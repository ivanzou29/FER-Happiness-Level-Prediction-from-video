Epoch: 1| Step: 0
Training loss: 7.4291481119103535
Validation loss: 6.590674254452956

Epoch: 6| Step: 1
Training loss: 7.082555062416261
Validation loss: 6.5866749814443395

Epoch: 6| Step: 2
Training loss: 7.890955670670339
Validation loss: 6.58107066754324

Epoch: 6| Step: 3
Training loss: 6.693145365615027
Validation loss: 6.577397953524827

Epoch: 6| Step: 4
Training loss: 6.611748451834207
Validation loss: 6.576402951217878

Epoch: 6| Step: 5
Training loss: 6.961971801227292
Validation loss: 6.570623230137608

Epoch: 6| Step: 6
Training loss: 6.416712707090137
Validation loss: 6.56840090607264

Epoch: 6| Step: 7
Training loss: 6.055602249447666
Validation loss: 6.56669048973165

Epoch: 6| Step: 8
Training loss: 6.5270848476855825
Validation loss: 6.560962771585385

Epoch: 6| Step: 9
Training loss: 6.9694347643878976
Validation loss: 6.557904975441571

Epoch: 6| Step: 10
Training loss: 5.869793471906148
Validation loss: 6.55445616511138

Epoch: 6| Step: 11
Training loss: 5.781484898099547
Validation loss: 6.548491271187677

Epoch: 6| Step: 12
Training loss: 5.831780726576668
Validation loss: 6.5463386699906145

Epoch: 6| Step: 13
Training loss: 4.39253426848382
Validation loss: 6.546227582134616

Epoch: 2| Step: 0
Training loss: 6.469847360310957
Validation loss: 6.540942721898693

Epoch: 6| Step: 1
Training loss: 7.340574446398933
Validation loss: 6.535563441199723

Epoch: 6| Step: 2
Training loss: 6.554245471258287
Validation loss: 6.536207114569471

Epoch: 6| Step: 3
Training loss: 6.268017851803498
Validation loss: 6.527833181736799

Epoch: 6| Step: 4
Training loss: 7.635078398396326
Validation loss: 6.526665730191876

Epoch: 6| Step: 5
Training loss: 6.1380476262496835
Validation loss: 6.519883758537447

Epoch: 6| Step: 6
Training loss: 6.5308615829105365
Validation loss: 6.516626374283492

Epoch: 6| Step: 7
Training loss: 6.061033091094921
Validation loss: 6.515626429048137

Epoch: 6| Step: 8
Training loss: 6.940627484276064
Validation loss: 6.509988633652753

Epoch: 6| Step: 9
Training loss: 5.956567604907707
Validation loss: 6.507948622834541

Epoch: 6| Step: 10
Training loss: 6.0035224747220015
Validation loss: 6.504039730146078

Epoch: 6| Step: 11
Training loss: 6.267231190732931
Validation loss: 6.499670526753949

Epoch: 6| Step: 12
Training loss: 6.550569279516261
Validation loss: 6.495835487056848

Epoch: 6| Step: 13
Training loss: 6.263564077650518
Validation loss: 6.490341551753851

Epoch: 3| Step: 0
Training loss: 6.593782976257884
Validation loss: 6.486815839324343

Epoch: 6| Step: 1
Training loss: 5.847281791200346
Validation loss: 6.482180117749481

Epoch: 6| Step: 2
Training loss: 6.618283880172767
Validation loss: 6.475849567728965

Epoch: 6| Step: 3
Training loss: 6.393430807400176
Validation loss: 6.472224649751056

Epoch: 6| Step: 4
Training loss: 6.4724944698211395
Validation loss: 6.46828922855774

Epoch: 6| Step: 5
Training loss: 7.282060962751848
Validation loss: 6.463551990697484

Epoch: 6| Step: 6
Training loss: 6.832038229431112
Validation loss: 6.456488682953809

Epoch: 6| Step: 7
Training loss: 5.818944824104006
Validation loss: 6.4568884157761905

Epoch: 6| Step: 8
Training loss: 6.844533657687055
Validation loss: 6.453019483909794

Epoch: 6| Step: 9
Training loss: 6.235041914908356
Validation loss: 6.446946674705014

Epoch: 6| Step: 10
Training loss: 6.37197385283791
Validation loss: 6.44164904082983

Epoch: 6| Step: 11
Training loss: 6.521250686045883
Validation loss: 6.440497896925003

Epoch: 6| Step: 12
Training loss: 5.842811549918526
Validation loss: 6.4309500563351065

Epoch: 6| Step: 13
Training loss: 6.844161069186405
Validation loss: 6.426894952430465

Epoch: 4| Step: 0
Training loss: 6.7316594501383324
Validation loss: 6.4221303228529765

Epoch: 6| Step: 1
Training loss: 7.19588717506939
Validation loss: 6.416049460409588

Epoch: 6| Step: 2
Training loss: 6.449839496833398
Validation loss: 6.413422601763459

Epoch: 6| Step: 3
Training loss: 7.14652654401333
Validation loss: 6.4061315269930486

Epoch: 6| Step: 4
Training loss: 7.09627753446773
Validation loss: 6.399264749470139

Epoch: 6| Step: 5
Training loss: 6.998657097749182
Validation loss: 6.3991263435470325

Epoch: 6| Step: 6
Training loss: 6.185060578946206
Validation loss: 6.393920106699629

Epoch: 6| Step: 7
Training loss: 5.471068147073464
Validation loss: 6.390348696698408

Epoch: 6| Step: 8
Training loss: 6.461281708447479
Validation loss: 6.384558017331606

Epoch: 6| Step: 9
Training loss: 5.195278907609913
Validation loss: 6.378320741536538

Epoch: 6| Step: 10
Training loss: 6.100860359928562
Validation loss: 6.371078298348581

Epoch: 6| Step: 11
Training loss: 5.742431635435157
Validation loss: 6.369486567828717

Epoch: 6| Step: 12
Training loss: 5.671864575252989
Validation loss: 6.363984453205572

Epoch: 6| Step: 13
Training loss: 6.833369495327175
Validation loss: 6.357536749056096

Epoch: 5| Step: 0
Training loss: 5.742838836890178
Validation loss: 6.350962796777986

Epoch: 6| Step: 1
Training loss: 5.248687216702791
Validation loss: 6.346806504589405

Epoch: 6| Step: 2
Training loss: 5.257764433461103
Validation loss: 6.349112080390849

Epoch: 6| Step: 3
Training loss: 5.985885867635744
Validation loss: 6.336826314367243

Epoch: 6| Step: 4
Training loss: 6.6600130574782845
Validation loss: 6.33450915373045

Epoch: 6| Step: 5
Training loss: 5.892627648843099
Validation loss: 6.328089167975681

Epoch: 6| Step: 6
Training loss: 6.819818607725953
Validation loss: 6.325659428581435

Epoch: 6| Step: 7
Training loss: 6.535520188891187
Validation loss: 6.324070994608341

Epoch: 6| Step: 8
Training loss: 7.0212746622020195
Validation loss: 6.310451472862121

Epoch: 6| Step: 9
Training loss: 5.6220997433060225
Validation loss: 6.309045366764207

Epoch: 6| Step: 10
Training loss: 6.472560773662153
Validation loss: 6.303180008157799

Epoch: 6| Step: 11
Training loss: 7.229313771036478
Validation loss: 6.297951487431094

Epoch: 6| Step: 12
Training loss: 6.946016599925839
Validation loss: 6.289242267631691

Epoch: 6| Step: 13
Training loss: 6.84313850632144
Validation loss: 6.2835739702434354

Epoch: 6| Step: 0
Training loss: 6.955226760557235
Validation loss: 6.280998021263523

Epoch: 6| Step: 1
Training loss: 6.627366992676294
Validation loss: 6.272841931280262

Epoch: 6| Step: 2
Training loss: 5.275289749937986
Validation loss: 6.265352605074915

Epoch: 6| Step: 3
Training loss: 7.144964790017228
Validation loss: 6.254685461510474

Epoch: 6| Step: 4
Training loss: 5.62251107994606
Validation loss: 6.252778710022373

Epoch: 6| Step: 5
Training loss: 6.1614974067160615
Validation loss: 6.2471900546342365

Epoch: 6| Step: 6
Training loss: 5.620687908820359
Validation loss: 6.244850718436187

Epoch: 6| Step: 7
Training loss: 5.439699977567446
Validation loss: 6.240303143341528

Epoch: 6| Step: 8
Training loss: 7.0859253871692225
Validation loss: 6.230782277694898

Epoch: 6| Step: 9
Training loss: 6.340291701384297
Validation loss: 6.221443729414159

Epoch: 6| Step: 10
Training loss: 6.939339608644439
Validation loss: 6.21262190299671

Epoch: 6| Step: 11
Training loss: 5.063280210302123
Validation loss: 6.212247066515777

Epoch: 6| Step: 12
Training loss: 6.168422689518164
Validation loss: 6.202303231611301

Epoch: 6| Step: 13
Training loss: 6.619064551237377
Validation loss: 6.1932923405457165

Epoch: 7| Step: 0
Training loss: 6.756528170043965
Validation loss: 6.191195653287387

Epoch: 6| Step: 1
Training loss: 7.051722582591855
Validation loss: 6.183416901029729

Epoch: 6| Step: 2
Training loss: 4.640888450671085
Validation loss: 6.175683213061398

Epoch: 6| Step: 3
Training loss: 5.6912239375398475
Validation loss: 6.170472881388599

Epoch: 6| Step: 4
Training loss: 6.465706371829667
Validation loss: 6.165329567318116

Epoch: 6| Step: 5
Training loss: 5.089652443581974
Validation loss: 6.155744018049787

Epoch: 6| Step: 6
Training loss: 4.960026214284227
Validation loss: 6.143443583175873

Epoch: 6| Step: 7
Training loss: 6.478927787801082
Validation loss: 6.141534800470524

Epoch: 6| Step: 8
Training loss: 6.784445014356888
Validation loss: 6.13509105863881

Epoch: 6| Step: 9
Training loss: 6.915261305852632
Validation loss: 6.126310428070003

Epoch: 6| Step: 10
Training loss: 5.887689400317359
Validation loss: 6.114286896826966

Epoch: 6| Step: 11
Training loss: 6.440772548801163
Validation loss: 6.109080238890753

Epoch: 6| Step: 12
Training loss: 6.277055089232666
Validation loss: 6.100841168081452

Epoch: 6| Step: 13
Training loss: 5.948772130621625
Validation loss: 6.0928740059770865

Epoch: 8| Step: 0
Training loss: 5.908189566100144
Validation loss: 6.087475280111836

Epoch: 6| Step: 1
Training loss: 6.113413224913307
Validation loss: 6.0782634136129

Epoch: 6| Step: 2
Training loss: 5.966609231398923
Validation loss: 6.067254246777447

Epoch: 6| Step: 3
Training loss: 6.7142588664158716
Validation loss: 6.065230124955142

Epoch: 6| Step: 4
Training loss: 6.234280157682413
Validation loss: 6.0543717772077175

Epoch: 6| Step: 5
Training loss: 5.395195568595144
Validation loss: 6.045843841730629

Epoch: 6| Step: 6
Training loss: 6.7279353319251225
Validation loss: 6.034215455786096

Epoch: 6| Step: 7
Training loss: 6.072314311581113
Validation loss: 6.026822249638243

Epoch: 6| Step: 8
Training loss: 5.747233513108652
Validation loss: 6.019781909996309

Epoch: 6| Step: 9
Training loss: 6.290996221058247
Validation loss: 6.009736622667635

Epoch: 6| Step: 10
Training loss: 5.90882841474207
Validation loss: 6.002692510607709

Epoch: 6| Step: 11
Training loss: 5.174307720669848
Validation loss: 5.989088185635244

Epoch: 6| Step: 12
Training loss: 6.79295723789637
Validation loss: 5.982151282023132

Epoch: 6| Step: 13
Training loss: 4.492570678290824
Validation loss: 5.976229578244501

Epoch: 9| Step: 0
Training loss: 6.244753657446185
Validation loss: 5.9693260213432735

Epoch: 6| Step: 1
Training loss: 5.1207322750357465
Validation loss: 5.959288604502575

Epoch: 6| Step: 2
Training loss: 6.288002142752945
Validation loss: 5.947220518493865

Epoch: 6| Step: 3
Training loss: 5.640632608255343
Validation loss: 5.939232810529913

Epoch: 6| Step: 4
Training loss: 6.58990742596681
Validation loss: 5.931183961304223

Epoch: 6| Step: 5
Training loss: 5.836932606864678
Validation loss: 5.917584444115156

Epoch: 6| Step: 6
Training loss: 4.58635048249597
Validation loss: 5.912799392276433

Epoch: 6| Step: 7
Training loss: 6.327060638209506
Validation loss: 5.896239393649422

Epoch: 6| Step: 8
Training loss: 5.434582333067344
Validation loss: 5.892820378564269

Epoch: 6| Step: 9
Training loss: 6.6109340262894145
Validation loss: 5.88095110084596

Epoch: 6| Step: 10
Training loss: 6.175462515494158
Validation loss: 5.868585775410884

Epoch: 6| Step: 11
Training loss: 5.53878529531588
Validation loss: 5.860851673944081

Epoch: 6| Step: 12
Training loss: 6.511440186471957
Validation loss: 5.85737340504184

Epoch: 6| Step: 13
Training loss: 5.111240617981824
Validation loss: 5.837893235236729

Epoch: 10| Step: 0
Training loss: 6.358089982655095
Validation loss: 5.8292603643100245

Epoch: 6| Step: 1
Training loss: 5.914965461120631
Validation loss: 5.82738039707534

Epoch: 6| Step: 2
Training loss: 4.907168940115669
Validation loss: 5.806762923163878

Epoch: 6| Step: 3
Training loss: 5.916013368169757
Validation loss: 5.79307875818757

Epoch: 6| Step: 4
Training loss: 5.931468590586422
Validation loss: 5.78651231560932

Epoch: 6| Step: 5
Training loss: 6.03902270463117
Validation loss: 5.774013104222788

Epoch: 6| Step: 6
Training loss: 5.5043633232629565
Validation loss: 5.764802253482998

Epoch: 6| Step: 7
Training loss: 6.358731024001227
Validation loss: 5.753716183271066

Epoch: 6| Step: 8
Training loss: 5.4337706657036
Validation loss: 5.7451922240663

Epoch: 6| Step: 9
Training loss: 5.7321367183121055
Validation loss: 5.7295268653857105

Epoch: 6| Step: 10
Training loss: 5.89749966675166
Validation loss: 5.7227990340635

Epoch: 6| Step: 11
Training loss: 5.65128981460016
Validation loss: 5.709804545026027

Epoch: 6| Step: 12
Training loss: 6.03291321586157
Validation loss: 5.692295825954326

Epoch: 6| Step: 13
Training loss: 4.171014475564799
Validation loss: 5.681330151820958

Epoch: 11| Step: 0
Training loss: 6.3565427579573655
Validation loss: 5.678005738824043

Epoch: 6| Step: 1
Training loss: 5.453806662377729
Validation loss: 5.665400160251487

Epoch: 6| Step: 2
Training loss: 4.54109836954183
Validation loss: 5.641308549423847

Epoch: 6| Step: 3
Training loss: 6.43301472377293
Validation loss: 5.641882853350256

Epoch: 6| Step: 4
Training loss: 6.341520772785493
Validation loss: 5.626949174034193

Epoch: 6| Step: 5
Training loss: 6.053543553728243
Validation loss: 5.615350202609737

Epoch: 6| Step: 6
Training loss: 5.381001160790772
Validation loss: 5.597552260871514

Epoch: 6| Step: 7
Training loss: 5.571597257442924
Validation loss: 5.587967349848559

Epoch: 6| Step: 8
Training loss: 4.893325011604017
Validation loss: 5.57512473462512

Epoch: 6| Step: 9
Training loss: 5.766676230597237
Validation loss: 5.5568148522242105

Epoch: 6| Step: 10
Training loss: 5.933431094503639
Validation loss: 5.542860856209694

Epoch: 6| Step: 11
Training loss: 4.547563533496429
Validation loss: 5.526208484792278

Epoch: 6| Step: 12
Training loss: 5.999112699385772
Validation loss: 5.520591195899583

Epoch: 6| Step: 13
Training loss: 3.9186355160382234
Validation loss: 5.506993561709243

Epoch: 12| Step: 0
Training loss: 6.791632092471749
Validation loss: 5.490327662461785

Epoch: 6| Step: 1
Training loss: 4.204768770553068
Validation loss: 5.480468248542367

Epoch: 6| Step: 2
Training loss: 5.718269703191473
Validation loss: 5.46168997941963

Epoch: 6| Step: 3
Training loss: 3.8351105150117273
Validation loss: 5.461971496724901

Epoch: 6| Step: 4
Training loss: 5.098872505169609
Validation loss: 5.437419997793513

Epoch: 6| Step: 5
Training loss: 5.485470393413104
Validation loss: 5.424363326583065

Epoch: 6| Step: 6
Training loss: 5.8684243271300645
Validation loss: 5.405570243604683

Epoch: 6| Step: 7
Training loss: 5.22774493380229
Validation loss: 5.399954134489196

Epoch: 6| Step: 8
Training loss: 6.06553432390927
Validation loss: 5.382370525866729

Epoch: 6| Step: 9
Training loss: 4.832746250846742
Validation loss: 5.369880101763229

Epoch: 6| Step: 10
Training loss: 6.367757235821374
Validation loss: 5.357955468616194

Epoch: 6| Step: 11
Training loss: 5.9005053804837075
Validation loss: 5.33560319763531

Epoch: 6| Step: 12
Training loss: 4.866133035292304
Validation loss: 5.3181066201701785

Epoch: 6| Step: 13
Training loss: 4.3180236823955145
Validation loss: 5.3131296825800005

Epoch: 13| Step: 0
Training loss: 5.260734845601197
Validation loss: 5.294779012029923

Epoch: 6| Step: 1
Training loss: 5.920499214053112
Validation loss: 5.275799231495563

Epoch: 6| Step: 2
Training loss: 5.175082500002868
Validation loss: 5.2603065046262465

Epoch: 6| Step: 3
Training loss: 5.3452123236168925
Validation loss: 5.2513678683428004

Epoch: 6| Step: 4
Training loss: 5.48466121437547
Validation loss: 5.230962085792555

Epoch: 6| Step: 5
Training loss: 4.872352468058735
Validation loss: 5.213657513047345

Epoch: 6| Step: 6
Training loss: 4.659910465739235
Validation loss: 5.203506472987411

Epoch: 6| Step: 7
Training loss: 5.684156168478858
Validation loss: 5.186227137479088

Epoch: 6| Step: 8
Training loss: 4.797459072874744
Validation loss: 5.158883502603872

Epoch: 6| Step: 9
Training loss: 4.665572287893476
Validation loss: 5.1490065484101395

Epoch: 6| Step: 10
Training loss: 4.895592649779813
Validation loss: 5.134695840390532

Epoch: 6| Step: 11
Training loss: 5.019967264319447
Validation loss: 5.116266285703791

Epoch: 6| Step: 12
Training loss: 5.853368666302537
Validation loss: 5.104516693361956

Epoch: 6| Step: 13
Training loss: 5.304432206899967
Validation loss: 5.081737178282793

Epoch: 14| Step: 0
Training loss: 4.543598475809125
Validation loss: 5.068939741634104

Epoch: 6| Step: 1
Training loss: 5.185296383427313
Validation loss: 5.044815594720919

Epoch: 6| Step: 2
Training loss: 4.332748422516851
Validation loss: 5.032790603231199

Epoch: 6| Step: 3
Training loss: 5.568863903726024
Validation loss: 5.014032449875968

Epoch: 6| Step: 4
Training loss: 4.998375247187264
Validation loss: 4.991590616553276

Epoch: 6| Step: 5
Training loss: 5.42941243963813
Validation loss: 4.977252492208541

Epoch: 6| Step: 6
Training loss: 5.830366015714388
Validation loss: 4.948467026710844

Epoch: 6| Step: 7
Training loss: 5.562823339772843
Validation loss: 4.94327172617967

Epoch: 6| Step: 8
Training loss: 5.14724444399243
Validation loss: 4.921402605431652

Epoch: 6| Step: 9
Training loss: 5.1620532121897496
Validation loss: 4.903312397776753

Epoch: 6| Step: 10
Training loss: 4.273222365185811
Validation loss: 4.86932042831417

Epoch: 6| Step: 11
Training loss: 4.446869750029842
Validation loss: 4.866842263414388

Epoch: 6| Step: 12
Training loss: 3.746192779664072
Validation loss: 4.84500181897153

Epoch: 6| Step: 13
Training loss: 5.279018314307402
Validation loss: 4.8256214486132

Epoch: 15| Step: 0
Training loss: 3.6192895042401525
Validation loss: 4.801298175210223

Epoch: 6| Step: 1
Training loss: 4.862143362739728
Validation loss: 4.7911503810159655

Epoch: 6| Step: 2
Training loss: 4.388013178274418
Validation loss: 4.7721311003584574

Epoch: 6| Step: 3
Training loss: 5.425153724848027
Validation loss: 4.751455629080317

Epoch: 6| Step: 4
Training loss: 5.100711675617268
Validation loss: 4.734115779222195

Epoch: 6| Step: 5
Training loss: 4.901896495098323
Validation loss: 4.7090132027625495

Epoch: 6| Step: 6
Training loss: 4.937752632727942
Validation loss: 4.69277604455213

Epoch: 6| Step: 7
Training loss: 4.216367147510689
Validation loss: 4.679612092646554

Epoch: 6| Step: 8
Training loss: 4.605731933942624
Validation loss: 4.644864181789494

Epoch: 6| Step: 9
Training loss: 5.199381813570353
Validation loss: 4.633283441386653

Epoch: 6| Step: 10
Training loss: 4.8815715219887945
Validation loss: 4.610143843139445

Epoch: 6| Step: 11
Training loss: 5.00899040663873
Validation loss: 4.5893289223285505

Epoch: 6| Step: 12
Training loss: 3.4850939363930205
Validation loss: 4.571170346834399

Epoch: 6| Step: 13
Training loss: 5.290067095556377
Validation loss: 4.548340750933573

Epoch: 16| Step: 0
Training loss: 4.211138152542008
Validation loss: 4.532991167983539

Epoch: 6| Step: 1
Training loss: 5.296772013425444
Validation loss: 4.507425689693519

Epoch: 6| Step: 2
Training loss: 4.915808047738137
Validation loss: 4.495461484803566

Epoch: 6| Step: 3
Training loss: 4.102090972278483
Validation loss: 4.485576404533704

Epoch: 6| Step: 4
Training loss: 4.651668265732085
Validation loss: 4.453575329407661

Epoch: 6| Step: 5
Training loss: 5.5657121620442735
Validation loss: 4.419161090820898

Epoch: 6| Step: 6
Training loss: 3.568407213947935
Validation loss: 4.395833089167819

Epoch: 6| Step: 7
Training loss: 4.880165688875625
Validation loss: 4.377371110040521

Epoch: 6| Step: 8
Training loss: 2.6765051983134875
Validation loss: 4.349936779007404

Epoch: 6| Step: 9
Training loss: 5.057470389867326
Validation loss: 4.339639605896042

Epoch: 6| Step: 10
Training loss: 4.872925145648931
Validation loss: 4.3244435327649775

Epoch: 6| Step: 11
Training loss: 3.2237467082651348
Validation loss: 4.290194484211835

Epoch: 6| Step: 12
Training loss: 4.247923848793253
Validation loss: 4.274212173495631

Epoch: 6| Step: 13
Training loss: 3.7370685136948993
Validation loss: 4.25414657746318

Epoch: 17| Step: 0
Training loss: 4.660461978524391
Validation loss: 4.2206906174711305

Epoch: 6| Step: 1
Training loss: 4.507680061285639
Validation loss: 4.1996177004199335

Epoch: 6| Step: 2
Training loss: 4.781320608777037
Validation loss: 4.169444945072931

Epoch: 6| Step: 3
Training loss: 4.801564660957861
Validation loss: 4.129360492083034

Epoch: 6| Step: 4
Training loss: 4.188788144704363
Validation loss: 4.126482724736723

Epoch: 6| Step: 5
Training loss: 4.168702708924039
Validation loss: 4.111639090268304

Epoch: 6| Step: 6
Training loss: 4.453844942488289
Validation loss: 4.095667356460216

Epoch: 6| Step: 7
Training loss: 3.618294663845672
Validation loss: 4.073883240720516

Epoch: 6| Step: 8
Training loss: 3.844373202781648
Validation loss: 4.041638194826342

Epoch: 6| Step: 9
Training loss: 4.582522418794042
Validation loss: 4.024153313269284

Epoch: 6| Step: 10
Training loss: 3.640344960980556
Validation loss: 4.000373725454848

Epoch: 6| Step: 11
Training loss: 3.0608636026385625
Validation loss: 3.9774592612325588

Epoch: 6| Step: 12
Training loss: 3.7583917183298823
Validation loss: 3.945233129456119

Epoch: 6| Step: 13
Training loss: 3.5998843704303547
Validation loss: 3.937446238379756

Epoch: 18| Step: 0
Training loss: 3.34112731183162
Validation loss: 3.9168823327247275

Epoch: 6| Step: 1
Training loss: 4.0039238757234
Validation loss: 3.894144222550279

Epoch: 6| Step: 2
Training loss: 2.9852811226662817
Validation loss: 3.8668244593470846

Epoch: 6| Step: 3
Training loss: 4.2939956172783935
Validation loss: 3.849818751428029

Epoch: 6| Step: 4
Training loss: 3.57620414248482
Validation loss: 3.8231608479999597

Epoch: 6| Step: 5
Training loss: 4.540640105440936
Validation loss: 3.8053599350415785

Epoch: 6| Step: 6
Training loss: 3.7731110804807977
Validation loss: 3.7853174681851733

Epoch: 6| Step: 7
Training loss: 2.8904427135830546
Validation loss: 3.765071052889985

Epoch: 6| Step: 8
Training loss: 3.972428186822625
Validation loss: 3.738017116397907

Epoch: 6| Step: 9
Training loss: 4.482883537636431
Validation loss: 3.718915026201715

Epoch: 6| Step: 10
Training loss: 4.370330280244601
Validation loss: 3.694195126439147

Epoch: 6| Step: 11
Training loss: 4.093555707907275
Validation loss: 3.6679806862476947

Epoch: 6| Step: 12
Training loss: 3.861917253007836
Validation loss: 3.650331640411389

Epoch: 6| Step: 13
Training loss: 3.0840926051702184
Validation loss: 3.621186041745178

Epoch: 19| Step: 0
Training loss: 3.586703881374376
Validation loss: 3.6051419103009796

Epoch: 6| Step: 1
Training loss: 4.255144259633049
Validation loss: 3.5768360747356747

Epoch: 6| Step: 2
Training loss: 3.3151718016879657
Validation loss: 3.555041610314797

Epoch: 6| Step: 3
Training loss: 3.397349075883755
Validation loss: 3.5204761894603207

Epoch: 6| Step: 4
Training loss: 3.6539822580108283
Validation loss: 3.5040381351393672

Epoch: 6| Step: 5
Training loss: 3.2834857408293234
Validation loss: 3.493487130370786

Epoch: 6| Step: 6
Training loss: 3.69398264918773
Validation loss: 3.486380952980768

Epoch: 6| Step: 7
Training loss: 2.9309979165680535
Validation loss: 3.450143021996637

Epoch: 6| Step: 8
Training loss: 3.8594565440841317
Validation loss: 3.4338027834661955

Epoch: 6| Step: 9
Training loss: 3.650909697160598
Validation loss: 3.398836290919085

Epoch: 6| Step: 10
Training loss: 3.5495753826815495
Validation loss: 3.3955733240418207

Epoch: 6| Step: 11
Training loss: 3.567759462904421
Validation loss: 3.3614718792380556

Epoch: 6| Step: 12
Training loss: 3.8217234122156905
Validation loss: 3.353124953698691

Epoch: 6| Step: 13
Training loss: 3.866141746231393
Validation loss: 3.332790655650632

Epoch: 20| Step: 0
Training loss: 3.0484926282315863
Validation loss: 3.325954496123782

Epoch: 6| Step: 1
Training loss: 3.6646485988464628
Validation loss: 3.2942679767757572

Epoch: 6| Step: 2
Training loss: 3.0792311796279237
Validation loss: 3.273852073298106

Epoch: 6| Step: 3
Training loss: 3.3520459091028867
Validation loss: 3.243189689603479

Epoch: 6| Step: 4
Training loss: 3.891934706764587
Validation loss: 3.234817855816303

Epoch: 6| Step: 5
Training loss: 3.984082379535015
Validation loss: 3.1941511752236473

Epoch: 6| Step: 6
Training loss: 3.1561818634836776
Validation loss: 3.1911213294360263

Epoch: 6| Step: 7
Training loss: 3.128110634449719
Validation loss: 3.1572012233964792

Epoch: 6| Step: 8
Training loss: 4.088487810237777
Validation loss: 3.1399210267056903

Epoch: 6| Step: 9
Training loss: 3.3375071779095333
Validation loss: 3.131499144797123

Epoch: 6| Step: 10
Training loss: 2.5640045029277805
Validation loss: 3.104275779901384

Epoch: 6| Step: 11
Training loss: 3.752604660821265
Validation loss: 3.0900956712298977

Epoch: 6| Step: 12
Training loss: 2.654982140834822
Validation loss: 3.0925638736903602

Epoch: 6| Step: 13
Training loss: 2.4543737646866717
Validation loss: 3.057565363678646

Epoch: 21| Step: 0
Training loss: 3.6832351590935133
Validation loss: 3.046408830419093

Epoch: 6| Step: 1
Training loss: 3.218378138125758
Validation loss: 3.0225055404293797

Epoch: 6| Step: 2
Training loss: 2.9000662368576378
Validation loss: 3.0270731076384982

Epoch: 6| Step: 3
Training loss: 3.1560508740752224
Validation loss: 3.0222031121033823

Epoch: 6| Step: 4
Training loss: 2.676956431031812
Validation loss: 3.0012694838085423

Epoch: 6| Step: 5
Training loss: 3.659532426661514
Validation loss: 2.980266992300409

Epoch: 6| Step: 6
Training loss: 2.8691545853557576
Validation loss: 2.9623647175452166

Epoch: 6| Step: 7
Training loss: 2.607263315930363
Validation loss: 2.964561149646707

Epoch: 6| Step: 8
Training loss: 3.1610631219148377
Validation loss: 2.931179984631576

Epoch: 6| Step: 9
Training loss: 3.3353316674887554
Validation loss: 2.9238900104450583

Epoch: 6| Step: 10
Training loss: 4.343695551030144
Validation loss: 2.923567522058991

Epoch: 6| Step: 11
Training loss: 2.627403249075397
Validation loss: 2.9181716557811246

Epoch: 6| Step: 12
Training loss: 2.569005941370014
Validation loss: 2.8851242625094464

Epoch: 6| Step: 13
Training loss: 3.257830795858772
Validation loss: 2.893294531666603

Epoch: 22| Step: 0
Training loss: 3.345815430653056
Validation loss: 2.8846655558410865

Epoch: 6| Step: 1
Training loss: 3.388293048889994
Validation loss: 2.8837782808890444

Epoch: 6| Step: 2
Training loss: 3.439526463451858
Validation loss: 2.852023928544725

Epoch: 6| Step: 3
Training loss: 3.0488859925041614
Validation loss: 2.8421626086367477

Epoch: 6| Step: 4
Training loss: 3.3377027642881587
Validation loss: 2.8333712134341456

Epoch: 6| Step: 5
Training loss: 3.343559473616894
Validation loss: 2.8193124345556297

Epoch: 6| Step: 6
Training loss: 2.4537784167843597
Validation loss: 2.834686374855835

Epoch: 6| Step: 7
Training loss: 3.314258900190979
Validation loss: 2.8039845999667445

Epoch: 6| Step: 8
Training loss: 3.137815366906478
Validation loss: 2.8041516979153043

Epoch: 6| Step: 9
Training loss: 3.171545002124436
Validation loss: 2.7878469257069347

Epoch: 6| Step: 10
Training loss: 2.196209272985125
Validation loss: 2.7883394528391157

Epoch: 6| Step: 11
Training loss: 2.6678446214432765
Validation loss: 2.792862731587387

Epoch: 6| Step: 12
Training loss: 3.0933695857894365
Validation loss: 2.79651007967336

Epoch: 6| Step: 13
Training loss: 2.6181797253354695
Validation loss: 2.7899303231102865

Epoch: 23| Step: 0
Training loss: 3.354828921190185
Validation loss: 2.776729477676429

Epoch: 6| Step: 1
Training loss: 3.3797685349793736
Validation loss: 2.749740723537119

Epoch: 6| Step: 2
Training loss: 3.325741196244009
Validation loss: 2.7535232672113668

Epoch: 6| Step: 3
Training loss: 2.6929886239792835
Validation loss: 2.7520549215060073

Epoch: 6| Step: 4
Training loss: 2.356949930428803
Validation loss: 2.773458713864589

Epoch: 6| Step: 5
Training loss: 3.2708772466024016
Validation loss: 2.7410375250315204

Epoch: 6| Step: 6
Training loss: 3.100569481993735
Validation loss: 2.724030841340855

Epoch: 6| Step: 7
Training loss: 2.5358689163156845
Validation loss: 2.7362136008200406

Epoch: 6| Step: 8
Training loss: 3.132842941326541
Validation loss: 2.7301353173426586

Epoch: 6| Step: 9
Training loss: 2.7754730062049977
Validation loss: 2.7338520793472223

Epoch: 6| Step: 10
Training loss: 3.6131611572103495
Validation loss: 2.702140077176076

Epoch: 6| Step: 11
Training loss: 3.174209261970883
Validation loss: 2.7236628685783058

Epoch: 6| Step: 12
Training loss: 2.470455498028009
Validation loss: 2.7223439331364636

Epoch: 6| Step: 13
Training loss: 3.04658906035076
Validation loss: 2.717332749916952

Epoch: 24| Step: 0
Training loss: 2.932066742224565
Validation loss: 2.716844480995099

Epoch: 6| Step: 1
Training loss: 2.7010685148619906
Validation loss: 2.6977868425233944

Epoch: 6| Step: 2
Training loss: 2.964694013068716
Validation loss: 2.692245471861466

Epoch: 6| Step: 3
Training loss: 2.0296877208354265
Validation loss: 2.707706240301339

Epoch: 6| Step: 4
Training loss: 3.329189792850334
Validation loss: 2.7079688711233803

Epoch: 6| Step: 5
Training loss: 3.031658499023217
Validation loss: 2.6853733400601008

Epoch: 6| Step: 6
Training loss: 3.313808542581295
Validation loss: 2.6891205259595212

Epoch: 6| Step: 7
Training loss: 2.94701985623104
Validation loss: 2.704966340761911

Epoch: 6| Step: 8
Training loss: 3.607409714212042
Validation loss: 2.702837137086458

Epoch: 6| Step: 9
Training loss: 2.808905954211877
Validation loss: 2.6615587107243206

Epoch: 6| Step: 10
Training loss: 2.4351075976213883
Validation loss: 2.6761045342824965

Epoch: 6| Step: 11
Training loss: 3.2728976075321463
Validation loss: 2.709016149377869

Epoch: 6| Step: 12
Training loss: 3.372868889385253
Validation loss: 2.6805556652563483

Epoch: 6| Step: 13
Training loss: 2.549887905275009
Validation loss: 2.6856736303938935

Epoch: 25| Step: 0
Training loss: 3.182546768743815
Validation loss: 2.6864226906136555

Epoch: 6| Step: 1
Training loss: 2.967268082025193
Validation loss: 2.6893058446570874

Epoch: 6| Step: 2
Training loss: 2.952624727694458
Validation loss: 2.6852553328356312

Epoch: 6| Step: 3
Training loss: 3.314185811167259
Validation loss: 2.6854228658822654

Epoch: 6| Step: 4
Training loss: 2.5693370510259843
Validation loss: 2.702164632470603

Epoch: 6| Step: 5
Training loss: 2.6847157804917607
Validation loss: 2.6954690638970926

Epoch: 6| Step: 6
Training loss: 2.9327929504751005
Validation loss: 2.684435731306665

Epoch: 6| Step: 7
Training loss: 1.787117446297518
Validation loss: 2.6778402527684437

Epoch: 6| Step: 8
Training loss: 2.598026197664061
Validation loss: 2.668470945805079

Epoch: 6| Step: 9
Training loss: 3.337197702268824
Validation loss: 2.6769677736502455

Epoch: 6| Step: 10
Training loss: 3.4067806565485688
Validation loss: 2.6628207332301366

Epoch: 6| Step: 11
Training loss: 3.796080329527432
Validation loss: 2.670529269211961

Epoch: 6| Step: 12
Training loss: 2.4514545171331967
Validation loss: 2.6834734137272616

Epoch: 6| Step: 13
Training loss: 3.824908341450237
Validation loss: 2.682435835490173

Epoch: 26| Step: 0
Training loss: 3.3555959337708923
Validation loss: 2.6656830627829184

Epoch: 6| Step: 1
Training loss: 3.7246900288691442
Validation loss: 2.647541575700654

Epoch: 6| Step: 2
Training loss: 2.18698986099607
Validation loss: 2.6456580135856758

Epoch: 6| Step: 3
Training loss: 2.1515005021038176
Validation loss: 2.667558980925301

Epoch: 6| Step: 4
Training loss: 2.7586091271519875
Validation loss: 2.684450908150475

Epoch: 6| Step: 5
Training loss: 2.719868747685938
Validation loss: 2.663519858689702

Epoch: 6| Step: 6
Training loss: 3.522710145701727
Validation loss: 2.662295747700754

Epoch: 6| Step: 7
Training loss: 3.055711813505132
Validation loss: 2.6946705395346484

Epoch: 6| Step: 8
Training loss: 3.2601247215986104
Validation loss: 2.6872313036744875

Epoch: 6| Step: 9
Training loss: 2.6265697327105206
Validation loss: 2.6599709576658874

Epoch: 6| Step: 10
Training loss: 2.3170878290513377
Validation loss: 2.666487825905757

Epoch: 6| Step: 11
Training loss: 3.7650411952628575
Validation loss: 2.673864518516879

Epoch: 6| Step: 12
Training loss: 2.1732448950522922
Validation loss: 2.65387524223384

Epoch: 6| Step: 13
Training loss: 3.987603170082653
Validation loss: 2.680852672034582

Epoch: 27| Step: 0
Training loss: 3.050671525415584
Validation loss: 2.658948178673311

Epoch: 6| Step: 1
Training loss: 2.9700317828086544
Validation loss: 2.66721946584263

Epoch: 6| Step: 2
Training loss: 3.758562485052035
Validation loss: 2.6594404851048727

Epoch: 6| Step: 3
Training loss: 3.073150177612568
Validation loss: 2.696554836015085

Epoch: 6| Step: 4
Training loss: 2.897073347591193
Validation loss: 2.6754762647432986

Epoch: 6| Step: 5
Training loss: 2.94975807361741
Validation loss: 2.683787635727207

Epoch: 6| Step: 6
Training loss: 2.7794572860309628
Validation loss: 2.677994424421375

Epoch: 6| Step: 7
Training loss: 3.1136812840938
Validation loss: 2.66130393327133

Epoch: 6| Step: 8
Training loss: 2.6250839219983386
Validation loss: 2.6624737775005163

Epoch: 6| Step: 9
Training loss: 3.162216740765277
Validation loss: 2.6507370916447184

Epoch: 6| Step: 10
Training loss: 2.9206032662835053
Validation loss: 2.662118315579195

Epoch: 6| Step: 11
Training loss: 2.9187906070473923
Validation loss: 2.683944236717709

Epoch: 6| Step: 12
Training loss: 2.643057521013723
Validation loss: 2.675123900000527

Epoch: 6| Step: 13
Training loss: 2.9816471435123786
Validation loss: 2.6602437676527706

Epoch: 28| Step: 0
Training loss: 2.91888078482331
Validation loss: 2.6997451113485837

Epoch: 6| Step: 1
Training loss: 2.584345116955689
Validation loss: 2.645055219627993

Epoch: 6| Step: 2
Training loss: 3.380352438434819
Validation loss: 2.6569364853796262

Epoch: 6| Step: 3
Training loss: 2.890942200448748
Validation loss: 2.650106785999218

Epoch: 6| Step: 4
Training loss: 3.389225684212456
Validation loss: 2.6740458785177657

Epoch: 6| Step: 5
Training loss: 3.42497162076233
Validation loss: 2.6748551153615865

Epoch: 6| Step: 6
Training loss: 3.057463104449635
Validation loss: 2.6645347112478297

Epoch: 6| Step: 7
Training loss: 2.99271892081456
Validation loss: 2.6656914816662427

Epoch: 6| Step: 8
Training loss: 2.548811474742072
Validation loss: 2.679239008384908

Epoch: 6| Step: 9
Training loss: 2.7427962189958603
Validation loss: 2.690210283115025

Epoch: 6| Step: 10
Training loss: 2.9905654056235753
Validation loss: 2.6927838077600343

Epoch: 6| Step: 11
Training loss: 2.8651012345514975
Validation loss: 2.6757656599057253

Epoch: 6| Step: 12
Training loss: 3.247919884158717
Validation loss: 2.6766432287905624

Epoch: 6| Step: 13
Training loss: 2.6266861904051253
Validation loss: 2.6706151481311484

Epoch: 29| Step: 0
Training loss: 2.456616583494372
Validation loss: 2.671329464906361

Epoch: 6| Step: 1
Training loss: 3.1770662567847086
Validation loss: 2.6621868413674825

Epoch: 6| Step: 2
Training loss: 2.8659974832676807
Validation loss: 2.6790354864149397

Epoch: 6| Step: 3
Training loss: 3.605098155639038
Validation loss: 2.6645595476707378

Epoch: 6| Step: 4
Training loss: 3.10113322556688
Validation loss: 2.6830793827180246

Epoch: 6| Step: 5
Training loss: 2.76788169041309
Validation loss: 2.696237857450926

Epoch: 6| Step: 6
Training loss: 3.615638483627354
Validation loss: 2.6868745229081887

Epoch: 6| Step: 7
Training loss: 2.9088585744543782
Validation loss: 2.6865847479762253

Epoch: 6| Step: 8
Training loss: 2.837811652054128
Validation loss: 2.672709693197744

Epoch: 6| Step: 9
Training loss: 3.3068808633380677
Validation loss: 2.6830354558717007

Epoch: 6| Step: 10
Training loss: 2.94411259906473
Validation loss: 2.6496447663088807

Epoch: 6| Step: 11
Training loss: 2.89565322279273
Validation loss: 2.659316588946124

Epoch: 6| Step: 12
Training loss: 2.6875886237147686
Validation loss: 2.6667534009097573

Epoch: 6| Step: 13
Training loss: 1.8901567115603384
Validation loss: 2.667282141779202

Epoch: 30| Step: 0
Training loss: 3.3628774438192717
Validation loss: 2.653795029300753

Epoch: 6| Step: 1
Training loss: 2.4082051050529167
Validation loss: 2.673706812256251

Epoch: 6| Step: 2
Training loss: 2.5802680154324324
Validation loss: 2.6725603285071164

Epoch: 6| Step: 3
Training loss: 1.987100726634291
Validation loss: 2.6568977709793433

Epoch: 6| Step: 4
Training loss: 3.824899614799512
Validation loss: 2.6907984359220594

Epoch: 6| Step: 5
Training loss: 3.1737722350848228
Validation loss: 2.6657582807257243

Epoch: 6| Step: 6
Training loss: 3.247197630257692
Validation loss: 2.68386233671913

Epoch: 6| Step: 7
Training loss: 3.073690250245715
Validation loss: 2.6509190387642962

Epoch: 6| Step: 8
Training loss: 2.4007223472730637
Validation loss: 2.670383117698618

Epoch: 6| Step: 9
Training loss: 3.0104895630208746
Validation loss: 2.6632719068805195

Epoch: 6| Step: 10
Training loss: 3.612437216665245
Validation loss: 2.6889493992134756

Epoch: 6| Step: 11
Training loss: 2.008969341046035
Validation loss: 2.6740537974695173

Epoch: 6| Step: 12
Training loss: 3.0453413796070823
Validation loss: 2.683286434898245

Epoch: 6| Step: 13
Training loss: 3.485826677435651
Validation loss: 2.654931244737487

Epoch: 31| Step: 0
Training loss: 2.5943179140769423
Validation loss: 2.661574671070336

Epoch: 6| Step: 1
Training loss: 3.613663408844531
Validation loss: 2.6664971681019503

Epoch: 6| Step: 2
Training loss: 2.8007860170374355
Validation loss: 2.6836910399434633

Epoch: 6| Step: 3
Training loss: 3.1015426673543334
Validation loss: 2.653572595867289

Epoch: 6| Step: 4
Training loss: 2.5225771922615112
Validation loss: 2.686193865659074

Epoch: 6| Step: 5
Training loss: 3.8740565474306683
Validation loss: 2.6743300420386324

Epoch: 6| Step: 6
Training loss: 1.5602617635945126
Validation loss: 2.6493609190063308

Epoch: 6| Step: 7
Training loss: 2.747205441402985
Validation loss: 2.6638273119022617

Epoch: 6| Step: 8
Training loss: 2.7038040631198044
Validation loss: 2.658590963833596

Epoch: 6| Step: 9
Training loss: 2.8770207476777707
Validation loss: 2.6605876773755788

Epoch: 6| Step: 10
Training loss: 3.1413336566391643
Validation loss: 2.659401225869801

Epoch: 6| Step: 11
Training loss: 2.717690623176822
Validation loss: 2.6568177747412847

Epoch: 6| Step: 12
Training loss: 2.927676718807702
Validation loss: 2.658613900228832

Epoch: 6| Step: 13
Training loss: 4.152344209342637
Validation loss: 2.658340795198344

Epoch: 32| Step: 0
Training loss: 3.515709091876228
Validation loss: 2.639939716986425

Epoch: 6| Step: 1
Training loss: 3.515703666654588
Validation loss: 2.6790770023589237

Epoch: 6| Step: 2
Training loss: 3.312400384520725
Validation loss: 2.649772891797506

Epoch: 6| Step: 3
Training loss: 2.3052034479414973
Validation loss: 2.6523366641633306

Epoch: 6| Step: 4
Training loss: 3.4967534130186415
Validation loss: 2.6666739127870778

Epoch: 6| Step: 5
Training loss: 2.7911078809542635
Validation loss: 2.6553601824862523

Epoch: 6| Step: 6
Training loss: 2.929549475915356
Validation loss: 2.7001266262178714

Epoch: 6| Step: 7
Training loss: 2.4951954450484393
Validation loss: 2.6717646754204347

Epoch: 6| Step: 8
Training loss: 3.188697889045009
Validation loss: 2.658458704934535

Epoch: 6| Step: 9
Training loss: 2.468750193149221
Validation loss: 2.6711048742702466

Epoch: 6| Step: 10
Training loss: 2.665376490181382
Validation loss: 2.651983166975691

Epoch: 6| Step: 11
Training loss: 2.8767078137097943
Validation loss: 2.6525056993641445

Epoch: 6| Step: 12
Training loss: 3.1951471486480356
Validation loss: 2.6621248134662254

Epoch: 6| Step: 13
Training loss: 2.1710878770878534
Validation loss: 2.672899666808232

Epoch: 33| Step: 0
Training loss: 2.823092709690875
Validation loss: 2.656535506422244

Epoch: 6| Step: 1
Training loss: 3.8506640765673663
Validation loss: 2.653395604574015

Epoch: 6| Step: 2
Training loss: 3.1808471064826955
Validation loss: 2.6983675674757497

Epoch: 6| Step: 3
Training loss: 3.110978063130202
Validation loss: 2.658364381807184

Epoch: 6| Step: 4
Training loss: 2.5033912545659938
Validation loss: 2.6587144512200513

Epoch: 6| Step: 5
Training loss: 2.3348836403388753
Validation loss: 2.672983483288632

Epoch: 6| Step: 6
Training loss: 2.88573111646565
Validation loss: 2.6494060331313443

Epoch: 6| Step: 7
Training loss: 3.0099901119335906
Validation loss: 2.6719343333194994

Epoch: 6| Step: 8
Training loss: 2.582122108603742
Validation loss: 2.6806256496570855

Epoch: 6| Step: 9
Training loss: 3.0914347298568092
Validation loss: 2.6744324436358697

Epoch: 6| Step: 10
Training loss: 2.9201160379111175
Validation loss: 2.6576375754871235

Epoch: 6| Step: 11
Training loss: 3.5453454303178806
Validation loss: 2.6356910064396404

Epoch: 6| Step: 12
Training loss: 3.0780909192672317
Validation loss: 2.669196198763372

Epoch: 6| Step: 13
Training loss: 1.8762645272055336
Validation loss: 2.6857720123815194

Epoch: 34| Step: 0
Training loss: 3.026297702342439
Validation loss: 2.6704968967476352

Epoch: 6| Step: 1
Training loss: 2.272069565366184
Validation loss: 2.6488023761228887

Epoch: 6| Step: 2
Training loss: 3.2500564863724777
Validation loss: 2.660929199087878

Epoch: 6| Step: 3
Training loss: 2.9905571143598055
Validation loss: 2.6692146519056674

Epoch: 6| Step: 4
Training loss: 3.368252402164948
Validation loss: 2.673772452258048

Epoch: 6| Step: 5
Training loss: 2.81491883426824
Validation loss: 2.6584196780736424

Epoch: 6| Step: 6
Training loss: 2.7018036010541984
Validation loss: 2.657343792334249

Epoch: 6| Step: 7
Training loss: 3.156725101782716
Validation loss: 2.6673283300866815

Epoch: 6| Step: 8
Training loss: 2.7841158899379055
Validation loss: 2.667028179262204

Epoch: 6| Step: 9
Training loss: 3.3843415573031717
Validation loss: 2.6475467832660065

Epoch: 6| Step: 10
Training loss: 3.020005913027602
Validation loss: 2.629998504511605

Epoch: 6| Step: 11
Training loss: 2.924747136589466
Validation loss: 2.652968644220214

Epoch: 6| Step: 12
Training loss: 2.5588289342053265
Validation loss: 2.6756444637532892

Epoch: 6| Step: 13
Training loss: 3.3728568725438106
Validation loss: 2.6653526049353804

Epoch: 35| Step: 0
Training loss: 3.060101406686004
Validation loss: 2.6492327803672073

Epoch: 6| Step: 1
Training loss: 2.7516746623775856
Validation loss: 2.636671521832233

Epoch: 6| Step: 2
Training loss: 3.582955909783518
Validation loss: 2.6529236612221765

Epoch: 6| Step: 3
Training loss: 2.5540215327072855
Validation loss: 2.6376368603143296

Epoch: 6| Step: 4
Training loss: 3.261194902029911
Validation loss: 2.6533139452280277

Epoch: 6| Step: 5
Training loss: 3.022893023688734
Validation loss: 2.663941668320705

Epoch: 6| Step: 6
Training loss: 2.61842476366048
Validation loss: 2.662262131127652

Epoch: 6| Step: 7
Training loss: 2.9795288363753074
Validation loss: 2.691812531714009

Epoch: 6| Step: 8
Training loss: 3.1622612241083927
Validation loss: 2.642975636342929

Epoch: 6| Step: 9
Training loss: 2.9461629838681107
Validation loss: 2.669372881907766

Epoch: 6| Step: 10
Training loss: 3.2209305275238034
Validation loss: 2.665824454949971

Epoch: 6| Step: 11
Training loss: 2.7367966745636827
Validation loss: 2.6421393304446763

Epoch: 6| Step: 12
Training loss: 2.9063600908982887
Validation loss: 2.6433298580466134

Epoch: 6| Step: 13
Training loss: 2.482402858466206
Validation loss: 2.653001826785501

Epoch: 36| Step: 0
Training loss: 2.6316938882120087
Validation loss: 2.669552380559777

Epoch: 6| Step: 1
Training loss: 2.987676900949186
Validation loss: 2.6807747323258644

Epoch: 6| Step: 2
Training loss: 2.7145247676813464
Validation loss: 2.6647197415584465

Epoch: 6| Step: 3
Training loss: 3.4589685216763324
Validation loss: 2.651276006063459

Epoch: 6| Step: 4
Training loss: 3.205427579640937
Validation loss: 2.6672102972645035

Epoch: 6| Step: 5
Training loss: 3.042430903606959
Validation loss: 2.6772150870948783

Epoch: 6| Step: 6
Training loss: 2.8176090883462606
Validation loss: 2.6502082633745965

Epoch: 6| Step: 7
Training loss: 2.532191442914725
Validation loss: 2.6682194917289843

Epoch: 6| Step: 8
Training loss: 2.9130566372038866
Validation loss: 2.641443317873136

Epoch: 6| Step: 9
Training loss: 3.4686878645546915
Validation loss: 2.6626349691917457

Epoch: 6| Step: 10
Training loss: 2.8627975908867045
Validation loss: 2.6632872129904595

Epoch: 6| Step: 11
Training loss: 3.1679666427435964
Validation loss: 2.662211509025384

Epoch: 6| Step: 12
Training loss: 2.534829610933173
Validation loss: 2.652525048577358

Epoch: 6| Step: 13
Training loss: 3.406169645429068
Validation loss: 2.668813926955335

Epoch: 37| Step: 0
Training loss: 2.8954519848644136
Validation loss: 2.6368266869210695

Epoch: 6| Step: 1
Training loss: 2.509166981589269
Validation loss: 2.6492451580831284

Epoch: 6| Step: 2
Training loss: 2.3148753364563155
Validation loss: 2.657985308142797

Epoch: 6| Step: 3
Training loss: 2.816065583809165
Validation loss: 2.664715626791969

Epoch: 6| Step: 4
Training loss: 3.1168318237227055
Validation loss: 2.662576209508626

Epoch: 6| Step: 5
Training loss: 2.710648491044974
Validation loss: 2.6517996561530257

Epoch: 6| Step: 6
Training loss: 3.4124310608771657
Validation loss: 2.676305586475598

Epoch: 6| Step: 7
Training loss: 2.613126148587668
Validation loss: 2.673178433958278

Epoch: 6| Step: 8
Training loss: 3.6019821749960474
Validation loss: 2.67453554391993

Epoch: 6| Step: 9
Training loss: 3.005426902469742
Validation loss: 2.6499204470441233

Epoch: 6| Step: 10
Training loss: 2.2334368677006284
Validation loss: 2.673238845035874

Epoch: 6| Step: 11
Training loss: 3.4678945775359606
Validation loss: 2.658221345841015

Epoch: 6| Step: 12
Training loss: 3.3743678313290624
Validation loss: 2.6699386840879784

Epoch: 6| Step: 13
Training loss: 2.8311028583345776
Validation loss: 2.655982201991028

Epoch: 38| Step: 0
Training loss: 2.8065762336580975
Validation loss: 2.6427298099556165

Epoch: 6| Step: 1
Training loss: 3.0287452653004805
Validation loss: 2.674782995990936

Epoch: 6| Step: 2
Training loss: 3.914054459432235
Validation loss: 2.6708910188704813

Epoch: 6| Step: 3
Training loss: 2.025182494429129
Validation loss: 2.6594151863605586

Epoch: 6| Step: 4
Training loss: 2.7989139903088276
Validation loss: 2.665065960476359

Epoch: 6| Step: 5
Training loss: 2.19496613617585
Validation loss: 2.6339149585385906

Epoch: 6| Step: 6
Training loss: 3.209480939117659
Validation loss: 2.6465494105587966

Epoch: 6| Step: 7
Training loss: 2.6873005637755445
Validation loss: 2.6740532625095925

Epoch: 6| Step: 8
Training loss: 3.6320567667805936
Validation loss: 2.663406966475213

Epoch: 6| Step: 9
Training loss: 2.291204186214054
Validation loss: 2.6751256115701145

Epoch: 6| Step: 10
Training loss: 3.362130387990568
Validation loss: 2.6515527895677358

Epoch: 6| Step: 11
Training loss: 2.621141504344456
Validation loss: 2.6639553793476365

Epoch: 6| Step: 12
Training loss: 3.350373312803223
Validation loss: 2.659145624690519

Epoch: 6| Step: 13
Training loss: 3.1636438163382543
Validation loss: 2.673416891200965

Epoch: 39| Step: 0
Training loss: 2.858273653643711
Validation loss: 2.6429028032186115

Epoch: 6| Step: 1
Training loss: 2.509572299977567
Validation loss: 2.665552754716626

Epoch: 6| Step: 2
Training loss: 2.271893268496014
Validation loss: 2.6241753294087733

Epoch: 6| Step: 3
Training loss: 3.9761274358333045
Validation loss: 2.652959121030461

Epoch: 6| Step: 4
Training loss: 2.750021327542919
Validation loss: 2.6394749376200757

Epoch: 6| Step: 5
Training loss: 3.3830388722431786
Validation loss: 2.647115037640094

Epoch: 6| Step: 6
Training loss: 2.5543587849370453
Validation loss: 2.643781165696114

Epoch: 6| Step: 7
Training loss: 3.311154938165252
Validation loss: 2.669204082159606

Epoch: 6| Step: 8
Training loss: 2.5543599049920425
Validation loss: 2.639661950816391

Epoch: 6| Step: 9
Training loss: 3.4008788711975053
Validation loss: 2.6323707647926846

Epoch: 6| Step: 10
Training loss: 2.7580030337642722
Validation loss: 2.6512071305747034

Epoch: 6| Step: 11
Training loss: 3.1462033961485267
Validation loss: 2.649687326172013

Epoch: 6| Step: 12
Training loss: 2.8258385451806967
Validation loss: 2.653010910149288

Epoch: 6| Step: 13
Training loss: 2.9042704413621374
Validation loss: 2.6767959944871063

Epoch: 40| Step: 0
Training loss: 3.498703307684874
Validation loss: 2.656941731459256

Epoch: 6| Step: 1
Training loss: 2.9766451606386535
Validation loss: 2.6581913049666888

Epoch: 6| Step: 2
Training loss: 2.8976793145819726
Validation loss: 2.6260662921188374

Epoch: 6| Step: 3
Training loss: 3.082958782919054
Validation loss: 2.669601972295587

Epoch: 6| Step: 4
Training loss: 2.661907678185443
Validation loss: 2.6552086040376786

Epoch: 6| Step: 5
Training loss: 2.4963382607158957
Validation loss: 2.6208851146846848

Epoch: 6| Step: 6
Training loss: 3.227207812048365
Validation loss: 2.6489022949653465

Epoch: 6| Step: 7
Training loss: 2.904145494016276
Validation loss: 2.6663669031869706

Epoch: 6| Step: 8
Training loss: 2.734724273172848
Validation loss: 2.666481635252624

Epoch: 6| Step: 9
Training loss: 3.4020945548631496
Validation loss: 2.6548502646397503

Epoch: 6| Step: 10
Training loss: 3.3379960509426008
Validation loss: 2.6523516206595708

Epoch: 6| Step: 11
Training loss: 2.715373430792226
Validation loss: 2.6342493231561357

Epoch: 6| Step: 12
Training loss: 3.0513332517175358
Validation loss: 2.651905319405077

Epoch: 6| Step: 13
Training loss: 1.680941588181763
Validation loss: 2.662709827465537

Epoch: 41| Step: 0
Training loss: 3.242899988778445
Validation loss: 2.641557412725088

Epoch: 6| Step: 1
Training loss: 3.32436577620843
Validation loss: 2.645492858981336

Epoch: 6| Step: 2
Training loss: 3.142700723991416
Validation loss: 2.6358533963747925

Epoch: 6| Step: 3
Training loss: 2.420059705108087
Validation loss: 2.6817554774649404

Epoch: 6| Step: 4
Training loss: 3.841335872108638
Validation loss: 2.6422576798531505

Epoch: 6| Step: 5
Training loss: 3.28220912902615
Validation loss: 2.6667144454500735

Epoch: 6| Step: 6
Training loss: 2.6239414805655663
Validation loss: 2.6444572808822273

Epoch: 6| Step: 7
Training loss: 2.4381036255541786
Validation loss: 2.652258600303548

Epoch: 6| Step: 8
Training loss: 2.812174205983873
Validation loss: 2.6555502426456554

Epoch: 6| Step: 9
Training loss: 3.2576659830568153
Validation loss: 2.6332561199145053

Epoch: 6| Step: 10
Training loss: 2.948530872283614
Validation loss: 2.647185694031925

Epoch: 6| Step: 11
Training loss: 2.4066007284217377
Validation loss: 2.6648919047356743

Epoch: 6| Step: 12
Training loss: 3.1919236248219938
Validation loss: 2.638310553984524

Epoch: 6| Step: 13
Training loss: 1.5932301440136711
Validation loss: 2.645056545520732

Epoch: 42| Step: 0
Training loss: 2.841525706564073
Validation loss: 2.656403452079915

Epoch: 6| Step: 1
Training loss: 2.1131916697020054
Validation loss: 2.6796446254207087

Epoch: 6| Step: 2
Training loss: 2.897659238400825
Validation loss: 2.6675207234251053

Epoch: 6| Step: 3
Training loss: 2.3438230375989546
Validation loss: 2.6473159460136664

Epoch: 6| Step: 4
Training loss: 2.9651670015852463
Validation loss: 2.641132921161057

Epoch: 6| Step: 5
Training loss: 2.6294867907589645
Validation loss: 2.6566945784290072

Epoch: 6| Step: 6
Training loss: 3.9977527504628156
Validation loss: 2.6763099856406267

Epoch: 6| Step: 7
Training loss: 2.893606431995992
Validation loss: 2.6408981256747386

Epoch: 6| Step: 8
Training loss: 3.618969340421947
Validation loss: 2.6515648518988892

Epoch: 6| Step: 9
Training loss: 3.4574206116802997
Validation loss: 2.6705006416518584

Epoch: 6| Step: 10
Training loss: 3.013156651518768
Validation loss: 2.6635496604426963

Epoch: 6| Step: 11
Training loss: 2.664890015356227
Validation loss: 2.6518723077644784

Epoch: 6| Step: 12
Training loss: 2.8027234014103555
Validation loss: 2.6437797615887413

Epoch: 6| Step: 13
Training loss: 2.465928022090636
Validation loss: 2.6553962006103347

Epoch: 43| Step: 0
Training loss: 3.9909527505874927
Validation loss: 2.652801696929219

Epoch: 6| Step: 1
Training loss: 3.3840131148767307
Validation loss: 2.629436199672988

Epoch: 6| Step: 2
Training loss: 2.671410414253002
Validation loss: 2.6766616995522012

Epoch: 6| Step: 3
Training loss: 2.7887753464364686
Validation loss: 2.6423781390021444

Epoch: 6| Step: 4
Training loss: 3.1958663945350954
Validation loss: 2.66334832922481

Epoch: 6| Step: 5
Training loss: 3.0589931417277967
Validation loss: 2.6464894955257123

Epoch: 6| Step: 6
Training loss: 3.06965486506229
Validation loss: 2.6549927865114564

Epoch: 6| Step: 7
Training loss: 2.270031452045087
Validation loss: 2.66763505029023

Epoch: 6| Step: 8
Training loss: 2.6209260116549142
Validation loss: 2.6375677603651804

Epoch: 6| Step: 9
Training loss: 2.2940420728781348
Validation loss: 2.6572807237660907

Epoch: 6| Step: 10
Training loss: 2.181937966707088
Validation loss: 2.629951983256466

Epoch: 6| Step: 11
Training loss: 3.741282184333668
Validation loss: 2.638519851824144

Epoch: 6| Step: 12
Training loss: 2.8224291691369197
Validation loss: 2.6579384327770255

Epoch: 6| Step: 13
Training loss: 2.495480266513659
Validation loss: 2.660155897279165

Epoch: 44| Step: 0
Training loss: 2.4057638494669122
Validation loss: 2.6495859343094272

Epoch: 6| Step: 1
Training loss: 2.74042630492094
Validation loss: 2.6367255496625224

Epoch: 6| Step: 2
Training loss: 2.8593678291939626
Validation loss: 2.639123503210292

Epoch: 6| Step: 3
Training loss: 3.0389987968299343
Validation loss: 2.6343243467327677

Epoch: 6| Step: 4
Training loss: 3.2382950914775055
Validation loss: 2.6548639550244326

Epoch: 6| Step: 5
Training loss: 2.6822757066171614
Validation loss: 2.6527675135671855

Epoch: 6| Step: 6
Training loss: 2.9715633513725908
Validation loss: 2.6315134555469313

Epoch: 6| Step: 7
Training loss: 3.401748622696363
Validation loss: 2.6570788784648705

Epoch: 6| Step: 8
Training loss: 2.844400352477362
Validation loss: 2.6426652391727727

Epoch: 6| Step: 9
Training loss: 3.4583664551646356
Validation loss: 2.6555289315843167

Epoch: 6| Step: 10
Training loss: 2.9035730646477704
Validation loss: 2.64858545293064

Epoch: 6| Step: 11
Training loss: 2.966358385963269
Validation loss: 2.6402299496520394

Epoch: 6| Step: 12
Training loss: 2.431684060072664
Validation loss: 2.6476745242124937

Epoch: 6| Step: 13
Training loss: 3.3632483574901446
Validation loss: 2.633831960335512

Epoch: 45| Step: 0
Training loss: 3.346178402966581
Validation loss: 2.6597160218548885

Epoch: 6| Step: 1
Training loss: 2.44827062333905
Validation loss: 2.6595438118395944

Epoch: 6| Step: 2
Training loss: 2.883530938170548
Validation loss: 2.676875590020696

Epoch: 6| Step: 3
Training loss: 3.5899986258586494
Validation loss: 2.66718482615662

Epoch: 6| Step: 4
Training loss: 2.1351826113076067
Validation loss: 2.668380164358893

Epoch: 6| Step: 5
Training loss: 2.920812240139869
Validation loss: 2.6339940629149803

Epoch: 6| Step: 6
Training loss: 2.7426787803053525
Validation loss: 2.6655791228707426

Epoch: 6| Step: 7
Training loss: 2.9078192627268047
Validation loss: 2.6523902274385005

Epoch: 6| Step: 8
Training loss: 2.6137807964479123
Validation loss: 2.6484221187165113

Epoch: 6| Step: 9
Training loss: 3.11719698414519
Validation loss: 2.6512458439464113

Epoch: 6| Step: 10
Training loss: 3.505370515620599
Validation loss: 2.6532791394590007

Epoch: 6| Step: 11
Training loss: 3.2447743586307713
Validation loss: 2.623925291311084

Epoch: 6| Step: 12
Training loss: 2.8078394103631403
Validation loss: 2.6677784685003063

Epoch: 6| Step: 13
Training loss: 2.5055897211572855
Validation loss: 2.660572894369466

Epoch: 46| Step: 0
Training loss: 2.714346289855073
Validation loss: 2.635629882579201

Epoch: 6| Step: 1
Training loss: 3.265444517852037
Validation loss: 2.6372205954742682

Epoch: 6| Step: 2
Training loss: 2.9204829362717883
Validation loss: 2.6435637916872357

Epoch: 6| Step: 3
Training loss: 3.0509838080962712
Validation loss: 2.649049418696974

Epoch: 6| Step: 4
Training loss: 2.663017358795671
Validation loss: 2.6571293552174664

Epoch: 6| Step: 5
Training loss: 3.064166802669215
Validation loss: 2.6565023033384856

Epoch: 6| Step: 6
Training loss: 2.3968761220280337
Validation loss: 2.644206180321933

Epoch: 6| Step: 7
Training loss: 2.3456128664462685
Validation loss: 2.6426925666534675

Epoch: 6| Step: 8
Training loss: 2.5826478992220756
Validation loss: 2.6723547409263895

Epoch: 6| Step: 9
Training loss: 3.642800397457672
Validation loss: 2.6364045511720646

Epoch: 6| Step: 10
Training loss: 3.1949835796859567
Validation loss: 2.642347546414627

Epoch: 6| Step: 11
Training loss: 3.6874164636492583
Validation loss: 2.630604794469194

Epoch: 6| Step: 12
Training loss: 2.629967847852385
Validation loss: 2.6551713600458955

Epoch: 6| Step: 13
Training loss: 2.71819475138398
Validation loss: 2.6534396008539445

Epoch: 47| Step: 0
Training loss: 3.4771618272908933
Validation loss: 2.6566370142238895

Epoch: 6| Step: 1
Training loss: 2.049744785518553
Validation loss: 2.657036671456556

Epoch: 6| Step: 2
Training loss: 3.0017221594013677
Validation loss: 2.665616889857316

Epoch: 6| Step: 3
Training loss: 2.690730969405756
Validation loss: 2.6502849429533697

Epoch: 6| Step: 4
Training loss: 3.6855968154572194
Validation loss: 2.6445511228737133

Epoch: 6| Step: 5
Training loss: 2.6575184205817277
Validation loss: 2.66435322245659

Epoch: 6| Step: 6
Training loss: 2.8875802165196967
Validation loss: 2.6492748842995257

Epoch: 6| Step: 7
Training loss: 3.554579915525109
Validation loss: 2.643005719215085

Epoch: 6| Step: 8
Training loss: 2.9602417140935255
Validation loss: 2.660424986555258

Epoch: 6| Step: 9
Training loss: 2.9835843142280094
Validation loss: 2.640277230685032

Epoch: 6| Step: 10
Training loss: 2.584154142193386
Validation loss: 2.6641104473769213

Epoch: 6| Step: 11
Training loss: 2.530237913894546
Validation loss: 2.6778823022907914

Epoch: 6| Step: 12
Training loss: 2.648622219429355
Validation loss: 2.667919992727966

Epoch: 6| Step: 13
Training loss: 2.7661315109312143
Validation loss: 2.6572730896018464

Epoch: 48| Step: 0
Training loss: 2.6914141340652393
Validation loss: 2.624614247751149

Epoch: 6| Step: 1
Training loss: 2.8023559740202444
Validation loss: 2.6342102334796724

Epoch: 6| Step: 2
Training loss: 3.141714941272807
Validation loss: 2.647651999939435

Epoch: 6| Step: 3
Training loss: 2.791834033864485
Validation loss: 2.6236707463627744

Epoch: 6| Step: 4
Training loss: 3.288125237597406
Validation loss: 2.647848184886237

Epoch: 6| Step: 5
Training loss: 2.351512312749593
Validation loss: 2.6580010719689438

Epoch: 6| Step: 6
Training loss: 2.5156841389593643
Validation loss: 2.630194088509331

Epoch: 6| Step: 7
Training loss: 3.234343007984518
Validation loss: 2.638590499366259

Epoch: 6| Step: 8
Training loss: 2.7702677060984824
Validation loss: 2.649657278522911

Epoch: 6| Step: 9
Training loss: 2.98855697257394
Validation loss: 2.6409529411769452

Epoch: 6| Step: 10
Training loss: 2.9894465150439795
Validation loss: 2.6419530680345447

Epoch: 6| Step: 11
Training loss: 3.4168898966987666
Validation loss: 2.632749173876249

Epoch: 6| Step: 12
Training loss: 3.0351179162234967
Validation loss: 2.6582731587764084

Epoch: 6| Step: 13
Training loss: 2.8361707018765823
Validation loss: 2.6461674391529124

Epoch: 49| Step: 0
Training loss: 3.0386719440460688
Validation loss: 2.658851946457535

Epoch: 6| Step: 1
Training loss: 2.3250176090681136
Validation loss: 2.644010178428716

Epoch: 6| Step: 2
Training loss: 2.469616894683535
Validation loss: 2.652574039535549

Epoch: 6| Step: 3
Training loss: 3.084357907635328
Validation loss: 2.652315636099402

Epoch: 6| Step: 4
Training loss: 2.9016927448512635
Validation loss: 2.639592443033923

Epoch: 6| Step: 5
Training loss: 2.7178029131755896
Validation loss: 2.6334237679617285

Epoch: 6| Step: 6
Training loss: 3.5022679201792655
Validation loss: 2.6503110001560617

Epoch: 6| Step: 7
Training loss: 2.9926800434507297
Validation loss: 2.6741220011071536

Epoch: 6| Step: 8
Training loss: 2.9626144451456957
Validation loss: 2.6323268419688883

Epoch: 6| Step: 9
Training loss: 3.6581015829890897
Validation loss: 2.649952532017485

Epoch: 6| Step: 10
Training loss: 2.3895902700636693
Validation loss: 2.6573690635269807

Epoch: 6| Step: 11
Training loss: 3.095192775115067
Validation loss: 2.6475395480590125

Epoch: 6| Step: 12
Training loss: 2.927047475864434
Validation loss: 2.6494711933970594

Epoch: 6| Step: 13
Training loss: 2.9403208722289205
Validation loss: 2.6297577801742675

Epoch: 50| Step: 0
Training loss: 2.8632356189875234
Validation loss: 2.663076238704301

Epoch: 6| Step: 1
Training loss: 2.7084442898445236
Validation loss: 2.6267403811626076

Epoch: 6| Step: 2
Training loss: 3.036445805222243
Validation loss: 2.6406375724278144

Epoch: 6| Step: 3
Training loss: 2.751564101262577
Validation loss: 2.636170131011226

Epoch: 6| Step: 4
Training loss: 2.747684891426461
Validation loss: 2.62774212420981

Epoch: 6| Step: 5
Training loss: 3.1764769595628723
Validation loss: 2.657257510551843

Epoch: 6| Step: 6
Training loss: 3.3738217593035063
Validation loss: 2.6753413755669078

Epoch: 6| Step: 7
Training loss: 3.452286838633014
Validation loss: 2.643618267780958

Epoch: 6| Step: 8
Training loss: 2.894533226846491
Validation loss: 2.648604192922848

Epoch: 6| Step: 9
Training loss: 2.4244897325219275
Validation loss: 2.669723084577438

Epoch: 6| Step: 10
Training loss: 2.9880731647322443
Validation loss: 2.6209511742647997

Epoch: 6| Step: 11
Training loss: 3.263029828659206
Validation loss: 2.639520973434798

Epoch: 6| Step: 12
Training loss: 2.4760366176307134
Validation loss: 2.6389601497243182

Epoch: 6| Step: 13
Training loss: 2.4571629232715204
Validation loss: 2.6510137012593495

Epoch: 51| Step: 0
Training loss: 3.0071763988497295
Validation loss: 2.636990135625544

Epoch: 6| Step: 1
Training loss: 2.096076469904662
Validation loss: 2.662752771575942

Epoch: 6| Step: 2
Training loss: 2.4460732736038118
Validation loss: 2.6603383450420712

Epoch: 6| Step: 3
Training loss: 2.579008008999941
Validation loss: 2.64258919753966

Epoch: 6| Step: 4
Training loss: 3.3017215630866525
Validation loss: 2.6390496792909857

Epoch: 6| Step: 5
Training loss: 3.544084568814379
Validation loss: 2.623988803030276

Epoch: 6| Step: 6
Training loss: 2.271748233076206
Validation loss: 2.6338474545637065

Epoch: 6| Step: 7
Training loss: 2.900621768462196
Validation loss: 2.623388264386859

Epoch: 6| Step: 8
Training loss: 3.218318873300043
Validation loss: 2.6359826356972964

Epoch: 6| Step: 9
Training loss: 3.351698794850362
Validation loss: 2.68126381617316

Epoch: 6| Step: 10
Training loss: 2.4135552030690572
Validation loss: 2.6206326383888277

Epoch: 6| Step: 11
Training loss: 3.040372041724435
Validation loss: 2.644522577624988

Epoch: 6| Step: 12
Training loss: 3.5667809982038357
Validation loss: 2.654052560869041

Epoch: 6| Step: 13
Training loss: 3.27592515763528
Validation loss: 2.631399170222863

Epoch: 52| Step: 0
Training loss: 3.593555611038525
Validation loss: 2.657544195598538

Epoch: 6| Step: 1
Training loss: 3.0871083802727584
Validation loss: 2.6481290654539946

Epoch: 6| Step: 2
Training loss: 3.114921798091814
Validation loss: 2.6544978926710083

Epoch: 6| Step: 3
Training loss: 2.6077170215679453
Validation loss: 2.63196565948856

Epoch: 6| Step: 4
Training loss: 3.6853161827061887
Validation loss: 2.6488477301049036

Epoch: 6| Step: 5
Training loss: 2.349301490049734
Validation loss: 2.649785811687241

Epoch: 6| Step: 6
Training loss: 2.0111612973470163
Validation loss: 2.6453752997316387

Epoch: 6| Step: 7
Training loss: 3.0673285585479726
Validation loss: 2.6540345103917553

Epoch: 6| Step: 8
Training loss: 3.635722121091885
Validation loss: 2.6193936752524385

Epoch: 6| Step: 9
Training loss: 2.0648014059931783
Validation loss: 2.636526884073614

Epoch: 6| Step: 10
Training loss: 2.5995057369813828
Validation loss: 2.652756058775952

Epoch: 6| Step: 11
Training loss: 2.4152298854617724
Validation loss: 2.6511575709094415

Epoch: 6| Step: 12
Training loss: 2.719530716972441
Validation loss: 2.645932902939106

Epoch: 6| Step: 13
Training loss: 4.13224618417288
Validation loss: 2.6438265767252407

Epoch: 53| Step: 0
Training loss: 2.2332212230195254
Validation loss: 2.656743172134696

Epoch: 6| Step: 1
Training loss: 2.7553935478467726
Validation loss: 2.645159992182183

Epoch: 6| Step: 2
Training loss: 2.9000029333691724
Validation loss: 2.651798764804745

Epoch: 6| Step: 3
Training loss: 2.746847513211052
Validation loss: 2.6668727440064375

Epoch: 6| Step: 4
Training loss: 3.702690002388018
Validation loss: 2.6566380033432715

Epoch: 6| Step: 5
Training loss: 2.19378467760636
Validation loss: 2.633825823842577

Epoch: 6| Step: 6
Training loss: 3.3397937793228074
Validation loss: 2.6306867104552962

Epoch: 6| Step: 7
Training loss: 2.7991661192460096
Validation loss: 2.62292652988548

Epoch: 6| Step: 8
Training loss: 3.3512181814320217
Validation loss: 2.6458170254603397

Epoch: 6| Step: 9
Training loss: 3.3485879569666364
Validation loss: 2.63248934399174

Epoch: 6| Step: 10
Training loss: 3.191374873143645
Validation loss: 2.648937616981047

Epoch: 6| Step: 11
Training loss: 2.8022708097419122
Validation loss: 2.6231633483625716

Epoch: 6| Step: 12
Training loss: 2.7755592504357467
Validation loss: 2.6431035923929085

Epoch: 6| Step: 13
Training loss: 2.466223377484316
Validation loss: 2.632778634530622

Epoch: 54| Step: 0
Training loss: 2.461306202228884
Validation loss: 2.647398804244065

Epoch: 6| Step: 1
Training loss: 3.941033125456733
Validation loss: 2.660583295092931

Epoch: 6| Step: 2
Training loss: 2.8299293452632575
Validation loss: 2.6423832626340995

Epoch: 6| Step: 3
Training loss: 3.144630117816857
Validation loss: 2.6426292929678716

Epoch: 6| Step: 4
Training loss: 2.9516135894408793
Validation loss: 2.6581071619003662

Epoch: 6| Step: 5
Training loss: 2.4518689870262267
Validation loss: 2.6512004603997688

Epoch: 6| Step: 6
Training loss: 3.531156015411353
Validation loss: 2.627386651826779

Epoch: 6| Step: 7
Training loss: 2.2206277557708107
Validation loss: 2.633418975412012

Epoch: 6| Step: 8
Training loss: 3.2155839478121617
Validation loss: 2.6412014449468533

Epoch: 6| Step: 9
Training loss: 3.0394683802209217
Validation loss: 2.6455732151021785

Epoch: 6| Step: 10
Training loss: 2.9611569929673625
Validation loss: 2.637312586555142

Epoch: 6| Step: 11
Training loss: 2.478500041506861
Validation loss: 2.6632976146649296

Epoch: 6| Step: 12
Training loss: 2.3360281323868373
Validation loss: 2.632932994012376

Epoch: 6| Step: 13
Training loss: 3.1925928158213783
Validation loss: 2.635140172295093

Epoch: 55| Step: 0
Training loss: 2.9046718455401184
Validation loss: 2.6375922544186894

Epoch: 6| Step: 1
Training loss: 2.6533214806367047
Validation loss: 2.6466860693375382

Epoch: 6| Step: 2
Training loss: 2.2994547778197414
Validation loss: 2.6308278620761882

Epoch: 6| Step: 3
Training loss: 2.8670695849710235
Validation loss: 2.6468099048733906

Epoch: 6| Step: 4
Training loss: 2.8250028120718946
Validation loss: 2.6097241804743727

Epoch: 6| Step: 5
Training loss: 3.071698446235322
Validation loss: 2.6483190371281227

Epoch: 6| Step: 6
Training loss: 3.041496968870018
Validation loss: 2.6380471655417965

Epoch: 6| Step: 7
Training loss: 2.668173116114727
Validation loss: 2.6240969734145314

Epoch: 6| Step: 8
Training loss: 3.111826481392073
Validation loss: 2.6521944765812813

Epoch: 6| Step: 9
Training loss: 3.381410797300816
Validation loss: 2.6519088527515398

Epoch: 6| Step: 10
Training loss: 2.954418080925483
Validation loss: 2.6449942365666885

Epoch: 6| Step: 11
Training loss: 3.7679367883486594
Validation loss: 2.6361385327809854

Epoch: 6| Step: 12
Training loss: 2.661151806124878
Validation loss: 2.640584721227408

Epoch: 6| Step: 13
Training loss: 2.6455054693257436
Validation loss: 2.6493053668966855

Epoch: 56| Step: 0
Training loss: 2.5660978971019377
Validation loss: 2.641660988647822

Epoch: 6| Step: 1
Training loss: 3.530143091689448
Validation loss: 2.635797112173215

Epoch: 6| Step: 2
Training loss: 3.502523057795015
Validation loss: 2.623064158439374

Epoch: 6| Step: 3
Training loss: 2.252286385114311
Validation loss: 2.638350179038544

Epoch: 6| Step: 4
Training loss: 2.4774163636410957
Validation loss: 2.644855271660038

Epoch: 6| Step: 5
Training loss: 2.6325395482236207
Validation loss: 2.637723741137735

Epoch: 6| Step: 6
Training loss: 2.9083031405946618
Validation loss: 2.617824500799412

Epoch: 6| Step: 7
Training loss: 3.2172544393666644
Validation loss: 2.6415099702074207

Epoch: 6| Step: 8
Training loss: 2.9494087208580195
Validation loss: 2.6541522897889984

Epoch: 6| Step: 9
Training loss: 2.738324609867564
Validation loss: 2.656426762508974

Epoch: 6| Step: 10
Training loss: 2.4267456299996026
Validation loss: 2.6121819935888793

Epoch: 6| Step: 11
Training loss: 3.328552075416908
Validation loss: 2.6302476163400033

Epoch: 6| Step: 12
Training loss: 3.4865978318294713
Validation loss: 2.6194142154696554

Epoch: 6| Step: 13
Training loss: 2.565295020940888
Validation loss: 2.6376902468247647

Epoch: 57| Step: 0
Training loss: 2.935516012084102
Validation loss: 2.633762271438887

Epoch: 6| Step: 1
Training loss: 2.626577539077539
Validation loss: 2.623216294510019

Epoch: 6| Step: 2
Training loss: 2.525932094648893
Validation loss: 2.626816413622714

Epoch: 6| Step: 3
Training loss: 2.7335358994329613
Validation loss: 2.666889805904943

Epoch: 6| Step: 4
Training loss: 2.9547039029509827
Validation loss: 2.644224723512413

Epoch: 6| Step: 5
Training loss: 3.2350811026310584
Validation loss: 2.633442309196242

Epoch: 6| Step: 6
Training loss: 2.8127680332893146
Validation loss: 2.6343332755357065

Epoch: 6| Step: 7
Training loss: 2.3401127375645214
Validation loss: 2.6169497273405735

Epoch: 6| Step: 8
Training loss: 2.5292434274336
Validation loss: 2.6607769970425164

Epoch: 6| Step: 9
Training loss: 3.078619128228488
Validation loss: 2.643545322412307

Epoch: 6| Step: 10
Training loss: 3.761399807189005
Validation loss: 2.6516783990987993

Epoch: 6| Step: 11
Training loss: 2.5689538768044633
Validation loss: 2.657397772014597

Epoch: 6| Step: 12
Training loss: 3.564836104211544
Validation loss: 2.6487907764276564

Epoch: 6| Step: 13
Training loss: 3.3864623503992166
Validation loss: 2.6627511406289712

Epoch: 58| Step: 0
Training loss: 3.173214784486144
Validation loss: 2.643430798389739

Epoch: 6| Step: 1
Training loss: 3.6485744671158686
Validation loss: 2.65639192321465

Epoch: 6| Step: 2
Training loss: 2.7145925721259907
Validation loss: 2.6452352635764633

Epoch: 6| Step: 3
Training loss: 3.2458122856688476
Validation loss: 2.63869933807846

Epoch: 6| Step: 4
Training loss: 3.2357434312656057
Validation loss: 2.6520760486109856

Epoch: 6| Step: 5
Training loss: 3.077539378579742
Validation loss: 2.6419295522709954

Epoch: 6| Step: 6
Training loss: 2.4497701459224257
Validation loss: 2.615952063920237

Epoch: 6| Step: 7
Training loss: 2.66775909538388
Validation loss: 2.650439519995908

Epoch: 6| Step: 8
Training loss: 3.481794282562717
Validation loss: 2.6627259879112013

Epoch: 6| Step: 9
Training loss: 3.100010865715427
Validation loss: 2.6386247488299595

Epoch: 6| Step: 10
Training loss: 2.2175975546725666
Validation loss: 2.6448566383633136

Epoch: 6| Step: 11
Training loss: 2.190299504323584
Validation loss: 2.6152862132221424

Epoch: 6| Step: 12
Training loss: 2.8509065892689827
Validation loss: 2.615144394299056

Epoch: 6| Step: 13
Training loss: 1.8011255824622694
Validation loss: 2.6155353785768334

Epoch: 59| Step: 0
Training loss: 2.132994368068666
Validation loss: 2.624516836723723

Epoch: 6| Step: 1
Training loss: 2.8431791633885743
Validation loss: 2.62282837197331

Epoch: 6| Step: 2
Training loss: 3.291004613297601
Validation loss: 2.61949417661863

Epoch: 6| Step: 3
Training loss: 3.0218287088661295
Validation loss: 2.632427088167923

Epoch: 6| Step: 4
Training loss: 2.9433937197316076
Validation loss: 2.6241102121808466

Epoch: 6| Step: 5
Training loss: 2.556982753350878
Validation loss: 2.6302628017565985

Epoch: 6| Step: 6
Training loss: 3.3615977895625027
Validation loss: 2.6198272126943283

Epoch: 6| Step: 7
Training loss: 3.6909998432863214
Validation loss: 2.6489823899132787

Epoch: 6| Step: 8
Training loss: 2.60892797969723
Validation loss: 2.6351343642733336

Epoch: 6| Step: 9
Training loss: 3.0006249094833746
Validation loss: 2.6341418665125658

Epoch: 6| Step: 10
Training loss: 1.3543768890747923
Validation loss: 2.6158981406643447

Epoch: 6| Step: 11
Training loss: 2.675505909362324
Validation loss: 2.6284545867357636

Epoch: 6| Step: 12
Training loss: 3.7658270943889582
Validation loss: 2.6250872082343584

Epoch: 6| Step: 13
Training loss: 2.8179301928448877
Validation loss: 2.6216377508145663

Epoch: 60| Step: 0
Training loss: 2.9630671670480218
Validation loss: 2.630972311318517

Epoch: 6| Step: 1
Training loss: 3.1604786862796943
Validation loss: 2.636196284941288

Epoch: 6| Step: 2
Training loss: 2.646455546429699
Validation loss: 2.636477582286759

Epoch: 6| Step: 3
Training loss: 2.8299172133882906
Validation loss: 2.6441640674253595

Epoch: 6| Step: 4
Training loss: 3.0277775016885644
Validation loss: 2.625508532119254

Epoch: 6| Step: 5
Training loss: 3.0925008390482547
Validation loss: 2.6240655688124197

Epoch: 6| Step: 6
Training loss: 2.1008823811627297
Validation loss: 2.6333065577815433

Epoch: 6| Step: 7
Training loss: 2.824423121738592
Validation loss: 2.632782242719985

Epoch: 6| Step: 8
Training loss: 2.4424089737703243
Validation loss: 2.6504520536064877

Epoch: 6| Step: 9
Training loss: 2.7152238977609056
Validation loss: 2.6445560697419412

Epoch: 6| Step: 10
Training loss: 3.485152358852695
Validation loss: 2.6346198589518672

Epoch: 6| Step: 11
Training loss: 3.580645210900233
Validation loss: 2.6418909168357074

Epoch: 6| Step: 12
Training loss: 3.097819262685468
Validation loss: 2.6450565823510765

Epoch: 6| Step: 13
Training loss: 2.518041741156226
Validation loss: 2.622180213320007

Epoch: 61| Step: 0
Training loss: 2.287035568701301
Validation loss: 2.644679492223519

Epoch: 6| Step: 1
Training loss: 2.8440762846168046
Validation loss: 2.6074185930463165

Epoch: 6| Step: 2
Training loss: 3.4334290413957596
Validation loss: 2.6571074383692195

Epoch: 6| Step: 3
Training loss: 3.2620105361627987
Validation loss: 2.6303203924807743

Epoch: 6| Step: 4
Training loss: 2.6558834047348348
Validation loss: 2.637592696661568

Epoch: 6| Step: 5
Training loss: 3.2276894584853544
Validation loss: 2.635319358556135

Epoch: 6| Step: 6
Training loss: 2.343522938219912
Validation loss: 2.640013562143069

Epoch: 6| Step: 7
Training loss: 2.9467815105215984
Validation loss: 2.6427601410516903

Epoch: 6| Step: 8
Training loss: 2.7107005606673065
Validation loss: 2.6472025341823215

Epoch: 6| Step: 9
Training loss: 3.1444633144835406
Validation loss: 2.6252236971685323

Epoch: 6| Step: 10
Training loss: 3.1834096656422024
Validation loss: 2.6583056289870464

Epoch: 6| Step: 11
Training loss: 2.4639103447592645
Validation loss: 2.6142407101167864

Epoch: 6| Step: 12
Training loss: 3.0090339063291522
Validation loss: 2.6201081280618213

Epoch: 6| Step: 13
Training loss: 3.0176686689995997
Validation loss: 2.6275665063583187

Epoch: 62| Step: 0
Training loss: 2.67774951131982
Validation loss: 2.6193115460502026

Epoch: 6| Step: 1
Training loss: 2.515015901549409
Validation loss: 2.6474063506790664

Epoch: 6| Step: 2
Training loss: 3.026168496674247
Validation loss: 2.6228021570725604

Epoch: 6| Step: 3
Training loss: 3.437890325406901
Validation loss: 2.6069647381166825

Epoch: 6| Step: 4
Training loss: 3.0104524990883976
Validation loss: 2.6466874321895544

Epoch: 6| Step: 5
Training loss: 2.691799893541516
Validation loss: 2.652077990618702

Epoch: 6| Step: 6
Training loss: 3.2075799990613514
Validation loss: 2.6311854797813177

Epoch: 6| Step: 7
Training loss: 2.8187960195908173
Validation loss: 2.6380546541822407

Epoch: 6| Step: 8
Training loss: 2.952254878632298
Validation loss: 2.6253872745397935

Epoch: 6| Step: 9
Training loss: 3.0512204214347847
Validation loss: 2.6236499336284798

Epoch: 6| Step: 10
Training loss: 3.033612304127766
Validation loss: 2.6451478831984137

Epoch: 6| Step: 11
Training loss: 2.6403259469158407
Validation loss: 2.6255364970928516

Epoch: 6| Step: 12
Training loss: 2.6196741845021068
Validation loss: 2.6372647847999016

Epoch: 6| Step: 13
Training loss: 2.9365775100504634
Validation loss: 2.62277329398784

Epoch: 63| Step: 0
Training loss: 2.713621630134161
Validation loss: 2.605393839143871

Epoch: 6| Step: 1
Training loss: 3.5645812798023533
Validation loss: 2.6165923312274684

Epoch: 6| Step: 2
Training loss: 2.7822155080236253
Validation loss: 2.619302913496469

Epoch: 6| Step: 3
Training loss: 2.773227221616953
Validation loss: 2.6193703650867026

Epoch: 6| Step: 4
Training loss: 3.1154605986629473
Validation loss: 2.6116136931078886

Epoch: 6| Step: 5
Training loss: 3.2170697613552415
Validation loss: 2.6543274631500573

Epoch: 6| Step: 6
Training loss: 3.423109972636816
Validation loss: 2.635728493599876

Epoch: 6| Step: 7
Training loss: 2.8128195687044033
Validation loss: 2.62626046849412

Epoch: 6| Step: 8
Training loss: 3.0327721932595755
Validation loss: 2.6306762850854666

Epoch: 6| Step: 9
Training loss: 2.495216752844682
Validation loss: 2.656648253493372

Epoch: 6| Step: 10
Training loss: 2.2461071246205058
Validation loss: 2.64329397907183

Epoch: 6| Step: 11
Training loss: 2.6452549179488574
Validation loss: 2.6305803469398814

Epoch: 6| Step: 12
Training loss: 3.0958771761993895
Validation loss: 2.6160419560826953

Epoch: 6| Step: 13
Training loss: 2.9164132871014083
Validation loss: 2.6300740343666837

Epoch: 64| Step: 0
Training loss: 2.401793477374561
Validation loss: 2.6120981880386807

Epoch: 6| Step: 1
Training loss: 3.0037557616319455
Validation loss: 2.626174799622183

Epoch: 6| Step: 2
Training loss: 2.417695999168831
Validation loss: 2.6542449622295625

Epoch: 6| Step: 3
Training loss: 3.3623686470554017
Validation loss: 2.620637783503213

Epoch: 6| Step: 4
Training loss: 2.425084307276739
Validation loss: 2.610331240693819

Epoch: 6| Step: 5
Training loss: 3.090400192369756
Validation loss: 2.648150471885182

Epoch: 6| Step: 6
Training loss: 2.8670122056640706
Validation loss: 2.6313827993621026

Epoch: 6| Step: 7
Training loss: 3.071175568004349
Validation loss: 2.6214121608985828

Epoch: 6| Step: 8
Training loss: 2.8719182290361296
Validation loss: 2.627346133023868

Epoch: 6| Step: 9
Training loss: 3.305025701148768
Validation loss: 2.6358237561118907

Epoch: 6| Step: 10
Training loss: 2.8321063432932174
Validation loss: 2.62806186738469

Epoch: 6| Step: 11
Training loss: 3.430787485770865
Validation loss: 2.6297044597707124

Epoch: 6| Step: 12
Training loss: 3.0120664165818773
Validation loss: 2.62859692420899

Epoch: 6| Step: 13
Training loss: 2.404019399415511
Validation loss: 2.6351243845638384

Epoch: 65| Step: 0
Training loss: 3.0937389026789606
Validation loss: 2.624682409682083

Epoch: 6| Step: 1
Training loss: 2.555985520538247
Validation loss: 2.638716121631817

Epoch: 6| Step: 2
Training loss: 3.4126549095233965
Validation loss: 2.6214217571299834

Epoch: 6| Step: 3
Training loss: 2.529689543300885
Validation loss: 2.6305469731520135

Epoch: 6| Step: 4
Training loss: 2.401825738898516
Validation loss: 2.625710010948275

Epoch: 6| Step: 5
Training loss: 2.919900645303258
Validation loss: 2.6079715016892453

Epoch: 6| Step: 6
Training loss: 2.8355374645219413
Validation loss: 2.633153852927687

Epoch: 6| Step: 7
Training loss: 2.6607196676139493
Validation loss: 2.633961850705211

Epoch: 6| Step: 8
Training loss: 2.9597526333521125
Validation loss: 2.6412243343450172

Epoch: 6| Step: 9
Training loss: 3.012856116555343
Validation loss: 2.642431643162027

Epoch: 6| Step: 10
Training loss: 2.5809425447994117
Validation loss: 2.6418121954485083

Epoch: 6| Step: 11
Training loss: 2.589717994271955
Validation loss: 2.6109653435994233

Epoch: 6| Step: 12
Training loss: 3.572982624360826
Validation loss: 2.6127304697725635

Epoch: 6| Step: 13
Training loss: 3.809387437332291
Validation loss: 2.6248975920343574

Epoch: 66| Step: 0
Training loss: 2.3741385252724023
Validation loss: 2.627667766380928

Epoch: 6| Step: 1
Training loss: 2.885363434852546
Validation loss: 2.644054987289657

Epoch: 6| Step: 2
Training loss: 2.737133618227426
Validation loss: 2.602594090956041

Epoch: 6| Step: 3
Training loss: 2.740910507171877
Validation loss: 2.6090198363806216

Epoch: 6| Step: 4
Training loss: 3.726977567129788
Validation loss: 2.6225045423961917

Epoch: 6| Step: 5
Training loss: 2.5231356130192033
Validation loss: 2.6243349161542007

Epoch: 6| Step: 6
Training loss: 3.7369974417245144
Validation loss: 2.621040457765147

Epoch: 6| Step: 7
Training loss: 2.624465524666143
Validation loss: 2.620118889993796

Epoch: 6| Step: 8
Training loss: 2.4976215492584766
Validation loss: 2.643902744215419

Epoch: 6| Step: 9
Training loss: 2.333541917560506
Validation loss: 2.643981010665443

Epoch: 6| Step: 10
Training loss: 2.390901636810234
Validation loss: 2.623512674885172

Epoch: 6| Step: 11
Training loss: 3.839616739697293
Validation loss: 2.6218164821539385

Epoch: 6| Step: 12
Training loss: 3.1302967196578324
Validation loss: 2.608791111847992

Epoch: 6| Step: 13
Training loss: 2.5031508617041434
Validation loss: 2.593979817545253

Epoch: 67| Step: 0
Training loss: 3.16317940150198
Validation loss: 2.638410241010659

Epoch: 6| Step: 1
Training loss: 2.4432837507344054
Validation loss: 2.640511618753587

Epoch: 6| Step: 2
Training loss: 2.6852963306424518
Validation loss: 2.631347728833045

Epoch: 6| Step: 3
Training loss: 3.0869756956141554
Validation loss: 2.6339954732121176

Epoch: 6| Step: 4
Training loss: 3.1055442944820855
Validation loss: 2.6357915896059767

Epoch: 6| Step: 5
Training loss: 2.518073744187122
Validation loss: 2.6168102616375535

Epoch: 6| Step: 6
Training loss: 2.8830166049231654
Validation loss: 2.6195098706478235

Epoch: 6| Step: 7
Training loss: 2.9879938523460376
Validation loss: 2.6177029910900877

Epoch: 6| Step: 8
Training loss: 2.767825183596002
Validation loss: 2.637579266052461

Epoch: 6| Step: 9
Training loss: 3.5120877930219163
Validation loss: 2.611315576391871

Epoch: 6| Step: 10
Training loss: 2.1798486137322204
Validation loss: 2.625958883315346

Epoch: 6| Step: 11
Training loss: 3.3674351718385975
Validation loss: 2.6179830675065365

Epoch: 6| Step: 12
Training loss: 2.64245379621376
Validation loss: 2.6308496256107596

Epoch: 6| Step: 13
Training loss: 3.1730350571651464
Validation loss: 2.614444755630929

Epoch: 68| Step: 0
Training loss: 2.2909933546045664
Validation loss: 2.6490484702932733

Epoch: 6| Step: 1
Training loss: 3.137687561994396
Validation loss: 2.6319280447052895

Epoch: 6| Step: 2
Training loss: 3.3820324850840175
Validation loss: 2.6106902657677944

Epoch: 6| Step: 3
Training loss: 2.8707871461501595
Validation loss: 2.613407799457897

Epoch: 6| Step: 4
Training loss: 2.612396409750723
Validation loss: 2.609892875001483

Epoch: 6| Step: 5
Training loss: 2.6470327787426964
Validation loss: 2.6233591409653116

Epoch: 6| Step: 6
Training loss: 3.2507280854652123
Validation loss: 2.641164741612875

Epoch: 6| Step: 7
Training loss: 2.487502043450058
Validation loss: 2.606530654144421

Epoch: 6| Step: 8
Training loss: 2.9322535962377003
Validation loss: 2.6368548711705597

Epoch: 6| Step: 9
Training loss: 3.3936708894223804
Validation loss: 2.601932305099773

Epoch: 6| Step: 10
Training loss: 2.3960016163866706
Validation loss: 2.6136683492451467

Epoch: 6| Step: 11
Training loss: 2.9179229937008224
Validation loss: 2.6150200033068853

Epoch: 6| Step: 12
Training loss: 3.2525665712690817
Validation loss: 2.627181168033731

Epoch: 6| Step: 13
Training loss: 2.7063416322343694
Validation loss: 2.5973357406368462

Epoch: 69| Step: 0
Training loss: 3.0240378560012786
Validation loss: 2.6279656513727847

Epoch: 6| Step: 1
Training loss: 2.998957770823331
Validation loss: 2.65677099649928

Epoch: 6| Step: 2
Training loss: 3.2627920611965044
Validation loss: 2.6212662415321075

Epoch: 6| Step: 3
Training loss: 3.1639271648333054
Validation loss: 2.597509352892714

Epoch: 6| Step: 4
Training loss: 3.260101465623748
Validation loss: 2.6456179606674217

Epoch: 6| Step: 5
Training loss: 2.8598342276594253
Validation loss: 2.6255165935611933

Epoch: 6| Step: 6
Training loss: 2.6496836563444193
Validation loss: 2.657580543937996

Epoch: 6| Step: 7
Training loss: 3.0929525869727184
Validation loss: 2.6277409300679566

Epoch: 6| Step: 8
Training loss: 2.588676177942704
Validation loss: 2.6148236323667877

Epoch: 6| Step: 9
Training loss: 2.5413326502549225
Validation loss: 2.6004835963229773

Epoch: 6| Step: 10
Training loss: 2.5772066272383363
Validation loss: 2.6003534691231502

Epoch: 6| Step: 11
Training loss: 3.461804696791549
Validation loss: 2.635837567202851

Epoch: 6| Step: 12
Training loss: 2.64654509414893
Validation loss: 2.626632900370281

Epoch: 6| Step: 13
Training loss: 1.7727729123471598
Validation loss: 2.615150244756198

Epoch: 70| Step: 0
Training loss: 2.7869548794885746
Validation loss: 2.6210062279411646

Epoch: 6| Step: 1
Training loss: 3.0257516920092398
Validation loss: 2.6264852066586224

Epoch: 6| Step: 2
Training loss: 2.3664737040696697
Validation loss: 2.64134974787586

Epoch: 6| Step: 3
Training loss: 2.898334347105224
Validation loss: 2.6362007612497833

Epoch: 6| Step: 4
Training loss: 3.167292399238338
Validation loss: 2.6383578169435524

Epoch: 6| Step: 5
Training loss: 3.2289075850053193
Validation loss: 2.624086897995483

Epoch: 6| Step: 6
Training loss: 2.4101248913769826
Validation loss: 2.6104888916106734

Epoch: 6| Step: 7
Training loss: 2.7077413841281652
Validation loss: 2.6180621235084907

Epoch: 6| Step: 8
Training loss: 2.6301992787623902
Validation loss: 2.608986503197172

Epoch: 6| Step: 9
Training loss: 3.0615682936307236
Validation loss: 2.6219086528969275

Epoch: 6| Step: 10
Training loss: 3.2014142189669568
Validation loss: 2.624101357035274

Epoch: 6| Step: 11
Training loss: 2.9395014660684478
Validation loss: 2.629839890214092

Epoch: 6| Step: 12
Training loss: 3.0565449952592605
Validation loss: 2.6093598148522323

Epoch: 6| Step: 13
Training loss: 3.0407581453095873
Validation loss: 2.6339262577797466

Epoch: 71| Step: 0
Training loss: 3.0531329714183935
Validation loss: 2.609764151156942

Epoch: 6| Step: 1
Training loss: 2.9316920225757643
Validation loss: 2.627263071720181

Epoch: 6| Step: 2
Training loss: 3.273166399452282
Validation loss: 2.630905082149618

Epoch: 6| Step: 3
Training loss: 2.6940824051327295
Validation loss: 2.6136341189967762

Epoch: 6| Step: 4
Training loss: 2.353364982374152
Validation loss: 2.627653865518399

Epoch: 6| Step: 5
Training loss: 2.498364294910862
Validation loss: 2.6121940963991563

Epoch: 6| Step: 6
Training loss: 3.281852303584289
Validation loss: 2.6525915954557027

Epoch: 6| Step: 7
Training loss: 2.8602705423400803
Validation loss: 2.621475099311717

Epoch: 6| Step: 8
Training loss: 3.330892209418762
Validation loss: 2.6484144570809898

Epoch: 6| Step: 9
Training loss: 3.380573615432794
Validation loss: 2.649670207684168

Epoch: 6| Step: 10
Training loss: 2.6716776992497078
Validation loss: 2.6192373257125516

Epoch: 6| Step: 11
Training loss: 2.997521489235761
Validation loss: 2.6361011166101096

Epoch: 6| Step: 12
Training loss: 2.5068688444348743
Validation loss: 2.634050819722103

Epoch: 6| Step: 13
Training loss: 2.8825402273396716
Validation loss: 2.628486224670417

Epoch: 72| Step: 0
Training loss: 2.7016897635989503
Validation loss: 2.622595749071795

Epoch: 6| Step: 1
Training loss: 3.2501742976474186
Validation loss: 2.6229805412673963

Epoch: 6| Step: 2
Training loss: 3.162969555882255
Validation loss: 2.649936366231431

Epoch: 6| Step: 3
Training loss: 2.8885678781355786
Validation loss: 2.6491533858777534

Epoch: 6| Step: 4
Training loss: 2.145094167069526
Validation loss: 2.6456781812902332

Epoch: 6| Step: 5
Training loss: 2.9219414198562874
Validation loss: 2.631845981305458

Epoch: 6| Step: 6
Training loss: 3.163372199969063
Validation loss: 2.618146599835906

Epoch: 6| Step: 7
Training loss: 3.2618696166456584
Validation loss: 2.628561152330017

Epoch: 6| Step: 8
Training loss: 2.7156519283807645
Validation loss: 2.620611124569816

Epoch: 6| Step: 9
Training loss: 2.517753884962575
Validation loss: 2.6169777837733936

Epoch: 6| Step: 10
Training loss: 2.389596555806843
Validation loss: 2.6038052438944415

Epoch: 6| Step: 11
Training loss: 2.7600303139611304
Validation loss: 2.614605416746918

Epoch: 6| Step: 12
Training loss: 3.5123131644628143
Validation loss: 2.6164184125969583

Epoch: 6| Step: 13
Training loss: 2.6399921810149953
Validation loss: 2.6045229008987487

Epoch: 73| Step: 0
Training loss: 3.306914028124151
Validation loss: 2.6139073413362057

Epoch: 6| Step: 1
Training loss: 2.5120092909149085
Validation loss: 2.616488401771515

Epoch: 6| Step: 2
Training loss: 3.2510899403386087
Validation loss: 2.606420375743552

Epoch: 6| Step: 3
Training loss: 3.2302612090414136
Validation loss: 2.6124108932598533

Epoch: 6| Step: 4
Training loss: 3.463851907167805
Validation loss: 2.647869504514701

Epoch: 6| Step: 5
Training loss: 2.631921090922981
Validation loss: 2.6074111737313626

Epoch: 6| Step: 6
Training loss: 2.485479145485152
Validation loss: 2.660127178321977

Epoch: 6| Step: 7
Training loss: 3.7232798707471138
Validation loss: 2.6134026435428974

Epoch: 6| Step: 8
Training loss: 2.8239136421572484
Validation loss: 2.5937606380366556

Epoch: 6| Step: 9
Training loss: 2.5559918634706036
Validation loss: 2.6194670690623827

Epoch: 6| Step: 10
Training loss: 2.75493318064776
Validation loss: 2.6364272118917897

Epoch: 6| Step: 11
Training loss: 2.141512944187943
Validation loss: 2.598552108787616

Epoch: 6| Step: 12
Training loss: 2.828463539388893
Validation loss: 2.6172946634332983

Epoch: 6| Step: 13
Training loss: 2.487912712172819
Validation loss: 2.6342904831818825

Epoch: 74| Step: 0
Training loss: 2.444374465181531
Validation loss: 2.6120686963171638

Epoch: 6| Step: 1
Training loss: 2.419557311496912
Validation loss: 2.655966452726437

Epoch: 6| Step: 2
Training loss: 2.4816146966920822
Validation loss: 2.6126730918311147

Epoch: 6| Step: 3
Training loss: 2.000755644146233
Validation loss: 2.6234530135400616

Epoch: 6| Step: 4
Training loss: 3.0310684621662487
Validation loss: 2.6334213556251793

Epoch: 6| Step: 5
Training loss: 2.5713765918685407
Validation loss: 2.612680160622925

Epoch: 6| Step: 6
Training loss: 2.9683074621336485
Validation loss: 2.5962123892412423

Epoch: 6| Step: 7
Training loss: 2.7593078017557815
Validation loss: 2.6211027062676617

Epoch: 6| Step: 8
Training loss: 3.2748959007899385
Validation loss: 2.601064954507214

Epoch: 6| Step: 9
Training loss: 3.7072636779660426
Validation loss: 2.6411566672671563

Epoch: 6| Step: 10
Training loss: 3.004132444598597
Validation loss: 2.615815217634509

Epoch: 6| Step: 11
Training loss: 3.109960452990526
Validation loss: 2.6250451406844926

Epoch: 6| Step: 12
Training loss: 3.3390141399274937
Validation loss: 2.6066204384695544

Epoch: 6| Step: 13
Training loss: 2.7492539520915162
Validation loss: 2.6403040770096315

Epoch: 75| Step: 0
Training loss: 2.6521436478158384
Validation loss: 2.6060520407280485

Epoch: 6| Step: 1
Training loss: 3.1646860520796594
Validation loss: 2.625560068873642

Epoch: 6| Step: 2
Training loss: 3.1908614441842262
Validation loss: 2.6133571060521223

Epoch: 6| Step: 3
Training loss: 2.2370258958500266
Validation loss: 2.614131269867035

Epoch: 6| Step: 4
Training loss: 2.6745383390116624
Validation loss: 2.594115142482411

Epoch: 6| Step: 5
Training loss: 2.864109476373305
Validation loss: 2.612572230923209

Epoch: 6| Step: 6
Training loss: 3.294591610133717
Validation loss: 2.6183195890487294

Epoch: 6| Step: 7
Training loss: 3.141850777922144
Validation loss: 2.6009306367741547

Epoch: 6| Step: 8
Training loss: 2.689173421395157
Validation loss: 2.619206259740141

Epoch: 6| Step: 9
Training loss: 2.2691790886953513
Validation loss: 2.612201245981378

Epoch: 6| Step: 10
Training loss: 2.652940550953702
Validation loss: 2.6158364465019375

Epoch: 6| Step: 11
Training loss: 3.1283932383158035
Validation loss: 2.6354414247122184

Epoch: 6| Step: 12
Training loss: 3.0529122816342147
Validation loss: 2.62514612491402

Epoch: 6| Step: 13
Training loss: 3.5907067723669766
Validation loss: 2.620944273522553

Epoch: 76| Step: 0
Training loss: 2.9784949730329116
Validation loss: 2.630169907155881

Epoch: 6| Step: 1
Training loss: 2.7591781044825394
Validation loss: 2.6287188061265216

Epoch: 6| Step: 2
Training loss: 2.5171791157029344
Validation loss: 2.623360779789343

Epoch: 6| Step: 3
Training loss: 2.655521966233187
Validation loss: 2.611982043749764

Epoch: 6| Step: 4
Training loss: 3.108784221710829
Validation loss: 2.6117549871971786

Epoch: 6| Step: 5
Training loss: 3.2793509664612706
Validation loss: 2.604839662938839

Epoch: 6| Step: 6
Training loss: 2.557499076268839
Validation loss: 2.604661150510522

Epoch: 6| Step: 7
Training loss: 3.0513309076405273
Validation loss: 2.639040271987911

Epoch: 6| Step: 8
Training loss: 2.9514969470618846
Validation loss: 2.592561390399765

Epoch: 6| Step: 9
Training loss: 2.887008962122475
Validation loss: 2.6229584055415702

Epoch: 6| Step: 10
Training loss: 3.38677014022609
Validation loss: 2.6014597734920746

Epoch: 6| Step: 11
Training loss: 2.8217125796258986
Validation loss: 2.609129278795915

Epoch: 6| Step: 12
Training loss: 2.5211010204927895
Validation loss: 2.5935083833456702

Epoch: 6| Step: 13
Training loss: 3.004964376736693
Validation loss: 2.619328330511167

Epoch: 77| Step: 0
Training loss: 4.132553121291119
Validation loss: 2.618896031021391

Epoch: 6| Step: 1
Training loss: 2.5984911501926256
Validation loss: 2.586616452014287

Epoch: 6| Step: 2
Training loss: 2.8723832536815617
Validation loss: 2.6004495789723263

Epoch: 6| Step: 3
Training loss: 2.942059164545395
Validation loss: 2.6212122984980364

Epoch: 6| Step: 4
Training loss: 2.5525974508395786
Validation loss: 2.5964929729935364

Epoch: 6| Step: 5
Training loss: 2.953952895277704
Validation loss: 2.600631825781173

Epoch: 6| Step: 6
Training loss: 2.4881788199764587
Validation loss: 2.6067327933616236

Epoch: 6| Step: 7
Training loss: 3.0246529119945498
Validation loss: 2.6153254583135115

Epoch: 6| Step: 8
Training loss: 2.6218245236581383
Validation loss: 2.614473479248994

Epoch: 6| Step: 9
Training loss: 2.811669375364231
Validation loss: 2.636005157079564

Epoch: 6| Step: 10
Training loss: 2.6851953782756555
Validation loss: 2.6139910045407833

Epoch: 6| Step: 11
Training loss: 3.078771842727277
Validation loss: 2.6305294698952895

Epoch: 6| Step: 12
Training loss: 2.7207136407280625
Validation loss: 2.6044735208841177

Epoch: 6| Step: 13
Training loss: 2.3809687250575444
Validation loss: 2.6159516983791264

Epoch: 78| Step: 0
Training loss: 2.6222366138196227
Validation loss: 2.6175787207066143

Epoch: 6| Step: 1
Training loss: 2.8974173259377967
Validation loss: 2.6195629806747136

Epoch: 6| Step: 2
Training loss: 3.4030421839814196
Validation loss: 2.627881912617423

Epoch: 6| Step: 3
Training loss: 2.6617551415376655
Validation loss: 2.6044485386714507

Epoch: 6| Step: 4
Training loss: 3.4551449214501346
Validation loss: 2.6127394321411175

Epoch: 6| Step: 5
Training loss: 2.5726837073331215
Validation loss: 2.6171776007469814

Epoch: 6| Step: 6
Training loss: 3.3511883008798686
Validation loss: 2.609861942880559

Epoch: 6| Step: 7
Training loss: 3.0179641427348827
Validation loss: 2.6049290774423475

Epoch: 6| Step: 8
Training loss: 2.3173095588664387
Validation loss: 2.6106422740935686

Epoch: 6| Step: 9
Training loss: 2.799314404747562
Validation loss: 2.6240380874011673

Epoch: 6| Step: 10
Training loss: 2.9631725722804663
Validation loss: 2.625088518821246

Epoch: 6| Step: 11
Training loss: 2.3579301262517607
Validation loss: 2.611231805868219

Epoch: 6| Step: 12
Training loss: 2.8050429775053103
Validation loss: 2.624493632623197

Epoch: 6| Step: 13
Training loss: 2.9455397945701707
Validation loss: 2.6193904650643263

Epoch: 79| Step: 0
Training loss: 1.9644839372568028
Validation loss: 2.591901283168186

Epoch: 6| Step: 1
Training loss: 2.8003475007631673
Validation loss: 2.6054360847548974

Epoch: 6| Step: 2
Training loss: 2.369316729787777
Validation loss: 2.620488250200118

Epoch: 6| Step: 3
Training loss: 3.223423204191518
Validation loss: 2.5854608572165434

Epoch: 6| Step: 4
Training loss: 2.517212929292332
Validation loss: 2.6443046053069112

Epoch: 6| Step: 5
Training loss: 2.880065270584955
Validation loss: 2.628778801439892

Epoch: 6| Step: 6
Training loss: 3.3640317356458778
Validation loss: 2.596674121229557

Epoch: 6| Step: 7
Training loss: 3.0072250783428176
Validation loss: 2.6373896012098768

Epoch: 6| Step: 8
Training loss: 2.822948882610053
Validation loss: 2.5967227363443404

Epoch: 6| Step: 9
Training loss: 2.483623462942052
Validation loss: 2.589475541041938

Epoch: 6| Step: 10
Training loss: 3.3209484972223846
Validation loss: 2.6215683391710694

Epoch: 6| Step: 11
Training loss: 2.9374353929273185
Validation loss: 2.631385408418535

Epoch: 6| Step: 12
Training loss: 3.4167608077562925
Validation loss: 2.6128436657421874

Epoch: 6| Step: 13
Training loss: 3.3361560472999514
Validation loss: 2.6006377217011987

Epoch: 80| Step: 0
Training loss: 2.648509516904331
Validation loss: 2.6145702506032498

Epoch: 6| Step: 1
Training loss: 2.134509630551017
Validation loss: 2.6002021240064113

Epoch: 6| Step: 2
Training loss: 2.1448696404528023
Validation loss: 2.6141170518499686

Epoch: 6| Step: 3
Training loss: 3.1113943319226998
Validation loss: 2.613573809383448

Epoch: 6| Step: 4
Training loss: 2.9681347661230215
Validation loss: 2.5766614153552894

Epoch: 6| Step: 5
Training loss: 2.8370367604705495
Validation loss: 2.599942720380175

Epoch: 6| Step: 6
Training loss: 3.9754769093146725
Validation loss: 2.6208958768497346

Epoch: 6| Step: 7
Training loss: 2.7407911609139686
Validation loss: 2.5974659815129346

Epoch: 6| Step: 8
Training loss: 3.5233289613098138
Validation loss: 2.6248501101513386

Epoch: 6| Step: 9
Training loss: 2.108514228669667
Validation loss: 2.595308946537906

Epoch: 6| Step: 10
Training loss: 3.0805820011815004
Validation loss: 2.6190007424857282

Epoch: 6| Step: 11
Training loss: 2.984417500617694
Validation loss: 2.5822379627846677

Epoch: 6| Step: 12
Training loss: 2.1591683141166422
Validation loss: 2.601209507234623

Epoch: 6| Step: 13
Training loss: 3.4093124202086362
Validation loss: 2.5852784016794934

Epoch: 81| Step: 0
Training loss: 2.817488336818218
Validation loss: 2.6062986963329755

Epoch: 6| Step: 1
Training loss: 3.619535734427869
Validation loss: 2.6296478051089256

Epoch: 6| Step: 2
Training loss: 2.5662852916344048
Validation loss: 2.6115496379628413

Epoch: 6| Step: 3
Training loss: 2.257316878148215
Validation loss: 2.6097243381401953

Epoch: 6| Step: 4
Training loss: 2.6465864436325113
Validation loss: 2.6062003194022694

Epoch: 6| Step: 5
Training loss: 2.6123146356411047
Validation loss: 2.586626479129833

Epoch: 6| Step: 6
Training loss: 3.117989420218928
Validation loss: 2.618677733304251

Epoch: 6| Step: 7
Training loss: 3.1181504523759505
Validation loss: 2.6140218171895784

Epoch: 6| Step: 8
Training loss: 2.572643764916182
Validation loss: 2.6231543874028387

Epoch: 6| Step: 9
Training loss: 3.7668332262825848
Validation loss: 2.632171549919534

Epoch: 6| Step: 10
Training loss: 2.5965742797804725
Validation loss: 2.599561546602336

Epoch: 6| Step: 11
Training loss: 2.4638608009355396
Validation loss: 2.616483481201117

Epoch: 6| Step: 12
Training loss: 2.6323823209508883
Validation loss: 2.5989358818683583

Epoch: 6| Step: 13
Training loss: 3.450201808168595
Validation loss: 2.6125702840813743

Epoch: 82| Step: 0
Training loss: 2.510917096627783
Validation loss: 2.631785106158544

Epoch: 6| Step: 1
Training loss: 2.5618973930591906
Validation loss: 2.610396077034495

Epoch: 6| Step: 2
Training loss: 2.510499649470247
Validation loss: 2.633813765439008

Epoch: 6| Step: 3
Training loss: 2.7424075481233023
Validation loss: 2.6187954748846876

Epoch: 6| Step: 4
Training loss: 2.8286923002864253
Validation loss: 2.6271652690451988

Epoch: 6| Step: 5
Training loss: 3.204351422985966
Validation loss: 2.595365605017166

Epoch: 6| Step: 6
Training loss: 2.9184499647652653
Validation loss: 2.6086214011514337

Epoch: 6| Step: 7
Training loss: 3.2877969005813994
Validation loss: 2.6012495737665353

Epoch: 6| Step: 8
Training loss: 2.7603360914070616
Validation loss: 2.5973478928854647

Epoch: 6| Step: 9
Training loss: 2.552708597206304
Validation loss: 2.601777467151871

Epoch: 6| Step: 10
Training loss: 3.075435489737687
Validation loss: 2.620426066345839

Epoch: 6| Step: 11
Training loss: 2.652699240231496
Validation loss: 2.612683165148022

Epoch: 6| Step: 12
Training loss: 3.104142430016715
Validation loss: 2.614098530457237

Epoch: 6| Step: 13
Training loss: 3.896405319138493
Validation loss: 2.604815260974853

Epoch: 83| Step: 0
Training loss: 3.098988577216959
Validation loss: 2.605210012971914

Epoch: 6| Step: 1
Training loss: 2.4033746755838536
Validation loss: 2.615193269917806

Epoch: 6| Step: 2
Training loss: 2.9083847901201696
Validation loss: 2.6010433419191434

Epoch: 6| Step: 3
Training loss: 1.956084184048071
Validation loss: 2.633094188048934

Epoch: 6| Step: 4
Training loss: 2.204990327774944
Validation loss: 2.615979953674386

Epoch: 6| Step: 5
Training loss: 3.589239192029433
Validation loss: 2.635971800429023

Epoch: 6| Step: 6
Training loss: 3.0937231814060135
Validation loss: 2.60388238319101

Epoch: 6| Step: 7
Training loss: 2.6138453765645533
Validation loss: 2.5747126206164452

Epoch: 6| Step: 8
Training loss: 2.917710544340655
Validation loss: 2.602039924391586

Epoch: 6| Step: 9
Training loss: 2.6404216620352
Validation loss: 2.6084000267532312

Epoch: 6| Step: 10
Training loss: 2.815506409106838
Validation loss: 2.6258111092222607

Epoch: 6| Step: 11
Training loss: 3.3243415352617434
Validation loss: 2.6097789036954913

Epoch: 6| Step: 12
Training loss: 2.917552341230292
Validation loss: 2.6376388479431814

Epoch: 6| Step: 13
Training loss: 3.595309773178426
Validation loss: 2.612149605635318

Epoch: 84| Step: 0
Training loss: 2.953600648388528
Validation loss: 2.607070077770848

Epoch: 6| Step: 1
Training loss: 3.4945254425812466
Validation loss: 2.591512068187895

Epoch: 6| Step: 2
Training loss: 2.958421911785045
Validation loss: 2.6156860266425275

Epoch: 6| Step: 3
Training loss: 2.94076502727057
Validation loss: 2.6178150730425735

Epoch: 6| Step: 4
Training loss: 3.739986783988572
Validation loss: 2.6238446591291384

Epoch: 6| Step: 5
Training loss: 2.3686172649465203
Validation loss: 2.595179645515456

Epoch: 6| Step: 6
Training loss: 3.183024237307672
Validation loss: 2.6145587853478527

Epoch: 6| Step: 7
Training loss: 2.636981594971884
Validation loss: 2.622374032226047

Epoch: 6| Step: 8
Training loss: 2.879992586762106
Validation loss: 2.6268631826668796

Epoch: 6| Step: 9
Training loss: 2.7196225925481716
Validation loss: 2.618249421662991

Epoch: 6| Step: 10
Training loss: 2.746269730508775
Validation loss: 2.6246376041366326

Epoch: 6| Step: 11
Training loss: 2.6908227650692895
Validation loss: 2.605889681564026

Epoch: 6| Step: 12
Training loss: 2.062591088335413
Validation loss: 2.6173149821064925

Epoch: 6| Step: 13
Training loss: 2.846319190831589
Validation loss: 2.637914781410978

Epoch: 85| Step: 0
Training loss: 2.7763888277383857
Validation loss: 2.604738194579664

Epoch: 6| Step: 1
Training loss: 3.294619109348392
Validation loss: 2.5789948558110893

Epoch: 6| Step: 2
Training loss: 3.2580779994294504
Validation loss: 2.597318612699963

Epoch: 6| Step: 3
Training loss: 3.1466865308856593
Validation loss: 2.63264800023651

Epoch: 6| Step: 4
Training loss: 2.440164430268343
Validation loss: 2.5917238648246985

Epoch: 6| Step: 5
Training loss: 3.142426993918773
Validation loss: 2.6245850402556523

Epoch: 6| Step: 6
Training loss: 2.565688963451676
Validation loss: 2.593490839678497

Epoch: 6| Step: 7
Training loss: 2.564008129410495
Validation loss: 2.5995388998217397

Epoch: 6| Step: 8
Training loss: 2.87861124543269
Validation loss: 2.590391532560413

Epoch: 6| Step: 9
Training loss: 2.592443113962831
Validation loss: 2.5973631946491635

Epoch: 6| Step: 10
Training loss: 2.9918553738242193
Validation loss: 2.610651825952546

Epoch: 6| Step: 11
Training loss: 3.236160154248444
Validation loss: 2.619717034569152

Epoch: 6| Step: 12
Training loss: 2.556265620624597
Validation loss: 2.6176044237939684

Epoch: 6| Step: 13
Training loss: 2.6510015358476138
Validation loss: 2.595315355362539

Epoch: 86| Step: 0
Training loss: 3.0398814218383405
Validation loss: 2.6151250714244325

Epoch: 6| Step: 1
Training loss: 2.722426811194301
Validation loss: 2.6064460285442297

Epoch: 6| Step: 2
Training loss: 3.226202032537413
Validation loss: 2.629373923234735

Epoch: 6| Step: 3
Training loss: 2.9443469501245128
Validation loss: 2.6337401932349245

Epoch: 6| Step: 4
Training loss: 3.360415275433121
Validation loss: 2.60172338707902

Epoch: 6| Step: 5
Training loss: 2.8389211045254017
Validation loss: 2.6276193247567172

Epoch: 6| Step: 6
Training loss: 2.323613140801775
Validation loss: 2.640592356067014

Epoch: 6| Step: 7
Training loss: 3.32756990630148
Validation loss: 2.615598128585756

Epoch: 6| Step: 8
Training loss: 3.170021154290984
Validation loss: 2.6231332011446487

Epoch: 6| Step: 9
Training loss: 2.5245664923152833
Validation loss: 2.632543809691354

Epoch: 6| Step: 10
Training loss: 2.8940516600937696
Validation loss: 2.6386835541542633

Epoch: 6| Step: 11
Training loss: 2.1198712333224203
Validation loss: 2.609109629375361

Epoch: 6| Step: 12
Training loss: 2.9814557082503823
Validation loss: 2.618586578622969

Epoch: 6| Step: 13
Training loss: 2.670585633533888
Validation loss: 2.6129671566514117

Epoch: 87| Step: 0
Training loss: 3.516678444600081
Validation loss: 2.602157359706255

Epoch: 6| Step: 1
Training loss: 2.063889699975401
Validation loss: 2.6088835108644526

Epoch: 6| Step: 2
Training loss: 2.6877702089248414
Validation loss: 2.621278331739484

Epoch: 6| Step: 3
Training loss: 2.5142773163642835
Validation loss: 2.5988493576414653

Epoch: 6| Step: 4
Training loss: 2.406434683710092
Validation loss: 2.614634140561

Epoch: 6| Step: 5
Training loss: 3.155446167364723
Validation loss: 2.6280071361315813

Epoch: 6| Step: 6
Training loss: 3.523609233316568
Validation loss: 2.6056245748411286

Epoch: 6| Step: 7
Training loss: 2.327221483884267
Validation loss: 2.5959662951223876

Epoch: 6| Step: 8
Training loss: 2.755159566311876
Validation loss: 2.5975100003391014

Epoch: 6| Step: 9
Training loss: 2.5718564669009685
Validation loss: 2.6127758337203293

Epoch: 6| Step: 10
Training loss: 3.5199661240248075
Validation loss: 2.6022543013991726

Epoch: 6| Step: 11
Training loss: 2.900825113447233
Validation loss: 2.5986084449863287

Epoch: 6| Step: 12
Training loss: 2.4511646772180176
Validation loss: 2.588999974420772

Epoch: 6| Step: 13
Training loss: 3.4488916468800443
Validation loss: 2.589499101504792

Epoch: 88| Step: 0
Training loss: 2.860305051207286
Validation loss: 2.6140019701507544

Epoch: 6| Step: 1
Training loss: 2.978980656576726
Validation loss: 2.611230751442261

Epoch: 6| Step: 2
Training loss: 1.9467044124906574
Validation loss: 2.635415276909619

Epoch: 6| Step: 3
Training loss: 2.7128387731838304
Validation loss: 2.602829678476703

Epoch: 6| Step: 4
Training loss: 2.484301775926848
Validation loss: 2.616519428978288

Epoch: 6| Step: 5
Training loss: 3.1696676456702506
Validation loss: 2.584803374021443

Epoch: 6| Step: 6
Training loss: 3.126187671038516
Validation loss: 2.6011143805044012

Epoch: 6| Step: 7
Training loss: 3.041115662994094
Validation loss: 2.6362166558275653

Epoch: 6| Step: 8
Training loss: 2.986636278758543
Validation loss: 2.600725691656678

Epoch: 6| Step: 9
Training loss: 2.700401565924693
Validation loss: 2.6215934525884217

Epoch: 6| Step: 10
Training loss: 2.6139458921592524
Validation loss: 2.6334207209018787

Epoch: 6| Step: 11
Training loss: 3.2743346958115493
Validation loss: 2.603675045410491

Epoch: 6| Step: 12
Training loss: 2.7750679488927257
Validation loss: 2.6075437015802447

Epoch: 6| Step: 13
Training loss: 3.4280234364406166
Validation loss: 2.5941910253248923

Epoch: 89| Step: 0
Training loss: 2.6551714334259753
Validation loss: 2.6022090958879716

Epoch: 6| Step: 1
Training loss: 3.014441065055408
Validation loss: 2.634009684176534

Epoch: 6| Step: 2
Training loss: 3.179039141562498
Validation loss: 2.6262982581601046

Epoch: 6| Step: 3
Training loss: 2.5301820362326914
Validation loss: 2.6125336274478594

Epoch: 6| Step: 4
Training loss: 3.6066844870173496
Validation loss: 2.6105729118387835

Epoch: 6| Step: 5
Training loss: 2.8231719254703846
Validation loss: 2.5931844597597054

Epoch: 6| Step: 6
Training loss: 2.367078319083836
Validation loss: 2.6212660273465684

Epoch: 6| Step: 7
Training loss: 2.685979102291296
Validation loss: 2.608199677877301

Epoch: 6| Step: 8
Training loss: 2.119671817425147
Validation loss: 2.6146232060368515

Epoch: 6| Step: 9
Training loss: 2.725722656319976
Validation loss: 2.577635020520845

Epoch: 6| Step: 10
Training loss: 2.6694723112160426
Validation loss: 2.590997304919468

Epoch: 6| Step: 11
Training loss: 3.720405274331472
Validation loss: 2.578505313052185

Epoch: 6| Step: 12
Training loss: 3.1300243423051604
Validation loss: 2.6320784548351437

Epoch: 6| Step: 13
Training loss: 2.2052010568658797
Validation loss: 2.596315516901916

Epoch: 90| Step: 0
Training loss: 2.8065069136229432
Validation loss: 2.581304065420494

Epoch: 6| Step: 1
Training loss: 2.6005965722182105
Validation loss: 2.611511214723693

Epoch: 6| Step: 2
Training loss: 2.6909003813530004
Validation loss: 2.601938196102386

Epoch: 6| Step: 3
Training loss: 3.2396659881416294
Validation loss: 2.5910496161711656

Epoch: 6| Step: 4
Training loss: 2.8368355666313287
Validation loss: 2.6251478256112413

Epoch: 6| Step: 5
Training loss: 3.0443112273047657
Validation loss: 2.593505219207574

Epoch: 6| Step: 6
Training loss: 3.0633005146957033
Validation loss: 2.5797775525828

Epoch: 6| Step: 7
Training loss: 3.563563138036077
Validation loss: 2.5916454357708227

Epoch: 6| Step: 8
Training loss: 2.7463608851942336
Validation loss: 2.6117403086419615

Epoch: 6| Step: 9
Training loss: 3.1586647993763655
Validation loss: 2.586736171273002

Epoch: 6| Step: 10
Training loss: 2.436281731185056
Validation loss: 2.6042417174978993

Epoch: 6| Step: 11
Training loss: 2.614317000199662
Validation loss: 2.599754743312263

Epoch: 6| Step: 12
Training loss: 1.765285493060337
Validation loss: 2.598408957218626

Epoch: 6| Step: 13
Training loss: 3.318179318200259
Validation loss: 2.6191082555583223

Epoch: 91| Step: 0
Training loss: 2.138220780409246
Validation loss: 2.613593006402654

Epoch: 6| Step: 1
Training loss: 2.8940432570888377
Validation loss: 2.601691644418121

Epoch: 6| Step: 2
Training loss: 3.2379705374345122
Validation loss: 2.615834746121184

Epoch: 6| Step: 3
Training loss: 2.9084302046272295
Validation loss: 2.6066348183484918

Epoch: 6| Step: 4
Training loss: 3.504284552285769
Validation loss: 2.616354317327706

Epoch: 6| Step: 5
Training loss: 2.683998132969396
Validation loss: 2.6048527102289554

Epoch: 6| Step: 6
Training loss: 3.077843357891654
Validation loss: 2.6226851554663626

Epoch: 6| Step: 7
Training loss: 2.6019176893651816
Validation loss: 2.604075446387262

Epoch: 6| Step: 8
Training loss: 3.1074215680978794
Validation loss: 2.589307338572373

Epoch: 6| Step: 9
Training loss: 2.8918467646057833
Validation loss: 2.6054868506083126

Epoch: 6| Step: 10
Training loss: 3.0563696402943137
Validation loss: 2.611043317027144

Epoch: 6| Step: 11
Training loss: 2.514316005028909
Validation loss: 2.597055862920683

Epoch: 6| Step: 12
Training loss: 2.5216186393136035
Validation loss: 2.5988488219978723

Epoch: 6| Step: 13
Training loss: 2.6707997082415162
Validation loss: 2.588499467539227

Epoch: 92| Step: 0
Training loss: 2.678648989326526
Validation loss: 2.5896620972472433

Epoch: 6| Step: 1
Training loss: 3.1628765379610955
Validation loss: 2.6067046925532504

Epoch: 6| Step: 2
Training loss: 3.956235845218063
Validation loss: 2.593237177687435

Epoch: 6| Step: 3
Training loss: 2.3689922842960462
Validation loss: 2.596760606376705

Epoch: 6| Step: 4
Training loss: 2.7157521875445174
Validation loss: 2.6118654516233364

Epoch: 6| Step: 5
Training loss: 2.4082358946662867
Validation loss: 2.5801704722270045

Epoch: 6| Step: 6
Training loss: 2.468406073841911
Validation loss: 2.609381377224826

Epoch: 6| Step: 7
Training loss: 3.0719825143713817
Validation loss: 2.630734536236799

Epoch: 6| Step: 8
Training loss: 2.706240055339064
Validation loss: 2.598558728630526

Epoch: 6| Step: 9
Training loss: 3.2527379460714303
Validation loss: 2.6257621520090098

Epoch: 6| Step: 10
Training loss: 3.3260342473728777
Validation loss: 2.622576863311215

Epoch: 6| Step: 11
Training loss: 2.644852273633997
Validation loss: 2.5953524804002774

Epoch: 6| Step: 12
Training loss: 2.069474536526198
Validation loss: 2.576491257941094

Epoch: 6| Step: 13
Training loss: 2.4216105655158646
Validation loss: 2.6077137104927517

Epoch: 93| Step: 0
Training loss: 2.3682413808254434
Validation loss: 2.583602502900213

Epoch: 6| Step: 1
Training loss: 3.096307641340999
Validation loss: 2.6052497773844334

Epoch: 6| Step: 2
Training loss: 2.5663571984467657
Validation loss: 2.5817029480957414

Epoch: 6| Step: 3
Training loss: 2.864505688164088
Validation loss: 2.6113575431110427

Epoch: 6| Step: 4
Training loss: 2.962622814610458
Validation loss: 2.6160853007428626

Epoch: 6| Step: 5
Training loss: 2.7709586227505025
Validation loss: 2.6224497718997877

Epoch: 6| Step: 6
Training loss: 3.3481345263472546
Validation loss: 2.603092465913054

Epoch: 6| Step: 7
Training loss: 2.25954500141817
Validation loss: 2.6182465821467042

Epoch: 6| Step: 8
Training loss: 2.8133525827692423
Validation loss: 2.585280061668237

Epoch: 6| Step: 9
Training loss: 2.8631510165002005
Validation loss: 2.5893683529811575

Epoch: 6| Step: 10
Training loss: 3.2246608348786077
Validation loss: 2.6366990067180733

Epoch: 6| Step: 11
Training loss: 3.2288030276077335
Validation loss: 2.6085341510276745

Epoch: 6| Step: 12
Training loss: 3.0081712384992776
Validation loss: 2.6194997002699596

Epoch: 6| Step: 13
Training loss: 2.1440793865936087
Validation loss: 2.592513885369886

Epoch: 94| Step: 0
Training loss: 2.197077682934455
Validation loss: 2.5962055007521214

Epoch: 6| Step: 1
Training loss: 3.281399968671075
Validation loss: 2.62505163951578

Epoch: 6| Step: 2
Training loss: 2.920723101557921
Validation loss: 2.615449564245463

Epoch: 6| Step: 3
Training loss: 3.0975915967007612
Validation loss: 2.583968412619584

Epoch: 6| Step: 4
Training loss: 2.0326247038362757
Validation loss: 2.6008808277977566

Epoch: 6| Step: 5
Training loss: 2.9592710450553574
Validation loss: 2.6117015534831056

Epoch: 6| Step: 6
Training loss: 3.0094181679613357
Validation loss: 2.594170299229817

Epoch: 6| Step: 7
Training loss: 2.7352941221711307
Validation loss: 2.613253516855958

Epoch: 6| Step: 8
Training loss: 2.752859189801046
Validation loss: 2.6257408178835804

Epoch: 6| Step: 9
Training loss: 2.9115114883911573
Validation loss: 2.589771612308452

Epoch: 6| Step: 10
Training loss: 3.000346163805292
Validation loss: 2.620999469170642

Epoch: 6| Step: 11
Training loss: 3.3314843930917
Validation loss: 2.589159640048428

Epoch: 6| Step: 12
Training loss: 2.998357005030298
Validation loss: 2.6161465000517095

Epoch: 6| Step: 13
Training loss: 2.738939497297218
Validation loss: 2.6224999522858816

Epoch: 95| Step: 0
Training loss: 1.8380495300675903
Validation loss: 2.6271062878655576

Epoch: 6| Step: 1
Training loss: 2.8361564110369883
Validation loss: 2.6128458360866302

Epoch: 6| Step: 2
Training loss: 2.882297542241133
Validation loss: 2.60468797810494

Epoch: 6| Step: 3
Training loss: 2.2578526265627628
Validation loss: 2.6006804398597456

Epoch: 6| Step: 4
Training loss: 2.990360509004879
Validation loss: 2.5939468662922236

Epoch: 6| Step: 5
Training loss: 2.6077614552397392
Validation loss: 2.6142289502021274

Epoch: 6| Step: 6
Training loss: 2.761188116178839
Validation loss: 2.6211144705530867

Epoch: 6| Step: 7
Training loss: 3.5765217350027756
Validation loss: 2.623333003684699

Epoch: 6| Step: 8
Training loss: 2.906365176964195
Validation loss: 2.5820070177189414

Epoch: 6| Step: 9
Training loss: 3.418203674962244
Validation loss: 2.6071342311751993

Epoch: 6| Step: 10
Training loss: 2.9550861930863093
Validation loss: 2.588300556600536

Epoch: 6| Step: 11
Training loss: 2.7717362464831243
Validation loss: 2.6262883229657064

Epoch: 6| Step: 12
Training loss: 2.949139847868384
Validation loss: 2.605211409821645

Epoch: 6| Step: 13
Training loss: 2.92785554702551
Validation loss: 2.605473442434396

Epoch: 96| Step: 0
Training loss: 3.2896061173935056
Validation loss: 2.6268376472740584

Epoch: 6| Step: 1
Training loss: 1.9779883507751004
Validation loss: 2.583737682754091

Epoch: 6| Step: 2
Training loss: 2.595147365435658
Validation loss: 2.6005254800553224

Epoch: 6| Step: 3
Training loss: 2.754868446158482
Validation loss: 2.5823067121368535

Epoch: 6| Step: 4
Training loss: 2.5645450712108238
Validation loss: 2.5942863663917213

Epoch: 6| Step: 5
Training loss: 3.3513789626865664
Validation loss: 2.6063609300311774

Epoch: 6| Step: 6
Training loss: 3.7786662203946206
Validation loss: 2.6078812182937865

Epoch: 6| Step: 7
Training loss: 3.1331709278574933
Validation loss: 2.595887536008217

Epoch: 6| Step: 8
Training loss: 3.3021158082410067
Validation loss: 2.600825150971005

Epoch: 6| Step: 9
Training loss: 2.355309628098579
Validation loss: 2.6227858171004867

Epoch: 6| Step: 10
Training loss: 3.225772049628137
Validation loss: 2.617342388165727

Epoch: 6| Step: 11
Training loss: 2.509060082918467
Validation loss: 2.626865296535397

Epoch: 6| Step: 12
Training loss: 2.5674468881672254
Validation loss: 2.617980837770109

Epoch: 6| Step: 13
Training loss: 2.0613662609210954
Validation loss: 2.6036387036739352

Epoch: 97| Step: 0
Training loss: 2.731658021666102
Validation loss: 2.593775932299995

Epoch: 6| Step: 1
Training loss: 2.444199573890568
Validation loss: 2.6072163703227984

Epoch: 6| Step: 2
Training loss: 2.40433515182011
Validation loss: 2.5950099110430367

Epoch: 6| Step: 3
Training loss: 3.24557369762404
Validation loss: 2.6127287173286113

Epoch: 6| Step: 4
Training loss: 2.6494674255418897
Validation loss: 2.6030636058773013

Epoch: 6| Step: 5
Training loss: 2.3076643000639305
Validation loss: 2.6283591615001636

Epoch: 6| Step: 6
Training loss: 2.8327198112292478
Validation loss: 2.6066157894075306

Epoch: 6| Step: 7
Training loss: 2.6349375494083778
Validation loss: 2.585877519965335

Epoch: 6| Step: 8
Training loss: 2.8263593188422704
Validation loss: 2.6078900410252905

Epoch: 6| Step: 9
Training loss: 2.88697642413913
Validation loss: 2.6082014009281043

Epoch: 6| Step: 10
Training loss: 3.027617805135683
Validation loss: 2.5804641706951412

Epoch: 6| Step: 11
Training loss: 2.649749520897878
Validation loss: 2.607173038493636

Epoch: 6| Step: 12
Training loss: 3.6340629148437933
Validation loss: 2.5968901031225933

Epoch: 6| Step: 13
Training loss: 3.3133418614861734
Validation loss: 2.593906539698288

Epoch: 98| Step: 0
Training loss: 3.2296451501233587
Validation loss: 2.6320304284757894

Epoch: 6| Step: 1
Training loss: 3.3643594358290776
Validation loss: 2.6041262131697076

Epoch: 6| Step: 2
Training loss: 2.6572655924125055
Validation loss: 2.609212972390095

Epoch: 6| Step: 3
Training loss: 2.3945519600450247
Validation loss: 2.6355665463334015

Epoch: 6| Step: 4
Training loss: 2.774437350719534
Validation loss: 2.5956912731986277

Epoch: 6| Step: 5
Training loss: 3.361717081922808
Validation loss: 2.6058613793313365

Epoch: 6| Step: 6
Training loss: 2.680724807912602
Validation loss: 2.5776745066700175

Epoch: 6| Step: 7
Training loss: 2.9352861543713984
Validation loss: 2.6261755122394126

Epoch: 6| Step: 8
Training loss: 2.363929243548939
Validation loss: 2.5879014188758465

Epoch: 6| Step: 9
Training loss: 2.5821651360546167
Validation loss: 2.6149061956639126

Epoch: 6| Step: 10
Training loss: 3.1847363627266296
Validation loss: 2.5662915132086686

Epoch: 6| Step: 11
Training loss: 3.071624397929468
Validation loss: 2.5903311331009395

Epoch: 6| Step: 12
Training loss: 2.470905377097302
Validation loss: 2.5661233116160336

Epoch: 6| Step: 13
Training loss: 2.7489489367402626
Validation loss: 2.6026866587555304

Epoch: 99| Step: 0
Training loss: 3.179331166689068
Validation loss: 2.604396056542155

Epoch: 6| Step: 1
Training loss: 3.0609731176542456
Validation loss: 2.5842805446415724

Epoch: 6| Step: 2
Training loss: 2.9161104671029965
Validation loss: 2.600243316210803

Epoch: 6| Step: 3
Training loss: 2.382241903056903
Validation loss: 2.573240030577372

Epoch: 6| Step: 4
Training loss: 2.5945028108797343
Validation loss: 2.5706702499954845

Epoch: 6| Step: 5
Training loss: 2.068338972212579
Validation loss: 2.596205965844207

Epoch: 6| Step: 6
Training loss: 3.441162377851732
Validation loss: 2.594634663195859

Epoch: 6| Step: 7
Training loss: 3.0123747866871993
Validation loss: 2.641711941472734

Epoch: 6| Step: 8
Training loss: 2.338986043757129
Validation loss: 2.613277979328989

Epoch: 6| Step: 9
Training loss: 3.5720194736475315
Validation loss: 2.6120680092951556

Epoch: 6| Step: 10
Training loss: 3.2437112559685652
Validation loss: 2.586378775100685

Epoch: 6| Step: 11
Training loss: 1.9336109507402548
Validation loss: 2.642234444293518

Epoch: 6| Step: 12
Training loss: 2.8413293617801965
Validation loss: 2.6010144187360837

Epoch: 6| Step: 13
Training loss: 2.787926450533659
Validation loss: 2.6004905503744813

Epoch: 100| Step: 0
Training loss: 2.7624471046596497
Validation loss: 2.6128731928686553

Epoch: 6| Step: 1
Training loss: 3.22958771616537
Validation loss: 2.647364248017403

Epoch: 6| Step: 2
Training loss: 2.6349974488566317
Validation loss: 2.619261912392758

Epoch: 6| Step: 3
Training loss: 2.8170221213547735
Validation loss: 2.604537027582222

Epoch: 6| Step: 4
Training loss: 2.6113798012253135
Validation loss: 2.599250702209245

Epoch: 6| Step: 5
Training loss: 3.6952242366903567
Validation loss: 2.602865894603768

Epoch: 6| Step: 6
Training loss: 2.6082792436965305
Validation loss: 2.6117042253910925

Epoch: 6| Step: 7
Training loss: 2.708897067356603
Validation loss: 2.585978548161395

Epoch: 6| Step: 8
Training loss: 2.692858123056364
Validation loss: 2.617841802069771

Epoch: 6| Step: 9
Training loss: 3.036906519551778
Validation loss: 2.6339780785213556

Epoch: 6| Step: 10
Training loss: 2.651648631183407
Validation loss: 2.582274312834089

Epoch: 6| Step: 11
Training loss: 2.947533536530943
Validation loss: 2.5980305621208233

Epoch: 6| Step: 12
Training loss: 2.4142205146505105
Validation loss: 2.569074272452913

Epoch: 6| Step: 13
Training loss: 3.027417306314051
Validation loss: 2.61343412281554

Epoch: 101| Step: 0
Training loss: 2.520716567264493
Validation loss: 2.5753065377797455

Epoch: 6| Step: 1
Training loss: 3.218793257635599
Validation loss: 2.615239698850991

Epoch: 6| Step: 2
Training loss: 2.26746877427981
Validation loss: 2.6270682092591873

Epoch: 6| Step: 3
Training loss: 3.129866053972295
Validation loss: 2.615425546510319

Epoch: 6| Step: 4
Training loss: 2.7933554214963805
Validation loss: 2.5972441695620767

Epoch: 6| Step: 5
Training loss: 2.4937463746008657
Validation loss: 2.572702548801856

Epoch: 6| Step: 6
Training loss: 3.150002973040434
Validation loss: 2.6092119436767236

Epoch: 6| Step: 7
Training loss: 2.286986363178891
Validation loss: 2.6174913749423827

Epoch: 6| Step: 8
Training loss: 1.8751122123201358
Validation loss: 2.628900050812511

Epoch: 6| Step: 9
Training loss: 3.4548642020581775
Validation loss: 2.605719840928207

Epoch: 6| Step: 10
Training loss: 2.8527831091042186
Validation loss: 2.6345495107103356

Epoch: 6| Step: 11
Training loss: 2.95942524562183
Validation loss: 2.563610922578148

Epoch: 6| Step: 12
Training loss: 3.04568160723289
Validation loss: 2.610216383962566

Epoch: 6| Step: 13
Training loss: 3.7361833990037496
Validation loss: 2.607609302309994

Epoch: 102| Step: 0
Training loss: 2.8891233100495013
Validation loss: 2.592888062358904

Epoch: 6| Step: 1
Training loss: 3.2337554485686546
Validation loss: 2.6067124030211506

Epoch: 6| Step: 2
Training loss: 3.4482889272179222
Validation loss: 2.6125580907738604

Epoch: 6| Step: 3
Training loss: 2.974445862011134
Validation loss: 2.6030020792783426

Epoch: 6| Step: 4
Training loss: 2.9248211536994755
Validation loss: 2.6001519609190047

Epoch: 6| Step: 5
Training loss: 3.319661298732999
Validation loss: 2.6142439428092072

Epoch: 6| Step: 6
Training loss: 2.7934656941533436
Validation loss: 2.6015497209976073

Epoch: 6| Step: 7
Training loss: 3.1366445644247225
Validation loss: 2.603214742287542

Epoch: 6| Step: 8
Training loss: 2.5601453429924823
Validation loss: 2.6155605763839564

Epoch: 6| Step: 9
Training loss: 2.6663933454950697
Validation loss: 2.6069356701838067

Epoch: 6| Step: 10
Training loss: 2.29747665725489
Validation loss: 2.6030101592085506

Epoch: 6| Step: 11
Training loss: 2.7484101121154865
Validation loss: 2.612558271328644

Epoch: 6| Step: 12
Training loss: 2.2654490435444545
Validation loss: 2.5929357864519096

Epoch: 6| Step: 13
Training loss: 2.0907935150153922
Validation loss: 2.6099107111464233

Epoch: 103| Step: 0
Training loss: 2.7253395988867615
Validation loss: 2.5997811807506968

Epoch: 6| Step: 1
Training loss: 2.68549316352538
Validation loss: 2.6169360996818667

Epoch: 6| Step: 2
Training loss: 2.9915429758271403
Validation loss: 2.5980471919857617

Epoch: 6| Step: 3
Training loss: 2.058972781645707
Validation loss: 2.626202554456093

Epoch: 6| Step: 4
Training loss: 2.3856558423026146
Validation loss: 2.603577879927969

Epoch: 6| Step: 5
Training loss: 2.7200868323434606
Validation loss: 2.6152943689095474

Epoch: 6| Step: 6
Training loss: 2.8098367585249693
Validation loss: 2.5929697946094286

Epoch: 6| Step: 7
Training loss: 2.8465503695970025
Validation loss: 2.5821787516342294

Epoch: 6| Step: 8
Training loss: 3.1694874163147793
Validation loss: 2.610023552044931

Epoch: 6| Step: 9
Training loss: 3.6383456843107256
Validation loss: 2.587378115698924

Epoch: 6| Step: 10
Training loss: 2.462349429101917
Validation loss: 2.598354707385676

Epoch: 6| Step: 11
Training loss: 2.5420065376383754
Validation loss: 2.582864919015071

Epoch: 6| Step: 12
Training loss: 3.282919613353964
Validation loss: 2.595822358024672

Epoch: 6| Step: 13
Training loss: 3.3625364110173557
Validation loss: 2.6028922295281642

Epoch: 104| Step: 0
Training loss: 2.890674157626779
Validation loss: 2.6180909494239963

Epoch: 6| Step: 1
Training loss: 2.6981000113815714
Validation loss: 2.5867631639569955

Epoch: 6| Step: 2
Training loss: 2.697516206651991
Validation loss: 2.6164986700765924

Epoch: 6| Step: 3
Training loss: 3.3361065931145784
Validation loss: 2.603152545642925

Epoch: 6| Step: 4
Training loss: 2.9483232161666577
Validation loss: 2.5666990154525386

Epoch: 6| Step: 5
Training loss: 3.088626356502283
Validation loss: 2.634927518846764

Epoch: 6| Step: 6
Training loss: 3.4379979553216575
Validation loss: 2.5710213512182256

Epoch: 6| Step: 7
Training loss: 2.1417420528616637
Validation loss: 2.634857298008458

Epoch: 6| Step: 8
Training loss: 3.0648613992688993
Validation loss: 2.6162760377210104

Epoch: 6| Step: 9
Training loss: 2.64275874319228
Validation loss: 2.6118004770411845

Epoch: 6| Step: 10
Training loss: 2.5671125627424365
Validation loss: 2.615655458044391

Epoch: 6| Step: 11
Training loss: 2.8003026321896254
Validation loss: 2.5712728488210077

Epoch: 6| Step: 12
Training loss: 2.5306292114072027
Validation loss: 2.588783947738537

Epoch: 6| Step: 13
Training loss: 2.449722359943695
Validation loss: 2.6048167038012164

Epoch: 105| Step: 0
Training loss: 2.9371935096092368
Validation loss: 2.57236573125283

Epoch: 6| Step: 1
Training loss: 3.0691422035084077
Validation loss: 2.593778509009777

Epoch: 6| Step: 2
Training loss: 1.879296022461353
Validation loss: 2.631630825471552

Epoch: 6| Step: 3
Training loss: 2.2954162324923564
Validation loss: 2.6038976701838323

Epoch: 6| Step: 4
Training loss: 3.1394189445188903
Validation loss: 2.5898915687954394

Epoch: 6| Step: 5
Training loss: 2.9856083902652024
Validation loss: 2.5991583454209937

Epoch: 6| Step: 6
Training loss: 2.7793050244467223
Validation loss: 2.5946468962706475

Epoch: 6| Step: 7
Training loss: 3.4224788881908834
Validation loss: 2.6036742340802843

Epoch: 6| Step: 8
Training loss: 2.1833523256868728
Validation loss: 2.624468728646562

Epoch: 6| Step: 9
Training loss: 2.7430904455957164
Validation loss: 2.5915299427961056

Epoch: 6| Step: 10
Training loss: 3.158857118626678
Validation loss: 2.580595002789292

Epoch: 6| Step: 11
Training loss: 2.587558019604928
Validation loss: 2.5951917238935986

Epoch: 6| Step: 12
Training loss: 2.8650017080251984
Validation loss: 2.612781668876043

Epoch: 6| Step: 13
Training loss: 3.5087235590879944
Validation loss: 2.6153881437637625

Epoch: 106| Step: 0
Training loss: 2.4388406441255985
Validation loss: 2.5591122142429943

Epoch: 6| Step: 1
Training loss: 2.6498383274784296
Validation loss: 2.608540030560749

Epoch: 6| Step: 2
Training loss: 2.0116140986508495
Validation loss: 2.5715815392340717

Epoch: 6| Step: 3
Training loss: 2.4159472370259882
Validation loss: 2.593793553603071

Epoch: 6| Step: 4
Training loss: 3.8441453435772153
Validation loss: 2.604475912785526

Epoch: 6| Step: 5
Training loss: 3.3983523303354217
Validation loss: 2.6134968031124366

Epoch: 6| Step: 6
Training loss: 2.9506712715514056
Validation loss: 2.581104380468754

Epoch: 6| Step: 7
Training loss: 2.8957042711071184
Validation loss: 2.570533988010512

Epoch: 6| Step: 8
Training loss: 2.284882670923226
Validation loss: 2.5999052615373626

Epoch: 6| Step: 9
Training loss: 2.828418021012261
Validation loss: 2.5937270375853956

Epoch: 6| Step: 10
Training loss: 2.5642470940179862
Validation loss: 2.5883443886013335

Epoch: 6| Step: 11
Training loss: 2.7923343391424233
Validation loss: 2.6215903614635114

Epoch: 6| Step: 12
Training loss: 2.728580373051776
Validation loss: 2.607002838950627

Epoch: 6| Step: 13
Training loss: 3.671812276101568
Validation loss: 2.6282022364837574

Epoch: 107| Step: 0
Training loss: 3.051755156248844
Validation loss: 2.614851733180991

Epoch: 6| Step: 1
Training loss: 3.0395275240701602
Validation loss: 2.6048004635928605

Epoch: 6| Step: 2
Training loss: 2.575981034736242
Validation loss: 2.604356892847

Epoch: 6| Step: 3
Training loss: 2.743159542983105
Validation loss: 2.6067928570492973

Epoch: 6| Step: 4
Training loss: 3.2230486266811385
Validation loss: 2.6045926713234158

Epoch: 6| Step: 5
Training loss: 2.518001973509678
Validation loss: 2.588118182389758

Epoch: 6| Step: 6
Training loss: 1.8953437242821312
Validation loss: 2.6270193408568705

Epoch: 6| Step: 7
Training loss: 2.264861616239843
Validation loss: 2.621029740697508

Epoch: 6| Step: 8
Training loss: 2.2142774608124234
Validation loss: 2.5991417394332537

Epoch: 6| Step: 9
Training loss: 2.434757940022265
Validation loss: 2.597792163037818

Epoch: 6| Step: 10
Training loss: 3.1059090931909155
Validation loss: 2.595411740674771

Epoch: 6| Step: 11
Training loss: 3.1170672630123906
Validation loss: 2.5771126468309147

Epoch: 6| Step: 12
Training loss: 4.123523794805618
Validation loss: 2.6357398842763744

Epoch: 6| Step: 13
Training loss: 2.9997326413865295
Validation loss: 2.58240452508681

Epoch: 108| Step: 0
Training loss: 2.3096993472807457
Validation loss: 2.6307355506870786

Epoch: 6| Step: 1
Training loss: 2.817768079837606
Validation loss: 2.5945663146088305

Epoch: 6| Step: 2
Training loss: 3.4056037499767156
Validation loss: 2.612490407364125

Epoch: 6| Step: 3
Training loss: 3.171900857152919
Validation loss: 2.5701339793834963

Epoch: 6| Step: 4
Training loss: 2.2554761156438228
Validation loss: 2.5943106578962674

Epoch: 6| Step: 5
Training loss: 2.8554998101294657
Validation loss: 2.592896812517336

Epoch: 6| Step: 6
Training loss: 3.0233611656626653
Validation loss: 2.5990872647162973

Epoch: 6| Step: 7
Training loss: 2.508910512156185
Validation loss: 2.61241303354259

Epoch: 6| Step: 8
Training loss: 3.2410096752254205
Validation loss: 2.5879121711005832

Epoch: 6| Step: 9
Training loss: 2.16261490974081
Validation loss: 2.6060885160418232

Epoch: 6| Step: 10
Training loss: 2.6060234977675756
Validation loss: 2.6108560557200295

Epoch: 6| Step: 11
Training loss: 3.305184545630738
Validation loss: 2.5887141013169144

Epoch: 6| Step: 12
Training loss: 2.905100113002122
Validation loss: 2.596139705675426

Epoch: 6| Step: 13
Training loss: 2.626052282226928
Validation loss: 2.587988851969645

Epoch: 109| Step: 0
Training loss: 3.2545640150096005
Validation loss: 2.5901246999996315

Epoch: 6| Step: 1
Training loss: 3.6787876721655794
Validation loss: 2.5927390327393347

Epoch: 6| Step: 2
Training loss: 2.573076611282314
Validation loss: 2.618450894128107

Epoch: 6| Step: 3
Training loss: 3.4247761451351986
Validation loss: 2.59437716240931

Epoch: 6| Step: 4
Training loss: 2.3488011163059253
Validation loss: 2.5823027817512982

Epoch: 6| Step: 5
Training loss: 2.3536415414643725
Validation loss: 2.6004225656887465

Epoch: 6| Step: 6
Training loss: 2.7088009552856493
Validation loss: 2.590711242537806

Epoch: 6| Step: 7
Training loss: 2.7246121751777728
Validation loss: 2.58713977448893

Epoch: 6| Step: 8
Training loss: 2.8966320409194117
Validation loss: 2.6245242233112025

Epoch: 6| Step: 9
Training loss: 2.173383010850372
Validation loss: 2.6078166251596393

Epoch: 6| Step: 10
Training loss: 2.1175535666796175
Validation loss: 2.597458444941356

Epoch: 6| Step: 11
Training loss: 2.873428246803175
Validation loss: 2.6145822325405392

Epoch: 6| Step: 12
Training loss: 3.2675217955956137
Validation loss: 2.5864390834877535

Epoch: 6| Step: 13
Training loss: 2.9496680315379313
Validation loss: 2.6120227125539968

Epoch: 110| Step: 0
Training loss: 2.2298798059137677
Validation loss: 2.5882183797509657

Epoch: 6| Step: 1
Training loss: 3.384007619429864
Validation loss: 2.5987404944437054

Epoch: 6| Step: 2
Training loss: 3.015013637733298
Validation loss: 2.603358691153215

Epoch: 6| Step: 3
Training loss: 3.3376500471011132
Validation loss: 2.599574257470217

Epoch: 6| Step: 4
Training loss: 3.4675294945527515
Validation loss: 2.5882212799450275

Epoch: 6| Step: 5
Training loss: 2.3056335576457796
Validation loss: 2.596358551049007

Epoch: 6| Step: 6
Training loss: 2.3862522000142303
Validation loss: 2.5540952402075305

Epoch: 6| Step: 7
Training loss: 2.3797491675518803
Validation loss: 2.5883826733955435

Epoch: 6| Step: 8
Training loss: 2.8687857764845153
Validation loss: 2.59113482673242

Epoch: 6| Step: 9
Training loss: 3.061172509044035
Validation loss: 2.5950933783596644

Epoch: 6| Step: 10
Training loss: 2.631143465399855
Validation loss: 2.6087256430394374

Epoch: 6| Step: 11
Training loss: 3.0125623577834353
Validation loss: 2.569694723326548

Epoch: 6| Step: 12
Training loss: 2.773837294440511
Validation loss: 2.5929560458641614

Epoch: 6| Step: 13
Training loss: 2.1198437908490613
Validation loss: 2.5553458105291793

Epoch: 111| Step: 0
Training loss: 2.139668048888901
Validation loss: 2.598558130773573

Epoch: 6| Step: 1
Training loss: 3.0088231358120163
Validation loss: 2.590450397643368

Epoch: 6| Step: 2
Training loss: 3.512163959325512
Validation loss: 2.5726175388840096

Epoch: 6| Step: 3
Training loss: 2.4097359907604017
Validation loss: 2.616470807407389

Epoch: 6| Step: 4
Training loss: 2.6529149380077084
Validation loss: 2.583330534167035

Epoch: 6| Step: 5
Training loss: 3.10806676285764
Validation loss: 2.627039812667971

Epoch: 6| Step: 6
Training loss: 3.1262723239984753
Validation loss: 2.586275390978701

Epoch: 6| Step: 7
Training loss: 2.329087026618687
Validation loss: 2.5869159513517936

Epoch: 6| Step: 8
Training loss: 3.054476601425322
Validation loss: 2.593945469800553

Epoch: 6| Step: 9
Training loss: 3.1119283802352165
Validation loss: 2.597359540711074

Epoch: 6| Step: 10
Training loss: 2.3053702684682884
Validation loss: 2.576736541686444

Epoch: 6| Step: 11
Training loss: 2.659443450297831
Validation loss: 2.591339890292659

Epoch: 6| Step: 12
Training loss: 2.9401668049728835
Validation loss: 2.5880648550030503

Epoch: 6| Step: 13
Training loss: 3.0611905782469107
Validation loss: 2.60206795242272

Epoch: 112| Step: 0
Training loss: 3.267966275324786
Validation loss: 2.5955377371093364

Epoch: 6| Step: 1
Training loss: 2.6450551808591896
Validation loss: 2.6222704531460583

Epoch: 6| Step: 2
Training loss: 3.0925022267709052
Validation loss: 2.6368381379936756

Epoch: 6| Step: 3
Training loss: 2.9926191770553423
Validation loss: 2.5805777021468916

Epoch: 6| Step: 4
Training loss: 2.6605899138015627
Validation loss: 2.6094976195812927

Epoch: 6| Step: 5
Training loss: 2.474945984838589
Validation loss: 2.588283777941266

Epoch: 6| Step: 6
Training loss: 2.9215851502290775
Validation loss: 2.581869194405185

Epoch: 6| Step: 7
Training loss: 3.189880080883907
Validation loss: 2.604280719515538

Epoch: 6| Step: 8
Training loss: 3.064485178987075
Validation loss: 2.600539309050843

Epoch: 6| Step: 9
Training loss: 2.7254833282761393
Validation loss: 2.5851872523819024

Epoch: 6| Step: 10
Training loss: 2.963151974300801
Validation loss: 2.595273937757664

Epoch: 6| Step: 11
Training loss: 2.629076562497214
Validation loss: 2.5642867023422093

Epoch: 6| Step: 12
Training loss: 2.8244221931932967
Validation loss: 2.606688278228665

Epoch: 6| Step: 13
Training loss: 1.8386693231140672
Validation loss: 2.597608800148289

Epoch: 113| Step: 0
Training loss: 2.415955230525458
Validation loss: 2.5859653089848638

Epoch: 6| Step: 1
Training loss: 3.45345460173118
Validation loss: 2.599041811283257

Epoch: 6| Step: 2
Training loss: 2.5946414748351208
Validation loss: 2.5858384277510993

Epoch: 6| Step: 3
Training loss: 3.3630555328584517
Validation loss: 2.590546376133319

Epoch: 6| Step: 4
Training loss: 3.2149279966938265
Validation loss: 2.621823237840483

Epoch: 6| Step: 5
Training loss: 2.220100958650656
Validation loss: 2.5844963709359154

Epoch: 6| Step: 6
Training loss: 2.98748138294245
Validation loss: 2.576857860082252

Epoch: 6| Step: 7
Training loss: 2.735089366784807
Validation loss: 2.607648777964258

Epoch: 6| Step: 8
Training loss: 1.834169876093514
Validation loss: 2.5933095946304827

Epoch: 6| Step: 9
Training loss: 3.128005451734236
Validation loss: 2.5857014808750827

Epoch: 6| Step: 10
Training loss: 3.305995961689314
Validation loss: 2.5859371946556666

Epoch: 6| Step: 11
Training loss: 2.915987171767579
Validation loss: 2.5939817694449228

Epoch: 6| Step: 12
Training loss: 2.242539859957574
Validation loss: 2.6140246652179693

Epoch: 6| Step: 13
Training loss: 2.9507132880171625
Validation loss: 2.6056749415072553

Epoch: 114| Step: 0
Training loss: 2.4312675220475897
Validation loss: 2.610232317436644

Epoch: 6| Step: 1
Training loss: 3.258950599551172
Validation loss: 2.6102790654113233

Epoch: 6| Step: 2
Training loss: 2.9936468883110665
Validation loss: 2.5934396254884406

Epoch: 6| Step: 3
Training loss: 2.5348576397771865
Validation loss: 2.569027159875134

Epoch: 6| Step: 4
Training loss: 2.6895525878598785
Validation loss: 2.552906001389479

Epoch: 6| Step: 5
Training loss: 2.6992623840426693
Validation loss: 2.597774309807384

Epoch: 6| Step: 6
Training loss: 3.2730312049746475
Validation loss: 2.6002824304542034

Epoch: 6| Step: 7
Training loss: 2.296586102852171
Validation loss: 2.5907826554627365

Epoch: 6| Step: 8
Training loss: 3.100802465372513
Validation loss: 2.5911923531354963

Epoch: 6| Step: 9
Training loss: 2.325857402258283
Validation loss: 2.5830217392516905

Epoch: 6| Step: 10
Training loss: 3.135139039042514
Validation loss: 2.5501570429450555

Epoch: 6| Step: 11
Training loss: 2.9868348853671653
Validation loss: 2.583305875438431

Epoch: 6| Step: 12
Training loss: 2.6302566574240127
Validation loss: 2.5667206155929394

Epoch: 6| Step: 13
Training loss: 3.2731027363691396
Validation loss: 2.5719304666820464

Epoch: 115| Step: 0
Training loss: 2.919754646130992
Validation loss: 2.598493262477045

Epoch: 6| Step: 1
Training loss: 3.090315328267489
Validation loss: 2.596079620664257

Epoch: 6| Step: 2
Training loss: 2.6841987027950123
Validation loss: 2.5955933466066625

Epoch: 6| Step: 3
Training loss: 2.887787617152159
Validation loss: 2.605656322719492

Epoch: 6| Step: 4
Training loss: 2.4826100155826802
Validation loss: 2.5855236450341788

Epoch: 6| Step: 5
Training loss: 2.835847038738871
Validation loss: 2.6062891393400958

Epoch: 6| Step: 6
Training loss: 3.0240979323499695
Validation loss: 2.5990969719787436

Epoch: 6| Step: 7
Training loss: 2.6128128156512376
Validation loss: 2.5998117831551677

Epoch: 6| Step: 8
Training loss: 3.1640579788740846
Validation loss: 2.607444722710472

Epoch: 6| Step: 9
Training loss: 2.582235308041502
Validation loss: 2.602123760291382

Epoch: 6| Step: 10
Training loss: 3.214721232382166
Validation loss: 2.5621547041142994

Epoch: 6| Step: 11
Training loss: 2.4815006542677653
Validation loss: 2.610635605349266

Epoch: 6| Step: 12
Training loss: 2.4937274444248385
Validation loss: 2.5889009916400645

Epoch: 6| Step: 13
Training loss: 2.9728062274810148
Validation loss: 2.6150795315761393

Epoch: 116| Step: 0
Training loss: 3.2232057415056823
Validation loss: 2.6227386879728805

Epoch: 6| Step: 1
Training loss: 2.7367029362209934
Validation loss: 2.611362962730229

Epoch: 6| Step: 2
Training loss: 2.616249485735745
Validation loss: 2.6453163805319817

Epoch: 6| Step: 3
Training loss: 3.129702882162336
Validation loss: 2.613066949611786

Epoch: 6| Step: 4
Training loss: 2.4069635893695063
Validation loss: 2.5961125221349053

Epoch: 6| Step: 5
Training loss: 2.592358503168062
Validation loss: 2.596669342797026

Epoch: 6| Step: 6
Training loss: 2.4780424972597013
Validation loss: 2.5907540026583122

Epoch: 6| Step: 7
Training loss: 3.118230583038102
Validation loss: 2.5837283796665402

Epoch: 6| Step: 8
Training loss: 3.05020241612879
Validation loss: 2.5867401514132986

Epoch: 6| Step: 9
Training loss: 3.3716617605186543
Validation loss: 2.6001587758517926

Epoch: 6| Step: 10
Training loss: 2.7762414646833316
Validation loss: 2.5974290781598306

Epoch: 6| Step: 11
Training loss: 2.649749071008941
Validation loss: 2.5687024775123852

Epoch: 6| Step: 12
Training loss: 2.523182197623625
Validation loss: 2.5604021422533254

Epoch: 6| Step: 13
Training loss: 2.1672667870460502
Validation loss: 2.5853942978670754

Epoch: 117| Step: 0
Training loss: 2.9624963044091204
Validation loss: 2.5936974427341553

Epoch: 6| Step: 1
Training loss: 2.1166894756299697
Validation loss: 2.603462227983663

Epoch: 6| Step: 2
Training loss: 3.434298880152654
Validation loss: 2.6155790648803925

Epoch: 6| Step: 3
Training loss: 2.652750559917402
Validation loss: 2.601746273992914

Epoch: 6| Step: 4
Training loss: 2.77623871658004
Validation loss: 2.571647511036874

Epoch: 6| Step: 5
Training loss: 2.9886507890381506
Validation loss: 2.5930629986209057

Epoch: 6| Step: 6
Training loss: 2.7037850164014507
Validation loss: 2.610556315610323

Epoch: 6| Step: 7
Training loss: 2.419517895936065
Validation loss: 2.621276325836909

Epoch: 6| Step: 8
Training loss: 3.2159607292168904
Validation loss: 2.576867377993598

Epoch: 6| Step: 9
Training loss: 2.4384354972513362
Validation loss: 2.5725522845496127

Epoch: 6| Step: 10
Training loss: 2.2950342808242956
Validation loss: 2.5765907871046227

Epoch: 6| Step: 11
Training loss: 2.3826275863189132
Validation loss: 2.586426930535117

Epoch: 6| Step: 12
Training loss: 3.686902013881158
Validation loss: 2.566621650580175

Epoch: 6| Step: 13
Training loss: 3.208639468825652
Validation loss: 2.5619376110914645

Epoch: 118| Step: 0
Training loss: 2.545909019714534
Validation loss: 2.579691655823649

Epoch: 6| Step: 1
Training loss: 2.24432186394182
Validation loss: 2.6140083694323395

Epoch: 6| Step: 2
Training loss: 2.361167883346279
Validation loss: 2.623846783245925

Epoch: 6| Step: 3
Training loss: 2.2594727216721315
Validation loss: 2.604360524171008

Epoch: 6| Step: 4
Training loss: 3.085404052983339
Validation loss: 2.573652889408598

Epoch: 6| Step: 5
Training loss: 2.977380675159704
Validation loss: 2.627684684786562

Epoch: 6| Step: 6
Training loss: 2.195267754909881
Validation loss: 2.593155615009171

Epoch: 6| Step: 7
Training loss: 2.9097790364798657
Validation loss: 2.5839093413307244

Epoch: 6| Step: 8
Training loss: 3.229098969436977
Validation loss: 2.594699115171036

Epoch: 6| Step: 9
Training loss: 3.3091755144981954
Validation loss: 2.596271802688716

Epoch: 6| Step: 10
Training loss: 3.5232393670040403
Validation loss: 2.584187720291313

Epoch: 6| Step: 11
Training loss: 2.6529764086626657
Validation loss: 2.5926525968656415

Epoch: 6| Step: 12
Training loss: 2.8004924886010563
Validation loss: 2.584066892852539

Epoch: 6| Step: 13
Training loss: 3.084683165765051
Validation loss: 2.585457485908941

Epoch: 119| Step: 0
Training loss: 3.320669644165338
Validation loss: 2.6252884303488235

Epoch: 6| Step: 1
Training loss: 2.512270568696643
Validation loss: 2.6404310814077268

Epoch: 6| Step: 2
Training loss: 3.055567153754523
Validation loss: 2.574975035853348

Epoch: 6| Step: 3
Training loss: 2.7740966873150814
Validation loss: 2.6111477822965257

Epoch: 6| Step: 4
Training loss: 2.7461197093534295
Validation loss: 2.6023936753540715

Epoch: 6| Step: 5
Training loss: 2.782256726429151
Validation loss: 2.6075315181951866

Epoch: 6| Step: 6
Training loss: 3.06666717391079
Validation loss: 2.5819253519861807

Epoch: 6| Step: 7
Training loss: 2.603435952984345
Validation loss: 2.6001001463377507

Epoch: 6| Step: 8
Training loss: 3.201757073808095
Validation loss: 2.607255906006262

Epoch: 6| Step: 9
Training loss: 2.3079742271663606
Validation loss: 2.6131312461845657

Epoch: 6| Step: 10
Training loss: 2.455421878902596
Validation loss: 2.593241296137725

Epoch: 6| Step: 11
Training loss: 2.3596891484578757
Validation loss: 2.5809350573211725

Epoch: 6| Step: 12
Training loss: 3.0804541436317576
Validation loss: 2.5743946601230037

Epoch: 6| Step: 13
Training loss: 2.823928163808886
Validation loss: 2.5957430780113855

Epoch: 120| Step: 0
Training loss: 2.5254313147763643
Validation loss: 2.5988662624176335

Epoch: 6| Step: 1
Training loss: 3.0402167709764325
Validation loss: 2.6163381673532604

Epoch: 6| Step: 2
Training loss: 2.7249107276222357
Validation loss: 2.6133866136440194

Epoch: 6| Step: 3
Training loss: 2.6872315383604883
Validation loss: 2.599106033635817

Epoch: 6| Step: 4
Training loss: 2.487050756785513
Validation loss: 2.595099934910402

Epoch: 6| Step: 5
Training loss: 2.9571966933779015
Validation loss: 2.6134657959341943

Epoch: 6| Step: 6
Training loss: 2.3249304443127614
Validation loss: 2.591971251903323

Epoch: 6| Step: 7
Training loss: 2.7321646339553065
Validation loss: 2.604768400177708

Epoch: 6| Step: 8
Training loss: 2.5433379343307028
Validation loss: 2.5789558063894567

Epoch: 6| Step: 9
Training loss: 2.9223558978734006
Validation loss: 2.579892085095861

Epoch: 6| Step: 10
Training loss: 3.59659682589352
Validation loss: 2.594601176822352

Epoch: 6| Step: 11
Training loss: 3.052941176816475
Validation loss: 2.5815815545087837

Epoch: 6| Step: 12
Training loss: 2.3379955602820726
Validation loss: 2.612406454203847

Epoch: 6| Step: 13
Training loss: 3.3890921648133325
Validation loss: 2.6280343877674244

Epoch: 121| Step: 0
Training loss: 2.748477861326014
Validation loss: 2.5781268227012357

Epoch: 6| Step: 1
Training loss: 2.3107119684256174
Validation loss: 2.6139615606549795

Epoch: 6| Step: 2
Training loss: 3.301528466875658
Validation loss: 2.5666031749971077

Epoch: 6| Step: 3
Training loss: 2.904082443643351
Validation loss: 2.547383856304878

Epoch: 6| Step: 4
Training loss: 2.6439843112289645
Validation loss: 2.629585232431224

Epoch: 6| Step: 5
Training loss: 2.392858720791099
Validation loss: 2.579560011671098

Epoch: 6| Step: 6
Training loss: 2.5438220677020014
Validation loss: 2.5860871599871897

Epoch: 6| Step: 7
Training loss: 2.321859030585224
Validation loss: 2.5930374220304575

Epoch: 6| Step: 8
Training loss: 3.5575993611017145
Validation loss: 2.5633758350746154

Epoch: 6| Step: 9
Training loss: 2.113627463589572
Validation loss: 2.5731346519952116

Epoch: 6| Step: 10
Training loss: 3.4108231669060944
Validation loss: 2.574490385783395

Epoch: 6| Step: 11
Training loss: 2.8931191071808575
Validation loss: 2.5928874968109255

Epoch: 6| Step: 12
Training loss: 2.984475019286821
Validation loss: 2.5604410521105323

Epoch: 6| Step: 13
Training loss: 2.9478273052424906
Validation loss: 2.5688137653619023

Epoch: 122| Step: 0
Training loss: 2.5017029684111147
Validation loss: 2.577139622928752

Epoch: 6| Step: 1
Training loss: 2.566076341672298
Validation loss: 2.5890639725572377

Epoch: 6| Step: 2
Training loss: 3.1765063819863175
Validation loss: 2.592047448725119

Epoch: 6| Step: 3
Training loss: 2.2048413239906974
Validation loss: 2.567916220385936

Epoch: 6| Step: 4
Training loss: 3.224066926095876
Validation loss: 2.621357570020311

Epoch: 6| Step: 5
Training loss: 2.6232483787142615
Validation loss: 2.5917010021701685

Epoch: 6| Step: 6
Training loss: 2.925852633370681
Validation loss: 2.5665372773014505

Epoch: 6| Step: 7
Training loss: 3.278983941292769
Validation loss: 2.5831041771959957

Epoch: 6| Step: 8
Training loss: 3.20325183152099
Validation loss: 2.635316300068818

Epoch: 6| Step: 9
Training loss: 2.6123917552663114
Validation loss: 2.5779091584015457

Epoch: 6| Step: 10
Training loss: 2.367751655456396
Validation loss: 2.5830205423003543

Epoch: 6| Step: 11
Training loss: 2.406111676092186
Validation loss: 2.575468321972396

Epoch: 6| Step: 12
Training loss: 2.708094972734091
Validation loss: 2.6111708831083975

Epoch: 6| Step: 13
Training loss: 3.308038838408778
Validation loss: 2.6051367661216243

Epoch: 123| Step: 0
Training loss: 2.6399761057263667
Validation loss: 2.596142677006376

Epoch: 6| Step: 1
Training loss: 3.41993567846836
Validation loss: 2.607878236744459

Epoch: 6| Step: 2
Training loss: 2.8726696023431018
Validation loss: 2.625149356872569

Epoch: 6| Step: 3
Training loss: 2.5137423466168047
Validation loss: 2.5703975283041114

Epoch: 6| Step: 4
Training loss: 2.8370552487457896
Validation loss: 2.597393834425308

Epoch: 6| Step: 5
Training loss: 2.9930769193574744
Validation loss: 2.589830665701953

Epoch: 6| Step: 6
Training loss: 2.8668462149998533
Validation loss: 2.5922665891400647

Epoch: 6| Step: 7
Training loss: 3.2528852713400416
Validation loss: 2.5810890140997556

Epoch: 6| Step: 8
Training loss: 2.7940420796004712
Validation loss: 2.5792261878741267

Epoch: 6| Step: 9
Training loss: 2.784967659534764
Validation loss: 2.5956040482017566

Epoch: 6| Step: 10
Training loss: 2.724465599505151
Validation loss: 2.5948160330461048

Epoch: 6| Step: 11
Training loss: 2.0214104238058503
Validation loss: 2.6068108815896815

Epoch: 6| Step: 12
Training loss: 2.7462534091600137
Validation loss: 2.5710687363585887

Epoch: 6| Step: 13
Training loss: 1.8893323530456183
Validation loss: 2.6112146119959

Epoch: 124| Step: 0
Training loss: 3.0869704437175525
Validation loss: 2.5936540876738565

Epoch: 6| Step: 1
Training loss: 2.8220091389725046
Validation loss: 2.5984316651510624

Epoch: 6| Step: 2
Training loss: 2.7974277568144537
Validation loss: 2.5946629678407285

Epoch: 6| Step: 3
Training loss: 3.289622062147501
Validation loss: 2.6021848968342423

Epoch: 6| Step: 4
Training loss: 2.143633767583144
Validation loss: 2.59417023301831

Epoch: 6| Step: 5
Training loss: 3.405957690654325
Validation loss: 2.5927604985040276

Epoch: 6| Step: 6
Training loss: 2.0097275443959703
Validation loss: 2.5981244410639697

Epoch: 6| Step: 7
Training loss: 2.3031843035450272
Validation loss: 2.6013188810824337

Epoch: 6| Step: 8
Training loss: 3.0326849303814747
Validation loss: 2.558811384205632

Epoch: 6| Step: 9
Training loss: 2.433119236223717
Validation loss: 2.600835844838705

Epoch: 6| Step: 10
Training loss: 2.514407603758658
Validation loss: 2.5539766167836064

Epoch: 6| Step: 11
Training loss: 3.0490270594931563
Validation loss: 2.6011752125763086

Epoch: 6| Step: 12
Training loss: 3.0139984329715697
Validation loss: 2.6050640323876673

Epoch: 6| Step: 13
Training loss: 3.428597731148782
Validation loss: 2.58744228869961

Epoch: 125| Step: 0
Training loss: 2.6025544529329174
Validation loss: 2.6028475157455837

Epoch: 6| Step: 1
Training loss: 3.2685729232293066
Validation loss: 2.5738538257804664

Epoch: 6| Step: 2
Training loss: 2.259191811127451
Validation loss: 2.5875083188048107

Epoch: 6| Step: 3
Training loss: 2.6112891389023667
Validation loss: 2.5874619342290073

Epoch: 6| Step: 4
Training loss: 2.3498947972226154
Validation loss: 2.573306151140301

Epoch: 6| Step: 5
Training loss: 2.550278711982097
Validation loss: 2.6084169561222663

Epoch: 6| Step: 6
Training loss: 3.2752173781142173
Validation loss: 2.5974366839058276

Epoch: 6| Step: 7
Training loss: 3.440723641598733
Validation loss: 2.603560126436281

Epoch: 6| Step: 8
Training loss: 3.172146790233558
Validation loss: 2.5664965210277457

Epoch: 6| Step: 9
Training loss: 2.8445416700449426
Validation loss: 2.6054391291203065

Epoch: 6| Step: 10
Training loss: 3.147609705993913
Validation loss: 2.6001471671867744

Epoch: 6| Step: 11
Training loss: 2.1277156755477646
Validation loss: 2.5932837318099047

Epoch: 6| Step: 12
Training loss: 2.078751433756799
Validation loss: 2.573962811280687

Epoch: 6| Step: 13
Training loss: 3.312875978257329
Validation loss: 2.587014108304833

Epoch: 126| Step: 0
Training loss: 2.8930716393017017
Validation loss: 2.61536646721679

Epoch: 6| Step: 1
Training loss: 2.451378850823281
Validation loss: 2.5749426657640333

Epoch: 6| Step: 2
Training loss: 2.0746225082622454
Validation loss: 2.6078115142248457

Epoch: 6| Step: 3
Training loss: 2.7230029111209904
Validation loss: 2.545757653308651

Epoch: 6| Step: 4
Training loss: 3.6783459074436067
Validation loss: 2.551691144618448

Epoch: 6| Step: 5
Training loss: 1.7007803920871603
Validation loss: 2.5947410221261906

Epoch: 6| Step: 6
Training loss: 2.941009048857869
Validation loss: 2.603750374940256

Epoch: 6| Step: 7
Training loss: 2.7011003795107045
Validation loss: 2.5954641367961044

Epoch: 6| Step: 8
Training loss: 2.717347934542664
Validation loss: 2.5893889066301994

Epoch: 6| Step: 9
Training loss: 3.2335566715567157
Validation loss: 2.5798117809030563

Epoch: 6| Step: 10
Training loss: 3.4932185278899675
Validation loss: 2.5860164392230796

Epoch: 6| Step: 11
Training loss: 2.3720699104569443
Validation loss: 2.59022773847492

Epoch: 6| Step: 12
Training loss: 2.3122541967125594
Validation loss: 2.573309221562264

Epoch: 6| Step: 13
Training loss: 3.4019455616501495
Validation loss: 2.61042364412031

Epoch: 127| Step: 0
Training loss: 2.909615977271377
Validation loss: 2.589872026330106

Epoch: 6| Step: 1
Training loss: 2.507098229911191
Validation loss: 2.580206395847068

Epoch: 6| Step: 2
Training loss: 3.1652691082800577
Validation loss: 2.587101355362884

Epoch: 6| Step: 3
Training loss: 2.7687932202687953
Validation loss: 2.6077456334867684

Epoch: 6| Step: 4
Training loss: 2.709031636129061
Validation loss: 2.592443252407404

Epoch: 6| Step: 5
Training loss: 2.988729924446051
Validation loss: 2.5969026345638238

Epoch: 6| Step: 6
Training loss: 2.6824426306058626
Validation loss: 2.5869851243958935

Epoch: 6| Step: 7
Training loss: 3.1443893116257735
Validation loss: 2.592822488621645

Epoch: 6| Step: 8
Training loss: 2.074669740431077
Validation loss: 2.590250788325026

Epoch: 6| Step: 9
Training loss: 2.320083555492727
Validation loss: 2.6053020573223917

Epoch: 6| Step: 10
Training loss: 3.25445984233274
Validation loss: 2.582053844813552

Epoch: 6| Step: 11
Training loss: 3.094747209224279
Validation loss: 2.598120213920249

Epoch: 6| Step: 12
Training loss: 2.662580508595411
Validation loss: 2.598585301556008

Epoch: 6| Step: 13
Training loss: 3.0917148253879168
Validation loss: 2.5915651356983647

Epoch: 128| Step: 0
Training loss: 2.465196780693481
Validation loss: 2.5989597254874393

Epoch: 6| Step: 1
Training loss: 3.2905975891304773
Validation loss: 2.5794130768776933

Epoch: 6| Step: 2
Training loss: 2.5541059199499707
Validation loss: 2.604199431838778

Epoch: 6| Step: 3
Training loss: 2.7954276831464733
Validation loss: 2.596932639093952

Epoch: 6| Step: 4
Training loss: 3.054321267108285
Validation loss: 2.606191638501527

Epoch: 6| Step: 5
Training loss: 2.633113130786728
Validation loss: 2.593907664419771

Epoch: 6| Step: 6
Training loss: 2.428638882060898
Validation loss: 2.5703970685159168

Epoch: 6| Step: 7
Training loss: 3.297154130012072
Validation loss: 2.5816149823554504

Epoch: 6| Step: 8
Training loss: 3.1692975475948026
Validation loss: 2.59702963021113

Epoch: 6| Step: 9
Training loss: 2.9171904683928056
Validation loss: 2.5863401682325344

Epoch: 6| Step: 10
Training loss: 2.733043411820155
Validation loss: 2.6040357826730975

Epoch: 6| Step: 11
Training loss: 2.454448658707532
Validation loss: 2.6073230704562858

Epoch: 6| Step: 12
Training loss: 2.735837360076621
Validation loss: 2.556906431002442

Epoch: 6| Step: 13
Training loss: 2.681385447675576
Validation loss: 2.5710233539515785

Epoch: 129| Step: 0
Training loss: 2.7821336692547813
Validation loss: 2.6086945653925477

Epoch: 6| Step: 1
Training loss: 2.422604161907795
Validation loss: 2.603288141201078

Epoch: 6| Step: 2
Training loss: 3.1144075546078955
Validation loss: 2.587659882257646

Epoch: 6| Step: 3
Training loss: 3.1387979687451426
Validation loss: 2.6004532078658342

Epoch: 6| Step: 4
Training loss: 2.76680226242659
Validation loss: 2.6146878202535353

Epoch: 6| Step: 5
Training loss: 2.9744726338707497
Validation loss: 2.5856152960707655

Epoch: 6| Step: 6
Training loss: 3.047226792591631
Validation loss: 2.5954939001587514

Epoch: 6| Step: 7
Training loss: 3.071801831449942
Validation loss: 2.5875617597090463

Epoch: 6| Step: 8
Training loss: 2.3194649429583
Validation loss: 2.6111898749271365

Epoch: 6| Step: 9
Training loss: 2.392666213301882
Validation loss: 2.6181317984869716

Epoch: 6| Step: 10
Training loss: 2.1185862295046958
Validation loss: 2.599916393049578

Epoch: 6| Step: 11
Training loss: 2.7800026143013716
Validation loss: 2.5491617569895246

Epoch: 6| Step: 12
Training loss: 3.3902340149354573
Validation loss: 2.585333420714728

Epoch: 6| Step: 13
Training loss: 2.3796577957713976
Validation loss: 2.6062656686883883

Epoch: 130| Step: 0
Training loss: 3.249669718465827
Validation loss: 2.6020403362229687

Epoch: 6| Step: 1
Training loss: 2.7151918476249848
Validation loss: 2.5980267463051967

Epoch: 6| Step: 2
Training loss: 2.460283368080031
Validation loss: 2.574051711792564

Epoch: 6| Step: 3
Training loss: 2.9733635641137823
Validation loss: 2.5899456969673023

Epoch: 6| Step: 4
Training loss: 3.2810475604869316
Validation loss: 2.592967850846185

Epoch: 6| Step: 5
Training loss: 2.479364296438328
Validation loss: 2.6045128285030175

Epoch: 6| Step: 6
Training loss: 2.1997856642611717
Validation loss: 2.5958739538166125

Epoch: 6| Step: 7
Training loss: 2.8657682060642435
Validation loss: 2.600696098572855

Epoch: 6| Step: 8
Training loss: 1.8927597730326595
Validation loss: 2.591018097952204

Epoch: 6| Step: 9
Training loss: 2.655645054763695
Validation loss: 2.6126456269795915

Epoch: 6| Step: 10
Training loss: 3.3637170453904406
Validation loss: 2.5903262667606155

Epoch: 6| Step: 11
Training loss: 2.9823787064041825
Validation loss: 2.5695635477442917

Epoch: 6| Step: 12
Training loss: 2.357378184143599
Validation loss: 2.5930106706440164

Epoch: 6| Step: 13
Training loss: 3.2336035651578507
Validation loss: 2.6044477748301245

Epoch: 131| Step: 0
Training loss: 2.4016032744739224
Validation loss: 2.5750080700891336

Epoch: 6| Step: 1
Training loss: 3.791318493182556
Validation loss: 2.5804609781438272

Epoch: 6| Step: 2
Training loss: 2.682190196269161
Validation loss: 2.6082128056674962

Epoch: 6| Step: 3
Training loss: 2.349461018864241
Validation loss: 2.590227464318141

Epoch: 6| Step: 4
Training loss: 2.6243443351420352
Validation loss: 2.58171099637836

Epoch: 6| Step: 5
Training loss: 3.0571060947504827
Validation loss: 2.5768025969040163

Epoch: 6| Step: 6
Training loss: 2.242769491445845
Validation loss: 2.562683421047538

Epoch: 6| Step: 7
Training loss: 2.458822643484938
Validation loss: 2.6004477827618215

Epoch: 6| Step: 8
Training loss: 2.52275175337352
Validation loss: 2.581415359192984

Epoch: 6| Step: 9
Training loss: 3.231303797851386
Validation loss: 2.600710515151707

Epoch: 6| Step: 10
Training loss: 2.310512823013553
Validation loss: 2.5570183996780598

Epoch: 6| Step: 11
Training loss: 3.218187597825043
Validation loss: 2.6080959988424643

Epoch: 6| Step: 12
Training loss: 2.6765972146334502
Validation loss: 2.5689821231073324

Epoch: 6| Step: 13
Training loss: 3.4872938854057707
Validation loss: 2.5604977782807348

Epoch: 132| Step: 0
Training loss: 2.4747469531852757
Validation loss: 2.595393779207659

Epoch: 6| Step: 1
Training loss: 2.551666433316483
Validation loss: 2.5925550647523905

Epoch: 6| Step: 2
Training loss: 3.1852007782560166
Validation loss: 2.6252898726650793

Epoch: 6| Step: 3
Training loss: 2.7156793200434257
Validation loss: 2.589461953929093

Epoch: 6| Step: 4
Training loss: 2.765422921421997
Validation loss: 2.58928677536499

Epoch: 6| Step: 5
Training loss: 2.960875658984813
Validation loss: 2.565425962097088

Epoch: 6| Step: 6
Training loss: 2.5159585861897398
Validation loss: 2.5792509233762835

Epoch: 6| Step: 7
Training loss: 2.7457672836703075
Validation loss: 2.574289151541927

Epoch: 6| Step: 8
Training loss: 2.9637790220618285
Validation loss: 2.5958851905101263

Epoch: 6| Step: 9
Training loss: 2.5397429977517225
Validation loss: 2.575837654903199

Epoch: 6| Step: 10
Training loss: 2.905050050498001
Validation loss: 2.5777455129841935

Epoch: 6| Step: 11
Training loss: 2.7433536147630595
Validation loss: 2.6024588453888446

Epoch: 6| Step: 12
Training loss: 2.9842839252096387
Validation loss: 2.5457578051176077

Epoch: 6| Step: 13
Training loss: 3.3139042307081197
Validation loss: 2.589644375069611

Epoch: 133| Step: 0
Training loss: 2.0432371470146165
Validation loss: 2.5790430725766087

Epoch: 6| Step: 1
Training loss: 2.7597620829716742
Validation loss: 2.565292773390307

Epoch: 6| Step: 2
Training loss: 2.831712333875263
Validation loss: 2.576480898846636

Epoch: 6| Step: 3
Training loss: 2.963666237267275
Validation loss: 2.5473934611942384

Epoch: 6| Step: 4
Training loss: 2.3478170076446543
Validation loss: 2.601428198101618

Epoch: 6| Step: 5
Training loss: 3.38954757237029
Validation loss: 2.5502376385748073

Epoch: 6| Step: 6
Training loss: 2.9152477809490933
Validation loss: 2.571961219056209

Epoch: 6| Step: 7
Training loss: 2.639407356817236
Validation loss: 2.589596331934689

Epoch: 6| Step: 8
Training loss: 2.9675036574793503
Validation loss: 2.581024631485423

Epoch: 6| Step: 9
Training loss: 2.780925260294625
Validation loss: 2.59340770828575

Epoch: 6| Step: 10
Training loss: 2.9349498636619797
Validation loss: 2.5731005809452716

Epoch: 6| Step: 11
Training loss: 2.9976253648110847
Validation loss: 2.5822247932858695

Epoch: 6| Step: 12
Training loss: 2.2554269615665192
Validation loss: 2.611957504360447

Epoch: 6| Step: 13
Training loss: 3.1221917313444076
Validation loss: 2.6163007188612326

Epoch: 134| Step: 0
Training loss: 2.5775493557160734
Validation loss: 2.613317185909334

Epoch: 6| Step: 1
Training loss: 2.413871782293699
Validation loss: 2.618079937291959

Epoch: 6| Step: 2
Training loss: 2.4254067541917186
Validation loss: 2.581408277284843

Epoch: 6| Step: 3
Training loss: 3.1179228945356443
Validation loss: 2.5919154183085396

Epoch: 6| Step: 4
Training loss: 2.1355983997951298
Validation loss: 2.5900035704841793

Epoch: 6| Step: 5
Training loss: 1.9930863091920208
Validation loss: 2.565265526804576

Epoch: 6| Step: 6
Training loss: 2.568437257463402
Validation loss: 2.6039127838089318

Epoch: 6| Step: 7
Training loss: 3.3516822918022324
Validation loss: 2.5885203311463707

Epoch: 6| Step: 8
Training loss: 3.416022046073868
Validation loss: 2.590290403816887

Epoch: 6| Step: 9
Training loss: 3.508249370328338
Validation loss: 2.5814982997916833

Epoch: 6| Step: 10
Training loss: 2.3251150246336416
Validation loss: 2.5921798225194244

Epoch: 6| Step: 11
Training loss: 2.9464479883388135
Validation loss: 2.5961468451588168

Epoch: 6| Step: 12
Training loss: 2.7589010624389307
Validation loss: 2.6070694022150356

Epoch: 6| Step: 13
Training loss: 3.492488703016553
Validation loss: 2.5530107950461187

Epoch: 135| Step: 0
Training loss: 2.3121769653690762
Validation loss: 2.5821397612835044

Epoch: 6| Step: 1
Training loss: 2.4010150987943977
Validation loss: 2.579185145063738

Epoch: 6| Step: 2
Training loss: 2.8447745018274397
Validation loss: 2.6021762261825714

Epoch: 6| Step: 3
Training loss: 3.114913225511398
Validation loss: 2.6210285953370436

Epoch: 6| Step: 4
Training loss: 2.7161483593956723
Validation loss: 2.6187451070174514

Epoch: 6| Step: 5
Training loss: 3.0670059686732665
Validation loss: 2.5688820556504517

Epoch: 6| Step: 6
Training loss: 2.5826517764725554
Validation loss: 2.579199407544212

Epoch: 6| Step: 7
Training loss: 2.9964830128280373
Validation loss: 2.594886351961794

Epoch: 6| Step: 8
Training loss: 3.1456008892624645
Validation loss: 2.5991744640562566

Epoch: 6| Step: 9
Training loss: 2.6023576683970897
Validation loss: 2.583600564989086

Epoch: 6| Step: 10
Training loss: 2.055824574345038
Validation loss: 2.58334210130022

Epoch: 6| Step: 11
Training loss: 3.1826432570273195
Validation loss: 2.5752713904773734

Epoch: 6| Step: 12
Training loss: 2.3938666412381275
Validation loss: 2.5580940355390136

Epoch: 6| Step: 13
Training loss: 3.628334747744068
Validation loss: 2.6080432814576193

Epoch: 136| Step: 0
Training loss: 2.538033896217623
Validation loss: 2.600942254755909

Epoch: 6| Step: 1
Training loss: 2.416009901405407
Validation loss: 2.578529520576162

Epoch: 6| Step: 2
Training loss: 2.5042571061528487
Validation loss: 2.595818593281234

Epoch: 6| Step: 3
Training loss: 2.8912212684744154
Validation loss: 2.5974998306747628

Epoch: 6| Step: 4
Training loss: 2.3136055855220627
Validation loss: 2.5679985906872265

Epoch: 6| Step: 5
Training loss: 2.599819573230899
Validation loss: 2.6073669907131767

Epoch: 6| Step: 6
Training loss: 2.6592720343517975
Validation loss: 2.585237911110237

Epoch: 6| Step: 7
Training loss: 2.7278670111427643
Validation loss: 2.596483150842834

Epoch: 6| Step: 8
Training loss: 2.9829299384088883
Validation loss: 2.5842807162598653

Epoch: 6| Step: 9
Training loss: 3.3628600030639872
Validation loss: 2.600945378305569

Epoch: 6| Step: 10
Training loss: 3.120084940903396
Validation loss: 2.617500354309901

Epoch: 6| Step: 11
Training loss: 2.7741913966272858
Validation loss: 2.6312257894169377

Epoch: 6| Step: 12
Training loss: 2.4886809646327883
Validation loss: 2.577309573412123

Epoch: 6| Step: 13
Training loss: 4.111590234370528
Validation loss: 2.5949885957728

Epoch: 137| Step: 0
Training loss: 2.969792393836275
Validation loss: 2.5923511989790824

Epoch: 6| Step: 1
Training loss: 2.8916596081855515
Validation loss: 2.6139089468554086

Epoch: 6| Step: 2
Training loss: 2.82613897403318
Validation loss: 2.5829472185445757

Epoch: 6| Step: 3
Training loss: 3.095069372727705
Validation loss: 2.6028049543030827

Epoch: 6| Step: 4
Training loss: 2.821287710388219
Validation loss: 2.6024372965865736

Epoch: 6| Step: 5
Training loss: 1.973980268559499
Validation loss: 2.6088040951549494

Epoch: 6| Step: 6
Training loss: 3.0968502963685016
Validation loss: 2.5757978260871544

Epoch: 6| Step: 7
Training loss: 2.6741713978539403
Validation loss: 2.569819625325372

Epoch: 6| Step: 8
Training loss: 2.2626761352095177
Validation loss: 2.5906468180151294

Epoch: 6| Step: 9
Training loss: 2.5536533327334228
Validation loss: 2.5431129990925747

Epoch: 6| Step: 10
Training loss: 2.599536003378551
Validation loss: 2.5808077966679597

Epoch: 6| Step: 11
Training loss: 3.0461498473510935
Validation loss: 2.6015222638648847

Epoch: 6| Step: 12
Training loss: 3.073911930269589
Validation loss: 2.565631305371626

Epoch: 6| Step: 13
Training loss: 2.2562387651073945
Validation loss: 2.5889352132157253

Epoch: 138| Step: 0
Training loss: 3.0905114379631655
Validation loss: 2.576760649422971

Epoch: 6| Step: 1
Training loss: 2.5646200946452864
Validation loss: 2.557407669661994

Epoch: 6| Step: 2
Training loss: 2.221157004106114
Validation loss: 2.5956857936975

Epoch: 6| Step: 3
Training loss: 2.534820299268759
Validation loss: 2.6090147042202516

Epoch: 6| Step: 4
Training loss: 2.568846124859955
Validation loss: 2.5932248420691546

Epoch: 6| Step: 5
Training loss: 3.131920590043181
Validation loss: 2.5908599400629395

Epoch: 6| Step: 6
Training loss: 3.0363682274947243
Validation loss: 2.5772538479262024

Epoch: 6| Step: 7
Training loss: 2.7216478009883116
Validation loss: 2.580868795469932

Epoch: 6| Step: 8
Training loss: 2.348375562509705
Validation loss: 2.610432722437111

Epoch: 6| Step: 9
Training loss: 3.4107968841799763
Validation loss: 2.5889389859882748

Epoch: 6| Step: 10
Training loss: 3.2857420191571762
Validation loss: 2.5655252690160584

Epoch: 6| Step: 11
Training loss: 2.314903556676841
Validation loss: 2.619765048867427

Epoch: 6| Step: 12
Training loss: 2.470120592764218
Validation loss: 2.5384302232665505

Epoch: 6| Step: 13
Training loss: 2.51402961894381
Validation loss: 2.5697075889119323

Epoch: 139| Step: 0
Training loss: 2.2772894144528393
Validation loss: 2.599401258497009

Epoch: 6| Step: 1
Training loss: 3.12302275094263
Validation loss: 2.605994209797625

Epoch: 6| Step: 2
Training loss: 2.682506090994512
Validation loss: 2.59280853739018

Epoch: 6| Step: 3
Training loss: 2.9729388750543744
Validation loss: 2.584986661439955

Epoch: 6| Step: 4
Training loss: 2.442498388533905
Validation loss: 2.557229001039919

Epoch: 6| Step: 5
Training loss: 2.5126151328965585
Validation loss: 2.575504633686462

Epoch: 6| Step: 6
Training loss: 2.1694030965635775
Validation loss: 2.606683082468555

Epoch: 6| Step: 7
Training loss: 2.640322515554685
Validation loss: 2.5576186950416284

Epoch: 6| Step: 8
Training loss: 2.4004474381753047
Validation loss: 2.573239282378846

Epoch: 6| Step: 9
Training loss: 3.8765202893223494
Validation loss: 2.5937008142039266

Epoch: 6| Step: 10
Training loss: 2.942035825509945
Validation loss: 2.602734481929399

Epoch: 6| Step: 11
Training loss: 2.9714338518714096
Validation loss: 2.5599414328700116

Epoch: 6| Step: 12
Training loss: 3.0807386426653625
Validation loss: 2.592447771629756

Epoch: 6| Step: 13
Training loss: 2.78475037515879
Validation loss: 2.585537083291186

Epoch: 140| Step: 0
Training loss: 3.350217749507666
Validation loss: 2.5675357786499178

Epoch: 6| Step: 1
Training loss: 3.309564549364265
Validation loss: 2.5841700032289276

Epoch: 6| Step: 2
Training loss: 2.844816573788366
Validation loss: 2.5617374292952637

Epoch: 6| Step: 3
Training loss: 3.019263725717674
Validation loss: 2.576002151003529

Epoch: 6| Step: 4
Training loss: 2.53924635001451
Validation loss: 2.5947472149909854

Epoch: 6| Step: 5
Training loss: 2.968716591094911
Validation loss: 2.5806587027250862

Epoch: 6| Step: 6
Training loss: 2.0931823872045925
Validation loss: 2.6008060198878353

Epoch: 6| Step: 7
Training loss: 2.722357450314024
Validation loss: 2.6494886866636995

Epoch: 6| Step: 8
Training loss: 2.7382072406078195
Validation loss: 2.5795439036460994

Epoch: 6| Step: 9
Training loss: 2.131590105142819
Validation loss: 2.599523533941737

Epoch: 6| Step: 10
Training loss: 2.523506848589948
Validation loss: 2.584642434518121

Epoch: 6| Step: 11
Training loss: 2.996802215169647
Validation loss: 2.6005496018846452

Epoch: 6| Step: 12
Training loss: 2.7350621695138773
Validation loss: 2.6105701896717393

Epoch: 6| Step: 13
Training loss: 2.6795445173280883
Validation loss: 2.5428932258998658

Epoch: 141| Step: 0
Training loss: 2.3712763456772303
Validation loss: 2.572755256948161

Epoch: 6| Step: 1
Training loss: 3.116173753842321
Validation loss: 2.5947920258751993

Epoch: 6| Step: 2
Training loss: 2.314827649681395
Validation loss: 2.6017322454727263

Epoch: 6| Step: 3
Training loss: 2.920562939138571
Validation loss: 2.5760575453015244

Epoch: 6| Step: 4
Training loss: 3.123841643223689
Validation loss: 2.615697752073519

Epoch: 6| Step: 5
Training loss: 3.234762712174905
Validation loss: 2.5765110606008927

Epoch: 6| Step: 6
Training loss: 2.8386427741752644
Validation loss: 2.622825956733718

Epoch: 6| Step: 7
Training loss: 2.197392574457677
Validation loss: 2.636063763122343

Epoch: 6| Step: 8
Training loss: 2.6076671013545454
Validation loss: 2.5965697529303644

Epoch: 6| Step: 9
Training loss: 2.536445466204102
Validation loss: 2.5798898770919054

Epoch: 6| Step: 10
Training loss: 2.807656929066557
Validation loss: 2.558633336626176

Epoch: 6| Step: 11
Training loss: 3.119499859459677
Validation loss: 2.584603772949033

Epoch: 6| Step: 12
Training loss: 2.8487007726723634
Validation loss: 2.5896408240857953

Epoch: 6| Step: 13
Training loss: 2.4880217651936145
Validation loss: 2.562209780445894

Epoch: 142| Step: 0
Training loss: 2.898209966483909
Validation loss: 2.6014938081822705

Epoch: 6| Step: 1
Training loss: 2.9359038866198817
Validation loss: 2.6199279533117363

Epoch: 6| Step: 2
Training loss: 2.42642208363677
Validation loss: 2.5943194111619454

Epoch: 6| Step: 3
Training loss: 3.146051832951917
Validation loss: 2.601130726516196

Epoch: 6| Step: 4
Training loss: 3.138612320530203
Validation loss: 2.6143651509353485

Epoch: 6| Step: 5
Training loss: 3.4198156282575254
Validation loss: 2.5980471752108967

Epoch: 6| Step: 6
Training loss: 2.5682547544340486
Validation loss: 2.5855787183417456

Epoch: 6| Step: 7
Training loss: 2.5752590086216216
Validation loss: 2.585392145133103

Epoch: 6| Step: 8
Training loss: 2.4602124311634994
Validation loss: 2.6111820235390852

Epoch: 6| Step: 9
Training loss: 2.6597769266539153
Validation loss: 2.569123046612098

Epoch: 6| Step: 10
Training loss: 3.0816088484901476
Validation loss: 2.6132683752653807

Epoch: 6| Step: 11
Training loss: 2.502183628110247
Validation loss: 2.575226554497701

Epoch: 6| Step: 12
Training loss: 2.610643272783452
Validation loss: 2.594610300619958

Epoch: 6| Step: 13
Training loss: 2.039700463126526
Validation loss: 2.5919143817407937

Epoch: 143| Step: 0
Training loss: 2.3045569431373565
Validation loss: 2.591777620399278

Epoch: 6| Step: 1
Training loss: 2.52829560598927
Validation loss: 2.621751747342236

Epoch: 6| Step: 2
Training loss: 3.5281158311993353
Validation loss: 2.5791391396028076

Epoch: 6| Step: 3
Training loss: 3.29710177685693
Validation loss: 2.604342573233988

Epoch: 6| Step: 4
Training loss: 2.4161320676011937
Validation loss: 2.573609366018987

Epoch: 6| Step: 5
Training loss: 3.4214159513901197
Validation loss: 2.5608569134018624

Epoch: 6| Step: 6
Training loss: 2.250262668960045
Validation loss: 2.5792621062581036

Epoch: 6| Step: 7
Training loss: 2.763826119260197
Validation loss: 2.569600914142442

Epoch: 6| Step: 8
Training loss: 2.596439851184285
Validation loss: 2.5698981329011663

Epoch: 6| Step: 9
Training loss: 2.6243264378639948
Validation loss: 2.556996805807182

Epoch: 6| Step: 10
Training loss: 3.262407533935708
Validation loss: 2.5730172730016214

Epoch: 6| Step: 11
Training loss: 2.4869581504586216
Validation loss: 2.600674881166424

Epoch: 6| Step: 12
Training loss: 2.470577770566282
Validation loss: 2.5783141423833147

Epoch: 6| Step: 13
Training loss: 2.132699816734831
Validation loss: 2.560919325412059

Epoch: 144| Step: 0
Training loss: 3.0840814730993804
Validation loss: 2.5602932744155273

Epoch: 6| Step: 1
Training loss: 2.594942668950349
Validation loss: 2.593421024631741

Epoch: 6| Step: 2
Training loss: 2.727533031092284
Validation loss: 2.598141182814223

Epoch: 6| Step: 3
Training loss: 2.3105611147727942
Validation loss: 2.570784972853479

Epoch: 6| Step: 4
Training loss: 2.549978787203052
Validation loss: 2.549847474061682

Epoch: 6| Step: 5
Training loss: 3.638957284247391
Validation loss: 2.5244058041243007

Epoch: 6| Step: 6
Training loss: 2.7013581074516617
Validation loss: 2.574762739669747

Epoch: 6| Step: 7
Training loss: 3.1368090472876267
Validation loss: 2.600041186177663

Epoch: 6| Step: 8
Training loss: 2.2882634874294596
Validation loss: 2.5657418486513497

Epoch: 6| Step: 9
Training loss: 2.359949509355347
Validation loss: 2.607028079893328

Epoch: 6| Step: 10
Training loss: 3.0050394329206735
Validation loss: 2.560873768648676

Epoch: 6| Step: 11
Training loss: 2.6620047668368496
Validation loss: 2.6078625690546833

Epoch: 6| Step: 12
Training loss: 2.953277422488393
Validation loss: 2.5798791023632224

Epoch: 6| Step: 13
Training loss: 2.6026471600439924
Validation loss: 2.5907481070046647

Epoch: 145| Step: 0
Training loss: 3.2835065076312455
Validation loss: 2.586474989920508

Epoch: 6| Step: 1
Training loss: 2.4741406075773527
Validation loss: 2.5958214731326867

Epoch: 6| Step: 2
Training loss: 3.8827837630192867
Validation loss: 2.582335775360411

Epoch: 6| Step: 3
Training loss: 2.6838780326135003
Validation loss: 2.6051281741798915

Epoch: 6| Step: 4
Training loss: 2.6023113100978303
Validation loss: 2.5795731580029377

Epoch: 6| Step: 5
Training loss: 2.287026394870632
Validation loss: 2.6120028836956557

Epoch: 6| Step: 6
Training loss: 2.9160533986899537
Validation loss: 2.6076245438588654

Epoch: 6| Step: 7
Training loss: 3.158654533969459
Validation loss: 2.5946715539270677

Epoch: 6| Step: 8
Training loss: 2.7864704642819076
Validation loss: 2.5728178396812127

Epoch: 6| Step: 9
Training loss: 2.452696453007278
Validation loss: 2.598839039331094

Epoch: 6| Step: 10
Training loss: 2.4919639176195005
Validation loss: 2.60939175405927

Epoch: 6| Step: 11
Training loss: 2.7897599574366945
Validation loss: 2.603928196642887

Epoch: 6| Step: 12
Training loss: 2.130150107883644
Validation loss: 2.5865167625115943

Epoch: 6| Step: 13
Training loss: 2.6535479097327084
Validation loss: 2.62468391581963

Epoch: 146| Step: 0
Training loss: 2.315695539421974
Validation loss: 2.5964529159997585

Epoch: 6| Step: 1
Training loss: 2.6811507875809317
Validation loss: 2.607466130827606

Epoch: 6| Step: 2
Training loss: 3.0697618917767207
Validation loss: 2.596473611038458

Epoch: 6| Step: 3
Training loss: 2.9248791922376163
Validation loss: 2.594126203968459

Epoch: 6| Step: 4
Training loss: 2.3051327032917555
Validation loss: 2.595662571862101

Epoch: 6| Step: 5
Training loss: 2.701868636269171
Validation loss: 2.600897624745365

Epoch: 6| Step: 6
Training loss: 3.0773841237395025
Validation loss: 2.5964817290567828

Epoch: 6| Step: 7
Training loss: 2.435860400298012
Validation loss: 2.5562544514691297

Epoch: 6| Step: 8
Training loss: 2.9167356937051383
Validation loss: 2.57573766766211

Epoch: 6| Step: 9
Training loss: 3.1174377493925824
Validation loss: 2.597533502731109

Epoch: 6| Step: 10
Training loss: 2.8871136757828033
Validation loss: 2.6095205119923106

Epoch: 6| Step: 11
Training loss: 2.5648181943058908
Validation loss: 2.581350961379399

Epoch: 6| Step: 12
Training loss: 3.322106879566444
Validation loss: 2.5901126841034445

Epoch: 6| Step: 13
Training loss: 1.8999148299552757
Validation loss: 2.586434773810081

Epoch: 147| Step: 0
Training loss: 2.9913526520768015
Validation loss: 2.543637044679973

Epoch: 6| Step: 1
Training loss: 3.075569292419396
Validation loss: 2.594878368254982

Epoch: 6| Step: 2
Training loss: 2.9439205047406465
Validation loss: 2.577138167591495

Epoch: 6| Step: 3
Training loss: 2.41284978831094
Validation loss: 2.5950986398027776

Epoch: 6| Step: 4
Training loss: 3.5920933097580163
Validation loss: 2.549743711688885

Epoch: 6| Step: 5
Training loss: 3.4044359608797103
Validation loss: 2.5878034382344866

Epoch: 6| Step: 6
Training loss: 2.673336766907476
Validation loss: 2.5738508795162827

Epoch: 6| Step: 7
Training loss: 2.1645601987902787
Validation loss: 2.5715589052431795

Epoch: 6| Step: 8
Training loss: 2.3643036955675276
Validation loss: 2.6252311413360054

Epoch: 6| Step: 9
Training loss: 1.7314824908762252
Validation loss: 2.568259149519871

Epoch: 6| Step: 10
Training loss: 2.8907497069805617
Validation loss: 2.5644749879777855

Epoch: 6| Step: 11
Training loss: 2.373698430036
Validation loss: 2.566256714954886

Epoch: 6| Step: 12
Training loss: 2.477333502385873
Validation loss: 2.5706541770179046

Epoch: 6| Step: 13
Training loss: 3.2067821931020792
Validation loss: 2.5915748261268887

Epoch: 148| Step: 0
Training loss: 3.570215536925262
Validation loss: 2.5595429569212693

Epoch: 6| Step: 1
Training loss: 3.0334488277316147
Validation loss: 2.583528358158353

Epoch: 6| Step: 2
Training loss: 2.6355469763181767
Validation loss: 2.543381357854681

Epoch: 6| Step: 3
Training loss: 3.0268191959861808
Validation loss: 2.584525658508293

Epoch: 6| Step: 4
Training loss: 2.8484464995743735
Validation loss: 2.5764116815940956

Epoch: 6| Step: 5
Training loss: 2.2121260720346476
Validation loss: 2.58533459477986

Epoch: 6| Step: 6
Training loss: 3.55297649412059
Validation loss: 2.6029285738076404

Epoch: 6| Step: 7
Training loss: 2.4736098730060503
Validation loss: 2.5945553547956903

Epoch: 6| Step: 8
Training loss: 2.5288549324322873
Validation loss: 2.579122964339426

Epoch: 6| Step: 9
Training loss: 2.9229854982572974
Validation loss: 2.592159691544208

Epoch: 6| Step: 10
Training loss: 1.9758039986781653
Validation loss: 2.5981986182258647

Epoch: 6| Step: 11
Training loss: 2.583081376699372
Validation loss: 2.587630001046371

Epoch: 6| Step: 12
Training loss: 2.4228819691826873
Validation loss: 2.602834865184941

Epoch: 6| Step: 13
Training loss: 2.1178382914969367
Validation loss: 2.575575944184448

Epoch: 149| Step: 0
Training loss: 2.4681615007318847
Validation loss: 2.5950446141729584

Epoch: 6| Step: 1
Training loss: 3.2634281635890576
Validation loss: 2.6025881039195844

Epoch: 6| Step: 2
Training loss: 2.942256728546516
Validation loss: 2.5945975303573388

Epoch: 6| Step: 3
Training loss: 3.217478973391103
Validation loss: 2.56254464747613

Epoch: 6| Step: 4
Training loss: 2.424927197179555
Validation loss: 2.576921013706622

Epoch: 6| Step: 5
Training loss: 2.5752655818235617
Validation loss: 2.5344588827643184

Epoch: 6| Step: 6
Training loss: 2.22357373332941
Validation loss: 2.5702594754478234

Epoch: 6| Step: 7
Training loss: 3.123378180226318
Validation loss: 2.61082664816015

Epoch: 6| Step: 8
Training loss: 2.673137522666556
Validation loss: 2.5813207543795964

Epoch: 6| Step: 9
Training loss: 3.002960492728173
Validation loss: 2.5952318754285466

Epoch: 6| Step: 10
Training loss: 2.3201049300832666
Validation loss: 2.5890653370255947

Epoch: 6| Step: 11
Training loss: 2.3130442004765395
Validation loss: 2.5547789848650084

Epoch: 6| Step: 12
Training loss: 2.616068586611122
Validation loss: 2.550788405884387

Epoch: 6| Step: 13
Training loss: 3.2407154096390465
Validation loss: 2.553401809523212

Epoch: 150| Step: 0
Training loss: 2.8379581703291694
Validation loss: 2.5529915953649582

Epoch: 6| Step: 1
Training loss: 2.629835942159153
Validation loss: 2.590823013858814

Epoch: 6| Step: 2
Training loss: 2.3541011857459977
Validation loss: 2.605921798079565

Epoch: 6| Step: 3
Training loss: 3.284234860059163
Validation loss: 2.5545860416641264

Epoch: 6| Step: 4
Training loss: 2.6707736416800234
Validation loss: 2.5604304658763946

Epoch: 6| Step: 5
Training loss: 3.2269313499825185
Validation loss: 2.5476393195421214

Epoch: 6| Step: 6
Training loss: 2.842967502125138
Validation loss: 2.5908172845999595

Epoch: 6| Step: 7
Training loss: 1.6867511641907
Validation loss: 2.6080857583986368

Epoch: 6| Step: 8
Training loss: 2.154249064519333
Validation loss: 2.6290640391209195

Epoch: 6| Step: 9
Training loss: 3.2988980852187835
Validation loss: 2.584881930338983

Epoch: 6| Step: 10
Training loss: 3.007118204415102
Validation loss: 2.5839630689850903

Epoch: 6| Step: 11
Training loss: 2.399927527605021
Validation loss: 2.575659948218204

Epoch: 6| Step: 12
Training loss: 2.7386215803854643
Validation loss: 2.5790630345665995

Epoch: 6| Step: 13
Training loss: 3.2093805032625347
Validation loss: 2.575930801050107

Epoch: 151| Step: 0
Training loss: 2.579317868863808
Validation loss: 2.6106130507068825

Epoch: 6| Step: 1
Training loss: 2.3711239154537083
Validation loss: 2.5574502277800737

Epoch: 6| Step: 2
Training loss: 2.7395995010266354
Validation loss: 2.597365516111211

Epoch: 6| Step: 3
Training loss: 3.0328144873367395
Validation loss: 2.593603236502268

Epoch: 6| Step: 4
Training loss: 2.5301648863486776
Validation loss: 2.6080116196494387

Epoch: 6| Step: 5
Training loss: 2.6662682493920347
Validation loss: 2.602673313971111

Epoch: 6| Step: 6
Training loss: 2.6040977977547226
Validation loss: 2.5568948485513445

Epoch: 6| Step: 7
Training loss: 2.7490154584697706
Validation loss: 2.5706040646243085

Epoch: 6| Step: 8
Training loss: 3.1260291884335434
Validation loss: 2.6019351604494187

Epoch: 6| Step: 9
Training loss: 2.6728716324431456
Validation loss: 2.581119121012499

Epoch: 6| Step: 10
Training loss: 2.626430485010089
Validation loss: 2.5692972411744717

Epoch: 6| Step: 11
Training loss: 2.5490187533479296
Validation loss: 2.556742639520517

Epoch: 6| Step: 12
Training loss: 3.486864509245371
Validation loss: 2.5976225746001926

Epoch: 6| Step: 13
Training loss: 2.969732182305189
Validation loss: 2.5735137206523255

Epoch: 152| Step: 0
Training loss: 2.6473949259510596
Validation loss: 2.59664159315976

Epoch: 6| Step: 1
Training loss: 3.2624683363974727
Validation loss: 2.5983193637279487

Epoch: 6| Step: 2
Training loss: 2.7564837575039873
Validation loss: 2.571275078183006

Epoch: 6| Step: 3
Training loss: 3.03279766411275
Validation loss: 2.5701095172260184

Epoch: 6| Step: 4
Training loss: 2.6551523970205193
Validation loss: 2.55175298612455

Epoch: 6| Step: 5
Training loss: 2.509588545552587
Validation loss: 2.6082042985603167

Epoch: 6| Step: 6
Training loss: 2.588954951389832
Validation loss: 2.5908994522402162

Epoch: 6| Step: 7
Training loss: 2.812752352095714
Validation loss: 2.5888251438699443

Epoch: 6| Step: 8
Training loss: 2.4442315683246396
Validation loss: 2.5829967103478353

Epoch: 6| Step: 9
Training loss: 2.912629212226898
Validation loss: 2.568359197327026

Epoch: 6| Step: 10
Training loss: 2.517638543871111
Validation loss: 2.5927806999602767

Epoch: 6| Step: 11
Training loss: 2.604824735782484
Validation loss: 2.603012509120161

Epoch: 6| Step: 12
Training loss: 2.7564742431765796
Validation loss: 2.547313265697763

Epoch: 6| Step: 13
Training loss: 2.8833586219457725
Validation loss: 2.5925263193013808

Epoch: 153| Step: 0
Training loss: 2.687116728665981
Validation loss: 2.576285736907171

Epoch: 6| Step: 1
Training loss: 3.71753089219824
Validation loss: 2.607604562595833

Epoch: 6| Step: 2
Training loss: 3.2035190246884016
Validation loss: 2.5879847519067765

Epoch: 6| Step: 3
Training loss: 2.442923356754677
Validation loss: 2.5903353264399462

Epoch: 6| Step: 4
Training loss: 2.616106681270021
Validation loss: 2.5833366343079858

Epoch: 6| Step: 5
Training loss: 3.3598839662588995
Validation loss: 2.5947886271713827

Epoch: 6| Step: 6
Training loss: 2.298657925510972
Validation loss: 2.602867099172846

Epoch: 6| Step: 7
Training loss: 2.081538444440749
Validation loss: 2.597870251592192

Epoch: 6| Step: 8
Training loss: 2.5244861230950475
Validation loss: 2.6166998746745245

Epoch: 6| Step: 9
Training loss: 2.238309796802034
Validation loss: 2.592232409565905

Epoch: 6| Step: 10
Training loss: 2.3315163304270143
Validation loss: 2.5933464083220836

Epoch: 6| Step: 11
Training loss: 3.068404597405053
Validation loss: 2.583569293272907

Epoch: 6| Step: 12
Training loss: 2.529337501936021
Validation loss: 2.602155385368399

Epoch: 6| Step: 13
Training loss: 3.0121433537629256
Validation loss: 2.584826621013167

Epoch: 154| Step: 0
Training loss: 3.370577422346827
Validation loss: 2.5640645337045336

Epoch: 6| Step: 1
Training loss: 2.4421849344133895
Validation loss: 2.575939382894141

Epoch: 6| Step: 2
Training loss: 3.0414135622945424
Validation loss: 2.5618940808047608

Epoch: 6| Step: 3
Training loss: 2.56948978510079
Validation loss: 2.615609053153463

Epoch: 6| Step: 4
Training loss: 2.414635846343456
Validation loss: 2.604293125814801

Epoch: 6| Step: 5
Training loss: 2.9858212786243157
Validation loss: 2.5748404603082484

Epoch: 6| Step: 6
Training loss: 2.075104088068442
Validation loss: 2.5790822508926325

Epoch: 6| Step: 7
Training loss: 2.880651806611243
Validation loss: 2.6058093728023213

Epoch: 6| Step: 8
Training loss: 2.024453162309338
Validation loss: 2.587837347409774

Epoch: 6| Step: 9
Training loss: 2.9688415513227295
Validation loss: 2.5982786087029686

Epoch: 6| Step: 10
Training loss: 2.8885427862679456
Validation loss: 2.6145105205130914

Epoch: 6| Step: 11
Training loss: 2.8258803084742046
Validation loss: 2.619186503373352

Epoch: 6| Step: 12
Training loss: 3.3494772659808074
Validation loss: 2.5985712618904957

Epoch: 6| Step: 13
Training loss: 2.7341939811733496
Validation loss: 2.573938033923855

Epoch: 155| Step: 0
Training loss: 2.3288669300055207
Validation loss: 2.5769233854193874

Epoch: 6| Step: 1
Training loss: 2.7898383250273233
Validation loss: 2.5600403026275136

Epoch: 6| Step: 2
Training loss: 2.487170296293294
Validation loss: 2.5927658002768066

Epoch: 6| Step: 3
Training loss: 2.737051999435437
Validation loss: 2.5801949006013967

Epoch: 6| Step: 4
Training loss: 2.6155736701696
Validation loss: 2.6118198814420577

Epoch: 6| Step: 5
Training loss: 2.272820772501874
Validation loss: 2.6047500908438126

Epoch: 6| Step: 6
Training loss: 3.301003424937665
Validation loss: 2.6095008031336935

Epoch: 6| Step: 7
Training loss: 2.8726174807117504
Validation loss: 2.572337536057325

Epoch: 6| Step: 8
Training loss: 3.088900686221689
Validation loss: 2.6073590609536765

Epoch: 6| Step: 9
Training loss: 2.4777907926657647
Validation loss: 2.587479560386502

Epoch: 6| Step: 10
Training loss: 2.5308884727476273
Validation loss: 2.6119951765763734

Epoch: 6| Step: 11
Training loss: 2.824962892541826
Validation loss: 2.593873441239387

Epoch: 6| Step: 12
Training loss: 3.254083269119474
Validation loss: 2.57866706009681

Epoch: 6| Step: 13
Training loss: 3.19699089906678
Validation loss: 2.5885323276938523

Epoch: 156| Step: 0
Training loss: 2.8582713180650536
Validation loss: 2.610042383270005

Epoch: 6| Step: 1
Training loss: 2.8359791986431633
Validation loss: 2.5893165523095574

Epoch: 6| Step: 2
Training loss: 2.08859791921709
Validation loss: 2.56488596428131

Epoch: 6| Step: 3
Training loss: 2.8590212743874264
Validation loss: 2.570056208187438

Epoch: 6| Step: 4
Training loss: 2.160540417247909
Validation loss: 2.587314737750028

Epoch: 6| Step: 5
Training loss: 2.70676049754171
Validation loss: 2.612748561283698

Epoch: 6| Step: 6
Training loss: 1.9575217844797146
Validation loss: 2.5995056561127265

Epoch: 6| Step: 7
Training loss: 3.8911980509514694
Validation loss: 2.586733766932296

Epoch: 6| Step: 8
Training loss: 2.373237658708182
Validation loss: 2.585076612885647

Epoch: 6| Step: 9
Training loss: 3.075425876806409
Validation loss: 2.5731305551638712

Epoch: 6| Step: 10
Training loss: 2.507820866175687
Validation loss: 2.5821343056453605

Epoch: 6| Step: 11
Training loss: 2.79042203876384
Validation loss: 2.5928712718592046

Epoch: 6| Step: 12
Training loss: 2.9043423534288118
Validation loss: 2.593019611202018

Epoch: 6| Step: 13
Training loss: 3.135932415253414
Validation loss: 2.5689966637698185

Epoch: 157| Step: 0
Training loss: 3.015961307095301
Validation loss: 2.576842468390169

Epoch: 6| Step: 1
Training loss: 2.4338404253367596
Validation loss: 2.5833339171817475

Epoch: 6| Step: 2
Training loss: 3.3336217914382624
Validation loss: 2.551812038270332

Epoch: 6| Step: 3
Training loss: 3.0647335082255407
Validation loss: 2.5599410773569997

Epoch: 6| Step: 4
Training loss: 2.120978982816788
Validation loss: 2.5530948973872607

Epoch: 6| Step: 5
Training loss: 2.049180690515205
Validation loss: 2.604868914681363

Epoch: 6| Step: 6
Training loss: 2.6907327415524573
Validation loss: 2.5738409520353653

Epoch: 6| Step: 7
Training loss: 2.477107520556182
Validation loss: 2.5805647228635684

Epoch: 6| Step: 8
Training loss: 2.606077932262556
Validation loss: 2.5955720272384157

Epoch: 6| Step: 9
Training loss: 3.1869911834910845
Validation loss: 2.5440395507590012

Epoch: 6| Step: 10
Training loss: 2.7042419242868787
Validation loss: 2.5892885585259897

Epoch: 6| Step: 11
Training loss: 2.920480323896332
Validation loss: 2.5815176946189187

Epoch: 6| Step: 12
Training loss: 2.957017865774284
Validation loss: 2.5904694523047898

Epoch: 6| Step: 13
Training loss: 2.0539823417164538
Validation loss: 2.584942754651649

Epoch: 158| Step: 0
Training loss: 2.4127494920187162
Validation loss: 2.5821575091541633

Epoch: 6| Step: 1
Training loss: 1.978206448437516
Validation loss: 2.5645090796557626

Epoch: 6| Step: 2
Training loss: 2.8750003317127866
Validation loss: 2.5927490089853444

Epoch: 6| Step: 3
Training loss: 2.9273191924906516
Validation loss: 2.5828205741656514

Epoch: 6| Step: 4
Training loss: 2.8729552585664484
Validation loss: 2.583636710811027

Epoch: 6| Step: 5
Training loss: 2.2402084069713335
Validation loss: 2.582160588907618

Epoch: 6| Step: 6
Training loss: 2.9747517201660476
Validation loss: 2.564586756165743

Epoch: 6| Step: 7
Training loss: 2.841141395087524
Validation loss: 2.5706710208815653

Epoch: 6| Step: 8
Training loss: 2.9218123322156577
Validation loss: 2.604992410653734

Epoch: 6| Step: 9
Training loss: 2.2154288351707563
Validation loss: 2.5356396393233016

Epoch: 6| Step: 10
Training loss: 3.4297175308337846
Validation loss: 2.584701232163111

Epoch: 6| Step: 11
Training loss: 2.8285950328067715
Validation loss: 2.560040654121121

Epoch: 6| Step: 12
Training loss: 3.4697786472747776
Validation loss: 2.588206629375444

Epoch: 6| Step: 13
Training loss: 2.7105655469964582
Validation loss: 2.6114251817640866

Epoch: 159| Step: 0
Training loss: 2.3542404388301637
Validation loss: 2.5833896107519445

Epoch: 6| Step: 1
Training loss: 2.784809535035267
Validation loss: 2.57933286113887

Epoch: 6| Step: 2
Training loss: 2.496546075995857
Validation loss: 2.5806324727120766

Epoch: 6| Step: 3
Training loss: 2.75789955585307
Validation loss: 2.5728672473378267

Epoch: 6| Step: 4
Training loss: 3.2706740192725166
Validation loss: 2.5811983367088756

Epoch: 6| Step: 5
Training loss: 2.343904108702973
Validation loss: 2.597617736723351

Epoch: 6| Step: 6
Training loss: 3.1970554811724528
Validation loss: 2.5799877826630024

Epoch: 6| Step: 7
Training loss: 2.1783173879766076
Validation loss: 2.6091184111066315

Epoch: 6| Step: 8
Training loss: 2.729056368241825
Validation loss: 2.621124379389377

Epoch: 6| Step: 9
Training loss: 3.180942447087745
Validation loss: 2.626418842145961

Epoch: 6| Step: 10
Training loss: 2.5279513871190655
Validation loss: 2.599689941360925

Epoch: 6| Step: 11
Training loss: 2.8210142324603136
Validation loss: 2.5719840986956735

Epoch: 6| Step: 12
Training loss: 2.6768243468963298
Validation loss: 2.6038642605992615

Epoch: 6| Step: 13
Training loss: 2.671938622146624
Validation loss: 2.5879280507095457

Epoch: 160| Step: 0
Training loss: 2.7299289852030415
Validation loss: 2.620540268195972

Epoch: 6| Step: 1
Training loss: 3.0922949866242964
Validation loss: 2.6008961748165444

Epoch: 6| Step: 2
Training loss: 2.550108465991981
Validation loss: 2.5910885199391243

Epoch: 6| Step: 3
Training loss: 2.6846365644675942
Validation loss: 2.594960341112468

Epoch: 6| Step: 4
Training loss: 3.148876377309086
Validation loss: 2.570533755635333

Epoch: 6| Step: 5
Training loss: 2.5923026769250392
Validation loss: 2.596583580285267

Epoch: 6| Step: 6
Training loss: 2.5874491073837147
Validation loss: 2.6026416715471643

Epoch: 6| Step: 7
Training loss: 2.6113924918733584
Validation loss: 2.5912980045119314

Epoch: 6| Step: 8
Training loss: 3.663070316632249
Validation loss: 2.5967685161768763

Epoch: 6| Step: 9
Training loss: 2.5379123371517176
Validation loss: 2.593390878643693

Epoch: 6| Step: 10
Training loss: 2.8327157712603412
Validation loss: 2.60476412476341

Epoch: 6| Step: 11
Training loss: 2.135829928967574
Validation loss: 2.623727956103341

Epoch: 6| Step: 12
Training loss: 2.014606425466282
Validation loss: 2.5835212393732236

Epoch: 6| Step: 13
Training loss: 2.6470779034917995
Validation loss: 2.5619950586101465

Epoch: 161| Step: 0
Training loss: 3.66869278039453
Validation loss: 2.6178227253243764

Epoch: 6| Step: 1
Training loss: 2.349144183219644
Validation loss: 2.5764931663740853

Epoch: 6| Step: 2
Training loss: 3.363879497279413
Validation loss: 2.5967680432876032

Epoch: 6| Step: 3
Training loss: 3.574801838324549
Validation loss: 2.5731468727087052

Epoch: 6| Step: 4
Training loss: 2.2720679913475097
Validation loss: 2.5909513696839124

Epoch: 6| Step: 5
Training loss: 2.5796362868920393
Validation loss: 2.591482052339004

Epoch: 6| Step: 6
Training loss: 2.6343027306324216
Validation loss: 2.58450848039442

Epoch: 6| Step: 7
Training loss: 2.786252612544427
Validation loss: 2.566822929630308

Epoch: 6| Step: 8
Training loss: 2.3808189182114368
Validation loss: 2.577631767277564

Epoch: 6| Step: 9
Training loss: 2.6051673085672333
Validation loss: 2.595050472404345

Epoch: 6| Step: 10
Training loss: 2.501350514891095
Validation loss: 2.5914622700999526

Epoch: 6| Step: 11
Training loss: 2.4001215387405526
Validation loss: 2.59788642262626

Epoch: 6| Step: 12
Training loss: 2.530092516327084
Validation loss: 2.5586579525878532

Epoch: 6| Step: 13
Training loss: 2.191536041060881
Validation loss: 2.5983599247326503

Epoch: 162| Step: 0
Training loss: 2.7946783208925576
Validation loss: 2.5814280104456824

Epoch: 6| Step: 1
Training loss: 2.8900144189917083
Validation loss: 2.5494749743382843

Epoch: 6| Step: 2
Training loss: 2.756411447792046
Validation loss: 2.541054659193012

Epoch: 6| Step: 3
Training loss: 2.6882436743595948
Validation loss: 2.594064297384016

Epoch: 6| Step: 4
Training loss: 3.4530106607554827
Validation loss: 2.568721522837141

Epoch: 6| Step: 5
Training loss: 2.7355909859013603
Validation loss: 2.602958421220592

Epoch: 6| Step: 6
Training loss: 2.0361797665824106
Validation loss: 2.6293387810603583

Epoch: 6| Step: 7
Training loss: 2.7535943903097304
Validation loss: 2.5359405290910826

Epoch: 6| Step: 8
Training loss: 2.587536090101571
Validation loss: 2.581702237104979

Epoch: 6| Step: 9
Training loss: 3.054239771975474
Validation loss: 2.6034706590088357

Epoch: 6| Step: 10
Training loss: 2.748572065519299
Validation loss: 2.5644913326062233

Epoch: 6| Step: 11
Training loss: 1.6337565198212216
Validation loss: 2.59411512172911

Epoch: 6| Step: 12
Training loss: 3.333542547018226
Validation loss: 2.574774378150916

Epoch: 6| Step: 13
Training loss: 2.4450498202188133
Validation loss: 2.5877458226251804

Epoch: 163| Step: 0
Training loss: 2.6531098597872997
Validation loss: 2.5918074839607663

Epoch: 6| Step: 1
Training loss: 2.0202642471911947
Validation loss: 2.5818246298902165

Epoch: 6| Step: 2
Training loss: 2.587916052351497
Validation loss: 2.540987794232841

Epoch: 6| Step: 3
Training loss: 3.49492959187633
Validation loss: 2.6024266969731076

Epoch: 6| Step: 4
Training loss: 3.7173100095735077
Validation loss: 2.586004176226847

Epoch: 6| Step: 5
Training loss: 2.682171173846022
Validation loss: 2.574055312168723

Epoch: 6| Step: 6
Training loss: 3.078767815870188
Validation loss: 2.5861248378137427

Epoch: 6| Step: 7
Training loss: 2.7366136378804824
Validation loss: 2.5982179002311163

Epoch: 6| Step: 8
Training loss: 2.743135293909533
Validation loss: 2.603691787901182

Epoch: 6| Step: 9
Training loss: 2.9090438047843654
Validation loss: 2.573382874726634

Epoch: 6| Step: 10
Training loss: 2.8253532863930713
Validation loss: 2.599866068650649

Epoch: 6| Step: 11
Training loss: 1.8253147010678927
Validation loss: 2.606195434493296

Epoch: 6| Step: 12
Training loss: 2.1215734343360055
Validation loss: 2.607729087098243

Epoch: 6| Step: 13
Training loss: 2.2580328705103963
Validation loss: 2.558281619526081

Epoch: 164| Step: 0
Training loss: 3.1356872914943326
Validation loss: 2.5727192168298094

Epoch: 6| Step: 1
Training loss: 2.841108331802846
Validation loss: 2.580269039788412

Epoch: 6| Step: 2
Training loss: 2.5885297338772264
Validation loss: 2.5863627462183034

Epoch: 6| Step: 3
Training loss: 2.6936577624042544
Validation loss: 2.5951449313490347

Epoch: 6| Step: 4
Training loss: 2.635231604631059
Validation loss: 2.5974279737160155

Epoch: 6| Step: 5
Training loss: 2.951123401943079
Validation loss: 2.5901210269420583

Epoch: 6| Step: 6
Training loss: 2.2812293064798803
Validation loss: 2.604248040353302

Epoch: 6| Step: 7
Training loss: 2.8455975577750676
Validation loss: 2.565721211482938

Epoch: 6| Step: 8
Training loss: 3.175170239067207
Validation loss: 2.5621721091434786

Epoch: 6| Step: 9
Training loss: 2.5916649584340377
Validation loss: 2.5423210413869737

Epoch: 6| Step: 10
Training loss: 2.17742299133143
Validation loss: 2.5828421883673696

Epoch: 6| Step: 11
Training loss: 2.599492621433171
Validation loss: 2.5991072646062796

Epoch: 6| Step: 12
Training loss: 3.091165869802419
Validation loss: 2.581549543330172

Epoch: 6| Step: 13
Training loss: 2.2574947357961253
Validation loss: 2.587729570388842

Epoch: 165| Step: 0
Training loss: 2.516726803429523
Validation loss: 2.579415882614255

Epoch: 6| Step: 1
Training loss: 2.5702127825748557
Validation loss: 2.5956247184028327

Epoch: 6| Step: 2
Training loss: 2.56128738368591
Validation loss: 2.569495356383413

Epoch: 6| Step: 3
Training loss: 2.399786951622475
Validation loss: 2.564386380284416

Epoch: 6| Step: 4
Training loss: 2.7713852717482084
Validation loss: 2.5923643135733956

Epoch: 6| Step: 5
Training loss: 3.026571221996338
Validation loss: 2.598110389040732

Epoch: 6| Step: 6
Training loss: 2.4337218910635605
Validation loss: 2.582762958570672

Epoch: 6| Step: 7
Training loss: 3.7113283614060286
Validation loss: 2.583265212037788

Epoch: 6| Step: 8
Training loss: 2.7512128062942676
Validation loss: 2.5684511833699344

Epoch: 6| Step: 9
Training loss: 2.637309052122536
Validation loss: 2.5853319868472986

Epoch: 6| Step: 10
Training loss: 2.5543018481609714
Validation loss: 2.584998550419393

Epoch: 6| Step: 11
Training loss: 2.5908795755095375
Validation loss: 2.597091585059204

Epoch: 6| Step: 12
Training loss: 2.5932897136357282
Validation loss: 2.5870652465522084

Epoch: 6| Step: 13
Training loss: 2.9342536031781017
Validation loss: 2.604444612170292

Epoch: 166| Step: 0
Training loss: 2.4180081908132247
Validation loss: 2.5874926397302054

Epoch: 6| Step: 1
Training loss: 2.9736866913222335
Validation loss: 2.57358358513845

Epoch: 6| Step: 2
Training loss: 2.514951248454827
Validation loss: 2.595297180850871

Epoch: 6| Step: 3
Training loss: 2.6698621339958133
Validation loss: 2.5778000294606978

Epoch: 6| Step: 4
Training loss: 2.3012920648065305
Validation loss: 2.5553593016450584

Epoch: 6| Step: 5
Training loss: 2.360711533887194
Validation loss: 2.598919251771381

Epoch: 6| Step: 6
Training loss: 3.2225440913247763
Validation loss: 2.5897117398839753

Epoch: 6| Step: 7
Training loss: 3.3629077876819857
Validation loss: 2.5954453015365573

Epoch: 6| Step: 8
Training loss: 2.507336532725969
Validation loss: 2.5704836987396784

Epoch: 6| Step: 9
Training loss: 2.4128764674108085
Validation loss: 2.5743250412168583

Epoch: 6| Step: 10
Training loss: 2.875870780100429
Validation loss: 2.58660751112855

Epoch: 6| Step: 11
Training loss: 3.406429461030073
Validation loss: 2.5760114829890193

Epoch: 6| Step: 12
Training loss: 2.3544008481738694
Validation loss: 2.617264898212093

Epoch: 6| Step: 13
Training loss: 2.0042792079149128
Validation loss: 2.5646103553477624

Epoch: 167| Step: 0
Training loss: 2.7389552528985157
Validation loss: 2.6104010483630433

Epoch: 6| Step: 1
Training loss: 2.596319832888872
Validation loss: 2.557247865149426

Epoch: 6| Step: 2
Training loss: 2.4104442949835514
Validation loss: 2.5738513167747707

Epoch: 6| Step: 3
Training loss: 3.133314744069033
Validation loss: 2.5757206847430334

Epoch: 6| Step: 4
Training loss: 2.2509350423231456
Validation loss: 2.577969838952047

Epoch: 6| Step: 5
Training loss: 2.8224636338410933
Validation loss: 2.590162585339652

Epoch: 6| Step: 6
Training loss: 2.8610666409424255
Validation loss: 2.631843552911434

Epoch: 6| Step: 7
Training loss: 2.51529999523109
Validation loss: 2.6067500895718037

Epoch: 6| Step: 8
Training loss: 3.1404271609115093
Validation loss: 2.591852171091542

Epoch: 6| Step: 9
Training loss: 2.6608099001330396
Validation loss: 2.5624159057048344

Epoch: 6| Step: 10
Training loss: 3.1012531577866453
Validation loss: 2.5625451216788133

Epoch: 6| Step: 11
Training loss: 2.9806047361056627
Validation loss: 2.578379571054379

Epoch: 6| Step: 12
Training loss: 2.876691569385911
Validation loss: 2.5763665500245083

Epoch: 6| Step: 13
Training loss: 1.6937399043947137
Validation loss: 2.5743545689848446

Epoch: 168| Step: 0
Training loss: 1.9909558846123778
Validation loss: 2.578118235211588

Epoch: 6| Step: 1
Training loss: 2.5628839530794023
Validation loss: 2.608017155824441

Epoch: 6| Step: 2
Training loss: 3.1505306281371976
Validation loss: 2.5875949458371625

Epoch: 6| Step: 3
Training loss: 2.6190393984446794
Validation loss: 2.5698719426941126

Epoch: 6| Step: 4
Training loss: 2.5814452090584075
Validation loss: 2.607198614074884

Epoch: 6| Step: 5
Training loss: 3.227363099165097
Validation loss: 2.579478166595982

Epoch: 6| Step: 6
Training loss: 3.3884520709512462
Validation loss: 2.571585189923424

Epoch: 6| Step: 7
Training loss: 2.5701976622926095
Validation loss: 2.5793392122553693

Epoch: 6| Step: 8
Training loss: 2.3691054024715785
Validation loss: 2.6049898981789674

Epoch: 6| Step: 9
Training loss: 2.5755105373586913
Validation loss: 2.5565161350581067

Epoch: 6| Step: 10
Training loss: 2.85742487877918
Validation loss: 2.588035381631214

Epoch: 6| Step: 11
Training loss: 2.3820957794407005
Validation loss: 2.5816314031722714

Epoch: 6| Step: 12
Training loss: 3.1662501178294153
Validation loss: 2.581193267422077

Epoch: 6| Step: 13
Training loss: 2.598166784152847
Validation loss: 2.596710103333927

Epoch: 169| Step: 0
Training loss: 2.8182572672132755
Validation loss: 2.5971859648337645

Epoch: 6| Step: 1
Training loss: 2.2885084295369698
Validation loss: 2.58631081001422

Epoch: 6| Step: 2
Training loss: 2.6676945692067515
Validation loss: 2.602051762054752

Epoch: 6| Step: 3
Training loss: 2.698225398914021
Validation loss: 2.606181128916825

Epoch: 6| Step: 4
Training loss: 3.027039110176169
Validation loss: 2.5768707396474153

Epoch: 6| Step: 5
Training loss: 2.1932819790997575
Validation loss: 2.5786878859443982

Epoch: 6| Step: 6
Training loss: 2.605759634454508
Validation loss: 2.5908745043857233

Epoch: 6| Step: 7
Training loss: 2.5041817976187155
Validation loss: 2.5764596581449277

Epoch: 6| Step: 8
Training loss: 2.4394146173276763
Validation loss: 2.606863539322691

Epoch: 6| Step: 9
Training loss: 3.3667821795094937
Validation loss: 2.5872729919147046

Epoch: 6| Step: 10
Training loss: 2.5373612088736746
Validation loss: 2.560488921407483

Epoch: 6| Step: 11
Training loss: 3.219295122225419
Validation loss: 2.5637749562315006

Epoch: 6| Step: 12
Training loss: 2.6722663458946
Validation loss: 2.565063710776249

Epoch: 6| Step: 13
Training loss: 3.0334790086524515
Validation loss: 2.6148484811414323

Epoch: 170| Step: 0
Training loss: 2.3075889814915524
Validation loss: 2.582154036236287

Epoch: 6| Step: 1
Training loss: 2.4049181534447417
Validation loss: 2.615356378749021

Epoch: 6| Step: 2
Training loss: 3.062018220335248
Validation loss: 2.6146010583867425

Epoch: 6| Step: 3
Training loss: 3.103960546695053
Validation loss: 2.621176621449069

Epoch: 6| Step: 4
Training loss: 3.0250096533755286
Validation loss: 2.580266853965267

Epoch: 6| Step: 5
Training loss: 3.2422269152348124
Validation loss: 2.6053808777098784

Epoch: 6| Step: 6
Training loss: 1.6987795207284513
Validation loss: 2.593324133333157

Epoch: 6| Step: 7
Training loss: 3.5722281160465843
Validation loss: 2.5825577113041103

Epoch: 6| Step: 8
Training loss: 2.123013521579945
Validation loss: 2.570499857556419

Epoch: 6| Step: 9
Training loss: 2.4363257685349153
Validation loss: 2.5733881576452653

Epoch: 6| Step: 10
Training loss: 2.6230672351220248
Validation loss: 2.643067247680958

Epoch: 6| Step: 11
Training loss: 2.6127675553712923
Validation loss: 2.597839397370719

Epoch: 6| Step: 12
Training loss: 2.7733503301111875
Validation loss: 2.5983954286584634

Epoch: 6| Step: 13
Training loss: 2.416514413794972
Validation loss: 2.5760955389987537

Epoch: 171| Step: 0
Training loss: 2.759977447307053
Validation loss: 2.559503004751105

Epoch: 6| Step: 1
Training loss: 2.7860980695235638
Validation loss: 2.563232155207524

Epoch: 6| Step: 2
Training loss: 3.137938000019722
Validation loss: 2.5533790916906742

Epoch: 6| Step: 3
Training loss: 2.6253895243509167
Validation loss: 2.581822088912205

Epoch: 6| Step: 4
Training loss: 2.463688357437036
Validation loss: 2.581516727363706

Epoch: 6| Step: 5
Training loss: 2.8654237566289757
Validation loss: 2.584501548807652

Epoch: 6| Step: 6
Training loss: 3.3774128518766378
Validation loss: 2.573917347930015

Epoch: 6| Step: 7
Training loss: 2.73094074933965
Validation loss: 2.548733425082362

Epoch: 6| Step: 8
Training loss: 2.551196591735458
Validation loss: 2.576525460268788

Epoch: 6| Step: 9
Training loss: 2.779742142910561
Validation loss: 2.5910242690428715

Epoch: 6| Step: 10
Training loss: 1.8002364188806246
Validation loss: 2.5589141597486713

Epoch: 6| Step: 11
Training loss: 3.061953593185849
Validation loss: 2.5922801694643804

Epoch: 6| Step: 12
Training loss: 2.6216298221716032
Validation loss: 2.569442094467169

Epoch: 6| Step: 13
Training loss: 2.0610268851816684
Validation loss: 2.5682392672615566

Epoch: 172| Step: 0
Training loss: 3.772914305246851
Validation loss: 2.6125226164232016

Epoch: 6| Step: 1
Training loss: 2.8710974038029473
Validation loss: 2.552045795163765

Epoch: 6| Step: 2
Training loss: 2.8522085633706458
Validation loss: 2.5423681305546095

Epoch: 6| Step: 3
Training loss: 1.7815781675839861
Validation loss: 2.6210623074581885

Epoch: 6| Step: 4
Training loss: 2.3548349315353407
Validation loss: 2.5675336688546295

Epoch: 6| Step: 5
Training loss: 2.500798098010745
Validation loss: 2.5707350784134544

Epoch: 6| Step: 6
Training loss: 2.400522723493427
Validation loss: 2.5920211193367395

Epoch: 6| Step: 7
Training loss: 3.235264457729877
Validation loss: 2.5920456714182247

Epoch: 6| Step: 8
Training loss: 2.442262740388679
Validation loss: 2.609382313519194

Epoch: 6| Step: 9
Training loss: 2.694226740096457
Validation loss: 2.5767520902123895

Epoch: 6| Step: 10
Training loss: 2.2150056433336687
Validation loss: 2.609992720679011

Epoch: 6| Step: 11
Training loss: 2.9955610177147203
Validation loss: 2.5865845675702333

Epoch: 6| Step: 12
Training loss: 2.382074760922918
Validation loss: 2.618291274796697

Epoch: 6| Step: 13
Training loss: 2.9346512312054935
Validation loss: 2.5963509105478835

Epoch: 173| Step: 0
Training loss: 3.083289137514933
Validation loss: 2.583221995494605

Epoch: 6| Step: 1
Training loss: 2.3739121605965177
Validation loss: 2.5759826260756404

Epoch: 6| Step: 2
Training loss: 2.2911427910546007
Validation loss: 2.5932029347838608

Epoch: 6| Step: 3
Training loss: 2.952830950917242
Validation loss: 2.5946663281754865

Epoch: 6| Step: 4
Training loss: 2.2118672818590617
Validation loss: 2.608841317147752

Epoch: 6| Step: 5
Training loss: 2.6464980684608834
Validation loss: 2.5706484297347307

Epoch: 6| Step: 6
Training loss: 2.3203670610890974
Validation loss: 2.597231133403505

Epoch: 6| Step: 7
Training loss: 2.388753919213961
Validation loss: 2.5611991872103

Epoch: 6| Step: 8
Training loss: 3.37372649855624
Validation loss: 2.5933042939694415

Epoch: 6| Step: 9
Training loss: 2.6987350184990824
Validation loss: 2.6040968999233645

Epoch: 6| Step: 10
Training loss: 2.9487540377871824
Validation loss: 2.6216514796901325

Epoch: 6| Step: 11
Training loss: 2.7224585134324526
Validation loss: 2.566889041711708

Epoch: 6| Step: 12
Training loss: 3.1400123112431104
Validation loss: 2.562983835614891

Epoch: 6| Step: 13
Training loss: 2.27973636943475
Validation loss: 2.609299729688459

Epoch: 174| Step: 0
Training loss: 1.9846557058203171
Validation loss: 2.5814870779356984

Epoch: 6| Step: 1
Training loss: 2.7181973827458084
Validation loss: 2.5701022585317395

Epoch: 6| Step: 2
Training loss: 3.201857302019426
Validation loss: 2.598318678990399

Epoch: 6| Step: 3
Training loss: 2.521543754747177
Validation loss: 2.575452485487148

Epoch: 6| Step: 4
Training loss: 2.618136014862822
Validation loss: 2.5925559171384767

Epoch: 6| Step: 5
Training loss: 3.0781978075740537
Validation loss: 2.5778038036126794

Epoch: 6| Step: 6
Training loss: 2.230129449961689
Validation loss: 2.5851836159424866

Epoch: 6| Step: 7
Training loss: 2.2904928380041896
Validation loss: 2.5611303672468204

Epoch: 6| Step: 8
Training loss: 2.5516184999822964
Validation loss: 2.5678258230549025

Epoch: 6| Step: 9
Training loss: 2.9895478001697033
Validation loss: 2.595552678167492

Epoch: 6| Step: 10
Training loss: 2.311906790039092
Validation loss: 2.578633983755825

Epoch: 6| Step: 11
Training loss: 3.134343332147788
Validation loss: 2.605858169689108

Epoch: 6| Step: 12
Training loss: 3.2786514892206147
Validation loss: 2.610938633527192

Epoch: 6| Step: 13
Training loss: 3.282753736068974
Validation loss: 2.5703825188201144

Epoch: 175| Step: 0
Training loss: 2.499708921653312
Validation loss: 2.582669595272098

Epoch: 6| Step: 1
Training loss: 2.7914700415150047
Validation loss: 2.5799267625338564

Epoch: 6| Step: 2
Training loss: 1.7167175066311442
Validation loss: 2.565002853835572

Epoch: 6| Step: 3
Training loss: 2.989659608583444
Validation loss: 2.5971462788195034

Epoch: 6| Step: 4
Training loss: 2.1486373530980454
Validation loss: 2.6214320608762534

Epoch: 6| Step: 5
Training loss: 2.5259343599684336
Validation loss: 2.5879887330986215

Epoch: 6| Step: 6
Training loss: 3.0813937573430903
Validation loss: 2.5762135509465525

Epoch: 6| Step: 7
Training loss: 2.536113070593647
Validation loss: 2.5690148686710015

Epoch: 6| Step: 8
Training loss: 2.214457483265468
Validation loss: 2.537505263504897

Epoch: 6| Step: 9
Training loss: 2.4124593504015954
Validation loss: 2.570357471567229

Epoch: 6| Step: 10
Training loss: 4.148951496818108
Validation loss: 2.571475772665353

Epoch: 6| Step: 11
Training loss: 3.0202016937406717
Validation loss: 2.559807293804861

Epoch: 6| Step: 12
Training loss: 2.498497416032513
Validation loss: 2.591000351408502

Epoch: 6| Step: 13
Training loss: 2.586954521879483
Validation loss: 2.6111991989720407

Epoch: 176| Step: 0
Training loss: 2.3720581506674123
Validation loss: 2.5901636325060573

Epoch: 6| Step: 1
Training loss: 2.668941739272215
Validation loss: 2.5314883625398132

Epoch: 6| Step: 2
Training loss: 3.329482683660616
Validation loss: 2.592647605842711

Epoch: 6| Step: 3
Training loss: 2.0880171449330054
Validation loss: 2.573194539512261

Epoch: 6| Step: 4
Training loss: 3.053384722592316
Validation loss: 2.5780385589278283

Epoch: 6| Step: 5
Training loss: 2.455785389995198
Validation loss: 2.5783550041770664

Epoch: 6| Step: 6
Training loss: 2.667613953978067
Validation loss: 2.595501540219523

Epoch: 6| Step: 7
Training loss: 2.9404593636932392
Validation loss: 2.599208221926614

Epoch: 6| Step: 8
Training loss: 2.6951240805405003
Validation loss: 2.5700852692965928

Epoch: 6| Step: 9
Training loss: 2.8134809690611102
Validation loss: 2.60241348482941

Epoch: 6| Step: 10
Training loss: 2.593147943321192
Validation loss: 2.605371702579516

Epoch: 6| Step: 11
Training loss: 1.827210809080417
Validation loss: 2.600570192359032

Epoch: 6| Step: 12
Training loss: 3.059390610995028
Validation loss: 2.5748738074072683

Epoch: 6| Step: 13
Training loss: 2.9639777123646747
Validation loss: 2.60172450250912

Epoch: 177| Step: 0
Training loss: 2.0642048118905567
Validation loss: 2.532466578345701

Epoch: 6| Step: 1
Training loss: 2.6814988134219
Validation loss: 2.6030590322058997

Epoch: 6| Step: 2
Training loss: 2.8612224676524916
Validation loss: 2.6029371513420885

Epoch: 6| Step: 3
Training loss: 2.452750790962245
Validation loss: 2.559945604886624

Epoch: 6| Step: 4
Training loss: 3.0444081810913106
Validation loss: 2.6035684064908127

Epoch: 6| Step: 5
Training loss: 2.599722546665531
Validation loss: 2.635383018840786

Epoch: 6| Step: 6
Training loss: 2.3981956335129
Validation loss: 2.5570779708664944

Epoch: 6| Step: 7
Training loss: 3.106992489287866
Validation loss: 2.5884687061384817

Epoch: 6| Step: 8
Training loss: 2.365662338385462
Validation loss: 2.614302154614458

Epoch: 6| Step: 9
Training loss: 3.1078895586144824
Validation loss: 2.588140501193485

Epoch: 6| Step: 10
Training loss: 2.7294430095357307
Validation loss: 2.5962062038212297

Epoch: 6| Step: 11
Training loss: 2.692408846956554
Validation loss: 2.589363053162632

Epoch: 6| Step: 12
Training loss: 2.847611205865883
Validation loss: 2.61638099660844

Epoch: 6| Step: 13
Training loss: 2.67963874260945
Validation loss: 2.6261381581455505

Epoch: 178| Step: 0
Training loss: 3.2194362760595077
Validation loss: 2.5550526341744018

Epoch: 6| Step: 1
Training loss: 2.7747861350188368
Validation loss: 2.5806573546734253

Epoch: 6| Step: 2
Training loss: 2.193083693995099
Validation loss: 2.594613842826432

Epoch: 6| Step: 3
Training loss: 2.4941982659928597
Validation loss: 2.5854589038417917

Epoch: 6| Step: 4
Training loss: 3.175435290196694
Validation loss: 2.5659306699358195

Epoch: 6| Step: 5
Training loss: 2.7015266764677692
Validation loss: 2.594327898579996

Epoch: 6| Step: 6
Training loss: 2.3138810235365956
Validation loss: 2.594615690502646

Epoch: 6| Step: 7
Training loss: 2.377211695377825
Validation loss: 2.601842122520436

Epoch: 6| Step: 8
Training loss: 2.9809521924228743
Validation loss: 2.5563675387942526

Epoch: 6| Step: 9
Training loss: 3.122821658985759
Validation loss: 2.5985600180674138

Epoch: 6| Step: 10
Training loss: 3.0672988661507294
Validation loss: 2.5573391932611615

Epoch: 6| Step: 11
Training loss: 2.5503617273213512
Validation loss: 2.5585180217999564

Epoch: 6| Step: 12
Training loss: 2.1820556464437946
Validation loss: 2.5804911048023205

Epoch: 6| Step: 13
Training loss: 2.7279578193748395
Validation loss: 2.570979830420275

Epoch: 179| Step: 0
Training loss: 3.3743884627527096
Validation loss: 2.5677092532069494

Epoch: 6| Step: 1
Training loss: 2.4842593568002043
Validation loss: 2.5429672781311807

Epoch: 6| Step: 2
Training loss: 2.6861473050375237
Validation loss: 2.5831265189765165

Epoch: 6| Step: 3
Training loss: 2.862226221576737
Validation loss: 2.5940181792697437

Epoch: 6| Step: 4
Training loss: 2.605928806483018
Validation loss: 2.5575677628971043

Epoch: 6| Step: 5
Training loss: 2.5646422200966064
Validation loss: 2.603407751598505

Epoch: 6| Step: 6
Training loss: 2.3375858882689595
Validation loss: 2.5894363823616766

Epoch: 6| Step: 7
Training loss: 2.273310706938667
Validation loss: 2.5668709885234584

Epoch: 6| Step: 8
Training loss: 2.715924779150899
Validation loss: 2.574981463427618

Epoch: 6| Step: 9
Training loss: 2.668545617311033
Validation loss: 2.559678845521781

Epoch: 6| Step: 10
Training loss: 2.818955367022878
Validation loss: 2.5880625311417993

Epoch: 6| Step: 11
Training loss: 2.558611268427622
Validation loss: 2.597550903621839

Epoch: 6| Step: 12
Training loss: 3.1075678035247143
Validation loss: 2.576989244344791

Epoch: 6| Step: 13
Training loss: 2.1453811267786858
Validation loss: 2.5699293385425253

Epoch: 180| Step: 0
Training loss: 3.062656943523211
Validation loss: 2.578840158659693

Epoch: 6| Step: 1
Training loss: 3.6632356341046535
Validation loss: 2.5884443929885657

Epoch: 6| Step: 2
Training loss: 2.4477558056078057
Validation loss: 2.5852806348301725

Epoch: 6| Step: 3
Training loss: 2.5977695067533
Validation loss: 2.605976997108445

Epoch: 6| Step: 4
Training loss: 2.33127457756607
Validation loss: 2.585379138456779

Epoch: 6| Step: 5
Training loss: 2.950007655246953
Validation loss: 2.6141435480206803

Epoch: 6| Step: 6
Training loss: 2.6869667766236334
Validation loss: 2.594689525333877

Epoch: 6| Step: 7
Training loss: 2.1512869509549675
Validation loss: 2.609621127367309

Epoch: 6| Step: 8
Training loss: 2.5788031408665653
Validation loss: 2.6167769532338188

Epoch: 6| Step: 9
Training loss: 2.3288241367138935
Validation loss: 2.5825988270815365

Epoch: 6| Step: 10
Training loss: 2.774080959412064
Validation loss: 2.5541660468694563

Epoch: 6| Step: 11
Training loss: 2.8035512338593036
Validation loss: 2.59993899512839

Epoch: 6| Step: 12
Training loss: 2.6551092952207958
Validation loss: 2.565798333732731

Epoch: 6| Step: 13
Training loss: 2.920436892812009
Validation loss: 2.5371636541634848

Epoch: 181| Step: 0
Training loss: 2.235242021842314
Validation loss: 2.5740624899990565

Epoch: 6| Step: 1
Training loss: 2.5102698149934763
Validation loss: 2.581654354008291

Epoch: 6| Step: 2
Training loss: 3.385225981208294
Validation loss: 2.5882010468635843

Epoch: 6| Step: 3
Training loss: 2.5922349848430577
Validation loss: 2.596142089455328

Epoch: 6| Step: 4
Training loss: 2.5168777095229724
Validation loss: 2.603398750211939

Epoch: 6| Step: 5
Training loss: 2.5252779930352527
Validation loss: 2.619560306995996

Epoch: 6| Step: 6
Training loss: 2.6067699288828092
Validation loss: 2.55790099160799

Epoch: 6| Step: 7
Training loss: 1.8484450223226323
Validation loss: 2.5775083906398124

Epoch: 6| Step: 8
Training loss: 2.6878433008273093
Validation loss: 2.5517436618708556

Epoch: 6| Step: 9
Training loss: 2.922814855526689
Validation loss: 2.5718519473809236

Epoch: 6| Step: 10
Training loss: 3.439747994307615
Validation loss: 2.5582604652179883

Epoch: 6| Step: 11
Training loss: 2.776873112758808
Validation loss: 2.6005789107546526

Epoch: 6| Step: 12
Training loss: 2.828294106164413
Validation loss: 2.567021099978501

Epoch: 6| Step: 13
Training loss: 2.6164762071270893
Validation loss: 2.5685251495090107

Epoch: 182| Step: 0
Training loss: 2.439260971527901
Validation loss: 2.561207245872191

Epoch: 6| Step: 1
Training loss: 3.0762065970262613
Validation loss: 2.6031825647992775

Epoch: 6| Step: 2
Training loss: 2.853343167273192
Validation loss: 2.579851033004891

Epoch: 6| Step: 3
Training loss: 1.9795996209129392
Validation loss: 2.557628423876005

Epoch: 6| Step: 4
Training loss: 2.9138658063435128
Validation loss: 2.588854580523267

Epoch: 6| Step: 5
Training loss: 2.7552499076913164
Validation loss: 2.576212296100413

Epoch: 6| Step: 6
Training loss: 2.6378343270823112
Validation loss: 2.6036824674947487

Epoch: 6| Step: 7
Training loss: 2.6145386913688142
Validation loss: 2.5835817652903814

Epoch: 6| Step: 8
Training loss: 2.8657660429844163
Validation loss: 2.5761511074290984

Epoch: 6| Step: 9
Training loss: 2.8076932734255644
Validation loss: 2.5767824587161865

Epoch: 6| Step: 10
Training loss: 2.907499803459443
Validation loss: 2.583184705547982

Epoch: 6| Step: 11
Training loss: 2.638306813431083
Validation loss: 2.593820245026091

Epoch: 6| Step: 12
Training loss: 2.9963273774214905
Validation loss: 2.576048225425101

Epoch: 6| Step: 13
Training loss: 2.104601736381617
Validation loss: 2.5497257140646052

Epoch: 183| Step: 0
Training loss: 2.736252842915166
Validation loss: 2.550439668850847

Epoch: 6| Step: 1
Training loss: 3.4409916570640466
Validation loss: 2.6179924447172085

Epoch: 6| Step: 2
Training loss: 2.1713656919202013
Validation loss: 2.5704568622332444

Epoch: 6| Step: 3
Training loss: 2.515476672615433
Validation loss: 2.59132070748453

Epoch: 6| Step: 4
Training loss: 2.773212434474877
Validation loss: 2.5668414895243874

Epoch: 6| Step: 5
Training loss: 2.6590121997841742
Validation loss: 2.5800399494885893

Epoch: 6| Step: 6
Training loss: 2.750279672446488
Validation loss: 2.586206897799952

Epoch: 6| Step: 7
Training loss: 2.703913402795906
Validation loss: 2.5575320520548592

Epoch: 6| Step: 8
Training loss: 3.347120493657206
Validation loss: 2.58840332401053

Epoch: 6| Step: 9
Training loss: 2.3859681292992962
Validation loss: 2.5634437211878005

Epoch: 6| Step: 10
Training loss: 2.1293620050435176
Validation loss: 2.5759915700017997

Epoch: 6| Step: 11
Training loss: 2.6209721316733883
Validation loss: 2.583957291775544

Epoch: 6| Step: 12
Training loss: 2.5748337516078954
Validation loss: 2.6026611196072436

Epoch: 6| Step: 13
Training loss: 2.8685035283873375
Validation loss: 2.562980142666105

Epoch: 184| Step: 0
Training loss: 2.833689573743355
Validation loss: 2.5959598671662207

Epoch: 6| Step: 1
Training loss: 2.924079267562403
Validation loss: 2.5581110883772

Epoch: 6| Step: 2
Training loss: 2.6921154577143964
Validation loss: 2.586490616189661

Epoch: 6| Step: 3
Training loss: 2.499908922443759
Validation loss: 2.569481205661107

Epoch: 6| Step: 4
Training loss: 3.024132621561589
Validation loss: 2.597451259713936

Epoch: 6| Step: 5
Training loss: 3.1747129175351665
Validation loss: 2.6020039795367644

Epoch: 6| Step: 6
Training loss: 2.7015798926689896
Validation loss: 2.5877159424062866

Epoch: 6| Step: 7
Training loss: 1.7131991831636586
Validation loss: 2.609728579887535

Epoch: 6| Step: 8
Training loss: 2.755604841020562
Validation loss: 2.610526550157577

Epoch: 6| Step: 9
Training loss: 3.063187813884399
Validation loss: 2.602346195637209

Epoch: 6| Step: 10
Training loss: 2.442171266859387
Validation loss: 2.575256217270455

Epoch: 6| Step: 11
Training loss: 2.290946315487724
Validation loss: 2.5395904037661294

Epoch: 6| Step: 12
Training loss: 2.234219632382335
Validation loss: 2.5681578440246744

Epoch: 6| Step: 13
Training loss: 3.2312844663807208
Validation loss: 2.5859643627249023

Epoch: 185| Step: 0
Training loss: 2.010402330205791
Validation loss: 2.5904297039679167

Epoch: 6| Step: 1
Training loss: 3.051839217664265
Validation loss: 2.591447305458441

Epoch: 6| Step: 2
Training loss: 3.3690409858454737
Validation loss: 2.554202756275615

Epoch: 6| Step: 3
Training loss: 2.382254713467144
Validation loss: 2.5923466449759442

Epoch: 6| Step: 4
Training loss: 2.7224938058213457
Validation loss: 2.5998634486708423

Epoch: 6| Step: 5
Training loss: 2.798400633295946
Validation loss: 2.584164830645222

Epoch: 6| Step: 6
Training loss: 2.8503059022264767
Validation loss: 2.5554506877208762

Epoch: 6| Step: 7
Training loss: 2.3447483225380337
Validation loss: 2.6050383866442295

Epoch: 6| Step: 8
Training loss: 2.206867583291278
Validation loss: 2.5904787485020786

Epoch: 6| Step: 9
Training loss: 2.2477908415369443
Validation loss: 2.608909236727891

Epoch: 6| Step: 10
Training loss: 2.44638467019382
Validation loss: 2.541813750493817

Epoch: 6| Step: 11
Training loss: 2.50087379444021
Validation loss: 2.5610396403033113

Epoch: 6| Step: 12
Training loss: 3.1258559008558024
Validation loss: 2.581862465243512

Epoch: 6| Step: 13
Training loss: 3.8016224760380117
Validation loss: 2.549474581668517

Epoch: 186| Step: 0
Training loss: 2.6525768239421987
Validation loss: 2.5793618018275137

Epoch: 6| Step: 1
Training loss: 2.4894440956496675
Validation loss: 2.6190033766023855

Epoch: 6| Step: 2
Training loss: 3.7293971894404656
Validation loss: 2.58935015157886

Epoch: 6| Step: 3
Training loss: 2.545913795743856
Validation loss: 2.597829000049077

Epoch: 6| Step: 4
Training loss: 2.9923016001009652
Validation loss: 2.579632053303713

Epoch: 6| Step: 5
Training loss: 2.5924973737800854
Validation loss: 2.6170844699230034

Epoch: 6| Step: 6
Training loss: 3.1586362675011403
Validation loss: 2.56821974720212

Epoch: 6| Step: 7
Training loss: 2.6512774429447727
Validation loss: 2.5655926326093788

Epoch: 6| Step: 8
Training loss: 2.2366073234216484
Validation loss: 2.6006182792110595

Epoch: 6| Step: 9
Training loss: 2.477295679776696
Validation loss: 2.6210889280587937

Epoch: 6| Step: 10
Training loss: 2.6457478867397755
Validation loss: 2.580712286463271

Epoch: 6| Step: 11
Training loss: 2.930418854026533
Validation loss: 2.5949541566597625

Epoch: 6| Step: 12
Training loss: 2.575432868795054
Validation loss: 2.620261870085427

Epoch: 6| Step: 13
Training loss: 1.565807275573885
Validation loss: 2.5934995413443405

Epoch: 187| Step: 0
Training loss: 2.4823361073585986
Validation loss: 2.5913798146132385

Epoch: 6| Step: 1
Training loss: 3.033682407652536
Validation loss: 2.6084034834002363

Epoch: 6| Step: 2
Training loss: 2.5986299683197984
Validation loss: 2.5670818631349657

Epoch: 6| Step: 3
Training loss: 2.235753947680534
Validation loss: 2.6028350542937435

Epoch: 6| Step: 4
Training loss: 2.7710698727099823
Validation loss: 2.6054230807286656

Epoch: 6| Step: 5
Training loss: 2.7810694603775765
Validation loss: 2.575454348403176

Epoch: 6| Step: 6
Training loss: 2.8042493387612435
Validation loss: 2.603047917087254

Epoch: 6| Step: 7
Training loss: 3.311445824206592
Validation loss: 2.604947816572785

Epoch: 6| Step: 8
Training loss: 2.9973425221059102
Validation loss: 2.5821937213420516

Epoch: 6| Step: 9
Training loss: 2.5192322073017883
Validation loss: 2.5634669708681925

Epoch: 6| Step: 10
Training loss: 2.553261641881195
Validation loss: 2.595341357959057

Epoch: 6| Step: 11
Training loss: 2.616690790668574
Validation loss: 2.6010000718506

Epoch: 6| Step: 12
Training loss: 2.446909227777347
Validation loss: 2.601106459279823

Epoch: 6| Step: 13
Training loss: 2.141440354597196
Validation loss: 2.5896931092813618

Epoch: 188| Step: 0
Training loss: 2.5962481131108297
Validation loss: 2.592578814773977

Epoch: 6| Step: 1
Training loss: 2.595526397176955
Validation loss: 2.5966759861980493

Epoch: 6| Step: 2
Training loss: 2.8245569134834803
Validation loss: 2.6012892671521657

Epoch: 6| Step: 3
Training loss: 1.9567994001339284
Validation loss: 2.5852781745961235

Epoch: 6| Step: 4
Training loss: 2.701920610369818
Validation loss: 2.6279922020450397

Epoch: 6| Step: 5
Training loss: 2.517041204594923
Validation loss: 2.5645436707045306

Epoch: 6| Step: 6
Training loss: 2.2358197429792286
Validation loss: 2.5572370361229733

Epoch: 6| Step: 7
Training loss: 3.284643834052202
Validation loss: 2.5893250155329204

Epoch: 6| Step: 8
Training loss: 2.5607572071972475
Validation loss: 2.571157540512131

Epoch: 6| Step: 9
Training loss: 2.7963024384480497
Validation loss: 2.572747460654802

Epoch: 6| Step: 10
Training loss: 2.8225992922892087
Validation loss: 2.6036476953692214

Epoch: 6| Step: 11
Training loss: 2.9344193557783123
Validation loss: 2.601511599425757

Epoch: 6| Step: 12
Training loss: 2.5610056916352004
Validation loss: 2.580586337581089

Epoch: 6| Step: 13
Training loss: 3.6177208262164773
Validation loss: 2.6091722568431863

Epoch: 189| Step: 0
Training loss: 2.3385868422145673
Validation loss: 2.55723565066192

Epoch: 6| Step: 1
Training loss: 3.299455690287847
Validation loss: 2.559729176808498

Epoch: 6| Step: 2
Training loss: 2.8388898630092845
Validation loss: 2.569680421061733

Epoch: 6| Step: 3
Training loss: 2.5232041194928105
Validation loss: 2.594570748122685

Epoch: 6| Step: 4
Training loss: 2.906713633318247
Validation loss: 2.5690905578842114

Epoch: 6| Step: 5
Training loss: 2.192753722626424
Validation loss: 2.6322499216972384

Epoch: 6| Step: 6
Training loss: 2.365470943700629
Validation loss: 2.569670265966423

Epoch: 6| Step: 7
Training loss: 2.4625555622784128
Validation loss: 2.589636470238386

Epoch: 6| Step: 8
Training loss: 2.908198698000744
Validation loss: 2.5936850257837265

Epoch: 6| Step: 9
Training loss: 2.430498484592401
Validation loss: 2.5711262650248745

Epoch: 6| Step: 10
Training loss: 2.123805215083005
Validation loss: 2.5605669291225572

Epoch: 6| Step: 11
Training loss: 3.5786041871750496
Validation loss: 2.59560451834004

Epoch: 6| Step: 12
Training loss: 2.7995899172618093
Validation loss: 2.579082237970467

Epoch: 6| Step: 13
Training loss: 3.221477501044185
Validation loss: 2.637451771000335

Epoch: 190| Step: 0
Training loss: 2.274629470497967
Validation loss: 2.5670950963376113

Epoch: 6| Step: 1
Training loss: 2.5897416544909677
Validation loss: 2.5907476597339847

Epoch: 6| Step: 2
Training loss: 3.72766314553103
Validation loss: 2.566878459099165

Epoch: 6| Step: 3
Training loss: 3.2331381381653004
Validation loss: 2.55055137864475

Epoch: 6| Step: 4
Training loss: 3.2218789012748417
Validation loss: 2.585502976376692

Epoch: 6| Step: 5
Training loss: 2.8661721741948627
Validation loss: 2.586497542941484

Epoch: 6| Step: 6
Training loss: 1.8679064400051386
Validation loss: 2.570792001257134

Epoch: 6| Step: 7
Training loss: 2.9584064385062963
Validation loss: 2.57536643949586

Epoch: 6| Step: 8
Training loss: 1.8054407702745283
Validation loss: 2.5636301407288546

Epoch: 6| Step: 9
Training loss: 2.6222176110861084
Validation loss: 2.5299362972653614

Epoch: 6| Step: 10
Training loss: 2.1735286866289854
Validation loss: 2.5732832274653448

Epoch: 6| Step: 11
Training loss: 2.455556745466555
Validation loss: 2.5805966290337796

Epoch: 6| Step: 12
Training loss: 2.9644683479604854
Validation loss: 2.584807801469237

Epoch: 6| Step: 13
Training loss: 2.083942273473505
Validation loss: 2.5743132398737876

Epoch: 191| Step: 0
Training loss: 3.329877365191084
Validation loss: 2.5751480311673904

Epoch: 6| Step: 1
Training loss: 2.4410747821859373
Validation loss: 2.5821353928025617

Epoch: 6| Step: 2
Training loss: 2.262118658311227
Validation loss: 2.552591049256009

Epoch: 6| Step: 3
Training loss: 3.44341642837731
Validation loss: 2.5726737594044775

Epoch: 6| Step: 4
Training loss: 1.8341126808403259
Validation loss: 2.583881467555381

Epoch: 6| Step: 5
Training loss: 3.0615647113944306
Validation loss: 2.569052795383604

Epoch: 6| Step: 6
Training loss: 2.640616964294125
Validation loss: 2.5624615636104378

Epoch: 6| Step: 7
Training loss: 2.9339363720943314
Validation loss: 2.6188608838251035

Epoch: 6| Step: 8
Training loss: 2.7092747934855574
Validation loss: 2.5778287268001203

Epoch: 6| Step: 9
Training loss: 2.340149517173172
Validation loss: 2.5980118688138134

Epoch: 6| Step: 10
Training loss: 2.54453633594561
Validation loss: 2.573888029290239

Epoch: 6| Step: 11
Training loss: 2.8778996978947298
Validation loss: 2.5676214500510652

Epoch: 6| Step: 12
Training loss: 2.125164250028597
Validation loss: 2.5710447637068152

Epoch: 6| Step: 13
Training loss: 2.669276529941838
Validation loss: 2.5884195076387306

Epoch: 192| Step: 0
Training loss: 3.179438550796511
Validation loss: 2.5658512256704014

Epoch: 6| Step: 1
Training loss: 2.219078576916506
Validation loss: 2.5863199353034014

Epoch: 6| Step: 2
Training loss: 2.131340888538081
Validation loss: 2.551721901797497

Epoch: 6| Step: 3
Training loss: 2.7503478957244427
Validation loss: 2.565358462215571

Epoch: 6| Step: 4
Training loss: 2.597950945895448
Validation loss: 2.5791111804773985

Epoch: 6| Step: 5
Training loss: 2.918026598008416
Validation loss: 2.593304574720876

Epoch: 6| Step: 6
Training loss: 2.7475663600748823
Validation loss: 2.600089812285451

Epoch: 6| Step: 7
Training loss: 2.91863720040792
Validation loss: 2.580318722055585

Epoch: 6| Step: 8
Training loss: 3.085353361446665
Validation loss: 2.5929990171246478

Epoch: 6| Step: 9
Training loss: 2.3894773234161217
Validation loss: 2.577146716069625

Epoch: 6| Step: 10
Training loss: 2.3305074291491406
Validation loss: 2.5724938171255656

Epoch: 6| Step: 11
Training loss: 2.50251776750871
Validation loss: 2.5746308424997197

Epoch: 6| Step: 12
Training loss: 2.827346273032689
Validation loss: 2.5843764288829973

Epoch: 6| Step: 13
Training loss: 2.546787845547939
Validation loss: 2.574030875325849

Epoch: 193| Step: 0
Training loss: 2.883647684002694
Validation loss: 2.579876527670402

Epoch: 6| Step: 1
Training loss: 2.828316697847459
Validation loss: 2.5532529808018656

Epoch: 6| Step: 2
Training loss: 2.850996572695157
Validation loss: 2.5891932403638083

Epoch: 6| Step: 3
Training loss: 2.394235315751646
Validation loss: 2.5909381524543815

Epoch: 6| Step: 4
Training loss: 2.9288792830492847
Validation loss: 2.580975845835748

Epoch: 6| Step: 5
Training loss: 2.6348595514091175
Validation loss: 2.5881279649674003

Epoch: 6| Step: 6
Training loss: 2.191758071482501
Validation loss: 2.6145907845901846

Epoch: 6| Step: 7
Training loss: 2.743805584529152
Validation loss: 2.589331869852298

Epoch: 6| Step: 8
Training loss: 2.945794913451909
Validation loss: 2.5878959159464197

Epoch: 6| Step: 9
Training loss: 2.5324126034387002
Validation loss: 2.6079134031792424

Epoch: 6| Step: 10
Training loss: 2.756097795431686
Validation loss: 2.605963946593469

Epoch: 6| Step: 11
Training loss: 3.15246944815029
Validation loss: 2.558003884907297

Epoch: 6| Step: 12
Training loss: 2.493378931417362
Validation loss: 2.588328739352853

Epoch: 6| Step: 13
Training loss: 1.9928544068891474
Validation loss: 2.606718721850608

Epoch: 194| Step: 0
Training loss: 2.411531868809672
Validation loss: 2.5446626486183233

Epoch: 6| Step: 1
Training loss: 2.4068943498577067
Validation loss: 2.594982826314707

Epoch: 6| Step: 2
Training loss: 2.5993192698582632
Validation loss: 2.586375323710372

Epoch: 6| Step: 3
Training loss: 2.937750947662712
Validation loss: 2.594091055693713

Epoch: 6| Step: 4
Training loss: 3.505177755161053
Validation loss: 2.622041124575674

Epoch: 6| Step: 5
Training loss: 2.1871327773169176
Validation loss: 2.5567772363769423

Epoch: 6| Step: 6
Training loss: 2.6596435411289874
Validation loss: 2.6234534435084207

Epoch: 6| Step: 7
Training loss: 2.2105544334669327
Validation loss: 2.6059142613686306

Epoch: 6| Step: 8
Training loss: 2.1612121319252555
Validation loss: 2.552644814426295

Epoch: 6| Step: 9
Training loss: 3.2547516932317166
Validation loss: 2.574619303939021

Epoch: 6| Step: 10
Training loss: 3.131049747116915
Validation loss: 2.573279018293798

Epoch: 6| Step: 11
Training loss: 2.5705526407873536
Validation loss: 2.5681542633314582

Epoch: 6| Step: 12
Training loss: 2.6555190932015362
Validation loss: 2.5537703599711943

Epoch: 6| Step: 13
Training loss: 2.262325330704455
Validation loss: 2.5519469592432062

Epoch: 195| Step: 0
Training loss: 2.511877075710801
Validation loss: 2.587492738808384

Epoch: 6| Step: 1
Training loss: 2.4240933011168386
Validation loss: 2.585620432041814

Epoch: 6| Step: 2
Training loss: 3.224018118965974
Validation loss: 2.5929690797872045

Epoch: 6| Step: 3
Training loss: 2.29301200448981
Validation loss: 2.564583243459713

Epoch: 6| Step: 4
Training loss: 2.1987094865442054
Validation loss: 2.571441260909748

Epoch: 6| Step: 5
Training loss: 2.6644874748383707
Validation loss: 2.577415637699568

Epoch: 6| Step: 6
Training loss: 3.024825376404274
Validation loss: 2.5945031181803033

Epoch: 6| Step: 7
Training loss: 2.5335639455467307
Validation loss: 2.5586616753206406

Epoch: 6| Step: 8
Training loss: 2.330928062320643
Validation loss: 2.618892451666473

Epoch: 6| Step: 9
Training loss: 2.9414474261518646
Validation loss: 2.5873710253407682

Epoch: 6| Step: 10
Training loss: 2.925165944405057
Validation loss: 2.5943242472840984

Epoch: 6| Step: 11
Training loss: 2.662851903162981
Validation loss: 2.6095091787905

Epoch: 6| Step: 12
Training loss: 3.0414438209594215
Validation loss: 2.5678381973238307

Epoch: 6| Step: 13
Training loss: 2.0753834933060227
Validation loss: 2.606777520160057

Epoch: 196| Step: 0
Training loss: 2.4663770836455017
Validation loss: 2.569472915534541

Epoch: 6| Step: 1
Training loss: 2.173837666863324
Validation loss: 2.5893784209233686

Epoch: 6| Step: 2
Training loss: 2.422752369115181
Validation loss: 2.601324521182753

Epoch: 6| Step: 3
Training loss: 2.645113769565096
Validation loss: 2.5838089103925785

Epoch: 6| Step: 4
Training loss: 2.564823585823732
Validation loss: 2.5825809224244347

Epoch: 6| Step: 5
Training loss: 2.357733755648507
Validation loss: 2.6017361011801654

Epoch: 6| Step: 6
Training loss: 2.6347093399404113
Validation loss: 2.562579452119286

Epoch: 6| Step: 7
Training loss: 3.200978224961814
Validation loss: 2.594534334195104

Epoch: 6| Step: 8
Training loss: 2.7136035309303
Validation loss: 2.6007142176119835

Epoch: 6| Step: 9
Training loss: 2.3588357271223503
Validation loss: 2.602518243307569

Epoch: 6| Step: 10
Training loss: 2.3357313186337763
Validation loss: 2.549868501107311

Epoch: 6| Step: 11
Training loss: 2.9906972655172184
Validation loss: 2.5682548752166574

Epoch: 6| Step: 12
Training loss: 3.524554361080826
Validation loss: 2.5632919920433745

Epoch: 6| Step: 13
Training loss: 2.6768144603637367
Validation loss: 2.5822050473506266

Epoch: 197| Step: 0
Training loss: 2.947673468560977
Validation loss: 2.5666898044245916

Epoch: 6| Step: 1
Training loss: 2.1477282653923733
Validation loss: 2.595864161914042

Epoch: 6| Step: 2
Training loss: 2.314618145817946
Validation loss: 2.554211153174511

Epoch: 6| Step: 3
Training loss: 2.591771853684798
Validation loss: 2.5936980763059125

Epoch: 6| Step: 4
Training loss: 3.605916665999955
Validation loss: 2.578699959053039

Epoch: 6| Step: 5
Training loss: 3.052179814572431
Validation loss: 2.597509463432352

Epoch: 6| Step: 6
Training loss: 2.38594144909525
Validation loss: 2.55763374835737

Epoch: 6| Step: 7
Training loss: 3.0178426385887285
Validation loss: 2.5584835546968057

Epoch: 6| Step: 8
Training loss: 2.316936464402536
Validation loss: 2.5806322839630997

Epoch: 6| Step: 9
Training loss: 1.9161806803468449
Validation loss: 2.6011124516978015

Epoch: 6| Step: 10
Training loss: 3.122924878646372
Validation loss: 2.6243113792824073

Epoch: 6| Step: 11
Training loss: 2.628083461655471
Validation loss: 2.5941050988533565

Epoch: 6| Step: 12
Training loss: 2.6255244684802737
Validation loss: 2.5778082480549243

Epoch: 6| Step: 13
Training loss: 2.7576074280827196
Validation loss: 2.587802001773008

Epoch: 198| Step: 0
Training loss: 3.292640895971533
Validation loss: 2.6172833687921693

Epoch: 6| Step: 1
Training loss: 2.390370872803193
Validation loss: 2.582242841389337

Epoch: 6| Step: 2
Training loss: 3.3867504289986816
Validation loss: 2.5635026070345543

Epoch: 6| Step: 3
Training loss: 2.7440991815987497
Validation loss: 2.626330900153387

Epoch: 6| Step: 4
Training loss: 2.497190040698792
Validation loss: 2.6015720103041153

Epoch: 6| Step: 5
Training loss: 2.2040122119267544
Validation loss: 2.6417275035101757

Epoch: 6| Step: 6
Training loss: 2.5042535835538278
Validation loss: 2.5877566111609323

Epoch: 6| Step: 7
Training loss: 2.4825517213779063
Validation loss: 2.5661493882303454

Epoch: 6| Step: 8
Training loss: 2.253447328915583
Validation loss: 2.5984871249097634

Epoch: 6| Step: 9
Training loss: 2.6412878163957307
Validation loss: 2.594011436162494

Epoch: 6| Step: 10
Training loss: 2.4504076248812505
Validation loss: 2.584634935936863

Epoch: 6| Step: 11
Training loss: 1.917469029481093
Validation loss: 2.577844518355448

Epoch: 6| Step: 12
Training loss: 3.4675792746087004
Validation loss: 2.5756751439299492

Epoch: 6| Step: 13
Training loss: 3.3360482762546266
Validation loss: 2.6012468300162372

Epoch: 199| Step: 0
Training loss: 3.064729307334318
Validation loss: 2.6028016684976887

Epoch: 6| Step: 1
Training loss: 2.6788944594556807
Validation loss: 2.5917391671507253

Epoch: 6| Step: 2
Training loss: 3.047222724048253
Validation loss: 2.5684760116606173

Epoch: 6| Step: 3
Training loss: 3.0928781224882442
Validation loss: 2.607992253757317

Epoch: 6| Step: 4
Training loss: 2.091827192897121
Validation loss: 2.585190404884145

Epoch: 6| Step: 5
Training loss: 2.1346047943761928
Validation loss: 2.6167615680742844

Epoch: 6| Step: 6
Training loss: 2.069541240479378
Validation loss: 2.6164016133879366

Epoch: 6| Step: 7
Training loss: 2.7320999708469498
Validation loss: 2.5630606221374928

Epoch: 6| Step: 8
Training loss: 2.768751026437539
Validation loss: 2.6087961112935885

Epoch: 6| Step: 9
Training loss: 2.9210048746697153
Validation loss: 2.562896063625338

Epoch: 6| Step: 10
Training loss: 3.0431840499692595
Validation loss: 2.577172007203075

Epoch: 6| Step: 11
Training loss: 2.206835928857089
Validation loss: 2.574905781107872

Epoch: 6| Step: 12
Training loss: 2.991464393032736
Validation loss: 2.532900459658166

Epoch: 6| Step: 13
Training loss: 2.7037718776147552
Validation loss: 2.571852396940949

Epoch: 200| Step: 0
Training loss: 2.93932383306809
Validation loss: 2.568456709993535

Epoch: 6| Step: 1
Training loss: 3.13068940099274
Validation loss: 2.5826926639381

Epoch: 6| Step: 2
Training loss: 2.2850194645559716
Validation loss: 2.593279987106763

Epoch: 6| Step: 3
Training loss: 2.684740379611091
Validation loss: 2.5620339642881214

Epoch: 6| Step: 4
Training loss: 3.2111941047101156
Validation loss: 2.580066239181652

Epoch: 6| Step: 5
Training loss: 2.8679790183860034
Validation loss: 2.5573059373021376

Epoch: 6| Step: 6
Training loss: 2.7928780067481274
Validation loss: 2.564569088625133

Epoch: 6| Step: 7
Training loss: 2.3670225180363436
Validation loss: 2.5992688303376807

Epoch: 6| Step: 8
Training loss: 2.2029747877925008
Validation loss: 2.590168474407978

Epoch: 6| Step: 9
Training loss: 2.5005713763562025
Validation loss: 2.5761560383615874

Epoch: 6| Step: 10
Training loss: 2.545698584587212
Validation loss: 2.5515400127165506

Epoch: 6| Step: 11
Training loss: 2.705961910709967
Validation loss: 2.579383859467242

Epoch: 6| Step: 12
Training loss: 2.8543563742601057
Validation loss: 2.602225687227374

Epoch: 6| Step: 13
Training loss: 2.241889535066116
Validation loss: 2.614866015832013

Epoch: 201| Step: 0
Training loss: 2.720306301821988
Validation loss: 2.579803273552314

Epoch: 6| Step: 1
Training loss: 3.532910387048825
Validation loss: 2.5809002955895224

Epoch: 6| Step: 2
Training loss: 2.2930514111151834
Validation loss: 2.6017423867691813

Epoch: 6| Step: 3
Training loss: 1.9729002546724137
Validation loss: 2.599997379800188

Epoch: 6| Step: 4
Training loss: 3.3327335453830513
Validation loss: 2.586436037573252

Epoch: 6| Step: 5
Training loss: 2.4996884151838104
Validation loss: 2.5930333902588565

Epoch: 6| Step: 6
Training loss: 2.5375994883610136
Validation loss: 2.581099020972511

Epoch: 6| Step: 7
Training loss: 3.0273725742075364
Validation loss: 2.6062515021921553

Epoch: 6| Step: 8
Training loss: 2.394653715452644
Validation loss: 2.6085955722071796

Epoch: 6| Step: 9
Training loss: 2.5564030011563688
Validation loss: 2.57585519937194

Epoch: 6| Step: 10
Training loss: 2.6633281870359786
Validation loss: 2.6149482003450037

Epoch: 6| Step: 11
Training loss: 2.5626462569017785
Validation loss: 2.563791057337329

Epoch: 6| Step: 12
Training loss: 2.783016372572192
Validation loss: 2.579253572742633

Epoch: 6| Step: 13
Training loss: 1.8063483584329878
Validation loss: 2.6008018370238686

Epoch: 202| Step: 0
Training loss: 2.875545615792067
Validation loss: 2.5806605057555

Epoch: 6| Step: 1
Training loss: 2.51049623059915
Validation loss: 2.5352559690299596

Epoch: 6| Step: 2
Training loss: 2.599417870716742
Validation loss: 2.592111849315604

Epoch: 6| Step: 3
Training loss: 3.0625348770335457
Validation loss: 2.6048895930499714

Epoch: 6| Step: 4
Training loss: 2.5140430855105134
Validation loss: 2.600943844622456

Epoch: 6| Step: 5
Training loss: 2.9646587892117022
Validation loss: 2.5457326558137594

Epoch: 6| Step: 6
Training loss: 2.4696680607320887
Validation loss: 2.566137025298775

Epoch: 6| Step: 7
Training loss: 2.2813685138173976
Validation loss: 2.5330712579820402

Epoch: 6| Step: 8
Training loss: 2.221346772790181
Validation loss: 2.579689065043283

Epoch: 6| Step: 9
Training loss: 3.2012581199772403
Validation loss: 2.603713677826591

Epoch: 6| Step: 10
Training loss: 2.937926728115906
Validation loss: 2.5840854092529946

Epoch: 6| Step: 11
Training loss: 2.31529499950944
Validation loss: 2.6198716831621227

Epoch: 6| Step: 12
Training loss: 2.6858503024608433
Validation loss: 2.571395384092876

Epoch: 6| Step: 13
Training loss: 2.7841848254950836
Validation loss: 2.608055627590982

Epoch: 203| Step: 0
Training loss: 2.6406913613552567
Validation loss: 2.5650325498842608

Epoch: 6| Step: 1
Training loss: 3.428336952911034
Validation loss: 2.576972566132249

Epoch: 6| Step: 2
Training loss: 3.398576965978078
Validation loss: 2.549235824235084

Epoch: 6| Step: 3
Training loss: 2.7721932212401597
Validation loss: 2.5816023071929552

Epoch: 6| Step: 4
Training loss: 2.581387576669549
Validation loss: 2.588568790399573

Epoch: 6| Step: 5
Training loss: 2.7520611581383045
Validation loss: 2.566831914461528

Epoch: 6| Step: 6
Training loss: 2.78545456154115
Validation loss: 2.5636508077301547

Epoch: 6| Step: 7
Training loss: 3.0514845190129
Validation loss: 2.590232607474686

Epoch: 6| Step: 8
Training loss: 2.392947595834713
Validation loss: 2.5706392857138987

Epoch: 6| Step: 9
Training loss: 1.8646161238133092
Validation loss: 2.5741996138881578

Epoch: 6| Step: 10
Training loss: 2.163352657088785
Validation loss: 2.5939516843309636

Epoch: 6| Step: 11
Training loss: 2.844194649946995
Validation loss: 2.5851275722802773

Epoch: 6| Step: 12
Training loss: 2.1708769117241387
Validation loss: 2.575266648984251

Epoch: 6| Step: 13
Training loss: 2.443092093725505
Validation loss: 2.5703403553552175

Epoch: 204| Step: 0
Training loss: 3.033458888071925
Validation loss: 2.56626294758719

Epoch: 6| Step: 1
Training loss: 2.5267214355303502
Validation loss: 2.611825959213522

Epoch: 6| Step: 2
Training loss: 2.5206862057292865
Validation loss: 2.5722330762986645

Epoch: 6| Step: 3
Training loss: 2.922415127529336
Validation loss: 2.552490337197217

Epoch: 6| Step: 4
Training loss: 2.540102795450668
Validation loss: 2.5617363024584705

Epoch: 6| Step: 5
Training loss: 1.7622757599942485
Validation loss: 2.560123633802043

Epoch: 6| Step: 6
Training loss: 2.049882150379464
Validation loss: 2.6047179835024803

Epoch: 6| Step: 7
Training loss: 2.2472457983003364
Validation loss: 2.5732217140968765

Epoch: 6| Step: 8
Training loss: 2.5613983391345423
Validation loss: 2.5815655127225297

Epoch: 6| Step: 9
Training loss: 2.9062450778058118
Validation loss: 2.563288003497848

Epoch: 6| Step: 10
Training loss: 3.3801439432948084
Validation loss: 2.596182456371769

Epoch: 6| Step: 11
Training loss: 3.041539611949772
Validation loss: 2.6093967341784725

Epoch: 6| Step: 12
Training loss: 3.0893136014553795
Validation loss: 2.585558575631719

Epoch: 6| Step: 13
Training loss: 2.7816089869927
Validation loss: 2.57147833682734

Epoch: 205| Step: 0
Training loss: 2.821322104530248
Validation loss: 2.5632609176290657

Epoch: 6| Step: 1
Training loss: 3.045234434126388
Validation loss: 2.603702531041133

Epoch: 6| Step: 2
Training loss: 3.0506548006665044
Validation loss: 2.58132226198199

Epoch: 6| Step: 3
Training loss: 2.5657220448065012
Validation loss: 2.5829126893487944

Epoch: 6| Step: 4
Training loss: 2.962755435281
Validation loss: 2.5577794155328726

Epoch: 6| Step: 5
Training loss: 2.810777263728655
Validation loss: 2.5506146107107974

Epoch: 6| Step: 6
Training loss: 2.8041464621131054
Validation loss: 2.5566181796147074

Epoch: 6| Step: 7
Training loss: 2.8778912477285243
Validation loss: 2.5743408642229753

Epoch: 6| Step: 8
Training loss: 2.5202554297799757
Validation loss: 2.5815016047679347

Epoch: 6| Step: 9
Training loss: 2.2654538846345473
Validation loss: 2.5911036746389655

Epoch: 6| Step: 10
Training loss: 1.8437783190605226
Validation loss: 2.55688576262717

Epoch: 6| Step: 11
Training loss: 2.253050855033013
Validation loss: 2.5505869067957123

Epoch: 6| Step: 12
Training loss: 2.6330144334999463
Validation loss: 2.5786914023027734

Epoch: 6| Step: 13
Training loss: 2.478774950726196
Validation loss: 2.56998076188347

Epoch: 206| Step: 0
Training loss: 2.2814942320634346
Validation loss: 2.556414983958042

Epoch: 6| Step: 1
Training loss: 3.2319081800089537
Validation loss: 2.581549666469947

Epoch: 6| Step: 2
Training loss: 1.8542585743045872
Validation loss: 2.5882696457488232

Epoch: 6| Step: 3
Training loss: 3.411908131229102
Validation loss: 2.5707221052815834

Epoch: 6| Step: 4
Training loss: 2.5464486543432487
Validation loss: 2.5657207598494307

Epoch: 6| Step: 5
Training loss: 2.5882267802016834
Validation loss: 2.5622173916826854

Epoch: 6| Step: 6
Training loss: 2.85573892841599
Validation loss: 2.574272434922737

Epoch: 6| Step: 7
Training loss: 1.8352650811090567
Validation loss: 2.569994304355882

Epoch: 6| Step: 8
Training loss: 2.419705606792128
Validation loss: 2.621147585931029

Epoch: 6| Step: 9
Training loss: 2.3624823110412723
Validation loss: 2.5935997196036777

Epoch: 6| Step: 10
Training loss: 2.726105222640169
Validation loss: 2.5865135422449677

Epoch: 6| Step: 11
Training loss: 3.0309057925141296
Validation loss: 2.5907085964773544

Epoch: 6| Step: 12
Training loss: 1.8465590334188497
Validation loss: 2.5791993409483824

Epoch: 6| Step: 13
Training loss: 4.18217106412092
Validation loss: 2.545410380343557

Epoch: 207| Step: 0
Training loss: 2.5292649197124715
Validation loss: 2.5845295944406996

Epoch: 6| Step: 1
Training loss: 2.61534723518379
Validation loss: 2.5828853199509214

Epoch: 6| Step: 2
Training loss: 1.7996628074588132
Validation loss: 2.5520111462192827

Epoch: 6| Step: 3
Training loss: 2.91345093883282
Validation loss: 2.6047793928025555

Epoch: 6| Step: 4
Training loss: 2.4316682745039473
Validation loss: 2.5859177457335423

Epoch: 6| Step: 5
Training loss: 2.7606425258917024
Validation loss: 2.589552625074216

Epoch: 6| Step: 6
Training loss: 2.5412794558220093
Validation loss: 2.586139307864499

Epoch: 6| Step: 7
Training loss: 2.7227442547929575
Validation loss: 2.581421291058179

Epoch: 6| Step: 8
Training loss: 2.5024073454236864
Validation loss: 2.6028069744409708

Epoch: 6| Step: 9
Training loss: 2.915446016924357
Validation loss: 2.5981734414857454

Epoch: 6| Step: 10
Training loss: 3.308320918087921
Validation loss: 2.605756597350414

Epoch: 6| Step: 11
Training loss: 2.216245500330867
Validation loss: 2.612780429630174

Epoch: 6| Step: 12
Training loss: 3.0119565481468693
Validation loss: 2.566086068412503

Epoch: 6| Step: 13
Training loss: 3.0499185082226896
Validation loss: 2.6152725935595766

Epoch: 208| Step: 0
Training loss: 3.0649415229334256
Validation loss: 2.5716959951506797

Epoch: 6| Step: 1
Training loss: 3.2371690264278854
Validation loss: 2.5624916252601646

Epoch: 6| Step: 2
Training loss: 2.4579917109996066
Validation loss: 2.5916295413496653

Epoch: 6| Step: 3
Training loss: 2.1584607276975634
Validation loss: 2.5878260747807746

Epoch: 6| Step: 4
Training loss: 2.284633061435213
Validation loss: 2.584412849042873

Epoch: 6| Step: 5
Training loss: 2.9567901633990763
Validation loss: 2.596020910875363

Epoch: 6| Step: 6
Training loss: 2.4134633329936026
Validation loss: 2.6062170909189746

Epoch: 6| Step: 7
Training loss: 2.6747043196644813
Validation loss: 2.6313306449699048

Epoch: 6| Step: 8
Training loss: 2.8558885341444977
Validation loss: 2.586078599922445

Epoch: 6| Step: 9
Training loss: 2.411505866903927
Validation loss: 2.592889122266673

Epoch: 6| Step: 10
Training loss: 3.2619811540687222
Validation loss: 2.608668598606498

Epoch: 6| Step: 11
Training loss: 2.0982994642041666
Validation loss: 2.5923890310137847

Epoch: 6| Step: 12
Training loss: 2.3402360131989135
Validation loss: 2.57902651897773

Epoch: 6| Step: 13
Training loss: 2.792341340560091
Validation loss: 2.5582956768729175

Epoch: 209| Step: 0
Training loss: 2.9211517907717504
Validation loss: 2.5760789654641787

Epoch: 6| Step: 1
Training loss: 2.7608948683240344
Validation loss: 2.6109256843999673

Epoch: 6| Step: 2
Training loss: 1.8752418362107066
Validation loss: 2.549928770170319

Epoch: 6| Step: 3
Training loss: 2.082535272965856
Validation loss: 2.5565018824095818

Epoch: 6| Step: 4
Training loss: 2.127625582403183
Validation loss: 2.554183229313986

Epoch: 6| Step: 5
Training loss: 3.050954112920335
Validation loss: 2.577048197702972

Epoch: 6| Step: 6
Training loss: 2.4449160318446514
Validation loss: 2.627878111368625

Epoch: 6| Step: 7
Training loss: 3.226883768339064
Validation loss: 2.5935831511712926

Epoch: 6| Step: 8
Training loss: 3.4668752742015565
Validation loss: 2.6057492028184854

Epoch: 6| Step: 9
Training loss: 2.4305693078030464
Validation loss: 2.58614543409301

Epoch: 6| Step: 10
Training loss: 2.4674401007187114
Validation loss: 2.593217372259277

Epoch: 6| Step: 11
Training loss: 3.0436166409018894
Validation loss: 2.586982740106106

Epoch: 6| Step: 12
Training loss: 2.416174005299092
Validation loss: 2.616677695614853

Epoch: 6| Step: 13
Training loss: 2.3720160360710922
Validation loss: 2.5855016377915945

Epoch: 210| Step: 0
Training loss: 2.7899051536654387
Validation loss: 2.6045505636133988

Epoch: 6| Step: 1
Training loss: 2.9481778158341903
Validation loss: 2.575787748855181

Epoch: 6| Step: 2
Training loss: 3.13408682535788
Validation loss: 2.5914217376535538

Epoch: 6| Step: 3
Training loss: 3.035649361437065
Validation loss: 2.6157466109821765

Epoch: 6| Step: 4
Training loss: 2.827754465351385
Validation loss: 2.581766990083446

Epoch: 6| Step: 5
Training loss: 2.422530251738285
Validation loss: 2.5865416641856194

Epoch: 6| Step: 6
Training loss: 2.7367469309173433
Validation loss: 2.582168609950389

Epoch: 6| Step: 7
Training loss: 2.6845273277751853
Validation loss: 2.5833139117804578

Epoch: 6| Step: 8
Training loss: 2.571838853287716
Validation loss: 2.5934040789246016

Epoch: 6| Step: 9
Training loss: 1.9776549204101337
Validation loss: 2.5822665691072353

Epoch: 6| Step: 10
Training loss: 2.4176646397258374
Validation loss: 2.607009433401581

Epoch: 6| Step: 11
Training loss: 2.598581708529586
Validation loss: 2.564722124633585

Epoch: 6| Step: 12
Training loss: 2.347356539111646
Validation loss: 2.560560096921908

Epoch: 6| Step: 13
Training loss: 2.830442543340158
Validation loss: 2.5852868334989685

Epoch: 211| Step: 0
Training loss: 2.870937130347631
Validation loss: 2.588520642128325

Epoch: 6| Step: 1
Training loss: 2.5809737678858995
Validation loss: 2.5712518811580813

Epoch: 6| Step: 2
Training loss: 2.7131612929680675
Validation loss: 2.5649869962126477

Epoch: 6| Step: 3
Training loss: 3.210628299722578
Validation loss: 2.595832097742199

Epoch: 6| Step: 4
Training loss: 1.9481655784593233
Validation loss: 2.595232073981806

Epoch: 6| Step: 5
Training loss: 2.607801042626447
Validation loss: 2.5950731366211883

Epoch: 6| Step: 6
Training loss: 2.8557624718013788
Validation loss: 2.6044012115847943

Epoch: 6| Step: 7
Training loss: 2.419177515853363
Validation loss: 2.59439224651547

Epoch: 6| Step: 8
Training loss: 2.4788122698512365
Validation loss: 2.611825789405177

Epoch: 6| Step: 9
Training loss: 2.8112538438009986
Validation loss: 2.569938842212065

Epoch: 6| Step: 10
Training loss: 2.7705863804344695
Validation loss: 2.6042337447520714

Epoch: 6| Step: 11
Training loss: 3.017007619512468
Validation loss: 2.592922642615041

Epoch: 6| Step: 12
Training loss: 1.9494812201950207
Validation loss: 2.614289010332186

Epoch: 6| Step: 13
Training loss: 2.435916386207557
Validation loss: 2.548383161420524

Epoch: 212| Step: 0
Training loss: 2.4832079563450917
Validation loss: 2.593792788106541

Epoch: 6| Step: 1
Training loss: 3.6064076301595533
Validation loss: 2.5810136464511855

Epoch: 6| Step: 2
Training loss: 2.6655605724280966
Validation loss: 2.588522759577708

Epoch: 6| Step: 3
Training loss: 2.1846737724159926
Validation loss: 2.572735322743591

Epoch: 6| Step: 4
Training loss: 3.2795475494199273
Validation loss: 2.5633469439276313

Epoch: 6| Step: 5
Training loss: 2.3537871018218968
Validation loss: 2.5715939024091963

Epoch: 6| Step: 6
Training loss: 2.410557050471758
Validation loss: 2.609863615719467

Epoch: 6| Step: 7
Training loss: 2.7906732262420233
Validation loss: 2.562901702256795

Epoch: 6| Step: 8
Training loss: 2.3508749935872033
Validation loss: 2.581908749844284

Epoch: 6| Step: 9
Training loss: 2.865543902631777
Validation loss: 2.5942029660024315

Epoch: 6| Step: 10
Training loss: 2.7197156046401783
Validation loss: 2.591506232624433

Epoch: 6| Step: 11
Training loss: 2.4974058042982867
Validation loss: 2.608026505956958

Epoch: 6| Step: 12
Training loss: 1.7441162927858997
Validation loss: 2.601942536262194

Epoch: 6| Step: 13
Training loss: 3.279191452249376
Validation loss: 2.599708938162035

Epoch: 213| Step: 0
Training loss: 2.4466671832272073
Validation loss: 2.5865339827920804

Epoch: 6| Step: 1
Training loss: 2.7022710785436743
Validation loss: 2.5556314257454757

Epoch: 6| Step: 2
Training loss: 3.141192180983375
Validation loss: 2.594686101794924

Epoch: 6| Step: 3
Training loss: 2.690034425366293
Validation loss: 2.593324663197983

Epoch: 6| Step: 4
Training loss: 3.03230220190481
Validation loss: 2.5760371738888588

Epoch: 6| Step: 5
Training loss: 2.7554864773073255
Validation loss: 2.5761793026822537

Epoch: 6| Step: 6
Training loss: 2.6262077096460024
Validation loss: 2.5706971710354676

Epoch: 6| Step: 7
Training loss: 2.387232448905259
Validation loss: 2.5730685469519594

Epoch: 6| Step: 8
Training loss: 2.2464525019202584
Validation loss: 2.6052735179534574

Epoch: 6| Step: 9
Training loss: 2.5102088388442536
Validation loss: 2.576765454825726

Epoch: 6| Step: 10
Training loss: 3.133139728760357
Validation loss: 2.5505209601556955

Epoch: 6| Step: 11
Training loss: 2.4587576763923407
Validation loss: 2.5452373148190364

Epoch: 6| Step: 12
Training loss: 2.705949839801629
Validation loss: 2.6040237463013027

Epoch: 6| Step: 13
Training loss: 2.6708395217450875
Validation loss: 2.596498278993145

Epoch: 214| Step: 0
Training loss: 2.34850713508599
Validation loss: 2.5822579695720727

Epoch: 6| Step: 1
Training loss: 3.0123212832547934
Validation loss: 2.565258801058678

Epoch: 6| Step: 2
Training loss: 2.480715473550256
Validation loss: 2.589187665919966

Epoch: 6| Step: 3
Training loss: 3.1386484787359175
Validation loss: 2.5805365755260428

Epoch: 6| Step: 4
Training loss: 2.125285409946266
Validation loss: 2.5592071221317467

Epoch: 6| Step: 5
Training loss: 2.5761877005946343
Validation loss: 2.5370341503926728

Epoch: 6| Step: 6
Training loss: 2.420375236550227
Validation loss: 2.6072931048713297

Epoch: 6| Step: 7
Training loss: 3.2424898673011735
Validation loss: 2.5665368138250875

Epoch: 6| Step: 8
Training loss: 2.7772214194611173
Validation loss: 2.5711166261515084

Epoch: 6| Step: 9
Training loss: 3.567573281212495
Validation loss: 2.5793995301860324

Epoch: 6| Step: 10
Training loss: 2.3414770676318506
Validation loss: 2.56661405540064

Epoch: 6| Step: 11
Training loss: 2.318277307743434
Validation loss: 2.600094713595216

Epoch: 6| Step: 12
Training loss: 2.024189930647738
Validation loss: 2.617138453957492

Epoch: 6| Step: 13
Training loss: 2.7654161104959725
Validation loss: 2.555837552430418

Epoch: 215| Step: 0
Training loss: 2.8887978217451344
Validation loss: 2.5934663299447633

Epoch: 6| Step: 1
Training loss: 2.4430814565163046
Validation loss: 2.635440543395418

Epoch: 6| Step: 2
Training loss: 3.011608077216289
Validation loss: 2.6255486086461026

Epoch: 6| Step: 3
Training loss: 2.326629158125746
Validation loss: 2.586496807498442

Epoch: 6| Step: 4
Training loss: 3.491736193004925
Validation loss: 2.563482710886124

Epoch: 6| Step: 5
Training loss: 2.7911704082561504
Validation loss: 2.568646392637033

Epoch: 6| Step: 6
Training loss: 2.651575980211204
Validation loss: 2.608052594143567

Epoch: 6| Step: 7
Training loss: 2.643883224268908
Validation loss: 2.573677698397482

Epoch: 6| Step: 8
Training loss: 2.507285374653466
Validation loss: 2.582303858909844

Epoch: 6| Step: 9
Training loss: 2.663310641246594
Validation loss: 2.597784885968931

Epoch: 6| Step: 10
Training loss: 2.445353644759181
Validation loss: 2.589632886574954

Epoch: 6| Step: 11
Training loss: 2.490045565758921
Validation loss: 2.569834579239233

Epoch: 6| Step: 12
Training loss: 2.193599371887607
Validation loss: 2.5734981082312953

Epoch: 6| Step: 13
Training loss: 2.4673825110202263
Validation loss: 2.554594158318716

Epoch: 216| Step: 0
Training loss: 2.420707076474052
Validation loss: 2.578185301591629

Epoch: 6| Step: 1
Training loss: 2.377865117193144
Validation loss: 2.5814445853897325

Epoch: 6| Step: 2
Training loss: 2.4401397105382716
Validation loss: 2.597195573091365

Epoch: 6| Step: 3
Training loss: 2.0644810727915504
Validation loss: 2.602794554163223

Epoch: 6| Step: 4
Training loss: 2.7231084155334364
Validation loss: 2.5846062001008296

Epoch: 6| Step: 5
Training loss: 2.789784741318417
Validation loss: 2.589756480501055

Epoch: 6| Step: 6
Training loss: 2.597846415736669
Validation loss: 2.5884512951989502

Epoch: 6| Step: 7
Training loss: 2.8816716280781045
Validation loss: 2.5962203411971405

Epoch: 6| Step: 8
Training loss: 2.521204287975598
Validation loss: 2.575983209267944

Epoch: 6| Step: 9
Training loss: 3.09432145823042
Validation loss: 2.5918565617706357

Epoch: 6| Step: 10
Training loss: 3.28379447009495
Validation loss: 2.5907555878922004

Epoch: 6| Step: 11
Training loss: 2.2084295383826436
Validation loss: 2.5653415584865766

Epoch: 6| Step: 12
Training loss: 2.745339171921072
Validation loss: 2.5615038642606023

Epoch: 6| Step: 13
Training loss: 2.910635152237552
Validation loss: 2.592645165948361

Epoch: 217| Step: 0
Training loss: 2.1717575370804454
Validation loss: 2.579491711383886

Epoch: 6| Step: 1
Training loss: 2.7767262905843393
Validation loss: 2.5967588382191282

Epoch: 6| Step: 2
Training loss: 2.288733344775299
Validation loss: 2.5819583856664323

Epoch: 6| Step: 3
Training loss: 2.7729025741284006
Validation loss: 2.5697225135487667

Epoch: 6| Step: 4
Training loss: 2.296292497120156
Validation loss: 2.5800434878516465

Epoch: 6| Step: 5
Training loss: 2.8106143988370578
Validation loss: 2.5912659046148465

Epoch: 6| Step: 6
Training loss: 3.400184200009485
Validation loss: 2.5834314530786133

Epoch: 6| Step: 7
Training loss: 2.5087784187444515
Validation loss: 2.5776576429299696

Epoch: 6| Step: 8
Training loss: 2.635514319097085
Validation loss: 2.5500983767159138

Epoch: 6| Step: 9
Training loss: 3.040843608403603
Validation loss: 2.582943238514788

Epoch: 6| Step: 10
Training loss: 2.3229774045202465
Validation loss: 2.5714844092551923

Epoch: 6| Step: 11
Training loss: 2.3641476895047244
Validation loss: 2.596712626781682

Epoch: 6| Step: 12
Training loss: 2.5374462441448977
Validation loss: 2.5969239143801666

Epoch: 6| Step: 13
Training loss: 3.0594652671083047
Validation loss: 2.560824581090025

Epoch: 218| Step: 0
Training loss: 2.521379322372256
Validation loss: 2.5552366128875286

Epoch: 6| Step: 1
Training loss: 2.6311009670647687
Validation loss: 2.5664871914039336

Epoch: 6| Step: 2
Training loss: 2.138736086364828
Validation loss: 2.5838533414663223

Epoch: 6| Step: 3
Training loss: 2.6472862239473587
Validation loss: 2.5889636940467646

Epoch: 6| Step: 4
Training loss: 1.7742993113521317
Validation loss: 2.5720374574822342

Epoch: 6| Step: 5
Training loss: 2.8025922254076283
Validation loss: 2.6107427018891207

Epoch: 6| Step: 6
Training loss: 3.0653898656421092
Validation loss: 2.5921784280427613

Epoch: 6| Step: 7
Training loss: 2.310526237492365
Validation loss: 2.5687468465229757

Epoch: 6| Step: 8
Training loss: 2.6870154010429292
Validation loss: 2.5853192466126944

Epoch: 6| Step: 9
Training loss: 3.219368884392397
Validation loss: 2.6000939346711274

Epoch: 6| Step: 10
Training loss: 2.9396902806116927
Validation loss: 2.604799287475421

Epoch: 6| Step: 11
Training loss: 2.609115587691136
Validation loss: 2.5907965532847226

Epoch: 6| Step: 12
Training loss: 2.7600548465089068
Validation loss: 2.594157630071894

Epoch: 6| Step: 13
Training loss: 2.753074054917806
Validation loss: 2.562863784046986

Epoch: 219| Step: 0
Training loss: 3.462052624166415
Validation loss: 2.576629716657609

Epoch: 6| Step: 1
Training loss: 2.237727284742023
Validation loss: 2.5650134861639207

Epoch: 6| Step: 2
Training loss: 2.8094158640638125
Validation loss: 2.614995875747375

Epoch: 6| Step: 3
Training loss: 2.867313891543219
Validation loss: 2.5896163462210096

Epoch: 6| Step: 4
Training loss: 2.670038852766147
Validation loss: 2.5672976793563245

Epoch: 6| Step: 5
Training loss: 2.2969284570402873
Validation loss: 2.5779375432620326

Epoch: 6| Step: 6
Training loss: 2.604898873707467
Validation loss: 2.549480727622193

Epoch: 6| Step: 7
Training loss: 2.196861073869001
Validation loss: 2.576755735566042

Epoch: 6| Step: 8
Training loss: 3.066556929269643
Validation loss: 2.6071027358180627

Epoch: 6| Step: 9
Training loss: 2.9221122767753216
Validation loss: 2.619260954182115

Epoch: 6| Step: 10
Training loss: 1.9621333393241223
Validation loss: 2.6155267227780628

Epoch: 6| Step: 11
Training loss: 2.3084632074978138
Validation loss: 2.557963634090684

Epoch: 6| Step: 12
Training loss: 2.589842645291054
Validation loss: 2.5727470715370364

Epoch: 6| Step: 13
Training loss: 2.381650647678343
Validation loss: 2.5797843309074597

Epoch: 220| Step: 0
Training loss: 2.1103943798800144
Validation loss: 2.6174758074002527

Epoch: 6| Step: 1
Training loss: 2.918695525287956
Validation loss: 2.5867709794539038

Epoch: 6| Step: 2
Training loss: 2.5710011403256723
Validation loss: 2.5735243671285413

Epoch: 6| Step: 3
Training loss: 2.3349981045766324
Validation loss: 2.57976795895226

Epoch: 6| Step: 4
Training loss: 2.3772533167632277
Validation loss: 2.589236791902128

Epoch: 6| Step: 5
Training loss: 3.0072439473806605
Validation loss: 2.558823590169527

Epoch: 6| Step: 6
Training loss: 2.091282657566669
Validation loss: 2.576865554650233

Epoch: 6| Step: 7
Training loss: 2.374942678462507
Validation loss: 2.593840294916993

Epoch: 6| Step: 8
Training loss: 2.3416681834947917
Validation loss: 2.546668572700821

Epoch: 6| Step: 9
Training loss: 2.7845289639463098
Validation loss: 2.575163652998192

Epoch: 6| Step: 10
Training loss: 2.543594775513396
Validation loss: 2.589715032398429

Epoch: 6| Step: 11
Training loss: 3.8165800431817467
Validation loss: 2.576213805697161

Epoch: 6| Step: 12
Training loss: 2.5455459216053176
Validation loss: 2.5548171294342845

Epoch: 6| Step: 13
Training loss: 3.30672556119687
Validation loss: 2.543558717310118

Epoch: 221| Step: 0
Training loss: 3.2593586497934526
Validation loss: 2.605991750427382

Epoch: 6| Step: 1
Training loss: 2.3111609628794554
Validation loss: 2.5573116283582924

Epoch: 6| Step: 2
Training loss: 2.2838363617768827
Validation loss: 2.604464538930203

Epoch: 6| Step: 3
Training loss: 2.342504755461109
Validation loss: 2.545266389368387

Epoch: 6| Step: 4
Training loss: 1.8883047447273866
Validation loss: 2.5726634337666163

Epoch: 6| Step: 5
Training loss: 3.3987989211551355
Validation loss: 2.5895775163647365

Epoch: 6| Step: 6
Training loss: 2.786379167139251
Validation loss: 2.571305501403076

Epoch: 6| Step: 7
Training loss: 2.954794759835936
Validation loss: 2.573219875965853

Epoch: 6| Step: 8
Training loss: 2.3659767604921575
Validation loss: 2.586290375633217

Epoch: 6| Step: 9
Training loss: 2.2697247473585804
Validation loss: 2.588761381461559

Epoch: 6| Step: 10
Training loss: 2.592813713493675
Validation loss: 2.5551915136483445

Epoch: 6| Step: 11
Training loss: 2.0900536547622783
Validation loss: 2.567333208427763

Epoch: 6| Step: 12
Training loss: 2.725471081392909
Validation loss: 2.5734350748265697

Epoch: 6| Step: 13
Training loss: 3.080736940083353
Validation loss: 2.5459328453959604

Epoch: 222| Step: 0
Training loss: 2.110375513225959
Validation loss: 2.63648517359486

Epoch: 6| Step: 1
Training loss: 3.357117928177592
Validation loss: 2.591292959929525

Epoch: 6| Step: 2
Training loss: 2.6696512884671213
Validation loss: 2.563838721097566

Epoch: 6| Step: 3
Training loss: 2.4725449764531073
Validation loss: 2.600641371033397

Epoch: 6| Step: 4
Training loss: 2.1335481485852488
Validation loss: 2.587828042219165

Epoch: 6| Step: 5
Training loss: 3.2600651918223416
Validation loss: 2.585271442408034

Epoch: 6| Step: 6
Training loss: 2.262764749791
Validation loss: 2.611650113322675

Epoch: 6| Step: 7
Training loss: 3.241342310298957
Validation loss: 2.575433620337997

Epoch: 6| Step: 8
Training loss: 2.805769942583163
Validation loss: 2.5894751133519183

Epoch: 6| Step: 9
Training loss: 2.619704854953911
Validation loss: 2.6223403281695528

Epoch: 6| Step: 10
Training loss: 2.2252956065428755
Validation loss: 2.569986541583209

Epoch: 6| Step: 11
Training loss: 2.367966828932277
Validation loss: 2.5999999779526903

Epoch: 6| Step: 12
Training loss: 2.5192291788397454
Validation loss: 2.6202321591174362

Epoch: 6| Step: 13
Training loss: 2.848865812055755
Validation loss: 2.5787246479070287

Epoch: 223| Step: 0
Training loss: 2.7241038957631756
Validation loss: 2.6079333786354675

Epoch: 6| Step: 1
Training loss: 2.5906268700752824
Validation loss: 2.5695320792544436

Epoch: 6| Step: 2
Training loss: 2.506954533588071
Validation loss: 2.6093199789637262

Epoch: 6| Step: 3
Training loss: 2.2953673104947474
Validation loss: 2.6033931874753735

Epoch: 6| Step: 4
Training loss: 2.446080681306913
Validation loss: 2.612733953070322

Epoch: 6| Step: 5
Training loss: 2.8128134658755877
Validation loss: 2.5726310445566587

Epoch: 6| Step: 6
Training loss: 2.6038362115367413
Validation loss: 2.557333072208274

Epoch: 6| Step: 7
Training loss: 2.714950713101944
Validation loss: 2.5742189382233445

Epoch: 6| Step: 8
Training loss: 2.4851869419940456
Validation loss: 2.586429666218205

Epoch: 6| Step: 9
Training loss: 2.9193773661403584
Validation loss: 2.5950822666625504

Epoch: 6| Step: 10
Training loss: 2.714703497248348
Validation loss: 2.6050462998493273

Epoch: 6| Step: 11
Training loss: 2.8990060089354333
Validation loss: 2.6030575234046998

Epoch: 6| Step: 12
Training loss: 2.3930235156232134
Validation loss: 2.5884002447518215

Epoch: 6| Step: 13
Training loss: 2.9977624814216903
Validation loss: 2.582136520665622

Epoch: 224| Step: 0
Training loss: 2.2765525634381207
Validation loss: 2.580073565232155

Epoch: 6| Step: 1
Training loss: 2.2956868945968396
Validation loss: 2.607822975720557

Epoch: 6| Step: 2
Training loss: 2.9631246173876904
Validation loss: 2.5779693014562675

Epoch: 6| Step: 3
Training loss: 2.5107385790400945
Validation loss: 2.5798662795526717

Epoch: 6| Step: 4
Training loss: 3.129513951792337
Validation loss: 2.5529940776749593

Epoch: 6| Step: 5
Training loss: 2.8325167956616033
Validation loss: 2.575328373323639

Epoch: 6| Step: 6
Training loss: 2.0038149926299886
Validation loss: 2.6147436499650047

Epoch: 6| Step: 7
Training loss: 3.0987611510217343
Validation loss: 2.573530198639394

Epoch: 6| Step: 8
Training loss: 2.9515998575442395
Validation loss: 2.571263014081143

Epoch: 6| Step: 9
Training loss: 3.2260662001967284
Validation loss: 2.5618152919168233

Epoch: 6| Step: 10
Training loss: 2.0736915507480957
Validation loss: 2.5786348874703284

Epoch: 6| Step: 11
Training loss: 2.8913025757808186
Validation loss: 2.5742185866739122

Epoch: 6| Step: 12
Training loss: 2.296777009495623
Validation loss: 2.565764930628971

Epoch: 6| Step: 13
Training loss: 1.6114514482873439
Validation loss: 2.573825331140818

Epoch: 225| Step: 0
Training loss: 1.6171583090096424
Validation loss: 2.5608832939113344

Epoch: 6| Step: 1
Training loss: 2.230541542054597
Validation loss: 2.5563647809687664

Epoch: 6| Step: 2
Training loss: 2.892851430897397
Validation loss: 2.582190135291815

Epoch: 6| Step: 3
Training loss: 2.1681686721586435
Validation loss: 2.5797753186434287

Epoch: 6| Step: 4
Training loss: 4.034432980617928
Validation loss: 2.5523086625844114

Epoch: 6| Step: 5
Training loss: 2.5272994118623355
Validation loss: 2.5964475684381316

Epoch: 6| Step: 6
Training loss: 2.688179107738769
Validation loss: 2.5578584429943225

Epoch: 6| Step: 7
Training loss: 2.6067999280181775
Validation loss: 2.6280771337145716

Epoch: 6| Step: 8
Training loss: 2.617241520110642
Validation loss: 2.5465672942065534

Epoch: 6| Step: 9
Training loss: 1.982369438191968
Validation loss: 2.549622717953632

Epoch: 6| Step: 10
Training loss: 2.9009165071966607
Validation loss: 2.5751729327707995

Epoch: 6| Step: 11
Training loss: 2.744381540386666
Validation loss: 2.5928955143318544

Epoch: 6| Step: 12
Training loss: 2.2101969742486816
Validation loss: 2.5898410654376565

Epoch: 6| Step: 13
Training loss: 3.107066922442236
Validation loss: 2.574147701177694

Epoch: 226| Step: 0
Training loss: 2.380780063024742
Validation loss: 2.591784980112903

Epoch: 6| Step: 1
Training loss: 2.2402660896430997
Validation loss: 2.5998201195214095

Epoch: 6| Step: 2
Training loss: 2.228420405982305
Validation loss: 2.5511392929639385

Epoch: 6| Step: 3
Training loss: 2.379373839578228
Validation loss: 2.5628518263956117

Epoch: 6| Step: 4
Training loss: 2.2809487757970492
Validation loss: 2.5981277919881385

Epoch: 6| Step: 5
Training loss: 2.6727705675981697
Validation loss: 2.594858943865845

Epoch: 6| Step: 6
Training loss: 2.2651252984764114
Validation loss: 2.584982547689592

Epoch: 6| Step: 7
Training loss: 2.8576554928422504
Validation loss: 2.564412717487825

Epoch: 6| Step: 8
Training loss: 2.79142690929046
Validation loss: 2.566291224507178

Epoch: 6| Step: 9
Training loss: 2.2922391234281405
Validation loss: 2.586860680559993

Epoch: 6| Step: 10
Training loss: 3.325341865346079
Validation loss: 2.5831026820469543

Epoch: 6| Step: 11
Training loss: 2.6269560292734875
Validation loss: 2.5788350877196833

Epoch: 6| Step: 12
Training loss: 3.4340626957301708
Validation loss: 2.559368512156684

Epoch: 6| Step: 13
Training loss: 2.7192315738408253
Validation loss: 2.5782180565490314

Epoch: 227| Step: 0
Training loss: 2.77260402996797
Validation loss: 2.606577405561262

Epoch: 6| Step: 1
Training loss: 2.574929030838516
Validation loss: 2.560058562205925

Epoch: 6| Step: 2
Training loss: 2.7162808134505405
Validation loss: 2.6194466173422106

Epoch: 6| Step: 3
Training loss: 3.0899437503571314
Validation loss: 2.6124759704172424

Epoch: 6| Step: 4
Training loss: 1.9318255113268845
Validation loss: 2.5654178087621284

Epoch: 6| Step: 5
Training loss: 3.3721011392668556
Validation loss: 2.5563878332897896

Epoch: 6| Step: 6
Training loss: 2.6998915544559847
Validation loss: 2.56960045920011

Epoch: 6| Step: 7
Training loss: 1.6356203312819964
Validation loss: 2.56696984005832

Epoch: 6| Step: 8
Training loss: 2.6223315345030964
Validation loss: 2.55289464581557

Epoch: 6| Step: 9
Training loss: 2.7106911495089445
Validation loss: 2.5712690900086104

Epoch: 6| Step: 10
Training loss: 2.6527081381115822
Validation loss: 2.5932884186126333

Epoch: 6| Step: 11
Training loss: 2.6233477160759526
Validation loss: 2.612890595114136

Epoch: 6| Step: 12
Training loss: 2.384644751332444
Validation loss: 2.577919030437485

Epoch: 6| Step: 13
Training loss: 2.964367010213181
Validation loss: 2.578608982850699

Epoch: 228| Step: 0
Training loss: 1.8929504721117676
Validation loss: 2.5841114960804688

Epoch: 6| Step: 1
Training loss: 3.2151574390833897
Validation loss: 2.609930796554625

Epoch: 6| Step: 2
Training loss: 2.4060012887014235
Validation loss: 2.603246070492566

Epoch: 6| Step: 3
Training loss: 2.786356492127435
Validation loss: 2.580744601071991

Epoch: 6| Step: 4
Training loss: 2.429635491995127
Validation loss: 2.57134690128991

Epoch: 6| Step: 5
Training loss: 3.0840613734252615
Validation loss: 2.557819852664875

Epoch: 6| Step: 6
Training loss: 2.9657193425148805
Validation loss: 2.5555789011123298

Epoch: 6| Step: 7
Training loss: 1.9141189255474478
Validation loss: 2.5953971277308066

Epoch: 6| Step: 8
Training loss: 3.0477073119500773
Validation loss: 2.5554609675407454

Epoch: 6| Step: 9
Training loss: 2.8063983427740964
Validation loss: 2.6020641504096207

Epoch: 6| Step: 10
Training loss: 2.3511014467368057
Validation loss: 2.5549644362007364

Epoch: 6| Step: 11
Training loss: 2.248332147204419
Validation loss: 2.5615192110060407

Epoch: 6| Step: 12
Training loss: 2.423313722579223
Validation loss: 2.5685270239369706

Epoch: 6| Step: 13
Training loss: 2.859253093851558
Validation loss: 2.588179294168347

Epoch: 229| Step: 0
Training loss: 2.607051157225182
Validation loss: 2.5877150913980165

Epoch: 6| Step: 1
Training loss: 1.596002744375943
Validation loss: 2.6191201991164568

Epoch: 6| Step: 2
Training loss: 2.4654336214430805
Validation loss: 2.5910867073452084

Epoch: 6| Step: 3
Training loss: 2.5302764527432826
Validation loss: 2.5968453531229114

Epoch: 6| Step: 4
Training loss: 3.2277583014607716
Validation loss: 2.5772278518364806

Epoch: 6| Step: 5
Training loss: 3.08608444443459
Validation loss: 2.5724063088299514

Epoch: 6| Step: 6
Training loss: 2.6720070611095212
Validation loss: 2.605996727206602

Epoch: 6| Step: 7
Training loss: 1.9233740566025992
Validation loss: 2.5692245335708552

Epoch: 6| Step: 8
Training loss: 2.546299500768424
Validation loss: 2.600655337420073

Epoch: 6| Step: 9
Training loss: 3.207027681560134
Validation loss: 2.5865882550654367

Epoch: 6| Step: 10
Training loss: 3.5217343292981695
Validation loss: 2.562788450111932

Epoch: 6| Step: 11
Training loss: 1.9375156894171646
Validation loss: 2.584715822262285

Epoch: 6| Step: 12
Training loss: 2.370318567297154
Validation loss: 2.553381424025303

Epoch: 6| Step: 13
Training loss: 2.115540824804569
Validation loss: 2.572620967376429

Epoch: 230| Step: 0
Training loss: 2.2503458393065663
Validation loss: 2.584013280458127

Epoch: 6| Step: 1
Training loss: 2.5671957766956126
Validation loss: 2.5755878074263827

Epoch: 6| Step: 2
Training loss: 2.818459195109461
Validation loss: 2.589146497835029

Epoch: 6| Step: 3
Training loss: 3.167873018937364
Validation loss: 2.542368410880676

Epoch: 6| Step: 4
Training loss: 2.406361564923305
Validation loss: 2.568599783222736

Epoch: 6| Step: 5
Training loss: 1.9883991798546528
Validation loss: 2.5329590262511736

Epoch: 6| Step: 6
Training loss: 2.3518516388117354
Validation loss: 2.558671896651564

Epoch: 6| Step: 7
Training loss: 2.9132545312427047
Validation loss: 2.608776862761293

Epoch: 6| Step: 8
Training loss: 2.7483328187231444
Validation loss: 2.569518018528516

Epoch: 6| Step: 9
Training loss: 3.0197374833557618
Validation loss: 2.5852508242912005

Epoch: 6| Step: 10
Training loss: 2.711151730210545
Validation loss: 2.5756963682088747

Epoch: 6| Step: 11
Training loss: 2.327690237529132
Validation loss: 2.581151575537389

Epoch: 6| Step: 12
Training loss: 2.563642758749457
Validation loss: 2.593921946758861

Epoch: 6| Step: 13
Training loss: 2.4792264936478516
Validation loss: 2.605880103395282

Epoch: 231| Step: 0
Training loss: 2.631928156721523
Validation loss: 2.5778261749218445

Epoch: 6| Step: 1
Training loss: 2.3692646041344343
Validation loss: 2.600686216393152

Epoch: 6| Step: 2
Training loss: 2.673849257614855
Validation loss: 2.577571947050001

Epoch: 6| Step: 3
Training loss: 2.5290040778281453
Validation loss: 2.5914699200680813

Epoch: 6| Step: 4
Training loss: 2.1579333382705395
Validation loss: 2.6044534150449437

Epoch: 6| Step: 5
Training loss: 2.539871415615627
Validation loss: 2.5941765497861087

Epoch: 6| Step: 6
Training loss: 3.2472714928278363
Validation loss: 2.576626680538776

Epoch: 6| Step: 7
Training loss: 2.6059597301987383
Validation loss: 2.5836519543678764

Epoch: 6| Step: 8
Training loss: 2.948255935035437
Validation loss: 2.609163469889106

Epoch: 6| Step: 9
Training loss: 2.4922739809152734
Validation loss: 2.567583099814368

Epoch: 6| Step: 10
Training loss: 2.6823301047129555
Validation loss: 2.6055191167265583

Epoch: 6| Step: 11
Training loss: 2.8857601984949777
Validation loss: 2.625554488646408

Epoch: 6| Step: 12
Training loss: 2.44362350487706
Validation loss: 2.573244225864942

Epoch: 6| Step: 13
Training loss: 2.02576021594725
Validation loss: 2.608101717667566

Epoch: 232| Step: 0
Training loss: 3.2891851479322245
Validation loss: 2.5727336197843877

Epoch: 6| Step: 1
Training loss: 2.8567880069537543
Validation loss: 2.601064874672647

Epoch: 6| Step: 2
Training loss: 2.4647719770280325
Validation loss: 2.631810241898883

Epoch: 6| Step: 3
Training loss: 2.611372679827454
Validation loss: 2.597043039038765

Epoch: 6| Step: 4
Training loss: 2.240650673776377
Validation loss: 2.5679528041113544

Epoch: 6| Step: 5
Training loss: 3.099437533388351
Validation loss: 2.6007282604951443

Epoch: 6| Step: 6
Training loss: 2.337012716491341
Validation loss: 2.6012055482485277

Epoch: 6| Step: 7
Training loss: 2.3279820340698825
Validation loss: 2.5735792907902635

Epoch: 6| Step: 8
Training loss: 2.796748067863181
Validation loss: 2.5740622848331003

Epoch: 6| Step: 9
Training loss: 2.716143531591087
Validation loss: 2.5866321819910985

Epoch: 6| Step: 10
Training loss: 2.1812834554035803
Validation loss: 2.5765471461839375

Epoch: 6| Step: 11
Training loss: 2.317168703729659
Validation loss: 2.5750982989178093

Epoch: 6| Step: 12
Training loss: 2.7468409166185284
Validation loss: 2.6019951003924557

Epoch: 6| Step: 13
Training loss: 1.7847782461012762
Validation loss: 2.5658284262286473

Epoch: 233| Step: 0
Training loss: 2.6296601482743664
Validation loss: 2.552383100539263

Epoch: 6| Step: 1
Training loss: 1.9225782642878317
Validation loss: 2.5550199223836887

Epoch: 6| Step: 2
Training loss: 2.983093785590787
Validation loss: 2.584521280173215

Epoch: 6| Step: 3
Training loss: 2.950353219820315
Validation loss: 2.577927025893705

Epoch: 6| Step: 4
Training loss: 2.8229320755616603
Validation loss: 2.6031666797629462

Epoch: 6| Step: 5
Training loss: 2.074575045169972
Validation loss: 2.5990328687545587

Epoch: 6| Step: 6
Training loss: 2.550403420943068
Validation loss: 2.576855830545025

Epoch: 6| Step: 7
Training loss: 2.772574620941071
Validation loss: 2.6115228553334413

Epoch: 6| Step: 8
Training loss: 2.002282032813615
Validation loss: 2.6047155563910644

Epoch: 6| Step: 9
Training loss: 2.560203826061793
Validation loss: 2.596928137548069

Epoch: 6| Step: 10
Training loss: 3.337585470983934
Validation loss: 2.6009095937734084

Epoch: 6| Step: 11
Training loss: 1.749002717458229
Validation loss: 2.60848542238237

Epoch: 6| Step: 12
Training loss: 2.4289788196970483
Validation loss: 2.5866895240875984

Epoch: 6| Step: 13
Training loss: 3.5345447664781093
Validation loss: 2.5765060159220843

Epoch: 234| Step: 0
Training loss: 2.5279053619754053
Validation loss: 2.5766963377459393

Epoch: 6| Step: 1
Training loss: 2.8635088945893097
Validation loss: 2.5517309237258634

Epoch: 6| Step: 2
Training loss: 2.4631182015631783
Validation loss: 2.553921531539904

Epoch: 6| Step: 3
Training loss: 2.6968916979788866
Validation loss: 2.5616927937699825

Epoch: 6| Step: 4
Training loss: 1.5225463608321352
Validation loss: 2.5810349981681937

Epoch: 6| Step: 5
Training loss: 2.6086756517154965
Validation loss: 2.5522296501106805

Epoch: 6| Step: 6
Training loss: 3.035523852618268
Validation loss: 2.5856303965897505

Epoch: 6| Step: 7
Training loss: 3.5553493009454638
Validation loss: 2.5831269973404924

Epoch: 6| Step: 8
Training loss: 2.5837431756876685
Validation loss: 2.59331543305586

Epoch: 6| Step: 9
Training loss: 2.139684762998925
Validation loss: 2.573465850064449

Epoch: 6| Step: 10
Training loss: 3.04119170848394
Validation loss: 2.5968943678076637

Epoch: 6| Step: 11
Training loss: 2.4555077127635756
Validation loss: 2.614616404292654

Epoch: 6| Step: 12
Training loss: 2.1548940845845737
Validation loss: 2.552788933522756

Epoch: 6| Step: 13
Training loss: 1.7847161282617983
Validation loss: 2.580246953947478

Epoch: 235| Step: 0
Training loss: 2.8248157846258812
Validation loss: 2.591620461464504

Epoch: 6| Step: 1
Training loss: 2.918567927887721
Validation loss: 2.591275897909661

Epoch: 6| Step: 2
Training loss: 2.493140728935072
Validation loss: 2.555414207920947

Epoch: 6| Step: 3
Training loss: 2.8692911938240173
Validation loss: 2.547036685286925

Epoch: 6| Step: 4
Training loss: 2.784306250685693
Validation loss: 2.5746409720547807

Epoch: 6| Step: 5
Training loss: 2.592344063876151
Validation loss: 2.592990421545367

Epoch: 6| Step: 6
Training loss: 2.935962680548284
Validation loss: 2.584359351951457

Epoch: 6| Step: 7
Training loss: 2.2359545266538117
Validation loss: 2.604925050297931

Epoch: 6| Step: 8
Training loss: 3.3180640652239033
Validation loss: 2.6261779361127333

Epoch: 6| Step: 9
Training loss: 2.002275721912154
Validation loss: 2.576118776001401

Epoch: 6| Step: 10
Training loss: 2.2315082432660662
Validation loss: 2.587373867034995

Epoch: 6| Step: 11
Training loss: 2.0871777222894523
Validation loss: 2.59420731218591

Epoch: 6| Step: 12
Training loss: 2.665653592634972
Validation loss: 2.5695715871578115

Epoch: 6| Step: 13
Training loss: 2.7473958429755383
Validation loss: 2.6159776369711794

Epoch: 236| Step: 0
Training loss: 2.4676917016910207
Validation loss: 2.5296425262077156

Epoch: 6| Step: 1
Training loss: 1.9969074658544042
Validation loss: 2.5678728084199194

Epoch: 6| Step: 2
Training loss: 2.7341062577199553
Validation loss: 2.5897230349927747

Epoch: 6| Step: 3
Training loss: 2.977351366972758
Validation loss: 2.5483091468553636

Epoch: 6| Step: 4
Training loss: 2.8030089559531057
Validation loss: 2.57000804027629

Epoch: 6| Step: 5
Training loss: 2.064729468148756
Validation loss: 2.6321541100603065

Epoch: 6| Step: 6
Training loss: 2.9326485687111363
Validation loss: 2.5784709639871832

Epoch: 6| Step: 7
Training loss: 2.8678543188532153
Validation loss: 2.5683055105791373

Epoch: 6| Step: 8
Training loss: 2.4129365437112207
Validation loss: 2.5893243600994365

Epoch: 6| Step: 9
Training loss: 2.735771476549058
Validation loss: 2.583867920478459

Epoch: 6| Step: 10
Training loss: 2.5052121189482723
Validation loss: 2.5906104825268903

Epoch: 6| Step: 11
Training loss: 2.8852617977368173
Validation loss: 2.596428357212383

Epoch: 6| Step: 12
Training loss: 2.2118459392103396
Validation loss: 2.606848777169644

Epoch: 6| Step: 13
Training loss: 2.724040966835
Validation loss: 2.614838743626473

Epoch: 237| Step: 0
Training loss: 2.110554909077458
Validation loss: 2.5750858674475623

Epoch: 6| Step: 1
Training loss: 2.687767813889551
Validation loss: 2.5958227441772186

Epoch: 6| Step: 2
Training loss: 2.5813745537880743
Validation loss: 2.5942313386027056

Epoch: 6| Step: 3
Training loss: 2.989704745460136
Validation loss: 2.5881983655499345

Epoch: 6| Step: 4
Training loss: 2.2896179983368636
Validation loss: 2.594350395686665

Epoch: 6| Step: 5
Training loss: 3.1578630914273687
Validation loss: 2.6011485941615935

Epoch: 6| Step: 6
Training loss: 2.5939053408513897
Validation loss: 2.5568441516497438

Epoch: 6| Step: 7
Training loss: 2.082292894595536
Validation loss: 2.5752438980578916

Epoch: 6| Step: 8
Training loss: 2.534183074419702
Validation loss: 2.570476275543487

Epoch: 6| Step: 9
Training loss: 3.3998316218252183
Validation loss: 2.600271796423026

Epoch: 6| Step: 10
Training loss: 2.7455208453441466
Validation loss: 2.5893400934274804

Epoch: 6| Step: 11
Training loss: 2.0019294253551454
Validation loss: 2.5729786748855

Epoch: 6| Step: 12
Training loss: 1.6762092239461088
Validation loss: 2.6440729439749666

Epoch: 6| Step: 13
Training loss: 3.080885989834879
Validation loss: 2.5909934817141314

Epoch: 238| Step: 0
Training loss: 2.5537706882350224
Validation loss: 2.569777840695845

Epoch: 6| Step: 1
Training loss: 2.886119073051735
Validation loss: 2.546536305641528

Epoch: 6| Step: 2
Training loss: 2.7082068682757106
Validation loss: 2.5969543046487233

Epoch: 6| Step: 3
Training loss: 2.9558948263162486
Validation loss: 2.603831895209235

Epoch: 6| Step: 4
Training loss: 2.59207218550608
Validation loss: 2.5909412262232023

Epoch: 6| Step: 5
Training loss: 2.6294224134576694
Validation loss: 2.56855505834912

Epoch: 6| Step: 6
Training loss: 2.47444972461894
Validation loss: 2.6118222842836296

Epoch: 6| Step: 7
Training loss: 2.8221835959370227
Validation loss: 2.610217482995307

Epoch: 6| Step: 8
Training loss: 2.320600189972245
Validation loss: 2.610512592390413

Epoch: 6| Step: 9
Training loss: 2.4234704453807123
Validation loss: 2.6017911298682894

Epoch: 6| Step: 10
Training loss: 2.888225157205688
Validation loss: 2.5740192474264676

Epoch: 6| Step: 11
Training loss: 2.4491371737436407
Validation loss: 2.621695032298446

Epoch: 6| Step: 12
Training loss: 2.446128246023927
Validation loss: 2.594901624770919

Epoch: 6| Step: 13
Training loss: 2.549531919864212
Validation loss: 2.6232437747576824

Epoch: 239| Step: 0
Training loss: 2.577112357352118
Validation loss: 2.5569838000690353

Epoch: 6| Step: 1
Training loss: 2.0251472937620822
Validation loss: 2.5883517080591276

Epoch: 6| Step: 2
Training loss: 2.045242473898529
Validation loss: 2.600243434521604

Epoch: 6| Step: 3
Training loss: 2.735164157885419
Validation loss: 2.6370298043388525

Epoch: 6| Step: 4
Training loss: 3.21413349820556
Validation loss: 2.6388786450287784

Epoch: 6| Step: 5
Training loss: 2.5263529372725757
Validation loss: 2.6278782118508275

Epoch: 6| Step: 6
Training loss: 3.0683158614037436
Validation loss: 2.5525471566982865

Epoch: 6| Step: 7
Training loss: 2.498409051118861
Validation loss: 2.587807460322385

Epoch: 6| Step: 8
Training loss: 2.4924399508146124
Validation loss: 2.5761379983673214

Epoch: 6| Step: 9
Training loss: 2.68437998441471
Validation loss: 2.5524167420461166

Epoch: 6| Step: 10
Training loss: 2.6181041421831193
Validation loss: 2.6092123612538334

Epoch: 6| Step: 11
Training loss: 2.494091681685016
Validation loss: 2.577335573650999

Epoch: 6| Step: 12
Training loss: 2.4766044733479804
Validation loss: 2.5781261992241986

Epoch: 6| Step: 13
Training loss: 3.1230610745162655
Validation loss: 2.6264980351514318

Epoch: 240| Step: 0
Training loss: 1.7474684115107504
Validation loss: 2.597534184714785

Epoch: 6| Step: 1
Training loss: 2.602264584494129
Validation loss: 2.583070522982898

Epoch: 6| Step: 2
Training loss: 2.5535656626938272
Validation loss: 2.585697466417471

Epoch: 6| Step: 3
Training loss: 2.684013855769043
Validation loss: 2.570842319399094

Epoch: 6| Step: 4
Training loss: 2.9682221595925546
Validation loss: 2.6145190767194655

Epoch: 6| Step: 5
Training loss: 2.6604916085302843
Validation loss: 2.617479685460003

Epoch: 6| Step: 6
Training loss: 2.6715000179461406
Validation loss: 2.5349835735922386

Epoch: 6| Step: 7
Training loss: 1.8357878279042545
Validation loss: 2.6025503433100954

Epoch: 6| Step: 8
Training loss: 2.5385987782670667
Validation loss: 2.6234162842100717

Epoch: 6| Step: 9
Training loss: 1.6037560304809317
Validation loss: 2.588571547587929

Epoch: 6| Step: 10
Training loss: 3.647297389029109
Validation loss: 2.5593187968276

Epoch: 6| Step: 11
Training loss: 2.693727065694586
Validation loss: 2.585999994700366

Epoch: 6| Step: 12
Training loss: 2.4732732741200603
Validation loss: 2.5998912171670794

Epoch: 6| Step: 13
Training loss: 2.6819845869459202
Validation loss: 2.5866360701181867

Epoch: 241| Step: 0
Training loss: 2.597874865976978
Validation loss: 2.622214144296905

Epoch: 6| Step: 1
Training loss: 3.266251353377811
Validation loss: 2.5846699092926677

Epoch: 6| Step: 2
Training loss: 2.7021670545923087
Validation loss: 2.556573141849342

Epoch: 6| Step: 3
Training loss: 2.040857102658209
Validation loss: 2.580784826383249

Epoch: 6| Step: 4
Training loss: 2.403924189548048
Validation loss: 2.590989786141499

Epoch: 6| Step: 5
Training loss: 2.3254393377829694
Validation loss: 2.5759315156243185

Epoch: 6| Step: 6
Training loss: 2.585332794017581
Validation loss: 2.5396174463172563

Epoch: 6| Step: 7
Training loss: 2.068345888434253
Validation loss: 2.5694871112001123

Epoch: 6| Step: 8
Training loss: 2.873421277015446
Validation loss: 2.591104834216709

Epoch: 6| Step: 9
Training loss: 2.55534676260952
Validation loss: 2.556486859532631

Epoch: 6| Step: 10
Training loss: 2.593771876966757
Validation loss: 2.5577628145244415

Epoch: 6| Step: 11
Training loss: 2.532625178023467
Validation loss: 2.5849365958199755

Epoch: 6| Step: 12
Training loss: 3.055213200049042
Validation loss: 2.5925468365423634

Epoch: 6| Step: 13
Training loss: 2.894514611488532
Validation loss: 2.5914699418318277

Epoch: 242| Step: 0
Training loss: 2.7247546304246386
Validation loss: 2.6071044079690844

Epoch: 6| Step: 1
Training loss: 2.49439412070726
Validation loss: 2.591266261766231

Epoch: 6| Step: 2
Training loss: 2.2186700511014017
Validation loss: 2.5814105117972925

Epoch: 6| Step: 3
Training loss: 2.453351247279789
Validation loss: 2.5533584821133997

Epoch: 6| Step: 4
Training loss: 2.547780256344558
Validation loss: 2.594445813405492

Epoch: 6| Step: 5
Training loss: 2.7701681289878612
Validation loss: 2.6009690162300165

Epoch: 6| Step: 6
Training loss: 2.7963378219898902
Validation loss: 2.5972666853323463

Epoch: 6| Step: 7
Training loss: 2.8287829903479578
Validation loss: 2.5731822896345395

Epoch: 6| Step: 8
Training loss: 2.0675968425169438
Validation loss: 2.5621125793519544

Epoch: 6| Step: 9
Training loss: 2.642489345099587
Validation loss: 2.601527970533954

Epoch: 6| Step: 10
Training loss: 2.5734128486457815
Validation loss: 2.588321150423732

Epoch: 6| Step: 11
Training loss: 2.6882427874659673
Validation loss: 2.5978252599241487

Epoch: 6| Step: 12
Training loss: 2.6053823659780186
Validation loss: 2.59517730925606

Epoch: 6| Step: 13
Training loss: 2.9031685521007455
Validation loss: 2.5561216052798788

Epoch: 243| Step: 0
Training loss: 2.7192392018734974
Validation loss: 2.5669701256873796

Epoch: 6| Step: 1
Training loss: 2.2923466685028666
Validation loss: 2.5759663075848938

Epoch: 6| Step: 2
Training loss: 2.2674619396847
Validation loss: 2.583463327813573

Epoch: 6| Step: 3
Training loss: 1.444937662542164
Validation loss: 2.5971329736772706

Epoch: 6| Step: 4
Training loss: 2.9380278417463903
Validation loss: 2.599346167379658

Epoch: 6| Step: 5
Training loss: 2.508792958863508
Validation loss: 2.5831142650873735

Epoch: 6| Step: 6
Training loss: 2.3933437072330728
Validation loss: 2.577292948002345

Epoch: 6| Step: 7
Training loss: 2.4485666480751385
Validation loss: 2.599813094650564

Epoch: 6| Step: 8
Training loss: 2.0853830808004954
Validation loss: 2.5780078750709388

Epoch: 6| Step: 9
Training loss: 3.0619308565631482
Validation loss: 2.5758519807053797

Epoch: 6| Step: 10
Training loss: 3.283537730198142
Validation loss: 2.556344989722945

Epoch: 6| Step: 11
Training loss: 2.3666925196063895
Validation loss: 2.5990124367463703

Epoch: 6| Step: 12
Training loss: 2.6683960512388505
Validation loss: 2.591578970960202

Epoch: 6| Step: 13
Training loss: 3.6990711541222447
Validation loss: 2.57095655295337

Epoch: 244| Step: 0
Training loss: 2.382365600701898
Validation loss: 2.56792139175602

Epoch: 6| Step: 1
Training loss: 1.9801578917308795
Validation loss: 2.568338792801795

Epoch: 6| Step: 2
Training loss: 2.542825111750746
Validation loss: 2.5804129065961092

Epoch: 6| Step: 3
Training loss: 2.289880703979631
Validation loss: 2.5677133536960017

Epoch: 6| Step: 4
Training loss: 2.8058120045891233
Validation loss: 2.591958418690159

Epoch: 6| Step: 5
Training loss: 2.7613652069110164
Validation loss: 2.574013273603859

Epoch: 6| Step: 6
Training loss: 2.899196473973806
Validation loss: 2.5678995950593912

Epoch: 6| Step: 7
Training loss: 2.5066807174627
Validation loss: 2.5777802038838447

Epoch: 6| Step: 8
Training loss: 2.4983671578053124
Validation loss: 2.5893086454874443

Epoch: 6| Step: 9
Training loss: 3.2883118703934113
Validation loss: 2.5759186134488417

Epoch: 6| Step: 10
Training loss: 2.362030757745781
Validation loss: 2.6013959324874283

Epoch: 6| Step: 11
Training loss: 3.1144040331481486
Validation loss: 2.5868682123303013

Epoch: 6| Step: 12
Training loss: 2.0868716773377707
Validation loss: 2.6140250800648213

Epoch: 6| Step: 13
Training loss: 2.3804733050972273
Validation loss: 2.6135131001259517

Epoch: 245| Step: 0
Training loss: 2.3835105999022095
Validation loss: 2.5620439125035115

Epoch: 6| Step: 1
Training loss: 2.335675483221319
Validation loss: 2.5654347479635304

Epoch: 6| Step: 2
Training loss: 2.764120436212697
Validation loss: 2.5854536108828903

Epoch: 6| Step: 3
Training loss: 2.039508873032003
Validation loss: 2.546607359721909

Epoch: 6| Step: 4
Training loss: 2.7618699956375092
Validation loss: 2.5926084896346735

Epoch: 6| Step: 5
Training loss: 2.539147384398406
Validation loss: 2.581321913386258

Epoch: 6| Step: 6
Training loss: 2.150761128035981
Validation loss: 2.590936132957092

Epoch: 6| Step: 7
Training loss: 2.773067567895615
Validation loss: 2.5934636787872685

Epoch: 6| Step: 8
Training loss: 1.707951627126734
Validation loss: 2.5805270502854354

Epoch: 6| Step: 9
Training loss: 3.679415229070712
Validation loss: 2.5598515145455387

Epoch: 6| Step: 10
Training loss: 2.4335829733032854
Validation loss: 2.6139663643600084

Epoch: 6| Step: 11
Training loss: 2.597544640459464
Validation loss: 2.595272148830983

Epoch: 6| Step: 12
Training loss: 2.7514788379330235
Validation loss: 2.607471165750539

Epoch: 6| Step: 13
Training loss: 2.807526408179145
Validation loss: 2.5719584211356477

Epoch: 246| Step: 0
Training loss: 2.9350585531343576
Validation loss: 2.5649572596570898

Epoch: 6| Step: 1
Training loss: 2.3481905768677565
Validation loss: 2.566124607360883

Epoch: 6| Step: 2
Training loss: 2.3086178128042163
Validation loss: 2.591283004295148

Epoch: 6| Step: 3
Training loss: 2.4711272949874976
Validation loss: 2.617619177197252

Epoch: 6| Step: 4
Training loss: 2.592670721688324
Validation loss: 2.565950075527856

Epoch: 6| Step: 5
Training loss: 2.8107899023282616
Validation loss: 2.5849397635043148

Epoch: 6| Step: 6
Training loss: 2.9877559025549516
Validation loss: 2.5888123960691773

Epoch: 6| Step: 7
Training loss: 2.4562092241392186
Validation loss: 2.5680224829612066

Epoch: 6| Step: 8
Training loss: 2.3150573199366544
Validation loss: 2.588709622121386

Epoch: 6| Step: 9
Training loss: 2.7994570614437344
Validation loss: 2.5545243349779225

Epoch: 6| Step: 10
Training loss: 2.4757336694702112
Validation loss: 2.5808906495133925

Epoch: 6| Step: 11
Training loss: 2.916798143602409
Validation loss: 2.5939823219063856

Epoch: 6| Step: 12
Training loss: 2.281632169300641
Validation loss: 2.6059536112003174

Epoch: 6| Step: 13
Training loss: 2.463368211464024
Validation loss: 2.5959001493199243

Epoch: 247| Step: 0
Training loss: 2.595483774944659
Validation loss: 2.5364932486361385

Epoch: 6| Step: 1
Training loss: 2.42117240312706
Validation loss: 2.594413596329376

Epoch: 6| Step: 2
Training loss: 2.149823993309562
Validation loss: 2.575589687663344

Epoch: 6| Step: 3
Training loss: 2.6151034583783606
Validation loss: 2.5753436396782763

Epoch: 6| Step: 4
Training loss: 2.439267617984135
Validation loss: 2.5949769264377887

Epoch: 6| Step: 5
Training loss: 2.740000665205158
Validation loss: 2.5825242152522785

Epoch: 6| Step: 6
Training loss: 2.4140486732259774
Validation loss: 2.5941227213793505

Epoch: 6| Step: 7
Training loss: 2.0161884318799865
Validation loss: 2.5850118833072644

Epoch: 6| Step: 8
Training loss: 2.293371733780147
Validation loss: 2.5804251325801144

Epoch: 6| Step: 9
Training loss: 2.7943332993397676
Validation loss: 2.5628924325681792

Epoch: 6| Step: 10
Training loss: 2.6885082216681604
Validation loss: 2.5369946774225567

Epoch: 6| Step: 11
Training loss: 2.9579391395957164
Validation loss: 2.6247439027586683

Epoch: 6| Step: 12
Training loss: 3.072803525404334
Validation loss: 2.576710333432723

Epoch: 6| Step: 13
Training loss: 3.290890002470732
Validation loss: 2.599121398038666

Epoch: 248| Step: 0
Training loss: 2.876683447189571
Validation loss: 2.6232229786701566

Epoch: 6| Step: 1
Training loss: 2.650344297247325
Validation loss: 2.613744083229004

Epoch: 6| Step: 2
Training loss: 2.7548340877969117
Validation loss: 2.5697867842698536

Epoch: 6| Step: 3
Training loss: 2.407296980936305
Validation loss: 2.594844166768902

Epoch: 6| Step: 4
Training loss: 2.2238671837262434
Validation loss: 2.5485161896850763

Epoch: 6| Step: 5
Training loss: 2.1835839232085457
Validation loss: 2.5819867389196993

Epoch: 6| Step: 6
Training loss: 2.4113461912594722
Validation loss: 2.5506856667665123

Epoch: 6| Step: 7
Training loss: 3.006788361815075
Validation loss: 2.549953253002067

Epoch: 6| Step: 8
Training loss: 2.1507504861102364
Validation loss: 2.58722360965854

Epoch: 6| Step: 9
Training loss: 2.752625772372756
Validation loss: 2.594896420229721

Epoch: 6| Step: 10
Training loss: 1.9447683775994986
Validation loss: 2.5553894804541

Epoch: 6| Step: 11
Training loss: 3.0388447112274557
Validation loss: 2.544001793798778

Epoch: 6| Step: 12
Training loss: 3.107888024334493
Validation loss: 2.5840159532169524

Epoch: 6| Step: 13
Training loss: 2.8917094078166588
Validation loss: 2.576595361990645

Epoch: 249| Step: 0
Training loss: 2.2022586498889596
Validation loss: 2.5730159777387795

Epoch: 6| Step: 1
Training loss: 1.8862936042412293
Validation loss: 2.563779631982253

Epoch: 6| Step: 2
Training loss: 3.1266783212906795
Validation loss: 2.5891503802060747

Epoch: 6| Step: 3
Training loss: 2.970155563904272
Validation loss: 2.5720371285595505

Epoch: 6| Step: 4
Training loss: 3.0002104367518827
Validation loss: 2.618665484241969

Epoch: 6| Step: 5
Training loss: 2.2551688057927834
Validation loss: 2.5886862238188044

Epoch: 6| Step: 6
Training loss: 2.4212915517602354
Validation loss: 2.612257186738395

Epoch: 6| Step: 7
Training loss: 2.5297998112421736
Validation loss: 2.57808564007826

Epoch: 6| Step: 8
Training loss: 3.1126233486261388
Validation loss: 2.628423855498574

Epoch: 6| Step: 9
Training loss: 2.8084203165168944
Validation loss: 2.5938125624551

Epoch: 6| Step: 10
Training loss: 2.3809803407026484
Validation loss: 2.5916634637724285

Epoch: 6| Step: 11
Training loss: 2.130131975840246
Validation loss: 2.6376210953028525

Epoch: 6| Step: 12
Training loss: 2.4873004699120114
Validation loss: 2.57171025530339

Epoch: 6| Step: 13
Training loss: 2.6373153802699716
Validation loss: 2.587193281468685

Epoch: 250| Step: 0
Training loss: 3.0708304009667264
Validation loss: 2.547357330962865

Epoch: 6| Step: 1
Training loss: 2.475510238302683
Validation loss: 2.579953546740996

Epoch: 6| Step: 2
Training loss: 2.246513208115697
Validation loss: 2.5915644788529804

Epoch: 6| Step: 3
Training loss: 2.6133659132399303
Validation loss: 2.609649127023135

Epoch: 6| Step: 4
Training loss: 2.6693072556902777
Validation loss: 2.6130651591311542

Epoch: 6| Step: 5
Training loss: 3.0983414920277434
Validation loss: 2.5725907395849807

Epoch: 6| Step: 6
Training loss: 2.9130294645988553
Validation loss: 2.620560936385191

Epoch: 6| Step: 7
Training loss: 2.637312306600257
Validation loss: 2.6394010579678686

Epoch: 6| Step: 8
Training loss: 1.9755388707783137
Validation loss: 2.6137442705676754

Epoch: 6| Step: 9
Training loss: 2.166101039512909
Validation loss: 2.6024331552557447

Epoch: 6| Step: 10
Training loss: 2.5203337581563363
Validation loss: 2.6126972320098987

Epoch: 6| Step: 11
Training loss: 2.711771636069115
Validation loss: 2.6138221826743293

Epoch: 6| Step: 12
Training loss: 2.2934904528548676
Validation loss: 2.621204983754749

Epoch: 6| Step: 13
Training loss: 2.638344858095787
Validation loss: 2.6164370684600438

Epoch: 251| Step: 0
Training loss: 2.4356925327334875
Validation loss: 2.595522829547533

Epoch: 6| Step: 1
Training loss: 2.5235323578097995
Validation loss: 2.6307058644552965

Epoch: 6| Step: 2
Training loss: 2.5441520504407196
Validation loss: 2.610744465485749

Epoch: 6| Step: 3
Training loss: 2.388988258700222
Validation loss: 2.5782602284037837

Epoch: 6| Step: 4
Training loss: 2.877273987114162
Validation loss: 2.6167529339662057

Epoch: 6| Step: 5
Training loss: 2.2300490537303115
Validation loss: 2.623172923039453

Epoch: 6| Step: 6
Training loss: 2.4460658658782766
Validation loss: 2.5849710077319834

Epoch: 6| Step: 7
Training loss: 2.308046537501985
Validation loss: 2.5902150698281075

Epoch: 6| Step: 8
Training loss: 2.6280787442340414
Validation loss: 2.5861745473582736

Epoch: 6| Step: 9
Training loss: 3.5596693069653496
Validation loss: 2.587657684844693

Epoch: 6| Step: 10
Training loss: 2.917064766735994
Validation loss: 2.583252062662062

Epoch: 6| Step: 11
Training loss: 2.260251216429459
Validation loss: 2.6346414607736994

Epoch: 6| Step: 12
Training loss: 2.5167309717042756
Validation loss: 2.625306397236615

Epoch: 6| Step: 13
Training loss: 2.3482373830642547
Validation loss: 2.5664232226340102

Epoch: 252| Step: 0
Training loss: 2.6307625869584714
Validation loss: 2.578304746644476

Epoch: 6| Step: 1
Training loss: 1.7780471918818235
Validation loss: 2.561690385939394

Epoch: 6| Step: 2
Training loss: 2.2311606594973767
Validation loss: 2.591728598960554

Epoch: 6| Step: 3
Training loss: 2.694519545523334
Validation loss: 2.568419761139663

Epoch: 6| Step: 4
Training loss: 3.3993446279446475
Validation loss: 2.562617089422444

Epoch: 6| Step: 5
Training loss: 2.321703458587138
Validation loss: 2.603092582124672

Epoch: 6| Step: 6
Training loss: 2.8497117817017092
Validation loss: 2.5576668938064704

Epoch: 6| Step: 7
Training loss: 2.6648087784690415
Validation loss: 2.5954285562251185

Epoch: 6| Step: 8
Training loss: 2.247520670217611
Validation loss: 2.565149419766509

Epoch: 6| Step: 9
Training loss: 2.361022677043245
Validation loss: 2.5681171803527363

Epoch: 6| Step: 10
Training loss: 2.5198845667362013
Validation loss: 2.5190380130344727

Epoch: 6| Step: 11
Training loss: 2.2287981554649483
Validation loss: 2.5929469726014998

Epoch: 6| Step: 12
Training loss: 3.0451060319551453
Validation loss: 2.5608405595919614

Epoch: 6| Step: 13
Training loss: 3.0112540236557446
Validation loss: 2.595460336962154

Epoch: 253| Step: 0
Training loss: 2.748844597590795
Validation loss: 2.5947470578971186

Epoch: 6| Step: 1
Training loss: 3.2061162612119536
Validation loss: 2.552312618065638

Epoch: 6| Step: 2
Training loss: 2.853392465846216
Validation loss: 2.5765675722685413

Epoch: 6| Step: 3
Training loss: 2.6465973439334376
Validation loss: 2.577613049362712

Epoch: 6| Step: 4
Training loss: 3.3728814716792335
Validation loss: 2.595696704293324

Epoch: 6| Step: 5
Training loss: 2.186482547106766
Validation loss: 2.553869643299546

Epoch: 6| Step: 6
Training loss: 2.833731137193144
Validation loss: 2.5888244754363665

Epoch: 6| Step: 7
Training loss: 2.505170815253649
Validation loss: 2.579491280547724

Epoch: 6| Step: 8
Training loss: 2.5459233477756205
Validation loss: 2.607441273641267

Epoch: 6| Step: 9
Training loss: 2.333658286582497
Validation loss: 2.590927398934766

Epoch: 6| Step: 10
Training loss: 2.426546476744777
Validation loss: 2.613740629721563

Epoch: 6| Step: 11
Training loss: 1.9592737685827235
Validation loss: 2.565060250694603

Epoch: 6| Step: 12
Training loss: 1.83257677622585
Validation loss: 2.589119828036231

Epoch: 6| Step: 13
Training loss: 2.7703752832242605
Validation loss: 2.5715802168298914

Epoch: 254| Step: 0
Training loss: 2.902694988946055
Validation loss: 2.5961931367767654

Epoch: 6| Step: 1
Training loss: 2.126456939297163
Validation loss: 2.5847513856559305

Epoch: 6| Step: 2
Training loss: 2.5994174121167557
Validation loss: 2.538100590521316

Epoch: 6| Step: 3
Training loss: 2.8742754479322152
Validation loss: 2.569186624860018

Epoch: 6| Step: 4
Training loss: 2.561138256459649
Validation loss: 2.600031829020731

Epoch: 6| Step: 5
Training loss: 2.3786242087656215
Validation loss: 2.612429447225271

Epoch: 6| Step: 6
Training loss: 2.372620444581866
Validation loss: 2.591078060898592

Epoch: 6| Step: 7
Training loss: 2.4775786135429487
Validation loss: 2.537288890531116

Epoch: 6| Step: 8
Training loss: 3.1494741697268083
Validation loss: 2.5429469299615226

Epoch: 6| Step: 9
Training loss: 2.3516573966006034
Validation loss: 2.5834478355566572

Epoch: 6| Step: 10
Training loss: 3.614479847653296
Validation loss: 2.5725356194262377

Epoch: 6| Step: 11
Training loss: 1.9488827218891285
Validation loss: 2.5983014598536616

Epoch: 6| Step: 12
Training loss: 1.8894192973151551
Validation loss: 2.5873832808679467

Epoch: 6| Step: 13
Training loss: 2.0316607720172457
Validation loss: 2.5730526344216686

Epoch: 255| Step: 0
Training loss: 2.401279815536382
Validation loss: 2.5975287683185124

Epoch: 6| Step: 1
Training loss: 2.6461927415133686
Validation loss: 2.5874688142903794

Epoch: 6| Step: 2
Training loss: 2.8402289086085823
Validation loss: 2.5767600395440926

Epoch: 6| Step: 3
Training loss: 2.4502328723082707
Validation loss: 2.5926134881490928

Epoch: 6| Step: 4
Training loss: 2.725849222268896
Validation loss: 2.547326033984909

Epoch: 6| Step: 5
Training loss: 2.527261110632116
Validation loss: 2.5680623525050246

Epoch: 6| Step: 6
Training loss: 3.3633138586362015
Validation loss: 2.549469393997461

Epoch: 6| Step: 7
Training loss: 2.5396530638320165
Validation loss: 2.5884197205805326

Epoch: 6| Step: 8
Training loss: 1.9343200552536843
Validation loss: 2.582643155389263

Epoch: 6| Step: 9
Training loss: 2.832295583030366
Validation loss: 2.5365832076689463

Epoch: 6| Step: 10
Training loss: 2.5884828516049665
Validation loss: 2.576908134392732

Epoch: 6| Step: 11
Training loss: 1.9908961280616106
Validation loss: 2.593717847917135

Epoch: 6| Step: 12
Training loss: 2.2615292062874435
Validation loss: 2.603175840506827

Epoch: 6| Step: 13
Training loss: 3.1865753627875506
Validation loss: 2.614034620543519

Epoch: 256| Step: 0
Training loss: 3.2892814074086187
Validation loss: 2.5945127185874703

Epoch: 6| Step: 1
Training loss: 2.296613405862277
Validation loss: 2.572757877629401

Epoch: 6| Step: 2
Training loss: 1.92034845279718
Validation loss: 2.5746866835037956

Epoch: 6| Step: 3
Training loss: 2.5498862222457936
Validation loss: 2.6139375988813893

Epoch: 6| Step: 4
Training loss: 2.3777648492661676
Validation loss: 2.6124505039077026

Epoch: 6| Step: 5
Training loss: 3.293198546947435
Validation loss: 2.6069065999600065

Epoch: 6| Step: 6
Training loss: 2.7611142026942357
Validation loss: 2.6013717524776947

Epoch: 6| Step: 7
Training loss: 2.4161210156631436
Validation loss: 2.616878345677936

Epoch: 6| Step: 8
Training loss: 2.336724904523197
Validation loss: 2.617266473265847

Epoch: 6| Step: 9
Training loss: 2.738350381672363
Validation loss: 2.5676376708121933

Epoch: 6| Step: 10
Training loss: 2.776127244347175
Validation loss: 2.6095897479840513

Epoch: 6| Step: 11
Training loss: 2.4100680095526235
Validation loss: 2.59432400419358

Epoch: 6| Step: 12
Training loss: 2.194801135254725
Validation loss: 2.6029973479180017

Epoch: 6| Step: 13
Training loss: 2.3008297460137292
Validation loss: 2.5808033007703424

Epoch: 257| Step: 0
Training loss: 2.2254618818952068
Validation loss: 2.5883925421320555

Epoch: 6| Step: 1
Training loss: 2.0481002285541625
Validation loss: 2.5672087906154637

Epoch: 6| Step: 2
Training loss: 2.194867180561871
Validation loss: 2.597450474075227

Epoch: 6| Step: 3
Training loss: 3.0939956721625115
Validation loss: 2.591597548437143

Epoch: 6| Step: 4
Training loss: 3.007605924572229
Validation loss: 2.578688086765673

Epoch: 6| Step: 5
Training loss: 1.9944422509627941
Validation loss: 2.5860744323948546

Epoch: 6| Step: 6
Training loss: 2.6262202378574293
Validation loss: 2.5758382440999137

Epoch: 6| Step: 7
Training loss: 2.826719324623114
Validation loss: 2.587970282268414

Epoch: 6| Step: 8
Training loss: 2.1370921811120054
Validation loss: 2.601948150378716

Epoch: 6| Step: 9
Training loss: 3.339652144083489
Validation loss: 2.5919998556457595

Epoch: 6| Step: 10
Training loss: 1.997033303064775
Validation loss: 2.607853155419423

Epoch: 6| Step: 11
Training loss: 2.167805433565621
Validation loss: 2.5572429579078864

Epoch: 6| Step: 12
Training loss: 2.8828181238300497
Validation loss: 2.577721352797122

Epoch: 6| Step: 13
Training loss: 2.7556830551874016
Validation loss: 2.6018866811532293

Epoch: 258| Step: 0
Training loss: 2.7605340512826526
Validation loss: 2.5598429969421717

Epoch: 6| Step: 1
Training loss: 2.245959468642285
Validation loss: 2.58812298849672

Epoch: 6| Step: 2
Training loss: 2.758543528205269
Validation loss: 2.5759139348516573

Epoch: 6| Step: 3
Training loss: 2.4908120117432064
Validation loss: 2.559305034589994

Epoch: 6| Step: 4
Training loss: 2.6191033027146005
Validation loss: 2.5962561834498095

Epoch: 6| Step: 5
Training loss: 1.8807966275310257
Validation loss: 2.5650793440505617

Epoch: 6| Step: 6
Training loss: 2.7214482390040278
Validation loss: 2.6248393500372043

Epoch: 6| Step: 7
Training loss: 2.52095831148753
Validation loss: 2.583925832891777

Epoch: 6| Step: 8
Training loss: 3.1032507311040236
Validation loss: 2.59661184690162

Epoch: 6| Step: 9
Training loss: 2.840259799625752
Validation loss: 2.5773377460451745

Epoch: 6| Step: 10
Training loss: 2.616101213171263
Validation loss: 2.5744061957072892

Epoch: 6| Step: 11
Training loss: 2.5808454552147038
Validation loss: 2.600929470734773

Epoch: 6| Step: 12
Training loss: 1.92974229495441
Validation loss: 2.572351139871619

Epoch: 6| Step: 13
Training loss: 2.9971797720521427
Validation loss: 2.57981172326662

Epoch: 259| Step: 0
Training loss: 1.7199430313212705
Validation loss: 2.579133617977876

Epoch: 6| Step: 1
Training loss: 2.7258490473372934
Validation loss: 2.6186868192284787

Epoch: 6| Step: 2
Training loss: 2.291620901402195
Validation loss: 2.603219360001203

Epoch: 6| Step: 3
Training loss: 2.6070292087875027
Validation loss: 2.568162947027957

Epoch: 6| Step: 4
Training loss: 3.3991161151209157
Validation loss: 2.5832352244165593

Epoch: 6| Step: 5
Training loss: 2.060646727253314
Validation loss: 2.581739409941916

Epoch: 6| Step: 6
Training loss: 2.4557737398333104
Validation loss: 2.5945571195144925

Epoch: 6| Step: 7
Training loss: 3.4356645712500193
Validation loss: 2.607243697677736

Epoch: 6| Step: 8
Training loss: 2.7422376666139887
Validation loss: 2.603219226068911

Epoch: 6| Step: 9
Training loss: 2.157683407445953
Validation loss: 2.551539436999046

Epoch: 6| Step: 10
Training loss: 2.7906919362412093
Validation loss: 2.5795278919230937

Epoch: 6| Step: 11
Training loss: 2.1752168481525738
Validation loss: 2.6031581650284283

Epoch: 6| Step: 12
Training loss: 2.313463577356446
Validation loss: 2.6177387311503595

Epoch: 6| Step: 13
Training loss: 2.7152965140665133
Validation loss: 2.5862537053525254

Epoch: 260| Step: 0
Training loss: 2.9614141478156704
Validation loss: 2.5573260008000784

Epoch: 6| Step: 1
Training loss: 1.789455254101106
Validation loss: 2.5750345898606914

Epoch: 6| Step: 2
Training loss: 2.7761095526567483
Validation loss: 2.5858854005970366

Epoch: 6| Step: 3
Training loss: 3.3459975630254815
Validation loss: 2.5908638782464815

Epoch: 6| Step: 4
Training loss: 2.765253936530259
Validation loss: 2.581265495873722

Epoch: 6| Step: 5
Training loss: 1.8266481482246983
Validation loss: 2.589822350634797

Epoch: 6| Step: 6
Training loss: 2.9034791268474898
Validation loss: 2.605549928218714

Epoch: 6| Step: 7
Training loss: 2.491102215507808
Validation loss: 2.5967033859751343

Epoch: 6| Step: 8
Training loss: 2.4846672989776493
Validation loss: 2.595580704148593

Epoch: 6| Step: 9
Training loss: 2.9040620833347046
Validation loss: 2.5471038544419473

Epoch: 6| Step: 10
Training loss: 2.5754032448879336
Validation loss: 2.6157490807823183

Epoch: 6| Step: 11
Training loss: 1.9608108054035713
Validation loss: 2.569007751580882

Epoch: 6| Step: 12
Training loss: 2.5511477150194337
Validation loss: 2.568665253739518

Epoch: 6| Step: 13
Training loss: 2.432709902325403
Validation loss: 2.6040640028539093

Epoch: 261| Step: 0
Training loss: 3.171503054604585
Validation loss: 2.591878048196819

Epoch: 6| Step: 1
Training loss: 2.749958731601748
Validation loss: 2.576894063176275

Epoch: 6| Step: 2
Training loss: 2.6945717498575936
Validation loss: 2.5839736401636895

Epoch: 6| Step: 3
Training loss: 2.735682757863631
Validation loss: 2.5950575072040203

Epoch: 6| Step: 4
Training loss: 2.84170039167183
Validation loss: 2.610209456313452

Epoch: 6| Step: 5
Training loss: 2.0574199652604106
Validation loss: 2.624052934570004

Epoch: 6| Step: 6
Training loss: 2.1196649561946757
Validation loss: 2.626025183793129

Epoch: 6| Step: 7
Training loss: 2.3373601657431995
Validation loss: 2.599936857395469

Epoch: 6| Step: 8
Training loss: 2.0417146352725166
Validation loss: 2.5776751953996837

Epoch: 6| Step: 9
Training loss: 2.6505241163646605
Validation loss: 2.554613935029737

Epoch: 6| Step: 10
Training loss: 2.4044993584136836
Validation loss: 2.600598312135988

Epoch: 6| Step: 11
Training loss: 2.4315149236460742
Validation loss: 2.613524291389308

Epoch: 6| Step: 12
Training loss: 2.8266577523768714
Validation loss: 2.566372155553828

Epoch: 6| Step: 13
Training loss: 2.570934185685757
Validation loss: 2.571821939320774

Epoch: 262| Step: 0
Training loss: 2.478727339171121
Validation loss: 2.560657893571604

Epoch: 6| Step: 1
Training loss: 3.019872806472642
Validation loss: 2.591294511196547

Epoch: 6| Step: 2
Training loss: 2.8301254700253886
Validation loss: 2.5650515514970214

Epoch: 6| Step: 3
Training loss: 2.338406180101046
Validation loss: 2.5708725363367178

Epoch: 6| Step: 4
Training loss: 3.011767514399313
Validation loss: 2.5658396786012667

Epoch: 6| Step: 5
Training loss: 2.128353614123012
Validation loss: 2.5635621645493702

Epoch: 6| Step: 6
Training loss: 2.5078826609271423
Validation loss: 2.612595181763283

Epoch: 6| Step: 7
Training loss: 2.2584010218462254
Validation loss: 2.591781300011417

Epoch: 6| Step: 8
Training loss: 2.8080907379172615
Validation loss: 2.573055490932851

Epoch: 6| Step: 9
Training loss: 1.7445717136799976
Validation loss: 2.610369597823161

Epoch: 6| Step: 10
Training loss: 2.53543432559214
Validation loss: 2.598389503971483

Epoch: 6| Step: 11
Training loss: 2.676919914828928
Validation loss: 2.5764067073688968

Epoch: 6| Step: 12
Training loss: 2.6481832646687207
Validation loss: 2.5950479409189646

Epoch: 6| Step: 13
Training loss: 2.249101989407894
Validation loss: 2.592429091467089

Epoch: 263| Step: 0
Training loss: 2.107033680542084
Validation loss: 2.5932057186801987

Epoch: 6| Step: 1
Training loss: 2.3818893895831907
Validation loss: 2.5746705096416607

Epoch: 6| Step: 2
Training loss: 2.8925011397271314
Validation loss: 2.601521015313792

Epoch: 6| Step: 3
Training loss: 2.441672251134048
Validation loss: 2.574305150039535

Epoch: 6| Step: 4
Training loss: 2.1875275746378664
Validation loss: 2.6149903033680713

Epoch: 6| Step: 5
Training loss: 2.4720983855226835
Validation loss: 2.559041953170846

Epoch: 6| Step: 6
Training loss: 2.43942292487186
Validation loss: 2.5954517406445445

Epoch: 6| Step: 7
Training loss: 2.507820105615414
Validation loss: 2.5865409386665856

Epoch: 6| Step: 8
Training loss: 2.720302796058941
Validation loss: 2.5898024785060403

Epoch: 6| Step: 9
Training loss: 2.9863480841080072
Validation loss: 2.594630836951717

Epoch: 6| Step: 10
Training loss: 2.5439102609749336
Validation loss: 2.573777490752201

Epoch: 6| Step: 11
Training loss: 2.5910072992502484
Validation loss: 2.627180105371875

Epoch: 6| Step: 12
Training loss: 3.1134518680702357
Validation loss: 2.6241050851099117

Epoch: 6| Step: 13
Training loss: 2.04818776672125
Validation loss: 2.6205808442942367

Epoch: 264| Step: 0
Training loss: 2.7443213352420037
Validation loss: 2.5980062382970734

Epoch: 6| Step: 1
Training loss: 3.054443661843188
Validation loss: 2.5862148230264657

Epoch: 6| Step: 2
Training loss: 1.9115241210038243
Validation loss: 2.596398051627012

Epoch: 6| Step: 3
Training loss: 2.4615502941782528
Validation loss: 2.5922012063789484

Epoch: 6| Step: 4
Training loss: 2.2404344464386954
Validation loss: 2.594834301821815

Epoch: 6| Step: 5
Training loss: 2.5978199842664806
Validation loss: 2.627484964358715

Epoch: 6| Step: 6
Training loss: 2.4232021510190536
Validation loss: 2.5698955162866306

Epoch: 6| Step: 7
Training loss: 1.9161874614347154
Validation loss: 2.603900288073583

Epoch: 6| Step: 8
Training loss: 2.6078872551097314
Validation loss: 2.5621720280970517

Epoch: 6| Step: 9
Training loss: 3.073923099168958
Validation loss: 2.5427422929644656

Epoch: 6| Step: 10
Training loss: 2.0260254794718744
Validation loss: 2.6222608429116927

Epoch: 6| Step: 11
Training loss: 3.2495197528192383
Validation loss: 2.6040382990218904

Epoch: 6| Step: 12
Training loss: 2.5029735047861816
Validation loss: 2.615326374835609

Epoch: 6| Step: 13
Training loss: 1.9698883277688624
Validation loss: 2.616299320583069

Epoch: 265| Step: 0
Training loss: 1.9320955888190694
Validation loss: 2.616285605267032

Epoch: 6| Step: 1
Training loss: 3.2876250326653302
Validation loss: 2.5822558033027536

Epoch: 6| Step: 2
Training loss: 2.403444115690759
Validation loss: 2.5878998209967343

Epoch: 6| Step: 3
Training loss: 2.6572424437059876
Validation loss: 2.5807987273834674

Epoch: 6| Step: 4
Training loss: 2.011194371887927
Validation loss: 2.6247373577478204

Epoch: 6| Step: 5
Training loss: 2.9333149743228097
Validation loss: 2.5751387408519304

Epoch: 6| Step: 6
Training loss: 2.2239756765887964
Validation loss: 2.6037063966308245

Epoch: 6| Step: 7
Training loss: 2.5151422641628587
Validation loss: 2.58532834168696

Epoch: 6| Step: 8
Training loss: 2.809962081246075
Validation loss: 2.5958968488491982

Epoch: 6| Step: 9
Training loss: 2.386751714750357
Validation loss: 2.5496827957534656

Epoch: 6| Step: 10
Training loss: 2.549895198388772
Validation loss: 2.5808399670404536

Epoch: 6| Step: 11
Training loss: 2.5646355267029
Validation loss: 2.5806347883628726

Epoch: 6| Step: 12
Training loss: 3.144619351687004
Validation loss: 2.600275952041165

Epoch: 6| Step: 13
Training loss: 1.855202617632889
Validation loss: 2.625958882339078

Epoch: 266| Step: 0
Training loss: 2.092032112123114
Validation loss: 2.5853154447590407

Epoch: 6| Step: 1
Training loss: 2.899823374137861
Validation loss: 2.5913956383479677

Epoch: 6| Step: 2
Training loss: 2.5722300324986276
Validation loss: 2.577676842382804

Epoch: 6| Step: 3
Training loss: 2.2982296225330017
Validation loss: 2.608543077200339

Epoch: 6| Step: 4
Training loss: 2.3250182243371245
Validation loss: 2.5501677482276586

Epoch: 6| Step: 5
Training loss: 2.24044317255226
Validation loss: 2.5940544640608034

Epoch: 6| Step: 6
Training loss: 2.262300037799817
Validation loss: 2.563595951360915

Epoch: 6| Step: 7
Training loss: 2.558837878978181
Validation loss: 2.5464145272571037

Epoch: 6| Step: 8
Training loss: 2.135742634030589
Validation loss: 2.5681310371190587

Epoch: 6| Step: 9
Training loss: 2.6199388304696796
Validation loss: 2.5895802101101437

Epoch: 6| Step: 10
Training loss: 2.3749107544845462
Validation loss: 2.574885849613333

Epoch: 6| Step: 11
Training loss: 2.646083449508941
Validation loss: 2.5560680636859443

Epoch: 6| Step: 12
Training loss: 3.379888878976425
Validation loss: 2.6197308796873036

Epoch: 6| Step: 13
Training loss: 3.255561764667421
Validation loss: 2.571546678977069

Epoch: 267| Step: 0
Training loss: 2.5949125327361746
Validation loss: 2.5641829943801357

Epoch: 6| Step: 1
Training loss: 2.159791995029149
Validation loss: 2.5934460755072424

Epoch: 6| Step: 2
Training loss: 2.6358554359238586
Validation loss: 2.583496396902062

Epoch: 6| Step: 3
Training loss: 3.5278245634112135
Validation loss: 2.6120804325880713

Epoch: 6| Step: 4
Training loss: 2.3645506421040565
Validation loss: 2.6305538516271496

Epoch: 6| Step: 5
Training loss: 2.7763665863798592
Validation loss: 2.548583481798241

Epoch: 6| Step: 6
Training loss: 2.22075401388757
Validation loss: 2.596708960080968

Epoch: 6| Step: 7
Training loss: 2.2409020969465323
Validation loss: 2.6356236972608307

Epoch: 6| Step: 8
Training loss: 2.6178623525046874
Validation loss: 2.6156374866116345

Epoch: 6| Step: 9
Training loss: 2.357855806654505
Validation loss: 2.5576367032793685

Epoch: 6| Step: 10
Training loss: 2.589250177224118
Validation loss: 2.6188439857501824

Epoch: 6| Step: 11
Training loss: 2.230100370808317
Validation loss: 2.584288549184382

Epoch: 6| Step: 12
Training loss: 3.1212028322028313
Validation loss: 2.5582089846617113

Epoch: 6| Step: 13
Training loss: 1.5909034889915228
Validation loss: 2.5416585463850225

Epoch: 268| Step: 0
Training loss: 2.522521428451031
Validation loss: 2.5421255259981876

Epoch: 6| Step: 1
Training loss: 2.344207007039226
Validation loss: 2.609152410252374

Epoch: 6| Step: 2
Training loss: 1.9430364445887267
Validation loss: 2.587678179759502

Epoch: 6| Step: 3
Training loss: 2.2269474165300784
Validation loss: 2.5864138705820614

Epoch: 6| Step: 4
Training loss: 2.3590126011905244
Validation loss: 2.6059784117465012

Epoch: 6| Step: 5
Training loss: 2.642231469490646
Validation loss: 2.5631131834904646

Epoch: 6| Step: 6
Training loss: 2.34260235981112
Validation loss: 2.5835281805362693

Epoch: 6| Step: 7
Training loss: 2.6809084588045424
Validation loss: 2.5882389088552737

Epoch: 6| Step: 8
Training loss: 2.227983737228733
Validation loss: 2.553519609292731

Epoch: 6| Step: 9
Training loss: 3.323366013203307
Validation loss: 2.6137500908105986

Epoch: 6| Step: 10
Training loss: 2.4733590668456054
Validation loss: 2.574968720765914

Epoch: 6| Step: 11
Training loss: 3.06995341212806
Validation loss: 2.5532319394577723

Epoch: 6| Step: 12
Training loss: 2.784084975425611
Validation loss: 2.552588861827005

Epoch: 6| Step: 13
Training loss: 2.1308777246288293
Validation loss: 2.5911081229821624

Epoch: 269| Step: 0
Training loss: 2.830365552713519
Validation loss: 2.581637776438908

Epoch: 6| Step: 1
Training loss: 2.725087288674621
Validation loss: 2.5942393934750942

Epoch: 6| Step: 2
Training loss: 2.5315095744847596
Validation loss: 2.606513109606632

Epoch: 6| Step: 3
Training loss: 2.8520868524753062
Validation loss: 2.547189447129301

Epoch: 6| Step: 4
Training loss: 1.8876307082234205
Validation loss: 2.5687413564521164

Epoch: 6| Step: 5
Training loss: 2.6346226477375616
Validation loss: 2.6132425490863684

Epoch: 6| Step: 6
Training loss: 2.082877439844419
Validation loss: 2.588938720607078

Epoch: 6| Step: 7
Training loss: 2.5334780271099406
Validation loss: 2.5607419129495788

Epoch: 6| Step: 8
Training loss: 2.6877263883118263
Validation loss: 2.600804609829224

Epoch: 6| Step: 9
Training loss: 2.636531568876823
Validation loss: 2.5894626518989554

Epoch: 6| Step: 10
Training loss: 2.3655747563255938
Validation loss: 2.5532902937191073

Epoch: 6| Step: 11
Training loss: 2.553942650517781
Validation loss: 2.59433379301571

Epoch: 6| Step: 12
Training loss: 2.743078451154956
Validation loss: 2.6182603665007482

Epoch: 6| Step: 13
Training loss: 2.46310590851322
Validation loss: 2.5893720449275364

Epoch: 270| Step: 0
Training loss: 2.961476299612905
Validation loss: 2.5562342923086905

Epoch: 6| Step: 1
Training loss: 2.742000475643459
Validation loss: 2.59801446007101

Epoch: 6| Step: 2
Training loss: 2.6039372966207663
Validation loss: 2.578604538794391

Epoch: 6| Step: 3
Training loss: 2.319890558686911
Validation loss: 2.5811944880643423

Epoch: 6| Step: 4
Training loss: 2.1731930033697004
Validation loss: 2.5845525621928522

Epoch: 6| Step: 5
Training loss: 2.7494747353804883
Validation loss: 2.5802900956285804

Epoch: 6| Step: 6
Training loss: 2.314521112529907
Validation loss: 2.6409221922937482

Epoch: 6| Step: 7
Training loss: 2.8281877205148005
Validation loss: 2.576161022524624

Epoch: 6| Step: 8
Training loss: 2.6255387252947653
Validation loss: 2.5590135650908694

Epoch: 6| Step: 9
Training loss: 2.397683587389211
Validation loss: 2.6338598057883424

Epoch: 6| Step: 10
Training loss: 2.4812842763075484
Validation loss: 2.6072360851424006

Epoch: 6| Step: 11
Training loss: 2.416381512184439
Validation loss: 2.5938743643530167

Epoch: 6| Step: 12
Training loss: 2.7265141436379463
Validation loss: 2.5828507522102684

Epoch: 6| Step: 13
Training loss: 2.456547093563298
Validation loss: 2.550035691820812

Epoch: 271| Step: 0
Training loss: 2.7138214162375784
Validation loss: 2.585362157392219

Epoch: 6| Step: 1
Training loss: 2.80810364331959
Validation loss: 2.590050763742772

Epoch: 6| Step: 2
Training loss: 2.6686103909356307
Validation loss: 2.604900695389378

Epoch: 6| Step: 3
Training loss: 3.0294970920295063
Validation loss: 2.599251892672918

Epoch: 6| Step: 4
Training loss: 2.475579195935101
Validation loss: 2.5487101093989106

Epoch: 6| Step: 5
Training loss: 2.6940162969604646
Validation loss: 2.563782478826321

Epoch: 6| Step: 6
Training loss: 2.435639282529252
Validation loss: 2.6072233516475363

Epoch: 6| Step: 7
Training loss: 2.78841428944351
Validation loss: 2.5555044318514946

Epoch: 6| Step: 8
Training loss: 1.7285587973510355
Validation loss: 2.6041825026163963

Epoch: 6| Step: 9
Training loss: 2.1099310248070573
Validation loss: 2.599502949969907

Epoch: 6| Step: 10
Training loss: 2.808636279042789
Validation loss: 2.615665182717808

Epoch: 6| Step: 11
Training loss: 1.8862751504423392
Validation loss: 2.599846725899735

Epoch: 6| Step: 12
Training loss: 2.28377153224639
Validation loss: 2.6164043196894986

Epoch: 6| Step: 13
Training loss: 2.9208817859354848
Validation loss: 2.563772489359564

Epoch: 272| Step: 0
Training loss: 2.244893318819052
Validation loss: 2.6389788424652467

Epoch: 6| Step: 1
Training loss: 1.9739448191264868
Validation loss: 2.6107446442020446

Epoch: 6| Step: 2
Training loss: 2.967184356639577
Validation loss: 2.554679816153789

Epoch: 6| Step: 3
Training loss: 2.9724647169529654
Validation loss: 2.5552088968802176

Epoch: 6| Step: 4
Training loss: 2.513657457952051
Validation loss: 2.53739506166918

Epoch: 6| Step: 5
Training loss: 2.6356776011561673
Validation loss: 2.5827808450918233

Epoch: 6| Step: 6
Training loss: 2.3500338937466014
Validation loss: 2.610455888500767

Epoch: 6| Step: 7
Training loss: 2.8120155764998933
Validation loss: 2.634507725135573

Epoch: 6| Step: 8
Training loss: 1.8354765617767466
Validation loss: 2.605520863196417

Epoch: 6| Step: 9
Training loss: 2.8577996588950842
Validation loss: 2.6343667872284855

Epoch: 6| Step: 10
Training loss: 2.026107852381008
Validation loss: 2.5921653317934124

Epoch: 6| Step: 11
Training loss: 2.757174842318583
Validation loss: 2.6022669459157353

Epoch: 6| Step: 12
Training loss: 2.6961258255435867
Validation loss: 2.6282262981620885

Epoch: 6| Step: 13
Training loss: 2.245822631395234
Validation loss: 2.5991234062443316

Epoch: 273| Step: 0
Training loss: 2.569194886973064
Validation loss: 2.60864008132737

Epoch: 6| Step: 1
Training loss: 2.73781608951413
Validation loss: 2.639943861630173

Epoch: 6| Step: 2
Training loss: 2.1851713592585207
Validation loss: 2.5949878815066802

Epoch: 6| Step: 3
Training loss: 2.2207054869572973
Validation loss: 2.5947281700073503

Epoch: 6| Step: 4
Training loss: 1.885006208333687
Validation loss: 2.6002322541271377

Epoch: 6| Step: 5
Training loss: 2.5887860516036825
Validation loss: 2.570150933385316

Epoch: 6| Step: 6
Training loss: 2.424677746784247
Validation loss: 2.5649829623279707

Epoch: 6| Step: 7
Training loss: 2.2180960322746026
Validation loss: 2.5968944783734798

Epoch: 6| Step: 8
Training loss: 3.010134269026204
Validation loss: 2.6065919602527683

Epoch: 6| Step: 9
Training loss: 2.9431822988684475
Validation loss: 2.5869024667432097

Epoch: 6| Step: 10
Training loss: 2.9088221826846885
Validation loss: 2.598289671210861

Epoch: 6| Step: 11
Training loss: 2.884334007624898
Validation loss: 2.585295062999655

Epoch: 6| Step: 12
Training loss: 2.323313406918571
Validation loss: 2.5952006737310596

Epoch: 6| Step: 13
Training loss: 2.1932537158711525
Validation loss: 2.5669471554167704

Epoch: 274| Step: 0
Training loss: 2.171746339348955
Validation loss: 2.589521927169397

Epoch: 6| Step: 1
Training loss: 2.4050308706162054
Validation loss: 2.5670241669325238

Epoch: 6| Step: 2
Training loss: 3.306343403237824
Validation loss: 2.591119220061261

Epoch: 6| Step: 3
Training loss: 2.453022171100706
Validation loss: 2.6011008876985517

Epoch: 6| Step: 4
Training loss: 2.07183068229492
Validation loss: 2.53537888298854

Epoch: 6| Step: 5
Training loss: 2.5514392792662086
Validation loss: 2.6056177033639485

Epoch: 6| Step: 6
Training loss: 1.45651227693003
Validation loss: 2.5813164619784987

Epoch: 6| Step: 7
Training loss: 1.8222566626881362
Validation loss: 2.551527473499612

Epoch: 6| Step: 8
Training loss: 2.7540859731913767
Validation loss: 2.597851745616367

Epoch: 6| Step: 9
Training loss: 2.659634487164761
Validation loss: 2.6026256989902268

Epoch: 6| Step: 10
Training loss: 3.025064666309063
Validation loss: 2.6269771417618664

Epoch: 6| Step: 11
Training loss: 2.5505263477214153
Validation loss: 2.5566875617308824

Epoch: 6| Step: 12
Training loss: 2.6667320322926455
Validation loss: 2.612323948801905

Epoch: 6| Step: 13
Training loss: 3.2490001020634036
Validation loss: 2.573794836108494

Epoch: 275| Step: 0
Training loss: 2.5088191878847663
Validation loss: 2.5390364854614247

Epoch: 6| Step: 1
Training loss: 2.05643728035282
Validation loss: 2.5833049277081295

Epoch: 6| Step: 2
Training loss: 2.2547303384054116
Validation loss: 2.583408686729406

Epoch: 6| Step: 3
Training loss: 2.204921666179004
Validation loss: 2.624735932708971

Epoch: 6| Step: 4
Training loss: 2.610256845544732
Validation loss: 2.5761039431551693

Epoch: 6| Step: 5
Training loss: 2.702043349990572
Validation loss: 2.5590066375781624

Epoch: 6| Step: 6
Training loss: 2.214927066265278
Validation loss: 2.6254442799017474

Epoch: 6| Step: 7
Training loss: 2.117657260932532
Validation loss: 2.585717587224839

Epoch: 6| Step: 8
Training loss: 2.241941431878221
Validation loss: 2.5778859991947525

Epoch: 6| Step: 9
Training loss: 3.0264688125785706
Validation loss: 2.561855728389184

Epoch: 6| Step: 10
Training loss: 2.700670484015483
Validation loss: 2.575012088766772

Epoch: 6| Step: 11
Training loss: 3.203504139861362
Validation loss: 2.5815444737399607

Epoch: 6| Step: 12
Training loss: 2.9808746101550945
Validation loss: 2.592521243982244

Epoch: 6| Step: 13
Training loss: 2.7824341899701586
Validation loss: 2.591514733212845

Epoch: 276| Step: 0
Training loss: 3.0925884185461663
Validation loss: 2.5809673810601645

Epoch: 6| Step: 1
Training loss: 2.5387665091897667
Validation loss: 2.5330497038758413

Epoch: 6| Step: 2
Training loss: 2.5450564017350765
Validation loss: 2.6193917236934268

Epoch: 6| Step: 3
Training loss: 2.606982201928482
Validation loss: 2.605951527589537

Epoch: 6| Step: 4
Training loss: 1.76229842095126
Validation loss: 2.6025972194184446

Epoch: 6| Step: 5
Training loss: 2.592983454300259
Validation loss: 2.5936984785893036

Epoch: 6| Step: 6
Training loss: 2.5464838581813214
Validation loss: 2.5773344914319716

Epoch: 6| Step: 7
Training loss: 2.3295972636481865
Validation loss: 2.572063915685809

Epoch: 6| Step: 8
Training loss: 2.2325346510228186
Validation loss: 2.597507153942497

Epoch: 6| Step: 9
Training loss: 2.3571238104145675
Validation loss: 2.6540153450880246

Epoch: 6| Step: 10
Training loss: 2.9343745059986936
Validation loss: 2.6383088637156105

Epoch: 6| Step: 11
Training loss: 2.2135242655949
Validation loss: 2.5796553727362412

Epoch: 6| Step: 12
Training loss: 2.5681105808680447
Validation loss: 2.637098119767424

Epoch: 6| Step: 13
Training loss: 2.502779274066342
Validation loss: 2.5978951756856437

Epoch: 277| Step: 0
Training loss: 2.0328205785803397
Validation loss: 2.618285724117784

Epoch: 6| Step: 1
Training loss: 2.1443909423733607
Validation loss: 2.6046697725359986

Epoch: 6| Step: 2
Training loss: 2.9377864941429044
Validation loss: 2.578096857846452

Epoch: 6| Step: 3
Training loss: 3.243651130948234
Validation loss: 2.6105483022456744

Epoch: 6| Step: 4
Training loss: 2.294096946982525
Validation loss: 2.586956255116744

Epoch: 6| Step: 5
Training loss: 2.396082812602401
Validation loss: 2.5786476855846194

Epoch: 6| Step: 6
Training loss: 2.6126567738780424
Validation loss: 2.569307867705287

Epoch: 6| Step: 7
Training loss: 2.2785199695521543
Validation loss: 2.5619869463901535

Epoch: 6| Step: 8
Training loss: 2.066653606414546
Validation loss: 2.6003898321257912

Epoch: 6| Step: 9
Training loss: 2.879520179991795
Validation loss: 2.5645448003063827

Epoch: 6| Step: 10
Training loss: 2.4351505792262333
Validation loss: 2.6242688767878937

Epoch: 6| Step: 11
Training loss: 2.607215215944203
Validation loss: 2.5819745868543533

Epoch: 6| Step: 12
Training loss: 2.4936532520466574
Validation loss: 2.5976269111145345

Epoch: 6| Step: 13
Training loss: 2.924925328793218
Validation loss: 2.573982647336569

Epoch: 278| Step: 0
Training loss: 2.627596161713267
Validation loss: 2.572848628280703

Epoch: 6| Step: 1
Training loss: 2.4586718590192658
Validation loss: 2.5977127694497812

Epoch: 6| Step: 2
Training loss: 3.232398419712862
Validation loss: 2.6067067657272185

Epoch: 6| Step: 3
Training loss: 2.4384655140606233
Validation loss: 2.5958570976975524

Epoch: 6| Step: 4
Training loss: 2.9298071264639263
Validation loss: 2.5972541753887786

Epoch: 6| Step: 5
Training loss: 2.8067326222037474
Validation loss: 2.605683792370278

Epoch: 6| Step: 6
Training loss: 1.9927822048163015
Validation loss: 2.6146223882989

Epoch: 6| Step: 7
Training loss: 2.0933864904243116
Validation loss: 2.6142891309492216

Epoch: 6| Step: 8
Training loss: 2.576296996345512
Validation loss: 2.6080948114327245

Epoch: 6| Step: 9
Training loss: 2.608737250874051
Validation loss: 2.6345148832527103

Epoch: 6| Step: 10
Training loss: 2.067234154691598
Validation loss: 2.5967787202968746

Epoch: 6| Step: 11
Training loss: 1.994903269169893
Validation loss: 2.6032602523590627

Epoch: 6| Step: 12
Training loss: 2.419129618344491
Validation loss: 2.5611170276502353

Epoch: 6| Step: 13
Training loss: 2.9923623136046458
Validation loss: 2.608428728480273

Epoch: 279| Step: 0
Training loss: 2.65102455918064
Validation loss: 2.566915322276724

Epoch: 6| Step: 1
Training loss: 2.3327028467222215
Validation loss: 2.6136402719998535

Epoch: 6| Step: 2
Training loss: 2.045051053256325
Validation loss: 2.5809221463863423

Epoch: 6| Step: 3
Training loss: 2.155840185169508
Validation loss: 2.608132056326316

Epoch: 6| Step: 4
Training loss: 3.408111343678226
Validation loss: 2.56290621155257

Epoch: 6| Step: 5
Training loss: 2.5131421838954138
Validation loss: 2.574971530349529

Epoch: 6| Step: 6
Training loss: 2.3665242792556853
Validation loss: 2.6205970101877356

Epoch: 6| Step: 7
Training loss: 2.2646579125367765
Validation loss: 2.5898046750890638

Epoch: 6| Step: 8
Training loss: 2.804980079457746
Validation loss: 2.580672155387758

Epoch: 6| Step: 9
Training loss: 2.1753822385407453
Validation loss: 2.6024150531100405

Epoch: 6| Step: 10
Training loss: 2.830795123546411
Validation loss: 2.574916007152209

Epoch: 6| Step: 11
Training loss: 2.1833576764018825
Validation loss: 2.578300484520427

Epoch: 6| Step: 12
Training loss: 2.270406163719257
Validation loss: 2.6195931190693362

Epoch: 6| Step: 13
Training loss: 3.379316466021917
Validation loss: 2.5915093418269435

Epoch: 280| Step: 0
Training loss: 2.210071191806174
Validation loss: 2.592971847126918

Epoch: 6| Step: 1
Training loss: 2.7194264765158733
Validation loss: 2.6040839128369018

Epoch: 6| Step: 2
Training loss: 2.65315577980043
Validation loss: 2.5670857474180697

Epoch: 6| Step: 3
Training loss: 2.5529895237589306
Validation loss: 2.5992190654620098

Epoch: 6| Step: 4
Training loss: 1.8896436430010235
Validation loss: 2.601533736316566

Epoch: 6| Step: 5
Training loss: 2.0156181394475055
Validation loss: 2.58660078636484

Epoch: 6| Step: 6
Training loss: 1.9528411658996176
Validation loss: 2.572089836387864

Epoch: 6| Step: 7
Training loss: 2.9832122295101344
Validation loss: 2.580469510646889

Epoch: 6| Step: 8
Training loss: 2.1911895155188934
Validation loss: 2.593268668936017

Epoch: 6| Step: 9
Training loss: 2.958713632415712
Validation loss: 2.582721525288763

Epoch: 6| Step: 10
Training loss: 2.9857551618843012
Validation loss: 2.548481375056414

Epoch: 6| Step: 11
Training loss: 2.7444499971571266
Validation loss: 2.5929137373162567

Epoch: 6| Step: 12
Training loss: 2.3436919141565227
Validation loss: 2.5705841935217157

Epoch: 6| Step: 13
Training loss: 2.9015974314882045
Validation loss: 2.562496072249425

Epoch: 281| Step: 0
Training loss: 2.563833494496084
Validation loss: 2.582112604104753

Epoch: 6| Step: 1
Training loss: 2.749737293526537
Validation loss: 2.5572660103325786

Epoch: 6| Step: 2
Training loss: 1.9392156080958654
Validation loss: 2.5592288546234063

Epoch: 6| Step: 3
Training loss: 2.5316310642828843
Validation loss: 2.6190947888913896

Epoch: 6| Step: 4
Training loss: 2.282315253712309
Validation loss: 2.5735422869786193

Epoch: 6| Step: 5
Training loss: 2.682615943244615
Validation loss: 2.587105198193

Epoch: 6| Step: 6
Training loss: 1.8647889249467033
Validation loss: 2.588097525537405

Epoch: 6| Step: 7
Training loss: 3.2506025195980945
Validation loss: 2.6047560109053776

Epoch: 6| Step: 8
Training loss: 1.9217325793583724
Validation loss: 2.5636072605330886

Epoch: 6| Step: 9
Training loss: 2.7283957365617044
Validation loss: 2.574396705542012

Epoch: 6| Step: 10
Training loss: 2.506373102299354
Validation loss: 2.5401945981856646

Epoch: 6| Step: 11
Training loss: 2.773792684672729
Validation loss: 2.609788165983811

Epoch: 6| Step: 12
Training loss: 2.2481996963219784
Validation loss: 2.568509340581076

Epoch: 6| Step: 13
Training loss: 2.73809674521616
Validation loss: 2.6183679383678586

Epoch: 282| Step: 0
Training loss: 1.628581428616638
Validation loss: 2.581146467423259

Epoch: 6| Step: 1
Training loss: 2.8118741504729803
Validation loss: 2.5260843273163767

Epoch: 6| Step: 2
Training loss: 2.1468452240546227
Validation loss: 2.5871353203134384

Epoch: 6| Step: 3
Training loss: 3.137769929133401
Validation loss: 2.576343804830771

Epoch: 6| Step: 4
Training loss: 2.5989905121568824
Validation loss: 2.584103266778844

Epoch: 6| Step: 5
Training loss: 1.903948410625531
Validation loss: 2.5726418755506604

Epoch: 6| Step: 6
Training loss: 2.196754497842557
Validation loss: 2.564193170707054

Epoch: 6| Step: 7
Training loss: 2.1471257314623573
Validation loss: 2.5582169605480183

Epoch: 6| Step: 8
Training loss: 2.7457586005252534
Validation loss: 2.550122488973897

Epoch: 6| Step: 9
Training loss: 3.287606757573638
Validation loss: 2.5624712750585417

Epoch: 6| Step: 10
Training loss: 2.503933387168906
Validation loss: 2.593390265755989

Epoch: 6| Step: 11
Training loss: 2.6470590790891837
Validation loss: 2.608122191509075

Epoch: 6| Step: 12
Training loss: 2.8247697010523094
Validation loss: 2.5755777950667955

Epoch: 6| Step: 13
Training loss: 2.7483497349712525
Validation loss: 2.561438926312961

Epoch: 283| Step: 0
Training loss: 2.2464810510172004
Validation loss: 2.591813987992394

Epoch: 6| Step: 1
Training loss: 1.5659003832180236
Validation loss: 2.648854919154158

Epoch: 6| Step: 2
Training loss: 2.8856152811562192
Validation loss: 2.5778959041368963

Epoch: 6| Step: 3
Training loss: 2.416455215762116
Validation loss: 2.592026609552074

Epoch: 6| Step: 4
Training loss: 3.3524793246753197
Validation loss: 2.593099335334587

Epoch: 6| Step: 5
Training loss: 2.2623115250290566
Validation loss: 2.605286325923238

Epoch: 6| Step: 6
Training loss: 2.2864323109831
Validation loss: 2.608556948210576

Epoch: 6| Step: 7
Training loss: 2.6480469542313565
Validation loss: 2.540183148949944

Epoch: 6| Step: 8
Training loss: 2.641841269738708
Validation loss: 2.56625675591309

Epoch: 6| Step: 9
Training loss: 2.562447338028327
Validation loss: 2.6209440465949307

Epoch: 6| Step: 10
Training loss: 2.2869667640742986
Validation loss: 2.611559023548976

Epoch: 6| Step: 11
Training loss: 2.8274449326391724
Validation loss: 2.5806024564842303

Epoch: 6| Step: 12
Training loss: 2.401428345983097
Validation loss: 2.566256316361602

Epoch: 6| Step: 13
Training loss: 2.3316946633407554
Validation loss: 2.572866609632865

Epoch: 284| Step: 0
Training loss: 3.1306228405561747
Validation loss: 2.56649429151045

Epoch: 6| Step: 1
Training loss: 2.8002559749218374
Validation loss: 2.621112248370859

Epoch: 6| Step: 2
Training loss: 2.4631270099313234
Validation loss: 2.5881510156883727

Epoch: 6| Step: 3
Training loss: 2.3976794110295376
Validation loss: 2.5772111184682056

Epoch: 6| Step: 4
Training loss: 3.562276197397244
Validation loss: 2.619951410185092

Epoch: 6| Step: 5
Training loss: 2.03292073717418
Validation loss: 2.6331938773514145

Epoch: 6| Step: 6
Training loss: 2.4567872913341193
Validation loss: 2.5924866554053745

Epoch: 6| Step: 7
Training loss: 2.5564917862758523
Validation loss: 2.6050754488939316

Epoch: 6| Step: 8
Training loss: 2.353212202465031
Validation loss: 2.6242481059197145

Epoch: 6| Step: 9
Training loss: 2.127110274913613
Validation loss: 2.571119562586707

Epoch: 6| Step: 10
Training loss: 1.6693302645842973
Validation loss: 2.599485342221117

Epoch: 6| Step: 11
Training loss: 2.6853365507128677
Validation loss: 2.6157402811285855

Epoch: 6| Step: 12
Training loss: 1.928213320893298
Validation loss: 2.5765128655388008

Epoch: 6| Step: 13
Training loss: 2.3048097739677447
Validation loss: 2.584162483435622

Epoch: 285| Step: 0
Training loss: 1.9684544901607415
Validation loss: 2.5401154707969047

Epoch: 6| Step: 1
Training loss: 3.033863003217192
Validation loss: 2.582341980105307

Epoch: 6| Step: 2
Training loss: 2.213268655134533
Validation loss: 2.575835980867205

Epoch: 6| Step: 3
Training loss: 1.5674901242226449
Validation loss: 2.5328985578532435

Epoch: 6| Step: 4
Training loss: 2.1622465481271314
Validation loss: 2.590241072158763

Epoch: 6| Step: 5
Training loss: 2.7944573550203087
Validation loss: 2.5994925948055525

Epoch: 6| Step: 6
Training loss: 2.4330874876260875
Validation loss: 2.605821188422661

Epoch: 6| Step: 7
Training loss: 2.3670050925299555
Validation loss: 2.586641062333972

Epoch: 6| Step: 8
Training loss: 2.8900396630756453
Validation loss: 2.5470629945493197

Epoch: 6| Step: 9
Training loss: 2.749561795087072
Validation loss: 2.5637754332064655

Epoch: 6| Step: 10
Training loss: 2.4080959027035096
Validation loss: 2.5817192233754382

Epoch: 6| Step: 11
Training loss: 3.019052089953167
Validation loss: 2.5850071864572586

Epoch: 6| Step: 12
Training loss: 2.7106710077611584
Validation loss: 2.533035651151606

Epoch: 6| Step: 13
Training loss: 2.4084581424179445
Validation loss: 2.5559809689429938

Epoch: 286| Step: 0
Training loss: 2.861628743807067
Validation loss: 2.55646915607043

Epoch: 6| Step: 1
Training loss: 2.312317505929923
Validation loss: 2.57417561661446

Epoch: 6| Step: 2
Training loss: 2.940646981654774
Validation loss: 2.577558523958496

Epoch: 6| Step: 3
Training loss: 1.9781463670103905
Validation loss: 2.5628171159805495

Epoch: 6| Step: 4
Training loss: 3.2004484577650283
Validation loss: 2.5974279707550396

Epoch: 6| Step: 5
Training loss: 2.6461979672339733
Validation loss: 2.593086475079052

Epoch: 6| Step: 6
Training loss: 1.7403131503547307
Validation loss: 2.6096258663660343

Epoch: 6| Step: 7
Training loss: 2.640471504761234
Validation loss: 2.5890323846167007

Epoch: 6| Step: 8
Training loss: 2.730634474193284
Validation loss: 2.5665633596984296

Epoch: 6| Step: 9
Training loss: 2.2781229403765124
Validation loss: 2.600262009250578

Epoch: 6| Step: 10
Training loss: 2.7022802543404056
Validation loss: 2.5721486488800966

Epoch: 6| Step: 11
Training loss: 1.8593431357851047
Validation loss: 2.6134332296630487

Epoch: 6| Step: 12
Training loss: 2.3960834096232086
Validation loss: 2.615082399039502

Epoch: 6| Step: 13
Training loss: 2.439304955092829
Validation loss: 2.584770272062919

Epoch: 287| Step: 0
Training loss: 2.4227816945664684
Validation loss: 2.596234712520695

Epoch: 6| Step: 1
Training loss: 2.6889453815887068
Validation loss: 2.594348322026132

Epoch: 6| Step: 2
Training loss: 2.0308351533255746
Validation loss: 2.6124275699511106

Epoch: 6| Step: 3
Training loss: 3.0426821298242537
Validation loss: 2.5959443655447534

Epoch: 6| Step: 4
Training loss: 3.5052252320802872
Validation loss: 2.5722283830246075

Epoch: 6| Step: 5
Training loss: 2.4963571710937895
Validation loss: 2.6148295580538026

Epoch: 6| Step: 6
Training loss: 3.089043630601195
Validation loss: 2.582409046489611

Epoch: 6| Step: 7
Training loss: 2.2833304129069045
Validation loss: 2.5760472471595555

Epoch: 6| Step: 8
Training loss: 1.928661985138267
Validation loss: 2.594765504011313

Epoch: 6| Step: 9
Training loss: 2.0732942809120107
Validation loss: 2.597618321966785

Epoch: 6| Step: 10
Training loss: 1.9683995010576893
Validation loss: 2.5849735109035126

Epoch: 6| Step: 11
Training loss: 2.671241015792683
Validation loss: 2.5733311427941943

Epoch: 6| Step: 12
Training loss: 2.0651315027442463
Validation loss: 2.5808853432125014

Epoch: 6| Step: 13
Training loss: 2.0123709501034623
Validation loss: 2.599762480309204

Epoch: 288| Step: 0
Training loss: 2.9611526451355
Validation loss: 2.5872968112309302

Epoch: 6| Step: 1
Training loss: 2.268783157148377
Validation loss: 2.609721629823153

Epoch: 6| Step: 2
Training loss: 2.267527025223653
Validation loss: 2.5795793206956072

Epoch: 6| Step: 3
Training loss: 2.6194714046460406
Validation loss: 2.5532326724336394

Epoch: 6| Step: 4
Training loss: 2.6535922049112632
Validation loss: 2.631866135038632

Epoch: 6| Step: 5
Training loss: 2.4207370176431073
Validation loss: 2.526016655051641

Epoch: 6| Step: 6
Training loss: 2.958389675696324
Validation loss: 2.570639561959742

Epoch: 6| Step: 7
Training loss: 2.518397822973384
Validation loss: 2.611945293469709

Epoch: 6| Step: 8
Training loss: 2.4697641148847813
Validation loss: 2.5510402877630303

Epoch: 6| Step: 9
Training loss: 2.7115381987967524
Validation loss: 2.5565140312105337

Epoch: 6| Step: 10
Training loss: 1.9683164694459607
Validation loss: 2.5150614592402136

Epoch: 6| Step: 11
Training loss: 2.241543029249615
Validation loss: 2.6218715254830167

Epoch: 6| Step: 12
Training loss: 2.3010627820445055
Validation loss: 2.5662143598264966

Epoch: 6| Step: 13
Training loss: 2.2166992165988866
Validation loss: 2.613151107685017

Epoch: 289| Step: 0
Training loss: 2.651760301197551
Validation loss: 2.550023565438829

Epoch: 6| Step: 1
Training loss: 2.601836318993753
Validation loss: 2.57161351798012

Epoch: 6| Step: 2
Training loss: 2.8943095051491436
Validation loss: 2.5707073450109568

Epoch: 6| Step: 3
Training loss: 2.1878302188673953
Validation loss: 2.622393394558938

Epoch: 6| Step: 4
Training loss: 3.009535892737093
Validation loss: 2.5441821369795656

Epoch: 6| Step: 5
Training loss: 2.12034793337828
Validation loss: 2.591654901352844

Epoch: 6| Step: 6
Training loss: 2.101087325026662
Validation loss: 2.57942417656439

Epoch: 6| Step: 7
Training loss: 2.4888475573131634
Validation loss: 2.579991836808392

Epoch: 6| Step: 8
Training loss: 2.830120752407142
Validation loss: 2.59435556229089

Epoch: 6| Step: 9
Training loss: 2.1295644320153784
Validation loss: 2.606375397899005

Epoch: 6| Step: 10
Training loss: 2.6304977610262585
Validation loss: 2.6146456535300997

Epoch: 6| Step: 11
Training loss: 2.3667281809947767
Validation loss: 2.6281344523826937

Epoch: 6| Step: 12
Training loss: 2.2337880464034368
Validation loss: 2.622220963484507

Epoch: 6| Step: 13
Training loss: 2.6943193900418376
Validation loss: 2.567058466434076

Epoch: 290| Step: 0
Training loss: 2.2501519469771067
Validation loss: 2.624818372717738

Epoch: 6| Step: 1
Training loss: 2.44591673189477
Validation loss: 2.5750815347868254

Epoch: 6| Step: 2
Training loss: 2.909927174813783
Validation loss: 2.601191061481552

Epoch: 6| Step: 3
Training loss: 1.9996928932914846
Validation loss: 2.6257947586846146

Epoch: 6| Step: 4
Training loss: 2.624587344477277
Validation loss: 2.6238118699343387

Epoch: 6| Step: 5
Training loss: 2.549118832200396
Validation loss: 2.555383003599967

Epoch: 6| Step: 6
Training loss: 2.402125799945675
Validation loss: 2.5861331667519356

Epoch: 6| Step: 7
Training loss: 2.6579517971630864
Validation loss: 2.557651897819276

Epoch: 6| Step: 8
Training loss: 2.473358295688293
Validation loss: 2.5596406842642443

Epoch: 6| Step: 9
Training loss: 2.8988030298275365
Validation loss: 2.548887328388838

Epoch: 6| Step: 10
Training loss: 1.9558714820360625
Validation loss: 2.566592873880368

Epoch: 6| Step: 11
Training loss: 2.3607721297327595
Validation loss: 2.5879734303899515

Epoch: 6| Step: 12
Training loss: 2.9456053570522016
Validation loss: 2.570682457492929

Epoch: 6| Step: 13
Training loss: 1.7648937094997843
Validation loss: 2.5716505046852314

Epoch: 291| Step: 0
Training loss: 2.1369999172298146
Validation loss: 2.6458271780048213

Epoch: 6| Step: 1
Training loss: 1.720924527736058
Validation loss: 2.5935384988079733

Epoch: 6| Step: 2
Training loss: 2.2734093942904017
Validation loss: 2.596875411623784

Epoch: 6| Step: 3
Training loss: 2.290753153589699
Validation loss: 2.588286355166248

Epoch: 6| Step: 4
Training loss: 3.1583666361023437
Validation loss: 2.578547579630777

Epoch: 6| Step: 5
Training loss: 2.904855208867537
Validation loss: 2.584443760393494

Epoch: 6| Step: 6
Training loss: 2.006656298985529
Validation loss: 2.612966670014651

Epoch: 6| Step: 7
Training loss: 2.136466560614517
Validation loss: 2.59020880971218

Epoch: 6| Step: 8
Training loss: 2.2736860316391954
Validation loss: 2.5741552522186777

Epoch: 6| Step: 9
Training loss: 2.607635009284138
Validation loss: 2.5767367754920785

Epoch: 6| Step: 10
Training loss: 2.912169631754189
Validation loss: 2.5678753861631693

Epoch: 6| Step: 11
Training loss: 2.4123946171805026
Validation loss: 2.575243367459372

Epoch: 6| Step: 12
Training loss: 2.662372937103193
Validation loss: 2.5781835172145673

Epoch: 6| Step: 13
Training loss: 3.033833140462725
Validation loss: 2.6127335046573217

Epoch: 292| Step: 0
Training loss: 2.116840404478965
Validation loss: 2.5916088036722886

Epoch: 6| Step: 1
Training loss: 2.579951893261851
Validation loss: 2.586814016790033

Epoch: 6| Step: 2
Training loss: 2.5628100882133835
Validation loss: 2.633209856769581

Epoch: 6| Step: 3
Training loss: 2.9501576526994704
Validation loss: 2.6182437788557085

Epoch: 6| Step: 4
Training loss: 2.5749690303977104
Validation loss: 2.601968295281879

Epoch: 6| Step: 5
Training loss: 2.5712941622801213
Validation loss: 2.5763715969665153

Epoch: 6| Step: 6
Training loss: 2.174851169098026
Validation loss: 2.579063262694215

Epoch: 6| Step: 7
Training loss: 2.0342696999107805
Validation loss: 2.5796357512341817

Epoch: 6| Step: 8
Training loss: 2.3962699713394593
Validation loss: 2.5886083939988787

Epoch: 6| Step: 9
Training loss: 2.725032519225222
Validation loss: 2.625218211927595

Epoch: 6| Step: 10
Training loss: 2.5274452531056513
Validation loss: 2.6452057744753183

Epoch: 6| Step: 11
Training loss: 2.6036568307895513
Validation loss: 2.6160809076098803

Epoch: 6| Step: 12
Training loss: 2.672611068258937
Validation loss: 2.5683528185596622

Epoch: 6| Step: 13
Training loss: 2.131294688542145
Validation loss: 2.5493013344929167

Epoch: 293| Step: 0
Training loss: 2.567312606019923
Validation loss: 2.6225792621622577

Epoch: 6| Step: 1
Training loss: 2.619190053452077
Validation loss: 2.580094315141318

Epoch: 6| Step: 2
Training loss: 2.724774318063994
Validation loss: 2.562171716918771

Epoch: 6| Step: 3
Training loss: 2.524978214585397
Validation loss: 2.5769174581230776

Epoch: 6| Step: 4
Training loss: 1.9642850714843492
Validation loss: 2.581942911188123

Epoch: 6| Step: 5
Training loss: 2.3460429864117573
Validation loss: 2.5757845281137643

Epoch: 6| Step: 6
Training loss: 2.5126846852913625
Validation loss: 2.579308855963855

Epoch: 6| Step: 7
Training loss: 2.4042090145019834
Validation loss: 2.6190156045072226

Epoch: 6| Step: 8
Training loss: 1.8508712830389298
Validation loss: 2.5793681667873893

Epoch: 6| Step: 9
Training loss: 3.1015116113288244
Validation loss: 2.60086467735296

Epoch: 6| Step: 10
Training loss: 2.601807087349386
Validation loss: 2.598390758960427

Epoch: 6| Step: 11
Training loss: 2.138491604666991
Validation loss: 2.6074788670696205

Epoch: 6| Step: 12
Training loss: 2.743695749081044
Validation loss: 2.582362746533458

Epoch: 6| Step: 13
Training loss: 2.363289926055872
Validation loss: 2.596590560578552

Epoch: 294| Step: 0
Training loss: 2.2445576863735304
Validation loss: 2.5696079368056406

Epoch: 6| Step: 1
Training loss: 2.5837592317354425
Validation loss: 2.580314399174984

Epoch: 6| Step: 2
Training loss: 2.2475093195534233
Validation loss: 2.607342709742948

Epoch: 6| Step: 3
Training loss: 2.6182279881346395
Validation loss: 2.591776920085408

Epoch: 6| Step: 4
Training loss: 2.03155808679946
Validation loss: 2.6146558996573765

Epoch: 6| Step: 5
Training loss: 2.363630890006283
Validation loss: 2.622835135805253

Epoch: 6| Step: 6
Training loss: 2.554288593844104
Validation loss: 2.59331248715374

Epoch: 6| Step: 7
Training loss: 2.4270474236141673
Validation loss: 2.6482992888481576

Epoch: 6| Step: 8
Training loss: 2.6794566063347083
Validation loss: 2.578545982914793

Epoch: 6| Step: 9
Training loss: 2.661063825080553
Validation loss: 2.569926054596061

Epoch: 6| Step: 10
Training loss: 2.492217156404171
Validation loss: 2.6197147715684337

Epoch: 6| Step: 11
Training loss: 2.7195567545452377
Validation loss: 2.590396510610968

Epoch: 6| Step: 12
Training loss: 2.8413676249050206
Validation loss: 2.586935887275849

Epoch: 6| Step: 13
Training loss: 2.240005973739833
Validation loss: 2.5674121664835847

Epoch: 295| Step: 0
Training loss: 2.66126818391349
Validation loss: 2.599615036560157

Epoch: 6| Step: 1
Training loss: 2.3450681921310155
Validation loss: 2.552736496022393

Epoch: 6| Step: 2
Training loss: 2.1881429544783857
Validation loss: 2.6005767301726905

Epoch: 6| Step: 3
Training loss: 2.895959828493322
Validation loss: 2.5874890511160085

Epoch: 6| Step: 4
Training loss: 1.9537375138189477
Validation loss: 2.5956093283633845

Epoch: 6| Step: 5
Training loss: 2.0089529635447185
Validation loss: 2.6324755883734436

Epoch: 6| Step: 6
Training loss: 2.5450758869121373
Validation loss: 2.5865214942842147

Epoch: 6| Step: 7
Training loss: 2.6217640504334137
Validation loss: 2.606348214883804

Epoch: 6| Step: 8
Training loss: 2.3640705398453115
Validation loss: 2.535840394178937

Epoch: 6| Step: 9
Training loss: 2.4517167051988835
Validation loss: 2.584567538981628

Epoch: 6| Step: 10
Training loss: 2.3926483766790825
Validation loss: 2.5915968500530386

Epoch: 6| Step: 11
Training loss: 3.131692357901097
Validation loss: 2.5893516010424786

Epoch: 6| Step: 12
Training loss: 2.4829206708387246
Validation loss: 2.570927209024844

Epoch: 6| Step: 13
Training loss: 2.238278693552205
Validation loss: 2.5801426683500113

Epoch: 296| Step: 0
Training loss: 3.0451469020141197
Validation loss: 2.5884770280300162

Epoch: 6| Step: 1
Training loss: 2.184065602319861
Validation loss: 2.597712315483196

Epoch: 6| Step: 2
Training loss: 2.396863588706335
Validation loss: 2.5952022641514847

Epoch: 6| Step: 3
Training loss: 2.2380525428869853
Validation loss: 2.6201847404308007

Epoch: 6| Step: 4
Training loss: 2.512138272337098
Validation loss: 2.5916449194113986

Epoch: 6| Step: 5
Training loss: 2.533289993902551
Validation loss: 2.607548203479994

Epoch: 6| Step: 6
Training loss: 2.1797573939776744
Validation loss: 2.575715304091384

Epoch: 6| Step: 7
Training loss: 2.7893093651689376
Validation loss: 2.5739773536862782

Epoch: 6| Step: 8
Training loss: 2.8008167472090233
Validation loss: 2.55799584772311

Epoch: 6| Step: 9
Training loss: 2.150525552256802
Validation loss: 2.621744996360663

Epoch: 6| Step: 10
Training loss: 2.532683920023404
Validation loss: 2.6319166540905177

Epoch: 6| Step: 11
Training loss: 2.5415451354274703
Validation loss: 2.604188111903992

Epoch: 6| Step: 12
Training loss: 2.358758302642652
Validation loss: 2.591071960184373

Epoch: 6| Step: 13
Training loss: 2.1794435644892154
Validation loss: 2.6175657593756334

Epoch: 297| Step: 0
Training loss: 3.0328207763684727
Validation loss: 2.5970856396295896

Epoch: 6| Step: 1
Training loss: 2.5357516725420504
Validation loss: 2.5933780682720204

Epoch: 6| Step: 2
Training loss: 1.7472799824620056
Validation loss: 2.5920278211364893

Epoch: 6| Step: 3
Training loss: 2.515125864872353
Validation loss: 2.5839214753676476

Epoch: 6| Step: 4
Training loss: 2.329224192591917
Validation loss: 2.664350400322534

Epoch: 6| Step: 5
Training loss: 2.9361562699143624
Validation loss: 2.6214596644676944

Epoch: 6| Step: 6
Training loss: 2.149549605633719
Validation loss: 2.6016186468501696

Epoch: 6| Step: 7
Training loss: 2.396055349484433
Validation loss: 2.623485654778529

Epoch: 6| Step: 8
Training loss: 2.181040026332865
Validation loss: 2.521771898891721

Epoch: 6| Step: 9
Training loss: 1.6841618050881493
Validation loss: 2.578780037406549

Epoch: 6| Step: 10
Training loss: 3.0755038647206447
Validation loss: 2.573386949239603

Epoch: 6| Step: 11
Training loss: 2.7122496142166037
Validation loss: 2.564683843496928

Epoch: 6| Step: 12
Training loss: 2.920984469071119
Validation loss: 2.5553720813956606

Epoch: 6| Step: 13
Training loss: 2.2436739682887445
Validation loss: 2.5927784149324222

Epoch: 298| Step: 0
Training loss: 2.2125459353748567
Validation loss: 2.6009538588866117

Epoch: 6| Step: 1
Training loss: 2.504805143167192
Validation loss: 2.5532230875024635

Epoch: 6| Step: 2
Training loss: 2.4370938476224384
Validation loss: 2.622251310854005

Epoch: 6| Step: 3
Training loss: 1.9174120186287893
Validation loss: 2.5650406534716557

Epoch: 6| Step: 4
Training loss: 2.298681262566648
Validation loss: 2.622711866140013

Epoch: 6| Step: 5
Training loss: 2.966567351432618
Validation loss: 2.5817035806390347

Epoch: 6| Step: 6
Training loss: 3.0928087440260548
Validation loss: 2.6358929907720214

Epoch: 6| Step: 7
Training loss: 2.0312992970279997
Validation loss: 2.586544753586111

Epoch: 6| Step: 8
Training loss: 2.2892746550375973
Validation loss: 2.579216023646996

Epoch: 6| Step: 9
Training loss: 2.578770966955423
Validation loss: 2.6067015218134046

Epoch: 6| Step: 10
Training loss: 2.252667012008696
Validation loss: 2.5799493007554575

Epoch: 6| Step: 11
Training loss: 2.4688740952604875
Validation loss: 2.627008966316802

Epoch: 6| Step: 12
Training loss: 2.665413522325404
Validation loss: 2.5900423048704773

Epoch: 6| Step: 13
Training loss: 2.8617140578039613
Validation loss: 2.6098064763181266

Epoch: 299| Step: 0
Training loss: 2.336435934620702
Validation loss: 2.5922730450444456

Epoch: 6| Step: 1
Training loss: 2.1553796310777695
Validation loss: 2.624446885823221

Epoch: 6| Step: 2
Training loss: 2.5296182906901663
Validation loss: 2.6277763755573926

Epoch: 6| Step: 3
Training loss: 2.8144505836321803
Validation loss: 2.588849434133923

Epoch: 6| Step: 4
Training loss: 2.106665899039181
Validation loss: 2.5932210013874357

Epoch: 6| Step: 5
Training loss: 2.287086128357787
Validation loss: 2.5864217664298073

Epoch: 6| Step: 6
Training loss: 2.528744340438657
Validation loss: 2.573294694309591

Epoch: 6| Step: 7
Training loss: 2.0734220364762246
Validation loss: 2.598982467077346

Epoch: 6| Step: 8
Training loss: 2.602944496738374
Validation loss: 2.57969625303626

Epoch: 6| Step: 9
Training loss: 3.0667072901592065
Validation loss: 2.5954834647970033

Epoch: 6| Step: 10
Training loss: 2.391736339480239
Validation loss: 2.5781664116927776

Epoch: 6| Step: 11
Training loss: 3.050434244229687
Validation loss: 2.633676211925679

Epoch: 6| Step: 12
Training loss: 1.833289781688923
Validation loss: 2.6318192683609096

Epoch: 6| Step: 13
Training loss: 2.3925836057016308
Validation loss: 2.597596904734581

Epoch: 300| Step: 0
Training loss: 2.398361353954626
Validation loss: 2.6048349162167175

Epoch: 6| Step: 1
Training loss: 2.451444986029923
Validation loss: 2.5924935023545315

Epoch: 6| Step: 2
Training loss: 2.9648085279219583
Validation loss: 2.5984715895285975

Epoch: 6| Step: 3
Training loss: 1.8438500845948538
Validation loss: 2.5606218684039606

Epoch: 6| Step: 4
Training loss: 1.4756662383531653
Validation loss: 2.579699460943709

Epoch: 6| Step: 5
Training loss: 2.49479534066606
Validation loss: 2.6098573221854844

Epoch: 6| Step: 6
Training loss: 2.1029820522570986
Validation loss: 2.5886824863296276

Epoch: 6| Step: 7
Training loss: 2.516403077913196
Validation loss: 2.5962710374291684

Epoch: 6| Step: 8
Training loss: 2.8365851049057293
Validation loss: 2.6379981973168865

Epoch: 6| Step: 9
Training loss: 2.09339560171117
Validation loss: 2.607264464388052

Epoch: 6| Step: 10
Training loss: 2.723108590641097
Validation loss: 2.5900766895292597

Epoch: 6| Step: 11
Training loss: 2.5928587703707233
Validation loss: 2.580212279819202

Epoch: 6| Step: 12
Training loss: 2.7751425216779406
Validation loss: 2.560450109398593

Epoch: 6| Step: 13
Training loss: 2.4910365589082355
Validation loss: 2.590665866284014

Epoch: 301| Step: 0
Training loss: 2.6852552220892463
Validation loss: 2.634411593708184

Epoch: 6| Step: 1
Training loss: 2.1341045783605344
Validation loss: 2.5586304990823194

Epoch: 6| Step: 2
Training loss: 2.6344735992550996
Validation loss: 2.5809820399440135

Epoch: 6| Step: 3
Training loss: 2.5012596771495317
Validation loss: 2.59074870270576

Epoch: 6| Step: 4
Training loss: 1.928723793469812
Validation loss: 2.5864432315952905

Epoch: 6| Step: 5
Training loss: 1.7018333226542233
Validation loss: 2.5952167477987245

Epoch: 6| Step: 6
Training loss: 2.454118855328548
Validation loss: 2.614560710118006

Epoch: 6| Step: 7
Training loss: 3.0726250634064414
Validation loss: 2.6247559671800094

Epoch: 6| Step: 8
Training loss: 2.4739444986592343
Validation loss: 2.578050014565062

Epoch: 6| Step: 9
Training loss: 2.499426203682807
Validation loss: 2.5655643579822116

Epoch: 6| Step: 10
Training loss: 2.305064025122103
Validation loss: 2.582440663327803

Epoch: 6| Step: 11
Training loss: 2.353166305767116
Validation loss: 2.6099723420551597

Epoch: 6| Step: 12
Training loss: 2.6100253819367825
Validation loss: 2.616402529533058

Epoch: 6| Step: 13
Training loss: 3.1091056975479927
Validation loss: 2.5472533831169084

Epoch: 302| Step: 0
Training loss: 2.219320304538248
Validation loss: 2.564962360032586

Epoch: 6| Step: 1
Training loss: 2.0890541367516775
Validation loss: 2.6372234641381236

Epoch: 6| Step: 2
Training loss: 2.815745706119564
Validation loss: 2.574591550640968

Epoch: 6| Step: 3
Training loss: 3.1022453421223357
Validation loss: 2.5956435158166338

Epoch: 6| Step: 4
Training loss: 2.8963345613017863
Validation loss: 2.604944994049708

Epoch: 6| Step: 5
Training loss: 1.863468440667567
Validation loss: 2.5622666255428466

Epoch: 6| Step: 6
Training loss: 2.327258057439692
Validation loss: 2.5831893089495375

Epoch: 6| Step: 7
Training loss: 2.4585295992161997
Validation loss: 2.6124969133846645

Epoch: 6| Step: 8
Training loss: 2.787455632836027
Validation loss: 2.5780184110034674

Epoch: 6| Step: 9
Training loss: 1.9912121348543481
Validation loss: 2.5731536236665855

Epoch: 6| Step: 10
Training loss: 2.5935562245246406
Validation loss: 2.591303624871547

Epoch: 6| Step: 11
Training loss: 2.1204462064051075
Validation loss: 2.595795397324171

Epoch: 6| Step: 12
Training loss: 2.3346750171293458
Validation loss: 2.590532794636908

Epoch: 6| Step: 13
Training loss: 2.695589532298221
Validation loss: 2.549043050814886

Epoch: 303| Step: 0
Training loss: 2.02136996770153
Validation loss: 2.5763619404025317

Epoch: 6| Step: 1
Training loss: 2.130633236417911
Validation loss: 2.5752653608256777

Epoch: 6| Step: 2
Training loss: 3.364219968718574
Validation loss: 2.572433237114565

Epoch: 6| Step: 3
Training loss: 2.0890925973737047
Validation loss: 2.623610870709556

Epoch: 6| Step: 4
Training loss: 1.9727809753267918
Validation loss: 2.637549461480665

Epoch: 6| Step: 5
Training loss: 2.360559431462757
Validation loss: 2.563775476204204

Epoch: 6| Step: 6
Training loss: 2.26326855414625
Validation loss: 2.5712704160624176

Epoch: 6| Step: 7
Training loss: 2.9334984978502456
Validation loss: 2.6375338709039093

Epoch: 6| Step: 8
Training loss: 3.0729158735543645
Validation loss: 2.610230778406561

Epoch: 6| Step: 9
Training loss: 2.2526009679047614
Validation loss: 2.5658389652130986

Epoch: 6| Step: 10
Training loss: 2.497943795517907
Validation loss: 2.5698165607099996

Epoch: 6| Step: 11
Training loss: 2.4671898269883936
Validation loss: 2.6219564979972905

Epoch: 6| Step: 12
Training loss: 1.8758419689565482
Validation loss: 2.653854517611946

Epoch: 6| Step: 13
Training loss: 2.630595555773989
Validation loss: 2.5826532247323137

Epoch: 304| Step: 0
Training loss: 2.8900753014069953
Validation loss: 2.579250931327865

Epoch: 6| Step: 1
Training loss: 2.507662189292874
Validation loss: 2.6040311915116696

Epoch: 6| Step: 2
Training loss: 3.0986680522637653
Validation loss: 2.5796260199314425

Epoch: 6| Step: 3
Training loss: 2.2989011378592146
Validation loss: 2.5774615844061195

Epoch: 6| Step: 4
Training loss: 1.2816337382960836
Validation loss: 2.5837305546234557

Epoch: 6| Step: 5
Training loss: 3.2545329540258665
Validation loss: 2.564697821270925

Epoch: 6| Step: 6
Training loss: 2.469070993149826
Validation loss: 2.5541177127828583

Epoch: 6| Step: 7
Training loss: 2.0719542705394205
Validation loss: 2.5935346521656597

Epoch: 6| Step: 8
Training loss: 2.3162408419086797
Validation loss: 2.511936696853393

Epoch: 6| Step: 9
Training loss: 2.416916132799618
Validation loss: 2.5632930401857026

Epoch: 6| Step: 10
Training loss: 2.0161730590443154
Validation loss: 2.576079100807513

Epoch: 6| Step: 11
Training loss: 2.211370526830272
Validation loss: 2.559592956351912

Epoch: 6| Step: 12
Training loss: 1.7267559512753656
Validation loss: 2.607296066441394

Epoch: 6| Step: 13
Training loss: 2.7296483631527346
Validation loss: 2.5700681442892677

Epoch: 305| Step: 0
Training loss: 2.0565875301046472
Validation loss: 2.599161108143633

Epoch: 6| Step: 1
Training loss: 2.4311193435982084
Validation loss: 2.585033681498581

Epoch: 6| Step: 2
Training loss: 2.1305669903880062
Validation loss: 2.577616734276461

Epoch: 6| Step: 3
Training loss: 1.8374790294255037
Validation loss: 2.588716160179559

Epoch: 6| Step: 4
Training loss: 2.054869901154072
Validation loss: 2.576214637616942

Epoch: 6| Step: 5
Training loss: 2.826479944443755
Validation loss: 2.555596714065823

Epoch: 6| Step: 6
Training loss: 2.5343095161830407
Validation loss: 2.584412129869959

Epoch: 6| Step: 7
Training loss: 2.4703787730216686
Validation loss: 2.604674256765364

Epoch: 6| Step: 8
Training loss: 2.1782418656159535
Validation loss: 2.5773735097163

Epoch: 6| Step: 9
Training loss: 2.757064761192981
Validation loss: 2.6005606557177776

Epoch: 6| Step: 10
Training loss: 3.628792981699055
Validation loss: 2.5841475340612208

Epoch: 6| Step: 11
Training loss: 2.352927790631758
Validation loss: 2.6109779469117793

Epoch: 6| Step: 12
Training loss: 2.4955877468768874
Validation loss: 2.6350335448990765

Epoch: 6| Step: 13
Training loss: 1.700262130835377
Validation loss: 2.591961411628637

Epoch: 306| Step: 0
Training loss: 2.3518717109440237
Validation loss: 2.6026120007614217

Epoch: 6| Step: 1
Training loss: 2.4402327257703127
Validation loss: 2.6198641219980003

Epoch: 6| Step: 2
Training loss: 2.9899554580381706
Validation loss: 2.573454878091322

Epoch: 6| Step: 3
Training loss: 1.8381741798563929
Validation loss: 2.618125623726434

Epoch: 6| Step: 4
Training loss: 2.3356418996704296
Validation loss: 2.597548790571109

Epoch: 6| Step: 5
Training loss: 2.5157972952085417
Validation loss: 2.6070085375563297

Epoch: 6| Step: 6
Training loss: 2.3114896061898973
Validation loss: 2.5756924138017525

Epoch: 6| Step: 7
Training loss: 1.9547283458025029
Validation loss: 2.558614511788417

Epoch: 6| Step: 8
Training loss: 2.166800079150777
Validation loss: 2.5964771487282308

Epoch: 6| Step: 9
Training loss: 2.7726459931855403
Validation loss: 2.650225998445004

Epoch: 6| Step: 10
Training loss: 2.3550181804044317
Validation loss: 2.548766757690101

Epoch: 6| Step: 11
Training loss: 2.4799169692629786
Validation loss: 2.6205955046361162

Epoch: 6| Step: 12
Training loss: 2.227858959007335
Validation loss: 2.6101006647166973

Epoch: 6| Step: 13
Training loss: 3.4478560766022963
Validation loss: 2.597898312767053

Epoch: 307| Step: 0
Training loss: 2.537036075370134
Validation loss: 2.5723656545140017

Epoch: 6| Step: 1
Training loss: 2.3225661100211337
Validation loss: 2.592234901769641

Epoch: 6| Step: 2
Training loss: 2.2950128805094105
Validation loss: 2.592245793265233

Epoch: 6| Step: 3
Training loss: 2.957641054918803
Validation loss: 2.5969853944583288

Epoch: 6| Step: 4
Training loss: 1.9939622341547374
Validation loss: 2.6418597315188426

Epoch: 6| Step: 5
Training loss: 2.050612553515415
Validation loss: 2.6349846928770218

Epoch: 6| Step: 6
Training loss: 2.1913974374196132
Validation loss: 2.609307805837463

Epoch: 6| Step: 7
Training loss: 2.8255563947604947
Validation loss: 2.5822681059410275

Epoch: 6| Step: 8
Training loss: 2.735809647357562
Validation loss: 2.5967186984475696

Epoch: 6| Step: 9
Training loss: 2.0408913314426647
Validation loss: 2.6241848193082573

Epoch: 6| Step: 10
Training loss: 2.000508124653689
Validation loss: 2.5827697518899644

Epoch: 6| Step: 11
Training loss: 2.8052531657488764
Validation loss: 2.6179927130287153

Epoch: 6| Step: 12
Training loss: 2.7364569013572715
Validation loss: 2.6437556259524797

Epoch: 6| Step: 13
Training loss: 1.9310967245664696
Validation loss: 2.594871763722119

Epoch: 308| Step: 0
Training loss: 2.2769922734440655
Validation loss: 2.5906928952096457

Epoch: 6| Step: 1
Training loss: 2.740547407002268
Validation loss: 2.605698096741745

Epoch: 6| Step: 2
Training loss: 2.470429054710025
Validation loss: 2.66614190124517

Epoch: 6| Step: 3
Training loss: 1.8465199757003443
Validation loss: 2.616475044096406

Epoch: 6| Step: 4
Training loss: 2.891206260182074
Validation loss: 2.5953679223393324

Epoch: 6| Step: 5
Training loss: 2.18199729906679
Validation loss: 2.634359130453457

Epoch: 6| Step: 6
Training loss: 2.3605650875052424
Validation loss: 2.5946274177815836

Epoch: 6| Step: 7
Training loss: 2.543294062513324
Validation loss: 2.6188518856284633

Epoch: 6| Step: 8
Training loss: 2.3214111809550744
Validation loss: 2.5787154688982756

Epoch: 6| Step: 9
Training loss: 2.606178564469423
Validation loss: 2.630620470940427

Epoch: 6| Step: 10
Training loss: 2.787815018032593
Validation loss: 2.5854533461355045

Epoch: 6| Step: 11
Training loss: 2.1115302484049807
Validation loss: 2.554321625127893

Epoch: 6| Step: 12
Training loss: 2.3794345613584564
Validation loss: 2.596522121300432

Epoch: 6| Step: 13
Training loss: 2.179332635903716
Validation loss: 2.6090193421293537

Epoch: 309| Step: 0
Training loss: 2.1177552084950495
Validation loss: 2.5948920001157303

Epoch: 6| Step: 1
Training loss: 2.1387881452056026
Validation loss: 2.6360198386180866

Epoch: 6| Step: 2
Training loss: 2.777923308904738
Validation loss: 2.6276537289289865

Epoch: 6| Step: 3
Training loss: 1.7022162296454177
Validation loss: 2.5787008637385807

Epoch: 6| Step: 4
Training loss: 2.695359381668815
Validation loss: 2.601506270146133

Epoch: 6| Step: 5
Training loss: 2.4701369047641037
Validation loss: 2.5990858695070247

Epoch: 6| Step: 6
Training loss: 2.215100577936256
Validation loss: 2.6000023369940326

Epoch: 6| Step: 7
Training loss: 2.5487470241228047
Validation loss: 2.5785368659060826

Epoch: 6| Step: 8
Training loss: 2.243256742616292
Validation loss: 2.603698446861174

Epoch: 6| Step: 9
Training loss: 2.657385908604269
Validation loss: 2.574007445677362

Epoch: 6| Step: 10
Training loss: 2.1840114569311093
Validation loss: 2.602191152768817

Epoch: 6| Step: 11
Training loss: 2.5542116801126196
Validation loss: 2.6207269343713824

Epoch: 6| Step: 12
Training loss: 3.328679141623725
Validation loss: 2.6009968921852726

Epoch: 6| Step: 13
Training loss: 1.6451504010721412
Validation loss: 2.608104364757854

Epoch: 310| Step: 0
Training loss: 2.4791410001393177
Validation loss: 2.61683645427139

Epoch: 6| Step: 1
Training loss: 2.937221595070308
Validation loss: 2.6097654316192958

Epoch: 6| Step: 2
Training loss: 2.481062113761223
Validation loss: 2.630555693063424

Epoch: 6| Step: 3
Training loss: 2.6996343047125677
Validation loss: 2.629815878149837

Epoch: 6| Step: 4
Training loss: 2.0954551016735916
Validation loss: 2.5853895620482876

Epoch: 6| Step: 5
Training loss: 2.1480346301961646
Validation loss: 2.572227046501378

Epoch: 6| Step: 6
Training loss: 1.9596505368347499
Validation loss: 2.583936932044016

Epoch: 6| Step: 7
Training loss: 2.502255661932761
Validation loss: 2.560128049355841

Epoch: 6| Step: 8
Training loss: 1.9168665684930315
Validation loss: 2.5834134281641545

Epoch: 6| Step: 9
Training loss: 2.438705048647855
Validation loss: 2.5583745992040106

Epoch: 6| Step: 10
Training loss: 2.660666709467232
Validation loss: 2.6088767226531444

Epoch: 6| Step: 11
Training loss: 2.8297532594771377
Validation loss: 2.6180970317319137

Epoch: 6| Step: 12
Training loss: 2.6367489509265765
Validation loss: 2.605125197352329

Epoch: 6| Step: 13
Training loss: 2.5193341318542934
Validation loss: 2.592859834245389

Epoch: 311| Step: 0
Training loss: 2.6856773760905877
Validation loss: 2.5554994279658234

Epoch: 6| Step: 1
Training loss: 2.59168712898182
Validation loss: 2.6247012451299243

Epoch: 6| Step: 2
Training loss: 2.5708168717593556
Validation loss: 2.6084688236833395

Epoch: 6| Step: 3
Training loss: 2.3875301498985944
Validation loss: 2.5937430595051074

Epoch: 6| Step: 4
Training loss: 2.59188325187523
Validation loss: 2.653769463243284

Epoch: 6| Step: 5
Training loss: 2.514815964534927
Validation loss: 2.5893769922660397

Epoch: 6| Step: 6
Training loss: 2.626362220076919
Validation loss: 2.577861042748587

Epoch: 6| Step: 7
Training loss: 2.2155240744778797
Validation loss: 2.5711010445426474

Epoch: 6| Step: 8
Training loss: 2.0549267531657827
Validation loss: 2.594608322515382

Epoch: 6| Step: 9
Training loss: 2.0355316811600117
Validation loss: 2.596718758670526

Epoch: 6| Step: 10
Training loss: 2.685429862507631
Validation loss: 2.5993974693496167

Epoch: 6| Step: 11
Training loss: 2.588508181032365
Validation loss: 2.6368531610099475

Epoch: 6| Step: 12
Training loss: 2.1398603646899708
Validation loss: 2.610097794726985

Epoch: 6| Step: 13
Training loss: 2.445714752944627
Validation loss: 2.552094652671063

Epoch: 312| Step: 0
Training loss: 2.1242358011653595
Validation loss: 2.6200053879858505

Epoch: 6| Step: 1
Training loss: 3.170522617617361
Validation loss: 2.607893248658326

Epoch: 6| Step: 2
Training loss: 2.6118859185371472
Validation loss: 2.5762788040937474

Epoch: 6| Step: 3
Training loss: 1.9775059073223709
Validation loss: 2.666842926517038

Epoch: 6| Step: 4
Training loss: 2.5146595304670374
Validation loss: 2.613954813091969

Epoch: 6| Step: 5
Training loss: 2.6360828226186444
Validation loss: 2.5718238711550154

Epoch: 6| Step: 6
Training loss: 2.086024821878953
Validation loss: 2.5882371180376422

Epoch: 6| Step: 7
Training loss: 1.7697038376876004
Validation loss: 2.6085120769850163

Epoch: 6| Step: 8
Training loss: 3.285721992104538
Validation loss: 2.59204487128356

Epoch: 6| Step: 9
Training loss: 2.7210949836704064
Validation loss: 2.565648527440822

Epoch: 6| Step: 10
Training loss: 2.694968204346115
Validation loss: 2.5833233910196283

Epoch: 6| Step: 11
Training loss: 1.8566212498002819
Validation loss: 2.5706343152781974

Epoch: 6| Step: 12
Training loss: 2.401336706960124
Validation loss: 2.590200560192433

Epoch: 6| Step: 13
Training loss: 1.5208897340671736
Validation loss: 2.624480239500042

Epoch: 313| Step: 0
Training loss: 2.5503527528203542
Validation loss: 2.5884774182495636

Epoch: 6| Step: 1
Training loss: 2.7160719035185736
Validation loss: 2.5834885754682486

Epoch: 6| Step: 2
Training loss: 1.8955394461191841
Validation loss: 2.610622853083674

Epoch: 6| Step: 3
Training loss: 2.055639706283857
Validation loss: 2.5815179776452726

Epoch: 6| Step: 4
Training loss: 2.1637552091380443
Validation loss: 2.617151582949273

Epoch: 6| Step: 5
Training loss: 2.387720774883406
Validation loss: 2.575548943248063

Epoch: 6| Step: 6
Training loss: 2.4023478190069705
Validation loss: 2.592379811385149

Epoch: 6| Step: 7
Training loss: 2.4309353583155175
Validation loss: 2.583022104490462

Epoch: 6| Step: 8
Training loss: 3.2055784180206213
Validation loss: 2.6127538460457695

Epoch: 6| Step: 9
Training loss: 2.7301290625501853
Validation loss: 2.5989016745931246

Epoch: 6| Step: 10
Training loss: 1.7635014685074977
Validation loss: 2.592889778776491

Epoch: 6| Step: 11
Training loss: 2.3244546722436703
Validation loss: 2.569396463323281

Epoch: 6| Step: 12
Training loss: 2.5002591952427644
Validation loss: 2.5400429301032905

Epoch: 6| Step: 13
Training loss: 2.236378658340086
Validation loss: 2.5903386270690136

Epoch: 314| Step: 0
Training loss: 2.56895276311239
Validation loss: 2.56991300854858

Epoch: 6| Step: 1
Training loss: 1.0619123741250143
Validation loss: 2.545130169427351

Epoch: 6| Step: 2
Training loss: 2.4426520259090805
Validation loss: 2.599538405740239

Epoch: 6| Step: 3
Training loss: 2.2733410162623433
Validation loss: 2.6154511335310966

Epoch: 6| Step: 4
Training loss: 2.7132084813397794
Validation loss: 2.614375195179006

Epoch: 6| Step: 5
Training loss: 1.6577270687141277
Validation loss: 2.566226303807712

Epoch: 6| Step: 6
Training loss: 2.7695872055018227
Validation loss: 2.6183844684389745

Epoch: 6| Step: 7
Training loss: 2.747322513029838
Validation loss: 2.5666608726724793

Epoch: 6| Step: 8
Training loss: 2.6252594774157063
Validation loss: 2.577526619965305

Epoch: 6| Step: 9
Training loss: 2.102292299296682
Validation loss: 2.6050069520582113

Epoch: 6| Step: 10
Training loss: 2.945820165134406
Validation loss: 2.591299672516427

Epoch: 6| Step: 11
Training loss: 2.4605437433005153
Validation loss: 2.598652489840435

Epoch: 6| Step: 12
Training loss: 2.3759912128992426
Validation loss: 2.5568110960527326

Epoch: 6| Step: 13
Training loss: 2.0730505920802362
Validation loss: 2.5803490734212917

Epoch: 315| Step: 0
Training loss: 2.1901856421254924
Validation loss: 2.572327541941905

Epoch: 6| Step: 1
Training loss: 2.567026002509245
Validation loss: 2.564890363140721

Epoch: 6| Step: 2
Training loss: 2.5391522670429776
Validation loss: 2.624928293259555

Epoch: 6| Step: 3
Training loss: 3.0494062815142833
Validation loss: 2.5956903359163603

Epoch: 6| Step: 4
Training loss: 2.4752214814317353
Validation loss: 2.566482393726578

Epoch: 6| Step: 5
Training loss: 2.396663743000962
Validation loss: 2.5915372552351896

Epoch: 6| Step: 6
Training loss: 2.5236098286745543
Validation loss: 2.6037079710249813

Epoch: 6| Step: 7
Training loss: 2.5662423695535836
Validation loss: 2.563404980919434

Epoch: 6| Step: 8
Training loss: 2.188435817545182
Validation loss: 2.601782737740937

Epoch: 6| Step: 9
Training loss: 1.8374569063907369
Validation loss: 2.5925460306292694

Epoch: 6| Step: 10
Training loss: 1.9974864423575804
Validation loss: 2.581458004164023

Epoch: 6| Step: 11
Training loss: 2.32521653756456
Validation loss: 2.6477026007349975

Epoch: 6| Step: 12
Training loss: 2.5997561120307067
Validation loss: 2.6131392702685434

Epoch: 6| Step: 13
Training loss: 2.3349248930391817
Validation loss: 2.638402167466105

Epoch: 316| Step: 0
Training loss: 2.106940100384652
Validation loss: 2.5947309819077953

Epoch: 6| Step: 1
Training loss: 2.5767310795828187
Validation loss: 2.600874857516848

Epoch: 6| Step: 2
Training loss: 2.4835493527188333
Validation loss: 2.582234221919166

Epoch: 6| Step: 3
Training loss: 2.0047156054696327
Validation loss: 2.6146470095509717

Epoch: 6| Step: 4
Training loss: 2.372341073022184
Validation loss: 2.563783379276342

Epoch: 6| Step: 5
Training loss: 2.603383478014688
Validation loss: 2.5901288422046305

Epoch: 6| Step: 6
Training loss: 2.7646471439252096
Validation loss: 2.5740769885178736

Epoch: 6| Step: 7
Training loss: 2.3283289877601363
Validation loss: 2.5819456362321125

Epoch: 6| Step: 8
Training loss: 2.404855695745256
Validation loss: 2.5883824257852512

Epoch: 6| Step: 9
Training loss: 2.4155097252901285
Validation loss: 2.5998466558884967

Epoch: 6| Step: 10
Training loss: 2.4790883946818516
Validation loss: 2.617036664078587

Epoch: 6| Step: 11
Training loss: 1.8874767984138987
Validation loss: 2.57111179722888

Epoch: 6| Step: 12
Training loss: 2.7350488322918025
Validation loss: 2.60639887149698

Epoch: 6| Step: 13
Training loss: 2.085186197945531
Validation loss: 2.5883832884594065

Epoch: 317| Step: 0
Training loss: 1.3373000129137758
Validation loss: 2.5878015401238392

Epoch: 6| Step: 1
Training loss: 2.114189700115326
Validation loss: 2.5567715000130855

Epoch: 6| Step: 2
Training loss: 3.121972563081128
Validation loss: 2.5584405678630637

Epoch: 6| Step: 3
Training loss: 3.2087161508698503
Validation loss: 2.556229448309829

Epoch: 6| Step: 4
Training loss: 2.6344269915933607
Validation loss: 2.5824745803784492

Epoch: 6| Step: 5
Training loss: 2.8796670599391576
Validation loss: 2.6212587831705756

Epoch: 6| Step: 6
Training loss: 2.6343468063854987
Validation loss: 2.6405121833248084

Epoch: 6| Step: 7
Training loss: 2.2850990744716886
Validation loss: 2.610771824647884

Epoch: 6| Step: 8
Training loss: 2.405501410227592
Validation loss: 2.584274721517022

Epoch: 6| Step: 9
Training loss: 1.415566334971998
Validation loss: 2.5317496340003043

Epoch: 6| Step: 10
Training loss: 1.60000281333676
Validation loss: 2.566338861811612

Epoch: 6| Step: 11
Training loss: 2.046905284395478
Validation loss: 2.61293679858543

Epoch: 6| Step: 12
Training loss: 2.65128670529897
Validation loss: 2.5699020174166507

Epoch: 6| Step: 13
Training loss: 2.180563801819367
Validation loss: 2.63443149231699

Epoch: 318| Step: 0
Training loss: 2.352465484722682
Validation loss: 2.5793739950254424

Epoch: 6| Step: 1
Training loss: 2.1646837795573086
Validation loss: 2.5949547395401193

Epoch: 6| Step: 2
Training loss: 2.2361789703603083
Validation loss: 2.5903431113652147

Epoch: 6| Step: 3
Training loss: 2.26176355083678
Validation loss: 2.577765154841543

Epoch: 6| Step: 4
Training loss: 2.6940816086583808
Validation loss: 2.635306714061716

Epoch: 6| Step: 5
Training loss: 3.3694349961979553
Validation loss: 2.6279009460942477

Epoch: 6| Step: 6
Training loss: 1.7979755514262732
Validation loss: 2.5176278601394517

Epoch: 6| Step: 7
Training loss: 2.5132708225858056
Validation loss: 2.6134301602767076

Epoch: 6| Step: 8
Training loss: 2.412709075881066
Validation loss: 2.5952206932005577

Epoch: 6| Step: 9
Training loss: 2.3979231192741994
Validation loss: 2.580220508117407

Epoch: 6| Step: 10
Training loss: 2.1863443864412226
Validation loss: 2.5763984007197704

Epoch: 6| Step: 11
Training loss: 2.231755461727043
Validation loss: 2.6188498524154755

Epoch: 6| Step: 12
Training loss: 2.1122654079218877
Validation loss: 2.666871119424236

Epoch: 6| Step: 13
Training loss: 2.719848060291114
Validation loss: 2.584340403022039

Epoch: 319| Step: 0
Training loss: 2.291338625461807
Validation loss: 2.572074833789262

Epoch: 6| Step: 1
Training loss: 3.2561800958375016
Validation loss: 2.58497610928027

Epoch: 6| Step: 2
Training loss: 2.5576833721510046
Validation loss: 2.6097219063525703

Epoch: 6| Step: 3
Training loss: 2.3954823333591997
Validation loss: 2.587478109874197

Epoch: 6| Step: 4
Training loss: 1.9758607123623322
Validation loss: 2.583959828669597

Epoch: 6| Step: 5
Training loss: 2.6833035730010817
Validation loss: 2.603633725341332

Epoch: 6| Step: 6
Training loss: 2.279295619777932
Validation loss: 2.613875147378618

Epoch: 6| Step: 7
Training loss: 2.010404109092062
Validation loss: 2.5837552807385036

Epoch: 6| Step: 8
Training loss: 2.5430319407591386
Validation loss: 2.6352138289639804

Epoch: 6| Step: 9
Training loss: 2.2734959126207746
Validation loss: 2.6369092787827184

Epoch: 6| Step: 10
Training loss: 1.8999246180789184
Validation loss: 2.5991387685718

Epoch: 6| Step: 11
Training loss: 2.433468149535195
Validation loss: 2.5985189619643774

Epoch: 6| Step: 12
Training loss: 2.8373849921089005
Validation loss: 2.5867832249402527

Epoch: 6| Step: 13
Training loss: 2.1960348115256774
Validation loss: 2.6410468086745573

Epoch: 320| Step: 0
Training loss: 2.3944432303102765
Validation loss: 2.6229701419563813

Epoch: 6| Step: 1
Training loss: 2.6379697191584244
Validation loss: 2.5698198587627212

Epoch: 6| Step: 2
Training loss: 2.496055734073279
Validation loss: 2.6125524081981815

Epoch: 6| Step: 3
Training loss: 1.9982268102324712
Validation loss: 2.5830699126088636

Epoch: 6| Step: 4
Training loss: 1.2800885029832785
Validation loss: 2.5756929433124465

Epoch: 6| Step: 5
Training loss: 2.1473479126264863
Validation loss: 2.609196225043163

Epoch: 6| Step: 6
Training loss: 2.464603273295475
Validation loss: 2.620233220683495

Epoch: 6| Step: 7
Training loss: 2.9299313049595934
Validation loss: 2.5965234976469187

Epoch: 6| Step: 8
Training loss: 2.8475497504519263
Validation loss: 2.582606826413779

Epoch: 6| Step: 9
Training loss: 2.420139404569255
Validation loss: 2.5962814251911333

Epoch: 6| Step: 10
Training loss: 2.0888183359762165
Validation loss: 2.547868524912806

Epoch: 6| Step: 11
Training loss: 2.335400880141475
Validation loss: 2.5868919600567137

Epoch: 6| Step: 12
Training loss: 2.8475194408901863
Validation loss: 2.6064694592126774

Epoch: 6| Step: 13
Training loss: 2.377894093836537
Validation loss: 2.5769956778381906

Epoch: 321| Step: 0
Training loss: 2.29232441103879
Validation loss: 2.5389647974442937

Epoch: 6| Step: 1
Training loss: 2.2765606274724735
Validation loss: 2.6727810014261753

Epoch: 6| Step: 2
Training loss: 1.9222476256841214
Validation loss: 2.5872773953191097

Epoch: 6| Step: 3
Training loss: 2.776452115880287
Validation loss: 2.5879251323557804

Epoch: 6| Step: 4
Training loss: 1.917438192851058
Validation loss: 2.5843185573191176

Epoch: 6| Step: 5
Training loss: 2.085912011380147
Validation loss: 2.542291132485902

Epoch: 6| Step: 6
Training loss: 2.3189121734582554
Validation loss: 2.5686513579369943

Epoch: 6| Step: 7
Training loss: 2.593122751157295
Validation loss: 2.5917754630758605

Epoch: 6| Step: 8
Training loss: 2.4030582016886575
Validation loss: 2.5921989950139928

Epoch: 6| Step: 9
Training loss: 3.1059425616335843
Validation loss: 2.622676672820489

Epoch: 6| Step: 10
Training loss: 2.860602110324634
Validation loss: 2.603803579962752

Epoch: 6| Step: 11
Training loss: 2.741450892791828
Validation loss: 2.5778493257157016

Epoch: 6| Step: 12
Training loss: 2.1769711649592343
Validation loss: 2.5751745529819194

Epoch: 6| Step: 13
Training loss: 1.7961513886696459
Validation loss: 2.5842198059303243

Epoch: 322| Step: 0
Training loss: 2.2450146014921786
Validation loss: 2.588141061835553

Epoch: 6| Step: 1
Training loss: 1.8684935530953763
Validation loss: 2.580687375726415

Epoch: 6| Step: 2
Training loss: 2.8239720660224834
Validation loss: 2.609261372551904

Epoch: 6| Step: 3
Training loss: 2.216298212773799
Validation loss: 2.6195304579084766

Epoch: 6| Step: 4
Training loss: 2.8959921008892766
Validation loss: 2.547066963209369

Epoch: 6| Step: 5
Training loss: 2.7600306594914863
Validation loss: 2.6137455260306766

Epoch: 6| Step: 6
Training loss: 1.6292888091497484
Validation loss: 2.598530506869961

Epoch: 6| Step: 7
Training loss: 2.0336995540240443
Validation loss: 2.6116392399264687

Epoch: 6| Step: 8
Training loss: 2.4199831556884686
Validation loss: 2.605078253561981

Epoch: 6| Step: 9
Training loss: 2.333855048391364
Validation loss: 2.6311976734820117

Epoch: 6| Step: 10
Training loss: 2.9310818621924457
Validation loss: 2.583230960999448

Epoch: 6| Step: 11
Training loss: 1.9598383159511934
Validation loss: 2.592702248492082

Epoch: 6| Step: 12
Training loss: 2.6603692819492393
Validation loss: 2.597898295991227

Epoch: 6| Step: 13
Training loss: 1.7171198657169353
Validation loss: 2.5985518128180907

Epoch: 323| Step: 0
Training loss: 2.19460287876912
Validation loss: 2.599171428134431

Epoch: 6| Step: 1
Training loss: 2.8658633799603317
Validation loss: 2.6332687961605785

Epoch: 6| Step: 2
Training loss: 2.7080936521454135
Validation loss: 2.5994179466569474

Epoch: 6| Step: 3
Training loss: 1.6205939200260775
Validation loss: 2.5871799548680197

Epoch: 6| Step: 4
Training loss: 1.9905594100805997
Validation loss: 2.5768645177490312

Epoch: 6| Step: 5
Training loss: 2.9321747254564263
Validation loss: 2.622032034631173

Epoch: 6| Step: 6
Training loss: 2.336892943679386
Validation loss: 2.596443193421526

Epoch: 6| Step: 7
Training loss: 2.673510134773172
Validation loss: 2.6007292807353504

Epoch: 6| Step: 8
Training loss: 2.444965374473235
Validation loss: 2.557944094246612

Epoch: 6| Step: 9
Training loss: 2.1901279467827464
Validation loss: 2.604401691947232

Epoch: 6| Step: 10
Training loss: 2.1529121548404992
Validation loss: 2.600047480794107

Epoch: 6| Step: 11
Training loss: 2.7111363406735833
Validation loss: 2.5783371058445326

Epoch: 6| Step: 12
Training loss: 2.078607603553292
Validation loss: 2.606035519984553

Epoch: 6| Step: 13
Training loss: 1.8683142035891955
Validation loss: 2.5701147240821745

Epoch: 324| Step: 0
Training loss: 1.8147565672120147
Validation loss: 2.6206117183739384

Epoch: 6| Step: 1
Training loss: 2.4558709199080972
Validation loss: 2.634389794399519

Epoch: 6| Step: 2
Training loss: 2.5672293958536425
Validation loss: 2.6293839145323847

Epoch: 6| Step: 3
Training loss: 2.3630542488473694
Validation loss: 2.6153667710856974

Epoch: 6| Step: 4
Training loss: 3.0529997472928514
Validation loss: 2.6244207281168404

Epoch: 6| Step: 5
Training loss: 2.6703713630987562
Validation loss: 2.573370586394784

Epoch: 6| Step: 6
Training loss: 1.83029476418352
Validation loss: 2.558804927534765

Epoch: 6| Step: 7
Training loss: 2.47239165374379
Validation loss: 2.622322880607107

Epoch: 6| Step: 8
Training loss: 2.096298033790083
Validation loss: 2.5793123187976907

Epoch: 6| Step: 9
Training loss: 2.2696784229456837
Validation loss: 2.5763928373991813

Epoch: 6| Step: 10
Training loss: 2.348173113145476
Validation loss: 2.5874900666685705

Epoch: 6| Step: 11
Training loss: 1.4118112589719927
Validation loss: 2.6009301902688575

Epoch: 6| Step: 12
Training loss: 2.6171446839431507
Validation loss: 2.588971687080932

Epoch: 6| Step: 13
Training loss: 2.5176189410420515
Validation loss: 2.6001179116223816

Epoch: 325| Step: 0
Training loss: 2.431237024110818
Validation loss: 2.589456194928024

Epoch: 6| Step: 1
Training loss: 2.0881726580298987
Validation loss: 2.5844603001254978

Epoch: 6| Step: 2
Training loss: 2.2043094562318166
Validation loss: 2.548996502341381

Epoch: 6| Step: 3
Training loss: 3.377070886556447
Validation loss: 2.6145000090683514

Epoch: 6| Step: 4
Training loss: 2.505633396773091
Validation loss: 2.5844351601671587

Epoch: 6| Step: 5
Training loss: 2.571687556651874
Validation loss: 2.617514037795995

Epoch: 6| Step: 6
Training loss: 2.859983285708371
Validation loss: 2.622044978773025

Epoch: 6| Step: 7
Training loss: 2.4866310288719515
Validation loss: 2.6029440417144274

Epoch: 6| Step: 8
Training loss: 1.9807471807561625
Validation loss: 2.5451689823778914

Epoch: 6| Step: 9
Training loss: 2.4805306494491144
Validation loss: 2.6222952597062377

Epoch: 6| Step: 10
Training loss: 2.273972281254344
Validation loss: 2.604787893379649

Epoch: 6| Step: 11
Training loss: 1.83668249719978
Validation loss: 2.6121475701497783

Epoch: 6| Step: 12
Training loss: 1.8950141841790382
Validation loss: 2.6005390606264225

Epoch: 6| Step: 13
Training loss: 1.7838867481532612
Validation loss: 2.5876820970269114

Epoch: 326| Step: 0
Training loss: 1.7787566553073102
Validation loss: 2.5882838418271588

Epoch: 6| Step: 1
Training loss: 1.930683079936054
Validation loss: 2.650920915858481

Epoch: 6| Step: 2
Training loss: 2.4054843625797533
Validation loss: 2.587705145775377

Epoch: 6| Step: 3
Training loss: 2.508920015011167
Validation loss: 2.6060468309109903

Epoch: 6| Step: 4
Training loss: 2.1127149348420247
Validation loss: 2.5423485953817733

Epoch: 6| Step: 5
Training loss: 2.134842350340963
Validation loss: 2.568818306195006

Epoch: 6| Step: 6
Training loss: 2.4372456735808705
Validation loss: 2.6040966055684986

Epoch: 6| Step: 7
Training loss: 3.134433697866848
Validation loss: 2.605501115719717

Epoch: 6| Step: 8
Training loss: 2.618520915133103
Validation loss: 2.584237646654994

Epoch: 6| Step: 9
Training loss: 2.25975380830964
Validation loss: 2.631532232358891

Epoch: 6| Step: 10
Training loss: 2.1200544364705904
Validation loss: 2.548842767561734

Epoch: 6| Step: 11
Training loss: 1.8599398099738238
Validation loss: 2.563927831663519

Epoch: 6| Step: 12
Training loss: 2.818826130517694
Validation loss: 2.5935916182643286

Epoch: 6| Step: 13
Training loss: 2.53165743339149
Validation loss: 2.5487125797851373

Epoch: 327| Step: 0
Training loss: 2.3630552577896244
Validation loss: 2.6131353489776177

Epoch: 6| Step: 1
Training loss: 2.5767479195394394
Validation loss: 2.585853887840227

Epoch: 6| Step: 2
Training loss: 2.538330160311417
Validation loss: 2.5648001795173405

Epoch: 6| Step: 3
Training loss: 2.7502077197606467
Validation loss: 2.5757209813454054

Epoch: 6| Step: 4
Training loss: 2.855350852024875
Validation loss: 2.565149946456481

Epoch: 6| Step: 5
Training loss: 1.7505891353225143
Validation loss: 2.598029305971121

Epoch: 6| Step: 6
Training loss: 2.4213712106751566
Validation loss: 2.590516706349852

Epoch: 6| Step: 7
Training loss: 2.3520945203823125
Validation loss: 2.633332607751541

Epoch: 6| Step: 8
Training loss: 2.360923410571791
Validation loss: 2.615023964907159

Epoch: 6| Step: 9
Training loss: 2.013014766656009
Validation loss: 2.5565557117384246

Epoch: 6| Step: 10
Training loss: 2.008751438142728
Validation loss: 2.589139131116507

Epoch: 6| Step: 11
Training loss: 2.614517717690619
Validation loss: 2.539406086003574

Epoch: 6| Step: 12
Training loss: 2.326322741224418
Validation loss: 2.5545641562730874

Epoch: 6| Step: 13
Training loss: 2.1450806072179205
Validation loss: 2.6006009708069664

Epoch: 328| Step: 0
Training loss: 2.0784613545055035
Validation loss: 2.5696248404039674

Epoch: 6| Step: 1
Training loss: 2.6464343752483903
Validation loss: 2.5603660288791086

Epoch: 6| Step: 2
Training loss: 2.9509939749800664
Validation loss: 2.5744828128222315

Epoch: 6| Step: 3
Training loss: 2.2524701440591683
Validation loss: 2.6025002353352056

Epoch: 6| Step: 4
Training loss: 2.0378644792759837
Validation loss: 2.590480079072326

Epoch: 6| Step: 5
Training loss: 1.914371636786575
Validation loss: 2.603922326879383

Epoch: 6| Step: 6
Training loss: 3.313504624521975
Validation loss: 2.584159324719084

Epoch: 6| Step: 7
Training loss: 2.3475274734595675
Validation loss: 2.6215565475851546

Epoch: 6| Step: 8
Training loss: 2.5763417868294334
Validation loss: 2.607931139323711

Epoch: 6| Step: 9
Training loss: 2.3778937930427446
Validation loss: 2.5804108848224914

Epoch: 6| Step: 10
Training loss: 1.6096983649557943
Validation loss: 2.612260808061531

Epoch: 6| Step: 11
Training loss: 2.6452693388156017
Validation loss: 2.6400443808438214

Epoch: 6| Step: 12
Training loss: 1.8326800078157024
Validation loss: 2.5738289178890654

Epoch: 6| Step: 13
Training loss: 2.5276163652839547
Validation loss: 2.602043487026465

Epoch: 329| Step: 0
Training loss: 1.8637518138608031
Validation loss: 2.596030116585352

Epoch: 6| Step: 1
Training loss: 2.667153810669356
Validation loss: 2.584269679097207

Epoch: 6| Step: 2
Training loss: 2.1601370453627555
Validation loss: 2.5890231550152873

Epoch: 6| Step: 3
Training loss: 2.1807067019594135
Validation loss: 2.644215017584896

Epoch: 6| Step: 4
Training loss: 2.6696451262761958
Validation loss: 2.5590778292747047

Epoch: 6| Step: 5
Training loss: 2.32583792569035
Validation loss: 2.5837236457553545

Epoch: 6| Step: 6
Training loss: 2.9534756891229414
Validation loss: 2.6088032510257695

Epoch: 6| Step: 7
Training loss: 2.892511525440251
Validation loss: 2.597414349242689

Epoch: 6| Step: 8
Training loss: 2.0454536919640196
Validation loss: 2.6229936341759026

Epoch: 6| Step: 9
Training loss: 2.2667130587075057
Validation loss: 2.58451530285105

Epoch: 6| Step: 10
Training loss: 1.859871293198646
Validation loss: 2.6184117526679467

Epoch: 6| Step: 11
Training loss: 2.4289465261943946
Validation loss: 2.60563368562056

Epoch: 6| Step: 12
Training loss: 2.453063186547053
Validation loss: 2.6134618054866885

Epoch: 6| Step: 13
Training loss: 2.2128185452390925
Validation loss: 2.5937148021489675

Epoch: 330| Step: 0
Training loss: 2.217165744021498
Validation loss: 2.572672923350223

Epoch: 6| Step: 1
Training loss: 2.1454529162725486
Validation loss: 2.6034749611647454

Epoch: 6| Step: 2
Training loss: 2.4916446297818244
Validation loss: 2.6069183958562814

Epoch: 6| Step: 3
Training loss: 2.0783430859852623
Validation loss: 2.565723039998316

Epoch: 6| Step: 4
Training loss: 2.3670558578095444
Validation loss: 2.6029585374381945

Epoch: 6| Step: 5
Training loss: 2.371238942862045
Validation loss: 2.6180684467692195

Epoch: 6| Step: 6
Training loss: 2.5824133147382136
Validation loss: 2.569848351926416

Epoch: 6| Step: 7
Training loss: 2.282391615234013
Validation loss: 2.5546922154637226

Epoch: 6| Step: 8
Training loss: 2.782457239691286
Validation loss: 2.602062920837987

Epoch: 6| Step: 9
Training loss: 2.8521199556780825
Validation loss: 2.5200766296604966

Epoch: 6| Step: 10
Training loss: 1.638374383450275
Validation loss: 2.573278057904343

Epoch: 6| Step: 11
Training loss: 2.5382756818743752
Validation loss: 2.589985540826907

Epoch: 6| Step: 12
Training loss: 2.1127208030018467
Validation loss: 2.6435921009706957

Epoch: 6| Step: 13
Training loss: 2.351886207377473
Validation loss: 2.6314218180279725

Epoch: 331| Step: 0
Training loss: 2.348773506375813
Validation loss: 2.6084908735218724

Epoch: 6| Step: 1
Training loss: 2.1944382851215094
Validation loss: 2.574888720518718

Epoch: 6| Step: 2
Training loss: 2.4032621783526635
Validation loss: 2.6050717841231297

Epoch: 6| Step: 3
Training loss: 2.8589030225437115
Validation loss: 2.5722584142493625

Epoch: 6| Step: 4
Training loss: 2.2175799226174018
Validation loss: 2.5520391807394978

Epoch: 6| Step: 5
Training loss: 1.8418698827324889
Validation loss: 2.6084112949928024

Epoch: 6| Step: 6
Training loss: 2.02947239488472
Validation loss: 2.563909243678482

Epoch: 6| Step: 7
Training loss: 2.2716357245498826
Validation loss: 2.6229755918260174

Epoch: 6| Step: 8
Training loss: 2.5466263538518588
Validation loss: 2.6263405418607193

Epoch: 6| Step: 9
Training loss: 2.0493450839926672
Validation loss: 2.593772852500825

Epoch: 6| Step: 10
Training loss: 2.912420469843608
Validation loss: 2.592771002173504

Epoch: 6| Step: 11
Training loss: 2.5424335344267193
Validation loss: 2.6036393564886002

Epoch: 6| Step: 12
Training loss: 2.1741770886655987
Validation loss: 2.604814656680354

Epoch: 6| Step: 13
Training loss: 2.873268435277092
Validation loss: 2.5473599656963715

Epoch: 332| Step: 0
Training loss: 2.683447688096598
Validation loss: 2.545761168829175

Epoch: 6| Step: 1
Training loss: 2.4690748556291675
Validation loss: 2.621476000970581

Epoch: 6| Step: 2
Training loss: 2.9200303073512113
Validation loss: 2.674955161271561

Epoch: 6| Step: 3
Training loss: 2.0394844407864956
Validation loss: 2.593371564703144

Epoch: 6| Step: 4
Training loss: 2.751290018777653
Validation loss: 2.559969150715607

Epoch: 6| Step: 5
Training loss: 1.8577650777990071
Validation loss: 2.600033517058275

Epoch: 6| Step: 6
Training loss: 2.3026261761250604
Validation loss: 2.5703040150679604

Epoch: 6| Step: 7
Training loss: 2.1569573168327145
Validation loss: 2.6353980161049164

Epoch: 6| Step: 8
Training loss: 1.7995405246488658
Validation loss: 2.6050354756494145

Epoch: 6| Step: 9
Training loss: 2.0625735183097396
Validation loss: 2.5470703168883646

Epoch: 6| Step: 10
Training loss: 2.631126882975507
Validation loss: 2.609747568449634

Epoch: 6| Step: 11
Training loss: 2.347815687506675
Validation loss: 2.6299392145023526

Epoch: 6| Step: 12
Training loss: 2.252978155295187
Validation loss: 2.592700276842089

Epoch: 6| Step: 13
Training loss: 2.389626387918042
Validation loss: 2.5906311628833247

Epoch: 333| Step: 0
Training loss: 2.885303279333545
Validation loss: 2.579838574750581

Epoch: 6| Step: 1
Training loss: 2.138620593705962
Validation loss: 2.6146336846299074

Epoch: 6| Step: 2
Training loss: 2.102836137860692
Validation loss: 2.6287169736435563

Epoch: 6| Step: 3
Training loss: 2.2421983459423003
Validation loss: 2.640603293732389

Epoch: 6| Step: 4
Training loss: 2.411826471580431
Validation loss: 2.578496018925184

Epoch: 6| Step: 5
Training loss: 2.3085549185080216
Validation loss: 2.5842656395989643

Epoch: 6| Step: 6
Training loss: 1.867889080957206
Validation loss: 2.585030750951708

Epoch: 6| Step: 7
Training loss: 1.9860923724709545
Validation loss: 2.5972520571613447

Epoch: 6| Step: 8
Training loss: 2.249803640486398
Validation loss: 2.615271044752231

Epoch: 6| Step: 9
Training loss: 2.4723145066466343
Validation loss: 2.5906251105958877

Epoch: 6| Step: 10
Training loss: 2.483049915022484
Validation loss: 2.6060094214428777

Epoch: 6| Step: 11
Training loss: 2.568104546382628
Validation loss: 2.5895020987707604

Epoch: 6| Step: 12
Training loss: 2.7603583755576433
Validation loss: 2.6119095683608307

Epoch: 6| Step: 13
Training loss: 2.371458123001625
Validation loss: 2.6246943239683147

Epoch: 334| Step: 0
Training loss: 2.180455663813293
Validation loss: 2.5767549993323686

Epoch: 6| Step: 1
Training loss: 1.9234358489264212
Validation loss: 2.613206767153786

Epoch: 6| Step: 2
Training loss: 2.3108275268056198
Validation loss: 2.638818529598266

Epoch: 6| Step: 3
Training loss: 2.5912581274086395
Validation loss: 2.586927936510418

Epoch: 6| Step: 4
Training loss: 2.464366546237115
Validation loss: 2.568781151964515

Epoch: 6| Step: 5
Training loss: 1.9725983563983023
Validation loss: 2.5913085625863324

Epoch: 6| Step: 6
Training loss: 2.490662015211485
Validation loss: 2.6225830119510967

Epoch: 6| Step: 7
Training loss: 2.3804872267343735
Validation loss: 2.616543479782865

Epoch: 6| Step: 8
Training loss: 3.087766467499202
Validation loss: 2.582928351560972

Epoch: 6| Step: 9
Training loss: 1.708223323846534
Validation loss: 2.568418758009497

Epoch: 6| Step: 10
Training loss: 1.9855050901541285
Validation loss: 2.583034021369552

Epoch: 6| Step: 11
Training loss: 2.259195399235912
Validation loss: 2.6170522298248033

Epoch: 6| Step: 12
Training loss: 2.3430642714304084
Validation loss: 2.6567950795132353

Epoch: 6| Step: 13
Training loss: 3.460277210222041
Validation loss: 2.611919838962536

Epoch: 335| Step: 0
Training loss: 2.0687007748374313
Validation loss: 2.5610470377979215

Epoch: 6| Step: 1
Training loss: 2.4997322892855793
Validation loss: 2.5950668240115924

Epoch: 6| Step: 2
Training loss: 3.1080798034634287
Validation loss: 2.591781803484823

Epoch: 6| Step: 3
Training loss: 2.457339996686247
Validation loss: 2.6026372507968665

Epoch: 6| Step: 4
Training loss: 2.5619683993592086
Validation loss: 2.5766122107940004

Epoch: 6| Step: 5
Training loss: 2.147427852249112
Validation loss: 2.5875909362986116

Epoch: 6| Step: 6
Training loss: 2.179303535359624
Validation loss: 2.6358031832878477

Epoch: 6| Step: 7
Training loss: 2.515458190315745
Validation loss: 2.500711992868904

Epoch: 6| Step: 8
Training loss: 2.3446302668233745
Validation loss: 2.6111153304601875

Epoch: 6| Step: 9
Training loss: 2.2840824049399253
Validation loss: 2.5872338325971693

Epoch: 6| Step: 10
Training loss: 2.062137225064704
Validation loss: 2.5814513762198383

Epoch: 6| Step: 11
Training loss: 2.105792698329107
Validation loss: 2.5807095000171016

Epoch: 6| Step: 12
Training loss: 2.3996301723686186
Validation loss: 2.6465125813597012

Epoch: 6| Step: 13
Training loss: 2.0883688026738585
Validation loss: 2.6142303427231353

Epoch: 336| Step: 0
Training loss: 2.177550221684116
Validation loss: 2.598921973318349

Epoch: 6| Step: 1
Training loss: 2.9692828854593554
Validation loss: 2.6281550745064934

Epoch: 6| Step: 2
Training loss: 2.431442068794778
Validation loss: 2.5699414887089356

Epoch: 6| Step: 3
Training loss: 2.9210687024618154
Validation loss: 2.58951108114276

Epoch: 6| Step: 4
Training loss: 1.8554221057048272
Validation loss: 2.6123605563660677

Epoch: 6| Step: 5
Training loss: 2.581861158531022
Validation loss: 2.5916836104722636

Epoch: 6| Step: 6
Training loss: 1.7528620884859198
Validation loss: 2.6003943809159

Epoch: 6| Step: 7
Training loss: 2.518415336998913
Validation loss: 2.5995377844400154

Epoch: 6| Step: 8
Training loss: 2.735495114466621
Validation loss: 2.6097752219537678

Epoch: 6| Step: 9
Training loss: 1.6503401347907343
Validation loss: 2.6103325704746845

Epoch: 6| Step: 10
Training loss: 2.5774217050909662
Validation loss: 2.612365596575992

Epoch: 6| Step: 11
Training loss: 2.1618899240058607
Validation loss: 2.573808964110642

Epoch: 6| Step: 12
Training loss: 1.3636415983590884
Validation loss: 2.5331046033825833

Epoch: 6| Step: 13
Training loss: 1.7758175511809757
Validation loss: 2.616875093217915

Epoch: 337| Step: 0
Training loss: 2.5885018256720564
Validation loss: 2.6068755153787735

Epoch: 6| Step: 1
Training loss: 2.712073536058754
Validation loss: 2.5822206165600843

Epoch: 6| Step: 2
Training loss: 2.34160169690054
Validation loss: 2.581292544275055

Epoch: 6| Step: 3
Training loss: 1.895915801661494
Validation loss: 2.6014631250473337

Epoch: 6| Step: 4
Training loss: 1.9504145010539762
Validation loss: 2.6340275711372048

Epoch: 6| Step: 5
Training loss: 2.0297586688455507
Validation loss: 2.6138991656287422

Epoch: 6| Step: 6
Training loss: 2.298569035088967
Validation loss: 2.585643571547014

Epoch: 6| Step: 7
Training loss: 2.195765112650176
Validation loss: 2.5622756863830864

Epoch: 6| Step: 8
Training loss: 2.6410326219860076
Validation loss: 2.5692735273886402

Epoch: 6| Step: 9
Training loss: 2.0817979749930835
Validation loss: 2.626444310356162

Epoch: 6| Step: 10
Training loss: 2.079756132465084
Validation loss: 2.515686455288506

Epoch: 6| Step: 11
Training loss: 2.513526562549051
Validation loss: 2.5963272078680517

Epoch: 6| Step: 12
Training loss: 3.0021602482222463
Validation loss: 2.6159785973644665

Epoch: 6| Step: 13
Training loss: 2.1676595931383815
Validation loss: 2.610965228720089

Epoch: 338| Step: 0
Training loss: 1.7628794565994483
Validation loss: 2.5650249320090253

Epoch: 6| Step: 1
Training loss: 1.8495935199706532
Validation loss: 2.587445597973128

Epoch: 6| Step: 2
Training loss: 2.091235002553989
Validation loss: 2.645223251853115

Epoch: 6| Step: 3
Training loss: 1.9294367947829376
Validation loss: 2.580291297323937

Epoch: 6| Step: 4
Training loss: 2.519316151035032
Validation loss: 2.6206565937284783

Epoch: 6| Step: 5
Training loss: 2.5283218212867262
Validation loss: 2.5979680479541623

Epoch: 6| Step: 6
Training loss: 2.4877457693786806
Validation loss: 2.5535825570320205

Epoch: 6| Step: 7
Training loss: 2.0056863058247787
Validation loss: 2.555272993892116

Epoch: 6| Step: 8
Training loss: 2.5347388442610725
Validation loss: 2.6092854735542113

Epoch: 6| Step: 9
Training loss: 3.1622512719571527
Validation loss: 2.6255610355259735

Epoch: 6| Step: 10
Training loss: 2.550037877418595
Validation loss: 2.5697421932858138

Epoch: 6| Step: 11
Training loss: 2.574155398618225
Validation loss: 2.60158101604031

Epoch: 6| Step: 12
Training loss: 1.9132268833272705
Validation loss: 2.610909504773893

Epoch: 6| Step: 13
Training loss: 2.449282120610354
Validation loss: 2.5823534424636287

Epoch: 339| Step: 0
Training loss: 2.1594210541115944
Validation loss: 2.548778023025219

Epoch: 6| Step: 1
Training loss: 2.4203432222784333
Validation loss: 2.5677989762422153

Epoch: 6| Step: 2
Training loss: 2.64822575895828
Validation loss: 2.631079921769954

Epoch: 6| Step: 3
Training loss: 2.469599131128216
Validation loss: 2.607102601593603

Epoch: 6| Step: 4
Training loss: 1.9228565841771972
Validation loss: 2.633758185203826

Epoch: 6| Step: 5
Training loss: 2.285419572835887
Validation loss: 2.574080717833449

Epoch: 6| Step: 6
Training loss: 2.594358257992328
Validation loss: 2.5399713845450176

Epoch: 6| Step: 7
Training loss: 2.378731556759256
Validation loss: 2.567960366380096

Epoch: 6| Step: 8
Training loss: 2.2873401606847095
Validation loss: 2.594898035535481

Epoch: 6| Step: 9
Training loss: 2.659106973304627
Validation loss: 2.6113323621787368

Epoch: 6| Step: 10
Training loss: 1.8363830025885246
Validation loss: 2.627799114584182

Epoch: 6| Step: 11
Training loss: 2.0954767195533197
Validation loss: 2.6153162450430565

Epoch: 6| Step: 12
Training loss: 2.3375148997112447
Validation loss: 2.611524831424379

Epoch: 6| Step: 13
Training loss: 2.8853698800123393
Validation loss: 2.564029048326453

Epoch: 340| Step: 0
Training loss: 2.2645225210251234
Validation loss: 2.6040013165226847

Epoch: 6| Step: 1
Training loss: 2.3125552609001145
Validation loss: 2.6379835190142535

Epoch: 6| Step: 2
Training loss: 2.9960751290470076
Validation loss: 2.6110453553372124

Epoch: 6| Step: 3
Training loss: 2.6210851086447065
Validation loss: 2.5972083478534396

Epoch: 6| Step: 4
Training loss: 2.614086625739732
Validation loss: 2.531454201881336

Epoch: 6| Step: 5
Training loss: 2.3768596395697874
Validation loss: 2.603121914559107

Epoch: 6| Step: 6
Training loss: 2.108441859933821
Validation loss: 2.561974246166353

Epoch: 6| Step: 7
Training loss: 1.635730089740711
Validation loss: 2.589566456238457

Epoch: 6| Step: 8
Training loss: 2.378455910236146
Validation loss: 2.6121383917979815

Epoch: 6| Step: 9
Training loss: 2.1372058599101487
Validation loss: 2.617448565815186

Epoch: 6| Step: 10
Training loss: 2.4334834335575257
Validation loss: 2.607029460526903

Epoch: 6| Step: 11
Training loss: 2.1022141591379615
Validation loss: 2.5815418381449557

Epoch: 6| Step: 12
Training loss: 2.4436819471947264
Validation loss: 2.6267450190056287

Epoch: 6| Step: 13
Training loss: 1.7623584879886234
Validation loss: 2.5784599635993986

Epoch: 341| Step: 0
Training loss: 2.8177082581205704
Validation loss: 2.607951304856412

Epoch: 6| Step: 1
Training loss: 2.203670569431071
Validation loss: 2.602648842445225

Epoch: 6| Step: 2
Training loss: 1.950454045278255
Validation loss: 2.5895931798462146

Epoch: 6| Step: 3
Training loss: 2.658539626708119
Validation loss: 2.588984549952046

Epoch: 6| Step: 4
Training loss: 2.727802945383701
Validation loss: 2.5645573868363694

Epoch: 6| Step: 5
Training loss: 1.92778328907912
Validation loss: 2.606741864862982

Epoch: 6| Step: 6
Training loss: 1.8151765331873126
Validation loss: 2.579566242969187

Epoch: 6| Step: 7
Training loss: 1.6635126629305304
Validation loss: 2.655181521236555

Epoch: 6| Step: 8
Training loss: 2.0869800948110875
Validation loss: 2.6021852820426163

Epoch: 6| Step: 9
Training loss: 2.492879645878037
Validation loss: 2.618472731162528

Epoch: 6| Step: 10
Training loss: 2.832703819651925
Validation loss: 2.5850678560909586

Epoch: 6| Step: 11
Training loss: 2.348431095969884
Validation loss: 2.550644962249269

Epoch: 6| Step: 12
Training loss: 2.142083221279226
Validation loss: 2.613139542021537

Epoch: 6| Step: 13
Training loss: 2.4868813593673598
Validation loss: 2.581995015675642

Epoch: 342| Step: 0
Training loss: 2.3391195714558655
Validation loss: 2.5541929872931175

Epoch: 6| Step: 1
Training loss: 2.48209050545759
Validation loss: 2.6152208981879

Epoch: 6| Step: 2
Training loss: 2.6276914331911967
Validation loss: 2.654170982748968

Epoch: 6| Step: 3
Training loss: 2.4376592339565337
Validation loss: 2.5308715900040983

Epoch: 6| Step: 4
Training loss: 2.4448120775144155
Validation loss: 2.6035698549314668

Epoch: 6| Step: 5
Training loss: 2.203518987827883
Validation loss: 2.601661225729097

Epoch: 6| Step: 6
Training loss: 2.1546491125724687
Validation loss: 2.635342966378874

Epoch: 6| Step: 7
Training loss: 2.289869355052381
Validation loss: 2.584863268892301

Epoch: 6| Step: 8
Training loss: 2.8384625251773077
Validation loss: 2.5798748483055034

Epoch: 6| Step: 9
Training loss: 2.001918945020717
Validation loss: 2.596369419321959

Epoch: 6| Step: 10
Training loss: 1.7741094316191737
Validation loss: 2.615516718242539

Epoch: 6| Step: 11
Training loss: 2.5931693656621793
Validation loss: 2.6184025071773416

Epoch: 6| Step: 12
Training loss: 2.102139645424915
Validation loss: 2.630160315063207

Epoch: 6| Step: 13
Training loss: 2.322107513409534
Validation loss: 2.6039620710829428

Epoch: 343| Step: 0
Training loss: 2.8466714796729873
Validation loss: 2.572306640680708

Epoch: 6| Step: 1
Training loss: 1.862499400913219
Validation loss: 2.5420640936974146

Epoch: 6| Step: 2
Training loss: 2.1329299838507407
Validation loss: 2.6375432942716377

Epoch: 6| Step: 3
Training loss: 2.018194409142911
Validation loss: 2.600562326653417

Epoch: 6| Step: 4
Training loss: 2.6699606300337417
Validation loss: 2.5932779625131603

Epoch: 6| Step: 5
Training loss: 2.1698559494373337
Validation loss: 2.5442349351838454

Epoch: 6| Step: 6
Training loss: 1.7897440848872885
Validation loss: 2.623074539785502

Epoch: 6| Step: 7
Training loss: 2.443517446550501
Validation loss: 2.565374093693682

Epoch: 6| Step: 8
Training loss: 2.07662841141164
Validation loss: 2.6094439603464057

Epoch: 6| Step: 9
Training loss: 2.648842389600379
Validation loss: 2.597251204342356

Epoch: 6| Step: 10
Training loss: 2.600624533985319
Validation loss: 2.561625497755531

Epoch: 6| Step: 11
Training loss: 2.320267904861331
Validation loss: 2.5743028914341353

Epoch: 6| Step: 12
Training loss: 2.2307003722706438
Validation loss: 2.619307081986002

Epoch: 6| Step: 13
Training loss: 2.3367917339287145
Validation loss: 2.570790164380508

Epoch: 344| Step: 0
Training loss: 2.6057830575212875
Validation loss: 2.5998141872341933

Epoch: 6| Step: 1
Training loss: 2.144669325088847
Validation loss: 2.6351561642325763

Epoch: 6| Step: 2
Training loss: 2.5182568542999175
Validation loss: 2.631495719062019

Epoch: 6| Step: 3
Training loss: 1.9000369896550686
Validation loss: 2.630740257497381

Epoch: 6| Step: 4
Training loss: 2.333932277465106
Validation loss: 2.529158392075988

Epoch: 6| Step: 5
Training loss: 2.1634315645146667
Validation loss: 2.5758182730429064

Epoch: 6| Step: 6
Training loss: 2.165250046102296
Validation loss: 2.5973430090938767

Epoch: 6| Step: 7
Training loss: 1.5461141082826613
Validation loss: 2.5820376957524407

Epoch: 6| Step: 8
Training loss: 2.1370035989362433
Validation loss: 2.554100081227894

Epoch: 6| Step: 9
Training loss: 2.4772747952895644
Validation loss: 2.587173622999347

Epoch: 6| Step: 10
Training loss: 2.7346431927627473
Validation loss: 2.6086532324526455

Epoch: 6| Step: 11
Training loss: 2.4733588740563
Validation loss: 2.593360410535453

Epoch: 6| Step: 12
Training loss: 2.319429171645794
Validation loss: 2.624321952047105

Epoch: 6| Step: 13
Training loss: 2.688839955405701
Validation loss: 2.605639684352864

Epoch: 345| Step: 0
Training loss: 2.4106403278934643
Validation loss: 2.5927766588906085

Epoch: 6| Step: 1
Training loss: 2.1227126433091343
Validation loss: 2.5884275281043627

Epoch: 6| Step: 2
Training loss: 2.394950195304337
Validation loss: 2.656659154969998

Epoch: 6| Step: 3
Training loss: 2.2548332225423486
Validation loss: 2.599594682104161

Epoch: 6| Step: 4
Training loss: 2.6223947221336297
Validation loss: 2.6051007163838853

Epoch: 6| Step: 5
Training loss: 3.3499401941227576
Validation loss: 2.607275856510301

Epoch: 6| Step: 6
Training loss: 1.9238902745156374
Validation loss: 2.5637403588107626

Epoch: 6| Step: 7
Training loss: 1.8322585885982206
Validation loss: 2.6170812255557903

Epoch: 6| Step: 8
Training loss: 2.3427807647603216
Validation loss: 2.627549190091037

Epoch: 6| Step: 9
Training loss: 1.4931795507392436
Validation loss: 2.5929205791828167

Epoch: 6| Step: 10
Training loss: 2.3281112772901986
Validation loss: 2.6192957167437023

Epoch: 6| Step: 11
Training loss: 2.381054339042352
Validation loss: 2.593043715852653

Epoch: 6| Step: 12
Training loss: 2.152177143052617
Validation loss: 2.623023825024426

Epoch: 6| Step: 13
Training loss: 2.5007608209673515
Validation loss: 2.6107475193724157

Epoch: 346| Step: 0
Training loss: 1.6616139912012102
Validation loss: 2.6571420357625093

Epoch: 6| Step: 1
Training loss: 2.5103351585061757
Validation loss: 2.6009218170482553

Epoch: 6| Step: 2
Training loss: 2.289488560731514
Validation loss: 2.6005540784314864

Epoch: 6| Step: 3
Training loss: 2.0050595182874247
Validation loss: 2.618601349009979

Epoch: 6| Step: 4
Training loss: 2.165606006797743
Validation loss: 2.6327769606718343

Epoch: 6| Step: 5
Training loss: 2.8610671409347463
Validation loss: 2.6213152611976542

Epoch: 6| Step: 6
Training loss: 2.2096163303597702
Validation loss: 2.5442112387017506

Epoch: 6| Step: 7
Training loss: 2.1926842429196114
Validation loss: 2.5681145569323243

Epoch: 6| Step: 8
Training loss: 3.409949297486076
Validation loss: 2.574297975873383

Epoch: 6| Step: 9
Training loss: 2.380602002021507
Validation loss: 2.584440574246083

Epoch: 6| Step: 10
Training loss: 2.443997453029573
Validation loss: 2.5635384062120576

Epoch: 6| Step: 11
Training loss: 1.7093183267463317
Validation loss: 2.544399757522441

Epoch: 6| Step: 12
Training loss: 1.535214566198148
Validation loss: 2.6186396319928607

Epoch: 6| Step: 13
Training loss: 2.4610446482750414
Validation loss: 2.5946381549783584

Epoch: 347| Step: 0
Training loss: 1.879438233753216
Validation loss: 2.596077609116554

Epoch: 6| Step: 1
Training loss: 2.4197012713775843
Validation loss: 2.5933003486177206

Epoch: 6| Step: 2
Training loss: 2.367542605313804
Validation loss: 2.5842644630641534

Epoch: 6| Step: 3
Training loss: 2.5635141366293905
Validation loss: 2.558086847978192

Epoch: 6| Step: 4
Training loss: 1.7718457039592685
Validation loss: 2.6064352190094464

Epoch: 6| Step: 5
Training loss: 2.406024179142108
Validation loss: 2.6350055980185094

Epoch: 6| Step: 6
Training loss: 2.275219405776372
Validation loss: 2.586270997763274

Epoch: 6| Step: 7
Training loss: 2.1726356107574385
Validation loss: 2.599209312791872

Epoch: 6| Step: 8
Training loss: 3.419105558717846
Validation loss: 2.6062955555918577

Epoch: 6| Step: 9
Training loss: 2.3651660307657854
Validation loss: 2.5687540826000816

Epoch: 6| Step: 10
Training loss: 2.054453093063134
Validation loss: 2.5685826602884325

Epoch: 6| Step: 11
Training loss: 2.0420213767491724
Validation loss: 2.623382861304188

Epoch: 6| Step: 12
Training loss: 2.341979209794593
Validation loss: 2.60024332114042

Epoch: 6| Step: 13
Training loss: 1.8042845833577112
Validation loss: 2.625229164820293

Epoch: 348| Step: 0
Training loss: 2.7183591188961564
Validation loss: 2.5808711675281453

Epoch: 6| Step: 1
Training loss: 1.8977173118142998
Validation loss: 2.579386713936461

Epoch: 6| Step: 2
Training loss: 2.0978758286785495
Validation loss: 2.6161365106254557

Epoch: 6| Step: 3
Training loss: 1.580033309923411
Validation loss: 2.5793462173497663

Epoch: 6| Step: 4
Training loss: 2.4642495770697375
Validation loss: 2.5658110569925765

Epoch: 6| Step: 5
Training loss: 2.6689169052069444
Validation loss: 2.632463709304492

Epoch: 6| Step: 6
Training loss: 2.0435946437572117
Validation loss: 2.5946950573285443

Epoch: 6| Step: 7
Training loss: 2.415861181875224
Validation loss: 2.6096777275823797

Epoch: 6| Step: 8
Training loss: 2.3897061046755588
Validation loss: 2.5647658248259035

Epoch: 6| Step: 9
Training loss: 2.428811065487288
Validation loss: 2.570789936017361

Epoch: 6| Step: 10
Training loss: 2.0488881701461037
Validation loss: 2.5751875554503423

Epoch: 6| Step: 11
Training loss: 2.670366720382368
Validation loss: 2.5908629065645656

Epoch: 6| Step: 12
Training loss: 2.3164894127672784
Validation loss: 2.610691234979987

Epoch: 6| Step: 13
Training loss: 2.191808435861341
Validation loss: 2.5742467672419362

Epoch: 349| Step: 0
Training loss: 2.0093567842930415
Validation loss: 2.634738450770836

Epoch: 6| Step: 1
Training loss: 2.5841035822606915
Validation loss: 2.6089899973892594

Epoch: 6| Step: 2
Training loss: 2.0661825192342778
Validation loss: 2.582693315098832

Epoch: 6| Step: 3
Training loss: 2.3660437713404985
Validation loss: 2.6605543947794783

Epoch: 6| Step: 4
Training loss: 2.6279461993744544
Validation loss: 2.5841057697988568

Epoch: 6| Step: 5
Training loss: 2.5538358522866744
Validation loss: 2.5761878707617902

Epoch: 6| Step: 6
Training loss: 2.3525380490476233
Validation loss: 2.6010048196573394

Epoch: 6| Step: 7
Training loss: 3.0219495793698985
Validation loss: 2.622779425550543

Epoch: 6| Step: 8
Training loss: 1.6549209444462727
Validation loss: 2.595496932480327

Epoch: 6| Step: 9
Training loss: 1.863016425612684
Validation loss: 2.5667886589420768

Epoch: 6| Step: 10
Training loss: 2.267689993741394
Validation loss: 2.629106150114098

Epoch: 6| Step: 11
Training loss: 1.9269162560969961
Validation loss: 2.5895713190566894

Epoch: 6| Step: 12
Training loss: 2.288554581154413
Validation loss: 2.6219961526548285

Epoch: 6| Step: 13
Training loss: 2.2965305615066574
Validation loss: 2.5624844930536264

Epoch: 350| Step: 0
Training loss: 2.3003855755245777
Validation loss: 2.5797293992333445

Epoch: 6| Step: 1
Training loss: 2.1444512023994986
Validation loss: 2.562996562843991

Epoch: 6| Step: 2
Training loss: 1.2925128421108567
Validation loss: 2.5677295359370715

Epoch: 6| Step: 3
Training loss: 2.390797727241476
Validation loss: 2.5885537401995102

Epoch: 6| Step: 4
Training loss: 2.9793465477761405
Validation loss: 2.5526798544786224

Epoch: 6| Step: 5
Training loss: 2.2661523665592114
Validation loss: 2.5844263049791807

Epoch: 6| Step: 6
Training loss: 2.3339328903840415
Validation loss: 2.566616848159957

Epoch: 6| Step: 7
Training loss: 2.1452702150671596
Validation loss: 2.535064563641397

Epoch: 6| Step: 8
Training loss: 2.2677511827669536
Validation loss: 2.610940013074798

Epoch: 6| Step: 9
Training loss: 1.7987325603601974
Validation loss: 2.5516492168443143

Epoch: 6| Step: 10
Training loss: 2.190692860290982
Validation loss: 2.6254043140769125

Epoch: 6| Step: 11
Training loss: 2.084130350879716
Validation loss: 2.630236043980034

Epoch: 6| Step: 12
Training loss: 2.5723451502157286
Validation loss: 2.562057482919714

Epoch: 6| Step: 13
Training loss: 2.710487966066382
Validation loss: 2.595003706950186

Epoch: 351| Step: 0
Training loss: 2.1875880632385587
Validation loss: 2.566396887083467

Epoch: 6| Step: 1
Training loss: 2.3990215373247175
Validation loss: 2.6230025165179502

Epoch: 6| Step: 2
Training loss: 2.291319271690826
Validation loss: 2.6054849299582954

Epoch: 6| Step: 3
Training loss: 1.8104533775245197
Validation loss: 2.597939226711564

Epoch: 6| Step: 4
Training loss: 1.6249895095486582
Validation loss: 2.6101037949859305

Epoch: 6| Step: 5
Training loss: 2.1880139428344796
Validation loss: 2.6214788780621916

Epoch: 6| Step: 6
Training loss: 2.344052918250168
Validation loss: 2.61515045356081

Epoch: 6| Step: 7
Training loss: 3.3055329379920555
Validation loss: 2.597311229678444

Epoch: 6| Step: 8
Training loss: 2.0328379366292633
Validation loss: 2.547233428988874

Epoch: 6| Step: 9
Training loss: 1.7864259173804478
Validation loss: 2.6120230639227966

Epoch: 6| Step: 10
Training loss: 2.2020857503896374
Validation loss: 2.550169239062116

Epoch: 6| Step: 11
Training loss: 1.911495558318202
Validation loss: 2.600135543680464

Epoch: 6| Step: 12
Training loss: 2.5605790916761397
Validation loss: 2.6290586301506464

Epoch: 6| Step: 13
Training loss: 2.974725752299126
Validation loss: 2.6073379921587

Epoch: 352| Step: 0
Training loss: 1.9418624249883891
Validation loss: 2.6037590708722855

Epoch: 6| Step: 1
Training loss: 2.0503015156890503
Validation loss: 2.5302789441663887

Epoch: 6| Step: 2
Training loss: 2.358185929543279
Validation loss: 2.5270110783382114

Epoch: 6| Step: 3
Training loss: 2.0578952595978004
Validation loss: 2.5934742932859542

Epoch: 6| Step: 4
Training loss: 2.5071227649260903
Validation loss: 2.587016894897129

Epoch: 6| Step: 5
Training loss: 1.9690645965627973
Validation loss: 2.584250475551922

Epoch: 6| Step: 6
Training loss: 2.0726680382868925
Validation loss: 2.5925199040765565

Epoch: 6| Step: 7
Training loss: 2.7450820991176195
Validation loss: 2.575711671199618

Epoch: 6| Step: 8
Training loss: 1.5340024383157502
Validation loss: 2.6613632335103183

Epoch: 6| Step: 9
Training loss: 1.9554173559185868
Validation loss: 2.5869304328333937

Epoch: 6| Step: 10
Training loss: 2.81140598636122
Validation loss: 2.5537482537647547

Epoch: 6| Step: 11
Training loss: 2.2502807865840295
Validation loss: 2.6210409820268916

Epoch: 6| Step: 12
Training loss: 3.059195935441753
Validation loss: 2.635155159266982

Epoch: 6| Step: 13
Training loss: 2.0570516583118126
Validation loss: 2.6227804293934143

Epoch: 353| Step: 0
Training loss: 2.229858421826458
Validation loss: 2.573546695945898

Epoch: 6| Step: 1
Training loss: 2.186903518006753
Validation loss: 2.6285312377005075

Epoch: 6| Step: 2
Training loss: 1.8307783645668352
Validation loss: 2.6083018666809177

Epoch: 6| Step: 3
Training loss: 2.6720156270101283
Validation loss: 2.630742124627251

Epoch: 6| Step: 4
Training loss: 2.0939184092645498
Validation loss: 2.6015041997259383

Epoch: 6| Step: 5
Training loss: 1.6417189084694948
Validation loss: 2.6045663506394265

Epoch: 6| Step: 6
Training loss: 2.747652438987885
Validation loss: 2.586306584377875

Epoch: 6| Step: 7
Training loss: 1.7492452083629422
Validation loss: 2.645124792238122

Epoch: 6| Step: 8
Training loss: 2.8734033546265145
Validation loss: 2.5475814315728256

Epoch: 6| Step: 9
Training loss: 2.4982566476987498
Validation loss: 2.6184362345067353

Epoch: 6| Step: 10
Training loss: 2.1077498215277224
Validation loss: 2.6033426348603936

Epoch: 6| Step: 11
Training loss: 2.25233444333676
Validation loss: 2.647096106969543

Epoch: 6| Step: 12
Training loss: 1.7670138137959623
Validation loss: 2.64194747779545

Epoch: 6| Step: 13
Training loss: 2.9264167940820642
Validation loss: 2.5710515780171423

Epoch: 354| Step: 0
Training loss: 2.1220145852381362
Validation loss: 2.594518639281962

Epoch: 6| Step: 1
Training loss: 2.420202354451569
Validation loss: 2.6353390129490966

Epoch: 6| Step: 2
Training loss: 1.9244586356740776
Validation loss: 2.615087347244526

Epoch: 6| Step: 3
Training loss: 2.84329823688821
Validation loss: 2.5830286093049355

Epoch: 6| Step: 4
Training loss: 2.585389047414191
Validation loss: 2.5570383932462284

Epoch: 6| Step: 5
Training loss: 2.4903689838006082
Validation loss: 2.632625413130439

Epoch: 6| Step: 6
Training loss: 1.9948818760752247
Validation loss: 2.600498510936554

Epoch: 6| Step: 7
Training loss: 2.492096997952646
Validation loss: 2.623221318748361

Epoch: 6| Step: 8
Training loss: 1.8730174073257144
Validation loss: 2.6027502760310055

Epoch: 6| Step: 9
Training loss: 2.087097759667871
Validation loss: 2.6250787460461913

Epoch: 6| Step: 10
Training loss: 2.314010127039636
Validation loss: 2.6136506603705496

Epoch: 6| Step: 11
Training loss: 2.170183140282341
Validation loss: 2.601828940909222

Epoch: 6| Step: 12
Training loss: 2.0576149859459627
Validation loss: 2.6262917384980655

Epoch: 6| Step: 13
Training loss: 2.1328010977974747
Validation loss: 2.5645931657922354

Epoch: 355| Step: 0
Training loss: 2.0435148424655383
Validation loss: 2.553192826355398

Epoch: 6| Step: 1
Training loss: 1.9709770685194479
Validation loss: 2.623111340358983

Epoch: 6| Step: 2
Training loss: 2.916000580796758
Validation loss: 2.6153765301599616

Epoch: 6| Step: 3
Training loss: 2.314976783454765
Validation loss: 2.593320899771398

Epoch: 6| Step: 4
Training loss: 2.156627787790369
Validation loss: 2.631121314554679

Epoch: 6| Step: 5
Training loss: 2.991248080439894
Validation loss: 2.5685124836101063

Epoch: 6| Step: 6
Training loss: 2.487540190098881
Validation loss: 2.5733309445435695

Epoch: 6| Step: 7
Training loss: 2.078065340720242
Validation loss: 2.5554298671216946

Epoch: 6| Step: 8
Training loss: 2.2753596094989166
Validation loss: 2.605866199444093

Epoch: 6| Step: 9
Training loss: 1.8099981997149035
Validation loss: 2.610292922285938

Epoch: 6| Step: 10
Training loss: 2.221635044194317
Validation loss: 2.6479150332555417

Epoch: 6| Step: 11
Training loss: 2.1354524811013116
Validation loss: 2.616286294121156

Epoch: 6| Step: 12
Training loss: 1.8652382096655609
Validation loss: 2.5792292721217094

Epoch: 6| Step: 13
Training loss: 2.4203675531636155
Validation loss: 2.5931967115388734

Epoch: 356| Step: 0
Training loss: 1.7255548497040476
Validation loss: 2.614471222005485

Epoch: 6| Step: 1
Training loss: 1.9193960189537966
Validation loss: 2.593292844425531

Epoch: 6| Step: 2
Training loss: 3.1086866680791374
Validation loss: 2.5761040705358966

Epoch: 6| Step: 3
Training loss: 3.1861165354190213
Validation loss: 2.6126524034360252

Epoch: 6| Step: 4
Training loss: 2.4444290856639896
Validation loss: 2.631778761791162

Epoch: 6| Step: 5
Training loss: 1.9428434214187582
Validation loss: 2.600981975501309

Epoch: 6| Step: 6
Training loss: 2.5477542412660528
Validation loss: 2.642232759930659

Epoch: 6| Step: 7
Training loss: 2.002882549116198
Validation loss: 2.5967917379946956

Epoch: 6| Step: 8
Training loss: 2.060211067497493
Validation loss: 2.592229870878128

Epoch: 6| Step: 9
Training loss: 1.8717356558314182
Validation loss: 2.6094238942785846

Epoch: 6| Step: 10
Training loss: 2.207087423234256
Validation loss: 2.6094475261356966

Epoch: 6| Step: 11
Training loss: 1.8366588717443495
Validation loss: 2.5841546451686748

Epoch: 6| Step: 12
Training loss: 2.4085783159551517
Validation loss: 2.6225157901120375

Epoch: 6| Step: 13
Training loss: 2.0766116490227375
Validation loss: 2.6280720085297506

Epoch: 357| Step: 0
Training loss: 2.2017376366419024
Validation loss: 2.61970759405117

Epoch: 6| Step: 1
Training loss: 2.1646097641164337
Validation loss: 2.633707724837185

Epoch: 6| Step: 2
Training loss: 2.151614306123301
Validation loss: 2.525798786353752

Epoch: 6| Step: 3
Training loss: 1.781382907125275
Validation loss: 2.5660739249672617

Epoch: 6| Step: 4
Training loss: 1.9526893435019181
Validation loss: 2.591088887009026

Epoch: 6| Step: 5
Training loss: 2.286420110732061
Validation loss: 2.6158639523346845

Epoch: 6| Step: 6
Training loss: 2.1519097030726506
Validation loss: 2.562481524713255

Epoch: 6| Step: 7
Training loss: 1.3535243002433248
Validation loss: 2.594168848505666

Epoch: 6| Step: 8
Training loss: 2.471632228653418
Validation loss: 2.5413735699989455

Epoch: 6| Step: 9
Training loss: 3.3350355729203316
Validation loss: 2.615166021711275

Epoch: 6| Step: 10
Training loss: 2.2086890551929885
Validation loss: 2.56973159199535

Epoch: 6| Step: 11
Training loss: 3.0860634307275867
Validation loss: 2.5630094420473286

Epoch: 6| Step: 12
Training loss: 2.277500363129002
Validation loss: 2.560767819110924

Epoch: 6| Step: 13
Training loss: 2.2285835596774466
Validation loss: 2.587014574058377

Epoch: 358| Step: 0
Training loss: 2.4258732432737786
Validation loss: 2.5604054384150494

Epoch: 6| Step: 1
Training loss: 2.0936401110607177
Validation loss: 2.598563659465299

Epoch: 6| Step: 2
Training loss: 1.9624271889561522
Validation loss: 2.565869423913729

Epoch: 6| Step: 3
Training loss: 2.0995106944470208
Validation loss: 2.61262167668691

Epoch: 6| Step: 4
Training loss: 3.324002286898748
Validation loss: 2.531978966578463

Epoch: 6| Step: 5
Training loss: 1.9354801108723694
Validation loss: 2.5506469000717966

Epoch: 6| Step: 6
Training loss: 2.0217770866729596
Validation loss: 2.6394600344238364

Epoch: 6| Step: 7
Training loss: 2.2724891598550996
Validation loss: 2.5965569246729983

Epoch: 6| Step: 8
Training loss: 2.386925321589414
Validation loss: 2.6343455422505047

Epoch: 6| Step: 9
Training loss: 1.504595472268712
Validation loss: 2.6110405708043674

Epoch: 6| Step: 10
Training loss: 2.1840992241840897
Validation loss: 2.614382362821039

Epoch: 6| Step: 11
Training loss: 2.201591661529497
Validation loss: 2.5393591630027044

Epoch: 6| Step: 12
Training loss: 1.9326516062103767
Validation loss: 2.5712012654324843

Epoch: 6| Step: 13
Training loss: 2.695041189498231
Validation loss: 2.589625347006081

Epoch: 359| Step: 0
Training loss: 2.1083167918565318
Validation loss: 2.6799979387494877

Epoch: 6| Step: 1
Training loss: 1.9019688544305549
Validation loss: 2.617799197473368

Epoch: 6| Step: 2
Training loss: 2.40734085523553
Validation loss: 2.6407421969765914

Epoch: 6| Step: 3
Training loss: 1.6671457873545268
Validation loss: 2.6337055814182615

Epoch: 6| Step: 4
Training loss: 2.575816837859817
Validation loss: 2.6050269719437664

Epoch: 6| Step: 5
Training loss: 2.237359674411583
Validation loss: 2.5858924157170904

Epoch: 6| Step: 6
Training loss: 2.5244252069990947
Validation loss: 2.606720810748993

Epoch: 6| Step: 7
Training loss: 2.494643576626099
Validation loss: 2.565513051968183

Epoch: 6| Step: 8
Training loss: 2.3350536498741365
Validation loss: 2.5617153077771566

Epoch: 6| Step: 9
Training loss: 1.93935262644405
Validation loss: 2.5840100620321755

Epoch: 6| Step: 10
Training loss: 2.025382384942857
Validation loss: 2.650681582883888

Epoch: 6| Step: 11
Training loss: 1.9951254330547306
Validation loss: 2.5843569900387693

Epoch: 6| Step: 12
Training loss: 2.7498722913739044
Validation loss: 2.5923031486510006

Epoch: 6| Step: 13
Training loss: 2.3943213515518487
Validation loss: 2.6367247577387625

Epoch: 360| Step: 0
Training loss: 1.9995494573476171
Validation loss: 2.577316487537744

Epoch: 6| Step: 1
Training loss: 1.7565262220919118
Validation loss: 2.6014412398358284

Epoch: 6| Step: 2
Training loss: 1.7396280279147585
Validation loss: 2.5760535765211108

Epoch: 6| Step: 3
Training loss: 2.0939841068397023
Validation loss: 2.5944640373583456

Epoch: 6| Step: 4
Training loss: 2.0294305722470036
Validation loss: 2.6385529003253385

Epoch: 6| Step: 5
Training loss: 2.2371796831553117
Validation loss: 2.595889895330264

Epoch: 6| Step: 6
Training loss: 2.139167345039707
Validation loss: 2.6067059794358625

Epoch: 6| Step: 7
Training loss: 2.258554831571635
Validation loss: 2.6222944443607443

Epoch: 6| Step: 8
Training loss: 2.959725728344423
Validation loss: 2.6290338054964217

Epoch: 6| Step: 9
Training loss: 2.7874359602478602
Validation loss: 2.6134246846159317

Epoch: 6| Step: 10
Training loss: 1.9294611995064843
Validation loss: 2.618155520163899

Epoch: 6| Step: 11
Training loss: 2.0723428235429084
Validation loss: 2.58763777528683

Epoch: 6| Step: 12
Training loss: 2.949674336189539
Validation loss: 2.5909864269751886

Epoch: 6| Step: 13
Training loss: 2.0465086397966785
Validation loss: 2.6186332724199026

Epoch: 361| Step: 0
Training loss: 2.610283790447852
Validation loss: 2.630338428309204

Epoch: 6| Step: 1
Training loss: 1.8349496334554023
Validation loss: 2.5738636087876503

Epoch: 6| Step: 2
Training loss: 1.8866716146011082
Validation loss: 2.5661081032989337

Epoch: 6| Step: 3
Training loss: 1.385134111239332
Validation loss: 2.6301324148480223

Epoch: 6| Step: 4
Training loss: 2.304145154340965
Validation loss: 2.6542694718906263

Epoch: 6| Step: 5
Training loss: 2.494555457499791
Validation loss: 2.641360727536708

Epoch: 6| Step: 6
Training loss: 2.3279777326665956
Validation loss: 2.636837283394202

Epoch: 6| Step: 7
Training loss: 2.060357570539989
Validation loss: 2.576309323458519

Epoch: 6| Step: 8
Training loss: 2.298118825431623
Validation loss: 2.562164178588364

Epoch: 6| Step: 9
Training loss: 2.544009041308285
Validation loss: 2.638046102398022

Epoch: 6| Step: 10
Training loss: 2.2114711157964955
Validation loss: 2.6585316538299475

Epoch: 6| Step: 11
Training loss: 2.1553856043110904
Validation loss: 2.596164792528621

Epoch: 6| Step: 12
Training loss: 2.161203858129548
Validation loss: 2.5872023808547744

Epoch: 6| Step: 13
Training loss: 2.446822507643563
Validation loss: 2.6035514603645606

Epoch: 362| Step: 0
Training loss: 2.375120260305892
Validation loss: 2.6603915448516813

Epoch: 6| Step: 1
Training loss: 2.223762116423304
Validation loss: 2.5971686217104892

Epoch: 6| Step: 2
Training loss: 2.277680413044122
Validation loss: 2.5854927475858718

Epoch: 6| Step: 3
Training loss: 2.2834320084163986
Validation loss: 2.595053286919241

Epoch: 6| Step: 4
Training loss: 2.566070859874674
Validation loss: 2.6282540186514005

Epoch: 6| Step: 5
Training loss: 2.0799003417642736
Validation loss: 2.6030217255593873

Epoch: 6| Step: 6
Training loss: 1.804607571239669
Validation loss: 2.6270670675072583

Epoch: 6| Step: 7
Training loss: 1.8527364751332183
Validation loss: 2.580702599948861

Epoch: 6| Step: 8
Training loss: 2.4058465000061404
Validation loss: 2.5920398617821774

Epoch: 6| Step: 9
Training loss: 2.711462052575129
Validation loss: 2.594608578424101

Epoch: 6| Step: 10
Training loss: 2.2215820291036144
Validation loss: 2.6037772941315684

Epoch: 6| Step: 11
Training loss: 2.0234721412786394
Validation loss: 2.6366980655395116

Epoch: 6| Step: 12
Training loss: 2.390231230974195
Validation loss: 2.60461347590307

Epoch: 6| Step: 13
Training loss: 2.008607818186281
Validation loss: 2.597919651530452

Epoch: 363| Step: 0
Training loss: 2.419410977994072
Validation loss: 2.584388426810685

Epoch: 6| Step: 1
Training loss: 2.145295331848753
Validation loss: 2.5896419209611596

Epoch: 6| Step: 2
Training loss: 2.480678663608021
Validation loss: 2.5768231139853763

Epoch: 6| Step: 3
Training loss: 2.1280630139077434
Validation loss: 2.583912221557402

Epoch: 6| Step: 4
Training loss: 2.283171797929868
Validation loss: 2.6056320774620785

Epoch: 6| Step: 5
Training loss: 1.8558427614413058
Validation loss: 2.609880906897574

Epoch: 6| Step: 6
Training loss: 2.536235467935877
Validation loss: 2.5816209902256806

Epoch: 6| Step: 7
Training loss: 1.3990823122231701
Validation loss: 2.6459830153525217

Epoch: 6| Step: 8
Training loss: 2.1628438775396712
Validation loss: 2.5894033604208544

Epoch: 6| Step: 9
Training loss: 1.9955142499452665
Validation loss: 2.589698300521192

Epoch: 6| Step: 10
Training loss: 2.6899650269401065
Validation loss: 2.619227639750005

Epoch: 6| Step: 11
Training loss: 2.4162046933650423
Validation loss: 2.638596071456177

Epoch: 6| Step: 12
Training loss: 2.143955952618901
Validation loss: 2.5546698618406625

Epoch: 6| Step: 13
Training loss: 2.2405939586835473
Validation loss: 2.6632453045924613

Epoch: 364| Step: 0
Training loss: 2.525893395126263
Validation loss: 2.616422965854805

Epoch: 6| Step: 1
Training loss: 1.8083647547978985
Validation loss: 2.5836732391344484

Epoch: 6| Step: 2
Training loss: 1.630027988521187
Validation loss: 2.646167444965789

Epoch: 6| Step: 3
Training loss: 2.4618274835405956
Validation loss: 2.595846715150715

Epoch: 6| Step: 4
Training loss: 2.129181506359645
Validation loss: 2.6031031002394944

Epoch: 6| Step: 5
Training loss: 2.187233717923741
Validation loss: 2.5476728938811295

Epoch: 6| Step: 6
Training loss: 2.0603354684575588
Validation loss: 2.5449609026686044

Epoch: 6| Step: 7
Training loss: 2.49063061721915
Validation loss: 2.6151104921715222

Epoch: 6| Step: 8
Training loss: 2.658432008193458
Validation loss: 2.5846323471359005

Epoch: 6| Step: 9
Training loss: 2.239656515182575
Validation loss: 2.584571971792921

Epoch: 6| Step: 10
Training loss: 2.1963108819850454
Validation loss: 2.5934074690634095

Epoch: 6| Step: 11
Training loss: 1.999541528127918
Validation loss: 2.5849055475475105

Epoch: 6| Step: 12
Training loss: 2.8071787191587227
Validation loss: 2.6098364493901642

Epoch: 6| Step: 13
Training loss: 1.5473620486051418
Validation loss: 2.583453625813437

Epoch: 365| Step: 0
Training loss: 2.3427416857737873
Validation loss: 2.579286921924446

Epoch: 6| Step: 1
Training loss: 2.1131503757418795
Validation loss: 2.58603318054786

Epoch: 6| Step: 2
Training loss: 1.9431044214827067
Validation loss: 2.6372775346115587

Epoch: 6| Step: 3
Training loss: 2.3596177134186385
Validation loss: 2.5943074146941476

Epoch: 6| Step: 4
Training loss: 1.94975129766772
Validation loss: 2.617053759945393

Epoch: 6| Step: 5
Training loss: 1.7518333640783437
Validation loss: 2.573801163040646

Epoch: 6| Step: 6
Training loss: 2.101603794755766
Validation loss: 2.6599657238252217

Epoch: 6| Step: 7
Training loss: 2.3796661115500464
Validation loss: 2.617599689446056

Epoch: 6| Step: 8
Training loss: 1.9433891869180073
Validation loss: 2.5951549363788087

Epoch: 6| Step: 9
Training loss: 1.962656430369787
Validation loss: 2.579759017187426

Epoch: 6| Step: 10
Training loss: 2.5226940087227203
Validation loss: 2.647085763659602

Epoch: 6| Step: 11
Training loss: 2.7570271440898604
Validation loss: 2.590241877799279

Epoch: 6| Step: 12
Training loss: 2.910561757349802
Validation loss: 2.639077028182224

Epoch: 6| Step: 13
Training loss: 2.6425191191790933
Validation loss: 2.5839974006023976

Epoch: 366| Step: 0
Training loss: 2.4315428687365688
Validation loss: 2.578469533263336

Epoch: 6| Step: 1
Training loss: 2.424836249574341
Validation loss: 2.591598509951494

Epoch: 6| Step: 2
Training loss: 1.8053511022898185
Validation loss: 2.620828116289287

Epoch: 6| Step: 3
Training loss: 2.261902164276085
Validation loss: 2.5583294500645017

Epoch: 6| Step: 4
Training loss: 2.577476651134981
Validation loss: 2.5949633898644002

Epoch: 6| Step: 5
Training loss: 2.297548156499251
Validation loss: 2.590987332317937

Epoch: 6| Step: 6
Training loss: 2.2132362304590094
Validation loss: 2.627734651058236

Epoch: 6| Step: 7
Training loss: 2.4482842568433774
Validation loss: 2.5692091001401502

Epoch: 6| Step: 8
Training loss: 1.5998864312397272
Validation loss: 2.609282520137197

Epoch: 6| Step: 9
Training loss: 1.9007583058607382
Validation loss: 2.608336188529604

Epoch: 6| Step: 10
Training loss: 1.3868973737839925
Validation loss: 2.576035348713881

Epoch: 6| Step: 11
Training loss: 3.266118208587347
Validation loss: 2.592077452092633

Epoch: 6| Step: 12
Training loss: 2.16337161276659
Validation loss: 2.64530497778978

Epoch: 6| Step: 13
Training loss: 2.4425172276899616
Validation loss: 2.607284028405069

Epoch: 367| Step: 0
Training loss: 2.856120273974676
Validation loss: 2.6213978126945574

Epoch: 6| Step: 1
Training loss: 2.1252284207713066
Validation loss: 2.591259147420095

Epoch: 6| Step: 2
Training loss: 2.7455069510518317
Validation loss: 2.520564422325785

Epoch: 6| Step: 3
Training loss: 2.4361314110349332
Validation loss: 2.587721106900997

Epoch: 6| Step: 4
Training loss: 1.780430387692111
Validation loss: 2.5802732763058165

Epoch: 6| Step: 5
Training loss: 2.4402037077433563
Validation loss: 2.593294465672949

Epoch: 6| Step: 6
Training loss: 2.1726733599678
Validation loss: 2.5986902340862637

Epoch: 6| Step: 7
Training loss: 2.345196188749847
Validation loss: 2.6532878981921693

Epoch: 6| Step: 8
Training loss: 1.7047759287527022
Validation loss: 2.6114102932331096

Epoch: 6| Step: 9
Training loss: 2.181366086127907
Validation loss: 2.6169952238687735

Epoch: 6| Step: 10
Training loss: 2.053331166778181
Validation loss: 2.6368173319664665

Epoch: 6| Step: 11
Training loss: 2.020655306285881
Validation loss: 2.633098617055498

Epoch: 6| Step: 12
Training loss: 1.603009124196834
Validation loss: 2.641859982850465

Epoch: 6| Step: 13
Training loss: 2.2128367539504104
Validation loss: 2.66568510836051

Epoch: 368| Step: 0
Training loss: 1.9192530416822562
Validation loss: 2.629126234166042

Epoch: 6| Step: 1
Training loss: 2.3528072066595223
Validation loss: 2.6195575413210697

Epoch: 6| Step: 2
Training loss: 2.542342382776121
Validation loss: 2.5812849659443353

Epoch: 6| Step: 3
Training loss: 1.8305577450656998
Validation loss: 2.6337918268578933

Epoch: 6| Step: 4
Training loss: 2.41566902702844
Validation loss: 2.5821727420832588

Epoch: 6| Step: 5
Training loss: 2.0070011859808563
Validation loss: 2.5873800705972174

Epoch: 6| Step: 6
Training loss: 2.513444796889177
Validation loss: 2.6470261590643176

Epoch: 6| Step: 7
Training loss: 1.9093289134056108
Validation loss: 2.6500689421137293

Epoch: 6| Step: 8
Training loss: 2.1891426458397425
Validation loss: 2.604745093966747

Epoch: 6| Step: 9
Training loss: 2.638526398596631
Validation loss: 2.6091552832470915

Epoch: 6| Step: 10
Training loss: 1.646235147349817
Validation loss: 2.625267957575292

Epoch: 6| Step: 11
Training loss: 1.9231868081609942
Validation loss: 2.578702181994087

Epoch: 6| Step: 12
Training loss: 2.292221649477212
Validation loss: 2.6018165277865677

Epoch: 6| Step: 13
Training loss: 2.8381236663929474
Validation loss: 2.5895635110214266

Epoch: 369| Step: 0
Training loss: 1.9372122766295183
Validation loss: 2.611814680185512

Epoch: 6| Step: 1
Training loss: 1.9090363821896008
Validation loss: 2.577438947345767

Epoch: 6| Step: 2
Training loss: 1.8002777388662825
Validation loss: 2.534286442083871

Epoch: 6| Step: 3
Training loss: 2.0075890086430817
Validation loss: 2.604629943657797

Epoch: 6| Step: 4
Training loss: 1.5226917495621266
Validation loss: 2.589275914987

Epoch: 6| Step: 5
Training loss: 2.0255009208230756
Validation loss: 2.596912950696232

Epoch: 6| Step: 6
Training loss: 2.492432680894857
Validation loss: 2.5741112592756012

Epoch: 6| Step: 7
Training loss: 2.337228271683688
Validation loss: 2.6442610978821706

Epoch: 6| Step: 8
Training loss: 2.841434584133628
Validation loss: 2.6060169775533857

Epoch: 6| Step: 9
Training loss: 2.413578910907967
Validation loss: 2.6265238612952144

Epoch: 6| Step: 10
Training loss: 2.582270393319861
Validation loss: 2.6052725673901906

Epoch: 6| Step: 11
Training loss: 2.1943196396674467
Validation loss: 2.6185812282898926

Epoch: 6| Step: 12
Training loss: 2.416616724309404
Validation loss: 2.649221224167439

Epoch: 6| Step: 13
Training loss: 2.066305868382371
Validation loss: 2.567104746316272

Epoch: 370| Step: 0
Training loss: 2.3274395849006058
Validation loss: 2.5346775646792454

Epoch: 6| Step: 1
Training loss: 1.8063703345107256
Validation loss: 2.572334089746282

Epoch: 6| Step: 2
Training loss: 2.125933834657617
Validation loss: 2.566938709296453

Epoch: 6| Step: 3
Training loss: 2.364474614762743
Validation loss: 2.56166706209004

Epoch: 6| Step: 4
Training loss: 1.630542984841258
Validation loss: 2.561789439379147

Epoch: 6| Step: 5
Training loss: 2.651927168074747
Validation loss: 2.6331008164648706

Epoch: 6| Step: 6
Training loss: 2.307305352462468
Validation loss: 2.5811842928530875

Epoch: 6| Step: 7
Training loss: 2.205828151410968
Validation loss: 2.5990039448984765

Epoch: 6| Step: 8
Training loss: 3.2751556475977153
Validation loss: 2.56645320691359

Epoch: 6| Step: 9
Training loss: 1.9179258633109317
Validation loss: 2.6378962395414947

Epoch: 6| Step: 10
Training loss: 2.3083749012239823
Validation loss: 2.5997947592932387

Epoch: 6| Step: 11
Training loss: 1.805447373042868
Validation loss: 2.5541644339078373

Epoch: 6| Step: 12
Training loss: 2.563872551260387
Validation loss: 2.562510469636856

Epoch: 6| Step: 13
Training loss: 1.6635306497908535
Validation loss: 2.5979976099456055

Epoch: 371| Step: 0
Training loss: 1.842359762250791
Validation loss: 2.586572097147021

Epoch: 6| Step: 1
Training loss: 1.5353814268101125
Validation loss: 2.604486226481752

Epoch: 6| Step: 2
Training loss: 2.1634608785514153
Validation loss: 2.593686848917007

Epoch: 6| Step: 3
Training loss: 2.317680638751467
Validation loss: 2.524366932931607

Epoch: 6| Step: 4
Training loss: 2.449885860042032
Validation loss: 2.5863334903525437

Epoch: 6| Step: 5
Training loss: 2.5986099672227203
Validation loss: 2.5548094239019

Epoch: 6| Step: 6
Training loss: 1.8328334459179492
Validation loss: 2.5795377686962584

Epoch: 6| Step: 7
Training loss: 2.1933558965911866
Validation loss: 2.5515547261229785

Epoch: 6| Step: 8
Training loss: 2.006869677331947
Validation loss: 2.5598806524464512

Epoch: 6| Step: 9
Training loss: 2.224979306242646
Validation loss: 2.5832413356991135

Epoch: 6| Step: 10
Training loss: 2.8522399933624674
Validation loss: 2.6088665118057928

Epoch: 6| Step: 11
Training loss: 2.0033407919306394
Validation loss: 2.604482785306487

Epoch: 6| Step: 12
Training loss: 1.867752436641778
Validation loss: 2.6385996031932146

Epoch: 6| Step: 13
Training loss: 2.067434246304576
Validation loss: 2.604083700191527

Epoch: 372| Step: 0
Training loss: 2.1462741016418807
Validation loss: 2.5785862534601978

Epoch: 6| Step: 1
Training loss: 2.793821916785313
Validation loss: 2.599745651374629

Epoch: 6| Step: 2
Training loss: 1.7826738522617078
Validation loss: 2.6240244071608743

Epoch: 6| Step: 3
Training loss: 2.3073733439458928
Validation loss: 2.641277562930708

Epoch: 6| Step: 4
Training loss: 2.4603440310883875
Validation loss: 2.6032468002189892

Epoch: 6| Step: 5
Training loss: 2.677041663254978
Validation loss: 2.640262012565128

Epoch: 6| Step: 6
Training loss: 2.3743423756092485
Validation loss: 2.583613267062134

Epoch: 6| Step: 7
Training loss: 2.0191167114518445
Validation loss: 2.617010424468243

Epoch: 6| Step: 8
Training loss: 2.0580932472019984
Validation loss: 2.622297301001757

Epoch: 6| Step: 9
Training loss: 1.711084507588142
Validation loss: 2.641810737892478

Epoch: 6| Step: 10
Training loss: 2.2263675001987346
Validation loss: 2.59410890660198

Epoch: 6| Step: 11
Training loss: 1.9051213284400734
Validation loss: 2.5889536175602017

Epoch: 6| Step: 12
Training loss: 2.2008369414379274
Validation loss: 2.6046596003145583

Epoch: 6| Step: 13
Training loss: 1.6775607106895762
Validation loss: 2.550584528685578

Epoch: 373| Step: 0
Training loss: 2.6951669847211703
Validation loss: 2.6534115087090626

Epoch: 6| Step: 1
Training loss: 2.0540928433392724
Validation loss: 2.5761572723371615

Epoch: 6| Step: 2
Training loss: 2.3531192936517797
Validation loss: 2.594456549871656

Epoch: 6| Step: 3
Training loss: 2.0351883488501525
Validation loss: 2.619231109513341

Epoch: 6| Step: 4
Training loss: 2.04572747365182
Validation loss: 2.590505780864512

Epoch: 6| Step: 5
Training loss: 2.506893571905153
Validation loss: 2.627284991635097

Epoch: 6| Step: 6
Training loss: 2.0868266635813884
Validation loss: 2.644245410175609

Epoch: 6| Step: 7
Training loss: 2.2762215992026693
Validation loss: 2.5735189231113518

Epoch: 6| Step: 8
Training loss: 2.134105360388634
Validation loss: 2.6374570052917354

Epoch: 6| Step: 9
Training loss: 1.7840002812227105
Validation loss: 2.594048401971418

Epoch: 6| Step: 10
Training loss: 2.393963446201819
Validation loss: 2.5888795329890817

Epoch: 6| Step: 11
Training loss: 1.7810830824427368
Validation loss: 2.5823392113017865

Epoch: 6| Step: 12
Training loss: 2.3020322860190348
Validation loss: 2.595029899383347

Epoch: 6| Step: 13
Training loss: 1.9865788514402094
Validation loss: 2.5715405628314314

Epoch: 374| Step: 0
Training loss: 2.044296387595721
Validation loss: 2.5593643782645157

Epoch: 6| Step: 1
Training loss: 1.4573493180813273
Validation loss: 2.618307817590825

Epoch: 6| Step: 2
Training loss: 1.869349803799397
Validation loss: 2.564458731217103

Epoch: 6| Step: 3
Training loss: 2.7464059405357326
Validation loss: 2.56763651760992

Epoch: 6| Step: 4
Training loss: 1.5855588413941992
Validation loss: 2.548349938479346

Epoch: 6| Step: 5
Training loss: 2.238100587167889
Validation loss: 2.6360305141926252

Epoch: 6| Step: 6
Training loss: 1.9013403531587407
Validation loss: 2.5631045476991625

Epoch: 6| Step: 7
Training loss: 2.368064793344666
Validation loss: 2.6236891532810023

Epoch: 6| Step: 8
Training loss: 2.3655091432448327
Validation loss: 2.5945970753516576

Epoch: 6| Step: 9
Training loss: 2.3800847684365882
Validation loss: 2.607287881801982

Epoch: 6| Step: 10
Training loss: 2.3368845777169938
Validation loss: 2.5780615387654278

Epoch: 6| Step: 11
Training loss: 2.2347217637525167
Validation loss: 2.572136021754931

Epoch: 6| Step: 12
Training loss: 2.783267286129965
Validation loss: 2.5727804412855053

Epoch: 6| Step: 13
Training loss: 1.7542568612488445
Validation loss: 2.5973206765863157

Epoch: 375| Step: 0
Training loss: 2.523794520959878
Validation loss: 2.6300511834173506

Epoch: 6| Step: 1
Training loss: 2.3871390664063292
Validation loss: 2.613228161421865

Epoch: 6| Step: 2
Training loss: 2.11757597227397
Validation loss: 2.5812872005635303

Epoch: 6| Step: 3
Training loss: 1.8459241300802294
Validation loss: 2.6162738418055214

Epoch: 6| Step: 4
Training loss: 2.363774322271663
Validation loss: 2.6143222062839206

Epoch: 6| Step: 5
Training loss: 1.8103099614498779
Validation loss: 2.5874956308987542

Epoch: 6| Step: 6
Training loss: 2.848471777244647
Validation loss: 2.6081123708872136

Epoch: 6| Step: 7
Training loss: 1.6654694389716185
Validation loss: 2.574611598923801

Epoch: 6| Step: 8
Training loss: 2.3291584767679296
Validation loss: 2.592498349793738

Epoch: 6| Step: 9
Training loss: 1.7827145094023584
Validation loss: 2.5953903872184485

Epoch: 6| Step: 10
Training loss: 2.0967090251062293
Validation loss: 2.5573129626519924

Epoch: 6| Step: 11
Training loss: 1.799397033789703
Validation loss: 2.5985215162125623

Epoch: 6| Step: 12
Training loss: 2.929145620459477
Validation loss: 2.597729299700749

Epoch: 6| Step: 13
Training loss: 1.9443330558782326
Validation loss: 2.5692845002553146

Epoch: 376| Step: 0
Training loss: 2.8054997110212003
Validation loss: 2.639287599372967

Epoch: 6| Step: 1
Training loss: 2.266750608554151
Validation loss: 2.620957661239384

Epoch: 6| Step: 2
Training loss: 2.1993566439340384
Validation loss: 2.569035794717726

Epoch: 6| Step: 3
Training loss: 2.238645513962096
Validation loss: 2.629087538320121

Epoch: 6| Step: 4
Training loss: 1.9856375334923169
Validation loss: 2.5666622290741374

Epoch: 6| Step: 5
Training loss: 1.6633106377810902
Validation loss: 2.6190255046438757

Epoch: 6| Step: 6
Training loss: 1.8922332354939584
Validation loss: 2.596421357722907

Epoch: 6| Step: 7
Training loss: 1.5443136414056622
Validation loss: 2.5903747486411324

Epoch: 6| Step: 8
Training loss: 2.2947575157234454
Validation loss: 2.602394571802829

Epoch: 6| Step: 9
Training loss: 2.1014122891543177
Validation loss: 2.6340012438403635

Epoch: 6| Step: 10
Training loss: 2.917700411753925
Validation loss: 2.6224647043113207

Epoch: 6| Step: 11
Training loss: 2.073332343924103
Validation loss: 2.616492962745968

Epoch: 6| Step: 12
Training loss: 2.3247625660407465
Validation loss: 2.6220201062922044

Epoch: 6| Step: 13
Training loss: 2.422799998191719
Validation loss: 2.65636049025147

Epoch: 377| Step: 0
Training loss: 2.031126517430554
Validation loss: 2.6240299891764804

Epoch: 6| Step: 1
Training loss: 2.2215844974456345
Validation loss: 2.6104190126345395

Epoch: 6| Step: 2
Training loss: 1.9429171725223457
Validation loss: 2.6495982919919676

Epoch: 6| Step: 3
Training loss: 2.562345453579635
Validation loss: 2.5616745138157895

Epoch: 6| Step: 4
Training loss: 2.0945476322180814
Validation loss: 2.63143460199536

Epoch: 6| Step: 5
Training loss: 2.8503719823247753
Validation loss: 2.6407285853116473

Epoch: 6| Step: 6
Training loss: 2.0920843074725153
Validation loss: 2.5683079581243446

Epoch: 6| Step: 7
Training loss: 2.2684850070349447
Validation loss: 2.6287990908372207

Epoch: 6| Step: 8
Training loss: 2.3026558924947347
Validation loss: 2.502969137431439

Epoch: 6| Step: 9
Training loss: 2.109539901504311
Validation loss: 2.5561975589229795

Epoch: 6| Step: 10
Training loss: 2.0569888378947594
Validation loss: 2.623154472428994

Epoch: 6| Step: 11
Training loss: 1.8786657738603394
Validation loss: 2.6040144979667095

Epoch: 6| Step: 12
Training loss: 1.3987886637916924
Validation loss: 2.650202602520984

Epoch: 6| Step: 13
Training loss: 2.1865770845361596
Validation loss: 2.5654517230276728

Epoch: 378| Step: 0
Training loss: 1.8850239789130723
Validation loss: 2.62310784249909

Epoch: 6| Step: 1
Training loss: 2.41686059458691
Validation loss: 2.6093758586813114

Epoch: 6| Step: 2
Training loss: 2.1577229651811685
Validation loss: 2.606061044262904

Epoch: 6| Step: 3
Training loss: 1.8262018374672673
Validation loss: 2.6146561594868762

Epoch: 6| Step: 4
Training loss: 2.2574258757088943
Validation loss: 2.5820194337382816

Epoch: 6| Step: 5
Training loss: 2.9797964075166314
Validation loss: 2.567257715054066

Epoch: 6| Step: 6
Training loss: 1.4554510880287819
Validation loss: 2.630940496702881

Epoch: 6| Step: 7
Training loss: 2.2514023119603244
Validation loss: 2.6614168087336916

Epoch: 6| Step: 8
Training loss: 2.2217992327040568
Validation loss: 2.617389682043016

Epoch: 6| Step: 9
Training loss: 2.6996016279133435
Validation loss: 2.5702014366361876

Epoch: 6| Step: 10
Training loss: 1.5818880746362145
Validation loss: 2.623223030954988

Epoch: 6| Step: 11
Training loss: 1.9727376486725527
Validation loss: 2.5934585929462326

Epoch: 6| Step: 12
Training loss: 2.0344506503101427
Validation loss: 2.5834142458573375

Epoch: 6| Step: 13
Training loss: 2.743953038656243
Validation loss: 2.6106868975807798

Epoch: 379| Step: 0
Training loss: 1.8006401089448492
Validation loss: 2.6271667425331136

Epoch: 6| Step: 1
Training loss: 1.7481606217356593
Validation loss: 2.5524774902886853

Epoch: 6| Step: 2
Training loss: 1.6720717840162607
Validation loss: 2.6049227965902495

Epoch: 6| Step: 3
Training loss: 2.2532698924634995
Validation loss: 2.5887537739947453

Epoch: 6| Step: 4
Training loss: 2.1001248458808663
Validation loss: 2.5920804903889656

Epoch: 6| Step: 5
Training loss: 2.564661184617244
Validation loss: 2.6364881772458917

Epoch: 6| Step: 6
Training loss: 1.9136618681484638
Validation loss: 2.6088147189739357

Epoch: 6| Step: 7
Training loss: 2.671123019579963
Validation loss: 2.6220478904383993

Epoch: 6| Step: 8
Training loss: 1.816836792157333
Validation loss: 2.5806102677903686

Epoch: 6| Step: 9
Training loss: 2.312938751663198
Validation loss: 2.5731669930216063

Epoch: 6| Step: 10
Training loss: 2.11575268764386
Validation loss: 2.5981188556873858

Epoch: 6| Step: 11
Training loss: 2.4346361208765184
Validation loss: 2.58047148866156

Epoch: 6| Step: 12
Training loss: 2.2871479451407217
Validation loss: 2.5805041018415626

Epoch: 6| Step: 13
Training loss: 2.170917217466846
Validation loss: 2.598858494145572

Epoch: 380| Step: 0
Training loss: 2.0793361719586434
Validation loss: 2.5736537351056032

Epoch: 6| Step: 1
Training loss: 1.7165381330993008
Validation loss: 2.608183871560657

Epoch: 6| Step: 2
Training loss: 2.268027038561058
Validation loss: 2.5696411063833327

Epoch: 6| Step: 3
Training loss: 1.655789581217392
Validation loss: 2.606765223538638

Epoch: 6| Step: 4
Training loss: 2.567582556150377
Validation loss: 2.6192128680008886

Epoch: 6| Step: 5
Training loss: 2.1731913577358175
Validation loss: 2.601003792625767

Epoch: 6| Step: 6
Training loss: 2.9279597770137737
Validation loss: 2.5635143846416164

Epoch: 6| Step: 7
Training loss: 2.0106060617472203
Validation loss: 2.549786607860579

Epoch: 6| Step: 8
Training loss: 2.378629621385478
Validation loss: 2.6691008354856134

Epoch: 6| Step: 9
Training loss: 1.931503738474752
Validation loss: 2.6307413274915916

Epoch: 6| Step: 10
Training loss: 2.4159824674361743
Validation loss: 2.658716482874392

Epoch: 6| Step: 11
Training loss: 1.3834433975249125
Validation loss: 2.620911869624143

Epoch: 6| Step: 12
Training loss: 1.9970263189492645
Validation loss: 2.6475291077134275

Epoch: 6| Step: 13
Training loss: 2.529677762253735
Validation loss: 2.629840628158518

Epoch: 381| Step: 0
Training loss: 1.1820914425245135
Validation loss: 2.629164109401793

Epoch: 6| Step: 1
Training loss: 2.2294554003480567
Validation loss: 2.6136471096338174

Epoch: 6| Step: 2
Training loss: 2.744001522136077
Validation loss: 2.5974151753591963

Epoch: 6| Step: 3
Training loss: 2.1468959757350707
Validation loss: 2.572968276739571

Epoch: 6| Step: 4
Training loss: 2.090689628753942
Validation loss: 2.5923825417752084

Epoch: 6| Step: 5
Training loss: 2.215624152050206
Validation loss: 2.5916927603676916

Epoch: 6| Step: 6
Training loss: 1.9824268059128947
Validation loss: 2.626545134889569

Epoch: 6| Step: 7
Training loss: 2.079030004786661
Validation loss: 2.593073771954985

Epoch: 6| Step: 8
Training loss: 1.9078604977230313
Validation loss: 2.5893438091759164

Epoch: 6| Step: 9
Training loss: 2.230451647263677
Validation loss: 2.6448779045630015

Epoch: 6| Step: 10
Training loss: 1.875938562090724
Validation loss: 2.6508166011757495

Epoch: 6| Step: 11
Training loss: 2.599395307501467
Validation loss: 2.597171669844357

Epoch: 6| Step: 12
Training loss: 2.4538231117522575
Validation loss: 2.5814500524165416

Epoch: 6| Step: 13
Training loss: 1.4807181840190318
Validation loss: 2.62512753631433

Epoch: 382| Step: 0
Training loss: 1.7622299636781955
Validation loss: 2.6493900981782197

Epoch: 6| Step: 1
Training loss: 1.816358996361157
Validation loss: 2.6186195311470217

Epoch: 6| Step: 2
Training loss: 1.4140768735376401
Validation loss: 2.629503658462781

Epoch: 6| Step: 3
Training loss: 1.593290823817634
Validation loss: 2.5939186487127306

Epoch: 6| Step: 4
Training loss: 2.751470692720602
Validation loss: 2.621010844631126

Epoch: 6| Step: 5
Training loss: 2.1834002632579135
Validation loss: 2.6444660601093393

Epoch: 6| Step: 6
Training loss: 1.464182467924487
Validation loss: 2.5688494800450337

Epoch: 6| Step: 7
Training loss: 2.153295842937782
Validation loss: 2.588553994230856

Epoch: 6| Step: 8
Training loss: 2.249050363834145
Validation loss: 2.6182420536014277

Epoch: 6| Step: 9
Training loss: 2.650733335260385
Validation loss: 2.5412265669569516

Epoch: 6| Step: 10
Training loss: 2.489175441212658
Validation loss: 2.578687282486315

Epoch: 6| Step: 11
Training loss: 2.3985074806565905
Validation loss: 2.6723918797434774

Epoch: 6| Step: 12
Training loss: 2.28015308920234
Validation loss: 2.632806079236287

Epoch: 6| Step: 13
Training loss: 1.921272183292068
Validation loss: 2.567282032628697

Epoch: 383| Step: 0
Training loss: 2.4975188340707435
Validation loss: 2.613821858029023

Epoch: 6| Step: 1
Training loss: 2.2107495339227152
Validation loss: 2.6014238748222667

Epoch: 6| Step: 2
Training loss: 1.9510762570219344
Validation loss: 2.641762806946805

Epoch: 6| Step: 3
Training loss: 1.8744450701634818
Validation loss: 2.6091408484800236

Epoch: 6| Step: 4
Training loss: 2.5700284574840473
Validation loss: 2.590022006829624

Epoch: 6| Step: 5
Training loss: 1.4409786923836474
Validation loss: 2.642583126978364

Epoch: 6| Step: 6
Training loss: 1.6386280804170898
Validation loss: 2.6418455948043698

Epoch: 6| Step: 7
Training loss: 2.6797287829363734
Validation loss: 2.6028828166306277

Epoch: 6| Step: 8
Training loss: 2.8951491135323932
Validation loss: 2.6307767364534156

Epoch: 6| Step: 9
Training loss: 2.2717977686456896
Validation loss: 2.6086690246238637

Epoch: 6| Step: 10
Training loss: 1.9189831446055996
Validation loss: 2.6010793857969783

Epoch: 6| Step: 11
Training loss: 2.2052046247068806
Validation loss: 2.6301370798501074

Epoch: 6| Step: 12
Training loss: 1.9606678081942783
Validation loss: 2.5893121721746706

Epoch: 6| Step: 13
Training loss: 1.6693971757690553
Validation loss: 2.6352416267390057

Epoch: 384| Step: 0
Training loss: 2.3510947538530766
Validation loss: 2.633627521623743

Epoch: 6| Step: 1
Training loss: 2.1334829988233586
Validation loss: 2.5517534964910786

Epoch: 6| Step: 2
Training loss: 2.1007177080139607
Validation loss: 2.616382682916404

Epoch: 6| Step: 3
Training loss: 2.3281167049388194
Validation loss: 2.6151778538749744

Epoch: 6| Step: 4
Training loss: 1.7247075952574669
Validation loss: 2.5696581394590408

Epoch: 6| Step: 5
Training loss: 2.2792457241408624
Validation loss: 2.6454873159537873

Epoch: 6| Step: 6
Training loss: 2.6915163590672653
Validation loss: 2.6051496761225885

Epoch: 6| Step: 7
Training loss: 2.32453867529624
Validation loss: 2.5980395682918305

Epoch: 6| Step: 8
Training loss: 2.8107781119585957
Validation loss: 2.623914515680116

Epoch: 6| Step: 9
Training loss: 1.8899425189042027
Validation loss: 2.5694302272948364

Epoch: 6| Step: 10
Training loss: 1.6082396715527216
Validation loss: 2.622317549628722

Epoch: 6| Step: 11
Training loss: 2.1320314199769768
Validation loss: 2.592574692304779

Epoch: 6| Step: 12
Training loss: 1.8002008590952172
Validation loss: 2.5933672171190496

Epoch: 6| Step: 13
Training loss: 1.9045545198303848
Validation loss: 2.5939997525486813

Epoch: 385| Step: 0
Training loss: 3.0059609002510146
Validation loss: 2.6109494666383535

Epoch: 6| Step: 1
Training loss: 2.7229331271183104
Validation loss: 2.5817435457406934

Epoch: 6| Step: 2
Training loss: 2.1521106739160056
Validation loss: 2.555996156274843

Epoch: 6| Step: 3
Training loss: 1.7318286245545949
Validation loss: 2.5724958929561286

Epoch: 6| Step: 4
Training loss: 2.2987746084201865
Validation loss: 2.562015358560122

Epoch: 6| Step: 5
Training loss: 1.9751168494123068
Validation loss: 2.6267907372371213

Epoch: 6| Step: 6
Training loss: 1.8432324863162135
Validation loss: 2.594904313977372

Epoch: 6| Step: 7
Training loss: 2.4552071840145726
Validation loss: 2.5954741267671158

Epoch: 6| Step: 8
Training loss: 2.1434216573185063
Validation loss: 2.5366484514409584

Epoch: 6| Step: 9
Training loss: 1.8542168499731209
Validation loss: 2.649353798097792

Epoch: 6| Step: 10
Training loss: 1.7496112664211003
Validation loss: 2.603482118935971

Epoch: 6| Step: 11
Training loss: 2.205853875668282
Validation loss: 2.6267211065037834

Epoch: 6| Step: 12
Training loss: 1.8238592998547076
Validation loss: 2.609946996981789

Epoch: 6| Step: 13
Training loss: 1.990642891268972
Validation loss: 2.6988005978699254

Epoch: 386| Step: 0
Training loss: 2.0911484683072854
Validation loss: 2.575525192462269

Epoch: 6| Step: 1
Training loss: 2.2843710047403825
Validation loss: 2.635872476844148

Epoch: 6| Step: 2
Training loss: 1.968156876607218
Validation loss: 2.5856126933788395

Epoch: 6| Step: 3
Training loss: 1.7730789158143307
Validation loss: 2.620216035001289

Epoch: 6| Step: 4
Training loss: 2.6736217834347724
Validation loss: 2.591743909171882

Epoch: 6| Step: 5
Training loss: 2.076885800421083
Validation loss: 2.6372810059013885

Epoch: 6| Step: 6
Training loss: 2.3752406148995124
Validation loss: 2.6309866915934212

Epoch: 6| Step: 7
Training loss: 2.3530610338005014
Validation loss: 2.594803350245149

Epoch: 6| Step: 8
Training loss: 1.8792530144295183
Validation loss: 2.637295058211404

Epoch: 6| Step: 9
Training loss: 1.9635502404414487
Validation loss: 2.610285984527589

Epoch: 6| Step: 10
Training loss: 1.979857100137
Validation loss: 2.60625181400935

Epoch: 6| Step: 11
Training loss: 1.7466297393758552
Validation loss: 2.585825638457837

Epoch: 6| Step: 12
Training loss: 2.4467979526203765
Validation loss: 2.5818608685916873

Epoch: 6| Step: 13
Training loss: 1.629987837857234
Validation loss: 2.6280174560050167

Epoch: 387| Step: 0
Training loss: 1.9803558859181718
Validation loss: 2.6046719073687203

Epoch: 6| Step: 1
Training loss: 1.7627072151606444
Validation loss: 2.5770618423068647

Epoch: 6| Step: 2
Training loss: 2.3978555078824346
Validation loss: 2.6177037256005393

Epoch: 6| Step: 3
Training loss: 2.3792142120616675
Validation loss: 2.600647807133808

Epoch: 6| Step: 4
Training loss: 2.211478770289335
Validation loss: 2.565865344457098

Epoch: 6| Step: 5
Training loss: 3.1406130055060912
Validation loss: 2.6139165188708313

Epoch: 6| Step: 6
Training loss: 2.04187215692178
Validation loss: 2.55994753767166

Epoch: 6| Step: 7
Training loss: 1.882529716307815
Validation loss: 2.5835613361161287

Epoch: 6| Step: 8
Training loss: 2.188601843036725
Validation loss: 2.6094949630976254

Epoch: 6| Step: 9
Training loss: 1.7472162585551756
Validation loss: 2.6015725503141236

Epoch: 6| Step: 10
Training loss: 2.16806354487292
Validation loss: 2.6323746437953175

Epoch: 6| Step: 11
Training loss: 2.390373665556565
Validation loss: 2.6399203842932124

Epoch: 6| Step: 12
Training loss: 1.3156764330743487
Validation loss: 2.6205728273436475

Epoch: 6| Step: 13
Training loss: 2.4554923716375927
Validation loss: 2.584442885492884

Epoch: 388| Step: 0
Training loss: 2.424451872237999
Validation loss: 2.638311877922483

Epoch: 6| Step: 1
Training loss: 1.8718274933608956
Validation loss: 2.544751624238435

Epoch: 6| Step: 2
Training loss: 1.7741051983999212
Validation loss: 2.5643921775914653

Epoch: 6| Step: 3
Training loss: 1.7994575186355195
Validation loss: 2.625484552698329

Epoch: 6| Step: 4
Training loss: 2.3515983908312776
Validation loss: 2.632812786762588

Epoch: 6| Step: 5
Training loss: 2.617073443760068
Validation loss: 2.6050479078773714

Epoch: 6| Step: 6
Training loss: 1.9705526182926354
Validation loss: 2.656824650816754

Epoch: 6| Step: 7
Training loss: 1.8518756328044819
Validation loss: 2.6012371677346033

Epoch: 6| Step: 8
Training loss: 2.054979658931106
Validation loss: 2.6444066999065607

Epoch: 6| Step: 9
Training loss: 2.2996095740614826
Validation loss: 2.563804422518287

Epoch: 6| Step: 10
Training loss: 2.706241729230334
Validation loss: 2.5972948754214205

Epoch: 6| Step: 11
Training loss: 2.4346408214067745
Validation loss: 2.6140398928983872

Epoch: 6| Step: 12
Training loss: 1.938470289859184
Validation loss: 2.6304375398262443

Epoch: 6| Step: 13
Training loss: 1.5984586831755954
Validation loss: 2.5893965122310374

Epoch: 389| Step: 0
Training loss: 2.0231921662172554
Validation loss: 2.6259535109049335

Epoch: 6| Step: 1
Training loss: 2.310142655859933
Validation loss: 2.6494453785469534

Epoch: 6| Step: 2
Training loss: 2.0439644423973395
Validation loss: 2.7004977794752563

Epoch: 6| Step: 3
Training loss: 2.6947755140467557
Validation loss: 2.6494527285332614

Epoch: 6| Step: 4
Training loss: 2.358971365450445
Validation loss: 2.6243500664262203

Epoch: 6| Step: 5
Training loss: 1.85414889323542
Validation loss: 2.581772790067794

Epoch: 6| Step: 6
Training loss: 1.7621914045571685
Validation loss: 2.630625120458972

Epoch: 6| Step: 7
Training loss: 2.0682049082134966
Validation loss: 2.6834446061250445

Epoch: 6| Step: 8
Training loss: 2.2654106301802637
Validation loss: 2.6232622921718023

Epoch: 6| Step: 9
Training loss: 2.8996847507526673
Validation loss: 2.647497071805045

Epoch: 6| Step: 10
Training loss: 1.5463498698048839
Validation loss: 2.668055080308942

Epoch: 6| Step: 11
Training loss: 2.297861523166894
Validation loss: 2.6735812404245793

Epoch: 6| Step: 12
Training loss: 1.613854553476053
Validation loss: 2.596834995258837

Epoch: 6| Step: 13
Training loss: 1.9374848026787106
Validation loss: 2.6267748612605355

Epoch: 390| Step: 0
Training loss: 1.7395884195889184
Validation loss: 2.5777697395775876

Epoch: 6| Step: 1
Training loss: 2.563808293268069
Validation loss: 2.6460699108558443

Epoch: 6| Step: 2
Training loss: 2.197267252603564
Validation loss: 2.642192367889113

Epoch: 6| Step: 3
Training loss: 2.3964794006544747
Validation loss: 2.612366401281505

Epoch: 6| Step: 4
Training loss: 2.2999910769082175
Validation loss: 2.594440874744594

Epoch: 6| Step: 5
Training loss: 2.052250101764912
Validation loss: 2.5958719588984596

Epoch: 6| Step: 6
Training loss: 2.27966922703009
Validation loss: 2.635360169176995

Epoch: 6| Step: 7
Training loss: 2.1474843633257867
Validation loss: 2.565384347739691

Epoch: 6| Step: 8
Training loss: 2.719143893767788
Validation loss: 2.673630426624127

Epoch: 6| Step: 9
Training loss: 1.9239596094424303
Validation loss: 2.6684287575843952

Epoch: 6| Step: 10
Training loss: 1.7238052930255607
Validation loss: 2.568274092555769

Epoch: 6| Step: 11
Training loss: 1.9041443749033513
Validation loss: 2.6115531493402453

Epoch: 6| Step: 12
Training loss: 2.017207980476734
Validation loss: 2.601235092172483

Epoch: 6| Step: 13
Training loss: 1.3889007594343052
Validation loss: 2.6091987992976735

Epoch: 391| Step: 0
Training loss: 1.8970797357567684
Validation loss: 2.58689508669727

Epoch: 6| Step: 1
Training loss: 2.7468711219386996
Validation loss: 2.631549268152005

Epoch: 6| Step: 2
Training loss: 2.6700840351724535
Validation loss: 2.592983776611145

Epoch: 6| Step: 3
Training loss: 2.485588497117323
Validation loss: 2.599234476539403

Epoch: 6| Step: 4
Training loss: 1.7553746930378606
Validation loss: 2.62840846194752

Epoch: 6| Step: 5
Training loss: 1.9073459414043512
Validation loss: 2.549738044964574

Epoch: 6| Step: 6
Training loss: 2.111501455470457
Validation loss: 2.605917029717929

Epoch: 6| Step: 7
Training loss: 2.3477714116799073
Validation loss: 2.5845198488309817

Epoch: 6| Step: 8
Training loss: 1.9327680578033393
Validation loss: 2.6021280026059666

Epoch: 6| Step: 9
Training loss: 2.2649869875502535
Validation loss: 2.5701984782056178

Epoch: 6| Step: 10
Training loss: 1.7849876274086134
Validation loss: 2.6308789545488347

Epoch: 6| Step: 11
Training loss: 1.8450374957153861
Validation loss: 2.585776830364312

Epoch: 6| Step: 12
Training loss: 1.870614390599645
Validation loss: 2.63748905428639

Epoch: 6| Step: 13
Training loss: 1.0948950631883523
Validation loss: 2.568717427949541

Epoch: 392| Step: 0
Training loss: 2.175794399365562
Validation loss: 2.652424956918082

Epoch: 6| Step: 1
Training loss: 2.1759475836190805
Validation loss: 2.658846254833039

Epoch: 6| Step: 2
Training loss: 2.10702757023542
Validation loss: 2.5893469417665114

Epoch: 6| Step: 3
Training loss: 1.3896929156757818
Validation loss: 2.621066964151083

Epoch: 6| Step: 4
Training loss: 2.1781720324655574
Validation loss: 2.6268593833596765

Epoch: 6| Step: 5
Training loss: 1.8920464334737925
Validation loss: 2.5501359499184826

Epoch: 6| Step: 6
Training loss: 1.8657999030192625
Validation loss: 2.6169992040304053

Epoch: 6| Step: 7
Training loss: 2.6328528879390145
Validation loss: 2.6342145221708444

Epoch: 6| Step: 8
Training loss: 2.1056032721694056
Validation loss: 2.6573758426680545

Epoch: 6| Step: 9
Training loss: 2.0476041470637116
Validation loss: 2.6442525622921713

Epoch: 6| Step: 10
Training loss: 2.251106519940234
Validation loss: 2.692873924550717

Epoch: 6| Step: 11
Training loss: 1.5765025041429042
Validation loss: 2.597878725435803

Epoch: 6| Step: 12
Training loss: 3.1390606224620288
Validation loss: 2.6046881670792

Epoch: 6| Step: 13
Training loss: 1.8977661201517046
Validation loss: 2.6064139597990623

Epoch: 393| Step: 0
Training loss: 1.6165939937394553
Validation loss: 2.6277163993083676

Epoch: 6| Step: 1
Training loss: 2.980865492106487
Validation loss: 2.5955199444261337

Epoch: 6| Step: 2
Training loss: 2.695710702865291
Validation loss: 2.622943744723114

Epoch: 6| Step: 3
Training loss: 2.0834365310540814
Validation loss: 2.613200346288517

Epoch: 6| Step: 4
Training loss: 1.8730817519074316
Validation loss: 2.596632646314141

Epoch: 6| Step: 5
Training loss: 1.6064521395181681
Validation loss: 2.5948735213099927

Epoch: 6| Step: 6
Training loss: 2.507539443127045
Validation loss: 2.661063250900419

Epoch: 6| Step: 7
Training loss: 1.6129890528270163
Validation loss: 2.64622742057413

Epoch: 6| Step: 8
Training loss: 1.954665713108779
Validation loss: 2.5893416171523045

Epoch: 6| Step: 9
Training loss: 2.4717443149517093
Validation loss: 2.560721391163345

Epoch: 6| Step: 10
Training loss: 1.7556233655868316
Validation loss: 2.6222749268301238

Epoch: 6| Step: 11
Training loss: 2.555383243372276
Validation loss: 2.6214527200784628

Epoch: 6| Step: 12
Training loss: 1.9931364903278797
Validation loss: 2.635389671655975

Epoch: 6| Step: 13
Training loss: 1.072056650945844
Validation loss: 2.641684133176187

Epoch: 394| Step: 0
Training loss: 2.105560017661827
Validation loss: 2.592350382126991

Epoch: 6| Step: 1
Training loss: 2.54610351860277
Validation loss: 2.6395227158607266

Epoch: 6| Step: 2
Training loss: 2.0694461953357
Validation loss: 2.6660356454369105

Epoch: 6| Step: 3
Training loss: 2.0450280862385823
Validation loss: 2.56499925074758

Epoch: 6| Step: 4
Training loss: 2.019289456028175
Validation loss: 2.60798252504794

Epoch: 6| Step: 5
Training loss: 2.432898849297497
Validation loss: 2.644746415837745

Epoch: 6| Step: 6
Training loss: 1.8314827624610324
Validation loss: 2.6283266412599837

Epoch: 6| Step: 7
Training loss: 2.003277715375338
Validation loss: 2.592056909871972

Epoch: 6| Step: 8
Training loss: 2.4552309751916472
Validation loss: 2.6080729002839407

Epoch: 6| Step: 9
Training loss: 1.967371624608316
Validation loss: 2.6231318700344213

Epoch: 6| Step: 10
Training loss: 1.8435223972335033
Validation loss: 2.587652331986484

Epoch: 6| Step: 11
Training loss: 2.6898635407051312
Validation loss: 2.599905139266966

Epoch: 6| Step: 12
Training loss: 1.4120512511134924
Validation loss: 2.6112496922645363

Epoch: 6| Step: 13
Training loss: 1.7211569838091583
Validation loss: 2.674749106010466

Epoch: 395| Step: 0
Training loss: 2.118304193908058
Validation loss: 2.60399181115287

Epoch: 6| Step: 1
Training loss: 2.394430684253937
Validation loss: 2.578121034402243

Epoch: 6| Step: 2
Training loss: 1.8078221432124504
Validation loss: 2.5799001420087593

Epoch: 6| Step: 3
Training loss: 2.0371936403952366
Validation loss: 2.6269858759625486

Epoch: 6| Step: 4
Training loss: 2.392919698194412
Validation loss: 2.5721138830226185

Epoch: 6| Step: 5
Training loss: 1.6052174615156922
Validation loss: 2.6223984682759687

Epoch: 6| Step: 6
Training loss: 2.3105052902336123
Validation loss: 2.548077496034541

Epoch: 6| Step: 7
Training loss: 1.8483597623806205
Validation loss: 2.5819139130468858

Epoch: 6| Step: 8
Training loss: 2.5565240540532055
Validation loss: 2.606152038472266

Epoch: 6| Step: 9
Training loss: 1.744178831359075
Validation loss: 2.5800739149901832

Epoch: 6| Step: 10
Training loss: 2.073223327752184
Validation loss: 2.609818143195363

Epoch: 6| Step: 11
Training loss: 2.434935174036018
Validation loss: 2.66023154808165

Epoch: 6| Step: 12
Training loss: 2.1757878246927147
Validation loss: 2.5736604777611882

Epoch: 6| Step: 13
Training loss: 1.3536123265983486
Validation loss: 2.628088615106796

Epoch: 396| Step: 0
Training loss: 3.006438657428238
Validation loss: 2.5857179173816514

Epoch: 6| Step: 1
Training loss: 2.03535188111743
Validation loss: 2.626835118607664

Epoch: 6| Step: 2
Training loss: 2.1196353739139115
Validation loss: 2.6444424716870523

Epoch: 6| Step: 3
Training loss: 2.3830082046937426
Validation loss: 2.611366156280113

Epoch: 6| Step: 4
Training loss: 2.607607488419158
Validation loss: 2.604799946888612

Epoch: 6| Step: 5
Training loss: 1.6746710098345943
Validation loss: 2.6284996763829804

Epoch: 6| Step: 6
Training loss: 2.305470996158841
Validation loss: 2.6096650069835317

Epoch: 6| Step: 7
Training loss: 1.7374107667252334
Validation loss: 2.568141061540961

Epoch: 6| Step: 8
Training loss: 1.8799433076711045
Validation loss: 2.5865317626173114

Epoch: 6| Step: 9
Training loss: 1.805065957552383
Validation loss: 2.5865491820177233

Epoch: 6| Step: 10
Training loss: 2.0316192291371205
Validation loss: 2.6477582774856536

Epoch: 6| Step: 11
Training loss: 1.920779900900636
Validation loss: 2.6180215005393404

Epoch: 6| Step: 12
Training loss: 1.6066110079108622
Validation loss: 2.6673206554784628

Epoch: 6| Step: 13
Training loss: 1.451252458884089
Validation loss: 2.6340068285584444

Epoch: 397| Step: 0
Training loss: 1.6080817795070372
Validation loss: 2.6843431957789

Epoch: 6| Step: 1
Training loss: 2.253686428093828
Validation loss: 2.6051460705002802

Epoch: 6| Step: 2
Training loss: 1.6712906431222074
Validation loss: 2.6588924865156436

Epoch: 6| Step: 3
Training loss: 2.1254648934253404
Validation loss: 2.62491101818774

Epoch: 6| Step: 4
Training loss: 1.3881048447864552
Validation loss: 2.604062827388327

Epoch: 6| Step: 5
Training loss: 2.6651288804029187
Validation loss: 2.5903394524730463

Epoch: 6| Step: 6
Training loss: 1.5565023133444207
Validation loss: 2.587917673004826

Epoch: 6| Step: 7
Training loss: 2.963143606330662
Validation loss: 2.6416300053871913

Epoch: 6| Step: 8
Training loss: 2.1889486693057627
Validation loss: 2.627976835718868

Epoch: 6| Step: 9
Training loss: 2.156009937136084
Validation loss: 2.6457322165697863

Epoch: 6| Step: 10
Training loss: 2.2531066216553897
Validation loss: 2.623365677687859

Epoch: 6| Step: 11
Training loss: 2.0527325166499675
Validation loss: 2.5958509232820464

Epoch: 6| Step: 12
Training loss: 2.2333706819438435
Validation loss: 2.617999754727084

Epoch: 6| Step: 13
Training loss: 1.8999994704597136
Validation loss: 2.6517857522458455

Epoch: 398| Step: 0
Training loss: 2.575878852566274
Validation loss: 2.617258169940082

Epoch: 6| Step: 1
Training loss: 2.4628614867118026
Validation loss: 2.634487138142155

Epoch: 6| Step: 2
Training loss: 2.144717793785007
Validation loss: 2.6271639770590887

Epoch: 6| Step: 3
Training loss: 2.305119981435825
Validation loss: 2.6393108327070234

Epoch: 6| Step: 4
Training loss: 2.010784280270623
Validation loss: 2.6192885933777545

Epoch: 6| Step: 5
Training loss: 2.5722342962096527
Validation loss: 2.5941712627552866

Epoch: 6| Step: 6
Training loss: 2.1461086898966926
Validation loss: 2.6603156885210493

Epoch: 6| Step: 7
Training loss: 1.922658124951468
Validation loss: 2.641031130025349

Epoch: 6| Step: 8
Training loss: 1.8445794131152098
Validation loss: 2.641131361310856

Epoch: 6| Step: 9
Training loss: 1.8391932412655938
Validation loss: 2.6853166789477227

Epoch: 6| Step: 10
Training loss: 1.942296336432074
Validation loss: 2.621108190340442

Epoch: 6| Step: 11
Training loss: 1.6666025467300505
Validation loss: 2.6159225196056695

Epoch: 6| Step: 12
Training loss: 1.8802995175329822
Validation loss: 2.634951163746503

Epoch: 6| Step: 13
Training loss: 1.612292783567314
Validation loss: 2.542234552675833

Epoch: 399| Step: 0
Training loss: 2.2939172501875493
Validation loss: 2.6237714121990017

Epoch: 6| Step: 1
Training loss: 2.1581905312839575
Validation loss: 2.6186366949998794

Epoch: 6| Step: 2
Training loss: 2.148104777147976
Validation loss: 2.572399379513504

Epoch: 6| Step: 3
Training loss: 2.2088006682701993
Validation loss: 2.638831834404792

Epoch: 6| Step: 4
Training loss: 2.0171107058160747
Validation loss: 2.591489962422432

Epoch: 6| Step: 5
Training loss: 1.836203308342813
Validation loss: 2.6396305303553596

Epoch: 6| Step: 6
Training loss: 2.213039948693688
Validation loss: 2.5801173253563916

Epoch: 6| Step: 7
Training loss: 1.7853082304185173
Validation loss: 2.6745268806506597

Epoch: 6| Step: 8
Training loss: 1.577167938395306
Validation loss: 2.6240086106811362

Epoch: 6| Step: 9
Training loss: 1.4074484910229619
Validation loss: 2.622687082092525

Epoch: 6| Step: 10
Training loss: 2.8363124294816036
Validation loss: 2.6639767476222818

Epoch: 6| Step: 11
Training loss: 2.4474133129568605
Validation loss: 2.6198190725858304

Epoch: 6| Step: 12
Training loss: 1.895275229443739
Validation loss: 2.6061314202890284

Epoch: 6| Step: 13
Training loss: 2.3381827800497423
Validation loss: 2.5940064522013735

Epoch: 400| Step: 0
Training loss: 1.9234547518987621
Validation loss: 2.6125145884826466

Epoch: 6| Step: 1
Training loss: 2.270747845175062
Validation loss: 2.5549190361501006

Epoch: 6| Step: 2
Training loss: 2.0502081369945784
Validation loss: 2.6779722887115804

Epoch: 6| Step: 3
Training loss: 2.1549344679920854
Validation loss: 2.6520501170167736

Epoch: 6| Step: 4
Training loss: 2.27018499889309
Validation loss: 2.6191642474903296

Epoch: 6| Step: 5
Training loss: 1.6262573366344195
Validation loss: 2.63345496848351

Epoch: 6| Step: 6
Training loss: 1.67384229763089
Validation loss: 2.6507939242003915

Epoch: 6| Step: 7
Training loss: 1.7948454964111948
Validation loss: 2.639396571546177

Epoch: 6| Step: 8
Training loss: 1.8891327698971279
Validation loss: 2.585362209946927

Epoch: 6| Step: 9
Training loss: 1.5652283308780235
Validation loss: 2.6228462872929823

Epoch: 6| Step: 10
Training loss: 2.0894949648710415
Validation loss: 2.6079716874765757

Epoch: 6| Step: 11
Training loss: 1.770728441011566
Validation loss: 2.6342232141271973

Epoch: 6| Step: 12
Training loss: 2.422040478375194
Validation loss: 2.6666934937491544

Epoch: 6| Step: 13
Training loss: 3.8059537374518277
Validation loss: 2.678418749839545

Epoch: 401| Step: 0
Training loss: 2.351525189176597
Validation loss: 2.5566653714506473

Epoch: 6| Step: 1
Training loss: 2.0692663464584373
Validation loss: 2.535753579284131

Epoch: 6| Step: 2
Training loss: 2.632855242373747
Validation loss: 2.574194398364258

Epoch: 6| Step: 3
Training loss: 1.6008521761059145
Validation loss: 2.5953830797088675

Epoch: 6| Step: 4
Training loss: 2.6630193284436654
Validation loss: 2.6356938188948655

Epoch: 6| Step: 5
Training loss: 2.4921572692376897
Validation loss: 2.6491206351028094

Epoch: 6| Step: 6
Training loss: 2.140083968574039
Validation loss: 2.562127881427077

Epoch: 6| Step: 7
Training loss: 1.969281805963491
Validation loss: 2.53029535669674

Epoch: 6| Step: 8
Training loss: 1.8853149246106649
Validation loss: 2.6793515196170428

Epoch: 6| Step: 9
Training loss: 1.7039466765661448
Validation loss: 2.611460701454751

Epoch: 6| Step: 10
Training loss: 1.377491773937331
Validation loss: 2.6480010976223713

Epoch: 6| Step: 11
Training loss: 2.134190599733588
Validation loss: 2.620632501433463

Epoch: 6| Step: 12
Training loss: 1.8834097140642272
Validation loss: 2.6024940412179944

Epoch: 6| Step: 13
Training loss: 1.9622504105972713
Validation loss: 2.6300057099931236

Epoch: 402| Step: 0
Training loss: 1.7703203542860022
Validation loss: 2.6136149634764707

Epoch: 6| Step: 1
Training loss: 2.5192149828753894
Validation loss: 2.595548674995607

Epoch: 6| Step: 2
Training loss: 1.8014764664314784
Validation loss: 2.6539672414109963

Epoch: 6| Step: 3
Training loss: 2.257452279364864
Validation loss: 2.578152108694716

Epoch: 6| Step: 4
Training loss: 1.406562431384604
Validation loss: 2.6075557374346046

Epoch: 6| Step: 5
Training loss: 2.16859682625061
Validation loss: 2.61732297083588

Epoch: 6| Step: 6
Training loss: 2.0631056387662228
Validation loss: 2.597656277633347

Epoch: 6| Step: 7
Training loss: 2.4448036907622557
Validation loss: 2.6503173204739183

Epoch: 6| Step: 8
Training loss: 2.0326509779519317
Validation loss: 2.633698304293588

Epoch: 6| Step: 9
Training loss: 2.866701838551115
Validation loss: 2.6134639223472598

Epoch: 6| Step: 10
Training loss: 2.221984869149209
Validation loss: 2.682435156933371

Epoch: 6| Step: 11
Training loss: 1.806966886186365
Validation loss: 2.6261302684712486

Epoch: 6| Step: 12
Training loss: 1.5718032062129403
Validation loss: 2.7248815828566806

Epoch: 6| Step: 13
Training loss: 2.1313046445581256
Validation loss: 2.6357231625012565

Epoch: 403| Step: 0
Training loss: 1.804849328385904
Validation loss: 2.605323720190155

Epoch: 6| Step: 1
Training loss: 1.9739903537162844
Validation loss: 2.612689211474468

Epoch: 6| Step: 2
Training loss: 2.331318655358174
Validation loss: 2.6201133833029684

Epoch: 6| Step: 3
Training loss: 1.5720607458224725
Validation loss: 2.660982382749427

Epoch: 6| Step: 4
Training loss: 2.4315552233057747
Validation loss: 2.6568456977112263

Epoch: 6| Step: 5
Training loss: 1.6979278220841922
Validation loss: 2.596851381041183

Epoch: 6| Step: 6
Training loss: 1.9636354769719173
Validation loss: 2.6168162886312785

Epoch: 6| Step: 7
Training loss: 2.1864782944619687
Validation loss: 2.625792303215012

Epoch: 6| Step: 8
Training loss: 1.8180066349424648
Validation loss: 2.599581726764938

Epoch: 6| Step: 9
Training loss: 2.099118083872726
Validation loss: 2.6166947174084068

Epoch: 6| Step: 10
Training loss: 3.010719064134362
Validation loss: 2.5883592057772478

Epoch: 6| Step: 11
Training loss: 1.6243143102177904
Validation loss: 2.62280493985242

Epoch: 6| Step: 12
Training loss: 2.4853019664439975
Validation loss: 2.6511573765446133

Epoch: 6| Step: 13
Training loss: 1.9133544234975397
Validation loss: 2.603561605406212

Epoch: 404| Step: 0
Training loss: 2.4966505501213794
Validation loss: 2.660333430411817

Epoch: 6| Step: 1
Training loss: 2.037182522244084
Validation loss: 2.634861575186996

Epoch: 6| Step: 2
Training loss: 1.7426970553522487
Validation loss: 2.6347595748467634

Epoch: 6| Step: 3
Training loss: 2.0614660734854087
Validation loss: 2.586829663309529

Epoch: 6| Step: 4
Training loss: 1.8406178654012695
Validation loss: 2.669360657547967

Epoch: 6| Step: 5
Training loss: 2.6966256743601638
Validation loss: 2.6010029099893845

Epoch: 6| Step: 6
Training loss: 2.197204426231072
Validation loss: 2.6157963044805888

Epoch: 6| Step: 7
Training loss: 2.229357440901795
Validation loss: 2.66397542729701

Epoch: 6| Step: 8
Training loss: 1.8623156974799084
Validation loss: 2.5866800670950085

Epoch: 6| Step: 9
Training loss: 1.908656992666707
Validation loss: 2.5828172946989625

Epoch: 6| Step: 10
Training loss: 2.3002140401677225
Validation loss: 2.5857973748867886

Epoch: 6| Step: 11
Training loss: 2.141924275837984
Validation loss: 2.640379767435958

Epoch: 6| Step: 12
Training loss: 2.0067941183294855
Validation loss: 2.554875798690064

Epoch: 6| Step: 13
Training loss: 1.2756161453859318
Validation loss: 2.6009200832608914

Epoch: 405| Step: 0
Training loss: 2.0112024329839175
Validation loss: 2.6236830052791484

Epoch: 6| Step: 1
Training loss: 2.3402441634252185
Validation loss: 2.584935223221674

Epoch: 6| Step: 2
Training loss: 1.700262761845965
Validation loss: 2.5591640582962434

Epoch: 6| Step: 3
Training loss: 1.8127831862640418
Validation loss: 2.6032838357821158

Epoch: 6| Step: 4
Training loss: 1.7939179345182246
Validation loss: 2.641848790321747

Epoch: 6| Step: 5
Training loss: 1.772073027563396
Validation loss: 2.5591196153055664

Epoch: 6| Step: 6
Training loss: 2.1281962199344338
Validation loss: 2.629408435097517

Epoch: 6| Step: 7
Training loss: 2.571588726959939
Validation loss: 2.6210897398669606

Epoch: 6| Step: 8
Training loss: 2.6536893282624168
Validation loss: 2.678148193772028

Epoch: 6| Step: 9
Training loss: 1.8455315727152088
Validation loss: 2.630003782879667

Epoch: 6| Step: 10
Training loss: 1.567224379283369
Validation loss: 2.6686522419787466

Epoch: 6| Step: 11
Training loss: 2.1562323085777857
Validation loss: 2.6491068061665897

Epoch: 6| Step: 12
Training loss: 1.6867895396839327
Validation loss: 2.5669174026185386

Epoch: 6| Step: 13
Training loss: 2.0650046197502427
Validation loss: 2.57880488057656

Epoch: 406| Step: 0
Training loss: 2.5575743063892857
Validation loss: 2.601483824574763

Epoch: 6| Step: 1
Training loss: 2.2029147216872946
Validation loss: 2.572315389093076

Epoch: 6| Step: 2
Training loss: 2.1198605487951068
Validation loss: 2.6129303152451726

Epoch: 6| Step: 3
Training loss: 2.907076318233104
Validation loss: 2.638555360437115

Epoch: 6| Step: 4
Training loss: 2.4546529300035274
Validation loss: 2.549126662543603

Epoch: 6| Step: 5
Training loss: 1.7693613404474702
Validation loss: 2.626735642785492

Epoch: 6| Step: 6
Training loss: 1.881589246812248
Validation loss: 2.593497935052434

Epoch: 6| Step: 7
Training loss: 2.2878648143925697
Validation loss: 2.5333012329355116

Epoch: 6| Step: 8
Training loss: 2.1847940329538305
Validation loss: 2.6337476892546494

Epoch: 6| Step: 9
Training loss: 1.780376621756886
Validation loss: 2.6056673263564942

Epoch: 6| Step: 10
Training loss: 1.6093316674185671
Validation loss: 2.6407711325744074

Epoch: 6| Step: 11
Training loss: 1.883351672204227
Validation loss: 2.6603443495515364

Epoch: 6| Step: 12
Training loss: 1.726721432650716
Validation loss: 2.6227147672902675

Epoch: 6| Step: 13
Training loss: 2.1362864389989196
Validation loss: 2.6573354589140132

Epoch: 407| Step: 0
Training loss: 1.9690913555366025
Validation loss: 2.551340452004213

Epoch: 6| Step: 1
Training loss: 1.7631375505662616
Validation loss: 2.6514953873569875

Epoch: 6| Step: 2
Training loss: 1.653505318346171
Validation loss: 2.606702617410673

Epoch: 6| Step: 3
Training loss: 2.38619764667229
Validation loss: 2.6492069941603535

Epoch: 6| Step: 4
Training loss: 1.9057704134641846
Validation loss: 2.611778282878495

Epoch: 6| Step: 5
Training loss: 1.9534338134769895
Validation loss: 2.747244880159489

Epoch: 6| Step: 6
Training loss: 2.659107331949188
Validation loss: 2.560466759065527

Epoch: 6| Step: 7
Training loss: 2.0700073017231153
Validation loss: 2.6035216315665393

Epoch: 6| Step: 8
Training loss: 2.277677900817639
Validation loss: 2.6214647067418837

Epoch: 6| Step: 9
Training loss: 1.8539229529295898
Validation loss: 2.594413322614925

Epoch: 6| Step: 10
Training loss: 2.3306907494360627
Validation loss: 2.5867345697008757

Epoch: 6| Step: 11
Training loss: 2.0199054541037476
Validation loss: 2.6492537579053383

Epoch: 6| Step: 12
Training loss: 1.4490643442161528
Validation loss: 2.5811248886829703

Epoch: 6| Step: 13
Training loss: 2.4452570217286427
Validation loss: 2.580858297000179

Epoch: 408| Step: 0
Training loss: 2.5115209237559353
Validation loss: 2.6137753254449687

Epoch: 6| Step: 1
Training loss: 2.215270847268526
Validation loss: 2.57210485085947

Epoch: 6| Step: 2
Training loss: 2.1496762675144243
Validation loss: 2.5765532713398525

Epoch: 6| Step: 3
Training loss: 1.8773500973407249
Validation loss: 2.5610649638707934

Epoch: 6| Step: 4
Training loss: 2.2632563343724246
Validation loss: 2.6173242676797916

Epoch: 6| Step: 5
Training loss: 2.5416173669588535
Validation loss: 2.585945551956718

Epoch: 6| Step: 6
Training loss: 1.45208415830015
Validation loss: 2.6052177411480564

Epoch: 6| Step: 7
Training loss: 1.3938270308072958
Validation loss: 2.5919111167475024

Epoch: 6| Step: 8
Training loss: 1.9440349995480466
Validation loss: 2.646225358017829

Epoch: 6| Step: 9
Training loss: 2.081783430226644
Validation loss: 2.5897354189686808

Epoch: 6| Step: 10
Training loss: 2.5196290936064667
Validation loss: 2.6540571664402064

Epoch: 6| Step: 11
Training loss: 1.2907421382182156
Validation loss: 2.6191641085005815

Epoch: 6| Step: 12
Training loss: 2.160791231336883
Validation loss: 2.615008642960817

Epoch: 6| Step: 13
Training loss: 2.084248062226231
Validation loss: 2.6438465838609413

Epoch: 409| Step: 0
Training loss: 1.9601798246569282
Validation loss: 2.568112777037878

Epoch: 6| Step: 1
Training loss: 2.145149405907041
Validation loss: 2.6102145159004913

Epoch: 6| Step: 2
Training loss: 1.715138264523801
Validation loss: 2.6449207582468564

Epoch: 6| Step: 3
Training loss: 2.4189711358759887
Validation loss: 2.6787358128372656

Epoch: 6| Step: 4
Training loss: 1.5570952973158372
Validation loss: 2.615767751219851

Epoch: 6| Step: 5
Training loss: 2.6086015297315854
Validation loss: 2.6216721757889414

Epoch: 6| Step: 6
Training loss: 1.8750957464567315
Validation loss: 2.6342489377705323

Epoch: 6| Step: 7
Training loss: 1.4795461714057907
Validation loss: 2.590230523589434

Epoch: 6| Step: 8
Training loss: 2.1835032326595973
Validation loss: 2.5689555433499436

Epoch: 6| Step: 9
Training loss: 2.4895855466016137
Validation loss: 2.5952103407062523

Epoch: 6| Step: 10
Training loss: 1.8712527022409136
Validation loss: 2.6410363446037546

Epoch: 6| Step: 11
Training loss: 1.9250919121932453
Validation loss: 2.6270073492862194

Epoch: 6| Step: 12
Training loss: 1.8031656032598729
Validation loss: 2.5988387867983187

Epoch: 6| Step: 13
Training loss: 2.5043930556482055
Validation loss: 2.6653513045284556

Epoch: 410| Step: 0
Training loss: 2.511133389763292
Validation loss: 2.676085094029804

Epoch: 6| Step: 1
Training loss: 2.2248987239119535
Validation loss: 2.676963656641563

Epoch: 6| Step: 2
Training loss: 1.759487591625189
Validation loss: 2.5727461253976904

Epoch: 6| Step: 3
Training loss: 1.8484798474914546
Validation loss: 2.6269377701620087

Epoch: 6| Step: 4
Training loss: 2.461582644231122
Validation loss: 2.6421155989920875

Epoch: 6| Step: 5
Training loss: 2.049322630459484
Validation loss: 2.632926513174045

Epoch: 6| Step: 6
Training loss: 1.9172166643357218
Validation loss: 2.6403694123797163

Epoch: 6| Step: 7
Training loss: 2.7749545394335473
Validation loss: 2.6229988670205775

Epoch: 6| Step: 8
Training loss: 1.764565479078647
Validation loss: 2.631512475493816

Epoch: 6| Step: 9
Training loss: 2.040281903105702
Validation loss: 2.6616831420584353

Epoch: 6| Step: 10
Training loss: 1.495578448044967
Validation loss: 2.6650143998510876

Epoch: 6| Step: 11
Training loss: 1.638787393965315
Validation loss: 2.5958342625578408

Epoch: 6| Step: 12
Training loss: 1.6636288933129069
Validation loss: 2.666545577402021

Epoch: 6| Step: 13
Training loss: 2.187759275057328
Validation loss: 2.632217676455881

Epoch: 411| Step: 0
Training loss: 2.0716208876044933
Validation loss: 2.627330089645535

Epoch: 6| Step: 1
Training loss: 2.3815244101058832
Validation loss: 2.6332230536143544

Epoch: 6| Step: 2
Training loss: 1.9765383752850865
Validation loss: 2.5989901175974075

Epoch: 6| Step: 3
Training loss: 2.1448840908931883
Validation loss: 2.5970823130259753

Epoch: 6| Step: 4
Training loss: 2.0582638789311005
Validation loss: 2.665732984237397

Epoch: 6| Step: 5
Training loss: 1.9449810680262336
Validation loss: 2.592769761273415

Epoch: 6| Step: 6
Training loss: 1.9368383446838044
Validation loss: 2.6510844355434333

Epoch: 6| Step: 7
Training loss: 1.5789939074601087
Validation loss: 2.610148557327073

Epoch: 6| Step: 8
Training loss: 2.3932193815400025
Validation loss: 2.59370907631258

Epoch: 6| Step: 9
Training loss: 1.891623934572626
Validation loss: 2.6146680047431827

Epoch: 6| Step: 10
Training loss: 2.128500467527525
Validation loss: 2.6527612580377

Epoch: 6| Step: 11
Training loss: 2.0828505401686086
Validation loss: 2.6717404653878174

Epoch: 6| Step: 12
Training loss: 2.3534347836867915
Validation loss: 2.612054969583181

Epoch: 6| Step: 13
Training loss: 2.107441786282212
Validation loss: 2.597116169162516

Epoch: 412| Step: 0
Training loss: 2.3476737175670883
Validation loss: 2.6113291067380393

Epoch: 6| Step: 1
Training loss: 2.094366182213654
Validation loss: 2.5833846564128495

Epoch: 6| Step: 2
Training loss: 2.1300426564848003
Validation loss: 2.690600347547118

Epoch: 6| Step: 3
Training loss: 1.4739437394604744
Validation loss: 2.5965866834080638

Epoch: 6| Step: 4
Training loss: 2.689276795434899
Validation loss: 2.6210894307930377

Epoch: 6| Step: 5
Training loss: 2.3501964162353013
Validation loss: 2.6167973885908133

Epoch: 6| Step: 6
Training loss: 1.751963739777626
Validation loss: 2.630757408536134

Epoch: 6| Step: 7
Training loss: 2.008514044243672
Validation loss: 2.595457663641797

Epoch: 6| Step: 8
Training loss: 1.939855190063616
Validation loss: 2.615951817449494

Epoch: 6| Step: 9
Training loss: 1.6311483709605201
Validation loss: 2.60674632192472

Epoch: 6| Step: 10
Training loss: 1.614191569718982
Validation loss: 2.6271454686052427

Epoch: 6| Step: 11
Training loss: 2.420579329891372
Validation loss: 2.618202951123053

Epoch: 6| Step: 12
Training loss: 2.031618172951129
Validation loss: 2.645718951308826

Epoch: 6| Step: 13
Training loss: 1.729348054433992
Validation loss: 2.6748851876072153

Epoch: 413| Step: 0
Training loss: 2.95238473484717
Validation loss: 2.5952329106712453

Epoch: 6| Step: 1
Training loss: 1.705386628756978
Validation loss: 2.591335744087625

Epoch: 6| Step: 2
Training loss: 2.4743690765456416
Validation loss: 2.6397482512407917

Epoch: 6| Step: 3
Training loss: 1.6354863664227344
Validation loss: 2.5770404969654277

Epoch: 6| Step: 4
Training loss: 2.282580053256386
Validation loss: 2.6063106366230246

Epoch: 6| Step: 5
Training loss: 1.3901082911262865
Validation loss: 2.6395814069705654

Epoch: 6| Step: 6
Training loss: 2.147152714209496
Validation loss: 2.5948286051312324

Epoch: 6| Step: 7
Training loss: 1.6135864708009395
Validation loss: 2.562974561222034

Epoch: 6| Step: 8
Training loss: 1.2464218425217768
Validation loss: 2.5626506886169107

Epoch: 6| Step: 9
Training loss: 2.2967107804947324
Validation loss: 2.5655824773216636

Epoch: 6| Step: 10
Training loss: 2.1246564250771423
Validation loss: 2.6433759615329993

Epoch: 6| Step: 11
Training loss: 1.8424962840566859
Validation loss: 2.6439884543805734

Epoch: 6| Step: 12
Training loss: 2.3525832485991556
Validation loss: 2.592626540109806

Epoch: 6| Step: 13
Training loss: 2.4389276480678483
Validation loss: 2.572729245296539

Epoch: 414| Step: 0
Training loss: 2.6572241399348107
Validation loss: 2.5863582024863723

Epoch: 6| Step: 1
Training loss: 1.7114465383013706
Validation loss: 2.634295953424873

Epoch: 6| Step: 2
Training loss: 1.9263995495371118
Validation loss: 2.5504183771248465

Epoch: 6| Step: 3
Training loss: 1.8846790985643762
Validation loss: 2.617401027157322

Epoch: 6| Step: 4
Training loss: 1.9579100320425855
Validation loss: 2.577939511286004

Epoch: 6| Step: 5
Training loss: 2.8385424879347054
Validation loss: 2.5786217880528906

Epoch: 6| Step: 6
Training loss: 1.7024032043186663
Validation loss: 2.6173424077553737

Epoch: 6| Step: 7
Training loss: 2.201891289898972
Validation loss: 2.6541709701923812

Epoch: 6| Step: 8
Training loss: 1.7087006600434538
Validation loss: 2.604607525005122

Epoch: 6| Step: 9
Training loss: 1.7367214791451933
Validation loss: 2.6605235592740843

Epoch: 6| Step: 10
Training loss: 1.4521513927970937
Validation loss: 2.641712884746758

Epoch: 6| Step: 11
Training loss: 2.2194957285868084
Validation loss: 2.681877944600582

Epoch: 6| Step: 12
Training loss: 2.0749297854022353
Validation loss: 2.6477566924916562

Epoch: 6| Step: 13
Training loss: 1.8799666428143034
Validation loss: 2.669136982264745

Epoch: 415| Step: 0
Training loss: 2.7395605127426035
Validation loss: 2.6358263578546284

Epoch: 6| Step: 1
Training loss: 1.3694558209343695
Validation loss: 2.6485160602786997

Epoch: 6| Step: 2
Training loss: 1.7196702747567152
Validation loss: 2.5788881049434718

Epoch: 6| Step: 3
Training loss: 1.4991072541204946
Validation loss: 2.588969672981239

Epoch: 6| Step: 4
Training loss: 2.1105791963866154
Validation loss: 2.6652434156739258

Epoch: 6| Step: 5
Training loss: 1.634769489826114
Validation loss: 2.616668270584262

Epoch: 6| Step: 6
Training loss: 1.9417735314601567
Validation loss: 2.653737124943238

Epoch: 6| Step: 7
Training loss: 2.0596836397149025
Validation loss: 2.6440184336171697

Epoch: 6| Step: 8
Training loss: 2.15644315877219
Validation loss: 2.640424196137591

Epoch: 6| Step: 9
Training loss: 2.1898653593436337
Validation loss: 2.6680490105180916

Epoch: 6| Step: 10
Training loss: 2.642057853960491
Validation loss: 2.6293102510374657

Epoch: 6| Step: 11
Training loss: 1.4508682282421985
Validation loss: 2.6415394738780353

Epoch: 6| Step: 12
Training loss: 2.197239149146046
Validation loss: 2.680641901017387

Epoch: 6| Step: 13
Training loss: 1.8159342490951436
Validation loss: 2.624783348288048

Epoch: 416| Step: 0
Training loss: 2.5636155096272084
Validation loss: 2.6337431776286606

Epoch: 6| Step: 1
Training loss: 2.041779793959247
Validation loss: 2.6079737370343414

Epoch: 6| Step: 2
Training loss: 2.5860339374365777
Validation loss: 2.62481026029661

Epoch: 6| Step: 3
Training loss: 1.763494303097891
Validation loss: 2.622110472863288

Epoch: 6| Step: 4
Training loss: 1.8790531220004618
Validation loss: 2.667430037945248

Epoch: 6| Step: 5
Training loss: 2.033911501914385
Validation loss: 2.584043221350109

Epoch: 6| Step: 6
Training loss: 1.9969190470295495
Validation loss: 2.6678133320677353

Epoch: 6| Step: 7
Training loss: 2.137768252310324
Validation loss: 2.6155351335370627

Epoch: 6| Step: 8
Training loss: 2.1935931766459533
Validation loss: 2.6601244355489735

Epoch: 6| Step: 9
Training loss: 1.9797555816914687
Validation loss: 2.618513827842118

Epoch: 6| Step: 10
Training loss: 1.9756047638747063
Validation loss: 2.6391827024856513

Epoch: 6| Step: 11
Training loss: 1.3566260330729116
Validation loss: 2.645309369876822

Epoch: 6| Step: 12
Training loss: 1.731247496344894
Validation loss: 2.592409904851788

Epoch: 6| Step: 13
Training loss: 1.6980517359019667
Validation loss: 2.619576939151465

Epoch: 417| Step: 0
Training loss: 1.9565720314435895
Validation loss: 2.6946600230212314

Epoch: 6| Step: 1
Training loss: 1.644804145841346
Validation loss: 2.5612725320100385

Epoch: 6| Step: 2
Training loss: 1.9257012712379258
Validation loss: 2.594720140364815

Epoch: 6| Step: 3
Training loss: 1.8666808905513705
Validation loss: 2.6197098213392915

Epoch: 6| Step: 4
Training loss: 2.6442824997543437
Validation loss: 2.5969085369760805

Epoch: 6| Step: 5
Training loss: 1.9219958259624526
Validation loss: 2.668693411275327

Epoch: 6| Step: 6
Training loss: 1.952299386047445
Validation loss: 2.626240321527488

Epoch: 6| Step: 7
Training loss: 1.8376770868410175
Validation loss: 2.6366674109367474

Epoch: 6| Step: 8
Training loss: 2.404871855591309
Validation loss: 2.6210049955183163

Epoch: 6| Step: 9
Training loss: 2.1463100928379197
Validation loss: 2.662708709661647

Epoch: 6| Step: 10
Training loss: 1.4643816002743013
Validation loss: 2.6551047667876895

Epoch: 6| Step: 11
Training loss: 2.117017675817016
Validation loss: 2.613047680051399

Epoch: 6| Step: 12
Training loss: 2.3756872487813325
Validation loss: 2.6271345354118623

Epoch: 6| Step: 13
Training loss: 1.8593059494917203
Validation loss: 2.592706797915458

Epoch: 418| Step: 0
Training loss: 1.979933687120735
Validation loss: 2.66472990385956

Epoch: 6| Step: 1
Training loss: 1.727373372914772
Validation loss: 2.611836413693333

Epoch: 6| Step: 2
Training loss: 1.7125014033625066
Validation loss: 2.628974169006289

Epoch: 6| Step: 3
Training loss: 2.1056062161611844
Validation loss: 2.587018422963181

Epoch: 6| Step: 4
Training loss: 2.7045858327708796
Validation loss: 2.5989511654047823

Epoch: 6| Step: 5
Training loss: 1.9922945480009382
Validation loss: 2.6755282063300867

Epoch: 6| Step: 6
Training loss: 1.783027163929246
Validation loss: 2.622380599754558

Epoch: 6| Step: 7
Training loss: 2.5852155801392422
Validation loss: 2.6182998255020093

Epoch: 6| Step: 8
Training loss: 1.9730722725184642
Validation loss: 2.5541013218445316

Epoch: 6| Step: 9
Training loss: 1.9249797646586035
Validation loss: 2.6223952265727326

Epoch: 6| Step: 10
Training loss: 1.9344200757618544
Validation loss: 2.603287173171772

Epoch: 6| Step: 11
Training loss: 1.9075031226496304
Validation loss: 2.6638968802386005

Epoch: 6| Step: 12
Training loss: 1.7937390370316388
Validation loss: 2.644549614964068

Epoch: 6| Step: 13
Training loss: 1.1105306274642464
Validation loss: 2.6103675197014464

Epoch: 419| Step: 0
Training loss: 2.365391014954079
Validation loss: 2.6250845177204782

Epoch: 6| Step: 1
Training loss: 1.5609138066934605
Validation loss: 2.6019346283969274

Epoch: 6| Step: 2
Training loss: 2.583839141385765
Validation loss: 2.635569792263027

Epoch: 6| Step: 3
Training loss: 3.0484716682337605
Validation loss: 2.6441987381892593

Epoch: 6| Step: 4
Training loss: 2.14092102231528
Validation loss: 2.670646257810829

Epoch: 6| Step: 5
Training loss: 1.5150334885172458
Validation loss: 2.6223770823455315

Epoch: 6| Step: 6
Training loss: 2.3820713579073565
Validation loss: 2.663199062799493

Epoch: 6| Step: 7
Training loss: 1.3859723728613644
Validation loss: 2.6893707693398428

Epoch: 6| Step: 8
Training loss: 1.626824308610246
Validation loss: 2.636659972805399

Epoch: 6| Step: 9
Training loss: 1.5615632873374385
Validation loss: 2.620050688596671

Epoch: 6| Step: 10
Training loss: 2.0661371701283855
Validation loss: 2.665735600065444

Epoch: 6| Step: 11
Training loss: 2.076061400150493
Validation loss: 2.52883931497347

Epoch: 6| Step: 12
Training loss: 1.7401418950332337
Validation loss: 2.672784624193665

Epoch: 6| Step: 13
Training loss: 1.6117355663847923
Validation loss: 2.6313178312690506

Epoch: 420| Step: 0
Training loss: 2.1649393997344832
Validation loss: 2.6083020170611366

Epoch: 6| Step: 1
Training loss: 1.7164546551691813
Validation loss: 2.6682771029415315

Epoch: 6| Step: 2
Training loss: 1.750614535195922
Validation loss: 2.59469977418698

Epoch: 6| Step: 3
Training loss: 2.09575136098962
Validation loss: 2.584989442283889

Epoch: 6| Step: 4
Training loss: 2.246551944603335
Validation loss: 2.6078998841110175

Epoch: 6| Step: 5
Training loss: 2.209670172024441
Validation loss: 2.625327366750575

Epoch: 6| Step: 6
Training loss: 1.7689397972907979
Validation loss: 2.652577105185471

Epoch: 6| Step: 7
Training loss: 1.895938814463615
Validation loss: 2.586748565584155

Epoch: 6| Step: 8
Training loss: 1.7940633254256124
Validation loss: 2.69690268963876

Epoch: 6| Step: 9
Training loss: 2.427053514114589
Validation loss: 2.621552007155237

Epoch: 6| Step: 10
Training loss: 2.572005899650962
Validation loss: 2.589872953344646

Epoch: 6| Step: 11
Training loss: 1.798136923136874
Validation loss: 2.5972003219304396

Epoch: 6| Step: 12
Training loss: 1.7997611046252566
Validation loss: 2.5883135535486197

Epoch: 6| Step: 13
Training loss: 1.436465098157873
Validation loss: 2.655877579332946

Epoch: 421| Step: 0
Training loss: 2.717790368507494
Validation loss: 2.619975008730668

Epoch: 6| Step: 1
Training loss: 1.4084247303636264
Validation loss: 2.6346135379528475

Epoch: 6| Step: 2
Training loss: 1.9628971839909073
Validation loss: 2.645709540588114

Epoch: 6| Step: 3
Training loss: 1.482888853078995
Validation loss: 2.615304975676256

Epoch: 6| Step: 4
Training loss: 1.7326356568834038
Validation loss: 2.587471904070053

Epoch: 6| Step: 5
Training loss: 2.532947677403227
Validation loss: 2.6911158322639266

Epoch: 6| Step: 6
Training loss: 1.551098692567063
Validation loss: 2.678676713435923

Epoch: 6| Step: 7
Training loss: 2.18988212581764
Validation loss: 2.627538593236297

Epoch: 6| Step: 8
Training loss: 1.716013099118012
Validation loss: 2.626865681052387

Epoch: 6| Step: 9
Training loss: 1.963245022033808
Validation loss: 2.598586532773145

Epoch: 6| Step: 10
Training loss: 1.986614675492262
Validation loss: 2.641452424484834

Epoch: 6| Step: 11
Training loss: 2.202226820944253
Validation loss: 2.600249754282395

Epoch: 6| Step: 12
Training loss: 2.0218160016326925
Validation loss: 2.643412571611024

Epoch: 6| Step: 13
Training loss: 2.7458946622522324
Validation loss: 2.648209093758096

Epoch: 422| Step: 0
Training loss: 2.5520177300773024
Validation loss: 2.6246004625804957

Epoch: 6| Step: 1
Training loss: 1.4721772808836908
Validation loss: 2.578647706462405

Epoch: 6| Step: 2
Training loss: 1.9492884071150578
Validation loss: 2.593272115106259

Epoch: 6| Step: 3
Training loss: 2.0930658617661018
Validation loss: 2.6346911618063573

Epoch: 6| Step: 4
Training loss: 2.5195511218329716
Validation loss: 2.612724463771352

Epoch: 6| Step: 5
Training loss: 2.252148344340797
Validation loss: 2.615104763185183

Epoch: 6| Step: 6
Training loss: 1.9673375709502703
Validation loss: 2.6194184160793643

Epoch: 6| Step: 7
Training loss: 2.024814564255898
Validation loss: 2.61465879699996

Epoch: 6| Step: 8
Training loss: 2.039743244057562
Validation loss: 2.610968229327372

Epoch: 6| Step: 9
Training loss: 1.9810309881706871
Validation loss: 2.616542291307756

Epoch: 6| Step: 10
Training loss: 1.718554398937355
Validation loss: 2.5873262900436105

Epoch: 6| Step: 11
Training loss: 1.2716327352150734
Validation loss: 2.5888573235436168

Epoch: 6| Step: 12
Training loss: 1.92046856785293
Validation loss: 2.5931796926917627

Epoch: 6| Step: 13
Training loss: 2.122533938043336
Validation loss: 2.6208713769038616

Epoch: 423| Step: 0
Training loss: 1.9524585655006736
Validation loss: 2.6230019774990407

Epoch: 6| Step: 1
Training loss: 1.9023589147319717
Validation loss: 2.656459465671242

Epoch: 6| Step: 2
Training loss: 2.2826952601934023
Validation loss: 2.583795015665361

Epoch: 6| Step: 3
Training loss: 1.7163667975550534
Validation loss: 2.639944499640594

Epoch: 6| Step: 4
Training loss: 2.194995029070185
Validation loss: 2.630702384489372

Epoch: 6| Step: 5
Training loss: 2.3301726687388844
Validation loss: 2.695635263153318

Epoch: 6| Step: 6
Training loss: 1.7410508626205294
Validation loss: 2.628865230942233

Epoch: 6| Step: 7
Training loss: 1.6625168476828576
Validation loss: 2.660889457450209

Epoch: 6| Step: 8
Training loss: 2.82456358180212
Validation loss: 2.5867803290802294

Epoch: 6| Step: 9
Training loss: 1.4177450208473925
Validation loss: 2.685516735038286

Epoch: 6| Step: 10
Training loss: 1.3731798349091642
Validation loss: 2.6169682119005966

Epoch: 6| Step: 11
Training loss: 2.0757083465098143
Validation loss: 2.642305553310485

Epoch: 6| Step: 12
Training loss: 2.432198848764056
Validation loss: 2.610926825355371

Epoch: 6| Step: 13
Training loss: 1.2804072795308237
Validation loss: 2.644566089472555

Epoch: 424| Step: 0
Training loss: 1.5259572636130854
Validation loss: 2.646966759421652

Epoch: 6| Step: 1
Training loss: 1.9507841196524123
Validation loss: 2.612912110198744

Epoch: 6| Step: 2
Training loss: 2.171405329795017
Validation loss: 2.6031215462315

Epoch: 6| Step: 3
Training loss: 1.221932876660116
Validation loss: 2.6369267630248614

Epoch: 6| Step: 4
Training loss: 1.1647843548517876
Validation loss: 2.6388025549982355

Epoch: 6| Step: 5
Training loss: 2.1744962832449146
Validation loss: 2.593176834621733

Epoch: 6| Step: 6
Training loss: 1.8454503123400972
Validation loss: 2.565166613589738

Epoch: 6| Step: 7
Training loss: 2.136641310939618
Validation loss: 2.597192935611413

Epoch: 6| Step: 8
Training loss: 1.8442716345524512
Validation loss: 2.67731790978048

Epoch: 6| Step: 9
Training loss: 1.4865169129549858
Validation loss: 2.574086456457251

Epoch: 6| Step: 10
Training loss: 3.068361239854621
Validation loss: 2.646754838730075

Epoch: 6| Step: 11
Training loss: 2.0352220872418254
Validation loss: 2.5940543741277255

Epoch: 6| Step: 12
Training loss: 2.401412262247256
Validation loss: 2.616304543300073

Epoch: 6| Step: 13
Training loss: 2.231078590626352
Validation loss: 2.6091720043279785

Epoch: 425| Step: 0
Training loss: 1.7246818138453217
Validation loss: 2.610547053101322

Epoch: 6| Step: 1
Training loss: 2.2388203822094317
Validation loss: 2.5760993136575965

Epoch: 6| Step: 2
Training loss: 1.6822453385185185
Validation loss: 2.6250068851972483

Epoch: 6| Step: 3
Training loss: 2.4860144430034055
Validation loss: 2.605190544085559

Epoch: 6| Step: 4
Training loss: 2.1026998512457054
Validation loss: 2.612589862336021

Epoch: 6| Step: 5
Training loss: 2.1970735593139845
Validation loss: 2.654698564851514

Epoch: 6| Step: 6
Training loss: 2.1986709915374605
Validation loss: 2.6200321563119444

Epoch: 6| Step: 7
Training loss: 2.098546810526966
Validation loss: 2.6966418330987474

Epoch: 6| Step: 8
Training loss: 1.808703557217668
Validation loss: 2.6328527409084876

Epoch: 6| Step: 9
Training loss: 1.2651126907876016
Validation loss: 2.5849981487655747

Epoch: 6| Step: 10
Training loss: 1.688773063541707
Validation loss: 2.5611130187007536

Epoch: 6| Step: 11
Training loss: 1.8345369881586584
Validation loss: 2.714094815633382

Epoch: 6| Step: 12
Training loss: 2.4481134430274345
Validation loss: 2.6150391995130224

Epoch: 6| Step: 13
Training loss: 1.7561275290145764
Validation loss: 2.6117707355834368

Epoch: 426| Step: 0
Training loss: 2.0289084216000846
Validation loss: 2.671076989028999

Epoch: 6| Step: 1
Training loss: 1.795264675210549
Validation loss: 2.6951115007016813

Epoch: 6| Step: 2
Training loss: 1.8242280294112891
Validation loss: 2.5506151213051096

Epoch: 6| Step: 3
Training loss: 1.6664726462283865
Validation loss: 2.6315595790056374

Epoch: 6| Step: 4
Training loss: 2.331512649099326
Validation loss: 2.688549746763501

Epoch: 6| Step: 5
Training loss: 1.9867669655082816
Validation loss: 2.585969018677466

Epoch: 6| Step: 6
Training loss: 2.5221833221397163
Validation loss: 2.647688390645496

Epoch: 6| Step: 7
Training loss: 1.7077231674353601
Validation loss: 2.6263364640890448

Epoch: 6| Step: 8
Training loss: 1.891665968145614
Validation loss: 2.722418119522319

Epoch: 6| Step: 9
Training loss: 1.6348107626823676
Validation loss: 2.6237211242217735

Epoch: 6| Step: 10
Training loss: 1.4854587814688334
Validation loss: 2.63159857167017

Epoch: 6| Step: 11
Training loss: 2.138867735930153
Validation loss: 2.5943999757889467

Epoch: 6| Step: 12
Training loss: 1.8282677358348403
Validation loss: 2.564637471947256

Epoch: 6| Step: 13
Training loss: 3.183703087175379
Validation loss: 2.6199288946436705

Epoch: 427| Step: 0
Training loss: 1.4843405468606472
Validation loss: 2.6011647063773284

Epoch: 6| Step: 1
Training loss: 1.7864534101798357
Validation loss: 2.653301843504354

Epoch: 6| Step: 2
Training loss: 1.937314547615484
Validation loss: 2.6108321214143526

Epoch: 6| Step: 3
Training loss: 2.461074486204745
Validation loss: 2.5868838753692556

Epoch: 6| Step: 4
Training loss: 1.483047212730184
Validation loss: 2.5994069195242075

Epoch: 6| Step: 5
Training loss: 2.204561130678881
Validation loss: 2.6525680010066774

Epoch: 6| Step: 6
Training loss: 2.8048026823656627
Validation loss: 2.5840091889689574

Epoch: 6| Step: 7
Training loss: 2.3198475998117933
Validation loss: 2.589499519290711

Epoch: 6| Step: 8
Training loss: 1.6927954626889707
Validation loss: 2.6774172039433526

Epoch: 6| Step: 9
Training loss: 1.820782252918433
Validation loss: 2.5881711362414217

Epoch: 6| Step: 10
Training loss: 1.672684518075443
Validation loss: 2.542843277180907

Epoch: 6| Step: 11
Training loss: 1.9436407911034663
Validation loss: 2.6552783981843104

Epoch: 6| Step: 12
Training loss: 1.330506601651976
Validation loss: 2.553359946988246

Epoch: 6| Step: 13
Training loss: 2.3030915505038965
Validation loss: 2.66562701507728

Epoch: 428| Step: 0
Training loss: 2.3683291662807258
Validation loss: 2.606356194932102

Epoch: 6| Step: 1
Training loss: 1.3846249529108554
Validation loss: 2.608623748956569

Epoch: 6| Step: 2
Training loss: 1.6485873330528014
Validation loss: 2.6205443065618454

Epoch: 6| Step: 3
Training loss: 2.2312145155534697
Validation loss: 2.6204985400074703

Epoch: 6| Step: 4
Training loss: 1.8148148322952395
Validation loss: 2.639881909792585

Epoch: 6| Step: 5
Training loss: 2.079859647783951
Validation loss: 2.607329332744141

Epoch: 6| Step: 6
Training loss: 1.9874485872924454
Validation loss: 2.6131667318938825

Epoch: 6| Step: 7
Training loss: 1.9840138024034615
Validation loss: 2.6464564763884812

Epoch: 6| Step: 8
Training loss: 2.2559285999592307
Validation loss: 2.6354488978971933

Epoch: 6| Step: 9
Training loss: 1.8003604422067245
Validation loss: 2.588274806167259

Epoch: 6| Step: 10
Training loss: 2.278766691363333
Validation loss: 2.632286627108009

Epoch: 6| Step: 11
Training loss: 1.850960420347137
Validation loss: 2.5591148654246774

Epoch: 6| Step: 12
Training loss: 1.891284732940891
Validation loss: 2.6438997150503143

Epoch: 6| Step: 13
Training loss: 1.9545845376637634
Validation loss: 2.631274860293771

Epoch: 429| Step: 0
Training loss: 2.082650441463503
Validation loss: 2.6542311416403255

Epoch: 6| Step: 1
Training loss: 2.770998804032265
Validation loss: 2.6411355613534484

Epoch: 6| Step: 2
Training loss: 1.919715722814422
Validation loss: 2.576961706583137

Epoch: 6| Step: 3
Training loss: 1.631731615550041
Validation loss: 2.580590142924887

Epoch: 6| Step: 4
Training loss: 1.9104808071383417
Validation loss: 2.659358291262114

Epoch: 6| Step: 5
Training loss: 1.502701869104337
Validation loss: 2.665301471148975

Epoch: 6| Step: 6
Training loss: 1.3394072241384545
Validation loss: 2.7046953948665835

Epoch: 6| Step: 7
Training loss: 2.0861682549901537
Validation loss: 2.588507363957931

Epoch: 6| Step: 8
Training loss: 2.0563192524016913
Validation loss: 2.7368601504261925

Epoch: 6| Step: 9
Training loss: 1.7824899473615745
Validation loss: 2.62823375040724

Epoch: 6| Step: 10
Training loss: 1.2478567345715468
Validation loss: 2.6075240116993728

Epoch: 6| Step: 11
Training loss: 2.477299625673844
Validation loss: 2.596758356936497

Epoch: 6| Step: 12
Training loss: 2.084177481973929
Validation loss: 2.5864306821867307

Epoch: 6| Step: 13
Training loss: 2.7067594405499626
Validation loss: 2.704217588834259

Epoch: 430| Step: 0
Training loss: 2.177548469853659
Validation loss: 2.691854415355392

Epoch: 6| Step: 1
Training loss: 1.6076645140760357
Validation loss: 2.597788050815472

Epoch: 6| Step: 2
Training loss: 1.689301553442829
Validation loss: 2.618254981231133

Epoch: 6| Step: 3
Training loss: 1.9791932823666956
Validation loss: 2.625321235279677

Epoch: 6| Step: 4
Training loss: 1.570738853156394
Validation loss: 2.604497391568019

Epoch: 6| Step: 5
Training loss: 2.361958081292554
Validation loss: 2.623303961983512

Epoch: 6| Step: 6
Training loss: 1.9918129363144657
Validation loss: 2.622746743266429

Epoch: 6| Step: 7
Training loss: 2.7815268732336556
Validation loss: 2.5275875836834305

Epoch: 6| Step: 8
Training loss: 2.059362857765442
Validation loss: 2.6170050542594536

Epoch: 6| Step: 9
Training loss: 2.5293562598602897
Validation loss: 2.6412866332309823

Epoch: 6| Step: 10
Training loss: 1.339762960506163
Validation loss: 2.6571497696785555

Epoch: 6| Step: 11
Training loss: 2.008959253470436
Validation loss: 2.5582565720446455

Epoch: 6| Step: 12
Training loss: 1.3661770819831291
Validation loss: 2.6111521915836797

Epoch: 6| Step: 13
Training loss: 1.4626396177764562
Validation loss: 2.629241188204497

Epoch: 431| Step: 0
Training loss: 1.0910548109207665
Validation loss: 2.669420334385758

Epoch: 6| Step: 1
Training loss: 2.5671162777085823
Validation loss: 2.640623669940429

Epoch: 6| Step: 2
Training loss: 2.1448932057362837
Validation loss: 2.64889767172121

Epoch: 6| Step: 3
Training loss: 1.9366461195104712
Validation loss: 2.642795671266067

Epoch: 6| Step: 4
Training loss: 1.3930334601398977
Validation loss: 2.5649267331530208

Epoch: 6| Step: 5
Training loss: 2.097934242738086
Validation loss: 2.649742420383779

Epoch: 6| Step: 6
Training loss: 1.3812906544083585
Validation loss: 2.6253699936997132

Epoch: 6| Step: 7
Training loss: 2.1672178325441838
Validation loss: 2.6624010800908997

Epoch: 6| Step: 8
Training loss: 2.139853456773918
Validation loss: 2.650985769081487

Epoch: 6| Step: 9
Training loss: 1.6832956992874497
Validation loss: 2.6205846018339605

Epoch: 6| Step: 10
Training loss: 2.0110869665552356
Validation loss: 2.6937505194756266

Epoch: 6| Step: 11
Training loss: 1.6760229545514433
Validation loss: 2.587882478050678

Epoch: 6| Step: 12
Training loss: 2.6198552896852147
Validation loss: 2.6516023853533923

Epoch: 6| Step: 13
Training loss: 1.7296565024640336
Validation loss: 2.5883537969235975

Epoch: 432| Step: 0
Training loss: 1.6796263217873981
Validation loss: 2.658026041778537

Epoch: 6| Step: 1
Training loss: 2.3206667645695567
Validation loss: 2.655551254373783

Epoch: 6| Step: 2
Training loss: 2.6127984893974334
Validation loss: 2.616782830411422

Epoch: 6| Step: 3
Training loss: 1.3671306489296025
Validation loss: 2.59045680067445

Epoch: 6| Step: 4
Training loss: 1.3084402876870485
Validation loss: 2.6664223661599964

Epoch: 6| Step: 5
Training loss: 2.127560811591303
Validation loss: 2.6817654934767745

Epoch: 6| Step: 6
Training loss: 1.7860629994643022
Validation loss: 2.705774185460069

Epoch: 6| Step: 7
Training loss: 1.6904102943581758
Validation loss: 2.5828581170130467

Epoch: 6| Step: 8
Training loss: 2.6996381022608773
Validation loss: 2.659024899309891

Epoch: 6| Step: 9
Training loss: 1.7235148878525222
Validation loss: 2.5352960656669428

Epoch: 6| Step: 10
Training loss: 2.1749162855151516
Validation loss: 2.5641638143660743

Epoch: 6| Step: 11
Training loss: 1.7161286912292533
Validation loss: 2.6853712493358453

Epoch: 6| Step: 12
Training loss: 2.08828797230493
Validation loss: 2.713749115662253

Epoch: 6| Step: 13
Training loss: 2.1367893800098092
Validation loss: 2.6253207807163257

Epoch: 433| Step: 0
Training loss: 1.705540894656932
Validation loss: 2.6473251186105635

Epoch: 6| Step: 1
Training loss: 1.6254439114410324
Validation loss: 2.6431572554827643

Epoch: 6| Step: 2
Training loss: 1.5919904532649507
Validation loss: 2.6584241516783935

Epoch: 6| Step: 3
Training loss: 2.0873419787506986
Validation loss: 2.5681055790842398

Epoch: 6| Step: 4
Training loss: 1.9793934809234843
Validation loss: 2.6390083919193805

Epoch: 6| Step: 5
Training loss: 2.7073393146881233
Validation loss: 2.67080126228279

Epoch: 6| Step: 6
Training loss: 1.7072305453866852
Validation loss: 2.5964810260622806

Epoch: 6| Step: 7
Training loss: 2.104420020333099
Validation loss: 2.5715520404371888

Epoch: 6| Step: 8
Training loss: 1.5907269398338097
Validation loss: 2.6829053241133294

Epoch: 6| Step: 9
Training loss: 2.122583136845538
Validation loss: 2.653446480369678

Epoch: 6| Step: 10
Training loss: 2.3041600545152523
Validation loss: 2.6546159383306547

Epoch: 6| Step: 11
Training loss: 1.652298514105416
Validation loss: 2.602056389221558

Epoch: 6| Step: 12
Training loss: 1.7553255926821876
Validation loss: 2.6146353799087714

Epoch: 6| Step: 13
Training loss: 1.501372186546494
Validation loss: 2.546137661940003

Epoch: 434| Step: 0
Training loss: 1.8871762054807804
Validation loss: 2.614568163073534

Epoch: 6| Step: 1
Training loss: 1.9200454936002185
Validation loss: 2.642647141958226

Epoch: 6| Step: 2
Training loss: 1.513449927024382
Validation loss: 2.6397023699234983

Epoch: 6| Step: 3
Training loss: 2.654509568832893
Validation loss: 2.6554720121110083

Epoch: 6| Step: 4
Training loss: 1.9862685293073965
Validation loss: 2.596552480974748

Epoch: 6| Step: 5
Training loss: 1.760330769928102
Validation loss: 2.645182833757667

Epoch: 6| Step: 6
Training loss: 1.7687482638401097
Validation loss: 2.5619616209287477

Epoch: 6| Step: 7
Training loss: 1.4984013462577919
Validation loss: 2.5729859145050247

Epoch: 6| Step: 8
Training loss: 1.9179492957222053
Validation loss: 2.6271887481473413

Epoch: 6| Step: 9
Training loss: 2.0414609870331515
Validation loss: 2.6480921033270954

Epoch: 6| Step: 10
Training loss: 1.7587174862240091
Validation loss: 2.5650920968619975

Epoch: 6| Step: 11
Training loss: 1.892601115399092
Validation loss: 2.6824983518166277

Epoch: 6| Step: 12
Training loss: 2.7667816674410877
Validation loss: 2.641035608816882

Epoch: 6| Step: 13
Training loss: 1.8384481591786663
Validation loss: 2.601594021533634

Epoch: 435| Step: 0
Training loss: 1.9027505239992946
Validation loss: 2.6450922241918553

Epoch: 6| Step: 1
Training loss: 2.098899089523002
Validation loss: 2.6705198595230017

Epoch: 6| Step: 2
Training loss: 1.8696329231846702
Validation loss: 2.647203394151472

Epoch: 6| Step: 3
Training loss: 1.626199279744837
Validation loss: 2.6556809319455725

Epoch: 6| Step: 4
Training loss: 2.3157124244155995
Validation loss: 2.6640844202551692

Epoch: 6| Step: 5
Training loss: 1.9950211661035815
Validation loss: 2.667968629407543

Epoch: 6| Step: 6
Training loss: 2.256375815986231
Validation loss: 2.6804751623343726

Epoch: 6| Step: 7
Training loss: 1.6402995922171606
Validation loss: 2.6188125113021123

Epoch: 6| Step: 8
Training loss: 1.5075944337636327
Validation loss: 2.6393834657896007

Epoch: 6| Step: 9
Training loss: 1.9486576717641977
Validation loss: 2.634276080068265

Epoch: 6| Step: 10
Training loss: 1.9571206687250235
Validation loss: 2.6122646266382947

Epoch: 6| Step: 11
Training loss: 2.9890332042576553
Validation loss: 2.673197755332627

Epoch: 6| Step: 12
Training loss: 1.7964332369240283
Validation loss: 2.6500168739643777

Epoch: 6| Step: 13
Training loss: 1.1917493982651641
Validation loss: 2.6627837478253795

Epoch: 436| Step: 0
Training loss: 2.4629912994887784
Validation loss: 2.6825368639926612

Epoch: 6| Step: 1
Training loss: 1.9458601460321499
Validation loss: 2.6548947838416934

Epoch: 6| Step: 2
Training loss: 2.0151553530948756
Validation loss: 2.6159107143306484

Epoch: 6| Step: 3
Training loss: 1.5611601616305903
Validation loss: 2.6650981767032196

Epoch: 6| Step: 4
Training loss: 2.3242218274007986
Validation loss: 2.6850123232732868

Epoch: 6| Step: 5
Training loss: 1.430515070633501
Validation loss: 2.6462287487859086

Epoch: 6| Step: 6
Training loss: 1.58243870138857
Validation loss: 2.6505785567653497

Epoch: 6| Step: 7
Training loss: 2.142059513779038
Validation loss: 2.694416868339855

Epoch: 6| Step: 8
Training loss: 2.121572535310308
Validation loss: 2.5982203491993334

Epoch: 6| Step: 9
Training loss: 2.6509829191782166
Validation loss: 2.6281701656899568

Epoch: 6| Step: 10
Training loss: 1.7263579786866197
Validation loss: 2.6361642990014795

Epoch: 6| Step: 11
Training loss: 2.3459909534068535
Validation loss: 2.6013634526198004

Epoch: 6| Step: 12
Training loss: 1.1825826121661769
Validation loss: 2.6461096120283036

Epoch: 6| Step: 13
Training loss: 1.4981415680123145
Validation loss: 2.50447160272436

Epoch: 437| Step: 0
Training loss: 1.4494131939762929
Validation loss: 2.572687792918236

Epoch: 6| Step: 1
Training loss: 1.9488098082500738
Validation loss: 2.5986808109009116

Epoch: 6| Step: 2
Training loss: 1.9579071095129108
Validation loss: 2.6476535699879373

Epoch: 6| Step: 3
Training loss: 1.675359855257235
Validation loss: 2.6893156271191327

Epoch: 6| Step: 4
Training loss: 3.13103802052906
Validation loss: 2.6138297799514643

Epoch: 6| Step: 5
Training loss: 1.6540561036923709
Validation loss: 2.641580149582533

Epoch: 6| Step: 6
Training loss: 1.9703258081360324
Validation loss: 2.6505381468246747

Epoch: 6| Step: 7
Training loss: 2.01625559797178
Validation loss: 2.5903342991368477

Epoch: 6| Step: 8
Training loss: 1.440262917385037
Validation loss: 2.61517449538888

Epoch: 6| Step: 9
Training loss: 1.7735079444640638
Validation loss: 2.5869407738677808

Epoch: 6| Step: 10
Training loss: 2.0821424386571583
Validation loss: 2.6441480019871735

Epoch: 6| Step: 11
Training loss: 2.1226065002609293
Validation loss: 2.5799444953208486

Epoch: 6| Step: 12
Training loss: 1.8678330458707235
Validation loss: 2.658444840676476

Epoch: 6| Step: 13
Training loss: 1.9304474480942275
Validation loss: 2.6431878270597498

Epoch: 438| Step: 0
Training loss: 2.558936642099849
Validation loss: 2.649756586562935

Epoch: 6| Step: 1
Training loss: 1.6172787553038523
Validation loss: 2.6109149827638714

Epoch: 6| Step: 2
Training loss: 2.576180574461714
Validation loss: 2.6142261818289345

Epoch: 6| Step: 3
Training loss: 2.016337305816876
Validation loss: 2.6475747914257197

Epoch: 6| Step: 4
Training loss: 1.7166777863497291
Validation loss: 2.6960787071215604

Epoch: 6| Step: 5
Training loss: 1.6939361188479183
Validation loss: 2.636949340508788

Epoch: 6| Step: 6
Training loss: 2.0441276224759046
Validation loss: 2.6531615068224776

Epoch: 6| Step: 7
Training loss: 1.5034328756061066
Validation loss: 2.655135535841998

Epoch: 6| Step: 8
Training loss: 1.8626782223218559
Validation loss: 2.6024296660513437

Epoch: 6| Step: 9
Training loss: 2.247700151605436
Validation loss: 2.6213923184700207

Epoch: 6| Step: 10
Training loss: 1.5363298351628465
Validation loss: 2.595719946563838

Epoch: 6| Step: 11
Training loss: 1.577211020913875
Validation loss: 2.5879462700385503

Epoch: 6| Step: 12
Training loss: 2.2065606349736755
Validation loss: 2.611166726175138

Epoch: 6| Step: 13
Training loss: 2.106959224116267
Validation loss: 2.6359833213491624

Epoch: 439| Step: 0
Training loss: 1.8367433767805499
Validation loss: 2.653171642857856

Epoch: 6| Step: 1
Training loss: 1.483119795284149
Validation loss: 2.6020747180021284

Epoch: 6| Step: 2
Training loss: 1.8405455852273935
Validation loss: 2.660821723949531

Epoch: 6| Step: 3
Training loss: 2.4938226674900537
Validation loss: 2.58275853357313

Epoch: 6| Step: 4
Training loss: 1.8257775518455808
Validation loss: 2.6067788153660545

Epoch: 6| Step: 5
Training loss: 2.2473081805189823
Validation loss: 2.6662369867085745

Epoch: 6| Step: 6
Training loss: 1.7734736636335502
Validation loss: 2.605168495343181

Epoch: 6| Step: 7
Training loss: 2.0652303252262523
Validation loss: 2.642443582199493

Epoch: 6| Step: 8
Training loss: 1.6353888377678871
Validation loss: 2.6382704696870594

Epoch: 6| Step: 9
Training loss: 1.9461568815266224
Validation loss: 2.6385863273351706

Epoch: 6| Step: 10
Training loss: 1.784029749190325
Validation loss: 2.598200174250121

Epoch: 6| Step: 11
Training loss: 1.68925900088209
Validation loss: 2.646943402486731

Epoch: 6| Step: 12
Training loss: 2.5671225931386923
Validation loss: 2.5959896080570934

Epoch: 6| Step: 13
Training loss: 1.9870392943184407
Validation loss: 2.6269930936108303

Epoch: 440| Step: 0
Training loss: 1.9473586141561847
Validation loss: 2.70625636697224

Epoch: 6| Step: 1
Training loss: 1.9837279578981224
Validation loss: 2.5992106630575478

Epoch: 6| Step: 2
Training loss: 2.721370442659661
Validation loss: 2.6363071770951545

Epoch: 6| Step: 3
Training loss: 1.986500720362193
Validation loss: 2.6296807038399095

Epoch: 6| Step: 4
Training loss: 1.3421363012565126
Validation loss: 2.590877078044142

Epoch: 6| Step: 5
Training loss: 1.2540598742535742
Validation loss: 2.6740635053437485

Epoch: 6| Step: 6
Training loss: 1.8316958512864174
Validation loss: 2.6826177279194976

Epoch: 6| Step: 7
Training loss: 1.5621545791285851
Validation loss: 2.6048067260402084

Epoch: 6| Step: 8
Training loss: 1.7730349449332887
Validation loss: 2.620683485508063

Epoch: 6| Step: 9
Training loss: 2.5060140750791144
Validation loss: 2.689046875781362

Epoch: 6| Step: 10
Training loss: 2.0063172944093233
Validation loss: 2.6616401546842616

Epoch: 6| Step: 11
Training loss: 1.6733759622095923
Validation loss: 2.623677736668513

Epoch: 6| Step: 12
Training loss: 1.791707711156258
Validation loss: 2.7031311797598283

Epoch: 6| Step: 13
Training loss: 2.0818295837414182
Validation loss: 2.6796548516657133

Epoch: 441| Step: 0
Training loss: 1.9015037985198775
Validation loss: 2.6558458979964996

Epoch: 6| Step: 1
Training loss: 2.049194070519814
Validation loss: 2.6960392102326907

Epoch: 6| Step: 2
Training loss: 2.16932385682465
Validation loss: 2.629816335348139

Epoch: 6| Step: 3
Training loss: 2.6409336789985653
Validation loss: 2.5946211851084677

Epoch: 6| Step: 4
Training loss: 2.1409851662247985
Validation loss: 2.632684006769816

Epoch: 6| Step: 5
Training loss: 2.006037658672612
Validation loss: 2.688429364368353

Epoch: 6| Step: 6
Training loss: 1.229398667806335
Validation loss: 2.6711748999356755

Epoch: 6| Step: 7
Training loss: 1.668957169492331
Validation loss: 2.613873484953286

Epoch: 6| Step: 8
Training loss: 1.419218411192013
Validation loss: 2.56831208161387

Epoch: 6| Step: 9
Training loss: 1.7069600175533928
Validation loss: 2.6232892354208865

Epoch: 6| Step: 10
Training loss: 1.7709971034297163
Validation loss: 2.675325430271967

Epoch: 6| Step: 11
Training loss: 2.224649778941965
Validation loss: 2.614579538080213

Epoch: 6| Step: 12
Training loss: 1.7236449849074438
Validation loss: 2.637305106500344

Epoch: 6| Step: 13
Training loss: 1.3274859517821478
Validation loss: 2.5999511273210465

Epoch: 442| Step: 0
Training loss: 1.845508835673465
Validation loss: 2.6517504024274965

Epoch: 6| Step: 1
Training loss: 1.7732380490171238
Validation loss: 2.6180045123427744

Epoch: 6| Step: 2
Training loss: 1.3659773348077098
Validation loss: 2.599187600936373

Epoch: 6| Step: 3
Training loss: 1.6836273119207696
Validation loss: 2.6346068014404316

Epoch: 6| Step: 4
Training loss: 2.0872882941248263
Validation loss: 2.6236456870287044

Epoch: 6| Step: 5
Training loss: 2.3266920762009
Validation loss: 2.630296413068136

Epoch: 6| Step: 6
Training loss: 2.301523396560585
Validation loss: 2.619775990798237

Epoch: 6| Step: 7
Training loss: 1.7177727435242345
Validation loss: 2.6245799268104433

Epoch: 6| Step: 8
Training loss: 2.1410162352401176
Validation loss: 2.5914023862832303

Epoch: 6| Step: 9
Training loss: 1.958094873181366
Validation loss: 2.6075620827319623

Epoch: 6| Step: 10
Training loss: 2.3511578284555594
Validation loss: 2.6033810053460447

Epoch: 6| Step: 11
Training loss: 1.504463944509871
Validation loss: 2.6479493567129104

Epoch: 6| Step: 12
Training loss: 1.0311786164517789
Validation loss: 2.6636020781095855

Epoch: 6| Step: 13
Training loss: 2.471271916833996
Validation loss: 2.535581219576388

Epoch: 443| Step: 0
Training loss: 1.4865582121361605
Validation loss: 2.60670929129935

Epoch: 6| Step: 1
Training loss: 1.9320457966986113
Validation loss: 2.639665168401221

Epoch: 6| Step: 2
Training loss: 2.735157794619628
Validation loss: 2.655511526378168

Epoch: 6| Step: 3
Training loss: 1.8045832616253614
Validation loss: 2.6491196296283546

Epoch: 6| Step: 4
Training loss: 1.8198432808776601
Validation loss: 2.6422086664384152

Epoch: 6| Step: 5
Training loss: 1.4930040611830178
Validation loss: 2.6662571400951296

Epoch: 6| Step: 6
Training loss: 1.904787284108655
Validation loss: 2.6586956879944132

Epoch: 6| Step: 7
Training loss: 1.7780140713112373
Validation loss: 2.682284539835791

Epoch: 6| Step: 8
Training loss: 1.8565325127057815
Validation loss: 2.688623623193309

Epoch: 6| Step: 9
Training loss: 1.601389880298147
Validation loss: 2.6326337205727532

Epoch: 6| Step: 10
Training loss: 2.118286860886906
Validation loss: 2.6811215696816233

Epoch: 6| Step: 11
Training loss: 1.5013189080501261
Validation loss: 2.6290771651155453

Epoch: 6| Step: 12
Training loss: 2.6906608800677763
Validation loss: 2.691599953948346

Epoch: 6| Step: 13
Training loss: 0.846553947149241
Validation loss: 2.6323346059413106

Epoch: 444| Step: 0
Training loss: 1.6227570239361562
Validation loss: 2.6386281309051625

Epoch: 6| Step: 1
Training loss: 1.3679542789096852
Validation loss: 2.6276449149943004

Epoch: 6| Step: 2
Training loss: 1.9741604650337496
Validation loss: 2.6288750423011416

Epoch: 6| Step: 3
Training loss: 1.848157173627499
Validation loss: 2.689939506350099

Epoch: 6| Step: 4
Training loss: 2.0048678286550405
Validation loss: 2.634825817332696

Epoch: 6| Step: 5
Training loss: 2.0645388149641684
Validation loss: 2.664156495330843

Epoch: 6| Step: 6
Training loss: 1.8306887655200084
Validation loss: 2.642816256590404

Epoch: 6| Step: 7
Training loss: 1.502876702180857
Validation loss: 2.577077028757568

Epoch: 6| Step: 8
Training loss: 1.9797318571762084
Validation loss: 2.625904273222907

Epoch: 6| Step: 9
Training loss: 2.528718318090189
Validation loss: 2.690547496362614

Epoch: 6| Step: 10
Training loss: 1.878020206517397
Validation loss: 2.6446321968346442

Epoch: 6| Step: 11
Training loss: 1.5375319097665632
Validation loss: 2.6549874545053296

Epoch: 6| Step: 12
Training loss: 2.1532554287985413
Validation loss: 2.644492025356056

Epoch: 6| Step: 13
Training loss: 2.257564544261977
Validation loss: 2.6313341435904296

Epoch: 445| Step: 0
Training loss: 1.8354786400899135
Validation loss: 2.678407058262673

Epoch: 6| Step: 1
Training loss: 1.7315339884934704
Validation loss: 2.6580767802414402

Epoch: 6| Step: 2
Training loss: 1.832876047266911
Validation loss: 2.6815317901706734

Epoch: 6| Step: 3
Training loss: 1.790063036868913
Validation loss: 2.6322861362515093

Epoch: 6| Step: 4
Training loss: 2.4258955530827278
Validation loss: 2.666872363335194

Epoch: 6| Step: 5
Training loss: 2.557512034278814
Validation loss: 2.629208944090721

Epoch: 6| Step: 6
Training loss: 2.823824822058087
Validation loss: 2.607032860973147

Epoch: 6| Step: 7
Training loss: 1.7084616946245859
Validation loss: 2.645909146892599

Epoch: 6| Step: 8
Training loss: 1.729754367214732
Validation loss: 2.606980717032091

Epoch: 6| Step: 9
Training loss: 1.8274211343637612
Validation loss: 2.5844625359669586

Epoch: 6| Step: 10
Training loss: 1.7846168020195985
Validation loss: 2.6483441238768433

Epoch: 6| Step: 11
Training loss: 0.9524453037807634
Validation loss: 2.5767095484346023

Epoch: 6| Step: 12
Training loss: 2.0396667988122474
Validation loss: 2.580781564196847

Epoch: 6| Step: 13
Training loss: 1.672025014261279
Validation loss: 2.5936180167156233

Epoch: 446| Step: 0
Training loss: 2.4798891847217197
Validation loss: 2.6125392963264256

Epoch: 6| Step: 1
Training loss: 1.6122730420690587
Validation loss: 2.685133740101987

Epoch: 6| Step: 2
Training loss: 2.765736033479111
Validation loss: 2.661002310994094

Epoch: 6| Step: 3
Training loss: 1.831113670924989
Validation loss: 2.635753859210404

Epoch: 6| Step: 4
Training loss: 1.496528104274131
Validation loss: 2.619172982296062

Epoch: 6| Step: 5
Training loss: 1.9487586692044658
Validation loss: 2.6153566551727723

Epoch: 6| Step: 6
Training loss: 1.571608886034188
Validation loss: 2.6619604681471523

Epoch: 6| Step: 7
Training loss: 1.6982471011914968
Validation loss: 2.603281312795417

Epoch: 6| Step: 8
Training loss: 1.41455078125
Validation loss: 2.6219186643312784

Epoch: 6| Step: 9
Training loss: 1.6791433473139978
Validation loss: 2.610065267956359

Epoch: 6| Step: 10
Training loss: 1.9221079615380885
Validation loss: 2.6108287485007136

Epoch: 6| Step: 11
Training loss: 1.8376619073031302
Validation loss: 2.60464533256286

Epoch: 6| Step: 12
Training loss: 2.10446658373346
Validation loss: 2.6064645197281857

Epoch: 6| Step: 13
Training loss: 1.7672876277387122
Validation loss: 2.5478454146288243

Epoch: 447| Step: 0
Training loss: 2.2969271076545765
Validation loss: 2.6283529346870846

Epoch: 6| Step: 1
Training loss: 1.7542438139755432
Validation loss: 2.6556597696315096

Epoch: 6| Step: 2
Training loss: 2.286327616112941
Validation loss: 2.5849729902361003

Epoch: 6| Step: 3
Training loss: 3.168584911853859
Validation loss: 2.609016004211283

Epoch: 6| Step: 4
Training loss: 1.7216670857540086
Validation loss: 2.635259713521882

Epoch: 6| Step: 5
Training loss: 2.0925168633550584
Validation loss: 2.6221767543027723

Epoch: 6| Step: 6
Training loss: 1.2995963441948208
Validation loss: 2.605847708933451

Epoch: 6| Step: 7
Training loss: 1.6143651835415984
Validation loss: 2.6571744078785304

Epoch: 6| Step: 8
Training loss: 1.540767209683749
Validation loss: 2.678467632808189

Epoch: 6| Step: 9
Training loss: 1.5511412695096711
Validation loss: 2.65541172010335

Epoch: 6| Step: 10
Training loss: 1.8025798297404974
Validation loss: 2.6468432053284277

Epoch: 6| Step: 11
Training loss: 1.5952129755163915
Validation loss: 2.6091383252615707

Epoch: 6| Step: 12
Training loss: 1.4510157874712193
Validation loss: 2.7498793384410694

Epoch: 6| Step: 13
Training loss: 1.5514007791404838
Validation loss: 2.6765309533172257

Epoch: 448| Step: 0
Training loss: 1.732664760004873
Validation loss: 2.6127366690581413

Epoch: 6| Step: 1
Training loss: 1.451148052199732
Validation loss: 2.5780548672849304

Epoch: 6| Step: 2
Training loss: 1.8579787453461245
Validation loss: 2.5417631027779004

Epoch: 6| Step: 3
Training loss: 2.0644300273660585
Validation loss: 2.680610646254113

Epoch: 6| Step: 4
Training loss: 2.2089933332806306
Validation loss: 2.6546361471069853

Epoch: 6| Step: 5
Training loss: 1.4412361189346632
Validation loss: 2.6310939847887553

Epoch: 6| Step: 6
Training loss: 2.1099983707078183
Validation loss: 2.628037716162346

Epoch: 6| Step: 7
Training loss: 2.3899548158404653
Validation loss: 2.599317032001924

Epoch: 6| Step: 8
Training loss: 1.5126918450371813
Validation loss: 2.663291192314363

Epoch: 6| Step: 9
Training loss: 1.8332332092456762
Validation loss: 2.628171314766241

Epoch: 6| Step: 10
Training loss: 2.194187405443924
Validation loss: 2.5619598677799518

Epoch: 6| Step: 11
Training loss: 1.7319850091263431
Validation loss: 2.6296599591448695

Epoch: 6| Step: 12
Training loss: 1.8528488776872098
Validation loss: 2.6343997992740373

Epoch: 6| Step: 13
Training loss: 2.0251820235212326
Validation loss: 2.6465012675631927

Epoch: 449| Step: 0
Training loss: 2.0074289155871132
Validation loss: 2.6675188397518594

Epoch: 6| Step: 1
Training loss: 1.5929877010189168
Validation loss: 2.5730485374597394

Epoch: 6| Step: 2
Training loss: 1.6122724505597632
Validation loss: 2.645836034076899

Epoch: 6| Step: 3
Training loss: 1.6134059756189965
Validation loss: 2.649335864625586

Epoch: 6| Step: 4
Training loss: 1.7405795216397708
Validation loss: 2.6181657643054903

Epoch: 6| Step: 5
Training loss: 1.8782233823375085
Validation loss: 2.6637230108494174

Epoch: 6| Step: 6
Training loss: 1.7951754950163241
Validation loss: 2.5911058157019022

Epoch: 6| Step: 7
Training loss: 2.159645834250267
Validation loss: 2.5470764253637594

Epoch: 6| Step: 8
Training loss: 1.7435036379243154
Validation loss: 2.6952658857440617

Epoch: 6| Step: 9
Training loss: 2.8884993702189674
Validation loss: 2.654405305359605

Epoch: 6| Step: 10
Training loss: 2.088040552563961
Validation loss: 2.632137573936048

Epoch: 6| Step: 11
Training loss: 1.8840810847034113
Validation loss: 2.6663799907296664

Epoch: 6| Step: 12
Training loss: 1.311316183363671
Validation loss: 2.5732743438637415

Epoch: 6| Step: 13
Training loss: 1.460393304497388
Validation loss: 2.635660490888667

Epoch: 450| Step: 0
Training loss: 2.3295287950008863
Validation loss: 2.6475955932839303

Epoch: 6| Step: 1
Training loss: 1.6571855601789072
Validation loss: 2.678052675414976

Epoch: 6| Step: 2
Training loss: 1.749115720494336
Validation loss: 2.7075851856928805

Epoch: 6| Step: 3
Training loss: 1.9416562078737278
Validation loss: 2.5979356189764116

Epoch: 6| Step: 4
Training loss: 2.1510475534230764
Validation loss: 2.614663723945714

Epoch: 6| Step: 5
Training loss: 1.7951548428280508
Validation loss: 2.7067466136001896

Epoch: 6| Step: 6
Training loss: 2.2267228988963215
Validation loss: 2.653758127735856

Epoch: 6| Step: 7
Training loss: 1.5064571000811027
Validation loss: 2.622536702269685

Epoch: 6| Step: 8
Training loss: 1.6519349225967932
Validation loss: 2.5809720802953793

Epoch: 6| Step: 9
Training loss: 1.429999812466269
Validation loss: 2.639828661805682

Epoch: 6| Step: 10
Training loss: 1.5532795266967951
Validation loss: 2.736089221471246

Epoch: 6| Step: 11
Training loss: 2.716489180713427
Validation loss: 2.6179842758916685

Epoch: 6| Step: 12
Training loss: 1.9390458123951426
Validation loss: 2.652259033818112

Epoch: 6| Step: 13
Training loss: 1.756335371121373
Validation loss: 2.66645016066915

Epoch: 451| Step: 0
Training loss: 1.9721133854285793
Validation loss: 2.617900825501354

Epoch: 6| Step: 1
Training loss: 1.7345158287815015
Validation loss: 2.553234946665642

Epoch: 6| Step: 2
Training loss: 1.9828086738759936
Validation loss: 2.6763294362334356

Epoch: 6| Step: 3
Training loss: 2.4813207890095934
Validation loss: 2.6316640130895173

Epoch: 6| Step: 4
Training loss: 1.4006264885652353
Validation loss: 2.6520026766036695

Epoch: 6| Step: 5
Training loss: 1.6051353238298622
Validation loss: 2.6711296716775976

Epoch: 6| Step: 6
Training loss: 1.6088029159462565
Validation loss: 2.676554314497544

Epoch: 6| Step: 7
Training loss: 1.8624342426750466
Validation loss: 2.7107265932119224

Epoch: 6| Step: 8
Training loss: 2.198249020390036
Validation loss: 2.6254257124541605

Epoch: 6| Step: 9
Training loss: 1.6441412891505325
Validation loss: 2.6764192880814925

Epoch: 6| Step: 10
Training loss: 1.9178888805408976
Validation loss: 2.6115645247177643

Epoch: 6| Step: 11
Training loss: 1.8893427638547866
Validation loss: 2.6709787290004434

Epoch: 6| Step: 12
Training loss: 2.7212132662325135
Validation loss: 2.6268775990993

Epoch: 6| Step: 13
Training loss: 1.894733158639205
Validation loss: 2.6650455672139706

Epoch: 452| Step: 0
Training loss: 1.8750942842302112
Validation loss: 2.608800822801657

Epoch: 6| Step: 1
Training loss: 1.5309035240089424
Validation loss: 2.576697418243127

Epoch: 6| Step: 2
Training loss: 2.255738675410058
Validation loss: 2.6077466962035176

Epoch: 6| Step: 3
Training loss: 2.039455916646301
Validation loss: 2.6184113463487555

Epoch: 6| Step: 4
Training loss: 1.9974176305371492
Validation loss: 2.6144851596195458

Epoch: 6| Step: 5
Training loss: 1.3431115075130862
Validation loss: 2.647881229269002

Epoch: 6| Step: 6
Training loss: 1.6403235748957845
Validation loss: 2.6742623096033173

Epoch: 6| Step: 7
Training loss: 1.8571315020958155
Validation loss: 2.6337297838455687

Epoch: 6| Step: 8
Training loss: 2.485288823802925
Validation loss: 2.6665592062996795

Epoch: 6| Step: 9
Training loss: 1.5067345120900018
Validation loss: 2.638651519667974

Epoch: 6| Step: 10
Training loss: 1.6582988805722354
Validation loss: 2.6551902968667878

Epoch: 6| Step: 11
Training loss: 2.156561898050527
Validation loss: 2.5707203182173157

Epoch: 6| Step: 12
Training loss: 2.1776327750963493
Validation loss: 2.6312022225996627

Epoch: 6| Step: 13
Training loss: 0.7334138789881577
Validation loss: 2.65277910940308

Epoch: 453| Step: 0
Training loss: 1.0777743225326297
Validation loss: 2.5959144552615165

Epoch: 6| Step: 1
Training loss: 1.83549539640385
Validation loss: 2.5844257941211013

Epoch: 6| Step: 2
Training loss: 1.7889009094558392
Validation loss: 2.5401749912938554

Epoch: 6| Step: 3
Training loss: 1.5562182993896534
Validation loss: 2.614174319644708

Epoch: 6| Step: 4
Training loss: 2.0797170406223957
Validation loss: 2.655158634364587

Epoch: 6| Step: 5
Training loss: 1.4149847237399273
Validation loss: 2.623980021727337

Epoch: 6| Step: 6
Training loss: 2.060106796348097
Validation loss: 2.6283579988507215

Epoch: 6| Step: 7
Training loss: 1.530952113234231
Validation loss: 2.67401260811835

Epoch: 6| Step: 8
Training loss: 1.6193525039953607
Validation loss: 2.6183794251285706

Epoch: 6| Step: 9
Training loss: 2.028490745352192
Validation loss: 2.6675582543761984

Epoch: 6| Step: 10
Training loss: 2.6992245796902496
Validation loss: 2.6875137363091377

Epoch: 6| Step: 11
Training loss: 1.8016113221698664
Validation loss: 2.647082142523096

Epoch: 6| Step: 12
Training loss: 2.115790550257131
Validation loss: 2.71460791184865

Epoch: 6| Step: 13
Training loss: 2.532974409309208
Validation loss: 2.603572463304209

Epoch: 454| Step: 0
Training loss: 2.3740911250505836
Validation loss: 2.6516793098235176

Epoch: 6| Step: 1
Training loss: 1.580977628266093
Validation loss: 2.54467922880365

Epoch: 6| Step: 2
Training loss: 2.08018701116121
Validation loss: 2.6632107470187494

Epoch: 6| Step: 3
Training loss: 2.2847933489219177
Validation loss: 2.6521585329037545

Epoch: 6| Step: 4
Training loss: 1.4550164331248814
Validation loss: 2.655627672521941

Epoch: 6| Step: 5
Training loss: 2.1573232661029254
Validation loss: 2.626441480675678

Epoch: 6| Step: 6
Training loss: 1.5804996564768798
Validation loss: 2.539690776425278

Epoch: 6| Step: 7
Training loss: 1.629363364063618
Validation loss: 2.6097698447154607

Epoch: 6| Step: 8
Training loss: 1.4554551013873773
Validation loss: 2.6670132421102366

Epoch: 6| Step: 9
Training loss: 1.5595494449869978
Validation loss: 2.5760325343193964

Epoch: 6| Step: 10
Training loss: 1.9327866227954917
Validation loss: 2.6332526175194095

Epoch: 6| Step: 11
Training loss: 1.9311054904042866
Validation loss: 2.673015917710153

Epoch: 6| Step: 12
Training loss: 1.735512025677717
Validation loss: 2.633417046902342

Epoch: 6| Step: 13
Training loss: 2.504023747060376
Validation loss: 2.555042436994343

Epoch: 455| Step: 0
Training loss: 1.7545896018786011
Validation loss: 2.613876599915756

Epoch: 6| Step: 1
Training loss: 1.5369043080132694
Validation loss: 2.5658778495747474

Epoch: 6| Step: 2
Training loss: 1.2904117805274309
Validation loss: 2.6536378489720014

Epoch: 6| Step: 3
Training loss: 2.149259208983389
Validation loss: 2.6289574519796775

Epoch: 6| Step: 4
Training loss: 2.0291261573627937
Validation loss: 2.6042415727896793

Epoch: 6| Step: 5
Training loss: 2.5127237780159866
Validation loss: 2.6640449167052096

Epoch: 6| Step: 6
Training loss: 1.7236945035879236
Validation loss: 2.661429482336496

Epoch: 6| Step: 7
Training loss: 1.3027894610378377
Validation loss: 2.6200206640769244

Epoch: 6| Step: 8
Training loss: 1.901586675686148
Validation loss: 2.603772504612369

Epoch: 6| Step: 9
Training loss: 1.816271180083875
Validation loss: 2.5959511707847645

Epoch: 6| Step: 10
Training loss: 1.6182005284769745
Validation loss: 2.5853610527515136

Epoch: 6| Step: 11
Training loss: 2.074650893660523
Validation loss: 2.688018489348737

Epoch: 6| Step: 12
Training loss: 2.5765819208767677
Validation loss: 2.617343534159809

Epoch: 6| Step: 13
Training loss: 1.7812239661740266
Validation loss: 2.6292260417399893

Epoch: 456| Step: 0
Training loss: 2.120404041762675
Validation loss: 2.6510066785936632

Epoch: 6| Step: 1
Training loss: 1.8017433889581893
Validation loss: 2.639905303956179

Epoch: 6| Step: 2
Training loss: 1.857045357104534
Validation loss: 2.664271763284852

Epoch: 6| Step: 3
Training loss: 2.2701575880764153
Validation loss: 2.6088210513823222

Epoch: 6| Step: 4
Training loss: 1.3826200706946559
Validation loss: 2.6221057838039945

Epoch: 6| Step: 5
Training loss: 1.8043501897889327
Validation loss: 2.6031694608823206

Epoch: 6| Step: 6
Training loss: 1.7526624045442918
Validation loss: 2.701456240894754

Epoch: 6| Step: 7
Training loss: 1.6735527675619342
Validation loss: 2.611624999507836

Epoch: 6| Step: 8
Training loss: 1.8215384223146396
Validation loss: 2.6815947864597307

Epoch: 6| Step: 9
Training loss: 2.321275812928899
Validation loss: 2.6324365502676565

Epoch: 6| Step: 10
Training loss: 2.038104888433096
Validation loss: 2.639926274040192

Epoch: 6| Step: 11
Training loss: 1.5817368975296087
Validation loss: 2.6170904394698002

Epoch: 6| Step: 12
Training loss: 2.4275868647990784
Validation loss: 2.6828585468405874

Epoch: 6| Step: 13
Training loss: 1.36028180624723
Validation loss: 2.664773032838399

Epoch: 457| Step: 0
Training loss: 1.802530361877467
Validation loss: 2.679803287593961

Epoch: 6| Step: 1
Training loss: 2.089991370005335
Validation loss: 2.6653723110242025

Epoch: 6| Step: 2
Training loss: 1.9173124787151903
Validation loss: 2.6741392305383673

Epoch: 6| Step: 3
Training loss: 1.50727107155453
Validation loss: 2.7381271546682653

Epoch: 6| Step: 4
Training loss: 1.5829270075719408
Validation loss: 2.6621795679470486

Epoch: 6| Step: 5
Training loss: 1.737344896817217
Validation loss: 2.674171478381991

Epoch: 6| Step: 6
Training loss: 1.7139361158459347
Validation loss: 2.6619611490339343

Epoch: 6| Step: 7
Training loss: 1.1913473145963656
Validation loss: 2.697917511737511

Epoch: 6| Step: 8
Training loss: 1.72052243482335
Validation loss: 2.6167074302861666

Epoch: 6| Step: 9
Training loss: 2.1682566408653607
Validation loss: 2.7388865839090903

Epoch: 6| Step: 10
Training loss: 2.9868840560248975
Validation loss: 2.67918918835992

Epoch: 6| Step: 11
Training loss: 1.898310276368168
Validation loss: 2.6583757728935655

Epoch: 6| Step: 12
Training loss: 1.5762847141493934
Validation loss: 2.669092475860935

Epoch: 6| Step: 13
Training loss: 2.1528120414167478
Validation loss: 2.5966137731275327

Epoch: 458| Step: 0
Training loss: 1.4707381407684161
Validation loss: 2.6284024629979843

Epoch: 6| Step: 1
Training loss: 2.1324782336645836
Validation loss: 2.642473415004657

Epoch: 6| Step: 2
Training loss: 1.8596659200342849
Validation loss: 2.6603903008014056

Epoch: 6| Step: 3
Training loss: 1.5303368473122037
Validation loss: 2.6823253947661367

Epoch: 6| Step: 4
Training loss: 2.3206675864662305
Validation loss: 2.6759340380808223

Epoch: 6| Step: 5
Training loss: 1.5525888050867378
Validation loss: 2.602816376778349

Epoch: 6| Step: 6
Training loss: 2.0187365741106134
Validation loss: 2.5934759509942964

Epoch: 6| Step: 7
Training loss: 1.9868911650348957
Validation loss: 2.68336897347206

Epoch: 6| Step: 8
Training loss: 2.0439441460370538
Validation loss: 2.692917577624793

Epoch: 6| Step: 9
Training loss: 2.013987977962733
Validation loss: 2.698612482751478

Epoch: 6| Step: 10
Training loss: 1.9388758173735425
Validation loss: 2.665214978542954

Epoch: 6| Step: 11
Training loss: 1.9090939553760813
Validation loss: 2.65317861244675

Epoch: 6| Step: 12
Training loss: 1.5484127531566587
Validation loss: 2.687614695073076

Epoch: 6| Step: 13
Training loss: 1.4897138453931364
Validation loss: 2.6221216733846613

Epoch: 459| Step: 0
Training loss: 2.4773233009247475
Validation loss: 2.620347149170942

Epoch: 6| Step: 1
Training loss: 1.672981680259569
Validation loss: 2.644328167813396

Epoch: 6| Step: 2
Training loss: 2.133761575552365
Validation loss: 2.598037826660451

Epoch: 6| Step: 3
Training loss: 1.7666564224354013
Validation loss: 2.66831471164481

Epoch: 6| Step: 4
Training loss: 1.4882876578766253
Validation loss: 2.5975144574504023

Epoch: 6| Step: 5
Training loss: 1.6057635034417725
Validation loss: 2.6328010596565394

Epoch: 6| Step: 6
Training loss: 1.4384770597313294
Validation loss: 2.6856120795633838

Epoch: 6| Step: 7
Training loss: 2.4983805179360377
Validation loss: 2.644152174453602

Epoch: 6| Step: 8
Training loss: 1.5284158597579054
Validation loss: 2.609715216100676

Epoch: 6| Step: 9
Training loss: 1.5643759338156655
Validation loss: 2.588490539099999

Epoch: 6| Step: 10
Training loss: 1.565774842665897
Validation loss: 2.6237283938434297

Epoch: 6| Step: 11
Training loss: 1.8280232719091958
Validation loss: 2.664441753006539

Epoch: 6| Step: 12
Training loss: 2.3748869618067854
Validation loss: 2.6385239199970854

Epoch: 6| Step: 13
Training loss: 1.8135587954018122
Validation loss: 2.6705645566902163

Epoch: 460| Step: 0
Training loss: 1.7029711452599938
Validation loss: 2.681110462646552

Epoch: 6| Step: 1
Training loss: 1.5292637457249314
Validation loss: 2.6269730293583278

Epoch: 6| Step: 2
Training loss: 1.7395276348159026
Validation loss: 2.590669321853968

Epoch: 6| Step: 3
Training loss: 1.738294691398172
Validation loss: 2.648483755598487

Epoch: 6| Step: 4
Training loss: 1.5451192428349527
Validation loss: 2.5994642362371434

Epoch: 6| Step: 5
Training loss: 1.8340180447771268
Validation loss: 2.6552495299226084

Epoch: 6| Step: 6
Training loss: 1.9542528481854935
Validation loss: 2.617464399436409

Epoch: 6| Step: 7
Training loss: 1.6114718656294345
Validation loss: 2.6172889607769454

Epoch: 6| Step: 8
Training loss: 1.2682553026873156
Validation loss: 2.596094545766275

Epoch: 6| Step: 9
Training loss: 2.7886907933549003
Validation loss: 2.6479854117419395

Epoch: 6| Step: 10
Training loss: 1.6117198860878206
Validation loss: 2.659254937073955

Epoch: 6| Step: 11
Training loss: 2.3617775917609887
Validation loss: 2.635354519231706

Epoch: 6| Step: 12
Training loss: 1.5509603478622105
Validation loss: 2.7094362258261944

Epoch: 6| Step: 13
Training loss: 2.2748192851634097
Validation loss: 2.6244015292220864

Epoch: 461| Step: 0
Training loss: 1.4007377247555899
Validation loss: 2.677757695045211

Epoch: 6| Step: 1
Training loss: 2.4136929028483003
Validation loss: 2.641140357372655

Epoch: 6| Step: 2
Training loss: 1.8082719355881982
Validation loss: 2.6703647119922147

Epoch: 6| Step: 3
Training loss: 1.778801422984277
Validation loss: 2.5612893995355335

Epoch: 6| Step: 4
Training loss: 2.0269599801221645
Validation loss: 2.546384934239193

Epoch: 6| Step: 5
Training loss: 1.8466419879811307
Validation loss: 2.6063760146184887

Epoch: 6| Step: 6
Training loss: 1.6435335807328988
Validation loss: 2.5786677609885342

Epoch: 6| Step: 7
Training loss: 2.0747912060582316
Validation loss: 2.6202065121377864

Epoch: 6| Step: 8
Training loss: 1.9427324213438535
Validation loss: 2.599054579929904

Epoch: 6| Step: 9
Training loss: 1.8706896510806919
Validation loss: 2.6115784621381395

Epoch: 6| Step: 10
Training loss: 1.971157600012778
Validation loss: 2.640393948893878

Epoch: 6| Step: 11
Training loss: 1.6710473980211051
Validation loss: 2.62034105594301

Epoch: 6| Step: 12
Training loss: 1.5766642391167327
Validation loss: 2.6405190727344965

Epoch: 6| Step: 13
Training loss: 2.400236567123232
Validation loss: 2.5498277257336457

Epoch: 462| Step: 0
Training loss: 1.8832490660233272
Validation loss: 2.6885258213764125

Epoch: 6| Step: 1
Training loss: 2.025531171669492
Validation loss: 2.6268248477662994

Epoch: 6| Step: 2
Training loss: 1.8121634861538614
Validation loss: 2.6400084280856486

Epoch: 6| Step: 3
Training loss: 1.7310696284120535
Validation loss: 2.5802779663728463

Epoch: 6| Step: 4
Training loss: 1.6397715937499313
Validation loss: 2.704119704445301

Epoch: 6| Step: 5
Training loss: 1.673757758603336
Validation loss: 2.606855888307165

Epoch: 6| Step: 6
Training loss: 2.134982615451477
Validation loss: 2.694749738388929

Epoch: 6| Step: 7
Training loss: 1.6877535170398537
Validation loss: 2.644207836280862

Epoch: 6| Step: 8
Training loss: 1.5067199543725904
Validation loss: 2.6483108635913224

Epoch: 6| Step: 9
Training loss: 2.1943875465045255
Validation loss: 2.6744665801450487

Epoch: 6| Step: 10
Training loss: 1.9839894678659222
Validation loss: 2.626324479161762

Epoch: 6| Step: 11
Training loss: 1.7384350655041698
Validation loss: 2.59728984742165

Epoch: 6| Step: 12
Training loss: 2.6443315484108916
Validation loss: 2.602782698209183

Epoch: 6| Step: 13
Training loss: 1.8559931285130795
Validation loss: 2.6233995044048997

Epoch: 463| Step: 0
Training loss: 2.4303805721207117
Validation loss: 2.55518682619538

Epoch: 6| Step: 1
Training loss: 1.5569328311453394
Validation loss: 2.611018682903028

Epoch: 6| Step: 2
Training loss: 1.58992202903496
Validation loss: 2.65186458262549

Epoch: 6| Step: 3
Training loss: 1.3995588697540473
Validation loss: 2.70858092552795

Epoch: 6| Step: 4
Training loss: 1.7661250258802192
Validation loss: 2.635268041844395

Epoch: 6| Step: 5
Training loss: 1.6563298188175637
Validation loss: 2.61145872138853

Epoch: 6| Step: 6
Training loss: 2.3617498306818674
Validation loss: 2.6029181899202745

Epoch: 6| Step: 7
Training loss: 2.108048990045913
Validation loss: 2.6890160266502945

Epoch: 6| Step: 8
Training loss: 2.1518627259244827
Validation loss: 2.6010306963823395

Epoch: 6| Step: 9
Training loss: 1.4844312155267994
Validation loss: 2.7334662389620044

Epoch: 6| Step: 10
Training loss: 1.3061031039930167
Validation loss: 2.663846776167904

Epoch: 6| Step: 11
Training loss: 1.4675793141859534
Validation loss: 2.6956197888356024

Epoch: 6| Step: 12
Training loss: 1.8414476534850273
Validation loss: 2.70268662398998

Epoch: 6| Step: 13
Training loss: 1.963317156705075
Validation loss: 2.5951702700888446

Epoch: 464| Step: 0
Training loss: 1.4127703500799853
Validation loss: 2.6394115217227943

Epoch: 6| Step: 1
Training loss: 1.4786155999472028
Validation loss: 2.6401955190426754

Epoch: 6| Step: 2
Training loss: 1.5779943128804852
Validation loss: 2.6551091967346996

Epoch: 6| Step: 3
Training loss: 1.9693884041540983
Validation loss: 2.6471528932485704

Epoch: 6| Step: 4
Training loss: 1.3816844843707594
Validation loss: 2.6469926352479485

Epoch: 6| Step: 5
Training loss: 1.7040254504850798
Validation loss: 2.6357277067261182

Epoch: 6| Step: 6
Training loss: 2.4808157129999953
Validation loss: 2.61681953528632

Epoch: 6| Step: 7
Training loss: 1.9771174680806707
Validation loss: 2.723537871818298

Epoch: 6| Step: 8
Training loss: 1.2663421953535021
Validation loss: 2.6194026402691355

Epoch: 6| Step: 9
Training loss: 2.1326618071478167
Validation loss: 2.661307307717721

Epoch: 6| Step: 10
Training loss: 1.74782045059401
Validation loss: 2.7004049855004477

Epoch: 6| Step: 11
Training loss: 1.6210431562135046
Validation loss: 2.620493550659265

Epoch: 6| Step: 12
Training loss: 1.9524643047552455
Validation loss: 2.6418451707405826

Epoch: 6| Step: 13
Training loss: 1.9791831634904753
Validation loss: 2.62001885339707

Epoch: 465| Step: 0
Training loss: 1.8932792380601582
Validation loss: 2.594013164684549

Epoch: 6| Step: 1
Training loss: 1.4678273651104512
Validation loss: 2.5855509349446684

Epoch: 6| Step: 2
Training loss: 1.6869863505464209
Validation loss: 2.5888774475195633

Epoch: 6| Step: 3
Training loss: 1.8652062538783307
Validation loss: 2.6534497570824027

Epoch: 6| Step: 4
Training loss: 2.274064754198222
Validation loss: 2.6339267687702117

Epoch: 6| Step: 5
Training loss: 1.9361123684161916
Validation loss: 2.6849544075513383

Epoch: 6| Step: 6
Training loss: 1.6148270781920144
Validation loss: 2.6624581643684206

Epoch: 6| Step: 7
Training loss: 1.786207828437685
Validation loss: 2.6314918027178087

Epoch: 6| Step: 8
Training loss: 1.779278785454491
Validation loss: 2.6245100840634756

Epoch: 6| Step: 9
Training loss: 1.7865441601065288
Validation loss: 2.6387762189932893

Epoch: 6| Step: 10
Training loss: 1.728382790844028
Validation loss: 2.6274468131831217

Epoch: 6| Step: 11
Training loss: 1.8399781261056118
Validation loss: 2.7087896664646083

Epoch: 6| Step: 12
Training loss: 1.8441080295338081
Validation loss: 2.635193032487615

Epoch: 6| Step: 13
Training loss: 2.246557463171875
Validation loss: 2.617762906878725

Epoch: 466| Step: 0
Training loss: 1.6042927614005575
Validation loss: 2.5620000358001267

Epoch: 6| Step: 1
Training loss: 1.978093636069762
Validation loss: 2.6551431336685587

Epoch: 6| Step: 2
Training loss: 1.2843118693854068
Validation loss: 2.6849003108833793

Epoch: 6| Step: 3
Training loss: 1.928214866485278
Validation loss: 2.6003123259867844

Epoch: 6| Step: 4
Training loss: 1.9638220859168702
Validation loss: 2.601744292445623

Epoch: 6| Step: 5
Training loss: 2.3923931688714735
Validation loss: 2.6451415854194553

Epoch: 6| Step: 6
Training loss: 1.6745030078604637
Validation loss: 2.671815295950525

Epoch: 6| Step: 7
Training loss: 2.250517891515039
Validation loss: 2.6748655678941304

Epoch: 6| Step: 8
Training loss: 1.8130456826482295
Validation loss: 2.629975266406781

Epoch: 6| Step: 9
Training loss: 1.9654222853888053
Validation loss: 2.5752472508805293

Epoch: 6| Step: 10
Training loss: 1.054457349744028
Validation loss: 2.6384363688486596

Epoch: 6| Step: 11
Training loss: 1.6425958330830552
Validation loss: 2.6084441824451448

Epoch: 6| Step: 12
Training loss: 2.6749248387125255
Validation loss: 2.6955279339829485

Epoch: 6| Step: 13
Training loss: 1.8195729206271494
Validation loss: 2.639640068610393

Epoch: 467| Step: 0
Training loss: 1.9290027716316653
Validation loss: 2.6309036409628703

Epoch: 6| Step: 1
Training loss: 2.816814842690536
Validation loss: 2.6403990957946917

Epoch: 6| Step: 2
Training loss: 1.6701974027996953
Validation loss: 2.6550352828548034

Epoch: 6| Step: 3
Training loss: 1.409994522922781
Validation loss: 2.6724923392210913

Epoch: 6| Step: 4
Training loss: 1.9585847760829143
Validation loss: 2.687668681783177

Epoch: 6| Step: 5
Training loss: 1.824595377759547
Validation loss: 2.6670459187937734

Epoch: 6| Step: 6
Training loss: 1.533388007612838
Validation loss: 2.6486414711846833

Epoch: 6| Step: 7
Training loss: 1.5011006132151412
Validation loss: 2.6331966325982896

Epoch: 6| Step: 8
Training loss: 1.867166239725164
Validation loss: 2.697342757454252

Epoch: 6| Step: 9
Training loss: 2.0714522769116503
Validation loss: 2.6977175313917288

Epoch: 6| Step: 10
Training loss: 2.214182490918122
Validation loss: 2.6306206590263295

Epoch: 6| Step: 11
Training loss: 1.4924757114906924
Validation loss: 2.644726280770855

Epoch: 6| Step: 12
Training loss: 1.5636534438904075
Validation loss: 2.6604376465741275

Epoch: 6| Step: 13
Training loss: 0.7418015932371999
Validation loss: 2.5891614886464382

Epoch: 468| Step: 0
Training loss: 1.196716082906534
Validation loss: 2.571995985980506

Epoch: 6| Step: 1
Training loss: 1.5945119345437544
Validation loss: 2.6729639311404556

Epoch: 6| Step: 2
Training loss: 1.76672133445129
Validation loss: 2.5872533380145164

Epoch: 6| Step: 3
Training loss: 1.4889085303777614
Validation loss: 2.6276306178981206

Epoch: 6| Step: 4
Training loss: 1.5821974678787918
Validation loss: 2.6911405091068006

Epoch: 6| Step: 5
Training loss: 1.3703129384508812
Validation loss: 2.6122628709376694

Epoch: 6| Step: 6
Training loss: 2.006135707939075
Validation loss: 2.646557435032756

Epoch: 6| Step: 7
Training loss: 2.1017673775453756
Validation loss: 2.556522367370475

Epoch: 6| Step: 8
Training loss: 1.351146964874433
Validation loss: 2.6407992795802353

Epoch: 6| Step: 9
Training loss: 1.7875652461381795
Validation loss: 2.6168791088298673

Epoch: 6| Step: 10
Training loss: 2.5210803097466252
Validation loss: 2.616973007147767

Epoch: 6| Step: 11
Training loss: 1.6973775776242976
Validation loss: 2.6658449422668054

Epoch: 6| Step: 12
Training loss: 2.4127191552746052
Validation loss: 2.682939572590289

Epoch: 6| Step: 13
Training loss: 2.160697000157416
Validation loss: 2.651647117641789

Epoch: 469| Step: 0
Training loss: 1.6959914856193155
Validation loss: 2.5807350259370017

Epoch: 6| Step: 1
Training loss: 2.003012772152308
Validation loss: 2.662327693162824

Epoch: 6| Step: 2
Training loss: 1.5355120142296204
Validation loss: 2.6070922559644645

Epoch: 6| Step: 3
Training loss: 0.7678560719530109
Validation loss: 2.691758338583481

Epoch: 6| Step: 4
Training loss: 1.8319651382327655
Validation loss: 2.5830308275282796

Epoch: 6| Step: 5
Training loss: 2.3679057123898652
Validation loss: 2.6790048330060134

Epoch: 6| Step: 6
Training loss: 2.2112898798527656
Validation loss: 2.684804315163906

Epoch: 6| Step: 7
Training loss: 2.0067661987958734
Validation loss: 2.6955802519355827

Epoch: 6| Step: 8
Training loss: 2.414237303099318
Validation loss: 2.6670324077312926

Epoch: 6| Step: 9
Training loss: 1.6873866149109225
Validation loss: 2.6418848771777292

Epoch: 6| Step: 10
Training loss: 1.3956652392998183
Validation loss: 2.7088674966676773

Epoch: 6| Step: 11
Training loss: 1.7228940769299879
Validation loss: 2.686936289072271

Epoch: 6| Step: 12
Training loss: 1.5779655300431998
Validation loss: 2.629617706884313

Epoch: 6| Step: 13
Training loss: 1.927955684306889
Validation loss: 2.6438960943983534

Epoch: 470| Step: 0
Training loss: 1.8270091376324065
Validation loss: 2.5449863131941397

Epoch: 6| Step: 1
Training loss: 1.4545800092504906
Validation loss: 2.675314119020748

Epoch: 6| Step: 2
Training loss: 1.4218344211027931
Validation loss: 2.607846742016875

Epoch: 6| Step: 3
Training loss: 2.2912251018164067
Validation loss: 2.599781361699787

Epoch: 6| Step: 4
Training loss: 1.486860743771389
Validation loss: 2.580233106608038

Epoch: 6| Step: 5
Training loss: 1.6537848787096912
Validation loss: 2.6185304842672052

Epoch: 6| Step: 6
Training loss: 1.8725509543928265
Validation loss: 2.731285875583748

Epoch: 6| Step: 7
Training loss: 2.174097035956061
Validation loss: 2.6406018092959944

Epoch: 6| Step: 8
Training loss: 1.9815740567002535
Validation loss: 2.644920087512378

Epoch: 6| Step: 9
Training loss: 2.022300135447157
Validation loss: 2.631203834129281

Epoch: 6| Step: 10
Training loss: 2.4588532840851345
Validation loss: 2.682194347310605

Epoch: 6| Step: 11
Training loss: 1.656625525170294
Validation loss: 2.663918579552132

Epoch: 6| Step: 12
Training loss: 1.837440038208717
Validation loss: 2.6641638557318434

Epoch: 6| Step: 13
Training loss: 1.7132531090272187
Validation loss: 2.648337081547921

Epoch: 471| Step: 0
Training loss: 1.9848719898140752
Validation loss: 2.636191563074284

Epoch: 6| Step: 1
Training loss: 1.9462795075499277
Validation loss: 2.627256061680306

Epoch: 6| Step: 2
Training loss: 1.7650244037356737
Validation loss: 2.6152331967129725

Epoch: 6| Step: 3
Training loss: 1.450240276423097
Validation loss: 2.624284182766902

Epoch: 6| Step: 4
Training loss: 1.637852533262788
Validation loss: 2.639718372098288

Epoch: 6| Step: 5
Training loss: 1.77194204590449
Validation loss: 2.6552924807615557

Epoch: 6| Step: 6
Training loss: 1.781819570395755
Validation loss: 2.6434412927443742

Epoch: 6| Step: 7
Training loss: 1.6656532385402343
Validation loss: 2.6530459088322442

Epoch: 6| Step: 8
Training loss: 1.2299619569555236
Validation loss: 2.7016429054297513

Epoch: 6| Step: 9
Training loss: 1.9398754693401976
Validation loss: 2.6519669381657907

Epoch: 6| Step: 10
Training loss: 2.5636202526693066
Validation loss: 2.5586219553710627

Epoch: 6| Step: 11
Training loss: 1.9518417415173401
Validation loss: 2.5749006904720813

Epoch: 6| Step: 12
Training loss: 2.216512061824804
Validation loss: 2.634103764063319

Epoch: 6| Step: 13
Training loss: 2.1420488286227513
Validation loss: 2.6897037196417783

Epoch: 472| Step: 0
Training loss: 2.019281427216079
Validation loss: 2.6164438448950245

Epoch: 6| Step: 1
Training loss: 1.2103932295788282
Validation loss: 2.5903918660802026

Epoch: 6| Step: 2
Training loss: 1.9645985019889773
Validation loss: 2.63191436992248

Epoch: 6| Step: 3
Training loss: 1.4377997541950869
Validation loss: 2.6237966579303023

Epoch: 6| Step: 4
Training loss: 2.7033463756781315
Validation loss: 2.6813699857747406

Epoch: 6| Step: 5
Training loss: 1.688724497412654
Validation loss: 2.70225125256879

Epoch: 6| Step: 6
Training loss: 1.4719519107105565
Validation loss: 2.6760019715378505

Epoch: 6| Step: 7
Training loss: 1.6896020724397651
Validation loss: 2.577882446433892

Epoch: 6| Step: 8
Training loss: 1.768097285959972
Validation loss: 2.65419205358383

Epoch: 6| Step: 9
Training loss: 1.7064157594084508
Validation loss: 2.6129339748808005

Epoch: 6| Step: 10
Training loss: 1.7948121544776878
Validation loss: 2.625747031364206

Epoch: 6| Step: 11
Training loss: 1.9726291767944184
Validation loss: 2.649548088789997

Epoch: 6| Step: 12
Training loss: 1.8551487696954756
Validation loss: 2.6569204006824614

Epoch: 6| Step: 13
Training loss: 1.7094817217161797
Validation loss: 2.645457115455702

Epoch: 473| Step: 0
Training loss: 1.8487243146059948
Validation loss: 2.664556595868128

Epoch: 6| Step: 1
Training loss: 1.3466158181605754
Validation loss: 2.717142629711408

Epoch: 6| Step: 2
Training loss: 1.1225002915821674
Validation loss: 2.607591014889929

Epoch: 6| Step: 3
Training loss: 1.4573185614430249
Validation loss: 2.6190422625514214

Epoch: 6| Step: 4
Training loss: 1.8729034146132497
Validation loss: 2.6183359647256053

Epoch: 6| Step: 5
Training loss: 1.7036658312017345
Validation loss: 2.6472937033994475

Epoch: 6| Step: 6
Training loss: 1.9265213911708943
Validation loss: 2.647419207554649

Epoch: 6| Step: 7
Training loss: 2.270660697137703
Validation loss: 2.6054584952942843

Epoch: 6| Step: 8
Training loss: 1.7447655595183196
Validation loss: 2.7547462678092263

Epoch: 6| Step: 9
Training loss: 1.9136624910864664
Validation loss: 2.68684622311933

Epoch: 6| Step: 10
Training loss: 2.033190812395176
Validation loss: 2.6494865743958624

Epoch: 6| Step: 11
Training loss: 2.223493636194022
Validation loss: 2.6577926894762016

Epoch: 6| Step: 12
Training loss: 1.6582778176962545
Validation loss: 2.6295232354320563

Epoch: 6| Step: 13
Training loss: 2.181759304278132
Validation loss: 2.65804197125447

Epoch: 474| Step: 0
Training loss: 1.820117727181954
Validation loss: 2.590915192824557

Epoch: 6| Step: 1
Training loss: 1.3743517387888466
Validation loss: 2.631608246195999

Epoch: 6| Step: 2
Training loss: 2.702199700368684
Validation loss: 2.6654594616865035

Epoch: 6| Step: 3
Training loss: 1.6673606460883457
Validation loss: 2.6716659340330238

Epoch: 6| Step: 4
Training loss: 1.9318011981809136
Validation loss: 2.6577523004809462

Epoch: 6| Step: 5
Training loss: 1.9305581047840197
Validation loss: 2.6180510760033857

Epoch: 6| Step: 6
Training loss: 1.6638747991447564
Validation loss: 2.617501913551209

Epoch: 6| Step: 7
Training loss: 1.6300691620365257
Validation loss: 2.6608242212808437

Epoch: 6| Step: 8
Training loss: 2.000666149780417
Validation loss: 2.6285378532401285

Epoch: 6| Step: 9
Training loss: 1.7584662006070426
Validation loss: 2.6015470514710595

Epoch: 6| Step: 10
Training loss: 1.6922395340658831
Validation loss: 2.556552039587371

Epoch: 6| Step: 11
Training loss: 1.419213371396858
Validation loss: 2.6475094992736325

Epoch: 6| Step: 12
Training loss: 1.5888625357664696
Validation loss: 2.645341098903301

Epoch: 6| Step: 13
Training loss: 1.4496876248595836
Validation loss: 2.6597356781376895

Epoch: 475| Step: 0
Training loss: 2.04380206587146
Validation loss: 2.641579911811219

Epoch: 6| Step: 1
Training loss: 1.6080498285733955
Validation loss: 2.6424419697631616

Epoch: 6| Step: 2
Training loss: 1.9580547526909258
Validation loss: 2.657517749168091

Epoch: 6| Step: 3
Training loss: 1.812180721180159
Validation loss: 2.5837986084179714

Epoch: 6| Step: 4
Training loss: 1.650110489584905
Validation loss: 2.6177509375413193

Epoch: 6| Step: 5
Training loss: 2.6860473610344653
Validation loss: 2.5925582893808765

Epoch: 6| Step: 6
Training loss: 1.4868257869931905
Validation loss: 2.6632242755440534

Epoch: 6| Step: 7
Training loss: 1.30220540301011
Validation loss: 2.663476222385082

Epoch: 6| Step: 8
Training loss: 1.6761575912048332
Validation loss: 2.6275372741146605

Epoch: 6| Step: 9
Training loss: 1.764807858045139
Validation loss: 2.6173057748599344

Epoch: 6| Step: 10
Training loss: 2.0357709604276
Validation loss: 2.690605929123467

Epoch: 6| Step: 11
Training loss: 1.264715173794161
Validation loss: 2.6130989847820127

Epoch: 6| Step: 12
Training loss: 1.8486197864619651
Validation loss: 2.6797091039741443

Epoch: 6| Step: 13
Training loss: 1.6182418555908247
Validation loss: 2.6538425410367017

Epoch: 476| Step: 0
Training loss: 2.027710868509604
Validation loss: 2.7282909167743057

Epoch: 6| Step: 1
Training loss: 1.7242679452381258
Validation loss: 2.5688627410667877

Epoch: 6| Step: 2
Training loss: 1.3637574683945561
Validation loss: 2.6722225319881634

Epoch: 6| Step: 3
Training loss: 1.925345040646796
Validation loss: 2.5920949865343843

Epoch: 6| Step: 4
Training loss: 1.4398653224378428
Validation loss: 2.6587384664900147

Epoch: 6| Step: 5
Training loss: 1.7415743035218165
Validation loss: 2.6799434014810237

Epoch: 6| Step: 6
Training loss: 2.7248117679364228
Validation loss: 2.5951215515541355

Epoch: 6| Step: 7
Training loss: 1.8304239799179165
Validation loss: 2.658673258539011

Epoch: 6| Step: 8
Training loss: 1.88807146377201
Validation loss: 2.5961316369493326

Epoch: 6| Step: 9
Training loss: 1.6626104906121735
Validation loss: 2.661396729469722

Epoch: 6| Step: 10
Training loss: 1.7631353869803266
Validation loss: 2.618831854936546

Epoch: 6| Step: 11
Training loss: 1.7687791990424384
Validation loss: 2.586650626508436

Epoch: 6| Step: 12
Training loss: 1.8714382674736678
Validation loss: 2.6354596706274918

Epoch: 6| Step: 13
Training loss: 1.8537318402029135
Validation loss: 2.6023825490201395

Epoch: 477| Step: 0
Training loss: 1.9226689133271642
Validation loss: 2.5967064869802283

Epoch: 6| Step: 1
Training loss: 1.5883873869807028
Validation loss: 2.662389371134308

Epoch: 6| Step: 2
Training loss: 1.6377781464311612
Validation loss: 2.689680465998452

Epoch: 6| Step: 3
Training loss: 1.512053460023768
Validation loss: 2.610196379816148

Epoch: 6| Step: 4
Training loss: 1.8983136674344052
Validation loss: 2.547859938070182

Epoch: 6| Step: 5
Training loss: 1.2864578751577367
Validation loss: 2.6227561102876265

Epoch: 6| Step: 6
Training loss: 2.4236874597201647
Validation loss: 2.6966677484824895

Epoch: 6| Step: 7
Training loss: 1.5179866991930469
Validation loss: 2.6372726781031934

Epoch: 6| Step: 8
Training loss: 1.6015242409206898
Validation loss: 2.6332529889341485

Epoch: 6| Step: 9
Training loss: 2.0650260945811967
Validation loss: 2.616495983468603

Epoch: 6| Step: 10
Training loss: 2.0725692253377543
Validation loss: 2.5757110421614002

Epoch: 6| Step: 11
Training loss: 1.498935242086893
Validation loss: 2.6341130897252083

Epoch: 6| Step: 12
Training loss: 1.5797373023328005
Validation loss: 2.725382716900354

Epoch: 6| Step: 13
Training loss: 2.1137643991585597
Validation loss: 2.753317248256642

Epoch: 478| Step: 0
Training loss: 1.807570561447045
Validation loss: 2.659145608301085

Epoch: 6| Step: 1
Training loss: 1.597598571482341
Validation loss: 2.6212775209677357

Epoch: 6| Step: 2
Training loss: 1.98918254337226
Validation loss: 2.617703745187482

Epoch: 6| Step: 3
Training loss: 1.738022002700932
Validation loss: 2.692222345870716

Epoch: 6| Step: 4
Training loss: 1.845664113757698
Validation loss: 2.660506542308287

Epoch: 6| Step: 5
Training loss: 1.8344935156311735
Validation loss: 2.6380184896636645

Epoch: 6| Step: 6
Training loss: 1.5685893611046684
Validation loss: 2.650944735546015

Epoch: 6| Step: 7
Training loss: 1.6190826810585177
Validation loss: 2.7005227674004906

Epoch: 6| Step: 8
Training loss: 1.680814072488032
Validation loss: 2.6295615670667996

Epoch: 6| Step: 9
Training loss: 1.6173546746133491
Validation loss: 2.661136551314639

Epoch: 6| Step: 10
Training loss: 1.4127275266788817
Validation loss: 2.6777097072108194

Epoch: 6| Step: 11
Training loss: 1.773980011493015
Validation loss: 2.7665962843597764

Epoch: 6| Step: 12
Training loss: 2.146029812110674
Validation loss: 2.7423641714814986

Epoch: 6| Step: 13
Training loss: 1.8743833799515115
Validation loss: 2.6933360929524746

Epoch: 479| Step: 0
Training loss: 1.7824127016452183
Validation loss: 2.611297797948421

Epoch: 6| Step: 1
Training loss: 1.4560609915869986
Validation loss: 2.6221101208908215

Epoch: 6| Step: 2
Training loss: 1.5622399685971493
Validation loss: 2.702701011598707

Epoch: 6| Step: 3
Training loss: 1.557933925843555
Validation loss: 2.6047540286950737

Epoch: 6| Step: 4
Training loss: 1.8094305158409631
Validation loss: 2.6811592659424166

Epoch: 6| Step: 5
Training loss: 2.430483181799306
Validation loss: 2.6410300486688216

Epoch: 6| Step: 6
Training loss: 1.9756979276525464
Validation loss: 2.61022288975822

Epoch: 6| Step: 7
Training loss: 1.3978078692756293
Validation loss: 2.655023162906375

Epoch: 6| Step: 8
Training loss: 2.216495389224918
Validation loss: 2.6775518880111036

Epoch: 6| Step: 9
Training loss: 1.909909222627604
Validation loss: 2.5599787244085714

Epoch: 6| Step: 10
Training loss: 1.7426977394026737
Validation loss: 2.6768378659977494

Epoch: 6| Step: 11
Training loss: 1.8297801553800679
Validation loss: 2.5722427957041396

Epoch: 6| Step: 12
Training loss: 1.6711721636408243
Validation loss: 2.5972347046087485

Epoch: 6| Step: 13
Training loss: 1.4232166374366257
Validation loss: 2.6187193064606875

Epoch: 480| Step: 0
Training loss: 1.319759636871423
Validation loss: 2.597193083673607

Epoch: 6| Step: 1
Training loss: 1.7697224292679496
Validation loss: 2.6509462250702316

Epoch: 6| Step: 2
Training loss: 1.6961223584068161
Validation loss: 2.6804989577781044

Epoch: 6| Step: 3
Training loss: 1.9221054187131261
Validation loss: 2.703050972662682

Epoch: 6| Step: 4
Training loss: 1.7234049789666674
Validation loss: 2.656928954434258

Epoch: 6| Step: 5
Training loss: 1.7941772111700078
Validation loss: 2.7060566902438183

Epoch: 6| Step: 6
Training loss: 2.044544786372724
Validation loss: 2.6189036072167666

Epoch: 6| Step: 7
Training loss: 1.8359430840589948
Validation loss: 2.620725587365704

Epoch: 6| Step: 8
Training loss: 2.130106904118578
Validation loss: 2.675416842285331

Epoch: 6| Step: 9
Training loss: 1.7702555742395563
Validation loss: 2.6702946593201062

Epoch: 6| Step: 10
Training loss: 1.3101002689746521
Validation loss: 2.720602805172326

Epoch: 6| Step: 11
Training loss: 2.019307402669195
Validation loss: 2.622610849762222

Epoch: 6| Step: 12
Training loss: 1.3462873057347453
Validation loss: 2.7206661236366023

Epoch: 6| Step: 13
Training loss: 1.7427246907757277
Validation loss: 2.60636795004071

Epoch: 481| Step: 0
Training loss: 1.4796293994489786
Validation loss: 2.6522589516581667

Epoch: 6| Step: 1
Training loss: 2.234764438649506
Validation loss: 2.7077881594858018

Epoch: 6| Step: 2
Training loss: 1.7175398294197752
Validation loss: 2.6510864440345667

Epoch: 6| Step: 3
Training loss: 1.6795209935185917
Validation loss: 2.727231320557502

Epoch: 6| Step: 4
Training loss: 1.8955854805821144
Validation loss: 2.629857779215422

Epoch: 6| Step: 5
Training loss: 2.4163452022326073
Validation loss: 2.7161515562187373

Epoch: 6| Step: 6
Training loss: 1.7657848724633227
Validation loss: 2.6540471381078485

Epoch: 6| Step: 7
Training loss: 1.6720943128825947
Validation loss: 2.6593140130771493

Epoch: 6| Step: 8
Training loss: 1.8116935382781476
Validation loss: 2.6599167803387256

Epoch: 6| Step: 9
Training loss: 1.1641209734881153
Validation loss: 2.6640665455271035

Epoch: 6| Step: 10
Training loss: 1.5416499815716704
Validation loss: 2.6845835080192515

Epoch: 6| Step: 11
Training loss: 2.3846248550794926
Validation loss: 2.7076097649849222

Epoch: 6| Step: 12
Training loss: 1.5720798548540216
Validation loss: 2.7129969960831954

Epoch: 6| Step: 13
Training loss: 1.7106465828272364
Validation loss: 2.604706813456379

Epoch: 482| Step: 0
Training loss: 1.7355458199692944
Validation loss: 2.6737502988536996

Epoch: 6| Step: 1
Training loss: 1.6168243442735502
Validation loss: 2.536138491428522

Epoch: 6| Step: 2
Training loss: 1.8030216075006582
Validation loss: 2.6339835961312623

Epoch: 6| Step: 3
Training loss: 1.9953447045077521
Validation loss: 2.6333089342021503

Epoch: 6| Step: 4
Training loss: 1.9805292425002363
Validation loss: 2.603533125733024

Epoch: 6| Step: 5
Training loss: 1.7996112721629625
Validation loss: 2.5628015624370954

Epoch: 6| Step: 6
Training loss: 1.618930632775164
Validation loss: 2.599649298548338

Epoch: 6| Step: 7
Training loss: 2.0562009857736387
Validation loss: 2.686128438527128

Epoch: 6| Step: 8
Training loss: 2.0091417714172906
Validation loss: 2.6347652163377875

Epoch: 6| Step: 9
Training loss: 1.324113104553001
Validation loss: 2.639233041661303

Epoch: 6| Step: 10
Training loss: 1.6318918215156042
Validation loss: 2.5780707738001936

Epoch: 6| Step: 11
Training loss: 1.4529950483727407
Validation loss: 2.5181871147617936

Epoch: 6| Step: 12
Training loss: 1.784693551565099
Validation loss: 2.6406923564473734

Epoch: 6| Step: 13
Training loss: 2.390208189288303
Validation loss: 2.6524633973558616

Epoch: 483| Step: 0
Training loss: 1.6000718786068249
Validation loss: 2.603872510642476

Epoch: 6| Step: 1
Training loss: 1.8060221175215576
Validation loss: 2.616569895535866

Epoch: 6| Step: 2
Training loss: 1.6969028168535703
Validation loss: 2.6311263217493748

Epoch: 6| Step: 3
Training loss: 1.3727594674415615
Validation loss: 2.6764741394933425

Epoch: 6| Step: 4
Training loss: 2.2873249424723316
Validation loss: 2.560121757727612

Epoch: 6| Step: 5
Training loss: 1.8185136936480835
Validation loss: 2.6842637261733278

Epoch: 6| Step: 6
Training loss: 1.2861093621806223
Validation loss: 2.6510525412352286

Epoch: 6| Step: 7
Training loss: 1.394907155382555
Validation loss: 2.636645953572296

Epoch: 6| Step: 8
Training loss: 1.431073127045712
Validation loss: 2.698394933180598

Epoch: 6| Step: 9
Training loss: 1.732965394851674
Validation loss: 2.664131352032251

Epoch: 6| Step: 10
Training loss: 1.770116848079039
Validation loss: 2.6597910326418406

Epoch: 6| Step: 11
Training loss: 2.130591049572869
Validation loss: 2.65294140423114

Epoch: 6| Step: 12
Training loss: 2.1151750860948666
Validation loss: 2.659347379641826

Epoch: 6| Step: 13
Training loss: 2.105364908407208
Validation loss: 2.6653886409594976

Epoch: 484| Step: 0
Training loss: 2.064522647318625
Validation loss: 2.695321719460148

Epoch: 6| Step: 1
Training loss: 1.8044186346408937
Validation loss: 2.68344829092447

Epoch: 6| Step: 2
Training loss: 1.4007328737823133
Validation loss: 2.7093729590597877

Epoch: 6| Step: 3
Training loss: 1.4885767846028122
Validation loss: 2.6372939967085856

Epoch: 6| Step: 4
Training loss: 1.7524583443168267
Validation loss: 2.715053439944928

Epoch: 6| Step: 5
Training loss: 1.6128386474571235
Validation loss: 2.627748297836489

Epoch: 6| Step: 6
Training loss: 1.750672619848499
Validation loss: 2.6406275144903515

Epoch: 6| Step: 7
Training loss: 1.666825843203496
Validation loss: 2.615335146965081

Epoch: 6| Step: 8
Training loss: 1.236763972252642
Validation loss: 2.5987052023986954

Epoch: 6| Step: 9
Training loss: 1.7346107391433152
Validation loss: 2.602427775653217

Epoch: 6| Step: 10
Training loss: 1.477405206702159
Validation loss: 2.6658558128670413

Epoch: 6| Step: 11
Training loss: 2.759201434888104
Validation loss: 2.6263433184511182

Epoch: 6| Step: 12
Training loss: 2.0825519876757146
Validation loss: 2.584531574307659

Epoch: 6| Step: 13
Training loss: 1.7652334268545875
Validation loss: 2.6315722980075242

Epoch: 485| Step: 0
Training loss: 1.8515821367341163
Validation loss: 2.6308160233159987

Epoch: 6| Step: 1
Training loss: 1.228678924429718
Validation loss: 2.5932441422736976

Epoch: 6| Step: 2
Training loss: 1.7387742618538218
Validation loss: 2.6007524031154885

Epoch: 6| Step: 3
Training loss: 1.486157521546174
Validation loss: 2.5973601773376105

Epoch: 6| Step: 4
Training loss: 1.7059299574065245
Validation loss: 2.5262462604577407

Epoch: 6| Step: 5
Training loss: 1.3234246948055053
Validation loss: 2.63998253332875

Epoch: 6| Step: 6
Training loss: 2.1567344674130022
Validation loss: 2.6457783159836015

Epoch: 6| Step: 7
Training loss: 2.0235105523432133
Validation loss: 2.6603720707245273

Epoch: 6| Step: 8
Training loss: 1.5267880885106544
Validation loss: 2.5719988341960938

Epoch: 6| Step: 9
Training loss: 1.9009493313317236
Validation loss: 2.6641117724467134

Epoch: 6| Step: 10
Training loss: 2.3210408002167373
Validation loss: 2.5613494153763994

Epoch: 6| Step: 11
Training loss: 1.649630363560275
Validation loss: 2.684827430093803

Epoch: 6| Step: 12
Training loss: 1.7823331116480654
Validation loss: 2.650966303223762

Epoch: 6| Step: 13
Training loss: 2.4436079915730127
Validation loss: 2.5965370952001154

Epoch: 486| Step: 0
Training loss: 1.0836261879178153
Validation loss: 2.6128574265981097

Epoch: 6| Step: 1
Training loss: 1.7783477965424899
Validation loss: 2.651594382914687

Epoch: 6| Step: 2
Training loss: 2.49315010063903
Validation loss: 2.709856871003881

Epoch: 6| Step: 3
Training loss: 1.6923853482922433
Validation loss: 2.616870875790091

Epoch: 6| Step: 4
Training loss: 1.404907560667495
Validation loss: 2.714832723327657

Epoch: 6| Step: 5
Training loss: 1.5638107905170617
Validation loss: 2.63784326052615

Epoch: 6| Step: 6
Training loss: 2.087630938232411
Validation loss: 2.6354499440927612

Epoch: 6| Step: 7
Training loss: 1.504712173719122
Validation loss: 2.6521432862963317

Epoch: 6| Step: 8
Training loss: 2.0229070844596837
Validation loss: 2.6481945446573323

Epoch: 6| Step: 9
Training loss: 1.5485162216484838
Validation loss: 2.5922393165246636

Epoch: 6| Step: 10
Training loss: 1.8877395174758205
Validation loss: 2.696547729451278

Epoch: 6| Step: 11
Training loss: 1.2751867531529921
Validation loss: 2.6555360064894877

Epoch: 6| Step: 12
Training loss: 1.6954138237695053
Validation loss: 2.6737070644295455

Epoch: 6| Step: 13
Training loss: 1.356783314633452
Validation loss: 2.6854042549037085

Epoch: 487| Step: 0
Training loss: 1.6481925456932611
Validation loss: 2.6066143908516035

Epoch: 6| Step: 1
Training loss: 2.1605155880486424
Validation loss: 2.6978765584384514

Epoch: 6| Step: 2
Training loss: 1.397274066151969
Validation loss: 2.6137627120815323

Epoch: 6| Step: 3
Training loss: 1.8640417950000692
Validation loss: 2.6521753008808453

Epoch: 6| Step: 4
Training loss: 1.3086132446658907
Validation loss: 2.5705363606296974

Epoch: 6| Step: 5
Training loss: 2.305866418382168
Validation loss: 2.6434396721883107

Epoch: 6| Step: 6
Training loss: 1.7488646230154608
Validation loss: 2.6112958157951747

Epoch: 6| Step: 7
Training loss: 1.7760137591215648
Validation loss: 2.643182024112792

Epoch: 6| Step: 8
Training loss: 1.6732748713039152
Validation loss: 2.6411701185106584

Epoch: 6| Step: 9
Training loss: 1.8432106910362398
Validation loss: 2.5525490478811843

Epoch: 6| Step: 10
Training loss: 1.7160884710593827
Validation loss: 2.649854779264648

Epoch: 6| Step: 11
Training loss: 1.3903293938359564
Validation loss: 2.61748904978264

Epoch: 6| Step: 12
Training loss: 1.978474231524206
Validation loss: 2.6657567247062652

Epoch: 6| Step: 13
Training loss: 1.393012536816071
Validation loss: 2.6069949208672876

Epoch: 488| Step: 0
Training loss: 1.4533506648899668
Validation loss: 2.6841436357910253

Epoch: 6| Step: 1
Training loss: 2.0575772115465876
Validation loss: 2.590774376105367

Epoch: 6| Step: 2
Training loss: 0.9169511389761636
Validation loss: 2.6387941047328267

Epoch: 6| Step: 3
Training loss: 1.829625939979528
Validation loss: 2.637548888013452

Epoch: 6| Step: 4
Training loss: 1.9951706037498715
Validation loss: 2.639218346913666

Epoch: 6| Step: 5
Training loss: 1.8277571870570957
Validation loss: 2.6416777815280392

Epoch: 6| Step: 6
Training loss: 1.54795090991308
Validation loss: 2.702234927195169

Epoch: 6| Step: 7
Training loss: 2.1255726884048514
Validation loss: 2.6717936137546836

Epoch: 6| Step: 8
Training loss: 1.1076488766806207
Validation loss: 2.623162952552476

Epoch: 6| Step: 9
Training loss: 1.4650239147018023
Validation loss: 2.692250602479282

Epoch: 6| Step: 10
Training loss: 2.28413647451375
Validation loss: 2.6767296653025143

Epoch: 6| Step: 11
Training loss: 1.4070004474121336
Validation loss: 2.696557401979141

Epoch: 6| Step: 12
Training loss: 1.64472094096478
Validation loss: 2.6955093632907836

Epoch: 6| Step: 13
Training loss: 3.1439138623830765
Validation loss: 2.583359015261374

Epoch: 489| Step: 0
Training loss: 1.899927629799125
Validation loss: 2.661466811174057

Epoch: 6| Step: 1
Training loss: 1.2125159036438884
Validation loss: 2.5771088458026186

Epoch: 6| Step: 2
Training loss: 1.421579015757046
Validation loss: 2.72557168950682

Epoch: 6| Step: 3
Training loss: 1.8256282874537786
Validation loss: 2.6256987427427467

Epoch: 6| Step: 4
Training loss: 2.7472799894428426
Validation loss: 2.6912243347588722

Epoch: 6| Step: 5
Training loss: 1.2079883718815145
Validation loss: 2.692959925780672

Epoch: 6| Step: 6
Training loss: 1.8287476351469112
Validation loss: 2.6332210022906293

Epoch: 6| Step: 7
Training loss: 1.9051460446422515
Validation loss: 2.6560317831143885

Epoch: 6| Step: 8
Training loss: 1.78815060492873
Validation loss: 2.692833965573888

Epoch: 6| Step: 9
Training loss: 1.7203008417467283
Validation loss: 2.589800658082736

Epoch: 6| Step: 10
Training loss: 2.0588275697011333
Validation loss: 2.636612429524267

Epoch: 6| Step: 11
Training loss: 1.6847814632160418
Validation loss: 2.640098230408846

Epoch: 6| Step: 12
Training loss: 1.2917516690659265
Validation loss: 2.686175917592304

Epoch: 6| Step: 13
Training loss: 1.6941915576993316
Validation loss: 2.5595063731854335

Epoch: 490| Step: 0
Training loss: 1.3748364784801916
Validation loss: 2.6949587734453386

Epoch: 6| Step: 1
Training loss: 1.5193355012543162
Validation loss: 2.6484427909859933

Epoch: 6| Step: 2
Training loss: 1.6291452502365797
Validation loss: 2.5860591827950454

Epoch: 6| Step: 3
Training loss: 1.512447841785327
Validation loss: 2.725333638805737

Epoch: 6| Step: 4
Training loss: 1.634635892799806
Validation loss: 2.650906302340519

Epoch: 6| Step: 5
Training loss: 2.4150552529279374
Validation loss: 2.7040891694791

Epoch: 6| Step: 6
Training loss: 1.7738336465157816
Validation loss: 2.645770320153277

Epoch: 6| Step: 7
Training loss: 1.8100053127484832
Validation loss: 2.646479765937169

Epoch: 6| Step: 8
Training loss: 1.0701302700423159
Validation loss: 2.6291474774401458

Epoch: 6| Step: 9
Training loss: 2.2662275894159505
Validation loss: 2.766578648478328

Epoch: 6| Step: 10
Training loss: 1.2169210453265966
Validation loss: 2.5945346691585334

Epoch: 6| Step: 11
Training loss: 2.057544419097692
Validation loss: 2.7120594363809207

Epoch: 6| Step: 12
Training loss: 1.8519822944511568
Validation loss: 2.7068678899191894

Epoch: 6| Step: 13
Training loss: 1.445999312241049
Validation loss: 2.628861881165649

Epoch: 491| Step: 0
Training loss: 1.5568606270241885
Validation loss: 2.6185328427684893

Epoch: 6| Step: 1
Training loss: 1.9167541884743107
Validation loss: 2.6660402495391793

Epoch: 6| Step: 2
Training loss: 1.686647128995939
Validation loss: 2.6434829002538334

Epoch: 6| Step: 3
Training loss: 2.0697970918361275
Validation loss: 2.656632687184136

Epoch: 6| Step: 4
Training loss: 1.6157283373606302
Validation loss: 2.6127417988135595

Epoch: 6| Step: 5
Training loss: 1.8333905673485469
Validation loss: 2.608568061476312

Epoch: 6| Step: 6
Training loss: 1.676709538221983
Validation loss: 2.6098501072445237

Epoch: 6| Step: 7
Training loss: 1.8128981317431714
Validation loss: 2.673724760607119

Epoch: 6| Step: 8
Training loss: 1.9380371210619614
Validation loss: 2.6436114669371595

Epoch: 6| Step: 9
Training loss: 1.440267800754646
Validation loss: 2.6727578959767704

Epoch: 6| Step: 10
Training loss: 1.2707321355998544
Validation loss: 2.541375795326553

Epoch: 6| Step: 11
Training loss: 1.121453310630266
Validation loss: 2.665851444052759

Epoch: 6| Step: 12
Training loss: 2.311905449395758
Validation loss: 2.56833303235199

Epoch: 6| Step: 13
Training loss: 1.1993982634243807
Validation loss: 2.603560193393659

Epoch: 492| Step: 0
Training loss: 2.2071716804050894
Validation loss: 2.7093936658794573

Epoch: 6| Step: 1
Training loss: 2.0171562115571837
Validation loss: 2.609129909602944

Epoch: 6| Step: 2
Training loss: 1.641677373602689
Validation loss: 2.6293821853751718

Epoch: 6| Step: 3
Training loss: 1.1192898476063793
Validation loss: 2.5884630880418626

Epoch: 6| Step: 4
Training loss: 1.4482237492504624
Validation loss: 2.7076075607685297

Epoch: 6| Step: 5
Training loss: 2.3596213508986352
Validation loss: 2.6120372854862257

Epoch: 6| Step: 6
Training loss: 1.4966806401037276
Validation loss: 2.611282941089073

Epoch: 6| Step: 7
Training loss: 1.9020052692929994
Validation loss: 2.6393844662313284

Epoch: 6| Step: 8
Training loss: 1.9677690150966125
Validation loss: 2.605900569113044

Epoch: 6| Step: 9
Training loss: 1.6776475450919297
Validation loss: 2.585583476618878

Epoch: 6| Step: 10
Training loss: 1.534353420004814
Validation loss: 2.6638840230136087

Epoch: 6| Step: 11
Training loss: 1.3251858670847523
Validation loss: 2.6193472553537216

Epoch: 6| Step: 12
Training loss: 1.630326491228772
Validation loss: 2.5792106811000513

Epoch: 6| Step: 13
Training loss: 1.3388317501350488
Validation loss: 2.66411698515133

Epoch: 493| Step: 0
Training loss: 1.8209683133279753
Validation loss: 2.637625904516095

Epoch: 6| Step: 1
Training loss: 1.7881678047376848
Validation loss: 2.625444571863193

Epoch: 6| Step: 2
Training loss: 1.956306490828973
Validation loss: 2.611680072107365

Epoch: 6| Step: 3
Training loss: 1.3000198289385994
Validation loss: 2.6025749044157607

Epoch: 6| Step: 4
Training loss: 1.1838189342048613
Validation loss: 2.6457987182254556

Epoch: 6| Step: 5
Training loss: 1.6591414637481987
Validation loss: 2.5749533785135728

Epoch: 6| Step: 6
Training loss: 1.6735113104491322
Validation loss: 2.671336184627529

Epoch: 6| Step: 7
Training loss: 2.3685526420890812
Validation loss: 2.652926378584112

Epoch: 6| Step: 8
Training loss: 1.9933651304526332
Validation loss: 2.5717433329708004

Epoch: 6| Step: 9
Training loss: 2.0015924789482566
Validation loss: 2.6216988283333085

Epoch: 6| Step: 10
Training loss: 1.4259736231789406
Validation loss: 2.555698360987701

Epoch: 6| Step: 11
Training loss: 1.4215710493238658
Validation loss: 2.6700905314366947

Epoch: 6| Step: 12
Training loss: 1.7150576377725497
Validation loss: 2.6482947013366385

Epoch: 6| Step: 13
Training loss: 1.1487283662703651
Validation loss: 2.626404085463826

Epoch: 494| Step: 0
Training loss: 1.1406858245099907
Validation loss: 2.7813886280913493

Epoch: 6| Step: 1
Training loss: 2.4420967773456224
Validation loss: 2.675694265464485

Epoch: 6| Step: 2
Training loss: 2.12113826135962
Validation loss: 2.5949224072653063

Epoch: 6| Step: 3
Training loss: 1.5802142976947127
Validation loss: 2.666762597014664

Epoch: 6| Step: 4
Training loss: 2.0251518851881345
Validation loss: 2.6380874432152446

Epoch: 6| Step: 5
Training loss: 1.4945717183450433
Validation loss: 2.7195730244844913

Epoch: 6| Step: 6
Training loss: 2.003075023866808
Validation loss: 2.644481667013669

Epoch: 6| Step: 7
Training loss: 1.8913420271182315
Validation loss: 2.6583897802368868

Epoch: 6| Step: 8
Training loss: 1.6508037343549813
Validation loss: 2.655166312263977

Epoch: 6| Step: 9
Training loss: 1.3807017278181233
Validation loss: 2.710748545623363

Epoch: 6| Step: 10
Training loss: 0.9944181223593631
Validation loss: 2.6007677163917453

Epoch: 6| Step: 11
Training loss: 1.8672960321654204
Validation loss: 2.633918925785645

Epoch: 6| Step: 12
Training loss: 1.9976456016402928
Validation loss: 2.724532306880964

Epoch: 6| Step: 13
Training loss: 1.7157795987539437
Validation loss: 2.592603398160721

Epoch: 495| Step: 0
Training loss: 1.7103489250989572
Validation loss: 2.6889329196679013

Epoch: 6| Step: 1
Training loss: 1.5674777278504244
Validation loss: 2.6437038426813686

Epoch: 6| Step: 2
Training loss: 1.743302471745969
Validation loss: 2.6943768399522887

Epoch: 6| Step: 3
Training loss: 1.3142012514938877
Validation loss: 2.603093528559778

Epoch: 6| Step: 4
Training loss: 1.354498788257844
Validation loss: 2.653521636021207

Epoch: 6| Step: 5
Training loss: 1.7358357919036747
Validation loss: 2.596877798677156

Epoch: 6| Step: 6
Training loss: 1.562439574026897
Validation loss: 2.64071295331375

Epoch: 6| Step: 7
Training loss: 1.6935276181109191
Validation loss: 2.650079852275013

Epoch: 6| Step: 8
Training loss: 1.1465023630735895
Validation loss: 2.6037660732819505

Epoch: 6| Step: 9
Training loss: 2.1588324962551417
Validation loss: 2.734834172710998

Epoch: 6| Step: 10
Training loss: 1.8225588056708002
Validation loss: 2.615529584850354

Epoch: 6| Step: 11
Training loss: 1.5206623329631548
Validation loss: 2.659893082200042

Epoch: 6| Step: 12
Training loss: 1.7681259402302587
Validation loss: 2.5878486180083784

Epoch: 6| Step: 13
Training loss: 2.8757387953497426
Validation loss: 2.624478957913965

Epoch: 496| Step: 0
Training loss: 1.9780650101133226
Validation loss: 2.5738931298970007

Epoch: 6| Step: 1
Training loss: 1.8459199969726177
Validation loss: 2.6008301918502426

Epoch: 6| Step: 2
Training loss: 1.305384558217759
Validation loss: 2.6373249803614223

Epoch: 6| Step: 3
Training loss: 1.233415061373521
Validation loss: 2.6732392746686076

Epoch: 6| Step: 4
Training loss: 2.067493059176657
Validation loss: 2.6470352697132147

Epoch: 6| Step: 5
Training loss: 1.6189930737013272
Validation loss: 2.536912062913043

Epoch: 6| Step: 6
Training loss: 1.7040586099977233
Validation loss: 2.58462555474465

Epoch: 6| Step: 7
Training loss: 2.530996050870385
Validation loss: 2.6164619126896715

Epoch: 6| Step: 8
Training loss: 1.3265502569669319
Validation loss: 2.6042223393221615

Epoch: 6| Step: 9
Training loss: 1.681081503894322
Validation loss: 2.705020978184856

Epoch: 6| Step: 10
Training loss: 1.9526390997148837
Validation loss: 2.6580638061323967

Epoch: 6| Step: 11
Training loss: 1.7648675019454627
Validation loss: 2.6517813563840678

Epoch: 6| Step: 12
Training loss: 1.500150355115
Validation loss: 2.6657744428864967

Epoch: 6| Step: 13
Training loss: 1.3064468764736163
Validation loss: 2.65561263118227

Epoch: 497| Step: 0
Training loss: 1.6617675860160084
Validation loss: 2.6512758088064743

Epoch: 6| Step: 1
Training loss: 1.871964859119117
Validation loss: 2.6638496180831472

Epoch: 6| Step: 2
Training loss: 1.5004208292325596
Validation loss: 2.5813164500606702

Epoch: 6| Step: 3
Training loss: 1.424973350409558
Validation loss: 2.6045646163252663

Epoch: 6| Step: 4
Training loss: 1.5229420956820838
Validation loss: 2.6984622318346645

Epoch: 6| Step: 5
Training loss: 1.432308608446204
Validation loss: 2.625716744900888

Epoch: 6| Step: 6
Training loss: 1.8960354526078294
Validation loss: 2.613689261079547

Epoch: 6| Step: 7
Training loss: 1.4677982087116719
Validation loss: 2.6591359799733625

Epoch: 6| Step: 8
Training loss: 1.6474914005269286
Validation loss: 2.723030131867214

Epoch: 6| Step: 9
Training loss: 1.7859159560084734
Validation loss: 2.7005052411320327

Epoch: 6| Step: 10
Training loss: 1.6174165130483609
Validation loss: 2.6248663444889497

Epoch: 6| Step: 11
Training loss: 2.1449934664540056
Validation loss: 2.5858032872810077

Epoch: 6| Step: 12
Training loss: 2.7247686305383474
Validation loss: 2.6340214122279035

Epoch: 6| Step: 13
Training loss: 1.2731349094100726
Validation loss: 2.685292086062387

Epoch: 498| Step: 0
Training loss: 1.2347001239089737
Validation loss: 2.7614265472155615

Epoch: 6| Step: 1
Training loss: 1.6669121640914437
Validation loss: 2.576938357800676

Epoch: 6| Step: 2
Training loss: 1.4116762375460243
Validation loss: 2.603485111427971

Epoch: 6| Step: 3
Training loss: 1.758096222762341
Validation loss: 2.6662948830553743

Epoch: 6| Step: 4
Training loss: 1.9802867196301044
Validation loss: 2.633737989492565

Epoch: 6| Step: 5
Training loss: 1.9250446017163894
Validation loss: 2.652849618802674

Epoch: 6| Step: 6
Training loss: 1.2494427869535196
Validation loss: 2.690330400003322

Epoch: 6| Step: 7
Training loss: 1.774236154743864
Validation loss: 2.652317706001718

Epoch: 6| Step: 8
Training loss: 1.2219254622319868
Validation loss: 2.62676364934934

Epoch: 6| Step: 9
Training loss: 1.9115935926541925
Validation loss: 2.699960185000094

Epoch: 6| Step: 10
Training loss: 1.1263615528201896
Validation loss: 2.6214903942205194

Epoch: 6| Step: 11
Training loss: 1.739324432416555
Validation loss: 2.601020567095458

Epoch: 6| Step: 12
Training loss: 2.1728658268492462
Validation loss: 2.640311776744209

Epoch: 6| Step: 13
Training loss: 2.8882448036756636
Validation loss: 2.6101684876858338

Epoch: 499| Step: 0
Training loss: 2.1937858730763082
Validation loss: 2.6686962528325213

Epoch: 6| Step: 1
Training loss: 2.5622471010041172
Validation loss: 2.6667600552551995

Epoch: 6| Step: 2
Training loss: 1.5709420076346925
Validation loss: 2.6319259728911346

Epoch: 6| Step: 3
Training loss: 2.167729874931133
Validation loss: 2.602364063803362

Epoch: 6| Step: 4
Training loss: 1.335110503205961
Validation loss: 2.705117633963895

Epoch: 6| Step: 5
Training loss: 1.7931025835339969
Validation loss: 2.671067473774053

Epoch: 6| Step: 6
Training loss: 1.3067202237321716
Validation loss: 2.593679615681299

Epoch: 6| Step: 7
Training loss: 1.9743332183947775
Validation loss: 2.6396049990129327

Epoch: 6| Step: 8
Training loss: 1.565353229866323
Validation loss: 2.657583632752204

Epoch: 6| Step: 9
Training loss: 1.5085952387387058
Validation loss: 2.684718978456863

Epoch: 6| Step: 10
Training loss: 1.6973799654919395
Validation loss: 2.620959170495493

Epoch: 6| Step: 11
Training loss: 1.1843347024227024
Validation loss: 2.7277041094231045

Epoch: 6| Step: 12
Training loss: 1.223929768763327
Validation loss: 2.70333629879845

Epoch: 6| Step: 13
Training loss: 1.2370666419436758
Validation loss: 2.660262574889308

Epoch: 500| Step: 0
Training loss: 1.987964537452001
Validation loss: 2.720863976331382

Epoch: 6| Step: 1
Training loss: 1.46553019397962
Validation loss: 2.6843480053288467

Epoch: 6| Step: 2
Training loss: 1.7920032303389317
Validation loss: 2.60637703953316

Epoch: 6| Step: 3
Training loss: 1.9365905965527708
Validation loss: 2.68821126535986

Epoch: 6| Step: 4
Training loss: 1.91659733052546
Validation loss: 2.647418076516205

Epoch: 6| Step: 5
Training loss: 1.4588654047042753
Validation loss: 2.6261760384046124

Epoch: 6| Step: 6
Training loss: 1.5324584707635207
Validation loss: 2.5754171371093877

Epoch: 6| Step: 7
Training loss: 1.4883345146359621
Validation loss: 2.697268433605153

Epoch: 6| Step: 8
Training loss: 1.8104005690701441
Validation loss: 2.614867360954106

Epoch: 6| Step: 9
Training loss: 1.3646032705622
Validation loss: 2.5808131835893238

Epoch: 6| Step: 10
Training loss: 1.1747949461877927
Validation loss: 2.685379573081794

Epoch: 6| Step: 11
Training loss: 2.5364062691005107
Validation loss: 2.58011730250327

Epoch: 6| Step: 12
Training loss: 1.813942565370427
Validation loss: 2.6791627508179587

Epoch: 6| Step: 13
Training loss: 1.7440293501912785
Validation loss: 2.6655955140529217

Epoch: 501| Step: 0
Training loss: 1.6364960803513247
Validation loss: 2.6035285361468894

Epoch: 6| Step: 1
Training loss: 1.199943100057096
Validation loss: 2.593754159642588

Epoch: 6| Step: 2
Training loss: 1.218333246428508
Validation loss: 2.6656319805372632

Epoch: 6| Step: 3
Training loss: 2.1311808063092412
Validation loss: 2.66013928368935

Epoch: 6| Step: 4
Training loss: 1.5873681742083348
Validation loss: 2.6031878049688593

Epoch: 6| Step: 5
Training loss: 1.3136983577839094
Validation loss: 2.6697019778775553

Epoch: 6| Step: 6
Training loss: 1.0264663720956537
Validation loss: 2.662604597795609

Epoch: 6| Step: 7
Training loss: 1.895542276138911
Validation loss: 2.582886184461089

Epoch: 6| Step: 8
Training loss: 1.7675630178912425
Validation loss: 2.551308921529116

Epoch: 6| Step: 9
Training loss: 2.5154413191749083
Validation loss: 2.6749227819912154

Epoch: 6| Step: 10
Training loss: 1.644951773403254
Validation loss: 2.737741306248327

Epoch: 6| Step: 11
Training loss: 1.8413710036078705
Validation loss: 2.631078755450947

Epoch: 6| Step: 12
Training loss: 1.7897464161269625
Validation loss: 2.629995754687222

Epoch: 6| Step: 13
Training loss: 1.7838621561655785
Validation loss: 2.6888049907212244

Epoch: 502| Step: 0
Training loss: 2.383326640708792
Validation loss: 2.684611906145726

Epoch: 6| Step: 1
Training loss: 1.7212585176410897
Validation loss: 2.6545839087564187

Epoch: 6| Step: 2
Training loss: 1.5240902798162166
Validation loss: 2.718024176171307

Epoch: 6| Step: 3
Training loss: 2.0498505142417836
Validation loss: 2.6037389211168036

Epoch: 6| Step: 4
Training loss: 1.3649278550417945
Validation loss: 2.6397184527061937

Epoch: 6| Step: 5
Training loss: 1.7513431435537634
Validation loss: 2.6420362467943117

Epoch: 6| Step: 6
Training loss: 1.727754483503757
Validation loss: 2.670325544242119

Epoch: 6| Step: 7
Training loss: 1.1036313696731568
Validation loss: 2.671088851857372

Epoch: 6| Step: 8
Training loss: 1.9143738785309827
Validation loss: 2.642531484685496

Epoch: 6| Step: 9
Training loss: 1.404446229168171
Validation loss: 2.703516633798662

Epoch: 6| Step: 10
Training loss: 1.6364748825444069
Validation loss: 2.608119525760906

Epoch: 6| Step: 11
Training loss: 1.6947075252204489
Validation loss: 2.637259845640837

Epoch: 6| Step: 12
Training loss: 1.4445235289825853
Validation loss: 2.733154594565988

Epoch: 6| Step: 13
Training loss: 1.2471888402952191
Validation loss: 2.63313062660513

Epoch: 503| Step: 0
Training loss: 1.1315823946565298
Validation loss: 2.722558827970834

Epoch: 6| Step: 1
Training loss: 1.4352525474208118
Validation loss: 2.6427072420827398

Epoch: 6| Step: 2
Training loss: 1.5096498669541483
Validation loss: 2.7069900472388713

Epoch: 6| Step: 3
Training loss: 1.5593183549213512
Validation loss: 2.6294583081655483

Epoch: 6| Step: 4
Training loss: 1.5748788665934752
Validation loss: 2.5794730760391156

Epoch: 6| Step: 5
Training loss: 1.718081812588124
Validation loss: 2.6409455316180255

Epoch: 6| Step: 6
Training loss: 1.4279127100917623
Validation loss: 2.6448049144523504

Epoch: 6| Step: 7
Training loss: 1.3663212238813438
Validation loss: 2.606435752110393

Epoch: 6| Step: 8
Training loss: 1.479312173196659
Validation loss: 2.6474127311909914

Epoch: 6| Step: 9
Training loss: 1.621931406558041
Validation loss: 2.6502080699074817

Epoch: 6| Step: 10
Training loss: 1.756814223913898
Validation loss: 2.6063436046808324

Epoch: 6| Step: 11
Training loss: 2.8354367321088283
Validation loss: 2.649333338079601

Epoch: 6| Step: 12
Training loss: 1.8925747236569668
Validation loss: 2.700872633878491

Epoch: 6| Step: 13
Training loss: 1.3471274402656834
Validation loss: 2.6586005661709593

Epoch: 504| Step: 0
Training loss: 1.6909664718805184
Validation loss: 2.6257242179375506

Epoch: 6| Step: 1
Training loss: 1.7519207359220375
Validation loss: 2.6780354539302214

Epoch: 6| Step: 2
Training loss: 1.92616401257648
Validation loss: 2.620680484774783

Epoch: 6| Step: 3
Training loss: 2.061133885950398
Validation loss: 2.702912979019382

Epoch: 6| Step: 4
Training loss: 2.062368677755818
Validation loss: 2.6653787879936646

Epoch: 6| Step: 5
Training loss: 1.7561667643198247
Validation loss: 2.6688168999851394

Epoch: 6| Step: 6
Training loss: 1.35042471209543
Validation loss: 2.7159318241571575

Epoch: 6| Step: 7
Training loss: 1.4643921830019466
Validation loss: 2.7205476457829314

Epoch: 6| Step: 8
Training loss: 1.2322250184808146
Validation loss: 2.6452513514858165

Epoch: 6| Step: 9
Training loss: 2.284053073226342
Validation loss: 2.636635853669399

Epoch: 6| Step: 10
Training loss: 1.812625025679297
Validation loss: 2.618215041767692

Epoch: 6| Step: 11
Training loss: 1.5899971552889345
Validation loss: 2.6757158346123946

Epoch: 6| Step: 12
Training loss: 1.8615209553635679
Validation loss: 2.612877756229103

Epoch: 6| Step: 13
Training loss: 1.161796771407275
Validation loss: 2.636794618208574

Epoch: 505| Step: 0
Training loss: 1.472581127891654
Validation loss: 2.625590366908289

Epoch: 6| Step: 1
Training loss: 1.5938233003402602
Validation loss: 2.659583963492851

Epoch: 6| Step: 2
Training loss: 2.062017442142927
Validation loss: 2.644103915092235

Epoch: 6| Step: 3
Training loss: 1.9819697423524987
Validation loss: 2.7390068443003255

Epoch: 6| Step: 4
Training loss: 1.4131853112194577
Validation loss: 2.5610852882099486

Epoch: 6| Step: 5
Training loss: 1.5203108565036403
Validation loss: 2.690055121893067

Epoch: 6| Step: 6
Training loss: 1.4914809546487122
Validation loss: 2.6306614548331164

Epoch: 6| Step: 7
Training loss: 1.7126326154608178
Validation loss: 2.566933462041574

Epoch: 6| Step: 8
Training loss: 1.71706356194874
Validation loss: 2.6381080429274175

Epoch: 6| Step: 9
Training loss: 1.8878045600581428
Validation loss: 2.690089671977186

Epoch: 6| Step: 10
Training loss: 1.5416274796050482
Validation loss: 2.6330203299318486

Epoch: 6| Step: 11
Training loss: 1.570796531360819
Validation loss: 2.6216020697766167

Epoch: 6| Step: 12
Training loss: 1.9785044783704704
Validation loss: 2.6784643843083797

Epoch: 6| Step: 13
Training loss: 1.598137370372362
Validation loss: 2.6107798844597974

Epoch: 506| Step: 0
Training loss: 1.5165912654844018
Validation loss: 2.65174074724818

Epoch: 6| Step: 1
Training loss: 1.7300766614785876
Validation loss: 2.6506870347750144

Epoch: 6| Step: 2
Training loss: 2.3069303299958657
Validation loss: 2.6358032027402913

Epoch: 6| Step: 3
Training loss: 1.5228281220641302
Validation loss: 2.610625225602919

Epoch: 6| Step: 4
Training loss: 1.947143795751672
Validation loss: 2.637361851347719

Epoch: 6| Step: 5
Training loss: 1.7320174268722401
Validation loss: 2.6523860751804063

Epoch: 6| Step: 6
Training loss: 1.3950379463558567
Validation loss: 2.6721294660660173

Epoch: 6| Step: 7
Training loss: 1.2308966967252097
Validation loss: 2.641672805978785

Epoch: 6| Step: 8
Training loss: 1.4474740026376183
Validation loss: 2.661246234681497

Epoch: 6| Step: 9
Training loss: 1.976269183804696
Validation loss: 2.661308252716072

Epoch: 6| Step: 10
Training loss: 1.5110369581528469
Validation loss: 2.697986524118323

Epoch: 6| Step: 11
Training loss: 1.6262398904637192
Validation loss: 2.716881901936581

Epoch: 6| Step: 12
Training loss: 1.441215936766087
Validation loss: 2.635367616813641

Epoch: 6| Step: 13
Training loss: 2.274432511866993
Validation loss: 2.529459563288312

Epoch: 507| Step: 0
Training loss: 1.3558019398949015
Validation loss: 2.5981437334869244

Epoch: 6| Step: 1
Training loss: 1.3373397695520253
Validation loss: 2.646165611971519

Epoch: 6| Step: 2
Training loss: 1.6129082717355123
Validation loss: 2.6753050586778593

Epoch: 6| Step: 3
Training loss: 1.671709854668507
Validation loss: 2.777109270322651

Epoch: 6| Step: 4
Training loss: 1.6990997623569388
Validation loss: 2.689011301719678

Epoch: 6| Step: 5
Training loss: 2.0678379457017027
Validation loss: 2.715236909375519

Epoch: 6| Step: 6
Training loss: 1.316205198969164
Validation loss: 2.672141809676105

Epoch: 6| Step: 7
Training loss: 1.965984036354612
Validation loss: 2.713119172252288

Epoch: 6| Step: 8
Training loss: 1.669609816991462
Validation loss: 2.692868189641447

Epoch: 6| Step: 9
Training loss: 2.371519851733383
Validation loss: 2.673579558550462

Epoch: 6| Step: 10
Training loss: 1.8792305585173497
Validation loss: 2.690610104340814

Epoch: 6| Step: 11
Training loss: 1.3485066702242456
Validation loss: 2.5879527585137194

Epoch: 6| Step: 12
Training loss: 1.4606682840445993
Validation loss: 2.6580693075018593

Epoch: 6| Step: 13
Training loss: 0.8910445178948599
Validation loss: 2.695850615236719

Epoch: 508| Step: 0
Training loss: 1.6929301737644666
Validation loss: 2.6821634547295963

Epoch: 6| Step: 1
Training loss: 1.7490204385617785
Validation loss: 2.7081713262777765

Epoch: 6| Step: 2
Training loss: 1.6755682536458287
Validation loss: 2.691228637616625

Epoch: 6| Step: 3
Training loss: 2.247153282706047
Validation loss: 2.6584169161806823

Epoch: 6| Step: 4
Training loss: 1.4727306397770967
Validation loss: 2.620463106624653

Epoch: 6| Step: 5
Training loss: 0.8515704793293735
Validation loss: 2.6410620649825325

Epoch: 6| Step: 6
Training loss: 1.2992622739804096
Validation loss: 2.722009703953385

Epoch: 6| Step: 7
Training loss: 1.91527248206946
Validation loss: 2.589518179006322

Epoch: 6| Step: 8
Training loss: 1.6365448124126232
Validation loss: 2.6359954607616047

Epoch: 6| Step: 9
Training loss: 2.0253428322019116
Validation loss: 2.6663479351738704

Epoch: 6| Step: 10
Training loss: 1.1244023642992467
Validation loss: 2.6449038134257257

Epoch: 6| Step: 11
Training loss: 1.8080592508819249
Validation loss: 2.7967112411851485

Epoch: 6| Step: 12
Training loss: 2.1431871659592683
Validation loss: 2.6373766069854265

Epoch: 6| Step: 13
Training loss: 1.97030057850558
Validation loss: 2.664459761844436

Epoch: 509| Step: 0
Training loss: 1.6104802160649692
Validation loss: 2.621378208294151

Epoch: 6| Step: 1
Training loss: 2.046501882776382
Validation loss: 2.710838785833281

Epoch: 6| Step: 2
Training loss: 1.3380527370277921
Validation loss: 2.6517696111702396

Epoch: 6| Step: 3
Training loss: 1.4651322144356043
Validation loss: 2.6564533635949386

Epoch: 6| Step: 4
Training loss: 2.1240745099822416
Validation loss: 2.6429353099746407

Epoch: 6| Step: 5
Training loss: 1.7904184858126324
Validation loss: 2.614830025715823

Epoch: 6| Step: 6
Training loss: 1.882686499973864
Validation loss: 2.6617098687960064

Epoch: 6| Step: 7
Training loss: 1.3735570271876758
Validation loss: 2.680468160427446

Epoch: 6| Step: 8
Training loss: 1.329434097475783
Validation loss: 2.6332904212350403

Epoch: 6| Step: 9
Training loss: 1.78801046698662
Validation loss: 2.607978353202671

Epoch: 6| Step: 10
Training loss: 1.9751892747600974
Validation loss: 2.646670499647857

Epoch: 6| Step: 11
Training loss: 1.850917011529511
Validation loss: 2.706621495796462

Epoch: 6| Step: 12
Training loss: 1.2091174815029049
Validation loss: 2.5961620276049064

Epoch: 6| Step: 13
Training loss: 0.6191191804944692
Validation loss: 2.642541843881293

Epoch: 510| Step: 0
Training loss: 1.8538838574471368
Validation loss: 2.7069319046978695

Epoch: 6| Step: 1
Training loss: 1.5841940330671358
Validation loss: 2.716716237172376

Epoch: 6| Step: 2
Training loss: 2.444983121973614
Validation loss: 2.563655295708419

Epoch: 6| Step: 3
Training loss: 1.899731983555702
Validation loss: 2.6601716270410116

Epoch: 6| Step: 4
Training loss: 1.6709963905254397
Validation loss: 2.771087885218956

Epoch: 6| Step: 5
Training loss: 1.331881025238944
Validation loss: 2.750205655019828

Epoch: 6| Step: 6
Training loss: 1.3339950091942074
Validation loss: 2.6357056761108466

Epoch: 6| Step: 7
Training loss: 1.5637363882714996
Validation loss: 2.6818808572643706

Epoch: 6| Step: 8
Training loss: 1.6086376686270223
Validation loss: 2.7402902719845246

Epoch: 6| Step: 9
Training loss: 1.8938343142634182
Validation loss: 2.6354720877386257

Epoch: 6| Step: 10
Training loss: 1.5202128394336614
Validation loss: 2.6581951077132318

Epoch: 6| Step: 11
Training loss: 1.664258846823885
Validation loss: 2.6469752581723003

Epoch: 6| Step: 12
Training loss: 1.2555089197574971
Validation loss: 2.658688383809667

Epoch: 6| Step: 13
Training loss: 1.8655505806091228
Validation loss: 2.6608057060955472

Epoch: 511| Step: 0
Training loss: 1.5790188212707428
Validation loss: 2.62524405017352

Epoch: 6| Step: 1
Training loss: 1.2790792731502467
Validation loss: 2.6360760587403083

Epoch: 6| Step: 2
Training loss: 1.565569037923944
Validation loss: 2.622234870661607

Epoch: 6| Step: 3
Training loss: 1.3676722076053365
Validation loss: 2.7028452040656954

Epoch: 6| Step: 4
Training loss: 1.6433549964797491
Validation loss: 2.70433913877505

Epoch: 6| Step: 5
Training loss: 1.6820179940076525
Validation loss: 2.6995789115595583

Epoch: 6| Step: 6
Training loss: 1.5729834771861821
Validation loss: 2.733546132271178

Epoch: 6| Step: 7
Training loss: 1.435041564445787
Validation loss: 2.662997855736238

Epoch: 6| Step: 8
Training loss: 1.6278223323836312
Validation loss: 2.6491038216617158

Epoch: 6| Step: 9
Training loss: 1.623400634699518
Validation loss: 2.6504983301469895

Epoch: 6| Step: 10
Training loss: 2.2694312383837394
Validation loss: 2.734855359802258

Epoch: 6| Step: 11
Training loss: 2.1030442923807695
Validation loss: 2.5940257100239394

Epoch: 6| Step: 12
Training loss: 2.0289486098834173
Validation loss: 2.6175059223250066

Epoch: 6| Step: 13
Training loss: 0.9279449545138915
Validation loss: 2.6803861379567637

Epoch: 512| Step: 0
Training loss: 2.1877829232496295
Validation loss: 2.6973339963586547

Epoch: 6| Step: 1
Training loss: 1.4963260798922549
Validation loss: 2.6293136207182997

Epoch: 6| Step: 2
Training loss: 1.7311605271999067
Validation loss: 2.689117452396231

Epoch: 6| Step: 3
Training loss: 1.855698484955309
Validation loss: 2.603465391836884

Epoch: 6| Step: 4
Training loss: 1.8119249418178156
Validation loss: 2.668569308740799

Epoch: 6| Step: 5
Training loss: 1.3972163489496159
Validation loss: 2.5933916615580985

Epoch: 6| Step: 6
Training loss: 1.0163712327629535
Validation loss: 2.7169276508909244

Epoch: 6| Step: 7
Training loss: 1.8872732291510779
Validation loss: 2.633286627306853

Epoch: 6| Step: 8
Training loss: 1.5286752501933132
Validation loss: 2.6208118011807207

Epoch: 6| Step: 9
Training loss: 1.6801500260259004
Validation loss: 2.7002473995084344

Epoch: 6| Step: 10
Training loss: 1.8219983067342382
Validation loss: 2.6775442934518905

Epoch: 6| Step: 11
Training loss: 2.1795894915241494
Validation loss: 2.6038114171701765

Epoch: 6| Step: 12
Training loss: 1.341200428070628
Validation loss: 2.719930655763759

Epoch: 6| Step: 13
Training loss: 1.7365399843945786
Validation loss: 2.649991441721765

Epoch: 513| Step: 0
Training loss: 1.3082095365005528
Validation loss: 2.7675623753365897

Epoch: 6| Step: 1
Training loss: 1.7151188032412121
Validation loss: 2.601348345864391

Epoch: 6| Step: 2
Training loss: 1.6975562370322117
Validation loss: 2.606266107394097

Epoch: 6| Step: 3
Training loss: 1.704712853737042
Validation loss: 2.608824302091272

Epoch: 6| Step: 4
Training loss: 1.5635654631482652
Validation loss: 2.6623437711905398

Epoch: 6| Step: 5
Training loss: 1.6960739324352871
Validation loss: 2.5721453886976664

Epoch: 6| Step: 6
Training loss: 1.7630351829977862
Validation loss: 2.686294781456532

Epoch: 6| Step: 7
Training loss: 2.439978391051365
Validation loss: 2.6636278654791092

Epoch: 6| Step: 8
Training loss: 1.8127680613162893
Validation loss: 2.684234420864057

Epoch: 6| Step: 9
Training loss: 1.5918838196395184
Validation loss: 2.677512161870532

Epoch: 6| Step: 10
Training loss: 1.7119017370447267
Validation loss: 2.708540747740593

Epoch: 6| Step: 11
Training loss: 1.7081461392939465
Validation loss: 2.65566014949663

Epoch: 6| Step: 12
Training loss: 1.4232982177929054
Validation loss: 2.708030894567672

Epoch: 6| Step: 13
Training loss: 1.230542668135655
Validation loss: 2.6959854472449085

Epoch: 514| Step: 0
Training loss: 2.3719458769208863
Validation loss: 2.6920402200846514

Epoch: 6| Step: 1
Training loss: 1.9799884763054785
Validation loss: 2.6931766807158204

Epoch: 6| Step: 2
Training loss: 1.0284314217818156
Validation loss: 2.611655104841297

Epoch: 6| Step: 3
Training loss: 1.4441852194329383
Validation loss: 2.663500330434502

Epoch: 6| Step: 4
Training loss: 1.734631562373055
Validation loss: 2.6895697432251287

Epoch: 6| Step: 5
Training loss: 1.6075200622160974
Validation loss: 2.6328738937457046

Epoch: 6| Step: 6
Training loss: 1.67701373538339
Validation loss: 2.7083298067080976

Epoch: 6| Step: 7
Training loss: 1.8954517134118654
Validation loss: 2.647928785153383

Epoch: 6| Step: 8
Training loss: 1.3826605072111136
Validation loss: 2.6292174154121084

Epoch: 6| Step: 9
Training loss: 1.8818365709732328
Validation loss: 2.6690788430900154

Epoch: 6| Step: 10
Training loss: 1.7482031043794617
Validation loss: 2.645587578999485

Epoch: 6| Step: 11
Training loss: 1.3321679456270294
Validation loss: 2.6305709863392277

Epoch: 6| Step: 12
Training loss: 1.4719443788800586
Validation loss: 2.563269300857055

Epoch: 6| Step: 13
Training loss: 1.908910364535468
Validation loss: 2.649007458282711

Epoch: 515| Step: 0
Training loss: 1.8911059059572488
Validation loss: 2.644194127081434

Epoch: 6| Step: 1
Training loss: 1.0298209258768145
Validation loss: 2.627477160687703

Epoch: 6| Step: 2
Training loss: 1.6721546973025
Validation loss: 2.698242354720252

Epoch: 6| Step: 3
Training loss: 1.4092480807451189
Validation loss: 2.5869439371160423

Epoch: 6| Step: 4
Training loss: 1.9409228822657931
Validation loss: 2.693751374101513

Epoch: 6| Step: 5
Training loss: 1.7596522219547317
Validation loss: 2.605171671885098

Epoch: 6| Step: 6
Training loss: 1.5094747917089604
Validation loss: 2.6759470500915667

Epoch: 6| Step: 7
Training loss: 1.4805404122353307
Validation loss: 2.672890410292201

Epoch: 6| Step: 8
Training loss: 2.4060468711822063
Validation loss: 2.6322961354867935

Epoch: 6| Step: 9
Training loss: 1.3427440515250417
Validation loss: 2.642537408388682

Epoch: 6| Step: 10
Training loss: 1.7251993727530974
Validation loss: 2.590665824722148

Epoch: 6| Step: 11
Training loss: 1.6116744715367832
Validation loss: 2.728023963027691

Epoch: 6| Step: 12
Training loss: 1.1138915413634403
Validation loss: 2.6603641871749497

Epoch: 6| Step: 13
Training loss: 1.8839104328044223
Validation loss: 2.643376956584341

Epoch: 516| Step: 0
Training loss: 1.1676861475329403
Validation loss: 2.6206991577416767

Epoch: 6| Step: 1
Training loss: 1.6093317414923514
Validation loss: 2.593789851641965

Epoch: 6| Step: 2
Training loss: 1.1750042144212829
Validation loss: 2.72048444518155

Epoch: 6| Step: 3
Training loss: 2.1298057965500203
Validation loss: 2.582472991054027

Epoch: 6| Step: 4
Training loss: 1.6720362790474756
Validation loss: 2.6203938487725833

Epoch: 6| Step: 5
Training loss: 1.7759325398529073
Validation loss: 2.640467428908995

Epoch: 6| Step: 6
Training loss: 1.695362354020176
Validation loss: 2.7211241313075396

Epoch: 6| Step: 7
Training loss: 1.5175951707587174
Validation loss: 2.6620856443769445

Epoch: 6| Step: 8
Training loss: 1.611124365668017
Validation loss: 2.6625185173068986

Epoch: 6| Step: 9
Training loss: 2.1337622459699346
Validation loss: 2.7592705209062127

Epoch: 6| Step: 10
Training loss: 1.600663169873438
Validation loss: 2.6040196616406486

Epoch: 6| Step: 11
Training loss: 1.5517874655462063
Validation loss: 2.680441094695537

Epoch: 6| Step: 12
Training loss: 1.6947939031203632
Validation loss: 2.5777017474041735

Epoch: 6| Step: 13
Training loss: 2.270767374276505
Validation loss: 2.6422632432393565

Epoch: 517| Step: 0
Training loss: 1.6746707250997444
Validation loss: 2.6665915006252363

Epoch: 6| Step: 1
Training loss: 1.2938974969054422
Validation loss: 2.624153914973774

Epoch: 6| Step: 2
Training loss: 1.0045292921072422
Validation loss: 2.640135611294944

Epoch: 6| Step: 3
Training loss: 1.7201785306538353
Validation loss: 2.68031420519024

Epoch: 6| Step: 4
Training loss: 1.64986506112619
Validation loss: 2.6626913042103055

Epoch: 6| Step: 5
Training loss: 1.3292089638910864
Validation loss: 2.6217589383310083

Epoch: 6| Step: 6
Training loss: 1.6665988987814542
Validation loss: 2.6892353625963494

Epoch: 6| Step: 7
Training loss: 1.7848821717596457
Validation loss: 2.6160243312766256

Epoch: 6| Step: 8
Training loss: 2.2991413172114474
Validation loss: 2.6318936691330967

Epoch: 6| Step: 9
Training loss: 1.5515743504865922
Validation loss: 2.6908731052026464

Epoch: 6| Step: 10
Training loss: 1.6483345180361932
Validation loss: 2.5835919014269932

Epoch: 6| Step: 11
Training loss: 1.6524569425297209
Validation loss: 2.6843421738916815

Epoch: 6| Step: 12
Training loss: 1.8370339224211008
Validation loss: 2.715020568665649

Epoch: 6| Step: 13
Training loss: 1.1574623865562195
Validation loss: 2.5981594242625192

Epoch: 518| Step: 0
Training loss: 1.154345412936242
Validation loss: 2.595918551194311

Epoch: 6| Step: 1
Training loss: 1.5938004878405871
Validation loss: 2.613028404462314

Epoch: 6| Step: 2
Training loss: 2.008624079804314
Validation loss: 2.6763359403276357

Epoch: 6| Step: 3
Training loss: 1.6801478974773205
Validation loss: 2.664757659260603

Epoch: 6| Step: 4
Training loss: 1.91869413561683
Validation loss: 2.699172264940553

Epoch: 6| Step: 5
Training loss: 1.3459780208811016
Validation loss: 2.683796642597448

Epoch: 6| Step: 6
Training loss: 2.1235766412257573
Validation loss: 2.6882556388121275

Epoch: 6| Step: 7
Training loss: 1.0460591909499024
Validation loss: 2.6035759992254865

Epoch: 6| Step: 8
Training loss: 1.9205822822644174
Validation loss: 2.6103809380924248

Epoch: 6| Step: 9
Training loss: 1.6172891483519052
Validation loss: 2.624670004037674

Epoch: 6| Step: 10
Training loss: 1.7428244209121255
Validation loss: 2.616717997524881

Epoch: 6| Step: 11
Training loss: 1.2820371675325706
Validation loss: 2.6815411287130004

Epoch: 6| Step: 12
Training loss: 1.3677307793353233
Validation loss: 2.711951787329365

Epoch: 6| Step: 13
Training loss: 1.9043476430532364
Validation loss: 2.6801398957426166

Epoch: 519| Step: 0
Training loss: 1.6884769155083856
Validation loss: 2.5876041409032227

Epoch: 6| Step: 1
Training loss: 2.1331192187307204
Validation loss: 2.6181410263290483

Epoch: 6| Step: 2
Training loss: 1.3519721320005738
Validation loss: 2.5993313181517474

Epoch: 6| Step: 3
Training loss: 1.117056138645402
Validation loss: 2.5335669669926215

Epoch: 6| Step: 4
Training loss: 1.217261554781479
Validation loss: 2.6631046534285363

Epoch: 6| Step: 5
Training loss: 1.78565688177213
Validation loss: 2.6207152172574113

Epoch: 6| Step: 6
Training loss: 1.722928879804887
Validation loss: 2.6019604052298084

Epoch: 6| Step: 7
Training loss: 1.2301249674760326
Validation loss: 2.6663062335303263

Epoch: 6| Step: 8
Training loss: 1.8081758152202896
Validation loss: 2.6017007714335323

Epoch: 6| Step: 9
Training loss: 1.4011540373748066
Validation loss: 2.6865503245824205

Epoch: 6| Step: 10
Training loss: 1.586095942958999
Validation loss: 2.6576014951342306

Epoch: 6| Step: 11
Training loss: 2.038789226591981
Validation loss: 2.73617688603436

Epoch: 6| Step: 12
Training loss: 1.8355722266908496
Validation loss: 2.749585382373865

Epoch: 6| Step: 13
Training loss: 1.7877917045046603
Validation loss: 2.6935839193514504

Epoch: 520| Step: 0
Training loss: 1.5032733328547057
Validation loss: 2.687955590198775

Epoch: 6| Step: 1
Training loss: 1.630533480490283
Validation loss: 2.6563092798787995

Epoch: 6| Step: 2
Training loss: 1.8402440633824446
Validation loss: 2.6779260953962063

Epoch: 6| Step: 3
Training loss: 1.3732611758910895
Validation loss: 2.7489586962709938

Epoch: 6| Step: 4
Training loss: 2.5239341412459484
Validation loss: 2.652990705420405

Epoch: 6| Step: 5
Training loss: 1.5429590152481678
Validation loss: 2.750465523330628

Epoch: 6| Step: 6
Training loss: 1.6507084106031378
Validation loss: 2.6720273945248234

Epoch: 6| Step: 7
Training loss: 1.360028778360723
Validation loss: 2.7537704044449445

Epoch: 6| Step: 8
Training loss: 1.3190159949749263
Validation loss: 2.683131730334076

Epoch: 6| Step: 9
Training loss: 1.190675204762955
Validation loss: 2.7006608471026046

Epoch: 6| Step: 10
Training loss: 1.0741152626820598
Validation loss: 2.717286246413891

Epoch: 6| Step: 11
Training loss: 1.96688827408347
Validation loss: 2.6522207199429624

Epoch: 6| Step: 12
Training loss: 1.5242307505093642
Validation loss: 2.6370946667076267

Epoch: 6| Step: 13
Training loss: 2.4393338860720273
Validation loss: 2.7056312264195665

Epoch: 521| Step: 0
Training loss: 1.5307281539133137
Validation loss: 2.7493358166101585

Epoch: 6| Step: 1
Training loss: 1.846776192179457
Validation loss: 2.6914122680671078

Epoch: 6| Step: 2
Training loss: 1.7434249383528895
Validation loss: 2.6517481237426064

Epoch: 6| Step: 3
Training loss: 1.6657815569791554
Validation loss: 2.6441346182488696

Epoch: 6| Step: 4
Training loss: 2.2885187434103376
Validation loss: 2.6405740786280427

Epoch: 6| Step: 5
Training loss: 1.39909598761403
Validation loss: 2.6417288912404167

Epoch: 6| Step: 6
Training loss: 1.4808335471309635
Validation loss: 2.72118264892414

Epoch: 6| Step: 7
Training loss: 1.5757407126936007
Validation loss: 2.6237774701023375

Epoch: 6| Step: 8
Training loss: 1.3338840608872644
Validation loss: 2.7110368403626994

Epoch: 6| Step: 9
Training loss: 1.9850927541667325
Validation loss: 2.6830610879948376

Epoch: 6| Step: 10
Training loss: 1.4976664511463025
Validation loss: 2.671419700848269

Epoch: 6| Step: 11
Training loss: 1.647119799955818
Validation loss: 2.693429214224196

Epoch: 6| Step: 12
Training loss: 1.5323305793694861
Validation loss: 2.6320846757566208

Epoch: 6| Step: 13
Training loss: 1.0090996263277463
Validation loss: 2.6390020775461043

Epoch: 522| Step: 0
Training loss: 1.5056451429869995
Validation loss: 2.693541829418855

Epoch: 6| Step: 1
Training loss: 1.5604654417406825
Validation loss: 2.6983811914587643

Epoch: 6| Step: 2
Training loss: 1.684775378143503
Validation loss: 2.662676838092839

Epoch: 6| Step: 3
Training loss: 1.7839152156286782
Validation loss: 2.6507792993439363

Epoch: 6| Step: 4
Training loss: 1.8867701805797523
Validation loss: 2.6236444372802454

Epoch: 6| Step: 5
Training loss: 1.9189053053240488
Validation loss: 2.706274795712297

Epoch: 6| Step: 6
Training loss: 1.8500970763434363
Validation loss: 2.6110633814498883

Epoch: 6| Step: 7
Training loss: 1.7245764723822015
Validation loss: 2.680471505965915

Epoch: 6| Step: 8
Training loss: 1.680255598651746
Validation loss: 2.678571345362977

Epoch: 6| Step: 9
Training loss: 2.230615935003919
Validation loss: 2.6829739438924043

Epoch: 6| Step: 10
Training loss: 1.0182102458526021
Validation loss: 2.5697294450952732

Epoch: 6| Step: 11
Training loss: 1.300030099080173
Validation loss: 2.684698078458969

Epoch: 6| Step: 12
Training loss: 1.7850078629606365
Validation loss: 2.696502627290644

Epoch: 6| Step: 13
Training loss: 1.612980036290947
Validation loss: 2.667656653848079

Epoch: 523| Step: 0
Training loss: 1.3763474018162893
Validation loss: 2.616487089816274

Epoch: 6| Step: 1
Training loss: 1.3531931483350963
Validation loss: 2.5682603094299785

Epoch: 6| Step: 2
Training loss: 2.092390615505146
Validation loss: 2.638692553703555

Epoch: 6| Step: 3
Training loss: 1.4295035488835808
Validation loss: 2.674959985784326

Epoch: 6| Step: 4
Training loss: 2.128448157064675
Validation loss: 2.650287769424524

Epoch: 6| Step: 5
Training loss: 1.4670966562050611
Validation loss: 2.671751608497338

Epoch: 6| Step: 6
Training loss: 1.6420821485472383
Validation loss: 2.661697627060801

Epoch: 6| Step: 7
Training loss: 1.6940928347977888
Validation loss: 2.662492868438079

Epoch: 6| Step: 8
Training loss: 1.7515137800915486
Validation loss: 2.6571242108141373

Epoch: 6| Step: 9
Training loss: 1.2932708940394382
Validation loss: 2.6913060050067483

Epoch: 6| Step: 10
Training loss: 1.3144722606972183
Validation loss: 2.6509157303946487

Epoch: 6| Step: 11
Training loss: 1.9299078441023823
Validation loss: 2.7004061351680586

Epoch: 6| Step: 12
Training loss: 1.6018139153367519
Validation loss: 2.7040435834928425

Epoch: 6| Step: 13
Training loss: 1.8474268055045584
Validation loss: 2.7239435849188225

Epoch: 524| Step: 0
Training loss: 1.2372386887673648
Validation loss: 2.6594172820666278

Epoch: 6| Step: 1
Training loss: 1.7037991930436123
Validation loss: 2.6496756452082595

Epoch: 6| Step: 2
Training loss: 2.092653813149574
Validation loss: 2.5651145635435486

Epoch: 6| Step: 3
Training loss: 1.645566202367225
Validation loss: 2.6526395665478937

Epoch: 6| Step: 4
Training loss: 1.5764935057772786
Validation loss: 2.6809508914690823

Epoch: 6| Step: 5
Training loss: 2.1296914988513103
Validation loss: 2.598766537741909

Epoch: 6| Step: 6
Training loss: 1.40404846795697
Validation loss: 2.6030532510895075

Epoch: 6| Step: 7
Training loss: 1.5466504174782025
Validation loss: 2.6275549685347004

Epoch: 6| Step: 8
Training loss: 1.5771974916181322
Validation loss: 2.6799332452127285

Epoch: 6| Step: 9
Training loss: 1.4010876313602703
Validation loss: 2.6166646827934255

Epoch: 6| Step: 10
Training loss: 1.8468766936989907
Validation loss: 2.683996327721333

Epoch: 6| Step: 11
Training loss: 1.166024724007892
Validation loss: 2.5659552998162645

Epoch: 6| Step: 12
Training loss: 1.5925446982825417
Validation loss: 2.763881060506969

Epoch: 6| Step: 13
Training loss: 2.0269152826146257
Validation loss: 2.6254458441897826

Epoch: 525| Step: 0
Training loss: 1.459293685052676
Validation loss: 2.6679643961764414

Epoch: 6| Step: 1
Training loss: 2.6152234351432875
Validation loss: 2.6716760929422874

Epoch: 6| Step: 2
Training loss: 1.6723860200324565
Validation loss: 2.6498323485034723

Epoch: 6| Step: 3
Training loss: 1.246552672826781
Validation loss: 2.594917859750455

Epoch: 6| Step: 4
Training loss: 1.467992221874035
Validation loss: 2.634897656550545

Epoch: 6| Step: 5
Training loss: 1.2016413073745198
Validation loss: 2.7058329023988725

Epoch: 6| Step: 6
Training loss: 1.3409126844490227
Validation loss: 2.6385218708512888

Epoch: 6| Step: 7
Training loss: 1.5720487646445356
Validation loss: 2.6178177367521123

Epoch: 6| Step: 8
Training loss: 1.5869233022567548
Validation loss: 2.6861342574968394

Epoch: 6| Step: 9
Training loss: 1.8893955110729392
Validation loss: 2.640740413610747

Epoch: 6| Step: 10
Training loss: 1.8719192627018448
Validation loss: 2.687517244780174

Epoch: 6| Step: 11
Training loss: 1.1438150606255446
Validation loss: 2.5784606516221364

Epoch: 6| Step: 12
Training loss: 1.607159320807522
Validation loss: 2.5347347824662787

Epoch: 6| Step: 13
Training loss: 1.5472766855601026
Validation loss: 2.610122250434841

Epoch: 526| Step: 0
Training loss: 1.6878009103999716
Validation loss: 2.6693774255118488

Epoch: 6| Step: 1
Training loss: 1.1882898815676706
Validation loss: 2.654678496094952

Epoch: 6| Step: 2
Training loss: 1.4138248307098595
Validation loss: 2.65914319326872

Epoch: 6| Step: 3
Training loss: 1.390073774150119
Validation loss: 2.6759051263199414

Epoch: 6| Step: 4
Training loss: 1.506032258436767
Validation loss: 2.695517675702868

Epoch: 6| Step: 5
Training loss: 2.722452996218644
Validation loss: 2.69461401398169

Epoch: 6| Step: 6
Training loss: 1.3587709597573894
Validation loss: 2.608574376793526

Epoch: 6| Step: 7
Training loss: 1.375847381960614
Validation loss: 2.64472986539007

Epoch: 6| Step: 8
Training loss: 1.4158994429707854
Validation loss: 2.6244674402171015

Epoch: 6| Step: 9
Training loss: 1.6024921231366367
Validation loss: 2.652249351492671

Epoch: 6| Step: 10
Training loss: 1.3460595443727852
Validation loss: 2.660547119786981

Epoch: 6| Step: 11
Training loss: 1.6326358097245155
Validation loss: 2.636567661418455

Epoch: 6| Step: 12
Training loss: 1.3702635683481659
Validation loss: 2.648191150597841

Epoch: 6| Step: 13
Training loss: 1.6297891908776607
Validation loss: 2.6185520357402225

Epoch: 527| Step: 0
Training loss: 1.7995774885846552
Validation loss: 2.798726959858414

Epoch: 6| Step: 1
Training loss: 1.252574034689948
Validation loss: 2.6684075320831857

Epoch: 6| Step: 2
Training loss: 1.4156230092824114
Validation loss: 2.7407539677356962

Epoch: 6| Step: 3
Training loss: 1.565993256955105
Validation loss: 2.6436990590704013

Epoch: 6| Step: 4
Training loss: 2.513540031810934
Validation loss: 2.690678845857072

Epoch: 6| Step: 5
Training loss: 1.708755565039859
Validation loss: 2.707200144745379

Epoch: 6| Step: 6
Training loss: 1.3693960172014468
Validation loss: 2.7322028851797273

Epoch: 6| Step: 7
Training loss: 1.870957339735785
Validation loss: 2.6674167676605087

Epoch: 6| Step: 8
Training loss: 1.7232331501502085
Validation loss: 2.6521558263545972

Epoch: 6| Step: 9
Training loss: 1.3843667299182911
Validation loss: 2.6301417058552876

Epoch: 6| Step: 10
Training loss: 1.272605202753468
Validation loss: 2.6458991836002768

Epoch: 6| Step: 11
Training loss: 1.3546226565143715
Validation loss: 2.703452425304338

Epoch: 6| Step: 12
Training loss: 1.288470508005519
Validation loss: 2.6303357451159717

Epoch: 6| Step: 13
Training loss: 1.218967662839253
Validation loss: 2.6504094576601247

Epoch: 528| Step: 0
Training loss: 2.469187251131907
Validation loss: 2.690941395092884

Epoch: 6| Step: 1
Training loss: 1.472215338556923
Validation loss: 2.5636973631227082

Epoch: 6| Step: 2
Training loss: 1.6523312687684264
Validation loss: 2.6848640440410447

Epoch: 6| Step: 3
Training loss: 0.8111846620671849
Validation loss: 2.649676193797704

Epoch: 6| Step: 4
Training loss: 1.631014477326993
Validation loss: 2.6752946049876374

Epoch: 6| Step: 5
Training loss: 1.9178383466282052
Validation loss: 2.663620166734347

Epoch: 6| Step: 6
Training loss: 0.9240326282057856
Validation loss: 2.6828605009664197

Epoch: 6| Step: 7
Training loss: 1.0319950995513723
Validation loss: 2.6069141436360486

Epoch: 6| Step: 8
Training loss: 1.4215404410337347
Validation loss: 2.6221435258004595

Epoch: 6| Step: 9
Training loss: 1.5750282042869317
Validation loss: 2.727052753063039

Epoch: 6| Step: 10
Training loss: 1.58613863266233
Validation loss: 2.722134897082756

Epoch: 6| Step: 11
Training loss: 2.101554785505125
Validation loss: 2.6548144385171173

Epoch: 6| Step: 12
Training loss: 1.7428431624269465
Validation loss: 2.5264746608303668

Epoch: 6| Step: 13
Training loss: 1.3809024097259996
Validation loss: 2.7063216134690813

Epoch: 529| Step: 0
Training loss: 1.646595870798587
Validation loss: 2.694699285159581

Epoch: 6| Step: 1
Training loss: 1.445645433175121
Validation loss: 2.6664577262557265

Epoch: 6| Step: 2
Training loss: 1.5449022757231035
Validation loss: 2.6419739432664975

Epoch: 6| Step: 3
Training loss: 1.3997271680650951
Validation loss: 2.5935054564439284

Epoch: 6| Step: 4
Training loss: 1.4472394315380184
Validation loss: 2.656281635016419

Epoch: 6| Step: 5
Training loss: 1.061391139625555
Validation loss: 2.6947206936248507

Epoch: 6| Step: 6
Training loss: 1.8787744043609094
Validation loss: 2.6975749816938084

Epoch: 6| Step: 7
Training loss: 1.9945696781100883
Validation loss: 2.6214275564150893

Epoch: 6| Step: 8
Training loss: 1.8853679109736126
Validation loss: 2.6722752985404967

Epoch: 6| Step: 9
Training loss: 1.39060914105577
Validation loss: 2.6736027705252425

Epoch: 6| Step: 10
Training loss: 1.325823596284806
Validation loss: 2.6387101300855424

Epoch: 6| Step: 11
Training loss: 1.7420296362273124
Validation loss: 2.7874421572660686

Epoch: 6| Step: 12
Training loss: 1.2357086509903725
Validation loss: 2.6828324330850437

Epoch: 6| Step: 13
Training loss: 2.9402002139265333
Validation loss: 2.6987078671319638

Epoch: 530| Step: 0
Training loss: 1.4149766359321148
Validation loss: 2.6780439804457146

Epoch: 6| Step: 1
Training loss: 1.715029626039906
Validation loss: 2.6387934829601023

Epoch: 6| Step: 2
Training loss: 2.007135536867028
Validation loss: 2.7710675219162755

Epoch: 6| Step: 3
Training loss: 1.4972168215573838
Validation loss: 2.641168954220786

Epoch: 6| Step: 4
Training loss: 1.5420531054900046
Validation loss: 2.7431299472529527

Epoch: 6| Step: 5
Training loss: 1.4096122389778414
Validation loss: 2.6315375125215787

Epoch: 6| Step: 6
Training loss: 1.8803456081108527
Validation loss: 2.6529953012391077

Epoch: 6| Step: 7
Training loss: 0.964797509201197
Validation loss: 2.6431733473109076

Epoch: 6| Step: 8
Training loss: 2.231139821984028
Validation loss: 2.5692355515487817

Epoch: 6| Step: 9
Training loss: 1.8146728119831357
Validation loss: 2.6334039123607575

Epoch: 6| Step: 10
Training loss: 1.5722904937862423
Validation loss: 2.6381682391690457

Epoch: 6| Step: 11
Training loss: 1.2554669990835936
Validation loss: 2.724205784334355

Epoch: 6| Step: 12
Training loss: 1.7570860315232355
Validation loss: 2.550918958053861

Epoch: 6| Step: 13
Training loss: 1.673965715519837
Validation loss: 2.7474975890574207

Epoch: 531| Step: 0
Training loss: 1.2801915425543735
Validation loss: 2.6105169477560097

Epoch: 6| Step: 1
Training loss: 1.3263679101071604
Validation loss: 2.630513974153223

Epoch: 6| Step: 2
Training loss: 1.7096296912216304
Validation loss: 2.603046423052536

Epoch: 6| Step: 3
Training loss: 1.88287967546221
Validation loss: 2.7100466708200632

Epoch: 6| Step: 4
Training loss: 1.6087778705829594
Validation loss: 2.6301677715756293

Epoch: 6| Step: 5
Training loss: 2.111725013828055
Validation loss: 2.630838969940117

Epoch: 6| Step: 6
Training loss: 1.7904692204271133
Validation loss: 2.688201540867154

Epoch: 6| Step: 7
Training loss: 1.4327568084975701
Validation loss: 2.7471825662355194

Epoch: 6| Step: 8
Training loss: 1.3583499946430513
Validation loss: 2.6578800457486285

Epoch: 6| Step: 9
Training loss: 1.457865049471975
Validation loss: 2.6608370465625

Epoch: 6| Step: 10
Training loss: 1.650089538919084
Validation loss: 2.6691083560999074

Epoch: 6| Step: 11
Training loss: 1.6173293194344933
Validation loss: 2.6346218945905644

Epoch: 6| Step: 12
Training loss: 1.5411687854614633
Validation loss: 2.6344135175972596

Epoch: 6| Step: 13
Training loss: 1.9539800374505802
Validation loss: 2.7095101733264904

Epoch: 532| Step: 0
Training loss: 1.7066742198498797
Validation loss: 2.6766227944341447

Epoch: 6| Step: 1
Training loss: 2.4229870611861584
Validation loss: 2.692337123524501

Epoch: 6| Step: 2
Training loss: 1.223778791312974
Validation loss: 2.736122908239808

Epoch: 6| Step: 3
Training loss: 1.3329299177389777
Validation loss: 2.691569609361929

Epoch: 6| Step: 4
Training loss: 1.4419068498404963
Validation loss: 2.703351483331203

Epoch: 6| Step: 5
Training loss: 2.1142363866552922
Validation loss: 2.7303265769261422

Epoch: 6| Step: 6
Training loss: 0.9518659436702409
Validation loss: 2.6192249911772114

Epoch: 6| Step: 7
Training loss: 1.7364726398003005
Validation loss: 2.665586388938532

Epoch: 6| Step: 8
Training loss: 1.4610745778772352
Validation loss: 2.625849246087072

Epoch: 6| Step: 9
Training loss: 1.6005515280487563
Validation loss: 2.6685565835458

Epoch: 6| Step: 10
Training loss: 1.3890293696671694
Validation loss: 2.6573689352180385

Epoch: 6| Step: 11
Training loss: 1.2165649584929825
Validation loss: 2.641670136239014

Epoch: 6| Step: 12
Training loss: 1.5739849664777221
Validation loss: 2.7387180781289047

Epoch: 6| Step: 13
Training loss: 1.7028949127164286
Validation loss: 2.6140460194476898

Epoch: 533| Step: 0
Training loss: 1.027334176950853
Validation loss: 2.694850007489449

Epoch: 6| Step: 1
Training loss: 2.6259084673557576
Validation loss: 2.6493478906030887

Epoch: 6| Step: 2
Training loss: 1.5598002188476847
Validation loss: 2.5866196146680545

Epoch: 6| Step: 3
Training loss: 1.2569535444198365
Validation loss: 2.735441841109802

Epoch: 6| Step: 4
Training loss: 1.596067725448817
Validation loss: 2.645738173803396

Epoch: 6| Step: 5
Training loss: 1.4310571332358486
Validation loss: 2.687228186927968

Epoch: 6| Step: 6
Training loss: 1.820329199456494
Validation loss: 2.6330507310085816

Epoch: 6| Step: 7
Training loss: 1.4687688298743107
Validation loss: 2.685763613489462

Epoch: 6| Step: 8
Training loss: 1.3796922210578024
Validation loss: 2.5631091746625403

Epoch: 6| Step: 9
Training loss: 1.389630079650791
Validation loss: 2.7038046177937316

Epoch: 6| Step: 10
Training loss: 1.6435456935842745
Validation loss: 2.674300873281808

Epoch: 6| Step: 11
Training loss: 1.2122873965407392
Validation loss: 2.662803730944704

Epoch: 6| Step: 12
Training loss: 1.7872783310032478
Validation loss: 2.690138357166154

Epoch: 6| Step: 13
Training loss: 1.7749548651101246
Validation loss: 2.654788398477778

Epoch: 534| Step: 0
Training loss: 1.831767829875926
Validation loss: 2.6207806805068863

Epoch: 6| Step: 1
Training loss: 2.4030911407268034
Validation loss: 2.684998237122107

Epoch: 6| Step: 2
Training loss: 1.1905528529778266
Validation loss: 2.6177749486311193

Epoch: 6| Step: 3
Training loss: 1.7067211576544516
Validation loss: 2.6116442471717822

Epoch: 6| Step: 4
Training loss: 1.6730228654811778
Validation loss: 2.5685830305745916

Epoch: 6| Step: 5
Training loss: 1.3494069103515773
Validation loss: 2.6256488050980757

Epoch: 6| Step: 6
Training loss: 1.3074910998360612
Validation loss: 2.6387459888061398

Epoch: 6| Step: 7
Training loss: 1.6578401813119565
Validation loss: 2.712878360958441

Epoch: 6| Step: 8
Training loss: 1.512110459788748
Validation loss: 2.6807483620615646

Epoch: 6| Step: 9
Training loss: 1.439552500385862
Validation loss: 2.706855683828479

Epoch: 6| Step: 10
Training loss: 1.6303584443064618
Validation loss: 2.750742091549155

Epoch: 6| Step: 11
Training loss: 1.4209325832183721
Validation loss: 2.6709072382772705

Epoch: 6| Step: 12
Training loss: 1.2289637489714702
Validation loss: 2.689801398569901

Epoch: 6| Step: 13
Training loss: 1.2348761205281027
Validation loss: 2.556154606859453

Epoch: 535| Step: 0
Training loss: 1.1254368040017333
Validation loss: 2.615992925802443

Epoch: 6| Step: 1
Training loss: 1.8234281276537196
Validation loss: 2.7098271982083797

Epoch: 6| Step: 2
Training loss: 1.596503777102558
Validation loss: 2.691794018247302

Epoch: 6| Step: 3
Training loss: 2.138967164438972
Validation loss: 2.649793505154633

Epoch: 6| Step: 4
Training loss: 1.318242498797889
Validation loss: 2.6085343746123337

Epoch: 6| Step: 5
Training loss: 1.1125730169101455
Validation loss: 2.710078298415919

Epoch: 6| Step: 6
Training loss: 1.6239722009262054
Validation loss: 2.738744092416063

Epoch: 6| Step: 7
Training loss: 1.8051778284112343
Validation loss: 2.6639452136107273

Epoch: 6| Step: 8
Training loss: 1.3007813416443754
Validation loss: 2.635595973549828

Epoch: 6| Step: 9
Training loss: 1.0088389292944686
Validation loss: 2.713391513357423

Epoch: 6| Step: 10
Training loss: 1.6447078945222562
Validation loss: 2.626247119523137

Epoch: 6| Step: 11
Training loss: 1.814853587064386
Validation loss: 2.5188796030993847

Epoch: 6| Step: 12
Training loss: 2.3577796645560922
Validation loss: 2.73086329851749

Epoch: 6| Step: 13
Training loss: 1.405796020131726
Validation loss: 2.6664797104651674

Epoch: 536| Step: 0
Training loss: 1.6822383230469915
Validation loss: 2.677425408792008

Epoch: 6| Step: 1
Training loss: 1.5957120897468495
Validation loss: 2.7062444072647507

Epoch: 6| Step: 2
Training loss: 1.9742759173999749
Validation loss: 2.6241015797820206

Epoch: 6| Step: 3
Training loss: 1.654397756479834
Validation loss: 2.667126139798198

Epoch: 6| Step: 4
Training loss: 1.3268061653355077
Validation loss: 2.646421335343854

Epoch: 6| Step: 5
Training loss: 1.737066843392708
Validation loss: 2.6937056026983246

Epoch: 6| Step: 6
Training loss: 1.1459373195742717
Validation loss: 2.619124993849498

Epoch: 6| Step: 7
Training loss: 1.4080804567703677
Validation loss: 2.6830249443945546

Epoch: 6| Step: 8
Training loss: 1.6250882491577678
Validation loss: 2.7069944216349056

Epoch: 6| Step: 9
Training loss: 1.5970378695627812
Validation loss: 2.6365484877730196

Epoch: 6| Step: 10
Training loss: 1.7460602964059697
Validation loss: 2.6652633899703213

Epoch: 6| Step: 11
Training loss: 1.5426206558249211
Validation loss: 2.7721566028876157

Epoch: 6| Step: 12
Training loss: 1.3704103685007942
Validation loss: 2.5706816886048

Epoch: 6| Step: 13
Training loss: 1.2852060140233357
Validation loss: 2.672144182739643

Epoch: 537| Step: 0
Training loss: 2.296754898771952
Validation loss: 2.730597874980321

Epoch: 6| Step: 1
Training loss: 1.7355336623426207
Validation loss: 2.7380856979597286

Epoch: 6| Step: 2
Training loss: 1.0050105689332838
Validation loss: 2.6329365012142074

Epoch: 6| Step: 3
Training loss: 1.6076737087242374
Validation loss: 2.668300296190804

Epoch: 6| Step: 4
Training loss: 1.6114087633704977
Validation loss: 2.847091213853581

Epoch: 6| Step: 5
Training loss: 0.9988872774620575
Validation loss: 2.7900012017521405

Epoch: 6| Step: 6
Training loss: 1.120176358643089
Validation loss: 2.8033468722778747

Epoch: 6| Step: 7
Training loss: 2.013440981928082
Validation loss: 2.706811638022076

Epoch: 6| Step: 8
Training loss: 1.1033265618599568
Validation loss: 2.6682773988632973

Epoch: 6| Step: 9
Training loss: 1.7059101115535253
Validation loss: 2.7317838077387018

Epoch: 6| Step: 10
Training loss: 1.695409534683408
Validation loss: 2.652707072145769

Epoch: 6| Step: 11
Training loss: 1.4743157302825585
Validation loss: 2.687900244405653

Epoch: 6| Step: 12
Training loss: 1.0583839912505697
Validation loss: 2.6395864291960898

Epoch: 6| Step: 13
Training loss: 2.0824497510839954
Validation loss: 2.595966165753631

Epoch: 538| Step: 0
Training loss: 1.2166609833641218
Validation loss: 2.6523789024678597

Epoch: 6| Step: 1
Training loss: 1.3162037498412589
Validation loss: 2.7154076889448007

Epoch: 6| Step: 2
Training loss: 1.4453063964714874
Validation loss: 2.6594481930573273

Epoch: 6| Step: 3
Training loss: 1.5486469331180075
Validation loss: 2.5929388573583085

Epoch: 6| Step: 4
Training loss: 1.8956080571847185
Validation loss: 2.7174445037574295

Epoch: 6| Step: 5
Training loss: 1.6933760592684775
Validation loss: 2.6591158420305248

Epoch: 6| Step: 6
Training loss: 1.2439620100887105
Validation loss: 2.6070753189766633

Epoch: 6| Step: 7
Training loss: 1.4183479411579127
Validation loss: 2.6800117536864683

Epoch: 6| Step: 8
Training loss: 1.73551889448945
Validation loss: 2.6797867589786395

Epoch: 6| Step: 9
Training loss: 1.3524203361981544
Validation loss: 2.6877901469623584

Epoch: 6| Step: 10
Training loss: 1.3823601796530032
Validation loss: 2.584714352345759

Epoch: 6| Step: 11
Training loss: 2.2714419701276163
Validation loss: 2.6744404256672594

Epoch: 6| Step: 12
Training loss: 1.8816685664007138
Validation loss: 2.6552741558246544

Epoch: 6| Step: 13
Training loss: 1.5615524470608968
Validation loss: 2.68363586508326

Epoch: 539| Step: 0
Training loss: 2.401520080787436
Validation loss: 2.6762291591088174

Epoch: 6| Step: 1
Training loss: 2.0544926656154376
Validation loss: 2.6556144296602673

Epoch: 6| Step: 2
Training loss: 1.7032554646489309
Validation loss: 2.632936894581362

Epoch: 6| Step: 3
Training loss: 1.0661100318511842
Validation loss: 2.674231818135721

Epoch: 6| Step: 4
Training loss: 1.3078237061379354
Validation loss: 2.640942090869232

Epoch: 6| Step: 5
Training loss: 2.0525198406045773
Validation loss: 2.6569073572434605

Epoch: 6| Step: 6
Training loss: 1.3916848248117561
Validation loss: 2.6890006896630445

Epoch: 6| Step: 7
Training loss: 1.1273669668068558
Validation loss: 2.655781651900728

Epoch: 6| Step: 8
Training loss: 1.2774466843500012
Validation loss: 2.6934463725004516

Epoch: 6| Step: 9
Training loss: 1.6532247733166197
Validation loss: 2.6372430674010303

Epoch: 6| Step: 10
Training loss: 1.1371990644176713
Validation loss: 2.580639380915126

Epoch: 6| Step: 11
Training loss: 1.9648075290018456
Validation loss: 2.611941219234079

Epoch: 6| Step: 12
Training loss: 1.5114444611971183
Validation loss: 2.5874914042249957

Epoch: 6| Step: 13
Training loss: 0.7611133223483719
Validation loss: 2.6135022756793496

Epoch: 540| Step: 0
Training loss: 1.8150772318946402
Validation loss: 2.733184628477093

Epoch: 6| Step: 1
Training loss: 1.271877339428899
Validation loss: 2.6079725997020056

Epoch: 6| Step: 2
Training loss: 1.6510278679143737
Validation loss: 2.689901930276333

Epoch: 6| Step: 3
Training loss: 1.6357631032944493
Validation loss: 2.597781087555878

Epoch: 6| Step: 4
Training loss: 1.3926856386004227
Validation loss: 2.6521849950759977

Epoch: 6| Step: 5
Training loss: 1.8798412130137534
Validation loss: 2.633230292135945

Epoch: 6| Step: 6
Training loss: 1.2612452607684892
Validation loss: 2.6556248720068383

Epoch: 6| Step: 7
Training loss: 1.1589245149783685
Validation loss: 2.6641540020854175

Epoch: 6| Step: 8
Training loss: 1.4535329922769042
Validation loss: 2.586949629367582

Epoch: 6| Step: 9
Training loss: 2.402111705955446
Validation loss: 2.6999594747661213

Epoch: 6| Step: 10
Training loss: 1.4133282857630822
Validation loss: 2.7333554750076434

Epoch: 6| Step: 11
Training loss: 1.6212579483155036
Validation loss: 2.684480361984209

Epoch: 6| Step: 12
Training loss: 1.6139149010262333
Validation loss: 2.611614485283885

Epoch: 6| Step: 13
Training loss: 1.277075876501487
Validation loss: 2.6175185264653162

Epoch: 541| Step: 0
Training loss: 1.2102001283200798
Validation loss: 2.648431149060483

Epoch: 6| Step: 1
Training loss: 1.9004431283094474
Validation loss: 2.6568653154050117

Epoch: 6| Step: 2
Training loss: 1.178762211984136
Validation loss: 2.6989012588568992

Epoch: 6| Step: 3
Training loss: 1.267643860697991
Validation loss: 2.692339352621367

Epoch: 6| Step: 4
Training loss: 1.4147785544580103
Validation loss: 2.559101998176954

Epoch: 6| Step: 5
Training loss: 1.6616132020272483
Validation loss: 2.615982857880435

Epoch: 6| Step: 6
Training loss: 2.1923367026053118
Validation loss: 2.717723363586069

Epoch: 6| Step: 7
Training loss: 1.217209698495452
Validation loss: 2.6323161474781602

Epoch: 6| Step: 8
Training loss: 1.7765274353056175
Validation loss: 2.628405918698901

Epoch: 6| Step: 9
Training loss: 1.7501991022471455
Validation loss: 2.6976417752728405

Epoch: 6| Step: 10
Training loss: 1.6796291607328768
Validation loss: 2.6680227249069897

Epoch: 6| Step: 11
Training loss: 1.7084366449270556
Validation loss: 2.744895554977443

Epoch: 6| Step: 12
Training loss: 1.5056053966672784
Validation loss: 2.598979741648114

Epoch: 6| Step: 13
Training loss: 1.972264317017014
Validation loss: 2.7158334288687254

Epoch: 542| Step: 0
Training loss: 2.342185960887482
Validation loss: 2.700664123960606

Epoch: 6| Step: 1
Training loss: 1.8183798292015534
Validation loss: 2.677272676137296

Epoch: 6| Step: 2
Training loss: 1.2434143629507617
Validation loss: 2.572832098099923

Epoch: 6| Step: 3
Training loss: 1.2289953705131675
Validation loss: 2.6659631518945917

Epoch: 6| Step: 4
Training loss: 1.5825396439104897
Validation loss: 2.6880403372791903

Epoch: 6| Step: 5
Training loss: 1.255124744887488
Validation loss: 2.686507336230432

Epoch: 6| Step: 6
Training loss: 1.2942883537022563
Validation loss: 2.629667691995481

Epoch: 6| Step: 7
Training loss: 1.5181930651115756
Validation loss: 2.6864556231437313

Epoch: 6| Step: 8
Training loss: 1.6518525099044221
Validation loss: 2.6811055822681062

Epoch: 6| Step: 9
Training loss: 1.396095275024196
Validation loss: 2.6269904518914036

Epoch: 6| Step: 10
Training loss: 1.7440488989825476
Validation loss: 2.752792890404911

Epoch: 6| Step: 11
Training loss: 1.4692164552892388
Validation loss: 2.6139343133394815

Epoch: 6| Step: 12
Training loss: 1.3297851508712684
Validation loss: 2.6617517483962096

Epoch: 6| Step: 13
Training loss: 1.9032818558919562
Validation loss: 2.6177340396464586

Epoch: 543| Step: 0
Training loss: 1.5481564387000284
Validation loss: 2.52470442086517

Epoch: 6| Step: 1
Training loss: 1.0005154473343298
Validation loss: 2.6805705073390533

Epoch: 6| Step: 2
Training loss: 1.5574490351780774
Validation loss: 2.584767040693965

Epoch: 6| Step: 3
Training loss: 2.0977708156563555
Validation loss: 2.7175805265541046

Epoch: 6| Step: 4
Training loss: 1.5620113371609803
Validation loss: 2.547699833534327

Epoch: 6| Step: 5
Training loss: 1.7641891447547395
Validation loss: 2.7269766076114976

Epoch: 6| Step: 6
Training loss: 1.4818228213593443
Validation loss: 2.6020056682653974

Epoch: 6| Step: 7
Training loss: 1.3722047135853008
Validation loss: 2.6509186935180806

Epoch: 6| Step: 8
Training loss: 1.7538117721021578
Validation loss: 2.677032928611545

Epoch: 6| Step: 9
Training loss: 1.4258857584236682
Validation loss: 2.643738907361881

Epoch: 6| Step: 10
Training loss: 1.3735894857945112
Validation loss: 2.623186736235305

Epoch: 6| Step: 11
Training loss: 1.6132850924023552
Validation loss: 2.7012827808516793

Epoch: 6| Step: 12
Training loss: 1.4570755939025386
Validation loss: 2.6308675554941305

Epoch: 6| Step: 13
Training loss: 1.3303735435769624
Validation loss: 2.624810587489616

Epoch: 544| Step: 0
Training loss: 1.2339884961703351
Validation loss: 2.581422837333205

Epoch: 6| Step: 1
Training loss: 1.8503741865372114
Validation loss: 2.715640941807059

Epoch: 6| Step: 2
Training loss: 1.2302423178005226
Validation loss: 2.7082416837597045

Epoch: 6| Step: 3
Training loss: 0.8982946531099064
Validation loss: 2.6238512659669677

Epoch: 6| Step: 4
Training loss: 1.1771743986749075
Validation loss: 2.694596624814758

Epoch: 6| Step: 5
Training loss: 1.2599667883840473
Validation loss: 2.555354971152602

Epoch: 6| Step: 6
Training loss: 1.8166990638900582
Validation loss: 2.634609707980546

Epoch: 6| Step: 7
Training loss: 1.3172952157682194
Validation loss: 2.6375460148436387

Epoch: 6| Step: 8
Training loss: 0.9744581514203041
Validation loss: 2.7114188285405754

Epoch: 6| Step: 9
Training loss: 1.3432579026606555
Validation loss: 2.574345530741421

Epoch: 6| Step: 10
Training loss: 2.370021219279267
Validation loss: 2.719154822818874

Epoch: 6| Step: 11
Training loss: 2.09280647540126
Validation loss: 2.600510254076637

Epoch: 6| Step: 12
Training loss: 1.333682069273007
Validation loss: 2.606432988246369

Epoch: 6| Step: 13
Training loss: 1.1678564215391638
Validation loss: 2.636812974346891

Epoch: 545| Step: 0
Training loss: 1.3449476360919579
Validation loss: 2.7136739327349164

Epoch: 6| Step: 1
Training loss: 1.5623709816118383
Validation loss: 2.6545602132284065

Epoch: 6| Step: 2
Training loss: 1.1163590567392925
Validation loss: 2.7252042088944535

Epoch: 6| Step: 3
Training loss: 1.5776680010826152
Validation loss: 2.5892527465564315

Epoch: 6| Step: 4
Training loss: 1.6605339069528622
Validation loss: 2.6478676320346812

Epoch: 6| Step: 5
Training loss: 1.3522221713891946
Validation loss: 2.6362018202753825

Epoch: 6| Step: 6
Training loss: 1.072711566962898
Validation loss: 2.6504499092199936

Epoch: 6| Step: 7
Training loss: 1.3986238323509885
Validation loss: 2.7295639640033253

Epoch: 6| Step: 8
Training loss: 1.3767241159017816
Validation loss: 2.647794296387912

Epoch: 6| Step: 9
Training loss: 1.2112102078415832
Validation loss: 2.64602349292121

Epoch: 6| Step: 10
Training loss: 1.2383693338828448
Validation loss: 2.5712743074780255

Epoch: 6| Step: 11
Training loss: 2.5858160722234085
Validation loss: 2.6944703067851647

Epoch: 6| Step: 12
Training loss: 0.8866335790120413
Validation loss: 2.703253618791802

Epoch: 6| Step: 13
Training loss: 2.3182998302497007
Validation loss: 2.507030985928863

Epoch: 546| Step: 0
Training loss: 1.5347776455698534
Validation loss: 2.6262845120892635

Epoch: 6| Step: 1
Training loss: 1.34540774975174
Validation loss: 2.6524996742106914

Epoch: 6| Step: 2
Training loss: 1.3667629345661574
Validation loss: 2.6851739874309937

Epoch: 6| Step: 3
Training loss: 1.433803449464241
Validation loss: 2.587151650601229

Epoch: 6| Step: 4
Training loss: 1.391252354759561
Validation loss: 2.670675520238513

Epoch: 6| Step: 5
Training loss: 1.652673422388875
Validation loss: 2.5813979806264826

Epoch: 6| Step: 6
Training loss: 1.5753110971957247
Validation loss: 2.6941964108222605

Epoch: 6| Step: 7
Training loss: 1.7178635131745015
Validation loss: 2.63417844337211

Epoch: 6| Step: 8
Training loss: 1.5816358284042558
Validation loss: 2.6582076442971494

Epoch: 6| Step: 9
Training loss: 1.6262409167142353
Validation loss: 2.7099427523562203

Epoch: 6| Step: 10
Training loss: 2.1661310878899034
Validation loss: 2.645102290351641

Epoch: 6| Step: 11
Training loss: 1.54188209609373
Validation loss: 2.603056522789322

Epoch: 6| Step: 12
Training loss: 1.6599744988976055
Validation loss: 2.593267410479706

Epoch: 6| Step: 13
Training loss: 1.6797214948186023
Validation loss: 2.67064601206805

Epoch: 547| Step: 0
Training loss: 0.8877838057084059
Validation loss: 2.67972389047477

Epoch: 6| Step: 1
Training loss: 2.1819384037837763
Validation loss: 2.717685753776051

Epoch: 6| Step: 2
Training loss: 1.2104691614967948
Validation loss: 2.6563675836913783

Epoch: 6| Step: 3
Training loss: 1.2307567441059308
Validation loss: 2.631078074367178

Epoch: 6| Step: 4
Training loss: 1.632986178127645
Validation loss: 2.540556034762109

Epoch: 6| Step: 5
Training loss: 1.432891257814064
Validation loss: 2.6778456991488726

Epoch: 6| Step: 6
Training loss: 1.6677792014846524
Validation loss: 2.691095183905619

Epoch: 6| Step: 7
Training loss: 1.0811017723133187
Validation loss: 2.6257524149368825

Epoch: 6| Step: 8
Training loss: 1.8298496685920969
Validation loss: 2.646171870498516

Epoch: 6| Step: 9
Training loss: 1.05817762691269
Validation loss: 2.7055079606898413

Epoch: 6| Step: 10
Training loss: 1.4782092080516054
Validation loss: 2.6319652542877616

Epoch: 6| Step: 11
Training loss: 1.8954580026299412
Validation loss: 2.7133308794698294

Epoch: 6| Step: 12
Training loss: 1.5836545551446874
Validation loss: 2.6956061527981485

Epoch: 6| Step: 13
Training loss: 1.4815742170043131
Validation loss: 2.665438811265713

Epoch: 548| Step: 0
Training loss: 1.4811325799299109
Validation loss: 2.6822125896422344

Epoch: 6| Step: 1
Training loss: 1.9560064194618776
Validation loss: 2.6083013447730314

Epoch: 6| Step: 2
Training loss: 1.0639195215901978
Validation loss: 2.6628144464407546

Epoch: 6| Step: 3
Training loss: 1.7770393530116602
Validation loss: 2.672925321318011

Epoch: 6| Step: 4
Training loss: 1.4793511754685253
Validation loss: 2.6872734514251873

Epoch: 6| Step: 5
Training loss: 1.1022222180221244
Validation loss: 2.6718755555453657

Epoch: 6| Step: 6
Training loss: 2.413515491917158
Validation loss: 2.6681229169930925

Epoch: 6| Step: 7
Training loss: 1.02935316015166
Validation loss: 2.6042001416095517

Epoch: 6| Step: 8
Training loss: 1.230482167973095
Validation loss: 2.6420787191465602

Epoch: 6| Step: 9
Training loss: 1.462583135214522
Validation loss: 2.6480590693207335

Epoch: 6| Step: 10
Training loss: 1.5411095342801464
Validation loss: 2.7055856503070665

Epoch: 6| Step: 11
Training loss: 1.9282239545410609
Validation loss: 2.6639527545539434

Epoch: 6| Step: 12
Training loss: 1.6565165755032432
Validation loss: 2.6402092354107576

Epoch: 6| Step: 13
Training loss: 1.4171725473172379
Validation loss: 2.6395686304090655

Epoch: 549| Step: 0
Training loss: 1.440619442612527
Validation loss: 2.6561593355730686

Epoch: 6| Step: 1
Training loss: 1.586648715796558
Validation loss: 2.686042394183026

Epoch: 6| Step: 2
Training loss: 1.1650809115034593
Validation loss: 2.703380495110694

Epoch: 6| Step: 3
Training loss: 1.518766470611805
Validation loss: 2.6941332200900727

Epoch: 6| Step: 4
Training loss: 1.2999467435345191
Validation loss: 2.701064544686262

Epoch: 6| Step: 5
Training loss: 1.7335751037832636
Validation loss: 2.62018405455843

Epoch: 6| Step: 6
Training loss: 1.6633980010820206
Validation loss: 2.7156043397132237

Epoch: 6| Step: 7
Training loss: 1.2692988256290503
Validation loss: 2.7046953702225305

Epoch: 6| Step: 8
Training loss: 2.2526710338627343
Validation loss: 2.6978057139777705

Epoch: 6| Step: 9
Training loss: 1.3640104600695473
Validation loss: 2.672866932685026

Epoch: 6| Step: 10
Training loss: 1.618558514437335
Validation loss: 2.679983296292551

Epoch: 6| Step: 11
Training loss: 0.9237064015239247
Validation loss: 2.665169786696721

Epoch: 6| Step: 12
Training loss: 2.056389977233004
Validation loss: 2.637355105330385

Epoch: 6| Step: 13
Training loss: 1.3470702735621007
Validation loss: 2.6445927458814054

Epoch: 550| Step: 0
Training loss: 1.642584946989029
Validation loss: 2.6883217503689165

Epoch: 6| Step: 1
Training loss: 1.4868802262062435
Validation loss: 2.779435452006101

Epoch: 6| Step: 2
Training loss: 2.558136551171754
Validation loss: 2.675996008867695

Epoch: 6| Step: 3
Training loss: 1.5775142280916337
Validation loss: 2.6377583400773497

Epoch: 6| Step: 4
Training loss: 1.1610229542883816
Validation loss: 2.6481686273307194

Epoch: 6| Step: 5
Training loss: 1.7125071114719614
Validation loss: 2.6651678551904108

Epoch: 6| Step: 6
Training loss: 1.5681264663999595
Validation loss: 2.624327476282622

Epoch: 6| Step: 7
Training loss: 1.1868024082091262
Validation loss: 2.6601199879331907

Epoch: 6| Step: 8
Training loss: 1.538361675432568
Validation loss: 2.7595997718224723

Epoch: 6| Step: 9
Training loss: 1.5301587634522207
Validation loss: 2.6661296740906226

Epoch: 6| Step: 10
Training loss: 1.2092633888334658
Validation loss: 2.6636457296766154

Epoch: 6| Step: 11
Training loss: 1.894506332390905
Validation loss: 2.715892730678468

Epoch: 6| Step: 12
Training loss: 1.511886074850356
Validation loss: 2.5919817617383165

Epoch: 6| Step: 13
Training loss: 1.4013095112804412
Validation loss: 2.6105582148527016

Epoch: 551| Step: 0
Training loss: 1.5986241624116921
Validation loss: 2.676305452369202

Epoch: 6| Step: 1
Training loss: 1.5851763322139987
Validation loss: 2.687436482012047

Epoch: 6| Step: 2
Training loss: 1.1805393604339558
Validation loss: 2.666478241395684

Epoch: 6| Step: 3
Training loss: 1.26751610085458
Validation loss: 2.6308986693984706

Epoch: 6| Step: 4
Training loss: 1.8665044963873458
Validation loss: 2.6087726744976987

Epoch: 6| Step: 5
Training loss: 1.7881971373635501
Validation loss: 2.668809219091025

Epoch: 6| Step: 6
Training loss: 1.1307117846801846
Validation loss: 2.6349591933806833

Epoch: 6| Step: 7
Training loss: 1.49608076204484
Validation loss: 2.640442255187658

Epoch: 6| Step: 8
Training loss: 1.3675951976522214
Validation loss: 2.595041872753222

Epoch: 6| Step: 9
Training loss: 2.284947677614263
Validation loss: 2.6638707249591835

Epoch: 6| Step: 10
Training loss: 1.4448326345226343
Validation loss: 2.610788188750214

Epoch: 6| Step: 11
Training loss: 1.2705454369969438
Validation loss: 2.6116364560470546

Epoch: 6| Step: 12
Training loss: 1.4151286115934707
Validation loss: 2.697709882417183

Epoch: 6| Step: 13
Training loss: 1.0820678264068404
Validation loss: 2.665136623847255

Epoch: 552| Step: 0
Training loss: 1.417331857279179
Validation loss: 2.5978976081822536

Epoch: 6| Step: 1
Training loss: 1.6074905473540937
Validation loss: 2.650824058577791

Epoch: 6| Step: 2
Training loss: 1.5681374132707293
Validation loss: 2.694412310823469

Epoch: 6| Step: 3
Training loss: 1.792996474905639
Validation loss: 2.706595205916193

Epoch: 6| Step: 4
Training loss: 2.311302390446085
Validation loss: 2.6547202466444153

Epoch: 6| Step: 5
Training loss: 1.388731664129669
Validation loss: 2.7375581341928212

Epoch: 6| Step: 6
Training loss: 1.3205858658617278
Validation loss: 2.691208439750263

Epoch: 6| Step: 7
Training loss: 1.5973805980206663
Validation loss: 2.7409390578022697

Epoch: 6| Step: 8
Training loss: 1.1393125638945556
Validation loss: 2.73056433411184

Epoch: 6| Step: 9
Training loss: 1.495337551628577
Validation loss: 2.735061284679456

Epoch: 6| Step: 10
Training loss: 0.9637340078746378
Validation loss: 2.7028473059342857

Epoch: 6| Step: 11
Training loss: 1.6522629449804498
Validation loss: 2.661715742112077

Epoch: 6| Step: 12
Training loss: 1.8006837367468354
Validation loss: 2.725096666108508

Epoch: 6| Step: 13
Training loss: 1.482726295787255
Validation loss: 2.7075856586377

Epoch: 553| Step: 0
Training loss: 2.3278542175528756
Validation loss: 2.626608887292983

Epoch: 6| Step: 1
Training loss: 1.7679189448267403
Validation loss: 2.618681174426768

Epoch: 6| Step: 2
Training loss: 1.0640029375207836
Validation loss: 2.6407455947851552

Epoch: 6| Step: 3
Training loss: 1.0195795391237172
Validation loss: 2.590220073951002

Epoch: 6| Step: 4
Training loss: 1.11722111151225
Validation loss: 2.633703657012047

Epoch: 6| Step: 5
Training loss: 1.1846478995806453
Validation loss: 2.6785620998331456

Epoch: 6| Step: 6
Training loss: 1.5470736597595875
Validation loss: 2.664609736473765

Epoch: 6| Step: 7
Training loss: 1.4443842200823085
Validation loss: 2.7683366575540496

Epoch: 6| Step: 8
Training loss: 1.3862148175190772
Validation loss: 2.6433207705110666

Epoch: 6| Step: 9
Training loss: 1.646559961287691
Validation loss: 2.6173857005162375

Epoch: 6| Step: 10
Training loss: 1.9877993256315698
Validation loss: 2.7058653798330385

Epoch: 6| Step: 11
Training loss: 1.6322931075033984
Validation loss: 2.6457705798340405

Epoch: 6| Step: 12
Training loss: 1.6063100276669882
Validation loss: 2.716503061103749

Epoch: 6| Step: 13
Training loss: 1.1860880739822228
Validation loss: 2.646612321239841

Epoch: 554| Step: 0
Training loss: 1.0839235580841933
Validation loss: 2.7214236994450194

Epoch: 6| Step: 1
Training loss: 1.3347431666600655
Validation loss: 2.7619420120718368

Epoch: 6| Step: 2
Training loss: 1.3895520131910433
Validation loss: 2.6648828349325053

Epoch: 6| Step: 3
Training loss: 1.7790054099315364
Validation loss: 2.709042845396645

Epoch: 6| Step: 4
Training loss: 1.5112463240030543
Validation loss: 2.7640728120384184

Epoch: 6| Step: 5
Training loss: 1.5812075884412333
Validation loss: 2.6986013318077453

Epoch: 6| Step: 6
Training loss: 1.604553184348209
Validation loss: 2.662318222709371

Epoch: 6| Step: 7
Training loss: 1.4000397352982963
Validation loss: 2.608765988199039

Epoch: 6| Step: 8
Training loss: 1.072822912372893
Validation loss: 2.6029684956916626

Epoch: 6| Step: 9
Training loss: 2.0390435579669752
Validation loss: 2.6955081402037298

Epoch: 6| Step: 10
Training loss: 1.3797067798550497
Validation loss: 2.5749538275321204

Epoch: 6| Step: 11
Training loss: 1.4018393116667305
Validation loss: 2.6681066042731407

Epoch: 6| Step: 12
Training loss: 1.05015624791131
Validation loss: 2.6186466523717358

Epoch: 6| Step: 13
Training loss: 1.9658814983065258
Validation loss: 2.620803385835603

Epoch: 555| Step: 0
Training loss: 1.7008036621187104
Validation loss: 2.6458989820667957

Epoch: 6| Step: 1
Training loss: 0.8775332428811174
Validation loss: 2.633152291271579

Epoch: 6| Step: 2
Training loss: 1.5922465245141126
Validation loss: 2.7142552661406167

Epoch: 6| Step: 3
Training loss: 1.3670426646218334
Validation loss: 2.687846898524393

Epoch: 6| Step: 4
Training loss: 2.4564907043392963
Validation loss: 2.576562419247029

Epoch: 6| Step: 5
Training loss: 1.3203422949323989
Validation loss: 2.704602863395576

Epoch: 6| Step: 6
Training loss: 1.1531598837933672
Validation loss: 2.716293053635843

Epoch: 6| Step: 7
Training loss: 1.5182518758324088
Validation loss: 2.7593711685676015

Epoch: 6| Step: 8
Training loss: 1.445679324226536
Validation loss: 2.6653504244450064

Epoch: 6| Step: 9
Training loss: 1.4875600273778837
Validation loss: 2.589203387206981

Epoch: 6| Step: 10
Training loss: 1.757202178117673
Validation loss: 2.6311338524976904

Epoch: 6| Step: 11
Training loss: 1.1243720951435083
Validation loss: 2.595008946841045

Epoch: 6| Step: 12
Training loss: 1.739467533239507
Validation loss: 2.708370051044362

Epoch: 6| Step: 13
Training loss: 1.7908954808862694
Validation loss: 2.6176456153934837

Epoch: 556| Step: 0
Training loss: 1.7035750048320806
Validation loss: 2.5834023585179855

Epoch: 6| Step: 1
Training loss: 1.9826817534787051
Validation loss: 2.6259009675073317

Epoch: 6| Step: 2
Training loss: 1.4778188376271644
Validation loss: 2.737946749086073

Epoch: 6| Step: 3
Training loss: 1.4217750598033119
Validation loss: 2.695943190356801

Epoch: 6| Step: 4
Training loss: 1.5935222238571496
Validation loss: 2.6576483701728

Epoch: 6| Step: 5
Training loss: 1.2040796332052421
Validation loss: 2.736762181122903

Epoch: 6| Step: 6
Training loss: 1.4142911104481897
Validation loss: 2.6992999561284026

Epoch: 6| Step: 7
Training loss: 1.6049481589718282
Validation loss: 2.606481110536265

Epoch: 6| Step: 8
Training loss: 2.170584315724105
Validation loss: 2.652613330229405

Epoch: 6| Step: 9
Training loss: 1.542963805371824
Validation loss: 2.655527437148774

Epoch: 6| Step: 10
Training loss: 1.1888266230456694
Validation loss: 2.622958255512943

Epoch: 6| Step: 11
Training loss: 1.6912190463665457
Validation loss: 2.6555339313725677

Epoch: 6| Step: 12
Training loss: 1.0496055520615915
Validation loss: 2.6441264923747054

Epoch: 6| Step: 13
Training loss: 1.3052171100505048
Validation loss: 2.718247317776721

Epoch: 557| Step: 0
Training loss: 1.4514982901210616
Validation loss: 2.585268215632038

Epoch: 6| Step: 1
Training loss: 1.0648444620019515
Validation loss: 2.6031564996983074

Epoch: 6| Step: 2
Training loss: 1.8338489746551847
Validation loss: 2.655876817734306

Epoch: 6| Step: 3
Training loss: 1.6085995778241777
Validation loss: 2.6057464431454584

Epoch: 6| Step: 4
Training loss: 1.5396014978613124
Validation loss: 2.6045231578019123

Epoch: 6| Step: 5
Training loss: 1.100123717113224
Validation loss: 2.5800747446716796

Epoch: 6| Step: 6
Training loss: 2.286630217073541
Validation loss: 2.6562988537343943

Epoch: 6| Step: 7
Training loss: 1.8423095507388025
Validation loss: 2.6834010473425933

Epoch: 6| Step: 8
Training loss: 1.2327440810950148
Validation loss: 2.6317639484666424

Epoch: 6| Step: 9
Training loss: 1.2882944304171968
Validation loss: 2.6442077470840375

Epoch: 6| Step: 10
Training loss: 1.1854946872844736
Validation loss: 2.6645549438963356

Epoch: 6| Step: 11
Training loss: 1.2184239464881894
Validation loss: 2.5947939415961154

Epoch: 6| Step: 12
Training loss: 1.3758064852582066
Validation loss: 2.5959000209354444

Epoch: 6| Step: 13
Training loss: 2.04142431520512
Validation loss: 2.6281209900215896

Epoch: 558| Step: 0
Training loss: 1.307598726400092
Validation loss: 2.724623460542487

Epoch: 6| Step: 1
Training loss: 1.7133347252024973
Validation loss: 2.676750496306698

Epoch: 6| Step: 2
Training loss: 1.3979133604022902
Validation loss: 2.6781277670696246

Epoch: 6| Step: 3
Training loss: 1.508530045778782
Validation loss: 2.6420288082526184

Epoch: 6| Step: 4
Training loss: 1.1896886733269523
Validation loss: 2.7588026743110294

Epoch: 6| Step: 5
Training loss: 1.4065845091648153
Validation loss: 2.804072729241205

Epoch: 6| Step: 6
Training loss: 1.5241393991029657
Validation loss: 2.57112749942024

Epoch: 6| Step: 7
Training loss: 1.4576034445065564
Validation loss: 2.6125688808628214

Epoch: 6| Step: 8
Training loss: 1.9629970844303504
Validation loss: 2.6279638642142507

Epoch: 6| Step: 9
Training loss: 1.2391546881344107
Validation loss: 2.5899560615967276

Epoch: 6| Step: 10
Training loss: 1.695977708948944
Validation loss: 2.6852892601574085

Epoch: 6| Step: 11
Training loss: 0.9437816930337664
Validation loss: 2.6863942133356944

Epoch: 6| Step: 12
Training loss: 2.287447102252961
Validation loss: 2.652453605593516

Epoch: 6| Step: 13
Training loss: 1.6574575232907363
Validation loss: 2.6549008595658683

Epoch: 559| Step: 0
Training loss: 1.655085892306827
Validation loss: 2.6802094653539017

Epoch: 6| Step: 1
Training loss: 1.4339767069288134
Validation loss: 2.7058309828650517

Epoch: 6| Step: 2
Training loss: 1.1110486582582493
Validation loss: 2.6961563518091842

Epoch: 6| Step: 3
Training loss: 1.3506911451249848
Validation loss: 2.7219059436529633

Epoch: 6| Step: 4
Training loss: 1.64548709301681
Validation loss: 2.645081598759411

Epoch: 6| Step: 5
Training loss: 1.1641766792982706
Validation loss: 2.697486185221729

Epoch: 6| Step: 6
Training loss: 2.3943028302171063
Validation loss: 2.5912922713566204

Epoch: 6| Step: 7
Training loss: 1.9379990457979261
Validation loss: 2.617838834802795

Epoch: 6| Step: 8
Training loss: 1.2750146378817555
Validation loss: 2.658326873426843

Epoch: 6| Step: 9
Training loss: 1.3698063210209939
Validation loss: 2.678853066048649

Epoch: 6| Step: 10
Training loss: 1.4503564199230519
Validation loss: 2.58461091255782

Epoch: 6| Step: 11
Training loss: 1.5468241365335598
Validation loss: 2.7454311278754453

Epoch: 6| Step: 12
Training loss: 1.3127235040644198
Validation loss: 2.6769992385347052

Epoch: 6| Step: 13
Training loss: 1.7763916819237902
Validation loss: 2.67760570038017

Epoch: 560| Step: 0
Training loss: 1.2429586931609424
Validation loss: 2.7012492613008843

Epoch: 6| Step: 1
Training loss: 1.4603668567182604
Validation loss: 2.6570348729763866

Epoch: 6| Step: 2
Training loss: 1.438210353316142
Validation loss: 2.597396547700566

Epoch: 6| Step: 3
Training loss: 2.200892514472256
Validation loss: 2.6710669574116594

Epoch: 6| Step: 4
Training loss: 1.61858024148895
Validation loss: 2.693751223733058

Epoch: 6| Step: 5
Training loss: 1.704772712123232
Validation loss: 2.6862801170162034

Epoch: 6| Step: 6
Training loss: 1.6234101073787552
Validation loss: 2.6867450379633984

Epoch: 6| Step: 7
Training loss: 1.194029075396343
Validation loss: 2.6695999153146537

Epoch: 6| Step: 8
Training loss: 1.5312392565291957
Validation loss: 2.6187727438258945

Epoch: 6| Step: 9
Training loss: 1.6891783386088173
Validation loss: 2.672022916830884

Epoch: 6| Step: 10
Training loss: 1.0522708473922802
Validation loss: 2.7000836888085127

Epoch: 6| Step: 11
Training loss: 1.2416522714347926
Validation loss: 2.711897744247735

Epoch: 6| Step: 12
Training loss: 1.3331962703748805
Validation loss: 2.598895915794799

Epoch: 6| Step: 13
Training loss: 0.8865496100213753
Validation loss: 2.6739699407155304

Epoch: 561| Step: 0
Training loss: 1.3326579658389017
Validation loss: 2.718629076452257

Epoch: 6| Step: 1
Training loss: 1.444802519031665
Validation loss: 2.543387079060365

Epoch: 6| Step: 2
Training loss: 1.5100683227138818
Validation loss: 2.654201487352406

Epoch: 6| Step: 3
Training loss: 1.4283020310475412
Validation loss: 2.7292943328277444

Epoch: 6| Step: 4
Training loss: 1.667406903231729
Validation loss: 2.6727760597984265

Epoch: 6| Step: 5
Training loss: 1.115837829121162
Validation loss: 2.614329836429366

Epoch: 6| Step: 6
Training loss: 1.7745132880424106
Validation loss: 2.6782154531813234

Epoch: 6| Step: 7
Training loss: 1.379065010073703
Validation loss: 2.6498862081325427

Epoch: 6| Step: 8
Training loss: 2.1191160982883646
Validation loss: 2.6356429009782385

Epoch: 6| Step: 9
Training loss: 1.571261143125171
Validation loss: 2.5964803052952483

Epoch: 6| Step: 10
Training loss: 1.2887147376548576
Validation loss: 2.509346762366895

Epoch: 6| Step: 11
Training loss: 1.2045655481975566
Validation loss: 2.6605211849995465

Epoch: 6| Step: 12
Training loss: 1.4339920031272695
Validation loss: 2.60782390962527

Epoch: 6| Step: 13
Training loss: 1.5132036038528514
Validation loss: 2.6605451425273037

Epoch: 562| Step: 0
Training loss: 1.7687725267896601
Validation loss: 2.6266069752558097

Epoch: 6| Step: 1
Training loss: 1.412159730216566
Validation loss: 2.64352818936545

Epoch: 6| Step: 2
Training loss: 1.9520903631658464
Validation loss: 2.705554705489387

Epoch: 6| Step: 3
Training loss: 2.252273153044833
Validation loss: 2.6229027506850198

Epoch: 6| Step: 4
Training loss: 1.1088750545504706
Validation loss: 2.7955804779228495

Epoch: 6| Step: 5
Training loss: 1.1430944596554864
Validation loss: 2.5677798132538263

Epoch: 6| Step: 6
Training loss: 1.3439350887841628
Validation loss: 2.6876929848919917

Epoch: 6| Step: 7
Training loss: 1.1863185627199924
Validation loss: 2.6852113785733445

Epoch: 6| Step: 8
Training loss: 1.5504955730061345
Validation loss: 2.679228898246179

Epoch: 6| Step: 9
Training loss: 1.3600616474765117
Validation loss: 2.6705551375259375

Epoch: 6| Step: 10
Training loss: 1.6923145559978678
Validation loss: 2.6509774350157285

Epoch: 6| Step: 11
Training loss: 1.0413135438651333
Validation loss: 2.666996920680452

Epoch: 6| Step: 12
Training loss: 1.4765630651402275
Validation loss: 2.6956038664868878

Epoch: 6| Step: 13
Training loss: 1.9451181092476981
Validation loss: 2.7221798834550777

Epoch: 563| Step: 0
Training loss: 0.8482791001072536
Validation loss: 2.7158045963731845

Epoch: 6| Step: 1
Training loss: 1.3275182347742505
Validation loss: 2.6178483780306374

Epoch: 6| Step: 2
Training loss: 2.1549345786305185
Validation loss: 2.598080320159331

Epoch: 6| Step: 3
Training loss: 1.3338768665785765
Validation loss: 2.6391235877219614

Epoch: 6| Step: 4
Training loss: 1.5582103592328622
Validation loss: 2.623120122615318

Epoch: 6| Step: 5
Training loss: 1.4492653070667683
Validation loss: 2.590148726675948

Epoch: 6| Step: 6
Training loss: 1.8176885857005818
Validation loss: 2.615358719527948

Epoch: 6| Step: 7
Training loss: 1.567942790836743
Validation loss: 2.643096003604794

Epoch: 6| Step: 8
Training loss: 1.407481777283244
Validation loss: 2.702414294075464

Epoch: 6| Step: 9
Training loss: 1.4342507668011553
Validation loss: 2.647751217138568

Epoch: 6| Step: 10
Training loss: 1.3876466467402324
Validation loss: 2.6654776064748553

Epoch: 6| Step: 11
Training loss: 1.4627611334700885
Validation loss: 2.6139684582548037

Epoch: 6| Step: 12
Training loss: 1.617757208536777
Validation loss: 2.64960606969739

Epoch: 6| Step: 13
Training loss: 1.1448115503576186
Validation loss: 2.7226402014004862

Epoch: 564| Step: 0
Training loss: 1.9884540355377927
Validation loss: 2.630079067923686

Epoch: 6| Step: 1
Training loss: 1.5462039301060329
Validation loss: 2.534624807606359

Epoch: 6| Step: 2
Training loss: 1.0064546767868319
Validation loss: 2.68061414941468

Epoch: 6| Step: 3
Training loss: 1.3253048743973284
Validation loss: 2.689584729059159

Epoch: 6| Step: 4
Training loss: 1.3072480983490498
Validation loss: 2.7664797605481626

Epoch: 6| Step: 5
Training loss: 1.710950877516195
Validation loss: 2.6827237942478384

Epoch: 6| Step: 6
Training loss: 1.6743711572185076
Validation loss: 2.6448205494056123

Epoch: 6| Step: 7
Training loss: 1.459468490579326
Validation loss: 2.6272478572557603

Epoch: 6| Step: 8
Training loss: 2.1581982642762005
Validation loss: 2.71900449737276

Epoch: 6| Step: 9
Training loss: 1.1753349090687502
Validation loss: 2.637391125363666

Epoch: 6| Step: 10
Training loss: 1.209412334171444
Validation loss: 2.608821765791801

Epoch: 6| Step: 11
Training loss: 1.5041386412372326
Validation loss: 2.729645858349257

Epoch: 6| Step: 12
Training loss: 1.5862978070256741
Validation loss: 2.6265661233071738

Epoch: 6| Step: 13
Training loss: 1.0704597316190003
Validation loss: 2.5844021988155275

Epoch: 565| Step: 0
Training loss: 1.4218257015191729
Validation loss: 2.682787385112607

Epoch: 6| Step: 1
Training loss: 1.2137245346053671
Validation loss: 2.722916152767886

Epoch: 6| Step: 2
Training loss: 1.6387229429523908
Validation loss: 2.6111266802542743

Epoch: 6| Step: 3
Training loss: 1.7402638305500273
Validation loss: 2.662490603761463

Epoch: 6| Step: 4
Training loss: 1.3660133769775253
Validation loss: 2.5947260329214537

Epoch: 6| Step: 5
Training loss: 1.6545461851874843
Validation loss: 2.6204401112093088

Epoch: 6| Step: 6
Training loss: 0.9930969635719294
Validation loss: 2.641765366934667

Epoch: 6| Step: 7
Training loss: 1.6180456713300424
Validation loss: 2.6520267806852025

Epoch: 6| Step: 8
Training loss: 1.4461115097694728
Validation loss: 2.5888860745791504

Epoch: 6| Step: 9
Training loss: 2.0277038136874133
Validation loss: 2.690716617832776

Epoch: 6| Step: 10
Training loss: 0.8984318608646057
Validation loss: 2.652546163897602

Epoch: 6| Step: 11
Training loss: 1.580940982341984
Validation loss: 2.614060384957924

Epoch: 6| Step: 12
Training loss: 1.123258938877546
Validation loss: 2.607528024015017

Epoch: 6| Step: 13
Training loss: 1.9341773799592414
Validation loss: 2.6571899825917935

Epoch: 566| Step: 0
Training loss: 1.6671526518221236
Validation loss: 2.6890042924852784

Epoch: 6| Step: 1
Training loss: 1.012704494217658
Validation loss: 2.643158504734337

Epoch: 6| Step: 2
Training loss: 1.4534353109477358
Validation loss: 2.6297091869491687

Epoch: 6| Step: 3
Training loss: 1.367031502679524
Validation loss: 2.6801800171936505

Epoch: 6| Step: 4
Training loss: 1.029981410868033
Validation loss: 2.7092991790833745

Epoch: 6| Step: 5
Training loss: 1.6087805381549993
Validation loss: 2.731723267702746

Epoch: 6| Step: 6
Training loss: 1.6989081438682552
Validation loss: 2.6479405657987067

Epoch: 6| Step: 7
Training loss: 1.530081322447275
Validation loss: 2.648202438297408

Epoch: 6| Step: 8
Training loss: 1.5198608668545774
Validation loss: 2.7011211402570217

Epoch: 6| Step: 9
Training loss: 1.466710724313393
Validation loss: 2.6716385814551935

Epoch: 6| Step: 10
Training loss: 2.3779058247647646
Validation loss: 2.608404683446363

Epoch: 6| Step: 11
Training loss: 1.3110202440376308
Validation loss: 2.5895090689476183

Epoch: 6| Step: 12
Training loss: 1.4419597607102523
Validation loss: 2.6889672362890202

Epoch: 6| Step: 13
Training loss: 1.7523249441048472
Validation loss: 2.719617272250444

Epoch: 567| Step: 0
Training loss: 2.0129816035848043
Validation loss: 2.6265512791201444

Epoch: 6| Step: 1
Training loss: 0.9451972954279126
Validation loss: 2.7477738663551574

Epoch: 6| Step: 2
Training loss: 1.6974292671849238
Validation loss: 2.6882226367824402

Epoch: 6| Step: 3
Training loss: 1.4160838143602987
Validation loss: 2.6133628869373755

Epoch: 6| Step: 4
Training loss: 1.5489155575101166
Validation loss: 2.7263129114465636

Epoch: 6| Step: 5
Training loss: 1.4791501093551152
Validation loss: 2.6532808525593348

Epoch: 6| Step: 6
Training loss: 1.4653973563256724
Validation loss: 2.715897946415662

Epoch: 6| Step: 7
Training loss: 1.191388239489892
Validation loss: 2.644706422784185

Epoch: 6| Step: 8
Training loss: 1.114024559969323
Validation loss: 2.6257383145223656

Epoch: 6| Step: 9
Training loss: 0.9963325662991772
Validation loss: 2.704513072965607

Epoch: 6| Step: 10
Training loss: 1.915979040887355
Validation loss: 2.634284371600047

Epoch: 6| Step: 11
Training loss: 1.58684930757305
Validation loss: 2.631672248557234

Epoch: 6| Step: 12
Training loss: 1.3993604800181043
Validation loss: 2.691289059796226

Epoch: 6| Step: 13
Training loss: 1.239917720710564
Validation loss: 2.618085927090668

Epoch: 568| Step: 0
Training loss: 1.6915663716067368
Validation loss: 2.7013129223729244

Epoch: 6| Step: 1
Training loss: 2.0419774759602767
Validation loss: 2.6338929877072106

Epoch: 6| Step: 2
Training loss: 1.510614509340917
Validation loss: 2.71919737894864

Epoch: 6| Step: 3
Training loss: 1.3366187071024667
Validation loss: 2.676765882413285

Epoch: 6| Step: 4
Training loss: 1.2947535340680203
Validation loss: 2.733951476972219

Epoch: 6| Step: 5
Training loss: 1.4333585707342609
Validation loss: 2.6296794394116088

Epoch: 6| Step: 6
Training loss: 1.7521838458332502
Validation loss: 2.743498467400819

Epoch: 6| Step: 7
Training loss: 1.296202013898785
Validation loss: 2.739828510434384

Epoch: 6| Step: 8
Training loss: 1.5239546460489273
Validation loss: 2.746147539277767

Epoch: 6| Step: 9
Training loss: 1.4478967605795916
Validation loss: 2.6647347803168557

Epoch: 6| Step: 10
Training loss: 1.4183862665222615
Validation loss: 2.6132650555277284

Epoch: 6| Step: 11
Training loss: 1.284992149566538
Validation loss: 2.717082380518151

Epoch: 6| Step: 12
Training loss: 1.327445810221305
Validation loss: 2.6523001270040574

Epoch: 6| Step: 13
Training loss: 1.501978205557012
Validation loss: 2.583799560928182

Epoch: 569| Step: 0
Training loss: 1.3093917008019984
Validation loss: 2.6570868393001197

Epoch: 6| Step: 1
Training loss: 1.480983594284527
Validation loss: 2.7026668911765794

Epoch: 6| Step: 2
Training loss: 1.4287446461975233
Validation loss: 2.6314417733432585

Epoch: 6| Step: 3
Training loss: 1.139173707910044
Validation loss: 2.661724578066939

Epoch: 6| Step: 4
Training loss: 1.219616166456878
Validation loss: 2.6363401035805794

Epoch: 6| Step: 5
Training loss: 1.6101250243363527
Validation loss: 2.6517295113479062

Epoch: 6| Step: 6
Training loss: 2.3415521107230233
Validation loss: 2.7228001521072516

Epoch: 6| Step: 7
Training loss: 1.1959826516867547
Validation loss: 2.6669741198233

Epoch: 6| Step: 8
Training loss: 1.3762310326124125
Validation loss: 2.663951651706766

Epoch: 6| Step: 9
Training loss: 1.320076960935484
Validation loss: 2.591925272605064

Epoch: 6| Step: 10
Training loss: 1.4731561030008307
Validation loss: 2.6485581891557985

Epoch: 6| Step: 11
Training loss: 1.3320434211778984
Validation loss: 2.671794704729223

Epoch: 6| Step: 12
Training loss: 1.403700233589572
Validation loss: 2.727178093521288

Epoch: 6| Step: 13
Training loss: 1.6352552184415459
Validation loss: 2.7879107013387063

Epoch: 570| Step: 0
Training loss: 1.0651876452624442
Validation loss: 2.5845962038312678

Epoch: 6| Step: 1
Training loss: 1.506609817518269
Validation loss: 2.614022839106459

Epoch: 6| Step: 2
Training loss: 1.5473706000586225
Validation loss: 2.6271808850476037

Epoch: 6| Step: 3
Training loss: 1.6896078579114846
Validation loss: 2.699858869375739

Epoch: 6| Step: 4
Training loss: 1.2515949564141207
Validation loss: 2.6323448689193873

Epoch: 6| Step: 5
Training loss: 1.2464083570386262
Validation loss: 2.6847937261058017

Epoch: 6| Step: 6
Training loss: 1.0464394645551722
Validation loss: 2.646770396300526

Epoch: 6| Step: 7
Training loss: 1.5340374079921464
Validation loss: 2.725945207239218

Epoch: 6| Step: 8
Training loss: 1.334674572874223
Validation loss: 2.656355725572423

Epoch: 6| Step: 9
Training loss: 1.467230964967454
Validation loss: 2.64708148444226

Epoch: 6| Step: 10
Training loss: 1.9066456868722501
Validation loss: 2.7138025314583683

Epoch: 6| Step: 11
Training loss: 2.0836175597539346
Validation loss: 2.5917767390720465

Epoch: 6| Step: 12
Training loss: 1.251014059727225
Validation loss: 2.725567068392957

Epoch: 6| Step: 13
Training loss: 2.013646418857343
Validation loss: 2.6306717633193943

Epoch: 571| Step: 0
Training loss: 1.8202233681529563
Validation loss: 2.678219786032863

Epoch: 6| Step: 1
Training loss: 1.059649233361959
Validation loss: 2.7115418681098302

Epoch: 6| Step: 2
Training loss: 1.2048815500441696
Validation loss: 2.7521759059241893

Epoch: 6| Step: 3
Training loss: 1.328513189693239
Validation loss: 2.6795253814043853

Epoch: 6| Step: 4
Training loss: 1.4098412751078113
Validation loss: 2.6222486985753264

Epoch: 6| Step: 5
Training loss: 0.8938662793471985
Validation loss: 2.639449799111672

Epoch: 6| Step: 6
Training loss: 1.9616586035619732
Validation loss: 2.670868925073393

Epoch: 6| Step: 7
Training loss: 0.9407607592074648
Validation loss: 2.7333919857129123

Epoch: 6| Step: 8
Training loss: 1.1376145755787743
Validation loss: 2.6704692038770874

Epoch: 6| Step: 9
Training loss: 2.1639814120638405
Validation loss: 2.6411485060232462

Epoch: 6| Step: 10
Training loss: 1.3161190636582738
Validation loss: 2.5747316324367073

Epoch: 6| Step: 11
Training loss: 1.7075089194426472
Validation loss: 2.679221689271035

Epoch: 6| Step: 12
Training loss: 1.557698999247438
Validation loss: 2.65468480360034

Epoch: 6| Step: 13
Training loss: 1.0715420753666212
Validation loss: 2.615073132955104

Epoch: 572| Step: 0
Training loss: 1.4009147312374148
Validation loss: 2.6502012395419494

Epoch: 6| Step: 1
Training loss: 1.034670733906758
Validation loss: 2.6731320225775983

Epoch: 6| Step: 2
Training loss: 1.653184320723165
Validation loss: 2.5960181675240213

Epoch: 6| Step: 3
Training loss: 1.2923333949394955
Validation loss: 2.714674359054654

Epoch: 6| Step: 4
Training loss: 1.9837506731365098
Validation loss: 2.7293856298974357

Epoch: 6| Step: 5
Training loss: 1.2250177654613017
Validation loss: 2.6104950657758526

Epoch: 6| Step: 6
Training loss: 1.7843721700402047
Validation loss: 2.804243449488101

Epoch: 6| Step: 7
Training loss: 1.2265984596764001
Validation loss: 2.6739949780806636

Epoch: 6| Step: 8
Training loss: 1.1902487212800992
Validation loss: 2.6600810249590467

Epoch: 6| Step: 9
Training loss: 1.3477207334267094
Validation loss: 2.6306808721363395

Epoch: 6| Step: 10
Training loss: 1.1363090484685898
Validation loss: 2.7296013491014652

Epoch: 6| Step: 11
Training loss: 1.3364013402039818
Validation loss: 2.65402323107523

Epoch: 6| Step: 12
Training loss: 1.9916969443324841
Validation loss: 2.678782182636182

Epoch: 6| Step: 13
Training loss: 0.8575909910499251
Validation loss: 2.6352222051005008

Epoch: 573| Step: 0
Training loss: 1.973340329445646
Validation loss: 2.652799659778632

Epoch: 6| Step: 1
Training loss: 1.2167760072636282
Validation loss: 2.6917028185888743

Epoch: 6| Step: 2
Training loss: 1.3882330564635852
Validation loss: 2.657697607679191

Epoch: 6| Step: 3
Training loss: 1.4591022734900334
Validation loss: 2.68060719760181

Epoch: 6| Step: 4
Training loss: 1.8092288391427616
Validation loss: 2.6083770714344374

Epoch: 6| Step: 5
Training loss: 1.2659759035031957
Validation loss: 2.6527704263021286

Epoch: 6| Step: 6
Training loss: 1.4334645226049854
Validation loss: 2.6725198087239495

Epoch: 6| Step: 7
Training loss: 1.3170666495528307
Validation loss: 2.709322476298091

Epoch: 6| Step: 8
Training loss: 1.4786374484105842
Validation loss: 2.682666533897458

Epoch: 6| Step: 9
Training loss: 1.3425513399419569
Validation loss: 2.6906319807730803

Epoch: 6| Step: 10
Training loss: 1.0909433594291988
Validation loss: 2.6217021256574307

Epoch: 6| Step: 11
Training loss: 1.4506854837637049
Validation loss: 2.768441795565988

Epoch: 6| Step: 12
Training loss: 1.5356581161213505
Validation loss: 2.6809971579331973

Epoch: 6| Step: 13
Training loss: 1.5578836530010327
Validation loss: 2.680107550404473

Epoch: 574| Step: 0
Training loss: 1.6689500267359545
Validation loss: 2.70425767917154

Epoch: 6| Step: 1
Training loss: 1.0738137331289914
Validation loss: 2.7068936922469846

Epoch: 6| Step: 2
Training loss: 1.3934957041350835
Validation loss: 2.649117379648043

Epoch: 6| Step: 3
Training loss: 1.5656701544000737
Validation loss: 2.637883518960343

Epoch: 6| Step: 4
Training loss: 0.8762009417286967
Validation loss: 2.7586645774767775

Epoch: 6| Step: 5
Training loss: 1.4627913682010654
Validation loss: 2.675182364910813

Epoch: 6| Step: 6
Training loss: 1.3157070125288868
Validation loss: 2.669769524491299

Epoch: 6| Step: 7
Training loss: 1.3510651307236359
Validation loss: 2.724664548133781

Epoch: 6| Step: 8
Training loss: 1.2144228092506728
Validation loss: 2.70335348428438

Epoch: 6| Step: 9
Training loss: 1.4976485417843741
Validation loss: 2.6606604513119168

Epoch: 6| Step: 10
Training loss: 1.216014727020177
Validation loss: 2.677568926860581

Epoch: 6| Step: 11
Training loss: 1.3721759144609504
Validation loss: 2.625795034009492

Epoch: 6| Step: 12
Training loss: 2.219300859867834
Validation loss: 2.703089539134484

Epoch: 6| Step: 13
Training loss: 1.3002433237360247
Validation loss: 2.710550092654301

Epoch: 575| Step: 0
Training loss: 1.0734656451004556
Validation loss: 2.6605241701869144

Epoch: 6| Step: 1
Training loss: 1.437234937030544
Validation loss: 2.7992014757477235

Epoch: 6| Step: 2
Training loss: 1.5018922473490217
Validation loss: 2.736384223572041

Epoch: 6| Step: 3
Training loss: 1.2066233911885895
Validation loss: 2.693577605380021

Epoch: 6| Step: 4
Training loss: 1.0038763257030863
Validation loss: 2.6908540269764694

Epoch: 6| Step: 5
Training loss: 1.2851016140255103
Validation loss: 2.7912125368846676

Epoch: 6| Step: 6
Training loss: 2.1348085111199997
Validation loss: 2.7287218704732785

Epoch: 6| Step: 7
Training loss: 1.349356377788071
Validation loss: 2.6713063814509357

Epoch: 6| Step: 8
Training loss: 1.7386732023872995
Validation loss: 2.6924268067951735

Epoch: 6| Step: 9
Training loss: 1.4535538235499033
Validation loss: 2.6488236251616613

Epoch: 6| Step: 10
Training loss: 1.417410159888658
Validation loss: 2.6757281022751354

Epoch: 6| Step: 11
Training loss: 1.1600249245037673
Validation loss: 2.626040171044192

Epoch: 6| Step: 12
Training loss: 1.5773447959711273
Validation loss: 2.5523503138557473

Epoch: 6| Step: 13
Training loss: 1.4987895373044138
Validation loss: 2.6660701538937746

Epoch: 576| Step: 0
Training loss: 1.4995222920449032
Validation loss: 2.689376852969596

Epoch: 6| Step: 1
Training loss: 1.3946940009196183
Validation loss: 2.6939168847095707

Epoch: 6| Step: 2
Training loss: 1.2772461740164314
Validation loss: 2.7053287250088958

Epoch: 6| Step: 3
Training loss: 1.294516153195743
Validation loss: 2.6546767785851473

Epoch: 6| Step: 4
Training loss: 1.6653735946240473
Validation loss: 2.720633295200148

Epoch: 6| Step: 5
Training loss: 1.23746885010018
Validation loss: 2.6252685464199943

Epoch: 6| Step: 6
Training loss: 1.2080027796795423
Validation loss: 2.7008520696041467

Epoch: 6| Step: 7
Training loss: 1.4798042194933745
Validation loss: 2.658397972449257

Epoch: 6| Step: 8
Training loss: 1.2311659033854598
Validation loss: 2.7201551248810167

Epoch: 6| Step: 9
Training loss: 1.887289651934992
Validation loss: 2.6873454197095175

Epoch: 6| Step: 10
Training loss: 1.0953992126358933
Validation loss: 2.7353723875664593

Epoch: 6| Step: 11
Training loss: 1.2348791613902061
Validation loss: 2.704337452330459

Epoch: 6| Step: 12
Training loss: 1.7950287331536758
Validation loss: 2.7052798990710833

Epoch: 6| Step: 13
Training loss: 1.3177108865142735
Validation loss: 2.758260503749934

Epoch: 577| Step: 0
Training loss: 1.429588272736986
Validation loss: 2.6231438802989473

Epoch: 6| Step: 1
Training loss: 1.2731177741900466
Validation loss: 2.636963573469975

Epoch: 6| Step: 2
Training loss: 1.3466697731234032
Validation loss: 2.729455806843332

Epoch: 6| Step: 3
Training loss: 1.2359488389065338
Validation loss: 2.581982962442407

Epoch: 6| Step: 4
Training loss: 1.6910333728982452
Validation loss: 2.699390917159982

Epoch: 6| Step: 5
Training loss: 1.9255419228426982
Validation loss: 2.742051565655542

Epoch: 6| Step: 6
Training loss: 1.7199175250440037
Validation loss: 2.744619569864488

Epoch: 6| Step: 7
Training loss: 1.085477772833489
Validation loss: 2.7120031409189007

Epoch: 6| Step: 8
Training loss: 1.6214178657538414
Validation loss: 2.653738660961027

Epoch: 6| Step: 9
Training loss: 1.3305787252153352
Validation loss: 2.6990466516436773

Epoch: 6| Step: 10
Training loss: 1.7396559861900471
Validation loss: 2.693942560801787

Epoch: 6| Step: 11
Training loss: 1.12420138517307
Validation loss: 2.7127726391814786

Epoch: 6| Step: 12
Training loss: 1.4637642506753523
Validation loss: 2.680406756908439

Epoch: 6| Step: 13
Training loss: 1.5915333161074283
Validation loss: 2.6534862735811506

Epoch: 578| Step: 0
Training loss: 1.1724122913797832
Validation loss: 2.6323515269782334

Epoch: 6| Step: 1
Training loss: 1.6222819558269335
Validation loss: 2.6602716103334054

Epoch: 6| Step: 2
Training loss: 1.4056355299497985
Validation loss: 2.706422294052992

Epoch: 6| Step: 3
Training loss: 1.2890537146066627
Validation loss: 2.68208860605783

Epoch: 6| Step: 4
Training loss: 1.0634928720447898
Validation loss: 2.6107702785712266

Epoch: 6| Step: 5
Training loss: 1.2171357541721333
Validation loss: 2.7189895171714915

Epoch: 6| Step: 6
Training loss: 1.5255728599330665
Validation loss: 2.6569307114959386

Epoch: 6| Step: 7
Training loss: 0.8933589199717188
Validation loss: 2.723314422851235

Epoch: 6| Step: 8
Training loss: 1.8091014042484965
Validation loss: 2.6173996402410395

Epoch: 6| Step: 9
Training loss: 1.3499409203494195
Validation loss: 2.6371816305249944

Epoch: 6| Step: 10
Training loss: 2.5503492004049853
Validation loss: 2.657643229185702

Epoch: 6| Step: 11
Training loss: 1.3859368497380362
Validation loss: 2.656998030880827

Epoch: 6| Step: 12
Training loss: 1.4251132183941384
Validation loss: 2.6343398395246687

Epoch: 6| Step: 13
Training loss: 1.7708765436024259
Validation loss: 2.6690070714323637

Epoch: 579| Step: 0
Training loss: 2.222185403465856
Validation loss: 2.750667566505983

Epoch: 6| Step: 1
Training loss: 1.4647562636635245
Validation loss: 2.792431994755731

Epoch: 6| Step: 2
Training loss: 1.1349621075762177
Validation loss: 2.762936664303021

Epoch: 6| Step: 3
Training loss: 1.2123342027078077
Validation loss: 2.625312966218048

Epoch: 6| Step: 4
Training loss: 1.4471624957984524
Validation loss: 2.718129923821386

Epoch: 6| Step: 5
Training loss: 1.3081286158832965
Validation loss: 2.6963186494358786

Epoch: 6| Step: 6
Training loss: 1.2671564985027275
Validation loss: 2.6477770717434934

Epoch: 6| Step: 7
Training loss: 1.4526223574657744
Validation loss: 2.758166404599926

Epoch: 6| Step: 8
Training loss: 1.499160849768631
Validation loss: 2.732631530437703

Epoch: 6| Step: 9
Training loss: 1.8401413857001465
Validation loss: 2.6841501725258374

Epoch: 6| Step: 10
Training loss: 1.3253188613274802
Validation loss: 2.766329057010479

Epoch: 6| Step: 11
Training loss: 1.0708827149598732
Validation loss: 2.6090312562118716

Epoch: 6| Step: 12
Training loss: 1.7015872277458859
Validation loss: 2.7041116384240294

Epoch: 6| Step: 13
Training loss: 1.2019534165881338
Validation loss: 2.7100462886455046

Epoch: 580| Step: 0
Training loss: 1.104128291104971
Validation loss: 2.690527164749572

Epoch: 6| Step: 1
Training loss: 1.4192817430922673
Validation loss: 2.631757664443528

Epoch: 6| Step: 2
Training loss: 1.182712138464776
Validation loss: 2.580484023338064

Epoch: 6| Step: 3
Training loss: 1.1892236948718697
Validation loss: 2.6774602807938983

Epoch: 6| Step: 4
Training loss: 1.4488498598691553
Validation loss: 2.6608378428715675

Epoch: 6| Step: 5
Training loss: 1.0776993837445243
Validation loss: 2.6035478330816306

Epoch: 6| Step: 6
Training loss: 0.9992722605081323
Validation loss: 2.5715398759479893

Epoch: 6| Step: 7
Training loss: 1.2629345212198912
Validation loss: 2.6773294596104544

Epoch: 6| Step: 8
Training loss: 0.9747697166998434
Validation loss: 2.5687163770304666

Epoch: 6| Step: 9
Training loss: 1.2887482231120486
Validation loss: 2.666138840615568

Epoch: 6| Step: 10
Training loss: 2.0053501095543513
Validation loss: 2.6733828688286345

Epoch: 6| Step: 11
Training loss: 1.9029409736142786
Validation loss: 2.748370705004477

Epoch: 6| Step: 12
Training loss: 1.9255461326823968
Validation loss: 2.6776004555313286

Epoch: 6| Step: 13
Training loss: 1.7286681716761356
Validation loss: 2.66281292528581

Epoch: 581| Step: 0
Training loss: 1.3683358737365956
Validation loss: 2.772440983747144

Epoch: 6| Step: 1
Training loss: 1.4549535915668517
Validation loss: 2.6365399622186674

Epoch: 6| Step: 2
Training loss: 1.36993624524927
Validation loss: 2.636486855795438

Epoch: 6| Step: 3
Training loss: 1.487372974774272
Validation loss: 2.6114938008322275

Epoch: 6| Step: 4
Training loss: 1.4832978205055134
Validation loss: 2.60465710228255

Epoch: 6| Step: 5
Training loss: 1.4650254607347943
Validation loss: 2.645530653010487

Epoch: 6| Step: 6
Training loss: 0.9447503428199875
Validation loss: 2.6101618034894813

Epoch: 6| Step: 7
Training loss: 1.612191411734751
Validation loss: 2.729947200611492

Epoch: 6| Step: 8
Training loss: 1.8425475256495676
Validation loss: 2.6426874484716327

Epoch: 6| Step: 9
Training loss: 1.0145356424913095
Validation loss: 2.6873179061872423

Epoch: 6| Step: 10
Training loss: 0.8699043604471245
Validation loss: 2.648659704568321

Epoch: 6| Step: 11
Training loss: 2.1953771181201147
Validation loss: 2.642741736005241

Epoch: 6| Step: 12
Training loss: 1.4009973549719164
Validation loss: 2.6943572013721284

Epoch: 6| Step: 13
Training loss: 1.7990902721069728
Validation loss: 2.626029935167092

Epoch: 582| Step: 0
Training loss: 1.3477772533991934
Validation loss: 2.644073238727315

Epoch: 6| Step: 1
Training loss: 1.861731566570314
Validation loss: 2.650955212001697

Epoch: 6| Step: 2
Training loss: 1.5067234355786803
Validation loss: 2.6566184409059947

Epoch: 6| Step: 3
Training loss: 1.4907043435914586
Validation loss: 2.763752223453186

Epoch: 6| Step: 4
Training loss: 0.8520738658674417
Validation loss: 2.5762118443158486

Epoch: 6| Step: 5
Training loss: 1.5373888549329258
Validation loss: 2.5953026345018753

Epoch: 6| Step: 6
Training loss: 1.0621384959351696
Validation loss: 2.7001037490749273

Epoch: 6| Step: 7
Training loss: 1.5900635063636324
Validation loss: 2.7022842957794544

Epoch: 6| Step: 8
Training loss: 2.04911320742135
Validation loss: 2.6315058664581104

Epoch: 6| Step: 9
Training loss: 1.0150869264634323
Validation loss: 2.564009409226716

Epoch: 6| Step: 10
Training loss: 1.559026137107811
Validation loss: 2.694992615709457

Epoch: 6| Step: 11
Training loss: 1.190102786585747
Validation loss: 2.715485048600255

Epoch: 6| Step: 12
Training loss: 1.236795008821027
Validation loss: 2.635609818905992

Epoch: 6| Step: 13
Training loss: 1.249673943909907
Validation loss: 2.6942896127343183

Epoch: 583| Step: 0
Training loss: 1.6023832125665698
Validation loss: 2.63075936238317

Epoch: 6| Step: 1
Training loss: 1.1507032193146243
Validation loss: 2.642487233057809

Epoch: 6| Step: 2
Training loss: 2.0718340195045117
Validation loss: 2.6505496334468357

Epoch: 6| Step: 3
Training loss: 1.2771957265030318
Validation loss: 2.7275992029040457

Epoch: 6| Step: 4
Training loss: 1.181790933428266
Validation loss: 2.675897550080169

Epoch: 6| Step: 5
Training loss: 1.3491804708364084
Validation loss: 2.7195511183241083

Epoch: 6| Step: 6
Training loss: 1.2332256132630428
Validation loss: 2.567809139736423

Epoch: 6| Step: 7
Training loss: 1.1075607293487597
Validation loss: 2.664869785251704

Epoch: 6| Step: 8
Training loss: 1.539209968743985
Validation loss: 2.7159522303604278

Epoch: 6| Step: 9
Training loss: 1.5682398084239106
Validation loss: 2.6833828417516994

Epoch: 6| Step: 10
Training loss: 1.7074685660466713
Validation loss: 2.7922915636430696

Epoch: 6| Step: 11
Training loss: 1.3661523878682245
Validation loss: 2.6400416346856352

Epoch: 6| Step: 12
Training loss: 1.2993245717694848
Validation loss: 2.7132052659310437

Epoch: 6| Step: 13
Training loss: 1.496021557851489
Validation loss: 2.6883055692755593

Epoch: 584| Step: 0
Training loss: 1.056594424550995
Validation loss: 2.7322633395258076

Epoch: 6| Step: 1
Training loss: 2.0118749465302446
Validation loss: 2.562423110636727

Epoch: 6| Step: 2
Training loss: 1.710381683227266
Validation loss: 2.7408374077847126

Epoch: 6| Step: 3
Training loss: 1.1986694071769857
Validation loss: 2.6459817422435914

Epoch: 6| Step: 4
Training loss: 1.278423541208923
Validation loss: 2.663514313715435

Epoch: 6| Step: 5
Training loss: 1.5294106783366768
Validation loss: 2.639535860747019

Epoch: 6| Step: 6
Training loss: 1.1900956246078525
Validation loss: 2.6019356353554395

Epoch: 6| Step: 7
Training loss: 1.5559370683775557
Validation loss: 2.6008580515509903

Epoch: 6| Step: 8
Training loss: 1.4540364678071642
Validation loss: 2.647381704851082

Epoch: 6| Step: 9
Training loss: 1.6279809459724086
Validation loss: 2.6690435426926746

Epoch: 6| Step: 10
Training loss: 1.5314060053860699
Validation loss: 2.6595546089095063

Epoch: 6| Step: 11
Training loss: 1.4328305242272117
Validation loss: 2.6607631679881827

Epoch: 6| Step: 12
Training loss: 1.3038690249716018
Validation loss: 2.745586084082428

Epoch: 6| Step: 13
Training loss: 1.0811038122413186
Validation loss: 2.6863700263552097

Epoch: 585| Step: 0
Training loss: 1.0893102727975916
Validation loss: 2.5856631395264085

Epoch: 6| Step: 1
Training loss: 1.293213236302637
Validation loss: 2.6607571403363512

Epoch: 6| Step: 2
Training loss: 2.4062266162875567
Validation loss: 2.708899368946963

Epoch: 6| Step: 3
Training loss: 1.392269961808068
Validation loss: 2.713480047265162

Epoch: 6| Step: 4
Training loss: 1.7256845857307501
Validation loss: 2.630124405567935

Epoch: 6| Step: 5
Training loss: 1.901553700786409
Validation loss: 2.6052423656694796

Epoch: 6| Step: 6
Training loss: 1.5908852055230445
Validation loss: 2.7515063499753425

Epoch: 6| Step: 7
Training loss: 1.1427681006928132
Validation loss: 2.6646447059604674

Epoch: 6| Step: 8
Training loss: 0.9868357645634181
Validation loss: 2.6988578374523353

Epoch: 6| Step: 9
Training loss: 0.7956525364236239
Validation loss: 2.712400405708981

Epoch: 6| Step: 10
Training loss: 1.0371567882325072
Validation loss: 2.7668331569338105

Epoch: 6| Step: 11
Training loss: 1.4513691784718379
Validation loss: 2.6785548574791544

Epoch: 6| Step: 12
Training loss: 1.4590789886804416
Validation loss: 2.7258843381501063

Epoch: 6| Step: 13
Training loss: 1.248359127711909
Validation loss: 2.69577464213377

Epoch: 586| Step: 0
Training loss: 1.0032552545420814
Validation loss: 2.634640354414425

Epoch: 6| Step: 1
Training loss: 1.3849448449896227
Validation loss: 2.619471342988806

Epoch: 6| Step: 2
Training loss: 0.9618233420100344
Validation loss: 2.7147784391892458

Epoch: 6| Step: 3
Training loss: 1.5920251226311937
Validation loss: 2.6984280179129674

Epoch: 6| Step: 4
Training loss: 1.2904403720723427
Validation loss: 2.6898343145135484

Epoch: 6| Step: 5
Training loss: 1.4423663655597938
Validation loss: 2.759306078296419

Epoch: 6| Step: 6
Training loss: 1.3176044478446176
Validation loss: 2.7089660139032605

Epoch: 6| Step: 7
Training loss: 2.3081493175804972
Validation loss: 2.66386381702774

Epoch: 6| Step: 8
Training loss: 1.6530561782558537
Validation loss: 2.736214817891853

Epoch: 6| Step: 9
Training loss: 1.114672089842634
Validation loss: 2.740033603103176

Epoch: 6| Step: 10
Training loss: 1.4270332587522558
Validation loss: 2.634914605397164

Epoch: 6| Step: 11
Training loss: 1.219049465850016
Validation loss: 2.625155509252827

Epoch: 6| Step: 12
Training loss: 1.4081191462476805
Validation loss: 2.580224545999967

Epoch: 6| Step: 13
Training loss: 1.3518750485346587
Validation loss: 2.6636476170512946

Epoch: 587| Step: 0
Training loss: 1.5164969384237665
Validation loss: 2.6178231366314417

Epoch: 6| Step: 1
Training loss: 1.391571579994991
Validation loss: 2.6990047295369397

Epoch: 6| Step: 2
Training loss: 1.3772801220629818
Validation loss: 2.7209960689332444

Epoch: 6| Step: 3
Training loss: 1.1480895053649351
Validation loss: 2.7161514995877147

Epoch: 6| Step: 4
Training loss: 1.3628063959808563
Validation loss: 2.6648568394049614

Epoch: 6| Step: 5
Training loss: 2.045662207610353
Validation loss: 2.642580298087186

Epoch: 6| Step: 6
Training loss: 1.593991803544245
Validation loss: 2.775750246947307

Epoch: 6| Step: 7
Training loss: 0.9618227532903871
Validation loss: 2.672595601638408

Epoch: 6| Step: 8
Training loss: 1.4016764974003677
Validation loss: 2.6400934805630616

Epoch: 6| Step: 9
Training loss: 1.0507801155169294
Validation loss: 2.751802136900273

Epoch: 6| Step: 10
Training loss: 1.273419245489609
Validation loss: 2.6715073821052235

Epoch: 6| Step: 11
Training loss: 0.8316118141297519
Validation loss: 2.6410095765842336

Epoch: 6| Step: 12
Training loss: 1.2105877771203877
Validation loss: 2.657417777064427

Epoch: 6| Step: 13
Training loss: 1.739591640368822
Validation loss: 2.7102296571866034

Epoch: 588| Step: 0
Training loss: 1.080997841157972
Validation loss: 2.6422570569549775

Epoch: 6| Step: 1
Training loss: 1.3430148486824087
Validation loss: 2.6597508002582524

Epoch: 6| Step: 2
Training loss: 1.5399896762551404
Validation loss: 2.654419931485745

Epoch: 6| Step: 3
Training loss: 1.4031360481353996
Validation loss: 2.7466380375300856

Epoch: 6| Step: 4
Training loss: 1.1167000727614793
Validation loss: 2.729442719306187

Epoch: 6| Step: 5
Training loss: 0.9637965028579444
Validation loss: 2.681356502909143

Epoch: 6| Step: 6
Training loss: 1.5192894436761455
Validation loss: 2.6443505017811066

Epoch: 6| Step: 7
Training loss: 1.8146774761014415
Validation loss: 2.561917509659292

Epoch: 6| Step: 8
Training loss: 1.2451899488544016
Validation loss: 2.6410145757091494

Epoch: 6| Step: 9
Training loss: 1.6715803510618783
Validation loss: 2.734751556298099

Epoch: 6| Step: 10
Training loss: 1.4804845320934854
Validation loss: 2.721869420155971

Epoch: 6| Step: 11
Training loss: 1.913377849590442
Validation loss: 2.6269381312466833

Epoch: 6| Step: 12
Training loss: 1.0959483805459773
Validation loss: 2.727114492886842

Epoch: 6| Step: 13
Training loss: 1.5308473018589694
Validation loss: 2.7275212041557495

Epoch: 589| Step: 0
Training loss: 1.1018596816445152
Validation loss: 2.6412940864806287

Epoch: 6| Step: 1
Training loss: 1.137585391517927
Validation loss: 2.7181980674653503

Epoch: 6| Step: 2
Training loss: 1.2086717635894324
Validation loss: 2.688572875976847

Epoch: 6| Step: 3
Training loss: 1.1827784081085024
Validation loss: 2.735067436334874

Epoch: 6| Step: 4
Training loss: 1.5053909701341461
Validation loss: 2.66689672426268

Epoch: 6| Step: 5
Training loss: 1.296975189383444
Validation loss: 2.6065312462385464

Epoch: 6| Step: 6
Training loss: 1.1306007629799542
Validation loss: 2.6820315993086714

Epoch: 6| Step: 7
Training loss: 1.280081518527839
Validation loss: 2.703205865914976

Epoch: 6| Step: 8
Training loss: 1.3829442624178339
Validation loss: 2.635667129386062

Epoch: 6| Step: 9
Training loss: 1.1966372360836008
Validation loss: 2.7208318852191162

Epoch: 6| Step: 10
Training loss: 1.672750796229923
Validation loss: 2.75069290858376

Epoch: 6| Step: 11
Training loss: 1.7297205976095325
Validation loss: 2.699168133360867

Epoch: 6| Step: 12
Training loss: 2.037276029856085
Validation loss: 2.6951580424828108

Epoch: 6| Step: 13
Training loss: 1.3186594529727638
Validation loss: 2.7176710106262525

Epoch: 590| Step: 0
Training loss: 1.5104053716127601
Validation loss: 2.669652867184153

Epoch: 6| Step: 1
Training loss: 1.5641263508601464
Validation loss: 2.7351908011468713

Epoch: 6| Step: 2
Training loss: 1.3941357048976075
Validation loss: 2.691054214426323

Epoch: 6| Step: 3
Training loss: 2.2123593991535255
Validation loss: 2.5954284930089675

Epoch: 6| Step: 4
Training loss: 1.1580157844113355
Validation loss: 2.7508603593181666

Epoch: 6| Step: 5
Training loss: 1.4117632134280076
Validation loss: 2.6868902384174387

Epoch: 6| Step: 6
Training loss: 1.295943465668704
Validation loss: 2.6733442506722467

Epoch: 6| Step: 7
Training loss: 0.9924785157191683
Validation loss: 2.6490383107392668

Epoch: 6| Step: 8
Training loss: 1.2698822475271216
Validation loss: 2.581590399593683

Epoch: 6| Step: 9
Training loss: 1.2596529178324998
Validation loss: 2.7201706292658643

Epoch: 6| Step: 10
Training loss: 1.437412425151692
Validation loss: 2.628071350078369

Epoch: 6| Step: 11
Training loss: 1.1293120925178872
Validation loss: 2.684556180101437

Epoch: 6| Step: 12
Training loss: 1.8610329809284722
Validation loss: 2.7123128526354683

Epoch: 6| Step: 13
Training loss: 1.1677182544532938
Validation loss: 2.6752260258886165

Epoch: 591| Step: 0
Training loss: 1.1050540968654912
Validation loss: 2.71720751007701

Epoch: 6| Step: 1
Training loss: 1.1206306271855881
Validation loss: 2.726293006415542

Epoch: 6| Step: 2
Training loss: 1.9635179418720852
Validation loss: 2.647929781398347

Epoch: 6| Step: 3
Training loss: 1.4275420720836811
Validation loss: 2.686824126940752

Epoch: 6| Step: 4
Training loss: 1.361409167117283
Validation loss: 2.6826253248395373

Epoch: 6| Step: 5
Training loss: 1.4652599506388506
Validation loss: 2.6858914782648524

Epoch: 6| Step: 6
Training loss: 1.5760678773437238
Validation loss: 2.6178656644538956

Epoch: 6| Step: 7
Training loss: 1.500129137838153
Validation loss: 2.617958898707519

Epoch: 6| Step: 8
Training loss: 1.4332255792405395
Validation loss: 2.67217542763983

Epoch: 6| Step: 9
Training loss: 1.3289180407486008
Validation loss: 2.7284629256995983

Epoch: 6| Step: 10
Training loss: 1.7368755700493776
Validation loss: 2.610896790176409

Epoch: 6| Step: 11
Training loss: 1.5726003349813245
Validation loss: 2.685696642863821

Epoch: 6| Step: 12
Training loss: 1.4129949090896978
Validation loss: 2.7076943513801357

Epoch: 6| Step: 13
Training loss: 1.4102720598761898
Validation loss: 2.7190292454499443

Epoch: 592| Step: 0
Training loss: 0.9720734225041922
Validation loss: 2.7203833746925983

Epoch: 6| Step: 1
Training loss: 1.3537770909128626
Validation loss: 2.69395445759688

Epoch: 6| Step: 2
Training loss: 1.3390560225660593
Validation loss: 2.6901225472272317

Epoch: 6| Step: 3
Training loss: 1.4668619723040153
Validation loss: 2.7301941084988948

Epoch: 6| Step: 4
Training loss: 0.8846850495353349
Validation loss: 2.746936695384543

Epoch: 6| Step: 5
Training loss: 1.973091908305182
Validation loss: 2.677035101501605

Epoch: 6| Step: 6
Training loss: 1.4114426427815991
Validation loss: 2.7177876565726113

Epoch: 6| Step: 7
Training loss: 1.2263150785638848
Validation loss: 2.652328715167841

Epoch: 6| Step: 8
Training loss: 1.3218810115163477
Validation loss: 2.669354043779588

Epoch: 6| Step: 9
Training loss: 1.7368919049429001
Validation loss: 2.663570062270843

Epoch: 6| Step: 10
Training loss: 1.1934497755307836
Validation loss: 2.6867033981430772

Epoch: 6| Step: 11
Training loss: 1.3087722884268682
Validation loss: 2.5837895144082763

Epoch: 6| Step: 12
Training loss: 1.3059296320057259
Validation loss: 2.6557500630556796

Epoch: 6| Step: 13
Training loss: 1.2209982553386798
Validation loss: 2.728183112271257

Epoch: 593| Step: 0
Training loss: 1.0692498159348207
Validation loss: 2.60219431028599

Epoch: 6| Step: 1
Training loss: 1.4639274477882076
Validation loss: 2.6596902196908667

Epoch: 6| Step: 2
Training loss: 1.051605128519605
Validation loss: 2.632014402936218

Epoch: 6| Step: 3
Training loss: 1.1864846556805035
Validation loss: 2.583283647846053

Epoch: 6| Step: 4
Training loss: 1.1910648044280243
Validation loss: 2.6652175698703218

Epoch: 6| Step: 5
Training loss: 1.2980503593074333
Validation loss: 2.5994364868491853

Epoch: 6| Step: 6
Training loss: 1.2130065960810892
Validation loss: 2.678261288776594

Epoch: 6| Step: 7
Training loss: 1.4838107994368388
Validation loss: 2.683740990373417

Epoch: 6| Step: 8
Training loss: 1.3783612781830006
Validation loss: 2.649706221156291

Epoch: 6| Step: 9
Training loss: 1.1812242010619485
Validation loss: 2.667169190620588

Epoch: 6| Step: 10
Training loss: 2.068278915382054
Validation loss: 2.738267553966166

Epoch: 6| Step: 11
Training loss: 1.3607961307508751
Validation loss: 2.656998718828471

Epoch: 6| Step: 12
Training loss: 1.4446421950438282
Validation loss: 2.693286523222836

Epoch: 6| Step: 13
Training loss: 2.0223801844015408
Validation loss: 2.597462489583981

Epoch: 594| Step: 0
Training loss: 1.135728437450354
Validation loss: 2.623035074422986

Epoch: 6| Step: 1
Training loss: 1.4508753765017304
Validation loss: 2.714070705489

Epoch: 6| Step: 2
Training loss: 1.63457368478189
Validation loss: 2.664928797390743

Epoch: 6| Step: 3
Training loss: 1.9987800572982017
Validation loss: 2.6173244772904543

Epoch: 6| Step: 4
Training loss: 1.174049293133086
Validation loss: 2.6606392043071203

Epoch: 6| Step: 5
Training loss: 1.1411513590305293
Validation loss: 2.7314465683004974

Epoch: 6| Step: 6
Training loss: 1.3873433600321095
Validation loss: 2.6587084285659306

Epoch: 6| Step: 7
Training loss: 1.5355445428994072
Validation loss: 2.7294460198435764

Epoch: 6| Step: 8
Training loss: 1.6795830982497983
Validation loss: 2.723325905632027

Epoch: 6| Step: 9
Training loss: 1.0121540326211929
Validation loss: 2.7585744910430243

Epoch: 6| Step: 10
Training loss: 1.3223261178405339
Validation loss: 2.6814360385984974

Epoch: 6| Step: 11
Training loss: 1.4693882144023864
Validation loss: 2.6195409374235865

Epoch: 6| Step: 12
Training loss: 1.4165360540130016
Validation loss: 2.6687121551221105

Epoch: 6| Step: 13
Training loss: 0.8988031058080818
Validation loss: 2.6872714194188743

Epoch: 595| Step: 0
Training loss: 1.771220161224343
Validation loss: 2.6493995945238593

Epoch: 6| Step: 1
Training loss: 1.1721486090094477
Validation loss: 2.6466560341094074

Epoch: 6| Step: 2
Training loss: 0.9033329483385661
Validation loss: 2.5999880224856

Epoch: 6| Step: 3
Training loss: 1.2118221865985013
Validation loss: 2.7036990399613163

Epoch: 6| Step: 4
Training loss: 1.210882074871957
Validation loss: 2.65426379796672

Epoch: 6| Step: 5
Training loss: 1.3079699495579145
Validation loss: 2.698016028776482

Epoch: 6| Step: 6
Training loss: 1.0211762935603246
Validation loss: 2.712260981266862

Epoch: 6| Step: 7
Training loss: 1.1848366132197046
Validation loss: 2.591906924968807

Epoch: 6| Step: 8
Training loss: 1.2359342746234383
Validation loss: 2.6827098284330684

Epoch: 6| Step: 9
Training loss: 1.2886087717249435
Validation loss: 2.664053181022185

Epoch: 6| Step: 10
Training loss: 2.2192390869944907
Validation loss: 2.6496387781892565

Epoch: 6| Step: 11
Training loss: 1.4913664950891719
Validation loss: 2.6958579889547543

Epoch: 6| Step: 12
Training loss: 1.3784422701707908
Validation loss: 2.5392885714240445

Epoch: 6| Step: 13
Training loss: 1.1211257557836105
Validation loss: 2.7197268047506817

Epoch: 596| Step: 0
Training loss: 1.000712855888334
Validation loss: 2.7670195025283255

Epoch: 6| Step: 1
Training loss: 0.7364501851956168
Validation loss: 2.71099061752254

Epoch: 6| Step: 2
Training loss: 1.3167714141674625
Validation loss: 2.6227240972817127

Epoch: 6| Step: 3
Training loss: 0.9836981732338226
Validation loss: 2.671984830703964

Epoch: 6| Step: 4
Training loss: 2.005778785579838
Validation loss: 2.6718585475531906

Epoch: 6| Step: 5
Training loss: 1.58139650774351
Validation loss: 2.660328218484695

Epoch: 6| Step: 6
Training loss: 1.1369129028209544
Validation loss: 2.633572561436927

Epoch: 6| Step: 7
Training loss: 1.438399489565834
Validation loss: 2.817720862902425

Epoch: 6| Step: 8
Training loss: 1.0282222342383858
Validation loss: 2.7227235129790426

Epoch: 6| Step: 9
Training loss: 1.2451842525596646
Validation loss: 2.666741318837045

Epoch: 6| Step: 10
Training loss: 1.4286617914639692
Validation loss: 2.7535071732048038

Epoch: 6| Step: 11
Training loss: 1.5751199343596625
Validation loss: 2.7008251483451486

Epoch: 6| Step: 12
Training loss: 1.7157444424211954
Validation loss: 2.8120575979616156

Epoch: 6| Step: 13
Training loss: 1.389400500270742
Validation loss: 2.6802643511091473

Epoch: 597| Step: 0
Training loss: 0.8583794115407851
Validation loss: 2.67554865383723

Epoch: 6| Step: 1
Training loss: 1.3655286916472287
Validation loss: 2.6556014570364486

Epoch: 6| Step: 2
Training loss: 1.1086207767603555
Validation loss: 2.671998708178654

Epoch: 6| Step: 3
Training loss: 1.2898880598011702
Validation loss: 2.5509945560829657

Epoch: 6| Step: 4
Training loss: 1.5973720904081314
Validation loss: 2.6800023562464292

Epoch: 6| Step: 5
Training loss: 1.6510152323278364
Validation loss: 2.6253518993264273

Epoch: 6| Step: 6
Training loss: 1.0008832487945787
Validation loss: 2.661704962477107

Epoch: 6| Step: 7
Training loss: 1.3345557311545648
Validation loss: 2.6872198479198874

Epoch: 6| Step: 8
Training loss: 1.3220891792527987
Validation loss: 2.724593447052337

Epoch: 6| Step: 9
Training loss: 1.7172983454853197
Validation loss: 2.6214496659496174

Epoch: 6| Step: 10
Training loss: 1.9414131271885235
Validation loss: 2.658708011048737

Epoch: 6| Step: 11
Training loss: 1.0930762259244102
Validation loss: 2.719229120722817

Epoch: 6| Step: 12
Training loss: 1.1970021889936657
Validation loss: 2.702140916340489

Epoch: 6| Step: 13
Training loss: 1.163344501033691
Validation loss: 2.599647468255807

Epoch: 598| Step: 0
Training loss: 1.5278445932439386
Validation loss: 2.6646195191634305

Epoch: 6| Step: 1
Training loss: 1.3582863230069127
Validation loss: 2.5845651549413518

Epoch: 6| Step: 2
Training loss: 1.8901618831677032
Validation loss: 2.668556888082732

Epoch: 6| Step: 3
Training loss: 1.2569999202524917
Validation loss: 2.6976460194279306

Epoch: 6| Step: 4
Training loss: 2.0929000040107817
Validation loss: 2.6166130619529535

Epoch: 6| Step: 5
Training loss: 1.3316170951933066
Validation loss: 2.6768228624343062

Epoch: 6| Step: 6
Training loss: 1.4327971612573103
Validation loss: 2.6009208984072263

Epoch: 6| Step: 7
Training loss: 1.214645614902905
Validation loss: 2.687884384105037

Epoch: 6| Step: 8
Training loss: 1.0557995620139866
Validation loss: 2.6489593885102694

Epoch: 6| Step: 9
Training loss: 1.1885277165834873
Validation loss: 2.6120349868785286

Epoch: 6| Step: 10
Training loss: 1.2727022915562123
Validation loss: 2.8355606295595663

Epoch: 6| Step: 11
Training loss: 0.9893256537926828
Validation loss: 2.665824278002876

Epoch: 6| Step: 12
Training loss: 1.4509703546304726
Validation loss: 2.6839886511052957

Epoch: 6| Step: 13
Training loss: 1.0611399753721296
Validation loss: 2.6686790391744837

Epoch: 599| Step: 0
Training loss: 1.288227157428752
Validation loss: 2.611404709275827

Epoch: 6| Step: 1
Training loss: 1.1656819797528537
Validation loss: 2.6871917826411558

Epoch: 6| Step: 2
Training loss: 1.4919701063367572
Validation loss: 2.6651801665953543

Epoch: 6| Step: 3
Training loss: 1.3331271946026515
Validation loss: 2.6494928405597613

Epoch: 6| Step: 4
Training loss: 1.426300873847891
Validation loss: 2.7900457150004336

Epoch: 6| Step: 5
Training loss: 2.0832596066462967
Validation loss: 2.696381509425117

Epoch: 6| Step: 6
Training loss: 1.2996251005844308
Validation loss: 2.78799673001341

Epoch: 6| Step: 7
Training loss: 1.2351239021017653
Validation loss: 2.6768926513710802

Epoch: 6| Step: 8
Training loss: 1.2109742189808397
Validation loss: 2.6041564928081677

Epoch: 6| Step: 9
Training loss: 1.1082876544994835
Validation loss: 2.667239187934641

Epoch: 6| Step: 10
Training loss: 1.3378126135587478
Validation loss: 2.66411445337748

Epoch: 6| Step: 11
Training loss: 1.3324949738226994
Validation loss: 2.649228478974004

Epoch: 6| Step: 12
Training loss: 1.1701482639760994
Validation loss: 2.6634438431228

Epoch: 6| Step: 13
Training loss: 1.8403566459533895
Validation loss: 2.58310741610368

Epoch: 600| Step: 0
Training loss: 0.9072804019256413
Validation loss: 2.7053425063029968

Epoch: 6| Step: 1
Training loss: 1.3049040745962939
Validation loss: 2.5728968655699176

Epoch: 6| Step: 2
Training loss: 1.0118581904051225
Validation loss: 2.5796492310949373

Epoch: 6| Step: 3
Training loss: 1.2957968309091992
Validation loss: 2.663178708185694

Epoch: 6| Step: 4
Training loss: 1.5831918485904857
Validation loss: 2.7614241789287526

Epoch: 6| Step: 5
Training loss: 1.927175639923107
Validation loss: 2.6295791060139013

Epoch: 6| Step: 6
Training loss: 1.4776290190467556
Validation loss: 2.656743873657717

Epoch: 6| Step: 7
Training loss: 1.4347271921113405
Validation loss: 2.6286541086592217

Epoch: 6| Step: 8
Training loss: 1.535456659563078
Validation loss: 2.5945974142592627

Epoch: 6| Step: 9
Training loss: 0.991889127788152
Validation loss: 2.6034199926859025

Epoch: 6| Step: 10
Training loss: 1.2587517021796528
Validation loss: 2.6596891025456824

Epoch: 6| Step: 11
Training loss: 1.2547656765308326
Validation loss: 2.6118958628748645

Epoch: 6| Step: 12
Training loss: 1.2385656950694248
Validation loss: 2.7009907826383315

Epoch: 6| Step: 13
Training loss: 1.4730925786331281
Validation loss: 2.6658867174797956

Epoch: 601| Step: 0
Training loss: 0.8850853618036727
Validation loss: 2.6374389607937725

Epoch: 6| Step: 1
Training loss: 1.1591299636061532
Validation loss: 2.6077710992461265

Epoch: 6| Step: 2
Training loss: 1.3966959759649675
Validation loss: 2.725644134530243

Epoch: 6| Step: 3
Training loss: 1.5275146700939717
Validation loss: 2.6382259784791944

Epoch: 6| Step: 4
Training loss: 1.1110953303382052
Validation loss: 2.704454690429919

Epoch: 6| Step: 5
Training loss: 1.2034203303124398
Validation loss: 2.6386661825958675

Epoch: 6| Step: 6
Training loss: 1.3062885077974304
Validation loss: 2.647031830584951

Epoch: 6| Step: 7
Training loss: 1.3207998335688607
Validation loss: 2.705880753871497

Epoch: 6| Step: 8
Training loss: 1.1798931220516211
Validation loss: 2.65574847897004

Epoch: 6| Step: 9
Training loss: 1.6967461496682952
Validation loss: 2.6597290669420293

Epoch: 6| Step: 10
Training loss: 1.4407857577645684
Validation loss: 2.6833261099460635

Epoch: 6| Step: 11
Training loss: 1.071792470351683
Validation loss: 2.6010100050763887

Epoch: 6| Step: 12
Training loss: 2.053835500004292
Validation loss: 2.7152183941718935

Epoch: 6| Step: 13
Training loss: 1.1186249561861827
Validation loss: 2.679377988784568

Epoch: 602| Step: 0
Training loss: 1.276263372143849
Validation loss: 2.632418751831207

Epoch: 6| Step: 1
Training loss: 1.3857216272314148
Validation loss: 2.637026836302901

Epoch: 6| Step: 2
Training loss: 0.9485882835626536
Validation loss: 2.6335933147368285

Epoch: 6| Step: 3
Training loss: 1.288149331060626
Validation loss: 2.8086055066388074

Epoch: 6| Step: 4
Training loss: 1.6802299865475208
Validation loss: 2.6855529844749664

Epoch: 6| Step: 5
Training loss: 1.6767391854763998
Validation loss: 2.559840521273655

Epoch: 6| Step: 6
Training loss: 1.4267224693228973
Validation loss: 2.6231525559192437

Epoch: 6| Step: 7
Training loss: 1.3360717884409496
Validation loss: 2.768296746013568

Epoch: 6| Step: 8
Training loss: 1.3477166646048377
Validation loss: 2.7146484531388166

Epoch: 6| Step: 9
Training loss: 0.993618871326576
Validation loss: 2.705061874497802

Epoch: 6| Step: 10
Training loss: 1.969982488041223
Validation loss: 2.6990945664388906

Epoch: 6| Step: 11
Training loss: 1.2317865974218647
Validation loss: 2.564981582050315

Epoch: 6| Step: 12
Training loss: 1.4635075285743657
Validation loss: 2.7101427462807037

Epoch: 6| Step: 13
Training loss: 1.7147029045501738
Validation loss: 2.650174222618405

Epoch: 603| Step: 0
Training loss: 1.4440886393469812
Validation loss: 2.6806835470095347

Epoch: 6| Step: 1
Training loss: 0.9451937640314952
Validation loss: 2.799099284575539

Epoch: 6| Step: 2
Training loss: 1.1430963889536094
Validation loss: 2.699715033038917

Epoch: 6| Step: 3
Training loss: 2.2873914432302547
Validation loss: 2.6704775980718054

Epoch: 6| Step: 4
Training loss: 1.2027044180409803
Validation loss: 2.777489854664079

Epoch: 6| Step: 5
Training loss: 1.5167487000019217
Validation loss: 2.7044683519993478

Epoch: 6| Step: 6
Training loss: 1.098847960704309
Validation loss: 2.732945976402273

Epoch: 6| Step: 7
Training loss: 1.458401932692385
Validation loss: 2.7529690842943184

Epoch: 6| Step: 8
Training loss: 1.4796981214969893
Validation loss: 2.7016383781327886

Epoch: 6| Step: 9
Training loss: 1.6200670782966184
Validation loss: 2.68621853618154

Epoch: 6| Step: 10
Training loss: 1.4749862088350731
Validation loss: 2.754912004660291

Epoch: 6| Step: 11
Training loss: 1.360274970643089
Validation loss: 2.7584364515593855

Epoch: 6| Step: 12
Training loss: 1.3444395292251805
Validation loss: 2.7072484237488146

Epoch: 6| Step: 13
Training loss: 1.1777673719854136
Validation loss: 2.691105626707601

Epoch: 604| Step: 0
Training loss: 1.3399255132611876
Validation loss: 2.7083596350542027

Epoch: 6| Step: 1
Training loss: 2.3843541895606943
Validation loss: 2.611238742095402

Epoch: 6| Step: 2
Training loss: 1.3833665330572065
Validation loss: 2.6767878815667427

Epoch: 6| Step: 3
Training loss: 1.6823143578604238
Validation loss: 2.6408310715314283

Epoch: 6| Step: 4
Training loss: 0.9177780927339906
Validation loss: 2.6166046350636543

Epoch: 6| Step: 5
Training loss: 1.2542578183546913
Validation loss: 2.7116531194004643

Epoch: 6| Step: 6
Training loss: 1.4305120706378966
Validation loss: 2.5718185640898708

Epoch: 6| Step: 7
Training loss: 1.3772858779009287
Validation loss: 2.6355590243600515

Epoch: 6| Step: 8
Training loss: 0.933986054677821
Validation loss: 2.6455650151549785

Epoch: 6| Step: 9
Training loss: 1.338340338423002
Validation loss: 2.568212431259238

Epoch: 6| Step: 10
Training loss: 1.0722984211671094
Validation loss: 2.710141486284298

Epoch: 6| Step: 11
Training loss: 1.1019866884157983
Validation loss: 2.749845800616582

Epoch: 6| Step: 12
Training loss: 1.4279875941712714
Validation loss: 2.6737703419156884

Epoch: 6| Step: 13
Training loss: 1.0707990000127683
Validation loss: 2.738294033152765

Epoch: 605| Step: 0
Training loss: 1.2544553986211793
Validation loss: 2.66454730170948

Epoch: 6| Step: 1
Training loss: 1.3235827243576725
Validation loss: 2.545347639420053

Epoch: 6| Step: 2
Training loss: 1.4606681208189065
Validation loss: 2.785419455759021

Epoch: 6| Step: 3
Training loss: 0.9852080075177462
Validation loss: 2.592395212685715

Epoch: 6| Step: 4
Training loss: 1.4532418973110497
Validation loss: 2.7405790399421646

Epoch: 6| Step: 5
Training loss: 1.3375374655066343
Validation loss: 2.6943326205948464

Epoch: 6| Step: 6
Training loss: 1.6164257817219916
Validation loss: 2.713796119048846

Epoch: 6| Step: 7
Training loss: 1.729946221193785
Validation loss: 2.729906594461496

Epoch: 6| Step: 8
Training loss: 1.2793939684648312
Validation loss: 2.746978349822787

Epoch: 6| Step: 9
Training loss: 1.7137178448332238
Validation loss: 2.7150694691818926

Epoch: 6| Step: 10
Training loss: 0.7989298189157001
Validation loss: 2.6835579412466393

Epoch: 6| Step: 11
Training loss: 1.9032278023751557
Validation loss: 2.678787970669981

Epoch: 6| Step: 12
Training loss: 1.0304691363862466
Validation loss: 2.7473878974763

Epoch: 6| Step: 13
Training loss: 1.1896877715078154
Validation loss: 2.6437017025183587

Epoch: 606| Step: 0
Training loss: 1.1296016043143726
Validation loss: 2.706233238508011

Epoch: 6| Step: 1
Training loss: 1.0070717625130168
Validation loss: 2.666905279661489

Epoch: 6| Step: 2
Training loss: 1.1935718303554836
Validation loss: 2.5822998530691095

Epoch: 6| Step: 3
Training loss: 1.5582818888096164
Validation loss: 2.7125400639869888

Epoch: 6| Step: 4
Training loss: 1.068853232768687
Validation loss: 2.714411289948823

Epoch: 6| Step: 5
Training loss: 1.5666643724357094
Validation loss: 2.7581298110132604

Epoch: 6| Step: 6
Training loss: 1.212983599307394
Validation loss: 2.690864054375631

Epoch: 6| Step: 7
Training loss: 1.477769308057971
Validation loss: 2.6417417049053498

Epoch: 6| Step: 8
Training loss: 1.381504064815587
Validation loss: 2.530302882574804

Epoch: 6| Step: 9
Training loss: 1.3405282187929686
Validation loss: 2.5509845698025964

Epoch: 6| Step: 10
Training loss: 1.168988857239024
Validation loss: 2.6241791062248474

Epoch: 6| Step: 11
Training loss: 1.1140614770400392
Validation loss: 2.73807648485646

Epoch: 6| Step: 12
Training loss: 2.0183250617758963
Validation loss: 2.6921863681150753

Epoch: 6| Step: 13
Training loss: 0.8317310705137746
Validation loss: 2.6820107252063394

Epoch: 607| Step: 0
Training loss: 2.1272101409007584
Validation loss: 2.693480916203976

Epoch: 6| Step: 1
Training loss: 1.1661751029444674
Validation loss: 2.7190693813966056

Epoch: 6| Step: 2
Training loss: 1.2574078400590898
Validation loss: 2.6000138955261627

Epoch: 6| Step: 3
Training loss: 1.0464891320405596
Validation loss: 2.635886069819321

Epoch: 6| Step: 4
Training loss: 1.1544387652718748
Validation loss: 2.7071356514489113

Epoch: 6| Step: 5
Training loss: 1.3671911621044703
Validation loss: 2.6322466658301287

Epoch: 6| Step: 6
Training loss: 1.36108221079621
Validation loss: 2.6045342075668723

Epoch: 6| Step: 7
Training loss: 1.4300845902772712
Validation loss: 2.660582228428054

Epoch: 6| Step: 8
Training loss: 0.732068355438204
Validation loss: 2.7203236515129263

Epoch: 6| Step: 9
Training loss: 0.9334701711673153
Validation loss: 2.6954240426025784

Epoch: 6| Step: 10
Training loss: 1.6492783991490885
Validation loss: 2.6006978512388113

Epoch: 6| Step: 11
Training loss: 1.3818471523948612
Validation loss: 2.6103383914498646

Epoch: 6| Step: 12
Training loss: 1.2357004992159355
Validation loss: 2.706821408361724

Epoch: 6| Step: 13
Training loss: 0.8759899669969731
Validation loss: 2.640353935548594

Epoch: 608| Step: 0
Training loss: 1.129165250113374
Validation loss: 2.7123914200990984

Epoch: 6| Step: 1
Training loss: 1.209784075331789
Validation loss: 2.5996779105076966

Epoch: 6| Step: 2
Training loss: 1.108526630802675
Validation loss: 2.689045410460409

Epoch: 6| Step: 3
Training loss: 1.2412414306928743
Validation loss: 2.6194578243604885

Epoch: 6| Step: 4
Training loss: 1.4184761085474862
Validation loss: 2.5863980158729842

Epoch: 6| Step: 5
Training loss: 1.5459763970541118
Validation loss: 2.63455477606806

Epoch: 6| Step: 6
Training loss: 1.343529039890373
Validation loss: 2.7482780013418457

Epoch: 6| Step: 7
Training loss: 1.6636590602906982
Validation loss: 2.6497211177598037

Epoch: 6| Step: 8
Training loss: 1.3506573860207987
Validation loss: 2.616320461254097

Epoch: 6| Step: 9
Training loss: 1.9735637126077707
Validation loss: 2.6987493397805

Epoch: 6| Step: 10
Training loss: 1.1305167250612926
Validation loss: 2.6875532678703755

Epoch: 6| Step: 11
Training loss: 1.3558218987906319
Validation loss: 2.640773469270762

Epoch: 6| Step: 12
Training loss: 1.184670742020031
Validation loss: 2.765971407786191

Epoch: 6| Step: 13
Training loss: 1.3894743713178714
Validation loss: 2.637552284103911

Epoch: 609| Step: 0
Training loss: 1.4378242127062288
Validation loss: 2.6115913589467143

Epoch: 6| Step: 1
Training loss: 1.1655716298339118
Validation loss: 2.681062773395412

Epoch: 6| Step: 2
Training loss: 1.250812457217749
Validation loss: 2.6997040898637303

Epoch: 6| Step: 3
Training loss: 1.8784443055446716
Validation loss: 2.6538108576243733

Epoch: 6| Step: 4
Training loss: 1.2033506900102702
Validation loss: 2.5989504680103113

Epoch: 6| Step: 5
Training loss: 1.4310862884843425
Validation loss: 2.6688592079056157

Epoch: 6| Step: 6
Training loss: 1.4152409822129182
Validation loss: 2.7696465874466316

Epoch: 6| Step: 7
Training loss: 1.4065867126862392
Validation loss: 2.6339551738442513

Epoch: 6| Step: 8
Training loss: 1.4563300769711585
Validation loss: 2.6797529638492916

Epoch: 6| Step: 9
Training loss: 1.0877134223316745
Validation loss: 2.6837004072721995

Epoch: 6| Step: 10
Training loss: 1.3070042308105545
Validation loss: 2.5767697428690655

Epoch: 6| Step: 11
Training loss: 1.3637436571681756
Validation loss: 2.752297496990037

Epoch: 6| Step: 12
Training loss: 1.08724139854904
Validation loss: 2.640961254457922

Epoch: 6| Step: 13
Training loss: 1.6953643931519935
Validation loss: 2.6540117401678924

Epoch: 610| Step: 0
Training loss: 0.8536199510307438
Validation loss: 2.5841798672201346

Epoch: 6| Step: 1
Training loss: 2.0867867901791057
Validation loss: 2.6218664605241924

Epoch: 6| Step: 2
Training loss: 1.2964033625049762
Validation loss: 2.737816991249471

Epoch: 6| Step: 3
Training loss: 1.2437003657726398
Validation loss: 2.7119733176705787

Epoch: 6| Step: 4
Training loss: 1.1049074291273988
Validation loss: 2.671516326738699

Epoch: 6| Step: 5
Training loss: 1.6396324425031328
Validation loss: 2.7575461236823253

Epoch: 6| Step: 6
Training loss: 1.250804928061668
Validation loss: 2.749626792500103

Epoch: 6| Step: 7
Training loss: 1.544546050259846
Validation loss: 2.7488896709777078

Epoch: 6| Step: 8
Training loss: 1.1592946047811763
Validation loss: 2.742800539089932

Epoch: 6| Step: 9
Training loss: 1.1912125727086713
Validation loss: 2.684590884036055

Epoch: 6| Step: 10
Training loss: 1.2678425047353712
Validation loss: 2.6433251988700714

Epoch: 6| Step: 11
Training loss: 1.449565177702175
Validation loss: 2.741859182892251

Epoch: 6| Step: 12
Training loss: 1.380239560715675
Validation loss: 2.7259978762153807

Epoch: 6| Step: 13
Training loss: 0.9190090696491254
Validation loss: 2.700471987235923

Epoch: 611| Step: 0
Training loss: 1.432023771259198
Validation loss: 2.747566845265352

Epoch: 6| Step: 1
Training loss: 2.0815210343488646
Validation loss: 2.6999113901623706

Epoch: 6| Step: 2
Training loss: 0.7719369068107954
Validation loss: 2.652793503863414

Epoch: 6| Step: 3
Training loss: 1.4291897099956998
Validation loss: 2.621311339423425

Epoch: 6| Step: 4
Training loss: 1.1258690973827856
Validation loss: 2.6117373207007284

Epoch: 6| Step: 5
Training loss: 1.842043717510651
Validation loss: 2.704556418742236

Epoch: 6| Step: 6
Training loss: 1.4662696510552597
Validation loss: 2.7172023360081994

Epoch: 6| Step: 7
Training loss: 0.9650840923254846
Validation loss: 2.636271978558081

Epoch: 6| Step: 8
Training loss: 1.4249351185534
Validation loss: 2.6548565224893097

Epoch: 6| Step: 9
Training loss: 1.3649167631432506
Validation loss: 2.75362939256754

Epoch: 6| Step: 10
Training loss: 1.367625444296927
Validation loss: 2.7079299784159963

Epoch: 6| Step: 11
Training loss: 0.9144710051798117
Validation loss: 2.696810902247893

Epoch: 6| Step: 12
Training loss: 1.2082253879255949
Validation loss: 2.711105426115767

Epoch: 6| Step: 13
Training loss: 1.1545138340745242
Validation loss: 2.6085729950120746

Epoch: 612| Step: 0
Training loss: 1.3382178581620896
Validation loss: 2.63849585656901

Epoch: 6| Step: 1
Training loss: 1.0163416754744206
Validation loss: 2.7306449760855274

Epoch: 6| Step: 2
Training loss: 0.9130225827682166
Validation loss: 2.7125345634586004

Epoch: 6| Step: 3
Training loss: 2.0854923759180246
Validation loss: 2.7262266392763514

Epoch: 6| Step: 4
Training loss: 1.181012401199155
Validation loss: 2.7049524798351436

Epoch: 6| Step: 5
Training loss: 1.7259755237209728
Validation loss: 2.755617041430566

Epoch: 6| Step: 6
Training loss: 1.0491501866006552
Validation loss: 2.586351645581654

Epoch: 6| Step: 7
Training loss: 1.022538583862272
Validation loss: 2.6337493878043947

Epoch: 6| Step: 8
Training loss: 1.364420504962298
Validation loss: 2.714201947095507

Epoch: 6| Step: 9
Training loss: 1.3477655781061602
Validation loss: 2.6801298253506345

Epoch: 6| Step: 10
Training loss: 1.6602896603105235
Validation loss: 2.6523892261031117

Epoch: 6| Step: 11
Training loss: 1.1168230435967097
Validation loss: 2.6831888914228252

Epoch: 6| Step: 12
Training loss: 1.0937199179735952
Validation loss: 2.6491075668083446

Epoch: 6| Step: 13
Training loss: 0.8198738014990609
Validation loss: 2.634063001131725

Epoch: 613| Step: 0
Training loss: 1.7759195175750653
Validation loss: 2.6575847141257243

Epoch: 6| Step: 1
Training loss: 1.1066101436274873
Validation loss: 2.6708040219276667

Epoch: 6| Step: 2
Training loss: 1.2328233261503314
Validation loss: 2.703108690335811

Epoch: 6| Step: 3
Training loss: 0.8800498812258242
Validation loss: 2.6984059092166337

Epoch: 6| Step: 4
Training loss: 1.3640372030352923
Validation loss: 2.7503621989925207

Epoch: 6| Step: 5
Training loss: 0.949865960402559
Validation loss: 2.6651889316673225

Epoch: 6| Step: 6
Training loss: 2.157985044482346
Validation loss: 2.6547229438192557

Epoch: 6| Step: 7
Training loss: 0.965407326617039
Validation loss: 2.69484495602295

Epoch: 6| Step: 8
Training loss: 1.0230657470174325
Validation loss: 2.7100297623822267

Epoch: 6| Step: 9
Training loss: 1.5546738513749983
Validation loss: 2.6914878751991322

Epoch: 6| Step: 10
Training loss: 1.4101551932967604
Validation loss: 2.681219573694121

Epoch: 6| Step: 11
Training loss: 1.3269747072294593
Validation loss: 2.6113569742000893

Epoch: 6| Step: 12
Training loss: 1.442530578606514
Validation loss: 2.650789518956856

Epoch: 6| Step: 13
Training loss: 1.328317157083675
Validation loss: 2.7321520867314426

Epoch: 614| Step: 0
Training loss: 1.376136137005355
Validation loss: 2.6441104044081882

Epoch: 6| Step: 1
Training loss: 0.9654528590961352
Validation loss: 2.6123863225706647

Epoch: 6| Step: 2
Training loss: 0.7619156020676255
Validation loss: 2.8183521253063217

Epoch: 6| Step: 3
Training loss: 1.255866304322106
Validation loss: 2.7272477679650255

Epoch: 6| Step: 4
Training loss: 0.9654676759821605
Validation loss: 2.723590116711435

Epoch: 6| Step: 5
Training loss: 2.340917477841012
Validation loss: 2.7372996151050235

Epoch: 6| Step: 6
Training loss: 1.0550960173461477
Validation loss: 2.6149939561993354

Epoch: 6| Step: 7
Training loss: 1.7164490990896366
Validation loss: 2.650123213869432

Epoch: 6| Step: 8
Training loss: 0.9948993777669697
Validation loss: 2.700836822609975

Epoch: 6| Step: 9
Training loss: 1.3047033525977176
Validation loss: 2.6495251745427266

Epoch: 6| Step: 10
Training loss: 1.5776055113605232
Validation loss: 2.6744705390010193

Epoch: 6| Step: 11
Training loss: 1.0355416210362167
Validation loss: 2.606524850237911

Epoch: 6| Step: 12
Training loss: 1.42786178333491
Validation loss: 2.6195244038848444

Epoch: 6| Step: 13
Training loss: 1.3853931807437048
Validation loss: 2.7308973736201443

Epoch: 615| Step: 0
Training loss: 1.014346976560046
Validation loss: 2.6570642766236157

Epoch: 6| Step: 1
Training loss: 1.9436293831349627
Validation loss: 2.7309048263774063

Epoch: 6| Step: 2
Training loss: 1.1517059112648855
Validation loss: 2.7167618662434534

Epoch: 6| Step: 3
Training loss: 1.5215950020957718
Validation loss: 2.705698446467961

Epoch: 6| Step: 4
Training loss: 1.2661957572322435
Validation loss: 2.6724708342288577

Epoch: 6| Step: 5
Training loss: 1.1085908294273654
Validation loss: 2.565527856112876

Epoch: 6| Step: 6
Training loss: 1.3783041528352071
Validation loss: 2.6835031973712917

Epoch: 6| Step: 7
Training loss: 1.0577388563116845
Validation loss: 2.635799205260134

Epoch: 6| Step: 8
Training loss: 1.6761821276231825
Validation loss: 2.728645023735207

Epoch: 6| Step: 9
Training loss: 1.157796289739761
Validation loss: 2.670101639186216

Epoch: 6| Step: 10
Training loss: 1.3418985519865305
Validation loss: 2.740365697613772

Epoch: 6| Step: 11
Training loss: 1.5917915578179982
Validation loss: 2.8258149983400482

Epoch: 6| Step: 12
Training loss: 0.7118525642027841
Validation loss: 2.6256201637030725

Epoch: 6| Step: 13
Training loss: 1.2963314985738181
Validation loss: 2.7232710226235506

Epoch: 616| Step: 0
Training loss: 1.3776372414015543
Validation loss: 2.5523834892461346

Epoch: 6| Step: 1
Training loss: 1.5950004309770247
Validation loss: 2.741593744810707

Epoch: 6| Step: 2
Training loss: 1.6276034993488215
Validation loss: 2.7202007702496185

Epoch: 6| Step: 3
Training loss: 1.1038967318438353
Validation loss: 2.6492740898371276

Epoch: 6| Step: 4
Training loss: 2.2206184149616846
Validation loss: 2.663909552628378

Epoch: 6| Step: 5
Training loss: 1.290737935960194
Validation loss: 2.7214888093335796

Epoch: 6| Step: 6
Training loss: 1.2445038126131895
Validation loss: 2.6983912469401825

Epoch: 6| Step: 7
Training loss: 1.247950781524131
Validation loss: 2.6789075604400656

Epoch: 6| Step: 8
Training loss: 1.5071578111597566
Validation loss: 2.6540996859746104

Epoch: 6| Step: 9
Training loss: 1.2415468495225326
Validation loss: 2.655636763315351

Epoch: 6| Step: 10
Training loss: 0.9455412595774894
Validation loss: 2.655128650564456

Epoch: 6| Step: 11
Training loss: 1.2310725108373561
Validation loss: 2.6402647245098456

Epoch: 6| Step: 12
Training loss: 1.079898260499048
Validation loss: 2.6714654750285654

Epoch: 6| Step: 13
Training loss: 1.415995672677319
Validation loss: 2.661310666747033

Epoch: 617| Step: 0
Training loss: 1.1795114550064594
Validation loss: 2.5968451240893833

Epoch: 6| Step: 1
Training loss: 0.9439334110115121
Validation loss: 2.6928206495912894

Epoch: 6| Step: 2
Training loss: 1.2976405630248675
Validation loss: 2.7361971370363793

Epoch: 6| Step: 3
Training loss: 1.1639181982116682
Validation loss: 2.599617841202357

Epoch: 6| Step: 4
Training loss: 1.4469230956947008
Validation loss: 2.6617106686965712

Epoch: 6| Step: 5
Training loss: 1.1105377121747615
Validation loss: 2.6758719566401483

Epoch: 6| Step: 6
Training loss: 1.6834360566601285
Validation loss: 2.78755768894159

Epoch: 6| Step: 7
Training loss: 1.5419781172667915
Validation loss: 2.681285930446056

Epoch: 6| Step: 8
Training loss: 0.9425870525824204
Validation loss: 2.6489644665079086

Epoch: 6| Step: 9
Training loss: 2.072081993660518
Validation loss: 2.714854329973051

Epoch: 6| Step: 10
Training loss: 1.3197390422651574
Validation loss: 2.666697234381042

Epoch: 6| Step: 11
Training loss: 1.0304535767057765
Validation loss: 2.775179443351878

Epoch: 6| Step: 12
Training loss: 1.3563518890220332
Validation loss: 2.66340204210662

Epoch: 6| Step: 13
Training loss: 0.9916100811775547
Validation loss: 2.690667643930934

Epoch: 618| Step: 0
Training loss: 1.318711342629172
Validation loss: 2.7097461514587

Epoch: 6| Step: 1
Training loss: 1.3289482706592672
Validation loss: 2.615395861959101

Epoch: 6| Step: 2
Training loss: 0.8395839555484054
Validation loss: 2.642515576187934

Epoch: 6| Step: 3
Training loss: 1.9028423681998865
Validation loss: 2.6951714410856615

Epoch: 6| Step: 4
Training loss: 1.2913103329946032
Validation loss: 2.7536013952657523

Epoch: 6| Step: 5
Training loss: 1.0685887622228785
Validation loss: 2.77167719419048

Epoch: 6| Step: 6
Training loss: 0.9076414278658556
Validation loss: 2.772687269711161

Epoch: 6| Step: 7
Training loss: 1.2201446964881018
Validation loss: 2.707415688595704

Epoch: 6| Step: 8
Training loss: 1.3976483382656257
Validation loss: 2.7323516025332246

Epoch: 6| Step: 9
Training loss: 1.5575117213020928
Validation loss: 2.726356832143189

Epoch: 6| Step: 10
Training loss: 1.5063367351711079
Validation loss: 2.6522615227799573

Epoch: 6| Step: 11
Training loss: 0.8615856866826238
Validation loss: 2.632285847970665

Epoch: 6| Step: 12
Training loss: 1.0608454331464359
Validation loss: 2.609839568188722

Epoch: 6| Step: 13
Training loss: 0.9902696772495673
Validation loss: 2.6486776610086182

Epoch: 619| Step: 0
Training loss: 1.4415346000612779
Validation loss: 2.746671946799562

Epoch: 6| Step: 1
Training loss: 0.8745579965552223
Validation loss: 2.771762147885903

Epoch: 6| Step: 2
Training loss: 1.3895781788117958
Validation loss: 2.652189915139551

Epoch: 6| Step: 3
Training loss: 1.2381911861747414
Validation loss: 2.6648457877175855

Epoch: 6| Step: 4
Training loss: 1.5557760903538305
Validation loss: 2.686940294435334

Epoch: 6| Step: 5
Training loss: 1.2815412795033827
Validation loss: 2.6421171495285343

Epoch: 6| Step: 6
Training loss: 1.3626033551273224
Validation loss: 2.702514888762674

Epoch: 6| Step: 7
Training loss: 0.8952210278077423
Validation loss: 2.7028502718805494

Epoch: 6| Step: 8
Training loss: 1.3214279519083345
Validation loss: 2.6847935332211783

Epoch: 6| Step: 9
Training loss: 0.8255472189038938
Validation loss: 2.717627567440753

Epoch: 6| Step: 10
Training loss: 2.2411347685858507
Validation loss: 2.666704375310615

Epoch: 6| Step: 11
Training loss: 0.6930411024716489
Validation loss: 2.6511372843662144

Epoch: 6| Step: 12
Training loss: 1.0875257774016491
Validation loss: 2.6294110158884436

Epoch: 6| Step: 13
Training loss: 0.6731951408005733
Validation loss: 2.6718385016637387

Epoch: 620| Step: 0
Training loss: 1.3629644512234231
Validation loss: 2.7048334568059826

Epoch: 6| Step: 1
Training loss: 1.0329375475554965
Validation loss: 2.726192033255474

Epoch: 6| Step: 2
Training loss: 0.8020236542202877
Validation loss: 2.715568078873309

Epoch: 6| Step: 3
Training loss: 1.2184043296257383
Validation loss: 2.7133170518247804

Epoch: 6| Step: 4
Training loss: 1.0202380540218983
Validation loss: 2.6696514133048765

Epoch: 6| Step: 5
Training loss: 1.312019986977343
Validation loss: 2.6955228866401186

Epoch: 6| Step: 6
Training loss: 1.6577484981396022
Validation loss: 2.6846268060177487

Epoch: 6| Step: 7
Training loss: 0.908335128543258
Validation loss: 2.6296580766232065

Epoch: 6| Step: 8
Training loss: 2.2366362113793166
Validation loss: 2.724678324776969

Epoch: 6| Step: 9
Training loss: 0.9189873421246626
Validation loss: 2.6223272144020147

Epoch: 6| Step: 10
Training loss: 1.24229977658124
Validation loss: 2.768352917234738

Epoch: 6| Step: 11
Training loss: 1.3232534485510223
Validation loss: 2.692210903735788

Epoch: 6| Step: 12
Training loss: 1.377928822366401
Validation loss: 2.6979663540386363

Epoch: 6| Step: 13
Training loss: 0.5200394460957064
Validation loss: 2.6400662946565334

Epoch: 621| Step: 0
Training loss: 1.3321074970158966
Validation loss: 2.6988499057893685

Epoch: 6| Step: 1
Training loss: 1.4457663983215356
Validation loss: 2.702868779804932

Epoch: 6| Step: 2
Training loss: 1.0950400238038334
Validation loss: 2.6803390293025795

Epoch: 6| Step: 3
Training loss: 1.4013641251055389
Validation loss: 2.6685876057855835

Epoch: 6| Step: 4
Training loss: 2.0180216889742315
Validation loss: 2.70462212805266

Epoch: 6| Step: 5
Training loss: 1.1932669695900922
Validation loss: 2.6938018155825265

Epoch: 6| Step: 6
Training loss: 1.2864282684313713
Validation loss: 2.6965265722205367

Epoch: 6| Step: 7
Training loss: 1.0237582337510627
Validation loss: 2.7581733356698455

Epoch: 6| Step: 8
Training loss: 1.2630742117492488
Validation loss: 2.7497788197681894

Epoch: 6| Step: 9
Training loss: 1.5841228457508236
Validation loss: 2.716927731095287

Epoch: 6| Step: 10
Training loss: 0.7591482758065345
Validation loss: 2.87177846485819

Epoch: 6| Step: 11
Training loss: 1.1924696882062242
Validation loss: 2.5275889904669557

Epoch: 6| Step: 12
Training loss: 1.2756523109215046
Validation loss: 2.7249563841176507

Epoch: 6| Step: 13
Training loss: 1.438354404128628
Validation loss: 2.6817040838140214

Epoch: 622| Step: 0
Training loss: 1.3782065888558042
Validation loss: 2.6860711271578688

Epoch: 6| Step: 1
Training loss: 1.2735370526863852
Validation loss: 2.5960140840925194

Epoch: 6| Step: 2
Training loss: 1.0563525020364437
Validation loss: 2.6746464261123912

Epoch: 6| Step: 3
Training loss: 1.3474733090278561
Validation loss: 2.631199238246863

Epoch: 6| Step: 4
Training loss: 2.09245442403475
Validation loss: 2.6469623972033145

Epoch: 6| Step: 5
Training loss: 0.6809166066228031
Validation loss: 2.6085939054344713

Epoch: 6| Step: 6
Training loss: 1.1471207524321057
Validation loss: 2.744306016811203

Epoch: 6| Step: 7
Training loss: 1.0234309188980617
Validation loss: 2.692555058765168

Epoch: 6| Step: 8
Training loss: 1.1320555163744976
Validation loss: 2.686145501233831

Epoch: 6| Step: 9
Training loss: 1.2824535299734814
Validation loss: 2.676903845818013

Epoch: 6| Step: 10
Training loss: 1.1256985085317452
Validation loss: 2.739937654138778

Epoch: 6| Step: 11
Training loss: 1.5516895929781005
Validation loss: 2.6338255634708028

Epoch: 6| Step: 12
Training loss: 1.4601483176941024
Validation loss: 2.7033757165763355

Epoch: 6| Step: 13
Training loss: 1.056476573231218
Validation loss: 2.705086892288777

Epoch: 623| Step: 0
Training loss: 1.1210325005045572
Validation loss: 2.6780451698671004

Epoch: 6| Step: 1
Training loss: 1.3434278412476355
Validation loss: 2.70781095277128

Epoch: 6| Step: 2
Training loss: 1.0401308690774154
Validation loss: 2.606145935664414

Epoch: 6| Step: 3
Training loss: 1.6029262040226937
Validation loss: 2.6549016320663568

Epoch: 6| Step: 4
Training loss: 1.107528654464066
Validation loss: 2.6321565858923277

Epoch: 6| Step: 5
Training loss: 2.083300348656526
Validation loss: 2.6896500635366953

Epoch: 6| Step: 6
Training loss: 1.226289123393226
Validation loss: 2.6912296797511623

Epoch: 6| Step: 7
Training loss: 1.059139885032324
Validation loss: 2.744423681987726

Epoch: 6| Step: 8
Training loss: 1.1760346402593875
Validation loss: 2.681395278155083

Epoch: 6| Step: 9
Training loss: 1.1243776083253862
Validation loss: 2.749533627696749

Epoch: 6| Step: 10
Training loss: 1.2523008152389523
Validation loss: 2.7027669063991757

Epoch: 6| Step: 11
Training loss: 1.3688018423217423
Validation loss: 2.729036843008911

Epoch: 6| Step: 12
Training loss: 1.3350012102728797
Validation loss: 2.7528126829794792

Epoch: 6| Step: 13
Training loss: 1.1371247395689903
Validation loss: 2.692491977094054

Epoch: 624| Step: 0
Training loss: 2.1263786780224807
Validation loss: 2.6643697125889334

Epoch: 6| Step: 1
Training loss: 1.0282331322849956
Validation loss: 2.703084335196729

Epoch: 6| Step: 2
Training loss: 1.1795505671574946
Validation loss: 2.6433072371051316

Epoch: 6| Step: 3
Training loss: 1.2492024738523018
Validation loss: 2.645557881122098

Epoch: 6| Step: 4
Training loss: 1.1978698002589838
Validation loss: 2.713425563167306

Epoch: 6| Step: 5
Training loss: 1.0927438740485484
Validation loss: 2.6437216427194534

Epoch: 6| Step: 6
Training loss: 1.6427499724315409
Validation loss: 2.7162898871809817

Epoch: 6| Step: 7
Training loss: 1.3085877831166435
Validation loss: 2.6544581228339927

Epoch: 6| Step: 8
Training loss: 1.2347567487069986
Validation loss: 2.6010447454418073

Epoch: 6| Step: 9
Training loss: 1.3102448935595734
Validation loss: 2.60018041649723

Epoch: 6| Step: 10
Training loss: 1.3348966414198238
Validation loss: 2.7287149125099335

Epoch: 6| Step: 11
Training loss: 1.115259227041535
Validation loss: 2.6705702857376057

Epoch: 6| Step: 12
Training loss: 1.3245981398758173
Validation loss: 2.6261851501244022

Epoch: 6| Step: 13
Training loss: 1.211855780147595
Validation loss: 2.7147930044615043

Epoch: 625| Step: 0
Training loss: 1.1907516932726732
Validation loss: 2.6057023548818643

Epoch: 6| Step: 1
Training loss: 1.4615056366265282
Validation loss: 2.6512630973034037

Epoch: 6| Step: 2
Training loss: 1.09365871593473
Validation loss: 2.6938945619839214

Epoch: 6| Step: 3
Training loss: 1.9076356073175469
Validation loss: 2.7619356900794574

Epoch: 6| Step: 4
Training loss: 1.3448063446512504
Validation loss: 2.7978707110421834

Epoch: 6| Step: 5
Training loss: 1.1525819693851425
Validation loss: 2.6884936846818737

Epoch: 6| Step: 6
Training loss: 1.1167864313000881
Validation loss: 2.7044521907306254

Epoch: 6| Step: 7
Training loss: 1.2219494614022763
Validation loss: 2.790189258129556

Epoch: 6| Step: 8
Training loss: 1.322819243120345
Validation loss: 2.763449658116947

Epoch: 6| Step: 9
Training loss: 1.475006494669436
Validation loss: 2.747526973519664

Epoch: 6| Step: 10
Training loss: 0.8197143190208963
Validation loss: 2.760457291461841

Epoch: 6| Step: 11
Training loss: 0.9121764850637508
Validation loss: 2.7745571743569406

Epoch: 6| Step: 12
Training loss: 1.708265822712605
Validation loss: 2.7686550337704188

Epoch: 6| Step: 13
Training loss: 1.168675798722831
Validation loss: 2.657603624103764

Epoch: 626| Step: 0
Training loss: 1.314699555149759
Validation loss: 2.653877711325948

Epoch: 6| Step: 1
Training loss: 1.4427831012985208
Validation loss: 2.6152671678285566

Epoch: 6| Step: 2
Training loss: 1.173937191077517
Validation loss: 2.6941869324972254

Epoch: 6| Step: 3
Training loss: 1.502932701578768
Validation loss: 2.7152834168196818

Epoch: 6| Step: 4
Training loss: 0.7209244881767389
Validation loss: 2.657895740752367

Epoch: 6| Step: 5
Training loss: 1.9788184277865681
Validation loss: 2.698012589069335

Epoch: 6| Step: 6
Training loss: 0.8659192683359764
Validation loss: 2.681101934408901

Epoch: 6| Step: 7
Training loss: 1.6488245649735391
Validation loss: 2.6704668230851274

Epoch: 6| Step: 8
Training loss: 1.1082682394449634
Validation loss: 2.7086246207625377

Epoch: 6| Step: 9
Training loss: 1.3211979802915708
Validation loss: 2.7049756296755465

Epoch: 6| Step: 10
Training loss: 1.2838282811442105
Validation loss: 2.630258914766142

Epoch: 6| Step: 11
Training loss: 1.1758631173968281
Validation loss: 2.645758600578859

Epoch: 6| Step: 12
Training loss: 0.8548797949009314
Validation loss: 2.661587770618969

Epoch: 6| Step: 13
Training loss: 0.9623733276142573
Validation loss: 2.64655111832853

Epoch: 627| Step: 0
Training loss: 1.4961192474981315
Validation loss: 2.7536423549090423

Epoch: 6| Step: 1
Training loss: 1.9867424846856
Validation loss: 2.673519367088808

Epoch: 6| Step: 2
Training loss: 1.500235539063269
Validation loss: 2.701156797799925

Epoch: 6| Step: 3
Training loss: 1.6671110355535717
Validation loss: 2.664413872118063

Epoch: 6| Step: 4
Training loss: 0.9967021804295823
Validation loss: 2.597203687865993

Epoch: 6| Step: 5
Training loss: 0.9795811195353928
Validation loss: 2.7709943299140862

Epoch: 6| Step: 6
Training loss: 1.1553168268512228
Validation loss: 2.7377038656237525

Epoch: 6| Step: 7
Training loss: 0.7267459924808496
Validation loss: 2.6355141566513733

Epoch: 6| Step: 8
Training loss: 0.8943808483303108
Validation loss: 2.663357761844511

Epoch: 6| Step: 9
Training loss: 1.4493141657015984
Validation loss: 2.589179220070106

Epoch: 6| Step: 10
Training loss: 1.540593968324567
Validation loss: 2.6532951244875953

Epoch: 6| Step: 11
Training loss: 1.045449325205469
Validation loss: 2.662009491550326

Epoch: 6| Step: 12
Training loss: 1.1647205924738837
Validation loss: 2.666888649479077

Epoch: 6| Step: 13
Training loss: 0.9329001112390845
Validation loss: 2.69218679567632

Epoch: 628| Step: 0
Training loss: 1.2280872368284699
Validation loss: 2.7480419810257115

Epoch: 6| Step: 1
Training loss: 1.0441742406044219
Validation loss: 2.5933053754554347

Epoch: 6| Step: 2
Training loss: 1.3022020616442695
Validation loss: 2.686876096276105

Epoch: 6| Step: 3
Training loss: 1.3544704487767525
Validation loss: 2.6768150139262477

Epoch: 6| Step: 4
Training loss: 1.4898932430245972
Validation loss: 2.7171015529195093

Epoch: 6| Step: 5
Training loss: 1.227155602771338
Validation loss: 2.700831903838963

Epoch: 6| Step: 6
Training loss: 1.1689134432496502
Validation loss: 2.7494819736779714

Epoch: 6| Step: 7
Training loss: 1.0956623797397134
Validation loss: 2.7092970103060265

Epoch: 6| Step: 8
Training loss: 1.2819097262569927
Validation loss: 2.6445024621811073

Epoch: 6| Step: 9
Training loss: 1.538148715236705
Validation loss: 2.7557021553242556

Epoch: 6| Step: 10
Training loss: 1.2450958369799372
Validation loss: 2.7185865274574987

Epoch: 6| Step: 11
Training loss: 1.3130880128570865
Validation loss: 2.724825194781462

Epoch: 6| Step: 12
Training loss: 1.2075034393830215
Validation loss: 2.7574166447782402

Epoch: 6| Step: 13
Training loss: 2.387939141116206
Validation loss: 2.6183150909823953

Epoch: 629| Step: 0
Training loss: 1.429437584217892
Validation loss: 2.674257268138701

Epoch: 6| Step: 1
Training loss: 1.4967485792574775
Validation loss: 2.6071055348635515

Epoch: 6| Step: 2
Training loss: 0.953592404685399
Validation loss: 2.675865681352644

Epoch: 6| Step: 3
Training loss: 1.1873877622868465
Validation loss: 2.7524514798539252

Epoch: 6| Step: 4
Training loss: 1.0591154044887316
Validation loss: 2.656492511022687

Epoch: 6| Step: 5
Training loss: 1.3745214323035995
Validation loss: 2.6869961227356716

Epoch: 6| Step: 6
Training loss: 1.526461217013357
Validation loss: 2.6395410884774932

Epoch: 6| Step: 7
Training loss: 1.360194605900575
Validation loss: 2.623978499553679

Epoch: 6| Step: 8
Training loss: 0.8349329179669048
Validation loss: 2.6759177820798103

Epoch: 6| Step: 9
Training loss: 1.1556815734846655
Validation loss: 2.632032106705402

Epoch: 6| Step: 10
Training loss: 1.99067750439352
Validation loss: 2.673053112557643

Epoch: 6| Step: 11
Training loss: 0.8533919395373654
Validation loss: 2.7057133770814317

Epoch: 6| Step: 12
Training loss: 1.5927652046556848
Validation loss: 2.6752976177704557

Epoch: 6| Step: 13
Training loss: 1.850362847803999
Validation loss: 2.717331280036905

Epoch: 630| Step: 0
Training loss: 1.0208964944619925
Validation loss: 2.668672956393165

Epoch: 6| Step: 1
Training loss: 1.0530848441689062
Validation loss: 2.636996894242733

Epoch: 6| Step: 2
Training loss: 1.2212555390684303
Validation loss: 2.6736858079591106

Epoch: 6| Step: 3
Training loss: 1.0975129926603273
Validation loss: 2.71450360701387

Epoch: 6| Step: 4
Training loss: 0.9853710100808639
Validation loss: 2.680397719040226

Epoch: 6| Step: 5
Training loss: 1.3160172518784932
Validation loss: 2.6278606147245966

Epoch: 6| Step: 6
Training loss: 1.7394261393840666
Validation loss: 2.6307698259158574

Epoch: 6| Step: 7
Training loss: 1.0829789731422816
Validation loss: 2.7129009300405995

Epoch: 6| Step: 8
Training loss: 1.0785086128976822
Validation loss: 2.651810195695333

Epoch: 6| Step: 9
Training loss: 1.045661678639964
Validation loss: 2.666583527786664

Epoch: 6| Step: 10
Training loss: 2.1709215005944285
Validation loss: 2.6862099449483265

Epoch: 6| Step: 11
Training loss: 1.517683381464827
Validation loss: 2.749011795344816

Epoch: 6| Step: 12
Training loss: 1.2835130012546225
Validation loss: 2.6722296562339007

Epoch: 6| Step: 13
Training loss: 1.0685902124718116
Validation loss: 2.6635103125872748

Epoch: 631| Step: 0
Training loss: 0.6926285451575597
Validation loss: 2.7701416629606364

Epoch: 6| Step: 1
Training loss: 1.3265699819976124
Validation loss: 2.6867328110623014

Epoch: 6| Step: 2
Training loss: 1.3941048790433892
Validation loss: 2.67953786602907

Epoch: 6| Step: 3
Training loss: 1.099985061890868
Validation loss: 2.68692779554561

Epoch: 6| Step: 4
Training loss: 1.06320436355235
Validation loss: 2.651413187006289

Epoch: 6| Step: 5
Training loss: 0.911524158099053
Validation loss: 2.7505558529809067

Epoch: 6| Step: 6
Training loss: 1.343728797213037
Validation loss: 2.665483836007961

Epoch: 6| Step: 7
Training loss: 1.1765942978329935
Validation loss: 2.754957825584843

Epoch: 6| Step: 8
Training loss: 1.042832212047473
Validation loss: 2.6627089609509347

Epoch: 6| Step: 9
Training loss: 1.362318075791067
Validation loss: 2.7311547818970507

Epoch: 6| Step: 10
Training loss: 1.0404451965241681
Validation loss: 2.711778815236032

Epoch: 6| Step: 11
Training loss: 2.057773607678693
Validation loss: 2.6725355817851772

Epoch: 6| Step: 12
Training loss: 1.2666155388619065
Validation loss: 2.680875093792868

Epoch: 6| Step: 13
Training loss: 1.2376929970723076
Validation loss: 2.66249508882068

Epoch: 632| Step: 0
Training loss: 1.2903712247131633
Validation loss: 2.636531414272616

Epoch: 6| Step: 1
Training loss: 1.1469002120653509
Validation loss: 2.7067195416510232

Epoch: 6| Step: 2
Training loss: 1.0031861568834315
Validation loss: 2.7716189407314213

Epoch: 6| Step: 3
Training loss: 1.242916061464308
Validation loss: 2.6412088746564204

Epoch: 6| Step: 4
Training loss: 0.7892891964222218
Validation loss: 2.665263977192748

Epoch: 6| Step: 5
Training loss: 1.3421941221915359
Validation loss: 2.6398011473514074

Epoch: 6| Step: 6
Training loss: 1.1112468133286397
Validation loss: 2.7091759468175267

Epoch: 6| Step: 7
Training loss: 1.3577271042847574
Validation loss: 2.7483788248911885

Epoch: 6| Step: 8
Training loss: 0.940993380729023
Validation loss: 2.6324831493466196

Epoch: 6| Step: 9
Training loss: 2.3743699894566297
Validation loss: 2.7141872284706143

Epoch: 6| Step: 10
Training loss: 1.1304938956141846
Validation loss: 2.640385925106969

Epoch: 6| Step: 11
Training loss: 1.4616968965757253
Validation loss: 2.776150418462612

Epoch: 6| Step: 12
Training loss: 0.75199909812792
Validation loss: 2.7500655482470395

Epoch: 6| Step: 13
Training loss: 0.6115924397870142
Validation loss: 2.738692660814961

Epoch: 633| Step: 0
Training loss: 1.3612928782734182
Validation loss: 2.6973241051634793

Epoch: 6| Step: 1
Training loss: 2.0511510315800265
Validation loss: 2.595925117017881

Epoch: 6| Step: 2
Training loss: 1.3757031983433967
Validation loss: 2.6358027426899637

Epoch: 6| Step: 3
Training loss: 1.2626738815672147
Validation loss: 2.7398085838260937

Epoch: 6| Step: 4
Training loss: 1.0580521778299699
Validation loss: 2.7474435910695574

Epoch: 6| Step: 5
Training loss: 1.3704944398468693
Validation loss: 2.694692824437035

Epoch: 6| Step: 6
Training loss: 1.1713258092197487
Validation loss: 2.6183958209920797

Epoch: 6| Step: 7
Training loss: 1.103194036295721
Validation loss: 2.7101137264851234

Epoch: 6| Step: 8
Training loss: 1.1998457372375477
Validation loss: 2.610274589828407

Epoch: 6| Step: 9
Training loss: 1.2020731700200922
Validation loss: 2.7065587163970477

Epoch: 6| Step: 10
Training loss: 1.1870870374088647
Validation loss: 2.662059303734702

Epoch: 6| Step: 11
Training loss: 0.9896322673276841
Validation loss: 2.7428273680116337

Epoch: 6| Step: 12
Training loss: 1.3955764486680202
Validation loss: 2.600606995934846

Epoch: 6| Step: 13
Training loss: 0.7612398255894433
Validation loss: 2.6362812177819523

Epoch: 634| Step: 0
Training loss: 1.4300119000720009
Validation loss: 2.6254765224043375

Epoch: 6| Step: 1
Training loss: 2.0719388511795764
Validation loss: 2.6210606779560535

Epoch: 6| Step: 2
Training loss: 0.9817774575951851
Validation loss: 2.7735649175519392

Epoch: 6| Step: 3
Training loss: 0.9785282644342587
Validation loss: 2.697360508612671

Epoch: 6| Step: 4
Training loss: 1.3977450569132293
Validation loss: 2.6923795446066086

Epoch: 6| Step: 5
Training loss: 1.3534779288807355
Validation loss: 2.662202417571724

Epoch: 6| Step: 6
Training loss: 1.3227275903505362
Validation loss: 2.701602605482644

Epoch: 6| Step: 7
Training loss: 1.0677931713110964
Validation loss: 2.7331311421853783

Epoch: 6| Step: 8
Training loss: 1.2538407923645454
Validation loss: 2.719900124398854

Epoch: 6| Step: 9
Training loss: 0.9559383146164695
Validation loss: 2.7991850426544485

Epoch: 6| Step: 10
Training loss: 0.8454794643035518
Validation loss: 2.748269895149544

Epoch: 6| Step: 11
Training loss: 1.272951747246482
Validation loss: 2.7445097940809604

Epoch: 6| Step: 12
Training loss: 0.8595014652486032
Validation loss: 2.727043710443629

Epoch: 6| Step: 13
Training loss: 1.6924037326723795
Validation loss: 2.6759721982911415

Epoch: 635| Step: 0
Training loss: 1.311161039478457
Validation loss: 2.7220912878073165

Epoch: 6| Step: 1
Training loss: 1.9782606226031956
Validation loss: 2.7122284669906107

Epoch: 6| Step: 2
Training loss: 1.4654803304299082
Validation loss: 2.6248300715154227

Epoch: 6| Step: 3
Training loss: 1.4783458939842637
Validation loss: 2.6736950089853253

Epoch: 6| Step: 4
Training loss: 1.1599708691589472
Validation loss: 2.6771008303529227

Epoch: 6| Step: 5
Training loss: 1.1813855108613498
Validation loss: 2.6068627997910654

Epoch: 6| Step: 6
Training loss: 1.0366374808268164
Validation loss: 2.5442727793693667

Epoch: 6| Step: 7
Training loss: 1.3000139144006087
Validation loss: 2.665271990529592

Epoch: 6| Step: 8
Training loss: 1.4585849363268126
Validation loss: 2.6096290158699627

Epoch: 6| Step: 9
Training loss: 1.015551579095701
Validation loss: 2.6181467868595605

Epoch: 6| Step: 10
Training loss: 1.0255070502170431
Validation loss: 2.6050444615394297

Epoch: 6| Step: 11
Training loss: 1.3835829835081876
Validation loss: 2.675753377085569

Epoch: 6| Step: 12
Training loss: 1.4122423713492898
Validation loss: 2.699960431872821

Epoch: 6| Step: 13
Training loss: 1.217654151244076
Validation loss: 2.7286889256846667

Epoch: 636| Step: 0
Training loss: 1.1265984411762815
Validation loss: 2.703397068660043

Epoch: 6| Step: 1
Training loss: 2.228528142253683
Validation loss: 2.709030016009893

Epoch: 6| Step: 2
Training loss: 0.9710875580790501
Validation loss: 2.676949681365748

Epoch: 6| Step: 3
Training loss: 1.6807535736168553
Validation loss: 2.6919877914304

Epoch: 6| Step: 4
Training loss: 0.9880027227731013
Validation loss: 2.8155667738416046

Epoch: 6| Step: 5
Training loss: 1.102653558291836
Validation loss: 2.691986052488891

Epoch: 6| Step: 6
Training loss: 0.858150164185906
Validation loss: 2.7257816282378524

Epoch: 6| Step: 7
Training loss: 1.1366840894730468
Validation loss: 2.794042863178074

Epoch: 6| Step: 8
Training loss: 1.2755675492533236
Validation loss: 2.708639201143072

Epoch: 6| Step: 9
Training loss: 0.8473781709680623
Validation loss: 2.7306112414531842

Epoch: 6| Step: 10
Training loss: 1.5431239569140185
Validation loss: 2.676463231560918

Epoch: 6| Step: 11
Training loss: 1.4613025229668053
Validation loss: 2.692809198574256

Epoch: 6| Step: 12
Training loss: 1.1576513098406538
Validation loss: 2.722044756349671

Epoch: 6| Step: 13
Training loss: 0.8522598141356648
Validation loss: 2.7131544236046197

Epoch: 637| Step: 0
Training loss: 1.0903681105483847
Validation loss: 2.6507952955787726

Epoch: 6| Step: 1
Training loss: 0.5850431610552732
Validation loss: 2.670671573515603

Epoch: 6| Step: 2
Training loss: 1.8207973767650527
Validation loss: 2.736555778119698

Epoch: 6| Step: 3
Training loss: 1.1843891052372422
Validation loss: 2.6559626771940077

Epoch: 6| Step: 4
Training loss: 1.1715094441233873
Validation loss: 2.6580542028204444

Epoch: 6| Step: 5
Training loss: 1.8870620573156571
Validation loss: 2.651346234418756

Epoch: 6| Step: 6
Training loss: 1.148574250052741
Validation loss: 2.818634495734364

Epoch: 6| Step: 7
Training loss: 1.1601034338645861
Validation loss: 2.5796413746423386

Epoch: 6| Step: 8
Training loss: 0.8867758509866154
Validation loss: 2.598619198289761

Epoch: 6| Step: 9
Training loss: 1.3535161534428082
Validation loss: 2.6352435743428244

Epoch: 6| Step: 10
Training loss: 1.27346914053148
Validation loss: 2.705500071264505

Epoch: 6| Step: 11
Training loss: 1.3135642777548109
Validation loss: 2.693750942981807

Epoch: 6| Step: 12
Training loss: 0.9890803547915398
Validation loss: 2.6891472197661552

Epoch: 6| Step: 13
Training loss: 1.0065994058858512
Validation loss: 2.6602558503249236

Epoch: 638| Step: 0
Training loss: 1.4612007108000022
Validation loss: 2.726925928033535

Epoch: 6| Step: 1
Training loss: 1.9732886178947415
Validation loss: 2.590776144389126

Epoch: 6| Step: 2
Training loss: 1.612579710417048
Validation loss: 2.670557287847656

Epoch: 6| Step: 3
Training loss: 0.9793688315152855
Validation loss: 2.755326016134282

Epoch: 6| Step: 4
Training loss: 1.0240803803322618
Validation loss: 2.7848570126359466

Epoch: 6| Step: 5
Training loss: 1.1655944370220808
Validation loss: 2.707646536692784

Epoch: 6| Step: 6
Training loss: 1.3926530258773107
Validation loss: 2.708274753274638

Epoch: 6| Step: 7
Training loss: 1.2051414337098119
Validation loss: 2.6886055025495734

Epoch: 6| Step: 8
Training loss: 1.4215394347225951
Validation loss: 2.6785361834666888

Epoch: 6| Step: 9
Training loss: 1.0781925567248325
Validation loss: 2.7299946895077283

Epoch: 6| Step: 10
Training loss: 1.229584100391886
Validation loss: 2.6905247121395073

Epoch: 6| Step: 11
Training loss: 1.1237149846919765
Validation loss: 2.617472744223601

Epoch: 6| Step: 12
Training loss: 0.7007797122117673
Validation loss: 2.646803891937171

Epoch: 6| Step: 13
Training loss: 1.0838245720819888
Validation loss: 2.749230828208112

Epoch: 639| Step: 0
Training loss: 1.3078803551866953
Validation loss: 2.728247337303272

Epoch: 6| Step: 1
Training loss: 2.0370977882355645
Validation loss: 2.651507073840103

Epoch: 6| Step: 2
Training loss: 1.0124450197715937
Validation loss: 2.64864785743239

Epoch: 6| Step: 3
Training loss: 1.2503859400996613
Validation loss: 2.654306436853015

Epoch: 6| Step: 4
Training loss: 1.0638725727435931
Validation loss: 2.8103352956428562

Epoch: 6| Step: 5
Training loss: 1.471982523560439
Validation loss: 2.6157961182689418

Epoch: 6| Step: 6
Training loss: 0.9884703082158331
Validation loss: 2.698412210940337

Epoch: 6| Step: 7
Training loss: 1.354533771737405
Validation loss: 2.688730820836718

Epoch: 6| Step: 8
Training loss: 0.6426809396784556
Validation loss: 2.6855206103042697

Epoch: 6| Step: 9
Training loss: 0.9030463715746675
Validation loss: 2.726271552488507

Epoch: 6| Step: 10
Training loss: 1.265510365510387
Validation loss: 2.6458302107768246

Epoch: 6| Step: 11
Training loss: 1.1561662798290606
Validation loss: 2.7213214613043415

Epoch: 6| Step: 12
Training loss: 1.5753295614192284
Validation loss: 2.6493163576153487

Epoch: 6| Step: 13
Training loss: 1.5140564657589055
Validation loss: 2.6206364975924075

Epoch: 640| Step: 0
Training loss: 1.9952770137394473
Validation loss: 2.6826154549076664

Epoch: 6| Step: 1
Training loss: 1.0020822661163504
Validation loss: 2.6501960860432034

Epoch: 6| Step: 2
Training loss: 0.8659878930661761
Validation loss: 2.597721045444101

Epoch: 6| Step: 3
Training loss: 0.9782330986471726
Validation loss: 2.6116048662681415

Epoch: 6| Step: 4
Training loss: 1.2166515771809767
Validation loss: 2.6159825820128484

Epoch: 6| Step: 5
Training loss: 1.114077367054744
Validation loss: 2.6737417049517362

Epoch: 6| Step: 6
Training loss: 1.1755572134103205
Validation loss: 2.661895984394098

Epoch: 6| Step: 7
Training loss: 1.187387059512824
Validation loss: 2.6015635888926596

Epoch: 6| Step: 8
Training loss: 1.1089871762929957
Validation loss: 2.6582481912880667

Epoch: 6| Step: 9
Training loss: 1.5026471304301912
Validation loss: 2.667422426581242

Epoch: 6| Step: 10
Training loss: 1.4252299876083596
Validation loss: 2.709875576097957

Epoch: 6| Step: 11
Training loss: 1.1802455769403277
Validation loss: 2.619187607451287

Epoch: 6| Step: 12
Training loss: 1.412868227265686
Validation loss: 2.662105685702268

Epoch: 6| Step: 13
Training loss: 0.9492418576791255
Validation loss: 2.7268251639910708

Epoch: 641| Step: 0
Training loss: 1.2583442653829546
Validation loss: 2.69896005407925

Epoch: 6| Step: 1
Training loss: 1.4809765108552384
Validation loss: 2.615569696660022

Epoch: 6| Step: 2
Training loss: 1.396196669172208
Validation loss: 2.635254036608534

Epoch: 6| Step: 3
Training loss: 0.7251887716979009
Validation loss: 2.555032311012799

Epoch: 6| Step: 4
Training loss: 0.9001554897883204
Validation loss: 2.6706597333118776

Epoch: 6| Step: 5
Training loss: 1.9571584938088957
Validation loss: 2.564477033311303

Epoch: 6| Step: 6
Training loss: 1.1626200091036785
Validation loss: 2.626380748692095

Epoch: 6| Step: 7
Training loss: 1.2818141253602104
Validation loss: 2.706094379256595

Epoch: 6| Step: 8
Training loss: 1.3346794406484093
Validation loss: 2.6185980027467943

Epoch: 6| Step: 9
Training loss: 1.261421097642414
Validation loss: 2.6987666466189997

Epoch: 6| Step: 10
Training loss: 1.4164442373947963
Validation loss: 2.6638187119717798

Epoch: 6| Step: 11
Training loss: 0.8719764650432341
Validation loss: 2.5921579331052462

Epoch: 6| Step: 12
Training loss: 1.3433113712963989
Validation loss: 2.5683485439132516

Epoch: 6| Step: 13
Training loss: 0.7772931029723049
Validation loss: 2.7082680740887066

Epoch: 642| Step: 0
Training loss: 1.1692315359103433
Validation loss: 2.5745815433687644

Epoch: 6| Step: 1
Training loss: 1.8234562393180056
Validation loss: 2.6495077806951044

Epoch: 6| Step: 2
Training loss: 1.0765014808315043
Validation loss: 2.724148631289161

Epoch: 6| Step: 3
Training loss: 1.206609905490339
Validation loss: 2.682738276017163

Epoch: 6| Step: 4
Training loss: 1.3605891538496937
Validation loss: 2.7148267071291463

Epoch: 6| Step: 5
Training loss: 1.1895899701754504
Validation loss: 2.6550101429766166

Epoch: 6| Step: 6
Training loss: 1.5669823250762724
Validation loss: 2.609529958909327

Epoch: 6| Step: 7
Training loss: 1.2454745389463793
Validation loss: 2.7074262559325852

Epoch: 6| Step: 8
Training loss: 1.1829546723279518
Validation loss: 2.715026030636917

Epoch: 6| Step: 9
Training loss: 1.6794854330900129
Validation loss: 2.69940315130644

Epoch: 6| Step: 10
Training loss: 0.8560909986791178
Validation loss: 2.650754838651139

Epoch: 6| Step: 11
Training loss: 0.8583249699700555
Validation loss: 2.7016196387814153

Epoch: 6| Step: 12
Training loss: 1.0777014301127381
Validation loss: 2.709161515053685

Epoch: 6| Step: 13
Training loss: 1.0992502605202812
Validation loss: 2.7603177969824304

Epoch: 643| Step: 0
Training loss: 1.0798329632120567
Validation loss: 2.725846346241442

Epoch: 6| Step: 1
Training loss: 1.166830880097726
Validation loss: 2.6179258644231105

Epoch: 6| Step: 2
Training loss: 0.9942321135686802
Validation loss: 2.714028912962676

Epoch: 6| Step: 3
Training loss: 1.0971075566784783
Validation loss: 2.80381276034964

Epoch: 6| Step: 4
Training loss: 1.508126339838703
Validation loss: 2.692735535039612

Epoch: 6| Step: 5
Training loss: 0.8954638820842701
Validation loss: 2.803956938142205

Epoch: 6| Step: 6
Training loss: 1.2820654344388913
Validation loss: 2.7094482670094937

Epoch: 6| Step: 7
Training loss: 1.4855604557817876
Validation loss: 2.604911141249059

Epoch: 6| Step: 8
Training loss: 1.1875337294757475
Validation loss: 2.6462198426820684

Epoch: 6| Step: 9
Training loss: 1.1141568137289353
Validation loss: 2.710142802091342

Epoch: 6| Step: 10
Training loss: 1.2007726982968754
Validation loss: 2.6203488593421955

Epoch: 6| Step: 11
Training loss: 1.2907876694993752
Validation loss: 2.701469761045917

Epoch: 6| Step: 12
Training loss: 2.045633886162385
Validation loss: 2.687996748059196

Epoch: 6| Step: 13
Training loss: 1.1323312723812753
Validation loss: 2.742995149372982

Epoch: 644| Step: 0
Training loss: 1.3788229076929381
Validation loss: 2.7778726073113043

Epoch: 6| Step: 1
Training loss: 0.9946620150988718
Validation loss: 2.637948724774513

Epoch: 6| Step: 2
Training loss: 1.2005396722182935
Validation loss: 2.7401481126422

Epoch: 6| Step: 3
Training loss: 1.2778839462282054
Validation loss: 2.732704443119066

Epoch: 6| Step: 4
Training loss: 1.2704785847215785
Validation loss: 2.7567938749759753

Epoch: 6| Step: 5
Training loss: 1.0086923942520454
Validation loss: 2.7255417466568144

Epoch: 6| Step: 6
Training loss: 0.6981849273464867
Validation loss: 2.6570357480953763

Epoch: 6| Step: 7
Training loss: 1.215311824987709
Validation loss: 2.6667705087542224

Epoch: 6| Step: 8
Training loss: 1.0115042204945603
Validation loss: 2.722497283338466

Epoch: 6| Step: 9
Training loss: 0.8460864812621501
Validation loss: 2.7565941138620533

Epoch: 6| Step: 10
Training loss: 1.6809081144755333
Validation loss: 2.7043508651763184

Epoch: 6| Step: 11
Training loss: 1.2484752415381835
Validation loss: 2.6475154050604863

Epoch: 6| Step: 12
Training loss: 1.8360605401548304
Validation loss: 2.6788164780851815

Epoch: 6| Step: 13
Training loss: 1.0823892490036302
Validation loss: 2.782992302207333

Epoch: 645| Step: 0
Training loss: 1.7646983592957601
Validation loss: 2.661236794095931

Epoch: 6| Step: 1
Training loss: 1.1366448132566724
Validation loss: 2.7940599495193656

Epoch: 6| Step: 2
Training loss: 1.2072594189334687
Validation loss: 2.704619237983695

Epoch: 6| Step: 3
Training loss: 1.2924414997401428
Validation loss: 2.644329712205045

Epoch: 6| Step: 4
Training loss: 1.2392196228539887
Validation loss: 2.6677084084571123

Epoch: 6| Step: 5
Training loss: 0.7479458334786786
Validation loss: 2.718319549638269

Epoch: 6| Step: 6
Training loss: 1.3716526468254986
Validation loss: 2.695628311086224

Epoch: 6| Step: 7
Training loss: 1.2145688153681162
Validation loss: 2.7357002649305473

Epoch: 6| Step: 8
Training loss: 1.4460204993624455
Validation loss: 2.7452575813691995

Epoch: 6| Step: 9
Training loss: 1.3501530172024354
Validation loss: 2.685129438934361

Epoch: 6| Step: 10
Training loss: 1.1326302217304842
Validation loss: 2.709416426734491

Epoch: 6| Step: 11
Training loss: 1.472701418560871
Validation loss: 2.7360609425550244

Epoch: 6| Step: 12
Training loss: 1.3181641836840357
Validation loss: 2.5861464937902885

Epoch: 6| Step: 13
Training loss: 0.9913578018603357
Validation loss: 2.70062359297246

Epoch: 646| Step: 0
Training loss: 1.2243798145707765
Validation loss: 2.774142743063019

Epoch: 6| Step: 1
Training loss: 1.1032537368998114
Validation loss: 2.70881725433712

Epoch: 6| Step: 2
Training loss: 1.1528733927485886
Validation loss: 2.6733221924935573

Epoch: 6| Step: 3
Training loss: 2.2698874530535713
Validation loss: 2.6124664909756135

Epoch: 6| Step: 4
Training loss: 0.8693744473486432
Validation loss: 2.656872715303132

Epoch: 6| Step: 5
Training loss: 1.4764066745136937
Validation loss: 2.688497807873113

Epoch: 6| Step: 6
Training loss: 1.1084066113410065
Validation loss: 2.6134087176334733

Epoch: 6| Step: 7
Training loss: 1.2736919593502731
Validation loss: 2.8245823677334263

Epoch: 6| Step: 8
Training loss: 1.277571071730553
Validation loss: 2.6571079632333436

Epoch: 6| Step: 9
Training loss: 1.3034576741506827
Validation loss: 2.7058613285836137

Epoch: 6| Step: 10
Training loss: 1.1216112065786608
Validation loss: 2.734569821778599

Epoch: 6| Step: 11
Training loss: 1.4083209577088154
Validation loss: 2.6362738116242275

Epoch: 6| Step: 12
Training loss: 0.9625870417586029
Validation loss: 2.735462247972035

Epoch: 6| Step: 13
Training loss: 0.7429889969017437
Validation loss: 2.662980710177294

Epoch: 647| Step: 0
Training loss: 1.1951279341876428
Validation loss: 2.7062590137312537

Epoch: 6| Step: 1
Training loss: 1.3939255967308644
Validation loss: 2.8219252300932816

Epoch: 6| Step: 2
Training loss: 2.217788595452658
Validation loss: 2.695614151068124

Epoch: 6| Step: 3
Training loss: 1.3708991105474333
Validation loss: 2.7289527988371534

Epoch: 6| Step: 4
Training loss: 1.0013163962000584
Validation loss: 2.7558989820075164

Epoch: 6| Step: 5
Training loss: 1.1317443020632734
Validation loss: 2.860060165659335

Epoch: 6| Step: 6
Training loss: 1.1020217911976768
Validation loss: 2.748491209401596

Epoch: 6| Step: 7
Training loss: 1.194312481404224
Validation loss: 2.722129547791238

Epoch: 6| Step: 8
Training loss: 1.5765903678374302
Validation loss: 2.7403862198287774

Epoch: 6| Step: 9
Training loss: 1.1625708937819008
Validation loss: 2.7116183439354584

Epoch: 6| Step: 10
Training loss: 1.1637967209497893
Validation loss: 2.6819472961112667

Epoch: 6| Step: 11
Training loss: 1.1596734169279916
Validation loss: 2.663753214544623

Epoch: 6| Step: 12
Training loss: 0.8770236728217884
Validation loss: 2.6328172118607704

Epoch: 6| Step: 13
Training loss: 0.7521041916537557
Validation loss: 2.7009391760066057

Epoch: 648| Step: 0
Training loss: 1.2512908945631998
Validation loss: 2.7440447486393063

Epoch: 6| Step: 1
Training loss: 1.1127509744846016
Validation loss: 2.6611812442415075

Epoch: 6| Step: 2
Training loss: 1.3959149673655313
Validation loss: 2.6450596470216197

Epoch: 6| Step: 3
Training loss: 1.033672723614824
Validation loss: 2.689120108397469

Epoch: 6| Step: 4
Training loss: 0.9162788582247563
Validation loss: 2.6984165859411275

Epoch: 6| Step: 5
Training loss: 0.9805875607425323
Validation loss: 2.7073554947053102

Epoch: 6| Step: 6
Training loss: 1.3098589346550562
Validation loss: 2.729109269319577

Epoch: 6| Step: 7
Training loss: 1.1163503004166553
Validation loss: 2.6251773188364047

Epoch: 6| Step: 8
Training loss: 1.2729193914772419
Validation loss: 2.688885049757317

Epoch: 6| Step: 9
Training loss: 1.5170737352550414
Validation loss: 2.6966181724971556

Epoch: 6| Step: 10
Training loss: 1.1646957211297693
Validation loss: 2.630904116486374

Epoch: 6| Step: 11
Training loss: 1.896420070135496
Validation loss: 2.659049346593847

Epoch: 6| Step: 12
Training loss: 1.262387833475366
Validation loss: 2.676861487868196

Epoch: 6| Step: 13
Training loss: 0.7831081798966545
Validation loss: 2.7459583115163917

Epoch: 649| Step: 0
Training loss: 1.0066310255949638
Validation loss: 2.761232946294719

Epoch: 6| Step: 1
Training loss: 1.2344367579209294
Validation loss: 2.7747610000513188

Epoch: 6| Step: 2
Training loss: 1.4440334949993978
Validation loss: 2.791954541473805

Epoch: 6| Step: 3
Training loss: 0.8715803899669421
Validation loss: 2.674092221788704

Epoch: 6| Step: 4
Training loss: 2.0004102762929747
Validation loss: 2.6778543018991185

Epoch: 6| Step: 5
Training loss: 1.3554800951040433
Validation loss: 2.694278447705361

Epoch: 6| Step: 6
Training loss: 0.6098165135284273
Validation loss: 2.7714084392637477

Epoch: 6| Step: 7
Training loss: 1.2807895484312033
Validation loss: 2.707100340661382

Epoch: 6| Step: 8
Training loss: 1.239907385305381
Validation loss: 2.7198568035340402

Epoch: 6| Step: 9
Training loss: 1.1956710776240675
Validation loss: 2.6554683473815275

Epoch: 6| Step: 10
Training loss: 1.3079985674229047
Validation loss: 2.700695308969937

Epoch: 6| Step: 11
Training loss: 1.1891894118645059
Validation loss: 2.65866511924485

Epoch: 6| Step: 12
Training loss: 1.0588895940350211
Validation loss: 2.6968002724013362

Epoch: 6| Step: 13
Training loss: 0.5910509904465099
Validation loss: 2.6813827615448

Epoch: 650| Step: 0
Training loss: 1.2316240971959842
Validation loss: 2.640539761244138

Epoch: 6| Step: 1
Training loss: 1.4170271003570687
Validation loss: 2.631084116421757

Epoch: 6| Step: 2
Training loss: 1.36508247720176
Validation loss: 2.654914219930138

Epoch: 6| Step: 3
Training loss: 1.1164092440928732
Validation loss: 2.6584414915268533

Epoch: 6| Step: 4
Training loss: 1.0818395892451964
Validation loss: 2.7299822018016995

Epoch: 6| Step: 5
Training loss: 1.2141055105634928
Validation loss: 2.675155422988384

Epoch: 6| Step: 6
Training loss: 1.0537141052141912
Validation loss: 2.685472017529529

Epoch: 6| Step: 7
Training loss: 1.1650332301234458
Validation loss: 2.679606128123129

Epoch: 6| Step: 8
Training loss: 1.8386380077620055
Validation loss: 2.695674596679233

Epoch: 6| Step: 9
Training loss: 1.3017237459205233
Validation loss: 2.6504428942493465

Epoch: 6| Step: 10
Training loss: 0.9608555580495715
Validation loss: 2.789765755984184

Epoch: 6| Step: 11
Training loss: 1.1951243931976556
Validation loss: 2.6160194960713743

Epoch: 6| Step: 12
Training loss: 1.445238761051797
Validation loss: 2.568289980790555

Epoch: 6| Step: 13
Training loss: 0.985444411410736
Validation loss: 2.7354163127538085

Epoch: 651| Step: 0
Training loss: 0.9998938384925222
Validation loss: 2.615837109993148

Epoch: 6| Step: 1
Training loss: 1.0719508419508816
Validation loss: 2.728799092716527

Epoch: 6| Step: 2
Training loss: 1.2328432453996985
Validation loss: 2.5297495786649744

Epoch: 6| Step: 3
Training loss: 1.3634258729140343
Validation loss: 2.630269729708295

Epoch: 6| Step: 4
Training loss: 1.139881152767556
Validation loss: 2.6032366450874074

Epoch: 6| Step: 5
Training loss: 1.3009654421603813
Validation loss: 2.640551950582985

Epoch: 6| Step: 6
Training loss: 1.2566135449822273
Validation loss: 2.710821732914612

Epoch: 6| Step: 7
Training loss: 1.193541567516051
Validation loss: 2.6401213468827254

Epoch: 6| Step: 8
Training loss: 2.0153956319728503
Validation loss: 2.640208730491208

Epoch: 6| Step: 9
Training loss: 0.7040308098025252
Validation loss: 2.702094573107465

Epoch: 6| Step: 10
Training loss: 1.1253763205225924
Validation loss: 2.685525054514847

Epoch: 6| Step: 11
Training loss: 1.3094686743247357
Validation loss: 2.7317218243353354

Epoch: 6| Step: 12
Training loss: 1.3892440797364896
Validation loss: 2.6538238505933482

Epoch: 6| Step: 13
Training loss: 0.7772101282645641
Validation loss: 2.7712834082349738

Epoch: 652| Step: 0
Training loss: 0.966812626874125
Validation loss: 2.7104428229989526

Epoch: 6| Step: 1
Training loss: 1.146519467078334
Validation loss: 2.7287193638798324

Epoch: 6| Step: 2
Training loss: 1.6698330682709315
Validation loss: 2.6789997210401175

Epoch: 6| Step: 3
Training loss: 1.4907957447076223
Validation loss: 2.702823914017619

Epoch: 6| Step: 4
Training loss: 1.4076315980578264
Validation loss: 2.662947103213745

Epoch: 6| Step: 5
Training loss: 0.9960364830160401
Validation loss: 2.649338603085192

Epoch: 6| Step: 6
Training loss: 1.0651125483971982
Validation loss: 2.725394634953415

Epoch: 6| Step: 7
Training loss: 1.1127538669975794
Validation loss: 2.7433524064652834

Epoch: 6| Step: 8
Training loss: 1.013646472766975
Validation loss: 2.6348602188668013

Epoch: 6| Step: 9
Training loss: 1.1747107210576246
Validation loss: 2.6959949477741065

Epoch: 6| Step: 10
Training loss: 1.965817765576778
Validation loss: 2.7544299621808666

Epoch: 6| Step: 11
Training loss: 0.8561832457646342
Validation loss: 2.6710141890636563

Epoch: 6| Step: 12
Training loss: 0.9946449364637746
Validation loss: 2.7118253006854247

Epoch: 6| Step: 13
Training loss: 1.4334617782675716
Validation loss: 2.6938570924681695

Epoch: 653| Step: 0
Training loss: 1.262943016355463
Validation loss: 2.7095523936679844

Epoch: 6| Step: 1
Training loss: 1.0251150578376165
Validation loss: 2.7339884579415004

Epoch: 6| Step: 2
Training loss: 2.3028176173726473
Validation loss: 2.665308891870489

Epoch: 6| Step: 3
Training loss: 1.0203138249200276
Validation loss: 2.719448623598989

Epoch: 6| Step: 4
Training loss: 0.8324541620001428
Validation loss: 2.793897594777859

Epoch: 6| Step: 5
Training loss: 1.2079771218375515
Validation loss: 2.605273838743881

Epoch: 6| Step: 6
Training loss: 1.1713405153195118
Validation loss: 2.7874767970381216

Epoch: 6| Step: 7
Training loss: 0.9724283219426628
Validation loss: 2.700202030643123

Epoch: 6| Step: 8
Training loss: 1.4070608556366153
Validation loss: 2.725401697339429

Epoch: 6| Step: 9
Training loss: 1.4443644945727423
Validation loss: 2.6239390331318737

Epoch: 6| Step: 10
Training loss: 1.115864109947213
Validation loss: 2.6327868051663565

Epoch: 6| Step: 11
Training loss: 1.369050984842495
Validation loss: 2.7827227220066995

Epoch: 6| Step: 12
Training loss: 1.2220366251556214
Validation loss: 2.5954499775217643

Epoch: 6| Step: 13
Training loss: 1.1822274256434773
Validation loss: 2.721928916811468

Epoch: 654| Step: 0
Training loss: 1.4386149519203935
Validation loss: 2.7356086088234695

Epoch: 6| Step: 1
Training loss: 0.902102913030994
Validation loss: 2.8495373268119484

Epoch: 6| Step: 2
Training loss: 0.6584049673783581
Validation loss: 2.6478102167395416

Epoch: 6| Step: 3
Training loss: 0.9859342185085236
Validation loss: 2.8142888440775944

Epoch: 6| Step: 4
Training loss: 1.5938785725510822
Validation loss: 2.752011094210232

Epoch: 6| Step: 5
Training loss: 1.3941047935338304
Validation loss: 2.799717680187294

Epoch: 6| Step: 6
Training loss: 1.1198249043108022
Validation loss: 2.75981783803883

Epoch: 6| Step: 7
Training loss: 0.8075713544799612
Validation loss: 2.7683386541346326

Epoch: 6| Step: 8
Training loss: 1.2622081645908838
Validation loss: 2.695301546559333

Epoch: 6| Step: 9
Training loss: 1.9176248214857863
Validation loss: 2.684698059360802

Epoch: 6| Step: 10
Training loss: 1.1223992910427756
Validation loss: 2.773159820969541

Epoch: 6| Step: 11
Training loss: 1.5662627118714398
Validation loss: 2.685893601991073

Epoch: 6| Step: 12
Training loss: 0.7688674774967859
Validation loss: 2.566948296944202

Epoch: 6| Step: 13
Training loss: 1.294921322645527
Validation loss: 2.7269604509424754

Epoch: 655| Step: 0
Training loss: 1.2589353205645837
Validation loss: 2.656190048014127

Epoch: 6| Step: 1
Training loss: 1.0638757662272302
Validation loss: 2.6649438073122935

Epoch: 6| Step: 2
Training loss: 1.927373510284808
Validation loss: 2.7285019823604832

Epoch: 6| Step: 3
Training loss: 0.9522339141821052
Validation loss: 2.5880482372690343

Epoch: 6| Step: 4
Training loss: 1.2866215570148596
Validation loss: 2.662767355220582

Epoch: 6| Step: 5
Training loss: 1.1217990477627449
Validation loss: 2.665101943622473

Epoch: 6| Step: 6
Training loss: 1.3375065384464342
Validation loss: 2.622173665820837

Epoch: 6| Step: 7
Training loss: 1.369621029319484
Validation loss: 2.6320546433845413

Epoch: 6| Step: 8
Training loss: 1.0865301806405048
Validation loss: 2.5696291767780735

Epoch: 6| Step: 9
Training loss: 1.1976103294213774
Validation loss: 2.742411283169609

Epoch: 6| Step: 10
Training loss: 1.5062611559696115
Validation loss: 2.7118041359700924

Epoch: 6| Step: 11
Training loss: 1.0561023405797736
Validation loss: 2.8155940862371245

Epoch: 6| Step: 12
Training loss: 1.1743725420249564
Validation loss: 2.6340085892313136

Epoch: 6| Step: 13
Training loss: 1.254216616238929
Validation loss: 2.7282460161328794

Epoch: 656| Step: 0
Training loss: 1.0535309278079017
Validation loss: 2.6697028963777725

Epoch: 6| Step: 1
Training loss: 1.3085727974651884
Validation loss: 2.7040350725951843

Epoch: 6| Step: 2
Training loss: 1.30009891610524
Validation loss: 2.7285392551680663

Epoch: 6| Step: 3
Training loss: 1.7950220920616493
Validation loss: 2.7310232538656125

Epoch: 6| Step: 4
Training loss: 1.3859423545915805
Validation loss: 2.723765060716809

Epoch: 6| Step: 5
Training loss: 1.3384650340823019
Validation loss: 2.729570065121004

Epoch: 6| Step: 6
Training loss: 0.8304716725625463
Validation loss: 2.6671951357369847

Epoch: 6| Step: 7
Training loss: 1.0491087127952077
Validation loss: 2.726213666948153

Epoch: 6| Step: 8
Training loss: 0.7814670642665734
Validation loss: 2.7138958781014284

Epoch: 6| Step: 9
Training loss: 1.432041918625869
Validation loss: 2.6957993305364054

Epoch: 6| Step: 10
Training loss: 1.226008101624795
Validation loss: 2.7616812065004606

Epoch: 6| Step: 11
Training loss: 1.956706067630322
Validation loss: 2.6950033611292095

Epoch: 6| Step: 12
Training loss: 1.166463334666206
Validation loss: 2.74784282917966

Epoch: 6| Step: 13
Training loss: 0.823911853802334
Validation loss: 2.6222540942184316

Epoch: 657| Step: 0
Training loss: 2.1773855434604608
Validation loss: 2.6919453127486133

Epoch: 6| Step: 1
Training loss: 1.1218589271520396
Validation loss: 2.7280372039703593

Epoch: 6| Step: 2
Training loss: 1.4220665603544185
Validation loss: 2.696978689899673

Epoch: 6| Step: 3
Training loss: 1.1171052809118092
Validation loss: 2.786859262715063

Epoch: 6| Step: 4
Training loss: 1.6318852470248628
Validation loss: 2.664624854023808

Epoch: 6| Step: 5
Training loss: 1.069324232063502
Validation loss: 2.6897069498016037

Epoch: 6| Step: 6
Training loss: 1.2496676480013078
Validation loss: 2.570376448775981

Epoch: 6| Step: 7
Training loss: 1.171347842857396
Validation loss: 2.6815595647815513

Epoch: 6| Step: 8
Training loss: 0.8835350388129385
Validation loss: 2.6283216258054667

Epoch: 6| Step: 9
Training loss: 1.0566485223104831
Validation loss: 2.6982629854393005

Epoch: 6| Step: 10
Training loss: 0.9867089471156397
Validation loss: 2.8670709351637322

Epoch: 6| Step: 11
Training loss: 0.8161519580863614
Validation loss: 2.760900950347606

Epoch: 6| Step: 12
Training loss: 1.3419942696757425
Validation loss: 2.688128245078939

Epoch: 6| Step: 13
Training loss: 0.9265153123441505
Validation loss: 2.7643664906499135

Epoch: 658| Step: 0
Training loss: 1.040561598487366
Validation loss: 2.7294375008046643

Epoch: 6| Step: 1
Training loss: 1.2183398999525568
Validation loss: 2.771877704188096

Epoch: 6| Step: 2
Training loss: 1.8617934198808868
Validation loss: 2.665307191310339

Epoch: 6| Step: 3
Training loss: 1.3311509610439594
Validation loss: 2.6885973747279994

Epoch: 6| Step: 4
Training loss: 1.539436798280153
Validation loss: 2.7099540808362836

Epoch: 6| Step: 5
Training loss: 1.1427091604882964
Validation loss: 2.7260847556076504

Epoch: 6| Step: 6
Training loss: 1.1478123423022943
Validation loss: 2.748226166074012

Epoch: 6| Step: 7
Training loss: 1.2257462719606382
Validation loss: 2.654380849106788

Epoch: 6| Step: 8
Training loss: 1.115560079870848
Validation loss: 2.6958555079110478

Epoch: 6| Step: 9
Training loss: 1.6756896236241603
Validation loss: 2.6241409568110865

Epoch: 6| Step: 10
Training loss: 0.8581400233854747
Validation loss: 2.708417425120133

Epoch: 6| Step: 11
Training loss: 0.7689591813235661
Validation loss: 2.7704564486731686

Epoch: 6| Step: 12
Training loss: 1.2055017354312716
Validation loss: 2.6717499907199196

Epoch: 6| Step: 13
Training loss: 1.3675573230284714
Validation loss: 2.641977383641819

Epoch: 659| Step: 0
Training loss: 1.2079428282939126
Validation loss: 2.6516782608465057

Epoch: 6| Step: 1
Training loss: 1.1825854346802995
Validation loss: 2.6220252755716644

Epoch: 6| Step: 2
Training loss: 1.2688361040034413
Validation loss: 2.6994863699524534

Epoch: 6| Step: 3
Training loss: 1.1552515616324857
Validation loss: 2.669094251328882

Epoch: 6| Step: 4
Training loss: 1.0636341549184256
Validation loss: 2.6058844123950267

Epoch: 6| Step: 5
Training loss: 1.3207893187753543
Validation loss: 2.633934755781623

Epoch: 6| Step: 6
Training loss: 1.1510330245900418
Validation loss: 2.6572225779531373

Epoch: 6| Step: 7
Training loss: 1.0954537337338646
Validation loss: 2.7404616194303135

Epoch: 6| Step: 8
Training loss: 2.207216184176667
Validation loss: 2.6714479692490087

Epoch: 6| Step: 9
Training loss: 0.8779923498346116
Validation loss: 2.7156427817166837

Epoch: 6| Step: 10
Training loss: 1.019775595195769
Validation loss: 2.6711513103154614

Epoch: 6| Step: 11
Training loss: 1.2986531304663145
Validation loss: 2.6869901920952657

Epoch: 6| Step: 12
Training loss: 1.009423321491447
Validation loss: 2.685135866337023

Epoch: 6| Step: 13
Training loss: 0.794544814752635
Validation loss: 2.67756659833911

Epoch: 660| Step: 0
Training loss: 0.6848039867668881
Validation loss: 2.7179581626820744

Epoch: 6| Step: 1
Training loss: 1.0637151837506709
Validation loss: 2.7115645721695416

Epoch: 6| Step: 2
Training loss: 1.6818032357772563
Validation loss: 2.653074283139986

Epoch: 6| Step: 3
Training loss: 0.8130455386415747
Validation loss: 2.594171613577292

Epoch: 6| Step: 4
Training loss: 1.0889074754318062
Validation loss: 2.7367987058627947

Epoch: 6| Step: 5
Training loss: 1.3242099277798858
Validation loss: 2.678264602612487

Epoch: 6| Step: 6
Training loss: 1.4098270697771165
Validation loss: 2.647409171508287

Epoch: 6| Step: 7
Training loss: 2.0360300015260724
Validation loss: 2.7297726405945295

Epoch: 6| Step: 8
Training loss: 0.8121902168701102
Validation loss: 2.70723092018827

Epoch: 6| Step: 9
Training loss: 1.3572921142030896
Validation loss: 2.6625159637929303

Epoch: 6| Step: 10
Training loss: 1.3668777986976637
Validation loss: 2.751325225526979

Epoch: 6| Step: 11
Training loss: 0.9152343932350017
Validation loss: 2.7153011507713245

Epoch: 6| Step: 12
Training loss: 0.9729854838493037
Validation loss: 2.601272276612339

Epoch: 6| Step: 13
Training loss: 0.7365098723884846
Validation loss: 2.6339521575716294

Epoch: 661| Step: 0
Training loss: 0.9575957832535185
Validation loss: 2.645551716108343

Epoch: 6| Step: 1
Training loss: 1.9568783515699226
Validation loss: 2.7216524596053513

Epoch: 6| Step: 2
Training loss: 1.02052358222714
Validation loss: 2.62258389172351

Epoch: 6| Step: 3
Training loss: 0.9277490875683725
Validation loss: 2.6837396300986347

Epoch: 6| Step: 4
Training loss: 1.347031246601685
Validation loss: 2.728709376942302

Epoch: 6| Step: 5
Training loss: 1.0092890369197451
Validation loss: 2.624510426922819

Epoch: 6| Step: 6
Training loss: 0.9744420032085208
Validation loss: 2.7071118742245526

Epoch: 6| Step: 7
Training loss: 1.338496206182006
Validation loss: 2.7626545585307283

Epoch: 6| Step: 8
Training loss: 1.293946049528092
Validation loss: 2.5953216545263227

Epoch: 6| Step: 9
Training loss: 0.932481046795948
Validation loss: 2.6928983529948907

Epoch: 6| Step: 10
Training loss: 1.4785417481386076
Validation loss: 2.729298728773014

Epoch: 6| Step: 11
Training loss: 0.9903189718914327
Validation loss: 2.673981156026819

Epoch: 6| Step: 12
Training loss: 1.0218339544329738
Validation loss: 2.7043458030174166

Epoch: 6| Step: 13
Training loss: 1.4401866850110459
Validation loss: 2.721105435703415

Epoch: 662| Step: 0
Training loss: 1.044248217609721
Validation loss: 2.7164911974702184

Epoch: 6| Step: 1
Training loss: 1.3832366637651017
Validation loss: 2.763053741140038

Epoch: 6| Step: 2
Training loss: 1.180862195575966
Validation loss: 2.722915717792293

Epoch: 6| Step: 3
Training loss: 1.1965414473882605
Validation loss: 2.694662139836757

Epoch: 6| Step: 4
Training loss: 1.1840964782462733
Validation loss: 2.7090601252742177

Epoch: 6| Step: 5
Training loss: 1.1322163558849998
Validation loss: 2.679426913573824

Epoch: 6| Step: 6
Training loss: 1.3534045593579525
Validation loss: 2.7148473270251343

Epoch: 6| Step: 7
Training loss: 0.7768997764779558
Validation loss: 2.723468315201464

Epoch: 6| Step: 8
Training loss: 1.891430265580638
Validation loss: 2.6518369465323035

Epoch: 6| Step: 9
Training loss: 1.131650289034045
Validation loss: 2.6944039835836384

Epoch: 6| Step: 10
Training loss: 1.0789075582111005
Validation loss: 2.6756122106672113

Epoch: 6| Step: 11
Training loss: 1.2614784602421507
Validation loss: 2.645000518704024

Epoch: 6| Step: 12
Training loss: 0.8619339730361609
Validation loss: 2.6848337541397145

Epoch: 6| Step: 13
Training loss: 1.0557327177605598
Validation loss: 2.6986118263119536

Epoch: 663| Step: 0
Training loss: 1.3218101720041342
Validation loss: 2.7187213266775085

Epoch: 6| Step: 1
Training loss: 0.7651313435865359
Validation loss: 2.7255305027184646

Epoch: 6| Step: 2
Training loss: 1.4635780664806881
Validation loss: 2.7183691429161194

Epoch: 6| Step: 3
Training loss: 0.6334295678641869
Validation loss: 2.5897172340052768

Epoch: 6| Step: 4
Training loss: 1.0480939686047988
Validation loss: 2.667857635432234

Epoch: 6| Step: 5
Training loss: 1.050095061131622
Validation loss: 2.6944465862023637

Epoch: 6| Step: 6
Training loss: 1.2583004022967028
Validation loss: 2.5837501321299605

Epoch: 6| Step: 7
Training loss: 1.1626518970639226
Validation loss: 2.633280821524974

Epoch: 6| Step: 8
Training loss: 1.351145332651406
Validation loss: 2.6816623011904257

Epoch: 6| Step: 9
Training loss: 0.9298848816164165
Validation loss: 2.526342060042113

Epoch: 6| Step: 10
Training loss: 0.9816118848656329
Validation loss: 2.6986250985191282

Epoch: 6| Step: 11
Training loss: 2.032250730049114
Validation loss: 2.5546269859494255

Epoch: 6| Step: 12
Training loss: 1.055459199377936
Validation loss: 2.7173758039357874

Epoch: 6| Step: 13
Training loss: 1.433849259975623
Validation loss: 2.6873941460281707

Epoch: 664| Step: 0
Training loss: 1.3318195790109812
Validation loss: 2.7417569358390863

Epoch: 6| Step: 1
Training loss: 1.0159616939277003
Validation loss: 2.640319077392359

Epoch: 6| Step: 2
Training loss: 1.3951679987908836
Validation loss: 2.618244231220718

Epoch: 6| Step: 3
Training loss: 1.0999157006300218
Validation loss: 2.7636454246823803

Epoch: 6| Step: 4
Training loss: 1.1775396132234572
Validation loss: 2.7195882988801445

Epoch: 6| Step: 5
Training loss: 1.2618870106277116
Validation loss: 2.6520919877253384

Epoch: 6| Step: 6
Training loss: 0.9330251710078308
Validation loss: 2.7411634932799522

Epoch: 6| Step: 7
Training loss: 1.372288935610193
Validation loss: 2.77967431550878

Epoch: 6| Step: 8
Training loss: 0.9431996338614674
Validation loss: 2.627701603083268

Epoch: 6| Step: 9
Training loss: 1.9644529890696414
Validation loss: 2.7447546923956967

Epoch: 6| Step: 10
Training loss: 1.0552245856511873
Validation loss: 2.752540477665067

Epoch: 6| Step: 11
Training loss: 0.9277723123924966
Validation loss: 2.7059956418914477

Epoch: 6| Step: 12
Training loss: 1.431478493787762
Validation loss: 2.657627184939766

Epoch: 6| Step: 13
Training loss: 1.3671996633806032
Validation loss: 2.737887860350986

Epoch: 665| Step: 0
Training loss: 1.2559574735542969
Validation loss: 2.7257937467567452

Epoch: 6| Step: 1
Training loss: 1.0583299822015848
Validation loss: 2.672460472574896

Epoch: 6| Step: 2
Training loss: 1.1459964058172243
Validation loss: 2.6494787455405557

Epoch: 6| Step: 3
Training loss: 1.8273930836933585
Validation loss: 2.7125128022382263

Epoch: 6| Step: 4
Training loss: 0.724959091150463
Validation loss: 2.7554092791430014

Epoch: 6| Step: 5
Training loss: 0.9669629503428844
Validation loss: 2.6652218983625326

Epoch: 6| Step: 6
Training loss: 1.6077892305490122
Validation loss: 2.7249782303611045

Epoch: 6| Step: 7
Training loss: 1.3302210704379864
Validation loss: 2.69097997220807

Epoch: 6| Step: 8
Training loss: 0.9611509132657546
Validation loss: 2.7525325549330932

Epoch: 6| Step: 9
Training loss: 1.5060189604154588
Validation loss: 2.6567071703421488

Epoch: 6| Step: 10
Training loss: 1.235890050235233
Validation loss: 2.73400714984109

Epoch: 6| Step: 11
Training loss: 1.3770741510974815
Validation loss: 2.6611754092430884

Epoch: 6| Step: 12
Training loss: 1.094483919502168
Validation loss: 2.757517593457524

Epoch: 6| Step: 13
Training loss: 0.8070850025751212
Validation loss: 2.5865972629186573

Epoch: 666| Step: 0
Training loss: 1.3084866152506258
Validation loss: 2.7260731283387813

Epoch: 6| Step: 1
Training loss: 1.1921800445683497
Validation loss: 2.7115552330278274

Epoch: 6| Step: 2
Training loss: 0.6887254197568686
Validation loss: 2.6410492460787878

Epoch: 6| Step: 3
Training loss: 1.2408366025254374
Validation loss: 2.67962044065999

Epoch: 6| Step: 4
Training loss: 1.209471966308594
Validation loss: 2.6544742968163795

Epoch: 6| Step: 5
Training loss: 1.39097903599083
Validation loss: 2.7853435455740057

Epoch: 6| Step: 6
Training loss: 1.2744104611868416
Validation loss: 2.7607163897874942

Epoch: 6| Step: 7
Training loss: 1.9622885620511668
Validation loss: 2.6463002203221015

Epoch: 6| Step: 8
Training loss: 1.1290436763339864
Validation loss: 2.7105546183076856

Epoch: 6| Step: 9
Training loss: 1.1793076364658617
Validation loss: 2.696810805284717

Epoch: 6| Step: 10
Training loss: 0.8999579459537657
Validation loss: 2.6588786698359756

Epoch: 6| Step: 11
Training loss: 1.271305475965637
Validation loss: 2.704946287176599

Epoch: 6| Step: 12
Training loss: 0.7263488455392902
Validation loss: 2.6651104461052713

Epoch: 6| Step: 13
Training loss: 1.024496389741061
Validation loss: 2.682419531920885

Epoch: 667| Step: 0
Training loss: 0.9734049294106498
Validation loss: 2.6029480502559807

Epoch: 6| Step: 1
Training loss: 1.0731592675649249
Validation loss: 2.7570703802356644

Epoch: 6| Step: 2
Training loss: 1.077054473569018
Validation loss: 2.7450719288942054

Epoch: 6| Step: 3
Training loss: 1.0458617929687268
Validation loss: 2.706831402181768

Epoch: 6| Step: 4
Training loss: 0.6402424391121706
Validation loss: 2.6497792211388087

Epoch: 6| Step: 5
Training loss: 2.2984223635633474
Validation loss: 2.7256100520681565

Epoch: 6| Step: 6
Training loss: 1.1731261631467538
Validation loss: 2.7152676513215606

Epoch: 6| Step: 7
Training loss: 0.762090347811156
Validation loss: 2.711885282867666

Epoch: 6| Step: 8
Training loss: 1.4487801682471955
Validation loss: 2.7247924136311354

Epoch: 6| Step: 9
Training loss: 0.7336679666858036
Validation loss: 2.730523068655018

Epoch: 6| Step: 10
Training loss: 1.2150087888423324
Validation loss: 2.603009612110216

Epoch: 6| Step: 11
Training loss: 1.1724410660823337
Validation loss: 2.6347833706089503

Epoch: 6| Step: 12
Training loss: 1.6237973384402635
Validation loss: 2.6791898935743585

Epoch: 6| Step: 13
Training loss: 0.9796214603147411
Validation loss: 2.69442712510219

Epoch: 668| Step: 0
Training loss: 1.4991034371466476
Validation loss: 2.6539687743977076

Epoch: 6| Step: 1
Training loss: 1.042480811804686
Validation loss: 2.672353200259657

Epoch: 6| Step: 2
Training loss: 1.2857607083795362
Validation loss: 2.7433268358439253

Epoch: 6| Step: 3
Training loss: 0.9119712512625741
Validation loss: 2.6275484778463625

Epoch: 6| Step: 4
Training loss: 1.2588956919418293
Validation loss: 2.7208686751567996

Epoch: 6| Step: 5
Training loss: 1.1240208921561101
Validation loss: 2.7275365270921945

Epoch: 6| Step: 6
Training loss: 1.3870800138742994
Validation loss: 2.6804990735030176

Epoch: 6| Step: 7
Training loss: 1.8181002029611024
Validation loss: 2.6798429333737968

Epoch: 6| Step: 8
Training loss: 0.7124947062513217
Validation loss: 2.5909616165029896

Epoch: 6| Step: 9
Training loss: 1.1743953813100834
Validation loss: 2.585885935951697

Epoch: 6| Step: 10
Training loss: 1.3732247162815543
Validation loss: 2.6948690098610117

Epoch: 6| Step: 11
Training loss: 1.0223816528476974
Validation loss: 2.5718453514989736

Epoch: 6| Step: 12
Training loss: 0.739251805713191
Validation loss: 2.741047654107292

Epoch: 6| Step: 13
Training loss: 1.025855897974971
Validation loss: 2.6936082994796697

Epoch: 669| Step: 0
Training loss: 1.1962822863328497
Validation loss: 2.7577136742257364

Epoch: 6| Step: 1
Training loss: 1.1119033585138218
Validation loss: 2.655112134901667

Epoch: 6| Step: 2
Training loss: 1.9735940951136473
Validation loss: 2.644284115915867

Epoch: 6| Step: 3
Training loss: 0.6407309188740259
Validation loss: 2.7369044872986126

Epoch: 6| Step: 4
Training loss: 1.4563053562628723
Validation loss: 2.65752606947597

Epoch: 6| Step: 5
Training loss: 1.141549402094443
Validation loss: 2.6793411056348915

Epoch: 6| Step: 6
Training loss: 1.2606993534248965
Validation loss: 2.647435047852226

Epoch: 6| Step: 7
Training loss: 1.1322204621265655
Validation loss: 2.6176853451490403

Epoch: 6| Step: 8
Training loss: 1.0514303138485976
Validation loss: 2.742748683491506

Epoch: 6| Step: 9
Training loss: 1.087395766075189
Validation loss: 2.63655855738177

Epoch: 6| Step: 10
Training loss: 1.3530492818672115
Validation loss: 2.6748984347377034

Epoch: 6| Step: 11
Training loss: 0.8095991730003506
Validation loss: 2.5966621119456246

Epoch: 6| Step: 12
Training loss: 1.4369401256110377
Validation loss: 2.6332395517678453

Epoch: 6| Step: 13
Training loss: 1.0719273768492965
Validation loss: 2.7421049592871887

Epoch: 670| Step: 0
Training loss: 0.9413118750408852
Validation loss: 2.6173576288664964

Epoch: 6| Step: 1
Training loss: 1.0324638043540948
Validation loss: 2.714939806786529

Epoch: 6| Step: 2
Training loss: 1.167357115568824
Validation loss: 2.7481807142619306

Epoch: 6| Step: 3
Training loss: 1.1769486521861574
Validation loss: 2.694307263167217

Epoch: 6| Step: 4
Training loss: 0.8519915628485594
Validation loss: 2.6998041170391374

Epoch: 6| Step: 5
Training loss: 0.8694314191598872
Validation loss: 2.6908855614726375

Epoch: 6| Step: 6
Training loss: 1.0311146271602747
Validation loss: 2.748047395555654

Epoch: 6| Step: 7
Training loss: 1.9791681055431825
Validation loss: 2.719158639302556

Epoch: 6| Step: 8
Training loss: 1.319855289185242
Validation loss: 2.6498893804093697

Epoch: 6| Step: 9
Training loss: 1.3644009339632737
Validation loss: 2.6134713185936262

Epoch: 6| Step: 10
Training loss: 1.283803720882412
Validation loss: 2.707811422363015

Epoch: 6| Step: 11
Training loss: 1.0148076216189323
Validation loss: 2.579750504693907

Epoch: 6| Step: 12
Training loss: 1.0864061400963332
Validation loss: 2.596889604588349

Epoch: 6| Step: 13
Training loss: 0.9566871803080298
Validation loss: 2.6852395982108503

Epoch: 671| Step: 0
Training loss: 1.0753552337819938
Validation loss: 2.696942423882628

Epoch: 6| Step: 1
Training loss: 0.8736817102118294
Validation loss: 2.7218209352053666

Epoch: 6| Step: 2
Training loss: 1.2538627545665129
Validation loss: 2.749681678090805

Epoch: 6| Step: 3
Training loss: 0.8378056836589061
Validation loss: 2.7272000234906093

Epoch: 6| Step: 4
Training loss: 0.8876799360733381
Validation loss: 2.6683185412771224

Epoch: 6| Step: 5
Training loss: 1.2652108727604539
Validation loss: 2.7638041728802007

Epoch: 6| Step: 6
Training loss: 1.0475491872268954
Validation loss: 2.6180645098496416

Epoch: 6| Step: 7
Training loss: 1.7178144509698408
Validation loss: 2.6449974689882105

Epoch: 6| Step: 8
Training loss: 0.9618741254697198
Validation loss: 2.6543016259896572

Epoch: 6| Step: 9
Training loss: 1.2171602395448773
Validation loss: 2.754163050207423

Epoch: 6| Step: 10
Training loss: 1.3142963106160646
Validation loss: 2.6540696506081756

Epoch: 6| Step: 11
Training loss: 1.4639383595210882
Validation loss: 2.6583691245630994

Epoch: 6| Step: 12
Training loss: 1.251712770048949
Validation loss: 2.735162378909377

Epoch: 6| Step: 13
Training loss: 1.3585513458741727
Validation loss: 2.6774099211496347

Epoch: 672| Step: 0
Training loss: 1.150424820759268
Validation loss: 2.673445216157013

Epoch: 6| Step: 1
Training loss: 0.8279263240082657
Validation loss: 2.6350257859602166

Epoch: 6| Step: 2
Training loss: 0.8907052388771335
Validation loss: 2.663975250227099

Epoch: 6| Step: 3
Training loss: 1.016014376606187
Validation loss: 2.74202555189406

Epoch: 6| Step: 4
Training loss: 1.106562689862239
Validation loss: 2.6381058175676384

Epoch: 6| Step: 5
Training loss: 1.09980422575285
Validation loss: 2.761836000064715

Epoch: 6| Step: 6
Training loss: 0.7457737261290529
Validation loss: 2.6663234581803845

Epoch: 6| Step: 7
Training loss: 1.1476139567186325
Validation loss: 2.66845450791714

Epoch: 6| Step: 8
Training loss: 0.940346719126156
Validation loss: 2.6704857820022547

Epoch: 6| Step: 9
Training loss: 0.9841225012630379
Validation loss: 2.658160461337536

Epoch: 6| Step: 10
Training loss: 1.085231743775662
Validation loss: 2.684345650216705

Epoch: 6| Step: 11
Training loss: 1.2385370610020214
Validation loss: 2.647371244515573

Epoch: 6| Step: 12
Training loss: 1.1733614331821776
Validation loss: 2.7039246048378556

Epoch: 6| Step: 13
Training loss: 2.787546638132827
Validation loss: 2.6526643181556215

Epoch: 673| Step: 0
Training loss: 2.2063912062803746
Validation loss: 2.6352073128756017

Epoch: 6| Step: 1
Training loss: 1.0918102502430107
Validation loss: 2.5746493769762893

Epoch: 6| Step: 2
Training loss: 0.9824322497083597
Validation loss: 2.6400982575979617

Epoch: 6| Step: 3
Training loss: 1.1934388878737594
Validation loss: 2.6723145346059853

Epoch: 6| Step: 4
Training loss: 1.4127055027099897
Validation loss: 2.611961396993144

Epoch: 6| Step: 5
Training loss: 1.0098726964736129
Validation loss: 2.633675798714089

Epoch: 6| Step: 6
Training loss: 1.2004112254298271
Validation loss: 2.5871089379608194

Epoch: 6| Step: 7
Training loss: 1.339623168938366
Validation loss: 2.708169928102499

Epoch: 6| Step: 8
Training loss: 1.1279614993146518
Validation loss: 2.7178697727612877

Epoch: 6| Step: 9
Training loss: 0.9282453234221097
Validation loss: 2.667149179653606

Epoch: 6| Step: 10
Training loss: 1.0966864268910244
Validation loss: 2.6723007949974567

Epoch: 6| Step: 11
Training loss: 1.1231865572100492
Validation loss: 2.6364521964125376

Epoch: 6| Step: 12
Training loss: 1.0753258011828672
Validation loss: 2.7151007545315218

Epoch: 6| Step: 13
Training loss: 1.3424195645209276
Validation loss: 2.6278271595681684

Epoch: 674| Step: 0
Training loss: 1.3837223831081162
Validation loss: 2.6012889655809066

Epoch: 6| Step: 1
Training loss: 1.2077772680673593
Validation loss: 2.806938577628368

Epoch: 6| Step: 2
Training loss: 1.096932386326299
Validation loss: 2.788034070869759

Epoch: 6| Step: 3
Training loss: 1.4586687065687916
Validation loss: 2.7732969427245444

Epoch: 6| Step: 4
Training loss: 1.0904639335555473
Validation loss: 2.730839208746119

Epoch: 6| Step: 5
Training loss: 1.3369840571580682
Validation loss: 2.671234499293032

Epoch: 6| Step: 6
Training loss: 0.832696281755011
Validation loss: 2.707099172055557

Epoch: 6| Step: 7
Training loss: 0.811461224793623
Validation loss: 2.702617112207265

Epoch: 6| Step: 8
Training loss: 1.8702212152855084
Validation loss: 2.7455596752230487

Epoch: 6| Step: 9
Training loss: 0.944619074194235
Validation loss: 2.6644639010600493

Epoch: 6| Step: 10
Training loss: 1.4107801584105832
Validation loss: 2.73094442450043

Epoch: 6| Step: 11
Training loss: 1.1969474133131839
Validation loss: 2.6252828798163153

Epoch: 6| Step: 12
Training loss: 0.9416142783881978
Validation loss: 2.6604053556015654

Epoch: 6| Step: 13
Training loss: 1.4956382277111393
Validation loss: 2.695347486794703

Epoch: 675| Step: 0
Training loss: 1.2065878241864434
Validation loss: 2.8166931287504604

Epoch: 6| Step: 1
Training loss: 1.0163673622145566
Validation loss: 2.6515579950562658

Epoch: 6| Step: 2
Training loss: 1.7464312540847808
Validation loss: 2.693534748217742

Epoch: 6| Step: 3
Training loss: 1.1487874127294793
Validation loss: 2.581744467233492

Epoch: 6| Step: 4
Training loss: 0.9576307637736201
Validation loss: 2.6556240659290378

Epoch: 6| Step: 5
Training loss: 1.0106956581794688
Validation loss: 2.6568955864448656

Epoch: 6| Step: 6
Training loss: 1.6545825698045122
Validation loss: 2.7122957201365847

Epoch: 6| Step: 7
Training loss: 1.3095435496076837
Validation loss: 2.6811167677304746

Epoch: 6| Step: 8
Training loss: 0.9014678270689179
Validation loss: 2.6166399227876456

Epoch: 6| Step: 9
Training loss: 0.8570710248593417
Validation loss: 2.7590807236924637

Epoch: 6| Step: 10
Training loss: 1.2645203278801778
Validation loss: 2.6974425851733135

Epoch: 6| Step: 11
Training loss: 1.1651725852407473
Validation loss: 2.584746415578094

Epoch: 6| Step: 12
Training loss: 0.8967055835279051
Validation loss: 2.645705600710956

Epoch: 6| Step: 13
Training loss: 0.7124520821101803
Validation loss: 2.590832482445546

Epoch: 676| Step: 0
Training loss: 1.2475212315528137
Validation loss: 2.6779994669876364

Epoch: 6| Step: 1
Training loss: 0.6731832984819411
Validation loss: 2.6586792697017603

Epoch: 6| Step: 2
Training loss: 1.224655515540752
Validation loss: 2.6836618391926605

Epoch: 6| Step: 3
Training loss: 1.0195255790932742
Validation loss: 2.7022662591507776

Epoch: 6| Step: 4
Training loss: 1.1092129978579428
Validation loss: 2.7694565964727844

Epoch: 6| Step: 5
Training loss: 0.8002750192227087
Validation loss: 2.6874812231149563

Epoch: 6| Step: 6
Training loss: 1.2795292068224764
Validation loss: 2.6720380701535333

Epoch: 6| Step: 7
Training loss: 2.073717074601346
Validation loss: 2.7317532967042752

Epoch: 6| Step: 8
Training loss: 0.6913017366373417
Validation loss: 2.671032024016178

Epoch: 6| Step: 9
Training loss: 1.0145490963046397
Validation loss: 2.6410863310377213

Epoch: 6| Step: 10
Training loss: 1.4031772527332
Validation loss: 2.6577705581730826

Epoch: 6| Step: 11
Training loss: 1.2007841151146843
Validation loss: 2.7726828990996726

Epoch: 6| Step: 12
Training loss: 1.1430252113398658
Validation loss: 2.713194602047469

Epoch: 6| Step: 13
Training loss: 0.7727134860818228
Validation loss: 2.6874068249526073

Epoch: 677| Step: 0
Training loss: 1.0256462432502422
Validation loss: 2.708989770121819

Epoch: 6| Step: 1
Training loss: 1.0750737896810978
Validation loss: 2.6946520904186397

Epoch: 6| Step: 2
Training loss: 1.7008492199935983
Validation loss: 2.7017015679224015

Epoch: 6| Step: 3
Training loss: 1.1746483093852291
Validation loss: 2.661082784516062

Epoch: 6| Step: 4
Training loss: 0.9753074210247666
Validation loss: 2.6771220510894294

Epoch: 6| Step: 5
Training loss: 1.046552124336503
Validation loss: 2.664642185271076

Epoch: 6| Step: 6
Training loss: 1.6004064341744941
Validation loss: 2.6943003809393984

Epoch: 6| Step: 7
Training loss: 1.2149530588509094
Validation loss: 2.6415660380605965

Epoch: 6| Step: 8
Training loss: 1.323870902947566
Validation loss: 2.7978500607019114

Epoch: 6| Step: 9
Training loss: 0.8955313410106825
Validation loss: 2.7250931110036922

Epoch: 6| Step: 10
Training loss: 1.2397765268179057
Validation loss: 2.710276039618647

Epoch: 6| Step: 11
Training loss: 1.1117349694490308
Validation loss: 2.774132337452938

Epoch: 6| Step: 12
Training loss: 0.9984005415259323
Validation loss: 2.6896097421193548

Epoch: 6| Step: 13
Training loss: 1.1350824698344613
Validation loss: 2.7314771146719883

Epoch: 678| Step: 0
Training loss: 1.621048156832492
Validation loss: 2.728625910833512

Epoch: 6| Step: 1
Training loss: 1.314102103309002
Validation loss: 2.704623141329634

Epoch: 6| Step: 2
Training loss: 1.1117185098054028
Validation loss: 2.706045971662904

Epoch: 6| Step: 3
Training loss: 1.0022975039796143
Validation loss: 2.6840402751374954

Epoch: 6| Step: 4
Training loss: 1.1608949101518111
Validation loss: 2.745709884771296

Epoch: 6| Step: 5
Training loss: 1.2559153305568695
Validation loss: 2.7194120802966304

Epoch: 6| Step: 6
Training loss: 1.0352798100269505
Validation loss: 2.6791695561488544

Epoch: 6| Step: 7
Training loss: 1.4295410748318313
Validation loss: 2.7070619061444803

Epoch: 6| Step: 8
Training loss: 1.1148365600610717
Validation loss: 2.8046997967645644

Epoch: 6| Step: 9
Training loss: 1.3051199738758568
Validation loss: 2.7245175574960396

Epoch: 6| Step: 10
Training loss: 0.9115044100786035
Validation loss: 2.659234405734661

Epoch: 6| Step: 11
Training loss: 1.9274607177175145
Validation loss: 2.7479117538887268

Epoch: 6| Step: 12
Training loss: 1.072295030423443
Validation loss: 2.5054162399911495

Epoch: 6| Step: 13
Training loss: 0.7416652649069694
Validation loss: 2.7185547546050195

Epoch: 679| Step: 0
Training loss: 0.7772965920104042
Validation loss: 2.619815625129479

Epoch: 6| Step: 1
Training loss: 1.5410826925905767
Validation loss: 2.6327164712387594

Epoch: 6| Step: 2
Training loss: 0.7761905109258962
Validation loss: 2.7466414042081766

Epoch: 6| Step: 3
Training loss: 0.9421153899729238
Validation loss: 2.833904308958474

Epoch: 6| Step: 4
Training loss: 1.0720642123028816
Validation loss: 2.654883831666775

Epoch: 6| Step: 5
Training loss: 1.6961565860897168
Validation loss: 2.638729893295575

Epoch: 6| Step: 6
Training loss: 0.7477210707353258
Validation loss: 2.7356054956518667

Epoch: 6| Step: 7
Training loss: 1.0462895934385028
Validation loss: 2.7122145722858204

Epoch: 6| Step: 8
Training loss: 1.210576157340358
Validation loss: 2.7102934336536753

Epoch: 6| Step: 9
Training loss: 1.0980322251619947
Validation loss: 2.6572829263143922

Epoch: 6| Step: 10
Training loss: 1.3972163489496159
Validation loss: 2.7544031308606973

Epoch: 6| Step: 11
Training loss: 0.9773824682578527
Validation loss: 2.7963877230702514

Epoch: 6| Step: 12
Training loss: 1.4096645015598597
Validation loss: 2.7439920458104785

Epoch: 6| Step: 13
Training loss: 1.0548119930684947
Validation loss: 2.6452622437202225

Epoch: 680| Step: 0
Training loss: 0.8524957844694289
Validation loss: 2.6072994350757646

Epoch: 6| Step: 1
Training loss: 1.0791224965270074
Validation loss: 2.716522026671991

Epoch: 6| Step: 2
Training loss: 1.3798593139807387
Validation loss: 2.6986780366011582

Epoch: 6| Step: 3
Training loss: 1.0266812585334557
Validation loss: 2.7612567411950506

Epoch: 6| Step: 4
Training loss: 1.2677008476861735
Validation loss: 2.8133470323982683

Epoch: 6| Step: 5
Training loss: 1.449701028453596
Validation loss: 2.759179214795041

Epoch: 6| Step: 6
Training loss: 0.9716045408088612
Validation loss: 2.755991368858774

Epoch: 6| Step: 7
Training loss: 1.4210175664193125
Validation loss: 2.8240576733759726

Epoch: 6| Step: 8
Training loss: 1.3604512831921654
Validation loss: 2.714854715247978

Epoch: 6| Step: 9
Training loss: 0.7821694113895041
Validation loss: 2.7120677907041095

Epoch: 6| Step: 10
Training loss: 1.8154265356010832
Validation loss: 2.8018680445126867

Epoch: 6| Step: 11
Training loss: 1.2263231955176017
Validation loss: 2.6385138034780473

Epoch: 6| Step: 12
Training loss: 1.048182681366877
Validation loss: 2.5588033009661078

Epoch: 6| Step: 13
Training loss: 1.0881771347291034
Validation loss: 2.686421379411548

Epoch: 681| Step: 0
Training loss: 1.098453218827842
Validation loss: 2.6313950905478354

Epoch: 6| Step: 1
Training loss: 0.8927382444506667
Validation loss: 2.7154969340949533

Epoch: 6| Step: 2
Training loss: 1.1823439845582355
Validation loss: 2.6171213752965397

Epoch: 6| Step: 3
Training loss: 1.273623634262019
Validation loss: 2.6536109448079

Epoch: 6| Step: 4
Training loss: 0.8484933121731792
Validation loss: 2.692713150156886

Epoch: 6| Step: 5
Training loss: 1.2848141107546787
Validation loss: 2.7317323267396967

Epoch: 6| Step: 6
Training loss: 1.836920617034591
Validation loss: 2.660631935327793

Epoch: 6| Step: 7
Training loss: 0.9577750915888945
Validation loss: 2.680614553956269

Epoch: 6| Step: 8
Training loss: 1.3482287531557382
Validation loss: 2.666975749149028

Epoch: 6| Step: 9
Training loss: 0.9246924069330164
Validation loss: 2.64505672773401

Epoch: 6| Step: 10
Training loss: 1.2045046339757448
Validation loss: 2.587030176753657

Epoch: 6| Step: 11
Training loss: 1.0425026527206371
Validation loss: 2.6159680085189936

Epoch: 6| Step: 12
Training loss: 1.206689878911391
Validation loss: 2.698607312929656

Epoch: 6| Step: 13
Training loss: 1.400200781729711
Validation loss: 2.7208048733280257

Epoch: 682| Step: 0
Training loss: 0.8651636581282854
Validation loss: 2.7264324123938017

Epoch: 6| Step: 1
Training loss: 1.156029963821093
Validation loss: 2.775392432688995

Epoch: 6| Step: 2
Training loss: 1.2382455333287965
Validation loss: 2.5963672332298287

Epoch: 6| Step: 3
Training loss: 1.1236252332087284
Validation loss: 2.716227285940837

Epoch: 6| Step: 4
Training loss: 1.183216802921622
Validation loss: 2.6607198198491564

Epoch: 6| Step: 5
Training loss: 1.0569277671125372
Validation loss: 2.7374667332103293

Epoch: 6| Step: 6
Training loss: 1.999069176072826
Validation loss: 2.7138306351663988

Epoch: 6| Step: 7
Training loss: 1.1408806605770703
Validation loss: 2.6821784226840144

Epoch: 6| Step: 8
Training loss: 0.9521968261943085
Validation loss: 2.637310678389832

Epoch: 6| Step: 9
Training loss: 0.9571031193119706
Validation loss: 2.681242701839419

Epoch: 6| Step: 10
Training loss: 1.2269634393345317
Validation loss: 2.666878723229448

Epoch: 6| Step: 11
Training loss: 0.9425065824041023
Validation loss: 2.782857858988622

Epoch: 6| Step: 12
Training loss: 1.0425308394044341
Validation loss: 2.601722346536022

Epoch: 6| Step: 13
Training loss: 1.0633275231488655
Validation loss: 2.7183579456995703

Epoch: 683| Step: 0
Training loss: 1.2384450425085094
Validation loss: 2.7981294811441333

Epoch: 6| Step: 1
Training loss: 0.8910726125137585
Validation loss: 2.703810764711019

Epoch: 6| Step: 2
Training loss: 1.2040381496094825
Validation loss: 2.6166151429524804

Epoch: 6| Step: 3
Training loss: 1.2703560834589362
Validation loss: 2.716666540114038

Epoch: 6| Step: 4
Training loss: 1.4893106419932989
Validation loss: 2.668527723470185

Epoch: 6| Step: 5
Training loss: 1.1057614858860039
Validation loss: 2.693342287557787

Epoch: 6| Step: 6
Training loss: 0.5573859862848694
Validation loss: 2.7507643527682735

Epoch: 6| Step: 7
Training loss: 1.1180855402799
Validation loss: 2.66083198206979

Epoch: 6| Step: 8
Training loss: 1.1969772912678218
Validation loss: 2.628898229182828

Epoch: 6| Step: 9
Training loss: 1.4644289777367017
Validation loss: 2.74733644946271

Epoch: 6| Step: 10
Training loss: 1.1594550585802934
Validation loss: 2.5931033076853733

Epoch: 6| Step: 11
Training loss: 1.1317654736680585
Validation loss: 2.70650504397071

Epoch: 6| Step: 12
Training loss: 1.6271184170986814
Validation loss: 2.6971523098373207

Epoch: 6| Step: 13
Training loss: 0.8505852367516488
Validation loss: 2.606868799136985

Epoch: 684| Step: 0
Training loss: 1.2691208396113778
Validation loss: 2.6532685584069884

Epoch: 6| Step: 1
Training loss: 0.8399367879743472
Validation loss: 2.744487632987586

Epoch: 6| Step: 2
Training loss: 1.2965997150970998
Validation loss: 2.6761832058464226

Epoch: 6| Step: 3
Training loss: 1.1324087015196973
Validation loss: 2.6929473386881657

Epoch: 6| Step: 4
Training loss: 0.8868742146935458
Validation loss: 2.674988490867601

Epoch: 6| Step: 5
Training loss: 0.9634238849857054
Validation loss: 2.6372667834020818

Epoch: 6| Step: 6
Training loss: 1.1126879801147844
Validation loss: 2.668663489244628

Epoch: 6| Step: 7
Training loss: 1.8877987505205742
Validation loss: 2.710607692261078

Epoch: 6| Step: 8
Training loss: 0.5809554327812783
Validation loss: 2.5835595767863495

Epoch: 6| Step: 9
Training loss: 1.469650155042537
Validation loss: 2.593014981256389

Epoch: 6| Step: 10
Training loss: 0.9904006126257091
Validation loss: 2.731797130871098

Epoch: 6| Step: 11
Training loss: 1.0298307652002843
Validation loss: 2.5753139361028405

Epoch: 6| Step: 12
Training loss: 1.2451762106874378
Validation loss: 2.6356464366724923

Epoch: 6| Step: 13
Training loss: 1.202739653865359
Validation loss: 2.729936322279382

Epoch: 685| Step: 0
Training loss: 0.8263267570311887
Validation loss: 2.7211848336654874

Epoch: 6| Step: 1
Training loss: 0.9723303988234482
Validation loss: 2.6236886461593345

Epoch: 6| Step: 2
Training loss: 1.1384612161750893
Validation loss: 2.6573527248287263

Epoch: 6| Step: 3
Training loss: 0.7607895098206691
Validation loss: 2.626573107859298

Epoch: 6| Step: 4
Training loss: 0.7373669326478011
Validation loss: 2.669904574184174

Epoch: 6| Step: 5
Training loss: 0.9040324275543067
Validation loss: 2.631250517394998

Epoch: 6| Step: 6
Training loss: 1.3034368219696235
Validation loss: 2.6964497967178396

Epoch: 6| Step: 7
Training loss: 1.2982524313019674
Validation loss: 2.7059147390260936

Epoch: 6| Step: 8
Training loss: 1.260176338844497
Validation loss: 2.668950973943046

Epoch: 6| Step: 9
Training loss: 1.9872881914433598
Validation loss: 2.7575171379086574

Epoch: 6| Step: 10
Training loss: 1.114358481190061
Validation loss: 2.734773876905653

Epoch: 6| Step: 11
Training loss: 1.01232385398271
Validation loss: 2.7454714061346994

Epoch: 6| Step: 12
Training loss: 0.8091033951143671
Validation loss: 2.688897141020736

Epoch: 6| Step: 13
Training loss: 1.1766734239386023
Validation loss: 2.693479766435834

Epoch: 686| Step: 0
Training loss: 0.9405567562656157
Validation loss: 2.725842443190828

Epoch: 6| Step: 1
Training loss: 0.9406066601254842
Validation loss: 2.6985539896581052

Epoch: 6| Step: 2
Training loss: 1.2931653014550024
Validation loss: 2.71326132102395

Epoch: 6| Step: 3
Training loss: 0.9783951614756964
Validation loss: 2.7074491668378133

Epoch: 6| Step: 4
Training loss: 0.8665942663126763
Validation loss: 2.7409664072034223

Epoch: 6| Step: 5
Training loss: 1.2522175668791427
Validation loss: 2.6501344623841763

Epoch: 6| Step: 6
Training loss: 1.9140697245558809
Validation loss: 2.736123903292279

Epoch: 6| Step: 7
Training loss: 0.7442084654474445
Validation loss: 2.6804708986429184

Epoch: 6| Step: 8
Training loss: 1.0338893983668755
Validation loss: 2.6941795161437523

Epoch: 6| Step: 9
Training loss: 1.115057722487798
Validation loss: 2.682519132290184

Epoch: 6| Step: 10
Training loss: 1.271191728844931
Validation loss: 2.71853323395166

Epoch: 6| Step: 11
Training loss: 1.1808065702321469
Validation loss: 2.673094580433266

Epoch: 6| Step: 12
Training loss: 0.766694586874323
Validation loss: 2.7307688692653245

Epoch: 6| Step: 13
Training loss: 1.6415919769388494
Validation loss: 2.6570348256987266

Epoch: 687| Step: 0
Training loss: 1.0090319330967539
Validation loss: 2.6160764483224708

Epoch: 6| Step: 1
Training loss: 1.1691553218795963
Validation loss: 2.643280573551673

Epoch: 6| Step: 2
Training loss: 1.1586718583738769
Validation loss: 2.73493484789608

Epoch: 6| Step: 3
Training loss: 0.8018046097102195
Validation loss: 2.626740684691726

Epoch: 6| Step: 4
Training loss: 0.8103934636917197
Validation loss: 2.785021097511989

Epoch: 6| Step: 5
Training loss: 0.859672217557375
Validation loss: 2.8102986679957036

Epoch: 6| Step: 6
Training loss: 1.114722406617725
Validation loss: 2.627595762668271

Epoch: 6| Step: 7
Training loss: 1.0334126308737541
Validation loss: 2.710880888076834

Epoch: 6| Step: 8
Training loss: 1.0660535068288068
Validation loss: 2.7065872836670106

Epoch: 6| Step: 9
Training loss: 1.0166876881932778
Validation loss: 2.7632031963884773

Epoch: 6| Step: 10
Training loss: 2.127690687408628
Validation loss: 2.6863018416602853

Epoch: 6| Step: 11
Training loss: 1.0490973498226497
Validation loss: 2.6874199693405734

Epoch: 6| Step: 12
Training loss: 1.3333031631076286
Validation loss: 2.6648391613008777

Epoch: 6| Step: 13
Training loss: 1.0120658131937843
Validation loss: 2.7014435069135687

Epoch: 688| Step: 0
Training loss: 1.298296826909958
Validation loss: 2.7260839760066546

Epoch: 6| Step: 1
Training loss: 2.035113489796409
Validation loss: 2.714744873795934

Epoch: 6| Step: 2
Training loss: 0.8980128072322382
Validation loss: 2.6017675979475947

Epoch: 6| Step: 3
Training loss: 0.967775408360758
Validation loss: 2.7384677223293474

Epoch: 6| Step: 4
Training loss: 1.1347750271064614
Validation loss: 2.688282092784844

Epoch: 6| Step: 5
Training loss: 1.518345544279528
Validation loss: 2.6736063849877008

Epoch: 6| Step: 6
Training loss: 0.9273915832061083
Validation loss: 2.7578776617752254

Epoch: 6| Step: 7
Training loss: 0.9708556702026592
Validation loss: 2.7103648143353958

Epoch: 6| Step: 8
Training loss: 0.9231786400585025
Validation loss: 2.640145153551368

Epoch: 6| Step: 9
Training loss: 0.9132812943797105
Validation loss: 2.6481673630171727

Epoch: 6| Step: 10
Training loss: 0.7793516746891154
Validation loss: 2.678844596657111

Epoch: 6| Step: 11
Training loss: 0.9869070035107114
Validation loss: 2.6784316243937245

Epoch: 6| Step: 12
Training loss: 0.6108055440541181
Validation loss: 2.6038570792646336

Epoch: 6| Step: 13
Training loss: 1.837525091194581
Validation loss: 2.609850815478549

Epoch: 689| Step: 0
Training loss: 1.061324703701038
Validation loss: 2.697882979228575

Epoch: 6| Step: 1
Training loss: 1.1909268774971729
Validation loss: 2.7350225353997897

Epoch: 6| Step: 2
Training loss: 1.407621477823718
Validation loss: 2.7112033098169532

Epoch: 6| Step: 3
Training loss: 1.7034743064552795
Validation loss: 2.7323573784205797

Epoch: 6| Step: 4
Training loss: 1.3289730281747967
Validation loss: 2.6064551885817

Epoch: 6| Step: 5
Training loss: 0.691747807335558
Validation loss: 2.6026401388636424

Epoch: 6| Step: 6
Training loss: 1.4310623812244134
Validation loss: 2.7299762208670684

Epoch: 6| Step: 7
Training loss: 1.1893652271183959
Validation loss: 2.6728865728234044

Epoch: 6| Step: 8
Training loss: 1.3207723505200255
Validation loss: 2.747987676543862

Epoch: 6| Step: 9
Training loss: 1.009534916448201
Validation loss: 2.613921160342144

Epoch: 6| Step: 10
Training loss: 1.1247247783124872
Validation loss: 2.7051598982214093

Epoch: 6| Step: 11
Training loss: 1.008757333173415
Validation loss: 2.8018678423030923

Epoch: 6| Step: 12
Training loss: 0.8885338980069414
Validation loss: 2.7087098971294727

Epoch: 6| Step: 13
Training loss: 0.7238128479335098
Validation loss: 2.7804030423525865

Epoch: 690| Step: 0
Training loss: 2.1193796893163275
Validation loss: 2.728771043583707

Epoch: 6| Step: 1
Training loss: 1.1291631386527
Validation loss: 2.6954880067415146

Epoch: 6| Step: 2
Training loss: 0.8942475847804061
Validation loss: 2.720914272280431

Epoch: 6| Step: 3
Training loss: 0.8750376012079892
Validation loss: 2.702690786235927

Epoch: 6| Step: 4
Training loss: 0.7687014835834144
Validation loss: 2.6937495163843184

Epoch: 6| Step: 5
Training loss: 1.0227019017858439
Validation loss: 2.6016966422328474

Epoch: 6| Step: 6
Training loss: 0.5835813324410223
Validation loss: 2.733166988049688

Epoch: 6| Step: 7
Training loss: 1.2592580319743523
Validation loss: 2.6913217603656396

Epoch: 6| Step: 8
Training loss: 1.4365289974558872
Validation loss: 2.630279283390029

Epoch: 6| Step: 9
Training loss: 1.0360777010628934
Validation loss: 2.6220344466911536

Epoch: 6| Step: 10
Training loss: 0.9754792576104313
Validation loss: 2.748513536421029

Epoch: 6| Step: 11
Training loss: 0.8045451214206282
Validation loss: 2.7328236462845434

Epoch: 6| Step: 12
Training loss: 1.0748547699878117
Validation loss: 2.65704244414514

Epoch: 6| Step: 13
Training loss: 1.3127776261028803
Validation loss: 2.654433416926703

Epoch: 691| Step: 0
Training loss: 1.0868014185579242
Validation loss: 2.6608435880441443

Epoch: 6| Step: 1
Training loss: 0.9822022209557163
Validation loss: 2.732530080819251

Epoch: 6| Step: 2
Training loss: 1.092854814678316
Validation loss: 2.7301589879543604

Epoch: 6| Step: 3
Training loss: 1.078597918738209
Validation loss: 2.5967758977796906

Epoch: 6| Step: 4
Training loss: 1.1719738727821054
Validation loss: 2.6894763624979285

Epoch: 6| Step: 5
Training loss: 2.0207127669506457
Validation loss: 2.6778261241032744

Epoch: 6| Step: 6
Training loss: 0.9865078299705176
Validation loss: 2.662380313989964

Epoch: 6| Step: 7
Training loss: 0.8020412301907193
Validation loss: 2.761495556214577

Epoch: 6| Step: 8
Training loss: 0.9087890703704263
Validation loss: 2.701214115103596

Epoch: 6| Step: 9
Training loss: 1.1695620281116808
Validation loss: 2.6443795200487004

Epoch: 6| Step: 10
Training loss: 1.386961966663517
Validation loss: 2.700485893943769

Epoch: 6| Step: 11
Training loss: 1.0845096999174733
Validation loss: 2.638658827824436

Epoch: 6| Step: 12
Training loss: 0.9906706441478111
Validation loss: 2.7429168369795702

Epoch: 6| Step: 13
Training loss: 0.88047927809533
Validation loss: 2.665671944315157

Epoch: 692| Step: 0
Training loss: 1.8849614333196685
Validation loss: 2.7112733191376535

Epoch: 6| Step: 1
Training loss: 0.8980486484425454
Validation loss: 2.6892656296132356

Epoch: 6| Step: 2
Training loss: 0.8603671155859547
Validation loss: 2.6918798092218252

Epoch: 6| Step: 3
Training loss: 1.4289192678819
Validation loss: 2.7414344305362506

Epoch: 6| Step: 4
Training loss: 0.4943835599908139
Validation loss: 2.76096593987933

Epoch: 6| Step: 5
Training loss: 1.21587345359518
Validation loss: 2.716495541466776

Epoch: 6| Step: 6
Training loss: 1.1202082842206718
Validation loss: 2.657062193534264

Epoch: 6| Step: 7
Training loss: 1.0650838960367977
Validation loss: 2.6707677124520512

Epoch: 6| Step: 8
Training loss: 1.283509936298328
Validation loss: 2.706848106136932

Epoch: 6| Step: 9
Training loss: 1.010357150392918
Validation loss: 2.694414087209165

Epoch: 6| Step: 10
Training loss: 1.1451215035716515
Validation loss: 2.658892995600585

Epoch: 6| Step: 11
Training loss: 1.3135163595417274
Validation loss: 2.7014436782061084

Epoch: 6| Step: 12
Training loss: 0.8663916157483227
Validation loss: 2.7251869749400974

Epoch: 6| Step: 13
Training loss: 1.3996684873992593
Validation loss: 2.7154047310499263

Epoch: 693| Step: 0
Training loss: 1.187759973277376
Validation loss: 2.766456193129639

Epoch: 6| Step: 1
Training loss: 0.8302623948157279
Validation loss: 2.7341657145345257

Epoch: 6| Step: 2
Training loss: 1.1848900875189785
Validation loss: 2.644804670185763

Epoch: 6| Step: 3
Training loss: 1.05904573032748
Validation loss: 2.6370354215297507

Epoch: 6| Step: 4
Training loss: 1.1020792297017665
Validation loss: 2.7810090105658047

Epoch: 6| Step: 5
Training loss: 1.9974008002254662
Validation loss: 2.687738976962969

Epoch: 6| Step: 6
Training loss: 1.3265476059723411
Validation loss: 2.68504647040173

Epoch: 6| Step: 7
Training loss: 1.1784194295059625
Validation loss: 2.6798019133622275

Epoch: 6| Step: 8
Training loss: 0.9405872375410858
Validation loss: 2.6744223920130348

Epoch: 6| Step: 9
Training loss: 1.010678024835434
Validation loss: 2.787106834454327

Epoch: 6| Step: 10
Training loss: 0.9730426373230592
Validation loss: 2.664066233740742

Epoch: 6| Step: 11
Training loss: 0.9645991768301359
Validation loss: 2.630461065739188

Epoch: 6| Step: 12
Training loss: 1.0115861253451353
Validation loss: 2.782861883821511

Epoch: 6| Step: 13
Training loss: 1.3020526526333305
Validation loss: 2.6949683108882794

Epoch: 694| Step: 0
Training loss: 0.7388243115998212
Validation loss: 2.6744997202856715

Epoch: 6| Step: 1
Training loss: 1.1781612400784924
Validation loss: 2.6959150199980035

Epoch: 6| Step: 2
Training loss: 1.2970920059464783
Validation loss: 2.632046421775444

Epoch: 6| Step: 3
Training loss: 0.8063967430768015
Validation loss: 2.6258448029003887

Epoch: 6| Step: 4
Training loss: 1.1859070986342846
Validation loss: 2.672909743339754

Epoch: 6| Step: 5
Training loss: 0.8800054500692833
Validation loss: 2.612049956745678

Epoch: 6| Step: 6
Training loss: 1.0854964424050404
Validation loss: 2.711643389160055

Epoch: 6| Step: 7
Training loss: 1.1292352427999859
Validation loss: 2.622146293636292

Epoch: 6| Step: 8
Training loss: 1.5342607288579084
Validation loss: 2.8392502871769425

Epoch: 6| Step: 9
Training loss: 1.0243237567441121
Validation loss: 2.6850187500015057

Epoch: 6| Step: 10
Training loss: 1.1380818901297733
Validation loss: 2.7340189468450777

Epoch: 6| Step: 11
Training loss: 1.1387527986695185
Validation loss: 2.714661883978041

Epoch: 6| Step: 12
Training loss: 1.390493150954129
Validation loss: 2.795468183095123

Epoch: 6| Step: 13
Training loss: 2.5642311017512593
Validation loss: 2.733365488113346

Epoch: 695| Step: 0
Training loss: 0.8826573666001475
Validation loss: 2.7744579822019015

Epoch: 6| Step: 1
Training loss: 0.9366667541377162
Validation loss: 2.6589497222864957

Epoch: 6| Step: 2
Training loss: 0.7799548285193442
Validation loss: 2.70751826293138

Epoch: 6| Step: 3
Training loss: 1.5239942267000675
Validation loss: 2.7559973742643415

Epoch: 6| Step: 4
Training loss: 1.0972957358433617
Validation loss: 2.648424786489893

Epoch: 6| Step: 5
Training loss: 1.3727389732450126
Validation loss: 2.7326878484313357

Epoch: 6| Step: 6
Training loss: 1.2000852057883384
Validation loss: 2.657913623221104

Epoch: 6| Step: 7
Training loss: 1.2263209111109103
Validation loss: 2.721903315876334

Epoch: 6| Step: 8
Training loss: 0.8616482578748518
Validation loss: 2.6476376680598794

Epoch: 6| Step: 9
Training loss: 1.002138652318817
Validation loss: 2.693332035230793

Epoch: 6| Step: 10
Training loss: 0.799359468990723
Validation loss: 2.6808864705138484

Epoch: 6| Step: 11
Training loss: 0.8873013166547895
Validation loss: 2.7420310717985212

Epoch: 6| Step: 12
Training loss: 0.9104926670455805
Validation loss: 2.7988666009419036

Epoch: 6| Step: 13
Training loss: 2.2806877593011334
Validation loss: 2.6030810889674685

Epoch: 696| Step: 0
Training loss: 0.7797730026301234
Validation loss: 2.7812753510065837

Epoch: 6| Step: 1
Training loss: 1.207530686835601
Validation loss: 2.6403209707610396

Epoch: 6| Step: 2
Training loss: 0.7315863968548622
Validation loss: 2.6106656641548405

Epoch: 6| Step: 3
Training loss: 1.1851129633341844
Validation loss: 2.6379061426789447

Epoch: 6| Step: 4
Training loss: 1.0847689152229145
Validation loss: 2.6678915062918716

Epoch: 6| Step: 5
Training loss: 0.6320092318817274
Validation loss: 2.6714198438368246

Epoch: 6| Step: 6
Training loss: 1.1022433077703562
Validation loss: 2.6336642428777224

Epoch: 6| Step: 7
Training loss: 1.0202781309265732
Validation loss: 2.671868795922491

Epoch: 6| Step: 8
Training loss: 1.1933075789029106
Validation loss: 2.6608251096056916

Epoch: 6| Step: 9
Training loss: 1.2667224976298428
Validation loss: 2.6533455109014064

Epoch: 6| Step: 10
Training loss: 1.1485267137402542
Validation loss: 2.648320738432575

Epoch: 6| Step: 11
Training loss: 1.96666976987734
Validation loss: 2.648119012735932

Epoch: 6| Step: 12
Training loss: 1.1122502421650844
Validation loss: 2.644010619598119

Epoch: 6| Step: 13
Training loss: 1.277475052830723
Validation loss: 2.789435688256805

Epoch: 697| Step: 0
Training loss: 1.3528420449791358
Validation loss: 2.59173666260038

Epoch: 6| Step: 1
Training loss: 1.0566362250442702
Validation loss: 2.719683300141186

Epoch: 6| Step: 2
Training loss: 1.5879087177292195
Validation loss: 2.6916487070643447

Epoch: 6| Step: 3
Training loss: 1.2611764031554422
Validation loss: 2.677371097760652

Epoch: 6| Step: 4
Training loss: 1.0149410585850458
Validation loss: 2.6288535062179177

Epoch: 6| Step: 5
Training loss: 1.0243426098919177
Validation loss: 2.628389351190524

Epoch: 6| Step: 6
Training loss: 1.075785323435178
Validation loss: 2.7383628780268663

Epoch: 6| Step: 7
Training loss: 0.7647484023422607
Validation loss: 2.5840538680964853

Epoch: 6| Step: 8
Training loss: 0.9578046204085712
Validation loss: 2.6368329685862615

Epoch: 6| Step: 9
Training loss: 1.9541504876199736
Validation loss: 2.6705492106927395

Epoch: 6| Step: 10
Training loss: 0.9600803615293513
Validation loss: 2.6167563256957087

Epoch: 6| Step: 11
Training loss: 0.592412194373263
Validation loss: 2.6991966221363923

Epoch: 6| Step: 12
Training loss: 1.1106283066098734
Validation loss: 2.7198195248501578

Epoch: 6| Step: 13
Training loss: 0.9010434711122177
Validation loss: 2.6592352569925697

Epoch: 698| Step: 0
Training loss: 0.7868721654233409
Validation loss: 2.74495985408554

Epoch: 6| Step: 1
Training loss: 1.4760419947431582
Validation loss: 2.613792481875511

Epoch: 6| Step: 2
Training loss: 1.353216140884447
Validation loss: 2.6921827666945037

Epoch: 6| Step: 3
Training loss: 1.1882464421959602
Validation loss: 2.6942239692363588

Epoch: 6| Step: 4
Training loss: 1.067576677842735
Validation loss: 2.715354350987204

Epoch: 6| Step: 5
Training loss: 0.6996502317493224
Validation loss: 2.74248745391468

Epoch: 6| Step: 6
Training loss: 1.2447867400046606
Validation loss: 2.7028647221670057

Epoch: 6| Step: 7
Training loss: 1.0640236644407821
Validation loss: 2.6365505423419293

Epoch: 6| Step: 8
Training loss: 1.2357603580350216
Validation loss: 2.700397050786941

Epoch: 6| Step: 9
Training loss: 1.7735662203552562
Validation loss: 2.6719615744507563

Epoch: 6| Step: 10
Training loss: 0.8438119512349515
Validation loss: 2.5970809340142664

Epoch: 6| Step: 11
Training loss: 0.7599970996951929
Validation loss: 2.7086096210135966

Epoch: 6| Step: 12
Training loss: 1.0655696507731458
Validation loss: 2.7592315383457318

Epoch: 6| Step: 13
Training loss: 0.9133750090755025
Validation loss: 2.728705092788565

Epoch: 699| Step: 0
Training loss: 1.864581855759133
Validation loss: 2.6737225533854687

Epoch: 6| Step: 1
Training loss: 1.008710653206555
Validation loss: 2.729926959591778

Epoch: 6| Step: 2
Training loss: 1.3064714672945354
Validation loss: 2.6795649179226015

Epoch: 6| Step: 3
Training loss: 0.840897896584366
Validation loss: 2.6547302840223366

Epoch: 6| Step: 4
Training loss: 0.7890659369969816
Validation loss: 2.6912928653098183

Epoch: 6| Step: 5
Training loss: 1.2354732408269467
Validation loss: 2.686098328951241

Epoch: 6| Step: 6
Training loss: 0.92940314937154
Validation loss: 2.6595199908478806

Epoch: 6| Step: 7
Training loss: 0.7766325491122795
Validation loss: 2.754633333004475

Epoch: 6| Step: 8
Training loss: 0.8229640431991063
Validation loss: 2.6418368932347236

Epoch: 6| Step: 9
Training loss: 1.515359127674901
Validation loss: 2.6398261883134237

Epoch: 6| Step: 10
Training loss: 0.4608599387393549
Validation loss: 2.6264405816975565

Epoch: 6| Step: 11
Training loss: 0.9435743004148864
Validation loss: 2.6701492275303855

Epoch: 6| Step: 12
Training loss: 1.0804609341176659
Validation loss: 2.622609952892339

Epoch: 6| Step: 13
Training loss: 1.510668485849693
Validation loss: 2.66124936548054

Epoch: 700| Step: 0
Training loss: 0.8532416910146401
Validation loss: 2.7585530270315712

Epoch: 6| Step: 1
Training loss: 1.2209998662762642
Validation loss: 2.710664623882548

Epoch: 6| Step: 2
Training loss: 0.8926574872083619
Validation loss: 2.690293503105418

Epoch: 6| Step: 3
Training loss: 1.2004191203138086
Validation loss: 2.591361772766667

Epoch: 6| Step: 4
Training loss: 1.0088864304414094
Validation loss: 2.621820213477534

Epoch: 6| Step: 5
Training loss: 1.0790823403972367
Validation loss: 2.698791718967032

Epoch: 6| Step: 6
Training loss: 1.2626659982911799
Validation loss: 2.669800429891756

Epoch: 6| Step: 7
Training loss: 1.1280002852635664
Validation loss: 2.7143493263504768

Epoch: 6| Step: 8
Training loss: 0.9169482788363494
Validation loss: 2.7884933365688993

Epoch: 6| Step: 9
Training loss: 0.7226574871980541
Validation loss: 2.686451203852586

Epoch: 6| Step: 10
Training loss: 1.173497513659931
Validation loss: 2.6877726125423425

Epoch: 6| Step: 11
Training loss: 0.8715400065914628
Validation loss: 2.7337799202906967

Epoch: 6| Step: 12
Training loss: 2.004188919208205
Validation loss: 2.696911998721179

Epoch: 6| Step: 13
Training loss: 0.6384300684111255
Validation loss: 2.6211099665242084

Epoch: 701| Step: 0
Training loss: 1.054965229907788
Validation loss: 2.786323309636135

Epoch: 6| Step: 1
Training loss: 0.9676382391885939
Validation loss: 2.6966758900065138

Epoch: 6| Step: 2
Training loss: 0.7576644988898188
Validation loss: 2.7081728834863594

Epoch: 6| Step: 3
Training loss: 1.0355373041091274
Validation loss: 2.6375868707131724

Epoch: 6| Step: 4
Training loss: 1.1494009945757777
Validation loss: 2.6399569053681278

Epoch: 6| Step: 5
Training loss: 0.7970391272772743
Validation loss: 2.688432871644472

Epoch: 6| Step: 6
Training loss: 2.037526571650511
Validation loss: 2.703654118732189

Epoch: 6| Step: 7
Training loss: 1.024704185692019
Validation loss: 2.7078832926074825

Epoch: 6| Step: 8
Training loss: 1.2435570131031193
Validation loss: 2.665515884643389

Epoch: 6| Step: 9
Training loss: 1.0846040621190973
Validation loss: 2.683614735977209

Epoch: 6| Step: 10
Training loss: 0.9670806160137674
Validation loss: 2.7024401398738913

Epoch: 6| Step: 11
Training loss: 1.2490463910890541
Validation loss: 2.67320037728233

Epoch: 6| Step: 12
Training loss: 1.2009751569733806
Validation loss: 2.602467575188836

Epoch: 6| Step: 13
Training loss: 0.8815212427523486
Validation loss: 2.637987858665263

Epoch: 702| Step: 0
Training loss: 1.138631358660872
Validation loss: 2.671896164373772

Epoch: 6| Step: 1
Training loss: 1.0161591519034163
Validation loss: 2.6681474591494365

Epoch: 6| Step: 2
Training loss: 0.9872943639922996
Validation loss: 2.625933704256739

Epoch: 6| Step: 3
Training loss: 0.512143053799432
Validation loss: 2.6784728568164136

Epoch: 6| Step: 4
Training loss: 1.15559074578031
Validation loss: 2.706272589461297

Epoch: 6| Step: 5
Training loss: 1.3377519744533397
Validation loss: 2.7359662195021417

Epoch: 6| Step: 6
Training loss: 1.8879924763270972
Validation loss: 2.7970620745453063

Epoch: 6| Step: 7
Training loss: 1.1494538876384424
Validation loss: 2.709662806075499

Epoch: 6| Step: 8
Training loss: 1.0595083754758865
Validation loss: 2.7289589210490464

Epoch: 6| Step: 9
Training loss: 1.042003971165505
Validation loss: 2.6666432134176326

Epoch: 6| Step: 10
Training loss: 1.3095349471332816
Validation loss: 2.7042394386110318

Epoch: 6| Step: 11
Training loss: 0.8170260764107944
Validation loss: 2.6996729123966596

Epoch: 6| Step: 12
Training loss: 1.1022411447378264
Validation loss: 2.6706597294721663

Epoch: 6| Step: 13
Training loss: 0.7869676031596545
Validation loss: 2.624200461838924

Epoch: 703| Step: 0
Training loss: 1.2859851981270782
Validation loss: 2.680960011143461

Epoch: 6| Step: 1
Training loss: 1.040164678446915
Validation loss: 2.7576255378234644

Epoch: 6| Step: 2
Training loss: 1.3428719335324124
Validation loss: 2.7978312079819143

Epoch: 6| Step: 3
Training loss: 1.259333289428301
Validation loss: 2.7255492535635644

Epoch: 6| Step: 4
Training loss: 1.0342910317628253
Validation loss: 2.7726054779425615

Epoch: 6| Step: 5
Training loss: 0.7441597282781086
Validation loss: 2.7242763384404984

Epoch: 6| Step: 6
Training loss: 1.0990175107718505
Validation loss: 2.741039377822785

Epoch: 6| Step: 7
Training loss: 0.7217434040689157
Validation loss: 2.702279766710966

Epoch: 6| Step: 8
Training loss: 0.8938033628205438
Validation loss: 2.6812919272462867

Epoch: 6| Step: 9
Training loss: 0.985814419664659
Validation loss: 2.7440281627400527

Epoch: 6| Step: 10
Training loss: 2.0744594283477418
Validation loss: 2.675279241084067

Epoch: 6| Step: 11
Training loss: 0.8943449267776826
Validation loss: 2.7206936994432525

Epoch: 6| Step: 12
Training loss: 1.15771597641367
Validation loss: 2.755290021246976

Epoch: 6| Step: 13
Training loss: 0.9205158688981636
Validation loss: 2.6501983665462308

Epoch: 704| Step: 0
Training loss: 1.9978321366498937
Validation loss: 2.7173316423180687

Epoch: 6| Step: 1
Training loss: 1.1698955857725541
Validation loss: 2.701989743473587

Epoch: 6| Step: 2
Training loss: 0.856536547195637
Validation loss: 2.65262856447061

Epoch: 6| Step: 3
Training loss: 0.7728968956227442
Validation loss: 2.700780129006705

Epoch: 6| Step: 4
Training loss: 1.1206864205169542
Validation loss: 2.729860088220871

Epoch: 6| Step: 5
Training loss: 0.9135977060549743
Validation loss: 2.723136304581428

Epoch: 6| Step: 6
Training loss: 0.860762845304991
Validation loss: 2.735686905517382

Epoch: 6| Step: 7
Training loss: 1.2927782546485451
Validation loss: 2.5985265526814465

Epoch: 6| Step: 8
Training loss: 1.1714125674513585
Validation loss: 2.6328154338378376

Epoch: 6| Step: 9
Training loss: 1.03278946843632
Validation loss: 2.786826177281703

Epoch: 6| Step: 10
Training loss: 1.016415215232067
Validation loss: 2.639179911718861

Epoch: 6| Step: 11
Training loss: 1.031351951414631
Validation loss: 2.628465290110741

Epoch: 6| Step: 12
Training loss: 1.244050649985608
Validation loss: 2.636231701348509

Epoch: 6| Step: 13
Training loss: 1.203269652551118
Validation loss: 2.814037565384922

Epoch: 705| Step: 0
Training loss: 1.1603748873318445
Validation loss: 2.702350284224255

Epoch: 6| Step: 1
Training loss: 1.0905209423364772
Validation loss: 2.6387134148963654

Epoch: 6| Step: 2
Training loss: 1.3538507044030454
Validation loss: 2.7392244422466163

Epoch: 6| Step: 3
Training loss: 1.8690920258425252
Validation loss: 2.6545624972253803

Epoch: 6| Step: 4
Training loss: 0.844797332092429
Validation loss: 2.6224206908453875

Epoch: 6| Step: 5
Training loss: 0.9566536917676088
Validation loss: 2.811981973830014

Epoch: 6| Step: 6
Training loss: 0.8215769151051999
Validation loss: 2.7387729623597576

Epoch: 6| Step: 7
Training loss: 0.7727016454924742
Validation loss: 2.69521246782875

Epoch: 6| Step: 8
Training loss: 1.0518396995636674
Validation loss: 2.7111774690749826

Epoch: 6| Step: 9
Training loss: 1.242879518846179
Validation loss: 2.684937127691551

Epoch: 6| Step: 10
Training loss: 1.2093000600696353
Validation loss: 2.5569424603917312

Epoch: 6| Step: 11
Training loss: 1.0821909321866314
Validation loss: 2.7259180898996758

Epoch: 6| Step: 12
Training loss: 1.041848827964701
Validation loss: 2.6888491732228976

Epoch: 6| Step: 13
Training loss: 0.7778552878639314
Validation loss: 2.772319848004846

Epoch: 706| Step: 0
Training loss: 0.8955251178296555
Validation loss: 2.6767840535163328

Epoch: 6| Step: 1
Training loss: 0.9382284830900605
Validation loss: 2.721650504367113

Epoch: 6| Step: 2
Training loss: 1.248198068740688
Validation loss: 2.6908352477723994

Epoch: 6| Step: 3
Training loss: 0.9364914555503521
Validation loss: 2.717725289813143

Epoch: 6| Step: 4
Training loss: 0.8808910085068729
Validation loss: 2.7212371482287323

Epoch: 6| Step: 5
Training loss: 1.3155788005772437
Validation loss: 2.6939318653939797

Epoch: 6| Step: 6
Training loss: 1.1594588627264266
Validation loss: 2.694801324657185

Epoch: 6| Step: 7
Training loss: 0.9447019512700281
Validation loss: 2.791911398369527

Epoch: 6| Step: 8
Training loss: 0.8627889619053112
Validation loss: 2.669680835480449

Epoch: 6| Step: 9
Training loss: 1.2957005525781387
Validation loss: 2.633722594392917

Epoch: 6| Step: 10
Training loss: 0.756318536915749
Validation loss: 2.6136063385911616

Epoch: 6| Step: 11
Training loss: 0.9312510125583546
Validation loss: 2.7597302100858454

Epoch: 6| Step: 12
Training loss: 1.72413837917914
Validation loss: 2.800746902925923

Epoch: 6| Step: 13
Training loss: 1.1544574038551527
Validation loss: 2.7078425563027504

Epoch: 707| Step: 0
Training loss: 1.1447499557731704
Validation loss: 2.690824138912599

Epoch: 6| Step: 1
Training loss: 1.2161476521883425
Validation loss: 2.6576927117986395

Epoch: 6| Step: 2
Training loss: 0.9985699561287732
Validation loss: 2.668433234584317

Epoch: 6| Step: 3
Training loss: 1.01886122160782
Validation loss: 2.606958374156181

Epoch: 6| Step: 4
Training loss: 0.7668588000189898
Validation loss: 2.6015425106089785

Epoch: 6| Step: 5
Training loss: 0.980916836543127
Validation loss: 2.617981810158692

Epoch: 6| Step: 6
Training loss: 1.1766705872431666
Validation loss: 2.7722900595951407

Epoch: 6| Step: 7
Training loss: 1.1499673942421713
Validation loss: 2.7419793091685176

Epoch: 6| Step: 8
Training loss: 0.9493120563628353
Validation loss: 2.719652097199607

Epoch: 6| Step: 9
Training loss: 0.8776628982104705
Validation loss: 2.7463086524826985

Epoch: 6| Step: 10
Training loss: 1.0590776414371332
Validation loss: 2.729779979969368

Epoch: 6| Step: 11
Training loss: 1.0560774509861406
Validation loss: 2.713420403617322

Epoch: 6| Step: 12
Training loss: 1.032642118449927
Validation loss: 2.6971839127941895

Epoch: 6| Step: 13
Training loss: 2.155640778653869
Validation loss: 2.7637498664352242

Epoch: 708| Step: 0
Training loss: 1.1989711046022005
Validation loss: 2.748925721694339

Epoch: 6| Step: 1
Training loss: 1.0737986350008382
Validation loss: 2.737203792276474

Epoch: 6| Step: 2
Training loss: 1.2956091436436208
Validation loss: 2.79321467886382

Epoch: 6| Step: 3
Training loss: 0.8825707906475848
Validation loss: 2.6430707753833937

Epoch: 6| Step: 4
Training loss: 1.2204213541986462
Validation loss: 2.8013147828873075

Epoch: 6| Step: 5
Training loss: 1.1271604350589604
Validation loss: 2.648080532468295

Epoch: 6| Step: 6
Training loss: 1.7122424300911063
Validation loss: 2.556183571274159

Epoch: 6| Step: 7
Training loss: 1.0562832663449593
Validation loss: 2.5805024661008398

Epoch: 6| Step: 8
Training loss: 0.9755272222344672
Validation loss: 2.697122440240126

Epoch: 6| Step: 9
Training loss: 0.8300320960353964
Validation loss: 2.6281034998718886

Epoch: 6| Step: 10
Training loss: 1.0000935153150956
Validation loss: 2.6511463799202604

Epoch: 6| Step: 11
Training loss: 1.2219075113249365
Validation loss: 2.7289702109842624

Epoch: 6| Step: 12
Training loss: 0.9128568474099431
Validation loss: 2.6165594932810756

Epoch: 6| Step: 13
Training loss: 1.0682563801830907
Validation loss: 2.675219033242019

Epoch: 709| Step: 0
Training loss: 1.0077401660126133
Validation loss: 2.686170674206975

Epoch: 6| Step: 1
Training loss: 1.0590697059600063
Validation loss: 2.635663041240853

Epoch: 6| Step: 2
Training loss: 1.2864756666655404
Validation loss: 2.688442251058617

Epoch: 6| Step: 3
Training loss: 1.1199009095362749
Validation loss: 2.650827517930946

Epoch: 6| Step: 4
Training loss: 1.04085896012761
Validation loss: 2.729966188286987

Epoch: 6| Step: 5
Training loss: 0.8834189973235539
Validation loss: 2.6786863968997525

Epoch: 6| Step: 6
Training loss: 0.7334611766814755
Validation loss: 2.624667156816311

Epoch: 6| Step: 7
Training loss: 1.0908935303734255
Validation loss: 2.5881974364498395

Epoch: 6| Step: 8
Training loss: 1.0296119627502882
Validation loss: 2.776635807772266

Epoch: 6| Step: 9
Training loss: 1.9273115967974412
Validation loss: 2.7195803767739606

Epoch: 6| Step: 10
Training loss: 0.7056447761068743
Validation loss: 2.7788167967536603

Epoch: 6| Step: 11
Training loss: 1.045390200613774
Validation loss: 2.7100711308256713

Epoch: 6| Step: 12
Training loss: 1.0197622687856553
Validation loss: 2.6674526489359485

Epoch: 6| Step: 13
Training loss: 1.1112850026645806
Validation loss: 2.7187916308478135

Epoch: 710| Step: 0
Training loss: 1.3516203145798198
Validation loss: 2.624875826030131

Epoch: 6| Step: 1
Training loss: 0.9597176663655117
Validation loss: 2.7691867706179436

Epoch: 6| Step: 2
Training loss: 1.0283090675949156
Validation loss: 2.712760191270644

Epoch: 6| Step: 3
Training loss: 1.9742416809223642
Validation loss: 2.616649679073038

Epoch: 6| Step: 4
Training loss: 0.8755391367296915
Validation loss: 2.6883793980601007

Epoch: 6| Step: 5
Training loss: 1.3078212450616977
Validation loss: 2.712437193753831

Epoch: 6| Step: 6
Training loss: 1.12120879642984
Validation loss: 2.6988131557633754

Epoch: 6| Step: 7
Training loss: 1.0125482759622746
Validation loss: 2.6228972156295423

Epoch: 6| Step: 8
Training loss: 0.6941309115149366
Validation loss: 2.7221057904058004

Epoch: 6| Step: 9
Training loss: 1.2759056278296288
Validation loss: 2.699980871906835

Epoch: 6| Step: 10
Training loss: 0.826621363946938
Validation loss: 2.6868679794433796

Epoch: 6| Step: 11
Training loss: 0.9137547292730472
Validation loss: 2.619961907586507

Epoch: 6| Step: 12
Training loss: 0.7766059172560836
Validation loss: 2.693880864872686

Epoch: 6| Step: 13
Training loss: 1.1717815107565086
Validation loss: 2.694112182827316

Epoch: 711| Step: 0
Training loss: 0.6226263989193696
Validation loss: 2.743483379856208

Epoch: 6| Step: 1
Training loss: 0.9546895240974509
Validation loss: 2.727576141688719

Epoch: 6| Step: 2
Training loss: 0.9685392150443077
Validation loss: 2.6953971118317313

Epoch: 6| Step: 3
Training loss: 0.9205276859436027
Validation loss: 2.748807868715652

Epoch: 6| Step: 4
Training loss: 1.3114213143906865
Validation loss: 2.7025746772786645

Epoch: 6| Step: 5
Training loss: 0.8729877494572961
Validation loss: 2.666700447705581

Epoch: 6| Step: 6
Training loss: 1.1342165959841335
Validation loss: 2.719437107477654

Epoch: 6| Step: 7
Training loss: 1.0616744705184862
Validation loss: 2.6776931034410216

Epoch: 6| Step: 8
Training loss: 1.0265481863664219
Validation loss: 2.606008419009698

Epoch: 6| Step: 9
Training loss: 1.1602127626571639
Validation loss: 2.6788729924594916

Epoch: 6| Step: 10
Training loss: 1.0334994318480237
Validation loss: 2.5986845300642036

Epoch: 6| Step: 11
Training loss: 1.8148010380251571
Validation loss: 2.723318316345868

Epoch: 6| Step: 12
Training loss: 1.0483178970178884
Validation loss: 2.762131576013447

Epoch: 6| Step: 13
Training loss: 1.4552051053549542
Validation loss: 2.694468281157734

Epoch: 712| Step: 0
Training loss: 0.8002275366855468
Validation loss: 2.6486833677086548

Epoch: 6| Step: 1
Training loss: 1.2799167674540823
Validation loss: 2.663994341952638

Epoch: 6| Step: 2
Training loss: 0.760422763190369
Validation loss: 2.7075807246687664

Epoch: 6| Step: 3
Training loss: 1.1321152744741019
Validation loss: 2.621632168105831

Epoch: 6| Step: 4
Training loss: 1.2400142444284654
Validation loss: 2.685065620922677

Epoch: 6| Step: 5
Training loss: 0.9906778941187846
Validation loss: 2.6267416567654505

Epoch: 6| Step: 6
Training loss: 1.1500448280387674
Validation loss: 2.7339148368320094

Epoch: 6| Step: 7
Training loss: 1.2095966914629974
Validation loss: 2.69070853831036

Epoch: 6| Step: 8
Training loss: 1.3395423661410062
Validation loss: 2.7903788048967284

Epoch: 6| Step: 9
Training loss: 1.1207329039740783
Validation loss: 2.6854334319346713

Epoch: 6| Step: 10
Training loss: 1.0937961023696143
Validation loss: 2.718573478123259

Epoch: 6| Step: 11
Training loss: 1.7180734169697238
Validation loss: 2.7066928795465044

Epoch: 6| Step: 12
Training loss: 0.9882622517203387
Validation loss: 2.6022313568877182

Epoch: 6| Step: 13
Training loss: 0.8565660519893333
Validation loss: 2.7793482230333355

Epoch: 713| Step: 0
Training loss: 0.747772046791166
Validation loss: 2.61228523370589

Epoch: 6| Step: 1
Training loss: 1.092617920419145
Validation loss: 2.7047275144074927

Epoch: 6| Step: 2
Training loss: 1.5690664785243902
Validation loss: 2.7591079838587143

Epoch: 6| Step: 3
Training loss: 1.1706381310389937
Validation loss: 2.674727094880784

Epoch: 6| Step: 4
Training loss: 0.9759724169374572
Validation loss: 2.647902354995828

Epoch: 6| Step: 5
Training loss: 0.9900199462345497
Validation loss: 2.768487593504159

Epoch: 6| Step: 6
Training loss: 1.807016628418978
Validation loss: 2.57712826371613

Epoch: 6| Step: 7
Training loss: 0.795817477549304
Validation loss: 2.645398441805508

Epoch: 6| Step: 8
Training loss: 0.885231821549537
Validation loss: 2.701401143230287

Epoch: 6| Step: 9
Training loss: 0.919122563292875
Validation loss: 2.7001971354008605

Epoch: 6| Step: 10
Training loss: 0.804730830831426
Validation loss: 2.5744353431420413

Epoch: 6| Step: 11
Training loss: 0.8046769817368543
Validation loss: 2.743434685375289

Epoch: 6| Step: 12
Training loss: 1.1826978761471507
Validation loss: 2.8032166838835284

Epoch: 6| Step: 13
Training loss: 1.3781976797440578
Validation loss: 2.6987663606899166

Epoch: 714| Step: 0
Training loss: 0.7691510805704799
Validation loss: 2.6875441595991534

Epoch: 6| Step: 1
Training loss: 1.024030615479295
Validation loss: 2.712134625308437

Epoch: 6| Step: 2
Training loss: 1.0982360394634956
Validation loss: 2.729583109783297

Epoch: 6| Step: 3
Training loss: 1.8256333153681237
Validation loss: 2.7147800388799954

Epoch: 6| Step: 4
Training loss: 1.0184291568401487
Validation loss: 2.6558153572589904

Epoch: 6| Step: 5
Training loss: 0.946987748436393
Validation loss: 2.693968533555472

Epoch: 6| Step: 6
Training loss: 1.0341778431876851
Validation loss: 2.6604037685060584

Epoch: 6| Step: 7
Training loss: 0.9574092196465082
Validation loss: 2.6927654732917077

Epoch: 6| Step: 8
Training loss: 0.9303039622659866
Validation loss: 2.6094996227489564

Epoch: 6| Step: 9
Training loss: 0.7952950466316884
Validation loss: 2.645355363273515

Epoch: 6| Step: 10
Training loss: 1.2814704891383455
Validation loss: 2.700694990021219

Epoch: 6| Step: 11
Training loss: 1.073778596348491
Validation loss: 2.700671339299332

Epoch: 6| Step: 12
Training loss: 1.0093041551606294
Validation loss: 2.6549947476287272

Epoch: 6| Step: 13
Training loss: 0.7927018641952706
Validation loss: 2.66945851952466

Epoch: 715| Step: 0
Training loss: 0.9775003736158667
Validation loss: 2.6444486916366823

Epoch: 6| Step: 1
Training loss: 2.084254696875834
Validation loss: 2.682686076490388

Epoch: 6| Step: 2
Training loss: 0.9092585512041815
Validation loss: 2.68576789359639

Epoch: 6| Step: 3
Training loss: 1.072970854986439
Validation loss: 2.6976063145544154

Epoch: 6| Step: 4
Training loss: 0.95337254795926
Validation loss: 2.7237785717830088

Epoch: 6| Step: 5
Training loss: 1.09528945485032
Validation loss: 2.646255206315624

Epoch: 6| Step: 6
Training loss: 1.0950837858360878
Validation loss: 2.7244685005143885

Epoch: 6| Step: 7
Training loss: 0.7842503726023213
Validation loss: 2.66638094258341

Epoch: 6| Step: 8
Training loss: 1.155098006148653
Validation loss: 2.7397461718827842

Epoch: 6| Step: 9
Training loss: 1.0125170765131386
Validation loss: 2.6254568967077154

Epoch: 6| Step: 10
Training loss: 0.874020095904052
Validation loss: 2.815224388780524

Epoch: 6| Step: 11
Training loss: 0.8201582990763571
Validation loss: 2.7345938214994154

Epoch: 6| Step: 12
Training loss: 1.4559371972477768
Validation loss: 2.6875448239884157

Epoch: 6| Step: 13
Training loss: 0.9318407591497327
Validation loss: 2.79712521938201

Epoch: 716| Step: 0
Training loss: 1.7388681171152953
Validation loss: 2.620927754705299

Epoch: 6| Step: 1
Training loss: 1.0754379289769989
Validation loss: 2.5910942703651423

Epoch: 6| Step: 2
Training loss: 1.057610368222331
Validation loss: 2.698229100582928

Epoch: 6| Step: 3
Training loss: 0.890989597045758
Validation loss: 2.8054966909400263

Epoch: 6| Step: 4
Training loss: 0.7923600439684279
Validation loss: 2.756141297298431

Epoch: 6| Step: 5
Training loss: 1.3211992885995372
Validation loss: 2.709897594057114

Epoch: 6| Step: 6
Training loss: 1.0476054589620536
Validation loss: 2.6482078246235377

Epoch: 6| Step: 7
Training loss: 0.794981070898934
Validation loss: 2.5785031565552265

Epoch: 6| Step: 8
Training loss: 0.9381730524675833
Validation loss: 2.718103809387975

Epoch: 6| Step: 9
Training loss: 1.355419322934828
Validation loss: 2.625988263948

Epoch: 6| Step: 10
Training loss: 1.1006761596851027
Validation loss: 2.6955448411335206

Epoch: 6| Step: 11
Training loss: 0.8094083580300989
Validation loss: 2.661556333520358

Epoch: 6| Step: 12
Training loss: 0.9097129495324487
Validation loss: 2.6410697557125045

Epoch: 6| Step: 13
Training loss: 1.2936604196983614
Validation loss: 2.6653859834323743

Epoch: 717| Step: 0
Training loss: 1.2356101508012889
Validation loss: 2.766141525874628

Epoch: 6| Step: 1
Training loss: 1.2638049755722311
Validation loss: 2.721976227730672

Epoch: 6| Step: 2
Training loss: 1.8162112551794607
Validation loss: 2.696005363989944

Epoch: 6| Step: 3
Training loss: 1.160387831671531
Validation loss: 2.706582401867768

Epoch: 6| Step: 4
Training loss: 0.6666286924593607
Validation loss: 2.6505912038475836

Epoch: 6| Step: 5
Training loss: 1.1165980137649683
Validation loss: 2.7648357773666086

Epoch: 6| Step: 6
Training loss: 1.0860831622673826
Validation loss: 2.6991572971945827

Epoch: 6| Step: 7
Training loss: 0.9030845870641477
Validation loss: 2.7412057937744545

Epoch: 6| Step: 8
Training loss: 1.1500613610856096
Validation loss: 2.7273762911170647

Epoch: 6| Step: 9
Training loss: 1.1501054134983468
Validation loss: 2.7015080710948087

Epoch: 6| Step: 10
Training loss: 0.9824330080891767
Validation loss: 2.67427209724565

Epoch: 6| Step: 11
Training loss: 0.8853360457273474
Validation loss: 2.6400526998989404

Epoch: 6| Step: 12
Training loss: 1.3196109510510243
Validation loss: 2.712969373227484

Epoch: 6| Step: 13
Training loss: 0.6982489738934848
Validation loss: 2.6311644712129416

Epoch: 718| Step: 0
Training loss: 0.7768103911954134
Validation loss: 2.723034633954518

Epoch: 6| Step: 1
Training loss: 0.6707097528093507
Validation loss: 2.603638222186091

Epoch: 6| Step: 2
Training loss: 1.1356866614691485
Validation loss: 2.613780529665675

Epoch: 6| Step: 3
Training loss: 1.241344525751477
Validation loss: 2.7053045187345304

Epoch: 6| Step: 4
Training loss: 0.8432022718759076
Validation loss: 2.704343521250933

Epoch: 6| Step: 5
Training loss: 0.98074868753906
Validation loss: 2.6216732749086162

Epoch: 6| Step: 6
Training loss: 1.0858547810397563
Validation loss: 2.6711977551507777

Epoch: 6| Step: 7
Training loss: 0.8509135091806033
Validation loss: 2.710256506785417

Epoch: 6| Step: 8
Training loss: 1.2174161311877443
Validation loss: 2.606056936726769

Epoch: 6| Step: 9
Training loss: 0.9097867878884323
Validation loss: 2.771162553082357

Epoch: 6| Step: 10
Training loss: 0.7507207109731916
Validation loss: 2.712242494898932

Epoch: 6| Step: 11
Training loss: 1.8065155810822648
Validation loss: 2.6790487446018116

Epoch: 6| Step: 12
Training loss: 1.0075979078252195
Validation loss: 2.6695131682393916

Epoch: 6| Step: 13
Training loss: 0.9678395823211323
Validation loss: 2.7035139862513637

Epoch: 719| Step: 0
Training loss: 1.2007806900807392
Validation loss: 2.756651885969419

Epoch: 6| Step: 1
Training loss: 1.402985025063587
Validation loss: 2.6654832473912826

Epoch: 6| Step: 2
Training loss: 1.00635559286202
Validation loss: 2.593619480597616

Epoch: 6| Step: 3
Training loss: 0.7359923955768112
Validation loss: 2.7161803246254856

Epoch: 6| Step: 4
Training loss: 1.0287879684690973
Validation loss: 2.674979769645849

Epoch: 6| Step: 5
Training loss: 1.0811069548255698
Validation loss: 2.578323412308296

Epoch: 6| Step: 6
Training loss: 0.9742214371094282
Validation loss: 2.728730966719961

Epoch: 6| Step: 7
Training loss: 1.0185407013998116
Validation loss: 2.7585986620187897

Epoch: 6| Step: 8
Training loss: 0.6437035534593355
Validation loss: 2.665291560149222

Epoch: 6| Step: 9
Training loss: 1.3062818459457222
Validation loss: 2.7372770645617273

Epoch: 6| Step: 10
Training loss: 2.037050504190388
Validation loss: 2.702658021181169

Epoch: 6| Step: 11
Training loss: 0.8303648689016061
Validation loss: 2.674454488823244

Epoch: 6| Step: 12
Training loss: 1.014847443113589
Validation loss: 2.732620708761617

Epoch: 6| Step: 13
Training loss: 1.0510007494298583
Validation loss: 2.626266312735235

Epoch: 720| Step: 0
Training loss: 0.8318730235201702
Validation loss: 2.6426179135551484

Epoch: 6| Step: 1
Training loss: 1.138683966806375
Validation loss: 2.643524581781574

Epoch: 6| Step: 2
Training loss: 1.733344932052735
Validation loss: 2.723021470365058

Epoch: 6| Step: 3
Training loss: 0.9392566435789377
Validation loss: 2.6540350348976434

Epoch: 6| Step: 4
Training loss: 0.7564625858981249
Validation loss: 2.7347585326500203

Epoch: 6| Step: 5
Training loss: 0.9887652813855426
Validation loss: 2.724109540445313

Epoch: 6| Step: 6
Training loss: 1.0728441911434081
Validation loss: 2.779457166125076

Epoch: 6| Step: 7
Training loss: 1.2305020282423285
Validation loss: 2.6284882913932024

Epoch: 6| Step: 8
Training loss: 1.08083759667804
Validation loss: 2.7011496976490506

Epoch: 6| Step: 9
Training loss: 1.2508277060026132
Validation loss: 2.6762282088419265

Epoch: 6| Step: 10
Training loss: 1.1078015842088267
Validation loss: 2.619355410141324

Epoch: 6| Step: 11
Training loss: 0.8909066072939825
Validation loss: 2.700539630939139

Epoch: 6| Step: 12
Training loss: 1.2347269642904155
Validation loss: 2.675029273223254

Epoch: 6| Step: 13
Training loss: 1.1025749045290987
Validation loss: 2.6035066623892114

Epoch: 721| Step: 0
Training loss: 1.340152849404556
Validation loss: 2.7974094217828678

Epoch: 6| Step: 1
Training loss: 1.9276419233822666
Validation loss: 2.685101038643289

Epoch: 6| Step: 2
Training loss: 0.9193351802332498
Validation loss: 2.6219913372619033

Epoch: 6| Step: 3
Training loss: 1.4425975146463812
Validation loss: 2.6775648079038716

Epoch: 6| Step: 4
Training loss: 1.0940395516911958
Validation loss: 2.710344010889221

Epoch: 6| Step: 5
Training loss: 1.0623681042653088
Validation loss: 2.630338584252061

Epoch: 6| Step: 6
Training loss: 1.0036563784974581
Validation loss: 2.6290110166904386

Epoch: 6| Step: 7
Training loss: 0.8171850988524191
Validation loss: 2.6498708662168178

Epoch: 6| Step: 8
Training loss: 1.1489827944012647
Validation loss: 2.630524815334811

Epoch: 6| Step: 9
Training loss: 1.3589840469294165
Validation loss: 2.6734061549112815

Epoch: 6| Step: 10
Training loss: 0.6460152851693878
Validation loss: 2.700283319229978

Epoch: 6| Step: 11
Training loss: 0.9863288501699067
Validation loss: 2.7025875667156076

Epoch: 6| Step: 12
Training loss: 0.8569892365303842
Validation loss: 2.701607167950026

Epoch: 6| Step: 13
Training loss: 0.7909592219836064
Validation loss: 2.6271616575325827

Epoch: 722| Step: 0
Training loss: 1.1530628094533948
Validation loss: 2.6591489045033967

Epoch: 6| Step: 1
Training loss: 0.8724795211203084
Validation loss: 2.7725754956528426

Epoch: 6| Step: 2
Training loss: 0.9448766412903669
Validation loss: 2.7796258704357824

Epoch: 6| Step: 3
Training loss: 1.1475590051178417
Validation loss: 2.66821398438473

Epoch: 6| Step: 4
Training loss: 1.1254974960645008
Validation loss: 2.7387310286712103

Epoch: 6| Step: 5
Training loss: 0.951561317380474
Validation loss: 2.732528744832071

Epoch: 6| Step: 6
Training loss: 0.9774232961604541
Validation loss: 2.686583440670164

Epoch: 6| Step: 7
Training loss: 1.1989478386166392
Validation loss: 2.6941743597012007

Epoch: 6| Step: 8
Training loss: 1.8293624341589845
Validation loss: 2.6984131951973764

Epoch: 6| Step: 9
Training loss: 0.6634755626151002
Validation loss: 2.7417716298858497

Epoch: 6| Step: 10
Training loss: 0.995967064075456
Validation loss: 2.693563963762938

Epoch: 6| Step: 11
Training loss: 0.8430783813007864
Validation loss: 2.6172387392516443

Epoch: 6| Step: 12
Training loss: 1.3379988355104087
Validation loss: 2.6725102597558883

Epoch: 6| Step: 13
Training loss: 1.346186668656086
Validation loss: 2.6574807545933377

Epoch: 723| Step: 0
Training loss: 1.3488126796409248
Validation loss: 2.7138658432700598

Epoch: 6| Step: 1
Training loss: 1.333419747333883
Validation loss: 2.687924472934851

Epoch: 6| Step: 2
Training loss: 0.950120317218464
Validation loss: 2.7004796758533383

Epoch: 6| Step: 3
Training loss: 0.9849501246687682
Validation loss: 2.6498371413592277

Epoch: 6| Step: 4
Training loss: 0.46932479267326094
Validation loss: 2.7316322843258365

Epoch: 6| Step: 5
Training loss: 0.504872777606694
Validation loss: 2.7368754805573747

Epoch: 6| Step: 6
Training loss: 0.773916808837481
Validation loss: 2.611550449791361

Epoch: 6| Step: 7
Training loss: 0.9773721009311597
Validation loss: 2.765950149472599

Epoch: 6| Step: 8
Training loss: 1.599765569678785
Validation loss: 2.7004613926858783

Epoch: 6| Step: 9
Training loss: 1.0791228831674862
Validation loss: 2.7425788689159045

Epoch: 6| Step: 10
Training loss: 1.7177018177224281
Validation loss: 2.6949504973603773

Epoch: 6| Step: 11
Training loss: 0.7543926745148065
Validation loss: 2.6974079800556923

Epoch: 6| Step: 12
Training loss: 1.1000491629798166
Validation loss: 2.7074659285287095

Epoch: 6| Step: 13
Training loss: 1.0226851165637403
Validation loss: 2.769134763859057

Epoch: 724| Step: 0
Training loss: 1.402353398281899
Validation loss: 2.693870626015291

Epoch: 6| Step: 1
Training loss: 1.1568684856905296
Validation loss: 2.597847752895073

Epoch: 6| Step: 2
Training loss: 1.0476410753031562
Validation loss: 2.731010579364898

Epoch: 6| Step: 3
Training loss: 0.6812621981727367
Validation loss: 2.8004391536060065

Epoch: 6| Step: 4
Training loss: 1.231391972136061
Validation loss: 2.6500452197584203

Epoch: 6| Step: 5
Training loss: 0.9770948866192989
Validation loss: 2.7490671856001083

Epoch: 6| Step: 6
Training loss: 0.9350946723212646
Validation loss: 2.6943543374005623

Epoch: 6| Step: 7
Training loss: 1.169212419145332
Validation loss: 2.7443784268913447

Epoch: 6| Step: 8
Training loss: 1.0891833201397298
Validation loss: 2.7566831471858855

Epoch: 6| Step: 9
Training loss: 0.8146899494211873
Validation loss: 2.790720838336407

Epoch: 6| Step: 10
Training loss: 0.7316312464465808
Validation loss: 2.639383535723404

Epoch: 6| Step: 11
Training loss: 1.7741669486448615
Validation loss: 2.707940379017991

Epoch: 6| Step: 12
Training loss: 0.9242463727678151
Validation loss: 2.566033643883751

Epoch: 6| Step: 13
Training loss: 1.5490336143535481
Validation loss: 2.717815158768378

Epoch: 725| Step: 0
Training loss: 0.9639737921511901
Validation loss: 2.7590952562559434

Epoch: 6| Step: 1
Training loss: 0.9451096056897953
Validation loss: 2.7382213816587964

Epoch: 6| Step: 2
Training loss: 1.2825692990562787
Validation loss: 2.6719852365520413

Epoch: 6| Step: 3
Training loss: 0.8947826848376801
Validation loss: 2.6790917933051643

Epoch: 6| Step: 4
Training loss: 0.837275708468771
Validation loss: 2.595289953091064

Epoch: 6| Step: 5
Training loss: 1.0913668145473654
Validation loss: 2.6632652861738007

Epoch: 6| Step: 6
Training loss: 0.7136131909760297
Validation loss: 2.74902000752701

Epoch: 6| Step: 7
Training loss: 1.0864572721910766
Validation loss: 2.6458321195804237

Epoch: 6| Step: 8
Training loss: 1.7274688827207374
Validation loss: 2.7090034987231126

Epoch: 6| Step: 9
Training loss: 1.0272810304011546
Validation loss: 2.6661002713813793

Epoch: 6| Step: 10
Training loss: 1.0308268863925591
Validation loss: 2.6564214053940263

Epoch: 6| Step: 11
Training loss: 1.20885125384075
Validation loss: 2.764526427087511

Epoch: 6| Step: 12
Training loss: 1.1177607846048017
Validation loss: 2.7299420713480753

Epoch: 6| Step: 13
Training loss: 1.4667986629795196
Validation loss: 2.6418783547391658

Epoch: 726| Step: 0
Training loss: 0.7214936673526867
Validation loss: 2.74559200953711

Epoch: 6| Step: 1
Training loss: 1.8111519239789875
Validation loss: 2.7132592064358954

Epoch: 6| Step: 2
Training loss: 1.2296403306302224
Validation loss: 2.754735832671432

Epoch: 6| Step: 3
Training loss: 0.7545735464684866
Validation loss: 2.6547421141543155

Epoch: 6| Step: 4
Training loss: 1.0414792400860482
Validation loss: 2.7613430097999077

Epoch: 6| Step: 5
Training loss: 0.9511819012561917
Validation loss: 2.6465894125716742

Epoch: 6| Step: 6
Training loss: 0.7950607291004654
Validation loss: 2.6205243983752258

Epoch: 6| Step: 7
Training loss: 1.016957743724267
Validation loss: 2.7862544499904063

Epoch: 6| Step: 8
Training loss: 1.036183664294667
Validation loss: 2.6685754196180236

Epoch: 6| Step: 9
Training loss: 1.1674412074999987
Validation loss: 2.7633384733942576

Epoch: 6| Step: 10
Training loss: 0.7507035611195348
Validation loss: 2.7254058681645557

Epoch: 6| Step: 11
Training loss: 1.2113087730990069
Validation loss: 2.734715108741504

Epoch: 6| Step: 12
Training loss: 1.0173306154983066
Validation loss: 2.7702704443930073

Epoch: 6| Step: 13
Training loss: 1.1665378340477306
Validation loss: 2.680943832473654

Epoch: 727| Step: 0
Training loss: 1.0596792138736695
Validation loss: 2.6814294445753886

Epoch: 6| Step: 1
Training loss: 1.4873296143214434
Validation loss: 2.674457107623757

Epoch: 6| Step: 2
Training loss: 0.9936183314395386
Validation loss: 2.670483547143737

Epoch: 6| Step: 3
Training loss: 0.7896680113814651
Validation loss: 2.791193092839984

Epoch: 6| Step: 4
Training loss: 1.0844174731288785
Validation loss: 2.713421027185503

Epoch: 6| Step: 5
Training loss: 0.9177515949930595
Validation loss: 2.679944030925414

Epoch: 6| Step: 6
Training loss: 0.7333541836447659
Validation loss: 2.722046413929376

Epoch: 6| Step: 7
Training loss: 0.8208901324363709
Validation loss: 2.6888115437738542

Epoch: 6| Step: 8
Training loss: 0.9857275616895008
Validation loss: 2.705894590147196

Epoch: 6| Step: 9
Training loss: 0.7607087702138656
Validation loss: 2.6413816797573357

Epoch: 6| Step: 10
Training loss: 1.0381636209211031
Validation loss: 2.6978427124403295

Epoch: 6| Step: 11
Training loss: 1.89002413698961
Validation loss: 2.596878392972154

Epoch: 6| Step: 12
Training loss: 1.0315909544525628
Validation loss: 2.6435243024845527

Epoch: 6| Step: 13
Training loss: 1.2823409111592992
Validation loss: 2.68571522604348

Epoch: 728| Step: 0
Training loss: 1.3078984021558933
Validation loss: 2.731655836854629

Epoch: 6| Step: 1
Training loss: 1.7788858619429626
Validation loss: 2.7334508278107434

Epoch: 6| Step: 2
Training loss: 1.1670322810352474
Validation loss: 2.7330902672337047

Epoch: 6| Step: 3
Training loss: 0.9312036157103603
Validation loss: 2.67943415835462

Epoch: 6| Step: 4
Training loss: 1.3011306889021435
Validation loss: 2.665288112836321

Epoch: 6| Step: 5
Training loss: 0.8365477357800564
Validation loss: 2.775795256562252

Epoch: 6| Step: 6
Training loss: 1.0494547699899985
Validation loss: 2.750506720744853

Epoch: 6| Step: 7
Training loss: 1.006557540810279
Validation loss: 2.6942389681953594

Epoch: 6| Step: 8
Training loss: 0.9441220377559042
Validation loss: 2.706594629081759

Epoch: 6| Step: 9
Training loss: 0.6006068776519705
Validation loss: 2.73234334400641

Epoch: 6| Step: 10
Training loss: 1.036235779042326
Validation loss: 2.7455168563448393

Epoch: 6| Step: 11
Training loss: 1.0789011497294139
Validation loss: 2.6864646277490136

Epoch: 6| Step: 12
Training loss: 1.005572646670813
Validation loss: 2.669366820395584

Epoch: 6| Step: 13
Training loss: 0.9435656462222297
Validation loss: 2.707423232030854

Epoch: 729| Step: 0
Training loss: 0.9526476368163589
Validation loss: 2.6910349383782513

Epoch: 6| Step: 1
Training loss: 1.668735086895888
Validation loss: 2.6415169899757682

Epoch: 6| Step: 2
Training loss: 0.8516007861008785
Validation loss: 2.709003663386413

Epoch: 6| Step: 3
Training loss: 0.9451701159476237
Validation loss: 2.620038818751888

Epoch: 6| Step: 4
Training loss: 0.8456923063436368
Validation loss: 2.7641809789801175

Epoch: 6| Step: 5
Training loss: 1.007791385873029
Validation loss: 2.6370671353934494

Epoch: 6| Step: 6
Training loss: 1.0850881644435528
Validation loss: 2.7601198123086115

Epoch: 6| Step: 7
Training loss: 0.7406471329613126
Validation loss: 2.707481414678412

Epoch: 6| Step: 8
Training loss: 0.9229534758955094
Validation loss: 2.65373313708913

Epoch: 6| Step: 9
Training loss: 1.2289421663170976
Validation loss: 2.626779276523015

Epoch: 6| Step: 10
Training loss: 1.1119864982464533
Validation loss: 2.748937483586

Epoch: 6| Step: 11
Training loss: 0.9183328109527413
Validation loss: 2.6365450038505704

Epoch: 6| Step: 12
Training loss: 1.0951366898385526
Validation loss: 2.757928551550828

Epoch: 6| Step: 13
Training loss: 0.8453474464173516
Validation loss: 2.768384278757125

Epoch: 730| Step: 0
Training loss: 0.6770579675666932
Validation loss: 2.5978210767015235

Epoch: 6| Step: 1
Training loss: 1.1283907653883727
Validation loss: 2.641618962308597

Epoch: 6| Step: 2
Training loss: 0.8849317382090399
Validation loss: 2.720561716546601

Epoch: 6| Step: 3
Training loss: 0.9036739502562495
Validation loss: 2.771627936891748

Epoch: 6| Step: 4
Training loss: 0.6817541601727651
Validation loss: 2.690853302906295

Epoch: 6| Step: 5
Training loss: 0.8998053711146877
Validation loss: 2.6600788295463045

Epoch: 6| Step: 6
Training loss: 1.1218349651535817
Validation loss: 2.579692807115125

Epoch: 6| Step: 7
Training loss: 1.1134239239203616
Validation loss: 2.553457388897064

Epoch: 6| Step: 8
Training loss: 1.2025314452249307
Validation loss: 2.625872470426338

Epoch: 6| Step: 9
Training loss: 1.0454956190801021
Validation loss: 2.6459065715357943

Epoch: 6| Step: 10
Training loss: 0.9307123834128189
Validation loss: 2.635691014220949

Epoch: 6| Step: 11
Training loss: 1.2852945920001346
Validation loss: 2.7129013959163384

Epoch: 6| Step: 12
Training loss: 1.7662078435554982
Validation loss: 2.6520377117922234

Epoch: 6| Step: 13
Training loss: 1.0955370336842871
Validation loss: 2.6445048261172293

Epoch: 731| Step: 0
Training loss: 1.0332708498819165
Validation loss: 2.7010033037728323

Epoch: 6| Step: 1
Training loss: 0.8968622080458889
Validation loss: 2.682283373799075

Epoch: 6| Step: 2
Training loss: 0.7913932746508898
Validation loss: 2.6686823476176293

Epoch: 6| Step: 3
Training loss: 0.8943213670538809
Validation loss: 2.700264830611286

Epoch: 6| Step: 4
Training loss: 0.9172165406290733
Validation loss: 2.648338362236759

Epoch: 6| Step: 5
Training loss: 1.3613733533135286
Validation loss: 2.710034537697504

Epoch: 6| Step: 6
Training loss: 0.923878835693622
Validation loss: 2.7827277281866443

Epoch: 6| Step: 7
Training loss: 0.9690331076132088
Validation loss: 2.557875384148466

Epoch: 6| Step: 8
Training loss: 1.282030937571374
Validation loss: 2.646049392504588

Epoch: 6| Step: 9
Training loss: 0.7919639648225503
Validation loss: 2.73018404526301

Epoch: 6| Step: 10
Training loss: 1.0954116188727197
Validation loss: 2.62637872033147

Epoch: 6| Step: 11
Training loss: 1.9051701973806825
Validation loss: 2.739281152998637

Epoch: 6| Step: 12
Training loss: 1.1073667589899996
Validation loss: 2.634477107325304

Epoch: 6| Step: 13
Training loss: 1.0838192925746013
Validation loss: 2.679436961731262

Epoch: 732| Step: 0
Training loss: 0.8040171673683179
Validation loss: 2.713920592470571

Epoch: 6| Step: 1
Training loss: 1.243858940299149
Validation loss: 2.7193262510030847

Epoch: 6| Step: 2
Training loss: 0.8220234421382983
Validation loss: 2.6432321862547474

Epoch: 6| Step: 3
Training loss: 1.8319883687220655
Validation loss: 2.7474645820153274

Epoch: 6| Step: 4
Training loss: 1.0217023511154812
Validation loss: 2.68353207885975

Epoch: 6| Step: 5
Training loss: 1.0923021815699292
Validation loss: 2.6585552107808414

Epoch: 6| Step: 6
Training loss: 1.1417360512098775
Validation loss: 2.7324354117513363

Epoch: 6| Step: 7
Training loss: 0.8932033494308271
Validation loss: 2.705309330819632

Epoch: 6| Step: 8
Training loss: 1.1297032799680493
Validation loss: 2.723335398328828

Epoch: 6| Step: 9
Training loss: 0.8902251031785295
Validation loss: 2.6441935056089694

Epoch: 6| Step: 10
Training loss: 1.2837808315954002
Validation loss: 2.6472442578590263

Epoch: 6| Step: 11
Training loss: 0.8001113694872506
Validation loss: 2.7276364908676247

Epoch: 6| Step: 12
Training loss: 0.8792301513626831
Validation loss: 2.6208871996283594

Epoch: 6| Step: 13
Training loss: 1.0285268722829057
Validation loss: 2.7998334964418157

Epoch: 733| Step: 0
Training loss: 1.1266848345614067
Validation loss: 2.7282038219740867

Epoch: 6| Step: 1
Training loss: 0.886743755240078
Validation loss: 2.733167452346971

Epoch: 6| Step: 2
Training loss: 0.6309712786085144
Validation loss: 2.5728194558950546

Epoch: 6| Step: 3
Training loss: 0.9220932524351989
Validation loss: 2.712999842264579

Epoch: 6| Step: 4
Training loss: 1.1344003532666032
Validation loss: 2.6641681320490886

Epoch: 6| Step: 5
Training loss: 1.049919711176813
Validation loss: 2.6944764426477836

Epoch: 6| Step: 6
Training loss: 0.9160969582178947
Validation loss: 2.693945075011072

Epoch: 6| Step: 7
Training loss: 0.7693527324438334
Validation loss: 2.761124683361983

Epoch: 6| Step: 8
Training loss: 1.0029976737241686
Validation loss: 2.694007045436232

Epoch: 6| Step: 9
Training loss: 1.1077901776086485
Validation loss: 2.7179320050961375

Epoch: 6| Step: 10
Training loss: 0.9462076787920447
Validation loss: 2.7196811358740303

Epoch: 6| Step: 11
Training loss: 1.042509342124301
Validation loss: 2.7002638147494475

Epoch: 6| Step: 12
Training loss: 1.9562337320157126
Validation loss: 2.654490321970856

Epoch: 6| Step: 13
Training loss: 0.9719025169475772
Validation loss: 2.683928575597064

Epoch: 734| Step: 0
Training loss: 1.3028088595530924
Validation loss: 2.7418263856716787

Epoch: 6| Step: 1
Training loss: 1.9268860037183526
Validation loss: 2.7615220763261927

Epoch: 6| Step: 2
Training loss: 1.0819304381413273
Validation loss: 2.7120213453320567

Epoch: 6| Step: 3
Training loss: 0.9550760031210452
Validation loss: 2.591510550685455

Epoch: 6| Step: 4
Training loss: 0.7900497756439117
Validation loss: 2.660890228212108

Epoch: 6| Step: 5
Training loss: 1.1821704527886032
Validation loss: 2.641608411219644

Epoch: 6| Step: 6
Training loss: 0.7558271613144166
Validation loss: 2.6324649237026714

Epoch: 6| Step: 7
Training loss: 0.990055376536667
Validation loss: 2.6536304999506095

Epoch: 6| Step: 8
Training loss: 0.8526810465557778
Validation loss: 2.6819207270789356

Epoch: 6| Step: 9
Training loss: 0.9037055766266324
Validation loss: 2.5959464986650045

Epoch: 6| Step: 10
Training loss: 1.0129347162326727
Validation loss: 2.7542798530914445

Epoch: 6| Step: 11
Training loss: 1.3702639163374934
Validation loss: 2.6876265259225187

Epoch: 6| Step: 12
Training loss: 1.018647494161474
Validation loss: 2.6725461191703683

Epoch: 6| Step: 13
Training loss: 1.068031051370078
Validation loss: 2.666238628503756

Epoch: 735| Step: 0
Training loss: 0.965165242984938
Validation loss: 2.6840016957040738

Epoch: 6| Step: 1
Training loss: 0.8169697546198905
Validation loss: 2.675019545853157

Epoch: 6| Step: 2
Training loss: 1.2335586745800102
Validation loss: 2.665896893603654

Epoch: 6| Step: 3
Training loss: 1.3716157533568092
Validation loss: 2.7182717247384134

Epoch: 6| Step: 4
Training loss: 0.8115259347227672
Validation loss: 2.7171483416913107

Epoch: 6| Step: 5
Training loss: 1.9464475698281327
Validation loss: 2.6878671378652204

Epoch: 6| Step: 6
Training loss: 0.8525363707964202
Validation loss: 2.741289828882712

Epoch: 6| Step: 7
Training loss: 0.6369247571321621
Validation loss: 2.6927285926231104

Epoch: 6| Step: 8
Training loss: 0.8235845069026437
Validation loss: 2.76799331688452

Epoch: 6| Step: 9
Training loss: 0.8155655616353737
Validation loss: 2.6801419149817436

Epoch: 6| Step: 10
Training loss: 0.9707824858800812
Validation loss: 2.7130276897051173

Epoch: 6| Step: 11
Training loss: 1.270191807192288
Validation loss: 2.651360393962588

Epoch: 6| Step: 12
Training loss: 0.9286331481124251
Validation loss: 2.6913047876299556

Epoch: 6| Step: 13
Training loss: 0.77299120578723
Validation loss: 2.725619257459996

Epoch: 736| Step: 0
Training loss: 1.0464548435009962
Validation loss: 2.7074313180132217

Epoch: 6| Step: 1
Training loss: 1.013136294076649
Validation loss: 2.7298886971372847

Epoch: 6| Step: 2
Training loss: 0.7010204183486248
Validation loss: 2.7522868103886995

Epoch: 6| Step: 3
Training loss: 0.7273758468347665
Validation loss: 2.5762270745866167

Epoch: 6| Step: 4
Training loss: 1.3713021839960944
Validation loss: 2.6183427127475283

Epoch: 6| Step: 5
Training loss: 1.290970101758613
Validation loss: 2.619461990156779

Epoch: 6| Step: 6
Training loss: 0.6889170651053054
Validation loss: 2.695068055336818

Epoch: 6| Step: 7
Training loss: 1.0788136369979768
Validation loss: 2.7091416079695576

Epoch: 6| Step: 8
Training loss: 0.6892937754336851
Validation loss: 2.6558585663292074

Epoch: 6| Step: 9
Training loss: 1.0133408904630385
Validation loss: 2.797035083003705

Epoch: 6| Step: 10
Training loss: 1.9286299676437433
Validation loss: 2.54933412871222

Epoch: 6| Step: 11
Training loss: 0.9832328649424985
Validation loss: 2.745955022423717

Epoch: 6| Step: 12
Training loss: 1.0084435904466422
Validation loss: 2.6832143730321563

Epoch: 6| Step: 13
Training loss: 1.4996169713854632
Validation loss: 2.715866133142017

Epoch: 737| Step: 0
Training loss: 0.7868449711239621
Validation loss: 2.6495873508209047

Epoch: 6| Step: 1
Training loss: 1.051166336232098
Validation loss: 2.716723561806254

Epoch: 6| Step: 2
Training loss: 0.8707650766285904
Validation loss: 2.7705875342910065

Epoch: 6| Step: 3
Training loss: 1.8778097716483224
Validation loss: 2.684568788393294

Epoch: 6| Step: 4
Training loss: 1.2314633179814718
Validation loss: 2.7480339021241917

Epoch: 6| Step: 5
Training loss: 1.0115556622292645
Validation loss: 2.774423753705213

Epoch: 6| Step: 6
Training loss: 1.1629236782349632
Validation loss: 2.657089641168832

Epoch: 6| Step: 7
Training loss: 0.7565493330189865
Validation loss: 2.6996556446046283

Epoch: 6| Step: 8
Training loss: 0.5266870153344997
Validation loss: 2.649593321640675

Epoch: 6| Step: 9
Training loss: 0.8608184482903775
Validation loss: 2.7186027338927885

Epoch: 6| Step: 10
Training loss: 0.9040973022914351
Validation loss: 2.645164557024011

Epoch: 6| Step: 11
Training loss: 1.058488284554786
Validation loss: 2.782068324593108

Epoch: 6| Step: 12
Training loss: 0.9872554838482736
Validation loss: 2.7665064636215337

Epoch: 6| Step: 13
Training loss: 0.9261901853658775
Validation loss: 2.7264236897677465

Epoch: 738| Step: 0
Training loss: 0.9673809098475888
Validation loss: 2.588828712807191

Epoch: 6| Step: 1
Training loss: 0.611008923348355
Validation loss: 2.6178927102501315

Epoch: 6| Step: 2
Training loss: 0.8229343476790264
Validation loss: 2.7251108940073703

Epoch: 6| Step: 3
Training loss: 0.8747104438152143
Validation loss: 2.6742809156794016

Epoch: 6| Step: 4
Training loss: 1.2476547652052403
Validation loss: 2.6566443201887084

Epoch: 6| Step: 5
Training loss: 1.058012630401678
Validation loss: 2.6660461979352252

Epoch: 6| Step: 6
Training loss: 0.8390536472983037
Validation loss: 2.640287232669619

Epoch: 6| Step: 7
Training loss: 0.8498847602814554
Validation loss: 2.6126114333756427

Epoch: 6| Step: 8
Training loss: 0.7012240462166692
Validation loss: 2.627605611939639

Epoch: 6| Step: 9
Training loss: 0.9157127416447646
Validation loss: 2.672063194698895

Epoch: 6| Step: 10
Training loss: 1.95317425475003
Validation loss: 2.725149280929379

Epoch: 6| Step: 11
Training loss: 1.3487672952810514
Validation loss: 2.6711123201390037

Epoch: 6| Step: 12
Training loss: 0.8749215567712813
Validation loss: 2.77275504798011

Epoch: 6| Step: 13
Training loss: 0.9527471450006154
Validation loss: 2.7294440258085166

Epoch: 739| Step: 0
Training loss: 1.1556939514947218
Validation loss: 2.695459513959545

Epoch: 6| Step: 1
Training loss: 0.9842247621237867
Validation loss: 2.770805261287621

Epoch: 6| Step: 2
Training loss: 0.5864364025923279
Validation loss: 2.7489366759600977

Epoch: 6| Step: 3
Training loss: 1.140181468273306
Validation loss: 2.726531125676874

Epoch: 6| Step: 4
Training loss: 1.0452222160728741
Validation loss: 2.6931532942825998

Epoch: 6| Step: 5
Training loss: 0.9581343540996646
Validation loss: 2.7132115918637925

Epoch: 6| Step: 6
Training loss: 1.0625849297182697
Validation loss: 2.7061444419363316

Epoch: 6| Step: 7
Training loss: 1.0304373226622587
Validation loss: 2.6693245085155

Epoch: 6| Step: 8
Training loss: 1.8173144623347348
Validation loss: 2.733496555496672

Epoch: 6| Step: 9
Training loss: 1.256949798240055
Validation loss: 2.6878169741603695

Epoch: 6| Step: 10
Training loss: 0.8133314719986593
Validation loss: 2.760261960066096

Epoch: 6| Step: 11
Training loss: 1.1527314132088773
Validation loss: 2.7233221533530245

Epoch: 6| Step: 12
Training loss: 0.8427901282928629
Validation loss: 2.6632303794335344

Epoch: 6| Step: 13
Training loss: 0.8228347874399923
Validation loss: 2.596594790212482

Epoch: 740| Step: 0
Training loss: 0.8345934321198323
Validation loss: 2.6712044387334575

Epoch: 6| Step: 1
Training loss: 1.143203798793223
Validation loss: 2.6701642301885204

Epoch: 6| Step: 2
Training loss: 0.8607056805836824
Validation loss: 2.674568673620785

Epoch: 6| Step: 3
Training loss: 0.8714651846899442
Validation loss: 2.6803778130507263

Epoch: 6| Step: 4
Training loss: 0.9766429105078442
Validation loss: 2.6770984746109696

Epoch: 6| Step: 5
Training loss: 1.065120998457873
Validation loss: 2.6574614544864477

Epoch: 6| Step: 6
Training loss: 1.0657065754651343
Validation loss: 2.6298336191403537

Epoch: 6| Step: 7
Training loss: 1.6534180812239714
Validation loss: 2.739518331892529

Epoch: 6| Step: 8
Training loss: 1.2548503233269923
Validation loss: 2.736238757275158

Epoch: 6| Step: 9
Training loss: 1.0856054882520845
Validation loss: 2.7062689992078646

Epoch: 6| Step: 10
Training loss: 1.3177635824610419
Validation loss: 2.704884546524423

Epoch: 6| Step: 11
Training loss: 0.7507360343536053
Validation loss: 2.6500437164260817

Epoch: 6| Step: 12
Training loss: 0.6084986033270801
Validation loss: 2.661312603942681

Epoch: 6| Step: 13
Training loss: 0.8387678840311025
Validation loss: 2.6437124130132057

Epoch: 741| Step: 0
Training loss: 0.893204517228286
Validation loss: 2.7188910406593996

Epoch: 6| Step: 1
Training loss: 0.989506982903035
Validation loss: 2.7273917765408724

Epoch: 6| Step: 2
Training loss: 0.8719620418511342
Validation loss: 2.652363682257475

Epoch: 6| Step: 3
Training loss: 0.971404254157176
Validation loss: 2.7551414143083126

Epoch: 6| Step: 4
Training loss: 1.3071965744064717
Validation loss: 2.663834019751773

Epoch: 6| Step: 5
Training loss: 1.0545462054516024
Validation loss: 2.7507706995033434

Epoch: 6| Step: 6
Training loss: 1.7067129855402157
Validation loss: 2.5954499350487636

Epoch: 6| Step: 7
Training loss: 1.0087871717673471
Validation loss: 2.759630233236967

Epoch: 6| Step: 8
Training loss: 1.045293210796751
Validation loss: 2.625836275788032

Epoch: 6| Step: 9
Training loss: 0.8104737030460412
Validation loss: 2.6597757064125647

Epoch: 6| Step: 10
Training loss: 0.9802148801859943
Validation loss: 2.7753533569705553

Epoch: 6| Step: 11
Training loss: 0.8630990919330918
Validation loss: 2.6403219465735983

Epoch: 6| Step: 12
Training loss: 0.9522905292614076
Validation loss: 2.7002332675104834

Epoch: 6| Step: 13
Training loss: 0.9076771843758824
Validation loss: 2.6330754535316414

Epoch: 742| Step: 0
Training loss: 0.5848668298185312
Validation loss: 2.700363057898997

Epoch: 6| Step: 1
Training loss: 1.833729946700314
Validation loss: 2.667229295669085

Epoch: 6| Step: 2
Training loss: 0.7109894785900643
Validation loss: 2.628145620890858

Epoch: 6| Step: 3
Training loss: 1.508204908155026
Validation loss: 2.6726916094976945

Epoch: 6| Step: 4
Training loss: 0.9384058708376384
Validation loss: 2.621284893211148

Epoch: 6| Step: 5
Training loss: 1.1002622465159833
Validation loss: 2.5830016361521504

Epoch: 6| Step: 6
Training loss: 0.7809747974148943
Validation loss: 2.68926239558682

Epoch: 6| Step: 7
Training loss: 1.0592910890908631
Validation loss: 2.6598882554180796

Epoch: 6| Step: 8
Training loss: 1.042881079714457
Validation loss: 2.6235267853072712

Epoch: 6| Step: 9
Training loss: 0.9589583321509955
Validation loss: 2.6202417432822362

Epoch: 6| Step: 10
Training loss: 0.8023443086468053
Validation loss: 2.7939704262803335

Epoch: 6| Step: 11
Training loss: 0.8734635419153615
Validation loss: 2.6866499273505986

Epoch: 6| Step: 12
Training loss: 1.0633941702544625
Validation loss: 2.6558486471186367

Epoch: 6| Step: 13
Training loss: 1.0197864081637154
Validation loss: 2.67330624186777

Epoch: 743| Step: 0
Training loss: 1.3133628370550166
Validation loss: 2.6437545040133656

Epoch: 6| Step: 1
Training loss: 0.8917526334398044
Validation loss: 2.7667719411286114

Epoch: 6| Step: 2
Training loss: 0.7258086857368239
Validation loss: 2.682592250677118

Epoch: 6| Step: 3
Training loss: 0.733281640557267
Validation loss: 2.693785640759716

Epoch: 6| Step: 4
Training loss: 0.8168944218026115
Validation loss: 2.6851378398100647

Epoch: 6| Step: 5
Training loss: 1.2086192921736383
Validation loss: 2.6723402340653353

Epoch: 6| Step: 6
Training loss: 1.9080307569323993
Validation loss: 2.7817287569932856

Epoch: 6| Step: 7
Training loss: 0.6015408004215826
Validation loss: 2.6600742869251164

Epoch: 6| Step: 8
Training loss: 0.8949870318533498
Validation loss: 2.64391668376017

Epoch: 6| Step: 9
Training loss: 0.8813064692375926
Validation loss: 2.704953879673502

Epoch: 6| Step: 10
Training loss: 1.0769914943320236
Validation loss: 2.654083509226384

Epoch: 6| Step: 11
Training loss: 0.8092703821622335
Validation loss: 2.768219730060634

Epoch: 6| Step: 12
Training loss: 1.5112843443799286
Validation loss: 2.629148364279239

Epoch: 6| Step: 13
Training loss: 0.8055259632470312
Validation loss: 2.685558122150813

Epoch: 744| Step: 0
Training loss: 0.8904419426431341
Validation loss: 2.6622695757281707

Epoch: 6| Step: 1
Training loss: 0.7365823807620838
Validation loss: 2.713933519650032

Epoch: 6| Step: 2
Training loss: 0.7678811831528867
Validation loss: 2.7481830277291883

Epoch: 6| Step: 3
Training loss: 1.7036227277656195
Validation loss: 2.678483628310187

Epoch: 6| Step: 4
Training loss: 0.9387030829275272
Validation loss: 2.603981033764096

Epoch: 6| Step: 5
Training loss: 1.1045939620370138
Validation loss: 2.6634054129322338

Epoch: 6| Step: 6
Training loss: 1.367994843936149
Validation loss: 2.6793711304018872

Epoch: 6| Step: 7
Training loss: 0.7807928273562367
Validation loss: 2.6718730138524114

Epoch: 6| Step: 8
Training loss: 1.038025647024786
Validation loss: 2.6934320315888667

Epoch: 6| Step: 9
Training loss: 0.5822922294309167
Validation loss: 2.744100942636062

Epoch: 6| Step: 10
Training loss: 0.6587702404944562
Validation loss: 2.6784745786886397

Epoch: 6| Step: 11
Training loss: 0.7509839438285246
Validation loss: 2.6500674358926872

Epoch: 6| Step: 12
Training loss: 1.1072016098324975
Validation loss: 2.7618152910012483

Epoch: 6| Step: 13
Training loss: 1.1029964880070322
Validation loss: 2.7232430379917942

Epoch: 745| Step: 0
Training loss: 0.5480377098616802
Validation loss: 2.601118039023772

Epoch: 6| Step: 1
Training loss: 0.8339071126343367
Validation loss: 2.776436190794963

Epoch: 6| Step: 2
Training loss: 0.49334453641998305
Validation loss: 2.6583283817187153

Epoch: 6| Step: 3
Training loss: 1.1015902035523464
Validation loss: 2.6101412655985583

Epoch: 6| Step: 4
Training loss: 1.664683839376101
Validation loss: 2.6236657571843307

Epoch: 6| Step: 5
Training loss: 1.112255386720193
Validation loss: 2.7597549459519315

Epoch: 6| Step: 6
Training loss: 1.0641707019435656
Validation loss: 2.689010955643925

Epoch: 6| Step: 7
Training loss: 0.6407311514390239
Validation loss: 2.7236251412381076

Epoch: 6| Step: 8
Training loss: 1.315185161652127
Validation loss: 2.762840018660972

Epoch: 6| Step: 9
Training loss: 1.370016734654485
Validation loss: 2.692028100084522

Epoch: 6| Step: 10
Training loss: 1.1207819382088278
Validation loss: 2.743735224270835

Epoch: 6| Step: 11
Training loss: 0.8872239610382517
Validation loss: 2.690237291061881

Epoch: 6| Step: 12
Training loss: 0.9235237055525753
Validation loss: 2.6803356419926354

Epoch: 6| Step: 13
Training loss: 1.250419021946588
Validation loss: 2.6177424937490197

Epoch: 746| Step: 0
Training loss: 0.7503345061430994
Validation loss: 2.7484988863462085

Epoch: 6| Step: 1
Training loss: 0.8449032637283077
Validation loss: 2.7357729102832637

Epoch: 6| Step: 2
Training loss: 1.1284884831487765
Validation loss: 2.7070867416191002

Epoch: 6| Step: 3
Training loss: 1.1578849368273874
Validation loss: 2.6962825513908935

Epoch: 6| Step: 4
Training loss: 1.015835432113553
Validation loss: 2.7402824957969383

Epoch: 6| Step: 5
Training loss: 0.8259453429110615
Validation loss: 2.664460544081631

Epoch: 6| Step: 6
Training loss: 0.7100695247593103
Validation loss: 2.662034255229378

Epoch: 6| Step: 7
Training loss: 1.7741926156877768
Validation loss: 2.619439338773612

Epoch: 6| Step: 8
Training loss: 0.9899072050185194
Validation loss: 2.662494061436593

Epoch: 6| Step: 9
Training loss: 0.7538726482908127
Validation loss: 2.6700163025631194

Epoch: 6| Step: 10
Training loss: 0.9787363195620299
Validation loss: 2.7217528398801107

Epoch: 6| Step: 11
Training loss: 1.2026072787771465
Validation loss: 2.6854925979096276

Epoch: 6| Step: 12
Training loss: 0.8809100218970263
Validation loss: 2.7611862184148914

Epoch: 6| Step: 13
Training loss: 0.8772693225410002
Validation loss: 2.691020827545237

Epoch: 747| Step: 0
Training loss: 1.2597641109487026
Validation loss: 2.6473423248911456

Epoch: 6| Step: 1
Training loss: 0.7573789949363695
Validation loss: 2.688324508240036

Epoch: 6| Step: 2
Training loss: 1.7304443633210402
Validation loss: 2.7549952839036673

Epoch: 6| Step: 3
Training loss: 0.8692952564999579
Validation loss: 2.6405048550547514

Epoch: 6| Step: 4
Training loss: 0.636238291319787
Validation loss: 2.7384916991233688

Epoch: 6| Step: 5
Training loss: 0.8868355695092534
Validation loss: 2.7380737864599785

Epoch: 6| Step: 6
Training loss: 1.070455054375241
Validation loss: 2.6452172934598615

Epoch: 6| Step: 7
Training loss: 0.8473429298572767
Validation loss: 2.741721344408916

Epoch: 6| Step: 8
Training loss: 0.6849681008701024
Validation loss: 2.6145895010981612

Epoch: 6| Step: 9
Training loss: 1.211927931811503
Validation loss: 2.7076165859249683

Epoch: 6| Step: 10
Training loss: 0.870199522838843
Validation loss: 2.696626299910591

Epoch: 6| Step: 11
Training loss: 1.1844325351076597
Validation loss: 2.718793669470014

Epoch: 6| Step: 12
Training loss: 1.1106185390819014
Validation loss: 2.7361054985108613

Epoch: 6| Step: 13
Training loss: 0.886087907406281
Validation loss: 2.7556233416363916

Epoch: 748| Step: 0
Training loss: 0.772830956497415
Validation loss: 2.612292072923894

Epoch: 6| Step: 1
Training loss: 0.707377944163606
Validation loss: 2.691722674637792

Epoch: 6| Step: 2
Training loss: 1.993120939693819
Validation loss: 2.711720659088666

Epoch: 6| Step: 3
Training loss: 0.7420821265657591
Validation loss: 2.74462401318653

Epoch: 6| Step: 4
Training loss: 0.9144588165562346
Validation loss: 2.6948927314820983

Epoch: 6| Step: 5
Training loss: 0.9740504188999998
Validation loss: 2.6170921713607105

Epoch: 6| Step: 6
Training loss: 0.9532017598745418
Validation loss: 2.746511351483793

Epoch: 6| Step: 7
Training loss: 0.8243687208513498
Validation loss: 2.652763067146461

Epoch: 6| Step: 8
Training loss: 1.2578506937803182
Validation loss: 2.7288941105813485

Epoch: 6| Step: 9
Training loss: 1.0681996897414343
Validation loss: 2.710715758800999

Epoch: 6| Step: 10
Training loss: 0.9933047574741881
Validation loss: 2.6208339276479315

Epoch: 6| Step: 11
Training loss: 0.9849430140843174
Validation loss: 2.6848779370628613

Epoch: 6| Step: 12
Training loss: 0.6362719460095607
Validation loss: 2.6722380468173017

Epoch: 6| Step: 13
Training loss: 1.081478817933817
Validation loss: 2.692141796625406

Epoch: 749| Step: 0
Training loss: 0.8775768822900855
Validation loss: 2.669833418623392

Epoch: 6| Step: 1
Training loss: 0.8235935171956005
Validation loss: 2.6323007450367375

Epoch: 6| Step: 2
Training loss: 1.0406367487430341
Validation loss: 2.71718181135007

Epoch: 6| Step: 3
Training loss: 1.2566645341613916
Validation loss: 2.670663275443267

Epoch: 6| Step: 4
Training loss: 0.9558591243243152
Validation loss: 2.5770068894080667

Epoch: 6| Step: 5
Training loss: 1.7188344761289103
Validation loss: 2.7197256048083776

Epoch: 6| Step: 6
Training loss: 0.9504609006337796
Validation loss: 2.647306293060651

Epoch: 6| Step: 7
Training loss: 1.075150685505936
Validation loss: 2.676971664643792

Epoch: 6| Step: 8
Training loss: 1.0495725579116906
Validation loss: 2.6425256909688466

Epoch: 6| Step: 9
Training loss: 0.7305899534801927
Validation loss: 2.73914459569533

Epoch: 6| Step: 10
Training loss: 1.1193146628556434
Validation loss: 2.6639077972827225

Epoch: 6| Step: 11
Training loss: 1.0411779910463468
Validation loss: 2.6052696113920604

Epoch: 6| Step: 12
Training loss: 0.6612283251694827
Validation loss: 2.79226839449322

Epoch: 6| Step: 13
Training loss: 1.1998280024448273
Validation loss: 2.7071732667276924

Epoch: 750| Step: 0
Training loss: 1.0052501426000335
Validation loss: 2.6182356127726205

Epoch: 6| Step: 1
Training loss: 0.746006985557515
Validation loss: 2.6836994281270896

Epoch: 6| Step: 2
Training loss: 1.126266243719054
Validation loss: 2.684730251993512

Epoch: 6| Step: 3
Training loss: 1.214395274701305
Validation loss: 2.769452682679631

Epoch: 6| Step: 4
Training loss: 0.8584535687376136
Validation loss: 2.6972860550408

Epoch: 6| Step: 5
Training loss: 0.9134660062410385
Validation loss: 2.651462860819692

Epoch: 6| Step: 6
Training loss: 1.5442992063577978
Validation loss: 2.632358979718489

Epoch: 6| Step: 7
Training loss: 0.6190345986253699
Validation loss: 2.6247894429240124

Epoch: 6| Step: 8
Training loss: 0.6957269140820953
Validation loss: 2.685858638562347

Epoch: 6| Step: 9
Training loss: 1.272249756135203
Validation loss: 2.748297228500056

Epoch: 6| Step: 10
Training loss: 0.697881880410434
Validation loss: 2.7112654029933894

Epoch: 6| Step: 11
Training loss: 0.832444603196636
Validation loss: 2.772919346959938

Epoch: 6| Step: 12
Training loss: 1.694675097201187
Validation loss: 2.6255404096266837

Epoch: 6| Step: 13
Training loss: 0.6584363801400791
Validation loss: 2.6050191364251107

Testing loss: 3.5231298326894485
