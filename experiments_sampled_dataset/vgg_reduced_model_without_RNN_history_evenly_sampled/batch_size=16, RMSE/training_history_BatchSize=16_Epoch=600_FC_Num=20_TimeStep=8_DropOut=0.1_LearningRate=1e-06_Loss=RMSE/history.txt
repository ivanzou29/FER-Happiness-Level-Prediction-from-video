Epoch: 1| Step: 0
Training loss: 4.316799508386447
Validation loss: 4.079003768320105

Epoch: 6| Step: 1
Training loss: 4.199687700922334
Validation loss: 4.079561805099754

Epoch: 6| Step: 2
Training loss: 5.1010921430852525
Validation loss: 4.077282298121267

Epoch: 6| Step: 3
Training loss: 4.009855526725975
Validation loss: 4.072929163051486

Epoch: 6| Step: 4
Training loss: 4.049898292300501
Validation loss: 4.072869288318943

Epoch: 6| Step: 5
Training loss: 3.112322459844927
Validation loss: 4.069616020121251

Epoch: 6| Step: 6
Training loss: 4.306995804514722
Validation loss: 4.06818859938453

Epoch: 6| Step: 7
Training loss: 3.1963870752903203
Validation loss: 4.064679192227842

Epoch: 6| Step: 8
Training loss: 3.990886558379051
Validation loss: 4.066120042396525

Epoch: 6| Step: 9
Training loss: 4.508001842522097
Validation loss: 4.063002587617528

Epoch: 6| Step: 10
Training loss: 4.115601206879425
Validation loss: 4.062649399603105

Epoch: 6| Step: 11
Training loss: 4.603155563056208
Validation loss: 4.060252786185738

Epoch: 6| Step: 12
Training loss: 4.808880919024651
Validation loss: 4.057727988926935

Epoch: 6| Step: 13
Training loss: 4.321663009067277
Validation loss: 4.057303281080786

Epoch: 2| Step: 0
Training loss: 3.515354264749067
Validation loss: 4.053974800353254

Epoch: 6| Step: 1
Training loss: 4.188190460217239
Validation loss: 4.052817931654997

Epoch: 6| Step: 2
Training loss: 4.541877018434772
Validation loss: 4.050454797076848

Epoch: 6| Step: 3
Training loss: 3.435635425148619
Validation loss: 4.052946785377632

Epoch: 6| Step: 4
Training loss: 5.15726585784949
Validation loss: 4.046918640648927

Epoch: 6| Step: 5
Training loss: 3.8633455554636074
Validation loss: 4.046842552691951

Epoch: 6| Step: 6
Training loss: 4.823336995581919
Validation loss: 4.046108829456006

Epoch: 6| Step: 7
Training loss: 3.9537985005571303
Validation loss: 4.043807785844361

Epoch: 6| Step: 8
Training loss: 4.478783287970137
Validation loss: 4.042914478408755

Epoch: 6| Step: 9
Training loss: 4.392829748726206
Validation loss: 4.03942976309496

Epoch: 6| Step: 10
Training loss: 2.9806556093128447
Validation loss: 4.038087939864656

Epoch: 6| Step: 11
Training loss: 4.30871659325956
Validation loss: 4.037071916333083

Epoch: 6| Step: 12
Training loss: 4.767872364883249
Validation loss: 4.034835450865851

Epoch: 6| Step: 13
Training loss: 3.2868700127310815
Validation loss: 4.034927810714649

Epoch: 3| Step: 0
Training loss: 5.121364886033648
Validation loss: 4.029148004990894

Epoch: 6| Step: 1
Training loss: 4.5350885377966215
Validation loss: 4.029268319993262

Epoch: 6| Step: 2
Training loss: 3.9576776998871552
Validation loss: 4.030891801278616

Epoch: 6| Step: 3
Training loss: 4.83934499958666
Validation loss: 4.026761092424348

Epoch: 6| Step: 4
Training loss: 5.053806328356976
Validation loss: 4.026404227476089

Epoch: 6| Step: 5
Training loss: 3.357897624360885
Validation loss: 4.025998394037418

Epoch: 6| Step: 6
Training loss: 2.9322137545617997
Validation loss: 4.021390538492273

Epoch: 6| Step: 7
Training loss: 3.0269742087962648
Validation loss: 4.019260652145324

Epoch: 6| Step: 8
Training loss: 3.999675976027059
Validation loss: 4.017897198502301

Epoch: 6| Step: 9
Training loss: 4.021106822672795
Validation loss: 4.017841546932903

Epoch: 6| Step: 10
Training loss: 4.207413424928847
Validation loss: 4.016058039994239

Epoch: 6| Step: 11
Training loss: 4.194815096502784
Validation loss: 4.014635682649807

Epoch: 6| Step: 12
Training loss: 3.4911102749911005
Validation loss: 4.012917167244145

Epoch: 6| Step: 13
Training loss: 5.345710439401737
Validation loss: 4.014224911894342

Epoch: 4| Step: 0
Training loss: 4.526643924421918
Validation loss: 4.012096820282396

Epoch: 6| Step: 1
Training loss: 3.289096279378573
Validation loss: 4.007483368199635

Epoch: 6| Step: 2
Training loss: 4.557213215470587
Validation loss: 4.007303548417413

Epoch: 6| Step: 3
Training loss: 5.0328584552266795
Validation loss: 4.005639464104848

Epoch: 6| Step: 4
Training loss: 3.579363079847174
Validation loss: 4.0049932178247705

Epoch: 6| Step: 5
Training loss: 4.026662182415956
Validation loss: 4.001070115294603

Epoch: 6| Step: 6
Training loss: 3.8564868576041507
Validation loss: 4.000632482177066

Epoch: 6| Step: 7
Training loss: 4.31470333701804
Validation loss: 3.9985707841957483

Epoch: 6| Step: 8
Training loss: 4.834892394200824
Validation loss: 3.997326543261632

Epoch: 6| Step: 9
Training loss: 3.1149435356006805
Validation loss: 3.9948071181634917

Epoch: 6| Step: 10
Training loss: 4.735771149596194
Validation loss: 3.9931746029625868

Epoch: 6| Step: 11
Training loss: 3.9609266653420603
Validation loss: 3.9917322719670985

Epoch: 6| Step: 12
Training loss: 3.495369436578764
Validation loss: 3.9893580753068765

Epoch: 6| Step: 13
Training loss: 4.345741090072928
Validation loss: 3.9918057201545882

Epoch: 5| Step: 0
Training loss: 4.326470124101311
Validation loss: 3.9868387691463734

Epoch: 6| Step: 1
Training loss: 4.401036634573985
Validation loss: 3.987904313598685

Epoch: 6| Step: 2
Training loss: 3.9060222101551836
Validation loss: 3.981453604596747

Epoch: 6| Step: 3
Training loss: 3.6820167248214983
Validation loss: 3.9805986125472286

Epoch: 6| Step: 4
Training loss: 3.9535638015324968
Validation loss: 3.9803602317007956

Epoch: 6| Step: 5
Training loss: 3.9720229222614893
Validation loss: 3.977240122424541

Epoch: 6| Step: 6
Training loss: 4.368708855649422
Validation loss: 3.978518766952422

Epoch: 6| Step: 7
Training loss: 4.502523985973056
Validation loss: 3.9759189207328585

Epoch: 6| Step: 8
Training loss: 3.841385028525249
Validation loss: 3.9732122588459875

Epoch: 6| Step: 9
Training loss: 3.748849183564316
Validation loss: 3.973737238491965

Epoch: 6| Step: 10
Training loss: 3.85959961272309
Validation loss: 3.9695374309457776

Epoch: 6| Step: 11
Training loss: 4.190731339097526
Validation loss: 3.970325408243162

Epoch: 6| Step: 12
Training loss: 4.461820765501123
Validation loss: 3.96678708263299

Epoch: 6| Step: 13
Training loss: 4.718295043840258
Validation loss: 3.966411296503536

Epoch: 6| Step: 0
Training loss: 3.9234557594594524
Validation loss: 3.963368979629

Epoch: 6| Step: 1
Training loss: 4.330351219117014
Validation loss: 3.959115120972126

Epoch: 6| Step: 2
Training loss: 3.5520516820189143
Validation loss: 3.9562628654277665

Epoch: 6| Step: 3
Training loss: 4.187494078674685
Validation loss: 3.9570000095999083

Epoch: 6| Step: 4
Training loss: 4.644921981764043
Validation loss: 3.9536645850064462

Epoch: 6| Step: 5
Training loss: 4.277196817182375
Validation loss: 3.9530664598763363

Epoch: 6| Step: 6
Training loss: 3.26872464055277
Validation loss: 3.951196569409853

Epoch: 6| Step: 7
Training loss: 3.370590296134636
Validation loss: 3.948571469701701

Epoch: 6| Step: 8
Training loss: 4.365479491859704
Validation loss: 3.945134053417868

Epoch: 6| Step: 9
Training loss: 4.000320421736552
Validation loss: 3.94023318731104

Epoch: 6| Step: 10
Training loss: 3.630372899766279
Validation loss: 3.941287039812173

Epoch: 6| Step: 11
Training loss: 5.000932225107354
Validation loss: 3.939709297667346

Epoch: 6| Step: 12
Training loss: 4.626984866264069
Validation loss: 3.937920728408626

Epoch: 6| Step: 13
Training loss: 3.695736495809727
Validation loss: 3.9343962070362983

Epoch: 7| Step: 0
Training loss: 3.5635620675631565
Validation loss: 3.933384531319522

Epoch: 6| Step: 1
Training loss: 4.103554901123913
Validation loss: 3.92904668233808

Epoch: 6| Step: 2
Training loss: 4.374716395313953
Validation loss: 3.922802662314319

Epoch: 6| Step: 3
Training loss: 4.702719433302328
Validation loss: 3.9225515420954777

Epoch: 6| Step: 4
Training loss: 4.05620333463984
Validation loss: 3.920872625115476

Epoch: 6| Step: 5
Training loss: 4.388192042360357
Validation loss: 3.918066633126381

Epoch: 6| Step: 6
Training loss: 4.644017889785151
Validation loss: 3.914496498476645

Epoch: 6| Step: 7
Training loss: 3.3318380498831894
Validation loss: 3.911211391084288

Epoch: 6| Step: 8
Training loss: 3.531318866429562
Validation loss: 3.906514802222529

Epoch: 6| Step: 9
Training loss: 4.380026844935259
Validation loss: 3.906766833826051

Epoch: 6| Step: 10
Training loss: 3.5869258939619053
Validation loss: 3.898482151274333

Epoch: 6| Step: 11
Training loss: 3.802333346294453
Validation loss: 3.898858840370501

Epoch: 6| Step: 12
Training loss: 4.3110698595290975
Validation loss: 3.893354599387931

Epoch: 6| Step: 13
Training loss: 3.7114867757556254
Validation loss: 3.8925253064720264

Epoch: 8| Step: 0
Training loss: 4.272463058035188
Validation loss: 3.886965645145989

Epoch: 6| Step: 1
Training loss: 4.170010839580837
Validation loss: 3.8815226997211716

Epoch: 6| Step: 2
Training loss: 4.75081507064306
Validation loss: 3.882763091593946

Epoch: 6| Step: 3
Training loss: 4.18450501790511
Validation loss: 3.8743558673141307

Epoch: 6| Step: 4
Training loss: 3.9270822675114947
Validation loss: 3.8788923363202215

Epoch: 6| Step: 5
Training loss: 3.7994509149677174
Validation loss: 3.872015363006976

Epoch: 6| Step: 6
Training loss: 4.319356581491759
Validation loss: 3.867659508223152

Epoch: 6| Step: 7
Training loss: 3.4496696756315206
Validation loss: 3.8632228787226865

Epoch: 6| Step: 8
Training loss: 3.828940666649608
Validation loss: 3.8618177163443708

Epoch: 6| Step: 9
Training loss: 3.561125506885914
Validation loss: 3.8547430341938997

Epoch: 6| Step: 10
Training loss: 3.3184481783475133
Validation loss: 3.8556873535383374

Epoch: 6| Step: 11
Training loss: 4.581079564690767
Validation loss: 3.8482607187459363

Epoch: 6| Step: 12
Training loss: 3.929382312368
Validation loss: 3.846914879102272

Epoch: 6| Step: 13
Training loss: 4.036446940088087
Validation loss: 3.8393829426057606

Epoch: 9| Step: 0
Training loss: 4.432546725556671
Validation loss: 3.8407376558629576

Epoch: 6| Step: 1
Training loss: 4.17621287014534
Validation loss: 3.8312523295147143

Epoch: 6| Step: 2
Training loss: 4.07688914313956
Validation loss: 3.8304591001261685

Epoch: 6| Step: 3
Training loss: 3.7595947860942993
Validation loss: 3.8265739025808867

Epoch: 6| Step: 4
Training loss: 4.027883143892038
Validation loss: 3.8213754310945367

Epoch: 6| Step: 5
Training loss: 3.3270158665711254
Validation loss: 3.8181074176980188

Epoch: 6| Step: 6
Training loss: 3.6511356416036738
Validation loss: 3.814494537371842

Epoch: 6| Step: 7
Training loss: 4.205148429654973
Validation loss: 3.8086462126116842

Epoch: 6| Step: 8
Training loss: 3.970750799985864
Validation loss: 3.8044620010882415

Epoch: 6| Step: 9
Training loss: 4.371129967315329
Validation loss: 3.796614268246535

Epoch: 6| Step: 10
Training loss: 4.364566241513869
Validation loss: 3.7948173099965254

Epoch: 6| Step: 11
Training loss: 3.9670786304417285
Validation loss: 3.7955181479721816

Epoch: 6| Step: 12
Training loss: 3.691418004900265
Validation loss: 3.7868750589828757

Epoch: 6| Step: 13
Training loss: 3.014178151333878
Validation loss: 3.7819440586569613

Epoch: 10| Step: 0
Training loss: 3.4946392422147867
Validation loss: 3.7794122910895105

Epoch: 6| Step: 1
Training loss: 4.283354304716275
Validation loss: 3.7739871269437053

Epoch: 6| Step: 2
Training loss: 4.550413242899192
Validation loss: 3.770721821871786

Epoch: 6| Step: 3
Training loss: 3.8054460399923498
Validation loss: 3.7667694919180494

Epoch: 6| Step: 4
Training loss: 4.318100540637369
Validation loss: 3.760882013441947

Epoch: 6| Step: 5
Training loss: 4.429355938594427
Validation loss: 3.7556537161919876

Epoch: 6| Step: 6
Training loss: 4.109743979246295
Validation loss: 3.750767837724176

Epoch: 6| Step: 7
Training loss: 3.353651698289484
Validation loss: 3.7453320782043398

Epoch: 6| Step: 8
Training loss: 2.9126565522780608
Validation loss: 3.7414331046762017

Epoch: 6| Step: 9
Training loss: 3.2350619411287096
Validation loss: 3.7349512005204724

Epoch: 6| Step: 10
Training loss: 3.651847079364695
Validation loss: 3.7297809489266736

Epoch: 6| Step: 11
Training loss: 4.627426747999958
Validation loss: 3.7212920021138363

Epoch: 6| Step: 12
Training loss: 3.6573497715811336
Validation loss: 3.7161682506736278

Epoch: 6| Step: 13
Training loss: 3.999617915978465
Validation loss: 3.7147906099808146

Epoch: 11| Step: 0
Training loss: 3.3570363975735784
Validation loss: 3.7041891893364007

Epoch: 6| Step: 1
Training loss: 4.173337072994356
Validation loss: 3.705339423100139

Epoch: 6| Step: 2
Training loss: 3.2161626694376295
Validation loss: 3.6977296251860845

Epoch: 6| Step: 3
Training loss: 3.936708885524206
Validation loss: 3.6930572392604986

Epoch: 6| Step: 4
Training loss: 3.332318596563646
Validation loss: 3.6839899675973458

Epoch: 6| Step: 5
Training loss: 3.649106211510334
Validation loss: 3.6764927035058053

Epoch: 6| Step: 6
Training loss: 4.397883053351027
Validation loss: 3.6767575907726555

Epoch: 6| Step: 7
Training loss: 3.7351022435177392
Validation loss: 3.6612502016333326

Epoch: 6| Step: 8
Training loss: 3.545733431982544
Validation loss: 3.6582648818014496

Epoch: 6| Step: 9
Training loss: 4.399575663825833
Validation loss: 3.6638435941900966

Epoch: 6| Step: 10
Training loss: 4.148564855772274
Validation loss: 3.648647604359366

Epoch: 6| Step: 11
Training loss: 3.336158048320922
Validation loss: 3.643531060207686

Epoch: 6| Step: 12
Training loss: 4.265956320838134
Validation loss: 3.6422661332941155

Epoch: 6| Step: 13
Training loss: 4.128063798056566
Validation loss: 3.6304276723000455

Epoch: 12| Step: 0
Training loss: 3.5292309415534655
Validation loss: 3.6234706669611967

Epoch: 6| Step: 1
Training loss: 3.0437797278611147
Validation loss: 3.613269347326734

Epoch: 6| Step: 2
Training loss: 4.1122623641626985
Validation loss: 3.6066427882537964

Epoch: 6| Step: 3
Training loss: 3.808398182078239
Validation loss: 3.602961024472565

Epoch: 6| Step: 4
Training loss: 3.722331654346008
Validation loss: 3.5984823875852565

Epoch: 6| Step: 5
Training loss: 5.2106896932035225
Validation loss: 3.5862998535361217

Epoch: 6| Step: 6
Training loss: 3.9629138477711017
Validation loss: 3.575846738681469

Epoch: 6| Step: 7
Training loss: 3.7341054396124203
Validation loss: 3.5672556034868133

Epoch: 6| Step: 8
Training loss: 2.9066063447111707
Validation loss: 3.5574073451395725

Epoch: 6| Step: 9
Training loss: 3.541583176171046
Validation loss: 3.5512703755050867

Epoch: 6| Step: 10
Training loss: 3.884544185965046
Validation loss: 3.5493852222549966

Epoch: 6| Step: 11
Training loss: 3.8693152537020987
Validation loss: 3.537727176298848

Epoch: 6| Step: 12
Training loss: 2.851926346650409
Validation loss: 3.521609489769912

Epoch: 6| Step: 13
Training loss: 3.925520581753273
Validation loss: 3.5113886020829295

Epoch: 13| Step: 0
Training loss: 4.165691922931573
Validation loss: 3.5200317969428907

Epoch: 6| Step: 1
Training loss: 2.969089528795803
Validation loss: 3.4981673389689214

Epoch: 6| Step: 2
Training loss: 4.032828561602314
Validation loss: 3.4905510319935797

Epoch: 6| Step: 3
Training loss: 3.0786216064146954
Validation loss: 3.4841723911764135

Epoch: 6| Step: 4
Training loss: 4.2650955486439575
Validation loss: 3.4778044029736908

Epoch: 6| Step: 5
Training loss: 4.025786726933253
Validation loss: 3.461877421773516

Epoch: 6| Step: 6
Training loss: 3.4268472854965735
Validation loss: 3.4605467308661533

Epoch: 6| Step: 7
Training loss: 3.2832940410709237
Validation loss: 3.440333578033906

Epoch: 6| Step: 8
Training loss: 3.473187743837478
Validation loss: 3.426395181974989

Epoch: 6| Step: 9
Training loss: 3.602731113790132
Validation loss: 3.4240419324931812

Epoch: 6| Step: 10
Training loss: 3.3402089415656966
Validation loss: 3.4189319789299937

Epoch: 6| Step: 11
Training loss: 3.848458112629723
Validation loss: 3.4012059819331704

Epoch: 6| Step: 12
Training loss: 4.040504419544108
Validation loss: 3.397473710929304

Epoch: 6| Step: 13
Training loss: 2.5710585418766403
Validation loss: 3.3784833651157338

Epoch: 14| Step: 0
Training loss: 3.905545346599589
Validation loss: 3.3789427092898836

Epoch: 6| Step: 1
Training loss: 3.658068995096755
Validation loss: 3.3629376113674834

Epoch: 6| Step: 2
Training loss: 3.03764596596219
Validation loss: 3.3506108240921346

Epoch: 6| Step: 3
Training loss: 3.0049435891745278
Validation loss: 3.339101408153716

Epoch: 6| Step: 4
Training loss: 3.7086143530045725
Validation loss: 3.3218359099872736

Epoch: 6| Step: 5
Training loss: 3.6828859848699187
Validation loss: 3.306210759522419

Epoch: 6| Step: 6
Training loss: 3.890312458031895
Validation loss: 3.2937006794735364

Epoch: 6| Step: 7
Training loss: 3.132575656376063
Validation loss: 3.286416363659812

Epoch: 6| Step: 8
Training loss: 3.738866937531008
Validation loss: 3.270809814376929

Epoch: 6| Step: 9
Training loss: 3.523678655047603
Validation loss: 3.2669958460031547

Epoch: 6| Step: 10
Training loss: 2.7167386035717014
Validation loss: 3.248339608295395

Epoch: 6| Step: 11
Training loss: 3.709407579364089
Validation loss: 3.237351523642894

Epoch: 6| Step: 12
Training loss: 3.560276341374799
Validation loss: 3.2177187929090434

Epoch: 6| Step: 13
Training loss: 3.6008840323188673
Validation loss: 3.207897412895645

Epoch: 15| Step: 0
Training loss: 3.653319137805545
Validation loss: 3.203513784596964

Epoch: 6| Step: 1
Training loss: 3.3617233230237025
Validation loss: 3.1928682614257102

Epoch: 6| Step: 2
Training loss: 3.1145669347699223
Validation loss: 3.1661157587579196

Epoch: 6| Step: 3
Training loss: 3.1887237593207782
Validation loss: 3.1520132412621664

Epoch: 6| Step: 4
Training loss: 3.170130508335638
Validation loss: 3.145923917710733

Epoch: 6| Step: 5
Training loss: 2.8799535122404345
Validation loss: 3.141839866001694

Epoch: 6| Step: 6
Training loss: 3.8561275271067035
Validation loss: 3.1234172676897582

Epoch: 6| Step: 7
Training loss: 3.4712134883884938
Validation loss: 3.10871990045318

Epoch: 6| Step: 8
Training loss: 3.3979830032381577
Validation loss: 3.099660857309697

Epoch: 6| Step: 9
Training loss: 3.486066604336906
Validation loss: 3.0755953157387963

Epoch: 6| Step: 10
Training loss: 3.895956530467515
Validation loss: 3.0732060906022274

Epoch: 6| Step: 11
Training loss: 2.844751202744728
Validation loss: 3.051658733270665

Epoch: 6| Step: 12
Training loss: 2.8388633242470274
Validation loss: 3.0268833130197152

Epoch: 6| Step: 13
Training loss: 3.6684930038770185
Validation loss: 3.018718834597267

Epoch: 16| Step: 0
Training loss: 3.4319396390786503
Validation loss: 2.999440465724316

Epoch: 6| Step: 1
Training loss: 3.374160944873433
Validation loss: 2.9897600581706425

Epoch: 6| Step: 2
Training loss: 3.44050827174834
Validation loss: 2.9686674554528922

Epoch: 6| Step: 3
Training loss: 3.205418505310883
Validation loss: 2.972475059590454

Epoch: 6| Step: 4
Training loss: 2.9305851489396355
Validation loss: 2.951006038251427

Epoch: 6| Step: 5
Training loss: 3.3021594178171823
Validation loss: 2.9312797829814943

Epoch: 6| Step: 6
Training loss: 2.739002432112852
Validation loss: 2.924631745609557

Epoch: 6| Step: 7
Training loss: 2.9473084989529834
Validation loss: 2.9065409662549575

Epoch: 6| Step: 8
Training loss: 2.966763283374263
Validation loss: 2.8909904801014075

Epoch: 6| Step: 9
Training loss: 2.4924421509177273
Validation loss: 2.8987235372121196

Epoch: 6| Step: 10
Training loss: 3.2031971993101607
Validation loss: 2.884765889827363

Epoch: 6| Step: 11
Training loss: 4.018175554525624
Validation loss: 2.854195095166487

Epoch: 6| Step: 12
Training loss: 3.2360210560796148
Validation loss: 2.841179821355926

Epoch: 6| Step: 13
Training loss: 2.874033724072655
Validation loss: 2.8308248596080037

Epoch: 17| Step: 0
Training loss: 2.9949520875285796
Validation loss: 2.8134633063270766

Epoch: 6| Step: 1
Training loss: 1.8868168080755292
Validation loss: 2.7953573547956463

Epoch: 6| Step: 2
Training loss: 2.8006933137291448
Validation loss: 2.8022722844700514

Epoch: 6| Step: 3
Training loss: 3.6047814934442997
Validation loss: 2.785814456114577

Epoch: 6| Step: 4
Training loss: 2.2134998153021224
Validation loss: 2.7633859154035187

Epoch: 6| Step: 5
Training loss: 3.567942694695619
Validation loss: 2.766246956765192

Epoch: 6| Step: 6
Training loss: 3.8200533726343915
Validation loss: 2.7578453032499377

Epoch: 6| Step: 7
Training loss: 2.8793706428787984
Validation loss: 2.738678037304443

Epoch: 6| Step: 8
Training loss: 2.748672338258584
Validation loss: 2.7321570072918506

Epoch: 6| Step: 9
Training loss: 2.4854472983157536
Validation loss: 2.7074433624319045

Epoch: 6| Step: 10
Training loss: 2.877922397237967
Validation loss: 2.705949756429655

Epoch: 6| Step: 11
Training loss: 3.4963978896164907
Validation loss: 2.702079280942231

Epoch: 6| Step: 12
Training loss: 3.1152793761444033
Validation loss: 2.6884847097580815

Epoch: 6| Step: 13
Training loss: 3.7420116534558803
Validation loss: 2.6809614875772887

Epoch: 18| Step: 0
Training loss: 2.827856398836222
Validation loss: 2.6627578656311517

Epoch: 6| Step: 1
Training loss: 2.8438091900712488
Validation loss: 2.658652582889579

Epoch: 6| Step: 2
Training loss: 3.152899748636352
Validation loss: 2.6596102843106033

Epoch: 6| Step: 3
Training loss: 3.3000296735874386
Validation loss: 2.6461991327019554

Epoch: 6| Step: 4
Training loss: 2.9428629516671214
Validation loss: 2.6463937857792597

Epoch: 6| Step: 5
Training loss: 3.2507593294892994
Validation loss: 2.6303900565854526

Epoch: 6| Step: 6
Training loss: 2.485640773171613
Validation loss: 2.6066857526361744

Epoch: 6| Step: 7
Training loss: 2.8887501177917745
Validation loss: 2.6219928322345822

Epoch: 6| Step: 8
Training loss: 3.138107429459764
Validation loss: 2.6063170675762506

Epoch: 6| Step: 9
Training loss: 3.492823736959926
Validation loss: 2.5997726549280453

Epoch: 6| Step: 10
Training loss: 2.3342146117481852
Validation loss: 2.6070134819102537

Epoch: 6| Step: 11
Training loss: 2.876510057691353
Validation loss: 2.59092169563297

Epoch: 6| Step: 12
Training loss: 2.7242078697221426
Validation loss: 2.5855063357264627

Epoch: 6| Step: 13
Training loss: 2.683219250530459
Validation loss: 2.5794160177824996

Epoch: 19| Step: 0
Training loss: 2.934933779227761
Validation loss: 2.5657158118594285

Epoch: 6| Step: 1
Training loss: 2.711371922932701
Validation loss: 2.576660086106226

Epoch: 6| Step: 2
Training loss: 3.069370581503896
Validation loss: 2.5561130411474

Epoch: 6| Step: 3
Training loss: 3.049192828323075
Validation loss: 2.549478802991042

Epoch: 6| Step: 4
Training loss: 2.9448860325158317
Validation loss: 2.540583694679844

Epoch: 6| Step: 5
Training loss: 3.1392474593285695
Validation loss: 2.53057716671107

Epoch: 6| Step: 6
Training loss: 3.272655457373382
Validation loss: 2.5499427659900307

Epoch: 6| Step: 7
Training loss: 2.742922084045237
Validation loss: 2.545455918262927

Epoch: 6| Step: 8
Training loss: 3.254454714196431
Validation loss: 2.5384118596157164

Epoch: 6| Step: 9
Training loss: 3.0744898675319523
Validation loss: 2.5385248702621026

Epoch: 6| Step: 10
Training loss: 2.8350694236799496
Validation loss: 2.5332996340125606

Epoch: 6| Step: 11
Training loss: 2.6759858213314205
Validation loss: 2.5362434957400626

Epoch: 6| Step: 12
Training loss: 2.450742402770546
Validation loss: 2.512318788467844

Epoch: 6| Step: 13
Training loss: 2.338325836031861
Validation loss: 2.5394207919795933

Epoch: 20| Step: 0
Training loss: 2.8904313306109763
Validation loss: 2.532152147561948

Epoch: 6| Step: 1
Training loss: 2.870971012735802
Validation loss: 2.5262325666777494

Epoch: 6| Step: 2
Training loss: 2.1826667797078496
Validation loss: 2.524273724835403

Epoch: 6| Step: 3
Training loss: 2.2848399929727132
Validation loss: 2.5170634569811448

Epoch: 6| Step: 4
Training loss: 3.219773509429874
Validation loss: 2.51537139761776

Epoch: 6| Step: 5
Training loss: 2.651790510634745
Validation loss: 2.5128481144660197

Epoch: 6| Step: 6
Training loss: 2.8220432708688663
Validation loss: 2.520270210882079

Epoch: 6| Step: 7
Training loss: 2.804013312021129
Validation loss: 2.4993790768090727

Epoch: 6| Step: 8
Training loss: 3.043249859147322
Validation loss: 2.5160466699777073

Epoch: 6| Step: 9
Training loss: 3.0618198184390173
Validation loss: 2.51072059537474

Epoch: 6| Step: 10
Training loss: 3.707727461336832
Validation loss: 2.4961850376239245

Epoch: 6| Step: 11
Training loss: 2.755682363036369
Validation loss: 2.4886095803967785

Epoch: 6| Step: 12
Training loss: 3.1286136333209256
Validation loss: 2.513332818925799

Epoch: 6| Step: 13
Training loss: 3.098877020444954
Validation loss: 2.513520707079588

Epoch: 21| Step: 0
Training loss: 2.5779931236986267
Validation loss: 2.5180111498531392

Epoch: 6| Step: 1
Training loss: 2.8927403313736715
Validation loss: 2.5119656720666583

Epoch: 6| Step: 2
Training loss: 2.7210788617971255
Validation loss: 2.521253020184356

Epoch: 6| Step: 3
Training loss: 2.5880383949556562
Validation loss: 2.5056430307418305

Epoch: 6| Step: 4
Training loss: 2.6400677696835224
Validation loss: 2.516990762204684

Epoch: 6| Step: 5
Training loss: 3.2070880471333227
Validation loss: 2.502621093445537

Epoch: 6| Step: 6
Training loss: 3.294574386824469
Validation loss: 2.506275353896612

Epoch: 6| Step: 7
Training loss: 3.219318524863044
Validation loss: 2.5187577649158177

Epoch: 6| Step: 8
Training loss: 2.4945680734441535
Validation loss: 2.518497886936977

Epoch: 6| Step: 9
Training loss: 2.267322193984668
Validation loss: 2.5144877506746353

Epoch: 6| Step: 10
Training loss: 3.486394049184131
Validation loss: 2.5223817716383334

Epoch: 6| Step: 11
Training loss: 3.1023011373005978
Validation loss: 2.5045526131720757

Epoch: 6| Step: 12
Training loss: 3.015593059153222
Validation loss: 2.5278426581633395

Epoch: 6| Step: 13
Training loss: 3.017448703990406
Validation loss: 2.5098161666362997

Epoch: 22| Step: 0
Training loss: 3.715562239518712
Validation loss: 2.520642909931948

Epoch: 6| Step: 1
Training loss: 3.4038256495793635
Validation loss: 2.515257392040829

Epoch: 6| Step: 2
Training loss: 2.239189562815948
Validation loss: 2.5294696568460506

Epoch: 6| Step: 3
Training loss: 2.7993502612339887
Validation loss: 2.523199040374424

Epoch: 6| Step: 4
Training loss: 2.355228240986141
Validation loss: 2.5101108803056307

Epoch: 6| Step: 5
Training loss: 2.8272472726679045
Validation loss: 2.5111757816631592

Epoch: 6| Step: 6
Training loss: 3.271574450718901
Validation loss: 2.5205306008081734

Epoch: 6| Step: 7
Training loss: 2.609843320565039
Validation loss: 2.5274148030077166

Epoch: 6| Step: 8
Training loss: 2.467344149351012
Validation loss: 2.513508377503092

Epoch: 6| Step: 9
Training loss: 2.804315143828047
Validation loss: 2.509973535823506

Epoch: 6| Step: 10
Training loss: 3.2298192175003195
Validation loss: 2.5196462745035637

Epoch: 6| Step: 11
Training loss: 2.4344267422192893
Validation loss: 2.518412823659753

Epoch: 6| Step: 12
Training loss: 2.7936741078286054
Validation loss: 2.5032668723816585

Epoch: 6| Step: 13
Training loss: 3.7372190746252976
Validation loss: 2.5241708617200125

Epoch: 23| Step: 0
Training loss: 3.015224449950873
Validation loss: 2.4944011947751976

Epoch: 6| Step: 1
Training loss: 2.278923834418038
Validation loss: 2.514681944615407

Epoch: 6| Step: 2
Training loss: 3.138003949427262
Validation loss: 2.517206132187287

Epoch: 6| Step: 3
Training loss: 3.315464204993365
Validation loss: 2.5147386764135504

Epoch: 6| Step: 4
Training loss: 2.754976364975919
Validation loss: 2.5013108364973

Epoch: 6| Step: 5
Training loss: 3.446742169889323
Validation loss: 2.514639517010355

Epoch: 6| Step: 6
Training loss: 2.277706791254904
Validation loss: 2.507143013239247

Epoch: 6| Step: 7
Training loss: 3.545448991242084
Validation loss: 2.5200395075752575

Epoch: 6| Step: 8
Training loss: 2.913489073104885
Validation loss: 2.511760763564182

Epoch: 6| Step: 9
Training loss: 2.392239094283075
Validation loss: 2.518124467251775

Epoch: 6| Step: 10
Training loss: 3.314406080479699
Validation loss: 2.5198874357019356

Epoch: 6| Step: 11
Training loss: 2.4406017229091157
Validation loss: 2.52334372774399

Epoch: 6| Step: 12
Training loss: 2.7442838909721545
Validation loss: 2.524325058595569

Epoch: 6| Step: 13
Training loss: 2.2357918042072376
Validation loss: 2.5060732362453204

Epoch: 24| Step: 0
Training loss: 3.0596593021390497
Validation loss: 2.5262902050763842

Epoch: 6| Step: 1
Training loss: 2.0977591093336327
Validation loss: 2.52056713388602

Epoch: 6| Step: 2
Training loss: 2.269763822998953
Validation loss: 2.507014663448102

Epoch: 6| Step: 3
Training loss: 3.423929929987807
Validation loss: 2.524174416446058

Epoch: 6| Step: 4
Training loss: 2.7133949420723513
Validation loss: 2.503596648399744

Epoch: 6| Step: 5
Training loss: 2.396584158190323
Validation loss: 2.5153096023676254

Epoch: 6| Step: 6
Training loss: 3.7095501364263357
Validation loss: 2.52268408012329

Epoch: 6| Step: 7
Training loss: 3.2903899280018316
Validation loss: 2.515991465512935

Epoch: 6| Step: 8
Training loss: 1.9901993947796903
Validation loss: 2.5135408620356796

Epoch: 6| Step: 9
Training loss: 3.3044906810110195
Validation loss: 2.512583991891439

Epoch: 6| Step: 10
Training loss: 2.886019775671824
Validation loss: 2.513948195971109

Epoch: 6| Step: 11
Training loss: 2.702991107425041
Validation loss: 2.494118248785683

Epoch: 6| Step: 12
Training loss: 2.821046770624259
Validation loss: 2.5158537073665026

Epoch: 6| Step: 13
Training loss: 3.548417751537819
Validation loss: 2.5097752247205376

Epoch: 25| Step: 0
Training loss: 2.6154365717788943
Validation loss: 2.540133584956908

Epoch: 6| Step: 1
Training loss: 3.8686118845405013
Validation loss: 2.5233511686947114

Epoch: 6| Step: 2
Training loss: 2.4195678550505857
Validation loss: 2.5009956161654068

Epoch: 6| Step: 3
Training loss: 3.2201040438315944
Validation loss: 2.526207594162786

Epoch: 6| Step: 4
Training loss: 2.608453188042715
Validation loss: 2.4971740640272664

Epoch: 6| Step: 5
Training loss: 3.2755021387360226
Validation loss: 2.5046190659463066

Epoch: 6| Step: 6
Training loss: 2.6359111538097806
Validation loss: 2.5205683859220382

Epoch: 6| Step: 7
Training loss: 2.424829858533269
Validation loss: 2.5215859096147866

Epoch: 6| Step: 8
Training loss: 3.11509844922896
Validation loss: 2.4953602220406106

Epoch: 6| Step: 9
Training loss: 1.992305078963607
Validation loss: 2.5061971211280847

Epoch: 6| Step: 10
Training loss: 2.672244397778759
Validation loss: 2.5165802860192668

Epoch: 6| Step: 11
Training loss: 3.5489327935427992
Validation loss: 2.5032875799617487

Epoch: 6| Step: 12
Training loss: 3.0311230505089464
Validation loss: 2.4889441258382443

Epoch: 6| Step: 13
Training loss: 1.9270055875474483
Validation loss: 2.524022512444496

Epoch: 26| Step: 0
Training loss: 2.9896529097662863
Validation loss: 2.502829719146726

Epoch: 6| Step: 1
Training loss: 2.7167945055536484
Validation loss: 2.4986688310311718

Epoch: 6| Step: 2
Training loss: 2.415706334095751
Validation loss: 2.500206888518732

Epoch: 6| Step: 3
Training loss: 2.4431090741286194
Validation loss: 2.4945812833259877

Epoch: 6| Step: 4
Training loss: 2.2551312745447185
Validation loss: 2.5045757759339113

Epoch: 6| Step: 5
Training loss: 3.288519807746327
Validation loss: 2.509817815248928

Epoch: 6| Step: 6
Training loss: 3.024525843258425
Validation loss: 2.496609494987474

Epoch: 6| Step: 7
Training loss: 2.9510912477094178
Validation loss: 2.506544028819763

Epoch: 6| Step: 8
Training loss: 2.877002516229966
Validation loss: 2.521509759291174

Epoch: 6| Step: 9
Training loss: 3.002020632221194
Validation loss: 2.513916990916665

Epoch: 6| Step: 10
Training loss: 3.133395704365588
Validation loss: 2.5050990914205755

Epoch: 6| Step: 11
Training loss: 3.0442950941456477
Validation loss: 2.5039459456248694

Epoch: 6| Step: 12
Training loss: 3.1440934344378344
Validation loss: 2.529154715623231

Epoch: 6| Step: 13
Training loss: 3.0218509582383697
Validation loss: 2.4920398381542874

Epoch: 27| Step: 0
Training loss: 2.743090967091951
Validation loss: 2.5053473080083983

Epoch: 6| Step: 1
Training loss: 2.9341096183202384
Validation loss: 2.5136651703078794

Epoch: 6| Step: 2
Training loss: 3.668253569670969
Validation loss: 2.523702153650689

Epoch: 6| Step: 3
Training loss: 3.1001826755475452
Validation loss: 2.4976191320081047

Epoch: 6| Step: 4
Training loss: 2.3494533065244294
Validation loss: 2.4917120893964495

Epoch: 6| Step: 5
Training loss: 2.922379394078909
Validation loss: 2.523304960076407

Epoch: 6| Step: 6
Training loss: 3.6857197230268315
Validation loss: 2.499201836893706

Epoch: 6| Step: 7
Training loss: 2.987925549449031
Validation loss: 2.5181790456838

Epoch: 6| Step: 8
Training loss: 2.487449806512082
Validation loss: 2.513713073686064

Epoch: 6| Step: 9
Training loss: 2.4534328777739542
Validation loss: 2.501665989738102

Epoch: 6| Step: 10
Training loss: 2.7788096662354063
Validation loss: 2.510853728625563

Epoch: 6| Step: 11
Training loss: 2.112309879573485
Validation loss: 2.506129422306219

Epoch: 6| Step: 12
Training loss: 2.7114269683192296
Validation loss: 2.5117607502956694

Epoch: 6| Step: 13
Training loss: 3.107881887206961
Validation loss: 2.5002402590082187

Epoch: 28| Step: 0
Training loss: 2.7574722036861155
Validation loss: 2.511951056419336

Epoch: 6| Step: 1
Training loss: 3.129073120696531
Validation loss: 2.4897072276772163

Epoch: 6| Step: 2
Training loss: 2.9826578522803335
Validation loss: 2.5252061631575957

Epoch: 6| Step: 3
Training loss: 3.007744964237736
Validation loss: 2.50115394929805

Epoch: 6| Step: 4
Training loss: 3.131949060798019
Validation loss: 2.5043359031763917

Epoch: 6| Step: 5
Training loss: 2.438916699427852
Validation loss: 2.5059608010092975

Epoch: 6| Step: 6
Training loss: 2.8182238508541064
Validation loss: 2.502324031083029

Epoch: 6| Step: 7
Training loss: 2.362670718690456
Validation loss: 2.5090759057415117

Epoch: 6| Step: 8
Training loss: 2.984153379829553
Validation loss: 2.51306180942357

Epoch: 6| Step: 9
Training loss: 2.86335818823558
Validation loss: 2.522934621513633

Epoch: 6| Step: 10
Training loss: 2.4680743681215054
Validation loss: 2.5300396428732723

Epoch: 6| Step: 11
Training loss: 2.392545041225346
Validation loss: 2.4925932467611362

Epoch: 6| Step: 12
Training loss: 3.8991204468173413
Validation loss: 2.4992640273372024

Epoch: 6| Step: 13
Training loss: 2.8085306768006855
Validation loss: 2.513341892975106

Epoch: 29| Step: 0
Training loss: 2.7811123245967475
Validation loss: 2.507439652424248

Epoch: 6| Step: 1
Training loss: 3.040446851163252
Validation loss: 2.5021627556593726

Epoch: 6| Step: 2
Training loss: 3.1366362032355224
Validation loss: 2.5157609975551614

Epoch: 6| Step: 3
Training loss: 2.1655112144445834
Validation loss: 2.502498185556841

Epoch: 6| Step: 4
Training loss: 2.975931576321647
Validation loss: 2.5158808338680294

Epoch: 6| Step: 5
Training loss: 2.4290398718936803
Validation loss: 2.5132649782510184

Epoch: 6| Step: 6
Training loss: 2.9315858107696187
Validation loss: 2.5147176685992054

Epoch: 6| Step: 7
Training loss: 3.6940066588898905
Validation loss: 2.5220765238517

Epoch: 6| Step: 8
Training loss: 3.4732968884079596
Validation loss: 2.504648630425829

Epoch: 6| Step: 9
Training loss: 2.2775619166779544
Validation loss: 2.510672868221059

Epoch: 6| Step: 10
Training loss: 2.5360361697027365
Validation loss: 2.4892334577425212

Epoch: 6| Step: 11
Training loss: 3.238165509372377
Validation loss: 2.5055819614348844

Epoch: 6| Step: 12
Training loss: 2.592555127049759
Validation loss: 2.506580904845929

Epoch: 6| Step: 13
Training loss: 2.6117771079401204
Validation loss: 2.4976481388581613

Epoch: 30| Step: 0
Training loss: 3.0877624523723117
Validation loss: 2.493286833639078

Epoch: 6| Step: 1
Training loss: 2.4271415299627104
Validation loss: 2.4961817552547356

Epoch: 6| Step: 2
Training loss: 2.695741392648111
Validation loss: 2.5091521432531554

Epoch: 6| Step: 3
Training loss: 2.9852124382347736
Validation loss: 2.5048033582016536

Epoch: 6| Step: 4
Training loss: 3.1131697458858905
Validation loss: 2.508817212645051

Epoch: 6| Step: 5
Training loss: 2.5323047088910675
Validation loss: 2.489015712655828

Epoch: 6| Step: 6
Training loss: 2.673559984871538
Validation loss: 2.499258177431192

Epoch: 6| Step: 7
Training loss: 3.0320178760212966
Validation loss: 2.4888247755645296

Epoch: 6| Step: 8
Training loss: 3.32731539769486
Validation loss: 2.4942970899731876

Epoch: 6| Step: 9
Training loss: 2.87140397452398
Validation loss: 2.5078536957853403

Epoch: 6| Step: 10
Training loss: 2.5779951583071066
Validation loss: 2.5072342871119457

Epoch: 6| Step: 11
Training loss: 2.6839131216607597
Validation loss: 2.5148515642869027

Epoch: 6| Step: 12
Training loss: 2.990238361617607
Validation loss: 2.521492060874257

Epoch: 6| Step: 13
Training loss: 3.733226008802614
Validation loss: 2.5058321487088007

Epoch: 31| Step: 0
Training loss: 3.4632582622636874
Validation loss: 2.5112171575867053

Epoch: 6| Step: 1
Training loss: 2.946633283100923
Validation loss: 2.510672486330737

Epoch: 6| Step: 2
Training loss: 2.6373128490128197
Validation loss: 2.5084761094652186

Epoch: 6| Step: 3
Training loss: 2.655201693846187
Validation loss: 2.510953844108888

Epoch: 6| Step: 4
Training loss: 2.3988426437895183
Validation loss: 2.519278745024799

Epoch: 6| Step: 5
Training loss: 1.873512250031004
Validation loss: 2.4957798747915616

Epoch: 6| Step: 6
Training loss: 2.3499728180956847
Validation loss: 2.4954009196645806

Epoch: 6| Step: 7
Training loss: 2.9034548207678785
Validation loss: 2.4826571675100113

Epoch: 6| Step: 8
Training loss: 3.5402293860475993
Validation loss: 2.4767430793036525

Epoch: 6| Step: 9
Training loss: 2.9082598555791472
Validation loss: 2.483728284523873

Epoch: 6| Step: 10
Training loss: 3.0916719489725097
Validation loss: 2.495879021329356

Epoch: 6| Step: 11
Training loss: 3.3395573364946665
Validation loss: 2.5007416086647183

Epoch: 6| Step: 12
Training loss: 2.7361997782566942
Validation loss: 2.484036274512395

Epoch: 6| Step: 13
Training loss: 3.4560403384309355
Validation loss: 2.4990806417080322

Epoch: 32| Step: 0
Training loss: 2.419996554474703
Validation loss: 2.502710703264203

Epoch: 6| Step: 1
Training loss: 2.6901260675435537
Validation loss: 2.5012665473116895

Epoch: 6| Step: 2
Training loss: 3.035991460504195
Validation loss: 2.4959279111075947

Epoch: 6| Step: 3
Training loss: 2.514302919223676
Validation loss: 2.496248177201701

Epoch: 6| Step: 4
Training loss: 2.826147494576724
Validation loss: 2.4972899458333475

Epoch: 6| Step: 5
Training loss: 2.8079807848802734
Validation loss: 2.485848526744879

Epoch: 6| Step: 6
Training loss: 2.991392184304389
Validation loss: 2.5007200742259466

Epoch: 6| Step: 7
Training loss: 3.1489351319469825
Validation loss: 2.498534696063187

Epoch: 6| Step: 8
Training loss: 2.9669158087994183
Validation loss: 2.504894097114927

Epoch: 6| Step: 9
Training loss: 2.9859116677404955
Validation loss: 2.5091623256531355

Epoch: 6| Step: 10
Training loss: 3.1033728862608823
Validation loss: 2.501172615196412

Epoch: 6| Step: 11
Training loss: 2.7301916764988468
Validation loss: 2.493665389366736

Epoch: 6| Step: 12
Training loss: 3.2286975807013816
Validation loss: 2.52270245155831

Epoch: 6| Step: 13
Training loss: 2.862265704698715
Validation loss: 2.505090787791125

Epoch: 33| Step: 0
Training loss: 2.171818574680142
Validation loss: 2.5081426779894946

Epoch: 6| Step: 1
Training loss: 3.068821824237441
Validation loss: 2.5120548628213393

Epoch: 6| Step: 2
Training loss: 3.383205752167465
Validation loss: 2.5104511700965575

Epoch: 6| Step: 3
Training loss: 1.9699308698888682
Validation loss: 2.5087611542235018

Epoch: 6| Step: 4
Training loss: 2.48262278826516
Validation loss: 2.5106278690923167

Epoch: 6| Step: 5
Training loss: 3.122026783839894
Validation loss: 2.4902758615742915

Epoch: 6| Step: 6
Training loss: 2.792657922908487
Validation loss: 2.5161685834005296

Epoch: 6| Step: 7
Training loss: 2.38269162731335
Validation loss: 2.5074602907821233

Epoch: 6| Step: 8
Training loss: 3.3488062482426546
Validation loss: 2.4966959854829556

Epoch: 6| Step: 9
Training loss: 3.4327462357943603
Validation loss: 2.5069053526488823

Epoch: 6| Step: 10
Training loss: 2.902911493931836
Validation loss: 2.4888295849133755

Epoch: 6| Step: 11
Training loss: 2.824741088345359
Validation loss: 2.4990048165876604

Epoch: 6| Step: 12
Training loss: 3.357180140094063
Validation loss: 2.4997713261278967

Epoch: 6| Step: 13
Training loss: 2.175917013374034
Validation loss: 2.5017546167161004

Epoch: 34| Step: 0
Training loss: 2.396892037262725
Validation loss: 2.518503459049381

Epoch: 6| Step: 1
Training loss: 3.014886162729656
Validation loss: 2.5141207050033

Epoch: 6| Step: 2
Training loss: 2.719411396825483
Validation loss: 2.4882621710959207

Epoch: 6| Step: 3
Training loss: 2.6128145493963695
Validation loss: 2.4843274359168874

Epoch: 6| Step: 4
Training loss: 2.809464660503738
Validation loss: 2.5186813550331113

Epoch: 6| Step: 5
Training loss: 2.9415863508835822
Validation loss: 2.4894528191079734

Epoch: 6| Step: 6
Training loss: 2.988707268958666
Validation loss: 2.487670400011064

Epoch: 6| Step: 7
Training loss: 3.181287508220679
Validation loss: 2.499136141761476

Epoch: 6| Step: 8
Training loss: 3.122787302572715
Validation loss: 2.5068515739213875

Epoch: 6| Step: 9
Training loss: 2.418965813523339
Validation loss: 2.5112236549418494

Epoch: 6| Step: 10
Training loss: 2.745333440154736
Validation loss: 2.511282556586231

Epoch: 6| Step: 11
Training loss: 3.305944037026663
Validation loss: 2.494188504562467

Epoch: 6| Step: 12
Training loss: 3.089301407740302
Validation loss: 2.508528481882112

Epoch: 6| Step: 13
Training loss: 2.4817967501898557
Validation loss: 2.5214296739170576

Epoch: 35| Step: 0
Training loss: 3.054866853799982
Validation loss: 2.4973372871574755

Epoch: 6| Step: 1
Training loss: 2.2254619890273823
Validation loss: 2.5005017566660426

Epoch: 6| Step: 2
Training loss: 3.2945547029322175
Validation loss: 2.5015995661220796

Epoch: 6| Step: 3
Training loss: 2.9648865305913863
Validation loss: 2.5109482644317973

Epoch: 6| Step: 4
Training loss: 3.1824741009469726
Validation loss: 2.505067948062997

Epoch: 6| Step: 5
Training loss: 2.671423890697671
Validation loss: 2.50056871077774

Epoch: 6| Step: 6
Training loss: 2.2578251716231783
Validation loss: 2.5060694379505395

Epoch: 6| Step: 7
Training loss: 3.5205995079511303
Validation loss: 2.498012368888331

Epoch: 6| Step: 8
Training loss: 2.8499132377401395
Validation loss: 2.509917068109878

Epoch: 6| Step: 9
Training loss: 2.8194232077547827
Validation loss: 2.509462919255451

Epoch: 6| Step: 10
Training loss: 3.054295663507721
Validation loss: 2.4984997811295626

Epoch: 6| Step: 11
Training loss: 2.0423215347820056
Validation loss: 2.4976289580393094

Epoch: 6| Step: 12
Training loss: 3.114072079411696
Validation loss: 2.5074018192537317

Epoch: 6| Step: 13
Training loss: 2.843423510243586
Validation loss: 2.5017553432545605

Epoch: 36| Step: 0
Training loss: 3.558203800413675
Validation loss: 2.500691456693517

Epoch: 6| Step: 1
Training loss: 2.4146318967827063
Validation loss: 2.49870477010364

Epoch: 6| Step: 2
Training loss: 3.140241912707476
Validation loss: 2.502945318109184

Epoch: 6| Step: 3
Training loss: 2.834052854692537
Validation loss: 2.5008083626062847

Epoch: 6| Step: 4
Training loss: 2.9456756125120003
Validation loss: 2.515820171020947

Epoch: 6| Step: 5
Training loss: 2.6434704499762165
Validation loss: 2.4960461483482224

Epoch: 6| Step: 6
Training loss: 1.8717074413166517
Validation loss: 2.4892141379309707

Epoch: 6| Step: 7
Training loss: 2.911892243854387
Validation loss: 2.5024431083827476

Epoch: 6| Step: 8
Training loss: 2.77108957544684
Validation loss: 2.502248236114856

Epoch: 6| Step: 9
Training loss: 2.4558326696682555
Validation loss: 2.4981194868307632

Epoch: 6| Step: 10
Training loss: 2.7887771417723877
Validation loss: 2.4950366089528933

Epoch: 6| Step: 11
Training loss: 3.7330286639646157
Validation loss: 2.5223346935378865

Epoch: 6| Step: 12
Training loss: 2.970429276805118
Validation loss: 2.496078035916669

Epoch: 6| Step: 13
Training loss: 2.664446224197558
Validation loss: 2.506438142362813

Epoch: 37| Step: 0
Training loss: 3.468145094356321
Validation loss: 2.4787348944056182

Epoch: 6| Step: 1
Training loss: 3.019720745185927
Validation loss: 2.5037349468082155

Epoch: 6| Step: 2
Training loss: 3.517593578620274
Validation loss: 2.512276608719111

Epoch: 6| Step: 3
Training loss: 2.4516840304709158
Validation loss: 2.5077856634426166

Epoch: 6| Step: 4
Training loss: 2.7031468737825244
Validation loss: 2.5007703558160643

Epoch: 6| Step: 5
Training loss: 2.444661111573433
Validation loss: 2.5010680234852236

Epoch: 6| Step: 6
Training loss: 2.4753387989929387
Validation loss: 2.4989024070403003

Epoch: 6| Step: 7
Training loss: 2.9019983838298353
Validation loss: 2.508192079972741

Epoch: 6| Step: 8
Training loss: 2.130278370894283
Validation loss: 2.5027218906294006

Epoch: 6| Step: 9
Training loss: 2.4612446911136066
Validation loss: 2.4955540871445634

Epoch: 6| Step: 10
Training loss: 3.164060992958746
Validation loss: 2.5155814163304044

Epoch: 6| Step: 11
Training loss: 3.5954049985045473
Validation loss: 2.5023998462938564

Epoch: 6| Step: 12
Training loss: 2.7699931503376467
Validation loss: 2.518133721540377

Epoch: 6| Step: 13
Training loss: 2.87466859980691
Validation loss: 2.5027052025224177

Epoch: 38| Step: 0
Training loss: 2.475969791184931
Validation loss: 2.509664501899594

Epoch: 6| Step: 1
Training loss: 3.3216159550888156
Validation loss: 2.5095318924460837

Epoch: 6| Step: 2
Training loss: 2.8721813814697574
Validation loss: 2.520326818924405

Epoch: 6| Step: 3
Training loss: 2.552111899287407
Validation loss: 2.5183682682244743

Epoch: 6| Step: 4
Training loss: 2.976721411440467
Validation loss: 2.5056415328544754

Epoch: 6| Step: 5
Training loss: 2.9021502054199977
Validation loss: 2.5126261450537264

Epoch: 6| Step: 6
Training loss: 2.743789248522491
Validation loss: 2.505757405711573

Epoch: 6| Step: 7
Training loss: 3.422646910117649
Validation loss: 2.4849617424441

Epoch: 6| Step: 8
Training loss: 2.2337480212236467
Validation loss: 2.501821050561451

Epoch: 6| Step: 9
Training loss: 3.1783696473368708
Validation loss: 2.4924949198964708

Epoch: 6| Step: 10
Training loss: 3.033264120241515
Validation loss: 2.5020790745629244

Epoch: 6| Step: 11
Training loss: 2.54788450115255
Validation loss: 2.48358309979689

Epoch: 6| Step: 12
Training loss: 2.495888953844276
Validation loss: 2.4995512344214403

Epoch: 6| Step: 13
Training loss: 3.3402797481313398
Validation loss: 2.5112476545324838

Epoch: 39| Step: 0
Training loss: 2.4470599575951697
Validation loss: 2.4871002210754884

Epoch: 6| Step: 1
Training loss: 2.921148036341145
Validation loss: 2.502474589690326

Epoch: 6| Step: 2
Training loss: 3.5073024319441135
Validation loss: 2.4957996039558052

Epoch: 6| Step: 3
Training loss: 2.7333468002669887
Validation loss: 2.496605760335345

Epoch: 6| Step: 4
Training loss: 3.0296485052407673
Validation loss: 2.4891585567189316

Epoch: 6| Step: 5
Training loss: 2.3269826659510633
Validation loss: 2.490295277123649

Epoch: 6| Step: 6
Training loss: 2.7344722185563337
Validation loss: 2.5050654806885606

Epoch: 6| Step: 7
Training loss: 3.0205717477775096
Validation loss: 2.4943937774351106

Epoch: 6| Step: 8
Training loss: 2.7123434944532883
Validation loss: 2.495757345840758

Epoch: 6| Step: 9
Training loss: 2.9290653636303414
Validation loss: 2.4688128256601747

Epoch: 6| Step: 10
Training loss: 2.1908841794704723
Validation loss: 2.4933727942074926

Epoch: 6| Step: 11
Training loss: 3.5921211863764766
Validation loss: 2.490124432595718

Epoch: 6| Step: 12
Training loss: 2.4186777976444813
Validation loss: 2.4908844968970985

Epoch: 6| Step: 13
Training loss: 3.3049943930250842
Validation loss: 2.4919870142738194

Epoch: 40| Step: 0
Training loss: 2.3651551438912612
Validation loss: 2.500972643708447

Epoch: 6| Step: 1
Training loss: 3.054862483249441
Validation loss: 2.488201539638369

Epoch: 6| Step: 2
Training loss: 2.648631851131978
Validation loss: 2.485556975213352

Epoch: 6| Step: 3
Training loss: 3.2560210573982324
Validation loss: 2.5017530427195025

Epoch: 6| Step: 4
Training loss: 2.6819825423296177
Validation loss: 2.507780774930154

Epoch: 6| Step: 5
Training loss: 2.6954478354270375
Validation loss: 2.5033400455666315

Epoch: 6| Step: 6
Training loss: 3.0959498743341514
Validation loss: 2.4942658107142055

Epoch: 6| Step: 7
Training loss: 2.932197167255492
Validation loss: 2.502238004063933

Epoch: 6| Step: 8
Training loss: 3.111120912748367
Validation loss: 2.5078909389570225

Epoch: 6| Step: 9
Training loss: 2.8310572139627395
Validation loss: 2.519818351727174

Epoch: 6| Step: 10
Training loss: 2.6043420554545214
Validation loss: 2.5051701030091484

Epoch: 6| Step: 11
Training loss: 2.749529364801415
Validation loss: 2.5087408688982458

Epoch: 6| Step: 12
Training loss: 2.8992188421037106
Validation loss: 2.495676526018271

Epoch: 6| Step: 13
Training loss: 3.131889682994948
Validation loss: 2.484067789912665

Epoch: 41| Step: 0
Training loss: 2.1646350970670762
Validation loss: 2.501723772965622

Epoch: 6| Step: 1
Training loss: 2.456517297697437
Validation loss: 2.497805972405128

Epoch: 6| Step: 2
Training loss: 2.8756192411196344
Validation loss: 2.5103004163818774

Epoch: 6| Step: 3
Training loss: 3.0529524224350997
Validation loss: 2.504448065372324

Epoch: 6| Step: 4
Training loss: 2.6468806459260827
Validation loss: 2.507165494585548

Epoch: 6| Step: 5
Training loss: 2.607681364370175
Validation loss: 2.497776220704506

Epoch: 6| Step: 6
Training loss: 2.8230259910519395
Validation loss: 2.5061993265439044

Epoch: 6| Step: 7
Training loss: 3.020337153934557
Validation loss: 2.496326239088053

Epoch: 6| Step: 8
Training loss: 3.14700231663922
Validation loss: 2.500714664958199

Epoch: 6| Step: 9
Training loss: 2.545269044396253
Validation loss: 2.4803232845550434

Epoch: 6| Step: 10
Training loss: 3.4129200994671236
Validation loss: 2.5039469909655434

Epoch: 6| Step: 11
Training loss: 3.28822790869809
Validation loss: 2.506014327758942

Epoch: 6| Step: 12
Training loss: 3.297074587597563
Validation loss: 2.503142579264425

Epoch: 6| Step: 13
Training loss: 1.9143381971208568
Validation loss: 2.4887631050652725

Epoch: 42| Step: 0
Training loss: 3.321951858621822
Validation loss: 2.5155476327855033

Epoch: 6| Step: 1
Training loss: 2.775317003856192
Validation loss: 2.4859407603583557

Epoch: 6| Step: 2
Training loss: 2.89517760685664
Validation loss: 2.490906895470927

Epoch: 6| Step: 3
Training loss: 2.8939694414087405
Validation loss: 2.491633242975133

Epoch: 6| Step: 4
Training loss: 2.8368641413959677
Validation loss: 2.5000020396316573

Epoch: 6| Step: 5
Training loss: 3.1575196988781733
Validation loss: 2.4987958166551416

Epoch: 6| Step: 6
Training loss: 2.7789268649465093
Validation loss: 2.497938626037606

Epoch: 6| Step: 7
Training loss: 2.9695123597116044
Validation loss: 2.4897444344208535

Epoch: 6| Step: 8
Training loss: 3.2753807254248133
Validation loss: 2.49382998475744

Epoch: 6| Step: 9
Training loss: 2.860104994013721
Validation loss: 2.5050411496470852

Epoch: 6| Step: 10
Training loss: 2.5102191915970327
Validation loss: 2.511830531494186

Epoch: 6| Step: 11
Training loss: 2.630007826209662
Validation loss: 2.5087022638903305

Epoch: 6| Step: 12
Training loss: 2.1420964662002997
Validation loss: 2.4932876366766537

Epoch: 6| Step: 13
Training loss: 2.9779722224593126
Validation loss: 2.50295387723598

Epoch: 43| Step: 0
Training loss: 2.612987279394569
Validation loss: 2.511304246474218

Epoch: 6| Step: 1
Training loss: 2.439788037927358
Validation loss: 2.4937810538500282

Epoch: 6| Step: 2
Training loss: 2.6709311084039298
Validation loss: 2.5004491300049128

Epoch: 6| Step: 3
Training loss: 2.7815762446361454
Validation loss: 2.4868033092404507

Epoch: 6| Step: 4
Training loss: 2.8098372676333154
Validation loss: 2.487326275213144

Epoch: 6| Step: 5
Training loss: 2.9096954595346105
Validation loss: 2.4923968658419686

Epoch: 6| Step: 6
Training loss: 3.0088007901021037
Validation loss: 2.496294830181145

Epoch: 6| Step: 7
Training loss: 2.677823945153563
Validation loss: 2.498512288915779

Epoch: 6| Step: 8
Training loss: 3.0350223938871497
Validation loss: 2.4921426783506417

Epoch: 6| Step: 9
Training loss: 2.6642765619185766
Validation loss: 2.5018669238384166

Epoch: 6| Step: 10
Training loss: 3.443615276934563
Validation loss: 2.4912425123802913

Epoch: 6| Step: 11
Training loss: 2.8397522377685736
Validation loss: 2.4923429376049175

Epoch: 6| Step: 12
Training loss: 2.982882940580644
Validation loss: 2.479094891962481

Epoch: 6| Step: 13
Training loss: 3.018061942908951
Validation loss: 2.5086260004436247

Epoch: 44| Step: 0
Training loss: 2.052936808933336
Validation loss: 2.5000982593382104

Epoch: 6| Step: 1
Training loss: 3.629699291878446
Validation loss: 2.4987209365412677

Epoch: 6| Step: 2
Training loss: 2.8659568868989425
Validation loss: 2.4918015436711265

Epoch: 6| Step: 3
Training loss: 2.6463295979301873
Validation loss: 2.484968704089618

Epoch: 6| Step: 4
Training loss: 3.0974924590209105
Validation loss: 2.4968430182505488

Epoch: 6| Step: 5
Training loss: 2.9411038956383306
Validation loss: 2.5011916473814515

Epoch: 6| Step: 6
Training loss: 2.8312584815835122
Validation loss: 2.49589793210529

Epoch: 6| Step: 7
Training loss: 2.475224371093631
Validation loss: 2.4814866143863994

Epoch: 6| Step: 8
Training loss: 2.477003762197275
Validation loss: 2.491717580454206

Epoch: 6| Step: 9
Training loss: 2.4174795318336653
Validation loss: 2.508552675881171

Epoch: 6| Step: 10
Training loss: 2.961815052283087
Validation loss: 2.478704268931313

Epoch: 6| Step: 11
Training loss: 2.6834598602255353
Validation loss: 2.496762802923917

Epoch: 6| Step: 12
Training loss: 3.127602066094389
Validation loss: 2.509224764746547

Epoch: 6| Step: 13
Training loss: 3.642717799559022
Validation loss: 2.50963161834233

Epoch: 45| Step: 0
Training loss: 2.9341674731303216
Validation loss: 2.4902700492335215

Epoch: 6| Step: 1
Training loss: 2.433200173675516
Validation loss: 2.5023550180349994

Epoch: 6| Step: 2
Training loss: 2.817297510082125
Validation loss: 2.500650175723307

Epoch: 6| Step: 3
Training loss: 2.621783147391912
Validation loss: 2.497991004888703

Epoch: 6| Step: 4
Training loss: 2.845731945847533
Validation loss: 2.4941347435477415

Epoch: 6| Step: 5
Training loss: 3.0052476127785757
Validation loss: 2.493183936269097

Epoch: 6| Step: 6
Training loss: 2.84021060888016
Validation loss: 2.478492989287201

Epoch: 6| Step: 7
Training loss: 3.06826488754899
Validation loss: 2.5121677789414245

Epoch: 6| Step: 8
Training loss: 3.1024408514023594
Validation loss: 2.4975918256411047

Epoch: 6| Step: 9
Training loss: 2.7088899382816183
Validation loss: 2.49450493142138

Epoch: 6| Step: 10
Training loss: 2.8356050659044034
Validation loss: 2.5022803356117818

Epoch: 6| Step: 11
Training loss: 3.253323836026113
Validation loss: 2.4914628030010966

Epoch: 6| Step: 12
Training loss: 2.8176143346163
Validation loss: 2.5020540310626456

Epoch: 6| Step: 13
Training loss: 2.688244916010182
Validation loss: 2.504298131116576

Epoch: 46| Step: 0
Training loss: 2.5545747597925454
Validation loss: 2.487795225002307

Epoch: 6| Step: 1
Training loss: 3.529366455067781
Validation loss: 2.4991788561546695

Epoch: 6| Step: 2
Training loss: 2.898210460068352
Validation loss: 2.4785468620269264

Epoch: 6| Step: 3
Training loss: 3.0161840681576138
Validation loss: 2.4894877723631295

Epoch: 6| Step: 4
Training loss: 2.921982217545288
Validation loss: 2.48123734316154

Epoch: 6| Step: 5
Training loss: 2.7478878406307414
Validation loss: 2.4648995341889766

Epoch: 6| Step: 6
Training loss: 2.365776825118356
Validation loss: 2.4811760161906085

Epoch: 6| Step: 7
Training loss: 2.8929760419036175
Validation loss: 2.4845240212828683

Epoch: 6| Step: 8
Training loss: 2.466347503204137
Validation loss: 2.4874895612044483

Epoch: 6| Step: 9
Training loss: 2.852313384388404
Validation loss: 2.5083394552928864

Epoch: 6| Step: 10
Training loss: 3.042594210843824
Validation loss: 2.4910106603112316

Epoch: 6| Step: 11
Training loss: 3.230610744026421
Validation loss: 2.512124400623206

Epoch: 6| Step: 12
Training loss: 2.544804579870809
Validation loss: 2.5055919608722697

Epoch: 6| Step: 13
Training loss: 2.420900210202558
Validation loss: 2.4863648337751694

Epoch: 47| Step: 0
Training loss: 3.033962648386865
Validation loss: 2.485474917063544

Epoch: 6| Step: 1
Training loss: 2.502958359332705
Validation loss: 2.4949666174987546

Epoch: 6| Step: 2
Training loss: 2.404185511770276
Validation loss: 2.4993204495573123

Epoch: 6| Step: 3
Training loss: 2.8115493015319983
Validation loss: 2.4861323824582993

Epoch: 6| Step: 4
Training loss: 2.3918285456866824
Validation loss: 2.4901838188983128

Epoch: 6| Step: 5
Training loss: 2.8814346618393447
Validation loss: 2.4740896153658145

Epoch: 6| Step: 6
Training loss: 2.773771625862552
Validation loss: 2.5034319905999403

Epoch: 6| Step: 7
Training loss: 2.786785403631714
Validation loss: 2.4925207187315084

Epoch: 6| Step: 8
Training loss: 3.0110822071723
Validation loss: 2.4961240809822653

Epoch: 6| Step: 9
Training loss: 3.357576962495727
Validation loss: 2.5003771251365148

Epoch: 6| Step: 10
Training loss: 3.1124307770289246
Validation loss: 2.4855820523943546

Epoch: 6| Step: 11
Training loss: 2.742317218375053
Validation loss: 2.4997163714238293

Epoch: 6| Step: 12
Training loss: 2.999323291750167
Validation loss: 2.4848223940121166

Epoch: 6| Step: 13
Training loss: 2.973782099341718
Validation loss: 2.488968495786874

Epoch: 48| Step: 0
Training loss: 3.378062660002017
Validation loss: 2.5113493294406917

Epoch: 6| Step: 1
Training loss: 2.930307388846338
Validation loss: 2.5041947336121932

Epoch: 6| Step: 2
Training loss: 3.1090926612451577
Validation loss: 2.4982735753721697

Epoch: 6| Step: 3
Training loss: 2.8413990069955974
Validation loss: 2.4973463238574034

Epoch: 6| Step: 4
Training loss: 2.337493888316605
Validation loss: 2.506583979272535

Epoch: 6| Step: 5
Training loss: 3.1300462796138357
Validation loss: 2.4924338503782866

Epoch: 6| Step: 6
Training loss: 2.767123059083005
Validation loss: 2.498202256920322

Epoch: 6| Step: 7
Training loss: 2.7966076600583207
Validation loss: 2.4987108290673072

Epoch: 6| Step: 8
Training loss: 2.8019313180144803
Validation loss: 2.480630489182867

Epoch: 6| Step: 9
Training loss: 2.2693976200439905
Validation loss: 2.4792313919311364

Epoch: 6| Step: 10
Training loss: 2.349791103574578
Validation loss: 2.492826623827906

Epoch: 6| Step: 11
Training loss: 2.3003861973817554
Validation loss: 2.4884857224053785

Epoch: 6| Step: 12
Training loss: 3.721075789243868
Validation loss: 2.4982631926142096

Epoch: 6| Step: 13
Training loss: 2.4553726493048558
Validation loss: 2.4820412708170445

Epoch: 49| Step: 0
Training loss: 2.46004060417098
Validation loss: 2.4918180100437817

Epoch: 6| Step: 1
Training loss: 2.845389428059796
Validation loss: 2.4690290713623746

Epoch: 6| Step: 2
Training loss: 2.769320416731535
Validation loss: 2.4908528546959405

Epoch: 6| Step: 3
Training loss: 2.379329148961253
Validation loss: 2.479524231092466

Epoch: 6| Step: 4
Training loss: 2.06530986465376
Validation loss: 2.4747494290335825

Epoch: 6| Step: 5
Training loss: 2.8312023975673677
Validation loss: 2.4955371800613944

Epoch: 6| Step: 6
Training loss: 3.49655745004495
Validation loss: 2.4800004295602798

Epoch: 6| Step: 7
Training loss: 2.688399053607099
Validation loss: 2.5004783828962704

Epoch: 6| Step: 8
Training loss: 2.954880127258513
Validation loss: 2.4585537534423625

Epoch: 6| Step: 9
Training loss: 2.9737909184158586
Validation loss: 2.503132823013028

Epoch: 6| Step: 10
Training loss: 2.6389646106586184
Validation loss: 2.5096590562382137

Epoch: 6| Step: 11
Training loss: 3.4697976119854093
Validation loss: 2.4995019473006836

Epoch: 6| Step: 12
Training loss: 3.1690900631424324
Validation loss: 2.4989646870060427

Epoch: 6| Step: 13
Training loss: 2.6551996286059216
Validation loss: 2.5022919434163176

Epoch: 50| Step: 0
Training loss: 3.0723128075684007
Validation loss: 2.474364164492532

Epoch: 6| Step: 1
Training loss: 2.6806873647097405
Validation loss: 2.509274836072202

Epoch: 6| Step: 2
Training loss: 2.665290795469429
Validation loss: 2.4925666186658115

Epoch: 6| Step: 3
Training loss: 2.3870265031804707
Validation loss: 2.4973023051811705

Epoch: 6| Step: 4
Training loss: 2.729351202474719
Validation loss: 2.4758691267058492

Epoch: 6| Step: 5
Training loss: 2.3970798290520374
Validation loss: 2.484359774185262

Epoch: 6| Step: 6
Training loss: 3.2042145155437227
Validation loss: 2.4771418790628266

Epoch: 6| Step: 7
Training loss: 2.8183111555451457
Validation loss: 2.4971435291796125

Epoch: 6| Step: 8
Training loss: 3.4518875045038766
Validation loss: 2.488667768757514

Epoch: 6| Step: 9
Training loss: 2.3788401026056056
Validation loss: 2.4794740997265894

Epoch: 6| Step: 10
Training loss: 2.6035179143897005
Validation loss: 2.4852822926859557

Epoch: 6| Step: 11
Training loss: 3.311154362127937
Validation loss: 2.496342964190274

Epoch: 6| Step: 12
Training loss: 2.312573509078965
Validation loss: 2.5078026944467338

Epoch: 6| Step: 13
Training loss: 3.5420508830779083
Validation loss: 2.488847080399371

Epoch: 51| Step: 0
Training loss: 3.3419478363951947
Validation loss: 2.4889973603742352

Epoch: 6| Step: 1
Training loss: 2.6210132478497803
Validation loss: 2.4842537821800614

Epoch: 6| Step: 2
Training loss: 2.9143856575067675
Validation loss: 2.493677249052551

Epoch: 6| Step: 3
Training loss: 3.3697033044627864
Validation loss: 2.498011921433614

Epoch: 6| Step: 4
Training loss: 2.606051950225273
Validation loss: 2.4829043406055016

Epoch: 6| Step: 5
Training loss: 2.605888550208623
Validation loss: 2.498402945761369

Epoch: 6| Step: 6
Training loss: 2.213673008032785
Validation loss: 2.493624797067885

Epoch: 6| Step: 7
Training loss: 2.550004031608237
Validation loss: 2.4883604931642282

Epoch: 6| Step: 8
Training loss: 2.400803681755103
Validation loss: 2.477666904987225

Epoch: 6| Step: 9
Training loss: 2.631962941914704
Validation loss: 2.484290475169136

Epoch: 6| Step: 10
Training loss: 2.5304645214416466
Validation loss: 2.484004999182124

Epoch: 6| Step: 11
Training loss: 2.799164756447936
Validation loss: 2.4854729743285797

Epoch: 6| Step: 12
Training loss: 3.5959473899412915
Validation loss: 2.4793109770795403

Epoch: 6| Step: 13
Training loss: 3.6197703555277942
Validation loss: 2.496230727426201

Epoch: 52| Step: 0
Training loss: 2.790255593244957
Validation loss: 2.4881508886543573

Epoch: 6| Step: 1
Training loss: 3.206277626320125
Validation loss: 2.4937214489139046

Epoch: 6| Step: 2
Training loss: 3.129150076329883
Validation loss: 2.483039474801992

Epoch: 6| Step: 3
Training loss: 3.231917917663391
Validation loss: 2.4815462879824848

Epoch: 6| Step: 4
Training loss: 2.577820916015856
Validation loss: 2.4941219321713595

Epoch: 6| Step: 5
Training loss: 2.8678641287462883
Validation loss: 2.4825792344800015

Epoch: 6| Step: 6
Training loss: 3.4143046766758967
Validation loss: 2.494457232647462

Epoch: 6| Step: 7
Training loss: 2.9081552474651993
Validation loss: 2.4773907759077254

Epoch: 6| Step: 8
Training loss: 2.5496659228326757
Validation loss: 2.4865798345257257

Epoch: 6| Step: 9
Training loss: 2.6118294142710985
Validation loss: 2.498395440768708

Epoch: 6| Step: 10
Training loss: 2.0493166971013315
Validation loss: 2.4974600635798354

Epoch: 6| Step: 11
Training loss: 2.7200061044904986
Validation loss: 2.4781962907002923

Epoch: 6| Step: 12
Training loss: 2.9676656248412248
Validation loss: 2.48492865682306

Epoch: 6| Step: 13
Training loss: 2.00520303568615
Validation loss: 2.480225606184092

Epoch: 53| Step: 0
Training loss: 2.74505864871104
Validation loss: 2.467407278869748

Epoch: 6| Step: 1
Training loss: 3.1307844413599795
Validation loss: 2.4746780583459493

Epoch: 6| Step: 2
Training loss: 3.13136238916745
Validation loss: 2.491667800388894

Epoch: 6| Step: 3
Training loss: 2.5504079081083675
Validation loss: 2.4792631162759218

Epoch: 6| Step: 4
Training loss: 2.3745719122312177
Validation loss: 2.4659941767060674

Epoch: 6| Step: 5
Training loss: 3.1275261396235075
Validation loss: 2.4784416692521827

Epoch: 6| Step: 6
Training loss: 2.522708752163473
Validation loss: 2.4721461677820225

Epoch: 6| Step: 7
Training loss: 2.7998399416271047
Validation loss: 2.4874702190880287

Epoch: 6| Step: 8
Training loss: 2.6525831156660025
Validation loss: 2.4893245613164434

Epoch: 6| Step: 9
Training loss: 2.7769619750406256
Validation loss: 2.4961773626656854

Epoch: 6| Step: 10
Training loss: 3.513797132243132
Validation loss: 2.4740101829669605

Epoch: 6| Step: 11
Training loss: 3.0377938336451376
Validation loss: 2.4753746412917037

Epoch: 6| Step: 12
Training loss: 2.5504808234380234
Validation loss: 2.48097197053449

Epoch: 6| Step: 13
Training loss: 2.5814953592728984
Validation loss: 2.4859129425952218

Epoch: 54| Step: 0
Training loss: 3.0843517236884517
Validation loss: 2.4837839573201808

Epoch: 6| Step: 1
Training loss: 3.1344505841012014
Validation loss: 2.4917992493787646

Epoch: 6| Step: 2
Training loss: 2.5769608152146697
Validation loss: 2.463089568684838

Epoch: 6| Step: 3
Training loss: 2.676794865326366
Validation loss: 2.4922260820589455

Epoch: 6| Step: 4
Training loss: 3.4373980420337475
Validation loss: 2.5007461480343163

Epoch: 6| Step: 5
Training loss: 2.557309546217145
Validation loss: 2.479937627850224

Epoch: 6| Step: 6
Training loss: 3.0676977462888106
Validation loss: 2.471038121976571

Epoch: 6| Step: 7
Training loss: 2.4963796150432658
Validation loss: 2.4919179880656555

Epoch: 6| Step: 8
Training loss: 2.5811979533344775
Validation loss: 2.496550169116066

Epoch: 6| Step: 9
Training loss: 2.3944095748679337
Validation loss: 2.482207561366608

Epoch: 6| Step: 10
Training loss: 2.843194928335498
Validation loss: 2.4855245039956406

Epoch: 6| Step: 11
Training loss: 3.3441344423418493
Validation loss: 2.477301703657542

Epoch: 6| Step: 12
Training loss: 2.7127642454476937
Validation loss: 2.4899389941665846

Epoch: 6| Step: 13
Training loss: 2.201367373784206
Validation loss: 2.4857118187801914

Epoch: 55| Step: 0
Training loss: 3.088584672307874
Validation loss: 2.5115722119498396

Epoch: 6| Step: 1
Training loss: 2.2188619665988347
Validation loss: 2.482267459302111

Epoch: 6| Step: 2
Training loss: 2.3548641915655715
Validation loss: 2.478107169814589

Epoch: 6| Step: 3
Training loss: 3.2832904102856824
Validation loss: 2.4931632625074265

Epoch: 6| Step: 4
Training loss: 3.090631628077606
Validation loss: 2.497463639900318

Epoch: 6| Step: 5
Training loss: 2.5819808331759906
Validation loss: 2.4928180314716553

Epoch: 6| Step: 6
Training loss: 2.9582436418145037
Validation loss: 2.475803319827439

Epoch: 6| Step: 7
Training loss: 2.121746489688131
Validation loss: 2.506414562108337

Epoch: 6| Step: 8
Training loss: 2.9195459232262726
Validation loss: 2.496581209248303

Epoch: 6| Step: 9
Training loss: 2.5982367992596163
Validation loss: 2.4909212527653986

Epoch: 6| Step: 10
Training loss: 2.569108860909339
Validation loss: 2.5049913467733615

Epoch: 6| Step: 11
Training loss: 3.41200609929746
Validation loss: 2.468293735205663

Epoch: 6| Step: 12
Training loss: 2.9274006374055337
Validation loss: 2.489289446139963

Epoch: 6| Step: 13
Training loss: 3.3501275109463533
Validation loss: 2.4817510756287082

Epoch: 56| Step: 0
Training loss: 2.416359114534064
Validation loss: 2.4688247590423553

Epoch: 6| Step: 1
Training loss: 3.634839876575683
Validation loss: 2.4897175184340075

Epoch: 6| Step: 2
Training loss: 2.859864906908472
Validation loss: 2.4862730288563606

Epoch: 6| Step: 3
Training loss: 3.061550226657116
Validation loss: 2.5032622402917077

Epoch: 6| Step: 4
Training loss: 2.6583990939944364
Validation loss: 2.47982838576254

Epoch: 6| Step: 5
Training loss: 2.9038453357168748
Validation loss: 2.475049703096259

Epoch: 6| Step: 6
Training loss: 2.823026497781722
Validation loss: 2.4709170939057734

Epoch: 6| Step: 7
Training loss: 2.9340158456011736
Validation loss: 2.482711685099745

Epoch: 6| Step: 8
Training loss: 1.9152452201310577
Validation loss: 2.489059175444142

Epoch: 6| Step: 9
Training loss: 2.348805379575031
Validation loss: 2.494401601767309

Epoch: 6| Step: 10
Training loss: 2.7618274370575255
Validation loss: 2.5011692122754585

Epoch: 6| Step: 11
Training loss: 3.269530374943879
Validation loss: 2.48254034862835

Epoch: 6| Step: 12
Training loss: 2.3197806933765417
Validation loss: 2.4926166111634287

Epoch: 6| Step: 13
Training loss: 3.357696539721308
Validation loss: 2.4688776153814915

Epoch: 57| Step: 0
Training loss: 2.7690183866805844
Validation loss: 2.5001370105321152

Epoch: 6| Step: 1
Training loss: 2.8973147950378833
Validation loss: 2.4874940335482565

Epoch: 6| Step: 2
Training loss: 2.467173785412523
Validation loss: 2.4906857435719334

Epoch: 6| Step: 3
Training loss: 2.269394048066124
Validation loss: 2.48380699069995

Epoch: 6| Step: 4
Training loss: 3.2033612420027087
Validation loss: 2.4831854315440873

Epoch: 6| Step: 5
Training loss: 2.824524331345768
Validation loss: 2.5076458637643624

Epoch: 6| Step: 6
Training loss: 3.0246053012572656
Validation loss: 2.4996029005207556

Epoch: 6| Step: 7
Training loss: 2.723430244405496
Validation loss: 2.484014000787642

Epoch: 6| Step: 8
Training loss: 2.3986995193552847
Validation loss: 2.4882458470702864

Epoch: 6| Step: 9
Training loss: 2.6442980980470883
Validation loss: 2.4927663049640514

Epoch: 6| Step: 10
Training loss: 3.090035877451585
Validation loss: 2.482619714111916

Epoch: 6| Step: 11
Training loss: 3.2296131112547632
Validation loss: 2.469884036419461

Epoch: 6| Step: 12
Training loss: 2.8163038174312156
Validation loss: 2.496843320115863

Epoch: 6| Step: 13
Training loss: 3.19269990323537
Validation loss: 2.4912182228193873

Epoch: 58| Step: 0
Training loss: 2.5510003315661076
Validation loss: 2.483947526227083

Epoch: 6| Step: 1
Training loss: 3.0854558254919175
Validation loss: 2.481762486083866

Epoch: 6| Step: 2
Training loss: 2.9450468150953095
Validation loss: 2.4956006277731855

Epoch: 6| Step: 3
Training loss: 2.4853066670797697
Validation loss: 2.4867268071826265

Epoch: 6| Step: 4
Training loss: 2.4518481776792704
Validation loss: 2.479535554606783

Epoch: 6| Step: 5
Training loss: 2.8910195571095407
Validation loss: 2.5017189217959337

Epoch: 6| Step: 6
Training loss: 2.7120164818220704
Validation loss: 2.469950825123374

Epoch: 6| Step: 7
Training loss: 2.852613114463745
Validation loss: 2.4853587231640777

Epoch: 6| Step: 8
Training loss: 2.874534901026042
Validation loss: 2.4788383486402594

Epoch: 6| Step: 9
Training loss: 3.013371549662185
Validation loss: 2.468406480965786

Epoch: 6| Step: 10
Training loss: 3.3380554765647656
Validation loss: 2.488548956373395

Epoch: 6| Step: 11
Training loss: 3.0936764795063936
Validation loss: 2.4677993503797246

Epoch: 6| Step: 12
Training loss: 2.465596079686964
Validation loss: 2.494713799625165

Epoch: 6| Step: 13
Training loss: 2.5715839059022
Validation loss: 2.4792216563638747

Epoch: 59| Step: 0
Training loss: 2.9185409699767138
Validation loss: 2.4733455777769717

Epoch: 6| Step: 1
Training loss: 3.654558882910783
Validation loss: 2.4825901723068453

Epoch: 6| Step: 2
Training loss: 2.844069578218344
Validation loss: 2.4754216959489104

Epoch: 6| Step: 3
Training loss: 2.566423529301134
Validation loss: 2.4759988746087855

Epoch: 6| Step: 4
Training loss: 2.91825895896209
Validation loss: 2.506916692585063

Epoch: 6| Step: 5
Training loss: 2.061440166633005
Validation loss: 2.4859487499992285

Epoch: 6| Step: 6
Training loss: 2.1595462537944936
Validation loss: 2.4902347847320714

Epoch: 6| Step: 7
Training loss: 2.695885196601594
Validation loss: 2.470812647072223

Epoch: 6| Step: 8
Training loss: 2.2295217023342024
Validation loss: 2.487576033852992

Epoch: 6| Step: 9
Training loss: 3.0621834416172304
Validation loss: 2.487623763575306

Epoch: 6| Step: 10
Training loss: 2.8877144671963633
Validation loss: 2.472391285641717

Epoch: 6| Step: 11
Training loss: 3.1137128313036824
Validation loss: 2.497028714995803

Epoch: 6| Step: 12
Training loss: 3.43474510080016
Validation loss: 2.4961968000960884

Epoch: 6| Step: 13
Training loss: 2.793065380212151
Validation loss: 2.478012089795766

Epoch: 60| Step: 0
Training loss: 2.345261658505654
Validation loss: 2.493051375156328

Epoch: 6| Step: 1
Training loss: 2.142471742031916
Validation loss: 2.497858256022866

Epoch: 6| Step: 2
Training loss: 3.069373222510573
Validation loss: 2.482977731852959

Epoch: 6| Step: 3
Training loss: 2.6204500274871902
Validation loss: 2.4940191180815647

Epoch: 6| Step: 4
Training loss: 3.3539275248004046
Validation loss: 2.4844474108609402

Epoch: 6| Step: 5
Training loss: 2.6121840290475955
Validation loss: 2.4972966477805763

Epoch: 6| Step: 6
Training loss: 2.8842835846835517
Validation loss: 2.4925021988915614

Epoch: 6| Step: 7
Training loss: 2.8987793425225976
Validation loss: 2.479470563631082

Epoch: 6| Step: 8
Training loss: 2.2152787038813786
Validation loss: 2.488196432858373

Epoch: 6| Step: 9
Training loss: 2.3500304443335267
Validation loss: 2.5004278042550814

Epoch: 6| Step: 10
Training loss: 4.361479876586293
Validation loss: 2.4921284391919603

Epoch: 6| Step: 11
Training loss: 2.8066360378028796
Validation loss: 2.4885174513656287

Epoch: 6| Step: 12
Training loss: 2.212945356643326
Validation loss: 2.4901867642919275

Epoch: 6| Step: 13
Training loss: 3.162053730353129
Validation loss: 2.4788077203072305

Epoch: 61| Step: 0
Training loss: 2.7792037122584152
Validation loss: 2.482628226109711

Epoch: 6| Step: 1
Training loss: 2.7426839091170514
Validation loss: 2.497514867768209

Epoch: 6| Step: 2
Training loss: 2.89996083989505
Validation loss: 2.483316978532324

Epoch: 6| Step: 3
Training loss: 3.1037062915884617
Validation loss: 2.4981024442011037

Epoch: 6| Step: 4
Training loss: 2.9180354221800764
Validation loss: 2.501942058693514

Epoch: 6| Step: 5
Training loss: 2.810995504852685
Validation loss: 2.4799197252674015

Epoch: 6| Step: 6
Training loss: 3.039641572752963
Validation loss: 2.487977115796107

Epoch: 6| Step: 7
Training loss: 3.168093677696286
Validation loss: 2.5002971031683145

Epoch: 6| Step: 8
Training loss: 3.0240156227192667
Validation loss: 2.4853961064054957

Epoch: 6| Step: 9
Training loss: 2.905130478362973
Validation loss: 2.4819924184043782

Epoch: 6| Step: 10
Training loss: 2.504399624449515
Validation loss: 2.4898669273168035

Epoch: 6| Step: 11
Training loss: 2.914161332732517
Validation loss: 2.5006350695084394

Epoch: 6| Step: 12
Training loss: 1.9486918683340324
Validation loss: 2.4790225884615413

Epoch: 6| Step: 13
Training loss: 2.5092748258555426
Validation loss: 2.4910826333543987

Epoch: 62| Step: 0
Training loss: 2.7731187234274035
Validation loss: 2.4776869480696053

Epoch: 6| Step: 1
Training loss: 2.9732192279606036
Validation loss: 2.484788820589039

Epoch: 6| Step: 2
Training loss: 2.9748434073644687
Validation loss: 2.480597239344448

Epoch: 6| Step: 3
Training loss: 3.047272954530267
Validation loss: 2.484665660503688

Epoch: 6| Step: 4
Training loss: 2.9407567577457914
Validation loss: 2.4966353960889824

Epoch: 6| Step: 5
Training loss: 2.2216129368406405
Validation loss: 2.4920244657675443

Epoch: 6| Step: 6
Training loss: 2.2610132042601756
Validation loss: 2.4882887195602477

Epoch: 6| Step: 7
Training loss: 2.8915189443301115
Validation loss: 2.480826816709488

Epoch: 6| Step: 8
Training loss: 3.287970644836068
Validation loss: 2.4949733056501766

Epoch: 6| Step: 9
Training loss: 2.320232043171841
Validation loss: 2.491217080035687

Epoch: 6| Step: 10
Training loss: 3.247688351661317
Validation loss: 2.4942960950617796

Epoch: 6| Step: 11
Training loss: 2.5780149494149054
Validation loss: 2.482574269483787

Epoch: 6| Step: 12
Training loss: 2.9053681378998486
Validation loss: 2.484167743421231

Epoch: 6| Step: 13
Training loss: 2.693459047682093
Validation loss: 2.4942717514704644

Epoch: 63| Step: 0
Training loss: 2.146851776308387
Validation loss: 2.4840611033600277

Epoch: 6| Step: 1
Training loss: 3.212384048922388
Validation loss: 2.4709031215041346

Epoch: 6| Step: 2
Training loss: 3.2323457553348542
Validation loss: 2.484682678190491

Epoch: 6| Step: 3
Training loss: 3.0175237656916094
Validation loss: 2.4761684708931435

Epoch: 6| Step: 4
Training loss: 2.5097912738840167
Validation loss: 2.4889760158145626

Epoch: 6| Step: 5
Training loss: 2.9909321116067202
Validation loss: 2.4963441821627623

Epoch: 6| Step: 6
Training loss: 2.627077279826326
Validation loss: 2.4917369713945887

Epoch: 6| Step: 7
Training loss: 2.4276609156474684
Validation loss: 2.4832232903958285

Epoch: 6| Step: 8
Training loss: 2.710508900821823
Validation loss: 2.494842673324109

Epoch: 6| Step: 9
Training loss: 2.0312234730088776
Validation loss: 2.472405039142228

Epoch: 6| Step: 10
Training loss: 3.2516270012899047
Validation loss: 2.4812924085407504

Epoch: 6| Step: 11
Training loss: 3.240756461292062
Validation loss: 2.499427547338533

Epoch: 6| Step: 12
Training loss: 2.6348215469070024
Validation loss: 2.4873181998121865

Epoch: 6| Step: 13
Training loss: 3.206009324467759
Validation loss: 2.472954702808322

Epoch: 64| Step: 0
Training loss: 2.260660770672184
Validation loss: 2.4726148934084105

Epoch: 6| Step: 1
Training loss: 3.042165549835344
Validation loss: 2.485624125608331

Epoch: 6| Step: 2
Training loss: 3.232017358091217
Validation loss: 2.4793516031309966

Epoch: 6| Step: 3
Training loss: 2.3694477432583794
Validation loss: 2.4678990798082587

Epoch: 6| Step: 4
Training loss: 2.814770269692107
Validation loss: 2.4730265026420373

Epoch: 6| Step: 5
Training loss: 3.0347722619473054
Validation loss: 2.500710691935081

Epoch: 6| Step: 6
Training loss: 2.8911142296089687
Validation loss: 2.4909482596927166

Epoch: 6| Step: 7
Training loss: 2.5662131969936395
Validation loss: 2.4878328787122985

Epoch: 6| Step: 8
Training loss: 3.574710732874825
Validation loss: 2.4694605508714913

Epoch: 6| Step: 9
Training loss: 2.9716835385490987
Validation loss: 2.5056844770525504

Epoch: 6| Step: 10
Training loss: 2.968849903232699
Validation loss: 2.4758344740673133

Epoch: 6| Step: 11
Training loss: 2.452849354413013
Validation loss: 2.4831906874869167

Epoch: 6| Step: 12
Training loss: 2.4892149989268844
Validation loss: 2.4709978043260232

Epoch: 6| Step: 13
Training loss: 2.3761631978177706
Validation loss: 2.4885087596549065

Epoch: 65| Step: 0
Training loss: 2.976879833857432
Validation loss: 2.483237193475718

Epoch: 6| Step: 1
Training loss: 2.3941704881236827
Validation loss: 2.4749396496513603

Epoch: 6| Step: 2
Training loss: 3.0420177379043354
Validation loss: 2.4842091156262764

Epoch: 6| Step: 3
Training loss: 2.3725441733811357
Validation loss: 2.5056544009463617

Epoch: 6| Step: 4
Training loss: 3.350816621458066
Validation loss: 2.488110400096154

Epoch: 6| Step: 5
Training loss: 2.441616201909956
Validation loss: 2.490911676098957

Epoch: 6| Step: 6
Training loss: 2.969662014260692
Validation loss: 2.4829427303187193

Epoch: 6| Step: 7
Training loss: 2.181456364267152
Validation loss: 2.504195163582339

Epoch: 6| Step: 8
Training loss: 3.2836337195792575
Validation loss: 2.4920374988170697

Epoch: 6| Step: 9
Training loss: 3.052197155875177
Validation loss: 2.4777597002715503

Epoch: 6| Step: 10
Training loss: 3.09135390462222
Validation loss: 2.477534631684283

Epoch: 6| Step: 11
Training loss: 2.796176588777075
Validation loss: 2.4876067407595865

Epoch: 6| Step: 12
Training loss: 2.31271897387556
Validation loss: 2.4858097188492643

Epoch: 6| Step: 13
Training loss: 2.759990664065507
Validation loss: 2.4693997058966612

Epoch: 66| Step: 0
Training loss: 3.0305335387787884
Validation loss: 2.4908835314989095

Epoch: 6| Step: 1
Training loss: 3.0954329411867074
Validation loss: 2.479983318236696

Epoch: 6| Step: 2
Training loss: 2.790318395980295
Validation loss: 2.4652027644633896

Epoch: 6| Step: 3
Training loss: 2.762066032879919
Validation loss: 2.4768880724120708

Epoch: 6| Step: 4
Training loss: 1.9408223983939241
Validation loss: 2.4737709320712726

Epoch: 6| Step: 5
Training loss: 3.259562582614494
Validation loss: 2.499793352795059

Epoch: 6| Step: 6
Training loss: 2.467405508410024
Validation loss: 2.4805580165084833

Epoch: 6| Step: 7
Training loss: 2.773888521728179
Validation loss: 2.4771790189144354

Epoch: 6| Step: 8
Training loss: 2.75752935495946
Validation loss: 2.4740798248528435

Epoch: 6| Step: 9
Training loss: 3.0541851284272297
Validation loss: 2.481891120203013

Epoch: 6| Step: 10
Training loss: 2.931904597282442
Validation loss: 2.493945403123701

Epoch: 6| Step: 11
Training loss: 2.9921153087223957
Validation loss: 2.459451485432306

Epoch: 6| Step: 12
Training loss: 2.5322730740160546
Validation loss: 2.492288233643243

Epoch: 6| Step: 13
Training loss: 2.706361982394176
Validation loss: 2.48645880049112

Epoch: 67| Step: 0
Training loss: 3.354747050680252
Validation loss: 2.4711029036691823

Epoch: 6| Step: 1
Training loss: 2.111210229565699
Validation loss: 2.4928018000133743

Epoch: 6| Step: 2
Training loss: 2.2243560030480505
Validation loss: 2.4830679736507166

Epoch: 6| Step: 3
Training loss: 2.7410568123308376
Validation loss: 2.4961366905390743

Epoch: 6| Step: 4
Training loss: 2.94033287291838
Validation loss: 2.4596778178370204

Epoch: 6| Step: 5
Training loss: 2.431751907437301
Validation loss: 2.4873273574282555

Epoch: 6| Step: 6
Training loss: 2.4590197644705674
Validation loss: 2.4683599406636105

Epoch: 6| Step: 7
Training loss: 2.835081533507589
Validation loss: 2.479128808256157

Epoch: 6| Step: 8
Training loss: 2.1445430345333087
Validation loss: 2.477960610821975

Epoch: 6| Step: 9
Training loss: 3.047225540732709
Validation loss: 2.4798075112335276

Epoch: 6| Step: 10
Training loss: 3.0590809011495317
Validation loss: 2.4799974265847697

Epoch: 6| Step: 11
Training loss: 2.924217875972518
Validation loss: 2.503294606367287

Epoch: 6| Step: 12
Training loss: 3.196736435856424
Validation loss: 2.4790030246442774

Epoch: 6| Step: 13
Training loss: 4.0004253161333905
Validation loss: 2.4919204334795215

Epoch: 68| Step: 0
Training loss: 2.882697043652593
Validation loss: 2.4689548709090743

Epoch: 6| Step: 1
Training loss: 2.8181991478731154
Validation loss: 2.491890435070969

Epoch: 6| Step: 2
Training loss: 2.851028685051815
Validation loss: 2.4992850122108954

Epoch: 6| Step: 3
Training loss: 3.180862097333202
Validation loss: 2.5036071165570015

Epoch: 6| Step: 4
Training loss: 3.205655619533983
Validation loss: 2.492480922402195

Epoch: 6| Step: 5
Training loss: 2.9212882528873316
Validation loss: 2.4773814729052237

Epoch: 6| Step: 6
Training loss: 2.689591060029467
Validation loss: 2.5006931974361715

Epoch: 6| Step: 7
Training loss: 2.8042027471600863
Validation loss: 2.480090484056769

Epoch: 6| Step: 8
Training loss: 3.053543696201883
Validation loss: 2.497667815287614

Epoch: 6| Step: 9
Training loss: 2.9091796875
Validation loss: 2.4878861486187525

Epoch: 6| Step: 10
Training loss: 2.293490244945923
Validation loss: 2.504962337964743

Epoch: 6| Step: 11
Training loss: 2.705941733759969
Validation loss: 2.4657010391354888

Epoch: 6| Step: 12
Training loss: 2.4273604751860325
Validation loss: 2.472480690322457

Epoch: 6| Step: 13
Training loss: 1.8535234071268731
Validation loss: 2.4939972501136776

Epoch: 69| Step: 0
Training loss: 2.494600759912291
Validation loss: 2.499549710319396

Epoch: 6| Step: 1
Training loss: 3.08235273147089
Validation loss: 2.4817579419481786

Epoch: 6| Step: 2
Training loss: 2.751743110998151
Validation loss: 2.4780587902182294

Epoch: 6| Step: 3
Training loss: 3.019696743120103
Validation loss: 2.4707614066740877

Epoch: 6| Step: 4
Training loss: 3.428440988420828
Validation loss: 2.491728261591757

Epoch: 6| Step: 5
Training loss: 3.0477037134217437
Validation loss: 2.5020110429954356

Epoch: 6| Step: 6
Training loss: 2.4709542007431886
Validation loss: 2.4777196409886235

Epoch: 6| Step: 7
Training loss: 2.661833963680195
Validation loss: 2.4788491933477874

Epoch: 6| Step: 8
Training loss: 2.6835795350788003
Validation loss: 2.4685644358081817

Epoch: 6| Step: 9
Training loss: 2.9357862952307423
Validation loss: 2.4668516849060866

Epoch: 6| Step: 10
Training loss: 3.3327346899979924
Validation loss: 2.4942461526714244

Epoch: 6| Step: 11
Training loss: 1.939732465190569
Validation loss: 2.4658966678382903

Epoch: 6| Step: 12
Training loss: 2.504154377514162
Validation loss: 2.4893471191343046

Epoch: 6| Step: 13
Training loss: 1.9955895789372289
Validation loss: 2.4875341714305264

Epoch: 70| Step: 0
Training loss: 3.0712219910204213
Validation loss: 2.494407944052464

Epoch: 6| Step: 1
Training loss: 2.9053131562411023
Validation loss: 2.4922683244441313

Epoch: 6| Step: 2
Training loss: 2.7909645412246884
Validation loss: 2.469032651484863

Epoch: 6| Step: 3
Training loss: 2.8388065506187523
Validation loss: 2.4856411222937806

Epoch: 6| Step: 4
Training loss: 2.501081137535699
Validation loss: 2.4768003706186916

Epoch: 6| Step: 5
Training loss: 3.029740104985866
Validation loss: 2.483275749415435

Epoch: 6| Step: 6
Training loss: 2.991912430751631
Validation loss: 2.4948436690451246

Epoch: 6| Step: 7
Training loss: 2.9556299313370786
Validation loss: 2.4819040473933867

Epoch: 6| Step: 8
Training loss: 2.1975258092482126
Validation loss: 2.48406008370819

Epoch: 6| Step: 9
Training loss: 2.3550397441126334
Validation loss: 2.490134318056942

Epoch: 6| Step: 10
Training loss: 2.935725223811261
Validation loss: 2.4826589611697374

Epoch: 6| Step: 11
Training loss: 2.855464408234558
Validation loss: 2.4704633078950318

Epoch: 6| Step: 12
Training loss: 2.8517228590933734
Validation loss: 2.4708971214502813

Epoch: 6| Step: 13
Training loss: 2.822566011804013
Validation loss: 2.47220251153021

Epoch: 71| Step: 0
Training loss: 2.712907234948477
Validation loss: 2.4929691209869715

Epoch: 6| Step: 1
Training loss: 2.7155124197605467
Validation loss: 2.475198823879817

Epoch: 6| Step: 2
Training loss: 2.5054464141164123
Validation loss: 2.4828847082519867

Epoch: 6| Step: 3
Training loss: 2.7232454338347125
Validation loss: 2.4747916817482887

Epoch: 6| Step: 4
Training loss: 3.045898750601138
Validation loss: 2.4765624058003572

Epoch: 6| Step: 5
Training loss: 2.851682226724569
Validation loss: 2.5053681810448407

Epoch: 6| Step: 6
Training loss: 3.0278521498510163
Validation loss: 2.480159861147262

Epoch: 6| Step: 7
Training loss: 2.686330851478186
Validation loss: 2.4863682219011896

Epoch: 6| Step: 8
Training loss: 2.0642379605308427
Validation loss: 2.4765022963813483

Epoch: 6| Step: 9
Training loss: 3.5006815383015035
Validation loss: 2.4771279107247564

Epoch: 6| Step: 10
Training loss: 2.461426410852801
Validation loss: 2.486438158451775

Epoch: 6| Step: 11
Training loss: 3.0700202006815482
Validation loss: 2.4725315887016945

Epoch: 6| Step: 12
Training loss: 3.037627442751502
Validation loss: 2.497206636823285

Epoch: 6| Step: 13
Training loss: 2.332181737188043
Validation loss: 2.4789775970354357

Epoch: 72| Step: 0
Training loss: 2.5021479915636067
Validation loss: 2.467913608349025

Epoch: 6| Step: 1
Training loss: 2.696304448355685
Validation loss: 2.499579966545434

Epoch: 6| Step: 2
Training loss: 3.4422840466771207
Validation loss: 2.4764507032062695

Epoch: 6| Step: 3
Training loss: 2.1798851443140586
Validation loss: 2.4850550689640096

Epoch: 6| Step: 4
Training loss: 3.1973995490621396
Validation loss: 2.4859439371395795

Epoch: 6| Step: 5
Training loss: 2.9157333697329086
Validation loss: 2.486701553399339

Epoch: 6| Step: 6
Training loss: 2.4016274973922305
Validation loss: 2.473885467613383

Epoch: 6| Step: 7
Training loss: 2.674315915918227
Validation loss: 2.478938537825668

Epoch: 6| Step: 8
Training loss: 2.330403691303487
Validation loss: 2.4750750768019496

Epoch: 6| Step: 9
Training loss: 2.8761673920666544
Validation loss: 2.4798439805503123

Epoch: 6| Step: 10
Training loss: 2.714890206577561
Validation loss: 2.472802216230446

Epoch: 6| Step: 11
Training loss: 2.699785231066404
Validation loss: 2.47515222278748

Epoch: 6| Step: 12
Training loss: 2.828256677755064
Validation loss: 2.4930303306132573

Epoch: 6| Step: 13
Training loss: 3.7848614557224773
Validation loss: 2.483244895007225

Epoch: 73| Step: 0
Training loss: 2.586530265980566
Validation loss: 2.4801006793039906

Epoch: 6| Step: 1
Training loss: 2.8432023076423207
Validation loss: 2.470382125996266

Epoch: 6| Step: 2
Training loss: 2.3021699247573526
Validation loss: 2.476270920454937

Epoch: 6| Step: 3
Training loss: 3.5045068878833265
Validation loss: 2.4832745033536456

Epoch: 6| Step: 4
Training loss: 3.3469243178665344
Validation loss: 2.484129658505471

Epoch: 6| Step: 5
Training loss: 3.4184085933510335
Validation loss: 2.4876050629990734

Epoch: 6| Step: 6
Training loss: 2.4098568920525842
Validation loss: 2.472817510098049

Epoch: 6| Step: 7
Training loss: 2.732294653656859
Validation loss: 2.4914399474132405

Epoch: 6| Step: 8
Training loss: 2.8085732067985654
Validation loss: 2.48231947274657

Epoch: 6| Step: 9
Training loss: 2.696668643062639
Validation loss: 2.4904965279799356

Epoch: 6| Step: 10
Training loss: 2.6923353476728367
Validation loss: 2.46940351180111

Epoch: 6| Step: 11
Training loss: 2.5438141011027593
Validation loss: 2.4518435111835437

Epoch: 6| Step: 12
Training loss: 2.598369391507
Validation loss: 2.475436359503127

Epoch: 6| Step: 13
Training loss: 1.837885371169264
Validation loss: 2.4709247456478973

Epoch: 74| Step: 0
Training loss: 2.674492518692835
Validation loss: 2.4754698516092657

Epoch: 6| Step: 1
Training loss: 3.022293702461425
Validation loss: 2.477214810785016

Epoch: 6| Step: 2
Training loss: 2.67240320528201
Validation loss: 2.485734372255081

Epoch: 6| Step: 3
Training loss: 2.755246273325193
Validation loss: 2.508956323760204

Epoch: 6| Step: 4
Training loss: 2.8936669092628295
Validation loss: 2.488180395347674

Epoch: 6| Step: 5
Training loss: 3.1132446440072683
Validation loss: 2.478284748407546

Epoch: 6| Step: 6
Training loss: 2.6044215166639986
Validation loss: 2.495234229232033

Epoch: 6| Step: 7
Training loss: 2.7801291961288364
Validation loss: 2.4687472782558744

Epoch: 6| Step: 8
Training loss: 2.713406804126535
Validation loss: 2.488405444753113

Epoch: 6| Step: 9
Training loss: 2.6770617017849205
Validation loss: 2.4763099078621247

Epoch: 6| Step: 10
Training loss: 2.602625724108259
Validation loss: 2.4848893352224146

Epoch: 6| Step: 11
Training loss: 3.277581625706885
Validation loss: 2.4845467805566854

Epoch: 6| Step: 12
Training loss: 2.8379645551278667
Validation loss: 2.4886572882365408

Epoch: 6| Step: 13
Training loss: 2.120859937619644
Validation loss: 2.467571733869141

Epoch: 75| Step: 0
Training loss: 2.3499317281017977
Validation loss: 2.483851673774166

Epoch: 6| Step: 1
Training loss: 2.5159154688730885
Validation loss: 2.485183108682439

Epoch: 6| Step: 2
Training loss: 3.21998602088121
Validation loss: 2.4775532623728314

Epoch: 6| Step: 3
Training loss: 2.213335549724955
Validation loss: 2.493223726004141

Epoch: 6| Step: 4
Training loss: 2.7073511152111682
Validation loss: 2.4721230521994997

Epoch: 6| Step: 5
Training loss: 2.851394439343365
Validation loss: 2.490251427209432

Epoch: 6| Step: 6
Training loss: 3.0627165737257047
Validation loss: 2.4756542965525328

Epoch: 6| Step: 7
Training loss: 2.7829935844914915
Validation loss: 2.4834718791796666

Epoch: 6| Step: 8
Training loss: 3.5579665936793563
Validation loss: 2.4757878285057293

Epoch: 6| Step: 9
Training loss: 2.5834707613250787
Validation loss: 2.4828038643552093

Epoch: 6| Step: 10
Training loss: 3.060744580454205
Validation loss: 2.4805182390909652

Epoch: 6| Step: 11
Training loss: 2.4662665901844156
Validation loss: 2.4739610413999045

Epoch: 6| Step: 12
Training loss: 2.4522084267166817
Validation loss: 2.4725950886349923

Epoch: 6| Step: 13
Training loss: 3.0090286768633554
Validation loss: 2.47128452923132

Epoch: 76| Step: 0
Training loss: 2.892284514924318
Validation loss: 2.4778566222881797

Epoch: 6| Step: 1
Training loss: 2.676603182668874
Validation loss: 2.4984656168030956

Epoch: 6| Step: 2
Training loss: 3.0304227663717707
Validation loss: 2.4882893717290644

Epoch: 6| Step: 3
Training loss: 2.936718613608586
Validation loss: 2.4951161477072095

Epoch: 6| Step: 4
Training loss: 2.8332395725070136
Validation loss: 2.4597985734727277

Epoch: 6| Step: 5
Training loss: 2.682799731286955
Validation loss: 2.478743304942108

Epoch: 6| Step: 6
Training loss: 2.787532867785267
Validation loss: 2.4883133493748013

Epoch: 6| Step: 7
Training loss: 2.437193924687156
Validation loss: 2.4693346578678232

Epoch: 6| Step: 8
Training loss: 3.087158579617044
Validation loss: 2.4849777723567685

Epoch: 6| Step: 9
Training loss: 2.710890535942713
Validation loss: 2.4830058153230805

Epoch: 6| Step: 10
Training loss: 3.004509239046718
Validation loss: 2.49303454467769

Epoch: 6| Step: 11
Training loss: 2.3806271396746523
Validation loss: 2.4811783316716327

Epoch: 6| Step: 12
Training loss: 2.8619419936640322
Validation loss: 2.4685850948961208

Epoch: 6| Step: 13
Training loss: 2.4301303079775827
Validation loss: 2.461636706883845

Epoch: 77| Step: 0
Training loss: 2.737812083670675
Validation loss: 2.4788788211033688

Epoch: 6| Step: 1
Training loss: 3.105506676016446
Validation loss: 2.477610064154493

Epoch: 6| Step: 2
Training loss: 2.5197302451394004
Validation loss: 2.4622105553426508

Epoch: 6| Step: 3
Training loss: 2.591626228515852
Validation loss: 2.4774226997385593

Epoch: 6| Step: 4
Training loss: 2.37345544884872
Validation loss: 2.481536076979653

Epoch: 6| Step: 5
Training loss: 2.7338626054510127
Validation loss: 2.4917143549608127

Epoch: 6| Step: 6
Training loss: 2.9970629938408524
Validation loss: 2.4750675145388694

Epoch: 6| Step: 7
Training loss: 3.042324169284592
Validation loss: 2.5053616874345686

Epoch: 6| Step: 8
Training loss: 2.9654345822075623
Validation loss: 2.4908566473762392

Epoch: 6| Step: 9
Training loss: 2.158232951929073
Validation loss: 2.48120468212743

Epoch: 6| Step: 10
Training loss: 3.1149792031562895
Validation loss: 2.4910154674981477

Epoch: 6| Step: 11
Training loss: 2.4510209116858803
Validation loss: 2.493943227989497

Epoch: 6| Step: 12
Training loss: 3.00716910478614
Validation loss: 2.4956289523621904

Epoch: 6| Step: 13
Training loss: 3.1571049806952667
Validation loss: 2.4903235796997016

Epoch: 78| Step: 0
Training loss: 2.892814672921955
Validation loss: 2.495176622959031

Epoch: 6| Step: 1
Training loss: 2.908682840618683
Validation loss: 2.474795095041671

Epoch: 6| Step: 2
Training loss: 2.623869697999052
Validation loss: 2.4911787643198093

Epoch: 6| Step: 3
Training loss: 2.632648044056963
Validation loss: 2.476444737297576

Epoch: 6| Step: 4
Training loss: 3.195474261454039
Validation loss: 2.4803435283921647

Epoch: 6| Step: 5
Training loss: 2.4316312123311796
Validation loss: 2.4863468722996163

Epoch: 6| Step: 6
Training loss: 3.0729192873841225
Validation loss: 2.4845759111324073

Epoch: 6| Step: 7
Training loss: 2.7489587373047812
Validation loss: 2.479209058493436

Epoch: 6| Step: 8
Training loss: 2.769034573847154
Validation loss: 2.487751818450262

Epoch: 6| Step: 9
Training loss: 2.244065617967019
Validation loss: 2.4830288889600296

Epoch: 6| Step: 10
Training loss: 3.103454474008151
Validation loss: 2.4813080023927263

Epoch: 6| Step: 11
Training loss: 3.123851565098611
Validation loss: 2.477604346267444

Epoch: 6| Step: 12
Training loss: 2.077821408231322
Validation loss: 2.493935070191384

Epoch: 6| Step: 13
Training loss: 2.7917552952907925
Validation loss: 2.485660035153277

Epoch: 79| Step: 0
Training loss: 2.672114132893463
Validation loss: 2.503104219238622

Epoch: 6| Step: 1
Training loss: 2.4943304624430946
Validation loss: 2.478215364340388

Epoch: 6| Step: 2
Training loss: 2.184163409942252
Validation loss: 2.4664193269940586

Epoch: 6| Step: 3
Training loss: 3.110670270416008
Validation loss: 2.48348464742954

Epoch: 6| Step: 4
Training loss: 2.3758643735715315
Validation loss: 2.48572855032636

Epoch: 6| Step: 5
Training loss: 3.0041153020255016
Validation loss: 2.470109476215206

Epoch: 6| Step: 6
Training loss: 3.157944630345833
Validation loss: 2.4861467487641282

Epoch: 6| Step: 7
Training loss: 3.138862380944534
Validation loss: 2.472913496862726

Epoch: 6| Step: 8
Training loss: 2.852920334359882
Validation loss: 2.4820308831622837

Epoch: 6| Step: 9
Training loss: 2.4842225033963072
Validation loss: 2.4782620505878317

Epoch: 6| Step: 10
Training loss: 2.4001736895971457
Validation loss: 2.4609798575547117

Epoch: 6| Step: 11
Training loss: 3.2637089853328503
Validation loss: 2.4759053278716014

Epoch: 6| Step: 12
Training loss: 2.879971725007178
Validation loss: 2.479189321390823

Epoch: 6| Step: 13
Training loss: 2.945928291685977
Validation loss: 2.470698096708646

Epoch: 80| Step: 0
Training loss: 2.707428697966307
Validation loss: 2.4792784923034956

Epoch: 6| Step: 1
Training loss: 2.9589942050682425
Validation loss: 2.4532342064395523

Epoch: 6| Step: 2
Training loss: 2.2572976551642476
Validation loss: 2.4762583179256215

Epoch: 6| Step: 3
Training loss: 2.8081083130229247
Validation loss: 2.4575579049292844

Epoch: 6| Step: 4
Training loss: 2.8017304114314503
Validation loss: 2.4738027383592858

Epoch: 6| Step: 5
Training loss: 2.5766756549923535
Validation loss: 2.4726320147697582

Epoch: 6| Step: 6
Training loss: 2.9261042540119244
Validation loss: 2.470194092952508

Epoch: 6| Step: 7
Training loss: 2.7917016629734683
Validation loss: 2.4572063266092243

Epoch: 6| Step: 8
Training loss: 3.0241504390474234
Validation loss: 2.4871592971792595

Epoch: 6| Step: 9
Training loss: 2.5701017438289893
Validation loss: 2.47328937978817

Epoch: 6| Step: 10
Training loss: 3.2145058511101343
Validation loss: 2.4545686073179063

Epoch: 6| Step: 11
Training loss: 2.8722459621993734
Validation loss: 2.4707181382176064

Epoch: 6| Step: 12
Training loss: 2.7514254603575594
Validation loss: 2.4905784181072534

Epoch: 6| Step: 13
Training loss: 2.5539656152882535
Validation loss: 2.470102019142575

Epoch: 81| Step: 0
Training loss: 2.739117852373624
Validation loss: 2.4742160585589175

Epoch: 6| Step: 1
Training loss: 2.573881135835513
Validation loss: 2.4683837068515473

Epoch: 6| Step: 2
Training loss: 2.3938949262207907
Validation loss: 2.501477744088524

Epoch: 6| Step: 3
Training loss: 2.763036691306745
Validation loss: 2.488181608042822

Epoch: 6| Step: 4
Training loss: 1.926123907775787
Validation loss: 2.4702296435508586

Epoch: 6| Step: 5
Training loss: 2.362709669870664
Validation loss: 2.4802722649288125

Epoch: 6| Step: 6
Training loss: 2.741023063676756
Validation loss: 2.47571078672104

Epoch: 6| Step: 7
Training loss: 2.757016680390626
Validation loss: 2.487464826869766

Epoch: 6| Step: 8
Training loss: 3.201653119094466
Validation loss: 2.4684462302650996

Epoch: 6| Step: 9
Training loss: 2.887167022133685
Validation loss: 2.4755818469981423

Epoch: 6| Step: 10
Training loss: 2.8886921787128745
Validation loss: 2.4996397527968712

Epoch: 6| Step: 11
Training loss: 3.016149603717766
Validation loss: 2.472913953005562

Epoch: 6| Step: 12
Training loss: 3.2363027826029493
Validation loss: 2.4783859198950764

Epoch: 6| Step: 13
Training loss: 3.224349253448722
Validation loss: 2.459773745164459

Epoch: 82| Step: 0
Training loss: 2.860517096556562
Validation loss: 2.489407867894925

Epoch: 6| Step: 1
Training loss: 2.7617368791948276
Validation loss: 2.4696066156712493

Epoch: 6| Step: 2
Training loss: 2.47762297539705
Validation loss: 2.4936691078613284

Epoch: 6| Step: 3
Training loss: 3.262464536276811
Validation loss: 2.470796636280443

Epoch: 6| Step: 4
Training loss: 2.694911584199985
Validation loss: 2.487485713405501

Epoch: 6| Step: 5
Training loss: 2.2535998898160488
Validation loss: 2.4785290538668057

Epoch: 6| Step: 6
Training loss: 2.652741931808464
Validation loss: 2.4896989025741836

Epoch: 6| Step: 7
Training loss: 2.8861638466263058
Validation loss: 2.490243867795329

Epoch: 6| Step: 8
Training loss: 2.0894362007692315
Validation loss: 2.492497618794403

Epoch: 6| Step: 9
Training loss: 2.5202143726295962
Validation loss: 2.4778327172720154

Epoch: 6| Step: 10
Training loss: 3.0418979783265043
Validation loss: 2.457660605596995

Epoch: 6| Step: 11
Training loss: 2.506038240157722
Validation loss: 2.4851860166769035

Epoch: 6| Step: 12
Training loss: 3.363136208626686
Validation loss: 2.4690363572384326

Epoch: 6| Step: 13
Training loss: 3.540836925174085
Validation loss: 2.490487033059532

Epoch: 83| Step: 0
Training loss: 2.435306442372647
Validation loss: 2.472821131388398

Epoch: 6| Step: 1
Training loss: 2.534506504395914
Validation loss: 2.47760541617348

Epoch: 6| Step: 2
Training loss: 3.195031039425988
Validation loss: 2.490522070618442

Epoch: 6| Step: 3
Training loss: 2.377153624805623
Validation loss: 2.487650703246795

Epoch: 6| Step: 4
Training loss: 2.9093245783614967
Validation loss: 2.478651248763835

Epoch: 6| Step: 5
Training loss: 3.024026660539279
Validation loss: 2.4757290832035093

Epoch: 6| Step: 6
Training loss: 2.9062283422832134
Validation loss: 2.474116499831239

Epoch: 6| Step: 7
Training loss: 2.700139420053311
Validation loss: 2.4887990579057075

Epoch: 6| Step: 8
Training loss: 2.478168436177248
Validation loss: 2.4979852197361674

Epoch: 6| Step: 9
Training loss: 3.2360982680895867
Validation loss: 2.483441597034265

Epoch: 6| Step: 10
Training loss: 3.00065573837278
Validation loss: 2.485875907449411

Epoch: 6| Step: 11
Training loss: 2.4038269922519797
Validation loss: 2.4782726867901026

Epoch: 6| Step: 12
Training loss: 2.9705710196732147
Validation loss: 2.4759429211482415

Epoch: 6| Step: 13
Training loss: 2.1316038626614544
Validation loss: 2.492911611999919

Epoch: 84| Step: 0
Training loss: 2.649441599043686
Validation loss: 2.4719108273513575

Epoch: 6| Step: 1
Training loss: 2.7686048069206803
Validation loss: 2.4921647899301584

Epoch: 6| Step: 2
Training loss: 2.3786127820832554
Validation loss: 2.4791216564840703

Epoch: 6| Step: 3
Training loss: 2.5966967653514192
Validation loss: 2.4701214749455

Epoch: 6| Step: 4
Training loss: 3.016643134880667
Validation loss: 2.4740616612425965

Epoch: 6| Step: 5
Training loss: 2.8796996805116613
Validation loss: 2.4686982609062604

Epoch: 6| Step: 6
Training loss: 2.9336358485140948
Validation loss: 2.4463597219898197

Epoch: 6| Step: 7
Training loss: 2.9161724398453486
Validation loss: 2.4678717229965943

Epoch: 6| Step: 8
Training loss: 2.7323958727653963
Validation loss: 2.466679958719538

Epoch: 6| Step: 9
Training loss: 3.169911646047883
Validation loss: 2.4839045850002135

Epoch: 6| Step: 10
Training loss: 3.061819195492881
Validation loss: 2.4721983221011907

Epoch: 6| Step: 11
Training loss: 1.7500000681195926
Validation loss: 2.4722507070820936

Epoch: 6| Step: 12
Training loss: 3.0716071663066624
Validation loss: 2.4758365698481515

Epoch: 6| Step: 13
Training loss: 2.534715234987798
Validation loss: 2.4729761825399232

Epoch: 85| Step: 0
Training loss: 2.956528090448216
Validation loss: 2.4578490957879136

Epoch: 6| Step: 1
Training loss: 2.635431905307866
Validation loss: 2.4693442953746323

Epoch: 6| Step: 2
Training loss: 2.404433518469323
Validation loss: 2.481607708075621

Epoch: 6| Step: 3
Training loss: 2.5015474298751155
Validation loss: 2.479799229397404

Epoch: 6| Step: 4
Training loss: 2.6082403034361596
Validation loss: 2.4579732522382827

Epoch: 6| Step: 5
Training loss: 2.8525225133784753
Validation loss: 2.4661550714749203

Epoch: 6| Step: 6
Training loss: 2.7067124039993367
Validation loss: 2.473861884853074

Epoch: 6| Step: 7
Training loss: 1.9968773186659745
Validation loss: 2.47888616076455

Epoch: 6| Step: 8
Training loss: 3.3136518383128606
Validation loss: 2.490536816138597

Epoch: 6| Step: 9
Training loss: 2.651016734867236
Validation loss: 2.4532301204687936

Epoch: 6| Step: 10
Training loss: 3.13742008183435
Validation loss: 2.4905588493342985

Epoch: 6| Step: 11
Training loss: 2.896835007540658
Validation loss: 2.481409554788599

Epoch: 6| Step: 12
Training loss: 3.279579100468978
Validation loss: 2.4816420683254647

Epoch: 6| Step: 13
Training loss: 2.70699848634123
Validation loss: 2.4820629797079774

Epoch: 86| Step: 0
Training loss: 3.145405182323309
Validation loss: 2.4840606265593217

Epoch: 6| Step: 1
Training loss: 2.9543828959527976
Validation loss: 2.4487491264782038

Epoch: 6| Step: 2
Training loss: 2.6890110824430353
Validation loss: 2.4785572570429553

Epoch: 6| Step: 3
Training loss: 3.2465499759307295
Validation loss: 2.4800983421431417

Epoch: 6| Step: 4
Training loss: 3.369588964734388
Validation loss: 2.467434761353644

Epoch: 6| Step: 5
Training loss: 2.2086093897985997
Validation loss: 2.4713311119685155

Epoch: 6| Step: 6
Training loss: 2.9653924527255477
Validation loss: 2.488877047506865

Epoch: 6| Step: 7
Training loss: 2.555806979190794
Validation loss: 2.4738350851881483

Epoch: 6| Step: 8
Training loss: 3.1655074222943447
Validation loss: 2.490658113128744

Epoch: 6| Step: 9
Training loss: 2.212606709811083
Validation loss: 2.486930422935258

Epoch: 6| Step: 10
Training loss: 2.7221900836405504
Validation loss: 2.478511082151903

Epoch: 6| Step: 11
Training loss: 2.3496865936046203
Validation loss: 2.478681746643033

Epoch: 6| Step: 12
Training loss: 2.2946912284362586
Validation loss: 2.477362533581275

Epoch: 6| Step: 13
Training loss: 2.6889865223925247
Validation loss: 2.4937750564119496

Epoch: 87| Step: 0
Training loss: 2.880814353461765
Validation loss: 2.4652816482029047

Epoch: 6| Step: 1
Training loss: 2.854856328873364
Validation loss: 2.4956074077062493

Epoch: 6| Step: 2
Training loss: 2.338398125426735
Validation loss: 2.4882329868277413

Epoch: 6| Step: 3
Training loss: 3.104282675672587
Validation loss: 2.4641917962866824

Epoch: 6| Step: 4
Training loss: 2.7999021036200458
Validation loss: 2.469534430927567

Epoch: 6| Step: 5
Training loss: 2.8132668191570924
Validation loss: 2.4591882924733577

Epoch: 6| Step: 6
Training loss: 2.7219775105037125
Validation loss: 2.450646762141126

Epoch: 6| Step: 7
Training loss: 3.1805253858028437
Validation loss: 2.471748969805477

Epoch: 6| Step: 8
Training loss: 2.9387554975723513
Validation loss: 2.4537514886657283

Epoch: 6| Step: 9
Training loss: 2.6758549366849835
Validation loss: 2.466996022744652

Epoch: 6| Step: 10
Training loss: 3.1151809544302904
Validation loss: 2.5004151543084934

Epoch: 6| Step: 11
Training loss: 2.027952363788391
Validation loss: 2.4820547064305134

Epoch: 6| Step: 12
Training loss: 1.7934906642469843
Validation loss: 2.4867186968450894

Epoch: 6| Step: 13
Training loss: 3.4696199168278556
Validation loss: 2.464939708215738

Epoch: 88| Step: 0
Training loss: 2.4497881505809946
Validation loss: 2.455525584522019

Epoch: 6| Step: 1
Training loss: 2.138721036999165
Validation loss: 2.4925028427581273

Epoch: 6| Step: 2
Training loss: 2.939514443401132
Validation loss: 2.468370590453349

Epoch: 6| Step: 3
Training loss: 3.2592045945181507
Validation loss: 2.4672149926628046

Epoch: 6| Step: 4
Training loss: 2.5222713267755363
Validation loss: 2.4722010649336164

Epoch: 6| Step: 5
Training loss: 3.272523738812868
Validation loss: 2.4747978308524816

Epoch: 6| Step: 6
Training loss: 2.3893575861578418
Validation loss: 2.477609514716409

Epoch: 6| Step: 7
Training loss: 2.045625960748705
Validation loss: 2.475593170940539

Epoch: 6| Step: 8
Training loss: 3.646424483556766
Validation loss: 2.4648847143455215

Epoch: 6| Step: 9
Training loss: 2.9537068757514393
Validation loss: 2.463032113536204

Epoch: 6| Step: 10
Training loss: 2.562993909175927
Validation loss: 2.471803136806428

Epoch: 6| Step: 11
Training loss: 2.947214499018125
Validation loss: 2.459889399328822

Epoch: 6| Step: 12
Training loss: 2.506421520423732
Validation loss: 2.443057706526152

Epoch: 6| Step: 13
Training loss: 2.563935598781628
Validation loss: 2.4729562619611425

Epoch: 89| Step: 0
Training loss: 2.5262950861860523
Validation loss: 2.444126831773697

Epoch: 6| Step: 1
Training loss: 3.1885496916862595
Validation loss: 2.4752340995972153

Epoch: 6| Step: 2
Training loss: 2.7452592734928936
Validation loss: 2.457846863676324

Epoch: 6| Step: 3
Training loss: 2.60744491738414
Validation loss: 2.4833885045793886

Epoch: 6| Step: 4
Training loss: 2.7136804077840155
Validation loss: 2.46707377207472

Epoch: 6| Step: 5
Training loss: 3.2337412927463887
Validation loss: 2.468027045617253

Epoch: 6| Step: 6
Training loss: 2.7861205754912217
Validation loss: 2.4573175863499985

Epoch: 6| Step: 7
Training loss: 2.5167027409812235
Validation loss: 2.4493539152082073

Epoch: 6| Step: 8
Training loss: 2.7593593851859475
Validation loss: 2.4732264771162833

Epoch: 6| Step: 9
Training loss: 3.1512402348440838
Validation loss: 2.466895463365811

Epoch: 6| Step: 10
Training loss: 2.646079304793388
Validation loss: 2.495030298576999

Epoch: 6| Step: 11
Training loss: 2.2501965542877507
Validation loss: 2.4855732735790337

Epoch: 6| Step: 12
Training loss: 2.5067974187182402
Validation loss: 2.4709750276388154

Epoch: 6| Step: 13
Training loss: 2.8045029433369812
Validation loss: 2.453990813010716

Epoch: 90| Step: 0
Training loss: 2.8224513854037467
Validation loss: 2.4850616311109635

Epoch: 6| Step: 1
Training loss: 3.1568504744298096
Validation loss: 2.4671802808189724

Epoch: 6| Step: 2
Training loss: 2.3027169806913013
Validation loss: 2.476783433332396

Epoch: 6| Step: 3
Training loss: 2.363347025815022
Validation loss: 2.4806049201349465

Epoch: 6| Step: 4
Training loss: 2.09280647540126
Validation loss: 2.4684028137327445

Epoch: 6| Step: 5
Training loss: 3.3097822448464465
Validation loss: 2.482178697349545

Epoch: 6| Step: 6
Training loss: 2.7516077717008773
Validation loss: 2.4962551679638896

Epoch: 6| Step: 7
Training loss: 3.1215859646879056
Validation loss: 2.4852736051339486

Epoch: 6| Step: 8
Training loss: 2.5986564832983365
Validation loss: 2.4731001600704765

Epoch: 6| Step: 9
Training loss: 2.5528208594641217
Validation loss: 2.4945792115146976

Epoch: 6| Step: 10
Training loss: 3.0621957433165083
Validation loss: 2.4807321638717545

Epoch: 6| Step: 11
Training loss: 2.770391978819711
Validation loss: 2.4872611858078253

Epoch: 6| Step: 12
Training loss: 2.7944577816121843
Validation loss: 2.4845175753464686

Epoch: 6| Step: 13
Training loss: 2.747602978651737
Validation loss: 2.4691215688273065

Epoch: 91| Step: 0
Training loss: 2.7673820474604596
Validation loss: 2.4732404488309

Epoch: 6| Step: 1
Training loss: 2.2740310995144366
Validation loss: 2.4730721082051255

Epoch: 6| Step: 2
Training loss: 3.1146241932786123
Validation loss: 2.495905568377953

Epoch: 6| Step: 3
Training loss: 2.5127784309027446
Validation loss: 2.4727919089894748

Epoch: 6| Step: 4
Training loss: 2.205702336015669
Validation loss: 2.4784892749170333

Epoch: 6| Step: 5
Training loss: 2.818447013861763
Validation loss: 2.476017516853073

Epoch: 6| Step: 6
Training loss: 3.0549960943968135
Validation loss: 2.47754099438284

Epoch: 6| Step: 7
Training loss: 2.6456210033693863
Validation loss: 2.4737582794977633

Epoch: 6| Step: 8
Training loss: 3.3527824120189713
Validation loss: 2.4575325057943846

Epoch: 6| Step: 9
Training loss: 3.1341750684965497
Validation loss: 2.449526267870805

Epoch: 6| Step: 10
Training loss: 2.5427165338513444
Validation loss: 2.4658937916772383

Epoch: 6| Step: 11
Training loss: 3.2591778206364133
Validation loss: 2.4814454483557986

Epoch: 6| Step: 12
Training loss: 2.322089442827981
Validation loss: 2.4750656998408807

Epoch: 6| Step: 13
Training loss: 2.0283676825158827
Validation loss: 2.4683000438281333

Epoch: 92| Step: 0
Training loss: 2.642862759956076
Validation loss: 2.45816230978538

Epoch: 6| Step: 1
Training loss: 2.5568454039694704
Validation loss: 2.474781165253013

Epoch: 6| Step: 2
Training loss: 2.5025850282718607
Validation loss: 2.4754611762237744

Epoch: 6| Step: 3
Training loss: 2.1476976265083656
Validation loss: 2.46839073913991

Epoch: 6| Step: 4
Training loss: 2.45252536321157
Validation loss: 2.4707697182855264

Epoch: 6| Step: 5
Training loss: 2.7794358412420777
Validation loss: 2.483803774544499

Epoch: 6| Step: 6
Training loss: 3.3989933655492552
Validation loss: 2.474804342505124

Epoch: 6| Step: 7
Training loss: 2.7006457651510174
Validation loss: 2.479784038550326

Epoch: 6| Step: 8
Training loss: 2.4820933871225437
Validation loss: 2.4773719908434764

Epoch: 6| Step: 9
Training loss: 2.7582820676282562
Validation loss: 2.4731952838046842

Epoch: 6| Step: 10
Training loss: 2.544547392314039
Validation loss: 2.4805093891282533

Epoch: 6| Step: 11
Training loss: 2.8228977010354934
Validation loss: 2.474230164045861

Epoch: 6| Step: 12
Training loss: 3.230269770738668
Validation loss: 2.4762410735902387

Epoch: 6| Step: 13
Training loss: 3.611089918286336
Validation loss: 2.4669878293556193

Epoch: 93| Step: 0
Training loss: 3.0859806106067045
Validation loss: 2.4750716556084065

Epoch: 6| Step: 1
Training loss: 2.6950842719269628
Validation loss: 2.4717061692979425

Epoch: 6| Step: 2
Training loss: 2.2560474928327623
Validation loss: 2.4733207864722

Epoch: 6| Step: 3
Training loss: 2.4045375328569367
Validation loss: 2.482419330382654

Epoch: 6| Step: 4
Training loss: 2.5566179640241415
Validation loss: 2.454064903891211

Epoch: 6| Step: 5
Training loss: 2.6324120282058194
Validation loss: 2.4679754902904083

Epoch: 6| Step: 6
Training loss: 2.6981770648753187
Validation loss: 2.450038779372259

Epoch: 6| Step: 7
Training loss: 3.006419307517217
Validation loss: 2.4679256219104753

Epoch: 6| Step: 8
Training loss: 2.278092590017765
Validation loss: 2.4684325066355908

Epoch: 6| Step: 9
Training loss: 2.7709051902077264
Validation loss: 2.467635102747382

Epoch: 6| Step: 10
Training loss: 2.997706808380164
Validation loss: 2.4743929632204815

Epoch: 6| Step: 11
Training loss: 2.7904758665554903
Validation loss: 2.4988114249032183

Epoch: 6| Step: 12
Training loss: 2.851354471221816
Validation loss: 2.453660186415562

Epoch: 6| Step: 13
Training loss: 3.5828410557150843
Validation loss: 2.4754351312434966

Epoch: 94| Step: 0
Training loss: 2.5800884746196657
Validation loss: 2.484098757942343

Epoch: 6| Step: 1
Training loss: 2.5211490612032743
Validation loss: 2.4697170873795695

Epoch: 6| Step: 2
Training loss: 2.6561225411745126
Validation loss: 2.4716524969990377

Epoch: 6| Step: 3
Training loss: 2.708915021980844
Validation loss: 2.477064466963894

Epoch: 6| Step: 4
Training loss: 2.4674967228366227
Validation loss: 2.494390213157427

Epoch: 6| Step: 5
Training loss: 2.3609020015893076
Validation loss: 2.4728416678298863

Epoch: 6| Step: 6
Training loss: 2.632980567706848
Validation loss: 2.4657831460788926

Epoch: 6| Step: 7
Training loss: 2.7224399475256202
Validation loss: 2.4676226005222652

Epoch: 6| Step: 8
Training loss: 3.304927591751255
Validation loss: 2.481889061555934

Epoch: 6| Step: 9
Training loss: 2.350293802603651
Validation loss: 2.447825147130634

Epoch: 6| Step: 10
Training loss: 2.084800610419394
Validation loss: 2.4614694098954337

Epoch: 6| Step: 11
Training loss: 3.7698277490257057
Validation loss: 2.4820765184900613

Epoch: 6| Step: 12
Training loss: 2.981212598138189
Validation loss: 2.472708723773132

Epoch: 6| Step: 13
Training loss: 2.97124240050991
Validation loss: 2.4575561315465926

Epoch: 95| Step: 0
Training loss: 2.2222490256070593
Validation loss: 2.4609064613594684

Epoch: 6| Step: 1
Training loss: 2.464246868040609
Validation loss: 2.4756682100374783

Epoch: 6| Step: 2
Training loss: 2.332016323431606
Validation loss: 2.475048538863982

Epoch: 6| Step: 3
Training loss: 2.4032546386673985
Validation loss: 2.481526458928644

Epoch: 6| Step: 4
Training loss: 3.317302461447786
Validation loss: 2.457110415903811

Epoch: 6| Step: 5
Training loss: 2.5499617704629913
Validation loss: 2.4757490901989896

Epoch: 6| Step: 6
Training loss: 2.491607311481668
Validation loss: 2.4638652542601753

Epoch: 6| Step: 7
Training loss: 2.8355948080869053
Validation loss: 2.461341262512217

Epoch: 6| Step: 8
Training loss: 2.627953275860319
Validation loss: 2.4649015253808875

Epoch: 6| Step: 9
Training loss: 3.625676979779989
Validation loss: 2.4976980358053824

Epoch: 6| Step: 10
Training loss: 2.8505069817131496
Validation loss: 2.454026947258909

Epoch: 6| Step: 11
Training loss: 2.438037519609057
Validation loss: 2.4625894190363615

Epoch: 6| Step: 12
Training loss: 2.9290526655938205
Validation loss: 2.48752138068132

Epoch: 6| Step: 13
Training loss: 3.303595757118694
Validation loss: 2.4795536295249483

Epoch: 96| Step: 0
Training loss: 2.8148842771875224
Validation loss: 2.4842374534863585

Epoch: 6| Step: 1
Training loss: 3.1908548688888256
Validation loss: 2.4889056927289626

Epoch: 6| Step: 2
Training loss: 2.504571359170321
Validation loss: 2.4798620490853263

Epoch: 6| Step: 3
Training loss: 3.3812177392122176
Validation loss: 2.48783229752636

Epoch: 6| Step: 4
Training loss: 3.288253430960075
Validation loss: 2.4799943181653257

Epoch: 6| Step: 5
Training loss: 2.5381765844781015
Validation loss: 2.481826152692212

Epoch: 6| Step: 6
Training loss: 3.0871317037619352
Validation loss: 2.5081278008852372

Epoch: 6| Step: 7
Training loss: 2.380532796991566
Validation loss: 2.5023015390241428

Epoch: 6| Step: 8
Training loss: 2.0478101152219583
Validation loss: 2.5019084429504055

Epoch: 6| Step: 9
Training loss: 2.629358487958046
Validation loss: 2.4760835903387526

Epoch: 6| Step: 10
Training loss: 2.6112143606599774
Validation loss: 2.485430177044461

Epoch: 6| Step: 11
Training loss: 2.4725025484787446
Validation loss: 2.472666483157445

Epoch: 6| Step: 12
Training loss: 2.7123592287443037
Validation loss: 2.4836660756287228

Epoch: 6| Step: 13
Training loss: 2.40843695799318
Validation loss: 2.4727625690922777

Epoch: 97| Step: 0
Training loss: 2.6476039418681196
Validation loss: 2.466314850799612

Epoch: 6| Step: 1
Training loss: 2.799663155593908
Validation loss: 2.477696054369248

Epoch: 6| Step: 2
Training loss: 3.269831672092366
Validation loss: 2.4757360200709853

Epoch: 6| Step: 3
Training loss: 2.6346403845790203
Validation loss: 2.4867031286754893

Epoch: 6| Step: 4
Training loss: 2.4818046276650993
Validation loss: 2.4726680964051493

Epoch: 6| Step: 5
Training loss: 2.1777470746546745
Validation loss: 2.4880397454894743

Epoch: 6| Step: 6
Training loss: 2.6981889054694426
Validation loss: 2.4880913683091075

Epoch: 6| Step: 7
Training loss: 2.604482850271508
Validation loss: 2.49059219160671

Epoch: 6| Step: 8
Training loss: 2.7929506528041315
Validation loss: 2.4762542181815657

Epoch: 6| Step: 9
Training loss: 2.840982620674854
Validation loss: 2.4647225545374885

Epoch: 6| Step: 10
Training loss: 2.9720787259298835
Validation loss: 2.4877990831426398

Epoch: 6| Step: 11
Training loss: 2.9773335897351894
Validation loss: 2.4804184909593214

Epoch: 6| Step: 12
Training loss: 2.5137769651934727
Validation loss: 2.4705479446816425

Epoch: 6| Step: 13
Training loss: 3.216527968135798
Validation loss: 2.495951101524719

Epoch: 98| Step: 0
Training loss: 2.5836478523839457
Validation loss: 2.476860856802377

Epoch: 6| Step: 1
Training loss: 2.1148229253424975
Validation loss: 2.478777892094326

Epoch: 6| Step: 2
Training loss: 3.013155702008427
Validation loss: 2.462644495393675

Epoch: 6| Step: 3
Training loss: 2.8298577327487076
Validation loss: 2.4784800018967608

Epoch: 6| Step: 4
Training loss: 3.2582982567917878
Validation loss: 2.4754030036490864

Epoch: 6| Step: 5
Training loss: 2.9191078505787598
Validation loss: 2.472512823746579

Epoch: 6| Step: 6
Training loss: 3.5331904388419293
Validation loss: 2.4805168531535435

Epoch: 6| Step: 7
Training loss: 2.4064387457997714
Validation loss: 2.467033694110181

Epoch: 6| Step: 8
Training loss: 2.934064438770794
Validation loss: 2.486638578649806

Epoch: 6| Step: 9
Training loss: 2.426198336853559
Validation loss: 2.4616325968475485

Epoch: 6| Step: 10
Training loss: 2.674969938590578
Validation loss: 2.4760904071468666

Epoch: 6| Step: 11
Training loss: 2.3130895533264084
Validation loss: 2.4887516855029883

Epoch: 6| Step: 12
Training loss: 1.9742378768326472
Validation loss: 2.4731937621191

Epoch: 6| Step: 13
Training loss: 2.97759927630572
Validation loss: 2.4750838850847265

Epoch: 99| Step: 0
Training loss: 1.9062477487019236
Validation loss: 2.465252178366767

Epoch: 6| Step: 1
Training loss: 2.432161402566607
Validation loss: 2.4739783606935655

Epoch: 6| Step: 2
Training loss: 3.4047529097878724
Validation loss: 2.4721941855515626

Epoch: 6| Step: 3
Training loss: 2.510732976421017
Validation loss: 2.4982757056895784

Epoch: 6| Step: 4
Training loss: 2.8172157595079788
Validation loss: 2.4730044044673782

Epoch: 6| Step: 5
Training loss: 2.3712803674501854
Validation loss: 2.4608775235557

Epoch: 6| Step: 6
Training loss: 2.5613925680803757
Validation loss: 2.457707778265005

Epoch: 6| Step: 7
Training loss: 2.914979682969338
Validation loss: 2.487954948966474

Epoch: 6| Step: 8
Training loss: 3.187148430079221
Validation loss: 2.4771478526067856

Epoch: 6| Step: 9
Training loss: 2.713664241860756
Validation loss: 2.455716331705115

Epoch: 6| Step: 10
Training loss: 3.0706625391868494
Validation loss: 2.4736133438955217

Epoch: 6| Step: 11
Training loss: 2.400010279792387
Validation loss: 2.4782068640818826

Epoch: 6| Step: 12
Training loss: 2.856160342355645
Validation loss: 2.446891352805876

Epoch: 6| Step: 13
Training loss: 3.342276845828328
Validation loss: 2.49163331396921

Epoch: 100| Step: 0
Training loss: 3.3396548569116327
Validation loss: 2.466109679487336

Epoch: 6| Step: 1
Training loss: 2.3286179398313904
Validation loss: 2.467370774310022

Epoch: 6| Step: 2
Training loss: 2.747725326281534
Validation loss: 2.4752895564124398

Epoch: 6| Step: 3
Training loss: 2.5033459207529023
Validation loss: 2.461084923769654

Epoch: 6| Step: 4
Training loss: 2.407942238789772
Validation loss: 2.487094585822388

Epoch: 6| Step: 5
Training loss: 2.8463371162334314
Validation loss: 2.4723558076030265

Epoch: 6| Step: 6
Training loss: 3.2946939349968725
Validation loss: 2.4882130462112735

Epoch: 6| Step: 7
Training loss: 1.9925287889341639
Validation loss: 2.4840808358111333

Epoch: 6| Step: 8
Training loss: 3.4394043242562935
Validation loss: 2.4542953043693734

Epoch: 6| Step: 9
Training loss: 2.359671264641084
Validation loss: 2.484839863031537

Epoch: 6| Step: 10
Training loss: 2.632791853011586
Validation loss: 2.4761318387314026

Epoch: 6| Step: 11
Training loss: 2.5479881802678497
Validation loss: 2.4910213995396067

Epoch: 6| Step: 12
Training loss: 2.883354652928673
Validation loss: 2.4767925082792774

Epoch: 6| Step: 13
Training loss: 3.010233274019419
Validation loss: 2.4661259327746836

Epoch: 101| Step: 0
Training loss: 2.6065111720088847
Validation loss: 2.4797942939847193

Epoch: 6| Step: 1
Training loss: 2.3534126987348407
Validation loss: 2.4905238946414436

Epoch: 6| Step: 2
Training loss: 3.081096783091986
Validation loss: 2.469313132963215

Epoch: 6| Step: 3
Training loss: 3.137631636210009
Validation loss: 2.4777143548159017

Epoch: 6| Step: 4
Training loss: 2.379440773730441
Validation loss: 2.4530427781927737

Epoch: 6| Step: 5
Training loss: 2.8846786785517744
Validation loss: 2.488994963587993

Epoch: 6| Step: 6
Training loss: 2.9492349182089925
Validation loss: 2.4510691879903814

Epoch: 6| Step: 7
Training loss: 2.633440706824413
Validation loss: 2.478126719496865

Epoch: 6| Step: 8
Training loss: 1.6334917763653936
Validation loss: 2.476192011497329

Epoch: 6| Step: 9
Training loss: 2.6408121618271063
Validation loss: 2.471632931892388

Epoch: 6| Step: 10
Training loss: 3.0790222719135927
Validation loss: 2.499075633583879

Epoch: 6| Step: 11
Training loss: 2.999680184165537
Validation loss: 2.4835466028067263

Epoch: 6| Step: 12
Training loss: 2.8265529077808926
Validation loss: 2.468759437294811

Epoch: 6| Step: 13
Training loss: 2.721977860864526
Validation loss: 2.4575342458124947

Epoch: 102| Step: 0
Training loss: 2.3003419414595605
Validation loss: 2.4686569792405075

Epoch: 6| Step: 1
Training loss: 3.13422953457315
Validation loss: 2.4671623386587833

Epoch: 6| Step: 2
Training loss: 3.223366103165165
Validation loss: 2.495714742892511

Epoch: 6| Step: 3
Training loss: 2.39373676505551
Validation loss: 2.4567000808922317

Epoch: 6| Step: 4
Training loss: 3.2137207442991786
Validation loss: 2.463318844067307

Epoch: 6| Step: 5
Training loss: 2.6446495311436116
Validation loss: 2.490847386433284

Epoch: 6| Step: 6
Training loss: 2.320457171415797
Validation loss: 2.4642029884282057

Epoch: 6| Step: 7
Training loss: 2.8429612962877178
Validation loss: 2.4949530263882336

Epoch: 6| Step: 8
Training loss: 2.173831415302429
Validation loss: 2.4639925857650673

Epoch: 6| Step: 9
Training loss: 2.852702041143953
Validation loss: 2.4804470664308678

Epoch: 6| Step: 10
Training loss: 2.7117564258909015
Validation loss: 2.4802118143935306

Epoch: 6| Step: 11
Training loss: 2.9420909312683663
Validation loss: 2.458282152800336

Epoch: 6| Step: 12
Training loss: 2.748828898672754
Validation loss: 2.4678939356912397

Epoch: 6| Step: 13
Training loss: 2.4254336883658882
Validation loss: 2.484455499720515

Epoch: 103| Step: 0
Training loss: 3.202733160103136
Validation loss: 2.466759884380214

Epoch: 6| Step: 1
Training loss: 3.1522889918377603
Validation loss: 2.4847640217114457

Epoch: 6| Step: 2
Training loss: 2.455510431434132
Validation loss: 2.467103441486359

Epoch: 6| Step: 3
Training loss: 3.013163614585461
Validation loss: 2.4606879380415587

Epoch: 6| Step: 4
Training loss: 2.295192491524542
Validation loss: 2.457878506276391

Epoch: 6| Step: 5
Training loss: 3.327614471965712
Validation loss: 2.4907758759322554

Epoch: 6| Step: 6
Training loss: 2.830616227850416
Validation loss: 2.470267964561402

Epoch: 6| Step: 7
Training loss: 2.1346052411447087
Validation loss: 2.4901598088173342

Epoch: 6| Step: 8
Training loss: 2.5243752452588604
Validation loss: 2.4503937039732167

Epoch: 6| Step: 9
Training loss: 2.999415976579695
Validation loss: 2.489966214576725

Epoch: 6| Step: 10
Training loss: 2.663265702013963
Validation loss: 2.4655995639371904

Epoch: 6| Step: 11
Training loss: 1.6673197499870562
Validation loss: 2.465738576409348

Epoch: 6| Step: 12
Training loss: 2.9093739117252597
Validation loss: 2.4658144861796387

Epoch: 6| Step: 13
Training loss: 2.878190799255064
Validation loss: 2.471131982126614

Epoch: 104| Step: 0
Training loss: 2.8118469327775224
Validation loss: 2.4721637040797426

Epoch: 6| Step: 1
Training loss: 2.8867425362687134
Validation loss: 2.4720416831732033

Epoch: 6| Step: 2
Training loss: 2.680492402575257
Validation loss: 2.478395939066346

Epoch: 6| Step: 3
Training loss: 2.2053709013174925
Validation loss: 2.4752815473837364

Epoch: 6| Step: 4
Training loss: 2.831516655834047
Validation loss: 2.461853773492404

Epoch: 6| Step: 5
Training loss: 2.8481943802024805
Validation loss: 2.4673610283095817

Epoch: 6| Step: 6
Training loss: 2.9250647121998243
Validation loss: 2.4821628197765158

Epoch: 6| Step: 7
Training loss: 3.3867904145117413
Validation loss: 2.468693055627658

Epoch: 6| Step: 8
Training loss: 2.120135855010516
Validation loss: 2.4853932357902284

Epoch: 6| Step: 9
Training loss: 2.7602479895152623
Validation loss: 2.455178046426145

Epoch: 6| Step: 10
Training loss: 3.047571034280313
Validation loss: 2.4580349328286455

Epoch: 6| Step: 11
Training loss: 2.4409892221952836
Validation loss: 2.503039290729903

Epoch: 6| Step: 12
Training loss: 2.0833584847521487
Validation loss: 2.4717025847503247

Epoch: 6| Step: 13
Training loss: 2.994958615279812
Validation loss: 2.476425983360164

Epoch: 105| Step: 0
Training loss: 2.3574576766259283
Validation loss: 2.4828321439107817

Epoch: 6| Step: 1
Training loss: 2.4698522497303452
Validation loss: 2.482968106996475

Epoch: 6| Step: 2
Training loss: 3.105278652298832
Validation loss: 2.46358248391013

Epoch: 6| Step: 3
Training loss: 2.696829018140059
Validation loss: 2.4840105000524773

Epoch: 6| Step: 4
Training loss: 2.9416422755569296
Validation loss: 2.475929884141634

Epoch: 6| Step: 5
Training loss: 2.890849666628126
Validation loss: 2.484525227507944

Epoch: 6| Step: 6
Training loss: 2.18889551608163
Validation loss: 2.4754617841334774

Epoch: 6| Step: 7
Training loss: 2.957079626214263
Validation loss: 2.4640838869944908

Epoch: 6| Step: 8
Training loss: 2.8394941405974596
Validation loss: 2.4857595605771774

Epoch: 6| Step: 9
Training loss: 2.595568467573306
Validation loss: 2.464635503182763

Epoch: 6| Step: 10
Training loss: 2.984211063376109
Validation loss: 2.4853643293451935

Epoch: 6| Step: 11
Training loss: 2.6353987038544258
Validation loss: 2.479554929152186

Epoch: 6| Step: 12
Training loss: 2.5653067313570994
Validation loss: 2.478303098297688

Epoch: 6| Step: 13
Training loss: 2.772913579750397
Validation loss: 2.462894017314296

Epoch: 106| Step: 0
Training loss: 2.9636316447797526
Validation loss: 2.4697117477470454

Epoch: 6| Step: 1
Training loss: 2.6007713054124233
Validation loss: 2.478943893779559

Epoch: 6| Step: 2
Training loss: 2.3485771822933486
Validation loss: 2.4774631684236676

Epoch: 6| Step: 3
Training loss: 2.281962244334974
Validation loss: 2.478394454708921

Epoch: 6| Step: 4
Training loss: 3.109949413513708
Validation loss: 2.4607453635366006

Epoch: 6| Step: 5
Training loss: 3.027140555176766
Validation loss: 2.4740044101295076

Epoch: 6| Step: 6
Training loss: 2.4555851936949065
Validation loss: 2.46974404124066

Epoch: 6| Step: 7
Training loss: 2.190977982884441
Validation loss: 2.481078743370731

Epoch: 6| Step: 8
Training loss: 3.392823662270009
Validation loss: 2.4730226971300446

Epoch: 6| Step: 9
Training loss: 2.69439186184712
Validation loss: 2.4697796092162028

Epoch: 6| Step: 10
Training loss: 2.392097169452576
Validation loss: 2.454055953307636

Epoch: 6| Step: 11
Training loss: 2.1393466668756087
Validation loss: 2.476942956582727

Epoch: 6| Step: 12
Training loss: 3.417736459740532
Validation loss: 2.477422001247473

Epoch: 6| Step: 13
Training loss: 2.701025704423605
Validation loss: 2.4843473179444184

Epoch: 107| Step: 0
Training loss: 3.610327524771209
Validation loss: 2.4815639308930155

Epoch: 6| Step: 1
Training loss: 3.002620347380016
Validation loss: 2.464267924317661

Epoch: 6| Step: 2
Training loss: 3.0829838391430133
Validation loss: 2.4764973782075304

Epoch: 6| Step: 3
Training loss: 2.3779108379643055
Validation loss: 2.481986429148307

Epoch: 6| Step: 4
Training loss: 2.899074268570065
Validation loss: 2.4718041086195823

Epoch: 6| Step: 5
Training loss: 3.1308883123077877
Validation loss: 2.467049803102724

Epoch: 6| Step: 6
Training loss: 2.578875160896607
Validation loss: 2.4807916861386174

Epoch: 6| Step: 7
Training loss: 2.181334061628716
Validation loss: 2.4771807611734564

Epoch: 6| Step: 8
Training loss: 1.991311871943718
Validation loss: 2.4778921943462446

Epoch: 6| Step: 9
Training loss: 2.614550910738544
Validation loss: 2.4743972774060046

Epoch: 6| Step: 10
Training loss: 2.186481347643686
Validation loss: 2.461853005499892

Epoch: 6| Step: 11
Training loss: 2.3848989888359386
Validation loss: 2.4528751573947574

Epoch: 6| Step: 12
Training loss: 3.0529471120092446
Validation loss: 2.485804144096342

Epoch: 6| Step: 13
Training loss: 2.3142886075164903
Validation loss: 2.4678527164043653

Epoch: 108| Step: 0
Training loss: 2.9789334363719777
Validation loss: 2.4632076534851755

Epoch: 6| Step: 1
Training loss: 2.569185050265894
Validation loss: 2.4607979089824386

Epoch: 6| Step: 2
Training loss: 2.472291747793139
Validation loss: 2.4948713836343748

Epoch: 6| Step: 3
Training loss: 2.091825825181903
Validation loss: 2.4772328912526023

Epoch: 6| Step: 4
Training loss: 2.6822900173342674
Validation loss: 2.4893426629928235

Epoch: 6| Step: 5
Training loss: 2.325869190628063
Validation loss: 2.4801019321288016

Epoch: 6| Step: 6
Training loss: 3.2832279601510876
Validation loss: 2.462485679321224

Epoch: 6| Step: 7
Training loss: 2.6757632512510527
Validation loss: 2.461305314804876

Epoch: 6| Step: 8
Training loss: 2.587556729639287
Validation loss: 2.4669899253777006

Epoch: 6| Step: 9
Training loss: 3.2509847762925674
Validation loss: 2.503070467521749

Epoch: 6| Step: 10
Training loss: 2.5456270308080224
Validation loss: 2.4738964044994325

Epoch: 6| Step: 11
Training loss: 2.1875687724610686
Validation loss: 2.4686582783734443

Epoch: 6| Step: 12
Training loss: 3.1205679936457575
Validation loss: 2.4673265678888727

Epoch: 6| Step: 13
Training loss: 3.165702338370747
Validation loss: 2.4954448218906125

Epoch: 109| Step: 0
Training loss: 2.858861658261746
Validation loss: 2.46967115204511

Epoch: 6| Step: 1
Training loss: 2.696344769491987
Validation loss: 2.4693444511026463

Epoch: 6| Step: 2
Training loss: 2.977260557807655
Validation loss: 2.470308290491355

Epoch: 6| Step: 3
Training loss: 2.626894403531651
Validation loss: 2.4768573242213257

Epoch: 6| Step: 4
Training loss: 2.991327784762739
Validation loss: 2.4716288099549235

Epoch: 6| Step: 5
Training loss: 2.322966730464982
Validation loss: 2.479317364171742

Epoch: 6| Step: 6
Training loss: 2.189785009134565
Validation loss: 2.476752112477587

Epoch: 6| Step: 7
Training loss: 2.09965979227258
Validation loss: 2.475763939238665

Epoch: 6| Step: 8
Training loss: 3.2160244855755202
Validation loss: 2.462662743212348

Epoch: 6| Step: 9
Training loss: 2.8798945683148496
Validation loss: 2.4793250758114063

Epoch: 6| Step: 10
Training loss: 2.6863613821647188
Validation loss: 2.475352800211579

Epoch: 6| Step: 11
Training loss: 2.31543071719452
Validation loss: 2.47154049366693

Epoch: 6| Step: 12
Training loss: 3.146078205472835
Validation loss: 2.4777911599656837

Epoch: 6| Step: 13
Training loss: 3.3094991370702975
Validation loss: 2.465873900693916

Epoch: 110| Step: 0
Training loss: 3.0852946324054695
Validation loss: 2.462126707545185

Epoch: 6| Step: 1
Training loss: 2.32358759156058
Validation loss: 2.4757310574013145

Epoch: 6| Step: 2
Training loss: 2.314185997077816
Validation loss: 2.4706795902048118

Epoch: 6| Step: 3
Training loss: 2.6814654710528587
Validation loss: 2.470893597981121

Epoch: 6| Step: 4
Training loss: 2.445426377639906
Validation loss: 2.4578253695896284

Epoch: 6| Step: 5
Training loss: 3.4712612924745847
Validation loss: 2.5063473161493093

Epoch: 6| Step: 6
Training loss: 1.997727056209952
Validation loss: 2.4862921570510252

Epoch: 6| Step: 7
Training loss: 2.5939532280780986
Validation loss: 2.458311480937238

Epoch: 6| Step: 8
Training loss: 2.890820965696923
Validation loss: 2.4579553252669895

Epoch: 6| Step: 9
Training loss: 2.584261348121174
Validation loss: 2.4688124767542936

Epoch: 6| Step: 10
Training loss: 2.647288925791103
Validation loss: 2.4619452435920732

Epoch: 6| Step: 11
Training loss: 2.63045715565133
Validation loss: 2.4607842994893843

Epoch: 6| Step: 12
Training loss: 2.9403247643497874
Validation loss: 2.4500008147771775

Epoch: 6| Step: 13
Training loss: 3.24122594339702
Validation loss: 2.4568627482933167

Epoch: 111| Step: 0
Training loss: 3.006530012703209
Validation loss: 2.4682835893406634

Epoch: 6| Step: 1
Training loss: 3.1532259513792633
Validation loss: 2.4714179409673

Epoch: 6| Step: 2
Training loss: 2.5249980435505455
Validation loss: 2.4576418981700883

Epoch: 6| Step: 3
Training loss: 2.373951027761157
Validation loss: 2.4787525656006544

Epoch: 6| Step: 4
Training loss: 2.5750758780253236
Validation loss: 2.468083950303979

Epoch: 6| Step: 5
Training loss: 3.2757225346142027
Validation loss: 2.4561389628196006

Epoch: 6| Step: 6
Training loss: 2.723472002328469
Validation loss: 2.466557725774968

Epoch: 6| Step: 7
Training loss: 2.46299788190818
Validation loss: 2.4830185632552344

Epoch: 6| Step: 8
Training loss: 2.401748409781749
Validation loss: 2.461643711582115

Epoch: 6| Step: 9
Training loss: 2.5654703927704254
Validation loss: 2.456096257701359

Epoch: 6| Step: 10
Training loss: 2.801002738420155
Validation loss: 2.4777565807675157

Epoch: 6| Step: 11
Training loss: 2.697189783000985
Validation loss: 2.484301095880878

Epoch: 6| Step: 12
Training loss: 2.3355197086339743
Validation loss: 2.4961276643521084

Epoch: 6| Step: 13
Training loss: 3.1601168673670093
Validation loss: 2.470568605861427

Epoch: 112| Step: 0
Training loss: 2.6589869143195233
Validation loss: 2.4675286453231227

Epoch: 6| Step: 1
Training loss: 2.4029842856373955
Validation loss: 2.475869651679343

Epoch: 6| Step: 2
Training loss: 2.864984398711169
Validation loss: 2.4899923340709527

Epoch: 6| Step: 3
Training loss: 2.6690201705221894
Validation loss: 2.4930045072302556

Epoch: 6| Step: 4
Training loss: 2.954747153113201
Validation loss: 2.471899378680071

Epoch: 6| Step: 5
Training loss: 2.3482743400092856
Validation loss: 2.480310860756176

Epoch: 6| Step: 6
Training loss: 2.682276062163853
Validation loss: 2.4716511548395363

Epoch: 6| Step: 7
Training loss: 3.0553396167938836
Validation loss: 2.48324541945381

Epoch: 6| Step: 8
Training loss: 2.8742064334473807
Validation loss: 2.4748678804601947

Epoch: 6| Step: 9
Training loss: 2.7324101827506273
Validation loss: 2.469984222430802

Epoch: 6| Step: 10
Training loss: 2.5496229079927537
Validation loss: 2.495252155501482

Epoch: 6| Step: 11
Training loss: 2.039906995560609
Validation loss: 2.4794054675544244

Epoch: 6| Step: 12
Training loss: 3.0277334048629267
Validation loss: 2.4747233765625922

Epoch: 6| Step: 13
Training loss: 3.1689529865565786
Validation loss: 2.4793853401360493

Epoch: 113| Step: 0
Training loss: 2.382614577781586
Validation loss: 2.4912804340204224

Epoch: 6| Step: 1
Training loss: 2.335575343607854
Validation loss: 2.4822360222580664

Epoch: 6| Step: 2
Training loss: 2.6201283799087727
Validation loss: 2.4634690433479802

Epoch: 6| Step: 3
Training loss: 3.0942180549209723
Validation loss: 2.4761701574379895

Epoch: 6| Step: 4
Training loss: 2.4111259896053223
Validation loss: 2.4692769680432396

Epoch: 6| Step: 5
Training loss: 2.7640616098319475
Validation loss: 2.458972788994904

Epoch: 6| Step: 6
Training loss: 2.8169215732175084
Validation loss: 2.488886994574427

Epoch: 6| Step: 7
Training loss: 2.5054184368851997
Validation loss: 2.4553933462993216

Epoch: 6| Step: 8
Training loss: 2.73133410710566
Validation loss: 2.4721956819276723

Epoch: 6| Step: 9
Training loss: 3.2902209491222574
Validation loss: 2.4779515241170103

Epoch: 6| Step: 10
Training loss: 2.275450454383752
Validation loss: 2.4766952734224366

Epoch: 6| Step: 11
Training loss: 3.0482634681911582
Validation loss: 2.461029706778102

Epoch: 6| Step: 12
Training loss: 3.223503528534461
Validation loss: 2.4719220519551315

Epoch: 6| Step: 13
Training loss: 1.8529513015523864
Validation loss: 2.4656218480495875

Epoch: 114| Step: 0
Training loss: 2.1665483100059975
Validation loss: 2.4666657440607307

Epoch: 6| Step: 1
Training loss: 3.1123546336594776
Validation loss: 2.452183387217722

Epoch: 6| Step: 2
Training loss: 2.7501170393573386
Validation loss: 2.4708681844478546

Epoch: 6| Step: 3
Training loss: 2.9285821482498746
Validation loss: 2.451194664699218

Epoch: 6| Step: 4
Training loss: 2.386201643296455
Validation loss: 2.4855824304040928

Epoch: 6| Step: 5
Training loss: 2.6763289065178513
Validation loss: 2.4750525722428605

Epoch: 6| Step: 6
Training loss: 2.2240368890996227
Validation loss: 2.4974646253378974

Epoch: 6| Step: 7
Training loss: 2.9922472596737224
Validation loss: 2.482300835486906

Epoch: 6| Step: 8
Training loss: 2.865698487515757
Validation loss: 2.488818734766117

Epoch: 6| Step: 9
Training loss: 2.573964594101763
Validation loss: 2.465011723826687

Epoch: 6| Step: 10
Training loss: 2.4856592853455814
Validation loss: 2.4640381681347767

Epoch: 6| Step: 11
Training loss: 2.6746583239094677
Validation loss: 2.476438987733936

Epoch: 6| Step: 12
Training loss: 2.78300917635634
Validation loss: 2.4615314642562796

Epoch: 6| Step: 13
Training loss: 3.2704025438418265
Validation loss: 2.476981218236991

Epoch: 115| Step: 0
Training loss: 2.6122656247079394
Validation loss: 2.4852960506652546

Epoch: 6| Step: 1
Training loss: 3.0233214205752876
Validation loss: 2.4685092516318567

Epoch: 6| Step: 2
Training loss: 1.816541966116017
Validation loss: 2.4785298037628687

Epoch: 6| Step: 3
Training loss: 3.0176026179730093
Validation loss: 2.47995966941373

Epoch: 6| Step: 4
Training loss: 2.8562294589917157
Validation loss: 2.4816595194436326

Epoch: 6| Step: 5
Training loss: 2.5972272246160175
Validation loss: 2.482283732791468

Epoch: 6| Step: 6
Training loss: 2.4421689238424493
Validation loss: 2.475649938993683

Epoch: 6| Step: 7
Training loss: 3.1892614546472404
Validation loss: 2.4661446059907504

Epoch: 6| Step: 8
Training loss: 3.3964821287370377
Validation loss: 2.4818404550904365

Epoch: 6| Step: 9
Training loss: 2.2911140700423016
Validation loss: 2.4846125735690774

Epoch: 6| Step: 10
Training loss: 2.377201264844157
Validation loss: 2.4833864306565294

Epoch: 6| Step: 11
Training loss: 2.5058833512833867
Validation loss: 2.4816657197107332

Epoch: 6| Step: 12
Training loss: 2.786067861608199
Validation loss: 2.479307031281478

Epoch: 6| Step: 13
Training loss: 2.5411263397046633
Validation loss: 2.4641366109408076

Epoch: 116| Step: 0
Training loss: 2.842729490170436
Validation loss: 2.4961237512996566

Epoch: 6| Step: 1
Training loss: 2.6794457507285743
Validation loss: 2.483416981873603

Epoch: 6| Step: 2
Training loss: 2.39123008899206
Validation loss: 2.467444508101837

Epoch: 6| Step: 3
Training loss: 2.4823850903610674
Validation loss: 2.486143920262445

Epoch: 6| Step: 4
Training loss: 2.574001829880284
Validation loss: 2.463489869004256

Epoch: 6| Step: 5
Training loss: 2.3587500142318327
Validation loss: 2.4813202744879828

Epoch: 6| Step: 6
Training loss: 3.339462811791425
Validation loss: 2.4794913251957458

Epoch: 6| Step: 7
Training loss: 2.6541805508508447
Validation loss: 2.4760647570486776

Epoch: 6| Step: 8
Training loss: 2.9366923094318
Validation loss: 2.4642645599028614

Epoch: 6| Step: 9
Training loss: 2.532545723535288
Validation loss: 2.4915239570282806

Epoch: 6| Step: 10
Training loss: 3.4331508520081147
Validation loss: 2.4897769648960146

Epoch: 6| Step: 11
Training loss: 2.672970374368825
Validation loss: 2.490985024911836

Epoch: 6| Step: 12
Training loss: 2.193997352327264
Validation loss: 2.481720687779167

Epoch: 6| Step: 13
Training loss: 2.891615249513791
Validation loss: 2.4765914563862252

Epoch: 117| Step: 0
Training loss: 2.4864779994289687
Validation loss: 2.4832075908787803

Epoch: 6| Step: 1
Training loss: 2.5734443483800042
Validation loss: 2.4864102080913195

Epoch: 6| Step: 2
Training loss: 2.5146765016637866
Validation loss: 2.4477073382695536

Epoch: 6| Step: 3
Training loss: 2.7835631448892433
Validation loss: 2.47337562593977

Epoch: 6| Step: 4
Training loss: 3.15807690011362
Validation loss: 2.4809335782260367

Epoch: 6| Step: 5
Training loss: 2.0596674339579875
Validation loss: 2.4822182705163263

Epoch: 6| Step: 6
Training loss: 2.628019685029925
Validation loss: 2.4781435679457138

Epoch: 6| Step: 7
Training loss: 2.8487391041726826
Validation loss: 2.4762926623330923

Epoch: 6| Step: 8
Training loss: 2.0224190877565946
Validation loss: 2.4873364521393087

Epoch: 6| Step: 9
Training loss: 3.2972663538642424
Validation loss: 2.4745147448968727

Epoch: 6| Step: 10
Training loss: 2.7639815625405255
Validation loss: 2.4876098540947402

Epoch: 6| Step: 11
Training loss: 2.583736162669976
Validation loss: 2.4901095034364324

Epoch: 6| Step: 12
Training loss: 3.297676169871428
Validation loss: 2.4637148585358273

Epoch: 6| Step: 13
Training loss: 2.4079059996079577
Validation loss: 2.4724792469992307

Epoch: 118| Step: 0
Training loss: 2.543434955854839
Validation loss: 2.4595501660197265

Epoch: 6| Step: 1
Training loss: 2.77148755794501
Validation loss: 2.4759165540394372

Epoch: 6| Step: 2
Training loss: 2.2956016280523928
Validation loss: 2.450595700304007

Epoch: 6| Step: 3
Training loss: 3.172285983515051
Validation loss: 2.4769687952700803

Epoch: 6| Step: 4
Training loss: 2.48669862346552
Validation loss: 2.4785187399284854

Epoch: 6| Step: 5
Training loss: 2.6979594184306284
Validation loss: 2.4755269124566492

Epoch: 6| Step: 6
Training loss: 2.704302933545774
Validation loss: 2.4677313139459875

Epoch: 6| Step: 7
Training loss: 2.529961340386469
Validation loss: 2.4841016176692716

Epoch: 6| Step: 8
Training loss: 2.76129760120923
Validation loss: 2.476376472013827

Epoch: 6| Step: 9
Training loss: 2.9968130349922095
Validation loss: 2.4672375603986834

Epoch: 6| Step: 10
Training loss: 2.705815910782179
Validation loss: 2.470195648658642

Epoch: 6| Step: 11
Training loss: 2.4774156899835287
Validation loss: 2.4715749295633924

Epoch: 6| Step: 12
Training loss: 3.210090915426343
Validation loss: 2.4852563686809246

Epoch: 6| Step: 13
Training loss: 2.127026993630904
Validation loss: 2.468716491496735

Epoch: 119| Step: 0
Training loss: 2.8531051852320566
Validation loss: 2.482923902593191

Epoch: 6| Step: 1
Training loss: 2.0617336814718406
Validation loss: 2.48524034778604

Epoch: 6| Step: 2
Training loss: 3.1646893669146268
Validation loss: 2.4681661654587312

Epoch: 6| Step: 3
Training loss: 2.5334692751231787
Validation loss: 2.459661725184311

Epoch: 6| Step: 4
Training loss: 2.2096107195296533
Validation loss: 2.476087853952101

Epoch: 6| Step: 5
Training loss: 2.7838588009192944
Validation loss: 2.4987311214356076

Epoch: 6| Step: 6
Training loss: 2.5015461908651093
Validation loss: 2.474533071978978

Epoch: 6| Step: 7
Training loss: 2.74967460441145
Validation loss: 2.452085627120206

Epoch: 6| Step: 8
Training loss: 2.5691301124917962
Validation loss: 2.4824649141634945

Epoch: 6| Step: 9
Training loss: 2.985191353394592
Validation loss: 2.4858143648968607

Epoch: 6| Step: 10
Training loss: 3.029640950498991
Validation loss: 2.4794091681443873

Epoch: 6| Step: 11
Training loss: 2.3335414067091613
Validation loss: 2.463756757327693

Epoch: 6| Step: 12
Training loss: 2.7438920420938158
Validation loss: 2.4908943042099443

Epoch: 6| Step: 13
Training loss: 3.2485451009378257
Validation loss: 2.4844018304343054

Epoch: 120| Step: 0
Training loss: 2.7738824191982454
Validation loss: 2.47037507031958

Epoch: 6| Step: 1
Training loss: 2.780442452795397
Validation loss: 2.473912954815589

Epoch: 6| Step: 2
Training loss: 3.0897187450021684
Validation loss: 2.4823205240961816

Epoch: 6| Step: 3
Training loss: 2.6462234649985596
Validation loss: 2.4650399818182325

Epoch: 6| Step: 4
Training loss: 2.3567325371147576
Validation loss: 2.4860060972841977

Epoch: 6| Step: 5
Training loss: 2.82726262048132
Validation loss: 2.4818370277285027

Epoch: 6| Step: 6
Training loss: 2.682303794660587
Validation loss: 2.476719319839098

Epoch: 6| Step: 7
Training loss: 2.5522895781551274
Validation loss: 2.4795866048999384

Epoch: 6| Step: 8
Training loss: 2.0689529273318756
Validation loss: 2.473912260514901

Epoch: 6| Step: 9
Training loss: 2.5427319113140774
Validation loss: 2.4759946087714195

Epoch: 6| Step: 10
Training loss: 3.3705163065514894
Validation loss: 2.4751213976190938

Epoch: 6| Step: 11
Training loss: 2.509315111863682
Validation loss: 2.4700387145910048

Epoch: 6| Step: 12
Training loss: 2.3416659435483784
Validation loss: 2.4729278041573832

Epoch: 6| Step: 13
Training loss: 2.8626595065390537
Validation loss: 2.47185974195206

Epoch: 121| Step: 0
Training loss: 2.7764404373086427
Validation loss: 2.4684933723349216

Epoch: 6| Step: 1
Training loss: 2.9347158995708336
Validation loss: 2.4807562626149786

Epoch: 6| Step: 2
Training loss: 2.37726996511335
Validation loss: 2.47141826875904

Epoch: 6| Step: 3
Training loss: 3.2778136651899623
Validation loss: 2.4735552812539563

Epoch: 6| Step: 4
Training loss: 2.0505412806030097
Validation loss: 2.45435030885039

Epoch: 6| Step: 5
Training loss: 2.407492279800919
Validation loss: 2.470179033998593

Epoch: 6| Step: 6
Training loss: 2.00792637364794
Validation loss: 2.476029487988645

Epoch: 6| Step: 7
Training loss: 2.7588629518589523
Validation loss: 2.4760101966439216

Epoch: 6| Step: 8
Training loss: 2.4972962063570185
Validation loss: 2.4732472879870095

Epoch: 6| Step: 9
Training loss: 3.2373954196372705
Validation loss: 2.485842500886816

Epoch: 6| Step: 10
Training loss: 2.3111278483913664
Validation loss: 2.455468220706603

Epoch: 6| Step: 11
Training loss: 2.4310120532334487
Validation loss: 2.4784321147024473

Epoch: 6| Step: 12
Training loss: 3.160354513731936
Validation loss: 2.4736856552306934

Epoch: 6| Step: 13
Training loss: 3.449617701924187
Validation loss: 2.493014918059248

Epoch: 122| Step: 0
Training loss: 2.946785070477132
Validation loss: 2.471223171045612

Epoch: 6| Step: 1
Training loss: 2.7791041979615376
Validation loss: 2.46302526787317

Epoch: 6| Step: 2
Training loss: 2.8899603002124787
Validation loss: 2.459312964029108

Epoch: 6| Step: 3
Training loss: 2.4755240107207666
Validation loss: 2.474700258636693

Epoch: 6| Step: 4
Training loss: 2.71655798930653
Validation loss: 2.48235071147908

Epoch: 6| Step: 5
Training loss: 3.3469545214241325
Validation loss: 2.468319042302063

Epoch: 6| Step: 6
Training loss: 2.10626454786942
Validation loss: 2.4832708446565936

Epoch: 6| Step: 7
Training loss: 2.6163895486575974
Validation loss: 2.450952274565378

Epoch: 6| Step: 8
Training loss: 1.992653706172904
Validation loss: 2.4737649524455305

Epoch: 6| Step: 9
Training loss: 2.4905699260753837
Validation loss: 2.4858797025665798

Epoch: 6| Step: 10
Training loss: 3.243193909123803
Validation loss: 2.4965149183615924

Epoch: 6| Step: 11
Training loss: 2.509152728696297
Validation loss: 2.4767949148036683

Epoch: 6| Step: 12
Training loss: 2.4208776573898896
Validation loss: 2.4753595483481283

Epoch: 6| Step: 13
Training loss: 2.9262256564920626
Validation loss: 2.4837931042274275

Epoch: 123| Step: 0
Training loss: 2.211969033878173
Validation loss: 2.457403481270658

Epoch: 6| Step: 1
Training loss: 2.975713333392398
Validation loss: 2.4662246914127013

Epoch: 6| Step: 2
Training loss: 2.532535556193395
Validation loss: 2.4704727521352083

Epoch: 6| Step: 3
Training loss: 2.5835965442901903
Validation loss: 2.488201533456457

Epoch: 6| Step: 4
Training loss: 2.594484340171288
Validation loss: 2.4753285354559322

Epoch: 6| Step: 5
Training loss: 2.8850459515963114
Validation loss: 2.4937870039851746

Epoch: 6| Step: 6
Training loss: 2.4054912014762473
Validation loss: 2.4838677686493025

Epoch: 6| Step: 7
Training loss: 3.155179739304386
Validation loss: 2.4823612423794836

Epoch: 6| Step: 8
Training loss: 3.2376368195480123
Validation loss: 2.476194953345338

Epoch: 6| Step: 9
Training loss: 2.566155408332066
Validation loss: 2.4369640260655236

Epoch: 6| Step: 10
Training loss: 2.3319068249299817
Validation loss: 2.4730381104022516

Epoch: 6| Step: 11
Training loss: 2.7764758163599748
Validation loss: 2.4516172031894876

Epoch: 6| Step: 12
Training loss: 2.516902243933518
Validation loss: 2.490190357235032

Epoch: 6| Step: 13
Training loss: 2.7086588052661686
Validation loss: 2.487072721909031

Epoch: 124| Step: 0
Training loss: 2.8848338910021
Validation loss: 2.479720390846015

Epoch: 6| Step: 1
Training loss: 2.208723597560347
Validation loss: 2.477222376841856

Epoch: 6| Step: 2
Training loss: 2.4870955248603286
Validation loss: 2.471234289846552

Epoch: 6| Step: 3
Training loss: 2.566871821473752
Validation loss: 2.483368628295739

Epoch: 6| Step: 4
Training loss: 2.6003487536471876
Validation loss: 2.488013441663658

Epoch: 6| Step: 5
Training loss: 3.157301925765012
Validation loss: 2.499155500786332

Epoch: 6| Step: 6
Training loss: 2.316491368291472
Validation loss: 2.477617018519419

Epoch: 6| Step: 7
Training loss: 2.3397232050086414
Validation loss: 2.4809003458832786

Epoch: 6| Step: 8
Training loss: 2.776423348721899
Validation loss: 2.486157124377821

Epoch: 6| Step: 9
Training loss: 3.2551642249615806
Validation loss: 2.468460891636666

Epoch: 6| Step: 10
Training loss: 3.023250130458669
Validation loss: 2.480340674409764

Epoch: 6| Step: 11
Training loss: 2.965085468314804
Validation loss: 2.468653853426244

Epoch: 6| Step: 12
Training loss: 2.335997615793396
Validation loss: 2.4663624285966264

Epoch: 6| Step: 13
Training loss: 2.3370958601063356
Validation loss: 2.4682896689710767

Epoch: 125| Step: 0
Training loss: 2.205781457874915
Validation loss: 2.477098494887927

Epoch: 6| Step: 1
Training loss: 2.142550750807924
Validation loss: 2.470558289301768

Epoch: 6| Step: 2
Training loss: 2.738788726407484
Validation loss: 2.458624750728079

Epoch: 6| Step: 3
Training loss: 3.1175705141415055
Validation loss: 2.4943249062199238

Epoch: 6| Step: 4
Training loss: 3.2328989097585117
Validation loss: 2.4837120339176946

Epoch: 6| Step: 5
Training loss: 3.4235363415404465
Validation loss: 2.468594435202154

Epoch: 6| Step: 6
Training loss: 1.6767478591543545
Validation loss: 2.4849162385110284

Epoch: 6| Step: 7
Training loss: 2.480394064912799
Validation loss: 2.460856263251768

Epoch: 6| Step: 8
Training loss: 2.2111190883081497
Validation loss: 2.483587180217275

Epoch: 6| Step: 9
Training loss: 2.314427268612163
Validation loss: 2.463895265088242

Epoch: 6| Step: 10
Training loss: 3.1302662535697032
Validation loss: 2.495179176656224

Epoch: 6| Step: 11
Training loss: 2.921351748038329
Validation loss: 2.4846813188227572

Epoch: 6| Step: 12
Training loss: 2.9591571216076593
Validation loss: 2.482175012249601

Epoch: 6| Step: 13
Training loss: 2.072150339556501
Validation loss: 2.477059992866178

Epoch: 126| Step: 0
Training loss: 2.6768465246609408
Validation loss: 2.4780961046105534

Epoch: 6| Step: 1
Training loss: 2.6284990151127565
Validation loss: 2.4949952534293365

Epoch: 6| Step: 2
Training loss: 2.060532643056597
Validation loss: 2.4678525881107984

Epoch: 6| Step: 3
Training loss: 2.5763399359984143
Validation loss: 2.4689359889513884

Epoch: 6| Step: 4
Training loss: 2.683937372810139
Validation loss: 2.4404801460900925

Epoch: 6| Step: 5
Training loss: 2.758595385209309
Validation loss: 2.468000569008425

Epoch: 6| Step: 6
Training loss: 2.8752847613412604
Validation loss: 2.4803391728700364

Epoch: 6| Step: 7
Training loss: 2.60077139708468
Validation loss: 2.4580089556003064

Epoch: 6| Step: 8
Training loss: 3.09162799231785
Validation loss: 2.471106340731842

Epoch: 6| Step: 9
Training loss: 2.638667357219948
Validation loss: 2.4679047734357775

Epoch: 6| Step: 10
Training loss: 2.914579698416293
Validation loss: 2.463243619223812

Epoch: 6| Step: 11
Training loss: 2.8323028223777427
Validation loss: 2.4504459462028225

Epoch: 6| Step: 12
Training loss: 2.825119697938164
Validation loss: 2.4805781013402344

Epoch: 6| Step: 13
Training loss: 2.4589479184648577
Validation loss: 2.457735516284831

Epoch: 127| Step: 0
Training loss: 2.83766462209813
Validation loss: 2.4831675069506223

Epoch: 6| Step: 1
Training loss: 3.246276483086225
Validation loss: 2.460203806180361

Epoch: 6| Step: 2
Training loss: 2.8348097227045823
Validation loss: 2.4883577650530313

Epoch: 6| Step: 3
Training loss: 2.814953306227557
Validation loss: 2.47670040546966

Epoch: 6| Step: 4
Training loss: 2.6826537150259315
Validation loss: 2.4712869950626226

Epoch: 6| Step: 5
Training loss: 3.0033944317709866
Validation loss: 2.482009341318674

Epoch: 6| Step: 6
Training loss: 2.530622428050469
Validation loss: 2.4920664091263696

Epoch: 6| Step: 7
Training loss: 2.838208846899425
Validation loss: 2.473451440216443

Epoch: 6| Step: 8
Training loss: 2.59172916970723
Validation loss: 2.4695191904337173

Epoch: 6| Step: 9
Training loss: 2.097475864603451
Validation loss: 2.4878282333428796

Epoch: 6| Step: 10
Training loss: 2.0741870252693944
Validation loss: 2.47921773627496

Epoch: 6| Step: 11
Training loss: 2.323668855642644
Validation loss: 2.481029151797448

Epoch: 6| Step: 12
Training loss: 2.834053191197997
Validation loss: 2.4728311326743317

Epoch: 6| Step: 13
Training loss: 2.6810804477959462
Validation loss: 2.4774534823038556

Epoch: 128| Step: 0
Training loss: 2.933679084197039
Validation loss: 2.4878054937840592

Epoch: 6| Step: 1
Training loss: 2.414710590562674
Validation loss: 2.477964304775796

Epoch: 6| Step: 2
Training loss: 2.3329579414667623
Validation loss: 2.493898685634586

Epoch: 6| Step: 3
Training loss: 2.7153916060016265
Validation loss: 2.4827027933910637

Epoch: 6| Step: 4
Training loss: 3.118404905991979
Validation loss: 2.492415355607286

Epoch: 6| Step: 5
Training loss: 2.1925050425281194
Validation loss: 2.4692305334362707

Epoch: 6| Step: 6
Training loss: 2.0215234135345814
Validation loss: 2.4881726956985055

Epoch: 6| Step: 7
Training loss: 2.6319299684616837
Validation loss: 2.4875040593193773

Epoch: 6| Step: 8
Training loss: 2.828352692432347
Validation loss: 2.4727108356812972

Epoch: 6| Step: 9
Training loss: 3.301621044703215
Validation loss: 2.479240464638852

Epoch: 6| Step: 10
Training loss: 2.5871768989258253
Validation loss: 2.466097306749967

Epoch: 6| Step: 11
Training loss: 1.8783998818217147
Validation loss: 2.478977093403165

Epoch: 6| Step: 12
Training loss: 3.3619295565222034
Validation loss: 2.482440700336829

Epoch: 6| Step: 13
Training loss: 2.614143446029865
Validation loss: 2.481706433242426

Epoch: 129| Step: 0
Training loss: 3.094850132630791
Validation loss: 2.476897077629162

Epoch: 6| Step: 1
Training loss: 2.761733167036052
Validation loss: 2.457763443831935

Epoch: 6| Step: 2
Training loss: 2.24191399477887
Validation loss: 2.473037442290181

Epoch: 6| Step: 3
Training loss: 2.15875198496698
Validation loss: 2.457839696915552

Epoch: 6| Step: 4
Training loss: 2.8949244511420025
Validation loss: 2.478139742360098

Epoch: 6| Step: 5
Training loss: 2.4266679159971662
Validation loss: 2.4554333010388736

Epoch: 6| Step: 6
Training loss: 2.7552028336256744
Validation loss: 2.4686902330899536

Epoch: 6| Step: 7
Training loss: 2.6509918228190217
Validation loss: 2.4911239740759235

Epoch: 6| Step: 8
Training loss: 2.2896447596642067
Validation loss: 2.49158741227538

Epoch: 6| Step: 9
Training loss: 2.8653565259195726
Validation loss: 2.4647139796615356

Epoch: 6| Step: 10
Training loss: 2.7431995230664596
Validation loss: 2.4871290073612586

Epoch: 6| Step: 11
Training loss: 3.279079627724227
Validation loss: 2.4833990321113224

Epoch: 6| Step: 12
Training loss: 2.325752636903582
Validation loss: 2.4661727319762057

Epoch: 6| Step: 13
Training loss: 2.650290142226352
Validation loss: 2.460743996675365

Epoch: 130| Step: 0
Training loss: 3.03285080631519
Validation loss: 2.4560561070735436

Epoch: 6| Step: 1
Training loss: 2.8049971640669416
Validation loss: 2.4865174062253708

Epoch: 6| Step: 2
Training loss: 2.3099305595760833
Validation loss: 2.4700323315289956

Epoch: 6| Step: 3
Training loss: 1.4191710364109635
Validation loss: 2.4932314337041355

Epoch: 6| Step: 4
Training loss: 3.4030595589222745
Validation loss: 2.4813832994918807

Epoch: 6| Step: 5
Training loss: 2.412865104126559
Validation loss: 2.4902945709191515

Epoch: 6| Step: 6
Training loss: 2.854364727044376
Validation loss: 2.4815072010197277

Epoch: 6| Step: 7
Training loss: 2.442779301396676
Validation loss: 2.4880370407254775

Epoch: 6| Step: 8
Training loss: 2.7058529181477025
Validation loss: 2.4700221756800746

Epoch: 6| Step: 9
Training loss: 2.825393622328356
Validation loss: 2.4812351775512522

Epoch: 6| Step: 10
Training loss: 3.0982554602998493
Validation loss: 2.4865964849694677

Epoch: 6| Step: 11
Training loss: 2.9198916634620162
Validation loss: 2.4909861302374012

Epoch: 6| Step: 12
Training loss: 1.988474538584939
Validation loss: 2.4818416011587194

Epoch: 6| Step: 13
Training loss: 2.3982897784440396
Validation loss: 2.471822157101381

Epoch: 131| Step: 0
Training loss: 2.118841334712104
Validation loss: 2.4944650855571076

Epoch: 6| Step: 1
Training loss: 2.2798327916720993
Validation loss: 2.4843486883300323

Epoch: 6| Step: 2
Training loss: 2.966659130844089
Validation loss: 2.4679201236228128

Epoch: 6| Step: 3
Training loss: 2.797711295295011
Validation loss: 2.4983627526405563

Epoch: 6| Step: 4
Training loss: 3.3776518681828596
Validation loss: 2.482382941243071

Epoch: 6| Step: 5
Training loss: 2.541460143490294
Validation loss: 2.4970322970674497

Epoch: 6| Step: 6
Training loss: 2.906992007459447
Validation loss: 2.468628165521637

Epoch: 6| Step: 7
Training loss: 2.3750208803564035
Validation loss: 2.4834270622991537

Epoch: 6| Step: 8
Training loss: 2.285378887057826
Validation loss: 2.452324015330885

Epoch: 6| Step: 9
Training loss: 2.593021520323038
Validation loss: 2.469037219040791

Epoch: 6| Step: 10
Training loss: 2.647951064547923
Validation loss: 2.4770925677972135

Epoch: 6| Step: 11
Training loss: 2.7892500443006805
Validation loss: 2.4894630408902505

Epoch: 6| Step: 12
Training loss: 3.222706557372489
Validation loss: 2.4890687767473763

Epoch: 6| Step: 13
Training loss: 1.8700624303545221
Validation loss: 2.4855524122294033

Epoch: 132| Step: 0
Training loss: 2.8266761398456586
Validation loss: 2.4937463581524204

Epoch: 6| Step: 1
Training loss: 2.951848152679858
Validation loss: 2.4778996497015138

Epoch: 6| Step: 2
Training loss: 2.672135725183373
Validation loss: 2.4767703019004337

Epoch: 6| Step: 3
Training loss: 2.060933761072708
Validation loss: 2.487633363720074

Epoch: 6| Step: 4
Training loss: 2.2992030172687925
Validation loss: 2.4825751627294705

Epoch: 6| Step: 5
Training loss: 2.5614039240132906
Validation loss: 2.448143172579358

Epoch: 6| Step: 6
Training loss: 3.0973477492580623
Validation loss: 2.48449899997727

Epoch: 6| Step: 7
Training loss: 3.2006451194889136
Validation loss: 2.481548435758894

Epoch: 6| Step: 8
Training loss: 2.271189413821443
Validation loss: 2.4875346537490066

Epoch: 6| Step: 9
Training loss: 2.7646305861144347
Validation loss: 2.4709109071307154

Epoch: 6| Step: 10
Training loss: 2.990197538401861
Validation loss: 2.4896740897921372

Epoch: 6| Step: 11
Training loss: 2.337233780169212
Validation loss: 2.477564369321496

Epoch: 6| Step: 12
Training loss: 2.6377059783776398
Validation loss: 2.464729465175147

Epoch: 6| Step: 13
Training loss: 2.4693616278423174
Validation loss: 2.4742617328569287

Epoch: 133| Step: 0
Training loss: 2.5247623520615177
Validation loss: 2.4735572110660926

Epoch: 6| Step: 1
Training loss: 2.816095639268243
Validation loss: 2.4800314855925514

Epoch: 6| Step: 2
Training loss: 2.8103883233324862
Validation loss: 2.497717303337206

Epoch: 6| Step: 3
Training loss: 2.998722122145486
Validation loss: 2.464942668173275

Epoch: 6| Step: 4
Training loss: 3.1452447875419125
Validation loss: 2.4790921495185563

Epoch: 6| Step: 5
Training loss: 2.3130303882956134
Validation loss: 2.486881726355514

Epoch: 6| Step: 6
Training loss: 2.875965122271389
Validation loss: 2.478951432841601

Epoch: 6| Step: 7
Training loss: 2.3930768174476396
Validation loss: 2.4935500485131157

Epoch: 6| Step: 8
Training loss: 2.3965232740259372
Validation loss: 2.4780604413368823

Epoch: 6| Step: 9
Training loss: 2.836362864643161
Validation loss: 2.4743460692792003

Epoch: 6| Step: 10
Training loss: 1.973160360150565
Validation loss: 2.487084413060436

Epoch: 6| Step: 11
Training loss: 2.987214180908706
Validation loss: 2.4998204218038365

Epoch: 6| Step: 12
Training loss: 2.1844311577341227
Validation loss: 2.487802754759414

Epoch: 6| Step: 13
Training loss: 3.2862783504640194
Validation loss: 2.476095230876264

Epoch: 134| Step: 0
Training loss: 2.8539278436319506
Validation loss: 2.4892460615240477

Epoch: 6| Step: 1
Training loss: 2.7191706364897184
Validation loss: 2.500217966606786

Epoch: 6| Step: 2
Training loss: 2.3863643002199515
Validation loss: 2.4669370888667044

Epoch: 6| Step: 3
Training loss: 2.4176526086366015
Validation loss: 2.458943939990769

Epoch: 6| Step: 4
Training loss: 3.1517746422270965
Validation loss: 2.464804975422656

Epoch: 6| Step: 5
Training loss: 2.487368333868653
Validation loss: 2.4764173454865053

Epoch: 6| Step: 6
Training loss: 2.6117866929482716
Validation loss: 2.4701749708674576

Epoch: 6| Step: 7
Training loss: 2.3134638865273773
Validation loss: 2.4897876589922463

Epoch: 6| Step: 8
Training loss: 2.564344719064853
Validation loss: 2.4746662723243826

Epoch: 6| Step: 9
Training loss: 2.9513298916374056
Validation loss: 2.4847248099672794

Epoch: 6| Step: 10
Training loss: 2.477774531053926
Validation loss: 2.472752821534197

Epoch: 6| Step: 11
Training loss: 2.745888757990488
Validation loss: 2.492322174063653

Epoch: 6| Step: 12
Training loss: 2.8370337351049484
Validation loss: 2.4630767540369205

Epoch: 6| Step: 13
Training loss: 2.839786660146583
Validation loss: 2.479788541849119

Epoch: 135| Step: 0
Training loss: 2.551023322823864
Validation loss: 2.47818705485956

Epoch: 6| Step: 1
Training loss: 2.6515214906757096
Validation loss: 2.475423574595428

Epoch: 6| Step: 2
Training loss: 2.655680606625262
Validation loss: 2.4873685997799133

Epoch: 6| Step: 3
Training loss: 2.785399010392358
Validation loss: 2.486072875659013

Epoch: 6| Step: 4
Training loss: 2.1243171716794866
Validation loss: 2.4646603735290062

Epoch: 6| Step: 5
Training loss: 3.047648796223021
Validation loss: 2.493867998633732

Epoch: 6| Step: 6
Training loss: 2.583239481872156
Validation loss: 2.4918249504766594

Epoch: 6| Step: 7
Training loss: 2.7434545127583614
Validation loss: 2.4805182411579856

Epoch: 6| Step: 8
Training loss: 2.893862339418023
Validation loss: 2.464516844980477

Epoch: 6| Step: 9
Training loss: 2.5827382745710183
Validation loss: 2.4860707601494263

Epoch: 6| Step: 10
Training loss: 2.6893888533703283
Validation loss: 2.4983563352261484

Epoch: 6| Step: 11
Training loss: 2.718746667618737
Validation loss: 2.4649280482781557

Epoch: 6| Step: 12
Training loss: 2.645855120071061
Validation loss: 2.4877142037036553

Epoch: 6| Step: 13
Training loss: 2.5693691574843114
Validation loss: 2.4780436704307816

Epoch: 136| Step: 0
Training loss: 2.8353768627354197
Validation loss: 2.4991555213023875

Epoch: 6| Step: 1
Training loss: 2.3767563198491493
Validation loss: 2.4812764726034935

Epoch: 6| Step: 2
Training loss: 3.1799212845470763
Validation loss: 2.4874797275851015

Epoch: 6| Step: 3
Training loss: 3.3535521676900237
Validation loss: 2.4589473294092206

Epoch: 6| Step: 4
Training loss: 2.5371540115576425
Validation loss: 2.4930553650130176

Epoch: 6| Step: 5
Training loss: 2.6365515535820734
Validation loss: 2.4640544912685773

Epoch: 6| Step: 6
Training loss: 2.5595065985488565
Validation loss: 2.4741768827335786

Epoch: 6| Step: 7
Training loss: 1.8283525635024729
Validation loss: 2.4735887076260052

Epoch: 6| Step: 8
Training loss: 2.0549081894165373
Validation loss: 2.4890966946795805

Epoch: 6| Step: 9
Training loss: 2.774929193504076
Validation loss: 2.4889502878733647

Epoch: 6| Step: 10
Training loss: 3.0396944384350104
Validation loss: 2.4738308208010955

Epoch: 6| Step: 11
Training loss: 2.862687656964673
Validation loss: 2.4760959245648437

Epoch: 6| Step: 12
Training loss: 2.650371914082811
Validation loss: 2.473156758334986

Epoch: 6| Step: 13
Training loss: 1.9127603266443103
Validation loss: 2.4780364927669245

Epoch: 137| Step: 0
Training loss: 3.1167716989481695
Validation loss: 2.4929573895616053

Epoch: 6| Step: 1
Training loss: 2.9202840625078417
Validation loss: 2.4617186093689707

Epoch: 6| Step: 2
Training loss: 2.1602480767101
Validation loss: 2.480671229006096

Epoch: 6| Step: 3
Training loss: 3.196335309396562
Validation loss: 2.485719078962873

Epoch: 6| Step: 4
Training loss: 2.874196645201167
Validation loss: 2.4869538343535624

Epoch: 6| Step: 5
Training loss: 2.204989895267645
Validation loss: 2.4699875665997486

Epoch: 6| Step: 6
Training loss: 2.479865630109018
Validation loss: 2.507699396461025

Epoch: 6| Step: 7
Training loss: 2.198614169507106
Validation loss: 2.4871038205390508

Epoch: 6| Step: 8
Training loss: 2.6958997888250074
Validation loss: 2.463662776967521

Epoch: 6| Step: 9
Training loss: 2.5273694091626364
Validation loss: 2.496457038188406

Epoch: 6| Step: 10
Training loss: 2.435451429220673
Validation loss: 2.48388775447068

Epoch: 6| Step: 11
Training loss: 2.639167699529576
Validation loss: 2.479746649275792

Epoch: 6| Step: 12
Training loss: 2.737060623094086
Validation loss: 2.498083141668848

Epoch: 6| Step: 13
Training loss: 3.024437081160385
Validation loss: 2.4904328297938623

Epoch: 138| Step: 0
Training loss: 2.5868226348745513
Validation loss: 2.4865291938098206

Epoch: 6| Step: 1
Training loss: 2.6208918077245866
Validation loss: 2.4917518445047313

Epoch: 6| Step: 2
Training loss: 2.6847529010979043
Validation loss: 2.4744842826861566

Epoch: 6| Step: 3
Training loss: 2.7614967008726743
Validation loss: 2.489618379834745

Epoch: 6| Step: 4
Training loss: 2.489569457798894
Validation loss: 2.486586838035555

Epoch: 6| Step: 5
Training loss: 2.493433912699904
Validation loss: 2.4674585499595114

Epoch: 6| Step: 6
Training loss: 2.4083177673822376
Validation loss: 2.500035769709165

Epoch: 6| Step: 7
Training loss: 2.490731127690333
Validation loss: 2.498226105559408

Epoch: 6| Step: 8
Training loss: 2.357844178206264
Validation loss: 2.4844380754649475

Epoch: 6| Step: 9
Training loss: 3.331608198707835
Validation loss: 2.4706580225417194

Epoch: 6| Step: 10
Training loss: 2.9400289484791657
Validation loss: 2.474199331016397

Epoch: 6| Step: 11
Training loss: 2.403672361106971
Validation loss: 2.4847285893027085

Epoch: 6| Step: 12
Training loss: 2.5470815937525746
Validation loss: 2.5022329920137087

Epoch: 6| Step: 13
Training loss: 3.445111534848883
Validation loss: 2.4711160854476453

Epoch: 139| Step: 0
Training loss: 2.468720447991143
Validation loss: 2.4939994000166408

Epoch: 6| Step: 1
Training loss: 2.2296060741074917
Validation loss: 2.4882967423581204

Epoch: 6| Step: 2
Training loss: 3.0355329635707804
Validation loss: 2.4869546796386395

Epoch: 6| Step: 3
Training loss: 2.169051056559507
Validation loss: 2.5093867478854035

Epoch: 6| Step: 4
Training loss: 2.4528614072653907
Validation loss: 2.483061161543962

Epoch: 6| Step: 5
Training loss: 2.6838677278947562
Validation loss: 2.49890241935118

Epoch: 6| Step: 6
Training loss: 3.3712193541924904
Validation loss: 2.471576432537916

Epoch: 6| Step: 7
Training loss: 2.9736187012185704
Validation loss: 2.481243923670898

Epoch: 6| Step: 8
Training loss: 2.8983358277947557
Validation loss: 2.4940535694558417

Epoch: 6| Step: 9
Training loss: 2.6672424847075686
Validation loss: 2.479143101397602

Epoch: 6| Step: 10
Training loss: 2.209452531417325
Validation loss: 2.485176678897569

Epoch: 6| Step: 11
Training loss: 2.3028086099476597
Validation loss: 2.4777670556636915

Epoch: 6| Step: 12
Training loss: 2.5142904023027683
Validation loss: 2.4940153189033882

Epoch: 6| Step: 13
Training loss: 3.052031862695041
Validation loss: 2.484438823577448

Epoch: 140| Step: 0
Training loss: 2.7218417422937677
Validation loss: 2.4992682339681482

Epoch: 6| Step: 1
Training loss: 2.7470278718004457
Validation loss: 2.5053525292257

Epoch: 6| Step: 2
Training loss: 2.73673212090051
Validation loss: 2.484578202808504

Epoch: 6| Step: 3
Training loss: 2.5520162352999196
Validation loss: 2.48265419562881

Epoch: 6| Step: 4
Training loss: 3.020646574013196
Validation loss: 2.484562430338515

Epoch: 6| Step: 5
Training loss: 2.52254779827098
Validation loss: 2.4686774308990267

Epoch: 6| Step: 6
Training loss: 1.7362867936148672
Validation loss: 2.4846525134650665

Epoch: 6| Step: 7
Training loss: 2.6440602366270154
Validation loss: 2.4823008788631578

Epoch: 6| Step: 8
Training loss: 3.1213612543275233
Validation loss: 2.489682911296327

Epoch: 6| Step: 9
Training loss: 2.345083340625915
Validation loss: 2.4814424486786995

Epoch: 6| Step: 10
Training loss: 2.354618963042769
Validation loss: 2.5070706085593475

Epoch: 6| Step: 11
Training loss: 2.780561726305306
Validation loss: 2.480842188212269

Epoch: 6| Step: 12
Training loss: 3.2775128108399096
Validation loss: 2.502589238540055

Epoch: 6| Step: 13
Training loss: 1.9381372572810505
Validation loss: 2.497535698997988

Epoch: 141| Step: 0
Training loss: 2.8704303416159287
Validation loss: 2.5029312464170768

Epoch: 6| Step: 1
Training loss: 2.6743903561672977
Validation loss: 2.4760675763567983

Epoch: 6| Step: 2
Training loss: 2.1955261126541936
Validation loss: 2.4810142092407097

Epoch: 6| Step: 3
Training loss: 2.4614755193750986
Validation loss: 2.4754122830177416

Epoch: 6| Step: 4
Training loss: 2.946050010241136
Validation loss: 2.491932439325994

Epoch: 6| Step: 5
Training loss: 2.4655626219001183
Validation loss: 2.475340244791503

Epoch: 6| Step: 6
Training loss: 2.42246952758142
Validation loss: 2.4891690207104835

Epoch: 6| Step: 7
Training loss: 2.429004438249374
Validation loss: 2.4834459109850835

Epoch: 6| Step: 8
Training loss: 3.0985738734841353
Validation loss: 2.4673740659142678

Epoch: 6| Step: 9
Training loss: 2.686054018166254
Validation loss: 2.5051918621919027

Epoch: 6| Step: 10
Training loss: 2.649186740098012
Validation loss: 2.4861228471533474

Epoch: 6| Step: 11
Training loss: 2.6834203228168056
Validation loss: 2.4809722536644494

Epoch: 6| Step: 12
Training loss: 2.5730576161272887
Validation loss: 2.487145948924745

Epoch: 6| Step: 13
Training loss: 2.8830597727517335
Validation loss: 2.473607044678362

Epoch: 142| Step: 0
Training loss: 2.18777551278369
Validation loss: 2.4923286399308267

Epoch: 6| Step: 1
Training loss: 2.37201151297929
Validation loss: 2.4633252153853

Epoch: 6| Step: 2
Training loss: 2.6725523686786903
Validation loss: 2.476992930109747

Epoch: 6| Step: 3
Training loss: 2.4983343297520797
Validation loss: 2.4728402423415763

Epoch: 6| Step: 4
Training loss: 3.014907672537549
Validation loss: 2.472759375895181

Epoch: 6| Step: 5
Training loss: 2.4368353695617535
Validation loss: 2.4886461566264173

Epoch: 6| Step: 6
Training loss: 2.9351137898886863
Validation loss: 2.4874051674607784

Epoch: 6| Step: 7
Training loss: 2.668704108886666
Validation loss: 2.4954144230664093

Epoch: 6| Step: 8
Training loss: 2.763470171250295
Validation loss: 2.494774502996106

Epoch: 6| Step: 9
Training loss: 2.464912715859907
Validation loss: 2.478334199390916

Epoch: 6| Step: 10
Training loss: 2.521221877070316
Validation loss: 2.4696231189565845

Epoch: 6| Step: 11
Training loss: 2.8038998828814585
Validation loss: 2.484518317243954

Epoch: 6| Step: 12
Training loss: 2.7974665351891037
Validation loss: 2.4822227632020843

Epoch: 6| Step: 13
Training loss: 2.8437240096361247
Validation loss: 2.497031656422167

Epoch: 143| Step: 0
Training loss: 2.606627977072707
Validation loss: 2.4849055585273416

Epoch: 6| Step: 1
Training loss: 3.0013310340704202
Validation loss: 2.4901272781959523

Epoch: 6| Step: 2
Training loss: 1.8929968844033953
Validation loss: 2.480997400435935

Epoch: 6| Step: 3
Training loss: 3.200124088504027
Validation loss: 2.4987969446873812

Epoch: 6| Step: 4
Training loss: 2.6751362489601327
Validation loss: 2.4826629326189584

Epoch: 6| Step: 5
Training loss: 2.906156312806545
Validation loss: 2.4791919944450402

Epoch: 6| Step: 6
Training loss: 2.313946658061188
Validation loss: 2.497420354170981

Epoch: 6| Step: 7
Training loss: 2.273868270910201
Validation loss: 2.4885753204694048

Epoch: 6| Step: 8
Training loss: 2.1280359011468355
Validation loss: 2.482764238567791

Epoch: 6| Step: 9
Training loss: 2.7675233349595985
Validation loss: 2.4760944502175395

Epoch: 6| Step: 10
Training loss: 2.733538952125853
Validation loss: 2.497922299564217

Epoch: 6| Step: 11
Training loss: 3.039674672738658
Validation loss: 2.503606906641337

Epoch: 6| Step: 12
Training loss: 2.7021124382088813
Validation loss: 2.487370463219266

Epoch: 6| Step: 13
Training loss: 2.2861029856421418
Validation loss: 2.4726187135449993

Epoch: 144| Step: 0
Training loss: 2.8716293146852143
Validation loss: 2.4751656481515814

Epoch: 6| Step: 1
Training loss: 2.4533483318547633
Validation loss: 2.4760067032295496

Epoch: 6| Step: 2
Training loss: 3.096695855711103
Validation loss: 2.47161271421079

Epoch: 6| Step: 3
Training loss: 2.787028706485225
Validation loss: 2.4802732122345685

Epoch: 6| Step: 4
Training loss: 2.9849943946261788
Validation loss: 2.487030206762269

Epoch: 6| Step: 5
Training loss: 2.0586322006311826
Validation loss: 2.4791281355809596

Epoch: 6| Step: 6
Training loss: 2.562902372449881
Validation loss: 2.478780581105737

Epoch: 6| Step: 7
Training loss: 2.2369390327900485
Validation loss: 2.4670176442449083

Epoch: 6| Step: 8
Training loss: 2.3698367159966613
Validation loss: 2.4894176975021467

Epoch: 6| Step: 9
Training loss: 3.3598753090837064
Validation loss: 2.48563760373829

Epoch: 6| Step: 10
Training loss: 2.697694295509394
Validation loss: 2.4849271320058337

Epoch: 6| Step: 11
Training loss: 2.069687313475522
Validation loss: 2.4924894716930743

Epoch: 6| Step: 12
Training loss: 2.329066348659376
Validation loss: 2.4953238634009787

Epoch: 6| Step: 13
Training loss: 2.864017740535667
Validation loss: 2.4713618018412324

Epoch: 145| Step: 0
Training loss: 2.1308980880563313
Validation loss: 2.4822501136713058

Epoch: 6| Step: 1
Training loss: 2.7480244910135805
Validation loss: 2.4926965655004025

Epoch: 6| Step: 2
Training loss: 2.9908753548390465
Validation loss: 2.4906658864091336

Epoch: 6| Step: 3
Training loss: 2.7975124719527527
Validation loss: 2.4916601866252592

Epoch: 6| Step: 4
Training loss: 2.058473760882845
Validation loss: 2.452579688232572

Epoch: 6| Step: 5
Training loss: 3.3449959973595
Validation loss: 2.479083328590488

Epoch: 6| Step: 6
Training loss: 2.677187184101904
Validation loss: 2.4763516856884076

Epoch: 6| Step: 7
Training loss: 2.5826289744635735
Validation loss: 2.4991622597916443

Epoch: 6| Step: 8
Training loss: 2.905518306382382
Validation loss: 2.48163115317905

Epoch: 6| Step: 9
Training loss: 2.5361621430485313
Validation loss: 2.4525247485712875

Epoch: 6| Step: 10
Training loss: 1.831761972772729
Validation loss: 2.4845416007430043

Epoch: 6| Step: 11
Training loss: 2.31885212881557
Validation loss: 2.4705961683596116

Epoch: 6| Step: 12
Training loss: 3.173702822045746
Validation loss: 2.508616435158847

Epoch: 6| Step: 13
Training loss: 2.5438693981595395
Validation loss: 2.493998481566809

Epoch: 146| Step: 0
Training loss: 3.016242087678297
Validation loss: 2.4833480127031082

Epoch: 6| Step: 1
Training loss: 3.5335487378036943
Validation loss: 2.5047236158201516

Epoch: 6| Step: 2
Training loss: 1.9280735324315337
Validation loss: 2.4806737991858454

Epoch: 6| Step: 3
Training loss: 1.785224095230184
Validation loss: 2.4742646531691865

Epoch: 6| Step: 4
Training loss: 2.816036797998326
Validation loss: 2.477909609797678

Epoch: 6| Step: 5
Training loss: 2.6652506307156236
Validation loss: 2.484642319354904

Epoch: 6| Step: 6
Training loss: 2.755503349638571
Validation loss: 2.5355600224835215

Epoch: 6| Step: 7
Training loss: 2.362137951432795
Validation loss: 2.483260497761951

Epoch: 6| Step: 8
Training loss: 2.0596668551785964
Validation loss: 2.480169996157293

Epoch: 6| Step: 9
Training loss: 3.0148719282135805
Validation loss: 2.485833769915434

Epoch: 6| Step: 10
Training loss: 2.2972627688725655
Validation loss: 2.477552940566515

Epoch: 6| Step: 11
Training loss: 2.4837735965646504
Validation loss: 2.478104767668099

Epoch: 6| Step: 12
Training loss: 2.8199265657156842
Validation loss: 2.4717961287465737

Epoch: 6| Step: 13
Training loss: 2.608072286914604
Validation loss: 2.483983207152928

Epoch: 147| Step: 0
Training loss: 2.8189458943912653
Validation loss: 2.4814252491513704

Epoch: 6| Step: 1
Training loss: 2.603169446110094
Validation loss: 2.4717132273980646

Epoch: 6| Step: 2
Training loss: 2.729632728520649
Validation loss: 2.4818453420169435

Epoch: 6| Step: 3
Training loss: 3.0495881349731064
Validation loss: 2.4695753226563646

Epoch: 6| Step: 4
Training loss: 2.2483168770442594
Validation loss: 2.483291466051631

Epoch: 6| Step: 5
Training loss: 2.8434416215973433
Validation loss: 2.4924164181269046

Epoch: 6| Step: 6
Training loss: 2.454161601123429
Validation loss: 2.4932970941983195

Epoch: 6| Step: 7
Training loss: 2.1533560752061414
Validation loss: 2.4634484480243986

Epoch: 6| Step: 8
Training loss: 2.3232588124011095
Validation loss: 2.4810115670822848

Epoch: 6| Step: 9
Training loss: 2.3544117847765973
Validation loss: 2.487472843049339

Epoch: 6| Step: 10
Training loss: 3.0046739725729843
Validation loss: 2.4912829304832775

Epoch: 6| Step: 11
Training loss: 2.540384459047108
Validation loss: 2.485676872247264

Epoch: 6| Step: 12
Training loss: 2.96471540452192
Validation loss: 2.4722296026541475

Epoch: 6| Step: 13
Training loss: 2.68737446691397
Validation loss: 2.4717126527937534

Epoch: 148| Step: 0
Training loss: 2.002466111866766
Validation loss: 2.485726495888736

Epoch: 6| Step: 1
Training loss: 2.5091528237158514
Validation loss: 2.485602668538682

Epoch: 6| Step: 2
Training loss: 3.3845457081525328
Validation loss: 2.480748154459574

Epoch: 6| Step: 3
Training loss: 2.127443703647342
Validation loss: 2.492777744186936

Epoch: 6| Step: 4
Training loss: 1.8725566202523825
Validation loss: 2.4942983942521084

Epoch: 6| Step: 5
Training loss: 2.367456905532695
Validation loss: 2.4760174091726426

Epoch: 6| Step: 6
Training loss: 2.5766778757000397
Validation loss: 2.498831858546694

Epoch: 6| Step: 7
Training loss: 2.8944854526783517
Validation loss: 2.474608254071653

Epoch: 6| Step: 8
Training loss: 2.889481436856445
Validation loss: 2.486808945153601

Epoch: 6| Step: 9
Training loss: 3.280467203407441
Validation loss: 2.5086935389004728

Epoch: 6| Step: 10
Training loss: 2.2978537413995728
Validation loss: 2.4919157730967973

Epoch: 6| Step: 11
Training loss: 2.5200708565514174
Validation loss: 2.4900359527786815

Epoch: 6| Step: 12
Training loss: 2.5505377520347436
Validation loss: 2.466850483549185

Epoch: 6| Step: 13
Training loss: 3.2956877826199276
Validation loss: 2.48924289462139

Epoch: 149| Step: 0
Training loss: 2.4424714473121396
Validation loss: 2.476847673511283

Epoch: 6| Step: 1
Training loss: 2.3681528873769833
Validation loss: 2.5004189278707445

Epoch: 6| Step: 2
Training loss: 2.8190498378660855
Validation loss: 2.50216319519982

Epoch: 6| Step: 3
Training loss: 2.349260286827254
Validation loss: 2.4752386173881784

Epoch: 6| Step: 4
Training loss: 3.651475837929495
Validation loss: 2.484000021554793

Epoch: 6| Step: 5
Training loss: 2.9286195970355426
Validation loss: 2.4905801093048097

Epoch: 6| Step: 6
Training loss: 2.709186263148966
Validation loss: 2.500311422947569

Epoch: 6| Step: 7
Training loss: 2.6672966530828317
Validation loss: 2.4721650034438856

Epoch: 6| Step: 8
Training loss: 2.8288403022704394
Validation loss: 2.511654058984757

Epoch: 6| Step: 9
Training loss: 1.679852641659327
Validation loss: 2.472364409894674

Epoch: 6| Step: 10
Training loss: 1.6405952087603963
Validation loss: 2.453545419326645

Epoch: 6| Step: 11
Training loss: 3.386845182634969
Validation loss: 2.489003221006422

Epoch: 6| Step: 12
Training loss: 2.590484125703858
Validation loss: 2.479007050555013

Epoch: 6| Step: 13
Training loss: 1.9968711100795629
Validation loss: 2.479356481521219

Epoch: 150| Step: 0
Training loss: 2.170894483802068
Validation loss: 2.5125131806597376

Epoch: 6| Step: 1
Training loss: 2.2158958452446846
Validation loss: 2.4942644468050186

Epoch: 6| Step: 2
Training loss: 2.6239800969566924
Validation loss: 2.493395490190206

Epoch: 6| Step: 3
Training loss: 3.6213635587943083
Validation loss: 2.482670672073381

Epoch: 6| Step: 4
Training loss: 2.2212275252442257
Validation loss: 2.4862872376204836

Epoch: 6| Step: 5
Training loss: 2.7468488151682307
Validation loss: 2.471321325568982

Epoch: 6| Step: 6
Training loss: 2.6129115460414125
Validation loss: 2.4912395846998843

Epoch: 6| Step: 7
Training loss: 2.9038850739912587
Validation loss: 2.4767272279548984

Epoch: 6| Step: 8
Training loss: 2.579037221722058
Validation loss: 2.5017427051443217

Epoch: 6| Step: 9
Training loss: 2.5502875932567077
Validation loss: 2.4855014555890915

Epoch: 6| Step: 10
Training loss: 2.146163124987851
Validation loss: 2.4799679331404945

Epoch: 6| Step: 11
Training loss: 3.1271977135369586
Validation loss: 2.480703172627209

Epoch: 6| Step: 12
Training loss: 2.515008886484634
Validation loss: 2.4918503303207595

Epoch: 6| Step: 13
Training loss: 2.6277214656743535
Validation loss: 2.488737581457475

Epoch: 151| Step: 0
Training loss: 1.5060871906852022
Validation loss: 2.4925009183577216

Epoch: 6| Step: 1
Training loss: 2.4675492855510575
Validation loss: 2.484794126790355

Epoch: 6| Step: 2
Training loss: 3.493378779525806
Validation loss: 2.4739271703202736

Epoch: 6| Step: 3
Training loss: 2.3859895132174906
Validation loss: 2.501070077621167

Epoch: 6| Step: 4
Training loss: 2.3046097047251366
Validation loss: 2.4758098961414468

Epoch: 6| Step: 5
Training loss: 3.21419610398131
Validation loss: 2.4795615130925945

Epoch: 6| Step: 6
Training loss: 3.353661935555032
Validation loss: 2.4908542660162514

Epoch: 6| Step: 7
Training loss: 2.4199135990324585
Validation loss: 2.5028293678128763

Epoch: 6| Step: 8
Training loss: 2.7169277178851567
Validation loss: 2.4872437966680763

Epoch: 6| Step: 9
Training loss: 2.870801596796007
Validation loss: 2.498594204646028

Epoch: 6| Step: 10
Training loss: 2.451415614437803
Validation loss: 2.4746340912374203

Epoch: 6| Step: 11
Training loss: 2.460657109832739
Validation loss: 2.482232038765048

Epoch: 6| Step: 12
Training loss: 2.089681743866614
Validation loss: 2.489010587461611

Epoch: 6| Step: 13
Training loss: 2.133346770164771
Validation loss: 2.492606831711309

Epoch: 152| Step: 0
Training loss: 2.2727702102073057
Validation loss: 2.5130361775975394

Epoch: 6| Step: 1
Training loss: 2.1458988241429866
Validation loss: 2.4920675818678446

Epoch: 6| Step: 2
Training loss: 2.335671195986391
Validation loss: 2.4955002384360276

Epoch: 6| Step: 3
Training loss: 3.118600319613145
Validation loss: 2.4863411270746503

Epoch: 6| Step: 4
Training loss: 3.0017196177278365
Validation loss: 2.492176647498897

Epoch: 6| Step: 5
Training loss: 2.6891717368796155
Validation loss: 2.5030169218594387

Epoch: 6| Step: 6
Training loss: 2.891686816699558
Validation loss: 2.507705966824603

Epoch: 6| Step: 7
Training loss: 2.5342888193023922
Validation loss: 2.490423919329475

Epoch: 6| Step: 8
Training loss: 3.393471362511196
Validation loss: 2.5003773025136833

Epoch: 6| Step: 9
Training loss: 1.148082340882893
Validation loss: 2.4734467087588112

Epoch: 6| Step: 10
Training loss: 2.789932756331427
Validation loss: 2.480447385794629

Epoch: 6| Step: 11
Training loss: 2.273116675742648
Validation loss: 2.500803761842017

Epoch: 6| Step: 12
Training loss: 2.6575407594585627
Validation loss: 2.468842558282891

Epoch: 6| Step: 13
Training loss: 3.0624875438203314
Validation loss: 2.5020264851769944

Epoch: 153| Step: 0
Training loss: 2.3050796433795946
Validation loss: 2.4880494465521568

Epoch: 6| Step: 1
Training loss: 2.678508888604443
Validation loss: 2.479378768135638

Epoch: 6| Step: 2
Training loss: 2.7497449236393847
Validation loss: 2.4961856096759356

Epoch: 6| Step: 3
Training loss: 2.428412295986181
Validation loss: 2.497028714995803

Epoch: 6| Step: 4
Training loss: 3.1486187828257313
Validation loss: 2.474683280560113

Epoch: 6| Step: 5
Training loss: 2.8551100311187523
Validation loss: 2.4798976244240514

Epoch: 6| Step: 6
Training loss: 2.4333546920605404
Validation loss: 2.483674856540355

Epoch: 6| Step: 7
Training loss: 2.344449053464018
Validation loss: 2.479873137423079

Epoch: 6| Step: 8
Training loss: 2.1721310910520772
Validation loss: 2.5013503416825507

Epoch: 6| Step: 9
Training loss: 2.2973507758194445
Validation loss: 2.4836939954551727

Epoch: 6| Step: 10
Training loss: 2.3617079360719386
Validation loss: 2.4891645014250403

Epoch: 6| Step: 11
Training loss: 3.0190132358054926
Validation loss: 2.4763078559631166

Epoch: 6| Step: 12
Training loss: 2.866594882184592
Validation loss: 2.4991449832083994

Epoch: 6| Step: 13
Training loss: 2.7300062756588526
Validation loss: 2.4796678473056586

Epoch: 154| Step: 0
Training loss: 2.363645112581667
Validation loss: 2.4809991250305408

Epoch: 6| Step: 1
Training loss: 2.825234469245584
Validation loss: 2.462243893130772

Epoch: 6| Step: 2
Training loss: 3.5222745274438343
Validation loss: 2.4920662640767275

Epoch: 6| Step: 3
Training loss: 2.57974432750381
Validation loss: 2.4810008413574756

Epoch: 6| Step: 4
Training loss: 2.634833672212462
Validation loss: 2.4711574510427723

Epoch: 6| Step: 5
Training loss: 2.3476231425104177
Validation loss: 2.4853319278161212

Epoch: 6| Step: 6
Training loss: 2.337725411220617
Validation loss: 2.5119353711153405

Epoch: 6| Step: 7
Training loss: 2.6107713081434945
Validation loss: 2.4883258177004843

Epoch: 6| Step: 8
Training loss: 2.477303956529333
Validation loss: 2.4866729910366323

Epoch: 6| Step: 9
Training loss: 2.692568324646906
Validation loss: 2.4916732730243565

Epoch: 6| Step: 10
Training loss: 2.6506857542537845
Validation loss: 2.4819653760006117

Epoch: 6| Step: 11
Training loss: 2.2867228037150182
Validation loss: 2.51632773351259

Epoch: 6| Step: 12
Training loss: 2.070588636876389
Validation loss: 2.501134745140161

Epoch: 6| Step: 13
Training loss: 2.941047960727571
Validation loss: 2.484886892174379

Epoch: 155| Step: 0
Training loss: 3.4307680274419132
Validation loss: 2.4850418084431216

Epoch: 6| Step: 1
Training loss: 2.5853796411937497
Validation loss: 2.5070589799323675

Epoch: 6| Step: 2
Training loss: 2.6378777111476808
Validation loss: 2.4519952634149274

Epoch: 6| Step: 3
Training loss: 2.4662138067838897
Validation loss: 2.4533971370761796

Epoch: 6| Step: 4
Training loss: 2.5670823784432053
Validation loss: 2.4843486057767032

Epoch: 6| Step: 5
Training loss: 2.338405160523553
Validation loss: 2.4832499541571145

Epoch: 6| Step: 6
Training loss: 2.8075095937264343
Validation loss: 2.461134027647702

Epoch: 6| Step: 7
Training loss: 2.168811970905459
Validation loss: 2.4862555245371953

Epoch: 6| Step: 8
Training loss: 2.3310603128532352
Validation loss: 2.4702071052262076

Epoch: 6| Step: 9
Training loss: 2.4571595272183098
Validation loss: 2.478057858101261

Epoch: 6| Step: 10
Training loss: 2.516057516316954
Validation loss: 2.501627960110046

Epoch: 6| Step: 11
Training loss: 2.7182567631337307
Validation loss: 2.481554523697987

Epoch: 6| Step: 12
Training loss: 2.9581375773678515
Validation loss: 2.4948975041808046

Epoch: 6| Step: 13
Training loss: 2.2855640536562256
Validation loss: 2.4807288450380938

Epoch: 156| Step: 0
Training loss: 2.451432050901923
Validation loss: 2.4893470944180347

Epoch: 6| Step: 1
Training loss: 2.1062741694209755
Validation loss: 2.4751239569896124

Epoch: 6| Step: 2
Training loss: 1.7605926907208347
Validation loss: 2.5144007358559044

Epoch: 6| Step: 3
Training loss: 3.061000223184083
Validation loss: 2.484879078118631

Epoch: 6| Step: 4
Training loss: 2.687828842271297
Validation loss: 2.5038275848471936

Epoch: 6| Step: 5
Training loss: 2.757925231185673
Validation loss: 2.4955327729829806

Epoch: 6| Step: 6
Training loss: 2.3195865407375305
Validation loss: 2.5235337455202185

Epoch: 6| Step: 7
Training loss: 2.5826291590960335
Validation loss: 2.4902073901855974

Epoch: 6| Step: 8
Training loss: 2.3669039616249554
Validation loss: 2.48366948808026

Epoch: 6| Step: 9
Training loss: 3.3515107121945884
Validation loss: 2.5160653313581482

Epoch: 6| Step: 10
Training loss: 3.2525975044290174
Validation loss: 2.510139872509528

Epoch: 6| Step: 11
Training loss: 2.178250840874173
Validation loss: 2.5100355063620494

Epoch: 6| Step: 12
Training loss: 2.58501203405062
Validation loss: 2.5017354376640335

Epoch: 6| Step: 13
Training loss: 2.7210448653599517
Validation loss: 2.4996673219071073

Epoch: 157| Step: 0
Training loss: 2.945304405140567
Validation loss: 2.4917208347516024

Epoch: 6| Step: 1
Training loss: 3.3413814819359833
Validation loss: 2.4958520811095375

Epoch: 6| Step: 2
Training loss: 1.924787841599291
Validation loss: 2.5071950862987067

Epoch: 6| Step: 3
Training loss: 2.7288438057601154
Validation loss: 2.4813583209036785

Epoch: 6| Step: 4
Training loss: 2.388405062105701
Validation loss: 2.502639366821654

Epoch: 6| Step: 5
Training loss: 2.819987439472552
Validation loss: 2.49995285830607

Epoch: 6| Step: 6
Training loss: 2.504178370122066
Validation loss: 2.4933568532252366

Epoch: 6| Step: 7
Training loss: 2.137593147969828
Validation loss: 2.490653322750278

Epoch: 6| Step: 8
Training loss: 2.6710080530522955
Validation loss: 2.511546682306889

Epoch: 6| Step: 9
Training loss: 2.8693108037515542
Validation loss: 2.477279416984509

Epoch: 6| Step: 10
Training loss: 2.014857892877612
Validation loss: 2.4843948919658607

Epoch: 6| Step: 11
Training loss: 2.7751233631928365
Validation loss: 2.5026526775120685

Epoch: 6| Step: 12
Training loss: 2.5355068252402404
Validation loss: 2.503917962890718

Epoch: 6| Step: 13
Training loss: 2.706368237174455
Validation loss: 2.495522965407818

Epoch: 158| Step: 0
Training loss: 2.6659633980690263
Validation loss: 2.5051473622456752

Epoch: 6| Step: 1
Training loss: 2.7195496534137433
Validation loss: 2.487866137984965

Epoch: 6| Step: 2
Training loss: 2.646988824155682
Validation loss: 2.47731368307539

Epoch: 6| Step: 3
Training loss: 2.623436871108797
Validation loss: 2.4693331950564894

Epoch: 6| Step: 4
Training loss: 2.803092056472082
Validation loss: 2.5102877380598603

Epoch: 6| Step: 5
Training loss: 2.39106377458258
Validation loss: 2.491100591042928

Epoch: 6| Step: 6
Training loss: 2.0199335461251486
Validation loss: 2.4974802773193194

Epoch: 6| Step: 7
Training loss: 2.7193805358030785
Validation loss: 2.4927697244981046

Epoch: 6| Step: 8
Training loss: 2.5754795257578067
Validation loss: 2.4895567284795193

Epoch: 6| Step: 9
Training loss: 2.8976895171781027
Validation loss: 2.5102485696112056

Epoch: 6| Step: 10
Training loss: 2.3331960456059937
Validation loss: 2.4985700824887895

Epoch: 6| Step: 11
Training loss: 3.385341905599796
Validation loss: 2.4748358853461214

Epoch: 6| Step: 12
Training loss: 2.352989093559075
Validation loss: 2.4913533346451175

Epoch: 6| Step: 13
Training loss: 2.03606700470693
Validation loss: 2.4839380269146867

Epoch: 159| Step: 0
Training loss: 2.775418372018891
Validation loss: 2.4704652795556705

Epoch: 6| Step: 1
Training loss: 2.7829085987254167
Validation loss: 2.4822921199432484

Epoch: 6| Step: 2
Training loss: 3.0646830971508154
Validation loss: 2.487024216753128

Epoch: 6| Step: 3
Training loss: 2.539135647233619
Validation loss: 2.472832360153927

Epoch: 6| Step: 4
Training loss: 2.849548464693436
Validation loss: 2.464115301767321

Epoch: 6| Step: 5
Training loss: 2.341933907388231
Validation loss: 2.4845638934699323

Epoch: 6| Step: 6
Training loss: 2.9494848674431893
Validation loss: 2.5051993284041663

Epoch: 6| Step: 7
Training loss: 2.3233892419109394
Validation loss: 2.479116992723375

Epoch: 6| Step: 8
Training loss: 3.042992881904473
Validation loss: 2.4792637418659926

Epoch: 6| Step: 9
Training loss: 1.9861664382709512
Validation loss: 2.505469041658032

Epoch: 6| Step: 10
Training loss: 2.4140965727836634
Validation loss: 2.4786494842669207

Epoch: 6| Step: 11
Training loss: 2.4712559982327345
Validation loss: 2.496808773755323

Epoch: 6| Step: 12
Training loss: 2.250910045112635
Validation loss: 2.467427065540933

Epoch: 6| Step: 13
Training loss: 2.187128089896934
Validation loss: 2.5114851634877517

Epoch: 160| Step: 0
Training loss: 3.0279811261998577
Validation loss: 2.497974614101531

Epoch: 6| Step: 1
Training loss: 2.560027534664611
Validation loss: 2.507699675551037

Epoch: 6| Step: 2
Training loss: 2.4703898717549095
Validation loss: 2.5059729994349573

Epoch: 6| Step: 3
Training loss: 2.406110685204562
Validation loss: 2.5145769931748525

Epoch: 6| Step: 4
Training loss: 2.4336311741579695
Validation loss: 2.481431202052683

Epoch: 6| Step: 5
Training loss: 3.4326723357500963
Validation loss: 2.472077940388126

Epoch: 6| Step: 6
Training loss: 2.6684074878892354
Validation loss: 2.482694383876743

Epoch: 6| Step: 7
Training loss: 2.55159056181465
Validation loss: 2.4928945615329505

Epoch: 6| Step: 8
Training loss: 2.1890110791284543
Validation loss: 2.5196240642597503

Epoch: 6| Step: 9
Training loss: 1.8921089968788654
Validation loss: 2.4849958345131484

Epoch: 6| Step: 10
Training loss: 2.7330678376684783
Validation loss: 2.488793352333893

Epoch: 6| Step: 11
Training loss: 2.4024782220685013
Validation loss: 2.5046764013120386

Epoch: 6| Step: 12
Training loss: 2.7714635567289814
Validation loss: 2.483237001969503

Epoch: 6| Step: 13
Training loss: 2.5705427165256194
Validation loss: 2.4848740269282454

Epoch: 161| Step: 0
Training loss: 2.71517235393263
Validation loss: 2.499277404214432

Epoch: 6| Step: 1
Training loss: 2.957890293813206
Validation loss: 2.509768882453445

Epoch: 6| Step: 2
Training loss: 2.3462253976953646
Validation loss: 2.5076646561569667

Epoch: 6| Step: 3
Training loss: 2.7674401140496383
Validation loss: 2.5021875316859448

Epoch: 6| Step: 4
Training loss: 1.8516579776403248
Validation loss: 2.4827948883065374

Epoch: 6| Step: 5
Training loss: 2.760700129703739
Validation loss: 2.484297795230231

Epoch: 6| Step: 6
Training loss: 3.0079402747819435
Validation loss: 2.4764188196415726

Epoch: 6| Step: 7
Training loss: 2.514597807439335
Validation loss: 2.494620162354457

Epoch: 6| Step: 8
Training loss: 2.2512745955763593
Validation loss: 2.509763186759111

Epoch: 6| Step: 9
Training loss: 3.3119693546996665
Validation loss: 2.4978258739011836

Epoch: 6| Step: 10
Training loss: 2.202987883068256
Validation loss: 2.5005410808643784

Epoch: 6| Step: 11
Training loss: 2.463948469601597
Validation loss: 2.502957327918562

Epoch: 6| Step: 12
Training loss: 2.571045003015649
Validation loss: 2.45230925852882

Epoch: 6| Step: 13
Training loss: 2.413615064913954
Validation loss: 2.4830851421830324

Epoch: 162| Step: 0
Training loss: 2.1873914419212737
Validation loss: 2.482111252337736

Epoch: 6| Step: 1
Training loss: 3.427153674546848
Validation loss: 2.4829540599253876

Epoch: 6| Step: 2
Training loss: 2.2217670398349316
Validation loss: 2.487421527922736

Epoch: 6| Step: 3
Training loss: 2.308826931764762
Validation loss: 2.4972343375071544

Epoch: 6| Step: 4
Training loss: 2.0809701359084825
Validation loss: 2.482596891735298

Epoch: 6| Step: 5
Training loss: 2.918789300102622
Validation loss: 2.4990072412175217

Epoch: 6| Step: 6
Training loss: 2.7536167290187703
Validation loss: 2.5066964305333754

Epoch: 6| Step: 7
Training loss: 3.426847563791519
Validation loss: 2.4727922397093

Epoch: 6| Step: 8
Training loss: 2.3723497159448588
Validation loss: 2.4897807314142546

Epoch: 6| Step: 9
Training loss: 2.78238020660463
Validation loss: 2.4985771868012314

Epoch: 6| Step: 10
Training loss: 2.381760261712942
Validation loss: 2.5029964762911607

Epoch: 6| Step: 11
Training loss: 2.2043594256835926
Validation loss: 2.487553652694233

Epoch: 6| Step: 12
Training loss: 1.9709523915734857
Validation loss: 2.4982186852090544

Epoch: 6| Step: 13
Training loss: 2.864927144081251
Validation loss: 2.485461784104364

Epoch: 163| Step: 0
Training loss: 3.0421987791004157
Validation loss: 2.4857879519232835

Epoch: 6| Step: 1
Training loss: 2.456901219358355
Validation loss: 2.485867416885045

Epoch: 6| Step: 2
Training loss: 2.912751012635458
Validation loss: 2.500425851094382

Epoch: 6| Step: 3
Training loss: 3.3221019993877277
Validation loss: 2.490091698693471

Epoch: 6| Step: 4
Training loss: 2.8397550923231036
Validation loss: 2.502100316566258

Epoch: 6| Step: 5
Training loss: 1.9449035950135123
Validation loss: 2.4775191993044374

Epoch: 6| Step: 6
Training loss: 2.6605158939442424
Validation loss: 2.5238747618713377

Epoch: 6| Step: 7
Training loss: 1.7400154977963302
Validation loss: 2.4906739293408213

Epoch: 6| Step: 8
Training loss: 2.416109174244847
Validation loss: 2.4855067633633414

Epoch: 6| Step: 9
Training loss: 2.2977165704544302
Validation loss: 2.494087230936899

Epoch: 6| Step: 10
Training loss: 3.2209448876911035
Validation loss: 2.50019591394456

Epoch: 6| Step: 11
Training loss: 2.272859480220322
Validation loss: 2.483590220141587

Epoch: 6| Step: 12
Training loss: 2.4366569039096593
Validation loss: 2.5266589488936173

Epoch: 6| Step: 13
Training loss: 2.048271227154503
Validation loss: 2.492230648253978

Epoch: 164| Step: 0
Training loss: 2.756111809343559
Validation loss: 2.48320286975123

Epoch: 6| Step: 1
Training loss: 2.9943814115509393
Validation loss: 2.5052984552037163

Epoch: 6| Step: 2
Training loss: 1.9820791465015255
Validation loss: 2.5015973761223247

Epoch: 6| Step: 3
Training loss: 3.043291850926722
Validation loss: 2.486475836320993

Epoch: 6| Step: 4
Training loss: 2.4185954870112654
Validation loss: 2.516259467734408

Epoch: 6| Step: 5
Training loss: 3.201353299560734
Validation loss: 2.496428930433382

Epoch: 6| Step: 6
Training loss: 2.2964419002014784
Validation loss: 2.5040012805072753

Epoch: 6| Step: 7
Training loss: 2.233206276576948
Validation loss: 2.4906954909394505

Epoch: 6| Step: 8
Training loss: 2.330442772572489
Validation loss: 2.5064912763913414

Epoch: 6| Step: 9
Training loss: 2.3192789877876616
Validation loss: 2.496890372668774

Epoch: 6| Step: 10
Training loss: 2.2419327115962235
Validation loss: 2.5097173337016008

Epoch: 6| Step: 11
Training loss: 2.145886380425705
Validation loss: 2.505363491444279

Epoch: 6| Step: 12
Training loss: 3.2556114171008974
Validation loss: 2.48910912251839

Epoch: 6| Step: 13
Training loss: 2.8134170732494956
Validation loss: 2.4964602832268823

Epoch: 165| Step: 0
Training loss: 3.141867017217921
Validation loss: 2.47770485747314

Epoch: 6| Step: 1
Training loss: 2.877109417162934
Validation loss: 2.4869666826557304

Epoch: 6| Step: 2
Training loss: 2.814284119041937
Validation loss: 2.4955585414402774

Epoch: 6| Step: 3
Training loss: 2.5007051427117335
Validation loss: 2.4988977791710476

Epoch: 6| Step: 4
Training loss: 2.278628999193769
Validation loss: 2.491223782369712

Epoch: 6| Step: 5
Training loss: 2.828560305651969
Validation loss: 2.488699243019224

Epoch: 6| Step: 6
Training loss: 2.534110442816011
Validation loss: 2.530622691442796

Epoch: 6| Step: 7
Training loss: 1.8915547378408506
Validation loss: 2.501943396899474

Epoch: 6| Step: 8
Training loss: 2.7536601071570708
Validation loss: 2.487077365597243

Epoch: 6| Step: 9
Training loss: 2.2110504013728156
Validation loss: 2.473242922041097

Epoch: 6| Step: 10
Training loss: 2.0678706902117376
Validation loss: 2.502325364986702

Epoch: 6| Step: 11
Training loss: 3.005509086558343
Validation loss: 2.5013144831559235

Epoch: 6| Step: 12
Training loss: 2.9156937929401043
Validation loss: 2.51542579526093

Epoch: 6| Step: 13
Training loss: 2.0107538075641656
Validation loss: 2.494207304815156

Epoch: 166| Step: 0
Training loss: 2.4119723756008526
Validation loss: 2.5022522205278928

Epoch: 6| Step: 1
Training loss: 2.5395236022116796
Validation loss: 2.491189697320177

Epoch: 6| Step: 2
Training loss: 2.727983863911492
Validation loss: 2.4891930310791603

Epoch: 6| Step: 3
Training loss: 2.0627889719735046
Validation loss: 2.493184074570027

Epoch: 6| Step: 4
Training loss: 2.6806690431420033
Validation loss: 2.5094983523217014

Epoch: 6| Step: 5
Training loss: 2.9288079734466557
Validation loss: 2.4991023205533085

Epoch: 6| Step: 6
Training loss: 2.926165200316109
Validation loss: 2.4665790429497796

Epoch: 6| Step: 7
Training loss: 2.7418169167885713
Validation loss: 2.5009549655052203

Epoch: 6| Step: 8
Training loss: 2.1473428052716805
Validation loss: 2.5190076821536183

Epoch: 6| Step: 9
Training loss: 3.104572517097324
Validation loss: 2.4789899840819545

Epoch: 6| Step: 10
Training loss: 2.640584098905455
Validation loss: 2.4918708385356845

Epoch: 6| Step: 11
Training loss: 2.2037668578249066
Validation loss: 2.487099433563293

Epoch: 6| Step: 12
Training loss: 2.4764945324737866
Validation loss: 2.475124240788528

Epoch: 6| Step: 13
Training loss: 2.704600730663343
Validation loss: 2.506268867751233

Epoch: 167| Step: 0
Training loss: 2.69943700148188
Validation loss: 2.498662081977169

Epoch: 6| Step: 1
Training loss: 2.351460096594553
Validation loss: 2.485808148163507

Epoch: 6| Step: 2
Training loss: 1.9587374195895035
Validation loss: 2.48500499759255

Epoch: 6| Step: 3
Training loss: 2.643762473940449
Validation loss: 2.499647939154934

Epoch: 6| Step: 4
Training loss: 2.5704757499448787
Validation loss: 2.4961617815959873

Epoch: 6| Step: 5
Training loss: 3.02070056141185
Validation loss: 2.499421647556259

Epoch: 6| Step: 6
Training loss: 1.9192771411172704
Validation loss: 2.4685179950677063

Epoch: 6| Step: 7
Training loss: 2.338673497982045
Validation loss: 2.4853100927514564

Epoch: 6| Step: 8
Training loss: 2.3674748312429013
Validation loss: 2.514868664670106

Epoch: 6| Step: 9
Training loss: 2.4855709436268363
Validation loss: 2.498506623994275

Epoch: 6| Step: 10
Training loss: 2.5410387065991458
Validation loss: 2.527428225642737

Epoch: 6| Step: 11
Training loss: 2.684046455856766
Validation loss: 2.47678929750632

Epoch: 6| Step: 12
Training loss: 3.293026671347064
Validation loss: 2.4822624255185515

Epoch: 6| Step: 13
Training loss: 3.093852494208541
Validation loss: 2.485386827178676

Epoch: 168| Step: 0
Training loss: 2.402408754043051
Validation loss: 2.489578140657721

Epoch: 6| Step: 1
Training loss: 2.489093258770047
Validation loss: 2.5045450918049554

Epoch: 6| Step: 2
Training loss: 2.8703226935507278
Validation loss: 2.4857572194549404

Epoch: 6| Step: 3
Training loss: 2.468750579447618
Validation loss: 2.488791615113952

Epoch: 6| Step: 4
Training loss: 2.6134710086187343
Validation loss: 2.4975455551248977

Epoch: 6| Step: 5
Training loss: 2.6653132481081414
Validation loss: 2.500546620712108

Epoch: 6| Step: 6
Training loss: 2.6689358434359103
Validation loss: 2.506277586861559

Epoch: 6| Step: 7
Training loss: 2.9837414133869657
Validation loss: 2.507335210690346

Epoch: 6| Step: 8
Training loss: 2.672099232327191
Validation loss: 2.5177932808083745

Epoch: 6| Step: 9
Training loss: 2.675207636252597
Validation loss: 2.499288564379283

Epoch: 6| Step: 10
Training loss: 1.3927023298561656
Validation loss: 2.452872854911912

Epoch: 6| Step: 11
Training loss: 2.1856719962159747
Validation loss: 2.5050362486150144

Epoch: 6| Step: 12
Training loss: 3.3910603749135158
Validation loss: 2.533138672965762

Epoch: 6| Step: 13
Training loss: 2.166238620241699
Validation loss: 2.5021653816306397

Epoch: 169| Step: 0
Training loss: 2.7614815055674047
Validation loss: 2.504181818093592

Epoch: 6| Step: 1
Training loss: 2.3281282770530627
Validation loss: 2.507345187798889

Epoch: 6| Step: 2
Training loss: 2.409840666699646
Validation loss: 2.479588196586022

Epoch: 6| Step: 3
Training loss: 2.908488734191512
Validation loss: 2.5018451546947786

Epoch: 6| Step: 4
Training loss: 1.9577245036425517
Validation loss: 2.503019946380031

Epoch: 6| Step: 5
Training loss: 2.8035226597245235
Validation loss: 2.500054174266939

Epoch: 6| Step: 6
Training loss: 2.883922993630537
Validation loss: 2.5055115181404015

Epoch: 6| Step: 7
Training loss: 2.603293636213106
Validation loss: 2.488295817167134

Epoch: 6| Step: 8
Training loss: 2.825153876645889
Validation loss: 2.509032588405958

Epoch: 6| Step: 9
Training loss: 2.68212210603828
Validation loss: 2.5022136506513672

Epoch: 6| Step: 10
Training loss: 2.3416682853104867
Validation loss: 2.514428101318872

Epoch: 6| Step: 11
Training loss: 2.0912646445555656
Validation loss: 2.5097582081233107

Epoch: 6| Step: 12
Training loss: 2.917587316623458
Validation loss: 2.517531442807261

Epoch: 6| Step: 13
Training loss: 2.6653448246066804
Validation loss: 2.5000455595807827

Epoch: 170| Step: 0
Training loss: 2.512370687924308
Validation loss: 2.4961376544190896

Epoch: 6| Step: 1
Training loss: 2.592606625695573
Validation loss: 2.498121325831

Epoch: 6| Step: 2
Training loss: 2.3278681466166047
Validation loss: 2.497608925129785

Epoch: 6| Step: 3
Training loss: 2.2858126227478657
Validation loss: 2.544011850821156

Epoch: 6| Step: 4
Training loss: 2.4681043142657915
Validation loss: 2.4882976211862116

Epoch: 6| Step: 5
Training loss: 2.463848608357418
Validation loss: 2.521580926363198

Epoch: 6| Step: 6
Training loss: 3.310412342860137
Validation loss: 2.511672795870692

Epoch: 6| Step: 7
Training loss: 2.5079929370081007
Validation loss: 2.519578310275874

Epoch: 6| Step: 8
Training loss: 2.09970975414121
Validation loss: 2.4975825886454905

Epoch: 6| Step: 9
Training loss: 2.8146308456314793
Validation loss: 2.500462749681892

Epoch: 6| Step: 10
Training loss: 3.025923621041347
Validation loss: 2.4905558827644807

Epoch: 6| Step: 11
Training loss: 2.4433382980206035
Validation loss: 2.501418867785992

Epoch: 6| Step: 12
Training loss: 2.701217331024568
Validation loss: 2.5016087237231193

Epoch: 6| Step: 13
Training loss: 2.5726241178385485
Validation loss: 2.4935159150688344

Epoch: 171| Step: 0
Training loss: 2.167124650919857
Validation loss: 2.4919526341197877

Epoch: 6| Step: 1
Training loss: 2.660848429472078
Validation loss: 2.497618791232068

Epoch: 6| Step: 2
Training loss: 2.7045589458341817
Validation loss: 2.49422749146854

Epoch: 6| Step: 3
Training loss: 3.2112255848943527
Validation loss: 2.5028122865776665

Epoch: 6| Step: 4
Training loss: 3.2455049387004338
Validation loss: 2.4943811996643186

Epoch: 6| Step: 5
Training loss: 2.237874311965984
Validation loss: 2.488556125350095

Epoch: 6| Step: 6
Training loss: 2.9345347270616946
Validation loss: 2.50761626612495

Epoch: 6| Step: 7
Training loss: 3.0788052964133112
Validation loss: 2.5013339944315995

Epoch: 6| Step: 8
Training loss: 2.459681211455522
Validation loss: 2.5035550958450536

Epoch: 6| Step: 9
Training loss: 1.8267296576718783
Validation loss: 2.498449608783848

Epoch: 6| Step: 10
Training loss: 2.1981411016295884
Validation loss: 2.482585489245832

Epoch: 6| Step: 11
Training loss: 2.8638675604625345
Validation loss: 2.4934492506934953

Epoch: 6| Step: 12
Training loss: 1.942601409778694
Validation loss: 2.504200394879865

Epoch: 6| Step: 13
Training loss: 1.8097499505032615
Validation loss: 2.5011559818387963

Epoch: 172| Step: 0
Training loss: 2.1321470459118492
Validation loss: 2.480743391965168

Epoch: 6| Step: 1
Training loss: 2.791783562865063
Validation loss: 2.491393703616289

Epoch: 6| Step: 2
Training loss: 2.787061042607159
Validation loss: 2.487712915552621

Epoch: 6| Step: 3
Training loss: 2.4064459782839354
Validation loss: 2.4883297780447005

Epoch: 6| Step: 4
Training loss: 3.0461966517507855
Validation loss: 2.484587700705136

Epoch: 6| Step: 5
Training loss: 2.532805259360072
Validation loss: 2.4849431703951255

Epoch: 6| Step: 6
Training loss: 2.5447174482001564
Validation loss: 2.4837081797504523

Epoch: 6| Step: 7
Training loss: 2.6339505506434366
Validation loss: 2.500669547631574

Epoch: 6| Step: 8
Training loss: 2.4451261699239417
Validation loss: 2.4881770684180182

Epoch: 6| Step: 9
Training loss: 2.5876442615633732
Validation loss: 2.509434289560918

Epoch: 6| Step: 10
Training loss: 2.4981289537678637
Validation loss: 2.5094254925390964

Epoch: 6| Step: 11
Training loss: 2.2616473830695756
Validation loss: 2.494828451630732

Epoch: 6| Step: 12
Training loss: 2.8473292033455
Validation loss: 2.5139068257355506

Epoch: 6| Step: 13
Training loss: 2.5120725960901975
Validation loss: 2.479910667449908

Epoch: 173| Step: 0
Training loss: 3.249401184082191
Validation loss: 2.498962037153763

Epoch: 6| Step: 1
Training loss: 2.0999756675400443
Validation loss: 2.504688305073229

Epoch: 6| Step: 2
Training loss: 2.1183687975556276
Validation loss: 2.5083687408546123

Epoch: 6| Step: 3
Training loss: 2.3973435880139706
Validation loss: 2.5110953320001337

Epoch: 6| Step: 4
Training loss: 2.6762051657244617
Validation loss: 2.485995319890535

Epoch: 6| Step: 5
Training loss: 1.983433537663321
Validation loss: 2.5071353339921694

Epoch: 6| Step: 6
Training loss: 2.830737514302223
Validation loss: 2.4883607218803636

Epoch: 6| Step: 7
Training loss: 2.862996793723168
Validation loss: 2.497758214017975

Epoch: 6| Step: 8
Training loss: 2.4013402812454103
Validation loss: 2.5151127389414047

Epoch: 6| Step: 9
Training loss: 2.186546553863959
Validation loss: 2.5299746674331294

Epoch: 6| Step: 10
Training loss: 2.686494861091656
Validation loss: 2.516649367200947

Epoch: 6| Step: 11
Training loss: 2.987795961156881
Validation loss: 2.4793181055572897

Epoch: 6| Step: 12
Training loss: 3.0102259873629285
Validation loss: 2.5239250616014024

Epoch: 6| Step: 13
Training loss: 1.8399466386603922
Validation loss: 2.523519632693173

Epoch: 174| Step: 0
Training loss: 2.501187709964955
Validation loss: 2.5043117713202707

Epoch: 6| Step: 1
Training loss: 2.354240843918029
Validation loss: 2.461468122590931

Epoch: 6| Step: 2
Training loss: 2.2216459904724744
Validation loss: 2.5160707927023833

Epoch: 6| Step: 3
Training loss: 2.0609582860909232
Validation loss: 2.469713448043414

Epoch: 6| Step: 4
Training loss: 3.116834577501395
Validation loss: 2.49642782854461

Epoch: 6| Step: 5
Training loss: 2.42364358622142
Validation loss: 2.496110006269159

Epoch: 6| Step: 6
Training loss: 3.1942854818699375
Validation loss: 2.50152102212454

Epoch: 6| Step: 7
Training loss: 1.5137559830463085
Validation loss: 2.484649397456075

Epoch: 6| Step: 8
Training loss: 2.4603675787860846
Validation loss: 2.5061295757484476

Epoch: 6| Step: 9
Training loss: 2.889762131032621
Validation loss: 2.491010468888054

Epoch: 6| Step: 10
Training loss: 2.8112646144760154
Validation loss: 2.5052888393524655

Epoch: 6| Step: 11
Training loss: 2.461963161295161
Validation loss: 2.4916747947420643

Epoch: 6| Step: 12
Training loss: 3.0681377600386845
Validation loss: 2.52302445940406

Epoch: 6| Step: 13
Training loss: 2.2466922393875333
Validation loss: 2.49583461007569

Epoch: 175| Step: 0
Training loss: 2.801861457596267
Validation loss: 2.498257554834497

Epoch: 6| Step: 1
Training loss: 2.8737650997234745
Validation loss: 2.4998841545993002

Epoch: 6| Step: 2
Training loss: 2.1189113229196197
Validation loss: 2.489229884016094

Epoch: 6| Step: 3
Training loss: 2.8373875129350186
Validation loss: 2.510599086749185

Epoch: 6| Step: 4
Training loss: 2.361413138526002
Validation loss: 2.4943512092669144

Epoch: 6| Step: 5
Training loss: 2.2665537015964254
Validation loss: 2.5011732937300963

Epoch: 6| Step: 6
Training loss: 2.9745216882696983
Validation loss: 2.5018447827286647

Epoch: 6| Step: 7
Training loss: 2.700705708006436
Validation loss: 2.525136471381097

Epoch: 6| Step: 8
Training loss: 2.627269671913235
Validation loss: 2.507613619280934

Epoch: 6| Step: 9
Training loss: 2.6127166366191727
Validation loss: 2.4867439844747263

Epoch: 6| Step: 10
Training loss: 2.2568050895771457
Validation loss: 2.4861929076419758

Epoch: 6| Step: 11
Training loss: 2.0857487853905265
Validation loss: 2.505857021964435

Epoch: 6| Step: 12
Training loss: 2.7784736577574036
Validation loss: 2.4985936546921663

Epoch: 6| Step: 13
Training loss: 2.2975630994564407
Validation loss: 2.5003534795195

Epoch: 176| Step: 0
Training loss: 2.6984421403642878
Validation loss: 2.5082180873500466

Epoch: 6| Step: 1
Training loss: 2.588692387594148
Validation loss: 2.4971833204997256

Epoch: 6| Step: 2
Training loss: 2.613535778839262
Validation loss: 2.4862033707105136

Epoch: 6| Step: 3
Training loss: 2.7810323394299683
Validation loss: 2.4928262782830917

Epoch: 6| Step: 4
Training loss: 2.573941900390468
Validation loss: 2.4949408275148643

Epoch: 6| Step: 5
Training loss: 2.975324558537723
Validation loss: 2.504443075146844

Epoch: 6| Step: 6
Training loss: 2.812252627196277
Validation loss: 2.477586961781704

Epoch: 6| Step: 7
Training loss: 2.393216990597993
Validation loss: 2.4741471893470415

Epoch: 6| Step: 8
Training loss: 2.3691798723434
Validation loss: 2.4953004092802633

Epoch: 6| Step: 9
Training loss: 2.2547861692287614
Validation loss: 2.530479401967582

Epoch: 6| Step: 10
Training loss: 2.4880176446479125
Validation loss: 2.5012515596130096

Epoch: 6| Step: 11
Training loss: 2.58939612016989
Validation loss: 2.5093479372487746

Epoch: 6| Step: 12
Training loss: 2.6020835377611906
Validation loss: 2.5030374041323387

Epoch: 6| Step: 13
Training loss: 1.7556040135803375
Validation loss: 2.500890782305976

Epoch: 177| Step: 0
Training loss: 1.874874492259376
Validation loss: 2.5065150870748583

Epoch: 6| Step: 1
Training loss: 2.2299566800139345
Validation loss: 2.5066527713942723

Epoch: 6| Step: 2
Training loss: 2.1229102012628167
Validation loss: 2.5046377561750837

Epoch: 6| Step: 3
Training loss: 2.3210930843859487
Validation loss: 2.4834439919540463

Epoch: 6| Step: 4
Training loss: 2.5057604228319312
Validation loss: 2.5039198549679242

Epoch: 6| Step: 5
Training loss: 2.2640831271772686
Validation loss: 2.4951221095567324

Epoch: 6| Step: 6
Training loss: 3.417526199028315
Validation loss: 2.4986643586819786

Epoch: 6| Step: 7
Training loss: 2.737384295522291
Validation loss: 2.4859416178473412

Epoch: 6| Step: 8
Training loss: 2.9949689641245594
Validation loss: 2.494030112640347

Epoch: 6| Step: 9
Training loss: 3.1315178610012
Validation loss: 2.516168835060617

Epoch: 6| Step: 10
Training loss: 2.8485884533849064
Validation loss: 2.5015773780667625

Epoch: 6| Step: 11
Training loss: 2.3230867081288866
Validation loss: 2.485661274346655

Epoch: 6| Step: 12
Training loss: 2.2685795953822554
Validation loss: 2.486293885190737

Epoch: 6| Step: 13
Training loss: 2.481228737535827
Validation loss: 2.4914758317859587

Epoch: 178| Step: 0
Training loss: 1.5146213629914178
Validation loss: 2.4879288611500114

Epoch: 6| Step: 1
Training loss: 2.7484688397605614
Validation loss: 2.498224230719822

Epoch: 6| Step: 2
Training loss: 2.8193293413825677
Validation loss: 2.5017841228206

Epoch: 6| Step: 3
Training loss: 3.0373341958589255
Validation loss: 2.48405287027871

Epoch: 6| Step: 4
Training loss: 2.8184917627701127
Validation loss: 2.5174147971858

Epoch: 6| Step: 5
Training loss: 2.7672068926381015
Validation loss: 2.508288487338845

Epoch: 6| Step: 6
Training loss: 2.113361350073358
Validation loss: 2.491707501673748

Epoch: 6| Step: 7
Training loss: 2.4090195607633875
Validation loss: 2.4995348815579996

Epoch: 6| Step: 8
Training loss: 2.7815080158694836
Validation loss: 2.4915998549569585

Epoch: 6| Step: 9
Training loss: 2.7712969188994196
Validation loss: 2.4970052830487046

Epoch: 6| Step: 10
Training loss: 2.723397152766518
Validation loss: 2.4907212168073323

Epoch: 6| Step: 11
Training loss: 2.632742861044654
Validation loss: 2.521304417479655

Epoch: 6| Step: 12
Training loss: 1.8945196092385608
Validation loss: 2.5014479453588425

Epoch: 6| Step: 13
Training loss: 2.49074165712403
Validation loss: 2.506511650495328

Epoch: 179| Step: 0
Training loss: 2.900212733917555
Validation loss: 2.496022089895741

Epoch: 6| Step: 1
Training loss: 2.5935944659927697
Validation loss: 2.5036827925672207

Epoch: 6| Step: 2
Training loss: 2.529226931043037
Validation loss: 2.505008808184607

Epoch: 6| Step: 3
Training loss: 2.362217081881162
Validation loss: 2.477027032499151

Epoch: 6| Step: 4
Training loss: 2.6090394678080435
Validation loss: 2.4729502554853675

Epoch: 6| Step: 5
Training loss: 2.5419553269693513
Validation loss: 2.508554372334292

Epoch: 6| Step: 6
Training loss: 2.9602632987992425
Validation loss: 2.5035148553902427

Epoch: 6| Step: 7
Training loss: 2.4682158846047355
Validation loss: 2.518801969444324

Epoch: 6| Step: 8
Training loss: 2.4776398153722865
Validation loss: 2.550104236663997

Epoch: 6| Step: 9
Training loss: 2.3238033660785495
Validation loss: 2.501549211014975

Epoch: 6| Step: 10
Training loss: 2.0292771368746525
Validation loss: 2.5169870323304613

Epoch: 6| Step: 11
Training loss: 2.885551660641422
Validation loss: 2.499292427343852

Epoch: 6| Step: 12
Training loss: 2.743608937732261
Validation loss: 2.4911316646032104

Epoch: 6| Step: 13
Training loss: 2.3809258668422326
Validation loss: 2.504027926242923

Epoch: 180| Step: 0
Training loss: 2.820681476496736
Validation loss: 2.5195307880517883

Epoch: 6| Step: 1
Training loss: 2.6900082792984286
Validation loss: 2.498880192984539

Epoch: 6| Step: 2
Training loss: 2.5800112210998183
Validation loss: 2.481542745542009

Epoch: 6| Step: 3
Training loss: 2.473460857500362
Validation loss: 2.5134401764166023

Epoch: 6| Step: 4
Training loss: 1.7025489882984726
Validation loss: 2.51873338700427

Epoch: 6| Step: 5
Training loss: 2.162308956814275
Validation loss: 2.497180413130272

Epoch: 6| Step: 6
Training loss: 2.59968091033713
Validation loss: 2.4971157643499984

Epoch: 6| Step: 7
Training loss: 2.581998192926154
Validation loss: 2.499489506519628

Epoch: 6| Step: 8
Training loss: 2.7618540254561728
Validation loss: 2.489020862559001

Epoch: 6| Step: 9
Training loss: 2.1547896374124886
Validation loss: 2.4994857710423846

Epoch: 6| Step: 10
Training loss: 2.54847713699249
Validation loss: 2.459435570065028

Epoch: 6| Step: 11
Training loss: 3.070385648132703
Validation loss: 2.5126167949772964

Epoch: 6| Step: 12
Training loss: 2.773083903378071
Validation loss: 2.5168630235974776

Epoch: 6| Step: 13
Training loss: 2.8160958932566715
Validation loss: 2.530382209925615

Epoch: 181| Step: 0
Training loss: 2.7617236707932205
Validation loss: 2.4810174383120076

Epoch: 6| Step: 1
Training loss: 2.2042010770345994
Validation loss: 2.5090090907758213

Epoch: 6| Step: 2
Training loss: 2.626800646132379
Validation loss: 2.506105491341266

Epoch: 6| Step: 3
Training loss: 2.404483295220033
Validation loss: 2.5028014473692712

Epoch: 6| Step: 4
Training loss: 2.1584521119807953
Validation loss: 2.4895610241107704

Epoch: 6| Step: 5
Training loss: 2.434668828544757
Validation loss: 2.4904547589121107

Epoch: 6| Step: 6
Training loss: 2.9002867195192827
Validation loss: 2.50558476083118

Epoch: 6| Step: 7
Training loss: 2.3311219862902544
Validation loss: 2.4863750661903685

Epoch: 6| Step: 8
Training loss: 1.7379385964067808
Validation loss: 2.5034417774308806

Epoch: 6| Step: 9
Training loss: 2.25553805882642
Validation loss: 2.5012846958053383

Epoch: 6| Step: 10
Training loss: 2.196808220620274
Validation loss: 2.4932024741806798

Epoch: 6| Step: 11
Training loss: 3.5574661294017713
Validation loss: 2.4826476322816284

Epoch: 6| Step: 12
Training loss: 3.179576824989568
Validation loss: 2.5025137732742055

Epoch: 6| Step: 13
Training loss: 2.3809696262734166
Validation loss: 2.4783369623275378

Epoch: 182| Step: 0
Training loss: 2.6538962313755183
Validation loss: 2.4850563316705707

Epoch: 6| Step: 1
Training loss: 3.169589417158673
Validation loss: 2.4953897297847547

Epoch: 6| Step: 2
Training loss: 2.3943441545037545
Validation loss: 2.5112150203824664

Epoch: 6| Step: 3
Training loss: 2.4147628212791887
Validation loss: 2.5100285713430353

Epoch: 6| Step: 4
Training loss: 2.739705323572184
Validation loss: 2.4889060635387374

Epoch: 6| Step: 5
Training loss: 3.5113670503981878
Validation loss: 2.4783761613529642

Epoch: 6| Step: 6
Training loss: 2.3954618304163073
Validation loss: 2.486591896056443

Epoch: 6| Step: 7
Training loss: 1.404070585267055
Validation loss: 2.499484893071086

Epoch: 6| Step: 8
Training loss: 2.779177890356488
Validation loss: 2.4862193730261137

Epoch: 6| Step: 9
Training loss: 2.525792396018169
Validation loss: 2.509136568167665

Epoch: 6| Step: 10
Training loss: 2.508010903944682
Validation loss: 2.494025430501989

Epoch: 6| Step: 11
Training loss: 2.2283491495389534
Validation loss: 2.5270024327952396

Epoch: 6| Step: 12
Training loss: 2.3696771503208893
Validation loss: 2.522204902022911

Epoch: 6| Step: 13
Training loss: 2.0090835051358944
Validation loss: 2.499439443275811

Epoch: 183| Step: 0
Training loss: 2.2354998124851395
Validation loss: 2.5014427836326485

Epoch: 6| Step: 1
Training loss: 2.23281613904204
Validation loss: 2.498946051806425

Epoch: 6| Step: 2
Training loss: 2.1500613092951624
Validation loss: 2.5174153063669604

Epoch: 6| Step: 3
Training loss: 2.6513725828674386
Validation loss: 2.4878073136159222

Epoch: 6| Step: 4
Training loss: 2.166946857626383
Validation loss: 2.531250314473232

Epoch: 6| Step: 5
Training loss: 3.1073543558032286
Validation loss: 2.512276547492398

Epoch: 6| Step: 6
Training loss: 2.8338235169286135
Validation loss: 2.5141727508048533

Epoch: 6| Step: 7
Training loss: 2.606916628687892
Validation loss: 2.5120778865022184

Epoch: 6| Step: 8
Training loss: 2.449220307515454
Validation loss: 2.518130595040298

Epoch: 6| Step: 9
Training loss: 2.2635041932610056
Validation loss: 2.493270945574865

Epoch: 6| Step: 10
Training loss: 3.025960180309282
Validation loss: 2.5029902684337753

Epoch: 6| Step: 11
Training loss: 2.6560744283657707
Validation loss: 2.494402984101131

Epoch: 6| Step: 12
Training loss: 2.410225890403934
Validation loss: 2.5003511356568073

Epoch: 6| Step: 13
Training loss: 3.127523242793938
Validation loss: 2.518802896661397

Epoch: 184| Step: 0
Training loss: 2.448195832478987
Validation loss: 2.506724036576845

Epoch: 6| Step: 1
Training loss: 2.4622438868836882
Validation loss: 2.479589328186841

Epoch: 6| Step: 2
Training loss: 2.8770482603711884
Validation loss: 2.485731397864857

Epoch: 6| Step: 3
Training loss: 2.9979504895947704
Validation loss: 2.5051707620399863

Epoch: 6| Step: 4
Training loss: 3.1992841814031565
Validation loss: 2.48259543570578

Epoch: 6| Step: 5
Training loss: 2.4789809683699726
Validation loss: 2.5122367263423415

Epoch: 6| Step: 6
Training loss: 2.7319490843087415
Validation loss: 2.5091410279812805

Epoch: 6| Step: 7
Training loss: 1.859739572382206
Validation loss: 2.4891899011857803

Epoch: 6| Step: 8
Training loss: 2.5701976622926095
Validation loss: 2.5094917549820495

Epoch: 6| Step: 9
Training loss: 2.524909095260868
Validation loss: 2.5051361616632644

Epoch: 6| Step: 10
Training loss: 2.285967821296897
Validation loss: 2.509069947928016

Epoch: 6| Step: 11
Training loss: 2.069577414090277
Validation loss: 2.501303370977228

Epoch: 6| Step: 12
Training loss: 2.3878622609068114
Validation loss: 2.5041769921606214

Epoch: 6| Step: 13
Training loss: 2.6339475635647425
Validation loss: 2.524995324564946

Epoch: 185| Step: 0
Training loss: 2.480728255987284
Validation loss: 2.5041446891897103

Epoch: 6| Step: 1
Training loss: 2.088632278823292
Validation loss: 2.49957828143712

Epoch: 6| Step: 2
Training loss: 2.491517553896523
Validation loss: 2.4738728322062453

Epoch: 6| Step: 3
Training loss: 3.0665101246339335
Validation loss: 2.531334204509439

Epoch: 6| Step: 4
Training loss: 2.5000524515371696
Validation loss: 2.4896732670542474

Epoch: 6| Step: 5
Training loss: 2.984245257528288
Validation loss: 2.504305878437903

Epoch: 6| Step: 6
Training loss: 2.017830758097109
Validation loss: 2.5026975270723812

Epoch: 6| Step: 7
Training loss: 3.024315521733802
Validation loss: 2.4964151706523117

Epoch: 6| Step: 8
Training loss: 2.63618176679002
Validation loss: 2.491637413102029

Epoch: 6| Step: 9
Training loss: 2.13940617745071
Validation loss: 2.49756782826822

Epoch: 6| Step: 10
Training loss: 2.0537418176321998
Validation loss: 2.505326811363625

Epoch: 6| Step: 11
Training loss: 2.8375864830785678
Validation loss: 2.5103657749269788

Epoch: 6| Step: 12
Training loss: 2.714107715535314
Validation loss: 2.503462105694192

Epoch: 6| Step: 13
Training loss: 2.187621848936162
Validation loss: 2.4886173528648032

Epoch: 186| Step: 0
Training loss: 2.288422062045727
Validation loss: 2.5005591413276482

Epoch: 6| Step: 1
Training loss: 3.0767348195218585
Validation loss: 2.4764331553397523

Epoch: 6| Step: 2
Training loss: 2.440871621149924
Validation loss: 2.5003697327011416

Epoch: 6| Step: 3
Training loss: 2.0726362898203754
Validation loss: 2.493089357716078

Epoch: 6| Step: 4
Training loss: 2.6196554362152646
Validation loss: 2.486465313567742

Epoch: 6| Step: 5
Training loss: 2.255754529489956
Validation loss: 2.5157208759124168

Epoch: 6| Step: 6
Training loss: 2.9748402015660464
Validation loss: 2.509124623184522

Epoch: 6| Step: 7
Training loss: 2.93537306382063
Validation loss: 2.4882111916454552

Epoch: 6| Step: 8
Training loss: 2.5908413859925554
Validation loss: 2.5072368975465467

Epoch: 6| Step: 9
Training loss: 2.249924976369655
Validation loss: 2.507412803696922

Epoch: 6| Step: 10
Training loss: 2.156889226397297
Validation loss: 2.4994434126783935

Epoch: 6| Step: 11
Training loss: 2.593718379184135
Validation loss: 2.5027490186171573

Epoch: 6| Step: 12
Training loss: 2.552454354441299
Validation loss: 2.522650270764238

Epoch: 6| Step: 13
Training loss: 2.666751522462517
Validation loss: 2.490475494788476

Epoch: 187| Step: 0
Training loss: 2.453185742834993
Validation loss: 2.484045464868374

Epoch: 6| Step: 1
Training loss: 2.6930740570469838
Validation loss: 2.501955704057173

Epoch: 6| Step: 2
Training loss: 2.748426160414889
Validation loss: 2.5248867333186142

Epoch: 6| Step: 3
Training loss: 2.647603581665309
Validation loss: 2.507161900405861

Epoch: 6| Step: 4
Training loss: 2.1716229409153343
Validation loss: 2.500830524680816

Epoch: 6| Step: 5
Training loss: 2.7373383078005795
Validation loss: 2.490398375684285

Epoch: 6| Step: 6
Training loss: 2.2665329790894932
Validation loss: 2.499116715908444

Epoch: 6| Step: 7
Training loss: 2.4540029521883966
Validation loss: 2.471835139024647

Epoch: 6| Step: 8
Training loss: 2.1207815822240472
Validation loss: 2.4941735863670735

Epoch: 6| Step: 9
Training loss: 2.9681257695903733
Validation loss: 2.472898943788717

Epoch: 6| Step: 10
Training loss: 2.434439571831707
Validation loss: 2.5233748467023815

Epoch: 6| Step: 11
Training loss: 2.563891521474089
Validation loss: 2.4838378856036933

Epoch: 6| Step: 12
Training loss: 2.8523978068093894
Validation loss: 2.4847469999388725

Epoch: 6| Step: 13
Training loss: 1.9465488044231254
Validation loss: 2.4803711858825532

Epoch: 188| Step: 0
Training loss: 2.954843818164692
Validation loss: 2.498587388698109

Epoch: 6| Step: 1
Training loss: 2.6105278346651515
Validation loss: 2.5291631460144197

Epoch: 6| Step: 2
Training loss: 2.305120602015792
Validation loss: 2.537972284068761

Epoch: 6| Step: 3
Training loss: 2.229302470506163
Validation loss: 2.4964365440299305

Epoch: 6| Step: 4
Training loss: 2.839148854867031
Validation loss: 2.502137729902217

Epoch: 6| Step: 5
Training loss: 2.3244807247971777
Validation loss: 2.5051584154163726

Epoch: 6| Step: 6
Training loss: 2.545470242328053
Validation loss: 2.522248644655237

Epoch: 6| Step: 7
Training loss: 2.4174938320960937
Validation loss: 2.487602703002333

Epoch: 6| Step: 8
Training loss: 2.182516361100963
Validation loss: 2.4680815924153743

Epoch: 6| Step: 9
Training loss: 2.1475690716436735
Validation loss: 2.4832620076008474

Epoch: 6| Step: 10
Training loss: 2.172178727462763
Validation loss: 2.5024182846878

Epoch: 6| Step: 11
Training loss: 2.884315326441225
Validation loss: 2.5298741636378583

Epoch: 6| Step: 12
Training loss: 2.706951806249949
Validation loss: 2.505737789736704

Epoch: 6| Step: 13
Training loss: 2.916455306614685
Validation loss: 2.514882527363377

Epoch: 189| Step: 0
Training loss: 2.4304679770056126
Validation loss: 2.4743516786540733

Epoch: 6| Step: 1
Training loss: 2.4311082617231397
Validation loss: 2.503800399432172

Epoch: 6| Step: 2
Training loss: 2.7476428940800646
Validation loss: 2.509978971610176

Epoch: 6| Step: 3
Training loss: 2.4732414625778767
Validation loss: 2.5388791455877238

Epoch: 6| Step: 4
Training loss: 2.489161361196573
Validation loss: 2.492268923111079

Epoch: 6| Step: 5
Training loss: 2.1043011713630264
Validation loss: 2.508436162575145

Epoch: 6| Step: 6
Training loss: 2.8625160849839766
Validation loss: 2.49312168876115

Epoch: 6| Step: 7
Training loss: 2.373057122855959
Validation loss: 2.5029911779508836

Epoch: 6| Step: 8
Training loss: 2.2898414510287846
Validation loss: 2.475293361546442

Epoch: 6| Step: 9
Training loss: 2.5654946483436545
Validation loss: 2.4883553604389443

Epoch: 6| Step: 10
Training loss: 2.5396864843243288
Validation loss: 2.510898808449988

Epoch: 6| Step: 11
Training loss: 2.6323209128184812
Validation loss: 2.478078733919925

Epoch: 6| Step: 12
Training loss: 2.379983792610441
Validation loss: 2.5086037989120893

Epoch: 6| Step: 13
Training loss: 3.553066814821863
Validation loss: 2.513658604302127

Epoch: 190| Step: 0
Training loss: 2.692682901898135
Validation loss: 2.4925648568200383

Epoch: 6| Step: 1
Training loss: 1.7726688819996703
Validation loss: 2.505564308590804

Epoch: 6| Step: 2
Training loss: 2.3311260773394795
Validation loss: 2.514361363324523

Epoch: 6| Step: 3
Training loss: 2.958838692783388
Validation loss: 2.4829734501283403

Epoch: 6| Step: 4
Training loss: 2.06595807181961
Validation loss: 2.519801040759017

Epoch: 6| Step: 5
Training loss: 2.459872351335183
Validation loss: 2.5093423734119815

Epoch: 6| Step: 6
Training loss: 2.500756149380533
Validation loss: 2.496375939610037

Epoch: 6| Step: 7
Training loss: 2.596397243947171
Validation loss: 2.4892261537405584

Epoch: 6| Step: 8
Training loss: 2.2988907668557395
Validation loss: 2.5135711436329

Epoch: 6| Step: 9
Training loss: 2.6042894156454874
Validation loss: 2.50565861270749

Epoch: 6| Step: 10
Training loss: 2.952864701036428
Validation loss: 2.5027936073002244

Epoch: 6| Step: 11
Training loss: 2.5818074139457186
Validation loss: 2.4996869916727067

Epoch: 6| Step: 12
Training loss: 3.1481671465713927
Validation loss: 2.474063369947765

Epoch: 6| Step: 13
Training loss: 2.341570234745395
Validation loss: 2.48807677727682

Epoch: 191| Step: 0
Training loss: 1.5897836134875787
Validation loss: 2.485444433948381

Epoch: 6| Step: 1
Training loss: 1.798077123148447
Validation loss: 2.5156587580481546

Epoch: 6| Step: 2
Training loss: 2.2994324854731056
Validation loss: 2.5103494148980077

Epoch: 6| Step: 3
Training loss: 2.1698966037710483
Validation loss: 2.5092881268892238

Epoch: 6| Step: 4
Training loss: 2.6090127842020787
Validation loss: 2.4845814819343346

Epoch: 6| Step: 5
Training loss: 2.7835683696744984
Validation loss: 2.5102121518931937

Epoch: 6| Step: 6
Training loss: 3.3139112813029077
Validation loss: 2.507074737670161

Epoch: 6| Step: 7
Training loss: 2.3024052068392984
Validation loss: 2.5031454387421967

Epoch: 6| Step: 8
Training loss: 3.122454407529373
Validation loss: 2.5042647635146222

Epoch: 6| Step: 9
Training loss: 2.5825786616263113
Validation loss: 2.473891971304718

Epoch: 6| Step: 10
Training loss: 2.312228006399166
Validation loss: 2.493733351510506

Epoch: 6| Step: 11
Training loss: 2.3221194234886715
Validation loss: 2.47371109785466

Epoch: 6| Step: 12
Training loss: 3.095643051960508
Validation loss: 2.501510647721232

Epoch: 6| Step: 13
Training loss: 2.629653892370334
Validation loss: 2.5141072123401007

Epoch: 192| Step: 0
Training loss: 2.3969580843574434
Validation loss: 2.5044900770466434

Epoch: 6| Step: 1
Training loss: 2.244580629936173
Validation loss: 2.5189404385615806

Epoch: 6| Step: 2
Training loss: 2.68458168024603
Validation loss: 2.502883355877344

Epoch: 6| Step: 3
Training loss: 2.461496247333066
Validation loss: 2.498045566520684

Epoch: 6| Step: 4
Training loss: 2.389580591982328
Validation loss: 2.5071000623253683

Epoch: 6| Step: 5
Training loss: 1.594160887167159
Validation loss: 2.5227265624664406

Epoch: 6| Step: 6
Training loss: 2.8554944664753403
Validation loss: 2.4644235812179067

Epoch: 6| Step: 7
Training loss: 2.700730867718706
Validation loss: 2.4938888798568937

Epoch: 6| Step: 8
Training loss: 2.507867830325658
Validation loss: 2.4992766554148225

Epoch: 6| Step: 9
Training loss: 2.5755382160542593
Validation loss: 2.5278069908668424

Epoch: 6| Step: 10
Training loss: 2.4146890660445393
Validation loss: 2.484463158264398

Epoch: 6| Step: 11
Training loss: 2.630344218656213
Validation loss: 2.4861379353361355

Epoch: 6| Step: 12
Training loss: 3.225233788111503
Validation loss: 2.513759569787983

Epoch: 6| Step: 13
Training loss: 2.6211479624842533
Validation loss: 2.480064311963389

Epoch: 193| Step: 0
Training loss: 2.2095961528849553
Validation loss: 2.5148521055884454

Epoch: 6| Step: 1
Training loss: 2.6742036721520237
Validation loss: 2.4862384150184784

Epoch: 6| Step: 2
Training loss: 2.594067657506016
Validation loss: 2.4902052673787725

Epoch: 6| Step: 3
Training loss: 2.6882495278501986
Validation loss: 2.512845459870058

Epoch: 6| Step: 4
Training loss: 2.861129805947205
Validation loss: 2.463914456718679

Epoch: 6| Step: 5
Training loss: 1.8718993298409399
Validation loss: 2.4735084512373087

Epoch: 6| Step: 6
Training loss: 2.186983319979857
Validation loss: 2.4878534231358214

Epoch: 6| Step: 7
Training loss: 2.7778972176198593
Validation loss: 2.5276695871043597

Epoch: 6| Step: 8
Training loss: 2.326101358083128
Validation loss: 2.4971641391904473

Epoch: 6| Step: 9
Training loss: 2.4495407452563223
Validation loss: 2.495479889489566

Epoch: 6| Step: 10
Training loss: 2.6114476361313668
Validation loss: 2.5006711735692075

Epoch: 6| Step: 11
Training loss: 3.125264271052292
Validation loss: 2.499640206113817

Epoch: 6| Step: 12
Training loss: 2.4650638923334487
Validation loss: 2.4888128906955873

Epoch: 6| Step: 13
Training loss: 2.396963753978045
Validation loss: 2.4984025814916686

Epoch: 194| Step: 0
Training loss: 2.4063031079265134
Validation loss: 2.492162169365909

Epoch: 6| Step: 1
Training loss: 2.472024412016094
Validation loss: 2.519919378667862

Epoch: 6| Step: 2
Training loss: 2.666175608323684
Validation loss: 2.501766905332574

Epoch: 6| Step: 3
Training loss: 2.3795886634745145
Validation loss: 2.5000953656127205

Epoch: 6| Step: 4
Training loss: 3.1441475770399285
Validation loss: 2.498735302801333

Epoch: 6| Step: 5
Training loss: 3.237661856946577
Validation loss: 2.4822126417376364

Epoch: 6| Step: 6
Training loss: 2.510509336246406
Validation loss: 2.4921926351195958

Epoch: 6| Step: 7
Training loss: 2.309928392068281
Validation loss: 2.523513886762864

Epoch: 6| Step: 8
Training loss: 2.701488462529035
Validation loss: 2.5114876143476064

Epoch: 6| Step: 9
Training loss: 2.501103729744802
Validation loss: 2.5267886019191823

Epoch: 6| Step: 10
Training loss: 2.019828494127885
Validation loss: 2.5076118853870093

Epoch: 6| Step: 11
Training loss: 2.414376741468417
Validation loss: 2.480543612667479

Epoch: 6| Step: 12
Training loss: 1.6763981037295737
Validation loss: 2.5069497446936566

Epoch: 6| Step: 13
Training loss: 2.2717344846652168
Validation loss: 2.530570208967073

Epoch: 195| Step: 0
Training loss: 2.494613949067633
Validation loss: 2.4650643436888626

Epoch: 6| Step: 1
Training loss: 2.9497034344069486
Validation loss: 2.5190711259238747

Epoch: 6| Step: 2
Training loss: 2.1322919608598765
Validation loss: 2.494177003971734

Epoch: 6| Step: 3
Training loss: 2.0851450354173413
Validation loss: 2.519948501676796

Epoch: 6| Step: 4
Training loss: 2.215296677123807
Validation loss: 2.5099746062311317

Epoch: 6| Step: 5
Training loss: 2.909971418207601
Validation loss: 2.5120671587106767

Epoch: 6| Step: 6
Training loss: 3.0551712160471127
Validation loss: 2.5056865974883107

Epoch: 6| Step: 7
Training loss: 2.772209131859312
Validation loss: 2.4981307599219775

Epoch: 6| Step: 8
Training loss: 2.1995072116339016
Validation loss: 2.5077915047015984

Epoch: 6| Step: 9
Training loss: 2.935476702005584
Validation loss: 2.521492178304921

Epoch: 6| Step: 10
Training loss: 2.4217117746785433
Validation loss: 2.5296460073713316

Epoch: 6| Step: 11
Training loss: 2.4733505841019467
Validation loss: 2.502977886472611

Epoch: 6| Step: 12
Training loss: 1.6616722455532096
Validation loss: 2.509322161235622

Epoch: 6| Step: 13
Training loss: 2.2813106163019006
Validation loss: 2.507251283006758

Epoch: 196| Step: 0
Training loss: 1.9863085600452988
Validation loss: 2.514690283859132

Epoch: 6| Step: 1
Training loss: 3.0257401877014622
Validation loss: 2.501423635498039

Epoch: 6| Step: 2
Training loss: 2.4377204599696394
Validation loss: 2.50606726822449

Epoch: 6| Step: 3
Training loss: 2.8843174756101075
Validation loss: 2.467803484946492

Epoch: 6| Step: 4
Training loss: 2.570318807576797
Validation loss: 2.4816442118868145

Epoch: 6| Step: 5
Training loss: 2.3341313655008356
Validation loss: 2.49098419334442

Epoch: 6| Step: 6
Training loss: 1.9576009503638576
Validation loss: 2.497409488481065

Epoch: 6| Step: 7
Training loss: 2.559131920977276
Validation loss: 2.492202251096342

Epoch: 6| Step: 8
Training loss: 2.390626894881551
Validation loss: 2.514776477192298

Epoch: 6| Step: 9
Training loss: 2.336888964749788
Validation loss: 2.4852140230992745

Epoch: 6| Step: 10
Training loss: 2.8103261387758223
Validation loss: 2.50621717642891

Epoch: 6| Step: 11
Training loss: 3.2797989316114053
Validation loss: 2.500760473443419

Epoch: 6| Step: 12
Training loss: 2.2224032990537563
Validation loss: 2.4838335898798807

Epoch: 6| Step: 13
Training loss: 1.9728849674996163
Validation loss: 2.4985719586079247

Epoch: 197| Step: 0
Training loss: 2.269936714130424
Validation loss: 2.5158025074759576

Epoch: 6| Step: 1
Training loss: 2.2332117213640412
Validation loss: 2.5087157355502567

Epoch: 6| Step: 2
Training loss: 2.555472996893922
Validation loss: 2.480086022653846

Epoch: 6| Step: 3
Training loss: 2.7192493725504407
Validation loss: 2.515730305147024

Epoch: 6| Step: 4
Training loss: 1.9310484500142637
Validation loss: 2.4740745542177365

Epoch: 6| Step: 5
Training loss: 3.0279323079594223
Validation loss: 2.4946243798992493

Epoch: 6| Step: 6
Training loss: 3.1953098138550753
Validation loss: 2.5076928133013507

Epoch: 6| Step: 7
Training loss: 2.105701553977635
Validation loss: 2.483676052855876

Epoch: 6| Step: 8
Training loss: 2.449485654752719
Validation loss: 2.500387013125472

Epoch: 6| Step: 9
Training loss: 2.512601753565711
Validation loss: 2.477617598997442

Epoch: 6| Step: 10
Training loss: 2.1649212286805266
Validation loss: 2.5072146540617664

Epoch: 6| Step: 11
Training loss: 3.0459305301992368
Validation loss: 2.490981586461107

Epoch: 6| Step: 12
Training loss: 2.179581615651754
Validation loss: 2.487614289637331

Epoch: 6| Step: 13
Training loss: 2.22798480733763
Validation loss: 2.501566928060942

Epoch: 198| Step: 0
Training loss: 3.340612204859953
Validation loss: 2.4853046442705127

Epoch: 6| Step: 1
Training loss: 2.261529627981855
Validation loss: 2.488273446603732

Epoch: 6| Step: 2
Training loss: 2.85635166112503
Validation loss: 2.4893203332476204

Epoch: 6| Step: 3
Training loss: 2.1863956388511667
Validation loss: 2.5101707609357793

Epoch: 6| Step: 4
Training loss: 2.132667061454607
Validation loss: 2.5055808400384154

Epoch: 6| Step: 5
Training loss: 2.8844151784427394
Validation loss: 2.510712070893673

Epoch: 6| Step: 6
Training loss: 1.707108484960768
Validation loss: 2.511936770335389

Epoch: 6| Step: 7
Training loss: 2.1545049267737095
Validation loss: 2.5235224904149556

Epoch: 6| Step: 8
Training loss: 2.820419774432524
Validation loss: 2.5048242802923366

Epoch: 6| Step: 9
Training loss: 2.7045077276840574
Validation loss: 2.514051159705452

Epoch: 6| Step: 10
Training loss: 2.443672580907316
Validation loss: 2.5229999601411857

Epoch: 6| Step: 11
Training loss: 2.2408970964220845
Validation loss: 2.4977715219817895

Epoch: 6| Step: 12
Training loss: 2.6883675705238645
Validation loss: 2.4961161665335374

Epoch: 6| Step: 13
Training loss: 2.7947925508383764
Validation loss: 2.5018894551560287

Epoch: 199| Step: 0
Training loss: 2.3975317422080193
Validation loss: 2.514240350820189

Epoch: 6| Step: 1
Training loss: 1.6987108896678167
Validation loss: 2.5185196098605194

Epoch: 6| Step: 2
Training loss: 2.5752696553487384
Validation loss: 2.497673611439441

Epoch: 6| Step: 3
Training loss: 2.3519586882044736
Validation loss: 2.5124879901541606

Epoch: 6| Step: 4
Training loss: 2.7642033258061365
Validation loss: 2.483004731224429

Epoch: 6| Step: 5
Training loss: 3.186580300883229
Validation loss: 2.499703957862173

Epoch: 6| Step: 6
Training loss: 2.455364104422076
Validation loss: 2.496583114073809

Epoch: 6| Step: 7
Training loss: 2.844721198608915
Validation loss: 2.5141196496169735

Epoch: 6| Step: 8
Training loss: 2.9095669757838993
Validation loss: 2.498783892517851

Epoch: 6| Step: 9
Training loss: 2.401649536064659
Validation loss: 2.4863773737364654

Epoch: 6| Step: 10
Training loss: 2.2665807352419893
Validation loss: 2.5118281044433552

Epoch: 6| Step: 11
Training loss: 1.9555140418043773
Validation loss: 2.488696424629348

Epoch: 6| Step: 12
Training loss: 2.719674578020917
Validation loss: 2.5267927535956836

Epoch: 6| Step: 13
Training loss: 2.386558315048155
Validation loss: 2.526282385133421

Epoch: 200| Step: 0
Training loss: 2.3259012751927712
Validation loss: 2.5227149333467143

Epoch: 6| Step: 1
Training loss: 2.5227321902765305
Validation loss: 2.5027560393643995

Epoch: 6| Step: 2
Training loss: 2.9012166397957655
Validation loss: 2.4818262115712413

Epoch: 6| Step: 3
Training loss: 2.458165911991887
Validation loss: 2.489542274241208

Epoch: 6| Step: 4
Training loss: 2.855104185698632
Validation loss: 2.46298047863586

Epoch: 6| Step: 5
Training loss: 2.500182335880022
Validation loss: 2.4914422667319576

Epoch: 6| Step: 6
Training loss: 2.809612911618746
Validation loss: 2.5110183020083636

Epoch: 6| Step: 7
Training loss: 2.5796451595165824
Validation loss: 2.49937422519129

Epoch: 6| Step: 8
Training loss: 2.696412235307967
Validation loss: 2.483366307630665

Epoch: 6| Step: 9
Training loss: 2.538460528100086
Validation loss: 2.5132181450486417

Epoch: 6| Step: 10
Training loss: 1.44261304997452
Validation loss: 2.5115108836167295

Epoch: 6| Step: 11
Training loss: 2.5660776424361167
Validation loss: 2.479209135013568

Epoch: 6| Step: 12
Training loss: 2.7182205386200597
Validation loss: 2.5045297408988922

Epoch: 6| Step: 13
Training loss: 2.2646386465870174
Validation loss: 2.5001280536465647

Epoch: 201| Step: 0
Training loss: 1.6049268415896278
Validation loss: 2.4950303396769504

Epoch: 6| Step: 1
Training loss: 2.672443530179276
Validation loss: 2.5300016303711574

Epoch: 6| Step: 2
Training loss: 2.909631873897721
Validation loss: 2.5014922723265625

Epoch: 6| Step: 3
Training loss: 2.787110230433033
Validation loss: 2.515563354674439

Epoch: 6| Step: 4
Training loss: 2.3377252072457715
Validation loss: 2.4885876319285747

Epoch: 6| Step: 5
Training loss: 2.292260029587265
Validation loss: 2.4967909613393893

Epoch: 6| Step: 6
Training loss: 3.3472528381495175
Validation loss: 2.4928829356802527

Epoch: 6| Step: 7
Training loss: 2.184891153238867
Validation loss: 2.5286124507628114

Epoch: 6| Step: 8
Training loss: 2.8438980567034022
Validation loss: 2.488340020924469

Epoch: 6| Step: 9
Training loss: 2.1599796492006442
Validation loss: 2.5073792628322433

Epoch: 6| Step: 10
Training loss: 2.420922664322605
Validation loss: 2.520948116733725

Epoch: 6| Step: 11
Training loss: 2.3072167952009566
Validation loss: 2.509918533824935

Epoch: 6| Step: 12
Training loss: 2.134239976669713
Validation loss: 2.5037065234703397

Epoch: 6| Step: 13
Training loss: 2.411282713546049
Validation loss: 2.510985011456771

Epoch: 202| Step: 0
Training loss: 2.8139202346721146
Validation loss: 2.492671990823336

Epoch: 6| Step: 1
Training loss: 2.786382504200885
Validation loss: 2.514759742160344

Epoch: 6| Step: 2
Training loss: 2.493057529610431
Validation loss: 2.498755690385806

Epoch: 6| Step: 3
Training loss: 2.552840098590142
Validation loss: 2.5037853695624404

Epoch: 6| Step: 4
Training loss: 1.816725048678621
Validation loss: 2.5018401705491975

Epoch: 6| Step: 5
Training loss: 2.799182046899299
Validation loss: 2.4914325161121966

Epoch: 6| Step: 6
Training loss: 2.3451842942036127
Validation loss: 2.5013886133051444

Epoch: 6| Step: 7
Training loss: 2.67607322269384
Validation loss: 2.481835738592952

Epoch: 6| Step: 8
Training loss: 2.471876651266634
Validation loss: 2.485435605652375

Epoch: 6| Step: 9
Training loss: 2.5263619026568227
Validation loss: 2.4920513018007657

Epoch: 6| Step: 10
Training loss: 2.097939243087842
Validation loss: 2.5205123528872315

Epoch: 6| Step: 11
Training loss: 2.480305824035296
Validation loss: 2.4911885118164325

Epoch: 6| Step: 12
Training loss: 2.852359022957946
Validation loss: 2.519085375618646

Epoch: 6| Step: 13
Training loss: 1.5028429904889897
Validation loss: 2.4970333391423583

Epoch: 203| Step: 0
Training loss: 2.176160139039549
Validation loss: 2.490952167496028

Epoch: 6| Step: 1
Training loss: 2.662823430864766
Validation loss: 2.4768559828121415

Epoch: 6| Step: 2
Training loss: 2.2181711650740388
Validation loss: 2.5091302385904037

Epoch: 6| Step: 3
Training loss: 2.75651126237489
Validation loss: 2.5146918507775133

Epoch: 6| Step: 4
Training loss: 2.8788267458492856
Validation loss: 2.511181400649442

Epoch: 6| Step: 5
Training loss: 2.150313234798936
Validation loss: 2.5095665200702024

Epoch: 6| Step: 6
Training loss: 2.257171011743976
Validation loss: 2.4725639542337907

Epoch: 6| Step: 7
Training loss: 2.436414623697472
Validation loss: 2.5353137521543543

Epoch: 6| Step: 8
Training loss: 2.894309175649355
Validation loss: 2.4892638877637103

Epoch: 6| Step: 9
Training loss: 2.7566784480287896
Validation loss: 2.473771902075056

Epoch: 6| Step: 10
Training loss: 2.548596040529278
Validation loss: 2.5058006671255666

Epoch: 6| Step: 11
Training loss: 1.8316939639254912
Validation loss: 2.503543969035384

Epoch: 6| Step: 12
Training loss: 2.7034897751075975
Validation loss: 2.4937983830136994

Epoch: 6| Step: 13
Training loss: 2.5690570768413465
Validation loss: 2.493940617003589

Epoch: 204| Step: 0
Training loss: 2.965050731565866
Validation loss: 2.4882928489295852

Epoch: 6| Step: 1
Training loss: 1.7790524495945035
Validation loss: 2.487566613838778

Epoch: 6| Step: 2
Training loss: 2.672964665811221
Validation loss: 2.4782207311674234

Epoch: 6| Step: 3
Training loss: 2.70944779770145
Validation loss: 2.509638100904289

Epoch: 6| Step: 4
Training loss: 2.922414474867492
Validation loss: 2.5010302866372194

Epoch: 6| Step: 5
Training loss: 2.3490182286737062
Validation loss: 2.503047027608626

Epoch: 6| Step: 6
Training loss: 2.3937457291288595
Validation loss: 2.4592157010553604

Epoch: 6| Step: 7
Training loss: 2.585134975222456
Validation loss: 2.507812528623327

Epoch: 6| Step: 8
Training loss: 2.113996402358474
Validation loss: 2.5038577156609705

Epoch: 6| Step: 9
Training loss: 2.453318788685738
Validation loss: 2.5186791376452025

Epoch: 6| Step: 10
Training loss: 3.0152516504537337
Validation loss: 2.48140594344909

Epoch: 6| Step: 11
Training loss: 1.7518180531430052
Validation loss: 2.5425091276389047

Epoch: 6| Step: 12
Training loss: 1.924279794100293
Validation loss: 2.507293846880294

Epoch: 6| Step: 13
Training loss: 3.347049974271887
Validation loss: 2.500461021594647

Epoch: 205| Step: 0
Training loss: 2.8049883242821405
Validation loss: 2.5053291434083955

Epoch: 6| Step: 1
Training loss: 2.765641724271908
Validation loss: 2.490466221104983

Epoch: 6| Step: 2
Training loss: 2.7704418928864674
Validation loss: 2.516010467625751

Epoch: 6| Step: 3
Training loss: 2.4365635564708095
Validation loss: 2.515068860477745

Epoch: 6| Step: 4
Training loss: 2.2853762789704266
Validation loss: 2.4964538835140466

Epoch: 6| Step: 5
Training loss: 2.926358297202507
Validation loss: 2.507801747828532

Epoch: 6| Step: 6
Training loss: 2.4433607410942426
Validation loss: 2.492705956872256

Epoch: 6| Step: 7
Training loss: 2.8318217864348303
Validation loss: 2.514735004365875

Epoch: 6| Step: 8
Training loss: 2.837674536357542
Validation loss: 2.486930964129002

Epoch: 6| Step: 9
Training loss: 2.4875446948152735
Validation loss: 2.5008691445915217

Epoch: 6| Step: 10
Training loss: 1.746478761558581
Validation loss: 2.4843108744906015

Epoch: 6| Step: 11
Training loss: 2.621015158098933
Validation loss: 2.4839863539275613

Epoch: 6| Step: 12
Training loss: 1.662126086069231
Validation loss: 2.4954117817722414

Epoch: 6| Step: 13
Training loss: 1.8170620298488998
Validation loss: 2.4847601815569136

Epoch: 206| Step: 0
Training loss: 2.198179280530373
Validation loss: 2.4894829787028514

Epoch: 6| Step: 1
Training loss: 3.527902147064901
Validation loss: 2.479621360185141

Epoch: 6| Step: 2
Training loss: 2.4326873609910673
Validation loss: 2.4893871844003033

Epoch: 6| Step: 3
Training loss: 2.413926994199534
Validation loss: 2.495839130636537

Epoch: 6| Step: 4
Training loss: 2.1246096308561278
Validation loss: 2.5214529124396137

Epoch: 6| Step: 5
Training loss: 2.8589657349909845
Validation loss: 2.50598812359982

Epoch: 6| Step: 6
Training loss: 1.8859074271774467
Validation loss: 2.5207064305208693

Epoch: 6| Step: 7
Training loss: 2.763846304952557
Validation loss: 2.495695914447306

Epoch: 6| Step: 8
Training loss: 1.7995884848778025
Validation loss: 2.5173155578482262

Epoch: 6| Step: 9
Training loss: 2.4589061285269658
Validation loss: 2.490708280827601

Epoch: 6| Step: 10
Training loss: 1.818067549777733
Validation loss: 2.5012679668490336

Epoch: 6| Step: 11
Training loss: 2.57169126500916
Validation loss: 2.4998328829868273

Epoch: 6| Step: 12
Training loss: 2.6105820839103098
Validation loss: 2.4884358385397434

Epoch: 6| Step: 13
Training loss: 3.2544161796565225
Validation loss: 2.489631157750938

Epoch: 207| Step: 0
Training loss: 2.880984835721498
Validation loss: 2.4980629317813494

Epoch: 6| Step: 1
Training loss: 2.3527233008881416
Validation loss: 2.506214246806074

Epoch: 6| Step: 2
Training loss: 2.2860336314787038
Validation loss: 2.5078901334398793

Epoch: 6| Step: 3
Training loss: 2.4014528685088097
Validation loss: 2.516285020879909

Epoch: 6| Step: 4
Training loss: 3.1244144654075505
Validation loss: 2.491245014026448

Epoch: 6| Step: 5
Training loss: 1.9561486604907352
Validation loss: 2.5017669391487303

Epoch: 6| Step: 6
Training loss: 2.010569894383534
Validation loss: 2.477026796526719

Epoch: 6| Step: 7
Training loss: 2.284809001394113
Validation loss: 2.4930201008342396

Epoch: 6| Step: 8
Training loss: 2.47572558007287
Validation loss: 2.5058151007309193

Epoch: 6| Step: 9
Training loss: 2.079319316736458
Validation loss: 2.4937724288016927

Epoch: 6| Step: 10
Training loss: 2.5710069825453363
Validation loss: 2.4929242763695987

Epoch: 6| Step: 11
Training loss: 2.6920482384722826
Validation loss: 2.4844009522919133

Epoch: 6| Step: 12
Training loss: 2.7563059206456084
Validation loss: 2.4988292003460644

Epoch: 6| Step: 13
Training loss: 2.7826335765928705
Validation loss: 2.483211924851516

Epoch: 208| Step: 0
Training loss: 2.7113750005796526
Validation loss: 2.5013149812657107

Epoch: 6| Step: 1
Training loss: 2.864220021645939
Validation loss: 2.5119728762707196

Epoch: 6| Step: 2
Training loss: 1.984546443711952
Validation loss: 2.5002625686418174

Epoch: 6| Step: 3
Training loss: 2.4114698790128966
Validation loss: 2.5009167651526054

Epoch: 6| Step: 4
Training loss: 2.300077942895848
Validation loss: 2.53818469199538

Epoch: 6| Step: 5
Training loss: 2.972376806531245
Validation loss: 2.491916416086102

Epoch: 6| Step: 6
Training loss: 2.497512342634432
Validation loss: 2.4974686409920137

Epoch: 6| Step: 7
Training loss: 1.994563761176075
Validation loss: 2.479049661932216

Epoch: 6| Step: 8
Training loss: 2.5727565473599796
Validation loss: 2.4907976877841342

Epoch: 6| Step: 9
Training loss: 2.88378823574531
Validation loss: 2.5105451216469366

Epoch: 6| Step: 10
Training loss: 2.4985122068304295
Validation loss: 2.5089885693798344

Epoch: 6| Step: 11
Training loss: 2.231768815445108
Validation loss: 2.490557957922643

Epoch: 6| Step: 12
Training loss: 2.4162380452262417
Validation loss: 2.507518995583577

Epoch: 6| Step: 13
Training loss: 2.286287467903976
Validation loss: 2.5299253543751683

Epoch: 209| Step: 0
Training loss: 2.4932325318643622
Validation loss: 2.4962255985595676

Epoch: 6| Step: 1
Training loss: 2.3595381926630257
Validation loss: 2.4925503310587147

Epoch: 6| Step: 2
Training loss: 2.281933825697687
Validation loss: 2.517303253987499

Epoch: 6| Step: 3
Training loss: 2.062709219753562
Validation loss: 2.5081232023038615

Epoch: 6| Step: 4
Training loss: 1.2764793527668832
Validation loss: 2.4965091143851734

Epoch: 6| Step: 5
Training loss: 2.1874428877868106
Validation loss: 2.4808051538376907

Epoch: 6| Step: 6
Training loss: 3.1778568180927893
Validation loss: 2.50232463144222

Epoch: 6| Step: 7
Training loss: 1.6223974661617317
Validation loss: 2.494653332165205

Epoch: 6| Step: 8
Training loss: 2.997819107797562
Validation loss: 2.4973587039703

Epoch: 6| Step: 9
Training loss: 3.3643020339074794
Validation loss: 2.4897867477408915

Epoch: 6| Step: 10
Training loss: 2.625425213479658
Validation loss: 2.5182407878269895

Epoch: 6| Step: 11
Training loss: 2.694336202966415
Validation loss: 2.4893504342017967

Epoch: 6| Step: 12
Training loss: 2.315672682710082
Validation loss: 2.504616433335516

Epoch: 6| Step: 13
Training loss: 2.583173398225108
Validation loss: 2.5107965077751526

Epoch: 210| Step: 0
Training loss: 1.8662596116837293
Validation loss: 2.4823562263427625

Epoch: 6| Step: 1
Training loss: 2.5207191210218087
Validation loss: 2.4827368070250335

Epoch: 6| Step: 2
Training loss: 2.074725360389881
Validation loss: 2.498593296606471

Epoch: 6| Step: 3
Training loss: 3.1941049994382658
Validation loss: 2.5114247905313842

Epoch: 6| Step: 4
Training loss: 2.4131817738835406
Validation loss: 2.505583366249279

Epoch: 6| Step: 5
Training loss: 2.4681347430402267
Validation loss: 2.5125875742337143

Epoch: 6| Step: 6
Training loss: 2.674021165676989
Validation loss: 2.5168991872036677

Epoch: 6| Step: 7
Training loss: 2.1670996771236894
Validation loss: 2.519007281172511

Epoch: 6| Step: 8
Training loss: 2.392161056601632
Validation loss: 2.5037309278933604

Epoch: 6| Step: 9
Training loss: 2.867793463512537
Validation loss: 2.469484491253978

Epoch: 6| Step: 10
Training loss: 2.2842859420428625
Validation loss: 2.5167691500091114

Epoch: 6| Step: 11
Training loss: 2.7559107634405295
Validation loss: 2.5116783749589287

Epoch: 6| Step: 12
Training loss: 2.4018921466406935
Validation loss: 2.476690678585333

Epoch: 6| Step: 13
Training loss: 2.4985923618897012
Validation loss: 2.4937561881350736

Epoch: 211| Step: 0
Training loss: 2.6254680761177385
Validation loss: 2.479658806143854

Epoch: 6| Step: 1
Training loss: 2.1693144050120923
Validation loss: 2.5060832828249056

Epoch: 6| Step: 2
Training loss: 2.462368794155371
Validation loss: 2.4879344584484246

Epoch: 6| Step: 3
Training loss: 2.3512214083760923
Validation loss: 2.5049723582971364

Epoch: 6| Step: 4
Training loss: 2.5654843327830656
Validation loss: 2.492141437750975

Epoch: 6| Step: 5
Training loss: 2.753288556890186
Validation loss: 2.505734061528005

Epoch: 6| Step: 6
Training loss: 2.0769662709920502
Validation loss: 2.4928957338848354

Epoch: 6| Step: 7
Training loss: 2.7192882136649383
Validation loss: 2.495126498352496

Epoch: 6| Step: 8
Training loss: 2.4620183599548233
Validation loss: 2.5046042252321223

Epoch: 6| Step: 9
Training loss: 3.0925122491937804
Validation loss: 2.5234060414728527

Epoch: 6| Step: 10
Training loss: 2.220178278732469
Validation loss: 2.4906284134571823

Epoch: 6| Step: 11
Training loss: 2.031940518897851
Validation loss: 2.483999648980586

Epoch: 6| Step: 12
Training loss: 2.5750268064418362
Validation loss: 2.4963647766935986

Epoch: 6| Step: 13
Training loss: 2.7362131098686717
Validation loss: 2.510284795826232

Epoch: 212| Step: 0
Training loss: 2.6565720306860934
Validation loss: 2.524436681496191

Epoch: 6| Step: 1
Training loss: 2.0345045572915623
Validation loss: 2.50890345345308

Epoch: 6| Step: 2
Training loss: 2.5650358910680064
Validation loss: 2.4811613338621568

Epoch: 6| Step: 3
Training loss: 1.803797514799195
Validation loss: 2.5097381617107763

Epoch: 6| Step: 4
Training loss: 2.4503508024721237
Validation loss: 2.5017356426130055

Epoch: 6| Step: 5
Training loss: 2.549433353520297
Validation loss: 2.486071484568583

Epoch: 6| Step: 6
Training loss: 3.10346046624402
Validation loss: 2.4828492789674734

Epoch: 6| Step: 7
Training loss: 2.2421537921777577
Validation loss: 2.502604567544268

Epoch: 6| Step: 8
Training loss: 2.852451969581527
Validation loss: 2.5126634858348034

Epoch: 6| Step: 9
Training loss: 2.583005966445465
Validation loss: 2.5008967442281316

Epoch: 6| Step: 10
Training loss: 2.1379431192737566
Validation loss: 2.4986882162484814

Epoch: 6| Step: 11
Training loss: 2.2358263543932724
Validation loss: 2.506643520742327

Epoch: 6| Step: 12
Training loss: 2.6606802403291674
Validation loss: 2.5024589320663826

Epoch: 6| Step: 13
Training loss: 2.499203078091737
Validation loss: 2.5058755924702445

Epoch: 213| Step: 0
Training loss: 2.919493658504142
Validation loss: 2.505592337397936

Epoch: 6| Step: 1
Training loss: 2.786766752958397
Validation loss: 2.4983446137053775

Epoch: 6| Step: 2
Training loss: 2.9145751174981838
Validation loss: 2.5177110987730766

Epoch: 6| Step: 3
Training loss: 1.9078763059151622
Validation loss: 2.5125349813446474

Epoch: 6| Step: 4
Training loss: 2.201661185008215
Validation loss: 2.4639580407775745

Epoch: 6| Step: 5
Training loss: 1.8684760719014601
Validation loss: 2.48706922238688

Epoch: 6| Step: 6
Training loss: 2.5292478578744513
Validation loss: 2.4899725836031785

Epoch: 6| Step: 7
Training loss: 2.412262378118058
Validation loss: 2.502421113234825

Epoch: 6| Step: 8
Training loss: 2.2670521417720377
Validation loss: 2.511921817725441

Epoch: 6| Step: 9
Training loss: 2.3811341425227392
Validation loss: 2.510938341458504

Epoch: 6| Step: 10
Training loss: 2.409102495469879
Validation loss: 2.515081060597124

Epoch: 6| Step: 11
Training loss: 2.6858868747842273
Validation loss: 2.5245868007694314

Epoch: 6| Step: 12
Training loss: 2.966537775675833
Validation loss: 2.4817883644629273

Epoch: 6| Step: 13
Training loss: 2.051134758408052
Validation loss: 2.512120626785339

Epoch: 214| Step: 0
Training loss: 2.3251135890654644
Validation loss: 2.5016910719648635

Epoch: 6| Step: 1
Training loss: 2.708177552266847
Validation loss: 2.518470829341201

Epoch: 6| Step: 2
Training loss: 2.4458369950933734
Validation loss: 2.496787683873872

Epoch: 6| Step: 3
Training loss: 2.0558888219615867
Validation loss: 2.510405461340754

Epoch: 6| Step: 4
Training loss: 2.7735177901560344
Validation loss: 2.518237611576384

Epoch: 6| Step: 5
Training loss: 2.1880703863646698
Validation loss: 2.4900417358087266

Epoch: 6| Step: 6
Training loss: 2.4396012859080276
Validation loss: 2.502490534058315

Epoch: 6| Step: 7
Training loss: 2.966218692374797
Validation loss: 2.492416803843014

Epoch: 6| Step: 8
Training loss: 2.506562013301462
Validation loss: 2.493470197111906

Epoch: 6| Step: 9
Training loss: 2.8338051758363996
Validation loss: 2.506229434981173

Epoch: 6| Step: 10
Training loss: 2.4882820165324566
Validation loss: 2.5218912498230246

Epoch: 6| Step: 11
Training loss: 1.8573591701059688
Validation loss: 2.5079873108782675

Epoch: 6| Step: 12
Training loss: 2.354129847235807
Validation loss: 2.5194091258524125

Epoch: 6| Step: 13
Training loss: 2.272758566034061
Validation loss: 2.5110106141936144

Epoch: 215| Step: 0
Training loss: 2.9521863949449476
Validation loss: 2.494128351230091

Epoch: 6| Step: 1
Training loss: 2.331454360636292
Validation loss: 2.5225320833264884

Epoch: 6| Step: 2
Training loss: 2.3061568409368864
Validation loss: 2.494837317591871

Epoch: 6| Step: 3
Training loss: 1.9048726468307327
Validation loss: 2.4713070805518313

Epoch: 6| Step: 4
Training loss: 2.1244779955415023
Validation loss: 2.488520740753507

Epoch: 6| Step: 5
Training loss: 2.3759065203018594
Validation loss: 2.534047512154754

Epoch: 6| Step: 6
Training loss: 3.1344216796806785
Validation loss: 2.5145247100329207

Epoch: 6| Step: 7
Training loss: 2.079041013825944
Validation loss: 2.481402142006215

Epoch: 6| Step: 8
Training loss: 2.752571550871962
Validation loss: 2.5020211642900834

Epoch: 6| Step: 9
Training loss: 2.223604827825387
Validation loss: 2.4865569082802756

Epoch: 6| Step: 10
Training loss: 3.031713863157122
Validation loss: 2.5081075850538066

Epoch: 6| Step: 11
Training loss: 2.610607472900412
Validation loss: 2.5146888504898683

Epoch: 6| Step: 12
Training loss: 1.8163811794724822
Validation loss: 2.480265735589498

Epoch: 6| Step: 13
Training loss: 2.752923192087273
Validation loss: 2.4692912008930334

Epoch: 216| Step: 0
Training loss: 2.927184477627683
Validation loss: 2.489057539861225

Epoch: 6| Step: 1
Training loss: 1.9087721601897334
Validation loss: 2.491360622120633

Epoch: 6| Step: 2
Training loss: 2.2091011535915044
Validation loss: 2.4855545513870263

Epoch: 6| Step: 3
Training loss: 2.3888228860751433
Validation loss: 2.507656100329924

Epoch: 6| Step: 4
Training loss: 2.8327428726081036
Validation loss: 2.5069375131838267

Epoch: 6| Step: 5
Training loss: 2.7444599875328746
Validation loss: 2.506044398522513

Epoch: 6| Step: 6
Training loss: 2.3868014606934853
Validation loss: 2.5034556880390495

Epoch: 6| Step: 7
Training loss: 2.2733445820385616
Validation loss: 2.471610213438455

Epoch: 6| Step: 8
Training loss: 2.213217917309435
Validation loss: 2.4748422829517946

Epoch: 6| Step: 9
Training loss: 2.6085574759640076
Validation loss: 2.4857255852112745

Epoch: 6| Step: 10
Training loss: 2.353879173976424
Validation loss: 2.5277324833448467

Epoch: 6| Step: 11
Training loss: 2.4435237887141517
Validation loss: 2.5260248330590027

Epoch: 6| Step: 12
Training loss: 2.494136992521337
Validation loss: 2.47031092178535

Epoch: 6| Step: 13
Training loss: 2.8267022026125495
Validation loss: 2.492592156547291

Epoch: 217| Step: 0
Training loss: 2.941163071994556
Validation loss: 2.508186404206252

Epoch: 6| Step: 1
Training loss: 1.7695051111307565
Validation loss: 2.492045756441322

Epoch: 6| Step: 2
Training loss: 2.0785400435073123
Validation loss: 2.476910290672754

Epoch: 6| Step: 3
Training loss: 2.8542243970244066
Validation loss: 2.488467105572338

Epoch: 6| Step: 4
Training loss: 2.716370516902143
Validation loss: 2.5259050628968565

Epoch: 6| Step: 5
Training loss: 2.492793281617862
Validation loss: 2.4928772600231364

Epoch: 6| Step: 6
Training loss: 2.412951562552613
Validation loss: 2.5095627168471193

Epoch: 6| Step: 7
Training loss: 2.689015870296791
Validation loss: 2.4847340627772163

Epoch: 6| Step: 8
Training loss: 2.5091513984221554
Validation loss: 2.5113902906100622

Epoch: 6| Step: 9
Training loss: 2.4380764401901858
Validation loss: 2.531900115533684

Epoch: 6| Step: 10
Training loss: 2.517253656542088
Validation loss: 2.4819917666467655

Epoch: 6| Step: 11
Training loss: 2.4859539268809283
Validation loss: 2.517700604743216

Epoch: 6| Step: 12
Training loss: 2.2950565120080477
Validation loss: 2.4984557499404647

Epoch: 6| Step: 13
Training loss: 2.3352244638056106
Validation loss: 2.518070405848348

Epoch: 218| Step: 0
Training loss: 2.39885665759803
Validation loss: 2.5047338510228756

Epoch: 6| Step: 1
Training loss: 2.367787300893074
Validation loss: 2.5156551036486987

Epoch: 6| Step: 2
Training loss: 2.787731975260077
Validation loss: 2.4914136753700857

Epoch: 6| Step: 3
Training loss: 2.988563035631729
Validation loss: 2.484940436468852

Epoch: 6| Step: 4
Training loss: 2.0803754280638613
Validation loss: 2.5064586150888406

Epoch: 6| Step: 5
Training loss: 2.429457282539272
Validation loss: 2.500193325894449

Epoch: 6| Step: 6
Training loss: 2.42887349614304
Validation loss: 2.5083875288535777

Epoch: 6| Step: 7
Training loss: 2.782831321108623
Validation loss: 2.48231468073484

Epoch: 6| Step: 8
Training loss: 1.8208964970484338
Validation loss: 2.4945480467845766

Epoch: 6| Step: 9
Training loss: 1.8817358460505351
Validation loss: 2.507404410598997

Epoch: 6| Step: 10
Training loss: 2.421584179552647
Validation loss: 2.4894098080740084

Epoch: 6| Step: 11
Training loss: 2.4866242213713248
Validation loss: 2.500843892153826

Epoch: 6| Step: 12
Training loss: 2.836334957297927
Validation loss: 2.4921724721022342

Epoch: 6| Step: 13
Training loss: 2.5123428827001115
Validation loss: 2.47104235020291

Epoch: 219| Step: 0
Training loss: 2.643834257474105
Validation loss: 2.5080208313451315

Epoch: 6| Step: 1
Training loss: 2.1594503121830226
Validation loss: 2.496827047572575

Epoch: 6| Step: 2
Training loss: 2.3634198613147293
Validation loss: 2.489973629662222

Epoch: 6| Step: 3
Training loss: 2.7154146101985126
Validation loss: 2.47799996788122

Epoch: 6| Step: 4
Training loss: 2.7702524728398217
Validation loss: 2.527325072489493

Epoch: 6| Step: 5
Training loss: 2.55335165672932
Validation loss: 2.515325980076047

Epoch: 6| Step: 6
Training loss: 2.200324368406257
Validation loss: 2.5145273465435825

Epoch: 6| Step: 7
Training loss: 2.5377831625208573
Validation loss: 2.525877887747533

Epoch: 6| Step: 8
Training loss: 2.316736413285417
Validation loss: 2.4872708476482375

Epoch: 6| Step: 9
Training loss: 2.3558126676139035
Validation loss: 2.5121186776132087

Epoch: 6| Step: 10
Training loss: 2.6812378427367705
Validation loss: 2.488831662540962

Epoch: 6| Step: 11
Training loss: 2.3018342540738113
Validation loss: 2.506415392647659

Epoch: 6| Step: 12
Training loss: 2.082687875577821
Validation loss: 2.4742684609154897

Epoch: 6| Step: 13
Training loss: 2.588501549351689
Validation loss: 2.4809232913341743

Epoch: 220| Step: 0
Training loss: 2.2731348209834974
Validation loss: 2.493594506623674

Epoch: 6| Step: 1
Training loss: 2.7914462975213765
Validation loss: 2.536609949773617

Epoch: 6| Step: 2
Training loss: 2.2326655751306634
Validation loss: 2.4944968761766337

Epoch: 6| Step: 3
Training loss: 2.677761264167965
Validation loss: 2.4746882334176

Epoch: 6| Step: 4
Training loss: 2.7506348137310996
Validation loss: 2.5181981738157093

Epoch: 6| Step: 5
Training loss: 1.9193508040090268
Validation loss: 2.514272691303817

Epoch: 6| Step: 6
Training loss: 2.6472284038302965
Validation loss: 2.5303433565819833

Epoch: 6| Step: 7
Training loss: 2.518960577631694
Validation loss: 2.4957721646899906

Epoch: 6| Step: 8
Training loss: 2.6098640577495336
Validation loss: 2.493577888514674

Epoch: 6| Step: 9
Training loss: 2.746958003780934
Validation loss: 2.474267720089117

Epoch: 6| Step: 10
Training loss: 2.599347337088082
Validation loss: 2.505605739321528

Epoch: 6| Step: 11
Training loss: 1.9579454064828916
Validation loss: 2.4879234884735997

Epoch: 6| Step: 12
Training loss: 2.485998810612094
Validation loss: 2.5290373906915247

Epoch: 6| Step: 13
Training loss: 1.6333169112385513
Validation loss: 2.5051388755960984

Epoch: 221| Step: 0
Training loss: 2.391069159043217
Validation loss: 2.502423633415283

Epoch: 6| Step: 1
Training loss: 2.2506509475038547
Validation loss: 2.499159724012768

Epoch: 6| Step: 2
Training loss: 1.545370429855707
Validation loss: 2.5178410720466085

Epoch: 6| Step: 3
Training loss: 2.457289156091132
Validation loss: 2.5093918386145786

Epoch: 6| Step: 4
Training loss: 2.661635739459912
Validation loss: 2.4988108349853375

Epoch: 6| Step: 5
Training loss: 2.461848402225854
Validation loss: 2.502313523749353

Epoch: 6| Step: 6
Training loss: 2.6832616342320588
Validation loss: 2.480410287646273

Epoch: 6| Step: 7
Training loss: 2.460935077968798
Validation loss: 2.5081227515422637

Epoch: 6| Step: 8
Training loss: 3.0708140965708495
Validation loss: 2.4971261606052404

Epoch: 6| Step: 9
Training loss: 2.6269070192282973
Validation loss: 2.5250360440630333

Epoch: 6| Step: 10
Training loss: 2.2457823960491035
Validation loss: 2.5152716393895274

Epoch: 6| Step: 11
Training loss: 2.4724677377106006
Validation loss: 2.502029261911097

Epoch: 6| Step: 12
Training loss: 2.3335475369179144
Validation loss: 2.509018606540452

Epoch: 6| Step: 13
Training loss: 2.706983337418703
Validation loss: 2.487407920321646

Epoch: 222| Step: 0
Training loss: 2.2518799663216837
Validation loss: 2.4995626025933726

Epoch: 6| Step: 1
Training loss: 2.3347240345368117
Validation loss: 2.5097614809084

Epoch: 6| Step: 2
Training loss: 2.406794597874659
Validation loss: 2.515437687900305

Epoch: 6| Step: 3
Training loss: 2.7239204438141207
Validation loss: 2.496370845957946

Epoch: 6| Step: 4
Training loss: 2.3230303635306306
Validation loss: 2.4996015333700368

Epoch: 6| Step: 5
Training loss: 2.7196211022248575
Validation loss: 2.512403766750453

Epoch: 6| Step: 6
Training loss: 2.152096271999149
Validation loss: 2.519750967999654

Epoch: 6| Step: 7
Training loss: 2.173658777377155
Validation loss: 2.49172074935593

Epoch: 6| Step: 8
Training loss: 2.641206936789841
Validation loss: 2.4927509370573104

Epoch: 6| Step: 9
Training loss: 2.5114094735108683
Validation loss: 2.5238851398278506

Epoch: 6| Step: 10
Training loss: 2.3966248462549418
Validation loss: 2.5270786194832224

Epoch: 6| Step: 11
Training loss: 2.868678897815929
Validation loss: 2.502991133908959

Epoch: 6| Step: 12
Training loss: 2.418928556726889
Validation loss: 2.4951993626389783

Epoch: 6| Step: 13
Training loss: 2.30201933989036
Validation loss: 2.510610618310461

Epoch: 223| Step: 0
Training loss: 2.328732609665991
Validation loss: 2.515839125515538

Epoch: 6| Step: 1
Training loss: 2.4147480111718687
Validation loss: 2.5138795423004394

Epoch: 6| Step: 2
Training loss: 2.489842474523863
Validation loss: 2.4890748354781858

Epoch: 6| Step: 3
Training loss: 3.1632348756035906
Validation loss: 2.490073598344055

Epoch: 6| Step: 4
Training loss: 2.4961251747887387
Validation loss: 2.5000351703384878

Epoch: 6| Step: 5
Training loss: 2.553360153817663
Validation loss: 2.5347526083972722

Epoch: 6| Step: 6
Training loss: 2.2347311522997755
Validation loss: 2.4792090409144865

Epoch: 6| Step: 7
Training loss: 2.195197594510087
Validation loss: 2.516470124433432

Epoch: 6| Step: 8
Training loss: 2.4019890251957117
Validation loss: 2.488334531685757

Epoch: 6| Step: 9
Training loss: 2.003208209852147
Validation loss: 2.5022764219356253

Epoch: 6| Step: 10
Training loss: 2.3342240086841035
Validation loss: 2.506624743194592

Epoch: 6| Step: 11
Training loss: 2.3486259095532653
Validation loss: 2.5146754398841566

Epoch: 6| Step: 12
Training loss: 2.76696331165008
Validation loss: 2.504270272091546

Epoch: 6| Step: 13
Training loss: 2.3917154056841943
Validation loss: 2.5156223707542673

Epoch: 224| Step: 0
Training loss: 2.6528771921628787
Validation loss: 2.470311748896312

Epoch: 6| Step: 1
Training loss: 2.5024745138816007
Validation loss: 2.5077340882360155

Epoch: 6| Step: 2
Training loss: 2.302183698534788
Validation loss: 2.487278158422744

Epoch: 6| Step: 3
Training loss: 2.2616581356906256
Validation loss: 2.4741633432069277

Epoch: 6| Step: 4
Training loss: 2.110926643755913
Validation loss: 2.486608260838283

Epoch: 6| Step: 5
Training loss: 2.8767359924214064
Validation loss: 2.5144534518307453

Epoch: 6| Step: 6
Training loss: 2.453557164703429
Validation loss: 2.4899606970057206

Epoch: 6| Step: 7
Training loss: 2.6462243659751468
Validation loss: 2.5015942033350025

Epoch: 6| Step: 8
Training loss: 2.2259469235408327
Validation loss: 2.471951991933719

Epoch: 6| Step: 9
Training loss: 2.232742246532977
Validation loss: 2.493833675250829

Epoch: 6| Step: 10
Training loss: 2.4217382577009134
Validation loss: 2.478330957513768

Epoch: 6| Step: 11
Training loss: 2.672089774439623
Validation loss: 2.48542329920916

Epoch: 6| Step: 12
Training loss: 2.3880067337490716
Validation loss: 2.534901513994748

Epoch: 6| Step: 13
Training loss: 2.6590976485290723
Validation loss: 2.5065780155360504

Epoch: 225| Step: 0
Training loss: 3.3677148251166615
Validation loss: 2.527440800232818

Epoch: 6| Step: 1
Training loss: 2.492482708992475
Validation loss: 2.4718915712760365

Epoch: 6| Step: 2
Training loss: 2.4678748788880442
Validation loss: 2.5087602478200957

Epoch: 6| Step: 3
Training loss: 2.0243141896794574
Validation loss: 2.497261445546709

Epoch: 6| Step: 4
Training loss: 2.20148661410256
Validation loss: 2.49438803789722

Epoch: 6| Step: 5
Training loss: 1.482755721425126
Validation loss: 2.4776839164228255

Epoch: 6| Step: 6
Training loss: 2.594295582209378
Validation loss: 2.501494290244599

Epoch: 6| Step: 7
Training loss: 2.5250130568062885
Validation loss: 2.5238159712676556

Epoch: 6| Step: 8
Training loss: 3.0000321068635105
Validation loss: 2.5003213655385546

Epoch: 6| Step: 9
Training loss: 2.248460879015441
Validation loss: 2.4739337889269293

Epoch: 6| Step: 10
Training loss: 2.705458146817224
Validation loss: 2.5083548891760685

Epoch: 6| Step: 11
Training loss: 2.224606910014273
Validation loss: 2.5099247623383256

Epoch: 6| Step: 12
Training loss: 1.9957377793832578
Validation loss: 2.5319458270823536

Epoch: 6| Step: 13
Training loss: 2.1709089806592834
Validation loss: 2.493276430114816

Epoch: 226| Step: 0
Training loss: 3.349014416230487
Validation loss: 2.4670768375425065

Epoch: 6| Step: 1
Training loss: 2.293657813441476
Validation loss: 2.5166317318868017

Epoch: 6| Step: 2
Training loss: 2.7646932810518887
Validation loss: 2.496972081852619

Epoch: 6| Step: 3
Training loss: 2.0875722358677367
Validation loss: 2.528181073364368

Epoch: 6| Step: 4
Training loss: 2.9485379879661533
Validation loss: 2.510177959056948

Epoch: 6| Step: 5
Training loss: 2.372700230275933
Validation loss: 2.5267735119583534

Epoch: 6| Step: 6
Training loss: 2.432381366216608
Validation loss: 2.505025181601079

Epoch: 6| Step: 7
Training loss: 2.420812361380715
Validation loss: 2.5425285748642077

Epoch: 6| Step: 8
Training loss: 1.57876430441567
Validation loss: 2.499154588847503

Epoch: 6| Step: 9
Training loss: 2.3260259190146044
Validation loss: 2.5199898719160867

Epoch: 6| Step: 10
Training loss: 2.263153306414787
Validation loss: 2.503887655673453

Epoch: 6| Step: 11
Training loss: 2.375837479552852
Validation loss: 2.5382870058904756

Epoch: 6| Step: 12
Training loss: 1.9210381895813726
Validation loss: 2.54437512150349

Epoch: 6| Step: 13
Training loss: 2.762143718822646
Validation loss: 2.495949848438327

Epoch: 227| Step: 0
Training loss: 3.1400252191782148
Validation loss: 2.5040171731777807

Epoch: 6| Step: 1
Training loss: 1.8169123118965025
Validation loss: 2.497524731162634

Epoch: 6| Step: 2
Training loss: 2.3217672289639033
Validation loss: 2.493822536934512

Epoch: 6| Step: 3
Training loss: 2.5478464157970726
Validation loss: 2.50479612825942

Epoch: 6| Step: 4
Training loss: 2.8581496985106782
Validation loss: 2.507596634020749

Epoch: 6| Step: 5
Training loss: 2.47702695901651
Validation loss: 2.4925306265733864

Epoch: 6| Step: 6
Training loss: 2.3247418496165113
Validation loss: 2.5049229081662903

Epoch: 6| Step: 7
Training loss: 2.508790678066091
Validation loss: 2.5151090302355543

Epoch: 6| Step: 8
Training loss: 2.24486889156851
Validation loss: 2.496257741611088

Epoch: 6| Step: 9
Training loss: 2.74216454651184
Validation loss: 2.4752327842369946

Epoch: 6| Step: 10
Training loss: 2.465148423312966
Validation loss: 2.504305408562728

Epoch: 6| Step: 11
Training loss: 1.841457946595466
Validation loss: 2.525630315016037

Epoch: 6| Step: 12
Training loss: 2.607678164341405
Validation loss: 2.5095011453060403

Epoch: 6| Step: 13
Training loss: 1.6423477573761434
Validation loss: 2.477984359419323

Epoch: 228| Step: 0
Training loss: 2.61932331446538
Validation loss: 2.4849448004327552

Epoch: 6| Step: 1
Training loss: 2.172524115074126
Validation loss: 2.503119401192063

Epoch: 6| Step: 2
Training loss: 2.160860412502519
Validation loss: 2.5043208877810827

Epoch: 6| Step: 3
Training loss: 2.2842690334973725
Validation loss: 2.532719742338125

Epoch: 6| Step: 4
Training loss: 2.5887550148392697
Validation loss: 2.492291457879616

Epoch: 6| Step: 5
Training loss: 1.967518194034508
Validation loss: 2.478877032981973

Epoch: 6| Step: 6
Training loss: 2.96080028850118
Validation loss: 2.483082767565996

Epoch: 6| Step: 7
Training loss: 2.885989870134263
Validation loss: 2.505491104184084

Epoch: 6| Step: 8
Training loss: 2.7139589034070366
Validation loss: 2.4898647187603773

Epoch: 6| Step: 9
Training loss: 2.203798015415438
Validation loss: 2.517999953548965

Epoch: 6| Step: 10
Training loss: 2.131143440871606
Validation loss: 2.516667659939697

Epoch: 6| Step: 11
Training loss: 2.51557837022486
Validation loss: 2.496919423920118

Epoch: 6| Step: 12
Training loss: 2.1142716827994796
Validation loss: 2.4867570606629186

Epoch: 6| Step: 13
Training loss: 2.4718398061530436
Validation loss: 2.498584111536943

Epoch: 229| Step: 0
Training loss: 1.9410426453667118
Validation loss: 2.5167763964874883

Epoch: 6| Step: 1
Training loss: 2.21866919142017
Validation loss: 2.5204399091380623

Epoch: 6| Step: 2
Training loss: 2.8228511638478753
Validation loss: 2.5097067495540957

Epoch: 6| Step: 3
Training loss: 2.9741051810776282
Validation loss: 2.523600753958363

Epoch: 6| Step: 4
Training loss: 1.4097627634984986
Validation loss: 2.4850603199209043

Epoch: 6| Step: 5
Training loss: 2.498087151197497
Validation loss: 2.51526674504169

Epoch: 6| Step: 6
Training loss: 1.7184626946039188
Validation loss: 2.4868123697867413

Epoch: 6| Step: 7
Training loss: 2.9297825505414274
Validation loss: 2.496224637794532

Epoch: 6| Step: 8
Training loss: 2.5302642032950953
Validation loss: 2.4804601189700004

Epoch: 6| Step: 9
Training loss: 2.066914313870749
Validation loss: 2.513502929460262

Epoch: 6| Step: 10
Training loss: 2.561206491155708
Validation loss: 2.4916890334065402

Epoch: 6| Step: 11
Training loss: 2.505683541911674
Validation loss: 2.4864121944295734

Epoch: 6| Step: 12
Training loss: 3.076606647103028
Validation loss: 2.4925538743114233

Epoch: 6| Step: 13
Training loss: 2.4383492579779946
Validation loss: 2.495606674241652

Epoch: 230| Step: 0
Training loss: 1.9927058125340547
Validation loss: 2.484728190527893

Epoch: 6| Step: 1
Training loss: 1.91603005935567
Validation loss: 2.520503809141032

Epoch: 6| Step: 2
Training loss: 2.346762387028537
Validation loss: 2.474561824193292

Epoch: 6| Step: 3
Training loss: 2.2652060285762516
Validation loss: 2.527025484129137

Epoch: 6| Step: 4
Training loss: 2.4395721626406046
Validation loss: 2.4837184994917303

Epoch: 6| Step: 5
Training loss: 2.0997963897453134
Validation loss: 2.5005593648271143

Epoch: 6| Step: 6
Training loss: 2.5535019856555956
Validation loss: 2.5022611913250743

Epoch: 6| Step: 7
Training loss: 2.9337177682153546
Validation loss: 2.5280414341101425

Epoch: 6| Step: 8
Training loss: 2.779767359186288
Validation loss: 2.519147854724309

Epoch: 6| Step: 9
Training loss: 2.6431529568113508
Validation loss: 2.4628672815040416

Epoch: 6| Step: 10
Training loss: 1.9222619512282957
Validation loss: 2.492998617956001

Epoch: 6| Step: 11
Training loss: 2.965822884938792
Validation loss: 2.4998730740064636

Epoch: 6| Step: 12
Training loss: 2.7901371613835577
Validation loss: 2.512978730998557

Epoch: 6| Step: 13
Training loss: 1.8038659806215376
Validation loss: 2.4779861885329546

Epoch: 231| Step: 0
Training loss: 2.423681065649831
Validation loss: 2.4821179100592055

Epoch: 6| Step: 1
Training loss: 3.0382530880066962
Validation loss: 2.481887369600859

Epoch: 6| Step: 2
Training loss: 2.5907393297982293
Validation loss: 2.486270080888524

Epoch: 6| Step: 3
Training loss: 2.354291985701172
Validation loss: 2.493653718788671

Epoch: 6| Step: 4
Training loss: 2.7930687946461283
Validation loss: 2.488966808644272

Epoch: 6| Step: 5
Training loss: 2.2292800113941857
Validation loss: 2.458951035765791

Epoch: 6| Step: 6
Training loss: 1.9426335651917526
Validation loss: 2.4758849462724317

Epoch: 6| Step: 7
Training loss: 2.8668194360465122
Validation loss: 2.48986600476853

Epoch: 6| Step: 8
Training loss: 2.5802778098883836
Validation loss: 2.5155351016756335

Epoch: 6| Step: 9
Training loss: 2.1773014476486954
Validation loss: 2.5170955335597056

Epoch: 6| Step: 10
Training loss: 1.9542064266863972
Validation loss: 2.5172011906783602

Epoch: 6| Step: 11
Training loss: 2.3080877533796293
Validation loss: 2.507593314449116

Epoch: 6| Step: 12
Training loss: 2.6308478657471435
Validation loss: 2.4840198215745777

Epoch: 6| Step: 13
Training loss: 1.747727007876596
Validation loss: 2.4854091700870695

Epoch: 232| Step: 0
Training loss: 2.4748903038298913
Validation loss: 2.5257629267804966

Epoch: 6| Step: 1
Training loss: 2.543055379068797
Validation loss: 2.4756358483272884

Epoch: 6| Step: 2
Training loss: 2.474590876509391
Validation loss: 2.5254500844569816

Epoch: 6| Step: 3
Training loss: 2.797099866298724
Validation loss: 2.5012943782962

Epoch: 6| Step: 4
Training loss: 2.5279560084499018
Validation loss: 2.4995184639713823

Epoch: 6| Step: 5
Training loss: 2.2889893816313767
Validation loss: 2.5150602890659726

Epoch: 6| Step: 6
Training loss: 2.025277144693383
Validation loss: 2.528115111144746

Epoch: 6| Step: 7
Training loss: 2.68037410203189
Validation loss: 2.489013353996617

Epoch: 6| Step: 8
Training loss: 2.363479782466714
Validation loss: 2.507302086977863

Epoch: 6| Step: 9
Training loss: 2.3214222729775638
Validation loss: 2.516562599285658

Epoch: 6| Step: 10
Training loss: 2.5820407607556968
Validation loss: 2.484875236078513

Epoch: 6| Step: 11
Training loss: 2.203112446634227
Validation loss: 2.529918914676485

Epoch: 6| Step: 12
Training loss: 2.303271773693863
Validation loss: 2.4860697727735093

Epoch: 6| Step: 13
Training loss: 2.1406879276576922
Validation loss: 2.510187275323309

Epoch: 233| Step: 0
Training loss: 2.435413151965013
Validation loss: 2.4877716040671793

Epoch: 6| Step: 1
Training loss: 2.490046044502281
Validation loss: 2.4862938222930717

Epoch: 6| Step: 2
Training loss: 3.355068977886224
Validation loss: 2.4744756090254802

Epoch: 6| Step: 3
Training loss: 2.0839878071521643
Validation loss: 2.481048696538221

Epoch: 6| Step: 4
Training loss: 2.8980632036476406
Validation loss: 2.4924678402435627

Epoch: 6| Step: 5
Training loss: 2.25172104181368
Validation loss: 2.5025722714233054

Epoch: 6| Step: 6
Training loss: 2.8059500824994226
Validation loss: 2.513775796460967

Epoch: 6| Step: 7
Training loss: 2.2246858953723887
Validation loss: 2.495582187289335

Epoch: 6| Step: 8
Training loss: 2.1649815780173043
Validation loss: 2.4817668163822844

Epoch: 6| Step: 9
Training loss: 2.464449263016569
Validation loss: 2.493963522658021

Epoch: 6| Step: 10
Training loss: 2.3613740649933033
Validation loss: 2.5155358945534982

Epoch: 6| Step: 11
Training loss: 1.8674420937340217
Validation loss: 2.5106726629805456

Epoch: 6| Step: 12
Training loss: 2.2343918592977365
Validation loss: 2.509548649059968

Epoch: 6| Step: 13
Training loss: 1.8924665703586223
Validation loss: 2.538809194242848

Epoch: 234| Step: 0
Training loss: 2.7831375060795294
Validation loss: 2.5095871041617337

Epoch: 6| Step: 1
Training loss: 2.844221977219901
Validation loss: 2.5241180846213163

Epoch: 6| Step: 2
Training loss: 1.762544628687522
Validation loss: 2.4702273811137774

Epoch: 6| Step: 3
Training loss: 2.4317392597339755
Validation loss: 2.4787522904911268

Epoch: 6| Step: 4
Training loss: 2.4652395278279613
Validation loss: 2.5116245075582553

Epoch: 6| Step: 5
Training loss: 2.4627378629641536
Validation loss: 2.4899279959574665

Epoch: 6| Step: 6
Training loss: 2.5267521963346797
Validation loss: 2.47380293577742

Epoch: 6| Step: 7
Training loss: 2.42990945372623
Validation loss: 2.4935045049355775

Epoch: 6| Step: 8
Training loss: 2.3812162461979858
Validation loss: 2.5160625257917197

Epoch: 6| Step: 9
Training loss: 2.932956672096106
Validation loss: 2.4803853147628896

Epoch: 6| Step: 10
Training loss: 2.4659832286836765
Validation loss: 2.514746063309428

Epoch: 6| Step: 11
Training loss: 2.209664237636755
Validation loss: 2.5114007599678723

Epoch: 6| Step: 12
Training loss: 2.1929917201465554
Validation loss: 2.544940735644104

Epoch: 6| Step: 13
Training loss: 1.7597328377737784
Validation loss: 2.532030667578749

Epoch: 235| Step: 0
Training loss: 2.5314973310034206
Validation loss: 2.4844507267909326

Epoch: 6| Step: 1
Training loss: 2.0151176109729843
Validation loss: 2.492564946300852

Epoch: 6| Step: 2
Training loss: 2.382191061062023
Validation loss: 2.491373131791326

Epoch: 6| Step: 3
Training loss: 2.0866051223421436
Validation loss: 2.509883525982755

Epoch: 6| Step: 4
Training loss: 2.473431265383952
Validation loss: 2.4930010684798756

Epoch: 6| Step: 5
Training loss: 2.0391646904020577
Validation loss: 2.49005247921593

Epoch: 6| Step: 6
Training loss: 2.5864666630742286
Validation loss: 2.5246039885459313

Epoch: 6| Step: 7
Training loss: 2.6394566767252168
Validation loss: 2.482955678878904

Epoch: 6| Step: 8
Training loss: 2.529959078672677
Validation loss: 2.4781583488440586

Epoch: 6| Step: 9
Training loss: 2.3491841705994485
Validation loss: 2.5053367463299794

Epoch: 6| Step: 10
Training loss: 2.7611355307369285
Validation loss: 2.4859267801008396

Epoch: 6| Step: 11
Training loss: 2.275898757975665
Validation loss: 2.4994042086538695

Epoch: 6| Step: 12
Training loss: 2.202431860572278
Validation loss: 2.502404897964249

Epoch: 6| Step: 13
Training loss: 2.695427579772655
Validation loss: 2.4879446411302197

Epoch: 236| Step: 0
Training loss: 2.6957327252520553
Validation loss: 2.5002998766963342

Epoch: 6| Step: 1
Training loss: 3.2347094966393697
Validation loss: 2.5397967320870554

Epoch: 6| Step: 2
Training loss: 2.784794638165948
Validation loss: 2.4867415432487525

Epoch: 6| Step: 3
Training loss: 1.8289816389877713
Validation loss: 2.5233771549558965

Epoch: 6| Step: 4
Training loss: 1.8005116027059869
Validation loss: 2.5074279641636656

Epoch: 6| Step: 5
Training loss: 2.109529616729147
Validation loss: 2.5043258198999974

Epoch: 6| Step: 6
Training loss: 2.0707212800297077
Validation loss: 2.522942388832962

Epoch: 6| Step: 7
Training loss: 2.650694299109949
Validation loss: 2.5182663931470843

Epoch: 6| Step: 8
Training loss: 2.960923650301547
Validation loss: 2.4730234766851438

Epoch: 6| Step: 9
Training loss: 2.129602832748455
Validation loss: 2.517377856836196

Epoch: 6| Step: 10
Training loss: 2.3757762644200198
Validation loss: 2.4748852664360808

Epoch: 6| Step: 11
Training loss: 2.6583945200544203
Validation loss: 2.472976137963453

Epoch: 6| Step: 12
Training loss: 1.9895912156939188
Validation loss: 2.4765667772810938

Epoch: 6| Step: 13
Training loss: 2.4237344802115612
Validation loss: 2.48260466444013

Epoch: 237| Step: 0
Training loss: 2.462453417652087
Validation loss: 2.502498807899547

Epoch: 6| Step: 1
Training loss: 2.7611022002010057
Validation loss: 2.5199605443925455

Epoch: 6| Step: 2
Training loss: 2.7491484970998648
Validation loss: 2.478378392560013

Epoch: 6| Step: 3
Training loss: 1.9806777272017786
Validation loss: 2.4822268019647202

Epoch: 6| Step: 4
Training loss: 2.3036071314109643
Validation loss: 2.477698482779146

Epoch: 6| Step: 5
Training loss: 2.2533000481233207
Validation loss: 2.5084853625569328

Epoch: 6| Step: 6
Training loss: 2.373635753515828
Validation loss: 2.517976096712963

Epoch: 6| Step: 7
Training loss: 2.0840651434822837
Validation loss: 2.4913058471956537

Epoch: 6| Step: 8
Training loss: 2.607621203172232
Validation loss: 2.4946012162002695

Epoch: 6| Step: 9
Training loss: 2.4185907552969077
Validation loss: 2.517750911743024

Epoch: 6| Step: 10
Training loss: 1.9868393261764732
Validation loss: 2.488712288331955

Epoch: 6| Step: 11
Training loss: 2.4324670329511235
Validation loss: 2.508651877626332

Epoch: 6| Step: 12
Training loss: 2.556085886268965
Validation loss: 2.519319962938731

Epoch: 6| Step: 13
Training loss: 2.9299907069661013
Validation loss: 2.513618358330453

Epoch: 238| Step: 0
Training loss: 2.390315416024826
Validation loss: 2.5107977565150277

Epoch: 6| Step: 1
Training loss: 2.13711259688628
Validation loss: 2.4801550639291943

Epoch: 6| Step: 2
Training loss: 2.37165235195634
Validation loss: 2.476144535084651

Epoch: 6| Step: 3
Training loss: 2.378857140746695
Validation loss: 2.4941179357978673

Epoch: 6| Step: 4
Training loss: 2.436043915739538
Validation loss: 2.5219551598130057

Epoch: 6| Step: 5
Training loss: 2.4856247547543764
Validation loss: 2.508823992625891

Epoch: 6| Step: 6
Training loss: 2.554755347047984
Validation loss: 2.4982818134103457

Epoch: 6| Step: 7
Training loss: 2.5822296758866243
Validation loss: 2.526331597297608

Epoch: 6| Step: 8
Training loss: 2.6452010192633777
Validation loss: 2.528744302928062

Epoch: 6| Step: 9
Training loss: 2.4426958508094634
Validation loss: 2.5082037646725346

Epoch: 6| Step: 10
Training loss: 2.287881696363511
Validation loss: 2.4723185548552338

Epoch: 6| Step: 11
Training loss: 2.4141711361832394
Validation loss: 2.5281618301250273

Epoch: 6| Step: 12
Training loss: 2.3653826489896637
Validation loss: 2.5139348390314944

Epoch: 6| Step: 13
Training loss: 2.3209477335358977
Validation loss: 2.496056182905748

Epoch: 239| Step: 0
Training loss: 2.4102364747778102
Validation loss: 2.501015707026146

Epoch: 6| Step: 1
Training loss: 2.137403082184074
Validation loss: 2.4947772518356963

Epoch: 6| Step: 2
Training loss: 2.2439388652572427
Validation loss: 2.5036759822807473

Epoch: 6| Step: 3
Training loss: 2.3903678805638164
Validation loss: 2.4921885410146833

Epoch: 6| Step: 4
Training loss: 2.336993026833992
Validation loss: 2.5096120704461753

Epoch: 6| Step: 5
Training loss: 2.835740263834667
Validation loss: 2.4775568063785367

Epoch: 6| Step: 6
Training loss: 1.9051404757031634
Validation loss: 2.4895972115364153

Epoch: 6| Step: 7
Training loss: 2.52601496626648
Validation loss: 2.5191446775820476

Epoch: 6| Step: 8
Training loss: 2.429567978056502
Validation loss: 2.508072615307937

Epoch: 6| Step: 9
Training loss: 2.5199454979830764
Validation loss: 2.5054934688185875

Epoch: 6| Step: 10
Training loss: 2.965142236292437
Validation loss: 2.5220136019311865

Epoch: 6| Step: 11
Training loss: 2.8761824788337567
Validation loss: 2.4962571901154833

Epoch: 6| Step: 12
Training loss: 1.823573323007039
Validation loss: 2.5324949982766056

Epoch: 6| Step: 13
Training loss: 1.7839749557550495
Validation loss: 2.5009170532001677

Epoch: 240| Step: 0
Training loss: 3.494404270552377
Validation loss: 2.480341097404013

Epoch: 6| Step: 1
Training loss: 2.2887519912252716
Validation loss: 2.522474930226645

Epoch: 6| Step: 2
Training loss: 2.0536765741002894
Validation loss: 2.498793421572721

Epoch: 6| Step: 3
Training loss: 2.661163453091949
Validation loss: 2.5081806854982314

Epoch: 6| Step: 4
Training loss: 2.711436728646525
Validation loss: 2.5193199527628076

Epoch: 6| Step: 5
Training loss: 2.0258421288878257
Validation loss: 2.501876130158182

Epoch: 6| Step: 6
Training loss: 2.2482977891982134
Validation loss: 2.511327340838632

Epoch: 6| Step: 7
Training loss: 2.600936126910288
Validation loss: 2.5139920088454777

Epoch: 6| Step: 8
Training loss: 2.0064931609253214
Validation loss: 2.5144949191055055

Epoch: 6| Step: 9
Training loss: 1.6385237543865407
Validation loss: 2.497812797156652

Epoch: 6| Step: 10
Training loss: 2.314912517039867
Validation loss: 2.4879220705961864

Epoch: 6| Step: 11
Training loss: 2.2359534603591573
Validation loss: 2.498343193533145

Epoch: 6| Step: 12
Training loss: 2.6982739971659178
Validation loss: 2.4874499940867523

Epoch: 6| Step: 13
Training loss: 2.5169316091297795
Validation loss: 2.467087247634852

Epoch: 241| Step: 0
Training loss: 2.9116947485259765
Validation loss: 2.4804801095100544

Epoch: 6| Step: 1
Training loss: 1.7342305853577566
Validation loss: 2.4923315066724863

Epoch: 6| Step: 2
Training loss: 1.8896194179780765
Validation loss: 2.5192612146141715

Epoch: 6| Step: 3
Training loss: 2.4642816014383877
Validation loss: 2.4807158724534015

Epoch: 6| Step: 4
Training loss: 1.8259273263313907
Validation loss: 2.5064548613591278

Epoch: 6| Step: 5
Training loss: 2.491419563245924
Validation loss: 2.475687059806055

Epoch: 6| Step: 6
Training loss: 2.691319789521984
Validation loss: 2.4875300150368416

Epoch: 6| Step: 7
Training loss: 2.2370892025074873
Validation loss: 2.528529548693814

Epoch: 6| Step: 8
Training loss: 2.3392673604030954
Validation loss: 2.49186899698019

Epoch: 6| Step: 9
Training loss: 2.623604721547115
Validation loss: 2.485300083917852

Epoch: 6| Step: 10
Training loss: 2.7121426324949396
Validation loss: 2.481437867797496

Epoch: 6| Step: 11
Training loss: 2.1575319100823704
Validation loss: 2.4955853646382833

Epoch: 6| Step: 12
Training loss: 2.363423291185968
Validation loss: 2.4790274571579043

Epoch: 6| Step: 13
Training loss: 2.7887547427367503
Validation loss: 2.485699954093371

Epoch: 242| Step: 0
Training loss: 2.4504782618609426
Validation loss: 2.49052532133119

Epoch: 6| Step: 1
Training loss: 2.009217716783091
Validation loss: 2.492525183590696

Epoch: 6| Step: 2
Training loss: 2.214072010609425
Validation loss: 2.5218069999124992

Epoch: 6| Step: 3
Training loss: 2.63660255458673
Validation loss: 2.4918409454979114

Epoch: 6| Step: 4
Training loss: 2.488615435761294
Validation loss: 2.521614052118344

Epoch: 6| Step: 5
Training loss: 1.899175429860288
Validation loss: 2.51215887821695

Epoch: 6| Step: 6
Training loss: 2.336865499129753
Validation loss: 2.507923932226223

Epoch: 6| Step: 7
Training loss: 2.5716591875417074
Validation loss: 2.517146637893501

Epoch: 6| Step: 8
Training loss: 2.518598800929585
Validation loss: 2.517207268773706

Epoch: 6| Step: 9
Training loss: 2.4717207791798597
Validation loss: 2.5264255432860065

Epoch: 6| Step: 10
Training loss: 2.4148645148962653
Validation loss: 2.5039310558718855

Epoch: 6| Step: 11
Training loss: 2.43760720041712
Validation loss: 2.474781946326007

Epoch: 6| Step: 12
Training loss: 2.447168005772003
Validation loss: 2.526658825615268

Epoch: 6| Step: 13
Training loss: 2.8839904528815645
Validation loss: 2.4716820875931758

Epoch: 243| Step: 0
Training loss: 2.439696080713243
Validation loss: 2.501158680615762

Epoch: 6| Step: 1
Training loss: 2.3401320953253424
Validation loss: 2.517690758277208

Epoch: 6| Step: 2
Training loss: 2.1551500915160573
Validation loss: 2.526117449326589

Epoch: 6| Step: 3
Training loss: 2.756540150843163
Validation loss: 2.5334763063638617

Epoch: 6| Step: 4
Training loss: 2.3224108933682466
Validation loss: 2.469804213935871

Epoch: 6| Step: 5
Training loss: 2.945470992865489
Validation loss: 2.532557189583649

Epoch: 6| Step: 6
Training loss: 2.5202744445008856
Validation loss: 2.48765375778583

Epoch: 6| Step: 7
Training loss: 2.8856043748818725
Validation loss: 2.515419557947084

Epoch: 6| Step: 8
Training loss: 2.814184574442615
Validation loss: 2.495138856600954

Epoch: 6| Step: 9
Training loss: 1.8113142936463102
Validation loss: 2.522320814884401

Epoch: 6| Step: 10
Training loss: 1.9348921914834363
Validation loss: 2.513483982847002

Epoch: 6| Step: 11
Training loss: 1.960907954871112
Validation loss: 2.503376611387629

Epoch: 6| Step: 12
Training loss: 2.287760185078128
Validation loss: 2.47978336863741

Epoch: 6| Step: 13
Training loss: 2.2420035363202615
Validation loss: 2.5167354496378866

Epoch: 244| Step: 0
Training loss: 1.927125225814625
Validation loss: 2.514534044858701

Epoch: 6| Step: 1
Training loss: 2.783990517046552
Validation loss: 2.5131448198162825

Epoch: 6| Step: 2
Training loss: 2.456527973782127
Validation loss: 2.4759898138371996

Epoch: 6| Step: 3
Training loss: 2.6221475998269663
Validation loss: 2.4969609924438934

Epoch: 6| Step: 4
Training loss: 2.512833651883095
Validation loss: 2.502892397135685

Epoch: 6| Step: 5
Training loss: 2.7458429127025847
Validation loss: 2.489724168171976

Epoch: 6| Step: 6
Training loss: 2.444585820165314
Validation loss: 2.4877427355627955

Epoch: 6| Step: 7
Training loss: 2.217930924649669
Validation loss: 2.508120680695425

Epoch: 6| Step: 8
Training loss: 2.0125631097411376
Validation loss: 2.498917389336328

Epoch: 6| Step: 9
Training loss: 1.6721109954550943
Validation loss: 2.4867916384164532

Epoch: 6| Step: 10
Training loss: 3.085000661296557
Validation loss: 2.5059535027950086

Epoch: 6| Step: 11
Training loss: 1.7975940095089493
Validation loss: 2.50151958992038

Epoch: 6| Step: 12
Training loss: 2.9257260000311547
Validation loss: 2.5033882438068935

Epoch: 6| Step: 13
Training loss: 2.0118479270571132
Validation loss: 2.485237496590264

Epoch: 245| Step: 0
Training loss: 1.4470059757807887
Validation loss: 2.5111498314614664

Epoch: 6| Step: 1
Training loss: 2.3417999293010734
Validation loss: 2.5048906009980523

Epoch: 6| Step: 2
Training loss: 2.1785045408035666
Validation loss: 2.4890460577917004

Epoch: 6| Step: 3
Training loss: 2.564121756604087
Validation loss: 2.5266657875350207

Epoch: 6| Step: 4
Training loss: 2.4450283677653406
Validation loss: 2.498706882098655

Epoch: 6| Step: 5
Training loss: 1.8947896564872135
Validation loss: 2.5281685115825296

Epoch: 6| Step: 6
Training loss: 2.590115678184933
Validation loss: 2.465176716135511

Epoch: 6| Step: 7
Training loss: 2.4316027780061704
Validation loss: 2.5178631066002772

Epoch: 6| Step: 8
Training loss: 2.55721584811086
Validation loss: 2.5043365480952264

Epoch: 6| Step: 9
Training loss: 3.0220777031371693
Validation loss: 2.4947526570638074

Epoch: 6| Step: 10
Training loss: 2.4028474605307557
Validation loss: 2.5130149270384163

Epoch: 6| Step: 11
Training loss: 3.06006385287814
Validation loss: 2.4978522201364193

Epoch: 6| Step: 12
Training loss: 2.241393264302092
Validation loss: 2.4838055560226477

Epoch: 6| Step: 13
Training loss: 1.8169745755933573
Validation loss: 2.4959969969210243

Epoch: 246| Step: 0
Training loss: 1.9909649856531078
Validation loss: 2.4910891436038987

Epoch: 6| Step: 1
Training loss: 2.898564173971293
Validation loss: 2.516894545571135

Epoch: 6| Step: 2
Training loss: 2.711499422523849
Validation loss: 2.501619291405485

Epoch: 6| Step: 3
Training loss: 2.2688718484572195
Validation loss: 2.4858543958320243

Epoch: 6| Step: 4
Training loss: 2.134338056878535
Validation loss: 2.5085786999590325

Epoch: 6| Step: 5
Training loss: 1.784941946309102
Validation loss: 2.498807497586428

Epoch: 6| Step: 6
Training loss: 2.5377313029284716
Validation loss: 2.4907183214510593

Epoch: 6| Step: 7
Training loss: 2.270479880540555
Validation loss: 2.5171803327596782

Epoch: 6| Step: 8
Training loss: 1.4000156810427258
Validation loss: 2.50123156904206

Epoch: 6| Step: 9
Training loss: 2.295969258996478
Validation loss: 2.5309827028663974

Epoch: 6| Step: 10
Training loss: 2.6667495555711023
Validation loss: 2.470897958740359

Epoch: 6| Step: 11
Training loss: 2.616528966240725
Validation loss: 2.528477306158656

Epoch: 6| Step: 12
Training loss: 3.001535022933513
Validation loss: 2.5359080539923387

Epoch: 6| Step: 13
Training loss: 2.5256661886525476
Validation loss: 2.492112930534432

Epoch: 247| Step: 0
Training loss: 2.3794235393682452
Validation loss: 2.4760420368075975

Epoch: 6| Step: 1
Training loss: 1.7826797369052465
Validation loss: 2.486299978007859

Epoch: 6| Step: 2
Training loss: 1.9314372049108073
Validation loss: 2.5192915383722196

Epoch: 6| Step: 3
Training loss: 2.0232829031192567
Validation loss: 2.4675674732030055

Epoch: 6| Step: 4
Training loss: 2.4986301483829503
Validation loss: 2.5163612946761518

Epoch: 6| Step: 5
Training loss: 3.0250140670575396
Validation loss: 2.5065191363004664

Epoch: 6| Step: 6
Training loss: 2.6583868071181374
Validation loss: 2.5029071885925873

Epoch: 6| Step: 7
Training loss: 2.234017083371653
Validation loss: 2.4936064725394176

Epoch: 6| Step: 8
Training loss: 1.9745882450108947
Validation loss: 2.5081814847893944

Epoch: 6| Step: 9
Training loss: 2.672997489850956
Validation loss: 2.501355119774219

Epoch: 6| Step: 10
Training loss: 2.934933454288788
Validation loss: 2.490914761631832

Epoch: 6| Step: 11
Training loss: 1.9165027244224062
Validation loss: 2.530656399862659

Epoch: 6| Step: 12
Training loss: 2.859801880703452
Validation loss: 2.49800676440959

Epoch: 6| Step: 13
Training loss: 2.0915365333147853
Validation loss: 2.4886354102385546

Epoch: 248| Step: 0
Training loss: 1.6169482067921923
Validation loss: 2.4968284609064857

Epoch: 6| Step: 1
Training loss: 2.7223027135233138
Validation loss: 2.509639362478772

Epoch: 6| Step: 2
Training loss: 2.3758264408749734
Validation loss: 2.5098844013379735

Epoch: 6| Step: 3
Training loss: 2.9638586606652466
Validation loss: 2.5151444199445407

Epoch: 6| Step: 4
Training loss: 1.8945068357801909
Validation loss: 2.496946501497085

Epoch: 6| Step: 5
Training loss: 2.7652400551694645
Validation loss: 2.492086883673026

Epoch: 6| Step: 6
Training loss: 1.2854576337191566
Validation loss: 2.506061534450947

Epoch: 6| Step: 7
Training loss: 3.0176072005071726
Validation loss: 2.509039372402733

Epoch: 6| Step: 8
Training loss: 1.3617446240381497
Validation loss: 2.4792016194844755

Epoch: 6| Step: 9
Training loss: 2.743584258128665
Validation loss: 2.5051008239836143

Epoch: 6| Step: 10
Training loss: 2.394013042290136
Validation loss: 2.5122971838716586

Epoch: 6| Step: 11
Training loss: 2.515684328505076
Validation loss: 2.504830425266104

Epoch: 6| Step: 12
Training loss: 2.413612792956847
Validation loss: 2.522791191083403

Epoch: 6| Step: 13
Training loss: 2.7249583249886236
Validation loss: 2.504302571907023

Epoch: 249| Step: 0
Training loss: 1.3410813201893612
Validation loss: 2.492390311693297

Epoch: 6| Step: 1
Training loss: 1.8715442600912404
Validation loss: 2.494248155381449

Epoch: 6| Step: 2
Training loss: 2.852711401685876
Validation loss: 2.510404887423025

Epoch: 6| Step: 3
Training loss: 2.3551382462405535
Validation loss: 2.462648475176485

Epoch: 6| Step: 4
Training loss: 2.888003918822105
Validation loss: 2.485060146608555

Epoch: 6| Step: 5
Training loss: 2.750730764223146
Validation loss: 2.473901064630333

Epoch: 6| Step: 6
Training loss: 2.681385625507951
Validation loss: 2.52040159012578

Epoch: 6| Step: 7
Training loss: 2.1345992097618507
Validation loss: 2.5339943185681673

Epoch: 6| Step: 8
Training loss: 2.9822874107601396
Validation loss: 2.515248176602544

Epoch: 6| Step: 9
Training loss: 2.084299994953611
Validation loss: 2.486394887508481

Epoch: 6| Step: 10
Training loss: 2.1065700389736777
Validation loss: 2.5009983064025207

Epoch: 6| Step: 11
Training loss: 2.1585780305735316
Validation loss: 2.5111594054724424

Epoch: 6| Step: 12
Training loss: 2.403068123133205
Validation loss: 2.4724289100561943

Epoch: 6| Step: 13
Training loss: 1.8867770673691349
Validation loss: 2.484015438440719

Epoch: 250| Step: 0
Training loss: 2.4320165136805594
Validation loss: 2.49224451754434

Epoch: 6| Step: 1
Training loss: 2.703861555178133
Validation loss: 2.5438502705729467

Epoch: 6| Step: 2
Training loss: 2.173173694520338
Validation loss: 2.4874639261043376

Epoch: 6| Step: 3
Training loss: 2.177361344347475
Validation loss: 2.5153596677360825

Epoch: 6| Step: 4
Training loss: 2.7272577574347974
Validation loss: 2.510524851757497

Epoch: 6| Step: 5
Training loss: 2.359381568343765
Validation loss: 2.4861649282296727

Epoch: 6| Step: 6
Training loss: 2.729020374444295
Validation loss: 2.4834307868331322

Epoch: 6| Step: 7
Training loss: 2.013035967047401
Validation loss: 2.4746604005296593

Epoch: 6| Step: 8
Training loss: 1.8893820089348383
Validation loss: 2.4981600840880227

Epoch: 6| Step: 9
Training loss: 2.5774607409531547
Validation loss: 2.5021079702826703

Epoch: 6| Step: 10
Training loss: 2.260846168977508
Validation loss: 2.5016824629154577

Epoch: 6| Step: 11
Training loss: 2.5646618353581103
Validation loss: 2.4990593709599374

Epoch: 6| Step: 12
Training loss: 2.407277866149547
Validation loss: 2.491746819592834

Epoch: 6| Step: 13
Training loss: 1.8620018235186406
Validation loss: 2.5079855649764

Epoch: 251| Step: 0
Training loss: 2.3336089402870703
Validation loss: 2.4697463337040175

Epoch: 6| Step: 1
Training loss: 2.9815129641952023
Validation loss: 2.5134210334940357

Epoch: 6| Step: 2
Training loss: 2.109388450297106
Validation loss: 2.5111207314710304

Epoch: 6| Step: 3
Training loss: 1.862319090076878
Validation loss: 2.4867996897548292

Epoch: 6| Step: 4
Training loss: 2.9654763894987943
Validation loss: 2.4844894738813768

Epoch: 6| Step: 5
Training loss: 2.065486017996624
Validation loss: 2.5194116178465658

Epoch: 6| Step: 6
Training loss: 1.8008538022599885
Validation loss: 2.48217171548515

Epoch: 6| Step: 7
Training loss: 2.7586861326207823
Validation loss: 2.47447808100115

Epoch: 6| Step: 8
Training loss: 3.010030983546784
Validation loss: 2.5468232822558727

Epoch: 6| Step: 9
Training loss: 1.559888717643629
Validation loss: 2.4999818093653268

Epoch: 6| Step: 10
Training loss: 2.075525823863949
Validation loss: 2.4992947814311224

Epoch: 6| Step: 11
Training loss: 2.1296423523134322
Validation loss: 2.5124362676058603

Epoch: 6| Step: 12
Training loss: 2.802663598845037
Validation loss: 2.5136475385344554

Epoch: 6| Step: 13
Training loss: 2.4143889863796324
Validation loss: 2.457621745853946

Epoch: 252| Step: 0
Training loss: 2.145469918695573
Validation loss: 2.513193278851866

Epoch: 6| Step: 1
Training loss: 3.0108937520133594
Validation loss: 2.5144604291921016

Epoch: 6| Step: 2
Training loss: 2.0872889794691765
Validation loss: 2.55353363763701

Epoch: 6| Step: 3
Training loss: 2.5791869779494703
Validation loss: 2.5120120229359544

Epoch: 6| Step: 4
Training loss: 2.527582785196748
Validation loss: 2.4861498608340815

Epoch: 6| Step: 5
Training loss: 3.2929966971771516
Validation loss: 2.494220931851943

Epoch: 6| Step: 6
Training loss: 2.1277296822238614
Validation loss: 2.491130499653995

Epoch: 6| Step: 7
Training loss: 1.842904689139556
Validation loss: 2.491541975844573

Epoch: 6| Step: 8
Training loss: 2.4187076653612554
Validation loss: 2.469811671907662

Epoch: 6| Step: 9
Training loss: 2.918634749757193
Validation loss: 2.5242492016433697

Epoch: 6| Step: 10
Training loss: 1.66767848613779
Validation loss: 2.508537922822407

Epoch: 6| Step: 11
Training loss: 2.0245404275337417
Validation loss: 2.5018014283158734

Epoch: 6| Step: 12
Training loss: 2.046018464930825
Validation loss: 2.5070870298639547

Epoch: 6| Step: 13
Training loss: 2.2367555967674275
Validation loss: 2.500280447580811

Epoch: 253| Step: 0
Training loss: 2.0521360154981774
Validation loss: 2.497872413767982

Epoch: 6| Step: 1
Training loss: 1.9703763269285537
Validation loss: 2.4882715271746787

Epoch: 6| Step: 2
Training loss: 2.0956394153876214
Validation loss: 2.5123371836574817

Epoch: 6| Step: 3
Training loss: 2.650786132088462
Validation loss: 2.5072227901243913

Epoch: 6| Step: 4
Training loss: 2.7198186067795365
Validation loss: 2.4907434264350603

Epoch: 6| Step: 5
Training loss: 2.699668129198939
Validation loss: 2.4857216660972123

Epoch: 6| Step: 6
Training loss: 2.1253732465676096
Validation loss: 2.4996747574433487

Epoch: 6| Step: 7
Training loss: 2.8204860475354314
Validation loss: 2.4990383975275554

Epoch: 6| Step: 8
Training loss: 2.7409546952843935
Validation loss: 2.48875524755501

Epoch: 6| Step: 9
Training loss: 1.8788076521605768
Validation loss: 2.497420300792176

Epoch: 6| Step: 10
Training loss: 2.2617594397381495
Validation loss: 2.491110566794542

Epoch: 6| Step: 11
Training loss: 2.5074325701545934
Validation loss: 2.484141938333305

Epoch: 6| Step: 12
Training loss: 1.9172438360640671
Validation loss: 2.501862959305618

Epoch: 6| Step: 13
Training loss: 2.989851156504169
Validation loss: 2.4800681955684554

Epoch: 254| Step: 0
Training loss: 2.4072128945479117
Validation loss: 2.4958271980227353

Epoch: 6| Step: 1
Training loss: 2.4000105778143155
Validation loss: 2.5201760603605217

Epoch: 6| Step: 2
Training loss: 2.2724899991762784
Validation loss: 2.4945431641892726

Epoch: 6| Step: 3
Training loss: 2.0975353127963627
Validation loss: 2.5087996203741985

Epoch: 6| Step: 4
Training loss: 2.425932211486249
Validation loss: 2.5234183618024315

Epoch: 6| Step: 5
Training loss: 2.479568726664269
Validation loss: 2.5078152580605133

Epoch: 6| Step: 6
Training loss: 2.7254064344330593
Validation loss: 2.48729188320234

Epoch: 6| Step: 7
Training loss: 1.8895090135499162
Validation loss: 2.5055360553914166

Epoch: 6| Step: 8
Training loss: 2.0376085966224684
Validation loss: 2.519981849303592

Epoch: 6| Step: 9
Training loss: 1.7454577488851772
Validation loss: 2.4876834084671406

Epoch: 6| Step: 10
Training loss: 2.691622566200431
Validation loss: 2.485257325949592

Epoch: 6| Step: 11
Training loss: 2.4681688421416985
Validation loss: 2.492428089355665

Epoch: 6| Step: 12
Training loss: 2.638038768249179
Validation loss: 2.4906371739398616

Epoch: 6| Step: 13
Training loss: 2.999033136330377
Validation loss: 2.5014819326488777

Epoch: 255| Step: 0
Training loss: 2.663864710113226
Validation loss: 2.518532560259635

Epoch: 6| Step: 1
Training loss: 2.887182051422993
Validation loss: 2.477992541795549

Epoch: 6| Step: 2
Training loss: 2.7859786051457895
Validation loss: 2.460637525020107

Epoch: 6| Step: 3
Training loss: 2.2872329013997157
Validation loss: 2.4760450321557226

Epoch: 6| Step: 4
Training loss: 1.9709486416183803
Validation loss: 2.4737895382527415

Epoch: 6| Step: 5
Training loss: 2.25671592403204
Validation loss: 2.5038977847403263

Epoch: 6| Step: 6
Training loss: 2.490010234244889
Validation loss: 2.517408888640081

Epoch: 6| Step: 7
Training loss: 1.6015925706971192
Validation loss: 2.4970466365960124

Epoch: 6| Step: 8
Training loss: 2.537341946344529
Validation loss: 2.508633605636542

Epoch: 6| Step: 9
Training loss: 1.6908072805238439
Validation loss: 2.5255573247728216

Epoch: 6| Step: 10
Training loss: 2.3057879390827623
Validation loss: 2.507266352426564

Epoch: 6| Step: 11
Training loss: 2.887333661197047
Validation loss: 2.5017587115619846

Epoch: 6| Step: 12
Training loss: 1.8756816260825573
Validation loss: 2.4695715284357007

Epoch: 6| Step: 13
Training loss: 2.63949596939892
Validation loss: 2.475264919219278

Epoch: 256| Step: 0
Training loss: 1.9639973874705976
Validation loss: 2.4916166107563646

Epoch: 6| Step: 1
Training loss: 2.2913223932778477
Validation loss: 2.5043850506340704

Epoch: 6| Step: 2
Training loss: 2.278661748921352
Validation loss: 2.5022225724086478

Epoch: 6| Step: 3
Training loss: 2.0135426965491483
Validation loss: 2.4883392678032825

Epoch: 6| Step: 4
Training loss: 2.601872239561539
Validation loss: 2.4494944116698347

Epoch: 6| Step: 5
Training loss: 2.6526407291856855
Validation loss: 2.516099229200429

Epoch: 6| Step: 6
Training loss: 2.5776229832018247
Validation loss: 2.4951153565602304

Epoch: 6| Step: 7
Training loss: 1.8823422046400762
Validation loss: 2.524805630017792

Epoch: 6| Step: 8
Training loss: 2.805188147614713
Validation loss: 2.502798057930362

Epoch: 6| Step: 9
Training loss: 2.067319960037437
Validation loss: 2.493394993582846

Epoch: 6| Step: 10
Training loss: 2.567331457948491
Validation loss: 2.500372782980522

Epoch: 6| Step: 11
Training loss: 2.467925211590923
Validation loss: 2.535018930578285

Epoch: 6| Step: 12
Training loss: 2.7629978611620625
Validation loss: 2.4698174452031365

Epoch: 6| Step: 13
Training loss: 2.259893600018492
Validation loss: 2.5029751742936033

Epoch: 257| Step: 0
Training loss: 2.259111182716881
Validation loss: 2.5061103166294587

Epoch: 6| Step: 1
Training loss: 2.920079786438631
Validation loss: 2.5136887600565703

Epoch: 6| Step: 2
Training loss: 2.4473801911032718
Validation loss: 2.4893332161936668

Epoch: 6| Step: 3
Training loss: 2.496190602030919
Validation loss: 2.4983142399035896

Epoch: 6| Step: 4
Training loss: 1.7999488081540258
Validation loss: 2.508861115123077

Epoch: 6| Step: 5
Training loss: 2.3416031223603424
Validation loss: 2.5221489490529687

Epoch: 6| Step: 6
Training loss: 1.8385391307377459
Validation loss: 2.5341465413757653

Epoch: 6| Step: 7
Training loss: 2.5003108784980603
Validation loss: 2.5163545431538967

Epoch: 6| Step: 8
Training loss: 2.252673573977374
Validation loss: 2.510154759136168

Epoch: 6| Step: 9
Training loss: 2.7646921599719563
Validation loss: 2.4728060562939493

Epoch: 6| Step: 10
Training loss: 1.8680225883073887
Validation loss: 2.4959353844890395

Epoch: 6| Step: 11
Training loss: 2.488076194087112
Validation loss: 2.5042332115529686

Epoch: 6| Step: 12
Training loss: 2.9211625643284367
Validation loss: 2.504421385208194

Epoch: 6| Step: 13
Training loss: 1.3673390331760182
Validation loss: 2.485878311368051

Epoch: 258| Step: 0
Training loss: 2.2128692922212028
Validation loss: 2.468190531787729

Epoch: 6| Step: 1
Training loss: 2.364538542425503
Validation loss: 2.4983198744769473

Epoch: 6| Step: 2
Training loss: 2.306860051712556
Validation loss: 2.4909345900517605

Epoch: 6| Step: 3
Training loss: 2.2210236840563318
Validation loss: 2.530676250689918

Epoch: 6| Step: 4
Training loss: 2.2765702623851554
Validation loss: 2.503747667015182

Epoch: 6| Step: 5
Training loss: 2.431370584591477
Validation loss: 2.476358045214921

Epoch: 6| Step: 6
Training loss: 2.414864317437081
Validation loss: 2.4886047798941293

Epoch: 6| Step: 7
Training loss: 2.112889505626899
Validation loss: 2.502746107469907

Epoch: 6| Step: 8
Training loss: 2.642101529627294
Validation loss: 2.510887102598561

Epoch: 6| Step: 9
Training loss: 2.4214450577609905
Validation loss: 2.4881014972851934

Epoch: 6| Step: 10
Training loss: 1.9075149341563595
Validation loss: 2.465201212885934

Epoch: 6| Step: 11
Training loss: 2.36792826628933
Validation loss: 2.5005156390316805

Epoch: 6| Step: 12
Training loss: 3.132424194928761
Validation loss: 2.5240867381749217

Epoch: 6| Step: 13
Training loss: 2.069043040193425
Validation loss: 2.4883293649081506

Epoch: 259| Step: 0
Training loss: 1.9243940266594388
Validation loss: 2.526607585437774

Epoch: 6| Step: 1
Training loss: 2.6480527165054872
Validation loss: 2.492515658342387

Epoch: 6| Step: 2
Training loss: 1.8949468097921716
Validation loss: 2.501092302977191

Epoch: 6| Step: 3
Training loss: 2.5821470387592083
Validation loss: 2.448693699894439

Epoch: 6| Step: 4
Training loss: 2.1908140963404725
Validation loss: 2.499747003038771

Epoch: 6| Step: 5
Training loss: 2.1717185643343755
Validation loss: 2.488876943472915

Epoch: 6| Step: 6
Training loss: 2.359407336285031
Validation loss: 2.483717037926658

Epoch: 6| Step: 7
Training loss: 2.3327239012709042
Validation loss: 2.4671081154876435

Epoch: 6| Step: 8
Training loss: 2.590725617703814
Validation loss: 2.4875121866777823

Epoch: 6| Step: 9
Training loss: 2.276141155055911
Validation loss: 2.49587121909033

Epoch: 6| Step: 10
Training loss: 3.059647769477167
Validation loss: 2.493070077040221

Epoch: 6| Step: 11
Training loss: 2.526458538042095
Validation loss: 2.495218535421249

Epoch: 6| Step: 12
Training loss: 2.351049018637661
Validation loss: 2.5102970110263105

Epoch: 6| Step: 13
Training loss: 2.124989116865226
Validation loss: 2.501291883626051

Epoch: 260| Step: 0
Training loss: 2.471223581854971
Validation loss: 2.5056259697109446

Epoch: 6| Step: 1
Training loss: 2.0428438750225837
Validation loss: 2.485311086102526

Epoch: 6| Step: 2
Training loss: 1.99722228276455
Validation loss: 2.5215161208288053

Epoch: 6| Step: 3
Training loss: 2.3029313977881976
Validation loss: 2.5213362530172407

Epoch: 6| Step: 4
Training loss: 1.9657548797830178
Validation loss: 2.5176278295911643

Epoch: 6| Step: 5
Training loss: 2.4349212699554266
Validation loss: 2.508007805712711

Epoch: 6| Step: 6
Training loss: 1.8310765623693348
Validation loss: 2.5074217120669933

Epoch: 6| Step: 7
Training loss: 2.992767835468799
Validation loss: 2.5004012954793127

Epoch: 6| Step: 8
Training loss: 2.7022527268567402
Validation loss: 2.5078314179034145

Epoch: 6| Step: 9
Training loss: 1.985766246023697
Validation loss: 2.530066290498496

Epoch: 6| Step: 10
Training loss: 2.403800014346486
Validation loss: 2.4967601794847756

Epoch: 6| Step: 11
Training loss: 2.4977934636479127
Validation loss: 2.486094785488405

Epoch: 6| Step: 12
Training loss: 2.7132437183037115
Validation loss: 2.498463578995433

Epoch: 6| Step: 13
Training loss: 2.5127393390284
Validation loss: 2.493912541536725

Epoch: 261| Step: 0
Training loss: 2.2481561098976677
Validation loss: 2.505283273664116

Epoch: 6| Step: 1
Training loss: 2.423951470912197
Validation loss: 2.5111127050250555

Epoch: 6| Step: 2
Training loss: 2.7587977046324816
Validation loss: 2.4949534620611793

Epoch: 6| Step: 3
Training loss: 1.8892059675564632
Validation loss: 2.5076808154368946

Epoch: 6| Step: 4
Training loss: 1.4571985552665172
Validation loss: 2.5089018635050544

Epoch: 6| Step: 5
Training loss: 1.73346528260197
Validation loss: 2.5397010544230465

Epoch: 6| Step: 6
Training loss: 2.402582420340568
Validation loss: 2.520901176606177

Epoch: 6| Step: 7
Training loss: 2.43038469228689
Validation loss: 2.5292918993388263

Epoch: 6| Step: 8
Training loss: 2.926379968884772
Validation loss: 2.496677249150429

Epoch: 6| Step: 9
Training loss: 2.937502272584726
Validation loss: 2.5049952162948146

Epoch: 6| Step: 10
Training loss: 2.596603845792119
Validation loss: 2.493523860389394

Epoch: 6| Step: 11
Training loss: 2.849101470382829
Validation loss: 2.468514758992672

Epoch: 6| Step: 12
Training loss: 1.8061190785409889
Validation loss: 2.4701447810229977

Epoch: 6| Step: 13
Training loss: 1.8059602683249796
Validation loss: 2.4900016419509527

Epoch: 262| Step: 0
Training loss: 2.2109700662216185
Validation loss: 2.531711344402038

Epoch: 6| Step: 1
Training loss: 2.206610229304452
Validation loss: 2.4753237195535656

Epoch: 6| Step: 2
Training loss: 2.8289805430191213
Validation loss: 2.4716656312463288

Epoch: 6| Step: 3
Training loss: 2.124936719961979
Validation loss: 2.4738501654111773

Epoch: 6| Step: 4
Training loss: 2.690472932388384
Validation loss: 2.488553467505129

Epoch: 6| Step: 5
Training loss: 1.8915688546838276
Validation loss: 2.470009186304015

Epoch: 6| Step: 6
Training loss: 2.3671315000853435
Validation loss: 2.521109849989298

Epoch: 6| Step: 7
Training loss: 2.2181460136048075
Validation loss: 2.5186703215114226

Epoch: 6| Step: 8
Training loss: 2.3175254035224038
Validation loss: 2.50352656294404

Epoch: 6| Step: 9
Training loss: 2.558136551171754
Validation loss: 2.4874665727459955

Epoch: 6| Step: 10
Training loss: 2.115011863945767
Validation loss: 2.494927420193728

Epoch: 6| Step: 11
Training loss: 2.473268068622975
Validation loss: 2.4699701648318664

Epoch: 6| Step: 12
Training loss: 2.2136272339083387
Validation loss: 2.4906966210963843

Epoch: 6| Step: 13
Training loss: 2.3809330766894368
Validation loss: 2.5197687778432845

Epoch: 263| Step: 0
Training loss: 1.8891182562311977
Validation loss: 2.5081755115638504

Epoch: 6| Step: 1
Training loss: 2.615767272944689
Validation loss: 2.506572707379311

Epoch: 6| Step: 2
Training loss: 1.9453123161591592
Validation loss: 2.468254253498324

Epoch: 6| Step: 3
Training loss: 2.092634786551163
Validation loss: 2.4838021066008795

Epoch: 6| Step: 4
Training loss: 1.6879968971251043
Validation loss: 2.5081303521283473

Epoch: 6| Step: 5
Training loss: 2.6401724342906254
Validation loss: 2.487767850995064

Epoch: 6| Step: 6
Training loss: 2.6764436444884847
Validation loss: 2.498542005687184

Epoch: 6| Step: 7
Training loss: 3.1047098252098992
Validation loss: 2.482721935668993

Epoch: 6| Step: 8
Training loss: 2.517061759133453
Validation loss: 2.504201590603479

Epoch: 6| Step: 9
Training loss: 2.40651176316925
Validation loss: 2.5017368620590417

Epoch: 6| Step: 10
Training loss: 2.5431528801185497
Validation loss: 2.4868136352091423

Epoch: 6| Step: 11
Training loss: 2.0868377457384115
Validation loss: 2.4864452845396694

Epoch: 6| Step: 12
Training loss: 2.5662393965690202
Validation loss: 2.516756410050589

Epoch: 6| Step: 13
Training loss: 1.4380533563108582
Validation loss: 2.494658438573024

Epoch: 264| Step: 0
Training loss: 2.055308665091759
Validation loss: 2.4746430440528586

Epoch: 6| Step: 1
Training loss: 2.513412545201342
Validation loss: 2.4878937273044794

Epoch: 6| Step: 2
Training loss: 2.0142981131731497
Validation loss: 2.4737708253293795

Epoch: 6| Step: 3
Training loss: 3.1191283950135937
Validation loss: 2.4885344370462064

Epoch: 6| Step: 4
Training loss: 2.4668852125042955
Validation loss: 2.5015144467890584

Epoch: 6| Step: 5
Training loss: 2.4805596762985207
Validation loss: 2.4685304003288824

Epoch: 6| Step: 6
Training loss: 2.2001760238973636
Validation loss: 2.5279889233986315

Epoch: 6| Step: 7
Training loss: 2.9965048138703767
Validation loss: 2.5368762285527846

Epoch: 6| Step: 8
Training loss: 2.1430449902986957
Validation loss: 2.519789077147085

Epoch: 6| Step: 9
Training loss: 2.0679750310545195
Validation loss: 2.468567184755256

Epoch: 6| Step: 10
Training loss: 2.1135843732970905
Validation loss: 2.5432164755631987

Epoch: 6| Step: 11
Training loss: 1.893664541299159
Validation loss: 2.4771328152276255

Epoch: 6| Step: 12
Training loss: 2.465570841340689
Validation loss: 2.4982186523710563

Epoch: 6| Step: 13
Training loss: 1.7861801316389518
Validation loss: 2.518401109979962

Epoch: 265| Step: 0
Training loss: 2.2937137361824917
Validation loss: 2.4677662735962094

Epoch: 6| Step: 1
Training loss: 2.654754756369651
Validation loss: 2.5200714903224526

Epoch: 6| Step: 2
Training loss: 2.579246970443078
Validation loss: 2.4977465943812227

Epoch: 6| Step: 3
Training loss: 2.463918569711703
Validation loss: 2.5201316876713484

Epoch: 6| Step: 4
Training loss: 1.9678149349106107
Validation loss: 2.523230164165289

Epoch: 6| Step: 5
Training loss: 2.300988387156878
Validation loss: 2.522236311497049

Epoch: 6| Step: 6
Training loss: 1.830456152175359
Validation loss: 2.512397654075367

Epoch: 6| Step: 7
Training loss: 2.858641483464033
Validation loss: 2.486498382865956

Epoch: 6| Step: 8
Training loss: 1.6796278832080054
Validation loss: 2.5021670947091224

Epoch: 6| Step: 9
Training loss: 2.588589509845502
Validation loss: 2.496612698753889

Epoch: 6| Step: 10
Training loss: 2.8795968499407127
Validation loss: 2.4970364540710674

Epoch: 6| Step: 11
Training loss: 2.078476496060933
Validation loss: 2.502151614461515

Epoch: 6| Step: 12
Training loss: 2.399387829908493
Validation loss: 2.4822863193751616

Epoch: 6| Step: 13
Training loss: 1.7549849763319567
Validation loss: 2.495492444258501

Epoch: 266| Step: 0
Training loss: 2.4509432864652823
Validation loss: 2.481334776104393

Epoch: 6| Step: 1
Training loss: 2.1851660129845922
Validation loss: 2.505168735826609

Epoch: 6| Step: 2
Training loss: 2.8644795531922966
Validation loss: 2.484300912196199

Epoch: 6| Step: 3
Training loss: 2.4779642752904003
Validation loss: 2.4747673483003343

Epoch: 6| Step: 4
Training loss: 2.523887381590869
Validation loss: 2.4751428119387726

Epoch: 6| Step: 5
Training loss: 2.0934837513637694
Validation loss: 2.503326295098567

Epoch: 6| Step: 6
Training loss: 1.7688093923565216
Validation loss: 2.5047633015618813

Epoch: 6| Step: 7
Training loss: 2.231328741655658
Validation loss: 2.4880395126222896

Epoch: 6| Step: 8
Training loss: 2.6695161635385913
Validation loss: 2.5027252765862746

Epoch: 6| Step: 9
Training loss: 2.1035441872190392
Validation loss: 2.4978010761642775

Epoch: 6| Step: 10
Training loss: 2.245966474824675
Validation loss: 2.5117578669442393

Epoch: 6| Step: 11
Training loss: 2.5903947569131365
Validation loss: 2.5044236101015285

Epoch: 6| Step: 12
Training loss: 2.3877735959815167
Validation loss: 2.5215768337149527

Epoch: 6| Step: 13
Training loss: 2.115652844289452
Validation loss: 2.5017674945534116

Epoch: 267| Step: 0
Training loss: 2.269357697618692
Validation loss: 2.4683861049565645

Epoch: 6| Step: 1
Training loss: 2.3474803484174376
Validation loss: 2.4864720885102973

Epoch: 6| Step: 2
Training loss: 2.4970332662484624
Validation loss: 2.5111137259430367

Epoch: 6| Step: 3
Training loss: 2.432451056432021
Validation loss: 2.501871953529361

Epoch: 6| Step: 4
Training loss: 2.245011521715534
Validation loss: 2.454480919577054

Epoch: 6| Step: 5
Training loss: 2.381130938419481
Validation loss: 2.5191422708076163

Epoch: 6| Step: 6
Training loss: 1.8220702758618954
Validation loss: 2.4863307841927256

Epoch: 6| Step: 7
Training loss: 2.5623138174014586
Validation loss: 2.48098670151607

Epoch: 6| Step: 8
Training loss: 2.2270111167434976
Validation loss: 2.4907596414585265

Epoch: 6| Step: 9
Training loss: 2.5619824514867533
Validation loss: 2.4778404324976333

Epoch: 6| Step: 10
Training loss: 2.517616762940512
Validation loss: 2.4739511576334197

Epoch: 6| Step: 11
Training loss: 2.110453690119072
Validation loss: 2.499252047478167

Epoch: 6| Step: 12
Training loss: 2.347357757938935
Validation loss: 2.4861035444163933

Epoch: 6| Step: 13
Training loss: 2.4432051965994237
Validation loss: 2.5006977317677967

Epoch: 268| Step: 0
Training loss: 2.237887629172207
Validation loss: 2.4975553845249525

Epoch: 6| Step: 1
Training loss: 1.862480967379618
Validation loss: 2.5109807825950274

Epoch: 6| Step: 2
Training loss: 2.209555042058631
Validation loss: 2.5004580406285264

Epoch: 6| Step: 3
Training loss: 1.7965005235636728
Validation loss: 2.513455541240025

Epoch: 6| Step: 4
Training loss: 2.5465886241711786
Validation loss: 2.4840926813986965

Epoch: 6| Step: 5
Training loss: 2.6301645608916955
Validation loss: 2.49663335986797

Epoch: 6| Step: 6
Training loss: 1.9196178548711809
Validation loss: 2.455575651480287

Epoch: 6| Step: 7
Training loss: 2.3615443885535767
Validation loss: 2.4779829586153235

Epoch: 6| Step: 8
Training loss: 2.5041064868197527
Validation loss: 2.4954104667744916

Epoch: 6| Step: 9
Training loss: 2.8484615657624692
Validation loss: 2.5097683666136548

Epoch: 6| Step: 10
Training loss: 2.6638097559269287
Validation loss: 2.508257042207

Epoch: 6| Step: 11
Training loss: 2.050813569313784
Validation loss: 2.537274973439102

Epoch: 6| Step: 12
Training loss: 2.8878594443125136
Validation loss: 2.5235152485779753

Epoch: 6| Step: 13
Training loss: 1.7732791914000643
Validation loss: 2.472549849609805

Epoch: 269| Step: 0
Training loss: 2.2530788972452593
Validation loss: 2.5103484442200292

Epoch: 6| Step: 1
Training loss: 2.6556142607211624
Validation loss: 2.511549529154105

Epoch: 6| Step: 2
Training loss: 2.5848257204552403
Validation loss: 2.479357363518257

Epoch: 6| Step: 3
Training loss: 2.7518365102931397
Validation loss: 2.4443803247759863

Epoch: 6| Step: 4
Training loss: 2.584389767956313
Validation loss: 2.5144605143252727

Epoch: 6| Step: 5
Training loss: 2.4848820390853454
Validation loss: 2.4955571196825463

Epoch: 6| Step: 6
Training loss: 2.4048987223342815
Validation loss: 2.4920343591226826

Epoch: 6| Step: 7
Training loss: 2.5010002042761914
Validation loss: 2.483551066251114

Epoch: 6| Step: 8
Training loss: 2.1150304637906405
Validation loss: 2.4971687261279496

Epoch: 6| Step: 9
Training loss: 2.672312382820263
Validation loss: 2.4723656500490048

Epoch: 6| Step: 10
Training loss: 1.976970524947818
Validation loss: 2.500311825901649

Epoch: 6| Step: 11
Training loss: 1.4039048880016958
Validation loss: 2.5014561206750505

Epoch: 6| Step: 12
Training loss: 1.9589485324916145
Validation loss: 2.4879183280554127

Epoch: 6| Step: 13
Training loss: 1.7708087545446909
Validation loss: 2.504730043532348

Epoch: 270| Step: 0
Training loss: 2.176210754846993
Validation loss: 2.489288849846066

Epoch: 6| Step: 1
Training loss: 1.9941023655732335
Validation loss: 2.525809424866557

Epoch: 6| Step: 2
Training loss: 2.553981671834377
Validation loss: 2.4949818905839756

Epoch: 6| Step: 3
Training loss: 2.644714619577384
Validation loss: 2.4825229006040233

Epoch: 6| Step: 4
Training loss: 1.711509225854461
Validation loss: 2.488733312732647

Epoch: 6| Step: 5
Training loss: 2.5475397471133907
Validation loss: 2.4936376048299254

Epoch: 6| Step: 6
Training loss: 2.142737467012481
Validation loss: 2.5105569567359276

Epoch: 6| Step: 7
Training loss: 2.9775385820658027
Validation loss: 2.5114803311731437

Epoch: 6| Step: 8
Training loss: 2.31892317461981
Validation loss: 2.490080646593136

Epoch: 6| Step: 9
Training loss: 2.664382870559826
Validation loss: 2.4817698161838195

Epoch: 6| Step: 10
Training loss: 2.071894663721733
Validation loss: 2.49725427384299

Epoch: 6| Step: 11
Training loss: 2.101531868750397
Validation loss: 2.4979137616833955

Epoch: 6| Step: 12
Training loss: 1.9113692038507253
Validation loss: 2.496803582416417

Epoch: 6| Step: 13
Training loss: 2.914803663809892
Validation loss: 2.513285501960711

Epoch: 271| Step: 0
Training loss: 2.3209961163489554
Validation loss: 2.4862087048271575

Epoch: 6| Step: 1
Training loss: 1.8909005208671539
Validation loss: 2.4942749130159507

Epoch: 6| Step: 2
Training loss: 2.475449176449217
Validation loss: 2.443662314458302

Epoch: 6| Step: 3
Training loss: 2.54914651687139
Validation loss: 2.45940371244073

Epoch: 6| Step: 4
Training loss: 2.1311990412999195
Validation loss: 2.5129503203993115

Epoch: 6| Step: 5
Training loss: 2.9985576977276196
Validation loss: 2.49331682501477

Epoch: 6| Step: 6
Training loss: 2.9834957725018034
Validation loss: 2.4981610595018737

Epoch: 6| Step: 7
Training loss: 2.4711768860871826
Validation loss: 2.508278494563075

Epoch: 6| Step: 8
Training loss: 2.17414769979411
Validation loss: 2.530453521061958

Epoch: 6| Step: 9
Training loss: 1.9681024848956028
Validation loss: 2.539762988018212

Epoch: 6| Step: 10
Training loss: 2.2008776734678683
Validation loss: 2.4904098566659543

Epoch: 6| Step: 11
Training loss: 2.1318943157232457
Validation loss: 2.5348012298199234

Epoch: 6| Step: 12
Training loss: 1.7427119675906408
Validation loss: 2.4535065529191735

Epoch: 6| Step: 13
Training loss: 2.4692274187304326
Validation loss: 2.5067889468589857

Epoch: 272| Step: 0
Training loss: 2.3862452060657304
Validation loss: 2.5196357305380226

Epoch: 6| Step: 1
Training loss: 1.0732368559353467
Validation loss: 2.4913618641381268

Epoch: 6| Step: 2
Training loss: 2.6769836842635013
Validation loss: 2.5047204515987658

Epoch: 6| Step: 3
Training loss: 2.2718338701599543
Validation loss: 2.536918882505187

Epoch: 6| Step: 4
Training loss: 2.133059085662478
Validation loss: 2.5053166225844214

Epoch: 6| Step: 5
Training loss: 2.2376188193371664
Validation loss: 2.5248990433770757

Epoch: 6| Step: 6
Training loss: 2.848247283594066
Validation loss: 2.4830517589888284

Epoch: 6| Step: 7
Training loss: 2.0987892429847514
Validation loss: 2.5269189219418884

Epoch: 6| Step: 8
Training loss: 2.7277187748484346
Validation loss: 2.5152953771472015

Epoch: 6| Step: 9
Training loss: 2.0777473967105227
Validation loss: 2.4693515180295904

Epoch: 6| Step: 10
Training loss: 2.1167848774298426
Validation loss: 2.4836420190542112

Epoch: 6| Step: 11
Training loss: 1.8541761533801668
Validation loss: 2.4813530414494887

Epoch: 6| Step: 12
Training loss: 2.6679947546030895
Validation loss: 2.488971414808675

Epoch: 6| Step: 13
Training loss: 3.1693324529988702
Validation loss: 2.4694115492374404

Epoch: 273| Step: 0
Training loss: 2.9528022064924198
Validation loss: 2.4935346494526374

Epoch: 6| Step: 1
Training loss: 2.524716457649912
Validation loss: 2.512630513988468

Epoch: 6| Step: 2
Training loss: 2.6140517850794205
Validation loss: 2.48765300754852

Epoch: 6| Step: 3
Training loss: 2.4362121505498187
Validation loss: 2.4563340061942345

Epoch: 6| Step: 4
Training loss: 1.8932378699633028
Validation loss: 2.5187650097442225

Epoch: 6| Step: 5
Training loss: 2.000079987833775
Validation loss: 2.4915459506264437

Epoch: 6| Step: 6
Training loss: 2.517425082625272
Validation loss: 2.5201565505116506

Epoch: 6| Step: 7
Training loss: 2.463180343443694
Validation loss: 2.494900988098477

Epoch: 6| Step: 8
Training loss: 1.997895564132586
Validation loss: 2.4897566917042044

Epoch: 6| Step: 9
Training loss: 2.319285566887244
Validation loss: 2.5234991155170503

Epoch: 6| Step: 10
Training loss: 1.8534179275860816
Validation loss: 2.501874765274359

Epoch: 6| Step: 11
Training loss: 1.715384222203631
Validation loss: 2.5109127298167295

Epoch: 6| Step: 12
Training loss: 2.5060292020650485
Validation loss: 2.508699363738952

Epoch: 6| Step: 13
Training loss: 2.4389952939321637
Validation loss: 2.5087720453450175

Epoch: 274| Step: 0
Training loss: 1.798554605736246
Validation loss: 2.527733251098428

Epoch: 6| Step: 1
Training loss: 2.0678479766454307
Validation loss: 2.465959686788247

Epoch: 6| Step: 2
Training loss: 2.47518314493133
Validation loss: 2.4970646402005348

Epoch: 6| Step: 3
Training loss: 2.35325607198193
Validation loss: 2.4621781552321056

Epoch: 6| Step: 4
Training loss: 1.9972778510934286
Validation loss: 2.4705916841046767

Epoch: 6| Step: 5
Training loss: 3.105418078890852
Validation loss: 2.5002993322443112

Epoch: 6| Step: 6
Training loss: 1.9494005015308302
Validation loss: 2.492728648641964

Epoch: 6| Step: 7
Training loss: 2.857528340356817
Validation loss: 2.522761938806226

Epoch: 6| Step: 8
Training loss: 2.6716207639860263
Validation loss: 2.479692283607303

Epoch: 6| Step: 9
Training loss: 2.2295552803298855
Validation loss: 2.515708134721476

Epoch: 6| Step: 10
Training loss: 2.14815117055064
Validation loss: 2.487548233861506

Epoch: 6| Step: 11
Training loss: 1.9894596946872984
Validation loss: 2.4669165500355077

Epoch: 6| Step: 12
Training loss: 2.190676535355266
Validation loss: 2.4785103715553753

Epoch: 6| Step: 13
Training loss: 2.595258159401571
Validation loss: 2.4494687018080734

Epoch: 275| Step: 0
Training loss: 2.3904257298612963
Validation loss: 2.542281554706114

Epoch: 6| Step: 1
Training loss: 2.7433115511091652
Validation loss: 2.4973217985288243

Epoch: 6| Step: 2
Training loss: 2.897952468471746
Validation loss: 2.544015951212959

Epoch: 6| Step: 3
Training loss: 2.2415528146791663
Validation loss: 2.4801841354865917

Epoch: 6| Step: 4
Training loss: 1.7648923586044354
Validation loss: 2.48703046961727

Epoch: 6| Step: 5
Training loss: 2.0169520777776335
Validation loss: 2.4747032628604586

Epoch: 6| Step: 6
Training loss: 2.015099627017339
Validation loss: 2.485570688868761

Epoch: 6| Step: 7
Training loss: 2.3710344234881373
Validation loss: 2.5002811089258183

Epoch: 6| Step: 8
Training loss: 1.9623957831051693
Validation loss: 2.49054949361339

Epoch: 6| Step: 9
Training loss: 2.268085064929305
Validation loss: 2.502442779532635

Epoch: 6| Step: 10
Training loss: 2.199048538803358
Validation loss: 2.500989345938732

Epoch: 6| Step: 11
Training loss: 2.5514019010965696
Validation loss: 2.5002900375789663

Epoch: 6| Step: 12
Training loss: 2.785830208878092
Validation loss: 2.498224688398362

Epoch: 6| Step: 13
Training loss: 2.365279936725704
Validation loss: 2.495629601585573

Epoch: 276| Step: 0
Training loss: 2.4009609801884433
Validation loss: 2.4789366845946716

Epoch: 6| Step: 1
Training loss: 2.5592399887600146
Validation loss: 2.500828780958401

Epoch: 6| Step: 2
Training loss: 2.5929633176998967
Validation loss: 2.5193670088450015

Epoch: 6| Step: 3
Training loss: 2.35425431304987
Validation loss: 2.4966591169659167

Epoch: 6| Step: 4
Training loss: 2.1513758315901015
Validation loss: 2.5185976527565237

Epoch: 6| Step: 5
Training loss: 2.3365451188338286
Validation loss: 2.4920530995006733

Epoch: 6| Step: 6
Training loss: 2.215778563952232
Validation loss: 2.493743828174669

Epoch: 6| Step: 7
Training loss: 2.3694503594290257
Validation loss: 2.5221958075136093

Epoch: 6| Step: 8
Training loss: 2.137760222361373
Validation loss: 2.5277520904000608

Epoch: 6| Step: 9
Training loss: 2.136824749927297
Validation loss: 2.5004166778830155

Epoch: 6| Step: 10
Training loss: 2.384751928291697
Validation loss: 2.5174059180681647

Epoch: 6| Step: 11
Training loss: 2.353704952998107
Validation loss: 2.480311311404211

Epoch: 6| Step: 12
Training loss: 2.535552054191146
Validation loss: 2.5071524767796904

Epoch: 6| Step: 13
Training loss: 2.582876831656621
Validation loss: 2.4618549627088107

Epoch: 277| Step: 0
Training loss: 2.219130147685287
Validation loss: 2.479920476810462

Epoch: 6| Step: 1
Training loss: 2.1887114303911566
Validation loss: 2.523208122631523

Epoch: 6| Step: 2
Training loss: 2.747209086406569
Validation loss: 2.4897797202827987

Epoch: 6| Step: 3
Training loss: 2.6071563242585003
Validation loss: 2.514671606157622

Epoch: 6| Step: 4
Training loss: 2.090668303493099
Validation loss: 2.4963348943373074

Epoch: 6| Step: 5
Training loss: 1.7685523283261806
Validation loss: 2.5073473303465854

Epoch: 6| Step: 6
Training loss: 2.3656613305551133
Validation loss: 2.487371458839498

Epoch: 6| Step: 7
Training loss: 1.5758960203589043
Validation loss: 2.4954117858816085

Epoch: 6| Step: 8
Training loss: 1.9952331001417771
Validation loss: 2.4755665070381903

Epoch: 6| Step: 9
Training loss: 2.1772050838710366
Validation loss: 2.513964383695459

Epoch: 6| Step: 10
Training loss: 2.8926707683720827
Validation loss: 2.4798881819624294

Epoch: 6| Step: 11
Training loss: 3.1539331374062916
Validation loss: 2.483712999006842

Epoch: 6| Step: 12
Training loss: 2.470845455849701
Validation loss: 2.5492540143789437

Epoch: 6| Step: 13
Training loss: 1.6420961595970198
Validation loss: 2.5011487085537505

Epoch: 278| Step: 0
Training loss: 2.4786145105618527
Validation loss: 2.4929616685354756

Epoch: 6| Step: 1
Training loss: 2.7346492956729764
Validation loss: 2.4714032307495564

Epoch: 6| Step: 2
Training loss: 1.845280545415868
Validation loss: 2.5025334513994086

Epoch: 6| Step: 3
Training loss: 2.155043333463159
Validation loss: 2.512089757231854

Epoch: 6| Step: 4
Training loss: 2.58838733440726
Validation loss: 2.522998343004664

Epoch: 6| Step: 5
Training loss: 2.3518704944560342
Validation loss: 2.4898992291612316

Epoch: 6| Step: 6
Training loss: 2.3900321275155783
Validation loss: 2.520645521736149

Epoch: 6| Step: 7
Training loss: 1.8479216628955044
Validation loss: 2.4876382212318413

Epoch: 6| Step: 8
Training loss: 2.2396964347728203
Validation loss: 2.4902624734044907

Epoch: 6| Step: 9
Training loss: 2.1240833773870076
Validation loss: 2.4880188048722736

Epoch: 6| Step: 10
Training loss: 2.3787535068728665
Validation loss: 2.495468271058424

Epoch: 6| Step: 11
Training loss: 2.5106490305974845
Validation loss: 2.5275184880448682

Epoch: 6| Step: 12
Training loss: 1.8748315099670638
Validation loss: 2.4739814486932215

Epoch: 6| Step: 13
Training loss: 2.998963494852352
Validation loss: 2.5162204543935762

Epoch: 279| Step: 0
Training loss: 2.0855806309750626
Validation loss: 2.50655496025805

Epoch: 6| Step: 1
Training loss: 2.149689798377442
Validation loss: 2.4733953088950997

Epoch: 6| Step: 2
Training loss: 2.7947043408203482
Validation loss: 2.470987954875394

Epoch: 6| Step: 3
Training loss: 2.72990461860567
Validation loss: 2.493605691194322

Epoch: 6| Step: 4
Training loss: 2.7771305909157826
Validation loss: 2.4855934952857823

Epoch: 6| Step: 5
Training loss: 2.694238952019403
Validation loss: 2.482062806186336

Epoch: 6| Step: 6
Training loss: 2.283871855426231
Validation loss: 2.52169058764737

Epoch: 6| Step: 7
Training loss: 2.27091793171032
Validation loss: 2.5116036686533207

Epoch: 6| Step: 8
Training loss: 2.1211798494121723
Validation loss: 2.5015759156629653

Epoch: 6| Step: 9
Training loss: 2.1477486910722217
Validation loss: 2.476124619288588

Epoch: 6| Step: 10
Training loss: 1.8811040701299069
Validation loss: 2.4790847680688177

Epoch: 6| Step: 11
Training loss: 2.4501231104223287
Validation loss: 2.4750339149619967

Epoch: 6| Step: 12
Training loss: 1.8526524422094814
Validation loss: 2.4610067326237695

Epoch: 6| Step: 13
Training loss: 1.9823482105117447
Validation loss: 2.4903441869598706

Epoch: 280| Step: 0
Training loss: 2.4240931044094025
Validation loss: 2.5176220427205616

Epoch: 6| Step: 1
Training loss: 2.1656935291539376
Validation loss: 2.504962620429978

Epoch: 6| Step: 2
Training loss: 2.3097840934026683
Validation loss: 2.5356861893365044

Epoch: 6| Step: 3
Training loss: 2.5612145898325074
Validation loss: 2.4880770791753255

Epoch: 6| Step: 4
Training loss: 2.055548077933426
Validation loss: 2.4888177515705814

Epoch: 6| Step: 5
Training loss: 2.4895418767523303
Validation loss: 2.5014140775175737

Epoch: 6| Step: 6
Training loss: 1.6808430090445916
Validation loss: 2.498977992648453

Epoch: 6| Step: 7
Training loss: 2.1570552483328633
Validation loss: 2.4875068739071917

Epoch: 6| Step: 8
Training loss: 2.3239670048142536
Validation loss: 2.5229510239016557

Epoch: 6| Step: 9
Training loss: 2.7040274993243045
Validation loss: 2.4632416397011982

Epoch: 6| Step: 10
Training loss: 2.002625649233225
Validation loss: 2.4850035630910754

Epoch: 6| Step: 11
Training loss: 2.584785227753846
Validation loss: 2.4996665968129412

Epoch: 6| Step: 12
Training loss: 2.1003593773102214
Validation loss: 2.4424523076123883

Epoch: 6| Step: 13
Training loss: 2.9202835726542644
Validation loss: 2.4483827111086853

Epoch: 281| Step: 0
Training loss: 2.60567408357407
Validation loss: 2.4733326524977293

Epoch: 6| Step: 1
Training loss: 1.7607305423734432
Validation loss: 2.4864343033549834

Epoch: 6| Step: 2
Training loss: 2.382769074591491
Validation loss: 2.4912846242897095

Epoch: 6| Step: 3
Training loss: 2.806845342275142
Validation loss: 2.5056094493042744

Epoch: 6| Step: 4
Training loss: 1.6961338145664964
Validation loss: 2.5119776464038157

Epoch: 6| Step: 5
Training loss: 2.1759657721632424
Validation loss: 2.4557497273808435

Epoch: 6| Step: 6
Training loss: 2.7925100523410005
Validation loss: 2.4861550290476764

Epoch: 6| Step: 7
Training loss: 2.4791502324262167
Validation loss: 2.4873275955155165

Epoch: 6| Step: 8
Training loss: 2.179088660668089
Validation loss: 2.4862996057783024

Epoch: 6| Step: 9
Training loss: 2.110737904247528
Validation loss: 2.494736167414906

Epoch: 6| Step: 10
Training loss: 2.3715103009760465
Validation loss: 2.4554455500203076

Epoch: 6| Step: 11
Training loss: 2.9029767050917195
Validation loss: 2.4949790710709743

Epoch: 6| Step: 12
Training loss: 1.8513292898111735
Validation loss: 2.498964401811081

Epoch: 6| Step: 13
Training loss: 1.8081655304338755
Validation loss: 2.455899120231485

Epoch: 282| Step: 0
Training loss: 2.178647028841923
Validation loss: 2.465874387249088

Epoch: 6| Step: 1
Training loss: 2.087050237572836
Validation loss: 2.4884055385044324

Epoch: 6| Step: 2
Training loss: 2.1538111951107903
Validation loss: 2.446153032048108

Epoch: 6| Step: 3
Training loss: 2.7345288914563013
Validation loss: 2.5084694634473137

Epoch: 6| Step: 4
Training loss: 1.511175881233421
Validation loss: 2.510191888506646

Epoch: 6| Step: 5
Training loss: 2.8668733263561816
Validation loss: 2.500221442598011

Epoch: 6| Step: 6
Training loss: 3.0072116003861566
Validation loss: 2.5002386697032573

Epoch: 6| Step: 7
Training loss: 2.3532275011654122
Validation loss: 2.5213403760509157

Epoch: 6| Step: 8
Training loss: 2.2594119415850984
Validation loss: 2.4771225787874305

Epoch: 6| Step: 9
Training loss: 2.038996085185156
Validation loss: 2.497769257806001

Epoch: 6| Step: 10
Training loss: 2.447769636784308
Validation loss: 2.5214072912838934

Epoch: 6| Step: 11
Training loss: 2.0597881637836175
Validation loss: 2.4926465905478103

Epoch: 6| Step: 12
Training loss: 2.161743905073079
Validation loss: 2.489891726851333

Epoch: 6| Step: 13
Training loss: 2.573663168244178
Validation loss: 2.5068026793561735

Epoch: 283| Step: 0
Training loss: 1.8628155588202664
Validation loss: 2.509031151804544

Epoch: 6| Step: 1
Training loss: 2.104386484983196
Validation loss: 2.4945607408710266

Epoch: 6| Step: 2
Training loss: 2.2747226504107054
Validation loss: 2.483384572486245

Epoch: 6| Step: 3
Training loss: 2.577558050528681
Validation loss: 2.5169259652939933

Epoch: 6| Step: 4
Training loss: 2.1324408909609622
Validation loss: 2.511877183895196

Epoch: 6| Step: 5
Training loss: 2.329580581637032
Validation loss: 2.5170671286874438

Epoch: 6| Step: 6
Training loss: 2.407284600910385
Validation loss: 2.4959417382836464

Epoch: 6| Step: 7
Training loss: 2.2809788791024834
Validation loss: 2.482478590167222

Epoch: 6| Step: 8
Training loss: 2.7222510409830054
Validation loss: 2.488599116113216

Epoch: 6| Step: 9
Training loss: 2.9498379291044787
Validation loss: 2.4806890941288766

Epoch: 6| Step: 10
Training loss: 2.4012219298597137
Validation loss: 2.476588217403561

Epoch: 6| Step: 11
Training loss: 2.217747743996092
Validation loss: 2.5258886908559113

Epoch: 6| Step: 12
Training loss: 1.896256123723381
Validation loss: 2.49237317845833

Epoch: 6| Step: 13
Training loss: 2.1241732840461762
Validation loss: 2.4893412582819074

Epoch: 284| Step: 0
Training loss: 2.016187012853912
Validation loss: 2.4994528356251196

Epoch: 6| Step: 1
Training loss: 2.3771095945315737
Validation loss: 2.5139478064202025

Epoch: 6| Step: 2
Training loss: 1.9863841781284144
Validation loss: 2.504480348564129

Epoch: 6| Step: 3
Training loss: 2.062738924926275
Validation loss: 2.5065979665363964

Epoch: 6| Step: 4
Training loss: 2.677320051797977
Validation loss: 2.513764097887769

Epoch: 6| Step: 5
Training loss: 1.7958752712064485
Validation loss: 2.5265354179268056

Epoch: 6| Step: 6
Training loss: 1.9402432863335344
Validation loss: 2.4851819698287665

Epoch: 6| Step: 7
Training loss: 2.3892357473384376
Validation loss: 2.4703541792134187

Epoch: 6| Step: 8
Training loss: 2.6676493463296755
Validation loss: 2.511932853333757

Epoch: 6| Step: 9
Training loss: 1.969581125816473
Validation loss: 2.5017680140923657

Epoch: 6| Step: 10
Training loss: 2.274926500914746
Validation loss: 2.504532695011351

Epoch: 6| Step: 11
Training loss: 3.0466308495929413
Validation loss: 2.4797166183514108

Epoch: 6| Step: 12
Training loss: 2.370375095413497
Validation loss: 2.456377265541191

Epoch: 6| Step: 13
Training loss: 2.363979469752359
Validation loss: 2.474131071647922

Epoch: 285| Step: 0
Training loss: 2.3314759377635363
Validation loss: 2.4705333444669804

Epoch: 6| Step: 1
Training loss: 2.0220250682767267
Validation loss: 2.4895077120372187

Epoch: 6| Step: 2
Training loss: 1.2625856049474653
Validation loss: 2.489594219106905

Epoch: 6| Step: 3
Training loss: 2.384647450811261
Validation loss: 2.4774899257383356

Epoch: 6| Step: 4
Training loss: 2.29204752676056
Validation loss: 2.4855453263855547

Epoch: 6| Step: 5
Training loss: 2.2935436769247333
Validation loss: 2.484889557036201

Epoch: 6| Step: 6
Training loss: 2.797795746198258
Validation loss: 2.447239098193443

Epoch: 6| Step: 7
Training loss: 2.088812172385039
Validation loss: 2.47914054721038

Epoch: 6| Step: 8
Training loss: 1.8339350392101141
Validation loss: 2.4963758892897343

Epoch: 6| Step: 9
Training loss: 2.256114281458494
Validation loss: 2.495579871818139

Epoch: 6| Step: 10
Training loss: 2.866652935202188
Validation loss: 2.467799892652444

Epoch: 6| Step: 11
Training loss: 2.4597657335586365
Validation loss: 2.505447889609437

Epoch: 6| Step: 12
Training loss: 2.8690759743715937
Validation loss: 2.4926053799862458

Epoch: 6| Step: 13
Training loss: 1.8681849923683813
Validation loss: 2.4857597059948295

Epoch: 286| Step: 0
Training loss: 2.4060059460814607
Validation loss: 2.525147493908373

Epoch: 6| Step: 1
Training loss: 2.2471630437053554
Validation loss: 2.4746079204865943

Epoch: 6| Step: 2
Training loss: 1.9873476965746806
Validation loss: 2.518073337966812

Epoch: 6| Step: 3
Training loss: 2.487748356981629
Validation loss: 2.521149081540355

Epoch: 6| Step: 4
Training loss: 2.0607733000965607
Validation loss: 2.494970531338504

Epoch: 6| Step: 5
Training loss: 2.295502856147068
Validation loss: 2.4905181075841787

Epoch: 6| Step: 6
Training loss: 2.422478582171389
Validation loss: 2.4402647406971774

Epoch: 6| Step: 7
Training loss: 2.160791231336883
Validation loss: 2.4844476822442054

Epoch: 6| Step: 8
Training loss: 2.219726992135902
Validation loss: 2.481484742396215

Epoch: 6| Step: 9
Training loss: 3.0481339421316127
Validation loss: 2.512468617536681

Epoch: 6| Step: 10
Training loss: 2.524668107079289
Validation loss: 2.5266199388592603

Epoch: 6| Step: 11
Training loss: 2.060441232296332
Validation loss: 2.4976818730110306

Epoch: 6| Step: 12
Training loss: 1.91135885064653
Validation loss: 2.494014967869723

Epoch: 6| Step: 13
Training loss: 2.113694127730071
Validation loss: 2.4888887003117492

Epoch: 287| Step: 0
Training loss: 2.067612986123898
Validation loss: 2.5252027723194153

Epoch: 6| Step: 1
Training loss: 1.9359491971380696
Validation loss: 2.5004115816968966

Epoch: 6| Step: 2
Training loss: 2.957120906624632
Validation loss: 2.519308983093716

Epoch: 6| Step: 3
Training loss: 1.668296763844682
Validation loss: 2.48884791422591

Epoch: 6| Step: 4
Training loss: 2.427436006215204
Validation loss: 2.4773965036010117

Epoch: 6| Step: 5
Training loss: 1.7040904397246246
Validation loss: 2.4883326349696406

Epoch: 6| Step: 6
Training loss: 3.0207457080277975
Validation loss: 2.47968650228708

Epoch: 6| Step: 7
Training loss: 2.343923028281028
Validation loss: 2.504780524040604

Epoch: 6| Step: 8
Training loss: 2.4297353856314174
Validation loss: 2.521188235201235

Epoch: 6| Step: 9
Training loss: 2.3368476446957906
Validation loss: 2.458207446490797

Epoch: 6| Step: 10
Training loss: 2.2056259137111467
Validation loss: 2.4823770877012934

Epoch: 6| Step: 11
Training loss: 2.58066817184926
Validation loss: 2.478902718099917

Epoch: 6| Step: 12
Training loss: 1.9949483253842364
Validation loss: 2.4844171240959203

Epoch: 6| Step: 13
Training loss: 1.9706283570275234
Validation loss: 2.4712137244863053

Epoch: 288| Step: 0
Training loss: 2.4533458051502723
Validation loss: 2.477166102253206

Epoch: 6| Step: 1
Training loss: 2.2139421407415485
Validation loss: 2.52310094910171

Epoch: 6| Step: 2
Training loss: 1.2244018184106253
Validation loss: 2.4891202865610182

Epoch: 6| Step: 3
Training loss: 2.774151261587581
Validation loss: 2.4742473218917738

Epoch: 6| Step: 4
Training loss: 2.3795385663521667
Validation loss: 2.4911454412183835

Epoch: 6| Step: 5
Training loss: 2.074516433073334
Validation loss: 2.486937316188488

Epoch: 6| Step: 6
Training loss: 2.385734592445954
Validation loss: 2.527253565044818

Epoch: 6| Step: 7
Training loss: 2.49261939632298
Validation loss: 2.507395535907702

Epoch: 6| Step: 8
Training loss: 2.418288596449517
Validation loss: 2.4944693290573436

Epoch: 6| Step: 9
Training loss: 2.085272865278896
Validation loss: 2.5113605987798335

Epoch: 6| Step: 10
Training loss: 2.5343973819670977
Validation loss: 2.4816760107563223

Epoch: 6| Step: 11
Training loss: 2.308799979717601
Validation loss: 2.4441214781905836

Epoch: 6| Step: 12
Training loss: 2.381917816794256
Validation loss: 2.4904113050385246

Epoch: 6| Step: 13
Training loss: 1.8622840116060233
Validation loss: 2.514837665743742

Epoch: 289| Step: 0
Training loss: 2.4345504325364122
Validation loss: 2.532467220150008

Epoch: 6| Step: 1
Training loss: 2.6676930498735243
Validation loss: 2.4721577703427102

Epoch: 6| Step: 2
Training loss: 2.0615786025971166
Validation loss: 2.4924338277497644

Epoch: 6| Step: 3
Training loss: 1.869943157494891
Validation loss: 2.4991268848284287

Epoch: 6| Step: 4
Training loss: 2.5792119364753328
Validation loss: 2.470444608172213

Epoch: 6| Step: 5
Training loss: 2.369888829066416
Validation loss: 2.476465939345133

Epoch: 6| Step: 6
Training loss: 2.7174479556605373
Validation loss: 2.4756521229517743

Epoch: 6| Step: 7
Training loss: 1.963276232141108
Validation loss: 2.4807503607981394

Epoch: 6| Step: 8
Training loss: 2.1827955612584877
Validation loss: 2.4761359076179064

Epoch: 6| Step: 9
Training loss: 1.6568206667688194
Validation loss: 2.5008337076630407

Epoch: 6| Step: 10
Training loss: 2.829911484429255
Validation loss: 2.4831006948360344

Epoch: 6| Step: 11
Training loss: 1.9660905101815822
Validation loss: 2.454289301318019

Epoch: 6| Step: 12
Training loss: 2.5330340844476673
Validation loss: 2.4842358044092587

Epoch: 6| Step: 13
Training loss: 1.9516766480414043
Validation loss: 2.463637337752877

Epoch: 290| Step: 0
Training loss: 2.5232275530044297
Validation loss: 2.5018168574452933

Epoch: 6| Step: 1
Training loss: 2.34783630188426
Validation loss: 2.4917242217679645

Epoch: 6| Step: 2
Training loss: 2.891529663387614
Validation loss: 2.493686238360739

Epoch: 6| Step: 3
Training loss: 1.4640451924899982
Validation loss: 2.4841776783860143

Epoch: 6| Step: 4
Training loss: 2.2009507942366913
Validation loss: 2.5066140524069973

Epoch: 6| Step: 5
Training loss: 2.2995365836959105
Validation loss: 2.4913087583336533

Epoch: 6| Step: 6
Training loss: 2.3186937844590148
Validation loss: 2.4948247482227073

Epoch: 6| Step: 7
Training loss: 1.833910143307683
Validation loss: 2.482460839127351

Epoch: 6| Step: 8
Training loss: 2.629114287308557
Validation loss: 2.46798963196392

Epoch: 6| Step: 9
Training loss: 2.2142122098263397
Validation loss: 2.527775985294635

Epoch: 6| Step: 10
Training loss: 2.3518288293625558
Validation loss: 2.5060499906524476

Epoch: 6| Step: 11
Training loss: 3.0642318499820367
Validation loss: 2.4714656497678753

Epoch: 6| Step: 12
Training loss: 1.3156487070878897
Validation loss: 2.5143122283627988

Epoch: 6| Step: 13
Training loss: 2.1050850654865636
Validation loss: 2.474481343466517

Epoch: 291| Step: 0
Training loss: 2.6583480627275695
Validation loss: 2.4748907047077986

Epoch: 6| Step: 1
Training loss: 2.1096001398947957
Validation loss: 2.5032509309102804

Epoch: 6| Step: 2
Training loss: 1.960285823183813
Validation loss: 2.4534035143064403

Epoch: 6| Step: 3
Training loss: 2.012387062837025
Validation loss: 2.4952008893982733

Epoch: 6| Step: 4
Training loss: 2.1885892063686594
Validation loss: 2.4836306636837966

Epoch: 6| Step: 5
Training loss: 2.054963068015331
Validation loss: 2.495885762501755

Epoch: 6| Step: 6
Training loss: 2.344488409071061
Validation loss: 2.4727542439626373

Epoch: 6| Step: 7
Training loss: 2.9291869689614045
Validation loss: 2.5243759307580538

Epoch: 6| Step: 8
Training loss: 2.16464699243726
Validation loss: 2.4765125778278767

Epoch: 6| Step: 9
Training loss: 2.125300890993626
Validation loss: 2.4956858419746006

Epoch: 6| Step: 10
Training loss: 2.497813412969091
Validation loss: 2.4750002558875757

Epoch: 6| Step: 11
Training loss: 2.167974908493505
Validation loss: 2.4968092737907597

Epoch: 6| Step: 12
Training loss: 2.7432567109554564
Validation loss: 2.4904773507562834

Epoch: 6| Step: 13
Training loss: 1.5277598563019752
Validation loss: 2.5038191254649105

Epoch: 292| Step: 0
Training loss: 1.8823168723510986
Validation loss: 2.514256134414881

Epoch: 6| Step: 1
Training loss: 2.3877445395296095
Validation loss: 2.4787910413323813

Epoch: 6| Step: 2
Training loss: 2.392176704207963
Validation loss: 2.48367949522735

Epoch: 6| Step: 3
Training loss: 2.217222305680605
Validation loss: 2.490659598411816

Epoch: 6| Step: 4
Training loss: 2.4407000931874556
Validation loss: 2.4910945773748367

Epoch: 6| Step: 5
Training loss: 2.1572924319391324
Validation loss: 2.4748895569744955

Epoch: 6| Step: 6
Training loss: 2.2902375938396813
Validation loss: 2.5213760087453667

Epoch: 6| Step: 7
Training loss: 2.896829410922626
Validation loss: 2.4988223552868885

Epoch: 6| Step: 8
Training loss: 1.788944423727043
Validation loss: 2.4578672331839826

Epoch: 6| Step: 9
Training loss: 1.8833016041246258
Validation loss: 2.469719009810537

Epoch: 6| Step: 10
Training loss: 2.3054797863542604
Validation loss: 2.4921830263064555

Epoch: 6| Step: 11
Training loss: 2.5960313806150697
Validation loss: 2.4531087776203138

Epoch: 6| Step: 12
Training loss: 1.9883690835254773
Validation loss: 2.5179747028851955

Epoch: 6| Step: 13
Training loss: 2.9815057672793164
Validation loss: 2.500727219587751

Epoch: 293| Step: 0
Training loss: 1.7138998783830222
Validation loss: 2.481417958325846

Epoch: 6| Step: 1
Training loss: 2.449581527004191
Validation loss: 2.4976242970175226

Epoch: 6| Step: 2
Training loss: 2.340690548721263
Validation loss: 2.480675201570697

Epoch: 6| Step: 3
Training loss: 2.009570350465302
Validation loss: 2.484156528741488

Epoch: 6| Step: 4
Training loss: 2.1297896765801276
Validation loss: 2.474566309023756

Epoch: 6| Step: 5
Training loss: 2.46180017276732
Validation loss: 2.4611331005788917

Epoch: 6| Step: 6
Training loss: 2.4976583004138537
Validation loss: 2.47886633214988

Epoch: 6| Step: 7
Training loss: 3.060703295500225
Validation loss: 2.486954286890365

Epoch: 6| Step: 8
Training loss: 1.865999362516141
Validation loss: 2.5051903241248525

Epoch: 6| Step: 9
Training loss: 2.3243140449542383
Validation loss: 2.481316051893947

Epoch: 6| Step: 10
Training loss: 1.8856729645866934
Validation loss: 2.4962998459381516

Epoch: 6| Step: 11
Training loss: 1.9909437897438687
Validation loss: 2.510800979955972

Epoch: 6| Step: 12
Training loss: 2.21346082352755
Validation loss: 2.465517795573196

Epoch: 6| Step: 13
Training loss: 2.8474970015592924
Validation loss: 2.497912550634107

Epoch: 294| Step: 0
Training loss: 2.3345482819369106
Validation loss: 2.4984516055592345

Epoch: 6| Step: 1
Training loss: 2.7387170812107495
Validation loss: 2.4826678902095525

Epoch: 6| Step: 2
Training loss: 2.101317324039226
Validation loss: 2.471376601516215

Epoch: 6| Step: 3
Training loss: 1.664623398790007
Validation loss: 2.4860353499743364

Epoch: 6| Step: 4
Training loss: 2.697384068611408
Validation loss: 2.4997198747773997

Epoch: 6| Step: 5
Training loss: 2.217586588410836
Validation loss: 2.4898024170991055

Epoch: 6| Step: 6
Training loss: 1.600741887946771
Validation loss: 2.492545697566803

Epoch: 6| Step: 7
Training loss: 2.3715391541992097
Validation loss: 2.4563178874596563

Epoch: 6| Step: 8
Training loss: 2.3334890949394156
Validation loss: 2.4890694977190915

Epoch: 6| Step: 9
Training loss: 2.1882277231911855
Validation loss: 2.4925736331240818

Epoch: 6| Step: 10
Training loss: 2.3648200455767086
Validation loss: 2.4552284958453763

Epoch: 6| Step: 11
Training loss: 2.2193170816764773
Validation loss: 2.4892700587911065

Epoch: 6| Step: 12
Training loss: 2.5184314308609324
Validation loss: 2.5206334797503294

Epoch: 6| Step: 13
Training loss: 1.9739129322101654
Validation loss: 2.4723027145422094

Epoch: 295| Step: 0
Training loss: 2.4329697986238186
Validation loss: 2.4640604237109636

Epoch: 6| Step: 1
Training loss: 2.3370679078590815
Validation loss: 2.4713053652727814

Epoch: 6| Step: 2
Training loss: 1.6719166402889813
Validation loss: 2.477391733628636

Epoch: 6| Step: 3
Training loss: 2.008458133898379
Validation loss: 2.514863581969246

Epoch: 6| Step: 4
Training loss: 2.981125585491112
Validation loss: 2.4972975645041338

Epoch: 6| Step: 5
Training loss: 1.9892882549370436
Validation loss: 2.4959412555355134

Epoch: 6| Step: 6
Training loss: 2.5319862707769234
Validation loss: 2.4959752027729527

Epoch: 6| Step: 7
Training loss: 2.4039442236042405
Validation loss: 2.4680203748141754

Epoch: 6| Step: 8
Training loss: 2.3037167331158552
Validation loss: 2.459260402492056

Epoch: 6| Step: 9
Training loss: 2.2618233190420733
Validation loss: 2.478658749413137

Epoch: 6| Step: 10
Training loss: 2.3007755506150227
Validation loss: 2.4582698470382893

Epoch: 6| Step: 11
Training loss: 2.2545266710684713
Validation loss: 2.4926733093226963

Epoch: 6| Step: 12
Training loss: 2.7161122823211454
Validation loss: 2.474522957394146

Epoch: 6| Step: 13
Training loss: 1.8141477264177253
Validation loss: 2.483217466709397

Epoch: 296| Step: 0
Training loss: 2.1371656992983312
Validation loss: 2.486572189718079

Epoch: 6| Step: 1
Training loss: 2.463139786848912
Validation loss: 2.5073610009949467

Epoch: 6| Step: 2
Training loss: 2.023439620911654
Validation loss: 2.481948980605815

Epoch: 6| Step: 3
Training loss: 2.4053170513453472
Validation loss: 2.458988610920747

Epoch: 6| Step: 4
Training loss: 1.9575746432867653
Validation loss: 2.4847415450644252

Epoch: 6| Step: 5
Training loss: 2.184486274995687
Validation loss: 2.482926145201166

Epoch: 6| Step: 6
Training loss: 1.7072615479036712
Validation loss: 2.4843022887990265

Epoch: 6| Step: 7
Training loss: 2.31619915350057
Validation loss: 2.469960799628336

Epoch: 6| Step: 8
Training loss: 2.1994830391124323
Validation loss: 2.510757597423779

Epoch: 6| Step: 9
Training loss: 2.578243183548283
Validation loss: 2.4505963475965955

Epoch: 6| Step: 10
Training loss: 2.797922204741912
Validation loss: 2.505457456758798

Epoch: 6| Step: 11
Training loss: 2.14311452182757
Validation loss: 2.5128561159848446

Epoch: 6| Step: 12
Training loss: 2.6337882477925603
Validation loss: 2.507263859608451

Epoch: 6| Step: 13
Training loss: 1.5191782563409681
Validation loss: 2.506370522673438

Epoch: 297| Step: 0
Training loss: 2.3870983165346864
Validation loss: 2.4837204585655983

Epoch: 6| Step: 1
Training loss: 2.8737345688693057
Validation loss: 2.496322396180627

Epoch: 6| Step: 2
Training loss: 1.69830016815377
Validation loss: 2.505138467278337

Epoch: 6| Step: 3
Training loss: 1.8867548905538336
Validation loss: 2.495203978874015

Epoch: 6| Step: 4
Training loss: 2.446728768491706
Validation loss: 2.487961756432459

Epoch: 6| Step: 5
Training loss: 2.039899632284918
Validation loss: 2.468342948057256

Epoch: 6| Step: 6
Training loss: 2.248251765614099
Validation loss: 2.4742459697424093

Epoch: 6| Step: 7
Training loss: 1.8812190867574066
Validation loss: 2.5040591009637003

Epoch: 6| Step: 8
Training loss: 2.1574769882796097
Validation loss: 2.4732399543958743

Epoch: 6| Step: 9
Training loss: 2.0922711971712
Validation loss: 2.475836618514978

Epoch: 6| Step: 10
Training loss: 1.772989762708582
Validation loss: 2.4899511876868985

Epoch: 6| Step: 11
Training loss: 3.031538172916128
Validation loss: 2.463844966075726

Epoch: 6| Step: 12
Training loss: 2.196715100303878
Validation loss: 2.4765998690261077

Epoch: 6| Step: 13
Training loss: 3.2448075703842965
Validation loss: 2.522993856118562

Epoch: 298| Step: 0
Training loss: 2.4311239528588042
Validation loss: 2.4800948751609844

Epoch: 6| Step: 1
Training loss: 1.9138710393320892
Validation loss: 2.4835151675027647

Epoch: 6| Step: 2
Training loss: 2.4821846381157373
Validation loss: 2.4974456915238656

Epoch: 6| Step: 3
Training loss: 2.1509870348282027
Validation loss: 2.499877888763388

Epoch: 6| Step: 4
Training loss: 2.3869181298421895
Validation loss: 2.4575565967988813

Epoch: 6| Step: 5
Training loss: 2.1458800474347384
Validation loss: 2.493100698797043

Epoch: 6| Step: 6
Training loss: 3.1601509688325
Validation loss: 2.454793599403245

Epoch: 6| Step: 7
Training loss: 2.5278491498025977
Validation loss: 2.449777679535564

Epoch: 6| Step: 8
Training loss: 1.776965962596516
Validation loss: 2.5137793057163593

Epoch: 6| Step: 9
Training loss: 2.3746098649679745
Validation loss: 2.4802364117498263

Epoch: 6| Step: 10
Training loss: 2.0540677720638736
Validation loss: 2.489852825470159

Epoch: 6| Step: 11
Training loss: 1.909085775343693
Validation loss: 2.4725720358303227

Epoch: 6| Step: 12
Training loss: 1.613505128562113
Validation loss: 2.446638482514256

Epoch: 6| Step: 13
Training loss: 2.331879832912765
Validation loss: 2.5031786533035882

Epoch: 299| Step: 0
Training loss: 2.6577494260019274
Validation loss: 2.4888537293728366

Epoch: 6| Step: 1
Training loss: 1.7428985649966644
Validation loss: 2.4980891215803465

Epoch: 6| Step: 2
Training loss: 2.6117881535178538
Validation loss: 2.4808810758806294

Epoch: 6| Step: 3
Training loss: 1.6880723900843349
Validation loss: 2.4976950961901863

Epoch: 6| Step: 4
Training loss: 3.4101770843883177
Validation loss: 2.4801035591462175

Epoch: 6| Step: 5
Training loss: 2.287467322611224
Validation loss: 2.477537928410604

Epoch: 6| Step: 6
Training loss: 1.5690425463245137
Validation loss: 2.492846485375388

Epoch: 6| Step: 7
Training loss: 2.3217065393219327
Validation loss: 2.5301142243085124

Epoch: 6| Step: 8
Training loss: 2.3277263940174056
Validation loss: 2.487085374779402

Epoch: 6| Step: 9
Training loss: 1.5219294199525208
Validation loss: 2.487458252511388

Epoch: 6| Step: 10
Training loss: 2.15220993373717
Validation loss: 2.509723722065706

Epoch: 6| Step: 11
Training loss: 2.3153753189789374
Validation loss: 2.470114591847419

Epoch: 6| Step: 12
Training loss: 2.7156848510187057
Validation loss: 2.5048876616360607

Epoch: 6| Step: 13
Training loss: 1.4555559231528739
Validation loss: 2.507795934194657

Epoch: 300| Step: 0
Training loss: 2.6840063052835323
Validation loss: 2.4996122305608717

Epoch: 6| Step: 1
Training loss: 2.1169999943995848
Validation loss: 2.494990087087459

Epoch: 6| Step: 2
Training loss: 2.015284664785809
Validation loss: 2.4832921897330227

Epoch: 6| Step: 3
Training loss: 2.2740481890267024
Validation loss: 2.5244411518543384

Epoch: 6| Step: 4
Training loss: 1.8772102044937506
Validation loss: 2.4934109230114343

Epoch: 6| Step: 5
Training loss: 1.887707689997574
Validation loss: 2.475768561683047

Epoch: 6| Step: 6
Training loss: 2.7349227792553834
Validation loss: 2.4923181120586584

Epoch: 6| Step: 7
Training loss: 2.616411600822201
Validation loss: 2.4809678238135313

Epoch: 6| Step: 8
Training loss: 1.8014417913912724
Validation loss: 2.5116049363855293

Epoch: 6| Step: 9
Training loss: 1.9261697064002445
Validation loss: 2.4707218642705455

Epoch: 6| Step: 10
Training loss: 1.967913131866845
Validation loss: 2.4736904204312613

Epoch: 6| Step: 11
Training loss: 2.4477784029824723
Validation loss: 2.4832658273601105

Epoch: 6| Step: 12
Training loss: 2.6023138754007973
Validation loss: 2.519394879006334

Epoch: 6| Step: 13
Training loss: 2.371036233471469
Validation loss: 2.474899917630749

Epoch: 301| Step: 0
Training loss: 2.2515397631247023
Validation loss: 2.5001461458045418

Epoch: 6| Step: 1
Training loss: 2.5017347039465765
Validation loss: 2.4997171836772023

Epoch: 6| Step: 2
Training loss: 2.5589476362493073
Validation loss: 2.481898769100057

Epoch: 6| Step: 3
Training loss: 2.2179905840963654
Validation loss: 2.479925870960159

Epoch: 6| Step: 4
Training loss: 2.2697444953469357
Validation loss: 2.4824901170703955

Epoch: 6| Step: 5
Training loss: 2.235843629286078
Validation loss: 2.5015354937457577

Epoch: 6| Step: 6
Training loss: 2.403153743497589
Validation loss: 2.477260023607552

Epoch: 6| Step: 7
Training loss: 2.2046819285343315
Validation loss: 2.488656004694178

Epoch: 6| Step: 8
Training loss: 2.073269556828884
Validation loss: 2.478853261910736

Epoch: 6| Step: 9
Training loss: 2.285197878727395
Validation loss: 2.4840727725643563

Epoch: 6| Step: 10
Training loss: 2.4170018544629914
Validation loss: 2.499731376531605

Epoch: 6| Step: 11
Training loss: 1.9057725402227672
Validation loss: 2.479460343045976

Epoch: 6| Step: 12
Training loss: 1.9130979637870145
Validation loss: 2.4515149991408056

Epoch: 6| Step: 13
Training loss: 2.6596266881807678
Validation loss: 2.503139194384115

Epoch: 302| Step: 0
Training loss: 1.6580437357831963
Validation loss: 2.4708596641013103

Epoch: 6| Step: 1
Training loss: 1.7876037914313592
Validation loss: 2.4632622799450354

Epoch: 6| Step: 2
Training loss: 2.100552794950072
Validation loss: 2.4886870526359672

Epoch: 6| Step: 3
Training loss: 2.968841230094954
Validation loss: 2.448432870728786

Epoch: 6| Step: 4
Training loss: 2.6537475466615796
Validation loss: 2.4730509942007295

Epoch: 6| Step: 5
Training loss: 2.408786279220043
Validation loss: 2.5231348611395408

Epoch: 6| Step: 6
Training loss: 2.062190408301409
Validation loss: 2.4949044206337527

Epoch: 6| Step: 7
Training loss: 2.31935485189656
Validation loss: 2.4635734570796584

Epoch: 6| Step: 8
Training loss: 2.7482681022692605
Validation loss: 2.4964841515875538

Epoch: 6| Step: 9
Training loss: 2.6908372961420546
Validation loss: 2.4865041782476536

Epoch: 6| Step: 10
Training loss: 2.57511772701432
Validation loss: 2.4666664965240677

Epoch: 6| Step: 11
Training loss: 1.956785144674037
Validation loss: 2.5107462329715204

Epoch: 6| Step: 12
Training loss: 1.2382640175567985
Validation loss: 2.5050324344203383

Epoch: 6| Step: 13
Training loss: 1.7632273370413254
Validation loss: 2.4828469784677893

Epoch: 303| Step: 0
Training loss: 2.006567305431544
Validation loss: 2.491531636031537

Epoch: 6| Step: 1
Training loss: 2.514424292194776
Validation loss: 2.4832407778912087

Epoch: 6| Step: 2
Training loss: 2.391010527596776
Validation loss: 2.479210780195832

Epoch: 6| Step: 3
Training loss: 2.739657895387405
Validation loss: 2.445934209413243

Epoch: 6| Step: 4
Training loss: 2.2089774673853095
Validation loss: 2.4852481307911423

Epoch: 6| Step: 5
Training loss: 2.378014107523556
Validation loss: 2.4863434593983746

Epoch: 6| Step: 6
Training loss: 2.0447224954289003
Validation loss: 2.482136726340206

Epoch: 6| Step: 7
Training loss: 2.7489928221818754
Validation loss: 2.499029585453316

Epoch: 6| Step: 8
Training loss: 2.7594490706631976
Validation loss: 2.4518067247079594

Epoch: 6| Step: 9
Training loss: 1.7974357725083598
Validation loss: 2.4694483143095316

Epoch: 6| Step: 10
Training loss: 2.131159214983567
Validation loss: 2.4965165737041275

Epoch: 6| Step: 11
Training loss: 1.8738945563339622
Validation loss: 2.4730916297911483

Epoch: 6| Step: 12
Training loss: 2.206386235599309
Validation loss: 2.481404516165269

Epoch: 6| Step: 13
Training loss: 1.5949200094129428
Validation loss: 2.485971645759763

Epoch: 304| Step: 0
Training loss: 2.2350068166061328
Validation loss: 2.4871006550317096

Epoch: 6| Step: 1
Training loss: 1.513748737967837
Validation loss: 2.4752469279477274

Epoch: 6| Step: 2
Training loss: 1.9674591192048152
Validation loss: 2.4670986469369343

Epoch: 6| Step: 3
Training loss: 2.411765082494742
Validation loss: 2.478553846861905

Epoch: 6| Step: 4
Training loss: 1.9196022675744264
Validation loss: 2.537448031405888

Epoch: 6| Step: 5
Training loss: 2.519691355741461
Validation loss: 2.5147041393800738

Epoch: 6| Step: 6
Training loss: 2.494185265818935
Validation loss: 2.4929594185015853

Epoch: 6| Step: 7
Training loss: 1.8048093019807143
Validation loss: 2.520895091145858

Epoch: 6| Step: 8
Training loss: 1.9195919587747676
Validation loss: 2.4844518118064296

Epoch: 6| Step: 9
Training loss: 2.8206335503186346
Validation loss: 2.4755889251154404

Epoch: 6| Step: 10
Training loss: 1.9489645629761503
Validation loss: 2.497501303869237

Epoch: 6| Step: 11
Training loss: 2.742746323379029
Validation loss: 2.5295133589829653

Epoch: 6| Step: 12
Training loss: 2.7568478720849536
Validation loss: 2.500076581951017

Epoch: 6| Step: 13
Training loss: 2.2217900041292675
Validation loss: 2.512409488600851

Epoch: 305| Step: 0
Training loss: 1.8110751108805445
Validation loss: 2.5124849556035938

Epoch: 6| Step: 1
Training loss: 1.5441406435282536
Validation loss: 2.4774633867632003

Epoch: 6| Step: 2
Training loss: 1.7554939407422248
Validation loss: 2.489807003183847

Epoch: 6| Step: 3
Training loss: 2.2541423389675668
Validation loss: 2.474305638717188

Epoch: 6| Step: 4
Training loss: 2.723548075389439
Validation loss: 2.5012932068059675

Epoch: 6| Step: 5
Training loss: 2.194693590123416
Validation loss: 2.4855582335392787

Epoch: 6| Step: 6
Training loss: 2.790317883310627
Validation loss: 2.491792174097044

Epoch: 6| Step: 7
Training loss: 1.7289005519050786
Validation loss: 2.5040132913948967

Epoch: 6| Step: 8
Training loss: 2.343722737471649
Validation loss: 2.490072229049997

Epoch: 6| Step: 9
Training loss: 1.8799481269091933
Validation loss: 2.492203201068069

Epoch: 6| Step: 10
Training loss: 1.8763494086314212
Validation loss: 2.480639820305686

Epoch: 6| Step: 11
Training loss: 2.823063826625544
Validation loss: 2.455629689784008

Epoch: 6| Step: 12
Training loss: 2.908675627435904
Validation loss: 2.4997559571874404

Epoch: 6| Step: 13
Training loss: 2.8129433176545526
Validation loss: 2.5207831115791244

Epoch: 306| Step: 0
Training loss: 2.280570150998001
Validation loss: 2.492478029604338

Epoch: 6| Step: 1
Training loss: 2.525696867911726
Validation loss: 2.4564789531600426

Epoch: 6| Step: 2
Training loss: 2.1500313690026274
Validation loss: 2.422356901146717

Epoch: 6| Step: 3
Training loss: 3.029329300982966
Validation loss: 2.489702429290988

Epoch: 6| Step: 4
Training loss: 2.204703989379557
Validation loss: 2.5146383114674697

Epoch: 6| Step: 5
Training loss: 2.1737966475217068
Validation loss: 2.4838668572903626

Epoch: 6| Step: 6
Training loss: 2.4785920019383494
Validation loss: 2.4467073621928255

Epoch: 6| Step: 7
Training loss: 1.367908048127177
Validation loss: 2.4638157834064076

Epoch: 6| Step: 8
Training loss: 2.3485069320475698
Validation loss: 2.471283247039565

Epoch: 6| Step: 9
Training loss: 2.2607282666958013
Validation loss: 2.484255499354278

Epoch: 6| Step: 10
Training loss: 2.417017045326719
Validation loss: 2.4739968901880354

Epoch: 6| Step: 11
Training loss: 2.391881674783891
Validation loss: 2.468713591101924

Epoch: 6| Step: 12
Training loss: 0.9423056140963575
Validation loss: 2.491091056745435

Epoch: 6| Step: 13
Training loss: 2.2870618390128303
Validation loss: 2.4653355257522174

Epoch: 307| Step: 0
Training loss: 2.4030397476928465
Validation loss: 2.506073557458243

Epoch: 6| Step: 1
Training loss: 2.093144799062241
Validation loss: 2.4910370127616375

Epoch: 6| Step: 2
Training loss: 2.128026938174695
Validation loss: 2.5106274361393743

Epoch: 6| Step: 3
Training loss: 2.6707029393145687
Validation loss: 2.4883838550695154

Epoch: 6| Step: 4
Training loss: 2.010668196944878
Validation loss: 2.4872351293666664

Epoch: 6| Step: 5
Training loss: 2.271768173371773
Validation loss: 2.499413606105976

Epoch: 6| Step: 6
Training loss: 1.897631690037974
Validation loss: 2.479601288798555

Epoch: 6| Step: 7
Training loss: 2.6054376374407378
Validation loss: 2.4723759549193787

Epoch: 6| Step: 8
Training loss: 2.109372739437446
Validation loss: 2.516282842642545

Epoch: 6| Step: 9
Training loss: 2.374886359457419
Validation loss: 2.509947698823089

Epoch: 6| Step: 10
Training loss: 2.1034345832592525
Validation loss: 2.5105503723895937

Epoch: 6| Step: 11
Training loss: 2.0390909127196104
Validation loss: 2.4759720266312817

Epoch: 6| Step: 12
Training loss: 2.651991628383352
Validation loss: 2.504971303150143

Epoch: 6| Step: 13
Training loss: 2.051663221805179
Validation loss: 2.4725416274483614

Epoch: 308| Step: 0
Training loss: 1.3390718688993188
Validation loss: 2.475460522746568

Epoch: 6| Step: 1
Training loss: 2.3176974064144344
Validation loss: 2.4742390090108466

Epoch: 6| Step: 2
Training loss: 2.0369751283440922
Validation loss: 2.464249980718984

Epoch: 6| Step: 3
Training loss: 2.854448420593309
Validation loss: 2.464174391042753

Epoch: 6| Step: 4
Training loss: 1.7927591039224025
Validation loss: 2.4822543635944405

Epoch: 6| Step: 5
Training loss: 2.8027931552797396
Validation loss: 2.467742236552447

Epoch: 6| Step: 6
Training loss: 2.4893623051761438
Validation loss: 2.490549240393918

Epoch: 6| Step: 7
Training loss: 1.576156143431406
Validation loss: 2.459504763142934

Epoch: 6| Step: 8
Training loss: 2.0135734822666764
Validation loss: 2.4302506556691763

Epoch: 6| Step: 9
Training loss: 2.152989894575685
Validation loss: 2.486904140363608

Epoch: 6| Step: 10
Training loss: 2.5067847692114276
Validation loss: 2.4614419264229648

Epoch: 6| Step: 11
Training loss: 2.1372975571450787
Validation loss: 2.496915522375706

Epoch: 6| Step: 12
Training loss: 2.428879385744711
Validation loss: 2.483560740460583

Epoch: 6| Step: 13
Training loss: 2.6795010070855834
Validation loss: 2.480077086385902

Epoch: 309| Step: 0
Training loss: 2.453795323237512
Validation loss: 2.4656591156771976

Epoch: 6| Step: 1
Training loss: 2.308257464138685
Validation loss: 2.489788901794404

Epoch: 6| Step: 2
Training loss: 2.9625920728065074
Validation loss: 2.5042797925545957

Epoch: 6| Step: 3
Training loss: 1.7514532050029727
Validation loss: 2.46016786998823

Epoch: 6| Step: 4
Training loss: 2.102277782912115
Validation loss: 2.4910611656706814

Epoch: 6| Step: 5
Training loss: 2.0941259701356043
Validation loss: 2.4796397058703756

Epoch: 6| Step: 6
Training loss: 1.8687022939863387
Validation loss: 2.486292550935003

Epoch: 6| Step: 7
Training loss: 2.170827928806052
Validation loss: 2.4655316789178845

Epoch: 6| Step: 8
Training loss: 1.6966936664394063
Validation loss: 2.4761467662319054

Epoch: 6| Step: 9
Training loss: 2.6725023213618218
Validation loss: 2.4893732008414755

Epoch: 6| Step: 10
Training loss: 2.162874081400068
Validation loss: 2.481111927860447

Epoch: 6| Step: 11
Training loss: 2.2216936383490555
Validation loss: 2.4841710499206218

Epoch: 6| Step: 12
Training loss: 2.669723894080393
Validation loss: 2.5234376838836656

Epoch: 6| Step: 13
Training loss: 1.7986180351578998
Validation loss: 2.456301254075455

Epoch: 310| Step: 0
Training loss: 2.132344736079588
Validation loss: 2.452551171692576

Epoch: 6| Step: 1
Training loss: 2.0281738463457653
Validation loss: 2.4799839663872123

Epoch: 6| Step: 2
Training loss: 2.599173700637652
Validation loss: 2.4752920710743247

Epoch: 6| Step: 3
Training loss: 2.112995798290027
Validation loss: 2.5082271129559204

Epoch: 6| Step: 4
Training loss: 2.166541927365974
Validation loss: 2.4869541858684894

Epoch: 6| Step: 5
Training loss: 1.8421905517552848
Validation loss: 2.443755974012343

Epoch: 6| Step: 6
Training loss: 2.415097011884356
Validation loss: 2.4610506546406214

Epoch: 6| Step: 7
Training loss: 2.4591118716636657
Validation loss: 2.4816950648833664

Epoch: 6| Step: 8
Training loss: 2.254046298589832
Validation loss: 2.446016152416479

Epoch: 6| Step: 9
Training loss: 2.4366868447835097
Validation loss: 2.522132840287246

Epoch: 6| Step: 10
Training loss: 2.432803593633344
Validation loss: 2.4711997890336916

Epoch: 6| Step: 11
Training loss: 1.9672897009324832
Validation loss: 2.513645297838057

Epoch: 6| Step: 12
Training loss: 2.4189699531319677
Validation loss: 2.4844615733130335

Epoch: 6| Step: 13
Training loss: 2.2407343072976946
Validation loss: 2.477240224406752

Epoch: 311| Step: 0
Training loss: 1.9268373143324609
Validation loss: 2.4451155855996856

Epoch: 6| Step: 1
Training loss: 2.1793278223067034
Validation loss: 2.4895324173221285

Epoch: 6| Step: 2
Training loss: 2.395510400210078
Validation loss: 2.4811305306539975

Epoch: 6| Step: 3
Training loss: 1.758866464626284
Validation loss: 2.4731440725582123

Epoch: 6| Step: 4
Training loss: 2.3454433173407536
Validation loss: 2.480818229294031

Epoch: 6| Step: 5
Training loss: 1.7810577824261684
Validation loss: 2.5017604607846473

Epoch: 6| Step: 6
Training loss: 2.8457927702828334
Validation loss: 2.492481482961747

Epoch: 6| Step: 7
Training loss: 2.4485923537975207
Validation loss: 2.482108132105627

Epoch: 6| Step: 8
Training loss: 1.8644035366328444
Validation loss: 2.5038873003925914

Epoch: 6| Step: 9
Training loss: 2.5285463375758632
Validation loss: 2.4735550832978466

Epoch: 6| Step: 10
Training loss: 2.5500178691761506
Validation loss: 2.5137456601079213

Epoch: 6| Step: 11
Training loss: 2.42415408295003
Validation loss: 2.4728781113257914

Epoch: 6| Step: 12
Training loss: 1.7782646057352838
Validation loss: 2.4661808438722375

Epoch: 6| Step: 13
Training loss: 2.3726099938640144
Validation loss: 2.4872276174748693

Epoch: 312| Step: 0
Training loss: 2.0537462290417534
Validation loss: 2.470356775693532

Epoch: 6| Step: 1
Training loss: 1.8998601159251194
Validation loss: 2.4813502333125275

Epoch: 6| Step: 2
Training loss: 2.751617476148599
Validation loss: 2.494978090816801

Epoch: 6| Step: 3
Training loss: 2.2470607633027213
Validation loss: 2.4865356695857352

Epoch: 6| Step: 4
Training loss: 2.179740877762642
Validation loss: 2.505528061703051

Epoch: 6| Step: 5
Training loss: 2.6968120439414944
Validation loss: 2.4748132814970356

Epoch: 6| Step: 6
Training loss: 1.9677338172577699
Validation loss: 2.4620827849407174

Epoch: 6| Step: 7
Training loss: 1.866231506010736
Validation loss: 2.495756269849076

Epoch: 6| Step: 8
Training loss: 2.1497654365511463
Validation loss: 2.452226462085659

Epoch: 6| Step: 9
Training loss: 2.0798353456469676
Validation loss: 2.4805146807131635

Epoch: 6| Step: 10
Training loss: 2.7239323475596877
Validation loss: 2.5138165069897256

Epoch: 6| Step: 11
Training loss: 1.8668913027725524
Validation loss: 2.489918449447857

Epoch: 6| Step: 12
Training loss: 2.456250962895406
Validation loss: 2.4992215175032686

Epoch: 6| Step: 13
Training loss: 2.0254703163941934
Validation loss: 2.479646170173291

Epoch: 313| Step: 0
Training loss: 2.288842929555621
Validation loss: 2.4812303720800704

Epoch: 6| Step: 1
Training loss: 2.328865394374687
Validation loss: 2.4795854200520835

Epoch: 6| Step: 2
Training loss: 2.9196546961793057
Validation loss: 2.4853753333084483

Epoch: 6| Step: 3
Training loss: 2.3489462661151257
Validation loss: 2.467276812118847

Epoch: 6| Step: 4
Training loss: 2.3308676112026117
Validation loss: 2.471906509863377

Epoch: 6| Step: 5
Training loss: 2.0516581086704107
Validation loss: 2.490344309462306

Epoch: 6| Step: 6
Training loss: 2.0551033324461447
Validation loss: 2.508677081103925

Epoch: 6| Step: 7
Training loss: 2.426893486052749
Validation loss: 2.4855473871614384

Epoch: 6| Step: 8
Training loss: 1.7537414881199909
Validation loss: 2.4678694106127392

Epoch: 6| Step: 9
Training loss: 2.384177895494739
Validation loss: 2.478503806544049

Epoch: 6| Step: 10
Training loss: 1.935629095184655
Validation loss: 2.5029880929658384

Epoch: 6| Step: 11
Training loss: 1.8968345876596342
Validation loss: 2.4720514324983274

Epoch: 6| Step: 12
Training loss: 2.4145127157483555
Validation loss: 2.4685810109675743

Epoch: 6| Step: 13
Training loss: 2.3883286960270174
Validation loss: 2.4664102164784922

Epoch: 314| Step: 0
Training loss: 2.385812840330971
Validation loss: 2.4514812916592152

Epoch: 6| Step: 1
Training loss: 2.0263876599116437
Validation loss: 2.463195068943273

Epoch: 6| Step: 2
Training loss: 2.2638494440034536
Validation loss: 2.490059301023793

Epoch: 6| Step: 3
Training loss: 2.3492262885502693
Validation loss: 2.513156559015431

Epoch: 6| Step: 4
Training loss: 2.4163716454036903
Validation loss: 2.494747084311473

Epoch: 6| Step: 5
Training loss: 2.193213059665077
Validation loss: 2.4612415001597747

Epoch: 6| Step: 6
Training loss: 2.2144486547543742
Validation loss: 2.475246234021215

Epoch: 6| Step: 7
Training loss: 2.4043465554181296
Validation loss: 2.5041978058496372

Epoch: 6| Step: 8
Training loss: 1.6027445083212288
Validation loss: 2.4892337708295487

Epoch: 6| Step: 9
Training loss: 2.576973952920037
Validation loss: 2.5172664866604735

Epoch: 6| Step: 10
Training loss: 2.20258730556204
Validation loss: 2.4478010336628926

Epoch: 6| Step: 11
Training loss: 1.5558507200283371
Validation loss: 2.5124556129227202

Epoch: 6| Step: 12
Training loss: 2.832185812053832
Validation loss: 2.49984506414081

Epoch: 6| Step: 13
Training loss: 2.1095853347462423
Validation loss: 2.485919404507491

Epoch: 315| Step: 0
Training loss: 2.8200910063864533
Validation loss: 2.4909101395062767

Epoch: 6| Step: 1
Training loss: 1.7102565716786031
Validation loss: 2.495803773284397

Epoch: 6| Step: 2
Training loss: 2.5262799861738365
Validation loss: 2.473899279128693

Epoch: 6| Step: 3
Training loss: 2.471652003283572
Validation loss: 2.4879932870241794

Epoch: 6| Step: 4
Training loss: 2.122875497984714
Validation loss: 2.4344666788122904

Epoch: 6| Step: 5
Training loss: 1.6410257485814548
Validation loss: 2.4472622351158955

Epoch: 6| Step: 6
Training loss: 1.6642726711742082
Validation loss: 2.471559023286314

Epoch: 6| Step: 7
Training loss: 1.626404888567729
Validation loss: 2.4596162722521813

Epoch: 6| Step: 8
Training loss: 1.9479174962441486
Validation loss: 2.492837753224857

Epoch: 6| Step: 9
Training loss: 2.5934425999128976
Validation loss: 2.491943287746774

Epoch: 6| Step: 10
Training loss: 2.191217043727286
Validation loss: 2.4930799528780985

Epoch: 6| Step: 11
Training loss: 2.924630727036555
Validation loss: 2.464389584254826

Epoch: 6| Step: 12
Training loss: 2.5102654460351608
Validation loss: 2.4440759900922973

Epoch: 6| Step: 13
Training loss: 1.9892778278555525
Validation loss: 2.481831228679177

Epoch: 316| Step: 0
Training loss: 2.459156275793719
Validation loss: 2.500012104456321

Epoch: 6| Step: 1
Training loss: 2.67494114962576
Validation loss: 2.4745599842604937

Epoch: 6| Step: 2
Training loss: 2.1790671063856846
Validation loss: 2.4894985397863776

Epoch: 6| Step: 3
Training loss: 2.02316011272856
Validation loss: 2.4707917793798657

Epoch: 6| Step: 4
Training loss: 2.2187910479120005
Validation loss: 2.4672038193802748

Epoch: 6| Step: 5
Training loss: 1.9145278676341788
Validation loss: 2.4724037326459203

Epoch: 6| Step: 6
Training loss: 1.7418781912575607
Validation loss: 2.4663239554307066

Epoch: 6| Step: 7
Training loss: 2.9929529709924054
Validation loss: 2.4777752811783444

Epoch: 6| Step: 8
Training loss: 2.807225686019222
Validation loss: 2.4690835451472983

Epoch: 6| Step: 9
Training loss: 1.9252235580033337
Validation loss: 2.4582089159227527

Epoch: 6| Step: 10
Training loss: 1.7821058258547073
Validation loss: 2.48436596564948

Epoch: 6| Step: 11
Training loss: 2.2820694379213418
Validation loss: 2.4637347196051427

Epoch: 6| Step: 12
Training loss: 1.9877627432991272
Validation loss: 2.4529597410477932

Epoch: 6| Step: 13
Training loss: 1.400919836861747
Validation loss: 2.4938713385309725

Epoch: 317| Step: 0
Training loss: 2.0419905528897093
Validation loss: 2.473683105772075

Epoch: 6| Step: 1
Training loss: 2.2655052416489716
Validation loss: 2.4746721793275293

Epoch: 6| Step: 2
Training loss: 2.187146403480752
Validation loss: 2.5207218751307416

Epoch: 6| Step: 3
Training loss: 1.9814247367170346
Validation loss: 2.4861808524248437

Epoch: 6| Step: 4
Training loss: 1.7707805476081657
Validation loss: 2.4856427895190527

Epoch: 6| Step: 5
Training loss: 2.23908457562145
Validation loss: 2.483415781304064

Epoch: 6| Step: 6
Training loss: 2.426140259546113
Validation loss: 2.512050666886994

Epoch: 6| Step: 7
Training loss: 2.475665775493918
Validation loss: 2.473439427582343

Epoch: 6| Step: 8
Training loss: 2.342297727142757
Validation loss: 2.4883684822475827

Epoch: 6| Step: 9
Training loss: 2.5732012345531508
Validation loss: 2.5341952027518424

Epoch: 6| Step: 10
Training loss: 1.7039359025854315
Validation loss: 2.472321870980188

Epoch: 6| Step: 11
Training loss: 2.3127967025532765
Validation loss: 2.4654511768906806

Epoch: 6| Step: 12
Training loss: 2.246628035978243
Validation loss: 2.4959447785676177

Epoch: 6| Step: 13
Training loss: 2.8792972790856624
Validation loss: 2.502070118481908

Epoch: 318| Step: 0
Training loss: 2.506946925346671
Validation loss: 2.452219525099308

Epoch: 6| Step: 1
Training loss: 1.4782392074627098
Validation loss: 2.482642795467786

Epoch: 6| Step: 2
Training loss: 1.7784566559913655
Validation loss: 2.4755535716075525

Epoch: 6| Step: 3
Training loss: 2.2892869442213177
Validation loss: 2.512968898676271

Epoch: 6| Step: 4
Training loss: 1.6584087194946835
Validation loss: 2.471456261186866

Epoch: 6| Step: 5
Training loss: 1.9604821151310663
Validation loss: 2.5021538321519476

Epoch: 6| Step: 6
Training loss: 2.094900128480908
Validation loss: 2.505277410184251

Epoch: 6| Step: 7
Training loss: 1.9607176030488531
Validation loss: 2.497871033867325

Epoch: 6| Step: 8
Training loss: 2.7129039832734474
Validation loss: 2.497571207355333

Epoch: 6| Step: 9
Training loss: 2.1396219172677537
Validation loss: 2.5157767863854206

Epoch: 6| Step: 10
Training loss: 2.261493889101431
Validation loss: 2.5201333315703303

Epoch: 6| Step: 11
Training loss: 2.833185379054792
Validation loss: 2.4809493892661685

Epoch: 6| Step: 12
Training loss: 2.830231445877076
Validation loss: 2.4834578783140873

Epoch: 6| Step: 13
Training loss: 2.76504053524167
Validation loss: 2.4773466841264438

Epoch: 319| Step: 0
Training loss: 1.958897232140795
Validation loss: 2.4871460602463915

Epoch: 6| Step: 1
Training loss: 2.452265011634423
Validation loss: 2.4758453578189425

Epoch: 6| Step: 2
Training loss: 2.243303612639231
Validation loss: 2.498262968909323

Epoch: 6| Step: 3
Training loss: 2.086682133155192
Validation loss: 2.458375529627022

Epoch: 6| Step: 4
Training loss: 1.5438055545833966
Validation loss: 2.467286830683728

Epoch: 6| Step: 5
Training loss: 2.2316724532234926
Validation loss: 2.488943000035612

Epoch: 6| Step: 6
Training loss: 1.807724614096618
Validation loss: 2.4453846805710873

Epoch: 6| Step: 7
Training loss: 2.600662029784736
Validation loss: 2.506141005122165

Epoch: 6| Step: 8
Training loss: 2.119963230497956
Validation loss: 2.4988592057371872

Epoch: 6| Step: 9
Training loss: 2.244285957271892
Validation loss: 2.463874690495522

Epoch: 6| Step: 10
Training loss: 2.094872927943009
Validation loss: 2.485527259970876

Epoch: 6| Step: 11
Training loss: 2.751784092711783
Validation loss: 2.462484308741138

Epoch: 6| Step: 12
Training loss: 2.602411538268719
Validation loss: 2.4762374552306765

Epoch: 6| Step: 13
Training loss: 2.3405487577807107
Validation loss: 2.4800296796953893

Epoch: 320| Step: 0
Training loss: 1.938884056173943
Validation loss: 2.478522677155254

Epoch: 6| Step: 1
Training loss: 1.8615790375132977
Validation loss: 2.461540168947183

Epoch: 6| Step: 2
Training loss: 2.882260980547277
Validation loss: 2.4775291950770586

Epoch: 6| Step: 3
Training loss: 1.8682267237841295
Validation loss: 2.5021882540004654

Epoch: 6| Step: 4
Training loss: 2.233663485686969
Validation loss: 2.500522290298421

Epoch: 6| Step: 5
Training loss: 2.3424512189184847
Validation loss: 2.476428950293038

Epoch: 6| Step: 6
Training loss: 2.2465282782806777
Validation loss: 2.473891777520663

Epoch: 6| Step: 7
Training loss: 2.1627409166853706
Validation loss: 2.4397901126593444

Epoch: 6| Step: 8
Training loss: 2.2864723523752195
Validation loss: 2.4881810176653936

Epoch: 6| Step: 9
Training loss: 2.142328405997901
Validation loss: 2.4860382074735745

Epoch: 6| Step: 10
Training loss: 2.4340940301077127
Validation loss: 2.4715134136603893

Epoch: 6| Step: 11
Training loss: 2.354644985612537
Validation loss: 2.4479699957455403

Epoch: 6| Step: 12
Training loss: 2.2638035259522344
Validation loss: 2.449435389003301

Epoch: 6| Step: 13
Training loss: 1.723644777423946
Validation loss: 2.4772334221463708

Epoch: 321| Step: 0
Training loss: 2.515628222350906
Validation loss: 2.4909892095030575

Epoch: 6| Step: 1
Training loss: 2.496696005505815
Validation loss: 2.4734140878846698

Epoch: 6| Step: 2
Training loss: 1.7684045703691684
Validation loss: 2.483321396966319

Epoch: 6| Step: 3
Training loss: 3.0774674850964994
Validation loss: 2.431970050728084

Epoch: 6| Step: 4
Training loss: 2.5017084959507487
Validation loss: 2.511530072741694

Epoch: 6| Step: 5
Training loss: 2.178199944103038
Validation loss: 2.4693102311928037

Epoch: 6| Step: 6
Training loss: 2.1740597501262795
Validation loss: 2.4816535484953284

Epoch: 6| Step: 7
Training loss: 2.400701293209705
Validation loss: 2.4461486900578726

Epoch: 6| Step: 8
Training loss: 2.0482623807425138
Validation loss: 2.461464599164242

Epoch: 6| Step: 9
Training loss: 1.6206327587196472
Validation loss: 2.4866145121709513

Epoch: 6| Step: 10
Training loss: 2.0890954505073642
Validation loss: 2.4400223081003696

Epoch: 6| Step: 11
Training loss: 2.1553102739899765
Validation loss: 2.4601732928584847

Epoch: 6| Step: 12
Training loss: 1.90062170397828
Validation loss: 2.4746372840873736

Epoch: 6| Step: 13
Training loss: 2.0859439006807228
Validation loss: 2.4960010272615034

Epoch: 322| Step: 0
Training loss: 1.9123935196100292
Validation loss: 2.498534897170478

Epoch: 6| Step: 1
Training loss: 2.2360784266303146
Validation loss: 2.475745581919148

Epoch: 6| Step: 2
Training loss: 2.0023794325061455
Validation loss: 2.490116403332084

Epoch: 6| Step: 3
Training loss: 2.318874234472735
Validation loss: 2.476861109351195

Epoch: 6| Step: 4
Training loss: 2.8216970326351363
Validation loss: 2.47138356823518

Epoch: 6| Step: 5
Training loss: 1.6077997590830821
Validation loss: 2.442511344733271

Epoch: 6| Step: 6
Training loss: 1.8702124190423097
Validation loss: 2.476579799030754

Epoch: 6| Step: 7
Training loss: 2.0213702035995285
Validation loss: 2.4769023624410496

Epoch: 6| Step: 8
Training loss: 2.3247762059618546
Validation loss: 2.457002465844945

Epoch: 6| Step: 9
Training loss: 2.359639740295008
Validation loss: 2.5037651155977283

Epoch: 6| Step: 10
Training loss: 2.0047829180849033
Validation loss: 2.49077749494802

Epoch: 6| Step: 11
Training loss: 2.1345206885372887
Validation loss: 2.5088004383725657

Epoch: 6| Step: 12
Training loss: 2.4894676554046464
Validation loss: 2.514228204231725

Epoch: 6| Step: 13
Training loss: 2.7758242371073316
Validation loss: 2.435444314452479

Epoch: 323| Step: 0
Training loss: 2.4021847555999147
Validation loss: 2.466648061106232

Epoch: 6| Step: 1
Training loss: 2.2413407165584256
Validation loss: 2.4752138761155047

Epoch: 6| Step: 2
Training loss: 2.9408965258043813
Validation loss: 2.4740280744289542

Epoch: 6| Step: 3
Training loss: 2.0258122357559634
Validation loss: 2.4715894655395383

Epoch: 6| Step: 4
Training loss: 1.4842999891100583
Validation loss: 2.4683448310527707

Epoch: 6| Step: 5
Training loss: 2.3202245419460654
Validation loss: 2.444222698155186

Epoch: 6| Step: 6
Training loss: 2.2396204272606384
Validation loss: 2.4795129344085947

Epoch: 6| Step: 7
Training loss: 2.531164191404595
Validation loss: 2.4765595187348497

Epoch: 6| Step: 8
Training loss: 2.3743606509914543
Validation loss: 2.4652081653388254

Epoch: 6| Step: 9
Training loss: 2.1919784478847437
Validation loss: 2.442045532796281

Epoch: 6| Step: 10
Training loss: 1.569194718507061
Validation loss: 2.4516947704745076

Epoch: 6| Step: 11
Training loss: 2.4051584517531377
Validation loss: 2.489149077293334

Epoch: 6| Step: 12
Training loss: 2.1457820503501703
Validation loss: 2.5109635628251596

Epoch: 6| Step: 13
Training loss: 1.5477253281776273
Validation loss: 2.4928901621233304

Epoch: 324| Step: 0
Training loss: 2.4386427719185853
Validation loss: 2.467765379145624

Epoch: 6| Step: 1
Training loss: 1.7038989627057888
Validation loss: 2.473346494567469

Epoch: 6| Step: 2
Training loss: 1.5141287427963195
Validation loss: 2.4446523310510577

Epoch: 6| Step: 3
Training loss: 1.629423283548199
Validation loss: 2.4879215285876017

Epoch: 6| Step: 4
Training loss: 1.7578101942259183
Validation loss: 2.493794406167867

Epoch: 6| Step: 5
Training loss: 2.3967487963459257
Validation loss: 2.4791803198466273

Epoch: 6| Step: 6
Training loss: 2.493744940501652
Validation loss: 2.4701301991824836

Epoch: 6| Step: 7
Training loss: 2.5384052071401024
Validation loss: 2.4809247514450794

Epoch: 6| Step: 8
Training loss: 2.0381102695301254
Validation loss: 2.498333018344894

Epoch: 6| Step: 9
Training loss: 2.544505977534392
Validation loss: 2.441765564956687

Epoch: 6| Step: 10
Training loss: 2.4820944437321883
Validation loss: 2.4945052890662445

Epoch: 6| Step: 11
Training loss: 2.7355165550973495
Validation loss: 2.4783120544098485

Epoch: 6| Step: 12
Training loss: 2.0173762793817875
Validation loss: 2.437626016376304

Epoch: 6| Step: 13
Training loss: 2.088681933733903
Validation loss: 2.475583553618473

Epoch: 325| Step: 0
Training loss: 1.981910436644864
Validation loss: 2.4715951278464843

Epoch: 6| Step: 1
Training loss: 2.9329142386705556
Validation loss: 2.4568443483536146

Epoch: 6| Step: 2
Training loss: 2.751723529667911
Validation loss: 2.4607310427103823

Epoch: 6| Step: 3
Training loss: 2.4968076350705575
Validation loss: 2.471916166900588

Epoch: 6| Step: 4
Training loss: 2.438020112715915
Validation loss: 2.4899571706547206

Epoch: 6| Step: 5
Training loss: 1.7745750912632186
Validation loss: 2.4633510314391334

Epoch: 6| Step: 6
Training loss: 2.655695599313095
Validation loss: 2.493716041427688

Epoch: 6| Step: 7
Training loss: 1.4871135947085194
Validation loss: 2.502246991304648

Epoch: 6| Step: 8
Training loss: 1.3981799096216103
Validation loss: 2.475064168947365

Epoch: 6| Step: 9
Training loss: 1.764730716511881
Validation loss: 2.494219627532516

Epoch: 6| Step: 10
Training loss: 1.9497501359928033
Validation loss: 2.5100802352423264

Epoch: 6| Step: 11
Training loss: 2.2294539031836695
Validation loss: 2.4791958421903635

Epoch: 6| Step: 12
Training loss: 2.5132340151374186
Validation loss: 2.4690543781899517

Epoch: 6| Step: 13
Training loss: 2.270025780485187
Validation loss: 2.4971176626079012

Epoch: 326| Step: 0
Training loss: 1.6285400710875424
Validation loss: 2.4896459795984827

Epoch: 6| Step: 1
Training loss: 1.868687749227722
Validation loss: 2.477979838357778

Epoch: 6| Step: 2
Training loss: 2.1938745533941253
Validation loss: 2.4938604563501

Epoch: 6| Step: 3
Training loss: 2.520217967522016
Validation loss: 2.445531444307175

Epoch: 6| Step: 4
Training loss: 2.436997777600502
Validation loss: 2.4847832368393883

Epoch: 6| Step: 5
Training loss: 2.5090178923229267
Validation loss: 2.4482826118216523

Epoch: 6| Step: 6
Training loss: 2.0446210492375725
Validation loss: 2.4877090701601867

Epoch: 6| Step: 7
Training loss: 1.6412580449531058
Validation loss: 2.488123146603328

Epoch: 6| Step: 8
Training loss: 2.405693088835502
Validation loss: 2.455909112139557

Epoch: 6| Step: 9
Training loss: 2.087813430372538
Validation loss: 2.4882574338013543

Epoch: 6| Step: 10
Training loss: 2.3011391430976085
Validation loss: 2.4944534731905392

Epoch: 6| Step: 11
Training loss: 2.3296155830197476
Validation loss: 2.503132182904925

Epoch: 6| Step: 12
Training loss: 2.590607543444748
Validation loss: 2.4633939500558695

Epoch: 6| Step: 13
Training loss: 2.4087380761018196
Validation loss: 2.4720667424182614

Epoch: 327| Step: 0
Training loss: 2.202489450106863
Validation loss: 2.470111394189328

Epoch: 6| Step: 1
Training loss: 2.3371886918133367
Validation loss: 2.499063519975388

Epoch: 6| Step: 2
Training loss: 2.5244493847262857
Validation loss: 2.472919494097612

Epoch: 6| Step: 3
Training loss: 2.0966299945715177
Validation loss: 2.435547964433955

Epoch: 6| Step: 4
Training loss: 2.107453551951457
Validation loss: 2.471155632435995

Epoch: 6| Step: 5
Training loss: 2.0863204775928814
Validation loss: 2.476209551237302

Epoch: 6| Step: 6
Training loss: 2.299594851759494
Validation loss: 2.495157045554499

Epoch: 6| Step: 7
Training loss: 2.455741507430772
Validation loss: 2.468657869214144

Epoch: 6| Step: 8
Training loss: 2.0570370544745775
Validation loss: 2.506103021919462

Epoch: 6| Step: 9
Training loss: 1.9833901431925907
Validation loss: 2.4739949078708707

Epoch: 6| Step: 10
Training loss: 1.7912341268492322
Validation loss: 2.485631506203394

Epoch: 6| Step: 11
Training loss: 2.775750197997314
Validation loss: 2.4494931944738347

Epoch: 6| Step: 12
Training loss: 2.0353707403691184
Validation loss: 2.428278793971736

Epoch: 6| Step: 13
Training loss: 1.6505810148133906
Validation loss: 2.492775139179274

Epoch: 328| Step: 0
Training loss: 2.4547312149244394
Validation loss: 2.5110685683020173

Epoch: 6| Step: 1
Training loss: 2.125339368760567
Validation loss: 2.4594971603019165

Epoch: 6| Step: 2
Training loss: 1.827774405484372
Validation loss: 2.4748411621289383

Epoch: 6| Step: 3
Training loss: 2.091620429795728
Validation loss: 2.435184026384684

Epoch: 6| Step: 4
Training loss: 2.4389121048946416
Validation loss: 2.4479189322693933

Epoch: 6| Step: 5
Training loss: 2.2051791091109307
Validation loss: 2.477189945398928

Epoch: 6| Step: 6
Training loss: 2.314108005980336
Validation loss: 2.520203762886075

Epoch: 6| Step: 7
Training loss: 2.3693493328953212
Validation loss: 2.500589304347985

Epoch: 6| Step: 8
Training loss: 2.571026271049322
Validation loss: 2.477423598980868

Epoch: 6| Step: 9
Training loss: 2.22097505566958
Validation loss: 2.492864846342103

Epoch: 6| Step: 10
Training loss: 2.353125271537532
Validation loss: 2.4609553687870678

Epoch: 6| Step: 11
Training loss: 2.040082303799142
Validation loss: 2.451828699209299

Epoch: 6| Step: 12
Training loss: 1.881401324601922
Validation loss: 2.467468691424631

Epoch: 6| Step: 13
Training loss: 1.8846226771406713
Validation loss: 2.4407339443097964

Epoch: 329| Step: 0
Training loss: 1.9432728197001259
Validation loss: 2.4671589137664416

Epoch: 6| Step: 1
Training loss: 2.126655382626691
Validation loss: 2.493349766426502

Epoch: 6| Step: 2
Training loss: 2.297365512502237
Validation loss: 2.45463955850809

Epoch: 6| Step: 3
Training loss: 2.088866616811224
Validation loss: 2.445238223601137

Epoch: 6| Step: 4
Training loss: 2.181167701545859
Validation loss: 2.4812490070481856

Epoch: 6| Step: 5
Training loss: 2.4692741513640657
Validation loss: 2.4688982406975963

Epoch: 6| Step: 6
Training loss: 2.235595583147623
Validation loss: 2.423426182892899

Epoch: 6| Step: 7
Training loss: 2.4110814919925567
Validation loss: 2.4887165210391515

Epoch: 6| Step: 8
Training loss: 1.8844439138080842
Validation loss: 2.4930333004085523

Epoch: 6| Step: 9
Training loss: 2.179527358868578
Validation loss: 2.5010951483989086

Epoch: 6| Step: 10
Training loss: 2.712718982910489
Validation loss: 2.4611006133672775

Epoch: 6| Step: 11
Training loss: 2.4132638739852252
Validation loss: 2.4558888140764417

Epoch: 6| Step: 12
Training loss: 2.008210970157065
Validation loss: 2.4679762008039243

Epoch: 6| Step: 13
Training loss: 1.3587763553369008
Validation loss: 2.471918287264175

Epoch: 330| Step: 0
Training loss: 1.9522734960255161
Validation loss: 2.4414009377042336

Epoch: 6| Step: 1
Training loss: 2.252325339875549
Validation loss: 2.484591901229916

Epoch: 6| Step: 2
Training loss: 1.7992856648069289
Validation loss: 2.508353406194662

Epoch: 6| Step: 3
Training loss: 2.4790734879964167
Validation loss: 2.4544370768819532

Epoch: 6| Step: 4
Training loss: 1.990923192372942
Validation loss: 2.4451697670012065

Epoch: 6| Step: 5
Training loss: 1.5736416120828811
Validation loss: 2.4920465722235705

Epoch: 6| Step: 6
Training loss: 1.7682782383113036
Validation loss: 2.51908744355794

Epoch: 6| Step: 7
Training loss: 2.3529981115408996
Validation loss: 2.4979172552494084

Epoch: 6| Step: 8
Training loss: 2.1429947036912687
Validation loss: 2.4712534747956507

Epoch: 6| Step: 9
Training loss: 1.6442879612388754
Validation loss: 2.4494958591170852

Epoch: 6| Step: 10
Training loss: 2.9900565664496797
Validation loss: 2.4759118583556154

Epoch: 6| Step: 11
Training loss: 2.6110766681356417
Validation loss: 2.4393067207247565

Epoch: 6| Step: 12
Training loss: 2.5883961770345567
Validation loss: 2.4558687695092396

Epoch: 6| Step: 13
Training loss: 2.330852165741637
Validation loss: 2.459236401150041

Epoch: 331| Step: 0
Training loss: 1.8608571404339136
Validation loss: 2.465298858449228

Epoch: 6| Step: 1
Training loss: 2.4832653710540424
Validation loss: 2.480866102464422

Epoch: 6| Step: 2
Training loss: 2.8188175032625327
Validation loss: 2.4718852023326705

Epoch: 6| Step: 3
Training loss: 2.270289177981553
Validation loss: 2.4711000299366965

Epoch: 6| Step: 4
Training loss: 2.950701006342901
Validation loss: 2.446498047338105

Epoch: 6| Step: 5
Training loss: 1.5985461603634548
Validation loss: 2.4768679695608924

Epoch: 6| Step: 6
Training loss: 2.1045558556929405
Validation loss: 2.45860678262748

Epoch: 6| Step: 7
Training loss: 2.3085412860208274
Validation loss: 2.5110848297201005

Epoch: 6| Step: 8
Training loss: 2.062259197627559
Validation loss: 2.485408567704842

Epoch: 6| Step: 9
Training loss: 1.9417770921907684
Validation loss: 2.466578931739253

Epoch: 6| Step: 10
Training loss: 1.9439438750795324
Validation loss: 2.4905866805691366

Epoch: 6| Step: 11
Training loss: 2.030327690247354
Validation loss: 2.4751074334149217

Epoch: 6| Step: 12
Training loss: 2.242027782108114
Validation loss: 2.477008771478374

Epoch: 6| Step: 13
Training loss: 2.2240270266022786
Validation loss: 2.474726427375095

Epoch: 332| Step: 0
Training loss: 2.3204345671016444
Validation loss: 2.4902553144873907

Epoch: 6| Step: 1
Training loss: 1.8506582764349244
Validation loss: 2.4815906677523936

Epoch: 6| Step: 2
Training loss: 1.4891953752280411
Validation loss: 2.4631492945561617

Epoch: 6| Step: 3
Training loss: 2.086904694425043
Validation loss: 2.451513507918986

Epoch: 6| Step: 4
Training loss: 2.026313064036228
Validation loss: 2.4812261297019473

Epoch: 6| Step: 5
Training loss: 2.145351676833255
Validation loss: 2.4304015188633494

Epoch: 6| Step: 6
Training loss: 2.2154936198678823
Validation loss: 2.4582735220875755

Epoch: 6| Step: 7
Training loss: 2.6730226427825343
Validation loss: 2.465607589859221

Epoch: 6| Step: 8
Training loss: 2.1102922493906227
Validation loss: 2.4400709606569375

Epoch: 6| Step: 9
Training loss: 2.7696688124224114
Validation loss: 2.4667275637709243

Epoch: 6| Step: 10
Training loss: 2.922633761044358
Validation loss: 2.484624359872436

Epoch: 6| Step: 11
Training loss: 2.191292989323284
Validation loss: 2.4751817964004044

Epoch: 6| Step: 12
Training loss: 1.8848087602334058
Validation loss: 2.4257456028310744

Epoch: 6| Step: 13
Training loss: 1.4502680596494835
Validation loss: 2.454802056458905

Epoch: 333| Step: 0
Training loss: 1.9445429126087834
Validation loss: 2.4671051269542725

Epoch: 6| Step: 1
Training loss: 1.9942854063734143
Validation loss: 2.447427992435775

Epoch: 6| Step: 2
Training loss: 2.25767036175375
Validation loss: 2.4716729342434736

Epoch: 6| Step: 3
Training loss: 2.333628658497165
Validation loss: 2.455852782382967

Epoch: 6| Step: 4
Training loss: 2.2478552238639375
Validation loss: 2.457214795183863

Epoch: 6| Step: 5
Training loss: 2.3613533668651896
Validation loss: 2.4847034596578306

Epoch: 6| Step: 6
Training loss: 3.060379851457181
Validation loss: 2.4719283243531143

Epoch: 6| Step: 7
Training loss: 1.2873616412734858
Validation loss: 2.465745330323538

Epoch: 6| Step: 8
Training loss: 2.0486875473102057
Validation loss: 2.4853514748224814

Epoch: 6| Step: 9
Training loss: 2.223480232777107
Validation loss: 2.4973241452347006

Epoch: 6| Step: 10
Training loss: 1.9471561014640373
Validation loss: 2.457486933154767

Epoch: 6| Step: 11
Training loss: 2.5790370368324522
Validation loss: 2.483761010428314

Epoch: 6| Step: 12
Training loss: 1.7556828462082001
Validation loss: 2.453061265171697

Epoch: 6| Step: 13
Training loss: 2.109642407457081
Validation loss: 2.4750045752294003

Epoch: 334| Step: 0
Training loss: 1.9157348800434872
Validation loss: 2.5031833900117353

Epoch: 6| Step: 1
Training loss: 1.7774010952931232
Validation loss: 2.4593086556973978

Epoch: 6| Step: 2
Training loss: 1.2473120876968542
Validation loss: 2.475689007631455

Epoch: 6| Step: 3
Training loss: 2.2066814314164835
Validation loss: 2.435055098962968

Epoch: 6| Step: 4
Training loss: 2.403375667599507
Validation loss: 2.4678529987021287

Epoch: 6| Step: 5
Training loss: 2.362775966128249
Validation loss: 2.514434913070569

Epoch: 6| Step: 6
Training loss: 2.3950009655402993
Validation loss: 2.483037391295457

Epoch: 6| Step: 7
Training loss: 2.4097209518776173
Validation loss: 2.4648794037672577

Epoch: 6| Step: 8
Training loss: 2.0867666818133195
Validation loss: 2.4690212123107833

Epoch: 6| Step: 9
Training loss: 2.686601000504743
Validation loss: 2.4731208942590333

Epoch: 6| Step: 10
Training loss: 2.141627390262635
Validation loss: 2.4824820414280233

Epoch: 6| Step: 11
Training loss: 2.236839695684121
Validation loss: 2.482289481210582

Epoch: 6| Step: 12
Training loss: 2.1884826632835535
Validation loss: 2.4572150320155792

Epoch: 6| Step: 13
Training loss: 2.28429157819688
Validation loss: 2.473403094968791

Epoch: 335| Step: 0
Training loss: 2.4545719228788063
Validation loss: 2.487444516282168

Epoch: 6| Step: 1
Training loss: 1.7401047646564216
Validation loss: 2.475184523497899

Epoch: 6| Step: 2
Training loss: 2.342015145686926
Validation loss: 2.4649211745989845

Epoch: 6| Step: 3
Training loss: 2.057913332983626
Validation loss: 2.4307868147457055

Epoch: 6| Step: 4
Training loss: 2.0797892625131142
Validation loss: 2.462721500394754

Epoch: 6| Step: 5
Training loss: 2.355755182820209
Validation loss: 2.463536640755183

Epoch: 6| Step: 6
Training loss: 2.406913764857387
Validation loss: 2.483136351795538

Epoch: 6| Step: 7
Training loss: 1.9274135272349475
Validation loss: 2.4695532678237666

Epoch: 6| Step: 8
Training loss: 2.355174285044177
Validation loss: 2.474503183950332

Epoch: 6| Step: 9
Training loss: 2.188841708019589
Validation loss: 2.449588186796824

Epoch: 6| Step: 10
Training loss: 2.5597426302997777
Validation loss: 2.509266840501813

Epoch: 6| Step: 11
Training loss: 2.0988708048729667
Validation loss: 2.451489341842293

Epoch: 6| Step: 12
Training loss: 2.4878125670075693
Validation loss: 2.48559788904505

Epoch: 6| Step: 13
Training loss: 1.6448921296948045
Validation loss: 2.495319868952436

Epoch: 336| Step: 0
Training loss: 2.0241203187002483
Validation loss: 2.4471565869613383

Epoch: 6| Step: 1
Training loss: 2.0649044009194526
Validation loss: 2.4839376966467617

Epoch: 6| Step: 2
Training loss: 2.117313057530144
Validation loss: 2.448648563708676

Epoch: 6| Step: 3
Training loss: 2.2842627710413543
Validation loss: 2.4638182806444107

Epoch: 6| Step: 4
Training loss: 2.4148445714370976
Validation loss: 2.431143072075468

Epoch: 6| Step: 5
Training loss: 2.3230650530806765
Validation loss: 2.4368179793303724

Epoch: 6| Step: 6
Training loss: 1.8212331645661344
Validation loss: 2.45835968602737

Epoch: 6| Step: 7
Training loss: 2.3752382058598704
Validation loss: 2.502321427305107

Epoch: 6| Step: 8
Training loss: 2.7571900613585467
Validation loss: 2.416739477207146

Epoch: 6| Step: 9
Training loss: 2.0359468590147274
Validation loss: 2.4838763950631133

Epoch: 6| Step: 10
Training loss: 2.5542413631135252
Validation loss: 2.474542680951676

Epoch: 6| Step: 11
Training loss: 1.420671225927285
Validation loss: 2.459160748062698

Epoch: 6| Step: 12
Training loss: 1.5490844052728128
Validation loss: 2.4876057462640873

Epoch: 6| Step: 13
Training loss: 2.809303247131659
Validation loss: 2.481849360218171

Epoch: 337| Step: 0
Training loss: 1.8410972002468626
Validation loss: 2.446762914975197

Epoch: 6| Step: 1
Training loss: 1.6874535165671827
Validation loss: 2.468192637175172

Epoch: 6| Step: 2
Training loss: 1.6094538104565672
Validation loss: 2.4441587327603553

Epoch: 6| Step: 3
Training loss: 1.9169201130466695
Validation loss: 2.4357699082828637

Epoch: 6| Step: 4
Training loss: 3.124160195994568
Validation loss: 2.4800577076500456

Epoch: 6| Step: 5
Training loss: 2.5125744253494107
Validation loss: 2.466813706779908

Epoch: 6| Step: 6
Training loss: 2.3220863626011883
Validation loss: 2.459919080356285

Epoch: 6| Step: 7
Training loss: 2.9748349119910964
Validation loss: 2.4645901341775667

Epoch: 6| Step: 8
Training loss: 1.994966670262226
Validation loss: 2.452902172474607

Epoch: 6| Step: 9
Training loss: 1.9513117193105203
Validation loss: 2.479521458622602

Epoch: 6| Step: 10
Training loss: 1.9960348639415266
Validation loss: 2.4347655274564537

Epoch: 6| Step: 11
Training loss: 2.309402040315518
Validation loss: 2.4438885125442855

Epoch: 6| Step: 12
Training loss: 2.184983904537042
Validation loss: 2.4789332190903575

Epoch: 6| Step: 13
Training loss: 1.557481258763304
Validation loss: 2.444476879682475

Epoch: 338| Step: 0
Training loss: 2.342466893242049
Validation loss: 2.4600545476052615

Epoch: 6| Step: 1
Training loss: 1.2910557912329157
Validation loss: 2.474654822933342

Epoch: 6| Step: 2
Training loss: 2.7392073301943625
Validation loss: 2.4707955727642563

Epoch: 6| Step: 3
Training loss: 2.1254402153457033
Validation loss: 2.489123656517274

Epoch: 6| Step: 4
Training loss: 1.6649333842013394
Validation loss: 2.4298403616368525

Epoch: 6| Step: 5
Training loss: 2.2782806510759683
Validation loss: 2.4422803490250953

Epoch: 6| Step: 6
Training loss: 2.3565675314088352
Validation loss: 2.4710727453920405

Epoch: 6| Step: 7
Training loss: 2.256157291441438
Validation loss: 2.474442805902456

Epoch: 6| Step: 8
Training loss: 2.6791829782546093
Validation loss: 2.471752838471836

Epoch: 6| Step: 9
Training loss: 1.610324246352424
Validation loss: 2.488653322232721

Epoch: 6| Step: 10
Training loss: 2.2805176696025904
Validation loss: 2.443201871384369

Epoch: 6| Step: 11
Training loss: 2.247835071439258
Validation loss: 2.427328243589139

Epoch: 6| Step: 12
Training loss: 2.529827613084063
Validation loss: 2.4648501345376244

Epoch: 6| Step: 13
Training loss: 1.5554714047664595
Validation loss: 2.4490806212362717

Epoch: 339| Step: 0
Training loss: 2.4097391568290285
Validation loss: 2.4686385046861474

Epoch: 6| Step: 1
Training loss: 2.35869563344819
Validation loss: 2.4851150189639553

Epoch: 6| Step: 2
Training loss: 1.615849923095739
Validation loss: 2.4882137406427853

Epoch: 6| Step: 3
Training loss: 2.783752686970737
Validation loss: 2.4553744910865443

Epoch: 6| Step: 4
Training loss: 2.0127076320280413
Validation loss: 2.450191748797829

Epoch: 6| Step: 5
Training loss: 2.3318764588886443
Validation loss: 2.447366391246154

Epoch: 6| Step: 6
Training loss: 2.250750522476605
Validation loss: 2.4915607024342417

Epoch: 6| Step: 7
Training loss: 2.5151499424066324
Validation loss: 2.457360689629826

Epoch: 6| Step: 8
Training loss: 1.8972491402839606
Validation loss: 2.426284013744647

Epoch: 6| Step: 9
Training loss: 1.8031648760374552
Validation loss: 2.4659756603708636

Epoch: 6| Step: 10
Training loss: 2.6847880675145035
Validation loss: 2.4358197361408997

Epoch: 6| Step: 11
Training loss: 1.820893027274959
Validation loss: 2.4454590416293773

Epoch: 6| Step: 12
Training loss: 1.9128196573832446
Validation loss: 2.450939085801125

Epoch: 6| Step: 13
Training loss: 1.9253916626840566
Validation loss: 2.4570177881516453

Epoch: 340| Step: 0
Training loss: 1.8628644497056932
Validation loss: 2.4269027227296722

Epoch: 6| Step: 1
Training loss: 2.5162161375402294
Validation loss: 2.503425647623469

Epoch: 6| Step: 2
Training loss: 1.9235555852717454
Validation loss: 2.4404931770820597

Epoch: 6| Step: 3
Training loss: 2.520396381266481
Validation loss: 2.476678920773445

Epoch: 6| Step: 4
Training loss: 1.7742022911259092
Validation loss: 2.490730458148591

Epoch: 6| Step: 5
Training loss: 2.1770478265473883
Validation loss: 2.4552619905630033

Epoch: 6| Step: 6
Training loss: 2.416792427824672
Validation loss: 2.427375133355395

Epoch: 6| Step: 7
Training loss: 2.232196946714904
Validation loss: 2.4495339675941192

Epoch: 6| Step: 8
Training loss: 2.2207439220911724
Validation loss: 2.4668871277891387

Epoch: 6| Step: 9
Training loss: 2.726393467601374
Validation loss: 2.5106973167390114

Epoch: 6| Step: 10
Training loss: 1.6913280865446654
Validation loss: 2.418833299911913

Epoch: 6| Step: 11
Training loss: 1.7905859977908403
Validation loss: 2.4957210253438356

Epoch: 6| Step: 12
Training loss: 2.2660271649394788
Validation loss: 2.492479137867736

Epoch: 6| Step: 13
Training loss: 2.2247530896634444
Validation loss: 2.4412698051799753

Epoch: 341| Step: 0
Training loss: 2.635168091481325
Validation loss: 2.4857564459559196

Epoch: 6| Step: 1
Training loss: 2.431148371987241
Validation loss: 2.4822928996856324

Epoch: 6| Step: 2
Training loss: 2.2471348215696882
Validation loss: 2.469597376772961

Epoch: 6| Step: 3
Training loss: 2.3025743009857593
Validation loss: 2.435982683369927

Epoch: 6| Step: 4
Training loss: 1.4657500451595606
Validation loss: 2.4689507943414695

Epoch: 6| Step: 5
Training loss: 2.3884006698745455
Validation loss: 2.4794126640025898

Epoch: 6| Step: 6
Training loss: 2.1186288804625226
Validation loss: 2.4622935569457205

Epoch: 6| Step: 7
Training loss: 2.1466009995188333
Validation loss: 2.4585402806396863

Epoch: 6| Step: 8
Training loss: 2.0496881387334156
Validation loss: 2.48418514274133

Epoch: 6| Step: 9
Training loss: 2.3600313397929034
Validation loss: 2.4860417404146813

Epoch: 6| Step: 10
Training loss: 2.101992424875941
Validation loss: 2.448683187525792

Epoch: 6| Step: 11
Training loss: 1.844431347142997
Validation loss: 2.4707017428953484

Epoch: 6| Step: 12
Training loss: 1.9840563420632604
Validation loss: 2.445610747656006

Epoch: 6| Step: 13
Training loss: 2.2390432608523905
Validation loss: 2.454274184468707

Epoch: 342| Step: 0
Training loss: 2.1705828877940654
Validation loss: 2.4638405839890747

Epoch: 6| Step: 1
Training loss: 2.2400093797078617
Validation loss: 2.4406897091975064

Epoch: 6| Step: 2
Training loss: 2.650181828864522
Validation loss: 2.444102272744013

Epoch: 6| Step: 3
Training loss: 1.827918277366154
Validation loss: 2.4586972849635322

Epoch: 6| Step: 4
Training loss: 1.7786083375730861
Validation loss: 2.453818228046493

Epoch: 6| Step: 5
Training loss: 2.073946775145219
Validation loss: 2.467554397140494

Epoch: 6| Step: 6
Training loss: 1.9428672282373898
Validation loss: 2.476605640989397

Epoch: 6| Step: 7
Training loss: 2.2409384834054396
Validation loss: 2.4905898612030684

Epoch: 6| Step: 8
Training loss: 2.0441405690151435
Validation loss: 2.4609619639441034

Epoch: 6| Step: 9
Training loss: 3.1307395107767078
Validation loss: 2.4053412198111888

Epoch: 6| Step: 10
Training loss: 2.1783859030994175
Validation loss: 2.4473027332388577

Epoch: 6| Step: 11
Training loss: 2.0131904033848267
Validation loss: 2.463532478214616

Epoch: 6| Step: 12
Training loss: 1.970355514552957
Validation loss: 2.4797387911087685

Epoch: 6| Step: 13
Training loss: 2.0870468104568443
Validation loss: 2.4339002116948754

Epoch: 343| Step: 0
Training loss: 2.694435662542585
Validation loss: 2.4639464573504988

Epoch: 6| Step: 1
Training loss: 1.8422554553620623
Validation loss: 2.4196516699529944

Epoch: 6| Step: 2
Training loss: 1.6235430862118365
Validation loss: 2.4336486419389987

Epoch: 6| Step: 3
Training loss: 2.402130167080795
Validation loss: 2.485828619597359

Epoch: 6| Step: 4
Training loss: 2.012901417758641
Validation loss: 2.498725963330965

Epoch: 6| Step: 5
Training loss: 1.7806728833536456
Validation loss: 2.4695279640324106

Epoch: 6| Step: 6
Training loss: 1.8796593312779197
Validation loss: 2.478730132697196

Epoch: 6| Step: 7
Training loss: 2.7756740095196344
Validation loss: 2.5036054812623085

Epoch: 6| Step: 8
Training loss: 2.1854341834147837
Validation loss: 2.453925714862444

Epoch: 6| Step: 9
Training loss: 2.1201749887762156
Validation loss: 2.464210830595613

Epoch: 6| Step: 10
Training loss: 1.9578666807381644
Validation loss: 2.422859953288504

Epoch: 6| Step: 11
Training loss: 1.909261794410111
Validation loss: 2.4607530344061095

Epoch: 6| Step: 12
Training loss: 2.6450464375102554
Validation loss: 2.4513687295948627

Epoch: 6| Step: 13
Training loss: 2.536628753973636
Validation loss: 2.4367400726213533

Epoch: 344| Step: 0
Training loss: 2.1968683451610063
Validation loss: 2.4601504466962125

Epoch: 6| Step: 1
Training loss: 2.1533550787301134
Validation loss: 2.4566906536226525

Epoch: 6| Step: 2
Training loss: 2.151581506361222
Validation loss: 2.5004153706438283

Epoch: 6| Step: 3
Training loss: 2.1492032992418766
Validation loss: 2.473043200798688

Epoch: 6| Step: 4
Training loss: 1.800886039415676
Validation loss: 2.4705459523333393

Epoch: 6| Step: 5
Training loss: 1.974512175177843
Validation loss: 2.411085344231742

Epoch: 6| Step: 6
Training loss: 2.6678942199395053
Validation loss: 2.454429279212277

Epoch: 6| Step: 7
Training loss: 1.401711919298241
Validation loss: 2.485780188656508

Epoch: 6| Step: 8
Training loss: 2.6314398472814915
Validation loss: 2.4346808724205884

Epoch: 6| Step: 9
Training loss: 1.8482953311165458
Validation loss: 2.4591223670776072

Epoch: 6| Step: 10
Training loss: 1.8515150490648062
Validation loss: 2.4687934363871524

Epoch: 6| Step: 11
Training loss: 2.848643692932169
Validation loss: 2.4687407423193446

Epoch: 6| Step: 12
Training loss: 2.502065854060484
Validation loss: 2.465980632796583

Epoch: 6| Step: 13
Training loss: 1.7072192335173313
Validation loss: 2.439504003125988

Epoch: 345| Step: 0
Training loss: 1.739912592018806
Validation loss: 2.490020057355943

Epoch: 6| Step: 1
Training loss: 2.213981770165574
Validation loss: 2.400981745818491

Epoch: 6| Step: 2
Training loss: 2.256999677976654
Validation loss: 2.497093739730283

Epoch: 6| Step: 3
Training loss: 1.805922180839554
Validation loss: 2.458753947327141

Epoch: 6| Step: 4
Training loss: 2.5791772717908534
Validation loss: 2.4465943321530257

Epoch: 6| Step: 5
Training loss: 1.917196642815786
Validation loss: 2.449429061099584

Epoch: 6| Step: 6
Training loss: 2.2886612576291956
Validation loss: 2.4485818912492885

Epoch: 6| Step: 7
Training loss: 1.6203153280971054
Validation loss: 2.4399085113124293

Epoch: 6| Step: 8
Training loss: 2.54306091047837
Validation loss: 2.485250861284307

Epoch: 6| Step: 9
Training loss: 2.4222316356304923
Validation loss: 2.493584046809755

Epoch: 6| Step: 10
Training loss: 2.2481883490860612
Validation loss: 2.4513524840887873

Epoch: 6| Step: 11
Training loss: 2.6952578331752384
Validation loss: 2.462512732115223

Epoch: 6| Step: 12
Training loss: 2.271722835183152
Validation loss: 2.449914586543649

Epoch: 6| Step: 13
Training loss: 1.4569595769276749
Validation loss: 2.471366435631386

Epoch: 346| Step: 0
Training loss: 2.03764826229318
Validation loss: 2.459684454983326

Epoch: 6| Step: 1
Training loss: 1.668462104108655
Validation loss: 2.4575497880419115

Epoch: 6| Step: 2
Training loss: 1.917600452621814
Validation loss: 2.4773280322223497

Epoch: 6| Step: 3
Training loss: 1.775317435020191
Validation loss: 2.4190681512406638

Epoch: 6| Step: 4
Training loss: 2.3401096810613327
Validation loss: 2.4711837817876177

Epoch: 6| Step: 5
Training loss: 2.1318158067075186
Validation loss: 2.45946940983699

Epoch: 6| Step: 6
Training loss: 2.248512412089775
Validation loss: 2.4564684876752794

Epoch: 6| Step: 7
Training loss: 1.720385934646537
Validation loss: 2.4875479123176185

Epoch: 6| Step: 8
Training loss: 2.831130985680644
Validation loss: 2.4585267597964573

Epoch: 6| Step: 9
Training loss: 2.6858128419434295
Validation loss: 2.4765608276970217

Epoch: 6| Step: 10
Training loss: 2.147498685150277
Validation loss: 2.474526870416248

Epoch: 6| Step: 11
Training loss: 2.294232775530921
Validation loss: 2.4351934905911987

Epoch: 6| Step: 12
Training loss: 2.2387920549064635
Validation loss: 2.4492658685910884

Epoch: 6| Step: 13
Training loss: 1.7571417991289415
Validation loss: 2.494533856297997

Epoch: 347| Step: 0
Training loss: 2.3148989219927008
Validation loss: 2.459585791249052

Epoch: 6| Step: 1
Training loss: 2.6528325255527103
Validation loss: 2.4721749451643285

Epoch: 6| Step: 2
Training loss: 2.6393322912324777
Validation loss: 2.4439422973627116

Epoch: 6| Step: 3
Training loss: 2.3044437602839265
Validation loss: 2.468732576008903

Epoch: 6| Step: 4
Training loss: 2.0155132173991066
Validation loss: 2.468761854765054

Epoch: 6| Step: 5
Training loss: 1.7085481446593827
Validation loss: 2.464687219907172

Epoch: 6| Step: 6
Training loss: 1.8973411879592483
Validation loss: 2.443380487471021

Epoch: 6| Step: 7
Training loss: 1.5240351360555986
Validation loss: 2.420511594069253

Epoch: 6| Step: 8
Training loss: 2.467730637644531
Validation loss: 2.4421110079901744

Epoch: 6| Step: 9
Training loss: 2.222529563578452
Validation loss: 2.441344408658977

Epoch: 6| Step: 10
Training loss: 2.191321386642239
Validation loss: 2.4385409145379735

Epoch: 6| Step: 11
Training loss: 1.931033695786297
Validation loss: 2.4505337192197953

Epoch: 6| Step: 12
Training loss: 2.3288184035815997
Validation loss: 2.467572807086249

Epoch: 6| Step: 13
Training loss: 1.930339996354497
Validation loss: 2.4665297273451428

Epoch: 348| Step: 0
Training loss: 1.9652310363219503
Validation loss: 2.4559787840041576

Epoch: 6| Step: 1
Training loss: 2.1982620353599196
Validation loss: 2.4325726013896642

Epoch: 6| Step: 2
Training loss: 2.2232263031819124
Validation loss: 2.4615655600568336

Epoch: 6| Step: 3
Training loss: 2.2137700460464407
Validation loss: 2.454198150694663

Epoch: 6| Step: 4
Training loss: 1.58003044292239
Validation loss: 2.4646708115104734

Epoch: 6| Step: 5
Training loss: 1.6025694868046225
Validation loss: 2.474666071349282

Epoch: 6| Step: 6
Training loss: 1.658163297105247
Validation loss: 2.50387707913515

Epoch: 6| Step: 7
Training loss: 2.370477486327089
Validation loss: 2.4405394525608304

Epoch: 6| Step: 8
Training loss: 2.261459203925215
Validation loss: 2.4413091483546143

Epoch: 6| Step: 9
Training loss: 2.0549998462983234
Validation loss: 2.4447118414648012

Epoch: 6| Step: 10
Training loss: 2.970272436779806
Validation loss: 2.442953514659398

Epoch: 6| Step: 11
Training loss: 2.4665273004115598
Validation loss: 2.447645126149967

Epoch: 6| Step: 12
Training loss: 2.0467454709135375
Validation loss: 2.460012284583429

Epoch: 6| Step: 13
Training loss: 2.485642691538013
Validation loss: 2.46219010098737

Epoch: 349| Step: 0
Training loss: 1.6846363353230422
Validation loss: 2.4510867239478937

Epoch: 6| Step: 1
Training loss: 1.809828400670701
Validation loss: 2.4186812763478143

Epoch: 6| Step: 2
Training loss: 1.684874010214963
Validation loss: 2.4409865167585383

Epoch: 6| Step: 3
Training loss: 2.3902370162976703
Validation loss: 2.4404008220365325

Epoch: 6| Step: 4
Training loss: 2.410106590414757
Validation loss: 2.4643948397139317

Epoch: 6| Step: 5
Training loss: 1.509905059810826
Validation loss: 2.4514724372639014

Epoch: 6| Step: 6
Training loss: 2.4798146744670553
Validation loss: 2.4380421993859707

Epoch: 6| Step: 7
Training loss: 2.1559669198239106
Validation loss: 2.484874738800061

Epoch: 6| Step: 8
Training loss: 2.598567946067759
Validation loss: 2.538368110709639

Epoch: 6| Step: 9
Training loss: 2.3732771396770893
Validation loss: 2.4651379197565326

Epoch: 6| Step: 10
Training loss: 2.768384688067742
Validation loss: 2.4488192292278814

Epoch: 6| Step: 11
Training loss: 1.970402765588682
Validation loss: 2.488503079172351

Epoch: 6| Step: 12
Training loss: 2.233096950983695
Validation loss: 2.4581795135590165

Epoch: 6| Step: 13
Training loss: 2.288632088774549
Validation loss: 2.450912534424652

Epoch: 350| Step: 0
Training loss: 1.8226775166905536
Validation loss: 2.443361963443666

Epoch: 6| Step: 1
Training loss: 1.9594319555835593
Validation loss: 2.480066100262458

Epoch: 6| Step: 2
Training loss: 1.907140492549551
Validation loss: 2.461157270398631

Epoch: 6| Step: 3
Training loss: 2.7708582960643975
Validation loss: 2.468771499180877

Epoch: 6| Step: 4
Training loss: 2.0766532103141833
Validation loss: 2.4516203507254692

Epoch: 6| Step: 5
Training loss: 2.237976799143239
Validation loss: 2.450213183247752

Epoch: 6| Step: 6
Training loss: 1.9903387130326424
Validation loss: 2.485817294841613

Epoch: 6| Step: 7
Training loss: 1.830349147925378
Validation loss: 2.483840904578621

Epoch: 6| Step: 8
Training loss: 1.8105906591296024
Validation loss: 2.470882673742237

Epoch: 6| Step: 9
Training loss: 2.3146262832442748
Validation loss: 2.4718336725073713

Epoch: 6| Step: 10
Training loss: 2.361757502867272
Validation loss: 2.469002777861727

Epoch: 6| Step: 11
Training loss: 2.517377444393328
Validation loss: 2.4258065504003388

Epoch: 6| Step: 12
Training loss: 2.0934240742270123
Validation loss: 2.489283826141549

Epoch: 6| Step: 13
Training loss: 2.4413898436948744
Validation loss: 2.4309042856709158

Epoch: 351| Step: 0
Training loss: 2.233579267179349
Validation loss: 2.4659982701166356

Epoch: 6| Step: 1
Training loss: 2.2057886997612406
Validation loss: 2.4872070498443817

Epoch: 6| Step: 2
Training loss: 1.8767178613287276
Validation loss: 2.472047491705651

Epoch: 6| Step: 3
Training loss: 1.566870870200559
Validation loss: 2.4508472336971647

Epoch: 6| Step: 4
Training loss: 2.4132104252591793
Validation loss: 2.4592395066183186

Epoch: 6| Step: 5
Training loss: 2.3593032522850206
Validation loss: 2.46144742147558

Epoch: 6| Step: 6
Training loss: 1.1605327265084686
Validation loss: 2.426978937704998

Epoch: 6| Step: 7
Training loss: 2.0583514481749954
Validation loss: 2.4246199798604504

Epoch: 6| Step: 8
Training loss: 1.7922836025183289
Validation loss: 2.473865549175091

Epoch: 6| Step: 9
Training loss: 2.421074322662254
Validation loss: 2.4262804497899886

Epoch: 6| Step: 10
Training loss: 1.6693558296865287
Validation loss: 2.442235566680773

Epoch: 6| Step: 11
Training loss: 2.760636307717177
Validation loss: 2.453919131091444

Epoch: 6| Step: 12
Training loss: 3.060871236102398
Validation loss: 2.422452188730296

Epoch: 6| Step: 13
Training loss: 1.9657554862130076
Validation loss: 2.425262296319214

Epoch: 352| Step: 0
Training loss: 2.553959827438736
Validation loss: 2.461470820097166

Epoch: 6| Step: 1
Training loss: 2.5375530744742907
Validation loss: 2.4830636693677945

Epoch: 6| Step: 2
Training loss: 1.950630792659921
Validation loss: 2.4285490404099965

Epoch: 6| Step: 3
Training loss: 2.149904062659005
Validation loss: 2.4612386695974617

Epoch: 6| Step: 4
Training loss: 2.3300146844098277
Validation loss: 2.44563897194553

Epoch: 6| Step: 5
Training loss: 1.8824554358041776
Validation loss: 2.461952281775531

Epoch: 6| Step: 6
Training loss: 2.3414978396372956
Validation loss: 2.463303165476135

Epoch: 6| Step: 7
Training loss: 2.013705973886848
Validation loss: 2.401985765662162

Epoch: 6| Step: 8
Training loss: 1.4918899638940117
Validation loss: 2.483414483697298

Epoch: 6| Step: 9
Training loss: 1.9807400790313585
Validation loss: 2.4400854048381553

Epoch: 6| Step: 10
Training loss: 1.7233115958657368
Validation loss: 2.5036590076813963

Epoch: 6| Step: 11
Training loss: 2.5421711363731765
Validation loss: 2.443364589656711

Epoch: 6| Step: 12
Training loss: 2.3676050403338307
Validation loss: 2.4636545303494244

Epoch: 6| Step: 13
Training loss: 1.6746085093740473
Validation loss: 2.459890251308532

Epoch: 353| Step: 0
Training loss: 1.5726586271250043
Validation loss: 2.4656525798725153

Epoch: 6| Step: 1
Training loss: 2.447330312642674
Validation loss: 2.442907925057031

Epoch: 6| Step: 2
Training loss: 1.9424746238985326
Validation loss: 2.4601681315450827

Epoch: 6| Step: 3
Training loss: 1.3911181657677936
Validation loss: 2.4644424150485444

Epoch: 6| Step: 4
Training loss: 2.1069648819917557
Validation loss: 2.477069507170704

Epoch: 6| Step: 5
Training loss: 2.202080445180952
Validation loss: 2.4588723055042445

Epoch: 6| Step: 6
Training loss: 2.457975415397842
Validation loss: 2.4629688406493164

Epoch: 6| Step: 7
Training loss: 2.2132547589031897
Validation loss: 2.453117638649995

Epoch: 6| Step: 8
Training loss: 2.391722184266782
Validation loss: 2.482351614099929

Epoch: 6| Step: 9
Training loss: 2.4214744975046565
Validation loss: 2.4305330157272516

Epoch: 6| Step: 10
Training loss: 2.2712837845720237
Validation loss: 2.454262678595414

Epoch: 6| Step: 11
Training loss: 2.2730627635945275
Validation loss: 2.413313840403697

Epoch: 6| Step: 12
Training loss: 1.9927405692918145
Validation loss: 2.4732197653995067

Epoch: 6| Step: 13
Training loss: 2.1169468366374176
Validation loss: 2.473478455474219

Epoch: 354| Step: 0
Training loss: 1.8814597434289682
Validation loss: 2.538982869328096

Epoch: 6| Step: 1
Training loss: 3.117106118729345
Validation loss: 2.4578114479298994

Epoch: 6| Step: 2
Training loss: 2.1834642511773428
Validation loss: 2.462614155974786

Epoch: 6| Step: 3
Training loss: 1.7450893167192436
Validation loss: 2.478308451487122

Epoch: 6| Step: 4
Training loss: 2.1408243573768924
Validation loss: 2.445698924811434

Epoch: 6| Step: 5
Training loss: 1.765432499206917
Validation loss: 2.4351549134547583

Epoch: 6| Step: 6
Training loss: 2.0007971128812794
Validation loss: 2.4698211715769043

Epoch: 6| Step: 7
Training loss: 2.641289170385912
Validation loss: 2.4564184848354764

Epoch: 6| Step: 8
Training loss: 1.7654749713723603
Validation loss: 2.4612440901084187

Epoch: 6| Step: 9
Training loss: 2.2366080696097512
Validation loss: 2.4697963012990076

Epoch: 6| Step: 10
Training loss: 2.5879263706257705
Validation loss: 2.507824861157848

Epoch: 6| Step: 11
Training loss: 1.5998628855605077
Validation loss: 2.429574155094287

Epoch: 6| Step: 12
Training loss: 1.9566026168729316
Validation loss: 2.4831906647741646

Epoch: 6| Step: 13
Training loss: 2.281916586278337
Validation loss: 2.44647126438206

Epoch: 355| Step: 0
Training loss: 2.04056724478292
Validation loss: 2.4512073730805874

Epoch: 6| Step: 1
Training loss: 2.118831545180458
Validation loss: 2.435384076511993

Epoch: 6| Step: 2
Training loss: 2.152215472654832
Validation loss: 2.424041077904904

Epoch: 6| Step: 3
Training loss: 2.348447948643225
Validation loss: 2.45227493053513

Epoch: 6| Step: 4
Training loss: 1.7454219609618362
Validation loss: 2.4469345224042387

Epoch: 6| Step: 5
Training loss: 1.8694485178590217
Validation loss: 2.4590564305316756

Epoch: 6| Step: 6
Training loss: 1.6941229518736423
Validation loss: 2.4370669823545597

Epoch: 6| Step: 7
Training loss: 2.8585413984043684
Validation loss: 2.430509119913565

Epoch: 6| Step: 8
Training loss: 2.082679060877522
Validation loss: 2.4716659818238758

Epoch: 6| Step: 9
Training loss: 2.404523155540363
Validation loss: 2.457684578517259

Epoch: 6| Step: 10
Training loss: 2.4010091408424876
Validation loss: 2.450666767824588

Epoch: 6| Step: 11
Training loss: 2.122600771754991
Validation loss: 2.4982128072004866

Epoch: 6| Step: 12
Training loss: 2.0356759782404
Validation loss: 2.486672049777226

Epoch: 6| Step: 13
Training loss: 1.5327086993893646
Validation loss: 2.4533523110433264

Epoch: 356| Step: 0
Training loss: 1.5301785515712605
Validation loss: 2.4667360183652365

Epoch: 6| Step: 1
Training loss: 2.0986063419907506
Validation loss: 2.442466203458674

Epoch: 6| Step: 2
Training loss: 2.5461329215712762
Validation loss: 2.459195341674586

Epoch: 6| Step: 3
Training loss: 2.0131014618182936
Validation loss: 2.441408509743578

Epoch: 6| Step: 4
Training loss: 2.018467517847505
Validation loss: 2.4831422623953165

Epoch: 6| Step: 5
Training loss: 2.279510880257089
Validation loss: 2.4294331513781153

Epoch: 6| Step: 6
Training loss: 2.0481485379786952
Validation loss: 2.4661320348766536

Epoch: 6| Step: 7
Training loss: 1.9970311541087578
Validation loss: 2.485201437552726

Epoch: 6| Step: 8
Training loss: 2.208167615706556
Validation loss: 2.4368781313288914

Epoch: 6| Step: 9
Training loss: 2.6418039974131866
Validation loss: 2.410391796262162

Epoch: 6| Step: 10
Training loss: 1.7997796506584
Validation loss: 2.453841142044388

Epoch: 6| Step: 11
Training loss: 2.585386096446756
Validation loss: 2.462399827897635

Epoch: 6| Step: 12
Training loss: 1.9592397567093798
Validation loss: 2.447550747100497

Epoch: 6| Step: 13
Training loss: 1.8285649088228173
Validation loss: 2.4638533103837266

Epoch: 357| Step: 0
Training loss: 1.5649637253429884
Validation loss: 2.437731161586282

Epoch: 6| Step: 1
Training loss: 1.7046515946142766
Validation loss: 2.4438913259624067

Epoch: 6| Step: 2
Training loss: 1.8203474704510374
Validation loss: 2.477472219667683

Epoch: 6| Step: 3
Training loss: 1.777523224540748
Validation loss: 2.40912808755162

Epoch: 6| Step: 4
Training loss: 1.8837568518622212
Validation loss: 2.4469658702802883

Epoch: 6| Step: 5
Training loss: 1.7965739122321234
Validation loss: 2.4624071594163732

Epoch: 6| Step: 6
Training loss: 2.758791050192868
Validation loss: 2.4781069442901686

Epoch: 6| Step: 7
Training loss: 2.4117972106330345
Validation loss: 2.460980553420506

Epoch: 6| Step: 8
Training loss: 2.473212831840068
Validation loss: 2.482733072156671

Epoch: 6| Step: 9
Training loss: 2.4186662644670203
Validation loss: 2.439898330944673

Epoch: 6| Step: 10
Training loss: 2.6484194954679308
Validation loss: 2.440076099866069

Epoch: 6| Step: 11
Training loss: 1.7144219438034072
Validation loss: 2.496320318625592

Epoch: 6| Step: 12
Training loss: 2.946566934350618
Validation loss: 2.481092410482821

Epoch: 6| Step: 13
Training loss: 1.4777760841882572
Validation loss: 2.4745673305155367

Epoch: 358| Step: 0
Training loss: 1.597641998451297
Validation loss: 2.4436375829027965

Epoch: 6| Step: 1
Training loss: 1.7626000206886185
Validation loss: 2.4406754461071283

Epoch: 6| Step: 2
Training loss: 2.365690960588111
Validation loss: 2.410281347496932

Epoch: 6| Step: 3
Training loss: 1.3039432618663382
Validation loss: 2.490451506048484

Epoch: 6| Step: 4
Training loss: 2.1402684492562125
Validation loss: 2.442288704554205

Epoch: 6| Step: 5
Training loss: 2.3197738073512575
Validation loss: 2.4416639134445663

Epoch: 6| Step: 6
Training loss: 2.253980718007241
Validation loss: 2.467719630838239

Epoch: 6| Step: 7
Training loss: 2.1238870511169137
Validation loss: 2.3959870102341765

Epoch: 6| Step: 8
Training loss: 2.4214800112630064
Validation loss: 2.432815369600315

Epoch: 6| Step: 9
Training loss: 1.3712460251283716
Validation loss: 2.4408250715340354

Epoch: 6| Step: 10
Training loss: 2.5249018244022623
Validation loss: 2.451953820249113

Epoch: 6| Step: 11
Training loss: 2.908279530666062
Validation loss: 2.4652081253015714

Epoch: 6| Step: 12
Training loss: 2.18191480151731
Validation loss: 2.4513170445839596

Epoch: 6| Step: 13
Training loss: 2.2670575052715916
Validation loss: 2.4637638881468367

Epoch: 359| Step: 0
Training loss: 2.0345592831355437
Validation loss: 2.433723341571162

Epoch: 6| Step: 1
Training loss: 2.706436422151316
Validation loss: 2.460379418715492

Epoch: 6| Step: 2
Training loss: 2.3886182752507903
Validation loss: 2.452439018854377

Epoch: 6| Step: 3
Training loss: 2.012794695773815
Validation loss: 2.4311482095945722

Epoch: 6| Step: 4
Training loss: 2.100381285249541
Validation loss: 2.4254511348540535

Epoch: 6| Step: 5
Training loss: 2.24447058367642
Validation loss: 2.4483615244989205

Epoch: 6| Step: 6
Training loss: 2.2611804380835636
Validation loss: 2.4792454818092136

Epoch: 6| Step: 7
Training loss: 2.1108458865465494
Validation loss: 2.4343765499101577

Epoch: 6| Step: 8
Training loss: 1.745486023557639
Validation loss: 2.4116993941342373

Epoch: 6| Step: 9
Training loss: 2.0840722363156323
Validation loss: 2.41100178870781

Epoch: 6| Step: 10
Training loss: 2.1287708484392573
Validation loss: 2.4600611316299434

Epoch: 6| Step: 11
Training loss: 1.5460057754507421
Validation loss: 2.437037382774905

Epoch: 6| Step: 12
Training loss: 1.9483857295569986
Validation loss: 2.4705050668122355

Epoch: 6| Step: 13
Training loss: 2.310791312256485
Validation loss: 2.461611369621919

Epoch: 360| Step: 0
Training loss: 2.153579163509198
Validation loss: 2.4375984638984067

Epoch: 6| Step: 1
Training loss: 2.1821077644107563
Validation loss: 2.5104295912968038

Epoch: 6| Step: 2
Training loss: 2.5278180250752835
Validation loss: 2.4315586414132553

Epoch: 6| Step: 3
Training loss: 2.1040467961477565
Validation loss: 2.473417600507965

Epoch: 6| Step: 4
Training loss: 2.087906725886527
Validation loss: 2.4721126285726696

Epoch: 6| Step: 5
Training loss: 2.204863058841943
Validation loss: 2.4631462158740227

Epoch: 6| Step: 6
Training loss: 2.1532242042044247
Validation loss: 2.412138949940243

Epoch: 6| Step: 7
Training loss: 2.3559806609080547
Validation loss: 2.4580646414634684

Epoch: 6| Step: 8
Training loss: 1.771539487475632
Validation loss: 2.48429630356379

Epoch: 6| Step: 9
Training loss: 2.250306638379721
Validation loss: 2.386960236054276

Epoch: 6| Step: 10
Training loss: 1.8813037446414789
Validation loss: 2.4489929500213004

Epoch: 6| Step: 11
Training loss: 1.9315675542296558
Validation loss: 2.4588241219329006

Epoch: 6| Step: 12
Training loss: 2.415150320141207
Validation loss: 2.494107375391211

Epoch: 6| Step: 13
Training loss: 1.9025520351677627
Validation loss: 2.4618440243954387

Epoch: 361| Step: 0
Training loss: 2.3500619961291735
Validation loss: 2.4033669229140844

Epoch: 6| Step: 1
Training loss: 2.4807647768730168
Validation loss: 2.4402751779726177

Epoch: 6| Step: 2
Training loss: 2.6107210810403094
Validation loss: 2.470640601630375

Epoch: 6| Step: 3
Training loss: 1.9737503492416644
Validation loss: 2.4771205844826123

Epoch: 6| Step: 4
Training loss: 1.9629326507472509
Validation loss: 2.475397167778326

Epoch: 6| Step: 5
Training loss: 2.1338442587969677
Validation loss: 2.428478598490088

Epoch: 6| Step: 6
Training loss: 1.7689335973772253
Validation loss: 2.4753202313844525

Epoch: 6| Step: 7
Training loss: 2.005771415884253
Validation loss: 2.426567185066732

Epoch: 6| Step: 8
Training loss: 1.9826162759709078
Validation loss: 2.4494866390832573

Epoch: 6| Step: 9
Training loss: 2.1107028878807657
Validation loss: 2.476563390238203

Epoch: 6| Step: 10
Training loss: 2.30462925724208
Validation loss: 2.4637627466760805

Epoch: 6| Step: 11
Training loss: 1.8479301781861044
Validation loss: 2.390103215579377

Epoch: 6| Step: 12
Training loss: 2.4946836210572156
Validation loss: 2.4285282603141547

Epoch: 6| Step: 13
Training loss: 1.780639409937182
Validation loss: 2.4633169686778524

Epoch: 362| Step: 0
Training loss: 1.8064742058064092
Validation loss: 2.451517658449275

Epoch: 6| Step: 1
Training loss: 1.3923011707691415
Validation loss: 2.497532853626892

Epoch: 6| Step: 2
Training loss: 2.192541688459662
Validation loss: 2.45528404168572

Epoch: 6| Step: 3
Training loss: 1.4544223203612374
Validation loss: 2.4686483977804707

Epoch: 6| Step: 4
Training loss: 2.0416582327947483
Validation loss: 2.4497253843341253

Epoch: 6| Step: 5
Training loss: 2.080057493295567
Validation loss: 2.4352943826419584

Epoch: 6| Step: 6
Training loss: 2.6870996043885365
Validation loss: 2.4793231959851227

Epoch: 6| Step: 7
Training loss: 2.3437331135459383
Validation loss: 2.4433081070922937

Epoch: 6| Step: 8
Training loss: 1.5953781936375628
Validation loss: 2.4474368719379753

Epoch: 6| Step: 9
Training loss: 2.526936564595411
Validation loss: 2.431639553846873

Epoch: 6| Step: 10
Training loss: 2.129351927976846
Validation loss: 2.4817600069019807

Epoch: 6| Step: 11
Training loss: 2.2563556339970683
Validation loss: 2.471843211076934

Epoch: 6| Step: 12
Training loss: 2.789436635800804
Validation loss: 2.433553269720082

Epoch: 6| Step: 13
Training loss: 2.1645397114572846
Validation loss: 2.423759725821803

Epoch: 363| Step: 0
Training loss: 2.4028146173768246
Validation loss: 2.4317263884644804

Epoch: 6| Step: 1
Training loss: 1.8318420182287924
Validation loss: 2.4893090660862702

Epoch: 6| Step: 2
Training loss: 2.146011814237784
Validation loss: 2.4769931971348322

Epoch: 6| Step: 3
Training loss: 2.084234449689375
Validation loss: 2.4478543209252046

Epoch: 6| Step: 4
Training loss: 2.0937966868191533
Validation loss: 2.4304228968438384

Epoch: 6| Step: 5
Training loss: 2.134549059270338
Validation loss: 2.465885043614988

Epoch: 6| Step: 6
Training loss: 2.3801005956082704
Validation loss: 2.446561341720206

Epoch: 6| Step: 7
Training loss: 2.7472418044364892
Validation loss: 2.480829071546983

Epoch: 6| Step: 8
Training loss: 1.8971002209360888
Validation loss: 2.4660399726165805

Epoch: 6| Step: 9
Training loss: 2.606451349690929
Validation loss: 2.4447114670976626

Epoch: 6| Step: 10
Training loss: 1.696991260683646
Validation loss: 2.448019408769038

Epoch: 6| Step: 11
Training loss: 1.4486331219137292
Validation loss: 2.423104344210482

Epoch: 6| Step: 12
Training loss: 2.030165749721927
Validation loss: 2.474744761176925

Epoch: 6| Step: 13
Training loss: 2.7583493150630307
Validation loss: 2.4497177720723284

Epoch: 364| Step: 0
Training loss: 1.8002841619199086
Validation loss: 2.4411291719450543

Epoch: 6| Step: 1
Training loss: 2.166641406376626
Validation loss: 2.4669921949405045

Epoch: 6| Step: 2
Training loss: 2.439577537766459
Validation loss: 2.420737875459769

Epoch: 6| Step: 3
Training loss: 1.8368911538934012
Validation loss: 2.435215767651138

Epoch: 6| Step: 4
Training loss: 2.206124394545277
Validation loss: 2.450852770809469

Epoch: 6| Step: 5
Training loss: 2.3988678884634873
Validation loss: 2.4839109974360234

Epoch: 6| Step: 6
Training loss: 2.5286193175780256
Validation loss: 2.4476561101111356

Epoch: 6| Step: 7
Training loss: 1.8974679739640503
Validation loss: 2.4677457941286387

Epoch: 6| Step: 8
Training loss: 1.9498200798172245
Validation loss: 2.4570531913400675

Epoch: 6| Step: 9
Training loss: 2.1063996983427593
Validation loss: 2.455485491381864

Epoch: 6| Step: 10
Training loss: 1.8531749802229196
Validation loss: 2.4995684374280507

Epoch: 6| Step: 11
Training loss: 2.5012636805612525
Validation loss: 2.430708627719873

Epoch: 6| Step: 12
Training loss: 2.083201696687585
Validation loss: 2.433929701965401

Epoch: 6| Step: 13
Training loss: 1.8626359825929226
Validation loss: 2.453491709189087

Epoch: 365| Step: 0
Training loss: 2.8603257229863086
Validation loss: 2.434026950547002

Epoch: 6| Step: 1
Training loss: 2.005203273486074
Validation loss: 2.4710762214013666

Epoch: 6| Step: 2
Training loss: 2.2014753509881277
Validation loss: 2.4390798528285647

Epoch: 6| Step: 3
Training loss: 1.3905529046390057
Validation loss: 2.4629313969983566

Epoch: 6| Step: 4
Training loss: 2.094985369719994
Validation loss: 2.449885938524482

Epoch: 6| Step: 5
Training loss: 2.575162630593479
Validation loss: 2.4469971936583845

Epoch: 6| Step: 6
Training loss: 2.112060532764456
Validation loss: 2.4512016741363793

Epoch: 6| Step: 7
Training loss: 1.7496033627746805
Validation loss: 2.470156877139257

Epoch: 6| Step: 8
Training loss: 1.8831883605365598
Validation loss: 2.4404002421605604

Epoch: 6| Step: 9
Training loss: 1.898684764190926
Validation loss: 2.3999033793959152

Epoch: 6| Step: 10
Training loss: 2.564959299608608
Validation loss: 2.420111026959478

Epoch: 6| Step: 11
Training loss: 2.1686493776048352
Validation loss: 2.4806979465507917

Epoch: 6| Step: 12
Training loss: 1.9829134026383177
Validation loss: 2.4299527414455317

Epoch: 6| Step: 13
Training loss: 2.0821616756389876
Validation loss: 2.4685427608711903

Epoch: 366| Step: 0
Training loss: 2.5475474212994604
Validation loss: 2.47072194209114

Epoch: 6| Step: 1
Training loss: 2.075989048570622
Validation loss: 2.4484589631673384

Epoch: 6| Step: 2
Training loss: 1.9621382604679363
Validation loss: 2.465840269934141

Epoch: 6| Step: 3
Training loss: 1.9888729271819492
Validation loss: 2.471393497539228

Epoch: 6| Step: 4
Training loss: 2.716874275777829
Validation loss: 2.443388035539093

Epoch: 6| Step: 5
Training loss: 1.9774335668234093
Validation loss: 2.4828545196175695

Epoch: 6| Step: 6
Training loss: 2.076281654993912
Validation loss: 2.4458482502628143

Epoch: 6| Step: 7
Training loss: 2.254438049940718
Validation loss: 2.4196487764345394

Epoch: 6| Step: 8
Training loss: 2.3827402572936958
Validation loss: 2.496339137739956

Epoch: 6| Step: 9
Training loss: 1.6027862339615764
Validation loss: 2.46172581898995

Epoch: 6| Step: 10
Training loss: 2.381665963915149
Validation loss: 2.443316883002178

Epoch: 6| Step: 11
Training loss: 1.2582881809916757
Validation loss: 2.427687226060056

Epoch: 6| Step: 12
Training loss: 2.060139432280794
Validation loss: 2.4387122658587876

Epoch: 6| Step: 13
Training loss: 2.4047890724111514
Validation loss: 2.4475767515328943

Epoch: 367| Step: 0
Training loss: 1.9776129664045383
Validation loss: 2.4486801283457993

Epoch: 6| Step: 1
Training loss: 1.776969987743549
Validation loss: 2.429876861352254

Epoch: 6| Step: 2
Training loss: 2.0257121964766123
Validation loss: 2.451570904664267

Epoch: 6| Step: 3
Training loss: 2.5307381194786482
Validation loss: 2.455496744087512

Epoch: 6| Step: 4
Training loss: 2.102466488093717
Validation loss: 2.456864418873924

Epoch: 6| Step: 5
Training loss: 2.1511067402920485
Validation loss: 2.4363503649161293

Epoch: 6| Step: 6
Training loss: 1.9405787218261072
Validation loss: 2.4564235058294837

Epoch: 6| Step: 7
Training loss: 1.7208098119770767
Validation loss: 2.4853607232363997

Epoch: 6| Step: 8
Training loss: 2.1647791588190977
Validation loss: 2.4446537079581803

Epoch: 6| Step: 9
Training loss: 1.79903249169907
Validation loss: 2.4459894983405617

Epoch: 6| Step: 10
Training loss: 2.047719300837391
Validation loss: 2.4134755039348117

Epoch: 6| Step: 11
Training loss: 2.9304487943160513
Validation loss: 2.433127685377485

Epoch: 6| Step: 12
Training loss: 1.9840988808109965
Validation loss: 2.473866050739108

Epoch: 6| Step: 13
Training loss: 2.1331763323987545
Validation loss: 2.427573121392342

Epoch: 368| Step: 0
Training loss: 2.0181997251926833
Validation loss: 2.4379828000949275

Epoch: 6| Step: 1
Training loss: 2.1253327501855397
Validation loss: 2.450093822386304

Epoch: 6| Step: 2
Training loss: 2.262994857539505
Validation loss: 2.472142604094119

Epoch: 6| Step: 3
Training loss: 2.467949653013029
Validation loss: 2.42157259457996

Epoch: 6| Step: 4
Training loss: 2.1509344953266325
Validation loss: 2.447586819312421

Epoch: 6| Step: 5
Training loss: 1.948976429036832
Validation loss: 2.4318456894177185

Epoch: 6| Step: 6
Training loss: 1.7682896989022399
Validation loss: 2.4872668433590004

Epoch: 6| Step: 7
Training loss: 2.1796121344987616
Validation loss: 2.4537387386093674

Epoch: 6| Step: 8
Training loss: 1.2537573134721487
Validation loss: 2.4615892845731326

Epoch: 6| Step: 9
Training loss: 2.1839330747362102
Validation loss: 2.464477145690359

Epoch: 6| Step: 10
Training loss: 2.40362802308091
Validation loss: 2.4107127149969285

Epoch: 6| Step: 11
Training loss: 1.4904340257807718
Validation loss: 2.466136764774948

Epoch: 6| Step: 12
Training loss: 2.4962894559978857
Validation loss: 2.4218472704456047

Epoch: 6| Step: 13
Training loss: 3.0491197973171067
Validation loss: 2.4349057127891602

Epoch: 369| Step: 0
Training loss: 2.089394323206584
Validation loss: 2.4400488865721046

Epoch: 6| Step: 1
Training loss: 1.7884921701551557
Validation loss: 2.452197231057317

Epoch: 6| Step: 2
Training loss: 1.918769436219028
Validation loss: 2.444145310146326

Epoch: 6| Step: 3
Training loss: 2.4337307078611286
Validation loss: 2.437648756559052

Epoch: 6| Step: 4
Training loss: 2.346915688396923
Validation loss: 2.4061722313371887

Epoch: 6| Step: 5
Training loss: 1.8168778002244637
Validation loss: 2.455854537161755

Epoch: 6| Step: 6
Training loss: 2.3010715890794984
Validation loss: 2.4258409411897377

Epoch: 6| Step: 7
Training loss: 2.379594875444187
Validation loss: 2.4801144427695747

Epoch: 6| Step: 8
Training loss: 2.233181507966151
Validation loss: 2.4484155953292555

Epoch: 6| Step: 9
Training loss: 2.412833978334779
Validation loss: 2.404454583566685

Epoch: 6| Step: 10
Training loss: 1.7416234493217226
Validation loss: 2.446995741590117

Epoch: 6| Step: 11
Training loss: 1.857655603763411
Validation loss: 2.4377261357444584

Epoch: 6| Step: 12
Training loss: 2.0595591993832465
Validation loss: 2.463355107907299

Epoch: 6| Step: 13
Training loss: 2.228810564160693
Validation loss: 2.46386877009186

Epoch: 370| Step: 0
Training loss: 1.6895921242042695
Validation loss: 2.43284844105812

Epoch: 6| Step: 1
Training loss: 1.9791545532926658
Validation loss: 2.4610220299999317

Epoch: 6| Step: 2
Training loss: 2.6014921161650193
Validation loss: 2.4548950915469807

Epoch: 6| Step: 3
Training loss: 2.482260133770049
Validation loss: 2.393879781395446

Epoch: 6| Step: 4
Training loss: 1.4208527128328015
Validation loss: 2.4181268963574576

Epoch: 6| Step: 5
Training loss: 2.108226548256134
Validation loss: 2.4170939861896605

Epoch: 6| Step: 6
Training loss: 2.130251734010877
Validation loss: 2.4368823788494844

Epoch: 6| Step: 7
Training loss: 1.965753666922477
Validation loss: 2.4478405007002686

Epoch: 6| Step: 8
Training loss: 2.1690145633502302
Validation loss: 2.437091613332113

Epoch: 6| Step: 9
Training loss: 2.1312771255691083
Validation loss: 2.4853565663024364

Epoch: 6| Step: 10
Training loss: 2.4320974878297164
Validation loss: 2.453524967963938

Epoch: 6| Step: 11
Training loss: 1.74242396097093
Validation loss: 2.4310445286248235

Epoch: 6| Step: 12
Training loss: 2.455094051385295
Validation loss: 2.434053077344113

Epoch: 6| Step: 13
Training loss: 1.9187416026773507
Validation loss: 2.457315747067947

Epoch: 371| Step: 0
Training loss: 1.8341598670529553
Validation loss: 2.417245277568937

Epoch: 6| Step: 1
Training loss: 1.9713731879891823
Validation loss: 2.4774412893597066

Epoch: 6| Step: 2
Training loss: 1.319507240451897
Validation loss: 2.404708809822045

Epoch: 6| Step: 3
Training loss: 1.8531192721556584
Validation loss: 2.415085488675485

Epoch: 6| Step: 4
Training loss: 3.143381607585723
Validation loss: 2.4230482368451987

Epoch: 6| Step: 5
Training loss: 2.673566851449105
Validation loss: 2.4625123026750657

Epoch: 6| Step: 6
Training loss: 2.052265669052935
Validation loss: 2.4124827980322125

Epoch: 6| Step: 7
Training loss: 1.6685923498315525
Validation loss: 2.424924826928968

Epoch: 6| Step: 8
Training loss: 2.060660032808175
Validation loss: 2.433566018081203

Epoch: 6| Step: 9
Training loss: 1.8365122443335455
Validation loss: 2.4410433733596686

Epoch: 6| Step: 10
Training loss: 2.0172474563399163
Validation loss: 2.413747791719147

Epoch: 6| Step: 11
Training loss: 2.2203284008683575
Validation loss: 2.4413457433278363

Epoch: 6| Step: 12
Training loss: 2.561827036252033
Validation loss: 2.4695806937264844

Epoch: 6| Step: 13
Training loss: 2.1509397049969743
Validation loss: 2.4720214719458067

Epoch: 372| Step: 0
Training loss: 1.8224372742040267
Validation loss: 2.486833697866941

Epoch: 6| Step: 1
Training loss: 2.232176332495219
Validation loss: 2.448509463601221

Epoch: 6| Step: 2
Training loss: 2.841099268703307
Validation loss: 2.442943434081685

Epoch: 6| Step: 3
Training loss: 2.1123808742545127
Validation loss: 2.4711971467559537

Epoch: 6| Step: 4
Training loss: 1.8874639772931359
Validation loss: 2.4279216427859054

Epoch: 6| Step: 5
Training loss: 2.1062428143206087
Validation loss: 2.449253127108414

Epoch: 6| Step: 6
Training loss: 1.8076099991204653
Validation loss: 2.424116186754718

Epoch: 6| Step: 7
Training loss: 1.7800250609916082
Validation loss: 2.4866316134315634

Epoch: 6| Step: 8
Training loss: 2.3960526628581635
Validation loss: 2.473173951097087

Epoch: 6| Step: 9
Training loss: 2.186257472693452
Validation loss: 2.483064858750629

Epoch: 6| Step: 10
Training loss: 2.0426400906765396
Validation loss: 2.4615343095833735

Epoch: 6| Step: 11
Training loss: 2.3525941936514343
Validation loss: 2.4481977037443508

Epoch: 6| Step: 12
Training loss: 2.1611193532821966
Validation loss: 2.46513414574498

Epoch: 6| Step: 13
Training loss: 1.456849851387127
Validation loss: 2.4633786507579165

Epoch: 373| Step: 0
Training loss: 1.9302310564158747
Validation loss: 2.4393605729355743

Epoch: 6| Step: 1
Training loss: 2.301737717681164
Validation loss: 2.472483777082017

Epoch: 6| Step: 2
Training loss: 1.978605277768874
Validation loss: 2.4721909760654457

Epoch: 6| Step: 3
Training loss: 1.56166069377027
Validation loss: 2.4523139879074707

Epoch: 6| Step: 4
Training loss: 1.8788182481868354
Validation loss: 2.461552600000613

Epoch: 6| Step: 5
Training loss: 1.815120775392165
Validation loss: 2.4378703456294764

Epoch: 6| Step: 6
Training loss: 2.5629539087730144
Validation loss: 2.442458008078269

Epoch: 6| Step: 7
Training loss: 2.254300775493182
Validation loss: 2.413614392567824

Epoch: 6| Step: 8
Training loss: 2.712902577142498
Validation loss: 2.4440683235226532

Epoch: 6| Step: 9
Training loss: 1.765009544930301
Validation loss: 2.406071083460604

Epoch: 6| Step: 10
Training loss: 2.120768204184254
Validation loss: 2.445388523851557

Epoch: 6| Step: 11
Training loss: 2.2770704887379205
Validation loss: 2.4732673181680904

Epoch: 6| Step: 12
Training loss: 2.165497452143613
Validation loss: 2.3997401872785837

Epoch: 6| Step: 13
Training loss: 2.22140075944795
Validation loss: 2.4565251023060406

Epoch: 374| Step: 0
Training loss: 2.217045303742171
Validation loss: 2.467344160780325

Epoch: 6| Step: 1
Training loss: 2.2455032766654197
Validation loss: 2.4195352335641487

Epoch: 6| Step: 2
Training loss: 1.845677031478912
Validation loss: 2.46681827844443

Epoch: 6| Step: 3
Training loss: 1.9383807487734643
Validation loss: 2.4367663675911087

Epoch: 6| Step: 4
Training loss: 2.0026601743038372
Validation loss: 2.4290763435322797

Epoch: 6| Step: 5
Training loss: 1.8435980524070619
Validation loss: 2.4307332482454385

Epoch: 6| Step: 6
Training loss: 2.583505829825375
Validation loss: 2.452712153410272

Epoch: 6| Step: 7
Training loss: 2.4120330674923918
Validation loss: 2.4710391039466013

Epoch: 6| Step: 8
Training loss: 1.9835899782689561
Validation loss: 2.4187004123064844

Epoch: 6| Step: 9
Training loss: 1.670157789553863
Validation loss: 2.414385773317542

Epoch: 6| Step: 10
Training loss: 1.8768776710737685
Validation loss: 2.42606225246437

Epoch: 6| Step: 11
Training loss: 2.6313718935171795
Validation loss: 2.4257050903977033

Epoch: 6| Step: 12
Training loss: 1.9276430983804773
Validation loss: 2.4667253199468675

Epoch: 6| Step: 13
Training loss: 2.160345196867599
Validation loss: 2.4278145326433567

Epoch: 375| Step: 0
Training loss: 2.320749158263041
Validation loss: 2.433869321206569

Epoch: 6| Step: 1
Training loss: 1.8045259213465923
Validation loss: 2.4723268783411783

Epoch: 6| Step: 2
Training loss: 1.9958725300910554
Validation loss: 2.464318149678194

Epoch: 6| Step: 3
Training loss: 2.5795868399359048
Validation loss: 2.3908792310011013

Epoch: 6| Step: 4
Training loss: 1.9680837078977929
Validation loss: 2.427536542155758

Epoch: 6| Step: 5
Training loss: 2.3118361473892324
Validation loss: 2.450191184317811

Epoch: 6| Step: 6
Training loss: 1.5357176552542287
Validation loss: 2.4261873682813

Epoch: 6| Step: 7
Training loss: 1.6196756433799642
Validation loss: 2.437407043510375

Epoch: 6| Step: 8
Training loss: 1.7363013489657162
Validation loss: 2.4469196932867554

Epoch: 6| Step: 9
Training loss: 2.7825547490384595
Validation loss: 2.4537088402065548

Epoch: 6| Step: 10
Training loss: 2.11776218849325
Validation loss: 2.44885017191513

Epoch: 6| Step: 11
Training loss: 2.1161334239668785
Validation loss: 2.490739488455451

Epoch: 6| Step: 12
Training loss: 2.6555528511271236
Validation loss: 2.4711616681719915

Epoch: 6| Step: 13
Training loss: 2.149132300648547
Validation loss: 2.4152500274127076

Epoch: 376| Step: 0
Training loss: 2.1555218780263843
Validation loss: 2.401103821412803

Epoch: 6| Step: 1
Training loss: 2.2083585005951543
Validation loss: 2.4337577500546392

Epoch: 6| Step: 2
Training loss: 2.031889594690668
Validation loss: 2.4562877704833186

Epoch: 6| Step: 3
Training loss: 1.9743775968422859
Validation loss: 2.4507422489986994

Epoch: 6| Step: 4
Training loss: 2.203551339095216
Validation loss: 2.4303761734716907

Epoch: 6| Step: 5
Training loss: 2.1767723798371352
Validation loss: 2.3967485567482125

Epoch: 6| Step: 6
Training loss: 1.4550435516551161
Validation loss: 2.4344838457436153

Epoch: 6| Step: 7
Training loss: 1.8827869840926965
Validation loss: 2.4329349337983888

Epoch: 6| Step: 8
Training loss: 3.2447602508803883
Validation loss: 2.466980939592749

Epoch: 6| Step: 9
Training loss: 1.627407857627506
Validation loss: 2.4723342685611613

Epoch: 6| Step: 10
Training loss: 1.9496454601276954
Validation loss: 2.4405862849352618

Epoch: 6| Step: 11
Training loss: 1.9327260546214315
Validation loss: 2.447374253843176

Epoch: 6| Step: 12
Training loss: 2.187134957508836
Validation loss: 2.4146233213297728

Epoch: 6| Step: 13
Training loss: 2.257438655116947
Validation loss: 2.450984680822289

Epoch: 377| Step: 0
Training loss: 1.9185747172162417
Validation loss: 2.4500935398734445

Epoch: 6| Step: 1
Training loss: 1.3780226861943825
Validation loss: 2.450010710929945

Epoch: 6| Step: 2
Training loss: 1.9034192062999415
Validation loss: 2.437344020483672

Epoch: 6| Step: 3
Training loss: 1.7991909858128392
Validation loss: 2.413472634878357

Epoch: 6| Step: 4
Training loss: 2.513168367525398
Validation loss: 2.4457348608153784

Epoch: 6| Step: 5
Training loss: 2.534216096649578
Validation loss: 2.436788693395268

Epoch: 6| Step: 6
Training loss: 1.6768493805078821
Validation loss: 2.4139556537222417

Epoch: 6| Step: 7
Training loss: 1.9754826909540137
Validation loss: 2.4327119593830075

Epoch: 6| Step: 8
Training loss: 2.7309470351288763
Validation loss: 2.4711271518210896

Epoch: 6| Step: 9
Training loss: 2.923926627641009
Validation loss: 2.4078138905635296

Epoch: 6| Step: 10
Training loss: 1.2725910111502678
Validation loss: 2.444241750572415

Epoch: 6| Step: 11
Training loss: 2.300036376167898
Validation loss: 2.4509497338850084

Epoch: 6| Step: 12
Training loss: 1.9027462637241497
Validation loss: 2.4642785356143975

Epoch: 6| Step: 13
Training loss: 2.342166620101644
Validation loss: 2.4420007445710916

Epoch: 378| Step: 0
Training loss: 2.6172131892978956
Validation loss: 2.470326240416602

Epoch: 6| Step: 1
Training loss: 1.9924224714945327
Validation loss: 2.408231737670976

Epoch: 6| Step: 2
Training loss: 2.244474407768212
Validation loss: 2.4404430843290315

Epoch: 6| Step: 3
Training loss: 1.7388907403431637
Validation loss: 2.4203124902975555

Epoch: 6| Step: 4
Training loss: 1.7623379247288244
Validation loss: 2.4463925872944694

Epoch: 6| Step: 5
Training loss: 1.9307429712867261
Validation loss: 2.4259739438401304

Epoch: 6| Step: 6
Training loss: 2.07305611248413
Validation loss: 2.4461850627652106

Epoch: 6| Step: 7
Training loss: 1.6885776610855332
Validation loss: 2.451895933728414

Epoch: 6| Step: 8
Training loss: 1.4315063080483788
Validation loss: 2.452958621199994

Epoch: 6| Step: 9
Training loss: 2.558821759729502
Validation loss: 2.437213886171803

Epoch: 6| Step: 10
Training loss: 2.5445211567852764
Validation loss: 2.456275724006872

Epoch: 6| Step: 11
Training loss: 2.4332576905429533
Validation loss: 2.3849663462300024

Epoch: 6| Step: 12
Training loss: 1.7049257750030216
Validation loss: 2.423595487142661

Epoch: 6| Step: 13
Training loss: 2.161506768721872
Validation loss: 2.418568769239267

Epoch: 379| Step: 0
Training loss: 2.1783299747821547
Validation loss: 2.4331360776055497

Epoch: 6| Step: 1
Training loss: 2.3885053824591087
Validation loss: 2.4391558050277764

Epoch: 6| Step: 2
Training loss: 2.1537237433871574
Validation loss: 2.4964589687814254

Epoch: 6| Step: 3
Training loss: 2.847208958623329
Validation loss: 2.4532912494336747

Epoch: 6| Step: 4
Training loss: 2.147696294373059
Validation loss: 2.4162801381107686

Epoch: 6| Step: 5
Training loss: 1.7300913379790803
Validation loss: 2.4602267810593803

Epoch: 6| Step: 6
Training loss: 1.7665035121482229
Validation loss: 2.4139134672029248

Epoch: 6| Step: 7
Training loss: 2.0245175811313207
Validation loss: 2.441703424033915

Epoch: 6| Step: 8
Training loss: 1.6185526223052695
Validation loss: 2.4221174560026886

Epoch: 6| Step: 9
Training loss: 1.855156609229875
Validation loss: 2.4440600537959973

Epoch: 6| Step: 10
Training loss: 2.5637743502631785
Validation loss: 2.432593088738761

Epoch: 6| Step: 11
Training loss: 2.308074428026015
Validation loss: 2.448090306295754

Epoch: 6| Step: 12
Training loss: 1.688516310780518
Validation loss: 2.404958054526798

Epoch: 6| Step: 13
Training loss: 1.9677219431460153
Validation loss: 2.44021745880751

Epoch: 380| Step: 0
Training loss: 1.7146011215653039
Validation loss: 2.4354343112153507

Epoch: 6| Step: 1
Training loss: 1.7817623004041818
Validation loss: 2.429900122974717

Epoch: 6| Step: 2
Training loss: 1.6831634042284374
Validation loss: 2.426855028394426

Epoch: 6| Step: 3
Training loss: 2.112979098735218
Validation loss: 2.4628337824825377

Epoch: 6| Step: 4
Training loss: 2.2281669323842315
Validation loss: 2.4126778938852755

Epoch: 6| Step: 5
Training loss: 2.738384598592453
Validation loss: 2.487959306097193

Epoch: 6| Step: 6
Training loss: 2.434167099425597
Validation loss: 2.447281718505004

Epoch: 6| Step: 7
Training loss: 1.951741514402237
Validation loss: 2.4263088746393895

Epoch: 6| Step: 8
Training loss: 1.8954781908789609
Validation loss: 2.433851414718844

Epoch: 6| Step: 9
Training loss: 2.038393926814148
Validation loss: 2.4322758927707406

Epoch: 6| Step: 10
Training loss: 2.45262461618866
Validation loss: 2.4674060658348336

Epoch: 6| Step: 11
Training loss: 1.9681859495114398
Validation loss: 2.460865609453182

Epoch: 6| Step: 12
Training loss: 2.023717676744574
Validation loss: 2.4871242081239533

Epoch: 6| Step: 13
Training loss: 2.0593732773074644
Validation loss: 2.4210771710627297

Epoch: 381| Step: 0
Training loss: 1.7985152346252387
Validation loss: 2.447918664167362

Epoch: 6| Step: 1
Training loss: 2.2389990702427394
Validation loss: 2.4749922987494

Epoch: 6| Step: 2
Training loss: 2.413399318228559
Validation loss: 2.4410448237176197

Epoch: 6| Step: 3
Training loss: 1.4803745370645274
Validation loss: 2.435943911404539

Epoch: 6| Step: 4
Training loss: 1.9713454924526557
Validation loss: 2.4775911317516086

Epoch: 6| Step: 5
Training loss: 2.368251649475651
Validation loss: 2.4782616471519123

Epoch: 6| Step: 6
Training loss: 2.1886207979020207
Validation loss: 2.4270952884513957

Epoch: 6| Step: 7
Training loss: 1.6653516190784565
Validation loss: 2.4476791074565396

Epoch: 6| Step: 8
Training loss: 1.9011932591304948
Validation loss: 2.419641626854512

Epoch: 6| Step: 9
Training loss: 2.0354006102549134
Validation loss: 2.4437338797115715

Epoch: 6| Step: 10
Training loss: 2.1588317231843477
Validation loss: 2.4521775347690524

Epoch: 6| Step: 11
Training loss: 2.111781577115247
Validation loss: 2.450419935601832

Epoch: 6| Step: 12
Training loss: 2.479215434473621
Validation loss: 2.468628281832286

Epoch: 6| Step: 13
Training loss: 2.515670775950703
Validation loss: 2.4620633832762135

Epoch: 382| Step: 0
Training loss: 1.632504155736427
Validation loss: 2.4153155427865434

Epoch: 6| Step: 1
Training loss: 2.358419464838973
Validation loss: 2.4799177611235277

Epoch: 6| Step: 2
Training loss: 2.131077993840798
Validation loss: 2.4574444955734642

Epoch: 6| Step: 3
Training loss: 1.9762592912391599
Validation loss: 2.446693357363588

Epoch: 6| Step: 4
Training loss: 2.2215602431833843
Validation loss: 2.427426662787697

Epoch: 6| Step: 5
Training loss: 1.8881707774285428
Validation loss: 2.458371306206569

Epoch: 6| Step: 6
Training loss: 1.8857592557730276
Validation loss: 2.459648682137113

Epoch: 6| Step: 7
Training loss: 2.5283252160535685
Validation loss: 2.4224829094406877

Epoch: 6| Step: 8
Training loss: 2.4298757989170645
Validation loss: 2.4238088581786688

Epoch: 6| Step: 9
Training loss: 1.9134359774598277
Validation loss: 2.4552742383108064

Epoch: 6| Step: 10
Training loss: 2.2522213884421203
Validation loss: 2.4277604385756373

Epoch: 6| Step: 11
Training loss: 1.1913012849189684
Validation loss: 2.399375124863012

Epoch: 6| Step: 12
Training loss: 2.2836328890066655
Validation loss: 2.438095534328187

Epoch: 6| Step: 13
Training loss: 2.6367444298517997
Validation loss: 2.469392546710804

Epoch: 383| Step: 0
Training loss: 1.5378901475087365
Validation loss: 2.420100609182023

Epoch: 6| Step: 1
Training loss: 1.9713341843378842
Validation loss: 2.4308240458792985

Epoch: 6| Step: 2
Training loss: 2.644129126669304
Validation loss: 2.394402327440465

Epoch: 6| Step: 3
Training loss: 1.9961487525483703
Validation loss: 2.449764221780028

Epoch: 6| Step: 4
Training loss: 1.8591285991091397
Validation loss: 2.408408102935785

Epoch: 6| Step: 5
Training loss: 2.258071620552032
Validation loss: 2.4400075567502673

Epoch: 6| Step: 6
Training loss: 1.1201873198606285
Validation loss: 2.469299773370826

Epoch: 6| Step: 7
Training loss: 2.2834819169904037
Validation loss: 2.4385627194756623

Epoch: 6| Step: 8
Training loss: 2.8765481843856335
Validation loss: 2.4656540469469483

Epoch: 6| Step: 9
Training loss: 2.689556754227396
Validation loss: 2.450196243707288

Epoch: 6| Step: 10
Training loss: 1.9755477411308446
Validation loss: 2.4688307641327167

Epoch: 6| Step: 11
Training loss: 2.293052450858662
Validation loss: 2.4064933995748716

Epoch: 6| Step: 12
Training loss: 1.549131654723701
Validation loss: 2.4109885079380167

Epoch: 6| Step: 13
Training loss: 1.6209503478082894
Validation loss: 2.429776663334994

Epoch: 384| Step: 0
Training loss: 1.7367340402963958
Validation loss: 2.4415811975288038

Epoch: 6| Step: 1
Training loss: 2.0936931773204153
Validation loss: 2.42854031036345

Epoch: 6| Step: 2
Training loss: 1.8992494958031052
Validation loss: 2.4537472802716094

Epoch: 6| Step: 3
Training loss: 1.7063858592960925
Validation loss: 2.464690589985904

Epoch: 6| Step: 4
Training loss: 1.924753096463435
Validation loss: 2.427159927457378

Epoch: 6| Step: 5
Training loss: 2.588299367042738
Validation loss: 2.413500276889811

Epoch: 6| Step: 6
Training loss: 2.1735556706788164
Validation loss: 2.4089942186788407

Epoch: 6| Step: 7
Training loss: 2.167296379231153
Validation loss: 2.423941459378277

Epoch: 6| Step: 8
Training loss: 2.0976731851984556
Validation loss: 2.4372108967455586

Epoch: 6| Step: 9
Training loss: 2.2695154921596883
Validation loss: 2.471310039625834

Epoch: 6| Step: 10
Training loss: 1.721176584599304
Validation loss: 2.4113179355587318

Epoch: 6| Step: 11
Training loss: 1.5691272570738843
Validation loss: 2.481998364780906

Epoch: 6| Step: 12
Training loss: 2.6177669054596095
Validation loss: 2.447140940485211

Epoch: 6| Step: 13
Training loss: 2.5649481453217913
Validation loss: 2.448371748207573

Epoch: 385| Step: 0
Training loss: 2.1028522376927334
Validation loss: 2.4279770209021807

Epoch: 6| Step: 1
Training loss: 2.555286675511981
Validation loss: 2.410918413183615

Epoch: 6| Step: 2
Training loss: 1.5317247394404585
Validation loss: 2.424714181478578

Epoch: 6| Step: 3
Training loss: 1.7166913274580062
Validation loss: 2.410191863948922

Epoch: 6| Step: 4
Training loss: 1.839494935356648
Validation loss: 2.43315701537717

Epoch: 6| Step: 5
Training loss: 2.4023616138817525
Validation loss: 2.440254126882522

Epoch: 6| Step: 6
Training loss: 2.126653925200812
Validation loss: 2.4989522245713958

Epoch: 6| Step: 7
Training loss: 2.164144245903594
Validation loss: 2.4439407123570995

Epoch: 6| Step: 8
Training loss: 2.142177269575202
Validation loss: 2.4550951874885594

Epoch: 6| Step: 9
Training loss: 2.2445081869627415
Validation loss: 2.4434658420244153

Epoch: 6| Step: 10
Training loss: 2.279952006587803
Validation loss: 2.473217149120728

Epoch: 6| Step: 11
Training loss: 1.5386124160949923
Validation loss: 2.428784627919796

Epoch: 6| Step: 12
Training loss: 2.379357406354769
Validation loss: 2.4656692427090947

Epoch: 6| Step: 13
Training loss: 1.6257237509917157
Validation loss: 2.4385539674569343

Epoch: 386| Step: 0
Training loss: 1.9241581202939926
Validation loss: 2.4046132967499547

Epoch: 6| Step: 1
Training loss: 1.4141744495568065
Validation loss: 2.4236962389786667

Epoch: 6| Step: 2
Training loss: 2.8065785273064683
Validation loss: 2.419859283320305

Epoch: 6| Step: 3
Training loss: 2.457791403396774
Validation loss: 2.427996838542259

Epoch: 6| Step: 4
Training loss: 2.344640130448294
Validation loss: 2.449195326439131

Epoch: 6| Step: 5
Training loss: 2.0456131401615654
Validation loss: 2.426718610026531

Epoch: 6| Step: 6
Training loss: 2.0547796308509247
Validation loss: 2.4265882693186764

Epoch: 6| Step: 7
Training loss: 1.8148060302492934
Validation loss: 2.445702350405502

Epoch: 6| Step: 8
Training loss: 1.9873742693592544
Validation loss: 2.474524742445769

Epoch: 6| Step: 9
Training loss: 2.2480406176946475
Validation loss: 2.435826115186654

Epoch: 6| Step: 10
Training loss: 1.9136935131424917
Validation loss: 2.394679607009817

Epoch: 6| Step: 11
Training loss: 2.351330108819187
Validation loss: 2.4613744620914035

Epoch: 6| Step: 12
Training loss: 1.5848619544145734
Validation loss: 2.419250422142076

Epoch: 6| Step: 13
Training loss: 1.7892423314496126
Validation loss: 2.4407982809453443

Epoch: 387| Step: 0
Training loss: 2.320746076257346
Validation loss: 2.458082156717833

Epoch: 6| Step: 1
Training loss: 1.930332153378359
Validation loss: 2.422511015866697

Epoch: 6| Step: 2
Training loss: 2.0396683183939635
Validation loss: 2.467837937668801

Epoch: 6| Step: 3
Training loss: 2.073561167245047
Validation loss: 2.4258875944510083

Epoch: 6| Step: 4
Training loss: 1.8246087059782545
Validation loss: 2.450243962898697

Epoch: 6| Step: 5
Training loss: 3.063897261767121
Validation loss: 2.445490096021647

Epoch: 6| Step: 6
Training loss: 1.7472486666140625
Validation loss: 2.4428171053638

Epoch: 6| Step: 7
Training loss: 2.188336021884604
Validation loss: 2.432459242316485

Epoch: 6| Step: 8
Training loss: 1.4521867738036083
Validation loss: 2.431660884043516

Epoch: 6| Step: 9
Training loss: 1.9982153559525682
Validation loss: 2.444005843072861

Epoch: 6| Step: 10
Training loss: 1.7313603500287313
Validation loss: 2.4363182343637595

Epoch: 6| Step: 11
Training loss: 2.1764942692497833
Validation loss: 2.424612958074664

Epoch: 6| Step: 12
Training loss: 2.206354790379157
Validation loss: 2.4294252929759694

Epoch: 6| Step: 13
Training loss: 1.431098450212437
Validation loss: 2.4202523227408164

Epoch: 388| Step: 0
Training loss: 1.4997323115228216
Validation loss: 2.4165459260774935

Epoch: 6| Step: 1
Training loss: 2.4371312180335254
Validation loss: 2.451041543971019

Epoch: 6| Step: 2
Training loss: 1.6931052187710705
Validation loss: 2.440388638834406

Epoch: 6| Step: 3
Training loss: 2.533630382121277
Validation loss: 2.441724581796128

Epoch: 6| Step: 4
Training loss: 2.471861604637377
Validation loss: 2.408744492809787

Epoch: 6| Step: 5
Training loss: 2.1485540185022955
Validation loss: 2.470543839612238

Epoch: 6| Step: 6
Training loss: 1.8418839920492378
Validation loss: 2.425587091821126

Epoch: 6| Step: 7
Training loss: 1.4418349210131947
Validation loss: 2.426943947204298

Epoch: 6| Step: 8
Training loss: 1.6525388201195013
Validation loss: 2.42651549369707

Epoch: 6| Step: 9
Training loss: 2.21807700682716
Validation loss: 2.4284733877611315

Epoch: 6| Step: 10
Training loss: 2.3124885558798858
Validation loss: 2.4701998529002704

Epoch: 6| Step: 11
Training loss: 1.8410086214194177
Validation loss: 2.4202823754588096

Epoch: 6| Step: 12
Training loss: 2.6046007532092443
Validation loss: 2.4426731109091264

Epoch: 6| Step: 13
Training loss: 2.0741312759259407
Validation loss: 2.441087794250561

Epoch: 389| Step: 0
Training loss: 1.9292160879221656
Validation loss: 2.4139276845129434

Epoch: 6| Step: 1
Training loss: 2.437951950820208
Validation loss: 2.431606510227965

Epoch: 6| Step: 2
Training loss: 2.2623068879894115
Validation loss: 2.3975503792087314

Epoch: 6| Step: 3
Training loss: 2.4993172666993644
Validation loss: 2.426316001403369

Epoch: 6| Step: 4
Training loss: 2.3134722341269134
Validation loss: 2.4713772093933093

Epoch: 6| Step: 5
Training loss: 2.1722558874506395
Validation loss: 2.432637221317098

Epoch: 6| Step: 6
Training loss: 2.2862452333128447
Validation loss: 2.4414439271706296

Epoch: 6| Step: 7
Training loss: 2.034115105829419
Validation loss: 2.45617336727801

Epoch: 6| Step: 8
Training loss: 1.9002157289606239
Validation loss: 2.442954396157033

Epoch: 6| Step: 9
Training loss: 1.7642742154952977
Validation loss: 2.4227259754822623

Epoch: 6| Step: 10
Training loss: 1.8768730980110504
Validation loss: 2.452795390729735

Epoch: 6| Step: 11
Training loss: 1.3564215837219877
Validation loss: 2.434136686265741

Epoch: 6| Step: 12
Training loss: 1.973866610715213
Validation loss: 2.422323139288666

Epoch: 6| Step: 13
Training loss: 2.442264204718276
Validation loss: 2.466654563093658

Epoch: 390| Step: 0
Training loss: 1.463220128841446
Validation loss: 2.443620129873667

Epoch: 6| Step: 1
Training loss: 2.4359217694002786
Validation loss: 2.4608120512740497

Epoch: 6| Step: 2
Training loss: 2.129664070968889
Validation loss: 2.4336091638590243

Epoch: 6| Step: 3
Training loss: 1.9314130720405833
Validation loss: 2.4165062948387472

Epoch: 6| Step: 4
Training loss: 2.0917209643526555
Validation loss: 2.436591844525039

Epoch: 6| Step: 5
Training loss: 1.9010173708961349
Validation loss: 2.4156439579346847

Epoch: 6| Step: 6
Training loss: 2.8253548053299387
Validation loss: 2.4105521562145658

Epoch: 6| Step: 7
Training loss: 2.0696573624395875
Validation loss: 2.4397720531326472

Epoch: 6| Step: 8
Training loss: 2.2602993162665403
Validation loss: 2.412239094136073

Epoch: 6| Step: 9
Training loss: 1.4141134600651097
Validation loss: 2.4401495032752663

Epoch: 6| Step: 10
Training loss: 2.6780333459899053
Validation loss: 2.4370286894474456

Epoch: 6| Step: 11
Training loss: 1.5017211099903176
Validation loss: 2.419312825060327

Epoch: 6| Step: 12
Training loss: 2.0023441881766493
Validation loss: 2.4269655500028944

Epoch: 6| Step: 13
Training loss: 1.6139832232523936
Validation loss: 2.470673914904536

Epoch: 391| Step: 0
Training loss: 2.2224742097506085
Validation loss: 2.416271812004771

Epoch: 6| Step: 1
Training loss: 2.3066120969605457
Validation loss: 2.3976836355039115

Epoch: 6| Step: 2
Training loss: 1.5729285317619754
Validation loss: 2.44498848572814

Epoch: 6| Step: 3
Training loss: 1.9690728301319302
Validation loss: 2.384763280407762

Epoch: 6| Step: 4
Training loss: 1.97073512434145
Validation loss: 2.4257411651287604

Epoch: 6| Step: 5
Training loss: 1.9147837000270824
Validation loss: 2.4292229665105696

Epoch: 6| Step: 6
Training loss: 2.452016008782206
Validation loss: 2.4404373612983865

Epoch: 6| Step: 7
Training loss: 1.5740585056274699
Validation loss: 2.480604450937716

Epoch: 6| Step: 8
Training loss: 1.9680458505026721
Validation loss: 2.442289110258503

Epoch: 6| Step: 9
Training loss: 2.4497958390164984
Validation loss: 2.442966573909369

Epoch: 6| Step: 10
Training loss: 2.205537597792402
Validation loss: 2.452699980667993

Epoch: 6| Step: 11
Training loss: 1.8425472668572243
Validation loss: 2.457687682817046

Epoch: 6| Step: 12
Training loss: 2.553933595246643
Validation loss: 2.4275385645227487

Epoch: 6| Step: 13
Training loss: 1.7136512033377882
Validation loss: 2.4115238255664346

Epoch: 392| Step: 0
Training loss: 1.1797087711664904
Validation loss: 2.462316448815975

Epoch: 6| Step: 1
Training loss: 2.4227295383167555
Validation loss: 2.4405481228784502

Epoch: 6| Step: 2
Training loss: 2.340613338915065
Validation loss: 2.3937762335011805

Epoch: 6| Step: 3
Training loss: 2.5156827173660723
Validation loss: 2.455763494743842

Epoch: 6| Step: 4
Training loss: 2.0727842151236633
Validation loss: 2.486000044996063

Epoch: 6| Step: 5
Training loss: 1.6541602428449274
Validation loss: 2.4136062086240067

Epoch: 6| Step: 6
Training loss: 1.806211810384759
Validation loss: 2.4114884417812887

Epoch: 6| Step: 7
Training loss: 2.3580865436555514
Validation loss: 2.4685083854910213

Epoch: 6| Step: 8
Training loss: 2.0474376341994596
Validation loss: 2.4230571273957096

Epoch: 6| Step: 9
Training loss: 1.4184851008410286
Validation loss: 2.4111870292121123

Epoch: 6| Step: 10
Training loss: 1.931984094645106
Validation loss: 2.4319339081629465

Epoch: 6| Step: 11
Training loss: 2.840052118226129
Validation loss: 2.4492243897085157

Epoch: 6| Step: 12
Training loss: 1.9167706696308966
Validation loss: 2.4475336267801975

Epoch: 6| Step: 13
Training loss: 1.811259864901366
Validation loss: 2.4464990533043705

Epoch: 393| Step: 0
Training loss: 1.9183055947046843
Validation loss: 2.41223155912823

Epoch: 6| Step: 1
Training loss: 2.320992418335148
Validation loss: 2.422947245392278

Epoch: 6| Step: 2
Training loss: 2.070267241361143
Validation loss: 2.4262665595093873

Epoch: 6| Step: 3
Training loss: 2.166244783653851
Validation loss: 2.4408384567401518

Epoch: 6| Step: 4
Training loss: 2.026677310606127
Validation loss: 2.4366873308541175

Epoch: 6| Step: 5
Training loss: 2.2532175158845984
Validation loss: 2.4135047976451767

Epoch: 6| Step: 6
Training loss: 2.4863268784057655
Validation loss: 2.4496768031721685

Epoch: 6| Step: 7
Training loss: 2.0505098871803367
Validation loss: 2.436955634396077

Epoch: 6| Step: 8
Training loss: 2.0312441312264977
Validation loss: 2.4489880729090108

Epoch: 6| Step: 9
Training loss: 1.9369227872396018
Validation loss: 2.435760607348702

Epoch: 6| Step: 10
Training loss: 1.4329263656449174
Validation loss: 2.4247853840330955

Epoch: 6| Step: 11
Training loss: 1.859741046681411
Validation loss: 2.453847417303012

Epoch: 6| Step: 12
Training loss: 2.3159014455747537
Validation loss: 2.4698331986953286

Epoch: 6| Step: 13
Training loss: 1.3697750346790099
Validation loss: 2.4328021552227335

Epoch: 394| Step: 0
Training loss: 1.4260908234926608
Validation loss: 2.4709051239397537

Epoch: 6| Step: 1
Training loss: 1.8693664478143361
Validation loss: 2.420487005142083

Epoch: 6| Step: 2
Training loss: 2.2773040715682002
Validation loss: 2.4341406547323006

Epoch: 6| Step: 3
Training loss: 2.5930151760247147
Validation loss: 2.443446104730942

Epoch: 6| Step: 4
Training loss: 1.7019793655722564
Validation loss: 2.4273872767879823

Epoch: 6| Step: 5
Training loss: 2.3380087151018256
Validation loss: 2.4421802515526947

Epoch: 6| Step: 6
Training loss: 2.0459909641219225
Validation loss: 2.4215799279598604

Epoch: 6| Step: 7
Training loss: 2.396304297113118
Validation loss: 2.4149836074448374

Epoch: 6| Step: 8
Training loss: 2.2208960456892295
Validation loss: 2.448904806678082

Epoch: 6| Step: 9
Training loss: 2.1541069548820664
Validation loss: 2.404108911167712

Epoch: 6| Step: 10
Training loss: 1.6672734904256772
Validation loss: 2.4218856837751175

Epoch: 6| Step: 11
Training loss: 1.3655979616469516
Validation loss: 2.4390436810800566

Epoch: 6| Step: 12
Training loss: 2.056096859131013
Validation loss: 2.3753277347947432

Epoch: 6| Step: 13
Training loss: 2.6036622334529924
Validation loss: 2.4274537667603795

Epoch: 395| Step: 0
Training loss: 2.2984893730736116
Validation loss: 2.447914195446756

Epoch: 6| Step: 1
Training loss: 2.945504341657162
Validation loss: 2.408677015943852

Epoch: 6| Step: 2
Training loss: 2.7178887066262383
Validation loss: 2.4457002665379566

Epoch: 6| Step: 3
Training loss: 1.9365017072619362
Validation loss: 2.4294079256798797

Epoch: 6| Step: 4
Training loss: 1.725455088638628
Validation loss: 2.46029646298875

Epoch: 6| Step: 5
Training loss: 2.408040458092189
Validation loss: 2.4696592341712953

Epoch: 6| Step: 6
Training loss: 2.119747739394528
Validation loss: 2.4261827026209897

Epoch: 6| Step: 7
Training loss: 1.5900561591493105
Validation loss: 2.3945425793075747

Epoch: 6| Step: 8
Training loss: 1.237105909847975
Validation loss: 2.4668744274379537

Epoch: 6| Step: 9
Training loss: 1.613770196080612
Validation loss: 2.3937683737065814

Epoch: 6| Step: 10
Training loss: 1.6860601145479317
Validation loss: 2.4662280365215223

Epoch: 6| Step: 11
Training loss: 1.8691225120759007
Validation loss: 2.428003946625442

Epoch: 6| Step: 12
Training loss: 1.7779903367577001
Validation loss: 2.4590903385932217

Epoch: 6| Step: 13
Training loss: 2.320540189007471
Validation loss: 2.4620431120022515

Epoch: 396| Step: 0
Training loss: 1.7283366482419946
Validation loss: 2.3984118531685574

Epoch: 6| Step: 1
Training loss: 2.0546275082957153
Validation loss: 2.4367938311102777

Epoch: 6| Step: 2
Training loss: 2.7881222804384835
Validation loss: 2.403321781356256

Epoch: 6| Step: 3
Training loss: 1.9262405683421464
Validation loss: 2.3958037821769427

Epoch: 6| Step: 4
Training loss: 2.4594674700132684
Validation loss: 2.4407229785638487

Epoch: 6| Step: 5
Training loss: 2.4138796838961167
Validation loss: 2.4661595378088275

Epoch: 6| Step: 6
Training loss: 2.4461730807710373
Validation loss: 2.450471768737975

Epoch: 6| Step: 7
Training loss: 1.6850623432251461
Validation loss: 2.4641693130162627

Epoch: 6| Step: 8
Training loss: 2.1768597818128
Validation loss: 2.452844798519726

Epoch: 6| Step: 9
Training loss: 1.8487407574219474
Validation loss: 2.421953817269941

Epoch: 6| Step: 10
Training loss: 1.679305348061027
Validation loss: 2.4508135112782017

Epoch: 6| Step: 11
Training loss: 1.7460772281010137
Validation loss: 2.4392409532255868

Epoch: 6| Step: 12
Training loss: 1.9878529984909898
Validation loss: 2.3962076230937464

Epoch: 6| Step: 13
Training loss: 1.672043622506475
Validation loss: 2.4635389062149313

Epoch: 397| Step: 0
Training loss: 2.6301527766538655
Validation loss: 2.4443486658084415

Epoch: 6| Step: 1
Training loss: 2.06793029772465
Validation loss: 2.467671961294624

Epoch: 6| Step: 2
Training loss: 1.7019619951767793
Validation loss: 2.4354598987045804

Epoch: 6| Step: 3
Training loss: 1.8399384103708825
Validation loss: 2.408151268324831

Epoch: 6| Step: 4
Training loss: 1.9717197121293542
Validation loss: 2.4642289523778387

Epoch: 6| Step: 5
Training loss: 2.1812672786520153
Validation loss: 2.4485507410061094

Epoch: 6| Step: 6
Training loss: 1.5831256613144546
Validation loss: 2.468872497186198

Epoch: 6| Step: 7
Training loss: 1.9982449460413714
Validation loss: 2.4637796595350494

Epoch: 6| Step: 8
Training loss: 1.5676657162911576
Validation loss: 2.432343467509848

Epoch: 6| Step: 9
Training loss: 2.1572197101945267
Validation loss: 2.4121932540364592

Epoch: 6| Step: 10
Training loss: 2.371120798374604
Validation loss: 2.448738685538261

Epoch: 6| Step: 11
Training loss: 2.2342221934746
Validation loss: 2.4319653503064496

Epoch: 6| Step: 12
Training loss: 2.08006116116909
Validation loss: 2.414165572812622

Epoch: 6| Step: 13
Training loss: 1.6570601731023844
Validation loss: 2.3996016547799925

Epoch: 398| Step: 0
Training loss: 2.1932439323610082
Validation loss: 2.4127456509368694

Epoch: 6| Step: 1
Training loss: 1.661952727452298
Validation loss: 2.408990447699387

Epoch: 6| Step: 2
Training loss: 1.530506810040731
Validation loss: 2.4388697572074336

Epoch: 6| Step: 3
Training loss: 2.3001847068592003
Validation loss: 2.437901954123674

Epoch: 6| Step: 4
Training loss: 1.7860021277454512
Validation loss: 2.4417354175778

Epoch: 6| Step: 5
Training loss: 1.7356887515554167
Validation loss: 2.4400183544531036

Epoch: 6| Step: 6
Training loss: 1.6895507784277282
Validation loss: 2.4157463753548236

Epoch: 6| Step: 7
Training loss: 2.033904234155537
Validation loss: 2.452277953345597

Epoch: 6| Step: 8
Training loss: 2.933808787422873
Validation loss: 2.4055068646820525

Epoch: 6| Step: 9
Training loss: 2.2370943181187464
Validation loss: 2.406521300720439

Epoch: 6| Step: 10
Training loss: 1.92113313079966
Validation loss: 2.4511184182568524

Epoch: 6| Step: 11
Training loss: 1.7670234610787043
Validation loss: 2.416059803075292

Epoch: 6| Step: 12
Training loss: 2.51195955679464
Validation loss: 2.422838321818958

Epoch: 6| Step: 13
Training loss: 2.397660020692905
Validation loss: 2.4088917190476002

Epoch: 399| Step: 0
Training loss: 1.7354047313095051
Validation loss: 2.437076365613457

Epoch: 6| Step: 1
Training loss: 1.6222863647693049
Validation loss: 2.4426958434628734

Epoch: 6| Step: 2
Training loss: 1.732977226552335
Validation loss: 2.410032540569161

Epoch: 6| Step: 3
Training loss: 2.5145610194149848
Validation loss: 2.448025841897662

Epoch: 6| Step: 4
Training loss: 1.9790928743224991
Validation loss: 2.4763447464045587

Epoch: 6| Step: 5
Training loss: 2.8617340529040747
Validation loss: 2.4532915838272973

Epoch: 6| Step: 6
Training loss: 2.6758303449818586
Validation loss: 2.4500156069340706

Epoch: 6| Step: 7
Training loss: 1.8135806841070274
Validation loss: 2.4712494995341423

Epoch: 6| Step: 8
Training loss: 2.2218737037536873
Validation loss: 2.4163368148150313

Epoch: 6| Step: 9
Training loss: 1.808385651647579
Validation loss: 2.3753800457781598

Epoch: 6| Step: 10
Training loss: 1.3642021500981434
Validation loss: 2.444564015468021

Epoch: 6| Step: 11
Training loss: 1.7960466548790082
Validation loss: 2.432386238683957

Epoch: 6| Step: 12
Training loss: 1.844656252795898
Validation loss: 2.4657756582477264

Epoch: 6| Step: 13
Training loss: 2.1920878664351853
Validation loss: 2.433367940838103

Epoch: 400| Step: 0
Training loss: 2.548222097792925
Validation loss: 2.394764755981277

Epoch: 6| Step: 1
Training loss: 2.317474273407162
Validation loss: 2.4461286442791548

Epoch: 6| Step: 2
Training loss: 1.7352695392035624
Validation loss: 2.4344031321016506

Epoch: 6| Step: 3
Training loss: 2.0922819086358984
Validation loss: 2.4294180983000166

Epoch: 6| Step: 4
Training loss: 1.6286656776083777
Validation loss: 2.4305333653817525

Epoch: 6| Step: 5
Training loss: 1.5411526192424063
Validation loss: 2.4268096508274057

Epoch: 6| Step: 6
Training loss: 1.9587722313549865
Validation loss: 2.4528830995330235

Epoch: 6| Step: 7
Training loss: 2.5697692482512533
Validation loss: 2.421652267540056

Epoch: 6| Step: 8
Training loss: 2.045732135432248
Validation loss: 2.454448872827434

Epoch: 6| Step: 9
Training loss: 1.520764945944306
Validation loss: 2.4201360826190665

Epoch: 6| Step: 10
Training loss: 2.6925097059608003
Validation loss: 2.4277628398487736

Epoch: 6| Step: 11
Training loss: 2.0197413794513803
Validation loss: 2.4651311142600365

Epoch: 6| Step: 12
Training loss: 2.1325848915581647
Validation loss: 2.406032275932065

Epoch: 6| Step: 13
Training loss: 2.181997408332999
Validation loss: 2.4355602081644636

Epoch: 401| Step: 0
Training loss: 1.7508928882117833
Validation loss: 2.408518443881604

Epoch: 6| Step: 1
Training loss: 2.3234583019359225
Validation loss: 2.4260252599874215

Epoch: 6| Step: 2
Training loss: 2.266652367584155
Validation loss: 2.417929552403869

Epoch: 6| Step: 3
Training loss: 2.2329655183076444
Validation loss: 2.416386046646295

Epoch: 6| Step: 4
Training loss: 1.773603658412383
Validation loss: 2.430490303706727

Epoch: 6| Step: 5
Training loss: 2.9094489755045463
Validation loss: 2.4275881162119175

Epoch: 6| Step: 6
Training loss: 1.6247672134335154
Validation loss: 2.4247309987706323

Epoch: 6| Step: 7
Training loss: 2.1389095365950626
Validation loss: 2.4491859048248177

Epoch: 6| Step: 8
Training loss: 2.0521470526340857
Validation loss: 2.39482623883215

Epoch: 6| Step: 9
Training loss: 1.902400773777977
Validation loss: 2.446450738687632

Epoch: 6| Step: 10
Training loss: 1.919556871180314
Validation loss: 2.4207103351570223

Epoch: 6| Step: 11
Training loss: 2.273303575274368
Validation loss: 2.4323249300442646

Epoch: 6| Step: 12
Training loss: 1.7450017394573647
Validation loss: 2.442708485861747

Epoch: 6| Step: 13
Training loss: 1.0781678453860521
Validation loss: 2.4356005998286374

Epoch: 402| Step: 0
Training loss: 1.8184749513274432
Validation loss: 2.4078786436577366

Epoch: 6| Step: 1
Training loss: 1.7507923239919885
Validation loss: 2.403202615474472

Epoch: 6| Step: 2
Training loss: 2.249384795960138
Validation loss: 2.414199781126773

Epoch: 6| Step: 3
Training loss: 3.1312685846017065
Validation loss: 2.406924319061585

Epoch: 6| Step: 4
Training loss: 1.8156979728386977
Validation loss: 2.419728163112443

Epoch: 6| Step: 5
Training loss: 2.2386154804039045
Validation loss: 2.4484023311237824

Epoch: 6| Step: 6
Training loss: 2.179137239081212
Validation loss: 2.427533793740476

Epoch: 6| Step: 7
Training loss: 2.278605038232288
Validation loss: 2.4253985011677246

Epoch: 6| Step: 8
Training loss: 1.9064718648903929
Validation loss: 2.432682262552776

Epoch: 6| Step: 9
Training loss: 1.753052229569441
Validation loss: 2.4280754644832627

Epoch: 6| Step: 10
Training loss: 1.7541324325205074
Validation loss: 2.417222888982664

Epoch: 6| Step: 11
Training loss: 1.9288432633601895
Validation loss: 2.445081588587031

Epoch: 6| Step: 12
Training loss: 1.5300565467308218
Validation loss: 2.4184470494427774

Epoch: 6| Step: 13
Training loss: 1.7834150307501386
Validation loss: 2.4235806781208002

Epoch: 403| Step: 0
Training loss: 0.8867771280708233
Validation loss: 2.432088578676014

Epoch: 6| Step: 1
Training loss: 2.5792953146884003
Validation loss: 2.406753834614517

Epoch: 6| Step: 2
Training loss: 2.0551570457353128
Validation loss: 2.423936784635621

Epoch: 6| Step: 3
Training loss: 2.3684790584644233
Validation loss: 2.3922421993840404

Epoch: 6| Step: 4
Training loss: 1.9775950633467319
Validation loss: 2.367850137634059

Epoch: 6| Step: 5
Training loss: 2.2759170905500623
Validation loss: 2.4194374268631207

Epoch: 6| Step: 6
Training loss: 1.930826877796685
Validation loss: 2.4231229807814745

Epoch: 6| Step: 7
Training loss: 2.0823826591707606
Validation loss: 2.4259472777403146

Epoch: 6| Step: 8
Training loss: 2.1190374533856917
Validation loss: 2.4275935062561302

Epoch: 6| Step: 9
Training loss: 1.9735538064808862
Validation loss: 2.4209923042331973

Epoch: 6| Step: 10
Training loss: 2.4070303506177826
Validation loss: 2.422419506605739

Epoch: 6| Step: 11
Training loss: 1.1561527726818404
Validation loss: 2.3799548069399674

Epoch: 6| Step: 12
Training loss: 1.9448257511409668
Validation loss: 2.423454567170986

Epoch: 6| Step: 13
Training loss: 2.4441536299310895
Validation loss: 2.4138891339237527

Epoch: 404| Step: 0
Training loss: 2.136338669134817
Validation loss: 2.4076119521081356

Epoch: 6| Step: 1
Training loss: 2.293110987656067
Validation loss: 2.4134002083963986

Epoch: 6| Step: 2
Training loss: 1.8878877860359111
Validation loss: 2.442822344266173

Epoch: 6| Step: 3
Training loss: 2.2626991057909507
Validation loss: 2.404221698268135

Epoch: 6| Step: 4
Training loss: 2.2821697314543683
Validation loss: 2.4439676641309855

Epoch: 6| Step: 5
Training loss: 1.7403097254134543
Validation loss: 2.4145205398683576

Epoch: 6| Step: 6
Training loss: 1.7486928417580012
Validation loss: 2.4460858335670927

Epoch: 6| Step: 7
Training loss: 2.506758709124004
Validation loss: 2.4383058838095524

Epoch: 6| Step: 8
Training loss: 1.7511731030546873
Validation loss: 2.423767231337135

Epoch: 6| Step: 9
Training loss: 2.581893293934164
Validation loss: 2.435730184615402

Epoch: 6| Step: 10
Training loss: 1.954223201993997
Validation loss: 2.4369346419461118

Epoch: 6| Step: 11
Training loss: 1.7017809262649366
Validation loss: 2.431182043978146

Epoch: 6| Step: 12
Training loss: 1.4731082779036797
Validation loss: 2.391347310199585

Epoch: 6| Step: 13
Training loss: 2.3503927065038255
Validation loss: 2.4879474634630006

Epoch: 405| Step: 0
Training loss: 2.2363769525919537
Validation loss: 2.412890401837334

Epoch: 6| Step: 1
Training loss: 1.4894243791328903
Validation loss: 2.4705368456208485

Epoch: 6| Step: 2
Training loss: 2.9393658495141497
Validation loss: 2.402523703862886

Epoch: 6| Step: 3
Training loss: 2.20289751325804
Validation loss: 2.4088457348960612

Epoch: 6| Step: 4
Training loss: 1.4492820869856464
Validation loss: 2.4427354328651525

Epoch: 6| Step: 5
Training loss: 1.628008624876453
Validation loss: 2.454445633870231

Epoch: 6| Step: 6
Training loss: 1.7136706117234488
Validation loss: 2.4224814363286025

Epoch: 6| Step: 7
Training loss: 2.1924042358711078
Validation loss: 2.4409593288432148

Epoch: 6| Step: 8
Training loss: 2.2802587994712176
Validation loss: 2.433294314943831

Epoch: 6| Step: 9
Training loss: 1.9300819642446256
Validation loss: 2.4319623228042335

Epoch: 6| Step: 10
Training loss: 1.38183145151657
Validation loss: 2.4296108149733193

Epoch: 6| Step: 11
Training loss: 1.972238870410171
Validation loss: 2.400461324069494

Epoch: 6| Step: 12
Training loss: 2.106866093302425
Validation loss: 2.4418429023999955

Epoch: 6| Step: 13
Training loss: 3.1656975183342912
Validation loss: 2.371130247987851

Epoch: 406| Step: 0
Training loss: 2.260236448730243
Validation loss: 2.4487505010817405

Epoch: 6| Step: 1
Training loss: 1.377082504795458
Validation loss: 2.3978122073654253

Epoch: 6| Step: 2
Training loss: 2.0109583334151133
Validation loss: 2.444265039105753

Epoch: 6| Step: 3
Training loss: 2.4504056789301254
Validation loss: 2.378080853561053

Epoch: 6| Step: 4
Training loss: 2.093841550732814
Validation loss: 2.405476446189079

Epoch: 6| Step: 5
Training loss: 1.9734164444501618
Validation loss: 2.4445247052770753

Epoch: 6| Step: 6
Training loss: 2.61595247650143
Validation loss: 2.4288789445528227

Epoch: 6| Step: 7
Training loss: 1.5829507298564527
Validation loss: 2.4286318222820165

Epoch: 6| Step: 8
Training loss: 2.0546603472986065
Validation loss: 2.4068844846601634

Epoch: 6| Step: 9
Training loss: 2.4325589694082317
Validation loss: 2.3975112546525965

Epoch: 6| Step: 10
Training loss: 1.7880462025384325
Validation loss: 2.4569220631219135

Epoch: 6| Step: 11
Training loss: 2.34603526283553
Validation loss: 2.3884490805744765

Epoch: 6| Step: 12
Training loss: 1.6268143428672024
Validation loss: 2.4076367656964055

Epoch: 6| Step: 13
Training loss: 1.2742841281642732
Validation loss: 2.4103834088683547

Epoch: 407| Step: 0
Training loss: 1.9998818601047965
Validation loss: 2.4044829902891274

Epoch: 6| Step: 1
Training loss: 1.8512079728409006
Validation loss: 2.432492554693087

Epoch: 6| Step: 2
Training loss: 1.66886959718903
Validation loss: 2.420647650544142

Epoch: 6| Step: 3
Training loss: 1.8827469050587498
Validation loss: 2.416650643329166

Epoch: 6| Step: 4
Training loss: 1.4210705839662778
Validation loss: 2.3999579833140134

Epoch: 6| Step: 5
Training loss: 2.7535836538114467
Validation loss: 2.4481611242787418

Epoch: 6| Step: 6
Training loss: 2.258380541243522
Validation loss: 2.4254884436622492

Epoch: 6| Step: 7
Training loss: 1.8230932386349832
Validation loss: 2.39604130217264

Epoch: 6| Step: 8
Training loss: 1.4199594862625318
Validation loss: 2.4221705885822202

Epoch: 6| Step: 9
Training loss: 1.4800277496004601
Validation loss: 2.4055251505491535

Epoch: 6| Step: 10
Training loss: 2.4781807507164273
Validation loss: 2.4386221240896093

Epoch: 6| Step: 11
Training loss: 2.7038788378278564
Validation loss: 2.4381379028230916

Epoch: 6| Step: 12
Training loss: 2.6633274708835724
Validation loss: 2.4045016267207475

Epoch: 6| Step: 13
Training loss: 1.3320954606585325
Validation loss: 2.428253292870694

Epoch: 408| Step: 0
Training loss: 1.8260307379869043
Validation loss: 2.434094471407562

Epoch: 6| Step: 1
Training loss: 1.9653835882212631
Validation loss: 2.4248267491720426

Epoch: 6| Step: 2
Training loss: 1.5982397827891142
Validation loss: 2.4177814885390627

Epoch: 6| Step: 3
Training loss: 2.355190178386278
Validation loss: 2.435834824383177

Epoch: 6| Step: 4
Training loss: 1.8693719957863848
Validation loss: 2.399952160536217

Epoch: 6| Step: 5
Training loss: 1.9094760050178723
Validation loss: 2.4423309446753287

Epoch: 6| Step: 6
Training loss: 1.9871266428229226
Validation loss: 2.4406858774247318

Epoch: 6| Step: 7
Training loss: 2.430447573003962
Validation loss: 2.491896849590069

Epoch: 6| Step: 8
Training loss: 2.616569787760998
Validation loss: 2.456710892884457

Epoch: 6| Step: 9
Training loss: 2.1218603164546828
Validation loss: 2.445305962232588

Epoch: 6| Step: 10
Training loss: 2.1656363923184636
Validation loss: 2.417901870905548

Epoch: 6| Step: 11
Training loss: 1.6247109376127002
Validation loss: 2.400223744808775

Epoch: 6| Step: 12
Training loss: 1.7464029264559233
Validation loss: 2.419870890267716

Epoch: 6| Step: 13
Training loss: 2.3311177929573472
Validation loss: 2.4573315864441247

Epoch: 409| Step: 0
Training loss: 1.973602913805106
Validation loss: 2.474821675061144

Epoch: 6| Step: 1
Training loss: 1.8836770506404805
Validation loss: 2.4220687042480016

Epoch: 6| Step: 2
Training loss: 1.7696878056607597
Validation loss: 2.419755562031105

Epoch: 6| Step: 3
Training loss: 2.641369415631131
Validation loss: 2.402070281034527

Epoch: 6| Step: 4
Training loss: 1.3670008940732163
Validation loss: 2.410879964409594

Epoch: 6| Step: 5
Training loss: 1.854029561092088
Validation loss: 2.4049707972351007

Epoch: 6| Step: 6
Training loss: 2.06902252891521
Validation loss: 2.432344066170243

Epoch: 6| Step: 7
Training loss: 1.816044334534236
Validation loss: 2.439471034507212

Epoch: 6| Step: 8
Training loss: 2.552576528629314
Validation loss: 2.389578568602869

Epoch: 6| Step: 9
Training loss: 1.6022861241580524
Validation loss: 2.408499170611418

Epoch: 6| Step: 10
Training loss: 2.3295282832694886
Validation loss: 2.4710844204274243

Epoch: 6| Step: 11
Training loss: 2.149100572393873
Validation loss: 2.4057291663398708

Epoch: 6| Step: 12
Training loss: 1.9175095639742554
Validation loss: 2.4083415358268487

Epoch: 6| Step: 13
Training loss: 2.2593183412742035
Validation loss: 2.411488465169372

Epoch: 410| Step: 0
Training loss: 1.8975390282237155
Validation loss: 2.4338283235817797

Epoch: 6| Step: 1
Training loss: 1.4491338576466737
Validation loss: 2.4321938947598785

Epoch: 6| Step: 2
Training loss: 1.8512815109342637
Validation loss: 2.38809506045133

Epoch: 6| Step: 3
Training loss: 1.9683014494951212
Validation loss: 2.383186064401887

Epoch: 6| Step: 4
Training loss: 2.3206931678546807
Validation loss: 2.4119557648327463

Epoch: 6| Step: 5
Training loss: 1.8232358453249027
Validation loss: 2.4190061102879414

Epoch: 6| Step: 6
Training loss: 2.657287753969724
Validation loss: 2.449827907914574

Epoch: 6| Step: 7
Training loss: 2.091273537074109
Validation loss: 2.4617852113836385

Epoch: 6| Step: 8
Training loss: 1.9663153838425722
Validation loss: 2.434188122061949

Epoch: 6| Step: 9
Training loss: 1.7865192043362306
Validation loss: 2.4342346574719778

Epoch: 6| Step: 10
Training loss: 2.6121949816333223
Validation loss: 2.4438616558821042

Epoch: 6| Step: 11
Training loss: 1.924479324967133
Validation loss: 2.407028191732708

Epoch: 6| Step: 12
Training loss: 2.050930867868093
Validation loss: 2.412511456115036

Epoch: 6| Step: 13
Training loss: 1.8846528488968737
Validation loss: 2.43070313173146

Epoch: 411| Step: 0
Training loss: 1.3792603121923948
Validation loss: 2.4380311505554695

Epoch: 6| Step: 1
Training loss: 2.4005469573151244
Validation loss: 2.442890602191287

Epoch: 6| Step: 2
Training loss: 2.4286280833776517
Validation loss: 2.4476949191189963

Epoch: 6| Step: 3
Training loss: 1.9293505416916414
Validation loss: 2.4491789053196378

Epoch: 6| Step: 4
Training loss: 1.798613395673102
Validation loss: 2.441392202160525

Epoch: 6| Step: 5
Training loss: 1.800326010532998
Validation loss: 2.458718030087064

Epoch: 6| Step: 6
Training loss: 2.7260392788235315
Validation loss: 2.415955042705583

Epoch: 6| Step: 7
Training loss: 1.9054317281519675
Validation loss: 2.412459336586926

Epoch: 6| Step: 8
Training loss: 2.168290727779783
Validation loss: 2.444122652959042

Epoch: 6| Step: 9
Training loss: 1.5513419955975818
Validation loss: 2.429180895272014

Epoch: 6| Step: 10
Training loss: 2.177872206085292
Validation loss: 2.361454213295297

Epoch: 6| Step: 11
Training loss: 2.1746463795099027
Validation loss: 2.3935988126223293

Epoch: 6| Step: 12
Training loss: 1.8389575549107782
Validation loss: 2.4153635212368236

Epoch: 6| Step: 13
Training loss: 2.433233096614403
Validation loss: 2.424374416746003

Epoch: 412| Step: 0
Training loss: 1.6620961781570691
Validation loss: 2.4051598848453337

Epoch: 6| Step: 1
Training loss: 1.881754154314767
Validation loss: 2.436426342227158

Epoch: 6| Step: 2
Training loss: 2.051617667973736
Validation loss: 2.4604031682146714

Epoch: 6| Step: 3
Training loss: 1.9872772139916073
Validation loss: 2.3870446127173195

Epoch: 6| Step: 4
Training loss: 1.984820338461509
Validation loss: 2.4539562964665453

Epoch: 6| Step: 5
Training loss: 1.9287707046712732
Validation loss: 2.442434985713697

Epoch: 6| Step: 6
Training loss: 2.2275012797856104
Validation loss: 2.444030658488341

Epoch: 6| Step: 7
Training loss: 2.8277211612245656
Validation loss: 2.4680406426981834

Epoch: 6| Step: 8
Training loss: 1.8283648211336094
Validation loss: 2.4297916603822896

Epoch: 6| Step: 9
Training loss: 2.0675464505901435
Validation loss: 2.427538650592116

Epoch: 6| Step: 10
Training loss: 1.7286491385582794
Validation loss: 2.4167178243696896

Epoch: 6| Step: 11
Training loss: 1.8321907933762027
Validation loss: 2.407141867658657

Epoch: 6| Step: 12
Training loss: 2.2401570021580244
Validation loss: 2.3998715748745085

Epoch: 6| Step: 13
Training loss: 2.0067012101217516
Validation loss: 2.3566229360093787

Epoch: 413| Step: 0
Training loss: 1.9217480873444777
Validation loss: 2.42639405843826

Epoch: 6| Step: 1
Training loss: 2.002253216837455
Validation loss: 2.3876370523857737

Epoch: 6| Step: 2
Training loss: 1.2063607634452473
Validation loss: 2.420634255361879

Epoch: 6| Step: 3
Training loss: 2.0696794801695177
Validation loss: 2.382179632117761

Epoch: 6| Step: 4
Training loss: 1.885598997569637
Validation loss: 2.4065914969143694

Epoch: 6| Step: 5
Training loss: 1.6156164822086423
Validation loss: 2.4029757593010266

Epoch: 6| Step: 6
Training loss: 2.4297546181193814
Validation loss: 2.4053702033179136

Epoch: 6| Step: 7
Training loss: 1.8433622178728541
Validation loss: 2.388032401078096

Epoch: 6| Step: 8
Training loss: 2.6281472367333643
Validation loss: 2.424886571694374

Epoch: 6| Step: 9
Training loss: 2.22763110835691
Validation loss: 2.4006497080519

Epoch: 6| Step: 10
Training loss: 2.1093867548862284
Validation loss: 2.416970372520552

Epoch: 6| Step: 11
Training loss: 1.7684198725189726
Validation loss: 2.4175870961525168

Epoch: 6| Step: 12
Training loss: 2.1624589067204014
Validation loss: 2.4672297205782963

Epoch: 6| Step: 13
Training loss: 2.2812821895470816
Validation loss: 2.4244097171483188

Epoch: 414| Step: 0
Training loss: 1.7885065672564315
Validation loss: 2.4320161927005737

Epoch: 6| Step: 1
Training loss: 2.3743155647665137
Validation loss: 2.4088582825008884

Epoch: 6| Step: 2
Training loss: 1.4454630180544608
Validation loss: 2.3822129706899013

Epoch: 6| Step: 3
Training loss: 1.8097400040174592
Validation loss: 2.418559781630722

Epoch: 6| Step: 4
Training loss: 1.9142149572573846
Validation loss: 2.398013929791783

Epoch: 6| Step: 5
Training loss: 2.727976172933252
Validation loss: 2.3866852971335915

Epoch: 6| Step: 6
Training loss: 1.9680201070580219
Validation loss: 2.436091243905331

Epoch: 6| Step: 7
Training loss: 2.2879117084487195
Validation loss: 2.4037759263702974

Epoch: 6| Step: 8
Training loss: 1.9959804555016332
Validation loss: 2.4233572741046947

Epoch: 6| Step: 9
Training loss: 2.13171168274083
Validation loss: 2.43016047273259

Epoch: 6| Step: 10
Training loss: 1.9445854574872627
Validation loss: 2.39961087258032

Epoch: 6| Step: 11
Training loss: 1.7144672093363724
Validation loss: 2.4045800309984418

Epoch: 6| Step: 12
Training loss: 1.8946231151213295
Validation loss: 2.419138524356008

Epoch: 6| Step: 13
Training loss: 2.036153420908897
Validation loss: 2.462927429122521

Epoch: 415| Step: 0
Training loss: 2.3028921602271657
Validation loss: 2.42110086242442

Epoch: 6| Step: 1
Training loss: 1.842849511545799
Validation loss: 2.4038048258337494

Epoch: 6| Step: 2
Training loss: 2.6466778786499425
Validation loss: 2.4040228065535847

Epoch: 6| Step: 3
Training loss: 2.5456328376033093
Validation loss: 2.4128969859985254

Epoch: 6| Step: 4
Training loss: 1.9867051028474083
Validation loss: 2.3984745663163003

Epoch: 6| Step: 5
Training loss: 2.840206747454511
Validation loss: 2.447951397532706

Epoch: 6| Step: 6
Training loss: 1.7389708790460425
Validation loss: 2.412657933413689

Epoch: 6| Step: 7
Training loss: 1.2706822269010003
Validation loss: 2.3904529820365195

Epoch: 6| Step: 8
Training loss: 1.63396810860486
Validation loss: 2.4712197507438263

Epoch: 6| Step: 9
Training loss: 1.666423787857673
Validation loss: 2.428092906243204

Epoch: 6| Step: 10
Training loss: 2.0722823074920513
Validation loss: 2.408944857064446

Epoch: 6| Step: 11
Training loss: 1.4336544512544878
Validation loss: 2.419770530073103

Epoch: 6| Step: 12
Training loss: 2.1898354188921862
Validation loss: 2.4440024775135414

Epoch: 6| Step: 13
Training loss: 1.441562468377623
Validation loss: 2.453119656126097

Epoch: 416| Step: 0
Training loss: 1.8408046408069638
Validation loss: 2.3871031590013

Epoch: 6| Step: 1
Training loss: 1.7030392546461166
Validation loss: 2.4427588449057955

Epoch: 6| Step: 2
Training loss: 2.3206090255997074
Validation loss: 2.4193605854280644

Epoch: 6| Step: 3
Training loss: 1.4201889101818947
Validation loss: 2.437012879588393

Epoch: 6| Step: 4
Training loss: 1.7266009572436851
Validation loss: 2.3740016045543397

Epoch: 6| Step: 5
Training loss: 2.29724927694351
Validation loss: 2.3728855880549817

Epoch: 6| Step: 6
Training loss: 1.777562926475619
Validation loss: 2.3976423677052665

Epoch: 6| Step: 7
Training loss: 2.2336042448626516
Validation loss: 2.432097194793708

Epoch: 6| Step: 8
Training loss: 2.2562753269116067
Validation loss: 2.4030959648348533

Epoch: 6| Step: 9
Training loss: 2.7178280023380745
Validation loss: 2.378090538555798

Epoch: 6| Step: 10
Training loss: 1.2290082710925172
Validation loss: 2.4111239162580937

Epoch: 6| Step: 11
Training loss: 2.3547864340063356
Validation loss: 2.4076376563976214

Epoch: 6| Step: 12
Training loss: 1.385413616817626
Validation loss: 2.3978156222543534

Epoch: 6| Step: 13
Training loss: 2.4001216380765946
Validation loss: 2.4084328513737514

Epoch: 417| Step: 0
Training loss: 2.081117468844183
Validation loss: 2.4081603607824436

Epoch: 6| Step: 1
Training loss: 2.2651507703440266
Validation loss: 2.4045584211269198

Epoch: 6| Step: 2
Training loss: 2.2955299643170934
Validation loss: 2.399670971172153

Epoch: 6| Step: 3
Training loss: 1.9364377463075613
Validation loss: 2.4400615101153162

Epoch: 6| Step: 4
Training loss: 2.13659154314558
Validation loss: 2.416009575646093

Epoch: 6| Step: 5
Training loss: 1.602476426782864
Validation loss: 2.4341211893839922

Epoch: 6| Step: 6
Training loss: 1.7692883053166666
Validation loss: 2.4162781339064163

Epoch: 6| Step: 7
Training loss: 1.5464856206778577
Validation loss: 2.3695974381039666

Epoch: 6| Step: 8
Training loss: 2.558805081324849
Validation loss: 2.386265439040648

Epoch: 6| Step: 9
Training loss: 1.5561717247332092
Validation loss: 2.4177045711456904

Epoch: 6| Step: 10
Training loss: 2.0586139019263885
Validation loss: 2.4343400776432667

Epoch: 6| Step: 11
Training loss: 1.728330095754673
Validation loss: 2.4150073554001024

Epoch: 6| Step: 12
Training loss: 2.440712108351928
Validation loss: 2.4294420618277877

Epoch: 6| Step: 13
Training loss: 1.016635802587406
Validation loss: 2.432468846757366

Epoch: 418| Step: 0
Training loss: 2.0144455882033725
Validation loss: 2.424598951449203

Epoch: 6| Step: 1
Training loss: 1.7277303345038104
Validation loss: 2.4117090482966534

Epoch: 6| Step: 2
Training loss: 1.899218614422108
Validation loss: 2.4099666283996823

Epoch: 6| Step: 3
Training loss: 2.0049568976433063
Validation loss: 2.3916099814600926

Epoch: 6| Step: 4
Training loss: 1.9965339667920001
Validation loss: 2.416234996956968

Epoch: 6| Step: 5
Training loss: 1.9734107661305293
Validation loss: 2.4130348572030087

Epoch: 6| Step: 6
Training loss: 1.7923096752344687
Validation loss: 2.4142733092029176

Epoch: 6| Step: 7
Training loss: 1.9859816287440482
Validation loss: 2.4247908585449074

Epoch: 6| Step: 8
Training loss: 2.211610078449436
Validation loss: 2.388966749241547

Epoch: 6| Step: 9
Training loss: 1.598012199016314
Validation loss: 2.3731296797808348

Epoch: 6| Step: 10
Training loss: 2.2062720149079236
Validation loss: 2.4086123529645613

Epoch: 6| Step: 11
Training loss: 1.7934202735181233
Validation loss: 2.4485143280555914

Epoch: 6| Step: 12
Training loss: 2.400014650776968
Validation loss: 2.3943230903956665

Epoch: 6| Step: 13
Training loss: 2.6551794250838165
Validation loss: 2.4194627543961613

Epoch: 419| Step: 0
Training loss: 2.7264108697652167
Validation loss: 2.4124291184022817

Epoch: 6| Step: 1
Training loss: 1.6304642432771552
Validation loss: 2.3867121505505087

Epoch: 6| Step: 2
Training loss: 1.635895077976042
Validation loss: 2.414896611353605

Epoch: 6| Step: 3
Training loss: 1.7079292222574585
Validation loss: 2.378647043643543

Epoch: 6| Step: 4
Training loss: 2.3516284008233703
Validation loss: 2.4328153643314385

Epoch: 6| Step: 5
Training loss: 2.1837672401800168
Validation loss: 2.401144257791844

Epoch: 6| Step: 6
Training loss: 1.6051758733393005
Validation loss: 2.427171291416018

Epoch: 6| Step: 7
Training loss: 1.6389853867536293
Validation loss: 2.4576900131255326

Epoch: 6| Step: 8
Training loss: 2.184014950222505
Validation loss: 2.425049316924733

Epoch: 6| Step: 9
Training loss: 1.300302594987603
Validation loss: 2.4165402663303897

Epoch: 6| Step: 10
Training loss: 1.4913727298444646
Validation loss: 2.4163769257278185

Epoch: 6| Step: 11
Training loss: 2.0129158680253
Validation loss: 2.455095793131629

Epoch: 6| Step: 12
Training loss: 2.482799102190094
Validation loss: 2.4077949885665677

Epoch: 6| Step: 13
Training loss: 2.982388139595139
Validation loss: 2.433428699078831

Epoch: 420| Step: 0
Training loss: 2.405235175611732
Validation loss: 2.4174214720053286

Epoch: 6| Step: 1
Training loss: 2.776682328282669
Validation loss: 2.413043856890378

Epoch: 6| Step: 2
Training loss: 1.5651196454171883
Validation loss: 2.3849372394525252

Epoch: 6| Step: 3
Training loss: 2.239845035846662
Validation loss: 2.3959320269173405

Epoch: 6| Step: 4
Training loss: 1.563748280671392
Validation loss: 2.4257715905461392

Epoch: 6| Step: 5
Training loss: 1.663180336818269
Validation loss: 2.406879858803771

Epoch: 6| Step: 6
Training loss: 2.1211942364405236
Validation loss: 2.444981717990181

Epoch: 6| Step: 7
Training loss: 1.8513175061865452
Validation loss: 2.411432447932184

Epoch: 6| Step: 8
Training loss: 1.8626402066089207
Validation loss: 2.372850498905887

Epoch: 6| Step: 9
Training loss: 1.9254559905739115
Validation loss: 2.4121236252626383

Epoch: 6| Step: 10
Training loss: 1.599664521809628
Validation loss: 2.405353503258809

Epoch: 6| Step: 11
Training loss: 2.3475800817640726
Validation loss: 2.424071011736138

Epoch: 6| Step: 12
Training loss: 2.167067881874234
Validation loss: 2.398448954085192

Epoch: 6| Step: 13
Training loss: 1.3589974240748095
Validation loss: 2.435681748482295

Epoch: 421| Step: 0
Training loss: 1.919497003432228
Validation loss: 2.413376794111107

Epoch: 6| Step: 1
Training loss: 2.395855734900082
Validation loss: 2.4212713774808785

Epoch: 6| Step: 2
Training loss: 1.8423362095985625
Validation loss: 2.414730655096812

Epoch: 6| Step: 3
Training loss: 2.0257199644093316
Validation loss: 2.4001828614084073

Epoch: 6| Step: 4
Training loss: 2.5368567642718105
Validation loss: 2.406778046171888

Epoch: 6| Step: 5
Training loss: 1.6593023280665655
Validation loss: 2.4571421869287464

Epoch: 6| Step: 6
Training loss: 1.6182067902287343
Validation loss: 2.4323340375352025

Epoch: 6| Step: 7
Training loss: 1.849286511448448
Validation loss: 2.401440744456501

Epoch: 6| Step: 8
Training loss: 1.758984120178543
Validation loss: 2.4456050042221626

Epoch: 6| Step: 9
Training loss: 2.369639521036008
Validation loss: 2.444174203760332

Epoch: 6| Step: 10
Training loss: 2.411376446403998
Validation loss: 2.4319512247415944

Epoch: 6| Step: 11
Training loss: 1.8346755865142657
Validation loss: 2.4569150658309367

Epoch: 6| Step: 12
Training loss: 1.9447343572322635
Validation loss: 2.409644219772616

Epoch: 6| Step: 13
Training loss: 1.7432753241584367
Validation loss: 2.4222942644357603

Epoch: 422| Step: 0
Training loss: 1.3201284788201644
Validation loss: 2.409223260425667

Epoch: 6| Step: 1
Training loss: 2.155823817498147
Validation loss: 2.42608375533061

Epoch: 6| Step: 2
Training loss: 1.8800873721902107
Validation loss: 2.3815707818481417

Epoch: 6| Step: 3
Training loss: 2.338826106274129
Validation loss: 2.3719545245260165

Epoch: 6| Step: 4
Training loss: 2.011484076876653
Validation loss: 2.4355176443050808

Epoch: 6| Step: 5
Training loss: 1.717337704338016
Validation loss: 2.4023168909662505

Epoch: 6| Step: 6
Training loss: 1.5653016721625508
Validation loss: 2.4272855079169124

Epoch: 6| Step: 7
Training loss: 1.8046079675893631
Validation loss: 2.435355107032154

Epoch: 6| Step: 8
Training loss: 1.7607555928410243
Validation loss: 2.365059557496109

Epoch: 6| Step: 9
Training loss: 2.1784375616392904
Validation loss: 2.417886101385714

Epoch: 6| Step: 10
Training loss: 2.9484731375881
Validation loss: 2.4167478584537507

Epoch: 6| Step: 11
Training loss: 1.9088861342212744
Validation loss: 2.434909047228063

Epoch: 6| Step: 12
Training loss: 1.7107629556328372
Validation loss: 2.4315837488574528

Epoch: 6| Step: 13
Training loss: 2.196016572066349
Validation loss: 2.3961677164550013

Epoch: 423| Step: 0
Training loss: 2.1925014540211847
Validation loss: 2.396339190467144

Epoch: 6| Step: 1
Training loss: 1.9353478692196886
Validation loss: 2.4405287874186556

Epoch: 6| Step: 2
Training loss: 1.4791342324296217
Validation loss: 2.3910860307035624

Epoch: 6| Step: 3
Training loss: 1.5485629495716378
Validation loss: 2.4262709973073613

Epoch: 6| Step: 4
Training loss: 1.8676463564879813
Validation loss: 2.4496609137773087

Epoch: 6| Step: 5
Training loss: 1.9828481732609649
Validation loss: 2.4072239831246134

Epoch: 6| Step: 6
Training loss: 1.6390545549372872
Validation loss: 2.4298900283357154

Epoch: 6| Step: 7
Training loss: 2.1122671010222147
Validation loss: 2.4375800831367775

Epoch: 6| Step: 8
Training loss: 3.0268979636500193
Validation loss: 2.44337925726172

Epoch: 6| Step: 9
Training loss: 1.7217377097337982
Validation loss: 2.401368486738961

Epoch: 6| Step: 10
Training loss: 2.4959304111390077
Validation loss: 2.4498110054757305

Epoch: 6| Step: 11
Training loss: 1.7187379316426448
Validation loss: 2.4281671575686206

Epoch: 6| Step: 12
Training loss: 1.6784968924858683
Validation loss: 2.4072965368538957

Epoch: 6| Step: 13
Training loss: 2.190907902755041
Validation loss: 2.4036583833741565

Epoch: 424| Step: 0
Training loss: 1.831255067160825
Validation loss: 2.3896437514578612

Epoch: 6| Step: 1
Training loss: 2.4757629451634764
Validation loss: 2.4183979523228034

Epoch: 6| Step: 2
Training loss: 1.7160338701493498
Validation loss: 2.392953943466665

Epoch: 6| Step: 3
Training loss: 1.8790682209333192
Validation loss: 2.391006495050516

Epoch: 6| Step: 4
Training loss: 2.589097319641058
Validation loss: 2.4567897122369646

Epoch: 6| Step: 5
Training loss: 2.2368653830625034
Validation loss: 2.4281362786094896

Epoch: 6| Step: 6
Training loss: 1.5719195441121092
Validation loss: 2.351507743677901

Epoch: 6| Step: 7
Training loss: 2.028959538138591
Validation loss: 2.4160311435767396

Epoch: 6| Step: 8
Training loss: 1.5122656806212293
Validation loss: 2.4378792609951376

Epoch: 6| Step: 9
Training loss: 1.9325245376746447
Validation loss: 2.429440497963926

Epoch: 6| Step: 10
Training loss: 1.504387637292505
Validation loss: 2.4512837129729492

Epoch: 6| Step: 11
Training loss: 2.2363900654972806
Validation loss: 2.3938827617487215

Epoch: 6| Step: 12
Training loss: 2.419033032006079
Validation loss: 2.4529910333495786

Epoch: 6| Step: 13
Training loss: 2.582470831914035
Validation loss: 2.416700136619819

Epoch: 425| Step: 0
Training loss: 1.519298074674444
Validation loss: 2.3961517600328026

Epoch: 6| Step: 1
Training loss: 1.9932901360329485
Validation loss: 2.42839918538752

Epoch: 6| Step: 2
Training loss: 2.583617492142195
Validation loss: 2.448023393477919

Epoch: 6| Step: 3
Training loss: 1.5635354235289596
Validation loss: 2.374401329029793

Epoch: 6| Step: 4
Training loss: 1.737966307494575
Validation loss: 2.4179603374669565

Epoch: 6| Step: 5
Training loss: 2.274238261876589
Validation loss: 2.4380197099815657

Epoch: 6| Step: 6
Training loss: 2.2467386132708684
Validation loss: 2.4306163554832247

Epoch: 6| Step: 7
Training loss: 2.3157577250097607
Validation loss: 2.404304834726548

Epoch: 6| Step: 8
Training loss: 1.8788867719437694
Validation loss: 2.372401375068058

Epoch: 6| Step: 9
Training loss: 1.688180856751592
Validation loss: 2.3862650275715667

Epoch: 6| Step: 10
Training loss: 2.319081811735827
Validation loss: 2.370048136030391

Epoch: 6| Step: 11
Training loss: 1.5035482401592042
Validation loss: 2.411749323871788

Epoch: 6| Step: 12
Training loss: 1.9324059739623987
Validation loss: 2.4728501336584374

Epoch: 6| Step: 13
Training loss: 2.134598539607148
Validation loss: 2.393366866550239

Epoch: 426| Step: 0
Training loss: 2.042459398890995
Validation loss: 2.369204339113431

Epoch: 6| Step: 1
Training loss: 1.6917947582864918
Validation loss: 2.392307792427527

Epoch: 6| Step: 2
Training loss: 1.8400764723103753
Validation loss: 2.4141373755969453

Epoch: 6| Step: 3
Training loss: 2.4246629972383795
Validation loss: 2.463552608195562

Epoch: 6| Step: 4
Training loss: 2.0598897889663874
Validation loss: 2.4299064199698743

Epoch: 6| Step: 5
Training loss: 1.9143443620193479
Validation loss: 2.4607756916167625

Epoch: 6| Step: 6
Training loss: 1.26914178596366
Validation loss: 2.446641665794189

Epoch: 6| Step: 7
Training loss: 1.9854007983165654
Validation loss: 2.4326314151102317

Epoch: 6| Step: 8
Training loss: 2.269241708482936
Validation loss: 2.4138964566607926

Epoch: 6| Step: 9
Training loss: 2.0161520098945798
Validation loss: 2.4080746554743326

Epoch: 6| Step: 10
Training loss: 1.8077196023163424
Validation loss: 2.429932248715434

Epoch: 6| Step: 11
Training loss: 1.510584521558208
Validation loss: 2.391384543767115

Epoch: 6| Step: 12
Training loss: 2.1215066806419207
Validation loss: 2.42609483479587

Epoch: 6| Step: 13
Training loss: 2.38604137341936
Validation loss: 2.4023903324077263

Epoch: 427| Step: 0
Training loss: 2.1572163945550322
Validation loss: 2.4193580836270905

Epoch: 6| Step: 1
Training loss: 1.6501165580039427
Validation loss: 2.436072582365608

Epoch: 6| Step: 2
Training loss: 2.328693090164247
Validation loss: 2.4163103463299045

Epoch: 6| Step: 3
Training loss: 2.421249210355568
Validation loss: 2.399000081491139

Epoch: 6| Step: 4
Training loss: 1.7932761599894
Validation loss: 2.452603650190311

Epoch: 6| Step: 5
Training loss: 1.8828068650030756
Validation loss: 2.4657593678216885

Epoch: 6| Step: 6
Training loss: 2.1449999132134123
Validation loss: 2.4315490808217115

Epoch: 6| Step: 7
Training loss: 2.0765181904838097
Validation loss: 2.432497250934242

Epoch: 6| Step: 8
Training loss: 2.159393010154068
Validation loss: 2.3875449946207037

Epoch: 6| Step: 9
Training loss: 1.9875030493562926
Validation loss: 2.4146263774730783

Epoch: 6| Step: 10
Training loss: 2.059135698646268
Validation loss: 2.403238058317064

Epoch: 6| Step: 11
Training loss: 1.8452009537177327
Validation loss: 2.408102828931809

Epoch: 6| Step: 12
Training loss: 1.4532514947778221
Validation loss: 2.3864812635959414

Epoch: 6| Step: 13
Training loss: 1.815444593281162
Validation loss: 2.3733491929936834

Epoch: 428| Step: 0
Training loss: 2.0493382199853145
Validation loss: 2.4126788735751843

Epoch: 6| Step: 1
Training loss: 2.03328321374294
Validation loss: 2.4187435370837957

Epoch: 6| Step: 2
Training loss: 1.7857539472262631
Validation loss: 2.4301760085852138

Epoch: 6| Step: 3
Training loss: 2.186050261615083
Validation loss: 2.414403044803269

Epoch: 6| Step: 4
Training loss: 1.7282757436390253
Validation loss: 2.393094542679255

Epoch: 6| Step: 5
Training loss: 2.1350604496780172
Validation loss: 2.4026379023427125

Epoch: 6| Step: 6
Training loss: 2.3641720944937177
Validation loss: 2.4437958819334993

Epoch: 6| Step: 7
Training loss: 2.1949002024701967
Validation loss: 2.406905113975513

Epoch: 6| Step: 8
Training loss: 1.8697411858873327
Validation loss: 2.3731153638888447

Epoch: 6| Step: 9
Training loss: 2.210613429174321
Validation loss: 2.3920783458187116

Epoch: 6| Step: 10
Training loss: 1.913983152652205
Validation loss: 2.4054774586529906

Epoch: 6| Step: 11
Training loss: 1.7908172663977802
Validation loss: 2.414117862586819

Epoch: 6| Step: 12
Training loss: 1.8161290111005157
Validation loss: 2.4260204180703537

Epoch: 6| Step: 13
Training loss: 1.7399767889469728
Validation loss: 2.4484321838614784

Epoch: 429| Step: 0
Training loss: 2.1622979306754697
Validation loss: 2.4301031241425597

Epoch: 6| Step: 1
Training loss: 2.1463487493762456
Validation loss: 2.4199729879009557

Epoch: 6| Step: 2
Training loss: 2.2953709459232137
Validation loss: 2.439371808592663

Epoch: 6| Step: 3
Training loss: 2.0923698773140496
Validation loss: 2.4423344495197314

Epoch: 6| Step: 4
Training loss: 1.8181331178255105
Validation loss: 2.4114404702178893

Epoch: 6| Step: 5
Training loss: 1.87929025005409
Validation loss: 2.403756522287966

Epoch: 6| Step: 6
Training loss: 1.9175988363086605
Validation loss: 2.4127290901195035

Epoch: 6| Step: 7
Training loss: 1.4603325718472313
Validation loss: 2.3965798183888434

Epoch: 6| Step: 8
Training loss: 2.586068233631236
Validation loss: 2.4015322631518314

Epoch: 6| Step: 9
Training loss: 1.8043649888958375
Validation loss: 2.4103268447816935

Epoch: 6| Step: 10
Training loss: 1.4592874766209047
Validation loss: 2.4451751308705307

Epoch: 6| Step: 11
Training loss: 1.538996816095203
Validation loss: 2.3958865687237196

Epoch: 6| Step: 12
Training loss: 2.080813167883227
Validation loss: 2.41338913544994

Epoch: 6| Step: 13
Training loss: 2.069308861793431
Validation loss: 2.441657529701352

Epoch: 430| Step: 0
Training loss: 1.5682743947342108
Validation loss: 2.4230116533095996

Epoch: 6| Step: 1
Training loss: 2.4504829320027146
Validation loss: 2.391603230429767

Epoch: 6| Step: 2
Training loss: 1.9554786233808934
Validation loss: 2.3865164958122094

Epoch: 6| Step: 3
Training loss: 1.5638617875525371
Validation loss: 2.3977184435635954

Epoch: 6| Step: 4
Training loss: 1.4551879022138383
Validation loss: 2.4437276492945568

Epoch: 6| Step: 5
Training loss: 2.0181239996961073
Validation loss: 2.4201219531572224

Epoch: 6| Step: 6
Training loss: 2.3951781551860742
Validation loss: 2.4173153702146126

Epoch: 6| Step: 7
Training loss: 1.7080743252174124
Validation loss: 2.464904594070208

Epoch: 6| Step: 8
Training loss: 1.988582026247073
Validation loss: 2.4177134399922826

Epoch: 6| Step: 9
Training loss: 2.4571717529879025
Validation loss: 2.4426994873687127

Epoch: 6| Step: 10
Training loss: 1.927133947859028
Validation loss: 2.3898499908374897

Epoch: 6| Step: 11
Training loss: 2.160901125741743
Validation loss: 2.414408516311125

Epoch: 6| Step: 12
Training loss: 1.785750676193013
Validation loss: 2.4024986747371058

Epoch: 6| Step: 13
Training loss: 2.7281759565385815
Validation loss: 2.4243022503933336

Epoch: 431| Step: 0
Training loss: 2.1331773383009263
Validation loss: 2.411646832377768

Epoch: 6| Step: 1
Training loss: 2.251687159055596
Validation loss: 2.4240037753750836

Epoch: 6| Step: 2
Training loss: 1.7344306730665462
Validation loss: 2.423186117646704

Epoch: 6| Step: 3
Training loss: 2.1947014117652084
Validation loss: 2.4075721056577946

Epoch: 6| Step: 4
Training loss: 1.9524884216512346
Validation loss: 2.4056995168623043

Epoch: 6| Step: 5
Training loss: 1.5947201337994275
Validation loss: 2.391278229067435

Epoch: 6| Step: 6
Training loss: 2.0758359535024127
Validation loss: 2.402458772290942

Epoch: 6| Step: 7
Training loss: 2.0178285131340443
Validation loss: 2.422893775384096

Epoch: 6| Step: 8
Training loss: 2.7041571085505756
Validation loss: 2.382084737477523

Epoch: 6| Step: 9
Training loss: 2.1563144618916863
Validation loss: 2.4080868046795345

Epoch: 6| Step: 10
Training loss: 1.8209785912693894
Validation loss: 2.4398669563580406

Epoch: 6| Step: 11
Training loss: 1.5152873813516352
Validation loss: 2.407364699882648

Epoch: 6| Step: 12
Training loss: 1.6940337249614492
Validation loss: 2.3995130689306556

Epoch: 6| Step: 13
Training loss: 1.7884752400822348
Validation loss: 2.4339058310735733

Epoch: 432| Step: 0
Training loss: 1.798665887431397
Validation loss: 2.3971554308155474

Epoch: 6| Step: 1
Training loss: 1.9798023073165432
Validation loss: 2.4135315173033596

Epoch: 6| Step: 2
Training loss: 2.20504060617024
Validation loss: 2.437087943158672

Epoch: 6| Step: 3
Training loss: 2.4656113579472985
Validation loss: 2.4046623885334446

Epoch: 6| Step: 4
Training loss: 1.7808777269546152
Validation loss: 2.408254328006413

Epoch: 6| Step: 5
Training loss: 1.8696336245533307
Validation loss: 2.4301171233070016

Epoch: 6| Step: 6
Training loss: 1.9013636764862294
Validation loss: 2.395828129003436

Epoch: 6| Step: 7
Training loss: 1.4563734599812455
Validation loss: 2.420217953168044

Epoch: 6| Step: 8
Training loss: 1.9743422149225718
Validation loss: 2.417663777107427

Epoch: 6| Step: 9
Training loss: 2.0465143482964403
Validation loss: 2.3864317430176905

Epoch: 6| Step: 10
Training loss: 2.3338584195550673
Validation loss: 2.3617495875335357

Epoch: 6| Step: 11
Training loss: 2.489371116457014
Validation loss: 2.401136485108477

Epoch: 6| Step: 12
Training loss: 1.930180042743683
Validation loss: 2.378337709256841

Epoch: 6| Step: 13
Training loss: 1.7243058314455286
Validation loss: 2.381209444167849

Epoch: 433| Step: 0
Training loss: 2.361761439900106
Validation loss: 2.386868952360347

Epoch: 6| Step: 1
Training loss: 1.8290022351067237
Validation loss: 2.414158539733842

Epoch: 6| Step: 2
Training loss: 1.8489200713447722
Validation loss: 2.4139826954849073

Epoch: 6| Step: 3
Training loss: 2.0446793522614866
Validation loss: 2.4127284664037068

Epoch: 6| Step: 4
Training loss: 1.5774485583011268
Validation loss: 2.4538940975565287

Epoch: 6| Step: 5
Training loss: 1.8548786068085679
Validation loss: 2.3797493334519886

Epoch: 6| Step: 6
Training loss: 2.499087262428656
Validation loss: 2.418636212337154

Epoch: 6| Step: 7
Training loss: 1.8321036058139626
Validation loss: 2.3624707910924396

Epoch: 6| Step: 8
Training loss: 1.9876440559818624
Validation loss: 2.3963214068593053

Epoch: 6| Step: 9
Training loss: 1.942278291969305
Validation loss: 2.3741038531008467

Epoch: 6| Step: 10
Training loss: 2.279002297266781
Validation loss: 2.3908904296429

Epoch: 6| Step: 11
Training loss: 2.005232641559912
Validation loss: 2.398602251425059

Epoch: 6| Step: 12
Training loss: 1.8604569052359785
Validation loss: 2.4205322332813095

Epoch: 6| Step: 13
Training loss: 1.2122809064673512
Validation loss: 2.4383897763916043

Epoch: 434| Step: 0
Training loss: 1.9064203405097924
Validation loss: 2.4431494658590913

Epoch: 6| Step: 1
Training loss: 2.30410335055983
Validation loss: 2.390739056968691

Epoch: 6| Step: 2
Training loss: 1.987532319100035
Validation loss: 2.3897414564314268

Epoch: 6| Step: 3
Training loss: 2.4156845223618024
Validation loss: 2.399399248471986

Epoch: 6| Step: 4
Training loss: 1.9762909593385116
Validation loss: 2.4327480898619833

Epoch: 6| Step: 5
Training loss: 1.4652640998447009
Validation loss: 2.451647265653015

Epoch: 6| Step: 6
Training loss: 1.5444579072787827
Validation loss: 2.389199217980006

Epoch: 6| Step: 7
Training loss: 1.568857686271626
Validation loss: 2.4039691960891925

Epoch: 6| Step: 8
Training loss: 2.1497260651066172
Validation loss: 2.4161331859492514

Epoch: 6| Step: 9
Training loss: 1.8044027789216914
Validation loss: 2.436785557211292

Epoch: 6| Step: 10
Training loss: 2.473334004109884
Validation loss: 2.4588084240648524

Epoch: 6| Step: 11
Training loss: 1.9402221507268549
Validation loss: 2.4232017500537935

Epoch: 6| Step: 12
Training loss: 1.9093244180675413
Validation loss: 2.4010006373887403

Epoch: 6| Step: 13
Training loss: 1.8480936383555815
Validation loss: 2.402932099759977

Epoch: 435| Step: 0
Training loss: 1.7493059962034292
Validation loss: 2.422626856320863

Epoch: 6| Step: 1
Training loss: 1.8849012889363235
Validation loss: 2.4069739228818885

Epoch: 6| Step: 2
Training loss: 2.2724749962634525
Validation loss: 2.405793728323651

Epoch: 6| Step: 3
Training loss: 2.0865262804348554
Validation loss: 2.415610448230471

Epoch: 6| Step: 4
Training loss: 2.1096437636215284
Validation loss: 2.4178052397624246

Epoch: 6| Step: 5
Training loss: 1.578625590178775
Validation loss: 2.443315556230163

Epoch: 6| Step: 6
Training loss: 1.0771488801846325
Validation loss: 2.4290635193657297

Epoch: 6| Step: 7
Training loss: 1.9310620929448312
Validation loss: 2.3880967480062862

Epoch: 6| Step: 8
Training loss: 2.610197748461173
Validation loss: 2.4508713993060933

Epoch: 6| Step: 9
Training loss: 2.1693928757889673
Validation loss: 2.4171188328935997

Epoch: 6| Step: 10
Training loss: 1.8007815147945847
Validation loss: 2.3811140392874104

Epoch: 6| Step: 11
Training loss: 1.768105444046562
Validation loss: 2.3919190763431413

Epoch: 6| Step: 12
Training loss: 2.364088390382539
Validation loss: 2.416111726096617

Epoch: 6| Step: 13
Training loss: 1.4492678569689201
Validation loss: 2.4190125331420957

Epoch: 436| Step: 0
Training loss: 1.2363343924172203
Validation loss: 2.4070265941352047

Epoch: 6| Step: 1
Training loss: 1.9512836779389027
Validation loss: 2.4090236983081357

Epoch: 6| Step: 2
Training loss: 2.2173670367403226
Validation loss: 2.4017351429560763

Epoch: 6| Step: 3
Training loss: 1.7543339876790645
Validation loss: 2.4157347995290923

Epoch: 6| Step: 4
Training loss: 2.079607900562163
Validation loss: 2.412324228524532

Epoch: 6| Step: 5
Training loss: 2.069549074308623
Validation loss: 2.428458143992289

Epoch: 6| Step: 6
Training loss: 2.2379939509046687
Validation loss: 2.4297937346816707

Epoch: 6| Step: 7
Training loss: 2.453859935907608
Validation loss: 2.4291169327182565

Epoch: 6| Step: 8
Training loss: 1.6729580944944342
Validation loss: 2.396664585901211

Epoch: 6| Step: 9
Training loss: 2.594114714569067
Validation loss: 2.3999395065477214

Epoch: 6| Step: 10
Training loss: 1.7808579130474231
Validation loss: 2.429903303916758

Epoch: 6| Step: 11
Training loss: 1.8236095383266004
Validation loss: 2.401638083367024

Epoch: 6| Step: 12
Training loss: 1.4225551948498902
Validation loss: 2.439456213616453

Epoch: 6| Step: 13
Training loss: 2.450490229081415
Validation loss: 2.413743297971431

Epoch: 437| Step: 0
Training loss: 1.7361430186412516
Validation loss: 2.4146530088086204

Epoch: 6| Step: 1
Training loss: 1.9799341687905032
Validation loss: 2.4418611912311836

Epoch: 6| Step: 2
Training loss: 2.693608992353293
Validation loss: 2.3810202703963768

Epoch: 6| Step: 3
Training loss: 2.156996887883898
Validation loss: 2.4272638118530905

Epoch: 6| Step: 4
Training loss: 1.6540646080351038
Validation loss: 2.4081044407195518

Epoch: 6| Step: 5
Training loss: 2.257260898673203
Validation loss: 2.4130633594621345

Epoch: 6| Step: 6
Training loss: 1.82589859983212
Validation loss: 2.372621211743997

Epoch: 6| Step: 7
Training loss: 1.553365634260386
Validation loss: 2.4004877585231483

Epoch: 6| Step: 8
Training loss: 1.9585598821340406
Validation loss: 2.4386625407290494

Epoch: 6| Step: 9
Training loss: 2.071032819855342
Validation loss: 2.4267398112811613

Epoch: 6| Step: 10
Training loss: 2.0967449574289923
Validation loss: 2.4259015767276706

Epoch: 6| Step: 11
Training loss: 1.608387171712215
Validation loss: 2.407428769687432

Epoch: 6| Step: 12
Training loss: 1.9289004925641533
Validation loss: 2.408153182417227

Epoch: 6| Step: 13
Training loss: 1.8294657168036685
Validation loss: 2.3962177815274326

Epoch: 438| Step: 0
Training loss: 2.218255753606744
Validation loss: 2.401913600121325

Epoch: 6| Step: 1
Training loss: 1.4497334268132125
Validation loss: 2.421057451379872

Epoch: 6| Step: 2
Training loss: 1.490529122458072
Validation loss: 2.399538974294435

Epoch: 6| Step: 3
Training loss: 1.5670488138343284
Validation loss: 2.3859257305107024

Epoch: 6| Step: 4
Training loss: 2.3019017857099566
Validation loss: 2.4581032407717887

Epoch: 6| Step: 5
Training loss: 1.8984318485882317
Validation loss: 2.3813306827585303

Epoch: 6| Step: 6
Training loss: 2.657515729138109
Validation loss: 2.3970132088435583

Epoch: 6| Step: 7
Training loss: 2.4984724146137163
Validation loss: 2.453979888744149

Epoch: 6| Step: 8
Training loss: 1.8204445197565673
Validation loss: 2.4164192655105996

Epoch: 6| Step: 9
Training loss: 1.956999148412021
Validation loss: 2.4263724251937226

Epoch: 6| Step: 10
Training loss: 2.041978993822453
Validation loss: 2.4367674612141483

Epoch: 6| Step: 11
Training loss: 1.8098343946242612
Validation loss: 2.4316025481685957

Epoch: 6| Step: 12
Training loss: 1.701119738545222
Validation loss: 2.425257854032846

Epoch: 6| Step: 13
Training loss: 1.8984389442469751
Validation loss: 2.396708307201294

Epoch: 439| Step: 0
Training loss: 1.9929100371908561
Validation loss: 2.4313079934621964

Epoch: 6| Step: 1
Training loss: 1.9313876427052787
Validation loss: 2.369710209332358

Epoch: 6| Step: 2
Training loss: 1.8248529087519143
Validation loss: 2.4119967484116653

Epoch: 6| Step: 3
Training loss: 2.0511495205052093
Validation loss: 2.397217105270061

Epoch: 6| Step: 4
Training loss: 1.6491939020566413
Validation loss: 2.4137309435739223

Epoch: 6| Step: 5
Training loss: 1.8585809887595872
Validation loss: 2.367322856897164

Epoch: 6| Step: 6
Training loss: 2.314671296085762
Validation loss: 2.4257380114911262

Epoch: 6| Step: 7
Training loss: 2.022736416874947
Validation loss: 2.424218987559504

Epoch: 6| Step: 8
Training loss: 2.3183708929789706
Validation loss: 2.445711622965619

Epoch: 6| Step: 9
Training loss: 1.831940410777637
Validation loss: 2.3799299627218913

Epoch: 6| Step: 10
Training loss: 2.1338973308130194
Validation loss: 2.3805564449350745

Epoch: 6| Step: 11
Training loss: 1.556922571166801
Validation loss: 2.417849066518978

Epoch: 6| Step: 12
Training loss: 1.9945553339973292
Validation loss: 2.3950953634196392

Epoch: 6| Step: 13
Training loss: 1.7779368322799427
Validation loss: 2.444687165619076

Epoch: 440| Step: 0
Training loss: 2.041524869185753
Validation loss: 2.4251988250259546

Epoch: 6| Step: 1
Training loss: 1.5342980235383117
Validation loss: 2.4449728164648104

Epoch: 6| Step: 2
Training loss: 1.5298996245425833
Validation loss: 2.3897309888646454

Epoch: 6| Step: 3
Training loss: 1.799734874909246
Validation loss: 2.436883863770417

Epoch: 6| Step: 4
Training loss: 2.621986748697533
Validation loss: 2.431131454620005

Epoch: 6| Step: 5
Training loss: 1.8388559722963558
Validation loss: 2.393956350559631

Epoch: 6| Step: 6
Training loss: 1.827880190898477
Validation loss: 2.398911005350434

Epoch: 6| Step: 7
Training loss: 2.389373451689414
Validation loss: 2.4348440022085014

Epoch: 6| Step: 8
Training loss: 1.9486460484642754
Validation loss: 2.3740574672517956

Epoch: 6| Step: 9
Training loss: 2.4084302264547097
Validation loss: 2.4158960856434035

Epoch: 6| Step: 10
Training loss: 1.7458293808533472
Validation loss: 2.406863882861571

Epoch: 6| Step: 11
Training loss: 1.7536627721539626
Validation loss: 2.391644632447285

Epoch: 6| Step: 12
Training loss: 1.7968263702446374
Validation loss: 2.449192991188478

Epoch: 6| Step: 13
Training loss: 2.0084031716810027
Validation loss: 2.4222285610357

Epoch: 441| Step: 0
Training loss: 2.4428413750722022
Validation loss: 2.4292645220265783

Epoch: 6| Step: 1
Training loss: 1.920176057492218
Validation loss: 2.4177452335432177

Epoch: 6| Step: 2
Training loss: 1.8067851240777424
Validation loss: 2.3618988813258115

Epoch: 6| Step: 3
Training loss: 1.5520369588934537
Validation loss: 2.3854886599531904

Epoch: 6| Step: 4
Training loss: 2.3208355554904494
Validation loss: 2.378204832313248

Epoch: 6| Step: 5
Training loss: 1.7228874345519039
Validation loss: 2.3708213861503498

Epoch: 6| Step: 6
Training loss: 1.1530324655843778
Validation loss: 2.373084959076247

Epoch: 6| Step: 7
Training loss: 1.84787953743374
Validation loss: 2.453598273601825

Epoch: 6| Step: 8
Training loss: 2.236958963630818
Validation loss: 2.4029658897515187

Epoch: 6| Step: 9
Training loss: 2.670421718196423
Validation loss: 2.417777125286724

Epoch: 6| Step: 10
Training loss: 1.8251096196108856
Validation loss: 2.3553622552360394

Epoch: 6| Step: 11
Training loss: 1.9418209254775052
Validation loss: 2.416386958524061

Epoch: 6| Step: 12
Training loss: 1.5232205750005416
Validation loss: 2.4342322657425175

Epoch: 6| Step: 13
Training loss: 2.3043822005479893
Validation loss: 2.3749415687838553

Epoch: 442| Step: 0
Training loss: 1.4925664450521148
Validation loss: 2.3854089451924745

Epoch: 6| Step: 1
Training loss: 1.430315890600925
Validation loss: 2.400136310926172

Epoch: 6| Step: 2
Training loss: 1.4655986010811306
Validation loss: 2.444836161741024

Epoch: 6| Step: 3
Training loss: 1.7270168207273828
Validation loss: 2.4607451405882497

Epoch: 6| Step: 4
Training loss: 2.143778128481129
Validation loss: 2.443881977261505

Epoch: 6| Step: 5
Training loss: 2.0507570683098124
Validation loss: 2.4312661270149563

Epoch: 6| Step: 6
Training loss: 2.0325101024944363
Validation loss: 2.403360797988612

Epoch: 6| Step: 7
Training loss: 2.2045481528969066
Validation loss: 2.396736521210827

Epoch: 6| Step: 8
Training loss: 2.2445190216910413
Validation loss: 2.419769106163693

Epoch: 6| Step: 9
Training loss: 1.132727573762957
Validation loss: 2.388732978599303

Epoch: 6| Step: 10
Training loss: 2.1566989818237183
Validation loss: 2.414732978023802

Epoch: 6| Step: 11
Training loss: 2.666373673873485
Validation loss: 2.4486685077194776

Epoch: 6| Step: 12
Training loss: 2.239558363191255
Validation loss: 2.4370257650152163

Epoch: 6| Step: 13
Training loss: 2.0459920128883637
Validation loss: 2.419338163434606

Epoch: 443| Step: 0
Training loss: 2.0887864905593654
Validation loss: 2.439792044485946

Epoch: 6| Step: 1
Training loss: 1.9334905423450217
Validation loss: 2.3894708378016647

Epoch: 6| Step: 2
Training loss: 2.2224140269897594
Validation loss: 2.4358615337949567

Epoch: 6| Step: 3
Training loss: 1.9408403949710087
Validation loss: 2.3837617319891033

Epoch: 6| Step: 4
Training loss: 2.170358581273466
Validation loss: 2.40839188485373

Epoch: 6| Step: 5
Training loss: 1.7223326363940805
Validation loss: 2.3933604300370956

Epoch: 6| Step: 6
Training loss: 2.3256140359539614
Validation loss: 2.3766474275003437

Epoch: 6| Step: 7
Training loss: 1.2877034739474793
Validation loss: 2.3992948553285216

Epoch: 6| Step: 8
Training loss: 1.6103379414978822
Validation loss: 2.4564428048861378

Epoch: 6| Step: 9
Training loss: 2.171416090090453
Validation loss: 2.400733383603482

Epoch: 6| Step: 10
Training loss: 2.1674981233617276
Validation loss: 2.4261538916660164

Epoch: 6| Step: 11
Training loss: 2.000819157692251
Validation loss: 2.3995899230800335

Epoch: 6| Step: 12
Training loss: 1.87242413651072
Validation loss: 2.3846577047176827

Epoch: 6| Step: 13
Training loss: 1.944858727901999
Validation loss: 2.4073506131356144

Epoch: 444| Step: 0
Training loss: 1.994790982743454
Validation loss: 2.388168100860934

Epoch: 6| Step: 1
Training loss: 2.402950055286352
Validation loss: 2.3995413194067696

Epoch: 6| Step: 2
Training loss: 1.8001220555779065
Validation loss: 2.366604228223698

Epoch: 6| Step: 3
Training loss: 1.9214071309072984
Validation loss: 2.4066537178247276

Epoch: 6| Step: 4
Training loss: 1.5391644284339303
Validation loss: 2.4005701870383023

Epoch: 6| Step: 5
Training loss: 1.6196880082533147
Validation loss: 2.4065105380817493

Epoch: 6| Step: 6
Training loss: 2.10656664361392
Validation loss: 2.3593074378999725

Epoch: 6| Step: 7
Training loss: 1.9325690742968828
Validation loss: 2.3935657579503515

Epoch: 6| Step: 8
Training loss: 1.3319415288784313
Validation loss: 2.386479570601684

Epoch: 6| Step: 9
Training loss: 2.3429056299655078
Validation loss: 2.418433722635031

Epoch: 6| Step: 10
Training loss: 2.2088060652779795
Validation loss: 2.4128980250980048

Epoch: 6| Step: 11
Training loss: 1.8232862552002358
Validation loss: 2.4010195474956233

Epoch: 6| Step: 12
Training loss: 2.234818421226765
Validation loss: 2.400436857629634

Epoch: 6| Step: 13
Training loss: 1.5276024640768895
Validation loss: 2.4122594693595776

Epoch: 445| Step: 0
Training loss: 1.496139326472073
Validation loss: 2.458638410233876

Epoch: 6| Step: 1
Training loss: 2.412227587563848
Validation loss: 2.423525648060469

Epoch: 6| Step: 2
Training loss: 2.0955889013897573
Validation loss: 2.4123149540934383

Epoch: 6| Step: 3
Training loss: 2.2646133795192305
Validation loss: 2.4315514456693696

Epoch: 6| Step: 4
Training loss: 2.048111753074591
Validation loss: 2.448769329827073

Epoch: 6| Step: 5
Training loss: 2.038607842630641
Validation loss: 2.452106249401229

Epoch: 6| Step: 6
Training loss: 1.6102575456276342
Validation loss: 2.353779115029608

Epoch: 6| Step: 7
Training loss: 2.1731227885496414
Validation loss: 2.3674190081377233

Epoch: 6| Step: 8
Training loss: 1.8173948817439112
Validation loss: 2.4355201958208377

Epoch: 6| Step: 9
Training loss: 1.4909509458397316
Validation loss: 2.3859820231732884

Epoch: 6| Step: 10
Training loss: 1.7842938032231976
Validation loss: 2.3833828699855797

Epoch: 6| Step: 11
Training loss: 1.8302778299938622
Validation loss: 2.409521162861454

Epoch: 6| Step: 12
Training loss: 1.5298314433030926
Validation loss: 2.3851528622797566

Epoch: 6| Step: 13
Training loss: 3.078240716763287
Validation loss: 2.448098281759415

Epoch: 446| Step: 0
Training loss: 2.2227240419692333
Validation loss: 2.395531397158715

Epoch: 6| Step: 1
Training loss: 2.103217171949105
Validation loss: 2.3823583370809556

Epoch: 6| Step: 2
Training loss: 1.9120891129664126
Validation loss: 2.361959850474109

Epoch: 6| Step: 3
Training loss: 1.5590561106863057
Validation loss: 2.3813132962831

Epoch: 6| Step: 4
Training loss: 1.983737632938865
Validation loss: 2.362773470598982

Epoch: 6| Step: 5
Training loss: 2.099186685286723
Validation loss: 2.412850929430211

Epoch: 6| Step: 6
Training loss: 1.9323423092795784
Validation loss: 2.454956668816964

Epoch: 6| Step: 7
Training loss: 1.7413738044053928
Validation loss: 2.3978802818413896

Epoch: 6| Step: 8
Training loss: 2.096939731741451
Validation loss: 2.3663090515265606

Epoch: 6| Step: 9
Training loss: 1.6968999365560238
Validation loss: 2.4002999439177546

Epoch: 6| Step: 10
Training loss: 2.335385158393196
Validation loss: 2.416982736876685

Epoch: 6| Step: 11
Training loss: 2.2985886389897443
Validation loss: 2.397182939080229

Epoch: 6| Step: 12
Training loss: 1.4234397578300046
Validation loss: 2.3577346189903867

Epoch: 6| Step: 13
Training loss: 1.7535534612219628
Validation loss: 2.4190698028818396

Epoch: 447| Step: 0
Training loss: 0.9568380355422625
Validation loss: 2.3967419185984693

Epoch: 6| Step: 1
Training loss: 2.0259494580726933
Validation loss: 2.40194975894224

Epoch: 6| Step: 2
Training loss: 2.252531958214649
Validation loss: 2.4206789448663266

Epoch: 6| Step: 3
Training loss: 1.971070511507447
Validation loss: 2.4061246449622633

Epoch: 6| Step: 4
Training loss: 1.4320446656842694
Validation loss: 2.4205237962951736

Epoch: 6| Step: 5
Training loss: 1.6859941474794873
Validation loss: 2.349998790659492

Epoch: 6| Step: 6
Training loss: 2.302678878413107
Validation loss: 2.43241584427293

Epoch: 6| Step: 7
Training loss: 1.9175148483159037
Validation loss: 2.399002235845881

Epoch: 6| Step: 8
Training loss: 2.116687673429442
Validation loss: 2.393937896008717

Epoch: 6| Step: 9
Training loss: 1.676239164517945
Validation loss: 2.3670593755544127

Epoch: 6| Step: 10
Training loss: 2.099625499574711
Validation loss: 2.4227871667279115

Epoch: 6| Step: 11
Training loss: 2.4472428280437604
Validation loss: 2.420690668615637

Epoch: 6| Step: 12
Training loss: 1.5798870107835723
Validation loss: 2.3682361956056486

Epoch: 6| Step: 13
Training loss: 2.185395018182765
Validation loss: 2.4006970612309817

Epoch: 448| Step: 0
Training loss: 2.019342941270558
Validation loss: 2.4011717769458945

Epoch: 6| Step: 1
Training loss: 2.5982257878344353
Validation loss: 2.398747361507195

Epoch: 6| Step: 2
Training loss: 1.9645640361831946
Validation loss: 2.3974729768859144

Epoch: 6| Step: 3
Training loss: 1.8707342578960198
Validation loss: 2.3929633743560914

Epoch: 6| Step: 4
Training loss: 1.8633481699444425
Validation loss: 2.4105388527607836

Epoch: 6| Step: 5
Training loss: 1.3548353842651997
Validation loss: 2.4101930786558965

Epoch: 6| Step: 6
Training loss: 1.9357119277191681
Validation loss: 2.4140410344834486

Epoch: 6| Step: 7
Training loss: 1.192569352538465
Validation loss: 2.414146633469522

Epoch: 6| Step: 8
Training loss: 1.7827316279210232
Validation loss: 2.430181181906097

Epoch: 6| Step: 9
Training loss: 2.2689836534135734
Validation loss: 2.383033985029604

Epoch: 6| Step: 10
Training loss: 1.3380844532695708
Validation loss: 2.4296513234805097

Epoch: 6| Step: 11
Training loss: 2.427088779776251
Validation loss: 2.4240867801510766

Epoch: 6| Step: 12
Training loss: 2.257647128797258
Validation loss: 2.3919137323803734

Epoch: 6| Step: 13
Training loss: 2.7598233335040345
Validation loss: 2.424468594068473

Epoch: 449| Step: 0
Training loss: 2.743712693918815
Validation loss: 2.3936372176749843

Epoch: 6| Step: 1
Training loss: 1.937819608353273
Validation loss: 2.414754795167786

Epoch: 6| Step: 2
Training loss: 1.9108326344323103
Validation loss: 2.42293514001696

Epoch: 6| Step: 3
Training loss: 1.7605334436933924
Validation loss: 2.4169570906050564

Epoch: 6| Step: 4
Training loss: 1.9690454654898184
Validation loss: 2.359263056094826

Epoch: 6| Step: 5
Training loss: 1.7190050802815957
Validation loss: 2.3970244964741236

Epoch: 6| Step: 6
Training loss: 1.656466703813172
Validation loss: 2.4357871375985867

Epoch: 6| Step: 7
Training loss: 2.2719717642681734
Validation loss: 2.399179285988899

Epoch: 6| Step: 8
Training loss: 1.8394774378030303
Validation loss: 2.409569142845544

Epoch: 6| Step: 9
Training loss: 1.8744163876473674
Validation loss: 2.4054193979550775

Epoch: 6| Step: 10
Training loss: 1.3862778513443579
Validation loss: 2.4081541767226877

Epoch: 6| Step: 11
Training loss: 1.4403969971131578
Validation loss: 2.3928326488236253

Epoch: 6| Step: 12
Training loss: 2.445240251247722
Validation loss: 2.386890191803744

Epoch: 6| Step: 13
Training loss: 2.0820706419233197
Validation loss: 2.4086631901850595

Epoch: 450| Step: 0
Training loss: 1.3997154150953741
Validation loss: 2.380115827034327

Epoch: 6| Step: 1
Training loss: 1.9534434554833555
Validation loss: 2.3889534082147694

Epoch: 6| Step: 2
Training loss: 2.222952502842789
Validation loss: 2.3889870010181866

Epoch: 6| Step: 3
Training loss: 1.8800553517613905
Validation loss: 2.4037491153349406

Epoch: 6| Step: 4
Training loss: 1.6864256087723941
Validation loss: 2.4326664507923614

Epoch: 6| Step: 5
Training loss: 2.0704693428944374
Validation loss: 2.3801761453677655

Epoch: 6| Step: 6
Training loss: 1.6094941030336816
Validation loss: 2.390120586917468

Epoch: 6| Step: 7
Training loss: 1.6177088684880276
Validation loss: 2.361610339210155

Epoch: 6| Step: 8
Training loss: 1.9434336585794953
Validation loss: 2.4081635534075256

Epoch: 6| Step: 9
Training loss: 2.1801763827161826
Validation loss: 2.3705809677762395

Epoch: 6| Step: 10
Training loss: 2.088350764529381
Validation loss: 2.4489937539744866

Epoch: 6| Step: 11
Training loss: 2.1146903425930126
Validation loss: 2.4213577051494437

Epoch: 6| Step: 12
Training loss: 2.2946065483168065
Validation loss: 2.364410788376428

Epoch: 6| Step: 13
Training loss: 2.2718220112955767
Validation loss: 2.4225869806374862

Epoch: 451| Step: 0
Training loss: 1.8272430379121407
Validation loss: 2.41145399301385

Epoch: 6| Step: 1
Training loss: 1.660886859570386
Validation loss: 2.4132994925329

Epoch: 6| Step: 2
Training loss: 2.059307517536472
Validation loss: 2.3675451337150557

Epoch: 6| Step: 3
Training loss: 1.94734594242585
Validation loss: 2.417015416147748

Epoch: 6| Step: 4
Training loss: 1.8577095073773102
Validation loss: 2.42157624274603

Epoch: 6| Step: 5
Training loss: 2.047630578280033
Validation loss: 2.406449840074281

Epoch: 6| Step: 6
Training loss: 1.2504945730269283
Validation loss: 2.3815216064369658

Epoch: 6| Step: 7
Training loss: 1.9830373024868189
Validation loss: 2.4005890102965965

Epoch: 6| Step: 8
Training loss: 2.964176871949149
Validation loss: 2.379108422452175

Epoch: 6| Step: 9
Training loss: 1.9198778521903244
Validation loss: 2.4025045382941803

Epoch: 6| Step: 10
Training loss: 1.2785235914337048
Validation loss: 2.410266749170345

Epoch: 6| Step: 11
Training loss: 1.656069115891821
Validation loss: 2.3915958898149903

Epoch: 6| Step: 12
Training loss: 2.3729287200523363
Validation loss: 2.446289191400462

Epoch: 6| Step: 13
Training loss: 1.9197393817650186
Validation loss: 2.431462349525544

Epoch: 452| Step: 0
Training loss: 1.8532418791529843
Validation loss: 2.4033817860870017

Epoch: 6| Step: 1
Training loss: 2.1395321026109957
Validation loss: 2.3919284759438297

Epoch: 6| Step: 2
Training loss: 2.2296478845382466
Validation loss: 2.3553976985167306

Epoch: 6| Step: 3
Training loss: 1.75344455139015
Validation loss: 2.3895040767920124

Epoch: 6| Step: 4
Training loss: 2.223372359135866
Validation loss: 2.3739109834809398

Epoch: 6| Step: 5
Training loss: 1.919974092567017
Validation loss: 2.40588451774664

Epoch: 6| Step: 6
Training loss: 1.4394489842100382
Validation loss: 2.380783686477537

Epoch: 6| Step: 7
Training loss: 1.9477453989496776
Validation loss: 2.4076980657215845

Epoch: 6| Step: 8
Training loss: 1.9943144570261275
Validation loss: 2.4139309863323546

Epoch: 6| Step: 9
Training loss: 1.7119667058185024
Validation loss: 2.3763773237727035

Epoch: 6| Step: 10
Training loss: 1.8861367411956211
Validation loss: 2.409182686169984

Epoch: 6| Step: 11
Training loss: 2.2353254310877047
Validation loss: 2.390707546596906

Epoch: 6| Step: 12
Training loss: 1.9607169950606969
Validation loss: 2.402354165278148

Epoch: 6| Step: 13
Training loss: 1.4179097313066278
Validation loss: 2.380140729629717

Epoch: 453| Step: 0
Training loss: 1.988936460566587
Validation loss: 2.4106521791599866

Epoch: 6| Step: 1
Training loss: 2.4789323028147576
Validation loss: 2.3526522307818754

Epoch: 6| Step: 2
Training loss: 1.7710796259723682
Validation loss: 2.3838068965836863

Epoch: 6| Step: 3
Training loss: 2.10987328189527
Validation loss: 2.3679948808873292

Epoch: 6| Step: 4
Training loss: 1.6121822428520545
Validation loss: 2.3264516446591545

Epoch: 6| Step: 5
Training loss: 2.102759265132271
Validation loss: 2.3933569145303464

Epoch: 6| Step: 6
Training loss: 1.758247152208213
Validation loss: 2.417592641045411

Epoch: 6| Step: 7
Training loss: 2.098564420200729
Validation loss: 2.438970973864354

Epoch: 6| Step: 8
Training loss: 1.652238414103296
Validation loss: 2.4139578345550414

Epoch: 6| Step: 9
Training loss: 1.6376214280860777
Validation loss: 2.4359427079598386

Epoch: 6| Step: 10
Training loss: 1.7926269737399303
Validation loss: 2.4536052051228223

Epoch: 6| Step: 11
Training loss: 1.5134404750040933
Validation loss: 2.40981501888739

Epoch: 6| Step: 12
Training loss: 2.369598470225539
Validation loss: 2.3868632254651803

Epoch: 6| Step: 13
Training loss: 2.1252232602587484
Validation loss: 2.421561348591771

Epoch: 454| Step: 0
Training loss: 1.8920286028395588
Validation loss: 2.414077400331183

Epoch: 6| Step: 1
Training loss: 1.8687817778165983
Validation loss: 2.4330013854345185

Epoch: 6| Step: 2
Training loss: 1.6501992018702687
Validation loss: 2.3800100441091074

Epoch: 6| Step: 3
Training loss: 1.6881623557687853
Validation loss: 2.3622993177827283

Epoch: 6| Step: 4
Training loss: 1.5514818429871013
Validation loss: 2.3849512264009363

Epoch: 6| Step: 5
Training loss: 1.7218108232726719
Validation loss: 2.39474575045077

Epoch: 6| Step: 6
Training loss: 2.578651883010276
Validation loss: 2.3783512133099354

Epoch: 6| Step: 7
Training loss: 1.8325615544408922
Validation loss: 2.3404581010962686

Epoch: 6| Step: 8
Training loss: 2.347591151701176
Validation loss: 2.4106170192046377

Epoch: 6| Step: 9
Training loss: 2.6890811261203047
Validation loss: 2.462555888126681

Epoch: 6| Step: 10
Training loss: 2.156170498031928
Validation loss: 2.3888418695080635

Epoch: 6| Step: 11
Training loss: 1.8064766474359206
Validation loss: 2.4560457003278624

Epoch: 6| Step: 12
Training loss: 1.482462323306668
Validation loss: 2.4170415677316943

Epoch: 6| Step: 13
Training loss: 0.8877420108879354
Validation loss: 2.389794083218876

Epoch: 455| Step: 0
Training loss: 1.9441196813790844
Validation loss: 2.366893396308915

Epoch: 6| Step: 1
Training loss: 1.6803120006626515
Validation loss: 2.398541724173875

Epoch: 6| Step: 2
Training loss: 1.593962711276197
Validation loss: 2.43669360873137

Epoch: 6| Step: 3
Training loss: 2.0409429655876568
Validation loss: 2.404338173592258

Epoch: 6| Step: 4
Training loss: 1.8568102675036122
Validation loss: 2.3877261142726516

Epoch: 6| Step: 5
Training loss: 2.0045734804215645
Validation loss: 2.3945337563275273

Epoch: 6| Step: 6
Training loss: 1.9734034567801415
Validation loss: 2.415282794874588

Epoch: 6| Step: 7
Training loss: 1.751039196453663
Validation loss: 2.448509211269166

Epoch: 6| Step: 8
Training loss: 1.7881432716265442
Validation loss: 2.37236463188251

Epoch: 6| Step: 9
Training loss: 1.970494723382877
Validation loss: 2.3815569634260467

Epoch: 6| Step: 10
Training loss: 2.035829985349476
Validation loss: 2.4222534307442696

Epoch: 6| Step: 11
Training loss: 2.2718021764194565
Validation loss: 2.3553138186336784

Epoch: 6| Step: 12
Training loss: 1.8277412729118874
Validation loss: 2.4039123680328593

Epoch: 6| Step: 13
Training loss: 2.064897126782726
Validation loss: 2.3985007554536786

Epoch: 456| Step: 0
Training loss: 1.5222076929672128
Validation loss: 2.366945992800197

Epoch: 6| Step: 1
Training loss: 1.9923510316038524
Validation loss: 2.384624229388184

Epoch: 6| Step: 2
Training loss: 2.0822914061197104
Validation loss: 2.396542286319611

Epoch: 6| Step: 3
Training loss: 2.1893808181079915
Validation loss: 2.3938138432089437

Epoch: 6| Step: 4
Training loss: 2.505489045487061
Validation loss: 2.3836567830556943

Epoch: 6| Step: 5
Training loss: 2.121277971504762
Validation loss: 2.4221686231209048

Epoch: 6| Step: 6
Training loss: 1.9200559862239368
Validation loss: 2.3926989632537765

Epoch: 6| Step: 7
Training loss: 1.6824331863763515
Validation loss: 2.4340247260804673

Epoch: 6| Step: 8
Training loss: 1.7420465386674664
Validation loss: 2.3849495710178386

Epoch: 6| Step: 9
Training loss: 2.0763537667265686
Validation loss: 2.3919060754662604

Epoch: 6| Step: 10
Training loss: 1.6481759103341
Validation loss: 2.4103582454482235

Epoch: 6| Step: 11
Training loss: 1.8850149355430739
Validation loss: 2.3692068083917386

Epoch: 6| Step: 12
Training loss: 1.6593480914389276
Validation loss: 2.380144399293785

Epoch: 6| Step: 13
Training loss: 1.4118029418902773
Validation loss: 2.3652771468593605

Epoch: 457| Step: 0
Training loss: 2.1577505888678994
Validation loss: 2.396700444186355

Epoch: 6| Step: 1
Training loss: 1.6677212319321038
Validation loss: 2.3808842127500593

Epoch: 6| Step: 2
Training loss: 1.875621629029969
Validation loss: 2.380213803025441

Epoch: 6| Step: 3
Training loss: 2.2550618136576097
Validation loss: 2.3987767789684713

Epoch: 6| Step: 4
Training loss: 2.0422053761710437
Validation loss: 2.372532411620153

Epoch: 6| Step: 5
Training loss: 2.229823244556692
Validation loss: 2.4032991734576346

Epoch: 6| Step: 6
Training loss: 1.8573030098828838
Validation loss: 2.418772594230527

Epoch: 6| Step: 7
Training loss: 2.1746536154449907
Validation loss: 2.373624339540733

Epoch: 6| Step: 8
Training loss: 1.3916287175256252
Validation loss: 2.3835187366012054

Epoch: 6| Step: 9
Training loss: 1.836426690042317
Validation loss: 2.3756940795718338

Epoch: 6| Step: 10
Training loss: 2.234843171695767
Validation loss: 2.4216368659710983

Epoch: 6| Step: 11
Training loss: 1.5592047466532688
Validation loss: 2.42585810575448

Epoch: 6| Step: 12
Training loss: 2.127571345387015
Validation loss: 2.366156574337289

Epoch: 6| Step: 13
Training loss: 1.2233091323565295
Validation loss: 2.4036142962692426

Epoch: 458| Step: 0
Training loss: 1.6234126774759925
Validation loss: 2.4103015244191623

Epoch: 6| Step: 1
Training loss: 2.1988595564170157
Validation loss: 2.3958176521833163

Epoch: 6| Step: 2
Training loss: 2.3268132962947865
Validation loss: 2.3512397653394546

Epoch: 6| Step: 3
Training loss: 1.59340432102024
Validation loss: 2.418788678056428

Epoch: 6| Step: 4
Training loss: 1.825750716496431
Validation loss: 2.4083437440975533

Epoch: 6| Step: 5
Training loss: 2.336096206427992
Validation loss: 2.42097231912654

Epoch: 6| Step: 6
Training loss: 2.369961262317951
Validation loss: 2.378710951467558

Epoch: 6| Step: 7
Training loss: 2.0527543521565974
Validation loss: 2.3972692348278715

Epoch: 6| Step: 8
Training loss: 1.5043378730760086
Validation loss: 2.4058120493064927

Epoch: 6| Step: 9
Training loss: 1.5243927919320002
Validation loss: 2.3809515130609844

Epoch: 6| Step: 10
Training loss: 1.5654364649387364
Validation loss: 2.434351318569387

Epoch: 6| Step: 11
Training loss: 1.7619605057108096
Validation loss: 2.4247521042753957

Epoch: 6| Step: 12
Training loss: 2.244131594540958
Validation loss: 2.4382907730075702

Epoch: 6| Step: 13
Training loss: 1.2961108702666515
Validation loss: 2.3647846763040983

Epoch: 459| Step: 0
Training loss: 1.7521555431724927
Validation loss: 2.3590966842648617

Epoch: 6| Step: 1
Training loss: 1.7454568610257264
Validation loss: 2.422356930779814

Epoch: 6| Step: 2
Training loss: 1.8166005020458413
Validation loss: 2.4032314060900513

Epoch: 6| Step: 3
Training loss: 2.296103626916597
Validation loss: 2.3811514247956724

Epoch: 6| Step: 4
Training loss: 2.3993741173033345
Validation loss: 2.4028822183262224

Epoch: 6| Step: 5
Training loss: 2.067924763637199
Validation loss: 2.4064132833195377

Epoch: 6| Step: 6
Training loss: 1.5990091206026267
Validation loss: 2.4085506291645467

Epoch: 6| Step: 7
Training loss: 1.5699171640933378
Validation loss: 2.378054210997793

Epoch: 6| Step: 8
Training loss: 1.3634226815823696
Validation loss: 2.397580526692634

Epoch: 6| Step: 9
Training loss: 1.6915789157050467
Validation loss: 2.362952576720763

Epoch: 6| Step: 10
Training loss: 1.7569915210647387
Validation loss: 2.373670047493377

Epoch: 6| Step: 11
Training loss: 1.3835062991248062
Validation loss: 2.349103194412163

Epoch: 6| Step: 12
Training loss: 2.6555438729973138
Validation loss: 2.421010371483239

Epoch: 6| Step: 13
Training loss: 2.1253652819661633
Validation loss: 2.4130961151837345

Epoch: 460| Step: 0
Training loss: 1.5238597578116109
Validation loss: 2.3798467062017394

Epoch: 6| Step: 1
Training loss: 2.0350737747203875
Validation loss: 2.3606904949281944

Epoch: 6| Step: 2
Training loss: 1.6655946939942698
Validation loss: 2.368693463449008

Epoch: 6| Step: 3
Training loss: 1.6113198389938468
Validation loss: 2.3487981846217583

Epoch: 6| Step: 4
Training loss: 1.7177419307176658
Validation loss: 2.4094910727445304

Epoch: 6| Step: 5
Training loss: 1.972514171960393
Validation loss: 2.420441618872123

Epoch: 6| Step: 6
Training loss: 2.5160788369555585
Validation loss: 2.3550246661929495

Epoch: 6| Step: 7
Training loss: 2.17733583096425
Validation loss: 2.445277470949754

Epoch: 6| Step: 8
Training loss: 2.0999350219846367
Validation loss: 2.3791278336036705

Epoch: 6| Step: 9
Training loss: 2.135885853899944
Validation loss: 2.397557083018851

Epoch: 6| Step: 10
Training loss: 1.4143157226439473
Validation loss: 2.402030754091999

Epoch: 6| Step: 11
Training loss: 1.2968248104816666
Validation loss: 2.3865034979991604

Epoch: 6| Step: 12
Training loss: 2.4055406590040382
Validation loss: 2.3351008203994823

Epoch: 6| Step: 13
Training loss: 2.0442430887141616
Validation loss: 2.3622137148321296

Epoch: 461| Step: 0
Training loss: 2.3095225161875126
Validation loss: 2.4279894485210574

Epoch: 6| Step: 1
Training loss: 2.1231453599871606
Validation loss: 2.406169476098643

Epoch: 6| Step: 2
Training loss: 1.7806641133793661
Validation loss: 2.388040369391617

Epoch: 6| Step: 3
Training loss: 1.2145156662654155
Validation loss: 2.4263228428657766

Epoch: 6| Step: 4
Training loss: 1.7964477031006458
Validation loss: 2.4143003357272095

Epoch: 6| Step: 5
Training loss: 1.3522498527381495
Validation loss: 2.437429931407614

Epoch: 6| Step: 6
Training loss: 1.4729688398661231
Validation loss: 2.411360346096038

Epoch: 6| Step: 7
Training loss: 2.0046545940264417
Validation loss: 2.3979772861273276

Epoch: 6| Step: 8
Training loss: 1.9118266846461904
Validation loss: 2.3883226860326636

Epoch: 6| Step: 9
Training loss: 2.0242276213969412
Validation loss: 2.412504746040659

Epoch: 6| Step: 10
Training loss: 2.271443754507013
Validation loss: 2.4043927237100973

Epoch: 6| Step: 11
Training loss: 2.1848266614862073
Validation loss: 2.3853252850317785

Epoch: 6| Step: 12
Training loss: 2.4147357680812362
Validation loss: 2.3854966534211197

Epoch: 6| Step: 13
Training loss: 0.7025778442911634
Validation loss: 2.4235943516112237

Epoch: 462| Step: 0
Training loss: 2.2466678316960396
Validation loss: 2.386627509703984

Epoch: 6| Step: 1
Training loss: 2.188660885812029
Validation loss: 2.3904543772932003

Epoch: 6| Step: 2
Training loss: 1.8893262958211583
Validation loss: 2.3989564553913616

Epoch: 6| Step: 3
Training loss: 2.161904040117025
Validation loss: 2.3838863971397433

Epoch: 6| Step: 4
Training loss: 1.688621995706785
Validation loss: 2.400859286015422

Epoch: 6| Step: 5
Training loss: 1.5325694724635637
Validation loss: 2.400009447680784

Epoch: 6| Step: 6
Training loss: 1.6032397907645237
Validation loss: 2.396164161201296

Epoch: 6| Step: 7
Training loss: 2.393427782807259
Validation loss: 2.383538496886618

Epoch: 6| Step: 8
Training loss: 1.7115862587475463
Validation loss: 2.448003689788484

Epoch: 6| Step: 9
Training loss: 1.8882350475638972
Validation loss: 2.395785659665267

Epoch: 6| Step: 10
Training loss: 1.8135945533901185
Validation loss: 2.3900563347001604

Epoch: 6| Step: 11
Training loss: 1.740730805665531
Validation loss: 2.3782892657458294

Epoch: 6| Step: 12
Training loss: 1.2366256476400297
Validation loss: 2.3893315049563326

Epoch: 6| Step: 13
Training loss: 2.64119899312355
Validation loss: 2.407545356064699

Epoch: 463| Step: 0
Training loss: 1.6155349470235305
Validation loss: 2.397779659829944

Epoch: 6| Step: 1
Training loss: 1.583309231959499
Validation loss: 2.410404223080084

Epoch: 6| Step: 2
Training loss: 1.484962588009161
Validation loss: 2.41823702601566

Epoch: 6| Step: 3
Training loss: 1.7301678880361946
Validation loss: 2.4119427316557442

Epoch: 6| Step: 4
Training loss: 1.5693077554884374
Validation loss: 2.4146536723719443

Epoch: 6| Step: 5
Training loss: 2.366241769751147
Validation loss: 2.406176764262417

Epoch: 6| Step: 6
Training loss: 2.6009483185194453
Validation loss: 2.3702852528663976

Epoch: 6| Step: 7
Training loss: 2.2512594512791892
Validation loss: 2.41233639936789

Epoch: 6| Step: 8
Training loss: 1.4254755397853613
Validation loss: 2.433606119966702

Epoch: 6| Step: 9
Training loss: 1.7511488685568748
Validation loss: 2.4218623928095218

Epoch: 6| Step: 10
Training loss: 2.1759771673182673
Validation loss: 2.4034469167196417

Epoch: 6| Step: 11
Training loss: 1.8458623262400289
Validation loss: 2.4246226189723923

Epoch: 6| Step: 12
Training loss: 1.9435437599007566
Validation loss: 2.4162918821419286

Epoch: 6| Step: 13
Training loss: 2.1714003888251674
Validation loss: 2.3674381653645713

Epoch: 464| Step: 0
Training loss: 1.7211610702113866
Validation loss: 2.393782838107646

Epoch: 6| Step: 1
Training loss: 1.5983785101930406
Validation loss: 2.385417427384923

Epoch: 6| Step: 2
Training loss: 1.9140482999313824
Validation loss: 2.380373822846175

Epoch: 6| Step: 3
Training loss: 1.3696524497335878
Validation loss: 2.3936403771908994

Epoch: 6| Step: 4
Training loss: 1.7577501073996487
Validation loss: 2.39711051879372

Epoch: 6| Step: 5
Training loss: 2.2736020372764165
Validation loss: 2.4010590483764345

Epoch: 6| Step: 6
Training loss: 1.8868566111236864
Validation loss: 2.4115951156618074

Epoch: 6| Step: 7
Training loss: 1.7431598225176026
Validation loss: 2.4098520038201308

Epoch: 6| Step: 8
Training loss: 2.5097443457269115
Validation loss: 2.3819921583962334

Epoch: 6| Step: 9
Training loss: 1.6533702069959517
Validation loss: 2.3511358824018913

Epoch: 6| Step: 10
Training loss: 1.7795475637666345
Validation loss: 2.3959860451186277

Epoch: 6| Step: 11
Training loss: 1.8636676379707129
Validation loss: 2.3773109470786884

Epoch: 6| Step: 12
Training loss: 2.4866657372473786
Validation loss: 2.358281593432062

Epoch: 6| Step: 13
Training loss: 1.6218073365902075
Validation loss: 2.365674861996335

Epoch: 465| Step: 0
Training loss: 1.654870952634388
Validation loss: 2.3957277707192732

Epoch: 6| Step: 1
Training loss: 1.7772399201299787
Validation loss: 2.4049164243935475

Epoch: 6| Step: 2
Training loss: 2.351508764115584
Validation loss: 2.3986067393375303

Epoch: 6| Step: 3
Training loss: 2.067608604300188
Validation loss: 2.38412230111407

Epoch: 6| Step: 4
Training loss: 1.707301138137262
Validation loss: 2.3937980403067294

Epoch: 6| Step: 5
Training loss: 2.078712552410582
Validation loss: 2.4375927426027832

Epoch: 6| Step: 6
Training loss: 2.563084326390896
Validation loss: 2.367830789937769

Epoch: 6| Step: 7
Training loss: 1.7409919776534475
Validation loss: 2.3995288491521385

Epoch: 6| Step: 8
Training loss: 2.017417879194093
Validation loss: 2.393500360579165

Epoch: 6| Step: 9
Training loss: 1.4074650919025724
Validation loss: 2.419266035473747

Epoch: 6| Step: 10
Training loss: 1.5212231315051767
Validation loss: 2.3970976177280567

Epoch: 6| Step: 11
Training loss: 1.6417839679669017
Validation loss: 2.4058557801922347

Epoch: 6| Step: 12
Training loss: 1.648681188713519
Validation loss: 2.431320706674349

Epoch: 6| Step: 13
Training loss: 2.122670972967492
Validation loss: 2.4086980896960384

Epoch: 466| Step: 0
Training loss: 1.4307378860539368
Validation loss: 2.386348443688117

Epoch: 6| Step: 1
Training loss: 1.6669519259792709
Validation loss: 2.381569788823287

Epoch: 6| Step: 2
Training loss: 1.492893870665234
Validation loss: 2.4184960098842048

Epoch: 6| Step: 3
Training loss: 1.8611740256662452
Validation loss: 2.4056663790918975

Epoch: 6| Step: 4
Training loss: 2.263055646750766
Validation loss: 2.380594668406059

Epoch: 6| Step: 5
Training loss: 1.2462700506833768
Validation loss: 2.4015311508144284

Epoch: 6| Step: 6
Training loss: 1.350621772561019
Validation loss: 2.324255157927321

Epoch: 6| Step: 7
Training loss: 2.406481050570091
Validation loss: 2.364477121507358

Epoch: 6| Step: 8
Training loss: 2.2107161016784715
Validation loss: 2.461847460847183

Epoch: 6| Step: 9
Training loss: 2.4113996813063054
Validation loss: 2.374566307365769

Epoch: 6| Step: 10
Training loss: 1.74923321410005
Validation loss: 2.4291079377006444

Epoch: 6| Step: 11
Training loss: 2.1685034839900315
Validation loss: 2.391867743368147

Epoch: 6| Step: 12
Training loss: 2.0034933575757363
Validation loss: 2.341440348292876

Epoch: 6| Step: 13
Training loss: 1.4269978388587503
Validation loss: 2.3631460705921463

Epoch: 467| Step: 0
Training loss: 1.7391786466270287
Validation loss: 2.3840819115243566

Epoch: 6| Step: 1
Training loss: 1.8004072549837766
Validation loss: 2.409477916645569

Epoch: 6| Step: 2
Training loss: 1.3498455012182389
Validation loss: 2.3838222021927296

Epoch: 6| Step: 3
Training loss: 1.8502352178380252
Validation loss: 2.391016257424806

Epoch: 6| Step: 4
Training loss: 1.429970635065937
Validation loss: 2.3571381559983404

Epoch: 6| Step: 5
Training loss: 2.1599290945636342
Validation loss: 2.409244393244929

Epoch: 6| Step: 6
Training loss: 1.8706907981264098
Validation loss: 2.355952103546054

Epoch: 6| Step: 7
Training loss: 1.7923105398843737
Validation loss: 2.3724840311075126

Epoch: 6| Step: 8
Training loss: 1.6700492230316544
Validation loss: 2.3803696435798245

Epoch: 6| Step: 9
Training loss: 2.2106195767168684
Validation loss: 2.4006716344957235

Epoch: 6| Step: 10
Training loss: 1.8863695030706122
Validation loss: 2.3989673064212256

Epoch: 6| Step: 11
Training loss: 2.7336072443356194
Validation loss: 2.3787727312425777

Epoch: 6| Step: 12
Training loss: 2.1273950655348575
Validation loss: 2.4000369381882045

Epoch: 6| Step: 13
Training loss: 1.0733876845615513
Validation loss: 2.3755068829072474

Epoch: 468| Step: 0
Training loss: 1.8096884922030796
Validation loss: 2.4046513702354932

Epoch: 6| Step: 1
Training loss: 2.1051590219265806
Validation loss: 2.372844988831642

Epoch: 6| Step: 2
Training loss: 2.1110358587315816
Validation loss: 2.3618116948366796

Epoch: 6| Step: 3
Training loss: 1.6451255467517352
Validation loss: 2.3969366956170632

Epoch: 6| Step: 4
Training loss: 1.6088442621721708
Validation loss: 2.3815955992616527

Epoch: 6| Step: 5
Training loss: 2.2293028982965764
Validation loss: 2.4216057888774905

Epoch: 6| Step: 6
Training loss: 1.8491539077123784
Validation loss: 2.3839546004277588

Epoch: 6| Step: 7
Training loss: 1.9676030769151924
Validation loss: 2.3806650023396836

Epoch: 6| Step: 8
Training loss: 1.8972616439504248
Validation loss: 2.4057641989916867

Epoch: 6| Step: 9
Training loss: 1.8428905229513066
Validation loss: 2.4007077922672235

Epoch: 6| Step: 10
Training loss: 1.370396754807473
Validation loss: 2.3997878009036757

Epoch: 6| Step: 11
Training loss: 2.4658619852604855
Validation loss: 2.3770474733267766

Epoch: 6| Step: 12
Training loss: 1.503176901192906
Validation loss: 2.4027359351627484

Epoch: 6| Step: 13
Training loss: 1.7297661519625893
Validation loss: 2.3783271252076066

Epoch: 469| Step: 0
Training loss: 2.462429405788359
Validation loss: 2.3936077172342825

Epoch: 6| Step: 1
Training loss: 1.7198369144038037
Validation loss: 2.4147252437723923

Epoch: 6| Step: 2
Training loss: 1.9292437703465943
Validation loss: 2.398207103719022

Epoch: 6| Step: 3
Training loss: 2.327021087478806
Validation loss: 2.391532938401651

Epoch: 6| Step: 4
Training loss: 1.5289730347874608
Validation loss: 2.4092029552934866

Epoch: 6| Step: 5
Training loss: 1.7873865798499318
Validation loss: 2.393734406759668

Epoch: 6| Step: 6
Training loss: 1.6156634829750645
Validation loss: 2.405250781862958

Epoch: 6| Step: 7
Training loss: 2.013815607367287
Validation loss: 2.3857649961573215

Epoch: 6| Step: 8
Training loss: 1.735689369686642
Validation loss: 2.39371504444179

Epoch: 6| Step: 9
Training loss: 2.0801434573806903
Validation loss: 2.3722182035222006

Epoch: 6| Step: 10
Training loss: 1.669575687686381
Validation loss: 2.378350216246057

Epoch: 6| Step: 11
Training loss: 2.2016151611440953
Validation loss: 2.3438751493559686

Epoch: 6| Step: 12
Training loss: 1.6555891337961384
Validation loss: 2.3749129317709063

Epoch: 6| Step: 13
Training loss: 1.2971884107483138
Validation loss: 2.385676622947422

Epoch: 470| Step: 0
Training loss: 2.4004773340789956
Validation loss: 2.3848543673577063

Epoch: 6| Step: 1
Training loss: 1.6087185900629606
Validation loss: 2.4164046363656357

Epoch: 6| Step: 2
Training loss: 2.0858140544582087
Validation loss: 2.4190242972910148

Epoch: 6| Step: 3
Training loss: 1.6541626930989826
Validation loss: 2.4496176823386655

Epoch: 6| Step: 4
Training loss: 2.6861880449097315
Validation loss: 2.4078402006441726

Epoch: 6| Step: 5
Training loss: 1.476475788779584
Validation loss: 2.4017764674516755

Epoch: 6| Step: 6
Training loss: 2.1065956171746194
Validation loss: 2.3967575352282986

Epoch: 6| Step: 7
Training loss: 1.8708659055234813
Validation loss: 2.3872788563556386

Epoch: 6| Step: 8
Training loss: 1.3905039531016474
Validation loss: 2.395194445614283

Epoch: 6| Step: 9
Training loss: 1.4735612997268672
Validation loss: 2.391874360747152

Epoch: 6| Step: 10
Training loss: 1.8300501150554598
Validation loss: 2.395091730577687

Epoch: 6| Step: 11
Training loss: 1.9876592296418776
Validation loss: 2.3752353488997446

Epoch: 6| Step: 12
Training loss: 1.6555635001200308
Validation loss: 2.450351922988619

Epoch: 6| Step: 13
Training loss: 1.8404921504783143
Validation loss: 2.3627372525775123

Epoch: 471| Step: 0
Training loss: 1.9024287837330214
Validation loss: 2.3912959054507423

Epoch: 6| Step: 1
Training loss: 2.5347019723115265
Validation loss: 2.39893398802519

Epoch: 6| Step: 2
Training loss: 2.086834318273453
Validation loss: 2.4206759307839314

Epoch: 6| Step: 3
Training loss: 1.6115527926942843
Validation loss: 2.4120501623864956

Epoch: 6| Step: 4
Training loss: 2.2739196475820487
Validation loss: 2.3745918171429414

Epoch: 6| Step: 5
Training loss: 2.095032256613248
Validation loss: 2.3799962909494137

Epoch: 6| Step: 6
Training loss: 1.7688124251386033
Validation loss: 2.360558025052239

Epoch: 6| Step: 7
Training loss: 1.5025835041320161
Validation loss: 2.3285382962386865

Epoch: 6| Step: 8
Training loss: 2.127194225423377
Validation loss: 2.39197193334384

Epoch: 6| Step: 9
Training loss: 1.5018012834444656
Validation loss: 2.381649513676572

Epoch: 6| Step: 10
Training loss: 1.5880646369808906
Validation loss: 2.3912577018710035

Epoch: 6| Step: 11
Training loss: 1.951107111897542
Validation loss: 2.364953999759996

Epoch: 6| Step: 12
Training loss: 1.3502946320198859
Validation loss: 2.4137794240251433

Epoch: 6| Step: 13
Training loss: 2.2539047690771783
Validation loss: 2.4280987074654754

Epoch: 472| Step: 0
Training loss: 1.6422507813780354
Validation loss: 2.3793171912397755

Epoch: 6| Step: 1
Training loss: 1.6051283426754264
Validation loss: 2.415828156962146

Epoch: 6| Step: 2
Training loss: 1.5399080848511832
Validation loss: 2.443207721199564

Epoch: 6| Step: 3
Training loss: 1.6235074745055504
Validation loss: 2.3999665833953143

Epoch: 6| Step: 4
Training loss: 1.453411689287987
Validation loss: 2.4199461253712014

Epoch: 6| Step: 5
Training loss: 1.9064779301688297
Validation loss: 2.3915798873467518

Epoch: 6| Step: 6
Training loss: 2.2129059241389717
Validation loss: 2.4099206285899566

Epoch: 6| Step: 7
Training loss: 1.9198549400606402
Validation loss: 2.416562093679428

Epoch: 6| Step: 8
Training loss: 1.9606548576768954
Validation loss: 2.4255656078042644

Epoch: 6| Step: 9
Training loss: 1.7500494541264906
Validation loss: 2.361628076449937

Epoch: 6| Step: 10
Training loss: 1.572774295384564
Validation loss: 2.4207902080553705

Epoch: 6| Step: 11
Training loss: 2.338093556812412
Validation loss: 2.3955353461055577

Epoch: 6| Step: 12
Training loss: 2.1404534709732346
Validation loss: 2.4012662824195594

Epoch: 6| Step: 13
Training loss: 2.4183580026698173
Validation loss: 2.4439184969948915

Epoch: 473| Step: 0
Training loss: 1.6420472292966992
Validation loss: 2.3505418490966408

Epoch: 6| Step: 1
Training loss: 1.6400725388185335
Validation loss: 2.4495840397999245

Epoch: 6| Step: 2
Training loss: 1.849954993757311
Validation loss: 2.3814482862819206

Epoch: 6| Step: 3
Training loss: 2.0553309372302175
Validation loss: 2.395887583100126

Epoch: 6| Step: 4
Training loss: 2.1081642349441854
Validation loss: 2.4553128702620115

Epoch: 6| Step: 5
Training loss: 1.9634287537776585
Validation loss: 2.403037998087091

Epoch: 6| Step: 6
Training loss: 1.4324693974127076
Validation loss: 2.375694238201332

Epoch: 6| Step: 7
Training loss: 1.8393410159830048
Validation loss: 2.3806043356356645

Epoch: 6| Step: 8
Training loss: 1.8203525784382157
Validation loss: 2.4117838088135137

Epoch: 6| Step: 9
Training loss: 2.1110916499306085
Validation loss: 2.409004429080244

Epoch: 6| Step: 10
Training loss: 1.855139773467639
Validation loss: 2.393351141033043

Epoch: 6| Step: 11
Training loss: 1.4023576486052856
Validation loss: 2.3852512509864665

Epoch: 6| Step: 12
Training loss: 2.5283159747331463
Validation loss: 2.3674979469139767

Epoch: 6| Step: 13
Training loss: 1.7860078679303408
Validation loss: 2.368631051707202

Epoch: 474| Step: 0
Training loss: 1.521068119407199
Validation loss: 2.416383912034053

Epoch: 6| Step: 1
Training loss: 1.5204069071015929
Validation loss: 2.426434161050411

Epoch: 6| Step: 2
Training loss: 1.7910488379341063
Validation loss: 2.3779757768100716

Epoch: 6| Step: 3
Training loss: 1.8947863220284866
Validation loss: 2.4200231007597433

Epoch: 6| Step: 4
Training loss: 2.4285193085086467
Validation loss: 2.3761624242468997

Epoch: 6| Step: 5
Training loss: 1.88078192277088
Validation loss: 2.4035975189485224

Epoch: 6| Step: 6
Training loss: 2.132235494400833
Validation loss: 2.392294950120222

Epoch: 6| Step: 7
Training loss: 1.1641531275346706
Validation loss: 2.3844798483415417

Epoch: 6| Step: 8
Training loss: 1.853762964883689
Validation loss: 2.417824342362781

Epoch: 6| Step: 9
Training loss: 1.7651105823402125
Validation loss: 2.3814784260740476

Epoch: 6| Step: 10
Training loss: 1.4506914003124267
Validation loss: 2.3354787320821138

Epoch: 6| Step: 11
Training loss: 1.4044519585513717
Validation loss: 2.367505218227751

Epoch: 6| Step: 12
Training loss: 2.821969430553772
Validation loss: 2.4033633068418947

Epoch: 6| Step: 13
Training loss: 2.4692319568555305
Validation loss: 2.4324499466402343

Epoch: 475| Step: 0
Training loss: 1.8968660106163127
Validation loss: 2.416855626114543

Epoch: 6| Step: 1
Training loss: 1.967894716524725
Validation loss: 2.4174646800440573

Epoch: 6| Step: 2
Training loss: 2.0331603237194606
Validation loss: 2.392535521894122

Epoch: 6| Step: 3
Training loss: 2.119454834316658
Validation loss: 2.387964871438654

Epoch: 6| Step: 4
Training loss: 1.7003735356312297
Validation loss: 2.4178428616468635

Epoch: 6| Step: 5
Training loss: 1.9146464799907748
Validation loss: 2.4077151860706065

Epoch: 6| Step: 6
Training loss: 2.433975606139416
Validation loss: 2.4109508311974985

Epoch: 6| Step: 7
Training loss: 1.6879337601026476
Validation loss: 2.45008535221809

Epoch: 6| Step: 8
Training loss: 1.4725974802286044
Validation loss: 2.431629581346443

Epoch: 6| Step: 9
Training loss: 1.5908941974190465
Validation loss: 2.402838977986115

Epoch: 6| Step: 10
Training loss: 2.1219837997925506
Validation loss: 2.4274377076086107

Epoch: 6| Step: 11
Training loss: 1.962242269904397
Validation loss: 2.4285536714388773

Epoch: 6| Step: 12
Training loss: 1.8613113450597918
Validation loss: 2.3327923442755942

Epoch: 6| Step: 13
Training loss: 1.159950983146403
Validation loss: 2.3911681636252107

Epoch: 476| Step: 0
Training loss: 1.5167352601494082
Validation loss: 2.4497790106563553

Epoch: 6| Step: 1
Training loss: 1.3259656068734464
Validation loss: 2.4226151133696088

Epoch: 6| Step: 2
Training loss: 1.4506876202979713
Validation loss: 2.382369784537509

Epoch: 6| Step: 3
Training loss: 2.2274314924637717
Validation loss: 2.442298070900405

Epoch: 6| Step: 4
Training loss: 1.8575711516234057
Validation loss: 2.378483376086241

Epoch: 6| Step: 5
Training loss: 2.416656384501014
Validation loss: 2.3988142921073003

Epoch: 6| Step: 6
Training loss: 1.7702647324773146
Validation loss: 2.3576472045642887

Epoch: 6| Step: 7
Training loss: 1.987742892604169
Validation loss: 2.3929691487889566

Epoch: 6| Step: 8
Training loss: 1.6798593832386193
Validation loss: 2.3721614621155624

Epoch: 6| Step: 9
Training loss: 2.1927369781097044
Validation loss: 2.393548648856216

Epoch: 6| Step: 10
Training loss: 2.1133461200114687
Validation loss: 2.3433242104815637

Epoch: 6| Step: 11
Training loss: 1.8852648454381862
Validation loss: 2.3991223166909434

Epoch: 6| Step: 12
Training loss: 1.4670877181015354
Validation loss: 2.3953882739421783

Epoch: 6| Step: 13
Training loss: 2.188940718188348
Validation loss: 2.405714539856972

Epoch: 477| Step: 0
Training loss: 1.7337669475142403
Validation loss: 2.398679607154301

Epoch: 6| Step: 1
Training loss: 1.8114082073568645
Validation loss: 2.3638310752108516

Epoch: 6| Step: 2
Training loss: 2.0224035265043754
Validation loss: 2.3876174511094073

Epoch: 6| Step: 3
Training loss: 2.1765100433096856
Validation loss: 2.3864929426454333

Epoch: 6| Step: 4
Training loss: 1.9803527557293004
Validation loss: 2.386545537406477

Epoch: 6| Step: 5
Training loss: 1.3665396763177728
Validation loss: 2.3937635875620322

Epoch: 6| Step: 6
Training loss: 1.523878923677843
Validation loss: 2.4116744761818856

Epoch: 6| Step: 7
Training loss: 2.1675472915224545
Validation loss: 2.403454606199134

Epoch: 6| Step: 8
Training loss: 1.4424831430385727
Validation loss: 2.4127780837135218

Epoch: 6| Step: 9
Training loss: 1.374902114851888
Validation loss: 2.4710656112838643

Epoch: 6| Step: 10
Training loss: 1.7023613994045856
Validation loss: 2.4041421770399793

Epoch: 6| Step: 11
Training loss: 3.0385274146348102
Validation loss: 2.388770016274451

Epoch: 6| Step: 12
Training loss: 1.3957508214599335
Validation loss: 2.373557513546571

Epoch: 6| Step: 13
Training loss: 1.7040994638686935
Validation loss: 2.3612430497845027

Epoch: 478| Step: 0
Training loss: 2.0757244270308757
Validation loss: 2.4192618274926203

Epoch: 6| Step: 1
Training loss: 1.5883037785078349
Validation loss: 2.347927214163902

Epoch: 6| Step: 2
Training loss: 1.7219312876728132
Validation loss: 2.3778670211647013

Epoch: 6| Step: 3
Training loss: 1.5973408954411639
Validation loss: 2.410832151943352

Epoch: 6| Step: 4
Training loss: 1.751916108862018
Validation loss: 2.372344734219079

Epoch: 6| Step: 5
Training loss: 1.995637606405648
Validation loss: 2.3913421863376128

Epoch: 6| Step: 6
Training loss: 1.2658514597291617
Validation loss: 2.3867146812009405

Epoch: 6| Step: 7
Training loss: 2.0958727424005605
Validation loss: 2.391017960073153

Epoch: 6| Step: 8
Training loss: 1.6434541559327378
Validation loss: 2.3371855854166945

Epoch: 6| Step: 9
Training loss: 1.8289659310322954
Validation loss: 2.3882522512923794

Epoch: 6| Step: 10
Training loss: 2.457436629726906
Validation loss: 2.405379428854488

Epoch: 6| Step: 11
Training loss: 1.6650649798661052
Validation loss: 2.376097953728035

Epoch: 6| Step: 12
Training loss: 2.2704262208122095
Validation loss: 2.416703321145694

Epoch: 6| Step: 13
Training loss: 2.2776766447033583
Validation loss: 2.396436620856726

Epoch: 479| Step: 0
Training loss: 2.062340123309006
Validation loss: 2.3759889880469633

Epoch: 6| Step: 1
Training loss: 1.8649578748348306
Validation loss: 2.4137706341877956

Epoch: 6| Step: 2
Training loss: 1.917915296877976
Validation loss: 2.378490846630504

Epoch: 6| Step: 3
Training loss: 1.7530698417377375
Validation loss: 2.409165645417298

Epoch: 6| Step: 4
Training loss: 2.431952202992312
Validation loss: 2.369502302477227

Epoch: 6| Step: 5
Training loss: 1.6299865214252773
Validation loss: 2.4038710205331713

Epoch: 6| Step: 6
Training loss: 2.2342288096160297
Validation loss: 2.385753474728635

Epoch: 6| Step: 7
Training loss: 1.7246396503836785
Validation loss: 2.441717832834799

Epoch: 6| Step: 8
Training loss: 1.442742779959746
Validation loss: 2.4223402028388232

Epoch: 6| Step: 9
Training loss: 1.8931412779195433
Validation loss: 2.386781470712562

Epoch: 6| Step: 10
Training loss: 1.5580685144033144
Validation loss: 2.4281536856191486

Epoch: 6| Step: 11
Training loss: 1.8162682265478334
Validation loss: 2.414379572286744

Epoch: 6| Step: 12
Training loss: 2.158069893017131
Validation loss: 2.396820443544802

Epoch: 6| Step: 13
Training loss: 2.0879131205304153
Validation loss: 2.41912039384809

Epoch: 480| Step: 0
Training loss: 2.004659827049537
Validation loss: 2.3976651700801974

Epoch: 6| Step: 1
Training loss: 1.8079784162212027
Validation loss: 2.396050969137227

Epoch: 6| Step: 2
Training loss: 2.447648465229102
Validation loss: 2.412585726874758

Epoch: 6| Step: 3
Training loss: 1.8286342074695483
Validation loss: 2.3939046864541513

Epoch: 6| Step: 4
Training loss: 1.3661657820813489
Validation loss: 2.3663170485721547

Epoch: 6| Step: 5
Training loss: 2.2447366611854647
Validation loss: 2.4040157299384

Epoch: 6| Step: 6
Training loss: 1.9768858030773586
Validation loss: 2.400119158946832

Epoch: 6| Step: 7
Training loss: 2.1813922081528108
Validation loss: 2.3822089221751863

Epoch: 6| Step: 8
Training loss: 1.7503453322690483
Validation loss: 2.3939135599431656

Epoch: 6| Step: 9
Training loss: 1.45542913721863
Validation loss: 2.358632898460436

Epoch: 6| Step: 10
Training loss: 1.8567713612203038
Validation loss: 2.3699602087199136

Epoch: 6| Step: 11
Training loss: 2.0436332599301004
Validation loss: 2.389386688442711

Epoch: 6| Step: 12
Training loss: 1.4758760986220647
Validation loss: 2.385001965485388

Epoch: 6| Step: 13
Training loss: 1.511205462863594
Validation loss: 2.4209606491584474

Epoch: 481| Step: 0
Training loss: 2.7135551193596976
Validation loss: 2.426461617370199

Epoch: 6| Step: 1
Training loss: 1.8280355969600406
Validation loss: 2.4354512386937883

Epoch: 6| Step: 2
Training loss: 1.4912096584392025
Validation loss: 2.3829555894159955

Epoch: 6| Step: 3
Training loss: 1.746809912818506
Validation loss: 2.4201420432706993

Epoch: 6| Step: 4
Training loss: 1.3253176920077843
Validation loss: 2.398294201735696

Epoch: 6| Step: 5
Training loss: 2.2842273878423085
Validation loss: 2.3719400442820247

Epoch: 6| Step: 6
Training loss: 1.4310642971519512
Validation loss: 2.382483770247221

Epoch: 6| Step: 7
Training loss: 1.263567912853063
Validation loss: 2.4300261768808347

Epoch: 6| Step: 8
Training loss: 1.7818641273169495
Validation loss: 2.370095452696589

Epoch: 6| Step: 9
Training loss: 1.3694850254472724
Validation loss: 2.4202356268605176

Epoch: 6| Step: 10
Training loss: 1.9379430694957707
Validation loss: 2.3705823422858416

Epoch: 6| Step: 11
Training loss: 1.9558385081060883
Validation loss: 2.325384861529758

Epoch: 6| Step: 12
Training loss: 1.8095746603850222
Validation loss: 2.374408637776402

Epoch: 6| Step: 13
Training loss: 2.6115496134214675
Validation loss: 2.4032444033041194

Epoch: 482| Step: 0
Training loss: 2.288903240613582
Validation loss: 2.4086406153921573

Epoch: 6| Step: 1
Training loss: 1.6468967269825097
Validation loss: 2.4003427872977814

Epoch: 6| Step: 2
Training loss: 1.656186948331832
Validation loss: 2.384761460417791

Epoch: 6| Step: 3
Training loss: 1.6885713073024102
Validation loss: 2.3963868513402904

Epoch: 6| Step: 4
Training loss: 2.456007509176598
Validation loss: 2.447325397648618

Epoch: 6| Step: 5
Training loss: 1.7421079198341172
Validation loss: 2.4131946835109916

Epoch: 6| Step: 6
Training loss: 1.314631683782388
Validation loss: 2.3833486969419138

Epoch: 6| Step: 7
Training loss: 2.414997105093222
Validation loss: 2.4305933886590076

Epoch: 6| Step: 8
Training loss: 1.499584776310687
Validation loss: 2.3853521016341737

Epoch: 6| Step: 9
Training loss: 1.9639409988926215
Validation loss: 2.390614765254442

Epoch: 6| Step: 10
Training loss: 2.1240822549327545
Validation loss: 2.410849320218901

Epoch: 6| Step: 11
Training loss: 1.5811132711168054
Validation loss: 2.41791040398279

Epoch: 6| Step: 12
Training loss: 1.6178567579588345
Validation loss: 2.4044360731166665

Epoch: 6| Step: 13
Training loss: 1.3072722181517433
Validation loss: 2.4024275298157587

Epoch: 483| Step: 0
Training loss: 1.339735110135201
Validation loss: 2.417132283088031

Epoch: 6| Step: 1
Training loss: 1.7537906328253696
Validation loss: 2.3769852318606066

Epoch: 6| Step: 2
Training loss: 1.8066564610792433
Validation loss: 2.394151073651299

Epoch: 6| Step: 3
Training loss: 1.482307278874153
Validation loss: 2.3590147241421886

Epoch: 6| Step: 4
Training loss: 1.7432737513633316
Validation loss: 2.376101604820462

Epoch: 6| Step: 5
Training loss: 1.5202474989918313
Validation loss: 2.41779843039537

Epoch: 6| Step: 6
Training loss: 1.8678947609575587
Validation loss: 2.3937738141993923

Epoch: 6| Step: 7
Training loss: 2.3576799581699484
Validation loss: 2.3533138411436636

Epoch: 6| Step: 8
Training loss: 1.8402246943401177
Validation loss: 2.3546586571180934

Epoch: 6| Step: 9
Training loss: 2.0692721073951
Validation loss: 2.3924750983310794

Epoch: 6| Step: 10
Training loss: 2.0094976218675304
Validation loss: 2.3904294089391787

Epoch: 6| Step: 11
Training loss: 1.8026380254884478
Validation loss: 2.3662153590025348

Epoch: 6| Step: 12
Training loss: 2.1491271975343014
Validation loss: 2.3995215712456863

Epoch: 6| Step: 13
Training loss: 1.7466406595075086
Validation loss: 2.3529894748928233

Epoch: 484| Step: 0
Training loss: 1.3660924395201846
Validation loss: 2.3683034272157557

Epoch: 6| Step: 1
Training loss: 1.5657328920631162
Validation loss: 2.360419404251334

Epoch: 6| Step: 2
Training loss: 2.02877821549534
Validation loss: 2.364513948228551

Epoch: 6| Step: 3
Training loss: 1.5936971917472762
Validation loss: 2.387268175027583

Epoch: 6| Step: 4
Training loss: 1.8662759000050275
Validation loss: 2.3782934917852465

Epoch: 6| Step: 5
Training loss: 1.8101294570276847
Validation loss: 2.368223091779347

Epoch: 6| Step: 6
Training loss: 1.8051378092900732
Validation loss: 2.407199673813545

Epoch: 6| Step: 7
Training loss: 1.8602571077973593
Validation loss: 2.3750932801456193

Epoch: 6| Step: 8
Training loss: 2.0945636819322724
Validation loss: 2.4078283067899777

Epoch: 6| Step: 9
Training loss: 2.2837445976974324
Validation loss: 2.3565189542203426

Epoch: 6| Step: 10
Training loss: 1.5772143465330475
Validation loss: 2.3851378785254234

Epoch: 6| Step: 11
Training loss: 1.830750625795692
Validation loss: 2.3628857982706366

Epoch: 6| Step: 12
Training loss: 2.5554189772206444
Validation loss: 2.3910571313723015

Epoch: 6| Step: 13
Training loss: 1.734290937156381
Validation loss: 2.4007513406244465

Epoch: 485| Step: 0
Training loss: 1.7176022945852458
Validation loss: 2.422274062523372

Epoch: 6| Step: 1
Training loss: 1.7179091737694658
Validation loss: 2.357573112015524

Epoch: 6| Step: 2
Training loss: 1.4841730883953996
Validation loss: 2.3949844029796643

Epoch: 6| Step: 3
Training loss: 1.3113883169732685
Validation loss: 2.393029504169973

Epoch: 6| Step: 4
Training loss: 2.2375278236747693
Validation loss: 2.393856673090234

Epoch: 6| Step: 5
Training loss: 2.0483158078335006
Validation loss: 2.414720201897703

Epoch: 6| Step: 6
Training loss: 1.772810098184821
Validation loss: 2.4243731975125478

Epoch: 6| Step: 7
Training loss: 1.61326011662346
Validation loss: 2.3580863686211964

Epoch: 6| Step: 8
Training loss: 2.500731361222836
Validation loss: 2.4278237937986087

Epoch: 6| Step: 9
Training loss: 1.838283257700176
Validation loss: 2.404501258354223

Epoch: 6| Step: 10
Training loss: 1.8481694934121693
Validation loss: 2.4032109159203885

Epoch: 6| Step: 11
Training loss: 1.6645613088411952
Validation loss: 2.3766248646561063

Epoch: 6| Step: 12
Training loss: 2.383819867426932
Validation loss: 2.448786323208157

Epoch: 6| Step: 13
Training loss: 1.6177412181622375
Validation loss: 2.399604840630146

Epoch: 486| Step: 0
Training loss: 2.1173037113516604
Validation loss: 2.407531801730851

Epoch: 6| Step: 1
Training loss: 1.8098559331726745
Validation loss: 2.3951900058948974

Epoch: 6| Step: 2
Training loss: 1.7787929118509953
Validation loss: 2.3754052019982184

Epoch: 6| Step: 3
Training loss: 1.9917134637269456
Validation loss: 2.3697168042026955

Epoch: 6| Step: 4
Training loss: 2.017099949763627
Validation loss: 2.402185026671772

Epoch: 6| Step: 5
Training loss: 1.544147900410542
Validation loss: 2.4342096553050525

Epoch: 6| Step: 6
Training loss: 1.7186227924783053
Validation loss: 2.3490968352389103

Epoch: 6| Step: 7
Training loss: 1.21298546658306
Validation loss: 2.4007713285444137

Epoch: 6| Step: 8
Training loss: 2.183864078609924
Validation loss: 2.355859190702839

Epoch: 6| Step: 9
Training loss: 1.64242716309856
Validation loss: 2.4030190222506453

Epoch: 6| Step: 10
Training loss: 2.0860871107761385
Validation loss: 2.401055418151365

Epoch: 6| Step: 11
Training loss: 2.077295352849756
Validation loss: 2.3645964414287355

Epoch: 6| Step: 12
Training loss: 1.2528743122140427
Validation loss: 2.390312701496823

Epoch: 6| Step: 13
Training loss: 2.159383956515208
Validation loss: 2.3675278842259058

Epoch: 487| Step: 0
Training loss: 1.6758378737337711
Validation loss: 2.3429177669581

Epoch: 6| Step: 1
Training loss: 1.9348311347121963
Validation loss: 2.388455352684067

Epoch: 6| Step: 2
Training loss: 1.2313350473841902
Validation loss: 2.382745696068897

Epoch: 6| Step: 3
Training loss: 1.7553161527606866
Validation loss: 2.312486987200672

Epoch: 6| Step: 4
Training loss: 2.256503349303404
Validation loss: 2.3675890581649934

Epoch: 6| Step: 5
Training loss: 2.1773424009627593
Validation loss: 2.383687584314635

Epoch: 6| Step: 6
Training loss: 1.467955678868429
Validation loss: 2.36661551465164

Epoch: 6| Step: 7
Training loss: 1.8076364443024786
Validation loss: 2.365398954952014

Epoch: 6| Step: 8
Training loss: 1.9712919748659503
Validation loss: 2.3879607918800083

Epoch: 6| Step: 9
Training loss: 1.861750391708462
Validation loss: 2.350695491813218

Epoch: 6| Step: 10
Training loss: 2.4075199095476165
Validation loss: 2.3745629513497577

Epoch: 6| Step: 11
Training loss: 1.7295997108021652
Validation loss: 2.3910054089101984

Epoch: 6| Step: 12
Training loss: 1.7068729981976745
Validation loss: 2.370583927134437

Epoch: 6| Step: 13
Training loss: 1.1424493700825014
Validation loss: 2.3988131827844135

Epoch: 488| Step: 0
Training loss: 1.61260425319326
Validation loss: 2.376904154434595

Epoch: 6| Step: 1
Training loss: 1.8046581051236685
Validation loss: 2.398153184721183

Epoch: 6| Step: 2
Training loss: 2.2331921841251803
Validation loss: 2.3638133637201677

Epoch: 6| Step: 3
Training loss: 2.253463516518957
Validation loss: 2.3893857753805396

Epoch: 6| Step: 4
Training loss: 1.754642391559166
Validation loss: 2.361777617812288

Epoch: 6| Step: 5
Training loss: 2.5847683479210573
Validation loss: 2.4244607185173064

Epoch: 6| Step: 6
Training loss: 1.2598046585068337
Validation loss: 2.4328896796425985

Epoch: 6| Step: 7
Training loss: 1.8470788420417419
Validation loss: 2.4062380572671094

Epoch: 6| Step: 8
Training loss: 1.6196057211890043
Validation loss: 2.4203612001050923

Epoch: 6| Step: 9
Training loss: 1.946669629869862
Validation loss: 2.408441615985383

Epoch: 6| Step: 10
Training loss: 1.149264291033412
Validation loss: 2.390926036772041

Epoch: 6| Step: 11
Training loss: 1.6839437806809765
Validation loss: 2.4322392456563953

Epoch: 6| Step: 12
Training loss: 1.6362652207170072
Validation loss: 2.3345232921772996

Epoch: 6| Step: 13
Training loss: 1.717852548899568
Validation loss: 2.4350027697309207

Epoch: 489| Step: 0
Training loss: 1.8688240062131936
Validation loss: 2.3788205339182964

Epoch: 6| Step: 1
Training loss: 1.8488559175163843
Validation loss: 2.372365534205658

Epoch: 6| Step: 2
Training loss: 1.3982138001946225
Validation loss: 2.370867428740879

Epoch: 6| Step: 3
Training loss: 2.0850210855639073
Validation loss: 2.420583040982262

Epoch: 6| Step: 4
Training loss: 1.4352996405671814
Validation loss: 2.412145300209839

Epoch: 6| Step: 5
Training loss: 1.8808915718785
Validation loss: 2.37968285182782

Epoch: 6| Step: 6
Training loss: 1.6841405701852927
Validation loss: 2.3911886765806085

Epoch: 6| Step: 7
Training loss: 1.990093731613642
Validation loss: 2.412383543869138

Epoch: 6| Step: 8
Training loss: 1.8188727583209097
Validation loss: 2.368641039428122

Epoch: 6| Step: 9
Training loss: 2.420862983176245
Validation loss: 2.4341398090113335

Epoch: 6| Step: 10
Training loss: 1.8200515756530389
Validation loss: 2.424094349165327

Epoch: 6| Step: 11
Training loss: 2.0142003428756126
Validation loss: 2.404907366575454

Epoch: 6| Step: 12
Training loss: 1.6925745358529192
Validation loss: 2.393319419755042

Epoch: 6| Step: 13
Training loss: 2.2481495347432756
Validation loss: 2.3946416372693125

Epoch: 490| Step: 0
Training loss: 2.045493555178638
Validation loss: 2.4273417095583674

Epoch: 6| Step: 1
Training loss: 1.2908603499811206
Validation loss: 2.4207424149993

Epoch: 6| Step: 2
Training loss: 2.197200411358636
Validation loss: 2.429661032928842

Epoch: 6| Step: 3
Training loss: 2.372083278352018
Validation loss: 2.3412551355213362

Epoch: 6| Step: 4
Training loss: 1.7054050127841758
Validation loss: 2.406686229501315

Epoch: 6| Step: 5
Training loss: 1.4253761029411904
Validation loss: 2.4032001219214707

Epoch: 6| Step: 6
Training loss: 1.6296798369391159
Validation loss: 2.3416993301327045

Epoch: 6| Step: 7
Training loss: 1.9553404793026175
Validation loss: 2.370181532988231

Epoch: 6| Step: 8
Training loss: 1.9547070618892444
Validation loss: 2.382581576234791

Epoch: 6| Step: 9
Training loss: 1.7197226806458177
Validation loss: 2.3734911782028685

Epoch: 6| Step: 10
Training loss: 1.8305852913969836
Validation loss: 2.3928411202353774

Epoch: 6| Step: 11
Training loss: 1.9755564304171556
Validation loss: 2.392917240529559

Epoch: 6| Step: 12
Training loss: 2.0303104281668114
Validation loss: 2.3816433269796606

Epoch: 6| Step: 13
Training loss: 1.8060765060999577
Validation loss: 2.37344402104491

Epoch: 491| Step: 0
Training loss: 1.6824729357238883
Validation loss: 2.358273123976967

Epoch: 6| Step: 1
Training loss: 2.1030064270240576
Validation loss: 2.414417740228084

Epoch: 6| Step: 2
Training loss: 1.9954313907437171
Validation loss: 2.4025681465648336

Epoch: 6| Step: 3
Training loss: 1.3345921306258623
Validation loss: 2.403290811446727

Epoch: 6| Step: 4
Training loss: 1.8054571450956955
Validation loss: 2.3952544270434446

Epoch: 6| Step: 5
Training loss: 1.8201984811855092
Validation loss: 2.406532362655842

Epoch: 6| Step: 6
Training loss: 2.072351222018687
Validation loss: 2.3310392806712623

Epoch: 6| Step: 7
Training loss: 1.1827776018081548
Validation loss: 2.384943927657734

Epoch: 6| Step: 8
Training loss: 1.9474633517263267
Validation loss: 2.360769891623546

Epoch: 6| Step: 9
Training loss: 1.7757208824385917
Validation loss: 2.4048985208588114

Epoch: 6| Step: 10
Training loss: 2.575325480510455
Validation loss: 2.377407384497709

Epoch: 6| Step: 11
Training loss: 1.167099287792698
Validation loss: 2.376967542888059

Epoch: 6| Step: 12
Training loss: 1.9368337900972934
Validation loss: 2.3834363443836892

Epoch: 6| Step: 13
Training loss: 2.028424337012625
Validation loss: 2.4141368175535947

Epoch: 492| Step: 0
Training loss: 1.576554451686554
Validation loss: 2.3970372957957156

Epoch: 6| Step: 1
Training loss: 1.8727823494289237
Validation loss: 2.392837608251193

Epoch: 6| Step: 2
Training loss: 1.4950892808977077
Validation loss: 2.4151214508196985

Epoch: 6| Step: 3
Training loss: 1.8243175537014285
Validation loss: 2.4007239981874497

Epoch: 6| Step: 4
Training loss: 1.8631369097001726
Validation loss: 2.3177824452132847

Epoch: 6| Step: 5
Training loss: 1.5721156457484855
Validation loss: 2.3919474733136386

Epoch: 6| Step: 6
Training loss: 1.8473159444388176
Validation loss: 2.4000902797269776

Epoch: 6| Step: 7
Training loss: 1.325563900990492
Validation loss: 2.389421237557629

Epoch: 6| Step: 8
Training loss: 1.9429419601182594
Validation loss: 2.355637847414623

Epoch: 6| Step: 9
Training loss: 1.7719926367837069
Validation loss: 2.39564422531647

Epoch: 6| Step: 10
Training loss: 2.1074243639205648
Validation loss: 2.3945683071930097

Epoch: 6| Step: 11
Training loss: 2.4918074841295157
Validation loss: 2.3772351277844206

Epoch: 6| Step: 12
Training loss: 2.206504880538857
Validation loss: 2.3711439995945867

Epoch: 6| Step: 13
Training loss: 1.7915159502141829
Validation loss: 2.367792566133978

Epoch: 493| Step: 0
Training loss: 1.4992961026702016
Validation loss: 2.3241960267434627

Epoch: 6| Step: 1
Training loss: 1.5395854700441034
Validation loss: 2.3910471284597716

Epoch: 6| Step: 2
Training loss: 1.4497314533297818
Validation loss: 2.384631325922072

Epoch: 6| Step: 3
Training loss: 2.144346135389097
Validation loss: 2.4027094550227712

Epoch: 6| Step: 4
Training loss: 1.661176874920828
Validation loss: 2.408577352691793

Epoch: 6| Step: 5
Training loss: 1.1562048929024833
Validation loss: 2.363804086581217

Epoch: 6| Step: 6
Training loss: 2.5201439873870473
Validation loss: 2.377311483571853

Epoch: 6| Step: 7
Training loss: 2.166982065377441
Validation loss: 2.3931055370561736

Epoch: 6| Step: 8
Training loss: 1.9780348770800449
Validation loss: 2.405895558101854

Epoch: 6| Step: 9
Training loss: 2.012794103516158
Validation loss: 2.400270318160786

Epoch: 6| Step: 10
Training loss: 1.7797239358469443
Validation loss: 2.3871436714503322

Epoch: 6| Step: 11
Training loss: 1.7646160787751544
Validation loss: 2.3635217248506715

Epoch: 6| Step: 12
Training loss: 2.097240328622878
Validation loss: 2.357646982740297

Epoch: 6| Step: 13
Training loss: 1.9782904509042747
Validation loss: 2.3548317558797245

Epoch: 494| Step: 0
Training loss: 2.0931680354480817
Validation loss: 2.4065631097540816

Epoch: 6| Step: 1
Training loss: 1.5130754243212923
Validation loss: 2.331191988431636

Epoch: 6| Step: 2
Training loss: 1.4849933340263386
Validation loss: 2.455843263129846

Epoch: 6| Step: 3
Training loss: 2.1130214115399353
Validation loss: 2.345166941459904

Epoch: 6| Step: 4
Training loss: 1.8231805301614243
Validation loss: 2.3956062537426326

Epoch: 6| Step: 5
Training loss: 1.8180802045951043
Validation loss: 2.3753484466023838

Epoch: 6| Step: 6
Training loss: 1.92620355954836
Validation loss: 2.371288880180442

Epoch: 6| Step: 7
Training loss: 1.6530363466544211
Validation loss: 2.385220597821228

Epoch: 6| Step: 8
Training loss: 3.0023494103979136
Validation loss: 2.4328218239651873

Epoch: 6| Step: 9
Training loss: 1.5519608400212135
Validation loss: 2.4144104105775956

Epoch: 6| Step: 10
Training loss: 1.4649044583774302
Validation loss: 2.390845885672987

Epoch: 6| Step: 11
Training loss: 1.538969627715215
Validation loss: 2.41512116846187

Epoch: 6| Step: 12
Training loss: 1.6861602268400808
Validation loss: 2.3795078115833457

Epoch: 6| Step: 13
Training loss: 2.0409590863879585
Validation loss: 2.3951180466146025

Epoch: 495| Step: 0
Training loss: 2.083179493628271
Validation loss: 2.3895195958872635

Epoch: 6| Step: 1
Training loss: 1.5837466888272689
Validation loss: 2.3432158651114956

Epoch: 6| Step: 2
Training loss: 1.881765683995295
Validation loss: 2.395338189391646

Epoch: 6| Step: 3
Training loss: 1.6243880660268017
Validation loss: 2.4138844885675215

Epoch: 6| Step: 4
Training loss: 1.7667697132695486
Validation loss: 2.385616654852604

Epoch: 6| Step: 5
Training loss: 2.2980693384836672
Validation loss: 2.3437437723275307

Epoch: 6| Step: 6
Training loss: 1.9623187546345904
Validation loss: 2.389100592146093

Epoch: 6| Step: 7
Training loss: 2.053203438431911
Validation loss: 2.3961020659135337

Epoch: 6| Step: 8
Training loss: 1.6278500139846377
Validation loss: 2.376407931346245

Epoch: 6| Step: 9
Training loss: 1.357915072413341
Validation loss: 2.3793161035345203

Epoch: 6| Step: 10
Training loss: 2.105208966536492
Validation loss: 2.3641416755111355

Epoch: 6| Step: 11
Training loss: 1.5803176453144359
Validation loss: 2.3813813353510374

Epoch: 6| Step: 12
Training loss: 1.84751017277334
Validation loss: 2.3776185550884876

Epoch: 6| Step: 13
Training loss: 2.158326517435552
Validation loss: 2.3597459648823396

Epoch: 496| Step: 0
Training loss: 1.4218943667926855
Validation loss: 2.366577046982547

Epoch: 6| Step: 1
Training loss: 1.908977495887122
Validation loss: 2.3356214103609787

Epoch: 6| Step: 2
Training loss: 2.497074036190761
Validation loss: 2.3505509091870724

Epoch: 6| Step: 3
Training loss: 2.1465399112754096
Validation loss: 2.472955100889987

Epoch: 6| Step: 4
Training loss: 1.4352073631259346
Validation loss: 2.358853577605033

Epoch: 6| Step: 5
Training loss: 1.5831027699629239
Validation loss: 2.3698145837677504

Epoch: 6| Step: 6
Training loss: 1.719536618645072
Validation loss: 2.3761929051222612

Epoch: 6| Step: 7
Training loss: 1.759288524176068
Validation loss: 2.3695927892237645

Epoch: 6| Step: 8
Training loss: 1.4030769152993614
Validation loss: 2.3779096951713616

Epoch: 6| Step: 9
Training loss: 1.3723431841929357
Validation loss: 2.3841299714672806

Epoch: 6| Step: 10
Training loss: 2.0620286576345164
Validation loss: 2.418449423921973

Epoch: 6| Step: 11
Training loss: 1.9709645486369465
Validation loss: 2.402069940043987

Epoch: 6| Step: 12
Training loss: 2.1415191787619765
Validation loss: 2.407787177727897

Epoch: 6| Step: 13
Training loss: 2.272962697580201
Validation loss: 2.4176224956584575

Epoch: 497| Step: 0
Training loss: 2.2052152200794635
Validation loss: 2.408825245655632

Epoch: 6| Step: 1
Training loss: 1.3857910491737977
Validation loss: 2.404868604229202

Epoch: 6| Step: 2
Training loss: 1.9272605677028063
Validation loss: 2.395279527585786

Epoch: 6| Step: 3
Training loss: 1.3882200039742274
Validation loss: 2.4090049303141146

Epoch: 6| Step: 4
Training loss: 1.3269069246969725
Validation loss: 2.3857775920820035

Epoch: 6| Step: 5
Training loss: 2.2069736709510694
Validation loss: 2.3659296350558625

Epoch: 6| Step: 6
Training loss: 1.0756022474064726
Validation loss: 2.360657050595588

Epoch: 6| Step: 7
Training loss: 1.9583344222802996
Validation loss: 2.3990250701774114

Epoch: 6| Step: 8
Training loss: 1.9511867824286624
Validation loss: 2.3615334100777385

Epoch: 6| Step: 9
Training loss: 2.4411339691917755
Validation loss: 2.371507654647344

Epoch: 6| Step: 10
Training loss: 1.109862099750526
Validation loss: 2.402446442030002

Epoch: 6| Step: 11
Training loss: 2.4706245741589288
Validation loss: 2.387613218488165

Epoch: 6| Step: 12
Training loss: 2.0673764696776225
Validation loss: 2.332000740467174

Epoch: 6| Step: 13
Training loss: 1.619005517418869
Validation loss: 2.4300315340876506

Epoch: 498| Step: 0
Training loss: 1.5269867072385575
Validation loss: 2.3980415468737197

Epoch: 6| Step: 1
Training loss: 1.390129686933392
Validation loss: 2.3930587878406855

Epoch: 6| Step: 2
Training loss: 1.5004607923368773
Validation loss: 2.3868745482067553

Epoch: 6| Step: 3
Training loss: 1.9914614083518138
Validation loss: 2.3565994547566267

Epoch: 6| Step: 4
Training loss: 2.1922184871949613
Validation loss: 2.407959975965937

Epoch: 6| Step: 5
Training loss: 1.8150221935207906
Validation loss: 2.330980719715751

Epoch: 6| Step: 6
Training loss: 1.9688788477802102
Validation loss: 2.425160838388827

Epoch: 6| Step: 7
Training loss: 2.3194979384212293
Validation loss: 2.378486065581885

Epoch: 6| Step: 8
Training loss: 1.9214172438410688
Validation loss: 2.3906153121667226

Epoch: 6| Step: 9
Training loss: 1.9002777097428438
Validation loss: 2.373140001818104

Epoch: 6| Step: 10
Training loss: 1.5367528169828617
Validation loss: 2.394506002431322

Epoch: 6| Step: 11
Training loss: 1.7929876322364935
Validation loss: 2.3875553617118594

Epoch: 6| Step: 12
Training loss: 2.0245485532538905
Validation loss: 2.3913164441119195

Epoch: 6| Step: 13
Training loss: 1.6443496567597518
Validation loss: 2.391119171118371

Epoch: 499| Step: 0
Training loss: 1.4343723604597685
Validation loss: 2.363604083478297

Epoch: 6| Step: 1
Training loss: 1.8626567185795484
Validation loss: 2.349364912878511

Epoch: 6| Step: 2
Training loss: 1.5660092428624004
Validation loss: 2.3213142654118104

Epoch: 6| Step: 3
Training loss: 1.6813136546056997
Validation loss: 2.3596788675341367

Epoch: 6| Step: 4
Training loss: 1.7418571124682838
Validation loss: 2.3983341039900226

Epoch: 6| Step: 5
Training loss: 1.711107916161553
Validation loss: 2.3944537538291115

Epoch: 6| Step: 6
Training loss: 1.6168638633459511
Validation loss: 2.384048362514749

Epoch: 6| Step: 7
Training loss: 2.344706835935865
Validation loss: 2.353873712067909

Epoch: 6| Step: 8
Training loss: 1.9625246228659718
Validation loss: 2.383452968906332

Epoch: 6| Step: 9
Training loss: 1.9142701951050571
Validation loss: 2.384953298852961

Epoch: 6| Step: 10
Training loss: 1.778867232104624
Validation loss: 2.370206202495823

Epoch: 6| Step: 11
Training loss: 1.6854008935191058
Validation loss: 2.3765845536821444

Epoch: 6| Step: 12
Training loss: 1.8012727741016825
Validation loss: 2.379379677159399

Epoch: 6| Step: 13
Training loss: 2.128040494655426
Validation loss: 2.36879176307214

Epoch: 500| Step: 0
Training loss: 1.584374018862569
Validation loss: 2.400717131828438

Epoch: 6| Step: 1
Training loss: 1.5858243704599517
Validation loss: 2.406892567904805

Epoch: 6| Step: 2
Training loss: 2.1857862026162036
Validation loss: 2.386940161480813

Epoch: 6| Step: 3
Training loss: 1.6780740485101737
Validation loss: 2.366936739853647

Epoch: 6| Step: 4
Training loss: 1.2276582136571794
Validation loss: 2.39416858533888

Epoch: 6| Step: 5
Training loss: 1.4811077097864596
Validation loss: 2.363960090376809

Epoch: 6| Step: 6
Training loss: 1.943178837503665
Validation loss: 2.3798893123941918

Epoch: 6| Step: 7
Training loss: 1.9102572236939843
Validation loss: 2.381507586966389

Epoch: 6| Step: 8
Training loss: 2.073381100356829
Validation loss: 2.3541565302366423

Epoch: 6| Step: 9
Training loss: 2.5978219115702714
Validation loss: 2.3487207774492926

Epoch: 6| Step: 10
Training loss: 1.7957026098456814
Validation loss: 2.3894741337191023

Epoch: 6| Step: 11
Training loss: 1.509267707628572
Validation loss: 2.383069125402952

Epoch: 6| Step: 12
Training loss: 1.6322061243223511
Validation loss: 2.37689061843167

Epoch: 6| Step: 13
Training loss: 2.191305610399363
Validation loss: 2.4021945205707738

Epoch: 501| Step: 0
Training loss: 2.1341331780589265
Validation loss: 2.39446450213884

Epoch: 6| Step: 1
Training loss: 2.094480131009974
Validation loss: 2.3721906024513366

Epoch: 6| Step: 2
Training loss: 1.9124730575758104
Validation loss: 2.3598581335685656

Epoch: 6| Step: 3
Training loss: 2.326565521012824
Validation loss: 2.4024833077746797

Epoch: 6| Step: 4
Training loss: 1.820183286869672
Validation loss: 2.3724985955571745

Epoch: 6| Step: 5
Training loss: 1.488056956934135
Validation loss: 2.4024284549949684

Epoch: 6| Step: 6
Training loss: 1.6243340521506264
Validation loss: 2.4367350542040995

Epoch: 6| Step: 7
Training loss: 2.112907559959402
Validation loss: 2.3506735916106654

Epoch: 6| Step: 8
Training loss: 1.8081439058203508
Validation loss: 2.3560222362566012

Epoch: 6| Step: 9
Training loss: 1.6305818058841888
Validation loss: 2.3870248180908535

Epoch: 6| Step: 10
Training loss: 1.2488869479885685
Validation loss: 2.404937403179812

Epoch: 6| Step: 11
Training loss: 1.330338462413158
Validation loss: 2.40146090598408

Epoch: 6| Step: 12
Training loss: 1.9473090898719194
Validation loss: 2.3521241807178734

Epoch: 6| Step: 13
Training loss: 1.9535965007050813
Validation loss: 2.4273298816886806

Epoch: 502| Step: 0
Training loss: 2.246923462579866
Validation loss: 2.3624081107783734

Epoch: 6| Step: 1
Training loss: 1.323632934984593
Validation loss: 2.406804077851364

Epoch: 6| Step: 2
Training loss: 1.6080186183477867
Validation loss: 2.3512603289806733

Epoch: 6| Step: 3
Training loss: 1.5854699709432587
Validation loss: 2.3893847947234828

Epoch: 6| Step: 4
Training loss: 1.5981873466614251
Validation loss: 2.365404065105848

Epoch: 6| Step: 5
Training loss: 1.8609256209115241
Validation loss: 2.3546403758029295

Epoch: 6| Step: 6
Training loss: 1.830561131398275
Validation loss: 2.3799648462399823

Epoch: 6| Step: 7
Training loss: 1.8804436815506183
Validation loss: 2.399305199430847

Epoch: 6| Step: 8
Training loss: 2.071648393439398
Validation loss: 2.4257666688599433

Epoch: 6| Step: 9
Training loss: 1.5815733447077127
Validation loss: 2.354016892655143

Epoch: 6| Step: 10
Training loss: 1.4998536038484873
Validation loss: 2.431961706129399

Epoch: 6| Step: 11
Training loss: 2.036904782840953
Validation loss: 2.3692348132036942

Epoch: 6| Step: 12
Training loss: 1.9963074213319671
Validation loss: 2.374829554418984

Epoch: 6| Step: 13
Training loss: 1.58568311633648
Validation loss: 2.3846667964491632

Epoch: 503| Step: 0
Training loss: 1.3447821002425908
Validation loss: 2.37861336031652

Epoch: 6| Step: 1
Training loss: 1.5782821123834392
Validation loss: 2.386458339320458

Epoch: 6| Step: 2
Training loss: 1.5719597370825198
Validation loss: 2.382322365151452

Epoch: 6| Step: 3
Training loss: 1.7664315736044476
Validation loss: 2.406108605404695

Epoch: 6| Step: 4
Training loss: 1.9648809410503862
Validation loss: 2.35963400380957

Epoch: 6| Step: 5
Training loss: 1.8488726815456813
Validation loss: 2.330401383325373

Epoch: 6| Step: 6
Training loss: 1.9650940024723642
Validation loss: 2.3899790350710632

Epoch: 6| Step: 7
Training loss: 1.4559983588618157
Validation loss: 2.3529388779017317

Epoch: 6| Step: 8
Training loss: 1.4204280323675318
Validation loss: 2.354797462445454

Epoch: 6| Step: 9
Training loss: 1.671404478227843
Validation loss: 2.4016005225334105

Epoch: 6| Step: 10
Training loss: 2.360893316758043
Validation loss: 2.344485907197782

Epoch: 6| Step: 11
Training loss: 1.6112735993378708
Validation loss: 2.4186443267935003

Epoch: 6| Step: 12
Training loss: 2.188034428299479
Validation loss: 2.3915239713940153

Epoch: 6| Step: 13
Training loss: 2.5076358530927707
Validation loss: 2.4325550468401627

Epoch: 504| Step: 0
Training loss: 1.9853303066603778
Validation loss: 2.3475634139680595

Epoch: 6| Step: 1
Training loss: 1.7713578588022325
Validation loss: 2.3668682638921372

Epoch: 6| Step: 2
Training loss: 2.295396913101954
Validation loss: 2.3844511388063965

Epoch: 6| Step: 3
Training loss: 1.6547863809148242
Validation loss: 2.4115168453788054

Epoch: 6| Step: 4
Training loss: 1.9120003939033645
Validation loss: 2.3505439082607444

Epoch: 6| Step: 5
Training loss: 1.7401075734395628
Validation loss: 2.3874477264569465

Epoch: 6| Step: 6
Training loss: 1.6195682563730964
Validation loss: 2.35443955615848

Epoch: 6| Step: 7
Training loss: 2.1492328073422504
Validation loss: 2.370697255931994

Epoch: 6| Step: 8
Training loss: 1.2667128044225098
Validation loss: 2.3943039394882684

Epoch: 6| Step: 9
Training loss: 2.231158736042759
Validation loss: 2.350757233559617

Epoch: 6| Step: 10
Training loss: 1.9674213103829155
Validation loss: 2.3832875273685885

Epoch: 6| Step: 11
Training loss: 2.0850715125464787
Validation loss: 2.338399154874202

Epoch: 6| Step: 12
Training loss: 1.0957273320806666
Validation loss: 2.3419595498510386

Epoch: 6| Step: 13
Training loss: 1.1548484349404151
Validation loss: 2.415753140628833

Epoch: 505| Step: 0
Training loss: 1.363634298785409
Validation loss: 2.3575954157074346

Epoch: 6| Step: 1
Training loss: 1.8452850675683745
Validation loss: 2.407038154326815

Epoch: 6| Step: 2
Training loss: 2.2653890552654103
Validation loss: 2.3850016182923888

Epoch: 6| Step: 3
Training loss: 2.0795221436393097
Validation loss: 2.342680213182501

Epoch: 6| Step: 4
Training loss: 2.0598187213133228
Validation loss: 2.416371571137446

Epoch: 6| Step: 5
Training loss: 1.8193023891498916
Validation loss: 2.401199730318105

Epoch: 6| Step: 6
Training loss: 1.8312252524724992
Validation loss: 2.4402583028667753

Epoch: 6| Step: 7
Training loss: 1.6812973469587051
Validation loss: 2.400954383582445

Epoch: 6| Step: 8
Training loss: 1.9626014002948253
Validation loss: 2.380972613096341

Epoch: 6| Step: 9
Training loss: 1.8097592382320393
Validation loss: 2.4311836531189854

Epoch: 6| Step: 10
Training loss: 1.673125895349251
Validation loss: 2.4051117417533208

Epoch: 6| Step: 11
Training loss: 2.326137026790818
Validation loss: 2.3950497148723007

Epoch: 6| Step: 12
Training loss: 1.2841372174684678
Validation loss: 2.355299411325069

Epoch: 6| Step: 13
Training loss: 1.5483309896812043
Validation loss: 2.4119697024525877

Epoch: 506| Step: 0
Training loss: 1.552861276875013
Validation loss: 2.3674579656591175

Epoch: 6| Step: 1
Training loss: 1.656873405740691
Validation loss: 2.377070098486655

Epoch: 6| Step: 2
Training loss: 2.2814031053140886
Validation loss: 2.398817322971454

Epoch: 6| Step: 3
Training loss: 1.7915828892246104
Validation loss: 2.3444958873380792

Epoch: 6| Step: 4
Training loss: 1.4174132717182444
Validation loss: 2.342668288352578

Epoch: 6| Step: 5
Training loss: 1.3076491861224382
Validation loss: 2.3511857821996553

Epoch: 6| Step: 6
Training loss: 1.9277891636321967
Validation loss: 2.355391325317818

Epoch: 6| Step: 7
Training loss: 1.7844296234909396
Validation loss: 2.3674282613651174

Epoch: 6| Step: 8
Training loss: 1.2766292335128548
Validation loss: 2.407443682324814

Epoch: 6| Step: 9
Training loss: 1.717445363892882
Validation loss: 2.3869503271344543

Epoch: 6| Step: 10
Training loss: 2.338664118924524
Validation loss: 2.3994828917726236

Epoch: 6| Step: 11
Training loss: 2.0117637851451846
Validation loss: 2.374808959531226

Epoch: 6| Step: 12
Training loss: 1.9948006041270967
Validation loss: 2.3891172191033463

Epoch: 6| Step: 13
Training loss: 1.624610267266526
Validation loss: 2.3661540877907883

Epoch: 507| Step: 0
Training loss: 2.0960675977624503
Validation loss: 2.377663625044173

Epoch: 6| Step: 1
Training loss: 2.0885353627351546
Validation loss: 2.4042788847480154

Epoch: 6| Step: 2
Training loss: 2.240813894569385
Validation loss: 2.351361251765001

Epoch: 6| Step: 3
Training loss: 1.9219569987350322
Validation loss: 2.361704846728879

Epoch: 6| Step: 4
Training loss: 1.584566924078483
Validation loss: 2.3914931520737546

Epoch: 6| Step: 5
Training loss: 1.0667751358929338
Validation loss: 2.4108719088894657

Epoch: 6| Step: 6
Training loss: 1.6843604092505655
Validation loss: 2.357189989704129

Epoch: 6| Step: 7
Training loss: 1.557330697717679
Validation loss: 2.320447168536783

Epoch: 6| Step: 8
Training loss: 1.6999855153083807
Validation loss: 2.3656758660280315

Epoch: 6| Step: 9
Training loss: 2.1605723085563437
Validation loss: 2.3599494789386206

Epoch: 6| Step: 10
Training loss: 2.072100863796474
Validation loss: 2.3792522006514383

Epoch: 6| Step: 11
Training loss: 1.5697254203212219
Validation loss: 2.35951196872886

Epoch: 6| Step: 12
Training loss: 1.506742582068405
Validation loss: 2.334369103951302

Epoch: 6| Step: 13
Training loss: 1.5641689542504018
Validation loss: 2.3797643268958195

Epoch: 508| Step: 0
Training loss: 1.673361714389647
Validation loss: 2.3793651004187755

Epoch: 6| Step: 1
Training loss: 1.6157376336803921
Validation loss: 2.385520583154843

Epoch: 6| Step: 2
Training loss: 1.7133251235013163
Validation loss: 2.43742356707708

Epoch: 6| Step: 3
Training loss: 1.6592268193349842
Validation loss: 2.4076607218773

Epoch: 6| Step: 4
Training loss: 1.7006720981433907
Validation loss: 2.381256268829224

Epoch: 6| Step: 5
Training loss: 1.4028381071347495
Validation loss: 2.3891988145272705

Epoch: 6| Step: 6
Training loss: 1.8831084086145893
Validation loss: 2.381319395559261

Epoch: 6| Step: 7
Training loss: 1.863439909060052
Validation loss: 2.406772513112199

Epoch: 6| Step: 8
Training loss: 2.0974298280383357
Validation loss: 2.4029580397447052

Epoch: 6| Step: 9
Training loss: 2.0342293823442517
Validation loss: 2.376833867765505

Epoch: 6| Step: 10
Training loss: 2.3962875820151917
Validation loss: 2.3494599200646853

Epoch: 6| Step: 11
Training loss: 1.6982638778310417
Validation loss: 2.362800579500715

Epoch: 6| Step: 12
Training loss: 1.4564202794403098
Validation loss: 2.383327724432403

Epoch: 6| Step: 13
Training loss: 1.9114146699691097
Validation loss: 2.4239218359749533

Epoch: 509| Step: 0
Training loss: 1.34713336918123
Validation loss: 2.3579851150485425

Epoch: 6| Step: 1
Training loss: 1.6476034793569747
Validation loss: 2.3409599964025163

Epoch: 6| Step: 2
Training loss: 1.9941872526839324
Validation loss: 2.3879851327854733

Epoch: 6| Step: 3
Training loss: 2.1652648009712796
Validation loss: 2.401811821399609

Epoch: 6| Step: 4
Training loss: 1.9460514610715705
Validation loss: 2.3363572784478586

Epoch: 6| Step: 5
Training loss: 2.0481107053935954
Validation loss: 2.3463083120942865

Epoch: 6| Step: 6
Training loss: 1.8523497376652882
Validation loss: 2.360382829705686

Epoch: 6| Step: 7
Training loss: 1.5747418540238827
Validation loss: 2.367032827715225

Epoch: 6| Step: 8
Training loss: 1.9474561286264718
Validation loss: 2.4084116284062236

Epoch: 6| Step: 9
Training loss: 2.065735331256468
Validation loss: 2.3582070283524317

Epoch: 6| Step: 10
Training loss: 1.2359911804501822
Validation loss: 2.4141134767837866

Epoch: 6| Step: 11
Training loss: 1.5625938387349079
Validation loss: 2.423809996253838

Epoch: 6| Step: 12
Training loss: 1.9386253780251723
Validation loss: 2.364597175416324

Epoch: 6| Step: 13
Training loss: 1.7410132723307317
Validation loss: 2.362159667205008

Epoch: 510| Step: 0
Training loss: 1.618612426449734
Validation loss: 2.330295410235281

Epoch: 6| Step: 1
Training loss: 2.0354500410245486
Validation loss: 2.3690032054804795

Epoch: 6| Step: 2
Training loss: 1.485945021874035
Validation loss: 2.365692743233151

Epoch: 6| Step: 3
Training loss: 1.4352530457690742
Validation loss: 2.426065587962498

Epoch: 6| Step: 4
Training loss: 1.4119455920535442
Validation loss: 2.4066594370398002

Epoch: 6| Step: 5
Training loss: 1.5906049326172291
Validation loss: 2.4041478169224897

Epoch: 6| Step: 6
Training loss: 1.9481215207775917
Validation loss: 2.4117427546481345

Epoch: 6| Step: 7
Training loss: 2.3930839906866437
Validation loss: 2.3784821505741425

Epoch: 6| Step: 8
Training loss: 2.0566340171946913
Validation loss: 2.3964297186782764

Epoch: 6| Step: 9
Training loss: 1.966045884040313
Validation loss: 2.3749808530354124

Epoch: 6| Step: 10
Training loss: 1.073806683661751
Validation loss: 2.4247429957955977

Epoch: 6| Step: 11
Training loss: 2.4895362264307748
Validation loss: 2.374969147598914

Epoch: 6| Step: 12
Training loss: 1.3712519366964402
Validation loss: 2.397779650207389

Epoch: 6| Step: 13
Training loss: 1.7709773809150609
Validation loss: 2.384921332585036

Epoch: 511| Step: 0
Training loss: 1.6594152614500903
Validation loss: 2.3583885444547925

Epoch: 6| Step: 1
Training loss: 1.9322324951105476
Validation loss: 2.370210681441929

Epoch: 6| Step: 2
Training loss: 1.3280649059388219
Validation loss: 2.3816608466733276

Epoch: 6| Step: 3
Training loss: 2.3100292306346946
Validation loss: 2.394294815824762

Epoch: 6| Step: 4
Training loss: 2.559475858794712
Validation loss: 2.3919150346106677

Epoch: 6| Step: 5
Training loss: 1.5423063377346615
Validation loss: 2.3747059111622177

Epoch: 6| Step: 6
Training loss: 1.469406143695682
Validation loss: 2.405276101036836

Epoch: 6| Step: 7
Training loss: 1.8259220380779662
Validation loss: 2.40753491745611

Epoch: 6| Step: 8
Training loss: 2.0456351682117124
Validation loss: 2.3650839422361236

Epoch: 6| Step: 9
Training loss: 2.012606704442062
Validation loss: 2.359734386488941

Epoch: 6| Step: 10
Training loss: 1.5268565618000565
Validation loss: 2.371921666485114

Epoch: 6| Step: 11
Training loss: 1.5809553090389579
Validation loss: 2.3936554549860185

Epoch: 6| Step: 12
Training loss: 1.2184065310350132
Validation loss: 2.3383662622138663

Epoch: 6| Step: 13
Training loss: 1.1717612147721372
Validation loss: 2.34542711638955

Epoch: 512| Step: 0
Training loss: 1.8626266385235002
Validation loss: 2.3713016211096374

Epoch: 6| Step: 1
Training loss: 1.7671844212566779
Validation loss: 2.3962604914123737

Epoch: 6| Step: 2
Training loss: 1.4627965023385954
Validation loss: 2.3710680041844934

Epoch: 6| Step: 3
Training loss: 2.4298630433282193
Validation loss: 2.3387563830553875

Epoch: 6| Step: 4
Training loss: 1.4408838002397892
Validation loss: 2.360918378674817

Epoch: 6| Step: 5
Training loss: 1.4415712339681206
Validation loss: 2.3571237897499033

Epoch: 6| Step: 6
Training loss: 1.4317876680433743
Validation loss: 2.3775128702395225

Epoch: 6| Step: 7
Training loss: 1.9100704992974413
Validation loss: 2.3885298723718935

Epoch: 6| Step: 8
Training loss: 2.4188999730813485
Validation loss: 2.387409642236381

Epoch: 6| Step: 9
Training loss: 1.7996191549066456
Validation loss: 2.4184071430029617

Epoch: 6| Step: 10
Training loss: 1.957640897471589
Validation loss: 2.359075971588969

Epoch: 6| Step: 11
Training loss: 1.7917741772827622
Validation loss: 2.3419801916927923

Epoch: 6| Step: 12
Training loss: 1.3383735175095592
Validation loss: 2.353753613041107

Epoch: 6| Step: 13
Training loss: 1.6131183828390347
Validation loss: 2.3374067457144414

Epoch: 513| Step: 0
Training loss: 1.543837908508271
Validation loss: 2.333050449937573

Epoch: 6| Step: 1
Training loss: 1.5568953895535376
Validation loss: 2.39363374648676

Epoch: 6| Step: 2
Training loss: 1.6807139254614725
Validation loss: 2.4206865404220403

Epoch: 6| Step: 3
Training loss: 1.3714015865083653
Validation loss: 2.3755750839605536

Epoch: 6| Step: 4
Training loss: 2.2149319101377882
Validation loss: 2.368472467724475

Epoch: 6| Step: 5
Training loss: 2.1126674247171366
Validation loss: 2.3535422599564213

Epoch: 6| Step: 6
Training loss: 1.6315555388677125
Validation loss: 2.4025242907466597

Epoch: 6| Step: 7
Training loss: 1.8787061303169732
Validation loss: 2.374778799324685

Epoch: 6| Step: 8
Training loss: 1.714031192072852
Validation loss: 2.346534565735221

Epoch: 6| Step: 9
Training loss: 1.6786070431464606
Validation loss: 2.409211481937543

Epoch: 6| Step: 10
Training loss: 1.9511130995198407
Validation loss: 2.4044960009954464

Epoch: 6| Step: 11
Training loss: 2.344010809056484
Validation loss: 2.33340524381

Epoch: 6| Step: 12
Training loss: 1.2873033947504793
Validation loss: 2.331429251395409

Epoch: 6| Step: 13
Training loss: 1.3865834344741237
Validation loss: 2.3949975113144277

Epoch: 514| Step: 0
Training loss: 1.5608495769616126
Validation loss: 2.358258988583255

Epoch: 6| Step: 1
Training loss: 2.08055534798531
Validation loss: 2.3389541836210985

Epoch: 6| Step: 2
Training loss: 2.08776980729426
Validation loss: 2.4243568245119476

Epoch: 6| Step: 3
Training loss: 1.2190344062937795
Validation loss: 2.3579112337156882

Epoch: 6| Step: 4
Training loss: 1.7577282694663035
Validation loss: 2.3980219210638856

Epoch: 6| Step: 5
Training loss: 1.4798052667401627
Validation loss: 2.392560832045046

Epoch: 6| Step: 6
Training loss: 2.295835921695125
Validation loss: 2.349386672512739

Epoch: 6| Step: 7
Training loss: 1.788316062898366
Validation loss: 2.356262590240808

Epoch: 6| Step: 8
Training loss: 1.8745726416252475
Validation loss: 2.3516095388772627

Epoch: 6| Step: 9
Training loss: 2.1409980838629865
Validation loss: 2.381134848802985

Epoch: 6| Step: 10
Training loss: 1.6782569648669752
Validation loss: 2.401594028026697

Epoch: 6| Step: 11
Training loss: 1.6578121375857433
Validation loss: 2.4446702391724813

Epoch: 6| Step: 12
Training loss: 1.7391881055962115
Validation loss: 2.3461205901131983

Epoch: 6| Step: 13
Training loss: 1.8524996804096805
Validation loss: 2.353395948063628

Epoch: 515| Step: 0
Training loss: 2.4284914268010884
Validation loss: 2.3690979369596628

Epoch: 6| Step: 1
Training loss: 1.9940246488526499
Validation loss: 2.3917914942784404

Epoch: 6| Step: 2
Training loss: 1.795652288647118
Validation loss: 2.3188575206474544

Epoch: 6| Step: 3
Training loss: 1.319987691619593
Validation loss: 2.3568186671075058

Epoch: 6| Step: 4
Training loss: 1.4030738566366077
Validation loss: 2.333676535626056

Epoch: 6| Step: 5
Training loss: 1.6930193180124467
Validation loss: 2.3549621436670045

Epoch: 6| Step: 6
Training loss: 1.3768555085771814
Validation loss: 2.3964838679381546

Epoch: 6| Step: 7
Training loss: 1.6888566391916453
Validation loss: 2.3835934531090532

Epoch: 6| Step: 8
Training loss: 2.0842436009844505
Validation loss: 2.413236939961104

Epoch: 6| Step: 9
Training loss: 1.7132502562176044
Validation loss: 2.3719283232987607

Epoch: 6| Step: 10
Training loss: 1.8064124380810318
Validation loss: 2.3977835879673526

Epoch: 6| Step: 11
Training loss: 2.243958202679978
Validation loss: 2.4315518431491117

Epoch: 6| Step: 12
Training loss: 1.619962807923057
Validation loss: 2.3733638228854215

Epoch: 6| Step: 13
Training loss: 1.8500182717941707
Validation loss: 2.3942929056436566

Epoch: 516| Step: 0
Training loss: 1.5271162951538957
Validation loss: 2.3646041271456766

Epoch: 6| Step: 1
Training loss: 1.8026149458086669
Validation loss: 2.322766064658711

Epoch: 6| Step: 2
Training loss: 1.8435284109634489
Validation loss: 2.3726460871118085

Epoch: 6| Step: 3
Training loss: 1.9087867742267313
Validation loss: 2.378167285138733

Epoch: 6| Step: 4
Training loss: 2.088645748547907
Validation loss: 2.3971163174594903

Epoch: 6| Step: 5
Training loss: 1.819329581707732
Validation loss: 2.4049139821865673

Epoch: 6| Step: 6
Training loss: 2.3095585441692776
Validation loss: 2.311453071501037

Epoch: 6| Step: 7
Training loss: 1.817925783575004
Validation loss: 2.3998709478171003

Epoch: 6| Step: 8
Training loss: 1.6041047550821297
Validation loss: 2.420659109678235

Epoch: 6| Step: 9
Training loss: 1.4927001392097892
Validation loss: 2.3835104901937187

Epoch: 6| Step: 10
Training loss: 1.465403864268345
Validation loss: 2.373267523617174

Epoch: 6| Step: 11
Training loss: 1.2201551992944568
Validation loss: 2.398817558087695

Epoch: 6| Step: 12
Training loss: 1.8330677736013927
Validation loss: 2.390583202841972

Epoch: 6| Step: 13
Training loss: 2.1865867888391106
Validation loss: 2.381434256152853

Epoch: 517| Step: 0
Training loss: 1.8286025246888236
Validation loss: 2.3609545681344075

Epoch: 6| Step: 1
Training loss: 2.3177901921478776
Validation loss: 2.363756553416226

Epoch: 6| Step: 2
Training loss: 1.7021309987945978
Validation loss: 2.3564861246425415

Epoch: 6| Step: 3
Training loss: 1.1508283575688403
Validation loss: 2.374584021243333

Epoch: 6| Step: 4
Training loss: 1.4285882778536472
Validation loss: 2.389478780397064

Epoch: 6| Step: 5
Training loss: 1.6388352577500516
Validation loss: 2.3473502057865407

Epoch: 6| Step: 6
Training loss: 1.5349443206877877
Validation loss: 2.36777589445503

Epoch: 6| Step: 7
Training loss: 1.9155909449675765
Validation loss: 2.411608501521267

Epoch: 6| Step: 8
Training loss: 1.4254969483245543
Validation loss: 2.3992472436745147

Epoch: 6| Step: 9
Training loss: 2.0744089732616344
Validation loss: 2.3516797433164878

Epoch: 6| Step: 10
Training loss: 1.4726959142225602
Validation loss: 2.3956285350809616

Epoch: 6| Step: 11
Training loss: 1.6680449350008184
Validation loss: 2.387034900687094

Epoch: 6| Step: 12
Training loss: 1.7291768851227236
Validation loss: 2.36799565063063

Epoch: 6| Step: 13
Training loss: 2.8501248850983245
Validation loss: 2.384741107180755

Epoch: 518| Step: 0
Training loss: 2.1116605456393236
Validation loss: 2.3632718319198

Epoch: 6| Step: 1
Training loss: 1.8408275654697963
Validation loss: 2.40139979743802

Epoch: 6| Step: 2
Training loss: 1.6566338004466614
Validation loss: 2.376062315361887

Epoch: 6| Step: 3
Training loss: 1.7843345570699334
Validation loss: 2.3741704553148244

Epoch: 6| Step: 4
Training loss: 1.69429597395233
Validation loss: 2.373150127201519

Epoch: 6| Step: 5
Training loss: 1.220394589914829
Validation loss: 2.3828071259307375

Epoch: 6| Step: 6
Training loss: 1.6268254810465905
Validation loss: 2.3592336072131928

Epoch: 6| Step: 7
Training loss: 1.7622037165085547
Validation loss: 2.3636569489356343

Epoch: 6| Step: 8
Training loss: 1.411471063009856
Validation loss: 2.3451278650683607

Epoch: 6| Step: 9
Training loss: 2.061132844888598
Validation loss: 2.3417571041332343

Epoch: 6| Step: 10
Training loss: 2.319227073925377
Validation loss: 2.401641878166633

Epoch: 6| Step: 11
Training loss: 1.8865047989052994
Validation loss: 2.419763427469021

Epoch: 6| Step: 12
Training loss: 1.6485156000085894
Validation loss: 2.3411232528374133

Epoch: 6| Step: 13
Training loss: 1.5587485482729933
Validation loss: 2.3438174439710893

Epoch: 519| Step: 0
Training loss: 1.816183622109491
Validation loss: 2.339274006028557

Epoch: 6| Step: 1
Training loss: 1.886635093334912
Validation loss: 2.357165207899164

Epoch: 6| Step: 2
Training loss: 1.517695163450611
Validation loss: 2.3869088512103755

Epoch: 6| Step: 3
Training loss: 1.1220622381944043
Validation loss: 2.380471518443539

Epoch: 6| Step: 4
Training loss: 1.8407849538630003
Validation loss: 2.385463910983538

Epoch: 6| Step: 5
Training loss: 1.5884186076876243
Validation loss: 2.341652999769148

Epoch: 6| Step: 6
Training loss: 1.7666574345953256
Validation loss: 2.3653280597763984

Epoch: 6| Step: 7
Training loss: 2.3348618904781975
Validation loss: 2.3488749944121405

Epoch: 6| Step: 8
Training loss: 1.36911163081706
Validation loss: 2.3532733966698127

Epoch: 6| Step: 9
Training loss: 2.494810535675452
Validation loss: 2.3626540423370117

Epoch: 6| Step: 10
Training loss: 1.753281785886523
Validation loss: 2.351933312811509

Epoch: 6| Step: 11
Training loss: 1.7765736011705162
Validation loss: 2.415389345758185

Epoch: 6| Step: 12
Training loss: 1.634968042090495
Validation loss: 2.3510425578656755

Epoch: 6| Step: 13
Training loss: 1.6881339683704062
Validation loss: 2.3772940089297427

Epoch: 520| Step: 0
Training loss: 1.6693336923302293
Validation loss: 2.3741429298513013

Epoch: 6| Step: 1
Training loss: 1.3383317874378542
Validation loss: 2.3791870154102934

Epoch: 6| Step: 2
Training loss: 1.7306964801920273
Validation loss: 2.4256352232762346

Epoch: 6| Step: 3
Training loss: 1.4368719304513686
Validation loss: 2.3420816238280646

Epoch: 6| Step: 4
Training loss: 1.3836420017403717
Validation loss: 2.374141634070174

Epoch: 6| Step: 5
Training loss: 2.2303048790161037
Validation loss: 2.350321801528479

Epoch: 6| Step: 6
Training loss: 1.97299868189308
Validation loss: 2.3694187185014073

Epoch: 6| Step: 7
Training loss: 1.5726530178319214
Validation loss: 2.33667616990914

Epoch: 6| Step: 8
Training loss: 2.192405758336214
Validation loss: 2.341146245432113

Epoch: 6| Step: 9
Training loss: 2.012614522957036
Validation loss: 2.4073537802115665

Epoch: 6| Step: 10
Training loss: 1.9030216583607085
Validation loss: 2.310211953183048

Epoch: 6| Step: 11
Training loss: 1.8299389830042299
Validation loss: 2.387406039041315

Epoch: 6| Step: 12
Training loss: 1.3955948991343903
Validation loss: 2.35319761615156

Epoch: 6| Step: 13
Training loss: 1.6328244003519312
Validation loss: 2.3937472402734024

Epoch: 521| Step: 0
Training loss: 1.485886938155443
Validation loss: 2.366099170742967

Epoch: 6| Step: 1
Training loss: 1.7607814553822867
Validation loss: 2.3762909533141268

Epoch: 6| Step: 2
Training loss: 1.7321938210856698
Validation loss: 2.3653998848599387

Epoch: 6| Step: 3
Training loss: 1.7384725058276524
Validation loss: 2.4026363935889408

Epoch: 6| Step: 4
Training loss: 1.5814492744659059
Validation loss: 2.4177359777863945

Epoch: 6| Step: 5
Training loss: 2.017937331891021
Validation loss: 2.3853101572676887

Epoch: 6| Step: 6
Training loss: 1.6867626839976853
Validation loss: 2.3843965195284267

Epoch: 6| Step: 7
Training loss: 2.3357169260865867
Validation loss: 2.3682272053385756

Epoch: 6| Step: 8
Training loss: 2.047725588116854
Validation loss: 2.3905172509394896

Epoch: 6| Step: 9
Training loss: 1.5993465072520712
Validation loss: 2.339554511139912

Epoch: 6| Step: 10
Training loss: 1.8359002941501004
Validation loss: 2.3506284840319656

Epoch: 6| Step: 11
Training loss: 1.9673569610057606
Validation loss: 2.3455030834766126

Epoch: 6| Step: 12
Training loss: 1.4603040005064918
Validation loss: 2.398606216692285

Epoch: 6| Step: 13
Training loss: 1.27547955750608
Validation loss: 2.3480957563336595

Epoch: 522| Step: 0
Training loss: 1.4158834461476522
Validation loss: 2.3981272793538944

Epoch: 6| Step: 1
Training loss: 1.772752806117277
Validation loss: 2.3944156916411026

Epoch: 6| Step: 2
Training loss: 1.8008703511799602
Validation loss: 2.419068011881732

Epoch: 6| Step: 3
Training loss: 1.4232218305760773
Validation loss: 2.3824957438186023

Epoch: 6| Step: 4
Training loss: 1.8806162327428626
Validation loss: 2.3471218539196252

Epoch: 6| Step: 5
Training loss: 1.6042073810249218
Validation loss: 2.363778237507962

Epoch: 6| Step: 6
Training loss: 2.274611861266727
Validation loss: 2.349164537123288

Epoch: 6| Step: 7
Training loss: 1.416656138811075
Validation loss: 2.3798832132231915

Epoch: 6| Step: 8
Training loss: 1.4461305519832974
Validation loss: 2.4144074863561977

Epoch: 6| Step: 9
Training loss: 1.8675498451209356
Validation loss: 2.341024822444006

Epoch: 6| Step: 10
Training loss: 2.330856768704289
Validation loss: 2.4431593294280893

Epoch: 6| Step: 11
Training loss: 1.9379075144773985
Validation loss: 2.3956966689314068

Epoch: 6| Step: 12
Training loss: 1.5111240528213217
Validation loss: 2.3841415198279665

Epoch: 6| Step: 13
Training loss: 1.8668739981404372
Validation loss: 2.4143579556236903

Epoch: 523| Step: 0
Training loss: 1.2156719071230229
Validation loss: 2.3645245604976175

Epoch: 6| Step: 1
Training loss: 1.393919310955958
Validation loss: 2.407727507450518

Epoch: 6| Step: 2
Training loss: 1.727101030554328
Validation loss: 2.3588275487532497

Epoch: 6| Step: 3
Training loss: 1.7543526062387236
Validation loss: 2.340472296899159

Epoch: 6| Step: 4
Training loss: 2.1282237787610896
Validation loss: 2.3635034188075723

Epoch: 6| Step: 5
Training loss: 2.110849275023026
Validation loss: 2.393006391939196

Epoch: 6| Step: 6
Training loss: 1.4851158301137222
Validation loss: 2.342801223190222

Epoch: 6| Step: 7
Training loss: 2.2378155022355837
Validation loss: 2.3791178823642083

Epoch: 6| Step: 8
Training loss: 2.0328529488763745
Validation loss: 2.4206591785176013

Epoch: 6| Step: 9
Training loss: 1.1471812325319124
Validation loss: 2.340157614021266

Epoch: 6| Step: 10
Training loss: 1.6556408319691933
Validation loss: 2.386915494151625

Epoch: 6| Step: 11
Training loss: 1.4066726473293956
Validation loss: 2.3526239315938975

Epoch: 6| Step: 12
Training loss: 1.89992706510195
Validation loss: 2.3544586153795755

Epoch: 6| Step: 13
Training loss: 2.282080512215421
Validation loss: 2.34034963289972

Epoch: 524| Step: 0
Training loss: 1.778814826261213
Validation loss: 2.3780366717403028

Epoch: 6| Step: 1
Training loss: 1.4175932415902295
Validation loss: 2.3643389733645255

Epoch: 6| Step: 2
Training loss: 1.6880694241010104
Validation loss: 2.3864438530843795

Epoch: 6| Step: 3
Training loss: 1.6029880041291127
Validation loss: 2.3449334201132666

Epoch: 6| Step: 4
Training loss: 2.0396372251888266
Validation loss: 2.3677703038186526

Epoch: 6| Step: 5
Training loss: 2.3935120546488817
Validation loss: 2.38350988141906

Epoch: 6| Step: 6
Training loss: 1.6895613619139753
Validation loss: 2.4272694032922355

Epoch: 6| Step: 7
Training loss: 1.3164504861615394
Validation loss: 2.3426505613137203

Epoch: 6| Step: 8
Training loss: 2.038746191754459
Validation loss: 2.3550062081013676

Epoch: 6| Step: 9
Training loss: 1.807490958036861
Validation loss: 2.414993760146257

Epoch: 6| Step: 10
Training loss: 1.3853484784700623
Validation loss: 2.4022444104147165

Epoch: 6| Step: 11
Training loss: 1.9634214679816957
Validation loss: 2.4113077631277227

Epoch: 6| Step: 12
Training loss: 1.17809693685039
Validation loss: 2.36296062255578

Epoch: 6| Step: 13
Training loss: 2.090673207181963
Validation loss: 2.338366934817354

Epoch: 525| Step: 0
Training loss: 1.4496231543076996
Validation loss: 2.401542063334487

Epoch: 6| Step: 1
Training loss: 1.5842211225375056
Validation loss: 2.388302681948942

Epoch: 6| Step: 2
Training loss: 1.769785814311152
Validation loss: 2.345679879798054

Epoch: 6| Step: 3
Training loss: 1.3108221864964011
Validation loss: 2.4230491880076412

Epoch: 6| Step: 4
Training loss: 1.8816628646249036
Validation loss: 2.4028005647698096

Epoch: 6| Step: 5
Training loss: 1.5390216028037047
Validation loss: 2.3342703118738566

Epoch: 6| Step: 6
Training loss: 2.4626030992332133
Validation loss: 2.3911149822210302

Epoch: 6| Step: 7
Training loss: 1.4351010415262224
Validation loss: 2.4146399986838265

Epoch: 6| Step: 8
Training loss: 2.154103855813563
Validation loss: 2.3540102527117135

Epoch: 6| Step: 9
Training loss: 2.161252176648837
Validation loss: 2.31509122922526

Epoch: 6| Step: 10
Training loss: 1.7983120686449643
Validation loss: 2.4107218573458344

Epoch: 6| Step: 11
Training loss: 1.7304914830352867
Validation loss: 2.3572108494608894

Epoch: 6| Step: 12
Training loss: 1.376006191738747
Validation loss: 2.42596978131021

Epoch: 6| Step: 13
Training loss: 1.5165964533025256
Validation loss: 2.366654514646666

Epoch: 526| Step: 0
Training loss: 2.1141731227625318
Validation loss: 2.390379540623859

Epoch: 6| Step: 1
Training loss: 2.1152298663963953
Validation loss: 2.419804545790844

Epoch: 6| Step: 2
Training loss: 1.7151085164740627
Validation loss: 2.4062270776141337

Epoch: 6| Step: 3
Training loss: 1.3895435628771196
Validation loss: 2.4018330493156315

Epoch: 6| Step: 4
Training loss: 2.2094695808852904
Validation loss: 2.397715273383406

Epoch: 6| Step: 5
Training loss: 1.518430649576477
Validation loss: 2.3514060607293734

Epoch: 6| Step: 6
Training loss: 1.9243444069502396
Validation loss: 2.4047649943421288

Epoch: 6| Step: 7
Training loss: 1.2602904653290077
Validation loss: 2.3793016476204776

Epoch: 6| Step: 8
Training loss: 1.267730374589992
Validation loss: 2.379770254009295

Epoch: 6| Step: 9
Training loss: 2.051313872426755
Validation loss: 2.384374368695178

Epoch: 6| Step: 10
Training loss: 1.9274523682405067
Validation loss: 2.338044000399349

Epoch: 6| Step: 11
Training loss: 1.7356310583385963
Validation loss: 2.3784681719310425

Epoch: 6| Step: 12
Training loss: 1.838634636305137
Validation loss: 2.3605876572387663

Epoch: 6| Step: 13
Training loss: 1.4564431975079353
Validation loss: 2.4332788590545316

Epoch: 527| Step: 0
Training loss: 1.7688790776362975
Validation loss: 2.381418637000712

Epoch: 6| Step: 1
Training loss: 1.7419569607092067
Validation loss: 2.3528998074636247

Epoch: 6| Step: 2
Training loss: 1.5001452693531376
Validation loss: 2.408831168311343

Epoch: 6| Step: 3
Training loss: 2.0929704040315764
Validation loss: 2.4036290459225573

Epoch: 6| Step: 4
Training loss: 1.9319230076709473
Validation loss: 2.408161776652042

Epoch: 6| Step: 5
Training loss: 1.8786773224946491
Validation loss: 2.3543058204161404

Epoch: 6| Step: 6
Training loss: 1.6602491644495474
Validation loss: 2.3703077819609835

Epoch: 6| Step: 7
Training loss: 2.1423146060599714
Validation loss: 2.3634498632993273

Epoch: 6| Step: 8
Training loss: 1.2556910186926376
Validation loss: 2.386891462405163

Epoch: 6| Step: 9
Training loss: 1.5414403371236876
Validation loss: 2.347722932033266

Epoch: 6| Step: 10
Training loss: 1.5966139100317613
Validation loss: 2.3930824373437014

Epoch: 6| Step: 11
Training loss: 1.8572350376957545
Validation loss: 2.3862953042010346

Epoch: 6| Step: 12
Training loss: 1.8980350774291204
Validation loss: 2.3944554647396963

Epoch: 6| Step: 13
Training loss: 1.6712211685147471
Validation loss: 2.357231440404703

Epoch: 528| Step: 0
Training loss: 1.8621336403816762
Validation loss: 2.391921693658697

Epoch: 6| Step: 1
Training loss: 1.733499529402509
Validation loss: 2.3098074234854087

Epoch: 6| Step: 2
Training loss: 2.2766156087635694
Validation loss: 2.369280308820521

Epoch: 6| Step: 3
Training loss: 1.3924821603889017
Validation loss: 2.421953713536837

Epoch: 6| Step: 4
Training loss: 1.80479384600253
Validation loss: 2.3424813132644378

Epoch: 6| Step: 5
Training loss: 1.199224813737978
Validation loss: 2.3937435807530485

Epoch: 6| Step: 6
Training loss: 2.527962704648981
Validation loss: 2.367208802319485

Epoch: 6| Step: 7
Training loss: 1.4370444861463316
Validation loss: 2.376393620100003

Epoch: 6| Step: 8
Training loss: 1.8396004355972349
Validation loss: 2.391731436722317

Epoch: 6| Step: 9
Training loss: 1.816880424709246
Validation loss: 2.360498413110427

Epoch: 6| Step: 10
Training loss: 1.1779493448865501
Validation loss: 2.3769212884230533

Epoch: 6| Step: 11
Training loss: 2.183441757344318
Validation loss: 2.3775001728399445

Epoch: 6| Step: 12
Training loss: 1.32614203125938
Validation loss: 2.4066430133009113

Epoch: 6| Step: 13
Training loss: 1.752206773374694
Validation loss: 2.3789984329930833

Epoch: 529| Step: 0
Training loss: 1.519423218640264
Validation loss: 2.3806099661299935

Epoch: 6| Step: 1
Training loss: 2.119881692860154
Validation loss: 2.4087491427571597

Epoch: 6| Step: 2
Training loss: 1.9371296313288864
Validation loss: 2.405908482317806

Epoch: 6| Step: 3
Training loss: 2.099415189057982
Validation loss: 2.3890653881122956

Epoch: 6| Step: 4
Training loss: 1.8388012566803444
Validation loss: 2.373343672195241

Epoch: 6| Step: 5
Training loss: 1.9978766494684022
Validation loss: 2.3779971064648944

Epoch: 6| Step: 6
Training loss: 1.638332472743096
Validation loss: 2.3842025578144477

Epoch: 6| Step: 7
Training loss: 1.8885033422818756
Validation loss: 2.3783790166720578

Epoch: 6| Step: 8
Training loss: 1.2812396723633404
Validation loss: 2.374912304600375

Epoch: 6| Step: 9
Training loss: 1.4859751057805073
Validation loss: 2.3855753228480387

Epoch: 6| Step: 10
Training loss: 1.410104935576267
Validation loss: 2.356223891532397

Epoch: 6| Step: 11
Training loss: 1.7894848987062602
Validation loss: 2.426143988547688

Epoch: 6| Step: 12
Training loss: 1.6749155791914447
Validation loss: 2.3493623409050164

Epoch: 6| Step: 13
Training loss: 1.5396199257734433
Validation loss: 2.3963111975131675

Epoch: 530| Step: 0
Training loss: 1.4807882241051342
Validation loss: 2.3991957474641

Epoch: 6| Step: 1
Training loss: 1.579156444117222
Validation loss: 2.3531061535801654

Epoch: 6| Step: 2
Training loss: 1.466201600481668
Validation loss: 2.411832628154208

Epoch: 6| Step: 3
Training loss: 1.896588213638326
Validation loss: 2.356365833735766

Epoch: 6| Step: 4
Training loss: 1.5692447809166299
Validation loss: 2.312076339115748

Epoch: 6| Step: 5
Training loss: 1.372131302859306
Validation loss: 2.3501105747900874

Epoch: 6| Step: 6
Training loss: 1.9907405610129632
Validation loss: 2.3906974097876845

Epoch: 6| Step: 7
Training loss: 1.7243500079244647
Validation loss: 2.3373725837960935

Epoch: 6| Step: 8
Training loss: 2.0691754367543673
Validation loss: 2.3626291062544142

Epoch: 6| Step: 9
Training loss: 1.2710765647547073
Validation loss: 2.3916797588559304

Epoch: 6| Step: 10
Training loss: 2.5166690152727837
Validation loss: 2.3870555511890634

Epoch: 6| Step: 11
Training loss: 1.8811914580605247
Validation loss: 2.3466677529511615

Epoch: 6| Step: 12
Training loss: 1.4542445310424565
Validation loss: 2.3731047619493943

Epoch: 6| Step: 13
Training loss: 1.564578162064961
Validation loss: 2.3876929332054355

Epoch: 531| Step: 0
Training loss: 1.1460598577208994
Validation loss: 2.36287723139738

Epoch: 6| Step: 1
Training loss: 2.2416583244234682
Validation loss: 2.3645869277580567

Epoch: 6| Step: 2
Training loss: 2.0125509077942905
Validation loss: 2.388790175814292

Epoch: 6| Step: 3
Training loss: 2.4049191448237193
Validation loss: 2.361354414532472

Epoch: 6| Step: 4
Training loss: 1.5537310394578765
Validation loss: 2.3458422372929837

Epoch: 6| Step: 5
Training loss: 1.6873711430837375
Validation loss: 2.336847312289367

Epoch: 6| Step: 6
Training loss: 1.977581440035906
Validation loss: 2.3666356413854377

Epoch: 6| Step: 7
Training loss: 1.3832480827551288
Validation loss: 2.3380169926111325

Epoch: 6| Step: 8
Training loss: 1.6581198016508296
Validation loss: 2.3760241290323947

Epoch: 6| Step: 9
Training loss: 1.2827001134449936
Validation loss: 2.367810679859138

Epoch: 6| Step: 10
Training loss: 2.0479101228140526
Validation loss: 2.4049509103086164

Epoch: 6| Step: 11
Training loss: 1.299350765308694
Validation loss: 2.3972371654347118

Epoch: 6| Step: 12
Training loss: 1.4726107562497999
Validation loss: 2.424907285733959

Epoch: 6| Step: 13
Training loss: 2.2432818251086495
Validation loss: 2.365239069298667

Epoch: 532| Step: 0
Training loss: 2.0962889351183227
Validation loss: 2.375579892720835

Epoch: 6| Step: 1
Training loss: 1.6739080314302717
Validation loss: 2.378352320319827

Epoch: 6| Step: 2
Training loss: 1.8559077657028493
Validation loss: 2.3664947029886587

Epoch: 6| Step: 3
Training loss: 1.4035517343132955
Validation loss: 2.384079596368597

Epoch: 6| Step: 4
Training loss: 1.503226069425005
Validation loss: 2.337266250573847

Epoch: 6| Step: 5
Training loss: 1.7369146225436238
Validation loss: 2.3970309423996277

Epoch: 6| Step: 6
Training loss: 1.8189890229248884
Validation loss: 2.369046127887999

Epoch: 6| Step: 7
Training loss: 1.8588204718995671
Validation loss: 2.3376870548636033

Epoch: 6| Step: 8
Training loss: 1.7600010789521119
Validation loss: 2.3500826911629358

Epoch: 6| Step: 9
Training loss: 1.4888961202689408
Validation loss: 2.3748426833238216

Epoch: 6| Step: 10
Training loss: 1.9016193365725977
Validation loss: 2.3845510933286556

Epoch: 6| Step: 11
Training loss: 1.8270353020241643
Validation loss: 2.350570129725555

Epoch: 6| Step: 12
Training loss: 2.157741307348607
Validation loss: 2.338537367511595

Epoch: 6| Step: 13
Training loss: 1.4353271316191174
Validation loss: 2.412593120512219

Epoch: 533| Step: 0
Training loss: 1.7019592635258747
Validation loss: 2.415123333912043

Epoch: 6| Step: 1
Training loss: 2.264324577964157
Validation loss: 2.3357966256369296

Epoch: 6| Step: 2
Training loss: 1.7160225468423667
Validation loss: 2.398376316557995

Epoch: 6| Step: 3
Training loss: 1.6570056415109593
Validation loss: 2.330876592686157

Epoch: 6| Step: 4
Training loss: 1.8212558119451383
Validation loss: 2.337834690926589

Epoch: 6| Step: 5
Training loss: 1.2768031851747885
Validation loss: 2.33316221100447

Epoch: 6| Step: 6
Training loss: 1.6085142778326766
Validation loss: 2.364316752805202

Epoch: 6| Step: 7
Training loss: 1.9253979779329635
Validation loss: 2.387297535812567

Epoch: 6| Step: 8
Training loss: 1.3126704695668954
Validation loss: 2.376560296652836

Epoch: 6| Step: 9
Training loss: 1.2955218690051815
Validation loss: 2.338120392669467

Epoch: 6| Step: 10
Training loss: 1.525431106166996
Validation loss: 2.396934806793235

Epoch: 6| Step: 11
Training loss: 1.8693327132390436
Validation loss: 2.41460250845038

Epoch: 6| Step: 12
Training loss: 1.965461406358943
Validation loss: 2.356240842967942

Epoch: 6| Step: 13
Training loss: 2.0713930009503234
Validation loss: 2.3763247057008865

Epoch: 534| Step: 0
Training loss: 2.2292103867090853
Validation loss: 2.390739730386431

Epoch: 6| Step: 1
Training loss: 1.8918831162267575
Validation loss: 2.4128802668476297

Epoch: 6| Step: 2
Training loss: 2.177015300460408
Validation loss: 2.3495376144019526

Epoch: 6| Step: 3
Training loss: 1.638732181571501
Validation loss: 2.387534159324861

Epoch: 6| Step: 4
Training loss: 1.6108702592848796
Validation loss: 2.4042991930798148

Epoch: 6| Step: 5
Training loss: 1.3903356529703654
Validation loss: 2.399392104797662

Epoch: 6| Step: 6
Training loss: 1.5947741041788255
Validation loss: 2.419545798405121

Epoch: 6| Step: 7
Training loss: 1.5752876382389587
Validation loss: 2.4298835883392575

Epoch: 6| Step: 8
Training loss: 1.6221842211942068
Validation loss: 2.407288248365498

Epoch: 6| Step: 9
Training loss: 1.640181926661862
Validation loss: 2.422321705238009

Epoch: 6| Step: 10
Training loss: 1.7617276819514427
Validation loss: 2.343032719499175

Epoch: 6| Step: 11
Training loss: 1.7033318910138517
Validation loss: 2.381939919437536

Epoch: 6| Step: 12
Training loss: 1.5267977702111784
Validation loss: 2.4105756170789436

Epoch: 6| Step: 13
Training loss: 1.8819388107584596
Validation loss: 2.397267420054736

Epoch: 535| Step: 0
Training loss: 1.720762842811278
Validation loss: 2.345229552406007

Epoch: 6| Step: 1
Training loss: 1.9458431148351272
Validation loss: 2.3946781756748927

Epoch: 6| Step: 2
Training loss: 1.4657900589191386
Validation loss: 2.3475334175341187

Epoch: 6| Step: 3
Training loss: 2.0060672522288696
Validation loss: 2.331513038343926

Epoch: 6| Step: 4
Training loss: 1.4617641782404114
Validation loss: 2.3666831432648854

Epoch: 6| Step: 5
Training loss: 1.493748911454191
Validation loss: 2.3527321379181907

Epoch: 6| Step: 6
Training loss: 2.0279683527235917
Validation loss: 2.346691501272539

Epoch: 6| Step: 7
Training loss: 1.827397323938602
Validation loss: 2.366252769718777

Epoch: 6| Step: 8
Training loss: 2.18012564025838
Validation loss: 2.381380686200273

Epoch: 6| Step: 9
Training loss: 1.6146758842604165
Validation loss: 2.401182887014317

Epoch: 6| Step: 10
Training loss: 1.9547421283848838
Validation loss: 2.375298256272625

Epoch: 6| Step: 11
Training loss: 1.6214501414295686
Validation loss: 2.407033248654348

Epoch: 6| Step: 12
Training loss: 1.2221754792455508
Validation loss: 2.366369755376515

Epoch: 6| Step: 13
Training loss: 0.8636900680330456
Validation loss: 2.3542714028051615

Epoch: 536| Step: 0
Training loss: 2.2613913079978403
Validation loss: 2.3362787886138436

Epoch: 6| Step: 1
Training loss: 1.2340259299869378
Validation loss: 2.3304340831357133

Epoch: 6| Step: 2
Training loss: 1.9264043763202878
Validation loss: 2.3466390871721075

Epoch: 6| Step: 3
Training loss: 1.7209445467919455
Validation loss: 2.362855753319721

Epoch: 6| Step: 4
Training loss: 1.4583887725464868
Validation loss: 2.417569328868453

Epoch: 6| Step: 5
Training loss: 2.4345546435767336
Validation loss: 2.3740613892862132

Epoch: 6| Step: 6
Training loss: 1.7698601086610593
Validation loss: 2.401075326665244

Epoch: 6| Step: 7
Training loss: 1.6703726176905984
Validation loss: 2.3911950192327103

Epoch: 6| Step: 8
Training loss: 2.087045782320949
Validation loss: 2.349746573665585

Epoch: 6| Step: 9
Training loss: 2.044209032683649
Validation loss: 2.3710474917746387

Epoch: 6| Step: 10
Training loss: 1.499798602253168
Validation loss: 2.353294511199028

Epoch: 6| Step: 11
Training loss: 1.3514667984260378
Validation loss: 2.3372714013961615

Epoch: 6| Step: 12
Training loss: 1.222843728606266
Validation loss: 2.4191461035536928

Epoch: 6| Step: 13
Training loss: 1.4647646463016424
Validation loss: 2.3456393506926934

Epoch: 537| Step: 0
Training loss: 2.3895024674780605
Validation loss: 2.368076335879278

Epoch: 6| Step: 1
Training loss: 1.5572775730613784
Validation loss: 2.390069771469621

Epoch: 6| Step: 2
Training loss: 1.7289113771661648
Validation loss: 2.370070892366832

Epoch: 6| Step: 3
Training loss: 1.9902120931499272
Validation loss: 2.3600291552949195

Epoch: 6| Step: 4
Training loss: 1.5456086957775752
Validation loss: 2.357022510053791

Epoch: 6| Step: 5
Training loss: 1.9750563722122307
Validation loss: 2.3966065395460414

Epoch: 6| Step: 6
Training loss: 1.6346936500592604
Validation loss: 2.3226029191393276

Epoch: 6| Step: 7
Training loss: 1.4258167001157973
Validation loss: 2.3690037811895577

Epoch: 6| Step: 8
Training loss: 1.7472736374662585
Validation loss: 2.353838708176061

Epoch: 6| Step: 9
Training loss: 1.7850301017680736
Validation loss: 2.396434408567348

Epoch: 6| Step: 10
Training loss: 1.7158182282019925
Validation loss: 2.412754547574382

Epoch: 6| Step: 11
Training loss: 1.4936986331806517
Validation loss: 2.372917560885959

Epoch: 6| Step: 12
Training loss: 2.020367978448744
Validation loss: 2.3728462642529067

Epoch: 6| Step: 13
Training loss: 1.4465584822751592
Validation loss: 2.321411023033623

Epoch: 538| Step: 0
Training loss: 1.7265602905811654
Validation loss: 2.3783643066062106

Epoch: 6| Step: 1
Training loss: 1.7806499876047885
Validation loss: 2.3581314781323957

Epoch: 6| Step: 2
Training loss: 1.5271126262497285
Validation loss: 2.3712380336233556

Epoch: 6| Step: 3
Training loss: 1.5220639810585865
Validation loss: 2.3693138992299945

Epoch: 6| Step: 4
Training loss: 1.9802619179009553
Validation loss: 2.4207115700029167

Epoch: 6| Step: 5
Training loss: 1.7225813730449644
Validation loss: 2.435602060795651

Epoch: 6| Step: 6
Training loss: 1.358660937902398
Validation loss: 2.3845858318390043

Epoch: 6| Step: 7
Training loss: 2.0209563961770733
Validation loss: 2.404624675574068

Epoch: 6| Step: 8
Training loss: 1.4276849448522642
Validation loss: 2.3693693801429303

Epoch: 6| Step: 9
Training loss: 1.6382360594942347
Validation loss: 2.397014496538797

Epoch: 6| Step: 10
Training loss: 1.626305862393861
Validation loss: 2.383301356194533

Epoch: 6| Step: 11
Training loss: 2.3680621756432836
Validation loss: 2.364653139943799

Epoch: 6| Step: 12
Training loss: 1.7355800944018291
Validation loss: 2.38821459693862

Epoch: 6| Step: 13
Training loss: 1.3299588277366827
Validation loss: 2.370012031342218

Epoch: 539| Step: 0
Training loss: 2.1973815073608867
Validation loss: 2.3400718633511017

Epoch: 6| Step: 1
Training loss: 1.7645385235077735
Validation loss: 2.3314782435783497

Epoch: 6| Step: 2
Training loss: 1.6492262846875343
Validation loss: 2.40450902229317

Epoch: 6| Step: 3
Training loss: 1.6065582513966357
Validation loss: 2.3540942405720306

Epoch: 6| Step: 4
Training loss: 1.7326741169329858
Validation loss: 2.3452329104987726

Epoch: 6| Step: 5
Training loss: 1.3009993453379691
Validation loss: 2.3567151557266253

Epoch: 6| Step: 6
Training loss: 1.975209734439772
Validation loss: 2.3809267336186264

Epoch: 6| Step: 7
Training loss: 1.409682598507173
Validation loss: 2.3394481214831573

Epoch: 6| Step: 8
Training loss: 1.7360380292981232
Validation loss: 2.346593306630333

Epoch: 6| Step: 9
Training loss: 1.5893136905271321
Validation loss: 2.398266910922254

Epoch: 6| Step: 10
Training loss: 1.8909541072188691
Validation loss: 2.3566078616920745

Epoch: 6| Step: 11
Training loss: 1.9393267479910736
Validation loss: 2.3528701699805943

Epoch: 6| Step: 12
Training loss: 1.8144791419521995
Validation loss: 2.331406310318517

Epoch: 6| Step: 13
Training loss: 1.481531491473077
Validation loss: 2.3825065536072305

Epoch: 540| Step: 0
Training loss: 2.0671772951550365
Validation loss: 2.35378844039387

Epoch: 6| Step: 1
Training loss: 1.5548811748770581
Validation loss: 2.3470938572357007

Epoch: 6| Step: 2
Training loss: 1.787847647839028
Validation loss: 2.386313788849542

Epoch: 6| Step: 3
Training loss: 1.7196277111265297
Validation loss: 2.358944242973211

Epoch: 6| Step: 4
Training loss: 1.6136429868359494
Validation loss: 2.3920897649788824

Epoch: 6| Step: 5
Training loss: 2.0086241985017717
Validation loss: 2.3803963076147734

Epoch: 6| Step: 6
Training loss: 1.9095634055327295
Validation loss: 2.349078683071319

Epoch: 6| Step: 7
Training loss: 1.9171508163760418
Validation loss: 2.392435514122978

Epoch: 6| Step: 8
Training loss: 1.1283602862799127
Validation loss: 2.416050560491793

Epoch: 6| Step: 9
Training loss: 1.7341650758461329
Validation loss: 2.378694152617886

Epoch: 6| Step: 10
Training loss: 1.3193667031971013
Validation loss: 2.4252652692903767

Epoch: 6| Step: 11
Training loss: 1.7236393828442407
Validation loss: 2.3667796443639

Epoch: 6| Step: 12
Training loss: 1.7555166213363194
Validation loss: 2.3250986776274627

Epoch: 6| Step: 13
Training loss: 0.8939180562933832
Validation loss: 2.3813884781508294

Epoch: 541| Step: 0
Training loss: 1.3561553535309907
Validation loss: 2.3806985365709505

Epoch: 6| Step: 1
Training loss: 1.6981345740909413
Validation loss: 2.378923971973372

Epoch: 6| Step: 2
Training loss: 1.829206228443906
Validation loss: 2.3496004225708385

Epoch: 6| Step: 3
Training loss: 2.0642750355571122
Validation loss: 2.379288724875902

Epoch: 6| Step: 4
Training loss: 2.253878746988828
Validation loss: 2.3791736777312766

Epoch: 6| Step: 5
Training loss: 1.3586123289183716
Validation loss: 2.346634634792797

Epoch: 6| Step: 6
Training loss: 1.8563299810473235
Validation loss: 2.339203665991287

Epoch: 6| Step: 7
Training loss: 1.4768888728409995
Validation loss: 2.3104288559269417

Epoch: 6| Step: 8
Training loss: 1.3972353749870614
Validation loss: 2.330834639204469

Epoch: 6| Step: 9
Training loss: 2.2006256861036944
Validation loss: 2.373184371483361

Epoch: 6| Step: 10
Training loss: 1.2605738686294763
Validation loss: 2.32694191805718

Epoch: 6| Step: 11
Training loss: 1.933951604847119
Validation loss: 2.370564133483637

Epoch: 6| Step: 12
Training loss: 1.3349324064966195
Validation loss: 2.388936303647459

Epoch: 6| Step: 13
Training loss: 1.7049869543566505
Validation loss: 2.3280793321998563

Epoch: 542| Step: 0
Training loss: 1.8663008112802784
Validation loss: 2.3188088035485057

Epoch: 6| Step: 1
Training loss: 1.4613763486669809
Validation loss: 2.395599434248328

Epoch: 6| Step: 2
Training loss: 2.0228032476790223
Validation loss: 2.3480359601103835

Epoch: 6| Step: 3
Training loss: 1.9970651789741478
Validation loss: 2.3344674130461756

Epoch: 6| Step: 4
Training loss: 1.0399739562955166
Validation loss: 2.3693964590222683

Epoch: 6| Step: 5
Training loss: 2.291228015417504
Validation loss: 2.3151056531048253

Epoch: 6| Step: 6
Training loss: 1.6974966859855383
Validation loss: 2.3668261371020276

Epoch: 6| Step: 7
Training loss: 1.6126474239173259
Validation loss: 2.392093027279858

Epoch: 6| Step: 8
Training loss: 1.6420746710986889
Validation loss: 2.4089927250800933

Epoch: 6| Step: 9
Training loss: 1.2478768437335732
Validation loss: 2.3491076339277517

Epoch: 6| Step: 10
Training loss: 1.609799819727511
Validation loss: 2.349687545551151

Epoch: 6| Step: 11
Training loss: 1.666089395050336
Validation loss: 2.378127765695682

Epoch: 6| Step: 12
Training loss: 1.8811987454855692
Validation loss: 2.386052490547569

Epoch: 6| Step: 13
Training loss: 1.5516721534973446
Validation loss: 2.3888072422565387

Epoch: 543| Step: 0
Training loss: 1.486236288714868
Validation loss: 2.3326018859932525

Epoch: 6| Step: 1
Training loss: 2.0764649149380663
Validation loss: 2.3469281804163113

Epoch: 6| Step: 2
Training loss: 1.7488794145013757
Validation loss: 2.3644527521940195

Epoch: 6| Step: 3
Training loss: 1.7426952768198867
Validation loss: 2.3661560201464327

Epoch: 6| Step: 4
Training loss: 1.4832238803443103
Validation loss: 2.300682343332183

Epoch: 6| Step: 5
Training loss: 1.5584545407951744
Validation loss: 2.3633326821225284

Epoch: 6| Step: 6
Training loss: 1.4111245758977828
Validation loss: 2.3870387342749053

Epoch: 6| Step: 7
Training loss: 2.007915924614635
Validation loss: 2.3522657970427057

Epoch: 6| Step: 8
Training loss: 1.4890428731931789
Validation loss: 2.3821615232630142

Epoch: 6| Step: 9
Training loss: 1.1523013349582785
Validation loss: 2.334912363152024

Epoch: 6| Step: 10
Training loss: 2.495084412241928
Validation loss: 2.371347893026465

Epoch: 6| Step: 11
Training loss: 1.5486416987129177
Validation loss: 2.4029342815289585

Epoch: 6| Step: 12
Training loss: 1.8378952301973055
Validation loss: 2.3506541723370273

Epoch: 6| Step: 13
Training loss: 2.0065728899228263
Validation loss: 2.378904042961174

Epoch: 544| Step: 0
Training loss: 1.7985691211304298
Validation loss: 2.3513266449532377

Epoch: 6| Step: 1
Training loss: 2.106447349833855
Validation loss: 2.372977203314608

Epoch: 6| Step: 2
Training loss: 1.5910469769508315
Validation loss: 2.3381655069160523

Epoch: 6| Step: 3
Training loss: 1.507340747778461
Validation loss: 2.4004638711964192

Epoch: 6| Step: 4
Training loss: 1.9118446424006386
Validation loss: 2.3773333222455917

Epoch: 6| Step: 5
Training loss: 1.4780963822350663
Validation loss: 2.3836821337070635

Epoch: 6| Step: 6
Training loss: 2.148490544444604
Validation loss: 2.3825487775963285

Epoch: 6| Step: 7
Training loss: 1.580781419404675
Validation loss: 2.3874212163429447

Epoch: 6| Step: 8
Training loss: 2.0422463534805106
Validation loss: 2.3689743213704073

Epoch: 6| Step: 9
Training loss: 1.1521587675943923
Validation loss: 2.402603817507345

Epoch: 6| Step: 10
Training loss: 1.4585725951333544
Validation loss: 2.3707881944891773

Epoch: 6| Step: 11
Training loss: 1.6043458153240233
Validation loss: 2.3391812570784096

Epoch: 6| Step: 12
Training loss: 1.3354311424022272
Validation loss: 2.3256742819082334

Epoch: 6| Step: 13
Training loss: 2.2182505945509923
Validation loss: 2.362888637613747

Epoch: 545| Step: 0
Training loss: 1.6895020229782451
Validation loss: 2.40443696766908

Epoch: 6| Step: 1
Training loss: 1.5889167051096063
Validation loss: 2.357881105262727

Epoch: 6| Step: 2
Training loss: 2.2449417477125233
Validation loss: 2.372365872441672

Epoch: 6| Step: 3
Training loss: 1.3888487455076792
Validation loss: 2.348324164696947

Epoch: 6| Step: 4
Training loss: 1.3474186784625948
Validation loss: 2.397283051440991

Epoch: 6| Step: 5
Training loss: 1.1965106618735375
Validation loss: 2.4028799031470527

Epoch: 6| Step: 6
Training loss: 1.636082199969602
Validation loss: 2.350688403524884

Epoch: 6| Step: 7
Training loss: 1.8356972395151587
Validation loss: 2.408637338251169

Epoch: 6| Step: 8
Training loss: 2.5458850457849267
Validation loss: 2.416795025628468

Epoch: 6| Step: 9
Training loss: 1.4867569133212302
Validation loss: 2.3512403083265663

Epoch: 6| Step: 10
Training loss: 1.3796669912056005
Validation loss: 2.3399340010097465

Epoch: 6| Step: 11
Training loss: 2.0562981504234883
Validation loss: 2.374865363492464

Epoch: 6| Step: 12
Training loss: 1.4361803382865297
Validation loss: 2.3851349313134285

Epoch: 6| Step: 13
Training loss: 1.4734655124756324
Validation loss: 2.3540262165329375

Epoch: 546| Step: 0
Training loss: 1.3935327026942688
Validation loss: 2.3621873692034923

Epoch: 6| Step: 1
Training loss: 1.3843238459451135
Validation loss: 2.3854683505349237

Epoch: 6| Step: 2
Training loss: 1.6811229161443821
Validation loss: 2.3987577127797794

Epoch: 6| Step: 3
Training loss: 1.280314406285765
Validation loss: 2.3761256302497387

Epoch: 6| Step: 4
Training loss: 1.7247845224889207
Validation loss: 2.363218275502544

Epoch: 6| Step: 5
Training loss: 1.890312547322678
Validation loss: 2.38835971611639

Epoch: 6| Step: 6
Training loss: 1.5713637899075261
Validation loss: 2.3621144121307154

Epoch: 6| Step: 7
Training loss: 1.6468728400257864
Validation loss: 2.3580175008351802

Epoch: 6| Step: 8
Training loss: 1.6102160876250229
Validation loss: 2.381291949500943

Epoch: 6| Step: 9
Training loss: 1.394151395465935
Validation loss: 2.3615885407692723

Epoch: 6| Step: 10
Training loss: 1.6864852680068396
Validation loss: 2.3700526185202553

Epoch: 6| Step: 11
Training loss: 2.442132802046861
Validation loss: 2.394116911892834

Epoch: 6| Step: 12
Training loss: 1.5071691217632743
Validation loss: 2.347174885268384

Epoch: 6| Step: 13
Training loss: 2.8822561828245203
Validation loss: 2.374699291283009

Epoch: 547| Step: 0
Training loss: 1.628127536295784
Validation loss: 2.3446095302235177

Epoch: 6| Step: 1
Training loss: 1.4442027187231485
Validation loss: 2.37571188054118

Epoch: 6| Step: 2
Training loss: 2.008456234581184
Validation loss: 2.337420414948465

Epoch: 6| Step: 3
Training loss: 2.020713474874724
Validation loss: 2.28036514452311

Epoch: 6| Step: 4
Training loss: 1.6046253225729317
Validation loss: 2.4028475442837984

Epoch: 6| Step: 5
Training loss: 1.5016555392113777
Validation loss: 2.3885454020900676

Epoch: 6| Step: 6
Training loss: 1.915873888783118
Validation loss: 2.337303174786753

Epoch: 6| Step: 7
Training loss: 1.4657472799407012
Validation loss: 2.4120568158004647

Epoch: 6| Step: 8
Training loss: 1.1755687230059184
Validation loss: 2.380826444957625

Epoch: 6| Step: 9
Training loss: 1.9120419171818128
Validation loss: 2.2980617080215375

Epoch: 6| Step: 10
Training loss: 1.9214344295021417
Validation loss: 2.3653816334534277

Epoch: 6| Step: 11
Training loss: 1.809316008928793
Validation loss: 2.359965234750339

Epoch: 6| Step: 12
Training loss: 1.3694754502657633
Validation loss: 2.3819669038435696

Epoch: 6| Step: 13
Training loss: 1.4159327831370756
Validation loss: 2.3701589583466833

Epoch: 548| Step: 0
Training loss: 1.7186918075420428
Validation loss: 2.3663896415289933

Epoch: 6| Step: 1
Training loss: 1.6924795925425795
Validation loss: 2.3753399392469574

Epoch: 6| Step: 2
Training loss: 1.7593794556691749
Validation loss: 2.3304820918964

Epoch: 6| Step: 3
Training loss: 1.8944899092420875
Validation loss: 2.36453980877469

Epoch: 6| Step: 4
Training loss: 1.3329395318621513
Validation loss: 2.360410080103987

Epoch: 6| Step: 5
Training loss: 2.180003153597449
Validation loss: 2.3806819240425416

Epoch: 6| Step: 6
Training loss: 1.9002929536943058
Validation loss: 2.375847155348846

Epoch: 6| Step: 7
Training loss: 1.4438904235718835
Validation loss: 2.3979936794148546

Epoch: 6| Step: 8
Training loss: 1.6929253854729713
Validation loss: 2.3974629820291633

Epoch: 6| Step: 9
Training loss: 1.4538415762216357
Validation loss: 2.3664182603515074

Epoch: 6| Step: 10
Training loss: 1.2187650141647044
Validation loss: 2.3280765065633875

Epoch: 6| Step: 11
Training loss: 1.7508015840397293
Validation loss: 2.3896621619290648

Epoch: 6| Step: 12
Training loss: 1.882786540885296
Validation loss: 2.426466301511793

Epoch: 6| Step: 13
Training loss: 1.6070550289073113
Validation loss: 2.3660774001135247

Epoch: 549| Step: 0
Training loss: 1.5383819779584724
Validation loss: 2.388354498363529

Epoch: 6| Step: 1
Training loss: 1.3709491533941063
Validation loss: 2.3642834595258555

Epoch: 6| Step: 2
Training loss: 1.402791538842482
Validation loss: 2.381441976878624

Epoch: 6| Step: 3
Training loss: 1.378419611920071
Validation loss: 2.386834969931865

Epoch: 6| Step: 4
Training loss: 1.7026131236938735
Validation loss: 2.37200445758733

Epoch: 6| Step: 5
Training loss: 1.6932280070421075
Validation loss: 2.3583051894713996

Epoch: 6| Step: 6
Training loss: 1.5821264167701543
Validation loss: 2.392045027923728

Epoch: 6| Step: 7
Training loss: 1.4636682295009396
Validation loss: 2.4048708951074196

Epoch: 6| Step: 8
Training loss: 1.8246855373407946
Validation loss: 2.3947138849239815

Epoch: 6| Step: 9
Training loss: 1.326762678771162
Validation loss: 2.3881332690012678

Epoch: 6| Step: 10
Training loss: 2.2964614184407104
Validation loss: 2.32307201653103

Epoch: 6| Step: 11
Training loss: 1.8780311243648897
Validation loss: 2.388876222602491

Epoch: 6| Step: 12
Training loss: 2.197529064068723
Validation loss: 2.3404611374280146

Epoch: 6| Step: 13
Training loss: 1.2781992156253008
Validation loss: 2.3435492480860605

Epoch: 550| Step: 0
Training loss: 1.4312526286405054
Validation loss: 2.367814698856959

Epoch: 6| Step: 1
Training loss: 1.7811778539134515
Validation loss: 2.363541439726724

Epoch: 6| Step: 2
Training loss: 1.0400065672190266
Validation loss: 2.341483941289726

Epoch: 6| Step: 3
Training loss: 2.0058783926800507
Validation loss: 2.341901762235168

Epoch: 6| Step: 4
Training loss: 1.6191203043620812
Validation loss: 2.4011356160184154

Epoch: 6| Step: 5
Training loss: 2.3451445436156892
Validation loss: 2.417603004945276

Epoch: 6| Step: 6
Training loss: 1.9633551052788283
Validation loss: 2.349616867518698

Epoch: 6| Step: 7
Training loss: 1.8138407648091985
Validation loss: 2.361145248041647

Epoch: 6| Step: 8
Training loss: 1.6197197296097812
Validation loss: 2.3903424849878596

Epoch: 6| Step: 9
Training loss: 1.3010645835615327
Validation loss: 2.320722779917744

Epoch: 6| Step: 10
Training loss: 1.786989435225532
Validation loss: 2.4278591580879887

Epoch: 6| Step: 11
Training loss: 1.2597608935836537
Validation loss: 2.3395473753996683

Epoch: 6| Step: 12
Training loss: 1.9421017051645686
Validation loss: 2.3503460784827674

Epoch: 6| Step: 13
Training loss: 1.3865322793586492
Validation loss: 2.3493646542627205

Epoch: 551| Step: 0
Training loss: 2.0058184863773114
Validation loss: 2.3626443309571683

Epoch: 6| Step: 1
Training loss: 1.3228235687578593
Validation loss: 2.3445443959883874

Epoch: 6| Step: 2
Training loss: 1.1239605446063974
Validation loss: 2.378482036322323

Epoch: 6| Step: 3
Training loss: 1.4337259590241902
Validation loss: 2.326766385256486

Epoch: 6| Step: 4
Training loss: 1.9655219361860141
Validation loss: 2.402898679505875

Epoch: 6| Step: 5
Training loss: 2.6472623575411904
Validation loss: 2.358558064596946

Epoch: 6| Step: 6
Training loss: 1.534665405387813
Validation loss: 2.4145351931696926

Epoch: 6| Step: 7
Training loss: 1.5817691538775331
Validation loss: 2.4145460761161783

Epoch: 6| Step: 8
Training loss: 1.873752814984895
Validation loss: 2.374567908988595

Epoch: 6| Step: 9
Training loss: 1.3326531801334875
Validation loss: 2.396701406874919

Epoch: 6| Step: 10
Training loss: 1.3473204263417788
Validation loss: 2.3873373963581797

Epoch: 6| Step: 11
Training loss: 1.8691606510568397
Validation loss: 2.386481600905568

Epoch: 6| Step: 12
Training loss: 1.6980718842062856
Validation loss: 2.3743696752598207

Epoch: 6| Step: 13
Training loss: 1.4908183742147265
Validation loss: 2.3565304510462433

Epoch: 552| Step: 0
Training loss: 1.7451520253500128
Validation loss: 2.3564359998259112

Epoch: 6| Step: 1
Training loss: 1.9245560096881773
Validation loss: 2.359305346723337

Epoch: 6| Step: 2
Training loss: 1.6340288076394358
Validation loss: 2.3927159798515247

Epoch: 6| Step: 3
Training loss: 0.9537874327446996
Validation loss: 2.3211677245492046

Epoch: 6| Step: 4
Training loss: 1.4815332616702133
Validation loss: 2.3404875693400267

Epoch: 6| Step: 5
Training loss: 1.569448812398018
Validation loss: 2.3593523773758207

Epoch: 6| Step: 6
Training loss: 2.071459182738572
Validation loss: 2.374590732671249

Epoch: 6| Step: 7
Training loss: 1.559331733546769
Validation loss: 2.391157180174859

Epoch: 6| Step: 8
Training loss: 1.9422266740600016
Validation loss: 2.308028627298208

Epoch: 6| Step: 9
Training loss: 1.6676092899544128
Validation loss: 2.370185051502185

Epoch: 6| Step: 10
Training loss: 1.987215607167352
Validation loss: 2.363401627159203

Epoch: 6| Step: 11
Training loss: 1.7107349432617556
Validation loss: 2.360915000000816

Epoch: 6| Step: 12
Training loss: 1.5533431485211164
Validation loss: 2.4008648567282735

Epoch: 6| Step: 13
Training loss: 1.8550534717225349
Validation loss: 2.390021140989808

Epoch: 553| Step: 0
Training loss: 1.54280425534857
Validation loss: 2.3359634310725244

Epoch: 6| Step: 1
Training loss: 1.6187033804878168
Validation loss: 2.3924591499633827

Epoch: 6| Step: 2
Training loss: 1.3284782388704544
Validation loss: 2.3772356448832705

Epoch: 6| Step: 3
Training loss: 1.4572527924106955
Validation loss: 2.2966567669609015

Epoch: 6| Step: 4
Training loss: 1.729842716410034
Validation loss: 2.3816815437713315

Epoch: 6| Step: 5
Training loss: 1.6600682852384907
Validation loss: 2.374443794322813

Epoch: 6| Step: 6
Training loss: 1.6351054760102888
Validation loss: 2.3567289419512716

Epoch: 6| Step: 7
Training loss: 1.8407501773981798
Validation loss: 2.3287659857176184

Epoch: 6| Step: 8
Training loss: 2.0991703301862565
Validation loss: 2.398266970249284

Epoch: 6| Step: 9
Training loss: 1.164481938724487
Validation loss: 2.3520369425355714

Epoch: 6| Step: 10
Training loss: 1.4912421142676593
Validation loss: 2.3408651578692186

Epoch: 6| Step: 11
Training loss: 2.0667163637810373
Validation loss: 2.348204968292215

Epoch: 6| Step: 12
Training loss: 1.7373290464978284
Validation loss: 2.3870502564809684

Epoch: 6| Step: 13
Training loss: 1.7420131442146753
Validation loss: 2.394926164968563

Epoch: 554| Step: 0
Training loss: 1.7703928754965685
Validation loss: 2.3804903229333156

Epoch: 6| Step: 1
Training loss: 1.6025267140844324
Validation loss: 2.348194239691255

Epoch: 6| Step: 2
Training loss: 1.879413750327978
Validation loss: 2.3992424791447338

Epoch: 6| Step: 3
Training loss: 1.2187688288090064
Validation loss: 2.361127608151343

Epoch: 6| Step: 4
Training loss: 1.638151793306285
Validation loss: 2.3653754925387904

Epoch: 6| Step: 5
Training loss: 1.5199983560402663
Validation loss: 2.3037550964311557

Epoch: 6| Step: 6
Training loss: 1.5959353704010675
Validation loss: 2.344115572075443

Epoch: 6| Step: 7
Training loss: 1.7401426485935638
Validation loss: 2.336536826235432

Epoch: 6| Step: 8
Training loss: 2.0628976149640144
Validation loss: 2.3429324156291718

Epoch: 6| Step: 9
Training loss: 1.5641261984309067
Validation loss: 2.3806008432902312

Epoch: 6| Step: 10
Training loss: 2.1645360765876287
Validation loss: 2.3795306422913693

Epoch: 6| Step: 11
Training loss: 1.7560572698330403
Validation loss: 2.313691978035327

Epoch: 6| Step: 12
Training loss: 1.6818505841725921
Validation loss: 2.37983384835791

Epoch: 6| Step: 13
Training loss: 1.4430006353121791
Validation loss: 2.3879298739667534

Epoch: 555| Step: 0
Training loss: 1.7771024770775135
Validation loss: 2.39062673402579

Epoch: 6| Step: 1
Training loss: 1.9219077502926007
Validation loss: 2.4098376114019766

Epoch: 6| Step: 2
Training loss: 1.31182626053048
Validation loss: 2.38893588405336

Epoch: 6| Step: 3
Training loss: 1.6271050829864437
Validation loss: 2.3377817229501705

Epoch: 6| Step: 4
Training loss: 1.5055084809235757
Validation loss: 2.375620833697245

Epoch: 6| Step: 5
Training loss: 1.5415533213145935
Validation loss: 2.4055815504580074

Epoch: 6| Step: 6
Training loss: 2.219984866082097
Validation loss: 2.3435446744284065

Epoch: 6| Step: 7
Training loss: 1.581711498960994
Validation loss: 2.3198094330007546

Epoch: 6| Step: 8
Training loss: 2.1196819405115157
Validation loss: 2.3717526015826857

Epoch: 6| Step: 9
Training loss: 1.6016556131230915
Validation loss: 2.362941123618309

Epoch: 6| Step: 10
Training loss: 1.5858166277445367
Validation loss: 2.389398877950214

Epoch: 6| Step: 11
Training loss: 1.927394230138604
Validation loss: 2.3369030253592866

Epoch: 6| Step: 12
Training loss: 1.0856969553238318
Validation loss: 2.3317308841729463

Epoch: 6| Step: 13
Training loss: 1.446941715292504
Validation loss: 2.3465279398530705

Epoch: 556| Step: 0
Training loss: 1.3337688132248962
Validation loss: 2.3719808821800816

Epoch: 6| Step: 1
Training loss: 1.4853270037725654
Validation loss: 2.359849015784274

Epoch: 6| Step: 2
Training loss: 1.5841851536399347
Validation loss: 2.3594702136614263

Epoch: 6| Step: 3
Training loss: 1.436838163523418
Validation loss: 2.4012340422052216

Epoch: 6| Step: 4
Training loss: 1.8188205220291447
Validation loss: 2.3531081571162633

Epoch: 6| Step: 5
Training loss: 1.6050389217993197
Validation loss: 2.38711182150412

Epoch: 6| Step: 6
Training loss: 1.2376172906026552
Validation loss: 2.388024971118422

Epoch: 6| Step: 7
Training loss: 1.9202431053988418
Validation loss: 2.368953340102565

Epoch: 6| Step: 8
Training loss: 2.048333150968655
Validation loss: 2.359512253395272

Epoch: 6| Step: 9
Training loss: 2.510447701121196
Validation loss: 2.3642456267444723

Epoch: 6| Step: 10
Training loss: 2.093882314572104
Validation loss: 2.3825492348995225

Epoch: 6| Step: 11
Training loss: 1.704284273424934
Validation loss: 2.3773513783740223

Epoch: 6| Step: 12
Training loss: 1.0002891599297177
Validation loss: 2.3625474146247405

Epoch: 6| Step: 13
Training loss: 1.2753598733790263
Validation loss: 2.375240624613377

Epoch: 557| Step: 0
Training loss: 1.7155138935181375
Validation loss: 2.3639410557062255

Epoch: 6| Step: 1
Training loss: 1.5745890065992996
Validation loss: 2.365213731247676

Epoch: 6| Step: 2
Training loss: 2.3210652475780176
Validation loss: 2.341164230242824

Epoch: 6| Step: 3
Training loss: 1.537382651712203
Validation loss: 2.350116615962679

Epoch: 6| Step: 4
Training loss: 1.7093525691539524
Validation loss: 2.3413670365419947

Epoch: 6| Step: 5
Training loss: 1.528173821104309
Validation loss: 2.4445743850982202

Epoch: 6| Step: 6
Training loss: 1.8648369969987635
Validation loss: 2.3002512169991505

Epoch: 6| Step: 7
Training loss: 2.1965385081638518
Validation loss: 2.3599562140613006

Epoch: 6| Step: 8
Training loss: 1.371443136100973
Validation loss: 2.362440834187847

Epoch: 6| Step: 9
Training loss: 1.6338772017468703
Validation loss: 2.371885313619369

Epoch: 6| Step: 10
Training loss: 1.7832608835114703
Validation loss: 2.341622120744421

Epoch: 6| Step: 11
Training loss: 1.2368815601053473
Validation loss: 2.3510061613065405

Epoch: 6| Step: 12
Training loss: 1.4373893695222177
Validation loss: 2.363186409021066

Epoch: 6| Step: 13
Training loss: 0.8385148646334256
Validation loss: 2.3402301546584914

Epoch: 558| Step: 0
Training loss: 1.4934206356063038
Validation loss: 2.3651998085900963

Epoch: 6| Step: 1
Training loss: 1.274735286758658
Validation loss: 2.399996772630634

Epoch: 6| Step: 2
Training loss: 2.1518791237247874
Validation loss: 2.331197217558027

Epoch: 6| Step: 3
Training loss: 1.7508772286249563
Validation loss: 2.3598327431730937

Epoch: 6| Step: 4
Training loss: 2.2662301143356616
Validation loss: 2.353155853627452

Epoch: 6| Step: 5
Training loss: 1.6446522285380223
Validation loss: 2.3391898953906898

Epoch: 6| Step: 6
Training loss: 1.5550635568319204
Validation loss: 2.330940972170129

Epoch: 6| Step: 7
Training loss: 1.3623186008194081
Validation loss: 2.3722315403223737

Epoch: 6| Step: 8
Training loss: 1.619182590727642
Validation loss: 2.3512069743552115

Epoch: 6| Step: 9
Training loss: 1.737499001043019
Validation loss: 2.3613005366898214

Epoch: 6| Step: 10
Training loss: 1.3358294348482362
Validation loss: 2.3265453881258304

Epoch: 6| Step: 11
Training loss: 1.4080479466283358
Validation loss: 2.358706117557399

Epoch: 6| Step: 12
Training loss: 2.1935078544328253
Validation loss: 2.358220894454847

Epoch: 6| Step: 13
Training loss: 1.527191622833688
Validation loss: 2.3581857789765936

Epoch: 559| Step: 0
Training loss: 1.7261197312113232
Validation loss: 2.3457911899739887

Epoch: 6| Step: 1
Training loss: 1.3365095375026133
Validation loss: 2.302779896388391

Epoch: 6| Step: 2
Training loss: 1.7867560699261578
Validation loss: 2.3846212793912125

Epoch: 6| Step: 3
Training loss: 2.2502265392276035
Validation loss: 2.366462328132987

Epoch: 6| Step: 4
Training loss: 2.0807069499548887
Validation loss: 2.388145937776961

Epoch: 6| Step: 5
Training loss: 1.8434232001906727
Validation loss: 2.4306371019066493

Epoch: 6| Step: 6
Training loss: 1.7352013895963994
Validation loss: 2.360889875610136

Epoch: 6| Step: 7
Training loss: 1.635767330147254
Validation loss: 2.3456678849695374

Epoch: 6| Step: 8
Training loss: 1.4997592573889655
Validation loss: 2.408195783886377

Epoch: 6| Step: 9
Training loss: 1.0635481320793962
Validation loss: 2.3791300512104314

Epoch: 6| Step: 10
Training loss: 1.0801654249232313
Validation loss: 2.4072574008380014

Epoch: 6| Step: 11
Training loss: 1.8727279884879082
Validation loss: 2.322236023778944

Epoch: 6| Step: 12
Training loss: 1.1455321638636102
Validation loss: 2.3851400464759047

Epoch: 6| Step: 13
Training loss: 1.8651801136372819
Validation loss: 2.314035207043187

Epoch: 560| Step: 0
Training loss: 1.4143821397197447
Validation loss: 2.4301248370547857

Epoch: 6| Step: 1
Training loss: 1.7946410514643518
Validation loss: 2.403586957602397

Epoch: 6| Step: 2
Training loss: 1.6005242680881968
Validation loss: 2.3504634511893383

Epoch: 6| Step: 3
Training loss: 1.6128593428856317
Validation loss: 2.3857101812970973

Epoch: 6| Step: 4
Training loss: 1.660065053791147
Validation loss: 2.3517096258167807

Epoch: 6| Step: 5
Training loss: 1.4824112601522137
Validation loss: 2.340132756466185

Epoch: 6| Step: 6
Training loss: 1.3923684667243423
Validation loss: 2.365536932816999

Epoch: 6| Step: 7
Training loss: 1.6890974607563631
Validation loss: 2.3922809203779383

Epoch: 6| Step: 8
Training loss: 1.9355809952608771
Validation loss: 2.3698224278107447

Epoch: 6| Step: 9
Training loss: 1.3893713711765414
Validation loss: 2.335783796404558

Epoch: 6| Step: 10
Training loss: 1.9206304474743132
Validation loss: 2.358013815218537

Epoch: 6| Step: 11
Training loss: 1.9710846636513963
Validation loss: 2.385650733619118

Epoch: 6| Step: 12
Training loss: 1.945941256594091
Validation loss: 2.363439584633439

Epoch: 6| Step: 13
Training loss: 1.5980131687963288
Validation loss: 2.355558887750724

Epoch: 561| Step: 0
Training loss: 1.5868243664554709
Validation loss: 2.377917147033955

Epoch: 6| Step: 1
Training loss: 2.601898721499301
Validation loss: 2.3308108937535166

Epoch: 6| Step: 2
Training loss: 1.7018490132376702
Validation loss: 2.413048392312126

Epoch: 6| Step: 3
Training loss: 1.3096087263078726
Validation loss: 2.3444823052828743

Epoch: 6| Step: 4
Training loss: 1.9227103302072046
Validation loss: 2.4052950969037905

Epoch: 6| Step: 5
Training loss: 1.770814409341861
Validation loss: 2.3922200906558597

Epoch: 6| Step: 6
Training loss: 1.6552463585543162
Validation loss: 2.399730650552254

Epoch: 6| Step: 7
Training loss: 1.388915135877347
Validation loss: 2.351200097502042

Epoch: 6| Step: 8
Training loss: 1.4761657181727752
Validation loss: 2.382819286695176

Epoch: 6| Step: 9
Training loss: 1.7523709992778662
Validation loss: 2.31432561696661

Epoch: 6| Step: 10
Training loss: 1.2766605615013364
Validation loss: 2.3962905989577723

Epoch: 6| Step: 11
Training loss: 1.2945633473903446
Validation loss: 2.3796202101147577

Epoch: 6| Step: 12
Training loss: 1.7616280745962147
Validation loss: 2.343456450643323

Epoch: 6| Step: 13
Training loss: 1.152377422293391
Validation loss: 2.3693473712249453

Epoch: 562| Step: 0
Training loss: 1.6638783814203366
Validation loss: 2.3649988330244245

Epoch: 6| Step: 1
Training loss: 1.9639104063494037
Validation loss: 2.3716495263480217

Epoch: 6| Step: 2
Training loss: 1.6215253508189098
Validation loss: 2.4176610036837642

Epoch: 6| Step: 3
Training loss: 1.777795017509847
Validation loss: 2.3901785703726346

Epoch: 6| Step: 4
Training loss: 1.646267660592253
Validation loss: 2.348795269851724

Epoch: 6| Step: 5
Training loss: 1.5814219867521462
Validation loss: 2.338050215841669

Epoch: 6| Step: 6
Training loss: 2.0390347884476507
Validation loss: 2.353885646022101

Epoch: 6| Step: 7
Training loss: 1.3421464267614507
Validation loss: 2.373578590205115

Epoch: 6| Step: 8
Training loss: 1.3197046268769075
Validation loss: 2.3609599452535366

Epoch: 6| Step: 9
Training loss: 1.5185537454780036
Validation loss: 2.3512262808467064

Epoch: 6| Step: 10
Training loss: 1.3278201033728483
Validation loss: 2.3376301990919464

Epoch: 6| Step: 11
Training loss: 2.353009257313375
Validation loss: 2.360400571282125

Epoch: 6| Step: 12
Training loss: 1.3067539319916488
Validation loss: 2.3345407860803427

Epoch: 6| Step: 13
Training loss: 1.4846446545263359
Validation loss: 2.360997262253182

Epoch: 563| Step: 0
Training loss: 1.4128015702636347
Validation loss: 2.307908988192678

Epoch: 6| Step: 1
Training loss: 1.4721080457850115
Validation loss: 2.3285443256691605

Epoch: 6| Step: 2
Training loss: 1.554984902924972
Validation loss: 2.3706891595754622

Epoch: 6| Step: 3
Training loss: 1.5865436767279
Validation loss: 2.359494724616626

Epoch: 6| Step: 4
Training loss: 2.362388152043247
Validation loss: 2.3788326493234826

Epoch: 6| Step: 5
Training loss: 1.3384724263887557
Validation loss: 2.4000445723667414

Epoch: 6| Step: 6
Training loss: 1.801782888015719
Validation loss: 2.3650527913799295

Epoch: 6| Step: 7
Training loss: 1.5680369120457087
Validation loss: 2.385662347959873

Epoch: 6| Step: 8
Training loss: 1.7160631853577353
Validation loss: 2.324043384918659

Epoch: 6| Step: 9
Training loss: 1.6553336433556818
Validation loss: 2.324699738553808

Epoch: 6| Step: 10
Training loss: 1.6611912272485516
Validation loss: 2.3592053467640666

Epoch: 6| Step: 11
Training loss: 1.7853456225628679
Validation loss: 2.341148999447339

Epoch: 6| Step: 12
Training loss: 1.9485774695834552
Validation loss: 2.3533331861806466

Epoch: 6| Step: 13
Training loss: 1.407046410427569
Validation loss: 2.3536599764924198

Epoch: 564| Step: 0
Training loss: 1.543038745692806
Validation loss: 2.409058235036375

Epoch: 6| Step: 1
Training loss: 1.6545335764701525
Validation loss: 2.352768774190875

Epoch: 6| Step: 2
Training loss: 2.6454485115285156
Validation loss: 2.321477034368418

Epoch: 6| Step: 3
Training loss: 1.7945637309315599
Validation loss: 2.402390463663578

Epoch: 6| Step: 4
Training loss: 1.3810797141905125
Validation loss: 2.3616724865401446

Epoch: 6| Step: 5
Training loss: 1.2580171975323347
Validation loss: 2.3846975051097408

Epoch: 6| Step: 6
Training loss: 1.468772157542515
Validation loss: 2.3528187597586645

Epoch: 6| Step: 7
Training loss: 1.4632961388526518
Validation loss: 2.39442872278911

Epoch: 6| Step: 8
Training loss: 1.5406468171283008
Validation loss: 2.416991413207897

Epoch: 6| Step: 9
Training loss: 1.6137748498872264
Validation loss: 2.364476840962434

Epoch: 6| Step: 10
Training loss: 1.6944932496315455
Validation loss: 2.3794957176620586

Epoch: 6| Step: 11
Training loss: 1.8720407657749187
Validation loss: 2.37108099822291

Epoch: 6| Step: 12
Training loss: 1.199329930224493
Validation loss: 2.3214970753805595

Epoch: 6| Step: 13
Training loss: 1.5998967882483812
Validation loss: 2.3830181138685207

Epoch: 565| Step: 0
Training loss: 1.1276905417305896
Validation loss: 2.37910935238938

Epoch: 6| Step: 1
Training loss: 1.6060986547750544
Validation loss: 2.374391498342781

Epoch: 6| Step: 2
Training loss: 1.2430452947826505
Validation loss: 2.3830029332670715

Epoch: 6| Step: 3
Training loss: 1.324388746304572
Validation loss: 2.3520106044462143

Epoch: 6| Step: 4
Training loss: 0.9748116629214715
Validation loss: 2.331889389872803

Epoch: 6| Step: 5
Training loss: 2.5553312744555634
Validation loss: 2.3720060874193214

Epoch: 6| Step: 6
Training loss: 1.7517835520115332
Validation loss: 2.401469057658179

Epoch: 6| Step: 7
Training loss: 1.761789933688684
Validation loss: 2.4293220613704225

Epoch: 6| Step: 8
Training loss: 1.7406534189202008
Validation loss: 2.3557814725150594

Epoch: 6| Step: 9
Training loss: 1.584672094175047
Validation loss: 2.3919608244355284

Epoch: 6| Step: 10
Training loss: 1.9566394162378977
Validation loss: 2.3884497385376315

Epoch: 6| Step: 11
Training loss: 1.3856221335884285
Validation loss: 2.3949409906084598

Epoch: 6| Step: 12
Training loss: 1.8912264915361692
Validation loss: 2.3631817773617194

Epoch: 6| Step: 13
Training loss: 1.6126715960611924
Validation loss: 2.3442053841262287

Epoch: 566| Step: 0
Training loss: 1.9062249854275752
Validation loss: 2.369270390880816

Epoch: 6| Step: 1
Training loss: 1.4263557844190655
Validation loss: 2.363497812099303

Epoch: 6| Step: 2
Training loss: 1.5529728160574254
Validation loss: 2.342227472438982

Epoch: 6| Step: 3
Training loss: 1.6459229440880172
Validation loss: 2.3762178941423215

Epoch: 6| Step: 4
Training loss: 1.6518172920183811
Validation loss: 2.375890303718307

Epoch: 6| Step: 5
Training loss: 1.4555091577921273
Validation loss: 2.352815670729413

Epoch: 6| Step: 6
Training loss: 1.6187262838975545
Validation loss: 2.3604515839523166

Epoch: 6| Step: 7
Training loss: 1.4268100319039405
Validation loss: 2.387749879402545

Epoch: 6| Step: 8
Training loss: 1.8374815596089873
Validation loss: 2.3880360081589824

Epoch: 6| Step: 9
Training loss: 1.369334774427637
Validation loss: 2.3420113298027494

Epoch: 6| Step: 10
Training loss: 2.544159641133302
Validation loss: 2.370627855839174

Epoch: 6| Step: 11
Training loss: 1.4836288182843191
Validation loss: 2.37291808702849

Epoch: 6| Step: 12
Training loss: 1.462363052477177
Validation loss: 2.380773272131716

Epoch: 6| Step: 13
Training loss: 1.3205033565017814
Validation loss: 2.3865654047567766

Epoch: 567| Step: 0
Training loss: 1.4332639226445163
Validation loss: 2.299332091979533

Epoch: 6| Step: 1
Training loss: 1.6889952640049215
Validation loss: 2.333377123200593

Epoch: 6| Step: 2
Training loss: 1.708968052377408
Validation loss: 2.3396740041606217

Epoch: 6| Step: 3
Training loss: 1.3969705655649989
Validation loss: 2.412408972027105

Epoch: 6| Step: 4
Training loss: 1.5375805996493617
Validation loss: 2.3938198854675146

Epoch: 6| Step: 5
Training loss: 1.8458458577829786
Validation loss: 2.384966478982236

Epoch: 6| Step: 6
Training loss: 1.7430543667340457
Validation loss: 2.3873024863354484

Epoch: 6| Step: 7
Training loss: 2.245676761564683
Validation loss: 2.3415420840953436

Epoch: 6| Step: 8
Training loss: 1.3113895441648145
Validation loss: 2.351070045192584

Epoch: 6| Step: 9
Training loss: 1.844145522285848
Validation loss: 2.318687042256388

Epoch: 6| Step: 10
Training loss: 1.9585631080181205
Validation loss: 2.344078328642236

Epoch: 6| Step: 11
Training loss: 1.800378452358367
Validation loss: 2.3817494420789873

Epoch: 6| Step: 12
Training loss: 1.3657853265921225
Validation loss: 2.406016802611365

Epoch: 6| Step: 13
Training loss: 1.313952595835475
Validation loss: 2.348938536805557

Epoch: 568| Step: 0
Training loss: 2.3223676731284164
Validation loss: 2.3358015129972767

Epoch: 6| Step: 1
Training loss: 1.5754554755996515
Validation loss: 2.343294047096335

Epoch: 6| Step: 2
Training loss: 1.469350489156808
Validation loss: 2.3714548950145593

Epoch: 6| Step: 3
Training loss: 1.970791439500957
Validation loss: 2.3134199816251266

Epoch: 6| Step: 4
Training loss: 1.4262467969880175
Validation loss: 2.3785580987958395

Epoch: 6| Step: 5
Training loss: 1.7588591447811903
Validation loss: 2.2581526766177933

Epoch: 6| Step: 6
Training loss: 1.661685445762946
Validation loss: 2.3220386671414905

Epoch: 6| Step: 7
Training loss: 1.3475421359634814
Validation loss: 2.3692469716752504

Epoch: 6| Step: 8
Training loss: 1.1281304779342418
Validation loss: 2.3335409156326024

Epoch: 6| Step: 9
Training loss: 1.6992292732702163
Validation loss: 2.3456500516336543

Epoch: 6| Step: 10
Training loss: 1.976553815136552
Validation loss: 2.3792064345407287

Epoch: 6| Step: 11
Training loss: 1.429541908730604
Validation loss: 2.3469354892436227

Epoch: 6| Step: 12
Training loss: 1.3550418764238183
Validation loss: 2.305846177033452

Epoch: 6| Step: 13
Training loss: 1.7996363113470724
Validation loss: 2.3417982018151493

Epoch: 569| Step: 0
Training loss: 1.6670712774607215
Validation loss: 2.3936909942093068

Epoch: 6| Step: 1
Training loss: 1.5029087474174754
Validation loss: 2.3084097976817133

Epoch: 6| Step: 2
Training loss: 1.7125529844900182
Validation loss: 2.4096432048038245

Epoch: 6| Step: 3
Training loss: 1.4311087792702022
Validation loss: 2.3642076388370787

Epoch: 6| Step: 4
Training loss: 1.692857362104497
Validation loss: 2.406174682921502

Epoch: 6| Step: 5
Training loss: 1.7274565992410207
Validation loss: 2.401386052551526

Epoch: 6| Step: 6
Training loss: 2.3647056133453197
Validation loss: 2.355918990762204

Epoch: 6| Step: 7
Training loss: 1.6088112149155467
Validation loss: 2.3481410861579914

Epoch: 6| Step: 8
Training loss: 1.5081388288386388
Validation loss: 2.3450666944394754

Epoch: 6| Step: 9
Training loss: 1.279500604379682
Validation loss: 2.310992704458442

Epoch: 6| Step: 10
Training loss: 1.6346808882141874
Validation loss: 2.377944236384571

Epoch: 6| Step: 11
Training loss: 1.9141190501053151
Validation loss: 2.3780771726274503

Epoch: 6| Step: 12
Training loss: 1.3653326913253447
Validation loss: 2.3502684790455626

Epoch: 6| Step: 13
Training loss: 1.5969780786021348
Validation loss: 2.377602988503623

Epoch: 570| Step: 0
Training loss: 1.8339312040931186
Validation loss: 2.2991380395412304

Epoch: 6| Step: 1
Training loss: 1.5769121400478912
Validation loss: 2.362682569691349

Epoch: 6| Step: 2
Training loss: 1.364779329662943
Validation loss: 2.3595424245806744

Epoch: 6| Step: 3
Training loss: 1.6639180725176288
Validation loss: 2.389079340161653

Epoch: 6| Step: 4
Training loss: 1.3553759628330475
Validation loss: 2.3661858157113946

Epoch: 6| Step: 5
Training loss: 1.5519057648060126
Validation loss: 2.401814970162077

Epoch: 6| Step: 6
Training loss: 2.3973570138817575
Validation loss: 2.3439060654174844

Epoch: 6| Step: 7
Training loss: 1.8701636565089899
Validation loss: 2.358202875572064

Epoch: 6| Step: 8
Training loss: 1.3359038588543446
Validation loss: 2.3619935189404524

Epoch: 6| Step: 9
Training loss: 1.6112828473752228
Validation loss: 2.333043704171482

Epoch: 6| Step: 10
Training loss: 1.3294228439437819
Validation loss: 2.384954502766173

Epoch: 6| Step: 11
Training loss: 1.6796432134423342
Validation loss: 2.35806157775455

Epoch: 6| Step: 12
Training loss: 1.6373456605582855
Validation loss: 2.353272217945799

Epoch: 6| Step: 13
Training loss: 1.1606652270418982
Validation loss: 2.4037910664369946

Epoch: 571| Step: 0
Training loss: 1.7342441268894038
Validation loss: 2.413671516891199

Epoch: 6| Step: 1
Training loss: 1.3461719687258533
Validation loss: 2.3692943714270083

Epoch: 6| Step: 2
Training loss: 1.351081806764019
Validation loss: 2.3434337509252163

Epoch: 6| Step: 3
Training loss: 1.8494067297582746
Validation loss: 2.334380030073032

Epoch: 6| Step: 4
Training loss: 2.2194730628179986
Validation loss: 2.3578321919832295

Epoch: 6| Step: 5
Training loss: 1.9604978030444684
Validation loss: 2.3297242907304967

Epoch: 6| Step: 6
Training loss: 1.1067777506294252
Validation loss: 2.4021484999968847

Epoch: 6| Step: 7
Training loss: 1.8262558208897626
Validation loss: 2.4169348234510455

Epoch: 6| Step: 8
Training loss: 1.6424759369224076
Validation loss: 2.3771633599512145

Epoch: 6| Step: 9
Training loss: 1.5402829515931895
Validation loss: 2.401181593013221

Epoch: 6| Step: 10
Training loss: 1.452870336387755
Validation loss: 2.362894948820049

Epoch: 6| Step: 11
Training loss: 2.0565770964487804
Validation loss: 2.4098859020986034

Epoch: 6| Step: 12
Training loss: 1.1535705243309151
Validation loss: 2.344798582402691

Epoch: 6| Step: 13
Training loss: 1.700987918687512
Validation loss: 2.3900512118247623

Epoch: 572| Step: 0
Training loss: 1.6025198703432575
Validation loss: 2.351704894700563

Epoch: 6| Step: 1
Training loss: 1.459558662440542
Validation loss: 2.3150954233494434

Epoch: 6| Step: 2
Training loss: 1.4201351042398866
Validation loss: 2.3912544963232985

Epoch: 6| Step: 3
Training loss: 1.8097439562700186
Validation loss: 2.3489777555309166

Epoch: 6| Step: 4
Training loss: 1.4620971157366178
Validation loss: 2.3192750217488567

Epoch: 6| Step: 5
Training loss: 1.4927278508970991
Validation loss: 2.3346258581365817

Epoch: 6| Step: 6
Training loss: 1.897864612433586
Validation loss: 2.316047397594742

Epoch: 6| Step: 7
Training loss: 1.5003515467362791
Validation loss: 2.3600573015982182

Epoch: 6| Step: 8
Training loss: 1.4347582668631937
Validation loss: 2.400857638397471

Epoch: 6| Step: 9
Training loss: 2.220466916582348
Validation loss: 2.327220397717663

Epoch: 6| Step: 10
Training loss: 1.5689114065838723
Validation loss: 2.3271590637328234

Epoch: 6| Step: 11
Training loss: 1.335931342930576
Validation loss: 2.3309204415384794

Epoch: 6| Step: 12
Training loss: 1.6230085347739163
Validation loss: 2.3892997614281244

Epoch: 6| Step: 13
Training loss: 2.4299737203613394
Validation loss: 2.3523263968430803

Epoch: 573| Step: 0
Training loss: 1.7009208485231386
Validation loss: 2.384625244255103

Epoch: 6| Step: 1
Training loss: 1.7189989776608288
Validation loss: 2.351355670618345

Epoch: 6| Step: 2
Training loss: 1.6941019121971121
Validation loss: 2.358118038756289

Epoch: 6| Step: 3
Training loss: 1.5834236704838074
Validation loss: 2.3649292787166845

Epoch: 6| Step: 4
Training loss: 2.07218669773409
Validation loss: 2.3106394197501

Epoch: 6| Step: 5
Training loss: 1.5837742375639556
Validation loss: 2.35954861218473

Epoch: 6| Step: 6
Training loss: 1.8359606152966381
Validation loss: 2.3757012621322575

Epoch: 6| Step: 7
Training loss: 1.599514652191049
Validation loss: 2.386779842377259

Epoch: 6| Step: 8
Training loss: 1.6225796794870135
Validation loss: 2.3345369294275042

Epoch: 6| Step: 9
Training loss: 1.8231458755987597
Validation loss: 2.4195234003789023

Epoch: 6| Step: 10
Training loss: 1.8735152405810456
Validation loss: 2.356324044677139

Epoch: 6| Step: 11
Training loss: 1.4367838195038378
Validation loss: 2.2938931600221864

Epoch: 6| Step: 12
Training loss: 1.1726595985928987
Validation loss: 2.3434114666989103

Epoch: 6| Step: 13
Training loss: 1.1967079643643062
Validation loss: 2.392250745222642

Epoch: 574| Step: 0
Training loss: 2.163254018758896
Validation loss: 2.395893883352409

Epoch: 6| Step: 1
Training loss: 1.303489683428677
Validation loss: 2.363488923123647

Epoch: 6| Step: 2
Training loss: 1.6808299592866385
Validation loss: 2.335899232814398

Epoch: 6| Step: 3
Training loss: 1.4972113277264625
Validation loss: 2.3409285059104055

Epoch: 6| Step: 4
Training loss: 1.6559092333055376
Validation loss: 2.351662852755277

Epoch: 6| Step: 5
Training loss: 1.4542478099725846
Validation loss: 2.3355538252086823

Epoch: 6| Step: 6
Training loss: 1.082796562925252
Validation loss: 2.4161007419736986

Epoch: 6| Step: 7
Training loss: 1.6101090322028053
Validation loss: 2.4099458050896603

Epoch: 6| Step: 8
Training loss: 1.2789034405900581
Validation loss: 2.375501453459381

Epoch: 6| Step: 9
Training loss: 2.3352021045336855
Validation loss: 2.417013669764252

Epoch: 6| Step: 10
Training loss: 1.3988682174156863
Validation loss: 2.355672609636271

Epoch: 6| Step: 11
Training loss: 1.2814775125358981
Validation loss: 2.3377881392210424

Epoch: 6| Step: 12
Training loss: 1.775579830616973
Validation loss: 2.344633734021832

Epoch: 6| Step: 13
Training loss: 1.5544692609955744
Validation loss: 2.315767644083182

Epoch: 575| Step: 0
Training loss: 1.4197765417639112
Validation loss: 2.3999650147453466

Epoch: 6| Step: 1
Training loss: 2.05144311306221
Validation loss: 2.3546020815892645

Epoch: 6| Step: 2
Training loss: 1.845034459006792
Validation loss: 2.3938264256972404

Epoch: 6| Step: 3
Training loss: 1.0709026408247801
Validation loss: 2.387560945212008

Epoch: 6| Step: 4
Training loss: 1.7221735063793164
Validation loss: 2.343762676245752

Epoch: 6| Step: 5
Training loss: 1.127443362333865
Validation loss: 2.361392750149994

Epoch: 6| Step: 6
Training loss: 1.668060800482538
Validation loss: 2.3764701464000764

Epoch: 6| Step: 7
Training loss: 1.7270356647583778
Validation loss: 2.3347542383663784

Epoch: 6| Step: 8
Training loss: 1.642778345848355
Validation loss: 2.3753266663085877

Epoch: 6| Step: 9
Training loss: 1.3098950648321346
Validation loss: 2.354163834590735

Epoch: 6| Step: 10
Training loss: 1.1547880983214371
Validation loss: 2.3540998887342734

Epoch: 6| Step: 11
Training loss: 1.6375910726366334
Validation loss: 2.3334748236947966

Epoch: 6| Step: 12
Training loss: 2.5944698208156223
Validation loss: 2.3773523780135335

Epoch: 6| Step: 13
Training loss: 1.3036086595970449
Validation loss: 2.358868782660173

Epoch: 576| Step: 0
Training loss: 1.589975562477651
Validation loss: 2.343132218735256

Epoch: 6| Step: 1
Training loss: 1.639018552934656
Validation loss: 2.3581628215212795

Epoch: 6| Step: 2
Training loss: 1.6718558194495188
Validation loss: 2.379411682321771

Epoch: 6| Step: 3
Training loss: 1.6422057756011348
Validation loss: 2.355494008943835

Epoch: 6| Step: 4
Training loss: 1.7354131117742733
Validation loss: 2.388472216510977

Epoch: 6| Step: 5
Training loss: 1.3527522500928342
Validation loss: 2.395832288259427

Epoch: 6| Step: 6
Training loss: 1.6241765503495371
Validation loss: 2.3705394795969736

Epoch: 6| Step: 7
Training loss: 1.5190000414568938
Validation loss: 2.373064911888288

Epoch: 6| Step: 8
Training loss: 2.1074878304018148
Validation loss: 2.3698890486628033

Epoch: 6| Step: 9
Training loss: 1.6107527381770679
Validation loss: 2.381439335127252

Epoch: 6| Step: 10
Training loss: 1.2795407594193957
Validation loss: 2.35702810171056

Epoch: 6| Step: 11
Training loss: 1.757339278207216
Validation loss: 2.346054850378515

Epoch: 6| Step: 12
Training loss: 1.3838334705708473
Validation loss: 2.3531351878000364

Epoch: 6| Step: 13
Training loss: 1.656433167315788
Validation loss: 2.3439282093181704

Epoch: 577| Step: 0
Training loss: 1.677179780007299
Validation loss: 2.375022092542672

Epoch: 6| Step: 1
Training loss: 1.321074632611229
Validation loss: 2.3990764589175595

Epoch: 6| Step: 2
Training loss: 1.0688559094873227
Validation loss: 2.3480594822361702

Epoch: 6| Step: 3
Training loss: 0.9944108696875178
Validation loss: 2.402998267824719

Epoch: 6| Step: 4
Training loss: 2.4129341723066657
Validation loss: 2.360188611817028

Epoch: 6| Step: 5
Training loss: 1.704759425980678
Validation loss: 2.4043230913501157

Epoch: 6| Step: 6
Training loss: 1.73634501428618
Validation loss: 2.354748325071421

Epoch: 6| Step: 7
Training loss: 1.8339126784150306
Validation loss: 2.4352265018556696

Epoch: 6| Step: 8
Training loss: 2.016786935335883
Validation loss: 2.3858324279585155

Epoch: 6| Step: 9
Training loss: 1.1742552933682249
Validation loss: 2.3981938579243653

Epoch: 6| Step: 10
Training loss: 1.5263100953264173
Validation loss: 2.3722790598309276

Epoch: 6| Step: 11
Training loss: 1.3653256190729015
Validation loss: 2.399709494844936

Epoch: 6| Step: 12
Training loss: 1.9308082939613103
Validation loss: 2.380164278068367

Epoch: 6| Step: 13
Training loss: 1.358442490917135
Validation loss: 2.3241047586593795

Epoch: 578| Step: 0
Training loss: 1.3616049004922668
Validation loss: 2.3570391501153387

Epoch: 6| Step: 1
Training loss: 2.029879768080802
Validation loss: 2.3525053328267886

Epoch: 6| Step: 2
Training loss: 1.41540067802759
Validation loss: 2.370069703608397

Epoch: 6| Step: 3
Training loss: 1.5788796008775916
Validation loss: 2.364957179167684

Epoch: 6| Step: 4
Training loss: 1.3094869269919767
Validation loss: 2.3558796514519016

Epoch: 6| Step: 5
Training loss: 1.4304583196504546
Validation loss: 2.3504498261778015

Epoch: 6| Step: 6
Training loss: 1.777051427926704
Validation loss: 2.3920823926338457

Epoch: 6| Step: 7
Training loss: 2.3185978471956417
Validation loss: 2.3074031969451116

Epoch: 6| Step: 8
Training loss: 1.3395488625813243
Validation loss: 2.3579054392059713

Epoch: 6| Step: 9
Training loss: 1.546353955609864
Validation loss: 2.368541286961102

Epoch: 6| Step: 10
Training loss: 1.142375386827518
Validation loss: 2.3583645171503957

Epoch: 6| Step: 11
Training loss: 1.8035885325784906
Validation loss: 2.355329835116658

Epoch: 6| Step: 12
Training loss: 1.4253081072284006
Validation loss: 2.3079485697817708

Epoch: 6| Step: 13
Training loss: 1.862375483094899
Validation loss: 2.3128733623166684

Epoch: 579| Step: 0
Training loss: 1.4777793109060444
Validation loss: 2.367881503952285

Epoch: 6| Step: 1
Training loss: 0.951002979362145
Validation loss: 2.326343211047652

Epoch: 6| Step: 2
Training loss: 2.238920589829451
Validation loss: 2.3395437560194163

Epoch: 6| Step: 3
Training loss: 2.078189475988152
Validation loss: 2.3689720152580938

Epoch: 6| Step: 4
Training loss: 1.1351843371660961
Validation loss: 2.3378380289369938

Epoch: 6| Step: 5
Training loss: 1.4637357463191538
Validation loss: 2.3982807340806302

Epoch: 6| Step: 6
Training loss: 1.7235141270221495
Validation loss: 2.3466513523382146

Epoch: 6| Step: 7
Training loss: 1.2947841933575144
Validation loss: 2.417668781562377

Epoch: 6| Step: 8
Training loss: 2.5480834340758385
Validation loss: 2.4434784269313554

Epoch: 6| Step: 9
Training loss: 1.4311721680646756
Validation loss: 2.38210786043057

Epoch: 6| Step: 10
Training loss: 1.2733839526941604
Validation loss: 2.3460719435860953

Epoch: 6| Step: 11
Training loss: 1.591003070260088
Validation loss: 2.3703846204619823

Epoch: 6| Step: 12
Training loss: 1.3244918496618077
Validation loss: 2.412420231191477

Epoch: 6| Step: 13
Training loss: 1.7787928448340362
Validation loss: 2.4353535343332346

Epoch: 580| Step: 0
Training loss: 1.5614179297630402
Validation loss: 2.3833877952951

Epoch: 6| Step: 1
Training loss: 1.4274455351051152
Validation loss: 2.395652406414058

Epoch: 6| Step: 2
Training loss: 1.4260351503649178
Validation loss: 2.434542179971403

Epoch: 6| Step: 3
Training loss: 1.1771998164963264
Validation loss: 2.3260201977219923

Epoch: 6| Step: 4
Training loss: 1.486250485611845
Validation loss: 2.369460814345167

Epoch: 6| Step: 5
Training loss: 0.9811349254606209
Validation loss: 2.339696788019359

Epoch: 6| Step: 6
Training loss: 1.8157473445779952
Validation loss: 2.323480748843239

Epoch: 6| Step: 7
Training loss: 1.6435168256835497
Validation loss: 2.3279061730428214

Epoch: 6| Step: 8
Training loss: 1.7819209926400301
Validation loss: 2.3155236601860723

Epoch: 6| Step: 9
Training loss: 2.4319627908445156
Validation loss: 2.3548781285180356

Epoch: 6| Step: 10
Training loss: 1.8588495874566726
Validation loss: 2.3757115082502063

Epoch: 6| Step: 11
Training loss: 1.8526896333610432
Validation loss: 2.3597212816237443

Epoch: 6| Step: 12
Training loss: 1.3508164656611819
Validation loss: 2.3627388953122552

Epoch: 6| Step: 13
Training loss: 1.6636056765489526
Validation loss: 2.355864251905068

Epoch: 581| Step: 0
Training loss: 1.475350664772755
Validation loss: 2.3566489212212294

Epoch: 6| Step: 1
Training loss: 1.1276385835794207
Validation loss: 2.373203028467583

Epoch: 6| Step: 2
Training loss: 1.46521357636219
Validation loss: 2.39232861602229

Epoch: 6| Step: 3
Training loss: 1.4669163397484688
Validation loss: 2.3359102604306323

Epoch: 6| Step: 4
Training loss: 1.5220617097532936
Validation loss: 2.3813001330757495

Epoch: 6| Step: 5
Training loss: 1.7842124263639005
Validation loss: 2.3808984862364455

Epoch: 6| Step: 6
Training loss: 1.0992472240281943
Validation loss: 2.361129698256944

Epoch: 6| Step: 7
Training loss: 1.7938853727823227
Validation loss: 2.3359490020926423

Epoch: 6| Step: 8
Training loss: 1.2557186920011831
Validation loss: 2.3731671791872246

Epoch: 6| Step: 9
Training loss: 1.9412018267272555
Validation loss: 2.4258888256047477

Epoch: 6| Step: 10
Training loss: 1.4919347099561604
Validation loss: 2.396355935159713

Epoch: 6| Step: 11
Training loss: 1.6668167602983535
Validation loss: 2.3584892192803064

Epoch: 6| Step: 12
Training loss: 2.164257274910253
Validation loss: 2.3371709725731415

Epoch: 6| Step: 13
Training loss: 1.1666127374082849
Validation loss: 2.3449065769507866

Epoch: 582| Step: 0
Training loss: 1.623750793362865
Validation loss: 2.3505082734515885

Epoch: 6| Step: 1
Training loss: 1.3730964054816555
Validation loss: 2.417545284239012

Epoch: 6| Step: 2
Training loss: 1.3722847224599821
Validation loss: 2.391543835977387

Epoch: 6| Step: 3
Training loss: 1.734924847846843
Validation loss: 2.384204979301565

Epoch: 6| Step: 4
Training loss: 1.732446577891628
Validation loss: 2.444293457234766

Epoch: 6| Step: 5
Training loss: 1.4824927191209756
Validation loss: 2.391950868709173

Epoch: 6| Step: 6
Training loss: 1.3893829971474572
Validation loss: 2.3585012135775156

Epoch: 6| Step: 7
Training loss: 1.318393644664548
Validation loss: 2.349652281811901

Epoch: 6| Step: 8
Training loss: 1.8316824444735442
Validation loss: 2.371543951685101

Epoch: 6| Step: 9
Training loss: 1.6307938796728776
Validation loss: 2.364847167876086

Epoch: 6| Step: 10
Training loss: 1.4129667304321016
Validation loss: 2.2959294479949506

Epoch: 6| Step: 11
Training loss: 2.012375926108479
Validation loss: 2.3667675344170793

Epoch: 6| Step: 12
Training loss: 2.0468492579115436
Validation loss: 2.364204949092697

Epoch: 6| Step: 13
Training loss: 1.3712548924709174
Validation loss: 2.352675233837124

Epoch: 583| Step: 0
Training loss: 1.5415663901356706
Validation loss: 2.3853936411667935

Epoch: 6| Step: 1
Training loss: 1.6036294392607493
Validation loss: 2.4156337867405826

Epoch: 6| Step: 2
Training loss: 1.4844284048010206
Validation loss: 2.363400265829039

Epoch: 6| Step: 3
Training loss: 1.6201943717722227
Validation loss: 2.3089556861010716

Epoch: 6| Step: 4
Training loss: 1.532136932727438
Validation loss: 2.3124725564105915

Epoch: 6| Step: 5
Training loss: 1.8141709879290882
Validation loss: 2.382663183511564

Epoch: 6| Step: 6
Training loss: 1.4842987040939075
Validation loss: 2.34590962766996

Epoch: 6| Step: 7
Training loss: 2.094992766993744
Validation loss: 2.3624788743781657

Epoch: 6| Step: 8
Training loss: 1.4574805173013423
Validation loss: 2.3898173960084335

Epoch: 6| Step: 9
Training loss: 1.5041552845250385
Validation loss: 2.340798911314101

Epoch: 6| Step: 10
Training loss: 1.6279563421070729
Validation loss: 2.3224024940032053

Epoch: 6| Step: 11
Training loss: 1.7230891853625863
Validation loss: 2.411629653834183

Epoch: 6| Step: 12
Training loss: 1.350724903385419
Validation loss: 2.3627825640779325

Epoch: 6| Step: 13
Training loss: 2.03675483697982
Validation loss: 2.38502960048864

Epoch: 584| Step: 0
Training loss: 1.7118779215068756
Validation loss: 2.430920765906953

Epoch: 6| Step: 1
Training loss: 1.6037992907209406
Validation loss: 2.2830995183389637

Epoch: 6| Step: 2
Training loss: 1.0919869518478604
Validation loss: 2.337501315479041

Epoch: 6| Step: 3
Training loss: 1.556623930225328
Validation loss: 2.3163832077277284

Epoch: 6| Step: 4
Training loss: 1.011068245453046
Validation loss: 2.3641775233929656

Epoch: 6| Step: 5
Training loss: 1.352436290375686
Validation loss: 2.403184943461865

Epoch: 6| Step: 6
Training loss: 1.4195421805246995
Validation loss: 2.3355074717256024

Epoch: 6| Step: 7
Training loss: 1.2170274249727
Validation loss: 2.4203321705039516

Epoch: 6| Step: 8
Training loss: 2.0747920104426565
Validation loss: 2.3494877025135583

Epoch: 6| Step: 9
Training loss: 2.5851777680770454
Validation loss: 2.366360995276154

Epoch: 6| Step: 10
Training loss: 1.6740325126361904
Validation loss: 2.407335867115484

Epoch: 6| Step: 11
Training loss: 1.664168591766441
Validation loss: 2.383799483566129

Epoch: 6| Step: 12
Training loss: 1.5174756107538558
Validation loss: 2.3732767572822806

Epoch: 6| Step: 13
Training loss: 1.4521517211630661
Validation loss: 2.406189822811004

Epoch: 585| Step: 0
Training loss: 1.8313711315101413
Validation loss: 2.397514791869346

Epoch: 6| Step: 1
Training loss: 1.4004614478255741
Validation loss: 2.337771438895622

Epoch: 6| Step: 2
Training loss: 0.9479838371931117
Validation loss: 2.3009402454506227

Epoch: 6| Step: 3
Training loss: 1.322223025921881
Validation loss: 2.3203688697159115

Epoch: 6| Step: 4
Training loss: 1.150674315415735
Validation loss: 2.3658705751020133

Epoch: 6| Step: 5
Training loss: 1.4312853613070817
Validation loss: 2.3024679150499825

Epoch: 6| Step: 6
Training loss: 2.062337233160777
Validation loss: 2.323570135453989

Epoch: 6| Step: 7
Training loss: 1.8935491474261401
Validation loss: 2.326950737316586

Epoch: 6| Step: 8
Training loss: 2.189652609946631
Validation loss: 2.368164190240131

Epoch: 6| Step: 9
Training loss: 1.7980569020815689
Validation loss: 2.360350773971951

Epoch: 6| Step: 10
Training loss: 1.5661543265407265
Validation loss: 2.3874503596807912

Epoch: 6| Step: 11
Training loss: 1.4825291450298834
Validation loss: 2.338606418696408

Epoch: 6| Step: 12
Training loss: 1.4670662664308955
Validation loss: 2.395211562218168

Epoch: 6| Step: 13
Training loss: 1.8921563748383563
Validation loss: 2.3783445841746786

Epoch: 586| Step: 0
Training loss: 1.5443949228728415
Validation loss: 2.3862710137413923

Epoch: 6| Step: 1
Training loss: 2.2409268866157204
Validation loss: 2.3528583534541823

Epoch: 6| Step: 2
Training loss: 1.5958737453725573
Validation loss: 2.3833091800517665

Epoch: 6| Step: 3
Training loss: 1.350564488966755
Validation loss: 2.3333303792849827

Epoch: 6| Step: 4
Training loss: 1.3027977877943906
Validation loss: 2.369060983465476

Epoch: 6| Step: 5
Training loss: 1.2886640915602368
Validation loss: 2.3193494501675556

Epoch: 6| Step: 6
Training loss: 1.6035123539286065
Validation loss: 2.3729785623917166

Epoch: 6| Step: 7
Training loss: 1.3732746309786468
Validation loss: 2.3405403742165998

Epoch: 6| Step: 8
Training loss: 1.2699579548821998
Validation loss: 2.3583238826370883

Epoch: 6| Step: 9
Training loss: 1.4500254727460993
Validation loss: 2.2969482847711773

Epoch: 6| Step: 10
Training loss: 1.8905396245170045
Validation loss: 2.3777630001996375

Epoch: 6| Step: 11
Training loss: 1.9113589753842637
Validation loss: 2.304613354496396

Epoch: 6| Step: 12
Training loss: 1.8432020245921752
Validation loss: 2.3545903556854704

Epoch: 6| Step: 13
Training loss: 1.2394624485515178
Validation loss: 2.3894472394579114

Epoch: 587| Step: 0
Training loss: 1.0037478904654449
Validation loss: 2.368596959146661

Epoch: 6| Step: 1
Training loss: 1.5130330368136387
Validation loss: 2.3612081958548803

Epoch: 6| Step: 2
Training loss: 1.564762994412723
Validation loss: 2.3781332182536383

Epoch: 6| Step: 3
Training loss: 1.50241260420374
Validation loss: 2.351239933251145

Epoch: 6| Step: 4
Training loss: 1.8351440663134233
Validation loss: 2.35451347728766

Epoch: 6| Step: 5
Training loss: 2.379870289866264
Validation loss: 2.3829254602385905

Epoch: 6| Step: 6
Training loss: 1.0709308592226159
Validation loss: 2.3304250251416816

Epoch: 6| Step: 7
Training loss: 1.7684287032147725
Validation loss: 2.415749543097248

Epoch: 6| Step: 8
Training loss: 1.737309079006535
Validation loss: 2.404711677607603

Epoch: 6| Step: 9
Training loss: 1.517518424058963
Validation loss: 2.385309002435676

Epoch: 6| Step: 10
Training loss: 1.6526783273020602
Validation loss: 2.336259261210774

Epoch: 6| Step: 11
Training loss: 1.2372700024735894
Validation loss: 2.3919946793826865

Epoch: 6| Step: 12
Training loss: 1.391840971045554
Validation loss: 2.3275914957027832

Epoch: 6| Step: 13
Training loss: 1.4724020498239208
Validation loss: 2.4088860519591484

Epoch: 588| Step: 0
Training loss: 1.4581380531717647
Validation loss: 2.312234383261111

Epoch: 6| Step: 1
Training loss: 1.6719859434020616
Validation loss: 2.3673197976230753

Epoch: 6| Step: 2
Training loss: 2.1962272937276124
Validation loss: 2.3355417317242493

Epoch: 6| Step: 3
Training loss: 1.6897998255621791
Validation loss: 2.392695441417933

Epoch: 6| Step: 4
Training loss: 1.3152672795529423
Validation loss: 2.3395653363406606

Epoch: 6| Step: 5
Training loss: 1.2978115606637555
Validation loss: 2.3760855870133604

Epoch: 6| Step: 6
Training loss: 1.8679203526550363
Validation loss: 2.397655079259464

Epoch: 6| Step: 7
Training loss: 2.196392730260964
Validation loss: 2.393290371719049

Epoch: 6| Step: 8
Training loss: 1.249684007758536
Validation loss: 2.3526149595796553

Epoch: 6| Step: 9
Training loss: 1.5912502356541798
Validation loss: 2.4141162526900697

Epoch: 6| Step: 10
Training loss: 1.3348268945311401
Validation loss: 2.3737313833628084

Epoch: 6| Step: 11
Training loss: 1.5577826432989386
Validation loss: 2.377372066620631

Epoch: 6| Step: 12
Training loss: 1.3437506209970858
Validation loss: 2.3283020665749246

Epoch: 6| Step: 13
Training loss: 1.2921815533022598
Validation loss: 2.3424539681161822

Epoch: 589| Step: 0
Training loss: 1.776048058044329
Validation loss: 2.352525231561712

Epoch: 6| Step: 1
Training loss: 1.5762083292814255
Validation loss: 2.335157857420823

Epoch: 6| Step: 2
Training loss: 1.4062810682467572
Validation loss: 2.3065336730423525

Epoch: 6| Step: 3
Training loss: 1.4339049622553928
Validation loss: 2.3453662738340064

Epoch: 6| Step: 4
Training loss: 1.2247171795619778
Validation loss: 2.4160692504117125

Epoch: 6| Step: 5
Training loss: 1.2286533587803254
Validation loss: 2.3809431829289496

Epoch: 6| Step: 6
Training loss: 1.4717435158479313
Validation loss: 2.3817169226047428

Epoch: 6| Step: 7
Training loss: 1.9715579157310563
Validation loss: 2.4052859067492696

Epoch: 6| Step: 8
Training loss: 1.3559895594991065
Validation loss: 2.3681749869626296

Epoch: 6| Step: 9
Training loss: 2.1760851991887673
Validation loss: 2.3623740401868325

Epoch: 6| Step: 10
Training loss: 1.5850675856082745
Validation loss: 2.3581967159634223

Epoch: 6| Step: 11
Training loss: 1.9813237799255419
Validation loss: 2.401777009687522

Epoch: 6| Step: 12
Training loss: 1.0594922296258011
Validation loss: 2.364616275276183

Epoch: 6| Step: 13
Training loss: 1.710795775513944
Validation loss: 2.4150850178951595

Epoch: 590| Step: 0
Training loss: 1.343467904576714
Validation loss: 2.393792129720332

Epoch: 6| Step: 1
Training loss: 1.0138682504118153
Validation loss: 2.3037808344590944

Epoch: 6| Step: 2
Training loss: 1.5561611533177453
Validation loss: 2.319732486349714

Epoch: 6| Step: 3
Training loss: 1.3154234344401767
Validation loss: 2.359218182289746

Epoch: 6| Step: 4
Training loss: 1.6493426545192487
Validation loss: 2.3406954401013396

Epoch: 6| Step: 5
Training loss: 1.7173551968718936
Validation loss: 2.355174539212227

Epoch: 6| Step: 6
Training loss: 1.5920064027647916
Validation loss: 2.40464061948373

Epoch: 6| Step: 7
Training loss: 1.2133728149998013
Validation loss: 2.2815953250538077

Epoch: 6| Step: 8
Training loss: 1.5149136476488565
Validation loss: 2.4063689776846817

Epoch: 6| Step: 9
Training loss: 1.874521448736632
Validation loss: 2.370402014635361

Epoch: 6| Step: 10
Training loss: 1.3310574638578436
Validation loss: 2.3073155823121847

Epoch: 6| Step: 11
Training loss: 1.9588565195183256
Validation loss: 2.371314205210096

Epoch: 6| Step: 12
Training loss: 2.3449812643120125
Validation loss: 2.415498630174065

Epoch: 6| Step: 13
Training loss: 1.2546688149701035
Validation loss: 2.3420327844924276

Epoch: 591| Step: 0
Training loss: 1.4985531345655012
Validation loss: 2.332986522059527

Epoch: 6| Step: 1
Training loss: 2.0928537528700133
Validation loss: 2.36523656769712

Epoch: 6| Step: 2
Training loss: 1.14020133315301
Validation loss: 2.372286167358658

Epoch: 6| Step: 3
Training loss: 1.6126784706414388
Validation loss: 2.333148321238219

Epoch: 6| Step: 4
Training loss: 1.4467019490511608
Validation loss: 2.3412939754330284

Epoch: 6| Step: 5
Training loss: 1.8746457718982072
Validation loss: 2.3148459475029113

Epoch: 6| Step: 6
Training loss: 1.3511661543756737
Validation loss: 2.3314973068726847

Epoch: 6| Step: 7
Training loss: 1.254371105315392
Validation loss: 2.413787290881184

Epoch: 6| Step: 8
Training loss: 1.2533815420970504
Validation loss: 2.376690484756165

Epoch: 6| Step: 9
Training loss: 1.5751623160872927
Validation loss: 2.372728587143591

Epoch: 6| Step: 10
Training loss: 1.1798034004725022
Validation loss: 2.3158976508678095

Epoch: 6| Step: 11
Training loss: 1.482871247585951
Validation loss: 2.3693967284353836

Epoch: 6| Step: 12
Training loss: 1.4405129411851612
Validation loss: 2.374885966526926

Epoch: 6| Step: 13
Training loss: 2.60817073969312
Validation loss: 2.379774960570713

Epoch: 592| Step: 0
Training loss: 1.5668267425300022
Validation loss: 2.384135816489435

Epoch: 6| Step: 1
Training loss: 1.3954961948431739
Validation loss: 2.3924261283016084

Epoch: 6| Step: 2
Training loss: 1.7516233544238156
Validation loss: 2.4008422203546007

Epoch: 6| Step: 3
Training loss: 2.2182881049119936
Validation loss: 2.3900133273054784

Epoch: 6| Step: 4
Training loss: 1.3528236282606458
Validation loss: 2.363965150502169

Epoch: 6| Step: 5
Training loss: 1.366760448789176
Validation loss: 2.3935757112440146

Epoch: 6| Step: 6
Training loss: 1.233935314047268
Validation loss: 2.3391470624412722

Epoch: 6| Step: 7
Training loss: 1.5182747242429964
Validation loss: 2.383912254009947

Epoch: 6| Step: 8
Training loss: 1.5425477817745605
Validation loss: 2.3485479356278574

Epoch: 6| Step: 9
Training loss: 1.3742328584520411
Validation loss: 2.3719197177504534

Epoch: 6| Step: 10
Training loss: 1.6071605075896314
Validation loss: 2.350895084963123

Epoch: 6| Step: 11
Training loss: 1.3959979724104183
Validation loss: 2.309801965021896

Epoch: 6| Step: 12
Training loss: 1.7717683978701981
Validation loss: 2.2986995238565937

Epoch: 6| Step: 13
Training loss: 1.915982898428776
Validation loss: 2.345576266500486

Epoch: 593| Step: 0
Training loss: 1.4279464376325741
Validation loss: 2.378151922653122

Epoch: 6| Step: 1
Training loss: 1.7569802581728837
Validation loss: 2.3404634267231548

Epoch: 6| Step: 2
Training loss: 2.0551745631567133
Validation loss: 2.367450779746919

Epoch: 6| Step: 3
Training loss: 1.687709795308403
Validation loss: 2.4061208018283775

Epoch: 6| Step: 4
Training loss: 1.3703922748724284
Validation loss: 2.359437669621062

Epoch: 6| Step: 5
Training loss: 1.421975100839831
Validation loss: 2.398273126356029

Epoch: 6| Step: 6
Training loss: 1.1383721037183088
Validation loss: 2.347727302089091

Epoch: 6| Step: 7
Training loss: 1.6260011963224057
Validation loss: 2.417413382607715

Epoch: 6| Step: 8
Training loss: 1.829926996494669
Validation loss: 2.3707454074328442

Epoch: 6| Step: 9
Training loss: 1.6842124846409405
Validation loss: 2.3504273772393263

Epoch: 6| Step: 10
Training loss: 1.3309053377814182
Validation loss: 2.3629069158711524

Epoch: 6| Step: 11
Training loss: 0.9876859779512742
Validation loss: 2.3078663372667125

Epoch: 6| Step: 12
Training loss: 1.542022569488729
Validation loss: 2.31561348846795

Epoch: 6| Step: 13
Training loss: 2.5353313556027812
Validation loss: 2.394356911941627

Epoch: 594| Step: 0
Training loss: 1.781720082678025
Validation loss: 2.36680084095441

Epoch: 6| Step: 1
Training loss: 1.1209611980484482
Validation loss: 2.419714686557436

Epoch: 6| Step: 2
Training loss: 1.3286262912526838
Validation loss: 2.3317051699028295

Epoch: 6| Step: 3
Training loss: 2.1560276303829813
Validation loss: 2.381121045077473

Epoch: 6| Step: 4
Training loss: 1.7052379415276162
Validation loss: 2.3381216930631328

Epoch: 6| Step: 5
Training loss: 2.055585657649678
Validation loss: 2.3587983291922803

Epoch: 6| Step: 6
Training loss: 1.7774015647791155
Validation loss: 2.4037550067707087

Epoch: 6| Step: 7
Training loss: 1.488645413918552
Validation loss: 2.3444339686677456

Epoch: 6| Step: 8
Training loss: 1.133632547252255
Validation loss: 2.3292034685223224

Epoch: 6| Step: 9
Training loss: 1.212776362984819
Validation loss: 2.3108860426729176

Epoch: 6| Step: 10
Training loss: 1.6695804715431515
Validation loss: 2.3596395316957817

Epoch: 6| Step: 11
Training loss: 1.4790154321573423
Validation loss: 2.355189318465712

Epoch: 6| Step: 12
Training loss: 1.2037665898179102
Validation loss: 2.360888721320523

Epoch: 6| Step: 13
Training loss: 2.0520968622320006
Validation loss: 2.3241175850739118

Epoch: 595| Step: 0
Training loss: 1.4283559466381728
Validation loss: 2.3330329981534264

Epoch: 6| Step: 1
Training loss: 1.6162576997105935
Validation loss: 2.3414728884642755

Epoch: 6| Step: 2
Training loss: 1.6567001450812637
Validation loss: 2.3734952313265367

Epoch: 6| Step: 3
Training loss: 1.1003245980167269
Validation loss: 2.3957672930403744

Epoch: 6| Step: 4
Training loss: 2.1702954153620206
Validation loss: 2.3359262146037363

Epoch: 6| Step: 5
Training loss: 1.548499054363727
Validation loss: 2.396001337125488

Epoch: 6| Step: 6
Training loss: 1.868453231262959
Validation loss: 2.3665661568496272

Epoch: 6| Step: 7
Training loss: 1.5676210786821971
Validation loss: 2.344950557572945

Epoch: 6| Step: 8
Training loss: 1.290859010924115
Validation loss: 2.3542388489685124

Epoch: 6| Step: 9
Training loss: 1.4089334950938643
Validation loss: 2.364489200899924

Epoch: 6| Step: 10
Training loss: 1.7375571810966586
Validation loss: 2.3404914030433086

Epoch: 6| Step: 11
Training loss: 1.4314982303098132
Validation loss: 2.4051278369905593

Epoch: 6| Step: 12
Training loss: 1.5821478153189203
Validation loss: 2.406412725082988

Epoch: 6| Step: 13
Training loss: 1.2208690805159859
Validation loss: 2.346665530340254

Epoch: 596| Step: 0
Training loss: 1.7665230146820525
Validation loss: 2.3529811285724813

Epoch: 6| Step: 1
Training loss: 1.6417051846524757
Validation loss: 2.365818751702409

Epoch: 6| Step: 2
Training loss: 1.1476945614895884
Validation loss: 2.3468478145848803

Epoch: 6| Step: 3
Training loss: 1.4301173496780246
Validation loss: 2.3620645359059997

Epoch: 6| Step: 4
Training loss: 1.5136907760916694
Validation loss: 2.376356633338864

Epoch: 6| Step: 5
Training loss: 1.6220038008216136
Validation loss: 2.3701093833721134

Epoch: 6| Step: 6
Training loss: 2.0807421273666145
Validation loss: 2.330128604475622

Epoch: 6| Step: 7
Training loss: 1.5149751823583186
Validation loss: 2.3456619011938837

Epoch: 6| Step: 8
Training loss: 1.4209319120573662
Validation loss: 2.3650147286347813

Epoch: 6| Step: 9
Training loss: 1.4906571614696558
Validation loss: 2.365407833498539

Epoch: 6| Step: 10
Training loss: 1.6700220981437863
Validation loss: 2.4460024580578876

Epoch: 6| Step: 11
Training loss: 1.792416622611574
Validation loss: 2.3703926832498814

Epoch: 6| Step: 12
Training loss: 1.3455304172016354
Validation loss: 2.358279008354525

Epoch: 6| Step: 13
Training loss: 1.9795047136690502
Validation loss: 2.3948125836062935

Epoch: 597| Step: 0
Training loss: 1.9259525246121558
Validation loss: 2.3368440683073657

Epoch: 6| Step: 1
Training loss: 1.8814523936545997
Validation loss: 2.379645694263133

Epoch: 6| Step: 2
Training loss: 1.6815614404765393
Validation loss: 2.3904382197205165

Epoch: 6| Step: 3
Training loss: 1.241753172367929
Validation loss: 2.4485446516275124

Epoch: 6| Step: 4
Training loss: 1.6546722670764398
Validation loss: 2.389202632303354

Epoch: 6| Step: 5
Training loss: 1.2888610220003076
Validation loss: 2.37393609587329

Epoch: 6| Step: 6
Training loss: 1.5881397009735478
Validation loss: 2.417831645759359

Epoch: 6| Step: 7
Training loss: 1.257852494451011
Validation loss: 2.413505607046442

Epoch: 6| Step: 8
Training loss: 1.1734558632298908
Validation loss: 2.3630450848112714

Epoch: 6| Step: 9
Training loss: 2.1579259357841347
Validation loss: 2.3820965962856513

Epoch: 6| Step: 10
Training loss: 1.9171925390001654
Validation loss: 2.418174931404769

Epoch: 6| Step: 11
Training loss: 1.2298706054081698
Validation loss: 2.361590363419955

Epoch: 6| Step: 12
Training loss: 1.0462461262292828
Validation loss: 2.330922513637005

Epoch: 6| Step: 13
Training loss: 1.4301103477317592
Validation loss: 2.321710428329696

Epoch: 598| Step: 0
Training loss: 0.9697837236504584
Validation loss: 2.342743516521553

Epoch: 6| Step: 1
Training loss: 1.7824744984861063
Validation loss: 2.3687995450257913

Epoch: 6| Step: 2
Training loss: 1.6695376305464908
Validation loss: 2.331339634436204

Epoch: 6| Step: 3
Training loss: 1.2603705321556895
Validation loss: 2.3912926420623

Epoch: 6| Step: 4
Training loss: 1.7274999360720764
Validation loss: 2.366694530055554

Epoch: 6| Step: 5
Training loss: 1.6899897963311765
Validation loss: 2.361688826260149

Epoch: 6| Step: 6
Training loss: 1.5753363719388371
Validation loss: 2.3537555160947083

Epoch: 6| Step: 7
Training loss: 1.4407850131126467
Validation loss: 2.3995170284191363

Epoch: 6| Step: 8
Training loss: 1.6268400631530169
Validation loss: 2.371424800255925

Epoch: 6| Step: 9
Training loss: 1.2470231372152085
Validation loss: 2.362079820684933

Epoch: 6| Step: 10
Training loss: 1.4212151977250416
Validation loss: 2.3300999074112934

Epoch: 6| Step: 11
Training loss: 2.0057664234944395
Validation loss: 2.3464279473686784

Epoch: 6| Step: 12
Training loss: 1.9395311845050918
Validation loss: 2.3848701112778907

Epoch: 6| Step: 13
Training loss: 0.9098592773034956
Validation loss: 2.313066771721309

Epoch: 599| Step: 0
Training loss: 1.5951168706283356
Validation loss: 2.319786831768464

Epoch: 6| Step: 1
Training loss: 1.6297116564005463
Validation loss: 2.350411016494152

Epoch: 6| Step: 2
Training loss: 1.7853166437192771
Validation loss: 2.3082248799833227

Epoch: 6| Step: 3
Training loss: 1.2029485697006792
Validation loss: 2.3805018590658857

Epoch: 6| Step: 4
Training loss: 2.2547366828867785
Validation loss: 2.4047014697679634

Epoch: 6| Step: 5
Training loss: 1.7720800910140901
Validation loss: 2.3562806375613246

Epoch: 6| Step: 6
Training loss: 1.496077096711941
Validation loss: 2.317465652051281

Epoch: 6| Step: 7
Training loss: 1.6410507376368761
Validation loss: 2.336411565798536

Epoch: 6| Step: 8
Training loss: 1.4494029953635221
Validation loss: 2.329718259952201

Epoch: 6| Step: 9
Training loss: 1.3966962746931633
Validation loss: 2.3355474867707593

Epoch: 6| Step: 10
Training loss: 1.490024936902585
Validation loss: 2.3872283562820877

Epoch: 6| Step: 11
Training loss: 1.2180624758790715
Validation loss: 2.3549130783131953

Epoch: 6| Step: 12
Training loss: 1.5290775068658795
Validation loss: 2.345670957181573

Epoch: 6| Step: 13
Training loss: 1.6090143781153523
Validation loss: 2.3492077903563255

Epoch: 600| Step: 0
Training loss: 1.940248324438354
Validation loss: 2.348017067122038

Epoch: 6| Step: 1
Training loss: 1.1394128498731506
Validation loss: 2.3491315032738376

Epoch: 6| Step: 2
Training loss: 2.070572286177219
Validation loss: 2.3417652523498105

Epoch: 6| Step: 3
Training loss: 1.572424232586143
Validation loss: 2.3763805288913167

Epoch: 6| Step: 4
Training loss: 1.4547924196489987
Validation loss: 2.340113741060755

Epoch: 6| Step: 5
Training loss: 1.1130098246254745
Validation loss: 2.3202921421526193

Epoch: 6| Step: 6
Training loss: 1.3460081333379461
Validation loss: 2.3440201853132514

Epoch: 6| Step: 7
Training loss: 1.9279922266522482
Validation loss: 2.3640624977877795

Epoch: 6| Step: 8
Training loss: 1.17818420828016
Validation loss: 2.3905672102169784

Epoch: 6| Step: 9
Training loss: 1.3803939358656803
Validation loss: 2.263145518581924

Epoch: 6| Step: 10
Training loss: 1.8442563800161036
Validation loss: 2.402913919519464

Epoch: 6| Step: 11
Training loss: 1.6509360230479149
Validation loss: 2.3881316603737943

Epoch: 6| Step: 12
Training loss: 1.1957249646589736
Validation loss: 2.340294093348631

Epoch: 6| Step: 13
Training loss: 1.1089910998111974
Validation loss: 2.374653409355986

Testing loss: 2.457687698324627
