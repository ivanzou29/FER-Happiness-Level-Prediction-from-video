Epoch: 1| Step: 0
Training loss: 4.2096966842155865
Validation loss: 4.600228161835735

Epoch: 6| Step: 1
Training loss: 4.639689855404745
Validation loss: 4.595649657391162

Epoch: 6| Step: 2
Training loss: 5.631985882806425
Validation loss: 4.593861543731082

Epoch: 6| Step: 3
Training loss: 4.558098328906098
Validation loss: 4.5919839805682905

Epoch: 6| Step: 4
Training loss: 4.250053405426173
Validation loss: 4.587633781609336

Epoch: 6| Step: 5
Training loss: 5.49248685061687
Validation loss: 4.585923370134399

Epoch: 6| Step: 6
Training loss: 4.7811444838106745
Validation loss: 4.582009698058484

Epoch: 6| Step: 7
Training loss: 3.3134059027151292
Validation loss: 4.578543112829771

Epoch: 6| Step: 8
Training loss: 4.34498413996112
Validation loss: 4.576961468173795

Epoch: 6| Step: 9
Training loss: 4.720807365936392
Validation loss: 4.573654911659568

Epoch: 6| Step: 10
Training loss: 3.980252036352495
Validation loss: 4.569031927432734

Epoch: 6| Step: 11
Training loss: 5.825063601952933
Validation loss: 4.567746399233381

Epoch: 6| Step: 12
Training loss: 4.119599245820762
Validation loss: 4.565334942378399

Epoch: 6| Step: 13
Training loss: 5.349716692402024
Validation loss: 4.561035633732091

Epoch: 2| Step: 0
Training loss: 3.6421775290779435
Validation loss: 4.559182982279782

Epoch: 6| Step: 1
Training loss: 5.239773372088218
Validation loss: 4.555597747966173

Epoch: 6| Step: 2
Training loss: 4.750291714996404
Validation loss: 4.553184329761815

Epoch: 6| Step: 3
Training loss: 4.5951639711099235
Validation loss: 4.549535190442466

Epoch: 6| Step: 4
Training loss: 4.881765903459693
Validation loss: 4.548151932230278

Epoch: 6| Step: 5
Training loss: 4.165231279452334
Validation loss: 4.545251287239495

Epoch: 6| Step: 6
Training loss: 3.787547014907765
Validation loss: 4.541444208334704

Epoch: 6| Step: 7
Training loss: 5.439881954034308
Validation loss: 4.538794802910747

Epoch: 6| Step: 8
Training loss: 4.799994532264138
Validation loss: 4.534815935413453

Epoch: 6| Step: 9
Training loss: 4.616026136856526
Validation loss: 4.5322275546448365

Epoch: 6| Step: 10
Training loss: 4.303082563292133
Validation loss: 4.528307550666771

Epoch: 6| Step: 11
Training loss: 5.670631966062623
Validation loss: 4.526211109933554

Epoch: 6| Step: 12
Training loss: 3.3727936773906855
Validation loss: 4.522704719529161

Epoch: 6| Step: 13
Training loss: 5.507334760142906
Validation loss: 4.521827373359701

Epoch: 3| Step: 0
Training loss: 4.208142090534251
Validation loss: 4.51698050053248

Epoch: 6| Step: 1
Training loss: 4.398185980264158
Validation loss: 4.515789889787442

Epoch: 6| Step: 2
Training loss: 4.300987023914721
Validation loss: 4.511187107380846

Epoch: 6| Step: 3
Training loss: 4.70678831874409
Validation loss: 4.507863622241056

Epoch: 6| Step: 4
Training loss: 4.370045499586593
Validation loss: 4.506628532509243

Epoch: 6| Step: 5
Training loss: 4.8084124756398205
Validation loss: 4.503781239722499

Epoch: 6| Step: 6
Training loss: 4.1663892017804685
Validation loss: 4.501288595250005

Epoch: 6| Step: 7
Training loss: 4.801193232043053
Validation loss: 4.49948471291183

Epoch: 6| Step: 8
Training loss: 5.38195280122279
Validation loss: 4.496587332039487

Epoch: 6| Step: 9
Training loss: 4.4479500667321545
Validation loss: 4.493112733068669

Epoch: 6| Step: 10
Training loss: 5.505201827532323
Validation loss: 4.489978825492526

Epoch: 6| Step: 11
Training loss: 3.984225520901623
Validation loss: 4.486790521601647

Epoch: 6| Step: 12
Training loss: 4.568875391709726
Validation loss: 4.482170337955525

Epoch: 6| Step: 13
Training loss: 4.587421235699857
Validation loss: 4.4802526479155595

Epoch: 4| Step: 0
Training loss: 3.512072450946279
Validation loss: 4.477648351748599

Epoch: 6| Step: 1
Training loss: 4.372545262097558
Validation loss: 4.47499442967233

Epoch: 6| Step: 2
Training loss: 5.11999565124327
Validation loss: 4.469582291215908

Epoch: 6| Step: 3
Training loss: 4.628443080730549
Validation loss: 4.468740520471543

Epoch: 6| Step: 4
Training loss: 4.31206189570122
Validation loss: 4.46614062432345

Epoch: 6| Step: 5
Training loss: 5.012603895675521
Validation loss: 4.462344440595897

Epoch: 6| Step: 6
Training loss: 4.038130219111799
Validation loss: 4.459843721374512

Epoch: 6| Step: 7
Training loss: 4.8894248196632155
Validation loss: 4.457568574087748

Epoch: 6| Step: 8
Training loss: 4.828408834762271
Validation loss: 4.45407593236015

Epoch: 6| Step: 9
Training loss: 5.000966741563047
Validation loss: 4.451602738787779

Epoch: 6| Step: 10
Training loss: 5.52444988291043
Validation loss: 4.44823190927818

Epoch: 6| Step: 11
Training loss: 3.3294909902125056
Validation loss: 4.442686528689724

Epoch: 6| Step: 12
Training loss: 4.345154898706144
Validation loss: 4.440335585747657

Epoch: 6| Step: 13
Training loss: 4.515584450509978
Validation loss: 4.436539989375904

Epoch: 5| Step: 0
Training loss: 5.2035234545020295
Validation loss: 4.432200570703913

Epoch: 6| Step: 1
Training loss: 4.642214929787903
Validation loss: 4.431207248617994

Epoch: 6| Step: 2
Training loss: 4.584470758042596
Validation loss: 4.42573476829478

Epoch: 6| Step: 3
Training loss: 4.990818176161588
Validation loss: 4.423028249181609

Epoch: 6| Step: 4
Training loss: 4.6231661073291574
Validation loss: 4.420312921892039

Epoch: 6| Step: 5
Training loss: 3.9537789629376796
Validation loss: 4.418921948733014

Epoch: 6| Step: 6
Training loss: 4.52986534272194
Validation loss: 4.413180634235286

Epoch: 6| Step: 7
Training loss: 3.4326101028998726
Validation loss: 4.4103050124371

Epoch: 6| Step: 8
Training loss: 5.151503349059485
Validation loss: 4.407848274538945

Epoch: 6| Step: 9
Training loss: 5.00164634303017
Validation loss: 4.403442205007996

Epoch: 6| Step: 10
Training loss: 4.453698479383586
Validation loss: 4.4003609825236865

Epoch: 6| Step: 11
Training loss: 3.5705926897886395
Validation loss: 4.398015746305549

Epoch: 6| Step: 12
Training loss: 4.063906851504483
Validation loss: 4.393098149455652

Epoch: 6| Step: 13
Training loss: 4.910772292550057
Validation loss: 4.390409553434708

Epoch: 6| Step: 0
Training loss: 4.854301527166435
Validation loss: 4.38892254042654

Epoch: 6| Step: 1
Training loss: 3.178449760055563
Validation loss: 4.381313731388132

Epoch: 6| Step: 2
Training loss: 4.878482064101072
Validation loss: 4.379749786748961

Epoch: 6| Step: 3
Training loss: 4.566283864778912
Validation loss: 4.377941081756677

Epoch: 6| Step: 4
Training loss: 4.2265990532441995
Validation loss: 4.373248585021908

Epoch: 6| Step: 5
Training loss: 5.115400675036327
Validation loss: 4.368472752100762

Epoch: 6| Step: 6
Training loss: 4.041127722813859
Validation loss: 4.3649743687375295

Epoch: 6| Step: 7
Training loss: 2.7170941802414132
Validation loss: 4.362921880957728

Epoch: 6| Step: 8
Training loss: 4.908191466858419
Validation loss: 4.358151994135425

Epoch: 6| Step: 9
Training loss: 4.260582259239239
Validation loss: 4.355991410780719

Epoch: 6| Step: 10
Training loss: 4.951667643448203
Validation loss: 4.35256120291161

Epoch: 6| Step: 11
Training loss: 5.012264278510445
Validation loss: 4.34637331823963

Epoch: 6| Step: 12
Training loss: 4.489086905498398
Validation loss: 4.3382671577461975

Epoch: 6| Step: 13
Training loss: 5.0336597429419925
Validation loss: 4.339351617694464

Epoch: 7| Step: 0
Training loss: 3.4910223124306543
Validation loss: 4.331843808001973

Epoch: 6| Step: 1
Training loss: 4.579314510236984
Validation loss: 4.329465067571392

Epoch: 6| Step: 2
Training loss: 4.615620355209876
Validation loss: 4.326999549817486

Epoch: 6| Step: 3
Training loss: 4.626957865592232
Validation loss: 4.324302823330388

Epoch: 6| Step: 4
Training loss: 3.8568774338885934
Validation loss: 4.318952045261832

Epoch: 6| Step: 5
Training loss: 4.614585905167643
Validation loss: 4.3139033305885475

Epoch: 6| Step: 6
Training loss: 4.623491402041425
Validation loss: 4.311987077296745

Epoch: 6| Step: 7
Training loss: 3.7010221667446617
Validation loss: 4.30391003940858

Epoch: 6| Step: 8
Training loss: 5.894793667017446
Validation loss: 4.300475823150422

Epoch: 6| Step: 9
Training loss: 4.631005589346086
Validation loss: 4.296987790056509

Epoch: 6| Step: 10
Training loss: 3.1781761082803675
Validation loss: 4.292034585396559

Epoch: 6| Step: 11
Training loss: 5.061704219862615
Validation loss: 4.288537452192325

Epoch: 6| Step: 12
Training loss: 4.059700103733153
Validation loss: 4.2839350234720905

Epoch: 6| Step: 13
Training loss: 4.2968379348543415
Validation loss: 4.277843707403666

Epoch: 8| Step: 0
Training loss: 4.675714350503033
Validation loss: 4.273068172813324

Epoch: 6| Step: 1
Training loss: 3.945963528239805
Validation loss: 4.269490450418968

Epoch: 6| Step: 2
Training loss: 3.6012235469568186
Validation loss: 4.265395633000412

Epoch: 6| Step: 3
Training loss: 4.164826915208192
Validation loss: 4.259972994985165

Epoch: 6| Step: 4
Training loss: 3.929792095635212
Validation loss: 4.254862626916499

Epoch: 6| Step: 5
Training loss: 4.745151052532736
Validation loss: 4.25010896056877

Epoch: 6| Step: 6
Training loss: 4.082875024935038
Validation loss: 4.244333235234713

Epoch: 6| Step: 7
Training loss: 4.273438615816239
Validation loss: 4.238524608185444

Epoch: 6| Step: 8
Training loss: 5.190979307829728
Validation loss: 4.236134856666481

Epoch: 6| Step: 9
Training loss: 5.335701933055126
Validation loss: 4.229030252719022

Epoch: 6| Step: 10
Training loss: 4.197897230281591
Validation loss: 4.2234384581910716

Epoch: 6| Step: 11
Training loss: 4.948340767871637
Validation loss: 4.2170790875324045

Epoch: 6| Step: 12
Training loss: 3.852856153775665
Validation loss: 4.213715652655488

Epoch: 6| Step: 13
Training loss: 3.1405803620311925
Validation loss: 4.211761143839591

Epoch: 9| Step: 0
Training loss: 4.760022882358463
Validation loss: 4.200630276838272

Epoch: 6| Step: 1
Training loss: 4.973619294386941
Validation loss: 4.195315130055768

Epoch: 6| Step: 2
Training loss: 3.6714752628989755
Validation loss: 4.191011628669769

Epoch: 6| Step: 3
Training loss: 5.020212517605588
Validation loss: 4.182961257300354

Epoch: 6| Step: 4
Training loss: 5.090537526764867
Validation loss: 4.182878118486934

Epoch: 6| Step: 5
Training loss: 3.204410648523394
Validation loss: 4.173405455234393

Epoch: 6| Step: 6
Training loss: 4.4297600526603595
Validation loss: 4.164235085213071

Epoch: 6| Step: 7
Training loss: 4.325788728095397
Validation loss: 4.160715454545633

Epoch: 6| Step: 8
Training loss: 4.359458567047373
Validation loss: 4.155336531129522

Epoch: 6| Step: 9
Training loss: 3.579632170976815
Validation loss: 4.147685823062447

Epoch: 6| Step: 10
Training loss: 4.24101901602805
Validation loss: 4.140901138654287

Epoch: 6| Step: 11
Training loss: 3.461385245885608
Validation loss: 4.1368585520879835

Epoch: 6| Step: 12
Training loss: 3.9783894177561305
Validation loss: 4.130334178924947

Epoch: 6| Step: 13
Training loss: 4.614679316892335
Validation loss: 4.121442280436177

Epoch: 10| Step: 0
Training loss: 4.427132759566308
Validation loss: 4.116338047231276

Epoch: 6| Step: 1
Training loss: 3.9755690257331895
Validation loss: 4.109749066920901

Epoch: 6| Step: 2
Training loss: 4.252871272740335
Validation loss: 4.104197369857252

Epoch: 6| Step: 3
Training loss: 3.8722012164584356
Validation loss: 4.097569958892958

Epoch: 6| Step: 4
Training loss: 5.268638948150347
Validation loss: 4.086853908386681

Epoch: 6| Step: 5
Training loss: 3.8485406314290427
Validation loss: 4.087845973068995

Epoch: 6| Step: 6
Training loss: 4.230656303552566
Validation loss: 4.078502989074515

Epoch: 6| Step: 7
Training loss: 3.776994943540146
Validation loss: 4.067043687163493

Epoch: 6| Step: 8
Training loss: 3.159623562084121
Validation loss: 4.0647955808332075

Epoch: 6| Step: 9
Training loss: 3.998132508166337
Validation loss: 4.0600944357383675

Epoch: 6| Step: 10
Training loss: 4.367338174530671
Validation loss: 4.050685499852279

Epoch: 6| Step: 11
Training loss: 4.797073012250625
Validation loss: 4.04210381299889

Epoch: 6| Step: 12
Training loss: 4.550641679056055
Validation loss: 4.033004059889934

Epoch: 6| Step: 13
Training loss: 3.8211817464326425
Validation loss: 4.029757911093603

Epoch: 11| Step: 0
Training loss: 3.752595893097157
Validation loss: 4.016755741728012

Epoch: 6| Step: 1
Training loss: 4.270849361234533
Validation loss: 4.008754688959068

Epoch: 6| Step: 2
Training loss: 3.600943886677492
Validation loss: 4.00229714302972

Epoch: 6| Step: 3
Training loss: 4.300880146881775
Validation loss: 3.9991648991798763

Epoch: 6| Step: 4
Training loss: 3.8876893025025763
Validation loss: 3.9912460427854124

Epoch: 6| Step: 5
Training loss: 4.377457500711141
Validation loss: 3.9873343184192778

Epoch: 6| Step: 6
Training loss: 5.132096378530453
Validation loss: 3.97040454061927

Epoch: 6| Step: 7
Training loss: 3.4445754320266215
Validation loss: 3.962453504596065

Epoch: 6| Step: 8
Training loss: 3.957140183902839
Validation loss: 3.952053518406241

Epoch: 6| Step: 9
Training loss: 2.9432728633810745
Validation loss: 3.9452358053609924

Epoch: 6| Step: 10
Training loss: 4.048476208023655
Validation loss: 3.935557255799565

Epoch: 6| Step: 11
Training loss: 4.623472219158251
Validation loss: 3.9299858732015793

Epoch: 6| Step: 12
Training loss: 4.740729671924526
Validation loss: 3.9223814286255227

Epoch: 6| Step: 13
Training loss: 3.819714208767158
Validation loss: 3.9104273213272913

Epoch: 12| Step: 0
Training loss: 3.7765544394113917
Validation loss: 3.9021458154583417

Epoch: 6| Step: 1
Training loss: 4.200266947664234
Validation loss: 3.8927991465438065

Epoch: 6| Step: 2
Training loss: 4.0321576183482835
Validation loss: 3.8832228839801264

Epoch: 6| Step: 3
Training loss: 4.531106459876265
Validation loss: 3.8767521602045645

Epoch: 6| Step: 4
Training loss: 3.5556046528870215
Validation loss: 3.8652404119531516

Epoch: 6| Step: 5
Training loss: 3.8229724072681193
Validation loss: 3.852657051514591

Epoch: 6| Step: 6
Training loss: 4.129874383895691
Validation loss: 3.841573936114304

Epoch: 6| Step: 7
Training loss: 3.680701761920555
Validation loss: 3.8293737949975637

Epoch: 6| Step: 8
Training loss: 2.7873270742380627
Validation loss: 3.8218609655212434

Epoch: 6| Step: 9
Training loss: 4.369954278562708
Validation loss: 3.815716000815433

Epoch: 6| Step: 10
Training loss: 4.481801853224047
Validation loss: 3.8014941307525234

Epoch: 6| Step: 11
Training loss: 3.753741877010676
Validation loss: 3.7922983847941802

Epoch: 6| Step: 12
Training loss: 4.046008160811532
Validation loss: 3.781358023578232

Epoch: 6| Step: 13
Training loss: 4.668258645221634
Validation loss: 3.7747117169679028

Epoch: 13| Step: 0
Training loss: 3.772096383741389
Validation loss: 3.7618951037262787

Epoch: 6| Step: 1
Training loss: 4.797841524548068
Validation loss: 3.7524411886531137

Epoch: 6| Step: 2
Training loss: 4.217275856452132
Validation loss: 3.7417099355728203

Epoch: 6| Step: 3
Training loss: 3.6968808868180756
Validation loss: 3.7218018622328635

Epoch: 6| Step: 4
Training loss: 4.905390378639166
Validation loss: 3.7158970632028914

Epoch: 6| Step: 5
Training loss: 3.2619163955836368
Validation loss: 3.7058874408092635

Epoch: 6| Step: 6
Training loss: 3.0502066370271463
Validation loss: 3.6907464349178727

Epoch: 6| Step: 7
Training loss: 3.2292479638151357
Validation loss: 3.6762951806802953

Epoch: 6| Step: 8
Training loss: 2.812475077200772
Validation loss: 3.66525741709288

Epoch: 6| Step: 9
Training loss: 4.720992408130621
Validation loss: 3.652304734460406

Epoch: 6| Step: 10
Training loss: 3.2819172498649225
Validation loss: 3.644121365912907

Epoch: 6| Step: 11
Training loss: 3.870147004206362
Validation loss: 3.6377720878115354

Epoch: 6| Step: 12
Training loss: 2.988625580141542
Validation loss: 3.6207120043954566

Epoch: 6| Step: 13
Training loss: 4.994862205582732
Validation loss: 3.612806516067505

Epoch: 14| Step: 0
Training loss: 3.8492126105545847
Validation loss: 3.597304451735156

Epoch: 6| Step: 1
Training loss: 3.3521618429457236
Validation loss: 3.5868669806997033

Epoch: 6| Step: 2
Training loss: 3.433963690608561
Validation loss: 3.5705067887403334

Epoch: 6| Step: 3
Training loss: 3.8094360046258613
Validation loss: 3.5635765102876347

Epoch: 6| Step: 4
Training loss: 4.00752456552802
Validation loss: 3.5430517659860383

Epoch: 6| Step: 5
Training loss: 3.989183224899409
Validation loss: 3.5331912166721953

Epoch: 6| Step: 6
Training loss: 3.968009819633885
Validation loss: 3.521204029967731

Epoch: 6| Step: 7
Training loss: 3.099126594313793
Validation loss: 3.502720884180867

Epoch: 6| Step: 8
Training loss: 4.0073265688296535
Validation loss: 3.491698792541044

Epoch: 6| Step: 9
Training loss: 3.1723452064500672
Validation loss: 3.480008680259488

Epoch: 6| Step: 10
Training loss: 3.5242973005994678
Validation loss: 3.465585872407408

Epoch: 6| Step: 11
Training loss: 3.8299446607929375
Validation loss: 3.4580745612562422

Epoch: 6| Step: 12
Training loss: 3.870845659699676
Validation loss: 3.4527103024907326

Epoch: 6| Step: 13
Training loss: 3.6047941922130438
Validation loss: 3.4249703595153056

Epoch: 15| Step: 0
Training loss: 3.4150544216125875
Validation loss: 3.4145860216869104

Epoch: 6| Step: 1
Training loss: 3.516212109179525
Validation loss: 3.3911374300637567

Epoch: 6| Step: 2
Training loss: 3.067592512879317
Validation loss: 3.3862318704796515

Epoch: 6| Step: 3
Training loss: 3.622460758478456
Validation loss: 3.367519022299562

Epoch: 6| Step: 4
Training loss: 3.6567941896451273
Validation loss: 3.360818398007877

Epoch: 6| Step: 5
Training loss: 4.015337625751949
Validation loss: 3.3532016252220544

Epoch: 6| Step: 6
Training loss: 2.3658010117474078
Validation loss: 3.3278448593660226

Epoch: 6| Step: 7
Training loss: 2.977380675159704
Validation loss: 3.307874712114697

Epoch: 6| Step: 8
Training loss: 3.76273016241485
Validation loss: 3.295519034938002

Epoch: 6| Step: 9
Training loss: 3.555021635008487
Validation loss: 3.2755657223134316

Epoch: 6| Step: 10
Training loss: 4.160957595942834
Validation loss: 3.2761296821716566

Epoch: 6| Step: 11
Training loss: 4.07624346711806
Validation loss: 3.2569019289109917

Epoch: 6| Step: 12
Training loss: 2.7906998815453843
Validation loss: 3.243633082317828

Epoch: 6| Step: 13
Training loss: 3.998889769019099
Validation loss: 3.226209610131173

Epoch: 16| Step: 0
Training loss: 3.17807708374031
Validation loss: 3.2082663679439016

Epoch: 6| Step: 1
Training loss: 3.2888134207386504
Validation loss: 3.194244895600709

Epoch: 6| Step: 2
Training loss: 2.781346008701037
Validation loss: 3.187099305329952

Epoch: 6| Step: 3
Training loss: 3.2407826516806972
Validation loss: 3.160864112660692

Epoch: 6| Step: 4
Training loss: 3.6177602359831744
Validation loss: 3.1473135434491915

Epoch: 6| Step: 5
Training loss: 3.9716840096331287
Validation loss: 3.134508608062012

Epoch: 6| Step: 6
Training loss: 3.2017378618015186
Validation loss: 3.119303465000418

Epoch: 6| Step: 7
Training loss: 3.0563526346958567
Validation loss: 3.100418279402635

Epoch: 6| Step: 8
Training loss: 3.170554802416598
Validation loss: 3.090327415115285

Epoch: 6| Step: 9
Training loss: 3.865929601289825
Validation loss: 3.074622312238322

Epoch: 6| Step: 10
Training loss: 3.0158283382506865
Validation loss: 3.0623895542771025

Epoch: 6| Step: 11
Training loss: 3.693107221156793
Validation loss: 3.0430649731864436

Epoch: 6| Step: 12
Training loss: 3.2884380264231052
Validation loss: 3.019088283233897

Epoch: 6| Step: 13
Training loss: 3.1939298814256047
Validation loss: 3.0234754697304167

Epoch: 17| Step: 0
Training loss: 3.6892540849235362
Validation loss: 3.000108181975168

Epoch: 6| Step: 1
Training loss: 3.4021154386208936
Validation loss: 2.990253997680694

Epoch: 6| Step: 2
Training loss: 2.7318647796991247
Validation loss: 2.9721008646958973

Epoch: 6| Step: 3
Training loss: 3.143636749229847
Validation loss: 2.955848613734337

Epoch: 6| Step: 4
Training loss: 3.073345055326779
Validation loss: 2.942931444990205

Epoch: 6| Step: 5
Training loss: 2.746367135690391
Validation loss: 2.932732307992932

Epoch: 6| Step: 6
Training loss: 3.1202444895293824
Validation loss: 2.9087974594296355

Epoch: 6| Step: 7
Training loss: 3.3750385706075092
Validation loss: 2.907181153881505

Epoch: 6| Step: 8
Training loss: 3.256931835404105
Validation loss: 2.8965021351010813

Epoch: 6| Step: 9
Training loss: 3.259371962870484
Validation loss: 2.874352728702402

Epoch: 6| Step: 10
Training loss: 3.182645804038653
Validation loss: 2.8557301541328033

Epoch: 6| Step: 11
Training loss: 2.958659803259053
Validation loss: 2.8471550634830525

Epoch: 6| Step: 12
Training loss: 3.15769155082883
Validation loss: 2.832608119894887

Epoch: 6| Step: 13
Training loss: 3.480626848699483
Validation loss: 2.822115149809947

Epoch: 18| Step: 0
Training loss: 2.511072054796493
Validation loss: 2.8179828647368623

Epoch: 6| Step: 1
Training loss: 3.4372072962206373
Validation loss: 2.804527741362547

Epoch: 6| Step: 2
Training loss: 3.437994626611901
Validation loss: 2.7983147723899595

Epoch: 6| Step: 3
Training loss: 2.384540569111485
Validation loss: 2.771707978863963

Epoch: 6| Step: 4
Training loss: 2.5197852191524537
Validation loss: 2.7575200552794863

Epoch: 6| Step: 5
Training loss: 3.0147283140029346
Validation loss: 2.7619880430914647

Epoch: 6| Step: 6
Training loss: 3.022825193872441
Validation loss: 2.75951735617154

Epoch: 6| Step: 7
Training loss: 3.1504056094168598
Validation loss: 2.735354636597193

Epoch: 6| Step: 8
Training loss: 2.9717847872578766
Validation loss: 2.7420420676320005

Epoch: 6| Step: 9
Training loss: 3.149916232978311
Validation loss: 2.7172232775286442

Epoch: 6| Step: 10
Training loss: 2.8389244638077384
Validation loss: 2.7070059262911443

Epoch: 6| Step: 11
Training loss: 3.418117463282655
Validation loss: 2.6858485213656693

Epoch: 6| Step: 12
Training loss: 3.6587564077474344
Validation loss: 2.6850775102650033

Epoch: 6| Step: 13
Training loss: 2.5280587129897207
Validation loss: 2.677230459040589

Epoch: 19| Step: 0
Training loss: 2.9806468105498047
Validation loss: 2.6710099477020757

Epoch: 6| Step: 1
Training loss: 2.989718621324151
Validation loss: 2.662742049092222

Epoch: 6| Step: 2
Training loss: 3.4362532695645083
Validation loss: 2.6533420094200673

Epoch: 6| Step: 3
Training loss: 3.063511272765187
Validation loss: 2.6515120995824537

Epoch: 6| Step: 4
Training loss: 2.9811818880821583
Validation loss: 2.628812951511633

Epoch: 6| Step: 5
Training loss: 2.767581312437517
Validation loss: 2.625714628154994

Epoch: 6| Step: 6
Training loss: 3.3546796765744826
Validation loss: 2.6058778613352906

Epoch: 6| Step: 7
Training loss: 2.7642490390866654
Validation loss: 2.6187898450012987

Epoch: 6| Step: 8
Training loss: 2.737228125740968
Validation loss: 2.596040093515668

Epoch: 6| Step: 9
Training loss: 2.723849457898364
Validation loss: 2.592534053643428

Epoch: 6| Step: 10
Training loss: 2.7988142397869544
Validation loss: 2.60131273490642

Epoch: 6| Step: 11
Training loss: 2.7765177210608596
Validation loss: 2.5888529396609674

Epoch: 6| Step: 12
Training loss: 3.168671291359447
Validation loss: 2.558615822357507

Epoch: 6| Step: 13
Training loss: 2.598638776093542
Validation loss: 2.572110801206667

Epoch: 20| Step: 0
Training loss: 3.011185931659959
Validation loss: 2.56211098740258

Epoch: 6| Step: 1
Training loss: 2.1114559505419717
Validation loss: 2.552315286856898

Epoch: 6| Step: 2
Training loss: 3.2681973925663277
Validation loss: 2.5679784178997567

Epoch: 6| Step: 3
Training loss: 2.810935623821419
Validation loss: 2.56382686498624

Epoch: 6| Step: 4
Training loss: 3.171199181630311
Validation loss: 2.5391429439703144

Epoch: 6| Step: 5
Training loss: 2.7025046987430965
Validation loss: 2.5571085068537194

Epoch: 6| Step: 6
Training loss: 2.674310745141329
Validation loss: 2.5380437172959427

Epoch: 6| Step: 7
Training loss: 3.1214115138615073
Validation loss: 2.5307702273595463

Epoch: 6| Step: 8
Training loss: 2.3201045190353056
Validation loss: 2.5219189777273825

Epoch: 6| Step: 9
Training loss: 3.0735869285512067
Validation loss: 2.530160707781989

Epoch: 6| Step: 10
Training loss: 3.359411620894146
Validation loss: 2.544629245626765

Epoch: 6| Step: 11
Training loss: 3.3502052244267615
Validation loss: 2.5245073644261384

Epoch: 6| Step: 12
Training loss: 2.812563153723461
Validation loss: 2.513785504267098

Epoch: 6| Step: 13
Training loss: 2.797359318063718
Validation loss: 2.532255189122097

Epoch: 21| Step: 0
Training loss: 2.6672509765222756
Validation loss: 2.5240332706780726

Epoch: 6| Step: 1
Training loss: 3.222728011748357
Validation loss: 2.529211031562879

Epoch: 6| Step: 2
Training loss: 2.4437997056828045
Validation loss: 2.513899448611077

Epoch: 6| Step: 3
Training loss: 2.9988833574518305
Validation loss: 2.5164765639105258

Epoch: 6| Step: 4
Training loss: 2.8399515459467253
Validation loss: 2.515612487619179

Epoch: 6| Step: 5
Training loss: 2.8723699730509926
Validation loss: 2.510503397152153

Epoch: 6| Step: 6
Training loss: 3.413696269419503
Validation loss: 2.5159980743395356

Epoch: 6| Step: 7
Training loss: 2.652903344698226
Validation loss: 2.5234176989017567

Epoch: 6| Step: 8
Training loss: 3.319524263054544
Validation loss: 2.4974111565754087

Epoch: 6| Step: 9
Training loss: 3.0205434901303843
Validation loss: 2.4970160750364068

Epoch: 6| Step: 10
Training loss: 2.498259224414926
Validation loss: 2.503134781230719

Epoch: 6| Step: 11
Training loss: 2.974680227837228
Validation loss: 2.5118832462962946

Epoch: 6| Step: 12
Training loss: 3.187096364513369
Validation loss: 2.5021627710279213

Epoch: 6| Step: 13
Training loss: 1.7341449344390876
Validation loss: 2.522587627386224

Epoch: 22| Step: 0
Training loss: 2.0385580206130416
Validation loss: 2.4964692809982143

Epoch: 6| Step: 1
Training loss: 3.3930972881945665
Validation loss: 2.5052648205405412

Epoch: 6| Step: 2
Training loss: 3.2954117117462807
Validation loss: 2.4981420791421725

Epoch: 6| Step: 3
Training loss: 2.7809072561920334
Validation loss: 2.501123299039331

Epoch: 6| Step: 4
Training loss: 2.880004010992436
Validation loss: 2.4937001468456566

Epoch: 6| Step: 5
Training loss: 2.982183320722996
Validation loss: 2.49807014426593

Epoch: 6| Step: 6
Training loss: 2.61239303296874
Validation loss: 2.5013750724616415

Epoch: 6| Step: 7
Training loss: 2.3791650089540957
Validation loss: 2.5053715557508762

Epoch: 6| Step: 8
Training loss: 3.561410837822803
Validation loss: 2.50673666900422

Epoch: 6| Step: 9
Training loss: 3.3949223019862234
Validation loss: 2.495320349766025

Epoch: 6| Step: 10
Training loss: 2.8787714229156
Validation loss: 2.4952873850539894

Epoch: 6| Step: 11
Training loss: 3.1188192661826855
Validation loss: 2.501212188162182

Epoch: 6| Step: 12
Training loss: 2.4879153954327995
Validation loss: 2.5096211758252975

Epoch: 6| Step: 13
Training loss: 1.7797321746014954
Validation loss: 2.495242600593973

Epoch: 23| Step: 0
Training loss: 3.4021654750222825
Validation loss: 2.5034685622462307

Epoch: 6| Step: 1
Training loss: 3.5285223494691267
Validation loss: 2.4841765782869567

Epoch: 6| Step: 2
Training loss: 2.992685620152798
Validation loss: 2.517622582408159

Epoch: 6| Step: 3
Training loss: 2.937497240430469
Validation loss: 2.49516672921996

Epoch: 6| Step: 4
Training loss: 3.349471571509394
Validation loss: 2.5061157996677283

Epoch: 6| Step: 5
Training loss: 2.7226490693839134
Validation loss: 2.5148587663402613

Epoch: 6| Step: 6
Training loss: 2.984214099321357
Validation loss: 2.488003591052491

Epoch: 6| Step: 7
Training loss: 2.7126009452072846
Validation loss: 2.493687647820463

Epoch: 6| Step: 8
Training loss: 2.4578090582821677
Validation loss: 2.5035129077100144

Epoch: 6| Step: 9
Training loss: 2.560052028067706
Validation loss: 2.4866172159048343

Epoch: 6| Step: 10
Training loss: 2.539667239431622
Validation loss: 2.492875275236931

Epoch: 6| Step: 11
Training loss: 2.278578356515796
Validation loss: 2.4989475834578556

Epoch: 6| Step: 12
Training loss: 2.988444484665433
Validation loss: 2.507859192390112

Epoch: 6| Step: 13
Training loss: 2.772104550117074
Validation loss: 2.4957941444770637

Epoch: 24| Step: 0
Training loss: 3.1989356953250416
Validation loss: 2.4825710661885303

Epoch: 6| Step: 1
Training loss: 2.768335081402684
Validation loss: 2.4987508996287624

Epoch: 6| Step: 2
Training loss: 2.6728677076661174
Validation loss: 2.4913729259898982

Epoch: 6| Step: 3
Training loss: 3.0215998937597197
Validation loss: 2.4935363921071296

Epoch: 6| Step: 4
Training loss: 2.613997334216976
Validation loss: 2.491512223943027

Epoch: 6| Step: 5
Training loss: 2.5305922795783253
Validation loss: 2.4937319585251534

Epoch: 6| Step: 6
Training loss: 3.1592479102950457
Validation loss: 2.4852193949280412

Epoch: 6| Step: 7
Training loss: 2.7048232196008657
Validation loss: 2.4892885944386185

Epoch: 6| Step: 8
Training loss: 2.406704550081259
Validation loss: 2.496244211961207

Epoch: 6| Step: 9
Training loss: 2.6585017813604304
Validation loss: 2.4956091453179474

Epoch: 6| Step: 10
Training loss: 3.388074909143217
Validation loss: 2.4993692791983086

Epoch: 6| Step: 11
Training loss: 3.03361497626491
Validation loss: 2.5009259560061445

Epoch: 6| Step: 12
Training loss: 3.2729914322603126
Validation loss: 2.4847588526680955

Epoch: 6| Step: 13
Training loss: 2.9422636973379617
Validation loss: 2.514518001497579

Epoch: 25| Step: 0
Training loss: 2.7661642637209236
Validation loss: 2.5019593446526227

Epoch: 6| Step: 1
Training loss: 2.9942301259658066
Validation loss: 2.4931881876053166

Epoch: 6| Step: 2
Training loss: 2.6963880963567384
Validation loss: 2.491732515411615

Epoch: 6| Step: 3
Training loss: 2.7777804904500645
Validation loss: 2.4915814177883973

Epoch: 6| Step: 4
Training loss: 2.75622651312892
Validation loss: 2.4923607221512474

Epoch: 6| Step: 5
Training loss: 2.615867350117013
Validation loss: 2.5043192826394156

Epoch: 6| Step: 6
Training loss: 3.1132227414710782
Validation loss: 2.4910662393058196

Epoch: 6| Step: 7
Training loss: 2.8747956576498073
Validation loss: 2.492450837140368

Epoch: 6| Step: 8
Training loss: 2.5492121732336437
Validation loss: 2.481184135346614

Epoch: 6| Step: 9
Training loss: 3.1763128795202085
Validation loss: 2.487351817425543

Epoch: 6| Step: 10
Training loss: 3.3495241026409057
Validation loss: 2.4898760606292303

Epoch: 6| Step: 11
Training loss: 3.360998710525388
Validation loss: 2.4824180146987986

Epoch: 6| Step: 12
Training loss: 2.4934723510677936
Validation loss: 2.493293493393582

Epoch: 6| Step: 13
Training loss: 2.6997617404504783
Validation loss: 2.5003156155124127

Epoch: 26| Step: 0
Training loss: 2.88980717817618
Validation loss: 2.4861117691598604

Epoch: 6| Step: 1
Training loss: 3.1612474516786295
Validation loss: 2.487895312130229

Epoch: 6| Step: 2
Training loss: 2.883747559121847
Validation loss: 2.4893396115560043

Epoch: 6| Step: 3
Training loss: 2.730082515964642
Validation loss: 2.486686235642438

Epoch: 6| Step: 4
Training loss: 2.9265020116775977
Validation loss: 2.4940903772979954

Epoch: 6| Step: 5
Training loss: 2.8463957499368897
Validation loss: 2.4935463390939696

Epoch: 6| Step: 6
Training loss: 2.405556715137103
Validation loss: 2.4989164198601537

Epoch: 6| Step: 7
Training loss: 3.70974487414566
Validation loss: 2.4993782823957695

Epoch: 6| Step: 8
Training loss: 2.6850626338991472
Validation loss: 2.4851340544602163

Epoch: 6| Step: 9
Training loss: 2.3247127232424805
Validation loss: 2.493034362664805

Epoch: 6| Step: 10
Training loss: 2.980864212378135
Validation loss: 2.4888847058356762

Epoch: 6| Step: 11
Training loss: 2.9287417093144166
Validation loss: 2.4879932298367033

Epoch: 6| Step: 12
Training loss: 2.7670524921794164
Validation loss: 2.495957946241252

Epoch: 6| Step: 13
Training loss: 3.1841652573681642
Validation loss: 2.503002766071235

Epoch: 27| Step: 0
Training loss: 2.7899708697804773
Validation loss: 2.5055543970368

Epoch: 6| Step: 1
Training loss: 2.846658246595927
Validation loss: 2.497041796873161

Epoch: 6| Step: 2
Training loss: 2.1346347276600337
Validation loss: 2.4921131033563

Epoch: 6| Step: 3
Training loss: 2.203061583127057
Validation loss: 2.4796188251004896

Epoch: 6| Step: 4
Training loss: 2.982845853336311
Validation loss: 2.49254415992441

Epoch: 6| Step: 5
Training loss: 3.010743137771501
Validation loss: 2.4907865955879345

Epoch: 6| Step: 6
Training loss: 2.945611184757761
Validation loss: 2.488670874584572

Epoch: 6| Step: 7
Training loss: 3.0007172362936734
Validation loss: 2.474170938282276

Epoch: 6| Step: 8
Training loss: 2.6877730474824224
Validation loss: 2.488925969762407

Epoch: 6| Step: 9
Training loss: 3.255819831887195
Validation loss: 2.48177223027767

Epoch: 6| Step: 10
Training loss: 3.223938694875104
Validation loss: 2.48604436124326

Epoch: 6| Step: 11
Training loss: 3.228064531496673
Validation loss: 2.486565577945728

Epoch: 6| Step: 12
Training loss: 3.1774744678975195
Validation loss: 2.491882155327277

Epoch: 6| Step: 13
Training loss: 2.37450353553173
Validation loss: 2.48081011824099

Epoch: 28| Step: 0
Training loss: 2.9533355476365353
Validation loss: 2.4829436120743424

Epoch: 6| Step: 1
Training loss: 2.706779875650595
Validation loss: 2.4914758544231814

Epoch: 6| Step: 2
Training loss: 3.3532565443930245
Validation loss: 2.4836747399021415

Epoch: 6| Step: 3
Training loss: 2.7423978980226598
Validation loss: 2.501621272328563

Epoch: 6| Step: 4
Training loss: 3.137155162812953
Validation loss: 2.49964325010421

Epoch: 6| Step: 5
Training loss: 2.901383951062309
Validation loss: 2.4731232784411543

Epoch: 6| Step: 6
Training loss: 3.218819330450232
Validation loss: 2.473837788898999

Epoch: 6| Step: 7
Training loss: 2.7190309576676177
Validation loss: 2.496495608689302

Epoch: 6| Step: 8
Training loss: 2.9947529046687595
Validation loss: 2.49139695010476

Epoch: 6| Step: 9
Training loss: 2.9319613571638943
Validation loss: 2.494292600535094

Epoch: 6| Step: 10
Training loss: 2.928515879007842
Validation loss: 2.4938666838499346

Epoch: 6| Step: 11
Training loss: 2.1283849795454732
Validation loss: 2.478781154071638

Epoch: 6| Step: 12
Training loss: 2.9759700315668804
Validation loss: 2.498007911784214

Epoch: 6| Step: 13
Training loss: 1.6808618033549156
Validation loss: 2.4851496639225625

Epoch: 29| Step: 0
Training loss: 2.887267601272002
Validation loss: 2.4746981173480793

Epoch: 6| Step: 1
Training loss: 2.822511275533314
Validation loss: 2.485990706149409

Epoch: 6| Step: 2
Training loss: 2.695192549980377
Validation loss: 2.4799539579777754

Epoch: 6| Step: 3
Training loss: 3.686922319066217
Validation loss: 2.479528170341351

Epoch: 6| Step: 4
Training loss: 2.8976194147446415
Validation loss: 2.485160940141704

Epoch: 6| Step: 5
Training loss: 2.440768276019188
Validation loss: 2.4888437646614263

Epoch: 6| Step: 6
Training loss: 2.557745640090002
Validation loss: 2.475655219219071

Epoch: 6| Step: 7
Training loss: 2.9245465962400226
Validation loss: 2.489252414885068

Epoch: 6| Step: 8
Training loss: 2.3281460959483598
Validation loss: 2.4971365393644533

Epoch: 6| Step: 9
Training loss: 3.220432767514796
Validation loss: 2.469492495206762

Epoch: 6| Step: 10
Training loss: 2.9621846735409885
Validation loss: 2.476111156674653

Epoch: 6| Step: 11
Training loss: 2.875087404995672
Validation loss: 2.4898696300929806

Epoch: 6| Step: 12
Training loss: 3.2176963785348107
Validation loss: 2.4809268057256335

Epoch: 6| Step: 13
Training loss: 2.116983776918723
Validation loss: 2.4769188678316616

Epoch: 30| Step: 0
Training loss: 2.8790437207468176
Validation loss: 2.495439507516593

Epoch: 6| Step: 1
Training loss: 2.048182179290453
Validation loss: 2.4806076464378033

Epoch: 6| Step: 2
Training loss: 2.3805226814713425
Validation loss: 2.4816430931029774

Epoch: 6| Step: 3
Training loss: 2.6997325093610347
Validation loss: 2.4854411116081616

Epoch: 6| Step: 4
Training loss: 2.881257917347785
Validation loss: 2.480220108289215

Epoch: 6| Step: 5
Training loss: 3.490254048279753
Validation loss: 2.480851076772584

Epoch: 6| Step: 6
Training loss: 3.4287704597332773
Validation loss: 2.4734510867825716

Epoch: 6| Step: 7
Training loss: 3.1499773902687145
Validation loss: 2.492404920673706

Epoch: 6| Step: 8
Training loss: 2.7560496977600817
Validation loss: 2.4653514971397086

Epoch: 6| Step: 9
Training loss: 2.702119320463381
Validation loss: 2.4679289522484154

Epoch: 6| Step: 10
Training loss: 2.584914543908619
Validation loss: 2.4702146434505545

Epoch: 6| Step: 11
Training loss: 3.4446382792770907
Validation loss: 2.4891556286472767

Epoch: 6| Step: 12
Training loss: 2.1434822782829888
Validation loss: 2.473755162202127

Epoch: 6| Step: 13
Training loss: 3.50255736517098
Validation loss: 2.465281421505203

Epoch: 31| Step: 0
Training loss: 3.449006537435944
Validation loss: 2.4750359373610697

Epoch: 6| Step: 1
Training loss: 2.3611296135669866
Validation loss: 2.4633912067835326

Epoch: 6| Step: 2
Training loss: 2.9142863415201834
Validation loss: 2.4715561200036955

Epoch: 6| Step: 3
Training loss: 2.9338731493009313
Validation loss: 2.464465094513731

Epoch: 6| Step: 4
Training loss: 3.049715410306723
Validation loss: 2.4746114490268964

Epoch: 6| Step: 5
Training loss: 2.4928237915931035
Validation loss: 2.4726528493060833

Epoch: 6| Step: 6
Training loss: 3.1316430246849043
Validation loss: 2.483651378086498

Epoch: 6| Step: 7
Training loss: 2.7454817674677874
Validation loss: 2.477230726798566

Epoch: 6| Step: 8
Training loss: 3.3490512927943605
Validation loss: 2.462677200627086

Epoch: 6| Step: 9
Training loss: 2.9646370756666793
Validation loss: 2.472353777308516

Epoch: 6| Step: 10
Training loss: 2.473213699443053
Validation loss: 2.471086595971085

Epoch: 6| Step: 11
Training loss: 2.447602878235834
Validation loss: 2.467265554432763

Epoch: 6| Step: 12
Training loss: 2.9328501809188654
Validation loss: 2.4758424968392996

Epoch: 6| Step: 13
Training loss: 2.702920542134431
Validation loss: 2.470944903595169

Epoch: 32| Step: 0
Training loss: 3.0237426603810875
Validation loss: 2.471803912597536

Epoch: 6| Step: 1
Training loss: 3.0271534718427877
Validation loss: 2.4882387225329765

Epoch: 6| Step: 2
Training loss: 2.574016279440309
Validation loss: 2.4620079711222296

Epoch: 6| Step: 3
Training loss: 3.3184141229757538
Validation loss: 2.471135192469425

Epoch: 6| Step: 4
Training loss: 2.869184167789912
Validation loss: 2.4766638557042615

Epoch: 6| Step: 5
Training loss: 2.968754497323896
Validation loss: 2.478805826643693

Epoch: 6| Step: 6
Training loss: 2.1295478623890016
Validation loss: 2.4754104861784243

Epoch: 6| Step: 7
Training loss: 3.0284067564149644
Validation loss: 2.4682806017112098

Epoch: 6| Step: 8
Training loss: 2.4921758286731994
Validation loss: 2.4749552462399187

Epoch: 6| Step: 9
Training loss: 3.0465328709156143
Validation loss: 2.477617433442226

Epoch: 6| Step: 10
Training loss: 2.636443851410575
Validation loss: 2.4763660704316472

Epoch: 6| Step: 11
Training loss: 3.3297491990687123
Validation loss: 2.476648082517961

Epoch: 6| Step: 12
Training loss: 2.481241613417128
Validation loss: 2.4686772792828053

Epoch: 6| Step: 13
Training loss: 3.320779493813644
Validation loss: 2.470601308925544

Epoch: 33| Step: 0
Training loss: 2.2895509374500107
Validation loss: 2.4795998030949002

Epoch: 6| Step: 1
Training loss: 2.2294707996948278
Validation loss: 2.478139595460803

Epoch: 6| Step: 2
Training loss: 2.89055010724349
Validation loss: 2.470158813757775

Epoch: 6| Step: 3
Training loss: 3.2320828631703447
Validation loss: 2.4718587898662614

Epoch: 6| Step: 4
Training loss: 3.2723576259897156
Validation loss: 2.480666799134347

Epoch: 6| Step: 5
Training loss: 2.349531443533027
Validation loss: 2.466973625823417

Epoch: 6| Step: 6
Training loss: 3.427054469828626
Validation loss: 2.4737811751262186

Epoch: 6| Step: 7
Training loss: 3.2424186899877134
Validation loss: 2.4784088565587936

Epoch: 6| Step: 8
Training loss: 2.414817914080998
Validation loss: 2.4700063735735536

Epoch: 6| Step: 9
Training loss: 2.1874180369689356
Validation loss: 2.4699559628807

Epoch: 6| Step: 10
Training loss: 3.6765089297819746
Validation loss: 2.4670142305825316

Epoch: 6| Step: 11
Training loss: 2.447534885800796
Validation loss: 2.4771999062788166

Epoch: 6| Step: 12
Training loss: 3.0136620650561334
Validation loss: 2.4671232409855763

Epoch: 6| Step: 13
Training loss: 3.0297164970690416
Validation loss: 2.467201473119596

Epoch: 34| Step: 0
Training loss: 3.1591526696584262
Validation loss: 2.4788305227570904

Epoch: 6| Step: 1
Training loss: 2.623327176362713
Validation loss: 2.4782452613913692

Epoch: 6| Step: 2
Training loss: 2.6587491115896786
Validation loss: 2.479666470197721

Epoch: 6| Step: 3
Training loss: 3.481810579760203
Validation loss: 2.48106964535349

Epoch: 6| Step: 4
Training loss: 2.60414558910741
Validation loss: 2.466053915395848

Epoch: 6| Step: 5
Training loss: 2.861997308693826
Validation loss: 2.4912244831654573

Epoch: 6| Step: 6
Training loss: 3.3520784847840086
Validation loss: 2.4752132510554508

Epoch: 6| Step: 7
Training loss: 2.8843406204042825
Validation loss: 2.477204321134952

Epoch: 6| Step: 8
Training loss: 2.133483781079298
Validation loss: 2.4834144826649935

Epoch: 6| Step: 9
Training loss: 3.0827608006546234
Validation loss: 2.446701209549902

Epoch: 6| Step: 10
Training loss: 2.8065405544420745
Validation loss: 2.4695139074696493

Epoch: 6| Step: 11
Training loss: 3.0163225543215675
Validation loss: 2.4814451947238645

Epoch: 6| Step: 12
Training loss: 1.8787141253611586
Validation loss: 2.4882591482126086

Epoch: 6| Step: 13
Training loss: 3.3897508470016695
Validation loss: 2.464162926194475

Epoch: 35| Step: 0
Training loss: 3.5241383196025264
Validation loss: 2.471887941364063

Epoch: 6| Step: 1
Training loss: 2.6461426461508224
Validation loss: 2.4709907644135303

Epoch: 6| Step: 2
Training loss: 2.9342609159902446
Validation loss: 2.4554687959801136

Epoch: 6| Step: 3
Training loss: 2.5027770830502276
Validation loss: 2.4800101662052643

Epoch: 6| Step: 4
Training loss: 3.20181173059165
Validation loss: 2.4748118149317264

Epoch: 6| Step: 5
Training loss: 3.179891443858825
Validation loss: 2.468337278289887

Epoch: 6| Step: 6
Training loss: 2.6915801369977106
Validation loss: 2.4777214133904586

Epoch: 6| Step: 7
Training loss: 2.382791287687344
Validation loss: 2.473939394055309

Epoch: 6| Step: 8
Training loss: 2.4807497841534016
Validation loss: 2.4794420813352067

Epoch: 6| Step: 9
Training loss: 2.5149493524445634
Validation loss: 2.465187520068562

Epoch: 6| Step: 10
Training loss: 3.4804325808305827
Validation loss: 2.4694930308789402

Epoch: 6| Step: 11
Training loss: 2.3652477815281174
Validation loss: 2.472517949959087

Epoch: 6| Step: 12
Training loss: 2.7128575805672894
Validation loss: 2.4802547523689027

Epoch: 6| Step: 13
Training loss: 3.2508913431775115
Validation loss: 2.47904295460565

Epoch: 36| Step: 0
Training loss: 3.1331187262663476
Validation loss: 2.466621429385516

Epoch: 6| Step: 1
Training loss: 3.212575081864424
Validation loss: 2.4855626273608786

Epoch: 6| Step: 2
Training loss: 2.6112780912138254
Validation loss: 2.4671366747108774

Epoch: 6| Step: 3
Training loss: 3.510965608111645
Validation loss: 2.4854484153871903

Epoch: 6| Step: 4
Training loss: 2.759712753275388
Validation loss: 2.485911898952533

Epoch: 6| Step: 5
Training loss: 2.8013293210212242
Validation loss: 2.4697375769704024

Epoch: 6| Step: 6
Training loss: 2.1699783496391922
Validation loss: 2.4710162866594443

Epoch: 6| Step: 7
Training loss: 2.5350900415083264
Validation loss: 2.4830578174307605

Epoch: 6| Step: 8
Training loss: 2.987559272465425
Validation loss: 2.4810637122503394

Epoch: 6| Step: 9
Training loss: 2.9714641812569713
Validation loss: 2.4634802262852347

Epoch: 6| Step: 10
Training loss: 2.498811153028038
Validation loss: 2.465525471350571

Epoch: 6| Step: 11
Training loss: 2.5385884473328164
Validation loss: 2.4858814939011222

Epoch: 6| Step: 12
Training loss: 2.6664925955543164
Validation loss: 2.475329343283798

Epoch: 6| Step: 13
Training loss: 3.639975690446102
Validation loss: 2.470989676081005

Epoch: 37| Step: 0
Training loss: 2.3375826244745057
Validation loss: 2.4830699941522636

Epoch: 6| Step: 1
Training loss: 2.954494582585216
Validation loss: 2.4738358375434

Epoch: 6| Step: 2
Training loss: 2.4400965236895598
Validation loss: 2.4748694466946777

Epoch: 6| Step: 3
Training loss: 2.8907831921979956
Validation loss: 2.4832878538356544

Epoch: 6| Step: 4
Training loss: 2.2247884542646403
Validation loss: 2.4774857752588137

Epoch: 6| Step: 5
Training loss: 3.2126086264921407
Validation loss: 2.4802709760135797

Epoch: 6| Step: 6
Training loss: 3.632970269171573
Validation loss: 2.485338856448049

Epoch: 6| Step: 7
Training loss: 3.0536199006557223
Validation loss: 2.4677637055560284

Epoch: 6| Step: 8
Training loss: 2.6363404857432204
Validation loss: 2.4629897897141064

Epoch: 6| Step: 9
Training loss: 2.968514844716257
Validation loss: 2.4536158802955597

Epoch: 6| Step: 10
Training loss: 3.1735171121653107
Validation loss: 2.46540611873168

Epoch: 6| Step: 11
Training loss: 2.799465407699958
Validation loss: 2.4627970654410345

Epoch: 6| Step: 12
Training loss: 2.3037460214515315
Validation loss: 2.458378883851948

Epoch: 6| Step: 13
Training loss: 3.097340821493454
Validation loss: 2.457598134293447

Epoch: 38| Step: 0
Training loss: 3.6059070126545323
Validation loss: 2.4671904431706957

Epoch: 6| Step: 1
Training loss: 2.386694775350127
Validation loss: 2.4789730715803957

Epoch: 6| Step: 2
Training loss: 3.2057423388626027
Validation loss: 2.4655506176204764

Epoch: 6| Step: 3
Training loss: 2.5383032969523827
Validation loss: 2.4822412724652474

Epoch: 6| Step: 4
Training loss: 2.574549189243047
Validation loss: 2.4728293940894357

Epoch: 6| Step: 5
Training loss: 2.7011183859603682
Validation loss: 2.4540155227554896

Epoch: 6| Step: 6
Training loss: 2.9519200364424325
Validation loss: 2.4578024233729026

Epoch: 6| Step: 7
Training loss: 2.6947501217815266
Validation loss: 2.4558532813624288

Epoch: 6| Step: 8
Training loss: 3.0488709783383277
Validation loss: 2.4605983861835012

Epoch: 6| Step: 9
Training loss: 2.941057688614555
Validation loss: 2.477817421251475

Epoch: 6| Step: 10
Training loss: 2.4839074036666977
Validation loss: 2.481642943311936

Epoch: 6| Step: 11
Training loss: 2.6243750418626455
Validation loss: 2.4669283938662945

Epoch: 6| Step: 12
Training loss: 2.9128955621563697
Validation loss: 2.4733764561718554

Epoch: 6| Step: 13
Training loss: 3.055755818672698
Validation loss: 2.4659457777835794

Epoch: 39| Step: 0
Training loss: 2.5410128101564924
Validation loss: 2.4682211246460777

Epoch: 6| Step: 1
Training loss: 2.5652309844655528
Validation loss: 2.4808013426903655

Epoch: 6| Step: 2
Training loss: 3.072335777767081
Validation loss: 2.4705709167565835

Epoch: 6| Step: 3
Training loss: 2.9892350014953726
Validation loss: 2.459948209727131

Epoch: 6| Step: 4
Training loss: 2.905730170243897
Validation loss: 2.471692493847475

Epoch: 6| Step: 5
Training loss: 2.9370175229187248
Validation loss: 2.4753199703929787

Epoch: 6| Step: 6
Training loss: 2.387607739798715
Validation loss: 2.4674680597271705

Epoch: 6| Step: 7
Training loss: 2.97904324220311
Validation loss: 2.4805377413497514

Epoch: 6| Step: 8
Training loss: 3.5670153462277967
Validation loss: 2.484571299914622

Epoch: 6| Step: 9
Training loss: 2.794776342243082
Validation loss: 2.4705071520674946

Epoch: 6| Step: 10
Training loss: 2.4447772625527406
Validation loss: 2.4771328628340625

Epoch: 6| Step: 11
Training loss: 3.022122355833789
Validation loss: 2.468761483006468

Epoch: 6| Step: 12
Training loss: 2.784440000655165
Validation loss: 2.4617378523345708

Epoch: 6| Step: 13
Training loss: 2.4129780429136725
Validation loss: 2.456585804376829

Epoch: 40| Step: 0
Training loss: 2.8124188729347552
Validation loss: 2.46789080891051

Epoch: 6| Step: 1
Training loss: 2.882022904600871
Validation loss: 2.4691783522509203

Epoch: 6| Step: 2
Training loss: 2.597102652623292
Validation loss: 2.474794904436034

Epoch: 6| Step: 3
Training loss: 2.8404683052044595
Validation loss: 2.462368592176567

Epoch: 6| Step: 4
Training loss: 2.8783982137919426
Validation loss: 2.4626077390939978

Epoch: 6| Step: 5
Training loss: 2.282917406203063
Validation loss: 2.455713900348562

Epoch: 6| Step: 6
Training loss: 2.2871343935437767
Validation loss: 2.4619631081888937

Epoch: 6| Step: 7
Training loss: 2.924505508227223
Validation loss: 2.4689610657006535

Epoch: 6| Step: 8
Training loss: 3.408823143818124
Validation loss: 2.4573111264264753

Epoch: 6| Step: 9
Training loss: 2.588188827895676
Validation loss: 2.4616025110479165

Epoch: 6| Step: 10
Training loss: 2.9132632061907695
Validation loss: 2.4637898816964587

Epoch: 6| Step: 11
Training loss: 3.6013586023831317
Validation loss: 2.478940715783985

Epoch: 6| Step: 12
Training loss: 2.6754970873006108
Validation loss: 2.459203181046483

Epoch: 6| Step: 13
Training loss: 2.7489282947290143
Validation loss: 2.467641020867671

Epoch: 41| Step: 0
Training loss: 2.6515049457766486
Validation loss: 2.4585965993942467

Epoch: 6| Step: 1
Training loss: 2.259830826698187
Validation loss: 2.473930051131359

Epoch: 6| Step: 2
Training loss: 2.445459720945151
Validation loss: 2.455456794556528

Epoch: 6| Step: 3
Training loss: 3.160914232335273
Validation loss: 2.4625044368797413

Epoch: 6| Step: 4
Training loss: 3.0268456621498867
Validation loss: 2.44890418589483

Epoch: 6| Step: 5
Training loss: 3.104861102844464
Validation loss: 2.462860657619253

Epoch: 6| Step: 6
Training loss: 2.5323263634883757
Validation loss: 2.455400366720313

Epoch: 6| Step: 7
Training loss: 3.268747105788633
Validation loss: 2.4653376252588304

Epoch: 6| Step: 8
Training loss: 2.477115990434424
Validation loss: 2.4660550381333675

Epoch: 6| Step: 9
Training loss: 2.9199022783623336
Validation loss: 2.482925681088862

Epoch: 6| Step: 10
Training loss: 2.8122250740465184
Validation loss: 2.4550075869543986

Epoch: 6| Step: 11
Training loss: 2.7896486836405057
Validation loss: 2.466237216316733

Epoch: 6| Step: 12
Training loss: 3.2580399468152543
Validation loss: 2.4675007415466825

Epoch: 6| Step: 13
Training loss: 2.588176115591086
Validation loss: 2.4816269207835036

Epoch: 42| Step: 0
Training loss: 3.287289247900956
Validation loss: 2.4592241577588445

Epoch: 6| Step: 1
Training loss: 2.806987191546456
Validation loss: 2.471004508071962

Epoch: 6| Step: 2
Training loss: 2.489743939144611
Validation loss: 2.461230838792105

Epoch: 6| Step: 3
Training loss: 2.3558725798497235
Validation loss: 2.4597747300680175

Epoch: 6| Step: 4
Training loss: 3.1749457166942365
Validation loss: 2.4688531260344964

Epoch: 6| Step: 5
Training loss: 2.871563059538694
Validation loss: 2.4512736771106103

Epoch: 6| Step: 6
Training loss: 2.6558929203348294
Validation loss: 2.455581184716476

Epoch: 6| Step: 7
Training loss: 3.301044015752154
Validation loss: 2.458003461204555

Epoch: 6| Step: 8
Training loss: 2.775472490793173
Validation loss: 2.472591378883599

Epoch: 6| Step: 9
Training loss: 3.0342271480034504
Validation loss: 2.4588260143032907

Epoch: 6| Step: 10
Training loss: 2.37094673819632
Validation loss: 2.454319426104912

Epoch: 6| Step: 11
Training loss: 2.5798071719715145
Validation loss: 2.4584612322101393

Epoch: 6| Step: 12
Training loss: 2.7426981654246125
Validation loss: 2.460779172274238

Epoch: 6| Step: 13
Training loss: 3.313395253248252
Validation loss: 2.4576828625971796

Epoch: 43| Step: 0
Training loss: 2.9953249426132085
Validation loss: 2.480411171335703

Epoch: 6| Step: 1
Training loss: 3.02886648951447
Validation loss: 2.47274618421516

Epoch: 6| Step: 2
Training loss: 2.9937284401135202
Validation loss: 2.468406407226518

Epoch: 6| Step: 3
Training loss: 3.0144967454040748
Validation loss: 2.4634816852874493

Epoch: 6| Step: 4
Training loss: 2.77125175204155
Validation loss: 2.4577438630810566

Epoch: 6| Step: 5
Training loss: 2.963330914468139
Validation loss: 2.465225911137652

Epoch: 6| Step: 6
Training loss: 2.5488752689605567
Validation loss: 2.471051958225114

Epoch: 6| Step: 7
Training loss: 2.821843880685622
Validation loss: 2.467583341835408

Epoch: 6| Step: 8
Training loss: 2.6824138329594933
Validation loss: 2.454504151694417

Epoch: 6| Step: 9
Training loss: 2.311739719266113
Validation loss: 2.472335526876899

Epoch: 6| Step: 10
Training loss: 2.812197181506108
Validation loss: 2.4678039544998676

Epoch: 6| Step: 11
Training loss: 2.1557065859491615
Validation loss: 2.462692187821474

Epoch: 6| Step: 12
Training loss: 2.7275380135604856
Validation loss: 2.4729750619079596

Epoch: 6| Step: 13
Training loss: 4.001502231797951
Validation loss: 2.46068919449906

Epoch: 44| Step: 0
Training loss: 2.8262280588424527
Validation loss: 2.461172295493498

Epoch: 6| Step: 1
Training loss: 2.983538924934877
Validation loss: 2.4707983908217566

Epoch: 6| Step: 2
Training loss: 2.5038569262521997
Validation loss: 2.4530340099056636

Epoch: 6| Step: 3
Training loss: 3.1201173403266784
Validation loss: 2.4698305653354065

Epoch: 6| Step: 4
Training loss: 2.479956770797018
Validation loss: 2.462378942007246

Epoch: 6| Step: 5
Training loss: 3.6726670729804898
Validation loss: 2.451748067216212

Epoch: 6| Step: 6
Training loss: 2.5710016967281173
Validation loss: 2.46584783970216

Epoch: 6| Step: 7
Training loss: 2.5180526298070642
Validation loss: 2.462529482825582

Epoch: 6| Step: 8
Training loss: 2.9071671874185405
Validation loss: 2.473889849005792

Epoch: 6| Step: 9
Training loss: 2.4854645649040252
Validation loss: 2.450516297521442

Epoch: 6| Step: 10
Training loss: 2.414622812768465
Validation loss: 2.4570767747494133

Epoch: 6| Step: 11
Training loss: 2.937967953033899
Validation loss: 2.4555576005155446

Epoch: 6| Step: 12
Training loss: 2.8772996744244197
Validation loss: 2.4635826155479106

Epoch: 6| Step: 13
Training loss: 3.0853525887033806
Validation loss: 2.4513619643073907

Epoch: 45| Step: 0
Training loss: 2.172038229976454
Validation loss: 2.461597767229898

Epoch: 6| Step: 1
Training loss: 3.4260260778304246
Validation loss: 2.454376964047039

Epoch: 6| Step: 2
Training loss: 2.9711189856750226
Validation loss: 2.4567517350922565

Epoch: 6| Step: 3
Training loss: 2.5162015455633733
Validation loss: 2.4635550796846766

Epoch: 6| Step: 4
Training loss: 2.5570994898626664
Validation loss: 2.4579736444023554

Epoch: 6| Step: 5
Training loss: 2.607550342838234
Validation loss: 2.456744138340653

Epoch: 6| Step: 6
Training loss: 2.6310922679605846
Validation loss: 2.46242305089242

Epoch: 6| Step: 7
Training loss: 2.796698538045801
Validation loss: 2.467420643513871

Epoch: 6| Step: 8
Training loss: 3.472775160102086
Validation loss: 2.4707197672639993

Epoch: 6| Step: 9
Training loss: 2.9335129646728695
Validation loss: 2.454634917162799

Epoch: 6| Step: 10
Training loss: 2.8734559598395113
Validation loss: 2.4544490201001365

Epoch: 6| Step: 11
Training loss: 2.272888012317022
Validation loss: 2.458095773349539

Epoch: 6| Step: 12
Training loss: 2.8415978640582673
Validation loss: 2.4572436071073733

Epoch: 6| Step: 13
Training loss: 3.423146747480329
Validation loss: 2.466811460955702

Epoch: 46| Step: 0
Training loss: 2.8414736849083027
Validation loss: 2.462284518101849

Epoch: 6| Step: 1
Training loss: 3.6480595068177277
Validation loss: 2.462188456406095

Epoch: 6| Step: 2
Training loss: 2.852643537061042
Validation loss: 2.46185527615367

Epoch: 6| Step: 3
Training loss: 1.8515910858651732
Validation loss: 2.4570042594518724

Epoch: 6| Step: 4
Training loss: 2.440303950373547
Validation loss: 2.460486014067532

Epoch: 6| Step: 5
Training loss: 2.365583625542503
Validation loss: 2.4678564426283636

Epoch: 6| Step: 6
Training loss: 2.5455732704936347
Validation loss: 2.459213439952728

Epoch: 6| Step: 7
Training loss: 2.8968975572417675
Validation loss: 2.482695458817477

Epoch: 6| Step: 8
Training loss: 3.268478971663732
Validation loss: 2.47590114574349

Epoch: 6| Step: 9
Training loss: 2.4412800748645505
Validation loss: 2.4512004086321975

Epoch: 6| Step: 10
Training loss: 3.296846073258762
Validation loss: 2.45475716522214

Epoch: 6| Step: 11
Training loss: 2.9255853442214335
Validation loss: 2.4468720129894797

Epoch: 6| Step: 12
Training loss: 2.788362901496266
Validation loss: 2.4592072018422937

Epoch: 6| Step: 13
Training loss: 2.7970277542084743
Validation loss: 2.470792603217124

Epoch: 47| Step: 0
Training loss: 2.870229328842294
Validation loss: 2.4652521721273066

Epoch: 6| Step: 1
Training loss: 2.936626547959024
Validation loss: 2.473129499590766

Epoch: 6| Step: 2
Training loss: 2.6721942554719056
Validation loss: 2.4605751829544458

Epoch: 6| Step: 3
Training loss: 3.040449830956029
Validation loss: 2.4743156961687345

Epoch: 6| Step: 4
Training loss: 3.1488706229299375
Validation loss: 2.4689398583912543

Epoch: 6| Step: 5
Training loss: 3.3511944193003345
Validation loss: 2.446403456892242

Epoch: 6| Step: 6
Training loss: 2.8529016146163655
Validation loss: 2.462160422347587

Epoch: 6| Step: 7
Training loss: 2.8432616768230505
Validation loss: 2.4580554321901094

Epoch: 6| Step: 8
Training loss: 2.5680865356802975
Validation loss: 2.470980862541131

Epoch: 6| Step: 9
Training loss: 2.6678657120876896
Validation loss: 2.459717388221708

Epoch: 6| Step: 10
Training loss: 2.8756248790174666
Validation loss: 2.462531131863872

Epoch: 6| Step: 11
Training loss: 2.230092138773242
Validation loss: 2.457343539589278

Epoch: 6| Step: 12
Training loss: 2.9247246376253297
Validation loss: 2.4590814094288214

Epoch: 6| Step: 13
Training loss: 1.9457984531824215
Validation loss: 2.4589222396783823

Epoch: 48| Step: 0
Training loss: 2.931408674097693
Validation loss: 2.4818875730900225

Epoch: 6| Step: 1
Training loss: 2.8616903967550162
Validation loss: 2.4571315625500807

Epoch: 6| Step: 2
Training loss: 3.123289326697371
Validation loss: 2.455329763800256

Epoch: 6| Step: 3
Training loss: 2.9113861966736123
Validation loss: 2.447064750548601

Epoch: 6| Step: 4
Training loss: 2.097991405116714
Validation loss: 2.4388585723212164

Epoch: 6| Step: 5
Training loss: 3.143026619837607
Validation loss: 2.462147364424077

Epoch: 6| Step: 6
Training loss: 3.0684829191690044
Validation loss: 2.459715538227127

Epoch: 6| Step: 7
Training loss: 2.630276236586095
Validation loss: 2.471452602628405

Epoch: 6| Step: 8
Training loss: 2.8641008190332466
Validation loss: 2.4574147074588177

Epoch: 6| Step: 9
Training loss: 3.440932761970205
Validation loss: 2.450320577627985

Epoch: 6| Step: 10
Training loss: 2.6714705668646292
Validation loss: 2.4630766135250606

Epoch: 6| Step: 11
Training loss: 2.20509704635787
Validation loss: 2.4557591927121787

Epoch: 6| Step: 12
Training loss: 2.7700933362198517
Validation loss: 2.4515551509407296

Epoch: 6| Step: 13
Training loss: 2.1941881660579723
Validation loss: 2.4589807833755355

Epoch: 49| Step: 0
Training loss: 3.0124675448240374
Validation loss: 2.4753945859060025

Epoch: 6| Step: 1
Training loss: 2.0858893799678464
Validation loss: 2.468277521120265

Epoch: 6| Step: 2
Training loss: 3.0996352196465065
Validation loss: 2.450163341009496

Epoch: 6| Step: 3
Training loss: 3.0457118234954184
Validation loss: 2.4602129438473006

Epoch: 6| Step: 4
Training loss: 3.672450763120446
Validation loss: 2.4632822268820225

Epoch: 6| Step: 5
Training loss: 2.532772971803193
Validation loss: 2.463642979834768

Epoch: 6| Step: 6
Training loss: 2.8256316601278804
Validation loss: 2.462620063779352

Epoch: 6| Step: 7
Training loss: 2.5673873628537556
Validation loss: 2.4753916280898745

Epoch: 6| Step: 8
Training loss: 2.786266817065248
Validation loss: 2.462836428528341

Epoch: 6| Step: 9
Training loss: 2.865858222015501
Validation loss: 2.4481481896019885

Epoch: 6| Step: 10
Training loss: 2.350521427500744
Validation loss: 2.457024617163923

Epoch: 6| Step: 11
Training loss: 2.510315593621176
Validation loss: 2.453703260955939

Epoch: 6| Step: 12
Training loss: 2.643766802650967
Validation loss: 2.4625251436842004

Epoch: 6| Step: 13
Training loss: 3.457940795559297
Validation loss: 2.453521085184564

Epoch: 50| Step: 0
Training loss: 2.727628220884354
Validation loss: 2.473571327046782

Epoch: 6| Step: 1
Training loss: 2.970000957142069
Validation loss: 2.45271364912946

Epoch: 6| Step: 2
Training loss: 3.2752648399371487
Validation loss: 2.462856353932223

Epoch: 6| Step: 3
Training loss: 2.452766343643689
Validation loss: 2.467475478006224

Epoch: 6| Step: 4
Training loss: 3.132063397960714
Validation loss: 2.4476669610055906

Epoch: 6| Step: 5
Training loss: 2.6883426498500764
Validation loss: 2.4425920486364934

Epoch: 6| Step: 6
Training loss: 3.0564175362878565
Validation loss: 2.4511294619584896

Epoch: 6| Step: 7
Training loss: 2.631790551411765
Validation loss: 2.46084454229516

Epoch: 6| Step: 8
Training loss: 2.634497581517023
Validation loss: 2.452597190394008

Epoch: 6| Step: 9
Training loss: 2.669890977726764
Validation loss: 2.462824341218049

Epoch: 6| Step: 10
Training loss: 2.7909038887054516
Validation loss: 2.465468723894726

Epoch: 6| Step: 11
Training loss: 3.037237958240682
Validation loss: 2.4684094627306923

Epoch: 6| Step: 12
Training loss: 2.3500834024117134
Validation loss: 2.4691084246810564

Epoch: 6| Step: 13
Training loss: 3.0028683936833986
Validation loss: 2.477898882026501

Epoch: 51| Step: 0
Training loss: 3.3441435680325213
Validation loss: 2.464884876595676

Epoch: 6| Step: 1
Training loss: 1.8166873181187109
Validation loss: 2.4804378089980714

Epoch: 6| Step: 2
Training loss: 3.0894727327421783
Validation loss: 2.465763656044921

Epoch: 6| Step: 3
Training loss: 2.698644022060022
Validation loss: 2.455099909412118

Epoch: 6| Step: 4
Training loss: 2.3032310927242405
Validation loss: 2.454899537117116

Epoch: 6| Step: 5
Training loss: 2.9611995047647572
Validation loss: 2.46606861386075

Epoch: 6| Step: 6
Training loss: 2.6607688612932052
Validation loss: 2.467820861997789

Epoch: 6| Step: 7
Training loss: 3.5055442222120488
Validation loss: 2.4449418168424235

Epoch: 6| Step: 8
Training loss: 2.3521097249886602
Validation loss: 2.4636664304446447

Epoch: 6| Step: 9
Training loss: 2.92128939548579
Validation loss: 2.4571792618213566

Epoch: 6| Step: 10
Training loss: 2.9303628778820783
Validation loss: 2.466917335677005

Epoch: 6| Step: 11
Training loss: 2.4559531461986897
Validation loss: 2.4653103918467636

Epoch: 6| Step: 12
Training loss: 2.791791248862956
Validation loss: 2.4809494719326057

Epoch: 6| Step: 13
Training loss: 3.187011681345277
Validation loss: 2.459263000260508

Epoch: 52| Step: 0
Training loss: 2.4989917629391645
Validation loss: 2.447451045345835

Epoch: 6| Step: 1
Training loss: 3.5420240932444296
Validation loss: 2.452200986297717

Epoch: 6| Step: 2
Training loss: 2.3861774636179973
Validation loss: 2.4559923668908414

Epoch: 6| Step: 3
Training loss: 3.1340040571214502
Validation loss: 2.459892114198918

Epoch: 6| Step: 4
Training loss: 2.3939851570657193
Validation loss: 2.4459539344901544

Epoch: 6| Step: 5
Training loss: 3.074752896932901
Validation loss: 2.4514187057605867

Epoch: 6| Step: 6
Training loss: 2.8069357189269564
Validation loss: 2.44515566110105

Epoch: 6| Step: 7
Training loss: 3.0137253544550076
Validation loss: 2.4538276637396583

Epoch: 6| Step: 8
Training loss: 2.7912203778387608
Validation loss: 2.46909945387398

Epoch: 6| Step: 9
Training loss: 2.9452571307171196
Validation loss: 2.4575689249092814

Epoch: 6| Step: 10
Training loss: 3.0348879033963745
Validation loss: 2.463790112173245

Epoch: 6| Step: 11
Training loss: 2.5416704605157605
Validation loss: 2.446979479623865

Epoch: 6| Step: 12
Training loss: 2.207169520004991
Validation loss: 2.4528762250228144

Epoch: 6| Step: 13
Training loss: 2.3949491002481746
Validation loss: 2.470619005091519

Epoch: 53| Step: 0
Training loss: 2.688584840633076
Validation loss: 2.461344596551361

Epoch: 6| Step: 1
Training loss: 2.1207520155190527
Validation loss: 2.462092472700078

Epoch: 6| Step: 2
Training loss: 2.47563678756947
Validation loss: 2.445325983303796

Epoch: 6| Step: 3
Training loss: 2.590524897464752
Validation loss: 2.44802751955597

Epoch: 6| Step: 4
Training loss: 2.6066948380700032
Validation loss: 2.4527064506458656

Epoch: 6| Step: 5
Training loss: 3.111489195405081
Validation loss: 2.458105286486928

Epoch: 6| Step: 6
Training loss: 2.1900691612854097
Validation loss: 2.464414123158195

Epoch: 6| Step: 7
Training loss: 2.82256373114726
Validation loss: 2.4577576411784188

Epoch: 6| Step: 8
Training loss: 3.2954471623926955
Validation loss: 2.464668006209783

Epoch: 6| Step: 9
Training loss: 2.584600373742421
Validation loss: 2.4471823860644566

Epoch: 6| Step: 10
Training loss: 2.8075307391582305
Validation loss: 2.458966170779067

Epoch: 6| Step: 11
Training loss: 3.2434673678651755
Validation loss: 2.4515937230709715

Epoch: 6| Step: 12
Training loss: 3.527536245439673
Validation loss: 2.448236645006977

Epoch: 6| Step: 13
Training loss: 2.896894758994524
Validation loss: 2.442546435494209

Epoch: 54| Step: 0
Training loss: 3.106682766830354
Validation loss: 2.4402486902130702

Epoch: 6| Step: 1
Training loss: 2.4250831275141898
Validation loss: 2.4460471410436178

Epoch: 6| Step: 2
Training loss: 2.0526129979799697
Validation loss: 2.4522988160200945

Epoch: 6| Step: 3
Training loss: 2.640479992378076
Validation loss: 2.451716942561706

Epoch: 6| Step: 4
Training loss: 2.912952692435409
Validation loss: 2.4470381581816385

Epoch: 6| Step: 5
Training loss: 2.709023539308867
Validation loss: 2.439597515476457

Epoch: 6| Step: 6
Training loss: 2.484194958958779
Validation loss: 2.458317758862977

Epoch: 6| Step: 7
Training loss: 3.17033732307233
Validation loss: 2.4371016886608845

Epoch: 6| Step: 8
Training loss: 2.972235951931656
Validation loss: 2.4353630747261352

Epoch: 6| Step: 9
Training loss: 3.133865750171838
Validation loss: 2.4425208508705105

Epoch: 6| Step: 10
Training loss: 2.6634834085258867
Validation loss: 2.4498039847342814

Epoch: 6| Step: 11
Training loss: 2.895868278310868
Validation loss: 2.4470845026558794

Epoch: 6| Step: 12
Training loss: 3.0356155892364294
Validation loss: 2.4460078819386104

Epoch: 6| Step: 13
Training loss: 3.0507409243293555
Validation loss: 2.4371469240384815

Epoch: 55| Step: 0
Training loss: 2.4928663519065792
Validation loss: 2.4464537110598648

Epoch: 6| Step: 1
Training loss: 1.9988670716583212
Validation loss: 2.4511141446792517

Epoch: 6| Step: 2
Training loss: 2.6329179057859737
Validation loss: 2.4478972232406857

Epoch: 6| Step: 3
Training loss: 2.4203946419180764
Validation loss: 2.4417710775170063

Epoch: 6| Step: 4
Training loss: 3.0652741304310682
Validation loss: 2.456919498355181

Epoch: 6| Step: 5
Training loss: 2.917348364229319
Validation loss: 2.4421852713774648

Epoch: 6| Step: 6
Training loss: 2.936247051135223
Validation loss: 2.4410654142966313

Epoch: 6| Step: 7
Training loss: 3.400622557695462
Validation loss: 2.4496412766326645

Epoch: 6| Step: 8
Training loss: 3.050180686226298
Validation loss: 2.4239846284026907

Epoch: 6| Step: 9
Training loss: 2.9189990572481896
Validation loss: 2.445495019945879

Epoch: 6| Step: 10
Training loss: 2.9429502854705962
Validation loss: 2.4581864957788193

Epoch: 6| Step: 11
Training loss: 2.6313059313848353
Validation loss: 2.4506484264980335

Epoch: 6| Step: 12
Training loss: 2.7459988530178134
Validation loss: 2.4618606401158227

Epoch: 6| Step: 13
Training loss: 3.0788656979813287
Validation loss: 2.436443841526668

Epoch: 56| Step: 0
Training loss: 2.9312665015693566
Validation loss: 2.4475170803403166

Epoch: 6| Step: 1
Training loss: 2.730521751402393
Validation loss: 2.4390327560848832

Epoch: 6| Step: 2
Training loss: 3.211623515334269
Validation loss: 2.45039465812185

Epoch: 6| Step: 3
Training loss: 2.6442034249125643
Validation loss: 2.4735923049864508

Epoch: 6| Step: 4
Training loss: 3.0257256890594975
Validation loss: 2.4583184492252608

Epoch: 6| Step: 5
Training loss: 2.4309251582975855
Validation loss: 2.448281185646608

Epoch: 6| Step: 6
Training loss: 2.821295231501779
Validation loss: 2.4379179737888865

Epoch: 6| Step: 7
Training loss: 2.8687738089311052
Validation loss: 2.4641609224414687

Epoch: 6| Step: 8
Training loss: 2.3121299447563946
Validation loss: 2.4419913497892805

Epoch: 6| Step: 9
Training loss: 2.895605796455518
Validation loss: 2.4683927830799566

Epoch: 6| Step: 10
Training loss: 2.363003700288966
Validation loss: 2.4577402101877213

Epoch: 6| Step: 11
Training loss: 2.609187319282012
Validation loss: 2.4517130788776695

Epoch: 6| Step: 12
Training loss: 2.6829807519780347
Validation loss: 2.4320460157241093

Epoch: 6| Step: 13
Training loss: 3.792692290267533
Validation loss: 2.4650569711934196

Epoch: 57| Step: 0
Training loss: 2.9533332872354863
Validation loss: 2.447150287735918

Epoch: 6| Step: 1
Training loss: 2.9954943200269093
Validation loss: 2.4385395867443798

Epoch: 6| Step: 2
Training loss: 3.3221848179197533
Validation loss: 2.439899851330501

Epoch: 6| Step: 3
Training loss: 2.301574673850293
Validation loss: 2.4494746779490058

Epoch: 6| Step: 4
Training loss: 2.5706290655941
Validation loss: 2.439243649037408

Epoch: 6| Step: 5
Training loss: 3.1930870009987617
Validation loss: 2.449654770645696

Epoch: 6| Step: 6
Training loss: 2.298101603679646
Validation loss: 2.432106636227484

Epoch: 6| Step: 7
Training loss: 2.9681967771955917
Validation loss: 2.449015842694397

Epoch: 6| Step: 8
Training loss: 3.1061427506596644
Validation loss: 2.4576991684835425

Epoch: 6| Step: 9
Training loss: 2.776035005848941
Validation loss: 2.457236670200265

Epoch: 6| Step: 10
Training loss: 2.9565316386679066
Validation loss: 2.4542055641670038

Epoch: 6| Step: 11
Training loss: 2.508824224585725
Validation loss: 2.45480249821342

Epoch: 6| Step: 12
Training loss: 2.6853444525985046
Validation loss: 2.4418016491390637

Epoch: 6| Step: 13
Training loss: 1.5266975928732052
Validation loss: 2.4607674728283473

Epoch: 58| Step: 0
Training loss: 2.414728066750486
Validation loss: 2.4421184245627736

Epoch: 6| Step: 1
Training loss: 2.7508225511279694
Validation loss: 2.464542385378992

Epoch: 6| Step: 2
Training loss: 2.7049895454529063
Validation loss: 2.4665362130146065

Epoch: 6| Step: 3
Training loss: 2.95229121956649
Validation loss: 2.444191801772647

Epoch: 6| Step: 4
Training loss: 2.2353477228014205
Validation loss: 2.449792729948779

Epoch: 6| Step: 5
Training loss: 3.0218522206091887
Validation loss: 2.456517270563634

Epoch: 6| Step: 6
Training loss: 2.8069815856634004
Validation loss: 2.441042144598094

Epoch: 6| Step: 7
Training loss: 3.2210941112073077
Validation loss: 2.452989914038619

Epoch: 6| Step: 8
Training loss: 2.527370352509239
Validation loss: 2.4602933869887633

Epoch: 6| Step: 9
Training loss: 2.9756183077907803
Validation loss: 2.463297546552824

Epoch: 6| Step: 10
Training loss: 2.9143992375186714
Validation loss: 2.4526968616935645

Epoch: 6| Step: 11
Training loss: 2.6100011748095677
Validation loss: 2.453218033897548

Epoch: 6| Step: 12
Training loss: 2.63538522412588
Validation loss: 2.4493519077136092

Epoch: 6| Step: 13
Training loss: 3.494312160624908
Validation loss: 2.4377205398954094

Epoch: 59| Step: 0
Training loss: 3.10165843286776
Validation loss: 2.444144436420438

Epoch: 6| Step: 1
Training loss: 2.6954583612310037
Validation loss: 2.4564613586383386

Epoch: 6| Step: 2
Training loss: 2.5304021475007032
Validation loss: 2.4512988252558716

Epoch: 6| Step: 3
Training loss: 3.044349601951354
Validation loss: 2.459494068709445

Epoch: 6| Step: 4
Training loss: 2.952623112733762
Validation loss: 2.4393690656299887

Epoch: 6| Step: 5
Training loss: 2.712092172929927
Validation loss: 2.4473726543001053

Epoch: 6| Step: 6
Training loss: 2.377310281719159
Validation loss: 2.4494236798566584

Epoch: 6| Step: 7
Training loss: 3.4174042502596005
Validation loss: 2.4518697952643076

Epoch: 6| Step: 8
Training loss: 2.162424286856471
Validation loss: 2.4574923755024782

Epoch: 6| Step: 9
Training loss: 2.1083511693549326
Validation loss: 2.4482686830192444

Epoch: 6| Step: 10
Training loss: 2.667849894120011
Validation loss: 2.4558199392900963

Epoch: 6| Step: 11
Training loss: 3.163173220903252
Validation loss: 2.442382018966478

Epoch: 6| Step: 12
Training loss: 2.9642777336131356
Validation loss: 2.4572925634412557

Epoch: 6| Step: 13
Training loss: 2.797341419733152
Validation loss: 2.447831406916184

Epoch: 60| Step: 0
Training loss: 2.4678265739852097
Validation loss: 2.4407098027978096

Epoch: 6| Step: 1
Training loss: 2.742703120343424
Validation loss: 2.4431475991217115

Epoch: 6| Step: 2
Training loss: 2.484188144782512
Validation loss: 2.4509188841250595

Epoch: 6| Step: 3
Training loss: 2.534582040704785
Validation loss: 2.4470576496406933

Epoch: 6| Step: 4
Training loss: 2.995218758466863
Validation loss: 2.452471055803141

Epoch: 6| Step: 5
Training loss: 3.0017721981607597
Validation loss: 2.4492873038168486

Epoch: 6| Step: 6
Training loss: 2.439131948495286
Validation loss: 2.4642688106747843

Epoch: 6| Step: 7
Training loss: 3.3434607835275005
Validation loss: 2.452392623467623

Epoch: 6| Step: 8
Training loss: 2.876286591948201
Validation loss: 2.442304045168249

Epoch: 6| Step: 9
Training loss: 3.101347101452684
Validation loss: 2.4542649223232824

Epoch: 6| Step: 10
Training loss: 2.752320264444843
Validation loss: 2.453332780772856

Epoch: 6| Step: 11
Training loss: 3.021555233342129
Validation loss: 2.453028832525709

Epoch: 6| Step: 12
Training loss: 2.5715722240709633
Validation loss: 2.4389946212247433

Epoch: 6| Step: 13
Training loss: 2.2354968262515302
Validation loss: 2.458065901347786

Epoch: 61| Step: 0
Training loss: 2.5784550311073153
Validation loss: 2.4405155885447654

Epoch: 6| Step: 1
Training loss: 2.27340834556317
Validation loss: 2.443617622485474

Epoch: 6| Step: 2
Training loss: 3.569916216938357
Validation loss: 2.4595264697813786

Epoch: 6| Step: 3
Training loss: 2.112720238756418
Validation loss: 2.462602193538031

Epoch: 6| Step: 4
Training loss: 3.0414471133348497
Validation loss: 2.456664353290254

Epoch: 6| Step: 5
Training loss: 3.304979243826506
Validation loss: 2.4526000377237955

Epoch: 6| Step: 6
Training loss: 2.590789116054405
Validation loss: 2.4422400247977505

Epoch: 6| Step: 7
Training loss: 3.0563772849820583
Validation loss: 2.438328367946012

Epoch: 6| Step: 8
Training loss: 2.616148785247646
Validation loss: 2.4556599338440828

Epoch: 6| Step: 9
Training loss: 2.2383907484396453
Validation loss: 2.4533625223138573

Epoch: 6| Step: 10
Training loss: 3.0617836873535875
Validation loss: 2.4579503908420652

Epoch: 6| Step: 11
Training loss: 2.738892752245108
Validation loss: 2.4569274138552806

Epoch: 6| Step: 12
Training loss: 2.7156661510093234
Validation loss: 2.457367443618663

Epoch: 6| Step: 13
Training loss: 2.685895573952883
Validation loss: 2.4604737974725572

Epoch: 62| Step: 0
Training loss: 2.6840989527135104
Validation loss: 2.448587151321155

Epoch: 6| Step: 1
Training loss: 2.461727923657931
Validation loss: 2.4476779563899185

Epoch: 6| Step: 2
Training loss: 2.893498162996254
Validation loss: 2.4537043433733428

Epoch: 6| Step: 3
Training loss: 2.275206202290125
Validation loss: 2.4623420849176196

Epoch: 6| Step: 4
Training loss: 3.2304104450319593
Validation loss: 2.462401187593046

Epoch: 6| Step: 5
Training loss: 2.844215606468093
Validation loss: 2.463084653913036

Epoch: 6| Step: 6
Training loss: 3.018990017844418
Validation loss: 2.459432070306928

Epoch: 6| Step: 7
Training loss: 2.4953126834494297
Validation loss: 2.453475575960919

Epoch: 6| Step: 8
Training loss: 3.2824970600379393
Validation loss: 2.4491593082735035

Epoch: 6| Step: 9
Training loss: 2.278891402318147
Validation loss: 2.450768304297471

Epoch: 6| Step: 10
Training loss: 2.3202961622491416
Validation loss: 2.4355240073004114

Epoch: 6| Step: 11
Training loss: 2.9229771784316627
Validation loss: 2.434958888490966

Epoch: 6| Step: 12
Training loss: 3.203253468984317
Validation loss: 2.4499325284023663

Epoch: 6| Step: 13
Training loss: 2.822295107572001
Validation loss: 2.456194674378573

Epoch: 63| Step: 0
Training loss: 2.4815600300003053
Validation loss: 2.4575818329525076

Epoch: 6| Step: 1
Training loss: 2.590837981116722
Validation loss: 2.4329888222003184

Epoch: 6| Step: 2
Training loss: 3.257295489738489
Validation loss: 2.4625758688935497

Epoch: 6| Step: 3
Training loss: 2.44455314765405
Validation loss: 2.4425434693877186

Epoch: 6| Step: 4
Training loss: 2.394211814694566
Validation loss: 2.447805479549002

Epoch: 6| Step: 5
Training loss: 3.0877198299342097
Validation loss: 2.4581219728466848

Epoch: 6| Step: 6
Training loss: 2.848771576743204
Validation loss: 2.460661768990662

Epoch: 6| Step: 7
Training loss: 2.5643711236770566
Validation loss: 2.460959301819583

Epoch: 6| Step: 8
Training loss: 3.110221402545414
Validation loss: 2.4438760283556764

Epoch: 6| Step: 9
Training loss: 3.3102700266800187
Validation loss: 2.457266704602924

Epoch: 6| Step: 10
Training loss: 2.345409873653931
Validation loss: 2.455294271025609

Epoch: 6| Step: 11
Training loss: 3.3574960111252077
Validation loss: 2.45938694356814

Epoch: 6| Step: 12
Training loss: 2.0643347468942888
Validation loss: 2.4529784543970328

Epoch: 6| Step: 13
Training loss: 2.615988750071936
Validation loss: 2.446727544680939

Epoch: 64| Step: 0
Training loss: 2.9345937109092137
Validation loss: 2.45140193141829

Epoch: 6| Step: 1
Training loss: 3.217774178442631
Validation loss: 2.4429353935161116

Epoch: 6| Step: 2
Training loss: 2.7265158925267476
Validation loss: 2.4381195660845876

Epoch: 6| Step: 3
Training loss: 2.2543490022916375
Validation loss: 2.448495547606605

Epoch: 6| Step: 4
Training loss: 2.1384210308800413
Validation loss: 2.44844960363639

Epoch: 6| Step: 5
Training loss: 3.3513998779111094
Validation loss: 2.451437107207557

Epoch: 6| Step: 6
Training loss: 2.4953826225617983
Validation loss: 2.4444665442474856

Epoch: 6| Step: 7
Training loss: 2.846781362088623
Validation loss: 2.461176082871649

Epoch: 6| Step: 8
Training loss: 2.933837230346128
Validation loss: 2.4567677925443037

Epoch: 6| Step: 9
Training loss: 2.6326344596816367
Validation loss: 2.450062010187303

Epoch: 6| Step: 10
Training loss: 2.1728857967808732
Validation loss: 2.4713532800844766

Epoch: 6| Step: 11
Training loss: 3.4146068846049618
Validation loss: 2.4418156851739576

Epoch: 6| Step: 12
Training loss: 2.554232868956674
Validation loss: 2.436711266029252

Epoch: 6| Step: 13
Training loss: 2.7738655727078956
Validation loss: 2.4467486322798417

Epoch: 65| Step: 0
Training loss: 2.9863329151980875
Validation loss: 2.4394376251096888

Epoch: 6| Step: 1
Training loss: 2.2449587400591287
Validation loss: 2.444763564400376

Epoch: 6| Step: 2
Training loss: 2.6945014949758335
Validation loss: 2.447429986843699

Epoch: 6| Step: 3
Training loss: 3.067097541006775
Validation loss: 2.45073839214657

Epoch: 6| Step: 4
Training loss: 2.893879476002907
Validation loss: 2.452201498565589

Epoch: 6| Step: 5
Training loss: 3.216928800137076
Validation loss: 2.4510189599459715

Epoch: 6| Step: 6
Training loss: 2.6988723024658077
Validation loss: 2.4452150355500786

Epoch: 6| Step: 7
Training loss: 2.435942714800584
Validation loss: 2.4411723520770026

Epoch: 6| Step: 8
Training loss: 2.6742477143502468
Validation loss: 2.4406919995401757

Epoch: 6| Step: 9
Training loss: 2.5587191718424287
Validation loss: 2.446445275444426

Epoch: 6| Step: 10
Training loss: 2.9936158279583625
Validation loss: 2.4397518031238503

Epoch: 6| Step: 11
Training loss: 2.547089175714696
Validation loss: 2.4588257922235353

Epoch: 6| Step: 12
Training loss: 2.6986723814735414
Validation loss: 2.4443633018128965

Epoch: 6| Step: 13
Training loss: 3.2539729263783106
Validation loss: 2.4409416250803653

Epoch: 66| Step: 0
Training loss: 2.9186110600274158
Validation loss: 2.4508916698867695

Epoch: 6| Step: 1
Training loss: 2.809985499090064
Validation loss: 2.426442173886197

Epoch: 6| Step: 2
Training loss: 2.721913831676891
Validation loss: 2.4574325048418704

Epoch: 6| Step: 3
Training loss: 3.11018874671975
Validation loss: 2.4594188634310585

Epoch: 6| Step: 4
Training loss: 2.4093063562413763
Validation loss: 2.451676483370826

Epoch: 6| Step: 5
Training loss: 3.327686979455812
Validation loss: 2.443496198870868

Epoch: 6| Step: 6
Training loss: 2.7552131311462587
Validation loss: 2.4567159790228215

Epoch: 6| Step: 7
Training loss: 2.7694120179674333
Validation loss: 2.4397044860741732

Epoch: 6| Step: 8
Training loss: 2.7944303942816515
Validation loss: 2.441313002251493

Epoch: 6| Step: 9
Training loss: 2.75112796538796
Validation loss: 2.4316345955403746

Epoch: 6| Step: 10
Training loss: 2.5623129799679063
Validation loss: 2.447057030484129

Epoch: 6| Step: 11
Training loss: 2.847611205865883
Validation loss: 2.4509361601849076

Epoch: 6| Step: 12
Training loss: 2.2861974707857686
Validation loss: 2.4513746467223165

Epoch: 6| Step: 13
Training loss: 2.6453013348329697
Validation loss: 2.4496604438858434

Epoch: 67| Step: 0
Training loss: 2.1891959019705363
Validation loss: 2.4289438147322864

Epoch: 6| Step: 1
Training loss: 2.174455934198651
Validation loss: 2.430987431313291

Epoch: 6| Step: 2
Training loss: 3.4197231825401655
Validation loss: 2.44121309614788

Epoch: 6| Step: 3
Training loss: 3.154634874499147
Validation loss: 2.4368499370726395

Epoch: 6| Step: 4
Training loss: 2.8390816737752034
Validation loss: 2.441359376650166

Epoch: 6| Step: 5
Training loss: 2.6218934523395765
Validation loss: 2.4354968605097143

Epoch: 6| Step: 6
Training loss: 2.8558541388783896
Validation loss: 2.431796372600798

Epoch: 6| Step: 7
Training loss: 2.8070970985679446
Validation loss: 2.446165792822496

Epoch: 6| Step: 8
Training loss: 3.0961678044878904
Validation loss: 2.4483998474802267

Epoch: 6| Step: 9
Training loss: 2.756712610430022
Validation loss: 2.4575406582067285

Epoch: 6| Step: 10
Training loss: 2.541694568001446
Validation loss: 2.448163755815282

Epoch: 6| Step: 11
Training loss: 2.9309341423161044
Validation loss: 2.4601435857200866

Epoch: 6| Step: 12
Training loss: 2.713232822134314
Validation loss: 2.438090040270541

Epoch: 6| Step: 13
Training loss: 2.207635685346173
Validation loss: 2.441885827393099

Epoch: 68| Step: 0
Training loss: 2.433362040502792
Validation loss: 2.4585565177534923

Epoch: 6| Step: 1
Training loss: 2.649816103618439
Validation loss: 2.4555731886641694

Epoch: 6| Step: 2
Training loss: 2.7961324206798666
Validation loss: 2.4433707276186607

Epoch: 6| Step: 3
Training loss: 2.985088642535827
Validation loss: 2.441395195917515

Epoch: 6| Step: 4
Training loss: 2.2875359037322798
Validation loss: 2.4362898336962786

Epoch: 6| Step: 5
Training loss: 2.8193744991084717
Validation loss: 2.442717327945601

Epoch: 6| Step: 6
Training loss: 2.5692700530202504
Validation loss: 2.4357965100004626

Epoch: 6| Step: 7
Training loss: 2.8407677743616357
Validation loss: 2.44431575781418

Epoch: 6| Step: 8
Training loss: 2.935364616659957
Validation loss: 2.4455593141437006

Epoch: 6| Step: 9
Training loss: 3.216290469398702
Validation loss: 2.4443357581537173

Epoch: 6| Step: 10
Training loss: 2.712110545946429
Validation loss: 2.4492994966597967

Epoch: 6| Step: 11
Training loss: 2.6163828053966034
Validation loss: 2.4397699888930178

Epoch: 6| Step: 12
Training loss: 3.187921683150003
Validation loss: 2.4499396952728114

Epoch: 6| Step: 13
Training loss: 2.6166816791986576
Validation loss: 2.44952499626812

Epoch: 69| Step: 0
Training loss: 2.4819557358562534
Validation loss: 2.4495025060601794

Epoch: 6| Step: 1
Training loss: 3.457664578286549
Validation loss: 2.44890535313471

Epoch: 6| Step: 2
Training loss: 2.300809746713115
Validation loss: 2.4614796697715735

Epoch: 6| Step: 3
Training loss: 2.3196723645803523
Validation loss: 2.4581429533102845

Epoch: 6| Step: 4
Training loss: 3.17211146483296
Validation loss: 2.452018890243589

Epoch: 6| Step: 5
Training loss: 3.462698942452903
Validation loss: 2.443658726541363

Epoch: 6| Step: 6
Training loss: 2.1662744998592016
Validation loss: 2.458134812281744

Epoch: 6| Step: 7
Training loss: 2.9341040928011703
Validation loss: 2.442665768437978

Epoch: 6| Step: 8
Training loss: 2.4476829471343673
Validation loss: 2.452010482138162

Epoch: 6| Step: 9
Training loss: 2.5477067958165733
Validation loss: 2.4555619540570666

Epoch: 6| Step: 10
Training loss: 2.7696218973452225
Validation loss: 2.4485421534702203

Epoch: 6| Step: 11
Training loss: 2.539673623119513
Validation loss: 2.4529579721792434

Epoch: 6| Step: 12
Training loss: 2.543310092688184
Validation loss: 2.450782505511176

Epoch: 6| Step: 13
Training loss: 3.529889275000309
Validation loss: 2.4627220224455186

Epoch: 70| Step: 0
Training loss: 2.10810983651818
Validation loss: 2.454865592055931

Epoch: 6| Step: 1
Training loss: 3.0933783722207577
Validation loss: 2.4398671418118227

Epoch: 6| Step: 2
Training loss: 2.6978149296689855
Validation loss: 2.4388277588270033

Epoch: 6| Step: 3
Training loss: 3.4812613632591978
Validation loss: 2.4461402502464513

Epoch: 6| Step: 4
Training loss: 2.5865899959815843
Validation loss: 2.4513918542083384

Epoch: 6| Step: 5
Training loss: 2.7127957969443974
Validation loss: 2.446956868585118

Epoch: 6| Step: 6
Training loss: 3.0487807353880245
Validation loss: 2.4478299584847125

Epoch: 6| Step: 7
Training loss: 3.1142135621758253
Validation loss: 2.458284683295378

Epoch: 6| Step: 8
Training loss: 2.4933079798662257
Validation loss: 2.451660032337466

Epoch: 6| Step: 9
Training loss: 2.9139869005148378
Validation loss: 2.44436298297862

Epoch: 6| Step: 10
Training loss: 2.3668327443410653
Validation loss: 2.4385681735706655

Epoch: 6| Step: 11
Training loss: 2.8914259342244044
Validation loss: 2.477106298817323

Epoch: 6| Step: 12
Training loss: 2.319439348023603
Validation loss: 2.453676953678028

Epoch: 6| Step: 13
Training loss: 2.6462669818172913
Validation loss: 2.4552263850838805

Epoch: 71| Step: 0
Training loss: 3.997883236605986
Validation loss: 2.462753967786021

Epoch: 6| Step: 1
Training loss: 2.537678408810496
Validation loss: 2.4599268595817962

Epoch: 6| Step: 2
Training loss: 3.2018778536275834
Validation loss: 2.447975276506327

Epoch: 6| Step: 3
Training loss: 2.232850308161572
Validation loss: 2.449252043770553

Epoch: 6| Step: 4
Training loss: 2.089102183887351
Validation loss: 2.4424754074846473

Epoch: 6| Step: 5
Training loss: 2.5675336199289256
Validation loss: 2.449116887594783

Epoch: 6| Step: 6
Training loss: 3.3245962715271675
Validation loss: 2.4408264600530223

Epoch: 6| Step: 7
Training loss: 2.5115560475952754
Validation loss: 2.443660544629757

Epoch: 6| Step: 8
Training loss: 2.3807927811582394
Validation loss: 2.4371328947761386

Epoch: 6| Step: 9
Training loss: 2.247543901772125
Validation loss: 2.446647596449509

Epoch: 6| Step: 10
Training loss: 2.403192336152272
Validation loss: 2.439092032582941

Epoch: 6| Step: 11
Training loss: 3.5107386561178346
Validation loss: 2.4645097511874234

Epoch: 6| Step: 12
Training loss: 2.3645683881872714
Validation loss: 2.4437552407210115

Epoch: 6| Step: 13
Training loss: 2.2923626854227397
Validation loss: 2.4517454468463002

Epoch: 72| Step: 0
Training loss: 1.9387993916086572
Validation loss: 2.445861844862002

Epoch: 6| Step: 1
Training loss: 2.481899539669607
Validation loss: 2.4552816882110653

Epoch: 6| Step: 2
Training loss: 3.2415072175521793
Validation loss: 2.4474655695732523

Epoch: 6| Step: 3
Training loss: 2.695251641070163
Validation loss: 2.462684164890042

Epoch: 6| Step: 4
Training loss: 2.6729707311532707
Validation loss: 2.4356421570511464

Epoch: 6| Step: 5
Training loss: 2.751247643171217
Validation loss: 2.4596921260346334

Epoch: 6| Step: 6
Training loss: 2.8184344941912123
Validation loss: 2.4527943518092687

Epoch: 6| Step: 7
Training loss: 2.6073929802940183
Validation loss: 2.46180111624681

Epoch: 6| Step: 8
Training loss: 2.5811353274682896
Validation loss: 2.4449207304365457

Epoch: 6| Step: 9
Training loss: 2.5544838547105853
Validation loss: 2.460926820126649

Epoch: 6| Step: 10
Training loss: 2.821613466092135
Validation loss: 2.4542376955706997

Epoch: 6| Step: 11
Training loss: 2.907387623603753
Validation loss: 2.4682956109683256

Epoch: 6| Step: 12
Training loss: 3.3662374266890023
Validation loss: 2.4574152426340565

Epoch: 6| Step: 13
Training loss: 3.182782141082354
Validation loss: 2.464275382399521

Epoch: 73| Step: 0
Training loss: 2.323788694456614
Validation loss: 2.4546407125766074

Epoch: 6| Step: 1
Training loss: 2.6072098206432566
Validation loss: 2.4678725789728175

Epoch: 6| Step: 2
Training loss: 2.495787504748724
Validation loss: 2.449159862000547

Epoch: 6| Step: 3
Training loss: 3.588989953257395
Validation loss: 2.4468692134757903

Epoch: 6| Step: 4
Training loss: 3.6891274174653987
Validation loss: 2.4690818776426657

Epoch: 6| Step: 5
Training loss: 1.9241780693781387
Validation loss: 2.450305743892644

Epoch: 6| Step: 6
Training loss: 2.879312846277014
Validation loss: 2.46890861403568

Epoch: 6| Step: 7
Training loss: 3.0599011663295723
Validation loss: 2.4677355026476553

Epoch: 6| Step: 8
Training loss: 2.600740778371224
Validation loss: 2.452094570258962

Epoch: 6| Step: 9
Training loss: 2.732835434326114
Validation loss: 2.454978226657712

Epoch: 6| Step: 10
Training loss: 2.6407393932958327
Validation loss: 2.454036589515122

Epoch: 6| Step: 11
Training loss: 2.498849317858241
Validation loss: 2.4443718122604667

Epoch: 6| Step: 12
Training loss: 2.3397332931200876
Validation loss: 2.448508128649182

Epoch: 6| Step: 13
Training loss: 3.158153752947804
Validation loss: 2.447328924671141

Epoch: 74| Step: 0
Training loss: 2.5792698023506326
Validation loss: 2.453474160118798

Epoch: 6| Step: 1
Training loss: 2.459576330220741
Validation loss: 2.448885546621195

Epoch: 6| Step: 2
Training loss: 3.035337543350854
Validation loss: 2.4366390652529266

Epoch: 6| Step: 3
Training loss: 2.9207373051405443
Validation loss: 2.4459952775549754

Epoch: 6| Step: 4
Training loss: 2.6038958192485353
Validation loss: 2.4437722133691375

Epoch: 6| Step: 5
Training loss: 2.910416436565138
Validation loss: 2.4569051865320244

Epoch: 6| Step: 6
Training loss: 2.1868365780403383
Validation loss: 2.456963940020645

Epoch: 6| Step: 7
Training loss: 2.09005068886356
Validation loss: 2.4427832831090797

Epoch: 6| Step: 8
Training loss: 2.458598451273508
Validation loss: 2.4381929416518116

Epoch: 6| Step: 9
Training loss: 2.9799362646878143
Validation loss: 2.4717589412029195

Epoch: 6| Step: 10
Training loss: 3.260871896051873
Validation loss: 2.4584296440361957

Epoch: 6| Step: 11
Training loss: 3.09610820249986
Validation loss: 2.45354705873009

Epoch: 6| Step: 12
Training loss: 3.027791990505384
Validation loss: 2.456542743854857

Epoch: 6| Step: 13
Training loss: 2.7761876185389305
Validation loss: 2.451909779191013

Epoch: 75| Step: 0
Training loss: 2.2067001229407386
Validation loss: 2.469103807938175

Epoch: 6| Step: 1
Training loss: 3.0939341788907058
Validation loss: 2.4426216837603385

Epoch: 6| Step: 2
Training loss: 2.719937032503678
Validation loss: 2.4571945663324897

Epoch: 6| Step: 3
Training loss: 3.5508436946602835
Validation loss: 2.461749220172351

Epoch: 6| Step: 4
Training loss: 2.907147012736389
Validation loss: 2.4300305919881344

Epoch: 6| Step: 5
Training loss: 2.4031777523684674
Validation loss: 2.452984954993724

Epoch: 6| Step: 6
Training loss: 2.7031569286070445
Validation loss: 2.4451328748783063

Epoch: 6| Step: 7
Training loss: 2.9738850403598938
Validation loss: 2.4664050245609572

Epoch: 6| Step: 8
Training loss: 2.5403808926922857
Validation loss: 2.4791862833086817

Epoch: 6| Step: 9
Training loss: 2.825725485895076
Validation loss: 2.4576152053648737

Epoch: 6| Step: 10
Training loss: 2.313864743413445
Validation loss: 2.460351953284684

Epoch: 6| Step: 11
Training loss: 2.390321001657894
Validation loss: 2.472939437779478

Epoch: 6| Step: 12
Training loss: 3.2124278375855133
Validation loss: 2.4705912954999953

Epoch: 6| Step: 13
Training loss: 1.932466675543825
Validation loss: 2.4630295811531147

Epoch: 76| Step: 0
Training loss: 2.1073639502002295
Validation loss: 2.4449669063876884

Epoch: 6| Step: 1
Training loss: 2.5334668283257726
Validation loss: 2.4585478316956113

Epoch: 6| Step: 2
Training loss: 2.8047633253808364
Validation loss: 2.453412025265455

Epoch: 6| Step: 3
Training loss: 2.899116868346809
Validation loss: 2.455597097399063

Epoch: 6| Step: 4
Training loss: 2.8143482493146457
Validation loss: 2.4412894755339036

Epoch: 6| Step: 5
Training loss: 2.7466279944070773
Validation loss: 2.4584904862596018

Epoch: 6| Step: 6
Training loss: 2.6278534775042077
Validation loss: 2.4564364000624392

Epoch: 6| Step: 7
Training loss: 2.696272615453731
Validation loss: 2.4408410919702157

Epoch: 6| Step: 8
Training loss: 3.0221774213250283
Validation loss: 2.4350127299958246

Epoch: 6| Step: 9
Training loss: 2.614892665199223
Validation loss: 2.4447104666877166

Epoch: 6| Step: 10
Training loss: 3.2756365033773664
Validation loss: 2.458848123128787

Epoch: 6| Step: 11
Training loss: 2.808722014277153
Validation loss: 2.4386386352182154

Epoch: 6| Step: 12
Training loss: 3.0087320086484475
Validation loss: 2.446134542641097

Epoch: 6| Step: 13
Training loss: 2.308008316606846
Validation loss: 2.425187688612797

Epoch: 77| Step: 0
Training loss: 2.834566147319599
Validation loss: 2.4438579245429426

Epoch: 6| Step: 1
Training loss: 2.0702738056525503
Validation loss: 2.440800899413542

Epoch: 6| Step: 2
Training loss: 2.8873807279715846
Validation loss: 2.4558390562324575

Epoch: 6| Step: 3
Training loss: 2.4815167953842114
Validation loss: 2.4440193718717693

Epoch: 6| Step: 4
Training loss: 2.8384416941731785
Validation loss: 2.4576415946191634

Epoch: 6| Step: 5
Training loss: 2.5805068601957983
Validation loss: 2.467331929307778

Epoch: 6| Step: 6
Training loss: 2.830415588435606
Validation loss: 2.4490386220996774

Epoch: 6| Step: 7
Training loss: 3.204271064978949
Validation loss: 2.456596580346915

Epoch: 6| Step: 8
Training loss: 3.0391977471311393
Validation loss: 2.450302110252005

Epoch: 6| Step: 9
Training loss: 2.873757467040341
Validation loss: 2.443935217802884

Epoch: 6| Step: 10
Training loss: 2.3125995923840392
Validation loss: 2.4490382515343274

Epoch: 6| Step: 11
Training loss: 3.1785792263419084
Validation loss: 2.4431964517672986

Epoch: 6| Step: 12
Training loss: 2.675691789676966
Validation loss: 2.4663221062338927

Epoch: 6| Step: 13
Training loss: 2.312591035442863
Validation loss: 2.4455419246231793

Epoch: 78| Step: 0
Training loss: 2.732723936518326
Validation loss: 2.462271411380917

Epoch: 6| Step: 1
Training loss: 3.0514243567821855
Validation loss: 2.4513614455892623

Epoch: 6| Step: 2
Training loss: 2.6607404563106845
Validation loss: 2.4643535156075815

Epoch: 6| Step: 3
Training loss: 2.7568727788784337
Validation loss: 2.439354558353881

Epoch: 6| Step: 4
Training loss: 2.7878237412286673
Validation loss: 2.4599698186597476

Epoch: 6| Step: 5
Training loss: 2.0936238265096025
Validation loss: 2.4465401686778843

Epoch: 6| Step: 6
Training loss: 2.7389367988149766
Validation loss: 2.4651458525456666

Epoch: 6| Step: 7
Training loss: 2.732984265468847
Validation loss: 2.4677044149774665

Epoch: 6| Step: 8
Training loss: 3.064464639577634
Validation loss: 2.465303886314223

Epoch: 6| Step: 9
Training loss: 3.069407866093638
Validation loss: 2.469169532245644

Epoch: 6| Step: 10
Training loss: 2.6865146516179945
Validation loss: 2.4612063160650157

Epoch: 6| Step: 11
Training loss: 3.0448222752712977
Validation loss: 2.438668114968497

Epoch: 6| Step: 12
Training loss: 2.377187624846458
Validation loss: 2.4691120078033384

Epoch: 6| Step: 13
Training loss: 2.478311685118268
Validation loss: 2.45310601239563

Epoch: 79| Step: 0
Training loss: 2.6686189677390826
Validation loss: 2.453624400966317

Epoch: 6| Step: 1
Training loss: 2.378790390625912
Validation loss: 2.4601513334947374

Epoch: 6| Step: 2
Training loss: 3.1087990999044783
Validation loss: 2.4648284981843065

Epoch: 6| Step: 3
Training loss: 2.488517714063536
Validation loss: 2.459166036588456

Epoch: 6| Step: 4
Training loss: 2.2317071740156633
Validation loss: 2.444359019571433

Epoch: 6| Step: 5
Training loss: 2.632477690918267
Validation loss: 2.432603596869235

Epoch: 6| Step: 6
Training loss: 3.737017474714728
Validation loss: 2.455331897965393

Epoch: 6| Step: 7
Training loss: 2.7332140392539697
Validation loss: 2.445562333199681

Epoch: 6| Step: 8
Training loss: 2.905874248537853
Validation loss: 2.4411718007388377

Epoch: 6| Step: 9
Training loss: 2.594798783749795
Validation loss: 2.441327439084137

Epoch: 6| Step: 10
Training loss: 2.681958629092791
Validation loss: 2.4342258572440265

Epoch: 6| Step: 11
Training loss: 2.652582306730921
Validation loss: 2.4544235334351376

Epoch: 6| Step: 12
Training loss: 3.129517608617418
Validation loss: 2.4398799307336794

Epoch: 6| Step: 13
Training loss: 1.7215648143265962
Validation loss: 2.4488953766180632

Epoch: 80| Step: 0
Training loss: 2.8740197874169824
Validation loss: 2.435463798699384

Epoch: 6| Step: 1
Training loss: 2.585447881624418
Validation loss: 2.4354941858134183

Epoch: 6| Step: 2
Training loss: 2.726768157985263
Validation loss: 2.448755078202349

Epoch: 6| Step: 3
Training loss: 2.7669842499456014
Validation loss: 2.4445041375439898

Epoch: 6| Step: 4
Training loss: 3.090998495308279
Validation loss: 2.431713221936072

Epoch: 6| Step: 5
Training loss: 2.982336496506314
Validation loss: 2.4467592137308554

Epoch: 6| Step: 6
Training loss: 2.974551344948571
Validation loss: 2.447200013776168

Epoch: 6| Step: 7
Training loss: 2.7733750887013815
Validation loss: 2.4483013499254125

Epoch: 6| Step: 8
Training loss: 2.304305119232158
Validation loss: 2.453849776854608

Epoch: 6| Step: 9
Training loss: 3.194646266882738
Validation loss: 2.4535426274273706

Epoch: 6| Step: 10
Training loss: 2.4990316422906536
Validation loss: 2.453280881118807

Epoch: 6| Step: 11
Training loss: 2.654653181423396
Validation loss: 2.455123148724666

Epoch: 6| Step: 12
Training loss: 2.0209614690158806
Validation loss: 2.443561646210168

Epoch: 6| Step: 13
Training loss: 2.8067183513669742
Validation loss: 2.4447998989928954

Epoch: 81| Step: 0
Training loss: 1.942780712371395
Validation loss: 2.4486487804296853

Epoch: 6| Step: 1
Training loss: 2.4531649446576194
Validation loss: 2.44401210896938

Epoch: 6| Step: 2
Training loss: 2.590045903804308
Validation loss: 2.4538840347599087

Epoch: 6| Step: 3
Training loss: 2.8443322895542424
Validation loss: 2.433109793450993

Epoch: 6| Step: 4
Training loss: 2.4790586773943764
Validation loss: 2.4562630940342736

Epoch: 6| Step: 5
Training loss: 2.8785786125258435
Validation loss: 2.447376375043082

Epoch: 6| Step: 6
Training loss: 2.9948689768667065
Validation loss: 2.452923043426758

Epoch: 6| Step: 7
Training loss: 2.897451227812767
Validation loss: 2.4471885039748678

Epoch: 6| Step: 8
Training loss: 2.710465975602926
Validation loss: 2.4577220541216174

Epoch: 6| Step: 9
Training loss: 2.7850345194404857
Validation loss: 2.450421298806061

Epoch: 6| Step: 10
Training loss: 2.861765878150275
Validation loss: 2.4432258833437173

Epoch: 6| Step: 11
Training loss: 2.5434763880736604
Validation loss: 2.469782860241985

Epoch: 6| Step: 12
Training loss: 3.274162121235045
Validation loss: 2.446023334954282

Epoch: 6| Step: 13
Training loss: 3.2125977913188293
Validation loss: 2.4637676517709166

Epoch: 82| Step: 0
Training loss: 3.332661863089168
Validation loss: 2.453276431570527

Epoch: 6| Step: 1
Training loss: 2.599332753173158
Validation loss: 2.4463937421096564

Epoch: 6| Step: 2
Training loss: 2.4445152079810795
Validation loss: 2.4487725208060973

Epoch: 6| Step: 3
Training loss: 2.7117735703053167
Validation loss: 2.4494079337789882

Epoch: 6| Step: 4
Training loss: 2.8584336362391207
Validation loss: 2.456796720319857

Epoch: 6| Step: 5
Training loss: 2.3214768079839447
Validation loss: 2.4438017187873733

Epoch: 6| Step: 6
Training loss: 2.5320678143331463
Validation loss: 2.4416696787483136

Epoch: 6| Step: 7
Training loss: 3.280818947226064
Validation loss: 2.4536084169786414

Epoch: 6| Step: 8
Training loss: 2.48028246563047
Validation loss: 2.451413288622693

Epoch: 6| Step: 9
Training loss: 3.1061146574258465
Validation loss: 2.4500840013831198

Epoch: 6| Step: 10
Training loss: 2.657284344511413
Validation loss: 2.4440275578208026

Epoch: 6| Step: 11
Training loss: 2.989166088871669
Validation loss: 2.462759063304328

Epoch: 6| Step: 12
Training loss: 2.4676199149354794
Validation loss: 2.434837589002702

Epoch: 6| Step: 13
Training loss: 2.122943107083439
Validation loss: 2.446995402145463

Epoch: 83| Step: 0
Training loss: 2.3636974630261607
Validation loss: 2.4500807440994516

Epoch: 6| Step: 1
Training loss: 2.8232234398698703
Validation loss: 2.451654837416472

Epoch: 6| Step: 2
Training loss: 2.587623622723834
Validation loss: 2.432933222024013

Epoch: 6| Step: 3
Training loss: 2.687350424219229
Validation loss: 2.446176192343258

Epoch: 6| Step: 4
Training loss: 2.8090572054379477
Validation loss: 2.4488147349315215

Epoch: 6| Step: 5
Training loss: 2.7426901679929108
Validation loss: 2.4567211371536217

Epoch: 6| Step: 6
Training loss: 2.7166722568696278
Validation loss: 2.4554689264867897

Epoch: 6| Step: 7
Training loss: 2.149429591606783
Validation loss: 2.436072748639474

Epoch: 6| Step: 8
Training loss: 3.2564334283224188
Validation loss: 2.453116244024908

Epoch: 6| Step: 9
Training loss: 2.6954833930198676
Validation loss: 2.4358379481091585

Epoch: 6| Step: 10
Training loss: 2.8362287051333266
Validation loss: 2.4587945017153165

Epoch: 6| Step: 11
Training loss: 2.2852810295793544
Validation loss: 2.4475328040172184

Epoch: 6| Step: 12
Training loss: 3.560102760460583
Validation loss: 2.433621336229962

Epoch: 6| Step: 13
Training loss: 2.5305449834389444
Validation loss: 2.441529835581686

Epoch: 84| Step: 0
Training loss: 2.923188592538358
Validation loss: 2.451794528649256

Epoch: 6| Step: 1
Training loss: 3.2540419459813443
Validation loss: 2.432481524392635

Epoch: 6| Step: 2
Training loss: 2.9575533487856287
Validation loss: 2.4462611066588833

Epoch: 6| Step: 3
Training loss: 2.4563859780603843
Validation loss: 2.457144743116306

Epoch: 6| Step: 4
Training loss: 2.3087818049794464
Validation loss: 2.4351366900615767

Epoch: 6| Step: 5
Training loss: 2.33874404360055
Validation loss: 2.463083500678418

Epoch: 6| Step: 6
Training loss: 2.6866799811261273
Validation loss: 2.457892911519356

Epoch: 6| Step: 7
Training loss: 2.5615078936158673
Validation loss: 2.451090101221259

Epoch: 6| Step: 8
Training loss: 2.2414375140780973
Validation loss: 2.4418131255380344

Epoch: 6| Step: 9
Training loss: 3.4484544471009717
Validation loss: 2.4402762369307314

Epoch: 6| Step: 10
Training loss: 3.1573017747382237
Validation loss: 2.434200842348607

Epoch: 6| Step: 11
Training loss: 2.641102042362041
Validation loss: 2.460230484446414

Epoch: 6| Step: 12
Training loss: 2.4035159344907773
Validation loss: 2.460165539942689

Epoch: 6| Step: 13
Training loss: 2.9714139530587333
Validation loss: 2.437968961766572

Epoch: 85| Step: 0
Training loss: 2.5518126571256463
Validation loss: 2.445553350448903

Epoch: 6| Step: 1
Training loss: 2.9123991854659845
Validation loss: 2.427070143025336

Epoch: 6| Step: 2
Training loss: 2.6538647881728656
Validation loss: 2.461893356803755

Epoch: 6| Step: 3
Training loss: 2.7751940685148346
Validation loss: 2.454939940579037

Epoch: 6| Step: 4
Training loss: 2.81571353006847
Validation loss: 2.4566905492692337

Epoch: 6| Step: 5
Training loss: 2.767102121837834
Validation loss: 2.447655495295502

Epoch: 6| Step: 6
Training loss: 2.811249688175196
Validation loss: 2.4380775737083633

Epoch: 6| Step: 7
Training loss: 2.5580194891693484
Validation loss: 2.4528955525115776

Epoch: 6| Step: 8
Training loss: 2.393971413514193
Validation loss: 2.449777083565762

Epoch: 6| Step: 9
Training loss: 2.4806071565716277
Validation loss: 2.4558019130870115

Epoch: 6| Step: 10
Training loss: 3.5257333520213443
Validation loss: 2.4460966851389783

Epoch: 6| Step: 11
Training loss: 2.6483685419788285
Validation loss: 2.426542062693606

Epoch: 6| Step: 12
Training loss: 2.72245413469225
Validation loss: 2.441989479017149

Epoch: 6| Step: 13
Training loss: 2.782556976804356
Validation loss: 2.4353743214571013

Epoch: 86| Step: 0
Training loss: 2.9559851626590334
Validation loss: 2.4561049065028215

Epoch: 6| Step: 1
Training loss: 2.7664853929016475
Validation loss: 2.4336191925065678

Epoch: 6| Step: 2
Training loss: 2.9481999740787943
Validation loss: 2.4498476429759033

Epoch: 6| Step: 3
Training loss: 2.5941757404263877
Validation loss: 2.4554020643979255

Epoch: 6| Step: 4
Training loss: 2.2587086308231696
Validation loss: 2.4629142441124925

Epoch: 6| Step: 5
Training loss: 3.047839672257326
Validation loss: 2.4580023441761263

Epoch: 6| Step: 6
Training loss: 2.610626468817855
Validation loss: 2.4334269344495145

Epoch: 6| Step: 7
Training loss: 2.9857067711684078
Validation loss: 2.4408001715363827

Epoch: 6| Step: 8
Training loss: 2.7761645167628846
Validation loss: 2.447898317650958

Epoch: 6| Step: 9
Training loss: 2.677833560856776
Validation loss: 2.437428010856141

Epoch: 6| Step: 10
Training loss: 2.974137407156971
Validation loss: 2.45242095786944

Epoch: 6| Step: 11
Training loss: 2.831573238826066
Validation loss: 2.432155278478449

Epoch: 6| Step: 12
Training loss: 2.7708471962335794
Validation loss: 2.445574532558936

Epoch: 6| Step: 13
Training loss: 1.4412635794642534
Validation loss: 2.449500114586116

Epoch: 87| Step: 0
Training loss: 2.905328748160472
Validation loss: 2.4561229325697003

Epoch: 6| Step: 1
Training loss: 2.7085258024246146
Validation loss: 2.4631205204891007

Epoch: 6| Step: 2
Training loss: 2.455991006256933
Validation loss: 2.463490952324853

Epoch: 6| Step: 3
Training loss: 3.251035525336429
Validation loss: 2.4774810866883175

Epoch: 6| Step: 4
Training loss: 2.5094372961309257
Validation loss: 2.4530600763950563

Epoch: 6| Step: 5
Training loss: 2.6466935529071907
Validation loss: 2.4657196942552155

Epoch: 6| Step: 6
Training loss: 2.774756405423012
Validation loss: 2.4538838931993006

Epoch: 6| Step: 7
Training loss: 2.520486813102662
Validation loss: 2.462759249636667

Epoch: 6| Step: 8
Training loss: 2.7698253911205564
Validation loss: 2.448988794165336

Epoch: 6| Step: 9
Training loss: 2.1593895874414004
Validation loss: 2.4761909953346932

Epoch: 6| Step: 10
Training loss: 2.485953639162089
Validation loss: 2.451467607960526

Epoch: 6| Step: 11
Training loss: 2.8161409335090553
Validation loss: 2.457411329488442

Epoch: 6| Step: 12
Training loss: 3.245398565187923
Validation loss: 2.4535256178795843

Epoch: 6| Step: 13
Training loss: 3.1676966012881507
Validation loss: 2.4547152277000928

Epoch: 88| Step: 0
Training loss: 3.5745170427098327
Validation loss: 2.4660816920838435

Epoch: 6| Step: 1
Training loss: 2.659693202919236
Validation loss: 2.4569347387482883

Epoch: 6| Step: 2
Training loss: 3.05206326596343
Validation loss: 2.460161375866539

Epoch: 6| Step: 3
Training loss: 2.420510676861
Validation loss: 2.437159619415169

Epoch: 6| Step: 4
Training loss: 2.6446001277727094
Validation loss: 2.4454110015747106

Epoch: 6| Step: 5
Training loss: 2.8617613793149617
Validation loss: 2.448552442385834

Epoch: 6| Step: 6
Training loss: 2.3630664570197233
Validation loss: 2.470805869656858

Epoch: 6| Step: 7
Training loss: 3.4957905387456627
Validation loss: 2.4404808819411903

Epoch: 6| Step: 8
Training loss: 2.9202367096154287
Validation loss: 2.4495980814769043

Epoch: 6| Step: 9
Training loss: 1.9796634519060303
Validation loss: 2.459789991853874

Epoch: 6| Step: 10
Training loss: 2.373292811329977
Validation loss: 2.4516397017088036

Epoch: 6| Step: 11
Training loss: 2.4653226021525714
Validation loss: 2.4623022318724317

Epoch: 6| Step: 12
Training loss: 2.440013469909009
Validation loss: 2.4550513427102656

Epoch: 6| Step: 13
Training loss: 2.702670726200336
Validation loss: 2.4456444406587767

Epoch: 89| Step: 0
Training loss: 2.6216162716467375
Validation loss: 2.4649724776388426

Epoch: 6| Step: 1
Training loss: 3.0014883164269457
Validation loss: 2.45105576765806

Epoch: 6| Step: 2
Training loss: 2.815299103533832
Validation loss: 2.457286579188176

Epoch: 6| Step: 3
Training loss: 3.0366461790072763
Validation loss: 2.4573696344358926

Epoch: 6| Step: 4
Training loss: 2.6720525671419386
Validation loss: 2.4434212975429435

Epoch: 6| Step: 5
Training loss: 2.5190636489235203
Validation loss: 2.434694839998791

Epoch: 6| Step: 6
Training loss: 2.2913690084714418
Validation loss: 2.4325609486059467

Epoch: 6| Step: 7
Training loss: 2.4832077643204262
Validation loss: 2.4221144405350863

Epoch: 6| Step: 8
Training loss: 2.054181751043661
Validation loss: 2.4525263269839486

Epoch: 6| Step: 9
Training loss: 3.1028364433435134
Validation loss: 2.454274928196473

Epoch: 6| Step: 10
Training loss: 2.5160501251200658
Validation loss: 2.4511870554315154

Epoch: 6| Step: 11
Training loss: 2.9695574816734718
Validation loss: 2.4333281890212413

Epoch: 6| Step: 12
Training loss: 3.5164049427815693
Validation loss: 2.448451875726283

Epoch: 6| Step: 13
Training loss: 2.115730713495072
Validation loss: 2.4304821860807286

Epoch: 90| Step: 0
Training loss: 2.3264095463634273
Validation loss: 2.4440548616017197

Epoch: 6| Step: 1
Training loss: 2.6704578768563656
Validation loss: 2.454227009523116

Epoch: 6| Step: 2
Training loss: 2.0901226677556197
Validation loss: 2.446186267983103

Epoch: 6| Step: 3
Training loss: 2.8953488902951237
Validation loss: 2.451765114191201

Epoch: 6| Step: 4
Training loss: 2.5438305028975345
Validation loss: 2.439676724840106

Epoch: 6| Step: 5
Training loss: 2.491107670861685
Validation loss: 2.4515270543705685

Epoch: 6| Step: 6
Training loss: 2.823307718778552
Validation loss: 2.439942836774394

Epoch: 6| Step: 7
Training loss: 3.466985992861065
Validation loss: 2.4523949671704637

Epoch: 6| Step: 8
Training loss: 2.593400862761703
Validation loss: 2.461462390119989

Epoch: 6| Step: 9
Training loss: 2.343001385976957
Validation loss: 2.4457532756770433

Epoch: 6| Step: 10
Training loss: 2.529592371583954
Validation loss: 2.448787667954108

Epoch: 6| Step: 11
Training loss: 3.2163869831730296
Validation loss: 2.4567195812629916

Epoch: 6| Step: 12
Training loss: 3.162116462459244
Validation loss: 2.441783773524456

Epoch: 6| Step: 13
Training loss: 2.8233626084984875
Validation loss: 2.4481656344353393

Epoch: 91| Step: 0
Training loss: 2.7160018536500967
Validation loss: 2.4507891322279214

Epoch: 6| Step: 1
Training loss: 2.616934784032532
Validation loss: 2.445795313410417

Epoch: 6| Step: 2
Training loss: 3.3173731819756442
Validation loss: 2.4434969668625066

Epoch: 6| Step: 3
Training loss: 2.846062694446096
Validation loss: 2.4400435566120287

Epoch: 6| Step: 4
Training loss: 2.7127932482298758
Validation loss: 2.470271755117881

Epoch: 6| Step: 5
Training loss: 2.9033546381569075
Validation loss: 2.473842918583753

Epoch: 6| Step: 6
Training loss: 2.2496471128297397
Validation loss: 2.4457479665340314

Epoch: 6| Step: 7
Training loss: 2.1622540460858093
Validation loss: 2.439623662479827

Epoch: 6| Step: 8
Training loss: 3.1073198283743024
Validation loss: 2.4573161508129053

Epoch: 6| Step: 9
Training loss: 3.1674063638457364
Validation loss: 2.441800520499348

Epoch: 6| Step: 10
Training loss: 2.3114527831341154
Validation loss: 2.4472379673473776

Epoch: 6| Step: 11
Training loss: 2.6511803211658225
Validation loss: 2.448255733203806

Epoch: 6| Step: 12
Training loss: 2.803234265769702
Validation loss: 2.445755068099821

Epoch: 6| Step: 13
Training loss: 2.134558776718188
Validation loss: 2.451699534499592

Epoch: 92| Step: 0
Training loss: 3.217542699665371
Validation loss: 2.454537295439143

Epoch: 6| Step: 1
Training loss: 2.912956293733509
Validation loss: 2.446984321975585

Epoch: 6| Step: 2
Training loss: 1.7096113526238248
Validation loss: 2.4426016289779353

Epoch: 6| Step: 3
Training loss: 2.848641851631185
Validation loss: 2.472765434672135

Epoch: 6| Step: 4
Training loss: 2.6070319523523175
Validation loss: 2.4316206114379812

Epoch: 6| Step: 5
Training loss: 2.3533231411173765
Validation loss: 2.4362283639003866

Epoch: 6| Step: 6
Training loss: 2.8607826311830156
Validation loss: 2.439380836176008

Epoch: 6| Step: 7
Training loss: 2.2465032320353804
Validation loss: 2.4283767951210318

Epoch: 6| Step: 8
Training loss: 3.124280770504914
Validation loss: 2.443482187177759

Epoch: 6| Step: 9
Training loss: 3.1362228286557454
Validation loss: 2.4486939396441785

Epoch: 6| Step: 10
Training loss: 2.4928616655256395
Validation loss: 2.431233915562639

Epoch: 6| Step: 11
Training loss: 2.0933331886016084
Validation loss: 2.451432482805997

Epoch: 6| Step: 12
Training loss: 2.891217475177115
Validation loss: 2.444115329527171

Epoch: 6| Step: 13
Training loss: 3.6803941959222155
Validation loss: 2.4390331145062247

Epoch: 93| Step: 0
Training loss: 2.830040720185007
Validation loss: 2.450983373890486

Epoch: 6| Step: 1
Training loss: 2.693593060021882
Validation loss: 2.444834662251083

Epoch: 6| Step: 2
Training loss: 2.602048994519348
Validation loss: 2.447685780280676

Epoch: 6| Step: 3
Training loss: 2.708146035002436
Validation loss: 2.4529073867019333

Epoch: 6| Step: 4
Training loss: 2.623219203897993
Validation loss: 2.4410325507845347

Epoch: 6| Step: 5
Training loss: 2.47431473155864
Validation loss: 2.440090446833273

Epoch: 6| Step: 6
Training loss: 2.5119130488065076
Validation loss: 2.466499302675746

Epoch: 6| Step: 7
Training loss: 3.0346068053093123
Validation loss: 2.463609040779499

Epoch: 6| Step: 8
Training loss: 3.2488233930657193
Validation loss: 2.444949808867777

Epoch: 6| Step: 9
Training loss: 2.718855055609903
Validation loss: 2.4549509347169094

Epoch: 6| Step: 10
Training loss: 2.908656610777378
Validation loss: 2.437078303272958

Epoch: 6| Step: 11
Training loss: 2.731334194395814
Validation loss: 2.454013906647795

Epoch: 6| Step: 12
Training loss: 2.3372880482585425
Validation loss: 2.4348195053770745

Epoch: 6| Step: 13
Training loss: 2.6006682637527647
Validation loss: 2.436439896803478

Epoch: 94| Step: 0
Training loss: 3.205273163769716
Validation loss: 2.4500589087818603

Epoch: 6| Step: 1
Training loss: 2.847578217702302
Validation loss: 2.440302484867679

Epoch: 6| Step: 2
Training loss: 2.6541235097333797
Validation loss: 2.4559178200563774

Epoch: 6| Step: 3
Training loss: 2.0905443389796226
Validation loss: 2.432379067521615

Epoch: 6| Step: 4
Training loss: 2.6956661268812105
Validation loss: 2.4585365210049748

Epoch: 6| Step: 5
Training loss: 2.413295784582627
Validation loss: 2.4480980670840657

Epoch: 6| Step: 6
Training loss: 2.6420591173163652
Validation loss: 2.4493582651230787

Epoch: 6| Step: 7
Training loss: 2.49098832030374
Validation loss: 2.4627744174581556

Epoch: 6| Step: 8
Training loss: 2.486979720563311
Validation loss: 2.4304090544989903

Epoch: 6| Step: 9
Training loss: 3.339626586278593
Validation loss: 2.4566720212494384

Epoch: 6| Step: 10
Training loss: 2.95411173164572
Validation loss: 2.469235070517411

Epoch: 6| Step: 11
Training loss: 2.564580584436013
Validation loss: 2.462894663716705

Epoch: 6| Step: 12
Training loss: 2.1497272850776956
Validation loss: 2.4512528815351913

Epoch: 6| Step: 13
Training loss: 3.5109800043321684
Validation loss: 2.4418307678633884

Epoch: 95| Step: 0
Training loss: 2.5722126068235784
Validation loss: 2.440762544297946

Epoch: 6| Step: 1
Training loss: 2.872633914067027
Validation loss: 2.454057395975099

Epoch: 6| Step: 2
Training loss: 2.647503443383417
Validation loss: 2.45219591274912

Epoch: 6| Step: 3
Training loss: 2.4539277530907295
Validation loss: 2.455577416897188

Epoch: 6| Step: 4
Training loss: 2.754883418307936
Validation loss: 2.453746080857068

Epoch: 6| Step: 5
Training loss: 2.5837178918239605
Validation loss: 2.4427941797864614

Epoch: 6| Step: 6
Training loss: 3.1167920466480177
Validation loss: 2.4565228246381774

Epoch: 6| Step: 7
Training loss: 2.6523756606776545
Validation loss: 2.4704870403583032

Epoch: 6| Step: 8
Training loss: 1.9928282062736489
Validation loss: 2.4468860754682487

Epoch: 6| Step: 9
Training loss: 3.3607542533345325
Validation loss: 2.459620228792937

Epoch: 6| Step: 10
Training loss: 2.5574991694921674
Validation loss: 2.4458190997075486

Epoch: 6| Step: 11
Training loss: 3.2615491628817326
Validation loss: 2.4522468652111833

Epoch: 6| Step: 12
Training loss: 2.3669810189314857
Validation loss: 2.449187463931255

Epoch: 6| Step: 13
Training loss: 2.9190599885469704
Validation loss: 2.443924175159142

Epoch: 96| Step: 0
Training loss: 2.552017262959464
Validation loss: 2.4407515345658397

Epoch: 6| Step: 1
Training loss: 2.494284008089836
Validation loss: 2.452201343839794

Epoch: 6| Step: 2
Training loss: 3.323132562748897
Validation loss: 2.453426888286248

Epoch: 6| Step: 3
Training loss: 2.2091764843795847
Validation loss: 2.4545655424175736

Epoch: 6| Step: 4
Training loss: 2.4746758528092223
Validation loss: 2.440683884858496

Epoch: 6| Step: 5
Training loss: 2.644695327604768
Validation loss: 2.4508985138764343

Epoch: 6| Step: 6
Training loss: 2.862353165371203
Validation loss: 2.4655180815176476

Epoch: 6| Step: 7
Training loss: 2.156017788532315
Validation loss: 2.4592336073719387

Epoch: 6| Step: 8
Training loss: 3.1202004769301848
Validation loss: 2.458350086798154

Epoch: 6| Step: 9
Training loss: 2.65569120026975
Validation loss: 2.4396875103466655

Epoch: 6| Step: 10
Training loss: 2.985614619022407
Validation loss: 2.4533291840094638

Epoch: 6| Step: 11
Training loss: 3.0016230325388586
Validation loss: 2.458420995070835

Epoch: 6| Step: 12
Training loss: 3.110257890808874
Validation loss: 2.474812789707

Epoch: 6| Step: 13
Training loss: 1.9484700387594773
Validation loss: 2.4430349112294265

Epoch: 97| Step: 0
Training loss: 2.742659047330226
Validation loss: 2.456649099740678

Epoch: 6| Step: 1
Training loss: 2.9524961740596574
Validation loss: 2.4458700518964838

Epoch: 6| Step: 2
Training loss: 2.2701760720351123
Validation loss: 2.451885482140295

Epoch: 6| Step: 3
Training loss: 3.1052467122863265
Validation loss: 2.463199987137484

Epoch: 6| Step: 4
Training loss: 3.0264801565616657
Validation loss: 2.435628813809709

Epoch: 6| Step: 5
Training loss: 3.0022002734550526
Validation loss: 2.4592496090057856

Epoch: 6| Step: 6
Training loss: 2.5360589205759423
Validation loss: 2.438260299832809

Epoch: 6| Step: 7
Training loss: 3.26976677742428
Validation loss: 2.4414145434166934

Epoch: 6| Step: 8
Training loss: 2.3205291955118557
Validation loss: 2.4468135054209696

Epoch: 6| Step: 9
Training loss: 2.9031467071477213
Validation loss: 2.455053579451976

Epoch: 6| Step: 10
Training loss: 2.3324800248021575
Validation loss: 2.4428297607780247

Epoch: 6| Step: 11
Training loss: 2.062934136216232
Validation loss: 2.4484440061192987

Epoch: 6| Step: 12
Training loss: 2.73135147779138
Validation loss: 2.452887884243467

Epoch: 6| Step: 13
Training loss: 2.275095751078338
Validation loss: 2.44689945056864

Epoch: 98| Step: 0
Training loss: 3.0309756439952116
Validation loss: 2.4346936627872253

Epoch: 6| Step: 1
Training loss: 2.8645944121175444
Validation loss: 2.4379688124467953

Epoch: 6| Step: 2
Training loss: 2.4505959856358315
Validation loss: 2.4643163083389896

Epoch: 6| Step: 3
Training loss: 2.8388280508245716
Validation loss: 2.4399360429580894

Epoch: 6| Step: 4
Training loss: 2.372239064055828
Validation loss: 2.4612854643377444

Epoch: 6| Step: 5
Training loss: 2.9166235421035296
Validation loss: 2.4525978478724353

Epoch: 6| Step: 6
Training loss: 2.2433343273838933
Validation loss: 2.451156451827943

Epoch: 6| Step: 7
Training loss: 2.8454098730378115
Validation loss: 2.444526196042967

Epoch: 6| Step: 8
Training loss: 2.6280432725824583
Validation loss: 2.4715228938228364

Epoch: 6| Step: 9
Training loss: 2.6322364969413514
Validation loss: 2.465157734002354

Epoch: 6| Step: 10
Training loss: 3.1178421442129602
Validation loss: 2.4600337762362194

Epoch: 6| Step: 11
Training loss: 2.888920131742636
Validation loss: 2.4472398079182427

Epoch: 6| Step: 12
Training loss: 2.0398095176626585
Validation loss: 2.444618126247974

Epoch: 6| Step: 13
Training loss: 3.0721684638760567
Validation loss: 2.443061000456749

Epoch: 99| Step: 0
Training loss: 2.313414315593569
Validation loss: 2.4497035427095195

Epoch: 6| Step: 1
Training loss: 2.7770515213041223
Validation loss: 2.449946128591135

Epoch: 6| Step: 2
Training loss: 2.8515964453780063
Validation loss: 2.4526901450146554

Epoch: 6| Step: 3
Training loss: 2.3827840834627296
Validation loss: 2.4408093997002887

Epoch: 6| Step: 4
Training loss: 3.006381241755005
Validation loss: 2.4381960392247666

Epoch: 6| Step: 5
Training loss: 3.2986092729172967
Validation loss: 2.466576738708219

Epoch: 6| Step: 6
Training loss: 3.205923802251433
Validation loss: 2.444199548717757

Epoch: 6| Step: 7
Training loss: 2.545287310227996
Validation loss: 2.439568451537515

Epoch: 6| Step: 8
Training loss: 2.457006408856937
Validation loss: 2.4424458981148387

Epoch: 6| Step: 9
Training loss: 2.6987851977471458
Validation loss: 2.4542981215262225

Epoch: 6| Step: 10
Training loss: 2.654807203803635
Validation loss: 2.4208364270393314

Epoch: 6| Step: 11
Training loss: 2.2345194736536103
Validation loss: 2.4394995904516286

Epoch: 6| Step: 12
Training loss: 3.1465572677873404
Validation loss: 2.4489098996072514

Epoch: 6| Step: 13
Training loss: 2.14729772678728
Validation loss: 2.4345722616311845

Epoch: 100| Step: 0
Training loss: 2.5498474187641644
Validation loss: 2.463695613842494

Epoch: 6| Step: 1
Training loss: 3.128983666918349
Validation loss: 2.4438923099236844

Epoch: 6| Step: 2
Training loss: 2.268630040888257
Validation loss: 2.4386722637081717

Epoch: 6| Step: 3
Training loss: 2.3213745152813567
Validation loss: 2.4457972148133185

Epoch: 6| Step: 4
Training loss: 2.1265071685117674
Validation loss: 2.434762000134314

Epoch: 6| Step: 5
Training loss: 2.9045524972094086
Validation loss: 2.4554052154348107

Epoch: 6| Step: 6
Training loss: 2.516600615116721
Validation loss: 2.436520824430561

Epoch: 6| Step: 7
Training loss: 3.081157449256986
Validation loss: 2.4501274914077977

Epoch: 6| Step: 8
Training loss: 2.6544711271214987
Validation loss: 2.429440975987197

Epoch: 6| Step: 9
Training loss: 2.725169878222886
Validation loss: 2.467495088545473

Epoch: 6| Step: 10
Training loss: 3.070551350939255
Validation loss: 2.443848398430254

Epoch: 6| Step: 11
Training loss: 2.1030549489749912
Validation loss: 2.436617525071835

Epoch: 6| Step: 12
Training loss: 2.9934877603311563
Validation loss: 2.4357745413704577

Epoch: 6| Step: 13
Training loss: 3.5517332439605993
Validation loss: 2.4462097549412367

Epoch: 101| Step: 0
Training loss: 2.365011392126409
Validation loss: 2.4397444276929576

Epoch: 6| Step: 1
Training loss: 2.7591113093046045
Validation loss: 2.454220678305232

Epoch: 6| Step: 2
Training loss: 3.0437714248937144
Validation loss: 2.451256703064847

Epoch: 6| Step: 3
Training loss: 3.2789458404470424
Validation loss: 2.435195684513242

Epoch: 6| Step: 4
Training loss: 2.6357141460045024
Validation loss: 2.4451613605068077

Epoch: 6| Step: 5
Training loss: 2.8088023992929667
Validation loss: 2.460098692955738

Epoch: 6| Step: 6
Training loss: 2.7549491044066663
Validation loss: 2.4502588315350797

Epoch: 6| Step: 7
Training loss: 2.4064969022831177
Validation loss: 2.4442726620561226

Epoch: 6| Step: 8
Training loss: 2.786565779756449
Validation loss: 2.4676296941974063

Epoch: 6| Step: 9
Training loss: 2.7714178764209936
Validation loss: 2.462571592296427

Epoch: 6| Step: 10
Training loss: 2.804508129111492
Validation loss: 2.4423934160144656

Epoch: 6| Step: 11
Training loss: 2.920070478555517
Validation loss: 2.4664897642276395

Epoch: 6| Step: 12
Training loss: 2.0165313339012285
Validation loss: 2.466106340455271

Epoch: 6| Step: 13
Training loss: 2.4373810567934644
Validation loss: 2.4737369019007813

Epoch: 102| Step: 0
Training loss: 2.763663075571239
Validation loss: 2.4695850048997507

Epoch: 6| Step: 1
Training loss: 2.087773690013573
Validation loss: 2.4483854565381264

Epoch: 6| Step: 2
Training loss: 3.186529273525532
Validation loss: 2.4504867610101617

Epoch: 6| Step: 3
Training loss: 2.231155102846179
Validation loss: 2.4654125543250145

Epoch: 6| Step: 4
Training loss: 2.5680128204584216
Validation loss: 2.450738179794622

Epoch: 6| Step: 5
Training loss: 2.411841101921005
Validation loss: 2.459357492743926

Epoch: 6| Step: 6
Training loss: 2.895525927430687
Validation loss: 2.4546880686053094

Epoch: 6| Step: 7
Training loss: 2.8054301944166475
Validation loss: 2.4519043119050865

Epoch: 6| Step: 8
Training loss: 2.7553364388022037
Validation loss: 2.437409607247433

Epoch: 6| Step: 9
Training loss: 2.9337245947538717
Validation loss: 2.4501027058295985

Epoch: 6| Step: 10
Training loss: 2.9927448918868844
Validation loss: 2.439638518081483

Epoch: 6| Step: 11
Training loss: 2.6025319169109222
Validation loss: 2.4394798946308374

Epoch: 6| Step: 12
Training loss: 3.159180442184995
Validation loss: 2.45325781297625

Epoch: 6| Step: 13
Training loss: 2.194895966134737
Validation loss: 2.4498975266922445

Epoch: 103| Step: 0
Training loss: 2.191767535287777
Validation loss: 2.4442312987692962

Epoch: 6| Step: 1
Training loss: 3.140944583252152
Validation loss: 2.4494881854390456

Epoch: 6| Step: 2
Training loss: 2.9609912877494136
Validation loss: 2.4602774379922088

Epoch: 6| Step: 3
Training loss: 2.786378311481778
Validation loss: 2.4608347516959546

Epoch: 6| Step: 4
Training loss: 2.2998571434437016
Validation loss: 2.455975291324285

Epoch: 6| Step: 5
Training loss: 2.5140671734147055
Validation loss: 2.448688147953948

Epoch: 6| Step: 6
Training loss: 2.4465063916061864
Validation loss: 2.459415805096257

Epoch: 6| Step: 7
Training loss: 2.3195827376913827
Validation loss: 2.455293199228343

Epoch: 6| Step: 8
Training loss: 3.1422169764125885
Validation loss: 2.4543874666519017

Epoch: 6| Step: 9
Training loss: 2.369464748315949
Validation loss: 2.462474391402869

Epoch: 6| Step: 10
Training loss: 2.8563711929486226
Validation loss: 2.4563760194021156

Epoch: 6| Step: 11
Training loss: 2.562398675915736
Validation loss: 2.463199503176369

Epoch: 6| Step: 12
Training loss: 2.7769223951870896
Validation loss: 2.4565454540747687

Epoch: 6| Step: 13
Training loss: 3.9450677474747535
Validation loss: 2.462083500278508

Epoch: 104| Step: 0
Training loss: 3.21813025572839
Validation loss: 2.459027109194496

Epoch: 6| Step: 1
Training loss: 2.3086897931719177
Validation loss: 2.460333855045563

Epoch: 6| Step: 2
Training loss: 3.446021874161879
Validation loss: 2.469063667920392

Epoch: 6| Step: 3
Training loss: 2.747734437057296
Validation loss: 2.460103158301045

Epoch: 6| Step: 4
Training loss: 2.4955173358196623
Validation loss: 2.4512054758743522

Epoch: 6| Step: 5
Training loss: 2.887459005750159
Validation loss: 2.434254964434741

Epoch: 6| Step: 6
Training loss: 2.3247351834011365
Validation loss: 2.440289216484168

Epoch: 6| Step: 7
Training loss: 3.0224347484729686
Validation loss: 2.4720374965827907

Epoch: 6| Step: 8
Training loss: 1.9923701183915774
Validation loss: 2.4461724813029804

Epoch: 6| Step: 9
Training loss: 2.7364093297417074
Validation loss: 2.4403662319836696

Epoch: 6| Step: 10
Training loss: 2.934360205924834
Validation loss: 2.440313357429509

Epoch: 6| Step: 11
Training loss: 2.2246851451854353
Validation loss: 2.4464166287156095

Epoch: 6| Step: 12
Training loss: 2.6418597703345386
Validation loss: 2.4510222002935858

Epoch: 6| Step: 13
Training loss: 2.5631864605194803
Validation loss: 2.4622965518395596

Epoch: 105| Step: 0
Training loss: 3.155997540036634
Validation loss: 2.451663748665094

Epoch: 6| Step: 1
Training loss: 2.7894514224083693
Validation loss: 2.441518527954176

Epoch: 6| Step: 2
Training loss: 2.422280554501645
Validation loss: 2.448897647247512

Epoch: 6| Step: 3
Training loss: 3.1503757918706907
Validation loss: 2.444671724081971

Epoch: 6| Step: 4
Training loss: 2.702779141389042
Validation loss: 2.4544244682607292

Epoch: 6| Step: 5
Training loss: 2.8293152722828796
Validation loss: 2.441986846076166

Epoch: 6| Step: 6
Training loss: 2.4652293730328254
Validation loss: 2.4513064995407614

Epoch: 6| Step: 7
Training loss: 2.8038136600609245
Validation loss: 2.4604870476564087

Epoch: 6| Step: 8
Training loss: 2.3634727211304623
Validation loss: 2.4454602199485933

Epoch: 6| Step: 9
Training loss: 1.7464410150649097
Validation loss: 2.4579047863158503

Epoch: 6| Step: 10
Training loss: 3.0989439549900597
Validation loss: 2.4510662897236024

Epoch: 6| Step: 11
Training loss: 3.0433360356809462
Validation loss: 2.4523478721124534

Epoch: 6| Step: 12
Training loss: 2.5521524432939025
Validation loss: 2.444128879222446

Epoch: 6| Step: 13
Training loss: 1.8315017683357535
Validation loss: 2.4726955670733957

Epoch: 106| Step: 0
Training loss: 2.3559323893627107
Validation loss: 2.444325150479398

Epoch: 6| Step: 1
Training loss: 2.645776903246555
Validation loss: 2.45626647462747

Epoch: 6| Step: 2
Training loss: 2.7583123205331517
Validation loss: 2.465694808600775

Epoch: 6| Step: 3
Training loss: 2.5029494053737076
Validation loss: 2.4497283459308252

Epoch: 6| Step: 4
Training loss: 3.1721314575548076
Validation loss: 2.435786768174708

Epoch: 6| Step: 5
Training loss: 2.5872544913909525
Validation loss: 2.444795892252344

Epoch: 6| Step: 6
Training loss: 2.921985154956913
Validation loss: 2.4402279204483905

Epoch: 6| Step: 7
Training loss: 2.486102673062213
Validation loss: 2.45921911720325

Epoch: 6| Step: 8
Training loss: 2.816044079142986
Validation loss: 2.4248581196000165

Epoch: 6| Step: 9
Training loss: 2.8232747844343544
Validation loss: 2.439850027993379

Epoch: 6| Step: 10
Training loss: 2.689680235338688
Validation loss: 2.444166423170686

Epoch: 6| Step: 11
Training loss: 2.335909329758025
Validation loss: 2.4350734019266125

Epoch: 6| Step: 12
Training loss: 2.828680500250525
Validation loss: 2.4427644932316537

Epoch: 6| Step: 13
Training loss: 3.2618357014961203
Validation loss: 2.4400948941605987

Epoch: 107| Step: 0
Training loss: 2.64650131163861
Validation loss: 2.4493126932060343

Epoch: 6| Step: 1
Training loss: 2.337984240959319
Validation loss: 2.4537552122735735

Epoch: 6| Step: 2
Training loss: 2.7389119030146962
Validation loss: 2.457573134061261

Epoch: 6| Step: 3
Training loss: 1.9442588679751658
Validation loss: 2.4536548170642094

Epoch: 6| Step: 4
Training loss: 2.7628742913812756
Validation loss: 2.4554214330832194

Epoch: 6| Step: 5
Training loss: 2.5318495428933216
Validation loss: 2.4468869377380096

Epoch: 6| Step: 6
Training loss: 3.0270586433287625
Validation loss: 2.4455567584260374

Epoch: 6| Step: 7
Training loss: 3.0209578565166395
Validation loss: 2.450901672795372

Epoch: 6| Step: 8
Training loss: 2.986749633022716
Validation loss: 2.4445591158863462

Epoch: 6| Step: 9
Training loss: 3.2529260228232886
Validation loss: 2.458523096596036

Epoch: 6| Step: 10
Training loss: 2.757992660213936
Validation loss: 2.463232597571363

Epoch: 6| Step: 11
Training loss: 2.587036728965753
Validation loss: 2.454378874469507

Epoch: 6| Step: 12
Training loss: 2.34970374167575
Validation loss: 2.4487562455133034

Epoch: 6| Step: 13
Training loss: 2.5691251012174487
Validation loss: 2.445293167616025

Epoch: 108| Step: 0
Training loss: 3.0053348790085526
Validation loss: 2.4394950642731845

Epoch: 6| Step: 1
Training loss: 2.4247130469996914
Validation loss: 2.4496595982902853

Epoch: 6| Step: 2
Training loss: 2.1504471690879954
Validation loss: 2.4557257141716073

Epoch: 6| Step: 3
Training loss: 3.2065771341282683
Validation loss: 2.436768884133242

Epoch: 6| Step: 4
Training loss: 2.295562888368948
Validation loss: 2.45108509963359

Epoch: 6| Step: 5
Training loss: 2.674304593686825
Validation loss: 2.4667529534488635

Epoch: 6| Step: 6
Training loss: 2.499420480316739
Validation loss: 2.44925554603789

Epoch: 6| Step: 7
Training loss: 2.9941218326424286
Validation loss: 2.4535908656085357

Epoch: 6| Step: 8
Training loss: 2.5910162249535245
Validation loss: 2.4495125512723424

Epoch: 6| Step: 9
Training loss: 2.523887003731542
Validation loss: 2.4506285974583735

Epoch: 6| Step: 10
Training loss: 2.562565128150062
Validation loss: 2.442803360537882

Epoch: 6| Step: 11
Training loss: 2.6242102388617004
Validation loss: 2.43739880272089

Epoch: 6| Step: 12
Training loss: 3.0154921744549794
Validation loss: 2.452143364888147

Epoch: 6| Step: 13
Training loss: 3.127654512218818
Validation loss: 2.4504495503368

Epoch: 109| Step: 0
Training loss: 2.6144903604662044
Validation loss: 2.443929946669676

Epoch: 6| Step: 1
Training loss: 2.700043084542584
Validation loss: 2.4508829786304114

Epoch: 6| Step: 2
Training loss: 2.7894514224083693
Validation loss: 2.456502935524781

Epoch: 6| Step: 3
Training loss: 3.0502533791777133
Validation loss: 2.471022045728157

Epoch: 6| Step: 4
Training loss: 2.6712891231915346
Validation loss: 2.4456468086487004

Epoch: 6| Step: 5
Training loss: 3.126411576944038
Validation loss: 2.4374151906629926

Epoch: 6| Step: 6
Training loss: 3.314123655453685
Validation loss: 2.442975816451787

Epoch: 6| Step: 7
Training loss: 2.514704375894815
Validation loss: 2.474412303435812

Epoch: 6| Step: 8
Training loss: 2.984712431840168
Validation loss: 2.4598501787617555

Epoch: 6| Step: 9
Training loss: 2.4741406075773527
Validation loss: 2.4595270962222178

Epoch: 6| Step: 10
Training loss: 1.5142242408237998
Validation loss: 2.44623126410617

Epoch: 6| Step: 11
Training loss: 2.5901667650949034
Validation loss: 2.4532738191030043

Epoch: 6| Step: 12
Training loss: 2.553742586891592
Validation loss: 2.43849060400701

Epoch: 6| Step: 13
Training loss: 2.4412159105490288
Validation loss: 2.4477998004386365

Epoch: 110| Step: 0
Training loss: 2.2462053088803646
Validation loss: 2.4531652529426133

Epoch: 6| Step: 1
Training loss: 2.7480139062743385
Validation loss: 2.4459468539400526

Epoch: 6| Step: 2
Training loss: 2.748001412759165
Validation loss: 2.4429493527269828

Epoch: 6| Step: 3
Training loss: 2.62473477431493
Validation loss: 2.4672357212382843

Epoch: 6| Step: 4
Training loss: 2.4427576337989225
Validation loss: 2.4436279247920787

Epoch: 6| Step: 5
Training loss: 2.412302702905325
Validation loss: 2.4555792867134674

Epoch: 6| Step: 6
Training loss: 2.4173436258072027
Validation loss: 2.427097210841559

Epoch: 6| Step: 7
Training loss: 2.9037374484857907
Validation loss: 2.440061939829454

Epoch: 6| Step: 8
Training loss: 2.4130474042729775
Validation loss: 2.4268665606853927

Epoch: 6| Step: 9
Training loss: 2.9518097062636315
Validation loss: 2.466871717134431

Epoch: 6| Step: 10
Training loss: 3.762733330572922
Validation loss: 2.479491256955828

Epoch: 6| Step: 11
Training loss: 2.7252516779035765
Validation loss: 2.4581932949505005

Epoch: 6| Step: 12
Training loss: 2.528677964063665
Validation loss: 2.4715175793558126

Epoch: 6| Step: 13
Training loss: 2.463629421958882
Validation loss: 2.468327009528033

Epoch: 111| Step: 0
Training loss: 2.9578633718654985
Validation loss: 2.4534882693931195

Epoch: 6| Step: 1
Training loss: 2.1576241799838036
Validation loss: 2.461066101745542

Epoch: 6| Step: 2
Training loss: 3.0819956652928293
Validation loss: 2.437958202306843

Epoch: 6| Step: 3
Training loss: 2.3316479340737657
Validation loss: 2.4508664861833003

Epoch: 6| Step: 4
Training loss: 1.8688583878434626
Validation loss: 2.4590039896600357

Epoch: 6| Step: 5
Training loss: 2.6009421768888927
Validation loss: 2.436822764023469

Epoch: 6| Step: 6
Training loss: 2.7401317052442864
Validation loss: 2.438665490530899

Epoch: 6| Step: 7
Training loss: 2.6089769619457868
Validation loss: 2.449365616838447

Epoch: 6| Step: 8
Training loss: 3.006436754163824
Validation loss: 2.4587618376324727

Epoch: 6| Step: 9
Training loss: 3.0506374505962635
Validation loss: 2.4424864629759817

Epoch: 6| Step: 10
Training loss: 3.141760473764943
Validation loss: 2.4440167767817416

Epoch: 6| Step: 11
Training loss: 3.0622184779724546
Validation loss: 2.435541980435639

Epoch: 6| Step: 12
Training loss: 2.1748465648331163
Validation loss: 2.4335090858054906

Epoch: 6| Step: 13
Training loss: 2.5795942339335394
Validation loss: 2.4373189250452363

Epoch: 112| Step: 0
Training loss: 2.8555074916147514
Validation loss: 2.435942214110584

Epoch: 6| Step: 1
Training loss: 2.5114155492905312
Validation loss: 2.4553547649481233

Epoch: 6| Step: 2
Training loss: 3.0026995910321057
Validation loss: 2.446518636031938

Epoch: 6| Step: 3
Training loss: 2.9665130218266347
Validation loss: 2.452055493709043

Epoch: 6| Step: 4
Training loss: 1.7761781999866766
Validation loss: 2.4470084288241347

Epoch: 6| Step: 5
Training loss: 2.5064866788986895
Validation loss: 2.457893753239363

Epoch: 6| Step: 6
Training loss: 2.851423537121295
Validation loss: 2.4400958554882606

Epoch: 6| Step: 7
Training loss: 2.6828502085840014
Validation loss: 2.456171759896413

Epoch: 6| Step: 8
Training loss: 2.729844268856422
Validation loss: 2.4564359794746053

Epoch: 6| Step: 9
Training loss: 2.516912095521421
Validation loss: 2.44623744413091

Epoch: 6| Step: 10
Training loss: 2.5415487001486023
Validation loss: 2.44393905811785

Epoch: 6| Step: 11
Training loss: 2.9152783677422267
Validation loss: 2.456020838778382

Epoch: 6| Step: 12
Training loss: 3.0413395605607465
Validation loss: 2.4421983720007847

Epoch: 6| Step: 13
Training loss: 2.838835441482715
Validation loss: 2.4473977786328946

Epoch: 113| Step: 0
Training loss: 2.866271826440129
Validation loss: 2.4492791228865674

Epoch: 6| Step: 1
Training loss: 2.210949469759725
Validation loss: 2.4583635017236083

Epoch: 6| Step: 2
Training loss: 2.4229568526220127
Validation loss: 2.4573259272629553

Epoch: 6| Step: 3
Training loss: 3.142963506707036
Validation loss: 2.4586174621515697

Epoch: 6| Step: 4
Training loss: 2.9440470033397115
Validation loss: 2.448404207466653

Epoch: 6| Step: 5
Training loss: 2.5136398159256115
Validation loss: 2.4522788696489854

Epoch: 6| Step: 6
Training loss: 2.667518499537264
Validation loss: 2.4335213471684582

Epoch: 6| Step: 7
Training loss: 2.4111356800876527
Validation loss: 2.447819183195914

Epoch: 6| Step: 8
Training loss: 2.9256358702615963
Validation loss: 2.4584633574001926

Epoch: 6| Step: 9
Training loss: 3.2161872809618384
Validation loss: 2.4469156229643088

Epoch: 6| Step: 10
Training loss: 2.5947327188426685
Validation loss: 2.438436929184854

Epoch: 6| Step: 11
Training loss: 2.4253646812335456
Validation loss: 2.417411065437837

Epoch: 6| Step: 12
Training loss: 2.59845132921568
Validation loss: 2.4400077826441215

Epoch: 6| Step: 13
Training loss: 2.6341489574975907
Validation loss: 2.455455483218652

Epoch: 114| Step: 0
Training loss: 2.2946042624297744
Validation loss: 2.457542453507208

Epoch: 6| Step: 1
Training loss: 2.3681906409590994
Validation loss: 2.4552111069381595

Epoch: 6| Step: 2
Training loss: 2.762195594552181
Validation loss: 2.439495435237278

Epoch: 6| Step: 3
Training loss: 3.3909052719793866
Validation loss: 2.4542095388319063

Epoch: 6| Step: 4
Training loss: 2.9868055103022813
Validation loss: 2.425738010962701

Epoch: 6| Step: 5
Training loss: 2.539143252922589
Validation loss: 2.435374241454331

Epoch: 6| Step: 6
Training loss: 2.3595213181554597
Validation loss: 2.446195902368783

Epoch: 6| Step: 7
Training loss: 3.447998383966408
Validation loss: 2.421044009755615

Epoch: 6| Step: 8
Training loss: 2.2010572753969027
Validation loss: 2.4515640991517764

Epoch: 6| Step: 9
Training loss: 2.81083273742772
Validation loss: 2.4637797927230927

Epoch: 6| Step: 10
Training loss: 2.3266568258928157
Validation loss: 2.4435844932462607

Epoch: 6| Step: 11
Training loss: 2.509070155343129
Validation loss: 2.4501415121827756

Epoch: 6| Step: 12
Training loss: 2.6786803196163045
Validation loss: 2.4602056151680944

Epoch: 6| Step: 13
Training loss: 2.706856505903977
Validation loss: 2.46958845549388

Epoch: 115| Step: 0
Training loss: 2.408491007605347
Validation loss: 2.4406258014155955

Epoch: 6| Step: 1
Training loss: 2.9880793883515393
Validation loss: 2.4506890360378706

Epoch: 6| Step: 2
Training loss: 2.883269483120244
Validation loss: 2.4594177001385145

Epoch: 6| Step: 3
Training loss: 2.3420652310533088
Validation loss: 2.4472432627822984

Epoch: 6| Step: 4
Training loss: 2.6723999043232114
Validation loss: 2.467811602389838

Epoch: 6| Step: 5
Training loss: 3.5707203571574397
Validation loss: 2.4409667300104347

Epoch: 6| Step: 6
Training loss: 2.439297722294415
Validation loss: 2.4406848974226696

Epoch: 6| Step: 7
Training loss: 2.6004314541458657
Validation loss: 2.4635377490304236

Epoch: 6| Step: 8
Training loss: 2.745819381963996
Validation loss: 2.4591528856207665

Epoch: 6| Step: 9
Training loss: 2.4768884486435647
Validation loss: 2.4566348155618583

Epoch: 6| Step: 10
Training loss: 2.703807590275146
Validation loss: 2.49263904353993

Epoch: 6| Step: 11
Training loss: 2.656346936420553
Validation loss: 2.4358974517982355

Epoch: 6| Step: 12
Training loss: 2.5375979850905357
Validation loss: 2.4512425694413125

Epoch: 6| Step: 13
Training loss: 2.217756451869675
Validation loss: 2.464589388881719

Epoch: 116| Step: 0
Training loss: 2.3927024840129945
Validation loss: 2.4474499559729304

Epoch: 6| Step: 1
Training loss: 2.5136244501887934
Validation loss: 2.445658303692482

Epoch: 6| Step: 2
Training loss: 2.2895782202217227
Validation loss: 2.465336253664569

Epoch: 6| Step: 3
Training loss: 2.6142437677643837
Validation loss: 2.465537146659163

Epoch: 6| Step: 4
Training loss: 2.7305128451430978
Validation loss: 2.4663428391953572

Epoch: 6| Step: 5
Training loss: 2.4230576119683924
Validation loss: 2.444143862152653

Epoch: 6| Step: 6
Training loss: 2.1856935944454907
Validation loss: 2.45063270032005

Epoch: 6| Step: 7
Training loss: 3.3611051140793893
Validation loss: 2.439662646025486

Epoch: 6| Step: 8
Training loss: 2.1561513684699602
Validation loss: 2.449760786168538

Epoch: 6| Step: 9
Training loss: 2.8868667502655994
Validation loss: 2.448254133189511

Epoch: 6| Step: 10
Training loss: 2.0081243013154566
Validation loss: 2.450036946659124

Epoch: 6| Step: 11
Training loss: 2.8799695725952916
Validation loss: 2.4419186321786306

Epoch: 6| Step: 12
Training loss: 3.231536651823723
Validation loss: 2.4702859121851937

Epoch: 6| Step: 13
Training loss: 3.8947878708080816
Validation loss: 2.460074433015095

Epoch: 117| Step: 0
Training loss: 2.496472444895264
Validation loss: 2.4569500917366516

Epoch: 6| Step: 1
Training loss: 2.8313869822124267
Validation loss: 2.456050077011735

Epoch: 6| Step: 2
Training loss: 2.8961620190016335
Validation loss: 2.4478048239253156

Epoch: 6| Step: 3
Training loss: 2.821778315411777
Validation loss: 2.4462793834182777

Epoch: 6| Step: 4
Training loss: 2.7822819199147966
Validation loss: 2.435595401178821

Epoch: 6| Step: 5
Training loss: 2.852162922393541
Validation loss: 2.4600329383747876

Epoch: 6| Step: 6
Training loss: 2.9940654548620085
Validation loss: 2.470985964956864

Epoch: 6| Step: 7
Training loss: 2.493543297941894
Validation loss: 2.454760594885198

Epoch: 6| Step: 8
Training loss: 2.035325876148373
Validation loss: 2.444631963641261

Epoch: 6| Step: 9
Training loss: 2.210297616622393
Validation loss: 2.4408799121819595

Epoch: 6| Step: 10
Training loss: 2.4838425167613365
Validation loss: 2.4666331790151963

Epoch: 6| Step: 11
Training loss: 3.323390978661087
Validation loss: 2.4453442460848773

Epoch: 6| Step: 12
Training loss: 2.829555423714832
Validation loss: 2.4570513101248577

Epoch: 6| Step: 13
Training loss: 1.7382263860723899
Validation loss: 2.44625827605452

Epoch: 118| Step: 0
Training loss: 2.8515895894475256
Validation loss: 2.437664822584563

Epoch: 6| Step: 1
Training loss: 3.637957860701555
Validation loss: 2.453672273943257

Epoch: 6| Step: 2
Training loss: 2.3888060188212523
Validation loss: 2.4459888296529204

Epoch: 6| Step: 3
Training loss: 2.528919795733339
Validation loss: 2.4505281432017934

Epoch: 6| Step: 4
Training loss: 2.5610068087831763
Validation loss: 2.4454631610266855

Epoch: 6| Step: 5
Training loss: 2.5683091539469705
Validation loss: 2.439543607545678

Epoch: 6| Step: 6
Training loss: 2.7191186413823663
Validation loss: 2.460588273705464

Epoch: 6| Step: 7
Training loss: 1.7499934605067546
Validation loss: 2.4482590929162837

Epoch: 6| Step: 8
Training loss: 2.635020250101472
Validation loss: 2.4386843235544613

Epoch: 6| Step: 9
Training loss: 2.5205199201811093
Validation loss: 2.4477243725389535

Epoch: 6| Step: 10
Training loss: 3.2916275859074093
Validation loss: 2.444964256730804

Epoch: 6| Step: 11
Training loss: 2.6570296097133186
Validation loss: 2.438161006770051

Epoch: 6| Step: 12
Training loss: 2.3300987939805196
Validation loss: 2.4360932055002555

Epoch: 6| Step: 13
Training loss: 2.9266437639398992
Validation loss: 2.4319959814173924

Epoch: 119| Step: 0
Training loss: 1.8124323865183727
Validation loss: 2.4524819125725377

Epoch: 6| Step: 1
Training loss: 3.143423020211658
Validation loss: 2.4496602063237543

Epoch: 6| Step: 2
Training loss: 2.5015051125705408
Validation loss: 2.46194014638939

Epoch: 6| Step: 3
Training loss: 2.5661817943132643
Validation loss: 2.4448194103937984

Epoch: 6| Step: 4
Training loss: 3.273116139226388
Validation loss: 2.4384464533086425

Epoch: 6| Step: 5
Training loss: 2.4967611313160467
Validation loss: 2.461633680464778

Epoch: 6| Step: 6
Training loss: 3.609717678960746
Validation loss: 2.469935655702767

Epoch: 6| Step: 7
Training loss: 2.302438446779522
Validation loss: 2.4487574410904034

Epoch: 6| Step: 8
Training loss: 1.8571217451886768
Validation loss: 2.476228836887729

Epoch: 6| Step: 9
Training loss: 2.5411049477478787
Validation loss: 2.437030674482718

Epoch: 6| Step: 10
Training loss: 2.7974407114081963
Validation loss: 2.4564978051134383

Epoch: 6| Step: 11
Training loss: 2.739406207683888
Validation loss: 2.4555649378467743

Epoch: 6| Step: 12
Training loss: 2.0859778468198305
Validation loss: 2.465002326264511

Epoch: 6| Step: 13
Training loss: 3.284308470425129
Validation loss: 2.4486732917661556

Epoch: 120| Step: 0
Training loss: 2.771500375713589
Validation loss: 2.4524182138215993

Epoch: 6| Step: 1
Training loss: 2.6255942988899257
Validation loss: 2.449975967749768

Epoch: 6| Step: 2
Training loss: 3.144225528616656
Validation loss: 2.4562601611910844

Epoch: 6| Step: 3
Training loss: 3.2545421844434994
Validation loss: 2.468154993366078

Epoch: 6| Step: 4
Training loss: 2.7724721168650093
Validation loss: 2.4460611852070846

Epoch: 6| Step: 5
Training loss: 2.9223358280482636
Validation loss: 2.469140556307895

Epoch: 6| Step: 6
Training loss: 2.940272868981276
Validation loss: 2.4715420692708476

Epoch: 6| Step: 7
Training loss: 2.0803318782280336
Validation loss: 2.465956202007239

Epoch: 6| Step: 8
Training loss: 2.626132720696238
Validation loss: 2.4526888625094485

Epoch: 6| Step: 9
Training loss: 2.5607230375375596
Validation loss: 2.4632964933285066

Epoch: 6| Step: 10
Training loss: 2.901734484545205
Validation loss: 2.4526688963150027

Epoch: 6| Step: 11
Training loss: 2.235956019465474
Validation loss: 2.464025217442258

Epoch: 6| Step: 12
Training loss: 2.2212567205547447
Validation loss: 2.474741193461639

Epoch: 6| Step: 13
Training loss: 1.6869121516610979
Validation loss: 2.4563055123661304

Epoch: 121| Step: 0
Training loss: 3.3303630628646426
Validation loss: 2.4784429249843556

Epoch: 6| Step: 1
Training loss: 2.5968151136119504
Validation loss: 2.4702831807176135

Epoch: 6| Step: 2
Training loss: 2.6476967825084716
Validation loss: 2.4722545096345425

Epoch: 6| Step: 3
Training loss: 2.689184326391293
Validation loss: 2.4465426657358096

Epoch: 6| Step: 4
Training loss: 2.5853233875924726
Validation loss: 2.4394527445712995

Epoch: 6| Step: 5
Training loss: 2.7115052258108614
Validation loss: 2.4526555704464763

Epoch: 6| Step: 6
Training loss: 2.197396371978045
Validation loss: 2.4352397193952386

Epoch: 6| Step: 7
Training loss: 2.496291461690029
Validation loss: 2.4536190022811186

Epoch: 6| Step: 8
Training loss: 3.1452738957089763
Validation loss: 2.452915817861453

Epoch: 6| Step: 9
Training loss: 2.7534574102318956
Validation loss: 2.460367052588832

Epoch: 6| Step: 10
Training loss: 2.328054849476625
Validation loss: 2.439967899972071

Epoch: 6| Step: 11
Training loss: 2.518905017711214
Validation loss: 2.444508423726177

Epoch: 6| Step: 12
Training loss: 2.9655140155569732
Validation loss: 2.426165532956051

Epoch: 6| Step: 13
Training loss: 1.827851299435627
Validation loss: 2.4535139580323753

Epoch: 122| Step: 0
Training loss: 2.177729338909536
Validation loss: 2.456603738211435

Epoch: 6| Step: 1
Training loss: 3.0357776923730375
Validation loss: 2.4629399197908426

Epoch: 6| Step: 2
Training loss: 2.5443636442271655
Validation loss: 2.4454564328663535

Epoch: 6| Step: 3
Training loss: 2.309285378168906
Validation loss: 2.449787373050377

Epoch: 6| Step: 4
Training loss: 2.2346972253177326
Validation loss: 2.441359423904097

Epoch: 6| Step: 5
Training loss: 2.8426212963303055
Validation loss: 2.433795579864288

Epoch: 6| Step: 6
Training loss: 2.271100603059836
Validation loss: 2.464380723184185

Epoch: 6| Step: 7
Training loss: 2.9142989402759385
Validation loss: 2.43202322420809

Epoch: 6| Step: 8
Training loss: 2.754147349956908
Validation loss: 2.4331872448100014

Epoch: 6| Step: 9
Training loss: 1.9826972657394777
Validation loss: 2.46172219804038

Epoch: 6| Step: 10
Training loss: 2.7292651578491536
Validation loss: 2.4620340883785987

Epoch: 6| Step: 11
Training loss: 3.02038451620525
Validation loss: 2.459555459962072

Epoch: 6| Step: 12
Training loss: 3.477270161474214
Validation loss: 2.4498193886897606

Epoch: 6| Step: 13
Training loss: 2.5898174209752347
Validation loss: 2.4609451114128604

Epoch: 123| Step: 0
Training loss: 3.0682210617895165
Validation loss: 2.449974344791831

Epoch: 6| Step: 1
Training loss: 2.2597217341243208
Validation loss: 2.455381493811907

Epoch: 6| Step: 2
Training loss: 2.994241592088386
Validation loss: 2.4523281111744843

Epoch: 6| Step: 3
Training loss: 2.566838940705469
Validation loss: 2.4423979588642286

Epoch: 6| Step: 4
Training loss: 2.733885454224234
Validation loss: 2.450323926662451

Epoch: 6| Step: 5
Training loss: 2.7208825002281167
Validation loss: 2.449279675539832

Epoch: 6| Step: 6
Training loss: 2.442815413632509
Validation loss: 2.438686817092645

Epoch: 6| Step: 7
Training loss: 3.020597479371466
Validation loss: 2.437070466367013

Epoch: 6| Step: 8
Training loss: 2.5163462298014725
Validation loss: 2.4543002367419753

Epoch: 6| Step: 9
Training loss: 2.6161137897813207
Validation loss: 2.435251846770769

Epoch: 6| Step: 10
Training loss: 2.287559979595683
Validation loss: 2.4432769105969503

Epoch: 6| Step: 11
Training loss: 2.9034934147858147
Validation loss: 2.452079868532885

Epoch: 6| Step: 12
Training loss: 2.230952489342745
Validation loss: 2.453852300950683

Epoch: 6| Step: 13
Training loss: 2.781511015913244
Validation loss: 2.46686136952569

Epoch: 124| Step: 0
Training loss: 2.5584048601852256
Validation loss: 2.4534191568934602

Epoch: 6| Step: 1
Training loss: 2.8023924722043883
Validation loss: 2.470868646156004

Epoch: 6| Step: 2
Training loss: 2.5903292239764477
Validation loss: 2.444105796026481

Epoch: 6| Step: 3
Training loss: 2.782108131638296
Validation loss: 2.4413998592826305

Epoch: 6| Step: 4
Training loss: 2.702627676489503
Validation loss: 2.4465280469605633

Epoch: 6| Step: 5
Training loss: 2.1395390115646022
Validation loss: 2.4652146914025224

Epoch: 6| Step: 6
Training loss: 2.598306720720517
Validation loss: 2.4512633232704295

Epoch: 6| Step: 7
Training loss: 2.4284353678920616
Validation loss: 2.470293585600374

Epoch: 6| Step: 8
Training loss: 2.6039864643055695
Validation loss: 2.446725975624715

Epoch: 6| Step: 9
Training loss: 2.7176709719500236
Validation loss: 2.4480786865348625

Epoch: 6| Step: 10
Training loss: 2.5028256660007484
Validation loss: 2.4573951990420952

Epoch: 6| Step: 11
Training loss: 3.560909652433688
Validation loss: 2.4611351625252817

Epoch: 6| Step: 12
Training loss: 2.031418191842267
Validation loss: 2.4481380644418085

Epoch: 6| Step: 13
Training loss: 3.2655800264172896
Validation loss: 2.4334478686650547

Epoch: 125| Step: 0
Training loss: 2.7618573058252807
Validation loss: 2.4590206787830313

Epoch: 6| Step: 1
Training loss: 2.4845807452148114
Validation loss: 2.4468802030154406

Epoch: 6| Step: 2
Training loss: 1.9720670821133293
Validation loss: 2.453416570701085

Epoch: 6| Step: 3
Training loss: 2.655202861155192
Validation loss: 2.447130286304413

Epoch: 6| Step: 4
Training loss: 3.1113757879961104
Validation loss: 2.4343031604085943

Epoch: 6| Step: 5
Training loss: 2.5534129098322786
Validation loss: 2.4465520860027294

Epoch: 6| Step: 6
Training loss: 2.443898239907944
Validation loss: 2.4339683532911653

Epoch: 6| Step: 7
Training loss: 3.0102731919115593
Validation loss: 2.4628790875573414

Epoch: 6| Step: 8
Training loss: 2.944011370481426
Validation loss: 2.4488255409103803

Epoch: 6| Step: 9
Training loss: 2.1810641846305274
Validation loss: 2.4423741696884664

Epoch: 6| Step: 10
Training loss: 3.1383988570877084
Validation loss: 2.4515859388402452

Epoch: 6| Step: 11
Training loss: 2.792145635785198
Validation loss: 2.461016894425619

Epoch: 6| Step: 12
Training loss: 2.4311376825194344
Validation loss: 2.4364881547760406

Epoch: 6| Step: 13
Training loss: 2.565649934338527
Validation loss: 2.4505192215465987

Epoch: 126| Step: 0
Training loss: 2.290638560089734
Validation loss: 2.4317224223834355

Epoch: 6| Step: 1
Training loss: 3.3224735901344817
Validation loss: 2.4519387365737675

Epoch: 6| Step: 2
Training loss: 2.3674967850176887
Validation loss: 2.45149000484658

Epoch: 6| Step: 3
Training loss: 2.594128316842319
Validation loss: 2.4349270585941123

Epoch: 6| Step: 4
Training loss: 2.450798924254388
Validation loss: 2.4555656347250587

Epoch: 6| Step: 5
Training loss: 2.616402488380022
Validation loss: 2.4494262257831374

Epoch: 6| Step: 6
Training loss: 2.2277382406635646
Validation loss: 2.4650136852876687

Epoch: 6| Step: 7
Training loss: 3.0216521282516093
Validation loss: 2.4454797009214535

Epoch: 6| Step: 8
Training loss: 2.944480070062558
Validation loss: 2.4594420728785824

Epoch: 6| Step: 9
Training loss: 3.211439107432534
Validation loss: 2.4439213470930246

Epoch: 6| Step: 10
Training loss: 2.632159687009875
Validation loss: 2.4493665441745525

Epoch: 6| Step: 11
Training loss: 3.055041046366302
Validation loss: 2.462050349828339

Epoch: 6| Step: 12
Training loss: 1.9136131537687056
Validation loss: 2.437725545767369

Epoch: 6| Step: 13
Training loss: 2.2529977326024038
Validation loss: 2.4434354197507147

Epoch: 127| Step: 0
Training loss: 2.133162808556829
Validation loss: 2.456250231246898

Epoch: 6| Step: 1
Training loss: 2.6239962702410637
Validation loss: 2.4478370550576196

Epoch: 6| Step: 2
Training loss: 2.73435023705305
Validation loss: 2.4424031052478257

Epoch: 6| Step: 3
Training loss: 2.4749353882033467
Validation loss: 2.452428209981095

Epoch: 6| Step: 4
Training loss: 2.6409939841072294
Validation loss: 2.4702690604764808

Epoch: 6| Step: 5
Training loss: 2.551670731388229
Validation loss: 2.4520601713019006

Epoch: 6| Step: 6
Training loss: 2.5526213617270415
Validation loss: 2.480681882781675

Epoch: 6| Step: 7
Training loss: 2.9430722892093084
Validation loss: 2.4706445052367694

Epoch: 6| Step: 8
Training loss: 2.8433633059330226
Validation loss: 2.455897672382678

Epoch: 6| Step: 9
Training loss: 2.7431841394946583
Validation loss: 2.4612493054119775

Epoch: 6| Step: 10
Training loss: 2.6417073396104755
Validation loss: 2.4494749689061077

Epoch: 6| Step: 11
Training loss: 3.060106704696491
Validation loss: 2.449656686843939

Epoch: 6| Step: 12
Training loss: 1.8558552229089524
Validation loss: 2.4368589855707983

Epoch: 6| Step: 13
Training loss: 3.670759575427912
Validation loss: 2.444981423352779

Epoch: 128| Step: 0
Training loss: 2.8453485376630487
Validation loss: 2.4587041666584115

Epoch: 6| Step: 1
Training loss: 2.8526716191705783
Validation loss: 2.4803028937815244

Epoch: 6| Step: 2
Training loss: 2.6956362322567324
Validation loss: 2.459933520546887

Epoch: 6| Step: 3
Training loss: 2.582417561636089
Validation loss: 2.4581510359086676

Epoch: 6| Step: 4
Training loss: 2.5018483005216847
Validation loss: 2.447871769947407

Epoch: 6| Step: 5
Training loss: 2.498574995178404
Validation loss: 2.4591470685234444

Epoch: 6| Step: 6
Training loss: 3.2178058906273166
Validation loss: 2.4537478893817313

Epoch: 6| Step: 7
Training loss: 2.8539153125283843
Validation loss: 2.4509899922194363

Epoch: 6| Step: 8
Training loss: 2.3410610796078326
Validation loss: 2.45227318783067

Epoch: 6| Step: 9
Training loss: 2.702353483140086
Validation loss: 2.453799679905673

Epoch: 6| Step: 10
Training loss: 2.319292865554007
Validation loss: 2.4723063054783116

Epoch: 6| Step: 11
Training loss: 2.857768623761904
Validation loss: 2.456909398907997

Epoch: 6| Step: 12
Training loss: 2.3310550966170567
Validation loss: 2.4566485059596213

Epoch: 6| Step: 13
Training loss: 2.5676324199934966
Validation loss: 2.4717862207659804

Epoch: 129| Step: 0
Training loss: 3.1080629273749367
Validation loss: 2.4681353548318445

Epoch: 6| Step: 1
Training loss: 2.9398972489443547
Validation loss: 2.471036683516863

Epoch: 6| Step: 2
Training loss: 2.3253119966916285
Validation loss: 2.455733165312087

Epoch: 6| Step: 3
Training loss: 2.970637153329353
Validation loss: 2.4553568792536105

Epoch: 6| Step: 4
Training loss: 3.372995982534423
Validation loss: 2.459339307963404

Epoch: 6| Step: 5
Training loss: 2.2169173287759185
Validation loss: 2.4627957902809188

Epoch: 6| Step: 6
Training loss: 2.5573981134101182
Validation loss: 2.4655808897125313

Epoch: 6| Step: 7
Training loss: 3.034715382335257
Validation loss: 2.476548418666415

Epoch: 6| Step: 8
Training loss: 2.6823402375696954
Validation loss: 2.475451044718622

Epoch: 6| Step: 9
Training loss: 2.617409403489189
Validation loss: 2.4594104602978644

Epoch: 6| Step: 10
Training loss: 2.5301810939343903
Validation loss: 2.486844142776222

Epoch: 6| Step: 11
Training loss: 1.9790443248748462
Validation loss: 2.4680483438687753

Epoch: 6| Step: 12
Training loss: 2.2934590583907637
Validation loss: 2.466477534754428

Epoch: 6| Step: 13
Training loss: 2.0513589681057365
Validation loss: 2.462754304017687

Epoch: 130| Step: 0
Training loss: 2.7783894776650033
Validation loss: 2.455702470121841

Epoch: 6| Step: 1
Training loss: 3.0163284034830644
Validation loss: 2.4493262643896907

Epoch: 6| Step: 2
Training loss: 2.7945430986784037
Validation loss: 2.441203404291635

Epoch: 6| Step: 3
Training loss: 3.0483426202959683
Validation loss: 2.4693504673874047

Epoch: 6| Step: 4
Training loss: 2.5337722833045944
Validation loss: 2.46316903008705

Epoch: 6| Step: 5
Training loss: 2.6971901365816864
Validation loss: 2.449810563867605

Epoch: 6| Step: 6
Training loss: 2.5022904394249093
Validation loss: 2.4394862977341902

Epoch: 6| Step: 7
Training loss: 2.0034181472588575
Validation loss: 2.4514028203358182

Epoch: 6| Step: 8
Training loss: 2.9950479325931116
Validation loss: 2.446251976611876

Epoch: 6| Step: 9
Training loss: 2.4637545492980855
Validation loss: 2.4479173267985868

Epoch: 6| Step: 10
Training loss: 2.4736098730060503
Validation loss: 2.4392356551321526

Epoch: 6| Step: 11
Training loss: 2.6745064253317143
Validation loss: 2.457125298287218

Epoch: 6| Step: 12
Training loss: 2.5064550986522898
Validation loss: 2.457156213583986

Epoch: 6| Step: 13
Training loss: 2.550449600975141
Validation loss: 2.4324980171289203

Epoch: 131| Step: 0
Training loss: 2.7935087095513693
Validation loss: 2.457672337565739

Epoch: 6| Step: 1
Training loss: 2.748872959497189
Validation loss: 2.4264567203274225

Epoch: 6| Step: 2
Training loss: 2.4603786257764746
Validation loss: 2.454144874778382

Epoch: 6| Step: 3
Training loss: 2.8662297366823863
Validation loss: 2.445409906051274

Epoch: 6| Step: 4
Training loss: 3.2911005297838525
Validation loss: 2.4353644716226324

Epoch: 6| Step: 5
Training loss: 2.626095860936001
Validation loss: 2.4281390163126733

Epoch: 6| Step: 6
Training loss: 2.76472484357727
Validation loss: 2.4546680956956766

Epoch: 6| Step: 7
Training loss: 2.123840015427907
Validation loss: 2.442173541641154

Epoch: 6| Step: 8
Training loss: 2.4483010064733337
Validation loss: 2.457579977177717

Epoch: 6| Step: 9
Training loss: 2.9437957824904886
Validation loss: 2.4518260120068667

Epoch: 6| Step: 10
Training loss: 2.9321678953095747
Validation loss: 2.451955134505274

Epoch: 6| Step: 11
Training loss: 1.9887469932202544
Validation loss: 2.45347645890264

Epoch: 6| Step: 12
Training loss: 2.364705411697734
Validation loss: 2.4541685049382065

Epoch: 6| Step: 13
Training loss: 2.7119486129697274
Validation loss: 2.4486818798890897

Epoch: 132| Step: 0
Training loss: 3.177653794067052
Validation loss: 2.4592610211823436

Epoch: 6| Step: 1
Training loss: 2.4029724787018343
Validation loss: 2.4531262592860834

Epoch: 6| Step: 2
Training loss: 2.8367565643135086
Validation loss: 2.4570639057879187

Epoch: 6| Step: 3
Training loss: 2.5184600208798273
Validation loss: 2.4520683575906808

Epoch: 6| Step: 4
Training loss: 2.7514050968862493
Validation loss: 2.4535927264901947

Epoch: 6| Step: 5
Training loss: 2.241726498945721
Validation loss: 2.4454140742794532

Epoch: 6| Step: 6
Training loss: 2.5014729928772446
Validation loss: 2.4510951090742212

Epoch: 6| Step: 7
Training loss: 2.5247540420241505
Validation loss: 2.440330286256949

Epoch: 6| Step: 8
Training loss: 2.5533465211127653
Validation loss: 2.4443674015565118

Epoch: 6| Step: 9
Training loss: 1.9775059073223709
Validation loss: 2.445841202423903

Epoch: 6| Step: 10
Training loss: 3.263661647668745
Validation loss: 2.4380228592993145

Epoch: 6| Step: 11
Training loss: 2.858072453225807
Validation loss: 2.468818173467362

Epoch: 6| Step: 12
Training loss: 2.871188747365461
Validation loss: 2.454653005200359

Epoch: 6| Step: 13
Training loss: 2.0818233994588553
Validation loss: 2.4666838644365514

Epoch: 133| Step: 0
Training loss: 2.5334534650059366
Validation loss: 2.459137207573808

Epoch: 6| Step: 1
Training loss: 1.9867499249675387
Validation loss: 2.458039488488848

Epoch: 6| Step: 2
Training loss: 2.2173255323653973
Validation loss: 2.466575723261435

Epoch: 6| Step: 3
Training loss: 2.7399829142796555
Validation loss: 2.441722932880027

Epoch: 6| Step: 4
Training loss: 2.714937716168336
Validation loss: 2.4620983234468614

Epoch: 6| Step: 5
Training loss: 2.6091525959556168
Validation loss: 2.464158734541076

Epoch: 6| Step: 6
Training loss: 2.69682724999936
Validation loss: 2.454034716434079

Epoch: 6| Step: 7
Training loss: 3.0198897016985247
Validation loss: 2.451399039819631

Epoch: 6| Step: 8
Training loss: 2.2876581564671827
Validation loss: 2.458934218975114

Epoch: 6| Step: 9
Training loss: 2.707152524931576
Validation loss: 2.474660483406181

Epoch: 6| Step: 10
Training loss: 2.4544913016231393
Validation loss: 2.466258433352784

Epoch: 6| Step: 11
Training loss: 3.0656855617066854
Validation loss: 2.4432425616742375

Epoch: 6| Step: 12
Training loss: 3.1027471552420756
Validation loss: 2.452584044969574

Epoch: 6| Step: 13
Training loss: 3.0767851881161667
Validation loss: 2.4769206972146134

Epoch: 134| Step: 0
Training loss: 2.6705593863295918
Validation loss: 2.4678136431736406

Epoch: 6| Step: 1
Training loss: 2.436249045170714
Validation loss: 2.45186986950091

Epoch: 6| Step: 2
Training loss: 2.3903406510133576
Validation loss: 2.458102824640894

Epoch: 6| Step: 3
Training loss: 2.5431678799482715
Validation loss: 2.4615528509955995

Epoch: 6| Step: 4
Training loss: 2.6437781654823556
Validation loss: 2.4657573679652445

Epoch: 6| Step: 5
Training loss: 2.390826646864822
Validation loss: 2.4544417431468823

Epoch: 6| Step: 6
Training loss: 3.2799323933309625
Validation loss: 2.473771116537833

Epoch: 6| Step: 7
Training loss: 2.8742090878812863
Validation loss: 2.4680054220532024

Epoch: 6| Step: 8
Training loss: 2.2709899521693186
Validation loss: 2.4479998380468735

Epoch: 6| Step: 9
Training loss: 2.7144289427089205
Validation loss: 2.449376238269801

Epoch: 6| Step: 10
Training loss: 2.7629351277531145
Validation loss: 2.4511459223052303

Epoch: 6| Step: 11
Training loss: 3.150769300222969
Validation loss: 2.4615367591449138

Epoch: 6| Step: 12
Training loss: 2.566670257598875
Validation loss: 2.445367298719823

Epoch: 6| Step: 13
Training loss: 1.8314045238722696
Validation loss: 2.4647171437567903

Epoch: 135| Step: 0
Training loss: 3.178723088254426
Validation loss: 2.430286712505663

Epoch: 6| Step: 1
Training loss: 2.8819231351705494
Validation loss: 2.45358934639248

Epoch: 6| Step: 2
Training loss: 2.8636572618258644
Validation loss: 2.4474000663642066

Epoch: 6| Step: 3
Training loss: 2.567118878181686
Validation loss: 2.442728890299425

Epoch: 6| Step: 4
Training loss: 2.2329963752522413
Validation loss: 2.44533146110406

Epoch: 6| Step: 5
Training loss: 2.357669340101499
Validation loss: 2.439664758168104

Epoch: 6| Step: 6
Training loss: 2.4000624330665206
Validation loss: 2.4551928402823977

Epoch: 6| Step: 7
Training loss: 2.7688037255717037
Validation loss: 2.4451898510456735

Epoch: 6| Step: 8
Training loss: 2.9502882477190098
Validation loss: 2.457616125415585

Epoch: 6| Step: 9
Training loss: 2.296647871556032
Validation loss: 2.453109723397504

Epoch: 6| Step: 10
Training loss: 2.134629143124003
Validation loss: 2.444066925307263

Epoch: 6| Step: 11
Training loss: 2.712970510011065
Validation loss: 2.4589501276828836

Epoch: 6| Step: 12
Training loss: 3.1039924999421737
Validation loss: 2.4465610933786452

Epoch: 6| Step: 13
Training loss: 2.513064390341975
Validation loss: 2.463335936896283

Epoch: 136| Step: 0
Training loss: 3.0932345490741464
Validation loss: 2.4582543020613286

Epoch: 6| Step: 1
Training loss: 2.3944926173219203
Validation loss: 2.4545877334837396

Epoch: 6| Step: 2
Training loss: 2.814580952840759
Validation loss: 2.46125962661826

Epoch: 6| Step: 3
Training loss: 2.75900718164287
Validation loss: 2.4403066870326877

Epoch: 6| Step: 4
Training loss: 2.170118101571448
Validation loss: 2.4561502741134706

Epoch: 6| Step: 5
Training loss: 2.0501747615104366
Validation loss: 2.448186521158553

Epoch: 6| Step: 6
Training loss: 3.1265932217927785
Validation loss: 2.443767975201156

Epoch: 6| Step: 7
Training loss: 2.4367659025776036
Validation loss: 2.429643149238708

Epoch: 6| Step: 8
Training loss: 2.6658723562122586
Validation loss: 2.4506634684253736

Epoch: 6| Step: 9
Training loss: 2.4992903655923953
Validation loss: 2.439762204765739

Epoch: 6| Step: 10
Training loss: 3.0377506670718404
Validation loss: 2.435810452762914

Epoch: 6| Step: 11
Training loss: 2.786090538969078
Validation loss: 2.456231972318959

Epoch: 6| Step: 12
Training loss: 2.486917118809724
Validation loss: 2.469984165345321

Epoch: 6| Step: 13
Training loss: 2.4239214710885646
Validation loss: 2.435683268342566

Epoch: 137| Step: 0
Training loss: 2.2222773492121295
Validation loss: 2.434830241855021

Epoch: 6| Step: 1
Training loss: 2.2214146047213554
Validation loss: 2.447807201345835

Epoch: 6| Step: 2
Training loss: 2.6200365643461434
Validation loss: 2.4500829539884905

Epoch: 6| Step: 3
Training loss: 2.6665880867188614
Validation loss: 2.449534206215034

Epoch: 6| Step: 4
Training loss: 2.4648977234458105
Validation loss: 2.4532882116745243

Epoch: 6| Step: 5
Training loss: 3.0186857986731312
Validation loss: 2.440368481134637

Epoch: 6| Step: 6
Training loss: 1.7678091667458107
Validation loss: 2.435900392319236

Epoch: 6| Step: 7
Training loss: 2.9592860304158592
Validation loss: 2.4407416644174775

Epoch: 6| Step: 8
Training loss: 2.4292580571548905
Validation loss: 2.430570830860178

Epoch: 6| Step: 9
Training loss: 2.9005634089422063
Validation loss: 2.4326863508941274

Epoch: 6| Step: 10
Training loss: 3.450388380663399
Validation loss: 2.4402366233900197

Epoch: 6| Step: 11
Training loss: 2.0892572738705253
Validation loss: 2.4476244929907627

Epoch: 6| Step: 12
Training loss: 2.8318140407004835
Validation loss: 2.4216430224817516

Epoch: 6| Step: 13
Training loss: 3.0732128625567063
Validation loss: 2.428930158163027

Epoch: 138| Step: 0
Training loss: 2.0981073160934764
Validation loss: 2.4373618192712336

Epoch: 6| Step: 1
Training loss: 2.967709971505906
Validation loss: 2.4346724097034294

Epoch: 6| Step: 2
Training loss: 2.4153713394166516
Validation loss: 2.456492842713916

Epoch: 6| Step: 3
Training loss: 2.554434854222944
Validation loss: 2.444205768492093

Epoch: 6| Step: 4
Training loss: 2.7119630308472815
Validation loss: 2.4324101497833963

Epoch: 6| Step: 5
Training loss: 3.4990216658957976
Validation loss: 2.4517240006967946

Epoch: 6| Step: 6
Training loss: 2.2270272823901394
Validation loss: 2.455109102622468

Epoch: 6| Step: 7
Training loss: 2.6440274140383875
Validation loss: 2.451149512336308

Epoch: 6| Step: 8
Training loss: 2.740923554917015
Validation loss: 2.449317121694791

Epoch: 6| Step: 9
Training loss: 2.227848257290749
Validation loss: 2.450245471633629

Epoch: 6| Step: 10
Training loss: 2.2801391823432478
Validation loss: 2.456544826873584

Epoch: 6| Step: 11
Training loss: 2.9516691625818963
Validation loss: 2.4486868099584873

Epoch: 6| Step: 12
Training loss: 2.856828232880839
Validation loss: 2.462568833533388

Epoch: 6| Step: 13
Training loss: 2.4178366185879
Validation loss: 2.438627149136127

Epoch: 139| Step: 0
Training loss: 2.707854438892801
Validation loss: 2.4505031262879458

Epoch: 6| Step: 1
Training loss: 2.313726872967959
Validation loss: 2.4402334254512903

Epoch: 6| Step: 2
Training loss: 2.4520922388148962
Validation loss: 2.4679458822624363

Epoch: 6| Step: 3
Training loss: 1.7271556266989638
Validation loss: 2.454245626509952

Epoch: 6| Step: 4
Training loss: 2.522084915897569
Validation loss: 2.4476505641962145

Epoch: 6| Step: 5
Training loss: 2.68377640503756
Validation loss: 2.459311241948236

Epoch: 6| Step: 6
Training loss: 3.167596345925057
Validation loss: 2.4590870463259877

Epoch: 6| Step: 7
Training loss: 2.577121053639092
Validation loss: 2.4580967015638744

Epoch: 6| Step: 8
Training loss: 2.81284686174903
Validation loss: 2.4346436297165552

Epoch: 6| Step: 9
Training loss: 2.996976918704099
Validation loss: 2.475249289367832

Epoch: 6| Step: 10
Training loss: 2.5259916529997026
Validation loss: 2.466700834694769

Epoch: 6| Step: 11
Training loss: 2.6878829505787567
Validation loss: 2.454652985356751

Epoch: 6| Step: 12
Training loss: 3.103520080678441
Validation loss: 2.4539640439268275

Epoch: 6| Step: 13
Training loss: 2.358212620461875
Validation loss: 2.4677208816377645

Epoch: 140| Step: 0
Training loss: 3.0432448451647907
Validation loss: 2.4342353230695424

Epoch: 6| Step: 1
Training loss: 2.4856163138702305
Validation loss: 2.4605965608144835

Epoch: 6| Step: 2
Training loss: 2.702140496521129
Validation loss: 2.4590417495773282

Epoch: 6| Step: 3
Training loss: 2.7625544685068717
Validation loss: 2.4562168757757488

Epoch: 6| Step: 4
Training loss: 2.873466580333493
Validation loss: 2.4630857436568037

Epoch: 6| Step: 5
Training loss: 1.7721590652027743
Validation loss: 2.455943018769033

Epoch: 6| Step: 6
Training loss: 2.8972102854909396
Validation loss: 2.4578699252548835

Epoch: 6| Step: 7
Training loss: 1.9923448687461935
Validation loss: 2.4405064664162324

Epoch: 6| Step: 8
Training loss: 3.4846670259317762
Validation loss: 2.45082294546415

Epoch: 6| Step: 9
Training loss: 2.5254838989687096
Validation loss: 2.454799556314834

Epoch: 6| Step: 10
Training loss: 2.498426705266119
Validation loss: 2.4542765472659704

Epoch: 6| Step: 11
Training loss: 2.977979107672662
Validation loss: 2.4636115486330925

Epoch: 6| Step: 12
Training loss: 2.1628404602880296
Validation loss: 2.451582737928956

Epoch: 6| Step: 13
Training loss: 1.9660148391706904
Validation loss: 2.438301598289642

Epoch: 141| Step: 0
Training loss: 2.8052811273327207
Validation loss: 2.44959364093739

Epoch: 6| Step: 1
Training loss: 2.7500847890093723
Validation loss: 2.452929235855678

Epoch: 6| Step: 2
Training loss: 2.313689879425135
Validation loss: 2.4386146569354596

Epoch: 6| Step: 3
Training loss: 2.8185265293899575
Validation loss: 2.440454371728071

Epoch: 6| Step: 4
Training loss: 2.626917002830181
Validation loss: 2.4498158767638696

Epoch: 6| Step: 5
Training loss: 2.9085557876228463
Validation loss: 2.4563778792174884

Epoch: 6| Step: 6
Training loss: 2.942850961295102
Validation loss: 2.4542707363683536

Epoch: 6| Step: 7
Training loss: 2.2367727578931396
Validation loss: 2.4508483262671175

Epoch: 6| Step: 8
Training loss: 2.8208589737673937
Validation loss: 2.4522779956847804

Epoch: 6| Step: 9
Training loss: 2.283202289617041
Validation loss: 2.445743045215458

Epoch: 6| Step: 10
Training loss: 2.827565343288966
Validation loss: 2.461155332426061

Epoch: 6| Step: 11
Training loss: 2.2337615764981833
Validation loss: 2.4431417900860906

Epoch: 6| Step: 12
Training loss: 2.3969910077565726
Validation loss: 2.4349492949246847

Epoch: 6| Step: 13
Training loss: 2.860098992081714
Validation loss: 2.450138066637077

Epoch: 142| Step: 0
Training loss: 2.9653713877600882
Validation loss: 2.4606730313641414

Epoch: 6| Step: 1
Training loss: 2.5522856547805604
Validation loss: 2.443475694873698

Epoch: 6| Step: 2
Training loss: 2.897590945431798
Validation loss: 2.4588074137509697

Epoch: 6| Step: 3
Training loss: 3.066010312316234
Validation loss: 2.4443392118783622

Epoch: 6| Step: 4
Training loss: 2.8770717951170095
Validation loss: 2.448329102369492

Epoch: 6| Step: 5
Training loss: 2.5844331266607847
Validation loss: 2.4502020590364806

Epoch: 6| Step: 6
Training loss: 2.4818837852966165
Validation loss: 2.4443853615827966

Epoch: 6| Step: 7
Training loss: 2.632839485731972
Validation loss: 2.437317445122592

Epoch: 6| Step: 8
Training loss: 2.267833816871789
Validation loss: 2.450179779073206

Epoch: 6| Step: 9
Training loss: 2.1355780811866203
Validation loss: 2.452005809678154

Epoch: 6| Step: 10
Training loss: 2.486782419035003
Validation loss: 2.456931161865941

Epoch: 6| Step: 11
Training loss: 2.302174792191877
Validation loss: 2.4432408849274396

Epoch: 6| Step: 12
Training loss: 2.653167372006869
Validation loss: 2.4428796597689164

Epoch: 6| Step: 13
Training loss: 2.9110874401550557
Validation loss: 2.452652478592132

Epoch: 143| Step: 0
Training loss: 2.6253722698907813
Validation loss: 2.432104839543485

Epoch: 6| Step: 1
Training loss: 2.6383882337662925
Validation loss: 2.454100645310209

Epoch: 6| Step: 2
Training loss: 2.724376775185728
Validation loss: 2.448441807315594

Epoch: 6| Step: 3
Training loss: 2.3193631782939748
Validation loss: 2.4477950314420043

Epoch: 6| Step: 4
Training loss: 2.8641754044891634
Validation loss: 2.4743900259645066

Epoch: 6| Step: 5
Training loss: 2.821839825145874
Validation loss: 2.4434192778297374

Epoch: 6| Step: 6
Training loss: 2.779417570151408
Validation loss: 2.4548864739894616

Epoch: 6| Step: 7
Training loss: 2.3442921329376216
Validation loss: 2.4740650019725217

Epoch: 6| Step: 8
Training loss: 2.391361696513057
Validation loss: 2.4595902825408182

Epoch: 6| Step: 9
Training loss: 2.3818789795337065
Validation loss: 2.4585049629957756

Epoch: 6| Step: 10
Training loss: 2.380403896007962
Validation loss: 2.461293301218802

Epoch: 6| Step: 11
Training loss: 3.04910900672037
Validation loss: 2.451624187367684

Epoch: 6| Step: 12
Training loss: 2.650757260358769
Validation loss: 2.466540452596053

Epoch: 6| Step: 13
Training loss: 2.9260680767282974
Validation loss: 2.4567766706381886

Epoch: 144| Step: 0
Training loss: 1.8098493464878291
Validation loss: 2.4533073368501976

Epoch: 6| Step: 1
Training loss: 2.5434668268522977
Validation loss: 2.473419663096481

Epoch: 6| Step: 2
Training loss: 2.7582747204441334
Validation loss: 2.4162781593701137

Epoch: 6| Step: 3
Training loss: 2.689130776229568
Validation loss: 2.471617076812963

Epoch: 6| Step: 4
Training loss: 2.406557435051552
Validation loss: 2.446851400028098

Epoch: 6| Step: 5
Training loss: 2.4195072536245465
Validation loss: 2.4353391831455036

Epoch: 6| Step: 6
Training loss: 1.991643794046795
Validation loss: 2.439307265127676

Epoch: 6| Step: 7
Training loss: 2.6363159776284264
Validation loss: 2.451030754037624

Epoch: 6| Step: 8
Training loss: 2.1360352031292855
Validation loss: 2.4496436114559654

Epoch: 6| Step: 9
Training loss: 3.0895588546952744
Validation loss: 2.4463598749891995

Epoch: 6| Step: 10
Training loss: 3.138684332679851
Validation loss: 2.4498108328090558

Epoch: 6| Step: 11
Training loss: 2.631912575704661
Validation loss: 2.435829886193636

Epoch: 6| Step: 12
Training loss: 2.960737317245648
Validation loss: 2.448112862883943

Epoch: 6| Step: 13
Training loss: 3.492671241794635
Validation loss: 2.4543497427154826

Epoch: 145| Step: 0
Training loss: 2.878135629773055
Validation loss: 2.449302281882209

Epoch: 6| Step: 1
Training loss: 2.49894234218996
Validation loss: 2.4461793961371283

Epoch: 6| Step: 2
Training loss: 3.0707982579319615
Validation loss: 2.450996019040936

Epoch: 6| Step: 3
Training loss: 2.650058486580967
Validation loss: 2.4349856180392666

Epoch: 6| Step: 4
Training loss: 2.251139034605593
Validation loss: 2.451249371663078

Epoch: 6| Step: 5
Training loss: 2.641052211535701
Validation loss: 2.458202443741066

Epoch: 6| Step: 6
Training loss: 2.93991541474819
Validation loss: 2.4653244167431887

Epoch: 6| Step: 7
Training loss: 2.9273167491081957
Validation loss: 2.4469388357600304

Epoch: 6| Step: 8
Training loss: 2.4377728822987974
Validation loss: 2.468847647465173

Epoch: 6| Step: 9
Training loss: 2.272102199774359
Validation loss: 2.4504745908135934

Epoch: 6| Step: 10
Training loss: 2.6377186327527977
Validation loss: 2.4597212195300044

Epoch: 6| Step: 11
Training loss: 2.3070317129825137
Validation loss: 2.4408667456654407

Epoch: 6| Step: 12
Training loss: 2.925661621907653
Validation loss: 2.4403129913171706

Epoch: 6| Step: 13
Training loss: 2.0288192289695672
Validation loss: 2.475931636080753

Epoch: 146| Step: 0
Training loss: 3.0613507041083876
Validation loss: 2.4352065861920456

Epoch: 6| Step: 1
Training loss: 2.682213840775281
Validation loss: 2.4707243130240815

Epoch: 6| Step: 2
Training loss: 2.3044535889970863
Validation loss: 2.466704658793855

Epoch: 6| Step: 3
Training loss: 2.0748133839717022
Validation loss: 2.4802831147364213

Epoch: 6| Step: 4
Training loss: 2.3758453069479053
Validation loss: 2.4642578404224493

Epoch: 6| Step: 5
Training loss: 2.5788208918181263
Validation loss: 2.4624064847759697

Epoch: 6| Step: 6
Training loss: 2.707626563554512
Validation loss: 2.4645401270829277

Epoch: 6| Step: 7
Training loss: 2.1503765441821576
Validation loss: 2.4654785241670774

Epoch: 6| Step: 8
Training loss: 3.25501158259568
Validation loss: 2.4608702458184735

Epoch: 6| Step: 9
Training loss: 2.8492228067346703
Validation loss: 2.469531993451455

Epoch: 6| Step: 10
Training loss: 2.7410930829726055
Validation loss: 2.4846598845648216

Epoch: 6| Step: 11
Training loss: 2.2547968488310186
Validation loss: 2.460224463574056

Epoch: 6| Step: 12
Training loss: 2.904506037042076
Validation loss: 2.4577987392746916

Epoch: 6| Step: 13
Training loss: 2.5749159752923343
Validation loss: 2.475138704132488

Epoch: 147| Step: 0
Training loss: 2.5149865139851832
Validation loss: 2.448449016243222

Epoch: 6| Step: 1
Training loss: 2.7665013363474906
Validation loss: 2.4509958067113087

Epoch: 6| Step: 2
Training loss: 2.4816501477342676
Validation loss: 2.4678595803601553

Epoch: 6| Step: 3
Training loss: 2.5713232771947414
Validation loss: 2.450944194376808

Epoch: 6| Step: 4
Training loss: 3.3696336822188475
Validation loss: 2.449947602978072

Epoch: 6| Step: 5
Training loss: 2.4118076892563503
Validation loss: 2.4532437274565204

Epoch: 6| Step: 6
Training loss: 2.6998608235410395
Validation loss: 2.4520480392343944

Epoch: 6| Step: 7
Training loss: 3.022536190248564
Validation loss: 2.4629044679862258

Epoch: 6| Step: 8
Training loss: 2.642902543256072
Validation loss: 2.469286769812549

Epoch: 6| Step: 9
Training loss: 3.268851260773955
Validation loss: 2.4493391384185226

Epoch: 6| Step: 10
Training loss: 2.2814792883620703
Validation loss: 2.446258501371166

Epoch: 6| Step: 11
Training loss: 2.0276171549523063
Validation loss: 2.4377795096763686

Epoch: 6| Step: 12
Training loss: 2.0187509826090877
Validation loss: 2.468161000085994

Epoch: 6| Step: 13
Training loss: 2.194298234996808
Validation loss: 2.4498914762398085

Epoch: 148| Step: 0
Training loss: 2.8122789084106516
Validation loss: 2.446748050764968

Epoch: 6| Step: 1
Training loss: 2.224315915331887
Validation loss: 2.423557710206679

Epoch: 6| Step: 2
Training loss: 2.4062028360079486
Validation loss: 2.4494604974115104

Epoch: 6| Step: 3
Training loss: 3.0617942775434877
Validation loss: 2.478573622123129

Epoch: 6| Step: 4
Training loss: 3.081147235139362
Validation loss: 2.452227298955341

Epoch: 6| Step: 5
Training loss: 2.186976342874333
Validation loss: 2.4577501935678145

Epoch: 6| Step: 6
Training loss: 2.607706598745181
Validation loss: 2.4530001644414736

Epoch: 6| Step: 7
Training loss: 2.57549424474329
Validation loss: 2.44366502952177

Epoch: 6| Step: 8
Training loss: 2.6686035116046067
Validation loss: 2.4711089104854977

Epoch: 6| Step: 9
Training loss: 1.9285937464396572
Validation loss: 2.4502853429133067

Epoch: 6| Step: 10
Training loss: 2.7566375390773787
Validation loss: 2.4674969607594015

Epoch: 6| Step: 11
Training loss: 3.2869431288731312
Validation loss: 2.440852756688971

Epoch: 6| Step: 12
Training loss: 2.4446977811604724
Validation loss: 2.4760215869628306

Epoch: 6| Step: 13
Training loss: 1.9959000047393298
Validation loss: 2.451497317751054

Epoch: 149| Step: 0
Training loss: 2.5243904511105653
Validation loss: 2.436209688152561

Epoch: 6| Step: 1
Training loss: 2.883061095893358
Validation loss: 2.452824823142824

Epoch: 6| Step: 2
Training loss: 2.5247744393397715
Validation loss: 2.450003281625237

Epoch: 6| Step: 3
Training loss: 2.778625106853394
Validation loss: 2.4558120578010882

Epoch: 6| Step: 4
Training loss: 3.1375893872662717
Validation loss: 2.4726483184962516

Epoch: 6| Step: 5
Training loss: 1.4377692426555602
Validation loss: 2.4699127192373282

Epoch: 6| Step: 6
Training loss: 2.61426328445449
Validation loss: 2.4536833406291647

Epoch: 6| Step: 7
Training loss: 2.1433849502130515
Validation loss: 2.4690568161375697

Epoch: 6| Step: 8
Training loss: 2.8085356004661386
Validation loss: 2.4663886634528405

Epoch: 6| Step: 9
Training loss: 2.5147485568661243
Validation loss: 2.455550301269077

Epoch: 6| Step: 10
Training loss: 2.7173384586668985
Validation loss: 2.481537749545621

Epoch: 6| Step: 11
Training loss: 2.297366031397796
Validation loss: 2.4660173949605753

Epoch: 6| Step: 12
Training loss: 2.892794398143712
Validation loss: 2.4624897660710676

Epoch: 6| Step: 13
Training loss: 3.135891359880262
Validation loss: 2.443646238031501

Epoch: 150| Step: 0
Training loss: 2.647524606015821
Validation loss: 2.4577832601607086

Epoch: 6| Step: 1
Training loss: 2.333812755196603
Validation loss: 2.4472711749299085

Epoch: 6| Step: 2
Training loss: 2.404327615499562
Validation loss: 2.4763806093416347

Epoch: 6| Step: 3
Training loss: 2.5062896763426896
Validation loss: 2.449462519469702

Epoch: 6| Step: 4
Training loss: 2.8243267202249998
Validation loss: 2.469095812589169

Epoch: 6| Step: 5
Training loss: 1.920334982061426
Validation loss: 2.4666275988574906

Epoch: 6| Step: 6
Training loss: 3.313459293445273
Validation loss: 2.45266738593508

Epoch: 6| Step: 7
Training loss: 2.5464389170255175
Validation loss: 2.464693149786454

Epoch: 6| Step: 8
Training loss: 2.77159689418791
Validation loss: 2.471710791033379

Epoch: 6| Step: 9
Training loss: 2.620854328437327
Validation loss: 2.4606431604362045

Epoch: 6| Step: 10
Training loss: 2.1499098293114347
Validation loss: 2.434612479093452

Epoch: 6| Step: 11
Training loss: 2.6604865901145227
Validation loss: 2.447035408097654

Epoch: 6| Step: 12
Training loss: 2.711068010074447
Validation loss: 2.453776548730109

Epoch: 6| Step: 13
Training loss: 2.958981474317885
Validation loss: 2.4484860531485166

Epoch: 151| Step: 0
Training loss: 2.655887893229646
Validation loss: 2.457685611198067

Epoch: 6| Step: 1
Training loss: 2.5401192212097023
Validation loss: 2.458062615009109

Epoch: 6| Step: 2
Training loss: 3.3479875469637017
Validation loss: 2.4465090877952265

Epoch: 6| Step: 3
Training loss: 2.451585614671046
Validation loss: 2.4534922713424048

Epoch: 6| Step: 4
Training loss: 1.942854404497621
Validation loss: 2.471442199513242

Epoch: 6| Step: 5
Training loss: 3.139634616756128
Validation loss: 2.458192043996098

Epoch: 6| Step: 6
Training loss: 2.618997523006216
Validation loss: 2.463503087356156

Epoch: 6| Step: 7
Training loss: 2.2841861589396357
Validation loss: 2.43894893239449

Epoch: 6| Step: 8
Training loss: 2.149428704232275
Validation loss: 2.442645016077065

Epoch: 6| Step: 9
Training loss: 2.2298176845726885
Validation loss: 2.4635474123368866

Epoch: 6| Step: 10
Training loss: 2.767071448056794
Validation loss: 2.4522665410796756

Epoch: 6| Step: 11
Training loss: 2.8262324455218835
Validation loss: 2.4486755646954417

Epoch: 6| Step: 12
Training loss: 2.829079651278629
Validation loss: 2.4603508394064617

Epoch: 6| Step: 13
Training loss: 2.472721719703712
Validation loss: 2.4453510426981433

Epoch: 152| Step: 0
Training loss: 2.8608814711113157
Validation loss: 2.4471383921811927

Epoch: 6| Step: 1
Training loss: 2.4146929167751785
Validation loss: 2.465145769349269

Epoch: 6| Step: 2
Training loss: 2.6099284607301776
Validation loss: 2.4578896009598035

Epoch: 6| Step: 3
Training loss: 2.097020456013301
Validation loss: 2.455768295764699

Epoch: 6| Step: 4
Training loss: 2.641691816272414
Validation loss: 2.4419493736012083

Epoch: 6| Step: 5
Training loss: 2.6354983069599514
Validation loss: 2.4465265820394126

Epoch: 6| Step: 6
Training loss: 2.1356273144047146
Validation loss: 2.4688234350752833

Epoch: 6| Step: 7
Training loss: 2.705539661241547
Validation loss: 2.4739050864084717

Epoch: 6| Step: 8
Training loss: 3.0341834592227923
Validation loss: 2.4695881752111433

Epoch: 6| Step: 9
Training loss: 2.8993668621431725
Validation loss: 2.45816269044729

Epoch: 6| Step: 10
Training loss: 2.524202496574587
Validation loss: 2.4545029568275845

Epoch: 6| Step: 11
Training loss: 2.6296492684317005
Validation loss: 2.461536670619135

Epoch: 6| Step: 12
Training loss: 2.92831885348543
Validation loss: 2.4460142721455482

Epoch: 6| Step: 13
Training loss: 1.9421482932321783
Validation loss: 2.4439125345410844

Epoch: 153| Step: 0
Training loss: 2.657908202550192
Validation loss: 2.4542647437025633

Epoch: 6| Step: 1
Training loss: 3.2028716196467313
Validation loss: 2.4636843647660234

Epoch: 6| Step: 2
Training loss: 3.2384167172358556
Validation loss: 2.4510241959606756

Epoch: 6| Step: 3
Training loss: 2.458697943938785
Validation loss: 2.455148177037081

Epoch: 6| Step: 4
Training loss: 2.528549072006691
Validation loss: 2.456948526600188

Epoch: 6| Step: 5
Training loss: 2.4431066344227883
Validation loss: 2.451085506496707

Epoch: 6| Step: 6
Training loss: 2.5910839488756148
Validation loss: 2.4752458425222916

Epoch: 6| Step: 7
Training loss: 2.306479685027611
Validation loss: 2.4444993196439073

Epoch: 6| Step: 8
Training loss: 2.0867841623923105
Validation loss: 2.4564356611636655

Epoch: 6| Step: 9
Training loss: 2.2535719598826085
Validation loss: 2.4526467777794823

Epoch: 6| Step: 10
Training loss: 2.63871271538065
Validation loss: 2.4688083013024076

Epoch: 6| Step: 11
Training loss: 2.6554078506170944
Validation loss: 2.4439745794340095

Epoch: 6| Step: 12
Training loss: 2.4463915896678436
Validation loss: 2.447818052617837

Epoch: 6| Step: 13
Training loss: 3.132110745417157
Validation loss: 2.456428351480774

Epoch: 154| Step: 0
Training loss: 3.014005077679261
Validation loss: 2.448345616620735

Epoch: 6| Step: 1
Training loss: 2.081164668169628
Validation loss: 2.458240747837435

Epoch: 6| Step: 2
Training loss: 2.9277197167536655
Validation loss: 2.4518782237182504

Epoch: 6| Step: 3
Training loss: 2.962594487095847
Validation loss: 2.4439068710356873

Epoch: 6| Step: 4
Training loss: 2.552880350855659
Validation loss: 2.4518131897237336

Epoch: 6| Step: 5
Training loss: 2.5427381935434368
Validation loss: 2.465235983793612

Epoch: 6| Step: 6
Training loss: 2.975896645709872
Validation loss: 2.4735849952191615

Epoch: 6| Step: 7
Training loss: 2.3981702823454802
Validation loss: 2.450171565548267

Epoch: 6| Step: 8
Training loss: 2.4309037773518827
Validation loss: 2.447898636024763

Epoch: 6| Step: 9
Training loss: 2.5918752490269577
Validation loss: 2.4698696990374804

Epoch: 6| Step: 10
Training loss: 2.1416640161678475
Validation loss: 2.4520668092027784

Epoch: 6| Step: 11
Training loss: 3.368896192446564
Validation loss: 2.4580719264644406

Epoch: 6| Step: 12
Training loss: 1.7635637252278278
Validation loss: 2.4582143363357316

Epoch: 6| Step: 13
Training loss: 2.247988437453159
Validation loss: 2.458948919337829

Epoch: 155| Step: 0
Training loss: 2.752703205060463
Validation loss: 2.460987752703122

Epoch: 6| Step: 1
Training loss: 2.5543821193146905
Validation loss: 2.455234257489334

Epoch: 6| Step: 2
Training loss: 2.938505933874064
Validation loss: 2.4445176305501493

Epoch: 6| Step: 3
Training loss: 2.6703533278860223
Validation loss: 2.478842458589359

Epoch: 6| Step: 4
Training loss: 1.996233791507662
Validation loss: 2.4487582503554823

Epoch: 6| Step: 5
Training loss: 2.7070465748010486
Validation loss: 2.45266366224358

Epoch: 6| Step: 6
Training loss: 2.639653766498274
Validation loss: 2.4554419166772625

Epoch: 6| Step: 7
Training loss: 2.5757344578064227
Validation loss: 2.486123114229003

Epoch: 6| Step: 8
Training loss: 2.657751937795174
Validation loss: 2.469018462830889

Epoch: 6| Step: 9
Training loss: 2.141881977445059
Validation loss: 2.449175544252094

Epoch: 6| Step: 10
Training loss: 2.9642293140081777
Validation loss: 2.454170332476785

Epoch: 6| Step: 11
Training loss: 2.7654024023788146
Validation loss: 2.467014596369411

Epoch: 6| Step: 12
Training loss: 2.3604723670988825
Validation loss: 2.458961708060617

Epoch: 6| Step: 13
Training loss: 2.505441846426533
Validation loss: 2.454416200003256

Epoch: 156| Step: 0
Training loss: 2.2133984568027194
Validation loss: 2.4741415017955157

Epoch: 6| Step: 1
Training loss: 2.6295871618012607
Validation loss: 2.4704684103419883

Epoch: 6| Step: 2
Training loss: 2.793421397842888
Validation loss: 2.4529801333711236

Epoch: 6| Step: 3
Training loss: 2.71142626487086
Validation loss: 2.4614261452635495

Epoch: 6| Step: 4
Training loss: 2.4079545164216696
Validation loss: 2.4592072841971304

Epoch: 6| Step: 5
Training loss: 2.6985957838683277
Validation loss: 2.463769957599141

Epoch: 6| Step: 6
Training loss: 2.5616990675290774
Validation loss: 2.4549998949999603

Epoch: 6| Step: 7
Training loss: 2.668083132613949
Validation loss: 2.4533533998852906

Epoch: 6| Step: 8
Training loss: 2.323934790952116
Validation loss: 2.4545805749624536

Epoch: 6| Step: 9
Training loss: 3.43462640121603
Validation loss: 2.461797941114064

Epoch: 6| Step: 10
Training loss: 2.1408382782879607
Validation loss: 2.453173550497047

Epoch: 6| Step: 11
Training loss: 2.540366345666808
Validation loss: 2.4516562710400924

Epoch: 6| Step: 12
Training loss: 2.3387589272308826
Validation loss: 2.4608036232072874

Epoch: 6| Step: 13
Training loss: 2.5214796472530234
Validation loss: 2.462321898709331

Epoch: 157| Step: 0
Training loss: 2.7077402394685604
Validation loss: 2.4529002718760613

Epoch: 6| Step: 1
Training loss: 2.8205818195617525
Validation loss: 2.4360795826960286

Epoch: 6| Step: 2
Training loss: 3.2362426672860147
Validation loss: 2.45906356664066

Epoch: 6| Step: 3
Training loss: 2.1463467499171998
Validation loss: 2.4588575650641395

Epoch: 6| Step: 4
Training loss: 2.2398375847382015
Validation loss: 2.4330011746955718

Epoch: 6| Step: 5
Training loss: 2.678195282092898
Validation loss: 2.463115077046432

Epoch: 6| Step: 6
Training loss: 2.185448256544009
Validation loss: 2.4671709902315526

Epoch: 6| Step: 7
Training loss: 2.566290029742186
Validation loss: 2.465436944229003

Epoch: 6| Step: 8
Training loss: 2.905613819346145
Validation loss: 2.4711130592262722

Epoch: 6| Step: 9
Training loss: 2.228585592336674
Validation loss: 2.4601378355737777

Epoch: 6| Step: 10
Training loss: 2.8277763025279548
Validation loss: 2.457042236866991

Epoch: 6| Step: 11
Training loss: 2.498236606482215
Validation loss: 2.4528540869309636

Epoch: 6| Step: 12
Training loss: 2.1592896639224133
Validation loss: 2.473505476655579

Epoch: 6| Step: 13
Training loss: 3.1311933561824747
Validation loss: 2.4544316324597846

Epoch: 158| Step: 0
Training loss: 2.374332735790538
Validation loss: 2.4667136107688985

Epoch: 6| Step: 1
Training loss: 2.274209641884243
Validation loss: 2.4610825529254625

Epoch: 6| Step: 2
Training loss: 2.536831389036119
Validation loss: 2.45205745298796

Epoch: 6| Step: 3
Training loss: 2.9248971252608826
Validation loss: 2.466331132879067

Epoch: 6| Step: 4
Training loss: 2.7515031867753157
Validation loss: 2.440097065815008

Epoch: 6| Step: 5
Training loss: 2.012354837240887
Validation loss: 2.4661913305126677

Epoch: 6| Step: 6
Training loss: 2.557471295565763
Validation loss: 2.459993975418788

Epoch: 6| Step: 7
Training loss: 2.545813684548963
Validation loss: 2.454437092549338

Epoch: 6| Step: 8
Training loss: 3.202412446944753
Validation loss: 2.4509662602890057

Epoch: 6| Step: 9
Training loss: 2.2889335517887788
Validation loss: 2.4483661745953778

Epoch: 6| Step: 10
Training loss: 2.1313826130974953
Validation loss: 2.463824170994524

Epoch: 6| Step: 11
Training loss: 2.9124153943522986
Validation loss: 2.4423157023749713

Epoch: 6| Step: 12
Training loss: 2.8127719323833413
Validation loss: 2.4543598286713193

Epoch: 6| Step: 13
Training loss: 3.212354064476561
Validation loss: 2.4680158630267557

Epoch: 159| Step: 0
Training loss: 2.267550367239667
Validation loss: 2.4547206939472543

Epoch: 6| Step: 1
Training loss: 3.153742483449862
Validation loss: 2.4783072784413833

Epoch: 6| Step: 2
Training loss: 2.0818204218347724
Validation loss: 2.460923790751092

Epoch: 6| Step: 3
Training loss: 2.3011142768185215
Validation loss: 2.470957508324071

Epoch: 6| Step: 4
Training loss: 2.293009301108101
Validation loss: 2.4690993604279012

Epoch: 6| Step: 5
Training loss: 3.242148525509342
Validation loss: 2.4582165279625214

Epoch: 6| Step: 6
Training loss: 2.5602110897892354
Validation loss: 2.4685128833965346

Epoch: 6| Step: 7
Training loss: 2.9833552830348604
Validation loss: 2.4566701449600585

Epoch: 6| Step: 8
Training loss: 2.7819074218067392
Validation loss: 2.4648093292722826

Epoch: 6| Step: 9
Training loss: 2.3573878932927776
Validation loss: 2.4417261215184354

Epoch: 6| Step: 10
Training loss: 2.022653553041124
Validation loss: 2.451126487412059

Epoch: 6| Step: 11
Training loss: 2.9565609919583804
Validation loss: 2.4488795606676703

Epoch: 6| Step: 12
Training loss: 2.4305994217562357
Validation loss: 2.4600376320625132

Epoch: 6| Step: 13
Training loss: 2.5946602200894904
Validation loss: 2.4480098695276564

Epoch: 160| Step: 0
Training loss: 2.2907000728446465
Validation loss: 2.4584954508835493

Epoch: 6| Step: 1
Training loss: 2.8009172776307354
Validation loss: 2.475109594029026

Epoch: 6| Step: 2
Training loss: 3.093603573811521
Validation loss: 2.4562514544879335

Epoch: 6| Step: 3
Training loss: 2.430806383784105
Validation loss: 2.465565267616775

Epoch: 6| Step: 4
Training loss: 3.493153551537513
Validation loss: 2.454214922638437

Epoch: 6| Step: 5
Training loss: 2.5949093169609476
Validation loss: 2.4373609399582237

Epoch: 6| Step: 6
Training loss: 1.927263103726081
Validation loss: 2.4484923667369

Epoch: 6| Step: 7
Training loss: 2.139913844575765
Validation loss: 2.4724153687339636

Epoch: 6| Step: 8
Training loss: 2.1106836851104216
Validation loss: 2.48012554755136

Epoch: 6| Step: 9
Training loss: 2.7406794648103245
Validation loss: 2.457036061064327

Epoch: 6| Step: 10
Training loss: 2.524863203516612
Validation loss: 2.457388866597597

Epoch: 6| Step: 11
Training loss: 2.9882807712928536
Validation loss: 2.4590572572579994

Epoch: 6| Step: 12
Training loss: 2.2450063179453963
Validation loss: 2.4479980074726075

Epoch: 6| Step: 13
Training loss: 2.5076178834689724
Validation loss: 2.4655365867322354

Epoch: 161| Step: 0
Training loss: 2.614361595285419
Validation loss: 2.461904477129678

Epoch: 6| Step: 1
Training loss: 2.1914997046903655
Validation loss: 2.4557611187622292

Epoch: 6| Step: 2
Training loss: 2.1123735378717887
Validation loss: 2.4527416944792653

Epoch: 6| Step: 3
Training loss: 2.2562798706782545
Validation loss: 2.4531874326399707

Epoch: 6| Step: 4
Training loss: 2.475341110613162
Validation loss: 2.4515094504525003

Epoch: 6| Step: 5
Training loss: 2.34364338950238
Validation loss: 2.483546829901685

Epoch: 6| Step: 6
Training loss: 2.5105765728390717
Validation loss: 2.4547899964255095

Epoch: 6| Step: 7
Training loss: 2.576619488957429
Validation loss: 2.4601003477917702

Epoch: 6| Step: 8
Training loss: 2.4880475424060338
Validation loss: 2.430483249305635

Epoch: 6| Step: 9
Training loss: 3.3600559697712056
Validation loss: 2.445736867086067

Epoch: 6| Step: 10
Training loss: 3.214758017823298
Validation loss: 2.4527249135066516

Epoch: 6| Step: 11
Training loss: 2.7869729300704655
Validation loss: 2.4693475864245737

Epoch: 6| Step: 12
Training loss: 2.871257170094035
Validation loss: 2.451780942896178

Epoch: 6| Step: 13
Training loss: 1.6895578340925925
Validation loss: 2.4646498689328236

Epoch: 162| Step: 0
Training loss: 2.700532850032153
Validation loss: 2.459956479191573

Epoch: 6| Step: 1
Training loss: 2.173332767993565
Validation loss: 2.453610230828996

Epoch: 6| Step: 2
Training loss: 2.5965494881447504
Validation loss: 2.450514165439361

Epoch: 6| Step: 3
Training loss: 2.714032344178415
Validation loss: 2.4664438696096846

Epoch: 6| Step: 4
Training loss: 1.642527539793133
Validation loss: 2.468254190140961

Epoch: 6| Step: 5
Training loss: 2.74513325505014
Validation loss: 2.472085482759503

Epoch: 6| Step: 6
Training loss: 2.5224937351175476
Validation loss: 2.452057173837858

Epoch: 6| Step: 7
Training loss: 2.9700007965908846
Validation loss: 2.4753327175158053

Epoch: 6| Step: 8
Training loss: 2.3165950087115372
Validation loss: 2.4838442579587783

Epoch: 6| Step: 9
Training loss: 2.666917451351237
Validation loss: 2.4838576998174484

Epoch: 6| Step: 10
Training loss: 3.231699255991615
Validation loss: 2.4673049122096833

Epoch: 6| Step: 11
Training loss: 2.405131488782374
Validation loss: 2.4623261762606976

Epoch: 6| Step: 12
Training loss: 2.5189619027255676
Validation loss: 2.461798124395042

Epoch: 6| Step: 13
Training loss: 2.873257648093728
Validation loss: 2.4747413327932417

Epoch: 163| Step: 0
Training loss: 2.8574307194518793
Validation loss: 2.468971244085351

Epoch: 6| Step: 1
Training loss: 2.186666057206666
Validation loss: 2.4806595220981813

Epoch: 6| Step: 2
Training loss: 2.885167924829987
Validation loss: 2.4524915880815774

Epoch: 6| Step: 3
Training loss: 2.523424744942851
Validation loss: 2.471734446176369

Epoch: 6| Step: 4
Training loss: 3.207230778944537
Validation loss: 2.4747983767712025

Epoch: 6| Step: 5
Training loss: 2.0558540310827373
Validation loss: 2.462624025904307

Epoch: 6| Step: 6
Training loss: 2.2840955571162267
Validation loss: 2.4466502034185353

Epoch: 6| Step: 7
Training loss: 2.53727598281984
Validation loss: 2.461210996057241

Epoch: 6| Step: 8
Training loss: 3.018620401763668
Validation loss: 2.4400691609068077

Epoch: 6| Step: 9
Training loss: 2.6165754371176537
Validation loss: 2.461160269409477

Epoch: 6| Step: 10
Training loss: 2.4167122233689833
Validation loss: 2.482158037274214

Epoch: 6| Step: 11
Training loss: 2.5518820754641456
Validation loss: 2.437206030768045

Epoch: 6| Step: 12
Training loss: 1.9367999381051573
Validation loss: 2.460258004115825

Epoch: 6| Step: 13
Training loss: 3.0124419020752757
Validation loss: 2.4446476287972776

Epoch: 164| Step: 0
Training loss: 2.6643608575025453
Validation loss: 2.4488781139030102

Epoch: 6| Step: 1
Training loss: 2.803008700778834
Validation loss: 2.4480761282113166

Epoch: 6| Step: 2
Training loss: 2.230285637014811
Validation loss: 2.4551533995467127

Epoch: 6| Step: 3
Training loss: 3.2502074542224837
Validation loss: 2.4632417562661915

Epoch: 6| Step: 4
Training loss: 2.3709366823363185
Validation loss: 2.452277942368772

Epoch: 6| Step: 5
Training loss: 2.4270218826395107
Validation loss: 2.4525082013098625

Epoch: 6| Step: 6
Training loss: 2.7227588781993672
Validation loss: 2.4549710275044716

Epoch: 6| Step: 7
Training loss: 2.2894788760468496
Validation loss: 2.4770845459691238

Epoch: 6| Step: 8
Training loss: 2.3836074253566446
Validation loss: 2.468090245440032

Epoch: 6| Step: 9
Training loss: 2.8547063349795136
Validation loss: 2.466618504701193

Epoch: 6| Step: 10
Training loss: 2.8208519586110685
Validation loss: 2.4587790101024427

Epoch: 6| Step: 11
Training loss: 2.182146114572587
Validation loss: 2.4486671472037846

Epoch: 6| Step: 12
Training loss: 2.6031192555083673
Validation loss: 2.4601135280833493

Epoch: 6| Step: 13
Training loss: 2.1092502133228157
Validation loss: 2.4675554464695364

Epoch: 165| Step: 0
Training loss: 1.9762854702376467
Validation loss: 2.4706760845839026

Epoch: 6| Step: 1
Training loss: 2.3388702456269153
Validation loss: 2.489750814311418

Epoch: 6| Step: 2
Training loss: 2.7421349849182652
Validation loss: 2.4834107849465266

Epoch: 6| Step: 3
Training loss: 2.8823334417336133
Validation loss: 2.4703294668542286

Epoch: 6| Step: 4
Training loss: 2.853325787234206
Validation loss: 2.4618831913303065

Epoch: 6| Step: 5
Training loss: 2.4563208494572764
Validation loss: 2.461722269897067

Epoch: 6| Step: 6
Training loss: 2.1349151642715163
Validation loss: 2.449696238054894

Epoch: 6| Step: 7
Training loss: 2.944290590965065
Validation loss: 2.4609801971539116

Epoch: 6| Step: 8
Training loss: 2.2559451924964513
Validation loss: 2.4556059139538324

Epoch: 6| Step: 9
Training loss: 2.7677512750726905
Validation loss: 2.4664905739110026

Epoch: 6| Step: 10
Training loss: 2.1674566540459277
Validation loss: 2.468382909213676

Epoch: 6| Step: 11
Training loss: 2.885797542034659
Validation loss: 2.4588637237804813

Epoch: 6| Step: 12
Training loss: 2.886613361257045
Validation loss: 2.4852360524232835

Epoch: 6| Step: 13
Training loss: 2.542520838139154
Validation loss: 2.475840921901212

Epoch: 166| Step: 0
Training loss: 2.7452313953419205
Validation loss: 2.4513543518986842

Epoch: 6| Step: 1
Training loss: 3.2518386041678258
Validation loss: 2.454511938159398

Epoch: 6| Step: 2
Training loss: 2.6163329594012805
Validation loss: 2.4597131900348184

Epoch: 6| Step: 3
Training loss: 3.0134104765523255
Validation loss: 2.457098312945629

Epoch: 6| Step: 4
Training loss: 2.4642340968631746
Validation loss: 2.486482608141784

Epoch: 6| Step: 5
Training loss: 2.63508521447114
Validation loss: 2.453070926377278

Epoch: 6| Step: 6
Training loss: 1.7205131503830098
Validation loss: 2.4466990112755687

Epoch: 6| Step: 7
Training loss: 2.7462194639165567
Validation loss: 2.471078630380338

Epoch: 6| Step: 8
Training loss: 2.467652958358263
Validation loss: 2.456471862767678

Epoch: 6| Step: 9
Training loss: 2.392864699036598
Validation loss: 2.479831346557101

Epoch: 6| Step: 10
Training loss: 2.795480817543061
Validation loss: 2.466832437144359

Epoch: 6| Step: 11
Training loss: 2.4280584338476516
Validation loss: 2.464516990611325

Epoch: 6| Step: 12
Training loss: 2.207612141820519
Validation loss: 2.476763064652192

Epoch: 6| Step: 13
Training loss: 2.232002332351177
Validation loss: 2.4818592238932893

Epoch: 167| Step: 0
Training loss: 2.5875762633358463
Validation loss: 2.4646544394102166

Epoch: 6| Step: 1
Training loss: 2.870484164134659
Validation loss: 2.4572892896309684

Epoch: 6| Step: 2
Training loss: 3.0078508647106856
Validation loss: 2.4747931703384243

Epoch: 6| Step: 3
Training loss: 2.8082941609111685
Validation loss: 2.4636982927810736

Epoch: 6| Step: 4
Training loss: 2.5577832984073003
Validation loss: 2.4796574590130924

Epoch: 6| Step: 5
Training loss: 2.6189220544927534
Validation loss: 2.4654121394278414

Epoch: 6| Step: 6
Training loss: 2.0602237972430477
Validation loss: 2.470907730216222

Epoch: 6| Step: 7
Training loss: 2.3906997968154955
Validation loss: 2.451722287924547

Epoch: 6| Step: 8
Training loss: 2.694928924246107
Validation loss: 2.450182894973934

Epoch: 6| Step: 9
Training loss: 2.4129527482466364
Validation loss: 2.449334617862774

Epoch: 6| Step: 10
Training loss: 2.7949372297141117
Validation loss: 2.442435479037361

Epoch: 6| Step: 11
Training loss: 2.5903255423016036
Validation loss: 2.483776700254369

Epoch: 6| Step: 12
Training loss: 2.140597823590036
Validation loss: 2.429198224088148

Epoch: 6| Step: 13
Training loss: 2.2143360343172795
Validation loss: 2.4529902944580875

Epoch: 168| Step: 0
Training loss: 3.2052872965527417
Validation loss: 2.4607988111745183

Epoch: 6| Step: 1
Training loss: 2.600725652227058
Validation loss: 2.447376247509263

Epoch: 6| Step: 2
Training loss: 2.27096433582463
Validation loss: 2.4532549277450606

Epoch: 6| Step: 3
Training loss: 2.6054339771152226
Validation loss: 2.458258856272126

Epoch: 6| Step: 4
Training loss: 2.4297383293894423
Validation loss: 2.450204789871803

Epoch: 6| Step: 5
Training loss: 2.8529293599066183
Validation loss: 2.4427114570153936

Epoch: 6| Step: 6
Training loss: 2.077596382081264
Validation loss: 2.4549074121371453

Epoch: 6| Step: 7
Training loss: 2.437596343655124
Validation loss: 2.459695894846729

Epoch: 6| Step: 8
Training loss: 2.6482677123972715
Validation loss: 2.459951410174701

Epoch: 6| Step: 9
Training loss: 2.5604185629440086
Validation loss: 2.4542128345084353

Epoch: 6| Step: 10
Training loss: 2.7584389469483908
Validation loss: 2.4645419370486157

Epoch: 6| Step: 11
Training loss: 2.312524125256863
Validation loss: 2.450384493071908

Epoch: 6| Step: 12
Training loss: 2.6379567044676824
Validation loss: 2.468251722318474

Epoch: 6| Step: 13
Training loss: 2.3393321807472924
Validation loss: 2.4502643820091734

Epoch: 169| Step: 0
Training loss: 2.2273599903019057
Validation loss: 2.474359345677106

Epoch: 6| Step: 1
Training loss: 1.8923502214995316
Validation loss: 2.4635538569482667

Epoch: 6| Step: 2
Training loss: 2.5215021512493068
Validation loss: 2.462556190030789

Epoch: 6| Step: 3
Training loss: 2.7594313584444445
Validation loss: 2.4550624919389747

Epoch: 6| Step: 4
Training loss: 3.6572337335126623
Validation loss: 2.4484273307615236

Epoch: 6| Step: 5
Training loss: 2.2232015306256803
Validation loss: 2.4642182129049814

Epoch: 6| Step: 6
Training loss: 2.3931598065231885
Validation loss: 2.4622978996186853

Epoch: 6| Step: 7
Training loss: 2.6265786283362087
Validation loss: 2.4896376934201694

Epoch: 6| Step: 8
Training loss: 2.57012920247828
Validation loss: 2.454721435450995

Epoch: 6| Step: 9
Training loss: 3.1985348446730875
Validation loss: 2.463952204851347

Epoch: 6| Step: 10
Training loss: 2.6341764725966517
Validation loss: 2.470674450320568

Epoch: 6| Step: 11
Training loss: 2.1940783089265308
Validation loss: 2.4687262134540573

Epoch: 6| Step: 12
Training loss: 2.186148416679379
Validation loss: 2.46610402017877

Epoch: 6| Step: 13
Training loss: 2.840453196618916
Validation loss: 2.462041447538733

Epoch: 170| Step: 0
Training loss: 2.738932446418663
Validation loss: 2.493133757203549

Epoch: 6| Step: 1
Training loss: 2.595926313944446
Validation loss: 2.4740186012755156

Epoch: 6| Step: 2
Training loss: 2.560200846065086
Validation loss: 2.4619276579378866

Epoch: 6| Step: 3
Training loss: 2.4563016308509815
Validation loss: 2.4685071205509823

Epoch: 6| Step: 4
Training loss: 2.6259823732038723
Validation loss: 2.4841437649770195

Epoch: 6| Step: 5
Training loss: 2.2496053561509077
Validation loss: 2.4557295313506367

Epoch: 6| Step: 6
Training loss: 2.0516151113511794
Validation loss: 2.4583554479801135

Epoch: 6| Step: 7
Training loss: 2.156198362754948
Validation loss: 2.4483060451618006

Epoch: 6| Step: 8
Training loss: 1.9320502391704173
Validation loss: 2.4600044238209726

Epoch: 6| Step: 9
Training loss: 2.7055705038968023
Validation loss: 2.432787714165344

Epoch: 6| Step: 10
Training loss: 2.196275167391572
Validation loss: 2.4562397279962696

Epoch: 6| Step: 11
Training loss: 2.79630141530283
Validation loss: 2.458703177155288

Epoch: 6| Step: 12
Training loss: 3.286668644789074
Validation loss: 2.471510969837795

Epoch: 6| Step: 13
Training loss: 3.3362609563528265
Validation loss: 2.4539441340746215

Epoch: 171| Step: 0
Training loss: 2.1372962185276103
Validation loss: 2.454560736433081

Epoch: 6| Step: 1
Training loss: 2.32402168528408
Validation loss: 2.4490573784951835

Epoch: 6| Step: 2
Training loss: 3.114556217819797
Validation loss: 2.4617536273302245

Epoch: 6| Step: 3
Training loss: 2.8434926010848556
Validation loss: 2.443071644051124

Epoch: 6| Step: 4
Training loss: 3.2971720629458963
Validation loss: 2.4515735335864366

Epoch: 6| Step: 5
Training loss: 2.550086868900828
Validation loss: 2.4543894219802365

Epoch: 6| Step: 6
Training loss: 1.9583360049723264
Validation loss: 2.4563820236158165

Epoch: 6| Step: 7
Training loss: 2.311645762434514
Validation loss: 2.469982470424903

Epoch: 6| Step: 8
Training loss: 2.435658957832235
Validation loss: 2.4679854873214175

Epoch: 6| Step: 9
Training loss: 2.510097805260559
Validation loss: 2.4600145564151754

Epoch: 6| Step: 10
Training loss: 2.801488215179139
Validation loss: 2.4654171545837302

Epoch: 6| Step: 11
Training loss: 2.378939723889595
Validation loss: 2.473296744328586

Epoch: 6| Step: 12
Training loss: 2.453011868534853
Validation loss: 2.4517064442017027

Epoch: 6| Step: 13
Training loss: 2.223737349836061
Validation loss: 2.46812861888352

Epoch: 172| Step: 0
Training loss: 2.379072211729406
Validation loss: 2.4463739880929265

Epoch: 6| Step: 1
Training loss: 2.367640083784952
Validation loss: 2.448288320701984

Epoch: 6| Step: 2
Training loss: 2.6273397281739586
Validation loss: 2.4668733632700546

Epoch: 6| Step: 3
Training loss: 2.6997408989810223
Validation loss: 2.4738914562743353

Epoch: 6| Step: 4
Training loss: 2.239383659037299
Validation loss: 2.456071164940639

Epoch: 6| Step: 5
Training loss: 3.410788216428018
Validation loss: 2.46583653130645

Epoch: 6| Step: 6
Training loss: 3.018563217797717
Validation loss: 2.4654258975472496

Epoch: 6| Step: 7
Training loss: 2.303887904195353
Validation loss: 2.4768053658203146

Epoch: 6| Step: 8
Training loss: 2.42998147148949
Validation loss: 2.4496062582023055

Epoch: 6| Step: 9
Training loss: 2.2698411319612792
Validation loss: 2.445403330803647

Epoch: 6| Step: 10
Training loss: 3.182203792143339
Validation loss: 2.4523312975228135

Epoch: 6| Step: 11
Training loss: 2.0093050504051138
Validation loss: 2.4595987387381246

Epoch: 6| Step: 12
Training loss: 2.177084404125285
Validation loss: 2.4661026542085187

Epoch: 6| Step: 13
Training loss: 2.475094621949585
Validation loss: 2.468734588512637

Epoch: 173| Step: 0
Training loss: 2.4410377651607855
Validation loss: 2.460597877747518

Epoch: 6| Step: 1
Training loss: 2.371224062008079
Validation loss: 2.4681477350102816

Epoch: 6| Step: 2
Training loss: 2.4044987634824992
Validation loss: 2.4413642810782794

Epoch: 6| Step: 3
Training loss: 2.5819863735344684
Validation loss: 2.463542692035988

Epoch: 6| Step: 4
Training loss: 2.218500687467319
Validation loss: 2.4629553831504714

Epoch: 6| Step: 5
Training loss: 2.843851947005043
Validation loss: 2.464510505869362

Epoch: 6| Step: 6
Training loss: 3.169467256467455
Validation loss: 2.4525786074093823

Epoch: 6| Step: 7
Training loss: 2.3958018978102147
Validation loss: 2.462209816094287

Epoch: 6| Step: 8
Training loss: 2.660058914622053
Validation loss: 2.4753421659623576

Epoch: 6| Step: 9
Training loss: 2.384454880322533
Validation loss: 2.461919452367017

Epoch: 6| Step: 10
Training loss: 2.683211164674864
Validation loss: 2.440365043851238

Epoch: 6| Step: 11
Training loss: 2.8118324335237883
Validation loss: 2.477160416458538

Epoch: 6| Step: 12
Training loss: 2.4377821734522174
Validation loss: 2.440121958278759

Epoch: 6| Step: 13
Training loss: 2.2595809821523956
Validation loss: 2.468717008645183

Epoch: 174| Step: 0
Training loss: 2.4958949718813974
Validation loss: 2.4581642057939797

Epoch: 6| Step: 1
Training loss: 2.1327888012362384
Validation loss: 2.4757841416593953

Epoch: 6| Step: 2
Training loss: 2.7644447351328107
Validation loss: 2.4530214395342598

Epoch: 6| Step: 3
Training loss: 2.1738719952895793
Validation loss: 2.4588795099169336

Epoch: 6| Step: 4
Training loss: 2.8861293165138364
Validation loss: 2.4548898784086743

Epoch: 6| Step: 5
Training loss: 2.684606369403637
Validation loss: 2.459047942235994

Epoch: 6| Step: 6
Training loss: 2.4479428120833355
Validation loss: 2.4634904580143613

Epoch: 6| Step: 7
Training loss: 2.42609082886439
Validation loss: 2.4649839782427123

Epoch: 6| Step: 8
Training loss: 2.340058840639489
Validation loss: 2.4742669751180375

Epoch: 6| Step: 9
Training loss: 2.6508070886298705
Validation loss: 2.4696977384230108

Epoch: 6| Step: 10
Training loss: 2.764943442982045
Validation loss: 2.4617204578582346

Epoch: 6| Step: 11
Training loss: 2.557761486479204
Validation loss: 2.4785066758295375

Epoch: 6| Step: 12
Training loss: 2.5065760906913024
Validation loss: 2.4499242141157493

Epoch: 6| Step: 13
Training loss: 2.9289628009928035
Validation loss: 2.4733468591587338

Epoch: 175| Step: 0
Training loss: 2.3631029802662047
Validation loss: 2.4576119424158107

Epoch: 6| Step: 1
Training loss: 2.070695373831524
Validation loss: 2.4731270060534647

Epoch: 6| Step: 2
Training loss: 2.6657915070060683
Validation loss: 2.466655354015192

Epoch: 6| Step: 3
Training loss: 2.370320377827116
Validation loss: 2.461922730433381

Epoch: 6| Step: 4
Training loss: 2.2388910924092387
Validation loss: 2.4598598768771582

Epoch: 6| Step: 5
Training loss: 2.9436546941988966
Validation loss: 2.4703510410179845

Epoch: 6| Step: 6
Training loss: 2.9648624062736477
Validation loss: 2.4713591182430963

Epoch: 6| Step: 7
Training loss: 1.9413674425510155
Validation loss: 2.4589699062991115

Epoch: 6| Step: 8
Training loss: 2.788780903424851
Validation loss: 2.461362021805863

Epoch: 6| Step: 9
Training loss: 2.801923064194664
Validation loss: 2.479094365603758

Epoch: 6| Step: 10
Training loss: 2.4618879148130484
Validation loss: 2.46682161131659

Epoch: 6| Step: 11
Training loss: 2.8318685971610535
Validation loss: 2.4640100578405937

Epoch: 6| Step: 12
Training loss: 2.3190406884443933
Validation loss: 2.467603159820777

Epoch: 6| Step: 13
Training loss: 3.012299913275086
Validation loss: 2.4964785087633428

Epoch: 176| Step: 0
Training loss: 2.9670247736900395
Validation loss: 2.4797477730505695

Epoch: 6| Step: 1
Training loss: 2.2504638617579737
Validation loss: 2.4391373372037677

Epoch: 6| Step: 2
Training loss: 2.169534863313407
Validation loss: 2.4607352360352874

Epoch: 6| Step: 3
Training loss: 2.2301958388136387
Validation loss: 2.4615103179155553

Epoch: 6| Step: 4
Training loss: 2.0802388160495697
Validation loss: 2.4780539206532395

Epoch: 6| Step: 5
Training loss: 1.9040394457409489
Validation loss: 2.4331468109754555

Epoch: 6| Step: 6
Training loss: 2.558650870813961
Validation loss: 2.45591938480584

Epoch: 6| Step: 7
Training loss: 2.9501188609859965
Validation loss: 2.4815501506728253

Epoch: 6| Step: 8
Training loss: 3.2872770632732884
Validation loss: 2.471587332965543

Epoch: 6| Step: 9
Training loss: 3.1393794536312165
Validation loss: 2.463157978958605

Epoch: 6| Step: 10
Training loss: 1.8271406082809278
Validation loss: 2.465847373934932

Epoch: 6| Step: 11
Training loss: 2.8466579115805195
Validation loss: 2.4424913247313222

Epoch: 6| Step: 12
Training loss: 2.4949818792812692
Validation loss: 2.4524127863472667

Epoch: 6| Step: 13
Training loss: 2.5655507791356396
Validation loss: 2.4676703006278093

Epoch: 177| Step: 0
Training loss: 2.8980923264607066
Validation loss: 2.486493248358878

Epoch: 6| Step: 1
Training loss: 2.6304433786852814
Validation loss: 2.4915886418328053

Epoch: 6| Step: 2
Training loss: 3.214549462532862
Validation loss: 2.4778916066903096

Epoch: 6| Step: 3
Training loss: 2.2672149341061782
Validation loss: 2.4803427201302117

Epoch: 6| Step: 4
Training loss: 2.525141940518034
Validation loss: 2.4763160832189635

Epoch: 6| Step: 5
Training loss: 1.9773505528399684
Validation loss: 2.4723559195906226

Epoch: 6| Step: 6
Training loss: 2.3755873907414573
Validation loss: 2.4645586219570697

Epoch: 6| Step: 7
Training loss: 2.636244893763206
Validation loss: 2.4638154681299294

Epoch: 6| Step: 8
Training loss: 2.7106741741593714
Validation loss: 2.482691683615305

Epoch: 6| Step: 9
Training loss: 2.4567929199295606
Validation loss: 2.470144450986563

Epoch: 6| Step: 10
Training loss: 2.1823439732172707
Validation loss: 2.4699283610621356

Epoch: 6| Step: 11
Training loss: 2.379724321186938
Validation loss: 2.473964472419276

Epoch: 6| Step: 12
Training loss: 2.7411520543584453
Validation loss: 2.4339168875714394

Epoch: 6| Step: 13
Training loss: 2.5460642829025586
Validation loss: 2.4709546271599185

Epoch: 178| Step: 0
Training loss: 2.7266439955809587
Validation loss: 2.4525373371679797

Epoch: 6| Step: 1
Training loss: 2.6409743941256316
Validation loss: 2.464965692486198

Epoch: 6| Step: 2
Training loss: 2.346136785182999
Validation loss: 2.4617369431968714

Epoch: 6| Step: 3
Training loss: 2.2798493148132386
Validation loss: 2.4445415226157303

Epoch: 6| Step: 4
Training loss: 1.7931207330652303
Validation loss: 2.4579725033716073

Epoch: 6| Step: 5
Training loss: 1.641624945224978
Validation loss: 2.4794759401485718

Epoch: 6| Step: 6
Training loss: 2.5485639530245754
Validation loss: 2.452145688965325

Epoch: 6| Step: 7
Training loss: 2.210644058865827
Validation loss: 2.4633008997995796

Epoch: 6| Step: 8
Training loss: 3.2200850893707895
Validation loss: 2.447329452624179

Epoch: 6| Step: 9
Training loss: 3.0175285063679453
Validation loss: 2.445274910743894

Epoch: 6| Step: 10
Training loss: 2.3322950051064995
Validation loss: 2.456102922270469

Epoch: 6| Step: 11
Training loss: 2.527426386665821
Validation loss: 2.4528528891699954

Epoch: 6| Step: 12
Training loss: 2.979292611258749
Validation loss: 2.4453981561384266

Epoch: 6| Step: 13
Training loss: 3.1470279235958634
Validation loss: 2.467953312609265

Epoch: 179| Step: 0
Training loss: 2.2715937423289376
Validation loss: 2.469459103706809

Epoch: 6| Step: 1
Training loss: 1.9612624062607094
Validation loss: 2.465376441372013

Epoch: 6| Step: 2
Training loss: 2.9197788165205845
Validation loss: 2.489804996901519

Epoch: 6| Step: 3
Training loss: 2.6835596340626218
Validation loss: 2.4494713465923823

Epoch: 6| Step: 4
Training loss: 3.043091287949146
Validation loss: 2.4565704929423346

Epoch: 6| Step: 5
Training loss: 2.2912662040607796
Validation loss: 2.4677605380950203

Epoch: 6| Step: 6
Training loss: 2.892333974071099
Validation loss: 2.4788903999079785

Epoch: 6| Step: 7
Training loss: 2.011649891684099
Validation loss: 2.471529367945374

Epoch: 6| Step: 8
Training loss: 2.7253409111187588
Validation loss: 2.478994443320817

Epoch: 6| Step: 9
Training loss: 2.094758431430069
Validation loss: 2.4828619925971704

Epoch: 6| Step: 10
Training loss: 2.2568407970658413
Validation loss: 2.4888117771943845

Epoch: 6| Step: 11
Training loss: 2.4252189930615833
Validation loss: 2.506096547603603

Epoch: 6| Step: 12
Training loss: 3.3195499756308005
Validation loss: 2.483236772265263

Epoch: 6| Step: 13
Training loss: 2.18651460523981
Validation loss: 2.4805614652739614

Epoch: 180| Step: 0
Training loss: 2.6944210623898774
Validation loss: 2.4753355894413884

Epoch: 6| Step: 1
Training loss: 2.5926564680536317
Validation loss: 2.4815839892464195

Epoch: 6| Step: 2
Training loss: 2.3355510481308888
Validation loss: 2.475875189262784

Epoch: 6| Step: 3
Training loss: 2.537206916607927
Validation loss: 2.4813779756653003

Epoch: 6| Step: 4
Training loss: 1.9997836234347608
Validation loss: 2.4790776047944645

Epoch: 6| Step: 5
Training loss: 1.9277380235013282
Validation loss: 2.471974614946263

Epoch: 6| Step: 6
Training loss: 2.4145141969075
Validation loss: 2.4739970352608442

Epoch: 6| Step: 7
Training loss: 2.744314211313544
Validation loss: 2.461453741395831

Epoch: 6| Step: 8
Training loss: 2.8323944069421283
Validation loss: 2.488581075988858

Epoch: 6| Step: 9
Training loss: 2.6276997806227715
Validation loss: 2.4643881216290198

Epoch: 6| Step: 10
Training loss: 3.3269866285958334
Validation loss: 2.4639593933703767

Epoch: 6| Step: 11
Training loss: 2.7824282775573885
Validation loss: 2.4642644756363836

Epoch: 6| Step: 12
Training loss: 2.310363607482445
Validation loss: 2.4805515235769477

Epoch: 6| Step: 13
Training loss: 1.6029262783924847
Validation loss: 2.469601954703287

Epoch: 181| Step: 0
Training loss: 2.8881871846580593
Validation loss: 2.4661839915322763

Epoch: 6| Step: 1
Training loss: 2.5946662847016158
Validation loss: 2.4757676815139713

Epoch: 6| Step: 2
Training loss: 2.4824336882279403
Validation loss: 2.4714359269188035

Epoch: 6| Step: 3
Training loss: 2.9083123221817995
Validation loss: 2.464186906601164

Epoch: 6| Step: 4
Training loss: 2.2347602778829034
Validation loss: 2.4632160660409914

Epoch: 6| Step: 5
Training loss: 2.7514400179808365
Validation loss: 2.4793301631229125

Epoch: 6| Step: 6
Training loss: 1.8169605352832332
Validation loss: 2.4346922191754863

Epoch: 6| Step: 7
Training loss: 2.266537186720443
Validation loss: 2.454274648254026

Epoch: 6| Step: 8
Training loss: 1.905093608368557
Validation loss: 2.4471944249242834

Epoch: 6| Step: 9
Training loss: 2.7771789244339864
Validation loss: 2.464071368832004

Epoch: 6| Step: 10
Training loss: 2.540896366730856
Validation loss: 2.4679482163888955

Epoch: 6| Step: 11
Training loss: 2.8771964266180627
Validation loss: 2.445217222577353

Epoch: 6| Step: 12
Training loss: 2.7697486092696257
Validation loss: 2.462118000763023

Epoch: 6| Step: 13
Training loss: 2.520874422437328
Validation loss: 2.4485298626248655

Epoch: 182| Step: 0
Training loss: 2.806078382652096
Validation loss: 2.448549665733514

Epoch: 6| Step: 1
Training loss: 2.5828963084392154
Validation loss: 2.450212394342785

Epoch: 6| Step: 2
Training loss: 2.0652195889005163
Validation loss: 2.4650825943941976

Epoch: 6| Step: 3
Training loss: 2.3271422904346006
Validation loss: 2.4699530577137794

Epoch: 6| Step: 4
Training loss: 2.4375491015061455
Validation loss: 2.441588288114237

Epoch: 6| Step: 5
Training loss: 2.413977760383163
Validation loss: 2.446794321104735

Epoch: 6| Step: 6
Training loss: 2.3101919873865904
Validation loss: 2.458424874282597

Epoch: 6| Step: 7
Training loss: 3.1416514982334593
Validation loss: 2.4576838765026845

Epoch: 6| Step: 8
Training loss: 2.2259456382344562
Validation loss: 2.442253677271124

Epoch: 6| Step: 9
Training loss: 2.4540932074942337
Validation loss: 2.445798294964639

Epoch: 6| Step: 10
Training loss: 2.5630615363441653
Validation loss: 2.4685824965525356

Epoch: 6| Step: 11
Training loss: 2.4647718802975493
Validation loss: 2.470971824869187

Epoch: 6| Step: 12
Training loss: 3.3231536557502968
Validation loss: 2.452474510092436

Epoch: 6| Step: 13
Training loss: 1.8832320383001018
Validation loss: 2.483889224192159

Epoch: 183| Step: 0
Training loss: 2.191756439787806
Validation loss: 2.449070203691971

Epoch: 6| Step: 1
Training loss: 2.31510016173169
Validation loss: 2.4622986711164856

Epoch: 6| Step: 2
Training loss: 2.3575853039871477
Validation loss: 2.4593985182407248

Epoch: 6| Step: 3
Training loss: 2.268486793740273
Validation loss: 2.4597159936907107

Epoch: 6| Step: 4
Training loss: 2.926083558053067
Validation loss: 2.451547176265848

Epoch: 6| Step: 5
Training loss: 2.1181320954826153
Validation loss: 2.4750251629526936

Epoch: 6| Step: 6
Training loss: 2.8745183126543403
Validation loss: 2.445203746012885

Epoch: 6| Step: 7
Training loss: 3.0067972426667384
Validation loss: 2.468045978675023

Epoch: 6| Step: 8
Training loss: 3.158242229533339
Validation loss: 2.463472542053888

Epoch: 6| Step: 9
Training loss: 2.388021210504389
Validation loss: 2.47346091761498

Epoch: 6| Step: 10
Training loss: 2.5082018778711275
Validation loss: 2.450362343453613

Epoch: 6| Step: 11
Training loss: 2.3006564820531303
Validation loss: 2.476483463169889

Epoch: 6| Step: 12
Training loss: 2.313474089144942
Validation loss: 2.446749819407975

Epoch: 6| Step: 13
Training loss: 2.4216243491136717
Validation loss: 2.465855023734646

Epoch: 184| Step: 0
Training loss: 2.636723271118809
Validation loss: 2.468418727885252

Epoch: 6| Step: 1
Training loss: 2.5561627436064702
Validation loss: 2.443471070093251

Epoch: 6| Step: 2
Training loss: 2.7814584718217077
Validation loss: 2.453348258707855

Epoch: 6| Step: 3
Training loss: 2.3938542913521488
Validation loss: 2.4648662796422274

Epoch: 6| Step: 4
Training loss: 2.1276901271330866
Validation loss: 2.45185487052488

Epoch: 6| Step: 5
Training loss: 2.6899739788172425
Validation loss: 2.4781867703769125

Epoch: 6| Step: 6
Training loss: 2.654625609127168
Validation loss: 2.461746808312292

Epoch: 6| Step: 7
Training loss: 2.1885336477383013
Validation loss: 2.464586534599375

Epoch: 6| Step: 8
Training loss: 2.0124942803153507
Validation loss: 2.4689710712011257

Epoch: 6| Step: 9
Training loss: 3.3549457537704224
Validation loss: 2.4598376057034717

Epoch: 6| Step: 10
Training loss: 2.357574179848594
Validation loss: 2.4806590229411865

Epoch: 6| Step: 11
Training loss: 2.132703729447979
Validation loss: 2.4444916344758414

Epoch: 6| Step: 12
Training loss: 3.0716821464470034
Validation loss: 2.4683768521426783

Epoch: 6| Step: 13
Training loss: 1.7613186603967819
Validation loss: 2.4541213859379454

Epoch: 185| Step: 0
Training loss: 2.1682121071536486
Validation loss: 2.429173744197119

Epoch: 6| Step: 1
Training loss: 2.7232999765819357
Validation loss: 2.4638441633267303

Epoch: 6| Step: 2
Training loss: 2.714470839102961
Validation loss: 2.4547341401950753

Epoch: 6| Step: 3
Training loss: 2.7457023330798047
Validation loss: 2.4691984559309565

Epoch: 6| Step: 4
Training loss: 2.656396121325574
Validation loss: 2.452722576390426

Epoch: 6| Step: 5
Training loss: 2.8502140567100187
Validation loss: 2.465671512447807

Epoch: 6| Step: 6
Training loss: 2.6004228358131125
Validation loss: 2.4753461046168654

Epoch: 6| Step: 7
Training loss: 2.560635144002019
Validation loss: 2.4754285301142684

Epoch: 6| Step: 8
Training loss: 2.095817342384971
Validation loss: 2.470529751991553

Epoch: 6| Step: 9
Training loss: 1.9582772618917217
Validation loss: 2.4639348270479937

Epoch: 6| Step: 10
Training loss: 2.9059193740970244
Validation loss: 2.491029396040869

Epoch: 6| Step: 11
Training loss: 2.1486525549327067
Validation loss: 2.4724723186212683

Epoch: 6| Step: 12
Training loss: 2.5101925972836754
Validation loss: 2.465665889564022

Epoch: 6| Step: 13
Training loss: 2.789172087581379
Validation loss: 2.4808864235073735

Epoch: 186| Step: 0
Training loss: 2.494977101314556
Validation loss: 2.4754158580509364

Epoch: 6| Step: 1
Training loss: 2.67132705513077
Validation loss: 2.4793448852472753

Epoch: 6| Step: 2
Training loss: 2.1626523928886585
Validation loss: 2.4650205212685936

Epoch: 6| Step: 3
Training loss: 2.4603095328197906
Validation loss: 2.4552433734516708

Epoch: 6| Step: 4
Training loss: 2.513421367027662
Validation loss: 2.4643667464917414

Epoch: 6| Step: 5
Training loss: 2.9727770345964926
Validation loss: 2.4606073171361387

Epoch: 6| Step: 6
Training loss: 2.6815104609251073
Validation loss: 2.4795353354157985

Epoch: 6| Step: 7
Training loss: 2.3371760424350834
Validation loss: 2.4702017625016093

Epoch: 6| Step: 8
Training loss: 1.655314271136275
Validation loss: 2.4845383298192405

Epoch: 6| Step: 9
Training loss: 2.8767976531098736
Validation loss: 2.4484422470764926

Epoch: 6| Step: 10
Training loss: 2.936427468449684
Validation loss: 2.4677025522708287

Epoch: 6| Step: 11
Training loss: 2.5309881380994645
Validation loss: 2.471957070566045

Epoch: 6| Step: 12
Training loss: 2.2176985062404895
Validation loss: 2.4702299362145865

Epoch: 6| Step: 13
Training loss: 2.8288344025673253
Validation loss: 2.474384811420001

Epoch: 187| Step: 0
Training loss: 2.4600119167132286
Validation loss: 2.475115458543518

Epoch: 6| Step: 1
Training loss: 2.2441979941263694
Validation loss: 2.4846332147822907

Epoch: 6| Step: 2
Training loss: 2.732867452026435
Validation loss: 2.4666312739264544

Epoch: 6| Step: 3
Training loss: 2.1760247195326365
Validation loss: 2.4740006651870043

Epoch: 6| Step: 4
Training loss: 2.566138498863442
Validation loss: 2.4664400383500973

Epoch: 6| Step: 5
Training loss: 2.562751571587808
Validation loss: 2.4555641036805977

Epoch: 6| Step: 6
Training loss: 2.337827396414202
Validation loss: 2.477991868294619

Epoch: 6| Step: 7
Training loss: 2.159044969790947
Validation loss: 2.4631627822193374

Epoch: 6| Step: 8
Training loss: 2.657867029203677
Validation loss: 2.458347940653567

Epoch: 6| Step: 9
Training loss: 2.669506785811227
Validation loss: 2.468131494517679

Epoch: 6| Step: 10
Training loss: 3.269958541094005
Validation loss: 2.4553143724888273

Epoch: 6| Step: 11
Training loss: 2.452225052317661
Validation loss: 2.462298790849591

Epoch: 6| Step: 12
Training loss: 2.5117683939677447
Validation loss: 2.463139257080675

Epoch: 6| Step: 13
Training loss: 2.2043293576210696
Validation loss: 2.4577521425700524

Epoch: 188| Step: 0
Training loss: 2.6814041200105536
Validation loss: 2.4460947745363715

Epoch: 6| Step: 1
Training loss: 2.035828814236714
Validation loss: 2.459421458947385

Epoch: 6| Step: 2
Training loss: 2.673228049531777
Validation loss: 2.4722494647961697

Epoch: 6| Step: 3
Training loss: 2.625314602845917
Validation loss: 2.4451622873404837

Epoch: 6| Step: 4
Training loss: 2.4874744394800623
Validation loss: 2.4645887075573345

Epoch: 6| Step: 5
Training loss: 2.842827615906347
Validation loss: 2.4543646407940947

Epoch: 6| Step: 6
Training loss: 2.4946171985589674
Validation loss: 2.4652397690883303

Epoch: 6| Step: 7
Training loss: 2.3987456381610537
Validation loss: 2.4669170852278244

Epoch: 6| Step: 8
Training loss: 2.820585200685952
Validation loss: 2.4675139072438266

Epoch: 6| Step: 9
Training loss: 2.7345601918314073
Validation loss: 2.4447434254708247

Epoch: 6| Step: 10
Training loss: 2.372538646387256
Validation loss: 2.483022924402064

Epoch: 6| Step: 11
Training loss: 2.211725532631831
Validation loss: 2.478953782459543

Epoch: 6| Step: 12
Training loss: 2.252939423472678
Validation loss: 2.4498284803267256

Epoch: 6| Step: 13
Training loss: 2.3981468198497904
Validation loss: 2.4812871909377074

Epoch: 189| Step: 0
Training loss: 2.9478645095434723
Validation loss: 2.4679977290587027

Epoch: 6| Step: 1
Training loss: 2.2248166383776113
Validation loss: 2.450850899479252

Epoch: 6| Step: 2
Training loss: 2.067097020205482
Validation loss: 2.4643936215552675

Epoch: 6| Step: 3
Training loss: 2.2315188205890326
Validation loss: 2.45044543042937

Epoch: 6| Step: 4
Training loss: 2.5783289973151207
Validation loss: 2.4803831018982123

Epoch: 6| Step: 5
Training loss: 2.6874017919294966
Validation loss: 2.4897996668857263

Epoch: 6| Step: 6
Training loss: 2.000170223621458
Validation loss: 2.453361322711213

Epoch: 6| Step: 7
Training loss: 2.64689767010381
Validation loss: 2.4665761473170518

Epoch: 6| Step: 8
Training loss: 2.798175871529131
Validation loss: 2.4644257527591584

Epoch: 6| Step: 9
Training loss: 2.5021030163738502
Validation loss: 2.4416236966336378

Epoch: 6| Step: 10
Training loss: 2.331436362500623
Validation loss: 2.454168823020898

Epoch: 6| Step: 11
Training loss: 2.4438731677146195
Validation loss: 2.466549373466481

Epoch: 6| Step: 12
Training loss: 2.5796312036038107
Validation loss: 2.4706244600175578

Epoch: 6| Step: 13
Training loss: 3.2761875882220504
Validation loss: 2.446320147226072

Epoch: 190| Step: 0
Training loss: 3.2668098599975104
Validation loss: 2.4352970407144765

Epoch: 6| Step: 1
Training loss: 2.764572029311051
Validation loss: 2.4500105769933835

Epoch: 6| Step: 2
Training loss: 2.067455234619546
Validation loss: 2.466094733853162

Epoch: 6| Step: 3
Training loss: 2.4797143945515465
Validation loss: 2.4847055902604267

Epoch: 6| Step: 4
Training loss: 2.069573497232997
Validation loss: 2.475105337016691

Epoch: 6| Step: 5
Training loss: 2.1550238619941453
Validation loss: 2.46926756594939

Epoch: 6| Step: 6
Training loss: 2.345783419668096
Validation loss: 2.464963392976673

Epoch: 6| Step: 7
Training loss: 2.5052844463584423
Validation loss: 2.472201111598036

Epoch: 6| Step: 8
Training loss: 2.493607263137035
Validation loss: 2.4594480477175247

Epoch: 6| Step: 9
Training loss: 2.3975281622448827
Validation loss: 2.4891528035646777

Epoch: 6| Step: 10
Training loss: 2.7135856951889834
Validation loss: 2.455962626403697

Epoch: 6| Step: 11
Training loss: 2.5907201880624764
Validation loss: 2.4748446116098575

Epoch: 6| Step: 12
Training loss: 2.11636359029917
Validation loss: 2.4846077679233467

Epoch: 6| Step: 13
Training loss: 3.1836812200407008
Validation loss: 2.4850720344665786

Epoch: 191| Step: 0
Training loss: 2.1962189347268932
Validation loss: 2.4782354991920004

Epoch: 6| Step: 1
Training loss: 2.2877050547594684
Validation loss: 2.48105973927452

Epoch: 6| Step: 2
Training loss: 2.487314464608287
Validation loss: 2.4910867405972517

Epoch: 6| Step: 3
Training loss: 2.8424352603944545
Validation loss: 2.500785513495565

Epoch: 6| Step: 4
Training loss: 2.623090049178147
Validation loss: 2.50346213385524

Epoch: 6| Step: 5
Training loss: 2.5053723784499
Validation loss: 2.4845770471684134

Epoch: 6| Step: 6
Training loss: 2.16438153390672
Validation loss: 2.495669684638847

Epoch: 6| Step: 7
Training loss: 2.1740372686551876
Validation loss: 2.4686098465259962

Epoch: 6| Step: 8
Training loss: 2.2518414273645826
Validation loss: 2.4820743205603653

Epoch: 6| Step: 9
Training loss: 2.59643094412571
Validation loss: 2.484612645795566

Epoch: 6| Step: 10
Training loss: 2.538561868463298
Validation loss: 2.4754638864435647

Epoch: 6| Step: 11
Training loss: 2.114284538117748
Validation loss: 2.470678876837041

Epoch: 6| Step: 12
Training loss: 3.6267724801035595
Validation loss: 2.465234143139959

Epoch: 6| Step: 13
Training loss: 2.3221439621660345
Validation loss: 2.4813808333621057

Epoch: 192| Step: 0
Training loss: 2.270497941846824
Validation loss: 2.4803264028981173

Epoch: 6| Step: 1
Training loss: 2.438003879209191
Validation loss: 2.454051312947886

Epoch: 6| Step: 2
Training loss: 2.262297613881607
Validation loss: 2.431493163049286

Epoch: 6| Step: 3
Training loss: 2.657591088529111
Validation loss: 2.464860331978136

Epoch: 6| Step: 4
Training loss: 2.32670621716277
Validation loss: 2.462074787096037

Epoch: 6| Step: 5
Training loss: 2.3488541021009675
Validation loss: 2.467694251106276

Epoch: 6| Step: 6
Training loss: 2.852240160542349
Validation loss: 2.490533368834235

Epoch: 6| Step: 7
Training loss: 2.0691546963383742
Validation loss: 2.4632337486546523

Epoch: 6| Step: 8
Training loss: 3.339918561844863
Validation loss: 2.4547366811360005

Epoch: 6| Step: 9
Training loss: 2.3572327443938743
Validation loss: 2.4489629104563178

Epoch: 6| Step: 10
Training loss: 2.192928445117458
Validation loss: 2.46513235701332

Epoch: 6| Step: 11
Training loss: 2.802581336332459
Validation loss: 2.4524451607610978

Epoch: 6| Step: 12
Training loss: 2.033104387537088
Validation loss: 2.473527564135138

Epoch: 6| Step: 13
Training loss: 3.357393895998529
Validation loss: 2.4832137459850157

Epoch: 193| Step: 0
Training loss: 1.6869887531224448
Validation loss: 2.4682800813554233

Epoch: 6| Step: 1
Training loss: 2.4729840632325057
Validation loss: 2.454348902913645

Epoch: 6| Step: 2
Training loss: 3.3222928951518944
Validation loss: 2.4463342443157368

Epoch: 6| Step: 3
Training loss: 2.2827861264772618
Validation loss: 2.4680156661844554

Epoch: 6| Step: 4
Training loss: 2.9629873462397796
Validation loss: 2.4436933234928464

Epoch: 6| Step: 5
Training loss: 2.6437411910106454
Validation loss: 2.4611266376495995

Epoch: 6| Step: 6
Training loss: 2.2564207229060287
Validation loss: 2.4876526262465033

Epoch: 6| Step: 7
Training loss: 2.4094365805983133
Validation loss: 2.4763379862003405

Epoch: 6| Step: 8
Training loss: 2.4716572121842133
Validation loss: 2.4897367602022316

Epoch: 6| Step: 9
Training loss: 2.9437552871170674
Validation loss: 2.4731994166067888

Epoch: 6| Step: 10
Training loss: 2.5199299814699674
Validation loss: 2.4832970242496613

Epoch: 6| Step: 11
Training loss: 2.420920005292944
Validation loss: 2.4967215411948964

Epoch: 6| Step: 12
Training loss: 2.3051858654096575
Validation loss: 2.4761072078482225

Epoch: 6| Step: 13
Training loss: 1.8689577019131618
Validation loss: 2.4596242541184394

Epoch: 194| Step: 0
Training loss: 2.1721572143743972
Validation loss: 2.487057544564372

Epoch: 6| Step: 1
Training loss: 2.2406161979810983
Validation loss: 2.4578838580566953

Epoch: 6| Step: 2
Training loss: 1.9382656184422964
Validation loss: 2.483765873965022

Epoch: 6| Step: 3
Training loss: 2.075911411372415
Validation loss: 2.490246342648939

Epoch: 6| Step: 4
Training loss: 2.402931402020237
Validation loss: 2.4658090289302543

Epoch: 6| Step: 5
Training loss: 2.7050379340425845
Validation loss: 2.4858086163785376

Epoch: 6| Step: 6
Training loss: 2.4634677050552334
Validation loss: 2.47518683319073

Epoch: 6| Step: 7
Training loss: 2.713437645224726
Validation loss: 2.5008474513339816

Epoch: 6| Step: 8
Training loss: 2.1392011153099104
Validation loss: 2.474754863460135

Epoch: 6| Step: 9
Training loss: 2.756071151501476
Validation loss: 2.46877658072145

Epoch: 6| Step: 10
Training loss: 3.12950480971094
Validation loss: 2.483439134496883

Epoch: 6| Step: 11
Training loss: 2.830706182466679
Validation loss: 2.4777956772329146

Epoch: 6| Step: 12
Training loss: 2.8275316153326324
Validation loss: 2.4604763960437657

Epoch: 6| Step: 13
Training loss: 2.2416218432893107
Validation loss: 2.4597387698890905

Epoch: 195| Step: 0
Training loss: 2.6914361916082155
Validation loss: 2.481496398921383

Epoch: 6| Step: 1
Training loss: 2.1589397295357324
Validation loss: 2.4703764640222787

Epoch: 6| Step: 2
Training loss: 2.7234123854756747
Validation loss: 2.4612909899456032

Epoch: 6| Step: 3
Training loss: 3.202620005923861
Validation loss: 2.4670490019161213

Epoch: 6| Step: 4
Training loss: 2.8738430846720533
Validation loss: 2.4531952588149464

Epoch: 6| Step: 5
Training loss: 1.955530013413708
Validation loss: 2.4689843142015633

Epoch: 6| Step: 6
Training loss: 2.1711287279801477
Validation loss: 2.4991918236855586

Epoch: 6| Step: 7
Training loss: 2.3333287806693574
Validation loss: 2.4604705659255846

Epoch: 6| Step: 8
Training loss: 2.61833388998931
Validation loss: 2.4858480420366584

Epoch: 6| Step: 9
Training loss: 2.320213957983516
Validation loss: 2.49268311988223

Epoch: 6| Step: 10
Training loss: 3.0107705371374487
Validation loss: 2.468935434987074

Epoch: 6| Step: 11
Training loss: 2.1501701997324263
Validation loss: 2.4772652227860457

Epoch: 6| Step: 12
Training loss: 1.9255562857873325
Validation loss: 2.4661521041365395

Epoch: 6| Step: 13
Training loss: 2.2780610880108614
Validation loss: 2.4688232398549808

Epoch: 196| Step: 0
Training loss: 1.9832958380844032
Validation loss: 2.4934069758785737

Epoch: 6| Step: 1
Training loss: 2.6025855999591534
Validation loss: 2.464024718557019

Epoch: 6| Step: 2
Training loss: 2.5534807907466543
Validation loss: 2.4679136384738958

Epoch: 6| Step: 3
Training loss: 2.3973019176195582
Validation loss: 2.4680758482984633

Epoch: 6| Step: 4
Training loss: 2.1418509209879235
Validation loss: 2.4776892492215445

Epoch: 6| Step: 5
Training loss: 3.0545941506876226
Validation loss: 2.463435748156795

Epoch: 6| Step: 6
Training loss: 2.293162660993897
Validation loss: 2.455628599863395

Epoch: 6| Step: 7
Training loss: 2.0762381341217337
Validation loss: 2.494041429913227

Epoch: 6| Step: 8
Training loss: 2.893438670999348
Validation loss: 2.4684394172725495

Epoch: 6| Step: 9
Training loss: 2.3030787138512707
Validation loss: 2.461689985205384

Epoch: 6| Step: 10
Training loss: 2.844615930199407
Validation loss: 2.4783861164309333

Epoch: 6| Step: 11
Training loss: 2.763484147776094
Validation loss: 2.4829996029151573

Epoch: 6| Step: 12
Training loss: 2.0216523179029626
Validation loss: 2.4596787121018098

Epoch: 6| Step: 13
Training loss: 2.8048496890126042
Validation loss: 2.4712258579035673

Epoch: 197| Step: 0
Training loss: 2.742198802783419
Validation loss: 2.4718716689217346

Epoch: 6| Step: 1
Training loss: 2.685848793397967
Validation loss: 2.4790434261666676

Epoch: 6| Step: 2
Training loss: 2.153233726646363
Validation loss: 2.4705596699301577

Epoch: 6| Step: 3
Training loss: 3.1617803184447353
Validation loss: 2.4560720897449393

Epoch: 6| Step: 4
Training loss: 2.1678743908941827
Validation loss: 2.489316878594411

Epoch: 6| Step: 5
Training loss: 2.410811225516358
Validation loss: 2.48275918307475

Epoch: 6| Step: 6
Training loss: 2.310202204453945
Validation loss: 2.466422141736387

Epoch: 6| Step: 7
Training loss: 2.4579457338456
Validation loss: 2.4689391273879178

Epoch: 6| Step: 8
Training loss: 2.963945054063638
Validation loss: 2.45638454719717

Epoch: 6| Step: 9
Training loss: 1.8772864070648332
Validation loss: 2.484499269291192

Epoch: 6| Step: 10
Training loss: 2.222879569528552
Validation loss: 2.4856086753816937

Epoch: 6| Step: 11
Training loss: 2.6002382682782836
Validation loss: 2.476408599919297

Epoch: 6| Step: 12
Training loss: 2.2768897623174675
Validation loss: 2.4843698807107235

Epoch: 6| Step: 13
Training loss: 2.58765283031893
Validation loss: 2.449438657611405

Epoch: 198| Step: 0
Training loss: 1.8759901611216525
Validation loss: 2.4468777283040772

Epoch: 6| Step: 1
Training loss: 2.4726161381027687
Validation loss: 2.477257759312234

Epoch: 6| Step: 2
Training loss: 2.7077169059172954
Validation loss: 2.473711733139641

Epoch: 6| Step: 3
Training loss: 2.2089294372796555
Validation loss: 2.4714678114911215

Epoch: 6| Step: 4
Training loss: 2.729230826596789
Validation loss: 2.480348166074262

Epoch: 6| Step: 5
Training loss: 3.049986048181861
Validation loss: 2.467435118766261

Epoch: 6| Step: 6
Training loss: 1.9494613465916317
Validation loss: 2.4482039447757384

Epoch: 6| Step: 7
Training loss: 2.2923004892242966
Validation loss: 2.4805404305204126

Epoch: 6| Step: 8
Training loss: 2.73162598978991
Validation loss: 2.464189436234362

Epoch: 6| Step: 9
Training loss: 2.6986302398075237
Validation loss: 2.4683646995279376

Epoch: 6| Step: 10
Training loss: 3.0051327348232473
Validation loss: 2.4789943316331144

Epoch: 6| Step: 11
Training loss: 2.7178246688263314
Validation loss: 2.44873927914348

Epoch: 6| Step: 12
Training loss: 2.0981226567723175
Validation loss: 2.471309835784391

Epoch: 6| Step: 13
Training loss: 1.4362690672509348
Validation loss: 2.469777673338345

Epoch: 199| Step: 0
Training loss: 2.0019675351996615
Validation loss: 2.461364476746628

Epoch: 6| Step: 1
Training loss: 2.4505448105409617
Validation loss: 2.4709977602326094

Epoch: 6| Step: 2
Training loss: 2.5022108792446343
Validation loss: 2.4628678165353657

Epoch: 6| Step: 3
Training loss: 2.550884624448651
Validation loss: 2.4613280502570785

Epoch: 6| Step: 4
Training loss: 2.5008934331898995
Validation loss: 2.473240053904818

Epoch: 6| Step: 5
Training loss: 3.1352906735136816
Validation loss: 2.4659672478728245

Epoch: 6| Step: 6
Training loss: 2.094091359110269
Validation loss: 2.4839819573177513

Epoch: 6| Step: 7
Training loss: 2.163774161289304
Validation loss: 2.478880397731025

Epoch: 6| Step: 8
Training loss: 2.5762553516019553
Validation loss: 2.4755168713175735

Epoch: 6| Step: 9
Training loss: 2.4156417865836124
Validation loss: 2.466500379477639

Epoch: 6| Step: 10
Training loss: 2.171525446803072
Validation loss: 2.44810335961133

Epoch: 6| Step: 11
Training loss: 2.730189929964657
Validation loss: 2.4824691368687515

Epoch: 6| Step: 12
Training loss: 2.2807928175899757
Validation loss: 2.4711584480080417

Epoch: 6| Step: 13
Training loss: 3.1215955882238267
Validation loss: 2.4618724614099077

Epoch: 200| Step: 0
Training loss: 2.643335520040691
Validation loss: 2.483526335530259

Epoch: 6| Step: 1
Training loss: 2.621174249677818
Validation loss: 2.468963952306238

Epoch: 6| Step: 2
Training loss: 2.5957464784283997
Validation loss: 2.4633813076661477

Epoch: 6| Step: 3
Training loss: 2.2770682899511008
Validation loss: 2.472062004162175

Epoch: 6| Step: 4
Training loss: 2.276088571537988
Validation loss: 2.477247521836019

Epoch: 6| Step: 5
Training loss: 2.208254422871235
Validation loss: 2.48203250271796

Epoch: 6| Step: 6
Training loss: 3.087129850246062
Validation loss: 2.4766436335462134

Epoch: 6| Step: 7
Training loss: 2.1067241825428966
Validation loss: 2.480683586926808

Epoch: 6| Step: 8
Training loss: 2.6269389666207674
Validation loss: 2.471697419507636

Epoch: 6| Step: 9
Training loss: 2.695082325713002
Validation loss: 2.4832142043653462

Epoch: 6| Step: 10
Training loss: 2.341008732182619
Validation loss: 2.476669722749108

Epoch: 6| Step: 11
Training loss: 2.4208067476144506
Validation loss: 2.4722980617679804

Epoch: 6| Step: 12
Training loss: 2.3398492523281504
Validation loss: 2.4873294022981898

Epoch: 6| Step: 13
Training loss: 2.357216763679505
Validation loss: 2.4601712358372394

Epoch: 201| Step: 0
Training loss: 2.7919739985799183
Validation loss: 2.470553272130098

Epoch: 6| Step: 1
Training loss: 2.3996260987533784
Validation loss: 2.4807334354959303

Epoch: 6| Step: 2
Training loss: 2.307396902837507
Validation loss: 2.4717289024276927

Epoch: 6| Step: 3
Training loss: 2.8561964034179197
Validation loss: 2.4706274266538455

Epoch: 6| Step: 4
Training loss: 2.4881443243514814
Validation loss: 2.4769332710161267

Epoch: 6| Step: 5
Training loss: 2.278597818504541
Validation loss: 2.4535463283650194

Epoch: 6| Step: 6
Training loss: 2.461622742209573
Validation loss: 2.4626053999056845

Epoch: 6| Step: 7
Training loss: 1.9587061980218134
Validation loss: 2.4758668155786143

Epoch: 6| Step: 8
Training loss: 3.2604662289168442
Validation loss: 2.4860789380818273

Epoch: 6| Step: 9
Training loss: 2.127619755352036
Validation loss: 2.4412579875596294

Epoch: 6| Step: 10
Training loss: 2.3762553059750977
Validation loss: 2.4679021650267714

Epoch: 6| Step: 11
Training loss: 2.1169648563673613
Validation loss: 2.4738566505420443

Epoch: 6| Step: 12
Training loss: 2.869542124307261
Validation loss: 2.456399806564174

Epoch: 6| Step: 13
Training loss: 1.8721110658383686
Validation loss: 2.464012862849931

Epoch: 202| Step: 0
Training loss: 2.1699876886888734
Validation loss: 2.4775698669011974

Epoch: 6| Step: 1
Training loss: 1.754141810853452
Validation loss: 2.4756130687474998

Epoch: 6| Step: 2
Training loss: 2.7889148662399204
Validation loss: 2.4775996465393266

Epoch: 6| Step: 3
Training loss: 2.4992211082187414
Validation loss: 2.473922956350821

Epoch: 6| Step: 4
Training loss: 2.858009053807904
Validation loss: 2.46019335237266

Epoch: 6| Step: 5
Training loss: 1.9978222315178467
Validation loss: 2.452651317316556

Epoch: 6| Step: 6
Training loss: 1.8497390459924457
Validation loss: 2.445767430540212

Epoch: 6| Step: 7
Training loss: 2.2644439776046483
Validation loss: 2.467433868860866

Epoch: 6| Step: 8
Training loss: 3.1820239731265003
Validation loss: 2.4536216927440675

Epoch: 6| Step: 9
Training loss: 2.5560440987855673
Validation loss: 2.4603073018984305

Epoch: 6| Step: 10
Training loss: 2.7805179961372777
Validation loss: 2.475774401855814

Epoch: 6| Step: 11
Training loss: 2.7807038874720633
Validation loss: 2.438335195680618

Epoch: 6| Step: 12
Training loss: 2.227334193299824
Validation loss: 2.458215651937772

Epoch: 6| Step: 13
Training loss: 2.621945829650999
Validation loss: 2.471013613060922

Epoch: 203| Step: 0
Training loss: 2.032186556362289
Validation loss: 2.4978226624536646

Epoch: 6| Step: 1
Training loss: 2.313412872764619
Validation loss: 2.465394755277515

Epoch: 6| Step: 2
Training loss: 2.388277584293985
Validation loss: 2.472299934492514

Epoch: 6| Step: 3
Training loss: 2.080842270878409
Validation loss: 2.480086308469172

Epoch: 6| Step: 4
Training loss: 3.346797659414008
Validation loss: 2.4849379552991966

Epoch: 6| Step: 5
Training loss: 2.7774414388696114
Validation loss: 2.482875509469355

Epoch: 6| Step: 6
Training loss: 2.366946570092749
Validation loss: 2.4839025538244335

Epoch: 6| Step: 7
Training loss: 2.231603757879933
Validation loss: 2.485761262272574

Epoch: 6| Step: 8
Training loss: 2.2776847047579545
Validation loss: 2.4632237479501367

Epoch: 6| Step: 9
Training loss: 2.6409297970357133
Validation loss: 2.4760175178884616

Epoch: 6| Step: 10
Training loss: 2.459890960509765
Validation loss: 2.4903678792305506

Epoch: 6| Step: 11
Training loss: 2.0761582095108237
Validation loss: 2.480134690378685

Epoch: 6| Step: 12
Training loss: 3.0323404140260446
Validation loss: 2.4883114134921565

Epoch: 6| Step: 13
Training loss: 2.466573600903552
Validation loss: 2.479808224559774

Epoch: 204| Step: 0
Training loss: 2.38803738443067
Validation loss: 2.4727821708777404

Epoch: 6| Step: 1
Training loss: 2.7730253531242415
Validation loss: 2.5008652328073575

Epoch: 6| Step: 2
Training loss: 2.363022164259002
Validation loss: 2.470807501758124

Epoch: 6| Step: 3
Training loss: 2.9076470739504874
Validation loss: 2.4927016373495428

Epoch: 6| Step: 4
Training loss: 2.476932726602945
Validation loss: 2.475715929093179

Epoch: 6| Step: 5
Training loss: 1.9278636143116978
Validation loss: 2.475813369124035

Epoch: 6| Step: 6
Training loss: 2.7150204388321586
Validation loss: 2.4716313024106342

Epoch: 6| Step: 7
Training loss: 2.3136027001018253
Validation loss: 2.4840434740574824

Epoch: 6| Step: 8
Training loss: 1.9420425324108819
Validation loss: 2.4813639867476946

Epoch: 6| Step: 9
Training loss: 2.796762815814885
Validation loss: 2.468767218259096

Epoch: 6| Step: 10
Training loss: 2.4197787164764977
Validation loss: 2.4762060979636087

Epoch: 6| Step: 11
Training loss: 2.4029543217045317
Validation loss: 2.470342268785857

Epoch: 6| Step: 12
Training loss: 2.479823231242346
Validation loss: 2.4597614249777324

Epoch: 6| Step: 13
Training loss: 2.7204508229714977
Validation loss: 2.4786242247249723

Epoch: 205| Step: 0
Training loss: 2.241024340339511
Validation loss: 2.471693776864133

Epoch: 6| Step: 1
Training loss: 2.3197888126935275
Validation loss: 2.4398510902882284

Epoch: 6| Step: 2
Training loss: 2.2324746326743936
Validation loss: 2.4552187564645016

Epoch: 6| Step: 3
Training loss: 2.953769835455147
Validation loss: 2.4837013466915243

Epoch: 6| Step: 4
Training loss: 2.2951205033723174
Validation loss: 2.470392886409231

Epoch: 6| Step: 5
Training loss: 2.9850680360436628
Validation loss: 2.472996720803785

Epoch: 6| Step: 6
Training loss: 2.1818073861259633
Validation loss: 2.4720153231949142

Epoch: 6| Step: 7
Training loss: 2.5926080970704226
Validation loss: 2.4911203279364647

Epoch: 6| Step: 8
Training loss: 2.7030191566163855
Validation loss: 2.4650788192579594

Epoch: 6| Step: 9
Training loss: 2.4629028223206095
Validation loss: 2.486649214075664

Epoch: 6| Step: 10
Training loss: 2.612982169743409
Validation loss: 2.4573205826136713

Epoch: 6| Step: 11
Training loss: 2.492430863411605
Validation loss: 2.453270673688416

Epoch: 6| Step: 12
Training loss: 2.4506490081334933
Validation loss: 2.462157339825919

Epoch: 6| Step: 13
Training loss: 1.604728138083134
Validation loss: 2.493402084879799

Epoch: 206| Step: 0
Training loss: 2.575705300189933
Validation loss: 2.4563003878046343

Epoch: 6| Step: 1
Training loss: 2.682069659381702
Validation loss: 2.4730257593703375

Epoch: 6| Step: 2
Training loss: 3.0211939804698
Validation loss: 2.452060769330563

Epoch: 6| Step: 3
Training loss: 2.736154293444615
Validation loss: 2.4797889605438392

Epoch: 6| Step: 4
Training loss: 2.5085193434105006
Validation loss: 2.4801068720976946

Epoch: 6| Step: 5
Training loss: 2.770096606831906
Validation loss: 2.454001971236423

Epoch: 6| Step: 6
Training loss: 1.8900577545424324
Validation loss: 2.4685109880667646

Epoch: 6| Step: 7
Training loss: 1.8500814187975105
Validation loss: 2.50260094837525

Epoch: 6| Step: 8
Training loss: 2.476212052541218
Validation loss: 2.4491094346433986

Epoch: 6| Step: 9
Training loss: 2.1809334424133207
Validation loss: 2.465524747653264

Epoch: 6| Step: 10
Training loss: 2.490201439733183
Validation loss: 2.473964271387164

Epoch: 6| Step: 11
Training loss: 2.3300386283193784
Validation loss: 2.469986316948071

Epoch: 6| Step: 12
Training loss: 2.1690003835942453
Validation loss: 2.449500884881737

Epoch: 6| Step: 13
Training loss: 2.7045294139727343
Validation loss: 2.483069730878011

Epoch: 207| Step: 0
Training loss: 3.0333879934004253
Validation loss: 2.4866604288540857

Epoch: 6| Step: 1
Training loss: 2.3437250771786866
Validation loss: 2.479183723995616

Epoch: 6| Step: 2
Training loss: 2.5764474670751865
Validation loss: 2.4828376917790815

Epoch: 6| Step: 3
Training loss: 2.2702034826286086
Validation loss: 2.470915496115275

Epoch: 6| Step: 4
Training loss: 2.763091915461477
Validation loss: 2.4764351284586685

Epoch: 6| Step: 5
Training loss: 2.562974653245941
Validation loss: 2.4814608527021136

Epoch: 6| Step: 6
Training loss: 2.8149162086225874
Validation loss: 2.471387547949016

Epoch: 6| Step: 7
Training loss: 1.9398326982543614
Validation loss: 2.4726279349333073

Epoch: 6| Step: 8
Training loss: 1.8208188511020096
Validation loss: 2.467876151423778

Epoch: 6| Step: 9
Training loss: 2.1921703074209997
Validation loss: 2.4602707878573926

Epoch: 6| Step: 10
Training loss: 3.0372863129226855
Validation loss: 2.4796364558782096

Epoch: 6| Step: 11
Training loss: 2.050787644149258
Validation loss: 2.440401775890187

Epoch: 6| Step: 12
Training loss: 2.1600054779689697
Validation loss: 2.4728201392403815

Epoch: 6| Step: 13
Training loss: 2.6618026142439724
Validation loss: 2.4933207172814704

Epoch: 208| Step: 0
Training loss: 2.6695190215060953
Validation loss: 2.4648480247350113

Epoch: 6| Step: 1
Training loss: 2.3803131503364323
Validation loss: 2.4524203714274737

Epoch: 6| Step: 2
Training loss: 2.4258875923374394
Validation loss: 2.4572672116415855

Epoch: 6| Step: 3
Training loss: 1.9939439996069914
Validation loss: 2.471992092829179

Epoch: 6| Step: 4
Training loss: 2.5048112349666076
Validation loss: 2.479018309212875

Epoch: 6| Step: 5
Training loss: 2.627666118535471
Validation loss: 2.4691488790858944

Epoch: 6| Step: 6
Training loss: 2.2172482203313963
Validation loss: 2.443895887007721

Epoch: 6| Step: 7
Training loss: 2.502454506444369
Validation loss: 2.459993254262721

Epoch: 6| Step: 8
Training loss: 2.413781208328478
Validation loss: 2.482058922603573

Epoch: 6| Step: 9
Training loss: 2.1582398010175536
Validation loss: 2.4600847956238217

Epoch: 6| Step: 10
Training loss: 2.835527710955611
Validation loss: 2.4695921417279494

Epoch: 6| Step: 11
Training loss: 2.6272021547854623
Validation loss: 2.4572124571215137

Epoch: 6| Step: 12
Training loss: 2.6570734879305977
Validation loss: 2.4484784098107792

Epoch: 6| Step: 13
Training loss: 2.1161922353667135
Validation loss: 2.4657298709443243

Epoch: 209| Step: 0
Training loss: 2.2638758780554764
Validation loss: 2.472754826618949

Epoch: 6| Step: 1
Training loss: 2.287640960185782
Validation loss: 2.468730707847364

Epoch: 6| Step: 2
Training loss: 2.0256803005618207
Validation loss: 2.48014033627738

Epoch: 6| Step: 3
Training loss: 2.2999829913629974
Validation loss: 2.457071446252129

Epoch: 6| Step: 4
Training loss: 2.9321586257991132
Validation loss: 2.4482871201837755

Epoch: 6| Step: 5
Training loss: 2.2923204587562194
Validation loss: 2.4612836311455917

Epoch: 6| Step: 6
Training loss: 3.0549495808987577
Validation loss: 2.4640164741907076

Epoch: 6| Step: 7
Training loss: 2.4882837412296204
Validation loss: 2.464516244773248

Epoch: 6| Step: 8
Training loss: 2.274510710363356
Validation loss: 2.4594776798689426

Epoch: 6| Step: 9
Training loss: 1.717166240307148
Validation loss: 2.4825300818192257

Epoch: 6| Step: 10
Training loss: 2.8608484692890324
Validation loss: 2.4471848971333032

Epoch: 6| Step: 11
Training loss: 1.6422686381671017
Validation loss: 2.4738116998831363

Epoch: 6| Step: 12
Training loss: 2.7393330120025516
Validation loss: 2.4821225402946197

Epoch: 6| Step: 13
Training loss: 3.577915768565303
Validation loss: 2.448962402745143

Epoch: 210| Step: 0
Training loss: 2.273944601546687
Validation loss: 2.4767121279862083

Epoch: 6| Step: 1
Training loss: 2.085654135898631
Validation loss: 2.4756318956360537

Epoch: 6| Step: 2
Training loss: 2.4341905085688826
Validation loss: 2.4523390553437427

Epoch: 6| Step: 3
Training loss: 2.6770016748068994
Validation loss: 2.4656642155891166

Epoch: 6| Step: 4
Training loss: 2.4252498615965976
Validation loss: 2.4833117445360875

Epoch: 6| Step: 5
Training loss: 3.5192464529091274
Validation loss: 2.492653699401056

Epoch: 6| Step: 6
Training loss: 2.4832756441144626
Validation loss: 2.471743171980482

Epoch: 6| Step: 7
Training loss: 2.0888482405492983
Validation loss: 2.501323757615916

Epoch: 6| Step: 8
Training loss: 2.175382128942266
Validation loss: 2.4776363294292034

Epoch: 6| Step: 9
Training loss: 2.0175110029371974
Validation loss: 2.511279879918362

Epoch: 6| Step: 10
Training loss: 2.8185499606655586
Validation loss: 2.479791444797725

Epoch: 6| Step: 11
Training loss: 2.404909231015555
Validation loss: 2.4849854597247845

Epoch: 6| Step: 12
Training loss: 1.581022567375629
Validation loss: 2.503967272126394

Epoch: 6| Step: 13
Training loss: 3.299994994651004
Validation loss: 2.497729135572666

Epoch: 211| Step: 0
Training loss: 1.998782979706246
Validation loss: 2.5018422465945953

Epoch: 6| Step: 1
Training loss: 2.6529629283778022
Validation loss: 2.486237850989068

Epoch: 6| Step: 2
Training loss: 2.6260432032381793
Validation loss: 2.4784460736213725

Epoch: 6| Step: 3
Training loss: 2.8749333249529117
Validation loss: 2.519077184242036

Epoch: 6| Step: 4
Training loss: 1.4663026589176016
Validation loss: 2.5028978902961803

Epoch: 6| Step: 5
Training loss: 3.027832621817492
Validation loss: 2.494526096098431

Epoch: 6| Step: 6
Training loss: 2.276303192639987
Validation loss: 2.4918969802465014

Epoch: 6| Step: 7
Training loss: 2.8009394942819923
Validation loss: 2.5056200589446935

Epoch: 6| Step: 8
Training loss: 2.5501786786477894
Validation loss: 2.482759963703024

Epoch: 6| Step: 9
Training loss: 1.968273286778366
Validation loss: 2.487935506394832

Epoch: 6| Step: 10
Training loss: 2.4567084896438933
Validation loss: 2.464446401290183

Epoch: 6| Step: 11
Training loss: 2.359369341104555
Validation loss: 2.4797976073493673

Epoch: 6| Step: 12
Training loss: 2.853788828842538
Validation loss: 2.476341102315144

Epoch: 6| Step: 13
Training loss: 2.050694403853091
Validation loss: 2.4746617410570635

Epoch: 212| Step: 0
Training loss: 2.395230911368341
Validation loss: 2.465608245947818

Epoch: 6| Step: 1
Training loss: 2.792376347385107
Validation loss: 2.466553872865645

Epoch: 6| Step: 2
Training loss: 2.6477099294165156
Validation loss: 2.486381529994833

Epoch: 6| Step: 3
Training loss: 2.4928222613211086
Validation loss: 2.453448561970286

Epoch: 6| Step: 4
Training loss: 2.345237971677678
Validation loss: 2.452996856162077

Epoch: 6| Step: 5
Training loss: 2.5661600537709695
Validation loss: 2.451712021722465

Epoch: 6| Step: 6
Training loss: 2.7560505628335306
Validation loss: 2.477924541072828

Epoch: 6| Step: 7
Training loss: 2.4671421851356734
Validation loss: 2.476625964383264

Epoch: 6| Step: 8
Training loss: 2.5581451255664667
Validation loss: 2.4660033771241037

Epoch: 6| Step: 9
Training loss: 2.2493891416604903
Validation loss: 2.4605947146065423

Epoch: 6| Step: 10
Training loss: 2.1306904167232985
Validation loss: 2.451015445555079

Epoch: 6| Step: 11
Training loss: 2.4248767585506146
Validation loss: 2.4611549782680497

Epoch: 6| Step: 12
Training loss: 2.4680769763485175
Validation loss: 2.477224020238919

Epoch: 6| Step: 13
Training loss: 1.6851920133358433
Validation loss: 2.447784970279177

Epoch: 213| Step: 0
Training loss: 1.7465085895850219
Validation loss: 2.499751237572588

Epoch: 6| Step: 1
Training loss: 1.7832921685907581
Validation loss: 2.4662097506335434

Epoch: 6| Step: 2
Training loss: 2.2402735393263606
Validation loss: 2.4973385539193815

Epoch: 6| Step: 3
Training loss: 2.7817900058409655
Validation loss: 2.457851214205963

Epoch: 6| Step: 4
Training loss: 2.770214862684303
Validation loss: 2.497395311173948

Epoch: 6| Step: 5
Training loss: 2.7200728081327106
Validation loss: 2.4709119373963606

Epoch: 6| Step: 6
Training loss: 1.897345209052816
Validation loss: 2.4816491580829982

Epoch: 6| Step: 7
Training loss: 2.5756642938406062
Validation loss: 2.467575050139666

Epoch: 6| Step: 8
Training loss: 2.359651258854903
Validation loss: 2.4381531449545757

Epoch: 6| Step: 9
Training loss: 3.2520683749284793
Validation loss: 2.437457544689592

Epoch: 6| Step: 10
Training loss: 2.8418327827413554
Validation loss: 2.498551917355414

Epoch: 6| Step: 11
Training loss: 2.466025092053743
Validation loss: 2.4975728117015934

Epoch: 6| Step: 12
Training loss: 2.0992919681956375
Validation loss: 2.469588097354822

Epoch: 6| Step: 13
Training loss: 2.086086767906566
Validation loss: 2.458593250158617

Epoch: 214| Step: 0
Training loss: 1.850949471631574
Validation loss: 2.4641779985055323

Epoch: 6| Step: 1
Training loss: 2.4621522841904873
Validation loss: 2.4562130327388014

Epoch: 6| Step: 2
Training loss: 1.9332355205961023
Validation loss: 2.456666298457996

Epoch: 6| Step: 3
Training loss: 3.216793020925894
Validation loss: 2.4434966542102017

Epoch: 6| Step: 4
Training loss: 2.097463815624771
Validation loss: 2.4692352402684543

Epoch: 6| Step: 5
Training loss: 2.920386929938675
Validation loss: 2.4701960399201375

Epoch: 6| Step: 6
Training loss: 2.345948879000414
Validation loss: 2.4802562335457576

Epoch: 6| Step: 7
Training loss: 2.2548871476043755
Validation loss: 2.4701242283869336

Epoch: 6| Step: 8
Training loss: 1.9773632734368054
Validation loss: 2.479792417615568

Epoch: 6| Step: 9
Training loss: 2.4431738718238303
Validation loss: 2.459751508125809

Epoch: 6| Step: 10
Training loss: 2.6458329528648123
Validation loss: 2.471824582984848

Epoch: 6| Step: 11
Training loss: 3.0872027543648017
Validation loss: 2.49485862125378

Epoch: 6| Step: 12
Training loss: 2.026507195840894
Validation loss: 2.462730900934998

Epoch: 6| Step: 13
Training loss: 2.2302474732210955
Validation loss: 2.4871846091899577

Epoch: 215| Step: 0
Training loss: 1.585202051274688
Validation loss: 2.4671750645444686

Epoch: 6| Step: 1
Training loss: 2.8566409521677816
Validation loss: 2.476714188866165

Epoch: 6| Step: 2
Training loss: 1.9769968754228011
Validation loss: 2.494629401070228

Epoch: 6| Step: 3
Training loss: 2.3292066890255607
Validation loss: 2.4594786117311473

Epoch: 6| Step: 4
Training loss: 2.1224286847214717
Validation loss: 2.461725822114149

Epoch: 6| Step: 5
Training loss: 2.9761656649327355
Validation loss: 2.4679697677406143

Epoch: 6| Step: 6
Training loss: 2.457660927921771
Validation loss: 2.4532670486192254

Epoch: 6| Step: 7
Training loss: 2.7512065668070416
Validation loss: 2.4799532891445057

Epoch: 6| Step: 8
Training loss: 2.1422026452128047
Validation loss: 2.4860113668568578

Epoch: 6| Step: 9
Training loss: 2.2936080223443485
Validation loss: 2.456594780180884

Epoch: 6| Step: 10
Training loss: 2.820850268209346
Validation loss: 2.472797981164295

Epoch: 6| Step: 11
Training loss: 2.9134949650509014
Validation loss: 2.4739474794487584

Epoch: 6| Step: 12
Training loss: 2.473167041250595
Validation loss: 2.496390426680247

Epoch: 6| Step: 13
Training loss: 1.6802563790698453
Validation loss: 2.4713836024670743

Epoch: 216| Step: 0
Training loss: 2.5378299479829516
Validation loss: 2.471654195960329

Epoch: 6| Step: 1
Training loss: 2.128298275429066
Validation loss: 2.47590312860531

Epoch: 6| Step: 2
Training loss: 2.64561469508849
Validation loss: 2.492884353821225

Epoch: 6| Step: 3
Training loss: 1.6649518569080408
Validation loss: 2.4735208335430965

Epoch: 6| Step: 4
Training loss: 2.753040020569697
Validation loss: 2.4787792076418116

Epoch: 6| Step: 5
Training loss: 1.9108285169489445
Validation loss: 2.46988673303786

Epoch: 6| Step: 6
Training loss: 2.566355712021426
Validation loss: 2.4858305991812295

Epoch: 6| Step: 7
Training loss: 3.3371921297297193
Validation loss: 2.4860452877877406

Epoch: 6| Step: 8
Training loss: 2.322831042526344
Validation loss: 2.478672954248558

Epoch: 6| Step: 9
Training loss: 2.188112990458878
Validation loss: 2.502030895930583

Epoch: 6| Step: 10
Training loss: 2.202708536379753
Validation loss: 2.4757724779138957

Epoch: 6| Step: 11
Training loss: 2.7133779836381597
Validation loss: 2.4994510529913567

Epoch: 6| Step: 12
Training loss: 2.6137496916133602
Validation loss: 2.4824192704849737

Epoch: 6| Step: 13
Training loss: 2.124045774846625
Validation loss: 2.488080773565162

Epoch: 217| Step: 0
Training loss: 2.4186508868115237
Validation loss: 2.4754624324322463

Epoch: 6| Step: 1
Training loss: 2.302728783986533
Validation loss: 2.493420617570938

Epoch: 6| Step: 2
Training loss: 2.583035226254575
Validation loss: 2.473097876417344

Epoch: 6| Step: 3
Training loss: 1.6255261963088983
Validation loss: 2.456842826453773

Epoch: 6| Step: 4
Training loss: 2.689667382221014
Validation loss: 2.4737166630699106

Epoch: 6| Step: 5
Training loss: 2.2429365973591295
Validation loss: 2.4587418060605786

Epoch: 6| Step: 6
Training loss: 1.9126117424328102
Validation loss: 2.483246650044575

Epoch: 6| Step: 7
Training loss: 2.497350242180039
Validation loss: 2.468371534537232

Epoch: 6| Step: 8
Training loss: 2.8416787453969907
Validation loss: 2.4671644282979828

Epoch: 6| Step: 9
Training loss: 2.2007839670052785
Validation loss: 2.4861756636417645

Epoch: 6| Step: 10
Training loss: 2.8741165130507182
Validation loss: 2.49363551784156

Epoch: 6| Step: 11
Training loss: 2.9914895780070347
Validation loss: 2.480439311770018

Epoch: 6| Step: 12
Training loss: 2.4743295705565314
Validation loss: 2.482101097367339

Epoch: 6| Step: 13
Training loss: 1.8262498808331356
Validation loss: 2.4703492000244953

Epoch: 218| Step: 0
Training loss: 2.152762647459396
Validation loss: 2.4782414069978658

Epoch: 6| Step: 1
Training loss: 2.4787820683346413
Validation loss: 2.4827711619744632

Epoch: 6| Step: 2
Training loss: 2.7864259712027457
Validation loss: 2.4961772784494998

Epoch: 6| Step: 3
Training loss: 1.7863850777808699
Validation loss: 2.4713278951374136

Epoch: 6| Step: 4
Training loss: 2.1299707953371705
Validation loss: 2.492562506661888

Epoch: 6| Step: 5
Training loss: 2.2819899312699072
Validation loss: 2.4849548839455675

Epoch: 6| Step: 6
Training loss: 3.2904078978009905
Validation loss: 2.4608844835359105

Epoch: 6| Step: 7
Training loss: 2.3315850474769655
Validation loss: 2.477712358918042

Epoch: 6| Step: 8
Training loss: 2.4459163419900856
Validation loss: 2.472186243750931

Epoch: 6| Step: 9
Training loss: 2.1620056072307077
Validation loss: 2.4493937947208004

Epoch: 6| Step: 10
Training loss: 2.497756141762718
Validation loss: 2.4719190039041354

Epoch: 6| Step: 11
Training loss: 2.567130487404482
Validation loss: 2.4997763410626637

Epoch: 6| Step: 12
Training loss: 2.219034955705645
Validation loss: 2.5043079053494104

Epoch: 6| Step: 13
Training loss: 2.4301525787049116
Validation loss: 2.472554752825223

Epoch: 219| Step: 0
Training loss: 2.4670346251966033
Validation loss: 2.484749363679689

Epoch: 6| Step: 1
Training loss: 2.281882524982082
Validation loss: 2.499005796801116

Epoch: 6| Step: 2
Training loss: 2.559858309579753
Validation loss: 2.4724087470994163

Epoch: 6| Step: 3
Training loss: 2.8272493808889694
Validation loss: 2.4654781789485964

Epoch: 6| Step: 4
Training loss: 1.885875442356157
Validation loss: 2.4945440069026783

Epoch: 6| Step: 5
Training loss: 2.007875909063787
Validation loss: 2.4717673360636483

Epoch: 6| Step: 6
Training loss: 2.2539085771624685
Validation loss: 2.482426206213624

Epoch: 6| Step: 7
Training loss: 2.358353147210054
Validation loss: 2.492790388668276

Epoch: 6| Step: 8
Training loss: 2.592957341053256
Validation loss: 2.4791696244598995

Epoch: 6| Step: 9
Training loss: 2.5470293618446718
Validation loss: 2.471266255861249

Epoch: 6| Step: 10
Training loss: 2.278543094317049
Validation loss: 2.457482774971836

Epoch: 6| Step: 11
Training loss: 2.7908729639558914
Validation loss: 2.4839669179635715

Epoch: 6| Step: 12
Training loss: 2.0176187753044275
Validation loss: 2.509523495198237

Epoch: 6| Step: 13
Training loss: 3.4459331757834963
Validation loss: 2.4712275322606763

Epoch: 220| Step: 0
Training loss: 2.406018629964364
Validation loss: 2.4896279882489516

Epoch: 6| Step: 1
Training loss: 2.7437838610947125
Validation loss: 2.4867523081300678

Epoch: 6| Step: 2
Training loss: 2.4084121106033187
Validation loss: 2.471653234460401

Epoch: 6| Step: 3
Training loss: 2.33565925293331
Validation loss: 2.469577927221977

Epoch: 6| Step: 4
Training loss: 2.3110574914242643
Validation loss: 2.480390132206908

Epoch: 6| Step: 5
Training loss: 1.9722144510298139
Validation loss: 2.4818980997579483

Epoch: 6| Step: 6
Training loss: 2.4532003208915913
Validation loss: 2.4652270508910004

Epoch: 6| Step: 7
Training loss: 2.429121534169275
Validation loss: 2.475453393516517

Epoch: 6| Step: 8
Training loss: 1.904368926421378
Validation loss: 2.473417405650268

Epoch: 6| Step: 9
Training loss: 3.0476279868834952
Validation loss: 2.4667390416421426

Epoch: 6| Step: 10
Training loss: 2.4466961245967886
Validation loss: 2.48044792426871

Epoch: 6| Step: 11
Training loss: 1.7922752884347013
Validation loss: 2.4616715750038987

Epoch: 6| Step: 12
Training loss: 2.714976618966437
Validation loss: 2.460385895069211

Epoch: 6| Step: 13
Training loss: 2.7024539709979427
Validation loss: 2.4785778876590765

Epoch: 221| Step: 0
Training loss: 2.5635230650544023
Validation loss: 2.475975830716448

Epoch: 6| Step: 1
Training loss: 2.398062710881395
Validation loss: 2.4840042014001025

Epoch: 6| Step: 2
Training loss: 2.7661365100663016
Validation loss: 2.47041035265245

Epoch: 6| Step: 3
Training loss: 2.530774672348312
Validation loss: 2.482603777917233

Epoch: 6| Step: 4
Training loss: 2.367793644516235
Validation loss: 2.448136417227489

Epoch: 6| Step: 5
Training loss: 1.8403675929130783
Validation loss: 2.479619864154667

Epoch: 6| Step: 6
Training loss: 2.299525489786954
Validation loss: 2.489258350098099

Epoch: 6| Step: 7
Training loss: 2.0720205494660684
Validation loss: 2.4928519955307165

Epoch: 6| Step: 8
Training loss: 2.534339808585435
Validation loss: 2.4894332085330975

Epoch: 6| Step: 9
Training loss: 2.7469586981302427
Validation loss: 2.459454085083652

Epoch: 6| Step: 10
Training loss: 2.676214876331969
Validation loss: 2.4582109704145045

Epoch: 6| Step: 11
Training loss: 2.4334051509170274
Validation loss: 2.4930228382400164

Epoch: 6| Step: 12
Training loss: 2.5723740678664404
Validation loss: 2.487043993727287

Epoch: 6| Step: 13
Training loss: 2.292891908882024
Validation loss: 2.4801471388343317

Epoch: 222| Step: 0
Training loss: 3.085732755025459
Validation loss: 2.4904264969439844

Epoch: 6| Step: 1
Training loss: 1.993666096419624
Validation loss: 2.483842822270875

Epoch: 6| Step: 2
Training loss: 2.012948676852162
Validation loss: 2.487903640177168

Epoch: 6| Step: 3
Training loss: 2.381489370735214
Validation loss: 2.486309852897384

Epoch: 6| Step: 4
Training loss: 2.361365886730217
Validation loss: 2.4859434565749807

Epoch: 6| Step: 5
Training loss: 3.1188865371814223
Validation loss: 2.462750955752009

Epoch: 6| Step: 6
Training loss: 1.9029144120486658
Validation loss: 2.4761673620591655

Epoch: 6| Step: 7
Training loss: 2.0751482071859613
Validation loss: 2.491117923930786

Epoch: 6| Step: 8
Training loss: 2.448634611860729
Validation loss: 2.455741748580321

Epoch: 6| Step: 9
Training loss: 2.064596324562852
Validation loss: 2.500248152199439

Epoch: 6| Step: 10
Training loss: 2.681670142203719
Validation loss: 2.488010380353423

Epoch: 6| Step: 11
Training loss: 3.0096151127396764
Validation loss: 2.48446176936827

Epoch: 6| Step: 12
Training loss: 1.603756996787694
Validation loss: 2.468851189430164

Epoch: 6| Step: 13
Training loss: 2.582336961708788
Validation loss: 2.4773266641621605

Epoch: 223| Step: 0
Training loss: 2.146383406370431
Validation loss: 2.4816712712196476

Epoch: 6| Step: 1
Training loss: 2.8804058170505136
Validation loss: 2.5002890676096925

Epoch: 6| Step: 2
Training loss: 2.154797050673182
Validation loss: 2.4937774958927026

Epoch: 6| Step: 3
Training loss: 2.8582000819992
Validation loss: 2.4916547108743816

Epoch: 6| Step: 4
Training loss: 2.7244650744437915
Validation loss: 2.4851610680575367

Epoch: 6| Step: 5
Training loss: 2.7990773656360264
Validation loss: 2.5007331367930044

Epoch: 6| Step: 6
Training loss: 2.5281812173560163
Validation loss: 2.477347716889778

Epoch: 6| Step: 7
Training loss: 2.6415344116927075
Validation loss: 2.4905119612658377

Epoch: 6| Step: 8
Training loss: 2.448778517490336
Validation loss: 2.479842181753147

Epoch: 6| Step: 9
Training loss: 1.9877149453683058
Validation loss: 2.4912025320086295

Epoch: 6| Step: 10
Training loss: 1.654622123658701
Validation loss: 2.5077648575526883

Epoch: 6| Step: 11
Training loss: 2.4234462440278866
Validation loss: 2.5361893363771704

Epoch: 6| Step: 12
Training loss: 2.060033537212071
Validation loss: 2.4967123328105267

Epoch: 6| Step: 13
Training loss: 2.2533783451452685
Validation loss: 2.476959230898944

Epoch: 224| Step: 0
Training loss: 2.7030346805720047
Validation loss: 2.504731856185146

Epoch: 6| Step: 1
Training loss: 2.0112818567611117
Validation loss: 2.5001929752155037

Epoch: 6| Step: 2
Training loss: 2.345113535656043
Validation loss: 2.4876611756420024

Epoch: 6| Step: 3
Training loss: 2.256570124436966
Validation loss: 2.484123453036146

Epoch: 6| Step: 4
Training loss: 2.211562752351077
Validation loss: 2.4759832825233925

Epoch: 6| Step: 5
Training loss: 2.5147489360985693
Validation loss: 2.4738012812989716

Epoch: 6| Step: 6
Training loss: 2.395924994885216
Validation loss: 2.4784793900727307

Epoch: 6| Step: 7
Training loss: 2.5470906733835568
Validation loss: 2.486484522765603

Epoch: 6| Step: 8
Training loss: 1.968742673345587
Validation loss: 2.4895432834095756

Epoch: 6| Step: 9
Training loss: 2.1001141744184437
Validation loss: 2.499029639823602

Epoch: 6| Step: 10
Training loss: 2.748711197298615
Validation loss: 2.4797742172780346

Epoch: 6| Step: 11
Training loss: 2.2963222954530416
Validation loss: 2.457963868442586

Epoch: 6| Step: 12
Training loss: 2.8404437956806854
Validation loss: 2.4510657311976005

Epoch: 6| Step: 13
Training loss: 2.8282666249932626
Validation loss: 2.4907791052140857

Epoch: 225| Step: 0
Training loss: 3.525874815260835
Validation loss: 2.472451221269372

Epoch: 6| Step: 1
Training loss: 2.1904723545498954
Validation loss: 2.4934286855460637

Epoch: 6| Step: 2
Training loss: 1.818024273570791
Validation loss: 2.438660449794644

Epoch: 6| Step: 3
Training loss: 1.9918980406861029
Validation loss: 2.4800435458920846

Epoch: 6| Step: 4
Training loss: 2.7230925682435747
Validation loss: 2.483999029743553

Epoch: 6| Step: 5
Training loss: 1.813916014967807
Validation loss: 2.5077778358889034

Epoch: 6| Step: 6
Training loss: 1.963824817536164
Validation loss: 2.4751835913342624

Epoch: 6| Step: 7
Training loss: 2.328200985481362
Validation loss: 2.4880602047442992

Epoch: 6| Step: 8
Training loss: 2.6398307011968485
Validation loss: 2.4673801753196

Epoch: 6| Step: 9
Training loss: 3.082540839822695
Validation loss: 2.476106395097376

Epoch: 6| Step: 10
Training loss: 2.6440890913134405
Validation loss: 2.4628106424722525

Epoch: 6| Step: 11
Training loss: 1.914322317745437
Validation loss: 2.4937459397450623

Epoch: 6| Step: 12
Training loss: 2.5431774422935423
Validation loss: 2.4952843316403124

Epoch: 6| Step: 13
Training loss: 1.800886039415676
Validation loss: 2.462408159924409

Epoch: 226| Step: 0
Training loss: 2.4326388474108467
Validation loss: 2.4669766186728235

Epoch: 6| Step: 1
Training loss: 2.0240744983623142
Validation loss: 2.481838166051165

Epoch: 6| Step: 2
Training loss: 2.6511828391827947
Validation loss: 2.4643028852467115

Epoch: 6| Step: 3
Training loss: 2.9468459126886635
Validation loss: 2.474857191297733

Epoch: 6| Step: 4
Training loss: 2.9275254066205285
Validation loss: 2.4710016347437893

Epoch: 6| Step: 5
Training loss: 2.6686811487397506
Validation loss: 2.4555064651391754

Epoch: 6| Step: 6
Training loss: 1.836400334882529
Validation loss: 2.4759735310782913

Epoch: 6| Step: 7
Training loss: 2.208427379213048
Validation loss: 2.4744690146608694

Epoch: 6| Step: 8
Training loss: 3.06641371416289
Validation loss: 2.471428803713455

Epoch: 6| Step: 9
Training loss: 2.234711094900936
Validation loss: 2.481982817098813

Epoch: 6| Step: 10
Training loss: 2.0199630541302653
Validation loss: 2.4816054115902615

Epoch: 6| Step: 11
Training loss: 2.229719313332411
Validation loss: 2.456020978650092

Epoch: 6| Step: 12
Training loss: 2.057593086148596
Validation loss: 2.4968600869312563

Epoch: 6| Step: 13
Training loss: 1.3338644887020106
Validation loss: 2.489940532388178

Epoch: 227| Step: 0
Training loss: 3.011077614707803
Validation loss: 2.4590807526413685

Epoch: 6| Step: 1
Training loss: 2.206378779556714
Validation loss: 2.496056411943796

Epoch: 6| Step: 2
Training loss: 2.597483234810352
Validation loss: 2.471570890509317

Epoch: 6| Step: 3
Training loss: 2.3253562900360776
Validation loss: 2.476653073886244

Epoch: 6| Step: 4
Training loss: 2.786895936252944
Validation loss: 2.487236733680354

Epoch: 6| Step: 5
Training loss: 2.131782590484321
Validation loss: 2.50887799577086

Epoch: 6| Step: 6
Training loss: 2.4337700891669756
Validation loss: 2.4926263808065277

Epoch: 6| Step: 7
Training loss: 2.1260029165152843
Validation loss: 2.4910241041506285

Epoch: 6| Step: 8
Training loss: 2.3377916001179995
Validation loss: 2.4997044870602103

Epoch: 6| Step: 9
Training loss: 2.818991396563048
Validation loss: 2.47708949299042

Epoch: 6| Step: 10
Training loss: 2.2936016814381053
Validation loss: 2.490024562733817

Epoch: 6| Step: 11
Training loss: 2.1351031065439745
Validation loss: 2.4747589884781935

Epoch: 6| Step: 12
Training loss: 1.981480748069815
Validation loss: 2.4790797929717043

Epoch: 6| Step: 13
Training loss: 2.250042173202308
Validation loss: 2.4644999559046066

Epoch: 228| Step: 0
Training loss: 2.4753962035896584
Validation loss: 2.483893132780092

Epoch: 6| Step: 1
Training loss: 2.882540392762218
Validation loss: 2.508716509123617

Epoch: 6| Step: 2
Training loss: 2.3937843738607785
Validation loss: 2.4966756539834924

Epoch: 6| Step: 3
Training loss: 2.3194996858314125
Validation loss: 2.481204547808285

Epoch: 6| Step: 4
Training loss: 2.4213067157111365
Validation loss: 2.4755843706832517

Epoch: 6| Step: 5
Training loss: 2.0780015492878663
Validation loss: 2.4840908681337273

Epoch: 6| Step: 6
Training loss: 2.349178487155491
Validation loss: 2.503386564334258

Epoch: 6| Step: 7
Training loss: 1.5129499916742553
Validation loss: 2.4962476031100325

Epoch: 6| Step: 8
Training loss: 2.475548858665861
Validation loss: 2.4754212589096594

Epoch: 6| Step: 9
Training loss: 2.4134001085446526
Validation loss: 2.496135926932213

Epoch: 6| Step: 10
Training loss: 2.6242350417389773
Validation loss: 2.5021246598114746

Epoch: 6| Step: 11
Training loss: 2.647662924417349
Validation loss: 2.483819893469152

Epoch: 6| Step: 12
Training loss: 2.6041161087214673
Validation loss: 2.485101200149393

Epoch: 6| Step: 13
Training loss: 1.957232740921792
Validation loss: 2.484461612524082

Epoch: 229| Step: 0
Training loss: 2.546476648924322
Validation loss: 2.5006433930594976

Epoch: 6| Step: 1
Training loss: 2.959426856870599
Validation loss: 2.5024624387516012

Epoch: 6| Step: 2
Training loss: 1.9454804007141753
Validation loss: 2.4651624356115454

Epoch: 6| Step: 3
Training loss: 2.1019218733158085
Validation loss: 2.487860618847796

Epoch: 6| Step: 4
Training loss: 2.263449209483962
Validation loss: 2.4895221381574646

Epoch: 6| Step: 5
Training loss: 2.2032295364577483
Validation loss: 2.4816537902260407

Epoch: 6| Step: 6
Training loss: 2.8686737449334676
Validation loss: 2.4548618706544993

Epoch: 6| Step: 7
Training loss: 1.9888838958263175
Validation loss: 2.48064315114322

Epoch: 6| Step: 8
Training loss: 2.279405658286672
Validation loss: 2.482483021453031

Epoch: 6| Step: 9
Training loss: 3.0372883538501236
Validation loss: 2.5072979935167217

Epoch: 6| Step: 10
Training loss: 2.191137287137432
Validation loss: 2.4597914202150277

Epoch: 6| Step: 11
Training loss: 2.2441756840848264
Validation loss: 2.4909762069897594

Epoch: 6| Step: 12
Training loss: 2.3696076262277286
Validation loss: 2.459529260099829

Epoch: 6| Step: 13
Training loss: 2.243426469094788
Validation loss: 2.468218276640845

Epoch: 230| Step: 0
Training loss: 2.704909601023116
Validation loss: 2.5021767409993756

Epoch: 6| Step: 1
Training loss: 1.9213078600200577
Validation loss: 2.470028621042279

Epoch: 6| Step: 2
Training loss: 2.1468935325744405
Validation loss: 2.494127677974907

Epoch: 6| Step: 3
Training loss: 2.463358532884656
Validation loss: 2.4619850055759818

Epoch: 6| Step: 4
Training loss: 2.344679991272713
Validation loss: 2.461895630023636

Epoch: 6| Step: 5
Training loss: 3.2055340895291224
Validation loss: 2.5065981056313458

Epoch: 6| Step: 6
Training loss: 1.8687760367222301
Validation loss: 2.4571581763598944

Epoch: 6| Step: 7
Training loss: 2.494604582863045
Validation loss: 2.4642577566759067

Epoch: 6| Step: 8
Training loss: 2.196556200579322
Validation loss: 2.4922799109898937

Epoch: 6| Step: 9
Training loss: 2.4739471970692337
Validation loss: 2.5023925581835784

Epoch: 6| Step: 10
Training loss: 2.857439897627715
Validation loss: 2.4862643220815297

Epoch: 6| Step: 11
Training loss: 2.3167345608795435
Validation loss: 2.49956299643745

Epoch: 6| Step: 12
Training loss: 2.0618365983720026
Validation loss: 2.4942275593052874

Epoch: 6| Step: 13
Training loss: 2.559615116243933
Validation loss: 2.4829808871292642

Epoch: 231| Step: 0
Training loss: 2.4891137567428188
Validation loss: 2.467255879192682

Epoch: 6| Step: 1
Training loss: 2.5307920065143277
Validation loss: 2.4789408036882454

Epoch: 6| Step: 2
Training loss: 2.7890062513476286
Validation loss: 2.4679437278420187

Epoch: 6| Step: 3
Training loss: 1.8977650522864546
Validation loss: 2.465203028605835

Epoch: 6| Step: 4
Training loss: 2.508246268433212
Validation loss: 2.4830903270998164

Epoch: 6| Step: 5
Training loss: 2.612256315264761
Validation loss: 2.5081915045264447

Epoch: 6| Step: 6
Training loss: 2.420639608995561
Validation loss: 2.4743119009283516

Epoch: 6| Step: 7
Training loss: 2.3705291830059614
Validation loss: 2.4763732053161127

Epoch: 6| Step: 8
Training loss: 1.9446915091121246
Validation loss: 2.4803448369077596

Epoch: 6| Step: 9
Training loss: 2.740162245548152
Validation loss: 2.4923871426142874

Epoch: 6| Step: 10
Training loss: 2.2700425850659047
Validation loss: 2.4965645422198497

Epoch: 6| Step: 11
Training loss: 2.3251725491719646
Validation loss: 2.487817094931759

Epoch: 6| Step: 12
Training loss: 2.3511751686043967
Validation loss: 2.522605062525552

Epoch: 6| Step: 13
Training loss: 2.173719542225812
Validation loss: 2.484951936477311

Epoch: 232| Step: 0
Training loss: 3.2089852665663705
Validation loss: 2.5156319827741633

Epoch: 6| Step: 1
Training loss: 2.412170063444538
Validation loss: 2.4894492817395317

Epoch: 6| Step: 2
Training loss: 2.249475205996407
Validation loss: 2.513143837466839

Epoch: 6| Step: 3
Training loss: 1.9109394363555705
Validation loss: 2.482057523066274

Epoch: 6| Step: 4
Training loss: 2.1672931890150164
Validation loss: 2.490845371211307

Epoch: 6| Step: 5
Training loss: 2.4968251095634595
Validation loss: 2.4953262797926716

Epoch: 6| Step: 6
Training loss: 1.8732285714750885
Validation loss: 2.479636608892092

Epoch: 6| Step: 7
Training loss: 2.7393178678242958
Validation loss: 2.481119431403489

Epoch: 6| Step: 8
Training loss: 2.7229166658883557
Validation loss: 2.4927969643902776

Epoch: 6| Step: 9
Training loss: 2.3368891687976245
Validation loss: 2.494565665567226

Epoch: 6| Step: 10
Training loss: 1.5392421869250354
Validation loss: 2.4951306595587206

Epoch: 6| Step: 11
Training loss: 2.0240386894584206
Validation loss: 2.4910136991522087

Epoch: 6| Step: 12
Training loss: 2.701779598516948
Validation loss: 2.495218702890913

Epoch: 6| Step: 13
Training loss: 2.642988152000033
Validation loss: 2.4781047231838826

Epoch: 233| Step: 0
Training loss: 2.496187927666315
Validation loss: 2.500463954369713

Epoch: 6| Step: 1
Training loss: 1.9267987702739355
Validation loss: 2.478636562857038

Epoch: 6| Step: 2
Training loss: 2.5229801672943344
Validation loss: 2.488570714602026

Epoch: 6| Step: 3
Training loss: 1.8963714786009291
Validation loss: 2.4966203467027346

Epoch: 6| Step: 4
Training loss: 2.090022170391858
Validation loss: 2.4825407709896345

Epoch: 6| Step: 5
Training loss: 2.8167568628740995
Validation loss: 2.4598652561334307

Epoch: 6| Step: 6
Training loss: 2.7802241287173413
Validation loss: 2.483733564090078

Epoch: 6| Step: 7
Training loss: 2.302189912241996
Validation loss: 2.4976345007537413

Epoch: 6| Step: 8
Training loss: 2.8225428672758652
Validation loss: 2.491820648974362

Epoch: 6| Step: 9
Training loss: 2.2324574385085594
Validation loss: 2.4706910761757825

Epoch: 6| Step: 10
Training loss: 2.2350891679219447
Validation loss: 2.470834054120031

Epoch: 6| Step: 11
Training loss: 2.535453978749552
Validation loss: 2.4612350468895943

Epoch: 6| Step: 12
Training loss: 2.684492779635892
Validation loss: 2.465168218755344

Epoch: 6| Step: 13
Training loss: 1.5997241378436806
Validation loss: 2.476926373726974

Epoch: 234| Step: 0
Training loss: 2.541625528054756
Validation loss: 2.50481877498075

Epoch: 6| Step: 1
Training loss: 1.9001355524396841
Validation loss: 2.4532132466959835

Epoch: 6| Step: 2
Training loss: 2.4348774030399296
Validation loss: 2.4865993150183248

Epoch: 6| Step: 3
Training loss: 2.5202109669373107
Validation loss: 2.4798327246072747

Epoch: 6| Step: 4
Training loss: 2.0775411832654638
Validation loss: 2.4820784582027158

Epoch: 6| Step: 5
Training loss: 1.871967597416087
Validation loss: 2.4889076137290043

Epoch: 6| Step: 6
Training loss: 2.7783791802309175
Validation loss: 2.468372999995658

Epoch: 6| Step: 7
Training loss: 1.9074515636288991
Validation loss: 2.4606540895018147

Epoch: 6| Step: 8
Training loss: 1.7551706085527878
Validation loss: 2.4964132328369137

Epoch: 6| Step: 9
Training loss: 2.2796301120073847
Validation loss: 2.499837122502786

Epoch: 6| Step: 10
Training loss: 1.9664114126411234
Validation loss: 2.4904425668279537

Epoch: 6| Step: 11
Training loss: 3.111980477602801
Validation loss: 2.505985232583479

Epoch: 6| Step: 12
Training loss: 3.2394451999141873
Validation loss: 2.4676293981085617

Epoch: 6| Step: 13
Training loss: 2.326296504322996
Validation loss: 2.4741561335626736

Epoch: 235| Step: 0
Training loss: 2.576881802531647
Validation loss: 2.492239539915004

Epoch: 6| Step: 1
Training loss: 2.5037746543641712
Validation loss: 2.4618306799830245

Epoch: 6| Step: 2
Training loss: 2.1218393044706714
Validation loss: 2.476013923016178

Epoch: 6| Step: 3
Training loss: 2.2295850081970086
Validation loss: 2.479711182392666

Epoch: 6| Step: 4
Training loss: 2.7456088119505475
Validation loss: 2.4736591314052423

Epoch: 6| Step: 5
Training loss: 2.246342122816393
Validation loss: 2.4720387716424743

Epoch: 6| Step: 6
Training loss: 2.3115465415247978
Validation loss: 2.4970729427999223

Epoch: 6| Step: 7
Training loss: 1.9351925183910499
Validation loss: 2.4700067835473813

Epoch: 6| Step: 8
Training loss: 2.5742215285336862
Validation loss: 2.5044896246075328

Epoch: 6| Step: 9
Training loss: 2.850353580425991
Validation loss: 2.4633243682361607

Epoch: 6| Step: 10
Training loss: 2.367375432476534
Validation loss: 2.4874134229423066

Epoch: 6| Step: 11
Training loss: 1.8752573472481593
Validation loss: 2.5089498379039883

Epoch: 6| Step: 12
Training loss: 2.042250906464143
Validation loss: 2.49960761631322

Epoch: 6| Step: 13
Training loss: 2.897642946971266
Validation loss: 2.479463244310937

Epoch: 236| Step: 0
Training loss: 2.1143991048703445
Validation loss: 2.490915340040171

Epoch: 6| Step: 1
Training loss: 2.592449827527208
Validation loss: 2.503670796989314

Epoch: 6| Step: 2
Training loss: 2.3771904330876765
Validation loss: 2.5006664751601586

Epoch: 6| Step: 3
Training loss: 2.4121111541617934
Validation loss: 2.4680816599320394

Epoch: 6| Step: 4
Training loss: 2.689050094336488
Validation loss: 2.492348019945423

Epoch: 6| Step: 5
Training loss: 2.4026343193177113
Validation loss: 2.4781913086471126

Epoch: 6| Step: 6
Training loss: 1.6775089063564317
Validation loss: 2.511152405156851

Epoch: 6| Step: 7
Training loss: 1.5828288010626768
Validation loss: 2.4756377744464833

Epoch: 6| Step: 8
Training loss: 2.6194202521312593
Validation loss: 2.5048231728854007

Epoch: 6| Step: 9
Training loss: 2.6392918217763652
Validation loss: 2.4915534896270843

Epoch: 6| Step: 10
Training loss: 1.960430550872359
Validation loss: 2.4826634515090857

Epoch: 6| Step: 11
Training loss: 2.587871646451636
Validation loss: 2.4644674784876806

Epoch: 6| Step: 12
Training loss: 2.7796094535004836
Validation loss: 2.489560369700687

Epoch: 6| Step: 13
Training loss: 2.444159775351499
Validation loss: 2.5180422888987395

Epoch: 237| Step: 0
Training loss: 2.3419442913880006
Validation loss: 2.4817613559904306

Epoch: 6| Step: 1
Training loss: 2.298561255716923
Validation loss: 2.4842482797844907

Epoch: 6| Step: 2
Training loss: 2.0757469395510775
Validation loss: 2.4904257578359434

Epoch: 6| Step: 3
Training loss: 2.826178455147402
Validation loss: 2.4778816899753915

Epoch: 6| Step: 4
Training loss: 2.392392770243686
Validation loss: 2.4680728993695977

Epoch: 6| Step: 5
Training loss: 2.3489748890047344
Validation loss: 2.482283448261933

Epoch: 6| Step: 6
Training loss: 2.4949623851195875
Validation loss: 2.4875140943255203

Epoch: 6| Step: 7
Training loss: 2.7970816253546276
Validation loss: 2.513767540869895

Epoch: 6| Step: 8
Training loss: 1.551685598048274
Validation loss: 2.498083803595572

Epoch: 6| Step: 9
Training loss: 2.563573844880287
Validation loss: 2.521915690223187

Epoch: 6| Step: 10
Training loss: 2.1396865458296217
Validation loss: 2.511945379961075

Epoch: 6| Step: 11
Training loss: 2.281071904167517
Validation loss: 2.4919844722223536

Epoch: 6| Step: 12
Training loss: 2.375303148698661
Validation loss: 2.5054983587242265

Epoch: 6| Step: 13
Training loss: 2.583938978838762
Validation loss: 2.4901377154673807

Epoch: 238| Step: 0
Training loss: 2.0742858760913245
Validation loss: 2.4677402211617023

Epoch: 6| Step: 1
Training loss: 2.480889424373448
Validation loss: 2.4923259665652524

Epoch: 6| Step: 2
Training loss: 2.619388941202312
Validation loss: 2.4948239127972185

Epoch: 6| Step: 3
Training loss: 2.2674237707209195
Validation loss: 2.4890554696319365

Epoch: 6| Step: 4
Training loss: 2.644264917753369
Validation loss: 2.516842567258126

Epoch: 6| Step: 5
Training loss: 2.2425411357530174
Validation loss: 2.4992121921592223

Epoch: 6| Step: 6
Training loss: 2.1134340015987654
Validation loss: 2.489931996996662

Epoch: 6| Step: 7
Training loss: 2.3932193815400025
Validation loss: 2.488382404486616

Epoch: 6| Step: 8
Training loss: 2.688801827172859
Validation loss: 2.46842135028845

Epoch: 6| Step: 9
Training loss: 2.296183994696418
Validation loss: 2.5042279526834226

Epoch: 6| Step: 10
Training loss: 2.098668257465915
Validation loss: 2.492898864267341

Epoch: 6| Step: 11
Training loss: 2.639881638850248
Validation loss: 2.4843408653580203

Epoch: 6| Step: 12
Training loss: 2.7667743428276976
Validation loss: 2.4850568835886784

Epoch: 6| Step: 13
Training loss: 1.7003456325349169
Validation loss: 2.4995019673010654

Epoch: 239| Step: 0
Training loss: 2.491431429506365
Validation loss: 2.50105329290304

Epoch: 6| Step: 1
Training loss: 2.011686276664484
Validation loss: 2.4582254764331646

Epoch: 6| Step: 2
Training loss: 2.410775919535079
Validation loss: 2.5041857001271106

Epoch: 6| Step: 3
Training loss: 2.3082353600965604
Validation loss: 2.5071157707227543

Epoch: 6| Step: 4
Training loss: 2.933059095076743
Validation loss: 2.4934111070531633

Epoch: 6| Step: 5
Training loss: 1.7004858444688005
Validation loss: 2.4886101181349107

Epoch: 6| Step: 6
Training loss: 2.033540109636995
Validation loss: 2.4995693676772843

Epoch: 6| Step: 7
Training loss: 2.5999585955330766
Validation loss: 2.4948188211142956

Epoch: 6| Step: 8
Training loss: 2.321229798327138
Validation loss: 2.4479530673875907

Epoch: 6| Step: 9
Training loss: 2.183943227463221
Validation loss: 2.498197319895207

Epoch: 6| Step: 10
Training loss: 2.71994492152491
Validation loss: 2.483813307398791

Epoch: 6| Step: 11
Training loss: 2.925659014156342
Validation loss: 2.5076179253849538

Epoch: 6| Step: 12
Training loss: 2.104769050813695
Validation loss: 2.4622171388080787

Epoch: 6| Step: 13
Training loss: 2.3781104549810315
Validation loss: 2.462240069912549

Epoch: 240| Step: 0
Training loss: 2.0486361083608724
Validation loss: 2.483593319931545

Epoch: 6| Step: 1
Training loss: 1.755878724192088
Validation loss: 2.5082062504239016

Epoch: 6| Step: 2
Training loss: 2.2440216325067373
Validation loss: 2.483166937061644

Epoch: 6| Step: 3
Training loss: 2.425147423736435
Validation loss: 2.4865107231670143

Epoch: 6| Step: 4
Training loss: 2.506640769574466
Validation loss: 2.462929148674953

Epoch: 6| Step: 5
Training loss: 1.9910518027003659
Validation loss: 2.52373829137895

Epoch: 6| Step: 6
Training loss: 2.9215747046554896
Validation loss: 2.48122189454909

Epoch: 6| Step: 7
Training loss: 2.5287225608826667
Validation loss: 2.4665941784477967

Epoch: 6| Step: 8
Training loss: 2.618299561138471
Validation loss: 2.471869452065421

Epoch: 6| Step: 9
Training loss: 2.3952339970713337
Validation loss: 2.4995585574829056

Epoch: 6| Step: 10
Training loss: 2.139412418164183
Validation loss: 2.4920378856205607

Epoch: 6| Step: 11
Training loss: 2.2834401525678065
Validation loss: 2.499987856517545

Epoch: 6| Step: 12
Training loss: 2.235426861922546
Validation loss: 2.50668604686786

Epoch: 6| Step: 13
Training loss: 3.1172210003192817
Validation loss: 2.48601390367259

Epoch: 241| Step: 0
Training loss: 1.9735283160965322
Validation loss: 2.486351760679609

Epoch: 6| Step: 1
Training loss: 2.1659604780161343
Validation loss: 2.494070346802658

Epoch: 6| Step: 2
Training loss: 2.13045474790274
Validation loss: 2.4929721021670015

Epoch: 6| Step: 3
Training loss: 2.608458580771897
Validation loss: 2.488608887105874

Epoch: 6| Step: 4
Training loss: 1.9898886787485488
Validation loss: 2.4744998593523366

Epoch: 6| Step: 5
Training loss: 2.191958869436818
Validation loss: 2.4754464807121073

Epoch: 6| Step: 6
Training loss: 2.776394838885781
Validation loss: 2.515064205274143

Epoch: 6| Step: 7
Training loss: 2.494692126832131
Validation loss: 2.4968921848524928

Epoch: 6| Step: 8
Training loss: 1.8543776345692309
Validation loss: 2.4834164492048165

Epoch: 6| Step: 9
Training loss: 2.0935772497166196
Validation loss: 2.49476623693462

Epoch: 6| Step: 10
Training loss: 2.3669696367682995
Validation loss: 2.491838869864976

Epoch: 6| Step: 11
Training loss: 2.625021253227299
Validation loss: 2.4668917980433958

Epoch: 6| Step: 12
Training loss: 2.9206829393298213
Validation loss: 2.4978199487824244

Epoch: 6| Step: 13
Training loss: 2.652904243406199
Validation loss: 2.494664956960894

Epoch: 242| Step: 0
Training loss: 2.116050048683328
Validation loss: 2.5054998321402504

Epoch: 6| Step: 1
Training loss: 2.2595684258908735
Validation loss: 2.5029099049423214

Epoch: 6| Step: 2
Training loss: 2.4427069777191455
Validation loss: 2.5117446402288355

Epoch: 6| Step: 3
Training loss: 2.1526392683638726
Validation loss: 2.503979785364049

Epoch: 6| Step: 4
Training loss: 1.6956378958493268
Validation loss: 2.4845816490891544

Epoch: 6| Step: 5
Training loss: 2.2108885419297883
Validation loss: 2.4760550048890746

Epoch: 6| Step: 6
Training loss: 2.5293399527279967
Validation loss: 2.4931400831766886

Epoch: 6| Step: 7
Training loss: 1.9750625286585755
Validation loss: 2.4965758202785686

Epoch: 6| Step: 8
Training loss: 2.2165032414972625
Validation loss: 2.501356382451574

Epoch: 6| Step: 9
Training loss: 2.0897657148105986
Validation loss: 2.5083730793894174

Epoch: 6| Step: 10
Training loss: 3.5247618899175635
Validation loss: 2.504102843203274

Epoch: 6| Step: 11
Training loss: 1.8699706973875647
Validation loss: 2.501865669103916

Epoch: 6| Step: 12
Training loss: 2.9032636496425774
Validation loss: 2.505940799923061

Epoch: 6| Step: 13
Training loss: 2.6183327062433253
Validation loss: 2.4615754373151937

Epoch: 243| Step: 0
Training loss: 2.9323070970652143
Validation loss: 2.4961052468947718

Epoch: 6| Step: 1
Training loss: 2.2640962902256554
Validation loss: 2.494907438548159

Epoch: 6| Step: 2
Training loss: 2.5343659613621
Validation loss: 2.4664063612598897

Epoch: 6| Step: 3
Training loss: 1.8952679332452818
Validation loss: 2.5198902995775936

Epoch: 6| Step: 4
Training loss: 2.651082026705888
Validation loss: 2.4991222532715978

Epoch: 6| Step: 5
Training loss: 2.279641198151492
Validation loss: 2.5064310726056287

Epoch: 6| Step: 6
Training loss: 2.201483040235953
Validation loss: 2.5071797465053742

Epoch: 6| Step: 7
Training loss: 2.6395853015999706
Validation loss: 2.488861757559729

Epoch: 6| Step: 8
Training loss: 2.670244578328596
Validation loss: 2.485215017004522

Epoch: 6| Step: 9
Training loss: 1.9313514114962924
Validation loss: 2.4852234953560117

Epoch: 6| Step: 10
Training loss: 2.0209508514317185
Validation loss: 2.5093569317175644

Epoch: 6| Step: 11
Training loss: 1.8621945841206868
Validation loss: 2.4844044947845285

Epoch: 6| Step: 12
Training loss: 2.5852864070992556
Validation loss: 2.496125177869883

Epoch: 6| Step: 13
Training loss: 2.1024358700146872
Validation loss: 2.4840526932839326

Epoch: 244| Step: 0
Training loss: 2.256705781756363
Validation loss: 2.4697927020425117

Epoch: 6| Step: 1
Training loss: 2.011663047241562
Validation loss: 2.4985705452341924

Epoch: 6| Step: 2
Training loss: 3.255082777526526
Validation loss: 2.5187166355139765

Epoch: 6| Step: 3
Training loss: 2.310050698256561
Validation loss: 2.4922820052852086

Epoch: 6| Step: 4
Training loss: 1.9859996962993656
Validation loss: 2.477532932616463

Epoch: 6| Step: 5
Training loss: 2.6342403716850575
Validation loss: 2.4913948139055324

Epoch: 6| Step: 6
Training loss: 1.756398628434836
Validation loss: 2.5021855798988573

Epoch: 6| Step: 7
Training loss: 2.7213205922563817
Validation loss: 2.4897408835660295

Epoch: 6| Step: 8
Training loss: 1.842487873053012
Validation loss: 2.5325174423511334

Epoch: 6| Step: 9
Training loss: 1.6273897645243782
Validation loss: 2.5313094099337907

Epoch: 6| Step: 10
Training loss: 2.2527693553766595
Validation loss: 2.531676077927259

Epoch: 6| Step: 11
Training loss: 2.8701552329798066
Validation loss: 2.4962415212220344

Epoch: 6| Step: 12
Training loss: 2.3739521325033057
Validation loss: 2.5408827105386154

Epoch: 6| Step: 13
Training loss: 2.7625698305167683
Validation loss: 2.493527341599769

Epoch: 245| Step: 0
Training loss: 2.4951858899237664
Validation loss: 2.5087227917158645

Epoch: 6| Step: 1
Training loss: 1.9584743638356028
Validation loss: 2.5090058149657524

Epoch: 6| Step: 2
Training loss: 3.041279668008677
Validation loss: 2.498602966954288

Epoch: 6| Step: 3
Training loss: 2.3881364223803074
Validation loss: 2.4973282073096073

Epoch: 6| Step: 4
Training loss: 2.6007549876992413
Validation loss: 2.4944954003724034

Epoch: 6| Step: 5
Training loss: 2.6168937859909795
Validation loss: 2.480870290689943

Epoch: 6| Step: 6
Training loss: 1.7274372077272808
Validation loss: 2.479488772401177

Epoch: 6| Step: 7
Training loss: 2.849336439818547
Validation loss: 2.4981518394911357

Epoch: 6| Step: 8
Training loss: 2.1375575676912404
Validation loss: 2.509434158795984

Epoch: 6| Step: 9
Training loss: 2.188085314236332
Validation loss: 2.4904789401141936

Epoch: 6| Step: 10
Training loss: 1.954860130145691
Validation loss: 2.4923609731294776

Epoch: 6| Step: 11
Training loss: 2.3480374602752736
Validation loss: 2.4742479228468093

Epoch: 6| Step: 12
Training loss: 2.007586870986076
Validation loss: 2.4752907417630574

Epoch: 6| Step: 13
Training loss: 2.3084866519878355
Validation loss: 2.4785776445940586

Epoch: 246| Step: 0
Training loss: 2.1746647982064053
Validation loss: 2.478944349846927

Epoch: 6| Step: 1
Training loss: 1.8839664326287373
Validation loss: 2.475500174312661

Epoch: 6| Step: 2
Training loss: 1.9414043464881576
Validation loss: 2.5119043951843603

Epoch: 6| Step: 3
Training loss: 2.153253325028057
Validation loss: 2.4870696883029266

Epoch: 6| Step: 4
Training loss: 2.5036199111395376
Validation loss: 2.4818788498974618

Epoch: 6| Step: 5
Training loss: 2.484273944454881
Validation loss: 2.496283245325485

Epoch: 6| Step: 6
Training loss: 2.4822637836289907
Validation loss: 2.478192823126132

Epoch: 6| Step: 7
Training loss: 2.568921950773565
Validation loss: 2.511213564612022

Epoch: 6| Step: 8
Training loss: 2.1932630645178484
Validation loss: 2.4722346838271063

Epoch: 6| Step: 9
Training loss: 2.6533625448078997
Validation loss: 2.47764368001405

Epoch: 6| Step: 10
Training loss: 2.3890704916401857
Validation loss: 2.4951266185652177

Epoch: 6| Step: 11
Training loss: 2.7787733730992548
Validation loss: 2.4868264414537853

Epoch: 6| Step: 12
Training loss: 2.2236627267627163
Validation loss: 2.4748885055757412

Epoch: 6| Step: 13
Training loss: 2.022828470724262
Validation loss: 2.4853063019220754

Epoch: 247| Step: 0
Training loss: 2.683324719843654
Validation loss: 2.4739743986185636

Epoch: 6| Step: 1
Training loss: 2.5706113508229866
Validation loss: 2.489663443604626

Epoch: 6| Step: 2
Training loss: 2.032365932570833
Validation loss: 2.483614837714167

Epoch: 6| Step: 3
Training loss: 2.113090577046852
Validation loss: 2.4912916660254893

Epoch: 6| Step: 4
Training loss: 2.0309443317186315
Validation loss: 2.5050353572381363

Epoch: 6| Step: 5
Training loss: 3.0095598173976588
Validation loss: 2.4773482136094644

Epoch: 6| Step: 6
Training loss: 3.0720658670854415
Validation loss: 2.5148589987628713

Epoch: 6| Step: 7
Training loss: 1.909246372316857
Validation loss: 2.4693562614866185

Epoch: 6| Step: 8
Training loss: 2.026284825133406
Validation loss: 2.4995119459329214

Epoch: 6| Step: 9
Training loss: 1.922081664844282
Validation loss: 2.5157660916903253

Epoch: 6| Step: 10
Training loss: 1.9038414043642926
Validation loss: 2.50558019850937

Epoch: 6| Step: 11
Training loss: 1.8235476972922662
Validation loss: 2.516320402200122

Epoch: 6| Step: 12
Training loss: 2.7562803167289074
Validation loss: 2.5049787782071387

Epoch: 6| Step: 13
Training loss: 2.3942091259996015
Validation loss: 2.5217599720782475

Epoch: 248| Step: 0
Training loss: 2.333892233079206
Validation loss: 2.4870905338335314

Epoch: 6| Step: 1
Training loss: 1.8568231718828898
Validation loss: 2.496381680225642

Epoch: 6| Step: 2
Training loss: 2.415421088175543
Validation loss: 2.507957353364326

Epoch: 6| Step: 3
Training loss: 1.7244408461417402
Validation loss: 2.5140793732964224

Epoch: 6| Step: 4
Training loss: 2.2693983554505004
Validation loss: 2.509605049469929

Epoch: 6| Step: 5
Training loss: 3.035822928912833
Validation loss: 2.5041696088951504

Epoch: 6| Step: 6
Training loss: 2.3360799790630247
Validation loss: 2.4814247594466003

Epoch: 6| Step: 7
Training loss: 1.9156476988699966
Validation loss: 2.506267945103105

Epoch: 6| Step: 8
Training loss: 2.854478990678954
Validation loss: 2.4835778426200408

Epoch: 6| Step: 9
Training loss: 2.4695731613527228
Validation loss: 2.4459091759082368

Epoch: 6| Step: 10
Training loss: 2.1127326521210343
Validation loss: 2.510669159593869

Epoch: 6| Step: 11
Training loss: 2.5894463926173983
Validation loss: 2.502213515410888

Epoch: 6| Step: 12
Training loss: 2.2407910188382587
Validation loss: 2.488010282465622

Epoch: 6| Step: 13
Training loss: 2.671952274387401
Validation loss: 2.4832354694030605

Epoch: 249| Step: 0
Training loss: 2.5174754664145236
Validation loss: 2.5035484859157675

Epoch: 6| Step: 1
Training loss: 2.3181277692073223
Validation loss: 2.5042894665364264

Epoch: 6| Step: 2
Training loss: 2.382804495375899
Validation loss: 2.485445694394207

Epoch: 6| Step: 3
Training loss: 2.237297547627466
Validation loss: 2.497720375330859

Epoch: 6| Step: 4
Training loss: 2.6731833662110063
Validation loss: 2.485944682736403

Epoch: 6| Step: 5
Training loss: 2.0862889368847557
Validation loss: 2.4959259944836245

Epoch: 6| Step: 6
Training loss: 2.3453315993312187
Validation loss: 2.5142745653923946

Epoch: 6| Step: 7
Training loss: 2.8132782601062805
Validation loss: 2.499956523353147

Epoch: 6| Step: 8
Training loss: 2.596287600557683
Validation loss: 2.481208379000738

Epoch: 6| Step: 9
Training loss: 2.0570110918412685
Validation loss: 2.475339963088697

Epoch: 6| Step: 10
Training loss: 1.8394424421964626
Validation loss: 2.483247630800201

Epoch: 6| Step: 11
Training loss: 2.408580196712445
Validation loss: 2.53021463953779

Epoch: 6| Step: 12
Training loss: 1.7319324236366571
Validation loss: 2.4844763950452924

Epoch: 6| Step: 13
Training loss: 2.2781503600081305
Validation loss: 2.497329967847981

Epoch: 250| Step: 0
Training loss: 1.7453965538227798
Validation loss: 2.5119063261520465

Epoch: 6| Step: 1
Training loss: 1.47837984174634
Validation loss: 2.451451194741628

Epoch: 6| Step: 2
Training loss: 2.417735247206761
Validation loss: 2.495842710306836

Epoch: 6| Step: 3
Training loss: 1.7669861534625335
Validation loss: 2.4888771474206544

Epoch: 6| Step: 4
Training loss: 2.177719376174526
Validation loss: 2.4790259886905943

Epoch: 6| Step: 5
Training loss: 2.5416513244499384
Validation loss: 2.527539233264729

Epoch: 6| Step: 6
Training loss: 1.960524496531072
Validation loss: 2.522169636793827

Epoch: 6| Step: 7
Training loss: 2.644420356622973
Validation loss: 2.5144431690193936

Epoch: 6| Step: 8
Training loss: 2.23292686644674
Validation loss: 2.480674160891668

Epoch: 6| Step: 9
Training loss: 2.3414213692371377
Validation loss: 2.502965384613959

Epoch: 6| Step: 10
Training loss: 2.5538465883247565
Validation loss: 2.4805164366487085

Epoch: 6| Step: 11
Training loss: 3.348189926785462
Validation loss: 2.484931378382198

Epoch: 6| Step: 12
Training loss: 2.681282213991223
Validation loss: 2.4775378487345954

Epoch: 6| Step: 13
Training loss: 2.2252071069916948
Validation loss: 2.4998037435551215

Epoch: 251| Step: 0
Training loss: 1.8948165206858971
Validation loss: 2.494720481260987

Epoch: 6| Step: 1
Training loss: 2.0127406811586694
Validation loss: 2.5060457079403182

Epoch: 6| Step: 2
Training loss: 2.2981620867332646
Validation loss: 2.5001575922773616

Epoch: 6| Step: 3
Training loss: 1.902802022453101
Validation loss: 2.4939819694566463

Epoch: 6| Step: 4
Training loss: 2.7668535337957496
Validation loss: 2.4708496039952808

Epoch: 6| Step: 5
Training loss: 2.273753350723591
Validation loss: 2.4933331749617547

Epoch: 6| Step: 6
Training loss: 2.7656724139098636
Validation loss: 2.5032522499823027

Epoch: 6| Step: 7
Training loss: 2.000450798728208
Validation loss: 2.520838610783335

Epoch: 6| Step: 8
Training loss: 2.3856088708018004
Validation loss: 2.4998988910451003

Epoch: 6| Step: 9
Training loss: 2.072961573537669
Validation loss: 2.5155206056229082

Epoch: 6| Step: 10
Training loss: 2.370038522012922
Validation loss: 2.4739926841091084

Epoch: 6| Step: 11
Training loss: 2.88301925124543
Validation loss: 2.515803600878876

Epoch: 6| Step: 12
Training loss: 2.3596684355503044
Validation loss: 2.4742733337860883

Epoch: 6| Step: 13
Training loss: 2.503025989264952
Validation loss: 2.513578135172471

Epoch: 252| Step: 0
Training loss: 1.8670523367126837
Validation loss: 2.4856811338446354

Epoch: 6| Step: 1
Training loss: 2.3269228295618936
Validation loss: 2.4923206064534953

Epoch: 6| Step: 2
Training loss: 2.071231508512032
Validation loss: 2.4788481291496156

Epoch: 6| Step: 3
Training loss: 1.9922370455695642
Validation loss: 2.5104660753008803

Epoch: 6| Step: 4
Training loss: 2.630976820875171
Validation loss: 2.4985453711441594

Epoch: 6| Step: 5
Training loss: 2.3539653680760817
Validation loss: 2.4790303713390456

Epoch: 6| Step: 6
Training loss: 2.3713808090173396
Validation loss: 2.500181298193761

Epoch: 6| Step: 7
Training loss: 2.2412143416368484
Validation loss: 2.4932320542469824

Epoch: 6| Step: 8
Training loss: 3.3710776247984846
Validation loss: 2.5195850694394326

Epoch: 6| Step: 9
Training loss: 1.572619210047229
Validation loss: 2.484559610351483

Epoch: 6| Step: 10
Training loss: 2.937432470965822
Validation loss: 2.4985909023559554

Epoch: 6| Step: 11
Training loss: 1.878577443496051
Validation loss: 2.49513067188821

Epoch: 6| Step: 12
Training loss: 2.375474380499539
Validation loss: 2.4994560572862494

Epoch: 6| Step: 13
Training loss: 1.8920585934919312
Validation loss: 2.494762738956047

Epoch: 253| Step: 0
Training loss: 2.4177107912177385
Validation loss: 2.4519760077680353

Epoch: 6| Step: 1
Training loss: 2.184615494964696
Validation loss: 2.489558916199154

Epoch: 6| Step: 2
Training loss: 1.8467055086441742
Validation loss: 2.4906887305728755

Epoch: 6| Step: 3
Training loss: 2.418122269744002
Validation loss: 2.5041282726486296

Epoch: 6| Step: 4
Training loss: 2.558465899119628
Validation loss: 2.5090388099227883

Epoch: 6| Step: 5
Training loss: 1.7625837211474396
Validation loss: 2.4983747521556654

Epoch: 6| Step: 6
Training loss: 2.373438271477821
Validation loss: 2.492464219726802

Epoch: 6| Step: 7
Training loss: 2.874031733125982
Validation loss: 2.477824544714347

Epoch: 6| Step: 8
Training loss: 2.788649413561664
Validation loss: 2.487389333556051

Epoch: 6| Step: 9
Training loss: 2.817345493009979
Validation loss: 2.501851188120881

Epoch: 6| Step: 10
Training loss: 2.186816190379656
Validation loss: 2.5038218828048318

Epoch: 6| Step: 11
Training loss: 2.1707708172817575
Validation loss: 2.498817537470206

Epoch: 6| Step: 12
Training loss: 2.0883192544854787
Validation loss: 2.5343879200179025

Epoch: 6| Step: 13
Training loss: 1.7657673871176591
Validation loss: 2.481977060222676

Epoch: 254| Step: 0
Training loss: 2.1575903665618203
Validation loss: 2.4957899530478866

Epoch: 6| Step: 1
Training loss: 2.261349979043971
Validation loss: 2.501720164819397

Epoch: 6| Step: 2
Training loss: 2.525926525729719
Validation loss: 2.5105310634493203

Epoch: 6| Step: 3
Training loss: 2.3810746656532062
Validation loss: 2.5031075043083684

Epoch: 6| Step: 4
Training loss: 1.9598956741088294
Validation loss: 2.5082043799779954

Epoch: 6| Step: 5
Training loss: 1.9218718986176069
Validation loss: 2.479874041979491

Epoch: 6| Step: 6
Training loss: 2.041773371600424
Validation loss: 2.4997482337105157

Epoch: 6| Step: 7
Training loss: 3.1747650359912374
Validation loss: 2.525995713629882

Epoch: 6| Step: 8
Training loss: 2.82878551883961
Validation loss: 2.508063036668896

Epoch: 6| Step: 9
Training loss: 1.9829379908513336
Validation loss: 2.5048222599395737

Epoch: 6| Step: 10
Training loss: 2.411411150367042
Validation loss: 2.5029062037614405

Epoch: 6| Step: 11
Training loss: 2.3751949431070347
Validation loss: 2.4988731982809256

Epoch: 6| Step: 12
Training loss: 2.360496305068893
Validation loss: 2.4755543855754794

Epoch: 6| Step: 13
Training loss: 1.615552582584277
Validation loss: 2.4774433894726284

Epoch: 255| Step: 0
Training loss: 1.4764674726314317
Validation loss: 2.505594516743753

Epoch: 6| Step: 1
Training loss: 3.112648932022922
Validation loss: 2.5263736372667482

Epoch: 6| Step: 2
Training loss: 2.2239151056333535
Validation loss: 2.498286178697591

Epoch: 6| Step: 3
Training loss: 2.9859506332292285
Validation loss: 2.4858895935634746

Epoch: 6| Step: 4
Training loss: 2.1374065401045925
Validation loss: 2.4865388677735734

Epoch: 6| Step: 5
Training loss: 2.4872512002862104
Validation loss: 2.4945555458815067

Epoch: 6| Step: 6
Training loss: 1.637609344209587
Validation loss: 2.513758781449056

Epoch: 6| Step: 7
Training loss: 2.2326568186191453
Validation loss: 2.495650100316134

Epoch: 6| Step: 8
Training loss: 2.4302663818786714
Validation loss: 2.50170561536015

Epoch: 6| Step: 9
Training loss: 2.290623780129226
Validation loss: 2.4894601801135847

Epoch: 6| Step: 10
Training loss: 2.0430216153308876
Validation loss: 2.5138225784814394

Epoch: 6| Step: 11
Training loss: 2.6764148713756435
Validation loss: 2.4834030808325496

Epoch: 6| Step: 12
Training loss: 1.5650349462586657
Validation loss: 2.498598108699347

Epoch: 6| Step: 13
Training loss: 2.5668575174624735
Validation loss: 2.5193373677775805

Epoch: 256| Step: 0
Training loss: 2.467189633717016
Validation loss: 2.5125838919000403

Epoch: 6| Step: 1
Training loss: 2.2902860008119372
Validation loss: 2.500267994780532

Epoch: 6| Step: 2
Training loss: 2.8645433087876193
Validation loss: 2.4970054801724295

Epoch: 6| Step: 3
Training loss: 1.862701069776052
Validation loss: 2.477742267211751

Epoch: 6| Step: 4
Training loss: 2.058945338067858
Validation loss: 2.4962547859218605

Epoch: 6| Step: 5
Training loss: 2.2184964961982243
Validation loss: 2.518976757570471

Epoch: 6| Step: 6
Training loss: 2.3178265030700076
Validation loss: 2.4588780408857267

Epoch: 6| Step: 7
Training loss: 2.952492459487007
Validation loss: 2.511125306186646

Epoch: 6| Step: 8
Training loss: 2.0651895730700573
Validation loss: 2.4948596036100326

Epoch: 6| Step: 9
Training loss: 1.7317661218411786
Validation loss: 2.4691600840590726

Epoch: 6| Step: 10
Training loss: 2.79686195754095
Validation loss: 2.508948251561653

Epoch: 6| Step: 11
Training loss: 2.2493363567317655
Validation loss: 2.4982209027991265

Epoch: 6| Step: 12
Training loss: 1.8501330302066579
Validation loss: 2.4956355894306155

Epoch: 6| Step: 13
Training loss: 2.546333302187213
Validation loss: 2.485800919696035

Epoch: 257| Step: 0
Training loss: 2.039927332088728
Validation loss: 2.522977868838788

Epoch: 6| Step: 1
Training loss: 2.2598911735191813
Validation loss: 2.4937319585251534

Epoch: 6| Step: 2
Training loss: 2.6133708396802238
Validation loss: 2.5022229514904186

Epoch: 6| Step: 3
Training loss: 2.481962171919499
Validation loss: 2.5084568009102144

Epoch: 6| Step: 4
Training loss: 2.1130762476742544
Validation loss: 2.5043188844249014

Epoch: 6| Step: 5
Training loss: 2.385563297568124
Validation loss: 2.5167064407173076

Epoch: 6| Step: 6
Training loss: 2.169774748366448
Validation loss: 2.4968730998737576

Epoch: 6| Step: 7
Training loss: 2.6581464392835437
Validation loss: 2.4948939899453966

Epoch: 6| Step: 8
Training loss: 1.9980392381330103
Validation loss: 2.5185046734302983

Epoch: 6| Step: 9
Training loss: 2.3513793874019
Validation loss: 2.500515313516438

Epoch: 6| Step: 10
Training loss: 3.059574052922227
Validation loss: 2.4973138201229745

Epoch: 6| Step: 11
Training loss: 1.9728643024374255
Validation loss: 2.5005830238755267

Epoch: 6| Step: 12
Training loss: 2.2073630834610247
Validation loss: 2.497078052473

Epoch: 6| Step: 13
Training loss: 2.2235253751630855
Validation loss: 2.4849445383888034

Epoch: 258| Step: 0
Training loss: 1.770635937927265
Validation loss: 2.4933960001637057

Epoch: 6| Step: 1
Training loss: 2.3627999816651712
Validation loss: 2.5180521716600115

Epoch: 6| Step: 2
Training loss: 2.1089691902033683
Validation loss: 2.5087476705449006

Epoch: 6| Step: 3
Training loss: 1.940354183054638
Validation loss: 2.4815440730538327

Epoch: 6| Step: 4
Training loss: 2.407634881540147
Validation loss: 2.4968472340941106

Epoch: 6| Step: 5
Training loss: 2.203347702133411
Validation loss: 2.5015640923991893

Epoch: 6| Step: 6
Training loss: 2.7519865663444527
Validation loss: 2.4922570495230914

Epoch: 6| Step: 7
Training loss: 2.7985942820086924
Validation loss: 2.5220834907967866

Epoch: 6| Step: 8
Training loss: 1.7931849530084176
Validation loss: 2.4683747749544143

Epoch: 6| Step: 9
Training loss: 2.5470447132692473
Validation loss: 2.4971912325928884

Epoch: 6| Step: 10
Training loss: 2.836236102564839
Validation loss: 2.4947263603047136

Epoch: 6| Step: 11
Training loss: 1.9037145418708505
Validation loss: 2.507116366355597

Epoch: 6| Step: 12
Training loss: 1.8076462704685323
Validation loss: 2.5235983290846473

Epoch: 6| Step: 13
Training loss: 2.951872060282817
Validation loss: 2.4635523136979565

Epoch: 259| Step: 0
Training loss: 1.8467397211041034
Validation loss: 2.510788134156723

Epoch: 6| Step: 1
Training loss: 1.9791531077138003
Validation loss: 2.503903357603778

Epoch: 6| Step: 2
Training loss: 2.4988397767053363
Validation loss: 2.513287406366418

Epoch: 6| Step: 3
Training loss: 2.0256628811786066
Validation loss: 2.511075542307062

Epoch: 6| Step: 4
Training loss: 1.8046030792703858
Validation loss: 2.490240006236385

Epoch: 6| Step: 5
Training loss: 2.0181102955584618
Validation loss: 2.4775511214805057

Epoch: 6| Step: 6
Training loss: 2.6217820561408884
Validation loss: 2.528193042895643

Epoch: 6| Step: 7
Training loss: 3.0956307291416487
Validation loss: 2.481974032266766

Epoch: 6| Step: 8
Training loss: 2.424965443315767
Validation loss: 2.4680522193745875

Epoch: 6| Step: 9
Training loss: 2.326470318281689
Validation loss: 2.4960110311875745

Epoch: 6| Step: 10
Training loss: 2.520893716220302
Validation loss: 2.4728403636377045

Epoch: 6| Step: 11
Training loss: 1.9974371463593055
Validation loss: 2.501624466602151

Epoch: 6| Step: 12
Training loss: 2.444342765234671
Validation loss: 2.5026476693654245

Epoch: 6| Step: 13
Training loss: 2.4940123379424333
Validation loss: 2.50988953497865

Epoch: 260| Step: 0
Training loss: 2.036160914824054
Validation loss: 2.523876047817957

Epoch: 6| Step: 1
Training loss: 2.024939491404041
Validation loss: 2.498590069728765

Epoch: 6| Step: 2
Training loss: 2.3192922487661547
Validation loss: 2.482548915113165

Epoch: 6| Step: 3
Training loss: 2.3515420196756622
Validation loss: 2.5110162233399245

Epoch: 6| Step: 4
Training loss: 2.389756786788145
Validation loss: 2.48904348080757

Epoch: 6| Step: 5
Training loss: 2.4540693081346374
Validation loss: 2.5057189199713643

Epoch: 6| Step: 6
Training loss: 1.5345507488093664
Validation loss: 2.510198594305516

Epoch: 6| Step: 7
Training loss: 2.6965212557913523
Validation loss: 2.492041281464589

Epoch: 6| Step: 8
Training loss: 2.3196669171733295
Validation loss: 2.491016781728537

Epoch: 6| Step: 9
Training loss: 2.193672191837627
Validation loss: 2.4588519026180826

Epoch: 6| Step: 10
Training loss: 2.7813892115352936
Validation loss: 2.500754313343035

Epoch: 6| Step: 11
Training loss: 2.1165534051744515
Validation loss: 2.4724724689678985

Epoch: 6| Step: 12
Training loss: 2.7236004236264404
Validation loss: 2.487737088368483

Epoch: 6| Step: 13
Training loss: 2.1668502534213
Validation loss: 2.4955936711318114

Epoch: 261| Step: 0
Training loss: 2.5938838326729945
Validation loss: 2.4983102215040454

Epoch: 6| Step: 1
Training loss: 2.5335137876019136
Validation loss: 2.5234771484624967

Epoch: 6| Step: 2
Training loss: 2.0848470402145356
Validation loss: 2.510178504430214

Epoch: 6| Step: 3
Training loss: 2.6375202232417165
Validation loss: 2.4717405686592886

Epoch: 6| Step: 4
Training loss: 1.5437247826373743
Validation loss: 2.473339425062253

Epoch: 6| Step: 5
Training loss: 2.5393798629785533
Validation loss: 2.5091109963731295

Epoch: 6| Step: 6
Training loss: 2.364547213868086
Validation loss: 2.475209873035543

Epoch: 6| Step: 7
Training loss: 2.9600223143483952
Validation loss: 2.5011728037918957

Epoch: 6| Step: 8
Training loss: 1.6027561112821243
Validation loss: 2.5024919754389257

Epoch: 6| Step: 9
Training loss: 2.402965930292395
Validation loss: 2.494797184171828

Epoch: 6| Step: 10
Training loss: 1.9449033498408521
Validation loss: 2.512027327097523

Epoch: 6| Step: 11
Training loss: 2.3587200948480183
Validation loss: 2.490894950550541

Epoch: 6| Step: 12
Training loss: 2.431141605265373
Validation loss: 2.5021459147473104

Epoch: 6| Step: 13
Training loss: 1.9890290598369482
Validation loss: 2.494117530815217

Epoch: 262| Step: 0
Training loss: 1.7713158641944893
Validation loss: 2.4907372714093037

Epoch: 6| Step: 1
Training loss: 1.8693592418030704
Validation loss: 2.5061615252846394

Epoch: 6| Step: 2
Training loss: 2.60428300724826
Validation loss: 2.4879756505502915

Epoch: 6| Step: 3
Training loss: 2.4926669338267327
Validation loss: 2.50280110525023

Epoch: 6| Step: 4
Training loss: 2.2888064713232934
Validation loss: 2.4802061748593873

Epoch: 6| Step: 5
Training loss: 2.2210908817966444
Validation loss: 2.502890086378758

Epoch: 6| Step: 6
Training loss: 2.428741957984446
Validation loss: 2.513830403020185

Epoch: 6| Step: 7
Training loss: 2.483119431399888
Validation loss: 2.502093623387436

Epoch: 6| Step: 8
Training loss: 1.8822909697330987
Validation loss: 2.5151474798262896

Epoch: 6| Step: 9
Training loss: 2.1631228613877327
Validation loss: 2.508291514701534

Epoch: 6| Step: 10
Training loss: 2.5769088188503964
Validation loss: 2.471840414434795

Epoch: 6| Step: 11
Training loss: 2.7497504727990667
Validation loss: 2.5174448855421754

Epoch: 6| Step: 12
Training loss: 2.3640274761300786
Validation loss: 2.5090115082922995

Epoch: 6| Step: 13
Training loss: 2.59719904267637
Validation loss: 2.527009310072441

Epoch: 263| Step: 0
Training loss: 2.338861886737208
Validation loss: 2.5329267082663547

Epoch: 6| Step: 1
Training loss: 2.2402192624953425
Validation loss: 2.5124188170002566

Epoch: 6| Step: 2
Training loss: 2.157935547963052
Validation loss: 2.511182064228024

Epoch: 6| Step: 3
Training loss: 1.917999205182401
Validation loss: 2.5165096728111807

Epoch: 6| Step: 4
Training loss: 2.864394820975224
Validation loss: 2.529058224819618

Epoch: 6| Step: 5
Training loss: 2.1193924011578056
Validation loss: 2.4883983330355943

Epoch: 6| Step: 6
Training loss: 2.223610296122825
Validation loss: 2.506849691215514

Epoch: 6| Step: 7
Training loss: 2.1606442553848693
Validation loss: 2.5159821839847814

Epoch: 6| Step: 8
Training loss: 2.6028954009686576
Validation loss: 2.5187758800011935

Epoch: 6| Step: 9
Training loss: 2.2316004459203564
Validation loss: 2.513071843876631

Epoch: 6| Step: 10
Training loss: 2.26014995026856
Validation loss: 2.4985034503602948

Epoch: 6| Step: 11
Training loss: 2.4853285393088824
Validation loss: 2.5190553312815607

Epoch: 6| Step: 12
Training loss: 2.3148879017064825
Validation loss: 2.5337353841358228

Epoch: 6| Step: 13
Training loss: 2.545411889071801
Validation loss: 2.4833269520003336

Epoch: 264| Step: 0
Training loss: 2.3897575849230535
Validation loss: 2.520041868731545

Epoch: 6| Step: 1
Training loss: 2.32582408697718
Validation loss: 2.5283327660473547

Epoch: 6| Step: 2
Training loss: 2.4694743964780925
Validation loss: 2.491399448508855

Epoch: 6| Step: 3
Training loss: 2.6168298277635755
Validation loss: 2.4777660437683044

Epoch: 6| Step: 4
Training loss: 2.251110756405326
Validation loss: 2.4941964107381547

Epoch: 6| Step: 5
Training loss: 2.097051039467993
Validation loss: 2.498928215641006

Epoch: 6| Step: 6
Training loss: 2.0515837343603103
Validation loss: 2.5272519141117438

Epoch: 6| Step: 7
Training loss: 2.746900719358404
Validation loss: 2.507959566432072

Epoch: 6| Step: 8
Training loss: 2.272953362056508
Validation loss: 2.5092283396244617

Epoch: 6| Step: 9
Training loss: 2.237077372611646
Validation loss: 2.518858150447437

Epoch: 6| Step: 10
Training loss: 2.1100879735821687
Validation loss: 2.504286671834403

Epoch: 6| Step: 11
Training loss: 2.6636196450783776
Validation loss: 2.5015015138449086

Epoch: 6| Step: 12
Training loss: 1.5872382481365728
Validation loss: 2.5024649783549187

Epoch: 6| Step: 13
Training loss: 2.6344820156964124
Validation loss: 2.525347448433754

Epoch: 265| Step: 0
Training loss: 2.5324887670661367
Validation loss: 2.491948139429205

Epoch: 6| Step: 1
Training loss: 2.800498873682652
Validation loss: 2.5205478162441604

Epoch: 6| Step: 2
Training loss: 1.5924252258663782
Validation loss: 2.5054099327354864

Epoch: 6| Step: 3
Training loss: 2.4928311560139407
Validation loss: 2.4963826260395763

Epoch: 6| Step: 4
Training loss: 2.159329192231885
Validation loss: 2.509964671237466

Epoch: 6| Step: 5
Training loss: 1.8704900544163965
Validation loss: 2.4995501533962643

Epoch: 6| Step: 6
Training loss: 2.0488303359958877
Validation loss: 2.524110284356098

Epoch: 6| Step: 7
Training loss: 1.8684178213412521
Validation loss: 2.4967350887941056

Epoch: 6| Step: 8
Training loss: 2.1770747669787607
Validation loss: 2.5163720204614934

Epoch: 6| Step: 9
Training loss: 2.670267525032449
Validation loss: 2.4879712795376063

Epoch: 6| Step: 10
Training loss: 2.66946141500787
Validation loss: 2.516735064592953

Epoch: 6| Step: 11
Training loss: 2.5390138592095752
Validation loss: 2.4876701088838624

Epoch: 6| Step: 12
Training loss: 2.541789963863645
Validation loss: 2.4868720650650507

Epoch: 6| Step: 13
Training loss: 2.1654332636166016
Validation loss: 2.479608451076996

Epoch: 266| Step: 0
Training loss: 2.6314341392328013
Validation loss: 2.4776167406970018

Epoch: 6| Step: 1
Training loss: 2.4645126289636927
Validation loss: 2.5207564334501322

Epoch: 6| Step: 2
Training loss: 1.5009042080854977
Validation loss: 2.5115416500448635

Epoch: 6| Step: 3
Training loss: 3.04515128650894
Validation loss: 2.4837564782063115

Epoch: 6| Step: 4
Training loss: 2.1657278765838974
Validation loss: 2.5037226289417616

Epoch: 6| Step: 5
Training loss: 1.8780610846435715
Validation loss: 2.5132779700067

Epoch: 6| Step: 6
Training loss: 2.1922168558429598
Validation loss: 2.5101872620464802

Epoch: 6| Step: 7
Training loss: 2.6302416103763315
Validation loss: 2.5047517502448726

Epoch: 6| Step: 8
Training loss: 2.4231178294211757
Validation loss: 2.506106528620453

Epoch: 6| Step: 9
Training loss: 2.1506487200359308
Validation loss: 2.5051695463121564

Epoch: 6| Step: 10
Training loss: 2.6194177035812674
Validation loss: 2.5142798379159323

Epoch: 6| Step: 11
Training loss: 2.028639186575647
Validation loss: 2.4766212726323285

Epoch: 6| Step: 12
Training loss: 1.9765985055893303
Validation loss: 2.489930913854416

Epoch: 6| Step: 13
Training loss: 2.216106290423386
Validation loss: 2.491519488316979

Epoch: 267| Step: 0
Training loss: 2.1358237894147383
Validation loss: 2.507176724957895

Epoch: 6| Step: 1
Training loss: 2.5174480963984744
Validation loss: 2.501041425142451

Epoch: 6| Step: 2
Training loss: 2.372922490631628
Validation loss: 2.51933659543023

Epoch: 6| Step: 3
Training loss: 2.6040765568719926
Validation loss: 2.4918872632986484

Epoch: 6| Step: 4
Training loss: 1.6940728502743745
Validation loss: 2.4854310651378837

Epoch: 6| Step: 5
Training loss: 2.572190639182029
Validation loss: 2.495014944615201

Epoch: 6| Step: 6
Training loss: 2.5512201419412017
Validation loss: 2.51933306135297

Epoch: 6| Step: 7
Training loss: 1.9047573687011203
Validation loss: 2.503467115283677

Epoch: 6| Step: 8
Training loss: 2.2042185997809103
Validation loss: 2.4758841727955154

Epoch: 6| Step: 9
Training loss: 2.1278486792247393
Validation loss: 2.519454631576869

Epoch: 6| Step: 10
Training loss: 2.8745319151262003
Validation loss: 2.5295556815329285

Epoch: 6| Step: 11
Training loss: 1.6898668433104773
Validation loss: 2.4858158015087106

Epoch: 6| Step: 12
Training loss: 2.214904676672476
Validation loss: 2.494532790569464

Epoch: 6| Step: 13
Training loss: 2.5845128309773058
Validation loss: 2.5313179116385176

Epoch: 268| Step: 0
Training loss: 2.847407912321807
Validation loss: 2.5117824615704802

Epoch: 6| Step: 1
Training loss: 2.3661396993571153
Validation loss: 2.489873240997375

Epoch: 6| Step: 2
Training loss: 2.205190353308242
Validation loss: 2.475480415923876

Epoch: 6| Step: 3
Training loss: 2.0373041164107386
Validation loss: 2.4991104543033167

Epoch: 6| Step: 4
Training loss: 2.673243478928142
Validation loss: 2.5021438235852034

Epoch: 6| Step: 5
Training loss: 2.1840641832038177
Validation loss: 2.4419383860174584

Epoch: 6| Step: 6
Training loss: 2.647856522023874
Validation loss: 2.5227792609592092

Epoch: 6| Step: 7
Training loss: 2.5702944120101106
Validation loss: 2.4907688450893497

Epoch: 6| Step: 8
Training loss: 1.657794735855579
Validation loss: 2.5084510235425532

Epoch: 6| Step: 9
Training loss: 1.8656117961167094
Validation loss: 2.5082302083617685

Epoch: 6| Step: 10
Training loss: 2.0560256603732556
Validation loss: 2.5076398585930013

Epoch: 6| Step: 11
Training loss: 2.372772175780207
Validation loss: 2.524055880898484

Epoch: 6| Step: 12
Training loss: 2.2563298515074677
Validation loss: 2.5276655124283787

Epoch: 6| Step: 13
Training loss: 2.0270848926670184
Validation loss: 2.45463690989268

Epoch: 269| Step: 0
Training loss: 1.9003234412303798
Validation loss: 2.4826632300127165

Epoch: 6| Step: 1
Training loss: 2.5288325881482576
Validation loss: 2.51977501761762

Epoch: 6| Step: 2
Training loss: 2.3574932754436877
Validation loss: 2.513000952027628

Epoch: 6| Step: 3
Training loss: 2.296757701551522
Validation loss: 2.4936376526353032

Epoch: 6| Step: 4
Training loss: 2.1659598175647052
Validation loss: 2.5280483866449353

Epoch: 6| Step: 5
Training loss: 2.0606780819452775
Validation loss: 2.4882010790858566

Epoch: 6| Step: 6
Training loss: 1.8980000309758238
Validation loss: 2.5059635467855657

Epoch: 6| Step: 7
Training loss: 2.4505522047271837
Validation loss: 2.5023930181731737

Epoch: 6| Step: 8
Training loss: 1.5295260319809285
Validation loss: 2.5080145730600414

Epoch: 6| Step: 9
Training loss: 1.9752342978460375
Validation loss: 2.493596294472282

Epoch: 6| Step: 10
Training loss: 2.046918795750453
Validation loss: 2.4903388936135826

Epoch: 6| Step: 11
Training loss: 2.3341507728668374
Validation loss: 2.4590946483499367

Epoch: 6| Step: 12
Training loss: 3.2061064451921792
Validation loss: 2.49593354182395

Epoch: 6| Step: 13
Training loss: 3.1522850588944675
Validation loss: 2.498525650322581

Epoch: 270| Step: 0
Training loss: 2.2389994961804893
Validation loss: 2.4965241500655693

Epoch: 6| Step: 1
Training loss: 1.5731894486039277
Validation loss: 2.4820529495174797

Epoch: 6| Step: 2
Training loss: 2.9747539642920535
Validation loss: 2.4951783598432846

Epoch: 6| Step: 3
Training loss: 2.365551776836183
Validation loss: 2.4929236058743354

Epoch: 6| Step: 4
Training loss: 2.0123299568320236
Validation loss: 2.523671691911936

Epoch: 6| Step: 5
Training loss: 1.861173000856565
Validation loss: 2.493315647205752

Epoch: 6| Step: 6
Training loss: 2.394644655214998
Validation loss: 2.491132927831536

Epoch: 6| Step: 7
Training loss: 2.237546364074782
Validation loss: 2.5168992106308017

Epoch: 6| Step: 8
Training loss: 2.265235604333388
Validation loss: 2.5055014866626277

Epoch: 6| Step: 9
Training loss: 2.0991336443238144
Validation loss: 2.5257192186212403

Epoch: 6| Step: 10
Training loss: 2.4986072475461674
Validation loss: 2.4960704674447656

Epoch: 6| Step: 11
Training loss: 2.7031621324050477
Validation loss: 2.519162325834078

Epoch: 6| Step: 12
Training loss: 2.283407784614882
Validation loss: 2.4923238558490453

Epoch: 6| Step: 13
Training loss: 2.02949941466991
Validation loss: 2.466324927323923

Epoch: 271| Step: 0
Training loss: 2.681653427682476
Validation loss: 2.4786561657667816

Epoch: 6| Step: 1
Training loss: 2.029035211752977
Validation loss: 2.4817989483653737

Epoch: 6| Step: 2
Training loss: 1.6343127207806405
Validation loss: 2.4949588113789294

Epoch: 6| Step: 3
Training loss: 2.6829497384998486
Validation loss: 2.481020417320297

Epoch: 6| Step: 4
Training loss: 1.941270973205261
Validation loss: 2.5189768506928525

Epoch: 6| Step: 5
Training loss: 2.5352297920645728
Validation loss: 2.4948127429363125

Epoch: 6| Step: 6
Training loss: 2.7125613930781847
Validation loss: 2.4977485763229113

Epoch: 6| Step: 7
Training loss: 1.9923665284141174
Validation loss: 2.479113720846998

Epoch: 6| Step: 8
Training loss: 2.3552666066544634
Validation loss: 2.5092732974428236

Epoch: 6| Step: 9
Training loss: 1.9026161954387952
Validation loss: 2.4767055074883175

Epoch: 6| Step: 10
Training loss: 2.246137270298484
Validation loss: 2.5029819711233654

Epoch: 6| Step: 11
Training loss: 2.784801829767982
Validation loss: 2.50330427084302

Epoch: 6| Step: 12
Training loss: 2.5051277026063894
Validation loss: 2.50779884254668

Epoch: 6| Step: 13
Training loss: 1.4901423794609943
Validation loss: 2.4973418162902785

Epoch: 272| Step: 0
Training loss: 1.8979110929851852
Validation loss: 2.482194193713311

Epoch: 6| Step: 1
Training loss: 2.2118248119410953
Validation loss: 2.5156481922741434

Epoch: 6| Step: 2
Training loss: 1.880861339785935
Validation loss: 2.5071846295433575

Epoch: 6| Step: 3
Training loss: 1.9154212333000182
Validation loss: 2.5029974728654127

Epoch: 6| Step: 4
Training loss: 2.658013151332907
Validation loss: 2.5092956473211094

Epoch: 6| Step: 5
Training loss: 2.608276684260647
Validation loss: 2.5204567986937185

Epoch: 6| Step: 6
Training loss: 1.9171962697420017
Validation loss: 2.4987577510394794

Epoch: 6| Step: 7
Training loss: 2.2406674858545004
Validation loss: 2.5131785968981313

Epoch: 6| Step: 8
Training loss: 2.362335772583821
Validation loss: 2.5201028307625513

Epoch: 6| Step: 9
Training loss: 2.498147946028778
Validation loss: 2.509973539909032

Epoch: 6| Step: 10
Training loss: 2.5603501210102073
Validation loss: 2.478288582044844

Epoch: 6| Step: 11
Training loss: 2.739946454910232
Validation loss: 2.51259264215267

Epoch: 6| Step: 12
Training loss: 2.1902473635736577
Validation loss: 2.5024051858405145

Epoch: 6| Step: 13
Training loss: 2.2137817850959713
Validation loss: 2.533933442869878

Epoch: 273| Step: 0
Training loss: 2.5498655582965473
Validation loss: 2.5314054462927196

Epoch: 6| Step: 1
Training loss: 2.5301275708147934
Validation loss: 2.518448677951333

Epoch: 6| Step: 2
Training loss: 2.773500855487852
Validation loss: 2.5129250108337793

Epoch: 6| Step: 3
Training loss: 1.3829337029223299
Validation loss: 2.503331948089293

Epoch: 6| Step: 4
Training loss: 2.4512996807442566
Validation loss: 2.4850411172517464

Epoch: 6| Step: 5
Training loss: 2.2838099499680884
Validation loss: 2.5061890651040373

Epoch: 6| Step: 6
Training loss: 2.3021220783638268
Validation loss: 2.495417009908785

Epoch: 6| Step: 7
Training loss: 1.7355063932318102
Validation loss: 2.505298287384558

Epoch: 6| Step: 8
Training loss: 1.9620133446522492
Validation loss: 2.503741612561051

Epoch: 6| Step: 9
Training loss: 3.258723508948846
Validation loss: 2.467498775828929

Epoch: 6| Step: 10
Training loss: 1.7715636449067593
Validation loss: 2.5092466777792226

Epoch: 6| Step: 11
Training loss: 2.2663178535482986
Validation loss: 2.514247220690517

Epoch: 6| Step: 12
Training loss: 1.945668934719081
Validation loss: 2.4817112925414877

Epoch: 6| Step: 13
Training loss: 2.260424518718061
Validation loss: 2.4902805034073636

Epoch: 274| Step: 0
Training loss: 2.3867031665049767
Validation loss: 2.5090777673637503

Epoch: 6| Step: 1
Training loss: 2.4594099844512813
Validation loss: 2.48679675375123

Epoch: 6| Step: 2
Training loss: 2.0991819150622497
Validation loss: 2.52166977296247

Epoch: 6| Step: 3
Training loss: 1.9725825229879632
Validation loss: 2.5017576755543125

Epoch: 6| Step: 4
Training loss: 1.7088028642448252
Validation loss: 2.518592553151761

Epoch: 6| Step: 5
Training loss: 2.3448404445740554
Validation loss: 2.504326004675123

Epoch: 6| Step: 6
Training loss: 2.367238059936023
Validation loss: 2.53319835334278

Epoch: 6| Step: 7
Training loss: 2.098675868967054
Validation loss: 2.4944503581195625

Epoch: 6| Step: 8
Training loss: 2.516398245873641
Validation loss: 2.4802701026103353

Epoch: 6| Step: 9
Training loss: 1.9660885699356332
Validation loss: 2.4907973347531334

Epoch: 6| Step: 10
Training loss: 1.855516164073474
Validation loss: 2.5287213706711107

Epoch: 6| Step: 11
Training loss: 2.993572980071092
Validation loss: 2.526741377640762

Epoch: 6| Step: 12
Training loss: 2.7169578170000928
Validation loss: 2.5061988350309456

Epoch: 6| Step: 13
Training loss: 2.2041663556257967
Validation loss: 2.506912374027625

Epoch: 275| Step: 0
Training loss: 3.0356649122310233
Validation loss: 2.48802329429661

Epoch: 6| Step: 1
Training loss: 1.9325825831248542
Validation loss: 2.520511283903429

Epoch: 6| Step: 2
Training loss: 2.717753786872006
Validation loss: 2.533178355801395

Epoch: 6| Step: 3
Training loss: 2.2097335071330177
Validation loss: 2.493712793332184

Epoch: 6| Step: 4
Training loss: 1.8913309970209757
Validation loss: 2.5097353260881077

Epoch: 6| Step: 5
Training loss: 2.2411026406977834
Validation loss: 2.530493680625274

Epoch: 6| Step: 6
Training loss: 2.0962084101518874
Validation loss: 2.5240944318678222

Epoch: 6| Step: 7
Training loss: 2.615835814372046
Validation loss: 2.502878061394711

Epoch: 6| Step: 8
Training loss: 2.480741903328554
Validation loss: 2.516640332581383

Epoch: 6| Step: 9
Training loss: 1.8996067292628218
Validation loss: 2.5200234005849595

Epoch: 6| Step: 10
Training loss: 2.3688068956773978
Validation loss: 2.489425367555291

Epoch: 6| Step: 11
Training loss: 1.6482052029192773
Validation loss: 2.5134358558080723

Epoch: 6| Step: 12
Training loss: 2.2015797491866627
Validation loss: 2.5069494287060676

Epoch: 6| Step: 13
Training loss: 2.35878336985423
Validation loss: 2.5245331966173032

Epoch: 276| Step: 0
Training loss: 2.826830319969338
Validation loss: 2.530274533768303

Epoch: 6| Step: 1
Training loss: 1.6690280239799218
Validation loss: 2.531778178932685

Epoch: 6| Step: 2
Training loss: 2.373729767675489
Validation loss: 2.516612761969496

Epoch: 6| Step: 3
Training loss: 2.791129663165139
Validation loss: 2.49237324943133

Epoch: 6| Step: 4
Training loss: 2.1122049069128264
Validation loss: 2.522763800491167

Epoch: 6| Step: 5
Training loss: 2.3585732215576805
Validation loss: 2.5214088977482385

Epoch: 6| Step: 6
Training loss: 2.530369358165941
Validation loss: 2.473312364752001

Epoch: 6| Step: 7
Training loss: 1.7538538459816357
Validation loss: 2.4941233177438016

Epoch: 6| Step: 8
Training loss: 2.2232030320005824
Validation loss: 2.4807455440536605

Epoch: 6| Step: 9
Training loss: 2.4645879887859095
Validation loss: 2.489616247258093

Epoch: 6| Step: 10
Training loss: 1.9637063831752242
Validation loss: 2.50169526426709

Epoch: 6| Step: 11
Training loss: 1.9552753665294587
Validation loss: 2.5302814842198726

Epoch: 6| Step: 12
Training loss: 2.107067513215707
Validation loss: 2.4946701301419827

Epoch: 6| Step: 13
Training loss: 2.463851704890911
Validation loss: 2.52099998802586

Epoch: 277| Step: 0
Training loss: 2.2261499926269237
Validation loss: 2.4966897583659526

Epoch: 6| Step: 1
Training loss: 2.0802968084870406
Validation loss: 2.4856112110613244

Epoch: 6| Step: 2
Training loss: 1.846539601500181
Validation loss: 2.500276401581034

Epoch: 6| Step: 3
Training loss: 2.392411704990242
Validation loss: 2.5182656835884054

Epoch: 6| Step: 4
Training loss: 2.9956794462264242
Validation loss: 2.470422235770686

Epoch: 6| Step: 5
Training loss: 2.7515842036139175
Validation loss: 2.5292369647130104

Epoch: 6| Step: 6
Training loss: 2.02175739305941
Validation loss: 2.501979876569092

Epoch: 6| Step: 7
Training loss: 2.550830320672
Validation loss: 2.5013009019391212

Epoch: 6| Step: 8
Training loss: 1.0339871120092399
Validation loss: 2.494602276761195

Epoch: 6| Step: 9
Training loss: 2.7771730008331126
Validation loss: 2.5077751851263095

Epoch: 6| Step: 10
Training loss: 2.2713315458045304
Validation loss: 2.5167518007509155

Epoch: 6| Step: 11
Training loss: 2.3964375162556664
Validation loss: 2.4810144159013987

Epoch: 6| Step: 12
Training loss: 2.0056164082705403
Validation loss: 2.510700612295455

Epoch: 6| Step: 13
Training loss: 1.6430217855893277
Validation loss: 2.4988289438618714

Epoch: 278| Step: 0
Training loss: 1.77069861703699
Validation loss: 2.527448694694245

Epoch: 6| Step: 1
Training loss: 2.345078765587434
Validation loss: 2.5161153215747856

Epoch: 6| Step: 2
Training loss: 1.849412788812068
Validation loss: 2.539854430075098

Epoch: 6| Step: 3
Training loss: 1.9927513371832681
Validation loss: 2.4945815387053853

Epoch: 6| Step: 4
Training loss: 2.654461247152476
Validation loss: 2.5070220025443497

Epoch: 6| Step: 5
Training loss: 2.53392753743149
Validation loss: 2.498292809219797

Epoch: 6| Step: 6
Training loss: 2.2533129567385575
Validation loss: 2.5140228377057965

Epoch: 6| Step: 7
Training loss: 2.0004260086300163
Validation loss: 2.519377336175395

Epoch: 6| Step: 8
Training loss: 2.035006175301295
Validation loss: 2.4847390100449314

Epoch: 6| Step: 9
Training loss: 2.1473368096657564
Validation loss: 2.502852973650425

Epoch: 6| Step: 10
Training loss: 2.79330267343864
Validation loss: 2.5061109017602337

Epoch: 6| Step: 11
Training loss: 2.3562929346842614
Validation loss: 2.546562591382358

Epoch: 6| Step: 12
Training loss: 2.3328285579550303
Validation loss: 2.483081323694484

Epoch: 6| Step: 13
Training loss: 2.707021385714351
Validation loss: 2.511128509809804

Epoch: 279| Step: 0
Training loss: 2.4360203286624054
Validation loss: 2.5291556066085503

Epoch: 6| Step: 1
Training loss: 2.8745043783481314
Validation loss: 2.5219172851816944

Epoch: 6| Step: 2
Training loss: 2.324663289617491
Validation loss: 2.5240950118138876

Epoch: 6| Step: 3
Training loss: 1.7044445840293123
Validation loss: 2.515534713389596

Epoch: 6| Step: 4
Training loss: 2.3192069248657954
Validation loss: 2.5213874076442604

Epoch: 6| Step: 5
Training loss: 2.2181618139200654
Validation loss: 2.4816638685163133

Epoch: 6| Step: 6
Training loss: 1.7345459999809185
Validation loss: 2.507432306371102

Epoch: 6| Step: 7
Training loss: 2.254395958972501
Validation loss: 2.499914347299091

Epoch: 6| Step: 8
Training loss: 2.286777436415965
Validation loss: 2.483243820304329

Epoch: 6| Step: 9
Training loss: 2.3596904619532006
Validation loss: 2.508365749356396

Epoch: 6| Step: 10
Training loss: 2.4879534399146923
Validation loss: 2.503767642616679

Epoch: 6| Step: 11
Training loss: 1.7568926629773467
Validation loss: 2.48423805202471

Epoch: 6| Step: 12
Training loss: 2.7704534246291797
Validation loss: 2.5007419039085197

Epoch: 6| Step: 13
Training loss: 2.043910901563239
Validation loss: 2.5089693904488373

Epoch: 280| Step: 0
Training loss: 2.1560653386309516
Validation loss: 2.5344077562851632

Epoch: 6| Step: 1
Training loss: 2.441571869382381
Validation loss: 2.480936776402208

Epoch: 6| Step: 2
Training loss: 2.352282239704558
Validation loss: 2.498914228534844

Epoch: 6| Step: 3
Training loss: 2.4048513335596104
Validation loss: 2.511375809423668

Epoch: 6| Step: 4
Training loss: 1.9117568473309179
Validation loss: 2.518069392841349

Epoch: 6| Step: 5
Training loss: 2.8481659191106132
Validation loss: 2.5084280427122128

Epoch: 6| Step: 6
Training loss: 1.515435905065219
Validation loss: 2.5006006349939502

Epoch: 6| Step: 7
Training loss: 2.597989948608595
Validation loss: 2.539832048312879

Epoch: 6| Step: 8
Training loss: 2.025469492422408
Validation loss: 2.4948663896671346

Epoch: 6| Step: 9
Training loss: 1.2252371363872323
Validation loss: 2.510493034338506

Epoch: 6| Step: 10
Training loss: 2.2627275552703825
Validation loss: 2.498014509691211

Epoch: 6| Step: 11
Training loss: 2.6575798744693584
Validation loss: 2.527094937149864

Epoch: 6| Step: 12
Training loss: 2.1379958665128025
Validation loss: 2.523416768808639

Epoch: 6| Step: 13
Training loss: 3.1235036700797956
Validation loss: 2.5630878151455807

Epoch: 281| Step: 0
Training loss: 2.814942803758868
Validation loss: 2.5184623702837396

Epoch: 6| Step: 1
Training loss: 1.4559243423381563
Validation loss: 2.5123208313640277

Epoch: 6| Step: 2
Training loss: 2.463842028210824
Validation loss: 2.5101086037697162

Epoch: 6| Step: 3
Training loss: 2.308844073516128
Validation loss: 2.494429781698512

Epoch: 6| Step: 4
Training loss: 1.6116734360109253
Validation loss: 2.497257576360702

Epoch: 6| Step: 5
Training loss: 1.899009210348267
Validation loss: 2.495153797793667

Epoch: 6| Step: 6
Training loss: 2.8902082813011516
Validation loss: 2.492554898716783

Epoch: 6| Step: 7
Training loss: 2.4086243445933864
Validation loss: 2.497011694695217

Epoch: 6| Step: 8
Training loss: 2.370406678151287
Validation loss: 2.5029982922478515

Epoch: 6| Step: 9
Training loss: 2.3837570569594555
Validation loss: 2.4886476240527924

Epoch: 6| Step: 10
Training loss: 1.828326091954865
Validation loss: 2.4731169240724005

Epoch: 6| Step: 11
Training loss: 2.841151800711729
Validation loss: 2.5063384704465625

Epoch: 6| Step: 12
Training loss: 2.396769387754565
Validation loss: 2.4949215899183286

Epoch: 6| Step: 13
Training loss: 1.5664832650370426
Validation loss: 2.4819013338768676

Epoch: 282| Step: 0
Training loss: 2.331226408074588
Validation loss: 2.516241671767854

Epoch: 6| Step: 1
Training loss: 2.646018935374398
Validation loss: 2.4669980714773483

Epoch: 6| Step: 2
Training loss: 2.0670745288200263
Validation loss: 2.5153576955940316

Epoch: 6| Step: 3
Training loss: 2.8231120493559927
Validation loss: 2.5009447312383792

Epoch: 6| Step: 4
Training loss: 1.7024712664046198
Validation loss: 2.4895865475144765

Epoch: 6| Step: 5
Training loss: 1.9176695176533332
Validation loss: 2.536152162047311

Epoch: 6| Step: 6
Training loss: 2.2508111127509576
Validation loss: 2.511185322906762

Epoch: 6| Step: 7
Training loss: 2.0338512490642753
Validation loss: 2.501718089697442

Epoch: 6| Step: 8
Training loss: 2.279838647988988
Validation loss: 2.4970883467333818

Epoch: 6| Step: 9
Training loss: 2.1217860432153834
Validation loss: 2.5037195745520333

Epoch: 6| Step: 10
Training loss: 1.9279146892778478
Validation loss: 2.490775874903002

Epoch: 6| Step: 11
Training loss: 2.742656787156612
Validation loss: 2.5290238397491955

Epoch: 6| Step: 12
Training loss: 2.603964306916348
Validation loss: 2.534359270954399

Epoch: 6| Step: 13
Training loss: 2.2563916655893896
Validation loss: 2.5236180083862942

Epoch: 283| Step: 0
Training loss: 2.738116685218612
Validation loss: 2.552747687600004

Epoch: 6| Step: 1
Training loss: 2.5681046392209725
Validation loss: 2.5222101305250635

Epoch: 6| Step: 2
Training loss: 2.925056561306263
Validation loss: 2.5159080466897263

Epoch: 6| Step: 3
Training loss: 1.7076414924854426
Validation loss: 2.5223294073603815

Epoch: 6| Step: 4
Training loss: 2.46776802717551
Validation loss: 2.479858475292959

Epoch: 6| Step: 5
Training loss: 2.2159672869529694
Validation loss: 2.522795327998304

Epoch: 6| Step: 6
Training loss: 2.2852388807175847
Validation loss: 2.4883302787537445

Epoch: 6| Step: 7
Training loss: 1.8544015485600744
Validation loss: 2.5022179885883133

Epoch: 6| Step: 8
Training loss: 1.9673567186312466
Validation loss: 2.507752580437678

Epoch: 6| Step: 9
Training loss: 2.2321674672541207
Validation loss: 2.5105733807652637

Epoch: 6| Step: 10
Training loss: 2.4071164243313294
Validation loss: 2.512514272943243

Epoch: 6| Step: 11
Training loss: 2.5746655922934716
Validation loss: 2.534376444044304

Epoch: 6| Step: 12
Training loss: 1.5620961239503846
Validation loss: 2.517510393124933

Epoch: 6| Step: 13
Training loss: 1.4309444217885197
Validation loss: 2.5140280730270996

Epoch: 284| Step: 0
Training loss: 2.294362672893731
Validation loss: 2.4976473998343165

Epoch: 6| Step: 1
Training loss: 1.866042164946613
Validation loss: 2.5034169994806406

Epoch: 6| Step: 2
Training loss: 1.498215567628691
Validation loss: 2.5093617762942784

Epoch: 6| Step: 3
Training loss: 2.355061712570061
Validation loss: 2.4781432451815526

Epoch: 6| Step: 4
Training loss: 2.759296655460756
Validation loss: 2.499550686729427

Epoch: 6| Step: 5
Training loss: 2.942910912666671
Validation loss: 2.498621586757314

Epoch: 6| Step: 6
Training loss: 2.2822628124461177
Validation loss: 2.5125226535631935

Epoch: 6| Step: 7
Training loss: 2.252839945248817
Validation loss: 2.4960406811920732

Epoch: 6| Step: 8
Training loss: 2.114533735423346
Validation loss: 2.495281781646619

Epoch: 6| Step: 9
Training loss: 2.7931224860715447
Validation loss: 2.488352011077576

Epoch: 6| Step: 10
Training loss: 1.9161283594032714
Validation loss: 2.4855462247520284

Epoch: 6| Step: 11
Training loss: 2.0616033512385776
Validation loss: 2.4892919466592764

Epoch: 6| Step: 12
Training loss: 2.074741908188993
Validation loss: 2.4941222405332457

Epoch: 6| Step: 13
Training loss: 2.6621969632624127
Validation loss: 2.5058798279012824

Epoch: 285| Step: 0
Training loss: 2.8750900586162182
Validation loss: 2.5054681494119113

Epoch: 6| Step: 1
Training loss: 1.404317842414531
Validation loss: 2.472627174952864

Epoch: 6| Step: 2
Training loss: 2.5534186989214973
Validation loss: 2.4973581198685086

Epoch: 6| Step: 3
Training loss: 2.210086510462436
Validation loss: 2.5127502680007527

Epoch: 6| Step: 4
Training loss: 2.0038705566082857
Validation loss: 2.5221558512535394

Epoch: 6| Step: 5
Training loss: 2.3041509488646374
Validation loss: 2.4990753371173864

Epoch: 6| Step: 6
Training loss: 2.779430951807049
Validation loss: 2.5205269321129795

Epoch: 6| Step: 7
Training loss: 2.318997508203534
Validation loss: 2.4854994566614557

Epoch: 6| Step: 8
Training loss: 2.1280108047297097
Validation loss: 2.487437388419045

Epoch: 6| Step: 9
Training loss: 2.057433407564507
Validation loss: 2.487266087851453

Epoch: 6| Step: 10
Training loss: 1.8613264598218549
Validation loss: 2.4959335274441727

Epoch: 6| Step: 11
Training loss: 2.2362417679150597
Validation loss: 2.47763931871106

Epoch: 6| Step: 12
Training loss: 2.494958944957597
Validation loss: 2.4878023013464654

Epoch: 6| Step: 13
Training loss: 2.271154771738902
Validation loss: 2.522312687883496

Epoch: 286| Step: 0
Training loss: 2.0439295651940568
Validation loss: 2.5099031238566507

Epoch: 6| Step: 1
Training loss: 1.7248492133538436
Validation loss: 2.4971835401948783

Epoch: 6| Step: 2
Training loss: 1.8311807248288912
Validation loss: 2.517888513145162

Epoch: 6| Step: 3
Training loss: 2.403586362445377
Validation loss: 2.5075483643380165

Epoch: 6| Step: 4
Training loss: 2.3142098987109505
Validation loss: 2.510261257833059

Epoch: 6| Step: 5
Training loss: 1.8772210635491215
Validation loss: 2.495021968630329

Epoch: 6| Step: 6
Training loss: 3.0928377289950904
Validation loss: 2.552487481776259

Epoch: 6| Step: 7
Training loss: 2.036038666888221
Validation loss: 2.521078991359051

Epoch: 6| Step: 8
Training loss: 2.630916014290321
Validation loss: 2.5020475283387897

Epoch: 6| Step: 9
Training loss: 2.2638709282763934
Validation loss: 2.5310233280643843

Epoch: 6| Step: 10
Training loss: 1.7728574367122027
Validation loss: 2.486285831183302

Epoch: 6| Step: 11
Training loss: 2.8145456292266826
Validation loss: 2.492799633137064

Epoch: 6| Step: 12
Training loss: 2.0542363008634514
Validation loss: 2.515281826574029

Epoch: 6| Step: 13
Training loss: 2.373002266170225
Validation loss: 2.5110957301609504

Epoch: 287| Step: 0
Training loss: 1.923984703237114
Validation loss: 2.4896738611966556

Epoch: 6| Step: 1
Training loss: 2.3828183033356582
Validation loss: 2.5051389277870855

Epoch: 6| Step: 2
Training loss: 1.9525820778606136
Validation loss: 2.5377743425453705

Epoch: 6| Step: 3
Training loss: 2.0724404968628436
Validation loss: 2.4928395961214975

Epoch: 6| Step: 4
Training loss: 2.7123376050583152
Validation loss: 2.4994452937832556

Epoch: 6| Step: 5
Training loss: 2.1276213241750686
Validation loss: 2.501964076496601

Epoch: 6| Step: 6
Training loss: 2.474390274621232
Validation loss: 2.5152579011491105

Epoch: 6| Step: 7
Training loss: 2.3396434156856114
Validation loss: 2.4750779210603744

Epoch: 6| Step: 8
Training loss: 1.9632143579237804
Validation loss: 2.471912381977059

Epoch: 6| Step: 9
Training loss: 1.9559177421209415
Validation loss: 2.50700139023354

Epoch: 6| Step: 10
Training loss: 2.8376651262138513
Validation loss: 2.4805880010747487

Epoch: 6| Step: 11
Training loss: 2.0935436545649906
Validation loss: 2.519039396096836

Epoch: 6| Step: 12
Training loss: 2.39744383267829
Validation loss: 2.5044079498199667

Epoch: 6| Step: 13
Training loss: 2.403464451342263
Validation loss: 2.50571558921564

Epoch: 288| Step: 0
Training loss: 2.1271342611116304
Validation loss: 2.522251586146231

Epoch: 6| Step: 1
Training loss: 1.499050078015513
Validation loss: 2.496853400753581

Epoch: 6| Step: 2
Training loss: 2.212236541751943
Validation loss: 2.494584149534306

Epoch: 6| Step: 3
Training loss: 3.0543681024075804
Validation loss: 2.5153606018276307

Epoch: 6| Step: 4
Training loss: 2.020707221536781
Validation loss: 2.5067420586296207

Epoch: 6| Step: 5
Training loss: 1.9127006824394266
Validation loss: 2.4937525293957963

Epoch: 6| Step: 6
Training loss: 1.9689907350646696
Validation loss: 2.5142406725191737

Epoch: 6| Step: 7
Training loss: 2.4694940918417103
Validation loss: 2.4811285364709614

Epoch: 6| Step: 8
Training loss: 1.9310428940420694
Validation loss: 2.5154906573124083

Epoch: 6| Step: 9
Training loss: 2.746287788058208
Validation loss: 2.5080082953378793

Epoch: 6| Step: 10
Training loss: 2.7890019770875463
Validation loss: 2.51937146377703

Epoch: 6| Step: 11
Training loss: 1.7630537096693086
Validation loss: 2.4756778301372697

Epoch: 6| Step: 12
Training loss: 2.2124283687396975
Validation loss: 2.5212686627735272

Epoch: 6| Step: 13
Training loss: 2.1405957073796986
Validation loss: 2.4922050428909426

Epoch: 289| Step: 0
Training loss: 2.3774660257665756
Validation loss: 2.5190347746912227

Epoch: 6| Step: 1
Training loss: 2.007934447863706
Validation loss: 2.473171007210453

Epoch: 6| Step: 2
Training loss: 2.2190233518894003
Validation loss: 2.511132111583923

Epoch: 6| Step: 3
Training loss: 2.760318557627235
Validation loss: 2.4870692079558507

Epoch: 6| Step: 4
Training loss: 2.029945189201149
Validation loss: 2.521393790842451

Epoch: 6| Step: 5
Training loss: 2.3734774477562084
Validation loss: 2.515474831016036

Epoch: 6| Step: 6
Training loss: 2.351592003520017
Validation loss: 2.508702445788367

Epoch: 6| Step: 7
Training loss: 1.9146712600171203
Validation loss: 2.5079392674677488

Epoch: 6| Step: 8
Training loss: 2.9445777199130605
Validation loss: 2.4749250649860297

Epoch: 6| Step: 9
Training loss: 2.2621241389039666
Validation loss: 2.5153838001067172

Epoch: 6| Step: 10
Training loss: 1.8647148966770448
Validation loss: 2.5025768228383094

Epoch: 6| Step: 11
Training loss: 2.642026630830503
Validation loss: 2.5114398594076928

Epoch: 6| Step: 12
Training loss: 1.991398015385001
Validation loss: 2.4840066251911295

Epoch: 6| Step: 13
Training loss: 1.4497104849024203
Validation loss: 2.4955296222766954

Epoch: 290| Step: 0
Training loss: 2.656011413630125
Validation loss: 2.5039787420847195

Epoch: 6| Step: 1
Training loss: 1.9218694175080888
Validation loss: 2.490512020968886

Epoch: 6| Step: 2
Training loss: 1.3198294574211609
Validation loss: 2.520631788375585

Epoch: 6| Step: 3
Training loss: 2.520908281037088
Validation loss: 2.499383846360715

Epoch: 6| Step: 4
Training loss: 2.614689696885375
Validation loss: 2.5230882025039088

Epoch: 6| Step: 5
Training loss: 2.1913313963374454
Validation loss: 2.4995695963934157

Epoch: 6| Step: 6
Training loss: 1.7499106248103697
Validation loss: 2.528295684065712

Epoch: 6| Step: 7
Training loss: 1.9489607095491517
Validation loss: 2.492832720217827

Epoch: 6| Step: 8
Training loss: 2.0001876266208156
Validation loss: 2.515923299640007

Epoch: 6| Step: 9
Training loss: 2.2555492633842475
Validation loss: 2.496660702388555

Epoch: 6| Step: 10
Training loss: 2.6922937267067013
Validation loss: 2.5128577819870257

Epoch: 6| Step: 11
Training loss: 2.383299930934211
Validation loss: 2.4879332981847293

Epoch: 6| Step: 12
Training loss: 2.6028727763003925
Validation loss: 2.51343542741872

Epoch: 6| Step: 13
Training loss: 2.2745258046697114
Validation loss: 2.4871214755643827

Epoch: 291| Step: 0
Training loss: 2.040413478386369
Validation loss: 2.509889484929279

Epoch: 6| Step: 1
Training loss: 2.4965078759553374
Validation loss: 2.498399383098809

Epoch: 6| Step: 2
Training loss: 1.6370078766947322
Validation loss: 2.521684663704281

Epoch: 6| Step: 3
Training loss: 2.51648569487946
Validation loss: 2.492242726668718

Epoch: 6| Step: 4
Training loss: 2.0416718956497597
Validation loss: 2.4979085018252327

Epoch: 6| Step: 5
Training loss: 2.463779128863867
Validation loss: 2.5218906495473483

Epoch: 6| Step: 6
Training loss: 2.20888982514827
Validation loss: 2.526337751351064

Epoch: 6| Step: 7
Training loss: 2.375698990606707
Validation loss: 2.5179711704599437

Epoch: 6| Step: 8
Training loss: 1.732800705700182
Validation loss: 2.5054527028621956

Epoch: 6| Step: 9
Training loss: 2.287433552428333
Validation loss: 2.499471141907939

Epoch: 6| Step: 10
Training loss: 2.422041758056825
Validation loss: 2.515612487619179

Epoch: 6| Step: 11
Training loss: 2.160315840553141
Validation loss: 2.5239141952381434

Epoch: 6| Step: 12
Training loss: 2.7158898403316902
Validation loss: 2.5252155955520696

Epoch: 6| Step: 13
Training loss: 2.552264356356246
Validation loss: 2.519704187691411

Epoch: 292| Step: 0
Training loss: 2.624833419600538
Validation loss: 2.511676927622556

Epoch: 6| Step: 1
Training loss: 1.7199740126221266
Validation loss: 2.4881229982327526

Epoch: 6| Step: 2
Training loss: 1.861664076245224
Validation loss: 2.5229935393460825

Epoch: 6| Step: 3
Training loss: 2.240082606767894
Validation loss: 2.4942077817318657

Epoch: 6| Step: 4
Training loss: 1.7211413999827967
Validation loss: 2.4959588285345293

Epoch: 6| Step: 5
Training loss: 1.8043519736162879
Validation loss: 2.4605155493237834

Epoch: 6| Step: 6
Training loss: 2.970579527240625
Validation loss: 2.5272362963836654

Epoch: 6| Step: 7
Training loss: 2.34123379743991
Validation loss: 2.5023509897324523

Epoch: 6| Step: 8
Training loss: 2.371304095771781
Validation loss: 2.476499972905164

Epoch: 6| Step: 9
Training loss: 2.1725152259003386
Validation loss: 2.4785430706796334

Epoch: 6| Step: 10
Training loss: 2.4393532383598284
Validation loss: 2.5176754559576424

Epoch: 6| Step: 11
Training loss: 2.6544499300518636
Validation loss: 2.4718684735366336

Epoch: 6| Step: 12
Training loss: 1.8282251575127446
Validation loss: 2.5163009847144355

Epoch: 6| Step: 13
Training loss: 2.639800987111793
Validation loss: 2.503163077919854

Epoch: 293| Step: 0
Training loss: 2.198874953180126
Validation loss: 2.4927727840772285

Epoch: 6| Step: 1
Training loss: 2.663741374867804
Validation loss: 2.4855600323253983

Epoch: 6| Step: 2
Training loss: 1.280339824896096
Validation loss: 2.4999219615610557

Epoch: 6| Step: 3
Training loss: 1.670842145799845
Validation loss: 2.4907052742937275

Epoch: 6| Step: 4
Training loss: 2.3536830731731175
Validation loss: 2.5024694859139593

Epoch: 6| Step: 5
Training loss: 2.482916637851053
Validation loss: 2.5072373934572387

Epoch: 6| Step: 6
Training loss: 2.1103288542493543
Validation loss: 2.4962921271727807

Epoch: 6| Step: 7
Training loss: 2.6468178626945242
Validation loss: 2.497169390863605

Epoch: 6| Step: 8
Training loss: 2.839107706636938
Validation loss: 2.4963628275426286

Epoch: 6| Step: 9
Training loss: 2.1959025720131407
Validation loss: 2.510347607322723

Epoch: 6| Step: 10
Training loss: 2.210212076290458
Validation loss: 2.480966180829724

Epoch: 6| Step: 11
Training loss: 1.5853235719528385
Validation loss: 2.500730158714148

Epoch: 6| Step: 12
Training loss: 2.501923584000563
Validation loss: 2.492139769215458

Epoch: 6| Step: 13
Training loss: 2.529058944528075
Validation loss: 2.5073367484641214

Epoch: 294| Step: 0
Training loss: 2.863529376719053
Validation loss: 2.469246177506034

Epoch: 6| Step: 1
Training loss: 1.692419792427233
Validation loss: 2.5371519472289004

Epoch: 6| Step: 2
Training loss: 2.3101122101451943
Validation loss: 2.5104040806701233

Epoch: 6| Step: 3
Training loss: 2.2264789766406623
Validation loss: 2.5475245224500216

Epoch: 6| Step: 4
Training loss: 2.0052114775661902
Validation loss: 2.495781641558085

Epoch: 6| Step: 5
Training loss: 1.7814503607246064
Validation loss: 2.5046140566137547

Epoch: 6| Step: 6
Training loss: 2.444767120285779
Validation loss: 2.5352440672253787

Epoch: 6| Step: 7
Training loss: 2.572268405643429
Validation loss: 2.499491089634123

Epoch: 6| Step: 8
Training loss: 2.173556328822188
Validation loss: 2.5192372353955474

Epoch: 6| Step: 9
Training loss: 2.5776400023213837
Validation loss: 2.51206576670697

Epoch: 6| Step: 10
Training loss: 2.738048244254694
Validation loss: 2.5044496735023554

Epoch: 6| Step: 11
Training loss: 1.5142632098466462
Validation loss: 2.509333900439249

Epoch: 6| Step: 12
Training loss: 1.7886123424052567
Validation loss: 2.499390546283262

Epoch: 6| Step: 13
Training loss: 2.5919355917333933
Validation loss: 2.4754501601646925

Epoch: 295| Step: 0
Training loss: 2.0556049111887527
Validation loss: 2.4904935757470703

Epoch: 6| Step: 1
Training loss: 2.1663264472094013
Validation loss: 2.487773109622524

Epoch: 6| Step: 2
Training loss: 1.862965427079933
Validation loss: 2.493879408131885

Epoch: 6| Step: 3
Training loss: 2.205012169283202
Validation loss: 2.4875787463322823

Epoch: 6| Step: 4
Training loss: 1.1632888066114904
Validation loss: 2.5245237657351565

Epoch: 6| Step: 5
Training loss: 2.6673261502502994
Validation loss: 2.519918331814227

Epoch: 6| Step: 6
Training loss: 2.4338817640313137
Validation loss: 2.4987919052160765

Epoch: 6| Step: 7
Training loss: 2.5508513506710293
Validation loss: 2.518761867742667

Epoch: 6| Step: 8
Training loss: 2.025698896765071
Validation loss: 2.5073355440110716

Epoch: 6| Step: 9
Training loss: 2.1885552177269916
Validation loss: 2.4653647543838066

Epoch: 6| Step: 10
Training loss: 2.296002592111912
Validation loss: 2.5115940657141675

Epoch: 6| Step: 11
Training loss: 2.2930153317244604
Validation loss: 2.4547590544616096

Epoch: 6| Step: 12
Training loss: 2.5752681740676016
Validation loss: 2.5058982365973583

Epoch: 6| Step: 13
Training loss: 2.892853738557404
Validation loss: 2.51394946558032

Epoch: 296| Step: 0
Training loss: 2.662144303180162
Validation loss: 2.5027153261315154

Epoch: 6| Step: 1
Training loss: 2.554643823092803
Validation loss: 2.4991265350256544

Epoch: 6| Step: 2
Training loss: 2.404232219505349
Validation loss: 2.511268437182098

Epoch: 6| Step: 3
Training loss: 2.8436342991358226
Validation loss: 2.471857799406245

Epoch: 6| Step: 4
Training loss: 2.412985354603961
Validation loss: 2.4937641696988435

Epoch: 6| Step: 5
Training loss: 2.010659185088697
Validation loss: 2.522237702969785

Epoch: 6| Step: 6
Training loss: 2.0898395288727816
Validation loss: 2.481642086920222

Epoch: 6| Step: 7
Training loss: 2.4786882873947897
Validation loss: 2.4891368664546163

Epoch: 6| Step: 8
Training loss: 1.8004142072725997
Validation loss: 2.5085199259354054

Epoch: 6| Step: 9
Training loss: 1.5086052742532219
Validation loss: 2.5073333508416806

Epoch: 6| Step: 10
Training loss: 2.2237188015186495
Validation loss: 2.4745272651369583

Epoch: 6| Step: 11
Training loss: 1.923626171685061
Validation loss: 2.45941146671569

Epoch: 6| Step: 12
Training loss: 2.161677840396862
Validation loss: 2.4828823282806263

Epoch: 6| Step: 13
Training loss: 2.127966661206433
Validation loss: 2.4744532202314424

Epoch: 297| Step: 0
Training loss: 2.11461931270063
Validation loss: 2.511654456546653

Epoch: 6| Step: 1
Training loss: 1.9133243928206414
Validation loss: 2.4905272287296962

Epoch: 6| Step: 2
Training loss: 1.8238627639850529
Validation loss: 2.4974195514357524

Epoch: 6| Step: 3
Training loss: 2.7509978824719648
Validation loss: 2.5126749160963073

Epoch: 6| Step: 4
Training loss: 2.615475040270753
Validation loss: 2.4980869644215424

Epoch: 6| Step: 5
Training loss: 1.8755562275141577
Validation loss: 2.493971178730763

Epoch: 6| Step: 6
Training loss: 2.127672646462075
Validation loss: 2.5200049465454484

Epoch: 6| Step: 7
Training loss: 2.180626123613378
Validation loss: 2.4866457387006204

Epoch: 6| Step: 8
Training loss: 1.957298519439909
Validation loss: 2.5239370269388686

Epoch: 6| Step: 9
Training loss: 2.2597559184374507
Validation loss: 2.5115074212088673

Epoch: 6| Step: 10
Training loss: 2.544308357912146
Validation loss: 2.535392543547091

Epoch: 6| Step: 11
Training loss: 2.2407072810304105
Validation loss: 2.47655738422961

Epoch: 6| Step: 12
Training loss: 2.6618082571697403
Validation loss: 2.5233956798330324

Epoch: 6| Step: 13
Training loss: 1.885320994722997
Validation loss: 2.495999663273405

Epoch: 298| Step: 0
Training loss: 1.8521052985360293
Validation loss: 2.516075277924362

Epoch: 6| Step: 1
Training loss: 2.3022464562068907
Validation loss: 2.5068923140620565

Epoch: 6| Step: 2
Training loss: 2.2559677031958034
Validation loss: 2.500143490026685

Epoch: 6| Step: 3
Training loss: 1.8830847325721662
Validation loss: 2.522298360372466

Epoch: 6| Step: 4
Training loss: 1.9976800934312602
Validation loss: 2.4751155579770594

Epoch: 6| Step: 5
Training loss: 2.4216785966544743
Validation loss: 2.4922114689442276

Epoch: 6| Step: 6
Training loss: 2.809437589192171
Validation loss: 2.486176920107818

Epoch: 6| Step: 7
Training loss: 1.5016995973747929
Validation loss: 2.4954839422387534

Epoch: 6| Step: 8
Training loss: 2.419274687721185
Validation loss: 2.5028412803587416

Epoch: 6| Step: 9
Training loss: 2.867319046869484
Validation loss: 2.508229272125831

Epoch: 6| Step: 10
Training loss: 2.7060677270977784
Validation loss: 2.498006417528786

Epoch: 6| Step: 11
Training loss: 2.1526853425338226
Validation loss: 2.494655250794605

Epoch: 6| Step: 12
Training loss: 1.6424500985889892
Validation loss: 2.518532217223787

Epoch: 6| Step: 13
Training loss: 1.9504861934694429
Validation loss: 2.5109862846061715

Epoch: 299| Step: 0
Training loss: 2.586631474337464
Validation loss: 2.48728165352813

Epoch: 6| Step: 1
Training loss: 2.367850534980166
Validation loss: 2.474433864795148

Epoch: 6| Step: 2
Training loss: 1.8162384940174787
Validation loss: 2.480026092706286

Epoch: 6| Step: 3
Training loss: 2.6646500552018106
Validation loss: 2.478972229778661

Epoch: 6| Step: 4
Training loss: 2.0907486997310905
Validation loss: 2.533956163048188

Epoch: 6| Step: 5
Training loss: 1.6696587249258297
Validation loss: 2.50670723039987

Epoch: 6| Step: 6
Training loss: 1.6071281674637135
Validation loss: 2.503570701557738

Epoch: 6| Step: 7
Training loss: 2.6827069501159078
Validation loss: 2.4890731942407904

Epoch: 6| Step: 8
Training loss: 2.1697082689080505
Validation loss: 2.493276198764949

Epoch: 6| Step: 9
Training loss: 2.593621675924835
Validation loss: 2.487729262655027

Epoch: 6| Step: 10
Training loss: 1.8126028623660824
Validation loss: 2.5270398817220707

Epoch: 6| Step: 11
Training loss: 2.320228138427203
Validation loss: 2.510274754828023

Epoch: 6| Step: 12
Training loss: 2.298076289544879
Validation loss: 2.478581215061628

Epoch: 6| Step: 13
Training loss: 1.6593331484357077
Validation loss: 2.5168394860095127

Epoch: 300| Step: 0
Training loss: 2.354648225756732
Validation loss: 2.484350859481596

Epoch: 6| Step: 1
Training loss: 1.7185421904733709
Validation loss: 2.4926091905698904

Epoch: 6| Step: 2
Training loss: 2.375465849312766
Validation loss: 2.488143416619647

Epoch: 6| Step: 3
Training loss: 1.8516464536280672
Validation loss: 2.505411922940359

Epoch: 6| Step: 4
Training loss: 2.0196753917144035
Validation loss: 2.501144228339033

Epoch: 6| Step: 5
Training loss: 2.0959828555374176
Validation loss: 2.5204853779442047

Epoch: 6| Step: 6
Training loss: 2.9708019995051287
Validation loss: 2.5192783389987894

Epoch: 6| Step: 7
Training loss: 3.0455258243350842
Validation loss: 2.5144234255570637

Epoch: 6| Step: 8
Training loss: 2.1291670613248077
Validation loss: 2.4862075303532016

Epoch: 6| Step: 9
Training loss: 2.5472864860027937
Validation loss: 2.5170494647264623

Epoch: 6| Step: 10
Training loss: 2.0796276195684116
Validation loss: 2.5558626968404257

Epoch: 6| Step: 11
Training loss: 1.9085674270020134
Validation loss: 2.5238692930357427

Epoch: 6| Step: 12
Training loss: 2.1465175858654044
Validation loss: 2.52157919648176

Epoch: 6| Step: 13
Training loss: 1.676097493242636
Validation loss: 2.4824588862883483

Epoch: 301| Step: 0
Training loss: 2.484743678729622
Validation loss: 2.529051299389183

Epoch: 6| Step: 1
Training loss: 2.133242832688143
Validation loss: 2.5110208217279166

Epoch: 6| Step: 2
Training loss: 1.686327774369462
Validation loss: 2.5164997269431972

Epoch: 6| Step: 3
Training loss: 2.2557697493018285
Validation loss: 2.503385657008938

Epoch: 6| Step: 4
Training loss: 2.752038720169026
Validation loss: 2.494084070181392

Epoch: 6| Step: 5
Training loss: 2.5082174669374653
Validation loss: 2.510143675879451

Epoch: 6| Step: 6
Training loss: 2.0688206317749054
Validation loss: 2.5126635164434457

Epoch: 6| Step: 7
Training loss: 2.21943976197951
Validation loss: 2.5103788751279907

Epoch: 6| Step: 8
Training loss: 2.134707548672505
Validation loss: 2.511471250397937

Epoch: 6| Step: 9
Training loss: 1.4723597868141443
Validation loss: 2.5209020918646465

Epoch: 6| Step: 10
Training loss: 2.834149093625793
Validation loss: 2.5133609661201026

Epoch: 6| Step: 11
Training loss: 1.7743320309662087
Validation loss: 2.4949745746398575

Epoch: 6| Step: 12
Training loss: 2.128523878003476
Validation loss: 2.517116158948418

Epoch: 6| Step: 13
Training loss: 2.6030449753054854
Validation loss: 2.4859217269142446

Epoch: 302| Step: 0
Training loss: 1.8059244911951773
Validation loss: 2.494363464468078

Epoch: 6| Step: 1
Training loss: 2.152437460740707
Validation loss: 2.511518980242898

Epoch: 6| Step: 2
Training loss: 3.3167406684121423
Validation loss: 2.4865886092719247

Epoch: 6| Step: 3
Training loss: 2.1298378122395407
Validation loss: 2.493598146061122

Epoch: 6| Step: 4
Training loss: 1.6755755104801457
Validation loss: 2.493386429917813

Epoch: 6| Step: 5
Training loss: 2.1502755365575075
Validation loss: 2.4953232993704377

Epoch: 6| Step: 6
Training loss: 1.9620551461607616
Validation loss: 2.4610603422961517

Epoch: 6| Step: 7
Training loss: 2.5697327861578603
Validation loss: 2.500131898907601

Epoch: 6| Step: 8
Training loss: 1.930086164181737
Validation loss: 2.4916095370138347

Epoch: 6| Step: 9
Training loss: 2.2674408048833166
Validation loss: 2.4875759173976983

Epoch: 6| Step: 10
Training loss: 2.292592734288517
Validation loss: 2.4961039753987406

Epoch: 6| Step: 11
Training loss: 2.008014238367855
Validation loss: 2.5022873423062393

Epoch: 6| Step: 12
Training loss: 2.2382514245940435
Validation loss: 2.516636509488155

Epoch: 6| Step: 13
Training loss: 2.398959621794058
Validation loss: 2.4909981210328507

Epoch: 303| Step: 0
Training loss: 2.5255346884058647
Validation loss: 2.522479031072775

Epoch: 6| Step: 1
Training loss: 2.176371359117199
Validation loss: 2.479448257162648

Epoch: 6| Step: 2
Training loss: 2.02312381625325
Validation loss: 2.4492538283993346

Epoch: 6| Step: 3
Training loss: 2.3553542683427975
Validation loss: 2.5168047262080653

Epoch: 6| Step: 4
Training loss: 2.5454611569170114
Validation loss: 2.5323933609715485

Epoch: 6| Step: 5
Training loss: 2.4964811355791845
Validation loss: 2.5078764436977976

Epoch: 6| Step: 6
Training loss: 1.8231690876899898
Validation loss: 2.511522689656708

Epoch: 6| Step: 7
Training loss: 1.905961124231848
Validation loss: 2.5009040305469825

Epoch: 6| Step: 8
Training loss: 2.330495152721917
Validation loss: 2.513656036232459

Epoch: 6| Step: 9
Training loss: 2.1095621661754804
Validation loss: 2.5059262033567262

Epoch: 6| Step: 10
Training loss: 2.2675823306916207
Validation loss: 2.5021535437344764

Epoch: 6| Step: 11
Training loss: 2.107340417795523
Validation loss: 2.548244663410302

Epoch: 6| Step: 12
Training loss: 1.9188708885456465
Validation loss: 2.5161403198767296

Epoch: 6| Step: 13
Training loss: 2.3443824423394974
Validation loss: 2.503553964324702

Epoch: 304| Step: 0
Training loss: 2.4024685959048626
Validation loss: 2.504347657052005

Epoch: 6| Step: 1
Training loss: 1.8470914917133276
Validation loss: 2.5209235749193986

Epoch: 6| Step: 2
Training loss: 1.8363987120155
Validation loss: 2.502759128732785

Epoch: 6| Step: 3
Training loss: 1.522469863718621
Validation loss: 2.505275417825927

Epoch: 6| Step: 4
Training loss: 2.0731728425829306
Validation loss: 2.500470141842268

Epoch: 6| Step: 5
Training loss: 2.4599994143043378
Validation loss: 2.5329631212568646

Epoch: 6| Step: 6
Training loss: 2.6828816675457796
Validation loss: 2.5087294442158794

Epoch: 6| Step: 7
Training loss: 2.211334300744335
Validation loss: 2.513756134953696

Epoch: 6| Step: 8
Training loss: 2.1387312928746653
Validation loss: 2.53470201125108

Epoch: 6| Step: 9
Training loss: 2.1447659278969184
Validation loss: 2.506451898261158

Epoch: 6| Step: 10
Training loss: 2.543742681769264
Validation loss: 2.49293115921929

Epoch: 6| Step: 11
Training loss: 2.316959205745774
Validation loss: 2.476324770103076

Epoch: 6| Step: 12
Training loss: 1.69830255472422
Validation loss: 2.5136606869047524

Epoch: 6| Step: 13
Training loss: 3.3368541878499394
Validation loss: 2.507894753404297

Epoch: 305| Step: 0
Training loss: 1.9972466351333562
Validation loss: 2.4845860147150547

Epoch: 6| Step: 1
Training loss: 2.712156346082073
Validation loss: 2.501501018334367

Epoch: 6| Step: 2
Training loss: 2.0780405586697683
Validation loss: 2.514792883858327

Epoch: 6| Step: 3
Training loss: 2.687879846033194
Validation loss: 2.4649281990849436

Epoch: 6| Step: 4
Training loss: 2.59977399504012
Validation loss: 2.5080696709868113

Epoch: 6| Step: 5
Training loss: 1.9702631267317976
Validation loss: 2.4841007853456243

Epoch: 6| Step: 6
Training loss: 1.8258344205884716
Validation loss: 2.490984643090693

Epoch: 6| Step: 7
Training loss: 2.051309339558829
Validation loss: 2.5079439997845467

Epoch: 6| Step: 8
Training loss: 2.3984551941656966
Validation loss: 2.5034361123995748

Epoch: 6| Step: 9
Training loss: 1.9163932467057192
Validation loss: 2.4836610818391045

Epoch: 6| Step: 10
Training loss: 2.1203820033759198
Validation loss: 2.4912260627851

Epoch: 6| Step: 11
Training loss: 2.1248497629350567
Validation loss: 2.4807805610871676

Epoch: 6| Step: 12
Training loss: 2.395569916770382
Validation loss: 2.494281817833804

Epoch: 6| Step: 13
Training loss: 2.1029314878861176
Validation loss: 2.4743805034291855

Epoch: 306| Step: 0
Training loss: 1.9723595122189752
Validation loss: 2.5269869443964077

Epoch: 6| Step: 1
Training loss: 2.5122263441464887
Validation loss: 2.501030167220776

Epoch: 6| Step: 2
Training loss: 2.990955069094452
Validation loss: 2.5109797769375772

Epoch: 6| Step: 3
Training loss: 2.1122882082257086
Validation loss: 2.4810225665852426

Epoch: 6| Step: 4
Training loss: 1.9880194650921317
Validation loss: 2.5201211696425507

Epoch: 6| Step: 5
Training loss: 1.7614345278974566
Validation loss: 2.507964177579887

Epoch: 6| Step: 6
Training loss: 2.7459779283563113
Validation loss: 2.5651616715266816

Epoch: 6| Step: 7
Training loss: 1.311192997074337
Validation loss: 2.5032772999293047

Epoch: 6| Step: 8
Training loss: 2.2778087422610356
Validation loss: 2.5030664424190086

Epoch: 6| Step: 9
Training loss: 2.222688215458301
Validation loss: 2.481061675648965

Epoch: 6| Step: 10
Training loss: 2.930320081445732
Validation loss: 2.5135996471661284

Epoch: 6| Step: 11
Training loss: 1.8637650539473336
Validation loss: 2.517434194878522

Epoch: 6| Step: 12
Training loss: 2.0403632330550203
Validation loss: 2.4773182022481217

Epoch: 6| Step: 13
Training loss: 1.445227955587862
Validation loss: 2.5167786883831096

Epoch: 307| Step: 0
Training loss: 2.3963920494644295
Validation loss: 2.4924221339192467

Epoch: 6| Step: 1
Training loss: 2.3989811880591354
Validation loss: 2.530229126383411

Epoch: 6| Step: 2
Training loss: 2.4490402132270956
Validation loss: 2.497733865166718

Epoch: 6| Step: 3
Training loss: 1.6923536506161063
Validation loss: 2.490976869775837

Epoch: 6| Step: 4
Training loss: 2.0738303185395845
Validation loss: 2.516206650014

Epoch: 6| Step: 5
Training loss: 2.505119898471727
Validation loss: 2.509988719635554

Epoch: 6| Step: 6
Training loss: 2.0663956351629538
Validation loss: 2.536589351505467

Epoch: 6| Step: 7
Training loss: 2.2019106717540287
Validation loss: 2.5225322530480057

Epoch: 6| Step: 8
Training loss: 2.501196479586978
Validation loss: 2.5244202552485087

Epoch: 6| Step: 9
Training loss: 1.9830592441567578
Validation loss: 2.5002749261121777

Epoch: 6| Step: 10
Training loss: 1.6719202053340196
Validation loss: 2.4685064558860055

Epoch: 6| Step: 11
Training loss: 2.3720295047822693
Validation loss: 2.52734228120387

Epoch: 6| Step: 12
Training loss: 2.4554123631993163
Validation loss: 2.5256363454199096

Epoch: 6| Step: 13
Training loss: 1.4030784871095718
Validation loss: 2.486962288222238

Epoch: 308| Step: 0
Training loss: 1.9180432089591533
Validation loss: 2.5022419178001774

Epoch: 6| Step: 1
Training loss: 2.4576288172817993
Validation loss: 2.4944126480833955

Epoch: 6| Step: 2
Training loss: 2.4327532203032836
Validation loss: 2.5201524357137686

Epoch: 6| Step: 3
Training loss: 2.019711750161754
Validation loss: 2.5090439657287904

Epoch: 6| Step: 4
Training loss: 2.731790247370292
Validation loss: 2.4923124711169637

Epoch: 6| Step: 5
Training loss: 2.504742701368952
Validation loss: 2.4682432739546263

Epoch: 6| Step: 6
Training loss: 2.453498471738667
Validation loss: 2.5524197733155467

Epoch: 6| Step: 7
Training loss: 1.8986914821947023
Validation loss: 2.488422629001862

Epoch: 6| Step: 8
Training loss: 2.2102808971456795
Validation loss: 2.4738853069898146

Epoch: 6| Step: 9
Training loss: 2.080029754792646
Validation loss: 2.519296730181443

Epoch: 6| Step: 10
Training loss: 2.1884279735095826
Validation loss: 2.4970212931405453

Epoch: 6| Step: 11
Training loss: 2.166775981884183
Validation loss: 2.4765766485385954

Epoch: 6| Step: 12
Training loss: 1.9810608349335876
Validation loss: 2.4926921893959744

Epoch: 6| Step: 13
Training loss: 2.000698206145233
Validation loss: 2.5334988591251433

Epoch: 309| Step: 0
Training loss: 1.540849529254823
Validation loss: 2.49083446963494

Epoch: 6| Step: 1
Training loss: 1.5376325441619947
Validation loss: 2.5113481003707077

Epoch: 6| Step: 2
Training loss: 2.41044577864264
Validation loss: 2.528907783010067

Epoch: 6| Step: 3
Training loss: 2.3061474330186704
Validation loss: 2.5002611526350487

Epoch: 6| Step: 4
Training loss: 1.8595083493411724
Validation loss: 2.51850698818325

Epoch: 6| Step: 5
Training loss: 2.878185000710592
Validation loss: 2.5171181572117534

Epoch: 6| Step: 6
Training loss: 2.597943420598701
Validation loss: 2.516925425457025

Epoch: 6| Step: 7
Training loss: 2.030586251605068
Validation loss: 2.502944076718412

Epoch: 6| Step: 8
Training loss: 1.8907088584272316
Validation loss: 2.5479729673393026

Epoch: 6| Step: 9
Training loss: 2.2081301493710193
Validation loss: 2.5294063776109055

Epoch: 6| Step: 10
Training loss: 2.1853044663517114
Validation loss: 2.5114032859389015

Epoch: 6| Step: 11
Training loss: 2.1976876764799975
Validation loss: 2.510868506876059

Epoch: 6| Step: 12
Training loss: 2.3007854986232523
Validation loss: 2.4936960593279434

Epoch: 6| Step: 13
Training loss: 3.1149064898959486
Validation loss: 2.530986371599353

Epoch: 310| Step: 0
Training loss: 2.604947840192212
Validation loss: 2.4940906085723396

Epoch: 6| Step: 1
Training loss: 1.8404067811994809
Validation loss: 2.52982904091599

Epoch: 6| Step: 2
Training loss: 1.9004398664973552
Validation loss: 2.5250582919869364

Epoch: 6| Step: 3
Training loss: 1.9552138488182298
Validation loss: 2.4984880264212257

Epoch: 6| Step: 4
Training loss: 2.349715308942991
Validation loss: 2.505132987217735

Epoch: 6| Step: 5
Training loss: 2.233133464618893
Validation loss: 2.5105564716923934

Epoch: 6| Step: 6
Training loss: 2.5708760394522123
Validation loss: 2.509792370927213

Epoch: 6| Step: 7
Training loss: 1.7563068638620154
Validation loss: 2.481021410322265

Epoch: 6| Step: 8
Training loss: 2.1949864481375103
Validation loss: 2.478179024160481

Epoch: 6| Step: 9
Training loss: 2.2326009683534633
Validation loss: 2.529852972434646

Epoch: 6| Step: 10
Training loss: 2.115049739820911
Validation loss: 2.5207752857391217

Epoch: 6| Step: 11
Training loss: 2.3364000149604576
Validation loss: 2.490128523917173

Epoch: 6| Step: 12
Training loss: 2.5032621081802393
Validation loss: 2.541570158978266

Epoch: 6| Step: 13
Training loss: 2.362746400447142
Validation loss: 2.513873128804386

Epoch: 311| Step: 0
Training loss: 2.0994028105147233
Validation loss: 2.4824908487305577

Epoch: 6| Step: 1
Training loss: 2.6047267972639685
Validation loss: 2.51502188503151

Epoch: 6| Step: 2
Training loss: 2.79264460463319
Validation loss: 2.5101835945749786

Epoch: 6| Step: 3
Training loss: 2.073271166778155
Validation loss: 2.5052584617384714

Epoch: 6| Step: 4
Training loss: 2.3000920401691562
Validation loss: 2.510909414629172

Epoch: 6| Step: 5
Training loss: 1.872928237737853
Validation loss: 2.4989284587783627

Epoch: 6| Step: 6
Training loss: 1.9947055236967886
Validation loss: 2.5429171564569217

Epoch: 6| Step: 7
Training loss: 2.31561028891561
Validation loss: 2.512767022537284

Epoch: 6| Step: 8
Training loss: 2.168185826336584
Validation loss: 2.5202125833193185

Epoch: 6| Step: 9
Training loss: 1.8367283193321937
Validation loss: 2.5224862611480776

Epoch: 6| Step: 10
Training loss: 2.338667381209667
Validation loss: 2.492636400333348

Epoch: 6| Step: 11
Training loss: 1.657321655206719
Validation loss: 2.500144152433318

Epoch: 6| Step: 12
Training loss: 2.598004081211893
Validation loss: 2.516483124601139

Epoch: 6| Step: 13
Training loss: 1.8346941694639702
Validation loss: 2.5335904058429715

Epoch: 312| Step: 0
Training loss: 2.3114978577746035
Validation loss: 2.505958885920641

Epoch: 6| Step: 1
Training loss: 2.0351913947001457
Validation loss: 2.4955150146381473

Epoch: 6| Step: 2
Training loss: 2.06271754186843
Validation loss: 2.496878247945118

Epoch: 6| Step: 3
Training loss: 3.0382267212137197
Validation loss: 2.515127728132324

Epoch: 6| Step: 4
Training loss: 2.5170897963900334
Validation loss: 2.495530980357949

Epoch: 6| Step: 5
Training loss: 2.488894975272563
Validation loss: 2.496205215472615

Epoch: 6| Step: 6
Training loss: 1.5410760401110708
Validation loss: 2.528143577457232

Epoch: 6| Step: 7
Training loss: 1.9034237782132946
Validation loss: 2.5085069509275746

Epoch: 6| Step: 8
Training loss: 2.041299812937837
Validation loss: 2.5023425007705025

Epoch: 6| Step: 9
Training loss: 2.0677077696164483
Validation loss: 2.491309584647566

Epoch: 6| Step: 10
Training loss: 2.2983443562236614
Validation loss: 2.5030963908718733

Epoch: 6| Step: 11
Training loss: 2.617912169379812
Validation loss: 2.5141750165230397

Epoch: 6| Step: 12
Training loss: 1.8909108599991293
Validation loss: 2.5023479131786064

Epoch: 6| Step: 13
Training loss: 1.833719740229847
Validation loss: 2.5134766361001715

Epoch: 313| Step: 0
Training loss: 2.615006451863194
Validation loss: 2.4583830900529224

Epoch: 6| Step: 1
Training loss: 1.9973455337364852
Validation loss: 2.5120596220831515

Epoch: 6| Step: 2
Training loss: 1.891073000454529
Validation loss: 2.52981389106134

Epoch: 6| Step: 3
Training loss: 1.8848416486043915
Validation loss: 2.4963775580747356

Epoch: 6| Step: 4
Training loss: 2.432652274498566
Validation loss: 2.478358699528282

Epoch: 6| Step: 5
Training loss: 2.313209940214797
Validation loss: 2.4511556072714207

Epoch: 6| Step: 6
Training loss: 2.380754626553923
Validation loss: 2.50274921119117

Epoch: 6| Step: 7
Training loss: 2.214527679442634
Validation loss: 2.508089771109967

Epoch: 6| Step: 8
Training loss: 2.0669869830972467
Validation loss: 2.4853625995276407

Epoch: 6| Step: 9
Training loss: 2.3411604753884334
Validation loss: 2.5236943175617372

Epoch: 6| Step: 10
Training loss: 2.046217252158183
Validation loss: 2.500750494667763

Epoch: 6| Step: 11
Training loss: 2.7239708593213035
Validation loss: 2.5149434360678633

Epoch: 6| Step: 12
Training loss: 1.6566875527572897
Validation loss: 2.5211338530882217

Epoch: 6| Step: 13
Training loss: 1.8513075898541513
Validation loss: 2.4992830296925432

Epoch: 314| Step: 0
Training loss: 2.1035119980237997
Validation loss: 2.5078086317587953

Epoch: 6| Step: 1
Training loss: 1.6382820475025628
Validation loss: 2.530764120045704

Epoch: 6| Step: 2
Training loss: 2.4988921571857854
Validation loss: 2.489424824844198

Epoch: 6| Step: 3
Training loss: 2.4928523883782048
Validation loss: 2.524736391227201

Epoch: 6| Step: 4
Training loss: 1.7005797799970355
Validation loss: 2.4884447427300893

Epoch: 6| Step: 5
Training loss: 2.188440393219631
Validation loss: 2.5414507078361166

Epoch: 6| Step: 6
Training loss: 2.944395210846161
Validation loss: 2.5046068803742867

Epoch: 6| Step: 7
Training loss: 1.9916460685250073
Validation loss: 2.5008955007954023

Epoch: 6| Step: 8
Training loss: 1.651345097751059
Validation loss: 2.5245121007199898

Epoch: 6| Step: 9
Training loss: 1.6678322372140666
Validation loss: 2.473778937700091

Epoch: 6| Step: 10
Training loss: 1.9890595657075274
Validation loss: 2.494644045238141

Epoch: 6| Step: 11
Training loss: 3.1558003624650235
Validation loss: 2.492134930250402

Epoch: 6| Step: 12
Training loss: 2.3734029118200595
Validation loss: 2.492443423253238

Epoch: 6| Step: 13
Training loss: 1.6129760453490538
Validation loss: 2.513879760536462

Epoch: 315| Step: 0
Training loss: 1.4119901699123827
Validation loss: 2.5242986443752935

Epoch: 6| Step: 1
Training loss: 1.981252962705882
Validation loss: 2.475717441979928

Epoch: 6| Step: 2
Training loss: 2.020848329888245
Validation loss: 2.488669872273311

Epoch: 6| Step: 3
Training loss: 2.0904804721477674
Validation loss: 2.4809212845844515

Epoch: 6| Step: 4
Training loss: 1.4155606084667218
Validation loss: 2.53954698911349

Epoch: 6| Step: 5
Training loss: 2.420620501076014
Validation loss: 2.5139815767923834

Epoch: 6| Step: 6
Training loss: 2.1960026752337507
Validation loss: 2.516853529342443

Epoch: 6| Step: 7
Training loss: 2.1101739571261646
Validation loss: 2.50963816832448

Epoch: 6| Step: 8
Training loss: 2.7748262608757424
Validation loss: 2.4950629152856836

Epoch: 6| Step: 9
Training loss: 2.399608810650776
Validation loss: 2.5328676672401675

Epoch: 6| Step: 10
Training loss: 2.2218582517526513
Validation loss: 2.489440561358248

Epoch: 6| Step: 11
Training loss: 2.3194958826428573
Validation loss: 2.531621737815818

Epoch: 6| Step: 12
Training loss: 2.409534936883163
Validation loss: 2.4693418753600316

Epoch: 6| Step: 13
Training loss: 2.6995112789205997
Validation loss: 2.4826078377454692

Epoch: 316| Step: 0
Training loss: 1.7193447124513384
Validation loss: 2.4883966661111785

Epoch: 6| Step: 1
Training loss: 2.55080779501406
Validation loss: 2.512740465902327

Epoch: 6| Step: 2
Training loss: 2.1949804740506518
Validation loss: 2.5150903541148066

Epoch: 6| Step: 3
Training loss: 1.4541542755881522
Validation loss: 2.509015387962016

Epoch: 6| Step: 4
Training loss: 1.9052676812284906
Validation loss: 2.4804657951339317

Epoch: 6| Step: 5
Training loss: 2.5310569972173367
Validation loss: 2.511527236079921

Epoch: 6| Step: 6
Training loss: 2.493358755373082
Validation loss: 2.4966170597716286

Epoch: 6| Step: 7
Training loss: 1.82863668470087
Validation loss: 2.5063275697729357

Epoch: 6| Step: 8
Training loss: 2.721376224896896
Validation loss: 2.5023535530121883

Epoch: 6| Step: 9
Training loss: 2.2509676653837185
Validation loss: 2.501218057072115

Epoch: 6| Step: 10
Training loss: 2.372695608004151
Validation loss: 2.5185656828481786

Epoch: 6| Step: 11
Training loss: 2.4900160749904683
Validation loss: 2.4619131044853075

Epoch: 6| Step: 12
Training loss: 2.1511375522871297
Validation loss: 2.5240803353794794

Epoch: 6| Step: 13
Training loss: 1.160520605549443
Validation loss: 2.5290607843452415

Epoch: 317| Step: 0
Training loss: 2.3311111449750848
Validation loss: 2.509440132090363

Epoch: 6| Step: 1
Training loss: 1.6598697190693754
Validation loss: 2.5014116137131284

Epoch: 6| Step: 2
Training loss: 1.9606397790324437
Validation loss: 2.52256317062988

Epoch: 6| Step: 3
Training loss: 2.432329023729169
Validation loss: 2.5250138446773915

Epoch: 6| Step: 4
Training loss: 2.086064824136702
Validation loss: 2.451082535034699

Epoch: 6| Step: 5
Training loss: 2.4488552377392243
Validation loss: 2.4955210803190377

Epoch: 6| Step: 6
Training loss: 2.844692032274124
Validation loss: 2.481690180760001

Epoch: 6| Step: 7
Training loss: 1.907330941324202
Validation loss: 2.494506672370322

Epoch: 6| Step: 8
Training loss: 2.2983678001971115
Validation loss: 2.5012020451446126

Epoch: 6| Step: 9
Training loss: 1.7257201612651305
Validation loss: 2.5044034795304326

Epoch: 6| Step: 10
Training loss: 2.7375442013590447
Validation loss: 2.4769563013436167

Epoch: 6| Step: 11
Training loss: 1.2286302182557043
Validation loss: 2.502175806596678

Epoch: 6| Step: 12
Training loss: 1.9630763938640703
Validation loss: 2.508853155020339

Epoch: 6| Step: 13
Training loss: 2.850998579728045
Validation loss: 2.509529363059057

Epoch: 318| Step: 0
Training loss: 2.190310171797967
Validation loss: 2.502470625095777

Epoch: 6| Step: 1
Training loss: 1.6544932999808117
Validation loss: 2.51325023602317

Epoch: 6| Step: 2
Training loss: 2.2667523966265715
Validation loss: 2.493547801066365

Epoch: 6| Step: 3
Training loss: 2.7274415093993905
Validation loss: 2.515789379470726

Epoch: 6| Step: 4
Training loss: 2.2094385032754045
Validation loss: 2.500344048688528

Epoch: 6| Step: 5
Training loss: 2.313321148220075
Validation loss: 2.495056056297688

Epoch: 6| Step: 6
Training loss: 2.571850533907872
Validation loss: 2.508236927581921

Epoch: 6| Step: 7
Training loss: 2.0233914285370966
Validation loss: 2.5299807492934727

Epoch: 6| Step: 8
Training loss: 2.446081461063829
Validation loss: 2.492176683502533

Epoch: 6| Step: 9
Training loss: 1.3917806730952054
Validation loss: 2.477750671288326

Epoch: 6| Step: 10
Training loss: 1.967365201721475
Validation loss: 2.5005420773919784

Epoch: 6| Step: 11
Training loss: 1.9499904656788463
Validation loss: 2.493584289440101

Epoch: 6| Step: 12
Training loss: 2.74509955651244
Validation loss: 2.515058550112654

Epoch: 6| Step: 13
Training loss: 1.4526816071058155
Validation loss: 2.5115663810149136

Epoch: 319| Step: 0
Training loss: 1.8313195120992698
Validation loss: 2.543301818054166

Epoch: 6| Step: 1
Training loss: 2.8248261659865004
Validation loss: 2.542924443350998

Epoch: 6| Step: 2
Training loss: 2.2554803439015103
Validation loss: 2.522281748936105

Epoch: 6| Step: 3
Training loss: 2.0719924732351385
Validation loss: 2.538534923735397

Epoch: 6| Step: 4
Training loss: 2.252271247620425
Validation loss: 2.5241860119276214

Epoch: 6| Step: 5
Training loss: 1.5012707890350387
Validation loss: 2.519807518524

Epoch: 6| Step: 6
Training loss: 1.7813739398869897
Validation loss: 2.526275777841178

Epoch: 6| Step: 7
Training loss: 2.192311472252433
Validation loss: 2.525609828182119

Epoch: 6| Step: 8
Training loss: 2.5994642806169916
Validation loss: 2.5246467107220485

Epoch: 6| Step: 9
Training loss: 2.146476599806778
Validation loss: 2.5234157559160177

Epoch: 6| Step: 10
Training loss: 2.3260859834714713
Validation loss: 2.5561050642123893

Epoch: 6| Step: 11
Training loss: 1.6613431390352527
Validation loss: 2.5257926538242694

Epoch: 6| Step: 12
Training loss: 2.8379996712639413
Validation loss: 2.527489879789901

Epoch: 6| Step: 13
Training loss: 1.440356940032684
Validation loss: 2.5164660331513375

Epoch: 320| Step: 0
Training loss: 2.293837634499187
Validation loss: 2.5199481929145415

Epoch: 6| Step: 1
Training loss: 2.115098887266853
Validation loss: 2.4833233522240867

Epoch: 6| Step: 2
Training loss: 2.344796112566992
Validation loss: 2.508723164705964

Epoch: 6| Step: 3
Training loss: 2.184937856737618
Validation loss: 2.4985282965334363

Epoch: 6| Step: 4
Training loss: 2.571518820738078
Validation loss: 2.5157627502893685

Epoch: 6| Step: 5
Training loss: 2.309137941822184
Validation loss: 2.4903763791573206

Epoch: 6| Step: 6
Training loss: 2.23856244143406
Validation loss: 2.4994859987404983

Epoch: 6| Step: 7
Training loss: 2.1085473591526926
Validation loss: 2.487107918890991

Epoch: 6| Step: 8
Training loss: 2.0853813658733005
Validation loss: 2.5149382638139772

Epoch: 6| Step: 9
Training loss: 1.684566491164144
Validation loss: 2.515763883451764

Epoch: 6| Step: 10
Training loss: 1.966299014829536
Validation loss: 2.487143087544414

Epoch: 6| Step: 11
Training loss: 2.1998678167687444
Validation loss: 2.522354572759199

Epoch: 6| Step: 12
Training loss: 2.450842895316216
Validation loss: 2.4784772835971256

Epoch: 6| Step: 13
Training loss: 1.7558807609367464
Validation loss: 2.5161798408346314

Epoch: 321| Step: 0
Training loss: 1.5059057641707678
Validation loss: 2.4833299241087654

Epoch: 6| Step: 1
Training loss: 2.5051255136442423
Validation loss: 2.506260007451078

Epoch: 6| Step: 2
Training loss: 1.819083654467123
Validation loss: 2.5244890142500602

Epoch: 6| Step: 3
Training loss: 2.987248979181857
Validation loss: 2.4913782119941876

Epoch: 6| Step: 4
Training loss: 1.790237374150267
Validation loss: 2.5196642448273727

Epoch: 6| Step: 5
Training loss: 2.68075282326866
Validation loss: 2.5036883157358814

Epoch: 6| Step: 6
Training loss: 2.017118743268373
Validation loss: 2.494400049852589

Epoch: 6| Step: 7
Training loss: 1.697191735032146
Validation loss: 2.512496623399866

Epoch: 6| Step: 8
Training loss: 1.9236910543650305
Validation loss: 2.5321559983573088

Epoch: 6| Step: 9
Training loss: 2.512362242001376
Validation loss: 2.5142856895782115

Epoch: 6| Step: 10
Training loss: 2.570971558088973
Validation loss: 2.5020703941013993

Epoch: 6| Step: 11
Training loss: 2.4945164623592775
Validation loss: 2.5247194632831746

Epoch: 6| Step: 12
Training loss: 1.4558294417546358
Validation loss: 2.530424366481189

Epoch: 6| Step: 13
Training loss: 1.9329523429146536
Validation loss: 2.508152553762222

Epoch: 322| Step: 0
Training loss: 2.3382834197753466
Validation loss: 2.519355923376934

Epoch: 6| Step: 1
Training loss: 2.4702630536935453
Validation loss: 2.5367068304398974

Epoch: 6| Step: 2
Training loss: 2.261543543853319
Validation loss: 2.540991658374255

Epoch: 6| Step: 3
Training loss: 2.6190807270252847
Validation loss: 2.5162444593049065

Epoch: 6| Step: 4
Training loss: 1.551596938689345
Validation loss: 2.505102374386027

Epoch: 6| Step: 5
Training loss: 1.8325107491920862
Validation loss: 2.5063067359241926

Epoch: 6| Step: 6
Training loss: 1.527380589189675
Validation loss: 2.5410908225413107

Epoch: 6| Step: 7
Training loss: 2.2400464192757825
Validation loss: 2.526499773778357

Epoch: 6| Step: 8
Training loss: 2.0084343923043435
Validation loss: 2.473380637386388

Epoch: 6| Step: 9
Training loss: 2.7017861286401095
Validation loss: 2.5213363455440874

Epoch: 6| Step: 10
Training loss: 2.6237791037796816
Validation loss: 2.5171909898740985

Epoch: 6| Step: 11
Training loss: 1.6911898644153531
Validation loss: 2.485362216326988

Epoch: 6| Step: 12
Training loss: 2.2695000493700315
Validation loss: 2.4939385940016043

Epoch: 6| Step: 13
Training loss: 1.6812426088305383
Validation loss: 2.493615809594369

Epoch: 323| Step: 0
Training loss: 2.636170732980482
Validation loss: 2.508022735659733

Epoch: 6| Step: 1
Training loss: 2.478588154289943
Validation loss: 2.5171185625677306

Epoch: 6| Step: 2
Training loss: 2.770752974948733
Validation loss: 2.515620958297867

Epoch: 6| Step: 3
Training loss: 1.836075213522726
Validation loss: 2.5247239564951465

Epoch: 6| Step: 4
Training loss: 2.092379220920095
Validation loss: 2.523898864627579

Epoch: 6| Step: 5
Training loss: 1.60764538310721
Validation loss: 2.523028531922397

Epoch: 6| Step: 6
Training loss: 2.0227392457368043
Validation loss: 2.486283913313135

Epoch: 6| Step: 7
Training loss: 2.45301789456919
Validation loss: 2.5028635114964803

Epoch: 6| Step: 8
Training loss: 2.6301040981273127
Validation loss: 2.5017367626588407

Epoch: 6| Step: 9
Training loss: 2.4158280221916453
Validation loss: 2.5288847245038872

Epoch: 6| Step: 10
Training loss: 1.9237439751979981
Validation loss: 2.469616960601119

Epoch: 6| Step: 11
Training loss: 1.9217627267685327
Validation loss: 2.510270094818972

Epoch: 6| Step: 12
Training loss: 1.971484147644937
Validation loss: 2.5455857443734797

Epoch: 6| Step: 13
Training loss: 1.8607504749884327
Validation loss: 2.477083103258542

Epoch: 324| Step: 0
Training loss: 2.110575694512771
Validation loss: 2.5287816231602362

Epoch: 6| Step: 1
Training loss: 2.7485857708327064
Validation loss: 2.5064599733852915

Epoch: 6| Step: 2
Training loss: 1.550019737856309
Validation loss: 2.5188074141680157

Epoch: 6| Step: 3
Training loss: 1.6646267646149429
Validation loss: 2.511927175813773

Epoch: 6| Step: 4
Training loss: 2.2696884022075
Validation loss: 2.499867869546324

Epoch: 6| Step: 5
Training loss: 2.1691658083132044
Validation loss: 2.4873206415028735

Epoch: 6| Step: 6
Training loss: 1.9336691485260098
Validation loss: 2.5015733966781064

Epoch: 6| Step: 7
Training loss: 1.7154788012305233
Validation loss: 2.5163276204255256

Epoch: 6| Step: 8
Training loss: 2.4131657684842294
Validation loss: 2.5410133246980116

Epoch: 6| Step: 9
Training loss: 2.047555359032625
Validation loss: 2.544560035445194

Epoch: 6| Step: 10
Training loss: 2.2771070301699403
Validation loss: 2.5121312063754355

Epoch: 6| Step: 11
Training loss: 2.8698149655337306
Validation loss: 2.518189101994798

Epoch: 6| Step: 12
Training loss: 2.389232154944799
Validation loss: 2.492805475574294

Epoch: 6| Step: 13
Training loss: 2.1465647910607495
Validation loss: 2.48963649276125

Epoch: 325| Step: 0
Training loss: 2.628776649125975
Validation loss: 2.529946791208386

Epoch: 6| Step: 1
Training loss: 2.236074374932438
Validation loss: 2.510148489575079

Epoch: 6| Step: 2
Training loss: 2.1474787011827825
Validation loss: 2.512923147980923

Epoch: 6| Step: 3
Training loss: 3.014396298574698
Validation loss: 2.480326831321147

Epoch: 6| Step: 4
Training loss: 1.9386112348921454
Validation loss: 2.5392920666226098

Epoch: 6| Step: 5
Training loss: 2.1474266309717067
Validation loss: 2.5067475310818104

Epoch: 6| Step: 6
Training loss: 2.309149299298379
Validation loss: 2.5142779347717457

Epoch: 6| Step: 7
Training loss: 1.7600820851690988
Validation loss: 2.504684900787542

Epoch: 6| Step: 8
Training loss: 2.0700273425374216
Validation loss: 2.5296185952317516

Epoch: 6| Step: 9
Training loss: 2.0722957684394596
Validation loss: 2.512858451244174

Epoch: 6| Step: 10
Training loss: 2.2200528470184415
Validation loss: 2.5062868214751313

Epoch: 6| Step: 11
Training loss: 1.8124755989273769
Validation loss: 2.4698952422093314

Epoch: 6| Step: 12
Training loss: 2.260526510871695
Validation loss: 2.5196054139748

Epoch: 6| Step: 13
Training loss: 1.5060248178916948
Validation loss: 2.537046733959061

Epoch: 326| Step: 0
Training loss: 1.9588918768665886
Validation loss: 2.4672015645593808

Epoch: 6| Step: 1
Training loss: 2.5209156579901095
Validation loss: 2.5186805784131936

Epoch: 6| Step: 2
Training loss: 2.35196882520503
Validation loss: 2.5011193353778043

Epoch: 6| Step: 3
Training loss: 2.402885859661113
Validation loss: 2.5048665773440124

Epoch: 6| Step: 4
Training loss: 1.7254237221256765
Validation loss: 2.506122294392875

Epoch: 6| Step: 5
Training loss: 2.8689888848468046
Validation loss: 2.529351909680268

Epoch: 6| Step: 6
Training loss: 2.0993816873274125
Validation loss: 2.4905542214014917

Epoch: 6| Step: 7
Training loss: 2.4191480481566536
Validation loss: 2.481248676422337

Epoch: 6| Step: 8
Training loss: 1.9234652879010778
Validation loss: 2.545213547090119

Epoch: 6| Step: 9
Training loss: 1.7459681250250578
Validation loss: 2.507264622382427

Epoch: 6| Step: 10
Training loss: 2.205071313271421
Validation loss: 2.5282501361918785

Epoch: 6| Step: 11
Training loss: 2.1492481158963668
Validation loss: 2.534593924377411

Epoch: 6| Step: 12
Training loss: 2.008027892675107
Validation loss: 2.501419220342826

Epoch: 6| Step: 13
Training loss: 1.1376656065897823
Validation loss: 2.4813782721799083

Epoch: 327| Step: 0
Training loss: 2.3444947140423165
Validation loss: 2.49981782310967

Epoch: 6| Step: 1
Training loss: 2.0180905661623916
Validation loss: 2.4928961174700253

Epoch: 6| Step: 2
Training loss: 2.2931353168978066
Validation loss: 2.5045049491455766

Epoch: 6| Step: 3
Training loss: 1.783967738933271
Validation loss: 2.4863626179836227

Epoch: 6| Step: 4
Training loss: 2.8085981642220177
Validation loss: 2.5184129386891008

Epoch: 6| Step: 5
Training loss: 2.2756982423498893
Validation loss: 2.520721324919412

Epoch: 6| Step: 6
Training loss: 2.152241726930634
Validation loss: 2.5058976422095403

Epoch: 6| Step: 7
Training loss: 2.12748617703422
Validation loss: 2.4826667811805647

Epoch: 6| Step: 8
Training loss: 2.097664433468674
Validation loss: 2.4906427383897696

Epoch: 6| Step: 9
Training loss: 1.153359485965489
Validation loss: 2.501165093914932

Epoch: 6| Step: 10
Training loss: 2.769749728302917
Validation loss: 2.5239975952568745

Epoch: 6| Step: 11
Training loss: 1.9102971623717797
Validation loss: 2.5106253071126163

Epoch: 6| Step: 12
Training loss: 2.408760049716828
Validation loss: 2.5007254112083

Epoch: 6| Step: 13
Training loss: 2.0707018216267
Validation loss: 2.517745240215171

Epoch: 328| Step: 0
Training loss: 2.035294950887801
Validation loss: 2.5143151006280107

Epoch: 6| Step: 1
Training loss: 2.181091294075803
Validation loss: 2.5227548253685796

Epoch: 6| Step: 2
Training loss: 2.1793123968446495
Validation loss: 2.483377857253709

Epoch: 6| Step: 3
Training loss: 1.8847374157944021
Validation loss: 2.4841323303716565

Epoch: 6| Step: 4
Training loss: 2.907266254557731
Validation loss: 2.528966666096807

Epoch: 6| Step: 5
Training loss: 1.8064926829207044
Validation loss: 2.47639075774837

Epoch: 6| Step: 6
Training loss: 2.437195000762295
Validation loss: 2.5072478269864624

Epoch: 6| Step: 7
Training loss: 2.1140451231790003
Validation loss: 2.4868814686391194

Epoch: 6| Step: 8
Training loss: 2.110377546765644
Validation loss: 2.5204938363149374

Epoch: 6| Step: 9
Training loss: 2.423228224198103
Validation loss: 2.515974222976114

Epoch: 6| Step: 10
Training loss: 2.7656768966374647
Validation loss: 2.5205522395934294

Epoch: 6| Step: 11
Training loss: 1.6443743053218776
Validation loss: 2.4786257919473074

Epoch: 6| Step: 12
Training loss: 1.2206053671793702
Validation loss: 2.541123713640812

Epoch: 6| Step: 13
Training loss: 2.2186153532193837
Validation loss: 2.5122921112749346

Epoch: 329| Step: 0
Training loss: 2.6568951889057124
Validation loss: 2.4931160049071166

Epoch: 6| Step: 1
Training loss: 2.4153622581834044
Validation loss: 2.515066914609803

Epoch: 6| Step: 2
Training loss: 2.2139842469810227
Validation loss: 2.4936567140571997

Epoch: 6| Step: 3
Training loss: 2.2962053840966816
Validation loss: 2.51385225041077

Epoch: 6| Step: 4
Training loss: 2.0070418129268432
Validation loss: 2.5433764374663843

Epoch: 6| Step: 5
Training loss: 1.976198788678474
Validation loss: 2.5054324245166244

Epoch: 6| Step: 6
Training loss: 2.283602611878225
Validation loss: 2.5412250345586402

Epoch: 6| Step: 7
Training loss: 2.0132639459733057
Validation loss: 2.5265987031128336

Epoch: 6| Step: 8
Training loss: 2.212004387297599
Validation loss: 2.521117885282175

Epoch: 6| Step: 9
Training loss: 2.755934813593628
Validation loss: 2.518355409107881

Epoch: 6| Step: 10
Training loss: 2.122031438395084
Validation loss: 2.5111342228255342

Epoch: 6| Step: 11
Training loss: 1.622626698959069
Validation loss: 2.502759546657658

Epoch: 6| Step: 12
Training loss: 2.007910937556843
Validation loss: 2.519327192412966

Epoch: 6| Step: 13
Training loss: 1.1787643862965933
Validation loss: 2.5102075990029893

Epoch: 330| Step: 0
Training loss: 2.427877064422231
Validation loss: 2.5036525521324684

Epoch: 6| Step: 1
Training loss: 1.7385693943501213
Validation loss: 2.4880475496187113

Epoch: 6| Step: 2
Training loss: 2.1627333101751502
Validation loss: 2.5071310209240414

Epoch: 6| Step: 3
Training loss: 2.2942840079291202
Validation loss: 2.4862864106685127

Epoch: 6| Step: 4
Training loss: 2.706766575236247
Validation loss: 2.5239825104474654

Epoch: 6| Step: 5
Training loss: 2.0715922305093817
Validation loss: 2.547609365404251

Epoch: 6| Step: 6
Training loss: 1.5952298642687004
Validation loss: 2.486137135145034

Epoch: 6| Step: 7
Training loss: 2.0172558478160614
Validation loss: 2.4802127002209504

Epoch: 6| Step: 8
Training loss: 2.0810340654773642
Validation loss: 2.5080592332102514

Epoch: 6| Step: 9
Training loss: 2.046659385448679
Validation loss: 2.477058751957237

Epoch: 6| Step: 10
Training loss: 2.0295722488208185
Validation loss: 2.504622995409598

Epoch: 6| Step: 11
Training loss: 2.214683351982477
Validation loss: 2.483398685254735

Epoch: 6| Step: 12
Training loss: 2.3281434333634765
Validation loss: 2.4887854758627026

Epoch: 6| Step: 13
Training loss: 2.5724278241737895
Validation loss: 2.498687433414473

Epoch: 331| Step: 0
Training loss: 2.758546207507693
Validation loss: 2.4955689857874512

Epoch: 6| Step: 1
Training loss: 2.503181531174904
Validation loss: 2.5092450318563824

Epoch: 6| Step: 2
Training loss: 2.6798626811873687
Validation loss: 2.5233589601309268

Epoch: 6| Step: 3
Training loss: 2.1844646648291675
Validation loss: 2.495921879797182

Epoch: 6| Step: 4
Training loss: 1.8388771709185314
Validation loss: 2.4985254153545178

Epoch: 6| Step: 5
Training loss: 1.691167237483428
Validation loss: 2.504436155351058

Epoch: 6| Step: 6
Training loss: 1.7332274618583088
Validation loss: 2.532725419809646

Epoch: 6| Step: 7
Training loss: 2.0709098673851085
Validation loss: 2.519597372840994

Epoch: 6| Step: 8
Training loss: 1.988864895458637
Validation loss: 2.4826997430867306

Epoch: 6| Step: 9
Training loss: 2.044920475912845
Validation loss: 2.465922093101635

Epoch: 6| Step: 10
Training loss: 2.1357667465437533
Validation loss: 2.544071065520877

Epoch: 6| Step: 11
Training loss: 2.3043299510785125
Validation loss: 2.5228229428238933

Epoch: 6| Step: 12
Training loss: 1.557396986173832
Validation loss: 2.5025112070852984

Epoch: 6| Step: 13
Training loss: 2.516406015030744
Validation loss: 2.5134826242665325

Epoch: 332| Step: 0
Training loss: 2.201361741929151
Validation loss: 2.5316145378812602

Epoch: 6| Step: 1
Training loss: 1.6468173919967593
Validation loss: 2.504893827946851

Epoch: 6| Step: 2
Training loss: 2.9306064639458156
Validation loss: 2.4878333939479464

Epoch: 6| Step: 3
Training loss: 2.1933221992202343
Validation loss: 2.477073928468931

Epoch: 6| Step: 4
Training loss: 2.0096173319773807
Validation loss: 2.4905067434197896

Epoch: 6| Step: 5
Training loss: 1.8069895144539936
Validation loss: 2.497642208185643

Epoch: 6| Step: 6
Training loss: 1.7098861320685956
Validation loss: 2.5107903860818492

Epoch: 6| Step: 7
Training loss: 1.6571852005049355
Validation loss: 2.53082557542215

Epoch: 6| Step: 8
Training loss: 2.2906244046365294
Validation loss: 2.5124132191484576

Epoch: 6| Step: 9
Training loss: 2.4698524427933672
Validation loss: 2.4865102148744294

Epoch: 6| Step: 10
Training loss: 2.178350004070598
Validation loss: 2.5476095243984878

Epoch: 6| Step: 11
Training loss: 2.3922193608569815
Validation loss: 2.479001920180595

Epoch: 6| Step: 12
Training loss: 1.7428850907065987
Validation loss: 2.543793336430051

Epoch: 6| Step: 13
Training loss: 2.578298851856088
Validation loss: 2.529330933031507

Epoch: 333| Step: 0
Training loss: 1.9433978359691273
Validation loss: 2.4952124952042003

Epoch: 6| Step: 1
Training loss: 2.568486176468251
Validation loss: 2.5006793365597915

Epoch: 6| Step: 2
Training loss: 2.198616880515197
Validation loss: 2.508013110832095

Epoch: 6| Step: 3
Training loss: 2.471409970220595
Validation loss: 2.55897924641999

Epoch: 6| Step: 4
Training loss: 2.3032683577622155
Validation loss: 2.531569798588456

Epoch: 6| Step: 5
Training loss: 2.105685928835541
Validation loss: 2.544383441010288

Epoch: 6| Step: 6
Training loss: 2.161401096796453
Validation loss: 2.445575071897625

Epoch: 6| Step: 7
Training loss: 2.3756363668674143
Validation loss: 2.5267897869536395

Epoch: 6| Step: 8
Training loss: 2.15449386069591
Validation loss: 2.489751751317855

Epoch: 6| Step: 9
Training loss: 1.6912578843659691
Validation loss: 2.5192427458328592

Epoch: 6| Step: 10
Training loss: 1.5305230887066315
Validation loss: 2.5379442997238675

Epoch: 6| Step: 11
Training loss: 2.347834169370834
Validation loss: 2.4914965766565365

Epoch: 6| Step: 12
Training loss: 2.1956558773520243
Validation loss: 2.4743264519084467

Epoch: 6| Step: 13
Training loss: 1.9549391599003134
Validation loss: 2.501437385151537

Epoch: 334| Step: 0
Training loss: 1.9361972736151492
Validation loss: 2.5253844589946004

Epoch: 6| Step: 1
Training loss: 2.215528594207646
Validation loss: 2.497184373804349

Epoch: 6| Step: 2
Training loss: 2.373002668055318
Validation loss: 2.4693367653943397

Epoch: 6| Step: 3
Training loss: 1.9077581474441156
Validation loss: 2.5244916078580273

Epoch: 6| Step: 4
Training loss: 1.8687783331620937
Validation loss: 2.5239474798031307

Epoch: 6| Step: 5
Training loss: 2.1169094452084263
Validation loss: 2.5480569834262154

Epoch: 6| Step: 6
Training loss: 2.603711589469482
Validation loss: 2.5509080931152295

Epoch: 6| Step: 7
Training loss: 2.4256711679933813
Validation loss: 2.52515767272338

Epoch: 6| Step: 8
Training loss: 2.6460590316346426
Validation loss: 2.511907039548295

Epoch: 6| Step: 9
Training loss: 1.7848616008371816
Validation loss: 2.507922711699705

Epoch: 6| Step: 10
Training loss: 2.2526797125759295
Validation loss: 2.4856668978943595

Epoch: 6| Step: 11
Training loss: 1.8675772288132197
Validation loss: 2.52377434326287

Epoch: 6| Step: 12
Training loss: 2.1748499632200633
Validation loss: 2.486169844808748

Epoch: 6| Step: 13
Training loss: 1.1724320677088411
Validation loss: 2.520029163629696

Epoch: 335| Step: 0
Training loss: 2.2610018158829024
Validation loss: 2.460204304277347

Epoch: 6| Step: 1
Training loss: 2.046117977481014
Validation loss: 2.521737702171374

Epoch: 6| Step: 2
Training loss: 1.59835225732849
Validation loss: 2.4957835757551177

Epoch: 6| Step: 3
Training loss: 2.2076907632557035
Validation loss: 2.489308252496483

Epoch: 6| Step: 4
Training loss: 2.3420784648126878
Validation loss: 2.517156721753816

Epoch: 6| Step: 5
Training loss: 2.0766749091109817
Validation loss: 2.503023134771808

Epoch: 6| Step: 6
Training loss: 2.125113989072759
Validation loss: 2.539887338447357

Epoch: 6| Step: 7
Training loss: 2.0582838024198002
Validation loss: 2.5230885306953175

Epoch: 6| Step: 8
Training loss: 2.2543465698243166
Validation loss: 2.4784187851286044

Epoch: 6| Step: 9
Training loss: 2.1900580571809605
Validation loss: 2.477088290389081

Epoch: 6| Step: 10
Training loss: 2.1342825382250616
Validation loss: 2.548994460678095

Epoch: 6| Step: 11
Training loss: 2.357395579674184
Validation loss: 2.5150764278409072

Epoch: 6| Step: 12
Training loss: 2.512921794198161
Validation loss: 2.509879532234537

Epoch: 6| Step: 13
Training loss: 1.9912324299010216
Validation loss: 2.4962602762299184

Epoch: 336| Step: 0
Training loss: 2.015443305764268
Validation loss: 2.5154498026598944

Epoch: 6| Step: 1
Training loss: 1.8965832481185916
Validation loss: 2.5375573257314827

Epoch: 6| Step: 2
Training loss: 2.123328729781226
Validation loss: 2.4852703996444623

Epoch: 6| Step: 3
Training loss: 2.074302887153023
Validation loss: 2.4942522445639486

Epoch: 6| Step: 4
Training loss: 2.1507185600170597
Validation loss: 2.479312014194708

Epoch: 6| Step: 5
Training loss: 2.053060721635186
Validation loss: 2.5009892367708404

Epoch: 6| Step: 6
Training loss: 1.8822068629313098
Validation loss: 2.4974192321893174

Epoch: 6| Step: 7
Training loss: 3.1139978136999433
Validation loss: 2.511732551486903

Epoch: 6| Step: 8
Training loss: 2.394614586927921
Validation loss: 2.5141451154045655

Epoch: 6| Step: 9
Training loss: 1.565202283613575
Validation loss: 2.4879473233253404

Epoch: 6| Step: 10
Training loss: 2.2444538000853957
Validation loss: 2.4920268683843325

Epoch: 6| Step: 11
Training loss: 2.3290172121780426
Validation loss: 2.504191442290656

Epoch: 6| Step: 12
Training loss: 1.8482388309826003
Validation loss: 2.531757700330598

Epoch: 6| Step: 13
Training loss: 1.760312756362807
Validation loss: 2.4829698049262916

Epoch: 337| Step: 0
Training loss: 1.641720070268843
Validation loss: 2.525662330499977

Epoch: 6| Step: 1
Training loss: 2.19415002637156
Validation loss: 2.524389923025352

Epoch: 6| Step: 2
Training loss: 2.80663043121844
Validation loss: 2.523243155920412

Epoch: 6| Step: 3
Training loss: 1.7475361509499463
Validation loss: 2.496521670652988

Epoch: 6| Step: 4
Training loss: 2.145729161175211
Validation loss: 2.4981795050653846

Epoch: 6| Step: 5
Training loss: 2.0134575597488187
Validation loss: 2.4951389552365453

Epoch: 6| Step: 6
Training loss: 2.6321971864781366
Validation loss: 2.4828853318970334

Epoch: 6| Step: 7
Training loss: 2.209662079673645
Validation loss: 2.460005265860629

Epoch: 6| Step: 8
Training loss: 2.0785902836149965
Validation loss: 2.4951666388050087

Epoch: 6| Step: 9
Training loss: 1.8816878889569182
Validation loss: 2.4898870060422595

Epoch: 6| Step: 10
Training loss: 1.5239496397273267
Validation loss: 2.530828730809735

Epoch: 6| Step: 11
Training loss: 1.8533782425706253
Validation loss: 2.49294385536879

Epoch: 6| Step: 12
Training loss: 2.9793097366089403
Validation loss: 2.5070263178451966

Epoch: 6| Step: 13
Training loss: 2.0228747907312083
Validation loss: 2.5125259186659745

Epoch: 338| Step: 0
Training loss: 2.431521002956253
Validation loss: 2.49770910244022

Epoch: 6| Step: 1
Training loss: 2.2804246219287383
Validation loss: 2.503085469934178

Epoch: 6| Step: 2
Training loss: 1.8367202713350383
Validation loss: 2.5143389269457654

Epoch: 6| Step: 3
Training loss: 2.2364204487629378
Validation loss: 2.5160404148435664

Epoch: 6| Step: 4
Training loss: 2.4108583982474263
Validation loss: 2.524325209408406

Epoch: 6| Step: 5
Training loss: 2.8141169668260977
Validation loss: 2.490007151709441

Epoch: 6| Step: 6
Training loss: 1.8112501899713873
Validation loss: 2.4901338115335343

Epoch: 6| Step: 7
Training loss: 2.0828693127449474
Validation loss: 2.4740774405563117

Epoch: 6| Step: 8
Training loss: 2.3434709509987637
Validation loss: 2.531472185603366

Epoch: 6| Step: 9
Training loss: 2.153104394999602
Validation loss: 2.490697067806725

Epoch: 6| Step: 10
Training loss: 1.8437896982865396
Validation loss: 2.5191482200648823

Epoch: 6| Step: 11
Training loss: 1.5104896615465992
Validation loss: 2.5020715457602085

Epoch: 6| Step: 12
Training loss: 2.0224994856523724
Validation loss: 2.5437968879226833

Epoch: 6| Step: 13
Training loss: 1.915019329461534
Validation loss: 2.4860320980310235

Epoch: 339| Step: 0
Training loss: 1.863992359411764
Validation loss: 2.5188097932729527

Epoch: 6| Step: 1
Training loss: 1.9830557575514571
Validation loss: 2.536357539972434

Epoch: 6| Step: 2
Training loss: 2.2314074890804276
Validation loss: 2.506614111726522

Epoch: 6| Step: 3
Training loss: 2.9554251941654868
Validation loss: 2.5040513610692425

Epoch: 6| Step: 4
Training loss: 2.1122829032264923
Validation loss: 2.5566830163990613

Epoch: 6| Step: 5
Training loss: 1.8547172871795174
Validation loss: 2.5072941352177054

Epoch: 6| Step: 6
Training loss: 1.6681153279921326
Validation loss: 2.489863768411252

Epoch: 6| Step: 7
Training loss: 2.0038842391502545
Validation loss: 2.4865610085646357

Epoch: 6| Step: 8
Training loss: 1.5967188839082245
Validation loss: 2.528222629824924

Epoch: 6| Step: 9
Training loss: 2.054568443185073
Validation loss: 2.51270723132626

Epoch: 6| Step: 10
Training loss: 1.8181708839477861
Validation loss: 2.4958175066481174

Epoch: 6| Step: 11
Training loss: 2.327189212622742
Validation loss: 2.5011278315662246

Epoch: 6| Step: 12
Training loss: 2.9800530739992768
Validation loss: 2.5550618389933204

Epoch: 6| Step: 13
Training loss: 2.733348195880707
Validation loss: 2.478190591752008

Epoch: 340| Step: 0
Training loss: 1.8425200287598573
Validation loss: 2.5215332624341436

Epoch: 6| Step: 1
Training loss: 2.9909832874317104
Validation loss: 2.5167272832093

Epoch: 6| Step: 2
Training loss: 3.0300841301547106
Validation loss: 2.5001812069347706

Epoch: 6| Step: 3
Training loss: 1.6853761376536438
Validation loss: 2.495278938842359

Epoch: 6| Step: 4
Training loss: 2.2574114063744326
Validation loss: 2.534133808859484

Epoch: 6| Step: 5
Training loss: 1.662546102702003
Validation loss: 2.526370428621472

Epoch: 6| Step: 6
Training loss: 1.8030086486405865
Validation loss: 2.4911623822238926

Epoch: 6| Step: 7
Training loss: 1.8820625806126983
Validation loss: 2.518667459302144

Epoch: 6| Step: 8
Training loss: 1.6042385167796847
Validation loss: 2.4486606320034983

Epoch: 6| Step: 9
Training loss: 1.982492710595602
Validation loss: 2.51659014803579

Epoch: 6| Step: 10
Training loss: 1.9207530895140286
Validation loss: 2.4885217894832095

Epoch: 6| Step: 11
Training loss: 2.616130193964448
Validation loss: 2.5086686963234666

Epoch: 6| Step: 12
Training loss: 2.0646884751581007
Validation loss: 2.5012330992939344

Epoch: 6| Step: 13
Training loss: 1.7238199537659695
Validation loss: 2.5608511991907337

Epoch: 341| Step: 0
Training loss: 2.0160344617259645
Validation loss: 2.4959147987407775

Epoch: 6| Step: 1
Training loss: 2.091093513211127
Validation loss: 2.5364419367612467

Epoch: 6| Step: 2
Training loss: 1.9527043614424615
Validation loss: 2.5323903401500854

Epoch: 6| Step: 3
Training loss: 2.272360844983572
Validation loss: 2.515253965877013

Epoch: 6| Step: 4
Training loss: 1.3319358903417724
Validation loss: 2.5116545632095897

Epoch: 6| Step: 5
Training loss: 1.7723967737611452
Validation loss: 2.5103877045513796

Epoch: 6| Step: 6
Training loss: 2.785352788253096
Validation loss: 2.506409787524728

Epoch: 6| Step: 7
Training loss: 2.5359819240286874
Validation loss: 2.5290097540110166

Epoch: 6| Step: 8
Training loss: 2.0726129382827985
Validation loss: 2.5024296162725475

Epoch: 6| Step: 9
Training loss: 2.954314784402115
Validation loss: 2.498720080359833

Epoch: 6| Step: 10
Training loss: 1.7409057007328095
Validation loss: 2.50631423870733

Epoch: 6| Step: 11
Training loss: 2.5357995297170732
Validation loss: 2.4812576435996627

Epoch: 6| Step: 12
Training loss: 1.8943887244029134
Validation loss: 2.476396846979495

Epoch: 6| Step: 13
Training loss: 1.7537633077234829
Validation loss: 2.5216638835364624

Epoch: 342| Step: 0
Training loss: 2.4924740043669598
Validation loss: 2.4824255318501494

Epoch: 6| Step: 1
Training loss: 2.1527422693530402
Validation loss: 2.52099664644365

Epoch: 6| Step: 2
Training loss: 2.5276003299047054
Validation loss: 2.492243012632861

Epoch: 6| Step: 3
Training loss: 2.0291529467652176
Validation loss: 2.518325607506646

Epoch: 6| Step: 4
Training loss: 1.6512612839572416
Validation loss: 2.535387401887318

Epoch: 6| Step: 5
Training loss: 2.4776180677255852
Validation loss: 2.5184539641308628

Epoch: 6| Step: 6
Training loss: 2.423034095269226
Validation loss: 2.5178736152255135

Epoch: 6| Step: 7
Training loss: 2.151202056545581
Validation loss: 2.522304846461478

Epoch: 6| Step: 8
Training loss: 1.9293994765834468
Validation loss: 2.486335892226919

Epoch: 6| Step: 9
Training loss: 2.3208208651067923
Validation loss: 2.4937999198827563

Epoch: 6| Step: 10
Training loss: 2.2542843823771745
Validation loss: 2.518731906062206

Epoch: 6| Step: 11
Training loss: 1.3126491280257968
Validation loss: 2.45013111170514

Epoch: 6| Step: 12
Training loss: 2.135904495218668
Validation loss: 2.498972140021101

Epoch: 6| Step: 13
Training loss: 2.0817991202459676
Validation loss: 2.500465044227216

Epoch: 343| Step: 0
Training loss: 1.8226386012577145
Validation loss: 2.5098770277119518

Epoch: 6| Step: 1
Training loss: 2.1433722694305275
Validation loss: 2.513909059060366

Epoch: 6| Step: 2
Training loss: 2.4598083812238034
Validation loss: 2.513024317459343

Epoch: 6| Step: 3
Training loss: 2.3452159111978363
Validation loss: 2.5547057301011127

Epoch: 6| Step: 4
Training loss: 2.1855740379302317
Validation loss: 2.522053353081037

Epoch: 6| Step: 5
Training loss: 2.009361530454587
Validation loss: 2.524729012237542

Epoch: 6| Step: 6
Training loss: 2.5831230036932955
Validation loss: 2.499493369173641

Epoch: 6| Step: 7
Training loss: 2.3092965284341016
Validation loss: 2.4749482802523266

Epoch: 6| Step: 8
Training loss: 1.7024135678571672
Validation loss: 2.495300324007093

Epoch: 6| Step: 9
Training loss: 1.2926211163497792
Validation loss: 2.4892046885842403

Epoch: 6| Step: 10
Training loss: 2.278328788862554
Validation loss: 2.501019083504962

Epoch: 6| Step: 11
Training loss: 2.022820102365612
Validation loss: 2.5501202511729355

Epoch: 6| Step: 12
Training loss: 2.543058566662223
Validation loss: 2.524911799109244

Epoch: 6| Step: 13
Training loss: 2.500199309987235
Validation loss: 2.49866232462742

Epoch: 344| Step: 0
Training loss: 2.2616248234827996
Validation loss: 2.492040005837566

Epoch: 6| Step: 1
Training loss: 2.3073120690355773
Validation loss: 2.501906783490245

Epoch: 6| Step: 2
Training loss: 2.1336798947689095
Validation loss: 2.5208443282343636

Epoch: 6| Step: 3
Training loss: 2.5899757593265087
Validation loss: 2.509464575762063

Epoch: 6| Step: 4
Training loss: 2.498605339133628
Validation loss: 2.5093754742792194

Epoch: 6| Step: 5
Training loss: 1.6484587609244297
Validation loss: 2.5078248575799496

Epoch: 6| Step: 6
Training loss: 2.0531357391866205
Validation loss: 2.509877352523749

Epoch: 6| Step: 7
Training loss: 1.654960346150237
Validation loss: 2.5576616445694342

Epoch: 6| Step: 8
Training loss: 2.260880969012407
Validation loss: 2.5419755751647064

Epoch: 6| Step: 9
Training loss: 1.7249538470742145
Validation loss: 2.5117529800387515

Epoch: 6| Step: 10
Training loss: 2.140849526317984
Validation loss: 2.5383658150781363

Epoch: 6| Step: 11
Training loss: 2.7944955773938838
Validation loss: 2.5328801687733407

Epoch: 6| Step: 12
Training loss: 1.920665577522842
Validation loss: 2.52260316312155

Epoch: 6| Step: 13
Training loss: 1.3163962887350302
Validation loss: 2.5224272338983083

Epoch: 345| Step: 0
Training loss: 1.8719056981901814
Validation loss: 2.5300782556707033

Epoch: 6| Step: 1
Training loss: 1.8126707325466884
Validation loss: 2.52499719678686

Epoch: 6| Step: 2
Training loss: 2.657688424579901
Validation loss: 2.5099419994489574

Epoch: 6| Step: 3
Training loss: 1.8397678108498787
Validation loss: 2.5262211277377844

Epoch: 6| Step: 4
Training loss: 2.1614901130515447
Validation loss: 2.497473179638299

Epoch: 6| Step: 5
Training loss: 2.102655403118327
Validation loss: 2.501907252791223

Epoch: 6| Step: 6
Training loss: 2.7587382462134036
Validation loss: 2.5142493721414096

Epoch: 6| Step: 7
Training loss: 2.2574414010960115
Validation loss: 2.5189431315150905

Epoch: 6| Step: 8
Training loss: 1.7051069294352497
Validation loss: 2.523227310176493

Epoch: 6| Step: 9
Training loss: 1.81869762646751
Validation loss: 2.5139424189861614

Epoch: 6| Step: 10
Training loss: 2.200087922680181
Validation loss: 2.487114237513924

Epoch: 6| Step: 11
Training loss: 2.0682726905820283
Validation loss: 2.53660660753128

Epoch: 6| Step: 12
Training loss: 2.52279683297598
Validation loss: 2.5153665625771473

Epoch: 6| Step: 13
Training loss: 2.0385856216934077
Validation loss: 2.5288097306973882

Epoch: 346| Step: 0
Training loss: 1.9907978671483468
Validation loss: 2.5148315686689937

Epoch: 6| Step: 1
Training loss: 2.0666209579868484
Validation loss: 2.523839037484126

Epoch: 6| Step: 2
Training loss: 1.7953230416807635
Validation loss: 2.5491700538348567

Epoch: 6| Step: 3
Training loss: 1.9913726935509488
Validation loss: 2.4867130627892706

Epoch: 6| Step: 4
Training loss: 2.78119899402953
Validation loss: 2.4988923633938627

Epoch: 6| Step: 5
Training loss: 2.2572935359320994
Validation loss: 2.4905535636496676

Epoch: 6| Step: 6
Training loss: 2.979854655465631
Validation loss: 2.500895919031707

Epoch: 6| Step: 7
Training loss: 2.0139448866969603
Validation loss: 2.5258833299054246

Epoch: 6| Step: 8
Training loss: 2.505655757632488
Validation loss: 2.533478258836315

Epoch: 6| Step: 9
Training loss: 1.7320320181012547
Validation loss: 2.4803628149739323

Epoch: 6| Step: 10
Training loss: 1.3486870403284592
Validation loss: 2.485034929532932

Epoch: 6| Step: 11
Training loss: 2.08931410307921
Validation loss: 2.5169239139128976

Epoch: 6| Step: 12
Training loss: 2.065216010112868
Validation loss: 2.487408791218591

Epoch: 6| Step: 13
Training loss: 2.415855063158331
Validation loss: 2.486964503479501

Epoch: 347| Step: 0
Training loss: 2.694358413563828
Validation loss: 2.502663614679459

Epoch: 6| Step: 1
Training loss: 1.710679126199575
Validation loss: 2.5047197504849628

Epoch: 6| Step: 2
Training loss: 2.4813282836556576
Validation loss: 2.5035433669205847

Epoch: 6| Step: 3
Training loss: 2.8937893430206327
Validation loss: 2.5356946839493752

Epoch: 6| Step: 4
Training loss: 2.192329416283222
Validation loss: 2.5428803657914254

Epoch: 6| Step: 5
Training loss: 1.878295926204192
Validation loss: 2.530089912248466

Epoch: 6| Step: 6
Training loss: 2.275539409701036
Validation loss: 2.5099796518487163

Epoch: 6| Step: 7
Training loss: 1.6020475815982602
Validation loss: 2.5443703405707803

Epoch: 6| Step: 8
Training loss: 2.1020340514541864
Validation loss: 2.5170738548728298

Epoch: 6| Step: 9
Training loss: 2.573472049298241
Validation loss: 2.540623534684395

Epoch: 6| Step: 10
Training loss: 1.2922620426619778
Validation loss: 2.5288329723649636

Epoch: 6| Step: 11
Training loss: 1.7958237599813218
Validation loss: 2.4693766595976365

Epoch: 6| Step: 12
Training loss: 1.7153676824993906
Validation loss: 2.5097193307055585

Epoch: 6| Step: 13
Training loss: 2.1891422102014286
Validation loss: 2.5225719624876013

Epoch: 348| Step: 0
Training loss: 1.8647687880140704
Validation loss: 2.4944564844563772

Epoch: 6| Step: 1
Training loss: 2.4921107743748814
Validation loss: 2.4744848856557042

Epoch: 6| Step: 2
Training loss: 1.6767107468733
Validation loss: 2.5157063187678688

Epoch: 6| Step: 3
Training loss: 3.055298727011697
Validation loss: 2.531599239724484

Epoch: 6| Step: 4
Training loss: 2.3808455556792336
Validation loss: 2.5335269674522016

Epoch: 6| Step: 5
Training loss: 1.3935384341751014
Validation loss: 2.5568554465688935

Epoch: 6| Step: 6
Training loss: 2.1820150001213086
Validation loss: 2.54725343243214

Epoch: 6| Step: 7
Training loss: 1.78648263749772
Validation loss: 2.5257571189636083

Epoch: 6| Step: 8
Training loss: 1.5563207893664026
Validation loss: 2.5115276413175134

Epoch: 6| Step: 9
Training loss: 1.8554143957910434
Validation loss: 2.520154754039533

Epoch: 6| Step: 10
Training loss: 2.62764171098415
Validation loss: 2.508540198739806

Epoch: 6| Step: 11
Training loss: 2.422806099369407
Validation loss: 2.4929570286096165

Epoch: 6| Step: 12
Training loss: 1.6637244082574103
Validation loss: 2.500873617098256

Epoch: 6| Step: 13
Training loss: 2.49032054078868
Validation loss: 2.511045745171029

Epoch: 349| Step: 0
Training loss: 2.0998948297959146
Validation loss: 2.4855322128797677

Epoch: 6| Step: 1
Training loss: 2.3718300796295972
Validation loss: 2.5233425908736993

Epoch: 6| Step: 2
Training loss: 2.0793049839570417
Validation loss: 2.501977821130807

Epoch: 6| Step: 3
Training loss: 2.1251191498506645
Validation loss: 2.492009045963727

Epoch: 6| Step: 4
Training loss: 1.7996863886701753
Validation loss: 2.5138348692937154

Epoch: 6| Step: 5
Training loss: 2.3390554587258854
Validation loss: 2.492352431626643

Epoch: 6| Step: 6
Training loss: 1.4620737155537455
Validation loss: 2.52116337643396

Epoch: 6| Step: 7
Training loss: 2.9668331985309306
Validation loss: 2.512753998042423

Epoch: 6| Step: 8
Training loss: 2.3151693660335977
Validation loss: 2.5134228531387257

Epoch: 6| Step: 9
Training loss: 1.5355505206468265
Validation loss: 2.515229915838942

Epoch: 6| Step: 10
Training loss: 2.3752764490757055
Validation loss: 2.5340236728574235

Epoch: 6| Step: 11
Training loss: 1.8228206136919556
Validation loss: 2.5125942154807754

Epoch: 6| Step: 12
Training loss: 1.9875010700342908
Validation loss: 2.5102139983747995

Epoch: 6| Step: 13
Training loss: 2.344402171633186
Validation loss: 2.524012474296794

Epoch: 350| Step: 0
Training loss: 2.059278341754305
Validation loss: 2.4605258954880234

Epoch: 6| Step: 1
Training loss: 2.5518899234482046
Validation loss: 2.503011004932019

Epoch: 6| Step: 2
Training loss: 1.7656244598657913
Validation loss: 2.518288347628586

Epoch: 6| Step: 3
Training loss: 1.831082942490332
Validation loss: 2.5009963613752153

Epoch: 6| Step: 4
Training loss: 2.364567884039018
Validation loss: 2.504702901688903

Epoch: 6| Step: 5
Training loss: 2.330676837241345
Validation loss: 2.5044161656324073

Epoch: 6| Step: 6
Training loss: 2.306633596385354
Validation loss: 2.5120756719599617

Epoch: 6| Step: 7
Training loss: 2.0444050803518268
Validation loss: 2.4975420589860193

Epoch: 6| Step: 8
Training loss: 2.49457849110769
Validation loss: 2.5384946742566195

Epoch: 6| Step: 9
Training loss: 1.9838444759031726
Validation loss: 2.501530267123576

Epoch: 6| Step: 10
Training loss: 2.1605586251460225
Validation loss: 2.5317770326861933

Epoch: 6| Step: 11
Training loss: 2.7532121798235796
Validation loss: 2.5448403232419556

Epoch: 6| Step: 12
Training loss: 1.7472529649009334
Validation loss: 2.5058888041268776

Epoch: 6| Step: 13
Training loss: 1.4039649199643411
Validation loss: 2.5310539950584134

Epoch: 351| Step: 0
Training loss: 1.9122498940881616
Validation loss: 2.5031222187050495

Epoch: 6| Step: 1
Training loss: 1.8705179686408524
Validation loss: 2.5221309791530264

Epoch: 6| Step: 2
Training loss: 1.861282780386154
Validation loss: 2.4953326454119678

Epoch: 6| Step: 3
Training loss: 2.2049988697767064
Validation loss: 2.490858274573262

Epoch: 6| Step: 4
Training loss: 2.039864101184206
Validation loss: 2.524212981854982

Epoch: 6| Step: 5
Training loss: 2.339535089427356
Validation loss: 2.524619341276534

Epoch: 6| Step: 6
Training loss: 2.5586094047708103
Validation loss: 2.5274568269881943

Epoch: 6| Step: 7
Training loss: 1.8276314354427041
Validation loss: 2.5142810339441968

Epoch: 6| Step: 8
Training loss: 1.4154895305024033
Validation loss: 2.5136998195235725

Epoch: 6| Step: 9
Training loss: 2.5837097714064807
Validation loss: 2.519553252474884

Epoch: 6| Step: 10
Training loss: 2.5480321584016603
Validation loss: 2.480135879098812

Epoch: 6| Step: 11
Training loss: 2.295349444876897
Validation loss: 2.4964136600395896

Epoch: 6| Step: 12
Training loss: 2.16374562281227
Validation loss: 2.5054932539449255

Epoch: 6| Step: 13
Training loss: 1.618627229843825
Validation loss: 2.5202522387757345

Epoch: 352| Step: 0
Training loss: 2.332762534851404
Validation loss: 2.490912182978786

Epoch: 6| Step: 1
Training loss: 1.9079815863834408
Validation loss: 2.500441446604275

Epoch: 6| Step: 2
Training loss: 1.8008005799023556
Validation loss: 2.508148441757665

Epoch: 6| Step: 3
Training loss: 1.5633126243786775
Validation loss: 2.5012617270283255

Epoch: 6| Step: 4
Training loss: 2.083934836974189
Validation loss: 2.519603817552833

Epoch: 6| Step: 5
Training loss: 1.7258659787531103
Validation loss: 2.49268799480782

Epoch: 6| Step: 6
Training loss: 2.232601395511849
Validation loss: 2.5179857608357663

Epoch: 6| Step: 7
Training loss: 2.121245826622674
Validation loss: 2.499006395905749

Epoch: 6| Step: 8
Training loss: 2.756229800195698
Validation loss: 2.5031406609954496

Epoch: 6| Step: 9
Training loss: 2.1374548388612533
Validation loss: 2.5148667767527346

Epoch: 6| Step: 10
Training loss: 1.7748206034522127
Validation loss: 2.4981344666387173

Epoch: 6| Step: 11
Training loss: 2.3716855261189767
Validation loss: 2.49612425147232

Epoch: 6| Step: 12
Training loss: 2.2756567541524637
Validation loss: 2.524372043213497

Epoch: 6| Step: 13
Training loss: 2.6546543489735934
Validation loss: 2.448891501154361

Epoch: 353| Step: 0
Training loss: 1.94359755086876
Validation loss: 2.5053716058905007

Epoch: 6| Step: 1
Training loss: 2.1581482202787043
Validation loss: 2.481053922909108

Epoch: 6| Step: 2
Training loss: 1.8384149595983292
Validation loss: 2.531060650649523

Epoch: 6| Step: 3
Training loss: 2.236917822769803
Validation loss: 2.534750150701896

Epoch: 6| Step: 4
Training loss: 2.337727043018738
Validation loss: 2.5270788507819377

Epoch: 6| Step: 5
Training loss: 2.7311434587522414
Validation loss: 2.4958446059379096

Epoch: 6| Step: 6
Training loss: 1.4073817043834238
Validation loss: 2.500854241645204

Epoch: 6| Step: 7
Training loss: 1.9253971111353203
Validation loss: 2.5119836187528075

Epoch: 6| Step: 8
Training loss: 2.0594010624951262
Validation loss: 2.4812721073538597

Epoch: 6| Step: 9
Training loss: 1.569171016171843
Validation loss: 2.507286242735953

Epoch: 6| Step: 10
Training loss: 2.9814243609544704
Validation loss: 2.5164810962900757

Epoch: 6| Step: 11
Training loss: 1.913580884481405
Validation loss: 2.504641190207975

Epoch: 6| Step: 12
Training loss: 2.1720164959599004
Validation loss: 2.458078101750433

Epoch: 6| Step: 13
Training loss: 1.4510872612129642
Validation loss: 2.4704557564202303

Epoch: 354| Step: 0
Training loss: 2.3089181120284406
Validation loss: 2.506953389285497

Epoch: 6| Step: 1
Training loss: 2.4007435997724005
Validation loss: 2.486011369950537

Epoch: 6| Step: 2
Training loss: 1.3634083423561287
Validation loss: 2.5238677846345383

Epoch: 6| Step: 3
Training loss: 2.4999416344505283
Validation loss: 2.5234342205697193

Epoch: 6| Step: 4
Training loss: 2.046993572498959
Validation loss: 2.4990875076022006

Epoch: 6| Step: 5
Training loss: 2.3646526802638075
Validation loss: 2.5049325428206943

Epoch: 6| Step: 6
Training loss: 1.642882038899261
Validation loss: 2.4676403325940757

Epoch: 6| Step: 7
Training loss: 2.0552295506486313
Validation loss: 2.508582592561487

Epoch: 6| Step: 8
Training loss: 2.116601841852547
Validation loss: 2.512690973265958

Epoch: 6| Step: 9
Training loss: 2.1353533355501764
Validation loss: 2.4774851280068932

Epoch: 6| Step: 10
Training loss: 2.038901954849236
Validation loss: 2.465239384839585

Epoch: 6| Step: 11
Training loss: 2.4415810484299403
Validation loss: 2.5046860451029707

Epoch: 6| Step: 12
Training loss: 2.2200733590248554
Validation loss: 2.5145409093387716

Epoch: 6| Step: 13
Training loss: 1.9804617676621246
Validation loss: 2.5010378908390734

Epoch: 355| Step: 0
Training loss: 3.143576682073956
Validation loss: 2.4747674000959226

Epoch: 6| Step: 1
Training loss: 1.7015803620773182
Validation loss: 2.5287503877475372

Epoch: 6| Step: 2
Training loss: 1.9322771618513743
Validation loss: 2.501128298963375

Epoch: 6| Step: 3
Training loss: 1.7703172567493877
Validation loss: 2.4965262182090324

Epoch: 6| Step: 4
Training loss: 2.5352307324863665
Validation loss: 2.5283407479663085

Epoch: 6| Step: 5
Training loss: 1.7207958183478955
Validation loss: 2.497323572930212

Epoch: 6| Step: 6
Training loss: 2.1437533275700758
Validation loss: 2.5280723451605116

Epoch: 6| Step: 7
Training loss: 1.7311639013812166
Validation loss: 2.4908017193328593

Epoch: 6| Step: 8
Training loss: 2.0252282896988993
Validation loss: 2.49549822388951

Epoch: 6| Step: 9
Training loss: 1.4281220751175259
Validation loss: 2.488556848530676

Epoch: 6| Step: 10
Training loss: 1.6935611239480244
Validation loss: 2.514623328534667

Epoch: 6| Step: 11
Training loss: 2.1512942654601117
Validation loss: 2.4948468565827926

Epoch: 6| Step: 12
Training loss: 2.246139923947945
Validation loss: 2.5375158413200034

Epoch: 6| Step: 13
Training loss: 3.3004859566507516
Validation loss: 2.475131975850079

Epoch: 356| Step: 0
Training loss: 1.4205365431266723
Validation loss: 2.5086112294212284

Epoch: 6| Step: 1
Training loss: 2.463981078452991
Validation loss: 2.5221530860048462

Epoch: 6| Step: 2
Training loss: 1.911257124314337
Validation loss: 2.5175466767571604

Epoch: 6| Step: 3
Training loss: 2.7979766551442014
Validation loss: 2.50949332616795

Epoch: 6| Step: 4
Training loss: 2.564062247081607
Validation loss: 2.507317488904222

Epoch: 6| Step: 5
Training loss: 2.4649567253229505
Validation loss: 2.51019788859405

Epoch: 6| Step: 6
Training loss: 2.541499356459064
Validation loss: 2.525005342560514

Epoch: 6| Step: 7
Training loss: 1.7050480615995849
Validation loss: 2.4919026375605733

Epoch: 6| Step: 8
Training loss: 2.593188305438573
Validation loss: 2.495475931246807

Epoch: 6| Step: 9
Training loss: 1.403589741772149
Validation loss: 2.495703523603112

Epoch: 6| Step: 10
Training loss: 1.6689911685936225
Validation loss: 2.526632891876831

Epoch: 6| Step: 11
Training loss: 1.94140115349636
Validation loss: 2.5318104052581494

Epoch: 6| Step: 12
Training loss: 1.5617464918961563
Validation loss: 2.515429297118591

Epoch: 6| Step: 13
Training loss: 1.9716609445694704
Validation loss: 2.523148802374519

Epoch: 357| Step: 0
Training loss: 2.1206393659685765
Validation loss: 2.4753685443677247

Epoch: 6| Step: 1
Training loss: 2.8291937563183995
Validation loss: 2.5131049287754204

Epoch: 6| Step: 2
Training loss: 2.445534985448229
Validation loss: 2.5182250307341447

Epoch: 6| Step: 3
Training loss: 2.3079277407542396
Validation loss: 2.500314184155775

Epoch: 6| Step: 4
Training loss: 2.0833670676996974
Validation loss: 2.4882067149239377

Epoch: 6| Step: 5
Training loss: 2.6294858840473543
Validation loss: 2.513290989746142

Epoch: 6| Step: 6
Training loss: 2.027422306251399
Validation loss: 2.491983026821639

Epoch: 6| Step: 7
Training loss: 1.6239611165836636
Validation loss: 2.4733035791829283

Epoch: 6| Step: 8
Training loss: 1.9622744679698823
Validation loss: 2.509009102015337

Epoch: 6| Step: 9
Training loss: 1.8595174526494134
Validation loss: 2.5153125672615717

Epoch: 6| Step: 10
Training loss: 1.8789973564027844
Validation loss: 2.477407578138623

Epoch: 6| Step: 11
Training loss: 2.210405696898004
Validation loss: 2.4857666076512026

Epoch: 6| Step: 12
Training loss: 1.761385325748551
Validation loss: 2.5007158936159866

Epoch: 6| Step: 13
Training loss: 1.1284680951686936
Validation loss: 2.5174604112622534

Epoch: 358| Step: 0
Training loss: 2.192963018297751
Validation loss: 2.506974841548384

Epoch: 6| Step: 1
Training loss: 2.494569793795259
Validation loss: 2.469842150748691

Epoch: 6| Step: 2
Training loss: 2.4557341288694783
Validation loss: 2.4962683555670107

Epoch: 6| Step: 3
Training loss: 1.8654342144869358
Validation loss: 2.539870434519039

Epoch: 6| Step: 4
Training loss: 1.8495734109574435
Validation loss: 2.518889885610881

Epoch: 6| Step: 5
Training loss: 1.6493283436411137
Validation loss: 2.5000783918252094

Epoch: 6| Step: 6
Training loss: 2.047048080930707
Validation loss: 2.508212376891053

Epoch: 6| Step: 7
Training loss: 1.6064494680797314
Validation loss: 2.4807465020295467

Epoch: 6| Step: 8
Training loss: 3.1530500752797566
Validation loss: 2.478839267019009

Epoch: 6| Step: 9
Training loss: 1.7439656442180536
Validation loss: 2.5081768955054633

Epoch: 6| Step: 10
Training loss: 1.8496664777599703
Validation loss: 2.536267399079062

Epoch: 6| Step: 11
Training loss: 2.0536074972835414
Validation loss: 2.518113318283122

Epoch: 6| Step: 12
Training loss: 2.1618972026371903
Validation loss: 2.4784463042868046

Epoch: 6| Step: 13
Training loss: 2.167887368264203
Validation loss: 2.5356828772183713

Epoch: 359| Step: 0
Training loss: 1.467887056766538
Validation loss: 2.516594289032137

Epoch: 6| Step: 1
Training loss: 1.8992904819012026
Validation loss: 2.5109735433838574

Epoch: 6| Step: 2
Training loss: 2.1740755418498967
Validation loss: 2.4952973836220216

Epoch: 6| Step: 3
Training loss: 2.40981622952899
Validation loss: 2.5119060470191243

Epoch: 6| Step: 4
Training loss: 2.796740565985074
Validation loss: 2.4950521708480653

Epoch: 6| Step: 5
Training loss: 2.346750703610991
Validation loss: 2.5280161275738626

Epoch: 6| Step: 6
Training loss: 2.1005440552179278
Validation loss: 2.5106572025013887

Epoch: 6| Step: 7
Training loss: 1.975571576234566
Validation loss: 2.5137749652939765

Epoch: 6| Step: 8
Training loss: 1.7501207037579345
Validation loss: 2.504274462123453

Epoch: 6| Step: 9
Training loss: 2.0804563366544335
Validation loss: 2.5076997057091135

Epoch: 6| Step: 10
Training loss: 2.1101782505621434
Validation loss: 2.487193789974091

Epoch: 6| Step: 11
Training loss: 1.76754925951914
Validation loss: 2.5343358169605237

Epoch: 6| Step: 12
Training loss: 1.7375908670060698
Validation loss: 2.5002216466457234

Epoch: 6| Step: 13
Training loss: 2.952489552426891
Validation loss: 2.515259097731532

Epoch: 360| Step: 0
Training loss: 1.913114351818083
Validation loss: 2.493413518101372

Epoch: 6| Step: 1
Training loss: 2.929975897263478
Validation loss: 2.5460243890796024

Epoch: 6| Step: 2
Training loss: 2.2194600648082328
Validation loss: 2.5177611591534137

Epoch: 6| Step: 3
Training loss: 2.5608660443003624
Validation loss: 2.482840508559135

Epoch: 6| Step: 4
Training loss: 2.0560841038345234
Validation loss: 2.4908851031011006

Epoch: 6| Step: 5
Training loss: 2.3299817355508363
Validation loss: 2.4846901054324864

Epoch: 6| Step: 6
Training loss: 1.8652865257761841
Validation loss: 2.5249110538505364

Epoch: 6| Step: 7
Training loss: 1.705659712525227
Validation loss: 2.5156861617986137

Epoch: 6| Step: 8
Training loss: 2.131448274489947
Validation loss: 2.4938461848519933

Epoch: 6| Step: 9
Training loss: 1.7633465945364737
Validation loss: 2.5004754403981457

Epoch: 6| Step: 10
Training loss: 1.5111467723440757
Validation loss: 2.503915697105905

Epoch: 6| Step: 11
Training loss: 2.345742764483451
Validation loss: 2.4963408671401286

Epoch: 6| Step: 12
Training loss: 2.214013968550287
Validation loss: 2.4972051138567886

Epoch: 6| Step: 13
Training loss: 1.5517315391203248
Validation loss: 2.49357352115362

Epoch: 361| Step: 0
Training loss: 2.7552275822236885
Validation loss: 2.5102242050633286

Epoch: 6| Step: 1
Training loss: 2.1544230364520143
Validation loss: 2.47331410610696

Epoch: 6| Step: 2
Training loss: 1.4106805307581973
Validation loss: 2.5303225239168787

Epoch: 6| Step: 3
Training loss: 2.2841943004021674
Validation loss: 2.4957014044439947

Epoch: 6| Step: 4
Training loss: 1.5964377683701951
Validation loss: 2.4882074330544914

Epoch: 6| Step: 5
Training loss: 2.335776639266889
Validation loss: 2.5307620650665164

Epoch: 6| Step: 6
Training loss: 1.9597049806399482
Validation loss: 2.50560427671099

Epoch: 6| Step: 7
Training loss: 2.197753960491418
Validation loss: 2.5021956113511

Epoch: 6| Step: 8
Training loss: 2.2221078313419733
Validation loss: 2.5331672062939106

Epoch: 6| Step: 9
Training loss: 1.9740797892893263
Validation loss: 2.4942111653710755

Epoch: 6| Step: 10
Training loss: 2.107001205190523
Validation loss: 2.54551817259681

Epoch: 6| Step: 11
Training loss: 2.142221231563668
Validation loss: 2.474859588309398

Epoch: 6| Step: 12
Training loss: 2.1996022731887885
Validation loss: 2.509429924255953

Epoch: 6| Step: 13
Training loss: 2.1903629641462095
Validation loss: 2.489452985420806

Epoch: 362| Step: 0
Training loss: 2.193608719061198
Validation loss: 2.51732730509447

Epoch: 6| Step: 1
Training loss: 2.054395415573412
Validation loss: 2.496538662974563

Epoch: 6| Step: 2
Training loss: 1.748075175988605
Validation loss: 2.51436854333128

Epoch: 6| Step: 3
Training loss: 2.8413256696970337
Validation loss: 2.4991132927491315

Epoch: 6| Step: 4
Training loss: 1.8911028171508844
Validation loss: 2.53809450892675

Epoch: 6| Step: 5
Training loss: 2.0673246884543017
Validation loss: 2.5016884731643554

Epoch: 6| Step: 6
Training loss: 2.8907414593305267
Validation loss: 2.486147824274496

Epoch: 6| Step: 7
Training loss: 1.309806421260614
Validation loss: 2.552719126082582

Epoch: 6| Step: 8
Training loss: 1.8805330652982881
Validation loss: 2.551016157548957

Epoch: 6| Step: 9
Training loss: 2.1149848093339534
Validation loss: 2.516321451569392

Epoch: 6| Step: 10
Training loss: 2.0036254448114055
Validation loss: 2.5429048428892327

Epoch: 6| Step: 11
Training loss: 1.977652629840844
Validation loss: 2.525947290113658

Epoch: 6| Step: 12
Training loss: 2.1770305231676725
Validation loss: 2.517987858185796

Epoch: 6| Step: 13
Training loss: 1.8463223503467021
Validation loss: 2.5272391428019376

Epoch: 363| Step: 0
Training loss: 1.8647661030732896
Validation loss: 2.540577624074683

Epoch: 6| Step: 1
Training loss: 2.2555546542365783
Validation loss: 2.507782253138817

Epoch: 6| Step: 2
Training loss: 2.589416008287786
Validation loss: 2.4977434977866326

Epoch: 6| Step: 3
Training loss: 1.7266581236997398
Validation loss: 2.470361848265512

Epoch: 6| Step: 4
Training loss: 2.0542063566736277
Validation loss: 2.488695394515293

Epoch: 6| Step: 5
Training loss: 2.374790483569199
Validation loss: 2.5373077190004185

Epoch: 6| Step: 6
Training loss: 2.1189907601097895
Validation loss: 2.5253566183892904

Epoch: 6| Step: 7
Training loss: 1.9024467675359817
Validation loss: 2.4807035560308397

Epoch: 6| Step: 8
Training loss: 2.3125573228484435
Validation loss: 2.514157104853597

Epoch: 6| Step: 9
Training loss: 2.4594061067933297
Validation loss: 2.463357548373269

Epoch: 6| Step: 10
Training loss: 1.4983625216217074
Validation loss: 2.482356802614328

Epoch: 6| Step: 11
Training loss: 1.906319163584232
Validation loss: 2.4606906926623062

Epoch: 6| Step: 12
Training loss: 2.3020466820286276
Validation loss: 2.479820544395341

Epoch: 6| Step: 13
Training loss: 2.104616123453303
Validation loss: 2.525710554445968

Epoch: 364| Step: 0
Training loss: 1.8241940482384713
Validation loss: 2.4995197927055397

Epoch: 6| Step: 1
Training loss: 2.332266279738073
Validation loss: 2.5158181401373776

Epoch: 6| Step: 2
Training loss: 2.1588750147225095
Validation loss: 2.5184229136477154

Epoch: 6| Step: 3
Training loss: 2.041306587177738
Validation loss: 2.535001672846664

Epoch: 6| Step: 4
Training loss: 1.6060995454495306
Validation loss: 2.5043360075918333

Epoch: 6| Step: 5
Training loss: 1.7819626035266374
Validation loss: 2.515764585563819

Epoch: 6| Step: 6
Training loss: 2.398215715423927
Validation loss: 2.49517031601956

Epoch: 6| Step: 7
Training loss: 2.2447159496970253
Validation loss: 2.513475422349843

Epoch: 6| Step: 8
Training loss: 2.057416025258083
Validation loss: 2.5064406380477973

Epoch: 6| Step: 9
Training loss: 2.1641825838890516
Validation loss: 2.4900200810359667

Epoch: 6| Step: 10
Training loss: 2.3707552672965955
Validation loss: 2.4928609230260297

Epoch: 6| Step: 11
Training loss: 1.8215880284113268
Validation loss: 2.4990128855128306

Epoch: 6| Step: 12
Training loss: 2.4885315103005605
Validation loss: 2.520097741324575

Epoch: 6| Step: 13
Training loss: 2.2921901336217934
Validation loss: 2.521706668739345

Epoch: 365| Step: 0
Training loss: 2.331384003497737
Validation loss: 2.506815594666361

Epoch: 6| Step: 1
Training loss: 2.131200383747055
Validation loss: 2.5030346064960356

Epoch: 6| Step: 2
Training loss: 2.7807388693228265
Validation loss: 2.517021248779342

Epoch: 6| Step: 3
Training loss: 2.101105707718516
Validation loss: 2.5074095268238064

Epoch: 6| Step: 4
Training loss: 2.0788731196421777
Validation loss: 2.516842825980978

Epoch: 6| Step: 5
Training loss: 1.0728020776586304
Validation loss: 2.4632314392021937

Epoch: 6| Step: 6
Training loss: 2.8321735214802652
Validation loss: 2.465012474714904

Epoch: 6| Step: 7
Training loss: 1.3587940772521825
Validation loss: 2.500600464809094

Epoch: 6| Step: 8
Training loss: 1.514572171148685
Validation loss: 2.5159935482224203

Epoch: 6| Step: 9
Training loss: 2.1408225754937407
Validation loss: 2.518195243878694

Epoch: 6| Step: 10
Training loss: 1.9816372225247376
Validation loss: 2.532603839780159

Epoch: 6| Step: 11
Training loss: 1.8544470614326
Validation loss: 2.490392807600144

Epoch: 6| Step: 12
Training loss: 2.227901872374474
Validation loss: 2.48324740367788

Epoch: 6| Step: 13
Training loss: 2.3652862870735363
Validation loss: 2.5077377470223214

Epoch: 366| Step: 0
Training loss: 2.2640767035818703
Validation loss: 2.513627114670996

Epoch: 6| Step: 1
Training loss: 2.1837534837525765
Validation loss: 2.5336674006974453

Epoch: 6| Step: 2
Training loss: 2.1112579983367197
Validation loss: 2.4989303720736147

Epoch: 6| Step: 3
Training loss: 1.7410155318792744
Validation loss: 2.478294527998355

Epoch: 6| Step: 4
Training loss: 2.1311540688322133
Validation loss: 2.525320876388504

Epoch: 6| Step: 5
Training loss: 2.4514777611990617
Validation loss: 2.4924192909390546

Epoch: 6| Step: 6
Training loss: 2.395774630504647
Validation loss: 2.4927314203065314

Epoch: 6| Step: 7
Training loss: 2.650071801706365
Validation loss: 2.4975655690400513

Epoch: 6| Step: 8
Training loss: 2.370862871018446
Validation loss: 2.486018469934384

Epoch: 6| Step: 9
Training loss: 2.1351010965537167
Validation loss: 2.5069300715780845

Epoch: 6| Step: 10
Training loss: 1.7154826231976714
Validation loss: 2.5070592048975233

Epoch: 6| Step: 11
Training loss: 1.4546932658768568
Validation loss: 2.535861445372655

Epoch: 6| Step: 12
Training loss: 1.707616849618054
Validation loss: 2.5254280206779507

Epoch: 6| Step: 13
Training loss: 1.43476042711504
Validation loss: 2.496502079150798

Epoch: 367| Step: 0
Training loss: 2.2239163921132707
Validation loss: 2.4953791614046943

Epoch: 6| Step: 1
Training loss: 2.2959660398849393
Validation loss: 2.4937861903142835

Epoch: 6| Step: 2
Training loss: 3.063105931965046
Validation loss: 2.5080379752353434

Epoch: 6| Step: 3
Training loss: 1.7392860508831993
Validation loss: 2.5456590183713685

Epoch: 6| Step: 4
Training loss: 2.375750774374989
Validation loss: 2.5474565784252174

Epoch: 6| Step: 5
Training loss: 2.089254991540701
Validation loss: 2.515737475132523

Epoch: 6| Step: 6
Training loss: 1.717070573985992
Validation loss: 2.4783819415922146

Epoch: 6| Step: 7
Training loss: 2.046332716997303
Validation loss: 2.5225551135173157

Epoch: 6| Step: 8
Training loss: 2.0115604079068077
Validation loss: 2.5139805886513855

Epoch: 6| Step: 9
Training loss: 1.884114745025171
Validation loss: 2.47734052168698

Epoch: 6| Step: 10
Training loss: 2.1235665367055088
Validation loss: 2.503479979191785

Epoch: 6| Step: 11
Training loss: 1.8045935668279347
Validation loss: 2.5265188703699826

Epoch: 6| Step: 12
Training loss: 1.480522939852773
Validation loss: 2.5252687618824967

Epoch: 6| Step: 13
Training loss: 2.2147877734879695
Validation loss: 2.5136589928779682

Epoch: 368| Step: 0
Training loss: 2.7994974298398945
Validation loss: 2.540126530259851

Epoch: 6| Step: 1
Training loss: 1.4198416958803801
Validation loss: 2.465252555854104

Epoch: 6| Step: 2
Training loss: 1.9985315773468444
Validation loss: 2.4865234252927935

Epoch: 6| Step: 3
Training loss: 1.5931256885310077
Validation loss: 2.5203450936181193

Epoch: 6| Step: 4
Training loss: 1.9452205774121345
Validation loss: 2.5168068744541077

Epoch: 6| Step: 5
Training loss: 2.19166212577011
Validation loss: 2.4932917413153817

Epoch: 6| Step: 6
Training loss: 2.744385276015904
Validation loss: 2.532598909081763

Epoch: 6| Step: 7
Training loss: 2.4247687003345435
Validation loss: 2.498047005847894

Epoch: 6| Step: 8
Training loss: 1.9971474331839016
Validation loss: 2.520710053188416

Epoch: 6| Step: 9
Training loss: 1.615720516605753
Validation loss: 2.5011864482274193

Epoch: 6| Step: 10
Training loss: 2.052105343566692
Validation loss: 2.5254159121646382

Epoch: 6| Step: 11
Training loss: 2.129241524989761
Validation loss: 2.4932249794324304

Epoch: 6| Step: 12
Training loss: 1.7206247682082814
Validation loss: 2.501747585985349

Epoch: 6| Step: 13
Training loss: 2.516992043520113
Validation loss: 2.521173965869678

Epoch: 369| Step: 0
Training loss: 2.0917235859374537
Validation loss: 2.4816048547723035

Epoch: 6| Step: 1
Training loss: 2.4875262925181794
Validation loss: 2.4944715294260216

Epoch: 6| Step: 2
Training loss: 2.369423191362325
Validation loss: 2.4862007350979103

Epoch: 6| Step: 3
Training loss: 1.7363808519834483
Validation loss: 2.549847747533026

Epoch: 6| Step: 4
Training loss: 2.145547928085655
Validation loss: 2.5442423392186377

Epoch: 6| Step: 5
Training loss: 1.4964324328778842
Validation loss: 2.5113508953811454

Epoch: 6| Step: 6
Training loss: 2.304855702614697
Validation loss: 2.4855735876428082

Epoch: 6| Step: 7
Training loss: 2.230921604128184
Validation loss: 2.5525343864064096

Epoch: 6| Step: 8
Training loss: 1.6575387223497577
Validation loss: 2.5110548703645503

Epoch: 6| Step: 9
Training loss: 2.4735040401489745
Validation loss: 2.525012444581537

Epoch: 6| Step: 10
Training loss: 2.3471955467779955
Validation loss: 2.5289187617290234

Epoch: 6| Step: 11
Training loss: 1.728763954729646
Validation loss: 2.540193813509206

Epoch: 6| Step: 12
Training loss: 2.444677300873822
Validation loss: 2.5064062321519343

Epoch: 6| Step: 13
Training loss: 1.7010017949430671
Validation loss: 2.5378813378602336

Epoch: 370| Step: 0
Training loss: 2.470810332252868
Validation loss: 2.495234510743679

Epoch: 6| Step: 1
Training loss: 1.8113094234262068
Validation loss: 2.5128139620893633

Epoch: 6| Step: 2
Training loss: 1.638535540505234
Validation loss: 2.5191994155601507

Epoch: 6| Step: 3
Training loss: 2.012872753807965
Validation loss: 2.4945089816436967

Epoch: 6| Step: 4
Training loss: 2.3573662499262826
Validation loss: 2.479896153370702

Epoch: 6| Step: 5
Training loss: 1.999625170869433
Validation loss: 2.5126169276172097

Epoch: 6| Step: 6
Training loss: 1.682530184470779
Validation loss: 2.514574693155432

Epoch: 6| Step: 7
Training loss: 2.6109372333592678
Validation loss: 2.4849766313456794

Epoch: 6| Step: 8
Training loss: 1.5318796070143217
Validation loss: 2.5285417330391087

Epoch: 6| Step: 9
Training loss: 2.7585035112174365
Validation loss: 2.4927277127545313

Epoch: 6| Step: 10
Training loss: 2.5337469712753524
Validation loss: 2.501868449090574

Epoch: 6| Step: 11
Training loss: 1.9884033165654833
Validation loss: 2.4877448460438027

Epoch: 6| Step: 12
Training loss: 1.9621626837397905
Validation loss: 2.509669211043877

Epoch: 6| Step: 13
Training loss: 1.0012806797923057
Validation loss: 2.4900066657516002

Epoch: 371| Step: 0
Training loss: 2.2289215975185224
Validation loss: 2.517625357215205

Epoch: 6| Step: 1
Training loss: 1.8582035509758157
Validation loss: 2.4712834638503534

Epoch: 6| Step: 2
Training loss: 1.7533214248257654
Validation loss: 2.5226733191846527

Epoch: 6| Step: 3
Training loss: 2.333172134099074
Validation loss: 2.4878289443693733

Epoch: 6| Step: 4
Training loss: 2.122857977667646
Validation loss: 2.5280280263929713

Epoch: 6| Step: 5
Training loss: 2.6586213241882466
Validation loss: 2.50843681717088

Epoch: 6| Step: 6
Training loss: 2.2423855896749743
Validation loss: 2.4825456425965675

Epoch: 6| Step: 7
Training loss: 2.324763591601507
Validation loss: 2.4842041322160764

Epoch: 6| Step: 8
Training loss: 1.5598542510929378
Validation loss: 2.5434447843002177

Epoch: 6| Step: 9
Training loss: 2.0055576829320745
Validation loss: 2.5032943493165063

Epoch: 6| Step: 10
Training loss: 1.7201782534516796
Validation loss: 2.506986280362308

Epoch: 6| Step: 11
Training loss: 2.5672519631630437
Validation loss: 2.494779368697017

Epoch: 6| Step: 12
Training loss: 1.961400133249662
Validation loss: 2.518615231554479

Epoch: 6| Step: 13
Training loss: 1.3780839753910772
Validation loss: 2.489733630992384

Epoch: 372| Step: 0
Training loss: 1.563883359788991
Validation loss: 2.4731110278670188

Epoch: 6| Step: 1
Training loss: 1.8987176633470815
Validation loss: 2.4813472464348836

Epoch: 6| Step: 2
Training loss: 2.529387742696891
Validation loss: 2.474369736527567

Epoch: 6| Step: 3
Training loss: 1.9558311940352002
Validation loss: 2.518471323039826

Epoch: 6| Step: 4
Training loss: 1.6232500190164978
Validation loss: 2.4903895000966827

Epoch: 6| Step: 5
Training loss: 1.9559844790507919
Validation loss: 2.517992130258414

Epoch: 6| Step: 6
Training loss: 2.1968447947697918
Validation loss: 2.5389284372078653

Epoch: 6| Step: 7
Training loss: 2.229911774741845
Validation loss: 2.45165383147438

Epoch: 6| Step: 8
Training loss: 1.6891776328851424
Validation loss: 2.4843155656504097

Epoch: 6| Step: 9
Training loss: 2.032058085580082
Validation loss: 2.4897302958413956

Epoch: 6| Step: 10
Training loss: 2.173908077939209
Validation loss: 2.5221176828286778

Epoch: 6| Step: 11
Training loss: 2.1054997769194634
Validation loss: 2.49056914068964

Epoch: 6| Step: 12
Training loss: 2.857112301935572
Validation loss: 2.5288916321431576

Epoch: 6| Step: 13
Training loss: 1.6811198669895284
Validation loss: 2.503238585058856

Epoch: 373| Step: 0
Training loss: 1.913952633565605
Validation loss: 2.5044806536034017

Epoch: 6| Step: 1
Training loss: 2.4761509117085194
Validation loss: 2.511390225278519

Epoch: 6| Step: 2
Training loss: 2.0512340227489316
Validation loss: 2.485467129095614

Epoch: 6| Step: 3
Training loss: 2.201575200820577
Validation loss: 2.501238706792971

Epoch: 6| Step: 4
Training loss: 2.2513772140389534
Validation loss: 2.5057743778615413

Epoch: 6| Step: 5
Training loss: 1.6347103496946123
Validation loss: 2.5206064674548023

Epoch: 6| Step: 6
Training loss: 2.7121479069597356
Validation loss: 2.518834605040704

Epoch: 6| Step: 7
Training loss: 2.440720118428716
Validation loss: 2.497362731086664

Epoch: 6| Step: 8
Training loss: 2.2399474328548705
Validation loss: 2.4956320536350223

Epoch: 6| Step: 9
Training loss: 2.1325048427370277
Validation loss: 2.492427931984212

Epoch: 6| Step: 10
Training loss: 1.8147431009458115
Validation loss: 2.4745246782129415

Epoch: 6| Step: 11
Training loss: 1.2781508576032292
Validation loss: 2.5209232657680984

Epoch: 6| Step: 12
Training loss: 1.726062132538131
Validation loss: 2.5267136108343173

Epoch: 6| Step: 13
Training loss: 2.1662991529942652
Validation loss: 2.5277342926871276

Epoch: 374| Step: 0
Training loss: 1.8808420087382982
Validation loss: 2.5139710773920116

Epoch: 6| Step: 1
Training loss: 1.804111867811012
Validation loss: 2.5148476273595612

Epoch: 6| Step: 2
Training loss: 2.414060919801263
Validation loss: 2.514723855661901

Epoch: 6| Step: 3
Training loss: 2.1298040054482796
Validation loss: 2.517176141804481

Epoch: 6| Step: 4
Training loss: 1.8262101276491622
Validation loss: 2.5147289518980234

Epoch: 6| Step: 5
Training loss: 2.2815661276639703
Validation loss: 2.463802124510263

Epoch: 6| Step: 6
Training loss: 2.178515594356565
Validation loss: 2.5203709816930826

Epoch: 6| Step: 7
Training loss: 2.547129425259148
Validation loss: 2.504976938100709

Epoch: 6| Step: 8
Training loss: 2.302192501281716
Validation loss: 2.5068894793109107

Epoch: 6| Step: 9
Training loss: 2.255259195389992
Validation loss: 2.5045438921509526

Epoch: 6| Step: 10
Training loss: 1.6421722382363488
Validation loss: 2.5290570611215673

Epoch: 6| Step: 11
Training loss: 1.340528441110705
Validation loss: 2.5041371210399475

Epoch: 6| Step: 12
Training loss: 2.0421409315594716
Validation loss: 2.515164265280601

Epoch: 6| Step: 13
Training loss: 2.062513293599145
Validation loss: 2.500733125003715

Epoch: 375| Step: 0
Training loss: 2.248659158242692
Validation loss: 2.5085002314087195

Epoch: 6| Step: 1
Training loss: 1.560636248076346
Validation loss: 2.5064121860688306

Epoch: 6| Step: 2
Training loss: 1.4593783131465838
Validation loss: 2.5100988929778105

Epoch: 6| Step: 3
Training loss: 1.9236504022446885
Validation loss: 2.4803477671119802

Epoch: 6| Step: 4
Training loss: 2.345616525644372
Validation loss: 2.5006085306358643

Epoch: 6| Step: 5
Training loss: 2.611715763054959
Validation loss: 2.51319896779261

Epoch: 6| Step: 6
Training loss: 2.014096412343593
Validation loss: 2.516623560028239

Epoch: 6| Step: 7
Training loss: 1.8950255702767083
Validation loss: 2.489695860326433

Epoch: 6| Step: 8
Training loss: 2.4876541473320364
Validation loss: 2.4870687410089265

Epoch: 6| Step: 9
Training loss: 1.6527886840004564
Validation loss: 2.503877471276719

Epoch: 6| Step: 10
Training loss: 2.2017177118260096
Validation loss: 2.495349147043448

Epoch: 6| Step: 11
Training loss: 2.7100556008241057
Validation loss: 2.520408462019763

Epoch: 6| Step: 12
Training loss: 1.7518775949176537
Validation loss: 2.5116754945750017

Epoch: 6| Step: 13
Training loss: 1.942563914913056
Validation loss: 2.5042201498396977

Epoch: 376| Step: 0
Training loss: 1.571337313293501
Validation loss: 2.522359733870952

Epoch: 6| Step: 1
Training loss: 2.299974802127968
Validation loss: 2.5292354514041873

Epoch: 6| Step: 2
Training loss: 2.0662313289918015
Validation loss: 2.489682453077257

Epoch: 6| Step: 3
Training loss: 2.2550731263071437
Validation loss: 2.501692777170039

Epoch: 6| Step: 4
Training loss: 2.729513151194092
Validation loss: 2.5202566311101395

Epoch: 6| Step: 5
Training loss: 1.8293864144978214
Validation loss: 2.4969995079326694

Epoch: 6| Step: 6
Training loss: 2.2791379793117956
Validation loss: 2.5051578495066793

Epoch: 6| Step: 7
Training loss: 1.534110686306355
Validation loss: 2.5106574240808195

Epoch: 6| Step: 8
Training loss: 1.8758518826914665
Validation loss: 2.4592788244890027

Epoch: 6| Step: 9
Training loss: 1.718691113937098
Validation loss: 2.4827092626260034

Epoch: 6| Step: 10
Training loss: 1.808936265846493
Validation loss: 2.4514000458662784

Epoch: 6| Step: 11
Training loss: 2.0159702448919714
Validation loss: 2.501627277600527

Epoch: 6| Step: 12
Training loss: 2.53227759330811
Validation loss: 2.5358550874715964

Epoch: 6| Step: 13
Training loss: 2.386013494953833
Validation loss: 2.5308630265294894

Epoch: 377| Step: 0
Training loss: 2.330711412983768
Validation loss: 2.501211705406316

Epoch: 6| Step: 1
Training loss: 2.3355707499446097
Validation loss: 2.5331529821755003

Epoch: 6| Step: 2
Training loss: 2.0881324677960365
Validation loss: 2.5183993193813703

Epoch: 6| Step: 3
Training loss: 2.113112465822132
Validation loss: 2.534202681641878

Epoch: 6| Step: 4
Training loss: 1.897387932645684
Validation loss: 2.532543843734113

Epoch: 6| Step: 5
Training loss: 1.6585585142571375
Validation loss: 2.5091158291639246

Epoch: 6| Step: 6
Training loss: 1.748788959540918
Validation loss: 2.5204096907400992

Epoch: 6| Step: 7
Training loss: 1.1618604890390198
Validation loss: 2.529546816147628

Epoch: 6| Step: 8
Training loss: 2.162513922497688
Validation loss: 2.492448402532528

Epoch: 6| Step: 9
Training loss: 2.043311591766504
Validation loss: 2.5236865799841235

Epoch: 6| Step: 10
Training loss: 2.5040898248325836
Validation loss: 2.4843898666204285

Epoch: 6| Step: 11
Training loss: 2.304888596893958
Validation loss: 2.5084494333077605

Epoch: 6| Step: 12
Training loss: 2.2163864226289745
Validation loss: 2.4842368358565468

Epoch: 6| Step: 13
Training loss: 2.389727654681555
Validation loss: 2.5121739896323474

Epoch: 378| Step: 0
Training loss: 2.051676469413256
Validation loss: 2.508267499090895

Epoch: 6| Step: 1
Training loss: 2.127656286216792
Validation loss: 2.5206212159863863

Epoch: 6| Step: 2
Training loss: 1.8616538308206836
Validation loss: 2.4732177285583035

Epoch: 6| Step: 3
Training loss: 2.121562533623727
Validation loss: 2.4798115492776596

Epoch: 6| Step: 4
Training loss: 2.1998433230703336
Validation loss: 2.5090756043261453

Epoch: 6| Step: 5
Training loss: 1.8511194270396094
Validation loss: 2.495806623708287

Epoch: 6| Step: 6
Training loss: 1.908067618393461
Validation loss: 2.522253546291314

Epoch: 6| Step: 7
Training loss: 1.869872903431619
Validation loss: 2.4909480857608495

Epoch: 6| Step: 8
Training loss: 1.475370541598235
Validation loss: 2.5222109909297545

Epoch: 6| Step: 9
Training loss: 2.082437271693808
Validation loss: 2.5348823399769955

Epoch: 6| Step: 10
Training loss: 2.3018089809888522
Validation loss: 2.517171270001256

Epoch: 6| Step: 11
Training loss: 2.170178635974983
Validation loss: 2.522656769667767

Epoch: 6| Step: 12
Training loss: 2.5680977691744085
Validation loss: 2.5388478380053505

Epoch: 6| Step: 13
Training loss: 2.636778428144082
Validation loss: 2.4971959919507243

Epoch: 379| Step: 0
Training loss: 2.8341765177584612
Validation loss: 2.503976713882934

Epoch: 6| Step: 1
Training loss: 2.1922168558429598
Validation loss: 2.519871535282998

Epoch: 6| Step: 2
Training loss: 1.945003316430253
Validation loss: 2.5413510392037537

Epoch: 6| Step: 3
Training loss: 1.7627851215002126
Validation loss: 2.4991672400456615

Epoch: 6| Step: 4
Training loss: 2.364562237571238
Validation loss: 2.513559742945044

Epoch: 6| Step: 5
Training loss: 1.8189431471367843
Validation loss: 2.512266565477264

Epoch: 6| Step: 6
Training loss: 2.6045767702800995
Validation loss: 2.5301636502069713

Epoch: 6| Step: 7
Training loss: 1.7780568463449724
Validation loss: 2.5292643622372566

Epoch: 6| Step: 8
Training loss: 1.705988165918339
Validation loss: 2.498366934109735

Epoch: 6| Step: 9
Training loss: 1.7449973673103825
Validation loss: 2.515069933813372

Epoch: 6| Step: 10
Training loss: 2.013452349591295
Validation loss: 2.5467581078868493

Epoch: 6| Step: 11
Training loss: 2.0119629943129222
Validation loss: 2.5027139022933906

Epoch: 6| Step: 12
Training loss: 1.9501207363213358
Validation loss: 2.5151165781112894

Epoch: 6| Step: 13
Training loss: 2.731302071430696
Validation loss: 2.498982068449028

Epoch: 380| Step: 0
Training loss: 1.7986983626259114
Validation loss: 2.4805579400299616

Epoch: 6| Step: 1
Training loss: 1.6187440319761335
Validation loss: 2.4791408956968075

Epoch: 6| Step: 2
Training loss: 1.8004379772763406
Validation loss: 2.511790299098621

Epoch: 6| Step: 3
Training loss: 2.243366317034194
Validation loss: 2.487582484231077

Epoch: 6| Step: 4
Training loss: 1.9133971634406868
Validation loss: 2.5152809510587426

Epoch: 6| Step: 5
Training loss: 1.8727419926282876
Validation loss: 2.475441477590237

Epoch: 6| Step: 6
Training loss: 2.2856754593446635
Validation loss: 2.5037179127085207

Epoch: 6| Step: 7
Training loss: 2.2887925128748976
Validation loss: 2.511155903275285

Epoch: 6| Step: 8
Training loss: 2.937530679745456
Validation loss: 2.505520754554281

Epoch: 6| Step: 9
Training loss: 1.7978029591602107
Validation loss: 2.5135869166410103

Epoch: 6| Step: 10
Training loss: 2.0919216770586795
Validation loss: 2.506005764251468

Epoch: 6| Step: 11
Training loss: 2.510155839679588
Validation loss: 2.5158992723038596

Epoch: 6| Step: 12
Training loss: 1.8091112883514786
Validation loss: 2.51962332812046

Epoch: 6| Step: 13
Training loss: 1.9689080311155864
Validation loss: 2.493677326156773

Epoch: 381| Step: 0
Training loss: 1.9123855406973538
Validation loss: 2.4980518318213103

Epoch: 6| Step: 1
Training loss: 1.361736613959107
Validation loss: 2.4905243043258842

Epoch: 6| Step: 2
Training loss: 2.2123348282190194
Validation loss: 2.486446148556462

Epoch: 6| Step: 3
Training loss: 1.695375221603999
Validation loss: 2.4740413711851925

Epoch: 6| Step: 4
Training loss: 1.9931814668634722
Validation loss: 2.4959328813812265

Epoch: 6| Step: 5
Training loss: 2.4668455866627528
Validation loss: 2.4767607688502054

Epoch: 6| Step: 6
Training loss: 2.765009752363283
Validation loss: 2.5090028293360063

Epoch: 6| Step: 7
Training loss: 1.8256320747152215
Validation loss: 2.4940669249402627

Epoch: 6| Step: 8
Training loss: 1.4455389721742071
Validation loss: 2.508193069372104

Epoch: 6| Step: 9
Training loss: 2.0620270389075386
Validation loss: 2.512009375620873

Epoch: 6| Step: 10
Training loss: 1.887285672581239
Validation loss: 2.472907346183042

Epoch: 6| Step: 11
Training loss: 2.667838991285428
Validation loss: 2.4813213495074113

Epoch: 6| Step: 12
Training loss: 2.300592022871653
Validation loss: 2.47975884432426

Epoch: 6| Step: 13
Training loss: 2.0865033128841453
Validation loss: 2.536362037836214

Epoch: 382| Step: 0
Training loss: 2.1187672932236974
Validation loss: 2.4893145995196284

Epoch: 6| Step: 1
Training loss: 2.8936876722836833
Validation loss: 2.5023587594739776

Epoch: 6| Step: 2
Training loss: 1.4399009225457309
Validation loss: 2.50241597963987

Epoch: 6| Step: 3
Training loss: 1.6925906644172237
Validation loss: 2.465896273815341

Epoch: 6| Step: 4
Training loss: 1.7653993445488878
Validation loss: 2.5390802758590887

Epoch: 6| Step: 5
Training loss: 1.6935471867265564
Validation loss: 2.5226307231403564

Epoch: 6| Step: 6
Training loss: 2.199582870993036
Validation loss: 2.54129078057639

Epoch: 6| Step: 7
Training loss: 2.024034566682107
Validation loss: 2.4913750982231138

Epoch: 6| Step: 8
Training loss: 1.9788116805969298
Validation loss: 2.5329322547100217

Epoch: 6| Step: 9
Training loss: 2.4914741092984865
Validation loss: 2.506586093322175

Epoch: 6| Step: 10
Training loss: 2.0174694050450848
Validation loss: 2.5249005694383735

Epoch: 6| Step: 11
Training loss: 2.399165934431948
Validation loss: 2.4760581192892666

Epoch: 6| Step: 12
Training loss: 1.7794515666024493
Validation loss: 2.522427059088031

Epoch: 6| Step: 13
Training loss: 2.5249442217114235
Validation loss: 2.492278511020384

Epoch: 383| Step: 0
Training loss: 1.8493482008549313
Validation loss: 2.521580449031941

Epoch: 6| Step: 1
Training loss: 1.913887109311179
Validation loss: 2.4836440752160867

Epoch: 6| Step: 2
Training loss: 1.7603980144287574
Validation loss: 2.5054738758460804

Epoch: 6| Step: 3
Training loss: 2.135188194396054
Validation loss: 2.5577143800180533

Epoch: 6| Step: 4
Training loss: 2.1070882199018093
Validation loss: 2.4956034270659635

Epoch: 6| Step: 5
Training loss: 1.7623314986609318
Validation loss: 2.535216707019763

Epoch: 6| Step: 6
Training loss: 1.904339943423229
Validation loss: 2.5414777235316657

Epoch: 6| Step: 7
Training loss: 2.47150084392233
Validation loss: 2.505892650778563

Epoch: 6| Step: 8
Training loss: 1.7272911778062336
Validation loss: 2.518937364967888

Epoch: 6| Step: 9
Training loss: 2.1267934972239275
Validation loss: 2.5487902820672548

Epoch: 6| Step: 10
Training loss: 2.7568774488771606
Validation loss: 2.5147710171149216

Epoch: 6| Step: 11
Training loss: 2.986429675554281
Validation loss: 2.516221613839827

Epoch: 6| Step: 12
Training loss: 1.474020975711597
Validation loss: 2.5342212932894617

Epoch: 6| Step: 13
Training loss: 1.2917218145267453
Validation loss: 2.519711865260412

Epoch: 384| Step: 0
Training loss: 2.266291342777424
Validation loss: 2.4894752851420003

Epoch: 6| Step: 1
Training loss: 1.6745865838306497
Validation loss: 2.476985374736878

Epoch: 6| Step: 2
Training loss: 2.2943027131849414
Validation loss: 2.5102288334979623

Epoch: 6| Step: 3
Training loss: 2.638033164856317
Validation loss: 2.4842503756909173

Epoch: 6| Step: 4
Training loss: 1.9489359373365245
Validation loss: 2.4676335547771244

Epoch: 6| Step: 5
Training loss: 1.958754825549581
Validation loss: 2.4705307097779734

Epoch: 6| Step: 6
Training loss: 2.484334405531405
Validation loss: 2.4513227997341906

Epoch: 6| Step: 7
Training loss: 2.126736548460485
Validation loss: 2.4792209718222846

Epoch: 6| Step: 8
Training loss: 2.190659121956412
Validation loss: 2.504800307176764

Epoch: 6| Step: 9
Training loss: 1.6725311417809388
Validation loss: 2.5180176291683773

Epoch: 6| Step: 10
Training loss: 1.9820304897669265
Validation loss: 2.514031236240881

Epoch: 6| Step: 11
Training loss: 1.3817142500389439
Validation loss: 2.5031155830523555

Epoch: 6| Step: 12
Training loss: 2.010428538970942
Validation loss: 2.485316577892966

Epoch: 6| Step: 13
Training loss: 2.0296986451110963
Validation loss: 2.4894515524526026

Epoch: 385| Step: 0
Training loss: 1.616677392681498
Validation loss: 2.504353101978822

Epoch: 6| Step: 1
Training loss: 2.5652275455965414
Validation loss: 2.4620811970358534

Epoch: 6| Step: 2
Training loss: 1.813351201093288
Validation loss: 2.5237571224094735

Epoch: 6| Step: 3
Training loss: 1.9392891898120306
Validation loss: 2.5223406281508067

Epoch: 6| Step: 4
Training loss: 2.1052415827850273
Validation loss: 2.5448267053396783

Epoch: 6| Step: 5
Training loss: 2.6842139803073892
Validation loss: 2.5190240358185725

Epoch: 6| Step: 6
Training loss: 1.9025150668416075
Validation loss: 2.5255378808564535

Epoch: 6| Step: 7
Training loss: 2.4928561183694677
Validation loss: 2.513801602274581

Epoch: 6| Step: 8
Training loss: 1.5582338457768108
Validation loss: 2.5314769250695988

Epoch: 6| Step: 9
Training loss: 1.4998173602493154
Validation loss: 2.5025895438098336

Epoch: 6| Step: 10
Training loss: 2.1310642329273093
Validation loss: 2.5034477747516624

Epoch: 6| Step: 11
Training loss: 1.8881637063173966
Validation loss: 2.5176530867886786

Epoch: 6| Step: 12
Training loss: 2.07231256573838
Validation loss: 2.4947403780840642

Epoch: 6| Step: 13
Training loss: 2.825086953504412
Validation loss: 2.524118699602139

Epoch: 386| Step: 0
Training loss: 2.020418131014791
Validation loss: 2.4912944434049153

Epoch: 6| Step: 1
Training loss: 2.165810880624133
Validation loss: 2.5257830672765706

Epoch: 6| Step: 2
Training loss: 2.0537675894171503
Validation loss: 2.5071944574528713

Epoch: 6| Step: 3
Training loss: 2.1296185063180664
Validation loss: 2.474916388726734

Epoch: 6| Step: 4
Training loss: 2.76329545871316
Validation loss: 2.5003424830318024

Epoch: 6| Step: 5
Training loss: 2.7061024403153087
Validation loss: 2.4858402681289213

Epoch: 6| Step: 6
Training loss: 1.931811318410829
Validation loss: 2.514680500027223

Epoch: 6| Step: 7
Training loss: 1.8114980361679345
Validation loss: 2.463688159728694

Epoch: 6| Step: 8
Training loss: 2.0852605171189933
Validation loss: 2.495243729718821

Epoch: 6| Step: 9
Training loss: 2.0884693795978486
Validation loss: 2.524268213701266

Epoch: 6| Step: 10
Training loss: 1.8008883562321538
Validation loss: 2.49976761363392

Epoch: 6| Step: 11
Training loss: 1.2855645084939409
Validation loss: 2.5239241901000735

Epoch: 6| Step: 12
Training loss: 1.7422827450842642
Validation loss: 2.489539509323737

Epoch: 6| Step: 13
Training loss: 1.76073507856562
Validation loss: 2.5468997990603546

Epoch: 387| Step: 0
Training loss: 2.41805177216365
Validation loss: 2.502281841658305

Epoch: 6| Step: 1
Training loss: 1.4997483678199368
Validation loss: 2.4950741282082993

Epoch: 6| Step: 2
Training loss: 2.3754758859999066
Validation loss: 2.527220388437489

Epoch: 6| Step: 3
Training loss: 2.7424580584564238
Validation loss: 2.4906614418908215

Epoch: 6| Step: 4
Training loss: 1.8144411675887617
Validation loss: 2.457794913314079

Epoch: 6| Step: 5
Training loss: 1.9345078898742485
Validation loss: 2.5253430324685286

Epoch: 6| Step: 6
Training loss: 1.663542402056693
Validation loss: 2.4578953422849596

Epoch: 6| Step: 7
Training loss: 1.5092344546387098
Validation loss: 2.509357489528856

Epoch: 6| Step: 8
Training loss: 1.7007107202697722
Validation loss: 2.5291877994511656

Epoch: 6| Step: 9
Training loss: 2.363823543152928
Validation loss: 2.5210352899544484

Epoch: 6| Step: 10
Training loss: 2.330900649825185
Validation loss: 2.501712625713769

Epoch: 6| Step: 11
Training loss: 2.0118890486549947
Validation loss: 2.5080294217040047

Epoch: 6| Step: 12
Training loss: 2.0255848452111125
Validation loss: 2.5064653339441456

Epoch: 6| Step: 13
Training loss: 2.0632753937597337
Validation loss: 2.494888124654924

Epoch: 388| Step: 0
Training loss: 2.0205946581444714
Validation loss: 2.5252609712627887

Epoch: 6| Step: 1
Training loss: 1.7455357421607398
Validation loss: 2.494467709354545

Epoch: 6| Step: 2
Training loss: 2.0188193625234914
Validation loss: 2.4985078624594643

Epoch: 6| Step: 3
Training loss: 1.935903937762382
Validation loss: 2.5413864952313157

Epoch: 6| Step: 4
Training loss: 1.9175234897373377
Validation loss: 2.5080396188838177

Epoch: 6| Step: 5
Training loss: 1.2492310543062688
Validation loss: 2.505878784389952

Epoch: 6| Step: 6
Training loss: 1.3596505072262273
Validation loss: 2.4785913441150127

Epoch: 6| Step: 7
Training loss: 1.9678359558927159
Validation loss: 2.5403462107910832

Epoch: 6| Step: 8
Training loss: 2.243809023960069
Validation loss: 2.517740617452318

Epoch: 6| Step: 9
Training loss: 1.9000287706304957
Validation loss: 2.547475492760118

Epoch: 6| Step: 10
Training loss: 2.482314400856283
Validation loss: 2.4790373620506

Epoch: 6| Step: 11
Training loss: 2.3194476741176917
Validation loss: 2.5054025725450693

Epoch: 6| Step: 12
Training loss: 2.613398573541168
Validation loss: 2.484389063802496

Epoch: 6| Step: 13
Training loss: 2.7602741612531867
Validation loss: 2.514307038496499

Epoch: 389| Step: 0
Training loss: 1.4310233124034317
Validation loss: 2.4883451845891713

Epoch: 6| Step: 1
Training loss: 2.0714403067571143
Validation loss: 2.5341102561660107

Epoch: 6| Step: 2
Training loss: 2.3811025018141296
Validation loss: 2.46741214243244

Epoch: 6| Step: 3
Training loss: 2.1173967208806648
Validation loss: 2.5191240665121195

Epoch: 6| Step: 4
Training loss: 1.8555955702958846
Validation loss: 2.5148745088459443

Epoch: 6| Step: 5
Training loss: 2.236501255580005
Validation loss: 2.489390993216263

Epoch: 6| Step: 6
Training loss: 2.142732459936831
Validation loss: 2.5234272888478864

Epoch: 6| Step: 7
Training loss: 2.5507803153113717
Validation loss: 2.504087363660841

Epoch: 6| Step: 8
Training loss: 1.637818542830338
Validation loss: 2.5011584684446437

Epoch: 6| Step: 9
Training loss: 1.4478882802838164
Validation loss: 2.521473062960959

Epoch: 6| Step: 10
Training loss: 2.4606011054807255
Validation loss: 2.497788326700138

Epoch: 6| Step: 11
Training loss: 2.7416576080018014
Validation loss: 2.5173782774260136

Epoch: 6| Step: 12
Training loss: 1.0669051460069785
Validation loss: 2.545372572208065

Epoch: 6| Step: 13
Training loss: 2.2373494443908215
Validation loss: 2.560550198007999

Epoch: 390| Step: 0
Training loss: 1.8733636709496726
Validation loss: 2.547939438207034

Epoch: 6| Step: 1
Training loss: 2.2714216071105193
Validation loss: 2.5148418952557288

Epoch: 6| Step: 2
Training loss: 1.5342879229852153
Validation loss: 2.4894808192356885

Epoch: 6| Step: 3
Training loss: 1.8234201517072526
Validation loss: 2.4963341282236695

Epoch: 6| Step: 4
Training loss: 1.9246861437287828
Validation loss: 2.5090267551451753

Epoch: 6| Step: 5
Training loss: 2.346464898943229
Validation loss: 2.497484910894687

Epoch: 6| Step: 6
Training loss: 2.4662420354096795
Validation loss: 2.5164645406874637

Epoch: 6| Step: 7
Training loss: 1.806808150488792
Validation loss: 2.492284456513688

Epoch: 6| Step: 8
Training loss: 2.7045206865847855
Validation loss: 2.494323242228371

Epoch: 6| Step: 9
Training loss: 1.6290160217621295
Validation loss: 2.484404174381603

Epoch: 6| Step: 10
Training loss: 1.961408277437768
Validation loss: 2.4735364276771303

Epoch: 6| Step: 11
Training loss: 2.3630017832564874
Validation loss: 2.468234966818728

Epoch: 6| Step: 12
Training loss: 1.712836687724223
Validation loss: 2.4444877604204436

Epoch: 6| Step: 13
Training loss: 2.168804935342203
Validation loss: 2.514897764107075

Epoch: 391| Step: 0
Training loss: 1.8911365416002701
Validation loss: 2.490090514726056

Epoch: 6| Step: 1
Training loss: 1.5723346197497603
Validation loss: 2.4886982479301807

Epoch: 6| Step: 2
Training loss: 1.9727034459275274
Validation loss: 2.5085960015036433

Epoch: 6| Step: 3
Training loss: 1.9320403669969761
Validation loss: 2.4823169445484305

Epoch: 6| Step: 4
Training loss: 2.981102232399877
Validation loss: 2.487957459585591

Epoch: 6| Step: 5
Training loss: 2.316093951268185
Validation loss: 2.511883560642619

Epoch: 6| Step: 6
Training loss: 2.070222903058308
Validation loss: 2.5031624460127735

Epoch: 6| Step: 7
Training loss: 1.6095711301531415
Validation loss: 2.5128284895696527

Epoch: 6| Step: 8
Training loss: 2.0084460257204877
Validation loss: 2.509634122088305

Epoch: 6| Step: 9
Training loss: 2.1434419015743824
Validation loss: 2.5025017434086108

Epoch: 6| Step: 10
Training loss: 2.2678940558674507
Validation loss: 2.526610231662425

Epoch: 6| Step: 11
Training loss: 1.9001804090478676
Validation loss: 2.4771795943205794

Epoch: 6| Step: 12
Training loss: 2.1154130206835244
Validation loss: 2.4992041069521167

Epoch: 6| Step: 13
Training loss: 1.370984238818479
Validation loss: 2.5159699668371225

Epoch: 392| Step: 0
Training loss: 1.9324584093837058
Validation loss: 2.510729877463779

Epoch: 6| Step: 1
Training loss: 2.0950354430630593
Validation loss: 2.437345464628413

Epoch: 6| Step: 2
Training loss: 1.5070867026940606
Validation loss: 2.537102447800667

Epoch: 6| Step: 3
Training loss: 2.1086102264879956
Validation loss: 2.504582647235688

Epoch: 6| Step: 4
Training loss: 1.9677080091479875
Validation loss: 2.507091691699245

Epoch: 6| Step: 5
Training loss: 1.8595028360483155
Validation loss: 2.485503171901321

Epoch: 6| Step: 6
Training loss: 2.5232880255773362
Validation loss: 2.497182901641623

Epoch: 6| Step: 7
Training loss: 2.737418872902698
Validation loss: 2.504582103714664

Epoch: 6| Step: 8
Training loss: 1.6319383535429286
Validation loss: 2.4556234060300723

Epoch: 6| Step: 9
Training loss: 2.211579893355613
Validation loss: 2.5299503965912793

Epoch: 6| Step: 10
Training loss: 1.8806538850867651
Validation loss: 2.5342166651748417

Epoch: 6| Step: 11
Training loss: 2.287749659354304
Validation loss: 2.526816151797421

Epoch: 6| Step: 12
Training loss: 1.5721220910560354
Validation loss: 2.4659923823606515

Epoch: 6| Step: 13
Training loss: 2.138173056483084
Validation loss: 2.508527994402416

Epoch: 393| Step: 0
Training loss: 1.7476426323132914
Validation loss: 2.5291241553463104

Epoch: 6| Step: 1
Training loss: 2.105545523806081
Validation loss: 2.474180272007334

Epoch: 6| Step: 2
Training loss: 1.4996939982778017
Validation loss: 2.5246904272945896

Epoch: 6| Step: 3
Training loss: 2.0619274847560907
Validation loss: 2.543558489525791

Epoch: 6| Step: 4
Training loss: 2.21688872159675
Validation loss: 2.4895887388120146

Epoch: 6| Step: 5
Training loss: 2.9281620377485127
Validation loss: 2.5098056824969466

Epoch: 6| Step: 6
Training loss: 1.7198118917599508
Validation loss: 2.5095287685097167

Epoch: 6| Step: 7
Training loss: 1.8537584634125956
Validation loss: 2.5336741096272455

Epoch: 6| Step: 8
Training loss: 1.7624490581752892
Validation loss: 2.516234617329148

Epoch: 6| Step: 9
Training loss: 2.1953181473737415
Validation loss: 2.5136885958571824

Epoch: 6| Step: 10
Training loss: 1.9168984093370076
Validation loss: 2.500042422765298

Epoch: 6| Step: 11
Training loss: 1.9892744720016078
Validation loss: 2.4950283699610076

Epoch: 6| Step: 12
Training loss: 2.23223614524996
Validation loss: 2.514344551098412

Epoch: 6| Step: 13
Training loss: 2.003787864474843
Validation loss: 2.478512149597833

Epoch: 394| Step: 0
Training loss: 1.9826710511505212
Validation loss: 2.493291056523919

Epoch: 6| Step: 1
Training loss: 1.284811420036241
Validation loss: 2.4727519631003103

Epoch: 6| Step: 2
Training loss: 1.4903266848150858
Validation loss: 2.5158457918061794

Epoch: 6| Step: 3
Training loss: 2.199983778807053
Validation loss: 2.5161959194483106

Epoch: 6| Step: 4
Training loss: 2.1948254679675254
Validation loss: 2.543247146732565

Epoch: 6| Step: 5
Training loss: 2.525245137165321
Validation loss: 2.5108733301580015

Epoch: 6| Step: 6
Training loss: 2.0059538673200246
Validation loss: 2.5250794076875795

Epoch: 6| Step: 7
Training loss: 2.353215748530266
Validation loss: 2.5030921829930066

Epoch: 6| Step: 8
Training loss: 2.7204894716563537
Validation loss: 2.500321466020349

Epoch: 6| Step: 9
Training loss: 1.879810583535297
Validation loss: 2.525806076959879

Epoch: 6| Step: 10
Training loss: 2.3069734260606047
Validation loss: 2.511826241797625

Epoch: 6| Step: 11
Training loss: 1.5791877718331266
Validation loss: 2.516999660101864

Epoch: 6| Step: 12
Training loss: 1.368253368700433
Validation loss: 2.5286463111895663

Epoch: 6| Step: 13
Training loss: 2.2886666746612705
Validation loss: 2.483914624227251

Epoch: 395| Step: 0
Training loss: 1.8173483753580055
Validation loss: 2.5240876736073505

Epoch: 6| Step: 1
Training loss: 2.20281569020807
Validation loss: 2.5032791822496203

Epoch: 6| Step: 2
Training loss: 2.4328490659382713
Validation loss: 2.5365365295896254

Epoch: 6| Step: 3
Training loss: 1.4631543806630394
Validation loss: 2.48094235950892

Epoch: 6| Step: 4
Training loss: 1.5131255314419114
Validation loss: 2.53962419757257

Epoch: 6| Step: 5
Training loss: 1.7610420229878463
Validation loss: 2.5289962581671928

Epoch: 6| Step: 6
Training loss: 3.4202299997723506
Validation loss: 2.5200391820386723

Epoch: 6| Step: 7
Training loss: 1.4307323869137327
Validation loss: 2.51994134723362

Epoch: 6| Step: 8
Training loss: 1.648767375030241
Validation loss: 2.5115745218639494

Epoch: 6| Step: 9
Training loss: 2.2860925565790406
Validation loss: 2.4864801264489427

Epoch: 6| Step: 10
Training loss: 2.103493976393069
Validation loss: 2.532353653686523

Epoch: 6| Step: 11
Training loss: 2.2865643197928645
Validation loss: 2.4652160984218794

Epoch: 6| Step: 12
Training loss: 1.7646958598618971
Validation loss: 2.531686338337873

Epoch: 6| Step: 13
Training loss: 1.6814823940148276
Validation loss: 2.516414248721808

Epoch: 396| Step: 0
Training loss: 2.1468195701228825
Validation loss: 2.5212456584538394

Epoch: 6| Step: 1
Training loss: 2.0107994571661534
Validation loss: 2.476574273891947

Epoch: 6| Step: 2
Training loss: 2.2464694828394847
Validation loss: 2.5236863971344246

Epoch: 6| Step: 3
Training loss: 1.4382523765338775
Validation loss: 2.534119750007259

Epoch: 6| Step: 4
Training loss: 2.497796804454432
Validation loss: 2.5111346577329186

Epoch: 6| Step: 5
Training loss: 1.8157793829671716
Validation loss: 2.513477829450763

Epoch: 6| Step: 6
Training loss: 1.9317420801686838
Validation loss: 2.4723632392133004

Epoch: 6| Step: 7
Training loss: 1.912617289617923
Validation loss: 2.5556267802279513

Epoch: 6| Step: 8
Training loss: 2.062770016652744
Validation loss: 2.549431884880914

Epoch: 6| Step: 9
Training loss: 1.9072643770452808
Validation loss: 2.4833611986499573

Epoch: 6| Step: 10
Training loss: 2.097689210998603
Validation loss: 2.5201902916008665

Epoch: 6| Step: 11
Training loss: 1.9707857536180382
Validation loss: 2.516940238337722

Epoch: 6| Step: 12
Training loss: 1.8083437258631254
Validation loss: 2.4868666406236706

Epoch: 6| Step: 13
Training loss: 2.6770274135424286
Validation loss: 2.4958655317398515

Epoch: 397| Step: 0
Training loss: 1.926400044592353
Validation loss: 2.517354293510381

Epoch: 6| Step: 1
Training loss: 1.7222371186189849
Validation loss: 2.4857206966312018

Epoch: 6| Step: 2
Training loss: 2.089311364357617
Validation loss: 2.513265186849989

Epoch: 6| Step: 3
Training loss: 1.7596213295360323
Validation loss: 2.4786461517845617

Epoch: 6| Step: 4
Training loss: 2.4946432899094773
Validation loss: 2.4991972403524896

Epoch: 6| Step: 5
Training loss: 2.4440241823264324
Validation loss: 2.5259917423113087

Epoch: 6| Step: 6
Training loss: 2.15705591151071
Validation loss: 2.5414465397553587

Epoch: 6| Step: 7
Training loss: 1.2915073214451538
Validation loss: 2.500868051834821

Epoch: 6| Step: 8
Training loss: 2.2030616913485312
Validation loss: 2.499359751313233

Epoch: 6| Step: 9
Training loss: 1.6845112931237287
Validation loss: 2.479471152980683

Epoch: 6| Step: 10
Training loss: 1.6873632304962851
Validation loss: 2.490748062250437

Epoch: 6| Step: 11
Training loss: 2.3676284026922096
Validation loss: 2.514746118359357

Epoch: 6| Step: 12
Training loss: 2.5712332424272386
Validation loss: 2.5179490528548683

Epoch: 6| Step: 13
Training loss: 1.9177096127725617
Validation loss: 2.5245475017979055

Epoch: 398| Step: 0
Training loss: 2.2568770321942764
Validation loss: 2.4558102445330845

Epoch: 6| Step: 1
Training loss: 1.6033627696252983
Validation loss: 2.486205708319197

Epoch: 6| Step: 2
Training loss: 1.7997288473194792
Validation loss: 2.465844214408935

Epoch: 6| Step: 3
Training loss: 2.387355188901231
Validation loss: 2.4790187993930144

Epoch: 6| Step: 4
Training loss: 1.5755187315703525
Validation loss: 2.5054094037193235

Epoch: 6| Step: 5
Training loss: 2.1291413063683984
Validation loss: 2.5277268240708315

Epoch: 6| Step: 6
Training loss: 1.5660995221138672
Validation loss: 2.448628702769542

Epoch: 6| Step: 7
Training loss: 2.0028794541329953
Validation loss: 2.490623633314761

Epoch: 6| Step: 8
Training loss: 2.297968182601646
Validation loss: 2.5037627083743055

Epoch: 6| Step: 9
Training loss: 2.490785018777338
Validation loss: 2.532510156893634

Epoch: 6| Step: 10
Training loss: 0.8972691444125341
Validation loss: 2.500859168812238

Epoch: 6| Step: 11
Training loss: 2.2919788725912777
Validation loss: 2.522352202587759

Epoch: 6| Step: 12
Training loss: 1.9615628890419563
Validation loss: 2.510089265897763

Epoch: 6| Step: 13
Training loss: 2.904732256580953
Validation loss: 2.4861359441384714

Epoch: 399| Step: 0
Training loss: 1.909552418259272
Validation loss: 2.533654027811222

Epoch: 6| Step: 1
Training loss: 2.1259666936782886
Validation loss: 2.4770977287757683

Epoch: 6| Step: 2
Training loss: 2.230934749098756
Validation loss: 2.5032661145342314

Epoch: 6| Step: 3
Training loss: 1.8463956310815541
Validation loss: 2.479860445686495

Epoch: 6| Step: 4
Training loss: 2.57452974191964
Validation loss: 2.505365725221945

Epoch: 6| Step: 5
Training loss: 1.948527670382146
Validation loss: 2.5366713241623433

Epoch: 6| Step: 6
Training loss: 1.541787847275516
Validation loss: 2.4852169305417875

Epoch: 6| Step: 7
Training loss: 2.359080315180405
Validation loss: 2.462276848359374

Epoch: 6| Step: 8
Training loss: 1.600138109922139
Validation loss: 2.484536463223907

Epoch: 6| Step: 9
Training loss: 1.8145722349099738
Validation loss: 2.512604504328485

Epoch: 6| Step: 10
Training loss: 2.4796268986950794
Validation loss: 2.499083254504585

Epoch: 6| Step: 11
Training loss: 1.3739374997417881
Validation loss: 2.5438530026622175

Epoch: 6| Step: 12
Training loss: 1.8782167180622542
Validation loss: 2.5256404857949084

Epoch: 6| Step: 13
Training loss: 2.5534279427625552
Validation loss: 2.50605452807899

Epoch: 400| Step: 0
Training loss: 1.7287864343606103
Validation loss: 2.531200812056956

Epoch: 6| Step: 1
Training loss: 1.8535298386120258
Validation loss: 2.5138640974646616

Epoch: 6| Step: 2
Training loss: 2.638312777714067
Validation loss: 2.5268234851238334

Epoch: 6| Step: 3
Training loss: 1.3319411261266045
Validation loss: 2.5193115627001585

Epoch: 6| Step: 4
Training loss: 1.72445107723929
Validation loss: 2.4926113226428943

Epoch: 6| Step: 5
Training loss: 1.5470900723226404
Validation loss: 2.508913305794923

Epoch: 6| Step: 6
Training loss: 2.28936265663529
Validation loss: 2.501918458606776

Epoch: 6| Step: 7
Training loss: 2.5060490858259037
Validation loss: 2.4780717715399656

Epoch: 6| Step: 8
Training loss: 1.7937397680755036
Validation loss: 2.503115816565359

Epoch: 6| Step: 9
Training loss: 2.4001635575194116
Validation loss: 2.4917707917472303

Epoch: 6| Step: 10
Training loss: 2.752217179267557
Validation loss: 2.535120098064118

Epoch: 6| Step: 11
Training loss: 1.8733048723758083
Validation loss: 2.495132185332597

Epoch: 6| Step: 12
Training loss: 1.5371037910873797
Validation loss: 2.48083961614022

Epoch: 6| Step: 13
Training loss: 1.9385801811293755
Validation loss: 2.5137223748109956

Epoch: 401| Step: 0
Training loss: 2.7495993409025874
Validation loss: 2.491131409384701

Epoch: 6| Step: 1
Training loss: 2.0644652511543704
Validation loss: 2.5022374303219794

Epoch: 6| Step: 2
Training loss: 1.941618940342587
Validation loss: 2.521893087245142

Epoch: 6| Step: 3
Training loss: 2.0859749894220068
Validation loss: 2.528571517648318

Epoch: 6| Step: 4
Training loss: 1.5150746398265682
Validation loss: 2.5326795624001166

Epoch: 6| Step: 5
Training loss: 2.276496638050274
Validation loss: 2.5451176792127974

Epoch: 6| Step: 6
Training loss: 1.8192472164944764
Validation loss: 2.5164830655142505

Epoch: 6| Step: 7
Training loss: 1.7619552960997908
Validation loss: 2.5278569877172674

Epoch: 6| Step: 8
Training loss: 1.4276669091019538
Validation loss: 2.521118547262261

Epoch: 6| Step: 9
Training loss: 2.0086082929799143
Validation loss: 2.5421293642071165

Epoch: 6| Step: 10
Training loss: 2.160950333673704
Validation loss: 2.527472187240279

Epoch: 6| Step: 11
Training loss: 2.253677647466511
Validation loss: 2.518459217725214

Epoch: 6| Step: 12
Training loss: 1.8456604967795562
Validation loss: 2.526232988837779

Epoch: 6| Step: 13
Training loss: 2.0556844751064904
Validation loss: 2.5065352922261823

Epoch: 402| Step: 0
Training loss: 1.9342114627465734
Validation loss: 2.507079178655207

Epoch: 6| Step: 1
Training loss: 1.9425949663590103
Validation loss: 2.5050905493453572

Epoch: 6| Step: 2
Training loss: 1.7485708122804413
Validation loss: 2.524193405707796

Epoch: 6| Step: 3
Training loss: 2.226045675695079
Validation loss: 2.4918413189573343

Epoch: 6| Step: 4
Training loss: 1.759314950355239
Validation loss: 2.526802528068116

Epoch: 6| Step: 5
Training loss: 1.0805528366677914
Validation loss: 2.534137943444127

Epoch: 6| Step: 6
Training loss: 1.8975799884446969
Validation loss: 2.5225230250591384

Epoch: 6| Step: 7
Training loss: 2.1479090925120747
Validation loss: 2.5305938933816488

Epoch: 6| Step: 8
Training loss: 1.6971679940364446
Validation loss: 2.5102470193234234

Epoch: 6| Step: 9
Training loss: 2.9927523804364284
Validation loss: 2.5374587882858926

Epoch: 6| Step: 10
Training loss: 1.9144583779266653
Validation loss: 2.5883202738623567

Epoch: 6| Step: 11
Training loss: 1.932588443089358
Validation loss: 2.5219195846038476

Epoch: 6| Step: 12
Training loss: 2.331573185749873
Validation loss: 2.4821280680593376

Epoch: 6| Step: 13
Training loss: 2.154069544400045
Validation loss: 2.481211058145559

Epoch: 403| Step: 0
Training loss: 1.7000193847224234
Validation loss: 2.4973888430267186

Epoch: 6| Step: 1
Training loss: 1.7432796322421098
Validation loss: 2.516853042456604

Epoch: 6| Step: 2
Training loss: 1.3923582783599138
Validation loss: 2.50803775751317

Epoch: 6| Step: 3
Training loss: 1.8882183804697352
Validation loss: 2.481222015435476

Epoch: 6| Step: 4
Training loss: 2.1660680188376924
Validation loss: 2.499318951983662

Epoch: 6| Step: 5
Training loss: 1.6744960311427999
Validation loss: 2.513152585769859

Epoch: 6| Step: 6
Training loss: 1.223459534428388
Validation loss: 2.490702887385271

Epoch: 6| Step: 7
Training loss: 1.8800887671271886
Validation loss: 2.5173302912897015

Epoch: 6| Step: 8
Training loss: 2.422160076467936
Validation loss: 2.504137371861645

Epoch: 6| Step: 9
Training loss: 1.9393017912461479
Validation loss: 2.5013333138916884

Epoch: 6| Step: 10
Training loss: 2.6489121453422073
Validation loss: 2.506214356257827

Epoch: 6| Step: 11
Training loss: 1.2797083535084732
Validation loss: 2.5277503708270883

Epoch: 6| Step: 12
Training loss: 3.0994872253617474
Validation loss: 2.518918113194402

Epoch: 6| Step: 13
Training loss: 2.5171742851530836
Validation loss: 2.523847663390434

Epoch: 404| Step: 0
Training loss: 2.2522639434785945
Validation loss: 2.464730594236698

Epoch: 6| Step: 1
Training loss: 1.4627047370997197
Validation loss: 2.501195494594733

Epoch: 6| Step: 2
Training loss: 2.3390376210084085
Validation loss: 2.492506133057676

Epoch: 6| Step: 3
Training loss: 1.6538138557037267
Validation loss: 2.5298368377355915

Epoch: 6| Step: 4
Training loss: 2.3606479065753025
Validation loss: 2.507149572790528

Epoch: 6| Step: 5
Training loss: 1.8923105340045254
Validation loss: 2.520426541846721

Epoch: 6| Step: 6
Training loss: 2.5861553549837417
Validation loss: 2.5032656813321537

Epoch: 6| Step: 7
Training loss: 1.5267406160582497
Validation loss: 2.473664850120685

Epoch: 6| Step: 8
Training loss: 1.9534976451147807
Validation loss: 2.4783117947678748

Epoch: 6| Step: 9
Training loss: 2.329824966274102
Validation loss: 2.5417652415286263

Epoch: 6| Step: 10
Training loss: 1.9922250781535518
Validation loss: 2.489100863906362

Epoch: 6| Step: 11
Training loss: 2.093591029266974
Validation loss: 2.5272641132390654

Epoch: 6| Step: 12
Training loss: 1.9915380877990807
Validation loss: 2.509445707969566

Epoch: 6| Step: 13
Training loss: 1.5029691080001149
Validation loss: 2.5039752129511252

Epoch: 405| Step: 0
Training loss: 2.009051819911047
Validation loss: 2.5149417877571274

Epoch: 6| Step: 1
Training loss: 1.9658380195892782
Validation loss: 2.496516381676235

Epoch: 6| Step: 2
Training loss: 2.1141386143867353
Validation loss: 2.515015103920609

Epoch: 6| Step: 3
Training loss: 1.3747410963969917
Validation loss: 2.494906951489697

Epoch: 6| Step: 4
Training loss: 2.151344801361628
Validation loss: 2.5214156733562154

Epoch: 6| Step: 5
Training loss: 1.8387683876305927
Validation loss: 2.5071998696119473

Epoch: 6| Step: 6
Training loss: 1.4974423697054218
Validation loss: 2.5155819707232547

Epoch: 6| Step: 7
Training loss: 2.272771573935405
Validation loss: 2.503559738657142

Epoch: 6| Step: 8
Training loss: 2.405001427854245
Validation loss: 2.520895410470177

Epoch: 6| Step: 9
Training loss: 2.1454093538941157
Validation loss: 2.524987988974929

Epoch: 6| Step: 10
Training loss: 2.151782729458279
Validation loss: 2.511527139108699

Epoch: 6| Step: 11
Training loss: 2.0000209807249134
Validation loss: 2.538926914024698

Epoch: 6| Step: 12
Training loss: 1.813299594640079
Validation loss: 2.4983161362247253

Epoch: 6| Step: 13
Training loss: 2.558694106601734
Validation loss: 2.4886696240132142

Epoch: 406| Step: 0
Training loss: 2.393892735142526
Validation loss: 2.4952816419208617

Epoch: 6| Step: 1
Training loss: 2.127261136874833
Validation loss: 2.512572860171512

Epoch: 6| Step: 2
Training loss: 1.8660446564011344
Validation loss: 2.470307707776885

Epoch: 6| Step: 3
Training loss: 1.7511547910634297
Validation loss: 2.5320804316926893

Epoch: 6| Step: 4
Training loss: 1.9237467017588559
Validation loss: 2.4897016045030673

Epoch: 6| Step: 5
Training loss: 2.0058625842461546
Validation loss: 2.472874054702867

Epoch: 6| Step: 6
Training loss: 2.578075061661233
Validation loss: 2.481277154511618

Epoch: 6| Step: 7
Training loss: 1.244425646653193
Validation loss: 2.4864734762834995

Epoch: 6| Step: 8
Training loss: 1.7818684090044519
Validation loss: 2.515888631116405

Epoch: 6| Step: 9
Training loss: 1.9855881234341757
Validation loss: 2.4769518053155593

Epoch: 6| Step: 10
Training loss: 1.460727696985095
Validation loss: 2.458563189209045

Epoch: 6| Step: 11
Training loss: 2.0420876931724665
Validation loss: 2.4981082301084023

Epoch: 6| Step: 12
Training loss: 2.3666838560241277
Validation loss: 2.500226622738799

Epoch: 6| Step: 13
Training loss: 2.290747117017934
Validation loss: 2.5091625018984063

Epoch: 407| Step: 0
Training loss: 2.111685949276161
Validation loss: 2.5383497041909844

Epoch: 6| Step: 1
Training loss: 1.8841807352266575
Validation loss: 2.522352521727611

Epoch: 6| Step: 2
Training loss: 2.2893818186648773
Validation loss: 2.4941209551778654

Epoch: 6| Step: 3
Training loss: 2.123060800178573
Validation loss: 2.5188027897922676

Epoch: 6| Step: 4
Training loss: 2.4985133519208103
Validation loss: 2.560356113695005

Epoch: 6| Step: 5
Training loss: 1.228370451726516
Validation loss: 2.5449562558054497

Epoch: 6| Step: 6
Training loss: 1.998802780399217
Validation loss: 2.530105555931806

Epoch: 6| Step: 7
Training loss: 1.9885789689538056
Validation loss: 2.528980184906918

Epoch: 6| Step: 8
Training loss: 2.393792142571777
Validation loss: 2.5304158156769017

Epoch: 6| Step: 9
Training loss: 2.082690508533012
Validation loss: 2.512013577747501

Epoch: 6| Step: 10
Training loss: 2.19016452362921
Validation loss: 2.518906490409426

Epoch: 6| Step: 11
Training loss: 1.4120834580360704
Validation loss: 2.530592650358088

Epoch: 6| Step: 12
Training loss: 2.10719152398979
Validation loss: 2.54070088398169

Epoch: 6| Step: 13
Training loss: 1.4576244629575228
Validation loss: 2.4891256030975066

Epoch: 408| Step: 0
Training loss: 2.382516511137391
Validation loss: 2.492000032087991

Epoch: 6| Step: 1
Training loss: 2.1190863958355113
Validation loss: 2.477273384770559

Epoch: 6| Step: 2
Training loss: 2.1429955937299763
Validation loss: 2.5102308295843603

Epoch: 6| Step: 3
Training loss: 2.301274348787526
Validation loss: 2.5033656650463794

Epoch: 6| Step: 4
Training loss: 2.3628837314176594
Validation loss: 2.5268799909975432

Epoch: 6| Step: 5
Training loss: 1.8303268084521205
Validation loss: 2.559975021116104

Epoch: 6| Step: 6
Training loss: 2.0893038328547253
Validation loss: 2.503077430524527

Epoch: 6| Step: 7
Training loss: 2.2980194354716987
Validation loss: 2.477053045217041

Epoch: 6| Step: 8
Training loss: 1.4512080191915355
Validation loss: 2.470872314917017

Epoch: 6| Step: 9
Training loss: 2.154778019564575
Validation loss: 2.5067221404800004

Epoch: 6| Step: 10
Training loss: 1.6266965812657967
Validation loss: 2.474119039517617

Epoch: 6| Step: 11
Training loss: 1.8829305144873763
Validation loss: 2.4624246625222344

Epoch: 6| Step: 12
Training loss: 2.021469396268479
Validation loss: 2.509909266610038

Epoch: 6| Step: 13
Training loss: 2.0020692372958817
Validation loss: 2.5056838529432515

Epoch: 409| Step: 0
Training loss: 1.2311433426413048
Validation loss: 2.4998254151040267

Epoch: 6| Step: 1
Training loss: 0.7278766847172035
Validation loss: 2.5025885583414884

Epoch: 6| Step: 2
Training loss: 1.5086552927906394
Validation loss: 2.5351365965569905

Epoch: 6| Step: 3
Training loss: 3.134425482909134
Validation loss: 2.501723003378494

Epoch: 6| Step: 4
Training loss: 2.085522556824062
Validation loss: 2.4922473329504555

Epoch: 6| Step: 5
Training loss: 2.4651129283919917
Validation loss: 2.4460283951039576

Epoch: 6| Step: 6
Training loss: 1.609933700618054
Validation loss: 2.4936351641842456

Epoch: 6| Step: 7
Training loss: 2.08377122727482
Validation loss: 2.4949432966818

Epoch: 6| Step: 8
Training loss: 1.6458177042673747
Validation loss: 2.5209356978916446

Epoch: 6| Step: 9
Training loss: 2.343280592641874
Validation loss: 2.498701463855734

Epoch: 6| Step: 10
Training loss: 2.198862809263275
Validation loss: 2.488662740708877

Epoch: 6| Step: 11
Training loss: 1.7994068387001558
Validation loss: 2.4798370593092423

Epoch: 6| Step: 12
Training loss: 2.3247833848355572
Validation loss: 2.5107877875101687

Epoch: 6| Step: 13
Training loss: 2.0515213275854194
Validation loss: 2.45333712676784

Epoch: 410| Step: 0
Training loss: 1.3910789177541014
Validation loss: 2.4947857665397803

Epoch: 6| Step: 1
Training loss: 1.8753368075180736
Validation loss: 2.4972827675387577

Epoch: 6| Step: 2
Training loss: 2.3508799630126553
Validation loss: 2.5004977376809165

Epoch: 6| Step: 3
Training loss: 2.5701850465289224
Validation loss: 2.4993634182557547

Epoch: 6| Step: 4
Training loss: 1.863500490225893
Validation loss: 2.4946228188741206

Epoch: 6| Step: 5
Training loss: 2.154205680016745
Validation loss: 2.535608636512092

Epoch: 6| Step: 6
Training loss: 2.425212504720813
Validation loss: 2.505122866215284

Epoch: 6| Step: 7
Training loss: 2.1957389444504813
Validation loss: 2.484374572791018

Epoch: 6| Step: 8
Training loss: 2.3796111066432397
Validation loss: 2.517645834687506

Epoch: 6| Step: 9
Training loss: 1.4793580249349145
Validation loss: 2.518459090482698

Epoch: 6| Step: 10
Training loss: 1.9471173473902534
Validation loss: 2.497586290017098

Epoch: 6| Step: 11
Training loss: 1.5555282696344146
Validation loss: 2.4909879425997676

Epoch: 6| Step: 12
Training loss: 1.8988763749318094
Validation loss: 2.529138628165363

Epoch: 6| Step: 13
Training loss: 1.7497373111295833
Validation loss: 2.474457349378498

Epoch: 411| Step: 0
Training loss: 2.33145149730582
Validation loss: 2.5342422780161327

Epoch: 6| Step: 1
Training loss: 2.001921922394032
Validation loss: 2.511670716723223

Epoch: 6| Step: 2
Training loss: 2.008271754839016
Validation loss: 2.473946128689897

Epoch: 6| Step: 3
Training loss: 1.7862791707437922
Validation loss: 2.5131366947649485

Epoch: 6| Step: 4
Training loss: 2.088482964531827
Validation loss: 2.556902497165971

Epoch: 6| Step: 5
Training loss: 2.3380591922116514
Validation loss: 2.4972040333558967

Epoch: 6| Step: 6
Training loss: 1.7234116193500302
Validation loss: 2.5007338092950024

Epoch: 6| Step: 7
Training loss: 2.08919428065213
Validation loss: 2.501302221014577

Epoch: 6| Step: 8
Training loss: 1.9646465589341973
Validation loss: 2.510578896944

Epoch: 6| Step: 9
Training loss: 2.3617053113246502
Validation loss: 2.531995759925933

Epoch: 6| Step: 10
Training loss: 1.94933408957822
Validation loss: 2.4788695500574196

Epoch: 6| Step: 11
Training loss: 1.9151799268333474
Validation loss: 2.5298193308322987

Epoch: 6| Step: 12
Training loss: 1.6723496663451272
Validation loss: 2.5149438142515597

Epoch: 6| Step: 13
Training loss: 1.8623656896512983
Validation loss: 2.5158822747100484

Epoch: 412| Step: 0
Training loss: 1.5546573655164868
Validation loss: 2.477787036891634

Epoch: 6| Step: 1
Training loss: 2.2455508430142506
Validation loss: 2.508262301827787

Epoch: 6| Step: 2
Training loss: 2.078504255292738
Validation loss: 2.4832148299924173

Epoch: 6| Step: 3
Training loss: 1.1562571138730167
Validation loss: 2.502574515887602

Epoch: 6| Step: 4
Training loss: 1.7050709238151556
Validation loss: 2.4805045026702874

Epoch: 6| Step: 5
Training loss: 2.4601836487984854
Validation loss: 2.4997820687417005

Epoch: 6| Step: 6
Training loss: 2.5524000840615546
Validation loss: 2.496573678242018

Epoch: 6| Step: 7
Training loss: 2.2779452280454633
Validation loss: 2.4795465865053488

Epoch: 6| Step: 8
Training loss: 2.0201436337308594
Validation loss: 2.52013009768635

Epoch: 6| Step: 9
Training loss: 2.492196588290394
Validation loss: 2.4956548667219645

Epoch: 6| Step: 10
Training loss: 1.9050884147211287
Validation loss: 2.5004160114474367

Epoch: 6| Step: 11
Training loss: 1.7746650379745688
Validation loss: 2.492946736828352

Epoch: 6| Step: 12
Training loss: 1.4950989286676972
Validation loss: 2.531762052958734

Epoch: 6| Step: 13
Training loss: 2.0460171831216742
Validation loss: 2.4950630036494235

Epoch: 413| Step: 0
Training loss: 2.2397788265573304
Validation loss: 2.5071121928325395

Epoch: 6| Step: 1
Training loss: 1.649611936075371
Validation loss: 2.510422149830585

Epoch: 6| Step: 2
Training loss: 1.9766767265273977
Validation loss: 2.47461650873357

Epoch: 6| Step: 3
Training loss: 2.533603280726177
Validation loss: 2.491685438508974

Epoch: 6| Step: 4
Training loss: 2.577006149266892
Validation loss: 2.4926140923809332

Epoch: 6| Step: 5
Training loss: 1.7589105186061567
Validation loss: 2.5174022254702826

Epoch: 6| Step: 6
Training loss: 2.083476926305523
Validation loss: 2.513079768684242

Epoch: 6| Step: 7
Training loss: 2.0310891894727967
Validation loss: 2.514040787042095

Epoch: 6| Step: 8
Training loss: 1.4541948543465415
Validation loss: 2.488678468650192

Epoch: 6| Step: 9
Training loss: 2.0374216076332794
Validation loss: 2.489407628976802

Epoch: 6| Step: 10
Training loss: 1.8128004153985997
Validation loss: 2.515890924839731

Epoch: 6| Step: 11
Training loss: 1.7351232753129782
Validation loss: 2.5192600636901608

Epoch: 6| Step: 12
Training loss: 2.1019143869984322
Validation loss: 2.512561597800098

Epoch: 6| Step: 13
Training loss: 1.7005118525113596
Validation loss: 2.508253586550417

Epoch: 414| Step: 0
Training loss: 2.221333893075592
Validation loss: 2.48503405419334

Epoch: 6| Step: 1
Training loss: 2.8968175592252177
Validation loss: 2.5123089188680763

Epoch: 6| Step: 2
Training loss: 1.3105970847777473
Validation loss: 2.498685406047671

Epoch: 6| Step: 3
Training loss: 2.282310970705875
Validation loss: 2.48357520525342

Epoch: 6| Step: 4
Training loss: 1.7041249970406926
Validation loss: 2.516254212603776

Epoch: 6| Step: 5
Training loss: 1.861544393362039
Validation loss: 2.4688770847677026

Epoch: 6| Step: 6
Training loss: 1.7379391451454806
Validation loss: 2.4968954950362403

Epoch: 6| Step: 7
Training loss: 1.7899197186416291
Validation loss: 2.5018678178811946

Epoch: 6| Step: 8
Training loss: 2.3605965994938636
Validation loss: 2.547487008346262

Epoch: 6| Step: 9
Training loss: 1.560161901166726
Validation loss: 2.5229509588694765

Epoch: 6| Step: 10
Training loss: 2.1411308192162286
Validation loss: 2.507449109733075

Epoch: 6| Step: 11
Training loss: 2.0307177506548535
Validation loss: 2.4996594494449065

Epoch: 6| Step: 12
Training loss: 2.1471009692190735
Validation loss: 2.5299241307830136

Epoch: 6| Step: 13
Training loss: 1.6387460757746146
Validation loss: 2.5054913620326973

Epoch: 415| Step: 0
Training loss: 1.942826547852611
Validation loss: 2.512998391447112

Epoch: 6| Step: 1
Training loss: 2.19795844112188
Validation loss: 2.457990485495678

Epoch: 6| Step: 2
Training loss: 1.8616229661384711
Validation loss: 2.508493322293796

Epoch: 6| Step: 3
Training loss: 1.7696402476174498
Validation loss: 2.5026884246731234

Epoch: 6| Step: 4
Training loss: 2.2004870049097893
Validation loss: 2.527402156270277

Epoch: 6| Step: 5
Training loss: 1.6368799244040824
Validation loss: 2.533887709508671

Epoch: 6| Step: 6
Training loss: 1.880544475683682
Validation loss: 2.525725176747017

Epoch: 6| Step: 7
Training loss: 2.8758845419807297
Validation loss: 2.5172053805734054

Epoch: 6| Step: 8
Training loss: 1.5670575621451088
Validation loss: 2.5071581855626643

Epoch: 6| Step: 9
Training loss: 2.696178529346559
Validation loss: 2.4749512862467005

Epoch: 6| Step: 10
Training loss: 2.036899164459733
Validation loss: 2.5291439234245914

Epoch: 6| Step: 11
Training loss: 1.8948272159283168
Validation loss: 2.5032014549662165

Epoch: 6| Step: 12
Training loss: 1.9347843088395067
Validation loss: 2.471497453048721

Epoch: 6| Step: 13
Training loss: 1.1448213385409314
Validation loss: 2.492396998529358

Epoch: 416| Step: 0
Training loss: 2.241650347549806
Validation loss: 2.500333460236545

Epoch: 6| Step: 1
Training loss: 1.4121090373227467
Validation loss: 2.536654107991684

Epoch: 6| Step: 2
Training loss: 1.6795241165541976
Validation loss: 2.4996919780603544

Epoch: 6| Step: 3
Training loss: 2.1312414398468924
Validation loss: 2.496164875017602

Epoch: 6| Step: 4
Training loss: 2.0757732421352997
Validation loss: 2.5498460343150056

Epoch: 6| Step: 5
Training loss: 1.4337909781096725
Validation loss: 2.572914079360355

Epoch: 6| Step: 6
Training loss: 1.6121312954491267
Validation loss: 2.542864298629779

Epoch: 6| Step: 7
Training loss: 1.9586857485381592
Validation loss: 2.5556293974078326

Epoch: 6| Step: 8
Training loss: 1.7144553889591883
Validation loss: 2.53635456127039

Epoch: 6| Step: 9
Training loss: 2.082228431167673
Validation loss: 2.518814914829411

Epoch: 6| Step: 10
Training loss: 2.2690793767757733
Validation loss: 2.572935836565805

Epoch: 6| Step: 11
Training loss: 2.9104565766278037
Validation loss: 2.5247754496565276

Epoch: 6| Step: 12
Training loss: 2.1737114257197727
Validation loss: 2.521503629547626

Epoch: 6| Step: 13
Training loss: 2.3974779427541
Validation loss: 2.536936696121055

Epoch: 417| Step: 0
Training loss: 2.2653966328198907
Validation loss: 2.4904099081362094

Epoch: 6| Step: 1
Training loss: 2.5281853667456247
Validation loss: 2.509385198086813

Epoch: 6| Step: 2
Training loss: 1.8949526603241003
Validation loss: 2.506332760819353

Epoch: 6| Step: 3
Training loss: 2.1901586452486543
Validation loss: 2.506284509756273

Epoch: 6| Step: 4
Training loss: 2.29754359057628
Validation loss: 2.500878714905598

Epoch: 6| Step: 5
Training loss: 1.5288021217874428
Validation loss: 2.510449305408013

Epoch: 6| Step: 6
Training loss: 1.5863096054337507
Validation loss: 2.4936629281870064

Epoch: 6| Step: 7
Training loss: 2.150994239512116
Validation loss: 2.51577038485924

Epoch: 6| Step: 8
Training loss: 1.9194286252241086
Validation loss: 2.5147351379135108

Epoch: 6| Step: 9
Training loss: 1.9118757563050475
Validation loss: 2.4904753300879934

Epoch: 6| Step: 10
Training loss: 2.221774122306162
Validation loss: 2.5064854668775314

Epoch: 6| Step: 11
Training loss: 1.7201974495953893
Validation loss: 2.495283414177128

Epoch: 6| Step: 12
Training loss: 1.8319117785705
Validation loss: 2.4938804813354403

Epoch: 6| Step: 13
Training loss: 1.49568086907961
Validation loss: 2.516527804079322

Epoch: 418| Step: 0
Training loss: 1.4512950901383455
Validation loss: 2.5308943346302573

Epoch: 6| Step: 1
Training loss: 1.7206184634837276
Validation loss: 2.499992579787533

Epoch: 6| Step: 2
Training loss: 2.176837329259272
Validation loss: 2.4697705079820587

Epoch: 6| Step: 3
Training loss: 1.5193646101790548
Validation loss: 2.492858501159421

Epoch: 6| Step: 4
Training loss: 1.2700491919715022
Validation loss: 2.49587626856745

Epoch: 6| Step: 5
Training loss: 2.608071647005094
Validation loss: 2.4774807534900765

Epoch: 6| Step: 6
Training loss: 1.3719051383842016
Validation loss: 2.464651914935017

Epoch: 6| Step: 7
Training loss: 1.5808655765337343
Validation loss: 2.4652798346207057

Epoch: 6| Step: 8
Training loss: 1.920109193498293
Validation loss: 2.503452292317626

Epoch: 6| Step: 9
Training loss: 1.8959043580329547
Validation loss: 2.5025625221682164

Epoch: 6| Step: 10
Training loss: 2.9496314966248494
Validation loss: 2.5095275610224794

Epoch: 6| Step: 11
Training loss: 2.4715310379477953
Validation loss: 2.474154270532473

Epoch: 6| Step: 12
Training loss: 1.8679917650388425
Validation loss: 2.531655088131668

Epoch: 6| Step: 13
Training loss: 2.4748763352142005
Validation loss: 2.5111841437800755

Epoch: 419| Step: 0
Training loss: 1.7891650441195992
Validation loss: 2.5195650177778908

Epoch: 6| Step: 1
Training loss: 2.0975425874117217
Validation loss: 2.519898679065776

Epoch: 6| Step: 2
Training loss: 1.7413834568207442
Validation loss: 2.4800817385210805

Epoch: 6| Step: 3
Training loss: 1.435344406693535
Validation loss: 2.510973873669174

Epoch: 6| Step: 4
Training loss: 2.489070749119501
Validation loss: 2.5213048384312575

Epoch: 6| Step: 5
Training loss: 1.5191111633629886
Validation loss: 2.4796024317662093

Epoch: 6| Step: 6
Training loss: 1.408125961242429
Validation loss: 2.520951523464022

Epoch: 6| Step: 7
Training loss: 2.5848437067592314
Validation loss: 2.4953529539508463

Epoch: 6| Step: 8
Training loss: 2.3124242203126832
Validation loss: 2.4672155631191894

Epoch: 6| Step: 9
Training loss: 1.9479687797660823
Validation loss: 2.5215576885120656

Epoch: 6| Step: 10
Training loss: 1.9539286676620944
Validation loss: 2.527043128067656

Epoch: 6| Step: 11
Training loss: 2.530785223593939
Validation loss: 2.499193240811087

Epoch: 6| Step: 12
Training loss: 1.7204810701773923
Validation loss: 2.4747324481865607

Epoch: 6| Step: 13
Training loss: 1.636274400358645
Validation loss: 2.500254006966645

Epoch: 420| Step: 0
Training loss: 1.6531069460714076
Validation loss: 2.4908254051931094

Epoch: 6| Step: 1
Training loss: 2.045246670496317
Validation loss: 2.5299159223136747

Epoch: 6| Step: 2
Training loss: 1.787383645278807
Validation loss: 2.514249480223728

Epoch: 6| Step: 3
Training loss: 2.090800470991211
Validation loss: 2.524996412971781

Epoch: 6| Step: 4
Training loss: 2.165424675641918
Validation loss: 2.5544414504006836

Epoch: 6| Step: 5
Training loss: 1.574303560835761
Validation loss: 2.4903822138970897

Epoch: 6| Step: 6
Training loss: 1.9936807458981343
Validation loss: 2.5131359929388175

Epoch: 6| Step: 7
Training loss: 1.7951677919770979
Validation loss: 2.520383076808394

Epoch: 6| Step: 8
Training loss: 1.6476336503412081
Validation loss: 2.4791609475440466

Epoch: 6| Step: 9
Training loss: 1.7558961722280915
Validation loss: 2.4838542158920065

Epoch: 6| Step: 10
Training loss: 1.7189773409217164
Validation loss: 2.477827949691327

Epoch: 6| Step: 11
Training loss: 2.13530197455828
Validation loss: 2.481517458630606

Epoch: 6| Step: 12
Training loss: 2.5383622832556205
Validation loss: 2.5578768414252537

Epoch: 6| Step: 13
Training loss: 3.1102756748493485
Validation loss: 2.493681793057309

Epoch: 421| Step: 0
Training loss: 1.903387828899662
Validation loss: 2.499071933392299

Epoch: 6| Step: 1
Training loss: 2.1574062619670884
Validation loss: 2.5496139107811233

Epoch: 6| Step: 2
Training loss: 1.8663459701033058
Validation loss: 2.515224431264664

Epoch: 6| Step: 3
Training loss: 2.2325007974552724
Validation loss: 2.4802234996411143

Epoch: 6| Step: 4
Training loss: 2.2348821104563745
Validation loss: 2.474137506306064

Epoch: 6| Step: 5
Training loss: 2.341459553837016
Validation loss: 2.505991136350384

Epoch: 6| Step: 6
Training loss: 2.0017056344733906
Validation loss: 2.541522973320964

Epoch: 6| Step: 7
Training loss: 1.7120189993641892
Validation loss: 2.536574301656768

Epoch: 6| Step: 8
Training loss: 1.8373905356882072
Validation loss: 2.5082085808135703

Epoch: 6| Step: 9
Training loss: 1.6516462436546353
Validation loss: 2.506453588976445

Epoch: 6| Step: 10
Training loss: 2.3664471063270054
Validation loss: 2.506982320857441

Epoch: 6| Step: 11
Training loss: 2.4059355889543306
Validation loss: 2.4992592821751436

Epoch: 6| Step: 12
Training loss: 1.2543061471392631
Validation loss: 2.5424131275343855

Epoch: 6| Step: 13
Training loss: 1.72247292717419
Validation loss: 2.535655383235576

Epoch: 422| Step: 0
Training loss: 2.5103666899416806
Validation loss: 2.5255866482096807

Epoch: 6| Step: 1
Training loss: 2.254868961256992
Validation loss: 2.5467350902035064

Epoch: 6| Step: 2
Training loss: 1.3277994542278921
Validation loss: 2.491593991172232

Epoch: 6| Step: 3
Training loss: 1.4575048909178867
Validation loss: 2.488816194113893

Epoch: 6| Step: 4
Training loss: 1.9252767463018048
Validation loss: 2.5063274265715028

Epoch: 6| Step: 5
Training loss: 1.841942240377919
Validation loss: 2.5014177486226896

Epoch: 6| Step: 6
Training loss: 1.8637511102786937
Validation loss: 2.501026336666264

Epoch: 6| Step: 7
Training loss: 2.4515017830773935
Validation loss: 2.4849546249976737

Epoch: 6| Step: 8
Training loss: 2.568343872487672
Validation loss: 2.520362070268742

Epoch: 6| Step: 9
Training loss: 2.204963404033877
Validation loss: 2.4975546269973767

Epoch: 6| Step: 10
Training loss: 2.00749198047371
Validation loss: 2.503173007135767

Epoch: 6| Step: 11
Training loss: 1.7585600895077267
Validation loss: 2.4863929480700033

Epoch: 6| Step: 12
Training loss: 1.74861771623803
Validation loss: 2.5108162404472667

Epoch: 6| Step: 13
Training loss: 1.3113319103742003
Validation loss: 2.491682812810622

Epoch: 423| Step: 0
Training loss: 1.5634183092481624
Validation loss: 2.4588653460840986

Epoch: 6| Step: 1
Training loss: 2.0783329909792663
Validation loss: 2.4773721978079966

Epoch: 6| Step: 2
Training loss: 2.039404127945837
Validation loss: 2.514760223334845

Epoch: 6| Step: 3
Training loss: 2.0876609740179903
Validation loss: 2.440656188334483

Epoch: 6| Step: 4
Training loss: 2.319074203981886
Validation loss: 2.471813700197861

Epoch: 6| Step: 5
Training loss: 1.9103178802319616
Validation loss: 2.4673425637931694

Epoch: 6| Step: 6
Training loss: 1.273876933473219
Validation loss: 2.5088548870345737

Epoch: 6| Step: 7
Training loss: 2.5368701096642896
Validation loss: 2.4786145333165384

Epoch: 6| Step: 8
Training loss: 2.337519795543059
Validation loss: 2.4941059281371367

Epoch: 6| Step: 9
Training loss: 1.9449102759566073
Validation loss: 2.4935626541226967

Epoch: 6| Step: 10
Training loss: 2.0285123716695943
Validation loss: 2.4936774433551863

Epoch: 6| Step: 11
Training loss: 2.013682412564875
Validation loss: 2.5578911936529733

Epoch: 6| Step: 12
Training loss: 1.7100512852702385
Validation loss: 2.4887197668995404

Epoch: 6| Step: 13
Training loss: 1.6225603570277058
Validation loss: 2.475215474238504

Epoch: 424| Step: 0
Training loss: 2.7554606927246104
Validation loss: 2.5007564538489326

Epoch: 6| Step: 1
Training loss: 1.543279148218945
Validation loss: 2.4727734176375846

Epoch: 6| Step: 2
Training loss: 2.023671965104788
Validation loss: 2.496812129227338

Epoch: 6| Step: 3
Training loss: 1.3035214632913532
Validation loss: 2.5086161347102087

Epoch: 6| Step: 4
Training loss: 2.402935470032108
Validation loss: 2.53393820707252

Epoch: 6| Step: 5
Training loss: 2.2159597555561854
Validation loss: 2.5333502819366505

Epoch: 6| Step: 6
Training loss: 1.9290449176816993
Validation loss: 2.5119686011052265

Epoch: 6| Step: 7
Training loss: 1.574468928825499
Validation loss: 2.564086003064675

Epoch: 6| Step: 8
Training loss: 1.6879901880458206
Validation loss: 2.497566596522084

Epoch: 6| Step: 9
Training loss: 2.0774229771260146
Validation loss: 2.533005644756821

Epoch: 6| Step: 10
Training loss: 2.3333053814258267
Validation loss: 2.4933369834049093

Epoch: 6| Step: 11
Training loss: 1.6755589335478087
Validation loss: 2.4954513371970393

Epoch: 6| Step: 12
Training loss: 1.9675852645371883
Validation loss: 2.5280428365847887

Epoch: 6| Step: 13
Training loss: 1.6339986043151349
Validation loss: 2.485715903956975

Epoch: 425| Step: 0
Training loss: 2.235514103690758
Validation loss: 2.5174192545541842

Epoch: 6| Step: 1
Training loss: 1.819695953606307
Validation loss: 2.525021193391125

Epoch: 6| Step: 2
Training loss: 2.1421376473645077
Validation loss: 2.472722204911445

Epoch: 6| Step: 3
Training loss: 1.5213272738362518
Validation loss: 2.511833868940404

Epoch: 6| Step: 4
Training loss: 1.8232967816001142
Validation loss: 2.4989317919121468

Epoch: 6| Step: 5
Training loss: 1.8480520973623633
Validation loss: 2.503287932255398

Epoch: 6| Step: 6
Training loss: 2.4709514990646784
Validation loss: 2.5466875734208205

Epoch: 6| Step: 7
Training loss: 1.7872571206643997
Validation loss: 2.4983800315546514

Epoch: 6| Step: 8
Training loss: 2.375026100416821
Validation loss: 2.495227519176798

Epoch: 6| Step: 9
Training loss: 1.8144918874946605
Validation loss: 2.4982687893345252

Epoch: 6| Step: 10
Training loss: 1.9885787291658996
Validation loss: 2.507035772111646

Epoch: 6| Step: 11
Training loss: 2.141744947177933
Validation loss: 2.4837258496233807

Epoch: 6| Step: 12
Training loss: 1.444248777162187
Validation loss: 2.5210986588031483

Epoch: 6| Step: 13
Training loss: 2.0312582162544164
Validation loss: 2.4973842357062654

Epoch: 426| Step: 0
Training loss: 1.5697829838820383
Validation loss: 2.5027188887963105

Epoch: 6| Step: 1
Training loss: 1.8717712577386123
Validation loss: 2.487996159791563

Epoch: 6| Step: 2
Training loss: 2.2371900205228985
Validation loss: 2.5200513550437478

Epoch: 6| Step: 3
Training loss: 2.3931293210747504
Validation loss: 2.465564275148431

Epoch: 6| Step: 4
Training loss: 1.8729556064426178
Validation loss: 2.52195089597838

Epoch: 6| Step: 5
Training loss: 2.1406069566843353
Validation loss: 2.5243349446880172

Epoch: 6| Step: 6
Training loss: 1.9983263165263518
Validation loss: 2.5140708443983795

Epoch: 6| Step: 7
Training loss: 2.1395055809367207
Validation loss: 2.530835529820914

Epoch: 6| Step: 8
Training loss: 2.395189104677952
Validation loss: 2.533860327575058

Epoch: 6| Step: 9
Training loss: 1.2969126868229919
Validation loss: 2.526086229684603

Epoch: 6| Step: 10
Training loss: 1.5690642752577526
Validation loss: 2.5383765539295085

Epoch: 6| Step: 11
Training loss: 1.947352125261097
Validation loss: 2.5412714076093934

Epoch: 6| Step: 12
Training loss: 1.842394573037043
Validation loss: 2.4882296713017817

Epoch: 6| Step: 13
Training loss: 2.8257895252548515
Validation loss: 2.514844806672717

Epoch: 427| Step: 0
Training loss: 1.2787216640550985
Validation loss: 2.505561596141964

Epoch: 6| Step: 1
Training loss: 2.478311011704068
Validation loss: 2.540070797464292

Epoch: 6| Step: 2
Training loss: 2.50173737238166
Validation loss: 2.523021077826953

Epoch: 6| Step: 3
Training loss: 1.7566633070757383
Validation loss: 2.51986548192675

Epoch: 6| Step: 4
Training loss: 1.8275211999918572
Validation loss: 2.523086654008884

Epoch: 6| Step: 5
Training loss: 1.8870922532407395
Validation loss: 2.5112600255790247

Epoch: 6| Step: 6
Training loss: 1.6558719419455596
Validation loss: 2.519413251022287

Epoch: 6| Step: 7
Training loss: 1.8673855345344794
Validation loss: 2.4840143516865316

Epoch: 6| Step: 8
Training loss: 2.482956775388913
Validation loss: 2.4863747063449617

Epoch: 6| Step: 9
Training loss: 1.9424122711755554
Validation loss: 2.4974963403096218

Epoch: 6| Step: 10
Training loss: 1.703218859964736
Validation loss: 2.4877220799598305

Epoch: 6| Step: 11
Training loss: 2.434347412579864
Validation loss: 2.518033861999342

Epoch: 6| Step: 12
Training loss: 1.209356691285957
Validation loss: 2.468213479063696

Epoch: 6| Step: 13
Training loss: 1.7014876027783592
Validation loss: 2.4960709594115427

Epoch: 428| Step: 0
Training loss: 1.901952683751746
Validation loss: 2.5062859755499383

Epoch: 6| Step: 1
Training loss: 1.3519890172867806
Validation loss: 2.4655662694427187

Epoch: 6| Step: 2
Training loss: 2.0308744817026256
Validation loss: 2.520137674266134

Epoch: 6| Step: 3
Training loss: 2.2412242348802147
Validation loss: 2.5090885411432624

Epoch: 6| Step: 4
Training loss: 1.7393717913198807
Validation loss: 2.4757360273195306

Epoch: 6| Step: 5
Training loss: 1.9297690432227024
Validation loss: 2.485917193475244

Epoch: 6| Step: 6
Training loss: 1.9724003087562036
Validation loss: 2.480438587256284

Epoch: 6| Step: 7
Training loss: 2.440907370904304
Validation loss: 2.4977208053891413

Epoch: 6| Step: 8
Training loss: 2.1386376504467624
Validation loss: 2.506177575085248

Epoch: 6| Step: 9
Training loss: 1.8147655665634812
Validation loss: 2.5528071726628108

Epoch: 6| Step: 10
Training loss: 2.7241744374510275
Validation loss: 2.513362359446483

Epoch: 6| Step: 11
Training loss: 1.3176927025311451
Validation loss: 2.5574760319594056

Epoch: 6| Step: 12
Training loss: 1.5468450986496058
Validation loss: 2.5021852848254014

Epoch: 6| Step: 13
Training loss: 1.9349845431200858
Validation loss: 2.4960641232215006

Epoch: 429| Step: 0
Training loss: 2.0477281495955455
Validation loss: 2.5440989270506744

Epoch: 6| Step: 1
Training loss: 1.8360944964871817
Validation loss: 2.4706330247563395

Epoch: 6| Step: 2
Training loss: 1.3129614064398143
Validation loss: 2.498633409067461

Epoch: 6| Step: 3
Training loss: 2.037677747778162
Validation loss: 2.533789672846936

Epoch: 6| Step: 4
Training loss: 1.6230625927619653
Validation loss: 2.5242734602728025

Epoch: 6| Step: 5
Training loss: 2.431598954054339
Validation loss: 2.5411756755047095

Epoch: 6| Step: 6
Training loss: 2.196618177180732
Validation loss: 2.537369255343991

Epoch: 6| Step: 7
Training loss: 1.567817641932796
Validation loss: 2.5143586685226023

Epoch: 6| Step: 8
Training loss: 1.7286467938843353
Validation loss: 2.5759256039598366

Epoch: 6| Step: 9
Training loss: 2.1087907900480327
Validation loss: 2.522697724061651

Epoch: 6| Step: 10
Training loss: 2.5925067541757296
Validation loss: 2.5483953398714907

Epoch: 6| Step: 11
Training loss: 1.5457293959615153
Validation loss: 2.5173277124535645

Epoch: 6| Step: 12
Training loss: 1.661766725178514
Validation loss: 2.500610567208157

Epoch: 6| Step: 13
Training loss: 2.940666277896726
Validation loss: 2.5122625408220367

Epoch: 430| Step: 0
Training loss: 1.8948167723393534
Validation loss: 2.535827420458465

Epoch: 6| Step: 1
Training loss: 2.1487078132504736
Validation loss: 2.529775548856607

Epoch: 6| Step: 2
Training loss: 1.981653885935172
Validation loss: 2.5013044420203974

Epoch: 6| Step: 3
Training loss: 1.8202293278762407
Validation loss: 2.514977246077194

Epoch: 6| Step: 4
Training loss: 1.6873848487277774
Validation loss: 2.4832013036109366

Epoch: 6| Step: 5
Training loss: 1.9869031645778679
Validation loss: 2.495542502445719

Epoch: 6| Step: 6
Training loss: 2.2971839956444433
Validation loss: 2.4867036523927317

Epoch: 6| Step: 7
Training loss: 1.7147659596936393
Validation loss: 2.4525885104079133

Epoch: 6| Step: 8
Training loss: 1.661884297104245
Validation loss: 2.4658463145220924

Epoch: 6| Step: 9
Training loss: 1.7167682667020543
Validation loss: 2.5334673130306573

Epoch: 6| Step: 10
Training loss: 1.834606970915551
Validation loss: 2.4857583920789974

Epoch: 6| Step: 11
Training loss: 2.134189370881242
Validation loss: 2.4824439141273906

Epoch: 6| Step: 12
Training loss: 2.4796318023906787
Validation loss: 2.4799575419699833

Epoch: 6| Step: 13
Training loss: 2.2767419036154957
Validation loss: 2.4852141339916805

Epoch: 431| Step: 0
Training loss: 1.8700487886275947
Validation loss: 2.4681561442310644

Epoch: 6| Step: 1
Training loss: 2.194371792305536
Validation loss: 2.483470903674006

Epoch: 6| Step: 2
Training loss: 1.90783937827382
Validation loss: 2.5360973396312687

Epoch: 6| Step: 3
Training loss: 2.6548115145055533
Validation loss: 2.5208290496345014

Epoch: 6| Step: 4
Training loss: 1.5989486578069774
Validation loss: 2.5259251971849492

Epoch: 6| Step: 5
Training loss: 1.9414073552640843
Validation loss: 2.4920391797658468

Epoch: 6| Step: 6
Training loss: 2.175351550750878
Validation loss: 2.5049620237733032

Epoch: 6| Step: 7
Training loss: 2.275173717196208
Validation loss: 2.4660814223179295

Epoch: 6| Step: 8
Training loss: 1.4355111669134628
Validation loss: 2.486151444709142

Epoch: 6| Step: 9
Training loss: 1.4950641645102754
Validation loss: 2.53006361901035

Epoch: 6| Step: 10
Training loss: 2.078706473550302
Validation loss: 2.5259644777670287

Epoch: 6| Step: 11
Training loss: 2.2706993366802433
Validation loss: 2.561646928511501

Epoch: 6| Step: 12
Training loss: 1.9244671839718255
Validation loss: 2.540436977936523

Epoch: 6| Step: 13
Training loss: 1.9046086608742676
Validation loss: 2.534272066439589

Epoch: 432| Step: 0
Training loss: 1.6565636391843583
Validation loss: 2.511480388336193

Epoch: 6| Step: 1
Training loss: 1.9359001199163122
Validation loss: 2.5192475561345797

Epoch: 6| Step: 2
Training loss: 2.752540801782694
Validation loss: 2.49033170969495

Epoch: 6| Step: 3
Training loss: 2.1123121369927587
Validation loss: 2.4960014237217596

Epoch: 6| Step: 4
Training loss: 1.5859826743922174
Validation loss: 2.5053039297859505

Epoch: 6| Step: 5
Training loss: 1.817508617312481
Validation loss: 2.4716128303809906

Epoch: 6| Step: 6
Training loss: 1.9804465990501872
Validation loss: 2.4879209721528097

Epoch: 6| Step: 7
Training loss: 1.9381306760053485
Validation loss: 2.5246518874568786

Epoch: 6| Step: 8
Training loss: 1.8605462240265631
Validation loss: 2.502225299747026

Epoch: 6| Step: 9
Training loss: 2.2348505327737493
Validation loss: 2.5120219881029615

Epoch: 6| Step: 10
Training loss: 1.943342812625717
Validation loss: 2.4966582261920687

Epoch: 6| Step: 11
Training loss: 2.1200137260280565
Validation loss: 2.4938616549754102

Epoch: 6| Step: 12
Training loss: 1.3660199220637215
Validation loss: 2.47952437584188

Epoch: 6| Step: 13
Training loss: 2.0031944036734655
Validation loss: 2.5076803835086143

Epoch: 433| Step: 0
Training loss: 2.1271394169880353
Validation loss: 2.5217378312816905

Epoch: 6| Step: 1
Training loss: 2.1912526231522644
Validation loss: 2.4659417918864732

Epoch: 6| Step: 2
Training loss: 1.8045940952982753
Validation loss: 2.5306712838189607

Epoch: 6| Step: 3
Training loss: 2.0053517740311455
Validation loss: 2.4897529200012136

Epoch: 6| Step: 4
Training loss: 2.245616138928091
Validation loss: 2.435668439139058

Epoch: 6| Step: 5
Training loss: 2.336989762211559
Validation loss: 2.4969467653616126

Epoch: 6| Step: 6
Training loss: 2.038450536573643
Validation loss: 2.4495479457169322

Epoch: 6| Step: 7
Training loss: 1.8525161540656585
Validation loss: 2.501507324172675

Epoch: 6| Step: 8
Training loss: 1.288195555493109
Validation loss: 2.5390454585637015

Epoch: 6| Step: 9
Training loss: 1.929567958820235
Validation loss: 2.4629484935570924

Epoch: 6| Step: 10
Training loss: 1.5241658352612701
Validation loss: 2.50197986119942

Epoch: 6| Step: 11
Training loss: 2.6449767600987353
Validation loss: 2.4853715013188995

Epoch: 6| Step: 12
Training loss: 1.68517029623333
Validation loss: 2.5074682691090167

Epoch: 6| Step: 13
Training loss: 1.1545931827910199
Validation loss: 2.4694429159597067

Epoch: 434| Step: 0
Training loss: 2.101636240066078
Validation loss: 2.4615164272936862

Epoch: 6| Step: 1
Training loss: 1.954400584434956
Validation loss: 2.494787128108762

Epoch: 6| Step: 2
Training loss: 2.1572619288918515
Validation loss: 2.5438812777494553

Epoch: 6| Step: 3
Training loss: 2.3035484473348395
Validation loss: 2.4986702489663175

Epoch: 6| Step: 4
Training loss: 2.484704241738802
Validation loss: 2.4727421532948095

Epoch: 6| Step: 5
Training loss: 2.0282349731535647
Validation loss: 2.46678096597328

Epoch: 6| Step: 6
Training loss: 1.5360252502770015
Validation loss: 2.5608337851838234

Epoch: 6| Step: 7
Training loss: 1.6393856635494035
Validation loss: 2.48052085593714

Epoch: 6| Step: 8
Training loss: 1.933323696814012
Validation loss: 2.5278143263896404

Epoch: 6| Step: 9
Training loss: 1.9692446980276064
Validation loss: 2.5194839863574297

Epoch: 6| Step: 10
Training loss: 2.3536782109621646
Validation loss: 2.5004877445284217

Epoch: 6| Step: 11
Training loss: 1.2063179748040933
Validation loss: 2.516226890434248

Epoch: 6| Step: 12
Training loss: 1.7974755651858485
Validation loss: 2.504076620065018

Epoch: 6| Step: 13
Training loss: 1.2597941550639293
Validation loss: 2.4981055824263425

Epoch: 435| Step: 0
Training loss: 1.5616153501522245
Validation loss: 2.4947750887304037

Epoch: 6| Step: 1
Training loss: 2.025105734996333
Validation loss: 2.5305747773947616

Epoch: 6| Step: 2
Training loss: 2.409659410208332
Validation loss: 2.495266639849568

Epoch: 6| Step: 3
Training loss: 1.9838563736949797
Validation loss: 2.487400329591579

Epoch: 6| Step: 4
Training loss: 1.887594837054584
Validation loss: 2.5023777063137307

Epoch: 6| Step: 5
Training loss: 1.988279930968681
Validation loss: 2.5218074497529828

Epoch: 6| Step: 6
Training loss: 1.8476025692519076
Validation loss: 2.522716367744902

Epoch: 6| Step: 7
Training loss: 1.64023723561164
Validation loss: 2.5320494116263714

Epoch: 6| Step: 8
Training loss: 1.4501930108357155
Validation loss: 2.526703812681684

Epoch: 6| Step: 9
Training loss: 2.2882159754181184
Validation loss: 2.482711543633952

Epoch: 6| Step: 10
Training loss: 2.3127933006896852
Validation loss: 2.528447574684313

Epoch: 6| Step: 11
Training loss: 2.237451103145015
Validation loss: 2.488807623964413

Epoch: 6| Step: 12
Training loss: 1.7350736018682742
Validation loss: 2.482614254563333

Epoch: 6| Step: 13
Training loss: 1.831781691612215
Validation loss: 2.5148742825411152

Epoch: 436| Step: 0
Training loss: 1.8889370784346948
Validation loss: 2.4981103123339117

Epoch: 6| Step: 1
Training loss: 2.2569529867418137
Validation loss: 2.5335424958081783

Epoch: 6| Step: 2
Training loss: 1.8172017642221487
Validation loss: 2.5340253512467976

Epoch: 6| Step: 3
Training loss: 2.0212149767651644
Validation loss: 2.5247301698071825

Epoch: 6| Step: 4
Training loss: 1.9356112349171326
Validation loss: 2.4705273414396878

Epoch: 6| Step: 5
Training loss: 1.3472231846354785
Validation loss: 2.528820685511571

Epoch: 6| Step: 6
Training loss: 2.150370113541765
Validation loss: 2.5025304058024584

Epoch: 6| Step: 7
Training loss: 1.0318387980496384
Validation loss: 2.491805713516365

Epoch: 6| Step: 8
Training loss: 2.864476889742292
Validation loss: 2.5130716490332636

Epoch: 6| Step: 9
Training loss: 2.262377285659051
Validation loss: 2.5076903766231458

Epoch: 6| Step: 10
Training loss: 2.0614446772244652
Validation loss: 2.474138219194696

Epoch: 6| Step: 11
Training loss: 1.3016956769532826
Validation loss: 2.4685958049861134

Epoch: 6| Step: 12
Training loss: 1.9190171245309835
Validation loss: 2.518265185777391

Epoch: 6| Step: 13
Training loss: 1.7496834196113635
Validation loss: 2.4812759487739426

Epoch: 437| Step: 0
Training loss: 1.812935349369539
Validation loss: 2.4600122950046805

Epoch: 6| Step: 1
Training loss: 1.9252854767203011
Validation loss: 2.4890232881597045

Epoch: 6| Step: 2
Training loss: 1.8464004087553447
Validation loss: 2.498022048668914

Epoch: 6| Step: 3
Training loss: 1.7103738770919288
Validation loss: 2.4732063232531307

Epoch: 6| Step: 4
Training loss: 1.556969582752409
Validation loss: 2.477018556106906

Epoch: 6| Step: 5
Training loss: 1.8290787515679185
Validation loss: 2.458038519577392

Epoch: 6| Step: 6
Training loss: 1.8335452463035402
Validation loss: 2.4887562343805505

Epoch: 6| Step: 7
Training loss: 1.9435549230290783
Validation loss: 2.4968569040172124

Epoch: 6| Step: 8
Training loss: 1.5744525745235478
Validation loss: 2.5201429024794626

Epoch: 6| Step: 9
Training loss: 2.8180480488998416
Validation loss: 2.4895906520768025

Epoch: 6| Step: 10
Training loss: 2.1604425333719113
Validation loss: 2.497998714299465

Epoch: 6| Step: 11
Training loss: 1.990530005184068
Validation loss: 2.509620820845354

Epoch: 6| Step: 12
Training loss: 1.9990890335628697
Validation loss: 2.512767885665296

Epoch: 6| Step: 13
Training loss: 1.6385404877396708
Validation loss: 2.4929205475086844

Epoch: 438| Step: 0
Training loss: 2.4632451938902444
Validation loss: 2.4623071711113353

Epoch: 6| Step: 1
Training loss: 2.070618229010669
Validation loss: 2.4627452996553756

Epoch: 6| Step: 2
Training loss: 1.6565231241995055
Validation loss: 2.564486240290957

Epoch: 6| Step: 3
Training loss: 2.000662098010011
Validation loss: 2.451406641631732

Epoch: 6| Step: 4
Training loss: 1.4134349378840494
Validation loss: 2.4922657981091736

Epoch: 6| Step: 5
Training loss: 1.5592232486986033
Validation loss: 2.506096500547367

Epoch: 6| Step: 6
Training loss: 2.3889401551100575
Validation loss: 2.4575821818880836

Epoch: 6| Step: 7
Training loss: 1.4592848625364672
Validation loss: 2.487177470789923

Epoch: 6| Step: 8
Training loss: 2.2535428658338486
Validation loss: 2.512307344340871

Epoch: 6| Step: 9
Training loss: 2.1817144997843636
Validation loss: 2.481688267602459

Epoch: 6| Step: 10
Training loss: 1.8770548686735256
Validation loss: 2.496522799712781

Epoch: 6| Step: 11
Training loss: 2.227978065643001
Validation loss: 2.495052378400995

Epoch: 6| Step: 12
Training loss: 1.810466678164202
Validation loss: 2.5406984269951134

Epoch: 6| Step: 13
Training loss: 1.162099424688231
Validation loss: 2.526023458895804

Epoch: 439| Step: 0
Training loss: 1.8951135114225077
Validation loss: 2.495438182260145

Epoch: 6| Step: 1
Training loss: 1.6411002061272502
Validation loss: 2.4906828821410687

Epoch: 6| Step: 2
Training loss: 1.1889234845058712
Validation loss: 2.5357416413970557

Epoch: 6| Step: 3
Training loss: 1.7858750379958475
Validation loss: 2.5013099112516333

Epoch: 6| Step: 4
Training loss: 2.3329143034381437
Validation loss: 2.4910743972366367

Epoch: 6| Step: 5
Training loss: 1.7160674922892867
Validation loss: 2.511286950317081

Epoch: 6| Step: 6
Training loss: 1.7974300688190687
Validation loss: 2.5352640242043125

Epoch: 6| Step: 7
Training loss: 1.6627319460955365
Validation loss: 2.5054953965414732

Epoch: 6| Step: 8
Training loss: 2.1927976491924546
Validation loss: 2.5316257749853532

Epoch: 6| Step: 9
Training loss: 2.194808956513259
Validation loss: 2.5116968901757595

Epoch: 6| Step: 10
Training loss: 2.227741130274805
Validation loss: 2.5254905661937412

Epoch: 6| Step: 11
Training loss: 2.3232958588207238
Validation loss: 2.4823381893882392

Epoch: 6| Step: 12
Training loss: 1.7483220912013093
Validation loss: 2.49591027523557

Epoch: 6| Step: 13
Training loss: 2.2091073053424393
Validation loss: 2.445783928022096

Epoch: 440| Step: 0
Training loss: 2.2738787560395495
Validation loss: 2.49263447706454

Epoch: 6| Step: 1
Training loss: 1.7998348902105001
Validation loss: 2.4780088200814627

Epoch: 6| Step: 2
Training loss: 1.9508002522023928
Validation loss: 2.4936437722301616

Epoch: 6| Step: 3
Training loss: 1.6693358346678628
Validation loss: 2.5248199539623473

Epoch: 6| Step: 4
Training loss: 1.8568500717682834
Validation loss: 2.5089461854833686

Epoch: 6| Step: 5
Training loss: 1.7496992261452442
Validation loss: 2.4628937154515995

Epoch: 6| Step: 6
Training loss: 2.1312360701567203
Validation loss: 2.5338546172350314

Epoch: 6| Step: 7
Training loss: 2.2910832673971004
Validation loss: 2.51437066205131

Epoch: 6| Step: 8
Training loss: 1.873295899703859
Validation loss: 2.5104647784004843

Epoch: 6| Step: 9
Training loss: 2.157433116136917
Validation loss: 2.509458010002945

Epoch: 6| Step: 10
Training loss: 1.9439390918467736
Validation loss: 2.5276559948522213

Epoch: 6| Step: 11
Training loss: 2.0731892877730704
Validation loss: 2.514806370803863

Epoch: 6| Step: 12
Training loss: 1.5860994754252375
Validation loss: 2.515049995994183

Epoch: 6| Step: 13
Training loss: 2.06488373306712
Validation loss: 2.50108704570355

Epoch: 441| Step: 0
Training loss: 1.6081577623560752
Validation loss: 2.5077313546213045

Epoch: 6| Step: 1
Training loss: 1.5925465696463352
Validation loss: 2.499247444874706

Epoch: 6| Step: 2
Training loss: 2.318468382151908
Validation loss: 2.5205645525132896

Epoch: 6| Step: 3
Training loss: 2.0193902857446027
Validation loss: 2.502866402021538

Epoch: 6| Step: 4
Training loss: 2.297614257594795
Validation loss: 2.481766151136549

Epoch: 6| Step: 5
Training loss: 1.7210069576479652
Validation loss: 2.5021196608538463

Epoch: 6| Step: 6
Training loss: 1.6033421003190547
Validation loss: 2.48164559047987

Epoch: 6| Step: 7
Training loss: 3.0967069424356417
Validation loss: 2.543992367067706

Epoch: 6| Step: 8
Training loss: 1.5716776062202729
Validation loss: 2.4950497279898896

Epoch: 6| Step: 9
Training loss: 2.0063098078574457
Validation loss: 2.504767217493338

Epoch: 6| Step: 10
Training loss: 1.977340243670649
Validation loss: 2.469172505821279

Epoch: 6| Step: 11
Training loss: 1.2925029733944602
Validation loss: 2.507465067455032

Epoch: 6| Step: 12
Training loss: 1.68915540243846
Validation loss: 2.4870956083532567

Epoch: 6| Step: 13
Training loss: 2.276180330034601
Validation loss: 2.4893542003355575

Epoch: 442| Step: 0
Training loss: 1.706759782587929
Validation loss: 2.5254705827378947

Epoch: 6| Step: 1
Training loss: 1.1456610925860893
Validation loss: 2.516517392725452

Epoch: 6| Step: 2
Training loss: 1.344352055011983
Validation loss: 2.471590159455485

Epoch: 6| Step: 3
Training loss: 2.1752246302221407
Validation loss: 2.4957010284805317

Epoch: 6| Step: 4
Training loss: 2.0680563094996893
Validation loss: 2.4864076304374434

Epoch: 6| Step: 5
Training loss: 1.6553738993988376
Validation loss: 2.520760659133253

Epoch: 6| Step: 6
Training loss: 2.2992123499064103
Validation loss: 2.4742558036333064

Epoch: 6| Step: 7
Training loss: 2.189653372135919
Validation loss: 2.441854147632681

Epoch: 6| Step: 8
Training loss: 2.1944243782939483
Validation loss: 2.5090825041745908

Epoch: 6| Step: 9
Training loss: 2.5815120757945613
Validation loss: 2.4988335595473887

Epoch: 6| Step: 10
Training loss: 1.9378768800456794
Validation loss: 2.537650493962257

Epoch: 6| Step: 11
Training loss: 1.6863655232870196
Validation loss: 2.528446806133714

Epoch: 6| Step: 12
Training loss: 1.6684552450284922
Validation loss: 2.5257656286998453

Epoch: 6| Step: 13
Training loss: 1.3689311216873083
Validation loss: 2.4738575490080192

Epoch: 443| Step: 0
Training loss: 1.5930642541353928
Validation loss: 2.4939935578064873

Epoch: 6| Step: 1
Training loss: 1.5392250711003197
Validation loss: 2.5232019330042124

Epoch: 6| Step: 2
Training loss: 1.8777280670498113
Validation loss: 2.5180034299369987

Epoch: 6| Step: 3
Training loss: 1.4118256132109697
Validation loss: 2.4945922774624654

Epoch: 6| Step: 4
Training loss: 1.8503501560713427
Validation loss: 2.5259886174181165

Epoch: 6| Step: 5
Training loss: 1.891965595718884
Validation loss: 2.534013625766745

Epoch: 6| Step: 6
Training loss: 2.166656041730603
Validation loss: 2.4981953331785434

Epoch: 6| Step: 7
Training loss: 2.0868776181670996
Validation loss: 2.5368360780673282

Epoch: 6| Step: 8
Training loss: 2.576881802531647
Validation loss: 2.5429015941096926

Epoch: 6| Step: 9
Training loss: 2.400714501676697
Validation loss: 2.536603985884224

Epoch: 6| Step: 10
Training loss: 1.5535281665459784
Validation loss: 2.518458825818244

Epoch: 6| Step: 11
Training loss: 1.8999473313510453
Validation loss: 2.528994883591159

Epoch: 6| Step: 12
Training loss: 2.1860619313924525
Validation loss: 2.5104194293549256

Epoch: 6| Step: 13
Training loss: 2.206941693944906
Validation loss: 2.496462738568065

Epoch: 444| Step: 0
Training loss: 1.9395644971326933
Validation loss: 2.513157709674336

Epoch: 6| Step: 1
Training loss: 2.2479787860969016
Validation loss: 2.49980728267998

Epoch: 6| Step: 2
Training loss: 1.212055404007351
Validation loss: 2.4890424137582046

Epoch: 6| Step: 3
Training loss: 2.4392413252793252
Validation loss: 2.461137604671727

Epoch: 6| Step: 4
Training loss: 1.7473206444684306
Validation loss: 2.4918826347465863

Epoch: 6| Step: 5
Training loss: 1.2985556868876444
Validation loss: 2.5646618763417846

Epoch: 6| Step: 6
Training loss: 1.4475766155410663
Validation loss: 2.477722711909387

Epoch: 6| Step: 7
Training loss: 1.9573424923645253
Validation loss: 2.487954914447376

Epoch: 6| Step: 8
Training loss: 1.7809414512696204
Validation loss: 2.5132733808486813

Epoch: 6| Step: 9
Training loss: 2.375375216107418
Validation loss: 2.5091594505546184

Epoch: 6| Step: 10
Training loss: 1.7750835425905056
Validation loss: 2.5156978509242442

Epoch: 6| Step: 11
Training loss: 2.153353750094692
Validation loss: 2.5577055435760094

Epoch: 6| Step: 12
Training loss: 2.4584242809304415
Validation loss: 2.5037002743679877

Epoch: 6| Step: 13
Training loss: 1.9150933428691812
Validation loss: 2.514582168210857

Epoch: 445| Step: 0
Training loss: 2.171042413094306
Validation loss: 2.5264452715961343

Epoch: 6| Step: 1
Training loss: 1.7322260972866594
Validation loss: 2.4989267424538153

Epoch: 6| Step: 2
Training loss: 2.181038823876669
Validation loss: 2.4781992937893875

Epoch: 6| Step: 3
Training loss: 1.2514111183234704
Validation loss: 2.504592197218618

Epoch: 6| Step: 4
Training loss: 1.9655430423407028
Validation loss: 2.5078209520453805

Epoch: 6| Step: 5
Training loss: 2.270454783486921
Validation loss: 2.4380285995645052

Epoch: 6| Step: 6
Training loss: 2.58643015983028
Validation loss: 2.527876128312874

Epoch: 6| Step: 7
Training loss: 1.669640875480764
Validation loss: 2.4769896233432247

Epoch: 6| Step: 8
Training loss: 2.075201056977343
Validation loss: 2.5108491483100113

Epoch: 6| Step: 9
Training loss: 1.0108148963318166
Validation loss: 2.486656524615857

Epoch: 6| Step: 10
Training loss: 1.9199310644013297
Validation loss: 2.4547249257374237

Epoch: 6| Step: 11
Training loss: 1.8781997081858324
Validation loss: 2.513454280561024

Epoch: 6| Step: 12
Training loss: 2.083874085501241
Validation loss: 2.5134304540169885

Epoch: 6| Step: 13
Training loss: 2.059176339044809
Validation loss: 2.5400962614510005

Epoch: 446| Step: 0
Training loss: 2.0400678122226226
Validation loss: 2.5297772858006384

Epoch: 6| Step: 1
Training loss: 1.2324223586382272
Validation loss: 2.4456825326275053

Epoch: 6| Step: 2
Training loss: 1.9541280993442705
Validation loss: 2.5261053106276052

Epoch: 6| Step: 3
Training loss: 2.195375597715609
Validation loss: 2.5124636049776794

Epoch: 6| Step: 4
Training loss: 1.9949127107420577
Validation loss: 2.508914081350992

Epoch: 6| Step: 5
Training loss: 2.9803132382840256
Validation loss: 2.4933448542375403

Epoch: 6| Step: 6
Training loss: 2.380626438628163
Validation loss: 2.488801257107094

Epoch: 6| Step: 7
Training loss: 1.3439951384745956
Validation loss: 2.5231169927550363

Epoch: 6| Step: 8
Training loss: 1.4587438096517378
Validation loss: 2.4869408725925077

Epoch: 6| Step: 9
Training loss: 2.1187852974711205
Validation loss: 2.508378910082207

Epoch: 6| Step: 10
Training loss: 1.8178610605459424
Validation loss: 2.495733288199502

Epoch: 6| Step: 11
Training loss: 1.7625580203198692
Validation loss: 2.529437885161759

Epoch: 6| Step: 12
Training loss: 1.1068809304921237
Validation loss: 2.4739358490125647

Epoch: 6| Step: 13
Training loss: 2.0516818149151006
Validation loss: 2.4896542132336235

Epoch: 447| Step: 0
Training loss: 2.1917356627691444
Validation loss: 2.4719811184795843

Epoch: 6| Step: 1
Training loss: 1.7824843964823376
Validation loss: 2.486646484087015

Epoch: 6| Step: 2
Training loss: 2.3321553617387116
Validation loss: 2.5328047988206794

Epoch: 6| Step: 3
Training loss: 2.7438515507494294
Validation loss: 2.4935128178468897

Epoch: 6| Step: 4
Training loss: 1.8205102641196882
Validation loss: 2.4768816505922397

Epoch: 6| Step: 5
Training loss: 1.2504782715396432
Validation loss: 2.4980036476119984

Epoch: 6| Step: 6
Training loss: 2.342828391393829
Validation loss: 2.5611343516451717

Epoch: 6| Step: 7
Training loss: 2.0602454376299795
Validation loss: 2.50800935840681

Epoch: 6| Step: 8
Training loss: 1.7874886865858035
Validation loss: 2.5109846714737025

Epoch: 6| Step: 9
Training loss: 1.5143868019314808
Validation loss: 2.513602438653043

Epoch: 6| Step: 10
Training loss: 1.619247451405642
Validation loss: 2.5097148468931723

Epoch: 6| Step: 11
Training loss: 1.4912024637017751
Validation loss: 2.5125758405387577

Epoch: 6| Step: 12
Training loss: 1.6377316347483322
Validation loss: 2.492674414928097

Epoch: 6| Step: 13
Training loss: 1.809008161552748
Validation loss: 2.4921453940890497

Epoch: 448| Step: 0
Training loss: 2.0586488777900827
Validation loss: 2.5247490056245554

Epoch: 6| Step: 1
Training loss: 1.6797641470521032
Validation loss: 2.4878985518489065

Epoch: 6| Step: 2
Training loss: 1.7489829514001358
Validation loss: 2.5206305180639217

Epoch: 6| Step: 3
Training loss: 1.9844070792421196
Validation loss: 2.4926949708714647

Epoch: 6| Step: 4
Training loss: 1.5892554842062336
Validation loss: 2.5021082213077785

Epoch: 6| Step: 5
Training loss: 2.3231000500012207
Validation loss: 2.504295122471455

Epoch: 6| Step: 6
Training loss: 1.232542875368225
Validation loss: 2.5210950402530705

Epoch: 6| Step: 7
Training loss: 1.9510199838042073
Validation loss: 2.49542003028529

Epoch: 6| Step: 8
Training loss: 2.132072907373183
Validation loss: 2.458521896383154

Epoch: 6| Step: 9
Training loss: 1.4771109072214808
Validation loss: 2.5422726636141864

Epoch: 6| Step: 10
Training loss: 1.8924254994613006
Validation loss: 2.4937191378832075

Epoch: 6| Step: 11
Training loss: 1.7986238676360948
Validation loss: 2.537838921310547

Epoch: 6| Step: 12
Training loss: 2.4516846139520196
Validation loss: 2.500412039487705

Epoch: 6| Step: 13
Training loss: 2.259347994103492
Validation loss: 2.5244640062081816

Epoch: 449| Step: 0
Training loss: 1.9245454796570625
Validation loss: 2.483856483463054

Epoch: 6| Step: 1
Training loss: 2.0821436982268824
Validation loss: 2.5251292052382035

Epoch: 6| Step: 2
Training loss: 1.741134530625176
Validation loss: 2.4692185589281945

Epoch: 6| Step: 3
Training loss: 1.591236001647604
Validation loss: 2.498821270868569

Epoch: 6| Step: 4
Training loss: 1.8666365700520715
Validation loss: 2.505879798232829

Epoch: 6| Step: 5
Training loss: 1.7729504290308455
Validation loss: 2.5217637924871354

Epoch: 6| Step: 6
Training loss: 1.4733823407913378
Validation loss: 2.497645960790036

Epoch: 6| Step: 7
Training loss: 2.384929979364117
Validation loss: 2.4858208301593

Epoch: 6| Step: 8
Training loss: 2.1770887846323297
Validation loss: 2.515202252303022

Epoch: 6| Step: 9
Training loss: 1.4827526663314214
Validation loss: 2.512706758941053

Epoch: 6| Step: 10
Training loss: 2.390649832802243
Validation loss: 2.5140255491834615

Epoch: 6| Step: 11
Training loss: 2.2185884873611017
Validation loss: 2.486045762145382

Epoch: 6| Step: 12
Training loss: 1.56905850116499
Validation loss: 2.508069134865478

Epoch: 6| Step: 13
Training loss: 2.0866909309455206
Validation loss: 2.447314212124498

Epoch: 450| Step: 0
Training loss: 2.07324149751225
Validation loss: 2.4919930530501895

Epoch: 6| Step: 1
Training loss: 2.457611840187797
Validation loss: 2.473419806130194

Epoch: 6| Step: 2
Training loss: 1.42326823294878
Validation loss: 2.4752100019834975

Epoch: 6| Step: 3
Training loss: 2.020985299390568
Validation loss: 2.4939854937145665

Epoch: 6| Step: 4
Training loss: 1.9960434640421683
Validation loss: 2.4852350982410676

Epoch: 6| Step: 5
Training loss: 1.935833552712625
Validation loss: 2.4809803817538207

Epoch: 6| Step: 6
Training loss: 1.3504963898227405
Validation loss: 2.500231872080733

Epoch: 6| Step: 7
Training loss: 2.211975285438586
Validation loss: 2.464964740857686

Epoch: 6| Step: 8
Training loss: 1.5009316888776532
Validation loss: 2.514631815798756

Epoch: 6| Step: 9
Training loss: 2.0608134454347793
Validation loss: 2.526698561010454

Epoch: 6| Step: 10
Training loss: 1.9429526358665945
Validation loss: 2.425729917065308

Epoch: 6| Step: 11
Training loss: 1.1638362075720643
Validation loss: 2.4723132115088258

Epoch: 6| Step: 12
Training loss: 2.3746919934169637
Validation loss: 2.45292758192999

Epoch: 6| Step: 13
Training loss: 2.165364668970953
Validation loss: 2.5396414622516503

Epoch: 451| Step: 0
Training loss: 1.9895447199671144
Validation loss: 2.4887566247842834

Epoch: 6| Step: 1
Training loss: 1.6567599393247996
Validation loss: 2.4814158290329558

Epoch: 6| Step: 2
Training loss: 1.7927150172792972
Validation loss: 2.468129433222737

Epoch: 6| Step: 3
Training loss: 2.0638744514043648
Validation loss: 2.488096840568131

Epoch: 6| Step: 4
Training loss: 1.8223094546494123
Validation loss: 2.4525676512429793

Epoch: 6| Step: 5
Training loss: 1.561751224395824
Validation loss: 2.494390573902026

Epoch: 6| Step: 6
Training loss: 2.7265710693924254
Validation loss: 2.5290699286728535

Epoch: 6| Step: 7
Training loss: 2.0100528078116877
Validation loss: 2.5093807744639496

Epoch: 6| Step: 8
Training loss: 2.218988647521291
Validation loss: 2.4948906904643136

Epoch: 6| Step: 9
Training loss: 2.1795131381173354
Validation loss: 2.4870108193254468

Epoch: 6| Step: 10
Training loss: 1.456682833415273
Validation loss: 2.4642194358319136

Epoch: 6| Step: 11
Training loss: 1.5297667657189344
Validation loss: 2.499897578407663

Epoch: 6| Step: 12
Training loss: 1.8221801214407303
Validation loss: 2.5412981437581372

Epoch: 6| Step: 13
Training loss: 1.7063693022327895
Validation loss: 2.487989211769206

Epoch: 452| Step: 0
Training loss: 2.5077889224456302
Validation loss: 2.5301127398954386

Epoch: 6| Step: 1
Training loss: 2.112116409778256
Validation loss: 2.499266786625308

Epoch: 6| Step: 2
Training loss: 1.8019154053285091
Validation loss: 2.503503472908448

Epoch: 6| Step: 3
Training loss: 2.0940781521208662
Validation loss: 2.4601843157120244

Epoch: 6| Step: 4
Training loss: 2.0465581517647347
Validation loss: 2.4887156258772904

Epoch: 6| Step: 5
Training loss: 2.235795216595052
Validation loss: 2.51158368800682

Epoch: 6| Step: 6
Training loss: 1.7443809215591393
Validation loss: 2.5036779800076574

Epoch: 6| Step: 7
Training loss: 1.5576357084028194
Validation loss: 2.5003717740818043

Epoch: 6| Step: 8
Training loss: 1.767341994219874
Validation loss: 2.507456023258862

Epoch: 6| Step: 9
Training loss: 1.4358814083264209
Validation loss: 2.4962609971785645

Epoch: 6| Step: 10
Training loss: 2.2339645755728874
Validation loss: 2.519947242720084

Epoch: 6| Step: 11
Training loss: 2.14204727036634
Validation loss: 2.4879726479271276

Epoch: 6| Step: 12
Training loss: 1.8164772594066931
Validation loss: 2.527258643622656

Epoch: 6| Step: 13
Training loss: 0.9345587686844199
Validation loss: 2.501083581165455

Epoch: 453| Step: 0
Training loss: 1.7135983335020295
Validation loss: 2.5160912125227

Epoch: 6| Step: 1
Training loss: 2.1614017586408734
Validation loss: 2.508261938989941

Epoch: 6| Step: 2
Training loss: 1.6672545429396073
Validation loss: 2.504216658924308

Epoch: 6| Step: 3
Training loss: 2.077316241532325
Validation loss: 2.4904257578359434

Epoch: 6| Step: 4
Training loss: 1.1415299783914863
Validation loss: 2.4719516984367798

Epoch: 6| Step: 5
Training loss: 1.3812311041734802
Validation loss: 2.493030409794134

Epoch: 6| Step: 6
Training loss: 2.686968373790069
Validation loss: 2.522843363881918

Epoch: 6| Step: 7
Training loss: 2.4133187046275055
Validation loss: 2.5666817569835083

Epoch: 6| Step: 8
Training loss: 1.5969309011330999
Validation loss: 2.5143980441549343

Epoch: 6| Step: 9
Training loss: 1.5721156457484855
Validation loss: 2.4888161281897787

Epoch: 6| Step: 10
Training loss: 1.6419522684108396
Validation loss: 2.4682785940304948

Epoch: 6| Step: 11
Training loss: 1.880271114523469
Validation loss: 2.475685874127429

Epoch: 6| Step: 12
Training loss: 2.067442549399707
Validation loss: 2.533895357254957

Epoch: 6| Step: 13
Training loss: 2.481842765819726
Validation loss: 2.495713131188502

Epoch: 454| Step: 0
Training loss: 2.27525943492513
Validation loss: 2.4883072975472014

Epoch: 6| Step: 1
Training loss: 1.8185573515177567
Validation loss: 2.4774483585427745

Epoch: 6| Step: 2
Training loss: 2.5950712951980037
Validation loss: 2.475703914502854

Epoch: 6| Step: 3
Training loss: 1.2719018019493014
Validation loss: 2.499913004930503

Epoch: 6| Step: 4
Training loss: 2.007714651373021
Validation loss: 2.5010969585610394

Epoch: 6| Step: 5
Training loss: 2.194471530773968
Validation loss: 2.515784321048502

Epoch: 6| Step: 6
Training loss: 1.4857202156441112
Validation loss: 2.5050885189736074

Epoch: 6| Step: 7
Training loss: 1.3956975681077937
Validation loss: 2.4910559006055224

Epoch: 6| Step: 8
Training loss: 2.269824430927447
Validation loss: 2.516098287231931

Epoch: 6| Step: 9
Training loss: 1.7785763668794954
Validation loss: 2.496956363029827

Epoch: 6| Step: 10
Training loss: 1.4702153302473455
Validation loss: 2.4794208323595375

Epoch: 6| Step: 11
Training loss: 1.7425044160674739
Validation loss: 2.4833792044309466

Epoch: 6| Step: 12
Training loss: 2.028215459795872
Validation loss: 2.511261386127553

Epoch: 6| Step: 13
Training loss: 2.2123361214329025
Validation loss: 2.512909566252393

Epoch: 455| Step: 0
Training loss: 1.571827930633015
Validation loss: 2.5352199216595177

Epoch: 6| Step: 1
Training loss: 1.9306586289124348
Validation loss: 2.5224218005453003

Epoch: 6| Step: 2
Training loss: 1.7383699887374149
Validation loss: 2.496963809205604

Epoch: 6| Step: 3
Training loss: 2.1776960566275703
Validation loss: 2.478986516583853

Epoch: 6| Step: 4
Training loss: 1.914118863268511
Validation loss: 2.4952467903740496

Epoch: 6| Step: 5
Training loss: 1.853372453761537
Validation loss: 2.473579205843265

Epoch: 6| Step: 6
Training loss: 1.8905018537785183
Validation loss: 2.4856073686057836

Epoch: 6| Step: 7
Training loss: 2.3615160189732847
Validation loss: 2.528598834683992

Epoch: 6| Step: 8
Training loss: 1.4859335497172863
Validation loss: 2.5131998218466602

Epoch: 6| Step: 9
Training loss: 1.926805637730861
Validation loss: 2.541649868965285

Epoch: 6| Step: 10
Training loss: 1.8699053532316965
Validation loss: 2.458515105940938

Epoch: 6| Step: 11
Training loss: 2.152533604163527
Validation loss: 2.516085066521664

Epoch: 6| Step: 12
Training loss: 1.8057848743977671
Validation loss: 2.5104606048274962

Epoch: 6| Step: 13
Training loss: 2.0141515743188383
Validation loss: 2.4453976393003143

Epoch: 456| Step: 0
Training loss: 1.5631770383766854
Validation loss: 2.465309127345619

Epoch: 6| Step: 1
Training loss: 1.7808287272961245
Validation loss: 2.4911504827798105

Epoch: 6| Step: 2
Training loss: 2.0851417195116495
Validation loss: 2.5179101675092435

Epoch: 6| Step: 3
Training loss: 2.4275529813632164
Validation loss: 2.484656514745055

Epoch: 6| Step: 4
Training loss: 1.8031485465113886
Validation loss: 2.488702693894294

Epoch: 6| Step: 5
Training loss: 1.9826968448657871
Validation loss: 2.53272168982667

Epoch: 6| Step: 6
Training loss: 1.4545591926738717
Validation loss: 2.517271703014721

Epoch: 6| Step: 7
Training loss: 1.604637431967321
Validation loss: 2.531682191648435

Epoch: 6| Step: 8
Training loss: 2.6748064701983836
Validation loss: 2.4911898856423345

Epoch: 6| Step: 9
Training loss: 2.3162895289021317
Validation loss: 2.5024843239214114

Epoch: 6| Step: 10
Training loss: 1.5045888169233694
Validation loss: 2.505990101069444

Epoch: 6| Step: 11
Training loss: 1.6273702794191216
Validation loss: 2.517773286152166

Epoch: 6| Step: 12
Training loss: 1.611645920365834
Validation loss: 2.532971562251167

Epoch: 6| Step: 13
Training loss: 1.7053249744128898
Validation loss: 2.494626004638652

Epoch: 457| Step: 0
Training loss: 1.8989003563039812
Validation loss: 2.4949776417903893

Epoch: 6| Step: 1
Training loss: 1.8128858352923354
Validation loss: 2.5283894632859667

Epoch: 6| Step: 2
Training loss: 1.26377328173947
Validation loss: 2.477819930244002

Epoch: 6| Step: 3
Training loss: 2.0679238412878505
Validation loss: 2.5028396245899596

Epoch: 6| Step: 4
Training loss: 2.4999740599240163
Validation loss: 2.5131915386067063

Epoch: 6| Step: 5
Training loss: 2.07186589533904
Validation loss: 2.5129187815953204

Epoch: 6| Step: 6
Training loss: 1.8940488220738054
Validation loss: 2.481463249533559

Epoch: 6| Step: 7
Training loss: 1.81683029639458
Validation loss: 2.493231511336265

Epoch: 6| Step: 8
Training loss: 1.5512747567880982
Validation loss: 2.4613054548970674

Epoch: 6| Step: 9
Training loss: 1.3593382994860572
Validation loss: 2.4442353651710644

Epoch: 6| Step: 10
Training loss: 2.3238537413621096
Validation loss: 2.4670062767828282

Epoch: 6| Step: 11
Training loss: 2.0080074705463673
Validation loss: 2.507894044488969

Epoch: 6| Step: 12
Training loss: 1.9363298882096824
Validation loss: 2.5298180030651403

Epoch: 6| Step: 13
Training loss: 2.149235136911867
Validation loss: 2.5249883707307275

Epoch: 458| Step: 0
Training loss: 1.6810202345847156
Validation loss: 2.4454318992455066

Epoch: 6| Step: 1
Training loss: 1.0556948901676557
Validation loss: 2.4987632727826936

Epoch: 6| Step: 2
Training loss: 1.7703664800051997
Validation loss: 2.5004220329427613

Epoch: 6| Step: 3
Training loss: 2.3724567448780047
Validation loss: 2.477895813393278

Epoch: 6| Step: 4
Training loss: 1.7530135365783346
Validation loss: 2.5005627029635553

Epoch: 6| Step: 5
Training loss: 1.7396603032366258
Validation loss: 2.5288630708484696

Epoch: 6| Step: 6
Training loss: 1.415461569945879
Validation loss: 2.516692453608276

Epoch: 6| Step: 7
Training loss: 1.8511666305284171
Validation loss: 2.5110842140995233

Epoch: 6| Step: 8
Training loss: 2.0709167750207875
Validation loss: 2.5160973106206286

Epoch: 6| Step: 9
Training loss: 1.9826396653381122
Validation loss: 2.503281819339085

Epoch: 6| Step: 10
Training loss: 2.7553825587741048
Validation loss: 2.5106010064673026

Epoch: 6| Step: 11
Training loss: 1.918936677481367
Validation loss: 2.4735736092264036

Epoch: 6| Step: 12
Training loss: 1.9868015261561855
Validation loss: 2.4956244437476776

Epoch: 6| Step: 13
Training loss: 1.688376728766707
Validation loss: 2.522603343000963

Epoch: 459| Step: 0
Training loss: 1.5876142535808935
Validation loss: 2.487681712208722

Epoch: 6| Step: 1
Training loss: 2.183380607889117
Validation loss: 2.5353955597804103

Epoch: 6| Step: 2
Training loss: 1.6837761375250655
Validation loss: 2.546293005826715

Epoch: 6| Step: 3
Training loss: 2.192023803950628
Validation loss: 2.4878498649449075

Epoch: 6| Step: 4
Training loss: 1.9112208857292898
Validation loss: 2.5310732097255713

Epoch: 6| Step: 5
Training loss: 1.9103725443507684
Validation loss: 2.498624105126963

Epoch: 6| Step: 6
Training loss: 1.7083069248794447
Validation loss: 2.5013699131473066

Epoch: 6| Step: 7
Training loss: 1.5827779632445662
Validation loss: 2.520265446272302

Epoch: 6| Step: 8
Training loss: 1.863222517131528
Validation loss: 2.497151914160088

Epoch: 6| Step: 9
Training loss: 1.6506832066607544
Validation loss: 2.532664688727714

Epoch: 6| Step: 10
Training loss: 2.022454453793627
Validation loss: 2.509762320554823

Epoch: 6| Step: 11
Training loss: 2.728960005140376
Validation loss: 2.5165464241995155

Epoch: 6| Step: 12
Training loss: 1.9653391886515632
Validation loss: 2.5402070979732763

Epoch: 6| Step: 13
Training loss: 1.0083540415148073
Validation loss: 2.5356310879074293

Epoch: 460| Step: 0
Training loss: 2.4511334541622833
Validation loss: 2.4960664937053845

Epoch: 6| Step: 1
Training loss: 2.0676600324881096
Validation loss: 2.5186187462814713

Epoch: 6| Step: 2
Training loss: 2.520061206528456
Validation loss: 2.516143183941849

Epoch: 6| Step: 3
Training loss: 1.9154125201573389
Validation loss: 2.495224078352928

Epoch: 6| Step: 4
Training loss: 1.4322289562946635
Validation loss: 2.5078053870930987

Epoch: 6| Step: 5
Training loss: 1.671159323698287
Validation loss: 2.467746641837671

Epoch: 6| Step: 6
Training loss: 1.7783562427726611
Validation loss: 2.4918330771166763

Epoch: 6| Step: 7
Training loss: 2.0512354175298024
Validation loss: 2.4625192460625542

Epoch: 6| Step: 8
Training loss: 2.0651193805020323
Validation loss: 2.4807792900038486

Epoch: 6| Step: 9
Training loss: 1.4805817976091766
Validation loss: 2.4891675093049725

Epoch: 6| Step: 10
Training loss: 1.8841352446257391
Validation loss: 2.4632439678777356

Epoch: 6| Step: 11
Training loss: 2.2540164702388292
Validation loss: 2.510241754669693

Epoch: 6| Step: 12
Training loss: 1.338496072588842
Validation loss: 2.512480444585369

Epoch: 6| Step: 13
Training loss: 0.8758582606217928
Validation loss: 2.5726833974262786

Epoch: 461| Step: 0
Training loss: 2.045631322061319
Validation loss: 2.4988558027436296

Epoch: 6| Step: 1
Training loss: 1.9910492880529238
Validation loss: 2.49354050456128

Epoch: 6| Step: 2
Training loss: 1.5981866753484946
Validation loss: 2.497546369110728

Epoch: 6| Step: 3
Training loss: 2.479504495464726
Validation loss: 2.507515664662953

Epoch: 6| Step: 4
Training loss: 1.6894965899394387
Validation loss: 2.5126167980382177

Epoch: 6| Step: 5
Training loss: 1.953246334121801
Validation loss: 2.490935032602673

Epoch: 6| Step: 6
Training loss: 2.2786765018397457
Validation loss: 2.5216604279528108

Epoch: 6| Step: 7
Training loss: 2.455236316036448
Validation loss: 2.529302707123289

Epoch: 6| Step: 8
Training loss: 1.7364941271971763
Validation loss: 2.5228357222633173

Epoch: 6| Step: 9
Training loss: 1.8658515268687923
Validation loss: 2.5444608059822316

Epoch: 6| Step: 10
Training loss: 2.3070789408445327
Validation loss: 2.516340270863209

Epoch: 6| Step: 11
Training loss: 1.4170057321081204
Validation loss: 2.478957767083823

Epoch: 6| Step: 12
Training loss: 1.1760033685999263
Validation loss: 2.4538129253830943

Epoch: 6| Step: 13
Training loss: 0.8599137784740133
Validation loss: 2.508616353404119

Epoch: 462| Step: 0
Training loss: 1.4922803280701538
Validation loss: 2.4930126392801664

Epoch: 6| Step: 1
Training loss: 1.1635476324235274
Validation loss: 2.5016503373009957

Epoch: 6| Step: 2
Training loss: 2.4903888968602836
Validation loss: 2.514804790704385

Epoch: 6| Step: 3
Training loss: 1.404362110644119
Validation loss: 2.48882084690985

Epoch: 6| Step: 4
Training loss: 2.0593486176394196
Validation loss: 2.475051189459625

Epoch: 6| Step: 5
Training loss: 2.0238248829833134
Validation loss: 2.4945892530007

Epoch: 6| Step: 6
Training loss: 1.3655274694606787
Validation loss: 2.514821162525665

Epoch: 6| Step: 7
Training loss: 1.9210529585235032
Validation loss: 2.451251634359815

Epoch: 6| Step: 8
Training loss: 1.7509580442063142
Validation loss: 2.47304742922511

Epoch: 6| Step: 9
Training loss: 2.180640555774837
Validation loss: 2.4767310215643144

Epoch: 6| Step: 10
Training loss: 1.4975160058492392
Validation loss: 2.4875246621109643

Epoch: 6| Step: 11
Training loss: 1.6383925007678306
Validation loss: 2.5175714205278523

Epoch: 6| Step: 12
Training loss: 2.0729551327713076
Validation loss: 2.4652935248455563

Epoch: 6| Step: 13
Training loss: 3.4586205573860145
Validation loss: 2.5179888416998195

Epoch: 463| Step: 0
Training loss: 1.887262806925624
Validation loss: 2.5065073987444304

Epoch: 6| Step: 1
Training loss: 1.7054002595185729
Validation loss: 2.489821847666498

Epoch: 6| Step: 2
Training loss: 2.2568554813425186
Validation loss: 2.5085558071648313

Epoch: 6| Step: 3
Training loss: 1.9085575582825862
Validation loss: 2.5035073503617267

Epoch: 6| Step: 4
Training loss: 2.099253126572069
Validation loss: 2.4476747283730838

Epoch: 6| Step: 5
Training loss: 1.2616245955067171
Validation loss: 2.492441443264389

Epoch: 6| Step: 6
Training loss: 2.1419428646043506
Validation loss: 2.469462291828166

Epoch: 6| Step: 7
Training loss: 1.9621888077985643
Validation loss: 2.4752669802684615

Epoch: 6| Step: 8
Training loss: 2.55190496535019
Validation loss: 2.511950811480733

Epoch: 6| Step: 9
Training loss: 1.7906284725029047
Validation loss: 2.473255704746078

Epoch: 6| Step: 10
Training loss: 1.5521057775867324
Validation loss: 2.4781416686021602

Epoch: 6| Step: 11
Training loss: 1.6288225989508953
Validation loss: 2.5027661955461955

Epoch: 6| Step: 12
Training loss: 1.6572372085508078
Validation loss: 2.5036538576814173

Epoch: 6| Step: 13
Training loss: 1.841365306530156
Validation loss: 2.47366888990119

Epoch: 464| Step: 0
Training loss: 1.8873780166922223
Validation loss: 2.497342910589946

Epoch: 6| Step: 1
Training loss: 1.6780481189471157
Validation loss: 2.5229328859554956

Epoch: 6| Step: 2
Training loss: 2.2529942404465557
Validation loss: 2.4956554317048107

Epoch: 6| Step: 3
Training loss: 1.7932027693138888
Validation loss: 2.4948953288491196

Epoch: 6| Step: 4
Training loss: 1.540731541661843
Validation loss: 2.485332098014993

Epoch: 6| Step: 5
Training loss: 1.8201607571334109
Validation loss: 2.496652473376943

Epoch: 6| Step: 6
Training loss: 1.9943955096962789
Validation loss: 2.485288173941309

Epoch: 6| Step: 7
Training loss: 2.6666530867071874
Validation loss: 2.5018523173372613

Epoch: 6| Step: 8
Training loss: 1.4552393471924774
Validation loss: 2.5259250977216765

Epoch: 6| Step: 9
Training loss: 1.7363344413376396
Validation loss: 2.486288048074393

Epoch: 6| Step: 10
Training loss: 1.8415918165275311
Validation loss: 2.5037304036420807

Epoch: 6| Step: 11
Training loss: 2.2275100565639443
Validation loss: 2.474100858580021

Epoch: 6| Step: 12
Training loss: 1.741426036340667
Validation loss: 2.5189635046430374

Epoch: 6| Step: 13
Training loss: 2.0035404815887166
Validation loss: 2.4904128357625646

Epoch: 465| Step: 0
Training loss: 2.0996575212503035
Validation loss: 2.474982789925371

Epoch: 6| Step: 1
Training loss: 1.7761594075154858
Validation loss: 2.4952573706162107

Epoch: 6| Step: 2
Training loss: 1.4347919996554868
Validation loss: 2.503379510536883

Epoch: 6| Step: 3
Training loss: 2.086108254290895
Validation loss: 2.5166876160123826

Epoch: 6| Step: 4
Training loss: 1.958473633414124
Validation loss: 2.5365053406547045

Epoch: 6| Step: 5
Training loss: 1.657861321653508
Validation loss: 2.4759592589853456

Epoch: 6| Step: 6
Training loss: 1.8049935746012524
Validation loss: 2.480268945996571

Epoch: 6| Step: 7
Training loss: 1.6279132844479551
Validation loss: 2.497444950387104

Epoch: 6| Step: 8
Training loss: 1.4161469497292782
Validation loss: 2.4715433907443267

Epoch: 6| Step: 9
Training loss: 2.57523817794126
Validation loss: 2.47205206820982

Epoch: 6| Step: 10
Training loss: 2.7078079496544643
Validation loss: 2.481667587432275

Epoch: 6| Step: 11
Training loss: 1.7632551915546524
Validation loss: 2.4570511223162717

Epoch: 6| Step: 12
Training loss: 1.803276269871302
Validation loss: 2.47085172060515

Epoch: 6| Step: 13
Training loss: 1.0957412577094743
Validation loss: 2.4836354779295338

Epoch: 466| Step: 0
Training loss: 1.6211921386275905
Validation loss: 2.4378881963082635

Epoch: 6| Step: 1
Training loss: 2.501229365395719
Validation loss: 2.490072768531355

Epoch: 6| Step: 2
Training loss: 1.5584756524414907
Validation loss: 2.4524274379915623

Epoch: 6| Step: 3
Training loss: 1.8408700465761694
Validation loss: 2.5116461791827276

Epoch: 6| Step: 4
Training loss: 1.3349673669376994
Validation loss: 2.5761453057345896

Epoch: 6| Step: 5
Training loss: 1.497739280345227
Validation loss: 2.4873631310720725

Epoch: 6| Step: 6
Training loss: 1.8760164684556988
Validation loss: 2.4975644430177972

Epoch: 6| Step: 7
Training loss: 2.200376053661477
Validation loss: 2.505954323256941

Epoch: 6| Step: 8
Training loss: 1.8787180594180297
Validation loss: 2.4941947204508796

Epoch: 6| Step: 9
Training loss: 1.4109226162654547
Validation loss: 2.450768469574297

Epoch: 6| Step: 10
Training loss: 2.3944948078512636
Validation loss: 2.5308862118623625

Epoch: 6| Step: 11
Training loss: 2.054468875756018
Validation loss: 2.499964865570933

Epoch: 6| Step: 12
Training loss: 2.0951672212784422
Validation loss: 2.476337370223694

Epoch: 6| Step: 13
Training loss: 2.175328425023189
Validation loss: 2.5379871862327823

Epoch: 467| Step: 0
Training loss: 1.7806599626894575
Validation loss: 2.4812865152314814

Epoch: 6| Step: 1
Training loss: 1.9139592979791076
Validation loss: 2.4953820647086626

Epoch: 6| Step: 2
Training loss: 1.7259053494347596
Validation loss: 2.5005425828322654

Epoch: 6| Step: 3
Training loss: 1.711659179096628
Validation loss: 2.5096035539473527

Epoch: 6| Step: 4
Training loss: 1.94344690787085
Validation loss: 2.5115377120120916

Epoch: 6| Step: 5
Training loss: 1.207977467235197
Validation loss: 2.5705726896538503

Epoch: 6| Step: 6
Training loss: 2.3062985753678764
Validation loss: 2.530694697318166

Epoch: 6| Step: 7
Training loss: 1.970115006764153
Validation loss: 2.5095046932293594

Epoch: 6| Step: 8
Training loss: 2.077235440188379
Validation loss: 2.55245006572417

Epoch: 6| Step: 9
Training loss: 1.473502242444846
Validation loss: 2.509364793678275

Epoch: 6| Step: 10
Training loss: 2.202266661183529
Validation loss: 2.47599521862095

Epoch: 6| Step: 11
Training loss: 2.112399271532976
Validation loss: 2.5219118649616745

Epoch: 6| Step: 12
Training loss: 1.7991835649953332
Validation loss: 2.5091491608626764

Epoch: 6| Step: 13
Training loss: 1.9979532020365431
Validation loss: 2.498791928299997

Epoch: 468| Step: 0
Training loss: 2.0062530042203948
Validation loss: 2.5185974552869905

Epoch: 6| Step: 1
Training loss: 1.8188293701891194
Validation loss: 2.4871901133354055

Epoch: 6| Step: 2
Training loss: 1.7978292833695622
Validation loss: 2.474286035531467

Epoch: 6| Step: 3
Training loss: 1.457706816380222
Validation loss: 2.5193739120529037

Epoch: 6| Step: 4
Training loss: 1.9807103478053212
Validation loss: 2.4863426788641094

Epoch: 6| Step: 5
Training loss: 2.120312176158321
Validation loss: 2.459380436960444

Epoch: 6| Step: 6
Training loss: 2.0807638981052614
Validation loss: 2.4743521366039536

Epoch: 6| Step: 7
Training loss: 2.4064141750062773
Validation loss: 2.4904209083347064

Epoch: 6| Step: 8
Training loss: 1.8910936767759658
Validation loss: 2.509145600176013

Epoch: 6| Step: 9
Training loss: 1.8352835281815987
Validation loss: 2.5188782413224686

Epoch: 6| Step: 10
Training loss: 2.419498976238781
Validation loss: 2.5064373138766745

Epoch: 6| Step: 11
Training loss: 1.165239647787187
Validation loss: 2.4953035726046005

Epoch: 6| Step: 12
Training loss: 1.7512984908018643
Validation loss: 2.439194342010448

Epoch: 6| Step: 13
Training loss: 1.505703493750725
Validation loss: 2.4752342880975995

Epoch: 469| Step: 0
Training loss: 2.402008876876246
Validation loss: 2.5050660588997102

Epoch: 6| Step: 1
Training loss: 1.4055583948593378
Validation loss: 2.5126637980429405

Epoch: 6| Step: 2
Training loss: 1.7983015948662875
Validation loss: 2.4760132758971976

Epoch: 6| Step: 3
Training loss: 1.7237115166609747
Validation loss: 2.535140525740918

Epoch: 6| Step: 4
Training loss: 1.9630132987941462
Validation loss: 2.5364626383087407

Epoch: 6| Step: 5
Training loss: 1.224287413598948
Validation loss: 2.4539160805282796

Epoch: 6| Step: 6
Training loss: 2.2544533843946404
Validation loss: 2.488285648285845

Epoch: 6| Step: 7
Training loss: 2.2374389554865646
Validation loss: 2.5494981749305725

Epoch: 6| Step: 8
Training loss: 1.83459469001207
Validation loss: 2.488734305747474

Epoch: 6| Step: 9
Training loss: 1.8833531913160517
Validation loss: 2.495844048701615

Epoch: 6| Step: 10
Training loss: 2.2090767622700582
Validation loss: 2.4462720360516568

Epoch: 6| Step: 11
Training loss: 1.7463396483820055
Validation loss: 2.4974769987054146

Epoch: 6| Step: 12
Training loss: 1.1898750847079966
Validation loss: 2.51944191130317

Epoch: 6| Step: 13
Training loss: 2.135816421928039
Validation loss: 2.525689315113631

Epoch: 470| Step: 0
Training loss: 2.274893173392522
Validation loss: 2.468993010268358

Epoch: 6| Step: 1
Training loss: 1.5251162156395377
Validation loss: 2.5172232379623205

Epoch: 6| Step: 2
Training loss: 2.1343190667571577
Validation loss: 2.496342713355647

Epoch: 6| Step: 3
Training loss: 1.6192563594229723
Validation loss: 2.548613188101588

Epoch: 6| Step: 4
Training loss: 1.384850245205198
Validation loss: 2.489706469821122

Epoch: 6| Step: 5
Training loss: 1.8423152448965865
Validation loss: 2.4847884192445546

Epoch: 6| Step: 6
Training loss: 2.674282929756126
Validation loss: 2.4862831647247012

Epoch: 6| Step: 7
Training loss: 1.6244365008557582
Validation loss: 2.5302860942027294

Epoch: 6| Step: 8
Training loss: 2.011823040379243
Validation loss: 2.537127969366709

Epoch: 6| Step: 9
Training loss: 1.9825519988851974
Validation loss: 2.5165787335198075

Epoch: 6| Step: 10
Training loss: 2.038708652472326
Validation loss: 2.500989588875713

Epoch: 6| Step: 11
Training loss: 2.1321691863330052
Validation loss: 2.475999641837493

Epoch: 6| Step: 12
Training loss: 1.7505756521300548
Validation loss: 2.4856175762916766

Epoch: 6| Step: 13
Training loss: 1.1553611431865374
Validation loss: 2.4994657366041806

Epoch: 471| Step: 0
Training loss: 1.5845271261342295
Validation loss: 2.482245554936433

Epoch: 6| Step: 1
Training loss: 1.8127713493591444
Validation loss: 2.5258932479593623

Epoch: 6| Step: 2
Training loss: 2.7017272687167346
Validation loss: 2.510811946975719

Epoch: 6| Step: 3
Training loss: 1.545370429855707
Validation loss: 2.4919392565017593

Epoch: 6| Step: 4
Training loss: 2.3740326768639624
Validation loss: 2.500302511801436

Epoch: 6| Step: 5
Training loss: 1.7505907015452093
Validation loss: 2.4840225792192294

Epoch: 6| Step: 6
Training loss: 1.8435862840284192
Validation loss: 2.4878450289709346

Epoch: 6| Step: 7
Training loss: 1.8193328578920862
Validation loss: 2.5344635185287285

Epoch: 6| Step: 8
Training loss: 1.2806408992765226
Validation loss: 2.497295101771216

Epoch: 6| Step: 9
Training loss: 2.016233367189125
Validation loss: 2.4543249788858814

Epoch: 6| Step: 10
Training loss: 2.481948050982756
Validation loss: 2.501102322414294

Epoch: 6| Step: 11
Training loss: 1.6040510986446124
Validation loss: 2.5150033657514888

Epoch: 6| Step: 12
Training loss: 1.3653108632677518
Validation loss: 2.521245140894905

Epoch: 6| Step: 13
Training loss: 1.277216167086226
Validation loss: 2.4569154696417392

Epoch: 472| Step: 0
Training loss: 2.277333490207914
Validation loss: 2.4770996219339536

Epoch: 6| Step: 1
Training loss: 1.390351729385091
Validation loss: 2.493034045941788

Epoch: 6| Step: 2
Training loss: 2.6155568067259036
Validation loss: 2.467426566824012

Epoch: 6| Step: 3
Training loss: 1.4471674382601176
Validation loss: 2.481486688770086

Epoch: 6| Step: 4
Training loss: 1.4956879625725004
Validation loss: 2.512518445655727

Epoch: 6| Step: 5
Training loss: 2.235632055973716
Validation loss: 2.5535274381885644

Epoch: 6| Step: 6
Training loss: 1.4781865468024755
Validation loss: 2.556018456675059

Epoch: 6| Step: 7
Training loss: 1.7611663019829662
Validation loss: 2.4757927900261207

Epoch: 6| Step: 8
Training loss: 1.8878106221652404
Validation loss: 2.4921569894358084

Epoch: 6| Step: 9
Training loss: 1.5796833464646185
Validation loss: 2.513460059687883

Epoch: 6| Step: 10
Training loss: 1.288615154904064
Validation loss: 2.4878798213941575

Epoch: 6| Step: 11
Training loss: 2.2527795153745864
Validation loss: 2.4639466472346565

Epoch: 6| Step: 12
Training loss: 1.9502892010762078
Validation loss: 2.52964305927704

Epoch: 6| Step: 13
Training loss: 2.236270767209307
Validation loss: 2.5176439814372955

Epoch: 473| Step: 0
Training loss: 1.4792026551216109
Validation loss: 2.496020882036993

Epoch: 6| Step: 1
Training loss: 2.6864971685147907
Validation loss: 2.501982948452275

Epoch: 6| Step: 2
Training loss: 2.3682148029357974
Validation loss: 2.512789178102884

Epoch: 6| Step: 3
Training loss: 2.2980198504700295
Validation loss: 2.5064383857944903

Epoch: 6| Step: 4
Training loss: 1.513763543091222
Validation loss: 2.499481454005305

Epoch: 6| Step: 5
Training loss: 2.375560092134647
Validation loss: 2.513076756270777

Epoch: 6| Step: 6
Training loss: 1.8133911046941815
Validation loss: 2.4562871943579094

Epoch: 6| Step: 7
Training loss: 1.7915930030524303
Validation loss: 2.4661015158993984

Epoch: 6| Step: 8
Training loss: 2.059719176178344
Validation loss: 2.504488082014747

Epoch: 6| Step: 9
Training loss: 1.763835574101112
Validation loss: 2.479160519436579

Epoch: 6| Step: 10
Training loss: 1.5370548534296953
Validation loss: 2.5279767683332968

Epoch: 6| Step: 11
Training loss: 1.639484917653039
Validation loss: 2.4730070956099643

Epoch: 6| Step: 12
Training loss: 1.3512883431978544
Validation loss: 2.4885495157582946

Epoch: 6| Step: 13
Training loss: 1.363020120440034
Validation loss: 2.470298942655377

Epoch: 474| Step: 0
Training loss: 2.003254507463688
Validation loss: 2.498994387113201

Epoch: 6| Step: 1
Training loss: 1.4815088810417956
Validation loss: 2.497752269750702

Epoch: 6| Step: 2
Training loss: 1.6338871244106619
Validation loss: 2.487433260721475

Epoch: 6| Step: 3
Training loss: 1.8406198083775203
Validation loss: 2.4925075575842675

Epoch: 6| Step: 4
Training loss: 1.587105006541259
Validation loss: 2.4949668312239504

Epoch: 6| Step: 5
Training loss: 1.8092054481982645
Validation loss: 2.4543975566307545

Epoch: 6| Step: 6
Training loss: 2.4399237686506052
Validation loss: 2.5022282719482374

Epoch: 6| Step: 7
Training loss: 1.4472330066541865
Validation loss: 2.5044585524906973

Epoch: 6| Step: 8
Training loss: 2.1606235102261326
Validation loss: 2.5232833530254597

Epoch: 6| Step: 9
Training loss: 1.7388517322301196
Validation loss: 2.449441374121802

Epoch: 6| Step: 10
Training loss: 1.8812516576816696
Validation loss: 2.4935351254698848

Epoch: 6| Step: 11
Training loss: 1.6930131217236235
Validation loss: 2.5168977428695114

Epoch: 6| Step: 12
Training loss: 1.9576756069490822
Validation loss: 2.513946166634573

Epoch: 6| Step: 13
Training loss: 2.4835215128148693
Validation loss: 2.522918446634545

Epoch: 475| Step: 0
Training loss: 1.248836261721567
Validation loss: 2.534687725451788

Epoch: 6| Step: 1
Training loss: 1.5547078960365162
Validation loss: 2.517810266519294

Epoch: 6| Step: 2
Training loss: 1.9246796403325845
Validation loss: 2.492819023887744

Epoch: 6| Step: 3
Training loss: 2.3002833813779455
Validation loss: 2.5149519722003033

Epoch: 6| Step: 4
Training loss: 1.961857310224771
Validation loss: 2.538297090605417

Epoch: 6| Step: 5
Training loss: 1.414466842251949
Validation loss: 2.5783505915004343

Epoch: 6| Step: 6
Training loss: 2.236876254810153
Validation loss: 2.5507932682561716

Epoch: 6| Step: 7
Training loss: 2.497992949690387
Validation loss: 2.520357364828682

Epoch: 6| Step: 8
Training loss: 1.323133040427607
Validation loss: 2.488709390123447

Epoch: 6| Step: 9
Training loss: 2.1394642376711235
Validation loss: 2.476796232439473

Epoch: 6| Step: 10
Training loss: 2.1066579768850677
Validation loss: 2.5130182894354283

Epoch: 6| Step: 11
Training loss: 1.6630021419683392
Validation loss: 2.475988133899617

Epoch: 6| Step: 12
Training loss: 1.5444094342137
Validation loss: 2.522446393844355

Epoch: 6| Step: 13
Training loss: 1.76536598668819
Validation loss: 2.5009512896205277

Epoch: 476| Step: 0
Training loss: 1.745519488157843
Validation loss: 2.4796392214992986

Epoch: 6| Step: 1
Training loss: 1.5966506442073756
Validation loss: 2.472250148157202

Epoch: 6| Step: 2
Training loss: 2.1735125618539373
Validation loss: 2.4910170698917247

Epoch: 6| Step: 3
Training loss: 2.405367602767477
Validation loss: 2.5075007184057174

Epoch: 6| Step: 4
Training loss: 1.3765810632915398
Validation loss: 2.5211736740354316

Epoch: 6| Step: 5
Training loss: 1.8472227592116923
Validation loss: 2.506416760173012

Epoch: 6| Step: 6
Training loss: 1.6286110004359442
Validation loss: 2.4901436918099495

Epoch: 6| Step: 7
Training loss: 1.6033148134527377
Validation loss: 2.5180652471441367

Epoch: 6| Step: 8
Training loss: 1.5041955446692372
Validation loss: 2.4695416083879715

Epoch: 6| Step: 9
Training loss: 1.969527499760133
Validation loss: 2.4827766831322107

Epoch: 6| Step: 10
Training loss: 2.177834984888669
Validation loss: 2.50265682108256

Epoch: 6| Step: 11
Training loss: 2.0249902371771675
Validation loss: 2.4974049019857665

Epoch: 6| Step: 12
Training loss: 1.4743868830494264
Validation loss: 2.4470118284887965

Epoch: 6| Step: 13
Training loss: 2.268456104253249
Validation loss: 2.494800350189425

Epoch: 477| Step: 0
Training loss: 2.0265316668939146
Validation loss: 2.496373330141585

Epoch: 6| Step: 1
Training loss: 1.556339325696747
Validation loss: 2.5101885202810825

Epoch: 6| Step: 2
Training loss: 2.7084173531826656
Validation loss: 2.527075826651011

Epoch: 6| Step: 3
Training loss: 1.1895596561424948
Validation loss: 2.5079618428743164

Epoch: 6| Step: 4
Training loss: 1.9605649313025866
Validation loss: 2.526741355319485

Epoch: 6| Step: 5
Training loss: 1.9136894018145765
Validation loss: 2.480529830913081

Epoch: 6| Step: 6
Training loss: 2.1077365870057476
Validation loss: 2.5357036880866266

Epoch: 6| Step: 7
Training loss: 1.81587588863334
Validation loss: 2.4918331460474255

Epoch: 6| Step: 8
Training loss: 1.2004651479432427
Validation loss: 2.50599023150259

Epoch: 6| Step: 9
Training loss: 1.7215416171859945
Validation loss: 2.5171313047671986

Epoch: 6| Step: 10
Training loss: 1.9677049800049249
Validation loss: 2.486535001491818

Epoch: 6| Step: 11
Training loss: 1.7189308764910523
Validation loss: 2.51431883140707

Epoch: 6| Step: 12
Training loss: 1.8876330448780236
Validation loss: 2.469789027006783

Epoch: 6| Step: 13
Training loss: 1.6759664081994494
Validation loss: 2.5324330068945935

Epoch: 478| Step: 0
Training loss: 2.035478738432459
Validation loss: 2.489656934260761

Epoch: 6| Step: 1
Training loss: 1.7438109493200185
Validation loss: 2.5619556820322855

Epoch: 6| Step: 2
Training loss: 1.7350519594662661
Validation loss: 2.4965095631361316

Epoch: 6| Step: 3
Training loss: 1.7707177367534257
Validation loss: 2.5459930515499147

Epoch: 6| Step: 4
Training loss: 1.656855274660048
Validation loss: 2.5331258736487032

Epoch: 6| Step: 5
Training loss: 1.462754450776757
Validation loss: 2.527048214677009

Epoch: 6| Step: 6
Training loss: 1.7607746174174805
Validation loss: 2.508211415095982

Epoch: 6| Step: 7
Training loss: 1.9796664627511007
Validation loss: 2.4508010571347842

Epoch: 6| Step: 8
Training loss: 1.815658776499272
Validation loss: 2.5162005521810595

Epoch: 6| Step: 9
Training loss: 1.6732050516089216
Validation loss: 2.5111407668465238

Epoch: 6| Step: 10
Training loss: 1.9595132343987094
Validation loss: 2.48321238529696

Epoch: 6| Step: 11
Training loss: 2.311396567533842
Validation loss: 2.541853249484687

Epoch: 6| Step: 12
Training loss: 2.6272085980271167
Validation loss: 2.456921574793873

Epoch: 6| Step: 13
Training loss: 1.2816922889813835
Validation loss: 2.5249506070863683

Epoch: 479| Step: 0
Training loss: 2.1196593322187094
Validation loss: 2.5153417670505083

Epoch: 6| Step: 1
Training loss: 1.942768010781635
Validation loss: 2.4970460411278603

Epoch: 6| Step: 2
Training loss: 1.4181504146337938
Validation loss: 2.4783516200116757

Epoch: 6| Step: 3
Training loss: 1.779286959271904
Validation loss: 2.545463204939281

Epoch: 6| Step: 4
Training loss: 2.0807527835987285
Validation loss: 2.4951528638433125

Epoch: 6| Step: 5
Training loss: 1.334400028467521
Validation loss: 2.4872396284512606

Epoch: 6| Step: 6
Training loss: 1.3909219146246161
Validation loss: 2.4964698067743085

Epoch: 6| Step: 7
Training loss: 2.658235593172854
Validation loss: 2.5095986219854374

Epoch: 6| Step: 8
Training loss: 1.7237373125855582
Validation loss: 2.521573999205207

Epoch: 6| Step: 9
Training loss: 1.6468899228543685
Validation loss: 2.4869422003153714

Epoch: 6| Step: 10
Training loss: 1.551332467074959
Validation loss: 2.4462581073290175

Epoch: 6| Step: 11
Training loss: 1.679995202557208
Validation loss: 2.524060179265257

Epoch: 6| Step: 12
Training loss: 1.909793000113806
Validation loss: 2.4623821309665277

Epoch: 6| Step: 13
Training loss: 2.4302648122159685
Validation loss: 2.5054124785602543

Epoch: 480| Step: 0
Training loss: 1.643565784763672
Validation loss: 2.4801051954657063

Epoch: 6| Step: 1
Training loss: 1.938050345736313
Validation loss: 2.49419704594463

Epoch: 6| Step: 2
Training loss: 1.6980985610358261
Validation loss: 2.546283752192572

Epoch: 6| Step: 3
Training loss: 1.289667577051226
Validation loss: 2.4920031872568313

Epoch: 6| Step: 4
Training loss: 2.0498349286120834
Validation loss: 2.50248643631217

Epoch: 6| Step: 5
Training loss: 2.0540940040390554
Validation loss: 2.5243838520685604

Epoch: 6| Step: 6
Training loss: 1.4446474761996826
Validation loss: 2.521746251903242

Epoch: 6| Step: 7
Training loss: 2.246231101438981
Validation loss: 2.5501068967080402

Epoch: 6| Step: 8
Training loss: 1.6214975612456184
Validation loss: 2.463537359833354

Epoch: 6| Step: 9
Training loss: 2.0871507638050613
Validation loss: 2.497802379639878

Epoch: 6| Step: 10
Training loss: 1.5409808136811909
Validation loss: 2.5196783222715475

Epoch: 6| Step: 11
Training loss: 2.3609470410157356
Validation loss: 2.4825270168452467

Epoch: 6| Step: 12
Training loss: 2.11869381180249
Validation loss: 2.494133012617871

Epoch: 6| Step: 13
Training loss: 2.031660889368811
Validation loss: 2.463479316749893

Epoch: 481| Step: 0
Training loss: 1.8423458506931547
Validation loss: 2.492972242022203

Epoch: 6| Step: 1
Training loss: 1.910310641487075
Validation loss: 2.547958781604053

Epoch: 6| Step: 2
Training loss: 1.6978029162288968
Validation loss: 2.5158941020150114

Epoch: 6| Step: 3
Training loss: 1.3810537328273067
Validation loss: 2.5565195580685587

Epoch: 6| Step: 4
Training loss: 1.6639521029392206
Validation loss: 2.4955414392025084

Epoch: 6| Step: 5
Training loss: 2.4204613282144867
Validation loss: 2.4907388482501274

Epoch: 6| Step: 6
Training loss: 2.6584463575804596
Validation loss: 2.485905053388144

Epoch: 6| Step: 7
Training loss: 1.5171606405220146
Validation loss: 2.49475005617357

Epoch: 6| Step: 8
Training loss: 1.6129022111428053
Validation loss: 2.453497312953296

Epoch: 6| Step: 9
Training loss: 1.4031127691266845
Validation loss: 2.489840892996796

Epoch: 6| Step: 10
Training loss: 1.1184349831283402
Validation loss: 2.4857746664349163

Epoch: 6| Step: 11
Training loss: 1.8250499195953223
Validation loss: 2.4603627669424664

Epoch: 6| Step: 12
Training loss: 2.4482746160160356
Validation loss: 2.4854900375442712

Epoch: 6| Step: 13
Training loss: 1.638368562582834
Validation loss: 2.5179425244920144

Epoch: 482| Step: 0
Training loss: 1.5175767110574976
Validation loss: 2.536798496855459

Epoch: 6| Step: 1
Training loss: 1.3668241181429064
Validation loss: 2.4800694060280937

Epoch: 6| Step: 2
Training loss: 1.8193297782789597
Validation loss: 2.463151406854612

Epoch: 6| Step: 3
Training loss: 1.3925645140080363
Validation loss: 2.486443334830029

Epoch: 6| Step: 4
Training loss: 2.4767409780793708
Validation loss: 2.5293250634713194

Epoch: 6| Step: 5
Training loss: 1.2960407377304202
Validation loss: 2.5176333455875897

Epoch: 6| Step: 6
Training loss: 2.126684194610177
Validation loss: 2.459398774667472

Epoch: 6| Step: 7
Training loss: 2.328139541887785
Validation loss: 2.466520834986478

Epoch: 6| Step: 8
Training loss: 1.538106708689112
Validation loss: 2.464030760315775

Epoch: 6| Step: 9
Training loss: 2.399245731720025
Validation loss: 2.528171054770395

Epoch: 6| Step: 10
Training loss: 1.9670200922046008
Validation loss: 2.4865398132074237

Epoch: 6| Step: 11
Training loss: 1.9329170044607251
Validation loss: 2.4883254777122636

Epoch: 6| Step: 12
Training loss: 1.5951481838211077
Validation loss: 2.506050124151418

Epoch: 6| Step: 13
Training loss: 1.2356742105829137
Validation loss: 2.480937292036688

Epoch: 483| Step: 0
Training loss: 1.7729231975119857
Validation loss: 2.558578832589588

Epoch: 6| Step: 1
Training loss: 1.5475873751770441
Validation loss: 2.50102708801713

Epoch: 6| Step: 2
Training loss: 1.8001354987749074
Validation loss: 2.5139175517952452

Epoch: 6| Step: 3
Training loss: 1.9890313972384748
Validation loss: 2.5052989494515385

Epoch: 6| Step: 4
Training loss: 1.3244109787853746
Validation loss: 2.568955082305733

Epoch: 6| Step: 5
Training loss: 2.0843176106068833
Validation loss: 2.483567683323921

Epoch: 6| Step: 6
Training loss: 1.8809067828105035
Validation loss: 2.5021142879110023

Epoch: 6| Step: 7
Training loss: 1.90266030437009
Validation loss: 2.5046984053139387

Epoch: 6| Step: 8
Training loss: 1.4384479714094724
Validation loss: 2.490822040626938

Epoch: 6| Step: 9
Training loss: 2.4402924217036106
Validation loss: 2.478019290290458

Epoch: 6| Step: 10
Training loss: 2.214055427319221
Validation loss: 2.476507540628336

Epoch: 6| Step: 11
Training loss: 1.5672001146928902
Validation loss: 2.5014647704728126

Epoch: 6| Step: 12
Training loss: 1.4588418709689503
Validation loss: 2.5070270152462

Epoch: 6| Step: 13
Training loss: 2.154629969503106
Validation loss: 2.4517111736975354

Epoch: 484| Step: 0
Training loss: 1.4312000715717363
Validation loss: 2.457687209244684

Epoch: 6| Step: 1
Training loss: 1.7813950195172639
Validation loss: 2.456334005672392

Epoch: 6| Step: 2
Training loss: 2.4638914756469834
Validation loss: 2.4874989423472864

Epoch: 6| Step: 3
Training loss: 2.1887375736809727
Validation loss: 2.5154799165584087

Epoch: 6| Step: 4
Training loss: 1.9796682692559449
Validation loss: 2.51035903893795

Epoch: 6| Step: 5
Training loss: 1.697573020499374
Validation loss: 2.4772297027829557

Epoch: 6| Step: 6
Training loss: 1.863339341255743
Validation loss: 2.455346308752075

Epoch: 6| Step: 7
Training loss: 1.4538588772885768
Validation loss: 2.466377746805452

Epoch: 6| Step: 8
Training loss: 2.007721657683212
Validation loss: 2.4663878282699554

Epoch: 6| Step: 9
Training loss: 1.8666854885832678
Validation loss: 2.491044982455071

Epoch: 6| Step: 10
Training loss: 1.5139320592917527
Validation loss: 2.4460670952604255

Epoch: 6| Step: 11
Training loss: 1.4274249074128174
Validation loss: 2.460064849855786

Epoch: 6| Step: 12
Training loss: 2.1109415524413477
Validation loss: 2.497548587297754

Epoch: 6| Step: 13
Training loss: 1.553516502850126
Validation loss: 2.4913521996410113

Epoch: 485| Step: 0
Training loss: 2.2535074234851407
Validation loss: 2.5191466793246122

Epoch: 6| Step: 1
Training loss: 1.5319111233720084
Validation loss: 2.523695707214755

Epoch: 6| Step: 2
Training loss: 1.5908986933479887
Validation loss: 2.4808828873581876

Epoch: 6| Step: 3
Training loss: 2.306828529139954
Validation loss: 2.5107555675505453

Epoch: 6| Step: 4
Training loss: 2.5517041813513526
Validation loss: 2.5047713452837734

Epoch: 6| Step: 5
Training loss: 1.5343729986422474
Validation loss: 2.5140009907779186

Epoch: 6| Step: 6
Training loss: 1.6838412711391777
Validation loss: 2.4768477946111593

Epoch: 6| Step: 7
Training loss: 2.0170013696441766
Validation loss: 2.4776407455771063

Epoch: 6| Step: 8
Training loss: 1.6543396062635305
Validation loss: 2.527937768493722

Epoch: 6| Step: 9
Training loss: 1.5364108406959647
Validation loss: 2.5053739798471

Epoch: 6| Step: 10
Training loss: 1.5889573684168623
Validation loss: 2.4837668096167365

Epoch: 6| Step: 11
Training loss: 1.5340893170640693
Validation loss: 2.504249032115148

Epoch: 6| Step: 12
Training loss: 2.2912403981808325
Validation loss: 2.504387455211977

Epoch: 6| Step: 13
Training loss: 0.7202996259022919
Validation loss: 2.5295232780061703

Epoch: 486| Step: 0
Training loss: 2.1582164919340014
Validation loss: 2.471815275109055

Epoch: 6| Step: 1
Training loss: 2.4433310771617736
Validation loss: 2.515148352330197

Epoch: 6| Step: 2
Training loss: 1.819399101074104
Validation loss: 2.4875547564527425

Epoch: 6| Step: 3
Training loss: 1.6753545186658587
Validation loss: 2.4985313388003045

Epoch: 6| Step: 4
Training loss: 2.364157875088613
Validation loss: 2.470762912737457

Epoch: 6| Step: 5
Training loss: 1.8739829802009964
Validation loss: 2.4710509674416987

Epoch: 6| Step: 6
Training loss: 1.2272636693401857
Validation loss: 2.493483698631884

Epoch: 6| Step: 7
Training loss: 1.8518736372655258
Validation loss: 2.4665832013883935

Epoch: 6| Step: 8
Training loss: 1.9378047826447506
Validation loss: 2.473370396818668

Epoch: 6| Step: 9
Training loss: 1.5499824369112305
Validation loss: 2.4968548340941603

Epoch: 6| Step: 10
Training loss: 1.8351325685183797
Validation loss: 2.4857041166411973

Epoch: 6| Step: 11
Training loss: 1.780161809638861
Validation loss: 2.4686646681036692

Epoch: 6| Step: 12
Training loss: 1.1206481260603736
Validation loss: 2.512088678540806

Epoch: 6| Step: 13
Training loss: 1.7871938216472307
Validation loss: 2.4648023949362443

Epoch: 487| Step: 0
Training loss: 1.2739247986982365
Validation loss: 2.484050265925714

Epoch: 6| Step: 1
Training loss: 1.492094506366864
Validation loss: 2.4985813822760856

Epoch: 6| Step: 2
Training loss: 1.6141460031510548
Validation loss: 2.4955697336449996

Epoch: 6| Step: 3
Training loss: 1.9028595963249115
Validation loss: 2.4975253973432445

Epoch: 6| Step: 4
Training loss: 1.7410534644684796
Validation loss: 2.495644807951408

Epoch: 6| Step: 5
Training loss: 1.8455870576724687
Validation loss: 2.5212464434349684

Epoch: 6| Step: 6
Training loss: 2.1110902946962833
Validation loss: 2.4738109143585505

Epoch: 6| Step: 7
Training loss: 1.4995614046382086
Validation loss: 2.5128774413414687

Epoch: 6| Step: 8
Training loss: 1.7169579613704236
Validation loss: 2.530699732521786

Epoch: 6| Step: 9
Training loss: 1.879071329522082
Validation loss: 2.539210646025088

Epoch: 6| Step: 10
Training loss: 1.898574259035325
Validation loss: 2.5054726843109147

Epoch: 6| Step: 11
Training loss: 1.8743200976760201
Validation loss: 2.5190715574255997

Epoch: 6| Step: 12
Training loss: 2.5941201371054663
Validation loss: 2.4860593751399165

Epoch: 6| Step: 13
Training loss: 2.0837029192845513
Validation loss: 2.4995171803653093

Epoch: 488| Step: 0
Training loss: 1.5947272352694921
Validation loss: 2.469505464461951

Epoch: 6| Step: 1
Training loss: 2.4555127617207844
Validation loss: 2.5052667888597324

Epoch: 6| Step: 2
Training loss: 1.3338595732679004
Validation loss: 2.5040883454679954

Epoch: 6| Step: 3
Training loss: 1.315150672417645
Validation loss: 2.4970718925282718

Epoch: 6| Step: 4
Training loss: 1.7216427128846616
Validation loss: 2.4839962741368833

Epoch: 6| Step: 5
Training loss: 1.5525809734070541
Validation loss: 2.484214216671342

Epoch: 6| Step: 6
Training loss: 1.7501919504888337
Validation loss: 2.5123102923692913

Epoch: 6| Step: 7
Training loss: 1.881330547952967
Validation loss: 2.4535343645571617

Epoch: 6| Step: 8
Training loss: 1.9093607550806087
Validation loss: 2.499042479384708

Epoch: 6| Step: 9
Training loss: 2.483022069518772
Validation loss: 2.5160140053511078

Epoch: 6| Step: 10
Training loss: 1.7198369144038037
Validation loss: 2.51154280858884

Epoch: 6| Step: 11
Training loss: 1.8784569343826982
Validation loss: 2.490805357704777

Epoch: 6| Step: 12
Training loss: 2.2257736147009486
Validation loss: 2.4636119435417556

Epoch: 6| Step: 13
Training loss: 0.6659056273431564
Validation loss: 2.544183702864438

Epoch: 489| Step: 0
Training loss: 1.7832019216777841
Validation loss: 2.508762537842049

Epoch: 6| Step: 1
Training loss: 1.3137592904790463
Validation loss: 2.4933984842266823

Epoch: 6| Step: 2
Training loss: 2.02205360248728
Validation loss: 2.4862461897435617

Epoch: 6| Step: 3
Training loss: 2.619427715727686
Validation loss: 2.4592397442975016

Epoch: 6| Step: 4
Training loss: 1.8648284949840148
Validation loss: 2.4952616179060865

Epoch: 6| Step: 5
Training loss: 1.920706603144254
Validation loss: 2.487679647532956

Epoch: 6| Step: 6
Training loss: 1.588228572153897
Validation loss: 2.525975502263168

Epoch: 6| Step: 7
Training loss: 1.5946612277549523
Validation loss: 2.503013255660343

Epoch: 6| Step: 8
Training loss: 1.5573562642694359
Validation loss: 2.5777625303002543

Epoch: 6| Step: 9
Training loss: 1.7874189265078573
Validation loss: 2.4987758767160555

Epoch: 6| Step: 10
Training loss: 1.5426692623708962
Validation loss: 2.498693402645839

Epoch: 6| Step: 11
Training loss: 2.074316909680068
Validation loss: 2.524894503770783

Epoch: 6| Step: 12
Training loss: 1.604838300860423
Validation loss: 2.501257979848619

Epoch: 6| Step: 13
Training loss: 1.718731342561199
Validation loss: 2.4775270914152188

Epoch: 490| Step: 0
Training loss: 1.4386508315549213
Validation loss: 2.5225917961394058

Epoch: 6| Step: 1
Training loss: 1.7210868208473415
Validation loss: 2.508389330687132

Epoch: 6| Step: 2
Training loss: 1.6216103339661567
Validation loss: 2.4564525712447636

Epoch: 6| Step: 3
Training loss: 1.6599602078643678
Validation loss: 2.4529596840886785

Epoch: 6| Step: 4
Training loss: 2.0981692462945385
Validation loss: 2.4931296543612835

Epoch: 6| Step: 5
Training loss: 2.492695914998879
Validation loss: 2.457055517033419

Epoch: 6| Step: 6
Training loss: 1.6068309193592254
Validation loss: 2.444664027920538

Epoch: 6| Step: 7
Training loss: 1.8246428100946035
Validation loss: 2.471322151304423

Epoch: 6| Step: 8
Training loss: 1.9353511337940412
Validation loss: 2.4718606774434138

Epoch: 6| Step: 9
Training loss: 1.5478483278258788
Validation loss: 2.4956842867495537

Epoch: 6| Step: 10
Training loss: 1.710585187756024
Validation loss: 2.461068342395841

Epoch: 6| Step: 11
Training loss: 2.0422928167854404
Validation loss: 2.5103934509105255

Epoch: 6| Step: 12
Training loss: 1.9770679053886087
Validation loss: 2.5050075586057683

Epoch: 6| Step: 13
Training loss: 2.23353923825822
Validation loss: 2.464983216425568

Epoch: 491| Step: 0
Training loss: 2.0967774779244346
Validation loss: 2.49441082382076

Epoch: 6| Step: 1
Training loss: 1.9338519916133496
Validation loss: 2.5339124737967507

Epoch: 6| Step: 2
Training loss: 1.6828414758651054
Validation loss: 2.5096213111773493

Epoch: 6| Step: 3
Training loss: 1.805068070879609
Validation loss: 2.569788917155522

Epoch: 6| Step: 4
Training loss: 2.1158688651195576
Validation loss: 2.4942835383823456

Epoch: 6| Step: 5
Training loss: 1.5828727085603336
Validation loss: 2.5151780325719755

Epoch: 6| Step: 6
Training loss: 1.8060330745756517
Validation loss: 2.50936725018476

Epoch: 6| Step: 7
Training loss: 1.4889101316745907
Validation loss: 2.5136806520615607

Epoch: 6| Step: 8
Training loss: 2.257291951610041
Validation loss: 2.499077431872957

Epoch: 6| Step: 9
Training loss: 1.7208002519852983
Validation loss: 2.4568392880460403

Epoch: 6| Step: 10
Training loss: 1.3509647613182023
Validation loss: 2.5017054186067753

Epoch: 6| Step: 11
Training loss: 2.1186439600152456
Validation loss: 2.523448630525269

Epoch: 6| Step: 12
Training loss: 1.5824053286758744
Validation loss: 2.484199044566027

Epoch: 6| Step: 13
Training loss: 1.8464337230019172
Validation loss: 2.4490586294049432

Epoch: 492| Step: 0
Training loss: 1.769988415674782
Validation loss: 2.4963702801100665

Epoch: 6| Step: 1
Training loss: 2.484724967826614
Validation loss: 2.513345260034754

Epoch: 6| Step: 2
Training loss: 1.7274305828186067
Validation loss: 2.4574596784639087

Epoch: 6| Step: 3
Training loss: 1.6826813741475468
Validation loss: 2.499886958325047

Epoch: 6| Step: 4
Training loss: 2.0356721132733506
Validation loss: 2.533349550291895

Epoch: 6| Step: 5
Training loss: 2.117185022556784
Validation loss: 2.5132932164779653

Epoch: 6| Step: 6
Training loss: 1.1718281037165963
Validation loss: 2.523368513217763

Epoch: 6| Step: 7
Training loss: 1.6513485628292568
Validation loss: 2.535788540349119

Epoch: 6| Step: 8
Training loss: 2.592933894075711
Validation loss: 2.489640744491644

Epoch: 6| Step: 9
Training loss: 1.8984032773045456
Validation loss: 2.5199576978914107

Epoch: 6| Step: 10
Training loss: 1.3974472034560532
Validation loss: 2.5333732168180894

Epoch: 6| Step: 11
Training loss: 1.1875583232812013
Validation loss: 2.5029737956697633

Epoch: 6| Step: 12
Training loss: 1.803350043839308
Validation loss: 2.5168193411714976

Epoch: 6| Step: 13
Training loss: 2.037744322561911
Validation loss: 2.4294993859241494

Epoch: 493| Step: 0
Training loss: 1.739167062746864
Validation loss: 2.5101377686021

Epoch: 6| Step: 1
Training loss: 1.3695115744640285
Validation loss: 2.4848526490130913

Epoch: 6| Step: 2
Training loss: 1.73798427831038
Validation loss: 2.4950316836449957

Epoch: 6| Step: 3
Training loss: 2.0449224579526986
Validation loss: 2.440891570413467

Epoch: 6| Step: 4
Training loss: 1.485350438906955
Validation loss: 2.4893118971706847

Epoch: 6| Step: 5
Training loss: 1.2657094856602973
Validation loss: 2.497668744191902

Epoch: 6| Step: 6
Training loss: 2.4691635944279966
Validation loss: 2.5286607472040648

Epoch: 6| Step: 7
Training loss: 1.9598807720977884
Validation loss: 2.521064660395885

Epoch: 6| Step: 8
Training loss: 1.5423078835913684
Validation loss: 2.505888231220802

Epoch: 6| Step: 9
Training loss: 1.6573448880719392
Validation loss: 2.4985655253141292

Epoch: 6| Step: 10
Training loss: 1.3970394285231635
Validation loss: 2.5264474106300696

Epoch: 6| Step: 11
Training loss: 3.1521587482985525
Validation loss: 2.502512264293981

Epoch: 6| Step: 12
Training loss: 1.3710674924591326
Validation loss: 2.536365496637498

Epoch: 6| Step: 13
Training loss: 1.4861524681128055
Validation loss: 2.471099708327438

Epoch: 494| Step: 0
Training loss: 1.9683230709203543
Validation loss: 2.520196129539619

Epoch: 6| Step: 1
Training loss: 1.8150670518916234
Validation loss: 2.4618791072182136

Epoch: 6| Step: 2
Training loss: 2.0395458130962054
Validation loss: 2.444466048187457

Epoch: 6| Step: 3
Training loss: 1.634965052683232
Validation loss: 2.52921360005637

Epoch: 6| Step: 4
Training loss: 2.1172487594919764
Validation loss: 2.5361286569071875

Epoch: 6| Step: 5
Training loss: 1.480188911985286
Validation loss: 2.473533454165472

Epoch: 6| Step: 6
Training loss: 2.7754155371968663
Validation loss: 2.458335380768866

Epoch: 6| Step: 7
Training loss: 1.6807384662904818
Validation loss: 2.5141670977169115

Epoch: 6| Step: 8
Training loss: 1.5803290357699586
Validation loss: 2.5131521420308753

Epoch: 6| Step: 9
Training loss: 1.7270094349155576
Validation loss: 2.4808553182420106

Epoch: 6| Step: 10
Training loss: 1.7823583266788405
Validation loss: 2.5025302552128057

Epoch: 6| Step: 11
Training loss: 1.3125614878465892
Validation loss: 2.5108342596741857

Epoch: 6| Step: 12
Training loss: 1.0453855252382078
Validation loss: 2.483722270036635

Epoch: 6| Step: 13
Training loss: 1.8023420673655182
Validation loss: 2.440032799996391

Epoch: 495| Step: 0
Training loss: 1.5961389775153738
Validation loss: 2.4515536702005414

Epoch: 6| Step: 1
Training loss: 1.9497766709208737
Validation loss: 2.4794807676309767

Epoch: 6| Step: 2
Training loss: 1.2158425202696952
Validation loss: 2.5247174471738254

Epoch: 6| Step: 3
Training loss: 2.0150263880665413
Validation loss: 2.5239475864544234

Epoch: 6| Step: 4
Training loss: 2.25471532306172
Validation loss: 2.5158260593512205

Epoch: 6| Step: 5
Training loss: 1.4174798800539168
Validation loss: 2.523587448108175

Epoch: 6| Step: 6
Training loss: 2.172809866172964
Validation loss: 2.5253222570250577

Epoch: 6| Step: 7
Training loss: 1.2646836912919275
Validation loss: 2.5093852266922014

Epoch: 6| Step: 8
Training loss: 1.5339953665731747
Validation loss: 2.5140979524074414

Epoch: 6| Step: 9
Training loss: 2.8151595362823896
Validation loss: 2.541173952404755

Epoch: 6| Step: 10
Training loss: 1.9111431669287078
Validation loss: 2.529063102614333

Epoch: 6| Step: 11
Training loss: 1.9402616569209177
Validation loss: 2.491946409038039

Epoch: 6| Step: 12
Training loss: 1.5500428101565038
Validation loss: 2.4763926832804026

Epoch: 6| Step: 13
Training loss: 1.0978952602396392
Validation loss: 2.5053810177965903

Epoch: 496| Step: 0
Training loss: 2.563426338793722
Validation loss: 2.5025820442015734

Epoch: 6| Step: 1
Training loss: 1.3806124065717613
Validation loss: 2.522419400963114

Epoch: 6| Step: 2
Training loss: 2.028204409979948
Validation loss: 2.4980621815914477

Epoch: 6| Step: 3
Training loss: 1.2502818743466708
Validation loss: 2.4864149478742927

Epoch: 6| Step: 4
Training loss: 1.5846085265319596
Validation loss: 2.4275690862187265

Epoch: 6| Step: 5
Training loss: 1.3563761902918965
Validation loss: 2.522620267868694

Epoch: 6| Step: 6
Training loss: 2.3214558568336057
Validation loss: 2.470640167377129

Epoch: 6| Step: 7
Training loss: 1.8659467205688014
Validation loss: 2.4621762852210667

Epoch: 6| Step: 8
Training loss: 1.1463415521565745
Validation loss: 2.4655737974212184

Epoch: 6| Step: 9
Training loss: 2.5511059401050282
Validation loss: 2.538773261698148

Epoch: 6| Step: 10
Training loss: 1.1624326624902703
Validation loss: 2.503615715916278

Epoch: 6| Step: 11
Training loss: 1.7313176606655891
Validation loss: 2.4430308994954344

Epoch: 6| Step: 12
Training loss: 1.6335364384132296
Validation loss: 2.442611500006912

Epoch: 6| Step: 13
Training loss: 1.7777105937952185
Validation loss: 2.4928612767931844

Epoch: 497| Step: 0
Training loss: 1.5201926863408224
Validation loss: 2.457893302653224

Epoch: 6| Step: 1
Training loss: 1.4654029694279411
Validation loss: 2.555751050681295

Epoch: 6| Step: 2
Training loss: 2.0463106964561035
Validation loss: 2.4918092922935937

Epoch: 6| Step: 3
Training loss: 2.161410803827637
Validation loss: 2.476895917370283

Epoch: 6| Step: 4
Training loss: 1.6833022854399862
Validation loss: 2.512140789402552

Epoch: 6| Step: 5
Training loss: 1.3039023498147697
Validation loss: 2.498314571349433

Epoch: 6| Step: 6
Training loss: 1.7838328859122596
Validation loss: 2.4704283065059127

Epoch: 6| Step: 7
Training loss: 2.0812858693007494
Validation loss: 2.4998275587127394

Epoch: 6| Step: 8
Training loss: 1.4894326229370172
Validation loss: 2.4745760867340674

Epoch: 6| Step: 9
Training loss: 1.8721798350852683
Validation loss: 2.5223532367430246

Epoch: 6| Step: 10
Training loss: 2.4122179014679825
Validation loss: 2.537736037776655

Epoch: 6| Step: 11
Training loss: 1.6336588878953622
Validation loss: 2.4928834035948757

Epoch: 6| Step: 12
Training loss: 2.071193752227236
Validation loss: 2.5221027590670206

Epoch: 6| Step: 13
Training loss: 1.410773736483983
Validation loss: 2.514176135105928

Epoch: 498| Step: 0
Training loss: 1.6280903408000418
Validation loss: 2.5627581008438227

Epoch: 6| Step: 1
Training loss: 1.9195979204969833
Validation loss: 2.5137531192713864

Epoch: 6| Step: 2
Training loss: 1.4125205637692444
Validation loss: 2.5102004142435743

Epoch: 6| Step: 3
Training loss: 2.527702860251842
Validation loss: 2.516607783641337

Epoch: 6| Step: 4
Training loss: 2.2036506620922363
Validation loss: 2.509504546122935

Epoch: 6| Step: 5
Training loss: 1.4243020105010418
Validation loss: 2.5169441791217353

Epoch: 6| Step: 6
Training loss: 1.651172556537445
Validation loss: 2.564031182002296

Epoch: 6| Step: 7
Training loss: 1.7549838895139789
Validation loss: 2.4609350847400715

Epoch: 6| Step: 8
Training loss: 2.1145126506348513
Validation loss: 2.482266043874261

Epoch: 6| Step: 9
Training loss: 1.3438364932589917
Validation loss: 2.519555545914547

Epoch: 6| Step: 10
Training loss: 1.8176188041550454
Validation loss: 2.4715657893011325

Epoch: 6| Step: 11
Training loss: 1.4668770881186122
Validation loss: 2.524021100118226

Epoch: 6| Step: 12
Training loss: 1.908808257907038
Validation loss: 2.500896282938238

Epoch: 6| Step: 13
Training loss: 1.9961083816619132
Validation loss: 2.5184050627294807

Epoch: 499| Step: 0
Training loss: 1.788420316222679
Validation loss: 2.4690290713623746

Epoch: 6| Step: 1
Training loss: 0.9628150399585318
Validation loss: 2.533425763669777

Epoch: 6| Step: 2
Training loss: 1.9898376368895656
Validation loss: 2.4938750484946857

Epoch: 6| Step: 3
Training loss: 2.6446211333333345
Validation loss: 2.5147732891752588

Epoch: 6| Step: 4
Training loss: 1.8719865106601996
Validation loss: 2.5051454301615754

Epoch: 6| Step: 5
Training loss: 1.8298674536475863
Validation loss: 2.459419129237073

Epoch: 6| Step: 6
Training loss: 1.672804672020509
Validation loss: 2.508618924589037

Epoch: 6| Step: 7
Training loss: 1.506062020249462
Validation loss: 2.5098765885009633

Epoch: 6| Step: 8
Training loss: 1.6011485983838118
Validation loss: 2.4649535251339674

Epoch: 6| Step: 9
Training loss: 1.9096557335887134
Validation loss: 2.49248178124109

Epoch: 6| Step: 10
Training loss: 2.2811390052861724
Validation loss: 2.5035311044320654

Epoch: 6| Step: 11
Training loss: 1.5568888046406073
Validation loss: 2.4823272674915775

Epoch: 6| Step: 12
Training loss: 1.6920778557786516
Validation loss: 2.5266172104578555

Epoch: 6| Step: 13
Training loss: 2.1416703616257595
Validation loss: 2.4927705647257543

Epoch: 500| Step: 0
Training loss: 2.2144217383447775
Validation loss: 2.4998811796110814

Epoch: 6| Step: 1
Training loss: 1.8645387001307532
Validation loss: 2.4742941109852423

Epoch: 6| Step: 2
Training loss: 1.0255294851103147
Validation loss: 2.525507883842786

Epoch: 6| Step: 3
Training loss: 2.320184466493371
Validation loss: 2.5252083113629014

Epoch: 6| Step: 4
Training loss: 1.2061990381257566
Validation loss: 2.42731115384643

Epoch: 6| Step: 5
Training loss: 1.617658758376137
Validation loss: 2.473069525978697

Epoch: 6| Step: 6
Training loss: 1.847922307994651
Validation loss: 2.4773637060395295

Epoch: 6| Step: 7
Training loss: 1.6973093815157627
Validation loss: 2.4960166154972465

Epoch: 6| Step: 8
Training loss: 1.9841394359712583
Validation loss: 2.4934548633597546

Epoch: 6| Step: 9
Training loss: 1.4521091971518123
Validation loss: 2.432594478794931

Epoch: 6| Step: 10
Training loss: 1.7999474835682057
Validation loss: 2.50044658374045

Epoch: 6| Step: 11
Training loss: 2.3097073988121184
Validation loss: 2.503332712573381

Epoch: 6| Step: 12
Training loss: 1.6429305089834545
Validation loss: 2.468272735083282

Epoch: 6| Step: 13
Training loss: 1.2414058889360906
Validation loss: 2.5242671122854734

Epoch: 501| Step: 0
Training loss: 2.0885853624093405
Validation loss: 2.4877520657714443

Epoch: 6| Step: 1
Training loss: 2.057095237400268
Validation loss: 2.5092485372314117

Epoch: 6| Step: 2
Training loss: 0.8992209625879769
Validation loss: 2.481184074385883

Epoch: 6| Step: 3
Training loss: 2.095481498212424
Validation loss: 2.520482336748175

Epoch: 6| Step: 4
Training loss: 1.5353704016800718
Validation loss: 2.5002436683202918

Epoch: 6| Step: 5
Training loss: 2.3294196913239222
Validation loss: 2.500828501101604

Epoch: 6| Step: 6
Training loss: 1.6796271734715456
Validation loss: 2.5346546274401263

Epoch: 6| Step: 7
Training loss: 2.0950388571110503
Validation loss: 2.553506354931423

Epoch: 6| Step: 8
Training loss: 1.9573517496964603
Validation loss: 2.5045330307522553

Epoch: 6| Step: 9
Training loss: 1.4015208090340712
Validation loss: 2.4883780784889855

Epoch: 6| Step: 10
Training loss: 2.2936748606668464
Validation loss: 2.518122184725639

Epoch: 6| Step: 11
Training loss: 1.402928222587508
Validation loss: 2.5141213586288123

Epoch: 6| Step: 12
Training loss: 1.50888213330459
Validation loss: 2.4485618758605803

Epoch: 6| Step: 13
Training loss: 1.1796393984657336
Validation loss: 2.477642343169442

Epoch: 502| Step: 0
Training loss: 2.466658466772248
Validation loss: 2.480188893886654

Epoch: 6| Step: 1
Training loss: 1.6045621739434246
Validation loss: 2.534175146815155

Epoch: 6| Step: 2
Training loss: 1.896284224440862
Validation loss: 2.5066494301179563

Epoch: 6| Step: 3
Training loss: 1.8738162436554933
Validation loss: 2.491512832052197

Epoch: 6| Step: 4
Training loss: 1.7274419003555528
Validation loss: 2.496458111310774

Epoch: 6| Step: 5
Training loss: 1.51611249496759
Validation loss: 2.4767176140013842

Epoch: 6| Step: 6
Training loss: 1.77664056638306
Validation loss: 2.5314928634851244

Epoch: 6| Step: 7
Training loss: 1.6389413823415366
Validation loss: 2.503611504302357

Epoch: 6| Step: 8
Training loss: 1.9401169607948179
Validation loss: 2.486648455287579

Epoch: 6| Step: 9
Training loss: 1.5526440864079627
Validation loss: 2.4786629175799235

Epoch: 6| Step: 10
Training loss: 1.5138707184162876
Validation loss: 2.4939283782276966

Epoch: 6| Step: 11
Training loss: 1.8108502476419097
Validation loss: 2.50205453312366

Epoch: 6| Step: 12
Training loss: 1.877196424198545
Validation loss: 2.4717522555793296

Epoch: 6| Step: 13
Training loss: 1.808054767488067
Validation loss: 2.506195793376808

Epoch: 503| Step: 0
Training loss: 1.8043335406485752
Validation loss: 2.4349963079866166

Epoch: 6| Step: 1
Training loss: 2.0491703354951465
Validation loss: 2.503441246974769

Epoch: 6| Step: 2
Training loss: 2.047620098983985
Validation loss: 2.530076314253543

Epoch: 6| Step: 3
Training loss: 1.7409339808611821
Validation loss: 2.507803060417822

Epoch: 6| Step: 4
Training loss: 1.4379883641500402
Validation loss: 2.4924911950216777

Epoch: 6| Step: 5
Training loss: 1.6020130547171365
Validation loss: 2.475058053650154

Epoch: 6| Step: 6
Training loss: 1.4268654241587284
Validation loss: 2.5399371381303926

Epoch: 6| Step: 7
Training loss: 1.7463676357309241
Validation loss: 2.5301539251956644

Epoch: 6| Step: 8
Training loss: 1.5063175043831996
Validation loss: 2.5512197982761675

Epoch: 6| Step: 9
Training loss: 2.3097334112601198
Validation loss: 2.557642384578423

Epoch: 6| Step: 10
Training loss: 2.1623754432395947
Validation loss: 2.4425493827047333

Epoch: 6| Step: 11
Training loss: 1.126215331277496
Validation loss: 2.545994946594317

Epoch: 6| Step: 12
Training loss: 1.7104842051446119
Validation loss: 2.5134320247806987

Epoch: 6| Step: 13
Training loss: 2.752845765587413
Validation loss: 2.5139637239105714

Epoch: 504| Step: 0
Training loss: 1.5320671392474898
Validation loss: 2.5365946170616915

Epoch: 6| Step: 1
Training loss: 1.2010881100111905
Validation loss: 2.4953478946821415

Epoch: 6| Step: 2
Training loss: 1.4411335508840826
Validation loss: 2.4883110250791187

Epoch: 6| Step: 3
Training loss: 2.546646575981635
Validation loss: 2.471430888707971

Epoch: 6| Step: 4
Training loss: 1.1951597028820318
Validation loss: 2.500858030434032

Epoch: 6| Step: 5
Training loss: 1.8276464373864965
Validation loss: 2.4421759408145522

Epoch: 6| Step: 6
Training loss: 1.7646688387292615
Validation loss: 2.524657004270066

Epoch: 6| Step: 7
Training loss: 1.4785161087660206
Validation loss: 2.4975062699851884

Epoch: 6| Step: 8
Training loss: 2.4892610689832564
Validation loss: 2.4683404730532454

Epoch: 6| Step: 9
Training loss: 1.790460032375188
Validation loss: 2.5187428242998426

Epoch: 6| Step: 10
Training loss: 1.4908234917941503
Validation loss: 2.49844976167164

Epoch: 6| Step: 11
Training loss: 1.9903826747219984
Validation loss: 2.4813369560921226

Epoch: 6| Step: 12
Training loss: 1.9680165938088734
Validation loss: 2.5346435208383857

Epoch: 6| Step: 13
Training loss: 1.6419385465443133
Validation loss: 2.491036014489873

Epoch: 505| Step: 0
Training loss: 2.39760871012254
Validation loss: 2.486009817954272

Epoch: 6| Step: 1
Training loss: 1.705139228975643
Validation loss: 2.4749009918134837

Epoch: 6| Step: 2
Training loss: 1.4953502271590506
Validation loss: 2.483307666760171

Epoch: 6| Step: 3
Training loss: 1.8400119453539996
Validation loss: 2.4776117486833047

Epoch: 6| Step: 4
Training loss: 1.9517631971211873
Validation loss: 2.487488270360547

Epoch: 6| Step: 5
Training loss: 1.7024809993406225
Validation loss: 2.4652910343013827

Epoch: 6| Step: 6
Training loss: 1.5394398183182196
Validation loss: 2.530477352455896

Epoch: 6| Step: 7
Training loss: 2.017491976735022
Validation loss: 2.5111667692075965

Epoch: 6| Step: 8
Training loss: 1.789490427870409
Validation loss: 2.513833455323059

Epoch: 6| Step: 9
Training loss: 2.1714350851757187
Validation loss: 2.4729542435629885

Epoch: 6| Step: 10
Training loss: 2.132003015741502
Validation loss: 2.506657315400187

Epoch: 6| Step: 11
Training loss: 1.1540894297751108
Validation loss: 2.495301776219057

Epoch: 6| Step: 12
Training loss: 1.5670992490769433
Validation loss: 2.4951047376995517

Epoch: 6| Step: 13
Training loss: 1.1034671198894528
Validation loss: 2.500341652525872

Epoch: 506| Step: 0
Training loss: 1.9063394244121679
Validation loss: 2.515612588509288

Epoch: 6| Step: 1
Training loss: 1.4756388525371191
Validation loss: 2.4868331968565696

Epoch: 6| Step: 2
Training loss: 1.5148478609750335
Validation loss: 2.473023907928285

Epoch: 6| Step: 3
Training loss: 2.3867473194766156
Validation loss: 2.483985852342892

Epoch: 6| Step: 4
Training loss: 2.03578384299702
Validation loss: 2.542187102029662

Epoch: 6| Step: 5
Training loss: 1.6232206432908065
Validation loss: 2.553922164941134

Epoch: 6| Step: 6
Training loss: 1.3476831405831675
Validation loss: 2.4725100511911298

Epoch: 6| Step: 7
Training loss: 1.9089452731329546
Validation loss: 2.510780099500129

Epoch: 6| Step: 8
Training loss: 1.898426825096981
Validation loss: 2.4906362568234504

Epoch: 6| Step: 9
Training loss: 1.7762591395723504
Validation loss: 2.5048098358600885

Epoch: 6| Step: 10
Training loss: 2.2927331234742683
Validation loss: 2.5230242907317515

Epoch: 6| Step: 11
Training loss: 1.4588986618009707
Validation loss: 2.5448421697827928

Epoch: 6| Step: 12
Training loss: 1.7882913984991498
Validation loss: 2.561704156378056

Epoch: 6| Step: 13
Training loss: 1.6448775626767818
Validation loss: 2.480237539437205

Epoch: 507| Step: 0
Training loss: 1.7593488972490894
Validation loss: 2.500499932744767

Epoch: 6| Step: 1
Training loss: 1.8895375300544128
Validation loss: 2.5291205477719214

Epoch: 6| Step: 2
Training loss: 2.2154270056750605
Validation loss: 2.51055853542434

Epoch: 6| Step: 3
Training loss: 1.7735738155725767
Validation loss: 2.4684400165258498

Epoch: 6| Step: 4
Training loss: 1.3669957489695443
Validation loss: 2.512286282521092

Epoch: 6| Step: 5
Training loss: 2.4556704393135806
Validation loss: 2.518589204303894

Epoch: 6| Step: 6
Training loss: 1.7992657223399222
Validation loss: 2.4684800529635913

Epoch: 6| Step: 7
Training loss: 1.0498409105305937
Validation loss: 2.4953057296011467

Epoch: 6| Step: 8
Training loss: 1.4343921402715347
Validation loss: 2.5464302448214093

Epoch: 6| Step: 9
Training loss: 1.9273508109654176
Validation loss: 2.4980810799455706

Epoch: 6| Step: 10
Training loss: 1.9214537864525654
Validation loss: 2.4743683481823395

Epoch: 6| Step: 11
Training loss: 1.528724612058745
Validation loss: 2.5377127705648883

Epoch: 6| Step: 12
Training loss: 1.767952928796794
Validation loss: 2.4842266890590823

Epoch: 6| Step: 13
Training loss: 1.8051627057783146
Validation loss: 2.5190508971621743

Epoch: 508| Step: 0
Training loss: 1.402034714844475
Validation loss: 2.515718318100329

Epoch: 6| Step: 1
Training loss: 2.066327560455304
Validation loss: 2.5046087893317366

Epoch: 6| Step: 2
Training loss: 1.3564000077505514
Validation loss: 2.5108140350026322

Epoch: 6| Step: 3
Training loss: 1.3716604251804547
Validation loss: 2.509008304009601

Epoch: 6| Step: 4
Training loss: 2.7669128178247453
Validation loss: 2.470387146628767

Epoch: 6| Step: 5
Training loss: 1.8485400805865455
Validation loss: 2.5083013275424464

Epoch: 6| Step: 6
Training loss: 2.0765137126349504
Validation loss: 2.524651314746839

Epoch: 6| Step: 7
Training loss: 1.530058104963805
Validation loss: 2.5562698116778844

Epoch: 6| Step: 8
Training loss: 1.1857463034198814
Validation loss: 2.5368895516108854

Epoch: 6| Step: 9
Training loss: 2.1009567125047113
Validation loss: 2.51824614417771

Epoch: 6| Step: 10
Training loss: 1.6001451128480912
Validation loss: 2.5592630883077394

Epoch: 6| Step: 11
Training loss: 1.6494058232753808
Validation loss: 2.542396146874553

Epoch: 6| Step: 12
Training loss: 1.3752434688372117
Validation loss: 2.5154168163777717

Epoch: 6| Step: 13
Training loss: 2.34051952251726
Validation loss: 2.453556696603019

Epoch: 509| Step: 0
Training loss: 2.196560759338132
Validation loss: 2.458066712763007

Epoch: 6| Step: 1
Training loss: 1.5685285617123683
Validation loss: 2.4778284742498076

Epoch: 6| Step: 2
Training loss: 1.2986615755381523
Validation loss: 2.5131207261317696

Epoch: 6| Step: 3
Training loss: 1.4966120606438722
Validation loss: 2.4684535936764527

Epoch: 6| Step: 4
Training loss: 1.3821953727261642
Validation loss: 2.439591454190748

Epoch: 6| Step: 5
Training loss: 1.6555986383167538
Validation loss: 2.4233056676616704

Epoch: 6| Step: 6
Training loss: 2.188611429425898
Validation loss: 2.4714621867538296

Epoch: 6| Step: 7
Training loss: 1.658116782089327
Validation loss: 2.4985212392808855

Epoch: 6| Step: 8
Training loss: 1.8257723937433967
Validation loss: 2.485123662195978

Epoch: 6| Step: 9
Training loss: 2.1477864336651886
Validation loss: 2.4427579822283443

Epoch: 6| Step: 10
Training loss: 1.6298368800635339
Validation loss: 2.5311181740392152

Epoch: 6| Step: 11
Training loss: 1.867236276412464
Validation loss: 2.4825551074793273

Epoch: 6| Step: 12
Training loss: 1.9000160969504059
Validation loss: 2.4973500512427935

Epoch: 6| Step: 13
Training loss: 1.6448255262056566
Validation loss: 2.459182645383499

Epoch: 510| Step: 0
Training loss: 1.5569058794154509
Validation loss: 2.5068392314854333

Epoch: 6| Step: 1
Training loss: 1.835974834955325
Validation loss: 2.4428764715867635

Epoch: 6| Step: 2
Training loss: 1.8919486464452815
Validation loss: 2.479191196148299

Epoch: 6| Step: 3
Training loss: 1.611638671542441
Validation loss: 2.5390529564866653

Epoch: 6| Step: 4
Training loss: 2.1768644913434265
Validation loss: 2.4920599148032805

Epoch: 6| Step: 5
Training loss: 1.6690488083446933
Validation loss: 2.50651927539979

Epoch: 6| Step: 6
Training loss: 1.6671093909030632
Validation loss: 2.4859883497763082

Epoch: 6| Step: 7
Training loss: 1.5555101834598088
Validation loss: 2.4699913082855836

Epoch: 6| Step: 8
Training loss: 1.9039624355761868
Validation loss: 2.497975242189528

Epoch: 6| Step: 9
Training loss: 1.343376196389621
Validation loss: 2.4620167334811707

Epoch: 6| Step: 10
Training loss: 2.469707255139043
Validation loss: 2.4358495610095012

Epoch: 6| Step: 11
Training loss: 1.404229641340802
Validation loss: 2.515953119507169

Epoch: 6| Step: 12
Training loss: 1.8798352520363544
Validation loss: 2.4884623109761046

Epoch: 6| Step: 13
Training loss: 1.358203075848881
Validation loss: 2.445807916728205

Epoch: 511| Step: 0
Training loss: 1.8214791288224632
Validation loss: 2.496822729532194

Epoch: 6| Step: 1
Training loss: 1.779788572206084
Validation loss: 2.536859501871675

Epoch: 6| Step: 2
Training loss: 1.909763163118108
Validation loss: 2.509022686465849

Epoch: 6| Step: 3
Training loss: 1.6873092543563037
Validation loss: 2.4718827339867486

Epoch: 6| Step: 4
Training loss: 1.4109126463736235
Validation loss: 2.4469614668713904

Epoch: 6| Step: 5
Training loss: 1.5277636797090732
Validation loss: 2.5138867175645943

Epoch: 6| Step: 6
Training loss: 2.2565345183220997
Validation loss: 2.4724794201565876

Epoch: 6| Step: 7
Training loss: 2.3350902028600875
Validation loss: 2.518139198760074

Epoch: 6| Step: 8
Training loss: 1.839818869258517
Validation loss: 2.5381439087089848

Epoch: 6| Step: 9
Training loss: 2.0409406292292225
Validation loss: 2.47510889281363

Epoch: 6| Step: 10
Training loss: 1.520123520776308
Validation loss: 2.534707690351021

Epoch: 6| Step: 11
Training loss: 1.6808807392965628
Validation loss: 2.521332402473907

Epoch: 6| Step: 12
Training loss: 1.216892685646572
Validation loss: 2.4948263605006282

Epoch: 6| Step: 13
Training loss: 1.511557084934077
Validation loss: 2.4512219006742595

Epoch: 512| Step: 0
Training loss: 1.4232384987504945
Validation loss: 2.449593423253417

Epoch: 6| Step: 1
Training loss: 2.258719608543639
Validation loss: 2.4838428439455367

Epoch: 6| Step: 2
Training loss: 1.6189141385435097
Validation loss: 2.5007624847759544

Epoch: 6| Step: 3
Training loss: 2.0126749377304476
Validation loss: 2.5064586304310486

Epoch: 6| Step: 4
Training loss: 1.4247027773162468
Validation loss: 2.4942274924963694

Epoch: 6| Step: 5
Training loss: 1.4384546841513408
Validation loss: 2.490287651957496

Epoch: 6| Step: 6
Training loss: 1.5934429994986854
Validation loss: 2.5214054377481268

Epoch: 6| Step: 7
Training loss: 1.7135215997728723
Validation loss: 2.4824776628078764

Epoch: 6| Step: 8
Training loss: 1.2886833789377874
Validation loss: 2.50119941508706

Epoch: 6| Step: 9
Training loss: 1.3439288353017316
Validation loss: 2.537128039087749

Epoch: 6| Step: 10
Training loss: 1.635297718298391
Validation loss: 2.495909054483498

Epoch: 6| Step: 11
Training loss: 2.8507460169916143
Validation loss: 2.5278345722409776

Epoch: 6| Step: 12
Training loss: 1.4107932556702811
Validation loss: 2.5332777377743865

Epoch: 6| Step: 13
Training loss: 2.0313090389181494
Validation loss: 2.4945912600598343

Epoch: 513| Step: 0
Training loss: 2.242011830961402
Validation loss: 2.484011922742761

Epoch: 6| Step: 1
Training loss: 1.6514561210159697
Validation loss: 2.4449054057166704

Epoch: 6| Step: 2
Training loss: 1.9131729238614787
Validation loss: 2.4895941861551494

Epoch: 6| Step: 3
Training loss: 1.0285327833159188
Validation loss: 2.4742411745278257

Epoch: 6| Step: 4
Training loss: 1.9708200501309523
Validation loss: 2.4548333498178967

Epoch: 6| Step: 5
Training loss: 1.3020380495462203
Validation loss: 2.5337783398609015

Epoch: 6| Step: 6
Training loss: 2.319764968542577
Validation loss: 2.4486074031205316

Epoch: 6| Step: 7
Training loss: 1.58478523074898
Validation loss: 2.480780637558826

Epoch: 6| Step: 8
Training loss: 1.6701365193512996
Validation loss: 2.449468716460626

Epoch: 6| Step: 9
Training loss: 1.675252693245833
Validation loss: 2.510660383747053

Epoch: 6| Step: 10
Training loss: 2.3153312465893743
Validation loss: 2.4453850747539776

Epoch: 6| Step: 11
Training loss: 1.8400908545163621
Validation loss: 2.4621739716531055

Epoch: 6| Step: 12
Training loss: 1.4179858162013188
Validation loss: 2.48021222268042

Epoch: 6| Step: 13
Training loss: 1.6396789002670111
Validation loss: 2.5265533148987056

Epoch: 514| Step: 0
Training loss: 2.0946739777053556
Validation loss: 2.474097154195011

Epoch: 6| Step: 1
Training loss: 0.8379821016043558
Validation loss: 2.465239931315117

Epoch: 6| Step: 2
Training loss: 1.9096763335600488
Validation loss: 2.4730644776197623

Epoch: 6| Step: 3
Training loss: 1.9723353965356938
Validation loss: 2.457842827095546

Epoch: 6| Step: 4
Training loss: 1.9119990222481498
Validation loss: 2.5183230533581282

Epoch: 6| Step: 5
Training loss: 2.070920689337445
Validation loss: 2.5693940337768923

Epoch: 6| Step: 6
Training loss: 1.7421935213951436
Validation loss: 2.523984791228898

Epoch: 6| Step: 7
Training loss: 1.7639843229907692
Validation loss: 2.5296939010076507

Epoch: 6| Step: 8
Training loss: 1.5835907208225992
Validation loss: 2.522510180008303

Epoch: 6| Step: 9
Training loss: 2.675640464476048
Validation loss: 2.562651100776032

Epoch: 6| Step: 10
Training loss: 1.02233262154109
Validation loss: 2.508648494048107

Epoch: 6| Step: 11
Training loss: 1.4155366074205329
Validation loss: 2.5263685401664175

Epoch: 6| Step: 12
Training loss: 1.7257194014070127
Validation loss: 2.5631490506189842

Epoch: 6| Step: 13
Training loss: 1.9779767792961611
Validation loss: 2.524703486676676

Epoch: 515| Step: 0
Training loss: 2.670087785456399
Validation loss: 2.5145031702693736

Epoch: 6| Step: 1
Training loss: 1.2595984532824966
Validation loss: 2.4859154403232773

Epoch: 6| Step: 2
Training loss: 1.803356522054357
Validation loss: 2.512431141209677

Epoch: 6| Step: 3
Training loss: 1.571519454272476
Validation loss: 2.4600202141008056

Epoch: 6| Step: 4
Training loss: 1.6404075841803245
Validation loss: 2.4903389594973864

Epoch: 6| Step: 5
Training loss: 1.4638559494961394
Validation loss: 2.5457719792005977

Epoch: 6| Step: 6
Training loss: 1.4963412167335872
Validation loss: 2.4556605278641768

Epoch: 6| Step: 7
Training loss: 1.7495806736603001
Validation loss: 2.4937447215315918

Epoch: 6| Step: 8
Training loss: 1.5485233810428412
Validation loss: 2.4958745460354144

Epoch: 6| Step: 9
Training loss: 1.699001675475284
Validation loss: 2.53977071396574

Epoch: 6| Step: 10
Training loss: 1.7225413727463135
Validation loss: 2.4906433374474535

Epoch: 6| Step: 11
Training loss: 2.1334701474347177
Validation loss: 2.4508764740275453

Epoch: 6| Step: 12
Training loss: 1.8551482556264887
Validation loss: 2.4865605611112525

Epoch: 6| Step: 13
Training loss: 1.6726657031530223
Validation loss: 2.4734637160524855

Epoch: 516| Step: 0
Training loss: 2.8417112986470667
Validation loss: 2.4717203238540186

Epoch: 6| Step: 1
Training loss: 1.5874148849137402
Validation loss: 2.460532547017164

Epoch: 6| Step: 2
Training loss: 1.9655812511821482
Validation loss: 2.4877474583798747

Epoch: 6| Step: 3
Training loss: 1.2162678212882212
Validation loss: 2.4974962489525225

Epoch: 6| Step: 4
Training loss: 1.1400445480175494
Validation loss: 2.457162948311527

Epoch: 6| Step: 5
Training loss: 1.5013147790862216
Validation loss: 2.511654588727038

Epoch: 6| Step: 6
Training loss: 1.974288053998178
Validation loss: 2.509484998258519

Epoch: 6| Step: 7
Training loss: 1.2238495582240332
Validation loss: 2.4688325512231892

Epoch: 6| Step: 8
Training loss: 1.679664931034787
Validation loss: 2.476982392945709

Epoch: 6| Step: 9
Training loss: 2.0046773100049133
Validation loss: 2.5194415083560853

Epoch: 6| Step: 10
Training loss: 2.128208206947605
Validation loss: 2.436659793012758

Epoch: 6| Step: 11
Training loss: 1.4801498512492985
Validation loss: 2.509269608202138

Epoch: 6| Step: 12
Training loss: 1.7240262973753469
Validation loss: 2.507872813736478

Epoch: 6| Step: 13
Training loss: 1.7804307894239964
Validation loss: 2.4910439708076404

Epoch: 517| Step: 0
Training loss: 1.347910406500043
Validation loss: 2.5621743804435377

Epoch: 6| Step: 1
Training loss: 2.071869117417766
Validation loss: 2.4925022019771843

Epoch: 6| Step: 2
Training loss: 1.4922236892545913
Validation loss: 2.4724302471274817

Epoch: 6| Step: 3
Training loss: 1.530204104354274
Validation loss: 2.4999497408583293

Epoch: 6| Step: 4
Training loss: 2.0313413159311957
Validation loss: 2.503707512594401

Epoch: 6| Step: 5
Training loss: 1.673819151312366
Validation loss: 2.4798842050357663

Epoch: 6| Step: 6
Training loss: 1.3286938066344087
Validation loss: 2.5385420757651898

Epoch: 6| Step: 7
Training loss: 1.9850120422997315
Validation loss: 2.521345412650228

Epoch: 6| Step: 8
Training loss: 1.9090772830592457
Validation loss: 2.4882790863990505

Epoch: 6| Step: 9
Training loss: 2.3273658282720397
Validation loss: 2.554624908644871

Epoch: 6| Step: 10
Training loss: 1.6972836755773826
Validation loss: 2.4485000969341395

Epoch: 6| Step: 11
Training loss: 1.9012093108649248
Validation loss: 2.5109328638460973

Epoch: 6| Step: 12
Training loss: 1.2509537872695022
Validation loss: 2.5260614125214005

Epoch: 6| Step: 13
Training loss: 2.2166427491506293
Validation loss: 2.5192507936955018

Epoch: 518| Step: 0
Training loss: 1.7271861335275516
Validation loss: 2.5079898673752377

Epoch: 6| Step: 1
Training loss: 1.3358920797914355
Validation loss: 2.499494446120722

Epoch: 6| Step: 2
Training loss: 1.6582493500394107
Validation loss: 2.555109082651043

Epoch: 6| Step: 3
Training loss: 2.077553577306046
Validation loss: 2.5464614773029832

Epoch: 6| Step: 4
Training loss: 1.9568569082851137
Validation loss: 2.4646633556653423

Epoch: 6| Step: 5
Training loss: 1.7640184503399188
Validation loss: 2.4886388138158053

Epoch: 6| Step: 6
Training loss: 1.3662659509256434
Validation loss: 2.491326907334673

Epoch: 6| Step: 7
Training loss: 1.8736977187300827
Validation loss: 2.5156054731989603

Epoch: 6| Step: 8
Training loss: 2.334685841895367
Validation loss: 2.4878894488881813

Epoch: 6| Step: 9
Training loss: 1.2988991624722992
Validation loss: 2.5027913763484686

Epoch: 6| Step: 10
Training loss: 1.9066204273957095
Validation loss: 2.5105647929841677

Epoch: 6| Step: 11
Training loss: 1.9363452792874767
Validation loss: 2.5157206557980127

Epoch: 6| Step: 12
Training loss: 1.3366290973717185
Validation loss: 2.48291231265551

Epoch: 6| Step: 13
Training loss: 1.9403876044246064
Validation loss: 2.551991643675359

Epoch: 519| Step: 0
Training loss: 1.5284380882634865
Validation loss: 2.4971996518044954

Epoch: 6| Step: 1
Training loss: 1.0369902863889042
Validation loss: 2.527202158388286

Epoch: 6| Step: 2
Training loss: 2.218865834825653
Validation loss: 2.5064315236714614

Epoch: 6| Step: 3
Training loss: 1.3959809789810025
Validation loss: 2.5208141258712775

Epoch: 6| Step: 4
Training loss: 1.6396288799598564
Validation loss: 2.488929525384896

Epoch: 6| Step: 5
Training loss: 1.9065019409786081
Validation loss: 2.533684434291987

Epoch: 6| Step: 6
Training loss: 1.906729278347824
Validation loss: 2.4867572400425053

Epoch: 6| Step: 7
Training loss: 1.9833416388308371
Validation loss: 2.5211134690265538

Epoch: 6| Step: 8
Training loss: 1.7146318517643842
Validation loss: 2.5695667902509096

Epoch: 6| Step: 9
Training loss: 1.7948882688213466
Validation loss: 2.4818882796207955

Epoch: 6| Step: 10
Training loss: 2.220495907149895
Validation loss: 2.5216153544678463

Epoch: 6| Step: 11
Training loss: 1.5065362302194618
Validation loss: 2.5338805504121193

Epoch: 6| Step: 12
Training loss: 1.6033528067555525
Validation loss: 2.518972922757292

Epoch: 6| Step: 13
Training loss: 1.3716850201354942
Validation loss: 2.536368298445016

Epoch: 520| Step: 0
Training loss: 1.7133066157225798
Validation loss: 2.5214844421034415

Epoch: 6| Step: 1
Training loss: 1.101407736870472
Validation loss: 2.509088230022866

Epoch: 6| Step: 2
Training loss: 2.102306588764841
Validation loss: 2.5212443528629236

Epoch: 6| Step: 3
Training loss: 1.4885352210867882
Validation loss: 2.503901566876088

Epoch: 6| Step: 4
Training loss: 1.589919479778443
Validation loss: 2.5134727847357636

Epoch: 6| Step: 5
Training loss: 2.2934904528548676
Validation loss: 2.501413175626045

Epoch: 6| Step: 6
Training loss: 1.6836592446884053
Validation loss: 2.5019052464776914

Epoch: 6| Step: 7
Training loss: 2.2828986076601048
Validation loss: 2.4750539912780374

Epoch: 6| Step: 8
Training loss: 1.9276074770638145
Validation loss: 2.508708546518253

Epoch: 6| Step: 9
Training loss: 1.3952279367484721
Validation loss: 2.523567218977371

Epoch: 6| Step: 10
Training loss: 1.8501627979302835
Validation loss: 2.511443557709744

Epoch: 6| Step: 11
Training loss: 1.7180029199106897
Validation loss: 2.5104297751120757

Epoch: 6| Step: 12
Training loss: 1.2792581100997014
Validation loss: 2.4605742457771522

Epoch: 6| Step: 13
Training loss: 1.8843394692077735
Validation loss: 2.451034158582614

Epoch: 521| Step: 0
Training loss: 1.8977907437013866
Validation loss: 2.522119833664584

Epoch: 6| Step: 1
Training loss: 1.4629498662018112
Validation loss: 2.492637421619336

Epoch: 6| Step: 2
Training loss: 1.884712748205814
Validation loss: 2.5201812386492346

Epoch: 6| Step: 3
Training loss: 1.5383235493545495
Validation loss: 2.4675326457995848

Epoch: 6| Step: 4
Training loss: 1.549947134777657
Validation loss: 2.499049359745572

Epoch: 6| Step: 5
Training loss: 1.882668770650241
Validation loss: 2.5028625676194847

Epoch: 6| Step: 6
Training loss: 1.4003922423881439
Validation loss: 2.4989790277567545

Epoch: 6| Step: 7
Training loss: 1.4377989250857233
Validation loss: 2.465092735234296

Epoch: 6| Step: 8
Training loss: 1.525939530045696
Validation loss: 2.5332681491925153

Epoch: 6| Step: 9
Training loss: 1.672127820445104
Validation loss: 2.5166245583369906

Epoch: 6| Step: 10
Training loss: 2.6800043124548534
Validation loss: 2.5033898659306137

Epoch: 6| Step: 11
Training loss: 1.9846047095760617
Validation loss: 2.5184099072059434

Epoch: 6| Step: 12
Training loss: 1.6219752109858185
Validation loss: 2.4908451159634635

Epoch: 6| Step: 13
Training loss: 1.9168977252619348
Validation loss: 2.535714801165906

Epoch: 522| Step: 0
Training loss: 1.5761394284677295
Validation loss: 2.4740974940660903

Epoch: 6| Step: 1
Training loss: 1.736104154784783
Validation loss: 2.499500386757613

Epoch: 6| Step: 2
Training loss: 1.7708321814439805
Validation loss: 2.5499258525635735

Epoch: 6| Step: 3
Training loss: 1.8442405436054763
Validation loss: 2.5091098040108397

Epoch: 6| Step: 4
Training loss: 1.590330457115624
Validation loss: 2.5023816792513363

Epoch: 6| Step: 5
Training loss: 1.9205905995390058
Validation loss: 2.5082563982961963

Epoch: 6| Step: 6
Training loss: 1.249194457847963
Validation loss: 2.515305032204556

Epoch: 6| Step: 7
Training loss: 1.7693994064561174
Validation loss: 2.511349935808884

Epoch: 6| Step: 8
Training loss: 1.6616759760578952
Validation loss: 2.5109851931894434

Epoch: 6| Step: 9
Training loss: 1.5321356878325678
Validation loss: 2.5303760793860404

Epoch: 6| Step: 10
Training loss: 1.7280710111879811
Validation loss: 2.5523699638192494

Epoch: 6| Step: 11
Training loss: 1.7178776000832532
Validation loss: 2.504333757028629

Epoch: 6| Step: 12
Training loss: 2.736126758210118
Validation loss: 2.5581309080498755

Epoch: 6| Step: 13
Training loss: 1.5363453537949465
Validation loss: 2.512439275685375

Epoch: 523| Step: 0
Training loss: 2.117912365462925
Validation loss: 2.5030748859095184

Epoch: 6| Step: 1
Training loss: 1.7078015577518924
Validation loss: 2.4952198998363433

Epoch: 6| Step: 2
Training loss: 1.8367924424368196
Validation loss: 2.4663565671763608

Epoch: 6| Step: 3
Training loss: 1.2336835252348113
Validation loss: 2.5025551986773715

Epoch: 6| Step: 4
Training loss: 1.7311784998041664
Validation loss: 2.523377366274775

Epoch: 6| Step: 5
Training loss: 1.904498436848787
Validation loss: 2.4970707324036474

Epoch: 6| Step: 6
Training loss: 1.3397302162402431
Validation loss: 2.468708308490805

Epoch: 6| Step: 7
Training loss: 2.317596387124134
Validation loss: 2.5207844052049175

Epoch: 6| Step: 8
Training loss: 2.1033030963100656
Validation loss: 2.460274225464582

Epoch: 6| Step: 9
Training loss: 1.6955192193775948
Validation loss: 2.498257381411512

Epoch: 6| Step: 10
Training loss: 1.6949560959792922
Validation loss: 2.530623284075432

Epoch: 6| Step: 11
Training loss: 1.2291814943270558
Validation loss: 2.5029840083250745

Epoch: 6| Step: 12
Training loss: 1.908068680492801
Validation loss: 2.5675832011585147

Epoch: 6| Step: 13
Training loss: 1.4492039435522264
Validation loss: 2.5256716860783883

Epoch: 524| Step: 0
Training loss: 1.6090540890039502
Validation loss: 2.4977974777470027

Epoch: 6| Step: 1
Training loss: 1.60326075880687
Validation loss: 2.5024678078736105

Epoch: 6| Step: 2
Training loss: 1.2052680906066833
Validation loss: 2.540777034252093

Epoch: 6| Step: 3
Training loss: 1.307069032514022
Validation loss: 2.500452345256032

Epoch: 6| Step: 4
Training loss: 2.5630161416880917
Validation loss: 2.4901966299453386

Epoch: 6| Step: 5
Training loss: 1.7781466839747009
Validation loss: 2.4552423554058977

Epoch: 6| Step: 6
Training loss: 1.6060849977045688
Validation loss: 2.470934687170882

Epoch: 6| Step: 7
Training loss: 1.4758794910371948
Validation loss: 2.479648583749963

Epoch: 6| Step: 8
Training loss: 1.4756733472724721
Validation loss: 2.467522011094452

Epoch: 6| Step: 9
Training loss: 1.712184016458637
Validation loss: 2.5347136126829177

Epoch: 6| Step: 10
Training loss: 1.8962533576347183
Validation loss: 2.4900160914635547

Epoch: 6| Step: 11
Training loss: 1.9865430867505385
Validation loss: 2.504325417591782

Epoch: 6| Step: 12
Training loss: 1.9452101592447923
Validation loss: 2.549163660740786

Epoch: 6| Step: 13
Training loss: 1.9290495524550495
Validation loss: 2.487989920688882

Epoch: 525| Step: 0
Training loss: 1.777468901199868
Validation loss: 2.4823271657650197

Epoch: 6| Step: 1
Training loss: 1.6221792975644385
Validation loss: 2.512987194232502

Epoch: 6| Step: 2
Training loss: 1.6555539953976874
Validation loss: 2.5161349870623395

Epoch: 6| Step: 3
Training loss: 1.7772529327329745
Validation loss: 2.471362560136119

Epoch: 6| Step: 4
Training loss: 1.8406911789504152
Validation loss: 2.509883671024131

Epoch: 6| Step: 5
Training loss: 1.222275842347785
Validation loss: 2.54774377740212

Epoch: 6| Step: 6
Training loss: 2.3462362707891757
Validation loss: 2.4971556798207626

Epoch: 6| Step: 7
Training loss: 1.3492221746086477
Validation loss: 2.5267534960358593

Epoch: 6| Step: 8
Training loss: 1.3470791230557257
Validation loss: 2.52112467285776

Epoch: 6| Step: 9
Training loss: 1.5229881210715495
Validation loss: 2.4757810817953985

Epoch: 6| Step: 10
Training loss: 1.7858219032556704
Validation loss: 2.511060862264256

Epoch: 6| Step: 11
Training loss: 2.054930001804659
Validation loss: 2.4612795252068502

Epoch: 6| Step: 12
Training loss: 1.9088126295565624
Validation loss: 2.4871655940259614

Epoch: 6| Step: 13
Training loss: 2.0683461189745773
Validation loss: 2.45311966344147

Epoch: 526| Step: 0
Training loss: 1.470662515391154
Validation loss: 2.4690895236509167

Epoch: 6| Step: 1
Training loss: 2.318774603124507
Validation loss: 2.491188740272927

Epoch: 6| Step: 2
Training loss: 2.1203423112138364
Validation loss: 2.5262969422229915

Epoch: 6| Step: 3
Training loss: 1.8555751408642966
Validation loss: 2.4636500818468132

Epoch: 6| Step: 4
Training loss: 1.6530447120134928
Validation loss: 2.4768521319494083

Epoch: 6| Step: 5
Training loss: 1.712499384636316
Validation loss: 2.459683835878413

Epoch: 6| Step: 6
Training loss: 1.4024443098901074
Validation loss: 2.503879258950039

Epoch: 6| Step: 7
Training loss: 1.7765831294409526
Validation loss: 2.4590386730503644

Epoch: 6| Step: 8
Training loss: 1.5850020031359797
Validation loss: 2.461730272011224

Epoch: 6| Step: 9
Training loss: 1.8971367920866418
Validation loss: 2.5024258995266013

Epoch: 6| Step: 10
Training loss: 1.6516484089344923
Validation loss: 2.4981695929457897

Epoch: 6| Step: 11
Training loss: 1.376242163252108
Validation loss: 2.5189834969758773

Epoch: 6| Step: 12
Training loss: 1.3907177926297187
Validation loss: 2.512923444854061

Epoch: 6| Step: 13
Training loss: 1.8518746672213844
Validation loss: 2.542270507643239

Epoch: 527| Step: 0
Training loss: 2.419844040377093
Validation loss: 2.545874034497901

Epoch: 6| Step: 1
Training loss: 1.956762116404059
Validation loss: 2.489946609074898

Epoch: 6| Step: 2
Training loss: 1.2243479764564495
Validation loss: 2.492510617485204

Epoch: 6| Step: 3
Training loss: 1.8756150826252669
Validation loss: 2.4792593141325416

Epoch: 6| Step: 4
Training loss: 1.449701768525729
Validation loss: 2.4923082717752547

Epoch: 6| Step: 5
Training loss: 1.6024288160489846
Validation loss: 2.4671270254629296

Epoch: 6| Step: 6
Training loss: 1.8937019971548639
Validation loss: 2.509322031486491

Epoch: 6| Step: 7
Training loss: 1.5729455082082795
Validation loss: 2.5137458248135065

Epoch: 6| Step: 8
Training loss: 1.8255018667704164
Validation loss: 2.479966184052764

Epoch: 6| Step: 9
Training loss: 1.8083714787317158
Validation loss: 2.4936122010251953

Epoch: 6| Step: 10
Training loss: 1.7051902637988507
Validation loss: 2.49901957309377

Epoch: 6| Step: 11
Training loss: 1.6862973766868197
Validation loss: 2.477881371315558

Epoch: 6| Step: 12
Training loss: 1.2874884965993802
Validation loss: 2.517121768747885

Epoch: 6| Step: 13
Training loss: 1.6790773214924597
Validation loss: 2.5068105058641463

Epoch: 528| Step: 0
Training loss: 1.8614923298667745
Validation loss: 2.4372182766877257

Epoch: 6| Step: 1
Training loss: 2.274756714105471
Validation loss: 2.4765303497644715

Epoch: 6| Step: 2
Training loss: 1.7771472864244748
Validation loss: 2.5041706735936775

Epoch: 6| Step: 3
Training loss: 2.4265941296030986
Validation loss: 2.4569952287998533

Epoch: 6| Step: 4
Training loss: 1.5590439531053104
Validation loss: 2.4463361211968815

Epoch: 6| Step: 5
Training loss: 1.9818803019288793
Validation loss: 2.534399011555167

Epoch: 6| Step: 6
Training loss: 1.766300848507684
Validation loss: 2.514587677634646

Epoch: 6| Step: 7
Training loss: 1.3030594130003816
Validation loss: 2.4954819482253368

Epoch: 6| Step: 8
Training loss: 1.3187870942453601
Validation loss: 2.5311340301414123

Epoch: 6| Step: 9
Training loss: 1.317462440838455
Validation loss: 2.48174527637854

Epoch: 6| Step: 10
Training loss: 1.415644482611175
Validation loss: 2.5050648630770347

Epoch: 6| Step: 11
Training loss: 1.6806901644908003
Validation loss: 2.5424697789949886

Epoch: 6| Step: 12
Training loss: 1.2851218361000702
Validation loss: 2.518561574612243

Epoch: 6| Step: 13
Training loss: 2.3113057945040523
Validation loss: 2.5259599603738616

Epoch: 529| Step: 0
Training loss: 1.5052496916512916
Validation loss: 2.4568038984709926

Epoch: 6| Step: 1
Training loss: 1.3930498477180326
Validation loss: 2.551013054265164

Epoch: 6| Step: 2
Training loss: 1.6001743907065935
Validation loss: 2.53372403674166

Epoch: 6| Step: 3
Training loss: 1.8005104771600295
Validation loss: 2.518703458573778

Epoch: 6| Step: 4
Training loss: 1.4051468230806905
Validation loss: 2.524282853497623

Epoch: 6| Step: 5
Training loss: 2.3112125421338887
Validation loss: 2.5213493124871973

Epoch: 6| Step: 6
Training loss: 1.6324513597237786
Validation loss: 2.524125955958267

Epoch: 6| Step: 7
Training loss: 2.373899706900106
Validation loss: 2.4703051496431683

Epoch: 6| Step: 8
Training loss: 1.813801068271226
Validation loss: 2.525942523018369

Epoch: 6| Step: 9
Training loss: 1.6446756403729377
Validation loss: 2.540093208410177

Epoch: 6| Step: 10
Training loss: 1.6289330349922349
Validation loss: 2.4760401141090176

Epoch: 6| Step: 11
Training loss: 1.8818064807591726
Validation loss: 2.559083485335207

Epoch: 6| Step: 12
Training loss: 1.302248382280282
Validation loss: 2.523104901600822

Epoch: 6| Step: 13
Training loss: 2.009487062357999
Validation loss: 2.5381049984309394

Epoch: 530| Step: 0
Training loss: 1.2315488888216584
Validation loss: 2.5587287021201472

Epoch: 6| Step: 1
Training loss: 1.8722962276473507
Validation loss: 2.483006111643296

Epoch: 6| Step: 2
Training loss: 2.637209155783374
Validation loss: 2.509683309821719

Epoch: 6| Step: 3
Training loss: 1.6394459438643878
Validation loss: 2.495819127529291

Epoch: 6| Step: 4
Training loss: 1.5966595289725172
Validation loss: 2.5029753074444536

Epoch: 6| Step: 5
Training loss: 0.9412379767370637
Validation loss: 2.4731823681057357

Epoch: 6| Step: 6
Training loss: 1.7024878613771661
Validation loss: 2.521651265397477

Epoch: 6| Step: 7
Training loss: 1.935954985335654
Validation loss: 2.478780626612059

Epoch: 6| Step: 8
Training loss: 1.3688813098646742
Validation loss: 2.489571668676756

Epoch: 6| Step: 9
Training loss: 1.5838561282469288
Validation loss: 2.46476571242128

Epoch: 6| Step: 10
Training loss: 1.9854661239543014
Validation loss: 2.4665116650815535

Epoch: 6| Step: 11
Training loss: 1.6735191460646255
Validation loss: 2.4887467122188207

Epoch: 6| Step: 12
Training loss: 1.8877262560917651
Validation loss: 2.5166844938277415

Epoch: 6| Step: 13
Training loss: 1.5785542272630466
Validation loss: 2.520188221514789

Epoch: 531| Step: 0
Training loss: 1.4487256139063835
Validation loss: 2.4628278387579563

Epoch: 6| Step: 1
Training loss: 1.262976996326343
Validation loss: 2.5654688948391122

Epoch: 6| Step: 2
Training loss: 2.024468236732927
Validation loss: 2.5325810305378833

Epoch: 6| Step: 3
Training loss: 2.2590866981273123
Validation loss: 2.54207400509623

Epoch: 6| Step: 4
Training loss: 1.5632857826392155
Validation loss: 2.5273214907494164

Epoch: 6| Step: 5
Training loss: 1.3470580611654261
Validation loss: 2.4989983151621513

Epoch: 6| Step: 6
Training loss: 1.6812770685335472
Validation loss: 2.4958724013427034

Epoch: 6| Step: 7
Training loss: 1.5119936197842603
Validation loss: 2.514748289772271

Epoch: 6| Step: 8
Training loss: 2.1547727085275232
Validation loss: 2.4773670081674313

Epoch: 6| Step: 9
Training loss: 1.1258938205620228
Validation loss: 2.5037233846031444

Epoch: 6| Step: 10
Training loss: 2.1307481549657945
Validation loss: 2.4730392564032186

Epoch: 6| Step: 11
Training loss: 1.8868681096257254
Validation loss: 2.451860631731824

Epoch: 6| Step: 12
Training loss: 1.296642788239764
Validation loss: 2.485914221366299

Epoch: 6| Step: 13
Training loss: 1.7096547234387605
Validation loss: 2.529081488531544

Epoch: 532| Step: 0
Training loss: 2.0598401344636237
Validation loss: 2.4643386165389454

Epoch: 6| Step: 1
Training loss: 1.8467705763262725
Validation loss: 2.5317049507634235

Epoch: 6| Step: 2
Training loss: 1.569627982728917
Validation loss: 2.4899229055884766

Epoch: 6| Step: 3
Training loss: 1.591954659908985
Validation loss: 2.512088470354401

Epoch: 6| Step: 4
Training loss: 1.6631781148761484
Validation loss: 2.4855938614326845

Epoch: 6| Step: 5
Training loss: 1.6136768955068581
Validation loss: 2.494592401297808

Epoch: 6| Step: 6
Training loss: 1.502176930354854
Validation loss: 2.5305966894226346

Epoch: 6| Step: 7
Training loss: 1.4313740605721086
Validation loss: 2.5560751756837483

Epoch: 6| Step: 8
Training loss: 1.4857618579086413
Validation loss: 2.500657020392523

Epoch: 6| Step: 9
Training loss: 1.6559181600702197
Validation loss: 2.529570892728669

Epoch: 6| Step: 10
Training loss: 2.1577166669310865
Validation loss: 2.5291225314823302

Epoch: 6| Step: 11
Training loss: 1.6912058652094004
Validation loss: 2.499433184530561

Epoch: 6| Step: 12
Training loss: 2.1482568283407586
Validation loss: 2.4747372522905016

Epoch: 6| Step: 13
Training loss: 1.2231710891733778
Validation loss: 2.479342744868001

Epoch: 533| Step: 0
Training loss: 1.642469695115054
Validation loss: 2.5042094912714883

Epoch: 6| Step: 1
Training loss: 1.4253250019149963
Validation loss: 2.498794661947669

Epoch: 6| Step: 2
Training loss: 2.1327360370050576
Validation loss: 2.503304448012779

Epoch: 6| Step: 3
Training loss: 1.4625973986935992
Validation loss: 2.511689173817527

Epoch: 6| Step: 4
Training loss: 2.159246049445194
Validation loss: 2.498413662449571

Epoch: 6| Step: 5
Training loss: 1.575856759905696
Validation loss: 2.498602264123904

Epoch: 6| Step: 6
Training loss: 1.7463428567106185
Validation loss: 2.4742844440609475

Epoch: 6| Step: 7
Training loss: 1.7575081116664133
Validation loss: 2.489442545793471

Epoch: 6| Step: 8
Training loss: 1.3969755576035932
Validation loss: 2.499635696529592

Epoch: 6| Step: 9
Training loss: 1.7397941948865425
Validation loss: 2.5293441924506084

Epoch: 6| Step: 10
Training loss: 1.2553620250942623
Validation loss: 2.486927312872925

Epoch: 6| Step: 11
Training loss: 1.9195326510506945
Validation loss: 2.50560049407593

Epoch: 6| Step: 12
Training loss: 2.0951598246206293
Validation loss: 2.5395940711684357

Epoch: 6| Step: 13
Training loss: 0.9885418212911943
Validation loss: 2.5043170346204024

Epoch: 534| Step: 0
Training loss: 1.8768563300190866
Validation loss: 2.4955632504933374

Epoch: 6| Step: 1
Training loss: 1.7665340817681214
Validation loss: 2.5349108081681586

Epoch: 6| Step: 2
Training loss: 1.2190527906620363
Validation loss: 2.4557050372036047

Epoch: 6| Step: 3
Training loss: 1.80215236406652
Validation loss: 2.510966364389501

Epoch: 6| Step: 4
Training loss: 1.5598132112133596
Validation loss: 2.500007451979493

Epoch: 6| Step: 5
Training loss: 1.5110192072649211
Validation loss: 2.503894883119575

Epoch: 6| Step: 6
Training loss: 1.592435930840672
Validation loss: 2.5068238782652355

Epoch: 6| Step: 7
Training loss: 1.6584759275513938
Validation loss: 2.4739627201233567

Epoch: 6| Step: 8
Training loss: 1.851103649343162
Validation loss: 2.4721654675023426

Epoch: 6| Step: 9
Training loss: 1.4716945108275947
Validation loss: 2.5187513119322573

Epoch: 6| Step: 10
Training loss: 1.6175519007473387
Validation loss: 2.5252952238210025

Epoch: 6| Step: 11
Training loss: 2.0912934880999225
Validation loss: 2.4345012958231433

Epoch: 6| Step: 12
Training loss: 1.721937933739235
Validation loss: 2.5321544741375765

Epoch: 6| Step: 13
Training loss: 2.1665981599785664
Validation loss: 2.4832920988857268

Epoch: 535| Step: 0
Training loss: 1.4168668306348249
Validation loss: 2.474853673466556

Epoch: 6| Step: 1
Training loss: 2.269588397516304
Validation loss: 2.4865711906848373

Epoch: 6| Step: 2
Training loss: 1.3943004256841451
Validation loss: 2.4406239873689604

Epoch: 6| Step: 3
Training loss: 2.1529991965781847
Validation loss: 2.5058729969863824

Epoch: 6| Step: 4
Training loss: 1.5870721826272625
Validation loss: 2.494293959289875

Epoch: 6| Step: 5
Training loss: 1.4643210330385452
Validation loss: 2.475562097545851

Epoch: 6| Step: 6
Training loss: 1.916210604049316
Validation loss: 2.4667923511018093

Epoch: 6| Step: 7
Training loss: 1.977622369965939
Validation loss: 2.4195827680982482

Epoch: 6| Step: 8
Training loss: 1.6704143667962499
Validation loss: 2.491948249507556

Epoch: 6| Step: 9
Training loss: 1.2542519731542203
Validation loss: 2.5350826896217504

Epoch: 6| Step: 10
Training loss: 1.9421571319489197
Validation loss: 2.4713921853215384

Epoch: 6| Step: 11
Training loss: 1.1945818494280374
Validation loss: 2.5390747231567086

Epoch: 6| Step: 12
Training loss: 1.6332484489233854
Validation loss: 2.4627288751973393

Epoch: 6| Step: 13
Training loss: 2.109504300145886
Validation loss: 2.5213018724495093

Epoch: 536| Step: 0
Training loss: 1.4678263905326612
Validation loss: 2.447974114582844

Epoch: 6| Step: 1
Training loss: 1.5387906061883805
Validation loss: 2.467195932693585

Epoch: 6| Step: 2
Training loss: 2.2323445517831644
Validation loss: 2.563705991917251

Epoch: 6| Step: 3
Training loss: 1.5876434621792415
Validation loss: 2.4880847646952504

Epoch: 6| Step: 4
Training loss: 1.874274113335495
Validation loss: 2.504185671462328

Epoch: 6| Step: 5
Training loss: 2.3016685238701107
Validation loss: 2.5659374343843866

Epoch: 6| Step: 6
Training loss: 1.5703134868865447
Validation loss: 2.458159960109328

Epoch: 6| Step: 7
Training loss: 1.5664334948826844
Validation loss: 2.5091925456613495

Epoch: 6| Step: 8
Training loss: 1.7770949640225124
Validation loss: 2.526543887498365

Epoch: 6| Step: 9
Training loss: 1.679530788474446
Validation loss: 2.4890995903772324

Epoch: 6| Step: 10
Training loss: 1.0788221454917366
Validation loss: 2.5009461448079766

Epoch: 6| Step: 11
Training loss: 1.6805763908895168
Validation loss: 2.4750124639647018

Epoch: 6| Step: 12
Training loss: 1.7198981178405142
Validation loss: 2.4684198204670413

Epoch: 6| Step: 13
Training loss: 1.7314495811689485
Validation loss: 2.5462377110620764

Epoch: 537| Step: 0
Training loss: 1.5909944536171172
Validation loss: 2.497945012709846

Epoch: 6| Step: 1
Training loss: 1.848885189991597
Validation loss: 2.5301574796217183

Epoch: 6| Step: 2
Training loss: 1.8729311019233676
Validation loss: 2.532541791844

Epoch: 6| Step: 3
Training loss: 1.8306864864172956
Validation loss: 2.5307989768172505

Epoch: 6| Step: 4
Training loss: 1.4340183554343138
Validation loss: 2.589434432975955

Epoch: 6| Step: 5
Training loss: 1.9258753384089524
Validation loss: 2.5518797739066397

Epoch: 6| Step: 6
Training loss: 1.4097276707352369
Validation loss: 2.5368919496326474

Epoch: 6| Step: 7
Training loss: 1.454189443910847
Validation loss: 2.530856243799441

Epoch: 6| Step: 8
Training loss: 1.3879967616452964
Validation loss: 2.5388685068086487

Epoch: 6| Step: 9
Training loss: 2.4112947764177024
Validation loss: 2.573663098516776

Epoch: 6| Step: 10
Training loss: 1.7880817373696234
Validation loss: 2.54993647989489

Epoch: 6| Step: 11
Training loss: 2.1388220329349785
Validation loss: 2.5088583571904692

Epoch: 6| Step: 12
Training loss: 1.2759785954464902
Validation loss: 2.4893563372560625

Epoch: 6| Step: 13
Training loss: 2.2071785936711943
Validation loss: 2.5089723352468103

Epoch: 538| Step: 0
Training loss: 1.7568039098664847
Validation loss: 2.5395819030040023

Epoch: 6| Step: 1
Training loss: 1.4147127458406596
Validation loss: 2.4991150130488387

Epoch: 6| Step: 2
Training loss: 1.437247378501021
Validation loss: 2.5474151787380457

Epoch: 6| Step: 3
Training loss: 1.4569067198689043
Validation loss: 2.497927115002339

Epoch: 6| Step: 4
Training loss: 1.9360182849201832
Validation loss: 2.5258378547438016

Epoch: 6| Step: 5
Training loss: 1.1862716344824182
Validation loss: 2.538360441090597

Epoch: 6| Step: 6
Training loss: 1.4328631376514067
Validation loss: 2.4952234305651624

Epoch: 6| Step: 7
Training loss: 2.515087757437562
Validation loss: 2.5107158157058036

Epoch: 6| Step: 8
Training loss: 1.5746397302720923
Validation loss: 2.489846413922204

Epoch: 6| Step: 9
Training loss: 1.3719798645399293
Validation loss: 2.488243066288014

Epoch: 6| Step: 10
Training loss: 1.808745408754249
Validation loss: 2.4534980151208723

Epoch: 6| Step: 11
Training loss: 2.194029952659376
Validation loss: 2.4724441621653495

Epoch: 6| Step: 12
Training loss: 2.0505796496891406
Validation loss: 2.4616707647769123

Epoch: 6| Step: 13
Training loss: 1.7643775246440299
Validation loss: 2.519002238371659

Epoch: 539| Step: 0
Training loss: 1.6007308661601067
Validation loss: 2.5347435401974887

Epoch: 6| Step: 1
Training loss: 2.02959315878768
Validation loss: 2.497999362906953

Epoch: 6| Step: 2
Training loss: 0.9834256514086104
Validation loss: 2.4918562675764213

Epoch: 6| Step: 3
Training loss: 2.0026876748824867
Validation loss: 2.468320884809742

Epoch: 6| Step: 4
Training loss: 1.2659437931895945
Validation loss: 2.515211104545309

Epoch: 6| Step: 5
Training loss: 1.6382114641118408
Validation loss: 2.4796018072954804

Epoch: 6| Step: 6
Training loss: 1.8218113700001817
Validation loss: 2.4836507143777493

Epoch: 6| Step: 7
Training loss: 1.4729934427771902
Validation loss: 2.5152566872391047

Epoch: 6| Step: 8
Training loss: 1.4396722386128615
Validation loss: 2.506132815423173

Epoch: 6| Step: 9
Training loss: 1.5231979573041778
Validation loss: 2.541366083966431

Epoch: 6| Step: 10
Training loss: 1.2961049378908425
Validation loss: 2.528821546201513

Epoch: 6| Step: 11
Training loss: 1.6028885724658397
Validation loss: 2.501170471971737

Epoch: 6| Step: 12
Training loss: 2.9102457122364807
Validation loss: 2.550738044916468

Epoch: 6| Step: 13
Training loss: 1.1737210800946887
Validation loss: 2.549517394886439

Epoch: 540| Step: 0
Training loss: 1.5690280348763388
Validation loss: 2.513897213238149

Epoch: 6| Step: 1
Training loss: 1.816356764908926
Validation loss: 2.4963644110995387

Epoch: 6| Step: 2
Training loss: 1.6853862522368948
Validation loss: 2.5261430590398373

Epoch: 6| Step: 3
Training loss: 1.0749346203106982
Validation loss: 2.5037333412909017

Epoch: 6| Step: 4
Training loss: 1.5207036455154999
Validation loss: 2.513264643166571

Epoch: 6| Step: 5
Training loss: 1.4249183029045533
Validation loss: 2.5006819953566857

Epoch: 6| Step: 6
Training loss: 2.3508749935872033
Validation loss: 2.5279319991395868

Epoch: 6| Step: 7
Training loss: 2.609202304995915
Validation loss: 2.458014113103746

Epoch: 6| Step: 8
Training loss: 2.0820223180067554
Validation loss: 2.5176216649391745

Epoch: 6| Step: 9
Training loss: 1.5051598018579384
Validation loss: 2.4585347066181176

Epoch: 6| Step: 10
Training loss: 1.1868132563034188
Validation loss: 2.450463677026213

Epoch: 6| Step: 11
Training loss: 1.8627521395427176
Validation loss: 2.4612410798722553

Epoch: 6| Step: 12
Training loss: 1.4431847658994221
Validation loss: 2.5009544914127546

Epoch: 6| Step: 13
Training loss: 1.3032492287972146
Validation loss: 2.5274750435359827

Epoch: 541| Step: 0
Training loss: 1.7641486012586916
Validation loss: 2.467149445410688

Epoch: 6| Step: 1
Training loss: 1.176780504189929
Validation loss: 2.521677180220326

Epoch: 6| Step: 2
Training loss: 1.8088368855917794
Validation loss: 2.4812461388674842

Epoch: 6| Step: 3
Training loss: 1.1597616121730847
Validation loss: 2.49653089668415

Epoch: 6| Step: 4
Training loss: 1.764016017521043
Validation loss: 2.4892701226434464

Epoch: 6| Step: 5
Training loss: 1.434888623929706
Validation loss: 2.5533190054780524

Epoch: 6| Step: 6
Training loss: 1.8234687913630305
Validation loss: 2.4613853670790062

Epoch: 6| Step: 7
Training loss: 1.4156584611521212
Validation loss: 2.458519229009594

Epoch: 6| Step: 8
Training loss: 2.568814011864477
Validation loss: 2.502752040388519

Epoch: 6| Step: 9
Training loss: 2.1436148598117644
Validation loss: 2.484584459764804

Epoch: 6| Step: 10
Training loss: 1.8881591605891048
Validation loss: 2.4567661845081172

Epoch: 6| Step: 11
Training loss: 1.4599160279986563
Validation loss: 2.501857070902261

Epoch: 6| Step: 12
Training loss: 1.871233208223581
Validation loss: 2.493125640972956

Epoch: 6| Step: 13
Training loss: 1.3008360521840812
Validation loss: 2.4955329096128014

Epoch: 542| Step: 0
Training loss: 1.7681654486508016
Validation loss: 2.493905089848496

Epoch: 6| Step: 1
Training loss: 1.1338322751979852
Validation loss: 2.503052904506877

Epoch: 6| Step: 2
Training loss: 1.2716338132828289
Validation loss: 2.547610825534499

Epoch: 6| Step: 3
Training loss: 1.5653779038534301
Validation loss: 2.459899645993667

Epoch: 6| Step: 4
Training loss: 1.4670697604743916
Validation loss: 2.493548473450006

Epoch: 6| Step: 5
Training loss: 2.0167147034317576
Validation loss: 2.5437148112983143

Epoch: 6| Step: 6
Training loss: 1.5184981651458356
Validation loss: 2.5354940358555464

Epoch: 6| Step: 7
Training loss: 1.7048055773994224
Validation loss: 2.518376059807349

Epoch: 6| Step: 8
Training loss: 2.48511662000413
Validation loss: 2.5191384504937124

Epoch: 6| Step: 9
Training loss: 1.383660740579517
Validation loss: 2.47398926659995

Epoch: 6| Step: 10
Training loss: 2.2520748744056442
Validation loss: 2.539848008485676

Epoch: 6| Step: 11
Training loss: 1.2451167566635284
Validation loss: 2.4949631208286447

Epoch: 6| Step: 12
Training loss: 2.0823859794698665
Validation loss: 2.4714306822832195

Epoch: 6| Step: 13
Training loss: 1.4622172905662594
Validation loss: 2.4619566042244325

Epoch: 543| Step: 0
Training loss: 1.1462707840461022
Validation loss: 2.4900337392243714

Epoch: 6| Step: 1
Training loss: 1.5121957583279775
Validation loss: 2.483026061036549

Epoch: 6| Step: 2
Training loss: 1.8884087806347227
Validation loss: 2.4895054212946794

Epoch: 6| Step: 3
Training loss: 1.5680978825437784
Validation loss: 2.5067557105909537

Epoch: 6| Step: 4
Training loss: 1.9222013615093068
Validation loss: 2.455079029293985

Epoch: 6| Step: 5
Training loss: 1.4541977235088177
Validation loss: 2.497552784500485

Epoch: 6| Step: 6
Training loss: 2.5869265045177863
Validation loss: 2.4931067425880453

Epoch: 6| Step: 7
Training loss: 1.932291351345753
Validation loss: 2.4556950569926643

Epoch: 6| Step: 8
Training loss: 1.5238488840088986
Validation loss: 2.4899797824573064

Epoch: 6| Step: 9
Training loss: 1.7375921705210082
Validation loss: 2.4720352964680936

Epoch: 6| Step: 10
Training loss: 1.5977805539299963
Validation loss: 2.5498258315269497

Epoch: 6| Step: 11
Training loss: 1.805874784891936
Validation loss: 2.473821612187113

Epoch: 6| Step: 12
Training loss: 0.9691808419299329
Validation loss: 2.453402162686107

Epoch: 6| Step: 13
Training loss: 1.7995692744423166
Validation loss: 2.491738017741779

Epoch: 544| Step: 0
Training loss: 1.602805274178053
Validation loss: 2.543459214941324

Epoch: 6| Step: 1
Training loss: 1.7103784771402781
Validation loss: 2.491074253158363

Epoch: 6| Step: 2
Training loss: 1.934965999215836
Validation loss: 2.522781079951126

Epoch: 6| Step: 3
Training loss: 1.614675219802715
Validation loss: 2.4926001613799205

Epoch: 6| Step: 4
Training loss: 1.6976450681427866
Validation loss: 2.487904011136294

Epoch: 6| Step: 5
Training loss: 1.2474632271524215
Validation loss: 2.48995299359541

Epoch: 6| Step: 6
Training loss: 1.6172696152631352
Validation loss: 2.509298639754047

Epoch: 6| Step: 7
Training loss: 2.418012134859164
Validation loss: 2.4983117997220017

Epoch: 6| Step: 8
Training loss: 1.7758407777474778
Validation loss: 2.530185265374854

Epoch: 6| Step: 9
Training loss: 1.9458592883495334
Validation loss: 2.451413004170334

Epoch: 6| Step: 10
Training loss: 1.4536222201973639
Validation loss: 2.5129755970647736

Epoch: 6| Step: 11
Training loss: 1.6090563115993501
Validation loss: 2.469276508113907

Epoch: 6| Step: 12
Training loss: 1.2769495271134357
Validation loss: 2.469095596624575

Epoch: 6| Step: 13
Training loss: 1.3616044189640288
Validation loss: 2.4987516373002707

Epoch: 545| Step: 0
Training loss: 1.7501320107941283
Validation loss: 2.5128693919409377

Epoch: 6| Step: 1
Training loss: 1.704935773607459
Validation loss: 2.4153913644979212

Epoch: 6| Step: 2
Training loss: 1.8834787669897672
Validation loss: 2.4971956829417876

Epoch: 6| Step: 3
Training loss: 1.7687944979512646
Validation loss: 2.528196071774317

Epoch: 6| Step: 4
Training loss: 1.0091905856480754
Validation loss: 2.518197838878676

Epoch: 6| Step: 5
Training loss: 1.7481172515511934
Validation loss: 2.5154272536894364

Epoch: 6| Step: 6
Training loss: 2.283447774631913
Validation loss: 2.506672525436128

Epoch: 6| Step: 7
Training loss: 1.2422596652583284
Validation loss: 2.488567440732712

Epoch: 6| Step: 8
Training loss: 1.7470185904952154
Validation loss: 2.501412951177989

Epoch: 6| Step: 9
Training loss: 1.6678939909786898
Validation loss: 2.486825329124908

Epoch: 6| Step: 10
Training loss: 1.0239503463687158
Validation loss: 2.545065040343149

Epoch: 6| Step: 11
Training loss: 1.5385114583756276
Validation loss: 2.4814629117044396

Epoch: 6| Step: 12
Training loss: 1.8149454785399566
Validation loss: 2.448802601441735

Epoch: 6| Step: 13
Training loss: 2.1669859161905087
Validation loss: 2.48705520260237

Epoch: 546| Step: 0
Training loss: 1.2650669892859356
Validation loss: 2.5013792232729584

Epoch: 6| Step: 1
Training loss: 1.475738376138033
Validation loss: 2.49864157922837

Epoch: 6| Step: 2
Training loss: 1.3623747776828272
Validation loss: 2.5392374392083767

Epoch: 6| Step: 3
Training loss: 1.425043620730217
Validation loss: 2.496827331471532

Epoch: 6| Step: 4
Training loss: 1.9356228133162456
Validation loss: 2.5069357972294255

Epoch: 6| Step: 5
Training loss: 1.7638461173704862
Validation loss: 2.446056060144835

Epoch: 6| Step: 6
Training loss: 2.285871657846306
Validation loss: 2.442727459832367

Epoch: 6| Step: 7
Training loss: 1.3420905578917823
Validation loss: 2.535172990952591

Epoch: 6| Step: 8
Training loss: 1.0639460764643867
Validation loss: 2.5016475816667

Epoch: 6| Step: 9
Training loss: 2.2087136666850613
Validation loss: 2.4735431561538905

Epoch: 6| Step: 10
Training loss: 2.3530274957362733
Validation loss: 2.528688509864539

Epoch: 6| Step: 11
Training loss: 1.4983007820138048
Validation loss: 2.516123015189095

Epoch: 6| Step: 12
Training loss: 0.7562615953297369
Validation loss: 2.54303197402657

Epoch: 6| Step: 13
Training loss: 1.936687668354363
Validation loss: 2.5116121834736314

Epoch: 547| Step: 0
Training loss: 1.4134325341882372
Validation loss: 2.501230109510933

Epoch: 6| Step: 1
Training loss: 1.7120410721923511
Validation loss: 2.4636493279418903

Epoch: 6| Step: 2
Training loss: 1.362119863134449
Validation loss: 2.471371495757653

Epoch: 6| Step: 3
Training loss: 2.2378566265936173
Validation loss: 2.5019634985932253

Epoch: 6| Step: 4
Training loss: 2.111946403603637
Validation loss: 2.430487088725037

Epoch: 6| Step: 5
Training loss: 1.9608389537107647
Validation loss: 2.4424774489704846

Epoch: 6| Step: 6
Training loss: 1.636839359182371
Validation loss: 2.540024551870128

Epoch: 6| Step: 7
Training loss: 1.247481479239729
Validation loss: 2.5196738109048966

Epoch: 6| Step: 8
Training loss: 1.7014723292367122
Validation loss: 2.496584900809081

Epoch: 6| Step: 9
Training loss: 1.6012561784278139
Validation loss: 2.5014647320407204

Epoch: 6| Step: 10
Training loss: 1.5223133341043074
Validation loss: 2.5041399711919645

Epoch: 6| Step: 11
Training loss: 1.5085640254912442
Validation loss: 2.52783926781926

Epoch: 6| Step: 12
Training loss: 2.0289239329616646
Validation loss: 2.4786831387779173

Epoch: 6| Step: 13
Training loss: 1.7580769657824273
Validation loss: 2.474496588623181

Epoch: 548| Step: 0
Training loss: 1.9081802601064226
Validation loss: 2.5300449544857373

Epoch: 6| Step: 1
Training loss: 1.4581224379862396
Validation loss: 2.4956527182451183

Epoch: 6| Step: 2
Training loss: 1.3644620924031656
Validation loss: 2.5073746444741083

Epoch: 6| Step: 3
Training loss: 1.9185020808491222
Validation loss: 2.492968378519366

Epoch: 6| Step: 4
Training loss: 1.468369536124933
Validation loss: 2.470232847282759

Epoch: 6| Step: 5
Training loss: 1.7937113236035798
Validation loss: 2.5126719251335894

Epoch: 6| Step: 6
Training loss: 2.413551745656426
Validation loss: 2.4603998167494208

Epoch: 6| Step: 7
Training loss: 1.9625181233729436
Validation loss: 2.4401471698737405

Epoch: 6| Step: 8
Training loss: 1.1059668399468456
Validation loss: 2.47667974368753

Epoch: 6| Step: 9
Training loss: 1.3100999959971449
Validation loss: 2.4686718377081416

Epoch: 6| Step: 10
Training loss: 1.7689955955351344
Validation loss: 2.523685539772327

Epoch: 6| Step: 11
Training loss: 1.259502909864068
Validation loss: 2.5132775313900475

Epoch: 6| Step: 12
Training loss: 1.5169687508248164
Validation loss: 2.4869578463626185

Epoch: 6| Step: 13
Training loss: 1.5719116570689953
Validation loss: 2.480923739804282

Epoch: 549| Step: 0
Training loss: 2.0272404932911043
Validation loss: 2.5333444753228043

Epoch: 6| Step: 1
Training loss: 1.2462819594070376
Validation loss: 2.4828918780955203

Epoch: 6| Step: 2
Training loss: 1.3789395336424353
Validation loss: 2.4583762199730823

Epoch: 6| Step: 3
Training loss: 1.3689306862771309
Validation loss: 2.556670454275177

Epoch: 6| Step: 4
Training loss: 1.7107357097755258
Validation loss: 2.5057292866708365

Epoch: 6| Step: 5
Training loss: 1.2013352693904837
Validation loss: 2.5166086413773185

Epoch: 6| Step: 6
Training loss: 1.8711745338282486
Validation loss: 2.5314761083224715

Epoch: 6| Step: 7
Training loss: 1.8352626128247223
Validation loss: 2.5059627672473033

Epoch: 6| Step: 8
Training loss: 1.536379727006921
Validation loss: 2.4627642368841416

Epoch: 6| Step: 9
Training loss: 1.6151738553316102
Validation loss: 2.4527623457360006

Epoch: 6| Step: 10
Training loss: 2.277034156131009
Validation loss: 2.5016945746026016

Epoch: 6| Step: 11
Training loss: 1.6140703022002933
Validation loss: 2.527819627465519

Epoch: 6| Step: 12
Training loss: 2.185607418418291
Validation loss: 2.4805444136294783

Epoch: 6| Step: 13
Training loss: 1.691561086144201
Validation loss: 2.486985681816595

Epoch: 550| Step: 0
Training loss: 2.3166876327700265
Validation loss: 2.5169000662303262

Epoch: 6| Step: 1
Training loss: 1.4729855116204802
Validation loss: 2.4786944692374395

Epoch: 6| Step: 2
Training loss: 1.011882164913868
Validation loss: 2.502366760725308

Epoch: 6| Step: 3
Training loss: 1.251607719299807
Validation loss: 2.4878142642072465

Epoch: 6| Step: 4
Training loss: 2.063174166459002
Validation loss: 2.4841201371852972

Epoch: 6| Step: 5
Training loss: 1.494019985938538
Validation loss: 2.4821594899454156

Epoch: 6| Step: 6
Training loss: 1.6584547950442303
Validation loss: 2.536479840618366

Epoch: 6| Step: 7
Training loss: 1.3991421676968896
Validation loss: 2.4877073775260974

Epoch: 6| Step: 8
Training loss: 1.509067072763662
Validation loss: 2.523875900533425

Epoch: 6| Step: 9
Training loss: 1.8501211100964543
Validation loss: 2.5286784517141467

Epoch: 6| Step: 10
Training loss: 1.5236590102131404
Validation loss: 2.480712333994244

Epoch: 6| Step: 11
Training loss: 2.0425917676950442
Validation loss: 2.494268050319308

Epoch: 6| Step: 12
Training loss: 1.6881729479593255
Validation loss: 2.4678109416928624

Epoch: 6| Step: 13
Training loss: 1.9045179659315772
Validation loss: 2.5211549975902336

Epoch: 551| Step: 0
Training loss: 1.6820389722194136
Validation loss: 2.46702722845348

Epoch: 6| Step: 1
Training loss: 1.6061227770343236
Validation loss: 2.4858240318450897

Epoch: 6| Step: 2
Training loss: 1.8438707085875579
Validation loss: 2.515703743617044

Epoch: 6| Step: 3
Training loss: 1.3067449006352785
Validation loss: 2.5507575590552394

Epoch: 6| Step: 4
Training loss: 1.451484820994485
Validation loss: 2.560100661684181

Epoch: 6| Step: 5
Training loss: 2.454719948265802
Validation loss: 2.540489017420685

Epoch: 6| Step: 6
Training loss: 1.8034502552555067
Validation loss: 2.574094667985373

Epoch: 6| Step: 7
Training loss: 2.337829742021314
Validation loss: 2.5610057642097925

Epoch: 6| Step: 8
Training loss: 1.4872135527674006
Validation loss: 2.5345922038831894

Epoch: 6| Step: 9
Training loss: 2.056562025519077
Validation loss: 2.5046553572071533

Epoch: 6| Step: 10
Training loss: 1.4810495168481712
Validation loss: 2.4836822615074157

Epoch: 6| Step: 11
Training loss: 1.3802857671165123
Validation loss: 2.5293737892261032

Epoch: 6| Step: 12
Training loss: 1.0639144234266993
Validation loss: 2.494286131536597

Epoch: 6| Step: 13
Training loss: 1.4790572631923768
Validation loss: 2.4848389138557487

Epoch: 552| Step: 0
Training loss: 1.2310309684849352
Validation loss: 2.472092145704211

Epoch: 6| Step: 1
Training loss: 1.5550157976727963
Validation loss: 2.4772761344022425

Epoch: 6| Step: 2
Training loss: 1.7679569070362913
Validation loss: 2.533484662166355

Epoch: 6| Step: 3
Training loss: 1.4950465429199273
Validation loss: 2.479221818709813

Epoch: 6| Step: 4
Training loss: 1.4264455423533289
Validation loss: 2.481582319552551

Epoch: 6| Step: 5
Training loss: 1.4574342226657149
Validation loss: 2.462015212175456

Epoch: 6| Step: 6
Training loss: 2.1696858522347644
Validation loss: 2.4521144073081746

Epoch: 6| Step: 7
Training loss: 2.1258979470923376
Validation loss: 2.449180512056931

Epoch: 6| Step: 8
Training loss: 1.4060506467447191
Validation loss: 2.4835965415206713

Epoch: 6| Step: 9
Training loss: 1.5028207006962482
Validation loss: 2.492066504797405

Epoch: 6| Step: 10
Training loss: 1.78738237807615
Validation loss: 2.4999930955935064

Epoch: 6| Step: 11
Training loss: 2.0567472743596715
Validation loss: 2.432715867998428

Epoch: 6| Step: 12
Training loss: 1.9457164176543527
Validation loss: 2.5164689549142296

Epoch: 6| Step: 13
Training loss: 1.76544863739968
Validation loss: 2.5008017438793506

Epoch: 553| Step: 0
Training loss: 1.8166127733525093
Validation loss: 2.509170126154808

Epoch: 6| Step: 1
Training loss: 1.4194749971117973
Validation loss: 2.4480574522637175

Epoch: 6| Step: 2
Training loss: 1.531446016182803
Validation loss: 2.4740392630033505

Epoch: 6| Step: 3
Training loss: 2.0492991296068572
Validation loss: 2.4969115623018934

Epoch: 6| Step: 4
Training loss: 1.8522082784049414
Validation loss: 2.5546478271414403

Epoch: 6| Step: 5
Training loss: 1.9372842730125257
Validation loss: 2.511451157432857

Epoch: 6| Step: 6
Training loss: 1.5555935620403005
Validation loss: 2.515036997592594

Epoch: 6| Step: 7
Training loss: 1.287710509636548
Validation loss: 2.5209796710155903

Epoch: 6| Step: 8
Training loss: 1.211954883069325
Validation loss: 2.464937029066287

Epoch: 6| Step: 9
Training loss: 1.4613650099344593
Validation loss: 2.546732014418859

Epoch: 6| Step: 10
Training loss: 1.324812584344093
Validation loss: 2.4846960236856885

Epoch: 6| Step: 11
Training loss: 1.9430027620155543
Validation loss: 2.4787625512284346

Epoch: 6| Step: 12
Training loss: 1.501371154343213
Validation loss: 2.4985358821855472

Epoch: 6| Step: 13
Training loss: 2.5330388847526013
Validation loss: 2.474076174318802

Epoch: 554| Step: 0
Training loss: 1.4302810520801335
Validation loss: 2.4642605182296586

Epoch: 6| Step: 1
Training loss: 2.034865228562591
Validation loss: 2.5202112019180194

Epoch: 6| Step: 2
Training loss: 1.571239748051109
Validation loss: 2.484797984431836

Epoch: 6| Step: 3
Training loss: 1.03526748923236
Validation loss: 2.4232118291788765

Epoch: 6| Step: 4
Training loss: 1.5794768633523044
Validation loss: 2.4767779096829226

Epoch: 6| Step: 5
Training loss: 1.2996976996111251
Validation loss: 2.498622391671417

Epoch: 6| Step: 6
Training loss: 1.6710966205616855
Validation loss: 2.5048708472319627

Epoch: 6| Step: 7
Training loss: 1.861769985017434
Validation loss: 2.4937445416265986

Epoch: 6| Step: 8
Training loss: 1.9312962301208492
Validation loss: 2.5044282722882123

Epoch: 6| Step: 9
Training loss: 1.1206406797640758
Validation loss: 2.5033382564841618

Epoch: 6| Step: 10
Training loss: 1.7217388867755847
Validation loss: 2.552119340238695

Epoch: 6| Step: 11
Training loss: 1.8283181373755222
Validation loss: 2.4358264340858793

Epoch: 6| Step: 12
Training loss: 2.245267234988399
Validation loss: 2.493505805516568

Epoch: 6| Step: 13
Training loss: 1.2403959874864154
Validation loss: 2.446768353410547

Epoch: 555| Step: 0
Training loss: 2.007966625665775
Validation loss: 2.4973475197830934

Epoch: 6| Step: 1
Training loss: 1.8290324770889372
Validation loss: 2.538476386815518

Epoch: 6| Step: 2
Training loss: 1.8817705619157907
Validation loss: 2.476454746723927

Epoch: 6| Step: 3
Training loss: 1.2512365900287141
Validation loss: 2.519242495497464

Epoch: 6| Step: 4
Training loss: 1.7820016713846334
Validation loss: 2.479618689661555

Epoch: 6| Step: 5
Training loss: 1.2475502805190242
Validation loss: 2.4400237254440555

Epoch: 6| Step: 6
Training loss: 2.6510959662152027
Validation loss: 2.464460224094855

Epoch: 6| Step: 7
Training loss: 1.495688600188191
Validation loss: 2.5237345024017883

Epoch: 6| Step: 8
Training loss: 1.8324031493027693
Validation loss: 2.4607248813748135

Epoch: 6| Step: 9
Training loss: 1.2697478593754548
Validation loss: 2.49266919543783

Epoch: 6| Step: 10
Training loss: 1.795243559228297
Validation loss: 2.487662684355805

Epoch: 6| Step: 11
Training loss: 1.5397058681648992
Validation loss: 2.5410174026880927

Epoch: 6| Step: 12
Training loss: 0.9215699677214905
Validation loss: 2.466348095689577

Epoch: 6| Step: 13
Training loss: 1.0316190348297531
Validation loss: 2.4334666820195907

Epoch: 556| Step: 0
Training loss: 2.24181817498784
Validation loss: 2.4832201653667116

Epoch: 6| Step: 1
Training loss: 1.5784956241917971
Validation loss: 2.4434714194701197

Epoch: 6| Step: 2
Training loss: 1.4851322852403035
Validation loss: 2.4541060001059

Epoch: 6| Step: 3
Training loss: 1.4387487709444498
Validation loss: 2.512105605874748

Epoch: 6| Step: 4
Training loss: 1.7296420290379457
Validation loss: 2.4844014228359366

Epoch: 6| Step: 5
Training loss: 1.8906574088857713
Validation loss: 2.463642191067918

Epoch: 6| Step: 6
Training loss: 1.534373775567151
Validation loss: 2.462692722370343

Epoch: 6| Step: 7
Training loss: 1.0947822059829924
Validation loss: 2.507667459362202

Epoch: 6| Step: 8
Training loss: 2.1063843047566015
Validation loss: 2.463998697312036

Epoch: 6| Step: 9
Training loss: 1.3946064306344217
Validation loss: 2.50499885528722

Epoch: 6| Step: 10
Training loss: 1.5846371887080102
Validation loss: 2.4667313166374463

Epoch: 6| Step: 11
Training loss: 1.4338456018397383
Validation loss: 2.5220774590132327

Epoch: 6| Step: 12
Training loss: 2.0419587944872415
Validation loss: 2.4515763089053504

Epoch: 6| Step: 13
Training loss: 1.635141637074314
Validation loss: 2.4289427128371273

Epoch: 557| Step: 0
Training loss: 1.5075121961008549
Validation loss: 2.4968560364157453

Epoch: 6| Step: 1
Training loss: 1.883975923959411
Validation loss: 2.4877223303755214

Epoch: 6| Step: 2
Training loss: 0.9373217095277905
Validation loss: 2.532833947256532

Epoch: 6| Step: 3
Training loss: 1.8096801922083605
Validation loss: 2.4933172296133748

Epoch: 6| Step: 4
Training loss: 1.786984898969291
Validation loss: 2.5158566064036703

Epoch: 6| Step: 5
Training loss: 2.010812025446055
Validation loss: 2.5429995688219567

Epoch: 6| Step: 6
Training loss: 2.0106418727253357
Validation loss: 2.47835603902266

Epoch: 6| Step: 7
Training loss: 1.4277484856572284
Validation loss: 2.5277041736632446

Epoch: 6| Step: 8
Training loss: 1.6207567714989253
Validation loss: 2.546383912360791

Epoch: 6| Step: 9
Training loss: 1.3811794487381788
Validation loss: 2.5470502048132926

Epoch: 6| Step: 10
Training loss: 1.4440627184638408
Validation loss: 2.5348863631043

Epoch: 6| Step: 11
Training loss: 2.1565065093124645
Validation loss: 2.458622150199827

Epoch: 6| Step: 12
Training loss: 1.7050482014305812
Validation loss: 2.4750394828997333

Epoch: 6| Step: 13
Training loss: 1.5770188789181032
Validation loss: 2.5049424721867446

Epoch: 558| Step: 0
Training loss: 1.4858485888205926
Validation loss: 2.442803459187744

Epoch: 6| Step: 1
Training loss: 1.5222780167934495
Validation loss: 2.4667127393207324

Epoch: 6| Step: 2
Training loss: 1.5021712959483735
Validation loss: 2.47367902248735

Epoch: 6| Step: 3
Training loss: 1.3348870413921443
Validation loss: 2.495311859488512

Epoch: 6| Step: 4
Training loss: 1.8059459443562444
Validation loss: 2.498720679532971

Epoch: 6| Step: 5
Training loss: 2.3715146239551848
Validation loss: 2.53011442189244

Epoch: 6| Step: 6
Training loss: 2.1365899809090645
Validation loss: 2.512411116124353

Epoch: 6| Step: 7
Training loss: 1.7767930739251034
Validation loss: 2.437991642493245

Epoch: 6| Step: 8
Training loss: 1.291510505875742
Validation loss: 2.4623661538538237

Epoch: 6| Step: 9
Training loss: 1.541638537313538
Validation loss: 2.497960316846588

Epoch: 6| Step: 10
Training loss: 1.1715958326333982
Validation loss: 2.49769484574795

Epoch: 6| Step: 11
Training loss: 1.47489520201728
Validation loss: 2.4882655566384475

Epoch: 6| Step: 12
Training loss: 1.3214470768151956
Validation loss: 2.502794111261503

Epoch: 6| Step: 13
Training loss: 2.2902862090117586
Validation loss: 2.5616397314043104

Epoch: 559| Step: 0
Training loss: 1.4946700610452086
Validation loss: 2.442590980186795

Epoch: 6| Step: 1
Training loss: 1.6519272732555415
Validation loss: 2.5109436158825686

Epoch: 6| Step: 2
Training loss: 1.73324850804061
Validation loss: 2.5162385969152865

Epoch: 6| Step: 3
Training loss: 1.4367342028634713
Validation loss: 2.5490425791290234

Epoch: 6| Step: 4
Training loss: 1.3856429964444597
Validation loss: 2.488896516199457

Epoch: 6| Step: 5
Training loss: 1.3299345367497586
Validation loss: 2.563451351762552

Epoch: 6| Step: 6
Training loss: 1.5195328974776174
Validation loss: 2.5663156461409384

Epoch: 6| Step: 7
Training loss: 1.5251081647191511
Validation loss: 2.5449674977143184

Epoch: 6| Step: 8
Training loss: 1.8461072691213756
Validation loss: 2.523837869348057

Epoch: 6| Step: 9
Training loss: 1.8586274255024415
Validation loss: 2.530939371506833

Epoch: 6| Step: 10
Training loss: 1.8771989008489187
Validation loss: 2.543006653353032

Epoch: 6| Step: 11
Training loss: 2.1218298658646724
Validation loss: 2.48982002518848

Epoch: 6| Step: 12
Training loss: 1.80177805819418
Validation loss: 2.510691046745861

Epoch: 6| Step: 13
Training loss: 1.9780701929487796
Validation loss: 2.489375753798129

Epoch: 560| Step: 0
Training loss: 1.6210501423681056
Validation loss: 2.558874322993818

Epoch: 6| Step: 1
Training loss: 2.0209973324432964
Validation loss: 2.5038890778202587

Epoch: 6| Step: 2
Training loss: 1.5681024438323625
Validation loss: 2.4698853618939225

Epoch: 6| Step: 3
Training loss: 1.811069910904388
Validation loss: 2.477667351977356

Epoch: 6| Step: 4
Training loss: 1.4788702636467501
Validation loss: 2.491241366006018

Epoch: 6| Step: 5
Training loss: 1.0205001027669298
Validation loss: 2.517939343792564

Epoch: 6| Step: 6
Training loss: 1.5570910865781888
Validation loss: 2.4724958130226935

Epoch: 6| Step: 7
Training loss: 2.0794641295978584
Validation loss: 2.4274289534990907

Epoch: 6| Step: 8
Training loss: 1.5572980117243316
Validation loss: 2.4416817773372883

Epoch: 6| Step: 9
Training loss: 2.371510803648444
Validation loss: 2.4840980602964433

Epoch: 6| Step: 10
Training loss: 1.6550119199064244
Validation loss: 2.5348248726787554

Epoch: 6| Step: 11
Training loss: 1.327665406534828
Validation loss: 2.525554259231865

Epoch: 6| Step: 12
Training loss: 1.1436008668822197
Validation loss: 2.4755525608785587

Epoch: 6| Step: 13
Training loss: 1.40984300848658
Validation loss: 2.535092874052059

Epoch: 561| Step: 0
Training loss: 0.7400339705814818
Validation loss: 2.453399073340045

Epoch: 6| Step: 1
Training loss: 1.9547134043976648
Validation loss: 2.471157011174513

Epoch: 6| Step: 2
Training loss: 1.452928345201818
Validation loss: 2.479481326993826

Epoch: 6| Step: 3
Training loss: 1.3033928758202622
Validation loss: 2.5053568555882064

Epoch: 6| Step: 4
Training loss: 1.5090006362074413
Validation loss: 2.5390493923003525

Epoch: 6| Step: 5
Training loss: 1.2714043986164147
Validation loss: 2.4799273564684685

Epoch: 6| Step: 6
Training loss: 2.200402275066798
Validation loss: 2.5028722424698477

Epoch: 6| Step: 7
Training loss: 1.6718072610127201
Validation loss: 2.488492437246845

Epoch: 6| Step: 8
Training loss: 2.1328259142778707
Validation loss: 2.563141437147776

Epoch: 6| Step: 9
Training loss: 2.045914169651625
Validation loss: 2.510055711772863

Epoch: 6| Step: 10
Training loss: 1.3627773982449807
Validation loss: 2.4712925667741876

Epoch: 6| Step: 11
Training loss: 1.7296888949311928
Validation loss: 2.4909699012506636

Epoch: 6| Step: 12
Training loss: 1.585278679569489
Validation loss: 2.5037973625436334

Epoch: 6| Step: 13
Training loss: 1.7045145927872065
Validation loss: 2.5267493016816416

Epoch: 562| Step: 0
Training loss: 0.8936227241003691
Validation loss: 2.4760856620954517

Epoch: 6| Step: 1
Training loss: 1.3368357265530098
Validation loss: 2.4980828266121904

Epoch: 6| Step: 2
Training loss: 1.9728766894158958
Validation loss: 2.583380942512966

Epoch: 6| Step: 3
Training loss: 1.8722655384072455
Validation loss: 2.5393359227780277

Epoch: 6| Step: 4
Training loss: 1.4480749999639624
Validation loss: 2.5554968106528357

Epoch: 6| Step: 5
Training loss: 1.8218927032500465
Validation loss: 2.4248375616122853

Epoch: 6| Step: 6
Training loss: 2.421976788750582
Validation loss: 2.4985138259634483

Epoch: 6| Step: 7
Training loss: 1.2037952092159203
Validation loss: 2.4760502297439393

Epoch: 6| Step: 8
Training loss: 1.5816587409868361
Validation loss: 2.5036194749267557

Epoch: 6| Step: 9
Training loss: 1.8365507359734017
Validation loss: 2.473968388915338

Epoch: 6| Step: 10
Training loss: 1.5264359139597934
Validation loss: 2.5230071572244235

Epoch: 6| Step: 11
Training loss: 1.2907801426336833
Validation loss: 2.50316803177907

Epoch: 6| Step: 12
Training loss: 1.557140925669941
Validation loss: 2.474318403498816

Epoch: 6| Step: 13
Training loss: 1.1797511607797146
Validation loss: 2.436972643881268

Epoch: 563| Step: 0
Training loss: 2.304089174352929
Validation loss: 2.4925381039697587

Epoch: 6| Step: 1
Training loss: 1.7810231114493842
Validation loss: 2.480728090639663

Epoch: 6| Step: 2
Training loss: 1.4171528636396706
Validation loss: 2.49106312874676

Epoch: 6| Step: 3
Training loss: 1.27311913190715
Validation loss: 2.464023760322523

Epoch: 6| Step: 4
Training loss: 1.8757431464910852
Validation loss: 2.4519129514450344

Epoch: 6| Step: 5
Training loss: 1.3431366252440444
Validation loss: 2.5079231302974345

Epoch: 6| Step: 6
Training loss: 2.3764447285239965
Validation loss: 2.493388953060981

Epoch: 6| Step: 7
Training loss: 1.5645382366293008
Validation loss: 2.460747231509607

Epoch: 6| Step: 8
Training loss: 1.371758802354761
Validation loss: 2.572264937313527

Epoch: 6| Step: 9
Training loss: 1.5046806422440753
Validation loss: 2.470715411897116

Epoch: 6| Step: 10
Training loss: 1.0151872131501314
Validation loss: 2.5543884090220765

Epoch: 6| Step: 11
Training loss: 1.7113742358054354
Validation loss: 2.474256604558533

Epoch: 6| Step: 12
Training loss: 1.2649091415042373
Validation loss: 2.503713548700157

Epoch: 6| Step: 13
Training loss: 1.6722321886347897
Validation loss: 2.5029301975794134

Epoch: 564| Step: 0
Training loss: 1.815258163713287
Validation loss: 2.5445246931568857

Epoch: 6| Step: 1
Training loss: 2.5468317507950755
Validation loss: 2.500732426360057

Epoch: 6| Step: 2
Training loss: 1.82875487081175
Validation loss: 2.513486427678024

Epoch: 6| Step: 3
Training loss: 1.731103096248195
Validation loss: 2.469614948297399

Epoch: 6| Step: 4
Training loss: 1.251885232259877
Validation loss: 2.4969839504736298

Epoch: 6| Step: 5
Training loss: 1.442002914700889
Validation loss: 2.468068415204369

Epoch: 6| Step: 6
Training loss: 1.6067667445332228
Validation loss: 2.52638945312917

Epoch: 6| Step: 7
Training loss: 1.689995792090239
Validation loss: 2.5212919119312764

Epoch: 6| Step: 8
Training loss: 1.4898774005708286
Validation loss: 2.520768630450743

Epoch: 6| Step: 9
Training loss: 1.6144096363116511
Validation loss: 2.4495069436251224

Epoch: 6| Step: 10
Training loss: 1.4620988279304166
Validation loss: 2.509857720741476

Epoch: 6| Step: 11
Training loss: 1.3653807991321667
Validation loss: 2.4518532616191617

Epoch: 6| Step: 12
Training loss: 1.1551678722967695
Validation loss: 2.520881629656795

Epoch: 6| Step: 13
Training loss: 2.1655135265025653
Validation loss: 2.507124735365525

Epoch: 565| Step: 0
Training loss: 2.0199918535276007
Validation loss: 2.436652575509167

Epoch: 6| Step: 1
Training loss: 1.7885964132145669
Validation loss: 2.517075758449289

Epoch: 6| Step: 2
Training loss: 2.1468808725157356
Validation loss: 2.468730156433099

Epoch: 6| Step: 3
Training loss: 1.4686963497671035
Validation loss: 2.4527738252008824

Epoch: 6| Step: 4
Training loss: 1.8015008179691605
Validation loss: 2.497461061336811

Epoch: 6| Step: 5
Training loss: 1.5037685578961821
Validation loss: 2.5020202872084663

Epoch: 6| Step: 6
Training loss: 1.80910687345882
Validation loss: 2.4976109194979648

Epoch: 6| Step: 7
Training loss: 0.9509002799109627
Validation loss: 2.461402200452124

Epoch: 6| Step: 8
Training loss: 1.5168287078872964
Validation loss: 2.5368973408785216

Epoch: 6| Step: 9
Training loss: 1.4387186938209815
Validation loss: 2.517390030489815

Epoch: 6| Step: 10
Training loss: 1.5500448097396822
Validation loss: 2.433999091906059

Epoch: 6| Step: 11
Training loss: 1.4640035025028377
Validation loss: 2.449522130711664

Epoch: 6| Step: 12
Training loss: 1.612009651088931
Validation loss: 2.537302079062533

Epoch: 6| Step: 13
Training loss: 1.222691349586043
Validation loss: 2.4843928591271465

Epoch: 566| Step: 0
Training loss: 1.6362650021534833
Validation loss: 2.490768930517658

Epoch: 6| Step: 1
Training loss: 1.2520726663110762
Validation loss: 2.5054107206316916

Epoch: 6| Step: 2
Training loss: 1.2134856455346474
Validation loss: 2.5380079307317494

Epoch: 6| Step: 3
Training loss: 1.5919232838994752
Validation loss: 2.5623726961981843

Epoch: 6| Step: 4
Training loss: 1.5388723343067012
Validation loss: 2.5319801512086997

Epoch: 6| Step: 5
Training loss: 1.3551510045413973
Validation loss: 2.5249110325284176

Epoch: 6| Step: 6
Training loss: 1.7667509556702021
Validation loss: 2.5357356638389024

Epoch: 6| Step: 7
Training loss: 2.367297683014818
Validation loss: 2.561560800083852

Epoch: 6| Step: 8
Training loss: 1.5585396740550552
Validation loss: 2.5412529504940853

Epoch: 6| Step: 9
Training loss: 1.9675368552530788
Validation loss: 2.5388969605960208

Epoch: 6| Step: 10
Training loss: 1.6608425023498448
Validation loss: 2.5587943711007886

Epoch: 6| Step: 11
Training loss: 1.9214397650912773
Validation loss: 2.515263918709457

Epoch: 6| Step: 12
Training loss: 1.4100261427437526
Validation loss: 2.481180702945141

Epoch: 6| Step: 13
Training loss: 1.3781937008988487
Validation loss: 2.4636233708911077

Epoch: 567| Step: 0
Training loss: 1.6381215932287416
Validation loss: 2.4925163094052216

Epoch: 6| Step: 1
Training loss: 1.6849934364440045
Validation loss: 2.5007239185766568

Epoch: 6| Step: 2
Training loss: 1.7792732915561122
Validation loss: 2.536575632709373

Epoch: 6| Step: 3
Training loss: 1.9594264800930634
Validation loss: 2.5142290964280476

Epoch: 6| Step: 4
Training loss: 1.516625850603366
Validation loss: 2.483946502400288

Epoch: 6| Step: 5
Training loss: 1.906826745006906
Validation loss: 2.519352887431765

Epoch: 6| Step: 6
Training loss: 1.0308032946783015
Validation loss: 2.492632257589922

Epoch: 6| Step: 7
Training loss: 1.719241817506481
Validation loss: 2.4653934825008363

Epoch: 6| Step: 8
Training loss: 2.0191025417261814
Validation loss: 2.4667167686616716

Epoch: 6| Step: 9
Training loss: 1.5781720598210387
Validation loss: 2.5109181043523323

Epoch: 6| Step: 10
Training loss: 1.0736632974455904
Validation loss: 2.4857780986809117

Epoch: 6| Step: 11
Training loss: 1.485891430899777
Validation loss: 2.5151532407927513

Epoch: 6| Step: 12
Training loss: 1.7111244970406327
Validation loss: 2.562086250523475

Epoch: 6| Step: 13
Training loss: 1.8693253795551612
Validation loss: 2.4853094934397677

Epoch: 568| Step: 0
Training loss: 1.5655670581687158
Validation loss: 2.464008432161428

Epoch: 6| Step: 1
Training loss: 1.798697302220657
Validation loss: 2.494616535712407

Epoch: 6| Step: 2
Training loss: 2.020238520070963
Validation loss: 2.5217870696112237

Epoch: 6| Step: 3
Training loss: 1.577918766256379
Validation loss: 2.498638484768961

Epoch: 6| Step: 4
Training loss: 0.9596660234736886
Validation loss: 2.4752128890694816

Epoch: 6| Step: 5
Training loss: 1.8136061877306233
Validation loss: 2.514193690775996

Epoch: 6| Step: 6
Training loss: 1.11505777594211
Validation loss: 2.542738242946238

Epoch: 6| Step: 7
Training loss: 1.5923313483937294
Validation loss: 2.4920862561583936

Epoch: 6| Step: 8
Training loss: 1.696968921851109
Validation loss: 2.4249833963897935

Epoch: 6| Step: 9
Training loss: 1.3985242763426653
Validation loss: 2.588006234816853

Epoch: 6| Step: 10
Training loss: 1.7280649405833366
Validation loss: 2.4696997096567967

Epoch: 6| Step: 11
Training loss: 1.5206379525432225
Validation loss: 2.508473551419815

Epoch: 6| Step: 12
Training loss: 1.821132229758894
Validation loss: 2.506872517778391

Epoch: 6| Step: 13
Training loss: 1.5850492348229264
Validation loss: 2.5403903817684883

Epoch: 569| Step: 0
Training loss: 1.4298314923592774
Validation loss: 2.5066279474560194

Epoch: 6| Step: 1
Training loss: 1.7077526951096926
Validation loss: 2.448518660615725

Epoch: 6| Step: 2
Training loss: 2.3895866782030035
Validation loss: 2.5251463730788384

Epoch: 6| Step: 3
Training loss: 1.773344869337109
Validation loss: 2.4618741108882904

Epoch: 6| Step: 4
Training loss: 1.6767044903158872
Validation loss: 2.5358718450406608

Epoch: 6| Step: 5
Training loss: 1.4517561505165888
Validation loss: 2.4714578441055757

Epoch: 6| Step: 6
Training loss: 1.4400456320632053
Validation loss: 2.472651021431171

Epoch: 6| Step: 7
Training loss: 1.5053497916764371
Validation loss: 2.5240666867267323

Epoch: 6| Step: 8
Training loss: 1.4876746195390327
Validation loss: 2.475564792121483

Epoch: 6| Step: 9
Training loss: 1.6030553791477393
Validation loss: 2.518372229169343

Epoch: 6| Step: 10
Training loss: 0.7022969986713083
Validation loss: 2.523715607205828

Epoch: 6| Step: 11
Training loss: 1.9043064528004332
Validation loss: 2.5160812690761856

Epoch: 6| Step: 12
Training loss: 1.9144454884294106
Validation loss: 2.5352641779056078

Epoch: 6| Step: 13
Training loss: 1.5754271760536378
Validation loss: 2.437820284162612

Epoch: 570| Step: 0
Training loss: 2.2099445391293946
Validation loss: 2.4727586045508487

Epoch: 6| Step: 1
Training loss: 1.6797657083445954
Validation loss: 2.5329787826189354

Epoch: 6| Step: 2
Training loss: 1.0448417846788989
Validation loss: 2.4865422654570164

Epoch: 6| Step: 3
Training loss: 1.4095554075633092
Validation loss: 2.5174065952814746

Epoch: 6| Step: 4
Training loss: 1.7668446067352288
Validation loss: 2.5031177768447126

Epoch: 6| Step: 5
Training loss: 1.9376580573800197
Validation loss: 2.56230703888426

Epoch: 6| Step: 6
Training loss: 1.437335129280832
Validation loss: 2.5471267490213547

Epoch: 6| Step: 7
Training loss: 1.1862905768317258
Validation loss: 2.4856747228812486

Epoch: 6| Step: 8
Training loss: 1.7661203685362012
Validation loss: 2.484421648921418

Epoch: 6| Step: 9
Training loss: 1.9657145517688077
Validation loss: 2.5352976552413797

Epoch: 6| Step: 10
Training loss: 1.2360776915777134
Validation loss: 2.5189065932031185

Epoch: 6| Step: 11
Training loss: 1.6173386065519515
Validation loss: 2.4899760471276995

Epoch: 6| Step: 12
Training loss: 1.39959489887831
Validation loss: 2.5026654933638866

Epoch: 6| Step: 13
Training loss: 1.8633342231561838
Validation loss: 2.508329485205286

Epoch: 571| Step: 0
Training loss: 1.7967480158510263
Validation loss: 2.5115899562819215

Epoch: 6| Step: 1
Training loss: 1.516161951337358
Validation loss: 2.524616840206409

Epoch: 6| Step: 2
Training loss: 1.3005348865797248
Validation loss: 2.45695422577897

Epoch: 6| Step: 3
Training loss: 1.8087096208073652
Validation loss: 2.5034409377126603

Epoch: 6| Step: 4
Training loss: 1.5333667060426854
Validation loss: 2.4391762496949627

Epoch: 6| Step: 5
Training loss: 1.653689150105237
Validation loss: 2.469634834582083

Epoch: 6| Step: 6
Training loss: 1.3769133000668121
Validation loss: 2.5163329436624693

Epoch: 6| Step: 7
Training loss: 1.4377539037294278
Validation loss: 2.5087159991988

Epoch: 6| Step: 8
Training loss: 1.3824824138578253
Validation loss: 2.531503961630628

Epoch: 6| Step: 9
Training loss: 1.8385463927066854
Validation loss: 2.470820706901445

Epoch: 6| Step: 10
Training loss: 1.8927140477426105
Validation loss: 2.459041656791583

Epoch: 6| Step: 11
Training loss: 1.3319468093911184
Validation loss: 2.496126660926907

Epoch: 6| Step: 12
Training loss: 1.9787024572640866
Validation loss: 2.4217357551804306

Epoch: 6| Step: 13
Training loss: 1.901609933303868
Validation loss: 2.5091052675116026

Epoch: 572| Step: 0
Training loss: 1.7273236146302822
Validation loss: 2.4915185375700912

Epoch: 6| Step: 1
Training loss: 1.6434508192817785
Validation loss: 2.548633824484062

Epoch: 6| Step: 2
Training loss: 1.0411189673912293
Validation loss: 2.5125553523556694

Epoch: 6| Step: 3
Training loss: 1.3696715540374382
Validation loss: 2.506980623340526

Epoch: 6| Step: 4
Training loss: 1.4864487467480958
Validation loss: 2.4919027229500124

Epoch: 6| Step: 5
Training loss: 1.4796136082343394
Validation loss: 2.5133855113994517

Epoch: 6| Step: 6
Training loss: 1.6603020099155572
Validation loss: 2.5045106127828567

Epoch: 6| Step: 7
Training loss: 1.7314452436504146
Validation loss: 2.4618524926369623

Epoch: 6| Step: 8
Training loss: 1.9027569770449502
Validation loss: 2.480137182555618

Epoch: 6| Step: 9
Training loss: 1.5573528196986042
Validation loss: 2.5141412038828848

Epoch: 6| Step: 10
Training loss: 1.34893737933799
Validation loss: 2.469039320591306

Epoch: 6| Step: 11
Training loss: 2.531699811740637
Validation loss: 2.4542048731700703

Epoch: 6| Step: 12
Training loss: 1.3379292503405893
Validation loss: 2.5053014882260807

Epoch: 6| Step: 13
Training loss: 1.6392950571211267
Validation loss: 2.522175153021725

Epoch: 573| Step: 0
Training loss: 2.1293623409449185
Validation loss: 2.512259723355451

Epoch: 6| Step: 1
Training loss: 1.8279735795914356
Validation loss: 2.48842905967163

Epoch: 6| Step: 2
Training loss: 1.9585802720667096
Validation loss: 2.489462492008589

Epoch: 6| Step: 3
Training loss: 1.5478457092752105
Validation loss: 2.499217899589849

Epoch: 6| Step: 4
Training loss: 1.3589674239980571
Validation loss: 2.504253137214278

Epoch: 6| Step: 5
Training loss: 1.8035614331735976
Validation loss: 2.486075652681538

Epoch: 6| Step: 6
Training loss: 1.748414274850633
Validation loss: 2.5003532734319234

Epoch: 6| Step: 7
Training loss: 1.1415069514767642
Validation loss: 2.4742575961305437

Epoch: 6| Step: 8
Training loss: 1.800885840831268
Validation loss: 2.5179662991768135

Epoch: 6| Step: 9
Training loss: 1.5835768696393884
Validation loss: 2.4707085890788374

Epoch: 6| Step: 10
Training loss: 1.9227046261389764
Validation loss: 2.5354407512823776

Epoch: 6| Step: 11
Training loss: 1.2278972094163236
Validation loss: 2.465112392807981

Epoch: 6| Step: 12
Training loss: 1.1502433643742473
Validation loss: 2.4713937579080305

Epoch: 6| Step: 13
Training loss: 1.2482309698162772
Validation loss: 2.455850087057009

Epoch: 574| Step: 0
Training loss: 1.8906821250167005
Validation loss: 2.5571296496381217

Epoch: 6| Step: 1
Training loss: 1.3780357487640973
Validation loss: 2.5410433475108025

Epoch: 6| Step: 2
Training loss: 2.0291228674117954
Validation loss: 2.5592790334853563

Epoch: 6| Step: 3
Training loss: 1.448526469011527
Validation loss: 2.5260182697484166

Epoch: 6| Step: 4
Training loss: 1.2587703114512063
Validation loss: 2.5290414190620853

Epoch: 6| Step: 5
Training loss: 1.3465688105161107
Validation loss: 2.504401740343042

Epoch: 6| Step: 6
Training loss: 1.2162740940636114
Validation loss: 2.503359989602034

Epoch: 6| Step: 7
Training loss: 2.180377591181058
Validation loss: 2.5630388201121668

Epoch: 6| Step: 8
Training loss: 2.0321243751714047
Validation loss: 2.532729076908381

Epoch: 6| Step: 9
Training loss: 1.4942717849907472
Validation loss: 2.5421856912231

Epoch: 6| Step: 10
Training loss: 1.4935749254617727
Validation loss: 2.5236280450554838

Epoch: 6| Step: 11
Training loss: 1.741098243031802
Validation loss: 2.4504695471684688

Epoch: 6| Step: 12
Training loss: 1.2553834858909225
Validation loss: 2.5226717587481966

Epoch: 6| Step: 13
Training loss: 1.4393147333459027
Validation loss: 2.506081403633721

Epoch: 575| Step: 0
Training loss: 1.4734595255656753
Validation loss: 2.4689460667191065

Epoch: 6| Step: 1
Training loss: 1.520672445627147
Validation loss: 2.4974066008788074

Epoch: 6| Step: 2
Training loss: 1.7386424857273761
Validation loss: 2.521071476079117

Epoch: 6| Step: 3
Training loss: 1.5725659196194168
Validation loss: 2.5009131896697854

Epoch: 6| Step: 4
Training loss: 1.8051267807624634
Validation loss: 2.4444186336131013

Epoch: 6| Step: 5
Training loss: 1.8057251956508364
Validation loss: 2.513408340823689

Epoch: 6| Step: 6
Training loss: 1.6655206873080486
Validation loss: 2.515590524051878

Epoch: 6| Step: 7
Training loss: 1.4066649778334859
Validation loss: 2.5207122306511605

Epoch: 6| Step: 8
Training loss: 1.4048156628894497
Validation loss: 2.4702889705535545

Epoch: 6| Step: 9
Training loss: 1.5907567657274067
Validation loss: 2.520063449149886

Epoch: 6| Step: 10
Training loss: 2.306024609642026
Validation loss: 2.476093771023542

Epoch: 6| Step: 11
Training loss: 1.4988319299493988
Validation loss: 2.4686462122994968

Epoch: 6| Step: 12
Training loss: 1.2247570380783235
Validation loss: 2.4905735658152555

Epoch: 6| Step: 13
Training loss: 0.9210188494668015
Validation loss: 2.4797225484746326

Epoch: 576| Step: 0
Training loss: 1.4744465516998506
Validation loss: 2.548107087002185

Epoch: 6| Step: 1
Training loss: 1.6915534045758729
Validation loss: 2.4874509051635223

Epoch: 6| Step: 2
Training loss: 1.9758760368444357
Validation loss: 2.509626595520045

Epoch: 6| Step: 3
Training loss: 1.611913808094385
Validation loss: 2.468373720780702

Epoch: 6| Step: 4
Training loss: 1.406658452373102
Validation loss: 2.50429238203177

Epoch: 6| Step: 5
Training loss: 1.6741642475379692
Validation loss: 2.5096276252147556

Epoch: 6| Step: 6
Training loss: 1.2388647972828413
Validation loss: 2.5053055220173417

Epoch: 6| Step: 7
Training loss: 1.7050140823274917
Validation loss: 2.538881403394253

Epoch: 6| Step: 8
Training loss: 2.1026576709026745
Validation loss: 2.469426759251053

Epoch: 6| Step: 9
Training loss: 1.4986261593111552
Validation loss: 2.5316874608288273

Epoch: 6| Step: 10
Training loss: 1.7221190291768673
Validation loss: 2.540353084741763

Epoch: 6| Step: 11
Training loss: 1.344720091073526
Validation loss: 2.4780808857362224

Epoch: 6| Step: 12
Training loss: 1.6050885346614256
Validation loss: 2.4853742621055046

Epoch: 6| Step: 13
Training loss: 1.2308724846076695
Validation loss: 2.5054533086110373

Epoch: 577| Step: 0
Training loss: 1.0632433254589448
Validation loss: 2.461326502486483

Epoch: 6| Step: 1
Training loss: 1.5564144645101137
Validation loss: 2.460204047934559

Epoch: 6| Step: 2
Training loss: 1.6411595518200017
Validation loss: 2.514483452257133

Epoch: 6| Step: 3
Training loss: 1.6106318038542111
Validation loss: 2.489683034346153

Epoch: 6| Step: 4
Training loss: 1.9036021368923326
Validation loss: 2.4783254036945928

Epoch: 6| Step: 5
Training loss: 1.5957498158379038
Validation loss: 2.4743287054170082

Epoch: 6| Step: 6
Training loss: 1.818119545433698
Validation loss: 2.515782730353996

Epoch: 6| Step: 7
Training loss: 1.775705911739146
Validation loss: 2.4340334248705604

Epoch: 6| Step: 8
Training loss: 1.306640761850119
Validation loss: 2.46897427033609

Epoch: 6| Step: 9
Training loss: 1.3920029660253606
Validation loss: 2.496130174453916

Epoch: 6| Step: 10
Training loss: 1.6932489167720677
Validation loss: 2.49026938522986

Epoch: 6| Step: 11
Training loss: 1.5136399001159095
Validation loss: 2.5160025933159704

Epoch: 6| Step: 12
Training loss: 2.105451990743828
Validation loss: 2.438874639837511

Epoch: 6| Step: 13
Training loss: 2.118103617416426
Validation loss: 2.445136881066659

Epoch: 578| Step: 0
Training loss: 0.9329051267300046
Validation loss: 2.5338416409352313

Epoch: 6| Step: 1
Training loss: 1.6329702638767456
Validation loss: 2.478909739162704

Epoch: 6| Step: 2
Training loss: 1.789547383928392
Validation loss: 2.5048849290088313

Epoch: 6| Step: 3
Training loss: 1.4859009779363832
Validation loss: 2.522548755616177

Epoch: 6| Step: 4
Training loss: 1.2178857135178145
Validation loss: 2.5215080979887885

Epoch: 6| Step: 5
Training loss: 1.504546586486508
Validation loss: 2.4925000687822974

Epoch: 6| Step: 6
Training loss: 1.1857542456772663
Validation loss: 2.479579602296154

Epoch: 6| Step: 7
Training loss: 2.5000591271084143
Validation loss: 2.5247264269967626

Epoch: 6| Step: 8
Training loss: 1.567313447647365
Validation loss: 2.5024357891524946

Epoch: 6| Step: 9
Training loss: 1.1618608481462043
Validation loss: 2.5690930256369446

Epoch: 6| Step: 10
Training loss: 2.047580510048236
Validation loss: 2.529160874464143

Epoch: 6| Step: 11
Training loss: 2.0747290376899787
Validation loss: 2.557253420997634

Epoch: 6| Step: 12
Training loss: 1.5866278287531317
Validation loss: 2.522582934227763

Epoch: 6| Step: 13
Training loss: 0.9513758258587945
Validation loss: 2.5260624426209466

Epoch: 579| Step: 0
Training loss: 1.9535416425724144
Validation loss: 2.529235400724037

Epoch: 6| Step: 1
Training loss: 1.5364627471688013
Validation loss: 2.471143601379581

Epoch: 6| Step: 2
Training loss: 1.5208557162096568
Validation loss: 2.4915738068475672

Epoch: 6| Step: 3
Training loss: 1.7428237369114223
Validation loss: 2.48824514440533

Epoch: 6| Step: 4
Training loss: 2.202895781584759
Validation loss: 2.4872140634414643

Epoch: 6| Step: 5
Training loss: 1.5554551572794932
Validation loss: 2.492843045378624

Epoch: 6| Step: 6
Training loss: 1.394315131187564
Validation loss: 2.4673662358787856

Epoch: 6| Step: 7
Training loss: 1.2047551988314174
Validation loss: 2.5237333047587622

Epoch: 6| Step: 8
Training loss: 1.4177952179455595
Validation loss: 2.507145106366828

Epoch: 6| Step: 9
Training loss: 1.8712558875185605
Validation loss: 2.5156617378166763

Epoch: 6| Step: 10
Training loss: 1.3295310263454776
Validation loss: 2.522117480552428

Epoch: 6| Step: 11
Training loss: 1.569480713656836
Validation loss: 2.4889146766102455

Epoch: 6| Step: 12
Training loss: 1.6820080009161293
Validation loss: 2.4626470677311416

Epoch: 6| Step: 13
Training loss: 0.8083781079217364
Validation loss: 2.5232494744795697

Epoch: 580| Step: 0
Training loss: 1.4242176417913013
Validation loss: 2.5196756138246084

Epoch: 6| Step: 1
Training loss: 1.2498676229954142
Validation loss: 2.4713403744684803

Epoch: 6| Step: 2
Training loss: 1.5035116891866436
Validation loss: 2.4634432071970602

Epoch: 6| Step: 3
Training loss: 1.31724517080595
Validation loss: 2.4659542937964596

Epoch: 6| Step: 4
Training loss: 1.652675586322957
Validation loss: 2.4612210309805254

Epoch: 6| Step: 5
Training loss: 2.0489202865949454
Validation loss: 2.467167492614026

Epoch: 6| Step: 6
Training loss: 2.3108271141074024
Validation loss: 2.5284190509585764

Epoch: 6| Step: 7
Training loss: 1.3596571706178542
Validation loss: 2.501061510510105

Epoch: 6| Step: 8
Training loss: 1.3717929546179173
Validation loss: 2.5332184838055274

Epoch: 6| Step: 9
Training loss: 1.7098758835393213
Validation loss: 2.51454207057898

Epoch: 6| Step: 10
Training loss: 1.355609106003205
Validation loss: 2.4444098889269172

Epoch: 6| Step: 11
Training loss: 1.7803894105636189
Validation loss: 2.4719175042492205

Epoch: 6| Step: 12
Training loss: 1.2275768872050088
Validation loss: 2.4804314919715127

Epoch: 6| Step: 13
Training loss: 1.8216709421822554
Validation loss: 2.5269762798984035

Epoch: 581| Step: 0
Training loss: 1.343666517636376
Validation loss: 2.5076182228861694

Epoch: 6| Step: 1
Training loss: 1.4999909400666334
Validation loss: 2.5037201213320976

Epoch: 6| Step: 2
Training loss: 1.5002028010285366
Validation loss: 2.470939089358274

Epoch: 6| Step: 3
Training loss: 2.2424460870052147
Validation loss: 2.483820521007934

Epoch: 6| Step: 4
Training loss: 1.798425287624492
Validation loss: 2.4484622948543606

Epoch: 6| Step: 5
Training loss: 1.7929841749404578
Validation loss: 2.432091797865228

Epoch: 6| Step: 6
Training loss: 1.078783801489643
Validation loss: 2.5181464066815944

Epoch: 6| Step: 7
Training loss: 1.6506707850919957
Validation loss: 2.5141762564471595

Epoch: 6| Step: 8
Training loss: 1.7876265314307807
Validation loss: 2.5040797589934356

Epoch: 6| Step: 9
Training loss: 1.7315243500185122
Validation loss: 2.4939812966759116

Epoch: 6| Step: 10
Training loss: 1.6756968799328678
Validation loss: 2.4899785994662595

Epoch: 6| Step: 11
Training loss: 1.4863788129908229
Validation loss: 2.50947218249994

Epoch: 6| Step: 12
Training loss: 1.3455735187099738
Validation loss: 2.4869370584778543

Epoch: 6| Step: 13
Training loss: 1.5314567582031475
Validation loss: 2.5369510071507047

Epoch: 582| Step: 0
Training loss: 1.685679690188447
Validation loss: 2.4674119283984792

Epoch: 6| Step: 1
Training loss: 1.6430416655130253
Validation loss: 2.480062393416827

Epoch: 6| Step: 2
Training loss: 1.2103972183389715
Validation loss: 2.470865662171027

Epoch: 6| Step: 3
Training loss: 1.456974304559112
Validation loss: 2.452707765543967

Epoch: 6| Step: 4
Training loss: 1.8355211150997557
Validation loss: 2.417869466037136

Epoch: 6| Step: 5
Training loss: 2.321654063581046
Validation loss: 2.519583258315043

Epoch: 6| Step: 6
Training loss: 1.4751480028285378
Validation loss: 2.4838045166551925

Epoch: 6| Step: 7
Training loss: 1.2410192214005962
Validation loss: 2.509391914214332

Epoch: 6| Step: 8
Training loss: 1.4808837792014033
Validation loss: 2.504534783667069

Epoch: 6| Step: 9
Training loss: 1.629253103527504
Validation loss: 2.4525384096469494

Epoch: 6| Step: 10
Training loss: 1.2941400575737323
Validation loss: 2.448586423664594

Epoch: 6| Step: 11
Training loss: 1.4168618666112116
Validation loss: 2.5093544665170926

Epoch: 6| Step: 12
Training loss: 2.18600325468472
Validation loss: 2.4826225342371893

Epoch: 6| Step: 13
Training loss: 1.3500339044622665
Validation loss: 2.5442311263497155

Epoch: 583| Step: 0
Training loss: 2.009028085332868
Validation loss: 2.55704864262135

Epoch: 6| Step: 1
Training loss: 1.2927483777102602
Validation loss: 2.477118424587623

Epoch: 6| Step: 2
Training loss: 1.805478405730617
Validation loss: 2.5318834420444385

Epoch: 6| Step: 3
Training loss: 1.0092037563506566
Validation loss: 2.5072606745644754

Epoch: 6| Step: 4
Training loss: 1.1864183418605243
Validation loss: 2.485575653036593

Epoch: 6| Step: 5
Training loss: 1.295580850190324
Validation loss: 2.4770757737790357

Epoch: 6| Step: 6
Training loss: 1.6099781276567713
Validation loss: 2.5299194426209275

Epoch: 6| Step: 7
Training loss: 1.5332470541328158
Validation loss: 2.5387361958910026

Epoch: 6| Step: 8
Training loss: 1.7754326575143333
Validation loss: 2.4649407836188524

Epoch: 6| Step: 9
Training loss: 2.310106946608067
Validation loss: 2.4785931769179625

Epoch: 6| Step: 10
Training loss: 1.5886303819575263
Validation loss: 2.4969341717029208

Epoch: 6| Step: 11
Training loss: 1.734353898753428
Validation loss: 2.5569058013483814

Epoch: 6| Step: 12
Training loss: 1.407457045582316
Validation loss: 2.4707000100753613

Epoch: 6| Step: 13
Training loss: 0.7154232240427091
Validation loss: 2.5233746231918057

Epoch: 584| Step: 0
Training loss: 1.655528217163914
Validation loss: 2.570342437911898

Epoch: 6| Step: 1
Training loss: 1.4145072954029503
Validation loss: 2.475160540887336

Epoch: 6| Step: 2
Training loss: 2.3238261428185885
Validation loss: 2.4849966371350543

Epoch: 6| Step: 3
Training loss: 1.5524814615663145
Validation loss: 2.4596303577584195

Epoch: 6| Step: 4
Training loss: 1.0803046377004597
Validation loss: 2.4767135305440746

Epoch: 6| Step: 5
Training loss: 1.4066713337722903
Validation loss: 2.4588244248165236

Epoch: 6| Step: 6
Training loss: 1.338022935548138
Validation loss: 2.4869397232045185

Epoch: 6| Step: 7
Training loss: 1.8228195019212605
Validation loss: 2.5218894581445666

Epoch: 6| Step: 8
Training loss: 1.2409775317153862
Validation loss: 2.504615186631617

Epoch: 6| Step: 9
Training loss: 1.7152016511704553
Validation loss: 2.547705566676785

Epoch: 6| Step: 10
Training loss: 1.5340367086064306
Validation loss: 2.5572934674591092

Epoch: 6| Step: 11
Training loss: 1.547694595994146
Validation loss: 2.5099012863390397

Epoch: 6| Step: 12
Training loss: 1.5904719730655217
Validation loss: 2.4697286613878853

Epoch: 6| Step: 13
Training loss: 1.9799355535904344
Validation loss: 2.4997981430925935

Epoch: 585| Step: 0
Training loss: 1.383320860442649
Validation loss: 2.487972077077976

Epoch: 6| Step: 1
Training loss: 1.4725230027686702
Validation loss: 2.4486730593430512

Epoch: 6| Step: 2
Training loss: 1.5722154313125398
Validation loss: 2.5333174826917357

Epoch: 6| Step: 3
Training loss: 1.7610919793243347
Validation loss: 2.528491484086309

Epoch: 6| Step: 4
Training loss: 1.290231994940849
Validation loss: 2.507117856715265

Epoch: 6| Step: 5
Training loss: 1.594331822126564
Validation loss: 2.4839438674892675

Epoch: 6| Step: 6
Training loss: 1.4038358098584587
Validation loss: 2.5229351417743873

Epoch: 6| Step: 7
Training loss: 2.101564882411812
Validation loss: 2.3966723281614577

Epoch: 6| Step: 8
Training loss: 1.431016898017455
Validation loss: 2.4556302441399964

Epoch: 6| Step: 9
Training loss: 1.1807526585962724
Validation loss: 2.409797201747173

Epoch: 6| Step: 10
Training loss: 1.4329593928427473
Validation loss: 2.441253412134675

Epoch: 6| Step: 11
Training loss: 1.4465779306442084
Validation loss: 2.44761468878824

Epoch: 6| Step: 12
Training loss: 2.2784833461411513
Validation loss: 2.501426526662075

Epoch: 6| Step: 13
Training loss: 1.1636263138942613
Validation loss: 2.4785109642363365

Epoch: 586| Step: 0
Training loss: 1.58291322589101
Validation loss: 2.490398414801859

Epoch: 6| Step: 1
Training loss: 2.264311521536942
Validation loss: 2.420605590185332

Epoch: 6| Step: 2
Training loss: 1.120824057010047
Validation loss: 2.469385298221612

Epoch: 6| Step: 3
Training loss: 1.7598718405792144
Validation loss: 2.4726133117488276

Epoch: 6| Step: 4
Training loss: 1.3927466677076512
Validation loss: 2.5136228509881673

Epoch: 6| Step: 5
Training loss: 1.3905820518462297
Validation loss: 2.4820007672906406

Epoch: 6| Step: 6
Training loss: 1.7394230553653414
Validation loss: 2.4676972389261818

Epoch: 6| Step: 7
Training loss: 1.0739275173399738
Validation loss: 2.46240324014867

Epoch: 6| Step: 8
Training loss: 1.7560180999674604
Validation loss: 2.4694701152176104

Epoch: 6| Step: 9
Training loss: 1.1179513520727082
Validation loss: 2.474560716711383

Epoch: 6| Step: 10
Training loss: 1.885820131355405
Validation loss: 2.5101909877263284

Epoch: 6| Step: 11
Training loss: 1.6248193787182168
Validation loss: 2.48783649076956

Epoch: 6| Step: 12
Training loss: 1.4822787289871344
Validation loss: 2.500168460379485

Epoch: 6| Step: 13
Training loss: 1.4844716893879244
Validation loss: 2.4969598271342193

Epoch: 587| Step: 0
Training loss: 1.4121497690588596
Validation loss: 2.457715926445112

Epoch: 6| Step: 1
Training loss: 1.276438494370882
Validation loss: 2.537454418656188

Epoch: 6| Step: 2
Training loss: 1.4398706211143055
Validation loss: 2.5148912196683586

Epoch: 6| Step: 3
Training loss: 1.2956724911352668
Validation loss: 2.4818804809147186

Epoch: 6| Step: 4
Training loss: 1.9858761613618763
Validation loss: 2.54350064575706

Epoch: 6| Step: 5
Training loss: 1.9100069639068993
Validation loss: 2.51992097438124

Epoch: 6| Step: 6
Training loss: 0.9437092829124933
Validation loss: 2.524990889708366

Epoch: 6| Step: 7
Training loss: 1.9877225019558173
Validation loss: 2.512728373279089

Epoch: 6| Step: 8
Training loss: 1.2675768083703678
Validation loss: 2.479854208858358

Epoch: 6| Step: 9
Training loss: 1.43401195444527
Validation loss: 2.4519193231254497

Epoch: 6| Step: 10
Training loss: 2.2153179865276917
Validation loss: 2.4681832080999073

Epoch: 6| Step: 11
Training loss: 1.4130344341939132
Validation loss: 2.5067334188601893

Epoch: 6| Step: 12
Training loss: 1.5514243687726077
Validation loss: 2.518341687690269

Epoch: 6| Step: 13
Training loss: 1.2793685776512507
Validation loss: 2.4986435758503447

Epoch: 588| Step: 0
Training loss: 1.4673702983304813
Validation loss: 2.4949593816570372

Epoch: 6| Step: 1
Training loss: 1.7813261584681839
Validation loss: 2.4388974046427285

Epoch: 6| Step: 2
Training loss: 1.3898965449220466
Validation loss: 2.518324044885202

Epoch: 6| Step: 3
Training loss: 1.3674651381740592
Validation loss: 2.4998075144509495

Epoch: 6| Step: 4
Training loss: 1.6735026199963123
Validation loss: 2.513567442341715

Epoch: 6| Step: 5
Training loss: 1.5749561485362098
Validation loss: 2.5211656175665667

Epoch: 6| Step: 6
Training loss: 1.3794023955804577
Validation loss: 2.4576628853397704

Epoch: 6| Step: 7
Training loss: 1.0530287520349597
Validation loss: 2.4767577588414906

Epoch: 6| Step: 8
Training loss: 1.1903587363975845
Validation loss: 2.4859064043521784

Epoch: 6| Step: 9
Training loss: 1.3090387754824349
Validation loss: 2.4993761063482247

Epoch: 6| Step: 10
Training loss: 1.673955745572375
Validation loss: 2.4697469969972974

Epoch: 6| Step: 11
Training loss: 2.5584398063182396
Validation loss: 2.5179382111001285

Epoch: 6| Step: 12
Training loss: 1.76895745344735
Validation loss: 2.4786058161880864

Epoch: 6| Step: 13
Training loss: 1.1459878239375934
Validation loss: 2.4951708780298008

Epoch: 589| Step: 0
Training loss: 1.6810499476422156
Validation loss: 2.457662822230928

Epoch: 6| Step: 1
Training loss: 1.6338077414129482
Validation loss: 2.4852535773329003

Epoch: 6| Step: 2
Training loss: 0.8389787344437014
Validation loss: 2.507192112827903

Epoch: 6| Step: 3
Training loss: 1.1988768944588606
Validation loss: 2.4814411681197286

Epoch: 6| Step: 4
Training loss: 2.0873836690502365
Validation loss: 2.4985668278779025

Epoch: 6| Step: 5
Training loss: 1.6905511892850626
Validation loss: 2.497663588512138

Epoch: 6| Step: 6
Training loss: 1.593858004631599
Validation loss: 2.484041737127858

Epoch: 6| Step: 7
Training loss: 1.218957394291115
Validation loss: 2.514639388555073

Epoch: 6| Step: 8
Training loss: 1.6802723420877954
Validation loss: 2.5134292535040625

Epoch: 6| Step: 9
Training loss: 1.452663717579981
Validation loss: 2.542072228651269

Epoch: 6| Step: 10
Training loss: 2.1234675098625586
Validation loss: 2.540651227165868

Epoch: 6| Step: 11
Training loss: 0.7959512704737141
Validation loss: 2.4952628317830814

Epoch: 6| Step: 12
Training loss: 1.7000717652824529
Validation loss: 2.5437979884409607

Epoch: 6| Step: 13
Training loss: 2.4591630623805143
Validation loss: 2.4942986080345615

Epoch: 590| Step: 0
Training loss: 1.6198271801685113
Validation loss: 2.519088068417216

Epoch: 6| Step: 1
Training loss: 1.4710863077762493
Validation loss: 2.485627190888874

Epoch: 6| Step: 2
Training loss: 1.3707185324202191
Validation loss: 2.5413010339448956

Epoch: 6| Step: 3
Training loss: 2.4311524908521998
Validation loss: 2.456912857913334

Epoch: 6| Step: 4
Training loss: 1.0038247873228667
Validation loss: 2.5088155378285744

Epoch: 6| Step: 5
Training loss: 1.5606118046665232
Validation loss: 2.492384282108158

Epoch: 6| Step: 6
Training loss: 1.2525570464705733
Validation loss: 2.48081073827401

Epoch: 6| Step: 7
Training loss: 1.9166816075060569
Validation loss: 2.512708612771907

Epoch: 6| Step: 8
Training loss: 1.3535913663647416
Validation loss: 2.5339537389786675

Epoch: 6| Step: 9
Training loss: 1.4582675464868717
Validation loss: 2.523443738830041

Epoch: 6| Step: 10
Training loss: 1.7512598271335862
Validation loss: 2.510021086812062

Epoch: 6| Step: 11
Training loss: 1.7295951618747991
Validation loss: 2.500647531757846

Epoch: 6| Step: 12
Training loss: 1.703910856315057
Validation loss: 2.461873188263523

Epoch: 6| Step: 13
Training loss: 1.749239074943329
Validation loss: 2.507421354219615

Epoch: 591| Step: 0
Training loss: 1.7545698987593992
Validation loss: 2.4779102667674002

Epoch: 6| Step: 1
Training loss: 1.255628597241077
Validation loss: 2.516303462466896

Epoch: 6| Step: 2
Training loss: 1.8209234039352857
Validation loss: 2.486301210695647

Epoch: 6| Step: 3
Training loss: 1.1182179533786067
Validation loss: 2.5445297156021343

Epoch: 6| Step: 4
Training loss: 1.612798068863984
Validation loss: 2.4993111892039477

Epoch: 6| Step: 5
Training loss: 1.1463243935008942
Validation loss: 2.5153392450346073

Epoch: 6| Step: 6
Training loss: 0.9861830500806881
Validation loss: 2.5370023188344453

Epoch: 6| Step: 7
Training loss: 1.4427001438757674
Validation loss: 2.502725311413821

Epoch: 6| Step: 8
Training loss: 1.1164692523923243
Validation loss: 2.4997246457299274

Epoch: 6| Step: 9
Training loss: 1.2494244204007305
Validation loss: 2.4886406320081615

Epoch: 6| Step: 10
Training loss: 1.5470386765323652
Validation loss: 2.493336018956302

Epoch: 6| Step: 11
Training loss: 1.7473963033009412
Validation loss: 2.5316805506916786

Epoch: 6| Step: 12
Training loss: 2.6528707213926968
Validation loss: 2.468038555878329

Epoch: 6| Step: 13
Training loss: 1.7750515755695684
Validation loss: 2.51422482713832

Epoch: 592| Step: 0
Training loss: 1.9265708929344696
Validation loss: 2.417068870888326

Epoch: 6| Step: 1
Training loss: 1.4174339610061122
Validation loss: 2.4416668123724463

Epoch: 6| Step: 2
Training loss: 1.4149273498540447
Validation loss: 2.4782748653335833

Epoch: 6| Step: 3
Training loss: 1.473070728854403
Validation loss: 2.4967893647049393

Epoch: 6| Step: 4
Training loss: 1.5516038533795493
Validation loss: 2.444867035300498

Epoch: 6| Step: 5
Training loss: 1.5706300177230257
Validation loss: 2.5119284637944452

Epoch: 6| Step: 6
Training loss: 1.469752355203495
Validation loss: 2.4755354581629807

Epoch: 6| Step: 7
Training loss: 1.4207062161915178
Validation loss: 2.4679501443528333

Epoch: 6| Step: 8
Training loss: 1.797432986987944
Validation loss: 2.4846862177020004

Epoch: 6| Step: 9
Training loss: 2.4580856995941116
Validation loss: 2.4628436369589193

Epoch: 6| Step: 10
Training loss: 1.5985867278692687
Validation loss: 2.472478031786781

Epoch: 6| Step: 11
Training loss: 1.2510581306350346
Validation loss: 2.4394051316645173

Epoch: 6| Step: 12
Training loss: 1.0404148336345234
Validation loss: 2.509811956234078

Epoch: 6| Step: 13
Training loss: 1.7526271038245484
Validation loss: 2.4752928499147195

Epoch: 593| Step: 0
Training loss: 1.2956108458316755
Validation loss: 2.553804340574749

Epoch: 6| Step: 1
Training loss: 1.4077819109609042
Validation loss: 2.488683012510985

Epoch: 6| Step: 2
Training loss: 1.5638677332869895
Validation loss: 2.537036462386424

Epoch: 6| Step: 3
Training loss: 1.3747438278850517
Validation loss: 2.4767581501014275

Epoch: 6| Step: 4
Training loss: 1.4417932502579063
Validation loss: 2.487576100840548

Epoch: 6| Step: 5
Training loss: 1.562330541958332
Validation loss: 2.506003235397409

Epoch: 6| Step: 6
Training loss: 1.4562467452246184
Validation loss: 2.4751448078371463

Epoch: 6| Step: 7
Training loss: 1.509265101126139
Validation loss: 2.513795108013204

Epoch: 6| Step: 8
Training loss: 1.3723373207585359
Validation loss: 2.536343340821136

Epoch: 6| Step: 9
Training loss: 1.6365251449392124
Validation loss: 2.5202888816775206

Epoch: 6| Step: 10
Training loss: 1.8677849871054861
Validation loss: 2.481677766903184

Epoch: 6| Step: 11
Training loss: 1.4339419573498573
Validation loss: 2.4686608735218445

Epoch: 6| Step: 12
Training loss: 1.7641479255258634
Validation loss: 2.504126377657601

Epoch: 6| Step: 13
Training loss: 2.6176372995591763
Validation loss: 2.5069245811171417

Epoch: 594| Step: 0
Training loss: 1.4005913371135108
Validation loss: 2.4750898604882523

Epoch: 6| Step: 1
Training loss: 1.4628876913980933
Validation loss: 2.521734218223571

Epoch: 6| Step: 2
Training loss: 1.3932496494201734
Validation loss: 2.5232954890440773

Epoch: 6| Step: 3
Training loss: 1.7112140867422998
Validation loss: 2.5152724619081064

Epoch: 6| Step: 4
Training loss: 1.0924353191511755
Validation loss: 2.4275748464507774

Epoch: 6| Step: 5
Training loss: 2.2732537578776983
Validation loss: 2.510801852949244

Epoch: 6| Step: 6
Training loss: 1.7345760332049074
Validation loss: 2.5115497251362973

Epoch: 6| Step: 7
Training loss: 1.695012360474296
Validation loss: 2.470663684908097

Epoch: 6| Step: 8
Training loss: 1.3230517711385499
Validation loss: 2.4804371837041113

Epoch: 6| Step: 9
Training loss: 1.791653485212704
Validation loss: 2.4585571934503463

Epoch: 6| Step: 10
Training loss: 1.410945850909456
Validation loss: 2.4940777167937336

Epoch: 6| Step: 11
Training loss: 1.4140992133501273
Validation loss: 2.4713749962427936

Epoch: 6| Step: 12
Training loss: 1.8602785751963589
Validation loss: 2.4988901330628126

Epoch: 6| Step: 13
Training loss: 1.1076961224848927
Validation loss: 2.5100587247479536

Epoch: 595| Step: 0
Training loss: 1.0504852218278402
Validation loss: 2.4687889597611874

Epoch: 6| Step: 1
Training loss: 1.8956239046671564
Validation loss: 2.5157926566381157

Epoch: 6| Step: 2
Training loss: 1.3288111989667266
Validation loss: 2.4686177614080536

Epoch: 6| Step: 3
Training loss: 1.2701683910501493
Validation loss: 2.429348850828836

Epoch: 6| Step: 4
Training loss: 1.593328307967195
Validation loss: 2.5027089669978504

Epoch: 6| Step: 5
Training loss: 1.490028217099695
Validation loss: 2.5057244146087827

Epoch: 6| Step: 6
Training loss: 1.7908142043142776
Validation loss: 2.5049634555444

Epoch: 6| Step: 7
Training loss: 2.24199343383127
Validation loss: 2.494424405552543

Epoch: 6| Step: 8
Training loss: 1.0778568321306308
Validation loss: 2.4898406201420897

Epoch: 6| Step: 9
Training loss: 1.886244246244661
Validation loss: 2.475788742320886

Epoch: 6| Step: 10
Training loss: 1.5402184033031345
Validation loss: 2.5440947139321284

Epoch: 6| Step: 11
Training loss: 1.8053366414245957
Validation loss: 2.510364740428929

Epoch: 6| Step: 12
Training loss: 1.2140372687311392
Validation loss: 2.473766200706552

Epoch: 6| Step: 13
Training loss: 1.3446123328134
Validation loss: 2.45746267038151

Epoch: 596| Step: 0
Training loss: 1.5811672535833523
Validation loss: 2.4847704835163826

Epoch: 6| Step: 1
Training loss: 1.2948587209453593
Validation loss: 2.553019425818092

Epoch: 6| Step: 2
Training loss: 1.4296159570022227
Validation loss: 2.529063809143668

Epoch: 6| Step: 3
Training loss: 1.4268828016778816
Validation loss: 2.439089690812314

Epoch: 6| Step: 4
Training loss: 1.440033959809512
Validation loss: 2.4598130268772733

Epoch: 6| Step: 5
Training loss: 1.4047196856620754
Validation loss: 2.4838750522839903

Epoch: 6| Step: 6
Training loss: 1.4965229265449569
Validation loss: 2.470770135395806

Epoch: 6| Step: 7
Training loss: 1.6319348472511417
Validation loss: 2.5405569136762427

Epoch: 6| Step: 8
Training loss: 1.590807573374024
Validation loss: 2.5054690621223887

Epoch: 6| Step: 9
Training loss: 2.1602336186769158
Validation loss: 2.4773405827422907

Epoch: 6| Step: 10
Training loss: 1.3226334977150527
Validation loss: 2.5151537280076393

Epoch: 6| Step: 11
Training loss: 2.089995818978102
Validation loss: 2.4993629074484196

Epoch: 6| Step: 12
Training loss: 1.67010125875433
Validation loss: 2.4442670759503504

Epoch: 6| Step: 13
Training loss: 1.7713227960653355
Validation loss: 2.473598879923858

Epoch: 597| Step: 0
Training loss: 1.4705962893321571
Validation loss: 2.4806707071156326

Epoch: 6| Step: 1
Training loss: 1.6148447214833268
Validation loss: 2.4842269738820324

Epoch: 6| Step: 2
Training loss: 1.030876670076533
Validation loss: 2.497253789295417

Epoch: 6| Step: 3
Training loss: 1.0474214977810876
Validation loss: 2.4759574263034922

Epoch: 6| Step: 4
Training loss: 2.3664507333095175
Validation loss: 2.4979471566493494

Epoch: 6| Step: 5
Training loss: 1.5389512694775818
Validation loss: 2.483398564474305

Epoch: 6| Step: 6
Training loss: 1.4346583932073151
Validation loss: 2.455458317837465

Epoch: 6| Step: 7
Training loss: 1.3150507346399698
Validation loss: 2.456498947872791

Epoch: 6| Step: 8
Training loss: 1.5962576492114346
Validation loss: 2.4645601219289666

Epoch: 6| Step: 9
Training loss: 1.801227241282329
Validation loss: 2.514569732202126

Epoch: 6| Step: 10
Training loss: 1.5631093172295607
Validation loss: 2.5008470033614123

Epoch: 6| Step: 11
Training loss: 1.5576873667820659
Validation loss: 2.504925304040366

Epoch: 6| Step: 12
Training loss: 1.3840297793811838
Validation loss: 2.494303876532878

Epoch: 6| Step: 13
Training loss: 1.632575204936719
Validation loss: 2.4682238718981937

Epoch: 598| Step: 0
Training loss: 1.9549149512794257
Validation loss: 2.547221410039865

Epoch: 6| Step: 1
Training loss: 1.5066788122368378
Validation loss: 2.4976284735644265

Epoch: 6| Step: 2
Training loss: 1.1291892677006563
Validation loss: 2.483456034649286

Epoch: 6| Step: 3
Training loss: 1.773204099109747
Validation loss: 2.4989767595456356

Epoch: 6| Step: 4
Training loss: 1.8889945069248832
Validation loss: 2.5511559044142316

Epoch: 6| Step: 5
Training loss: 1.7870029105070435
Validation loss: 2.4709820196118284

Epoch: 6| Step: 6
Training loss: 1.3274304088304518
Validation loss: 2.527183474759196

Epoch: 6| Step: 7
Training loss: 1.000458373874308
Validation loss: 2.459327206592413

Epoch: 6| Step: 8
Training loss: 2.1854665842043497
Validation loss: 2.500306005105747

Epoch: 6| Step: 9
Training loss: 1.5886581461575624
Validation loss: 2.420622161719281

Epoch: 6| Step: 10
Training loss: 1.6919811232124822
Validation loss: 2.453497474911609

Epoch: 6| Step: 11
Training loss: 1.364180303950919
Validation loss: 2.484727537940249

Epoch: 6| Step: 12
Training loss: 0.9614023464402002
Validation loss: 2.470221319225127

Epoch: 6| Step: 13
Training loss: 1.656628475490958
Validation loss: 2.4795499549984283

Epoch: 599| Step: 0
Training loss: 1.3022831674454178
Validation loss: 2.5324778777220405

Epoch: 6| Step: 1
Training loss: 1.2212846759257991
Validation loss: 2.5163334102729413

Epoch: 6| Step: 2
Training loss: 2.1933001325968067
Validation loss: 2.5112202962671595

Epoch: 6| Step: 3
Training loss: 1.7473948024362023
Validation loss: 2.488335249779422

Epoch: 6| Step: 4
Training loss: 1.1233838446568087
Validation loss: 2.4753329319005566

Epoch: 6| Step: 5
Training loss: 1.9695040757310682
Validation loss: 2.5241767605312373

Epoch: 6| Step: 6
Training loss: 1.845726117995009
Validation loss: 2.517604912161483

Epoch: 6| Step: 7
Training loss: 1.9101870793700126
Validation loss: 2.463156204403788

Epoch: 6| Step: 8
Training loss: 1.21817991176984
Validation loss: 2.481317378493875

Epoch: 6| Step: 9
Training loss: 1.622847304945184
Validation loss: 2.528132816433781

Epoch: 6| Step: 10
Training loss: 1.3716412182127817
Validation loss: 2.4814279218632542

Epoch: 6| Step: 11
Training loss: 1.3442256883945203
Validation loss: 2.432460572375193

Epoch: 6| Step: 12
Training loss: 1.5016517287148898
Validation loss: 2.4851345006230594

Epoch: 6| Step: 13
Training loss: 1.117015798752406
Validation loss: 2.4784270979543215

Epoch: 600| Step: 0
Training loss: 1.762026943814813
Validation loss: 2.562129009092242

Epoch: 6| Step: 1
Training loss: 1.7265584954262807
Validation loss: 2.5118518104445537

Epoch: 6| Step: 2
Training loss: 1.7292594731562085
Validation loss: 2.392648296319155

Epoch: 6| Step: 3
Training loss: 1.4038784799180282
Validation loss: 2.45335264124881

Epoch: 6| Step: 4
Training loss: 1.4923400800897677
Validation loss: 2.492761631764665

Epoch: 6| Step: 5
Training loss: 1.3724958418347126
Validation loss: 2.5251211481912614

Epoch: 6| Step: 6
Training loss: 1.2142430626567158
Validation loss: 2.4948035768309436

Epoch: 6| Step: 7
Training loss: 1.5066270664941195
Validation loss: 2.551427236923765

Epoch: 6| Step: 8
Training loss: 1.139508471683012
Validation loss: 2.5250592473650317

Epoch: 6| Step: 9
Training loss: 2.383729851912119
Validation loss: 2.5056098355473364

Epoch: 6| Step: 10
Training loss: 1.5568394169058473
Validation loss: 2.5073230454759994

Epoch: 6| Step: 11
Training loss: 1.2155073996490866
Validation loss: 2.4589437252197097

Epoch: 6| Step: 12
Training loss: 1.5126338426624513
Validation loss: 2.4710793425952473

Epoch: 6| Step: 13
Training loss: 1.1263001664279508
Validation loss: 2.5231788223541356

Epoch: 601| Step: 0
Training loss: 1.7093025652446678
Validation loss: 2.5293562598602897

Epoch: 6| Step: 1
Training loss: 1.651871489724259
Validation loss: 2.5450625674237077

Epoch: 6| Step: 2
Training loss: 1.4609107356756281
Validation loss: 2.515890570234929

Epoch: 6| Step: 3
Training loss: 2.250260020172387
Validation loss: 2.4300382332170107

Epoch: 6| Step: 4
Training loss: 0.952624611750735
Validation loss: 2.521688767868839

Epoch: 6| Step: 5
Training loss: 1.4199118003855111
Validation loss: 2.546559603979624

Epoch: 6| Step: 6
Training loss: 1.0767828838959173
Validation loss: 2.514734553769983

Epoch: 6| Step: 7
Training loss: 1.4490919031940617
Validation loss: 2.5764411347011476

Epoch: 6| Step: 8
Training loss: 1.3128779639121912
Validation loss: 2.5354137774298064

Epoch: 6| Step: 9
Training loss: 1.8483329969130067
Validation loss: 2.49562881676488

Epoch: 6| Step: 10
Training loss: 1.6093518153622413
Validation loss: 2.496881697783568

Epoch: 6| Step: 11
Training loss: 1.4314817415885768
Validation loss: 2.5172512937889144

Epoch: 6| Step: 12
Training loss: 1.4458321951532784
Validation loss: 2.5209768643082713

Epoch: 6| Step: 13
Training loss: 2.004697884988385
Validation loss: 2.532978303893198

Epoch: 602| Step: 0
Training loss: 1.3453564910253455
Validation loss: 2.4657832687618577

Epoch: 6| Step: 1
Training loss: 1.6657806266523725
Validation loss: 2.481980365508894

Epoch: 6| Step: 2
Training loss: 1.5363046170513486
Validation loss: 2.450600962068582

Epoch: 6| Step: 3
Training loss: 1.606960670801766
Validation loss: 2.435521955775693

Epoch: 6| Step: 4
Training loss: 1.5948448160668187
Validation loss: 2.4807624227698817

Epoch: 6| Step: 5
Training loss: 1.6912768448801727
Validation loss: 2.4974550983985053

Epoch: 6| Step: 6
Training loss: 1.289958573053213
Validation loss: 2.4797815139701522

Epoch: 6| Step: 7
Training loss: 1.2072824753726017
Validation loss: 2.536056633973811

Epoch: 6| Step: 8
Training loss: 2.0669523790223123
Validation loss: 2.5500244682339694

Epoch: 6| Step: 9
Training loss: 1.2858306135806883
Validation loss: 2.4580414210958104

Epoch: 6| Step: 10
Training loss: 0.9651394904325652
Validation loss: 2.4337863835673437

Epoch: 6| Step: 11
Training loss: 1.447565827528222
Validation loss: 2.4821964225212025

Epoch: 6| Step: 12
Training loss: 2.0033912517449903
Validation loss: 2.4567902172870855

Epoch: 6| Step: 13
Training loss: 1.771730921032584
Validation loss: 2.475678470095219

Epoch: 603| Step: 0
Training loss: 1.1844374667883204
Validation loss: 2.487207808977418

Epoch: 6| Step: 1
Training loss: 1.5828147172676967
Validation loss: 2.4323247097608185

Epoch: 6| Step: 2
Training loss: 1.4282317541109804
Validation loss: 2.510054484112145

Epoch: 6| Step: 3
Training loss: 1.2089650486894303
Validation loss: 2.56668702572804

Epoch: 6| Step: 4
Training loss: 1.3851932355027645
Validation loss: 2.481619542741106

Epoch: 6| Step: 5
Training loss: 1.8537456663136362
Validation loss: 2.5253794888218972

Epoch: 6| Step: 6
Training loss: 1.4458288971377575
Validation loss: 2.518175659636052

Epoch: 6| Step: 7
Training loss: 2.17259917775802
Validation loss: 2.4985607495831665

Epoch: 6| Step: 8
Training loss: 1.7737831081448459
Validation loss: 2.5022660127566856

Epoch: 6| Step: 9
Training loss: 1.1497390015522517
Validation loss: 2.505417526202758

Epoch: 6| Step: 10
Training loss: 2.0153387295197174
Validation loss: 2.4927791233075367

Epoch: 6| Step: 11
Training loss: 1.2688421168970134
Validation loss: 2.521481558687277

Epoch: 6| Step: 12
Training loss: 1.3003844609663067
Validation loss: 2.4880123679901507

Epoch: 6| Step: 13
Training loss: 1.6592608022816677
Validation loss: 2.49427589097695

Epoch: 604| Step: 0
Training loss: 1.2023008421937376
Validation loss: 2.5834491980295575

Epoch: 6| Step: 1
Training loss: 0.9655129278138304
Validation loss: 2.522475234106178

Epoch: 6| Step: 2
Training loss: 1.5303937113710966
Validation loss: 2.4430817650243557

Epoch: 6| Step: 3
Training loss: 1.5726941016503249
Validation loss: 2.544440269254832

Epoch: 6| Step: 4
Training loss: 1.6449693109959993
Validation loss: 2.4574154189393242

Epoch: 6| Step: 5
Training loss: 1.6283130617679216
Validation loss: 2.488082123863021

Epoch: 6| Step: 6
Training loss: 1.7793185152146918
Validation loss: 2.5365794641560617

Epoch: 6| Step: 7
Training loss: 1.0860552278002884
Validation loss: 2.4908192493406935

Epoch: 6| Step: 8
Training loss: 1.456811801451173
Validation loss: 2.5565142608488896

Epoch: 6| Step: 9
Training loss: 1.608168510859502
Validation loss: 2.4903488780782443

Epoch: 6| Step: 10
Training loss: 1.9615501875260786
Validation loss: 2.4639774077547956

Epoch: 6| Step: 11
Training loss: 1.547862806790783
Validation loss: 2.49935023570051

Epoch: 6| Step: 12
Training loss: 1.1301278761017104
Validation loss: 2.4797783866713283

Epoch: 6| Step: 13
Training loss: 2.1548767139545943
Validation loss: 2.47367521383372

Epoch: 605| Step: 0
Training loss: 1.342517154164888
Validation loss: 2.523324196667916

Epoch: 6| Step: 1
Training loss: 1.1922821827258614
Validation loss: 2.5116208513718257

Epoch: 6| Step: 2
Training loss: 2.3639151235405453
Validation loss: 2.4482212143387305

Epoch: 6| Step: 3
Training loss: 1.3599709267874638
Validation loss: 2.520492912771269

Epoch: 6| Step: 4
Training loss: 1.5596458306896153
Validation loss: 2.4921111123036366

Epoch: 6| Step: 5
Training loss: 1.297884674453573
Validation loss: 2.515056721458219

Epoch: 6| Step: 6
Training loss: 1.6574600405932356
Validation loss: 2.4961673552981

Epoch: 6| Step: 7
Training loss: 1.0892330632673648
Validation loss: 2.4427387104384115

Epoch: 6| Step: 8
Training loss: 1.3052236403379296
Validation loss: 2.5456514079800705

Epoch: 6| Step: 9
Training loss: 2.008607818186281
Validation loss: 2.551196331472113

Epoch: 6| Step: 10
Training loss: 1.4323284999850792
Validation loss: 2.477147325834344

Epoch: 6| Step: 11
Training loss: 1.1582843308180755
Validation loss: 2.481399412443695

Epoch: 6| Step: 12
Training loss: 1.7924085751764889
Validation loss: 2.5012710016839326

Epoch: 6| Step: 13
Training loss: 1.4407289976369455
Validation loss: 2.478144544513946

Epoch: 606| Step: 0
Training loss: 1.7227832288935
Validation loss: 2.4742319332486145

Epoch: 6| Step: 1
Training loss: 1.607788859824725
Validation loss: 2.572164213179251

Epoch: 6| Step: 2
Training loss: 0.9757554037856864
Validation loss: 2.460441541202603

Epoch: 6| Step: 3
Training loss: 1.3867170306987582
Validation loss: 2.4517729302675018

Epoch: 6| Step: 4
Training loss: 1.1087476003936982
Validation loss: 2.508781876743718

Epoch: 6| Step: 5
Training loss: 2.140296632404634
Validation loss: 2.5472821634242644

Epoch: 6| Step: 6
Training loss: 1.4161799473621093
Validation loss: 2.5327508331458146

Epoch: 6| Step: 7
Training loss: 1.0590985773041874
Validation loss: 2.474590793630538

Epoch: 6| Step: 8
Training loss: 1.6229853245417774
Validation loss: 2.4904514522629664

Epoch: 6| Step: 9
Training loss: 1.017999192175704
Validation loss: 2.4873029291418494

Epoch: 6| Step: 10
Training loss: 1.584077844084496
Validation loss: 2.5368861511252336

Epoch: 6| Step: 11
Training loss: 1.7496762657452118
Validation loss: 2.498500228496909

Epoch: 6| Step: 12
Training loss: 2.198326566780711
Validation loss: 2.478068178613205

Epoch: 6| Step: 13
Training loss: 1.8816539318080636
Validation loss: 2.5187007083648343

Epoch: 607| Step: 0
Training loss: 1.5600603512558566
Validation loss: 2.499260241260722

Epoch: 6| Step: 1
Training loss: 1.3012884943798853
Validation loss: 2.4742920760645526

Epoch: 6| Step: 2
Training loss: 1.665042570675373
Validation loss: 2.4838420997820405

Epoch: 6| Step: 3
Training loss: 1.5176884084566153
Validation loss: 2.527947568962462

Epoch: 6| Step: 4
Training loss: 1.2149935810877153
Validation loss: 2.503713887622712

Epoch: 6| Step: 5
Training loss: 1.3691561231402614
Validation loss: 2.4839637494907096

Epoch: 6| Step: 6
Training loss: 1.9857557404161528
Validation loss: 2.456029052574498

Epoch: 6| Step: 7
Training loss: 1.2531943038079205
Validation loss: 2.521755972740337

Epoch: 6| Step: 8
Training loss: 1.8326210748037077
Validation loss: 2.4905953465003927

Epoch: 6| Step: 9
Training loss: 1.7860369690489528
Validation loss: 2.4656054697872656

Epoch: 6| Step: 10
Training loss: 1.2743486292618957
Validation loss: 2.441574911218826

Epoch: 6| Step: 11
Training loss: 1.4879657881608235
Validation loss: 2.5157310775824873

Epoch: 6| Step: 12
Training loss: 1.8588669026598432
Validation loss: 2.4253814083977003

Epoch: 6| Step: 13
Training loss: 1.087938400123545
Validation loss: 2.4971473107656608

Epoch: 608| Step: 0
Training loss: 1.274785551100241
Validation loss: 2.5540712758673

Epoch: 6| Step: 1
Training loss: 0.8206220133742338
Validation loss: 2.416163290962923

Epoch: 6| Step: 2
Training loss: 1.9681947924346301
Validation loss: 2.551322353605371

Epoch: 6| Step: 3
Training loss: 1.4221834958949895
Validation loss: 2.5416944187235466

Epoch: 6| Step: 4
Training loss: 1.2647458072132136
Validation loss: 2.5489715260491144

Epoch: 6| Step: 5
Training loss: 1.2733354586105852
Validation loss: 2.4946915328572485

Epoch: 6| Step: 6
Training loss: 1.2961763085484965
Validation loss: 2.4811419046994505

Epoch: 6| Step: 7
Training loss: 1.233103036428711
Validation loss: 2.5602024331941404

Epoch: 6| Step: 8
Training loss: 1.6227844246430687
Validation loss: 2.5406071051224304

Epoch: 6| Step: 9
Training loss: 1.5769017076744207
Validation loss: 2.5240821950763395

Epoch: 6| Step: 10
Training loss: 1.8982483569454225
Validation loss: 2.4877991511546758

Epoch: 6| Step: 11
Training loss: 1.6854474335617973
Validation loss: 2.5213796609537087

Epoch: 6| Step: 12
Training loss: 2.206531677419799
Validation loss: 2.532057596473518

Epoch: 6| Step: 13
Training loss: 1.4689211644207885
Validation loss: 2.466034813186107

Epoch: 609| Step: 0
Training loss: 1.324152716956693
Validation loss: 2.497441391490474

Epoch: 6| Step: 1
Training loss: 1.5890952557964009
Validation loss: 2.5144172744598716

Epoch: 6| Step: 2
Training loss: 1.7911178576329478
Validation loss: 2.500379114220803

Epoch: 6| Step: 3
Training loss: 1.141871881256271
Validation loss: 2.5154628284837814

Epoch: 6| Step: 4
Training loss: 1.216017962097216
Validation loss: 2.4761235270004835

Epoch: 6| Step: 5
Training loss: 1.0683148529985573
Validation loss: 2.51643403514318

Epoch: 6| Step: 6
Training loss: 1.292855018615483
Validation loss: 2.4315868949134796

Epoch: 6| Step: 7
Training loss: 1.2725054366439665
Validation loss: 2.430393398831155

Epoch: 6| Step: 8
Training loss: 1.4875391914910758
Validation loss: 2.462741874866155

Epoch: 6| Step: 9
Training loss: 1.6203460071891793
Validation loss: 2.4828625873369643

Epoch: 6| Step: 10
Training loss: 1.8329220946343516
Validation loss: 2.4732431542283484

Epoch: 6| Step: 11
Training loss: 2.4520570410585845
Validation loss: 2.5237346283625146

Epoch: 6| Step: 12
Training loss: 1.3133147753374161
Validation loss: 2.50943175905391

Epoch: 6| Step: 13
Training loss: 1.2036306136239368
Validation loss: 2.5240749868389827

Epoch: 610| Step: 0
Training loss: 1.632638657364026
Validation loss: 2.4715277031281726

Epoch: 6| Step: 1
Training loss: 1.6063113635027129
Validation loss: 2.52773453102528

Epoch: 6| Step: 2
Training loss: 1.7204624315110653
Validation loss: 2.5099362735055695

Epoch: 6| Step: 3
Training loss: 1.4265704753272581
Validation loss: 2.4673744628182708

Epoch: 6| Step: 4
Training loss: 1.5529904712156233
Validation loss: 2.4906933170842342

Epoch: 6| Step: 5
Training loss: 2.564183682234522
Validation loss: 2.516120003362484

Epoch: 6| Step: 6
Training loss: 1.5227310498939985
Validation loss: 2.493258192481913

Epoch: 6| Step: 7
Training loss: 1.2264139850871658
Validation loss: 2.4746135375557206

Epoch: 6| Step: 8
Training loss: 1.6092227011903502
Validation loss: 2.5428682829162623

Epoch: 6| Step: 9
Training loss: 1.1859786176024496
Validation loss: 2.5208567546453744

Epoch: 6| Step: 10
Training loss: 1.3203281198514385
Validation loss: 2.4590685196823623

Epoch: 6| Step: 11
Training loss: 1.2160592330823643
Validation loss: 2.522062969052939

Epoch: 6| Step: 12
Training loss: 1.6795725228635128
Validation loss: 2.550020124157762

Epoch: 6| Step: 13
Training loss: 0.9796245938049931
Validation loss: 2.549258819338882

Epoch: 611| Step: 0
Training loss: 1.3967941260768175
Validation loss: 2.5040554337309753

Epoch: 6| Step: 1
Training loss: 1.3003576006925768
Validation loss: 2.480433715128473

Epoch: 6| Step: 2
Training loss: 1.6727214346188226
Validation loss: 2.4936169245486606

Epoch: 6| Step: 3
Training loss: 1.62883891965912
Validation loss: 2.4927918510840215

Epoch: 6| Step: 4
Training loss: 1.7176879375751328
Validation loss: 2.5160082942453506

Epoch: 6| Step: 5
Training loss: 1.4690127847840981
Validation loss: 2.493416623157891

Epoch: 6| Step: 6
Training loss: 1.5287024657001425
Validation loss: 2.5233475802979495

Epoch: 6| Step: 7
Training loss: 1.6085046433182262
Validation loss: 2.501423972681114

Epoch: 6| Step: 8
Training loss: 1.9025395036122577
Validation loss: 2.4848652358103616

Epoch: 6| Step: 9
Training loss: 1.4363863404370498
Validation loss: 2.4963569595415325

Epoch: 6| Step: 10
Training loss: 1.5505192532935488
Validation loss: 2.5258015268040195

Epoch: 6| Step: 11
Training loss: 1.427156636752398
Validation loss: 2.4920265535907427

Epoch: 6| Step: 12
Training loss: 1.4883161725930585
Validation loss: 2.4813426695105916

Epoch: 6| Step: 13
Training loss: 0.8274078862993535
Validation loss: 2.423303656572877

Epoch: 612| Step: 0
Training loss: 1.2877193967677942
Validation loss: 2.5299504776566026

Epoch: 6| Step: 1
Training loss: 1.7582745432253315
Validation loss: 2.469283576273512

Epoch: 6| Step: 2
Training loss: 1.4637787469635757
Validation loss: 2.4981175667570845

Epoch: 6| Step: 3
Training loss: 1.2993567287376975
Validation loss: 2.555187335876042

Epoch: 6| Step: 4
Training loss: 1.61928580706538
Validation loss: 2.5376082190312244

Epoch: 6| Step: 5
Training loss: 1.59807314481662
Validation loss: 2.5008693926656775

Epoch: 6| Step: 6
Training loss: 1.5258491403346723
Validation loss: 2.5046004441574277

Epoch: 6| Step: 7
Training loss: 1.2235635431872425
Validation loss: 2.540240632281888

Epoch: 6| Step: 8
Training loss: 1.3847348918651907
Validation loss: 2.5236166491662844

Epoch: 6| Step: 9
Training loss: 1.58224644080449
Validation loss: 2.5164039408128103

Epoch: 6| Step: 10
Training loss: 1.4403311175225084
Validation loss: 2.4731090438031864

Epoch: 6| Step: 11
Training loss: 2.451296957403665
Validation loss: 2.5984431315159955

Epoch: 6| Step: 12
Training loss: 1.2479890860728347
Validation loss: 2.4628063975110925

Epoch: 6| Step: 13
Training loss: 1.074942993160673
Validation loss: 2.526443156913746

Epoch: 613| Step: 0
Training loss: 1.3615157273134015
Validation loss: 2.4871273632936797

Epoch: 6| Step: 1
Training loss: 1.8448954757814433
Validation loss: 2.457308854181896

Epoch: 6| Step: 2
Training loss: 1.5004890757197702
Validation loss: 2.5268379203920617

Epoch: 6| Step: 3
Training loss: 1.443962084893247
Validation loss: 2.4970054642587964

Epoch: 6| Step: 4
Training loss: 1.5823849129674061
Validation loss: 2.509266759789945

Epoch: 6| Step: 5
Training loss: 1.9929758942826303
Validation loss: 2.5263172672096856

Epoch: 6| Step: 6
Training loss: 1.239728497038125
Validation loss: 2.504345373229769

Epoch: 6| Step: 7
Training loss: 1.7042937162213951
Validation loss: 2.5105348682689095

Epoch: 6| Step: 8
Training loss: 1.4805392044735852
Validation loss: 2.5027742620757443

Epoch: 6| Step: 9
Training loss: 1.4799646007325264
Validation loss: 2.4815407506571474

Epoch: 6| Step: 10
Training loss: 0.971768199780647
Validation loss: 2.4191778613206893

Epoch: 6| Step: 11
Training loss: 1.578641297138694
Validation loss: 2.4698748437103273

Epoch: 6| Step: 12
Training loss: 1.4143265114166517
Validation loss: 2.545057203547415

Epoch: 6| Step: 13
Training loss: 1.4437370993297918
Validation loss: 2.540052855444494

Epoch: 614| Step: 0
Training loss: 1.472631398606005
Validation loss: 2.498396880407413

Epoch: 6| Step: 1
Training loss: 1.3325442224146078
Validation loss: 2.4975248800011527

Epoch: 6| Step: 2
Training loss: 1.1993405656110576
Validation loss: 2.540774285738243

Epoch: 6| Step: 3
Training loss: 1.33160326394185
Validation loss: 2.5817627351645407

Epoch: 6| Step: 4
Training loss: 1.3317886981902187
Validation loss: 2.4507486467362285

Epoch: 6| Step: 5
Training loss: 2.4419745432333655
Validation loss: 2.5175843355818266

Epoch: 6| Step: 6
Training loss: 1.6413913934934963
Validation loss: 2.484145538987341

Epoch: 6| Step: 7
Training loss: 1.097450698666283
Validation loss: 2.4746984571366233

Epoch: 6| Step: 8
Training loss: 1.707799673075901
Validation loss: 2.5193743231513626

Epoch: 6| Step: 9
Training loss: 1.271804136509414
Validation loss: 2.5062231993299044

Epoch: 6| Step: 10
Training loss: 1.319160410218977
Validation loss: 2.522107525288198

Epoch: 6| Step: 11
Training loss: 1.6392596421719579
Validation loss: 2.4869610074129853

Epoch: 6| Step: 12
Training loss: 1.4166763342733186
Validation loss: 2.4339453312004617

Epoch: 6| Step: 13
Training loss: 1.1624746053239492
Validation loss: 2.5345725683187945

Epoch: 615| Step: 0
Training loss: 2.1457380502033168
Validation loss: 2.5403012791274553

Epoch: 6| Step: 1
Training loss: 1.552563160027715
Validation loss: 2.5059775871284033

Epoch: 6| Step: 2
Training loss: 1.4047552854075664
Validation loss: 2.5450286896963754

Epoch: 6| Step: 3
Training loss: 1.177974594188745
Validation loss: 2.5753316105628947

Epoch: 6| Step: 4
Training loss: 1.7697123925332519
Validation loss: 2.4624526201754606

Epoch: 6| Step: 5
Training loss: 1.4944952251042816
Validation loss: 2.4842182382647304

Epoch: 6| Step: 6
Training loss: 1.5967825666874935
Validation loss: 2.4636505646788303

Epoch: 6| Step: 7
Training loss: 1.346854460663636
Validation loss: 2.5488528462180264

Epoch: 6| Step: 8
Training loss: 1.6494557639090828
Validation loss: 2.410704135173491

Epoch: 6| Step: 9
Training loss: 1.396056038849368
Validation loss: 2.4753128656145225

Epoch: 6| Step: 10
Training loss: 0.9540270929548054
Validation loss: 2.466119023971162

Epoch: 6| Step: 11
Training loss: 1.813043249865253
Validation loss: 2.4787230149396184

Epoch: 6| Step: 12
Training loss: 1.619568182767497
Validation loss: 2.474355945251714

Epoch: 6| Step: 13
Training loss: 0.7325110622781497
Validation loss: 2.533644980975469

Epoch: 616| Step: 0
Training loss: 0.9259532655988866
Validation loss: 2.5172466874322774

Epoch: 6| Step: 1
Training loss: 1.0089566146097635
Validation loss: 2.5018878433310094

Epoch: 6| Step: 2
Training loss: 1.3297982838760023
Validation loss: 2.555077097006315

Epoch: 6| Step: 3
Training loss: 0.9440432452928211
Validation loss: 2.552935099063924

Epoch: 6| Step: 4
Training loss: 1.611503600767198
Validation loss: 2.5919104204260743

Epoch: 6| Step: 5
Training loss: 1.8867721392104833
Validation loss: 2.551444057000842

Epoch: 6| Step: 6
Training loss: 1.4210796437289506
Validation loss: 2.5605434889114864

Epoch: 6| Step: 7
Training loss: 1.6693629707065831
Validation loss: 2.5176992127994273

Epoch: 6| Step: 8
Training loss: 1.802270501032745
Validation loss: 2.508759812501095

Epoch: 6| Step: 9
Training loss: 2.1712839982835948
Validation loss: 2.453854905489151

Epoch: 6| Step: 10
Training loss: 1.6806777519098568
Validation loss: 2.480036126442448

Epoch: 6| Step: 11
Training loss: 1.6829152875445839
Validation loss: 2.4463312911854818

Epoch: 6| Step: 12
Training loss: 1.6595644625389716
Validation loss: 2.5410743384944463

Epoch: 6| Step: 13
Training loss: 1.1910041505755689
Validation loss: 2.4361734895733425

Epoch: 617| Step: 0
Training loss: 1.3260211662312
Validation loss: 2.448692985879792

Epoch: 6| Step: 1
Training loss: 1.073814621247566
Validation loss: 2.5023798843612757

Epoch: 6| Step: 2
Training loss: 2.1089218217984667
Validation loss: 2.440662115677551

Epoch: 6| Step: 3
Training loss: 1.8458178287770572
Validation loss: 2.492643957634056

Epoch: 6| Step: 4
Training loss: 1.1651280793606758
Validation loss: 2.492145864199527

Epoch: 6| Step: 5
Training loss: 1.2067600180062106
Validation loss: 2.482562934013244

Epoch: 6| Step: 6
Training loss: 1.3401753095988502
Validation loss: 2.5061780190362066

Epoch: 6| Step: 7
Training loss: 1.4423160317986818
Validation loss: 2.5316712973161164

Epoch: 6| Step: 8
Training loss: 1.0838581733440136
Validation loss: 2.540959328546307

Epoch: 6| Step: 9
Training loss: 1.1081145742305678
Validation loss: 2.5401878681263863

Epoch: 6| Step: 10
Training loss: 1.563292035585607
Validation loss: 2.54440723160675

Epoch: 6| Step: 11
Training loss: 1.6958040148975793
Validation loss: 2.523142728431456

Epoch: 6| Step: 12
Training loss: 1.0585204377073063
Validation loss: 2.5002166879739893

Epoch: 6| Step: 13
Training loss: 2.9150788117578856
Validation loss: 2.499596678081547

Epoch: 618| Step: 0
Training loss: 1.8456501625172368
Validation loss: 2.4928451674818226

Epoch: 6| Step: 1
Training loss: 1.4744037004744177
Validation loss: 2.578177779258114

Epoch: 6| Step: 2
Training loss: 1.694683890109374
Validation loss: 2.4884641390844173

Epoch: 6| Step: 3
Training loss: 1.290426746132375
Validation loss: 2.487257119660437

Epoch: 6| Step: 4
Training loss: 1.3011117692828629
Validation loss: 2.5130523691563584

Epoch: 6| Step: 5
Training loss: 1.156699995161696
Validation loss: 2.471442280423071

Epoch: 6| Step: 6
Training loss: 1.4998687845694714
Validation loss: 2.4574788713225515

Epoch: 6| Step: 7
Training loss: 1.3435458094684372
Validation loss: 2.5203674541520935

Epoch: 6| Step: 8
Training loss: 1.5673157294347693
Validation loss: 2.4835531895843546

Epoch: 6| Step: 9
Training loss: 1.3996181512249266
Validation loss: 2.494661968555011

Epoch: 6| Step: 10
Training loss: 2.109273837454115
Validation loss: 2.4497218607619393

Epoch: 6| Step: 11
Training loss: 1.4305573199033916
Validation loss: 2.5354090524007167

Epoch: 6| Step: 12
Training loss: 1.4419716653883872
Validation loss: 2.41353182587093

Epoch: 6| Step: 13
Training loss: 0.8165982034427557
Validation loss: 2.503569802491105

Epoch: 619| Step: 0
Training loss: 1.017600266111387
Validation loss: 2.4844672196976534

Epoch: 6| Step: 1
Training loss: 1.1275127218167347
Validation loss: 2.472464020509989

Epoch: 6| Step: 2
Training loss: 1.5136843182452258
Validation loss: 2.464902959100471

Epoch: 6| Step: 3
Training loss: 1.4287079337160837
Validation loss: 2.5198667465198534

Epoch: 6| Step: 4
Training loss: 1.346595324445772
Validation loss: 2.485180993962795

Epoch: 6| Step: 5
Training loss: 1.5107274316758774
Validation loss: 2.4848617775425788

Epoch: 6| Step: 6
Training loss: 1.4068745815525594
Validation loss: 2.4886390280844353

Epoch: 6| Step: 7
Training loss: 1.572073106055918
Validation loss: 2.514442922794205

Epoch: 6| Step: 8
Training loss: 1.0745098482535353
Validation loss: 2.5232117061465016

Epoch: 6| Step: 9
Training loss: 1.985175984842628
Validation loss: 2.543377802757915

Epoch: 6| Step: 10
Training loss: 2.5486717205365035
Validation loss: 2.552008268161883

Epoch: 6| Step: 11
Training loss: 1.1597837113293235
Validation loss: 2.5413898483363497

Epoch: 6| Step: 12
Training loss: 1.6919501929877094
Validation loss: 2.524154562729175

Epoch: 6| Step: 13
Training loss: 1.2291498290810674
Validation loss: 2.5066968876877582

Epoch: 620| Step: 0
Training loss: 1.3832829854987285
Validation loss: 2.520010716753581

Epoch: 6| Step: 1
Training loss: 1.5597230266789013
Validation loss: 2.5028933640475244

Epoch: 6| Step: 2
Training loss: 2.1652828590323114
Validation loss: 2.4751506111588735

Epoch: 6| Step: 3
Training loss: 1.30021604796773
Validation loss: 2.4307296855408844

Epoch: 6| Step: 4
Training loss: 1.4600246249695852
Validation loss: 2.502763582497207

Epoch: 6| Step: 5
Training loss: 1.2377098522081715
Validation loss: 2.479265939185239

Epoch: 6| Step: 6
Training loss: 1.4806971713471575
Validation loss: 2.4663567584341313

Epoch: 6| Step: 7
Training loss: 1.5085490903165524
Validation loss: 2.521084030514316

Epoch: 6| Step: 8
Training loss: 1.1073168077363011
Validation loss: 2.507641864407711

Epoch: 6| Step: 9
Training loss: 1.5668053629875187
Validation loss: 2.545005875967956

Epoch: 6| Step: 10
Training loss: 1.5340701233454306
Validation loss: 2.4670640384098914

Epoch: 6| Step: 11
Training loss: 1.4164524851436697
Validation loss: 2.4448742799345218

Epoch: 6| Step: 12
Training loss: 1.2200673637396762
Validation loss: 2.527568960716844

Epoch: 6| Step: 13
Training loss: 1.8531124532702627
Validation loss: 2.495931545088338

Epoch: 621| Step: 0
Training loss: 0.9970778447239368
Validation loss: 2.521712573823144

Epoch: 6| Step: 1
Training loss: 1.279517048533228
Validation loss: 2.469791990494572

Epoch: 6| Step: 2
Training loss: 0.9683028081119456
Validation loss: 2.511530821971005

Epoch: 6| Step: 3
Training loss: 1.5688620173975047
Validation loss: 2.481303888262008

Epoch: 6| Step: 4
Training loss: 1.1583135594022638
Validation loss: 2.4789133401773227

Epoch: 6| Step: 5
Training loss: 1.340358045982169
Validation loss: 2.452684715006356

Epoch: 6| Step: 6
Training loss: 2.1072852061221816
Validation loss: 2.4845575260560473

Epoch: 6| Step: 7
Training loss: 2.111811946798037
Validation loss: 2.5402590957433335

Epoch: 6| Step: 8
Training loss: 1.5712896694374217
Validation loss: 2.4999218897768762

Epoch: 6| Step: 9
Training loss: 0.8902778618214594
Validation loss: 2.476675683975394

Epoch: 6| Step: 10
Training loss: 1.5630632529709365
Validation loss: 2.463117622872168

Epoch: 6| Step: 11
Training loss: 1.626304542981485
Validation loss: 2.478384323299258

Epoch: 6| Step: 12
Training loss: 1.3497882288383505
Validation loss: 2.525724292671661

Epoch: 6| Step: 13
Training loss: 1.4352928300137202
Validation loss: 2.5019077569310406

Epoch: 622| Step: 0
Training loss: 1.2672895623249771
Validation loss: 2.4407568661309207

Epoch: 6| Step: 1
Training loss: 1.4186895550862908
Validation loss: 2.456727094609037

Epoch: 6| Step: 2
Training loss: 0.6533256040167809
Validation loss: 2.454076238325201

Epoch: 6| Step: 3
Training loss: 1.5602016329671322
Validation loss: 2.4846047462688774

Epoch: 6| Step: 4
Training loss: 1.167306820899697
Validation loss: 2.5165899392030755

Epoch: 6| Step: 5
Training loss: 2.3792062955407465
Validation loss: 2.5163763421413363

Epoch: 6| Step: 6
Training loss: 1.9961247451077841
Validation loss: 2.4945158416220887

Epoch: 6| Step: 7
Training loss: 1.2316805246594749
Validation loss: 2.428273414422501

Epoch: 6| Step: 8
Training loss: 1.6344109700841676
Validation loss: 2.535692800416508

Epoch: 6| Step: 9
Training loss: 1.4557258546776761
Validation loss: 2.5037340058195574

Epoch: 6| Step: 10
Training loss: 1.2196232528243942
Validation loss: 2.4604242386309427

Epoch: 6| Step: 11
Training loss: 1.6682405272720375
Validation loss: 2.4877491350138494

Epoch: 6| Step: 12
Training loss: 1.3634432720977567
Validation loss: 2.4761664199122584

Epoch: 6| Step: 13
Training loss: 1.103046094541681
Validation loss: 2.4677387418222936

Epoch: 623| Step: 0
Training loss: 1.1352147380675952
Validation loss: 2.579477271127804

Epoch: 6| Step: 1
Training loss: 2.073471595696551
Validation loss: 2.500049287556277

Epoch: 6| Step: 2
Training loss: 1.6776293542963323
Validation loss: 2.559822414369637

Epoch: 6| Step: 3
Training loss: 1.0786972185927426
Validation loss: 2.561693374210933

Epoch: 6| Step: 4
Training loss: 0.7531356035174636
Validation loss: 2.556712169353265

Epoch: 6| Step: 5
Training loss: 1.4557985711200891
Validation loss: 2.4419217995645868

Epoch: 6| Step: 6
Training loss: 1.4029903355739366
Validation loss: 2.563135244934535

Epoch: 6| Step: 7
Training loss: 1.2265667277463712
Validation loss: 2.5254417137448284

Epoch: 6| Step: 8
Training loss: 1.9956243452052551
Validation loss: 2.5068669003831348

Epoch: 6| Step: 9
Training loss: 0.564104018440128
Validation loss: 2.510692485460762

Epoch: 6| Step: 10
Training loss: 1.175202236627459
Validation loss: 2.4801699382726006

Epoch: 6| Step: 11
Training loss: 1.7901476771424176
Validation loss: 2.4623090889160135

Epoch: 6| Step: 12
Training loss: 1.660029363832095
Validation loss: 2.451015519817558

Epoch: 6| Step: 13
Training loss: 1.94365502030367
Validation loss: 2.4997347824354677

Epoch: 624| Step: 0
Training loss: 1.352396801239085
Validation loss: 2.485181212655837

Epoch: 6| Step: 1
Training loss: 1.140877316929494
Validation loss: 2.460549360177244

Epoch: 6| Step: 2
Training loss: 2.160795755212845
Validation loss: 2.471476818305199

Epoch: 6| Step: 3
Training loss: 1.6090496438039399
Validation loss: 2.493086768458516

Epoch: 6| Step: 4
Training loss: 1.3960203453537932
Validation loss: 2.4964597903099173

Epoch: 6| Step: 5
Training loss: 1.1015185624687107
Validation loss: 2.4573665933724027

Epoch: 6| Step: 6
Training loss: 1.0154567872643068
Validation loss: 2.5020002208086085

Epoch: 6| Step: 7
Training loss: 1.4916676519522085
Validation loss: 2.4432901218346257

Epoch: 6| Step: 8
Training loss: 1.9374346568256164
Validation loss: 2.522020751004063

Epoch: 6| Step: 9
Training loss: 1.4045835157356759
Validation loss: 2.4418948834770764

Epoch: 6| Step: 10
Training loss: 2.012268346876556
Validation loss: 2.5092918528824075

Epoch: 6| Step: 11
Training loss: 1.368225488366143
Validation loss: 2.5021594022398546

Epoch: 6| Step: 12
Training loss: 1.3789148951791668
Validation loss: 2.5166161730405117

Epoch: 6| Step: 13
Training loss: 0.9610059760282004
Validation loss: 2.465427729739053

Epoch: 625| Step: 0
Training loss: 1.7883449264795266
Validation loss: 2.4886413912189678

Epoch: 6| Step: 1
Training loss: 2.2617608101051903
Validation loss: 2.510284456769584

Epoch: 6| Step: 2
Training loss: 1.6179979293159277
Validation loss: 2.4988469756624663

Epoch: 6| Step: 3
Training loss: 1.4444112081045841
Validation loss: 2.5241261692457653

Epoch: 6| Step: 4
Training loss: 1.3186202179744928
Validation loss: 2.5317370413198104

Epoch: 6| Step: 5
Training loss: 0.9992463729177943
Validation loss: 2.524078733662407

Epoch: 6| Step: 6
Training loss: 1.5991353321169552
Validation loss: 2.485520919779264

Epoch: 6| Step: 7
Training loss: 1.2300056676036237
Validation loss: 2.5458594956995624

Epoch: 6| Step: 8
Training loss: 1.1481602132897089
Validation loss: 2.531565324615689

Epoch: 6| Step: 9
Training loss: 1.7237364826958712
Validation loss: 2.4768436751419545

Epoch: 6| Step: 10
Training loss: 1.0457626240347002
Validation loss: 2.5315471339564404

Epoch: 6| Step: 11
Training loss: 1.72856528000712
Validation loss: 2.4703350479898414

Epoch: 6| Step: 12
Training loss: 1.4138224698354274
Validation loss: 2.5293912961725415

Epoch: 6| Step: 13
Training loss: 1.5809326878791319
Validation loss: 2.5252529511835133

Epoch: 626| Step: 0
Training loss: 1.3824652111787945
Validation loss: 2.47572089541747

Epoch: 6| Step: 1
Training loss: 0.9681231716525383
Validation loss: 2.515944889401799

Epoch: 6| Step: 2
Training loss: 1.0145006852427312
Validation loss: 2.558934624396796

Epoch: 6| Step: 3
Training loss: 0.7016983393484892
Validation loss: 2.461207307686635

Epoch: 6| Step: 4
Training loss: 1.652046050540568
Validation loss: 2.487248718329531

Epoch: 6| Step: 5
Training loss: 1.3331672545155664
Validation loss: 2.522076796268356

Epoch: 6| Step: 6
Training loss: 1.6006918424675738
Validation loss: 2.4531808782384066

Epoch: 6| Step: 7
Training loss: 1.9709307989923197
Validation loss: 2.44145071154071

Epoch: 6| Step: 8
Training loss: 2.3505013438376956
Validation loss: 2.513208052525863

Epoch: 6| Step: 9
Training loss: 1.3761549347379773
Validation loss: 2.5038460147749917

Epoch: 6| Step: 10
Training loss: 1.0774605956694365
Validation loss: 2.5169209122117273

Epoch: 6| Step: 11
Training loss: 1.4129906063968964
Validation loss: 2.5107721015758644

Epoch: 6| Step: 12
Training loss: 1.7369273881949043
Validation loss: 2.4916039407689703

Epoch: 6| Step: 13
Training loss: 1.373325889314149
Validation loss: 2.541462342515206

Epoch: 627| Step: 0
Training loss: 1.2551596488322518
Validation loss: 2.4908230585399114

Epoch: 6| Step: 1
Training loss: 1.292228740509145
Validation loss: 2.5183860104807625

Epoch: 6| Step: 2
Training loss: 1.6123231716933326
Validation loss: 2.5062495196874965

Epoch: 6| Step: 3
Training loss: 1.214186659347016
Validation loss: 2.5014670774221157

Epoch: 6| Step: 4
Training loss: 1.6878480905454176
Validation loss: 2.4597074305443236

Epoch: 6| Step: 5
Training loss: 2.708484958414666
Validation loss: 2.4372322644358353

Epoch: 6| Step: 6
Training loss: 1.2191151292085074
Validation loss: 2.5342605535240135

Epoch: 6| Step: 7
Training loss: 1.2544529753865048
Validation loss: 2.4668181838726877

Epoch: 6| Step: 8
Training loss: 1.7588731066815806
Validation loss: 2.530508975334763

Epoch: 6| Step: 9
Training loss: 1.5822744677046086
Validation loss: 2.466278015628399

Epoch: 6| Step: 10
Training loss: 1.2613419008374
Validation loss: 2.492359631835691

Epoch: 6| Step: 11
Training loss: 1.2783563082809233
Validation loss: 2.443428100554261

Epoch: 6| Step: 12
Training loss: 1.5221085449492169
Validation loss: 2.535062789869118

Epoch: 6| Step: 13
Training loss: 0.6719723120900423
Validation loss: 2.460933149717737

Epoch: 628| Step: 0
Training loss: 1.4853671322018462
Validation loss: 2.5285804148413216

Epoch: 6| Step: 1
Training loss: 1.4499041229646168
Validation loss: 2.4431998399475106

Epoch: 6| Step: 2
Training loss: 1.7184698396710396
Validation loss: 2.4952174658754616

Epoch: 6| Step: 3
Training loss: 0.8138916861479177
Validation loss: 2.5124049774471255

Epoch: 6| Step: 4
Training loss: 0.9856093705509813
Validation loss: 2.491627121014542

Epoch: 6| Step: 5
Training loss: 1.4135582377793754
Validation loss: 2.4877528736871364

Epoch: 6| Step: 6
Training loss: 1.4737721877171017
Validation loss: 2.505725166597139

Epoch: 6| Step: 7
Training loss: 2.063356972878924
Validation loss: 2.5874204771125187

Epoch: 6| Step: 8
Training loss: 1.4158830251761816
Validation loss: 2.541238984494173

Epoch: 6| Step: 9
Training loss: 1.596096555284452
Validation loss: 2.5469257212035545

Epoch: 6| Step: 10
Training loss: 0.7242662383376841
Validation loss: 2.5344728770218357

Epoch: 6| Step: 11
Training loss: 2.2139384792915746
Validation loss: 2.513540301073044

Epoch: 6| Step: 12
Training loss: 1.0437319816815813
Validation loss: 2.5304401398025274

Epoch: 6| Step: 13
Training loss: 1.7113667128269425
Validation loss: 2.5159331418146342

Epoch: 629| Step: 0
Training loss: 1.3483255244823866
Validation loss: 2.56594173902419

Epoch: 6| Step: 1
Training loss: 1.592705477838179
Validation loss: 2.502146945471351

Epoch: 6| Step: 2
Training loss: 1.2526361325230562
Validation loss: 2.481824375991025

Epoch: 6| Step: 3
Training loss: 1.1173034821174297
Validation loss: 2.4892596024334495

Epoch: 6| Step: 4
Training loss: 1.6786865090572802
Validation loss: 2.403490861299505

Epoch: 6| Step: 5
Training loss: 1.7234169454723614
Validation loss: 2.4593160808673282

Epoch: 6| Step: 6
Training loss: 1.152537339323482
Validation loss: 2.4925064066491283

Epoch: 6| Step: 7
Training loss: 1.5182494417890215
Validation loss: 2.521498484984399

Epoch: 6| Step: 8
Training loss: 1.522171668367986
Validation loss: 2.478786125631211

Epoch: 6| Step: 9
Training loss: 1.3577327235131866
Validation loss: 2.4363833873376914

Epoch: 6| Step: 10
Training loss: 1.25816311895514
Validation loss: 2.5062674561608334

Epoch: 6| Step: 11
Training loss: 1.5786184917898465
Validation loss: 2.512945742885019

Epoch: 6| Step: 12
Training loss: 0.90960204970331
Validation loss: 2.5413525624471545

Epoch: 6| Step: 13
Training loss: 2.7112773935034213
Validation loss: 2.495786648074567

Epoch: 630| Step: 0
Training loss: 0.941442465184509
Validation loss: 2.5111137361522147

Epoch: 6| Step: 1
Training loss: 1.992081762761503
Validation loss: 2.514809730805646

Epoch: 6| Step: 2
Training loss: 1.1302197480687375
Validation loss: 2.5420788927086173

Epoch: 6| Step: 3
Training loss: 2.1890518133758934
Validation loss: 2.490408139617637

Epoch: 6| Step: 4
Training loss: 1.4626655354514277
Validation loss: 2.507865522108635

Epoch: 6| Step: 5
Training loss: 1.5233327976339943
Validation loss: 2.5139394718519217

Epoch: 6| Step: 6
Training loss: 1.4964487635657757
Validation loss: 2.5447624368836546

Epoch: 6| Step: 7
Training loss: 1.3062724462889492
Validation loss: 2.505607473068975

Epoch: 6| Step: 8
Training loss: 1.390937170072785
Validation loss: 2.5001177647243513

Epoch: 6| Step: 9
Training loss: 0.8820893693398189
Validation loss: 2.4679303473324987

Epoch: 6| Step: 10
Training loss: 1.4918684693262665
Validation loss: 2.4563044436193606

Epoch: 6| Step: 11
Training loss: 1.6577184393370432
Validation loss: 2.5438711395891525

Epoch: 6| Step: 12
Training loss: 1.5909047628319066
Validation loss: 2.4969178838375257

Epoch: 6| Step: 13
Training loss: 1.4707202277132643
Validation loss: 2.5078977633533035

Epoch: 631| Step: 0
Training loss: 1.7440515647098342
Validation loss: 2.4823840111550015

Epoch: 6| Step: 1
Training loss: 2.2848526190508855
Validation loss: 2.4895480635668377

Epoch: 6| Step: 2
Training loss: 1.3353004498231522
Validation loss: 2.4884418838734197

Epoch: 6| Step: 3
Training loss: 1.1721328960200341
Validation loss: 2.492567414735822

Epoch: 6| Step: 4
Training loss: 1.6322255516984874
Validation loss: 2.516623859520906

Epoch: 6| Step: 5
Training loss: 1.1542863409655757
Validation loss: 2.479280302883924

Epoch: 6| Step: 6
Training loss: 1.5774794665177598
Validation loss: 2.5205320237356457

Epoch: 6| Step: 7
Training loss: 0.9749716045450706
Validation loss: 2.49861839633997

Epoch: 6| Step: 8
Training loss: 1.066091581876614
Validation loss: 2.507848507887137

Epoch: 6| Step: 9
Training loss: 1.2717160718444154
Validation loss: 2.517329857198109

Epoch: 6| Step: 10
Training loss: 1.409016917682824
Validation loss: 2.47477486900839

Epoch: 6| Step: 11
Training loss: 1.5073409059501066
Validation loss: 2.5079823655160762

Epoch: 6| Step: 12
Training loss: 1.6434358768052542
Validation loss: 2.5341423643162564

Epoch: 6| Step: 13
Training loss: 1.3835568337493984
Validation loss: 2.5034336393206083

Epoch: 632| Step: 0
Training loss: 1.3187155461443385
Validation loss: 2.4591287643844297

Epoch: 6| Step: 1
Training loss: 1.218536162568056
Validation loss: 2.4682399616978654

Epoch: 6| Step: 2
Training loss: 1.4373993216378567
Validation loss: 2.503133531740528

Epoch: 6| Step: 3
Training loss: 1.1938072150934094
Validation loss: 2.490214297016426

Epoch: 6| Step: 4
Training loss: 1.5583920455860816
Validation loss: 2.4665822046525587

Epoch: 6| Step: 5
Training loss: 1.2727077710218129
Validation loss: 2.4665502340590555

Epoch: 6| Step: 6
Training loss: 1.8651307082202946
Validation loss: 2.4954539455749605

Epoch: 6| Step: 7
Training loss: 1.2520758558273246
Validation loss: 2.4982996911321886

Epoch: 6| Step: 8
Training loss: 1.4420155630396163
Validation loss: 2.5198880878316348

Epoch: 6| Step: 9
Training loss: 1.0938540817874394
Validation loss: 2.5354564802517903

Epoch: 6| Step: 10
Training loss: 1.426809196408522
Validation loss: 2.4622594701848293

Epoch: 6| Step: 11
Training loss: 1.6445828608662085
Validation loss: 2.5351897499966363

Epoch: 6| Step: 12
Training loss: 2.3018755811845395
Validation loss: 2.5013993376995716

Epoch: 6| Step: 13
Training loss: 1.3858455433922194
Validation loss: 2.496478833264589

Epoch: 633| Step: 0
Training loss: 1.6338028528118316
Validation loss: 2.4901690007668176

Epoch: 6| Step: 1
Training loss: 0.9480760391458601
Validation loss: 2.48353890892047

Epoch: 6| Step: 2
Training loss: 1.625578117237212
Validation loss: 2.490200056096536

Epoch: 6| Step: 3
Training loss: 1.357969017357976
Validation loss: 2.4622358531208595

Epoch: 6| Step: 4
Training loss: 1.1311185602364597
Validation loss: 2.477355974841633

Epoch: 6| Step: 5
Training loss: 1.7164996587506829
Validation loss: 2.486575041445433

Epoch: 6| Step: 6
Training loss: 2.413102141032202
Validation loss: 2.502276384028261

Epoch: 6| Step: 7
Training loss: 1.154486419554906
Validation loss: 2.570255559554935

Epoch: 6| Step: 8
Training loss: 1.2005918513522091
Validation loss: 2.5070464881991152

Epoch: 6| Step: 9
Training loss: 1.3518503577128784
Validation loss: 2.4910675421889565

Epoch: 6| Step: 10
Training loss: 1.3122579260521516
Validation loss: 2.439767452329432

Epoch: 6| Step: 11
Training loss: 1.6911714668395028
Validation loss: 2.500411982071617

Epoch: 6| Step: 12
Training loss: 1.0165595230073021
Validation loss: 2.4840962398112496

Epoch: 6| Step: 13
Training loss: 1.515473033719233
Validation loss: 2.464958323855833

Epoch: 634| Step: 0
Training loss: 1.6703310816474395
Validation loss: 2.4956972513799722

Epoch: 6| Step: 1
Training loss: 1.3741746506113006
Validation loss: 2.5059671314308303

Epoch: 6| Step: 2
Training loss: 1.354681572466667
Validation loss: 2.539421555189864

Epoch: 6| Step: 3
Training loss: 2.191863585160388
Validation loss: 2.509034297817523

Epoch: 6| Step: 4
Training loss: 1.6340180103798885
Validation loss: 2.489551394842915

Epoch: 6| Step: 5
Training loss: 1.4775426931393347
Validation loss: 2.524726175174267

Epoch: 6| Step: 6
Training loss: 1.2298946918594147
Validation loss: 2.476856776686337

Epoch: 6| Step: 7
Training loss: 1.4801529117153154
Validation loss: 2.5154266737833044

Epoch: 6| Step: 8
Training loss: 1.336147091135014
Validation loss: 2.5087586582922503

Epoch: 6| Step: 9
Training loss: 1.5464707433953002
Validation loss: 2.466611828010128

Epoch: 6| Step: 10
Training loss: 1.332750322114687
Validation loss: 2.472752794578548

Epoch: 6| Step: 11
Training loss: 1.7733011739486984
Validation loss: 2.504495462294126

Epoch: 6| Step: 12
Training loss: 0.8293822479506281
Validation loss: 2.550283237565848

Epoch: 6| Step: 13
Training loss: 1.2583352181544725
Validation loss: 2.4872081161350508

Epoch: 635| Step: 0
Training loss: 1.1742336188496127
Validation loss: 2.451468559599666

Epoch: 6| Step: 1
Training loss: 1.2223497683028153
Validation loss: 2.4753425854091655

Epoch: 6| Step: 2
Training loss: 1.712297569617777
Validation loss: 2.5011680632761033

Epoch: 6| Step: 3
Training loss: 1.357652383896061
Validation loss: 2.5367525281361094

Epoch: 6| Step: 4
Training loss: 1.2777117744389925
Validation loss: 2.4960483904642174

Epoch: 6| Step: 5
Training loss: 1.3826767590812592
Validation loss: 2.426101224618018

Epoch: 6| Step: 6
Training loss: 1.5953769980907295
Validation loss: 2.496720514391899

Epoch: 6| Step: 7
Training loss: 2.2931985301312645
Validation loss: 2.4485111137056377

Epoch: 6| Step: 8
Training loss: 1.3909030164919176
Validation loss: 2.486238489775566

Epoch: 6| Step: 9
Training loss: 1.1920821477054557
Validation loss: 2.485174480614985

Epoch: 6| Step: 10
Training loss: 1.2193500313287269
Validation loss: 2.5126119495344335

Epoch: 6| Step: 11
Training loss: 1.2663449253151848
Validation loss: 2.499595076059912

Epoch: 6| Step: 12
Training loss: 1.230200069097183
Validation loss: 2.4433890018663913

Epoch: 6| Step: 13
Training loss: 0.5346865576730759
Validation loss: 2.5372462185492966

Epoch: 636| Step: 0
Training loss: 0.861281136336104
Validation loss: 2.503678932280816

Epoch: 6| Step: 1
Training loss: 1.9709608591878016
Validation loss: 2.4791239821565805

Epoch: 6| Step: 2
Training loss: 1.88410784850447
Validation loss: 2.5734056570489816

Epoch: 6| Step: 3
Training loss: 1.0684580086153674
Validation loss: 2.5401885322014097

Epoch: 6| Step: 4
Training loss: 1.0450205533502384
Validation loss: 2.5322160668682345

Epoch: 6| Step: 5
Training loss: 1.1450211970270399
Validation loss: 2.537438314106247

Epoch: 6| Step: 6
Training loss: 1.8749801634692886
Validation loss: 2.499539701581772

Epoch: 6| Step: 7
Training loss: 2.2625637024399725
Validation loss: 2.5175800287043213

Epoch: 6| Step: 8
Training loss: 0.973568959184535
Validation loss: 2.4702626665938676

Epoch: 6| Step: 9
Training loss: 1.3249263167136727
Validation loss: 2.4815509781700276

Epoch: 6| Step: 10
Training loss: 1.342964519429714
Validation loss: 2.528213918458139

Epoch: 6| Step: 11
Training loss: 1.2149132221142653
Validation loss: 2.505409608367756

Epoch: 6| Step: 12
Training loss: 1.3225379561978954
Validation loss: 2.475473612970249

Epoch: 6| Step: 13
Training loss: 0.937977828007783
Validation loss: 2.4802975769383293

Epoch: 637| Step: 0
Training loss: 1.229200551271796
Validation loss: 2.461325415088524

Epoch: 6| Step: 1
Training loss: 1.1495020078398437
Validation loss: 2.495811814039356

Epoch: 6| Step: 2
Training loss: 1.1131979927920779
Validation loss: 2.5174065962998404

Epoch: 6| Step: 3
Training loss: 1.6428263836107644
Validation loss: 2.4880129089485497

Epoch: 6| Step: 4
Training loss: 1.593374993579027
Validation loss: 2.531984925667936

Epoch: 6| Step: 5
Training loss: 1.9096750850832631
Validation loss: 2.492154454758513

Epoch: 6| Step: 6
Training loss: 1.210181215446162
Validation loss: 2.486528570047678

Epoch: 6| Step: 7
Training loss: 1.5189462825325195
Validation loss: 2.5282537977360824

Epoch: 6| Step: 8
Training loss: 1.524176941439516
Validation loss: 2.5124841821701462

Epoch: 6| Step: 9
Training loss: 1.6023905776540537
Validation loss: 2.5473761544536653

Epoch: 6| Step: 10
Training loss: 0.8512821260907568
Validation loss: 2.5042319359940346

Epoch: 6| Step: 11
Training loss: 1.4273332901327622
Validation loss: 2.49298465208344

Epoch: 6| Step: 12
Training loss: 1.8847247657893025
Validation loss: 2.5343940732223635

Epoch: 6| Step: 13
Training loss: 1.2369911380657002
Validation loss: 2.466499521985822

Epoch: 638| Step: 0
Training loss: 1.2247553834160285
Validation loss: 2.4608501709865602

Epoch: 6| Step: 1
Training loss: 1.156021147065954
Validation loss: 2.489675391344388

Epoch: 6| Step: 2
Training loss: 1.6137441197413034
Validation loss: 2.4845810238062533

Epoch: 6| Step: 3
Training loss: 1.2583519862647194
Validation loss: 2.4610425555229942

Epoch: 6| Step: 4
Training loss: 1.654466424425528
Validation loss: 2.49651282659033

Epoch: 6| Step: 5
Training loss: 1.213654552442912
Validation loss: 2.4996383887431226

Epoch: 6| Step: 6
Training loss: 1.7167725718647417
Validation loss: 2.518882845713203

Epoch: 6| Step: 7
Training loss: 2.066923311151657
Validation loss: 2.50404881897964

Epoch: 6| Step: 8
Training loss: 1.8334745728389108
Validation loss: 2.5081499570571704

Epoch: 6| Step: 9
Training loss: 1.4144470366415673
Validation loss: 2.4696245712155007

Epoch: 6| Step: 10
Training loss: 1.1624497884755836
Validation loss: 2.4682211578831725

Epoch: 6| Step: 11
Training loss: 1.4980326307432714
Validation loss: 2.5670595869399793

Epoch: 6| Step: 12
Training loss: 1.3480301048188519
Validation loss: 2.533223937011709

Epoch: 6| Step: 13
Training loss: 1.4905236039773646
Validation loss: 2.500554827168898

Epoch: 639| Step: 0
Training loss: 1.375553886520066
Validation loss: 2.4773192707254705

Epoch: 6| Step: 1
Training loss: 1.5045320868323904
Validation loss: 2.49956218721088

Epoch: 6| Step: 2
Training loss: 1.4709678300235227
Validation loss: 2.450366266809974

Epoch: 6| Step: 3
Training loss: 1.535683655354155
Validation loss: 2.4445400145552876

Epoch: 6| Step: 4
Training loss: 1.1538605615743354
Validation loss: 2.4932286379176305

Epoch: 6| Step: 5
Training loss: 1.3293016494723524
Validation loss: 2.543682142170287

Epoch: 6| Step: 6
Training loss: 1.4651045503512994
Validation loss: 2.467752937834184

Epoch: 6| Step: 7
Training loss: 1.1455974104785422
Validation loss: 2.456859919468724

Epoch: 6| Step: 8
Training loss: 1.8533661503710779
Validation loss: 2.5354097965959106

Epoch: 6| Step: 9
Training loss: 1.7299604853488795
Validation loss: 2.514305632438539

Epoch: 6| Step: 10
Training loss: 2.0785337347321735
Validation loss: 2.5072288719596654

Epoch: 6| Step: 11
Training loss: 1.3046853984884366
Validation loss: 2.469929164428565

Epoch: 6| Step: 12
Training loss: 0.9715988355573867
Validation loss: 2.4954406653175805

Epoch: 6| Step: 13
Training loss: 1.3984538668734974
Validation loss: 2.443530875760924

Epoch: 640| Step: 0
Training loss: 1.071384310943482
Validation loss: 2.4638414538518436

Epoch: 6| Step: 1
Training loss: 1.4160765746580974
Validation loss: 2.4572568100250614

Epoch: 6| Step: 2
Training loss: 1.3064745696286728
Validation loss: 2.486734771102161

Epoch: 6| Step: 3
Training loss: 1.8548616399859077
Validation loss: 2.486907209220722

Epoch: 6| Step: 4
Training loss: 1.1545869362778456
Validation loss: 2.5403436949295672

Epoch: 6| Step: 5
Training loss: 1.5035855037935215
Validation loss: 2.4426461149396195

Epoch: 6| Step: 6
Training loss: 2.4077468774011037
Validation loss: 2.5456619499319344

Epoch: 6| Step: 7
Training loss: 1.4406413708333832
Validation loss: 2.4830436139334258

Epoch: 6| Step: 8
Training loss: 1.0499123877349246
Validation loss: 2.5420856026343026

Epoch: 6| Step: 9
Training loss: 1.112542318760788
Validation loss: 2.4755335972064194

Epoch: 6| Step: 10
Training loss: 1.3827648262383618
Validation loss: 2.5191012779467354

Epoch: 6| Step: 11
Training loss: 1.1023314477354367
Validation loss: 2.4530265213038183

Epoch: 6| Step: 12
Training loss: 1.4143575286797556
Validation loss: 2.5205908243158768

Epoch: 6| Step: 13
Training loss: 0.9085725094648702
Validation loss: 2.535994497652685

Epoch: 641| Step: 0
Training loss: 1.2846555807110094
Validation loss: 2.5457605857626575

Epoch: 6| Step: 1
Training loss: 1.307642166548664
Validation loss: 2.583586629450182

Epoch: 6| Step: 2
Training loss: 1.45958798343064
Validation loss: 2.468907848756872

Epoch: 6| Step: 3
Training loss: 1.2883368559357788
Validation loss: 2.4736375995664464

Epoch: 6| Step: 4
Training loss: 1.329555997162037
Validation loss: 2.5321979537777866

Epoch: 6| Step: 5
Training loss: 1.1765500720255544
Validation loss: 2.5282467550132157

Epoch: 6| Step: 6
Training loss: 1.5549736334721103
Validation loss: 2.4694833617706147

Epoch: 6| Step: 7
Training loss: 1.4159687323862702
Validation loss: 2.497484452567334

Epoch: 6| Step: 8
Training loss: 2.0721735812499102
Validation loss: 2.515418881217985

Epoch: 6| Step: 9
Training loss: 1.202093648397968
Validation loss: 2.512299792106904

Epoch: 6| Step: 10
Training loss: 1.6846431992837005
Validation loss: 2.547126762105638

Epoch: 6| Step: 11
Training loss: 1.5855775621991854
Validation loss: 2.5090381079721626

Epoch: 6| Step: 12
Training loss: 1.374641458408488
Validation loss: 2.5321153361533226

Epoch: 6| Step: 13
Training loss: 0.9852702595917706
Validation loss: 2.5066368923658593

Epoch: 642| Step: 0
Training loss: 1.772401011060815
Validation loss: 2.536147540488778

Epoch: 6| Step: 1
Training loss: 1.3384689529004465
Validation loss: 2.5344768239245865

Epoch: 6| Step: 2
Training loss: 1.0864629777691406
Validation loss: 2.513676846904194

Epoch: 6| Step: 3
Training loss: 1.3168644772594846
Validation loss: 2.5606235623981317

Epoch: 6| Step: 4
Training loss: 0.7708364735788527
Validation loss: 2.5278061916961985

Epoch: 6| Step: 5
Training loss: 1.208253605722564
Validation loss: 2.534884728772812

Epoch: 6| Step: 6
Training loss: 1.5741112911378972
Validation loss: 2.5515604440730426

Epoch: 6| Step: 7
Training loss: 2.2215826730191885
Validation loss: 2.4849940600781952

Epoch: 6| Step: 8
Training loss: 1.8668690174416873
Validation loss: 2.5911822041872297

Epoch: 6| Step: 9
Training loss: 1.266853348669777
Validation loss: 2.469904502828357

Epoch: 6| Step: 10
Training loss: 1.6152675860495178
Validation loss: 2.524788755338176

Epoch: 6| Step: 11
Training loss: 0.6766029389874334
Validation loss: 2.581331972986056

Epoch: 6| Step: 12
Training loss: 1.6065279768339988
Validation loss: 2.5395303819823067

Epoch: 6| Step: 13
Training loss: 1.0725854282101337
Validation loss: 2.5130111014902283

Epoch: 643| Step: 0
Training loss: 1.272153054475935
Validation loss: 2.486513519289882

Epoch: 6| Step: 1
Training loss: 1.2112564651269477
Validation loss: 2.477611477585993

Epoch: 6| Step: 2
Training loss: 1.3162863475856355
Validation loss: 2.5295313129236012

Epoch: 6| Step: 3
Training loss: 1.3392789667958631
Validation loss: 2.4720442923996084

Epoch: 6| Step: 4
Training loss: 1.5895878916317172
Validation loss: 2.4838937190161463

Epoch: 6| Step: 5
Training loss: 2.365840717593936
Validation loss: 2.5024345469967297

Epoch: 6| Step: 6
Training loss: 1.3590798331580944
Validation loss: 2.4926102766622997

Epoch: 6| Step: 7
Training loss: 1.088551401097822
Validation loss: 2.4962416372730587

Epoch: 6| Step: 8
Training loss: 1.3840700885825645
Validation loss: 2.510215315830424

Epoch: 6| Step: 9
Training loss: 1.7753946537186138
Validation loss: 2.516673275322873

Epoch: 6| Step: 10
Training loss: 0.9939667975063267
Validation loss: 2.463667225447209

Epoch: 6| Step: 11
Training loss: 1.3333106734416598
Validation loss: 2.5123324540035137

Epoch: 6| Step: 12
Training loss: 1.3123528080103177
Validation loss: 2.494458537870383

Epoch: 6| Step: 13
Training loss: 1.420859340903272
Validation loss: 2.442466764475961

Epoch: 644| Step: 0
Training loss: 1.1764044646656049
Validation loss: 2.5150681663259697

Epoch: 6| Step: 1
Training loss: 1.08070363700158
Validation loss: 2.502818987565462

Epoch: 6| Step: 2
Training loss: 1.3783923263948374
Validation loss: 2.533935415730415

Epoch: 6| Step: 3
Training loss: 1.5555768560283307
Validation loss: 2.5117444024147337

Epoch: 6| Step: 4
Training loss: 1.4448805704888117
Validation loss: 2.5355494486420698

Epoch: 6| Step: 5
Training loss: 1.5919998133194397
Validation loss: 2.5023171269419735

Epoch: 6| Step: 6
Training loss: 1.2191581042795847
Validation loss: 2.4746713122358774

Epoch: 6| Step: 7
Training loss: 1.3942763151627018
Validation loss: 2.508724839073163

Epoch: 6| Step: 8
Training loss: 1.581466837855815
Validation loss: 2.52009969449807

Epoch: 6| Step: 9
Training loss: 0.9517847237010536
Validation loss: 2.4750094528655784

Epoch: 6| Step: 10
Training loss: 2.100133473832117
Validation loss: 2.53787347484106

Epoch: 6| Step: 11
Training loss: 1.4822729385204398
Validation loss: 2.530088515974858

Epoch: 6| Step: 12
Training loss: 1.1976065469221409
Validation loss: 2.542277461600967

Epoch: 6| Step: 13
Training loss: 1.438891773679207
Validation loss: 2.5147454230990514

Epoch: 645| Step: 0
Training loss: 1.7421575295645924
Validation loss: 2.449130700617182

Epoch: 6| Step: 1
Training loss: 1.5635122453571753
Validation loss: 2.5510134572500927

Epoch: 6| Step: 2
Training loss: 1.190750241638582
Validation loss: 2.5204326772611974

Epoch: 6| Step: 3
Training loss: 1.4669062628256915
Validation loss: 2.4936831356960445

Epoch: 6| Step: 4
Training loss: 1.768082587824668
Validation loss: 2.525611749686313

Epoch: 6| Step: 5
Training loss: 2.1445758307709712
Validation loss: 2.554845163769223

Epoch: 6| Step: 6
Training loss: 0.9295436202838994
Validation loss: 2.4900808978011786

Epoch: 6| Step: 7
Training loss: 1.3319268507331927
Validation loss: 2.4473340104045

Epoch: 6| Step: 8
Training loss: 1.1629961493207794
Validation loss: 2.515678640089386

Epoch: 6| Step: 9
Training loss: 1.1494352197766042
Validation loss: 2.4319055564398298

Epoch: 6| Step: 10
Training loss: 1.4768756352769128
Validation loss: 2.520510095408536

Epoch: 6| Step: 11
Training loss: 1.2491150107379883
Validation loss: 2.489280432715069

Epoch: 6| Step: 12
Training loss: 0.705024209959562
Validation loss: 2.4344589472300107

Epoch: 6| Step: 13
Training loss: 1.4592434450113085
Validation loss: 2.5009683312880453

Epoch: 646| Step: 0
Training loss: 1.735618283152676
Validation loss: 2.4983299460784165

Epoch: 6| Step: 1
Training loss: 1.2356091860201561
Validation loss: 2.47711059637553

Epoch: 6| Step: 2
Training loss: 1.7735485428651019
Validation loss: 2.4867216288171208

Epoch: 6| Step: 3
Training loss: 1.0297033097438368
Validation loss: 2.506238640619414

Epoch: 6| Step: 4
Training loss: 1.1104239219633671
Validation loss: 2.55807930462542

Epoch: 6| Step: 5
Training loss: 1.4863364661806029
Validation loss: 2.4626552552624954

Epoch: 6| Step: 6
Training loss: 1.4247504701816087
Validation loss: 2.4638196530837186

Epoch: 6| Step: 7
Training loss: 1.2863702113231357
Validation loss: 2.4805793751103566

Epoch: 6| Step: 8
Training loss: 1.7658491414352522
Validation loss: 2.4895453120427105

Epoch: 6| Step: 9
Training loss: 1.2411543670416416
Validation loss: 2.4346298566476956

Epoch: 6| Step: 10
Training loss: 0.830618038736742
Validation loss: 2.4976476410435122

Epoch: 6| Step: 11
Training loss: 1.2109890834527366
Validation loss: 2.500165185290753

Epoch: 6| Step: 12
Training loss: 1.1188219825134371
Validation loss: 2.4754679636773007

Epoch: 6| Step: 13
Training loss: 2.4599766384349073
Validation loss: 2.503870246851951

Epoch: 647| Step: 0
Training loss: 0.6018576455312888
Validation loss: 2.55724112834147

Epoch: 6| Step: 1
Training loss: 1.2156157172076636
Validation loss: 2.541078305409919

Epoch: 6| Step: 2
Training loss: 2.138566969994194
Validation loss: 2.5730106462307862

Epoch: 6| Step: 3
Training loss: 1.5870498739961734
Validation loss: 2.563869398543654

Epoch: 6| Step: 4
Training loss: 1.3736675048161553
Validation loss: 2.584358643675472

Epoch: 6| Step: 5
Training loss: 1.5995993887527873
Validation loss: 2.615362838431174

Epoch: 6| Step: 6
Training loss: 1.5336718966394827
Validation loss: 2.5060731400860297

Epoch: 6| Step: 7
Training loss: 1.4538496938094878
Validation loss: 2.5325075512518076

Epoch: 6| Step: 8
Training loss: 1.4874232264348852
Validation loss: 2.5717927762226105

Epoch: 6| Step: 9
Training loss: 1.458800686018594
Validation loss: 2.5563328822387

Epoch: 6| Step: 10
Training loss: 1.155835670261638
Validation loss: 2.5018880902794747

Epoch: 6| Step: 11
Training loss: 1.3795737577148472
Validation loss: 2.4925387807398773

Epoch: 6| Step: 12
Training loss: 1.3234243344999852
Validation loss: 2.500157613810585

Epoch: 6| Step: 13
Training loss: 1.5749461573525523
Validation loss: 2.4319014230377545

Epoch: 648| Step: 0
Training loss: 1.5829873292552028
Validation loss: 2.512556842550118

Epoch: 6| Step: 1
Training loss: 1.2982805747125559
Validation loss: 2.5022925642735423

Epoch: 6| Step: 2
Training loss: 1.0885037623959424
Validation loss: 2.541371251863219

Epoch: 6| Step: 3
Training loss: 1.323819170505364
Validation loss: 2.4689149143376112

Epoch: 6| Step: 4
Training loss: 1.477305230536717
Validation loss: 2.514382649405267

Epoch: 6| Step: 5
Training loss: 1.5849891420347466
Validation loss: 2.5007863889599773

Epoch: 6| Step: 6
Training loss: 1.7383400896379373
Validation loss: 2.5373095316184244

Epoch: 6| Step: 7
Training loss: 1.9960277568859495
Validation loss: 2.4627282433250772

Epoch: 6| Step: 8
Training loss: 1.2191355657793386
Validation loss: 2.5018327814121375

Epoch: 6| Step: 9
Training loss: 1.2234071126114034
Validation loss: 2.5313483279510147

Epoch: 6| Step: 10
Training loss: 1.3271415210625055
Validation loss: 2.4998268580213243

Epoch: 6| Step: 11
Training loss: 1.4844501677102668
Validation loss: 2.4908638930777705

Epoch: 6| Step: 12
Training loss: 1.398273309200637
Validation loss: 2.4884850671974164

Epoch: 6| Step: 13
Training loss: 1.2263756870947895
Validation loss: 2.4728560325593127

Epoch: 649| Step: 0
Training loss: 1.8080869421858368
Validation loss: 2.4230508670888167

Epoch: 6| Step: 1
Training loss: 1.2156331236109408
Validation loss: 2.4865536791855956

Epoch: 6| Step: 2
Training loss: 1.4197471542638869
Validation loss: 2.5226442088320944

Epoch: 6| Step: 3
Training loss: 1.3469907140036492
Validation loss: 2.5765059572166913

Epoch: 6| Step: 4
Training loss: 1.4283571985239958
Validation loss: 2.548366689334196

Epoch: 6| Step: 5
Training loss: 0.9551202495623063
Validation loss: 2.5088049585623593

Epoch: 6| Step: 6
Training loss: 1.168310823391494
Validation loss: 2.4794705646650286

Epoch: 6| Step: 7
Training loss: 1.7346754758896064
Validation loss: 2.503741406752358

Epoch: 6| Step: 8
Training loss: 1.7362564466890926
Validation loss: 2.4657473359081026

Epoch: 6| Step: 9
Training loss: 1.8366965165571327
Validation loss: 2.462809016521834

Epoch: 6| Step: 10
Training loss: 1.3648531794972902
Validation loss: 2.4884836146131115

Epoch: 6| Step: 11
Training loss: 1.6020132779536718
Validation loss: 2.4390771799592446

Epoch: 6| Step: 12
Training loss: 1.2296456142014915
Validation loss: 2.5417452977721555

Epoch: 6| Step: 13
Training loss: 1.536892518156596
Validation loss: 2.4738810717052537

Epoch: 650| Step: 0
Training loss: 0.8344998341303638
Validation loss: 2.545133113180686

Epoch: 6| Step: 1
Training loss: 1.377961480782996
Validation loss: 2.4833633768588186

Epoch: 6| Step: 2
Training loss: 1.3637600907635117
Validation loss: 2.4475289185401903

Epoch: 6| Step: 3
Training loss: 1.5651480551694879
Validation loss: 2.5175150102006025

Epoch: 6| Step: 4
Training loss: 1.4372072336360444
Validation loss: 2.4197918229280075

Epoch: 6| Step: 5
Training loss: 1.0185460266739885
Validation loss: 2.4859132241311688

Epoch: 6| Step: 6
Training loss: 1.5639356502651143
Validation loss: 2.5177303165009954

Epoch: 6| Step: 7
Training loss: 1.9866142554484933
Validation loss: 2.50956572939255

Epoch: 6| Step: 8
Training loss: 1.5177688380608472
Validation loss: 2.4539368242830117

Epoch: 6| Step: 9
Training loss: 1.2925848722353834
Validation loss: 2.5094470983618455

Epoch: 6| Step: 10
Training loss: 1.4707776135633015
Validation loss: 2.437528595863129

Epoch: 6| Step: 11
Training loss: 0.9642180603252362
Validation loss: 2.5366407038561034

Epoch: 6| Step: 12
Training loss: 1.7119990152017488
Validation loss: 2.484495404994766

Epoch: 6| Step: 13
Training loss: 1.0502993815362398
Validation loss: 2.47257199332023

Epoch: 651| Step: 0
Training loss: 1.6583020435748759
Validation loss: 2.525813029050353

Epoch: 6| Step: 1
Training loss: 1.5732068768829877
Validation loss: 2.5981874507397205

Epoch: 6| Step: 2
Training loss: 0.9584328489187626
Validation loss: 2.5359012372420184

Epoch: 6| Step: 3
Training loss: 1.4049672103938224
Validation loss: 2.448158690654689

Epoch: 6| Step: 4
Training loss: 1.4196731790353077
Validation loss: 2.4976071945547678

Epoch: 6| Step: 5
Training loss: 1.5098816899820064
Validation loss: 2.5223862334420786

Epoch: 6| Step: 6
Training loss: 1.5547220044164956
Validation loss: 2.4950658323149355

Epoch: 6| Step: 7
Training loss: 1.2857194495475854
Validation loss: 2.480659866237417

Epoch: 6| Step: 8
Training loss: 1.5211384959171161
Validation loss: 2.4754210321048995

Epoch: 6| Step: 9
Training loss: 1.1349192004915094
Validation loss: 2.4985538591553755

Epoch: 6| Step: 10
Training loss: 1.1540566338008613
Validation loss: 2.538721140592375

Epoch: 6| Step: 11
Training loss: 2.004174762902459
Validation loss: 2.519768731042375

Epoch: 6| Step: 12
Training loss: 0.8209831039836766
Validation loss: 2.528811375544578

Epoch: 6| Step: 13
Training loss: 1.759241701432594
Validation loss: 2.5026306872791437

Epoch: 652| Step: 0
Training loss: 1.473287431957008
Validation loss: 2.5069311105613314

Epoch: 6| Step: 1
Training loss: 1.3242444511327567
Validation loss: 2.5149088325286875

Epoch: 6| Step: 2
Training loss: 0.8268349153544168
Validation loss: 2.4861135072212117

Epoch: 6| Step: 3
Training loss: 1.5529943092669332
Validation loss: 2.5300308263015245

Epoch: 6| Step: 4
Training loss: 1.393077274016713
Validation loss: 2.5029598449985073

Epoch: 6| Step: 5
Training loss: 1.507926185551865
Validation loss: 2.395075471562246

Epoch: 6| Step: 6
Training loss: 1.2604145123592072
Validation loss: 2.4665167102224683

Epoch: 6| Step: 7
Training loss: 1.3968258740280142
Validation loss: 2.435569716170294

Epoch: 6| Step: 8
Training loss: 1.5424921386122732
Validation loss: 2.523180499829091

Epoch: 6| Step: 9
Training loss: 1.6606140223647439
Validation loss: 2.529907429577596

Epoch: 6| Step: 10
Training loss: 1.0686471052999178
Validation loss: 2.4683587545811996

Epoch: 6| Step: 11
Training loss: 1.158870922638986
Validation loss: 2.455949372686955

Epoch: 6| Step: 12
Training loss: 1.2851992892679196
Validation loss: 2.4877036016855376

Epoch: 6| Step: 13
Training loss: 2.5245921797050954
Validation loss: 2.5452830809467164

Epoch: 653| Step: 0
Training loss: 1.2719396663788094
Validation loss: 2.4497836036454177

Epoch: 6| Step: 1
Training loss: 1.283881207143319
Validation loss: 2.5210192279687265

Epoch: 6| Step: 2
Training loss: 1.4737687095638687
Validation loss: 2.534181008682477

Epoch: 6| Step: 3
Training loss: 1.7934408792110605
Validation loss: 2.4236820049287138

Epoch: 6| Step: 4
Training loss: 1.3314459177480014
Validation loss: 2.5011332763276086

Epoch: 6| Step: 5
Training loss: 1.3735508217784442
Validation loss: 2.510553956612522

Epoch: 6| Step: 6
Training loss: 2.1797712850020377
Validation loss: 2.543707957014424

Epoch: 6| Step: 7
Training loss: 1.3847549933064411
Validation loss: 2.558017699244058

Epoch: 6| Step: 8
Training loss: 1.0943322403079556
Validation loss: 2.5433935874705633

Epoch: 6| Step: 9
Training loss: 1.212571450713956
Validation loss: 2.521605809989228

Epoch: 6| Step: 10
Training loss: 1.0171213131420893
Validation loss: 2.4585107127901207

Epoch: 6| Step: 11
Training loss: 0.9893383659862861
Validation loss: 2.4858532376913427

Epoch: 6| Step: 12
Training loss: 0.8456936807083081
Validation loss: 2.5694345724782193

Epoch: 6| Step: 13
Training loss: 1.6751415392159734
Validation loss: 2.5235011148214057

Epoch: 654| Step: 0
Training loss: 1.4389916020427331
Validation loss: 2.473884235474905

Epoch: 6| Step: 1
Training loss: 1.7319878310773786
Validation loss: 2.5295169953883456

Epoch: 6| Step: 2
Training loss: 2.450838031299511
Validation loss: 2.460764824557808

Epoch: 6| Step: 3
Training loss: 1.2789463174423996
Validation loss: 2.507568371004359

Epoch: 6| Step: 4
Training loss: 1.0578569050741973
Validation loss: 2.4839404079387086

Epoch: 6| Step: 5
Training loss: 1.0650692897517753
Validation loss: 2.445692693111023

Epoch: 6| Step: 6
Training loss: 1.2257824987109738
Validation loss: 2.5135895745335697

Epoch: 6| Step: 7
Training loss: 1.3263213982091033
Validation loss: 2.4866168921786063

Epoch: 6| Step: 8
Training loss: 1.337524274801846
Validation loss: 2.438767790521106

Epoch: 6| Step: 9
Training loss: 1.0658114944101613
Validation loss: 2.4949155746710225

Epoch: 6| Step: 10
Training loss: 1.0298516011043732
Validation loss: 2.476645087899188

Epoch: 6| Step: 11
Training loss: 1.7131315472939432
Validation loss: 2.4495705422575536

Epoch: 6| Step: 12
Training loss: 0.7626849966291798
Validation loss: 2.5418669418139093

Epoch: 6| Step: 13
Training loss: 1.6576112874963118
Validation loss: 2.464815289020531

Epoch: 655| Step: 0
Training loss: 1.0210091121651796
Validation loss: 2.4985051536367116

Epoch: 6| Step: 1
Training loss: 1.9731398188046918
Validation loss: 2.4675043529775436

Epoch: 6| Step: 2
Training loss: 1.3114207235351405
Validation loss: 2.5367609080126656

Epoch: 6| Step: 3
Training loss: 2.031333569494838
Validation loss: 2.459731271995791

Epoch: 6| Step: 4
Training loss: 1.4362104685682473
Validation loss: 2.534795448780207

Epoch: 6| Step: 5
Training loss: 1.7074823896357285
Validation loss: 2.54945468263407

Epoch: 6| Step: 6
Training loss: 1.0866592533545192
Validation loss: 2.551060910541473

Epoch: 6| Step: 7
Training loss: 1.1247138083206485
Validation loss: 2.615037628019496

Epoch: 6| Step: 8
Training loss: 1.175726195405678
Validation loss: 2.5604148167329033

Epoch: 6| Step: 9
Training loss: 1.3976961440421345
Validation loss: 2.5042016550988295

Epoch: 6| Step: 10
Training loss: 1.5620327060025285
Validation loss: 2.4718962175555848

Epoch: 6| Step: 11
Training loss: 1.060954259815902
Validation loss: 2.5282684494368173

Epoch: 6| Step: 12
Training loss: 1.1301993913194228
Validation loss: 2.494171585138952

Epoch: 6| Step: 13
Training loss: 1.3531538134319694
Validation loss: 2.404141546831072

Epoch: 656| Step: 0
Training loss: 1.0021582796828683
Validation loss: 2.5085284982336304

Epoch: 6| Step: 1
Training loss: 1.5535468896641034
Validation loss: 2.430193579792287

Epoch: 6| Step: 2
Training loss: 1.360505215195681
Validation loss: 2.5029015653705344

Epoch: 6| Step: 3
Training loss: 2.244731987840666
Validation loss: 2.5052971556282326

Epoch: 6| Step: 4
Training loss: 1.396362640837022
Validation loss: 2.479668672329417

Epoch: 6| Step: 5
Training loss: 1.3139662953471172
Validation loss: 2.5062440430791812

Epoch: 6| Step: 6
Training loss: 1.4172897184239774
Validation loss: 2.517477468975173

Epoch: 6| Step: 7
Training loss: 0.9453656520560398
Validation loss: 2.4931440451279587

Epoch: 6| Step: 8
Training loss: 1.2126075795220677
Validation loss: 2.48282333575382

Epoch: 6| Step: 9
Training loss: 1.347952016910312
Validation loss: 2.4967268353844507

Epoch: 6| Step: 10
Training loss: 1.4310089841250069
Validation loss: 2.431642998192895

Epoch: 6| Step: 11
Training loss: 1.1069423168698527
Validation loss: 2.521171409522551

Epoch: 6| Step: 12
Training loss: 1.5132526826303785
Validation loss: 2.473522943721445

Epoch: 6| Step: 13
Training loss: 1.448253052787125
Validation loss: 2.5167032737354056

Epoch: 657| Step: 0
Training loss: 0.9764857147546989
Validation loss: 2.49411314692521

Epoch: 6| Step: 1
Training loss: 1.197939958207741
Validation loss: 2.4646060495447304

Epoch: 6| Step: 2
Training loss: 0.9222443051036985
Validation loss: 2.516711896595728

Epoch: 6| Step: 3
Training loss: 1.1220902855326387
Validation loss: 2.515923939550657

Epoch: 6| Step: 4
Training loss: 1.4141739437805458
Validation loss: 2.504329254360628

Epoch: 6| Step: 5
Training loss: 1.1426755162652724
Validation loss: 2.513194978292928

Epoch: 6| Step: 6
Training loss: 1.1199682880067396
Validation loss: 2.501938636325858

Epoch: 6| Step: 7
Training loss: 1.7743824193355267
Validation loss: 2.515600329821888

Epoch: 6| Step: 8
Training loss: 1.4569342941465573
Validation loss: 2.564871809118324

Epoch: 6| Step: 9
Training loss: 1.6076694080082374
Validation loss: 2.5133878431069223

Epoch: 6| Step: 10
Training loss: 1.2360952438212378
Validation loss: 2.4657152619550327

Epoch: 6| Step: 11
Training loss: 1.2076301940484067
Validation loss: 2.557502591688107

Epoch: 6| Step: 12
Training loss: 2.323334136079771
Validation loss: 2.502488978964443

Epoch: 6| Step: 13
Training loss: 1.5437293387200282
Validation loss: 2.538018560997014

Epoch: 658| Step: 0
Training loss: 1.2928239908461527
Validation loss: 2.4929844854920424

Epoch: 6| Step: 1
Training loss: 2.177824146832422
Validation loss: 2.477980346331008

Epoch: 6| Step: 2
Training loss: 1.526008666357627
Validation loss: 2.51691703657937

Epoch: 6| Step: 3
Training loss: 1.754890420649896
Validation loss: 2.4510982959794982

Epoch: 6| Step: 4
Training loss: 1.2341254259663406
Validation loss: 2.4409073120885214

Epoch: 6| Step: 5
Training loss: 2.0076204794411305
Validation loss: 2.4847870501331912

Epoch: 6| Step: 6
Training loss: 1.437149170897162
Validation loss: 2.4772751119576975

Epoch: 6| Step: 7
Training loss: 0.7665102375812498
Validation loss: 2.469439334355714

Epoch: 6| Step: 8
Training loss: 1.531757426362661
Validation loss: 2.5320966280297297

Epoch: 6| Step: 9
Training loss: 1.3710713615654526
Validation loss: 2.5101600954637524

Epoch: 6| Step: 10
Training loss: 0.9560572436165077
Validation loss: 2.4894737486925202

Epoch: 6| Step: 11
Training loss: 1.295570728804947
Validation loss: 2.5209648391591135

Epoch: 6| Step: 12
Training loss: 0.7567767507729122
Validation loss: 2.466977276475696

Epoch: 6| Step: 13
Training loss: 0.6534872711287482
Validation loss: 2.5052830797499492

Epoch: 659| Step: 0
Training loss: 1.1379633117151953
Validation loss: 2.508584618061346

Epoch: 6| Step: 1
Training loss: 1.1370766197631696
Validation loss: 2.407927662480752

Epoch: 6| Step: 2
Training loss: 1.4962844129539186
Validation loss: 2.5130516948502004

Epoch: 6| Step: 3
Training loss: 1.19441503604398
Validation loss: 2.481688136408556

Epoch: 6| Step: 4
Training loss: 1.2671937991737123
Validation loss: 2.512772717034173

Epoch: 6| Step: 5
Training loss: 1.5830165479208393
Validation loss: 2.516054630757146

Epoch: 6| Step: 6
Training loss: 1.289459953301582
Validation loss: 2.541182328798309

Epoch: 6| Step: 7
Training loss: 1.5513756523300004
Validation loss: 2.5425245779457195

Epoch: 6| Step: 8
Training loss: 0.9989550912994718
Validation loss: 2.527959890482969

Epoch: 6| Step: 9
Training loss: 1.4162365971172621
Validation loss: 2.5413446294662205

Epoch: 6| Step: 10
Training loss: 0.8985916005538203
Validation loss: 2.4685009755087437

Epoch: 6| Step: 11
Training loss: 2.3123594705307755
Validation loss: 2.534904731562555

Epoch: 6| Step: 12
Training loss: 0.776178301020046
Validation loss: 2.4538119182361946

Epoch: 6| Step: 13
Training loss: 1.763681878518834
Validation loss: 2.4956420528766645

Epoch: 660| Step: 0
Training loss: 1.60874652628016
Validation loss: 2.505014084859544

Epoch: 6| Step: 1
Training loss: 1.4500820334018938
Validation loss: 2.4557892566675372

Epoch: 6| Step: 2
Training loss: 1.6631234254940683
Validation loss: 2.4568427367153913

Epoch: 6| Step: 3
Training loss: 0.8732139205708968
Validation loss: 2.482761271977637

Epoch: 6| Step: 4
Training loss: 1.5535346889692978
Validation loss: 2.4737764121731236

Epoch: 6| Step: 5
Training loss: 1.2428124253366748
Validation loss: 2.517748257225205

Epoch: 6| Step: 6
Training loss: 2.0109985247454363
Validation loss: 2.602100860934176

Epoch: 6| Step: 7
Training loss: 1.258332139239892
Validation loss: 2.459833711523305

Epoch: 6| Step: 8
Training loss: 1.2907269453745316
Validation loss: 2.489135432789461

Epoch: 6| Step: 9
Training loss: 1.441679393660683
Validation loss: 2.5653342623170534

Epoch: 6| Step: 10
Training loss: 1.4191677604367934
Validation loss: 2.465137835519909

Epoch: 6| Step: 11
Training loss: 0.8712126646429686
Validation loss: 2.5370784386513354

Epoch: 6| Step: 12
Training loss: 1.542124843387452
Validation loss: 2.520601900793156

Epoch: 6| Step: 13
Training loss: 1.0182581293356163
Validation loss: 2.541082481156825

Epoch: 661| Step: 0
Training loss: 1.4989971146151795
Validation loss: 2.5666784149458257

Epoch: 6| Step: 1
Training loss: 1.0324126538699478
Validation loss: 2.5150200930463704

Epoch: 6| Step: 2
Training loss: 1.126068243841739
Validation loss: 2.473361143993944

Epoch: 6| Step: 3
Training loss: 1.668170211024957
Validation loss: 2.459720860996511

Epoch: 6| Step: 4
Training loss: 0.9137643833306884
Validation loss: 2.5088791647412956

Epoch: 6| Step: 5
Training loss: 1.3479941566436853
Validation loss: 2.5237302583342878

Epoch: 6| Step: 6
Training loss: 1.3482188059605635
Validation loss: 2.5094211353916793

Epoch: 6| Step: 7
Training loss: 1.2464637326665495
Validation loss: 2.445509982450629

Epoch: 6| Step: 8
Training loss: 1.2092999614925342
Validation loss: 2.4766329251344943

Epoch: 6| Step: 9
Training loss: 1.261581602407865
Validation loss: 2.512120847215181

Epoch: 6| Step: 10
Training loss: 2.4224277972945796
Validation loss: 2.531302839057087

Epoch: 6| Step: 11
Training loss: 1.6994652580263374
Validation loss: 2.522001673211222

Epoch: 6| Step: 12
Training loss: 1.4062715316819479
Validation loss: 2.495476112054295

Epoch: 6| Step: 13
Training loss: 1.1644191835531355
Validation loss: 2.457126142356879

Epoch: 662| Step: 0
Training loss: 1.2917884441108687
Validation loss: 2.480743797581029

Epoch: 6| Step: 1
Training loss: 1.3104316672157437
Validation loss: 2.4676971371159664

Epoch: 6| Step: 2
Training loss: 1.2225267628117658
Validation loss: 2.5205797579607596

Epoch: 6| Step: 3
Training loss: 1.352165749050716
Validation loss: 2.4804422129234633

Epoch: 6| Step: 4
Training loss: 1.1750920198809913
Validation loss: 2.472035687956947

Epoch: 6| Step: 5
Training loss: 1.7154271690943457
Validation loss: 2.5107244433028404

Epoch: 6| Step: 6
Training loss: 0.7602339921424441
Validation loss: 2.5512687982125497

Epoch: 6| Step: 7
Training loss: 0.958565490355848
Validation loss: 2.5243268637789327

Epoch: 6| Step: 8
Training loss: 1.3186711147633183
Validation loss: 2.5506468101158557

Epoch: 6| Step: 9
Training loss: 1.700708547360357
Validation loss: 2.5346789048193052

Epoch: 6| Step: 10
Training loss: 1.6028004397695121
Validation loss: 2.536166872739565

Epoch: 6| Step: 11
Training loss: 2.3067178349892665
Validation loss: 2.520502238715961

Epoch: 6| Step: 12
Training loss: 0.8166371799193056
Validation loss: 2.546276422557502

Epoch: 6| Step: 13
Training loss: 0.9330215296576427
Validation loss: 2.54507428128439

Epoch: 663| Step: 0
Training loss: 1.7386824584172595
Validation loss: 2.5575911161109297

Epoch: 6| Step: 1
Training loss: 1.7376289429605811
Validation loss: 2.4829646729311614

Epoch: 6| Step: 2
Training loss: 1.0932612280697593
Validation loss: 2.477071748869246

Epoch: 6| Step: 3
Training loss: 1.3132023521564948
Validation loss: 2.488916529621853

Epoch: 6| Step: 4
Training loss: 1.0463232038039405
Validation loss: 2.478857334603817

Epoch: 6| Step: 5
Training loss: 1.068755081789305
Validation loss: 2.4745795189726563

Epoch: 6| Step: 6
Training loss: 1.1275505188241501
Validation loss: 2.480119704186858

Epoch: 6| Step: 7
Training loss: 1.3223495569454335
Validation loss: 2.4999896049283397

Epoch: 6| Step: 8
Training loss: 2.2044881296614776
Validation loss: 2.543391581628093

Epoch: 6| Step: 9
Training loss: 1.380934825168634
Validation loss: 2.5625671179840714

Epoch: 6| Step: 10
Training loss: 0.8948337759664711
Validation loss: 2.4837123745374363

Epoch: 6| Step: 11
Training loss: 1.44164557395602
Validation loss: 2.5224709919852386

Epoch: 6| Step: 12
Training loss: 1.2607309354225318
Validation loss: 2.5200006249845828

Epoch: 6| Step: 13
Training loss: 1.7788618039495534
Validation loss: 2.5292578904478127

Epoch: 664| Step: 0
Training loss: 1.5555315649740886
Validation loss: 2.4947266264593106

Epoch: 6| Step: 1
Training loss: 1.3632748666520953
Validation loss: 2.5098631138790632

Epoch: 6| Step: 2
Training loss: 1.548327294054904
Validation loss: 2.550983006082416

Epoch: 6| Step: 3
Training loss: 1.324974901933306
Validation loss: 2.5288073625210656

Epoch: 6| Step: 4
Training loss: 0.9624427233411245
Validation loss: 2.4967019959273524

Epoch: 6| Step: 5
Training loss: 1.2249291107530424
Validation loss: 2.4598678480521894

Epoch: 6| Step: 6
Training loss: 1.3066780757811436
Validation loss: 2.4820634899441614

Epoch: 6| Step: 7
Training loss: 1.1523570948975697
Validation loss: 2.502562075527061

Epoch: 6| Step: 8
Training loss: 1.454215430213596
Validation loss: 2.538154668700058

Epoch: 6| Step: 9
Training loss: 0.9646232445673574
Validation loss: 2.5356070794864

Epoch: 6| Step: 10
Training loss: 1.4259145177978414
Validation loss: 2.4735621755060766

Epoch: 6| Step: 11
Training loss: 1.995703254023227
Validation loss: 2.4740721227688955

Epoch: 6| Step: 12
Training loss: 1.537402346851577
Validation loss: 2.5256684724812053

Epoch: 6| Step: 13
Training loss: 1.027339804754188
Validation loss: 2.538096978534671

Epoch: 665| Step: 0
Training loss: 1.6139705930911998
Validation loss: 2.4895247929087247

Epoch: 6| Step: 1
Training loss: 0.8877783674575805
Validation loss: 2.5025735816334245

Epoch: 6| Step: 2
Training loss: 0.9783840129003878
Validation loss: 2.5224821582810684

Epoch: 6| Step: 3
Training loss: 0.9477061397694541
Validation loss: 2.499303382293214

Epoch: 6| Step: 4
Training loss: 1.7406145872835357
Validation loss: 2.526594538941521

Epoch: 6| Step: 5
Training loss: 1.2249118851091854
Validation loss: 2.562640597700455

Epoch: 6| Step: 6
Training loss: 1.2650862123867757
Validation loss: 2.504758128756474

Epoch: 6| Step: 7
Training loss: 2.192825157212718
Validation loss: 2.510846848959866

Epoch: 6| Step: 8
Training loss: 1.4911998256226875
Validation loss: 2.477368286175638

Epoch: 6| Step: 9
Training loss: 1.2333472596920168
Validation loss: 2.5065432249153274

Epoch: 6| Step: 10
Training loss: 1.3592629222048647
Validation loss: 2.517820627726323

Epoch: 6| Step: 11
Training loss: 1.2735008738843887
Validation loss: 2.5172417144315578

Epoch: 6| Step: 12
Training loss: 1.3085495670887666
Validation loss: 2.546498206666233

Epoch: 6| Step: 13
Training loss: 0.8889400538646738
Validation loss: 2.542518368795001

Epoch: 666| Step: 0
Training loss: 1.4947053926494778
Validation loss: 2.5527553461297736

Epoch: 6| Step: 1
Training loss: 0.9869925196942959
Validation loss: 2.5441455434669833

Epoch: 6| Step: 2
Training loss: 1.0421874588218578
Validation loss: 2.4456330587610933

Epoch: 6| Step: 3
Training loss: 1.4506547501918403
Validation loss: 2.51731536435173

Epoch: 6| Step: 4
Training loss: 1.2205104828462097
Validation loss: 2.5062514744471107

Epoch: 6| Step: 5
Training loss: 1.360573032422321
Validation loss: 2.564082548662462

Epoch: 6| Step: 6
Training loss: 1.5389321363977106
Validation loss: 2.5296849889825825

Epoch: 6| Step: 7
Training loss: 1.283270800706009
Validation loss: 2.50919521740398

Epoch: 6| Step: 8
Training loss: 1.4049636467544193
Validation loss: 2.5028190367319216

Epoch: 6| Step: 9
Training loss: 0.947395740499941
Validation loss: 2.517561329163846

Epoch: 6| Step: 10
Training loss: 2.357309207578479
Validation loss: 2.5055211520661778

Epoch: 6| Step: 11
Training loss: 0.7486751298615724
Validation loss: 2.469770028422486

Epoch: 6| Step: 12
Training loss: 1.1635576215769714
Validation loss: 2.5135457097675684

Epoch: 6| Step: 13
Training loss: 1.8265759678875209
Validation loss: 2.503424248766631

Epoch: 667| Step: 0
Training loss: 1.0367735123131019
Validation loss: 2.498983990936093

Epoch: 6| Step: 1
Training loss: 1.7261573005332052
Validation loss: 2.517674734013332

Epoch: 6| Step: 2
Training loss: 1.3722274744565648
Validation loss: 2.4572749903944344

Epoch: 6| Step: 3
Training loss: 1.2357149215495005
Validation loss: 2.5082322014392924

Epoch: 6| Step: 4
Training loss: 1.2222487285417798
Validation loss: 2.412206108375894

Epoch: 6| Step: 5
Training loss: 1.65189674770142
Validation loss: 2.515518759979154

Epoch: 6| Step: 6
Training loss: 1.21197647315189
Validation loss: 2.517478718983619

Epoch: 6| Step: 7
Training loss: 1.4544104356305327
Validation loss: 2.5118586006055112

Epoch: 6| Step: 8
Training loss: 1.2211916014843907
Validation loss: 2.5266279403943264

Epoch: 6| Step: 9
Training loss: 0.9542511087780438
Validation loss: 2.4611627051509766

Epoch: 6| Step: 10
Training loss: 1.1401915053084135
Validation loss: 2.4576951754707075

Epoch: 6| Step: 11
Training loss: 1.1956358328935224
Validation loss: 2.470460894165181

Epoch: 6| Step: 12
Training loss: 1.3460734042037603
Validation loss: 2.529696180186641

Epoch: 6| Step: 13
Training loss: 2.7315013499234793
Validation loss: 2.5098388293471134

Epoch: 668| Step: 0
Training loss: 1.118731145859725
Validation loss: 2.478869730524873

Epoch: 6| Step: 1
Training loss: 1.9381091483118962
Validation loss: 2.5152613685865557

Epoch: 6| Step: 2
Training loss: 1.0656679832761393
Validation loss: 2.47248483365083

Epoch: 6| Step: 3
Training loss: 1.620458565789308
Validation loss: 2.515538294587157

Epoch: 6| Step: 4
Training loss: 1.2399182975678498
Validation loss: 2.4388927270323677

Epoch: 6| Step: 5
Training loss: 1.114717701213241
Validation loss: 2.4590354443088454

Epoch: 6| Step: 6
Training loss: 1.2805086177370604
Validation loss: 2.546979358356211

Epoch: 6| Step: 7
Training loss: 1.129262109126984
Validation loss: 2.5523724467338185

Epoch: 6| Step: 8
Training loss: 1.2092152315022777
Validation loss: 2.4761319909265143

Epoch: 6| Step: 9
Training loss: 1.0632474177777873
Validation loss: 2.449735374214528

Epoch: 6| Step: 10
Training loss: 1.2218194114742862
Validation loss: 2.5278705677330233

Epoch: 6| Step: 11
Training loss: 1.7216078147664728
Validation loss: 2.464740363639896

Epoch: 6| Step: 12
Training loss: 1.4516027537370486
Validation loss: 2.534317774656567

Epoch: 6| Step: 13
Training loss: 1.862083962076826
Validation loss: 2.443020776737417

Epoch: 669| Step: 0
Training loss: 1.7951592256274163
Validation loss: 2.4918422911861473

Epoch: 6| Step: 1
Training loss: 1.0573340095848176
Validation loss: 2.5284095098566426

Epoch: 6| Step: 2
Training loss: 1.3721107124001073
Validation loss: 2.481976078964982

Epoch: 6| Step: 3
Training loss: 1.093923282520658
Validation loss: 2.510397244705383

Epoch: 6| Step: 4
Training loss: 1.035067745239906
Validation loss: 2.47238977590419

Epoch: 6| Step: 5
Training loss: 1.3407148193290375
Validation loss: 2.4738761897717247

Epoch: 6| Step: 6
Training loss: 1.3243031432679868
Validation loss: 2.5298643990064025

Epoch: 6| Step: 7
Training loss: 1.6762165491235506
Validation loss: 2.5265038914297144

Epoch: 6| Step: 8
Training loss: 0.9382319771743026
Validation loss: 2.4679596387222356

Epoch: 6| Step: 9
Training loss: 1.3944264433983544
Validation loss: 2.5047745744332155

Epoch: 6| Step: 10
Training loss: 1.579213135504468
Validation loss: 2.4515153431883476

Epoch: 6| Step: 11
Training loss: 1.3612356058696065
Validation loss: 2.486771861497167

Epoch: 6| Step: 12
Training loss: 1.2378630789439211
Validation loss: 2.475267774652287

Epoch: 6| Step: 13
Training loss: 0.9273270204572809
Validation loss: 2.483728770161859

Epoch: 670| Step: 0
Training loss: 1.2011495448572247
Validation loss: 2.5498807629498335

Epoch: 6| Step: 1
Training loss: 1.2109072773761276
Validation loss: 2.5357694195441423

Epoch: 6| Step: 2
Training loss: 1.0170333487670267
Validation loss: 2.4838870443802157

Epoch: 6| Step: 3
Training loss: 1.365853841711823
Validation loss: 2.5847032138822987

Epoch: 6| Step: 4
Training loss: 1.3951096390465634
Validation loss: 2.4670687259947046

Epoch: 6| Step: 5
Training loss: 1.2853327574873725
Validation loss: 2.425567495471363

Epoch: 6| Step: 6
Training loss: 1.0699971423601156
Validation loss: 2.557546566598689

Epoch: 6| Step: 7
Training loss: 1.2004694179467017
Validation loss: 2.5122752632617393

Epoch: 6| Step: 8
Training loss: 2.0828117353433635
Validation loss: 2.514542800049618

Epoch: 6| Step: 9
Training loss: 0.9319652255799119
Validation loss: 2.4898733748488775

Epoch: 6| Step: 10
Training loss: 1.9160319880759935
Validation loss: 2.4702543807781776

Epoch: 6| Step: 11
Training loss: 1.0516926383082663
Validation loss: 2.4635231322447844

Epoch: 6| Step: 12
Training loss: 1.5488598352483691
Validation loss: 2.5095940046469396

Epoch: 6| Step: 13
Training loss: 1.4182695222180401
Validation loss: 2.516634619840943

Epoch: 671| Step: 0
Training loss: 1.6613756436266423
Validation loss: 2.447669575267952

Epoch: 6| Step: 1
Training loss: 1.1530345333350478
Validation loss: 2.4288925074725656

Epoch: 6| Step: 2
Training loss: 1.4572990928098943
Validation loss: 2.4724854122231585

Epoch: 6| Step: 3
Training loss: 1.1306046642121557
Validation loss: 2.479016358832709

Epoch: 6| Step: 4
Training loss: 2.320426347296449
Validation loss: 2.472613414393433

Epoch: 6| Step: 5
Training loss: 1.5468904899052807
Validation loss: 2.5120568839906663

Epoch: 6| Step: 6
Training loss: 0.9631356010868525
Validation loss: 2.5068091605410143

Epoch: 6| Step: 7
Training loss: 1.298472007173582
Validation loss: 2.5230002151843

Epoch: 6| Step: 8
Training loss: 1.1160540399559193
Validation loss: 2.5165104674194434

Epoch: 6| Step: 9
Training loss: 1.171808368060106
Validation loss: 2.5069572721402786

Epoch: 6| Step: 10
Training loss: 1.1924906314025998
Validation loss: 2.452600473603284

Epoch: 6| Step: 11
Training loss: 0.8402588284320103
Validation loss: 2.461613166119342

Epoch: 6| Step: 12
Training loss: 1.324497069871483
Validation loss: 2.484545508304644

Epoch: 6| Step: 13
Training loss: 0.7381690207459853
Validation loss: 2.4837255946760526

Epoch: 672| Step: 0
Training loss: 1.3577411084123656
Validation loss: 2.4898112463858473

Epoch: 6| Step: 1
Training loss: 1.064355800274056
Validation loss: 2.486393892528271

Epoch: 6| Step: 2
Training loss: 1.9558958616638014
Validation loss: 2.5395563707671234

Epoch: 6| Step: 3
Training loss: 1.3737075974061534
Validation loss: 2.4680186182979402

Epoch: 6| Step: 4
Training loss: 1.2451063208012327
Validation loss: 2.5133886387021525

Epoch: 6| Step: 5
Training loss: 1.765772180414971
Validation loss: 2.5447992567542945

Epoch: 6| Step: 6
Training loss: 1.237995102609244
Validation loss: 2.4626854900756654

Epoch: 6| Step: 7
Training loss: 1.2543347063421162
Validation loss: 2.5563931794089343

Epoch: 6| Step: 8
Training loss: 1.3177398808538938
Validation loss: 2.515933228426415

Epoch: 6| Step: 9
Training loss: 1.0742098721224054
Validation loss: 2.463373064268592

Epoch: 6| Step: 10
Training loss: 1.1819860536717528
Validation loss: 2.5042805024930512

Epoch: 6| Step: 11
Training loss: 1.421696997598844
Validation loss: 2.4882382753812924

Epoch: 6| Step: 12
Training loss: 1.3128826855025295
Validation loss: 2.5317243665555536

Epoch: 6| Step: 13
Training loss: 1.1068460356650696
Validation loss: 2.4973010517462155

Epoch: 673| Step: 0
Training loss: 1.1249706476409014
Validation loss: 2.4987303062967556

Epoch: 6| Step: 1
Training loss: 1.3268054465609047
Validation loss: 2.5767202329449

Epoch: 6| Step: 2
Training loss: 1.1749050386081012
Validation loss: 2.4864219044199753

Epoch: 6| Step: 3
Training loss: 0.9165476411069594
Validation loss: 2.5082427299727934

Epoch: 6| Step: 4
Training loss: 1.9794288930009332
Validation loss: 2.5115120881089115

Epoch: 6| Step: 5
Training loss: 1.404080391486918
Validation loss: 2.5306209287397765

Epoch: 6| Step: 6
Training loss: 1.420443306618358
Validation loss: 2.4987418269695794

Epoch: 6| Step: 7
Training loss: 0.9487337670929059
Validation loss: 2.5398078555197228

Epoch: 6| Step: 8
Training loss: 1.1638944363721069
Validation loss: 2.4571965131671427

Epoch: 6| Step: 9
Training loss: 1.2091371504434303
Validation loss: 2.5794895502453667

Epoch: 6| Step: 10
Training loss: 0.9335120257117406
Validation loss: 2.5391866896227118

Epoch: 6| Step: 11
Training loss: 2.147749024098001
Validation loss: 2.4542354497287837

Epoch: 6| Step: 12
Training loss: 1.5468315349598956
Validation loss: 2.4814210928565483

Epoch: 6| Step: 13
Training loss: 1.435605168618724
Validation loss: 2.4695660722219768

Epoch: 674| Step: 0
Training loss: 1.5785082361189509
Validation loss: 2.495339327445483

Epoch: 6| Step: 1
Training loss: 1.2193529153815357
Validation loss: 2.494116108236045

Epoch: 6| Step: 2
Training loss: 1.3785132693764852
Validation loss: 2.536083515065333

Epoch: 6| Step: 3
Training loss: 1.5150205055586488
Validation loss: 2.517382865211108

Epoch: 6| Step: 4
Training loss: 0.6003654757651056
Validation loss: 2.543890882762465

Epoch: 6| Step: 5
Training loss: 1.0365047668075074
Validation loss: 2.5138973784436978

Epoch: 6| Step: 6
Training loss: 1.244142972503795
Validation loss: 2.4956043716339553

Epoch: 6| Step: 7
Training loss: 1.2976655044547194
Validation loss: 2.545201798616825

Epoch: 6| Step: 8
Training loss: 1.3176177927306298
Validation loss: 2.4776103238700053

Epoch: 6| Step: 9
Training loss: 1.0863444162825475
Validation loss: 2.5161725111289823

Epoch: 6| Step: 10
Training loss: 1.265862148342851
Validation loss: 2.510548599678015

Epoch: 6| Step: 11
Training loss: 2.350824690240249
Validation loss: 2.5338616549945674

Epoch: 6| Step: 12
Training loss: 1.2152468389781153
Validation loss: 2.5038740904614873

Epoch: 6| Step: 13
Training loss: 1.2855298736941017
Validation loss: 2.627037307616994

Epoch: 675| Step: 0
Training loss: 1.3904775477040057
Validation loss: 2.555131263370419

Epoch: 6| Step: 1
Training loss: 1.3128094081392772
Validation loss: 2.515428895567058

Epoch: 6| Step: 2
Training loss: 0.8622825680203772
Validation loss: 2.54386282646911

Epoch: 6| Step: 3
Training loss: 1.0787677231235582
Validation loss: 2.4582078813760027

Epoch: 6| Step: 4
Training loss: 1.3229196303126662
Validation loss: 2.4535957941729927

Epoch: 6| Step: 5
Training loss: 1.762898728740653
Validation loss: 2.464237159621437

Epoch: 6| Step: 6
Training loss: 0.7343853483079695
Validation loss: 2.4811910972589213

Epoch: 6| Step: 7
Training loss: 2.3059821161931495
Validation loss: 2.5346391048861334

Epoch: 6| Step: 8
Training loss: 1.1453181871634677
Validation loss: 2.5492840517665822

Epoch: 6| Step: 9
Training loss: 0.9921228582996631
Validation loss: 2.5246366110828977

Epoch: 6| Step: 10
Training loss: 1.2443544692104196
Validation loss: 2.5563941080340054

Epoch: 6| Step: 11
Training loss: 1.3114994413292496
Validation loss: 2.5002340268762677

Epoch: 6| Step: 12
Training loss: 1.1867375184634898
Validation loss: 2.4552127608918206

Epoch: 6| Step: 13
Training loss: 1.7722779907306367
Validation loss: 2.515512558565456

Epoch: 676| Step: 0
Training loss: 1.2000023086843534
Validation loss: 2.4803234612991543

Epoch: 6| Step: 1
Training loss: 1.3270773851070714
Validation loss: 2.446545362408805

Epoch: 6| Step: 2
Training loss: 0.8357364020489456
Validation loss: 2.4602845570135075

Epoch: 6| Step: 3
Training loss: 1.072410254113626
Validation loss: 2.518413864013488

Epoch: 6| Step: 4
Training loss: 1.319430942912485
Validation loss: 2.4929684885526675

Epoch: 6| Step: 5
Training loss: 1.0112392511727815
Validation loss: 2.5304751803566763

Epoch: 6| Step: 6
Training loss: 1.081499871284382
Validation loss: 2.4889966095119265

Epoch: 6| Step: 7
Training loss: 1.4732059495037753
Validation loss: 2.5330493870958084

Epoch: 6| Step: 8
Training loss: 1.1011930887885995
Validation loss: 2.5014258615204144

Epoch: 6| Step: 9
Training loss: 1.4701138109797065
Validation loss: 2.460379417673522

Epoch: 6| Step: 10
Training loss: 1.4163190003679336
Validation loss: 2.543603632251537

Epoch: 6| Step: 11
Training loss: 1.3941261707603008
Validation loss: 2.505593787225857

Epoch: 6| Step: 12
Training loss: 2.2334214956997287
Validation loss: 2.4947897638986785

Epoch: 6| Step: 13
Training loss: 1.4797366302293558
Validation loss: 2.5120113412066627

Epoch: 677| Step: 0
Training loss: 1.2447580096218303
Validation loss: 2.5853126920310485

Epoch: 6| Step: 1
Training loss: 1.4543311742876879
Validation loss: 2.5178960903610723

Epoch: 6| Step: 2
Training loss: 2.0556885344074827
Validation loss: 2.4923996317039943

Epoch: 6| Step: 3
Training loss: 1.3518049871521742
Validation loss: 2.4989692737162197

Epoch: 6| Step: 4
Training loss: 1.4715292587300826
Validation loss: 2.56410199623638

Epoch: 6| Step: 5
Training loss: 1.1556441291971238
Validation loss: 2.55298443862678

Epoch: 6| Step: 6
Training loss: 1.5077713086129931
Validation loss: 2.542781628317496

Epoch: 6| Step: 7
Training loss: 1.0576272754417029
Validation loss: 2.580468383048696

Epoch: 6| Step: 8
Training loss: 1.0518798757293903
Validation loss: 2.5288589347358954

Epoch: 6| Step: 9
Training loss: 1.339947176575356
Validation loss: 2.561164709143737

Epoch: 6| Step: 10
Training loss: 1.3736963160597409
Validation loss: 2.4716829329149794

Epoch: 6| Step: 11
Training loss: 1.2306033106297636
Validation loss: 2.4779488921425035

Epoch: 6| Step: 12
Training loss: 1.466899761548453
Validation loss: 2.541615876151457

Epoch: 6| Step: 13
Training loss: 1.4483129750274326
Validation loss: 2.542458877949652

Epoch: 678| Step: 0
Training loss: 1.230078450624163
Validation loss: 2.527103540783585

Epoch: 6| Step: 1
Training loss: 1.2330562452124485
Validation loss: 2.5023245341143747

Epoch: 6| Step: 2
Training loss: 0.9122853732162407
Validation loss: 2.5102679185111025

Epoch: 6| Step: 3
Training loss: 1.595070833887451
Validation loss: 2.4861031175044426

Epoch: 6| Step: 4
Training loss: 1.2650811239473327
Validation loss: 2.497735304160354

Epoch: 6| Step: 5
Training loss: 0.7705941000851415
Validation loss: 2.5361578934959974

Epoch: 6| Step: 6
Training loss: 1.5813283606853643
Validation loss: 2.5262521950148984

Epoch: 6| Step: 7
Training loss: 1.6121476372443253
Validation loss: 2.5499232938740004

Epoch: 6| Step: 8
Training loss: 1.1082699066790611
Validation loss: 2.5357576293370494

Epoch: 6| Step: 9
Training loss: 1.2916495516883948
Validation loss: 2.486375611629295

Epoch: 6| Step: 10
Training loss: 2.3299267856408137
Validation loss: 2.554452514578715

Epoch: 6| Step: 11
Training loss: 0.8969767097460465
Validation loss: 2.5228929525465515

Epoch: 6| Step: 12
Training loss: 1.3107039560703149
Validation loss: 2.5420661913511813

Epoch: 6| Step: 13
Training loss: 1.467849455366798
Validation loss: 2.442139618095277

Epoch: 679| Step: 0
Training loss: 0.8914869052997143
Validation loss: 2.511218374980712

Epoch: 6| Step: 1
Training loss: 1.330244101588882
Validation loss: 2.557671259976711

Epoch: 6| Step: 2
Training loss: 1.1723223023281135
Validation loss: 2.5274638982843283

Epoch: 6| Step: 3
Training loss: 1.1622948762956824
Validation loss: 2.5629218529857636

Epoch: 6| Step: 4
Training loss: 0.9781183894607388
Validation loss: 2.5196089395302455

Epoch: 6| Step: 5
Training loss: 1.3649972428653805
Validation loss: 2.482176107555243

Epoch: 6| Step: 6
Training loss: 1.4508316647547213
Validation loss: 2.493690993099508

Epoch: 6| Step: 7
Training loss: 1.8190485941858847
Validation loss: 2.5037324315314313

Epoch: 6| Step: 8
Training loss: 0.93474383522076
Validation loss: 2.4848030749824637

Epoch: 6| Step: 9
Training loss: 1.3339008623514605
Validation loss: 2.5044842833631655

Epoch: 6| Step: 10
Training loss: 1.250577983744522
Validation loss: 2.4681278284341

Epoch: 6| Step: 11
Training loss: 1.994637333117909
Validation loss: 2.5257288957471915

Epoch: 6| Step: 12
Training loss: 1.605898685851053
Validation loss: 2.5032941045549815

Epoch: 6| Step: 13
Training loss: 1.3032382522513075
Validation loss: 2.4553217220321804

Epoch: 680| Step: 0
Training loss: 1.1921082976544064
Validation loss: 2.4016899792671795

Epoch: 6| Step: 1
Training loss: 2.1432849479699567
Validation loss: 2.5293611239040685

Epoch: 6| Step: 2
Training loss: 1.3858027481921706
Validation loss: 2.5494376362509206

Epoch: 6| Step: 3
Training loss: 1.5222868657753164
Validation loss: 2.4988300057062607

Epoch: 6| Step: 4
Training loss: 1.2944851652424747
Validation loss: 2.533796944507645

Epoch: 6| Step: 5
Training loss: 0.9509864642085499
Validation loss: 2.5024711936620476

Epoch: 6| Step: 6
Training loss: 1.5854710987720666
Validation loss: 2.465363851262962

Epoch: 6| Step: 7
Training loss: 1.0038335751600722
Validation loss: 2.517171891771587

Epoch: 6| Step: 8
Training loss: 0.9020923743261118
Validation loss: 2.4935445234505464

Epoch: 6| Step: 9
Training loss: 1.4756879689192968
Validation loss: 2.515002217466013

Epoch: 6| Step: 10
Training loss: 1.4214388000109304
Validation loss: 2.509747219133915

Epoch: 6| Step: 11
Training loss: 1.3715205818770826
Validation loss: 2.5173472452447783

Epoch: 6| Step: 12
Training loss: 1.1532022672574676
Validation loss: 2.4826006474613966

Epoch: 6| Step: 13
Training loss: 0.6313381209099633
Validation loss: 2.5399533156572422

Epoch: 681| Step: 0
Training loss: 1.3019968945104359
Validation loss: 2.466354302225873

Epoch: 6| Step: 1
Training loss: 1.4729213324243153
Validation loss: 2.5301505663192483

Epoch: 6| Step: 2
Training loss: 1.2745828451002088
Validation loss: 2.5138132048100292

Epoch: 6| Step: 3
Training loss: 1.3150013294865954
Validation loss: 2.513490429464513

Epoch: 6| Step: 4
Training loss: 1.419677797351944
Validation loss: 2.543420192452582

Epoch: 6| Step: 5
Training loss: 1.1473249379179096
Validation loss: 2.604636948647474

Epoch: 6| Step: 6
Training loss: 1.2159566902365921
Validation loss: 2.5806846980301614

Epoch: 6| Step: 7
Training loss: 1.3517510166887539
Validation loss: 2.512680772516493

Epoch: 6| Step: 8
Training loss: 2.3578485262414492
Validation loss: 2.5570074954878494

Epoch: 6| Step: 9
Training loss: 1.4238000770181944
Validation loss: 2.5145918224383874

Epoch: 6| Step: 10
Training loss: 0.9766702211096164
Validation loss: 2.5601568005882758

Epoch: 6| Step: 11
Training loss: 1.0039928116940018
Validation loss: 2.502305804068425

Epoch: 6| Step: 12
Training loss: 0.9265753322182334
Validation loss: 2.532379514160457

Epoch: 6| Step: 13
Training loss: 1.1652208236023989
Validation loss: 2.496091100181118

Epoch: 682| Step: 0
Training loss: 1.0492096105931643
Validation loss: 2.5244151450642165

Epoch: 6| Step: 1
Training loss: 1.1762783482507346
Validation loss: 2.5473709504325615

Epoch: 6| Step: 2
Training loss: 0.9324154620675206
Validation loss: 2.490290303833778

Epoch: 6| Step: 3
Training loss: 1.415012693718901
Validation loss: 2.4944890511155555

Epoch: 6| Step: 4
Training loss: 1.4323109388499817
Validation loss: 2.537379713494485

Epoch: 6| Step: 5
Training loss: 1.7081345543313278
Validation loss: 2.5121860293078897

Epoch: 6| Step: 6
Training loss: 1.9613384429654164
Validation loss: 2.492127771568667

Epoch: 6| Step: 7
Training loss: 1.0113838260026486
Validation loss: 2.530179769650055

Epoch: 6| Step: 8
Training loss: 1.6103155850381465
Validation loss: 2.5471908591902763

Epoch: 6| Step: 9
Training loss: 1.0995856328267788
Validation loss: 2.475877499346755

Epoch: 6| Step: 10
Training loss: 1.3335063742566458
Validation loss: 2.4799897328001985

Epoch: 6| Step: 11
Training loss: 1.091456870432237
Validation loss: 2.4886739958596

Epoch: 6| Step: 12
Training loss: 1.3080199848421505
Validation loss: 2.512817768043283

Epoch: 6| Step: 13
Training loss: 1.6263741038745618
Validation loss: 2.4798628419971958

Epoch: 683| Step: 0
Training loss: 1.0224024073654512
Validation loss: 2.430008672510293

Epoch: 6| Step: 1
Training loss: 1.2514409343148631
Validation loss: 2.50369392899937

Epoch: 6| Step: 2
Training loss: 0.9001293672196921
Validation loss: 2.4523068917452755

Epoch: 6| Step: 3
Training loss: 1.4098847357664661
Validation loss: 2.53606203407155

Epoch: 6| Step: 4
Training loss: 1.209322732589451
Validation loss: 2.4980936503762856

Epoch: 6| Step: 5
Training loss: 1.5848615031097533
Validation loss: 2.5241298052870125

Epoch: 6| Step: 6
Training loss: 2.0900166948007612
Validation loss: 2.5430110416695326

Epoch: 6| Step: 7
Training loss: 1.2664088894571217
Validation loss: 2.5444583244152335

Epoch: 6| Step: 8
Training loss: 1.3356787001471782
Validation loss: 2.5026448011239295

Epoch: 6| Step: 9
Training loss: 0.908130569020869
Validation loss: 2.5037744106735103

Epoch: 6| Step: 10
Training loss: 1.3105922185157166
Validation loss: 2.5584192886120927

Epoch: 6| Step: 11
Training loss: 1.3652223250876483
Validation loss: 2.5167712911551607

Epoch: 6| Step: 12
Training loss: 1.1418679141204247
Validation loss: 2.4393709037306044

Epoch: 6| Step: 13
Training loss: 1.3994254772628494
Validation loss: 2.4594641417683585

Epoch: 684| Step: 0
Training loss: 1.2114889058491896
Validation loss: 2.532074590274098

Epoch: 6| Step: 1
Training loss: 1.004809615098604
Validation loss: 2.493132707843156

Epoch: 6| Step: 2
Training loss: 1.8675548240039435
Validation loss: 2.4189421097293176

Epoch: 6| Step: 3
Training loss: 0.9961584930322868
Validation loss: 2.469741087556526

Epoch: 6| Step: 4
Training loss: 1.1635570068623127
Validation loss: 2.49701642359481

Epoch: 6| Step: 5
Training loss: 1.0077014832378501
Validation loss: 2.458523632572755

Epoch: 6| Step: 6
Training loss: 1.5294296966985945
Validation loss: 2.3834577768308987

Epoch: 6| Step: 7
Training loss: 1.4739356516608235
Validation loss: 2.5231193429029073

Epoch: 6| Step: 8
Training loss: 1.6591571269710292
Validation loss: 2.52880823943593

Epoch: 6| Step: 9
Training loss: 1.1751107873835225
Validation loss: 2.486991333809582

Epoch: 6| Step: 10
Training loss: 1.6759069435624505
Validation loss: 2.4974055266242186

Epoch: 6| Step: 11
Training loss: 1.3544391602447954
Validation loss: 2.4649892376346507

Epoch: 6| Step: 12
Training loss: 1.1062051322157231
Validation loss: 2.4347840326523094

Epoch: 6| Step: 13
Training loss: 0.7486961873352423
Validation loss: 2.4400618715374813

Epoch: 685| Step: 0
Training loss: 1.2136248394974565
Validation loss: 2.5113254762902386

Epoch: 6| Step: 1
Training loss: 1.281080746520146
Validation loss: 2.5439051798644905

Epoch: 6| Step: 2
Training loss: 0.8947128045024215
Validation loss: 2.487366762105778

Epoch: 6| Step: 3
Training loss: 2.2728537108189983
Validation loss: 2.469995693471893

Epoch: 6| Step: 4
Training loss: 1.4247507211924662
Validation loss: 2.524649210747138

Epoch: 6| Step: 5
Training loss: 1.133665198000912
Validation loss: 2.5365509894255474

Epoch: 6| Step: 6
Training loss: 1.3655260726747105
Validation loss: 2.5653153799718242

Epoch: 6| Step: 7
Training loss: 1.0124557932869418
Validation loss: 2.512483125076026

Epoch: 6| Step: 8
Training loss: 1.1028427368066016
Validation loss: 2.513193280892012

Epoch: 6| Step: 9
Training loss: 1.4694786699167606
Validation loss: 2.4794780711073736

Epoch: 6| Step: 10
Training loss: 1.159335684302478
Validation loss: 2.481474475352092

Epoch: 6| Step: 11
Training loss: 1.099959593811049
Validation loss: 2.545775862262723

Epoch: 6| Step: 12
Training loss: 1.35553954541457
Validation loss: 2.552289513870493

Epoch: 6| Step: 13
Training loss: 1.0568287905760005
Validation loss: 2.5026671241509706

Epoch: 686| Step: 0
Training loss: 0.7320280109606627
Validation loss: 2.4916409422195107

Epoch: 6| Step: 1
Training loss: 1.306438983588815
Validation loss: 2.5217976228804

Epoch: 6| Step: 2
Training loss: 1.5551642065650506
Validation loss: 2.4962007412769966

Epoch: 6| Step: 3
Training loss: 0.7894813256981438
Validation loss: 2.477338363018582

Epoch: 6| Step: 4
Training loss: 1.2923111640770881
Validation loss: 2.4996143248665086

Epoch: 6| Step: 5
Training loss: 0.9650111806053803
Validation loss: 2.5424805126120344

Epoch: 6| Step: 6
Training loss: 1.3542020304048163
Validation loss: 2.5046334080992607

Epoch: 6| Step: 7
Training loss: 1.1706269803007519
Validation loss: 2.505674466729898

Epoch: 6| Step: 8
Training loss: 2.1248404499070124
Validation loss: 2.544460119848846

Epoch: 6| Step: 9
Training loss: 1.5962347968205712
Validation loss: 2.565079400019152

Epoch: 6| Step: 10
Training loss: 1.24128469612671
Validation loss: 2.5684950157458806

Epoch: 6| Step: 11
Training loss: 1.2585975140184396
Validation loss: 2.496583382084181

Epoch: 6| Step: 12
Training loss: 0.8775213223227878
Validation loss: 2.5204959163211886

Epoch: 6| Step: 13
Training loss: 1.5975613367665873
Validation loss: 2.5407324462098515

Epoch: 687| Step: 0
Training loss: 1.3435158636464815
Validation loss: 2.5093542795581514

Epoch: 6| Step: 1
Training loss: 1.358917773293198
Validation loss: 2.4932846805511395

Epoch: 6| Step: 2
Training loss: 0.8851727692021344
Validation loss: 2.518905232458554

Epoch: 6| Step: 3
Training loss: 2.0039198133221543
Validation loss: 2.46856793975454

Epoch: 6| Step: 4
Training loss: 1.3368929296346088
Validation loss: 2.546249349038474

Epoch: 6| Step: 5
Training loss: 1.2927418766183305
Validation loss: 2.4950759334913233

Epoch: 6| Step: 6
Training loss: 1.5459184097089111
Validation loss: 2.4402292967002794

Epoch: 6| Step: 7
Training loss: 1.02289910751365
Validation loss: 2.544544124977796

Epoch: 6| Step: 8
Training loss: 1.5530862661401788
Validation loss: 2.536871196008081

Epoch: 6| Step: 9
Training loss: 1.0904173076677801
Validation loss: 2.485380000797832

Epoch: 6| Step: 10
Training loss: 0.881497374099568
Validation loss: 2.543015616982957

Epoch: 6| Step: 11
Training loss: 1.102948500478026
Validation loss: 2.5361219782255144

Epoch: 6| Step: 12
Training loss: 1.2014191163706558
Validation loss: 2.5203308490112972

Epoch: 6| Step: 13
Training loss: 1.2918642057088745
Validation loss: 2.536853549685105

Epoch: 688| Step: 0
Training loss: 0.7162568347331856
Validation loss: 2.4526852010422373

Epoch: 6| Step: 1
Training loss: 1.3091521936187647
Validation loss: 2.4999640513470918

Epoch: 6| Step: 2
Training loss: 1.4123328152180605
Validation loss: 2.5243968835858146

Epoch: 6| Step: 3
Training loss: 1.9073580663829213
Validation loss: 2.485201935797369

Epoch: 6| Step: 4
Training loss: 1.4718580435324866
Validation loss: 2.4588005479846395

Epoch: 6| Step: 5
Training loss: 0.9409910370625869
Validation loss: 2.5162541504550155

Epoch: 6| Step: 6
Training loss: 1.2536633217572644
Validation loss: 2.4821209548815033

Epoch: 6| Step: 7
Training loss: 1.2531026957137008
Validation loss: 2.47647848802289

Epoch: 6| Step: 8
Training loss: 1.4003229058357274
Validation loss: 2.4826559376596746

Epoch: 6| Step: 9
Training loss: 1.2110579892173083
Validation loss: 2.510464654326907

Epoch: 6| Step: 10
Training loss: 1.0434795371856347
Validation loss: 2.54068299787233

Epoch: 6| Step: 11
Training loss: 1.3539577274034518
Validation loss: 2.4640510558140005

Epoch: 6| Step: 12
Training loss: 1.2714087116564075
Validation loss: 2.497699427605225

Epoch: 6| Step: 13
Training loss: 1.135075800881037
Validation loss: 2.466751765554491

Epoch: 689| Step: 0
Training loss: 1.4098366668465743
Validation loss: 2.4989065455443615

Epoch: 6| Step: 1
Training loss: 1.5346805524659082
Validation loss: 2.4454959277834987

Epoch: 6| Step: 2
Training loss: 1.4763059039920776
Validation loss: 2.486835310171237

Epoch: 6| Step: 3
Training loss: 0.7666786883973467
Validation loss: 2.4884639768263375

Epoch: 6| Step: 4
Training loss: 1.1193065154203032
Validation loss: 2.5452647032832436

Epoch: 6| Step: 5
Training loss: 1.2372833948629114
Validation loss: 2.5080861680333006

Epoch: 6| Step: 6
Training loss: 1.5909842634399851
Validation loss: 2.5318838875632808

Epoch: 6| Step: 7
Training loss: 1.821534168430794
Validation loss: 2.5054851716122313

Epoch: 6| Step: 8
Training loss: 1.2798057417685773
Validation loss: 2.5254480298486612

Epoch: 6| Step: 9
Training loss: 1.0299833205641045
Validation loss: 2.5182892475485334

Epoch: 6| Step: 10
Training loss: 1.166611102461307
Validation loss: 2.4829296624365282

Epoch: 6| Step: 11
Training loss: 1.1623675404219138
Validation loss: 2.5490090962498875

Epoch: 6| Step: 12
Training loss: 1.648054684125216
Validation loss: 2.480243298800495

Epoch: 6| Step: 13
Training loss: 0.862011627477302
Validation loss: 2.565340124437638

Epoch: 690| Step: 0
Training loss: 1.416547330804137
Validation loss: 2.535100755808288

Epoch: 6| Step: 1
Training loss: 1.4836750187041328
Validation loss: 2.5654571292027724

Epoch: 6| Step: 2
Training loss: 1.0696533846729441
Validation loss: 2.5360931061439436

Epoch: 6| Step: 3
Training loss: 1.5365439008603823
Validation loss: 2.5290106364310154

Epoch: 6| Step: 4
Training loss: 1.6144918190237008
Validation loss: 2.51052035661929

Epoch: 6| Step: 5
Training loss: 1.2773748271556409
Validation loss: 2.54103503321067

Epoch: 6| Step: 6
Training loss: 1.2960964301727158
Validation loss: 2.535392514729558

Epoch: 6| Step: 7
Training loss: 1.2050201550456168
Validation loss: 2.408710096330682

Epoch: 6| Step: 8
Training loss: 1.9561979000478482
Validation loss: 2.4940382552229243

Epoch: 6| Step: 9
Training loss: 1.1033961408626796
Validation loss: 2.5604556893369175

Epoch: 6| Step: 10
Training loss: 0.9200209384069684
Validation loss: 2.5616781295862667

Epoch: 6| Step: 11
Training loss: 0.8026370989664813
Validation loss: 2.507827483244778

Epoch: 6| Step: 12
Training loss: 1.0927974913048888
Validation loss: 2.505608752020292

Epoch: 6| Step: 13
Training loss: 1.480652810282812
Validation loss: 2.497479745597006

Epoch: 691| Step: 0
Training loss: 1.280907003500813
Validation loss: 2.398903522521898

Epoch: 6| Step: 1
Training loss: 1.274689228854418
Validation loss: 2.4587582555881755

Epoch: 6| Step: 2
Training loss: 1.7848237978095471
Validation loss: 2.5865046396587488

Epoch: 6| Step: 3
Training loss: 1.158861921763099
Validation loss: 2.5003629764472284

Epoch: 6| Step: 4
Training loss: 1.3735515160913596
Validation loss: 2.454450105322119

Epoch: 6| Step: 5
Training loss: 1.2222360979843474
Validation loss: 2.523234585860316

Epoch: 6| Step: 6
Training loss: 1.1958165321543304
Validation loss: 2.470806454847773

Epoch: 6| Step: 7
Training loss: 1.568995288654594
Validation loss: 2.4594575019427904

Epoch: 6| Step: 8
Training loss: 1.0192920506523193
Validation loss: 2.4268062809630644

Epoch: 6| Step: 9
Training loss: 1.0879484260585917
Validation loss: 2.503530735276469

Epoch: 6| Step: 10
Training loss: 1.144441256060886
Validation loss: 2.476203807339442

Epoch: 6| Step: 11
Training loss: 0.8063786337502582
Validation loss: 2.480565062857293

Epoch: 6| Step: 12
Training loss: 1.9687978950608591
Validation loss: 2.534639816941254

Epoch: 6| Step: 13
Training loss: 1.9917575746269887
Validation loss: 2.5494743448599597

Epoch: 692| Step: 0
Training loss: 1.2696206398817984
Validation loss: 2.538895819582969

Epoch: 6| Step: 1
Training loss: 1.2775373866215025
Validation loss: 2.5518220856089044

Epoch: 6| Step: 2
Training loss: 1.4010132239573287
Validation loss: 2.537533095086547

Epoch: 6| Step: 3
Training loss: 1.9911935757810413
Validation loss: 2.5373643187505865

Epoch: 6| Step: 4
Training loss: 1.4023480003526292
Validation loss: 2.51604432850726

Epoch: 6| Step: 5
Training loss: 1.261447747477754
Validation loss: 2.5017961976380283

Epoch: 6| Step: 6
Training loss: 1.2458805870527176
Validation loss: 2.4293418849226875

Epoch: 6| Step: 7
Training loss: 0.8560276383189493
Validation loss: 2.5013695329113634

Epoch: 6| Step: 8
Training loss: 1.4887133193922244
Validation loss: 2.451619836244781

Epoch: 6| Step: 9
Training loss: 1.2332992695065068
Validation loss: 2.4499917536017684

Epoch: 6| Step: 10
Training loss: 1.5471388466585163
Validation loss: 2.5168302116830716

Epoch: 6| Step: 11
Training loss: 1.5447329708308408
Validation loss: 2.486993895396191

Epoch: 6| Step: 12
Training loss: 1.2252429254184012
Validation loss: 2.4455601454327502

Epoch: 6| Step: 13
Training loss: 0.5740816380815436
Validation loss: 2.504760524788166

Epoch: 693| Step: 0
Training loss: 0.8884073387712824
Validation loss: 2.5049692256043277

Epoch: 6| Step: 1
Training loss: 1.1136321468485757
Validation loss: 2.5106351618874982

Epoch: 6| Step: 2
Training loss: 1.6009748916086728
Validation loss: 2.5353329082475597

Epoch: 6| Step: 3
Training loss: 1.4803565795597606
Validation loss: 2.4893578614199283

Epoch: 6| Step: 4
Training loss: 1.1453667933565441
Validation loss: 2.5241169623190163

Epoch: 6| Step: 5
Training loss: 2.0441163087663696
Validation loss: 2.571891263151485

Epoch: 6| Step: 6
Training loss: 1.4165305838954145
Validation loss: 2.481692050529176

Epoch: 6| Step: 7
Training loss: 0.8828529416163775
Validation loss: 2.519696789895068

Epoch: 6| Step: 8
Training loss: 0.7470661636935453
Validation loss: 2.5744180279923734

Epoch: 6| Step: 9
Training loss: 1.3653814102912225
Validation loss: 2.4904074725625756

Epoch: 6| Step: 10
Training loss: 1.4115053945580858
Validation loss: 2.513182485436158

Epoch: 6| Step: 11
Training loss: 0.9382139983838752
Validation loss: 2.5113574674204595

Epoch: 6| Step: 12
Training loss: 1.3060925621541173
Validation loss: 2.504536224382998

Epoch: 6| Step: 13
Training loss: 1.1497244857309488
Validation loss: 2.483379221980377

Epoch: 694| Step: 0
Training loss: 1.5005614501512199
Validation loss: 2.557024992700264

Epoch: 6| Step: 1
Training loss: 1.460050752358592
Validation loss: 2.45713634003096

Epoch: 6| Step: 2
Training loss: 0.8802679745183198
Validation loss: 2.4844490690844587

Epoch: 6| Step: 3
Training loss: 1.6949863383775035
Validation loss: 2.500990390465078

Epoch: 6| Step: 4
Training loss: 1.4033619364151422
Validation loss: 2.4605265425125595

Epoch: 6| Step: 5
Training loss: 1.096152745438099
Validation loss: 2.4658183563591796

Epoch: 6| Step: 6
Training loss: 1.2500648004901584
Validation loss: 2.4619305158235023

Epoch: 6| Step: 7
Training loss: 0.8421622631700983
Validation loss: 2.4833823437123868

Epoch: 6| Step: 8
Training loss: 0.8342025078483608
Validation loss: 2.473284048904487

Epoch: 6| Step: 9
Training loss: 1.1726850634446244
Validation loss: 2.486493020501993

Epoch: 6| Step: 10
Training loss: 1.147105995635176
Validation loss: 2.4909042493970865

Epoch: 6| Step: 11
Training loss: 1.017791667065622
Validation loss: 2.511657895786149

Epoch: 6| Step: 12
Training loss: 2.1831748710765693
Validation loss: 2.4650933883399917

Epoch: 6| Step: 13
Training loss: 1.1475803524133097
Validation loss: 2.4661376249917395

Epoch: 695| Step: 0
Training loss: 1.071527000856039
Validation loss: 2.488611060721586

Epoch: 6| Step: 1
Training loss: 1.5130100304573015
Validation loss: 2.51520581715621

Epoch: 6| Step: 2
Training loss: 1.2619782172165512
Validation loss: 2.5267573515077117

Epoch: 6| Step: 3
Training loss: 0.9268038932189205
Validation loss: 2.55647860448383

Epoch: 6| Step: 4
Training loss: 1.5538914621760926
Validation loss: 2.5010152457581944

Epoch: 6| Step: 5
Training loss: 0.9699173323808746
Validation loss: 2.5075428558058133

Epoch: 6| Step: 6
Training loss: 0.9735727856037553
Validation loss: 2.5071271741272887

Epoch: 6| Step: 7
Training loss: 1.466879444871368
Validation loss: 2.508095737384685

Epoch: 6| Step: 8
Training loss: 2.2299470575317546
Validation loss: 2.4581686902969477

Epoch: 6| Step: 9
Training loss: 1.102193773260994
Validation loss: 2.515611688650901

Epoch: 6| Step: 10
Training loss: 1.2493997086127857
Validation loss: 2.46945445284183

Epoch: 6| Step: 11
Training loss: 0.5130937463161069
Validation loss: 2.5015997311149643

Epoch: 6| Step: 12
Training loss: 1.3619468300981967
Validation loss: 2.501648640265135

Epoch: 6| Step: 13
Training loss: 1.610496056472228
Validation loss: 2.5293943418600486

Epoch: 696| Step: 0
Training loss: 0.8232034513471597
Validation loss: 2.594499800122715

Epoch: 6| Step: 1
Training loss: 0.9606897608533302
Validation loss: 2.4677476978375474

Epoch: 6| Step: 2
Training loss: 1.163106436112394
Validation loss: 2.5323880077171066

Epoch: 6| Step: 3
Training loss: 0.9109942135569505
Validation loss: 2.479919989392946

Epoch: 6| Step: 4
Training loss: 0.8502303736910737
Validation loss: 2.443027758732313

Epoch: 6| Step: 5
Training loss: 1.517709144621741
Validation loss: 2.4945698883425975

Epoch: 6| Step: 6
Training loss: 1.6324273344169073
Validation loss: 2.4877413670468105

Epoch: 6| Step: 7
Training loss: 1.1874457899067583
Validation loss: 2.504508736506102

Epoch: 6| Step: 8
Training loss: 1.153193687316098
Validation loss: 2.5312896850991438

Epoch: 6| Step: 9
Training loss: 0.8606046722161169
Validation loss: 2.489157351709206

Epoch: 6| Step: 10
Training loss: 1.3284788670063208
Validation loss: 2.5283537611170366

Epoch: 6| Step: 11
Training loss: 2.35879549905452
Validation loss: 2.4466976407584453

Epoch: 6| Step: 12
Training loss: 1.4679413862454278
Validation loss: 2.598727403641838

Epoch: 6| Step: 13
Training loss: 1.0269565215114465
Validation loss: 2.4397541158879426

Epoch: 697| Step: 0
Training loss: 1.4182833067830845
Validation loss: 2.453371414820395

Epoch: 6| Step: 1
Training loss: 1.4774691911251066
Validation loss: 2.492759261737552

Epoch: 6| Step: 2
Training loss: 1.218952797865351
Validation loss: 2.536898307966776

Epoch: 6| Step: 3
Training loss: 1.288401902600115
Validation loss: 2.54989940192336

Epoch: 6| Step: 4
Training loss: 0.7364630942255976
Validation loss: 2.5303906220432513

Epoch: 6| Step: 5
Training loss: 1.4204082259515503
Validation loss: 2.53817299078021

Epoch: 6| Step: 6
Training loss: 0.8059099781533391
Validation loss: 2.5180354471993165

Epoch: 6| Step: 7
Training loss: 1.1635272440390705
Validation loss: 2.4672635007268635

Epoch: 6| Step: 8
Training loss: 1.4863101592212498
Validation loss: 2.5334320507612453

Epoch: 6| Step: 9
Training loss: 0.9683679011724724
Validation loss: 2.520691571630669

Epoch: 6| Step: 10
Training loss: 1.5673567249824714
Validation loss: 2.5247239737571885

Epoch: 6| Step: 11
Training loss: 2.2611346767154576
Validation loss: 2.521857535049699

Epoch: 6| Step: 12
Training loss: 0.8519175777863904
Validation loss: 2.5303064793449184

Epoch: 6| Step: 13
Training loss: 0.6040161921023375
Validation loss: 2.5173378526185775

Epoch: 698| Step: 0
Training loss: 1.151522793337609
Validation loss: 2.465371878472275

Epoch: 6| Step: 1
Training loss: 1.142428135604624
Validation loss: 2.4514364854969095

Epoch: 6| Step: 2
Training loss: 0.9641071241243174
Validation loss: 2.5126633144263977

Epoch: 6| Step: 3
Training loss: 1.3031985072345744
Validation loss: 2.51651722718254

Epoch: 6| Step: 4
Training loss: 0.7018827484803745
Validation loss: 2.5215355164550735

Epoch: 6| Step: 5
Training loss: 1.364249729796095
Validation loss: 2.551534810154695

Epoch: 6| Step: 6
Training loss: 1.2634797458723568
Validation loss: 2.525847389320469

Epoch: 6| Step: 7
Training loss: 1.04527051581901
Validation loss: 2.536191807840247

Epoch: 6| Step: 8
Training loss: 1.1562596913524381
Validation loss: 2.4664751212816176

Epoch: 6| Step: 9
Training loss: 1.5541180665272574
Validation loss: 2.5791394010223807

Epoch: 6| Step: 10
Training loss: 1.5132963243796171
Validation loss: 2.519389508308073

Epoch: 6| Step: 11
Training loss: 0.8160342596472839
Validation loss: 2.5424478195572284

Epoch: 6| Step: 12
Training loss: 2.306175449892847
Validation loss: 2.5519027642732963

Epoch: 6| Step: 13
Training loss: 1.2698155950347167
Validation loss: 2.5063822915558243

Epoch: 699| Step: 0
Training loss: 0.7430340005198264
Validation loss: 2.4707635757578292

Epoch: 6| Step: 1
Training loss: 1.3220646535036866
Validation loss: 2.4641667557926503

Epoch: 6| Step: 2
Training loss: 1.188297806824475
Validation loss: 2.511460408750454

Epoch: 6| Step: 3
Training loss: 1.195057162270387
Validation loss: 2.472018425054461

Epoch: 6| Step: 4
Training loss: 1.3988458048010282
Validation loss: 2.496089783487123

Epoch: 6| Step: 5
Training loss: 0.7777037433931979
Validation loss: 2.5339819869336755

Epoch: 6| Step: 6
Training loss: 1.476175570376097
Validation loss: 2.4624559787371574

Epoch: 6| Step: 7
Training loss: 2.0953497397621685
Validation loss: 2.5078860230495135

Epoch: 6| Step: 8
Training loss: 1.103668148336642
Validation loss: 2.4600082171656625

Epoch: 6| Step: 9
Training loss: 0.7981845343005017
Validation loss: 2.4707267202709544

Epoch: 6| Step: 10
Training loss: 1.2483235561427666
Validation loss: 2.5333591203505135

Epoch: 6| Step: 11
Training loss: 1.4839425511100883
Validation loss: 2.503858429302667

Epoch: 6| Step: 12
Training loss: 1.1750858316117436
Validation loss: 2.47249785045861

Epoch: 6| Step: 13
Training loss: 1.8368663629547508
Validation loss: 2.4661990811175403

Epoch: 700| Step: 0
Training loss: 1.4795298958684664
Validation loss: 2.5089181021813154

Epoch: 6| Step: 1
Training loss: 1.0750353119839036
Validation loss: 2.5768463295039057

Epoch: 6| Step: 2
Training loss: 1.3043893256358094
Validation loss: 2.5229424914622176

Epoch: 6| Step: 3
Training loss: 1.62231708006865
Validation loss: 2.4635477932073315

Epoch: 6| Step: 4
Training loss: 0.9207357382227843
Validation loss: 2.517473309573965

Epoch: 6| Step: 5
Training loss: 0.6574732415298659
Validation loss: 2.498947378280224

Epoch: 6| Step: 6
Training loss: 1.0478225519123077
Validation loss: 2.6091028034319086

Epoch: 6| Step: 7
Training loss: 1.246928064273615
Validation loss: 2.4403520457917316

Epoch: 6| Step: 8
Training loss: 1.1359306303758439
Validation loss: 2.490356416585047

Epoch: 6| Step: 9
Training loss: 1.442337025075134
Validation loss: 2.5047374865568166

Epoch: 6| Step: 10
Training loss: 2.1777890048851343
Validation loss: 2.4854220377205056

Epoch: 6| Step: 11
Training loss: 0.8576466954262505
Validation loss: 2.528793902600074

Epoch: 6| Step: 12
Training loss: 1.4415002807712183
Validation loss: 2.4946387466284334

Epoch: 6| Step: 13
Training loss: 1.2530292997656387
Validation loss: 2.4356862722741353

Testing loss: 2.534210144526353
