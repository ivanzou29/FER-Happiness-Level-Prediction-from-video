Epoch: 1| Step: 0
Training loss: 7.256892906707652
Validation loss: 6.932074148065246

Epoch: 6| Step: 1
Training loss: 6.816510341253938
Validation loss: 6.93092872335672

Epoch: 6| Step: 2
Training loss: 6.791281316703603
Validation loss: 6.926227496417774

Epoch: 6| Step: 3
Training loss: 6.625174466121098
Validation loss: 6.923848125122774

Epoch: 6| Step: 4
Training loss: 7.114543000568174
Validation loss: 6.920853417222389

Epoch: 6| Step: 5
Training loss: 7.406579891535449
Validation loss: 6.920533545455433

Epoch: 6| Step: 6
Training loss: 4.841139945412582
Validation loss: 6.914809810833526

Epoch: 6| Step: 7
Training loss: 7.655995391971872
Validation loss: 6.910794547410174

Epoch: 6| Step: 8
Training loss: 7.680798843083961
Validation loss: 6.910677898236402

Epoch: 6| Step: 9
Training loss: 5.183834757372967
Validation loss: 6.906557595132969

Epoch: 6| Step: 10
Training loss: 6.821123457299873
Validation loss: 6.903453436832218

Epoch: 6| Step: 11
Training loss: 7.2096296552336865
Validation loss: 6.9030275463967605

Epoch: 6| Step: 12
Training loss: 7.42059148029862
Validation loss: 6.900294326061929

Epoch: 6| Step: 13
Training loss: 7.409415683127844
Validation loss: 6.897142507639781

Epoch: 2| Step: 0
Training loss: 6.010108380094199
Validation loss: 6.893952308472142

Epoch: 6| Step: 1
Training loss: 7.12586434458801
Validation loss: 6.892796046950219

Epoch: 6| Step: 2
Training loss: 8.14430127448093
Validation loss: 6.888909355201095

Epoch: 6| Step: 3
Training loss: 5.5046322129239975
Validation loss: 6.887255630280693

Epoch: 6| Step: 4
Training loss: 6.278057444746824
Validation loss: 6.8860492028223295

Epoch: 6| Step: 5
Training loss: 7.441257072815753
Validation loss: 6.881540275466498

Epoch: 6| Step: 6
Training loss: 7.045438971180636
Validation loss: 6.879678718589778

Epoch: 6| Step: 7
Training loss: 7.2076976106237565
Validation loss: 6.879784863411978

Epoch: 6| Step: 8
Training loss: 7.198865313658759
Validation loss: 6.875963464610488

Epoch: 6| Step: 9
Training loss: 6.263942578243766
Validation loss: 6.87520352805313

Epoch: 6| Step: 10
Training loss: 6.057067639534214
Validation loss: 6.870858576291235

Epoch: 6| Step: 11
Training loss: 5.853760330741738
Validation loss: 6.86936215963228

Epoch: 6| Step: 12
Training loss: 8.089517908243542
Validation loss: 6.866648901320949

Epoch: 6| Step: 13
Training loss: 7.699210822547923
Validation loss: 6.865595935134544

Epoch: 3| Step: 0
Training loss: 6.7128247059972646
Validation loss: 6.861719125647395

Epoch: 6| Step: 1
Training loss: 6.18120308483128
Validation loss: 6.86125690359057

Epoch: 6| Step: 2
Training loss: 6.968998241707335
Validation loss: 6.8593770959481715

Epoch: 6| Step: 3
Training loss: 7.466974917361375
Validation loss: 6.856926537030052

Epoch: 6| Step: 4
Training loss: 6.600820212983448
Validation loss: 6.8538291567036085

Epoch: 6| Step: 5
Training loss: 7.9853751494889815
Validation loss: 6.850777592666083

Epoch: 6| Step: 6
Training loss: 7.575698558461895
Validation loss: 6.848625510838156

Epoch: 6| Step: 7
Training loss: 6.275414028414965
Validation loss: 6.846396194189403

Epoch: 6| Step: 8
Training loss: 6.785540792212028
Validation loss: 6.843582158004888

Epoch: 6| Step: 9
Training loss: 6.656535397710776
Validation loss: 6.845381919732292

Epoch: 6| Step: 10
Training loss: 7.297986356413558
Validation loss: 6.8408080407185885

Epoch: 6| Step: 11
Training loss: 6.740586958323779
Validation loss: 6.8378582351039805

Epoch: 6| Step: 12
Training loss: 6.042735809788025
Validation loss: 6.837618306948106

Epoch: 6| Step: 13
Training loss: 5.633791178469658
Validation loss: 6.83576993122193

Epoch: 4| Step: 0
Training loss: 6.269514213372491
Validation loss: 6.8331349201744755

Epoch: 6| Step: 1
Training loss: 6.55546730686136
Validation loss: 6.829726978544996

Epoch: 6| Step: 2
Training loss: 7.553729559709592
Validation loss: 6.8293890936180714

Epoch: 6| Step: 3
Training loss: 6.075928592746968
Validation loss: 6.8256274497781755

Epoch: 6| Step: 4
Training loss: 7.84560272099372
Validation loss: 6.823068237374572

Epoch: 6| Step: 5
Training loss: 6.682206099555265
Validation loss: 6.821419199687689

Epoch: 6| Step: 6
Training loss: 7.035280149259477
Validation loss: 6.821585834200516

Epoch: 6| Step: 7
Training loss: 6.166771896426735
Validation loss: 6.818013039541839

Epoch: 6| Step: 8
Training loss: 5.965454789736376
Validation loss: 6.816306935184002

Epoch: 6| Step: 9
Training loss: 6.1722019543540565
Validation loss: 6.813503820998105

Epoch: 6| Step: 10
Training loss: 8.044623850770813
Validation loss: 6.809752469542006

Epoch: 6| Step: 11
Training loss: 6.99141166261384
Validation loss: 6.809781656139632

Epoch: 6| Step: 12
Training loss: 6.705059065931986
Validation loss: 6.807218128424165

Epoch: 6| Step: 13
Training loss: 6.933879835647234
Validation loss: 6.80403876625024

Epoch: 5| Step: 0
Training loss: 6.370337482896498
Validation loss: 6.802051800087831

Epoch: 6| Step: 1
Training loss: 6.964913856209139
Validation loss: 6.800983455799743

Epoch: 6| Step: 2
Training loss: 5.522086791730133
Validation loss: 6.799022214226346

Epoch: 6| Step: 3
Training loss: 6.625537778512186
Validation loss: 6.794413347571405

Epoch: 6| Step: 4
Training loss: 6.323813394205
Validation loss: 6.794846842620707

Epoch: 6| Step: 5
Training loss: 7.570640533237336
Validation loss: 6.792712879610736

Epoch: 6| Step: 6
Training loss: 6.226944781238529
Validation loss: 6.7867015680163965

Epoch: 6| Step: 7
Training loss: 6.594603279912567
Validation loss: 6.78425949863769

Epoch: 6| Step: 8
Training loss: 7.641190147171733
Validation loss: 6.784138079952085

Epoch: 6| Step: 9
Training loss: 7.594383433103961
Validation loss: 6.7825764390430345

Epoch: 6| Step: 10
Training loss: 6.478881862387026
Validation loss: 6.779891599596305

Epoch: 6| Step: 11
Training loss: 7.634206747979677
Validation loss: 6.777706591463569

Epoch: 6| Step: 12
Training loss: 6.759080783262467
Validation loss: 6.777206280585952

Epoch: 6| Step: 13
Training loss: 5.758690610512725
Validation loss: 6.771523827366764

Epoch: 6| Step: 0
Training loss: 7.3577088496760705
Validation loss: 6.7721801518853395

Epoch: 6| Step: 1
Training loss: 7.725486626467141
Validation loss: 6.767566963670411

Epoch: 6| Step: 2
Training loss: 5.831436975227025
Validation loss: 6.7641531907298775

Epoch: 6| Step: 3
Training loss: 6.96567840624154
Validation loss: 6.76157677105196

Epoch: 6| Step: 4
Training loss: 5.941301594451376
Validation loss: 6.7584886457216475

Epoch: 6| Step: 5
Training loss: 7.260143681725374
Validation loss: 6.7557890180059275

Epoch: 6| Step: 6
Training loss: 7.340494156504038
Validation loss: 6.756386558597045

Epoch: 6| Step: 7
Training loss: 5.472877906378416
Validation loss: 6.752099267136673

Epoch: 6| Step: 8
Training loss: 6.288672469466243
Validation loss: 6.749948991334392

Epoch: 6| Step: 9
Training loss: 6.523827820938859
Validation loss: 6.7481896218446

Epoch: 6| Step: 10
Training loss: 6.670612725019889
Validation loss: 6.744188046634562

Epoch: 6| Step: 11
Training loss: 6.239084706791183
Validation loss: 6.740383375789846

Epoch: 6| Step: 12
Training loss: 7.7945810127333015
Validation loss: 6.7395641669422615

Epoch: 6| Step: 13
Training loss: 6.414145763010116
Validation loss: 6.737072678622119

Epoch: 7| Step: 0
Training loss: 5.6438881689248666
Validation loss: 6.733545258747726

Epoch: 6| Step: 1
Training loss: 5.939468539317387
Validation loss: 6.73229650549581

Epoch: 6| Step: 2
Training loss: 7.281757910044665
Validation loss: 6.730468838368975

Epoch: 6| Step: 3
Training loss: 6.375707848837686
Validation loss: 6.72539391822268

Epoch: 6| Step: 4
Training loss: 6.599736248872943
Validation loss: 6.72465922174638

Epoch: 6| Step: 5
Training loss: 6.405692620569516
Validation loss: 6.723005530131635

Epoch: 6| Step: 6
Training loss: 7.304644155118726
Validation loss: 6.7176301351518015

Epoch: 6| Step: 7
Training loss: 7.764574682177845
Validation loss: 6.715108759986292

Epoch: 6| Step: 8
Training loss: 7.419336531350339
Validation loss: 6.711475634810227

Epoch: 6| Step: 9
Training loss: 7.292870936174534
Validation loss: 6.707710255011159

Epoch: 6| Step: 10
Training loss: 6.881752443463455
Validation loss: 6.704945123325

Epoch: 6| Step: 11
Training loss: 6.032806353799317
Validation loss: 6.703644922203559

Epoch: 6| Step: 12
Training loss: 6.719434126688806
Validation loss: 6.701080854275004

Epoch: 6| Step: 13
Training loss: 5.088959295756569
Validation loss: 6.697287088718989

Epoch: 8| Step: 0
Training loss: 5.4918860492484445
Validation loss: 6.694323764828044

Epoch: 6| Step: 1
Training loss: 7.258890948535759
Validation loss: 6.687637589896285

Epoch: 6| Step: 2
Training loss: 6.232798594557063
Validation loss: 6.689618607412783

Epoch: 6| Step: 3
Training loss: 6.058075538967787
Validation loss: 6.684766083119644

Epoch: 6| Step: 4
Training loss: 6.542929687383395
Validation loss: 6.681232578095213

Epoch: 6| Step: 5
Training loss: 7.455183788467204
Validation loss: 6.677780658878118

Epoch: 6| Step: 6
Training loss: 7.328793883552576
Validation loss: 6.674714394168336

Epoch: 6| Step: 7
Training loss: 6.344005560777495
Validation loss: 6.669600725046269

Epoch: 6| Step: 8
Training loss: 7.201096917412294
Validation loss: 6.666450710285395

Epoch: 6| Step: 9
Training loss: 7.151455134927087
Validation loss: 6.659145796221403

Epoch: 6| Step: 10
Training loss: 6.4734942596473735
Validation loss: 6.659272970973436

Epoch: 6| Step: 11
Training loss: 5.905439694642605
Validation loss: 6.659785116347378

Epoch: 6| Step: 12
Training loss: 7.132802071203356
Validation loss: 6.653937996302637

Epoch: 6| Step: 13
Training loss: 6.229785731076708
Validation loss: 6.6496692683478695

Epoch: 9| Step: 0
Training loss: 7.948620313008484
Validation loss: 6.644589864603929

Epoch: 6| Step: 1
Training loss: 6.950985560073309
Validation loss: 6.6409014614979265

Epoch: 6| Step: 2
Training loss: 5.77748141792112
Validation loss: 6.636694429682049

Epoch: 6| Step: 3
Training loss: 7.313777453355211
Validation loss: 6.633526457800484

Epoch: 6| Step: 4
Training loss: 6.881981651221827
Validation loss: 6.627757768676104

Epoch: 6| Step: 5
Training loss: 7.57816074008969
Validation loss: 6.620652778333107

Epoch: 6| Step: 6
Training loss: 5.780408643380904
Validation loss: 6.619613407923081

Epoch: 6| Step: 7
Training loss: 6.555880450515042
Validation loss: 6.61509149673099

Epoch: 6| Step: 8
Training loss: 6.877522508646089
Validation loss: 6.616548688613772

Epoch: 6| Step: 9
Training loss: 5.434488449097039
Validation loss: 6.606522291368438

Epoch: 6| Step: 10
Training loss: 6.76627366125796
Validation loss: 6.603458673904593

Epoch: 6| Step: 11
Training loss: 5.7379734483904326
Validation loss: 6.601866018365388

Epoch: 6| Step: 12
Training loss: 5.4535513549972
Validation loss: 6.595903241079199

Epoch: 6| Step: 13
Training loss: 7.196001680485273
Validation loss: 6.586694404861162

Epoch: 10| Step: 0
Training loss: 7.358088354552318
Validation loss: 6.580190972750646

Epoch: 6| Step: 1
Training loss: 5.881711981016813
Validation loss: 6.581896665530029

Epoch: 6| Step: 2
Training loss: 6.398756752852677
Validation loss: 6.57414012551395

Epoch: 6| Step: 3
Training loss: 6.318673014336901
Validation loss: 6.566298887402841

Epoch: 6| Step: 4
Training loss: 7.309519885952481
Validation loss: 6.561598624162792

Epoch: 6| Step: 5
Training loss: 6.795705830656328
Validation loss: 6.560801981038254

Epoch: 6| Step: 6
Training loss: 6.458042884776419
Validation loss: 6.553332610570862

Epoch: 6| Step: 7
Training loss: 6.560040694319877
Validation loss: 6.551015222334597

Epoch: 6| Step: 8
Training loss: 7.32259773728356
Validation loss: 6.541791487407498

Epoch: 6| Step: 9
Training loss: 5.8037161136240165
Validation loss: 6.536959088482453

Epoch: 6| Step: 10
Training loss: 6.025056653528052
Validation loss: 6.529955773844759

Epoch: 6| Step: 11
Training loss: 5.720168641278679
Validation loss: 6.525196417822226

Epoch: 6| Step: 12
Training loss: 6.903041733066448
Validation loss: 6.51607699796324

Epoch: 6| Step: 13
Training loss: 6.533190571269703
Validation loss: 6.514324357544252

Epoch: 11| Step: 0
Training loss: 6.191876029594677
Validation loss: 6.510021797921076

Epoch: 6| Step: 1
Training loss: 6.503228779468355
Validation loss: 6.504068812877057

Epoch: 6| Step: 2
Training loss: 5.470356558105032
Validation loss: 6.499237987697514

Epoch: 6| Step: 3
Training loss: 5.450305286221377
Validation loss: 6.491741803199223

Epoch: 6| Step: 4
Training loss: 6.632798696982104
Validation loss: 6.484265393564924

Epoch: 6| Step: 5
Training loss: 6.705904155534352
Validation loss: 6.476522432022209

Epoch: 6| Step: 6
Training loss: 7.020910638068551
Validation loss: 6.472843050901413

Epoch: 6| Step: 7
Training loss: 7.912739017004207
Validation loss: 6.460413746642782

Epoch: 6| Step: 8
Training loss: 7.075712285395946
Validation loss: 6.4609656879577795

Epoch: 6| Step: 9
Training loss: 6.487432802179377
Validation loss: 6.450497021309219

Epoch: 6| Step: 10
Training loss: 5.389253392077927
Validation loss: 6.452875181506848

Epoch: 6| Step: 11
Training loss: 7.263217847214397
Validation loss: 6.438950512709564

Epoch: 6| Step: 12
Training loss: 6.011304378791067
Validation loss: 6.428734228596018

Epoch: 6| Step: 13
Training loss: 5.339947691814814
Validation loss: 6.421894123458204

Epoch: 12| Step: 0
Training loss: 5.707474061470058
Validation loss: 6.420514658009449

Epoch: 6| Step: 1
Training loss: 6.109566375778957
Validation loss: 6.410932910337083

Epoch: 6| Step: 2
Training loss: 5.3992179162973235
Validation loss: 6.40466943466855

Epoch: 6| Step: 3
Training loss: 5.714644161970999
Validation loss: 6.396794738479217

Epoch: 6| Step: 4
Training loss: 5.537110408399374
Validation loss: 6.387356121834148

Epoch: 6| Step: 5
Training loss: 7.452196491232992
Validation loss: 6.380851824925552

Epoch: 6| Step: 6
Training loss: 6.683575485802047
Validation loss: 6.373051560557117

Epoch: 6| Step: 7
Training loss: 7.104859915848315
Validation loss: 6.360500155833983

Epoch: 6| Step: 8
Training loss: 7.210540992027234
Validation loss: 6.356623357620592

Epoch: 6| Step: 9
Training loss: 6.2432797733147325
Validation loss: 6.34653490211706

Epoch: 6| Step: 10
Training loss: 5.967239588220223
Validation loss: 6.335726489301171

Epoch: 6| Step: 11
Training loss: 7.195113155490502
Validation loss: 6.3290018004686734

Epoch: 6| Step: 12
Training loss: 5.975981002144191
Validation loss: 6.315654890993703

Epoch: 6| Step: 13
Training loss: 6.2911550890703944
Validation loss: 6.304600800546596

Epoch: 13| Step: 0
Training loss: 6.6013729632554465
Validation loss: 6.292422277426447

Epoch: 6| Step: 1
Training loss: 7.125650476577944
Validation loss: 6.285878268413352

Epoch: 6| Step: 2
Training loss: 7.289768720393409
Validation loss: 6.274531305289541

Epoch: 6| Step: 3
Training loss: 5.506659723944055
Validation loss: 6.272719208988064

Epoch: 6| Step: 4
Training loss: 5.624095081019406
Validation loss: 6.25374841654547

Epoch: 6| Step: 5
Training loss: 6.016902005285688
Validation loss: 6.245661664250311

Epoch: 6| Step: 6
Training loss: 5.437838138282903
Validation loss: 6.235278505516987

Epoch: 6| Step: 7
Training loss: 6.672545352465796
Validation loss: 6.2231810142841795

Epoch: 6| Step: 8
Training loss: 6.794097122266292
Validation loss: 6.201477177418056

Epoch: 6| Step: 9
Training loss: 6.355201945363925
Validation loss: 6.201001894075152

Epoch: 6| Step: 10
Training loss: 5.700413725712118
Validation loss: 6.192966565881025

Epoch: 6| Step: 11
Training loss: 6.264664802321766
Validation loss: 6.180071502690316

Epoch: 6| Step: 12
Training loss: 5.657001255789838
Validation loss: 6.163018216861343

Epoch: 6| Step: 13
Training loss: 5.673091201067965
Validation loss: 6.157266339183689

Epoch: 14| Step: 0
Training loss: 6.284283109701604
Validation loss: 6.148644671300004

Epoch: 6| Step: 1
Training loss: 5.45477567244692
Validation loss: 6.134261638902054

Epoch: 6| Step: 2
Training loss: 6.057600105897446
Validation loss: 6.122091279470364

Epoch: 6| Step: 3
Training loss: 5.4620826404623575
Validation loss: 6.103066085595679

Epoch: 6| Step: 4
Training loss: 6.656775512009186
Validation loss: 6.09855558204826

Epoch: 6| Step: 5
Training loss: 5.575084894329367
Validation loss: 6.081527345239061

Epoch: 6| Step: 6
Training loss: 6.132498063694819
Validation loss: 6.065991584370684

Epoch: 6| Step: 7
Training loss: 6.794489860781435
Validation loss: 6.06998689948387

Epoch: 6| Step: 8
Training loss: 6.803549389969754
Validation loss: 6.048185722362301

Epoch: 6| Step: 9
Training loss: 5.335463138344671
Validation loss: 6.038056097209844

Epoch: 6| Step: 10
Training loss: 6.1430820664704315
Validation loss: 6.0289885004396915

Epoch: 6| Step: 11
Training loss: 6.113483735164996
Validation loss: 6.017349086021931

Epoch: 6| Step: 12
Training loss: 5.978727778721053
Validation loss: 6.00527004154065

Epoch: 6| Step: 13
Training loss: 6.022799724058014
Validation loss: 5.987160367887859

Epoch: 15| Step: 0
Training loss: 5.421140065801391
Validation loss: 5.976115212970513

Epoch: 6| Step: 1
Training loss: 6.557055730920581
Validation loss: 5.962391447282699

Epoch: 6| Step: 2
Training loss: 6.572064505187967
Validation loss: 5.949676649242346

Epoch: 6| Step: 3
Training loss: 5.786494335356705
Validation loss: 5.9332268061839235

Epoch: 6| Step: 4
Training loss: 5.361661106462869
Validation loss: 5.925802029803693

Epoch: 6| Step: 5
Training loss: 5.231075146303989
Validation loss: 5.9085338608774824

Epoch: 6| Step: 6
Training loss: 6.80858170403768
Validation loss: 5.9063188199757795

Epoch: 6| Step: 7
Training loss: 5.942565363491195
Validation loss: 5.885485392815444

Epoch: 6| Step: 8
Training loss: 6.266273369858737
Validation loss: 5.864010308797626

Epoch: 6| Step: 9
Training loss: 5.533049037631244
Validation loss: 5.8539522362604375

Epoch: 6| Step: 10
Training loss: 5.732426865947572
Validation loss: 5.84156211654261

Epoch: 6| Step: 11
Training loss: 5.8156467246706
Validation loss: 5.826227092150901

Epoch: 6| Step: 12
Training loss: 5.620173439254761
Validation loss: 5.813214068877626

Epoch: 6| Step: 13
Training loss: 5.5374228306338145
Validation loss: 5.802049444059171

Epoch: 16| Step: 0
Training loss: 5.9497156668292375
Validation loss: 5.783354281634917

Epoch: 6| Step: 1
Training loss: 5.224950156818278
Validation loss: 5.773630011479421

Epoch: 6| Step: 2
Training loss: 5.739400963444656
Validation loss: 5.759514433049894

Epoch: 6| Step: 3
Training loss: 5.851689947189368
Validation loss: 5.74464678793396

Epoch: 6| Step: 4
Training loss: 4.67762631986366
Validation loss: 5.729766160432451

Epoch: 6| Step: 5
Training loss: 6.128569516522404
Validation loss: 5.706177106267109

Epoch: 6| Step: 6
Training loss: 5.314057245338846
Validation loss: 5.692112738500069

Epoch: 6| Step: 7
Training loss: 6.000004132587281
Validation loss: 5.681935159592139

Epoch: 6| Step: 8
Training loss: 5.485821742328001
Validation loss: 5.6697959849048285

Epoch: 6| Step: 9
Training loss: 6.563707803660667
Validation loss: 5.644912357027626

Epoch: 6| Step: 10
Training loss: 6.0778466482094125
Validation loss: 5.649739008567319

Epoch: 6| Step: 11
Training loss: 5.510168212981484
Validation loss: 5.62285922752214

Epoch: 6| Step: 12
Training loss: 4.911706696342773
Validation loss: 5.60721159610541

Epoch: 6| Step: 13
Training loss: 6.4461008040653445
Validation loss: 5.580169899457382

Epoch: 17| Step: 0
Training loss: 6.321314332682573
Validation loss: 5.571132224794831

Epoch: 6| Step: 1
Training loss: 4.95081378913433
Validation loss: 5.550438986632442

Epoch: 6| Step: 2
Training loss: 5.591235058988603
Validation loss: 5.547036426996612

Epoch: 6| Step: 3
Training loss: 5.166578640751945
Validation loss: 5.526183071969489

Epoch: 6| Step: 4
Training loss: 6.51383204685002
Validation loss: 5.5062635931985335

Epoch: 6| Step: 5
Training loss: 5.301680014308775
Validation loss: 5.4962744302356485

Epoch: 6| Step: 6
Training loss: 5.523506908709053
Validation loss: 5.478669456749813

Epoch: 6| Step: 7
Training loss: 5.474691596555242
Validation loss: 5.451547038197462

Epoch: 6| Step: 8
Training loss: 5.5395721071991995
Validation loss: 5.442700595990539

Epoch: 6| Step: 9
Training loss: 6.271915921095329
Validation loss: 5.41411212416066

Epoch: 6| Step: 10
Training loss: 5.195815809149456
Validation loss: 5.3974259063312315

Epoch: 6| Step: 11
Training loss: 4.90133362352151
Validation loss: 5.38515999325292

Epoch: 6| Step: 12
Training loss: 5.177647806118066
Validation loss: 5.370743212764041

Epoch: 6| Step: 13
Training loss: 3.6535904821914644
Validation loss: 5.354398099081432

Epoch: 18| Step: 0
Training loss: 5.889279806409574
Validation loss: 5.347076996112017

Epoch: 6| Step: 1
Training loss: 5.018825947530115
Validation loss: 5.30233204669645

Epoch: 6| Step: 2
Training loss: 5.5896217840604185
Validation loss: 5.288852179920861

Epoch: 6| Step: 3
Training loss: 6.202944505501406
Validation loss: 5.275965654159079

Epoch: 6| Step: 4
Training loss: 5.280844407618038
Validation loss: 5.253209743831417

Epoch: 6| Step: 5
Training loss: 5.627821490180885
Validation loss: 5.255820162199184

Epoch: 6| Step: 6
Training loss: 5.202282903303689
Validation loss: 5.218380492556271

Epoch: 6| Step: 7
Training loss: 5.490858283430806
Validation loss: 5.20756016790458

Epoch: 6| Step: 8
Training loss: 5.708327504547188
Validation loss: 5.17672390260694

Epoch: 6| Step: 9
Training loss: 4.640842214310877
Validation loss: 5.1620605663106645

Epoch: 6| Step: 10
Training loss: 4.538904919408606
Validation loss: 5.144184803862218

Epoch: 6| Step: 11
Training loss: 4.676904529079153
Validation loss: 5.130518907293365

Epoch: 6| Step: 12
Training loss: 4.9587020523218746
Validation loss: 5.1020536340372935

Epoch: 6| Step: 13
Training loss: 3.4152381670940715
Validation loss: 5.096884569219328

Epoch: 19| Step: 0
Training loss: 5.507134751629692
Validation loss: 5.0813851451939795

Epoch: 6| Step: 1
Training loss: 5.052517692010209
Validation loss: 5.048167646397362

Epoch: 6| Step: 2
Training loss: 5.810554424890053
Validation loss: 5.021351685349952

Epoch: 6| Step: 3
Training loss: 4.5716440201125526
Validation loss: 5.011737171156793

Epoch: 6| Step: 4
Training loss: 4.427512090527544
Validation loss: 4.987455581745636

Epoch: 6| Step: 5
Training loss: 4.891416248018252
Validation loss: 4.969619356064382

Epoch: 6| Step: 6
Training loss: 5.112700054106608
Validation loss: 4.9360313718412465

Epoch: 6| Step: 7
Training loss: 4.650309004822371
Validation loss: 4.929881207383343

Epoch: 6| Step: 8
Training loss: 4.40950811605575
Validation loss: 4.907015172627246

Epoch: 6| Step: 9
Training loss: 5.703704553707733
Validation loss: 4.889545347580706

Epoch: 6| Step: 10
Training loss: 5.225874554757371
Validation loss: 4.873758133146142

Epoch: 6| Step: 11
Training loss: 4.588103476597154
Validation loss: 4.829357724325153

Epoch: 6| Step: 12
Training loss: 4.524491524974968
Validation loss: 4.811647825271794

Epoch: 6| Step: 13
Training loss: 5.044433002953757
Validation loss: 4.796963044932774

Epoch: 20| Step: 0
Training loss: 4.487348361627779
Validation loss: 4.761463873606203

Epoch: 6| Step: 1
Training loss: 5.2980516415272
Validation loss: 4.74072435507868

Epoch: 6| Step: 2
Training loss: 5.631072941070055
Validation loss: 4.722392983257601

Epoch: 6| Step: 3
Training loss: 4.895230693115327
Validation loss: 4.702696068542395

Epoch: 6| Step: 4
Training loss: 4.607200394077884
Validation loss: 4.688635706987147

Epoch: 6| Step: 5
Training loss: 4.203041274360685
Validation loss: 4.653185440266299

Epoch: 6| Step: 6
Training loss: 4.3499213639090515
Validation loss: 4.643367609455937

Epoch: 6| Step: 7
Training loss: 5.293414310409257
Validation loss: 4.604841395653664

Epoch: 6| Step: 8
Training loss: 3.356749888439351
Validation loss: 4.589804664991729

Epoch: 6| Step: 9
Training loss: 4.904919875304213
Validation loss: 4.556000034476074

Epoch: 6| Step: 10
Training loss: 4.878773133880086
Validation loss: 4.542088292128748

Epoch: 6| Step: 11
Training loss: 4.294795972532189
Validation loss: 4.510770780655234

Epoch: 6| Step: 12
Training loss: 4.347414734910776
Validation loss: 4.487094114948049

Epoch: 6| Step: 13
Training loss: 4.177054971930031
Validation loss: 4.476892411445197

Epoch: 21| Step: 0
Training loss: 4.303331220307682
Validation loss: 4.428455261331333

Epoch: 6| Step: 1
Training loss: 4.9759356285052885
Validation loss: 4.422208335073321

Epoch: 6| Step: 2
Training loss: 4.7933712567211755
Validation loss: 4.393605198499716

Epoch: 6| Step: 3
Training loss: 5.158889927002772
Validation loss: 4.365729680279057

Epoch: 6| Step: 4
Training loss: 4.532312939377017
Validation loss: 4.33097857175686

Epoch: 6| Step: 5
Training loss: 5.4335126617107194
Validation loss: 4.338648897782115

Epoch: 6| Step: 6
Training loss: 3.449020501009212
Validation loss: 4.27073709102852

Epoch: 6| Step: 7
Training loss: 4.429525597790849
Validation loss: 4.259883770365933

Epoch: 6| Step: 8
Training loss: 3.8623840709683344
Validation loss: 4.234078442499644

Epoch: 6| Step: 9
Training loss: 3.4109836549034585
Validation loss: 4.211199399851429

Epoch: 6| Step: 10
Training loss: 3.818415071125127
Validation loss: 4.1984604206730625

Epoch: 6| Step: 11
Training loss: 3.820515945103749
Validation loss: 4.150661427262042

Epoch: 6| Step: 12
Training loss: 3.9837945253477156
Validation loss: 4.121988021586156

Epoch: 6| Step: 13
Training loss: 4.5884189942928595
Validation loss: 4.090811319613306

Epoch: 22| Step: 0
Training loss: 3.84938591357389
Validation loss: 4.083168208935812

Epoch: 6| Step: 1
Training loss: 3.1496721975123423
Validation loss: 4.063080224187487

Epoch: 6| Step: 2
Training loss: 5.415738109325342
Validation loss: 4.039607686990267

Epoch: 6| Step: 3
Training loss: 4.082584442181088
Validation loss: 4.000548846778704

Epoch: 6| Step: 4
Training loss: 4.406172731411932
Validation loss: 3.990319939397255

Epoch: 6| Step: 5
Training loss: 4.6530886165100815
Validation loss: 3.9498910954079642

Epoch: 6| Step: 6
Training loss: 4.20806934296654
Validation loss: 3.9340749474931296

Epoch: 6| Step: 7
Training loss: 3.0774826696358795
Validation loss: 3.927014655343418

Epoch: 6| Step: 8
Training loss: 2.847719712459423
Validation loss: 3.8989428936257378

Epoch: 6| Step: 9
Training loss: 4.184238131323792
Validation loss: 3.8702235480689575

Epoch: 6| Step: 10
Training loss: 3.9537262591247115
Validation loss: 3.8125388084465808

Epoch: 6| Step: 11
Training loss: 4.114241702548272
Validation loss: 3.8113072784130537

Epoch: 6| Step: 12
Training loss: 3.473470688908859
Validation loss: 3.7991682573135876

Epoch: 6| Step: 13
Training loss: 4.3691622341748815
Validation loss: 3.753890518080902

Epoch: 23| Step: 0
Training loss: 3.3185527850676526
Validation loss: 3.7197002817805953

Epoch: 6| Step: 1
Training loss: 3.4827633538935188
Validation loss: 3.6935062343350267

Epoch: 6| Step: 2
Training loss: 3.5648482764702525
Validation loss: 3.710586937848862

Epoch: 6| Step: 3
Training loss: 4.024062261869508
Validation loss: 3.6628849481152708

Epoch: 6| Step: 4
Training loss: 3.56008548226756
Validation loss: 3.6402747570095833

Epoch: 6| Step: 5
Training loss: 3.5936637536356035
Validation loss: 3.6068767340888614

Epoch: 6| Step: 6
Training loss: 4.2622052132703905
Validation loss: 3.5985753945951697

Epoch: 6| Step: 7
Training loss: 3.7554552452966696
Validation loss: 3.5746748632051024

Epoch: 6| Step: 8
Training loss: 2.6330191420783993
Validation loss: 3.54282225130827

Epoch: 6| Step: 9
Training loss: 3.7625029351612693
Validation loss: 3.531830959389362

Epoch: 6| Step: 10
Training loss: 4.276501549149483
Validation loss: 3.4828012095215595

Epoch: 6| Step: 11
Training loss: 3.5070034529922145
Validation loss: 3.4675887422904923

Epoch: 6| Step: 12
Training loss: 4.057370277723817
Validation loss: 3.4462338509583463

Epoch: 6| Step: 13
Training loss: 3.6586808169242357
Validation loss: 3.41392434848916

Epoch: 24| Step: 0
Training loss: 3.625279382923204
Validation loss: 3.4130564032931945

Epoch: 6| Step: 1
Training loss: 3.721063743596867
Validation loss: 3.379399422380906

Epoch: 6| Step: 2
Training loss: 3.6463766220019598
Validation loss: 3.338474092479073

Epoch: 6| Step: 3
Training loss: 3.40050911738011
Validation loss: 3.3209570289174506

Epoch: 6| Step: 4
Training loss: 3.491698228667616
Validation loss: 3.3069254178799876

Epoch: 6| Step: 5
Training loss: 2.8347148519076795
Validation loss: 3.2698151659024646

Epoch: 6| Step: 6
Training loss: 3.200749106940601
Validation loss: 3.248273902266517

Epoch: 6| Step: 7
Training loss: 3.4315739268560885
Validation loss: 3.2342725692682293

Epoch: 6| Step: 8
Training loss: 3.136461525295377
Validation loss: 3.219045697735348

Epoch: 6| Step: 9
Training loss: 3.985921761464114
Validation loss: 3.195552053647532

Epoch: 6| Step: 10
Training loss: 4.123711124547972
Validation loss: 3.1790337595110914

Epoch: 6| Step: 11
Training loss: 3.426590270466084
Validation loss: 3.114641139172096

Epoch: 6| Step: 12
Training loss: 2.447122020115762
Validation loss: 3.1522354802914796

Epoch: 6| Step: 13
Training loss: 3.4347380205891347
Validation loss: 3.1035133616384605

Epoch: 25| Step: 0
Training loss: 3.0121908448690773
Validation loss: 3.0859182398464906

Epoch: 6| Step: 1
Training loss: 4.089487200536822
Validation loss: 3.0464183068596835

Epoch: 6| Step: 2
Training loss: 3.0304976640675614
Validation loss: 3.059345143897636

Epoch: 6| Step: 3
Training loss: 2.9975830514583954
Validation loss: 3.0550576833279908

Epoch: 6| Step: 4
Training loss: 4.454218786997492
Validation loss: 3.0507986446296114

Epoch: 6| Step: 5
Training loss: 2.6242587541606985
Validation loss: 3.0369054922066288

Epoch: 6| Step: 6
Training loss: 2.2607874295216597
Validation loss: 3.013669261740238

Epoch: 6| Step: 7
Training loss: 4.024721285250719
Validation loss: 2.9982868707381423

Epoch: 6| Step: 8
Training loss: 3.088258281055886
Validation loss: 2.9787632756367293

Epoch: 6| Step: 9
Training loss: 3.2938418062506423
Validation loss: 2.9730434249939894

Epoch: 6| Step: 10
Training loss: 3.306779203986631
Validation loss: 2.9501439870209696

Epoch: 6| Step: 11
Training loss: 3.338860475232724
Validation loss: 2.945837878430429

Epoch: 6| Step: 12
Training loss: 2.87519205529968
Validation loss: 2.946904162952916

Epoch: 6| Step: 13
Training loss: 2.2757818450560285
Validation loss: 2.8823842083067834

Epoch: 26| Step: 0
Training loss: 3.4238437232245946
Validation loss: 2.927989376463172

Epoch: 6| Step: 1
Training loss: 4.21379193606765
Validation loss: 2.919571272860137

Epoch: 6| Step: 2
Training loss: 3.695227204642917
Validation loss: 2.867682731477811

Epoch: 6| Step: 3
Training loss: 2.992439598041171
Validation loss: 2.870991511279352

Epoch: 6| Step: 4
Training loss: 3.5057772230973665
Validation loss: 2.876489722356531

Epoch: 6| Step: 5
Training loss: 3.233166749995485
Validation loss: 2.839411089714258

Epoch: 6| Step: 6
Training loss: 3.005478942076395
Validation loss: 2.8479078201896013

Epoch: 6| Step: 7
Training loss: 2.1360938014318624
Validation loss: 2.862943570090922

Epoch: 6| Step: 8
Training loss: 3.3968912048795565
Validation loss: 2.885134237601472

Epoch: 6| Step: 9
Training loss: 3.1959594966914375
Validation loss: 2.8436298599657275

Epoch: 6| Step: 10
Training loss: 2.7159033594255995
Validation loss: 2.8053593802691976

Epoch: 6| Step: 11
Training loss: 2.126266550832804
Validation loss: 2.812217755665785

Epoch: 6| Step: 12
Training loss: 2.7180744077141012
Validation loss: 2.8510208404335584

Epoch: 6| Step: 13
Training loss: 2.9813882151939333
Validation loss: 2.8416434473793517

Epoch: 27| Step: 0
Training loss: 2.504831604313311
Validation loss: 2.7769281522246136

Epoch: 6| Step: 1
Training loss: 3.116286068557247
Validation loss: 2.7807638368610474

Epoch: 6| Step: 2
Training loss: 2.586791851055758
Validation loss: 2.811191317261339

Epoch: 6| Step: 3
Training loss: 3.0200881740506396
Validation loss: 2.810888590808395

Epoch: 6| Step: 4
Training loss: 3.7135509403464297
Validation loss: 2.828768973944284

Epoch: 6| Step: 5
Training loss: 3.571041642073616
Validation loss: 2.7790111800508757

Epoch: 6| Step: 6
Training loss: 3.2505238917725072
Validation loss: 2.8049251553854493

Epoch: 6| Step: 7
Training loss: 2.692755948991679
Validation loss: 2.7489149324552984

Epoch: 6| Step: 8
Training loss: 3.258151322636616
Validation loss: 2.7837857186826405

Epoch: 6| Step: 9
Training loss: 3.0317869988863353
Validation loss: 2.8058381588257753

Epoch: 6| Step: 10
Training loss: 3.421919034212964
Validation loss: 2.782014746040963

Epoch: 6| Step: 11
Training loss: 3.2605987270496644
Validation loss: 2.711196740913395

Epoch: 6| Step: 12
Training loss: 3.4889080855643937
Validation loss: 2.763688792903759

Epoch: 6| Step: 13
Training loss: 2.490772670833735
Validation loss: 2.7405210328437

Epoch: 28| Step: 0
Training loss: 3.182581678662375
Validation loss: 2.7568385050116904

Epoch: 6| Step: 1
Training loss: 3.2912888772872675
Validation loss: 2.756660937483492

Epoch: 6| Step: 2
Training loss: 3.937399242262429
Validation loss: 2.765874573436029

Epoch: 6| Step: 3
Training loss: 3.253431122930878
Validation loss: 2.735304842357998

Epoch: 6| Step: 4
Training loss: 2.7362317565895333
Validation loss: 2.7386515627667585

Epoch: 6| Step: 5
Training loss: 3.3353159412533193
Validation loss: 2.7402103161557645

Epoch: 6| Step: 6
Training loss: 3.2476607487151608
Validation loss: 2.780331611057115

Epoch: 6| Step: 7
Training loss: 2.569263186089929
Validation loss: 2.730760700770809

Epoch: 6| Step: 8
Training loss: 3.057229313818397
Validation loss: 2.7532070520015286

Epoch: 6| Step: 9
Training loss: 2.708803067675508
Validation loss: 2.777503668342022

Epoch: 6| Step: 10
Training loss: 2.987369333386419
Validation loss: 2.7254126135247465

Epoch: 6| Step: 11
Training loss: 2.640679714380915
Validation loss: 2.7438317776234955

Epoch: 6| Step: 12
Training loss: 2.8945282847277323
Validation loss: 2.6869169481796087

Epoch: 6| Step: 13
Training loss: 3.742743018853389
Validation loss: 2.749269925529138

Epoch: 29| Step: 0
Training loss: 3.051128216305238
Validation loss: 2.709727101095157

Epoch: 6| Step: 1
Training loss: 3.0690404377719105
Validation loss: 2.757409265536881

Epoch: 6| Step: 2
Training loss: 2.7597302045121688
Validation loss: 2.7362052387069267

Epoch: 6| Step: 3
Training loss: 3.5627442660998616
Validation loss: 2.716013204996494

Epoch: 6| Step: 4
Training loss: 3.3740659763508707
Validation loss: 2.733258192343627

Epoch: 6| Step: 5
Training loss: 2.801629825087327
Validation loss: 2.7396886983019484

Epoch: 6| Step: 6
Training loss: 3.436980745804912
Validation loss: 2.7364618647666212

Epoch: 6| Step: 7
Training loss: 3.271576199737441
Validation loss: 2.7106403839220983

Epoch: 6| Step: 8
Training loss: 3.0555165914497993
Validation loss: 2.7070747401234363

Epoch: 6| Step: 9
Training loss: 3.2783480936509064
Validation loss: 2.714042341672575

Epoch: 6| Step: 10
Training loss: 2.9570070615960833
Validation loss: 2.682123655430927

Epoch: 6| Step: 11
Training loss: 2.5570628471065655
Validation loss: 2.689523528911198

Epoch: 6| Step: 12
Training loss: 3.1776423895241397
Validation loss: 2.7022427255902697

Epoch: 6| Step: 13
Training loss: 2.989741907112147
Validation loss: 2.71963092363841

Epoch: 30| Step: 0
Training loss: 3.321171476665574
Validation loss: 2.7271065437608093

Epoch: 6| Step: 1
Training loss: 3.1761214671124494
Validation loss: 2.700447237124977

Epoch: 6| Step: 2
Training loss: 3.0306443071369884
Validation loss: 2.736021694896532

Epoch: 6| Step: 3
Training loss: 2.8807815799877434
Validation loss: 2.695228416269132

Epoch: 6| Step: 4
Training loss: 2.8671389375570655
Validation loss: 2.7216258272229528

Epoch: 6| Step: 5
Training loss: 2.9706894813439977
Validation loss: 2.712106578701203

Epoch: 6| Step: 6
Training loss: 2.3637409362135045
Validation loss: 2.6929247099523344

Epoch: 6| Step: 7
Training loss: 2.903175614719568
Validation loss: 2.6885006742692172

Epoch: 6| Step: 8
Training loss: 3.5661345563267974
Validation loss: 2.692635885084271

Epoch: 6| Step: 9
Training loss: 2.9691556954500116
Validation loss: 2.6905964381500276

Epoch: 6| Step: 10
Training loss: 3.6487893173854276
Validation loss: 2.729680479281915

Epoch: 6| Step: 11
Training loss: 3.8481511915962696
Validation loss: 2.6961199843987353

Epoch: 6| Step: 12
Training loss: 2.7227429413094955
Validation loss: 2.7283468169650416

Epoch: 6| Step: 13
Training loss: 2.9292587576905587
Validation loss: 2.718697341486305

Epoch: 31| Step: 0
Training loss: 2.791555279080045
Validation loss: 2.7161014259755842

Epoch: 6| Step: 1
Training loss: 3.0943767798936226
Validation loss: 2.710189884103734

Epoch: 6| Step: 2
Training loss: 3.4078050615945727
Validation loss: 2.7029770163286635

Epoch: 6| Step: 3
Training loss: 2.78123122648268
Validation loss: 2.7088549144053675

Epoch: 6| Step: 4
Training loss: 3.233013953988533
Validation loss: 2.7123881885992165

Epoch: 6| Step: 5
Training loss: 3.0153593430590386
Validation loss: 2.693885125421175

Epoch: 6| Step: 6
Training loss: 2.9454271208217433
Validation loss: 2.6725509221322468

Epoch: 6| Step: 7
Training loss: 3.0140360861214623
Validation loss: 2.722164100450353

Epoch: 6| Step: 8
Training loss: 3.7122859392200986
Validation loss: 2.71320572703015

Epoch: 6| Step: 9
Training loss: 2.979604693313858
Validation loss: 2.6841957105088676

Epoch: 6| Step: 10
Training loss: 2.7976954444881708
Validation loss: 2.750983154767042

Epoch: 6| Step: 11
Training loss: 2.0656792383965095
Validation loss: 2.700202446491456

Epoch: 6| Step: 12
Training loss: 4.004682422862442
Validation loss: 2.729387740445032

Epoch: 6| Step: 13
Training loss: 2.632622686499654
Validation loss: 2.711434165417601

Epoch: 32| Step: 0
Training loss: 2.3304370434222186
Validation loss: 2.7321265342050696

Epoch: 6| Step: 1
Training loss: 3.165373956605483
Validation loss: 2.703278923595774

Epoch: 6| Step: 2
Training loss: 2.9129029285876507
Validation loss: 2.6949185238467126

Epoch: 6| Step: 3
Training loss: 3.879379258987009
Validation loss: 2.6928684781008205

Epoch: 6| Step: 4
Training loss: 2.153645587323016
Validation loss: 2.7041209881046715

Epoch: 6| Step: 5
Training loss: 2.451439539668558
Validation loss: 2.683302654857083

Epoch: 6| Step: 6
Training loss: 3.2286190101792167
Validation loss: 2.716318464420414

Epoch: 6| Step: 7
Training loss: 3.3123749043577546
Validation loss: 2.721164158160307

Epoch: 6| Step: 8
Training loss: 3.2806523823335714
Validation loss: 2.7017572582029197

Epoch: 6| Step: 9
Training loss: 2.9778550112689586
Validation loss: 2.7064843832506797

Epoch: 6| Step: 10
Training loss: 3.6021737264775413
Validation loss: 2.7113537292875596

Epoch: 6| Step: 11
Training loss: 3.307850579721471
Validation loss: 2.7558839670027964

Epoch: 6| Step: 12
Training loss: 2.1808850133319115
Validation loss: 2.7066926200277486

Epoch: 6| Step: 13
Training loss: 4.1120084149909095
Validation loss: 2.7062820737701454

Epoch: 33| Step: 0
Training loss: 3.0185548454686955
Validation loss: 2.67364482101059

Epoch: 6| Step: 1
Training loss: 2.892349141373328
Validation loss: 2.7429701623639526

Epoch: 6| Step: 2
Training loss: 3.3077629334308853
Validation loss: 2.7293084627608146

Epoch: 6| Step: 3
Training loss: 2.9366345043636666
Validation loss: 2.7309213117403823

Epoch: 6| Step: 4
Training loss: 2.329223783153271
Validation loss: 2.7086681894133413

Epoch: 6| Step: 5
Training loss: 3.171714139721051
Validation loss: 2.688940377187238

Epoch: 6| Step: 6
Training loss: 3.03654316717677
Validation loss: 2.699288516452416

Epoch: 6| Step: 7
Training loss: 3.1627063246658773
Validation loss: 2.708639143408517

Epoch: 6| Step: 8
Training loss: 3.619395428749575
Validation loss: 2.6979017141268864

Epoch: 6| Step: 9
Training loss: 2.7854940201587817
Validation loss: 2.6803290624787492

Epoch: 6| Step: 10
Training loss: 3.0712828522393494
Validation loss: 2.7390118592472503

Epoch: 6| Step: 11
Training loss: 3.754537507488985
Validation loss: 2.7020064479476207

Epoch: 6| Step: 12
Training loss: 3.2716763294897997
Validation loss: 2.6927867657498505

Epoch: 6| Step: 13
Training loss: 2.1804247193929207
Validation loss: 2.694198686909403

Epoch: 34| Step: 0
Training loss: 3.6605204886467626
Validation loss: 2.704783477912474

Epoch: 6| Step: 1
Training loss: 2.489041246801183
Validation loss: 2.680697553505265

Epoch: 6| Step: 2
Training loss: 3.4251033238328246
Validation loss: 2.676314697073695

Epoch: 6| Step: 3
Training loss: 2.515234780700338
Validation loss: 2.6881088936884434

Epoch: 6| Step: 4
Training loss: 2.983546916057695
Validation loss: 2.671881668455741

Epoch: 6| Step: 5
Training loss: 2.7300754422114446
Validation loss: 2.699305226245926

Epoch: 6| Step: 6
Training loss: 3.231299075670753
Validation loss: 2.7117731827018874

Epoch: 6| Step: 7
Training loss: 3.3322685130393026
Validation loss: 2.7208223178316855

Epoch: 6| Step: 8
Training loss: 2.6959330411117786
Validation loss: 2.705459101978666

Epoch: 6| Step: 9
Training loss: 3.0727591436496957
Validation loss: 2.717330265838078

Epoch: 6| Step: 10
Training loss: 2.825544666008119
Validation loss: 2.689750482713186

Epoch: 6| Step: 11
Training loss: 3.0461218269817203
Validation loss: 2.6748232160039107

Epoch: 6| Step: 12
Training loss: 2.7108219352957086
Validation loss: 2.684753663099106

Epoch: 6| Step: 13
Training loss: 4.192896312345916
Validation loss: 2.6997969278697562

Epoch: 35| Step: 0
Training loss: 2.6813872259987948
Validation loss: 2.6813093343362913

Epoch: 6| Step: 1
Training loss: 3.11219636592757
Validation loss: 2.735903336658301

Epoch: 6| Step: 2
Training loss: 3.0620554387252135
Validation loss: 2.685714244769282

Epoch: 6| Step: 3
Training loss: 3.3796404266959117
Validation loss: 2.6959742388405696

Epoch: 6| Step: 4
Training loss: 3.569916216938357
Validation loss: 2.6669934361607277

Epoch: 6| Step: 5
Training loss: 3.1057477333903782
Validation loss: 2.709493783826339

Epoch: 6| Step: 6
Training loss: 3.23148146488352
Validation loss: 2.677706629645116

Epoch: 6| Step: 7
Training loss: 3.4114404731263552
Validation loss: 2.6887008424268495

Epoch: 6| Step: 8
Training loss: 2.6249165294636727
Validation loss: 2.6922125777795376

Epoch: 6| Step: 9
Training loss: 2.44389102070355
Validation loss: 2.7017107836091685

Epoch: 6| Step: 10
Training loss: 2.8605447679819496
Validation loss: 2.7027444746501272

Epoch: 6| Step: 11
Training loss: 2.5416419439728926
Validation loss: 2.685142834112962

Epoch: 6| Step: 12
Training loss: 2.9255648075814995
Validation loss: 2.728177308752669

Epoch: 6| Step: 13
Training loss: 3.975974528493978
Validation loss: 2.6904126938905044

Epoch: 36| Step: 0
Training loss: 2.8191776264220825
Validation loss: 2.649981510707709

Epoch: 6| Step: 1
Training loss: 3.1274279508517147
Validation loss: 2.6851213349620777

Epoch: 6| Step: 2
Training loss: 3.591199683139963
Validation loss: 2.699744081047387

Epoch: 6| Step: 3
Training loss: 4.0387201219431725
Validation loss: 2.674491688586518

Epoch: 6| Step: 4
Training loss: 3.8553846479555585
Validation loss: 2.6966830342591575

Epoch: 6| Step: 5
Training loss: 2.543480231299571
Validation loss: 2.6533696443300605

Epoch: 6| Step: 6
Training loss: 2.6363324369778782
Validation loss: 2.7083356413977344

Epoch: 6| Step: 7
Training loss: 3.169895099143692
Validation loss: 2.684770059440989

Epoch: 6| Step: 8
Training loss: 2.816243710635731
Validation loss: 2.662117282271652

Epoch: 6| Step: 9
Training loss: 2.894296984130798
Validation loss: 2.6903450728594365

Epoch: 6| Step: 10
Training loss: 2.821374920271119
Validation loss: 2.6640534870362242

Epoch: 6| Step: 11
Training loss: 2.263173006397161
Validation loss: 2.6786806100820555

Epoch: 6| Step: 12
Training loss: 3.264817863630102
Validation loss: 2.666985502973737

Epoch: 6| Step: 13
Training loss: 2.525999203878898
Validation loss: 2.6718648092241906

Epoch: 37| Step: 0
Training loss: 2.8389708214980622
Validation loss: 2.6808942803270592

Epoch: 6| Step: 1
Training loss: 2.8238778442784556
Validation loss: 2.7096148983969126

Epoch: 6| Step: 2
Training loss: 2.3684137271745507
Validation loss: 2.6779535809600103

Epoch: 6| Step: 3
Training loss: 3.5474014227668182
Validation loss: 2.6382604629718136

Epoch: 6| Step: 4
Training loss: 3.498988822916979
Validation loss: 2.7050444392408823

Epoch: 6| Step: 5
Training loss: 3.4236637822437612
Validation loss: 2.6878612434829137

Epoch: 6| Step: 6
Training loss: 2.4788409320967295
Validation loss: 2.700004175464739

Epoch: 6| Step: 7
Training loss: 2.7787495206145207
Validation loss: 2.6978232891422325

Epoch: 6| Step: 8
Training loss: 3.1805187891390307
Validation loss: 2.7106745959672174

Epoch: 6| Step: 9
Training loss: 3.4674336453052317
Validation loss: 2.6872974738209243

Epoch: 6| Step: 10
Training loss: 3.5113586309026386
Validation loss: 2.6862106521370794

Epoch: 6| Step: 11
Training loss: 3.221474984734556
Validation loss: 2.6519075080503356

Epoch: 6| Step: 12
Training loss: 2.269696910806606
Validation loss: 2.7087347889500415

Epoch: 6| Step: 13
Training loss: 2.90680205321496
Validation loss: 2.68604214793996

Epoch: 38| Step: 0
Training loss: 3.597440864336744
Validation loss: 2.677176434683298

Epoch: 6| Step: 1
Training loss: 3.7226126989517034
Validation loss: 2.6704094674373136

Epoch: 6| Step: 2
Training loss: 3.167089751908377
Validation loss: 2.7179352696203765

Epoch: 6| Step: 3
Training loss: 3.1200448996418704
Validation loss: 2.6866475532635783

Epoch: 6| Step: 4
Training loss: 2.206189992807236
Validation loss: 2.6905142089593075

Epoch: 6| Step: 5
Training loss: 2.772688041756265
Validation loss: 2.6873783867218783

Epoch: 6| Step: 6
Training loss: 2.728660060852515
Validation loss: 2.700025691886636

Epoch: 6| Step: 7
Training loss: 3.3427770036772535
Validation loss: 2.6874479120409904

Epoch: 6| Step: 8
Training loss: 2.9540114913954527
Validation loss: 2.667223409503767

Epoch: 6| Step: 9
Training loss: 3.1825502148043125
Validation loss: 2.695280955948782

Epoch: 6| Step: 10
Training loss: 3.104869703178905
Validation loss: 2.7116048271138156

Epoch: 6| Step: 11
Training loss: 3.1156621657195114
Validation loss: 2.6990993554021143

Epoch: 6| Step: 12
Training loss: 2.781811346775527
Validation loss: 2.672647721988834

Epoch: 6| Step: 13
Training loss: 2.28016072225436
Validation loss: 2.7076162753661617

Epoch: 39| Step: 0
Training loss: 2.872614658813003
Validation loss: 2.6847275715965333

Epoch: 6| Step: 1
Training loss: 2.985605994585894
Validation loss: 2.695497932255688

Epoch: 6| Step: 2
Training loss: 3.4822140137944153
Validation loss: 2.71417759799044

Epoch: 6| Step: 3
Training loss: 2.7921538331190696
Validation loss: 2.6483905446981106

Epoch: 6| Step: 4
Training loss: 3.07236386946581
Validation loss: 2.6595152433966707

Epoch: 6| Step: 5
Training loss: 2.1929741076929563
Validation loss: 2.6530675171648554

Epoch: 6| Step: 6
Training loss: 2.788828522086693
Validation loss: 2.6577371370867704

Epoch: 6| Step: 7
Training loss: 3.1272731905507394
Validation loss: 2.6917558461418105

Epoch: 6| Step: 8
Training loss: 2.82637551502643
Validation loss: 2.658909403895989

Epoch: 6| Step: 9
Training loss: 3.8252611308002273
Validation loss: 2.6871500028218467

Epoch: 6| Step: 10
Training loss: 2.479439397177048
Validation loss: 2.6581628705116613

Epoch: 6| Step: 11
Training loss: 3.735937581686532
Validation loss: 2.685489336428454

Epoch: 6| Step: 12
Training loss: 2.7285879749489723
Validation loss: 2.6389523683291474

Epoch: 6| Step: 13
Training loss: 3.8676809285113616
Validation loss: 2.6586270471509934

Epoch: 40| Step: 0
Training loss: 2.6694049683650167
Validation loss: 2.6746445493745625

Epoch: 6| Step: 1
Training loss: 3.0728466650969204
Validation loss: 2.681519067214847

Epoch: 6| Step: 2
Training loss: 3.296264302610022
Validation loss: 2.671249740583452

Epoch: 6| Step: 3
Training loss: 3.101046348690402
Validation loss: 2.69650930519607

Epoch: 6| Step: 4
Training loss: 3.0044106802776818
Validation loss: 2.649014417536652

Epoch: 6| Step: 5
Training loss: 3.536500251682639
Validation loss: 2.7076511770296294

Epoch: 6| Step: 6
Training loss: 2.796622152993459
Validation loss: 2.644437636092662

Epoch: 6| Step: 7
Training loss: 3.373183149932461
Validation loss: 2.684339725180913

Epoch: 6| Step: 8
Training loss: 3.704817501829583
Validation loss: 2.639036128353639

Epoch: 6| Step: 9
Training loss: 2.3538280232240925
Validation loss: 2.6825715051739243

Epoch: 6| Step: 10
Training loss: 2.6256815615897358
Validation loss: 2.696372617802522

Epoch: 6| Step: 11
Training loss: 2.8154640685227323
Validation loss: 2.6552814790561796

Epoch: 6| Step: 12
Training loss: 2.683995912227559
Validation loss: 2.7081306170252115

Epoch: 6| Step: 13
Training loss: 3.3151056370078895
Validation loss: 2.6817087886382396

Epoch: 41| Step: 0
Training loss: 3.7901327922173915
Validation loss: 2.6661419502844472

Epoch: 6| Step: 1
Training loss: 2.76746854383447
Validation loss: 2.674714355850737

Epoch: 6| Step: 2
Training loss: 2.8593214686651507
Validation loss: 2.653294816266545

Epoch: 6| Step: 3
Training loss: 3.082881138265129
Validation loss: 2.688624493751576

Epoch: 6| Step: 4
Training loss: 2.8706054272224226
Validation loss: 2.640832554868183

Epoch: 6| Step: 5
Training loss: 2.8165503265310785
Validation loss: 2.6581348032083034

Epoch: 6| Step: 6
Training loss: 3.4003721145748336
Validation loss: 2.674322576370288

Epoch: 6| Step: 7
Training loss: 2.580721201084032
Validation loss: 2.683400923144501

Epoch: 6| Step: 8
Training loss: 2.356347573281242
Validation loss: 2.6650951552761404

Epoch: 6| Step: 9
Training loss: 3.1730891567607946
Validation loss: 2.6653658686650403

Epoch: 6| Step: 10
Training loss: 2.266752501807258
Validation loss: 2.6742370446665666

Epoch: 6| Step: 11
Training loss: 3.404577001885488
Validation loss: 2.684230522252001

Epoch: 6| Step: 12
Training loss: 3.0528982244196334
Validation loss: 2.6899095614249706

Epoch: 6| Step: 13
Training loss: 3.653209628519117
Validation loss: 2.6813656996037847

Epoch: 42| Step: 0
Training loss: 2.454446813097647
Validation loss: 2.6366960645616606

Epoch: 6| Step: 1
Training loss: 2.9726827171641226
Validation loss: 2.70036384397631

Epoch: 6| Step: 2
Training loss: 3.234717014676719
Validation loss: 2.681846849542788

Epoch: 6| Step: 3
Training loss: 4.264925609445206
Validation loss: 2.6205581923101926

Epoch: 6| Step: 4
Training loss: 2.1961002769088243
Validation loss: 2.65697404233418

Epoch: 6| Step: 5
Training loss: 3.4467301339135665
Validation loss: 2.653137775883519

Epoch: 6| Step: 6
Training loss: 3.055813086860218
Validation loss: 2.6980034928281706

Epoch: 6| Step: 7
Training loss: 3.032054833603286
Validation loss: 2.650009211135121

Epoch: 6| Step: 8
Training loss: 3.208951981253874
Validation loss: 2.6948532581174036

Epoch: 6| Step: 9
Training loss: 3.114652209758956
Validation loss: 2.6667648157648935

Epoch: 6| Step: 10
Training loss: 2.69007235887057
Validation loss: 2.6891435804322144

Epoch: 6| Step: 11
Training loss: 2.3125925818803594
Validation loss: 2.716512015182473

Epoch: 6| Step: 12
Training loss: 3.3792652446574833
Validation loss: 2.682828283986461

Epoch: 6| Step: 13
Training loss: 2.25508613049771
Validation loss: 2.666037438806847

Epoch: 43| Step: 0
Training loss: 3.050692470299136
Validation loss: 2.6659814552864876

Epoch: 6| Step: 1
Training loss: 2.4837682210928698
Validation loss: 2.6914757703330543

Epoch: 6| Step: 2
Training loss: 3.046421741125921
Validation loss: 2.6605011211387914

Epoch: 6| Step: 3
Training loss: 2.7957320621832285
Validation loss: 2.68324817329219

Epoch: 6| Step: 4
Training loss: 2.813609857920367
Validation loss: 2.676815550249678

Epoch: 6| Step: 5
Training loss: 4.105135627392487
Validation loss: 2.660259329214611

Epoch: 6| Step: 6
Training loss: 3.1564388407500483
Validation loss: 2.655704621335305

Epoch: 6| Step: 7
Training loss: 3.5398818661218954
Validation loss: 2.717049617288453

Epoch: 6| Step: 8
Training loss: 2.9621829028173887
Validation loss: 2.6524038246851065

Epoch: 6| Step: 9
Training loss: 2.5399145956024
Validation loss: 2.6760993746253914

Epoch: 6| Step: 10
Training loss: 2.9549238589525504
Validation loss: 2.676275554138267

Epoch: 6| Step: 11
Training loss: 3.3092804143282777
Validation loss: 2.6360770254264994

Epoch: 6| Step: 12
Training loss: 2.441846639967907
Validation loss: 2.6566187352314192

Epoch: 6| Step: 13
Training loss: 3.1344924189746215
Validation loss: 2.6593036642670294

Epoch: 44| Step: 0
Training loss: 3.498930086364627
Validation loss: 2.6648043146206

Epoch: 6| Step: 1
Training loss: 2.298866394813407
Validation loss: 2.699073558347899

Epoch: 6| Step: 2
Training loss: 2.236810383999888
Validation loss: 2.6782970611407024

Epoch: 6| Step: 3
Training loss: 2.9523306287850954
Validation loss: 2.649098246512444

Epoch: 6| Step: 4
Training loss: 3.4219770024394682
Validation loss: 2.696490187936384

Epoch: 6| Step: 5
Training loss: 3.6459535560767704
Validation loss: 2.6756418671939977

Epoch: 6| Step: 6
Training loss: 3.1556373228156263
Validation loss: 2.680178486764291

Epoch: 6| Step: 7
Training loss: 2.6679517709127545
Validation loss: 2.6627313814441296

Epoch: 6| Step: 8
Training loss: 2.9816513015354014
Validation loss: 2.650230440416345

Epoch: 6| Step: 9
Training loss: 2.8620959400701467
Validation loss: 2.658945576415201

Epoch: 6| Step: 10
Training loss: 2.784661590178233
Validation loss: 2.6742217810971805

Epoch: 6| Step: 11
Training loss: 2.470518420405718
Validation loss: 2.6881646462205415

Epoch: 6| Step: 12
Training loss: 3.317002888671059
Validation loss: 2.6766682694042525

Epoch: 6| Step: 13
Training loss: 4.403667802565998
Validation loss: 2.6434403200229304

Epoch: 45| Step: 0
Training loss: 3.162698032375861
Validation loss: 2.6990317430408473

Epoch: 6| Step: 1
Training loss: 3.5512061205861696
Validation loss: 2.6607572174163843

Epoch: 6| Step: 2
Training loss: 2.849470818898468
Validation loss: 2.662998662951438

Epoch: 6| Step: 3
Training loss: 2.609612185725629
Validation loss: 2.672337678424466

Epoch: 6| Step: 4
Training loss: 3.14429240770928
Validation loss: 2.6895872502016345

Epoch: 6| Step: 5
Training loss: 3.6088836467586876
Validation loss: 2.6458884606412996

Epoch: 6| Step: 6
Training loss: 3.06144384740046
Validation loss: 2.678404506496253

Epoch: 6| Step: 7
Training loss: 3.407213547239759
Validation loss: 2.7042926839044577

Epoch: 6| Step: 8
Training loss: 2.8944857821580734
Validation loss: 2.7075457302526487

Epoch: 6| Step: 9
Training loss: 3.050553512376493
Validation loss: 2.676848710152521

Epoch: 6| Step: 10
Training loss: 2.6424399013415893
Validation loss: 2.7026885154033584

Epoch: 6| Step: 11
Training loss: 1.996603465833983
Validation loss: 2.6890712741635894

Epoch: 6| Step: 12
Training loss: 3.0705165649623205
Validation loss: 2.6801448687499287

Epoch: 6| Step: 13
Training loss: 3.1116356993981547
Validation loss: 2.644154334127783

Epoch: 46| Step: 0
Training loss: 3.687112690903597
Validation loss: 2.6605311600218307

Epoch: 6| Step: 1
Training loss: 2.8816861896136707
Validation loss: 2.6959880983818367

Epoch: 6| Step: 2
Training loss: 3.3215158952053883
Validation loss: 2.615117976890925

Epoch: 6| Step: 3
Training loss: 2.6799481768365943
Validation loss: 2.6648705981529646

Epoch: 6| Step: 4
Training loss: 2.805985429352107
Validation loss: 2.666357728792779

Epoch: 6| Step: 5
Training loss: 3.0495585825694427
Validation loss: 2.6757330279117744

Epoch: 6| Step: 6
Training loss: 2.6654876745164793
Validation loss: 2.6494396096255657

Epoch: 6| Step: 7
Training loss: 3.2660218504194045
Validation loss: 2.6733144737182735

Epoch: 6| Step: 8
Training loss: 3.0118530085184894
Validation loss: 2.6759362980863455

Epoch: 6| Step: 9
Training loss: 2.952123562994775
Validation loss: 2.6809206376810213

Epoch: 6| Step: 10
Training loss: 2.5255179789825903
Validation loss: 2.6502218998685887

Epoch: 6| Step: 11
Training loss: 3.5836038413445226
Validation loss: 2.6406939524772635

Epoch: 6| Step: 12
Training loss: 2.7581105706040385
Validation loss: 2.6765160735087457

Epoch: 6| Step: 13
Training loss: 3.2058064471840217
Validation loss: 2.6084279402509156

Epoch: 47| Step: 0
Training loss: 2.715521814209878
Validation loss: 2.6203084811965573

Epoch: 6| Step: 1
Training loss: 2.396073160745366
Validation loss: 2.6217093011366948

Epoch: 6| Step: 2
Training loss: 3.373706145762992
Validation loss: 2.6827726355643557

Epoch: 6| Step: 3
Training loss: 3.687000305457189
Validation loss: 2.6488603670623063

Epoch: 6| Step: 4
Training loss: 3.5566179671762495
Validation loss: 2.6770866048958943

Epoch: 6| Step: 5
Training loss: 2.918170069193085
Validation loss: 2.6453368987540875

Epoch: 6| Step: 6
Training loss: 2.946921963686618
Validation loss: 2.661638571214591

Epoch: 6| Step: 7
Training loss: 2.995798825068326
Validation loss: 2.6460245528597564

Epoch: 6| Step: 8
Training loss: 3.105835092876875
Validation loss: 2.6500843370560734

Epoch: 6| Step: 9
Training loss: 3.0304759502202425
Validation loss: 2.653124951067981

Epoch: 6| Step: 10
Training loss: 2.908855295935229
Validation loss: 2.6275937264646223

Epoch: 6| Step: 11
Training loss: 2.5804432012186544
Validation loss: 2.6502208329027654

Epoch: 6| Step: 12
Training loss: 2.777814908309306
Validation loss: 2.6438788307823637

Epoch: 6| Step: 13
Training loss: 2.680345549013313
Validation loss: 2.6323252038573814

Epoch: 48| Step: 0
Training loss: 2.99283985168061
Validation loss: 2.665437099246747

Epoch: 6| Step: 1
Training loss: 3.461737891101025
Validation loss: 2.6622702844615285

Epoch: 6| Step: 2
Training loss: 2.5393785485391422
Validation loss: 2.6455503371666453

Epoch: 6| Step: 3
Training loss: 3.2247667095172243
Validation loss: 2.6904802055492794

Epoch: 6| Step: 4
Training loss: 2.874057781235933
Validation loss: 2.6362062518407003

Epoch: 6| Step: 5
Training loss: 2.9169184621479114
Validation loss: 2.6563708804455737

Epoch: 6| Step: 6
Training loss: 2.7127220590291694
Validation loss: 2.6700140951562763

Epoch: 6| Step: 7
Training loss: 2.9025441815466095
Validation loss: 2.653917574867174

Epoch: 6| Step: 8
Training loss: 3.4308471109630796
Validation loss: 2.6836668429293216

Epoch: 6| Step: 9
Training loss: 3.700327399950076
Validation loss: 2.6230411320721827

Epoch: 6| Step: 10
Training loss: 2.5830037511782815
Validation loss: 2.657465020480316

Epoch: 6| Step: 11
Training loss: 2.29912576231381
Validation loss: 2.670637104836984

Epoch: 6| Step: 12
Training loss: 3.0778669065139685
Validation loss: 2.6503158598569585

Epoch: 6| Step: 13
Training loss: 3.2668317545481913
Validation loss: 2.6451142502875715

Epoch: 49| Step: 0
Training loss: 2.746702644921124
Validation loss: 2.66481375603605

Epoch: 6| Step: 1
Training loss: 2.664388865954483
Validation loss: 2.6467188763905467

Epoch: 6| Step: 2
Training loss: 3.673218306894179
Validation loss: 2.69617635572015

Epoch: 6| Step: 3
Training loss: 3.5146419252683487
Validation loss: 2.668657308441759

Epoch: 6| Step: 4
Training loss: 2.450542864698774
Validation loss: 2.617335543534216

Epoch: 6| Step: 5
Training loss: 3.2723013788596726
Validation loss: 2.668842366083105

Epoch: 6| Step: 6
Training loss: 3.173097271620587
Validation loss: 2.6818952417813864

Epoch: 6| Step: 7
Training loss: 3.2753452031734263
Validation loss: 2.64552334154906

Epoch: 6| Step: 8
Training loss: 2.887930113889947
Validation loss: 2.6462708743574503

Epoch: 6| Step: 9
Training loss: 3.6350794128390764
Validation loss: 2.647313150263339

Epoch: 6| Step: 10
Training loss: 2.051868433922944
Validation loss: 2.643917498255504

Epoch: 6| Step: 11
Training loss: 3.3750454934904037
Validation loss: 2.609671385464394

Epoch: 6| Step: 12
Training loss: 2.7139365896689887
Validation loss: 2.6137318708764914

Epoch: 6| Step: 13
Training loss: 1.9693855591893143
Validation loss: 2.653256204291769

Epoch: 50| Step: 0
Training loss: 2.5729805221561666
Validation loss: 2.605466896245018

Epoch: 6| Step: 1
Training loss: 3.063986125735352
Validation loss: 2.674444544643036

Epoch: 6| Step: 2
Training loss: 2.8992846297208805
Validation loss: 2.6558007320607024

Epoch: 6| Step: 3
Training loss: 3.278414127483619
Validation loss: 2.682327480218447

Epoch: 6| Step: 4
Training loss: 2.5282179957993036
Validation loss: 2.6512886382154486

Epoch: 6| Step: 5
Training loss: 2.605482384504477
Validation loss: 2.667681938822065

Epoch: 6| Step: 6
Training loss: 3.0804620381378185
Validation loss: 2.6400785648362093

Epoch: 6| Step: 7
Training loss: 3.0275902432411885
Validation loss: 2.63675042294796

Epoch: 6| Step: 8
Training loss: 3.641582444975295
Validation loss: 2.6548439073138566

Epoch: 6| Step: 9
Training loss: 2.3350162794701506
Validation loss: 2.664249070451019

Epoch: 6| Step: 10
Training loss: 2.759472398777835
Validation loss: 2.642940462596322

Epoch: 6| Step: 11
Training loss: 3.7323618294653325
Validation loss: 2.6670852231388658

Epoch: 6| Step: 12
Training loss: 2.9679429412868394
Validation loss: 2.669983305529207

Epoch: 6| Step: 13
Training loss: 3.0640567793104583
Validation loss: 2.6553735627449027

Epoch: 51| Step: 0
Training loss: 3.0158751388931133
Validation loss: 2.641300792349073

Epoch: 6| Step: 1
Training loss: 2.8260740989532915
Validation loss: 2.648737907886713

Epoch: 6| Step: 2
Training loss: 3.4669341412085606
Validation loss: 2.665653874422024

Epoch: 6| Step: 3
Training loss: 2.5878692510909795
Validation loss: 2.612055151154207

Epoch: 6| Step: 4
Training loss: 3.9625313164950637
Validation loss: 2.652492046582616

Epoch: 6| Step: 5
Training loss: 3.0427954334267393
Validation loss: 2.648045628867808

Epoch: 6| Step: 6
Training loss: 2.3422853089333127
Validation loss: 2.644141841442619

Epoch: 6| Step: 7
Training loss: 2.3270501849603447
Validation loss: 2.672139601146917

Epoch: 6| Step: 8
Training loss: 3.235757283599043
Validation loss: 2.618280897005194

Epoch: 6| Step: 9
Training loss: 2.550782465094705
Validation loss: 2.642333728601203

Epoch: 6| Step: 10
Training loss: 3.174253126592479
Validation loss: 2.6788068199737936

Epoch: 6| Step: 11
Training loss: 3.235826691738494
Validation loss: 2.6452070251823483

Epoch: 6| Step: 12
Training loss: 3.0578905566373806
Validation loss: 2.6373946635744243

Epoch: 6| Step: 13
Training loss: 3.0727014153733045
Validation loss: 2.666715979761062

Epoch: 52| Step: 0
Training loss: 3.0618841369455203
Validation loss: 2.6113387493494464

Epoch: 6| Step: 1
Training loss: 2.993996016362763
Validation loss: 2.6570340914476076

Epoch: 6| Step: 2
Training loss: 3.793660376808318
Validation loss: 2.6633636199759163

Epoch: 6| Step: 3
Training loss: 1.8986332168476643
Validation loss: 2.6718739656682517

Epoch: 6| Step: 4
Training loss: 2.2330005393055368
Validation loss: 2.666140428143331

Epoch: 6| Step: 5
Training loss: 3.13358805277156
Validation loss: 2.642294913761333

Epoch: 6| Step: 6
Training loss: 2.3898136532332757
Validation loss: 2.641374339341062

Epoch: 6| Step: 7
Training loss: 2.8246325431108867
Validation loss: 2.6375351130991267

Epoch: 6| Step: 8
Training loss: 2.715475017238123
Validation loss: 2.6464502524393634

Epoch: 6| Step: 9
Training loss: 3.1995758490796358
Validation loss: 2.6212925490556693

Epoch: 6| Step: 10
Training loss: 2.939329835454299
Validation loss: 2.6967995081002556

Epoch: 6| Step: 11
Training loss: 3.4761877650917863
Validation loss: 2.631728366728935

Epoch: 6| Step: 12
Training loss: 2.6043422385476527
Validation loss: 2.6403465019768784

Epoch: 6| Step: 13
Training loss: 4.423109118239181
Validation loss: 2.6602154254859185

Epoch: 53| Step: 0
Training loss: 2.6725627170265676
Validation loss: 2.6540072214534796

Epoch: 6| Step: 1
Training loss: 3.6527066789934928
Validation loss: 2.6310150202517066

Epoch: 6| Step: 2
Training loss: 3.3922410620735333
Validation loss: 2.6381545321103412

Epoch: 6| Step: 3
Training loss: 2.6016790690382017
Validation loss: 2.654598078071201

Epoch: 6| Step: 4
Training loss: 2.5303380759907546
Validation loss: 2.5961293706706345

Epoch: 6| Step: 5
Training loss: 3.5795280004739114
Validation loss: 2.6366655830057595

Epoch: 6| Step: 6
Training loss: 3.247452250798435
Validation loss: 2.6919023343637027

Epoch: 6| Step: 7
Training loss: 2.812518734339731
Validation loss: 2.6565982250137963

Epoch: 6| Step: 8
Training loss: 2.87577958525361
Validation loss: 2.5863281496221013

Epoch: 6| Step: 9
Training loss: 2.4146394009426073
Validation loss: 2.671836238192044

Epoch: 6| Step: 10
Training loss: 2.818251345355727
Validation loss: 2.6316739065581456

Epoch: 6| Step: 11
Training loss: 3.1828843151262287
Validation loss: 2.6182863938422356

Epoch: 6| Step: 12
Training loss: 2.9783913908517143
Validation loss: 2.6249733116328455

Epoch: 6| Step: 13
Training loss: 2.840213295086211
Validation loss: 2.639011292640255

Epoch: 54| Step: 0
Training loss: 2.7700829218767957
Validation loss: 2.6432620237377287

Epoch: 6| Step: 1
Training loss: 3.390032879155146
Validation loss: 2.6767485836920617

Epoch: 6| Step: 2
Training loss: 3.14346716273968
Validation loss: 2.6434095612806847

Epoch: 6| Step: 3
Training loss: 2.962145073469444
Validation loss: 2.6386118597900343

Epoch: 6| Step: 4
Training loss: 3.5913292734470037
Validation loss: 2.605563405856667

Epoch: 6| Step: 5
Training loss: 3.4850690347190847
Validation loss: 2.6661338169637934

Epoch: 6| Step: 6
Training loss: 2.897179178771774
Validation loss: 2.679429627020167

Epoch: 6| Step: 7
Training loss: 2.177581754391349
Validation loss: 2.631978883026531

Epoch: 6| Step: 8
Training loss: 3.3303146681018325
Validation loss: 2.634944961754342

Epoch: 6| Step: 9
Training loss: 2.9009248902920963
Validation loss: 2.6103635279549775

Epoch: 6| Step: 10
Training loss: 3.0551162770021403
Validation loss: 2.60013290721078

Epoch: 6| Step: 11
Training loss: 3.211852896859832
Validation loss: 2.6482005418510752

Epoch: 6| Step: 12
Training loss: 2.3146212359832123
Validation loss: 2.6791635478999316

Epoch: 6| Step: 13
Training loss: 1.9738190802286337
Validation loss: 2.6381557691545416

Epoch: 55| Step: 0
Training loss: 3.0143755760564064
Validation loss: 2.619100984858827

Epoch: 6| Step: 1
Training loss: 2.741010190369327
Validation loss: 2.620017749180181

Epoch: 6| Step: 2
Training loss: 2.56535877700462
Validation loss: 2.6505431299124127

Epoch: 6| Step: 3
Training loss: 2.8507486932703516
Validation loss: 2.6660635439823483

Epoch: 6| Step: 4
Training loss: 2.934988368464594
Validation loss: 2.6425792348268935

Epoch: 6| Step: 5
Training loss: 2.6204266445386253
Validation loss: 2.638688488705279

Epoch: 6| Step: 6
Training loss: 2.887023992234613
Validation loss: 2.6421754851329164

Epoch: 6| Step: 7
Training loss: 3.3273731510738043
Validation loss: 2.5929890977010293

Epoch: 6| Step: 8
Training loss: 4.2494430177016564
Validation loss: 2.6361216073636373

Epoch: 6| Step: 9
Training loss: 3.2069371310698123
Validation loss: 2.6246442294903405

Epoch: 6| Step: 10
Training loss: 2.554567200047657
Validation loss: 2.669868191022721

Epoch: 6| Step: 11
Training loss: 2.875722545552088
Validation loss: 2.638133663582844

Epoch: 6| Step: 12
Training loss: 2.6050631594918014
Validation loss: 2.6544554872004875

Epoch: 6| Step: 13
Training loss: 3.714854275500993
Validation loss: 2.609778488173673

Epoch: 56| Step: 0
Training loss: 3.512061996573158
Validation loss: 2.678967500693622

Epoch: 6| Step: 1
Training loss: 2.960324025074799
Validation loss: 2.61783787313337

Epoch: 6| Step: 2
Training loss: 2.828777427658368
Validation loss: 2.6117627593183954

Epoch: 6| Step: 3
Training loss: 2.5238208774780824
Validation loss: 2.6675558815577105

Epoch: 6| Step: 4
Training loss: 2.693780524485824
Validation loss: 2.6413300197977443

Epoch: 6| Step: 5
Training loss: 3.51547824129444
Validation loss: 2.6481668876893356

Epoch: 6| Step: 6
Training loss: 3.1323413827593845
Validation loss: 2.6591378907947543

Epoch: 6| Step: 7
Training loss: 3.692644055035294
Validation loss: 2.639523843483582

Epoch: 6| Step: 8
Training loss: 2.8697382004056027
Validation loss: 2.6581720423275246

Epoch: 6| Step: 9
Training loss: 2.357489432415381
Validation loss: 2.645869647154664

Epoch: 6| Step: 10
Training loss: 2.779398441134354
Validation loss: 2.627239511315684

Epoch: 6| Step: 11
Training loss: 2.753803570503792
Validation loss: 2.6543138545092044

Epoch: 6| Step: 12
Training loss: 3.4024293803356724
Validation loss: 2.6346249918332325

Epoch: 6| Step: 13
Training loss: 1.7670105755354026
Validation loss: 2.629501235705203

Epoch: 57| Step: 0
Training loss: 2.4597890929395523
Validation loss: 2.66946598631162

Epoch: 6| Step: 1
Training loss: 2.4037039030974405
Validation loss: 2.61283060635307

Epoch: 6| Step: 2
Training loss: 2.9266789565411244
Validation loss: 2.6607029708275483

Epoch: 6| Step: 3
Training loss: 2.8520243231550753
Validation loss: 2.584785109231402

Epoch: 6| Step: 4
Training loss: 2.9350700879542235
Validation loss: 2.644914865082617

Epoch: 6| Step: 5
Training loss: 3.14695670846667
Validation loss: 2.6251080691451327

Epoch: 6| Step: 6
Training loss: 2.968537011788205
Validation loss: 2.642666411049239

Epoch: 6| Step: 7
Training loss: 3.0805419108259944
Validation loss: 2.6689106519886234

Epoch: 6| Step: 8
Training loss: 3.648074407705423
Validation loss: 2.6393611470987595

Epoch: 6| Step: 9
Training loss: 3.7076436090726106
Validation loss: 2.6196036335647017

Epoch: 6| Step: 10
Training loss: 3.433583751051994
Validation loss: 2.64788333216742

Epoch: 6| Step: 11
Training loss: 3.1029790530885397
Validation loss: 2.645559774617623

Epoch: 6| Step: 12
Training loss: 2.3938046919747467
Validation loss: 2.656389164038822

Epoch: 6| Step: 13
Training loss: 1.8178961437301742
Validation loss: 2.664679886646308

Epoch: 58| Step: 0
Training loss: 3.0994279948998407
Validation loss: 2.6271090436419002

Epoch: 6| Step: 1
Training loss: 3.257059060479209
Validation loss: 2.63464861755444

Epoch: 6| Step: 2
Training loss: 3.119560084507046
Validation loss: 2.6638661594517496

Epoch: 6| Step: 3
Training loss: 3.4040649124931206
Validation loss: 2.636495353322881

Epoch: 6| Step: 4
Training loss: 3.0763121557796054
Validation loss: 2.6515357014936187

Epoch: 6| Step: 5
Training loss: 3.153100888299008
Validation loss: 2.655005830666019

Epoch: 6| Step: 6
Training loss: 2.8665221894990847
Validation loss: 2.6721766220718437

Epoch: 6| Step: 7
Training loss: 2.7977464053645873
Validation loss: 2.6364312998244386

Epoch: 6| Step: 8
Training loss: 2.7996985818205236
Validation loss: 2.63556743636245

Epoch: 6| Step: 9
Training loss: 2.3168000116553755
Validation loss: 2.6309739385794804

Epoch: 6| Step: 10
Training loss: 2.9473400473125233
Validation loss: 2.626135346683039

Epoch: 6| Step: 11
Training loss: 3.197080239786194
Validation loss: 2.650198336558717

Epoch: 6| Step: 12
Training loss: 3.1163246279891506
Validation loss: 2.662933520331107

Epoch: 6| Step: 13
Training loss: 2.256373280039394
Validation loss: 2.6507979648322615

Epoch: 59| Step: 0
Training loss: 3.1206738854400626
Validation loss: 2.67687567621359

Epoch: 6| Step: 1
Training loss: 3.1321678354497973
Validation loss: 2.653259560952886

Epoch: 6| Step: 2
Training loss: 3.18227556706345
Validation loss: 2.6568830320910983

Epoch: 6| Step: 3
Training loss: 3.3583062889455295
Validation loss: 2.6737096388969896

Epoch: 6| Step: 4
Training loss: 3.189913565203107
Validation loss: 2.6484538046437547

Epoch: 6| Step: 5
Training loss: 3.2713120873476975
Validation loss: 2.617604615753281

Epoch: 6| Step: 6
Training loss: 3.2702032239566643
Validation loss: 2.6395645288817593

Epoch: 6| Step: 7
Training loss: 2.7029642928316227
Validation loss: 2.6271817222961267

Epoch: 6| Step: 8
Training loss: 2.5987285953317296
Validation loss: 2.656548447464102

Epoch: 6| Step: 9
Training loss: 3.136515039501258
Validation loss: 2.626701834631499

Epoch: 6| Step: 10
Training loss: 2.3071427020916895
Validation loss: 2.6573848724918356

Epoch: 6| Step: 11
Training loss: 2.500418151217656
Validation loss: 2.6064392556234943

Epoch: 6| Step: 12
Training loss: 3.0223380364249297
Validation loss: 2.6454897124424726

Epoch: 6| Step: 13
Training loss: 2.4948578403008352
Validation loss: 2.627718932004774

Epoch: 60| Step: 0
Training loss: 2.9275648234656155
Validation loss: 2.610666970197678

Epoch: 6| Step: 1
Training loss: 2.0936324812518396
Validation loss: 2.644305553473052

Epoch: 6| Step: 2
Training loss: 2.6902185928415756
Validation loss: 2.6343010392516995

Epoch: 6| Step: 3
Training loss: 3.200554835379713
Validation loss: 2.6387601586422798

Epoch: 6| Step: 4
Training loss: 3.2649599703194045
Validation loss: 2.66677847718848

Epoch: 6| Step: 5
Training loss: 3.2382276505289727
Validation loss: 2.604906585583919

Epoch: 6| Step: 6
Training loss: 2.8719919473540494
Validation loss: 2.636988195144796

Epoch: 6| Step: 7
Training loss: 3.000142570922558
Validation loss: 2.622527943475792

Epoch: 6| Step: 8
Training loss: 2.7567929552695607
Validation loss: 2.6210717968916715

Epoch: 6| Step: 9
Training loss: 2.539997104883421
Validation loss: 2.6424060282825295

Epoch: 6| Step: 10
Training loss: 3.0076130590330616
Validation loss: 2.646289208357733

Epoch: 6| Step: 11
Training loss: 2.9817773188669006
Validation loss: 2.6366960577556107

Epoch: 6| Step: 12
Training loss: 3.538319490764731
Validation loss: 2.629106133537403

Epoch: 6| Step: 13
Training loss: 3.4465601039722156
Validation loss: 2.629218072601416

Epoch: 61| Step: 0
Training loss: 2.8881046339190766
Validation loss: 2.615693512655357

Epoch: 6| Step: 1
Training loss: 2.9883380560368673
Validation loss: 2.5748924352176235

Epoch: 6| Step: 2
Training loss: 2.85836840979701
Validation loss: 2.6290547530812782

Epoch: 6| Step: 3
Training loss: 2.959162761485485
Validation loss: 2.6432267121980964

Epoch: 6| Step: 4
Training loss: 2.3744235091991484
Validation loss: 2.605074828914271

Epoch: 6| Step: 5
Training loss: 3.237688661476323
Validation loss: 2.6225312070097258

Epoch: 6| Step: 6
Training loss: 3.5286993756988734
Validation loss: 2.620177828864202

Epoch: 6| Step: 7
Training loss: 3.138478014976094
Validation loss: 2.620676814924668

Epoch: 6| Step: 8
Training loss: 1.5883304976724542
Validation loss: 2.644101911962355

Epoch: 6| Step: 9
Training loss: 2.9915775643541926
Validation loss: 2.6201791722377896

Epoch: 6| Step: 10
Training loss: 3.1041716163817674
Validation loss: 2.6445826632412253

Epoch: 6| Step: 11
Training loss: 3.122977250631036
Validation loss: 2.641534239912092

Epoch: 6| Step: 12
Training loss: 3.0928047354451262
Validation loss: 2.662332340268791

Epoch: 6| Step: 13
Training loss: 3.490223991835423
Validation loss: 2.638698862988189

Epoch: 62| Step: 0
Training loss: 2.8119574129398726
Validation loss: 2.6475052657682103

Epoch: 6| Step: 1
Training loss: 3.1982852752345634
Validation loss: 2.6784121790169086

Epoch: 6| Step: 2
Training loss: 2.2186509231152467
Validation loss: 2.630753894531279

Epoch: 6| Step: 3
Training loss: 3.5076915150871875
Validation loss: 2.642087316581878

Epoch: 6| Step: 4
Training loss: 2.877047763156172
Validation loss: 2.6391532375511413

Epoch: 6| Step: 5
Training loss: 3.3041717631880783
Validation loss: 2.607116997496265

Epoch: 6| Step: 6
Training loss: 2.9081588547041815
Validation loss: 2.59783140300249

Epoch: 6| Step: 7
Training loss: 3.0944290186620997
Validation loss: 2.603834162660457

Epoch: 6| Step: 8
Training loss: 2.5224676482864177
Validation loss: 2.595488168369887

Epoch: 6| Step: 9
Training loss: 3.299205950369589
Validation loss: 2.5964236642290706

Epoch: 6| Step: 10
Training loss: 3.0091662246364317
Validation loss: 2.607314314633714

Epoch: 6| Step: 11
Training loss: 2.582859385503912
Validation loss: 2.6742816154777693

Epoch: 6| Step: 12
Training loss: 3.32249698360355
Validation loss: 2.623859291464544

Epoch: 6| Step: 13
Training loss: 2.4461823400186047
Validation loss: 2.6209500885361825

Epoch: 63| Step: 0
Training loss: 2.880931540409689
Validation loss: 2.6351521443678987

Epoch: 6| Step: 1
Training loss: 2.035120636084743
Validation loss: 2.61363673203859

Epoch: 6| Step: 2
Training loss: 3.0699801277238166
Validation loss: 2.5877979925552697

Epoch: 6| Step: 3
Training loss: 2.321615039756218
Validation loss: 2.621062920721935

Epoch: 6| Step: 4
Training loss: 3.008807604768814
Validation loss: 2.5842629621382756

Epoch: 6| Step: 5
Training loss: 2.7270434810639754
Validation loss: 2.640250398652215

Epoch: 6| Step: 6
Training loss: 3.2525835772133225
Validation loss: 2.622919710577443

Epoch: 6| Step: 7
Training loss: 3.317094315861004
Validation loss: 2.63167533076256

Epoch: 6| Step: 8
Training loss: 3.475708588732177
Validation loss: 2.590848018610545

Epoch: 6| Step: 9
Training loss: 3.107245708197741
Validation loss: 2.57518602036408

Epoch: 6| Step: 10
Training loss: 3.4313046199154806
Validation loss: 2.5960391188335787

Epoch: 6| Step: 11
Training loss: 2.9516269981724204
Validation loss: 2.628070369717117

Epoch: 6| Step: 12
Training loss: 2.400554803459067
Validation loss: 2.702067759104781

Epoch: 6| Step: 13
Training loss: 3.7714238134783504
Validation loss: 2.646797177733871

Epoch: 64| Step: 0
Training loss: 3.2701224427237086
Validation loss: 2.644378339721464

Epoch: 6| Step: 1
Training loss: 3.0399871439410973
Validation loss: 2.619746311016694

Epoch: 6| Step: 2
Training loss: 3.6223984953017867
Validation loss: 2.6016707149792935

Epoch: 6| Step: 3
Training loss: 3.043066216647506
Validation loss: 2.580481023048525

Epoch: 6| Step: 4
Training loss: 2.666496619127449
Validation loss: 2.6296643520151397

Epoch: 6| Step: 5
Training loss: 3.000997377541301
Validation loss: 2.6580574936248325

Epoch: 6| Step: 6
Training loss: 3.1958371503493
Validation loss: 2.6347236103007767

Epoch: 6| Step: 7
Training loss: 2.6967714645650425
Validation loss: 2.654769316836077

Epoch: 6| Step: 8
Training loss: 2.2152914035528215
Validation loss: 2.634165147178435

Epoch: 6| Step: 9
Training loss: 3.1496675043373097
Validation loss: 2.63011155577384

Epoch: 6| Step: 10
Training loss: 3.4832980967903846
Validation loss: 2.604299494811618

Epoch: 6| Step: 11
Training loss: 2.3916422356433222
Validation loss: 2.6375923934093164

Epoch: 6| Step: 12
Training loss: 3.1171822990049027
Validation loss: 2.6259108963570084

Epoch: 6| Step: 13
Training loss: 2.456286974136024
Validation loss: 2.6478850061585675

Epoch: 65| Step: 0
Training loss: 2.8591008289406004
Validation loss: 2.627593434741977

Epoch: 6| Step: 1
Training loss: 3.0133918043669623
Validation loss: 2.6054862936986685

Epoch: 6| Step: 2
Training loss: 3.3802687880052673
Validation loss: 2.6430865030398807

Epoch: 6| Step: 3
Training loss: 3.068132631312205
Validation loss: 2.6329683793420164

Epoch: 6| Step: 4
Training loss: 2.640536605890386
Validation loss: 2.6178564229104087

Epoch: 6| Step: 5
Training loss: 2.582714734820464
Validation loss: 2.6335942983960607

Epoch: 6| Step: 6
Training loss: 3.599862117246103
Validation loss: 2.616583863121221

Epoch: 6| Step: 7
Training loss: 2.4987611562185004
Validation loss: 2.617077444373951

Epoch: 6| Step: 8
Training loss: 2.7805528088366693
Validation loss: 2.6425739301605735

Epoch: 6| Step: 9
Training loss: 2.954701804979253
Validation loss: 2.59564672179323

Epoch: 6| Step: 10
Training loss: 3.6048870505999226
Validation loss: 2.5979918373019655

Epoch: 6| Step: 11
Training loss: 2.4057453171217587
Validation loss: 2.6051772593617604

Epoch: 6| Step: 12
Training loss: 2.9758873521752993
Validation loss: 2.61421665283652

Epoch: 6| Step: 13
Training loss: 2.772518553744839
Validation loss: 2.615970672149312

Epoch: 66| Step: 0
Training loss: 3.378958888002203
Validation loss: 2.6420384533183054

Epoch: 6| Step: 1
Training loss: 2.7549812978120096
Validation loss: 2.5896024173157484

Epoch: 6| Step: 2
Training loss: 2.7589854050706877
Validation loss: 2.641225002135523

Epoch: 6| Step: 3
Training loss: 3.428659619604923
Validation loss: 2.6679784761720975

Epoch: 6| Step: 4
Training loss: 2.689538404432712
Validation loss: 2.633305351559858

Epoch: 6| Step: 5
Training loss: 2.2258412046113603
Validation loss: 2.6081114695231102

Epoch: 6| Step: 6
Training loss: 3.070119138263583
Validation loss: 2.6232798712806

Epoch: 6| Step: 7
Training loss: 2.714949220214084
Validation loss: 2.6178778859215144

Epoch: 6| Step: 8
Training loss: 2.8728344266285633
Validation loss: 2.6282211713172914

Epoch: 6| Step: 9
Training loss: 2.648407072269438
Validation loss: 2.632498526374738

Epoch: 6| Step: 10
Training loss: 3.7723794089446114
Validation loss: 2.6446793216165445

Epoch: 6| Step: 11
Training loss: 2.9650549128627457
Validation loss: 2.631385264228777

Epoch: 6| Step: 12
Training loss: 2.428728901942759
Validation loss: 2.6023973468515855

Epoch: 6| Step: 13
Training loss: 2.4039052463017385
Validation loss: 2.643354294342632

Epoch: 67| Step: 0
Training loss: 3.345987444820437
Validation loss: 2.6335886816530985

Epoch: 6| Step: 1
Training loss: 2.6132019669576025
Validation loss: 2.6555398029018007

Epoch: 6| Step: 2
Training loss: 2.883785094075326
Validation loss: 2.612990594579561

Epoch: 6| Step: 3
Training loss: 2.217650880035046
Validation loss: 2.611472229395998

Epoch: 6| Step: 4
Training loss: 3.0317001795021805
Validation loss: 2.589605717888985

Epoch: 6| Step: 5
Training loss: 2.8654909857609985
Validation loss: 2.624386930192389

Epoch: 6| Step: 6
Training loss: 2.5126690290538964
Validation loss: 2.6308955765388884

Epoch: 6| Step: 7
Training loss: 3.0750759146398874
Validation loss: 2.5652742662504284

Epoch: 6| Step: 8
Training loss: 2.4708289555408447
Validation loss: 2.586813378559081

Epoch: 6| Step: 9
Training loss: 3.2830681985864723
Validation loss: 2.6493539364713836

Epoch: 6| Step: 10
Training loss: 3.1032427409136405
Validation loss: 2.6114135353195658

Epoch: 6| Step: 11
Training loss: 3.024325454788544
Validation loss: 2.6141522976409868

Epoch: 6| Step: 12
Training loss: 2.5552712802984283
Validation loss: 2.5916985153880727

Epoch: 6| Step: 13
Training loss: 4.375324346236017
Validation loss: 2.6007545697499452

Epoch: 68| Step: 0
Training loss: 2.390322797037179
Validation loss: 2.597961166093746

Epoch: 6| Step: 1
Training loss: 2.2857759075713853
Validation loss: 2.608472880737891

Epoch: 6| Step: 2
Training loss: 2.9154864148468005
Validation loss: 2.6061951482448222

Epoch: 6| Step: 3
Training loss: 3.1043510296923182
Validation loss: 2.599624196999519

Epoch: 6| Step: 4
Training loss: 2.6149764556991872
Validation loss: 2.6081348793321153

Epoch: 6| Step: 5
Training loss: 2.8334472483754083
Validation loss: 2.6321755421954163

Epoch: 6| Step: 6
Training loss: 3.1525730583806832
Validation loss: 2.6203894002489885

Epoch: 6| Step: 7
Training loss: 2.801785383491042
Validation loss: 2.571365465419198

Epoch: 6| Step: 8
Training loss: 3.0734074259975293
Validation loss: 2.6539742301617566

Epoch: 6| Step: 9
Training loss: 3.4325667614983915
Validation loss: 2.6139346634705616

Epoch: 6| Step: 10
Training loss: 3.0975420282574517
Validation loss: 2.5981122371905343

Epoch: 6| Step: 11
Training loss: 3.0523596281600867
Validation loss: 2.634327915338074

Epoch: 6| Step: 12
Training loss: 3.3377641951900783
Validation loss: 2.5766567450714963

Epoch: 6| Step: 13
Training loss: 2.5513612517155173
Validation loss: 2.6145699701742724

Epoch: 69| Step: 0
Training loss: 2.3573442018065616
Validation loss: 2.6066491548740816

Epoch: 6| Step: 1
Training loss: 2.8497084351356374
Validation loss: 2.6193115480076945

Epoch: 6| Step: 2
Training loss: 3.0589775536453443
Validation loss: 2.6159802084724135

Epoch: 6| Step: 3
Training loss: 3.6411260824859624
Validation loss: 2.609125149069494

Epoch: 6| Step: 4
Training loss: 2.772965855858371
Validation loss: 2.6038036488830207

Epoch: 6| Step: 5
Training loss: 2.3122415140387877
Validation loss: 2.63656043011473

Epoch: 6| Step: 6
Training loss: 2.9186909508296828
Validation loss: 2.6364733923265065

Epoch: 6| Step: 7
Training loss: 3.2755003918138157
Validation loss: 2.640896700619591

Epoch: 6| Step: 8
Training loss: 3.61216278086195
Validation loss: 2.616269946770166

Epoch: 6| Step: 9
Training loss: 3.0416562502608633
Validation loss: 2.6151244528469695

Epoch: 6| Step: 10
Training loss: 2.012120830760257
Validation loss: 2.6040666929354166

Epoch: 6| Step: 11
Training loss: 3.1137973639991174
Validation loss: 2.6449501356685667

Epoch: 6| Step: 12
Training loss: 3.38466419171442
Validation loss: 2.6726357039718414

Epoch: 6| Step: 13
Training loss: 2.9265363913052216
Validation loss: 2.6262600018913793

Epoch: 70| Step: 0
Training loss: 2.7725961187984223
Validation loss: 2.6054061525694348

Epoch: 6| Step: 1
Training loss: 2.7004642511299535
Validation loss: 2.6410660379952717

Epoch: 6| Step: 2
Training loss: 2.940617307354942
Validation loss: 2.6175816353812422

Epoch: 6| Step: 3
Training loss: 3.2315232240720917
Validation loss: 2.615629486363589

Epoch: 6| Step: 4
Training loss: 2.507110021963824
Validation loss: 2.6304676691158924

Epoch: 6| Step: 5
Training loss: 3.7733957987311424
Validation loss: 2.5984036205889174

Epoch: 6| Step: 6
Training loss: 3.034275707816434
Validation loss: 2.6053876145148767

Epoch: 6| Step: 7
Training loss: 2.418820627053729
Validation loss: 2.581163025304221

Epoch: 6| Step: 8
Training loss: 2.647725687610689
Validation loss: 2.632007564316997

Epoch: 6| Step: 9
Training loss: 3.013588331230222
Validation loss: 2.598497237434521

Epoch: 6| Step: 10
Training loss: 2.794110684932385
Validation loss: 2.5999307045012365

Epoch: 6| Step: 11
Training loss: 2.896958953398087
Validation loss: 2.6249203227930686

Epoch: 6| Step: 12
Training loss: 2.8501466345291555
Validation loss: 2.604222536205546

Epoch: 6| Step: 13
Training loss: 3.625710910935975
Validation loss: 2.5939211659811625

Epoch: 71| Step: 0
Training loss: 2.5109468166745814
Validation loss: 2.620957184889414

Epoch: 6| Step: 1
Training loss: 2.48225657995487
Validation loss: 2.576893105128979

Epoch: 6| Step: 2
Training loss: 3.116211243536494
Validation loss: 2.5777901221611415

Epoch: 6| Step: 3
Training loss: 3.1358469586494953
Validation loss: 2.6038255250686624

Epoch: 6| Step: 4
Training loss: 3.065403087800729
Validation loss: 2.5974548809526024

Epoch: 6| Step: 5
Training loss: 2.8277056472695485
Validation loss: 2.622867340984892

Epoch: 6| Step: 6
Training loss: 2.6929583454954757
Validation loss: 2.6010311724391255

Epoch: 6| Step: 7
Training loss: 2.169992632875374
Validation loss: 2.629609535175878

Epoch: 6| Step: 8
Training loss: 2.7929812130950076
Validation loss: 2.5558820173850463

Epoch: 6| Step: 9
Training loss: 3.1077918234665223
Validation loss: 2.6070039904731632

Epoch: 6| Step: 10
Training loss: 3.038619845202698
Validation loss: 2.618619319682014

Epoch: 6| Step: 11
Training loss: 3.2767329050265586
Validation loss: 2.6274432986534655

Epoch: 6| Step: 12
Training loss: 2.8796041359635525
Validation loss: 2.593673467711614

Epoch: 6| Step: 13
Training loss: 4.202817317095629
Validation loss: 2.615998406867362

Epoch: 72| Step: 0
Training loss: 3.3723149391792027
Validation loss: 2.622862904475846

Epoch: 6| Step: 1
Training loss: 3.3531934064587094
Validation loss: 2.5855194181113337

Epoch: 6| Step: 2
Training loss: 2.412840895212096
Validation loss: 2.6308897815587353

Epoch: 6| Step: 3
Training loss: 2.4680288686068597
Validation loss: 2.6224290491887223

Epoch: 6| Step: 4
Training loss: 3.02886648951447
Validation loss: 2.6369306304644553

Epoch: 6| Step: 5
Training loss: 2.5956713442726196
Validation loss: 2.618967880899124

Epoch: 6| Step: 6
Training loss: 3.8168989974248686
Validation loss: 2.6020012533313435

Epoch: 6| Step: 7
Training loss: 3.0344375682473386
Validation loss: 2.6248309642083125

Epoch: 6| Step: 8
Training loss: 2.0390309298471996
Validation loss: 2.6171511313749574

Epoch: 6| Step: 9
Training loss: 2.931520910696957
Validation loss: 2.5965886994979477

Epoch: 6| Step: 10
Training loss: 2.2774965944903274
Validation loss: 2.6179218386655823

Epoch: 6| Step: 11
Training loss: 2.284108813598244
Validation loss: 2.5761653409306224

Epoch: 6| Step: 12
Training loss: 3.4340656116862722
Validation loss: 2.5793591620144376

Epoch: 6| Step: 13
Training loss: 3.5695355193859206
Validation loss: 2.6320132350832606

Epoch: 73| Step: 0
Training loss: 2.636778428144082
Validation loss: 2.607176202760233

Epoch: 6| Step: 1
Training loss: 2.6030357244782785
Validation loss: 2.6312648669204712

Epoch: 6| Step: 2
Training loss: 3.2894030324476033
Validation loss: 2.586782362723542

Epoch: 6| Step: 3
Training loss: 2.110026393201015
Validation loss: 2.611186538801898

Epoch: 6| Step: 4
Training loss: 3.5768526305399537
Validation loss: 2.597547115723046

Epoch: 6| Step: 5
Training loss: 2.387170327478498
Validation loss: 2.6062564607696905

Epoch: 6| Step: 6
Training loss: 3.0978349631711195
Validation loss: 2.5818249952983376

Epoch: 6| Step: 7
Training loss: 2.744239148309198
Validation loss: 2.60889906236593

Epoch: 6| Step: 8
Training loss: 2.6021481333091563
Validation loss: 2.6223145502765

Epoch: 6| Step: 9
Training loss: 3.668377708248699
Validation loss: 2.6231618823989553

Epoch: 6| Step: 10
Training loss: 3.3400793159798066
Validation loss: 2.6164319596670658

Epoch: 6| Step: 11
Training loss: 2.6759560632334676
Validation loss: 2.574002595784695

Epoch: 6| Step: 12
Training loss: 2.209053881670618
Validation loss: 2.594407515316317

Epoch: 6| Step: 13
Training loss: 4.0035403796251465
Validation loss: 2.607947882015451

Epoch: 74| Step: 0
Training loss: 2.768435155047457
Validation loss: 2.602856809593841

Epoch: 6| Step: 1
Training loss: 3.3157849128551553
Validation loss: 2.5802997941237518

Epoch: 6| Step: 2
Training loss: 3.0134231355952363
Validation loss: 2.570867519484097

Epoch: 6| Step: 3
Training loss: 3.20294278254572
Validation loss: 2.569400537672407

Epoch: 6| Step: 4
Training loss: 3.556990797389676
Validation loss: 2.6262283517801452

Epoch: 6| Step: 5
Training loss: 2.8580689496104776
Validation loss: 2.6195021489153523

Epoch: 6| Step: 6
Training loss: 2.4588422302417485
Validation loss: 2.5955831615312017

Epoch: 6| Step: 7
Training loss: 3.2810908687696436
Validation loss: 2.6153062298999266

Epoch: 6| Step: 8
Training loss: 3.1071198686522905
Validation loss: 2.6021063614091022

Epoch: 6| Step: 9
Training loss: 2.7247612804876193
Validation loss: 2.623058579743839

Epoch: 6| Step: 10
Training loss: 3.271730255452139
Validation loss: 2.5521451686845853

Epoch: 6| Step: 11
Training loss: 2.25690882988894
Validation loss: 2.6219649829730916

Epoch: 6| Step: 12
Training loss: 1.8958367637631188
Validation loss: 2.61498015854852

Epoch: 6| Step: 13
Training loss: 2.951938289793343
Validation loss: 2.6081436795809325

Epoch: 75| Step: 0
Training loss: 1.9911492727776976
Validation loss: 2.649306516482706

Epoch: 6| Step: 1
Training loss: 3.5659814521020494
Validation loss: 2.6077060393602873

Epoch: 6| Step: 2
Training loss: 2.4511347186551338
Validation loss: 2.541939634179239

Epoch: 6| Step: 3
Training loss: 2.8118505787769315
Validation loss: 2.586695146531801

Epoch: 6| Step: 4
Training loss: 2.6514346288038695
Validation loss: 2.5848505352736266

Epoch: 6| Step: 5
Training loss: 3.1020362934126697
Validation loss: 2.604557185927632

Epoch: 6| Step: 6
Training loss: 3.423146747480329
Validation loss: 2.605799730390018

Epoch: 6| Step: 7
Training loss: 2.988366458650365
Validation loss: 2.588555664993902

Epoch: 6| Step: 8
Training loss: 3.0853848892076305
Validation loss: 2.613948499985631

Epoch: 6| Step: 9
Training loss: 2.2762033738247625
Validation loss: 2.5546163585619635

Epoch: 6| Step: 10
Training loss: 2.8107666608328
Validation loss: 2.589252108926608

Epoch: 6| Step: 11
Training loss: 3.105435583549306
Validation loss: 2.586660458244702

Epoch: 6| Step: 12
Training loss: 3.1266450748091197
Validation loss: 2.598427627936703

Epoch: 6| Step: 13
Training loss: 3.214986285807784
Validation loss: 2.610927305499105

Epoch: 76| Step: 0
Training loss: 2.526742760544949
Validation loss: 2.636912896389262

Epoch: 6| Step: 1
Training loss: 1.9154405265463306
Validation loss: 2.6084794527990613

Epoch: 6| Step: 2
Training loss: 2.858942551560377
Validation loss: 2.5818085171279783

Epoch: 6| Step: 3
Training loss: 3.4919343382964168
Validation loss: 2.5610210914170475

Epoch: 6| Step: 4
Training loss: 3.0481326906452537
Validation loss: 2.6019146014679158

Epoch: 6| Step: 5
Training loss: 2.5236037822536024
Validation loss: 2.5891070945585115

Epoch: 6| Step: 6
Training loss: 2.7115571031278227
Validation loss: 2.6298583914029496

Epoch: 6| Step: 7
Training loss: 2.9542595838417287
Validation loss: 2.5802077337017555

Epoch: 6| Step: 8
Training loss: 2.5645250831845483
Validation loss: 2.609198436740608

Epoch: 6| Step: 9
Training loss: 3.2327784039122243
Validation loss: 2.620201446895663

Epoch: 6| Step: 10
Training loss: 2.2651480337108265
Validation loss: 2.542901879921806

Epoch: 6| Step: 11
Training loss: 3.50030489002317
Validation loss: 2.6166464988297573

Epoch: 6| Step: 12
Training loss: 3.4234151640128125
Validation loss: 2.6131798984989327

Epoch: 6| Step: 13
Training loss: 4.00955465721498
Validation loss: 2.584840984274606

Epoch: 77| Step: 0
Training loss: 3.4295089779491734
Validation loss: 2.57756315580821

Epoch: 6| Step: 1
Training loss: 3.2823156170509447
Validation loss: 2.6128219602362486

Epoch: 6| Step: 2
Training loss: 2.2175350892603323
Validation loss: 2.5762304719049065

Epoch: 6| Step: 3
Training loss: 3.054023690062487
Validation loss: 2.6145217830085703

Epoch: 6| Step: 4
Training loss: 3.4584181595169574
Validation loss: 2.613137270872004

Epoch: 6| Step: 5
Training loss: 2.8986623836171015
Validation loss: 2.611989480507413

Epoch: 6| Step: 6
Training loss: 3.10781437800424
Validation loss: 2.630758086779459

Epoch: 6| Step: 7
Training loss: 2.8819012946354503
Validation loss: 2.565395041443848

Epoch: 6| Step: 8
Training loss: 2.6953138268508963
Validation loss: 2.620822167972303

Epoch: 6| Step: 9
Training loss: 2.520918116969653
Validation loss: 2.6120476448993166

Epoch: 6| Step: 10
Training loss: 2.819316825630147
Validation loss: 2.58982416064901

Epoch: 6| Step: 11
Training loss: 2.209556660609565
Validation loss: 2.6119992688853304

Epoch: 6| Step: 12
Training loss: 2.3319486414912176
Validation loss: 2.5816493551286253

Epoch: 6| Step: 13
Training loss: 3.503985451916319
Validation loss: 2.6200109585051665

Epoch: 78| Step: 0
Training loss: 2.3710411606413166
Validation loss: 2.5528755235897895

Epoch: 6| Step: 1
Training loss: 2.6644103418843326
Validation loss: 2.602200859782094

Epoch: 6| Step: 2
Training loss: 2.9771266612874623
Validation loss: 2.573130619924145

Epoch: 6| Step: 3
Training loss: 3.0686201328371228
Validation loss: 2.6188899065184708

Epoch: 6| Step: 4
Training loss: 2.630059407364611
Validation loss: 2.5691633940106535

Epoch: 6| Step: 5
Training loss: 2.3713750782315555
Validation loss: 2.5859753128497744

Epoch: 6| Step: 6
Training loss: 2.4159701319168265
Validation loss: 2.6425682044462424

Epoch: 6| Step: 7
Training loss: 3.3355858503549105
Validation loss: 2.6291233654430544

Epoch: 6| Step: 8
Training loss: 3.21364952330944
Validation loss: 2.6137277219396338

Epoch: 6| Step: 9
Training loss: 3.349122197170051
Validation loss: 2.6353939460249376

Epoch: 6| Step: 10
Training loss: 2.723715446151452
Validation loss: 2.587214330005433

Epoch: 6| Step: 11
Training loss: 3.0004323012093814
Validation loss: 2.6012620447847588

Epoch: 6| Step: 12
Training loss: 2.9631751470178567
Validation loss: 2.604209701346578

Epoch: 6| Step: 13
Training loss: 3.4145110859112093
Validation loss: 2.632323988420836

Epoch: 79| Step: 0
Training loss: 3.404810049889726
Validation loss: 2.591378655158542

Epoch: 6| Step: 1
Training loss: 2.2698229603902798
Validation loss: 2.5851508550321394

Epoch: 6| Step: 2
Training loss: 3.425044016311597
Validation loss: 2.6375719840638583

Epoch: 6| Step: 3
Training loss: 2.9851991803602216
Validation loss: 2.5747890254964996

Epoch: 6| Step: 4
Training loss: 3.483912689604058
Validation loss: 2.6046036518943736

Epoch: 6| Step: 5
Training loss: 2.4388201146529322
Validation loss: 2.5667667687287152

Epoch: 6| Step: 6
Training loss: 2.8258180429743724
Validation loss: 2.5865253280643135

Epoch: 6| Step: 7
Training loss: 3.1127376297164266
Validation loss: 2.5959934841442514

Epoch: 6| Step: 8
Training loss: 3.1753035933357734
Validation loss: 2.6400224085851463

Epoch: 6| Step: 9
Training loss: 2.375713241291169
Validation loss: 2.5730143656338087

Epoch: 6| Step: 10
Training loss: 3.1172086098321867
Validation loss: 2.6087622391866336

Epoch: 6| Step: 11
Training loss: 1.6935685148522635
Validation loss: 2.6470677925467023

Epoch: 6| Step: 12
Training loss: 2.9992519081709346
Validation loss: 2.5779120642268696

Epoch: 6| Step: 13
Training loss: 3.3643128057007496
Validation loss: 2.5942576317245676

Epoch: 80| Step: 0
Training loss: 2.636046463772496
Validation loss: 2.6152922701948222

Epoch: 6| Step: 1
Training loss: 3.7549027500689798
Validation loss: 2.6172851975262876

Epoch: 6| Step: 2
Training loss: 2.788863145558297
Validation loss: 2.5961646513200884

Epoch: 6| Step: 3
Training loss: 2.9464575365632726
Validation loss: 2.5930670046415214

Epoch: 6| Step: 4
Training loss: 2.536460129713066
Validation loss: 2.602801560152716

Epoch: 6| Step: 5
Training loss: 3.1630530736946665
Validation loss: 2.656138179000954

Epoch: 6| Step: 6
Training loss: 2.8161196834045503
Validation loss: 2.5952272583201093

Epoch: 6| Step: 7
Training loss: 2.9066311165913388
Validation loss: 2.5917082231229527

Epoch: 6| Step: 8
Training loss: 2.957456933527837
Validation loss: 2.574071911680201

Epoch: 6| Step: 9
Training loss: 2.767925103403587
Validation loss: 2.643708280095845

Epoch: 6| Step: 10
Training loss: 3.113562136893666
Validation loss: 2.606367636270196

Epoch: 6| Step: 11
Training loss: 2.6234631353674165
Validation loss: 2.574414759729871

Epoch: 6| Step: 12
Training loss: 2.4747650651497297
Validation loss: 2.613466006835257

Epoch: 6| Step: 13
Training loss: 2.774617548525991
Validation loss: 2.5816958242772143

Epoch: 81| Step: 0
Training loss: 3.397340373821938
Validation loss: 2.5656068047792884

Epoch: 6| Step: 1
Training loss: 2.7256718358575576
Validation loss: 2.5900566421775384

Epoch: 6| Step: 2
Training loss: 2.422427009923767
Validation loss: 2.6092094421428014

Epoch: 6| Step: 3
Training loss: 2.372038952937006
Validation loss: 2.5597341063249375

Epoch: 6| Step: 4
Training loss: 2.8297839278374366
Validation loss: 2.5914665268999535

Epoch: 6| Step: 5
Training loss: 3.36140487024714
Validation loss: 2.597734857788966

Epoch: 6| Step: 6
Training loss: 3.3779685069773606
Validation loss: 2.603905037483998

Epoch: 6| Step: 7
Training loss: 2.5319768544927523
Validation loss: 2.5629030536459574

Epoch: 6| Step: 8
Training loss: 2.105272726300731
Validation loss: 2.5851185865774364

Epoch: 6| Step: 9
Training loss: 3.127012901521082
Validation loss: 2.578872603095157

Epoch: 6| Step: 10
Training loss: 2.9497339872262973
Validation loss: 2.599435912863622

Epoch: 6| Step: 11
Training loss: 2.8827584114272886
Validation loss: 2.5966916572117738

Epoch: 6| Step: 12
Training loss: 2.736225482940624
Validation loss: 2.5577551569560137

Epoch: 6| Step: 13
Training loss: 4.23225129984781
Validation loss: 2.60315853827495

Epoch: 82| Step: 0
Training loss: 3.0611388626579177
Validation loss: 2.600004463333956

Epoch: 6| Step: 1
Training loss: 3.7302008248027847
Validation loss: 2.623447404400922

Epoch: 6| Step: 2
Training loss: 3.16448112826688
Validation loss: 2.6164385773843315

Epoch: 6| Step: 3
Training loss: 3.0783477547691054
Validation loss: 2.612277650337658

Epoch: 6| Step: 4
Training loss: 2.4667367572964416
Validation loss: 2.5945028494158207

Epoch: 6| Step: 5
Training loss: 3.062060889079075
Validation loss: 2.589666439172166

Epoch: 6| Step: 6
Training loss: 2.2842686160008387
Validation loss: 2.570447372447194

Epoch: 6| Step: 7
Training loss: 2.4759983900431637
Validation loss: 2.5832793249649937

Epoch: 6| Step: 8
Training loss: 2.8074862401528278
Validation loss: 2.6195645993646757

Epoch: 6| Step: 9
Training loss: 2.187751101659533
Validation loss: 2.5816391656858104

Epoch: 6| Step: 10
Training loss: 3.3989403363631214
Validation loss: 2.5786970203140784

Epoch: 6| Step: 11
Training loss: 2.6168864973830153
Validation loss: 2.5914285893949396

Epoch: 6| Step: 12
Training loss: 3.0889655214252087
Validation loss: 2.6057653357790023

Epoch: 6| Step: 13
Training loss: 3.2969425429526007
Validation loss: 2.6313445634310177

Epoch: 83| Step: 0
Training loss: 2.612828784312901
Validation loss: 2.60455111973883

Epoch: 6| Step: 1
Training loss: 2.467644069527802
Validation loss: 2.6115692739330334

Epoch: 6| Step: 2
Training loss: 2.7097158180246734
Validation loss: 2.5579941534920843

Epoch: 6| Step: 3
Training loss: 2.8688981360790335
Validation loss: 2.6154137154671835

Epoch: 6| Step: 4
Training loss: 2.824632205483121
Validation loss: 2.581348950768457

Epoch: 6| Step: 5
Training loss: 3.1485362451559213
Validation loss: 2.60649402666494

Epoch: 6| Step: 6
Training loss: 3.176578135529338
Validation loss: 2.5698123039611644

Epoch: 6| Step: 7
Training loss: 3.1657749392820906
Validation loss: 2.651916153374791

Epoch: 6| Step: 8
Training loss: 2.2610493725224425
Validation loss: 2.596182259866125

Epoch: 6| Step: 9
Training loss: 3.2241612844520016
Validation loss: 2.599094122388314

Epoch: 6| Step: 10
Training loss: 2.9948614936096396
Validation loss: 2.620163484174377

Epoch: 6| Step: 11
Training loss: 2.776309307620826
Validation loss: 2.583026506209097

Epoch: 6| Step: 12
Training loss: 2.806023154828657
Validation loss: 2.6150314900684837

Epoch: 6| Step: 13
Training loss: 3.529562487843333
Validation loss: 2.6282909739720126

Epoch: 84| Step: 0
Training loss: 2.9198622681520487
Validation loss: 2.576020066554655

Epoch: 6| Step: 1
Training loss: 2.374820602066247
Validation loss: 2.589241742469401

Epoch: 6| Step: 2
Training loss: 2.1936724092069935
Validation loss: 2.61776970338534

Epoch: 6| Step: 3
Training loss: 2.553930701287241
Validation loss: 2.580830132997673

Epoch: 6| Step: 4
Training loss: 2.8422914893874855
Validation loss: 2.6250076899340176

Epoch: 6| Step: 5
Training loss: 2.7556493126222126
Validation loss: 2.589597895107795

Epoch: 6| Step: 6
Training loss: 3.1542249169423786
Validation loss: 2.5851963816370453

Epoch: 6| Step: 7
Training loss: 2.8501474710424115
Validation loss: 2.575494442827393

Epoch: 6| Step: 8
Training loss: 2.7524515841710215
Validation loss: 2.52951384951287

Epoch: 6| Step: 9
Training loss: 2.8307806371216633
Validation loss: 2.5686286532136036

Epoch: 6| Step: 10
Training loss: 2.5316361497752067
Validation loss: 2.5848373721430375

Epoch: 6| Step: 11
Training loss: 3.807058359382688
Validation loss: 2.570844016630732

Epoch: 6| Step: 12
Training loss: 3.453421049243688
Validation loss: 2.641417180956468

Epoch: 6| Step: 13
Training loss: 3.9366878095721765
Validation loss: 2.5420376681541352

Epoch: 85| Step: 0
Training loss: 2.7664897881310266
Validation loss: 2.580940609857528

Epoch: 6| Step: 1
Training loss: 2.162264410868228
Validation loss: 2.6306350163729375

Epoch: 6| Step: 2
Training loss: 3.306484878936946
Validation loss: 2.586880055003741

Epoch: 6| Step: 3
Training loss: 2.5757274229831317
Validation loss: 2.584645697782801

Epoch: 6| Step: 4
Training loss: 2.6152631830704216
Validation loss: 2.550548465770747

Epoch: 6| Step: 5
Training loss: 3.0371947837669246
Validation loss: 2.5771785596098806

Epoch: 6| Step: 6
Training loss: 3.3014035332425875
Validation loss: 2.5678891683599963

Epoch: 6| Step: 7
Training loss: 3.2413852664307847
Validation loss: 2.5578343465324376

Epoch: 6| Step: 8
Training loss: 2.8459812675068683
Validation loss: 2.5939194205962433

Epoch: 6| Step: 9
Training loss: 2.959964481604609
Validation loss: 2.5744836482887314

Epoch: 6| Step: 10
Training loss: 2.8176384504093748
Validation loss: 2.596295169163266

Epoch: 6| Step: 11
Training loss: 2.3791838485533825
Validation loss: 2.616128002826226

Epoch: 6| Step: 12
Training loss: 3.3809779877463693
Validation loss: 2.6333617912391363

Epoch: 6| Step: 13
Training loss: 3.5383177388357128
Validation loss: 2.597127798285259

Epoch: 86| Step: 0
Training loss: 3.10457958231619
Validation loss: 2.6454344240333385

Epoch: 6| Step: 1
Training loss: 3.49172089806976
Validation loss: 2.640527161165913

Epoch: 6| Step: 2
Training loss: 2.0744080537953766
Validation loss: 2.6451707665531043

Epoch: 6| Step: 3
Training loss: 3.368809709745214
Validation loss: 2.59330023196729

Epoch: 6| Step: 4
Training loss: 3.054653157775305
Validation loss: 2.5872935235659837

Epoch: 6| Step: 5
Training loss: 2.7827180566884637
Validation loss: 2.544545036769553

Epoch: 6| Step: 6
Training loss: 2.438183419692112
Validation loss: 2.570169879202904

Epoch: 6| Step: 7
Training loss: 2.795914127946717
Validation loss: 2.6484774541362426

Epoch: 6| Step: 8
Training loss: 2.3060736157130037
Validation loss: 2.590527054839987

Epoch: 6| Step: 9
Training loss: 2.7187703449759604
Validation loss: 2.595785984369967

Epoch: 6| Step: 10
Training loss: 2.9058481574402886
Validation loss: 2.6165052812564613

Epoch: 6| Step: 11
Training loss: 3.2638244045371594
Validation loss: 2.6297812137085255

Epoch: 6| Step: 12
Training loss: 2.666579771612926
Validation loss: 2.5996901543656934

Epoch: 6| Step: 13
Training loss: 2.765364122748445
Validation loss: 2.5697103803044756

Epoch: 87| Step: 0
Training loss: 2.7867308201166185
Validation loss: 2.611604669450478

Epoch: 6| Step: 1
Training loss: 2.58383129816919
Validation loss: 2.6477315861376507

Epoch: 6| Step: 2
Training loss: 2.087120834910284
Validation loss: 2.601718460261904

Epoch: 6| Step: 3
Training loss: 2.779389005247858
Validation loss: 2.565673273939458

Epoch: 6| Step: 4
Training loss: 2.6594291062908066
Validation loss: 2.6292498944081872

Epoch: 6| Step: 5
Training loss: 2.5370328802098947
Validation loss: 2.617859813210219

Epoch: 6| Step: 6
Training loss: 3.2053897945564103
Validation loss: 2.6026873649988578

Epoch: 6| Step: 7
Training loss: 3.2361713525697864
Validation loss: 2.601447441387123

Epoch: 6| Step: 8
Training loss: 3.0093958266697234
Validation loss: 2.606964164805263

Epoch: 6| Step: 9
Training loss: 3.1616052198563858
Validation loss: 2.567981185215854

Epoch: 6| Step: 10
Training loss: 3.498415724638434
Validation loss: 2.5806624538216547

Epoch: 6| Step: 11
Training loss: 2.2797807116208815
Validation loss: 2.597247218594342

Epoch: 6| Step: 12
Training loss: 3.501472163535178
Validation loss: 2.5895434438569

Epoch: 6| Step: 13
Training loss: 2.6858708078782474
Validation loss: 2.5655826391990435

Epoch: 88| Step: 0
Training loss: 2.829663948622484
Validation loss: 2.6236399014407286

Epoch: 6| Step: 1
Training loss: 2.701284498623735
Validation loss: 2.5565034347317317

Epoch: 6| Step: 2
Training loss: 2.946203931691881
Validation loss: 2.602796535895891

Epoch: 6| Step: 3
Training loss: 3.558008541557948
Validation loss: 2.6149977678439105

Epoch: 6| Step: 4
Training loss: 2.9882981642699415
Validation loss: 2.606913001416134

Epoch: 6| Step: 5
Training loss: 2.3631944876893876
Validation loss: 2.6222536317910374

Epoch: 6| Step: 6
Training loss: 2.8154065689900203
Validation loss: 2.580919934297089

Epoch: 6| Step: 7
Training loss: 2.5566857598431922
Validation loss: 2.5921598557178633

Epoch: 6| Step: 8
Training loss: 2.3909893880151527
Validation loss: 2.57902586390909

Epoch: 6| Step: 9
Training loss: 3.6139438001087174
Validation loss: 2.5494078892751

Epoch: 6| Step: 10
Training loss: 2.79199526167197
Validation loss: 2.5943447824216226

Epoch: 6| Step: 11
Training loss: 2.5818316083820276
Validation loss: 2.5672795291833705

Epoch: 6| Step: 12
Training loss: 2.649896900402669
Validation loss: 2.5617847660002564

Epoch: 6| Step: 13
Training loss: 3.5833169507975495
Validation loss: 2.5728731132196487

Epoch: 89| Step: 0
Training loss: 3.1953562241526305
Validation loss: 2.584897740295296

Epoch: 6| Step: 1
Training loss: 2.865707140029237
Validation loss: 2.62026982243542

Epoch: 6| Step: 2
Training loss: 2.283315794475978
Validation loss: 2.589633976028961

Epoch: 6| Step: 3
Training loss: 3.43471400329399
Validation loss: 2.595188167658225

Epoch: 6| Step: 4
Training loss: 2.7636472020210485
Validation loss: 2.5911146559776888

Epoch: 6| Step: 5
Training loss: 2.658951227332592
Validation loss: 2.618893005725287

Epoch: 6| Step: 6
Training loss: 3.323380361190468
Validation loss: 2.5926914320848278

Epoch: 6| Step: 7
Training loss: 2.229975390277089
Validation loss: 2.6237489929495887

Epoch: 6| Step: 8
Training loss: 2.727021711530939
Validation loss: 2.598859141255852

Epoch: 6| Step: 9
Training loss: 2.8410672119525846
Validation loss: 2.5896541607915604

Epoch: 6| Step: 10
Training loss: 3.4094147984937937
Validation loss: 2.5528865107027827

Epoch: 6| Step: 11
Training loss: 2.8620914417536474
Validation loss: 2.6025076686504254

Epoch: 6| Step: 12
Training loss: 2.632759252173891
Validation loss: 2.6035217251113183

Epoch: 6| Step: 13
Training loss: 2.7047611643050145
Validation loss: 2.614575074761364

Epoch: 90| Step: 0
Training loss: 3.2922728901757567
Validation loss: 2.6356017241379512

Epoch: 6| Step: 1
Training loss: 2.7283238184473055
Validation loss: 2.5744777761185667

Epoch: 6| Step: 2
Training loss: 3.4806210947999507
Validation loss: 2.5562045792957764

Epoch: 6| Step: 3
Training loss: 2.3798349255928004
Validation loss: 2.60549680657804

Epoch: 6| Step: 4
Training loss: 2.577610126292431
Validation loss: 2.5900282763053615

Epoch: 6| Step: 5
Training loss: 3.5026910518188994
Validation loss: 2.5461920849292903

Epoch: 6| Step: 6
Training loss: 1.935910834497487
Validation loss: 2.5840406488221337

Epoch: 6| Step: 7
Training loss: 2.2856665929859483
Validation loss: 2.5996986193188536

Epoch: 6| Step: 8
Training loss: 2.905232241041953
Validation loss: 2.575277337489999

Epoch: 6| Step: 9
Training loss: 2.9653123728997035
Validation loss: 2.621056827201784

Epoch: 6| Step: 10
Training loss: 3.315493400759307
Validation loss: 2.5634197972385624

Epoch: 6| Step: 11
Training loss: 3.78101417499701
Validation loss: 2.565276653727943

Epoch: 6| Step: 12
Training loss: 2.3061134194556767
Validation loss: 2.546091876939116

Epoch: 6| Step: 13
Training loss: 1.9461291946619768
Validation loss: 2.606351848351448

Epoch: 91| Step: 0
Training loss: 2.0966336334529276
Validation loss: 2.5967744188939816

Epoch: 6| Step: 1
Training loss: 2.7278632528928486
Validation loss: 2.623505318673805

Epoch: 6| Step: 2
Training loss: 2.940164372267256
Validation loss: 2.5527055723055465

Epoch: 6| Step: 3
Training loss: 2.2852190579643126
Validation loss: 2.579183254526223

Epoch: 6| Step: 4
Training loss: 3.015724931553435
Validation loss: 2.57635936368742

Epoch: 6| Step: 5
Training loss: 3.597021454879411
Validation loss: 2.5798791023632224

Epoch: 6| Step: 6
Training loss: 2.4595258266630795
Validation loss: 2.613224170120973

Epoch: 6| Step: 7
Training loss: 2.0284212810013096
Validation loss: 2.6008883652947934

Epoch: 6| Step: 8
Training loss: 3.065188103982033
Validation loss: 2.5345276991733487

Epoch: 6| Step: 9
Training loss: 3.019195340559396
Validation loss: 2.5698917385010507

Epoch: 6| Step: 10
Training loss: 3.522585882218831
Validation loss: 2.6130641780453563

Epoch: 6| Step: 11
Training loss: 3.1243778372360813
Validation loss: 2.62418149384193

Epoch: 6| Step: 12
Training loss: 3.041141377558087
Validation loss: 2.570953270318994

Epoch: 6| Step: 13
Training loss: 3.16481653341636
Validation loss: 2.6285005317425956

Epoch: 92| Step: 0
Training loss: 2.721087974172021
Validation loss: 2.5971015263241077

Epoch: 6| Step: 1
Training loss: 2.8094494700506836
Validation loss: 2.5482518626352184

Epoch: 6| Step: 2
Training loss: 2.463758226571557
Validation loss: 2.6195770301656176

Epoch: 6| Step: 3
Training loss: 2.9505893377222745
Validation loss: 2.5581864788793487

Epoch: 6| Step: 4
Training loss: 2.7586825027816384
Validation loss: 2.5848718111624374

Epoch: 6| Step: 5
Training loss: 3.195669438728151
Validation loss: 2.6224411340352214

Epoch: 6| Step: 6
Training loss: 2.742131594009216
Validation loss: 2.57199802533309

Epoch: 6| Step: 7
Training loss: 2.182253950304452
Validation loss: 2.6136131978932586

Epoch: 6| Step: 8
Training loss: 1.7847455176166118
Validation loss: 2.5929761454452502

Epoch: 6| Step: 9
Training loss: 3.184464149612304
Validation loss: 2.6128507183738696

Epoch: 6| Step: 10
Training loss: 3.9791595432290965
Validation loss: 2.624463474311987

Epoch: 6| Step: 11
Training loss: 3.2348741523991857
Validation loss: 2.5835439838923913

Epoch: 6| Step: 12
Training loss: 2.704652564111278
Validation loss: 2.586811618467937

Epoch: 6| Step: 13
Training loss: 2.9799383448936783
Validation loss: 2.5529046703155784

Epoch: 93| Step: 0
Training loss: 2.3282115331351836
Validation loss: 2.6042717053959192

Epoch: 6| Step: 1
Training loss: 3.265272349613563
Validation loss: 2.554263691881963

Epoch: 6| Step: 2
Training loss: 2.292358733206158
Validation loss: 2.544321826442235

Epoch: 6| Step: 3
Training loss: 3.1255999180016802
Validation loss: 2.5647437814060545

Epoch: 6| Step: 4
Training loss: 2.437689064714121
Validation loss: 2.58803331034009

Epoch: 6| Step: 5
Training loss: 2.999847885090042
Validation loss: 2.6137687725846717

Epoch: 6| Step: 6
Training loss: 2.9263307592694447
Validation loss: 2.604562322934166

Epoch: 6| Step: 7
Training loss: 2.911176054798763
Validation loss: 2.591759661443126

Epoch: 6| Step: 8
Training loss: 3.1268337210279538
Validation loss: 2.582912030303057

Epoch: 6| Step: 9
Training loss: 2.099809106597352
Validation loss: 2.5709015363650765

Epoch: 6| Step: 10
Training loss: 3.392616495762068
Validation loss: 2.584270263395423

Epoch: 6| Step: 11
Training loss: 2.9086779225414556
Validation loss: 2.5956924534429406

Epoch: 6| Step: 12
Training loss: 3.2968252458479137
Validation loss: 2.6030121230493295

Epoch: 6| Step: 13
Training loss: 2.873018826076118
Validation loss: 2.543931602132618

Epoch: 94| Step: 0
Training loss: 2.674360758615808
Validation loss: 2.5464681147725985

Epoch: 6| Step: 1
Training loss: 3.092474780585072
Validation loss: 2.6090883595312677

Epoch: 6| Step: 2
Training loss: 2.75356495142414
Validation loss: 2.558487382393835

Epoch: 6| Step: 3
Training loss: 1.99262116143977
Validation loss: 2.5641869425418298

Epoch: 6| Step: 4
Training loss: 3.1846980326945036
Validation loss: 2.588016761744207

Epoch: 6| Step: 5
Training loss: 2.5608653925949483
Validation loss: 2.561808072766535

Epoch: 6| Step: 6
Training loss: 3.181030139932608
Validation loss: 2.581445296451458

Epoch: 6| Step: 7
Training loss: 2.7414904629591716
Validation loss: 2.5655749699971304

Epoch: 6| Step: 8
Training loss: 3.4642694076806007
Validation loss: 2.5432100785914544

Epoch: 6| Step: 9
Training loss: 2.708102368018784
Validation loss: 2.5254259020983647

Epoch: 6| Step: 10
Training loss: 3.340102871664036
Validation loss: 2.5720125001049143

Epoch: 6| Step: 11
Training loss: 2.228216687813176
Validation loss: 2.565900052103108

Epoch: 6| Step: 12
Training loss: 3.153299898073823
Validation loss: 2.5633930507950358

Epoch: 6| Step: 13
Training loss: 2.941371071492409
Validation loss: 2.5662184557112293

Epoch: 95| Step: 0
Training loss: 3.6863212641168803
Validation loss: 2.6100939670869243

Epoch: 6| Step: 1
Training loss: 3.4253948346065477
Validation loss: 2.5755424792656094

Epoch: 6| Step: 2
Training loss: 2.327674770984456
Validation loss: 2.542299362006548

Epoch: 6| Step: 3
Training loss: 2.654131235058854
Validation loss: 2.588533371558229

Epoch: 6| Step: 4
Training loss: 2.780640010163017
Validation loss: 2.5738710635496216

Epoch: 6| Step: 5
Training loss: 3.074237052736971
Validation loss: 2.5674475621664463

Epoch: 6| Step: 6
Training loss: 3.3000103112261967
Validation loss: 2.5827044215330437

Epoch: 6| Step: 7
Training loss: 2.9620003516321276
Validation loss: 2.560508585506914

Epoch: 6| Step: 8
Training loss: 2.3239487435077333
Validation loss: 2.6316062335546473

Epoch: 6| Step: 9
Training loss: 2.7612150561158044
Validation loss: 2.591199369717939

Epoch: 6| Step: 10
Training loss: 2.83895536901873
Validation loss: 2.592628267083132

Epoch: 6| Step: 11
Training loss: 2.19313370179749
Validation loss: 2.5943754519165307

Epoch: 6| Step: 12
Training loss: 2.877583876778487
Validation loss: 2.5920119043337904

Epoch: 6| Step: 13
Training loss: 2.3668338524057404
Validation loss: 2.577875219073908

Epoch: 96| Step: 0
Training loss: 3.072469870634541
Validation loss: 2.6130591332963666

Epoch: 6| Step: 1
Training loss: 2.4455566284386854
Validation loss: 2.618444889499156

Epoch: 6| Step: 2
Training loss: 2.338511602014484
Validation loss: 2.6000870081523537

Epoch: 6| Step: 3
Training loss: 2.257712074871107
Validation loss: 2.5817264374919175

Epoch: 6| Step: 4
Training loss: 3.4388024376962063
Validation loss: 2.6002295024018682

Epoch: 6| Step: 5
Training loss: 2.4933914576944614
Validation loss: 2.6235226567463323

Epoch: 6| Step: 6
Training loss: 2.1143255844002278
Validation loss: 2.565212517854765

Epoch: 6| Step: 7
Training loss: 3.656587503620125
Validation loss: 2.5473274822007155

Epoch: 6| Step: 8
Training loss: 3.416325776997152
Validation loss: 2.5505188443268665

Epoch: 6| Step: 9
Training loss: 2.7993442993797184
Validation loss: 2.5814423350171136

Epoch: 6| Step: 10
Training loss: 3.2379094222125233
Validation loss: 2.555109930472372

Epoch: 6| Step: 11
Training loss: 2.6326379010633487
Validation loss: 2.6237326813474047

Epoch: 6| Step: 12
Training loss: 2.764233945162541
Validation loss: 2.606764523809126

Epoch: 6| Step: 13
Training loss: 3.085534950751978
Validation loss: 2.562624650430063

Epoch: 97| Step: 0
Training loss: 3.0017355031520996
Validation loss: 2.5810180997685435

Epoch: 6| Step: 1
Training loss: 3.6672401557721064
Validation loss: 2.6093646054143433

Epoch: 6| Step: 2
Training loss: 2.4723991754569674
Validation loss: 2.5424654048691933

Epoch: 6| Step: 3
Training loss: 2.8715645540325356
Validation loss: 2.59256948803651

Epoch: 6| Step: 4
Training loss: 2.4495345160035558
Validation loss: 2.580134614181658

Epoch: 6| Step: 5
Training loss: 2.892068203650784
Validation loss: 2.5722858433984634

Epoch: 6| Step: 6
Training loss: 2.7239996552600165
Validation loss: 2.540187006241523

Epoch: 6| Step: 7
Training loss: 3.183520656752938
Validation loss: 2.542707032283172

Epoch: 6| Step: 8
Training loss: 3.3908045848628685
Validation loss: 2.559332669176361

Epoch: 6| Step: 9
Training loss: 2.141819752764578
Validation loss: 2.584672535746796

Epoch: 6| Step: 10
Training loss: 2.193971380382669
Validation loss: 2.5955517773802783

Epoch: 6| Step: 11
Training loss: 3.0476938565615073
Validation loss: 2.5930565624790693

Epoch: 6| Step: 12
Training loss: 3.0212378570855547
Validation loss: 2.589464313165475

Epoch: 6| Step: 13
Training loss: 2.5607661452346315
Validation loss: 2.594310586747453

Epoch: 98| Step: 0
Training loss: 3.175400151545711
Validation loss: 2.560014251909975

Epoch: 6| Step: 1
Training loss: 2.5790357426048405
Validation loss: 2.6106328478956056

Epoch: 6| Step: 2
Training loss: 3.0542269698604345
Validation loss: 2.5976845246820246

Epoch: 6| Step: 3
Training loss: 2.466894394010897
Validation loss: 2.5314247560203

Epoch: 6| Step: 4
Training loss: 3.097064006130459
Validation loss: 2.581009808953863

Epoch: 6| Step: 5
Training loss: 2.487931974082071
Validation loss: 2.5872456944054485

Epoch: 6| Step: 6
Training loss: 2.3232984243403774
Validation loss: 2.6015871739001932

Epoch: 6| Step: 7
Training loss: 2.459287641396386
Validation loss: 2.552779421742445

Epoch: 6| Step: 8
Training loss: 3.3395059336646558
Validation loss: 2.541735164204157

Epoch: 6| Step: 9
Training loss: 4.420470968502567
Validation loss: 2.5923786395218182

Epoch: 6| Step: 10
Training loss: 2.1814867475947777
Validation loss: 2.533725826628252

Epoch: 6| Step: 11
Training loss: 3.0652515740007478
Validation loss: 2.5818093482379743

Epoch: 6| Step: 12
Training loss: 2.544858356423841
Validation loss: 2.5920377679758677

Epoch: 6| Step: 13
Training loss: 2.5796568047899835
Validation loss: 2.563062810131584

Epoch: 99| Step: 0
Training loss: 2.494840256464016
Validation loss: 2.5938845027678172

Epoch: 6| Step: 1
Training loss: 1.823150648813488
Validation loss: 2.5719778460375555

Epoch: 6| Step: 2
Training loss: 2.573763585696276
Validation loss: 2.604446833808802

Epoch: 6| Step: 3
Training loss: 3.1833782099677936
Validation loss: 2.584608447718727

Epoch: 6| Step: 4
Training loss: 3.004075778498103
Validation loss: 2.5807641207671814

Epoch: 6| Step: 5
Training loss: 2.7489436461555137
Validation loss: 2.5666733579331322

Epoch: 6| Step: 6
Training loss: 3.0734040127099784
Validation loss: 2.6059567877689758

Epoch: 6| Step: 7
Training loss: 3.1496806754882223
Validation loss: 2.552566740366647

Epoch: 6| Step: 8
Training loss: 2.5325443114069106
Validation loss: 2.594212605072555

Epoch: 6| Step: 9
Training loss: 3.1243145000096746
Validation loss: 2.5321872545307422

Epoch: 6| Step: 10
Training loss: 2.688157821699692
Validation loss: 2.586537455775933

Epoch: 6| Step: 11
Training loss: 3.631872436963675
Validation loss: 2.5623458117605673

Epoch: 6| Step: 12
Training loss: 3.002701179059871
Validation loss: 2.5591157504869857

Epoch: 6| Step: 13
Training loss: 2.4900605025083915
Validation loss: 2.575849703551098

Epoch: 100| Step: 0
Training loss: 1.9705143848543631
Validation loss: 2.579165465315394

Epoch: 6| Step: 1
Training loss: 3.138701955654704
Validation loss: 2.5478905734657933

Epoch: 6| Step: 2
Training loss: 2.5696646850864644
Validation loss: 2.649257883139279

Epoch: 6| Step: 3
Training loss: 2.3555212821606326
Validation loss: 2.604600367373833

Epoch: 6| Step: 4
Training loss: 3.2725681798490087
Validation loss: 2.5561212071120414

Epoch: 6| Step: 5
Training loss: 3.2370357165789376
Validation loss: 2.5919801792324786

Epoch: 6| Step: 6
Training loss: 2.5601510237313625
Validation loss: 2.560609459762366

Epoch: 6| Step: 7
Training loss: 3.082384289923403
Validation loss: 2.622545441483544

Epoch: 6| Step: 8
Training loss: 2.810822049919467
Validation loss: 2.559257612952444

Epoch: 6| Step: 9
Training loss: 3.6624348813670267
Validation loss: 2.6109566716682737

Epoch: 6| Step: 10
Training loss: 2.651429413404237
Validation loss: 2.512342506165733

Epoch: 6| Step: 11
Training loss: 2.503673143887952
Validation loss: 2.602603222194402

Epoch: 6| Step: 12
Training loss: 2.6531308878371616
Validation loss: 2.5637502514068626

Epoch: 6| Step: 13
Training loss: 2.9597991929372856
Validation loss: 2.5609473930522726

Epoch: 101| Step: 0
Training loss: 3.2097492478969443
Validation loss: 2.5884371847199334

Epoch: 6| Step: 1
Training loss: 2.970951749591514
Validation loss: 2.594371532897627

Epoch: 6| Step: 2
Training loss: 3.557491864686351
Validation loss: 2.5668351089829233

Epoch: 6| Step: 3
Training loss: 3.3346101858467256
Validation loss: 2.585024935467466

Epoch: 6| Step: 4
Training loss: 2.87477011383475
Validation loss: 2.582746544948155

Epoch: 6| Step: 5
Training loss: 2.2536554312687116
Validation loss: 2.5705500577503537

Epoch: 6| Step: 6
Training loss: 3.016436531885117
Validation loss: 2.5520639843654056

Epoch: 6| Step: 7
Training loss: 2.319291117988
Validation loss: 2.55519866219822

Epoch: 6| Step: 8
Training loss: 2.7656062066253235
Validation loss: 2.574021599901656

Epoch: 6| Step: 9
Training loss: 2.6510683569223468
Validation loss: 2.5653227758796455

Epoch: 6| Step: 10
Training loss: 2.5576009673383147
Validation loss: 2.568186493383598

Epoch: 6| Step: 11
Training loss: 2.5954756913388835
Validation loss: 2.5725650890071727

Epoch: 6| Step: 12
Training loss: 3.17506931860038
Validation loss: 2.573894127905577

Epoch: 6| Step: 13
Training loss: 1.7150128048788549
Validation loss: 2.5814903829263165

Epoch: 102| Step: 0
Training loss: 2.6339259297724817
Validation loss: 2.5824412480398484

Epoch: 6| Step: 1
Training loss: 2.9062291626542143
Validation loss: 2.545562554953018

Epoch: 6| Step: 2
Training loss: 2.7974765919105735
Validation loss: 2.61044613754672

Epoch: 6| Step: 3
Training loss: 2.9057669289384687
Validation loss: 2.599144944053904

Epoch: 6| Step: 4
Training loss: 2.9500066854110223
Validation loss: 2.5558813303055725

Epoch: 6| Step: 5
Training loss: 3.105063357973755
Validation loss: 2.5885744800684427

Epoch: 6| Step: 6
Training loss: 2.7084150644343423
Validation loss: 2.578308392288676

Epoch: 6| Step: 7
Training loss: 2.6221011367776184
Validation loss: 2.5752246072969895

Epoch: 6| Step: 8
Training loss: 2.64693766297947
Validation loss: 2.5392803412321068

Epoch: 6| Step: 9
Training loss: 2.9208700318327905
Validation loss: 2.5475150539093447

Epoch: 6| Step: 10
Training loss: 2.9595058069856917
Validation loss: 2.590374500231581

Epoch: 6| Step: 11
Training loss: 2.8109162003800616
Validation loss: 2.563276710919668

Epoch: 6| Step: 12
Training loss: 2.78494976717507
Validation loss: 2.6220463348781533

Epoch: 6| Step: 13
Training loss: 3.5736054107888076
Validation loss: 2.581330775251183

Epoch: 103| Step: 0
Training loss: 3.006356022922112
Validation loss: 2.5927326605583443

Epoch: 6| Step: 1
Training loss: 2.9655382953667315
Validation loss: 2.6222080602956357

Epoch: 6| Step: 2
Training loss: 2.9295559866315224
Validation loss: 2.5714069102016746

Epoch: 6| Step: 3
Training loss: 2.644505735919435
Validation loss: 2.578502233904064

Epoch: 6| Step: 4
Training loss: 2.6249742052536575
Validation loss: 2.5593140718577936

Epoch: 6| Step: 5
Training loss: 2.409485858192589
Validation loss: 2.6114115341108843

Epoch: 6| Step: 6
Training loss: 3.369397493604705
Validation loss: 2.613980239936963

Epoch: 6| Step: 7
Training loss: 3.1758292969920174
Validation loss: 2.5927197747532276

Epoch: 6| Step: 8
Training loss: 2.6478364425579777
Validation loss: 2.582739755538242

Epoch: 6| Step: 9
Training loss: 3.2084377981906393
Validation loss: 2.610765137577447

Epoch: 6| Step: 10
Training loss: 3.162065191119276
Validation loss: 2.53962549876191

Epoch: 6| Step: 11
Training loss: 2.592858586466694
Validation loss: 2.5633692173825278

Epoch: 6| Step: 12
Training loss: 2.5649540013284184
Validation loss: 2.6162414476734144

Epoch: 6| Step: 13
Training loss: 1.893634009507352
Validation loss: 2.5348017006160517

Epoch: 104| Step: 0
Training loss: 2.505403782020358
Validation loss: 2.5428312515959717

Epoch: 6| Step: 1
Training loss: 3.0594573184229836
Validation loss: 2.605893859704462

Epoch: 6| Step: 2
Training loss: 2.4691713190909295
Validation loss: 2.5775716924336223

Epoch: 6| Step: 3
Training loss: 2.9710947514707096
Validation loss: 2.5853701704853993

Epoch: 6| Step: 4
Training loss: 3.5104142971011956
Validation loss: 2.597426144819192

Epoch: 6| Step: 5
Training loss: 2.5468351208893765
Validation loss: 2.554975447442737

Epoch: 6| Step: 6
Training loss: 2.9934861674157234
Validation loss: 2.6056067270664154

Epoch: 6| Step: 7
Training loss: 2.8659881661191418
Validation loss: 2.5982654544002095

Epoch: 6| Step: 8
Training loss: 2.6397751563588043
Validation loss: 2.6110103307437393

Epoch: 6| Step: 9
Training loss: 2.596799230101372
Validation loss: 2.51232487123226

Epoch: 6| Step: 10
Training loss: 3.81145250282283
Validation loss: 2.611956060571101

Epoch: 6| Step: 11
Training loss: 3.0157211367448045
Validation loss: 2.5889946302790467

Epoch: 6| Step: 12
Training loss: 2.4778949029416912
Validation loss: 2.5949071029640742

Epoch: 6| Step: 13
Training loss: 2.4516898652757053
Validation loss: 2.62025257828961

Epoch: 105| Step: 0
Training loss: 3.237649190992679
Validation loss: 2.5608429492008415

Epoch: 6| Step: 1
Training loss: 1.7044749378298836
Validation loss: 2.530958053745491

Epoch: 6| Step: 2
Training loss: 2.9455873882208126
Validation loss: 2.5723553924191735

Epoch: 6| Step: 3
Training loss: 2.6739545615307954
Validation loss: 2.5894339231059074

Epoch: 6| Step: 4
Training loss: 2.362906333251845
Validation loss: 2.5453999023120177

Epoch: 6| Step: 5
Training loss: 2.958111624849678
Validation loss: 2.5269037018838545

Epoch: 6| Step: 6
Training loss: 3.3313502770767145
Validation loss: 2.5778110207306084

Epoch: 6| Step: 7
Training loss: 2.793592007327799
Validation loss: 2.5621298866095117

Epoch: 6| Step: 8
Training loss: 3.3225558253435583
Validation loss: 2.555179725771333

Epoch: 6| Step: 9
Training loss: 2.7748205040968066
Validation loss: 2.5728307633849505

Epoch: 6| Step: 10
Training loss: 2.6002703599480226
Validation loss: 2.544451928550522

Epoch: 6| Step: 11
Training loss: 1.9391347080160573
Validation loss: 2.5585570655189946

Epoch: 6| Step: 12
Training loss: 3.705082500738718
Validation loss: 2.4960866899724468

Epoch: 6| Step: 13
Training loss: 3.1676735699314236
Validation loss: 2.5519939139904966

Epoch: 106| Step: 0
Training loss: 2.9972971820698797
Validation loss: 2.55544469958385

Epoch: 6| Step: 1
Training loss: 2.609077390956568
Validation loss: 2.5355174943020637

Epoch: 6| Step: 2
Training loss: 2.649395344686
Validation loss: 2.5825225326456773

Epoch: 6| Step: 3
Training loss: 3.0208492585562627
Validation loss: 2.5518159533313725

Epoch: 6| Step: 4
Training loss: 1.8735531628866573
Validation loss: 2.5705504187773025

Epoch: 6| Step: 5
Training loss: 2.759605797245136
Validation loss: 2.5502749242372347

Epoch: 6| Step: 6
Training loss: 3.11394084993314
Validation loss: 2.559057132855364

Epoch: 6| Step: 7
Training loss: 2.7957184174329814
Validation loss: 2.5921464023446137

Epoch: 6| Step: 8
Training loss: 2.7051943757455184
Validation loss: 2.5997050932538284

Epoch: 6| Step: 9
Training loss: 2.538616434675547
Validation loss: 2.548004166824847

Epoch: 6| Step: 10
Training loss: 3.1418843188051824
Validation loss: 2.5969012594054703

Epoch: 6| Step: 11
Training loss: 2.7941340649715913
Validation loss: 2.576169481697499

Epoch: 6| Step: 12
Training loss: 3.6063996969850782
Validation loss: 2.5046552466637233

Epoch: 6| Step: 13
Training loss: 2.865785510644085
Validation loss: 2.550338456680627

Epoch: 107| Step: 0
Training loss: 2.764932923012076
Validation loss: 2.5419262029498335

Epoch: 6| Step: 1
Training loss: 3.463212688377508
Validation loss: 2.5807109503602246

Epoch: 6| Step: 2
Training loss: 2.748465196427657
Validation loss: 2.615946961040107

Epoch: 6| Step: 3
Training loss: 2.703705829994995
Validation loss: 2.5888650970692537

Epoch: 6| Step: 4
Training loss: 2.6112512478750123
Validation loss: 2.5928529862861383

Epoch: 6| Step: 5
Training loss: 2.885507373325127
Validation loss: 2.5592763990018734

Epoch: 6| Step: 6
Training loss: 2.9804527512267196
Validation loss: 2.557887847145623

Epoch: 6| Step: 7
Training loss: 2.6744750461466147
Validation loss: 2.539158385480117

Epoch: 6| Step: 8
Training loss: 3.0993186078765578
Validation loss: 2.5710233305190586

Epoch: 6| Step: 9
Training loss: 2.606395916776228
Validation loss: 2.6059431144284044

Epoch: 6| Step: 10
Training loss: 3.5004466997918273
Validation loss: 2.620011247158137

Epoch: 6| Step: 11
Training loss: 2.9015377768766153
Validation loss: 2.599271958857173

Epoch: 6| Step: 12
Training loss: 2.1401422332128646
Validation loss: 2.5817878177358407

Epoch: 6| Step: 13
Training loss: 2.7390205375734267
Validation loss: 2.5946364831917377

Epoch: 108| Step: 0
Training loss: 2.9322885588950744
Validation loss: 2.5223804005722257

Epoch: 6| Step: 1
Training loss: 3.311013806027703
Validation loss: 2.6183292734748544

Epoch: 6| Step: 2
Training loss: 2.8453537327870255
Validation loss: 2.6026392218141368

Epoch: 6| Step: 3
Training loss: 2.658000414180221
Validation loss: 2.607888682474038

Epoch: 6| Step: 4
Training loss: 3.094352124121332
Validation loss: 2.588760841750058

Epoch: 6| Step: 5
Training loss: 3.217998676202572
Validation loss: 2.5906433307486996

Epoch: 6| Step: 6
Training loss: 2.7382115941568506
Validation loss: 2.6061276369920834

Epoch: 6| Step: 7
Training loss: 2.7051805387314443
Validation loss: 2.580218440488581

Epoch: 6| Step: 8
Training loss: 2.4239247169890343
Validation loss: 2.5561798273812677

Epoch: 6| Step: 9
Training loss: 2.614347733499749
Validation loss: 2.6017335195417766

Epoch: 6| Step: 10
Training loss: 2.6617722497237466
Validation loss: 2.5658576980811647

Epoch: 6| Step: 11
Training loss: 3.25475022818212
Validation loss: 2.5867945724782335

Epoch: 6| Step: 12
Training loss: 2.9222170379682937
Validation loss: 2.5829343881372924

Epoch: 6| Step: 13
Training loss: 2.9855393939315698
Validation loss: 2.572307011427427

Epoch: 109| Step: 0
Training loss: 3.3487537058503256
Validation loss: 2.5606123151368894

Epoch: 6| Step: 1
Training loss: 2.9735223257901824
Validation loss: 2.5602560034797133

Epoch: 6| Step: 2
Training loss: 3.3229589349974216
Validation loss: 2.583799667093361

Epoch: 6| Step: 3
Training loss: 2.9714898566853276
Validation loss: 2.591911515351872

Epoch: 6| Step: 4
Training loss: 3.893518559173679
Validation loss: 2.6001755390117918

Epoch: 6| Step: 5
Training loss: 2.2060194548841014
Validation loss: 2.507804336204884

Epoch: 6| Step: 6
Training loss: 2.019699591403177
Validation loss: 2.579248380856702

Epoch: 6| Step: 7
Training loss: 2.4037620265618176
Validation loss: 2.587123773112656

Epoch: 6| Step: 8
Training loss: 2.755611330112217
Validation loss: 2.6043353892807883

Epoch: 6| Step: 9
Training loss: 2.4858157220980273
Validation loss: 2.5026038053987225

Epoch: 6| Step: 10
Training loss: 2.6662661927237172
Validation loss: 2.575157604179206

Epoch: 6| Step: 11
Training loss: 3.0171906355175317
Validation loss: 2.5421921996837287

Epoch: 6| Step: 12
Training loss: 2.2555055018708616
Validation loss: 2.5082899795572375

Epoch: 6| Step: 13
Training loss: 3.877948869491088
Validation loss: 2.6158747630885806

Epoch: 110| Step: 0
Training loss: 3.1486086361095738
Validation loss: 2.5490113445808653

Epoch: 6| Step: 1
Training loss: 2.8288590126760704
Validation loss: 2.5866107957009623

Epoch: 6| Step: 2
Training loss: 2.4896818857092584
Validation loss: 2.5546363548730358

Epoch: 6| Step: 3
Training loss: 2.9987825466487164
Validation loss: 2.5089344194314265

Epoch: 6| Step: 4
Training loss: 2.511862553444404
Validation loss: 2.549275913176939

Epoch: 6| Step: 5
Training loss: 2.279024057151695
Validation loss: 2.59728961447914

Epoch: 6| Step: 6
Training loss: 2.4961783763407674
Validation loss: 2.5956883043139083

Epoch: 6| Step: 7
Training loss: 3.3383725857978233
Validation loss: 2.5769729282490745

Epoch: 6| Step: 8
Training loss: 2.9950956947692333
Validation loss: 2.560726057973242

Epoch: 6| Step: 9
Training loss: 2.6849532369452023
Validation loss: 2.5753646785496254

Epoch: 6| Step: 10
Training loss: 3.015214328770891
Validation loss: 2.6234880948176724

Epoch: 6| Step: 11
Training loss: 2.7198843507864137
Validation loss: 2.609832442588059

Epoch: 6| Step: 12
Training loss: 3.1946020852228463
Validation loss: 2.531734462222567

Epoch: 6| Step: 13
Training loss: 2.934047699408581
Validation loss: 2.6184326687198625

Epoch: 111| Step: 0
Training loss: 2.5229455804992393
Validation loss: 2.5237356604275836

Epoch: 6| Step: 1
Training loss: 2.64265562452761
Validation loss: 2.5961647155057856

Epoch: 6| Step: 2
Training loss: 2.518682387133129
Validation loss: 2.57021562628315

Epoch: 6| Step: 3
Training loss: 2.587210627052879
Validation loss: 2.5772402381594284

Epoch: 6| Step: 4
Training loss: 2.6822890395858394
Validation loss: 2.4954081151869443

Epoch: 6| Step: 5
Training loss: 2.861084473947847
Validation loss: 2.5531340747470703

Epoch: 6| Step: 6
Training loss: 3.1632904994732334
Validation loss: 2.6311101289598184

Epoch: 6| Step: 7
Training loss: 2.634579119574621
Validation loss: 2.6090918545695247

Epoch: 6| Step: 8
Training loss: 2.2358133448179904
Validation loss: 2.609878675150524

Epoch: 6| Step: 9
Training loss: 3.2979451110602804
Validation loss: 2.560851496514227

Epoch: 6| Step: 10
Training loss: 3.1085615004453073
Validation loss: 2.569898521951518

Epoch: 6| Step: 11
Training loss: 2.498151572675248
Validation loss: 2.533264970531665

Epoch: 6| Step: 12
Training loss: 3.5114604782841794
Validation loss: 2.6194643130759028

Epoch: 6| Step: 13
Training loss: 3.147683330162814
Validation loss: 2.5947041659756156

Epoch: 112| Step: 0
Training loss: 2.397185455468591
Validation loss: 2.5970048444030223

Epoch: 6| Step: 1
Training loss: 2.959797098577214
Validation loss: 2.6141761466310722

Epoch: 6| Step: 2
Training loss: 3.0720154211134085
Validation loss: 2.633481071500322

Epoch: 6| Step: 3
Training loss: 2.814131369587321
Validation loss: 2.6098706145200654

Epoch: 6| Step: 4
Training loss: 2.3851736908370897
Validation loss: 2.607145053544809

Epoch: 6| Step: 5
Training loss: 2.3017856756440946
Validation loss: 2.523551318378671

Epoch: 6| Step: 6
Training loss: 2.495080685581826
Validation loss: 2.5861220433210907

Epoch: 6| Step: 7
Training loss: 2.925073841173648
Validation loss: 2.5958314933316697

Epoch: 6| Step: 8
Training loss: 2.851738075181253
Validation loss: 2.596004993867042

Epoch: 6| Step: 9
Training loss: 2.630106092423567
Validation loss: 2.5583426634049973

Epoch: 6| Step: 10
Training loss: 3.9256124128028427
Validation loss: 2.5894477063925243

Epoch: 6| Step: 11
Training loss: 2.3513120600263777
Validation loss: 2.586455058373374

Epoch: 6| Step: 12
Training loss: 2.9412470517384888
Validation loss: 2.5984272747294788

Epoch: 6| Step: 13
Training loss: 2.8557041973938224
Validation loss: 2.5796923892316577

Epoch: 113| Step: 0
Training loss: 2.281879494964845
Validation loss: 2.5641551301236154

Epoch: 6| Step: 1
Training loss: 2.768988336849206
Validation loss: 2.5368367642416425

Epoch: 6| Step: 2
Training loss: 2.7205954240785846
Validation loss: 2.6229941531604037

Epoch: 6| Step: 3
Training loss: 2.566997489003646
Validation loss: 2.567214359857969

Epoch: 6| Step: 4
Training loss: 2.933962375932703
Validation loss: 2.605074262075595

Epoch: 6| Step: 5
Training loss: 3.0587103615621625
Validation loss: 2.640301879716819

Epoch: 6| Step: 6
Training loss: 2.960299380343929
Validation loss: 2.590163163359724

Epoch: 6| Step: 7
Training loss: 3.0328740753888095
Validation loss: 2.59268617959983

Epoch: 6| Step: 8
Training loss: 2.8458388485350072
Validation loss: 2.5686183991442078

Epoch: 6| Step: 9
Training loss: 3.304166567891822
Validation loss: 2.542547238494763

Epoch: 6| Step: 10
Training loss: 2.846732284033827
Validation loss: 2.601181516275328

Epoch: 6| Step: 11
Training loss: 2.1713390100623746
Validation loss: 2.547177556800063

Epoch: 6| Step: 12
Training loss: 2.9551618706635563
Validation loss: 2.5528930069454088

Epoch: 6| Step: 13
Training loss: 3.403034897689499
Validation loss: 2.5317053061910175

Epoch: 114| Step: 0
Training loss: 3.4601206622831224
Validation loss: 2.5656406136268566

Epoch: 6| Step: 1
Training loss: 2.3217115711799723
Validation loss: 2.580039643446289

Epoch: 6| Step: 2
Training loss: 2.350289136265547
Validation loss: 2.578583620806797

Epoch: 6| Step: 3
Training loss: 2.6694400690285236
Validation loss: 2.5431877505542135

Epoch: 6| Step: 4
Training loss: 2.81339342973652
Validation loss: 2.5563692356075824

Epoch: 6| Step: 5
Training loss: 3.2426304526105447
Validation loss: 2.5403683427971955

Epoch: 6| Step: 6
Training loss: 2.64119375751225
Validation loss: 2.5653103510021564

Epoch: 6| Step: 7
Training loss: 2.3798495522398864
Validation loss: 2.5899217070117313

Epoch: 6| Step: 8
Training loss: 2.5570826137476033
Validation loss: 2.5281028066056703

Epoch: 6| Step: 9
Training loss: 4.073986072424714
Validation loss: 2.571623183901034

Epoch: 6| Step: 10
Training loss: 3.2546122175530385
Validation loss: 2.4985027998315257

Epoch: 6| Step: 11
Training loss: 2.4898942782467097
Validation loss: 2.6043526635146206

Epoch: 6| Step: 12
Training loss: 2.6961921472758092
Validation loss: 2.6167306779590658

Epoch: 6| Step: 13
Training loss: 2.4851755255989243
Validation loss: 2.5474739746873976

Epoch: 115| Step: 0
Training loss: 2.4369909292873273
Validation loss: 2.5616233986046435

Epoch: 6| Step: 1
Training loss: 2.4138697081187788
Validation loss: 2.5515952548694747

Epoch: 6| Step: 2
Training loss: 3.097522631694145
Validation loss: 2.54533559948014

Epoch: 6| Step: 3
Training loss: 2.679900135912597
Validation loss: 2.5626136460453464

Epoch: 6| Step: 4
Training loss: 2.848873176673546
Validation loss: 2.59335918721685

Epoch: 6| Step: 5
Training loss: 2.68751463775197
Validation loss: 2.556879206343799

Epoch: 6| Step: 6
Training loss: 3.1752788150946474
Validation loss: 2.6100987209423536

Epoch: 6| Step: 7
Training loss: 3.4175605224965304
Validation loss: 2.568802577413474

Epoch: 6| Step: 8
Training loss: 2.55673947299839
Validation loss: 2.56373134514554

Epoch: 6| Step: 9
Training loss: 2.9344884165985183
Validation loss: 2.533575132265157

Epoch: 6| Step: 10
Training loss: 2.7727569174851796
Validation loss: 2.5867632154921782

Epoch: 6| Step: 11
Training loss: 2.9425066223329295
Validation loss: 2.5164061984094577

Epoch: 6| Step: 12
Training loss: 2.553428596366212
Validation loss: 2.5763888621699027

Epoch: 6| Step: 13
Training loss: 3.4226611205490625
Validation loss: 2.5552804281465074

Epoch: 116| Step: 0
Training loss: 2.29979701597712
Validation loss: 2.5584794183727406

Epoch: 6| Step: 1
Training loss: 3.998881899013866
Validation loss: 2.5724501993824083

Epoch: 6| Step: 2
Training loss: 2.9025734236808547
Validation loss: 2.5449874348556607

Epoch: 6| Step: 3
Training loss: 2.330937472505949
Validation loss: 2.521882730571199

Epoch: 6| Step: 4
Training loss: 2.6144256138946425
Validation loss: 2.565369848560601

Epoch: 6| Step: 5
Training loss: 3.327223104854488
Validation loss: 2.545317752989611

Epoch: 6| Step: 6
Training loss: 2.6121235151836597
Validation loss: 2.5512594239563193

Epoch: 6| Step: 7
Training loss: 2.7516798610667434
Validation loss: 2.555683357963755

Epoch: 6| Step: 8
Training loss: 2.3214978616455273
Validation loss: 2.6002573291018063

Epoch: 6| Step: 9
Training loss: 2.8958583986217565
Validation loss: 2.6025827246373394

Epoch: 6| Step: 10
Training loss: 3.133005797399374
Validation loss: 2.57187702792554

Epoch: 6| Step: 11
Training loss: 2.3762061419345093
Validation loss: 2.577959519610169

Epoch: 6| Step: 12
Training loss: 2.80629061731115
Validation loss: 2.5838606101470085

Epoch: 6| Step: 13
Training loss: 2.5978901004936996
Validation loss: 2.562875724637496

Epoch: 117| Step: 0
Training loss: 2.58280695402885
Validation loss: 2.5669324872933883

Epoch: 6| Step: 1
Training loss: 2.353788823776427
Validation loss: 2.5969560993268415

Epoch: 6| Step: 2
Training loss: 3.203149116239245
Validation loss: 2.62691746346075

Epoch: 6| Step: 3
Training loss: 3.0852005090579295
Validation loss: 2.611174801458654

Epoch: 6| Step: 4
Training loss: 2.3657772282308667
Validation loss: 2.5672992561065993

Epoch: 6| Step: 5
Training loss: 2.646274910270344
Validation loss: 2.5696049063577227

Epoch: 6| Step: 6
Training loss: 2.175487231347521
Validation loss: 2.5529763761008777

Epoch: 6| Step: 7
Training loss: 2.9434939975745364
Validation loss: 2.6210987675480646

Epoch: 6| Step: 8
Training loss: 2.13360469204902
Validation loss: 2.5720102713820974

Epoch: 6| Step: 9
Training loss: 3.2815397588764506
Validation loss: 2.534665859410696

Epoch: 6| Step: 10
Training loss: 3.3350397192835977
Validation loss: 2.596277248367887

Epoch: 6| Step: 11
Training loss: 3.1158291335654456
Validation loss: 2.568944784632208

Epoch: 6| Step: 12
Training loss: 3.040910879498244
Validation loss: 2.579665362313161

Epoch: 6| Step: 13
Training loss: 2.119568559182551
Validation loss: 2.5673856663326378

Epoch: 118| Step: 0
Training loss: 3.0870384087479317
Validation loss: 2.5485603035595994

Epoch: 6| Step: 1
Training loss: 2.5511127624532217
Validation loss: 2.5626758191978816

Epoch: 6| Step: 2
Training loss: 3.0247112420087605
Validation loss: 2.578257946416187

Epoch: 6| Step: 3
Training loss: 3.453850717363452
Validation loss: 2.5464628736596997

Epoch: 6| Step: 4
Training loss: 3.5425681967621934
Validation loss: 2.576786916858825

Epoch: 6| Step: 5
Training loss: 2.6246034231798308
Validation loss: 2.6003496715044587

Epoch: 6| Step: 6
Training loss: 2.850326144647201
Validation loss: 2.6009825767436943

Epoch: 6| Step: 7
Training loss: 2.0511023279160208
Validation loss: 2.584547627441467

Epoch: 6| Step: 8
Training loss: 2.20699160379905
Validation loss: 2.5236140251991275

Epoch: 6| Step: 9
Training loss: 2.4943535937119794
Validation loss: 2.563413150657394

Epoch: 6| Step: 10
Training loss: 2.6515466674979407
Validation loss: 2.556157921536423

Epoch: 6| Step: 11
Training loss: 2.3920054719664585
Validation loss: 2.6001897346676457

Epoch: 6| Step: 12
Training loss: 3.3759038209457874
Validation loss: 2.5901864186630266

Epoch: 6| Step: 13
Training loss: 2.7221183519160914
Validation loss: 2.586817659856863

Epoch: 119| Step: 0
Training loss: 3.632544591725815
Validation loss: 2.5690581840019067

Epoch: 6| Step: 1
Training loss: 3.1039814392400102
Validation loss: 2.6147427910855634

Epoch: 6| Step: 2
Training loss: 2.8705999455769495
Validation loss: 2.5341231066576286

Epoch: 6| Step: 3
Training loss: 3.352113478394443
Validation loss: 2.6077805633143574

Epoch: 6| Step: 4
Training loss: 2.331493526553649
Validation loss: 2.5398959530006393

Epoch: 6| Step: 5
Training loss: 1.888614184219402
Validation loss: 2.590505584917887

Epoch: 6| Step: 6
Training loss: 2.823829972349263
Validation loss: 2.579253089187507

Epoch: 6| Step: 7
Training loss: 2.378736267531302
Validation loss: 2.5643715265622262

Epoch: 6| Step: 8
Training loss: 2.9494682155978182
Validation loss: 2.660261134187994

Epoch: 6| Step: 9
Training loss: 2.8135083404303503
Validation loss: 2.61854503566736

Epoch: 6| Step: 10
Training loss: 2.630258198381868
Validation loss: 2.546122433927199

Epoch: 6| Step: 11
Training loss: 3.02316779774547
Validation loss: 2.58965430928478

Epoch: 6| Step: 12
Training loss: 3.430171854145884
Validation loss: 2.5530780158883

Epoch: 6| Step: 13
Training loss: 2.228456568290666
Validation loss: 2.590041606067014

Epoch: 120| Step: 0
Training loss: 2.7229526528099197
Validation loss: 2.5473432615605778

Epoch: 6| Step: 1
Training loss: 2.715646309544017
Validation loss: 2.583599016048322

Epoch: 6| Step: 2
Training loss: 1.934930635929085
Validation loss: 2.581430692833001

Epoch: 6| Step: 3
Training loss: 2.1085051827135226
Validation loss: 2.5864770446184844

Epoch: 6| Step: 4
Training loss: 3.3547962300803498
Validation loss: 2.5648455865774378

Epoch: 6| Step: 5
Training loss: 3.2358966878235744
Validation loss: 2.5889427359801083

Epoch: 6| Step: 6
Training loss: 3.0351033052714094
Validation loss: 2.573975639596993

Epoch: 6| Step: 7
Training loss: 2.409582431438378
Validation loss: 2.6321614586579893

Epoch: 6| Step: 8
Training loss: 3.060579904695733
Validation loss: 2.6267217584617426

Epoch: 6| Step: 9
Training loss: 2.8563660178630697
Validation loss: 2.613308062677124

Epoch: 6| Step: 10
Training loss: 2.662130152844446
Validation loss: 2.628422648011498

Epoch: 6| Step: 11
Training loss: 2.3763905520061432
Validation loss: 2.5613415958758985

Epoch: 6| Step: 12
Training loss: 3.36487147432964
Validation loss: 2.563738677875598

Epoch: 6| Step: 13
Training loss: 3.323631154001834
Validation loss: 2.564733674735078

Epoch: 121| Step: 0
Training loss: 2.740482941689772
Validation loss: 2.5397653863551053

Epoch: 6| Step: 1
Training loss: 3.2622172265991893
Validation loss: 2.5695721887659277

Epoch: 6| Step: 2
Training loss: 3.0181668494272222
Validation loss: 2.5680448815790036

Epoch: 6| Step: 3
Training loss: 3.2273645766469743
Validation loss: 2.5865294462990143

Epoch: 6| Step: 4
Training loss: 2.0890832390679503
Validation loss: 2.569253702870889

Epoch: 6| Step: 5
Training loss: 2.6020219643418616
Validation loss: 2.634516866425279

Epoch: 6| Step: 6
Training loss: 2.2028941581398214
Validation loss: 2.6182164067106233

Epoch: 6| Step: 7
Training loss: 2.5275825965433123
Validation loss: 2.5789020887355476

Epoch: 6| Step: 8
Training loss: 2.552773508182018
Validation loss: 2.5645190272666674

Epoch: 6| Step: 9
Training loss: 2.5291756501475566
Validation loss: 2.5560757182849403

Epoch: 6| Step: 10
Training loss: 3.4154354451204543
Validation loss: 2.5596821376071786

Epoch: 6| Step: 11
Training loss: 2.9598734612094604
Validation loss: 2.6345338255063764

Epoch: 6| Step: 12
Training loss: 2.9227641175734824
Validation loss: 2.5609161620521936

Epoch: 6| Step: 13
Training loss: 3.6218655945702674
Validation loss: 2.5098626246157334

Epoch: 122| Step: 0
Training loss: 1.8582770688330579
Validation loss: 2.589942707638531

Epoch: 6| Step: 1
Training loss: 2.9287124028318274
Validation loss: 2.596831649576987

Epoch: 6| Step: 2
Training loss: 3.193501675202931
Validation loss: 2.5823720505697656

Epoch: 6| Step: 3
Training loss: 2.7496395741866513
Validation loss: 2.6019910361934575

Epoch: 6| Step: 4
Training loss: 2.967400013011262
Validation loss: 2.643566971550954

Epoch: 6| Step: 5
Training loss: 2.787865817438142
Validation loss: 2.6060542796870134

Epoch: 6| Step: 6
Training loss: 3.673081349997401
Validation loss: 2.5962286199739752

Epoch: 6| Step: 7
Training loss: 2.559961690020012
Validation loss: 2.6236882015728207

Epoch: 6| Step: 8
Training loss: 2.88555017339183
Validation loss: 2.5587632250335726

Epoch: 6| Step: 9
Training loss: 2.4943184188049545
Validation loss: 2.612231109138022

Epoch: 6| Step: 10
Training loss: 3.1863995316662397
Validation loss: 2.654232127792798

Epoch: 6| Step: 11
Training loss: 2.8659708627629232
Validation loss: 2.649788951189648

Epoch: 6| Step: 12
Training loss: 2.4688566160720344
Validation loss: 2.587497176516126

Epoch: 6| Step: 13
Training loss: 2.232875400775736
Validation loss: 2.588390404767384

Epoch: 123| Step: 0
Training loss: 3.063087251372622
Validation loss: 2.601689267693711

Epoch: 6| Step: 1
Training loss: 2.6585495812006035
Validation loss: 2.5823712940968746

Epoch: 6| Step: 2
Training loss: 3.1040041750850325
Validation loss: 2.611744244787974

Epoch: 6| Step: 3
Training loss: 2.685413970432945
Validation loss: 2.5672314250122836

Epoch: 6| Step: 4
Training loss: 3.974374465186486
Validation loss: 2.567747043952729

Epoch: 6| Step: 5
Training loss: 1.9956331262802367
Validation loss: 2.5428641574859125

Epoch: 6| Step: 6
Training loss: 2.711062733508675
Validation loss: 2.6054986667073172

Epoch: 6| Step: 7
Training loss: 2.8305633318537082
Validation loss: 2.598651459906127

Epoch: 6| Step: 8
Training loss: 2.485401349421517
Validation loss: 2.591566430098759

Epoch: 6| Step: 9
Training loss: 2.8513377479921598
Validation loss: 2.538455101797134

Epoch: 6| Step: 10
Training loss: 2.3508084631245167
Validation loss: 2.5896396796918695

Epoch: 6| Step: 11
Training loss: 2.9216303595466533
Validation loss: 2.5312331510646695

Epoch: 6| Step: 12
Training loss: 3.1853373053382112
Validation loss: 2.5238228551962343

Epoch: 6| Step: 13
Training loss: 2.828048705025574
Validation loss: 2.59414884858962

Epoch: 124| Step: 0
Training loss: 2.399691673182781
Validation loss: 2.5332210548138203

Epoch: 6| Step: 1
Training loss: 2.783474150729322
Validation loss: 2.6026557877563663

Epoch: 6| Step: 2
Training loss: 3.0011753323063517
Validation loss: 2.5783027207319638

Epoch: 6| Step: 3
Training loss: 3.831338957956395
Validation loss: 2.540046481793296

Epoch: 6| Step: 4
Training loss: 2.875152915536794
Validation loss: 2.5653599412241004

Epoch: 6| Step: 5
Training loss: 2.086746687507491
Validation loss: 2.5550528679575466

Epoch: 6| Step: 6
Training loss: 2.879193771683723
Validation loss: 2.5283699640893884

Epoch: 6| Step: 7
Training loss: 3.210262478231053
Validation loss: 2.603477786266236

Epoch: 6| Step: 8
Training loss: 2.6928223537208558
Validation loss: 2.5845863692020816

Epoch: 6| Step: 9
Training loss: 3.081262219387377
Validation loss: 2.525256831280743

Epoch: 6| Step: 10
Training loss: 2.6184530813643847
Validation loss: 2.5562391794228776

Epoch: 6| Step: 11
Training loss: 2.4925488057614404
Validation loss: 2.571700811013961

Epoch: 6| Step: 12
Training loss: 2.537505908075981
Validation loss: 2.562053376380469

Epoch: 6| Step: 13
Training loss: 2.4591332982108027
Validation loss: 2.57798713621245

Epoch: 125| Step: 0
Training loss: 2.7502295658353546
Validation loss: 2.5600693342346217

Epoch: 6| Step: 1
Training loss: 2.400712018887696
Validation loss: 2.5364667832472456

Epoch: 6| Step: 2
Training loss: 3.3816926789791286
Validation loss: 2.586567182106762

Epoch: 6| Step: 3
Training loss: 2.5150202622554882
Validation loss: 2.60031432341374

Epoch: 6| Step: 4
Training loss: 2.5687343773285574
Validation loss: 2.6040246274215244

Epoch: 6| Step: 5
Training loss: 3.076805800257
Validation loss: 2.5627825541452607

Epoch: 6| Step: 6
Training loss: 2.330843266654735
Validation loss: 2.5646161181614495

Epoch: 6| Step: 7
Training loss: 3.0742607840896174
Validation loss: 2.6118155184336347

Epoch: 6| Step: 8
Training loss: 3.239352464371195
Validation loss: 2.5495920349964387

Epoch: 6| Step: 9
Training loss: 2.3231064130210397
Validation loss: 2.589694736742108

Epoch: 6| Step: 10
Training loss: 2.5349272402642717
Validation loss: 2.5731652216034937

Epoch: 6| Step: 11
Training loss: 3.0137837377469068
Validation loss: 2.5702660085721956

Epoch: 6| Step: 12
Training loss: 2.9877092998401906
Validation loss: 2.585202804622891

Epoch: 6| Step: 13
Training loss: 2.9054350992312195
Validation loss: 2.556796287309465

Epoch: 126| Step: 0
Training loss: 3.185032506564273
Validation loss: 2.5694410812598334

Epoch: 6| Step: 1
Training loss: 3.115641351501961
Validation loss: 2.6032064837585307

Epoch: 6| Step: 2
Training loss: 3.051816718181495
Validation loss: 2.5205520117641784

Epoch: 6| Step: 3
Training loss: 2.958300379896422
Validation loss: 2.5764449715405755

Epoch: 6| Step: 4
Training loss: 2.8609911410992246
Validation loss: 2.600645303769643

Epoch: 6| Step: 5
Training loss: 3.3605824274534593
Validation loss: 2.5087213917251354

Epoch: 6| Step: 6
Training loss: 2.466092671375562
Validation loss: 2.5778307466209243

Epoch: 6| Step: 7
Training loss: 2.3670657287097
Validation loss: 2.5403165526317744

Epoch: 6| Step: 8
Training loss: 2.671230394561895
Validation loss: 2.6018802973824933

Epoch: 6| Step: 9
Training loss: 2.847669310991138
Validation loss: 2.525698231087366

Epoch: 6| Step: 10
Training loss: 2.064045182761146
Validation loss: 2.573320092540105

Epoch: 6| Step: 11
Training loss: 2.666576731675251
Validation loss: 2.5554621929503

Epoch: 6| Step: 12
Training loss: 2.753688679210215
Validation loss: 2.5722788664170158

Epoch: 6| Step: 13
Training loss: 2.970954638586489
Validation loss: 2.6275017278301904

Epoch: 127| Step: 0
Training loss: 2.767866185608608
Validation loss: 2.540097014365628

Epoch: 6| Step: 1
Training loss: 2.9217183280188475
Validation loss: 2.5776847674798

Epoch: 6| Step: 2
Training loss: 2.8533318034135275
Validation loss: 2.5538471153380864

Epoch: 6| Step: 3
Training loss: 2.6120743181133204
Validation loss: 2.5799085327778326

Epoch: 6| Step: 4
Training loss: 2.5998861508018667
Validation loss: 2.55428683342156

Epoch: 6| Step: 5
Training loss: 2.7986112352176087
Validation loss: 2.5652022751145838

Epoch: 6| Step: 6
Training loss: 2.9656436127700623
Validation loss: 2.5489195702323078

Epoch: 6| Step: 7
Training loss: 2.4051215758494826
Validation loss: 2.6197957769693696

Epoch: 6| Step: 8
Training loss: 2.0654801310698883
Validation loss: 2.657035020598464

Epoch: 6| Step: 9
Training loss: 2.4508166295113263
Validation loss: 2.552358723377647

Epoch: 6| Step: 10
Training loss: 3.0692017077115716
Validation loss: 2.5734596757203367

Epoch: 6| Step: 11
Training loss: 2.9619454552923408
Validation loss: 2.5174962017250917

Epoch: 6| Step: 12
Training loss: 3.0902287644822506
Validation loss: 2.607221540438041

Epoch: 6| Step: 13
Training loss: 3.741774629820868
Validation loss: 2.5645626949327123

Epoch: 128| Step: 0
Training loss: 2.8460154469996377
Validation loss: 2.599686943514181

Epoch: 6| Step: 1
Training loss: 3.0890959595569503
Validation loss: 2.5881029200684122

Epoch: 6| Step: 2
Training loss: 2.2046012531716115
Validation loss: 2.528583666306129

Epoch: 6| Step: 3
Training loss: 2.7068577390167556
Validation loss: 2.5608427880249462

Epoch: 6| Step: 4
Training loss: 3.1990392911739316
Validation loss: 2.506847999744718

Epoch: 6| Step: 5
Training loss: 2.493549895324907
Validation loss: 2.5328285250938993

Epoch: 6| Step: 6
Training loss: 2.8620987723398708
Validation loss: 2.6199589701187977

Epoch: 6| Step: 7
Training loss: 2.568291144679495
Validation loss: 2.5765884797590695

Epoch: 6| Step: 8
Training loss: 2.6600992473931204
Validation loss: 2.569559821350864

Epoch: 6| Step: 9
Training loss: 2.6013648155643234
Validation loss: 2.5885356078431143

Epoch: 6| Step: 10
Training loss: 2.857039701779439
Validation loss: 2.5670179790918612

Epoch: 6| Step: 11
Training loss: 3.5529809229752245
Validation loss: 2.58096105977571

Epoch: 6| Step: 12
Training loss: 2.925190885135112
Validation loss: 2.531185186283758

Epoch: 6| Step: 13
Training loss: 2.7720422808242384
Validation loss: 2.513003949229714

Epoch: 129| Step: 0
Training loss: 2.4835445527576563
Validation loss: 2.59753775352948

Epoch: 6| Step: 1
Training loss: 3.215213351134034
Validation loss: 2.6404299731052148

Epoch: 6| Step: 2
Training loss: 3.30921701372961
Validation loss: 2.569641158261905

Epoch: 6| Step: 3
Training loss: 2.5586865590276258
Validation loss: 2.5741509369140063

Epoch: 6| Step: 4
Training loss: 2.6394690517223345
Validation loss: 2.4707873727796903

Epoch: 6| Step: 5
Training loss: 3.1945349159882057
Validation loss: 2.5914499596680356

Epoch: 6| Step: 6
Training loss: 2.573427116220228
Validation loss: 2.5378476723704932

Epoch: 6| Step: 7
Training loss: 3.4751124411854413
Validation loss: 2.5796924627712023

Epoch: 6| Step: 8
Training loss: 2.4633645336083436
Validation loss: 2.5589542202936006

Epoch: 6| Step: 9
Training loss: 2.6263970789878885
Validation loss: 2.5398018183886735

Epoch: 6| Step: 10
Training loss: 2.834538054060914
Validation loss: 2.576287046447557

Epoch: 6| Step: 11
Training loss: 2.2338397045086857
Validation loss: 2.605460245740575

Epoch: 6| Step: 12
Training loss: 3.0746987730281545
Validation loss: 2.587104393557564

Epoch: 6| Step: 13
Training loss: 2.1052572112250414
Validation loss: 2.557586695676052

Epoch: 130| Step: 0
Training loss: 2.598628592102454
Validation loss: 2.5972700274926472

Epoch: 6| Step: 1
Training loss: 2.6406974105387158
Validation loss: 2.5964812886978894

Epoch: 6| Step: 2
Training loss: 3.0870093693271285
Validation loss: 2.5435542402356757

Epoch: 6| Step: 3
Training loss: 2.9907379224737918
Validation loss: 2.588992987525094

Epoch: 6| Step: 4
Training loss: 2.5849793840246615
Validation loss: 2.5484799043595014

Epoch: 6| Step: 5
Training loss: 1.7740739528977765
Validation loss: 2.5872834891269747

Epoch: 6| Step: 6
Training loss: 2.502436785437807
Validation loss: 2.5884891277798316

Epoch: 6| Step: 7
Training loss: 2.5007699734386786
Validation loss: 2.529805195814486

Epoch: 6| Step: 8
Training loss: 3.353811936348628
Validation loss: 2.6312025743302137

Epoch: 6| Step: 9
Training loss: 3.100265577691963
Validation loss: 2.5404787779298728

Epoch: 6| Step: 10
Training loss: 2.939411920911375
Validation loss: 2.5832175725239104

Epoch: 6| Step: 11
Training loss: 2.7871648065178003
Validation loss: 2.538160350175113

Epoch: 6| Step: 12
Training loss: 2.7837095208173324
Validation loss: 2.560124548556812

Epoch: 6| Step: 13
Training loss: 3.3802256218811455
Validation loss: 2.549470445811442

Epoch: 131| Step: 0
Training loss: 2.4629249903121395
Validation loss: 2.5450259820374312

Epoch: 6| Step: 1
Training loss: 2.6395214415783324
Validation loss: 2.5273217879599867

Epoch: 6| Step: 2
Training loss: 2.656118322362337
Validation loss: 2.5260311030496942

Epoch: 6| Step: 3
Training loss: 2.4604542091169126
Validation loss: 2.4878982375634053

Epoch: 6| Step: 4
Training loss: 2.6127997669009626
Validation loss: 2.57487929535471

Epoch: 6| Step: 5
Training loss: 2.603007422238414
Validation loss: 2.5672356760544934

Epoch: 6| Step: 6
Training loss: 2.903087577126937
Validation loss: 2.61942954002864

Epoch: 6| Step: 7
Training loss: 2.5813946884281505
Validation loss: 2.594985116316903

Epoch: 6| Step: 8
Training loss: 3.6402002176826613
Validation loss: 2.5314168101566334

Epoch: 6| Step: 9
Training loss: 2.3913637902105416
Validation loss: 2.5461680200267436

Epoch: 6| Step: 10
Training loss: 2.8116661531108336
Validation loss: 2.4947496029956575

Epoch: 6| Step: 11
Training loss: 2.956545831504085
Validation loss: 2.5218667248111335

Epoch: 6| Step: 12
Training loss: 2.8945467352613785
Validation loss: 2.5817085188406095

Epoch: 6| Step: 13
Training loss: 3.593679410821682
Validation loss: 2.5463464609895192

Epoch: 132| Step: 0
Training loss: 1.967941966069535
Validation loss: 2.592018878146593

Epoch: 6| Step: 1
Training loss: 2.900631960708627
Validation loss: 2.523957959540746

Epoch: 6| Step: 2
Training loss: 3.191631108443652
Validation loss: 2.569091432025766

Epoch: 6| Step: 3
Training loss: 2.1835971347734837
Validation loss: 2.644043575229188

Epoch: 6| Step: 4
Training loss: 2.4299842187188494
Validation loss: 2.5365073559855276

Epoch: 6| Step: 5
Training loss: 2.1889233999011397
Validation loss: 2.5343955834509297

Epoch: 6| Step: 6
Training loss: 2.526211091222781
Validation loss: 2.533217296212349

Epoch: 6| Step: 7
Training loss: 3.1949904449749837
Validation loss: 2.585948409096623

Epoch: 6| Step: 8
Training loss: 2.7574680534718747
Validation loss: 2.6122571357061632

Epoch: 6| Step: 9
Training loss: 2.4068070794811485
Validation loss: 2.6464365238573544

Epoch: 6| Step: 10
Training loss: 3.578514511029941
Validation loss: 2.564861393099397

Epoch: 6| Step: 11
Training loss: 3.097093721089485
Validation loss: 2.5884322563840163

Epoch: 6| Step: 12
Training loss: 3.5220405871399234
Validation loss: 2.59904653603506

Epoch: 6| Step: 13
Training loss: 2.6374925622338012
Validation loss: 2.6155216719969583

Epoch: 133| Step: 0
Training loss: 3.428759195090831
Validation loss: 2.5237353048934046

Epoch: 6| Step: 1
Training loss: 3.3800102062184108
Validation loss: 2.5578566334122415

Epoch: 6| Step: 2
Training loss: 1.8683964474601187
Validation loss: 2.549278819459925

Epoch: 6| Step: 3
Training loss: 3.2536798331996675
Validation loss: 2.536968830646138

Epoch: 6| Step: 4
Training loss: 2.6852233469895523
Validation loss: 2.504087772149996

Epoch: 6| Step: 5
Training loss: 2.7427742267888116
Validation loss: 2.6019669316681964

Epoch: 6| Step: 6
Training loss: 2.650568552025549
Validation loss: 2.5482329188513217

Epoch: 6| Step: 7
Training loss: 2.7220791132499262
Validation loss: 2.5963957204134855

Epoch: 6| Step: 8
Training loss: 2.746010921526012
Validation loss: 2.5905840722307483

Epoch: 6| Step: 9
Training loss: 2.848183330635883
Validation loss: 2.5623000032146757

Epoch: 6| Step: 10
Training loss: 2.465009535641439
Validation loss: 2.575240505411064

Epoch: 6| Step: 11
Training loss: 2.271418248244799
Validation loss: 2.578978273075192

Epoch: 6| Step: 12
Training loss: 2.845271615201266
Validation loss: 2.5855100282298524

Epoch: 6| Step: 13
Training loss: 3.3041984611094337
Validation loss: 2.5824708160306997

Epoch: 134| Step: 0
Training loss: 2.524266157115372
Validation loss: 2.5759610787193106

Epoch: 6| Step: 1
Training loss: 3.0026678303004304
Validation loss: 2.6334058184893707

Epoch: 6| Step: 2
Training loss: 2.5558777815622262
Validation loss: 2.5436225061977913

Epoch: 6| Step: 3
Training loss: 2.9937574286956044
Validation loss: 2.596565152023367

Epoch: 6| Step: 4
Training loss: 3.5559899260181926
Validation loss: 2.605903693605925

Epoch: 6| Step: 5
Training loss: 2.749301474893853
Validation loss: 2.6061846868743843

Epoch: 6| Step: 6
Training loss: 2.8968939359801142
Validation loss: 2.5764032684910507

Epoch: 6| Step: 7
Training loss: 3.1727537243975794
Validation loss: 2.582391359415652

Epoch: 6| Step: 8
Training loss: 3.058396217330282
Validation loss: 2.5290970147861382

Epoch: 6| Step: 9
Training loss: 2.6907722601206814
Validation loss: 2.584072054719262

Epoch: 6| Step: 10
Training loss: 1.9674490611596673
Validation loss: 2.524721960697686

Epoch: 6| Step: 11
Training loss: 2.5930015679121885
Validation loss: 2.5443829845817114

Epoch: 6| Step: 12
Training loss: 2.8514752100295535
Validation loss: 2.547218013282567

Epoch: 6| Step: 13
Training loss: 2.3265162292347283
Validation loss: 2.6022913855676078

Epoch: 135| Step: 0
Training loss: 2.901736127827958
Validation loss: 2.5688887858815104

Epoch: 6| Step: 1
Training loss: 2.535856975938705
Validation loss: 2.6074214187909877

Epoch: 6| Step: 2
Training loss: 2.921221165251525
Validation loss: 2.466349980208111

Epoch: 6| Step: 3
Training loss: 2.2579844056259124
Validation loss: 2.556922736782822

Epoch: 6| Step: 4
Training loss: 3.240100308266612
Validation loss: 2.5859131595814437

Epoch: 6| Step: 5
Training loss: 2.184963172235605
Validation loss: 2.5383887945285393

Epoch: 6| Step: 6
Training loss: 2.5787869615074013
Validation loss: 2.5875885931875877

Epoch: 6| Step: 7
Training loss: 2.974662594935926
Validation loss: 2.552446340460282

Epoch: 6| Step: 8
Training loss: 3.012287407809237
Validation loss: 2.5708652000215952

Epoch: 6| Step: 9
Training loss: 2.7512956514778306
Validation loss: 2.559553440656854

Epoch: 6| Step: 10
Training loss: 3.192275714448949
Validation loss: 2.5554995874723545

Epoch: 6| Step: 11
Training loss: 3.107428319937534
Validation loss: 2.582435745387971

Epoch: 6| Step: 12
Training loss: 2.571047228586736
Validation loss: 2.583686698922672

Epoch: 6| Step: 13
Training loss: 2.6898233883253524
Validation loss: 2.5860504838508906

Epoch: 136| Step: 0
Training loss: 2.295921491071518
Validation loss: 2.564741331459107

Epoch: 6| Step: 1
Training loss: 2.5877365815002067
Validation loss: 2.6295840595997317

Epoch: 6| Step: 2
Training loss: 2.8049945291340017
Validation loss: 2.5570373385297596

Epoch: 6| Step: 3
Training loss: 3.361109370151486
Validation loss: 2.526101297872048

Epoch: 6| Step: 4
Training loss: 2.820699057677141
Validation loss: 2.5785061879789746

Epoch: 6| Step: 5
Training loss: 2.3219714672231415
Validation loss: 2.5407945221567703

Epoch: 6| Step: 6
Training loss: 2.6131175721233335
Validation loss: 2.570579474299271

Epoch: 6| Step: 7
Training loss: 2.515168616556006
Validation loss: 2.5845410887573785

Epoch: 6| Step: 8
Training loss: 2.830106599505218
Validation loss: 2.576178104542031

Epoch: 6| Step: 9
Training loss: 3.441020896371473
Validation loss: 2.579893531923711

Epoch: 6| Step: 10
Training loss: 2.498062336555454
Validation loss: 2.627296449167417

Epoch: 6| Step: 11
Training loss: 2.8971485654839726
Validation loss: 2.535582615352984

Epoch: 6| Step: 12
Training loss: 2.6169421636118
Validation loss: 2.630194370196567

Epoch: 6| Step: 13
Training loss: 3.375833620328631
Validation loss: 2.486366528869836

Epoch: 137| Step: 0
Training loss: 2.9638670266165525
Validation loss: 2.610439536064355

Epoch: 6| Step: 1
Training loss: 2.687633333669007
Validation loss: 2.5121372559174935

Epoch: 6| Step: 2
Training loss: 2.8166034010454006
Validation loss: 2.585988668459661

Epoch: 6| Step: 3
Training loss: 3.176485065767959
Validation loss: 2.5834006556439575

Epoch: 6| Step: 4
Training loss: 2.7864531805163124
Validation loss: 2.60551077891573

Epoch: 6| Step: 5
Training loss: 2.3413389902061015
Validation loss: 2.623864611494149

Epoch: 6| Step: 6
Training loss: 2.1286921122235074
Validation loss: 2.534095029222802

Epoch: 6| Step: 7
Training loss: 2.7596985848633677
Validation loss: 2.552643100072614

Epoch: 6| Step: 8
Training loss: 2.9836279448342418
Validation loss: 2.5027295368110893

Epoch: 6| Step: 9
Training loss: 3.5470129313936303
Validation loss: 2.541288799302854

Epoch: 6| Step: 10
Training loss: 2.3386782894425666
Validation loss: 2.642156630653774

Epoch: 6| Step: 11
Training loss: 2.292918631998595
Validation loss: 2.573146205183867

Epoch: 6| Step: 12
Training loss: 3.3715316470370933
Validation loss: 2.575777641725142

Epoch: 6| Step: 13
Training loss: 2.177725178652107
Validation loss: 2.5238638505980644

Epoch: 138| Step: 0
Training loss: 2.3532454339524835
Validation loss: 2.5283630388016465

Epoch: 6| Step: 1
Training loss: 2.283310886838897
Validation loss: 2.5977085919673195

Epoch: 6| Step: 2
Training loss: 3.088955950599829
Validation loss: 2.605411008455237

Epoch: 6| Step: 3
Training loss: 2.478746576273175
Validation loss: 2.5415388088925392

Epoch: 6| Step: 4
Training loss: 2.8167102242286424
Validation loss: 2.5170938622144496

Epoch: 6| Step: 5
Training loss: 2.4800584829264314
Validation loss: 2.631573701809036

Epoch: 6| Step: 6
Training loss: 2.506714862891093
Validation loss: 2.582038463244689

Epoch: 6| Step: 7
Training loss: 3.166176473589882
Validation loss: 2.5849103244198113

Epoch: 6| Step: 8
Training loss: 2.787023060457208
Validation loss: 2.565575721430044

Epoch: 6| Step: 9
Training loss: 3.3285058032032944
Validation loss: 2.5913906374844466

Epoch: 6| Step: 10
Training loss: 2.3049407302617415
Validation loss: 2.572308984755839

Epoch: 6| Step: 11
Training loss: 2.920178088936693
Validation loss: 2.5877892340720807

Epoch: 6| Step: 12
Training loss: 3.3779438037252025
Validation loss: 2.554014286508393

Epoch: 6| Step: 13
Training loss: 2.8089139328750896
Validation loss: 2.572742851025452

Epoch: 139| Step: 0
Training loss: 2.378199179416034
Validation loss: 2.523185003909871

Epoch: 6| Step: 1
Training loss: 1.938160014791137
Validation loss: 2.532403500538962

Epoch: 6| Step: 2
Training loss: 3.1970419085980137
Validation loss: 2.5795438012811074

Epoch: 6| Step: 3
Training loss: 3.1002303560869833
Validation loss: 2.5550713718758002

Epoch: 6| Step: 4
Training loss: 2.1507021533681603
Validation loss: 2.511303920315714

Epoch: 6| Step: 5
Training loss: 3.270685682588523
Validation loss: 2.5263031049864932

Epoch: 6| Step: 6
Training loss: 2.23378313668664
Validation loss: 2.5477927641958993

Epoch: 6| Step: 7
Training loss: 2.4756587452311263
Validation loss: 2.5516388292352703

Epoch: 6| Step: 8
Training loss: 3.024394196939924
Validation loss: 2.585643956245239

Epoch: 6| Step: 9
Training loss: 3.4547173466421865
Validation loss: 2.6007031604885427

Epoch: 6| Step: 10
Training loss: 3.2488336671078133
Validation loss: 2.56541976040846

Epoch: 6| Step: 11
Training loss: 2.84763431409804
Validation loss: 2.554189051786785

Epoch: 6| Step: 12
Training loss: 2.6110857078542993
Validation loss: 2.596368507956764

Epoch: 6| Step: 13
Training loss: 2.6123015844023625
Validation loss: 2.547156051608739

Epoch: 140| Step: 0
Training loss: 2.4014292395208185
Validation loss: 2.56327116512641

Epoch: 6| Step: 1
Training loss: 2.346743896723518
Validation loss: 2.5397108468471647

Epoch: 6| Step: 2
Training loss: 3.6920695037003037
Validation loss: 2.556819752849827

Epoch: 6| Step: 3
Training loss: 2.6818723974346406
Validation loss: 2.5648843000891772

Epoch: 6| Step: 4
Training loss: 3.34910952561468
Validation loss: 2.6059193288032234

Epoch: 6| Step: 5
Training loss: 3.3483996995722753
Validation loss: 2.5833826920408174

Epoch: 6| Step: 6
Training loss: 2.601579545798605
Validation loss: 2.604496451548936

Epoch: 6| Step: 7
Training loss: 3.2833364483452234
Validation loss: 2.594910030260743

Epoch: 6| Step: 8
Training loss: 2.6351210437167896
Validation loss: 2.528768171719459

Epoch: 6| Step: 9
Training loss: 1.9764594854115134
Validation loss: 2.5584085266707417

Epoch: 6| Step: 10
Training loss: 2.4377404118845107
Validation loss: 2.6082544493014486

Epoch: 6| Step: 11
Training loss: 2.78479172727413
Validation loss: 2.5824285828892064

Epoch: 6| Step: 12
Training loss: 2.4575694454466825
Validation loss: 2.572799911795955

Epoch: 6| Step: 13
Training loss: 2.207466987198847
Validation loss: 2.548310856076548

Epoch: 141| Step: 0
Training loss: 3.024621854744288
Validation loss: 2.6013055007011667

Epoch: 6| Step: 1
Training loss: 3.167241964450609
Validation loss: 2.5736058935194683

Epoch: 6| Step: 2
Training loss: 2.320549230348012
Validation loss: 2.5306510039320207

Epoch: 6| Step: 3
Training loss: 3.065105342081515
Validation loss: 2.527384281538739

Epoch: 6| Step: 4
Training loss: 2.8348255341953887
Validation loss: 2.565478104254879

Epoch: 6| Step: 5
Training loss: 2.7401169135217693
Validation loss: 2.555942203827176

Epoch: 6| Step: 6
Training loss: 2.687446416276322
Validation loss: 2.5508904544506

Epoch: 6| Step: 7
Training loss: 2.6000124234122794
Validation loss: 2.571027852492827

Epoch: 6| Step: 8
Training loss: 2.8391327315499706
Validation loss: 2.5729495906595687

Epoch: 6| Step: 9
Training loss: 2.596085381759854
Validation loss: 2.6255341424418415

Epoch: 6| Step: 10
Training loss: 2.693499057348273
Validation loss: 2.536444105772243

Epoch: 6| Step: 11
Training loss: 2.5159843614635022
Validation loss: 2.573988801502591

Epoch: 6| Step: 12
Training loss: 2.752816405304923
Validation loss: 2.525689925144258

Epoch: 6| Step: 13
Training loss: 3.207649124972298
Validation loss: 2.6020594823693557

Epoch: 142| Step: 0
Training loss: 2.6804620718810264
Validation loss: 2.577502933155712

Epoch: 6| Step: 1
Training loss: 2.5058019071011652
Validation loss: 2.5030823686782493

Epoch: 6| Step: 2
Training loss: 2.640097119539004
Validation loss: 2.59307741018195

Epoch: 6| Step: 3
Training loss: 3.277299519218815
Validation loss: 2.5550004458161646

Epoch: 6| Step: 4
Training loss: 2.988948812281904
Validation loss: 2.5659862996396634

Epoch: 6| Step: 5
Training loss: 2.4233898716469913
Validation loss: 2.5524108512488066

Epoch: 6| Step: 6
Training loss: 2.6759343235754787
Validation loss: 2.5281988146961316

Epoch: 6| Step: 7
Training loss: 2.864392323917054
Validation loss: 2.5735477673058753

Epoch: 6| Step: 8
Training loss: 2.991858083255995
Validation loss: 2.6071690974129016

Epoch: 6| Step: 9
Training loss: 2.67252649763369
Validation loss: 2.549737355224027

Epoch: 6| Step: 10
Training loss: 2.4024636339497776
Validation loss: 2.608140578413203

Epoch: 6| Step: 11
Training loss: 2.9215208440739215
Validation loss: 2.521807271341682

Epoch: 6| Step: 12
Training loss: 2.88364999902806
Validation loss: 2.525568807322301

Epoch: 6| Step: 13
Training loss: 2.5216081442621547
Validation loss: 2.619089588378496

Epoch: 143| Step: 0
Training loss: 2.5817998415946395
Validation loss: 2.5479432384792515

Epoch: 6| Step: 1
Training loss: 2.6455651295009073
Validation loss: 2.499492747621115

Epoch: 6| Step: 2
Training loss: 2.919753012989344
Validation loss: 2.6048945926023386

Epoch: 6| Step: 3
Training loss: 2.984238067201717
Validation loss: 2.5432178857979504

Epoch: 6| Step: 4
Training loss: 3.6878149900225154
Validation loss: 2.5430182567188186

Epoch: 6| Step: 5
Training loss: 2.7080601089770897
Validation loss: 2.5808831688378318

Epoch: 6| Step: 6
Training loss: 3.3491609234241357
Validation loss: 2.64746703222093

Epoch: 6| Step: 7
Training loss: 2.553924446589589
Validation loss: 2.5668573696479484

Epoch: 6| Step: 8
Training loss: 2.528531722464401
Validation loss: 2.6128725021335475

Epoch: 6| Step: 9
Training loss: 2.576005839216829
Validation loss: 2.5446258534690323

Epoch: 6| Step: 10
Training loss: 2.3073344919149816
Validation loss: 2.5590387995118435

Epoch: 6| Step: 11
Training loss: 2.430104505073519
Validation loss: 2.567669649753584

Epoch: 6| Step: 12
Training loss: 2.0883898089242234
Validation loss: 2.608858577268822

Epoch: 6| Step: 13
Training loss: 3.0567420235777267
Validation loss: 2.5937334325275865

Epoch: 144| Step: 0
Training loss: 2.9676665889061993
Validation loss: 2.6012644140152226

Epoch: 6| Step: 1
Training loss: 2.8629076871442893
Validation loss: 2.6165406923032957

Epoch: 6| Step: 2
Training loss: 2.5681597846045823
Validation loss: 2.5792346991162365

Epoch: 6| Step: 3
Training loss: 2.4642429979938303
Validation loss: 2.5848878517695533

Epoch: 6| Step: 4
Training loss: 2.5618901341129243
Validation loss: 2.585073594125347

Epoch: 6| Step: 5
Training loss: 2.7995616433465904
Validation loss: 2.5565935981620824

Epoch: 6| Step: 6
Training loss: 2.283428145154932
Validation loss: 2.5321340461635797

Epoch: 6| Step: 7
Training loss: 2.904941387274617
Validation loss: 2.5610004632560712

Epoch: 6| Step: 8
Training loss: 2.3331178724628168
Validation loss: 2.5218051578530045

Epoch: 6| Step: 9
Training loss: 3.0184189893370386
Validation loss: 2.4876314133957713

Epoch: 6| Step: 10
Training loss: 3.2233187647598447
Validation loss: 2.576720962224042

Epoch: 6| Step: 11
Training loss: 2.9985998383071073
Validation loss: 2.558865379350223

Epoch: 6| Step: 12
Training loss: 2.7085397103736355
Validation loss: 2.585161113934323

Epoch: 6| Step: 13
Training loss: 3.4448270909914496
Validation loss: 2.6104560701830177

Epoch: 145| Step: 0
Training loss: 2.5370823107678886
Validation loss: 2.509582179318276

Epoch: 6| Step: 1
Training loss: 2.9630579942015904
Validation loss: 2.52767372059907

Epoch: 6| Step: 2
Training loss: 3.0557547263535136
Validation loss: 2.5718959829572734

Epoch: 6| Step: 3
Training loss: 2.450994842337104
Validation loss: 2.5647423510211564

Epoch: 6| Step: 4
Training loss: 2.4477192792377953
Validation loss: 2.6104116136323765

Epoch: 6| Step: 5
Training loss: 3.3874705183146867
Validation loss: 2.62082452147674

Epoch: 6| Step: 6
Training loss: 2.5753195555092345
Validation loss: 2.6408892617804067

Epoch: 6| Step: 7
Training loss: 2.780501790076813
Validation loss: 2.5856268529827746

Epoch: 6| Step: 8
Training loss: 2.218458666949671
Validation loss: 2.569770688807071

Epoch: 6| Step: 9
Training loss: 3.288476887305472
Validation loss: 2.6048564314060805

Epoch: 6| Step: 10
Training loss: 3.026202531873241
Validation loss: 2.5968597407317366

Epoch: 6| Step: 11
Training loss: 2.693192862051623
Validation loss: 2.5514922176739625

Epoch: 6| Step: 12
Training loss: 2.832719137901497
Validation loss: 2.5752067489289505

Epoch: 6| Step: 13
Training loss: 2.211463461277162
Validation loss: 2.6241271056523816

Epoch: 146| Step: 0
Training loss: 2.9679201271229396
Validation loss: 2.5986744103761312

Epoch: 6| Step: 1
Training loss: 3.191997571346726
Validation loss: 2.598177076518474

Epoch: 6| Step: 2
Training loss: 3.6415032240258722
Validation loss: 2.5916821801181236

Epoch: 6| Step: 3
Training loss: 2.3872834831443965
Validation loss: 2.605687259507624

Epoch: 6| Step: 4
Training loss: 2.1720111173060723
Validation loss: 2.6512858244146047

Epoch: 6| Step: 5
Training loss: 2.975325039329425
Validation loss: 2.6339062872214156

Epoch: 6| Step: 6
Training loss: 3.060700647012471
Validation loss: 2.7019470463079

Epoch: 6| Step: 7
Training loss: 2.973332612617759
Validation loss: 2.5696119275134963

Epoch: 6| Step: 8
Training loss: 1.7605589709428187
Validation loss: 2.586685540896129

Epoch: 6| Step: 9
Training loss: 2.9792276300626166
Validation loss: 2.570101915396584

Epoch: 6| Step: 10
Training loss: 2.122763185752392
Validation loss: 2.5854089861878826

Epoch: 6| Step: 11
Training loss: 2.700414456240677
Validation loss: 2.620260526754237

Epoch: 6| Step: 12
Training loss: 2.4555168397171045
Validation loss: 2.6487345745316544

Epoch: 6| Step: 13
Training loss: 2.6996576198086073
Validation loss: 2.6196301515530753

Epoch: 147| Step: 0
Training loss: 2.1388102168797833
Validation loss: 2.664055704193498

Epoch: 6| Step: 1
Training loss: 3.496065244078968
Validation loss: 2.5886614368561847

Epoch: 6| Step: 2
Training loss: 3.0644605939201526
Validation loss: 2.5868492451104923

Epoch: 6| Step: 3
Training loss: 2.809428933106474
Validation loss: 2.5545427634432696

Epoch: 6| Step: 4
Training loss: 2.7084479870124976
Validation loss: 2.562193275180612

Epoch: 6| Step: 5
Training loss: 3.0512748055268264
Validation loss: 2.5803940091603694

Epoch: 6| Step: 6
Training loss: 2.8116140029699626
Validation loss: 2.5767876331854214

Epoch: 6| Step: 7
Training loss: 2.4798214045175153
Validation loss: 2.606977056906383

Epoch: 6| Step: 8
Training loss: 2.982603496025235
Validation loss: 2.5154364801920415

Epoch: 6| Step: 9
Training loss: 2.0106068918102253
Validation loss: 2.6006722245425253

Epoch: 6| Step: 10
Training loss: 2.5299637905741283
Validation loss: 2.6118366217813245

Epoch: 6| Step: 11
Training loss: 2.293372565458788
Validation loss: 2.5747368458766666

Epoch: 6| Step: 12
Training loss: 2.985766341146088
Validation loss: 2.561477754365281

Epoch: 6| Step: 13
Training loss: 2.625362098787471
Validation loss: 2.5848718468667466

Epoch: 148| Step: 0
Training loss: 2.8674120074526086
Validation loss: 2.5310987627127575

Epoch: 6| Step: 1
Training loss: 2.3768961514844116
Validation loss: 2.5955516944130195

Epoch: 6| Step: 2
Training loss: 2.913646842213822
Validation loss: 2.5248620297622244

Epoch: 6| Step: 3
Training loss: 2.7972861898769263
Validation loss: 2.595152812486495

Epoch: 6| Step: 4
Training loss: 2.832708869633464
Validation loss: 2.516130738327462

Epoch: 6| Step: 5
Training loss: 2.434840879313156
Validation loss: 2.609748176513566

Epoch: 6| Step: 6
Training loss: 3.197365099198977
Validation loss: 2.4949335700200392

Epoch: 6| Step: 7
Training loss: 3.366757535809735
Validation loss: 2.5785580208961068

Epoch: 6| Step: 8
Training loss: 2.672856379300099
Validation loss: 2.5692803434032707

Epoch: 6| Step: 9
Training loss: 2.62786581641538
Validation loss: 2.5793266978573435

Epoch: 6| Step: 10
Training loss: 2.960558059254504
Validation loss: 2.532925056476404

Epoch: 6| Step: 11
Training loss: 2.73710391519208
Validation loss: 2.5307885887189014

Epoch: 6| Step: 12
Training loss: 2.3529279932886946
Validation loss: 2.563003820657124

Epoch: 6| Step: 13
Training loss: 2.454032389967235
Validation loss: 2.5552619026667167

Epoch: 149| Step: 0
Training loss: 2.817513638372846
Validation loss: 2.540107050514631

Epoch: 6| Step: 1
Training loss: 2.865521271636825
Validation loss: 2.5463387600277003

Epoch: 6| Step: 2
Training loss: 2.7157902885678586
Validation loss: 2.592220500359256

Epoch: 6| Step: 3
Training loss: 2.513521819834023
Validation loss: 2.616507012065001

Epoch: 6| Step: 4
Training loss: 2.0127862856987506
Validation loss: 2.522037017026117

Epoch: 6| Step: 5
Training loss: 2.6969438563957504
Validation loss: 2.633192786934894

Epoch: 6| Step: 6
Training loss: 2.4110770421861125
Validation loss: 2.5680585290967133

Epoch: 6| Step: 7
Training loss: 3.08488488896056
Validation loss: 2.567130106922399

Epoch: 6| Step: 8
Training loss: 2.582969598902112
Validation loss: 2.514282229971892

Epoch: 6| Step: 9
Training loss: 2.8660325886802895
Validation loss: 2.5409034424963135

Epoch: 6| Step: 10
Training loss: 3.197529142841974
Validation loss: 2.608076220732749

Epoch: 6| Step: 11
Training loss: 2.6106729534367012
Validation loss: 2.6001543252452217

Epoch: 6| Step: 12
Training loss: 3.7348637600196612
Validation loss: 2.663070506049639

Epoch: 6| Step: 13
Training loss: 3.1633518504119005
Validation loss: 2.556198736341134

Epoch: 150| Step: 0
Training loss: 3.1840424578342255
Validation loss: 2.577876586481032

Epoch: 6| Step: 1
Training loss: 2.4863747279975525
Validation loss: 2.575039297931616

Epoch: 6| Step: 2
Training loss: 2.646246169515008
Validation loss: 2.6053222422205278

Epoch: 6| Step: 3
Training loss: 2.9042604260700386
Validation loss: 2.5484378462935986

Epoch: 6| Step: 4
Training loss: 2.9667754985549015
Validation loss: 2.6087716976938196

Epoch: 6| Step: 5
Training loss: 2.860007627783787
Validation loss: 2.5966712709548476

Epoch: 6| Step: 6
Training loss: 2.5296683373765116
Validation loss: 2.583056385095269

Epoch: 6| Step: 7
Training loss: 2.8883961925794766
Validation loss: 2.5463662977303034

Epoch: 6| Step: 8
Training loss: 2.6172611055414547
Validation loss: 2.542988737087729

Epoch: 6| Step: 9
Training loss: 2.345337597066543
Validation loss: 2.5622927524126817

Epoch: 6| Step: 10
Training loss: 3.4266597095621734
Validation loss: 2.6216112423765967

Epoch: 6| Step: 11
Training loss: 2.6686564015897765
Validation loss: 2.5606482513349316

Epoch: 6| Step: 12
Training loss: 2.6065071473088595
Validation loss: 2.6330534270133343

Epoch: 6| Step: 13
Training loss: 2.344407053082291
Validation loss: 2.588881060945977

Epoch: 151| Step: 0
Training loss: 2.2445024509089384
Validation loss: 2.5458629818769487

Epoch: 6| Step: 1
Training loss: 2.3350757042581507
Validation loss: 2.536539283706058

Epoch: 6| Step: 2
Training loss: 2.5828369545629863
Validation loss: 2.5593204025340306

Epoch: 6| Step: 3
Training loss: 3.2201471351984305
Validation loss: 2.51057684650356

Epoch: 6| Step: 4
Training loss: 2.9670193094692983
Validation loss: 2.5379636304097337

Epoch: 6| Step: 5
Training loss: 3.169920822021159
Validation loss: 2.5780658584627756

Epoch: 6| Step: 6
Training loss: 2.8816080859708895
Validation loss: 2.5489822770435846

Epoch: 6| Step: 7
Training loss: 2.3582039257261145
Validation loss: 2.5413503290290347

Epoch: 6| Step: 8
Training loss: 2.6600598109124984
Validation loss: 2.521243842421432

Epoch: 6| Step: 9
Training loss: 2.6362488730633036
Validation loss: 2.5051421042717905

Epoch: 6| Step: 10
Training loss: 3.1811942764528123
Validation loss: 2.568832042415773

Epoch: 6| Step: 11
Training loss: 3.0696964956355837
Validation loss: 2.5693297173110268

Epoch: 6| Step: 12
Training loss: 2.573906145810804
Validation loss: 2.6009653693288266

Epoch: 6| Step: 13
Training loss: 2.387029299846656
Validation loss: 2.623180976999548

Epoch: 152| Step: 0
Training loss: 2.275971668368762
Validation loss: 2.530802292288128

Epoch: 6| Step: 1
Training loss: 3.76510426573235
Validation loss: 2.597504320373293

Epoch: 6| Step: 2
Training loss: 2.5262101474432823
Validation loss: 2.562538051647847

Epoch: 6| Step: 3
Training loss: 2.5078234330649045
Validation loss: 2.5379529564791707

Epoch: 6| Step: 4
Training loss: 2.644202162581205
Validation loss: 2.495465056063215

Epoch: 6| Step: 5
Training loss: 3.3310174685512317
Validation loss: 2.600522006036051

Epoch: 6| Step: 6
Training loss: 2.5570589310557725
Validation loss: 2.628324176451074

Epoch: 6| Step: 7
Training loss: 2.2324953509343217
Validation loss: 2.5596632964454495

Epoch: 6| Step: 8
Training loss: 2.9897532309572044
Validation loss: 2.5153469817906626

Epoch: 6| Step: 9
Training loss: 2.990508960796555
Validation loss: 2.553442158353334

Epoch: 6| Step: 10
Training loss: 2.316033010020241
Validation loss: 2.562685487818398

Epoch: 6| Step: 11
Training loss: 3.1972134259063623
Validation loss: 2.5408119837074774

Epoch: 6| Step: 12
Training loss: 2.564658860541372
Validation loss: 2.5076016333057383

Epoch: 6| Step: 13
Training loss: 2.4763873787466046
Validation loss: 2.5276570314015765

Epoch: 153| Step: 0
Training loss: 3.2340376673423368
Validation loss: 2.5502073570809656

Epoch: 6| Step: 1
Training loss: 2.7128011580257483
Validation loss: 2.604084764402697

Epoch: 6| Step: 2
Training loss: 2.9677090074550248
Validation loss: 2.511455356920761

Epoch: 6| Step: 3
Training loss: 2.39458959611063
Validation loss: 2.606553470325416

Epoch: 6| Step: 4
Training loss: 2.7033599575000093
Validation loss: 2.5607477795762934

Epoch: 6| Step: 5
Training loss: 3.051751406243276
Validation loss: 2.5147833185831963

Epoch: 6| Step: 6
Training loss: 2.710571967994349
Validation loss: 2.5659769681607396

Epoch: 6| Step: 7
Training loss: 2.928532324340476
Validation loss: 2.5022337307077596

Epoch: 6| Step: 8
Training loss: 3.0781559821568956
Validation loss: 2.574311360198311

Epoch: 6| Step: 9
Training loss: 2.5575041103236784
Validation loss: 2.560409311299527

Epoch: 6| Step: 10
Training loss: 2.3233402932207388
Validation loss: 2.543864575965414

Epoch: 6| Step: 11
Training loss: 2.5161081170048156
Validation loss: 2.5482021738868927

Epoch: 6| Step: 12
Training loss: 2.5424314713596625
Validation loss: 2.555812921341196

Epoch: 6| Step: 13
Training loss: 2.4488912603771054
Validation loss: 2.6041573128480997

Epoch: 154| Step: 0
Training loss: 2.9030177693021924
Validation loss: 2.617584505000605

Epoch: 6| Step: 1
Training loss: 3.173643774694127
Validation loss: 2.517578926399106

Epoch: 6| Step: 2
Training loss: 2.5973555541422875
Validation loss: 2.59886525920209

Epoch: 6| Step: 3
Training loss: 3.314456577782527
Validation loss: 2.550707724135186

Epoch: 6| Step: 4
Training loss: 3.250685986234831
Validation loss: 2.6084702870935215

Epoch: 6| Step: 5
Training loss: 2.574251721739714
Validation loss: 2.5925870409048435

Epoch: 6| Step: 6
Training loss: 2.658396672497761
Validation loss: 2.561028593071309

Epoch: 6| Step: 7
Training loss: 2.8909672714909007
Validation loss: 2.6281014396748135

Epoch: 6| Step: 8
Training loss: 2.5824044516244973
Validation loss: 2.5407971939654406

Epoch: 6| Step: 9
Training loss: 2.831928203944253
Validation loss: 2.629577696272949

Epoch: 6| Step: 10
Training loss: 2.569236646159658
Validation loss: 2.537482418506768

Epoch: 6| Step: 11
Training loss: 1.9705186801035621
Validation loss: 2.5570490075597045

Epoch: 6| Step: 12
Training loss: 2.5431810047267054
Validation loss: 2.5150889724484062

Epoch: 6| Step: 13
Training loss: 2.342274519288048
Validation loss: 2.5175525829428858

Epoch: 155| Step: 0
Training loss: 1.859990699191066
Validation loss: 2.598311819765098

Epoch: 6| Step: 1
Training loss: 3.540018723001914
Validation loss: 2.5282291402616686

Epoch: 6| Step: 2
Training loss: 2.107641567484791
Validation loss: 2.626474186286132

Epoch: 6| Step: 3
Training loss: 2.578598533838131
Validation loss: 2.5270883837197826

Epoch: 6| Step: 4
Training loss: 2.922226175838192
Validation loss: 2.582182709511102

Epoch: 6| Step: 5
Training loss: 2.8538481448754047
Validation loss: 2.5194041693307856

Epoch: 6| Step: 6
Training loss: 2.5929511804953775
Validation loss: 2.549730296935402

Epoch: 6| Step: 7
Training loss: 3.636910176386477
Validation loss: 2.5898246452000437

Epoch: 6| Step: 8
Training loss: 3.177280123926891
Validation loss: 2.609248798775115

Epoch: 6| Step: 9
Training loss: 2.7457115374013075
Validation loss: 2.557979989255874

Epoch: 6| Step: 10
Training loss: 2.4304227544441366
Validation loss: 2.5943438683688638

Epoch: 6| Step: 11
Training loss: 2.5255769806893995
Validation loss: 2.550858056113835

Epoch: 6| Step: 12
Training loss: 2.843376386643711
Validation loss: 2.563044823514438

Epoch: 6| Step: 13
Training loss: 1.6714649588894066
Validation loss: 2.6215051648712753

Epoch: 156| Step: 0
Training loss: 3.181628035771594
Validation loss: 2.5748688491282956

Epoch: 6| Step: 1
Training loss: 2.6271201155102064
Validation loss: 2.5956424520952432

Epoch: 6| Step: 2
Training loss: 2.637936459265567
Validation loss: 2.574236741699373

Epoch: 6| Step: 3
Training loss: 2.7465130633702044
Validation loss: 2.5324925662285316

Epoch: 6| Step: 4
Training loss: 2.427623203030807
Validation loss: 2.514842465612369

Epoch: 6| Step: 5
Training loss: 2.700699175270885
Validation loss: 2.5691937234935347

Epoch: 6| Step: 6
Training loss: 2.2596280411336163
Validation loss: 2.569169673475339

Epoch: 6| Step: 7
Training loss: 2.6403035526889322
Validation loss: 2.5586423572293335

Epoch: 6| Step: 8
Training loss: 2.8324955842403727
Validation loss: 2.523327005844169

Epoch: 6| Step: 9
Training loss: 3.122073672581864
Validation loss: 2.529427799585445

Epoch: 6| Step: 10
Training loss: 2.4968290245970124
Validation loss: 2.4983580108973467

Epoch: 6| Step: 11
Training loss: 2.9052529214086533
Validation loss: 2.571218982620141

Epoch: 6| Step: 12
Training loss: 2.67632739208628
Validation loss: 2.5169931089058952

Epoch: 6| Step: 13
Training loss: 3.365028202341144
Validation loss: 2.503317933359712

Epoch: 157| Step: 0
Training loss: 2.7107382049740183
Validation loss: 2.534332920853668

Epoch: 6| Step: 1
Training loss: 2.716886473658458
Validation loss: 2.535081249579847

Epoch: 6| Step: 2
Training loss: 2.824358376076101
Validation loss: 2.591485839210371

Epoch: 6| Step: 3
Training loss: 2.8453642905903966
Validation loss: 2.6315006641689194

Epoch: 6| Step: 4
Training loss: 2.738667459502039
Validation loss: 2.5949945489707344

Epoch: 6| Step: 5
Training loss: 2.35535801363094
Validation loss: 2.6054402980612186

Epoch: 6| Step: 6
Training loss: 2.0724315235343167
Validation loss: 2.606975572990439

Epoch: 6| Step: 7
Training loss: 2.929697916648148
Validation loss: 2.579019500092493

Epoch: 6| Step: 8
Training loss: 2.494424897843967
Validation loss: 2.526897277819049

Epoch: 6| Step: 9
Training loss: 2.431676412418629
Validation loss: 2.659819762457305

Epoch: 6| Step: 10
Training loss: 3.5541133207288187
Validation loss: 2.58571803139976

Epoch: 6| Step: 11
Training loss: 2.9801874790486456
Validation loss: 2.5819794073757207

Epoch: 6| Step: 12
Training loss: 2.581597042076608
Validation loss: 2.518827259651131

Epoch: 6| Step: 13
Training loss: 3.9290062255033327
Validation loss: 2.6188453386182653

Epoch: 158| Step: 0
Training loss: 2.9335534388874858
Validation loss: 2.555854199044516

Epoch: 6| Step: 1
Training loss: 2.8060338606147472
Validation loss: 2.5980788617510235

Epoch: 6| Step: 2
Training loss: 2.7970742948482576
Validation loss: 2.5737146116106

Epoch: 6| Step: 3
Training loss: 3.120651271044035
Validation loss: 2.5834166324482184

Epoch: 6| Step: 4
Training loss: 2.656739672236472
Validation loss: 2.5731614725295286

Epoch: 6| Step: 5
Training loss: 2.5715583170598233
Validation loss: 2.564349527739679

Epoch: 6| Step: 6
Training loss: 2.5548733051637282
Validation loss: 2.526423231729248

Epoch: 6| Step: 7
Training loss: 2.20581647811962
Validation loss: 2.5559730783552874

Epoch: 6| Step: 8
Training loss: 3.2752282973061737
Validation loss: 2.5106442732566965

Epoch: 6| Step: 9
Training loss: 2.6760640461303797
Validation loss: 2.5617763368843973

Epoch: 6| Step: 10
Training loss: 2.9227208835742853
Validation loss: 2.5884641210396526

Epoch: 6| Step: 11
Training loss: 2.7991350302498845
Validation loss: 2.5334809899678423

Epoch: 6| Step: 12
Training loss: 3.0873068559906507
Validation loss: 2.6069758414524316

Epoch: 6| Step: 13
Training loss: 2.1370136399215363
Validation loss: 2.5397758457423025

Epoch: 159| Step: 0
Training loss: 2.745987305402759
Validation loss: 2.4861478871758553

Epoch: 6| Step: 1
Training loss: 1.600663020923556
Validation loss: 2.548524629462467

Epoch: 6| Step: 2
Training loss: 2.8923873889996883
Validation loss: 2.581829557930713

Epoch: 6| Step: 3
Training loss: 2.741659347230674
Validation loss: 2.5475611826491846

Epoch: 6| Step: 4
Training loss: 2.6439920661795693
Validation loss: 2.55506022559384

Epoch: 6| Step: 5
Training loss: 3.052012020662366
Validation loss: 2.5667090694385886

Epoch: 6| Step: 6
Training loss: 2.881625295429945
Validation loss: 2.5597590061468845

Epoch: 6| Step: 7
Training loss: 2.420053005899062
Validation loss: 2.604989349036099

Epoch: 6| Step: 8
Training loss: 2.3643561322686844
Validation loss: 2.568702787899515

Epoch: 6| Step: 9
Training loss: 2.1981674581575406
Validation loss: 2.540142876134611

Epoch: 6| Step: 10
Training loss: 3.151195141966601
Validation loss: 2.5262893100361246

Epoch: 6| Step: 11
Training loss: 2.9167085553748886
Validation loss: 2.6044898832176484

Epoch: 6| Step: 12
Training loss: 3.3005698954614884
Validation loss: 2.538472826869235

Epoch: 6| Step: 13
Training loss: 2.942474698044626
Validation loss: 2.562467851494656

Epoch: 160| Step: 0
Training loss: 2.5652940915404865
Validation loss: 2.6157112269187923

Epoch: 6| Step: 1
Training loss: 2.688344423571149
Validation loss: 2.574065011248294

Epoch: 6| Step: 2
Training loss: 2.5918450771469086
Validation loss: 2.5361521064511843

Epoch: 6| Step: 3
Training loss: 2.4606916032283954
Validation loss: 2.613438524811964

Epoch: 6| Step: 4
Training loss: 2.4712656458821036
Validation loss: 2.582656956057176

Epoch: 6| Step: 5
Training loss: 3.3316382548685732
Validation loss: 2.513849568320577

Epoch: 6| Step: 6
Training loss: 2.7746847437584856
Validation loss: 2.5536768090839215

Epoch: 6| Step: 7
Training loss: 2.7655870682868384
Validation loss: 2.5589224139533107

Epoch: 6| Step: 8
Training loss: 2.088747681868138
Validation loss: 2.5209232027175

Epoch: 6| Step: 9
Training loss: 2.5384088701950986
Validation loss: 2.6054988713657337

Epoch: 6| Step: 10
Training loss: 2.8698777718385444
Validation loss: 2.6061681295918304

Epoch: 6| Step: 11
Training loss: 2.684971440481249
Validation loss: 2.543982482793544

Epoch: 6| Step: 12
Training loss: 2.592081567440424
Validation loss: 2.483241983707238

Epoch: 6| Step: 13
Training loss: 4.388381330433118
Validation loss: 2.5376536449045157

Epoch: 161| Step: 0
Training loss: 2.6635084722780538
Validation loss: 2.548974569964541

Epoch: 6| Step: 1
Training loss: 3.199265252638218
Validation loss: 2.5745809817654703

Epoch: 6| Step: 2
Training loss: 2.8757508997311794
Validation loss: 2.581019377109854

Epoch: 6| Step: 3
Training loss: 2.6363986350818656
Validation loss: 2.573578446064934

Epoch: 6| Step: 4
Training loss: 2.987770745047782
Validation loss: 2.588389335093948

Epoch: 6| Step: 5
Training loss: 2.844108307451416
Validation loss: 2.5857873088644903

Epoch: 6| Step: 6
Training loss: 2.518813677188741
Validation loss: 2.556695873259833

Epoch: 6| Step: 7
Training loss: 2.3853140285571506
Validation loss: 2.5740410510641634

Epoch: 6| Step: 8
Training loss: 2.763660401229495
Validation loss: 2.50696486807899

Epoch: 6| Step: 9
Training loss: 2.5785793944380324
Validation loss: 2.5970777515248935

Epoch: 6| Step: 10
Training loss: 2.451805586035293
Validation loss: 2.5421988725024964

Epoch: 6| Step: 11
Training loss: 2.5462447246633575
Validation loss: 2.536647125479771

Epoch: 6| Step: 12
Training loss: 3.4398368521748353
Validation loss: 2.540261510768295

Epoch: 6| Step: 13
Training loss: 2.0228238740245
Validation loss: 2.541927189808489

Epoch: 162| Step: 0
Training loss: 2.4468000963226944
Validation loss: 2.5776355774804567

Epoch: 6| Step: 1
Training loss: 2.607979224139817
Validation loss: 2.5608467803789217

Epoch: 6| Step: 2
Training loss: 3.2274130376776204
Validation loss: 2.6120462953807535

Epoch: 6| Step: 3
Training loss: 2.4345411290494154
Validation loss: 2.5711340203681505

Epoch: 6| Step: 4
Training loss: 2.9904332210073172
Validation loss: 2.510616494862756

Epoch: 6| Step: 5
Training loss: 2.716619950655378
Validation loss: 2.623656345531637

Epoch: 6| Step: 6
Training loss: 2.7086718323276746
Validation loss: 2.495861350188547

Epoch: 6| Step: 7
Training loss: 2.4061923329762993
Validation loss: 2.6311686291923793

Epoch: 6| Step: 8
Training loss: 3.33065184184558
Validation loss: 2.533530326911712

Epoch: 6| Step: 9
Training loss: 3.019111633753855
Validation loss: 2.533779289927475

Epoch: 6| Step: 10
Training loss: 2.5202270493326564
Validation loss: 2.577886606818303

Epoch: 6| Step: 11
Training loss: 2.8104779922283334
Validation loss: 2.4988681723003707

Epoch: 6| Step: 12
Training loss: 2.4635086433718913
Validation loss: 2.532004912891283

Epoch: 6| Step: 13
Training loss: 2.5022264103527867
Validation loss: 2.599915988770139

Epoch: 163| Step: 0
Training loss: 2.8512795503883672
Validation loss: 2.537983662974354

Epoch: 6| Step: 1
Training loss: 2.4900919076893997
Validation loss: 2.560976461425364

Epoch: 6| Step: 2
Training loss: 2.633802278829929
Validation loss: 2.5712084946021907

Epoch: 6| Step: 3
Training loss: 3.3520976886398417
Validation loss: 2.5568551116825278

Epoch: 6| Step: 4
Training loss: 2.177198513458154
Validation loss: 2.5514625107284523

Epoch: 6| Step: 5
Training loss: 2.5565516585337105
Validation loss: 2.595889911625281

Epoch: 6| Step: 6
Training loss: 2.9473552551190583
Validation loss: 2.5838509592475236

Epoch: 6| Step: 7
Training loss: 2.8155690720028073
Validation loss: 2.552871657351961

Epoch: 6| Step: 8
Training loss: 2.6524912550168143
Validation loss: 2.5665682241480123

Epoch: 6| Step: 9
Training loss: 2.4887048190128893
Validation loss: 2.5165948696879066

Epoch: 6| Step: 10
Training loss: 2.316885012575942
Validation loss: 2.5311741434588506

Epoch: 6| Step: 11
Training loss: 3.0518417175965555
Validation loss: 2.535533659584265

Epoch: 6| Step: 12
Training loss: 3.016390688445274
Validation loss: 2.5177030607533486

Epoch: 6| Step: 13
Training loss: 2.870386153238127
Validation loss: 2.542949678143372

Epoch: 164| Step: 0
Training loss: 2.8364919745703068
Validation loss: 2.562734243519918

Epoch: 6| Step: 1
Training loss: 2.5382753061569567
Validation loss: 2.549106818118191

Epoch: 6| Step: 2
Training loss: 2.897740035955435
Validation loss: 2.506752618989172

Epoch: 6| Step: 3
Training loss: 3.0063039984978692
Validation loss: 2.6193956454055725

Epoch: 6| Step: 4
Training loss: 2.4323797979187467
Validation loss: 2.554831208853992

Epoch: 6| Step: 5
Training loss: 2.4920518413680557
Validation loss: 2.563181073559466

Epoch: 6| Step: 6
Training loss: 2.680907747348364
Validation loss: 2.604836489928784

Epoch: 6| Step: 7
Training loss: 2.422214804160671
Validation loss: 2.5558021800215935

Epoch: 6| Step: 8
Training loss: 2.832894029406703
Validation loss: 2.5556961200441775

Epoch: 6| Step: 9
Training loss: 2.842789036961236
Validation loss: 2.5882735779687946

Epoch: 6| Step: 10
Training loss: 2.6807371702804152
Validation loss: 2.5684529710148816

Epoch: 6| Step: 11
Training loss: 2.455295647185465
Validation loss: 2.630497331234746

Epoch: 6| Step: 12
Training loss: 3.234144856838835
Validation loss: 2.554009865905427

Epoch: 6| Step: 13
Training loss: 3.5083918103730625
Validation loss: 2.565990946883345

Epoch: 165| Step: 0
Training loss: 3.2875715124670615
Validation loss: 2.5886183183248686

Epoch: 6| Step: 1
Training loss: 2.522471334485445
Validation loss: 2.493480416819254

Epoch: 6| Step: 2
Training loss: 3.9961920732649703
Validation loss: 2.5004763159711203

Epoch: 6| Step: 3
Training loss: 2.7863767712976646
Validation loss: 2.629545328568791

Epoch: 6| Step: 4
Training loss: 1.9374844335115282
Validation loss: 2.540495455553823

Epoch: 6| Step: 5
Training loss: 3.0663938096881407
Validation loss: 2.5882634373853315

Epoch: 6| Step: 6
Training loss: 2.443181873829621
Validation loss: 2.565712162810607

Epoch: 6| Step: 7
Training loss: 2.5486299050377603
Validation loss: 2.5698712633452803

Epoch: 6| Step: 8
Training loss: 2.595365641564889
Validation loss: 2.600649043289117

Epoch: 6| Step: 9
Training loss: 3.004006253922984
Validation loss: 2.526598851253304

Epoch: 6| Step: 10
Training loss: 2.7296497606573875
Validation loss: 2.5722814208086766

Epoch: 6| Step: 11
Training loss: 2.3597556306109224
Validation loss: 2.5731484946937084

Epoch: 6| Step: 12
Training loss: 2.219602394239379
Validation loss: 2.571737847801476

Epoch: 6| Step: 13
Training loss: 1.9389111701877697
Validation loss: 2.56758445023728

Epoch: 166| Step: 0
Training loss: 3.0871857641520073
Validation loss: 2.6192781128530367

Epoch: 6| Step: 1
Training loss: 2.9953792272069184
Validation loss: 2.51591432151339

Epoch: 6| Step: 2
Training loss: 2.3395808459093477
Validation loss: 2.540889593631902

Epoch: 6| Step: 3
Training loss: 2.6735688133251707
Validation loss: 2.5985338700959257

Epoch: 6| Step: 4
Training loss: 2.337183693276886
Validation loss: 2.5779841270503865

Epoch: 6| Step: 5
Training loss: 2.3995732404846897
Validation loss: 2.515697017844641

Epoch: 6| Step: 6
Training loss: 3.1105316924390864
Validation loss: 2.598428377761936

Epoch: 6| Step: 7
Training loss: 3.02442541419003
Validation loss: 2.6039200024021207

Epoch: 6| Step: 8
Training loss: 2.7530970040498928
Validation loss: 2.563875749969025

Epoch: 6| Step: 9
Training loss: 3.22893948319835
Validation loss: 2.580928556169954

Epoch: 6| Step: 10
Training loss: 2.250170595271547
Validation loss: 2.5062054313211726

Epoch: 6| Step: 11
Training loss: 2.784679398771584
Validation loss: 2.5940164438330005

Epoch: 6| Step: 12
Training loss: 2.9258239498511287
Validation loss: 2.53696074753772

Epoch: 6| Step: 13
Training loss: 2.2768934272483268
Validation loss: 2.5447029894338384

Epoch: 167| Step: 0
Training loss: 2.632973323630382
Validation loss: 2.5376220635779

Epoch: 6| Step: 1
Training loss: 2.368548615684474
Validation loss: 2.516111554741667

Epoch: 6| Step: 2
Training loss: 2.8195426080294745
Validation loss: 2.558086591422385

Epoch: 6| Step: 3
Training loss: 2.9024196527549635
Validation loss: 2.479069397044385

Epoch: 6| Step: 4
Training loss: 2.5357785629323097
Validation loss: 2.5695747099314104

Epoch: 6| Step: 5
Training loss: 2.7159900907130647
Validation loss: 2.590463601527225

Epoch: 6| Step: 6
Training loss: 2.6575001187113667
Validation loss: 2.552618563698774

Epoch: 6| Step: 7
Training loss: 2.3006779335023912
Validation loss: 2.5569473832492444

Epoch: 6| Step: 8
Training loss: 2.2968350361571663
Validation loss: 2.513786797414617

Epoch: 6| Step: 9
Training loss: 3.088883396604246
Validation loss: 2.5527331297019407

Epoch: 6| Step: 10
Training loss: 2.971051097305924
Validation loss: 2.5624147226393745

Epoch: 6| Step: 11
Training loss: 3.161150913699333
Validation loss: 2.586536441831643

Epoch: 6| Step: 12
Training loss: 3.0773286515480716
Validation loss: 2.5194898941068575

Epoch: 6| Step: 13
Training loss: 2.639691249826233
Validation loss: 2.573696358771223

Epoch: 168| Step: 0
Training loss: 3.082726925852733
Validation loss: 2.596931418938865

Epoch: 6| Step: 1
Training loss: 2.6745834454070248
Validation loss: 2.612117949435544

Epoch: 6| Step: 2
Training loss: 1.5716374818850378
Validation loss: 2.5494327004007307

Epoch: 6| Step: 3
Training loss: 2.3793806533205224
Validation loss: 2.6374522949159496

Epoch: 6| Step: 4
Training loss: 2.144216823631221
Validation loss: 2.5947523398026693

Epoch: 6| Step: 5
Training loss: 3.0369767040455757
Validation loss: 2.570936285710333

Epoch: 6| Step: 6
Training loss: 2.6551242013390133
Validation loss: 2.5665210430929815

Epoch: 6| Step: 7
Training loss: 2.8247165267639667
Validation loss: 2.5838290082034274

Epoch: 6| Step: 8
Training loss: 2.8251883925014627
Validation loss: 2.5540362358331037

Epoch: 6| Step: 9
Training loss: 2.9769672909529605
Validation loss: 2.5677346357979327

Epoch: 6| Step: 10
Training loss: 3.1324091244947194
Validation loss: 2.6407465238423358

Epoch: 6| Step: 11
Training loss: 2.899476392107491
Validation loss: 2.6020786431532845

Epoch: 6| Step: 12
Training loss: 2.5513641485893923
Validation loss: 2.5826118820067725

Epoch: 6| Step: 13
Training loss: 3.0399800854582764
Validation loss: 2.5740306054197437

Epoch: 169| Step: 0
Training loss: 3.0242704284083968
Validation loss: 2.563802034669731

Epoch: 6| Step: 1
Training loss: 3.5325846892596915
Validation loss: 2.6012118981951766

Epoch: 6| Step: 2
Training loss: 2.3957687590369283
Validation loss: 2.634223190770264

Epoch: 6| Step: 3
Training loss: 3.543301298607332
Validation loss: 2.554546728511475

Epoch: 6| Step: 4
Training loss: 1.954834213056726
Validation loss: 2.522312747850207

Epoch: 6| Step: 5
Training loss: 2.4519108969039234
Validation loss: 2.6166136253122168

Epoch: 6| Step: 6
Training loss: 2.5509397682367716
Validation loss: 2.6010300517835714

Epoch: 6| Step: 7
Training loss: 1.7902512245126092
Validation loss: 2.5284825571771377

Epoch: 6| Step: 8
Training loss: 2.021243994237391
Validation loss: 2.4865765693760973

Epoch: 6| Step: 9
Training loss: 3.003257095972517
Validation loss: 2.5758280147499795

Epoch: 6| Step: 10
Training loss: 2.7075034606291544
Validation loss: 2.5232542192305876

Epoch: 6| Step: 11
Training loss: 2.9016726964383595
Validation loss: 2.464026606933355

Epoch: 6| Step: 12
Training loss: 2.9531036860589968
Validation loss: 2.5271973652563045

Epoch: 6| Step: 13
Training loss: 2.584553604688874
Validation loss: 2.592191959379666

Epoch: 170| Step: 0
Training loss: 2.1708305646862844
Validation loss: 2.5723947832127627

Epoch: 6| Step: 1
Training loss: 2.790807439942713
Validation loss: 2.5061976305424865

Epoch: 6| Step: 2
Training loss: 2.6595174103561625
Validation loss: 2.537409832848317

Epoch: 6| Step: 3
Training loss: 2.3544168480013967
Validation loss: 2.5043930300567685

Epoch: 6| Step: 4
Training loss: 2.4054060607849026
Validation loss: 2.5954172316198085

Epoch: 6| Step: 5
Training loss: 2.594722978950527
Validation loss: 2.5377679621614506

Epoch: 6| Step: 6
Training loss: 3.5976194033977666
Validation loss: 2.600095836625865

Epoch: 6| Step: 7
Training loss: 2.5556450312149632
Validation loss: 2.612586518185834

Epoch: 6| Step: 8
Training loss: 2.5724587798824565
Validation loss: 2.5296337761525995

Epoch: 6| Step: 9
Training loss: 2.671539731769234
Validation loss: 2.511264961679259

Epoch: 6| Step: 10
Training loss: 3.569614467373012
Validation loss: 2.5856087323245753

Epoch: 6| Step: 11
Training loss: 2.3488071051817547
Validation loss: 2.540212465026422

Epoch: 6| Step: 12
Training loss: 2.5733962648072444
Validation loss: 2.548563554681905

Epoch: 6| Step: 13
Training loss: 2.900350510034035
Validation loss: 2.579536993503113

Epoch: 171| Step: 0
Training loss: 2.1538108630223536
Validation loss: 2.587320986042163

Epoch: 6| Step: 1
Training loss: 3.240685687329158
Validation loss: 2.5875720774146043

Epoch: 6| Step: 2
Training loss: 3.4720988561119297
Validation loss: 2.590225844120266

Epoch: 6| Step: 3
Training loss: 3.0904248796710214
Validation loss: 2.554808036120906

Epoch: 6| Step: 4
Training loss: 2.226019542145612
Validation loss: 2.551663227340067

Epoch: 6| Step: 5
Training loss: 2.5317868263939123
Validation loss: 2.528789902221104

Epoch: 6| Step: 6
Training loss: 3.0792418646674387
Validation loss: 2.5326449339587587

Epoch: 6| Step: 7
Training loss: 2.3278507352739206
Validation loss: 2.5625848013279358

Epoch: 6| Step: 8
Training loss: 2.934379381007945
Validation loss: 2.529831810441483

Epoch: 6| Step: 9
Training loss: 2.643504902906725
Validation loss: 2.5263799880790407

Epoch: 6| Step: 10
Training loss: 2.6674993724875886
Validation loss: 2.5013251125512745

Epoch: 6| Step: 11
Training loss: 2.711261125315752
Validation loss: 2.569432144963357

Epoch: 6| Step: 12
Training loss: 2.3339110295091694
Validation loss: 2.510427290541181

Epoch: 6| Step: 13
Training loss: 2.418201835872795
Validation loss: 2.564746510230377

Epoch: 172| Step: 0
Training loss: 2.792109686776421
Validation loss: 2.5434614233251507

Epoch: 6| Step: 1
Training loss: 2.264130724398286
Validation loss: 2.5224433509473045

Epoch: 6| Step: 2
Training loss: 2.2921347978042066
Validation loss: 2.572536305545539

Epoch: 6| Step: 3
Training loss: 2.6248145264995295
Validation loss: 2.5581031161694545

Epoch: 6| Step: 4
Training loss: 2.3515239725093453
Validation loss: 2.5867820118904525

Epoch: 6| Step: 5
Training loss: 2.785438298607661
Validation loss: 2.605766702324124

Epoch: 6| Step: 6
Training loss: 3.3343851019608866
Validation loss: 2.589801265880545

Epoch: 6| Step: 7
Training loss: 2.5888021684710614
Validation loss: 2.5632934162366627

Epoch: 6| Step: 8
Training loss: 2.3808008926882147
Validation loss: 2.5444761718959783

Epoch: 6| Step: 9
Training loss: 3.0447455374092005
Validation loss: 2.5828426350219083

Epoch: 6| Step: 10
Training loss: 2.4884086827774037
Validation loss: 2.598152675129053

Epoch: 6| Step: 11
Training loss: 3.0725352077468924
Validation loss: 2.5862063516077116

Epoch: 6| Step: 12
Training loss: 3.1578260962237454
Validation loss: 2.6555766855010408

Epoch: 6| Step: 13
Training loss: 2.3463086213078066
Validation loss: 2.620847762953198

Epoch: 173| Step: 0
Training loss: 2.51192282504692
Validation loss: 2.5765712795721023

Epoch: 6| Step: 1
Training loss: 2.338583273967075
Validation loss: 2.5842476284390954

Epoch: 6| Step: 2
Training loss: 2.5776068889310384
Validation loss: 2.557223014059562

Epoch: 6| Step: 3
Training loss: 2.3164958968674774
Validation loss: 2.5660329655168774

Epoch: 6| Step: 4
Training loss: 2.7532927134044494
Validation loss: 2.5934118689716095

Epoch: 6| Step: 5
Training loss: 2.6059979726296048
Validation loss: 2.5445518162584624

Epoch: 6| Step: 6
Training loss: 3.306975598388564
Validation loss: 2.610481071504247

Epoch: 6| Step: 7
Training loss: 2.2755415051907324
Validation loss: 2.595541767953951

Epoch: 6| Step: 8
Training loss: 3.8688190756009626
Validation loss: 2.5727841361101773

Epoch: 6| Step: 9
Training loss: 2.7027218909484585
Validation loss: 2.550304468095876

Epoch: 6| Step: 10
Training loss: 2.293504382711231
Validation loss: 2.58778075790064

Epoch: 6| Step: 11
Training loss: 2.8048771446101166
Validation loss: 2.5064751191591066

Epoch: 6| Step: 12
Training loss: 2.6137603639883373
Validation loss: 2.6709861886582007

Epoch: 6| Step: 13
Training loss: 2.620094984531345
Validation loss: 2.5229748225182633

Epoch: 174| Step: 0
Training loss: 2.891664060505362
Validation loss: 2.603562462066174

Epoch: 6| Step: 1
Training loss: 2.637444380765839
Validation loss: 2.627662747717537

Epoch: 6| Step: 2
Training loss: 3.3661892643721356
Validation loss: 2.5538844868308166

Epoch: 6| Step: 3
Training loss: 2.653764167420802
Validation loss: 2.4812141412766286

Epoch: 6| Step: 4
Training loss: 2.2771424193073297
Validation loss: 2.5610198381361307

Epoch: 6| Step: 5
Training loss: 2.587426071216573
Validation loss: 2.5493687899061883

Epoch: 6| Step: 6
Training loss: 2.57020545435101
Validation loss: 2.595802354059073

Epoch: 6| Step: 7
Training loss: 2.671224236013776
Validation loss: 2.637835576911022

Epoch: 6| Step: 8
Training loss: 2.051379888444924
Validation loss: 2.5369257106685086

Epoch: 6| Step: 9
Training loss: 3.387216005702487
Validation loss: 2.605820888359694

Epoch: 6| Step: 10
Training loss: 2.8159036174611534
Validation loss: 2.55785791079391

Epoch: 6| Step: 11
Training loss: 2.0931919549875984
Validation loss: 2.5017214365352607

Epoch: 6| Step: 12
Training loss: 2.9207346929926015
Validation loss: 2.52801533658207

Epoch: 6| Step: 13
Training loss: 2.3528054839865735
Validation loss: 2.537416071675509

Epoch: 175| Step: 0
Training loss: 3.101974498375868
Validation loss: 2.5549977055793316

Epoch: 6| Step: 1
Training loss: 3.129686427389981
Validation loss: 2.610853884703443

Epoch: 6| Step: 2
Training loss: 2.636864597384125
Validation loss: 2.556005173146251

Epoch: 6| Step: 3
Training loss: 2.224476904939755
Validation loss: 2.518965894286772

Epoch: 6| Step: 4
Training loss: 2.8160258762460364
Validation loss: 2.5414387926751894

Epoch: 6| Step: 5
Training loss: 2.1873803242235432
Validation loss: 2.610981911699394

Epoch: 6| Step: 6
Training loss: 1.771109645454144
Validation loss: 2.598667508682856

Epoch: 6| Step: 7
Training loss: 2.128029627070301
Validation loss: 2.584221125338668

Epoch: 6| Step: 8
Training loss: 2.332093817863549
Validation loss: 2.570786277218152

Epoch: 6| Step: 9
Training loss: 3.5949946362875873
Validation loss: 2.51467794931268

Epoch: 6| Step: 10
Training loss: 2.960115746477483
Validation loss: 2.5338678388177502

Epoch: 6| Step: 11
Training loss: 3.045482454210868
Validation loss: 2.6212395190614863

Epoch: 6| Step: 12
Training loss: 2.9415038397862987
Validation loss: 2.522947502000295

Epoch: 6| Step: 13
Training loss: 3.1087420408778197
Validation loss: 2.5489855537771646

Testing loss: 2.710018437750212
