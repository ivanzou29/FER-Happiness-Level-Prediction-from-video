Epoch: 1| Step: 0
Training loss: 6.467495856591583
Validation loss: 6.873129966772158

Epoch: 6| Step: 1
Training loss: 7.448567338455618
Validation loss: 6.869782736312974

Epoch: 6| Step: 2
Training loss: 6.785265880483068
Validation loss: 6.86417554777927

Epoch: 6| Step: 3
Training loss: 7.240930079790175
Validation loss: 6.863151780333492

Epoch: 6| Step: 4
Training loss: 6.589286269580376
Validation loss: 6.859139352738998

Epoch: 6| Step: 5
Training loss: 6.6855933778144605
Validation loss: 6.856709595756718

Epoch: 6| Step: 6
Training loss: 6.003688949792401
Validation loss: 6.8505213561914164

Epoch: 6| Step: 7
Training loss: 6.559312027932895
Validation loss: 6.846481448686684

Epoch: 6| Step: 8
Training loss: 7.523304146825684
Validation loss: 6.849769637873097

Epoch: 6| Step: 9
Training loss: 6.879717508770857
Validation loss: 6.840304186872567

Epoch: 6| Step: 10
Training loss: 5.907384047046279
Validation loss: 6.839164899738365

Epoch: 6| Step: 11
Training loss: 7.5899854834295875
Validation loss: 6.83695611530488

Epoch: 6| Step: 12
Training loss: 7.2082157309168755
Validation loss: 6.833673273130288

Epoch: 6| Step: 13
Training loss: 6.551808685546454
Validation loss: 6.829902587060462

Epoch: 2| Step: 0
Training loss: 6.739476796113446
Validation loss: 6.827292134177423

Epoch: 6| Step: 1
Training loss: 6.933642165323922
Validation loss: 6.8266060031434215

Epoch: 6| Step: 2
Training loss: 6.63460894768274
Validation loss: 6.8218921028940365

Epoch: 6| Step: 3
Training loss: 7.609926427016846
Validation loss: 6.819895683955655

Epoch: 6| Step: 4
Training loss: 7.815588744886671
Validation loss: 6.817005802979747

Epoch: 6| Step: 5
Training loss: 6.664717325682313
Validation loss: 6.812796911471772

Epoch: 6| Step: 6
Training loss: 6.951600737068922
Validation loss: 6.810350792378398

Epoch: 6| Step: 7
Training loss: 6.578244459648671
Validation loss: 6.805478259544683

Epoch: 6| Step: 8
Training loss: 6.820672129514792
Validation loss: 6.802650185197729

Epoch: 6| Step: 9
Training loss: 5.757962560056949
Validation loss: 6.801431373976016

Epoch: 6| Step: 10
Training loss: 5.885889229046157
Validation loss: 6.7972866229323206

Epoch: 6| Step: 11
Training loss: 6.83198378967935
Validation loss: 6.792566056311886

Epoch: 6| Step: 12
Training loss: 6.431786825984078
Validation loss: 6.79224994730861

Epoch: 6| Step: 13
Training loss: 7.63135301425147
Validation loss: 6.7877459578321755

Epoch: 3| Step: 0
Training loss: 6.199504881747299
Validation loss: 6.787431515886186

Epoch: 6| Step: 1
Training loss: 6.642713366474624
Validation loss: 6.7823057374074605

Epoch: 6| Step: 2
Training loss: 5.109689498694738
Validation loss: 6.778150958492691

Epoch: 6| Step: 3
Training loss: 7.355991760232697
Validation loss: 6.774540286607328

Epoch: 6| Step: 4
Training loss: 7.2739810924855925
Validation loss: 6.771087685123151

Epoch: 6| Step: 5
Training loss: 6.421429769484661
Validation loss: 6.769363512864855

Epoch: 6| Step: 6
Training loss: 7.018467928210983
Validation loss: 6.767594868475114

Epoch: 6| Step: 7
Training loss: 6.947294726885912
Validation loss: 6.762873522099004

Epoch: 6| Step: 8
Training loss: 6.906214649230793
Validation loss: 6.759709010333471

Epoch: 6| Step: 9
Training loss: 7.095430822001204
Validation loss: 6.757072981574219

Epoch: 6| Step: 10
Training loss: 6.767041205703383
Validation loss: 6.755343398597649

Epoch: 6| Step: 11
Training loss: 7.028557427156438
Validation loss: 6.748348509560687

Epoch: 6| Step: 12
Training loss: 6.114249311830259
Validation loss: 6.746760822828977

Epoch: 6| Step: 13
Training loss: 7.801043602013617
Validation loss: 6.743103618353447

Epoch: 4| Step: 0
Training loss: 7.009758006230187
Validation loss: 6.739646777299939

Epoch: 6| Step: 1
Training loss: 6.939307999643481
Validation loss: 6.7386053233829255

Epoch: 6| Step: 2
Training loss: 6.1594285843607155
Validation loss: 6.7316224482652345

Epoch: 6| Step: 3
Training loss: 6.280498706429677
Validation loss: 6.730038394567046

Epoch: 6| Step: 4
Training loss: 6.498442243100578
Validation loss: 6.723074392244274

Epoch: 6| Step: 5
Training loss: 5.852586562385459
Validation loss: 6.725810458612762

Epoch: 6| Step: 6
Training loss: 7.20776588396751
Validation loss: 6.721393170793277

Epoch: 6| Step: 7
Training loss: 6.152173236724399
Validation loss: 6.717767214791843

Epoch: 6| Step: 8
Training loss: 7.6206787872356
Validation loss: 6.7109006466962

Epoch: 6| Step: 9
Training loss: 6.456483571941161
Validation loss: 6.709939434088163

Epoch: 6| Step: 10
Training loss: 5.706646226745317
Validation loss: 6.702344869712552

Epoch: 6| Step: 11
Training loss: 7.673562417851572
Validation loss: 6.700073979740242

Epoch: 6| Step: 12
Training loss: 6.892389949436109
Validation loss: 6.696089474016187

Epoch: 6| Step: 13
Training loss: 7.455639940679058
Validation loss: 6.694129712919681

Epoch: 5| Step: 0
Training loss: 7.229382104072896
Validation loss: 6.690264046582707

Epoch: 6| Step: 1
Training loss: 6.114477344051409
Validation loss: 6.683412357788133

Epoch: 6| Step: 2
Training loss: 5.57891737495171
Validation loss: 6.6827479873356

Epoch: 6| Step: 3
Training loss: 6.676902859808311
Validation loss: 6.679323261056735

Epoch: 6| Step: 4
Training loss: 6.493071164289765
Validation loss: 6.672408425726381

Epoch: 6| Step: 5
Training loss: 7.956601205702221
Validation loss: 6.66685451837671

Epoch: 6| Step: 6
Training loss: 6.940794016683628
Validation loss: 6.668092308608386

Epoch: 6| Step: 7
Training loss: 6.746647037331796
Validation loss: 6.663264173366397

Epoch: 6| Step: 8
Training loss: 6.21922538128839
Validation loss: 6.660346315610711

Epoch: 6| Step: 9
Training loss: 6.291373677621196
Validation loss: 6.65321589295465

Epoch: 6| Step: 10
Training loss: 6.993585372228081
Validation loss: 6.6475439882418295

Epoch: 6| Step: 11
Training loss: 6.785811757699848
Validation loss: 6.64524671406273

Epoch: 6| Step: 12
Training loss: 6.483500741139124
Validation loss: 6.640480852004236

Epoch: 6| Step: 13
Training loss: 6.185307277981174
Validation loss: 6.638120179081482

Epoch: 6| Step: 0
Training loss: 6.185255472000025
Validation loss: 6.6303912697565

Epoch: 6| Step: 1
Training loss: 7.257480313980363
Validation loss: 6.627893034065655

Epoch: 6| Step: 2
Training loss: 7.580084918912828
Validation loss: 6.622019829022075

Epoch: 6| Step: 3
Training loss: 6.315989521271588
Validation loss: 6.620110135673044

Epoch: 6| Step: 4
Training loss: 5.372672353245825
Validation loss: 6.6125611580677495

Epoch: 6| Step: 5
Training loss: 6.125899268328131
Validation loss: 6.607157689198773

Epoch: 6| Step: 6
Training loss: 7.649562608768474
Validation loss: 6.607439061563844

Epoch: 6| Step: 7
Training loss: 7.214296494709253
Validation loss: 6.597757009675713

Epoch: 6| Step: 8
Training loss: 7.021334697205067
Validation loss: 6.596098963893159

Epoch: 6| Step: 9
Training loss: 5.195055870658908
Validation loss: 6.587911243393748

Epoch: 6| Step: 10
Training loss: 8.107758524463813
Validation loss: 6.585292387083807

Epoch: 6| Step: 11
Training loss: 6.115788598228576
Validation loss: 6.580093285347278

Epoch: 6| Step: 12
Training loss: 5.475267112869964
Validation loss: 6.578548514511584

Epoch: 6| Step: 13
Training loss: 5.28517573790753
Validation loss: 6.570971065774141

Epoch: 7| Step: 0
Training loss: 6.886090298094112
Validation loss: 6.567623996407002

Epoch: 6| Step: 1
Training loss: 7.128578224473756
Validation loss: 6.558616805782874

Epoch: 6| Step: 2
Training loss: 6.917117858632658
Validation loss: 6.5577941304283565

Epoch: 6| Step: 3
Training loss: 5.776266063279033
Validation loss: 6.54728209514023

Epoch: 6| Step: 4
Training loss: 6.218316911348355
Validation loss: 6.544695353001821

Epoch: 6| Step: 5
Training loss: 6.605621209801756
Validation loss: 6.539183758428436

Epoch: 6| Step: 6
Training loss: 6.552433685817144
Validation loss: 6.531670069895675

Epoch: 6| Step: 7
Training loss: 6.046447265637303
Validation loss: 6.526926713578816

Epoch: 6| Step: 8
Training loss: 6.636801518759926
Validation loss: 6.52575668305764

Epoch: 6| Step: 9
Training loss: 6.684295456935999
Validation loss: 6.516977919605373

Epoch: 6| Step: 10
Training loss: 7.195533044937064
Validation loss: 6.513127205825954

Epoch: 6| Step: 11
Training loss: 5.6070876704546935
Validation loss: 6.503438754631134

Epoch: 6| Step: 12
Training loss: 5.511148943737024
Validation loss: 6.499200524069436

Epoch: 6| Step: 13
Training loss: 7.764734105791555
Validation loss: 6.491158542141959

Epoch: 8| Step: 0
Training loss: 6.522971715687729
Validation loss: 6.487133629249753

Epoch: 6| Step: 1
Training loss: 6.513458696848906
Validation loss: 6.48387895394951

Epoch: 6| Step: 2
Training loss: 6.7102886059430285
Validation loss: 6.480548900203617

Epoch: 6| Step: 3
Training loss: 7.423582759938246
Validation loss: 6.467280030580175

Epoch: 6| Step: 4
Training loss: 6.4359712729942045
Validation loss: 6.464170751960836

Epoch: 6| Step: 5
Training loss: 6.1997780790912564
Validation loss: 6.459059355777248

Epoch: 6| Step: 6
Training loss: 7.448712784337619
Validation loss: 6.448939181832876

Epoch: 6| Step: 7
Training loss: 5.407566329260019
Validation loss: 6.442945267897791

Epoch: 6| Step: 8
Training loss: 5.768045387756137
Validation loss: 6.435064437878484

Epoch: 6| Step: 9
Training loss: 6.664431133561542
Validation loss: 6.429024331773646

Epoch: 6| Step: 10
Training loss: 5.909648260761208
Validation loss: 6.424398954354217

Epoch: 6| Step: 11
Training loss: 6.925415511352573
Validation loss: 6.416572670260769

Epoch: 6| Step: 12
Training loss: 5.318621171944313
Validation loss: 6.412503897708064

Epoch: 6| Step: 13
Training loss: 6.57936443331995
Validation loss: 6.40255006021555

Epoch: 9| Step: 0
Training loss: 5.359425892046086
Validation loss: 6.396801644536609

Epoch: 6| Step: 1
Training loss: 6.651367115809903
Validation loss: 6.3903309840470985

Epoch: 6| Step: 2
Training loss: 6.281796559709501
Validation loss: 6.381204856078196

Epoch: 6| Step: 3
Training loss: 5.937263564371427
Validation loss: 6.375235906873158

Epoch: 6| Step: 4
Training loss: 6.558426819086159
Validation loss: 6.373296900654642

Epoch: 6| Step: 5
Training loss: 5.412065850657268
Validation loss: 6.362059190267733

Epoch: 6| Step: 6
Training loss: 6.667491321422191
Validation loss: 6.353431722365541

Epoch: 6| Step: 7
Training loss: 7.128736620413371
Validation loss: 6.3442793986466866

Epoch: 6| Step: 8
Training loss: 6.302314926389864
Validation loss: 6.34242468515373

Epoch: 6| Step: 9
Training loss: 6.658439741688827
Validation loss: 6.33119606435887

Epoch: 6| Step: 10
Training loss: 6.787182722175617
Validation loss: 6.323992044275144

Epoch: 6| Step: 11
Training loss: 6.656782675190531
Validation loss: 6.315959238042265

Epoch: 6| Step: 12
Training loss: 5.918584306889098
Validation loss: 6.30862285597521

Epoch: 6| Step: 13
Training loss: 6.118566131167077
Validation loss: 6.300402465767763

Epoch: 10| Step: 0
Training loss: 6.696448782754097
Validation loss: 6.294575232504842

Epoch: 6| Step: 1
Training loss: 6.25332553128296
Validation loss: 6.279382111136366

Epoch: 6| Step: 2
Training loss: 6.378053420102994
Validation loss: 6.270574805644787

Epoch: 6| Step: 3
Training loss: 7.248906546380914
Validation loss: 6.266503718283893

Epoch: 6| Step: 4
Training loss: 7.114375977591928
Validation loss: 6.25568794254124

Epoch: 6| Step: 5
Training loss: 6.059334784025582
Validation loss: 6.24462503305346

Epoch: 6| Step: 6
Training loss: 5.166723353577424
Validation loss: 6.237459953959311

Epoch: 6| Step: 7
Training loss: 5.452436605904396
Validation loss: 6.226182105817645

Epoch: 6| Step: 8
Training loss: 6.809939682030993
Validation loss: 6.213571236594402

Epoch: 6| Step: 9
Training loss: 7.119202245961024
Validation loss: 6.205891492022428

Epoch: 6| Step: 10
Training loss: 6.080969921848791
Validation loss: 6.201159809964133

Epoch: 6| Step: 11
Training loss: 5.230648889495048
Validation loss: 6.187735902646537

Epoch: 6| Step: 12
Training loss: 3.9735531314971198
Validation loss: 6.177039336157632

Epoch: 6| Step: 13
Training loss: 7.091058027041599
Validation loss: 6.169427904809878

Epoch: 11| Step: 0
Training loss: 6.070596538560636
Validation loss: 6.160266779069019

Epoch: 6| Step: 1
Training loss: 5.575744804956992
Validation loss: 6.152045807051122

Epoch: 6| Step: 2
Training loss: 5.012866441074875
Validation loss: 6.145390991621768

Epoch: 6| Step: 3
Training loss: 6.5258112260624825
Validation loss: 6.130743187425204

Epoch: 6| Step: 4
Training loss: 6.3145023607151
Validation loss: 6.119908798308182

Epoch: 6| Step: 5
Training loss: 7.145983665671846
Validation loss: 6.110325451735249

Epoch: 6| Step: 6
Training loss: 6.647369621751419
Validation loss: 6.100562585352479

Epoch: 6| Step: 7
Training loss: 5.509218639766619
Validation loss: 6.091870924656251

Epoch: 6| Step: 8
Training loss: 6.496579664158954
Validation loss: 6.078159839051453

Epoch: 6| Step: 9
Training loss: 5.649994315085463
Validation loss: 6.071198486983023

Epoch: 6| Step: 10
Training loss: 6.481704787186947
Validation loss: 6.057728115597339

Epoch: 6| Step: 11
Training loss: 6.189586249160037
Validation loss: 6.049426821855754

Epoch: 6| Step: 12
Training loss: 4.8632359514080115
Validation loss: 6.034932251895832

Epoch: 6| Step: 13
Training loss: 6.440816969141451
Validation loss: 6.023748004087536

Epoch: 12| Step: 0
Training loss: 6.120081269466366
Validation loss: 6.0147866436127595

Epoch: 6| Step: 1
Training loss: 5.568313475345726
Validation loss: 6.002288785160709

Epoch: 6| Step: 2
Training loss: 5.497730827394906
Validation loss: 5.99249204255412

Epoch: 6| Step: 3
Training loss: 5.9670494013666096
Validation loss: 5.9773755982023005

Epoch: 6| Step: 4
Training loss: 4.667010067611962
Validation loss: 5.974535433883481

Epoch: 6| Step: 5
Training loss: 5.353086647123445
Validation loss: 5.952143957269003

Epoch: 6| Step: 6
Training loss: 5.744677526654904
Validation loss: 5.9408376469552575

Epoch: 6| Step: 7
Training loss: 5.43481677268527
Validation loss: 5.918176657921595

Epoch: 6| Step: 8
Training loss: 7.365080288347751
Validation loss: 5.921726925512445

Epoch: 6| Step: 9
Training loss: 5.927479851928603
Validation loss: 5.906571169809259

Epoch: 6| Step: 10
Training loss: 6.244052956746936
Validation loss: 5.888427620471507

Epoch: 6| Step: 11
Training loss: 6.369335275697774
Validation loss: 5.878636746342244

Epoch: 6| Step: 12
Training loss: 6.357064542088994
Validation loss: 5.861136048080572

Epoch: 6| Step: 13
Training loss: 5.918715144762734
Validation loss: 5.855300064326206

Epoch: 13| Step: 0
Training loss: 5.833334386916293
Validation loss: 5.840606400184492

Epoch: 6| Step: 1
Training loss: 4.185909367687871
Validation loss: 5.823178078105335

Epoch: 6| Step: 2
Training loss: 4.677087230156831
Validation loss: 5.8076102191248395

Epoch: 6| Step: 3
Training loss: 6.321234372953018
Validation loss: 5.796098273255779

Epoch: 6| Step: 4
Training loss: 5.414248860992609
Validation loss: 5.782523456458505

Epoch: 6| Step: 5
Training loss: 6.022385165147823
Validation loss: 5.767446073892545

Epoch: 6| Step: 6
Training loss: 5.661649539904012
Validation loss: 5.757062355680993

Epoch: 6| Step: 7
Training loss: 5.794710891529124
Validation loss: 5.738099608372948

Epoch: 6| Step: 8
Training loss: 4.698547163084093
Validation loss: 5.731623986638455

Epoch: 6| Step: 9
Training loss: 7.024177215287056
Validation loss: 5.716150625608417

Epoch: 6| Step: 10
Training loss: 6.180048607693715
Validation loss: 5.699710166023138

Epoch: 6| Step: 11
Training loss: 5.917302845167364
Validation loss: 5.683133184853965

Epoch: 6| Step: 12
Training loss: 6.1748120236839625
Validation loss: 5.671898572224106

Epoch: 6| Step: 13
Training loss: 5.7468203170191
Validation loss: 5.652524889132926

Epoch: 14| Step: 0
Training loss: 5.265072937955579
Validation loss: 5.63900071248808

Epoch: 6| Step: 1
Training loss: 4.950105823965487
Validation loss: 5.619361236978523

Epoch: 6| Step: 2
Training loss: 5.157083709824451
Validation loss: 5.603776909593978

Epoch: 6| Step: 3
Training loss: 6.949205575451256
Validation loss: 5.589847444679683

Epoch: 6| Step: 4
Training loss: 6.714486690168592
Validation loss: 5.566154031038953

Epoch: 6| Step: 5
Training loss: 4.518863770462767
Validation loss: 5.557498434166182

Epoch: 6| Step: 6
Training loss: 4.895881728345694
Validation loss: 5.529110411671015

Epoch: 6| Step: 7
Training loss: 5.808018423088006
Validation loss: 5.511286069607078

Epoch: 6| Step: 8
Training loss: 4.696908079882366
Validation loss: 5.517079320531299

Epoch: 6| Step: 9
Training loss: 3.9524383551696305
Validation loss: 5.478369650611424

Epoch: 6| Step: 10
Training loss: 5.991481455918986
Validation loss: 5.465118661412668

Epoch: 6| Step: 11
Training loss: 5.928928331672544
Validation loss: 5.44488511566846

Epoch: 6| Step: 12
Training loss: 6.037260075258361
Validation loss: 5.429899545222033

Epoch: 6| Step: 13
Training loss: 5.7937299314478485
Validation loss: 5.407593249578445

Epoch: 15| Step: 0
Training loss: 4.596631865356985
Validation loss: 5.386353148205559

Epoch: 6| Step: 1
Training loss: 5.132359500676999
Validation loss: 5.384432097406216

Epoch: 6| Step: 2
Training loss: 5.937333917804663
Validation loss: 5.351972999215126

Epoch: 6| Step: 3
Training loss: 4.748290306388209
Validation loss: 5.336238390349414

Epoch: 6| Step: 4
Training loss: 4.858134316784272
Validation loss: 5.314891427977195

Epoch: 6| Step: 5
Training loss: 4.956276261210769
Validation loss: 5.304934714314198

Epoch: 6| Step: 6
Training loss: 4.945359939419974
Validation loss: 5.276698698441863

Epoch: 6| Step: 7
Training loss: 6.352950916823024
Validation loss: 5.259115133845141

Epoch: 6| Step: 8
Training loss: 5.975678102967328
Validation loss: 5.247308000860394

Epoch: 6| Step: 9
Training loss: 4.3863832883893235
Validation loss: 5.2354790938709685

Epoch: 6| Step: 10
Training loss: 5.312086380957109
Validation loss: 5.202796512527229

Epoch: 6| Step: 11
Training loss: 5.070078134630646
Validation loss: 5.182461306468359

Epoch: 6| Step: 12
Training loss: 5.910848129528584
Validation loss: 5.160841629690528

Epoch: 6| Step: 13
Training loss: 5.07511404125447
Validation loss: 5.142156820620484

Epoch: 16| Step: 0
Training loss: 4.179039450344907
Validation loss: 5.114231963778263

Epoch: 6| Step: 1
Training loss: 5.525240807442207
Validation loss: 5.094318363467981

Epoch: 6| Step: 2
Training loss: 6.181789036034403
Validation loss: 5.074956885877615

Epoch: 6| Step: 3
Training loss: 4.652767235789843
Validation loss: 5.05511219133407

Epoch: 6| Step: 4
Training loss: 4.799912277055867
Validation loss: 5.02931441007226

Epoch: 6| Step: 5
Training loss: 5.385125846561135
Validation loss: 5.0029525304577245

Epoch: 6| Step: 6
Training loss: 5.4260610641491125
Validation loss: 4.974059918738603

Epoch: 6| Step: 7
Training loss: 5.299094846194475
Validation loss: 4.960133860644448

Epoch: 6| Step: 8
Training loss: 5.537567496480397
Validation loss: 4.944579096846355

Epoch: 6| Step: 9
Training loss: 4.847073307075625
Validation loss: 4.9169333302031335

Epoch: 6| Step: 10
Training loss: 4.107351290703552
Validation loss: 4.898189668659285

Epoch: 6| Step: 11
Training loss: 4.081917004606429
Validation loss: 4.85363569035413

Epoch: 6| Step: 12
Training loss: 4.451165018917493
Validation loss: 4.8433231839204485

Epoch: 6| Step: 13
Training loss: 4.967351560712204
Validation loss: 4.825780202312631

Epoch: 17| Step: 0
Training loss: 4.306516615278062
Validation loss: 4.802610558139411

Epoch: 6| Step: 1
Training loss: 4.185798868843337
Validation loss: 4.783135267838154

Epoch: 6| Step: 2
Training loss: 4.4639226275339245
Validation loss: 4.763757677074133

Epoch: 6| Step: 3
Training loss: 4.496470444688916
Validation loss: 4.735030293621195

Epoch: 6| Step: 4
Training loss: 5.605752184145214
Validation loss: 4.7060576520486235

Epoch: 6| Step: 5
Training loss: 4.4496902872384
Validation loss: 4.688523259746818

Epoch: 6| Step: 6
Training loss: 4.6867907178223795
Validation loss: 4.672567154608882

Epoch: 6| Step: 7
Training loss: 5.014971443924085
Validation loss: 4.6260284238248275

Epoch: 6| Step: 8
Training loss: 4.7945137300834775
Validation loss: 4.6199959176843715

Epoch: 6| Step: 9
Training loss: 4.8932881767067276
Validation loss: 4.589237112896857

Epoch: 6| Step: 10
Training loss: 5.109397398173384
Validation loss: 4.558627766831657

Epoch: 6| Step: 11
Training loss: 3.4337202619522325
Validation loss: 4.543231394643172

Epoch: 6| Step: 12
Training loss: 4.520427539151441
Validation loss: 4.511696580344859

Epoch: 6| Step: 13
Training loss: 5.136421316840335
Validation loss: 4.482944981551815

Epoch: 18| Step: 0
Training loss: 5.16256955448614
Validation loss: 4.467940780649964

Epoch: 6| Step: 1
Training loss: 3.815797224227317
Validation loss: 4.437456444181781

Epoch: 6| Step: 2
Training loss: 5.491003828707006
Validation loss: 4.412252198562266

Epoch: 6| Step: 3
Training loss: 4.618065248764433
Validation loss: 4.382379599646416

Epoch: 6| Step: 4
Training loss: 4.673688351637018
Validation loss: 4.368698595696886

Epoch: 6| Step: 5
Training loss: 3.1933053201655883
Validation loss: 4.338150056178625

Epoch: 6| Step: 6
Training loss: 4.173674805984338
Validation loss: 4.308433119091806

Epoch: 6| Step: 7
Training loss: 4.0486224904817405
Validation loss: 4.276538519593677

Epoch: 6| Step: 8
Training loss: 4.010100486809107
Validation loss: 4.238757416631182

Epoch: 6| Step: 9
Training loss: 4.48973863278506
Validation loss: 4.217484912002713

Epoch: 6| Step: 10
Training loss: 4.511871784471686
Validation loss: 4.191066799339389

Epoch: 6| Step: 11
Training loss: 3.9891557323230784
Validation loss: 4.15939038225298

Epoch: 6| Step: 12
Training loss: 3.441996044318471
Validation loss: 4.143115678983784

Epoch: 6| Step: 13
Training loss: 4.299875106772043
Validation loss: 4.110269431155805

Epoch: 19| Step: 0
Training loss: 4.071060316980355
Validation loss: 4.080852614288431

Epoch: 6| Step: 1
Training loss: 3.4243891985815247
Validation loss: 4.065208065065854

Epoch: 6| Step: 2
Training loss: 3.909281294543559
Validation loss: 4.040582772642356

Epoch: 6| Step: 3
Training loss: 4.455651353000164
Validation loss: 4.01841553651336

Epoch: 6| Step: 4
Training loss: 3.649406876121838
Validation loss: 3.976362040934665

Epoch: 6| Step: 5
Training loss: 4.0862336789911184
Validation loss: 3.964156804288067

Epoch: 6| Step: 6
Training loss: 3.2024986585127366
Validation loss: 3.9344096807353113

Epoch: 6| Step: 7
Training loss: 3.74850281391748
Validation loss: 3.9091432209066275

Epoch: 6| Step: 8
Training loss: 3.4853727682617013
Validation loss: 3.877579431563665

Epoch: 6| Step: 9
Training loss: 4.102923881209594
Validation loss: 3.879877736599207

Epoch: 6| Step: 10
Training loss: 3.8962971348339233
Validation loss: 3.844586507869145

Epoch: 6| Step: 11
Training loss: 4.947415403439894
Validation loss: 3.810549654905244

Epoch: 6| Step: 12
Training loss: 4.4082427151938415
Validation loss: 3.773196754086852

Epoch: 6| Step: 13
Training loss: 3.6246619231325337
Validation loss: 3.7478585394291644

Epoch: 20| Step: 0
Training loss: 3.9435090730470117
Validation loss: 3.7138699327772335

Epoch: 6| Step: 1
Training loss: 2.7209036178818855
Validation loss: 3.6930503710528346

Epoch: 6| Step: 2
Training loss: 3.697771282651385
Validation loss: 3.656731076665773

Epoch: 6| Step: 3
Training loss: 4.344190177295279
Validation loss: 3.6558349951609475

Epoch: 6| Step: 4
Training loss: 3.5274535169451893
Validation loss: 3.619153667230524

Epoch: 6| Step: 5
Training loss: 3.8867288100529356
Validation loss: 3.5955159902833493

Epoch: 6| Step: 6
Training loss: 4.5091717817655494
Validation loss: 3.559540229171832

Epoch: 6| Step: 7
Training loss: 3.459557113747193
Validation loss: 3.537526604250054

Epoch: 6| Step: 8
Training loss: 2.9050787749911033
Validation loss: 3.507105603747724

Epoch: 6| Step: 9
Training loss: 4.329502148276255
Validation loss: 3.47701606699923

Epoch: 6| Step: 10
Training loss: 3.54976506060241
Validation loss: 3.4617127355103223

Epoch: 6| Step: 11
Training loss: 2.9946271149029577
Validation loss: 3.4362234361096644

Epoch: 6| Step: 12
Training loss: 3.193867624882634
Validation loss: 3.4004903241323494

Epoch: 6| Step: 13
Training loss: 3.452830030175994
Validation loss: 3.38407020972349

Epoch: 21| Step: 0
Training loss: 2.8626100344102836
Validation loss: 3.36656511929917

Epoch: 6| Step: 1
Training loss: 3.3165418329819745
Validation loss: 3.3170202722115665

Epoch: 6| Step: 2
Training loss: 4.148844381088104
Validation loss: 3.302332949841166

Epoch: 6| Step: 3
Training loss: 4.314686980845282
Validation loss: 3.288041104283462

Epoch: 6| Step: 4
Training loss: 3.1799454268085277
Validation loss: 3.2629844029003876

Epoch: 6| Step: 5
Training loss: 3.5535822564895967
Validation loss: 3.2327205291849945

Epoch: 6| Step: 6
Training loss: 3.7588429772942233
Validation loss: 3.2193813610749658

Epoch: 6| Step: 7
Training loss: 3.520197899413838
Validation loss: 3.19374235280836

Epoch: 6| Step: 8
Training loss: 2.8338122430603017
Validation loss: 3.1808940550115676

Epoch: 6| Step: 9
Training loss: 2.8733628628917898
Validation loss: 3.146253987296016

Epoch: 6| Step: 10
Training loss: 3.35768745086558
Validation loss: 3.1380353795625298

Epoch: 6| Step: 11
Training loss: 2.335841352340356
Validation loss: 3.1209153188996095

Epoch: 6| Step: 12
Training loss: 2.9846561958493436
Validation loss: 3.0961271011789298

Epoch: 6| Step: 13
Training loss: 3.4248990844561384
Validation loss: 3.0939595920154948

Epoch: 22| Step: 0
Training loss: 3.5168698967760537
Validation loss: 3.0686318289412164

Epoch: 6| Step: 1
Training loss: 2.677918141943695
Validation loss: 3.0356547240800187

Epoch: 6| Step: 2
Training loss: 2.76472622335158
Validation loss: 3.022667205052557

Epoch: 6| Step: 3
Training loss: 3.7370401871469836
Validation loss: 3.010880069099907

Epoch: 6| Step: 4
Training loss: 3.45337658824367
Validation loss: 3.000739749846027

Epoch: 6| Step: 5
Training loss: 3.254002673860189
Validation loss: 2.9948173110242036

Epoch: 6| Step: 6
Training loss: 3.6080967344693082
Validation loss: 2.9967381637232005

Epoch: 6| Step: 7
Training loss: 2.699540247450929
Validation loss: 2.94996840705313

Epoch: 6| Step: 8
Training loss: 2.6458885507503793
Validation loss: 2.9554369210023093

Epoch: 6| Step: 9
Training loss: 3.6446395808859546
Validation loss: 2.920439471868889

Epoch: 6| Step: 10
Training loss: 2.3408884508817236
Validation loss: 2.915477797514465

Epoch: 6| Step: 11
Training loss: 2.539416667005829
Validation loss: 2.886706188952257

Epoch: 6| Step: 12
Training loss: 2.6093821268498294
Validation loss: 2.9135177161571364

Epoch: 6| Step: 13
Training loss: 4.160631208216039
Validation loss: 2.898702422891056

Epoch: 23| Step: 0
Training loss: 2.6197369811845497
Validation loss: 2.874042039292909

Epoch: 6| Step: 1
Training loss: 3.075032806221485
Validation loss: 2.8589147534340995

Epoch: 6| Step: 2
Training loss: 2.6893378782270183
Validation loss: 2.8520704184818126

Epoch: 6| Step: 3
Training loss: 2.712825941903471
Validation loss: 2.8168218733618082

Epoch: 6| Step: 4
Training loss: 2.817089828516072
Validation loss: 2.8313471952497067

Epoch: 6| Step: 5
Training loss: 2.7247654805190344
Validation loss: 2.8083262165727105

Epoch: 6| Step: 6
Training loss: 2.522469727681403
Validation loss: 2.792588353772712

Epoch: 6| Step: 7
Training loss: 3.625592282020522
Validation loss: 2.7844493605001936

Epoch: 6| Step: 8
Training loss: 3.7052559817452275
Validation loss: 2.763192652165219

Epoch: 6| Step: 9
Training loss: 3.1697231566544644
Validation loss: 2.7654220388856383

Epoch: 6| Step: 10
Training loss: 2.685459515624578
Validation loss: 2.763546318617798

Epoch: 6| Step: 11
Training loss: 3.106990647620204
Validation loss: 2.763622037173761

Epoch: 6| Step: 12
Training loss: 3.2492466566974523
Validation loss: 2.7572147242443883

Epoch: 6| Step: 13
Training loss: 3.2961400374412704
Validation loss: 2.7520872121107307

Epoch: 24| Step: 0
Training loss: 3.6856987643416717
Validation loss: 2.7510388296249624

Epoch: 6| Step: 1
Training loss: 2.547133262973196
Validation loss: 2.718262480317405

Epoch: 6| Step: 2
Training loss: 3.3456761881851276
Validation loss: 2.746431246327717

Epoch: 6| Step: 3
Training loss: 2.710228995047637
Validation loss: 2.7073238031054685

Epoch: 6| Step: 4
Training loss: 2.516240394145673
Validation loss: 2.70813147563287

Epoch: 6| Step: 5
Training loss: 2.5842593184461164
Validation loss: 2.7066918158983078

Epoch: 6| Step: 6
Training loss: 2.1143347182173358
Validation loss: 2.7144826813446774

Epoch: 6| Step: 7
Training loss: 3.6199630733313723
Validation loss: 2.7088118598181103

Epoch: 6| Step: 8
Training loss: 3.453950394937437
Validation loss: 2.699370252324166

Epoch: 6| Step: 9
Training loss: 2.4687119493087217
Validation loss: 2.702180263798329

Epoch: 6| Step: 10
Training loss: 2.571707489009413
Validation loss: 2.7108055669664197

Epoch: 6| Step: 11
Training loss: 2.5779034143648487
Validation loss: 2.7026162461562566

Epoch: 6| Step: 12
Training loss: 3.7192392748640692
Validation loss: 2.679717076984812

Epoch: 6| Step: 13
Training loss: 3.109889922325144
Validation loss: 2.6798538849477342

Epoch: 25| Step: 0
Training loss: 3.040880458721355
Validation loss: 2.6649013535368193

Epoch: 6| Step: 1
Training loss: 2.9916966287145024
Validation loss: 2.6940976389677527

Epoch: 6| Step: 2
Training loss: 3.6630376427684808
Validation loss: 2.6782912950186257

Epoch: 6| Step: 3
Training loss: 2.4148057700767662
Validation loss: 2.6828815337680947

Epoch: 6| Step: 4
Training loss: 2.5071366489754285
Validation loss: 2.661891033153012

Epoch: 6| Step: 5
Training loss: 2.539272076687207
Validation loss: 2.6823058610144916

Epoch: 6| Step: 6
Training loss: 2.6742346979056313
Validation loss: 2.6821444588796894

Epoch: 6| Step: 7
Training loss: 2.81334817600704
Validation loss: 2.673965847853422

Epoch: 6| Step: 8
Training loss: 3.8329626539935373
Validation loss: 2.6856914634525353

Epoch: 6| Step: 9
Training loss: 3.26045862400411
Validation loss: 2.6672142121041604

Epoch: 6| Step: 10
Training loss: 2.8153029144357657
Validation loss: 2.6910756247390375

Epoch: 6| Step: 11
Training loss: 2.9547071305968884
Validation loss: 2.662617788559922

Epoch: 6| Step: 12
Training loss: 2.7545521945796514
Validation loss: 2.669810551728733

Epoch: 6| Step: 13
Training loss: 2.269759411266793
Validation loss: 2.6742342808952

Epoch: 26| Step: 0
Training loss: 3.1049180796162608
Validation loss: 2.6559933774306868

Epoch: 6| Step: 1
Training loss: 2.989725957961856
Validation loss: 2.6617604118299814

Epoch: 6| Step: 2
Training loss: 2.5018970920979626
Validation loss: 2.6561093085016525

Epoch: 6| Step: 3
Training loss: 2.85916720609809
Validation loss: 2.6763452510211314

Epoch: 6| Step: 4
Training loss: 3.9263103071680194
Validation loss: 2.6858562442087095

Epoch: 6| Step: 5
Training loss: 3.236669933292562
Validation loss: 2.687637191575135

Epoch: 6| Step: 6
Training loss: 2.314150453244444
Validation loss: 2.661846478310545

Epoch: 6| Step: 7
Training loss: 2.6315627032330737
Validation loss: 2.657546506935562

Epoch: 6| Step: 8
Training loss: 3.107236500598932
Validation loss: 2.672447488194968

Epoch: 6| Step: 9
Training loss: 3.2007427009344953
Validation loss: 2.68904300512051

Epoch: 6| Step: 10
Training loss: 2.731188939719217
Validation loss: 2.6628121319742792

Epoch: 6| Step: 11
Training loss: 2.454149360358244
Validation loss: 2.667411889138366

Epoch: 6| Step: 12
Training loss: 2.999985694851148
Validation loss: 2.677819705004249

Epoch: 6| Step: 13
Training loss: 2.6814924117192027
Validation loss: 2.686099699484469

Epoch: 27| Step: 0
Training loss: 2.6951469923425795
Validation loss: 2.6717090066985665

Epoch: 6| Step: 1
Training loss: 3.130412183440453
Validation loss: 2.659239570156992

Epoch: 6| Step: 2
Training loss: 2.9474663991525505
Validation loss: 2.663974473621425

Epoch: 6| Step: 3
Training loss: 3.4455403016916017
Validation loss: 2.6568998715657934

Epoch: 6| Step: 4
Training loss: 3.3632046893507246
Validation loss: 2.669492468027531

Epoch: 6| Step: 5
Training loss: 3.1608436317856046
Validation loss: 2.653069244896221

Epoch: 6| Step: 6
Training loss: 2.3670307774801085
Validation loss: 2.6757230185410585

Epoch: 6| Step: 7
Training loss: 2.334251484290594
Validation loss: 2.6598384613691732

Epoch: 6| Step: 8
Training loss: 2.396803905322938
Validation loss: 2.660689653983736

Epoch: 6| Step: 9
Training loss: 3.650549985653382
Validation loss: 2.658836066187325

Epoch: 6| Step: 10
Training loss: 2.8294406591523615
Validation loss: 2.6619653788104394

Epoch: 6| Step: 11
Training loss: 3.0139242327405453
Validation loss: 2.676965009825157

Epoch: 6| Step: 12
Training loss: 2.7500893838401157
Validation loss: 2.662088273419137

Epoch: 6| Step: 13
Training loss: 2.6299009439358265
Validation loss: 2.674417234862108

Epoch: 28| Step: 0
Training loss: 2.751006722411883
Validation loss: 2.6628439335688356

Epoch: 6| Step: 1
Training loss: 2.836156074781072
Validation loss: 2.650066930916655

Epoch: 6| Step: 2
Training loss: 2.709517753034663
Validation loss: 2.648361944999438

Epoch: 6| Step: 3
Training loss: 2.8241827871478447
Validation loss: 2.6681168276592904

Epoch: 6| Step: 4
Training loss: 3.3935175919735103
Validation loss: 2.672125899014957

Epoch: 6| Step: 5
Training loss: 3.3566309877814637
Validation loss: 2.6525616435265666

Epoch: 6| Step: 6
Training loss: 2.912209583914683
Validation loss: 2.6192027493242405

Epoch: 6| Step: 7
Training loss: 2.9081427860597437
Validation loss: 2.6458992136365156

Epoch: 6| Step: 8
Training loss: 2.6681293310763357
Validation loss: 2.684743298718362

Epoch: 6| Step: 9
Training loss: 2.7497749236505347
Validation loss: 2.6650695042707575

Epoch: 6| Step: 10
Training loss: 3.0359575350459123
Validation loss: 2.670495959800769

Epoch: 6| Step: 11
Training loss: 3.4548469496308423
Validation loss: 2.6708032463477602

Epoch: 6| Step: 12
Training loss: 2.8424558943763065
Validation loss: 2.64485079255166

Epoch: 6| Step: 13
Training loss: 2.2989106791410894
Validation loss: 2.6718110625772598

Epoch: 29| Step: 0
Training loss: 3.0586529917235294
Validation loss: 2.678692604328108

Epoch: 6| Step: 1
Training loss: 2.910548978586426
Validation loss: 2.663916912749323

Epoch: 6| Step: 2
Training loss: 3.3852828874809684
Validation loss: 2.665098745204398

Epoch: 6| Step: 3
Training loss: 3.149048549526182
Validation loss: 2.6575103655362455

Epoch: 6| Step: 4
Training loss: 3.1027774304972513
Validation loss: 2.6769976124367

Epoch: 6| Step: 5
Training loss: 2.748341320235208
Validation loss: 2.6632415562243925

Epoch: 6| Step: 6
Training loss: 2.925967038702293
Validation loss: 2.676372764793229

Epoch: 6| Step: 7
Training loss: 2.3330839455255132
Validation loss: 2.653713183237831

Epoch: 6| Step: 8
Training loss: 3.096378481389542
Validation loss: 2.6664776578056846

Epoch: 6| Step: 9
Training loss: 2.759196596005387
Validation loss: 2.6668723344964613

Epoch: 6| Step: 10
Training loss: 2.9903345172241758
Validation loss: 2.6870029921869616

Epoch: 6| Step: 11
Training loss: 2.397032683555891
Validation loss: 2.6673130125655273

Epoch: 6| Step: 12
Training loss: 3.27452910437634
Validation loss: 2.6684265392569726

Epoch: 6| Step: 13
Training loss: 2.7491208318393316
Validation loss: 2.6439542491874506

Epoch: 30| Step: 0
Training loss: 3.062933287817833
Validation loss: 2.6744678588657536

Epoch: 6| Step: 1
Training loss: 2.6068430054410814
Validation loss: 2.638219979017659

Epoch: 6| Step: 2
Training loss: 2.447770416003194
Validation loss: 2.6567546039454872

Epoch: 6| Step: 3
Training loss: 2.656627134589792
Validation loss: 2.6516948539706453

Epoch: 6| Step: 4
Training loss: 3.4880939702490936
Validation loss: 2.673830569914305

Epoch: 6| Step: 5
Training loss: 3.289228204100455
Validation loss: 2.640900032218706

Epoch: 6| Step: 6
Training loss: 2.5831523544742345
Validation loss: 2.6474089836467707

Epoch: 6| Step: 7
Training loss: 2.6849086599601675
Validation loss: 2.660454405733116

Epoch: 6| Step: 8
Training loss: 2.6546272257517884
Validation loss: 2.69280761248841

Epoch: 6| Step: 9
Training loss: 2.5300501110557327
Validation loss: 2.634914311566194

Epoch: 6| Step: 10
Training loss: 2.9977635948719747
Validation loss: 2.6738038981753802

Epoch: 6| Step: 11
Training loss: 3.6552915702612627
Validation loss: 2.663004116100068

Epoch: 6| Step: 12
Training loss: 2.8895545420808646
Validation loss: 2.6532809482146504

Epoch: 6| Step: 13
Training loss: 3.1976839326712954
Validation loss: 2.6640179920601486

Epoch: 31| Step: 0
Training loss: 3.1961052617677215
Validation loss: 2.677073302516928

Epoch: 6| Step: 1
Training loss: 3.2632897893580664
Validation loss: 2.6533426722284235

Epoch: 6| Step: 2
Training loss: 2.6580628435844655
Validation loss: 2.6530123934403145

Epoch: 6| Step: 3
Training loss: 2.5275016629206983
Validation loss: 2.6572112716482863

Epoch: 6| Step: 4
Training loss: 3.0722485521815837
Validation loss: 2.645323780755507

Epoch: 6| Step: 5
Training loss: 3.00598199803691
Validation loss: 2.6648512856684183

Epoch: 6| Step: 6
Training loss: 2.978959847765184
Validation loss: 2.675100333703447

Epoch: 6| Step: 7
Training loss: 3.2703936497971906
Validation loss: 2.668354587205755

Epoch: 6| Step: 8
Training loss: 2.9558677248750507
Validation loss: 2.683478526724297

Epoch: 6| Step: 9
Training loss: 2.809727637507354
Validation loss: 2.6502336577454675

Epoch: 6| Step: 10
Training loss: 2.8096879252298854
Validation loss: 2.6467034076299782

Epoch: 6| Step: 11
Training loss: 2.7245775227752844
Validation loss: 2.6554674360254658

Epoch: 6| Step: 12
Training loss: 3.1789489938220563
Validation loss: 2.69893657527868

Epoch: 6| Step: 13
Training loss: 2.0211366511017403
Validation loss: 2.6764458485082425

Epoch: 32| Step: 0
Training loss: 2.746037228953583
Validation loss: 2.6567009067195833

Epoch: 6| Step: 1
Training loss: 2.4642029426526797
Validation loss: 2.674641118909112

Epoch: 6| Step: 2
Training loss: 3.2900323955483057
Validation loss: 2.634656835908452

Epoch: 6| Step: 3
Training loss: 2.775299736537391
Validation loss: 2.667986524595938

Epoch: 6| Step: 4
Training loss: 2.6206206166153176
Validation loss: 2.658342827138253

Epoch: 6| Step: 5
Training loss: 3.2000334916746347
Validation loss: 2.642072439765114

Epoch: 6| Step: 6
Training loss: 2.790757804692246
Validation loss: 2.665119690203885

Epoch: 6| Step: 7
Training loss: 3.1823794055753742
Validation loss: 2.6489211440136744

Epoch: 6| Step: 8
Training loss: 3.499975068139786
Validation loss: 2.659781751710202

Epoch: 6| Step: 9
Training loss: 2.5277015397402294
Validation loss: 2.640978306115135

Epoch: 6| Step: 10
Training loss: 2.553031828171266
Validation loss: 2.6748591886530115

Epoch: 6| Step: 11
Training loss: 3.02387118124704
Validation loss: 2.6618737928230893

Epoch: 6| Step: 12
Training loss: 3.108421754644716
Validation loss: 2.6641084612144295

Epoch: 6| Step: 13
Training loss: 3.1643369202467087
Validation loss: 2.6700881099814904

Epoch: 33| Step: 0
Training loss: 2.8345299793003154
Validation loss: 2.6659143589035366

Epoch: 6| Step: 1
Training loss: 2.7605057228165863
Validation loss: 2.674534999470995

Epoch: 6| Step: 2
Training loss: 3.101100781566778
Validation loss: 2.684553010591201

Epoch: 6| Step: 3
Training loss: 2.6603133593530655
Validation loss: 2.6608256616772747

Epoch: 6| Step: 4
Training loss: 2.7142276201986575
Validation loss: 2.6684972932897475

Epoch: 6| Step: 5
Training loss: 3.1634737950592173
Validation loss: 2.663783328393618

Epoch: 6| Step: 6
Training loss: 2.943089787338791
Validation loss: 2.6264938239027495

Epoch: 6| Step: 7
Training loss: 2.768123295728133
Validation loss: 2.6593448587513655

Epoch: 6| Step: 8
Training loss: 3.7135635239794755
Validation loss: 2.674868315199339

Epoch: 6| Step: 9
Training loss: 2.6504361423527905
Validation loss: 2.636854746724572

Epoch: 6| Step: 10
Training loss: 3.549129895242729
Validation loss: 2.652964683234534

Epoch: 6| Step: 11
Training loss: 3.062954927247957
Validation loss: 2.6494054931946183

Epoch: 6| Step: 12
Training loss: 2.46168627776554
Validation loss: 2.651219273769779

Epoch: 6| Step: 13
Training loss: 2.2103562955914353
Validation loss: 2.681099864258547

Epoch: 34| Step: 0
Training loss: 2.5974662539187263
Validation loss: 2.6792794332488876

Epoch: 6| Step: 1
Training loss: 3.0798085831945223
Validation loss: 2.663774548350657

Epoch: 6| Step: 2
Training loss: 2.3503029323687974
Validation loss: 2.6631245128467698

Epoch: 6| Step: 3
Training loss: 3.0944690831967203
Validation loss: 2.6450160085697383

Epoch: 6| Step: 4
Training loss: 2.3496426574429954
Validation loss: 2.6487102856288165

Epoch: 6| Step: 5
Training loss: 3.360087758235191
Validation loss: 2.6512727638916562

Epoch: 6| Step: 6
Training loss: 3.40972792829324
Validation loss: 2.695078982140772

Epoch: 6| Step: 7
Training loss: 2.78681534711221
Validation loss: 2.6712166493770093

Epoch: 6| Step: 8
Training loss: 3.1117192158470024
Validation loss: 2.6527371277719367

Epoch: 6| Step: 9
Training loss: 2.0981790185996516
Validation loss: 2.6580901719014633

Epoch: 6| Step: 10
Training loss: 2.9452835203004843
Validation loss: 2.649355067651036

Epoch: 6| Step: 11
Training loss: 3.553690676252697
Validation loss: 2.6628955660645413

Epoch: 6| Step: 12
Training loss: 2.684694822219492
Validation loss: 2.660079631382951

Epoch: 6| Step: 13
Training loss: 3.4873844031861383
Validation loss: 2.6687326586954994

Epoch: 35| Step: 0
Training loss: 2.543330809899008
Validation loss: 2.652179923244545

Epoch: 6| Step: 1
Training loss: 3.0107116202733897
Validation loss: 2.6507724733517057

Epoch: 6| Step: 2
Training loss: 2.908707430880086
Validation loss: 2.665053580245587

Epoch: 6| Step: 3
Training loss: 2.6678271053576186
Validation loss: 2.6637763345811876

Epoch: 6| Step: 4
Training loss: 2.710612428727045
Validation loss: 2.6504473967938265

Epoch: 6| Step: 5
Training loss: 2.978819144371314
Validation loss: 2.6932189372239432

Epoch: 6| Step: 6
Training loss: 2.7084236912448514
Validation loss: 2.6495841675392686

Epoch: 6| Step: 7
Training loss: 3.388671875
Validation loss: 2.656488614159272

Epoch: 6| Step: 8
Training loss: 3.227195252820799
Validation loss: 2.6679057250445113

Epoch: 6| Step: 9
Training loss: 2.4354104108596832
Validation loss: 2.6355577880424494

Epoch: 6| Step: 10
Training loss: 2.743593556456084
Validation loss: 2.6446788679570363

Epoch: 6| Step: 11
Training loss: 3.3987861542148425
Validation loss: 2.6488982775727954

Epoch: 6| Step: 12
Training loss: 2.9448824702646244
Validation loss: 2.654271862381789

Epoch: 6| Step: 13
Training loss: 3.1814343951731923
Validation loss: 2.668640865937824

Epoch: 36| Step: 0
Training loss: 2.6445683937337945
Validation loss: 2.673702647078699

Epoch: 6| Step: 1
Training loss: 3.2527413177691007
Validation loss: 2.6425039459853172

Epoch: 6| Step: 2
Training loss: 2.6021923872057844
Validation loss: 2.6539723272141678

Epoch: 6| Step: 3
Training loss: 3.129716899122402
Validation loss: 2.653671895533301

Epoch: 6| Step: 4
Training loss: 2.7531760688401197
Validation loss: 2.65254261641957

Epoch: 6| Step: 5
Training loss: 3.090102540570891
Validation loss: 2.6948088429938784

Epoch: 6| Step: 6
Training loss: 3.2115486844188705
Validation loss: 2.648557765198835

Epoch: 6| Step: 7
Training loss: 2.5551834791560664
Validation loss: 2.673276563266211

Epoch: 6| Step: 8
Training loss: 2.696573244542709
Validation loss: 2.6956850150839338

Epoch: 6| Step: 9
Training loss: 2.8421401612888717
Validation loss: 2.6536908092421068

Epoch: 6| Step: 10
Training loss: 2.3440779392968243
Validation loss: 2.6662922245085134

Epoch: 6| Step: 11
Training loss: 3.8836740194254404
Validation loss: 2.631636409375035

Epoch: 6| Step: 12
Training loss: 2.8582628098695197
Validation loss: 2.673959858591817

Epoch: 6| Step: 13
Training loss: 2.462365502107028
Validation loss: 2.6553691226189233

Epoch: 37| Step: 0
Training loss: 3.3981332927782986
Validation loss: 2.6469364077632638

Epoch: 6| Step: 1
Training loss: 3.097922237949625
Validation loss: 2.667144267961448

Epoch: 6| Step: 2
Training loss: 2.4116990454696436
Validation loss: 2.657849157996102

Epoch: 6| Step: 3
Training loss: 2.531777880220089
Validation loss: 2.6489974814814015

Epoch: 6| Step: 4
Training loss: 3.1389144870160632
Validation loss: 2.6515174801521533

Epoch: 6| Step: 5
Training loss: 2.267542376306279
Validation loss: 2.6621691840528823

Epoch: 6| Step: 6
Training loss: 3.293071559690316
Validation loss: 2.681112194299073

Epoch: 6| Step: 7
Training loss: 3.250627750512184
Validation loss: 2.676851184870018

Epoch: 6| Step: 8
Training loss: 3.211017988175361
Validation loss: 2.6582597304264093

Epoch: 6| Step: 9
Training loss: 2.9903027846212127
Validation loss: 2.6655457265951195

Epoch: 6| Step: 10
Training loss: 2.816001407980567
Validation loss: 2.662053479328197

Epoch: 6| Step: 11
Training loss: 2.55794548383397
Validation loss: 2.6851850413777107

Epoch: 6| Step: 12
Training loss: 2.8994188318312912
Validation loss: 2.659581640431532

Epoch: 6| Step: 13
Training loss: 2.5654634227357005
Validation loss: 2.6414541462258594

Epoch: 38| Step: 0
Training loss: 3.5330697831043696
Validation loss: 2.6706147007972683

Epoch: 6| Step: 1
Training loss: 2.14055349411535
Validation loss: 2.6435853194547607

Epoch: 6| Step: 2
Training loss: 3.0490780421872827
Validation loss: 2.6363719347186927

Epoch: 6| Step: 3
Training loss: 3.5344585594330584
Validation loss: 2.654943953162128

Epoch: 6| Step: 4
Training loss: 3.155152838340573
Validation loss: 2.6834302088954805

Epoch: 6| Step: 5
Training loss: 3.3390818301236225
Validation loss: 2.672446539461251

Epoch: 6| Step: 6
Training loss: 3.3035660231851667
Validation loss: 2.6471983670080332

Epoch: 6| Step: 7
Training loss: 2.794472968240532
Validation loss: 2.665773777399007

Epoch: 6| Step: 8
Training loss: 3.0145109816917626
Validation loss: 2.6574525064399173

Epoch: 6| Step: 9
Training loss: 2.5440881377852897
Validation loss: 2.6801299267434477

Epoch: 6| Step: 10
Training loss: 1.9846390676137389
Validation loss: 2.679087317849229

Epoch: 6| Step: 11
Training loss: 2.407428502400672
Validation loss: 2.6741819479666087

Epoch: 6| Step: 12
Training loss: 2.6553897137732796
Validation loss: 2.6632026206294697

Epoch: 6| Step: 13
Training loss: 2.3137297582333427
Validation loss: 2.668559087088128

Epoch: 39| Step: 0
Training loss: 3.4462190503656362
Validation loss: 2.688481538204324

Epoch: 6| Step: 1
Training loss: 2.2453091785297503
Validation loss: 2.6515313772478297

Epoch: 6| Step: 2
Training loss: 2.854493690931438
Validation loss: 2.6689890908758342

Epoch: 6| Step: 3
Training loss: 2.717458747192695
Validation loss: 2.646576248473489

Epoch: 6| Step: 4
Training loss: 2.435430185907551
Validation loss: 2.6769816693457567

Epoch: 6| Step: 5
Training loss: 3.4069743654872724
Validation loss: 2.6277395632431593

Epoch: 6| Step: 6
Training loss: 2.854871194208674
Validation loss: 2.6697652811523636

Epoch: 6| Step: 7
Training loss: 3.556624268479001
Validation loss: 2.646502417882911

Epoch: 6| Step: 8
Training loss: 2.1932298005470865
Validation loss: 2.665354168885472

Epoch: 6| Step: 9
Training loss: 2.7377472926929287
Validation loss: 2.6618784002715037

Epoch: 6| Step: 10
Training loss: 3.2037921489870613
Validation loss: 2.67174048169999

Epoch: 6| Step: 11
Training loss: 2.6711062390598093
Validation loss: 2.667518348651116

Epoch: 6| Step: 12
Training loss: 2.6575258668948702
Validation loss: 2.644746229725755

Epoch: 6| Step: 13
Training loss: 3.6977033240156683
Validation loss: 2.653232520095864

Epoch: 40| Step: 0
Training loss: 2.448374528202902
Validation loss: 2.6430381820271203

Epoch: 6| Step: 1
Training loss: 2.9463215928246407
Validation loss: 2.6277978092515166

Epoch: 6| Step: 2
Training loss: 2.8518089710477863
Validation loss: 2.668416239237881

Epoch: 6| Step: 3
Training loss: 2.160580364071894
Validation loss: 2.670895275778411

Epoch: 6| Step: 4
Training loss: 3.069199066557308
Validation loss: 2.6280737429386756

Epoch: 6| Step: 5
Training loss: 3.3313648769474913
Validation loss: 2.6508553927832454

Epoch: 6| Step: 6
Training loss: 2.9739276908903705
Validation loss: 2.653582631789654

Epoch: 6| Step: 7
Training loss: 2.3718710918168147
Validation loss: 2.6581239637219785

Epoch: 6| Step: 8
Training loss: 3.1075860632888466
Validation loss: 2.6494725083714465

Epoch: 6| Step: 9
Training loss: 3.1999431903087925
Validation loss: 2.6521399581879708

Epoch: 6| Step: 10
Training loss: 2.208154011289349
Validation loss: 2.6593755565756623

Epoch: 6| Step: 11
Training loss: 2.71429104015717
Validation loss: 2.6546918194330975

Epoch: 6| Step: 12
Training loss: 3.7618851827878803
Validation loss: 2.6562999365960622

Epoch: 6| Step: 13
Training loss: 3.44833912331003
Validation loss: 2.6348007794430988

Epoch: 41| Step: 0
Training loss: 3.1918504235445835
Validation loss: 2.66719053074475

Epoch: 6| Step: 1
Training loss: 2.4793014062335503
Validation loss: 2.65387893814316

Epoch: 6| Step: 2
Training loss: 3.7627375125374924
Validation loss: 2.6668486270300193

Epoch: 6| Step: 3
Training loss: 2.942527850982654
Validation loss: 2.6504742692324106

Epoch: 6| Step: 4
Training loss: 3.1410966964940883
Validation loss: 2.619294889698224

Epoch: 6| Step: 5
Training loss: 2.490251895618512
Validation loss: 2.6340972140848544

Epoch: 6| Step: 6
Training loss: 2.4814044779390536
Validation loss: 2.6380223642489824

Epoch: 6| Step: 7
Training loss: 3.0788226426259264
Validation loss: 2.639017399103852

Epoch: 6| Step: 8
Training loss: 2.988094548395577
Validation loss: 2.659656590427228

Epoch: 6| Step: 9
Training loss: 2.8410510995224385
Validation loss: 2.650011322018968

Epoch: 6| Step: 10
Training loss: 2.6954603956253496
Validation loss: 2.6732943313402275

Epoch: 6| Step: 11
Training loss: 2.9802213993650537
Validation loss: 2.669267192671019

Epoch: 6| Step: 12
Training loss: 2.5109568815308205
Validation loss: 2.6433855473726475

Epoch: 6| Step: 13
Training loss: 2.6945068924561415
Validation loss: 2.621836473420804

Epoch: 42| Step: 0
Training loss: 2.776649699561893
Validation loss: 2.6572242393073013

Epoch: 6| Step: 1
Training loss: 2.4992806353334616
Validation loss: 2.6495184885224115

Epoch: 6| Step: 2
Training loss: 2.6985683955002644
Validation loss: 2.6521044158954674

Epoch: 6| Step: 3
Training loss: 3.3142623531758484
Validation loss: 2.6387414798968303

Epoch: 6| Step: 4
Training loss: 2.7471998871025103
Validation loss: 2.6840060951495395

Epoch: 6| Step: 5
Training loss: 2.427745570481527
Validation loss: 2.657197499290288

Epoch: 6| Step: 6
Training loss: 3.651466043852685
Validation loss: 2.6610561218079

Epoch: 6| Step: 7
Training loss: 3.014915264197813
Validation loss: 2.654642905221219

Epoch: 6| Step: 8
Training loss: 2.484068077849934
Validation loss: 2.6423749004657826

Epoch: 6| Step: 9
Training loss: 2.5132501421785785
Validation loss: 2.6650412442070763

Epoch: 6| Step: 10
Training loss: 2.924640346488955
Validation loss: 2.660270802772564

Epoch: 6| Step: 11
Training loss: 2.791592601723576
Validation loss: 2.6556847382867863

Epoch: 6| Step: 12
Training loss: 2.974901111145335
Validation loss: 2.661374902670763

Epoch: 6| Step: 13
Training loss: 3.969139740798051
Validation loss: 2.6471910281943245

Epoch: 43| Step: 0
Training loss: 2.7507042416576235
Validation loss: 2.652746782223965

Epoch: 6| Step: 1
Training loss: 2.630555223811593
Validation loss: 2.6597570133246173

Epoch: 6| Step: 2
Training loss: 2.4913916198932506
Validation loss: 2.6671596546960203

Epoch: 6| Step: 3
Training loss: 3.1971073845520004
Validation loss: 2.665761071556868

Epoch: 6| Step: 4
Training loss: 2.8944846289788826
Validation loss: 2.6584951159873205

Epoch: 6| Step: 5
Training loss: 2.9139535182997554
Validation loss: 2.665921976015615

Epoch: 6| Step: 6
Training loss: 2.905378805862361
Validation loss: 2.656968170114918

Epoch: 6| Step: 7
Training loss: 3.35670883480533
Validation loss: 2.6432254784970164

Epoch: 6| Step: 8
Training loss: 3.405383638568506
Validation loss: 2.660950601298012

Epoch: 6| Step: 9
Training loss: 3.14963692283198
Validation loss: 2.6427512562408118

Epoch: 6| Step: 10
Training loss: 2.6999568123365725
Validation loss: 2.6549482800573583

Epoch: 6| Step: 11
Training loss: 2.4183444962177068
Validation loss: 2.6390718160465925

Epoch: 6| Step: 12
Training loss: 2.8705330022135045
Validation loss: 2.6603463953795425

Epoch: 6| Step: 13
Training loss: 2.644858313300832
Validation loss: 2.6504364064126738

Epoch: 44| Step: 0
Training loss: 3.142826656094604
Validation loss: 2.6466792909060692

Epoch: 6| Step: 1
Training loss: 3.1086362028135217
Validation loss: 2.643373652352955

Epoch: 6| Step: 2
Training loss: 2.2191982622388706
Validation loss: 2.6737903618161383

Epoch: 6| Step: 3
Training loss: 2.7771201171117794
Validation loss: 2.6679775729329496

Epoch: 6| Step: 4
Training loss: 3.5044470192203594
Validation loss: 2.641493140350868

Epoch: 6| Step: 5
Training loss: 3.050161613810214
Validation loss: 2.624696949440744

Epoch: 6| Step: 6
Training loss: 3.0064319959975174
Validation loss: 2.6430569167331557

Epoch: 6| Step: 7
Training loss: 3.1370790115538125
Validation loss: 2.6393887846385504

Epoch: 6| Step: 8
Training loss: 2.7021037912488928
Validation loss: 2.6517878926518232

Epoch: 6| Step: 9
Training loss: 2.0632248962864543
Validation loss: 2.6255681526148593

Epoch: 6| Step: 10
Training loss: 2.9411510746925327
Validation loss: 2.652878793424808

Epoch: 6| Step: 11
Training loss: 3.1934168632535602
Validation loss: 2.6608657101666933

Epoch: 6| Step: 12
Training loss: 2.7905217475200885
Validation loss: 2.636651441777676

Epoch: 6| Step: 13
Training loss: 2.642257998093905
Validation loss: 2.6599176477629296

Epoch: 45| Step: 0
Training loss: 2.6744586432442414
Validation loss: 2.665299854265758

Epoch: 6| Step: 1
Training loss: 2.3774549946501438
Validation loss: 2.6498289255826104

Epoch: 6| Step: 2
Training loss: 3.0011902673156
Validation loss: 2.6630971447393375

Epoch: 6| Step: 3
Training loss: 2.9321199212107336
Validation loss: 2.6653026244160594

Epoch: 6| Step: 4
Training loss: 2.8868300812640184
Validation loss: 2.6740266591435113

Epoch: 6| Step: 5
Training loss: 3.933724667322407
Validation loss: 2.6589382131390153

Epoch: 6| Step: 6
Training loss: 2.794667827541654
Validation loss: 2.6428221515241614

Epoch: 6| Step: 7
Training loss: 2.1501037794394064
Validation loss: 2.6494116879459324

Epoch: 6| Step: 8
Training loss: 2.8844951898035815
Validation loss: 2.6768772880201928

Epoch: 6| Step: 9
Training loss: 2.8498590267183337
Validation loss: 2.6508077191900887

Epoch: 6| Step: 10
Training loss: 2.2923913907913325
Validation loss: 2.6291541645603136

Epoch: 6| Step: 11
Training loss: 2.3483609428795207
Validation loss: 2.657325719835135

Epoch: 6| Step: 12
Training loss: 3.317042564930917
Validation loss: 2.6433968294074988

Epoch: 6| Step: 13
Training loss: 4.212115913788628
Validation loss: 2.65208510227942

Epoch: 46| Step: 0
Training loss: 3.040345065961623
Validation loss: 2.6601480921140657

Epoch: 6| Step: 1
Training loss: 3.087144987259795
Validation loss: 2.660273044283316

Epoch: 6| Step: 2
Training loss: 3.1682688692034136
Validation loss: 2.657284482472035

Epoch: 6| Step: 3
Training loss: 2.7175390243184823
Validation loss: 2.6654825664424138

Epoch: 6| Step: 4
Training loss: 3.224876868684488
Validation loss: 2.6398025069598647

Epoch: 6| Step: 5
Training loss: 2.7826868696090177
Validation loss: 2.662382852227442

Epoch: 6| Step: 6
Training loss: 2.2638621871507305
Validation loss: 2.658019092616026

Epoch: 6| Step: 7
Training loss: 2.883064734529693
Validation loss: 2.660398668979661

Epoch: 6| Step: 8
Training loss: 2.7412015441146504
Validation loss: 2.640067234634328

Epoch: 6| Step: 9
Training loss: 2.891070852176101
Validation loss: 2.6683254828319676

Epoch: 6| Step: 10
Training loss: 3.1498172283129926
Validation loss: 2.639535153679288

Epoch: 6| Step: 11
Training loss: 2.772079350143576
Validation loss: 2.6317305000686773

Epoch: 6| Step: 12
Training loss: 2.7984040412201883
Validation loss: 2.669153874093636

Epoch: 6| Step: 13
Training loss: 2.992347971943248
Validation loss: 2.6275510672938838

Epoch: 47| Step: 0
Training loss: 2.9028878401515965
Validation loss: 2.6530254908157693

Epoch: 6| Step: 1
Training loss: 3.362351912743792
Validation loss: 2.637579976560417

Epoch: 6| Step: 2
Training loss: 2.9530403892062167
Validation loss: 2.6522366340229917

Epoch: 6| Step: 3
Training loss: 3.476495840740857
Validation loss: 2.6466985926328936

Epoch: 6| Step: 4
Training loss: 2.506716289570179
Validation loss: 2.6498531161925163

Epoch: 6| Step: 5
Training loss: 3.7792702528535855
Validation loss: 2.6325221049592917

Epoch: 6| Step: 6
Training loss: 2.335263056017887
Validation loss: 2.6624986110022912

Epoch: 6| Step: 7
Training loss: 3.232475275710714
Validation loss: 2.671984075615297

Epoch: 6| Step: 8
Training loss: 2.565930837785878
Validation loss: 2.6308560141201736

Epoch: 6| Step: 9
Training loss: 2.7314617223318294
Validation loss: 2.625026159747008

Epoch: 6| Step: 10
Training loss: 2.4028928051747127
Validation loss: 2.6415627990138555

Epoch: 6| Step: 11
Training loss: 2.6840041733778954
Validation loss: 2.6778656320983427

Epoch: 6| Step: 12
Training loss: 2.403722947117709
Validation loss: 2.6522444499046403

Epoch: 6| Step: 13
Training loss: 3.006105567809363
Validation loss: 2.634743562014873

Epoch: 48| Step: 0
Training loss: 3.281470009830204
Validation loss: 2.6252993917371894

Epoch: 6| Step: 1
Training loss: 2.8295983960316184
Validation loss: 2.619205781603469

Epoch: 6| Step: 2
Training loss: 3.042835394271813
Validation loss: 2.6258615817241595

Epoch: 6| Step: 3
Training loss: 2.2565272279800292
Validation loss: 2.651220359673111

Epoch: 6| Step: 4
Training loss: 2.8488331731795737
Validation loss: 2.6451209978385846

Epoch: 6| Step: 5
Training loss: 3.2352968827914084
Validation loss: 2.6700941088879073

Epoch: 6| Step: 6
Training loss: 3.665811670205661
Validation loss: 2.6377414163065422

Epoch: 6| Step: 7
Training loss: 2.6907409820192867
Validation loss: 2.6591832401028856

Epoch: 6| Step: 8
Training loss: 2.774913642158175
Validation loss: 2.663807245996213

Epoch: 6| Step: 9
Training loss: 2.4739821797610317
Validation loss: 2.6507651076821124

Epoch: 6| Step: 10
Training loss: 2.971633795447482
Validation loss: 2.6685642344252596

Epoch: 6| Step: 11
Training loss: 2.3512136004082813
Validation loss: 2.6474089526593025

Epoch: 6| Step: 12
Training loss: 3.0017915780276088
Validation loss: 2.647966151344183

Epoch: 6| Step: 13
Training loss: 2.5591041579997675
Validation loss: 2.642338082937511

Epoch: 49| Step: 0
Training loss: 3.292349362298189
Validation loss: 2.655826012144502

Epoch: 6| Step: 1
Training loss: 2.3572343626880223
Validation loss: 2.649641849170376

Epoch: 6| Step: 2
Training loss: 3.0751148357503264
Validation loss: 2.6321409409713037

Epoch: 6| Step: 3
Training loss: 3.533278971079921
Validation loss: 2.6483928078798975

Epoch: 6| Step: 4
Training loss: 3.223204705933984
Validation loss: 2.6367098210106494

Epoch: 6| Step: 5
Training loss: 3.089666735260155
Validation loss: 2.634995374591251

Epoch: 6| Step: 6
Training loss: 2.411237922191282
Validation loss: 2.653717794228273

Epoch: 6| Step: 7
Training loss: 2.5507833997825453
Validation loss: 2.638142739833482

Epoch: 6| Step: 8
Training loss: 2.761536760822146
Validation loss: 2.6502641999290883

Epoch: 6| Step: 9
Training loss: 2.691728857717515
Validation loss: 2.6454546787209274

Epoch: 6| Step: 10
Training loss: 2.3283939078262597
Validation loss: 2.65188593763509

Epoch: 6| Step: 11
Training loss: 2.986349521158636
Validation loss: 2.665634216578105

Epoch: 6| Step: 12
Training loss: 3.0735704836367916
Validation loss: 2.64268385526148

Epoch: 6| Step: 13
Training loss: 3.18328788551789
Validation loss: 2.664765144029833

Epoch: 50| Step: 0
Training loss: 2.7624679908796708
Validation loss: 2.651069870310879

Epoch: 6| Step: 1
Training loss: 2.634532785272103
Validation loss: 2.6538721954714766

Epoch: 6| Step: 2
Training loss: 2.2782869299753776
Validation loss: 2.6723073204089465

Epoch: 6| Step: 3
Training loss: 2.0857138067308387
Validation loss: 2.6585127494886605

Epoch: 6| Step: 4
Training loss: 3.219971064088069
Validation loss: 2.6368291710049765

Epoch: 6| Step: 5
Training loss: 2.457662092045853
Validation loss: 2.6326516947850203

Epoch: 6| Step: 6
Training loss: 2.646591218150013
Validation loss: 2.677333198787811

Epoch: 6| Step: 7
Training loss: 2.6822607736135606
Validation loss: 2.656241446957218

Epoch: 6| Step: 8
Training loss: 3.939073278585635
Validation loss: 2.6358351950072345

Epoch: 6| Step: 9
Training loss: 3.007094101758143
Validation loss: 2.6615399636971695

Epoch: 6| Step: 10
Training loss: 3.6166891656928764
Validation loss: 2.6554568550042252

Epoch: 6| Step: 11
Training loss: 2.9531652054244755
Validation loss: 2.6755885633949243

Epoch: 6| Step: 12
Training loss: 3.2041649595602486
Validation loss: 2.6559777710870316

Epoch: 6| Step: 13
Training loss: 2.7146337633774467
Validation loss: 2.666729078088046

Epoch: 51| Step: 0
Training loss: 3.008445455164787
Validation loss: 2.6706140537949143

Epoch: 6| Step: 1
Training loss: 3.316019743378583
Validation loss: 2.650013771493442

Epoch: 6| Step: 2
Training loss: 3.2465485071799955
Validation loss: 2.671479312977274

Epoch: 6| Step: 3
Training loss: 3.191993239173326
Validation loss: 2.6341198771356757

Epoch: 6| Step: 4
Training loss: 3.2627790543634383
Validation loss: 2.6605450278616147

Epoch: 6| Step: 5
Training loss: 2.6618937952936994
Validation loss: 2.6528418249978722

Epoch: 6| Step: 6
Training loss: 2.2599917128081843
Validation loss: 2.668718907370455

Epoch: 6| Step: 7
Training loss: 2.887995828440604
Validation loss: 2.6411981525533585

Epoch: 6| Step: 8
Training loss: 2.4992300755350607
Validation loss: 2.6700000604612075

Epoch: 6| Step: 9
Training loss: 3.507198424422126
Validation loss: 2.6537416991822735

Epoch: 6| Step: 10
Training loss: 2.6486729880096767
Validation loss: 2.647475387988864

Epoch: 6| Step: 11
Training loss: 2.0281178901912167
Validation loss: 2.66978591011154

Epoch: 6| Step: 12
Training loss: 2.975221667326077
Validation loss: 2.641386858218028

Epoch: 6| Step: 13
Training loss: 2.6013959768343216
Validation loss: 2.682814268547738

Epoch: 52| Step: 0
Training loss: 2.924695616966712
Validation loss: 2.6662500489280605

Epoch: 6| Step: 1
Training loss: 3.5408365211702897
Validation loss: 2.669937948584572

Epoch: 6| Step: 2
Training loss: 2.7005156342552312
Validation loss: 2.642163737969889

Epoch: 6| Step: 3
Training loss: 3.209518973177222
Validation loss: 2.652525590778552

Epoch: 6| Step: 4
Training loss: 2.645414083910873
Validation loss: 2.635707763434433

Epoch: 6| Step: 5
Training loss: 2.8420725475718633
Validation loss: 2.6555898011214083

Epoch: 6| Step: 6
Training loss: 2.946220278292622
Validation loss: 2.6413400459426426

Epoch: 6| Step: 7
Training loss: 3.058692901290402
Validation loss: 2.6790076674538845

Epoch: 6| Step: 8
Training loss: 3.0635993696993835
Validation loss: 2.6618527201939948

Epoch: 6| Step: 9
Training loss: 3.0402991125122014
Validation loss: 2.655602832689768

Epoch: 6| Step: 10
Training loss: 2.743868929082016
Validation loss: 2.6567945526574244

Epoch: 6| Step: 11
Training loss: 2.717250103308837
Validation loss: 2.6524550408703877

Epoch: 6| Step: 12
Training loss: 2.1378298142502516
Validation loss: 2.6338846959166733

Epoch: 6| Step: 13
Training loss: 2.5840437947863855
Validation loss: 2.6555960374381216

Epoch: 53| Step: 0
Training loss: 2.6803228664920455
Validation loss: 2.66041772277237

Epoch: 6| Step: 1
Training loss: 2.3044617623161057
Validation loss: 2.6552674823494122

Epoch: 6| Step: 2
Training loss: 3.442084567088988
Validation loss: 2.6648498618782153

Epoch: 6| Step: 3
Training loss: 2.7041345375946273
Validation loss: 2.6283756394647315

Epoch: 6| Step: 4
Training loss: 2.806747062857574
Validation loss: 2.659063313752596

Epoch: 6| Step: 5
Training loss: 2.904870639094038
Validation loss: 2.6608698973653904

Epoch: 6| Step: 6
Training loss: 2.8205089553504195
Validation loss: 2.6623707686162086

Epoch: 6| Step: 7
Training loss: 3.444342028896655
Validation loss: 2.6503080363532106

Epoch: 6| Step: 8
Training loss: 2.6641058149200494
Validation loss: 2.6386721334362164

Epoch: 6| Step: 9
Training loss: 3.1073767600629782
Validation loss: 2.6658899755361523

Epoch: 6| Step: 10
Training loss: 3.1976825905951505
Validation loss: 2.6468329917870266

Epoch: 6| Step: 11
Training loss: 2.8856128024611234
Validation loss: 2.658214642152267

Epoch: 6| Step: 12
Training loss: 2.7083507146033057
Validation loss: 2.656851185199359

Epoch: 6| Step: 13
Training loss: 2.1583694877198436
Validation loss: 2.656608166515737

Epoch: 54| Step: 0
Training loss: 2.594247977010514
Validation loss: 2.6510859595599547

Epoch: 6| Step: 1
Training loss: 2.818807522679502
Validation loss: 2.652898725527712

Epoch: 6| Step: 2
Training loss: 2.972042145626616
Validation loss: 2.6558047481823452

Epoch: 6| Step: 3
Training loss: 2.3633524734231357
Validation loss: 2.6386811165079167

Epoch: 6| Step: 4
Training loss: 2.5771049562337067
Validation loss: 2.640276633535933

Epoch: 6| Step: 5
Training loss: 2.683169935318006
Validation loss: 2.653881228522437

Epoch: 6| Step: 6
Training loss: 4.057256983297413
Validation loss: 2.6273145916217167

Epoch: 6| Step: 7
Training loss: 2.90611037052221
Validation loss: 2.614466778112917

Epoch: 6| Step: 8
Training loss: 2.8609164726280443
Validation loss: 2.6406589056135417

Epoch: 6| Step: 9
Training loss: 2.7820889354232534
Validation loss: 2.6428305098522435

Epoch: 6| Step: 10
Training loss: 2.2367385421021155
Validation loss: 2.640839790976766

Epoch: 6| Step: 11
Training loss: 2.7672675476041695
Validation loss: 2.627770108339514

Epoch: 6| Step: 12
Training loss: 3.518645349711434
Validation loss: 2.6459233134902465

Epoch: 6| Step: 13
Training loss: 2.7196313591393704
Validation loss: 2.6411462647828445

Epoch: 55| Step: 0
Training loss: 3.146317669970897
Validation loss: 2.663465078342149

Epoch: 6| Step: 1
Training loss: 3.1515072985586836
Validation loss: 2.626670015139413

Epoch: 6| Step: 2
Training loss: 2.625472979849521
Validation loss: 2.6648502168638166

Epoch: 6| Step: 3
Training loss: 3.3460688171241584
Validation loss: 2.629299627154344

Epoch: 6| Step: 4
Training loss: 2.8114087000891153
Validation loss: 2.6468520444411214

Epoch: 6| Step: 5
Training loss: 3.1771049790609114
Validation loss: 2.6578940870519716

Epoch: 6| Step: 6
Training loss: 2.7309415350640944
Validation loss: 2.6400642243736816

Epoch: 6| Step: 7
Training loss: 2.8443441923011608
Validation loss: 2.6436062361037176

Epoch: 6| Step: 8
Training loss: 2.5226317261856224
Validation loss: 2.6476847403171977

Epoch: 6| Step: 9
Training loss: 2.8247445488946448
Validation loss: 2.6486724208224173

Epoch: 6| Step: 10
Training loss: 2.93001365372012
Validation loss: 2.6357598856833095

Epoch: 6| Step: 11
Training loss: 2.5037358980357807
Validation loss: 2.6499474907407463

Epoch: 6| Step: 12
Training loss: 3.094382327415314
Validation loss: 2.632807235052809

Epoch: 6| Step: 13
Training loss: 2.634473146757493
Validation loss: 2.676159398851326

Epoch: 56| Step: 0
Training loss: 3.458187896857003
Validation loss: 2.657971955499351

Epoch: 6| Step: 1
Training loss: 3.5936839222016213
Validation loss: 2.6250339882833504

Epoch: 6| Step: 2
Training loss: 2.89574774380082
Validation loss: 2.6272842188206944

Epoch: 6| Step: 3
Training loss: 2.7637515861958715
Validation loss: 2.644895576509157

Epoch: 6| Step: 4
Training loss: 2.928940334411738
Validation loss: 2.640243276475684

Epoch: 6| Step: 5
Training loss: 2.522169804506848
Validation loss: 2.6456894099441386

Epoch: 6| Step: 6
Training loss: 2.1497485790068325
Validation loss: 2.630013050947026

Epoch: 6| Step: 7
Training loss: 2.569486630296785
Validation loss: 2.6352443973557937

Epoch: 6| Step: 8
Training loss: 2.498787776781685
Validation loss: 2.625797683765884

Epoch: 6| Step: 9
Training loss: 3.318831528633851
Validation loss: 2.6580915732718533

Epoch: 6| Step: 10
Training loss: 3.0874251630724983
Validation loss: 2.6292847637862047

Epoch: 6| Step: 11
Training loss: 1.9709134400790669
Validation loss: 2.6474257642756998

Epoch: 6| Step: 12
Training loss: 3.296212947956914
Validation loss: 2.635240531332829

Epoch: 6| Step: 13
Training loss: 3.0339557330549036
Validation loss: 2.6166916165776657

Epoch: 57| Step: 0
Training loss: 2.0697195679525815
Validation loss: 2.6384383189524843

Epoch: 6| Step: 1
Training loss: 3.263360073095644
Validation loss: 2.6459444255403928

Epoch: 6| Step: 2
Training loss: 2.1657514350830875
Validation loss: 2.637662587599877

Epoch: 6| Step: 3
Training loss: 2.86938492141966
Validation loss: 2.6770473219403517

Epoch: 6| Step: 4
Training loss: 2.939624099574937
Validation loss: 2.6473950992881217

Epoch: 6| Step: 5
Training loss: 3.1509690625782403
Validation loss: 2.6603280811637444

Epoch: 6| Step: 6
Training loss: 3.2601096564262724
Validation loss: 2.669273393191059

Epoch: 6| Step: 7
Training loss: 2.803216490002036
Validation loss: 2.6549975092192772

Epoch: 6| Step: 8
Training loss: 3.0968664636888845
Validation loss: 2.646645556376265

Epoch: 6| Step: 9
Training loss: 2.8786645837022116
Validation loss: 2.6467890764999455

Epoch: 6| Step: 10
Training loss: 3.1097752299146673
Validation loss: 2.647419516459757

Epoch: 6| Step: 11
Training loss: 2.650602642847429
Validation loss: 2.657787253125407

Epoch: 6| Step: 12
Training loss: 2.888489465325499
Validation loss: 2.634783788998332

Epoch: 6| Step: 13
Training loss: 2.9349308547757054
Validation loss: 2.620862238884812

Epoch: 58| Step: 0
Training loss: 2.788786460402161
Validation loss: 2.6508237703787505

Epoch: 6| Step: 1
Training loss: 3.1191563710368837
Validation loss: 2.6698193752967034

Epoch: 6| Step: 2
Training loss: 3.091815073679068
Validation loss: 2.6800717840313646

Epoch: 6| Step: 3
Training loss: 3.6970406940955938
Validation loss: 2.6651986908288765

Epoch: 6| Step: 4
Training loss: 3.0607755827516576
Validation loss: 2.6551159903356774

Epoch: 6| Step: 5
Training loss: 3.010155654380456
Validation loss: 2.6503353048588174

Epoch: 6| Step: 6
Training loss: 3.1047835451810095
Validation loss: 2.664960066762762

Epoch: 6| Step: 7
Training loss: 2.4946124198937762
Validation loss: 2.6376042202212964

Epoch: 6| Step: 8
Training loss: 2.7919838189036
Validation loss: 2.667920654797362

Epoch: 6| Step: 9
Training loss: 2.8704869881278388
Validation loss: 2.6384126497574623

Epoch: 6| Step: 10
Training loss: 2.1493691383807674
Validation loss: 2.635853560744805

Epoch: 6| Step: 11
Training loss: 2.6513160208863527
Validation loss: 2.65052351862247

Epoch: 6| Step: 12
Training loss: 2.641986022161432
Validation loss: 2.6450261990811117

Epoch: 6| Step: 13
Training loss: 2.5412260726350167
Validation loss: 2.6663264825422717

Epoch: 59| Step: 0
Training loss: 2.3396362824080073
Validation loss: 2.6448281894650894

Epoch: 6| Step: 1
Training loss: 3.2366943888814403
Validation loss: 2.6532699565266813

Epoch: 6| Step: 2
Training loss: 2.897480850485584
Validation loss: 2.622421736861743

Epoch: 6| Step: 3
Training loss: 2.9449546859700564
Validation loss: 2.656442868531345

Epoch: 6| Step: 4
Training loss: 2.303454259889869
Validation loss: 2.6526808606557903

Epoch: 6| Step: 5
Training loss: 3.075994383520349
Validation loss: 2.6452448911359014

Epoch: 6| Step: 6
Training loss: 3.0949163839110225
Validation loss: 2.6268569532836032

Epoch: 6| Step: 7
Training loss: 2.7772980805624554
Validation loss: 2.6597832543577855

Epoch: 6| Step: 8
Training loss: 2.5140495342633926
Validation loss: 2.637112337343533

Epoch: 6| Step: 9
Training loss: 2.6886072760972377
Validation loss: 2.6382125510939978

Epoch: 6| Step: 10
Training loss: 2.834941594566719
Validation loss: 2.624737332353029

Epoch: 6| Step: 11
Training loss: 3.4047726568432726
Validation loss: 2.6305192778004995

Epoch: 6| Step: 12
Training loss: 3.541389424561564
Validation loss: 2.6264597539742587

Epoch: 6| Step: 13
Training loss: 2.1734553014820164
Validation loss: 2.676328576044242

Epoch: 60| Step: 0
Training loss: 3.074482578071271
Validation loss: 2.611705473981985

Epoch: 6| Step: 1
Training loss: 2.849327235540072
Validation loss: 2.654670445469388

Epoch: 6| Step: 2
Training loss: 3.422806843725355
Validation loss: 2.6401748006472117

Epoch: 6| Step: 3
Training loss: 3.544691850749859
Validation loss: 2.6359160303331177

Epoch: 6| Step: 4
Training loss: 2.5812070053251444
Validation loss: 2.6325060911773934

Epoch: 6| Step: 5
Training loss: 2.479798137694062
Validation loss: 2.620949148549151

Epoch: 6| Step: 6
Training loss: 3.1281859370040213
Validation loss: 2.66585822951162

Epoch: 6| Step: 7
Training loss: 2.774028618371341
Validation loss: 2.661047836622328

Epoch: 6| Step: 8
Training loss: 2.4097067044284013
Validation loss: 2.6652675317853634

Epoch: 6| Step: 9
Training loss: 2.604207112316125
Validation loss: 2.637976228423359

Epoch: 6| Step: 10
Training loss: 2.841755597316196
Validation loss: 2.6608132395572

Epoch: 6| Step: 11
Training loss: 2.786958130312902
Validation loss: 2.643416902834164

Epoch: 6| Step: 12
Training loss: 2.608008843693629
Validation loss: 2.657498190312774

Epoch: 6| Step: 13
Training loss: 2.9463023336210887
Validation loss: 2.6439795058243023

Epoch: 61| Step: 0
Training loss: 3.2238001047643317
Validation loss: 2.6315527752496113

Epoch: 6| Step: 1
Training loss: 3.2765559453357485
Validation loss: 2.6390870366583314

Epoch: 6| Step: 2
Training loss: 2.8808277606845842
Validation loss: 2.6295113352259722

Epoch: 6| Step: 3
Training loss: 3.190664179427818
Validation loss: 2.65406074521849

Epoch: 6| Step: 4
Training loss: 2.8869020974208275
Validation loss: 2.6502888837613994

Epoch: 6| Step: 5
Training loss: 3.06618667107929
Validation loss: 2.6491923237704103

Epoch: 6| Step: 6
Training loss: 2.1847932690693086
Validation loss: 2.6538000970794564

Epoch: 6| Step: 7
Training loss: 2.5457968272720217
Validation loss: 2.64148127077796

Epoch: 6| Step: 8
Training loss: 3.3992324074830496
Validation loss: 2.632687678871014

Epoch: 6| Step: 9
Training loss: 2.615366743639475
Validation loss: 2.627538175644608

Epoch: 6| Step: 10
Training loss: 2.8375621167076353
Validation loss: 2.6576083450659174

Epoch: 6| Step: 11
Training loss: 2.3335515215449676
Validation loss: 2.640453147842064

Epoch: 6| Step: 12
Training loss: 3.030826971680037
Validation loss: 2.6562055686598143

Epoch: 6| Step: 13
Training loss: 2.246191722557557
Validation loss: 2.634930674593312

Epoch: 62| Step: 0
Training loss: 2.6932653641701143
Validation loss: 2.651696647854879

Epoch: 6| Step: 1
Training loss: 2.3841103943156523
Validation loss: 2.6079953216796645

Epoch: 6| Step: 2
Training loss: 3.614933902035951
Validation loss: 2.65192134364941

Epoch: 6| Step: 3
Training loss: 3.6992356361398513
Validation loss: 2.635034412731319

Epoch: 6| Step: 4
Training loss: 3.3767845239685457
Validation loss: 2.6435759622336836

Epoch: 6| Step: 5
Training loss: 1.721992278215771
Validation loss: 2.6674242161355375

Epoch: 6| Step: 6
Training loss: 2.6558986655862444
Validation loss: 2.662253549252148

Epoch: 6| Step: 7
Training loss: 3.01985085832777
Validation loss: 2.6522599714078967

Epoch: 6| Step: 8
Training loss: 2.6282375896708405
Validation loss: 2.6497446843459205

Epoch: 6| Step: 9
Training loss: 2.7180299353449278
Validation loss: 2.637386493605321

Epoch: 6| Step: 10
Training loss: 2.423758088482507
Validation loss: 2.655577866160525

Epoch: 6| Step: 11
Training loss: 3.6383880160514326
Validation loss: 2.639120200453296

Epoch: 6| Step: 12
Training loss: 2.3694612265684842
Validation loss: 2.643385633687719

Epoch: 6| Step: 13
Training loss: 2.0861144258710134
Validation loss: 2.622503281839598

Epoch: 63| Step: 0
Training loss: 3.0669075525739533
Validation loss: 2.6419299200399737

Epoch: 6| Step: 1
Training loss: 2.2556494677097323
Validation loss: 2.6176147768447646

Epoch: 6| Step: 2
Training loss: 3.5943495540550643
Validation loss: 2.6396673914751982

Epoch: 6| Step: 3
Training loss: 2.905411465996368
Validation loss: 2.6558848468456078

Epoch: 6| Step: 4
Training loss: 2.6469381133462506
Validation loss: 2.6429982484828285

Epoch: 6| Step: 5
Training loss: 2.3851810877606616
Validation loss: 2.632679806876911

Epoch: 6| Step: 6
Training loss: 3.3570278750964824
Validation loss: 2.615335868417263

Epoch: 6| Step: 7
Training loss: 2.821125621293416
Validation loss: 2.6389642104183055

Epoch: 6| Step: 8
Training loss: 2.814662695235729
Validation loss: 2.6539539970257935

Epoch: 6| Step: 9
Training loss: 2.214821251918086
Validation loss: 2.6390773497207727

Epoch: 6| Step: 10
Training loss: 2.4736698236719894
Validation loss: 2.649601471386406

Epoch: 6| Step: 11
Training loss: 2.533780187380876
Validation loss: 2.641809122158655

Epoch: 6| Step: 12
Training loss: 3.641761176820103
Validation loss: 2.660313395972189

Epoch: 6| Step: 13
Training loss: 3.1559491911208006
Validation loss: 2.6116523592618313

Epoch: 64| Step: 0
Training loss: 2.445813404979026
Validation loss: 2.6354952214437

Epoch: 6| Step: 1
Training loss: 3.3181366377019437
Validation loss: 2.6283843592644893

Epoch: 6| Step: 2
Training loss: 1.998758168922512
Validation loss: 2.6573473888752193

Epoch: 6| Step: 3
Training loss: 2.8784957862281138
Validation loss: 2.6358296190261044

Epoch: 6| Step: 4
Training loss: 2.9708978211696486
Validation loss: 2.655408226173767

Epoch: 6| Step: 5
Training loss: 3.402061056487357
Validation loss: 2.6346855279410435

Epoch: 6| Step: 6
Training loss: 3.1027385490242447
Validation loss: 2.6679275733646777

Epoch: 6| Step: 7
Training loss: 2.588120014892435
Validation loss: 2.6253799352987848

Epoch: 6| Step: 8
Training loss: 3.878802249125029
Validation loss: 2.63670518465248

Epoch: 6| Step: 9
Training loss: 2.9615593813253533
Validation loss: 2.610359342728204

Epoch: 6| Step: 10
Training loss: 1.994816858781614
Validation loss: 2.641863787270813

Epoch: 6| Step: 11
Training loss: 2.7627149886627
Validation loss: 2.6382814811111683

Epoch: 6| Step: 12
Training loss: 3.0668728807471948
Validation loss: 2.6441850696633002

Epoch: 6| Step: 13
Training loss: 1.7836469618102682
Validation loss: 2.6783528149955145

Epoch: 65| Step: 0
Training loss: 3.216300847362863
Validation loss: 2.610446333960697

Epoch: 6| Step: 1
Training loss: 2.9039563387906746
Validation loss: 2.664017789972717

Epoch: 6| Step: 2
Training loss: 3.5402051415783813
Validation loss: 2.63314684980799

Epoch: 6| Step: 3
Training loss: 3.1636655205247024
Validation loss: 2.649066532486637

Epoch: 6| Step: 4
Training loss: 2.64659085780937
Validation loss: 2.6678635989948285

Epoch: 6| Step: 5
Training loss: 3.1588622510051296
Validation loss: 2.617869396512278

Epoch: 6| Step: 6
Training loss: 1.9371863695840728
Validation loss: 2.6310926713471

Epoch: 6| Step: 7
Training loss: 2.6223083501705178
Validation loss: 2.626115108457048

Epoch: 6| Step: 8
Training loss: 1.9134129881920312
Validation loss: 2.6304592149779875

Epoch: 6| Step: 9
Training loss: 3.2092678806216606
Validation loss: 2.623470325574015

Epoch: 6| Step: 10
Training loss: 2.1116656263911397
Validation loss: 2.632134196182728

Epoch: 6| Step: 11
Training loss: 3.131951953534027
Validation loss: 2.6284170455763203

Epoch: 6| Step: 12
Training loss: 3.2695481677056337
Validation loss: 2.655664744074386

Epoch: 6| Step: 13
Training loss: 3.067114642497833
Validation loss: 2.6223805235017164

Epoch: 66| Step: 0
Training loss: 3.210770577131697
Validation loss: 2.6482902735431364

Epoch: 6| Step: 1
Training loss: 2.838002863618402
Validation loss: 2.652855140648783

Epoch: 6| Step: 2
Training loss: 2.933148509040486
Validation loss: 2.632754227636121

Epoch: 6| Step: 3
Training loss: 2.8691690442240407
Validation loss: 2.6265562691618016

Epoch: 6| Step: 4
Training loss: 2.7101981174361396
Validation loss: 2.6399025566822063

Epoch: 6| Step: 5
Training loss: 2.633752490940011
Validation loss: 2.6255149004260954

Epoch: 6| Step: 6
Training loss: 3.012564415460656
Validation loss: 2.6351256376236076

Epoch: 6| Step: 7
Training loss: 2.73613067938385
Validation loss: 2.6423724439100886

Epoch: 6| Step: 8
Training loss: 3.3455543284556652
Validation loss: 2.6353728085510317

Epoch: 6| Step: 9
Training loss: 2.3589258840188143
Validation loss: 2.6268284275357887

Epoch: 6| Step: 10
Training loss: 2.593153275937638
Validation loss: 2.630049480529715

Epoch: 6| Step: 11
Training loss: 3.1901835196869515
Validation loss: 2.642117089370066

Epoch: 6| Step: 12
Training loss: 2.7891240473776273
Validation loss: 2.65230447561063

Epoch: 6| Step: 13
Training loss: 2.5006590928068344
Validation loss: 2.6528981920999715

Epoch: 67| Step: 0
Training loss: 3.006010551195542
Validation loss: 2.6682092283822016

Epoch: 6| Step: 1
Training loss: 2.6670393881991257
Validation loss: 2.6352824716393277

Epoch: 6| Step: 2
Training loss: 3.1808793367239447
Validation loss: 2.6280167916869432

Epoch: 6| Step: 3
Training loss: 2.2865083264654538
Validation loss: 2.637413279928224

Epoch: 6| Step: 4
Training loss: 2.6933042259185704
Validation loss: 2.6382394203719124

Epoch: 6| Step: 5
Training loss: 2.728337538088116
Validation loss: 2.633987610966274

Epoch: 6| Step: 6
Training loss: 3.1734289111909098
Validation loss: 2.6442246110475693

Epoch: 6| Step: 7
Training loss: 3.5141677209715194
Validation loss: 2.636100754835527

Epoch: 6| Step: 8
Training loss: 3.3255837637917223
Validation loss: 2.668020565335931

Epoch: 6| Step: 9
Training loss: 2.4040201928152305
Validation loss: 2.645895882518683

Epoch: 6| Step: 10
Training loss: 2.967274992076244
Validation loss: 2.6524766240547333

Epoch: 6| Step: 11
Training loss: 2.5575579927344663
Validation loss: 2.6804214037471423

Epoch: 6| Step: 12
Training loss: 2.1358780401251423
Validation loss: 2.6670978457760683

Epoch: 6| Step: 13
Training loss: 3.4303556238997874
Validation loss: 2.664130602415933

Epoch: 68| Step: 0
Training loss: 3.1231893252866487
Validation loss: 2.6375494167696663

Epoch: 6| Step: 1
Training loss: 2.7248743290751833
Validation loss: 2.660934317347989

Epoch: 6| Step: 2
Training loss: 2.717205968424423
Validation loss: 2.6226106562143054

Epoch: 6| Step: 3
Training loss: 2.5445598540954424
Validation loss: 2.6697185137139114

Epoch: 6| Step: 4
Training loss: 3.709977646217968
Validation loss: 2.6224718386013945

Epoch: 6| Step: 5
Training loss: 3.016670638726361
Validation loss: 2.615833222147869

Epoch: 6| Step: 6
Training loss: 2.8299359166738154
Validation loss: 2.635485014506856

Epoch: 6| Step: 7
Training loss: 2.918333794205079
Validation loss: 2.6291489551801073

Epoch: 6| Step: 8
Training loss: 2.481574057069467
Validation loss: 2.6355456077053825

Epoch: 6| Step: 9
Training loss: 2.6302447829537874
Validation loss: 2.6253124320678007

Epoch: 6| Step: 10
Training loss: 2.9380330352899504
Validation loss: 2.6337746371768773

Epoch: 6| Step: 11
Training loss: 3.1343384638869445
Validation loss: 2.602350568610812

Epoch: 6| Step: 12
Training loss: 2.763835004433546
Validation loss: 2.62482702033962

Epoch: 6| Step: 13
Training loss: 2.303655153951836
Validation loss: 2.6224354464805235

Epoch: 69| Step: 0
Training loss: 2.434049854429374
Validation loss: 2.6527425739889097

Epoch: 6| Step: 1
Training loss: 3.0024955224758942
Validation loss: 2.642605082796231

Epoch: 6| Step: 2
Training loss: 2.3849263804847376
Validation loss: 2.6392112044674483

Epoch: 6| Step: 3
Training loss: 2.420949254458584
Validation loss: 2.618681460289374

Epoch: 6| Step: 4
Training loss: 2.9532750005823942
Validation loss: 2.631543277823646

Epoch: 6| Step: 5
Training loss: 2.904654772626952
Validation loss: 2.618893284712455

Epoch: 6| Step: 6
Training loss: 3.0319073151183664
Validation loss: 2.617537196034614

Epoch: 6| Step: 7
Training loss: 2.800907573750754
Validation loss: 2.6618526835960474

Epoch: 6| Step: 8
Training loss: 2.859554431059051
Validation loss: 2.6525241482911723

Epoch: 6| Step: 9
Training loss: 2.865197096298048
Validation loss: 2.625669052776513

Epoch: 6| Step: 10
Training loss: 2.9000562070463944
Validation loss: 2.658430853874484

Epoch: 6| Step: 11
Training loss: 3.591246421166883
Validation loss: 2.6450633707563185

Epoch: 6| Step: 12
Training loss: 2.629434654333496
Validation loss: 2.6545959360681346

Epoch: 6| Step: 13
Training loss: 3.0369008670387485
Validation loss: 2.643451209051728

Epoch: 70| Step: 0
Training loss: 2.8589492230704647
Validation loss: 2.6520564878063775

Epoch: 6| Step: 1
Training loss: 3.178343242702496
Validation loss: 2.65585606046752

Epoch: 6| Step: 2
Training loss: 3.593673307180985
Validation loss: 2.633989843698539

Epoch: 6| Step: 3
Training loss: 3.1235851899839253
Validation loss: 2.650079811644952

Epoch: 6| Step: 4
Training loss: 3.5508011249787548
Validation loss: 2.6411325561930776

Epoch: 6| Step: 5
Training loss: 2.5177867438959236
Validation loss: 2.647809402473439

Epoch: 6| Step: 6
Training loss: 2.4576521969735796
Validation loss: 2.6370792474572258

Epoch: 6| Step: 7
Training loss: 2.826995118090068
Validation loss: 2.6327498063270762

Epoch: 6| Step: 8
Training loss: 2.978194462705622
Validation loss: 2.6387807132703696

Epoch: 6| Step: 9
Training loss: 2.6109197007582163
Validation loss: 2.6387451435683946

Epoch: 6| Step: 10
Training loss: 2.161978037910531
Validation loss: 2.6243681784523587

Epoch: 6| Step: 11
Training loss: 2.6846935789270128
Validation loss: 2.639657816413223

Epoch: 6| Step: 12
Training loss: 2.724033614820873
Validation loss: 2.6391462377230694

Epoch: 6| Step: 13
Training loss: 2.365391518926894
Validation loss: 2.6340150839530616

Epoch: 71| Step: 0
Training loss: 3.0025992259734577
Validation loss: 2.6562455705078563

Epoch: 6| Step: 1
Training loss: 3.2280967334495743
Validation loss: 2.64483285762556

Epoch: 6| Step: 2
Training loss: 3.1526886138033787
Validation loss: 2.6212792217298957

Epoch: 6| Step: 3
Training loss: 2.6642586644237514
Validation loss: 2.612060262618779

Epoch: 6| Step: 4
Training loss: 2.5241709490647697
Validation loss: 2.614465709302677

Epoch: 6| Step: 5
Training loss: 2.847429849967911
Validation loss: 2.6362905960327043

Epoch: 6| Step: 6
Training loss: 3.287477958808375
Validation loss: 2.6384027630961238

Epoch: 6| Step: 7
Training loss: 2.841810298507815
Validation loss: 2.638365184700061

Epoch: 6| Step: 8
Training loss: 2.3812152449507047
Validation loss: 2.6540074088479453

Epoch: 6| Step: 9
Training loss: 3.2732121428710927
Validation loss: 2.6381263005244553

Epoch: 6| Step: 10
Training loss: 3.2811567020776176
Validation loss: 2.636511852391669

Epoch: 6| Step: 11
Training loss: 1.91016118023632
Validation loss: 2.614866253091208

Epoch: 6| Step: 12
Training loss: 2.1898582825465986
Validation loss: 2.641115701606234

Epoch: 6| Step: 13
Training loss: 3.28539849475648
Validation loss: 2.6298447643478164

Epoch: 72| Step: 0
Training loss: 2.7670479255168194
Validation loss: 2.669440226528614

Epoch: 6| Step: 1
Training loss: 2.6229861572691506
Validation loss: 2.631883125811326

Epoch: 6| Step: 2
Training loss: 2.2925823347475833
Validation loss: 2.626863078242121

Epoch: 6| Step: 3
Training loss: 3.642153570474536
Validation loss: 2.665334536724638

Epoch: 6| Step: 4
Training loss: 2.375552865980335
Validation loss: 2.637849890614715

Epoch: 6| Step: 5
Training loss: 2.7211823380293683
Validation loss: 2.6748291889558824

Epoch: 6| Step: 6
Training loss: 3.2144334607757683
Validation loss: 2.613063736556627

Epoch: 6| Step: 7
Training loss: 3.5597317296648376
Validation loss: 2.6311443491303304

Epoch: 6| Step: 8
Training loss: 2.7436008560555294
Validation loss: 2.6439417759190738

Epoch: 6| Step: 9
Training loss: 3.0283302324188544
Validation loss: 2.657900149168253

Epoch: 6| Step: 10
Training loss: 2.826994527735236
Validation loss: 2.642176623266941

Epoch: 6| Step: 11
Training loss: 2.7255211183117853
Validation loss: 2.6325788594174675

Epoch: 6| Step: 12
Training loss: 3.0288475977483156
Validation loss: 2.6327634188327265

Epoch: 6| Step: 13
Training loss: 2.015840622361898
Validation loss: 2.6182139666543227

Epoch: 73| Step: 0
Training loss: 2.706283223782962
Validation loss: 2.6519457036794774

Epoch: 6| Step: 1
Training loss: 2.6493889554019083
Validation loss: 2.6354214627171504

Epoch: 6| Step: 2
Training loss: 2.3258490991097927
Validation loss: 2.6076895959468755

Epoch: 6| Step: 3
Training loss: 3.573404054606138
Validation loss: 2.6163084128073173

Epoch: 6| Step: 4
Training loss: 3.0954696037711456
Validation loss: 2.6158655997745472

Epoch: 6| Step: 5
Training loss: 3.245064582593486
Validation loss: 2.649314450354445

Epoch: 6| Step: 6
Training loss: 2.4184644742497268
Validation loss: 2.625792600995742

Epoch: 6| Step: 7
Training loss: 2.658497476642208
Validation loss: 2.633931401745903

Epoch: 6| Step: 8
Training loss: 2.8083607201603917
Validation loss: 2.6319486117799196

Epoch: 6| Step: 9
Training loss: 3.0236456747614966
Validation loss: 2.641551336395873

Epoch: 6| Step: 10
Training loss: 3.1092277760372027
Validation loss: 2.647999669612783

Epoch: 6| Step: 11
Training loss: 2.758623646866101
Validation loss: 2.6499906068427603

Epoch: 6| Step: 12
Training loss: 2.7473018587983615
Validation loss: 2.618655667916445

Epoch: 6| Step: 13
Training loss: 2.027639025755894
Validation loss: 2.6568953326759472

Epoch: 74| Step: 0
Training loss: 2.152480770118228
Validation loss: 2.626428983778495

Epoch: 6| Step: 1
Training loss: 2.2779519265237407
Validation loss: 2.6293296792941936

Epoch: 6| Step: 2
Training loss: 2.774448264319722
Validation loss: 2.6351142997458936

Epoch: 6| Step: 3
Training loss: 2.6368008523097095
Validation loss: 2.6254668614125523

Epoch: 6| Step: 4
Training loss: 2.6988560478432304
Validation loss: 2.6466973847656243

Epoch: 6| Step: 5
Training loss: 3.5253224543270396
Validation loss: 2.6476868201335133

Epoch: 6| Step: 6
Training loss: 2.7726962106275224
Validation loss: 2.654849316859845

Epoch: 6| Step: 7
Training loss: 2.721092355110628
Validation loss: 2.647459449646152

Epoch: 6| Step: 8
Training loss: 2.72231786477714
Validation loss: 2.6023971754429085

Epoch: 6| Step: 9
Training loss: 2.8352951289094364
Validation loss: 2.629739443029743

Epoch: 6| Step: 10
Training loss: 3.2422342687703596
Validation loss: 2.6338314814472126

Epoch: 6| Step: 11
Training loss: 3.166783347406194
Validation loss: 2.6397622234065827

Epoch: 6| Step: 12
Training loss: 3.1388748378682982
Validation loss: 2.644309117333746

Epoch: 6| Step: 13
Training loss: 3.37965072632993
Validation loss: 2.6163879338823537

Epoch: 75| Step: 0
Training loss: 2.60390561639164
Validation loss: 2.6265480215572725

Epoch: 6| Step: 1
Training loss: 3.3401683984208894
Validation loss: 2.644416887918693

Epoch: 6| Step: 2
Training loss: 2.5536293381442148
Validation loss: 2.624401765619223

Epoch: 6| Step: 3
Training loss: 2.8186371706691746
Validation loss: 2.6337408940713307

Epoch: 6| Step: 4
Training loss: 2.7605513245949
Validation loss: 2.623999266694004

Epoch: 6| Step: 5
Training loss: 3.08507098816448
Validation loss: 2.6436117181022425

Epoch: 6| Step: 6
Training loss: 2.0500277633647808
Validation loss: 2.637854601252386

Epoch: 6| Step: 7
Training loss: 2.8214434525026664
Validation loss: 2.6482363369255024

Epoch: 6| Step: 8
Training loss: 3.442271302493559
Validation loss: 2.6249119030398393

Epoch: 6| Step: 9
Training loss: 3.1119846147093178
Validation loss: 2.6447825242241043

Epoch: 6| Step: 10
Training loss: 3.2369158066768065
Validation loss: 2.6379253064563244

Epoch: 6| Step: 11
Training loss: 2.606119466389771
Validation loss: 2.626080973577512

Epoch: 6| Step: 12
Training loss: 2.1997975863193338
Validation loss: 2.6424911292254323

Epoch: 6| Step: 13
Training loss: 2.703953081423664
Validation loss: 2.6402252626722813

Epoch: 76| Step: 0
Training loss: 2.689092297474815
Validation loss: 2.6592158862284503

Epoch: 6| Step: 1
Training loss: 3.3366549790133546
Validation loss: 2.6183859635128184

Epoch: 6| Step: 2
Training loss: 2.4246332028820494
Validation loss: 2.648471963817745

Epoch: 6| Step: 3
Training loss: 2.5937867679058124
Validation loss: 2.652722069076016

Epoch: 6| Step: 4
Training loss: 4.138053354560034
Validation loss: 2.645133819301119

Epoch: 6| Step: 5
Training loss: 2.2412531697069467
Validation loss: 2.625097854048262

Epoch: 6| Step: 6
Training loss: 2.145371347218999
Validation loss: 2.640486147873566

Epoch: 6| Step: 7
Training loss: 2.8528875747281184
Validation loss: 2.6322828366026614

Epoch: 6| Step: 8
Training loss: 2.352743973602369
Validation loss: 2.664349663276461

Epoch: 6| Step: 9
Training loss: 2.3455684473918357
Validation loss: 2.6450336776547405

Epoch: 6| Step: 10
Training loss: 2.4792058177602776
Validation loss: 2.628608434539942

Epoch: 6| Step: 11
Training loss: 3.35418299953362
Validation loss: 2.6610884260781114

Epoch: 6| Step: 12
Training loss: 3.5693812251316426
Validation loss: 2.6014964225783404

Epoch: 6| Step: 13
Training loss: 2.5153637862975193
Validation loss: 2.6247573799990396

Epoch: 77| Step: 0
Training loss: 2.637475025366104
Validation loss: 2.628837750945848

Epoch: 6| Step: 1
Training loss: 2.8184646089804275
Validation loss: 2.617448123107092

Epoch: 6| Step: 2
Training loss: 1.6389429097872044
Validation loss: 2.632329288421275

Epoch: 6| Step: 3
Training loss: 2.6140888146662373
Validation loss: 2.6328971525176192

Epoch: 6| Step: 4
Training loss: 3.0535433838846346
Validation loss: 2.632866355316211

Epoch: 6| Step: 5
Training loss: 2.7479505705073484
Validation loss: 2.6636244419995316

Epoch: 6| Step: 6
Training loss: 2.813638329613781
Validation loss: 2.6214874613993335

Epoch: 6| Step: 7
Training loss: 2.8008891873596435
Validation loss: 2.6194289254037826

Epoch: 6| Step: 8
Training loss: 3.04653318395155
Validation loss: 2.6530263121777238

Epoch: 6| Step: 9
Training loss: 3.739459674175556
Validation loss: 2.6373888002511547

Epoch: 6| Step: 10
Training loss: 2.6956747060465385
Validation loss: 2.6343405090603556

Epoch: 6| Step: 11
Training loss: 2.4404081944331657
Validation loss: 2.6401143379690284

Epoch: 6| Step: 12
Training loss: 3.0951605769640422
Validation loss: 2.6240483769660807

Epoch: 6| Step: 13
Training loss: 3.7288708844796594
Validation loss: 2.644933862736063

Epoch: 78| Step: 0
Training loss: 3.2658900103202
Validation loss: 2.6223755866143046

Epoch: 6| Step: 1
Training loss: 2.663583841140387
Validation loss: 2.628807175345566

Epoch: 6| Step: 2
Training loss: 3.2948526986847644
Validation loss: 2.6277773940764453

Epoch: 6| Step: 3
Training loss: 2.965830923795637
Validation loss: 2.6379083507139436

Epoch: 6| Step: 4
Training loss: 2.3667449033816688
Validation loss: 2.6367724234443988

Epoch: 6| Step: 5
Training loss: 2.1396466546375503
Validation loss: 2.6335871514049325

Epoch: 6| Step: 6
Training loss: 2.7260295707794806
Validation loss: 2.6205162726610958

Epoch: 6| Step: 7
Training loss: 2.7637079351114773
Validation loss: 2.6424106095241924

Epoch: 6| Step: 8
Training loss: 2.838143995700717
Validation loss: 2.6528506731147456

Epoch: 6| Step: 9
Training loss: 3.0696798745415665
Validation loss: 2.637815633033996

Epoch: 6| Step: 10
Training loss: 2.7098307260383883
Validation loss: 2.6566488431025737

Epoch: 6| Step: 11
Training loss: 2.773533435290587
Validation loss: 2.6428187447448934

Epoch: 6| Step: 12
Training loss: 3.170931971883424
Validation loss: 2.635702258187853

Epoch: 6| Step: 13
Training loss: 3.0138617385914874
Validation loss: 2.6393191424183464

Epoch: 79| Step: 0
Training loss: 2.71960225394776
Validation loss: 2.64998973133205

Epoch: 6| Step: 1
Training loss: 2.9271812196340226
Validation loss: 2.6517583937608977

Epoch: 6| Step: 2
Training loss: 3.3191430040557264
Validation loss: 2.618435477683074

Epoch: 6| Step: 3
Training loss: 3.5919511356386002
Validation loss: 2.6533688607555344

Epoch: 6| Step: 4
Training loss: 2.4742469913664418
Validation loss: 2.649092379093066

Epoch: 6| Step: 5
Training loss: 2.348556066833419
Validation loss: 2.6326404971904354

Epoch: 6| Step: 6
Training loss: 2.379508507572491
Validation loss: 2.6444115559160974

Epoch: 6| Step: 7
Training loss: 3.53913822050963
Validation loss: 2.653335099198303

Epoch: 6| Step: 8
Training loss: 2.793714218422548
Validation loss: 2.656062000433143

Epoch: 6| Step: 9
Training loss: 3.2386181406484926
Validation loss: 2.64304085523482

Epoch: 6| Step: 10
Training loss: 2.5757434364345557
Validation loss: 2.6153671220052304

Epoch: 6| Step: 11
Training loss: 2.595114291693274
Validation loss: 2.6459922371384916

Epoch: 6| Step: 12
Training loss: 2.535669683298251
Validation loss: 2.6225576665586767

Epoch: 6| Step: 13
Training loss: 2.11113953431833
Validation loss: 2.637270747551147

Epoch: 80| Step: 0
Training loss: 3.785148187555913
Validation loss: 2.633253224536656

Epoch: 6| Step: 1
Training loss: 1.933050892467307
Validation loss: 2.6403221854291545

Epoch: 6| Step: 2
Training loss: 2.2794538769098245
Validation loss: 2.6369250888825846

Epoch: 6| Step: 3
Training loss: 2.49360487283788
Validation loss: 2.6202988490907857

Epoch: 6| Step: 4
Training loss: 2.917358988383509
Validation loss: 2.6324916442162594

Epoch: 6| Step: 5
Training loss: 2.7033461992903858
Validation loss: 2.614780075605996

Epoch: 6| Step: 6
Training loss: 3.1628665877459774
Validation loss: 2.6347918619543957

Epoch: 6| Step: 7
Training loss: 3.453730879574347
Validation loss: 2.6369402222346054

Epoch: 6| Step: 8
Training loss: 2.6962875592795066
Validation loss: 2.6301932722009926

Epoch: 6| Step: 9
Training loss: 2.739670165877245
Validation loss: 2.6511061178838733

Epoch: 6| Step: 10
Training loss: 3.590224684800871
Validation loss: 2.6303240240225594

Epoch: 6| Step: 11
Training loss: 2.33421032183008
Validation loss: 2.638839399995964

Epoch: 6| Step: 12
Training loss: 2.8016342502816234
Validation loss: 2.645343388921855

Epoch: 6| Step: 13
Training loss: 2.4217392421943034
Validation loss: 2.6316274743444423

Epoch: 81| Step: 0
Training loss: 2.383885076543436
Validation loss: 2.6411424840806714

Epoch: 6| Step: 1
Training loss: 3.309839727895148
Validation loss: 2.6244683398710977

Epoch: 6| Step: 2
Training loss: 2.425996386928651
Validation loss: 2.6539330624357276

Epoch: 6| Step: 3
Training loss: 2.6984205818639904
Validation loss: 2.6321266848541574

Epoch: 6| Step: 4
Training loss: 2.710309926149124
Validation loss: 2.6183460642325103

Epoch: 6| Step: 5
Training loss: 2.825872883933802
Validation loss: 2.615493164746809

Epoch: 6| Step: 6
Training loss: 2.941207494011116
Validation loss: 2.6388294950176037

Epoch: 6| Step: 7
Training loss: 3.0722293063452475
Validation loss: 2.6398370912789693

Epoch: 6| Step: 8
Training loss: 3.6667323684585784
Validation loss: 2.6329272755691657

Epoch: 6| Step: 9
Training loss: 2.5440257229974033
Validation loss: 2.6190000425992146

Epoch: 6| Step: 10
Training loss: 2.418389846050311
Validation loss: 2.6341809503910065

Epoch: 6| Step: 11
Training loss: 2.8629858012858285
Validation loss: 2.6307798352995877

Epoch: 6| Step: 12
Training loss: 2.8715547567809683
Validation loss: 2.6116329722671194

Epoch: 6| Step: 13
Training loss: 2.8379773246821682
Validation loss: 2.6515362758032057

Epoch: 82| Step: 0
Training loss: 2.262544840162855
Validation loss: 2.6396634532629197

Epoch: 6| Step: 1
Training loss: 3.1247079331288545
Validation loss: 2.6435080983578776

Epoch: 6| Step: 2
Training loss: 2.1262042055575163
Validation loss: 2.6463923423714006

Epoch: 6| Step: 3
Training loss: 2.576358444248772
Validation loss: 2.631903559303277

Epoch: 6| Step: 4
Training loss: 2.1629884994984145
Validation loss: 2.6490066250291364

Epoch: 6| Step: 5
Training loss: 2.776554558892344
Validation loss: 2.599229843855855

Epoch: 6| Step: 6
Training loss: 3.2993368927535673
Validation loss: 2.6176920458805895

Epoch: 6| Step: 7
Training loss: 2.554472094679274
Validation loss: 2.6190551999350884

Epoch: 6| Step: 8
Training loss: 2.8079441895168875
Validation loss: 2.6000106387319057

Epoch: 6| Step: 9
Training loss: 2.757142328633583
Validation loss: 2.659153551380089

Epoch: 6| Step: 10
Training loss: 3.3064349809613973
Validation loss: 2.6467106092839825

Epoch: 6| Step: 11
Training loss: 3.1155129430701294
Validation loss: 2.6385956993361535

Epoch: 6| Step: 12
Training loss: 3.423349280637489
Validation loss: 2.6482561074559996

Epoch: 6| Step: 13
Training loss: 3.2241605449771877
Validation loss: 2.6525730778949477

Epoch: 83| Step: 0
Training loss: 3.0156839789913366
Validation loss: 2.6321495801192936

Epoch: 6| Step: 1
Training loss: 3.0991884461352464
Validation loss: 2.6305816289643738

Epoch: 6| Step: 2
Training loss: 3.1968068403657695
Validation loss: 2.63913863949845

Epoch: 6| Step: 3
Training loss: 2.8929298903049356
Validation loss: 2.6493836498556425

Epoch: 6| Step: 4
Training loss: 2.469520158993206
Validation loss: 2.6366158550182806

Epoch: 6| Step: 5
Training loss: 2.8240586864652104
Validation loss: 2.6384220991362537

Epoch: 6| Step: 6
Training loss: 2.472799529011835
Validation loss: 2.6272538378622445

Epoch: 6| Step: 7
Training loss: 2.498726997517692
Validation loss: 2.662260322696133

Epoch: 6| Step: 8
Training loss: 2.8282037376276064
Validation loss: 2.6079066011380054

Epoch: 6| Step: 9
Training loss: 2.2774498000406775
Validation loss: 2.63980128816803

Epoch: 6| Step: 10
Training loss: 3.5914649664821665
Validation loss: 2.6425528743719764

Epoch: 6| Step: 11
Training loss: 2.9050219822903807
Validation loss: 2.616493660363701

Epoch: 6| Step: 12
Training loss: 3.0263687631086573
Validation loss: 2.6383497204040176

Epoch: 6| Step: 13
Training loss: 2.7450882656727504
Validation loss: 2.6319660666373763

Epoch: 84| Step: 0
Training loss: 3.476342217828116
Validation loss: 2.6218465125091606

Epoch: 6| Step: 1
Training loss: 2.9742858670725285
Validation loss: 2.6292537672896223

Epoch: 6| Step: 2
Training loss: 3.2114732578428615
Validation loss: 2.638740929034079

Epoch: 6| Step: 3
Training loss: 2.203356899745257
Validation loss: 2.638839081828682

Epoch: 6| Step: 4
Training loss: 2.637441849632494
Validation loss: 2.6571327011968813

Epoch: 6| Step: 5
Training loss: 3.236762451053642
Validation loss: 2.6237902243858393

Epoch: 6| Step: 6
Training loss: 2.6184844945361467
Validation loss: 2.6406936612310052

Epoch: 6| Step: 7
Training loss: 3.141217987103869
Validation loss: 2.670071616759905

Epoch: 6| Step: 8
Training loss: 1.903879912283847
Validation loss: 2.6260554051965554

Epoch: 6| Step: 9
Training loss: 2.873156910441726
Validation loss: 2.6297967040198524

Epoch: 6| Step: 10
Training loss: 3.0694510535106208
Validation loss: 2.628645278573429

Epoch: 6| Step: 11
Training loss: 2.2857380444279616
Validation loss: 2.6227175990365956

Epoch: 6| Step: 12
Training loss: 2.6500978019948507
Validation loss: 2.658532221806699

Epoch: 6| Step: 13
Training loss: 3.4901768573446867
Validation loss: 2.642796693697251

Epoch: 85| Step: 0
Training loss: 2.7816525285870846
Validation loss: 2.6562086928531956

Epoch: 6| Step: 1
Training loss: 2.8618548536622495
Validation loss: 2.649461957594618

Epoch: 6| Step: 2
Training loss: 3.082032487721551
Validation loss: 2.6064414165471104

Epoch: 6| Step: 3
Training loss: 2.54679243269872
Validation loss: 2.6440738951329203

Epoch: 6| Step: 4
Training loss: 3.28523869359987
Validation loss: 2.6188558991882256

Epoch: 6| Step: 5
Training loss: 2.145227871508531
Validation loss: 2.63723379946776

Epoch: 6| Step: 6
Training loss: 3.2943425146855847
Validation loss: 2.663937547540651

Epoch: 6| Step: 7
Training loss: 2.7547309235922235
Validation loss: 2.6564298893374216

Epoch: 6| Step: 8
Training loss: 1.3773606583308802
Validation loss: 2.6663083113206363

Epoch: 6| Step: 9
Training loss: 3.265145298527403
Validation loss: 2.6450179935611464

Epoch: 6| Step: 10
Training loss: 3.2690095291535597
Validation loss: 2.6473982658346893

Epoch: 6| Step: 11
Training loss: 2.557461973114557
Validation loss: 2.6559172767563712

Epoch: 6| Step: 12
Training loss: 2.874261844246622
Validation loss: 2.6338344375103837

Epoch: 6| Step: 13
Training loss: 3.3737787933647363
Validation loss: 2.6273442195717145

Epoch: 86| Step: 0
Training loss: 2.508869079287884
Validation loss: 2.6291262361162264

Epoch: 6| Step: 1
Training loss: 3.3220353985851996
Validation loss: 2.638358646272662

Epoch: 6| Step: 2
Training loss: 2.314801282489923
Validation loss: 2.6584486970632284

Epoch: 6| Step: 3
Training loss: 2.9986594701906486
Validation loss: 2.6579870037423876

Epoch: 6| Step: 4
Training loss: 3.0223929402185625
Validation loss: 2.6625312097370504

Epoch: 6| Step: 5
Training loss: 2.64495873200902
Validation loss: 2.646990027047404

Epoch: 6| Step: 6
Training loss: 2.963549425665828
Validation loss: 2.6534170921866336

Epoch: 6| Step: 7
Training loss: 2.627669929359453
Validation loss: 2.647300794502859

Epoch: 6| Step: 8
Training loss: 3.252599703457623
Validation loss: 2.6462619422383766

Epoch: 6| Step: 9
Training loss: 2.58619988254166
Validation loss: 2.642412553784454

Epoch: 6| Step: 10
Training loss: 2.8461493127275235
Validation loss: 2.6749037260959714

Epoch: 6| Step: 11
Training loss: 2.8385428239079253
Validation loss: 2.6570696266533975

Epoch: 6| Step: 12
Training loss: 3.136214618384456
Validation loss: 2.65456673492788

Epoch: 6| Step: 13
Training loss: 2.337032099929801
Validation loss: 2.657713097335065

Epoch: 87| Step: 0
Training loss: 2.694122228549949
Validation loss: 2.629299465299699

Epoch: 6| Step: 1
Training loss: 3.143640541309758
Validation loss: 2.6602650370894136

Epoch: 6| Step: 2
Training loss: 2.63372352300732
Validation loss: 2.6477679007122865

Epoch: 6| Step: 3
Training loss: 2.5515745836615378
Validation loss: 2.6647720380801667

Epoch: 6| Step: 4
Training loss: 2.924173358928784
Validation loss: 2.6306341154170245

Epoch: 6| Step: 5
Training loss: 2.9789608081750703
Validation loss: 2.6592591239168035

Epoch: 6| Step: 6
Training loss: 3.0336247216863144
Validation loss: 2.6523130684130556

Epoch: 6| Step: 7
Training loss: 3.397891086191281
Validation loss: 2.6486732745069492

Epoch: 6| Step: 8
Training loss: 2.6679347917174523
Validation loss: 2.6267605516210093

Epoch: 6| Step: 9
Training loss: 2.5747223565499002
Validation loss: 2.6534771261468424

Epoch: 6| Step: 10
Training loss: 3.257884219178344
Validation loss: 2.631873985114589

Epoch: 6| Step: 11
Training loss: 2.679482499447188
Validation loss: 2.637816683636222

Epoch: 6| Step: 12
Training loss: 2.6585007051815284
Validation loss: 2.6317723881851305

Epoch: 6| Step: 13
Training loss: 2.277448753173985
Validation loss: 2.6591722149675574

Epoch: 88| Step: 0
Training loss: 3.018651046868656
Validation loss: 2.6444479044493523

Epoch: 6| Step: 1
Training loss: 2.308972013050301
Validation loss: 2.6303801066327135

Epoch: 6| Step: 2
Training loss: 2.978028904904596
Validation loss: 2.6356272125544167

Epoch: 6| Step: 3
Training loss: 2.476405189885077
Validation loss: 2.6185699648974436

Epoch: 6| Step: 4
Training loss: 2.9442567425605533
Validation loss: 2.6535211771105307

Epoch: 6| Step: 5
Training loss: 2.5639649832323568
Validation loss: 2.6351886887204867

Epoch: 6| Step: 6
Training loss: 2.498816019076311
Validation loss: 2.6150893446599492

Epoch: 6| Step: 7
Training loss: 3.176349058922242
Validation loss: 2.6199725703122043

Epoch: 6| Step: 8
Training loss: 3.273087585247031
Validation loss: 2.651546856999997

Epoch: 6| Step: 9
Training loss: 3.0292184845394026
Validation loss: 2.6374562033814706

Epoch: 6| Step: 10
Training loss: 2.255007787043962
Validation loss: 2.6227496218964563

Epoch: 6| Step: 11
Training loss: 3.7140201012514726
Validation loss: 2.6539953257416196

Epoch: 6| Step: 12
Training loss: 2.400089850333285
Validation loss: 2.632092694655631

Epoch: 6| Step: 13
Training loss: 2.556545037215897
Validation loss: 2.6316602353255356

Epoch: 89| Step: 0
Training loss: 3.1812127131766985
Validation loss: 2.617256684996659

Epoch: 6| Step: 1
Training loss: 2.9838321851223752
Validation loss: 2.6426186653933916

Epoch: 6| Step: 2
Training loss: 3.1747675893230074
Validation loss: 2.632766783120103

Epoch: 6| Step: 3
Training loss: 2.3454547023168275
Validation loss: 2.6200567032440083

Epoch: 6| Step: 4
Training loss: 2.94965542219429
Validation loss: 2.640484893474072

Epoch: 6| Step: 5
Training loss: 3.230738710426962
Validation loss: 2.6427279512952393

Epoch: 6| Step: 6
Training loss: 2.166385436757666
Validation loss: 2.620326100667438

Epoch: 6| Step: 7
Training loss: 2.92353732714923
Validation loss: 2.64248984667288

Epoch: 6| Step: 8
Training loss: 2.6144408431620323
Validation loss: 2.6446459270281077

Epoch: 6| Step: 9
Training loss: 2.970421571449714
Validation loss: 2.636414472553886

Epoch: 6| Step: 10
Training loss: 2.380234220824473
Validation loss: 2.6461892121600767

Epoch: 6| Step: 11
Training loss: 2.629945546735975
Validation loss: 2.660833247109964

Epoch: 6| Step: 12
Training loss: 2.7430488124930856
Validation loss: 2.640460434506642

Epoch: 6| Step: 13
Training loss: 3.5836023776755335
Validation loss: 2.658911114332989

Epoch: 90| Step: 0
Training loss: 2.7328419774833788
Validation loss: 2.6403882660279585

Epoch: 6| Step: 1
Training loss: 3.0843229681726054
Validation loss: 2.637847377364107

Epoch: 6| Step: 2
Training loss: 3.0601924065330337
Validation loss: 2.6448608198893737

Epoch: 6| Step: 3
Training loss: 2.5106812228231443
Validation loss: 2.642841778250971

Epoch: 6| Step: 4
Training loss: 2.466002855248202
Validation loss: 2.628296017283929

Epoch: 6| Step: 5
Training loss: 3.1582762002600258
Validation loss: 2.6441645357163903

Epoch: 6| Step: 6
Training loss: 2.5373018234362443
Validation loss: 2.6493361945956035

Epoch: 6| Step: 7
Training loss: 2.603001743434772
Validation loss: 2.645320708637987

Epoch: 6| Step: 8
Training loss: 2.5967321143106834
Validation loss: 2.6349801541812576

Epoch: 6| Step: 9
Training loss: 3.1069878851166637
Validation loss: 2.6285746270662633

Epoch: 6| Step: 10
Training loss: 3.3451700492936687
Validation loss: 2.628009887061253

Epoch: 6| Step: 11
Training loss: 2.2818232821912177
Validation loss: 2.6224816162033724

Epoch: 6| Step: 12
Training loss: 3.3278637993983757
Validation loss: 2.6466798536773335

Epoch: 6| Step: 13
Training loss: 2.0666653735659257
Validation loss: 2.650895972930176

Epoch: 91| Step: 0
Training loss: 2.7762857774733285
Validation loss: 2.6548850193938

Epoch: 6| Step: 1
Training loss: 3.4564124291659937
Validation loss: 2.6580072110010056

Epoch: 6| Step: 2
Training loss: 2.6860931617674484
Validation loss: 2.6158296557528278

Epoch: 6| Step: 3
Training loss: 2.6627825125948803
Validation loss: 2.6139408000740705

Epoch: 6| Step: 4
Training loss: 2.600498474460969
Validation loss: 2.644570351918041

Epoch: 6| Step: 5
Training loss: 2.6280592394209386
Validation loss: 2.632209370622352

Epoch: 6| Step: 6
Training loss: 3.6308254919579594
Validation loss: 2.621184339226767

Epoch: 6| Step: 7
Training loss: 2.657716144517296
Validation loss: 2.6047804380295783

Epoch: 6| Step: 8
Training loss: 2.712651043742934
Validation loss: 2.614739230066422

Epoch: 6| Step: 9
Training loss: 2.9943909661733854
Validation loss: 2.6479707650809554

Epoch: 6| Step: 10
Training loss: 3.284871600470799
Validation loss: 2.646674422590619

Epoch: 6| Step: 11
Training loss: 2.5702781790902933
Validation loss: 2.62674345646726

Epoch: 6| Step: 12
Training loss: 2.628993040015409
Validation loss: 2.6315289980104626

Epoch: 6| Step: 13
Training loss: 2.0917588060407266
Validation loss: 2.6205956768110044

Epoch: 92| Step: 0
Training loss: 2.968108097750424
Validation loss: 2.6243989278753337

Epoch: 6| Step: 1
Training loss: 3.2967176354623926
Validation loss: 2.6362690223107874

Epoch: 6| Step: 2
Training loss: 2.8735108872833486
Validation loss: 2.6367700365335858

Epoch: 6| Step: 3
Training loss: 2.900692784660493
Validation loss: 2.649619544323273

Epoch: 6| Step: 4
Training loss: 2.1154204592302293
Validation loss: 2.6396159524241853

Epoch: 6| Step: 5
Training loss: 3.4916173823724233
Validation loss: 2.6424254902581734

Epoch: 6| Step: 6
Training loss: 2.7579067311384358
Validation loss: 2.656367292233404

Epoch: 6| Step: 7
Training loss: 3.1183448115480266
Validation loss: 2.650434193338552

Epoch: 6| Step: 8
Training loss: 2.8967039779993446
Validation loss: 2.6427935410381553

Epoch: 6| Step: 9
Training loss: 2.603669467510214
Validation loss: 2.653080560639184

Epoch: 6| Step: 10
Training loss: 2.7787108242415366
Validation loss: 2.641656446865762

Epoch: 6| Step: 11
Training loss: 2.6869545316494223
Validation loss: 2.6337456597539473

Epoch: 6| Step: 12
Training loss: 2.5385056105035706
Validation loss: 2.6380132768943043

Epoch: 6| Step: 13
Training loss: 2.323054892585637
Validation loss: 2.632521720294668

Epoch: 93| Step: 0
Training loss: 3.193144046161421
Validation loss: 2.618139989373459

Epoch: 6| Step: 1
Training loss: 3.452113905414274
Validation loss: 2.635290906899158

Epoch: 6| Step: 2
Training loss: 2.6887333723376092
Validation loss: 2.6430549797365694

Epoch: 6| Step: 3
Training loss: 2.7278250582918657
Validation loss: 2.645691527181531

Epoch: 6| Step: 4
Training loss: 1.6939334446286676
Validation loss: 2.6205786627469627

Epoch: 6| Step: 5
Training loss: 3.81940997175593
Validation loss: 2.6111733042195233

Epoch: 6| Step: 6
Training loss: 2.8899350554352927
Validation loss: 2.6446384270011594

Epoch: 6| Step: 7
Training loss: 2.412129538756815
Validation loss: 2.6376023710704715

Epoch: 6| Step: 8
Training loss: 3.2157187400923077
Validation loss: 2.640191628226438

Epoch: 6| Step: 9
Training loss: 3.0191168457547835
Validation loss: 2.6394384331871077

Epoch: 6| Step: 10
Training loss: 2.0195447083841938
Validation loss: 2.6310041216518596

Epoch: 6| Step: 11
Training loss: 2.868780956225952
Validation loss: 2.6209335570397543

Epoch: 6| Step: 12
Training loss: 2.375471770963308
Validation loss: 2.6480716509866546

Epoch: 6| Step: 13
Training loss: 2.7099679757791484
Validation loss: 2.6242360372097604

Epoch: 94| Step: 0
Training loss: 3.3606003057002853
Validation loss: 2.608617517293343

Epoch: 6| Step: 1
Training loss: 3.1147984118925764
Validation loss: 2.6275370867837236

Epoch: 6| Step: 2
Training loss: 2.889666754176909
Validation loss: 2.606419279044057

Epoch: 6| Step: 3
Training loss: 1.9845934169442903
Validation loss: 2.6432503114698473

Epoch: 6| Step: 4
Training loss: 3.550570810123036
Validation loss: 2.6501621254208456

Epoch: 6| Step: 5
Training loss: 2.211080270208142
Validation loss: 2.6148502488318113

Epoch: 6| Step: 6
Training loss: 2.5919937254511862
Validation loss: 2.6123625828535086

Epoch: 6| Step: 7
Training loss: 2.5842443726079694
Validation loss: 2.6577722982804737

Epoch: 6| Step: 8
Training loss: 2.4411384618761938
Validation loss: 2.652057288685226

Epoch: 6| Step: 9
Training loss: 2.923194954299957
Validation loss: 2.653750636073001

Epoch: 6| Step: 10
Training loss: 3.0286548950024765
Validation loss: 2.6393096166021315

Epoch: 6| Step: 11
Training loss: 2.6408937757594435
Validation loss: 2.6365530082114463

Epoch: 6| Step: 12
Training loss: 3.332029675822093
Validation loss: 2.633522229904776

Epoch: 6| Step: 13
Training loss: 2.5786472600754315
Validation loss: 2.62641701489097

Epoch: 95| Step: 0
Training loss: 3.095769820111594
Validation loss: 2.636731129096538

Epoch: 6| Step: 1
Training loss: 3.129355485267506
Validation loss: 2.6244927515373324

Epoch: 6| Step: 2
Training loss: 2.6278040305509345
Validation loss: 2.6411050596905032

Epoch: 6| Step: 3
Training loss: 2.2912799393299754
Validation loss: 2.6127534202038447

Epoch: 6| Step: 4
Training loss: 2.6391863092049457
Validation loss: 2.6333821757771365

Epoch: 6| Step: 5
Training loss: 2.6343232752743813
Validation loss: 2.6417403375610014

Epoch: 6| Step: 6
Training loss: 2.313676483288822
Validation loss: 2.6186833859452254

Epoch: 6| Step: 7
Training loss: 3.267423143832842
Validation loss: 2.634075747949151

Epoch: 6| Step: 8
Training loss: 3.303121570018767
Validation loss: 2.6618702601837447

Epoch: 6| Step: 9
Training loss: 2.7005761097051684
Validation loss: 2.616452163542657

Epoch: 6| Step: 10
Training loss: 2.7178439680481588
Validation loss: 2.6355556558552626

Epoch: 6| Step: 11
Training loss: 3.3419378486118463
Validation loss: 2.632627515555605

Epoch: 6| Step: 12
Training loss: 2.7070745819719115
Validation loss: 2.607696219137402

Epoch: 6| Step: 13
Training loss: 2.633910179535799
Validation loss: 2.6415511248256216

Epoch: 96| Step: 0
Training loss: 3.154087043136824
Validation loss: 2.6280804318154676

Epoch: 6| Step: 1
Training loss: 2.390478191979196
Validation loss: 2.6549735528084324

Epoch: 6| Step: 2
Training loss: 3.338520274140867
Validation loss: 2.607500995576845

Epoch: 6| Step: 3
Training loss: 2.6399268858350853
Validation loss: 2.6312148010785084

Epoch: 6| Step: 4
Training loss: 2.501250526470108
Validation loss: 2.6197212063141087

Epoch: 6| Step: 5
Training loss: 2.847605679956498
Validation loss: 2.651614676595866

Epoch: 6| Step: 6
Training loss: 3.610475842929562
Validation loss: 2.670779218617098

Epoch: 6| Step: 7
Training loss: 3.146627582722198
Validation loss: 2.628507596007543

Epoch: 6| Step: 8
Training loss: 2.8200828902595347
Validation loss: 2.643025528871987

Epoch: 6| Step: 9
Training loss: 2.129468035287632
Validation loss: 2.6430291342271524

Epoch: 6| Step: 10
Training loss: 2.4290299583776833
Validation loss: 2.6550479521585753

Epoch: 6| Step: 11
Training loss: 2.976310659252636
Validation loss: 2.6322226299459057

Epoch: 6| Step: 12
Training loss: 2.853131591521856
Validation loss: 2.6772845775842122

Epoch: 6| Step: 13
Training loss: 2.724600449414144
Validation loss: 2.660589400223509

Epoch: 97| Step: 0
Training loss: 3.3193151075490146
Validation loss: 2.6531910712780507

Epoch: 6| Step: 1
Training loss: 2.116464639268727
Validation loss: 2.6438266669045953

Epoch: 6| Step: 2
Training loss: 2.810863612223296
Validation loss: 2.6501952778305244

Epoch: 6| Step: 3
Training loss: 3.09723182262383
Validation loss: 2.6499143850543705

Epoch: 6| Step: 4
Training loss: 2.736877865403255
Validation loss: 2.6545124332995016

Epoch: 6| Step: 5
Training loss: 1.8316194441553648
Validation loss: 2.637316020860394

Epoch: 6| Step: 6
Training loss: 3.2100121865679947
Validation loss: 2.6471544829621263

Epoch: 6| Step: 7
Training loss: 2.8046635278723966
Validation loss: 2.6353772590204176

Epoch: 6| Step: 8
Training loss: 3.2485653571819686
Validation loss: 2.635569438197179

Epoch: 6| Step: 9
Training loss: 2.0573645727703505
Validation loss: 2.6462809379713232

Epoch: 6| Step: 10
Training loss: 3.1458111355905753
Validation loss: 2.647138044415929

Epoch: 6| Step: 11
Training loss: 2.418659265674398
Validation loss: 2.6498667274252474

Epoch: 6| Step: 12
Training loss: 3.2488577375934904
Validation loss: 2.635942127457552

Epoch: 6| Step: 13
Training loss: 3.026117915879701
Validation loss: 2.6386619514187704

Epoch: 98| Step: 0
Training loss: 3.1168004610715365
Validation loss: 2.6320724783731695

Epoch: 6| Step: 1
Training loss: 2.5579195721399492
Validation loss: 2.6503521544989415

Epoch: 6| Step: 2
Training loss: 2.510929250555249
Validation loss: 2.652092290286289

Epoch: 6| Step: 3
Training loss: 2.47100147963896
Validation loss: 2.6323938556329596

Epoch: 6| Step: 4
Training loss: 3.0155693404837542
Validation loss: 2.646869345325501

Epoch: 6| Step: 5
Training loss: 3.5198271327486514
Validation loss: 2.615343306420815

Epoch: 6| Step: 6
Training loss: 2.3027011393315586
Validation loss: 2.6295630489612405

Epoch: 6| Step: 7
Training loss: 2.254597100172544
Validation loss: 2.645245918435323

Epoch: 6| Step: 8
Training loss: 2.8728541783504986
Validation loss: 2.6361601950949414

Epoch: 6| Step: 9
Training loss: 3.0126014534102987
Validation loss: 2.6677917691780055

Epoch: 6| Step: 10
Training loss: 2.5450881587499725
Validation loss: 2.6326178642514377

Epoch: 6| Step: 11
Training loss: 3.116297850656504
Validation loss: 2.672651472512245

Epoch: 6| Step: 12
Training loss: 3.0596845491660205
Validation loss: 2.6522432126654487

Epoch: 6| Step: 13
Training loss: 3.1318030502833603
Validation loss: 2.620959160714186

Epoch: 99| Step: 0
Training loss: 3.2649122126462484
Validation loss: 2.6333597906467663

Epoch: 6| Step: 1
Training loss: 2.218705297745103
Validation loss: 2.6472173889480106

Epoch: 6| Step: 2
Training loss: 2.5541093737932092
Validation loss: 2.6508823592454975

Epoch: 6| Step: 3
Training loss: 2.7114106130974305
Validation loss: 2.651593783480104

Epoch: 6| Step: 4
Training loss: 2.8986949549256518
Validation loss: 2.616597309399086

Epoch: 6| Step: 5
Training loss: 3.0186426747832313
Validation loss: 2.6508337954316694

Epoch: 6| Step: 6
Training loss: 2.746005277985615
Validation loss: 2.619600838576381

Epoch: 6| Step: 7
Training loss: 3.5095808503810435
Validation loss: 2.6429768172965984

Epoch: 6| Step: 8
Training loss: 3.6298204139024035
Validation loss: 2.6573038094302226

Epoch: 6| Step: 9
Training loss: 2.7029740837172884
Validation loss: 2.6427725122207546

Epoch: 6| Step: 10
Training loss: 2.142874990116456
Validation loss: 2.642420223120488

Epoch: 6| Step: 11
Training loss: 2.5339134238130323
Validation loss: 2.6313595496128013

Epoch: 6| Step: 12
Training loss: 2.4547288838958607
Validation loss: 2.631618905570951

Epoch: 6| Step: 13
Training loss: 2.7994512701492824
Validation loss: 2.633034671759478

Epoch: 100| Step: 0
Training loss: 3.3463627954908612
Validation loss: 2.6215566786247986

Epoch: 6| Step: 1
Training loss: 2.902661476867737
Validation loss: 2.6418316453019832

Epoch: 6| Step: 2
Training loss: 2.568509568148883
Validation loss: 2.634477177875905

Epoch: 6| Step: 3
Training loss: 3.4358241764686452
Validation loss: 2.6478256645109735

Epoch: 6| Step: 4
Training loss: 2.589257635706602
Validation loss: 2.6533785839231823

Epoch: 6| Step: 5
Training loss: 2.9634733186604865
Validation loss: 2.6502276109820633

Epoch: 6| Step: 6
Training loss: 2.6101506159794963
Validation loss: 2.628525645249929

Epoch: 6| Step: 7
Training loss: 3.1929860494698965
Validation loss: 2.6259749575250915

Epoch: 6| Step: 8
Training loss: 2.8277243651829327
Validation loss: 2.6130301694595635

Epoch: 6| Step: 9
Training loss: 2.3730275847981392
Validation loss: 2.611842652399683

Epoch: 6| Step: 10
Training loss: 2.7366592021783034
Validation loss: 2.6310420351380417

Epoch: 6| Step: 11
Training loss: 2.470926990846107
Validation loss: 2.6366050602729842

Epoch: 6| Step: 12
Training loss: 2.5611209414999805
Validation loss: 2.649058978200216

Epoch: 6| Step: 13
Training loss: 3.027668360872798
Validation loss: 2.639493617973945

Epoch: 101| Step: 0
Training loss: 2.7911415365339916
Validation loss: 2.6432470371465233

Epoch: 6| Step: 1
Training loss: 2.4432769200403195
Validation loss: 2.62573216546039

Epoch: 6| Step: 2
Training loss: 2.6364861731916336
Validation loss: 2.631526104629132

Epoch: 6| Step: 3
Training loss: 2.996950825198376
Validation loss: 2.633541388591665

Epoch: 6| Step: 4
Training loss: 2.3884436934272415
Validation loss: 2.64112771356796

Epoch: 6| Step: 5
Training loss: 2.978445663881225
Validation loss: 2.6227741922680483

Epoch: 6| Step: 6
Training loss: 2.9053482789729954
Validation loss: 2.6350033632281766

Epoch: 6| Step: 7
Training loss: 2.8660487270432324
Validation loss: 2.6139952550563597

Epoch: 6| Step: 8
Training loss: 3.0355356340171964
Validation loss: 2.6190529495768855

Epoch: 6| Step: 9
Training loss: 3.1596326170199176
Validation loss: 2.646625011006816

Epoch: 6| Step: 10
Training loss: 3.252860644296927
Validation loss: 2.64553866022465

Epoch: 6| Step: 11
Training loss: 2.2315103801030296
Validation loss: 2.6193273566649804

Epoch: 6| Step: 12
Training loss: 2.627540630458352
Validation loss: 2.625427469117066

Epoch: 6| Step: 13
Training loss: 3.063248679064042
Validation loss: 2.65397142210613

Epoch: 102| Step: 0
Training loss: 3.6708229668103187
Validation loss: 2.6481538505074336

Epoch: 6| Step: 1
Training loss: 2.781435499541622
Validation loss: 2.6539064090402005

Epoch: 6| Step: 2
Training loss: 2.2622025520845197
Validation loss: 2.6685482236572025

Epoch: 6| Step: 3
Training loss: 2.9655870151800454
Validation loss: 2.643344248682004

Epoch: 6| Step: 4
Training loss: 2.6521610876903
Validation loss: 2.6505903120929215

Epoch: 6| Step: 5
Training loss: 3.061846760738146
Validation loss: 2.6383463651790926

Epoch: 6| Step: 6
Training loss: 2.6215330571562863
Validation loss: 2.6305914266124866

Epoch: 6| Step: 7
Training loss: 3.429784265078559
Validation loss: 2.6306753739112474

Epoch: 6| Step: 8
Training loss: 2.307179903950252
Validation loss: 2.640315490668686

Epoch: 6| Step: 9
Training loss: 3.0646985006227347
Validation loss: 2.6395441279864382

Epoch: 6| Step: 10
Training loss: 3.0691645759812243
Validation loss: 2.6240182340542657

Epoch: 6| Step: 11
Training loss: 2.2528547614328893
Validation loss: 2.6519830577399306

Epoch: 6| Step: 12
Training loss: 2.4362944531678887
Validation loss: 2.623627807458906

Epoch: 6| Step: 13
Training loss: 2.493852113244074
Validation loss: 2.663659554352366

Epoch: 103| Step: 0
Training loss: 2.6239933626916727
Validation loss: 2.6625130183904804

Epoch: 6| Step: 1
Training loss: 3.051765156241164
Validation loss: 2.630426250938844

Epoch: 6| Step: 2
Training loss: 3.474572870364029
Validation loss: 2.63264039786379

Epoch: 6| Step: 3
Training loss: 3.069070734794312
Validation loss: 2.639922167241912

Epoch: 6| Step: 4
Training loss: 3.1700680852371392
Validation loss: 2.6371988067476533

Epoch: 6| Step: 5
Training loss: 3.252346072355344
Validation loss: 2.635816834977399

Epoch: 6| Step: 6
Training loss: 2.6534656966403523
Validation loss: 2.624884548666168

Epoch: 6| Step: 7
Training loss: 2.723971384477926
Validation loss: 2.644817795605609

Epoch: 6| Step: 8
Training loss: 2.7533115042343765
Validation loss: 2.638104033391368

Epoch: 6| Step: 9
Training loss: 1.8838408894625132
Validation loss: 2.6236681921703733

Epoch: 6| Step: 10
Training loss: 2.2929013711884876
Validation loss: 2.659728606210767

Epoch: 6| Step: 11
Training loss: 2.264750134157412
Validation loss: 2.649351223186487

Epoch: 6| Step: 12
Training loss: 2.758878420842646
Validation loss: 2.6525441289669747

Epoch: 6| Step: 13
Training loss: 3.439226583875982
Validation loss: 2.634787758829161

Epoch: 104| Step: 0
Training loss: 3.1851649988094985
Validation loss: 2.6212182312591885

Epoch: 6| Step: 1
Training loss: 2.649264046302299
Validation loss: 2.6620311869879543

Epoch: 6| Step: 2
Training loss: 2.8841438837335485
Validation loss: 2.646432811741943

Epoch: 6| Step: 3
Training loss: 2.8490152765937653
Validation loss: 2.6530960922282927

Epoch: 6| Step: 4
Training loss: 2.2862771439648593
Validation loss: 2.636246583896777

Epoch: 6| Step: 5
Training loss: 2.8154972635945845
Validation loss: 2.629055967103866

Epoch: 6| Step: 6
Training loss: 2.8989875867827224
Validation loss: 2.651526020394273

Epoch: 6| Step: 7
Training loss: 1.9307854497989976
Validation loss: 2.61707509043856

Epoch: 6| Step: 8
Training loss: 2.036319685669137
Validation loss: 2.6136355912852967

Epoch: 6| Step: 9
Training loss: 3.196803857155307
Validation loss: 2.624295819471396

Epoch: 6| Step: 10
Training loss: 2.7638071411243725
Validation loss: 2.6283945420812813

Epoch: 6| Step: 11
Training loss: 2.371564186850589
Validation loss: 2.6692515405197295

Epoch: 6| Step: 12
Training loss: 3.8402160277795114
Validation loss: 2.6307856470880377

Epoch: 6| Step: 13
Training loss: 3.5146900883628884
Validation loss: 2.6288722659467596

Epoch: 105| Step: 0
Training loss: 2.8599946231391353
Validation loss: 2.6269479068634594

Epoch: 6| Step: 1
Training loss: 3.0574936721499224
Validation loss: 2.6441745404484385

Epoch: 6| Step: 2
Training loss: 3.402055590193895
Validation loss: 2.628980285131564

Epoch: 6| Step: 3
Training loss: 2.5429944390143504
Validation loss: 2.6275166256768694

Epoch: 6| Step: 4
Training loss: 2.690281160827656
Validation loss: 2.6273801309625524

Epoch: 6| Step: 5
Training loss: 1.720897996932932
Validation loss: 2.629760113008632

Epoch: 6| Step: 6
Training loss: 2.658459451328515
Validation loss: 2.625433175578116

Epoch: 6| Step: 7
Training loss: 3.050693720735396
Validation loss: 2.631146484892283

Epoch: 6| Step: 8
Training loss: 3.2605934623259154
Validation loss: 2.6264709125223553

Epoch: 6| Step: 9
Training loss: 3.077100244336588
Validation loss: 2.6271508014967866

Epoch: 6| Step: 10
Training loss: 2.3165069095040027
Validation loss: 2.6493836246970903

Epoch: 6| Step: 11
Training loss: 2.6543054980544256
Validation loss: 2.6079235386252186

Epoch: 6| Step: 12
Training loss: 2.665963129777356
Validation loss: 2.6554734525143613

Epoch: 6| Step: 13
Training loss: 3.373689609028069
Validation loss: 2.6468986870763134

Epoch: 106| Step: 0
Training loss: 2.5936678218462297
Validation loss: 2.6282700632177933

Epoch: 6| Step: 1
Training loss: 3.27800219426713
Validation loss: 2.6171217181442854

Epoch: 6| Step: 2
Training loss: 1.942794825151513
Validation loss: 2.6304716771347727

Epoch: 6| Step: 3
Training loss: 2.8547876800848533
Validation loss: 2.635186040624225

Epoch: 6| Step: 4
Training loss: 3.037298087485193
Validation loss: 2.6311537797924114

Epoch: 6| Step: 5
Training loss: 3.135246872132839
Validation loss: 2.616409968423602

Epoch: 6| Step: 6
Training loss: 2.715451750150877
Validation loss: 2.6333012013352612

Epoch: 6| Step: 7
Training loss: 2.4794432435044786
Validation loss: 2.6511418089392604

Epoch: 6| Step: 8
Training loss: 3.5410987099412186
Validation loss: 2.6471294357834054

Epoch: 6| Step: 9
Training loss: 2.717267476287384
Validation loss: 2.6391007218741382

Epoch: 6| Step: 10
Training loss: 2.118985021828988
Validation loss: 2.654810127819947

Epoch: 6| Step: 11
Training loss: 2.363119022066212
Validation loss: 2.6290956511945947

Epoch: 6| Step: 12
Training loss: 3.7276497140620752
Validation loss: 2.6159578145709936

Epoch: 6| Step: 13
Training loss: 2.2664642884095896
Validation loss: 2.6252713187732954

Epoch: 107| Step: 0
Training loss: 2.502510145778458
Validation loss: 2.63598120603964

Epoch: 6| Step: 1
Training loss: 2.52520416114231
Validation loss: 2.637824124337141

Epoch: 6| Step: 2
Training loss: 2.448324767379716
Validation loss: 2.674001071765

Epoch: 6| Step: 3
Training loss: 3.5523558630484047
Validation loss: 2.6651265381268145

Epoch: 6| Step: 4
Training loss: 2.4921628179493878
Validation loss: 2.6279590938997663

Epoch: 6| Step: 5
Training loss: 3.170031533310067
Validation loss: 2.695933487097395

Epoch: 6| Step: 6
Training loss: 3.350785883488723
Validation loss: 2.640962376612948

Epoch: 6| Step: 7
Training loss: 2.9464882848724554
Validation loss: 2.639583177522252

Epoch: 6| Step: 8
Training loss: 2.734294083624179
Validation loss: 2.660665620674524

Epoch: 6| Step: 9
Training loss: 2.739906775427041
Validation loss: 2.645824006671146

Epoch: 6| Step: 10
Training loss: 3.1271428200190785
Validation loss: 2.648724589927347

Epoch: 6| Step: 11
Training loss: 2.5519586857049474
Validation loss: 2.6496071388458806

Epoch: 6| Step: 12
Training loss: 2.6767747357295204
Validation loss: 2.6488266061108794

Epoch: 6| Step: 13
Training loss: 2.3857763649439967
Validation loss: 2.6309480158028835

Epoch: 108| Step: 0
Training loss: 2.810989822146712
Validation loss: 2.6676052240231183

Epoch: 6| Step: 1
Training loss: 2.680673845895171
Validation loss: 2.6379954373668526

Epoch: 6| Step: 2
Training loss: 3.0625087192956233
Validation loss: 2.6356369802603483

Epoch: 6| Step: 3
Training loss: 2.9922486938912263
Validation loss: 2.636878390384573

Epoch: 6| Step: 4
Training loss: 2.705704973765583
Validation loss: 2.6261009841202423

Epoch: 6| Step: 5
Training loss: 2.0758368723362
Validation loss: 2.654913403014738

Epoch: 6| Step: 6
Training loss: 2.86959330478437
Validation loss: 2.6317871975657203

Epoch: 6| Step: 7
Training loss: 3.1652365684383983
Validation loss: 2.663863220354081

Epoch: 6| Step: 8
Training loss: 1.9420158918066404
Validation loss: 2.6320863471336757

Epoch: 6| Step: 9
Training loss: 3.15844680327316
Validation loss: 2.639824435405257

Epoch: 6| Step: 10
Training loss: 2.6278988408631827
Validation loss: 2.6575633557114093

Epoch: 6| Step: 11
Training loss: 3.1933414563717455
Validation loss: 2.6084522435522763

Epoch: 6| Step: 12
Training loss: 3.128879123146297
Validation loss: 2.6280994282497847

Epoch: 6| Step: 13
Training loss: 2.3699210218959648
Validation loss: 2.6296546420657116

Epoch: 109| Step: 0
Training loss: 2.730894129284643
Validation loss: 2.6459295752548364

Epoch: 6| Step: 1
Training loss: 3.4931839922900854
Validation loss: 2.6667966432838273

Epoch: 6| Step: 2
Training loss: 2.81483853922247
Validation loss: 2.6594826799907225

Epoch: 6| Step: 3
Training loss: 3.0737898453483607
Validation loss: 2.6547140990455476

Epoch: 6| Step: 4
Training loss: 2.647453462877912
Validation loss: 2.6402214845352447

Epoch: 6| Step: 5
Training loss: 2.4489237776546267
Validation loss: 2.6494110473771926

Epoch: 6| Step: 6
Training loss: 3.1140538576793806
Validation loss: 2.6569084774880722

Epoch: 6| Step: 7
Training loss: 2.944974925480104
Validation loss: 2.6523173667369613

Epoch: 6| Step: 8
Training loss: 2.391352524102469
Validation loss: 2.631888668268631

Epoch: 6| Step: 9
Training loss: 1.7785837396271131
Validation loss: 2.6228071957884036

Epoch: 6| Step: 10
Training loss: 2.6982434245495717
Validation loss: 2.6204849836327457

Epoch: 6| Step: 11
Training loss: 3.663046104155588
Validation loss: 2.6429906167132446

Epoch: 6| Step: 12
Training loss: 2.64222641639316
Validation loss: 2.6437175204833365

Epoch: 6| Step: 13
Training loss: 2.319526410764308
Validation loss: 2.608420533635245

Epoch: 110| Step: 0
Training loss: 2.764618771365913
Validation loss: 2.633077759085916

Epoch: 6| Step: 1
Training loss: 2.2788430671708135
Validation loss: 2.6409840653685417

Epoch: 6| Step: 2
Training loss: 3.1491958802816336
Validation loss: 2.6453695316254273

Epoch: 6| Step: 3
Training loss: 2.5092264627886496
Validation loss: 2.6363591970585145

Epoch: 6| Step: 4
Training loss: 2.6994536942115497
Validation loss: 2.6325822268621373

Epoch: 6| Step: 5
Training loss: 2.4294186164271427
Validation loss: 2.649756812958026

Epoch: 6| Step: 6
Training loss: 3.535234212279145
Validation loss: 2.5755969030226167

Epoch: 6| Step: 7
Training loss: 2.8455853251291434
Validation loss: 2.61272499117358

Epoch: 6| Step: 8
Training loss: 2.6788239714234767
Validation loss: 2.622766529996414

Epoch: 6| Step: 9
Training loss: 2.722903619417328
Validation loss: 2.624683556378322

Epoch: 6| Step: 10
Training loss: 2.310335744593539
Validation loss: 2.623853642157754

Epoch: 6| Step: 11
Training loss: 2.964944588978089
Validation loss: 2.617557928091505

Epoch: 6| Step: 12
Training loss: 3.21946293610982
Validation loss: 2.622129730573705

Epoch: 6| Step: 13
Training loss: 2.7677492938147172
Validation loss: 2.6301289131668666

Epoch: 111| Step: 0
Training loss: 2.9333871496928103
Validation loss: 2.6226314371183324

Epoch: 6| Step: 1
Training loss: 2.274857644458499
Validation loss: 2.641781386696234

Epoch: 6| Step: 2
Training loss: 3.0446001999946755
Validation loss: 2.605866569351347

Epoch: 6| Step: 3
Training loss: 2.7795549006192775
Validation loss: 2.6314582095975294

Epoch: 6| Step: 4
Training loss: 2.8651252002888246
Validation loss: 2.6606492135743616

Epoch: 6| Step: 5
Training loss: 2.8497800507917495
Validation loss: 2.628311820183837

Epoch: 6| Step: 6
Training loss: 2.8049212600073656
Validation loss: 2.6234866397845917

Epoch: 6| Step: 7
Training loss: 2.5013469881987773
Validation loss: 2.6211063026548342

Epoch: 6| Step: 8
Training loss: 3.1989164663738707
Validation loss: 2.602251215379083

Epoch: 6| Step: 9
Training loss: 3.131392996867381
Validation loss: 2.6202156759254853

Epoch: 6| Step: 10
Training loss: 2.7265147557491543
Validation loss: 2.613737952048637

Epoch: 6| Step: 11
Training loss: 2.437827846291509
Validation loss: 2.647594499115877

Epoch: 6| Step: 12
Training loss: 2.660936776036216
Validation loss: 2.64198995594129

Epoch: 6| Step: 13
Training loss: 2.987564379904183
Validation loss: 2.6300499757026503

Epoch: 112| Step: 0
Training loss: 3.1447071476424626
Validation loss: 2.628321386834719

Epoch: 6| Step: 1
Training loss: 2.613140564283447
Validation loss: 2.6480082221685333

Epoch: 6| Step: 2
Training loss: 2.8117579010921703
Validation loss: 2.6257611698092473

Epoch: 6| Step: 3
Training loss: 2.795469815479647
Validation loss: 2.639415986750675

Epoch: 6| Step: 4
Training loss: 2.296621918521484
Validation loss: 2.6424403660574587

Epoch: 6| Step: 5
Training loss: 2.186731694037699
Validation loss: 2.6535772515429636

Epoch: 6| Step: 6
Training loss: 2.324841122685062
Validation loss: 2.6370654564795046

Epoch: 6| Step: 7
Training loss: 3.5901253375007456
Validation loss: 2.651382557499906

Epoch: 6| Step: 8
Training loss: 2.699859763848078
Validation loss: 2.6777902497107906

Epoch: 6| Step: 9
Training loss: 3.094591276823688
Validation loss: 2.6109793156380503

Epoch: 6| Step: 10
Training loss: 2.628844942055373
Validation loss: 2.6518574626395184

Epoch: 6| Step: 11
Training loss: 3.3105748178208643
Validation loss: 2.6489035095697

Epoch: 6| Step: 12
Training loss: 2.86230868570601
Validation loss: 2.606129562578773

Epoch: 6| Step: 13
Training loss: 2.9747106844205637
Validation loss: 2.6254455942162265

Epoch: 113| Step: 0
Training loss: 2.7108900082520537
Validation loss: 2.6256412644761085

Epoch: 6| Step: 1
Training loss: 2.6986549771335926
Validation loss: 2.632772814483006

Epoch: 6| Step: 2
Training loss: 2.6098895450765727
Validation loss: 2.6362319566203176

Epoch: 6| Step: 3
Training loss: 2.947637717772382
Validation loss: 2.6389231932359998

Epoch: 6| Step: 4
Training loss: 2.0013985512357784
Validation loss: 2.627977057161612

Epoch: 6| Step: 5
Training loss: 2.470102639787753
Validation loss: 2.620447193290446

Epoch: 6| Step: 6
Training loss: 2.8746926516571643
Validation loss: 2.6467800008413858

Epoch: 6| Step: 7
Training loss: 2.8514558118954576
Validation loss: 2.6484316030452337

Epoch: 6| Step: 8
Training loss: 2.6697623840782096
Validation loss: 2.649562741728962

Epoch: 6| Step: 9
Training loss: 2.6199053416733618
Validation loss: 2.6455130744594397

Epoch: 6| Step: 10
Training loss: 3.59274131882898
Validation loss: 2.6508038284764126

Epoch: 6| Step: 11
Training loss: 2.956882568814128
Validation loss: 2.638625216160919

Epoch: 6| Step: 12
Training loss: 2.4940782985801073
Validation loss: 2.667779562077783

Epoch: 6| Step: 13
Training loss: 4.013180474784726
Validation loss: 2.6474705114539625

Epoch: 114| Step: 0
Training loss: 3.0915538044059834
Validation loss: 2.6546669438042034

Epoch: 6| Step: 1
Training loss: 2.405165390704062
Validation loss: 2.631805873066506

Epoch: 6| Step: 2
Training loss: 1.7223068886457946
Validation loss: 2.604387473969057

Epoch: 6| Step: 3
Training loss: 2.7158074075172087
Validation loss: 2.6351302276309347

Epoch: 6| Step: 4
Training loss: 2.8361318642503237
Validation loss: 2.6365381176693505

Epoch: 6| Step: 5
Training loss: 2.8144226284347047
Validation loss: 2.638011925109964

Epoch: 6| Step: 6
Training loss: 3.679183374685941
Validation loss: 2.627927193052661

Epoch: 6| Step: 7
Training loss: 3.361647861663264
Validation loss: 2.6361118638211076

Epoch: 6| Step: 8
Training loss: 3.291909478483023
Validation loss: 2.63873488022318

Epoch: 6| Step: 9
Training loss: 2.553059190254482
Validation loss: 2.6355307513531847

Epoch: 6| Step: 10
Training loss: 2.462138146473373
Validation loss: 2.6275553456331995

Epoch: 6| Step: 11
Training loss: 2.6136988832135613
Validation loss: 2.6445799140404826

Epoch: 6| Step: 12
Training loss: 2.4029202893673403
Validation loss: 2.6281198116593325

Epoch: 6| Step: 13
Training loss: 3.1972155138864706
Validation loss: 2.6381220393284455

Epoch: 115| Step: 0
Training loss: 2.7356869411275766
Validation loss: 2.6493993168138066

Epoch: 6| Step: 1
Training loss: 3.1223910312864884
Validation loss: 2.6674750189859835

Epoch: 6| Step: 2
Training loss: 2.196546757405975
Validation loss: 2.660324924225409

Epoch: 6| Step: 3
Training loss: 2.6181318259042077
Validation loss: 2.6220854083947516

Epoch: 6| Step: 4
Training loss: 3.2828956473640667
Validation loss: 2.644025990669838

Epoch: 6| Step: 5
Training loss: 2.8957754079024665
Validation loss: 2.6634554242406616

Epoch: 6| Step: 6
Training loss: 2.6355742054369293
Validation loss: 2.624441727174526

Epoch: 6| Step: 7
Training loss: 3.100102078387636
Validation loss: 2.6252976691665832

Epoch: 6| Step: 8
Training loss: 2.3825416285909875
Validation loss: 2.6586037945850904

Epoch: 6| Step: 9
Training loss: 2.904932851622654
Validation loss: 2.635868201305983

Epoch: 6| Step: 10
Training loss: 2.9669251304362665
Validation loss: 2.65702122513522

Epoch: 6| Step: 11
Training loss: 2.8837809602938163
Validation loss: 2.640120533158316

Epoch: 6| Step: 12
Training loss: 2.691311905180367
Validation loss: 2.643792536223235

Epoch: 6| Step: 13
Training loss: 2.5423248460240444
Validation loss: 2.646690222789112

Epoch: 116| Step: 0
Training loss: 4.116407519586657
Validation loss: 2.6173046964345748

Epoch: 6| Step: 1
Training loss: 1.9292331423199056
Validation loss: 2.6336615669665058

Epoch: 6| Step: 2
Training loss: 2.930978882051396
Validation loss: 2.6414387951277463

Epoch: 6| Step: 3
Training loss: 2.7361035796017164
Validation loss: 2.6495374086583596

Epoch: 6| Step: 4
Training loss: 3.1275169917315133
Validation loss: 2.6303528286184177

Epoch: 6| Step: 5
Training loss: 2.84749248018017
Validation loss: 2.638848919251838

Epoch: 6| Step: 6
Training loss: 3.014619017106198
Validation loss: 2.649520057948666

Epoch: 6| Step: 7
Training loss: 2.378333111954349
Validation loss: 2.630536341594207

Epoch: 6| Step: 8
Training loss: 2.9459022316076475
Validation loss: 2.6298749155382533

Epoch: 6| Step: 9
Training loss: 2.4841312312845236
Validation loss: 2.6383070602426697

Epoch: 6| Step: 10
Training loss: 2.8030036823467626
Validation loss: 2.6228587953957807

Epoch: 6| Step: 11
Training loss: 2.397151142312594
Validation loss: 2.648900505479511

Epoch: 6| Step: 12
Training loss: 2.6651926635895413
Validation loss: 2.621233871932765

Epoch: 6| Step: 13
Training loss: 2.1349495601726054
Validation loss: 2.6142141796272953

Epoch: 117| Step: 0
Training loss: 3.099076742693619
Validation loss: 2.626165236865967

Epoch: 6| Step: 1
Training loss: 2.3157894348984125
Validation loss: 2.6399128567598686

Epoch: 6| Step: 2
Training loss: 2.053900854568679
Validation loss: 2.6447119441840994

Epoch: 6| Step: 3
Training loss: 2.6620276950051833
Validation loss: 2.6403064442191972

Epoch: 6| Step: 4
Training loss: 2.889311786003844
Validation loss: 2.660772221965761

Epoch: 6| Step: 5
Training loss: 2.595591431475761
Validation loss: 2.6036330415091027

Epoch: 6| Step: 6
Training loss: 2.6213827187079484
Validation loss: 2.6611088670065506

Epoch: 6| Step: 7
Training loss: 2.8324346426067226
Validation loss: 2.624362186385491

Epoch: 6| Step: 8
Training loss: 2.9413736653137876
Validation loss: 2.6597729305059854

Epoch: 6| Step: 9
Training loss: 2.4655025708029066
Validation loss: 2.6123944392257603

Epoch: 6| Step: 10
Training loss: 2.9481053555941834
Validation loss: 2.6560186798113645

Epoch: 6| Step: 11
Training loss: 2.8674446011474073
Validation loss: 2.612525808064882

Epoch: 6| Step: 12
Training loss: 3.3691410495923644
Validation loss: 2.620676697536335

Epoch: 6| Step: 13
Training loss: 3.7729405930910365
Validation loss: 2.628812769147644

Epoch: 118| Step: 0
Training loss: 2.471666472424915
Validation loss: 2.6071443927581286

Epoch: 6| Step: 1
Training loss: 2.8344973435751997
Validation loss: 2.6353794205352963

Epoch: 6| Step: 2
Training loss: 3.4555729953152703
Validation loss: 2.632344294318332

Epoch: 6| Step: 3
Training loss: 2.6939467356060005
Validation loss: 2.618092293868386

Epoch: 6| Step: 4
Training loss: 2.862518750258425
Validation loss: 2.641338344509505

Epoch: 6| Step: 5
Training loss: 2.555498187024737
Validation loss: 2.619168180309873

Epoch: 6| Step: 6
Training loss: 2.8358873935613103
Validation loss: 2.614779464300235

Epoch: 6| Step: 7
Training loss: 2.611237917406936
Validation loss: 2.593957314753819

Epoch: 6| Step: 8
Training loss: 3.3349786671380843
Validation loss: 2.64557442638979

Epoch: 6| Step: 9
Training loss: 1.9223127409337688
Validation loss: 2.639670199208157

Epoch: 6| Step: 10
Training loss: 2.918046860881402
Validation loss: 2.6427127560185775

Epoch: 6| Step: 11
Training loss: 2.9027301433574997
Validation loss: 2.631612181850342

Epoch: 6| Step: 12
Training loss: 2.7912174736481883
Validation loss: 2.638772043369722

Epoch: 6| Step: 13
Training loss: 2.8339251479855223
Validation loss: 2.635534398088131

Epoch: 119| Step: 0
Training loss: 2.0755939414926363
Validation loss: 2.6293107717002377

Epoch: 6| Step: 1
Training loss: 2.2611513364912383
Validation loss: 2.6368343579201885

Epoch: 6| Step: 2
Training loss: 2.8397369574572973
Validation loss: 2.622212404056942

Epoch: 6| Step: 3
Training loss: 3.072544208950392
Validation loss: 2.6454486123124163

Epoch: 6| Step: 4
Training loss: 3.0894926428694145
Validation loss: 2.6152543675679354

Epoch: 6| Step: 5
Training loss: 2.6325001517184394
Validation loss: 2.6256955832233575

Epoch: 6| Step: 6
Training loss: 2.0463986606927564
Validation loss: 2.627044269447345

Epoch: 6| Step: 7
Training loss: 2.7775143169923378
Validation loss: 2.6429415228013067

Epoch: 6| Step: 8
Training loss: 3.378126603513438
Validation loss: 2.646330452370495

Epoch: 6| Step: 9
Training loss: 3.2012067307628
Validation loss: 2.644353659370299

Epoch: 6| Step: 10
Training loss: 2.95363471259428
Validation loss: 2.6502786341660185

Epoch: 6| Step: 11
Training loss: 2.530707124492535
Validation loss: 2.6442532690679914

Epoch: 6| Step: 12
Training loss: 2.9579270491306096
Validation loss: 2.6343272185505078

Epoch: 6| Step: 13
Training loss: 3.1510811963504928
Validation loss: 2.6403383901746684

Epoch: 120| Step: 0
Training loss: 2.3377027699041384
Validation loss: 2.6346799028210137

Epoch: 6| Step: 1
Training loss: 2.5947861038285183
Validation loss: 2.6396870251481808

Epoch: 6| Step: 2
Training loss: 3.590124806224371
Validation loss: 2.6488032771901207

Epoch: 6| Step: 3
Training loss: 2.543385367538238
Validation loss: 2.6234803486383167

Epoch: 6| Step: 4
Training loss: 3.184998671502955
Validation loss: 2.645680841171566

Epoch: 6| Step: 5
Training loss: 2.7680731675890917
Validation loss: 2.6384839443634016

Epoch: 6| Step: 6
Training loss: 3.4672296989936355
Validation loss: 2.6496635587961292

Epoch: 6| Step: 7
Training loss: 2.2488477723610316
Validation loss: 2.6185983767296093

Epoch: 6| Step: 8
Training loss: 2.511482286965305
Validation loss: 2.6661166276279595

Epoch: 6| Step: 9
Training loss: 2.605929538409524
Validation loss: 2.64352129713036

Epoch: 6| Step: 10
Training loss: 2.000534582219098
Validation loss: 2.6415897458208164

Epoch: 6| Step: 11
Training loss: 2.790473474231243
Validation loss: 2.647656064247474

Epoch: 6| Step: 12
Training loss: 3.0814920202693834
Validation loss: 2.648856660279334

Epoch: 6| Step: 13
Training loss: 3.275946845707494
Validation loss: 2.6355786409756585

Epoch: 121| Step: 0
Training loss: 2.9396114471482586
Validation loss: 2.6331715616926603

Epoch: 6| Step: 1
Training loss: 2.634735129867768
Validation loss: 2.6749365733028347

Epoch: 6| Step: 2
Training loss: 2.9432662209981033
Validation loss: 2.6402282018668997

Epoch: 6| Step: 3
Training loss: 3.3313348183202676
Validation loss: 2.622482775592671

Epoch: 6| Step: 4
Training loss: 3.2089912103358427
Validation loss: 2.65424161647328

Epoch: 6| Step: 5
Training loss: 2.4384375505301943
Validation loss: 2.647839726697248

Epoch: 6| Step: 6
Training loss: 2.487690374862612
Validation loss: 2.6502226456803455

Epoch: 6| Step: 7
Training loss: 2.668062490489216
Validation loss: 2.6598987445978293

Epoch: 6| Step: 8
Training loss: 2.539664704727568
Validation loss: 2.6423346600106425

Epoch: 6| Step: 9
Training loss: 2.747682982470096
Validation loss: 2.6555064927585397

Epoch: 6| Step: 10
Training loss: 2.663253706154321
Validation loss: 2.639438932426319

Epoch: 6| Step: 11
Training loss: 2.671837611243564
Validation loss: 2.6421993906958114

Epoch: 6| Step: 12
Training loss: 3.234188203439329
Validation loss: 2.6355938482024293

Epoch: 6| Step: 13
Training loss: 2.162148631221085
Validation loss: 2.662225161073682

Epoch: 122| Step: 0
Training loss: 3.0021783549412797
Validation loss: 2.6295257117912914

Epoch: 6| Step: 1
Training loss: 2.3007499550211414
Validation loss: 2.5861084237196765

Epoch: 6| Step: 2
Training loss: 2.528752731646101
Validation loss: 2.626381558864573

Epoch: 6| Step: 3
Training loss: 3.090411610271104
Validation loss: 2.651087310479959

Epoch: 6| Step: 4
Training loss: 2.9055814897082066
Validation loss: 2.645411282274242

Epoch: 6| Step: 5
Training loss: 2.5145847231005916
Validation loss: 2.612047219923728

Epoch: 6| Step: 6
Training loss: 2.4600656085065573
Validation loss: 2.6331383142134483

Epoch: 6| Step: 7
Training loss: 3.4927799140534375
Validation loss: 2.6344216705116996

Epoch: 6| Step: 8
Training loss: 3.0979279330437173
Validation loss: 2.645416209121323

Epoch: 6| Step: 9
Training loss: 3.0359218814936964
Validation loss: 2.670539466044161

Epoch: 6| Step: 10
Training loss: 3.041711902717498
Validation loss: 2.637058669845422

Epoch: 6| Step: 11
Training loss: 2.3143424864773916
Validation loss: 2.630024078422991

Epoch: 6| Step: 12
Training loss: 2.820499318875273
Validation loss: 2.652635015536041

Epoch: 6| Step: 13
Training loss: 2.112406946423867
Validation loss: 2.638081029459398

Epoch: 123| Step: 0
Training loss: 3.0172734474018896
Validation loss: 2.643536494547896

Epoch: 6| Step: 1
Training loss: 2.647905954678946
Validation loss: 2.658185636038461

Epoch: 6| Step: 2
Training loss: 2.018877584010172
Validation loss: 2.6352715157812128

Epoch: 6| Step: 3
Training loss: 2.043460473134049
Validation loss: 2.63287870773537

Epoch: 6| Step: 4
Training loss: 3.085802756156385
Validation loss: 2.622138254096578

Epoch: 6| Step: 5
Training loss: 2.759237726237995
Validation loss: 2.6228738593847694

Epoch: 6| Step: 6
Training loss: 2.6522691404385705
Validation loss: 2.6450711748808526

Epoch: 6| Step: 7
Training loss: 2.920793465756265
Validation loss: 2.6055198399128106

Epoch: 6| Step: 8
Training loss: 2.8235088632808276
Validation loss: 2.6273591026995393

Epoch: 6| Step: 9
Training loss: 2.7764734978437153
Validation loss: 2.6269787031853493

Epoch: 6| Step: 10
Training loss: 2.2607048542408807
Validation loss: 2.6496392387398973

Epoch: 6| Step: 11
Training loss: 3.228272656796302
Validation loss: 2.605503449609665

Epoch: 6| Step: 12
Training loss: 3.2754725865099266
Validation loss: 2.5662458899784313

Epoch: 6| Step: 13
Training loss: 3.879265928927645
Validation loss: 2.640117091819855

Epoch: 124| Step: 0
Training loss: 3.3296765932775383
Validation loss: 2.629132490350524

Epoch: 6| Step: 1
Training loss: 2.425463866081646
Validation loss: 2.6383424900979064

Epoch: 6| Step: 2
Training loss: 3.0595576885412243
Validation loss: 2.640924601661647

Epoch: 6| Step: 3
Training loss: 3.4606900438834427
Validation loss: 2.6219854864253804

Epoch: 6| Step: 4
Training loss: 2.8023260264371928
Validation loss: 2.597977881266241

Epoch: 6| Step: 5
Training loss: 2.7308638345526184
Validation loss: 2.633196599496401

Epoch: 6| Step: 6
Training loss: 2.1736776431798623
Validation loss: 2.6525159654827584

Epoch: 6| Step: 7
Training loss: 2.5015214105361174
Validation loss: 2.639881410637147

Epoch: 6| Step: 8
Training loss: 2.7200189895527993
Validation loss: 2.6163977871313135

Epoch: 6| Step: 9
Training loss: 2.8724549680256017
Validation loss: 2.6517721334614706

Epoch: 6| Step: 10
Training loss: 2.9774594695105634
Validation loss: 2.6373415315913444

Epoch: 6| Step: 11
Training loss: 2.766834576425418
Validation loss: 2.6171531130117764

Epoch: 6| Step: 12
Training loss: 2.4548448498834934
Validation loss: 2.672979463725455

Epoch: 6| Step: 13
Training loss: 2.4852745299027137
Validation loss: 2.643643214402407

Epoch: 125| Step: 0
Training loss: 2.3448128896865907
Validation loss: 2.6487361966875436

Epoch: 6| Step: 1
Training loss: 2.830473372697543
Validation loss: 2.632704396555775

Epoch: 6| Step: 2
Training loss: 2.1606238412674634
Validation loss: 2.6268398011767062

Epoch: 6| Step: 3
Training loss: 3.1708815949852975
Validation loss: 2.6596792342488604

Epoch: 6| Step: 4
Training loss: 2.1952654741891124
Validation loss: 2.657049287799312

Epoch: 6| Step: 5
Training loss: 3.0623857126514547
Validation loss: 2.6346440704953187

Epoch: 6| Step: 6
Training loss: 2.118660727451579
Validation loss: 2.636378031737094

Epoch: 6| Step: 7
Training loss: 1.929465833279883
Validation loss: 2.6324554811821046

Epoch: 6| Step: 8
Training loss: 3.3936003537844663
Validation loss: 2.6363457241858486

Epoch: 6| Step: 9
Training loss: 2.8648990156607756
Validation loss: 2.6671900674576774

Epoch: 6| Step: 10
Training loss: 3.3123655471865536
Validation loss: 2.634299915232264

Epoch: 6| Step: 11
Training loss: 2.958717500341351
Validation loss: 2.6403781799545847

Epoch: 6| Step: 12
Training loss: 3.3473210740079233
Validation loss: 2.6317373355113554

Epoch: 6| Step: 13
Training loss: 2.5518811411787214
Validation loss: 2.6552941288410943

Epoch: 126| Step: 0
Training loss: 3.64579334055446
Validation loss: 2.626520449968947

Epoch: 6| Step: 1
Training loss: 2.8951729952393657
Validation loss: 2.629317035245804

Epoch: 6| Step: 2
Training loss: 2.6872602843785964
Validation loss: 2.6468543002213445

Epoch: 6| Step: 3
Training loss: 2.6585145161110266
Validation loss: 2.629875688566169

Epoch: 6| Step: 4
Training loss: 2.4263289320152426
Validation loss: 2.653836554660837

Epoch: 6| Step: 5
Training loss: 3.1830576439424787
Validation loss: 2.6511002171949265

Epoch: 6| Step: 6
Training loss: 2.525676666841432
Validation loss: 2.6223060214608886

Epoch: 6| Step: 7
Training loss: 2.2768570918159825
Validation loss: 2.610468597389223

Epoch: 6| Step: 8
Training loss: 3.433094183607981
Validation loss: 2.636209219828053

Epoch: 6| Step: 9
Training loss: 3.155514621991483
Validation loss: 2.6479260742808344

Epoch: 6| Step: 10
Training loss: 2.3386679928876246
Validation loss: 2.6445413241115237

Epoch: 6| Step: 11
Training loss: 2.339174713113678
Validation loss: 2.621486092291955

Epoch: 6| Step: 12
Training loss: 2.5929216647836837
Validation loss: 2.6226689936465646

Epoch: 6| Step: 13
Training loss: 2.431070014155661
Validation loss: 2.642051152924534

Epoch: 127| Step: 0
Training loss: 2.6746882747234975
Validation loss: 2.6582633025824425

Epoch: 6| Step: 1
Training loss: 2.9984559218102675
Validation loss: 2.6351783200756285

Epoch: 6| Step: 2
Training loss: 3.0834519818821167
Validation loss: 2.6220500952063683

Epoch: 6| Step: 3
Training loss: 2.9927490344910757
Validation loss: 2.5956223874824293

Epoch: 6| Step: 4
Training loss: 3.1052270567307216
Validation loss: 2.6288431837753246

Epoch: 6| Step: 5
Training loss: 2.4064819422317205
Validation loss: 2.638333702640333

Epoch: 6| Step: 6
Training loss: 3.180758359200526
Validation loss: 2.6308848060703838

Epoch: 6| Step: 7
Training loss: 3.087093088617991
Validation loss: 2.6269416669461587

Epoch: 6| Step: 8
Training loss: 2.169271761438752
Validation loss: 2.6526809756614185

Epoch: 6| Step: 9
Training loss: 2.6265653756583753
Validation loss: 2.6762285182534615

Epoch: 6| Step: 10
Training loss: 2.8339800003196767
Validation loss: 2.6368000113097145

Epoch: 6| Step: 11
Training loss: 2.1335195410445724
Validation loss: 2.652489433158119

Epoch: 6| Step: 12
Training loss: 2.7295404037557063
Validation loss: 2.6416896482770804

Epoch: 6| Step: 13
Training loss: 2.7412899102446784
Validation loss: 2.6359248839620473

Epoch: 128| Step: 0
Training loss: 1.9979860179056765
Validation loss: 2.639672680616155

Epoch: 6| Step: 1
Training loss: 3.189853472558199
Validation loss: 2.6297239972251703

Epoch: 6| Step: 2
Training loss: 2.6238854176404134
Validation loss: 2.640959234383529

Epoch: 6| Step: 3
Training loss: 2.7995230643209204
Validation loss: 2.6413644686182374

Epoch: 6| Step: 4
Training loss: 2.6100143288990014
Validation loss: 2.6325048670597972

Epoch: 6| Step: 5
Training loss: 2.2557162681204352
Validation loss: 2.6331622628777636

Epoch: 6| Step: 6
Training loss: 2.7810616590186252
Validation loss: 2.6493207720820475

Epoch: 6| Step: 7
Training loss: 2.516856490380444
Validation loss: 2.6541816992912004

Epoch: 6| Step: 8
Training loss: 3.2630102467447646
Validation loss: 2.6219673413182534

Epoch: 6| Step: 9
Training loss: 3.088869348718814
Validation loss: 2.5996267570648626

Epoch: 6| Step: 10
Training loss: 2.876382412471589
Validation loss: 2.616090273019653

Epoch: 6| Step: 11
Training loss: 3.1421934547917996
Validation loss: 2.613375471820511

Epoch: 6| Step: 12
Training loss: 2.8797362747242827
Validation loss: 2.6280580727368568

Epoch: 6| Step: 13
Training loss: 2.728438816614197
Validation loss: 2.618800255038739

Epoch: 129| Step: 0
Training loss: 3.145276018168954
Validation loss: 2.611291136768715

Epoch: 6| Step: 1
Training loss: 2.6339395074871335
Validation loss: 2.6331170174582668

Epoch: 6| Step: 2
Training loss: 3.5089848859477253
Validation loss: 2.6132947181759145

Epoch: 6| Step: 3
Training loss: 2.8402042291306073
Validation loss: 2.6312023862859086

Epoch: 6| Step: 4
Training loss: 3.001738680226864
Validation loss: 2.6167728747645898

Epoch: 6| Step: 5
Training loss: 2.7064235605171114
Validation loss: 2.5814273326483717

Epoch: 6| Step: 6
Training loss: 2.7610425323559427
Validation loss: 2.6434271819445976

Epoch: 6| Step: 7
Training loss: 2.75681656531008
Validation loss: 2.6404586441541436

Epoch: 6| Step: 8
Training loss: 2.6825443087115417
Validation loss: 2.6222950925311035

Epoch: 6| Step: 9
Training loss: 2.889582430494003
Validation loss: 2.6124148264328313

Epoch: 6| Step: 10
Training loss: 2.2193948587674828
Validation loss: 2.6354171241903503

Epoch: 6| Step: 11
Training loss: 2.337731938406268
Validation loss: 2.6183794270867593

Epoch: 6| Step: 12
Training loss: 2.6795940772139604
Validation loss: 2.641124647246923

Epoch: 6| Step: 13
Training loss: 2.4856199588009917
Validation loss: 2.6364523461594764

Epoch: 130| Step: 0
Training loss: 2.323597441903714
Validation loss: 2.62838709614422

Epoch: 6| Step: 1
Training loss: 2.114070159830566
Validation loss: 2.648454022438423

Epoch: 6| Step: 2
Training loss: 3.003588755165435
Validation loss: 2.6870456558566844

Epoch: 6| Step: 3
Training loss: 2.3553780558824973
Validation loss: 2.6418567126263257

Epoch: 6| Step: 4
Training loss: 2.3188355751389595
Validation loss: 2.609112699914131

Epoch: 6| Step: 5
Training loss: 1.9327522681680243
Validation loss: 2.644014590119433

Epoch: 6| Step: 6
Training loss: 2.4562953216797667
Validation loss: 2.618229713398189

Epoch: 6| Step: 7
Training loss: 2.8800699063929764
Validation loss: 2.677566522700426

Epoch: 6| Step: 8
Training loss: 3.2085403441653524
Validation loss: 2.6300907228520622

Epoch: 6| Step: 9
Training loss: 3.5404869059393413
Validation loss: 2.6581947962026238

Epoch: 6| Step: 10
Training loss: 2.3299481722589017
Validation loss: 2.6301978605815854

Epoch: 6| Step: 11
Training loss: 2.8389567127159236
Validation loss: 2.642500564019895

Epoch: 6| Step: 12
Training loss: 4.050872831127846
Validation loss: 2.662320553012176

Epoch: 6| Step: 13
Training loss: 2.577481368670017
Validation loss: 2.653047603723472

Epoch: 131| Step: 0
Training loss: 2.6224445438249044
Validation loss: 2.623992582068824

Epoch: 6| Step: 1
Training loss: 2.83532657821189
Validation loss: 2.612807872459876

Epoch: 6| Step: 2
Training loss: 3.4898826964156275
Validation loss: 2.619496137888083

Epoch: 6| Step: 3
Training loss: 3.2222022644243373
Validation loss: 2.638949590919247

Epoch: 6| Step: 4
Training loss: 3.0337158870154406
Validation loss: 2.6312371518445405

Epoch: 6| Step: 5
Training loss: 2.6574875585313245
Validation loss: 2.6344233355404194

Epoch: 6| Step: 6
Training loss: 3.158121441767968
Validation loss: 2.678600953813955

Epoch: 6| Step: 7
Training loss: 2.6412638957880756
Validation loss: 2.636132669581314

Epoch: 6| Step: 8
Training loss: 2.1927357820679028
Validation loss: 2.616750610109716

Epoch: 6| Step: 9
Training loss: 2.571999781607089
Validation loss: 2.6058846199745145

Epoch: 6| Step: 10
Training loss: 2.7399305309761406
Validation loss: 2.6401705728588616

Epoch: 6| Step: 11
Training loss: 2.075656543412748
Validation loss: 2.621401143648148

Epoch: 6| Step: 12
Training loss: 2.6021815757642797
Validation loss: 2.652401769831297

Epoch: 6| Step: 13
Training loss: 2.674106045665193
Validation loss: 2.648826378184524

Epoch: 132| Step: 0
Training loss: 2.2517435947419018
Validation loss: 2.634620431110513

Epoch: 6| Step: 1
Training loss: 2.179471350449838
Validation loss: 2.6167325315722043

Epoch: 6| Step: 2
Training loss: 2.8079811245101824
Validation loss: 2.6155908785132564

Epoch: 6| Step: 3
Training loss: 3.461901115102728
Validation loss: 2.6125713286446257

Epoch: 6| Step: 4
Training loss: 2.984246855376284
Validation loss: 2.6380607502269533

Epoch: 6| Step: 5
Training loss: 3.062506539474045
Validation loss: 2.6029026002227282

Epoch: 6| Step: 6
Training loss: 2.4239392743073793
Validation loss: 2.619380852093346

Epoch: 6| Step: 7
Training loss: 2.5985473022383516
Validation loss: 2.648957547770013

Epoch: 6| Step: 8
Training loss: 2.003120729438883
Validation loss: 2.6408312520947166

Epoch: 6| Step: 9
Training loss: 3.7686238990551044
Validation loss: 2.6094335734038325

Epoch: 6| Step: 10
Training loss: 2.8570727475964963
Validation loss: 2.6335736117849353

Epoch: 6| Step: 11
Training loss: 3.015615670777749
Validation loss: 2.648117699993738

Epoch: 6| Step: 12
Training loss: 2.15828862776048
Validation loss: 2.630884794377098

Epoch: 6| Step: 13
Training loss: 2.3775859607836534
Validation loss: 2.6410018245244364

Epoch: 133| Step: 0
Training loss: 2.8840713026991436
Validation loss: 2.6095683494292348

Epoch: 6| Step: 1
Training loss: 3.1348419845645292
Validation loss: 2.631556869780152

Epoch: 6| Step: 2
Training loss: 2.912513136936407
Validation loss: 2.6330690665126353

Epoch: 6| Step: 3
Training loss: 3.0925938150890353
Validation loss: 2.634627859431037

Epoch: 6| Step: 4
Training loss: 3.0344399253742966
Validation loss: 2.630724111056499

Epoch: 6| Step: 5
Training loss: 1.7648573700546888
Validation loss: 2.618556850115138

Epoch: 6| Step: 6
Training loss: 3.242830732032773
Validation loss: 2.61787756667557

Epoch: 6| Step: 7
Training loss: 2.77913559682275
Validation loss: 2.6419069062395364

Epoch: 6| Step: 8
Training loss: 3.219547802466701
Validation loss: 2.6289512451116677

Epoch: 6| Step: 9
Training loss: 2.935383460292703
Validation loss: 2.6568107500485576

Epoch: 6| Step: 10
Training loss: 2.238974152743357
Validation loss: 2.6093423306013674

Epoch: 6| Step: 11
Training loss: 2.6511956090891915
Validation loss: 2.627551640016107

Epoch: 6| Step: 12
Training loss: 2.6505711605735858
Validation loss: 2.6261752613591223

Epoch: 6| Step: 13
Training loss: 1.8169718856358008
Validation loss: 2.6485246808593654

Epoch: 134| Step: 0
Training loss: 2.8292028575561883
Validation loss: 2.6614727649755388

Epoch: 6| Step: 1
Training loss: 2.444727038415209
Validation loss: 2.6643847487526378

Epoch: 6| Step: 2
Training loss: 2.031538370643711
Validation loss: 2.6108261130099937

Epoch: 6| Step: 3
Training loss: 2.724216971630657
Validation loss: 2.63563507282729

Epoch: 6| Step: 4
Training loss: 3.298704968282771
Validation loss: 2.6195291181168674

Epoch: 6| Step: 5
Training loss: 2.5849629666241563
Validation loss: 2.642876331528759

Epoch: 6| Step: 6
Training loss: 3.2624956679041373
Validation loss: 2.6026571332789743

Epoch: 6| Step: 7
Training loss: 2.9264808297154272
Validation loss: 2.6052751652020234

Epoch: 6| Step: 8
Training loss: 3.379579333700915
Validation loss: 2.6115800533827693

Epoch: 6| Step: 9
Training loss: 2.6287490775069986
Validation loss: 2.6026055074615577

Epoch: 6| Step: 10
Training loss: 2.255754529489956
Validation loss: 2.6148889622259937

Epoch: 6| Step: 11
Training loss: 3.0334004118772144
Validation loss: 2.6377326224729267

Epoch: 6| Step: 12
Training loss: 2.40954789903174
Validation loss: 2.624430670381312

Epoch: 6| Step: 13
Training loss: 3.1607695598556775
Validation loss: 2.6376925415418624

Epoch: 135| Step: 0
Training loss: 3.6589641441387837
Validation loss: 2.617695221915582

Epoch: 6| Step: 1
Training loss: 3.1881056565470236
Validation loss: 2.6343117432014918

Epoch: 6| Step: 2
Training loss: 2.72913202355992
Validation loss: 2.6169078184634493

Epoch: 6| Step: 3
Training loss: 2.2060804091157635
Validation loss: 2.6536107076315325

Epoch: 6| Step: 4
Training loss: 2.7852820840153014
Validation loss: 2.610892733942654

Epoch: 6| Step: 5
Training loss: 2.4331679361995366
Validation loss: 2.61408198603327

Epoch: 6| Step: 6
Training loss: 1.8440724107133049
Validation loss: 2.6185216043782256

Epoch: 6| Step: 7
Training loss: 3.575782775545201
Validation loss: 2.6538866081528725

Epoch: 6| Step: 8
Training loss: 2.230948107729336
Validation loss: 2.6364215418681485

Epoch: 6| Step: 9
Training loss: 3.5675278369697008
Validation loss: 2.6429011765123005

Epoch: 6| Step: 10
Training loss: 2.3617876866179475
Validation loss: 2.6346568427197696

Epoch: 6| Step: 11
Training loss: 2.1072646145129976
Validation loss: 2.625714530519072

Epoch: 6| Step: 12
Training loss: 2.865986835095449
Validation loss: 2.643268126200562

Epoch: 6| Step: 13
Training loss: 2.8246912897276375
Validation loss: 2.635389671655975

Epoch: 136| Step: 0
Training loss: 3.916173186901924
Validation loss: 2.609960341901311

Epoch: 6| Step: 1
Training loss: 1.9186539368082345
Validation loss: 2.599647929773657

Epoch: 6| Step: 2
Training loss: 2.8674286369350224
Validation loss: 2.615883435376222

Epoch: 6| Step: 3
Training loss: 2.418777848115435
Validation loss: 2.6016402122870725

Epoch: 6| Step: 4
Training loss: 2.4400775681345017
Validation loss: 2.6264842349780215

Epoch: 6| Step: 5
Training loss: 3.0967568322048824
Validation loss: 2.606761189888002

Epoch: 6| Step: 6
Training loss: 2.5645187613577636
Validation loss: 2.6113245210364933

Epoch: 6| Step: 7
Training loss: 2.344319388844366
Validation loss: 2.622754462288618

Epoch: 6| Step: 8
Training loss: 2.512336998961345
Validation loss: 2.6398570946609645

Epoch: 6| Step: 9
Training loss: 2.2183393716288107
Validation loss: 2.5906315755387714

Epoch: 6| Step: 10
Training loss: 3.023625173337921
Validation loss: 2.623937173862357

Epoch: 6| Step: 11
Training loss: 3.2964031731578105
Validation loss: 2.593120124364323

Epoch: 6| Step: 12
Training loss: 2.5929558698765858
Validation loss: 2.6043677464449937

Epoch: 6| Step: 13
Training loss: 3.05199358464238
Validation loss: 2.6108809717128434

Epoch: 137| Step: 0
Training loss: 3.753480313496549
Validation loss: 2.639799989741369

Epoch: 6| Step: 1
Training loss: 2.3712111920050147
Validation loss: 2.613052511925901

Epoch: 6| Step: 2
Training loss: 2.757297629904895
Validation loss: 2.6313718818260585

Epoch: 6| Step: 3
Training loss: 2.7224013265307767
Validation loss: 2.63124797445762

Epoch: 6| Step: 4
Training loss: 2.922077845095899
Validation loss: 2.587541612620738

Epoch: 6| Step: 5
Training loss: 2.202868291089084
Validation loss: 2.631569218604083

Epoch: 6| Step: 6
Training loss: 1.8397407259919238
Validation loss: 2.6368982402396277

Epoch: 6| Step: 7
Training loss: 2.4890836802202276
Validation loss: 2.5951601354622853

Epoch: 6| Step: 8
Training loss: 2.1503008166276985
Validation loss: 2.6337622782525183

Epoch: 6| Step: 9
Training loss: 3.417802590827288
Validation loss: 2.6075596125510256

Epoch: 6| Step: 10
Training loss: 3.034565321888797
Validation loss: 2.6242973443916586

Epoch: 6| Step: 11
Training loss: 2.9480125133088375
Validation loss: 2.6225360111471674

Epoch: 6| Step: 12
Training loss: 3.1201078650584515
Validation loss: 2.628752477164103

Epoch: 6| Step: 13
Training loss: 2.325981638421806
Validation loss: 2.6137543240630667

Epoch: 138| Step: 0
Training loss: 2.519261734615917
Validation loss: 2.628502364376455

Epoch: 6| Step: 1
Training loss: 2.9412300290111837
Validation loss: 2.594158896002235

Epoch: 6| Step: 2
Training loss: 2.9235352068119087
Validation loss: 2.625218694828472

Epoch: 6| Step: 3
Training loss: 2.401265319425853
Validation loss: 2.615891557840821

Epoch: 6| Step: 4
Training loss: 2.8031453858041466
Validation loss: 2.630451340213299

Epoch: 6| Step: 5
Training loss: 1.8552466972392614
Validation loss: 2.642317043703787

Epoch: 6| Step: 6
Training loss: 3.322019035252666
Validation loss: 2.603629810411697

Epoch: 6| Step: 7
Training loss: 3.1883032291611006
Validation loss: 2.6107528867414183

Epoch: 6| Step: 8
Training loss: 3.353390210871987
Validation loss: 2.6249666197217514

Epoch: 6| Step: 9
Training loss: 2.94481381512681
Validation loss: 2.6310987416246348

Epoch: 6| Step: 10
Training loss: 3.1645046349074266
Validation loss: 2.634470370464026

Epoch: 6| Step: 11
Training loss: 2.296787597654122
Validation loss: 2.618007783473956

Epoch: 6| Step: 12
Training loss: 2.17920452495923
Validation loss: 2.6718593995865154

Epoch: 6| Step: 13
Training loss: 2.355789896516568
Validation loss: 2.6311930600509594

Epoch: 139| Step: 0
Training loss: 3.3772033281009213
Validation loss: 2.602346935467231

Epoch: 6| Step: 1
Training loss: 2.745107633776954
Validation loss: 2.6250339873067383

Epoch: 6| Step: 2
Training loss: 2.485514637331701
Validation loss: 2.6332772987180753

Epoch: 6| Step: 3
Training loss: 2.5002028382984247
Validation loss: 2.6554656557909007

Epoch: 6| Step: 4
Training loss: 1.9573089950739166
Validation loss: 2.613140181671071

Epoch: 6| Step: 5
Training loss: 2.5608552445892436
Validation loss: 2.6225646774268445

Epoch: 6| Step: 6
Training loss: 2.9518668910877732
Validation loss: 2.6493644750990266

Epoch: 6| Step: 7
Training loss: 2.7462489815433577
Validation loss: 2.6217171816247493

Epoch: 6| Step: 8
Training loss: 3.413092643501996
Validation loss: 2.6120266188301753

Epoch: 6| Step: 9
Training loss: 3.580713260499709
Validation loss: 2.6384576576469723

Epoch: 6| Step: 10
Training loss: 2.518015040091394
Validation loss: 2.6383674759151017

Epoch: 6| Step: 11
Training loss: 2.12324294208776
Validation loss: 2.657046258184385

Epoch: 6| Step: 12
Training loss: 2.4278824654400406
Validation loss: 2.6463392195708644

Epoch: 6| Step: 13
Training loss: 2.9518636603362745
Validation loss: 2.626451343060406

Epoch: 140| Step: 0
Training loss: 3.009644740484867
Validation loss: 2.6342208998433976

Epoch: 6| Step: 1
Training loss: 3.896499060122703
Validation loss: 2.6097100705726106

Epoch: 6| Step: 2
Training loss: 2.6368564598008564
Validation loss: 2.616237146912868

Epoch: 6| Step: 3
Training loss: 3.1236664024545324
Validation loss: 2.6284267113300968

Epoch: 6| Step: 4
Training loss: 2.522172829437978
Validation loss: 2.6388802091250314

Epoch: 6| Step: 5
Training loss: 2.9031670738760265
Validation loss: 2.6037176881370776

Epoch: 6| Step: 6
Training loss: 2.397957520809417
Validation loss: 2.6261003398178957

Epoch: 6| Step: 7
Training loss: 2.614363783981701
Validation loss: 2.6374834312576

Epoch: 6| Step: 8
Training loss: 2.9988769972489546
Validation loss: 2.6185434085148755

Epoch: 6| Step: 9
Training loss: 3.1386518210700354
Validation loss: 2.6160057332290685

Epoch: 6| Step: 10
Training loss: 2.049994036037795
Validation loss: 2.6070911585642693

Epoch: 6| Step: 11
Training loss: 2.339559139716541
Validation loss: 2.6529399605203423

Epoch: 6| Step: 12
Training loss: 2.304913215575686
Validation loss: 2.592498270684236

Epoch: 6| Step: 13
Training loss: 2.1145297890885506
Validation loss: 2.663062483200379

Epoch: 141| Step: 0
Training loss: 2.7155922276458564
Validation loss: 2.6417585302670834

Epoch: 6| Step: 1
Training loss: 2.068439255163425
Validation loss: 2.641208982881835

Epoch: 6| Step: 2
Training loss: 2.84208513089164
Validation loss: 2.629329031882952

Epoch: 6| Step: 3
Training loss: 2.35338879002112
Validation loss: 2.628720869740721

Epoch: 6| Step: 4
Training loss: 2.5098482704656226
Validation loss: 2.6172483434386575

Epoch: 6| Step: 5
Training loss: 3.4673182651500656
Validation loss: 2.599403106715258

Epoch: 6| Step: 6
Training loss: 2.935455422363305
Validation loss: 2.6416819438244783

Epoch: 6| Step: 7
Training loss: 2.943832713785369
Validation loss: 2.622764472449319

Epoch: 6| Step: 8
Training loss: 3.2078893445115684
Validation loss: 2.6129851150543026

Epoch: 6| Step: 9
Training loss: 3.0554031353320585
Validation loss: 2.61942701399785

Epoch: 6| Step: 10
Training loss: 2.651629749315242
Validation loss: 2.608494131030521

Epoch: 6| Step: 11
Training loss: 2.416278994367038
Validation loss: 2.6349771692426756

Epoch: 6| Step: 12
Training loss: 2.2985885352658415
Validation loss: 2.6325888254051946

Epoch: 6| Step: 13
Training loss: 3.081169056167731
Validation loss: 2.6202828173530412

Epoch: 142| Step: 0
Training loss: 3.0461457773693077
Validation loss: 2.6230075265052704

Epoch: 6| Step: 1
Training loss: 2.674417546400318
Validation loss: 2.641216334434581

Epoch: 6| Step: 2
Training loss: 3.0902813819740413
Validation loss: 2.617181343581958

Epoch: 6| Step: 3
Training loss: 1.5884005958162148
Validation loss: 2.6049786436794165

Epoch: 6| Step: 4
Training loss: 2.4047158044409684
Validation loss: 2.636961389920945

Epoch: 6| Step: 5
Training loss: 3.1063443083233753
Validation loss: 2.603939679661759

Epoch: 6| Step: 6
Training loss: 3.0367078902136506
Validation loss: 2.6104371653404908

Epoch: 6| Step: 7
Training loss: 1.8938796348391693
Validation loss: 2.5998966562511687

Epoch: 6| Step: 8
Training loss: 2.656783824460882
Validation loss: 2.6222875539968586

Epoch: 6| Step: 9
Training loss: 2.433689072703001
Validation loss: 2.6200907996831546

Epoch: 6| Step: 10
Training loss: 3.461572868632627
Validation loss: 2.6132511329886654

Epoch: 6| Step: 11
Training loss: 2.6648072574904877
Validation loss: 2.606996089602289

Epoch: 6| Step: 12
Training loss: 2.8777532248347626
Validation loss: 2.626041277121799

Epoch: 6| Step: 13
Training loss: 3.606448750167601
Validation loss: 2.634455574220438

Epoch: 143| Step: 0
Training loss: 2.9054943455930093
Validation loss: 2.584715896650751

Epoch: 6| Step: 1
Training loss: 2.7060323085843856
Validation loss: 2.603771729742262

Epoch: 6| Step: 2
Training loss: 3.1464533079142103
Validation loss: 2.6542587991664455

Epoch: 6| Step: 3
Training loss: 2.5498121678605328
Validation loss: 2.6352476641115934

Epoch: 6| Step: 4
Training loss: 2.867162553642327
Validation loss: 2.6411720763024755

Epoch: 6| Step: 5
Training loss: 2.090783594157381
Validation loss: 2.608050622302558

Epoch: 6| Step: 6
Training loss: 2.6335336846376842
Validation loss: 2.61186569406278

Epoch: 6| Step: 7
Training loss: 2.044512367963057
Validation loss: 2.6168236127031492

Epoch: 6| Step: 8
Training loss: 2.671596936485749
Validation loss: 2.6086000496880266

Epoch: 6| Step: 9
Training loss: 3.2060935058474676
Validation loss: 2.62106417463556

Epoch: 6| Step: 10
Training loss: 3.381321109157973
Validation loss: 2.6601023564124042

Epoch: 6| Step: 11
Training loss: 2.644406562243553
Validation loss: 2.6469393288519107

Epoch: 6| Step: 12
Training loss: 3.1761815193057057
Validation loss: 2.6296995727034984

Epoch: 6| Step: 13
Training loss: 2.0369247981981085
Validation loss: 2.634102165986866

Epoch: 144| Step: 0
Training loss: 2.5944263541575463
Validation loss: 2.616711877231523

Epoch: 6| Step: 1
Training loss: 2.811484344200032
Validation loss: 2.616743622852561

Epoch: 6| Step: 2
Training loss: 3.2697023189733505
Validation loss: 2.613698386904559

Epoch: 6| Step: 3
Training loss: 2.7579216003450684
Validation loss: 2.598919545232998

Epoch: 6| Step: 4
Training loss: 2.4741415712191603
Validation loss: 2.6564016956345617

Epoch: 6| Step: 5
Training loss: 2.5893321272725767
Validation loss: 2.621890934549313

Epoch: 6| Step: 6
Training loss: 2.690928910976777
Validation loss: 2.622500161482863

Epoch: 6| Step: 7
Training loss: 2.459353854756174
Validation loss: 2.6149848201901458

Epoch: 6| Step: 8
Training loss: 2.6439817863564175
Validation loss: 2.613856154474033

Epoch: 6| Step: 9
Training loss: 3.1445565738013688
Validation loss: 2.630433243758773

Epoch: 6| Step: 10
Training loss: 2.6914813691439923
Validation loss: 2.6184915006451703

Epoch: 6| Step: 11
Training loss: 2.488083668384435
Validation loss: 2.620135772018956

Epoch: 6| Step: 12
Training loss: 2.986516374002503
Validation loss: 2.6159959608222874

Epoch: 6| Step: 13
Training loss: 3.1916381303459396
Validation loss: 2.58680065156675

Epoch: 145| Step: 0
Training loss: 3.2653244829391515
Validation loss: 2.6150396235122058

Epoch: 6| Step: 1
Training loss: 2.3145631401859026
Validation loss: 2.5964479525229653

Epoch: 6| Step: 2
Training loss: 2.411745607691803
Validation loss: 2.6158498574201077

Epoch: 6| Step: 3
Training loss: 2.0541025931970647
Validation loss: 2.586022560785939

Epoch: 6| Step: 4
Training loss: 3.0023306694212355
Validation loss: 2.6083548756624255

Epoch: 6| Step: 5
Training loss: 2.7157341025399084
Validation loss: 2.6230922921635695

Epoch: 6| Step: 6
Training loss: 2.549091614882775
Validation loss: 2.5979601260174716

Epoch: 6| Step: 7
Training loss: 3.1928377524567675
Validation loss: 2.599607361745842

Epoch: 6| Step: 8
Training loss: 2.984692142272477
Validation loss: 2.6357980497829883

Epoch: 6| Step: 9
Training loss: 2.794846806294452
Validation loss: 2.612730034114714

Epoch: 6| Step: 10
Training loss: 3.07701315381174
Validation loss: 2.604851917964956

Epoch: 6| Step: 11
Training loss: 3.041042751615123
Validation loss: 2.618214542398149

Epoch: 6| Step: 12
Training loss: 2.796110251101683
Validation loss: 2.6413407039980634

Epoch: 6| Step: 13
Training loss: 2.1790682005168316
Validation loss: 2.5932084640182276

Epoch: 146| Step: 0
Training loss: 2.2550922625290326
Validation loss: 2.5919698365439716

Epoch: 6| Step: 1
Training loss: 2.29836676285821
Validation loss: 2.643000804364132

Epoch: 6| Step: 2
Training loss: 2.7155685225782595
Validation loss: 2.6123428650148734

Epoch: 6| Step: 3
Training loss: 2.997020831652067
Validation loss: 2.6426915092588668

Epoch: 6| Step: 4
Training loss: 2.6494008340586177
Validation loss: 2.6628042806805463

Epoch: 6| Step: 5
Training loss: 3.0225920369891655
Validation loss: 2.5949223173623093

Epoch: 6| Step: 6
Training loss: 2.4214275315897784
Validation loss: 2.623657002159665

Epoch: 6| Step: 7
Training loss: 2.541811631451374
Validation loss: 2.629915367111314

Epoch: 6| Step: 8
Training loss: 2.974876747463272
Validation loss: 2.6318496409387495

Epoch: 6| Step: 9
Training loss: 2.8137629746180726
Validation loss: 2.642974202708114

Epoch: 6| Step: 10
Training loss: 2.9508619568614436
Validation loss: 2.614619386982716

Epoch: 6| Step: 11
Training loss: 2.638628503992193
Validation loss: 2.6357255702994595

Epoch: 6| Step: 12
Training loss: 2.883669511310869
Validation loss: 2.63260685543076

Epoch: 6| Step: 13
Training loss: 4.096948669842022
Validation loss: 2.5899458612813

Epoch: 147| Step: 0
Training loss: 2.7850653378066466
Validation loss: 2.612631758542665

Epoch: 6| Step: 1
Training loss: 2.9427673513970216
Validation loss: 2.6404171501618188

Epoch: 6| Step: 2
Training loss: 2.9927616215993984
Validation loss: 2.629501727081568

Epoch: 6| Step: 3
Training loss: 3.072199506102729
Validation loss: 2.6210027028190317

Epoch: 6| Step: 4
Training loss: 2.627584365956634
Validation loss: 2.616660490499648

Epoch: 6| Step: 5
Training loss: 3.085168515739102
Validation loss: 2.6259091536855186

Epoch: 6| Step: 6
Training loss: 2.283928122169419
Validation loss: 2.6439612285294514

Epoch: 6| Step: 7
Training loss: 2.2842950225063774
Validation loss: 2.597622523280453

Epoch: 6| Step: 8
Training loss: 2.426877571082982
Validation loss: 2.5989073426271143

Epoch: 6| Step: 9
Training loss: 2.243669505256048
Validation loss: 2.619546068534346

Epoch: 6| Step: 10
Training loss: 3.152860577840895
Validation loss: 2.5912578236806114

Epoch: 6| Step: 11
Training loss: 2.254331446164259
Validation loss: 2.6278324247373783

Epoch: 6| Step: 12
Training loss: 2.983266574673877
Validation loss: 2.6074379976112176

Epoch: 6| Step: 13
Training loss: 3.411439075367081
Validation loss: 2.594959260316205

Epoch: 148| Step: 0
Training loss: 2.7832186300280832
Validation loss: 2.6195656259698223

Epoch: 6| Step: 1
Training loss: 1.7010318597751104
Validation loss: 2.6690055379581765

Epoch: 6| Step: 2
Training loss: 2.7048207515196943
Validation loss: 2.613570220287363

Epoch: 6| Step: 3
Training loss: 2.824678544516578
Validation loss: 2.599212504507123

Epoch: 6| Step: 4
Training loss: 2.325494188680792
Validation loss: 2.6000479264649945

Epoch: 6| Step: 5
Training loss: 3.5839584308069816
Validation loss: 2.600004101466816

Epoch: 6| Step: 6
Training loss: 2.8813265974409434
Validation loss: 2.6406188147318845

Epoch: 6| Step: 7
Training loss: 2.3273886725888047
Validation loss: 2.6365873881819293

Epoch: 6| Step: 8
Training loss: 3.5511988697446366
Validation loss: 2.6240276971662584

Epoch: 6| Step: 9
Training loss: 3.166274966726199
Validation loss: 2.6459079275225057

Epoch: 6| Step: 10
Training loss: 2.947424983525162
Validation loss: 2.624952953598714

Epoch: 6| Step: 11
Training loss: 1.9900706694625083
Validation loss: 2.6104109153713337

Epoch: 6| Step: 12
Training loss: 2.4335935540604856
Validation loss: 2.6386932522530584

Epoch: 6| Step: 13
Training loss: 2.713633227618807
Validation loss: 2.621426082635082

Epoch: 149| Step: 0
Training loss: 2.630779352932263
Validation loss: 2.633432619017822

Epoch: 6| Step: 1
Training loss: 1.9188535556744266
Validation loss: 2.643042717554987

Epoch: 6| Step: 2
Training loss: 3.490667161541761
Validation loss: 2.652743917783606

Epoch: 6| Step: 3
Training loss: 2.461456825319383
Validation loss: 2.615676489246888

Epoch: 6| Step: 4
Training loss: 2.578481198759921
Validation loss: 2.6273780565378897

Epoch: 6| Step: 5
Training loss: 3.1179569986839284
Validation loss: 2.614533849003679

Epoch: 6| Step: 6
Training loss: 2.8749082799461667
Validation loss: 2.614425266771037

Epoch: 6| Step: 7
Training loss: 2.913522296977971
Validation loss: 2.654672264865581

Epoch: 6| Step: 8
Training loss: 3.479061300239298
Validation loss: 2.62010873274287

Epoch: 6| Step: 9
Training loss: 2.495416827042335
Validation loss: 2.6282773280606766

Epoch: 6| Step: 10
Training loss: 2.46270030025171
Validation loss: 2.5842656445590597

Epoch: 6| Step: 11
Training loss: 2.7492534317643162
Validation loss: 2.6203702168216787

Epoch: 6| Step: 12
Training loss: 2.0775478393334863
Validation loss: 2.6290029908296404

Epoch: 6| Step: 13
Training loss: 3.0959226127336654
Validation loss: 2.6256619354729365

Epoch: 150| Step: 0
Training loss: 2.5590484448073845
Validation loss: 2.632968157345393

Epoch: 6| Step: 1
Training loss: 2.2935900390728037
Validation loss: 2.614290204734782

Epoch: 6| Step: 2
Training loss: 3.632738075724542
Validation loss: 2.613419819096193

Epoch: 6| Step: 3
Training loss: 2.8283610377156534
Validation loss: 2.6369495991138225

Epoch: 6| Step: 4
Training loss: 2.489903279153344
Validation loss: 2.5977914663190593

Epoch: 6| Step: 5
Training loss: 2.8423510453543304
Validation loss: 2.6389673355940877

Epoch: 6| Step: 6
Training loss: 2.555783284678532
Validation loss: 2.6045104819136817

Epoch: 6| Step: 7
Training loss: 2.418160722103389
Validation loss: 2.5981309909523502

Epoch: 6| Step: 8
Training loss: 2.357858739036746
Validation loss: 2.6065111346338883

Epoch: 6| Step: 9
Training loss: 2.6088127398474916
Validation loss: 2.622992535609501

Epoch: 6| Step: 10
Training loss: 2.795820751436654
Validation loss: 2.623548472604467

Epoch: 6| Step: 11
Training loss: 3.243155534842748
Validation loss: 2.6196098371363177

Epoch: 6| Step: 12
Training loss: 3.0918471524457534
Validation loss: 2.64097715678681

Epoch: 6| Step: 13
Training loss: 2.1330844580002353
Validation loss: 2.5959120920115177

Testing loss: 2.485977792509907
