Epoch: 1| Step: 0
Training loss: 6.75023735476784
Validation loss: 6.408864498790542

Epoch: 5| Step: 1
Training loss: 6.1246646088618535
Validation loss: 6.401592241540256

Epoch: 5| Step: 2
Training loss: 6.945008759352321
Validation loss: 6.398503588824291

Epoch: 5| Step: 3
Training loss: 6.41919126841749
Validation loss: 6.3987049538353284

Epoch: 5| Step: 4
Training loss: 4.611808729190606
Validation loss: 6.395997163737849

Epoch: 5| Step: 5
Training loss: 6.585483666617891
Validation loss: 6.391724159277461

Epoch: 5| Step: 6
Training loss: 6.137074305422205
Validation loss: 6.388540478813344

Epoch: 5| Step: 7
Training loss: 6.875249129896642
Validation loss: 6.380195770016913

Epoch: 5| Step: 8
Training loss: 6.892913507531808
Validation loss: 6.378303153040532

Epoch: 5| Step: 9
Training loss: 6.344626079630858
Validation loss: 6.37191858201736

Epoch: 5| Step: 10
Training loss: 6.392446244438596
Validation loss: 6.369993086634837

Epoch: 2| Step: 0
Training loss: 5.789218998285297
Validation loss: 6.368823961167428

Epoch: 5| Step: 1
Training loss: 6.299035243687775
Validation loss: 6.363194356184403

Epoch: 5| Step: 2
Training loss: 6.228614536001239
Validation loss: 6.357821649307161

Epoch: 5| Step: 3
Training loss: 8.088070559532513
Validation loss: 6.354250339042552

Epoch: 5| Step: 4
Training loss: 5.7912112635587665
Validation loss: 6.350345949091924

Epoch: 5| Step: 5
Training loss: 6.147197128101415
Validation loss: 6.350130107523091

Epoch: 5| Step: 6
Training loss: 6.419730837874881
Validation loss: 6.345483169437895

Epoch: 5| Step: 7
Training loss: 5.593730052720631
Validation loss: 6.341910101439049

Epoch: 5| Step: 8
Training loss: 6.576632441363804
Validation loss: 6.339390823596482

Epoch: 5| Step: 9
Training loss: 6.803919156445877
Validation loss: 6.338352851287659

Epoch: 5| Step: 10
Training loss: 5.79588617903611
Validation loss: 6.334142242525766

Epoch: 3| Step: 0
Training loss: 6.119215433032991
Validation loss: 6.329574069433355

Epoch: 5| Step: 1
Training loss: 6.15536167300017
Validation loss: 6.328353651243809

Epoch: 5| Step: 2
Training loss: 6.105458753190792
Validation loss: 6.32725051231735

Epoch: 5| Step: 3
Training loss: 6.366974210384641
Validation loss: 6.324193393323254

Epoch: 5| Step: 4
Training loss: 6.434306417343335
Validation loss: 6.318999985766907

Epoch: 5| Step: 5
Training loss: 6.270656781758142
Validation loss: 6.318061703960735

Epoch: 5| Step: 6
Training loss: 5.616401882703216
Validation loss: 6.317470947569172

Epoch: 5| Step: 7
Training loss: 6.919390161356572
Validation loss: 6.310569312793532

Epoch: 5| Step: 8
Training loss: 7.105182862153421
Validation loss: 6.307580529334402

Epoch: 5| Step: 9
Training loss: 5.681544277178094
Validation loss: 6.306632725914102

Epoch: 5| Step: 10
Training loss: 6.756097935492413
Validation loss: 6.299362728157159

Epoch: 4| Step: 0
Training loss: 6.396467974692715
Validation loss: 6.299093778260666

Epoch: 5| Step: 1
Training loss: 7.133099687023835
Validation loss: 6.295586405726478

Epoch: 5| Step: 2
Training loss: 5.783527647303083
Validation loss: 6.294179456838554

Epoch: 5| Step: 3
Training loss: 6.0624836400391375
Validation loss: 6.289209657696532

Epoch: 5| Step: 4
Training loss: 6.733565492058412
Validation loss: 6.286343757951494

Epoch: 5| Step: 5
Training loss: 4.833232659354723
Validation loss: 6.284368793843899

Epoch: 5| Step: 6
Training loss: 6.967470060078187
Validation loss: 6.282042975978918

Epoch: 5| Step: 7
Training loss: 5.965046477604384
Validation loss: 6.278159516552334

Epoch: 5| Step: 8
Training loss: 6.174749318335693
Validation loss: 6.2734318557227775

Epoch: 5| Step: 9
Training loss: 6.567202962802251
Validation loss: 6.2651467396370055

Epoch: 5| Step: 10
Training loss: 6.3145802913076565
Validation loss: 6.266585623287577

Epoch: 5| Step: 0
Training loss: 7.138752564523457
Validation loss: 6.2621493462691005

Epoch: 5| Step: 1
Training loss: 5.758710814421977
Validation loss: 6.2558937487882895

Epoch: 5| Step: 2
Training loss: 5.400930268019554
Validation loss: 6.248836387685005

Epoch: 5| Step: 3
Training loss: 5.626971259678778
Validation loss: 6.245980113175774

Epoch: 5| Step: 4
Training loss: 6.259585240185678
Validation loss: 6.2447918133607905

Epoch: 5| Step: 5
Training loss: 5.93496810737403
Validation loss: 6.240485498695352

Epoch: 5| Step: 6
Training loss: 5.540358807343738
Validation loss: 6.232132041814681

Epoch: 5| Step: 7
Training loss: 7.292950965765676
Validation loss: 6.230018755264453

Epoch: 5| Step: 8
Training loss: 5.958982134443204
Validation loss: 6.225076714790989

Epoch: 5| Step: 9
Training loss: 6.823612494088628
Validation loss: 6.2177482841587715

Epoch: 5| Step: 10
Training loss: 6.717667745320799
Validation loss: 6.213131386451372

Epoch: 6| Step: 0
Training loss: 6.166584461110999
Validation loss: 6.206254677053612

Epoch: 5| Step: 1
Training loss: 6.726935364139494
Validation loss: 6.201434210965302

Epoch: 5| Step: 2
Training loss: 6.2754568837927485
Validation loss: 6.193797496815816

Epoch: 5| Step: 3
Training loss: 6.299523944125256
Validation loss: 6.18608451787312

Epoch: 5| Step: 4
Training loss: 6.492583812456146
Validation loss: 6.184776425170192

Epoch: 5| Step: 5
Training loss: 6.607029852766052
Validation loss: 6.176217689930982

Epoch: 5| Step: 6
Training loss: 6.380019661325994
Validation loss: 6.168885136556939

Epoch: 5| Step: 7
Training loss: 5.683287013844918
Validation loss: 6.163463428510153

Epoch: 5| Step: 8
Training loss: 6.1156317241555715
Validation loss: 6.158227623188997

Epoch: 5| Step: 9
Training loss: 5.058531347648406
Validation loss: 6.145772693877846

Epoch: 5| Step: 10
Training loss: 6.172806063573221
Validation loss: 6.142904351683671

Epoch: 7| Step: 0
Training loss: 5.887485952826262
Validation loss: 6.134284527591295

Epoch: 5| Step: 1
Training loss: 6.171402770699959
Validation loss: 6.128257339033441

Epoch: 5| Step: 2
Training loss: 6.593668426442984
Validation loss: 6.123279838109736

Epoch: 5| Step: 3
Training loss: 5.831387912963352
Validation loss: 6.115957590755648

Epoch: 5| Step: 4
Training loss: 5.371252483449907
Validation loss: 6.11058280366572

Epoch: 5| Step: 5
Training loss: 6.812358329769772
Validation loss: 6.100420742563627

Epoch: 5| Step: 6
Training loss: 5.880403022707938
Validation loss: 6.096623639085366

Epoch: 5| Step: 7
Training loss: 6.5135257550139825
Validation loss: 6.086249927412945

Epoch: 5| Step: 8
Training loss: 5.916219058589594
Validation loss: 6.079691989568635

Epoch: 5| Step: 9
Training loss: 6.5827921713355115
Validation loss: 6.072313348999005

Epoch: 5| Step: 10
Training loss: 5.450399772610667
Validation loss: 6.060294369693272

Epoch: 8| Step: 0
Training loss: 5.768360512460103
Validation loss: 6.058379711244372

Epoch: 5| Step: 1
Training loss: 6.510328156950434
Validation loss: 6.044440182008352

Epoch: 5| Step: 2
Training loss: 5.5973301517670775
Validation loss: 6.03826252470087

Epoch: 5| Step: 3
Training loss: 5.895861011166078
Validation loss: 6.032900936713413

Epoch: 5| Step: 4
Training loss: 6.7425626117768065
Validation loss: 6.022092657778307

Epoch: 5| Step: 5
Training loss: 6.688849767498011
Validation loss: 6.01257030851956

Epoch: 5| Step: 6
Training loss: 5.864665905476741
Validation loss: 6.007225369041506

Epoch: 5| Step: 7
Training loss: 5.401989796283891
Validation loss: 5.998415635230514

Epoch: 5| Step: 8
Training loss: 5.774904800224863
Validation loss: 5.9882892025584775

Epoch: 5| Step: 9
Training loss: 5.773231017429948
Validation loss: 5.97963944805119

Epoch: 5| Step: 10
Training loss: 6.172252633818839
Validation loss: 5.970954771720229

Epoch: 9| Step: 0
Training loss: 4.74175912848474
Validation loss: 5.965366372783818

Epoch: 5| Step: 1
Training loss: 6.172886401010097
Validation loss: 5.954055769783539

Epoch: 5| Step: 2
Training loss: 5.9430705391120275
Validation loss: 5.945694710106895

Epoch: 5| Step: 3
Training loss: 7.3913068073785695
Validation loss: 5.935275570340686

Epoch: 5| Step: 4
Training loss: 5.261959078935209
Validation loss: 5.924894427152522

Epoch: 5| Step: 5
Training loss: 6.172962411622375
Validation loss: 5.910281842047236

Epoch: 5| Step: 6
Training loss: 6.7887579495125845
Validation loss: 5.908598186993924

Epoch: 5| Step: 7
Training loss: 6.472827160914937
Validation loss: 5.8992519047601695

Epoch: 5| Step: 8
Training loss: 5.204823259766394
Validation loss: 5.886022509741159

Epoch: 5| Step: 9
Training loss: 5.203169355690255
Validation loss: 5.87543743724372

Epoch: 5| Step: 10
Training loss: 5.323981231518801
Validation loss: 5.8661556098676035

Epoch: 10| Step: 0
Training loss: 5.37689885154683
Validation loss: 5.855900960343511

Epoch: 5| Step: 1
Training loss: 5.5767417068737855
Validation loss: 5.850889552584141

Epoch: 5| Step: 2
Training loss: 6.25969158253792
Validation loss: 5.84025020668537

Epoch: 5| Step: 3
Training loss: 6.4938613074330265
Validation loss: 5.833093402106237

Epoch: 5| Step: 4
Training loss: 5.797233632142535
Validation loss: 5.819818510509988

Epoch: 5| Step: 5
Training loss: 6.563938818740018
Validation loss: 5.812772367149289

Epoch: 5| Step: 6
Training loss: 5.039019349379199
Validation loss: 5.798999997127548

Epoch: 5| Step: 7
Training loss: 5.969712104948345
Validation loss: 5.7911863265795

Epoch: 5| Step: 8
Training loss: 5.788479300709824
Validation loss: 5.77823413695739

Epoch: 5| Step: 9
Training loss: 5.641900000355702
Validation loss: 5.768877965637734

Epoch: 5| Step: 10
Training loss: 5.376545351239997
Validation loss: 5.757326773562673

Epoch: 11| Step: 0
Training loss: 5.203158175159347
Validation loss: 5.741872292604471

Epoch: 5| Step: 1
Training loss: 6.01385329277344
Validation loss: 5.737368968232613

Epoch: 5| Step: 2
Training loss: 3.916565115944593
Validation loss: 5.725857054564629

Epoch: 5| Step: 3
Training loss: 6.202135444330785
Validation loss: 5.713742616513499

Epoch: 5| Step: 4
Training loss: 5.448210942311598
Validation loss: 5.702691027033935

Epoch: 5| Step: 5
Training loss: 5.408951277420494
Validation loss: 5.692388170920705

Epoch: 5| Step: 6
Training loss: 5.915744154385523
Validation loss: 5.688925884284732

Epoch: 5| Step: 7
Training loss: 5.2307759679776815
Validation loss: 5.66982365325752

Epoch: 5| Step: 8
Training loss: 7.068771953194524
Validation loss: 5.6544155458574705

Epoch: 5| Step: 9
Training loss: 6.181640933550545
Validation loss: 5.650717377737031

Epoch: 5| Step: 10
Training loss: 5.6758729910213
Validation loss: 5.6286444248468355

Epoch: 12| Step: 0
Training loss: 5.378598982180062
Validation loss: 5.623521157843844

Epoch: 5| Step: 1
Training loss: 5.021984976019466
Validation loss: 5.601696901863905

Epoch: 5| Step: 2
Training loss: 5.206010997548103
Validation loss: 5.598607258608435

Epoch: 5| Step: 3
Training loss: 5.886669176446042
Validation loss: 5.585514540047969

Epoch: 5| Step: 4
Training loss: 6.057826177401054
Validation loss: 5.579058941151539

Epoch: 5| Step: 5
Training loss: 6.456400559507941
Validation loss: 5.549743518854329

Epoch: 5| Step: 6
Training loss: 5.750477646601411
Validation loss: 5.5423211263238485

Epoch: 5| Step: 7
Training loss: 4.765601186223801
Validation loss: 5.524422002502189

Epoch: 5| Step: 8
Training loss: 6.156296473293813
Validation loss: 5.510724391409403

Epoch: 5| Step: 9
Training loss: 5.600197086953255
Validation loss: 5.497124392840278

Epoch: 5| Step: 10
Training loss: 4.7097421524514615
Validation loss: 5.488677193265342

Epoch: 13| Step: 0
Training loss: 5.897800759816343
Validation loss: 5.47557219783938

Epoch: 5| Step: 1
Training loss: 5.577872305310127
Validation loss: 5.456426841592289

Epoch: 5| Step: 2
Training loss: 4.190521289017162
Validation loss: 5.442855449402964

Epoch: 5| Step: 3
Training loss: 5.0567273795184455
Validation loss: 5.429887435913602

Epoch: 5| Step: 4
Training loss: 6.214321687591111
Validation loss: 5.404947160294428

Epoch: 5| Step: 5
Training loss: 6.1410657418761545
Validation loss: 5.391988527192777

Epoch: 5| Step: 6
Training loss: 6.045898989586673
Validation loss: 5.379447323865474

Epoch: 5| Step: 7
Training loss: 4.943074037658394
Validation loss: 5.356807020201356

Epoch: 5| Step: 8
Training loss: 5.405034275846111
Validation loss: 5.344066519107534

Epoch: 5| Step: 9
Training loss: 4.4445506215658215
Validation loss: 5.33448829886435

Epoch: 5| Step: 10
Training loss: 5.327421169834499
Validation loss: 5.311959656965954

Epoch: 14| Step: 0
Training loss: 5.4490118828341325
Validation loss: 5.3075225231456375

Epoch: 5| Step: 1
Training loss: 6.274335557023461
Validation loss: 5.287618000838709

Epoch: 5| Step: 2
Training loss: 4.357413120508911
Validation loss: 5.262548401390559

Epoch: 5| Step: 3
Training loss: 5.631344586762419
Validation loss: 5.245682135655798

Epoch: 5| Step: 4
Training loss: 4.329287156064273
Validation loss: 5.231094512234128

Epoch: 5| Step: 5
Training loss: 6.065839024914185
Validation loss: 5.2242981022552035

Epoch: 5| Step: 6
Training loss: 5.874737023494315
Validation loss: 5.197158732899662

Epoch: 5| Step: 7
Training loss: 4.4503447838418495
Validation loss: 5.175066837994585

Epoch: 5| Step: 8
Training loss: 5.064067456632293
Validation loss: 5.165587418034276

Epoch: 5| Step: 9
Training loss: 4.3947729968228755
Validation loss: 5.15173770457151

Epoch: 5| Step: 10
Training loss: 5.438437545452831
Validation loss: 5.133817007954132

Epoch: 15| Step: 0
Training loss: 5.91573158002906
Validation loss: 5.119645467690872

Epoch: 5| Step: 1
Training loss: 4.32341281234481
Validation loss: 5.09488695336297

Epoch: 5| Step: 2
Training loss: 4.7116846406258945
Validation loss: 5.071896492931212

Epoch: 5| Step: 3
Training loss: 4.78184994193539
Validation loss: 5.058072164054473

Epoch: 5| Step: 4
Training loss: 5.266374936454247
Validation loss: 5.029200630832156

Epoch: 5| Step: 5
Training loss: 4.547051600012235
Validation loss: 5.0188467086395

Epoch: 5| Step: 6
Training loss: 5.370837174269449
Validation loss: 5.00129629169402

Epoch: 5| Step: 7
Training loss: 5.885644886914541
Validation loss: 4.986174355443609

Epoch: 5| Step: 8
Training loss: 4.923327809827664
Validation loss: 4.949572347706822

Epoch: 5| Step: 9
Training loss: 4.838573224389429
Validation loss: 4.942967793537556

Epoch: 5| Step: 10
Training loss: 4.84051523792196
Validation loss: 4.925315184642883

Epoch: 16| Step: 0
Training loss: 4.459992049684837
Validation loss: 4.903724695088396

Epoch: 5| Step: 1
Training loss: 5.20120341240908
Validation loss: 4.874920653230441

Epoch: 5| Step: 2
Training loss: 4.793978832607143
Validation loss: 4.852946284044326

Epoch: 5| Step: 3
Training loss: 5.214462437779627
Validation loss: 4.823529603739823

Epoch: 5| Step: 4
Training loss: 5.4198548348894375
Validation loss: 4.8132925927065635

Epoch: 5| Step: 5
Training loss: 4.649522260509843
Validation loss: 4.802299252107046

Epoch: 5| Step: 6
Training loss: 4.994532838651398
Validation loss: 4.76790409713208

Epoch: 5| Step: 7
Training loss: 5.211126000971196
Validation loss: 4.740335443431779

Epoch: 5| Step: 8
Training loss: 3.370438919915093
Validation loss: 4.717895930346412

Epoch: 5| Step: 9
Training loss: 5.023809962013275
Validation loss: 4.710705480370315

Epoch: 5| Step: 10
Training loss: 4.686326960971869
Validation loss: 4.669534388078317

Epoch: 17| Step: 0
Training loss: 4.125091089341098
Validation loss: 4.655852933015172

Epoch: 5| Step: 1
Training loss: 4.404089648326106
Validation loss: 4.6332545574240624

Epoch: 5| Step: 2
Training loss: 4.551136235484008
Validation loss: 4.62254458109381

Epoch: 5| Step: 3
Training loss: 5.1863801046083715
Validation loss: 4.589680010323598

Epoch: 5| Step: 4
Training loss: 5.029475118200667
Validation loss: 4.567378603922105

Epoch: 5| Step: 5
Training loss: 4.5102934200137295
Validation loss: 4.552812719430093

Epoch: 5| Step: 6
Training loss: 4.732393460694206
Validation loss: 4.527228454052108

Epoch: 5| Step: 7
Training loss: 4.317831089067832
Validation loss: 4.507726698956521

Epoch: 5| Step: 8
Training loss: 4.469715787654972
Validation loss: 4.480049866209827

Epoch: 5| Step: 9
Training loss: 4.117506213944917
Validation loss: 4.446617630525846

Epoch: 5| Step: 10
Training loss: 5.201699368024609
Validation loss: 4.42857151022988

Epoch: 18| Step: 0
Training loss: 4.606350802142879
Validation loss: 4.393385164544967

Epoch: 5| Step: 1
Training loss: 4.573332794419267
Validation loss: 4.382868550020268

Epoch: 5| Step: 2
Training loss: 4.6094600346367125
Validation loss: 4.353947323016326

Epoch: 5| Step: 3
Training loss: 4.642623522403724
Validation loss: 4.325243743585398

Epoch: 5| Step: 4
Training loss: 4.817172865794346
Validation loss: 4.302003160082361

Epoch: 5| Step: 5
Training loss: 4.837008208281481
Validation loss: 4.276407770402582

Epoch: 5| Step: 6
Training loss: 2.9406450358082212
Validation loss: 4.245146296751119

Epoch: 5| Step: 7
Training loss: 4.721541431694837
Validation loss: 4.233954196625585

Epoch: 5| Step: 8
Training loss: 4.181938007583037
Validation loss: 4.199810018310282

Epoch: 5| Step: 9
Training loss: 3.636002516154981
Validation loss: 4.188223212965247

Epoch: 5| Step: 10
Training loss: 4.103754994357112
Validation loss: 4.141833032588694

Epoch: 19| Step: 0
Training loss: 4.501831953358465
Validation loss: 4.132566580442162

Epoch: 5| Step: 1
Training loss: 3.2773740128221367
Validation loss: 4.111370880720712

Epoch: 5| Step: 2
Training loss: 4.376798641503468
Validation loss: 4.079801576986269

Epoch: 5| Step: 3
Training loss: 3.269159475904172
Validation loss: 4.054555012839106

Epoch: 5| Step: 4
Training loss: 4.299796370186993
Validation loss: 4.018999808408781

Epoch: 5| Step: 5
Training loss: 3.200380368276238
Validation loss: 3.9895796804583536

Epoch: 5| Step: 6
Training loss: 4.827305400132403
Validation loss: 3.9719779307604246

Epoch: 5| Step: 7
Training loss: 4.525644347116971
Validation loss: 3.9528529926262523

Epoch: 5| Step: 8
Training loss: 4.036772501214615
Validation loss: 3.9381755165410404

Epoch: 5| Step: 9
Training loss: 4.189653440723844
Validation loss: 3.9005718244261227

Epoch: 5| Step: 10
Training loss: 4.177212732963293
Validation loss: 3.8579764686666835

Epoch: 20| Step: 0
Training loss: 3.515633273644778
Validation loss: 3.852234452446262

Epoch: 5| Step: 1
Training loss: 4.18072827652302
Validation loss: 3.819729297763815

Epoch: 5| Step: 2
Training loss: 3.4627010080541463
Validation loss: 3.7878144411380905

Epoch: 5| Step: 3
Training loss: 4.2230975320127975
Validation loss: 3.769644922141517

Epoch: 5| Step: 4
Training loss: 3.5744168586234353
Validation loss: 3.74576909791079

Epoch: 5| Step: 5
Training loss: 3.79382390008433
Validation loss: 3.692151618289384

Epoch: 5| Step: 6
Training loss: 3.917073262530427
Validation loss: 3.6881683783930193

Epoch: 5| Step: 7
Training loss: 3.8770185565952087
Validation loss: 3.6685189134819836

Epoch: 5| Step: 8
Training loss: 3.2681350917372187
Validation loss: 3.63782524648196

Epoch: 5| Step: 9
Training loss: 4.309690361849056
Validation loss: 3.6074662964920687

Epoch: 5| Step: 10
Training loss: 3.9663743245295944
Validation loss: 3.579114583023137

Epoch: 21| Step: 0
Training loss: 4.260969478989366
Validation loss: 3.574337738421664

Epoch: 5| Step: 1
Training loss: 3.2744008105812217
Validation loss: 3.5479115181427328

Epoch: 5| Step: 2
Training loss: 3.0834580129898144
Validation loss: 3.493387594605534

Epoch: 5| Step: 3
Training loss: 2.9081545916030858
Validation loss: 3.4920989067969517

Epoch: 5| Step: 4
Training loss: 4.248923894741545
Validation loss: 3.4572353989872413

Epoch: 5| Step: 5
Training loss: 3.7566847665435894
Validation loss: 3.420307388653751

Epoch: 5| Step: 6
Training loss: 3.30977172778965
Validation loss: 3.4089384868626147

Epoch: 5| Step: 7
Training loss: 3.1901975698486087
Validation loss: 3.3786535840652108

Epoch: 5| Step: 8
Training loss: 3.74199954777383
Validation loss: 3.3499835346829276

Epoch: 5| Step: 9
Training loss: 4.129933961058588
Validation loss: 3.3403730831609657

Epoch: 5| Step: 10
Training loss: 3.169239772288132
Validation loss: 3.300104730795594

Epoch: 22| Step: 0
Training loss: 3.6262558701844747
Validation loss: 3.2832824147358552

Epoch: 5| Step: 1
Training loss: 3.208379390105237
Validation loss: 3.2585190987697037

Epoch: 5| Step: 2
Training loss: 2.5530874858887636
Validation loss: 3.2337975494063693

Epoch: 5| Step: 3
Training loss: 3.7189682327476965
Validation loss: 3.2437674353491732

Epoch: 5| Step: 4
Training loss: 3.6560413268443437
Validation loss: 3.220133233228263

Epoch: 5| Step: 5
Training loss: 2.646430321173074
Validation loss: 3.1604326447407924

Epoch: 5| Step: 6
Training loss: 3.246725927460905
Validation loss: 3.1628722712711865

Epoch: 5| Step: 7
Training loss: 3.17964625976212
Validation loss: 3.1465988423016413

Epoch: 5| Step: 8
Training loss: 2.9582587935678784
Validation loss: 3.1282348100830926

Epoch: 5| Step: 9
Training loss: 3.7058216690166987
Validation loss: 3.1119793053392417

Epoch: 5| Step: 10
Training loss: 4.364392746047042
Validation loss: 3.0998754318857853

Epoch: 23| Step: 0
Training loss: 3.0264330472423997
Validation loss: 3.051411299211901

Epoch: 5| Step: 1
Training loss: 3.343733457720471
Validation loss: 3.043875900144007

Epoch: 5| Step: 2
Training loss: 3.7836449975074413
Validation loss: 3.029807266387763

Epoch: 5| Step: 3
Training loss: 3.2131524161961305
Validation loss: 3.0153921714240015

Epoch: 5| Step: 4
Training loss: 3.3602606027448787
Validation loss: 2.9872513701107692

Epoch: 5| Step: 5
Training loss: 2.916252070433155
Validation loss: 2.971613485598341

Epoch: 5| Step: 6
Training loss: 2.9649757888603125
Validation loss: 2.9675095864520276

Epoch: 5| Step: 7
Training loss: 3.469026984076019
Validation loss: 2.9340473088397974

Epoch: 5| Step: 8
Training loss: 2.8606882883696594
Validation loss: 2.925192986744298

Epoch: 5| Step: 9
Training loss: 2.8662046156233516
Validation loss: 2.921903137945432

Epoch: 5| Step: 10
Training loss: 3.314853623784788
Validation loss: 2.929579176564831

Epoch: 24| Step: 0
Training loss: 3.4133339111009744
Validation loss: 2.885296579908576

Epoch: 5| Step: 1
Training loss: 3.089256954295496
Validation loss: 2.8695458721056823

Epoch: 5| Step: 2
Training loss: 2.4995828280475165
Validation loss: 2.864353584331447

Epoch: 5| Step: 3
Training loss: 3.036584623577525
Validation loss: 2.85782683992634

Epoch: 5| Step: 4
Training loss: 2.951987072531247
Validation loss: 2.845907311422431

Epoch: 5| Step: 5
Training loss: 2.7295418013156336
Validation loss: 2.8376899235375594

Epoch: 5| Step: 6
Training loss: 3.2685189451754297
Validation loss: 2.824176884977169

Epoch: 5| Step: 7
Training loss: 3.1527536496785666
Validation loss: 2.8197154692386

Epoch: 5| Step: 8
Training loss: 2.6710793721564356
Validation loss: 2.7852180005939733

Epoch: 5| Step: 9
Training loss: 3.0425976586948384
Validation loss: 2.778688315460356

Epoch: 5| Step: 10
Training loss: 3.8262604824397384
Validation loss: 2.801446063546056

Epoch: 25| Step: 0
Training loss: 2.9349786204610546
Validation loss: 2.788254082026701

Epoch: 5| Step: 1
Training loss: 2.2519297271862864
Validation loss: 2.765841198977846

Epoch: 5| Step: 2
Training loss: 2.947573009360042
Validation loss: 2.7727054760493113

Epoch: 5| Step: 3
Training loss: 2.8888432140489115
Validation loss: 2.749818230939439

Epoch: 5| Step: 4
Training loss: 3.2434287027867645
Validation loss: 2.738935503392797

Epoch: 5| Step: 5
Training loss: 3.0157168675793873
Validation loss: 2.717337324654064

Epoch: 5| Step: 6
Training loss: 3.5899007334041704
Validation loss: 2.730986499341187

Epoch: 5| Step: 7
Training loss: 2.742204714990034
Validation loss: 2.7081575101539017

Epoch: 5| Step: 8
Training loss: 3.4381105747693486
Validation loss: 2.7212043954542215

Epoch: 5| Step: 9
Training loss: 3.278979433200527
Validation loss: 2.7069667990852166

Epoch: 5| Step: 10
Training loss: 2.6255252857519857
Validation loss: 2.6932099037992576

Epoch: 26| Step: 0
Training loss: 2.7630129618387276
Validation loss: 2.7113998901527765

Epoch: 5| Step: 1
Training loss: 3.4968440950202413
Validation loss: 2.6833872947573987

Epoch: 5| Step: 2
Training loss: 2.6944971592870997
Validation loss: 2.681132612606741

Epoch: 5| Step: 3
Training loss: 3.0298830076488206
Validation loss: 2.6943073126453574

Epoch: 5| Step: 4
Training loss: 3.2202125855872485
Validation loss: 2.696450026798521

Epoch: 5| Step: 5
Training loss: 2.649506569754336
Validation loss: 2.7147665935160123

Epoch: 5| Step: 6
Training loss: 2.898472047995753
Validation loss: 2.6922327414499767

Epoch: 5| Step: 7
Training loss: 2.544272936556886
Validation loss: 2.680292018337663

Epoch: 5| Step: 8
Training loss: 3.685893339156954
Validation loss: 2.675830095882884

Epoch: 5| Step: 9
Training loss: 2.801049808836982
Validation loss: 2.6671792647721833

Epoch: 5| Step: 10
Training loss: 3.0376649599846677
Validation loss: 2.673579653479531

Epoch: 27| Step: 0
Training loss: 3.2690915047857865
Validation loss: 2.683155733438822

Epoch: 5| Step: 1
Training loss: 2.427376878093054
Validation loss: 2.698840281373732

Epoch: 5| Step: 2
Training loss: 3.7479290648010233
Validation loss: 2.6628854063903953

Epoch: 5| Step: 3
Training loss: 2.6785666565625506
Validation loss: 2.6845906491192086

Epoch: 5| Step: 4
Training loss: 2.332630176407412
Validation loss: 2.6821198741848677

Epoch: 5| Step: 5
Training loss: 3.07145394032796
Validation loss: 2.658372087093612

Epoch: 5| Step: 6
Training loss: 3.2324786685437434
Validation loss: 2.6535191376139147

Epoch: 5| Step: 7
Training loss: 2.9263095760676707
Validation loss: 2.6733138053129046

Epoch: 5| Step: 8
Training loss: 2.6179877580745528
Validation loss: 2.6755683298639776

Epoch: 5| Step: 9
Training loss: 3.0329943484974677
Validation loss: 2.6384933964017527

Epoch: 5| Step: 10
Training loss: 3.3329773394904203
Validation loss: 2.673457465471215

Epoch: 28| Step: 0
Training loss: 3.0623425813037497
Validation loss: 2.6763125504199494

Epoch: 5| Step: 1
Training loss: 3.153366282279508
Validation loss: 2.6724247127370413

Epoch: 5| Step: 2
Training loss: 2.962919271553177
Validation loss: 2.6948035231758802

Epoch: 5| Step: 3
Training loss: 3.403753503187536
Validation loss: 2.642574581117822

Epoch: 5| Step: 4
Training loss: 2.9685498621889033
Validation loss: 2.6705513898182334

Epoch: 5| Step: 5
Training loss: 3.3022358053888414
Validation loss: 2.667534521291075

Epoch: 5| Step: 6
Training loss: 2.5055951449679696
Validation loss: 2.650426674869701

Epoch: 5| Step: 7
Training loss: 3.2480283772210794
Validation loss: 2.637258113384867

Epoch: 5| Step: 8
Training loss: 2.8887418644327103
Validation loss: 2.6382289247598125

Epoch: 5| Step: 9
Training loss: 2.758904519154838
Validation loss: 2.6515666550560537

Epoch: 5| Step: 10
Training loss: 2.6966676705275634
Validation loss: 2.670219043996312

Epoch: 29| Step: 0
Training loss: 2.978883814333294
Validation loss: 2.6589107392710805

Epoch: 5| Step: 1
Training loss: 2.7006123943250953
Validation loss: 2.6692907480396877

Epoch: 5| Step: 2
Training loss: 3.3907000977246513
Validation loss: 2.6704044292591202

Epoch: 5| Step: 3
Training loss: 2.5262067498341687
Validation loss: 2.6435723741102763

Epoch: 5| Step: 4
Training loss: 3.5122101199177473
Validation loss: 2.635019172115675

Epoch: 5| Step: 5
Training loss: 2.951622797853429
Validation loss: 2.657861154134609

Epoch: 5| Step: 6
Training loss: 3.2272110626640083
Validation loss: 2.6552320765407114

Epoch: 5| Step: 7
Training loss: 3.242940424623346
Validation loss: 2.6678427091704804

Epoch: 5| Step: 8
Training loss: 2.822340386796329
Validation loss: 2.6795173733801536

Epoch: 5| Step: 9
Training loss: 3.090150839571381
Validation loss: 2.639511435720653

Epoch: 5| Step: 10
Training loss: 2.337319772065523
Validation loss: 2.6726496461710676

Epoch: 30| Step: 0
Training loss: 3.125481987976499
Validation loss: 2.6402705494042453

Epoch: 5| Step: 1
Training loss: 2.977733952245641
Validation loss: 2.6484747564088824

Epoch: 5| Step: 2
Training loss: 2.79874114961575
Validation loss: 2.636127424880294

Epoch: 5| Step: 3
Training loss: 3.4272338153919715
Validation loss: 2.6456682752678504

Epoch: 5| Step: 4
Training loss: 3.4421923429132124
Validation loss: 2.6635743510911887

Epoch: 5| Step: 5
Training loss: 3.673566323199409
Validation loss: 2.6484332176428214

Epoch: 5| Step: 6
Training loss: 2.7263943420846197
Validation loss: 2.6176069349340687

Epoch: 5| Step: 7
Training loss: 2.4405395922693667
Validation loss: 2.661383038493976

Epoch: 5| Step: 8
Training loss: 2.5159076034367325
Validation loss: 2.6546754014862386

Epoch: 5| Step: 9
Training loss: 2.657287933414777
Validation loss: 2.6588382761249623

Epoch: 5| Step: 10
Training loss: 3.0372082856683087
Validation loss: 2.680162230680994

Epoch: 31| Step: 0
Training loss: 2.6884227321901566
Validation loss: 2.6414593667629527

Epoch: 5| Step: 1
Training loss: 3.0234632072045833
Validation loss: 2.6226395523690407

Epoch: 5| Step: 2
Training loss: 3.1721819649224257
Validation loss: 2.6435324505751163

Epoch: 5| Step: 3
Training loss: 2.957639603919376
Validation loss: 2.6523349591522

Epoch: 5| Step: 4
Training loss: 3.182697193302462
Validation loss: 2.6448881944731704

Epoch: 5| Step: 5
Training loss: 2.636883946647937
Validation loss: 2.661566318148016

Epoch: 5| Step: 6
Training loss: 2.862528411857497
Validation loss: 2.663859143722083

Epoch: 5| Step: 7
Training loss: 3.902259680650991
Validation loss: 2.618054735335493

Epoch: 5| Step: 8
Training loss: 2.5607794591283057
Validation loss: 2.643858508751601

Epoch: 5| Step: 9
Training loss: 2.789506123627859
Validation loss: 2.6501529815067126

Epoch: 5| Step: 10
Training loss: 2.824265939996267
Validation loss: 2.6822180481718183

Epoch: 32| Step: 0
Training loss: 2.1818047635070403
Validation loss: 2.6340019893785267

Epoch: 5| Step: 1
Training loss: 3.50428468835838
Validation loss: 2.667730918587793

Epoch: 5| Step: 2
Training loss: 3.371550174372036
Validation loss: 2.6499033232901215

Epoch: 5| Step: 3
Training loss: 2.760012346323014
Validation loss: 2.669044252508812

Epoch: 5| Step: 4
Training loss: 2.889784902203944
Validation loss: 2.6489573232421972

Epoch: 5| Step: 5
Training loss: 2.645252664681327
Validation loss: 2.653651626279334

Epoch: 5| Step: 6
Training loss: 3.7118787354853393
Validation loss: 2.6398386052794423

Epoch: 5| Step: 7
Training loss: 3.253578563369506
Validation loss: 2.6461625137045344

Epoch: 5| Step: 8
Training loss: 3.189574221235266
Validation loss: 2.6552604496932894

Epoch: 5| Step: 9
Training loss: 2.8200996297457106
Validation loss: 2.6617580723685434

Epoch: 5| Step: 10
Training loss: 1.9311570351949967
Validation loss: 2.632897451442182

Epoch: 33| Step: 0
Training loss: 2.9392764624549526
Validation loss: 2.612605355468931

Epoch: 5| Step: 1
Training loss: 2.7538912725379507
Validation loss: 2.650286898848514

Epoch: 5| Step: 2
Training loss: 3.5679209105189345
Validation loss: 2.6615004416455204

Epoch: 5| Step: 3
Training loss: 2.629676830612361
Validation loss: 2.636862438058922

Epoch: 5| Step: 4
Training loss: 2.9189154175765046
Validation loss: 2.6548583832805543

Epoch: 5| Step: 5
Training loss: 3.365164376901868
Validation loss: 2.615793217285782

Epoch: 5| Step: 6
Training loss: 3.2481575658566557
Validation loss: 2.6584219037869707

Epoch: 5| Step: 7
Training loss: 2.252901431775835
Validation loss: 2.6592335057918306

Epoch: 5| Step: 8
Training loss: 2.914299758375078
Validation loss: 2.6195136698492854

Epoch: 5| Step: 9
Training loss: 3.321157262711248
Validation loss: 2.6590555256268775

Epoch: 5| Step: 10
Training loss: 2.7801978875129896
Validation loss: 2.635260683425998

Epoch: 34| Step: 0
Training loss: 3.7430973101763874
Validation loss: 2.6540912346682894

Epoch: 5| Step: 1
Training loss: 2.7354997338037044
Validation loss: 2.6357739947346412

Epoch: 5| Step: 2
Training loss: 3.3484738930465845
Validation loss: 2.6571240091672172

Epoch: 5| Step: 3
Training loss: 2.9306726859149204
Validation loss: 2.626737314638167

Epoch: 5| Step: 4
Training loss: 2.9629570910166025
Validation loss: 2.6217811643655207

Epoch: 5| Step: 5
Training loss: 2.969838956583261
Validation loss: 2.649131043047433

Epoch: 5| Step: 6
Training loss: 2.596562894021607
Validation loss: 2.641553140565358

Epoch: 5| Step: 7
Training loss: 3.0713758495786543
Validation loss: 2.641943813712862

Epoch: 5| Step: 8
Training loss: 3.294516782161216
Validation loss: 2.6601428648861116

Epoch: 5| Step: 9
Training loss: 2.699089610299419
Validation loss: 2.6592701197706377

Epoch: 5| Step: 10
Training loss: 1.9349415407048955
Validation loss: 2.648209449038218

Epoch: 35| Step: 0
Training loss: 2.8430837332799253
Validation loss: 2.6227899087008226

Epoch: 5| Step: 1
Training loss: 2.166916270428296
Validation loss: 2.626402575432211

Epoch: 5| Step: 2
Training loss: 3.518984668556284
Validation loss: 2.630939810711219

Epoch: 5| Step: 3
Training loss: 2.7905431071159104
Validation loss: 2.6240921501532046

Epoch: 5| Step: 4
Training loss: 2.5872331122266417
Validation loss: 2.6331702200794713

Epoch: 5| Step: 5
Training loss: 3.650408128887274
Validation loss: 2.649442059628602

Epoch: 5| Step: 6
Training loss: 2.8630717410347097
Validation loss: 2.6236345340530747

Epoch: 5| Step: 7
Training loss: 2.7171403351036125
Validation loss: 2.6250137313116424

Epoch: 5| Step: 8
Training loss: 2.877667723539257
Validation loss: 2.650711160491777

Epoch: 5| Step: 9
Training loss: 3.4959187554405657
Validation loss: 2.660180668576273

Epoch: 5| Step: 10
Training loss: 2.670626878619454
Validation loss: 2.673798927756489

Epoch: 36| Step: 0
Training loss: 3.8109885800024617
Validation loss: 2.6516221597911787

Epoch: 5| Step: 1
Training loss: 2.724469887502469
Validation loss: 2.630027514447555

Epoch: 5| Step: 2
Training loss: 3.137297884445637
Validation loss: 2.6461404013898

Epoch: 5| Step: 3
Training loss: 2.966222229002509
Validation loss: 2.65040295378174

Epoch: 5| Step: 4
Training loss: 2.8883744009906076
Validation loss: 2.629055752577827

Epoch: 5| Step: 5
Training loss: 2.4680117698462976
Validation loss: 2.6523939466809208

Epoch: 5| Step: 6
Training loss: 2.9372918887176276
Validation loss: 2.634289171333983

Epoch: 5| Step: 7
Training loss: 3.640020099207123
Validation loss: 2.6497388899534853

Epoch: 5| Step: 8
Training loss: 2.2694300827615757
Validation loss: 2.6432451613919383

Epoch: 5| Step: 9
Training loss: 2.632207965211952
Validation loss: 2.6387054812114177

Epoch: 5| Step: 10
Training loss: 2.8469465127415257
Validation loss: 2.633249655448483

Epoch: 37| Step: 0
Training loss: 2.8497367134952443
Validation loss: 2.6195166361977553

Epoch: 5| Step: 1
Training loss: 3.0205957428904275
Validation loss: 2.6354064694775214

Epoch: 5| Step: 2
Training loss: 3.168194820366924
Validation loss: 2.626278066580481

Epoch: 5| Step: 3
Training loss: 2.2989884598530717
Validation loss: 2.6182198641059267

Epoch: 5| Step: 4
Training loss: 3.9468135584309842
Validation loss: 2.6409977096915656

Epoch: 5| Step: 5
Training loss: 2.7386390789627204
Validation loss: 2.648791928172717

Epoch: 5| Step: 6
Training loss: 1.8837375505285336
Validation loss: 2.655554611030086

Epoch: 5| Step: 7
Training loss: 2.940165994071231
Validation loss: 2.656320575546224

Epoch: 5| Step: 8
Training loss: 3.1708984375
Validation loss: 2.6290734713945403

Epoch: 5| Step: 9
Training loss: 3.2416178375201494
Validation loss: 2.6678533943375116

Epoch: 5| Step: 10
Training loss: 2.9366267103348447
Validation loss: 2.6587061568087673

Epoch: 38| Step: 0
Training loss: 2.3216848714004756
Validation loss: 2.639125032191102

Epoch: 5| Step: 1
Training loss: 3.476262111759313
Validation loss: 2.6629534686318195

Epoch: 5| Step: 2
Training loss: 3.6126808781203232
Validation loss: 2.640908421384109

Epoch: 5| Step: 3
Training loss: 2.561597711763903
Validation loss: 2.6467970033890693

Epoch: 5| Step: 4
Training loss: 2.390087491113964
Validation loss: 2.658119795344707

Epoch: 5| Step: 5
Training loss: 3.394272068958644
Validation loss: 2.638628484560578

Epoch: 5| Step: 6
Training loss: 2.9595410921724543
Validation loss: 2.657850179459229

Epoch: 5| Step: 7
Training loss: 3.144844522923869
Validation loss: 2.6472906931246767

Epoch: 5| Step: 8
Training loss: 2.752989617785059
Validation loss: 2.6604367292114115

Epoch: 5| Step: 9
Training loss: 2.6460389385284913
Validation loss: 2.6316659380130702

Epoch: 5| Step: 10
Training loss: 3.3182633842428833
Validation loss: 2.6152280541994815

Epoch: 39| Step: 0
Training loss: 2.7713823467720062
Validation loss: 2.6436891747237854

Epoch: 5| Step: 1
Training loss: 2.776070475950686
Validation loss: 2.641731833614293

Epoch: 5| Step: 2
Training loss: 2.552578676899875
Validation loss: 2.648976814508437

Epoch: 5| Step: 3
Training loss: 2.8622135602070995
Validation loss: 2.6325468830856478

Epoch: 5| Step: 4
Training loss: 2.513037636392712
Validation loss: 2.636107905709404

Epoch: 5| Step: 5
Training loss: 2.4433926489353563
Validation loss: 2.6354541901541917

Epoch: 5| Step: 6
Training loss: 2.734332972612287
Validation loss: 2.65659104823374

Epoch: 5| Step: 7
Training loss: 2.6811317577832674
Validation loss: 2.6501689157421673

Epoch: 5| Step: 8
Training loss: 3.973270995101227
Validation loss: 2.663549655630245

Epoch: 5| Step: 9
Training loss: 3.4387349077986924
Validation loss: 2.6674605317185844

Epoch: 5| Step: 10
Training loss: 3.610790156911777
Validation loss: 2.6151758383917176

Epoch: 40| Step: 0
Training loss: 3.2848380679742037
Validation loss: 2.6440520513794015

Epoch: 5| Step: 1
Training loss: 3.4755587725476755
Validation loss: 2.6532564187935566

Epoch: 5| Step: 2
Training loss: 3.0232121188907843
Validation loss: 2.6446388389845796

Epoch: 5| Step: 3
Training loss: 2.8373547420207914
Validation loss: 2.632688948184039

Epoch: 5| Step: 4
Training loss: 2.7429327753544244
Validation loss: 2.6442852977394153

Epoch: 5| Step: 5
Training loss: 2.9056745390136802
Validation loss: 2.6246495723478014

Epoch: 5| Step: 6
Training loss: 2.940265408946755
Validation loss: 2.6473049276220397

Epoch: 5| Step: 7
Training loss: 2.666185623729504
Validation loss: 2.643164438671244

Epoch: 5| Step: 8
Training loss: 3.193728476375308
Validation loss: 2.6371507880903553

Epoch: 5| Step: 9
Training loss: 2.150196257216899
Validation loss: 2.644389702348764

Epoch: 5| Step: 10
Training loss: 3.2996924054679893
Validation loss: 2.648309057733369

Epoch: 41| Step: 0
Training loss: 2.7521684073717947
Validation loss: 2.6489222308591054

Epoch: 5| Step: 1
Training loss: 2.7216977329976757
Validation loss: 2.620332032499959

Epoch: 5| Step: 2
Training loss: 3.1023641554411867
Validation loss: 2.6338908609856326

Epoch: 5| Step: 3
Training loss: 2.8041775805717704
Validation loss: 2.639505784948703

Epoch: 5| Step: 4
Training loss: 2.240591617692017
Validation loss: 2.642875345019106

Epoch: 5| Step: 5
Training loss: 3.4528742220165514
Validation loss: 2.6151641973770463

Epoch: 5| Step: 6
Training loss: 3.914530286417676
Validation loss: 2.6427072411126584

Epoch: 5| Step: 7
Training loss: 3.3231215139804453
Validation loss: 2.6354632649324223

Epoch: 5| Step: 8
Training loss: 3.1147858586802672
Validation loss: 2.6235007435064377

Epoch: 5| Step: 9
Training loss: 2.212027021812132
Validation loss: 2.645747953598452

Epoch: 5| Step: 10
Training loss: 2.623166215785036
Validation loss: 2.63548875955165

Epoch: 42| Step: 0
Training loss: 3.3498969218779004
Validation loss: 2.633831739385027

Epoch: 5| Step: 1
Training loss: 3.482584266492022
Validation loss: 2.6589540918350116

Epoch: 5| Step: 2
Training loss: 2.9168239732737478
Validation loss: 2.6051149885300853

Epoch: 5| Step: 3
Training loss: 3.2987477556447224
Validation loss: 2.633454760156759

Epoch: 5| Step: 4
Training loss: 2.6328970785167454
Validation loss: 2.637958559687006

Epoch: 5| Step: 5
Training loss: 2.901221077449007
Validation loss: 2.590859637277726

Epoch: 5| Step: 6
Training loss: 2.8309367833977217
Validation loss: 2.649880256354367

Epoch: 5| Step: 7
Training loss: 2.8937730298042488
Validation loss: 2.6485303743377457

Epoch: 5| Step: 8
Training loss: 3.0653604655791375
Validation loss: 2.622722499113716

Epoch: 5| Step: 9
Training loss: 2.34435732284386
Validation loss: 2.618756199563435

Epoch: 5| Step: 10
Training loss: 2.5457985130047387
Validation loss: 2.6171086835311717

Epoch: 43| Step: 0
Training loss: 3.340146413552083
Validation loss: 2.6476930063186623

Epoch: 5| Step: 1
Training loss: 2.1790343916106
Validation loss: 2.62236068791159

Epoch: 5| Step: 2
Training loss: 3.298437245566369
Validation loss: 2.620923239595966

Epoch: 5| Step: 3
Training loss: 3.585373911066086
Validation loss: 2.609829941648888

Epoch: 5| Step: 4
Training loss: 2.4630176290608343
Validation loss: 2.626623039643282

Epoch: 5| Step: 5
Training loss: 2.8087205712305057
Validation loss: 2.625316286345119

Epoch: 5| Step: 6
Training loss: 3.400057562172503
Validation loss: 2.638896400866982

Epoch: 5| Step: 7
Training loss: 2.695413957980612
Validation loss: 2.6423333143179413

Epoch: 5| Step: 8
Training loss: 3.051762968745644
Validation loss: 2.630984392001955

Epoch: 5| Step: 9
Training loss: 2.0085739888510368
Validation loss: 2.620145252088442

Epoch: 5| Step: 10
Training loss: 3.419234140765297
Validation loss: 2.6328936696057976

Epoch: 44| Step: 0
Training loss: 3.076343001192541
Validation loss: 2.6501020681189518

Epoch: 5| Step: 1
Training loss: 3.0143303340329006
Validation loss: 2.6563325139258347

Epoch: 5| Step: 2
Training loss: 2.5227320012603607
Validation loss: 2.628676325156515

Epoch: 5| Step: 3
Training loss: 3.0912628965806785
Validation loss: 2.6369048095102703

Epoch: 5| Step: 4
Training loss: 3.253564054119767
Validation loss: 2.6635485526161635

Epoch: 5| Step: 5
Training loss: 3.3318002672173916
Validation loss: 2.624074752340488

Epoch: 5| Step: 6
Training loss: 3.2015502035818035
Validation loss: 2.6361871203007476

Epoch: 5| Step: 7
Training loss: 3.4807786386138195
Validation loss: 2.6112049748167885

Epoch: 5| Step: 8
Training loss: 2.4811922234791717
Validation loss: 2.626641324366965

Epoch: 5| Step: 9
Training loss: 2.355386963495114
Validation loss: 2.635793198329646

Epoch: 5| Step: 10
Training loss: 2.555696993751577
Validation loss: 2.656837921418408

Epoch: 45| Step: 0
Training loss: 2.6068114519844947
Validation loss: 2.6284127169456992

Epoch: 5| Step: 1
Training loss: 2.984577112194499
Validation loss: 2.6332598058213104

Epoch: 5| Step: 2
Training loss: 2.7928517137027997
Validation loss: 2.626829512786644

Epoch: 5| Step: 3
Training loss: 3.2101941512862795
Validation loss: 2.6274446744138293

Epoch: 5| Step: 4
Training loss: 3.063020934349404
Validation loss: 2.638018070329598

Epoch: 5| Step: 5
Training loss: 3.6377809081792
Validation loss: 2.6098692638757974

Epoch: 5| Step: 6
Training loss: 2.9163017771310726
Validation loss: 2.614112956481832

Epoch: 5| Step: 7
Training loss: 2.59054201589092
Validation loss: 2.643263550324635

Epoch: 5| Step: 8
Training loss: 3.0170733674725105
Validation loss: 2.63019308944536

Epoch: 5| Step: 9
Training loss: 2.826656402833166
Validation loss: 2.637047048629696

Epoch: 5| Step: 10
Training loss: 2.640184264110331
Validation loss: 2.6516117896624163

Epoch: 46| Step: 0
Training loss: 2.273534294243936
Validation loss: 2.643093071479011

Epoch: 5| Step: 1
Training loss: 2.689042292003075
Validation loss: 2.601201400028851

Epoch: 5| Step: 2
Training loss: 3.7496070655953146
Validation loss: 2.6270861893469903

Epoch: 5| Step: 3
Training loss: 3.0419478264722906
Validation loss: 2.62599159103132

Epoch: 5| Step: 4
Training loss: 2.177182306354932
Validation loss: 2.636170328426038

Epoch: 5| Step: 5
Training loss: 3.3820694246030008
Validation loss: 2.59296819886494

Epoch: 5| Step: 6
Training loss: 3.0773054087125007
Validation loss: 2.630239939776404

Epoch: 5| Step: 7
Training loss: 3.3162183225335933
Validation loss: 2.625679660593744

Epoch: 5| Step: 8
Training loss: 2.940082470003167
Validation loss: 2.633830408814975

Epoch: 5| Step: 9
Training loss: 2.798737486538294
Validation loss: 2.65374348250543

Epoch: 5| Step: 10
Training loss: 2.914580352832578
Validation loss: 2.6098916957763483

Epoch: 47| Step: 0
Training loss: 2.3415570999341866
Validation loss: 2.6485977417189686

Epoch: 5| Step: 1
Training loss: 3.1087463356797143
Validation loss: 2.6236396991745443

Epoch: 5| Step: 2
Training loss: 2.9690092274775233
Validation loss: 2.6268603875952765

Epoch: 5| Step: 3
Training loss: 2.778487387194176
Validation loss: 2.617446275877379

Epoch: 5| Step: 4
Training loss: 2.447879406801013
Validation loss: 2.6490429840615284

Epoch: 5| Step: 5
Training loss: 2.771014119228266
Validation loss: 2.6285072127060665

Epoch: 5| Step: 6
Training loss: 3.618805690198506
Validation loss: 2.6303215503642066

Epoch: 5| Step: 7
Training loss: 2.9907122528518038
Validation loss: 2.6114121545495506

Epoch: 5| Step: 8
Training loss: 2.842749115588586
Validation loss: 2.640893861185209

Epoch: 5| Step: 9
Training loss: 3.465830906357083
Validation loss: 2.612570555893552

Epoch: 5| Step: 10
Training loss: 2.957142675358969
Validation loss: 2.6311013704499504

Epoch: 48| Step: 0
Training loss: 3.1217831648721224
Validation loss: 2.6518782405708716

Epoch: 5| Step: 1
Training loss: 3.652233036423573
Validation loss: 2.647574053582754

Epoch: 5| Step: 2
Training loss: 2.9239589175196654
Validation loss: 2.66310725451055

Epoch: 5| Step: 3
Training loss: 2.976836264528667
Validation loss: 2.6141962022090373

Epoch: 5| Step: 4
Training loss: 2.697195440286637
Validation loss: 2.6315261533392817

Epoch: 5| Step: 5
Training loss: 3.159077803370633
Validation loss: 2.640611909077959

Epoch: 5| Step: 6
Training loss: 2.232047088748439
Validation loss: 2.6231957430174795

Epoch: 5| Step: 7
Training loss: 3.2543402813956406
Validation loss: 2.6364055683026058

Epoch: 5| Step: 8
Training loss: 2.9812545040584424
Validation loss: 2.6310622681074882

Epoch: 5| Step: 9
Training loss: 3.03238648808333
Validation loss: 2.6457088642397224

Epoch: 5| Step: 10
Training loss: 2.133995761942208
Validation loss: 2.627277956283474

Epoch: 49| Step: 0
Training loss: 2.8040382250031923
Validation loss: 2.637204546063856

Epoch: 5| Step: 1
Training loss: 2.554679287305224
Validation loss: 2.6272832015741168

Epoch: 5| Step: 2
Training loss: 3.20681208095114
Validation loss: 2.6064753960239444

Epoch: 5| Step: 3
Training loss: 2.89135947304308
Validation loss: 2.6377873171540407

Epoch: 5| Step: 4
Training loss: 2.699194989465564
Validation loss: 2.6541719486400823

Epoch: 5| Step: 5
Training loss: 3.507316299380677
Validation loss: 2.6280515213473925

Epoch: 5| Step: 6
Training loss: 3.1312947770684247
Validation loss: 2.658121259389112

Epoch: 5| Step: 7
Training loss: 2.7374956035143243
Validation loss: 2.6433752128196573

Epoch: 5| Step: 8
Training loss: 2.982157577465265
Validation loss: 2.611032568744411

Epoch: 5| Step: 9
Training loss: 3.0213145607176832
Validation loss: 2.6758848693152224

Epoch: 5| Step: 10
Training loss: 2.749276152626964
Validation loss: 2.616486825269581

Epoch: 50| Step: 0
Training loss: 3.550295487047398
Validation loss: 2.6223403780279444

Epoch: 5| Step: 1
Training loss: 2.880178680175299
Validation loss: 2.6444549522881666

Epoch: 5| Step: 2
Training loss: 2.681972941501788
Validation loss: 2.641681898212965

Epoch: 5| Step: 3
Training loss: 2.79552149921543
Validation loss: 2.6107823766334453

Epoch: 5| Step: 4
Training loss: 2.6336730094124845
Validation loss: 2.6278887019765143

Epoch: 5| Step: 5
Training loss: 2.410239046674723
Validation loss: 2.6263669425337643

Epoch: 5| Step: 6
Training loss: 2.6038120384352332
Validation loss: 2.627926239952681

Epoch: 5| Step: 7
Training loss: 3.766511551580385
Validation loss: 2.6417190014630414

Epoch: 5| Step: 8
Training loss: 3.320252469586009
Validation loss: 2.6376329880785634

Epoch: 5| Step: 9
Training loss: 2.7998033250127485
Validation loss: 2.620105447111803

Epoch: 5| Step: 10
Training loss: 2.4858417140074724
Validation loss: 2.6452808318412098

Epoch: 51| Step: 0
Training loss: 2.4233838703215325
Validation loss: 2.6187106513962606

Epoch: 5| Step: 1
Training loss: 3.2500032278191604
Validation loss: 2.618639038720544

Epoch: 5| Step: 2
Training loss: 3.053235111183716
Validation loss: 2.6161216018698896

Epoch: 5| Step: 3
Training loss: 3.1016295303288888
Validation loss: 2.617285177936213

Epoch: 5| Step: 4
Training loss: 2.8300673416806297
Validation loss: 2.625085614434817

Epoch: 5| Step: 5
Training loss: 3.2509431204160086
Validation loss: 2.6315353205734096

Epoch: 5| Step: 6
Training loss: 2.832377066709597
Validation loss: 2.6185354117604143

Epoch: 5| Step: 7
Training loss: 3.09449250529977
Validation loss: 2.6222079028915912

Epoch: 5| Step: 8
Training loss: 3.1732661762130285
Validation loss: 2.6093700802615247

Epoch: 5| Step: 9
Training loss: 2.6700501930862375
Validation loss: 2.625178568831675

Epoch: 5| Step: 10
Training loss: 2.4133457737104993
Validation loss: 2.6348558726050597

Epoch: 52| Step: 0
Training loss: 2.9923664567384747
Validation loss: 2.6094054722064377

Epoch: 5| Step: 1
Training loss: 3.2951328682629533
Validation loss: 2.6254240680838166

Epoch: 5| Step: 2
Training loss: 2.997742439245851
Validation loss: 2.6304567940751156

Epoch: 5| Step: 3
Training loss: 2.587074329542615
Validation loss: 2.6193711921083502

Epoch: 5| Step: 4
Training loss: 2.6234307821254816
Validation loss: 2.6257511788836316

Epoch: 5| Step: 5
Training loss: 3.48447435177513
Validation loss: 2.631014964711348

Epoch: 5| Step: 6
Training loss: 3.0363479690168313
Validation loss: 2.6700178080922727

Epoch: 5| Step: 7
Training loss: 2.691484380952748
Validation loss: 2.6279556922407745

Epoch: 5| Step: 8
Training loss: 2.7610929608361445
Validation loss: 2.628043949575258

Epoch: 5| Step: 9
Training loss: 3.2115722919792553
Validation loss: 2.6129415354951693

Epoch: 5| Step: 10
Training loss: 2.521012029277908
Validation loss: 2.608593317739595

Epoch: 53| Step: 0
Training loss: 2.7830989563839426
Validation loss: 2.610869500075619

Epoch: 5| Step: 1
Training loss: 3.1523844398415584
Validation loss: 2.633973385283299

Epoch: 5| Step: 2
Training loss: 2.905677985227029
Validation loss: 2.623501900490994

Epoch: 5| Step: 3
Training loss: 3.146153684224714
Validation loss: 2.6211665426289983

Epoch: 5| Step: 4
Training loss: 2.8623105182152315
Validation loss: 2.6281583042279855

Epoch: 5| Step: 5
Training loss: 2.984313804438437
Validation loss: 2.6521715793985705

Epoch: 5| Step: 6
Training loss: 3.689837474603625
Validation loss: 2.627362387065569

Epoch: 5| Step: 7
Training loss: 2.325513463081622
Validation loss: 2.634323968170318

Epoch: 5| Step: 8
Training loss: 2.471670716690309
Validation loss: 2.6205829730130548

Epoch: 5| Step: 9
Training loss: 2.7647081137589673
Validation loss: 2.6355265093059983

Epoch: 5| Step: 10
Training loss: 2.9400978775340083
Validation loss: 2.5963624522576967

Epoch: 54| Step: 0
Training loss: 2.693199501520947
Validation loss: 2.6103924983006155

Epoch: 5| Step: 1
Training loss: 2.961468570963021
Validation loss: 2.6176131853511135

Epoch: 5| Step: 2
Training loss: 3.1176884375354894
Validation loss: 2.6212867680540364

Epoch: 5| Step: 3
Training loss: 3.0280836419429598
Validation loss: 2.634606076507764

Epoch: 5| Step: 4
Training loss: 2.5574727871548024
Validation loss: 2.6352887287738738

Epoch: 5| Step: 5
Training loss: 3.011838601346208
Validation loss: 2.629013126881713

Epoch: 5| Step: 6
Training loss: 2.5872073095516828
Validation loss: 2.617678924496287

Epoch: 5| Step: 7
Training loss: 3.3010544161652176
Validation loss: 2.6278948284324835

Epoch: 5| Step: 8
Training loss: 3.368142685085465
Validation loss: 2.6015447859681604

Epoch: 5| Step: 9
Training loss: 2.9749394194261116
Validation loss: 2.610185370226781

Epoch: 5| Step: 10
Training loss: 2.4582501952342817
Validation loss: 2.644362769532046

Epoch: 55| Step: 0
Training loss: 2.867372096301326
Validation loss: 2.6377662353053615

Epoch: 5| Step: 1
Training loss: 2.68922918712977
Validation loss: 2.6342864727011976

Epoch: 5| Step: 2
Training loss: 2.5229297044345222
Validation loss: 2.6382656830264906

Epoch: 5| Step: 3
Training loss: 2.850129904212478
Validation loss: 2.6163066862768103

Epoch: 5| Step: 4
Training loss: 1.980231637698853
Validation loss: 2.645911813324091

Epoch: 5| Step: 5
Training loss: 3.145102274919235
Validation loss: 2.635443354658796

Epoch: 5| Step: 6
Training loss: 3.512363124366162
Validation loss: 2.6301212845056128

Epoch: 5| Step: 7
Training loss: 3.0283418843455316
Validation loss: 2.606407200565279

Epoch: 5| Step: 8
Training loss: 3.141019729936069
Validation loss: 2.6513741724682243

Epoch: 5| Step: 9
Training loss: 3.018021970038207
Validation loss: 2.6237792210292126

Epoch: 5| Step: 10
Training loss: 3.1806603145606562
Validation loss: 2.6167543711900763

Epoch: 56| Step: 0
Training loss: 2.397367058370711
Validation loss: 2.6410972666573818

Epoch: 5| Step: 1
Training loss: 2.7643715986989448
Validation loss: 2.632829797229731

Epoch: 5| Step: 2
Training loss: 2.4229839124283252
Validation loss: 2.6064386064608382

Epoch: 5| Step: 3
Training loss: 3.3386395341371924
Validation loss: 2.619813777611974

Epoch: 5| Step: 4
Training loss: 3.0339863804289595
Validation loss: 2.6202281838667063

Epoch: 5| Step: 5
Training loss: 2.7594755091782197
Validation loss: 2.5913086644865784

Epoch: 5| Step: 6
Training loss: 3.368964839164163
Validation loss: 2.6004970647285126

Epoch: 5| Step: 7
Training loss: 2.5798162288421183
Validation loss: 2.6248605811250245

Epoch: 5| Step: 8
Training loss: 2.549490024957858
Validation loss: 2.6156927766003193

Epoch: 5| Step: 9
Training loss: 3.0492799315397585
Validation loss: 2.6159193159380125

Epoch: 5| Step: 10
Training loss: 3.7230889147997637
Validation loss: 2.64371906232258

Epoch: 57| Step: 0
Training loss: 3.7453551454308407
Validation loss: 2.6125960825617356

Epoch: 5| Step: 1
Training loss: 2.7266864912374107
Validation loss: 2.6227573682790553

Epoch: 5| Step: 2
Training loss: 3.223904380696112
Validation loss: 2.6375072170248837

Epoch: 5| Step: 3
Training loss: 2.567499819034024
Validation loss: 2.6221835393690203

Epoch: 5| Step: 4
Training loss: 3.0417352607691623
Validation loss: 2.6360250718626794

Epoch: 5| Step: 5
Training loss: 3.1642722731387525
Validation loss: 2.6362094376618557

Epoch: 5| Step: 6
Training loss: 2.977952047091321
Validation loss: 2.6120895090725127

Epoch: 5| Step: 7
Training loss: 2.259402866640152
Validation loss: 2.6343605892128963

Epoch: 5| Step: 8
Training loss: 2.629961683335053
Validation loss: 2.6339261108091376

Epoch: 5| Step: 9
Training loss: 2.602786855728167
Validation loss: 2.6176745585217676

Epoch: 5| Step: 10
Training loss: 2.8494418685239338
Validation loss: 2.6276611408456425

Epoch: 58| Step: 0
Training loss: 2.4937379612070387
Validation loss: 2.631117390832698

Epoch: 5| Step: 1
Training loss: 2.662852440373229
Validation loss: 2.6067213074030238

Epoch: 5| Step: 2
Training loss: 3.370906466589386
Validation loss: 2.645766847405096

Epoch: 5| Step: 3
Training loss: 2.604079486659222
Validation loss: 2.6060371057601177

Epoch: 5| Step: 4
Training loss: 3.080292069594828
Validation loss: 2.645790716643085

Epoch: 5| Step: 5
Training loss: 3.5759753303956994
Validation loss: 2.620726095060736

Epoch: 5| Step: 6
Training loss: 3.0979045369146587
Validation loss: 2.6264916677642365

Epoch: 5| Step: 7
Training loss: 3.141466929379297
Validation loss: 2.6308085993366834

Epoch: 5| Step: 8
Training loss: 2.6110416046883618
Validation loss: 2.617943937657685

Epoch: 5| Step: 9
Training loss: 3.241941879344516
Validation loss: 2.629935502496244

Epoch: 5| Step: 10
Training loss: 2.286176822048094
Validation loss: 2.6503629512900164

Epoch: 59| Step: 0
Training loss: 2.6536965157882118
Validation loss: 2.6221565143654084

Epoch: 5| Step: 1
Training loss: 2.9914143412518706
Validation loss: 2.6196553461824537

Epoch: 5| Step: 2
Training loss: 3.2945599133857293
Validation loss: 2.625000136727497

Epoch: 5| Step: 3
Training loss: 2.9894688459177643
Validation loss: 2.618278502049072

Epoch: 5| Step: 4
Training loss: 3.2617887752120187
Validation loss: 2.612023475161639

Epoch: 5| Step: 5
Training loss: 2.397033877124196
Validation loss: 2.6402473565578957

Epoch: 5| Step: 6
Training loss: 3.1125397032384727
Validation loss: 2.623072714110211

Epoch: 5| Step: 7
Training loss: 3.376734817535144
Validation loss: 2.6050758454840177

Epoch: 5| Step: 8
Training loss: 2.3719924153854794
Validation loss: 2.6133099314708317

Epoch: 5| Step: 9
Training loss: 1.9962082921438282
Validation loss: 2.655648701872955

Epoch: 5| Step: 10
Training loss: 3.48685165449424
Validation loss: 2.6344975085342077

Epoch: 60| Step: 0
Training loss: 2.785260084873038
Validation loss: 2.612102003908833

Epoch: 5| Step: 1
Training loss: 2.6030530354053596
Validation loss: 2.5985060653898135

Epoch: 5| Step: 2
Training loss: 3.2735151404593954
Validation loss: 2.6086325347803947

Epoch: 5| Step: 3
Training loss: 2.977819142441793
Validation loss: 2.6154191144287178

Epoch: 5| Step: 4
Training loss: 2.956475511784636
Validation loss: 2.5874943022615446

Epoch: 5| Step: 5
Training loss: 2.6873958478750892
Validation loss: 2.605681862026771

Epoch: 5| Step: 6
Training loss: 3.30357713735669
Validation loss: 2.592693168408477

Epoch: 5| Step: 7
Training loss: 3.3018633812334026
Validation loss: 2.6022392392220866

Epoch: 5| Step: 8
Training loss: 2.665453416281679
Validation loss: 2.6264145668358156

Epoch: 5| Step: 9
Training loss: 2.6660318115637285
Validation loss: 2.601143341999234

Epoch: 5| Step: 10
Training loss: 2.7048610338486636
Validation loss: 2.6199840128549488

Epoch: 61| Step: 0
Training loss: 2.6173737872426197
Validation loss: 2.6085643495250266

Epoch: 5| Step: 1
Training loss: 2.5905212160680016
Validation loss: 2.597753937967943

Epoch: 5| Step: 2
Training loss: 2.3692882520150382
Validation loss: 2.6114305310513695

Epoch: 5| Step: 3
Training loss: 3.530512639933813
Validation loss: 2.6026614742099072

Epoch: 5| Step: 4
Training loss: 2.8678031073411554
Validation loss: 2.5905341603108543

Epoch: 5| Step: 5
Training loss: 3.2969617787009367
Validation loss: 2.6312785772304785

Epoch: 5| Step: 6
Training loss: 2.868912430031451
Validation loss: 2.6138387679745447

Epoch: 5| Step: 7
Training loss: 2.5732455230054283
Validation loss: 2.62442470580862

Epoch: 5| Step: 8
Training loss: 3.317562337604465
Validation loss: 2.6465854120101304

Epoch: 5| Step: 9
Training loss: 3.267546020277129
Validation loss: 2.6414621347401375

Epoch: 5| Step: 10
Training loss: 2.517049634817665
Validation loss: 2.6107620660362696

Epoch: 62| Step: 0
Training loss: 2.876853345499
Validation loss: 2.5825568715008713

Epoch: 5| Step: 1
Training loss: 2.7239860012966313
Validation loss: 2.621837311398189

Epoch: 5| Step: 2
Training loss: 3.300119403644072
Validation loss: 2.5986091227417214

Epoch: 5| Step: 3
Training loss: 2.8422475346059555
Validation loss: 2.6394893764680845

Epoch: 5| Step: 4
Training loss: 2.3111944895257746
Validation loss: 2.6123434361645135

Epoch: 5| Step: 5
Training loss: 3.1081752283489537
Validation loss: 2.5996562607484552

Epoch: 5| Step: 6
Training loss: 2.7621008191888596
Validation loss: 2.6091288896999143

Epoch: 5| Step: 7
Training loss: 3.2747229189540374
Validation loss: 2.6091770398892815

Epoch: 5| Step: 8
Training loss: 2.269026419454255
Validation loss: 2.628461656976226

Epoch: 5| Step: 9
Training loss: 3.5938801617478
Validation loss: 2.608983830471157

Epoch: 5| Step: 10
Training loss: 2.8841447103862903
Validation loss: 2.594838240889311

Epoch: 63| Step: 0
Training loss: 1.9334408478055103
Validation loss: 2.6107107566241416

Epoch: 5| Step: 1
Training loss: 3.0710748012504494
Validation loss: 2.6130776905076507

Epoch: 5| Step: 2
Training loss: 3.2473864683960962
Validation loss: 2.642824530058792

Epoch: 5| Step: 3
Training loss: 2.9767520073265357
Validation loss: 2.626317486139343

Epoch: 5| Step: 4
Training loss: 2.895328633262947
Validation loss: 2.623135434319981

Epoch: 5| Step: 5
Training loss: 2.552443145507332
Validation loss: 2.6226094392081425

Epoch: 5| Step: 6
Training loss: 2.611676691454368
Validation loss: 2.614381651401944

Epoch: 5| Step: 7
Training loss: 3.319882497431638
Validation loss: 2.5982553612002355

Epoch: 5| Step: 8
Training loss: 2.7990858833790253
Validation loss: 2.6174442014153096

Epoch: 5| Step: 9
Training loss: 3.3515522563217583
Validation loss: 2.5945158024488872

Epoch: 5| Step: 10
Training loss: 3.3411370166038843
Validation loss: 2.609013869002694

Epoch: 64| Step: 0
Training loss: 2.4350606988316796
Validation loss: 2.639085888449179

Epoch: 5| Step: 1
Training loss: 2.6129691218388613
Validation loss: 2.590790662675507

Epoch: 5| Step: 2
Training loss: 2.66155431366589
Validation loss: 2.615375988099038

Epoch: 5| Step: 3
Training loss: 3.305219747189205
Validation loss: 2.5986740039304372

Epoch: 5| Step: 4
Training loss: 3.2954959244955377
Validation loss: 2.5904655184698413

Epoch: 5| Step: 5
Training loss: 3.0634667563897087
Validation loss: 2.613817196765308

Epoch: 5| Step: 6
Training loss: 2.357663879361962
Validation loss: 2.6249579022416367

Epoch: 5| Step: 7
Training loss: 2.8842644072023456
Validation loss: 2.6288096201974156

Epoch: 5| Step: 8
Training loss: 2.730622425038841
Validation loss: 2.6246382800543624

Epoch: 5| Step: 9
Training loss: 3.2568971367938166
Validation loss: 2.598138335135668

Epoch: 5| Step: 10
Training loss: 3.344221135397808
Validation loss: 2.6235581240487784

Epoch: 65| Step: 0
Training loss: 3.105526790436393
Validation loss: 2.602304228902783

Epoch: 5| Step: 1
Training loss: 3.188480002151667
Validation loss: 2.62223514636026

Epoch: 5| Step: 2
Training loss: 2.5117075491220895
Validation loss: 2.6244300276225743

Epoch: 5| Step: 3
Training loss: 2.5443820102626
Validation loss: 2.6106760790918115

Epoch: 5| Step: 4
Training loss: 2.6284173791478302
Validation loss: 2.6183242124340658

Epoch: 5| Step: 5
Training loss: 2.986307048037132
Validation loss: 2.6269749089246734

Epoch: 5| Step: 6
Training loss: 3.0446810134651026
Validation loss: 2.6171542443954463

Epoch: 5| Step: 7
Training loss: 3.211004029116127
Validation loss: 2.61483000218566

Epoch: 5| Step: 8
Training loss: 2.8121708147469806
Validation loss: 2.651334179795318

Epoch: 5| Step: 9
Training loss: 2.747496939632249
Validation loss: 2.6292115416534956

Epoch: 5| Step: 10
Training loss: 3.18334974980407
Validation loss: 2.589404560857062

Epoch: 66| Step: 0
Training loss: 3.129682770762153
Validation loss: 2.586904176231175

Epoch: 5| Step: 1
Training loss: 2.7825095078682036
Validation loss: 2.614517186237588

Epoch: 5| Step: 2
Training loss: 2.6133029634631373
Validation loss: 2.5745441277751158

Epoch: 5| Step: 3
Training loss: 2.9873457098666685
Validation loss: 2.6230578687231896

Epoch: 5| Step: 4
Training loss: 3.3689563468625456
Validation loss: 2.6123844030678405

Epoch: 5| Step: 5
Training loss: 2.6542566337089357
Validation loss: 2.601466218407794

Epoch: 5| Step: 6
Training loss: 3.464641990937334
Validation loss: 2.610022628749576

Epoch: 5| Step: 7
Training loss: 2.5941201371054663
Validation loss: 2.61955275374101

Epoch: 5| Step: 8
Training loss: 3.0800414340217124
Validation loss: 2.604377540828445

Epoch: 5| Step: 9
Training loss: 2.4026281669162777
Validation loss: 2.626031485438882

Epoch: 5| Step: 10
Training loss: 2.7227722756225283
Validation loss: 2.620703866925825

Epoch: 67| Step: 0
Training loss: 2.9069669105895746
Validation loss: 2.57928902508766

Epoch: 5| Step: 1
Training loss: 2.916804192343423
Validation loss: 2.6092266197526057

Epoch: 5| Step: 2
Training loss: 3.1007441827236146
Validation loss: 2.6194189582824565

Epoch: 5| Step: 3
Training loss: 2.4622195824843454
Validation loss: 2.609720064950981

Epoch: 5| Step: 4
Training loss: 2.4439114100231834
Validation loss: 2.5956309940993116

Epoch: 5| Step: 5
Training loss: 3.3941348143975754
Validation loss: 2.5857410252794244

Epoch: 5| Step: 6
Training loss: 3.4151821788266576
Validation loss: 2.60674905890303

Epoch: 5| Step: 7
Training loss: 2.3965327251005832
Validation loss: 2.595465456414807

Epoch: 5| Step: 8
Training loss: 3.4501808008557684
Validation loss: 2.584242719890173

Epoch: 5| Step: 9
Training loss: 2.5563705453220655
Validation loss: 2.6053755568368304

Epoch: 5| Step: 10
Training loss: 2.8683909870968427
Validation loss: 2.6056820283000444

Epoch: 68| Step: 0
Training loss: 2.971708730705512
Validation loss: 2.592933509470348

Epoch: 5| Step: 1
Training loss: 2.9894111043164258
Validation loss: 2.6229942401464967

Epoch: 5| Step: 2
Training loss: 2.677371344801211
Validation loss: 2.6021314715255013

Epoch: 5| Step: 3
Training loss: 3.222184802163276
Validation loss: 2.6087465630480904

Epoch: 5| Step: 4
Training loss: 3.514636362727591
Validation loss: 2.6356046538982527

Epoch: 5| Step: 5
Training loss: 2.8887808200804788
Validation loss: 2.6002210322754618

Epoch: 5| Step: 6
Training loss: 2.414664480465693
Validation loss: 2.5843068973401566

Epoch: 5| Step: 7
Training loss: 2.2449606516900733
Validation loss: 2.60683560218969

Epoch: 5| Step: 8
Training loss: 3.2008097398983013
Validation loss: 2.602991273169634

Epoch: 5| Step: 9
Training loss: 2.7176488641500245
Validation loss: 2.5980249010548744

Epoch: 5| Step: 10
Training loss: 2.7802547431427174
Validation loss: 2.6037645353527576

Epoch: 69| Step: 0
Training loss: 2.5957110241955617
Validation loss: 2.6495647745953

Epoch: 5| Step: 1
Training loss: 2.879281546200378
Validation loss: 2.590209706419042

Epoch: 5| Step: 2
Training loss: 2.3732704088713255
Validation loss: 2.612561305432162

Epoch: 5| Step: 3
Training loss: 2.2479404984402027
Validation loss: 2.614340112232002

Epoch: 5| Step: 4
Training loss: 2.540538933716716
Validation loss: 2.6412455463173385

Epoch: 5| Step: 5
Training loss: 3.3321026596520777
Validation loss: 2.612656213590532

Epoch: 5| Step: 6
Training loss: 3.1525257157344013
Validation loss: 2.602639571494706

Epoch: 5| Step: 7
Training loss: 3.1903174421160236
Validation loss: 2.613921666416489

Epoch: 5| Step: 8
Training loss: 3.3909717857111783
Validation loss: 2.616834568402675

Epoch: 5| Step: 9
Training loss: 2.7077937737998887
Validation loss: 2.5866546830952766

Epoch: 5| Step: 10
Training loss: 3.5149597894965092
Validation loss: 2.629335973995182

Epoch: 70| Step: 0
Training loss: 3.5484008195896983
Validation loss: 2.613507147912018

Epoch: 5| Step: 1
Training loss: 3.1113540255611363
Validation loss: 2.617170718461735

Epoch: 5| Step: 2
Training loss: 3.073571879906528
Validation loss: 2.618586887013289

Epoch: 5| Step: 3
Training loss: 2.7026851053567156
Validation loss: 2.6160761871641

Epoch: 5| Step: 4
Training loss: 2.837251048993488
Validation loss: 2.629027703147459

Epoch: 5| Step: 5
Training loss: 2.614466559448105
Validation loss: 2.608340696924451

Epoch: 5| Step: 6
Training loss: 2.8298231895937938
Validation loss: 2.612094814796973

Epoch: 5| Step: 7
Training loss: 3.132384615856238
Validation loss: 2.6259785814086496

Epoch: 5| Step: 8
Training loss: 2.8823648741018295
Validation loss: 2.606524319122282

Epoch: 5| Step: 9
Training loss: 2.7522967024590024
Validation loss: 2.599621575789787

Epoch: 5| Step: 10
Training loss: 2.230685195174775
Validation loss: 2.631166150969222

Epoch: 71| Step: 0
Training loss: 2.6392444861787068
Validation loss: 2.601543727615978

Epoch: 5| Step: 1
Training loss: 2.1246426225723525
Validation loss: 2.6108961450677586

Epoch: 5| Step: 2
Training loss: 3.068445778740487
Validation loss: 2.6196197252409226

Epoch: 5| Step: 3
Training loss: 2.725764466592381
Validation loss: 2.597908383177373

Epoch: 5| Step: 4
Training loss: 3.099649987919188
Validation loss: 2.6354396484597338

Epoch: 5| Step: 5
Training loss: 3.1583341761229775
Validation loss: 2.6047946253209835

Epoch: 5| Step: 6
Training loss: 2.618408647017008
Validation loss: 2.575465381039084

Epoch: 5| Step: 7
Training loss: 2.9172906662240212
Validation loss: 2.6117178361775206

Epoch: 5| Step: 8
Training loss: 3.4284875808408555
Validation loss: 2.592819192143251

Epoch: 5| Step: 9
Training loss: 2.871754846560318
Validation loss: 2.596133838052109

Epoch: 5| Step: 10
Training loss: 3.1680759171916706
Validation loss: 2.610962028788562

Epoch: 72| Step: 0
Training loss: 2.6864238624880685
Validation loss: 2.6012558299794524

Epoch: 5| Step: 1
Training loss: 3.1720520872094338
Validation loss: 2.6396080505885373

Epoch: 5| Step: 2
Training loss: 2.674115050631912
Validation loss: 2.6194518602087955

Epoch: 5| Step: 3
Training loss: 2.8326784012748125
Validation loss: 2.596776295637318

Epoch: 5| Step: 4
Training loss: 2.4726058207547603
Validation loss: 2.5998890675621813

Epoch: 5| Step: 5
Training loss: 2.5818261600363788
Validation loss: 2.6111134522412356

Epoch: 5| Step: 6
Training loss: 3.9222841087432343
Validation loss: 2.5844693902869786

Epoch: 5| Step: 7
Training loss: 3.0050922726191898
Validation loss: 2.6233441901912324

Epoch: 5| Step: 8
Training loss: 3.3610853942083416
Validation loss: 2.5799972621988734

Epoch: 5| Step: 9
Training loss: 2.696251835439992
Validation loss: 2.6079836092940982

Epoch: 5| Step: 10
Training loss: 2.311976193051375
Validation loss: 2.6137604257802907

Epoch: 73| Step: 0
Training loss: 2.2270087614739285
Validation loss: 2.59483061912915

Epoch: 5| Step: 1
Training loss: 3.4142260479544646
Validation loss: 2.623026690644694

Epoch: 5| Step: 2
Training loss: 3.1416102140365023
Validation loss: 2.5923082990621986

Epoch: 5| Step: 3
Training loss: 3.0258013333836784
Validation loss: 2.601305305568044

Epoch: 5| Step: 4
Training loss: 2.3883314911683726
Validation loss: 2.6018648487698517

Epoch: 5| Step: 5
Training loss: 3.215363137247505
Validation loss: 2.59494434943114

Epoch: 5| Step: 6
Training loss: 2.5353644569139018
Validation loss: 2.6355952250581134

Epoch: 5| Step: 7
Training loss: 2.537960999053146
Validation loss: 2.5984530330790068

Epoch: 5| Step: 8
Training loss: 2.8839208441676765
Validation loss: 2.6151627504565704

Epoch: 5| Step: 9
Training loss: 3.7730007511222086
Validation loss: 2.583431524527044

Epoch: 5| Step: 10
Training loss: 2.4852649366349926
Validation loss: 2.6139137663494023

Epoch: 74| Step: 0
Training loss: 2.996815899056349
Validation loss: 2.614332932216509

Epoch: 5| Step: 1
Training loss: 2.5531047619469267
Validation loss: 2.585706274619091

Epoch: 5| Step: 2
Training loss: 2.5894059721733105
Validation loss: 2.5844401496906517

Epoch: 5| Step: 3
Training loss: 2.8604542514214586
Validation loss: 2.5901908369095104

Epoch: 5| Step: 4
Training loss: 3.001616519281036
Validation loss: 2.5859330387967376

Epoch: 5| Step: 5
Training loss: 3.241578414879395
Validation loss: 2.608577227821078

Epoch: 5| Step: 6
Training loss: 2.8127531149666147
Validation loss: 2.594371888633324

Epoch: 5| Step: 7
Training loss: 3.358141295540649
Validation loss: 2.6053734412763347

Epoch: 5| Step: 8
Training loss: 2.737511019053121
Validation loss: 2.5797010609208404

Epoch: 5| Step: 9
Training loss: 2.5595787889441386
Validation loss: 2.5789021374455743

Epoch: 5| Step: 10
Training loss: 2.999480997332194
Validation loss: 2.593293346616913

Epoch: 75| Step: 0
Training loss: 3.1748450894749314
Validation loss: 2.581718252223738

Epoch: 5| Step: 1
Training loss: 2.916797980122748
Validation loss: 2.6085706039191145

Epoch: 5| Step: 2
Training loss: 2.8519882093402527
Validation loss: 2.6066902727368935

Epoch: 5| Step: 3
Training loss: 3.269555605634717
Validation loss: 2.5938535418342243

Epoch: 5| Step: 4
Training loss: 2.343730265216394
Validation loss: 2.5983697042700875

Epoch: 5| Step: 5
Training loss: 3.3339406096094932
Validation loss: 2.6174546716532485

Epoch: 5| Step: 6
Training loss: 2.776535753626849
Validation loss: 2.5974065203692662

Epoch: 5| Step: 7
Training loss: 3.0987956199350126
Validation loss: 2.5758853415810323

Epoch: 5| Step: 8
Training loss: 2.2957391330711463
Validation loss: 2.5911261191040436

Epoch: 5| Step: 9
Training loss: 2.5641743841872326
Validation loss: 2.617712337965049

Epoch: 5| Step: 10
Training loss: 2.971462576535333
Validation loss: 2.6340709867567917

Epoch: 76| Step: 0
Training loss: 3.09895949590752
Validation loss: 2.6208313066201567

Epoch: 5| Step: 1
Training loss: 2.9047859359896626
Validation loss: 2.57617731042553

Epoch: 5| Step: 2
Training loss: 3.229967292879872
Validation loss: 2.598795845018679

Epoch: 5| Step: 3
Training loss: 2.6459913632114245
Validation loss: 2.615665454208373

Epoch: 5| Step: 4
Training loss: 2.9011988891149225
Validation loss: 2.6020783362547566

Epoch: 5| Step: 5
Training loss: 3.102158496391014
Validation loss: 2.6166098875437074

Epoch: 5| Step: 6
Training loss: 2.824357700754981
Validation loss: 2.611817709263522

Epoch: 5| Step: 7
Training loss: 2.5310723513206077
Validation loss: 2.592226540021052

Epoch: 5| Step: 8
Training loss: 2.7920663082588772
Validation loss: 2.579551290809982

Epoch: 5| Step: 9
Training loss: 2.951787736658101
Validation loss: 2.616993050598047

Epoch: 5| Step: 10
Training loss: 2.921651903090865
Validation loss: 2.614215096048671

Epoch: 77| Step: 0
Training loss: 2.7705759679447217
Validation loss: 2.5966631713001815

Epoch: 5| Step: 1
Training loss: 3.6148261319422215
Validation loss: 2.6153358595951586

Epoch: 5| Step: 2
Training loss: 3.1065113164946427
Validation loss: 2.6325918899826575

Epoch: 5| Step: 3
Training loss: 2.251337077962969
Validation loss: 2.6016554883125913

Epoch: 5| Step: 4
Training loss: 2.4585311508330943
Validation loss: 2.6117311877541374

Epoch: 5| Step: 5
Training loss: 2.177305389712431
Validation loss: 2.584597450639375

Epoch: 5| Step: 6
Training loss: 2.95100722494246
Validation loss: 2.588261683232706

Epoch: 5| Step: 7
Training loss: 3.2755756542009595
Validation loss: 2.600874555897538

Epoch: 5| Step: 8
Training loss: 2.8417205275934156
Validation loss: 2.6040453361221165

Epoch: 5| Step: 9
Training loss: 2.5547645860526806
Validation loss: 2.6018441916864115

Epoch: 5| Step: 10
Training loss: 3.3923959633737413
Validation loss: 2.5936267120241543

Epoch: 78| Step: 0
Training loss: 3.786179663029062
Validation loss: 2.6016431448179413

Epoch: 5| Step: 1
Training loss: 3.2578829019015463
Validation loss: 2.583461430483488

Epoch: 5| Step: 2
Training loss: 2.2282473965234484
Validation loss: 2.584366377661758

Epoch: 5| Step: 3
Training loss: 2.625151402784747
Validation loss: 2.5738047896646106

Epoch: 5| Step: 4
Training loss: 2.605830086011808
Validation loss: 2.573028670290162

Epoch: 5| Step: 5
Training loss: 2.669289570564317
Validation loss: 2.590350870535184

Epoch: 5| Step: 6
Training loss: 2.8749255295106226
Validation loss: 2.582201534784207

Epoch: 5| Step: 7
Training loss: 3.115965639583567
Validation loss: 2.588792017084447

Epoch: 5| Step: 8
Training loss: 2.50721671849941
Validation loss: 2.5947666500965663

Epoch: 5| Step: 9
Training loss: 2.8506396328768604
Validation loss: 2.5914870332410262

Epoch: 5| Step: 10
Training loss: 2.961508019068879
Validation loss: 2.5993777463636047

Epoch: 79| Step: 0
Training loss: 3.162757585612454
Validation loss: 2.612501489177942

Epoch: 5| Step: 1
Training loss: 3.3808480917633785
Validation loss: 2.5898046226245066

Epoch: 5| Step: 2
Training loss: 3.3780927263071536
Validation loss: 2.6056291577836195

Epoch: 5| Step: 3
Training loss: 2.293847196842758
Validation loss: 2.610536997074698

Epoch: 5| Step: 4
Training loss: 3.3749464525284076
Validation loss: 2.5866839070821785

Epoch: 5| Step: 5
Training loss: 3.36032900016946
Validation loss: 2.577698602650657

Epoch: 5| Step: 6
Training loss: 3.155460674429503
Validation loss: 2.597226275056149

Epoch: 5| Step: 7
Training loss: 2.764827462412731
Validation loss: 2.5993557785011467

Epoch: 5| Step: 8
Training loss: 1.9834619659362143
Validation loss: 2.615289416685084

Epoch: 5| Step: 9
Training loss: 1.9781121372570052
Validation loss: 2.621733839210775

Epoch: 5| Step: 10
Training loss: 2.275398378809214
Validation loss: 2.593598605621595

Epoch: 80| Step: 0
Training loss: 3.093307001012775
Validation loss: 2.5753505600773554

Epoch: 5| Step: 1
Training loss: 2.6841358153749257
Validation loss: 2.5858850506336526

Epoch: 5| Step: 2
Training loss: 2.921307840227642
Validation loss: 2.6022214480275636

Epoch: 5| Step: 3
Training loss: 2.8875511528207167
Validation loss: 2.5795458853520343

Epoch: 5| Step: 4
Training loss: 2.637579973644516
Validation loss: 2.625344480890282

Epoch: 5| Step: 5
Training loss: 2.52508141792394
Validation loss: 2.589455715258198

Epoch: 5| Step: 6
Training loss: 3.6426303563195597
Validation loss: 2.5650261913287173

Epoch: 5| Step: 7
Training loss: 2.7501733898640657
Validation loss: 2.584581479150644

Epoch: 5| Step: 8
Training loss: 2.6538445744887196
Validation loss: 2.5808414212836

Epoch: 5| Step: 9
Training loss: 2.5078944492914013
Validation loss: 2.590288078983136

Epoch: 5| Step: 10
Training loss: 3.0416093759933034
Validation loss: 2.594659473127486

Epoch: 81| Step: 0
Training loss: 3.3579987301667877
Validation loss: 2.5984787369105877

Epoch: 5| Step: 1
Training loss: 3.8124549737991784
Validation loss: 2.5711798978601883

Epoch: 5| Step: 2
Training loss: 2.902927263011586
Validation loss: 2.6014767805455445

Epoch: 5| Step: 3
Training loss: 2.6419053444203775
Validation loss: 2.585268152167442

Epoch: 5| Step: 4
Training loss: 2.9939031637428806
Validation loss: 2.606992071059425

Epoch: 5| Step: 5
Training loss: 3.0467665432920406
Validation loss: 2.6101483933026928

Epoch: 5| Step: 6
Training loss: 2.426484674015062
Validation loss: 2.6237958283952705

Epoch: 5| Step: 7
Training loss: 2.230811097817179
Validation loss: 2.578188124076869

Epoch: 5| Step: 8
Training loss: 2.3000364798265083
Validation loss: 2.5965902436519226

Epoch: 5| Step: 9
Training loss: 2.3988662982556446
Validation loss: 2.5804684108661022

Epoch: 5| Step: 10
Training loss: 3.398236849769861
Validation loss: 2.5856279753568585

Epoch: 82| Step: 0
Training loss: 3.030714164644749
Validation loss: 2.578058510796467

Epoch: 5| Step: 1
Training loss: 2.9096059803794003
Validation loss: 2.6157328153413473

Epoch: 5| Step: 2
Training loss: 2.3834873932172345
Validation loss: 2.5668792271290446

Epoch: 5| Step: 3
Training loss: 3.050015283765177
Validation loss: 2.5898056808245173

Epoch: 5| Step: 4
Training loss: 2.9137024848824487
Validation loss: 2.60933776891786

Epoch: 5| Step: 5
Training loss: 3.203564720675339
Validation loss: 2.5722878959758613

Epoch: 5| Step: 6
Training loss: 3.2288304964044983
Validation loss: 2.61574645906979

Epoch: 5| Step: 7
Training loss: 2.002704103619417
Validation loss: 2.6040784470576788

Epoch: 5| Step: 8
Training loss: 3.1563998649445346
Validation loss: 2.597521735276906

Epoch: 5| Step: 9
Training loss: 2.3658614772382554
Validation loss: 2.6252753156832753

Epoch: 5| Step: 10
Training loss: 3.183934629948172
Validation loss: 2.5930957381669835

Epoch: 83| Step: 0
Training loss: 2.2221678078135243
Validation loss: 2.596283144796198

Epoch: 5| Step: 1
Training loss: 2.5000021934499657
Validation loss: 2.616205508815465

Epoch: 5| Step: 2
Training loss: 3.140162951134889
Validation loss: 2.5772968830438074

Epoch: 5| Step: 3
Training loss: 2.7640838639472562
Validation loss: 2.6165238301930933

Epoch: 5| Step: 4
Training loss: 3.0308301182596016
Validation loss: 2.5785012361876993

Epoch: 5| Step: 5
Training loss: 2.53699641750806
Validation loss: 2.597461889500749

Epoch: 5| Step: 6
Training loss: 3.0736420028596636
Validation loss: 2.5900009039042926

Epoch: 5| Step: 7
Training loss: 3.5138356720350368
Validation loss: 2.582779517999586

Epoch: 5| Step: 8
Training loss: 3.231284761518547
Validation loss: 2.6068890933551154

Epoch: 5| Step: 9
Training loss: 2.339958277273311
Validation loss: 2.601078307543292

Epoch: 5| Step: 10
Training loss: 3.0011764444904525
Validation loss: 2.589136840894502

Epoch: 84| Step: 0
Training loss: 3.0444636266186054
Validation loss: 2.5729041113980347

Epoch: 5| Step: 1
Training loss: 2.865573355938417
Validation loss: 2.602927405708559

Epoch: 5| Step: 2
Training loss: 2.517767331609616
Validation loss: 2.6127180191528345

Epoch: 5| Step: 3
Training loss: 2.2142486041778406
Validation loss: 2.60514482417798

Epoch: 5| Step: 4
Training loss: 3.1600869905594107
Validation loss: 2.576438629210076

Epoch: 5| Step: 5
Training loss: 2.5395760823731233
Validation loss: 2.5838060508868423

Epoch: 5| Step: 6
Training loss: 2.520614509437726
Validation loss: 2.600070164556469

Epoch: 5| Step: 7
Training loss: 3.118458118425988
Validation loss: 2.5825940628090334

Epoch: 5| Step: 8
Training loss: 3.2003188332032284
Validation loss: 2.5763747771717402

Epoch: 5| Step: 9
Training loss: 3.379630832488041
Validation loss: 2.6205442977572755

Epoch: 5| Step: 10
Training loss: 2.6549452325951726
Validation loss: 2.6067408430421493

Epoch: 85| Step: 0
Training loss: 3.2345495499397785
Validation loss: 2.6032181063552886

Epoch: 5| Step: 1
Training loss: 2.56971821973165
Validation loss: 2.5974375465338015

Epoch: 5| Step: 2
Training loss: 3.2899399264338336
Validation loss: 2.592852784584494

Epoch: 5| Step: 3
Training loss: 2.297869304907863
Validation loss: 2.597953314198333

Epoch: 5| Step: 4
Training loss: 2.9525840304155677
Validation loss: 2.605054906822631

Epoch: 5| Step: 5
Training loss: 2.857638639622849
Validation loss: 2.6286299121638774

Epoch: 5| Step: 6
Training loss: 2.5271446939699067
Validation loss: 2.581528769367351

Epoch: 5| Step: 7
Training loss: 2.6780353936213253
Validation loss: 2.58358071049483

Epoch: 5| Step: 8
Training loss: 3.230055278623929
Validation loss: 2.599648209840005

Epoch: 5| Step: 9
Training loss: 2.6610827296032578
Validation loss: 2.581022537682603

Epoch: 5| Step: 10
Training loss: 3.272294092891269
Validation loss: 2.6128352963590777

Epoch: 86| Step: 0
Training loss: 3.0905591134202437
Validation loss: 2.5809570766831165

Epoch: 5| Step: 1
Training loss: 3.0051198821821767
Validation loss: 2.6113226125340545

Epoch: 5| Step: 2
Training loss: 2.825810533898625
Validation loss: 2.5880428089446266

Epoch: 5| Step: 3
Training loss: 2.513934212891341
Validation loss: 2.6065913716147624

Epoch: 5| Step: 4
Training loss: 2.8006189956379335
Validation loss: 2.5748576521443085

Epoch: 5| Step: 5
Training loss: 2.8449851906228405
Validation loss: 2.6026289746750755

Epoch: 5| Step: 6
Training loss: 2.715309772698623
Validation loss: 2.6084924602617723

Epoch: 5| Step: 7
Training loss: 3.0816120979535073
Validation loss: 2.5700903051322608

Epoch: 5| Step: 8
Training loss: 3.045402601464194
Validation loss: 2.5787563541569423

Epoch: 5| Step: 9
Training loss: 2.770341289303975
Validation loss: 2.5899344394539314

Epoch: 5| Step: 10
Training loss: 2.9651901585550298
Validation loss: 2.573967739433365

Epoch: 87| Step: 0
Training loss: 3.270846923670305
Validation loss: 2.598332302668425

Epoch: 5| Step: 1
Training loss: 3.11605913969436
Validation loss: 2.616199763608715

Epoch: 5| Step: 2
Training loss: 2.159548020228391
Validation loss: 2.587403725443079

Epoch: 5| Step: 3
Training loss: 3.118035757959655
Validation loss: 2.585435881176443

Epoch: 5| Step: 4
Training loss: 3.0774154232498185
Validation loss: 2.580837729054011

Epoch: 5| Step: 5
Training loss: 3.5426955280709995
Validation loss: 2.5896761079970636

Epoch: 5| Step: 6
Training loss: 2.4617642421750126
Validation loss: 2.6001931016631326

Epoch: 5| Step: 7
Training loss: 2.71844200055848
Validation loss: 2.621601252259752

Epoch: 5| Step: 8
Training loss: 2.3264574056629037
Validation loss: 2.585372870597702

Epoch: 5| Step: 9
Training loss: 2.9946288664422998
Validation loss: 2.6263469554921426

Epoch: 5| Step: 10
Training loss: 2.824561049531073
Validation loss: 2.604284959300883

Epoch: 88| Step: 0
Training loss: 3.004163237493483
Validation loss: 2.6117074391371955

Epoch: 5| Step: 1
Training loss: 2.679509815964726
Validation loss: 2.6322440064956587

Epoch: 5| Step: 2
Training loss: 2.5401292643357567
Validation loss: 2.5994639462887847

Epoch: 5| Step: 3
Training loss: 2.8514315640422625
Validation loss: 2.5908698142057895

Epoch: 5| Step: 4
Training loss: 3.433512646581964
Validation loss: 2.5930612101462285

Epoch: 5| Step: 5
Training loss: 2.55998199307546
Validation loss: 2.590630348457634

Epoch: 5| Step: 6
Training loss: 2.651498471657609
Validation loss: 2.581798717556368

Epoch: 5| Step: 7
Training loss: 2.90623014709911
Validation loss: 2.571161039251017

Epoch: 5| Step: 8
Training loss: 3.121725426681117
Validation loss: 2.6028654533551023

Epoch: 5| Step: 9
Training loss: 2.838872562451912
Validation loss: 2.5788955248024954

Epoch: 5| Step: 10
Training loss: 2.6900717384670925
Validation loss: 2.6048293526104027

Epoch: 89| Step: 0
Training loss: 2.6416731339946082
Validation loss: 2.5820331176018314

Epoch: 5| Step: 1
Training loss: 2.6009367685753526
Validation loss: 2.60165129104814

Epoch: 5| Step: 2
Training loss: 3.161532975666328
Validation loss: 2.6091190080176423

Epoch: 5| Step: 3
Training loss: 3.507574060573101
Validation loss: 2.593940564778203

Epoch: 5| Step: 4
Training loss: 2.081845158890181
Validation loss: 2.616285405371918

Epoch: 5| Step: 5
Training loss: 2.5208930541811756
Validation loss: 2.570845465559088

Epoch: 5| Step: 6
Training loss: 2.6316975120136377
Validation loss: 2.6152566986355326

Epoch: 5| Step: 7
Training loss: 3.598237660631957
Validation loss: 2.568175831267533

Epoch: 5| Step: 8
Training loss: 2.656199735278092
Validation loss: 2.5892582277901797

Epoch: 5| Step: 9
Training loss: 3.1748665668954232
Validation loss: 2.58712721755896

Epoch: 5| Step: 10
Training loss: 2.713622420873325
Validation loss: 2.581725555712485

Epoch: 90| Step: 0
Training loss: 3.159266173226925
Validation loss: 2.60030019646527

Epoch: 5| Step: 1
Training loss: 2.5144649697937864
Validation loss: 2.5975551356398046

Epoch: 5| Step: 2
Training loss: 2.54863851141572
Validation loss: 2.5602579860964854

Epoch: 5| Step: 3
Training loss: 2.4021776095370697
Validation loss: 2.589687168644981

Epoch: 5| Step: 4
Training loss: 2.793241388845558
Validation loss: 2.602924241201416

Epoch: 5| Step: 5
Training loss: 2.9568445103891015
Validation loss: 2.5702155444929167

Epoch: 5| Step: 6
Training loss: 3.177901532654075
Validation loss: 2.608485758502723

Epoch: 5| Step: 7
Training loss: 3.2914431693258592
Validation loss: 2.596502469283647

Epoch: 5| Step: 8
Training loss: 2.5861862385681125
Validation loss: 2.583708208639924

Epoch: 5| Step: 9
Training loss: 3.3683791032487904
Validation loss: 2.581379534330462

Epoch: 5| Step: 10
Training loss: 2.268565407381581
Validation loss: 2.5747503912125804

Epoch: 91| Step: 0
Training loss: 3.1412697505064378
Validation loss: 2.566172867146601

Epoch: 5| Step: 1
Training loss: 3.047670231258785
Validation loss: 2.5889247108178313

Epoch: 5| Step: 2
Training loss: 2.473479557221995
Validation loss: 2.5690037938635157

Epoch: 5| Step: 3
Training loss: 2.7823410465871947
Validation loss: 2.556393771081535

Epoch: 5| Step: 4
Training loss: 2.8528406074569213
Validation loss: 2.6122421007821415

Epoch: 5| Step: 5
Training loss: 2.4881580268375467
Validation loss: 2.566615545671727

Epoch: 5| Step: 6
Training loss: 2.9607447256981665
Validation loss: 2.6019150152897144

Epoch: 5| Step: 7
Training loss: 3.3198786193995686
Validation loss: 2.5793519999176118

Epoch: 5| Step: 8
Training loss: 2.375136421702551
Validation loss: 2.581198678368913

Epoch: 5| Step: 9
Training loss: 3.3004353900717533
Validation loss: 2.565327713634968

Epoch: 5| Step: 10
Training loss: 2.707142925298397
Validation loss: 2.5953153958621513

Epoch: 92| Step: 0
Training loss: 2.9994204279230985
Validation loss: 2.571750558124643

Epoch: 5| Step: 1
Training loss: 2.4093714692996584
Validation loss: 2.594882831862437

Epoch: 5| Step: 2
Training loss: 2.722237290667222
Validation loss: 2.5844619834544087

Epoch: 5| Step: 3
Training loss: 3.0735956163949996
Validation loss: 2.577307920226124

Epoch: 5| Step: 4
Training loss: 2.4962716912256955
Validation loss: 2.576958968807578

Epoch: 5| Step: 5
Training loss: 3.1416754792458326
Validation loss: 2.5741528152127517

Epoch: 5| Step: 6
Training loss: 3.467491540217789
Validation loss: 2.5934247058662416

Epoch: 5| Step: 7
Training loss: 2.387293070668373
Validation loss: 2.5984265614085973

Epoch: 5| Step: 8
Training loss: 3.11770495563141
Validation loss: 2.5841201876628057

Epoch: 5| Step: 9
Training loss: 2.7217098216622064
Validation loss: 2.611102454864157

Epoch: 5| Step: 10
Training loss: 2.7401006425347743
Validation loss: 2.6049639889411997

Epoch: 93| Step: 0
Training loss: 2.8566611496980765
Validation loss: 2.595656446367149

Epoch: 5| Step: 1
Training loss: 3.5432317230306603
Validation loss: 2.60863713405892

Epoch: 5| Step: 2
Training loss: 2.6731228061869485
Validation loss: 2.5824412579670466

Epoch: 5| Step: 3
Training loss: 2.65386954959606
Validation loss: 2.5980816187143474

Epoch: 5| Step: 4
Training loss: 3.0083029607224088
Validation loss: 2.6042759363363692

Epoch: 5| Step: 5
Training loss: 2.8554305088389222
Validation loss: 2.593760619257293

Epoch: 5| Step: 6
Training loss: 2.697935470063853
Validation loss: 2.606455354805641

Epoch: 5| Step: 7
Training loss: 2.4850271076896018
Validation loss: 2.596526364868533

Epoch: 5| Step: 8
Training loss: 2.7257014010611256
Validation loss: 2.59605625027458

Epoch: 5| Step: 9
Training loss: 3.1339536952314693
Validation loss: 2.5738466005545866

Epoch: 5| Step: 10
Training loss: 2.6718537625366676
Validation loss: 2.6071852953346415

Epoch: 94| Step: 0
Training loss: 3.0238191427815178
Validation loss: 2.5786697945676296

Epoch: 5| Step: 1
Training loss: 2.8487531645063875
Validation loss: 2.562160154267511

Epoch: 5| Step: 2
Training loss: 2.5367279118359827
Validation loss: 2.5752387364147453

Epoch: 5| Step: 3
Training loss: 2.897702023537257
Validation loss: 2.6058668900687647

Epoch: 5| Step: 4
Training loss: 2.758380431573144
Validation loss: 2.5667683877539456

Epoch: 5| Step: 5
Training loss: 3.1091825339400563
Validation loss: 2.575111917018346

Epoch: 5| Step: 6
Training loss: 2.8422998776273327
Validation loss: 2.587813077365712

Epoch: 5| Step: 7
Training loss: 3.108488790461501
Validation loss: 2.5885201073185717

Epoch: 5| Step: 8
Training loss: 2.8735576826458806
Validation loss: 2.583017785141683

Epoch: 5| Step: 9
Training loss: 1.8050445599748703
Validation loss: 2.5863615869925143

Epoch: 5| Step: 10
Training loss: 3.3344423038801065
Validation loss: 2.570231391800718

Epoch: 95| Step: 0
Training loss: 2.6752608412728014
Validation loss: 2.5728902036147847

Epoch: 5| Step: 1
Training loss: 2.841273140903257
Validation loss: 2.599511894826292

Epoch: 5| Step: 2
Training loss: 3.295375247826386
Validation loss: 2.5989271905129594

Epoch: 5| Step: 3
Training loss: 3.0760106604581123
Validation loss: 2.5868765091445263

Epoch: 5| Step: 4
Training loss: 3.007604497678032
Validation loss: 2.567834927176102

Epoch: 5| Step: 5
Training loss: 2.587365991927714
Validation loss: 2.594234270614725

Epoch: 5| Step: 6
Training loss: 2.5583331026290477
Validation loss: 2.581104466880111

Epoch: 5| Step: 7
Training loss: 2.7624670415094594
Validation loss: 2.612342470018701

Epoch: 5| Step: 8
Training loss: 2.6160643943420503
Validation loss: 2.5997460606111167

Epoch: 5| Step: 9
Training loss: 2.731461373187498
Validation loss: 2.600191337811575

Epoch: 5| Step: 10
Training loss: 3.0122443506183276
Validation loss: 2.5880298522410765

Epoch: 96| Step: 0
Training loss: 2.7209305185561616
Validation loss: 2.5454860704647535

Epoch: 5| Step: 1
Training loss: 2.6370339438344472
Validation loss: 2.559988366162748

Epoch: 5| Step: 2
Training loss: 2.3480504572969054
Validation loss: 2.6067509343658473

Epoch: 5| Step: 3
Training loss: 2.0482626135433186
Validation loss: 2.6144990049878367

Epoch: 5| Step: 4
Training loss: 3.6482662838739937
Validation loss: 2.590751200294908

Epoch: 5| Step: 5
Training loss: 3.305281637544857
Validation loss: 2.591489790292309

Epoch: 5| Step: 6
Training loss: 2.6314597800528214
Validation loss: 2.6002699912164937

Epoch: 5| Step: 7
Training loss: 3.265239053944862
Validation loss: 2.5996105998151395

Epoch: 5| Step: 8
Training loss: 2.820980764242997
Validation loss: 2.5772503176698196

Epoch: 5| Step: 9
Training loss: 2.7515996268701226
Validation loss: 2.570048704953482

Epoch: 5| Step: 10
Training loss: 2.6303715922735975
Validation loss: 2.555366303754425

Epoch: 97| Step: 0
Training loss: 2.704497501568902
Validation loss: 2.5657391528594595

Epoch: 5| Step: 1
Training loss: 2.7659916176768933
Validation loss: 2.566500646428746

Epoch: 5| Step: 2
Training loss: 2.702778788539501
Validation loss: 2.599176079662332

Epoch: 5| Step: 3
Training loss: 2.588089430748152
Validation loss: 2.5612748901872653

Epoch: 5| Step: 4
Training loss: 2.749938530668428
Validation loss: 2.597132258026691

Epoch: 5| Step: 5
Training loss: 2.5620439635352956
Validation loss: 2.5620966968359937

Epoch: 5| Step: 6
Training loss: 2.9414469398227263
Validation loss: 2.593466304243772

Epoch: 5| Step: 7
Training loss: 2.6783558731539125
Validation loss: 2.5954922338619664

Epoch: 5| Step: 8
Training loss: 3.32759956904474
Validation loss: 2.5492632431523004

Epoch: 5| Step: 9
Training loss: 3.1545080533507575
Validation loss: 2.580393558107954

Epoch: 5| Step: 10
Training loss: 2.8806824296824445
Validation loss: 2.6025977316348525

Epoch: 98| Step: 0
Training loss: 2.668950583002251
Validation loss: 2.5810558913225075

Epoch: 5| Step: 1
Training loss: 2.9644381078524957
Validation loss: 2.5687358583853923

Epoch: 5| Step: 2
Training loss: 3.1399269656781
Validation loss: 2.5676301295588555

Epoch: 5| Step: 3
Training loss: 2.650306154955751
Validation loss: 2.582370853317293

Epoch: 5| Step: 4
Training loss: 3.0277154509713724
Validation loss: 2.5642629102276926

Epoch: 5| Step: 5
Training loss: 2.6465686967655344
Validation loss: 2.5778064619251064

Epoch: 5| Step: 6
Training loss: 2.3189399332983176
Validation loss: 2.58308639960448

Epoch: 5| Step: 7
Training loss: 2.66784247662264
Validation loss: 2.567226374081945

Epoch: 5| Step: 8
Training loss: 2.8452541858577614
Validation loss: 2.5734013813318133

Epoch: 5| Step: 9
Training loss: 2.9658553617866423
Validation loss: 2.5725632683445516

Epoch: 5| Step: 10
Training loss: 3.414328278904999
Validation loss: 2.5978007427291407

Epoch: 99| Step: 0
Training loss: 3.1635604648494233
Validation loss: 2.5808789680877933

Epoch: 5| Step: 1
Training loss: 2.7274589922905284
Validation loss: 2.5905683375513253

Epoch: 5| Step: 2
Training loss: 3.151419843358509
Validation loss: 2.5657494134399306

Epoch: 5| Step: 3
Training loss: 2.31842241466657
Validation loss: 2.5955479213753385

Epoch: 5| Step: 4
Training loss: 2.81095428376968
Validation loss: 2.5882692545074666

Epoch: 5| Step: 5
Training loss: 3.039038023077844
Validation loss: 2.5943584595769273

Epoch: 5| Step: 6
Training loss: 2.54552213157994
Validation loss: 2.5795662648333644

Epoch: 5| Step: 7
Training loss: 2.8331848741419776
Validation loss: 2.5949203888928727

Epoch: 5| Step: 8
Training loss: 2.963743465549919
Validation loss: 2.5805263369837745

Epoch: 5| Step: 9
Training loss: 2.9428579286793837
Validation loss: 2.5802085076998056

Epoch: 5| Step: 10
Training loss: 2.545248249289781
Validation loss: 2.6112832552507217

Epoch: 100| Step: 0
Training loss: 2.3795609097990336
Validation loss: 2.568736972171506

Epoch: 5| Step: 1
Training loss: 2.15780097356172
Validation loss: 2.5995683897097743

Epoch: 5| Step: 2
Training loss: 3.358607004782376
Validation loss: 2.5802849863057786

Epoch: 5| Step: 3
Training loss: 3.3525612505637743
Validation loss: 2.588306512305088

Epoch: 5| Step: 4
Training loss: 2.6178606221025924
Validation loss: 2.5863119786794915

Epoch: 5| Step: 5
Training loss: 3.0348822471236425
Validation loss: 2.5856218280723353

Epoch: 5| Step: 6
Training loss: 2.6263386174265935
Validation loss: 2.6057568964369477

Epoch: 5| Step: 7
Training loss: 2.771698226366722
Validation loss: 2.623496096996599

Epoch: 5| Step: 8
Training loss: 2.7434625948661906
Validation loss: 2.5948755841772098

Epoch: 5| Step: 9
Training loss: 2.690561369565548
Validation loss: 2.58789864314225

Epoch: 5| Step: 10
Training loss: 3.578346079030914
Validation loss: 2.5985862249689156

Epoch: 101| Step: 0
Training loss: 3.843379801468994
Validation loss: 2.6232670646749914

Epoch: 5| Step: 1
Training loss: 2.832070312230607
Validation loss: 2.59870276967152

Epoch: 5| Step: 2
Training loss: 2.9038926274860395
Validation loss: 2.6178587340338058

Epoch: 5| Step: 3
Training loss: 2.227888816524825
Validation loss: 2.56388292430102

Epoch: 5| Step: 4
Training loss: 3.1537170822112985
Validation loss: 2.5759112706052174

Epoch: 5| Step: 5
Training loss: 2.423695427691895
Validation loss: 2.599711496171679

Epoch: 5| Step: 6
Training loss: 2.9200352063081536
Validation loss: 2.5688931728968893

Epoch: 5| Step: 7
Training loss: 2.734663332314817
Validation loss: 2.560184136590533

Epoch: 5| Step: 8
Training loss: 2.8916962159449007
Validation loss: 2.564736377581262

Epoch: 5| Step: 9
Training loss: 2.2526238295444805
Validation loss: 2.608049883107538

Epoch: 5| Step: 10
Training loss: 2.6651897115262346
Validation loss: 2.5883394541459817

Epoch: 102| Step: 0
Training loss: 3.005507341359739
Validation loss: 2.5790531291367405

Epoch: 5| Step: 1
Training loss: 2.648838879262889
Validation loss: 2.5901642125054156

Epoch: 5| Step: 2
Training loss: 2.911407324674522
Validation loss: 2.5684546558516383

Epoch: 5| Step: 3
Training loss: 2.8596026220555357
Validation loss: 2.5678875720050205

Epoch: 5| Step: 4
Training loss: 2.7370508670337985
Validation loss: 2.5854483000649786

Epoch: 5| Step: 5
Training loss: 2.706181820898221
Validation loss: 2.5960335689650624

Epoch: 5| Step: 6
Training loss: 3.273098657227779
Validation loss: 2.596686779096868

Epoch: 5| Step: 7
Training loss: 3.475369983983537
Validation loss: 2.5849608859288864

Epoch: 5| Step: 8
Training loss: 2.911963148942366
Validation loss: 2.575803581786255

Epoch: 5| Step: 9
Training loss: 2.0192529719043817
Validation loss: 2.5646638995350357

Epoch: 5| Step: 10
Training loss: 2.5046374224953323
Validation loss: 2.582491910999389

Epoch: 103| Step: 0
Training loss: 3.2828527986430633
Validation loss: 2.5559732298082616

Epoch: 5| Step: 1
Training loss: 2.9276143380891972
Validation loss: 2.602036808067309

Epoch: 5| Step: 2
Training loss: 2.8958308999762616
Validation loss: 2.560056095257769

Epoch: 5| Step: 3
Training loss: 3.215953612149598
Validation loss: 2.607489733235258

Epoch: 5| Step: 4
Training loss: 2.9673799264552705
Validation loss: 2.5623033599678613

Epoch: 5| Step: 5
Training loss: 2.7970814548779535
Validation loss: 2.5608364200673215

Epoch: 5| Step: 6
Training loss: 3.2797932615488095
Validation loss: 2.5681280184047774

Epoch: 5| Step: 7
Training loss: 1.7614216691466318
Validation loss: 2.5783806518404737

Epoch: 5| Step: 8
Training loss: 2.6236636075158017
Validation loss: 2.5561925804640717

Epoch: 5| Step: 9
Training loss: 2.835371649331273
Validation loss: 2.5462658519381214

Epoch: 5| Step: 10
Training loss: 2.1196729422149088
Validation loss: 2.5446738641193236

Epoch: 104| Step: 0
Training loss: 2.8033901603766087
Validation loss: 2.570300179035653

Epoch: 5| Step: 1
Training loss: 2.6878567835824687
Validation loss: 2.56361894665859

Epoch: 5| Step: 2
Training loss: 3.1088188862578843
Validation loss: 2.574953481558856

Epoch: 5| Step: 3
Training loss: 2.217840948719253
Validation loss: 2.5727905123606636

Epoch: 5| Step: 4
Training loss: 2.675208260103186
Validation loss: 2.5429764198341425

Epoch: 5| Step: 5
Training loss: 3.4064419193621656
Validation loss: 2.577033375180306

Epoch: 5| Step: 6
Training loss: 2.7033418777870146
Validation loss: 2.57010932271682

Epoch: 5| Step: 7
Training loss: 2.317798524166134
Validation loss: 2.581518860488683

Epoch: 5| Step: 8
Training loss: 3.177284326084422
Validation loss: 2.573812306849946

Epoch: 5| Step: 9
Training loss: 3.1339816910647706
Validation loss: 2.580631314389191

Epoch: 5| Step: 10
Training loss: 2.5940102136450567
Validation loss: 2.565685404292944

Epoch: 105| Step: 0
Training loss: 2.996416494798868
Validation loss: 2.536128061517633

Epoch: 5| Step: 1
Training loss: 3.0399581256291364
Validation loss: 2.550335914488479

Epoch: 5| Step: 2
Training loss: 3.612152484163377
Validation loss: 2.5616388952515625

Epoch: 5| Step: 3
Training loss: 2.97383581511509
Validation loss: 2.595204376149275

Epoch: 5| Step: 4
Training loss: 2.542690279431748
Validation loss: 2.563047218069835

Epoch: 5| Step: 5
Training loss: 3.276286703789778
Validation loss: 2.5853184602620973

Epoch: 5| Step: 6
Training loss: 2.8155103890890043
Validation loss: 2.5715458196270853

Epoch: 5| Step: 7
Training loss: 2.374416078762922
Validation loss: 2.582507749484976

Epoch: 5| Step: 8
Training loss: 2.5629562343949277
Validation loss: 2.584266227866169

Epoch: 5| Step: 9
Training loss: 2.09002205631719
Validation loss: 2.575184183635152

Epoch: 5| Step: 10
Training loss: 2.588267311176105
Validation loss: 2.5912493895248954

Epoch: 106| Step: 0
Training loss: 2.923657531450299
Validation loss: 2.59448579862392

Epoch: 5| Step: 1
Training loss: 3.4995610098057357
Validation loss: 2.577416644290736

Epoch: 5| Step: 2
Training loss: 3.2179022107673694
Validation loss: 2.585164340844002

Epoch: 5| Step: 3
Training loss: 3.0040999053718367
Validation loss: 2.596742595991695

Epoch: 5| Step: 4
Training loss: 2.552331053460252
Validation loss: 2.5742810183117757

Epoch: 5| Step: 5
Training loss: 2.2374319226015276
Validation loss: 2.5718020327709294

Epoch: 5| Step: 6
Training loss: 2.7825055663677793
Validation loss: 2.5718934291795885

Epoch: 5| Step: 7
Training loss: 3.2099713359277877
Validation loss: 2.589235510693776

Epoch: 5| Step: 8
Training loss: 2.6768504436042586
Validation loss: 2.5646438014782915

Epoch: 5| Step: 9
Training loss: 1.8824926714102257
Validation loss: 2.6059807309445735

Epoch: 5| Step: 10
Training loss: 2.945580751057172
Validation loss: 2.58364564362067

Epoch: 107| Step: 0
Training loss: 2.4991115898871934
Validation loss: 2.5671579368908857

Epoch: 5| Step: 1
Training loss: 3.6076260908036692
Validation loss: 2.561452302766046

Epoch: 5| Step: 2
Training loss: 2.6626736329104865
Validation loss: 2.60127929951366

Epoch: 5| Step: 3
Training loss: 3.2380687611696866
Validation loss: 2.5813849160862006

Epoch: 5| Step: 4
Training loss: 3.1259619186044065
Validation loss: 2.5813957987386456

Epoch: 5| Step: 5
Training loss: 2.5861187551540006
Validation loss: 2.5640225673001904

Epoch: 5| Step: 6
Training loss: 2.1674302540681674
Validation loss: 2.599858590312139

Epoch: 5| Step: 7
Training loss: 2.5005175054891273
Validation loss: 2.572279240157663

Epoch: 5| Step: 8
Training loss: 2.969480404597918
Validation loss: 2.564063072945654

Epoch: 5| Step: 9
Training loss: 2.4579500018032805
Validation loss: 2.6238524589478907

Epoch: 5| Step: 10
Training loss: 2.881368797650049
Validation loss: 2.546560335855866

Epoch: 108| Step: 0
Training loss: 3.1212416364369076
Validation loss: 2.5595721173649704

Epoch: 5| Step: 1
Training loss: 2.9498482745964494
Validation loss: 2.5794121436192654

Epoch: 5| Step: 2
Training loss: 2.907314474758305
Validation loss: 2.6056725334887973

Epoch: 5| Step: 3
Training loss: 3.1568068211454237
Validation loss: 2.557529682407423

Epoch: 5| Step: 4
Training loss: 3.2096874467554275
Validation loss: 2.5871067093610924

Epoch: 5| Step: 5
Training loss: 2.4068264951848075
Validation loss: 2.587386166144907

Epoch: 5| Step: 6
Training loss: 2.5489194188631035
Validation loss: 2.566778069922998

Epoch: 5| Step: 7
Training loss: 2.5743380390133943
Validation loss: 2.5413983894536445

Epoch: 5| Step: 8
Training loss: 2.7606667075483804
Validation loss: 2.546809593421262

Epoch: 5| Step: 9
Training loss: 2.579131513693941
Validation loss: 2.5708199910258935

Epoch: 5| Step: 10
Training loss: 3.004862817816155
Validation loss: 2.5865700891079064

Epoch: 109| Step: 0
Training loss: 3.336474766225817
Validation loss: 2.5848225109753202

Epoch: 5| Step: 1
Training loss: 2.494522005823284
Validation loss: 2.5847534109772656

Epoch: 5| Step: 2
Training loss: 2.55089883109789
Validation loss: 2.588369010719447

Epoch: 5| Step: 3
Training loss: 2.813851688670919
Validation loss: 2.5731083960951167

Epoch: 5| Step: 4
Training loss: 3.398315006547808
Validation loss: 2.5675675032519134

Epoch: 5| Step: 5
Training loss: 2.6118318789414796
Validation loss: 2.5675558430859065

Epoch: 5| Step: 6
Training loss: 2.321081682634137
Validation loss: 2.581717732885818

Epoch: 5| Step: 7
Training loss: 2.155939162696455
Validation loss: 2.5705281217774667

Epoch: 5| Step: 8
Training loss: 2.850708047016343
Validation loss: 2.595057872724617

Epoch: 5| Step: 9
Training loss: 3.309296120197953
Validation loss: 2.570754853612657

Epoch: 5| Step: 10
Training loss: 2.833544349292373
Validation loss: 2.5551440036268978

Epoch: 110| Step: 0
Training loss: 3.237701327275812
Validation loss: 2.563662047660916

Epoch: 5| Step: 1
Training loss: 2.1676129573265093
Validation loss: 2.5703579233834137

Epoch: 5| Step: 2
Training loss: 2.5203560831897898
Validation loss: 2.5826134891134873

Epoch: 5| Step: 3
Training loss: 2.4195211477441365
Validation loss: 2.5705155983922507

Epoch: 5| Step: 4
Training loss: 2.9671244135975496
Validation loss: 2.581526966943364

Epoch: 5| Step: 5
Training loss: 3.169654407134782
Validation loss: 2.5805548351192686

Epoch: 5| Step: 6
Training loss: 3.3682039855201364
Validation loss: 2.5826704112155205

Epoch: 5| Step: 7
Training loss: 2.410542906870873
Validation loss: 2.5846836644238755

Epoch: 5| Step: 8
Training loss: 2.851854116082038
Validation loss: 2.5942567907677914

Epoch: 5| Step: 9
Training loss: 2.807946057505224
Validation loss: 2.543139182616115

Epoch: 5| Step: 10
Training loss: 2.9026190933910634
Validation loss: 2.5552010661130953

Epoch: 111| Step: 0
Training loss: 2.149957625392907
Validation loss: 2.575443254999555

Epoch: 5| Step: 1
Training loss: 2.6480217441346037
Validation loss: 2.5722503074877427

Epoch: 5| Step: 2
Training loss: 3.149929857229959
Validation loss: 2.592460075345744

Epoch: 5| Step: 3
Training loss: 2.9787716014493415
Validation loss: 2.5514316730540227

Epoch: 5| Step: 4
Training loss: 3.385879078120309
Validation loss: 2.566626871503941

Epoch: 5| Step: 5
Training loss: 2.67536947604317
Validation loss: 2.5840393471795444

Epoch: 5| Step: 6
Training loss: 2.552089758624857
Validation loss: 2.5718074505177078

Epoch: 5| Step: 7
Training loss: 2.9681328382968926
Validation loss: 2.551796528160011

Epoch: 5| Step: 8
Training loss: 2.35782638151356
Validation loss: 2.5714504070635886

Epoch: 5| Step: 9
Training loss: 2.5365487669398767
Validation loss: 2.567124654338326

Epoch: 5| Step: 10
Training loss: 3.343959053135647
Validation loss: 2.5550143526483793

Epoch: 112| Step: 0
Training loss: 3.19644197307435
Validation loss: 2.6009100323968766

Epoch: 5| Step: 1
Training loss: 2.3692146912371257
Validation loss: 2.5582472945435932

Epoch: 5| Step: 2
Training loss: 2.8093571374853608
Validation loss: 2.545460510331817

Epoch: 5| Step: 3
Training loss: 2.5550493923123603
Validation loss: 2.548589085705816

Epoch: 5| Step: 4
Training loss: 2.284504489385811
Validation loss: 2.570579511199395

Epoch: 5| Step: 5
Training loss: 2.6702283280143795
Validation loss: 2.5757293220290034

Epoch: 5| Step: 6
Training loss: 2.9203141067035108
Validation loss: 2.569955167054143

Epoch: 5| Step: 7
Training loss: 2.8002922450549415
Validation loss: 2.5540315010905354

Epoch: 5| Step: 8
Training loss: 3.2851407190198425
Validation loss: 2.592554226209889

Epoch: 5| Step: 9
Training loss: 3.2468726443593328
Validation loss: 2.5700517872471362

Epoch: 5| Step: 10
Training loss: 2.770529068228957
Validation loss: 2.573303302877326

Epoch: 113| Step: 0
Training loss: 2.622585094078664
Validation loss: 2.5681135476933927

Epoch: 5| Step: 1
Training loss: 2.941958999877124
Validation loss: 2.601925686942946

Epoch: 5| Step: 2
Training loss: 2.3173408359820233
Validation loss: 2.5797233959017145

Epoch: 5| Step: 3
Training loss: 2.2760180741985265
Validation loss: 2.55361079667068

Epoch: 5| Step: 4
Training loss: 3.040917622206558
Validation loss: 2.5565765422212974

Epoch: 5| Step: 5
Training loss: 2.210849719781847
Validation loss: 2.5814610132490383

Epoch: 5| Step: 6
Training loss: 2.333649500361944
Validation loss: 2.5612520860420185

Epoch: 5| Step: 7
Training loss: 2.9282502985214593
Validation loss: 2.5691910103689835

Epoch: 5| Step: 8
Training loss: 3.6739407835929603
Validation loss: 2.590076015479913

Epoch: 5| Step: 9
Training loss: 3.3268755506120535
Validation loss: 2.567818178024148

Epoch: 5| Step: 10
Training loss: 2.738945938824723
Validation loss: 2.5793598925352694

Epoch: 114| Step: 0
Training loss: 2.908122454178313
Validation loss: 2.5779007223404755

Epoch: 5| Step: 1
Training loss: 3.199444400715006
Validation loss: 2.591247875826008

Epoch: 5| Step: 2
Training loss: 3.1891388513451684
Validation loss: 2.5894516279132573

Epoch: 5| Step: 3
Training loss: 3.06719082070869
Validation loss: 2.558221302730725

Epoch: 5| Step: 4
Training loss: 2.777420665250011
Validation loss: 2.556600186263252

Epoch: 5| Step: 5
Training loss: 2.5277122924575814
Validation loss: 2.531966790167513

Epoch: 5| Step: 6
Training loss: 2.8751270431976335
Validation loss: 2.5627310283811684

Epoch: 5| Step: 7
Training loss: 2.1811619082263154
Validation loss: 2.5675853388700847

Epoch: 5| Step: 8
Training loss: 2.3199014524378914
Validation loss: 2.591216130487508

Epoch: 5| Step: 9
Training loss: 3.2499432192023834
Validation loss: 2.576755688805261

Epoch: 5| Step: 10
Training loss: 2.5348354424631654
Validation loss: 2.5704581926954564

Epoch: 115| Step: 0
Training loss: 3.0032308982572538
Validation loss: 2.5556036869350747

Epoch: 5| Step: 1
Training loss: 3.314782705650727
Validation loss: 2.591630860942486

Epoch: 5| Step: 2
Training loss: 2.2002947869906437
Validation loss: 2.556625259999884

Epoch: 5| Step: 3
Training loss: 2.899726683792499
Validation loss: 2.5914948681261247

Epoch: 5| Step: 4
Training loss: 3.164011410901198
Validation loss: 2.5601037769840143

Epoch: 5| Step: 5
Training loss: 3.02335075628552
Validation loss: 2.565298002015388

Epoch: 5| Step: 6
Training loss: 2.8272887621694998
Validation loss: 2.565293862688078

Epoch: 5| Step: 7
Training loss: 2.714882654144585
Validation loss: 2.5749491561424263

Epoch: 5| Step: 8
Training loss: 2.731778639693451
Validation loss: 2.5630557710353608

Epoch: 5| Step: 9
Training loss: 2.83573690078025
Validation loss: 2.6273487129132964

Epoch: 5| Step: 10
Training loss: 2.072592002197843
Validation loss: 2.5947480538127925

Epoch: 116| Step: 0
Training loss: 2.487205764007515
Validation loss: 2.584711322252037

Epoch: 5| Step: 1
Training loss: 2.55811781788332
Validation loss: 2.5630400203936525

Epoch: 5| Step: 2
Training loss: 2.7896974839854125
Validation loss: 2.610968807650827

Epoch: 5| Step: 3
Training loss: 3.810839932589834
Validation loss: 2.6091070835275163

Epoch: 5| Step: 4
Training loss: 2.625885859377416
Validation loss: 2.587318855719074

Epoch: 5| Step: 5
Training loss: 2.3330920185462882
Validation loss: 2.595890967838447

Epoch: 5| Step: 6
Training loss: 2.358206756573835
Validation loss: 2.591800663389651

Epoch: 5| Step: 7
Training loss: 3.4981529266622164
Validation loss: 2.560583990521745

Epoch: 5| Step: 8
Training loss: 2.155376423223413
Validation loss: 2.578722458786496

Epoch: 5| Step: 9
Training loss: 3.0662564963930143
Validation loss: 2.5441418680145325

Epoch: 5| Step: 10
Training loss: 2.6147676582765054
Validation loss: 2.5532467575783375

Epoch: 117| Step: 0
Training loss: 2.7863938844066602
Validation loss: 2.5871477265851732

Epoch: 5| Step: 1
Training loss: 2.690014749366003
Validation loss: 2.5560159582455473

Epoch: 5| Step: 2
Training loss: 2.593423753925597
Validation loss: 2.5592509786011965

Epoch: 5| Step: 3
Training loss: 2.784303253653755
Validation loss: 2.5956901927067113

Epoch: 5| Step: 4
Training loss: 2.480456254582208
Validation loss: 2.602118605662961

Epoch: 5| Step: 5
Training loss: 3.0330893058570974
Validation loss: 2.5644357844370638

Epoch: 5| Step: 6
Training loss: 2.788920935876861
Validation loss: 2.6008621017494096

Epoch: 5| Step: 7
Training loss: 2.9977623223573304
Validation loss: 2.5817787230977083

Epoch: 5| Step: 8
Training loss: 3.415506088267046
Validation loss: 2.5472706932076843

Epoch: 5| Step: 9
Training loss: 2.873000237289297
Validation loss: 2.5504784030122263

Epoch: 5| Step: 10
Training loss: 2.2437335808028354
Validation loss: 2.5710644128821354

Epoch: 118| Step: 0
Training loss: 3.562690462073887
Validation loss: 2.577206368606921

Epoch: 5| Step: 1
Training loss: 2.467029503177771
Validation loss: 2.5652470254643687

Epoch: 5| Step: 2
Training loss: 3.172378274612964
Validation loss: 2.592613210289296

Epoch: 5| Step: 3
Training loss: 2.7657530156911934
Validation loss: 2.5615732941896496

Epoch: 5| Step: 4
Training loss: 2.473865279739834
Validation loss: 2.5722402940969293

Epoch: 5| Step: 5
Training loss: 2.479771794002341
Validation loss: 2.5608819885069654

Epoch: 5| Step: 6
Training loss: 2.531627485596978
Validation loss: 2.5645811912134686

Epoch: 5| Step: 7
Training loss: 2.9806484103268347
Validation loss: 2.5561798333987804

Epoch: 5| Step: 8
Training loss: 2.4432723337064317
Validation loss: 2.5831249528797264

Epoch: 5| Step: 9
Training loss: 2.7921213851982505
Validation loss: 2.5594976260644415

Epoch: 5| Step: 10
Training loss: 2.9793483082988277
Validation loss: 2.556571684832195

Epoch: 119| Step: 0
Training loss: 3.110717483626479
Validation loss: 2.5934720068922084

Epoch: 5| Step: 1
Training loss: 3.1073833585470423
Validation loss: 2.5758054150876775

Epoch: 5| Step: 2
Training loss: 2.281774904662082
Validation loss: 2.549782483569409

Epoch: 5| Step: 3
Training loss: 2.992348290647582
Validation loss: 2.5669954506718455

Epoch: 5| Step: 4
Training loss: 3.0862556390104388
Validation loss: 2.561818797410381

Epoch: 5| Step: 5
Training loss: 2.625790703985463
Validation loss: 2.5534929127581742

Epoch: 5| Step: 6
Training loss: 3.0629960261763434
Validation loss: 2.5679027108812034

Epoch: 5| Step: 7
Training loss: 2.7869341767815206
Validation loss: 2.5437541013782696

Epoch: 5| Step: 8
Training loss: 2.3068221212200553
Validation loss: 2.5858261371423175

Epoch: 5| Step: 9
Training loss: 2.4655902777911485
Validation loss: 2.5734762422152175

Epoch: 5| Step: 10
Training loss: 3.032367932745137
Validation loss: 2.5506112657124613

Epoch: 120| Step: 0
Training loss: 2.8953635477340947
Validation loss: 2.5870031898285717

Epoch: 5| Step: 1
Training loss: 2.3387399658770796
Validation loss: 2.566588061417789

Epoch: 5| Step: 2
Training loss: 3.3813338010208014
Validation loss: 2.582624331846245

Epoch: 5| Step: 3
Training loss: 2.725852895829962
Validation loss: 2.5778078104731232

Epoch: 5| Step: 4
Training loss: 2.496456686984622
Validation loss: 2.5976061512448156

Epoch: 5| Step: 5
Training loss: 3.2791953783987795
Validation loss: 2.5458499665889507

Epoch: 5| Step: 6
Training loss: 2.850348896287331
Validation loss: 2.573761523837032

Epoch: 5| Step: 7
Training loss: 2.6078655879775083
Validation loss: 2.5582692927285966

Epoch: 5| Step: 8
Training loss: 3.0357541314082575
Validation loss: 2.5805409943991915

Epoch: 5| Step: 9
Training loss: 2.7017707740011145
Validation loss: 2.568143766790516

Epoch: 5| Step: 10
Training loss: 2.3786283183484898
Validation loss: 2.585316069477161

Epoch: 121| Step: 0
Training loss: 3.2018817256549323
Validation loss: 2.5719980243363394

Epoch: 5| Step: 1
Training loss: 3.3754967218020644
Validation loss: 2.542607070085342

Epoch: 5| Step: 2
Training loss: 2.1902567250523313
Validation loss: 2.5553714543732378

Epoch: 5| Step: 3
Training loss: 2.274381146780389
Validation loss: 2.564368085540948

Epoch: 5| Step: 4
Training loss: 2.9042939196983957
Validation loss: 2.570252510420757

Epoch: 5| Step: 5
Training loss: 3.3647780859044496
Validation loss: 2.6092001085311023

Epoch: 5| Step: 6
Training loss: 3.08618997434365
Validation loss: 2.5819914075057877

Epoch: 5| Step: 7
Training loss: 2.3852392627653116
Validation loss: 2.586465779937311

Epoch: 5| Step: 8
Training loss: 2.402219890099702
Validation loss: 2.5714759162265897

Epoch: 5| Step: 9
Training loss: 2.406997960747876
Validation loss: 2.56935628222209

Epoch: 5| Step: 10
Training loss: 3.0526425280089042
Validation loss: 2.5506115471427786

Epoch: 122| Step: 0
Training loss: 2.612792923124766
Validation loss: 2.5736097445470505

Epoch: 5| Step: 1
Training loss: 3.138201789334308
Validation loss: 2.5935161795045074

Epoch: 5| Step: 2
Training loss: 2.8526896718093018
Validation loss: 2.54963010332601

Epoch: 5| Step: 3
Training loss: 3.05183640523799
Validation loss: 2.5750707090764577

Epoch: 5| Step: 4
Training loss: 2.300694825082549
Validation loss: 2.5956315610248755

Epoch: 5| Step: 5
Training loss: 3.1247958307327295
Validation loss: 2.580069702986232

Epoch: 5| Step: 6
Training loss: 1.9980562420548087
Validation loss: 2.59125406912436

Epoch: 5| Step: 7
Training loss: 2.702540516368764
Validation loss: 2.549179651994119

Epoch: 5| Step: 8
Training loss: 3.4316816159244334
Validation loss: 2.572454852388832

Epoch: 5| Step: 9
Training loss: 2.7701004799201345
Validation loss: 2.5772834475779334

Epoch: 5| Step: 10
Training loss: 2.5420769740710156
Validation loss: 2.5833802245413238

Epoch: 123| Step: 0
Training loss: 3.1683141705854734
Validation loss: 2.574158497904639

Epoch: 5| Step: 1
Training loss: 3.090323969082646
Validation loss: 2.5683115156451115

Epoch: 5| Step: 2
Training loss: 2.6511909327925784
Validation loss: 2.5929941706214072

Epoch: 5| Step: 3
Training loss: 2.646433924795884
Validation loss: 2.5600957008292413

Epoch: 5| Step: 4
Training loss: 3.2017949017631566
Validation loss: 2.602064528246621

Epoch: 5| Step: 5
Training loss: 2.3257209603437126
Validation loss: 2.577299100232117

Epoch: 5| Step: 6
Training loss: 3.3572599628279924
Validation loss: 2.582434234464729

Epoch: 5| Step: 7
Training loss: 2.4273071404168154
Validation loss: 2.5731642093640246

Epoch: 5| Step: 8
Training loss: 2.7693792174971588
Validation loss: 2.5603047233388914

Epoch: 5| Step: 9
Training loss: 2.5988219893678512
Validation loss: 2.549067117741013

Epoch: 5| Step: 10
Training loss: 2.226433358713765
Validation loss: 2.569667614700775

Epoch: 124| Step: 0
Training loss: 2.382383514310623
Validation loss: 2.584910752369219

Epoch: 5| Step: 1
Training loss: 3.2270041987791074
Validation loss: 2.5804329791952703

Epoch: 5| Step: 2
Training loss: 2.76756735660286
Validation loss: 2.5557045692135483

Epoch: 5| Step: 3
Training loss: 3.247973910926935
Validation loss: 2.5964983619301574

Epoch: 5| Step: 4
Training loss: 2.4547191712529557
Validation loss: 2.5554251670641515

Epoch: 5| Step: 5
Training loss: 2.14574660585809
Validation loss: 2.5582443573627223

Epoch: 5| Step: 6
Training loss: 3.118838988966747
Validation loss: 2.58079863301506

Epoch: 5| Step: 7
Training loss: 2.4875424903806116
Validation loss: 2.5629827093260906

Epoch: 5| Step: 8
Training loss: 3.22424513979576
Validation loss: 2.5949024477355707

Epoch: 5| Step: 9
Training loss: 2.873997720907286
Validation loss: 2.567758248980165

Epoch: 5| Step: 10
Training loss: 2.5787658819614676
Validation loss: 2.54816307714487

Epoch: 125| Step: 0
Training loss: 2.1859345420397474
Validation loss: 2.5613066753217644

Epoch: 5| Step: 1
Training loss: 3.093566734974016
Validation loss: 2.5466504436167967

Epoch: 5| Step: 2
Training loss: 3.302016601530008
Validation loss: 2.5652879694816844

Epoch: 5| Step: 3
Training loss: 2.8483418710698594
Validation loss: 2.566629383576543

Epoch: 5| Step: 4
Training loss: 3.0055665188924543
Validation loss: 2.5460399811744208

Epoch: 5| Step: 5
Training loss: 2.6211369563491353
Validation loss: 2.5780903485437725

Epoch: 5| Step: 6
Training loss: 2.792363454678653
Validation loss: 2.557500386407124

Epoch: 5| Step: 7
Training loss: 2.8338060171735027
Validation loss: 2.5470872170684724

Epoch: 5| Step: 8
Training loss: 2.630320923664735
Validation loss: 2.538360816795414

Epoch: 5| Step: 9
Training loss: 2.937667030293185
Validation loss: 2.5438788601143

Epoch: 5| Step: 10
Training loss: 2.449387539974817
Validation loss: 2.5560745498367594

Epoch: 126| Step: 0
Training loss: 2.795481926275732
Validation loss: 2.5778754577486582

Epoch: 5| Step: 1
Training loss: 2.494563963711709
Validation loss: 2.5615776316837717

Epoch: 5| Step: 2
Training loss: 2.706450340837277
Validation loss: 2.565168658371789

Epoch: 5| Step: 3
Training loss: 2.5016164322328343
Validation loss: 2.557209806963912

Epoch: 5| Step: 4
Training loss: 2.498771174743303
Validation loss: 2.576062824725371

Epoch: 5| Step: 5
Training loss: 3.3892064093448253
Validation loss: 2.5375574904069387

Epoch: 5| Step: 6
Training loss: 2.8234002706736323
Validation loss: 2.5760251549783804

Epoch: 5| Step: 7
Training loss: 2.9882046558811344
Validation loss: 2.5501817990313653

Epoch: 5| Step: 8
Training loss: 3.162382607674824
Validation loss: 2.5746225570058536

Epoch: 5| Step: 9
Training loss: 2.915179900021147
Validation loss: 2.5836536789058626

Epoch: 5| Step: 10
Training loss: 2.2706189068923286
Validation loss: 2.565998218706322

Epoch: 127| Step: 0
Training loss: 3.3308701633239735
Validation loss: 2.568012276386257

Epoch: 5| Step: 1
Training loss: 2.3980470022601366
Validation loss: 2.5761215564663926

Epoch: 5| Step: 2
Training loss: 3.1083814097377624
Validation loss: 2.5801920370904234

Epoch: 5| Step: 3
Training loss: 2.7511543972072796
Validation loss: 2.5642749652732175

Epoch: 5| Step: 4
Training loss: 2.518030284351031
Validation loss: 2.5865753104028153

Epoch: 5| Step: 5
Training loss: 2.573656035121142
Validation loss: 2.5795241829057343

Epoch: 5| Step: 6
Training loss: 2.5428317687940796
Validation loss: 2.588419955311708

Epoch: 5| Step: 7
Training loss: 3.1242284203713804
Validation loss: 2.55447320113614

Epoch: 5| Step: 8
Training loss: 2.972474021188516
Validation loss: 2.5775054465638036

Epoch: 5| Step: 9
Training loss: 2.6022395722085645
Validation loss: 2.5633672021683807

Epoch: 5| Step: 10
Training loss: 2.8465719788264003
Validation loss: 2.5899624292259626

Epoch: 128| Step: 0
Training loss: 3.168922741637647
Validation loss: 2.5554896498955153

Epoch: 5| Step: 1
Training loss: 2.9668881651524184
Validation loss: 2.550683116879779

Epoch: 5| Step: 2
Training loss: 3.1219817272191603
Validation loss: 2.58930885192056

Epoch: 5| Step: 3
Training loss: 3.363037951239119
Validation loss: 2.54728159479581

Epoch: 5| Step: 4
Training loss: 2.3790372364582346
Validation loss: 2.575495616400735

Epoch: 5| Step: 5
Training loss: 2.575936885872078
Validation loss: 2.6229245174241957

Epoch: 5| Step: 6
Training loss: 2.47640085745778
Validation loss: 2.566613086524201

Epoch: 5| Step: 7
Training loss: 2.197400494992728
Validation loss: 2.59575838429719

Epoch: 5| Step: 8
Training loss: 2.6493515192868995
Validation loss: 2.5581996288221838

Epoch: 5| Step: 9
Training loss: 2.871852976784096
Validation loss: 2.5853226349579916

Epoch: 5| Step: 10
Training loss: 2.8320472453750876
Validation loss: 2.567791906699585

Epoch: 129| Step: 0
Training loss: 3.1570931998492187
Validation loss: 2.5541732344228194

Epoch: 5| Step: 1
Training loss: 2.590814422934316
Validation loss: 2.565362027823873

Epoch: 5| Step: 2
Training loss: 2.7122088262847144
Validation loss: 2.5687985520155334

Epoch: 5| Step: 3
Training loss: 3.2276656733392537
Validation loss: 2.5776561530754916

Epoch: 5| Step: 4
Training loss: 3.0287551838275095
Validation loss: 2.5926315875359136

Epoch: 5| Step: 5
Training loss: 2.1658377406667575
Validation loss: 2.5653750255634096

Epoch: 5| Step: 6
Training loss: 3.0172998392614754
Validation loss: 2.61633522385731

Epoch: 5| Step: 7
Training loss: 2.737642178261708
Validation loss: 2.565184882650192

Epoch: 5| Step: 8
Training loss: 2.6188680690469557
Validation loss: 2.5849543730840097

Epoch: 5| Step: 9
Training loss: 2.135969459501092
Validation loss: 2.5724792334468205

Epoch: 5| Step: 10
Training loss: 3.140416380372873
Validation loss: 2.5541709148557206

Epoch: 130| Step: 0
Training loss: 2.5664484261541056
Validation loss: 2.5536440475438313

Epoch: 5| Step: 1
Training loss: 2.7261338211204413
Validation loss: 2.5805009838496207

Epoch: 5| Step: 2
Training loss: 2.5696877876957953
Validation loss: 2.5941010845532717

Epoch: 5| Step: 3
Training loss: 2.384943075240466
Validation loss: 2.565125451760404

Epoch: 5| Step: 4
Training loss: 2.911338043912561
Validation loss: 2.592788324285726

Epoch: 5| Step: 5
Training loss: 3.6943440690582596
Validation loss: 2.577949674579415

Epoch: 5| Step: 6
Training loss: 2.7009727421175707
Validation loss: 2.5798129276691335

Epoch: 5| Step: 7
Training loss: 2.819591482887387
Validation loss: 2.554270773775389

Epoch: 5| Step: 8
Training loss: 2.7291847014862625
Validation loss: 2.5567605215734472

Epoch: 5| Step: 9
Training loss: 2.6615683774848513
Validation loss: 2.5773378952480037

Epoch: 5| Step: 10
Training loss: 2.859531252401252
Validation loss: 2.572938617481304

Epoch: 131| Step: 0
Training loss: 2.5165534349782988
Validation loss: 2.5642868343089487

Epoch: 5| Step: 1
Training loss: 2.2206500876609563
Validation loss: 2.5890128262591467

Epoch: 5| Step: 2
Training loss: 2.6160917351063397
Validation loss: 2.542741769698844

Epoch: 5| Step: 3
Training loss: 2.6785444040297577
Validation loss: 2.5831213681222835

Epoch: 5| Step: 4
Training loss: 2.916747137503651
Validation loss: 2.52069894718383

Epoch: 5| Step: 5
Training loss: 3.0173730082997396
Validation loss: 2.575741284592376

Epoch: 5| Step: 6
Training loss: 3.0172589080752377
Validation loss: 2.55247011817688

Epoch: 5| Step: 7
Training loss: 2.7642896628958886
Validation loss: 2.563980895169823

Epoch: 5| Step: 8
Training loss: 3.2183590253386902
Validation loss: 2.564967356451736

Epoch: 5| Step: 9
Training loss: 3.0947415082768637
Validation loss: 2.569560459876494

Epoch: 5| Step: 10
Training loss: 2.4010160917849457
Validation loss: 2.5587838632153184

Epoch: 132| Step: 0
Training loss: 2.7783984020770065
Validation loss: 2.56198451882309

Epoch: 5| Step: 1
Training loss: 2.960524880035231
Validation loss: 2.561334410422007

Epoch: 5| Step: 2
Training loss: 2.891623329768628
Validation loss: 2.59008532546168

Epoch: 5| Step: 3
Training loss: 2.751610544403719
Validation loss: 2.544953489643558

Epoch: 5| Step: 4
Training loss: 2.3721133307132605
Validation loss: 2.541251462499337

Epoch: 5| Step: 5
Training loss: 2.7597895551698253
Validation loss: 2.5679509322592176

Epoch: 5| Step: 6
Training loss: 2.7585252915938243
Validation loss: 2.5801346837341694

Epoch: 5| Step: 7
Training loss: 2.6545646257349564
Validation loss: 2.5808898389672006

Epoch: 5| Step: 8
Training loss: 2.764721394138482
Validation loss: 2.5355259308369815

Epoch: 5| Step: 9
Training loss: 3.5030811916201725
Validation loss: 2.5349565230715574

Epoch: 5| Step: 10
Training loss: 2.5283269134352806
Validation loss: 2.5782270717706597

Epoch: 133| Step: 0
Training loss: 2.6002190130863254
Validation loss: 2.601156281676045

Epoch: 5| Step: 1
Training loss: 2.132419312393988
Validation loss: 2.5766635047424007

Epoch: 5| Step: 2
Training loss: 2.0924201271919505
Validation loss: 2.5688690512053443

Epoch: 5| Step: 3
Training loss: 2.8158656010091776
Validation loss: 2.6015402510147165

Epoch: 5| Step: 4
Training loss: 2.4346252508655413
Validation loss: 2.598192544098164

Epoch: 5| Step: 5
Training loss: 3.2865408248745207
Validation loss: 2.5598887613265773

Epoch: 5| Step: 6
Training loss: 3.388323728063366
Validation loss: 2.5653209910501453

Epoch: 5| Step: 7
Training loss: 3.5312593173013833
Validation loss: 2.552475408221664

Epoch: 5| Step: 8
Training loss: 2.423919995677823
Validation loss: 2.581280670504227

Epoch: 5| Step: 9
Training loss: 2.8488023751278675
Validation loss: 2.5658494482024703

Epoch: 5| Step: 10
Training loss: 2.3190588855908008
Validation loss: 2.6113162105977343

Epoch: 134| Step: 0
Training loss: 3.5687182850939996
Validation loss: 2.5513550781377416

Epoch: 5| Step: 1
Training loss: 2.198814775077723
Validation loss: 2.542392814255494

Epoch: 5| Step: 2
Training loss: 2.308127005912184
Validation loss: 2.5811008127697503

Epoch: 5| Step: 3
Training loss: 2.796123808672297
Validation loss: 2.5837753273717325

Epoch: 5| Step: 4
Training loss: 2.5498807991440993
Validation loss: 2.5662758853207177

Epoch: 5| Step: 5
Training loss: 2.9329158644836113
Validation loss: 2.517545975142108

Epoch: 5| Step: 6
Training loss: 2.674705924153286
Validation loss: 2.56044235373471

Epoch: 5| Step: 7
Training loss: 2.9330758400810217
Validation loss: 2.598469500411576

Epoch: 5| Step: 8
Training loss: 2.6297770130791105
Validation loss: 2.5408593530836447

Epoch: 5| Step: 9
Training loss: 3.1227647034816033
Validation loss: 2.576935492660688

Epoch: 5| Step: 10
Training loss: 2.438163862546954
Validation loss: 2.5592449993561144

Epoch: 135| Step: 0
Training loss: 2.128061445410328
Validation loss: 2.5728929477126616

Epoch: 5| Step: 1
Training loss: 2.680531538447791
Validation loss: 2.5551323896084406

Epoch: 5| Step: 2
Training loss: 2.9043674729776914
Validation loss: 2.5798258501174907

Epoch: 5| Step: 3
Training loss: 2.598959688990258
Validation loss: 2.597028255613594

Epoch: 5| Step: 4
Training loss: 3.1371025715220866
Validation loss: 2.5869727708573413

Epoch: 5| Step: 5
Training loss: 2.779779023780672
Validation loss: 2.5887825043939614

Epoch: 5| Step: 6
Training loss: 2.6436826620702254
Validation loss: 2.5392534556179296

Epoch: 5| Step: 7
Training loss: 2.995965151656709
Validation loss: 2.5546527664629686

Epoch: 5| Step: 8
Training loss: 2.8939814695385864
Validation loss: 2.560891345558696

Epoch: 5| Step: 9
Training loss: 3.027081326831661
Validation loss: 2.543268400717653

Epoch: 5| Step: 10
Training loss: 2.7573421606713273
Validation loss: 2.5398980403328584

Epoch: 136| Step: 0
Training loss: 2.751682633696945
Validation loss: 2.527575603170807

Epoch: 5| Step: 1
Training loss: 3.015799878045449
Validation loss: 2.5660946532091717

Epoch: 5| Step: 2
Training loss: 2.733339211604923
Validation loss: 2.572711061696487

Epoch: 5| Step: 3
Training loss: 2.8243405644275357
Validation loss: 2.560543895402538

Epoch: 5| Step: 4
Training loss: 2.47351367903012
Validation loss: 2.537245336467515

Epoch: 5| Step: 5
Training loss: 2.651142550624253
Validation loss: 2.547180615943314

Epoch: 5| Step: 6
Training loss: 3.016679332418531
Validation loss: 2.558362331976251

Epoch: 5| Step: 7
Training loss: 2.9249209271037686
Validation loss: 2.5618603225837258

Epoch: 5| Step: 8
Training loss: 2.695370969276367
Validation loss: 2.535386934738952

Epoch: 5| Step: 9
Training loss: 2.4759607396256267
Validation loss: 2.548235069777685

Epoch: 5| Step: 10
Training loss: 3.023679738357925
Validation loss: 2.5522952613121994

Epoch: 137| Step: 0
Training loss: 2.5896089887588523
Validation loss: 2.546877661403602

Epoch: 5| Step: 1
Training loss: 2.6233599852969616
Validation loss: 2.5541643415665063

Epoch: 5| Step: 2
Training loss: 3.172707434351497
Validation loss: 2.5562956287756404

Epoch: 5| Step: 3
Training loss: 2.623173214276398
Validation loss: 2.5440508667538655

Epoch: 5| Step: 4
Training loss: 3.3568142379349695
Validation loss: 2.546187904473024

Epoch: 5| Step: 5
Training loss: 2.9079550386859565
Validation loss: 2.553825524767714

Epoch: 5| Step: 6
Training loss: 2.3788735774259817
Validation loss: 2.5753518462024076

Epoch: 5| Step: 7
Training loss: 2.5141883681080044
Validation loss: 2.5497856004161066

Epoch: 5| Step: 8
Training loss: 2.790176126533527
Validation loss: 2.5585718172284477

Epoch: 5| Step: 9
Training loss: 3.0319533957570934
Validation loss: 2.5570180196964873

Epoch: 5| Step: 10
Training loss: 2.308759499423441
Validation loss: 2.5553143515485943

Epoch: 138| Step: 0
Training loss: 2.636950221321321
Validation loss: 2.5592087890138804

Epoch: 5| Step: 1
Training loss: 2.385144102913406
Validation loss: 2.5535597263574648

Epoch: 5| Step: 2
Training loss: 3.119675181426724
Validation loss: 2.549251989012204

Epoch: 5| Step: 3
Training loss: 2.7597472236813543
Validation loss: 2.560872866675042

Epoch: 5| Step: 4
Training loss: 3.273291536777806
Validation loss: 2.5590341125943574

Epoch: 5| Step: 5
Training loss: 3.1589105553349315
Validation loss: 2.5758476513237927

Epoch: 5| Step: 6
Training loss: 2.3748247182311744
Validation loss: 2.542545839987594

Epoch: 5| Step: 7
Training loss: 2.900879522662891
Validation loss: 2.539701797360578

Epoch: 5| Step: 8
Training loss: 2.4316361147674037
Validation loss: 2.5169949738391955

Epoch: 5| Step: 9
Training loss: 2.893688660995246
Validation loss: 2.5708418836232223

Epoch: 5| Step: 10
Training loss: 2.4486794007168675
Validation loss: 2.5808457134814398

Epoch: 139| Step: 0
Training loss: 3.1191874042555074
Validation loss: 2.57475250305984

Epoch: 5| Step: 1
Training loss: 2.3149480491724717
Validation loss: 2.5371933931315866

Epoch: 5| Step: 2
Training loss: 2.9462270758622706
Validation loss: 2.5695950916726504

Epoch: 5| Step: 3
Training loss: 3.004126571691052
Validation loss: 2.606412523758427

Epoch: 5| Step: 4
Training loss: 2.433982267028356
Validation loss: 2.558777174535005

Epoch: 5| Step: 5
Training loss: 2.521538081583342
Validation loss: 2.5864567572540844

Epoch: 5| Step: 6
Training loss: 3.4346481978214087
Validation loss: 2.5770653310402256

Epoch: 5| Step: 7
Training loss: 2.9280723086637024
Validation loss: 2.544765224408985

Epoch: 5| Step: 8
Training loss: 1.9891800862906281
Validation loss: 2.5558612484456695

Epoch: 5| Step: 9
Training loss: 3.4268425544790464
Validation loss: 2.5741064603711745

Epoch: 5| Step: 10
Training loss: 2.0588498037729344
Validation loss: 2.5652647702839637

Epoch: 140| Step: 0
Training loss: 3.1599827213056395
Validation loss: 2.579893448452896

Epoch: 5| Step: 1
Training loss: 2.338450531291732
Validation loss: 2.599803000063307

Epoch: 5| Step: 2
Training loss: 2.7283497721045356
Validation loss: 2.539675178661522

Epoch: 5| Step: 3
Training loss: 2.727446317205625
Validation loss: 2.569748890836651

Epoch: 5| Step: 4
Training loss: 2.356898542846504
Validation loss: 2.556386448371339

Epoch: 5| Step: 5
Training loss: 3.096746361579214
Validation loss: 2.5526734541060008

Epoch: 5| Step: 6
Training loss: 2.730668787798331
Validation loss: 2.578902827338509

Epoch: 5| Step: 7
Training loss: 2.6306792992670243
Validation loss: 2.5582633562836774

Epoch: 5| Step: 8
Training loss: 2.781297747598613
Validation loss: 2.520227641358155

Epoch: 5| Step: 9
Training loss: 3.304887625764771
Validation loss: 2.5250866394546447

Epoch: 5| Step: 10
Training loss: 2.3179873752135
Validation loss: 2.5450342702046056

Epoch: 141| Step: 0
Training loss: 3.1166823510848
Validation loss: 2.5578038532881355

Epoch: 5| Step: 1
Training loss: 2.7153923962253623
Validation loss: 2.5469041665769656

Epoch: 5| Step: 2
Training loss: 3.6243011853364573
Validation loss: 2.5747080802217184

Epoch: 5| Step: 3
Training loss: 2.32242926942605
Validation loss: 2.536432467278188

Epoch: 5| Step: 4
Training loss: 2.7097056995511397
Validation loss: 2.556678522198039

Epoch: 5| Step: 5
Training loss: 2.321896510069495
Validation loss: 2.5769094177507035

Epoch: 5| Step: 6
Training loss: 2.9803257179187135
Validation loss: 2.55255324051719

Epoch: 5| Step: 7
Training loss: 2.393581880487361
Validation loss: 2.5563566478733715

Epoch: 5| Step: 8
Training loss: 2.128100545465394
Validation loss: 2.575523791954378

Epoch: 5| Step: 9
Training loss: 2.8960889159193877
Validation loss: 2.5538659411867375

Epoch: 5| Step: 10
Training loss: 3.052667052050759
Validation loss: 2.5484021483506822

Epoch: 142| Step: 0
Training loss: 2.371775797703129
Validation loss: 2.5946878199871883

Epoch: 5| Step: 1
Training loss: 2.50206242366527
Validation loss: 2.5616387081054284

Epoch: 5| Step: 2
Training loss: 2.7972665864250024
Validation loss: 2.561004218120279

Epoch: 5| Step: 3
Training loss: 2.7680775602973586
Validation loss: 2.559875876437232

Epoch: 5| Step: 4
Training loss: 2.6569938067047105
Validation loss: 2.5435085639502466

Epoch: 5| Step: 5
Training loss: 2.3297615187902894
Validation loss: 2.53756677384221

Epoch: 5| Step: 6
Training loss: 3.253855985365446
Validation loss: 2.567236986216894

Epoch: 5| Step: 7
Training loss: 2.4251043631522697
Validation loss: 2.584098267676129

Epoch: 5| Step: 8
Training loss: 3.33933815503307
Validation loss: 2.584057495708711

Epoch: 5| Step: 9
Training loss: 2.8759311329179322
Validation loss: 2.576131661251974

Epoch: 5| Step: 10
Training loss: 3.03508728027534
Validation loss: 2.560055589049928

Epoch: 143| Step: 0
Training loss: 3.668080288589665
Validation loss: 2.542843263066404

Epoch: 5| Step: 1
Training loss: 2.8101106454915232
Validation loss: 2.5578530187544204

Epoch: 5| Step: 2
Training loss: 2.780951666100915
Validation loss: 2.5810671120734425

Epoch: 5| Step: 3
Training loss: 3.1064988832912284
Validation loss: 2.5848532726250943

Epoch: 5| Step: 4
Training loss: 2.3734492208104787
Validation loss: 2.579571483409659

Epoch: 5| Step: 5
Training loss: 2.726977122788244
Validation loss: 2.568581417683547

Epoch: 5| Step: 6
Training loss: 2.4633172049228844
Validation loss: 2.5376837008985

Epoch: 5| Step: 7
Training loss: 2.0295871677517785
Validation loss: 2.5770874739913814

Epoch: 5| Step: 8
Training loss: 2.5850948562779257
Validation loss: 2.5703688547176697

Epoch: 5| Step: 9
Training loss: 2.925426425987286
Validation loss: 2.5680095310662363

Epoch: 5| Step: 10
Training loss: 2.577448438245224
Validation loss: 2.548089581372736

Epoch: 144| Step: 0
Training loss: 2.380578967285568
Validation loss: 2.5626763563999995

Epoch: 5| Step: 1
Training loss: 2.565929815698745
Validation loss: 2.559022543279725

Epoch: 5| Step: 2
Training loss: 2.9654575762906785
Validation loss: 2.5755149817767573

Epoch: 5| Step: 3
Training loss: 2.5916830812611074
Validation loss: 2.578872141835706

Epoch: 5| Step: 4
Training loss: 2.2115609196571957
Validation loss: 2.600827803495889

Epoch: 5| Step: 5
Training loss: 2.846131386142864
Validation loss: 2.555565878126612

Epoch: 5| Step: 6
Training loss: 3.309573194064104
Validation loss: 2.5557482249836747

Epoch: 5| Step: 7
Training loss: 2.9710892947351883
Validation loss: 2.5870506043002286

Epoch: 5| Step: 8
Training loss: 2.9363974267318254
Validation loss: 2.581294705890374

Epoch: 5| Step: 9
Training loss: 2.4313970604673796
Validation loss: 2.537418012528581

Epoch: 5| Step: 10
Training loss: 3.054811128812196
Validation loss: 2.555961479638609

Epoch: 145| Step: 0
Training loss: 2.7481005784720094
Validation loss: 2.5455051192893037

Epoch: 5| Step: 1
Training loss: 2.851899427601508
Validation loss: 2.5682486074901374

Epoch: 5| Step: 2
Training loss: 2.3148365073423864
Validation loss: 2.557627174445555

Epoch: 5| Step: 3
Training loss: 2.8146824316447354
Validation loss: 2.5804421669969226

Epoch: 5| Step: 4
Training loss: 3.288303894849564
Validation loss: 2.548082614099763

Epoch: 5| Step: 5
Training loss: 2.3650501031387146
Validation loss: 2.567027287811641

Epoch: 5| Step: 6
Training loss: 2.614291191244232
Validation loss: 2.5441859650323235

Epoch: 5| Step: 7
Training loss: 2.5554685186224484
Validation loss: 2.5797149657734773

Epoch: 5| Step: 8
Training loss: 3.0164752611448074
Validation loss: 2.5517095181944374

Epoch: 5| Step: 9
Training loss: 3.2774418121689544
Validation loss: 2.53833239436697

Epoch: 5| Step: 10
Training loss: 2.0211209620121
Validation loss: 2.5147093335241255

Epoch: 146| Step: 0
Training loss: 2.9072854443251965
Validation loss: 2.5486505669348576

Epoch: 5| Step: 1
Training loss: 3.3820181039407964
Validation loss: 2.581599736204817

Epoch: 5| Step: 2
Training loss: 1.9532329071753967
Validation loss: 2.5774659250016807

Epoch: 5| Step: 3
Training loss: 2.8774059014465942
Validation loss: 2.5353849963756554

Epoch: 5| Step: 4
Training loss: 2.157053700917095
Validation loss: 2.5624570585345006

Epoch: 5| Step: 5
Training loss: 2.900315162370576
Validation loss: 2.5668376483174793

Epoch: 5| Step: 6
Training loss: 2.6680715158534443
Validation loss: 2.5588324427881903

Epoch: 5| Step: 7
Training loss: 2.7354032490486673
Validation loss: 2.579431336473053

Epoch: 5| Step: 8
Training loss: 3.4712827216787865
Validation loss: 2.5421258199652614

Epoch: 5| Step: 9
Training loss: 2.118221691960382
Validation loss: 2.5578165331256644

Epoch: 5| Step: 10
Training loss: 2.9506009734342515
Validation loss: 2.5238086190446096

Epoch: 147| Step: 0
Training loss: 2.475787405510157
Validation loss: 2.586851490779493

Epoch: 5| Step: 1
Training loss: 2.5286722126196017
Validation loss: 2.55372161985349

Epoch: 5| Step: 2
Training loss: 2.498299401756697
Validation loss: 2.5629608436212843

Epoch: 5| Step: 3
Training loss: 3.163799962584087
Validation loss: 2.5146171473416032

Epoch: 5| Step: 4
Training loss: 2.7566835507940968
Validation loss: 2.5827121470726206

Epoch: 5| Step: 5
Training loss: 2.000593693353303
Validation loss: 2.5599290369533674

Epoch: 5| Step: 6
Training loss: 3.204857483312212
Validation loss: 2.577304387059711

Epoch: 5| Step: 7
Training loss: 2.3577047334770334
Validation loss: 2.5339560821110125

Epoch: 5| Step: 8
Training loss: 2.7779251112541843
Validation loss: 2.560420193993449

Epoch: 5| Step: 9
Training loss: 3.138318481680286
Validation loss: 2.564350187557143

Epoch: 5| Step: 10
Training loss: 2.8837728580648685
Validation loss: 2.5610275895486434

Epoch: 148| Step: 0
Training loss: 2.894703560049202
Validation loss: 2.5475823966178965

Epoch: 5| Step: 1
Training loss: 2.8909169642459536
Validation loss: 2.5508526813088634

Epoch: 5| Step: 2
Training loss: 2.4752678119375706
Validation loss: 2.5437509227189756

Epoch: 5| Step: 3
Training loss: 2.35080481200804
Validation loss: 2.6134370710503996

Epoch: 5| Step: 4
Training loss: 2.855151115733939
Validation loss: 2.5283535461582574

Epoch: 5| Step: 5
Training loss: 3.1580714644788928
Validation loss: 2.588906228038835

Epoch: 5| Step: 6
Training loss: 3.377557844885034
Validation loss: 2.555574561462006

Epoch: 5| Step: 7
Training loss: 2.305792385280456
Validation loss: 2.573548737058106

Epoch: 5| Step: 8
Training loss: 2.254223039337031
Validation loss: 2.5522093938683748

Epoch: 5| Step: 9
Training loss: 2.7111577101213404
Validation loss: 2.566712328036286

Epoch: 5| Step: 10
Training loss: 2.811163097105291
Validation loss: 2.551001336520948

Epoch: 149| Step: 0
Training loss: 2.235474002762906
Validation loss: 2.5549296422103667

Epoch: 5| Step: 1
Training loss: 2.810939271002864
Validation loss: 2.5839088839468607

Epoch: 5| Step: 2
Training loss: 2.498695605450718
Validation loss: 2.5779925091391513

Epoch: 5| Step: 3
Training loss: 2.751128918671104
Validation loss: 2.557042690309018

Epoch: 5| Step: 4
Training loss: 3.1856676706768403
Validation loss: 2.543635110587898

Epoch: 5| Step: 5
Training loss: 3.039664162355715
Validation loss: 2.536240534087737

Epoch: 5| Step: 6
Training loss: 2.2359498349535283
Validation loss: 2.5775574408384765

Epoch: 5| Step: 7
Training loss: 2.2418716686724927
Validation loss: 2.574419315579112

Epoch: 5| Step: 8
Training loss: 2.856214767672814
Validation loss: 2.578429488581523

Epoch: 5| Step: 9
Training loss: 3.1280633788846632
Validation loss: 2.552445621320011

Epoch: 5| Step: 10
Training loss: 3.063220659438468
Validation loss: 2.596761549196138

Epoch: 150| Step: 0
Training loss: 3.039846284895178
Validation loss: 2.5518618887951865

Epoch: 5| Step: 1
Training loss: 2.1547711594725842
Validation loss: 2.570166858893442

Epoch: 5| Step: 2
Training loss: 2.673165795918211
Validation loss: 2.5507278324978717

Epoch: 5| Step: 3
Training loss: 2.6895413297706874
Validation loss: 2.539744602712274

Epoch: 5| Step: 4
Training loss: 2.3567470036490943
Validation loss: 2.573018330134888

Epoch: 5| Step: 5
Training loss: 2.366363784948042
Validation loss: 2.565499562784843

Epoch: 5| Step: 6
Training loss: 3.3416864320038866
Validation loss: 2.5472333122416937

Epoch: 5| Step: 7
Training loss: 2.925043845866954
Validation loss: 2.5248817479512384

Epoch: 5| Step: 8
Training loss: 3.3212169896252326
Validation loss: 2.5642319455567724

Epoch: 5| Step: 9
Training loss: 2.6147575371043943
Validation loss: 2.5561326947808474

Epoch: 5| Step: 10
Training loss: 2.3270906544441847
Validation loss: 2.5818040815579195

Epoch: 151| Step: 0
Training loss: 2.920305126133932
Validation loss: 2.546505444553975

Epoch: 5| Step: 1
Training loss: 2.9484202535556476
Validation loss: 2.571243528941544

Epoch: 5| Step: 2
Training loss: 2.5514190016771336
Validation loss: 2.5671682666976343

Epoch: 5| Step: 3
Training loss: 2.745270824170317
Validation loss: 2.5727333836220216

Epoch: 5| Step: 4
Training loss: 2.7812428849375723
Validation loss: 2.583597263193994

Epoch: 5| Step: 5
Training loss: 2.5988386861797843
Validation loss: 2.503871631125431

Epoch: 5| Step: 6
Training loss: 2.4215344589525825
Validation loss: 2.5827825622707445

Epoch: 5| Step: 7
Training loss: 2.47933737116368
Validation loss: 2.563729284217634

Epoch: 5| Step: 8
Training loss: 2.204960917085385
Validation loss: 2.570833057899425

Epoch: 5| Step: 9
Training loss: 3.2021682426861604
Validation loss: 2.5595693159175203

Epoch: 5| Step: 10
Training loss: 3.289508707763539
Validation loss: 2.566760298610288

Epoch: 152| Step: 0
Training loss: 3.0092533772294248
Validation loss: 2.5707820111055484

Epoch: 5| Step: 1
Training loss: 3.138886383265693
Validation loss: 2.524751136956981

Epoch: 5| Step: 2
Training loss: 2.7103764285932814
Validation loss: 2.529802829076717

Epoch: 5| Step: 3
Training loss: 3.2950211506050415
Validation loss: 2.5419538262748462

Epoch: 5| Step: 4
Training loss: 2.801512299580955
Validation loss: 2.559751253396659

Epoch: 5| Step: 5
Training loss: 2.255873220161788
Validation loss: 2.553557490564765

Epoch: 5| Step: 6
Training loss: 2.6186665014097286
Validation loss: 2.542852391100755

Epoch: 5| Step: 7
Training loss: 2.693573232988962
Validation loss: 2.5838324381903837

Epoch: 5| Step: 8
Training loss: 2.7322148100766346
Validation loss: 2.5436212896984958

Epoch: 5| Step: 9
Training loss: 2.7161888248385337
Validation loss: 2.5452576708658996

Epoch: 5| Step: 10
Training loss: 2.222044956236624
Validation loss: 2.5437524797989295

Epoch: 153| Step: 0
Training loss: 2.83455268950587
Validation loss: 2.554545891542389

Epoch: 5| Step: 1
Training loss: 2.9776847906286705
Validation loss: 2.548904870279359

Epoch: 5| Step: 2
Training loss: 3.186930437251093
Validation loss: 2.5629932420075345

Epoch: 5| Step: 3
Training loss: 2.741546121128978
Validation loss: 2.587816290071256

Epoch: 5| Step: 4
Training loss: 2.547866628243355
Validation loss: 2.56243180174958

Epoch: 5| Step: 5
Training loss: 2.668867951049043
Validation loss: 2.5664897925144534

Epoch: 5| Step: 6
Training loss: 2.7895003971442134
Validation loss: 2.576980459073726

Epoch: 5| Step: 7
Training loss: 2.8323905348605747
Validation loss: 2.572238582836731

Epoch: 5| Step: 8
Training loss: 2.619703216778619
Validation loss: 2.545595049892348

Epoch: 5| Step: 9
Training loss: 2.247990664683334
Validation loss: 2.566289712569948

Epoch: 5| Step: 10
Training loss: 3.003217719926214
Validation loss: 2.512996199139251

Epoch: 154| Step: 0
Training loss: 2.8807928355663126
Validation loss: 2.553794785897115

Epoch: 5| Step: 1
Training loss: 2.110790879517543
Validation loss: 2.552589321809936

Epoch: 5| Step: 2
Training loss: 3.061411294297779
Validation loss: 2.5629577397963748

Epoch: 5| Step: 3
Training loss: 3.056937479345057
Validation loss: 2.503799752327438

Epoch: 5| Step: 4
Training loss: 2.681364907956916
Validation loss: 2.538361921690442

Epoch: 5| Step: 5
Training loss: 2.4166613173151554
Validation loss: 2.496421147370773

Epoch: 5| Step: 6
Training loss: 3.3340483057633663
Validation loss: 2.5567325804347685

Epoch: 5| Step: 7
Training loss: 2.5255850048150488
Validation loss: 2.5205451667061025

Epoch: 5| Step: 8
Training loss: 2.7169249097874575
Validation loss: 2.596444756421986

Epoch: 5| Step: 9
Training loss: 2.9840819529511435
Validation loss: 2.5426638331735796

Epoch: 5| Step: 10
Training loss: 2.100671288508919
Validation loss: 2.576847773564926

Epoch: 155| Step: 0
Training loss: 2.7670768763068527
Validation loss: 2.59368146995354

Epoch: 5| Step: 1
Training loss: 2.6123404641241708
Validation loss: 2.575653673628166

Epoch: 5| Step: 2
Training loss: 2.5186741516960613
Validation loss: 2.549985271751534

Epoch: 5| Step: 3
Training loss: 3.156729029194195
Validation loss: 2.5283264368706377

Epoch: 5| Step: 4
Training loss: 2.8902656950467143
Validation loss: 2.5487824989704397

Epoch: 5| Step: 5
Training loss: 2.5207130676669323
Validation loss: 2.5529807673639393

Epoch: 5| Step: 6
Training loss: 2.343483057714921
Validation loss: 2.577186769243779

Epoch: 5| Step: 7
Training loss: 2.9553895371480525
Validation loss: 2.546732772921489

Epoch: 5| Step: 8
Training loss: 2.979850814976582
Validation loss: 2.506884467356687

Epoch: 5| Step: 9
Training loss: 2.3268337893467703
Validation loss: 2.5511684027496897

Epoch: 5| Step: 10
Training loss: 2.956036620877232
Validation loss: 2.5296138021179218

Epoch: 156| Step: 0
Training loss: 2.412709471152194
Validation loss: 2.521135663098701

Epoch: 5| Step: 1
Training loss: 2.8033901603766087
Validation loss: 2.5341234668043

Epoch: 5| Step: 2
Training loss: 2.166529272075841
Validation loss: 2.5496308604637257

Epoch: 5| Step: 3
Training loss: 3.0637089425631165
Validation loss: 2.5540233645800483

Epoch: 5| Step: 4
Training loss: 2.935936532012796
Validation loss: 2.5603214089966393

Epoch: 5| Step: 5
Training loss: 2.492083221454253
Validation loss: 2.5799290683843648

Epoch: 5| Step: 6
Training loss: 2.8612601314446966
Validation loss: 2.5388999908414682

Epoch: 5| Step: 7
Training loss: 2.3738772097345247
Validation loss: 2.5508128382540947

Epoch: 5| Step: 8
Training loss: 2.687288231601398
Validation loss: 2.5642371703463374

Epoch: 5| Step: 9
Training loss: 3.506563299804683
Validation loss: 2.535461658171582

Epoch: 5| Step: 10
Training loss: 2.7181123884710625
Validation loss: 2.58730417824074

Epoch: 157| Step: 0
Training loss: 2.42283719545569
Validation loss: 2.5908528701179185

Epoch: 5| Step: 1
Training loss: 2.8671046772566013
Validation loss: 2.5946431130247793

Epoch: 5| Step: 2
Training loss: 2.5765817358109753
Validation loss: 2.5662128932983737

Epoch: 5| Step: 3
Training loss: 2.511392954910603
Validation loss: 2.584663179487715

Epoch: 5| Step: 4
Training loss: 2.4646616050778993
Validation loss: 2.555745367184075

Epoch: 5| Step: 5
Training loss: 2.9052762276772315
Validation loss: 2.5580500279480667

Epoch: 5| Step: 6
Training loss: 2.6299894235492576
Validation loss: 2.583193159584184

Epoch: 5| Step: 7
Training loss: 2.732255212092448
Validation loss: 2.5300311768978845

Epoch: 5| Step: 8
Training loss: 2.8134698679035677
Validation loss: 2.596271214179458

Epoch: 5| Step: 9
Training loss: 3.202372988371722
Validation loss: 2.563565299643416

Epoch: 5| Step: 10
Training loss: 3.2575480035859035
Validation loss: 2.5765545906941427

Epoch: 158| Step: 0
Training loss: 2.996990124477119
Validation loss: 2.553600132928295

Epoch: 5| Step: 1
Training loss: 3.105304910428436
Validation loss: 2.602615972383451

Epoch: 5| Step: 2
Training loss: 2.704234165785367
Validation loss: 2.596089704054413

Epoch: 5| Step: 3
Training loss: 2.2865399206344037
Validation loss: 2.5599366689915515

Epoch: 5| Step: 4
Training loss: 2.9377486752703565
Validation loss: 2.601587618321906

Epoch: 5| Step: 5
Training loss: 2.4353396305358213
Validation loss: 2.5208418630809746

Epoch: 5| Step: 6
Training loss: 2.7637976520075913
Validation loss: 2.535632435631897

Epoch: 5| Step: 7
Training loss: 2.614159588968872
Validation loss: 2.5435773411295393

Epoch: 5| Step: 8
Training loss: 3.1817572228673505
Validation loss: 2.529052653661029

Epoch: 5| Step: 9
Training loss: 1.7479428052558117
Validation loss: 2.5700643517949286

Epoch: 5| Step: 10
Training loss: 3.0919879557879577
Validation loss: 2.5644972696292565

Epoch: 159| Step: 0
Training loss: 2.774342220118761
Validation loss: 2.589699502305589

Epoch: 5| Step: 1
Training loss: 2.5388714058197803
Validation loss: 2.526545871202467

Epoch: 5| Step: 2
Training loss: 2.6529510656704622
Validation loss: 2.558870473333651

Epoch: 5| Step: 3
Training loss: 3.270773156132873
Validation loss: 2.5470208245122645

Epoch: 5| Step: 4
Training loss: 2.5599834832016275
Validation loss: 2.5578955143392763

Epoch: 5| Step: 5
Training loss: 2.809535265330373
Validation loss: 2.5677792541564672

Epoch: 5| Step: 6
Training loss: 1.7549696249656295
Validation loss: 2.6033438165596534

Epoch: 5| Step: 7
Training loss: 2.8299229423357284
Validation loss: 2.537388778335105

Epoch: 5| Step: 8
Training loss: 2.6655982281144333
Validation loss: 2.5778358563328587

Epoch: 5| Step: 9
Training loss: 2.9125797702850864
Validation loss: 2.5499707327676613

Epoch: 5| Step: 10
Training loss: 2.86805450053551
Validation loss: 2.5571956464033905

Epoch: 160| Step: 0
Training loss: 3.707462394250973
Validation loss: 2.5776599513076035

Epoch: 5| Step: 1
Training loss: 3.3286479127237056
Validation loss: 2.52875949974239

Epoch: 5| Step: 2
Training loss: 2.557040656072774
Validation loss: 2.6043734665662757

Epoch: 5| Step: 3
Training loss: 2.3161549938499126
Validation loss: 2.5184285408954357

Epoch: 5| Step: 4
Training loss: 2.561829735159904
Validation loss: 2.520295763033602

Epoch: 5| Step: 5
Training loss: 2.3120324976791973
Validation loss: 2.5424034050113216

Epoch: 5| Step: 6
Training loss: 2.6710210852210268
Validation loss: 2.5391124615040948

Epoch: 5| Step: 7
Training loss: 2.538303109095724
Validation loss: 2.5797142507566178

Epoch: 5| Step: 8
Training loss: 3.038504188854851
Validation loss: 2.540569230551167

Epoch: 5| Step: 9
Training loss: 2.2952682168842413
Validation loss: 2.551205628584863

Epoch: 5| Step: 10
Training loss: 2.3051075698013994
Validation loss: 2.5592492506418734

Epoch: 161| Step: 0
Training loss: 3.0455500925466548
Validation loss: 2.500088992637083

Epoch: 5| Step: 1
Training loss: 2.650549662463164
Validation loss: 2.5177049750547758

Epoch: 5| Step: 2
Training loss: 2.7160387222271347
Validation loss: 2.5685695555174894

Epoch: 5| Step: 3
Training loss: 2.520725836445367
Validation loss: 2.50453453544417

Epoch: 5| Step: 4
Training loss: 2.627524478990693
Validation loss: 2.5325425135993203

Epoch: 5| Step: 5
Training loss: 3.0836848668586843
Validation loss: 2.5289740073792304

Epoch: 5| Step: 6
Training loss: 2.939993591301609
Validation loss: 2.553542202388718

Epoch: 5| Step: 7
Training loss: 2.191421916722073
Validation loss: 2.54338266619355

Epoch: 5| Step: 8
Training loss: 2.56037833606987
Validation loss: 2.5559952024304113

Epoch: 5| Step: 9
Training loss: 2.6693762086987465
Validation loss: 2.5557409214887703

Epoch: 5| Step: 10
Training loss: 2.874563266919847
Validation loss: 2.570616476879761

Epoch: 162| Step: 0
Training loss: 2.933670144540414
Validation loss: 2.530973970612313

Epoch: 5| Step: 1
Training loss: 2.6390790759255465
Validation loss: 2.5610822631929326

Epoch: 5| Step: 2
Training loss: 2.605853050977936
Validation loss: 2.556272644822003

Epoch: 5| Step: 3
Training loss: 2.395504926204692
Validation loss: 2.581408883086187

Epoch: 5| Step: 4
Training loss: 2.8465810245016274
Validation loss: 2.564563041807929

Epoch: 5| Step: 5
Training loss: 2.764444045175494
Validation loss: 2.545189318826278

Epoch: 5| Step: 6
Training loss: 2.677133661135992
Validation loss: 2.6121715022167256

Epoch: 5| Step: 7
Training loss: 2.416076610045284
Validation loss: 2.5532693530887056

Epoch: 5| Step: 8
Training loss: 3.0105836463386235
Validation loss: 2.548267519571342

Epoch: 5| Step: 9
Training loss: 3.082754768182898
Validation loss: 2.53008939041916

Epoch: 5| Step: 10
Training loss: 2.8781033228286717
Validation loss: 2.5880572702529725

Epoch: 163| Step: 0
Training loss: 2.992360082684054
Validation loss: 2.5490965307764486

Epoch: 5| Step: 1
Training loss: 2.222027574067656
Validation loss: 2.5723174281924353

Epoch: 5| Step: 2
Training loss: 2.189105289539305
Validation loss: 2.5433950157503933

Epoch: 5| Step: 3
Training loss: 2.285245349157759
Validation loss: 2.53242698761381

Epoch: 5| Step: 4
Training loss: 2.9068511013114025
Validation loss: 2.538903362376554

Epoch: 5| Step: 5
Training loss: 2.5123139383685023
Validation loss: 2.545670521026269

Epoch: 5| Step: 6
Training loss: 3.131021572773392
Validation loss: 2.5408716392326225

Epoch: 5| Step: 7
Training loss: 2.562092632384978
Validation loss: 2.5791622473009443

Epoch: 5| Step: 8
Training loss: 2.4787885126381726
Validation loss: 2.543775516408336

Epoch: 5| Step: 9
Training loss: 3.064601099588194
Validation loss: 2.564805023321894

Epoch: 5| Step: 10
Training loss: 3.4558417908695573
Validation loss: 2.56767602372833

Epoch: 164| Step: 0
Training loss: 2.946724874286911
Validation loss: 2.537029120182207

Epoch: 5| Step: 1
Training loss: 2.4482887364068002
Validation loss: 2.5697975474433052

Epoch: 5| Step: 2
Training loss: 2.4232273386985113
Validation loss: 2.549681286536029

Epoch: 5| Step: 3
Training loss: 2.545671986296822
Validation loss: 2.5376972242875313

Epoch: 5| Step: 4
Training loss: 2.5114645347270774
Validation loss: 2.5814804038875074

Epoch: 5| Step: 5
Training loss: 2.8195531779234857
Validation loss: 2.551784858720241

Epoch: 5| Step: 6
Training loss: 1.7761931667054263
Validation loss: 2.54513224440867

Epoch: 5| Step: 7
Training loss: 2.6585530787161415
Validation loss: 2.53780131858281

Epoch: 5| Step: 8
Training loss: 3.4631354454666456
Validation loss: 2.5382120212181474

Epoch: 5| Step: 9
Training loss: 3.1674345156336914
Validation loss: 2.5087142119063883

Epoch: 5| Step: 10
Training loss: 2.937354226249171
Validation loss: 2.5469883850051325

Epoch: 165| Step: 0
Training loss: 2.6728385392562704
Validation loss: 2.527608574800265

Epoch: 5| Step: 1
Training loss: 2.945359287851601
Validation loss: 2.5487405142953388

Epoch: 5| Step: 2
Training loss: 2.5502323418776167
Validation loss: 2.5588898573281376

Epoch: 5| Step: 3
Training loss: 2.681766070872069
Validation loss: 2.566542283639931

Epoch: 5| Step: 4
Training loss: 2.8017794268184226
Validation loss: 2.5568804907309612

Epoch: 5| Step: 5
Training loss: 3.6471629887929726
Validation loss: 2.557739220319944

Epoch: 5| Step: 6
Training loss: 2.506494954379391
Validation loss: 2.6103395454293987

Epoch: 5| Step: 7
Training loss: 2.829267408087699
Validation loss: 2.5270320712004017

Epoch: 5| Step: 8
Training loss: 2.1542599105084617
Validation loss: 2.5434159590586423

Epoch: 5| Step: 9
Training loss: 2.250315538109518
Validation loss: 2.525671499312271

Epoch: 5| Step: 10
Training loss: 2.8463119871336287
Validation loss: 2.5313363697949725

Epoch: 166| Step: 0
Training loss: 2.6145208181579935
Validation loss: 2.5387734505298125

Epoch: 5| Step: 1
Training loss: 2.7910336493196426
Validation loss: 2.606415247317014

Epoch: 5| Step: 2
Training loss: 2.253227673861731
Validation loss: 2.517891441402764

Epoch: 5| Step: 3
Training loss: 2.4946436721982987
Validation loss: 2.5734136276761164

Epoch: 5| Step: 4
Training loss: 2.7898916513330727
Validation loss: 2.578194719144393

Epoch: 5| Step: 5
Training loss: 3.038561154471855
Validation loss: 2.5457522536369073

Epoch: 5| Step: 6
Training loss: 2.511859800848497
Validation loss: 2.5214519567118097

Epoch: 5| Step: 7
Training loss: 3.154730100377144
Validation loss: 2.565152523937726

Epoch: 5| Step: 8
Training loss: 2.7407273972628468
Validation loss: 2.5610636905912223

Epoch: 5| Step: 9
Training loss: 2.63339580107689
Validation loss: 2.539180094706928

Epoch: 5| Step: 10
Training loss: 2.85400687185742
Validation loss: 2.534111072064149

Epoch: 167| Step: 0
Training loss: 3.1418626159217498
Validation loss: 2.57392862171269

Epoch: 5| Step: 1
Training loss: 2.8956596450495113
Validation loss: 2.5749476010018624

Epoch: 5| Step: 2
Training loss: 2.416172130452847
Validation loss: 2.5196666622951924

Epoch: 5| Step: 3
Training loss: 2.322046729985284
Validation loss: 2.5650539091983613

Epoch: 5| Step: 4
Training loss: 1.719546254988165
Validation loss: 2.5753761550396455

Epoch: 5| Step: 5
Training loss: 2.5199094503271144
Validation loss: 2.5610091822204937

Epoch: 5| Step: 6
Training loss: 2.464648932784838
Validation loss: 2.5563935935797693

Epoch: 5| Step: 7
Training loss: 2.984429164215204
Validation loss: 2.5419900514615126

Epoch: 5| Step: 8
Training loss: 3.26024918943655
Validation loss: 2.5859113701273273

Epoch: 5| Step: 9
Training loss: 3.1381483038922298
Validation loss: 2.585745187395669

Epoch: 5| Step: 10
Training loss: 2.8819800521509675
Validation loss: 2.559805878688486

Epoch: 168| Step: 0
Training loss: 3.161731907143445
Validation loss: 2.554914059213549

Epoch: 5| Step: 1
Training loss: 2.2555377417154823
Validation loss: 2.591198426853411

Epoch: 5| Step: 2
Training loss: 2.619609748080574
Validation loss: 2.550452073697168

Epoch: 5| Step: 3
Training loss: 3.137590755046742
Validation loss: 2.5791452307713767

Epoch: 5| Step: 4
Training loss: 2.447129716927762
Validation loss: 2.530553173152029

Epoch: 5| Step: 5
Training loss: 2.3556640948874468
Validation loss: 2.5548588185804952

Epoch: 5| Step: 6
Training loss: 2.6088420757720003
Validation loss: 2.57595326625286

Epoch: 5| Step: 7
Training loss: 3.4870730504489695
Validation loss: 2.529071098446997

Epoch: 5| Step: 8
Training loss: 2.828625882300281
Validation loss: 2.5524140321806024

Epoch: 5| Step: 9
Training loss: 2.438947199088452
Validation loss: 2.5414177957499766

Epoch: 5| Step: 10
Training loss: 2.4440758841513563
Validation loss: 2.554813663502943

Epoch: 169| Step: 0
Training loss: 2.5022787199404557
Validation loss: 2.570124181182248

Epoch: 5| Step: 1
Training loss: 2.863585826708581
Validation loss: 2.5245454434085572

Epoch: 5| Step: 2
Training loss: 2.513992063911919
Validation loss: 2.525951851171072

Epoch: 5| Step: 3
Training loss: 2.720629689032705
Validation loss: 2.5857763396018383

Epoch: 5| Step: 4
Training loss: 2.881982368515901
Validation loss: 2.582273861117327

Epoch: 5| Step: 5
Training loss: 3.348646625035307
Validation loss: 2.5466618028736145

Epoch: 5| Step: 6
Training loss: 2.2849891014590464
Validation loss: 2.580279017550772

Epoch: 5| Step: 7
Training loss: 2.4428001879981682
Validation loss: 2.5443196510482102

Epoch: 5| Step: 8
Training loss: 3.086731164009854
Validation loss: 2.5433067068349797

Epoch: 5| Step: 9
Training loss: 2.628028212861813
Validation loss: 2.5892072566210897

Epoch: 5| Step: 10
Training loss: 2.6396488891104406
Validation loss: 2.5161388017476853

Epoch: 170| Step: 0
Training loss: 2.852222272239453
Validation loss: 2.5399115998757296

Epoch: 5| Step: 1
Training loss: 2.8022590686094246
Validation loss: 2.562644799336007

Epoch: 5| Step: 2
Training loss: 2.420782224167069
Validation loss: 2.563409878364938

Epoch: 5| Step: 3
Training loss: 3.3450236524079253
Validation loss: 2.527549615446459

Epoch: 5| Step: 4
Training loss: 2.8021184264376213
Validation loss: 2.540090538384194

Epoch: 5| Step: 5
Training loss: 2.640098203219729
Validation loss: 2.5352880874443144

Epoch: 5| Step: 6
Training loss: 2.6296038446022854
Validation loss: 2.5440659288045686

Epoch: 5| Step: 7
Training loss: 2.7524849328400465
Validation loss: 2.5778878031699817

Epoch: 5| Step: 8
Training loss: 2.533700204518955
Validation loss: 2.550934796601322

Epoch: 5| Step: 9
Training loss: 2.2901587871821927
Validation loss: 2.585591285766537

Epoch: 5| Step: 10
Training loss: 2.721797331480352
Validation loss: 2.5183990995010688

Epoch: 171| Step: 0
Training loss: 2.2158176225399604
Validation loss: 2.539984840746385

Epoch: 5| Step: 1
Training loss: 3.1182223253932766
Validation loss: 2.592767900416551

Epoch: 5| Step: 2
Training loss: 2.8057955197568734
Validation loss: 2.5509453177242065

Epoch: 5| Step: 3
Training loss: 2.436193164771193
Validation loss: 2.5695809424972764

Epoch: 5| Step: 4
Training loss: 2.990305017076654
Validation loss: 2.5552887974256375

Epoch: 5| Step: 5
Training loss: 2.610302697383304
Validation loss: 2.5405216811912035

Epoch: 5| Step: 6
Training loss: 2.316952620040376
Validation loss: 2.5487552961663513

Epoch: 5| Step: 7
Training loss: 2.662193201862511
Validation loss: 2.574966820163495

Epoch: 5| Step: 8
Training loss: 3.1679484299691256
Validation loss: 2.5591156903808963

Epoch: 5| Step: 9
Training loss: 2.8417878140963797
Validation loss: 2.5546413805197

Epoch: 5| Step: 10
Training loss: 2.3615946654778996
Validation loss: 2.5609000198464686

Epoch: 172| Step: 0
Training loss: 2.8683108589966135
Validation loss: 2.5693931028659014

Epoch: 5| Step: 1
Training loss: 2.6770275026033676
Validation loss: 2.5534039771796153

Epoch: 5| Step: 2
Training loss: 2.7868018298094235
Validation loss: 2.599083654136079

Epoch: 5| Step: 3
Training loss: 2.220310897880261
Validation loss: 2.554666049999311

Epoch: 5| Step: 4
Training loss: 2.891615909127277
Validation loss: 2.5759829087149306

Epoch: 5| Step: 5
Training loss: 2.0661737495102592
Validation loss: 2.5615095499933043

Epoch: 5| Step: 6
Training loss: 3.3376457611143473
Validation loss: 2.5227527116575277

Epoch: 5| Step: 7
Training loss: 2.4420355634232034
Validation loss: 2.5931160116533847

Epoch: 5| Step: 8
Training loss: 2.8692905290783624
Validation loss: 2.5679268885715683

Epoch: 5| Step: 9
Training loss: 2.9750461670955795
Validation loss: 2.5744573319595463

Epoch: 5| Step: 10
Training loss: 2.3578944329144167
Validation loss: 2.5479048843466208

Epoch: 173| Step: 0
Training loss: 2.9104990098063914
Validation loss: 2.5957314525613353

Epoch: 5| Step: 1
Training loss: 2.6946735896393292
Validation loss: 2.565151457566389

Epoch: 5| Step: 2
Training loss: 2.9707835410405257
Validation loss: 2.5583336798239555

Epoch: 5| Step: 3
Training loss: 2.7493203797218695
Validation loss: 2.5241780778086516

Epoch: 5| Step: 4
Training loss: 2.744128287616839
Validation loss: 2.552839261061524

Epoch: 5| Step: 5
Training loss: 2.4160169078727898
Validation loss: 2.5620396678562862

Epoch: 5| Step: 6
Training loss: 2.3802675758741008
Validation loss: 2.5335875569474866

Epoch: 5| Step: 7
Training loss: 2.597860824445701
Validation loss: 2.58154785810217

Epoch: 5| Step: 8
Training loss: 2.604026933100068
Validation loss: 2.5885964636628134

Epoch: 5| Step: 9
Training loss: 1.9396963898528938
Validation loss: 2.535787965099383

Epoch: 5| Step: 10
Training loss: 3.6797450358758192
Validation loss: 2.531745835748254

Epoch: 174| Step: 0
Training loss: 1.9907976875078668
Validation loss: 2.5444202190102776

Epoch: 5| Step: 1
Training loss: 2.729001154260891
Validation loss: 2.564017968981125

Epoch: 5| Step: 2
Training loss: 2.7473209509505323
Validation loss: 2.5520684726291627

Epoch: 5| Step: 3
Training loss: 2.486271644064629
Validation loss: 2.5443845926608355

Epoch: 5| Step: 4
Training loss: 2.9173681414699395
Validation loss: 2.5649008200218573

Epoch: 5| Step: 5
Training loss: 2.9262761714763847
Validation loss: 2.534502749723724

Epoch: 5| Step: 6
Training loss: 3.0377647943815345
Validation loss: 2.5643296596565692

Epoch: 5| Step: 7
Training loss: 2.7061593549317577
Validation loss: 2.586793269248236

Epoch: 5| Step: 8
Training loss: 3.0619646499755993
Validation loss: 2.542703458095378

Epoch: 5| Step: 9
Training loss: 2.7077869940171184
Validation loss: 2.5469124003168826

Epoch: 5| Step: 10
Training loss: 2.367370094836055
Validation loss: 2.5801510861512056

Epoch: 175| Step: 0
Training loss: 3.3296923461477816
Validation loss: 2.57257012945559

Epoch: 5| Step: 1
Training loss: 2.488105420378377
Validation loss: 2.542837760420633

Epoch: 5| Step: 2
Training loss: 2.78790678126777
Validation loss: 2.556700784559571

Epoch: 5| Step: 3
Training loss: 3.095443416255142
Validation loss: 2.5820614114553924

Epoch: 5| Step: 4
Training loss: 2.6334455957103815
Validation loss: 2.5720034441621467

Epoch: 5| Step: 5
Training loss: 2.595470639072489
Validation loss: 2.5599406637601096

Epoch: 5| Step: 6
Training loss: 2.2071376538579086
Validation loss: 2.569373486806672

Epoch: 5| Step: 7
Training loss: 2.894259420750754
Validation loss: 2.570447207884121

Epoch: 5| Step: 8
Training loss: 2.268982182331495
Validation loss: 2.587061339251195

Epoch: 5| Step: 9
Training loss: 2.4637001637180003
Validation loss: 2.543930133340257

Epoch: 5| Step: 10
Training loss: 2.891093942905789
Validation loss: 2.56597801320814

Epoch: 176| Step: 0
Training loss: 2.7452443357026564
Validation loss: 2.576610384036425

Epoch: 5| Step: 1
Training loss: 2.8868905353148784
Validation loss: 2.5418939994791945

Epoch: 5| Step: 2
Training loss: 2.1404814289145504
Validation loss: 2.5434668197967762

Epoch: 5| Step: 3
Training loss: 2.8936369179696873
Validation loss: 2.550355511115689

Epoch: 5| Step: 4
Training loss: 2.8969158280837988
Validation loss: 2.5535543953891526

Epoch: 5| Step: 5
Training loss: 2.217649804939597
Validation loss: 2.537778735868798

Epoch: 5| Step: 6
Training loss: 2.883080115987101
Validation loss: 2.5722819918837967

Epoch: 5| Step: 7
Training loss: 2.7335761947046326
Validation loss: 2.565767296667322

Epoch: 5| Step: 8
Training loss: 2.1747124887492424
Validation loss: 2.566504598017288

Epoch: 5| Step: 9
Training loss: 2.8189819240525056
Validation loss: 2.537433208922373

Epoch: 5| Step: 10
Training loss: 2.863530708885019
Validation loss: 2.562557906110074

Epoch: 177| Step: 0
Training loss: 2.63055531444591
Validation loss: 2.5616165707229355

Epoch: 5| Step: 1
Training loss: 2.9305301522534455
Validation loss: 2.522782637271376

Epoch: 5| Step: 2
Training loss: 2.521135254321167
Validation loss: 2.5744257106832866

Epoch: 5| Step: 3
Training loss: 2.748167814780568
Validation loss: 2.578311143546002

Epoch: 5| Step: 4
Training loss: 2.5597787689937985
Validation loss: 2.5639721963096225

Epoch: 5| Step: 5
Training loss: 1.7482535639633408
Validation loss: 2.565270381722826

Epoch: 5| Step: 6
Training loss: 2.7876545747741552
Validation loss: 2.5886357137810245

Epoch: 5| Step: 7
Training loss: 2.2884276880129204
Validation loss: 2.541979210887241

Epoch: 5| Step: 8
Training loss: 2.7643973864123916
Validation loss: 2.5492661585004788

Epoch: 5| Step: 9
Training loss: 3.022296542378938
Validation loss: 2.525142718196466

Epoch: 5| Step: 10
Training loss: 3.1264343021920116
Validation loss: 2.5802080476727514

Epoch: 178| Step: 0
Training loss: 2.651413317537237
Validation loss: 2.6182729229481887

Epoch: 5| Step: 1
Training loss: 2.7010798131738
Validation loss: 2.549018393797185

Epoch: 5| Step: 2
Training loss: 2.656641583469859
Validation loss: 2.5604230826205105

Epoch: 5| Step: 3
Training loss: 1.825876989372289
Validation loss: 2.5140252641674246

Epoch: 5| Step: 4
Training loss: 3.036311377780104
Validation loss: 2.5272327459643633

Epoch: 5| Step: 5
Training loss: 2.616403490750215
Validation loss: 2.5362629677598845

Epoch: 5| Step: 6
Training loss: 3.1804333311210997
Validation loss: 2.560626671054733

Epoch: 5| Step: 7
Training loss: 2.371222151621414
Validation loss: 2.529020402331499

Epoch: 5| Step: 8
Training loss: 3.1705746545597564
Validation loss: 2.548127923670537

Epoch: 5| Step: 9
Training loss: 2.3274283166780676
Validation loss: 2.5648980119006812

Epoch: 5| Step: 10
Training loss: 2.8615987500007507
Validation loss: 2.566404265639928

Epoch: 179| Step: 0
Training loss: 2.4114464470479082
Validation loss: 2.54834744057954

Epoch: 5| Step: 1
Training loss: 2.426082672213742
Validation loss: 2.5425972131948584

Epoch: 5| Step: 2
Training loss: 2.64965387279157
Validation loss: 2.571254638968876

Epoch: 5| Step: 3
Training loss: 3.2426176590112714
Validation loss: 2.5513171300006516

Epoch: 5| Step: 4
Training loss: 3.0629647349968745
Validation loss: 2.5596649399947937

Epoch: 5| Step: 5
Training loss: 2.825098599764028
Validation loss: 2.5694041181254645

Epoch: 5| Step: 6
Training loss: 3.0778005980905334
Validation loss: 2.557764883266743

Epoch: 5| Step: 7
Training loss: 2.742232710854153
Validation loss: 2.5696246558347937

Epoch: 5| Step: 8
Training loss: 2.1447375811488425
Validation loss: 2.5647855081112896

Epoch: 5| Step: 9
Training loss: 2.2213137147059228
Validation loss: 2.564482688460051

Epoch: 5| Step: 10
Training loss: 2.5985506052620777
Validation loss: 2.5597163742430964

Epoch: 180| Step: 0
Training loss: 2.5164840842535185
Validation loss: 2.5755376875071354

Epoch: 5| Step: 1
Training loss: 2.0327731950436068
Validation loss: 2.559567566138097

Epoch: 5| Step: 2
Training loss: 2.9997033926249417
Validation loss: 2.534702995359604

Epoch: 5| Step: 3
Training loss: 2.607810276549382
Validation loss: 2.5516479559461582

Epoch: 5| Step: 4
Training loss: 2.4129636170813678
Validation loss: 2.5323343161155254

Epoch: 5| Step: 5
Training loss: 3.1452978491027386
Validation loss: 2.5376083150057935

Epoch: 5| Step: 6
Training loss: 2.8390826815033248
Validation loss: 2.545167413070168

Epoch: 5| Step: 7
Training loss: 2.9134339173657144
Validation loss: 2.5813703141124162

Epoch: 5| Step: 8
Training loss: 2.8230625598176684
Validation loss: 2.5303304792958614

Epoch: 5| Step: 9
Training loss: 2.8874983089821886
Validation loss: 2.523617989084969

Epoch: 5| Step: 10
Training loss: 2.333210453703384
Validation loss: 2.5562607646504576

Epoch: 181| Step: 0
Training loss: 2.9438485876206233
Validation loss: 2.55118430607077

Epoch: 5| Step: 1
Training loss: 2.5662414404962774
Validation loss: 2.521883401499539

Epoch: 5| Step: 2
Training loss: 2.7248161428879425
Validation loss: 2.553595345172571

Epoch: 5| Step: 3
Training loss: 2.5895569701526666
Validation loss: 2.576089253527675

Epoch: 5| Step: 4
Training loss: 3.1843831400069997
Validation loss: 2.5595603146067294

Epoch: 5| Step: 5
Training loss: 1.912513697955375
Validation loss: 2.57920180797484

Epoch: 5| Step: 6
Training loss: 2.6899106946110516
Validation loss: 2.539348598923467

Epoch: 5| Step: 7
Training loss: 2.818069030652627
Validation loss: 2.5468498393313945

Epoch: 5| Step: 8
Training loss: 2.415484457134571
Validation loss: 2.540964882679392

Epoch: 5| Step: 9
Training loss: 2.5483703903820434
Validation loss: 2.5929919085213227

Epoch: 5| Step: 10
Training loss: 3.2733827281366414
Validation loss: 2.5434378340380124

Epoch: 182| Step: 0
Training loss: 2.7180190583628243
Validation loss: 2.572775313561567

Epoch: 5| Step: 1
Training loss: 2.8790308020886126
Validation loss: 2.5241474125903114

Epoch: 5| Step: 2
Training loss: 2.513338744193947
Validation loss: 2.581274783008461

Epoch: 5| Step: 3
Training loss: 2.616443494119902
Validation loss: 2.5470931906327965

Epoch: 5| Step: 4
Training loss: 2.8262812046924926
Validation loss: 2.5694230854137388

Epoch: 5| Step: 5
Training loss: 2.825135985620826
Validation loss: 2.5496692137698567

Epoch: 5| Step: 6
Training loss: 3.157173248322283
Validation loss: 2.5382959967920034

Epoch: 5| Step: 7
Training loss: 2.271627747987607
Validation loss: 2.5487046234430846

Epoch: 5| Step: 8
Training loss: 2.573119234046656
Validation loss: 2.560784246466792

Epoch: 5| Step: 9
Training loss: 2.5112007045891906
Validation loss: 2.5553078062822885

Epoch: 5| Step: 10
Training loss: 2.550137355321446
Validation loss: 2.580427306347249

Epoch: 183| Step: 0
Training loss: 2.5220128812287013
Validation loss: 2.5374880388479997

Epoch: 5| Step: 1
Training loss: 2.7698934772818036
Validation loss: 2.5447859670476576

Epoch: 5| Step: 2
Training loss: 2.1218451473962014
Validation loss: 2.5723711986392943

Epoch: 5| Step: 3
Training loss: 3.0956775555923524
Validation loss: 2.5356359166603477

Epoch: 5| Step: 4
Training loss: 2.6427739896175333
Validation loss: 2.5925292537361146

Epoch: 5| Step: 5
Training loss: 3.2096926464165456
Validation loss: 2.5516784896003877

Epoch: 5| Step: 6
Training loss: 2.7517010023014663
Validation loss: 2.550733998548239

Epoch: 5| Step: 7
Training loss: 2.2873993648217645
Validation loss: 2.5385119183405314

Epoch: 5| Step: 8
Training loss: 2.6369745427140776
Validation loss: 2.5348105415543896

Epoch: 5| Step: 9
Training loss: 2.5809828206628267
Validation loss: 2.5472940784256477

Epoch: 5| Step: 10
Training loss: 2.796609279860682
Validation loss: 2.525442479149445

Epoch: 184| Step: 0
Training loss: 2.49563226627598
Validation loss: 2.5943959026563945

Epoch: 5| Step: 1
Training loss: 2.615341400851019
Validation loss: 2.523979178400345

Epoch: 5| Step: 2
Training loss: 2.665887559881998
Validation loss: 2.569003142226663

Epoch: 5| Step: 3
Training loss: 1.8138454310670284
Validation loss: 2.5426551702754114

Epoch: 5| Step: 4
Training loss: 2.934152359483834
Validation loss: 2.536207620092823

Epoch: 5| Step: 5
Training loss: 2.835039821661289
Validation loss: 2.554548877132297

Epoch: 5| Step: 6
Training loss: 2.7327916383901245
Validation loss: 2.534261566128562

Epoch: 5| Step: 7
Training loss: 2.512583724567487
Validation loss: 2.572087272835492

Epoch: 5| Step: 8
Training loss: 2.5571550590455394
Validation loss: 2.5402540779741423

Epoch: 5| Step: 9
Training loss: 3.0619976643778277
Validation loss: 2.5679762186200827

Epoch: 5| Step: 10
Training loss: 3.3964461883275994
Validation loss: 2.518860425182214

Epoch: 185| Step: 0
Training loss: 2.5245799026763955
Validation loss: 2.5626035959996183

Epoch: 5| Step: 1
Training loss: 2.2412787001262036
Validation loss: 2.546609117399624

Epoch: 5| Step: 2
Training loss: 2.6711705935666674
Validation loss: 2.584725783354746

Epoch: 5| Step: 3
Training loss: 2.9031844840304983
Validation loss: 2.534991265563616

Epoch: 5| Step: 4
Training loss: 2.642416442300686
Validation loss: 2.579173313774879

Epoch: 5| Step: 5
Training loss: 3.3626274510163348
Validation loss: 2.5822820495882537

Epoch: 5| Step: 6
Training loss: 2.4756208007283798
Validation loss: 2.556200694023271

Epoch: 5| Step: 7
Training loss: 3.2643690112338564
Validation loss: 2.572649876446102

Epoch: 5| Step: 8
Training loss: 2.0609667309588926
Validation loss: 2.5654379467229473

Epoch: 5| Step: 9
Training loss: 2.633240164142732
Validation loss: 2.5680674057842476

Epoch: 5| Step: 10
Training loss: 2.6878464054150832
Validation loss: 2.559851697816411

Epoch: 186| Step: 0
Training loss: 2.8490929348035423
Validation loss: 2.579068853554018

Epoch: 5| Step: 1
Training loss: 2.5446897153435994
Validation loss: 2.535589686231163

Epoch: 5| Step: 2
Training loss: 2.1715424646717834
Validation loss: 2.5485182890697393

Epoch: 5| Step: 3
Training loss: 2.474140993034121
Validation loss: 2.5540493308587426

Epoch: 5| Step: 4
Training loss: 2.9885011280422114
Validation loss: 2.5383002286252183

Epoch: 5| Step: 5
Training loss: 2.6059374066064747
Validation loss: 2.5575127529968698

Epoch: 5| Step: 6
Training loss: 2.7653799864433437
Validation loss: 2.5534685331398

Epoch: 5| Step: 7
Training loss: 2.6248227014156953
Validation loss: 2.5695377651814395

Epoch: 5| Step: 8
Training loss: 2.9063189098433244
Validation loss: 2.53376639469103

Epoch: 5| Step: 9
Training loss: 2.917140613377307
Validation loss: 2.559582305513399

Epoch: 5| Step: 10
Training loss: 2.5505511193206982
Validation loss: 2.5580164715510154

Epoch: 187| Step: 0
Training loss: 2.32572034526061
Validation loss: 2.5361812426977957

Epoch: 5| Step: 1
Training loss: 2.6196870169900226
Validation loss: 2.5706537890791883

Epoch: 5| Step: 2
Training loss: 3.0023497280405778
Validation loss: 2.5243256054824794

Epoch: 5| Step: 3
Training loss: 2.683404507690201
Validation loss: 2.566014106046728

Epoch: 5| Step: 4
Training loss: 2.0322306686572524
Validation loss: 2.5592324187544584

Epoch: 5| Step: 5
Training loss: 2.44773184437058
Validation loss: 2.563916612895773

Epoch: 5| Step: 6
Training loss: 2.6938982362961545
Validation loss: 2.5375628378072

Epoch: 5| Step: 7
Training loss: 3.224750444086448
Validation loss: 2.5212697914277284

Epoch: 5| Step: 8
Training loss: 2.5504378223419453
Validation loss: 2.5646137000804052

Epoch: 5| Step: 9
Training loss: 3.0137995595824476
Validation loss: 2.550440826813287

Epoch: 5| Step: 10
Training loss: 2.5225418438196026
Validation loss: 2.538478922706123

Epoch: 188| Step: 0
Training loss: 2.452775772408798
Validation loss: 2.5869288264265466

Epoch: 5| Step: 1
Training loss: 2.7464658395561963
Validation loss: 2.5466957424285184

Epoch: 5| Step: 2
Training loss: 3.1802928451436014
Validation loss: 2.5617073027527804

Epoch: 5| Step: 3
Training loss: 3.0600770980497045
Validation loss: 2.5100549437189734

Epoch: 5| Step: 4
Training loss: 2.8172447025290905
Validation loss: 2.5318172360604723

Epoch: 5| Step: 5
Training loss: 1.8883392135694663
Validation loss: 2.585241757701912

Epoch: 5| Step: 6
Training loss: 2.683381406775965
Validation loss: 2.553757823674534

Epoch: 5| Step: 7
Training loss: 2.2667820573868407
Validation loss: 2.567082999609201

Epoch: 5| Step: 8
Training loss: 3.1652793522350513
Validation loss: 2.5406168718549433

Epoch: 5| Step: 9
Training loss: 3.128085939695098
Validation loss: 2.5556828799800977

Epoch: 5| Step: 10
Training loss: 1.8201481822756311
Validation loss: 2.587768542892262

Epoch: 189| Step: 0
Training loss: 3.0253332537733293
Validation loss: 2.5543863495887162

Epoch: 5| Step: 1
Training loss: 2.9427854994837257
Validation loss: 2.582767676375986

Epoch: 5| Step: 2
Training loss: 3.075125380030101
Validation loss: 2.5582597507184084

Epoch: 5| Step: 3
Training loss: 1.8207135720516963
Validation loss: 2.593367594740331

Epoch: 5| Step: 4
Training loss: 2.9994306023975006
Validation loss: 2.5382942959768573

Epoch: 5| Step: 5
Training loss: 2.4404374054187183
Validation loss: 2.5498652255083725

Epoch: 5| Step: 6
Training loss: 2.7180703727757094
Validation loss: 2.5095276264025137

Epoch: 5| Step: 7
Training loss: 2.4627427034782086
Validation loss: 2.578184549359265

Epoch: 5| Step: 8
Training loss: 2.3479496269541458
Validation loss: 2.547505790625535

Epoch: 5| Step: 9
Training loss: 2.610212271670626
Validation loss: 2.5250682335870036

Epoch: 5| Step: 10
Training loss: 2.548368425678596
Validation loss: 2.559747341458747

Epoch: 190| Step: 0
Training loss: 2.7380048800105206
Validation loss: 2.5655912136893746

Epoch: 5| Step: 1
Training loss: 3.1037416273811473
Validation loss: 2.5790575296771103

Epoch: 5| Step: 2
Training loss: 2.704873197760053
Validation loss: 2.5820937151370873

Epoch: 5| Step: 3
Training loss: 1.9153950315156298
Validation loss: 2.5605656896361615

Epoch: 5| Step: 4
Training loss: 2.845006644135613
Validation loss: 2.562890000857327

Epoch: 5| Step: 5
Training loss: 2.4365647306746396
Validation loss: 2.5505500971012145

Epoch: 5| Step: 6
Training loss: 2.379225936480966
Validation loss: 2.5226935351588855

Epoch: 5| Step: 7
Training loss: 2.8563262862487586
Validation loss: 2.575014334803121

Epoch: 5| Step: 8
Training loss: 2.5797146606863914
Validation loss: 2.5696930223428907

Epoch: 5| Step: 9
Training loss: 2.6613234593406374
Validation loss: 2.603291746442357

Epoch: 5| Step: 10
Training loss: 2.8461712600746294
Validation loss: 2.537849469450407

Epoch: 191| Step: 0
Training loss: 2.616531699844568
Validation loss: 2.5299446895859705

Epoch: 5| Step: 1
Training loss: 2.3665306262644497
Validation loss: 2.5835578244014084

Epoch: 5| Step: 2
Training loss: 2.8408923200632468
Validation loss: 2.5044874791033065

Epoch: 5| Step: 3
Training loss: 2.3105154027270656
Validation loss: 2.553376412967086

Epoch: 5| Step: 4
Training loss: 2.687015489772817
Validation loss: 2.528923463404061

Epoch: 5| Step: 5
Training loss: 2.9548228393737856
Validation loss: 2.552970121073518

Epoch: 5| Step: 6
Training loss: 2.288521972997492
Validation loss: 2.5244623844241514

Epoch: 5| Step: 7
Training loss: 2.9937370411506783
Validation loss: 2.559105668672526

Epoch: 5| Step: 8
Training loss: 3.419709099338229
Validation loss: 2.5418388692321745

Epoch: 5| Step: 9
Training loss: 2.5058771669465316
Validation loss: 2.5467692331265535

Epoch: 5| Step: 10
Training loss: 2.135770765269481
Validation loss: 2.5611152048552563

Epoch: 192| Step: 0
Training loss: 2.9076664251977338
Validation loss: 2.5811562466272675

Epoch: 5| Step: 1
Training loss: 2.260104484505924
Validation loss: 2.5415139161648717

Epoch: 5| Step: 2
Training loss: 2.318173331144848
Validation loss: 2.5262805331449405

Epoch: 5| Step: 3
Training loss: 2.6781775666355987
Validation loss: 2.5734481279237253

Epoch: 5| Step: 4
Training loss: 2.627578649532447
Validation loss: 2.5241346560422646

Epoch: 5| Step: 5
Training loss: 2.5511231361257867
Validation loss: 2.5880730073216287

Epoch: 5| Step: 6
Training loss: 2.9372392903963154
Validation loss: 2.5608801765565463

Epoch: 5| Step: 7
Training loss: 3.0465887473205657
Validation loss: 2.541006040394644

Epoch: 5| Step: 8
Training loss: 1.936626914410281
Validation loss: 2.537769707777898

Epoch: 5| Step: 9
Training loss: 2.624466160578421
Validation loss: 2.627617073927831

Epoch: 5| Step: 10
Training loss: 3.4534116600118585
Validation loss: 2.5110793299667415

Epoch: 193| Step: 0
Training loss: 3.0119700048708484
Validation loss: 2.5535929839192217

Epoch: 5| Step: 1
Training loss: 3.2927754301294465
Validation loss: 2.5217544610418186

Epoch: 5| Step: 2
Training loss: 2.6687209938492025
Validation loss: 2.565983563142027

Epoch: 5| Step: 3
Training loss: 2.375064748584139
Validation loss: 2.5746182544332643

Epoch: 5| Step: 4
Training loss: 2.0271064163676282
Validation loss: 2.5790402038106435

Epoch: 5| Step: 5
Training loss: 2.565661178501057
Validation loss: 2.528765383794606

Epoch: 5| Step: 6
Training loss: 2.4815712708771085
Validation loss: 2.5536900444903874

Epoch: 5| Step: 7
Training loss: 2.7137803005106544
Validation loss: 2.5566512289320635

Epoch: 5| Step: 8
Training loss: 2.429233619024642
Validation loss: 2.5572442320873403

Epoch: 5| Step: 9
Training loss: 2.2936580213352316
Validation loss: 2.5515726164016614

Epoch: 5| Step: 10
Training loss: 3.079935383800087
Validation loss: 2.5579926842556335

Epoch: 194| Step: 0
Training loss: 2.5138120575106324
Validation loss: 2.536793567236025

Epoch: 5| Step: 1
Training loss: 2.479314772939622
Validation loss: 2.549088060709881

Epoch: 5| Step: 2
Training loss: 1.8992243890274547
Validation loss: 2.5617696630224285

Epoch: 5| Step: 3
Training loss: 2.5950208560936057
Validation loss: 2.557903359909201

Epoch: 5| Step: 4
Training loss: 2.74766745045765
Validation loss: 2.5658167082019383

Epoch: 5| Step: 5
Training loss: 2.5508464904199917
Validation loss: 2.519485446506915

Epoch: 5| Step: 6
Training loss: 2.660003971441072
Validation loss: 2.4969395475786924

Epoch: 5| Step: 7
Training loss: 3.1969351157822214
Validation loss: 2.5617278501659735

Epoch: 5| Step: 8
Training loss: 2.8550452297923683
Validation loss: 2.570863194672062

Epoch: 5| Step: 9
Training loss: 2.843184194764111
Validation loss: 2.553913704855953

Epoch: 5| Step: 10
Training loss: 2.729178498997167
Validation loss: 2.5060199286514186

Epoch: 195| Step: 0
Training loss: 2.612237057389747
Validation loss: 2.5439085487970425

Epoch: 5| Step: 1
Training loss: 2.0405716846739224
Validation loss: 2.5689527785803388

Epoch: 5| Step: 2
Training loss: 2.7123258262300047
Validation loss: 2.5940177345394817

Epoch: 5| Step: 3
Training loss: 2.928850466364114
Validation loss: 2.5380790730652456

Epoch: 5| Step: 4
Training loss: 2.6240911272728655
Validation loss: 2.5173949757015412

Epoch: 5| Step: 5
Training loss: 2.6975748933112484
Validation loss: 2.572852568126678

Epoch: 5| Step: 6
Training loss: 2.9544025866772183
Validation loss: 2.536937154899843

Epoch: 5| Step: 7
Training loss: 3.125140377706431
Validation loss: 2.5519133678006205

Epoch: 5| Step: 8
Training loss: 2.7340827131728664
Validation loss: 2.572591226883692

Epoch: 5| Step: 9
Training loss: 2.5251719652291986
Validation loss: 2.5636746255250076

Epoch: 5| Step: 10
Training loss: 2.2722024086127464
Validation loss: 2.529275249199179

Epoch: 196| Step: 0
Training loss: 2.5815185407186636
Validation loss: 2.5220959507448413

Epoch: 5| Step: 1
Training loss: 2.962884509407828
Validation loss: 2.5841939662237614

Epoch: 5| Step: 2
Training loss: 2.169748046944446
Validation loss: 2.570999224824579

Epoch: 5| Step: 3
Training loss: 2.1809233849950487
Validation loss: 2.5782519754543354

Epoch: 5| Step: 4
Training loss: 2.906592564236112
Validation loss: 2.5571989587284314

Epoch: 5| Step: 5
Training loss: 2.105871951080341
Validation loss: 2.5749065736252708

Epoch: 5| Step: 6
Training loss: 2.0883399187345963
Validation loss: 2.576813810806308

Epoch: 5| Step: 7
Training loss: 2.987565018333414
Validation loss: 2.597879808964762

Epoch: 5| Step: 8
Training loss: 2.2329103164122235
Validation loss: 2.5736772242537866

Epoch: 5| Step: 9
Training loss: 3.702864110585205
Validation loss: 2.5388257583796823

Epoch: 5| Step: 10
Training loss: 3.2052624525663327
Validation loss: 2.5697171811934867

Epoch: 197| Step: 0
Training loss: 2.2560807817145703
Validation loss: 2.546019670652237

Epoch: 5| Step: 1
Training loss: 2.058198431230117
Validation loss: 2.538717913219133

Epoch: 5| Step: 2
Training loss: 2.533120582665188
Validation loss: 2.572293508040006

Epoch: 5| Step: 3
Training loss: 2.968029055142144
Validation loss: 2.5205937713012925

Epoch: 5| Step: 4
Training loss: 2.877922397237967
Validation loss: 2.5275044497037364

Epoch: 5| Step: 5
Training loss: 2.725713384499048
Validation loss: 2.5532928781520923

Epoch: 5| Step: 6
Training loss: 3.166529920202029
Validation loss: 2.5147090154531986

Epoch: 5| Step: 7
Training loss: 2.6201317467215697
Validation loss: 2.5319025952337335

Epoch: 5| Step: 8
Training loss: 2.513667037710235
Validation loss: 2.556461302087818

Epoch: 5| Step: 9
Training loss: 2.9474608986730497
Validation loss: 2.556504612009013

Epoch: 5| Step: 10
Training loss: 2.462541039604136
Validation loss: 2.5331915637094102

Epoch: 198| Step: 0
Training loss: 2.59197394909542
Validation loss: 2.570158162018202

Epoch: 5| Step: 1
Training loss: 2.895454125767042
Validation loss: 2.532156253996862

Epoch: 5| Step: 2
Training loss: 2.651509711437507
Validation loss: 2.53742334708846

Epoch: 5| Step: 3
Training loss: 2.6027090850888435
Validation loss: 2.5629479056579214

Epoch: 5| Step: 4
Training loss: 1.8833476845298571
Validation loss: 2.5623980346049717

Epoch: 5| Step: 5
Training loss: 2.6457947455368216
Validation loss: 2.5655138014206926

Epoch: 5| Step: 6
Training loss: 3.073779917009422
Validation loss: 2.5651262682873557

Epoch: 5| Step: 7
Training loss: 2.8415720218174623
Validation loss: 2.5734276461970316

Epoch: 5| Step: 8
Training loss: 2.984648367459787
Validation loss: 2.5504150338795113

Epoch: 5| Step: 9
Training loss: 2.6241186569763024
Validation loss: 2.582060241859139

Epoch: 5| Step: 10
Training loss: 2.148264708072757
Validation loss: 2.5914866405068944

Epoch: 199| Step: 0
Training loss: 2.813230970548338
Validation loss: 2.574393449202318

Epoch: 5| Step: 1
Training loss: 3.3789416713732248
Validation loss: 2.5137276760288647

Epoch: 5| Step: 2
Training loss: 2.204240881590464
Validation loss: 2.5505027117025487

Epoch: 5| Step: 3
Training loss: 2.228607844484873
Validation loss: 2.548122341888833

Epoch: 5| Step: 4
Training loss: 2.290729839845309
Validation loss: 2.566022575191832

Epoch: 5| Step: 5
Training loss: 3.1284119862129662
Validation loss: 2.5625625400629923

Epoch: 5| Step: 6
Training loss: 2.61296547206369
Validation loss: 2.543619109673862

Epoch: 5| Step: 7
Training loss: 2.5650582917786036
Validation loss: 2.543503787436202

Epoch: 5| Step: 8
Training loss: 2.1484760072898523
Validation loss: 2.5494688801570127

Epoch: 5| Step: 9
Training loss: 1.889396205105468
Validation loss: 2.5397406448171562

Epoch: 5| Step: 10
Training loss: 3.597561349352296
Validation loss: 2.5617938225404657

Epoch: 200| Step: 0
Training loss: 2.8175622099513262
Validation loss: 2.5389229301163754

Epoch: 5| Step: 1
Training loss: 2.00167323691343
Validation loss: 2.5562508621252475

Epoch: 5| Step: 2
Training loss: 2.87702969761896
Validation loss: 2.5306081126362514

Epoch: 5| Step: 3
Training loss: 2.897634883502547
Validation loss: 2.5747295016541587

Epoch: 5| Step: 4
Training loss: 2.8042080185114626
Validation loss: 2.5355476519541664

Epoch: 5| Step: 5
Training loss: 3.1191283950135937
Validation loss: 2.5438397856114507

Epoch: 5| Step: 6
Training loss: 2.8631433555216157
Validation loss: 2.513239084812996

Epoch: 5| Step: 7
Training loss: 2.457999761762988
Validation loss: 2.546544311040173

Epoch: 5| Step: 8
Training loss: 2.3113921321163624
Validation loss: 2.536345336065448

Epoch: 5| Step: 9
Training loss: 2.381477557345468
Validation loss: 2.548169885238575

Epoch: 5| Step: 10
Training loss: 2.3558314915548526
Validation loss: 2.561335781655188

Epoch: 201| Step: 0
Training loss: 2.5220949363052965
Validation loss: 2.584006884279068

Epoch: 5| Step: 1
Training loss: 3.335657469813172
Validation loss: 2.5622406604951187

Epoch: 5| Step: 2
Training loss: 2.9919717178028
Validation loss: 2.544620861437771

Epoch: 5| Step: 3
Training loss: 2.41751898062828
Validation loss: 2.571835916676966

Epoch: 5| Step: 4
Training loss: 2.3748792316449867
Validation loss: 2.5277693606084792

Epoch: 5| Step: 5
Training loss: 3.2706143899195497
Validation loss: 2.574022000280369

Epoch: 5| Step: 6
Training loss: 2.5383696094842114
Validation loss: 2.5943893443264243

Epoch: 5| Step: 7
Training loss: 2.099193499874309
Validation loss: 2.551775596871293

Epoch: 5| Step: 8
Training loss: 2.3934638427527877
Validation loss: 2.5325718614338615

Epoch: 5| Step: 9
Training loss: 2.441822132546892
Validation loss: 2.526599211457838

Epoch: 5| Step: 10
Training loss: 2.331442600506559
Validation loss: 2.538896071009783

Epoch: 202| Step: 0
Training loss: 2.8328034709569807
Validation loss: 2.5669653219216984

Epoch: 5| Step: 1
Training loss: 2.8168630877594825
Validation loss: 2.5742275954864233

Epoch: 5| Step: 2
Training loss: 2.432979500097419
Validation loss: 2.538877880366997

Epoch: 5| Step: 3
Training loss: 1.9859160199268004
Validation loss: 2.5739034326735033

Epoch: 5| Step: 4
Training loss: 3.4149051560374915
Validation loss: 2.5451897841754985

Epoch: 5| Step: 5
Training loss: 2.6434222872736357
Validation loss: 2.5455718786844233

Epoch: 5| Step: 6
Training loss: 3.284511289663391
Validation loss: 2.5784365886137923

Epoch: 5| Step: 7
Training loss: 2.4506487162696735
Validation loss: 2.543514396748122

Epoch: 5| Step: 8
Training loss: 2.214090101329808
Validation loss: 2.528377601148988

Epoch: 5| Step: 9
Training loss: 2.1071476231999102
Validation loss: 2.5396343799417864

Epoch: 5| Step: 10
Training loss: 2.4550246154732025
Validation loss: 2.5343029965827144

Epoch: 203| Step: 0
Training loss: 2.577808615026877
Validation loss: 2.566792939681967

Epoch: 5| Step: 1
Training loss: 2.7481447377297505
Validation loss: 2.60996571580039

Epoch: 5| Step: 2
Training loss: 2.209925011963573
Validation loss: 2.5389924009883784

Epoch: 5| Step: 3
Training loss: 2.8953635477340947
Validation loss: 2.5887495394721602

Epoch: 5| Step: 4
Training loss: 2.247817994769564
Validation loss: 2.5564347546056116

Epoch: 5| Step: 5
Training loss: 2.644515202303137
Validation loss: 2.521698658196833

Epoch: 5| Step: 6
Training loss: 2.5444006572751925
Validation loss: 2.570450034378104

Epoch: 5| Step: 7
Training loss: 3.4534768318005558
Validation loss: 2.559164057294494

Epoch: 5| Step: 8
Training loss: 2.2760345202813177
Validation loss: 2.548766749643415

Epoch: 5| Step: 9
Training loss: 2.785645173162174
Validation loss: 2.534090517218603

Epoch: 5| Step: 10
Training loss: 2.777038643304016
Validation loss: 2.5673671203579818

Epoch: 204| Step: 0
Training loss: 2.7673319058942623
Validation loss: 2.5777357934416556

Epoch: 5| Step: 1
Training loss: 2.471803539222167
Validation loss: 2.5581408263469037

Epoch: 5| Step: 2
Training loss: 2.6522209577269305
Validation loss: 2.556354750481673

Epoch: 5| Step: 3
Training loss: 2.047925723092385
Validation loss: 2.5565668234227963

Epoch: 5| Step: 4
Training loss: 2.618954008254264
Validation loss: 2.5756754425282207

Epoch: 5| Step: 5
Training loss: 2.632238399045649
Validation loss: 2.5701846465499494

Epoch: 5| Step: 6
Training loss: 2.835439254667033
Validation loss: 2.5593877241000227

Epoch: 5| Step: 7
Training loss: 2.3443576279405636
Validation loss: 2.5680350364736504

Epoch: 5| Step: 8
Training loss: 2.698859758146137
Validation loss: 2.576457699935851

Epoch: 5| Step: 9
Training loss: 3.108993123436774
Validation loss: 2.5234937312037453

Epoch: 5| Step: 10
Training loss: 3.090081091251926
Validation loss: 2.5630176460541083

Epoch: 205| Step: 0
Training loss: 2.6581897609130904
Validation loss: 2.5712885091508157

Epoch: 5| Step: 1
Training loss: 2.9499659520140216
Validation loss: 2.5899344671696665

Epoch: 5| Step: 2
Training loss: 2.4730196379958915
Validation loss: 2.580977842334744

Epoch: 5| Step: 3
Training loss: 2.344917718545896
Validation loss: 2.5677472306536666

Epoch: 5| Step: 4
Training loss: 2.7472372048430898
Validation loss: 2.5439995037548084

Epoch: 5| Step: 5
Training loss: 2.553756871001812
Validation loss: 2.575517111909461

Epoch: 5| Step: 6
Training loss: 2.2701335377003042
Validation loss: 2.5593764233278766

Epoch: 5| Step: 7
Training loss: 2.2337811087569883
Validation loss: 2.5463485239050003

Epoch: 5| Step: 8
Training loss: 3.2532228482616525
Validation loss: 2.571870134064673

Epoch: 5| Step: 9
Training loss: 2.661920217509301
Validation loss: 2.566274847387433

Epoch: 5| Step: 10
Training loss: 2.7300097689611014
Validation loss: 2.561076578513633

Epoch: 206| Step: 0
Training loss: 2.839977906638161
Validation loss: 2.5742384117959425

Epoch: 5| Step: 1
Training loss: 2.6978664516258224
Validation loss: 2.540200985089793

Epoch: 5| Step: 2
Training loss: 3.0413238819961603
Validation loss: 2.6060973143474055

Epoch: 5| Step: 3
Training loss: 2.5820646759962913
Validation loss: 2.52477147032618

Epoch: 5| Step: 4
Training loss: 2.9197783265822417
Validation loss: 2.566847775668066

Epoch: 5| Step: 5
Training loss: 2.499271858988989
Validation loss: 2.558559142636973

Epoch: 5| Step: 6
Training loss: 2.929721842246634
Validation loss: 2.5477545129496098

Epoch: 5| Step: 7
Training loss: 2.4359754049252795
Validation loss: 2.5649083603042633

Epoch: 5| Step: 8
Training loss: 2.2864562941928077
Validation loss: 2.545512055850022

Epoch: 5| Step: 9
Training loss: 2.59118304713122
Validation loss: 2.544960922815402

Epoch: 5| Step: 10
Training loss: 2.280043086765806
Validation loss: 2.552670198677303

Epoch: 207| Step: 0
Training loss: 2.262825123731036
Validation loss: 2.548633922558157

Epoch: 5| Step: 1
Training loss: 2.8933432505330705
Validation loss: 2.5447516464017355

Epoch: 5| Step: 2
Training loss: 3.0909335484786533
Validation loss: 2.6128797783907953

Epoch: 5| Step: 3
Training loss: 3.023506104629836
Validation loss: 2.5361432949551452

Epoch: 5| Step: 4
Training loss: 2.9768691017657885
Validation loss: 2.574190907233849

Epoch: 5| Step: 5
Training loss: 2.209314728040213
Validation loss: 2.6180872637040076

Epoch: 5| Step: 6
Training loss: 3.0335033732392818
Validation loss: 2.547342337687237

Epoch: 5| Step: 7
Training loss: 1.9661279808059187
Validation loss: 2.5256520451094318

Epoch: 5| Step: 8
Training loss: 2.371474007747373
Validation loss: 2.598259105639426

Epoch: 5| Step: 9
Training loss: 2.672945577733194
Validation loss: 2.5113566374947287

Epoch: 5| Step: 10
Training loss: 2.4295041913618354
Validation loss: 2.537978689191803

Epoch: 208| Step: 0
Training loss: 2.824171305953067
Validation loss: 2.5317936248573285

Epoch: 5| Step: 1
Training loss: 2.1141171873339957
Validation loss: 2.5676090323032374

Epoch: 5| Step: 2
Training loss: 2.7324006718541614
Validation loss: 2.503817090990471

Epoch: 5| Step: 3
Training loss: 2.754639180366018
Validation loss: 2.5391864372150437

Epoch: 5| Step: 4
Training loss: 1.947161611459292
Validation loss: 2.551704775115885

Epoch: 5| Step: 5
Training loss: 2.444037351763009
Validation loss: 2.4917735284677858

Epoch: 5| Step: 6
Training loss: 2.9166152041300206
Validation loss: 2.5810097900817253

Epoch: 5| Step: 7
Training loss: 2.4336416567377834
Validation loss: 2.561744793751942

Epoch: 5| Step: 8
Training loss: 3.0279045914468283
Validation loss: 2.516122917376109

Epoch: 5| Step: 9
Training loss: 2.81519764695889
Validation loss: 2.5266792090759402

Epoch: 5| Step: 10
Training loss: 2.753974556583064
Validation loss: 2.5522032163152994

Epoch: 209| Step: 0
Training loss: 2.236157326651811
Validation loss: 2.566393690518203

Epoch: 5| Step: 1
Training loss: 2.8699606807022384
Validation loss: 2.5552808936645515

Epoch: 5| Step: 2
Training loss: 3.01490466750008
Validation loss: 2.5354684806537358

Epoch: 5| Step: 3
Training loss: 2.3879676959921485
Validation loss: 2.562196249858306

Epoch: 5| Step: 4
Training loss: 2.404927769803578
Validation loss: 2.5377983031884264

Epoch: 5| Step: 5
Training loss: 2.467195238580822
Validation loss: 2.571297343780055

Epoch: 5| Step: 6
Training loss: 2.8244395822636075
Validation loss: 2.5379462331021165

Epoch: 5| Step: 7
Training loss: 2.5124634014140037
Validation loss: 2.5643701639503433

Epoch: 5| Step: 8
Training loss: 2.6525704423213816
Validation loss: 2.5187861812566643

Epoch: 5| Step: 9
Training loss: 3.45868673395626
Validation loss: 2.4993195643477906

Epoch: 5| Step: 10
Training loss: 2.094936660865218
Validation loss: 2.562562647108006

Epoch: 210| Step: 0
Training loss: 2.667051903395904
Validation loss: 2.544765656590991

Epoch: 5| Step: 1
Training loss: 2.6694484645386733
Validation loss: 2.536361983255443

Epoch: 5| Step: 2
Training loss: 2.480489607595624
Validation loss: 2.533678581899968

Epoch: 5| Step: 3
Training loss: 2.455589757031921
Validation loss: 2.5685343868923476

Epoch: 5| Step: 4
Training loss: 2.8123604633897124
Validation loss: 2.547235626049037

Epoch: 5| Step: 5
Training loss: 2.8153089271816603
Validation loss: 2.5801796992166355

Epoch: 5| Step: 6
Training loss: 3.0853635616398787
Validation loss: 2.5659606719602253

Epoch: 5| Step: 7
Training loss: 2.6404952519610148
Validation loss: 2.5846493558083403

Epoch: 5| Step: 8
Training loss: 2.1967644827814516
Validation loss: 2.5687756415079543

Epoch: 5| Step: 9
Training loss: 2.4967202607714936
Validation loss: 2.531197209467945

Epoch: 5| Step: 10
Training loss: 2.55660929125184
Validation loss: 2.5756470944492893

Epoch: 211| Step: 0
Training loss: 2.671936926765449
Validation loss: 2.56455319433217

Epoch: 5| Step: 1
Training loss: 2.2358979057042534
Validation loss: 2.551961046963599

Epoch: 5| Step: 2
Training loss: 2.8702695325232184
Validation loss: 2.5387038928804877

Epoch: 5| Step: 3
Training loss: 3.126606337636985
Validation loss: 2.549151574460619

Epoch: 5| Step: 4
Training loss: 1.735429185667216
Validation loss: 2.5725751599288613

Epoch: 5| Step: 5
Training loss: 2.5357743319457535
Validation loss: 2.5508406939856627

Epoch: 5| Step: 6
Training loss: 2.1362340959790633
Validation loss: 2.619852797335416

Epoch: 5| Step: 7
Training loss: 3.007978954911167
Validation loss: 2.517379207204223

Epoch: 5| Step: 8
Training loss: 2.9580592355323057
Validation loss: 2.531553568500628

Epoch: 5| Step: 9
Training loss: 2.8827453440052224
Validation loss: 2.5149980060621107

Epoch: 5| Step: 10
Training loss: 2.504808569806186
Validation loss: 2.5517194644648287

Epoch: 212| Step: 0
Training loss: 2.1744606489356233
Validation loss: 2.549285877992939

Epoch: 5| Step: 1
Training loss: 2.9026890750779955
Validation loss: 2.5651959049870277

Epoch: 5| Step: 2
Training loss: 2.1724851560798872
Validation loss: 2.5514315253506026

Epoch: 5| Step: 3
Training loss: 3.022982304336084
Validation loss: 2.530931683427776

Epoch: 5| Step: 4
Training loss: 2.262950818581375
Validation loss: 2.6015227418025946

Epoch: 5| Step: 5
Training loss: 2.9932253957317214
Validation loss: 2.529883247771586

Epoch: 5| Step: 6
Training loss: 2.3974314017719864
Validation loss: 2.5433308925538194

Epoch: 5| Step: 7
Training loss: 3.1668489972543896
Validation loss: 2.6000525438869713

Epoch: 5| Step: 8
Training loss: 2.3285495447773727
Validation loss: 2.5658764328107244

Epoch: 5| Step: 9
Training loss: 2.838231191658327
Validation loss: 2.5131848622153576

Epoch: 5| Step: 10
Training loss: 2.7292669923314
Validation loss: 2.5336778554091444

Epoch: 213| Step: 0
Training loss: 2.365560041415097
Validation loss: 2.5864484353050154

Epoch: 5| Step: 1
Training loss: 3.1778943303511413
Validation loss: 2.561225695317888

Epoch: 5| Step: 2
Training loss: 2.4715561189664377
Validation loss: 2.5536327394243297

Epoch: 5| Step: 3
Training loss: 2.8396560208110277
Validation loss: 2.5822675658651737

Epoch: 5| Step: 4
Training loss: 2.6070228985774704
Validation loss: 2.539349138031786

Epoch: 5| Step: 5
Training loss: 2.438945732767343
Validation loss: 2.570149052161943

Epoch: 5| Step: 6
Training loss: 3.1563811322156012
Validation loss: 2.5525339766311412

Epoch: 5| Step: 7
Training loss: 2.7654149034946744
Validation loss: 2.502067771104268

Epoch: 5| Step: 8
Training loss: 2.5235732665018045
Validation loss: 2.539290479548641

Epoch: 5| Step: 9
Training loss: 1.8987838994227735
Validation loss: 2.5671865374914753

Epoch: 5| Step: 10
Training loss: 2.3943251354628265
Validation loss: 2.578762006821512

Epoch: 214| Step: 0
Training loss: 2.6328113227637853
Validation loss: 2.5443029350126136

Epoch: 5| Step: 1
Training loss: 2.8392074690711135
Validation loss: 2.5504749774222892

Epoch: 5| Step: 2
Training loss: 2.4834312709808475
Validation loss: 2.5402664255842553

Epoch: 5| Step: 3
Training loss: 3.0354729564494454
Validation loss: 2.5876424663713093

Epoch: 5| Step: 4
Training loss: 2.4236636540189522
Validation loss: 2.5252458061851044

Epoch: 5| Step: 5
Training loss: 2.892504766488331
Validation loss: 2.5466882680139915

Epoch: 5| Step: 6
Training loss: 1.8454636837288443
Validation loss: 2.5531366628525887

Epoch: 5| Step: 7
Training loss: 2.8631931515160103
Validation loss: 2.5563631653830723

Epoch: 5| Step: 8
Training loss: 2.9744942756170687
Validation loss: 2.5601666719839096

Epoch: 5| Step: 9
Training loss: 2.5848521003249294
Validation loss: 2.564786809529771

Epoch: 5| Step: 10
Training loss: 2.3677281936190737
Validation loss: 2.5440950988669515

Epoch: 215| Step: 0
Training loss: 2.440602406728112
Validation loss: 2.5232665677334865

Epoch: 5| Step: 1
Training loss: 2.777927428558897
Validation loss: 2.5717409873832415

Epoch: 5| Step: 2
Training loss: 2.2826815777154943
Validation loss: 2.5133938274048666

Epoch: 5| Step: 3
Training loss: 2.4374192053291375
Validation loss: 2.539230322454392

Epoch: 5| Step: 4
Training loss: 2.859989954790734
Validation loss: 2.54964523598271

Epoch: 5| Step: 5
Training loss: 3.21278703052973
Validation loss: 2.583383794550387

Epoch: 5| Step: 6
Training loss: 2.8753706651660003
Validation loss: 2.5746315793408105

Epoch: 5| Step: 7
Training loss: 2.7141352984691083
Validation loss: 2.537220559240924

Epoch: 5| Step: 8
Training loss: 2.1930257487457516
Validation loss: 2.554081290228574

Epoch: 5| Step: 9
Training loss: 2.2607812074791362
Validation loss: 2.5521901740956014

Epoch: 5| Step: 10
Training loss: 2.269800271981815
Validation loss: 2.5477147120059795

Epoch: 216| Step: 0
Training loss: 2.082844358917421
Validation loss: 2.5387601585639556

Epoch: 5| Step: 1
Training loss: 3.271478399015064
Validation loss: 2.5395518740182217

Epoch: 5| Step: 2
Training loss: 3.1118543698281504
Validation loss: 2.5515188592831013

Epoch: 5| Step: 3
Training loss: 2.889629955690305
Validation loss: 2.550629727475493

Epoch: 5| Step: 4
Training loss: 2.78629231656552
Validation loss: 2.498666615890647

Epoch: 5| Step: 5
Training loss: 2.5043788707866033
Validation loss: 2.582100158747893

Epoch: 5| Step: 6
Training loss: 2.553692358470896
Validation loss: 2.5470516994855297

Epoch: 5| Step: 7
Training loss: 2.839025912261662
Validation loss: 2.5953101951141067

Epoch: 5| Step: 8
Training loss: 2.351585818964011
Validation loss: 2.5702962701866507

Epoch: 5| Step: 9
Training loss: 1.5811883635438473
Validation loss: 2.572975146734333

Epoch: 5| Step: 10
Training loss: 2.4611108143645777
Validation loss: 2.5695147959146305

Epoch: 217| Step: 0
Training loss: 2.1136697634149035
Validation loss: 2.520444959233864

Epoch: 5| Step: 1
Training loss: 2.5288824618272208
Validation loss: 2.5692544512322493

Epoch: 5| Step: 2
Training loss: 2.1302015930914786
Validation loss: 2.5723009239987253

Epoch: 5| Step: 3
Training loss: 2.8188254538711845
Validation loss: 2.5992803995287472

Epoch: 5| Step: 4
Training loss: 3.5346147828593724
Validation loss: 2.5834669527818743

Epoch: 5| Step: 5
Training loss: 2.42835888613747
Validation loss: 2.5556423990041477

Epoch: 5| Step: 6
Training loss: 2.2140213988802606
Validation loss: 2.589450327010547

Epoch: 5| Step: 7
Training loss: 3.1503606559524644
Validation loss: 2.561342438631532

Epoch: 5| Step: 8
Training loss: 2.656648493776025
Validation loss: 2.5665951033120287

Epoch: 5| Step: 9
Training loss: 2.5451134516641964
Validation loss: 2.5609107142568366

Epoch: 5| Step: 10
Training loss: 2.5111912103647995
Validation loss: 2.548528266907369

Epoch: 218| Step: 0
Training loss: 2.8627166399538995
Validation loss: 2.52112301333535

Epoch: 5| Step: 1
Training loss: 2.08227823878722
Validation loss: 2.554138146605084

Epoch: 5| Step: 2
Training loss: 2.939416949787782
Validation loss: 2.4963605025259934

Epoch: 5| Step: 3
Training loss: 2.606018008511694
Validation loss: 2.542833753906309

Epoch: 5| Step: 4
Training loss: 2.797401676989834
Validation loss: 2.56186109612079

Epoch: 5| Step: 5
Training loss: 3.0673015089411946
Validation loss: 2.530666227791623

Epoch: 5| Step: 6
Training loss: 2.218014877393272
Validation loss: 2.5829274543113305

Epoch: 5| Step: 7
Training loss: 2.431522081541955
Validation loss: 2.511969886002949

Epoch: 5| Step: 8
Training loss: 2.6596447961314977
Validation loss: 2.5751512427495724

Epoch: 5| Step: 9
Training loss: 2.3877164812456297
Validation loss: 2.539348458593755

Epoch: 5| Step: 10
Training loss: 2.775446720079886
Validation loss: 2.550842053272052

Epoch: 219| Step: 0
Training loss: 1.7848948614961775
Validation loss: 2.5633450017043935

Epoch: 5| Step: 1
Training loss: 2.732421438722937
Validation loss: 2.529123686027427

Epoch: 5| Step: 2
Training loss: 3.1937968569787687
Validation loss: 2.5532670146273255

Epoch: 5| Step: 3
Training loss: 2.2850007876472036
Validation loss: 2.536327997400578

Epoch: 5| Step: 4
Training loss: 3.0666380970771274
Validation loss: 2.5556578170601814

Epoch: 5| Step: 5
Training loss: 1.5256458415757035
Validation loss: 2.5426064752045323

Epoch: 5| Step: 6
Training loss: 2.835964906838557
Validation loss: 2.5390044386971917

Epoch: 5| Step: 7
Training loss: 2.756047362060414
Validation loss: 2.591834665669862

Epoch: 5| Step: 8
Training loss: 2.4097357928809746
Validation loss: 2.5064966102904913

Epoch: 5| Step: 9
Training loss: 3.1616295019796494
Validation loss: 2.521747976078713

Epoch: 5| Step: 10
Training loss: 2.356250335936181
Validation loss: 2.535792242568371

Epoch: 220| Step: 0
Training loss: 2.2246917896896523
Validation loss: 2.547091835888013

Epoch: 5| Step: 1
Training loss: 2.01977289698357
Validation loss: 2.5437956684833773

Epoch: 5| Step: 2
Training loss: 2.461736930700131
Validation loss: 2.5389184650620313

Epoch: 5| Step: 3
Training loss: 3.1773102892916323
Validation loss: 2.5137229030975408

Epoch: 5| Step: 4
Training loss: 2.4187553740843377
Validation loss: 2.5643427566030765

Epoch: 5| Step: 5
Training loss: 2.792281913335188
Validation loss: 2.523311919565812

Epoch: 5| Step: 6
Training loss: 2.4976492319971975
Validation loss: 2.556126734317961

Epoch: 5| Step: 7
Training loss: 2.759109667488149
Validation loss: 2.582555485725663

Epoch: 5| Step: 8
Training loss: 2.267974477163476
Validation loss: 2.5465519841992066

Epoch: 5| Step: 9
Training loss: 2.342578340765425
Validation loss: 2.5892781743929385

Epoch: 5| Step: 10
Training loss: 3.3048189466230213
Validation loss: 2.5385684306493626

Epoch: 221| Step: 0
Training loss: 2.6480181426726177
Validation loss: 2.516716674044901

Epoch: 5| Step: 1
Training loss: 2.5286708926142003
Validation loss: 2.585959323104072

Epoch: 5| Step: 2
Training loss: 2.67949833772255
Validation loss: 2.5516841942122013

Epoch: 5| Step: 3
Training loss: 2.341364956715349
Validation loss: 2.5371215853363767

Epoch: 5| Step: 4
Training loss: 2.062424976255943
Validation loss: 2.552219590313921

Epoch: 5| Step: 5
Training loss: 2.8639356586112474
Validation loss: 2.536818409267459

Epoch: 5| Step: 6
Training loss: 2.775036418091593
Validation loss: 2.610679708500024

Epoch: 5| Step: 7
Training loss: 2.8605257647427047
Validation loss: 2.5801902536043633

Epoch: 5| Step: 8
Training loss: 2.1945497538518803
Validation loss: 2.581587487978198

Epoch: 5| Step: 9
Training loss: 2.9934028567571382
Validation loss: 2.5863450965900845

Epoch: 5| Step: 10
Training loss: 3.018258797623821
Validation loss: 2.564162520629769

Epoch: 222| Step: 0
Training loss: 2.1369165750873518
Validation loss: 2.567147664963337

Epoch: 5| Step: 1
Training loss: 2.1819000499711176
Validation loss: 2.545747937516569

Epoch: 5| Step: 2
Training loss: 2.041073563770941
Validation loss: 2.5090867582031926

Epoch: 5| Step: 3
Training loss: 3.068918625186262
Validation loss: 2.547599751265922

Epoch: 5| Step: 4
Training loss: 2.851830540431084
Validation loss: 2.5650032736124846

Epoch: 5| Step: 5
Training loss: 2.702661904594142
Validation loss: 2.551202293405317

Epoch: 5| Step: 6
Training loss: 2.7979930156214308
Validation loss: 2.6063784893637827

Epoch: 5| Step: 7
Training loss: 3.0055370095981937
Validation loss: 2.5772187699540905

Epoch: 5| Step: 8
Training loss: 2.4808586715243157
Validation loss: 2.5257660580428865

Epoch: 5| Step: 9
Training loss: 2.783468583146402
Validation loss: 2.6003830168126725

Epoch: 5| Step: 10
Training loss: 2.8713536566564275
Validation loss: 2.5812746966028053

Epoch: 223| Step: 0
Training loss: 2.9597664885301302
Validation loss: 2.5802142893287323

Epoch: 5| Step: 1
Training loss: 2.2594370557776102
Validation loss: 2.5518738175746756

Epoch: 5| Step: 2
Training loss: 2.6202871613707597
Validation loss: 2.527534622328999

Epoch: 5| Step: 3
Training loss: 3.2270421740716846
Validation loss: 2.6001508872105177

Epoch: 5| Step: 4
Training loss: 2.232272032133529
Validation loss: 2.562023491703408

Epoch: 5| Step: 5
Training loss: 2.111225813822549
Validation loss: 2.5456507231746563

Epoch: 5| Step: 6
Training loss: 2.380045500568809
Validation loss: 2.5355439584775104

Epoch: 5| Step: 7
Training loss: 2.773479192715889
Validation loss: 2.5882371111041644

Epoch: 5| Step: 8
Training loss: 2.6548804847843472
Validation loss: 2.5673628505609645

Epoch: 5| Step: 9
Training loss: 2.9300268358166885
Validation loss: 2.560293963314935

Epoch: 5| Step: 10
Training loss: 2.260802720909344
Validation loss: 2.556907097753786

Epoch: 224| Step: 0
Training loss: 2.292091526760465
Validation loss: 2.558043273208907

Epoch: 5| Step: 1
Training loss: 2.330780869803769
Validation loss: 2.5322993169789045

Epoch: 5| Step: 2
Training loss: 2.379638759542197
Validation loss: 2.5725805640891677

Epoch: 5| Step: 3
Training loss: 2.8483328309866915
Validation loss: 2.5276320131195362

Epoch: 5| Step: 4
Training loss: 2.4961279447359463
Validation loss: 2.577487348379438

Epoch: 5| Step: 5
Training loss: 2.1463608571717896
Validation loss: 2.5599427587828933

Epoch: 5| Step: 6
Training loss: 3.681277439811782
Validation loss: 2.537314983609927

Epoch: 5| Step: 7
Training loss: 2.611364645406554
Validation loss: 2.561080866799028

Epoch: 5| Step: 8
Training loss: 2.555003482047319
Validation loss: 2.509859042469828

Epoch: 5| Step: 9
Training loss: 2.7896842370409987
Validation loss: 2.565879649003807

Epoch: 5| Step: 10
Training loss: 2.284876723188198
Validation loss: 2.5385835484557515

Epoch: 225| Step: 0
Training loss: 1.5356579608663568
Validation loss: 2.5334726882903023

Epoch: 5| Step: 1
Training loss: 2.8160755741100276
Validation loss: 2.5574691103060565

Epoch: 5| Step: 2
Training loss: 2.1291182386212233
Validation loss: 2.5460753880152995

Epoch: 5| Step: 3
Training loss: 3.200929661653398
Validation loss: 2.5430264072703403

Epoch: 5| Step: 4
Training loss: 3.14080476009185
Validation loss: 2.5110725713894064

Epoch: 5| Step: 5
Training loss: 2.8554866179652145
Validation loss: 2.615697077275827

Epoch: 5| Step: 6
Training loss: 2.3682722873144404
Validation loss: 2.561305858578064

Epoch: 5| Step: 7
Training loss: 2.4921803250104886
Validation loss: 2.527249548533257

Epoch: 5| Step: 8
Training loss: 2.4761539928574705
Validation loss: 2.561333906969056

Epoch: 5| Step: 9
Training loss: 2.811837181825642
Validation loss: 2.5809061104345976

Epoch: 5| Step: 10
Training loss: 2.1080618833112155
Validation loss: 2.5786923139504587

Epoch: 226| Step: 0
Training loss: 2.973377676606061
Validation loss: 2.552642471375545

Epoch: 5| Step: 1
Training loss: 2.374036493112497
Validation loss: 2.511067227812516

Epoch: 5| Step: 2
Training loss: 2.6829082385283933
Validation loss: 2.5675139347460365

Epoch: 5| Step: 3
Training loss: 2.344782080702052
Validation loss: 2.5571465505062574

Epoch: 5| Step: 4
Training loss: 2.716039424480888
Validation loss: 2.551466893544504

Epoch: 5| Step: 5
Training loss: 2.298380663160593
Validation loss: 2.49619840121763

Epoch: 5| Step: 6
Training loss: 3.155823027180364
Validation loss: 2.562790496791456

Epoch: 5| Step: 7
Training loss: 2.7493443140883005
Validation loss: 2.5632876144443033

Epoch: 5| Step: 8
Training loss: 2.4189039156732286
Validation loss: 2.5149229957151342

Epoch: 5| Step: 9
Training loss: 2.5517120298825384
Validation loss: 2.5391217352155167

Epoch: 5| Step: 10
Training loss: 2.090637170502458
Validation loss: 2.531704991267995

Epoch: 227| Step: 0
Training loss: 2.074874630553236
Validation loss: 2.556868874072309

Epoch: 5| Step: 1
Training loss: 2.7291658318981806
Validation loss: 2.5452098273504546

Epoch: 5| Step: 2
Training loss: 2.3712562367101366
Validation loss: 2.5610697686936623

Epoch: 5| Step: 3
Training loss: 3.3974607971489625
Validation loss: 2.5594568859019864

Epoch: 5| Step: 4
Training loss: 2.393433660017759
Validation loss: 2.549314728374395

Epoch: 5| Step: 5
Training loss: 2.3330816973375397
Validation loss: 2.562511581126609

Epoch: 5| Step: 6
Training loss: 2.6246884479014576
Validation loss: 2.531853984974658

Epoch: 5| Step: 7
Training loss: 2.603814510694553
Validation loss: 2.5223453776605584

Epoch: 5| Step: 8
Training loss: 2.7054784154980935
Validation loss: 2.5708462114626993

Epoch: 5| Step: 9
Training loss: 2.627383104041516
Validation loss: 2.583965366769119

Epoch: 5| Step: 10
Training loss: 2.575633654358877
Validation loss: 2.5773476411581155

Epoch: 228| Step: 0
Training loss: 2.416076610045284
Validation loss: 2.5009870641750505

Epoch: 5| Step: 1
Training loss: 2.899630648013202
Validation loss: 2.508267318183392

Epoch: 5| Step: 2
Training loss: 1.8109789418176316
Validation loss: 2.5453726578181057

Epoch: 5| Step: 3
Training loss: 2.6511845478358063
Validation loss: 2.5656160346838512

Epoch: 5| Step: 4
Training loss: 3.0795586824692873
Validation loss: 2.568647756972672

Epoch: 5| Step: 5
Training loss: 2.257511950489743
Validation loss: 2.540395337710288

Epoch: 5| Step: 6
Training loss: 2.9626955635774337
Validation loss: 2.579961363986524

Epoch: 5| Step: 7
Training loss: 2.722453346518266
Validation loss: 2.5785189310551737

Epoch: 5| Step: 8
Training loss: 2.355351029169871
Validation loss: 2.5270786286134355

Epoch: 5| Step: 9
Training loss: 2.6753304428926556
Validation loss: 2.567569622005627

Epoch: 5| Step: 10
Training loss: 2.402021482608217
Validation loss: 2.5652499646209934

Epoch: 229| Step: 0
Training loss: 2.8100088318926937
Validation loss: 2.539308448156393

Epoch: 5| Step: 1
Training loss: 1.9443114742347591
Validation loss: 2.605421224973262

Epoch: 5| Step: 2
Training loss: 2.6365029931980146
Validation loss: 2.526530454077014

Epoch: 5| Step: 3
Training loss: 2.64037795858096
Validation loss: 2.5246747876284585

Epoch: 5| Step: 4
Training loss: 2.450839587785907
Validation loss: 2.5745380068010957

Epoch: 5| Step: 5
Training loss: 3.2066770629820027
Validation loss: 2.562200487242197

Epoch: 5| Step: 6
Training loss: 2.6670957061221547
Validation loss: 2.561714750358467

Epoch: 5| Step: 7
Training loss: 2.291890971448272
Validation loss: 2.520986640991916

Epoch: 5| Step: 8
Training loss: 3.22429438715573
Validation loss: 2.564597727093409

Epoch: 5| Step: 9
Training loss: 2.564549068797384
Validation loss: 2.539945051283427

Epoch: 5| Step: 10
Training loss: 1.972681630792786
Validation loss: 2.544979298643187

Epoch: 230| Step: 0
Training loss: 2.1914203935734533
Validation loss: 2.5956211716498117

Epoch: 5| Step: 1
Training loss: 2.31068297474663
Validation loss: 2.5787734642156455

Epoch: 5| Step: 2
Training loss: 1.9656479632517596
Validation loss: 2.542005711668028

Epoch: 5| Step: 3
Training loss: 2.565164529829226
Validation loss: 2.5724954793846426

Epoch: 5| Step: 4
Training loss: 2.7991102439809303
Validation loss: 2.5828422776982833

Epoch: 5| Step: 5
Training loss: 2.817912002131687
Validation loss: 2.570940280339241

Epoch: 5| Step: 6
Training loss: 2.5600626449072705
Validation loss: 2.5499723147024014

Epoch: 5| Step: 7
Training loss: 3.2152415292526104
Validation loss: 2.5518296042593462

Epoch: 5| Step: 8
Training loss: 2.462395904974355
Validation loss: 2.524028959061455

Epoch: 5| Step: 9
Training loss: 2.745725430658347
Validation loss: 2.5294103496495035

Epoch: 5| Step: 10
Training loss: 2.456587856051709
Validation loss: 2.5942367608953347

Epoch: 231| Step: 0
Training loss: 2.585071153528454
Validation loss: 2.55731528738894

Epoch: 5| Step: 1
Training loss: 2.4636957121760843
Validation loss: 2.5472307236735268

Epoch: 5| Step: 2
Training loss: 2.503306776821046
Validation loss: 2.5545039539219165

Epoch: 5| Step: 3
Training loss: 2.4893132679128365
Validation loss: 2.532195343765029

Epoch: 5| Step: 4
Training loss: 2.6985148548553517
Validation loss: 2.556760029753489

Epoch: 5| Step: 5
Training loss: 2.4598665359392546
Validation loss: 2.5317151062518657

Epoch: 5| Step: 6
Training loss: 2.8891507074931053
Validation loss: 2.5280661502033692

Epoch: 5| Step: 7
Training loss: 2.3878780365282446
Validation loss: 2.530097202648585

Epoch: 5| Step: 8
Training loss: 3.0473449344629775
Validation loss: 2.5792634411237905

Epoch: 5| Step: 9
Training loss: 2.2531078914675304
Validation loss: 2.5845097044305643

Epoch: 5| Step: 10
Training loss: 2.656224508724191
Validation loss: 2.5463807712147615

Epoch: 232| Step: 0
Training loss: 2.0485924657055765
Validation loss: 2.560385798555216

Epoch: 5| Step: 1
Training loss: 2.2930769886679014
Validation loss: 2.6023246311251085

Epoch: 5| Step: 2
Training loss: 2.352819569334267
Validation loss: 2.596702412529282

Epoch: 5| Step: 3
Training loss: 2.5122152404354456
Validation loss: 2.5884607368066215

Epoch: 5| Step: 4
Training loss: 2.97705042086526
Validation loss: 2.5932389630749935

Epoch: 5| Step: 5
Training loss: 2.6057361196795874
Validation loss: 2.532571556741272

Epoch: 5| Step: 6
Training loss: 3.4096455579444833
Validation loss: 2.6084700679260315

Epoch: 5| Step: 7
Training loss: 2.2041615962623395
Validation loss: 2.5282068812012666

Epoch: 5| Step: 8
Training loss: 2.5470996593782287
Validation loss: 2.5587629254636135

Epoch: 5| Step: 9
Training loss: 3.062518217071536
Validation loss: 2.617605070187516

Epoch: 5| Step: 10
Training loss: 2.1065875815785784
Validation loss: 2.521845900397722

Epoch: 233| Step: 0
Training loss: 2.4160772021255568
Validation loss: 2.5383036817554947

Epoch: 5| Step: 1
Training loss: 2.980780069033321
Validation loss: 2.5523537494840167

Epoch: 5| Step: 2
Training loss: 2.228092992694479
Validation loss: 2.556906954377196

Epoch: 5| Step: 3
Training loss: 3.362289229243074
Validation loss: 2.546324895418694

Epoch: 5| Step: 4
Training loss: 2.084518578658619
Validation loss: 2.5631363851590625

Epoch: 5| Step: 5
Training loss: 2.6335478980939717
Validation loss: 2.5278924144638784

Epoch: 5| Step: 6
Training loss: 2.80082917538211
Validation loss: 2.546672301383094

Epoch: 5| Step: 7
Training loss: 2.219179783418372
Validation loss: 2.5667144380073013

Epoch: 5| Step: 8
Training loss: 2.2054480891893347
Validation loss: 2.5868983213540777

Epoch: 5| Step: 9
Training loss: 2.9632478824248425
Validation loss: 2.5972045002304305

Epoch: 5| Step: 10
Training loss: 2.5080003519499074
Validation loss: 2.5902206559171983

Epoch: 234| Step: 0
Training loss: 2.4395577963370125
Validation loss: 2.5456842446870107

Epoch: 5| Step: 1
Training loss: 2.8120873890316824
Validation loss: 2.5790235776287713

Epoch: 5| Step: 2
Training loss: 1.970065570456525
Validation loss: 2.542525850426505

Epoch: 5| Step: 3
Training loss: 2.8243219085045683
Validation loss: 2.556124459650015

Epoch: 5| Step: 4
Training loss: 2.5583102702572664
Validation loss: 2.5518961650496323

Epoch: 5| Step: 5
Training loss: 2.7944890079606313
Validation loss: 2.543100255016267

Epoch: 5| Step: 6
Training loss: 3.014031814569289
Validation loss: 2.5589297173844194

Epoch: 5| Step: 7
Training loss: 2.3960991311176127
Validation loss: 2.5880945776582003

Epoch: 5| Step: 8
Training loss: 2.894128933642366
Validation loss: 2.521536264744842

Epoch: 5| Step: 9
Training loss: 2.4606230035279117
Validation loss: 2.554643915416802

Epoch: 5| Step: 10
Training loss: 1.6477579460756944
Validation loss: 2.561369081377199

Epoch: 235| Step: 0
Training loss: 2.106955150436508
Validation loss: 2.58033856190816

Epoch: 5| Step: 1
Training loss: 2.4316756280424965
Validation loss: 2.5509787490604103

Epoch: 5| Step: 2
Training loss: 1.9314799767507271
Validation loss: 2.549731888571139

Epoch: 5| Step: 3
Training loss: 2.8316025402882716
Validation loss: 2.553303243971236

Epoch: 5| Step: 4
Training loss: 2.6047986497144455
Validation loss: 2.55657523963169

Epoch: 5| Step: 5
Training loss: 3.192770098057148
Validation loss: 2.5942781496019642

Epoch: 5| Step: 6
Training loss: 2.233019117294867
Validation loss: 2.56299139754109

Epoch: 5| Step: 7
Training loss: 2.806146693717668
Validation loss: 2.551922109775517

Epoch: 5| Step: 8
Training loss: 2.536345263290607
Validation loss: 2.533977914820337

Epoch: 5| Step: 9
Training loss: 2.9245974663132395
Validation loss: 2.59970698760403

Epoch: 5| Step: 10
Training loss: 2.826545147607953
Validation loss: 2.579962348717311

Epoch: 236| Step: 0
Training loss: 2.019431962131063
Validation loss: 2.5414576161223863

Epoch: 5| Step: 1
Training loss: 1.7948733915769022
Validation loss: 2.514225793770591

Epoch: 5| Step: 2
Training loss: 2.419948082043827
Validation loss: 2.5555395169607147

Epoch: 5| Step: 3
Training loss: 2.8359697828741055
Validation loss: 2.559676205440502

Epoch: 5| Step: 4
Training loss: 2.418698103789092
Validation loss: 2.556412591212945

Epoch: 5| Step: 5
Training loss: 2.531572486208856
Validation loss: 2.5091657259075415

Epoch: 5| Step: 6
Training loss: 3.0289980988822403
Validation loss: 2.5388859078940356

Epoch: 5| Step: 7
Training loss: 2.3136482481013365
Validation loss: 2.5310258643321712

Epoch: 5| Step: 8
Training loss: 2.9487378669414768
Validation loss: 2.4960978798090134

Epoch: 5| Step: 9
Training loss: 2.6790341840373597
Validation loss: 2.5400291340770123

Epoch: 5| Step: 10
Training loss: 2.623195663856443
Validation loss: 2.545997885823519

Epoch: 237| Step: 0
Training loss: 2.0146015733158116
Validation loss: 2.59196005560836

Epoch: 5| Step: 1
Training loss: 3.2694574527775186
Validation loss: 2.575635776430692

Epoch: 5| Step: 2
Training loss: 2.679752805041982
Validation loss: 2.5273524187199943

Epoch: 5| Step: 3
Training loss: 2.7617684755070777
Validation loss: 2.5219807665575686

Epoch: 5| Step: 4
Training loss: 2.209894156532152
Validation loss: 2.580545879192381

Epoch: 5| Step: 5
Training loss: 3.0073213250539133
Validation loss: 2.5511874563756742

Epoch: 5| Step: 6
Training loss: 2.4250611051745823
Validation loss: 2.6040141484707724

Epoch: 5| Step: 7
Training loss: 2.079854374702879
Validation loss: 2.5730627293399064

Epoch: 5| Step: 8
Training loss: 2.544576906960568
Validation loss: 2.533849453231127

Epoch: 5| Step: 9
Training loss: 2.6633834197101556
Validation loss: 2.5617246117476773

Epoch: 5| Step: 10
Training loss: 2.5212725632376136
Validation loss: 2.570221144125555

Epoch: 238| Step: 0
Training loss: 2.85453962873252
Validation loss: 2.586472244373632

Epoch: 5| Step: 1
Training loss: 2.95685418630631
Validation loss: 2.5916095653624773

Epoch: 5| Step: 2
Training loss: 2.6714736012334845
Validation loss: 2.524905748698748

Epoch: 5| Step: 3
Training loss: 2.1902243951250693
Validation loss: 2.573559864029817

Epoch: 5| Step: 4
Training loss: 2.4695319373936284
Validation loss: 2.5766239240004563

Epoch: 5| Step: 5
Training loss: 2.988192368725167
Validation loss: 2.5730011309909733

Epoch: 5| Step: 6
Training loss: 2.566512989628893
Validation loss: 2.567234984024846

Epoch: 5| Step: 7
Training loss: 2.1648114282183735
Validation loss: 2.55191194629762

Epoch: 5| Step: 8
Training loss: 2.2389452949509416
Validation loss: 2.604112130527221

Epoch: 5| Step: 9
Training loss: 2.612184576677972
Validation loss: 2.602985225983864

Epoch: 5| Step: 10
Training loss: 2.603169354522286
Validation loss: 2.511724182009738

Epoch: 239| Step: 0
Training loss: 2.740572113953542
Validation loss: 2.5423852162710503

Epoch: 5| Step: 1
Training loss: 2.6394358107227727
Validation loss: 2.544204879498543

Epoch: 5| Step: 2
Training loss: 2.1758665003075546
Validation loss: 2.5472979531290134

Epoch: 5| Step: 3
Training loss: 2.7711615881885274
Validation loss: 2.56917558571751

Epoch: 5| Step: 4
Training loss: 2.2829748452363496
Validation loss: 2.531523089842131

Epoch: 5| Step: 5
Training loss: 2.2119895130619396
Validation loss: 2.6084935098977935

Epoch: 5| Step: 6
Training loss: 2.733091914362471
Validation loss: 2.5803668862648244

Epoch: 5| Step: 7
Training loss: 3.1420935997573705
Validation loss: 2.541135013867856

Epoch: 5| Step: 8
Training loss: 2.661202335674408
Validation loss: 2.5308027379972944

Epoch: 5| Step: 9
Training loss: 2.4181025503481535
Validation loss: 2.5339137303677304

Epoch: 5| Step: 10
Training loss: 2.342262813484614
Validation loss: 2.584662988057487

Epoch: 240| Step: 0
Training loss: 2.763214440113764
Validation loss: 2.5729518703805536

Epoch: 5| Step: 1
Training loss: 2.6261713048663946
Validation loss: 2.558856393596843

Epoch: 5| Step: 2
Training loss: 2.8773329847239557
Validation loss: 2.566196641053731

Epoch: 5| Step: 3
Training loss: 2.480951313326785
Validation loss: 2.535783412635099

Epoch: 5| Step: 4
Training loss: 2.3796631058502737
Validation loss: 2.5430937246856886

Epoch: 5| Step: 5
Training loss: 1.8189866636268648
Validation loss: 2.560543543978012

Epoch: 5| Step: 6
Training loss: 2.9735418897737524
Validation loss: 2.585677753942184

Epoch: 5| Step: 7
Training loss: 2.305209239804974
Validation loss: 2.5367716607321924

Epoch: 5| Step: 8
Training loss: 2.911516074129516
Validation loss: 2.567177114507567

Epoch: 5| Step: 9
Training loss: 1.9776762587439365
Validation loss: 2.5554005430354847

Epoch: 5| Step: 10
Training loss: 2.732613044906311
Validation loss: 2.525556913665724

Epoch: 241| Step: 0
Training loss: 2.62518119186669
Validation loss: 2.5440022220795995

Epoch: 5| Step: 1
Training loss: 2.2412896568419485
Validation loss: 2.569772238102004

Epoch: 5| Step: 2
Training loss: 1.7542059627429445
Validation loss: 2.552183502287391

Epoch: 5| Step: 3
Training loss: 2.9378833926375214
Validation loss: 2.534211561593839

Epoch: 5| Step: 4
Training loss: 2.3366560325253602
Validation loss: 2.5412348019427147

Epoch: 5| Step: 5
Training loss: 2.2283213310898056
Validation loss: 2.5225946101963497

Epoch: 5| Step: 6
Training loss: 2.523210166871482
Validation loss: 2.5391508151740463

Epoch: 5| Step: 7
Training loss: 2.471608305962542
Validation loss: 2.5501657658085404

Epoch: 5| Step: 8
Training loss: 2.6262279544796527
Validation loss: 2.553467411689826

Epoch: 5| Step: 9
Training loss: 1.9717504253423268
Validation loss: 2.5529632243583853

Epoch: 5| Step: 10
Training loss: 3.816479716379626
Validation loss: 2.5199074207045316

Epoch: 242| Step: 0
Training loss: 2.4890819560773454
Validation loss: 2.5556793159144617

Epoch: 5| Step: 1
Training loss: 2.836931206918935
Validation loss: 2.5661240848670865

Epoch: 5| Step: 2
Training loss: 2.400684906664689
Validation loss: 2.5493563898447764

Epoch: 5| Step: 3
Training loss: 2.983227414287903
Validation loss: 2.5133595381127622

Epoch: 5| Step: 4
Training loss: 1.8043652531645007
Validation loss: 2.5125096931039943

Epoch: 5| Step: 5
Training loss: 2.347537223350175
Validation loss: 2.5303642539172246

Epoch: 5| Step: 6
Training loss: 2.6930099603672026
Validation loss: 2.5734978014110337

Epoch: 5| Step: 7
Training loss: 2.746083765567953
Validation loss: 2.559986941132194

Epoch: 5| Step: 8
Training loss: 2.6469881035826006
Validation loss: 2.537148494551964

Epoch: 5| Step: 9
Training loss: 2.6080905699771266
Validation loss: 2.5422507942394366

Epoch: 5| Step: 10
Training loss: 2.673648803136992
Validation loss: 2.5346252056110297

Epoch: 243| Step: 0
Training loss: 2.351310944646996
Validation loss: 2.5491753436882076

Epoch: 5| Step: 1
Training loss: 2.919140357108495
Validation loss: 2.5530526512563805

Epoch: 5| Step: 2
Training loss: 2.7010693092760842
Validation loss: 2.6075032736019605

Epoch: 5| Step: 3
Training loss: 2.6773057145154437
Validation loss: 2.5173671353364364

Epoch: 5| Step: 4
Training loss: 2.230848183233943
Validation loss: 2.5548345132065946

Epoch: 5| Step: 5
Training loss: 2.591584462112218
Validation loss: 2.5737245425670894

Epoch: 5| Step: 6
Training loss: 2.1295464069426875
Validation loss: 2.5123767277060782

Epoch: 5| Step: 7
Training loss: 2.3446320971898973
Validation loss: 2.5941751484769324

Epoch: 5| Step: 8
Training loss: 2.9564929305865757
Validation loss: 2.5780019980006736

Epoch: 5| Step: 9
Training loss: 2.607603831139489
Validation loss: 2.581829974971791

Epoch: 5| Step: 10
Training loss: 2.5816419253098557
Validation loss: 2.5671944834886475

Epoch: 244| Step: 0
Training loss: 1.9978489633279053
Validation loss: 2.5850489421065714

Epoch: 5| Step: 1
Training loss: 2.391512637434167
Validation loss: 2.5281510144212294

Epoch: 5| Step: 2
Training loss: 2.778695808874083
Validation loss: 2.541173325914377

Epoch: 5| Step: 3
Training loss: 2.8136951874012546
Validation loss: 2.587739456476371

Epoch: 5| Step: 4
Training loss: 2.686631883091567
Validation loss: 2.5864649037383205

Epoch: 5| Step: 5
Training loss: 1.662550189759283
Validation loss: 2.5396709026852218

Epoch: 5| Step: 6
Training loss: 3.0728475961627457
Validation loss: 2.536118293672096

Epoch: 5| Step: 7
Training loss: 3.2056618669739785
Validation loss: 2.5290590864423943

Epoch: 5| Step: 8
Training loss: 2.175146808273576
Validation loss: 2.5868045220973244

Epoch: 5| Step: 9
Training loss: 2.507818774634382
Validation loss: 2.5268231645195263

Epoch: 5| Step: 10
Training loss: 2.3851522996046963
Validation loss: 2.521026419266439

Epoch: 245| Step: 0
Training loss: 2.741123960478881
Validation loss: 2.561176289301528

Epoch: 5| Step: 1
Training loss: 2.259405293663883
Validation loss: 2.579766922969202

Epoch: 5| Step: 2
Training loss: 2.461152179376324
Validation loss: 2.525044127778953

Epoch: 5| Step: 3
Training loss: 2.447181450567561
Validation loss: 2.548276271035395

Epoch: 5| Step: 4
Training loss: 2.4584459074290486
Validation loss: 2.5336268588753597

Epoch: 5| Step: 5
Training loss: 2.0543352992832262
Validation loss: 2.560314722330481

Epoch: 5| Step: 6
Training loss: 2.9823281823650967
Validation loss: 2.5235075272137113

Epoch: 5| Step: 7
Training loss: 2.4804427979080366
Validation loss: 2.5435642335145947

Epoch: 5| Step: 8
Training loss: 2.367504639988575
Validation loss: 2.5321212620173097

Epoch: 5| Step: 9
Training loss: 2.759360076414645
Validation loss: 2.5563891540259474

Epoch: 5| Step: 10
Training loss: 2.8748178839016196
Validation loss: 2.5699373139661175

Epoch: 246| Step: 0
Training loss: 2.4741158418541307
Validation loss: 2.5371101894284362

Epoch: 5| Step: 1
Training loss: 2.2136866862345292
Validation loss: 2.564584850868192

Epoch: 5| Step: 2
Training loss: 2.4954750117994333
Validation loss: 2.5237633015329544

Epoch: 5| Step: 3
Training loss: 2.770693687036742
Validation loss: 2.5469721796915237

Epoch: 5| Step: 4
Training loss: 2.654992916866416
Validation loss: 2.5513814142110065

Epoch: 5| Step: 5
Training loss: 2.756839656253027
Validation loss: 2.5716299568029313

Epoch: 5| Step: 6
Training loss: 2.500453907768157
Validation loss: 2.556988563433322

Epoch: 5| Step: 7
Training loss: 2.144217046014111
Validation loss: 2.5808792412509853

Epoch: 5| Step: 8
Training loss: 2.440184850726045
Validation loss: 2.5410580349314436

Epoch: 5| Step: 9
Training loss: 2.9458722865124995
Validation loss: 2.5600419028743735

Epoch: 5| Step: 10
Training loss: 2.6918102564663853
Validation loss: 2.533637908211452

Epoch: 247| Step: 0
Training loss: 2.240745479478312
Validation loss: 2.519298068327323

Epoch: 5| Step: 1
Training loss: 2.586539575839982
Validation loss: 2.5369935850686196

Epoch: 5| Step: 2
Training loss: 2.782752584833006
Validation loss: 2.533593465707969

Epoch: 5| Step: 3
Training loss: 2.5080781124550864
Validation loss: 2.5721620124951285

Epoch: 5| Step: 4
Training loss: 2.2982922807014208
Validation loss: 2.567513907786768

Epoch: 5| Step: 5
Training loss: 2.107983957023304
Validation loss: 2.5577144842590203

Epoch: 5| Step: 6
Training loss: 2.5507291873216262
Validation loss: 2.5254636302122937

Epoch: 5| Step: 7
Training loss: 3.064958325300303
Validation loss: 2.567837835915555

Epoch: 5| Step: 8
Training loss: 2.6761999095093696
Validation loss: 2.586092939377937

Epoch: 5| Step: 9
Training loss: 2.6340798064403397
Validation loss: 2.5628928016758774

Epoch: 5| Step: 10
Training loss: 2.7302335056588776
Validation loss: 2.549411342443978

Epoch: 248| Step: 0
Training loss: 1.9313001187929046
Validation loss: 2.5460454028914423

Epoch: 5| Step: 1
Training loss: 3.1090622941160007
Validation loss: 2.5611230725936567

Epoch: 5| Step: 2
Training loss: 2.633101993571655
Validation loss: 2.573840667168788

Epoch: 5| Step: 3
Training loss: 2.543627206898798
Validation loss: 2.5955508509124012

Epoch: 5| Step: 4
Training loss: 2.64868117930292
Validation loss: 2.5492178471608753

Epoch: 5| Step: 5
Training loss: 2.550205884363618
Validation loss: 2.5593728333540073

Epoch: 5| Step: 6
Training loss: 2.9530755901744508
Validation loss: 2.5409509796676484

Epoch: 5| Step: 7
Training loss: 2.5549607437014505
Validation loss: 2.5607492442286137

Epoch: 5| Step: 8
Training loss: 2.7605782707461883
Validation loss: 2.5836964208845874

Epoch: 5| Step: 9
Training loss: 2.116674494791449
Validation loss: 2.5373020154085584

Epoch: 5| Step: 10
Training loss: 2.648563438279434
Validation loss: 2.5921620443692763

Epoch: 249| Step: 0
Training loss: 2.6422509599189987
Validation loss: 2.544917553441931

Epoch: 5| Step: 1
Training loss: 3.131459997753332
Validation loss: 2.5619075129205915

Epoch: 5| Step: 2
Training loss: 2.6485640684058755
Validation loss: 2.5537749707188926

Epoch: 5| Step: 3
Training loss: 2.5147505478358236
Validation loss: 2.540473512351268

Epoch: 5| Step: 4
Training loss: 2.5388719692635657
Validation loss: 2.5454039939212385

Epoch: 5| Step: 5
Training loss: 1.7766023871272973
Validation loss: 2.537259789232757

Epoch: 5| Step: 6
Training loss: 2.6148237343310723
Validation loss: 2.576121975426677

Epoch: 5| Step: 7
Training loss: 2.596754241596143
Validation loss: 2.5717338638815193

Epoch: 5| Step: 8
Training loss: 2.454863400048306
Validation loss: 2.5801806595211496

Epoch: 5| Step: 9
Training loss: 2.6629597011815984
Validation loss: 2.558315257622229

Epoch: 5| Step: 10
Training loss: 2.526941093431513
Validation loss: 2.563541657839659

Epoch: 250| Step: 0
Training loss: 2.7179798482354167
Validation loss: 2.5281541528662026

Epoch: 5| Step: 1
Training loss: 2.2475472963170606
Validation loss: 2.582196155723261

Epoch: 5| Step: 2
Training loss: 2.6387136189217477
Validation loss: 2.5691992704722533

Epoch: 5| Step: 3
Training loss: 2.356077504610821
Validation loss: 2.516178323748295

Epoch: 5| Step: 4
Training loss: 2.202293942670759
Validation loss: 2.5268931445760465

Epoch: 5| Step: 5
Training loss: 2.613563237279245
Validation loss: 2.5802577748309496

Epoch: 5| Step: 6
Training loss: 2.01866488439682
Validation loss: 2.5739462499094663

Epoch: 5| Step: 7
Training loss: 2.495269209379343
Validation loss: 2.5550559663347197

Epoch: 5| Step: 8
Training loss: 3.078340629344556
Validation loss: 2.5371539761922595

Epoch: 5| Step: 9
Training loss: 2.6016425959540483
Validation loss: 2.478687506518471

Epoch: 5| Step: 10
Training loss: 3.006992931919652
Validation loss: 2.5582283486154833

Epoch: 251| Step: 0
Training loss: 3.4147042166767734
Validation loss: 2.5485872750746674

Epoch: 5| Step: 1
Training loss: 2.1926893533955933
Validation loss: 2.5483449215512386

Epoch: 5| Step: 2
Training loss: 1.7989090394947986
Validation loss: 2.5644218977066164

Epoch: 5| Step: 3
Training loss: 2.4504437219944197
Validation loss: 2.5603070083111708

Epoch: 5| Step: 4
Training loss: 2.4048170306421857
Validation loss: 2.5477115030693205

Epoch: 5| Step: 5
Training loss: 2.774675979255228
Validation loss: 2.569909371444779

Epoch: 5| Step: 6
Training loss: 2.6166742077696514
Validation loss: 2.5659306269741955

Epoch: 5| Step: 7
Training loss: 2.4978069222983477
Validation loss: 2.544863424549995

Epoch: 5| Step: 8
Training loss: 2.6479552063337017
Validation loss: 2.5367654304261027

Epoch: 5| Step: 9
Training loss: 2.2750643123716845
Validation loss: 2.583894105741367

Epoch: 5| Step: 10
Training loss: 2.7580271521179895
Validation loss: 2.5690299949167956

Epoch: 252| Step: 0
Training loss: 1.9859414713630015
Validation loss: 2.562026535621704

Epoch: 5| Step: 1
Training loss: 2.5649459144586073
Validation loss: 2.5777054749565034

Epoch: 5| Step: 2
Training loss: 2.628128821044757
Validation loss: 2.5618643823998393

Epoch: 5| Step: 3
Training loss: 2.5542073863166346
Validation loss: 2.589981625063726

Epoch: 5| Step: 4
Training loss: 1.9511011242568685
Validation loss: 2.572356477729575

Epoch: 5| Step: 5
Training loss: 3.1718261414321196
Validation loss: 2.572687631487923

Epoch: 5| Step: 6
Training loss: 2.4086641363846306
Validation loss: 2.5712911821752336

Epoch: 5| Step: 7
Training loss: 2.385565496296755
Validation loss: 2.564734512377802

Epoch: 5| Step: 8
Training loss: 2.6065707185490132
Validation loss: 2.550644353664141

Epoch: 5| Step: 9
Training loss: 2.8188778934941783
Validation loss: 2.5648929828623164

Epoch: 5| Step: 10
Training loss: 2.5835061066800624
Validation loss: 2.5812877914958388

Epoch: 253| Step: 0
Training loss: 1.8853213108741453
Validation loss: 2.5494966847092537

Epoch: 5| Step: 1
Training loss: 2.7550436930990787
Validation loss: 2.565466955221616

Epoch: 5| Step: 2
Training loss: 2.93513572184106
Validation loss: 2.547440654851525

Epoch: 5| Step: 3
Training loss: 2.175610958537329
Validation loss: 2.5582312607618722

Epoch: 5| Step: 4
Training loss: 2.0082751976663378
Validation loss: 2.6257306892147234

Epoch: 5| Step: 5
Training loss: 2.5585588991543453
Validation loss: 2.5119146888987705

Epoch: 5| Step: 6
Training loss: 2.4412853485689063
Validation loss: 2.540981944537086

Epoch: 5| Step: 7
Training loss: 2.996029292361962
Validation loss: 2.546945759776558

Epoch: 5| Step: 8
Training loss: 2.5887422132167734
Validation loss: 2.608345856948232

Epoch: 5| Step: 9
Training loss: 3.103536213253768
Validation loss: 2.5750478080789985

Epoch: 5| Step: 10
Training loss: 2.1975187571205685
Validation loss: 2.6024519064477185

Epoch: 254| Step: 0
Training loss: 2.64568498651135
Validation loss: 2.542614317537314

Epoch: 5| Step: 1
Training loss: 2.6725216802390315
Validation loss: 2.531721032040042

Epoch: 5| Step: 2
Training loss: 2.4079769922469003
Validation loss: 2.5550744988260843

Epoch: 5| Step: 3
Training loss: 2.9282745616256958
Validation loss: 2.529460402477096

Epoch: 5| Step: 4
Training loss: 2.8998621809208385
Validation loss: 2.5646938514049316

Epoch: 5| Step: 5
Training loss: 2.19924346747322
Validation loss: 2.5139126180990083

Epoch: 5| Step: 6
Training loss: 2.1185889303823715
Validation loss: 2.5706205517884175

Epoch: 5| Step: 7
Training loss: 2.5891751308034747
Validation loss: 2.560874090996557

Epoch: 5| Step: 8
Training loss: 2.4375135959343877
Validation loss: 2.513470458206894

Epoch: 5| Step: 9
Training loss: 2.3095472919373328
Validation loss: 2.568103855585378

Epoch: 5| Step: 10
Training loss: 2.7411377030317943
Validation loss: 2.5434328018770676

Epoch: 255| Step: 0
Training loss: 2.887942002060149
Validation loss: 2.507088916481825

Epoch: 5| Step: 1
Training loss: 2.3428698094952662
Validation loss: 2.533288447595537

Epoch: 5| Step: 2
Training loss: 3.0470685848458343
Validation loss: 2.6102104615529664

Epoch: 5| Step: 3
Training loss: 2.134662315053672
Validation loss: 2.529870341289727

Epoch: 5| Step: 4
Training loss: 2.2913630775731244
Validation loss: 2.540579093796163

Epoch: 5| Step: 5
Training loss: 2.9025001535078823
Validation loss: 2.543349052859561

Epoch: 5| Step: 6
Training loss: 2.4389489586726194
Validation loss: 2.5441386132571413

Epoch: 5| Step: 7
Training loss: 1.961326834034908
Validation loss: 2.587225923373591

Epoch: 5| Step: 8
Training loss: 2.2440398005187556
Validation loss: 2.5483303576155563

Epoch: 5| Step: 9
Training loss: 2.7996685206522227
Validation loss: 2.5508763271500174

Epoch: 5| Step: 10
Training loss: 2.663451988989129
Validation loss: 2.5846754151230096

Epoch: 256| Step: 0
Training loss: 2.3250538071179454
Validation loss: 2.5874027940760076

Epoch: 5| Step: 1
Training loss: 2.307019931702151
Validation loss: 2.5536322806332676

Epoch: 5| Step: 2
Training loss: 2.7939305496759137
Validation loss: 2.4851923855752056

Epoch: 5| Step: 3
Training loss: 3.0246418764599157
Validation loss: 2.563766824644655

Epoch: 5| Step: 4
Training loss: 2.729236504823551
Validation loss: 2.559898146043883

Epoch: 5| Step: 5
Training loss: 2.1616494948333282
Validation loss: 2.518981707809

Epoch: 5| Step: 6
Training loss: 2.2855119998861384
Validation loss: 2.583493509265591

Epoch: 5| Step: 7
Training loss: 2.578723999720761
Validation loss: 2.565306309631142

Epoch: 5| Step: 8
Training loss: 2.0508448418339937
Validation loss: 2.54793068558605

Epoch: 5| Step: 9
Training loss: 2.676479454556003
Validation loss: 2.5863679738790664

Epoch: 5| Step: 10
Training loss: 2.664946020842889
Validation loss: 2.583874854757188

Epoch: 257| Step: 0
Training loss: 2.944310835040173
Validation loss: 2.5319031414964437

Epoch: 5| Step: 1
Training loss: 2.2405694845603032
Validation loss: 2.600284911984796

Epoch: 5| Step: 2
Training loss: 2.448520104451727
Validation loss: 2.593132005712312

Epoch: 5| Step: 3
Training loss: 2.4301743586901856
Validation loss: 2.6346260398155543

Epoch: 5| Step: 4
Training loss: 2.6884177659128663
Validation loss: 2.556740850706726

Epoch: 5| Step: 5
Training loss: 2.492084465169041
Validation loss: 2.55182420136179

Epoch: 5| Step: 6
Training loss: 2.5692159522475815
Validation loss: 2.564180138982628

Epoch: 5| Step: 7
Training loss: 2.3722424811759546
Validation loss: 2.582319306406016

Epoch: 5| Step: 8
Training loss: 2.653607389092357
Validation loss: 2.5783116764961242

Epoch: 5| Step: 9
Training loss: 2.5640630839438416
Validation loss: 2.558977250289711

Epoch: 5| Step: 10
Training loss: 2.5257203726920157
Validation loss: 2.5375889492847064

Epoch: 258| Step: 0
Training loss: 3.0031162607182935
Validation loss: 2.610746505993056

Epoch: 5| Step: 1
Training loss: 2.9117700799993287
Validation loss: 2.5893952271414986

Epoch: 5| Step: 2
Training loss: 1.5960828126298268
Validation loss: 2.589758948359754

Epoch: 5| Step: 3
Training loss: 2.7566809561688497
Validation loss: 2.527266179558059

Epoch: 5| Step: 4
Training loss: 2.723216629920683
Validation loss: 2.5502730906771918

Epoch: 5| Step: 5
Training loss: 2.557798958138404
Validation loss: 2.572122761661903

Epoch: 5| Step: 6
Training loss: 2.6636778254511735
Validation loss: 2.5572944188143376

Epoch: 5| Step: 7
Training loss: 2.4189512262745634
Validation loss: 2.556618135493849

Epoch: 5| Step: 8
Training loss: 2.064308991539016
Validation loss: 2.5762544430723286

Epoch: 5| Step: 9
Training loss: 2.0692807487700224
Validation loss: 2.524011505318368

Epoch: 5| Step: 10
Training loss: 2.6564667557184034
Validation loss: 2.5265323271907345

Epoch: 259| Step: 0
Training loss: 2.5902692120239696
Validation loss: 2.5668401092473716

Epoch: 5| Step: 1
Training loss: 2.335549618977314
Validation loss: 2.5761588983976207

Epoch: 5| Step: 2
Training loss: 2.8881384800074437
Validation loss: 2.5009751356218612

Epoch: 5| Step: 3
Training loss: 2.776993054703739
Validation loss: 2.5241836455071387

Epoch: 5| Step: 4
Training loss: 2.33632888832201
Validation loss: 2.5897972963841354

Epoch: 5| Step: 5
Training loss: 2.2768272481597385
Validation loss: 2.5527074131569325

Epoch: 5| Step: 6
Training loss: 2.4925155184615657
Validation loss: 2.5469684071602434

Epoch: 5| Step: 7
Training loss: 1.8701349083282468
Validation loss: 2.537906517742427

Epoch: 5| Step: 8
Training loss: 1.9345075817615247
Validation loss: 2.5400575344916305

Epoch: 5| Step: 9
Training loss: 2.9479943974000444
Validation loss: 2.550011653137604

Epoch: 5| Step: 10
Training loss: 2.5271650719900403
Validation loss: 2.563636939747672

Epoch: 260| Step: 0
Training loss: 2.699332779988937
Validation loss: 2.5844699219671927

Epoch: 5| Step: 1
Training loss: 2.3930703415884036
Validation loss: 2.5905495320100416

Epoch: 5| Step: 2
Training loss: 2.9904751571697457
Validation loss: 2.579587744310409

Epoch: 5| Step: 3
Training loss: 2.2441577296522324
Validation loss: 2.5420623732166385

Epoch: 5| Step: 4
Training loss: 2.4301386472606183
Validation loss: 2.564216581054591

Epoch: 5| Step: 5
Training loss: 2.9150655620654806
Validation loss: 2.529201197472528

Epoch: 5| Step: 6
Training loss: 2.227649303017943
Validation loss: 2.5939320415015077

Epoch: 5| Step: 7
Training loss: 1.8733927513804154
Validation loss: 2.545321850270471

Epoch: 5| Step: 8
Training loss: 2.333991321250124
Validation loss: 2.547334522490355

Epoch: 5| Step: 9
Training loss: 2.7303595132219587
Validation loss: 2.555983513544512

Epoch: 5| Step: 10
Training loss: 2.6488799229181414
Validation loss: 2.5161483537188727

Epoch: 261| Step: 0
Training loss: 2.863249441597279
Validation loss: 2.5670762137120775

Epoch: 5| Step: 1
Training loss: 2.7390228007475836
Validation loss: 2.5761319896518646

Epoch: 5| Step: 2
Training loss: 2.444084273400948
Validation loss: 2.551925648950816

Epoch: 5| Step: 3
Training loss: 2.543015252551001
Validation loss: 2.5508561767424047

Epoch: 5| Step: 4
Training loss: 2.018590121241973
Validation loss: 2.563911361455715

Epoch: 5| Step: 5
Training loss: 2.854817411392991
Validation loss: 2.520403521703557

Epoch: 5| Step: 6
Training loss: 2.3680504966326312
Validation loss: 2.553593633464897

Epoch: 5| Step: 7
Training loss: 2.1716570847778813
Validation loss: 2.5547669402023323

Epoch: 5| Step: 8
Training loss: 2.6973842453890304
Validation loss: 2.570650935882869

Epoch: 5| Step: 9
Training loss: 2.2747626883009
Validation loss: 2.5731191926995294

Epoch: 5| Step: 10
Training loss: 2.694424424856301
Validation loss: 2.51416688970261

Epoch: 262| Step: 0
Training loss: 2.53827615152107
Validation loss: 2.538869738712077

Epoch: 5| Step: 1
Training loss: 1.8886237153123333
Validation loss: 2.558621205903768

Epoch: 5| Step: 2
Training loss: 2.328262939463045
Validation loss: 2.598131104425715

Epoch: 5| Step: 3
Training loss: 3.088400174395642
Validation loss: 2.5179286236654974

Epoch: 5| Step: 4
Training loss: 2.262690676246869
Validation loss: 2.572205125826657

Epoch: 5| Step: 5
Training loss: 2.7025345173906636
Validation loss: 2.5662499318677465

Epoch: 5| Step: 6
Training loss: 2.299628235998965
Validation loss: 2.563650339231971

Epoch: 5| Step: 7
Training loss: 2.068397528825094
Validation loss: 2.559076965737623

Epoch: 5| Step: 8
Training loss: 2.6284595580462926
Validation loss: 2.533663565353003

Epoch: 5| Step: 9
Training loss: 2.818886520564514
Validation loss: 2.5446901309155527

Epoch: 5| Step: 10
Training loss: 2.6981959744560893
Validation loss: 2.5257456443752564

Epoch: 263| Step: 0
Training loss: 2.406135457272744
Validation loss: 2.564962728842414

Epoch: 5| Step: 1
Training loss: 2.6274219420767846
Validation loss: 2.5537700156454823

Epoch: 5| Step: 2
Training loss: 2.447602098963611
Validation loss: 2.56166975416107

Epoch: 5| Step: 3
Training loss: 2.9164894776791304
Validation loss: 2.579785482654448

Epoch: 5| Step: 4
Training loss: 2.3953370174539237
Validation loss: 2.613209362964358

Epoch: 5| Step: 5
Training loss: 2.756859720136302
Validation loss: 2.6140319461139097

Epoch: 5| Step: 6
Training loss: 2.274372550877078
Validation loss: 2.5614014318377194

Epoch: 5| Step: 7
Training loss: 2.2799948806035975
Validation loss: 2.5981292365548216

Epoch: 5| Step: 8
Training loss: 2.260440339932799
Validation loss: 2.5374233733570986

Epoch: 5| Step: 9
Training loss: 2.4558582022548694
Validation loss: 2.616398492123191

Epoch: 5| Step: 10
Training loss: 2.8514315640422625
Validation loss: 2.5900782068819925

Epoch: 264| Step: 0
Training loss: 2.2588012008901583
Validation loss: 2.5418659503933143

Epoch: 5| Step: 1
Training loss: 2.636668384212251
Validation loss: 2.6044616696200404

Epoch: 5| Step: 2
Training loss: 1.9855988100394126
Validation loss: 2.510386702741197

Epoch: 5| Step: 3
Training loss: 2.6138633456070455
Validation loss: 2.5784895046647245

Epoch: 5| Step: 4
Training loss: 2.2920522076517624
Validation loss: 2.5425785842127864

Epoch: 5| Step: 5
Training loss: 2.634657306862369
Validation loss: 2.5580942940984106

Epoch: 5| Step: 6
Training loss: 2.764200048221129
Validation loss: 2.6075865179798265

Epoch: 5| Step: 7
Training loss: 2.8521864952970866
Validation loss: 2.560111814059553

Epoch: 5| Step: 8
Training loss: 2.3440252523917264
Validation loss: 2.5502526017603295

Epoch: 5| Step: 9
Training loss: 1.8913649695144759
Validation loss: 2.586674042233345

Epoch: 5| Step: 10
Training loss: 2.8311141429920155
Validation loss: 2.577530048392901

Epoch: 265| Step: 0
Training loss: 2.3748026314089707
Validation loss: 2.521530112698319

Epoch: 5| Step: 1
Training loss: 2.4110087119047527
Validation loss: 2.5683488184091483

Epoch: 5| Step: 2
Training loss: 2.37441989439524
Validation loss: 2.555443297099737

Epoch: 5| Step: 3
Training loss: 3.1421691742243607
Validation loss: 2.5657768856948366

Epoch: 5| Step: 4
Training loss: 2.4487292516977286
Validation loss: 2.5541652479165973

Epoch: 5| Step: 5
Training loss: 2.686882214178253
Validation loss: 2.576910089274969

Epoch: 5| Step: 6
Training loss: 2.4189804992457464
Validation loss: 2.562562244938866

Epoch: 5| Step: 7
Training loss: 2.5634518227972873
Validation loss: 2.5433438259827543

Epoch: 5| Step: 8
Training loss: 2.334481490437034
Validation loss: 2.5593970896196976

Epoch: 5| Step: 9
Training loss: 2.530538765155667
Validation loss: 2.499330388397509

Epoch: 5| Step: 10
Training loss: 1.76495503905956
Validation loss: 2.5725697452936473

Epoch: 266| Step: 0
Training loss: 1.9028559001221397
Validation loss: 2.545553076093212

Epoch: 5| Step: 1
Training loss: 2.7701218248425454
Validation loss: 2.551936181057412

Epoch: 5| Step: 2
Training loss: 2.779879971938758
Validation loss: 2.5612938796405347

Epoch: 5| Step: 3
Training loss: 2.3659603349870806
Validation loss: 2.5833414364097873

Epoch: 5| Step: 4
Training loss: 2.845819747095551
Validation loss: 2.57990402338875

Epoch: 5| Step: 5
Training loss: 2.2276777720129117
Validation loss: 2.5388411018516073

Epoch: 5| Step: 6
Training loss: 2.0284574826857282
Validation loss: 2.5567908668322703

Epoch: 5| Step: 7
Training loss: 2.990791174278895
Validation loss: 2.527219333449634

Epoch: 5| Step: 8
Training loss: 2.260322627442143
Validation loss: 2.5629093604527236

Epoch: 5| Step: 9
Training loss: 2.9273649648117046
Validation loss: 2.54624774918485

Epoch: 5| Step: 10
Training loss: 2.323082910812753
Validation loss: 2.558696460141795

Epoch: 267| Step: 0
Training loss: 2.8179233396132357
Validation loss: 2.5276443047368122

Epoch: 5| Step: 1
Training loss: 2.724577697788525
Validation loss: 2.5635913222760505

Epoch: 5| Step: 2
Training loss: 2.6527740174467143
Validation loss: 2.5507483346833606

Epoch: 5| Step: 3
Training loss: 2.9883978926887993
Validation loss: 2.576114938676141

Epoch: 5| Step: 4
Training loss: 2.4058114184694097
Validation loss: 2.5416496924511507

Epoch: 5| Step: 5
Training loss: 1.9967934414202624
Validation loss: 2.5828778544816817

Epoch: 5| Step: 6
Training loss: 2.1790825335841197
Validation loss: 2.543702607414929

Epoch: 5| Step: 7
Training loss: 2.2485431617155265
Validation loss: 2.5411752931541765

Epoch: 5| Step: 8
Training loss: 2.322244475631722
Validation loss: 2.5574277333642543

Epoch: 5| Step: 9
Training loss: 2.4620855650733247
Validation loss: 2.612914057767032

Epoch: 5| Step: 10
Training loss: 2.5326472064331065
Validation loss: 2.587916781447497

Epoch: 268| Step: 0
Training loss: 2.559619121530046
Validation loss: 2.5090569877701134

Epoch: 5| Step: 1
Training loss: 2.729484762819732
Validation loss: 2.572692436526611

Epoch: 5| Step: 2
Training loss: 2.41200499521121
Validation loss: 2.512344073527977

Epoch: 5| Step: 3
Training loss: 3.2077411418843327
Validation loss: 2.5294390608468644

Epoch: 5| Step: 4
Training loss: 2.7157993308981405
Validation loss: 2.610245705094001

Epoch: 5| Step: 5
Training loss: 2.831711660307953
Validation loss: 2.529477522678314

Epoch: 5| Step: 6
Training loss: 2.2673464844877578
Validation loss: 2.563016742834458

Epoch: 5| Step: 7
Training loss: 1.3958916106323327
Validation loss: 2.5582346970101777

Epoch: 5| Step: 8
Training loss: 2.195801487015536
Validation loss: 2.5563842902637575

Epoch: 5| Step: 9
Training loss: 2.154031026420177
Validation loss: 2.5800556738534146

Epoch: 5| Step: 10
Training loss: 2.5192673182678202
Validation loss: 2.5341188779653567

Epoch: 269| Step: 0
Training loss: 2.6132396472305066
Validation loss: 2.5798104443336314

Epoch: 5| Step: 1
Training loss: 2.6851420149371727
Validation loss: 2.560475869328162

Epoch: 5| Step: 2
Training loss: 2.514895315551157
Validation loss: 2.5595691506550615

Epoch: 5| Step: 3
Training loss: 2.5017146905927223
Validation loss: 2.5868881961908983

Epoch: 5| Step: 4
Training loss: 2.1468955315242537
Validation loss: 2.5875095443941905

Epoch: 5| Step: 5
Training loss: 3.2467591192514393
Validation loss: 2.5781319676240133

Epoch: 5| Step: 6
Training loss: 2.0635733845747746
Validation loss: 2.52996950665613

Epoch: 5| Step: 7
Training loss: 2.0185613018457187
Validation loss: 2.527664747696921

Epoch: 5| Step: 8
Training loss: 2.6736652110077244
Validation loss: 2.5671304634371084

Epoch: 5| Step: 9
Training loss: 2.5616373610531715
Validation loss: 2.5859359831917543

Epoch: 5| Step: 10
Training loss: 2.3909243726588105
Validation loss: 2.5446782828066152

Epoch: 270| Step: 0
Training loss: 2.882713584960365
Validation loss: 2.604475919675774

Epoch: 5| Step: 1
Training loss: 2.42158988997205
Validation loss: 2.5720812606373253

Epoch: 5| Step: 2
Training loss: 2.1535328870413952
Validation loss: 2.574053964642634

Epoch: 5| Step: 3
Training loss: 2.876430321536282
Validation loss: 2.59877463182745

Epoch: 5| Step: 4
Training loss: 2.78347860478764
Validation loss: 2.569453713148037

Epoch: 5| Step: 5
Training loss: 2.655809612792652
Validation loss: 2.5685476904625517

Epoch: 5| Step: 6
Training loss: 2.2758257404853977
Validation loss: 2.567646312324434

Epoch: 5| Step: 7
Training loss: 2.1695649740244405
Validation loss: 2.5442116669473154

Epoch: 5| Step: 8
Training loss: 2.597086679068955
Validation loss: 2.5626114361591177

Epoch: 5| Step: 9
Training loss: 2.2822316814033843
Validation loss: 2.518746649285109

Epoch: 5| Step: 10
Training loss: 1.9342693959437487
Validation loss: 2.5733549785846033

Epoch: 271| Step: 0
Training loss: 1.9967863967652224
Validation loss: 2.528201806049247

Epoch: 5| Step: 1
Training loss: 2.804599516187206
Validation loss: 2.5673858260992417

Epoch: 5| Step: 2
Training loss: 2.6999132778227657
Validation loss: 2.5289874095743237

Epoch: 5| Step: 3
Training loss: 2.145852493151214
Validation loss: 2.565179841681738

Epoch: 5| Step: 4
Training loss: 2.5625803865058923
Validation loss: 2.573454958782415

Epoch: 5| Step: 5
Training loss: 2.4656066197627653
Validation loss: 2.5371526343282276

Epoch: 5| Step: 6
Training loss: 2.296754379738323
Validation loss: 2.568869575136759

Epoch: 5| Step: 7
Training loss: 2.2889285520349474
Validation loss: 2.5816970208497234

Epoch: 5| Step: 8
Training loss: 3.105064893649473
Validation loss: 2.5414796158905864

Epoch: 5| Step: 9
Training loss: 2.142451043476571
Validation loss: 2.5506104415234954

Epoch: 5| Step: 10
Training loss: 2.8557853471033967
Validation loss: 2.552443440797084

Epoch: 272| Step: 0
Training loss: 1.7273139526612844
Validation loss: 2.573053003068215

Epoch: 5| Step: 1
Training loss: 2.2241054965664686
Validation loss: 2.5295970669396857

Epoch: 5| Step: 2
Training loss: 2.8434796886037277
Validation loss: 2.524580373855439

Epoch: 5| Step: 3
Training loss: 2.6412666037922694
Validation loss: 2.5871978514790714

Epoch: 5| Step: 4
Training loss: 3.0530953318970986
Validation loss: 2.591443840043909

Epoch: 5| Step: 5
Training loss: 2.200459159272718
Validation loss: 2.5902977286625832

Epoch: 5| Step: 6
Training loss: 2.3878729444086666
Validation loss: 2.532832292369597

Epoch: 5| Step: 7
Training loss: 2.5547828773169616
Validation loss: 2.5832022517236015

Epoch: 5| Step: 8
Training loss: 2.670765428875067
Validation loss: 2.5823698685121896

Epoch: 5| Step: 9
Training loss: 2.5538688071123876
Validation loss: 2.5600168846327263

Epoch: 5| Step: 10
Training loss: 2.4855332463676336
Validation loss: 2.5897182724423895

Epoch: 273| Step: 0
Training loss: 2.5457749126451206
Validation loss: 2.5268836616289603

Epoch: 5| Step: 1
Training loss: 2.1517095998927243
Validation loss: 2.5722999373316164

Epoch: 5| Step: 2
Training loss: 2.266670038650847
Validation loss: 2.5059813758438194

Epoch: 5| Step: 3
Training loss: 2.2345505225324946
Validation loss: 2.5595552625608553

Epoch: 5| Step: 4
Training loss: 2.6179285622941264
Validation loss: 2.5718945595405156

Epoch: 5| Step: 5
Training loss: 2.2379567708330907
Validation loss: 2.587953974977177

Epoch: 5| Step: 6
Training loss: 2.316633190855406
Validation loss: 2.533244031345188

Epoch: 5| Step: 7
Training loss: 3.2319996537878777
Validation loss: 2.5768778947124984

Epoch: 5| Step: 8
Training loss: 2.6312099752757243
Validation loss: 2.56721040187236

Epoch: 5| Step: 9
Training loss: 2.3355090919012222
Validation loss: 2.553133791084521

Epoch: 5| Step: 10
Training loss: 2.375447682801199
Validation loss: 2.566083487872757

Epoch: 274| Step: 0
Training loss: 2.4680308972655056
Validation loss: 2.554443099818807

Epoch: 5| Step: 1
Training loss: 2.444840358210783
Validation loss: 2.583155188900019

Epoch: 5| Step: 2
Training loss: 2.7463468215258655
Validation loss: 2.5742976930490995

Epoch: 5| Step: 3
Training loss: 3.117020145981431
Validation loss: 2.5392103461676045

Epoch: 5| Step: 4
Training loss: 2.437037986593932
Validation loss: 2.5571939541485054

Epoch: 5| Step: 5
Training loss: 2.0808141990986737
Validation loss: 2.5837810980427065

Epoch: 5| Step: 6
Training loss: 2.533383071143456
Validation loss: 2.558762650941279

Epoch: 5| Step: 7
Training loss: 2.677128673916617
Validation loss: 2.5929918788609063

Epoch: 5| Step: 8
Training loss: 2.1576366665056605
Validation loss: 2.5553868730607996

Epoch: 5| Step: 9
Training loss: 2.145451249361078
Validation loss: 2.5417148424811318

Epoch: 5| Step: 10
Training loss: 2.161524086070823
Validation loss: 2.5979139517373326

Epoch: 275| Step: 0
Training loss: 2.4404596797814375
Validation loss: 2.5574871606957283

Epoch: 5| Step: 1
Training loss: 2.9856759476302535
Validation loss: 2.5761940176695886

Epoch: 5| Step: 2
Training loss: 2.320422648374611
Validation loss: 2.5622653718706214

Epoch: 5| Step: 3
Training loss: 2.8869792319998657
Validation loss: 2.6129864689935736

Epoch: 5| Step: 4
Training loss: 1.9297942467944444
Validation loss: 2.5621414013692796

Epoch: 5| Step: 5
Training loss: 2.3905231728403042
Validation loss: 2.538392696459561

Epoch: 5| Step: 6
Training loss: 2.7446243457114976
Validation loss: 2.570983861875847

Epoch: 5| Step: 7
Training loss: 2.2150075808152097
Validation loss: 2.5552767421234845

Epoch: 5| Step: 8
Training loss: 2.429785821525998
Validation loss: 2.585723169149667

Epoch: 5| Step: 9
Training loss: 2.317192677487578
Validation loss: 2.5365373027638984

Epoch: 5| Step: 10
Training loss: 2.3904930527120754
Validation loss: 2.589739971624073

Epoch: 276| Step: 0
Training loss: 2.536116266912721
Validation loss: 2.5322324233098836

Epoch: 5| Step: 1
Training loss: 3.041807214982185
Validation loss: 2.6227704798958382

Epoch: 5| Step: 2
Training loss: 2.5507196532869516
Validation loss: 2.53918731559362

Epoch: 5| Step: 3
Training loss: 2.7198994278546484
Validation loss: 2.5755112291555124

Epoch: 5| Step: 4
Training loss: 2.0846066462008523
Validation loss: 2.537775319906437

Epoch: 5| Step: 5
Training loss: 2.369592232049938
Validation loss: 2.573109950354622

Epoch: 5| Step: 6
Training loss: 2.8219919038976817
Validation loss: 2.558564727701265

Epoch: 5| Step: 7
Training loss: 1.8866099450623994
Validation loss: 2.584174429777763

Epoch: 5| Step: 8
Training loss: 2.095897654866595
Validation loss: 2.520013784968886

Epoch: 5| Step: 9
Training loss: 2.143200515302174
Validation loss: 2.5368199028941727

Epoch: 5| Step: 10
Training loss: 2.63918929035434
Validation loss: 2.5882646972841687

Epoch: 277| Step: 0
Training loss: 1.7499497270175002
Validation loss: 2.5601266394236273

Epoch: 5| Step: 1
Training loss: 2.324051538431042
Validation loss: 2.5155305135779926

Epoch: 5| Step: 2
Training loss: 2.9194015396535375
Validation loss: 2.540852424504845

Epoch: 5| Step: 3
Training loss: 2.6583430402652257
Validation loss: 2.543864298827543

Epoch: 5| Step: 4
Training loss: 2.83309651301377
Validation loss: 2.5386759958722163

Epoch: 5| Step: 5
Training loss: 3.1675690987990306
Validation loss: 2.540692619012471

Epoch: 5| Step: 6
Training loss: 1.8263851265652982
Validation loss: 2.5947148959386306

Epoch: 5| Step: 7
Training loss: 1.9262806707139883
Validation loss: 2.556819503185552

Epoch: 5| Step: 8
Training loss: 2.3553534585499833
Validation loss: 2.5732365306801332

Epoch: 5| Step: 9
Training loss: 2.874084990474482
Validation loss: 2.523313402899759

Epoch: 5| Step: 10
Training loss: 2.7145983688004462
Validation loss: 2.532874030615814

Epoch: 278| Step: 0
Training loss: 2.682952759885978
Validation loss: 2.5495445533601453

Epoch: 5| Step: 1
Training loss: 2.943270271233406
Validation loss: 2.5543830687433497

Epoch: 5| Step: 2
Training loss: 1.8133879492519485
Validation loss: 2.588700676581232

Epoch: 5| Step: 3
Training loss: 2.4705789286040143
Validation loss: 2.5731404116587857

Epoch: 5| Step: 4
Training loss: 2.2003042140783546
Validation loss: 2.54914896169257

Epoch: 5| Step: 5
Training loss: 2.754992721187994
Validation loss: 2.559676725244277

Epoch: 5| Step: 6
Training loss: 2.011490951529113
Validation loss: 2.543351138869782

Epoch: 5| Step: 7
Training loss: 2.6835185877506462
Validation loss: 2.55670427300051

Epoch: 5| Step: 8
Training loss: 2.27344788224514
Validation loss: 2.5974390684694133

Epoch: 5| Step: 9
Training loss: 2.4294586564507163
Validation loss: 2.589381390112343

Epoch: 5| Step: 10
Training loss: 3.007513650687196
Validation loss: 2.6052842358746937

Epoch: 279| Step: 0
Training loss: 2.3368188732637476
Validation loss: 2.56205692557547

Epoch: 5| Step: 1
Training loss: 2.5993621043651025
Validation loss: 2.5492951076565724

Epoch: 5| Step: 2
Training loss: 2.7410977798551452
Validation loss: 2.5692243419881367

Epoch: 5| Step: 3
Training loss: 2.0834512931489595
Validation loss: 2.586327031516782

Epoch: 5| Step: 4
Training loss: 3.0001719743391964
Validation loss: 2.5326017545342157

Epoch: 5| Step: 5
Training loss: 2.128285280709328
Validation loss: 2.5336010505954807

Epoch: 5| Step: 6
Training loss: 2.2181295682591884
Validation loss: 2.534046926393006

Epoch: 5| Step: 7
Training loss: 2.4101225172059437
Validation loss: 2.5734352187766016

Epoch: 5| Step: 8
Training loss: 2.627362323642022
Validation loss: 2.550894386503518

Epoch: 5| Step: 9
Training loss: 2.51376776523468
Validation loss: 2.5935894194520825

Epoch: 5| Step: 10
Training loss: 2.5283061675806526
Validation loss: 2.5390304995051336

Epoch: 280| Step: 0
Training loss: 2.4186713903304593
Validation loss: 2.565864866871499

Epoch: 5| Step: 1
Training loss: 2.691673143770753
Validation loss: 2.5793038396173875

Epoch: 5| Step: 2
Training loss: 2.7333686938751045
Validation loss: 2.5554183361646823

Epoch: 5| Step: 3
Training loss: 2.4903231257162783
Validation loss: 2.653064500396318

Epoch: 5| Step: 4
Training loss: 2.447694830616285
Validation loss: 2.580637712974208

Epoch: 5| Step: 5
Training loss: 2.3250267355417416
Validation loss: 2.553198885039678

Epoch: 5| Step: 6
Training loss: 2.6227315456114564
Validation loss: 2.5626135420036653

Epoch: 5| Step: 7
Training loss: 2.443198756024157
Validation loss: 2.5059184600217774

Epoch: 5| Step: 8
Training loss: 1.738218293496518
Validation loss: 2.5636950331732065

Epoch: 5| Step: 9
Training loss: 2.7494705730943934
Validation loss: 2.547893558804877

Epoch: 5| Step: 10
Training loss: 2.116352550097098
Validation loss: 2.546972624584118

Epoch: 281| Step: 0
Training loss: 2.070306741958384
Validation loss: 2.5492176953065537

Epoch: 5| Step: 1
Training loss: 2.695905979441381
Validation loss: 2.577761894800844

Epoch: 5| Step: 2
Training loss: 1.4377540695565314
Validation loss: 2.515711661662418

Epoch: 5| Step: 3
Training loss: 2.5658642154366054
Validation loss: 2.582272421579866

Epoch: 5| Step: 4
Training loss: 2.965813559837555
Validation loss: 2.5557072555279587

Epoch: 5| Step: 5
Training loss: 2.1723295326209415
Validation loss: 2.4948929459493625

Epoch: 5| Step: 6
Training loss: 2.017049241886662
Validation loss: 2.547474316341894

Epoch: 5| Step: 7
Training loss: 2.295994284838698
Validation loss: 2.58237797130269

Epoch: 5| Step: 8
Training loss: 3.3300154067590935
Validation loss: 2.58841950615309

Epoch: 5| Step: 9
Training loss: 2.21912445347176
Validation loss: 2.5962761572581066

Epoch: 5| Step: 10
Training loss: 2.5172710838150945
Validation loss: 2.5649812092452886

Epoch: 282| Step: 0
Training loss: 2.7701945512666932
Validation loss: 2.5711289751102058

Epoch: 5| Step: 1
Training loss: 1.917089132382961
Validation loss: 2.548681853683198

Epoch: 5| Step: 2
Training loss: 2.127696178101129
Validation loss: 2.558779412780184

Epoch: 5| Step: 3
Training loss: 2.5158895033632827
Validation loss: 2.584966626184224

Epoch: 5| Step: 4
Training loss: 2.160154042579116
Validation loss: 2.5807088195476156

Epoch: 5| Step: 5
Training loss: 1.8717022187187364
Validation loss: 2.5657123156870725

Epoch: 5| Step: 6
Training loss: 3.1231558889862
Validation loss: 2.5289948004678053

Epoch: 5| Step: 7
Training loss: 2.4038004110825844
Validation loss: 2.569421346335747

Epoch: 5| Step: 8
Training loss: 2.4005084214510726
Validation loss: 2.5812193834786847

Epoch: 5| Step: 9
Training loss: 2.6668834796821663
Validation loss: 2.561670412667233

Epoch: 5| Step: 10
Training loss: 2.9727433501427383
Validation loss: 2.5688005070812934

Epoch: 283| Step: 0
Training loss: 1.964294902978188
Validation loss: 2.5821559226130715

Epoch: 5| Step: 1
Training loss: 2.0961907806857614
Validation loss: 2.556067075767606

Epoch: 5| Step: 2
Training loss: 2.192800802303197
Validation loss: 2.59744545624651

Epoch: 5| Step: 3
Training loss: 2.7815309018357914
Validation loss: 2.545057948950618

Epoch: 5| Step: 4
Training loss: 2.027638908171559
Validation loss: 2.5220803244679866

Epoch: 5| Step: 5
Training loss: 2.4557968459338273
Validation loss: 2.5778892173106507

Epoch: 5| Step: 6
Training loss: 2.622400904438731
Validation loss: 2.5668800031485985

Epoch: 5| Step: 7
Training loss: 2.9578520871438765
Validation loss: 2.505486245983822

Epoch: 5| Step: 8
Training loss: 2.51563457226561
Validation loss: 2.5642143135630016

Epoch: 5| Step: 9
Training loss: 2.676297815956741
Validation loss: 2.5659662009506525

Epoch: 5| Step: 10
Training loss: 2.4009672361630465
Validation loss: 2.5414083861660197

Epoch: 284| Step: 0
Training loss: 3.118087906210621
Validation loss: 2.5738065775753958

Epoch: 5| Step: 1
Training loss: 2.489910747966062
Validation loss: 2.631440476637186

Epoch: 5| Step: 2
Training loss: 2.4886152441538765
Validation loss: 2.5805486707824654

Epoch: 5| Step: 3
Training loss: 2.3029296378063773
Validation loss: 2.5410078241428837

Epoch: 5| Step: 4
Training loss: 2.5827437209925446
Validation loss: 2.568544898804534

Epoch: 5| Step: 5
Training loss: 2.732310447574999
Validation loss: 2.5028591275612477

Epoch: 5| Step: 6
Training loss: 2.4014492943910963
Validation loss: 2.5385595780564114

Epoch: 5| Step: 7
Training loss: 2.233543401299442
Validation loss: 2.5212308571415103

Epoch: 5| Step: 8
Training loss: 1.9508085017502612
Validation loss: 2.564296771784819

Epoch: 5| Step: 9
Training loss: 2.2082613327476657
Validation loss: 2.5744825359929857

Epoch: 5| Step: 10
Training loss: 2.4244576742419475
Validation loss: 2.548684535329136

Epoch: 285| Step: 0
Training loss: 2.180415534392105
Validation loss: 2.5872722487651574

Epoch: 5| Step: 1
Training loss: 2.7190191201494933
Validation loss: 2.4661649755711355

Epoch: 5| Step: 2
Training loss: 2.3169807120595873
Validation loss: 2.5733555952478215

Epoch: 5| Step: 3
Training loss: 2.4386288889772256
Validation loss: 2.590183971996409

Epoch: 5| Step: 4
Training loss: 2.88094742979835
Validation loss: 2.5270108389173305

Epoch: 5| Step: 5
Training loss: 2.6956134130599025
Validation loss: 2.589423449461884

Epoch: 5| Step: 6
Training loss: 3.13735867976131
Validation loss: 2.548008839319637

Epoch: 5| Step: 7
Training loss: 1.9418855071727399
Validation loss: 2.6218145656439473

Epoch: 5| Step: 8
Training loss: 1.7979688549166033
Validation loss: 2.577378372661929

Epoch: 5| Step: 9
Training loss: 2.036126723611999
Validation loss: 2.5310938179409486

Epoch: 5| Step: 10
Training loss: 2.636325835163243
Validation loss: 2.573570569585569

Epoch: 286| Step: 0
Training loss: 2.278955115264212
Validation loss: 2.5921740250519494

Epoch: 5| Step: 1
Training loss: 1.9208745445856132
Validation loss: 2.517893532722347

Epoch: 5| Step: 2
Training loss: 2.707438208525657
Validation loss: 2.5478460938133574

Epoch: 5| Step: 3
Training loss: 2.663583662119488
Validation loss: 2.5250888029906475

Epoch: 5| Step: 4
Training loss: 2.9774187913865524
Validation loss: 2.5743669063948156

Epoch: 5| Step: 5
Training loss: 2.401128892838111
Validation loss: 2.529275429617667

Epoch: 5| Step: 6
Training loss: 2.1545126729943505
Validation loss: 2.6042754805606574

Epoch: 5| Step: 7
Training loss: 2.5204616514322
Validation loss: 2.6026498392772925

Epoch: 5| Step: 8
Training loss: 2.5153373411631796
Validation loss: 2.5634561511124145

Epoch: 5| Step: 9
Training loss: 2.8392252714264745
Validation loss: 2.5803963111160715

Epoch: 5| Step: 10
Training loss: 2.275392196720219
Validation loss: 2.558371596033366

Epoch: 287| Step: 0
Training loss: 2.7393667814778575
Validation loss: 2.5252794295307504

Epoch: 5| Step: 1
Training loss: 2.774822480305847
Validation loss: 2.544260020949995

Epoch: 5| Step: 2
Training loss: 1.8951091710754264
Validation loss: 2.5835901103651198

Epoch: 5| Step: 3
Training loss: 3.278106200652497
Validation loss: 2.5834014902111475

Epoch: 5| Step: 4
Training loss: 2.6876062771387343
Validation loss: 2.519052406412316

Epoch: 5| Step: 5
Training loss: 2.0948308176270416
Validation loss: 2.5718398221891015

Epoch: 5| Step: 6
Training loss: 2.6996593860955564
Validation loss: 2.526391775371646

Epoch: 5| Step: 7
Training loss: 2.2549401197920216
Validation loss: 2.5628500978631754

Epoch: 5| Step: 8
Training loss: 1.7022037639369683
Validation loss: 2.574584608286712

Epoch: 5| Step: 9
Training loss: 2.5338073809787884
Validation loss: 2.5397189020239397

Epoch: 5| Step: 10
Training loss: 1.68015513453149
Validation loss: 2.528578914826759

Epoch: 288| Step: 0
Training loss: 2.363422282400826
Validation loss: 2.584775588241236

Epoch: 5| Step: 1
Training loss: 2.2321563589505153
Validation loss: 2.56859954069188

Epoch: 5| Step: 2
Training loss: 2.6135305790357477
Validation loss: 2.526116160461561

Epoch: 5| Step: 3
Training loss: 2.1923511664266684
Validation loss: 2.552922428119869

Epoch: 5| Step: 4
Training loss: 2.3044812126296
Validation loss: 2.4934620511320755

Epoch: 5| Step: 5
Training loss: 2.5253020681858036
Validation loss: 2.6433812694389935

Epoch: 5| Step: 6
Training loss: 2.377460409931879
Validation loss: 2.5725499317273415

Epoch: 5| Step: 7
Training loss: 2.454510922943634
Validation loss: 2.535096721897365

Epoch: 5| Step: 8
Training loss: 2.976772351013887
Validation loss: 2.5855641261711684

Epoch: 5| Step: 9
Training loss: 2.5537881463889995
Validation loss: 2.51590432641907

Epoch: 5| Step: 10
Training loss: 2.6021847825524627
Validation loss: 2.596089727754432

Epoch: 289| Step: 0
Training loss: 2.348776957634826
Validation loss: 2.579036184948452

Epoch: 5| Step: 1
Training loss: 2.8758112550645354
Validation loss: 2.560623312103555

Epoch: 5| Step: 2
Training loss: 2.319648108103569
Validation loss: 2.5932217013113235

Epoch: 5| Step: 3
Training loss: 2.099072196907384
Validation loss: 2.5438589294013014

Epoch: 5| Step: 4
Training loss: 2.813178256161515
Validation loss: 2.574117328480092

Epoch: 5| Step: 5
Training loss: 1.8806786692990305
Validation loss: 2.577910237395931

Epoch: 5| Step: 6
Training loss: 3.2921803391518587
Validation loss: 2.5844277115743015

Epoch: 5| Step: 7
Training loss: 1.9788596333383048
Validation loss: 2.5543760007102203

Epoch: 5| Step: 8
Training loss: 2.289762943108374
Validation loss: 2.562529907132074

Epoch: 5| Step: 9
Training loss: 1.988973380921894
Validation loss: 2.609031558853424

Epoch: 5| Step: 10
Training loss: 2.539398265058867
Validation loss: 2.5818361491577617

Epoch: 290| Step: 0
Training loss: 2.6554521147702683
Validation loss: 2.5839889725123735

Epoch: 5| Step: 1
Training loss: 2.727614410266552
Validation loss: 2.5775465966833844

Epoch: 5| Step: 2
Training loss: 2.543344027578819
Validation loss: 2.559119275706656

Epoch: 5| Step: 3
Training loss: 2.3111147468896944
Validation loss: 2.553587838748642

Epoch: 5| Step: 4
Training loss: 2.442985817142373
Validation loss: 2.5725680805912323

Epoch: 5| Step: 5
Training loss: 2.9142572169152765
Validation loss: 2.5834995554368154

Epoch: 5| Step: 6
Training loss: 2.8424448225022285
Validation loss: 2.6000717066428405

Epoch: 5| Step: 7
Training loss: 2.259851083153442
Validation loss: 2.5594046721597192

Epoch: 5| Step: 8
Training loss: 2.0641118311563877
Validation loss: 2.545795201958775

Epoch: 5| Step: 9
Training loss: 2.1853830175533635
Validation loss: 2.5859972496405432

Epoch: 5| Step: 10
Training loss: 1.8656336491829972
Validation loss: 2.5861153965997596

Epoch: 291| Step: 0
Training loss: 2.621011337599235
Validation loss: 2.5677382570124845

Epoch: 5| Step: 1
Training loss: 2.384682443778629
Validation loss: 2.550236625276974

Epoch: 5| Step: 2
Training loss: 2.5044243762996725
Validation loss: 2.5328821389117695

Epoch: 5| Step: 3
Training loss: 2.31692596832268
Validation loss: 2.5393752119598556

Epoch: 5| Step: 4
Training loss: 2.3737000371044994
Validation loss: 2.570915379121397

Epoch: 5| Step: 5
Training loss: 2.3152113819219524
Validation loss: 2.4975729143468723

Epoch: 5| Step: 6
Training loss: 2.0522244270990755
Validation loss: 2.6003151466371373

Epoch: 5| Step: 7
Training loss: 2.3177727050985824
Validation loss: 2.598988329255836

Epoch: 5| Step: 8
Training loss: 2.986163816553679
Validation loss: 2.5843611905913595

Epoch: 5| Step: 9
Training loss: 2.7207590331544798
Validation loss: 2.570876571949282

Epoch: 5| Step: 10
Training loss: 2.4175167123400323
Validation loss: 2.6136985958251584

Epoch: 292| Step: 0
Training loss: 2.581671015877587
Validation loss: 2.5543459966040434

Epoch: 5| Step: 1
Training loss: 1.7251161757338092
Validation loss: 2.5351692140091866

Epoch: 5| Step: 2
Training loss: 2.5488256929466364
Validation loss: 2.5876668856321055

Epoch: 5| Step: 3
Training loss: 1.9950306071177937
Validation loss: 2.5337507498329286

Epoch: 5| Step: 4
Training loss: 2.2332772712882925
Validation loss: 2.5630706083773895

Epoch: 5| Step: 5
Training loss: 2.9220223619152397
Validation loss: 2.6283493140772083

Epoch: 5| Step: 6
Training loss: 2.682323527224057
Validation loss: 2.596173248239551

Epoch: 5| Step: 7
Training loss: 2.357849840762136
Validation loss: 2.594400268279539

Epoch: 5| Step: 8
Training loss: 2.447106431561598
Validation loss: 2.5688008463983234

Epoch: 5| Step: 9
Training loss: 2.1425988223276753
Validation loss: 2.5945861453106462

Epoch: 5| Step: 10
Training loss: 3.045012075716575
Validation loss: 2.5608835642020336

Epoch: 293| Step: 0
Training loss: 2.549960087482529
Validation loss: 2.5749239830602644

Epoch: 5| Step: 1
Training loss: 2.7556748358826635
Validation loss: 2.518604413533986

Epoch: 5| Step: 2
Training loss: 1.882691818738394
Validation loss: 2.610825619100669

Epoch: 5| Step: 3
Training loss: 2.369727757748452
Validation loss: 2.517678993379946

Epoch: 5| Step: 4
Training loss: 2.1631465584761624
Validation loss: 2.5508795059753453

Epoch: 5| Step: 5
Training loss: 2.545856857399233
Validation loss: 2.4975197240244067

Epoch: 5| Step: 6
Training loss: 2.8665248510486854
Validation loss: 2.5354536339586295

Epoch: 5| Step: 7
Training loss: 2.161589493659497
Validation loss: 2.5753361657856573

Epoch: 5| Step: 8
Training loss: 2.2509675594654555
Validation loss: 2.5192357862960884

Epoch: 5| Step: 9
Training loss: 2.1354072632621337
Validation loss: 2.5680681465051

Epoch: 5| Step: 10
Training loss: 2.940457093393954
Validation loss: 2.5729537764569077

Epoch: 294| Step: 0
Training loss: 3.139358340991333
Validation loss: 2.579477821726476

Epoch: 5| Step: 1
Training loss: 2.8889450552770413
Validation loss: 2.5542698393600194

Epoch: 5| Step: 2
Training loss: 2.041299112153116
Validation loss: 2.5642163401087106

Epoch: 5| Step: 3
Training loss: 2.035795905692663
Validation loss: 2.549747029672788

Epoch: 5| Step: 4
Training loss: 1.8948744001006985
Validation loss: 2.5743125213648868

Epoch: 5| Step: 5
Training loss: 2.3704213629752235
Validation loss: 2.5542393979075864

Epoch: 5| Step: 6
Training loss: 2.3213731801058395
Validation loss: 2.589695906850115

Epoch: 5| Step: 7
Training loss: 1.9096444347221893
Validation loss: 2.500420157699135

Epoch: 5| Step: 8
Training loss: 2.4892813740180526
Validation loss: 2.55416761365945

Epoch: 5| Step: 9
Training loss: 2.4719717515609148
Validation loss: 2.6155348385091486

Epoch: 5| Step: 10
Training loss: 2.9601639111989306
Validation loss: 2.5879003212627745

Epoch: 295| Step: 0
Training loss: 2.945444604961777
Validation loss: 2.5832261090713677

Epoch: 5| Step: 1
Training loss: 2.3978524255529625
Validation loss: 2.584226392052933

Epoch: 5| Step: 2
Training loss: 2.163561270607695
Validation loss: 2.5844986335282703

Epoch: 5| Step: 3
Training loss: 2.568248256121674
Validation loss: 2.5946881737034535

Epoch: 5| Step: 4
Training loss: 2.635823325243593
Validation loss: 2.5758460459673453

Epoch: 5| Step: 5
Training loss: 1.9693382837473936
Validation loss: 2.5311007428470593

Epoch: 5| Step: 6
Training loss: 2.126909968391083
Validation loss: 2.587067030748946

Epoch: 5| Step: 7
Training loss: 2.5513208820340547
Validation loss: 2.558263678960477

Epoch: 5| Step: 8
Training loss: 2.5795943263583756
Validation loss: 2.576908586055223

Epoch: 5| Step: 9
Training loss: 2.1902438802225417
Validation loss: 2.542330914473934

Epoch: 5| Step: 10
Training loss: 2.3293954339959417
Validation loss: 2.569770158574882

Epoch: 296| Step: 0
Training loss: 2.0035906983826584
Validation loss: 2.587505795297607

Epoch: 5| Step: 1
Training loss: 2.459880105175034
Validation loss: 2.5583185634872776

Epoch: 5| Step: 2
Training loss: 2.3904075773014353
Validation loss: 2.5620513621325713

Epoch: 5| Step: 3
Training loss: 2.3473709618606664
Validation loss: 2.528963771951028

Epoch: 5| Step: 4
Training loss: 2.33259900209042
Validation loss: 2.5915904399465197

Epoch: 5| Step: 5
Training loss: 2.85704487564472
Validation loss: 2.5398851287222963

Epoch: 5| Step: 6
Training loss: 1.7628408440615673
Validation loss: 2.530778787096223

Epoch: 5| Step: 7
Training loss: 2.462902047889351
Validation loss: 2.5594886615615504

Epoch: 5| Step: 8
Training loss: 3.0783661878560915
Validation loss: 2.544663626356084

Epoch: 5| Step: 9
Training loss: 2.513678988644509
Validation loss: 2.5036579381574686

Epoch: 5| Step: 10
Training loss: 2.1678512953825044
Validation loss: 2.5701058454883525

Epoch: 297| Step: 0
Training loss: 2.270856408051546
Validation loss: 2.6331710155062416

Epoch: 5| Step: 1
Training loss: 1.9916159614056697
Validation loss: 2.569972544193426

Epoch: 5| Step: 2
Training loss: 2.5950169054483996
Validation loss: 2.5560869353602995

Epoch: 5| Step: 3
Training loss: 2.882916373679083
Validation loss: 2.505511430145157

Epoch: 5| Step: 4
Training loss: 2.017021109694171
Validation loss: 2.5560450711667264

Epoch: 5| Step: 5
Training loss: 2.5543301300296894
Validation loss: 2.543138513263208

Epoch: 5| Step: 6
Training loss: 2.7679569736179594
Validation loss: 2.5335863391714373

Epoch: 5| Step: 7
Training loss: 2.980548742578246
Validation loss: 2.5815132853622376

Epoch: 5| Step: 8
Training loss: 2.1155859037812847
Validation loss: 2.581535266027831

Epoch: 5| Step: 9
Training loss: 1.8938013302736225
Validation loss: 2.604094828609489

Epoch: 5| Step: 10
Training loss: 2.4935551540959655
Validation loss: 2.570807039263979

Epoch: 298| Step: 0
Training loss: 2.29769311983631
Validation loss: 2.5315565650037417

Epoch: 5| Step: 1
Training loss: 2.1619501374005936
Validation loss: 2.5298995468419117

Epoch: 5| Step: 2
Training loss: 2.5226941977417368
Validation loss: 2.5748332597553265

Epoch: 5| Step: 3
Training loss: 2.304130874916856
Validation loss: 2.571331142611829

Epoch: 5| Step: 4
Training loss: 1.804335192355872
Validation loss: 2.572800189802688

Epoch: 5| Step: 5
Training loss: 2.3963525513547714
Validation loss: 2.5238822926742137

Epoch: 5| Step: 6
Training loss: 2.508834488020533
Validation loss: 2.569406900867895

Epoch: 5| Step: 7
Training loss: 2.266855997237834
Validation loss: 2.5773660974117134

Epoch: 5| Step: 8
Training loss: 2.9093250700602793
Validation loss: 2.5758655370966124

Epoch: 5| Step: 9
Training loss: 2.762801976334354
Validation loss: 2.5833496934436884

Epoch: 5| Step: 10
Training loss: 2.3588616020999047
Validation loss: 2.563576782955149

Epoch: 299| Step: 0
Training loss: 2.4568573567240453
Validation loss: 2.600944256627391

Epoch: 5| Step: 1
Training loss: 1.9788105962250206
Validation loss: 2.575812410882255

Epoch: 5| Step: 2
Training loss: 2.457128671434078
Validation loss: 2.523743917948749

Epoch: 5| Step: 3
Training loss: 1.8703555759450528
Validation loss: 2.55976514042751

Epoch: 5| Step: 4
Training loss: 2.051720627489074
Validation loss: 2.572934473507594

Epoch: 5| Step: 5
Training loss: 2.22059855219098
Validation loss: 2.562830713812525

Epoch: 5| Step: 6
Training loss: 2.985118992924152
Validation loss: 2.576366038563351

Epoch: 5| Step: 7
Training loss: 2.43904358332921
Validation loss: 2.5902273965212435

Epoch: 5| Step: 8
Training loss: 2.0133551303155195
Validation loss: 2.5941043052834485

Epoch: 5| Step: 9
Training loss: 2.7931203520918197
Validation loss: 2.580491569746264

Epoch: 5| Step: 10
Training loss: 2.769542957706213
Validation loss: 2.542053429925008

Epoch: 300| Step: 0
Training loss: 2.2348531998250056
Validation loss: 2.603867146320554

Epoch: 5| Step: 1
Training loss: 2.939324157521712
Validation loss: 2.5752882160875328

Epoch: 5| Step: 2
Training loss: 1.7406493097932845
Validation loss: 2.578083072543918

Epoch: 5| Step: 3
Training loss: 3.1739722022586223
Validation loss: 2.5824937683410845

Epoch: 5| Step: 4
Training loss: 2.3167721232647103
Validation loss: 2.5477824911696922

Epoch: 5| Step: 5
Training loss: 2.3408442477330214
Validation loss: 2.5618892249919982

Epoch: 5| Step: 6
Training loss: 2.3834711884153035
Validation loss: 2.5977449298198065

Epoch: 5| Step: 7
Training loss: 2.555845412341981
Validation loss: 2.558616293280487

Epoch: 5| Step: 8
Training loss: 2.1051886943773774
Validation loss: 2.5945237516998794

Epoch: 5| Step: 9
Training loss: 1.8423185449117923
Validation loss: 2.5394119686061094

Epoch: 5| Step: 10
Training loss: 2.203551555490054
Validation loss: 2.4967311879884386

Testing loss: 2.6097167623112125
