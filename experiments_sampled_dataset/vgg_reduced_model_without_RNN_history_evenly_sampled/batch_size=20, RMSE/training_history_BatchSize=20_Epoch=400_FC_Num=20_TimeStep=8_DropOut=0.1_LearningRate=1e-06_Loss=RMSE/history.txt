Epoch: 1| Step: 0
Training loss: 5.323662374061493
Validation loss: 5.267803026139025

Epoch: 5| Step: 1
Training loss: 5.872807519752584
Validation loss: 5.263079878499244

Epoch: 5| Step: 2
Training loss: 5.69608606179189
Validation loss: 5.258706418539153

Epoch: 5| Step: 3
Training loss: 4.997952232642424
Validation loss: 5.254968675916743

Epoch: 5| Step: 4
Training loss: 5.647536167604799
Validation loss: 5.249195871331572

Epoch: 5| Step: 5
Training loss: 5.100673533824453
Validation loss: 5.242736248762574

Epoch: 5| Step: 6
Training loss: 4.35355636967811
Validation loss: 5.242043115727199

Epoch: 5| Step: 7
Training loss: 4.86416772323596
Validation loss: 5.237758621689949

Epoch: 5| Step: 8
Training loss: 5.44173398095519
Validation loss: 5.233515747247892

Epoch: 5| Step: 9
Training loss: 5.522862859075558
Validation loss: 5.231068877208298

Epoch: 5| Step: 10
Training loss: 5.397437172718851
Validation loss: 5.224982596771387

Epoch: 2| Step: 0
Training loss: 4.697357798601884
Validation loss: 5.221354689736277

Epoch: 5| Step: 1
Training loss: 5.191373550851684
Validation loss: 5.21897772442657

Epoch: 5| Step: 2
Training loss: 5.1791448754823755
Validation loss: 5.214263848622789

Epoch: 5| Step: 3
Training loss: 4.651980702210119
Validation loss: 5.211891816649929

Epoch: 5| Step: 4
Training loss: 5.25551896426416
Validation loss: 5.20837501295907

Epoch: 5| Step: 5
Training loss: 4.3208919088328726
Validation loss: 5.206015657984688

Epoch: 5| Step: 6
Training loss: 6.5305800390909114
Validation loss: 5.197797217519266

Epoch: 5| Step: 7
Training loss: 5.9216012212026925
Validation loss: 5.194812227450342

Epoch: 5| Step: 8
Training loss: 4.729207356595785
Validation loss: 5.192572977432618

Epoch: 5| Step: 9
Training loss: 5.6878896726486055
Validation loss: 5.187231624978645

Epoch: 5| Step: 10
Training loss: 5.391247876434651
Validation loss: 5.180300965039776

Epoch: 3| Step: 0
Training loss: 4.314541540798442
Validation loss: 5.177246615416389

Epoch: 5| Step: 1
Training loss: 4.8505508424654
Validation loss: 5.176546169416559

Epoch: 5| Step: 2
Training loss: 5.484136592541201
Validation loss: 5.169233309164618

Epoch: 5| Step: 3
Training loss: 4.823853810209778
Validation loss: 5.165138198494621

Epoch: 5| Step: 4
Training loss: 5.64604927954415
Validation loss: 5.1581741675561705

Epoch: 5| Step: 5
Training loss: 6.31547581998092
Validation loss: 5.156020551233195

Epoch: 5| Step: 6
Training loss: 4.373723743116787
Validation loss: 5.157764523380113

Epoch: 5| Step: 7
Training loss: 5.451132336496703
Validation loss: 5.148064210680798

Epoch: 5| Step: 8
Training loss: 5.340534871492091
Validation loss: 5.143497017214696

Epoch: 5| Step: 9
Training loss: 5.425742405312264
Validation loss: 5.13978855262335

Epoch: 5| Step: 10
Training loss: 5.062923649145343
Validation loss: 5.136450203265153

Epoch: 4| Step: 0
Training loss: 5.134873346625861
Validation loss: 5.1297278257965555

Epoch: 5| Step: 1
Training loss: 6.249587999115734
Validation loss: 5.122649873764406

Epoch: 5| Step: 2
Training loss: 5.634409176875685
Validation loss: 5.11716348867412

Epoch: 5| Step: 3
Training loss: 5.458041622530144
Validation loss: 5.110092627988977

Epoch: 5| Step: 4
Training loss: 4.596967128553984
Validation loss: 5.109805704080161

Epoch: 5| Step: 5
Training loss: 5.732994142006024
Validation loss: 5.100465176331471

Epoch: 5| Step: 6
Training loss: 4.558303156909168
Validation loss: 5.101270189418982

Epoch: 5| Step: 7
Training loss: 5.021015253636071
Validation loss: 5.0935414076094245

Epoch: 5| Step: 8
Training loss: 5.019847387904493
Validation loss: 5.088771678044429

Epoch: 5| Step: 9
Training loss: 4.811456740613686
Validation loss: 5.08149233759091

Epoch: 5| Step: 10
Training loss: 4.181579047742555
Validation loss: 5.074267421472786

Epoch: 5| Step: 0
Training loss: 4.500691254823001
Validation loss: 5.065522209782978

Epoch: 5| Step: 1
Training loss: 6.077797692123106
Validation loss: 5.0642962219570675

Epoch: 5| Step: 2
Training loss: 5.785492201483616
Validation loss: 5.057219807926944

Epoch: 5| Step: 3
Training loss: 5.2204055444440245
Validation loss: 5.052764774902081

Epoch: 5| Step: 4
Training loss: 4.88519531702904
Validation loss: 5.0458571814976265

Epoch: 5| Step: 5
Training loss: 3.869805207192446
Validation loss: 5.0443168630116695

Epoch: 5| Step: 6
Training loss: 5.780061506848281
Validation loss: 5.0397800192588145

Epoch: 5| Step: 7
Training loss: 5.890345883017569
Validation loss: 5.030399175921112

Epoch: 5| Step: 8
Training loss: 5.580348493296868
Validation loss: 5.024868657764838

Epoch: 5| Step: 9
Training loss: 3.8090728614910936
Validation loss: 5.016046988228414

Epoch: 5| Step: 10
Training loss: 3.9125394922767858
Validation loss: 5.009399095152267

Epoch: 6| Step: 0
Training loss: 5.058630512354353
Validation loss: 5.000233581173215

Epoch: 5| Step: 1
Training loss: 4.844215813665328
Validation loss: 5.001754621047511

Epoch: 5| Step: 2
Training loss: 4.5785055685864515
Validation loss: 4.990762535991085

Epoch: 5| Step: 3
Training loss: 4.859344580453923
Validation loss: 4.9866496169982355

Epoch: 5| Step: 4
Training loss: 3.8925776350037324
Validation loss: 4.9804677905267365

Epoch: 5| Step: 5
Training loss: 4.569617376691439
Validation loss: 4.974725188190046

Epoch: 5| Step: 6
Training loss: 5.228960841207537
Validation loss: 4.9691108855813875

Epoch: 5| Step: 7
Training loss: 5.9099154930721225
Validation loss: 4.960954551160398

Epoch: 5| Step: 8
Training loss: 5.65433431820504
Validation loss: 4.955716838845801

Epoch: 5| Step: 9
Training loss: 5.627616612816186
Validation loss: 4.947209759285266

Epoch: 5| Step: 10
Training loss: 4.880954333935213
Validation loss: 4.940720433815149

Epoch: 7| Step: 0
Training loss: 5.057759644070436
Validation loss: 4.932318472691674

Epoch: 5| Step: 1
Training loss: 5.428627053312832
Validation loss: 4.924677679369779

Epoch: 5| Step: 2
Training loss: 4.1104623494588
Validation loss: 4.915967606197655

Epoch: 5| Step: 3
Training loss: 4.131346473202244
Validation loss: 4.911806641525545

Epoch: 5| Step: 4
Training loss: 5.0716204961922635
Validation loss: 4.905493512893565

Epoch: 5| Step: 5
Training loss: 4.342445452077949
Validation loss: 4.891901663088359

Epoch: 5| Step: 6
Training loss: 3.9265851312752478
Validation loss: 4.884702534489229

Epoch: 5| Step: 7
Training loss: 6.148226548954229
Validation loss: 4.881173065668737

Epoch: 5| Step: 8
Training loss: 5.8401403039251765
Validation loss: 4.871386094841678

Epoch: 5| Step: 9
Training loss: 5.4659484662872915
Validation loss: 4.8676412241835205

Epoch: 5| Step: 10
Training loss: 4.486168054324928
Validation loss: 4.858060571114149

Epoch: 8| Step: 0
Training loss: 4.965369652147834
Validation loss: 4.848297622211807

Epoch: 5| Step: 1
Training loss: 5.494878985779339
Validation loss: 4.844155087767991

Epoch: 5| Step: 2
Training loss: 4.684162426706669
Validation loss: 4.831077296686688

Epoch: 5| Step: 3
Training loss: 5.280311275323325
Validation loss: 4.822702722777088

Epoch: 5| Step: 4
Training loss: 5.38845949767247
Validation loss: 4.819604146138745

Epoch: 5| Step: 5
Training loss: 4.41992942684673
Validation loss: 4.8077357979851225

Epoch: 5| Step: 6
Training loss: 4.436490656005072
Validation loss: 4.803866366919274

Epoch: 5| Step: 7
Training loss: 4.6879752363260465
Validation loss: 4.79143095502306

Epoch: 5| Step: 8
Training loss: 4.523005278762008
Validation loss: 4.783462384668941

Epoch: 5| Step: 9
Training loss: 4.777235352728233
Validation loss: 4.773670004308252

Epoch: 5| Step: 10
Training loss: 4.973783043240876
Validation loss: 4.7641087371723385

Epoch: 9| Step: 0
Training loss: 5.088996775749986
Validation loss: 4.759453677599967

Epoch: 5| Step: 1
Training loss: 4.299126940077417
Validation loss: 4.7522804580422635

Epoch: 5| Step: 2
Training loss: 5.300374453290331
Validation loss: 4.743065695240144

Epoch: 5| Step: 3
Training loss: 4.484756719312754
Validation loss: 4.734641776265824

Epoch: 5| Step: 4
Training loss: 4.311426664931802
Validation loss: 4.722926736612826

Epoch: 5| Step: 5
Training loss: 5.479046703035835
Validation loss: 4.713618555180072

Epoch: 5| Step: 6
Training loss: 4.743141643933791
Validation loss: 4.702463685893945

Epoch: 5| Step: 7
Training loss: 4.8275912585490435
Validation loss: 4.69682831605419

Epoch: 5| Step: 8
Training loss: 4.0401338377585905
Validation loss: 4.688606351503396

Epoch: 5| Step: 9
Training loss: 4.714441214304699
Validation loss: 4.675029551559771

Epoch: 5| Step: 10
Training loss: 5.302522152751455
Validation loss: 4.6704607268944045

Epoch: 10| Step: 0
Training loss: 5.1108997181469995
Validation loss: 4.660428335330235

Epoch: 5| Step: 1
Training loss: 4.85723829977044
Validation loss: 4.6476549752334195

Epoch: 5| Step: 2
Training loss: 4.8195303555959415
Validation loss: 4.641862813768176

Epoch: 5| Step: 3
Training loss: 4.787467952451688
Validation loss: 4.63042400402316

Epoch: 5| Step: 4
Training loss: 4.720718680479647
Validation loss: 4.616306201181773

Epoch: 5| Step: 5
Training loss: 4.350242537829294
Validation loss: 4.611062818622662

Epoch: 5| Step: 6
Training loss: 4.049621592610223
Validation loss: 4.598634329957241

Epoch: 5| Step: 7
Training loss: 3.7171732661330306
Validation loss: 4.58184295466865

Epoch: 5| Step: 8
Training loss: 3.6115004321471327
Validation loss: 4.581648382455551

Epoch: 5| Step: 9
Training loss: 5.322646022816481
Validation loss: 4.569952231974943

Epoch: 5| Step: 10
Training loss: 5.972774726485975
Validation loss: 4.557854159705016

Epoch: 11| Step: 0
Training loss: 4.971429833911554
Validation loss: 4.548084498058763

Epoch: 5| Step: 1
Training loss: 4.310549529904031
Validation loss: 4.533002992522019

Epoch: 5| Step: 2
Training loss: 4.0416876933281705
Validation loss: 4.528019339468817

Epoch: 5| Step: 3
Training loss: 4.995697840915182
Validation loss: 4.514457946111549

Epoch: 5| Step: 4
Training loss: 4.1644657934540215
Validation loss: 4.510214297216004

Epoch: 5| Step: 5
Training loss: 3.717688785728539
Validation loss: 4.490267475517534

Epoch: 5| Step: 6
Training loss: 4.557390670427584
Validation loss: 4.48684929743625

Epoch: 5| Step: 7
Training loss: 5.482593562227561
Validation loss: 4.468295696631379

Epoch: 5| Step: 8
Training loss: 5.188631233137149
Validation loss: 4.4601794033791595

Epoch: 5| Step: 9
Training loss: 4.155029576606008
Validation loss: 4.4476366978274156

Epoch: 5| Step: 10
Training loss: 4.518357027939867
Validation loss: 4.43269175922632

Epoch: 12| Step: 0
Training loss: 4.358315178351338
Validation loss: 4.422068358412668

Epoch: 5| Step: 1
Training loss: 4.320961874089377
Validation loss: 4.407691086308074

Epoch: 5| Step: 2
Training loss: 4.233112442581473
Validation loss: 4.400613202857207

Epoch: 5| Step: 3
Training loss: 4.628320687514491
Validation loss: 4.38769502854013

Epoch: 5| Step: 4
Training loss: 3.6194660433670203
Validation loss: 4.374789482243555

Epoch: 5| Step: 5
Training loss: 5.501454074422815
Validation loss: 4.353441928879106

Epoch: 5| Step: 6
Training loss: 4.826107060218355
Validation loss: 4.347693480996965

Epoch: 5| Step: 7
Training loss: 3.8696476056823426
Validation loss: 4.328933412278513

Epoch: 5| Step: 8
Training loss: 4.3016876457458535
Validation loss: 4.313801587300955

Epoch: 5| Step: 9
Training loss: 4.439569769626319
Validation loss: 4.303624416287002

Epoch: 5| Step: 10
Training loss: 4.647108077031807
Validation loss: 4.2922110175992385

Epoch: 13| Step: 0
Training loss: 4.5446016586539075
Validation loss: 4.284108576990672

Epoch: 5| Step: 1
Training loss: 3.900792696672633
Validation loss: 4.262107495349456

Epoch: 5| Step: 2
Training loss: 4.947519686651554
Validation loss: 4.24694777834441

Epoch: 5| Step: 3
Training loss: 4.5765609413006265
Validation loss: 4.236524072497487

Epoch: 5| Step: 4
Training loss: 4.450309639777054
Validation loss: 4.218483464105855

Epoch: 5| Step: 5
Training loss: 4.020206198267312
Validation loss: 4.207516307748391

Epoch: 5| Step: 6
Training loss: 3.544885018317353
Validation loss: 4.196825983448462

Epoch: 5| Step: 7
Training loss: 3.9625890775950987
Validation loss: 4.174606382204225

Epoch: 5| Step: 8
Training loss: 4.394465711316844
Validation loss: 4.162404581981822

Epoch: 5| Step: 9
Training loss: 3.7307935323687573
Validation loss: 4.14713443707089

Epoch: 5| Step: 10
Training loss: 5.168464942461175
Validation loss: 4.138670326410747

Epoch: 14| Step: 0
Training loss: 4.132322112845455
Validation loss: 4.116087868531239

Epoch: 5| Step: 1
Training loss: 3.368200021553481
Validation loss: 4.104415266795679

Epoch: 5| Step: 2
Training loss: 3.870995575153618
Validation loss: 4.081819442432808

Epoch: 5| Step: 3
Training loss: 3.3925713784475233
Validation loss: 4.074625279646623

Epoch: 5| Step: 4
Training loss: 4.74949884280568
Validation loss: 4.054104935138207

Epoch: 5| Step: 5
Training loss: 4.339381813990086
Validation loss: 4.043415839583138

Epoch: 5| Step: 6
Training loss: 4.653982954688306
Validation loss: 4.027133422972598

Epoch: 5| Step: 7
Training loss: 4.526331474879342
Validation loss: 4.010016564284945

Epoch: 5| Step: 8
Training loss: 5.26517926149145
Validation loss: 3.9888353919265294

Epoch: 5| Step: 9
Training loss: 3.5592658102353294
Validation loss: 3.977478825620616

Epoch: 5| Step: 10
Training loss: 2.8618408576976457
Validation loss: 3.9586119449577746

Epoch: 15| Step: 0
Training loss: 3.593297117141596
Validation loss: 3.9333255109888223

Epoch: 5| Step: 1
Training loss: 4.714978864830762
Validation loss: 3.9159362367578883

Epoch: 5| Step: 2
Training loss: 4.467713989529358
Validation loss: 3.9037414450194765

Epoch: 5| Step: 3
Training loss: 4.262670590743031
Validation loss: 3.8909938159886455

Epoch: 5| Step: 4
Training loss: 3.401153391258492
Validation loss: 3.8703877816570738

Epoch: 5| Step: 5
Training loss: 4.4818786690872106
Validation loss: 3.853565493555704

Epoch: 5| Step: 6
Training loss: 3.60944264005885
Validation loss: 3.8414221637066883

Epoch: 5| Step: 7
Training loss: 3.7274148474112923
Validation loss: 3.813411512903698

Epoch: 5| Step: 8
Training loss: 4.184122573953491
Validation loss: 3.7930147563986774

Epoch: 5| Step: 9
Training loss: 3.0227166630004
Validation loss: 3.76514665120697

Epoch: 5| Step: 10
Training loss: 3.8992220714068075
Validation loss: 3.760609876977456

Epoch: 16| Step: 0
Training loss: 4.053284742373621
Validation loss: 3.7481849201803086

Epoch: 5| Step: 1
Training loss: 3.9746192125953193
Validation loss: 3.7220363626150568

Epoch: 5| Step: 2
Training loss: 2.8156067537484972
Validation loss: 3.702752728033322

Epoch: 5| Step: 3
Training loss: 4.252366697272963
Validation loss: 3.673480067896693

Epoch: 5| Step: 4
Training loss: 4.3198857846879495
Validation loss: 3.662600480903092

Epoch: 5| Step: 5
Training loss: 2.983779767978258
Validation loss: 3.646764845206881

Epoch: 5| Step: 6
Training loss: 3.205283577405355
Validation loss: 3.6240292070643365

Epoch: 5| Step: 7
Training loss: 4.051697438880459
Validation loss: 3.61159548328301

Epoch: 5| Step: 8
Training loss: 4.171249056945457
Validation loss: 3.584612208695046

Epoch: 5| Step: 9
Training loss: 3.8790318832719626
Validation loss: 3.5554997365959813

Epoch: 5| Step: 10
Training loss: 3.451341677743002
Validation loss: 3.5531305497901666

Epoch: 17| Step: 0
Training loss: 2.9946193125788976
Validation loss: 3.5297935474085453

Epoch: 5| Step: 1
Training loss: 3.6109384560676605
Validation loss: 3.505116792080883

Epoch: 5| Step: 2
Training loss: 3.8942031033394486
Validation loss: 3.48781034744389

Epoch: 5| Step: 3
Training loss: 3.5436011173789517
Validation loss: 3.4639907769025435

Epoch: 5| Step: 4
Training loss: 4.05303274504081
Validation loss: 3.4523810589071653

Epoch: 5| Step: 5
Training loss: 2.922546635917266
Validation loss: 3.4207733938834286

Epoch: 5| Step: 6
Training loss: 3.411558162403066
Validation loss: 3.399960035503022

Epoch: 5| Step: 7
Training loss: 3.640213447852042
Validation loss: 3.4008956179568837

Epoch: 5| Step: 8
Training loss: 4.546996649199561
Validation loss: 3.3767846499950465

Epoch: 5| Step: 9
Training loss: 3.102170332147047
Validation loss: 3.355930443727241

Epoch: 5| Step: 10
Training loss: 3.372843724656479
Validation loss: 3.31697970686854

Epoch: 18| Step: 0
Training loss: 3.3103362880108844
Validation loss: 3.299539111429624

Epoch: 5| Step: 1
Training loss: 3.597279548597361
Validation loss: 3.284564594352407

Epoch: 5| Step: 2
Training loss: 4.018508528934478
Validation loss: 3.263476747388242

Epoch: 5| Step: 3
Training loss: 3.0696304767403046
Validation loss: 3.234792592727223

Epoch: 5| Step: 4
Training loss: 3.263371324197902
Validation loss: 3.2245038450172614

Epoch: 5| Step: 5
Training loss: 4.2144009248812155
Validation loss: 3.212230576397992

Epoch: 5| Step: 6
Training loss: 2.707730289714686
Validation loss: 3.17413475081333

Epoch: 5| Step: 7
Training loss: 3.474331600757401
Validation loss: 3.1661916051538093

Epoch: 5| Step: 8
Training loss: 3.0108631863254796
Validation loss: 3.155166898242261

Epoch: 5| Step: 9
Training loss: 3.537892533485325
Validation loss: 3.1245932365582942

Epoch: 5| Step: 10
Training loss: 2.713592548344835
Validation loss: 3.0963608510128178

Epoch: 19| Step: 0
Training loss: 3.4383591011870505
Validation loss: 3.0950784541767153

Epoch: 5| Step: 1
Training loss: 3.217023812530486
Validation loss: 3.0850574896518856

Epoch: 5| Step: 2
Training loss: 3.1440702301800907
Validation loss: 3.055486742315617

Epoch: 5| Step: 3
Training loss: 3.2698889824923274
Validation loss: 3.0251886692871803

Epoch: 5| Step: 4
Training loss: 3.226422101307525
Validation loss: 3.004096002006351

Epoch: 5| Step: 5
Training loss: 3.2025218861030815
Validation loss: 2.9939603991376282

Epoch: 5| Step: 6
Training loss: 2.5391233466266985
Validation loss: 2.9801160913150286

Epoch: 5| Step: 7
Training loss: 3.15314292940424
Validation loss: 2.9650416279733367

Epoch: 5| Step: 8
Training loss: 3.7906088279133847
Validation loss: 2.927787131820416

Epoch: 5| Step: 9
Training loss: 3.3757875724509034
Validation loss: 2.915480016919636

Epoch: 5| Step: 10
Training loss: 2.9664877855469616
Validation loss: 2.9071861944195354

Epoch: 20| Step: 0
Training loss: 3.054041957694411
Validation loss: 2.906634244151885

Epoch: 5| Step: 1
Training loss: 2.9509831487471176
Validation loss: 2.874209872794068

Epoch: 5| Step: 2
Training loss: 3.1574725814196696
Validation loss: 2.866248630550384

Epoch: 5| Step: 3
Training loss: 3.5610932366737047
Validation loss: 2.8660092531015393

Epoch: 5| Step: 4
Training loss: 3.341076361314753
Validation loss: 2.8299381959187992

Epoch: 5| Step: 5
Training loss: 3.0879789529191863
Validation loss: 2.8305146826767347

Epoch: 5| Step: 6
Training loss: 3.5161916318538364
Validation loss: 2.8025506968604263

Epoch: 5| Step: 7
Training loss: 3.066692674222489
Validation loss: 2.7827682600399197

Epoch: 5| Step: 8
Training loss: 2.6685923438216754
Validation loss: 2.7779326796325132

Epoch: 5| Step: 9
Training loss: 2.7501112308548494
Validation loss: 2.7637022210335025

Epoch: 5| Step: 10
Training loss: 2.501146435135343
Validation loss: 2.749715557284988

Epoch: 21| Step: 0
Training loss: 3.2982581252020626
Validation loss: 2.72316281698773

Epoch: 5| Step: 1
Training loss: 2.9270758215829344
Validation loss: 2.7311742919887676

Epoch: 5| Step: 2
Training loss: 3.187091726447566
Validation loss: 2.7210248190963187

Epoch: 5| Step: 3
Training loss: 2.6464118525291536
Validation loss: 2.7045443870601678

Epoch: 5| Step: 4
Training loss: 2.8883093554218164
Validation loss: 2.682932133745889

Epoch: 5| Step: 5
Training loss: 2.9164432076729256
Validation loss: 2.688717568439442

Epoch: 5| Step: 6
Training loss: 2.5899168438615314
Validation loss: 2.67756341672529

Epoch: 5| Step: 7
Training loss: 2.7938966716864364
Validation loss: 2.672806714624352

Epoch: 5| Step: 8
Training loss: 2.559808014882968
Validation loss: 2.664022997087314

Epoch: 5| Step: 9
Training loss: 2.8981443190038716
Validation loss: 2.6444003237750877

Epoch: 5| Step: 10
Training loss: 3.9660815782491348
Validation loss: 2.6359965218147865

Epoch: 22| Step: 0
Training loss: 3.5447830551331325
Validation loss: 2.6176189783833554

Epoch: 5| Step: 1
Training loss: 2.9416497320997115
Validation loss: 2.629294221593811

Epoch: 5| Step: 2
Training loss: 3.050372341754338
Validation loss: 2.6211010983083525

Epoch: 5| Step: 3
Training loss: 2.6829191689899985
Validation loss: 2.6076722882722057

Epoch: 5| Step: 4
Training loss: 3.3864232058635886
Validation loss: 2.6020626292087323

Epoch: 5| Step: 5
Training loss: 2.5635150666751136
Validation loss: 2.591186044922766

Epoch: 5| Step: 6
Training loss: 2.0997844676265798
Validation loss: 2.574467640942419

Epoch: 5| Step: 7
Training loss: 2.8702598969815787
Validation loss: 2.578756775671576

Epoch: 5| Step: 8
Training loss: 3.176567627789608
Validation loss: 2.5967418180366035

Epoch: 5| Step: 9
Training loss: 2.968275333404066
Validation loss: 2.5577235391745115

Epoch: 5| Step: 10
Training loss: 2.543261064408418
Validation loss: 2.575364649681644

Epoch: 23| Step: 0
Training loss: 2.8266370030712022
Validation loss: 2.5549522614685474

Epoch: 5| Step: 1
Training loss: 3.0815209569433493
Validation loss: 2.5654784200285317

Epoch: 5| Step: 2
Training loss: 3.0270367472862607
Validation loss: 2.5807508732181366

Epoch: 5| Step: 3
Training loss: 2.9331824856320403
Validation loss: 2.568526496941389

Epoch: 5| Step: 4
Training loss: 3.1138933793314503
Validation loss: 2.550842446233823

Epoch: 5| Step: 5
Training loss: 2.7844465081722363
Validation loss: 2.558955600816869

Epoch: 5| Step: 6
Training loss: 2.9691942384524426
Validation loss: 2.5445210792066986

Epoch: 5| Step: 7
Training loss: 2.916666376023051
Validation loss: 2.5216217777555525

Epoch: 5| Step: 8
Training loss: 2.4770011633699696
Validation loss: 2.5754859003121946

Epoch: 5| Step: 9
Training loss: 2.514204773513478
Validation loss: 2.546279154057214

Epoch: 5| Step: 10
Training loss: 3.114986704006567
Validation loss: 2.5398567768480675

Epoch: 24| Step: 0
Training loss: 3.24444604362669
Validation loss: 2.542763200312193

Epoch: 5| Step: 1
Training loss: 2.65352670528817
Validation loss: 2.5342880909633374

Epoch: 5| Step: 2
Training loss: 2.3795520926791416
Validation loss: 2.5427106447787353

Epoch: 5| Step: 3
Training loss: 2.9714598485065586
Validation loss: 2.5477358673404806

Epoch: 5| Step: 4
Training loss: 2.8486164080775516
Validation loss: 2.538526786029999

Epoch: 5| Step: 5
Training loss: 2.5809497501605883
Validation loss: 2.544550017867043

Epoch: 5| Step: 6
Training loss: 2.8415676588185534
Validation loss: 2.5374397204800516

Epoch: 5| Step: 7
Training loss: 2.4970053857173133
Validation loss: 2.539540623278095

Epoch: 5| Step: 8
Training loss: 2.738701672460607
Validation loss: 2.5167339909488318

Epoch: 5| Step: 9
Training loss: 3.2099964405646153
Validation loss: 2.515299918789691

Epoch: 5| Step: 10
Training loss: 3.6882051989716733
Validation loss: 2.5256284422483963

Epoch: 25| Step: 0
Training loss: 2.6962431696848155
Validation loss: 2.5010823101502755

Epoch: 5| Step: 1
Training loss: 2.3924368182123814
Validation loss: 2.534464959933128

Epoch: 5| Step: 2
Training loss: 2.868677734262634
Validation loss: 2.53012366474998

Epoch: 5| Step: 3
Training loss: 2.753453427144113
Validation loss: 2.5321585906930464

Epoch: 5| Step: 4
Training loss: 3.0461083645896845
Validation loss: 2.517540406002048

Epoch: 5| Step: 5
Training loss: 3.2850656757728034
Validation loss: 2.55565195178984

Epoch: 5| Step: 6
Training loss: 3.115821787780554
Validation loss: 2.5161720190170374

Epoch: 5| Step: 7
Training loss: 3.3084427079602676
Validation loss: 2.5262759199118427

Epoch: 5| Step: 8
Training loss: 2.8054833093370037
Validation loss: 2.5288985874092464

Epoch: 5| Step: 9
Training loss: 2.737790573932763
Validation loss: 2.5381761158230156

Epoch: 5| Step: 10
Training loss: 2.7340117294964053
Validation loss: 2.506271721104907

Epoch: 26| Step: 0
Training loss: 2.5709918669338663
Validation loss: 2.5276568255116696

Epoch: 5| Step: 1
Training loss: 2.897222464750318
Validation loss: 2.5291543375372156

Epoch: 5| Step: 2
Training loss: 2.1199035115146927
Validation loss: 2.523758330199224

Epoch: 5| Step: 3
Training loss: 2.8702560759819717
Validation loss: 2.513730776389656

Epoch: 5| Step: 4
Training loss: 2.904611433242836
Validation loss: 2.524709690900308

Epoch: 5| Step: 5
Training loss: 2.799688277603724
Validation loss: 2.5438361485169607

Epoch: 5| Step: 6
Training loss: 3.2330663125068893
Validation loss: 2.516707728289383

Epoch: 5| Step: 7
Training loss: 3.2074806929949022
Validation loss: 2.4972546187751035

Epoch: 5| Step: 8
Training loss: 3.257761856527081
Validation loss: 2.4989848259967165

Epoch: 5| Step: 9
Training loss: 2.761159794423234
Validation loss: 2.518739724001509

Epoch: 5| Step: 10
Training loss: 2.8774365590622883
Validation loss: 2.5330986059388256

Epoch: 27| Step: 0
Training loss: 2.673898744730307
Validation loss: 2.5395097952881067

Epoch: 5| Step: 1
Training loss: 2.8052860567015827
Validation loss: 2.517056057534563

Epoch: 5| Step: 2
Training loss: 2.9020572074230806
Validation loss: 2.5156634936772546

Epoch: 5| Step: 3
Training loss: 2.7145980174871953
Validation loss: 2.5440958233907147

Epoch: 5| Step: 4
Training loss: 2.8502428319442896
Validation loss: 2.5145271140903174

Epoch: 5| Step: 5
Training loss: 2.736730814130471
Validation loss: 2.515027303791091

Epoch: 5| Step: 6
Training loss: 3.584177952665647
Validation loss: 2.5199905469090114

Epoch: 5| Step: 7
Training loss: 3.077480500420555
Validation loss: 2.5115539765170696

Epoch: 5| Step: 8
Training loss: 2.4973926298872073
Validation loss: 2.508733899643814

Epoch: 5| Step: 9
Training loss: 2.3505530741367013
Validation loss: 2.51862913062721

Epoch: 5| Step: 10
Training loss: 3.3937228769022907
Validation loss: 2.5435444988927167

Epoch: 28| Step: 0
Training loss: 3.244314061626702
Validation loss: 2.5360965986704107

Epoch: 5| Step: 1
Training loss: 3.2574513919040564
Validation loss: 2.521630747761005

Epoch: 5| Step: 2
Training loss: 2.8250711719020916
Validation loss: 2.5273037331151795

Epoch: 5| Step: 3
Training loss: 2.4557760698701094
Validation loss: 2.532587209389877

Epoch: 5| Step: 4
Training loss: 2.766377147401901
Validation loss: 2.515595867192365

Epoch: 5| Step: 5
Training loss: 2.6222624354951836
Validation loss: 2.522551460978243

Epoch: 5| Step: 6
Training loss: 2.525876593685511
Validation loss: 2.5255494193238652

Epoch: 5| Step: 7
Training loss: 2.942481018108894
Validation loss: 2.5317986320547092

Epoch: 5| Step: 8
Training loss: 3.310880733073557
Validation loss: 2.5377441638748572

Epoch: 5| Step: 9
Training loss: 2.750254012427495
Validation loss: 2.521528254169331

Epoch: 5| Step: 10
Training loss: 2.5962834681785907
Validation loss: 2.546908126425378

Epoch: 29| Step: 0
Training loss: 3.041997830552551
Validation loss: 2.496691207202707

Epoch: 5| Step: 1
Training loss: 2.4340629798809346
Validation loss: 2.5227135345155323

Epoch: 5| Step: 2
Training loss: 2.5688490020162558
Validation loss: 2.507973145323241

Epoch: 5| Step: 3
Training loss: 2.934428780644839
Validation loss: 2.5187664122949953

Epoch: 5| Step: 4
Training loss: 2.790728416107211
Validation loss: 2.521860472930613

Epoch: 5| Step: 5
Training loss: 2.4584527929559417
Validation loss: 2.5049288737963784

Epoch: 5| Step: 6
Training loss: 3.431111172784246
Validation loss: 2.4997739525602225

Epoch: 5| Step: 7
Training loss: 2.878322837234677
Validation loss: 2.5048678331339613

Epoch: 5| Step: 8
Training loss: 2.921296087839216
Validation loss: 2.514824534740621

Epoch: 5| Step: 9
Training loss: 3.1174239831388695
Validation loss: 2.502491702426955

Epoch: 5| Step: 10
Training loss: 2.9640156791982735
Validation loss: 2.520800896841597

Epoch: 30| Step: 0
Training loss: 2.9527447168033105
Validation loss: 2.5270310404816203

Epoch: 5| Step: 1
Training loss: 3.0756649507913516
Validation loss: 2.515255263365748

Epoch: 5| Step: 2
Training loss: 2.5400818641866683
Validation loss: 2.51520559444859

Epoch: 5| Step: 3
Training loss: 2.31160811674875
Validation loss: 2.5164953321263646

Epoch: 5| Step: 4
Training loss: 2.7271316065545856
Validation loss: 2.51761529356099

Epoch: 5| Step: 5
Training loss: 2.4126535396438413
Validation loss: 2.522076003413827

Epoch: 5| Step: 6
Training loss: 2.4419304124819563
Validation loss: 2.517617857082919

Epoch: 5| Step: 7
Training loss: 3.2291131456103113
Validation loss: 2.5132136486072754

Epoch: 5| Step: 8
Training loss: 3.108791737508273
Validation loss: 2.5493866522842232

Epoch: 5| Step: 9
Training loss: 3.192053291535625
Validation loss: 2.5220622260018715

Epoch: 5| Step: 10
Training loss: 3.480836448555404
Validation loss: 2.5280711505865554

Epoch: 31| Step: 0
Training loss: 2.9053623935961173
Validation loss: 2.5302957802052815

Epoch: 5| Step: 1
Training loss: 3.056273377998043
Validation loss: 2.5139395891254956

Epoch: 5| Step: 2
Training loss: 2.7499472873143973
Validation loss: 2.4970690389287262

Epoch: 5| Step: 3
Training loss: 2.7435700933263267
Validation loss: 2.5312182344575143

Epoch: 5| Step: 4
Training loss: 2.88457503363924
Validation loss: 2.495323230536101

Epoch: 5| Step: 5
Training loss: 2.9187631610843194
Validation loss: 2.507529358419445

Epoch: 5| Step: 6
Training loss: 2.868099389858626
Validation loss: 2.5183638125357932

Epoch: 5| Step: 7
Training loss: 2.423213269050466
Validation loss: 2.5137572527031358

Epoch: 5| Step: 8
Training loss: 3.1475536535172868
Validation loss: 2.5191837738604597

Epoch: 5| Step: 9
Training loss: 2.876021659769512
Validation loss: 2.5377866032222594

Epoch: 5| Step: 10
Training loss: 2.8741425603923156
Validation loss: 2.53757619363016

Epoch: 32| Step: 0
Training loss: 2.7177934388861558
Validation loss: 2.542179382417346

Epoch: 5| Step: 1
Training loss: 3.2607089918102874
Validation loss: 2.529367331399573

Epoch: 5| Step: 2
Training loss: 3.171888379599629
Validation loss: 2.516536294598202

Epoch: 5| Step: 3
Training loss: 2.4290019843767525
Validation loss: 2.4870524009037323

Epoch: 5| Step: 4
Training loss: 2.6777675857543444
Validation loss: 2.5010966551590976

Epoch: 5| Step: 5
Training loss: 2.6405272155353114
Validation loss: 2.4964648129238536

Epoch: 5| Step: 6
Training loss: 2.3879717894953316
Validation loss: 2.522373823713249

Epoch: 5| Step: 7
Training loss: 3.110820031930026
Validation loss: 2.498775864404552

Epoch: 5| Step: 8
Training loss: 3.257902807360814
Validation loss: 2.522627487376618

Epoch: 5| Step: 9
Training loss: 2.8409186720253032
Validation loss: 2.5282592139928677

Epoch: 5| Step: 10
Training loss: 2.9422329048790026
Validation loss: 2.5302981024087514

Epoch: 33| Step: 0
Training loss: 2.5200487182085936
Validation loss: 2.5165870654594236

Epoch: 5| Step: 1
Training loss: 3.309834253362093
Validation loss: 2.5091759062089896

Epoch: 5| Step: 2
Training loss: 3.123411919478088
Validation loss: 2.5077609958828324

Epoch: 5| Step: 3
Training loss: 2.9181383688778353
Validation loss: 2.5016804308024616

Epoch: 5| Step: 4
Training loss: 3.095100801518041
Validation loss: 2.502282616196164

Epoch: 5| Step: 5
Training loss: 2.841191744528131
Validation loss: 2.52461017270488

Epoch: 5| Step: 6
Training loss: 2.909596475105993
Validation loss: 2.528675707284952

Epoch: 5| Step: 7
Training loss: 3.1685406677805017
Validation loss: 2.5077404463833144

Epoch: 5| Step: 8
Training loss: 2.2649659349183007
Validation loss: 2.5078745392721116

Epoch: 5| Step: 9
Training loss: 2.873964206034647
Validation loss: 2.5390326011796804

Epoch: 5| Step: 10
Training loss: 2.3483211445362357
Validation loss: 2.5071237527023578

Epoch: 34| Step: 0
Training loss: 3.1151834035308865
Validation loss: 2.5235838691902464

Epoch: 5| Step: 1
Training loss: 2.8516994495688683
Validation loss: 2.5431551079214345

Epoch: 5| Step: 2
Training loss: 2.5874684576056195
Validation loss: 2.514738847680496

Epoch: 5| Step: 3
Training loss: 2.933120709718289
Validation loss: 2.5112866726465857

Epoch: 5| Step: 4
Training loss: 2.294501499064977
Validation loss: 2.5179636652488715

Epoch: 5| Step: 5
Training loss: 3.4387075903997637
Validation loss: 2.526640458088629

Epoch: 5| Step: 6
Training loss: 3.1965768266715373
Validation loss: 2.5329947799009522

Epoch: 5| Step: 7
Training loss: 2.5719028179383905
Validation loss: 2.5002450479368337

Epoch: 5| Step: 8
Training loss: 2.5796855480572565
Validation loss: 2.519842391545591

Epoch: 5| Step: 9
Training loss: 2.799656683446386
Validation loss: 2.5203131824947653

Epoch: 5| Step: 10
Training loss: 2.9725033774649487
Validation loss: 2.5083015687491765

Epoch: 35| Step: 0
Training loss: 2.9090116771832117
Validation loss: 2.5396879368964638

Epoch: 5| Step: 1
Training loss: 2.6983641225162898
Validation loss: 2.4868322020517266

Epoch: 5| Step: 2
Training loss: 2.374958941456103
Validation loss: 2.507249120438403

Epoch: 5| Step: 3
Training loss: 3.1161082605596873
Validation loss: 2.4999299598439855

Epoch: 5| Step: 4
Training loss: 2.688251301632714
Validation loss: 2.520656310147138

Epoch: 5| Step: 5
Training loss: 2.9046513251996164
Validation loss: 2.501989938560659

Epoch: 5| Step: 6
Training loss: 3.1891618772028343
Validation loss: 2.507682413826463

Epoch: 5| Step: 7
Training loss: 2.422344137714746
Validation loss: 2.5250036358388326

Epoch: 5| Step: 8
Training loss: 3.494593395326161
Validation loss: 2.5123467541641316

Epoch: 5| Step: 9
Training loss: 2.762187653571879
Validation loss: 2.524500611333132

Epoch: 5| Step: 10
Training loss: 2.8318815625850733
Validation loss: 2.517532908162465

Epoch: 36| Step: 0
Training loss: 2.981971931617088
Validation loss: 2.5246453327624008

Epoch: 5| Step: 1
Training loss: 3.0911857690242694
Validation loss: 2.5152594748485315

Epoch: 5| Step: 2
Training loss: 2.3780408766676606
Validation loss: 2.4960010498576852

Epoch: 5| Step: 3
Training loss: 2.812510596361332
Validation loss: 2.509300602354933

Epoch: 5| Step: 4
Training loss: 3.2296712829743734
Validation loss: 2.4943847742325294

Epoch: 5| Step: 5
Training loss: 2.669919017463723
Validation loss: 2.5461375934725483

Epoch: 5| Step: 6
Training loss: 2.3962610167089426
Validation loss: 2.5205569975585234

Epoch: 5| Step: 7
Training loss: 3.0107233403865976
Validation loss: 2.5466253330770123

Epoch: 5| Step: 8
Training loss: 2.5747929165725973
Validation loss: 2.516916112741814

Epoch: 5| Step: 9
Training loss: 2.945474230628803
Validation loss: 2.5316019080731738

Epoch: 5| Step: 10
Training loss: 3.2253037184004447
Validation loss: 2.509120258362536

Epoch: 37| Step: 0
Training loss: 2.7905777947511785
Validation loss: 2.518353359909154

Epoch: 5| Step: 1
Training loss: 2.690232240939966
Validation loss: 2.5083537036086465

Epoch: 5| Step: 2
Training loss: 2.895965426791872
Validation loss: 2.5119515013910703

Epoch: 5| Step: 3
Training loss: 2.8689200756046724
Validation loss: 2.533020696578885

Epoch: 5| Step: 4
Training loss: 2.8451350266203796
Validation loss: 2.539359258911097

Epoch: 5| Step: 5
Training loss: 2.9038604428935213
Validation loss: 2.5135963630599067

Epoch: 5| Step: 6
Training loss: 2.691481103395999
Validation loss: 2.519506799188607

Epoch: 5| Step: 7
Training loss: 3.0123719374159386
Validation loss: 2.511679075150979

Epoch: 5| Step: 8
Training loss: 2.604004226704579
Validation loss: 2.5206033857219046

Epoch: 5| Step: 9
Training loss: 3.33289664904902
Validation loss: 2.5197834163111654

Epoch: 5| Step: 10
Training loss: 2.5907359247882686
Validation loss: 2.501503857142138

Epoch: 38| Step: 0
Training loss: 2.019215424447914
Validation loss: 2.522748239323642

Epoch: 5| Step: 1
Training loss: 2.383243909460889
Validation loss: 2.541693778744887

Epoch: 5| Step: 2
Training loss: 3.17815735386947
Validation loss: 2.5230900080641643

Epoch: 5| Step: 3
Training loss: 2.784719039606531
Validation loss: 2.515104450534347

Epoch: 5| Step: 4
Training loss: 1.9695284076626283
Validation loss: 2.498787787041222

Epoch: 5| Step: 5
Training loss: 3.07580866531351
Validation loss: 2.529052168110054

Epoch: 5| Step: 6
Training loss: 3.370221463858733
Validation loss: 2.520367609779006

Epoch: 5| Step: 7
Training loss: 3.53573215914966
Validation loss: 2.5176448968616083

Epoch: 5| Step: 8
Training loss: 3.1106946435589444
Validation loss: 2.495675136171987

Epoch: 5| Step: 9
Training loss: 2.6125131342069476
Validation loss: 2.5022066135262757

Epoch: 5| Step: 10
Training loss: 2.931823602769503
Validation loss: 2.5089510277878064

Epoch: 39| Step: 0
Training loss: 2.9027153588438144
Validation loss: 2.5210172368651715

Epoch: 5| Step: 1
Training loss: 3.3176382268009066
Validation loss: 2.489829238470457

Epoch: 5| Step: 2
Training loss: 2.6289934934562416
Validation loss: 2.5150528551850164

Epoch: 5| Step: 3
Training loss: 2.103038964063409
Validation loss: 2.529936110814068

Epoch: 5| Step: 4
Training loss: 2.8666253227387073
Validation loss: 2.5176903153380703

Epoch: 5| Step: 5
Training loss: 2.9894291287481805
Validation loss: 2.512772724686001

Epoch: 5| Step: 6
Training loss: 2.498135443601903
Validation loss: 2.50696820688968

Epoch: 5| Step: 7
Training loss: 2.517430859765072
Validation loss: 2.5149095705576463

Epoch: 5| Step: 8
Training loss: 2.742390334406526
Validation loss: 2.5135950851130655

Epoch: 5| Step: 9
Training loss: 3.5932588988069005
Validation loss: 2.4976713748880277

Epoch: 5| Step: 10
Training loss: 2.953071391915873
Validation loss: 2.515226809172059

Epoch: 40| Step: 0
Training loss: 2.0118305064149284
Validation loss: 2.504041869427918

Epoch: 5| Step: 1
Training loss: 2.874459589049244
Validation loss: 2.519622791405085

Epoch: 5| Step: 2
Training loss: 3.240455109457042
Validation loss: 2.52045690345845

Epoch: 5| Step: 3
Training loss: 2.746206788602971
Validation loss: 2.5276726617435052

Epoch: 5| Step: 4
Training loss: 2.791400602576807
Validation loss: 2.5113002294643385

Epoch: 5| Step: 5
Training loss: 2.5023820019625975
Validation loss: 2.5382903398602594

Epoch: 5| Step: 6
Training loss: 2.4066583856596915
Validation loss: 2.5128270316732837

Epoch: 5| Step: 7
Training loss: 3.3179407602256403
Validation loss: 2.51054901017931

Epoch: 5| Step: 8
Training loss: 3.234595544639599
Validation loss: 2.4981943757365292

Epoch: 5| Step: 9
Training loss: 3.0796334690132845
Validation loss: 2.515044069661013

Epoch: 5| Step: 10
Training loss: 2.8708331554248536
Validation loss: 2.514270872274177

Epoch: 41| Step: 0
Training loss: 2.9138726793906455
Validation loss: 2.510007440354738

Epoch: 5| Step: 1
Training loss: 2.2135886752055014
Validation loss: 2.534953322256214

Epoch: 5| Step: 2
Training loss: 2.502635139223391
Validation loss: 2.510613737837328

Epoch: 5| Step: 3
Training loss: 2.943602209572598
Validation loss: 2.5201606317334697

Epoch: 5| Step: 4
Training loss: 2.9009007271865923
Validation loss: 2.519962942246796

Epoch: 5| Step: 5
Training loss: 2.6447822305201236
Validation loss: 2.511469270098623

Epoch: 5| Step: 6
Training loss: 3.4233562451134167
Validation loss: 2.515299761830011

Epoch: 5| Step: 7
Training loss: 3.012771283989435
Validation loss: 2.493545468798462

Epoch: 5| Step: 8
Training loss: 2.80998490516165
Validation loss: 2.4921572342624563

Epoch: 5| Step: 9
Training loss: 2.9333245652963624
Validation loss: 2.5025773206968425

Epoch: 5| Step: 10
Training loss: 3.01753877780779
Validation loss: 2.5077903239791874

Epoch: 42| Step: 0
Training loss: 2.749260542894188
Validation loss: 2.515692792827509

Epoch: 5| Step: 1
Training loss: 3.1173400076747657
Validation loss: 2.4948712253894754

Epoch: 5| Step: 2
Training loss: 2.68909212015209
Validation loss: 2.499690426353376

Epoch: 5| Step: 3
Training loss: 2.8492139368040132
Validation loss: 2.4959340204650684

Epoch: 5| Step: 4
Training loss: 3.0559338614811464
Validation loss: 2.508656673490641

Epoch: 5| Step: 5
Training loss: 2.3027278521496357
Validation loss: 2.5116629135255457

Epoch: 5| Step: 6
Training loss: 3.091828645505592
Validation loss: 2.516509226607969

Epoch: 5| Step: 7
Training loss: 2.922382004756749
Validation loss: 2.5030438587072594

Epoch: 5| Step: 8
Training loss: 2.713414097067439
Validation loss: 2.5179686337693195

Epoch: 5| Step: 9
Training loss: 3.1642324896466056
Validation loss: 2.5214860536022243

Epoch: 5| Step: 10
Training loss: 2.4775161591742902
Validation loss: 2.5178708651283297

Epoch: 43| Step: 0
Training loss: 3.068212358727321
Validation loss: 2.5203708748904434

Epoch: 5| Step: 1
Training loss: 3.2594054647687893
Validation loss: 2.5165440551793985

Epoch: 5| Step: 2
Training loss: 2.984791991176407
Validation loss: 2.514177763525159

Epoch: 5| Step: 3
Training loss: 2.6838754564375233
Validation loss: 2.5126069469543286

Epoch: 5| Step: 4
Training loss: 2.7355535964414783
Validation loss: 2.5258778415672922

Epoch: 5| Step: 5
Training loss: 2.531972805479792
Validation loss: 2.5285634487578754

Epoch: 5| Step: 6
Training loss: 2.584526852778739
Validation loss: 2.5308371698061265

Epoch: 5| Step: 7
Training loss: 3.2298872769176077
Validation loss: 2.537060806906015

Epoch: 5| Step: 8
Training loss: 2.7372317840307305
Validation loss: 2.506610873696601

Epoch: 5| Step: 9
Training loss: 1.9965612532163517
Validation loss: 2.5156890569526142

Epoch: 5| Step: 10
Training loss: 3.2985102498657235
Validation loss: 2.525180686582497

Epoch: 44| Step: 0
Training loss: 2.7009127169152527
Validation loss: 2.519122196285722

Epoch: 5| Step: 1
Training loss: 3.1422834430086115
Validation loss: 2.513311786100104

Epoch: 5| Step: 2
Training loss: 2.704491947714296
Validation loss: 2.493270926038612

Epoch: 5| Step: 3
Training loss: 3.198856244724677
Validation loss: 2.503708862143991

Epoch: 5| Step: 4
Training loss: 2.305482578526968
Validation loss: 2.524947609850847

Epoch: 5| Step: 5
Training loss: 2.820366349062835
Validation loss: 2.5308929063863883

Epoch: 5| Step: 6
Training loss: 2.904510633840876
Validation loss: 2.529593028305936

Epoch: 5| Step: 7
Training loss: 2.6782835015450543
Validation loss: 2.50400429155309

Epoch: 5| Step: 8
Training loss: 2.9600142597164307
Validation loss: 2.505363789213199

Epoch: 5| Step: 9
Training loss: 2.729662512854296
Validation loss: 2.501785242844731

Epoch: 5| Step: 10
Training loss: 3.083244752041065
Validation loss: 2.5211592622624743

Epoch: 45| Step: 0
Training loss: 2.2834407790397884
Validation loss: 2.5135501372797293

Epoch: 5| Step: 1
Training loss: 2.7412799083158372
Validation loss: 2.544438100007352

Epoch: 5| Step: 2
Training loss: 2.7934205443425326
Validation loss: 2.5230172227422343

Epoch: 5| Step: 3
Training loss: 3.2409618588857154
Validation loss: 2.5306469538107486

Epoch: 5| Step: 4
Training loss: 2.8413766871485877
Validation loss: 2.510974676155109

Epoch: 5| Step: 5
Training loss: 3.2503738188334896
Validation loss: 2.5068291368023172

Epoch: 5| Step: 6
Training loss: 2.4795483420925524
Validation loss: 2.5183711643669913

Epoch: 5| Step: 7
Training loss: 3.0785076077844153
Validation loss: 2.50077263008893

Epoch: 5| Step: 8
Training loss: 2.7391580655301704
Validation loss: 2.5238939118443358

Epoch: 5| Step: 9
Training loss: 3.0080702634072107
Validation loss: 2.4989325572294026

Epoch: 5| Step: 10
Training loss: 2.537650599027404
Validation loss: 2.4923907817575777

Epoch: 46| Step: 0
Training loss: 3.0894508160196517
Validation loss: 2.49171477473818

Epoch: 5| Step: 1
Training loss: 2.8573340965029073
Validation loss: 2.5081377012476422

Epoch: 5| Step: 2
Training loss: 2.7771264700795766
Validation loss: 2.4892130668351604

Epoch: 5| Step: 3
Training loss: 2.678643826914068
Validation loss: 2.5158054361235265

Epoch: 5| Step: 4
Training loss: 2.980291798789611
Validation loss: 2.5114907603457968

Epoch: 5| Step: 5
Training loss: 3.099918573602195
Validation loss: 2.5160755571042026

Epoch: 5| Step: 6
Training loss: 2.519150532191181
Validation loss: 2.5082029245043693

Epoch: 5| Step: 7
Training loss: 2.3267729244543562
Validation loss: 2.5169236847366534

Epoch: 5| Step: 8
Training loss: 3.1119181138863823
Validation loss: 2.5167491319370803

Epoch: 5| Step: 9
Training loss: 2.6920402676998503
Validation loss: 2.4836255366669797

Epoch: 5| Step: 10
Training loss: 2.940167453694044
Validation loss: 2.5199650735578443

Epoch: 47| Step: 0
Training loss: 2.663068837753361
Validation loss: 2.5078211217402426

Epoch: 5| Step: 1
Training loss: 3.6573428615520585
Validation loss: 2.4968463449275027

Epoch: 5| Step: 2
Training loss: 2.5639877652487852
Validation loss: 2.5058877524349104

Epoch: 5| Step: 3
Training loss: 3.0477858526840103
Validation loss: 2.528561021546239

Epoch: 5| Step: 4
Training loss: 2.515500178113221
Validation loss: 2.5130102415061937

Epoch: 5| Step: 5
Training loss: 2.8021456535433478
Validation loss: 2.521101852295116

Epoch: 5| Step: 6
Training loss: 2.8224874547877237
Validation loss: 2.4994547813407273

Epoch: 5| Step: 7
Training loss: 3.042960914924926
Validation loss: 2.5105294673839915

Epoch: 5| Step: 8
Training loss: 2.517502836133009
Validation loss: 2.515637657028211

Epoch: 5| Step: 9
Training loss: 2.771028746021827
Validation loss: 2.503928647784147

Epoch: 5| Step: 10
Training loss: 2.2667433510692603
Validation loss: 2.5054590243352957

Epoch: 48| Step: 0
Training loss: 2.914003100569626
Validation loss: 2.5021799857919973

Epoch: 5| Step: 1
Training loss: 2.648594224281757
Validation loss: 2.5201786858727377

Epoch: 5| Step: 2
Training loss: 2.9872820212036464
Validation loss: 2.50911437626247

Epoch: 5| Step: 3
Training loss: 3.0152027842584976
Validation loss: 2.517715173776569

Epoch: 5| Step: 4
Training loss: 2.195913320842284
Validation loss: 2.5155292885891574

Epoch: 5| Step: 5
Training loss: 3.3924628695520105
Validation loss: 2.4986101019540303

Epoch: 5| Step: 6
Training loss: 2.5758902371934647
Validation loss: 2.520402464879459

Epoch: 5| Step: 7
Training loss: 2.867945931971762
Validation loss: 2.466893502361839

Epoch: 5| Step: 8
Training loss: 2.862910518610954
Validation loss: 2.4952987346379545

Epoch: 5| Step: 9
Training loss: 2.6575977272301863
Validation loss: 2.5209372344876884

Epoch: 5| Step: 10
Training loss: 2.820510138774922
Validation loss: 2.4816260540557735

Epoch: 49| Step: 0
Training loss: 2.388547705404104
Validation loss: 2.508454771219147

Epoch: 5| Step: 1
Training loss: 3.100344171184445
Validation loss: 2.5092548317733474

Epoch: 5| Step: 2
Training loss: 3.1696697517957952
Validation loss: 2.5078612532304545

Epoch: 5| Step: 3
Training loss: 2.131614152779951
Validation loss: 2.483308563871447

Epoch: 5| Step: 4
Training loss: 2.7334426598278316
Validation loss: 2.4770711196207373

Epoch: 5| Step: 5
Training loss: 3.008737080145729
Validation loss: 2.4928531925841266

Epoch: 5| Step: 6
Training loss: 2.5208850151207707
Validation loss: 2.5131915304461168

Epoch: 5| Step: 7
Training loss: 3.302347712156808
Validation loss: 2.5088674985145607

Epoch: 5| Step: 8
Training loss: 3.1952272884133897
Validation loss: 2.527334393510605

Epoch: 5| Step: 9
Training loss: 2.149042550632707
Validation loss: 2.5168126102314994

Epoch: 5| Step: 10
Training loss: 3.038477039576198
Validation loss: 2.4827805717876577

Epoch: 50| Step: 0
Training loss: 2.819422784940293
Validation loss: 2.5165699614723875

Epoch: 5| Step: 1
Training loss: 2.349065221369046
Validation loss: 2.500965696884474

Epoch: 5| Step: 2
Training loss: 2.527656170315107
Validation loss: 2.5193682553720023

Epoch: 5| Step: 3
Training loss: 2.7625888171525363
Validation loss: 2.496598908153191

Epoch: 5| Step: 4
Training loss: 2.662432040211336
Validation loss: 2.5123835246115687

Epoch: 5| Step: 5
Training loss: 3.190635335907368
Validation loss: 2.510422834033834

Epoch: 5| Step: 6
Training loss: 2.4999423020380465
Validation loss: 2.492518502241196

Epoch: 5| Step: 7
Training loss: 2.83017483605892
Validation loss: 2.4985904247368187

Epoch: 5| Step: 8
Training loss: 3.69299179015085
Validation loss: 2.5027262415140017

Epoch: 5| Step: 9
Training loss: 3.0246144450993926
Validation loss: 2.5159017473950165

Epoch: 5| Step: 10
Training loss: 2.23485437332655
Validation loss: 2.4935580718609307

Epoch: 51| Step: 0
Training loss: 3.1888691074881677
Validation loss: 2.4988701010305805

Epoch: 5| Step: 1
Training loss: 3.164918986122821
Validation loss: 2.5010457056609683

Epoch: 5| Step: 2
Training loss: 2.8676333379632997
Validation loss: 2.5166842951894357

Epoch: 5| Step: 3
Training loss: 3.188309660160805
Validation loss: 2.484087146137484

Epoch: 5| Step: 4
Training loss: 2.418773018187772
Validation loss: 2.515864495436229

Epoch: 5| Step: 5
Training loss: 2.5838160730337556
Validation loss: 2.508227947494475

Epoch: 5| Step: 6
Training loss: 2.7495664775031328
Validation loss: 2.517752671237758

Epoch: 5| Step: 7
Training loss: 2.6896393710759163
Validation loss: 2.509876326506465

Epoch: 5| Step: 8
Training loss: 3.156693833370858
Validation loss: 2.5297717577745056

Epoch: 5| Step: 9
Training loss: 2.439639986087855
Validation loss: 2.4807405123490014

Epoch: 5| Step: 10
Training loss: 2.317964541100672
Validation loss: 2.4992076284620555

Epoch: 52| Step: 0
Training loss: 3.1724367442937944
Validation loss: 2.505256947248312

Epoch: 5| Step: 1
Training loss: 2.449240360438453
Validation loss: 2.5235825465232953

Epoch: 5| Step: 2
Training loss: 3.1328242199457366
Validation loss: 2.5112019939633474

Epoch: 5| Step: 3
Training loss: 2.637351902424183
Validation loss: 2.508470320900098

Epoch: 5| Step: 4
Training loss: 2.8272091557598986
Validation loss: 2.5104969464384355

Epoch: 5| Step: 5
Training loss: 3.1224162292238535
Validation loss: 2.5158129946475585

Epoch: 5| Step: 6
Training loss: 2.070694682995136
Validation loss: 2.5097257834179705

Epoch: 5| Step: 7
Training loss: 3.1166182454745566
Validation loss: 2.499514799307633

Epoch: 5| Step: 8
Training loss: 2.783702240745338
Validation loss: 2.508068607432367

Epoch: 5| Step: 9
Training loss: 2.919194751647597
Validation loss: 2.5127532430563173

Epoch: 5| Step: 10
Training loss: 2.618042034875397
Validation loss: 2.5038914900415032

Epoch: 53| Step: 0
Training loss: 3.0538906609348855
Validation loss: 2.4782501647174366

Epoch: 5| Step: 1
Training loss: 2.6778609832281446
Validation loss: 2.4997432464095235

Epoch: 5| Step: 2
Training loss: 3.085777877349146
Validation loss: 2.5098379744047357

Epoch: 5| Step: 3
Training loss: 2.939825395602334
Validation loss: 2.50678411980904

Epoch: 5| Step: 4
Training loss: 2.734768212519755
Validation loss: 2.5075444159444102

Epoch: 5| Step: 5
Training loss: 3.0263463893888445
Validation loss: 2.5048706379339336

Epoch: 5| Step: 6
Training loss: 2.5935379309306477
Validation loss: 2.5025472830547595

Epoch: 5| Step: 7
Training loss: 2.5945230274248186
Validation loss: 2.507944319224553

Epoch: 5| Step: 8
Training loss: 2.785656385204292
Validation loss: 2.4993570823911253

Epoch: 5| Step: 9
Training loss: 2.544384915082593
Validation loss: 2.509935886906887

Epoch: 5| Step: 10
Training loss: 2.8904803265633054
Validation loss: 2.5106023380156026

Epoch: 54| Step: 0
Training loss: 2.2308289459189172
Validation loss: 2.5061003325588143

Epoch: 5| Step: 1
Training loss: 2.0910590800290354
Validation loss: 2.5026843835905925

Epoch: 5| Step: 2
Training loss: 3.0620099668234704
Validation loss: 2.495984123205779

Epoch: 5| Step: 3
Training loss: 3.478262976200046
Validation loss: 2.4917188644772086

Epoch: 5| Step: 4
Training loss: 2.7972572960454567
Validation loss: 2.522846422555217

Epoch: 5| Step: 5
Training loss: 2.782677016475545
Validation loss: 2.496485945581951

Epoch: 5| Step: 6
Training loss: 2.8948208436231084
Validation loss: 2.525096350478078

Epoch: 5| Step: 7
Training loss: 2.7241492316978633
Validation loss: 2.5025181240084278

Epoch: 5| Step: 8
Training loss: 3.007699146859609
Validation loss: 2.516152521933015

Epoch: 5| Step: 9
Training loss: 2.982690785294163
Validation loss: 2.4920944981904483

Epoch: 5| Step: 10
Training loss: 2.873349586788978
Validation loss: 2.5075554002741334

Epoch: 55| Step: 0
Training loss: 2.0153660570937713
Validation loss: 2.493779705609934

Epoch: 5| Step: 1
Training loss: 2.6014771776842407
Validation loss: 2.4905906620222336

Epoch: 5| Step: 2
Training loss: 2.627351434284081
Validation loss: 2.4985160094314094

Epoch: 5| Step: 3
Training loss: 3.447937810704302
Validation loss: 2.4882084592492983

Epoch: 5| Step: 4
Training loss: 3.4092212282183407
Validation loss: 2.4950553252397323

Epoch: 5| Step: 5
Training loss: 2.2252473929381047
Validation loss: 2.4921122413042442

Epoch: 5| Step: 6
Training loss: 3.228059361428436
Validation loss: 2.4961556399308225

Epoch: 5| Step: 7
Training loss: 2.483452967721213
Validation loss: 2.5115768297344756

Epoch: 5| Step: 8
Training loss: 2.900907137826035
Validation loss: 2.5047674140062033

Epoch: 5| Step: 9
Training loss: 2.6430485004387236
Validation loss: 2.5098512877754633

Epoch: 5| Step: 10
Training loss: 2.964425883040431
Validation loss: 2.5122288784715994

Epoch: 56| Step: 0
Training loss: 2.4354563239670153
Validation loss: 2.502319230253323

Epoch: 5| Step: 1
Training loss: 2.7828112731279755
Validation loss: 2.500297858839655

Epoch: 5| Step: 2
Training loss: 2.938222106484411
Validation loss: 2.4950574387826667

Epoch: 5| Step: 3
Training loss: 2.9415155114376534
Validation loss: 2.510111887332523

Epoch: 5| Step: 4
Training loss: 3.308362283908296
Validation loss: 2.512660969803107

Epoch: 5| Step: 5
Training loss: 2.9094329139853774
Validation loss: 2.5284583414655657

Epoch: 5| Step: 6
Training loss: 2.9844878010627522
Validation loss: 2.4991979368608406

Epoch: 5| Step: 7
Training loss: 2.5452049724424173
Validation loss: 2.5307746576600074

Epoch: 5| Step: 8
Training loss: 2.2229198976568916
Validation loss: 2.4837668627728906

Epoch: 5| Step: 9
Training loss: 2.797372528662822
Validation loss: 2.480288911203687

Epoch: 5| Step: 10
Training loss: 3.175493253104578
Validation loss: 2.502758770218745

Epoch: 57| Step: 0
Training loss: 3.316364553164701
Validation loss: 2.4987908546409736

Epoch: 5| Step: 1
Training loss: 2.795888034003086
Validation loss: 2.4955355179054615

Epoch: 5| Step: 2
Training loss: 2.5688407417846735
Validation loss: 2.513931470721958

Epoch: 5| Step: 3
Training loss: 2.5902711449459495
Validation loss: 2.5184620984940578

Epoch: 5| Step: 4
Training loss: 2.83551829368732
Validation loss: 2.5114937164780784

Epoch: 5| Step: 5
Training loss: 2.941768547937827
Validation loss: 2.506130440139493

Epoch: 5| Step: 6
Training loss: 2.659805073013476
Validation loss: 2.498970025685571

Epoch: 5| Step: 7
Training loss: 2.472693565050932
Validation loss: 2.486508602874845

Epoch: 5| Step: 8
Training loss: 2.6353769915060767
Validation loss: 2.47604044025347

Epoch: 5| Step: 9
Training loss: 3.1397457884887765
Validation loss: 2.494694577747756

Epoch: 5| Step: 10
Training loss: 3.009902663827409
Validation loss: 2.531414948759015

Epoch: 58| Step: 0
Training loss: 2.8464957594954683
Validation loss: 2.4921587515699253

Epoch: 5| Step: 1
Training loss: 2.9555736259953327
Validation loss: 2.4897237892465363

Epoch: 5| Step: 2
Training loss: 3.2184979979002306
Validation loss: 2.5130854782842778

Epoch: 5| Step: 3
Training loss: 2.820275811038628
Validation loss: 2.4965980558648706

Epoch: 5| Step: 4
Training loss: 2.7878294711563334
Validation loss: 2.5053473474041987

Epoch: 5| Step: 5
Training loss: 2.5695063013644206
Validation loss: 2.500217568764414

Epoch: 5| Step: 6
Training loss: 2.798202881384222
Validation loss: 2.5338806940798864

Epoch: 5| Step: 7
Training loss: 2.8109628503408035
Validation loss: 2.5296194135920698

Epoch: 5| Step: 8
Training loss: 2.6934923301008324
Validation loss: 2.517685480677766

Epoch: 5| Step: 9
Training loss: 2.575817485782379
Validation loss: 2.5200842186084356

Epoch: 5| Step: 10
Training loss: 2.8355475543828397
Validation loss: 2.508890211689384

Epoch: 59| Step: 0
Training loss: 3.060921086826688
Validation loss: 2.519231533632119

Epoch: 5| Step: 1
Training loss: 2.2392594095815825
Validation loss: 2.4953568327679414

Epoch: 5| Step: 2
Training loss: 2.6549511595003543
Validation loss: 2.48716563319438

Epoch: 5| Step: 3
Training loss: 2.3381998085549838
Validation loss: 2.515397710919961

Epoch: 5| Step: 4
Training loss: 2.8529295270461037
Validation loss: 2.493412158866805

Epoch: 5| Step: 5
Training loss: 3.5496731782294
Validation loss: 2.5074129662624345

Epoch: 5| Step: 6
Training loss: 3.123963145860453
Validation loss: 2.516897852875245

Epoch: 5| Step: 7
Training loss: 3.0245100775342846
Validation loss: 2.5000041469416527

Epoch: 5| Step: 8
Training loss: 2.698710370252077
Validation loss: 2.5004592289143295

Epoch: 5| Step: 9
Training loss: 2.8462389439572062
Validation loss: 2.5137974786041197

Epoch: 5| Step: 10
Training loss: 1.978860898407458
Validation loss: 2.493478055186378

Epoch: 60| Step: 0
Training loss: 2.9194270196264207
Validation loss: 2.51139218522407

Epoch: 5| Step: 1
Training loss: 2.6976330484099003
Validation loss: 2.512135235323082

Epoch: 5| Step: 2
Training loss: 2.984132127715538
Validation loss: 2.505796931848831

Epoch: 5| Step: 3
Training loss: 3.309721303080509
Validation loss: 2.5023350905777866

Epoch: 5| Step: 4
Training loss: 3.2422389750243568
Validation loss: 2.522378317038167

Epoch: 5| Step: 5
Training loss: 2.575241047956118
Validation loss: 2.54206287846932

Epoch: 5| Step: 6
Training loss: 3.019398596293769
Validation loss: 2.492068750493888

Epoch: 5| Step: 7
Training loss: 2.5418527149417582
Validation loss: 2.4939476553518727

Epoch: 5| Step: 8
Training loss: 2.731508856406912
Validation loss: 2.5005239614424277

Epoch: 5| Step: 9
Training loss: 2.424429352464021
Validation loss: 2.511065803605445

Epoch: 5| Step: 10
Training loss: 2.269547743089006
Validation loss: 2.479603518903205

Epoch: 61| Step: 0
Training loss: 2.6274733925151827
Validation loss: 2.498134546684035

Epoch: 5| Step: 1
Training loss: 3.04863011598758
Validation loss: 2.50230344461773

Epoch: 5| Step: 2
Training loss: 2.6805246897113446
Validation loss: 2.51363163230049

Epoch: 5| Step: 3
Training loss: 3.2385250869446005
Validation loss: 2.495829382813914

Epoch: 5| Step: 4
Training loss: 2.52840206858329
Validation loss: 2.517622080396869

Epoch: 5| Step: 5
Training loss: 2.946500098611185
Validation loss: 2.5129095693129573

Epoch: 5| Step: 6
Training loss: 2.823434723523901
Validation loss: 2.5084087113028017

Epoch: 5| Step: 7
Training loss: 2.5853835143474875
Validation loss: 2.520409951131087

Epoch: 5| Step: 8
Training loss: 2.782567772875358
Validation loss: 2.495231093560021

Epoch: 5| Step: 9
Training loss: 2.5972394336350013
Validation loss: 2.4984775224507945

Epoch: 5| Step: 10
Training loss: 2.9650381876398484
Validation loss: 2.5082296502997776

Epoch: 62| Step: 0
Training loss: 2.2848046187127067
Validation loss: 2.5046988454329466

Epoch: 5| Step: 1
Training loss: 2.7020964677815464
Validation loss: 2.5032178770734608

Epoch: 5| Step: 2
Training loss: 2.88890164527359
Validation loss: 2.496761474262716

Epoch: 5| Step: 3
Training loss: 2.6923708578182635
Validation loss: 2.4916265489448515

Epoch: 5| Step: 4
Training loss: 3.049429267889859
Validation loss: 2.50032490495606

Epoch: 5| Step: 5
Training loss: 2.3080794896035033
Validation loss: 2.493551342901702

Epoch: 5| Step: 6
Training loss: 2.8492803769341193
Validation loss: 2.4834474862617393

Epoch: 5| Step: 7
Training loss: 2.643455387951921
Validation loss: 2.482596875212982

Epoch: 5| Step: 8
Training loss: 3.142297100354219
Validation loss: 2.5004507519847885

Epoch: 5| Step: 9
Training loss: 3.3560054469740703
Validation loss: 2.510504303436787

Epoch: 5| Step: 10
Training loss: 2.9888317124744854
Validation loss: 2.4911261156529485

Epoch: 63| Step: 0
Training loss: 3.1548473905238454
Validation loss: 2.5166458721343545

Epoch: 5| Step: 1
Training loss: 2.606676819611636
Validation loss: 2.5031626713281203

Epoch: 5| Step: 2
Training loss: 3.1267100423747185
Validation loss: 2.489283101112426

Epoch: 5| Step: 3
Training loss: 2.3379415125714402
Validation loss: 2.524982968271622

Epoch: 5| Step: 4
Training loss: 3.006619144862045
Validation loss: 2.5068463246352723

Epoch: 5| Step: 5
Training loss: 2.643990443052255
Validation loss: 2.4802138351545686

Epoch: 5| Step: 6
Training loss: 3.0208377355784646
Validation loss: 2.504544456152181

Epoch: 5| Step: 7
Training loss: 2.616144593107089
Validation loss: 2.493292248225457

Epoch: 5| Step: 8
Training loss: 2.9632927779464504
Validation loss: 2.5175923322306986

Epoch: 5| Step: 9
Training loss: 2.4230106767394783
Validation loss: 2.4952852408840083

Epoch: 5| Step: 10
Training loss: 2.905350740830803
Validation loss: 2.5271844252761837

Epoch: 64| Step: 0
Training loss: 2.5056706013268215
Validation loss: 2.5077308741427187

Epoch: 5| Step: 1
Training loss: 3.1123005508189485
Validation loss: 2.5045711472883028

Epoch: 5| Step: 2
Training loss: 3.2585602046362085
Validation loss: 2.5039163861586204

Epoch: 5| Step: 3
Training loss: 2.681482275658676
Validation loss: 2.5055288014720185

Epoch: 5| Step: 4
Training loss: 2.729545993991123
Validation loss: 2.5091691220705044

Epoch: 5| Step: 5
Training loss: 3.5358806394825435
Validation loss: 2.524880224924619

Epoch: 5| Step: 6
Training loss: 2.4308208018090953
Validation loss: 2.5099708465244706

Epoch: 5| Step: 7
Training loss: 3.3112067811131998
Validation loss: 2.4880492456277157

Epoch: 5| Step: 8
Training loss: 1.9279125869451683
Validation loss: 2.516630976026652

Epoch: 5| Step: 9
Training loss: 2.383747855287016
Validation loss: 2.5166059713929756

Epoch: 5| Step: 10
Training loss: 2.6180246409224828
Validation loss: 2.5117795282322626

Epoch: 65| Step: 0
Training loss: 2.8136411259252747
Validation loss: 2.5327766642597713

Epoch: 5| Step: 1
Training loss: 2.3877994569248226
Validation loss: 2.5164726988000057

Epoch: 5| Step: 2
Training loss: 2.550168207642011
Validation loss: 2.5009461222564737

Epoch: 5| Step: 3
Training loss: 2.939756460158553
Validation loss: 2.492547626046725

Epoch: 5| Step: 4
Training loss: 2.7852396263708
Validation loss: 2.4928120090915593

Epoch: 5| Step: 5
Training loss: 3.19722326922922
Validation loss: 2.509826672692846

Epoch: 5| Step: 6
Training loss: 3.425604473150648
Validation loss: 2.505681745294306

Epoch: 5| Step: 7
Training loss: 2.773425550838035
Validation loss: 2.510662308013257

Epoch: 5| Step: 8
Training loss: 2.6237973682622115
Validation loss: 2.529454554501159

Epoch: 5| Step: 9
Training loss: 2.938062735690812
Validation loss: 2.5041225579819684

Epoch: 5| Step: 10
Training loss: 1.9768340636654216
Validation loss: 2.537212607278157

Epoch: 66| Step: 0
Training loss: 2.991856489472895
Validation loss: 2.5111221127685455

Epoch: 5| Step: 1
Training loss: 3.119461950711769
Validation loss: 2.4922018992929686

Epoch: 5| Step: 2
Training loss: 2.857000980941823
Validation loss: 2.5091441810085287

Epoch: 5| Step: 3
Training loss: 2.9076898761128933
Validation loss: 2.5049724749670967

Epoch: 5| Step: 4
Training loss: 2.4556395648185516
Validation loss: 2.4954760956172515

Epoch: 5| Step: 5
Training loss: 2.231620638113663
Validation loss: 2.4984642418474534

Epoch: 5| Step: 6
Training loss: 2.1882970175401457
Validation loss: 2.498249081722274

Epoch: 5| Step: 7
Training loss: 2.222837631789282
Validation loss: 2.498464096656198

Epoch: 5| Step: 8
Training loss: 3.6434820531405965
Validation loss: 2.5252996155054444

Epoch: 5| Step: 9
Training loss: 2.657697754299847
Validation loss: 2.5084921914679823

Epoch: 5| Step: 10
Training loss: 3.1190518036332064
Validation loss: 2.4897098647263105

Epoch: 67| Step: 0
Training loss: 2.748021367652143
Validation loss: 2.4965737429344235

Epoch: 5| Step: 1
Training loss: 2.463018209857045
Validation loss: 2.5135566464529933

Epoch: 5| Step: 2
Training loss: 2.787969294845527
Validation loss: 2.4849354359551654

Epoch: 5| Step: 3
Training loss: 2.397858192488747
Validation loss: 2.5035657730711907

Epoch: 5| Step: 4
Training loss: 2.7901345978677714
Validation loss: 2.504311903888211

Epoch: 5| Step: 5
Training loss: 2.7802833849049304
Validation loss: 2.5094324751968466

Epoch: 5| Step: 6
Training loss: 2.931804410970659
Validation loss: 2.4963063939300847

Epoch: 5| Step: 7
Training loss: 3.2301271712362034
Validation loss: 2.5016355076691155

Epoch: 5| Step: 8
Training loss: 2.6886038176782088
Validation loss: 2.5002972908045034

Epoch: 5| Step: 9
Training loss: 3.0274536900400166
Validation loss: 2.487388658476834

Epoch: 5| Step: 10
Training loss: 2.9075199756936523
Validation loss: 2.4933133851528253

Epoch: 68| Step: 0
Training loss: 2.8746025805905573
Validation loss: 2.493353509554263

Epoch: 5| Step: 1
Training loss: 3.1281217622692568
Validation loss: 2.4835053042109134

Epoch: 5| Step: 2
Training loss: 2.5155932501453813
Validation loss: 2.4979284984640895

Epoch: 5| Step: 3
Training loss: 2.379645973289077
Validation loss: 2.4903703776376145

Epoch: 5| Step: 4
Training loss: 2.987183692180251
Validation loss: 2.501728795258762

Epoch: 5| Step: 5
Training loss: 3.029021712398194
Validation loss: 2.504893074685467

Epoch: 5| Step: 6
Training loss: 2.3228414092823906
Validation loss: 2.5034858008001817

Epoch: 5| Step: 7
Training loss: 2.6887365645707404
Validation loss: 2.5032102031954087

Epoch: 5| Step: 8
Training loss: 2.8830864008600607
Validation loss: 2.504852564036444

Epoch: 5| Step: 9
Training loss: 3.0251978596695004
Validation loss: 2.4977467093359365

Epoch: 5| Step: 10
Training loss: 2.7489026220953954
Validation loss: 2.5071824638499547

Epoch: 69| Step: 0
Training loss: 2.5329292284585043
Validation loss: 2.501326959443826

Epoch: 5| Step: 1
Training loss: 3.0043759220662296
Validation loss: 2.4923958269714674

Epoch: 5| Step: 2
Training loss: 2.7789909532200014
Validation loss: 2.4993494417909017

Epoch: 5| Step: 3
Training loss: 2.8256579856575708
Validation loss: 2.497903257350749

Epoch: 5| Step: 4
Training loss: 2.6363988159487253
Validation loss: 2.497710278690678

Epoch: 5| Step: 5
Training loss: 3.2620494195222234
Validation loss: 2.4897859765233825

Epoch: 5| Step: 6
Training loss: 2.3195348393331208
Validation loss: 2.48553668410412

Epoch: 5| Step: 7
Training loss: 2.418534072582336
Validation loss: 2.503436092942648

Epoch: 5| Step: 8
Training loss: 2.8391905063456453
Validation loss: 2.5166403621229816

Epoch: 5| Step: 9
Training loss: 3.10056855925248
Validation loss: 2.505280504629785

Epoch: 5| Step: 10
Training loss: 2.8673908878709256
Validation loss: 2.5041165842883473

Epoch: 70| Step: 0
Training loss: 2.6656016269388076
Validation loss: 2.5014031102895458

Epoch: 5| Step: 1
Training loss: 2.513140855733
Validation loss: 2.5127930968303636

Epoch: 5| Step: 2
Training loss: 3.279856794766693
Validation loss: 2.484939499711535

Epoch: 5| Step: 3
Training loss: 2.996107755426848
Validation loss: 2.5214977041485884

Epoch: 5| Step: 4
Training loss: 2.7153033629044283
Validation loss: 2.5067281560314973

Epoch: 5| Step: 5
Training loss: 2.649192679886379
Validation loss: 2.519896047666339

Epoch: 5| Step: 6
Training loss: 2.5580152017650204
Validation loss: 2.512243786904925

Epoch: 5| Step: 7
Training loss: 2.74118380096561
Validation loss: 2.5227086322488765

Epoch: 5| Step: 8
Training loss: 3.3940803043933565
Validation loss: 2.5163078026030727

Epoch: 5| Step: 9
Training loss: 2.585444561861363
Validation loss: 2.5161574614259488

Epoch: 5| Step: 10
Training loss: 2.374063206680472
Validation loss: 2.5039940871543336

Epoch: 71| Step: 0
Training loss: 2.6288926462895614
Validation loss: 2.5006522517314513

Epoch: 5| Step: 1
Training loss: 2.8268536824163313
Validation loss: 2.4815346306585746

Epoch: 5| Step: 2
Training loss: 2.830850541859149
Validation loss: 2.489022631033293

Epoch: 5| Step: 3
Training loss: 2.668567327818312
Validation loss: 2.5180175110666148

Epoch: 5| Step: 4
Training loss: 2.6237612935150754
Validation loss: 2.521201892318794

Epoch: 5| Step: 5
Training loss: 3.168687092233749
Validation loss: 2.517551218920706

Epoch: 5| Step: 6
Training loss: 2.092890776648059
Validation loss: 2.5212314880788997

Epoch: 5| Step: 7
Training loss: 2.434433597745787
Validation loss: 2.5057636588915404

Epoch: 5| Step: 8
Training loss: 3.33465651634936
Validation loss: 2.5036997501102896

Epoch: 5| Step: 9
Training loss: 2.7626131543766426
Validation loss: 2.5094587986713552

Epoch: 5| Step: 10
Training loss: 3.1022467254859944
Validation loss: 2.4962962905438686

Epoch: 72| Step: 0
Training loss: 2.5860326467106938
Validation loss: 2.4987873982047306

Epoch: 5| Step: 1
Training loss: 2.502916732677164
Validation loss: 2.5210150200064523

Epoch: 5| Step: 2
Training loss: 2.466781217475546
Validation loss: 2.50057987850729

Epoch: 5| Step: 3
Training loss: 2.314178991379942
Validation loss: 2.5120428811982043

Epoch: 5| Step: 4
Training loss: 3.082972548400633
Validation loss: 2.493149173135996

Epoch: 5| Step: 5
Training loss: 2.687650188419028
Validation loss: 2.5245007169455524

Epoch: 5| Step: 6
Training loss: 3.431850298846651
Validation loss: 2.5073603568540324

Epoch: 5| Step: 7
Training loss: 3.448130590404233
Validation loss: 2.501283961955662

Epoch: 5| Step: 8
Training loss: 2.916796835764865
Validation loss: 2.517836202039063

Epoch: 5| Step: 9
Training loss: 2.1200302577108703
Validation loss: 2.5244091625201373

Epoch: 5| Step: 10
Training loss: 2.7575033300938214
Validation loss: 2.4905662873595333

Epoch: 73| Step: 0
Training loss: 2.388564275032069
Validation loss: 2.4994261411156145

Epoch: 5| Step: 1
Training loss: 2.865083260116945
Validation loss: 2.497101952914686

Epoch: 5| Step: 2
Training loss: 2.7379623858680424
Validation loss: 2.4960937797847698

Epoch: 5| Step: 3
Training loss: 3.055010141958331
Validation loss: 2.501140838704309

Epoch: 5| Step: 4
Training loss: 3.0135943439273603
Validation loss: 2.5320260698845565

Epoch: 5| Step: 5
Training loss: 2.671670381619192
Validation loss: 2.4890686747813597

Epoch: 5| Step: 6
Training loss: 2.7200381855528204
Validation loss: 2.4844692529914583

Epoch: 5| Step: 7
Training loss: 3.0082852078830182
Validation loss: 2.5151152662809007

Epoch: 5| Step: 8
Training loss: 3.009380140131822
Validation loss: 2.48703492990162

Epoch: 5| Step: 9
Training loss: 1.7339615200089373
Validation loss: 2.508177623249934

Epoch: 5| Step: 10
Training loss: 3.2001990375607705
Validation loss: 2.5096002615471744

Epoch: 74| Step: 0
Training loss: 2.4256244799193936
Validation loss: 2.5060025990914956

Epoch: 5| Step: 1
Training loss: 2.677098394170964
Validation loss: 2.4853383912390363

Epoch: 5| Step: 2
Training loss: 3.094228842312907
Validation loss: 2.4883292289130616

Epoch: 5| Step: 3
Training loss: 2.7051361187939533
Validation loss: 2.489023107913449

Epoch: 5| Step: 4
Training loss: 2.8935522156060145
Validation loss: 2.481703695750457

Epoch: 5| Step: 5
Training loss: 3.318100136099511
Validation loss: 2.492263032098622

Epoch: 5| Step: 6
Training loss: 2.5739688549395328
Validation loss: 2.5001183666387465

Epoch: 5| Step: 7
Training loss: 2.71007953006275
Validation loss: 2.5197204859643283

Epoch: 5| Step: 8
Training loss: 2.9146754052373494
Validation loss: 2.494042951213931

Epoch: 5| Step: 9
Training loss: 2.2919159377961646
Validation loss: 2.5037424040540257

Epoch: 5| Step: 10
Training loss: 2.903318341636566
Validation loss: 2.5077922100679677

Epoch: 75| Step: 0
Training loss: 3.154344191063461
Validation loss: 2.505702073801411

Epoch: 5| Step: 1
Training loss: 3.0362510719470177
Validation loss: 2.504165988916772

Epoch: 5| Step: 2
Training loss: 3.3831930673271584
Validation loss: 2.4948771929620834

Epoch: 5| Step: 3
Training loss: 3.052775923921506
Validation loss: 2.493900063107345

Epoch: 5| Step: 4
Training loss: 3.053800722466851
Validation loss: 2.511386963803235

Epoch: 5| Step: 5
Training loss: 2.643166757733191
Validation loss: 2.4846326194345285

Epoch: 5| Step: 6
Training loss: 2.328361140826701
Validation loss: 2.5299592732287817

Epoch: 5| Step: 7
Training loss: 2.2320234822641134
Validation loss: 2.519606019373561

Epoch: 5| Step: 8
Training loss: 2.156600923592526
Validation loss: 2.519926872458736

Epoch: 5| Step: 9
Training loss: 2.740174948822171
Validation loss: 2.5017162707619667

Epoch: 5| Step: 10
Training loss: 2.5919629110637987
Validation loss: 2.49629570927442

Epoch: 76| Step: 0
Training loss: 2.85624314856177
Validation loss: 2.4915369371332012

Epoch: 5| Step: 1
Training loss: 2.9877096190393395
Validation loss: 2.4950525952013134

Epoch: 5| Step: 2
Training loss: 2.4660155205837633
Validation loss: 2.4849076827665484

Epoch: 5| Step: 3
Training loss: 2.933200205325072
Validation loss: 2.4947311438897617

Epoch: 5| Step: 4
Training loss: 2.6497097504207154
Validation loss: 2.5255899370258676

Epoch: 5| Step: 5
Training loss: 2.8015321286326933
Validation loss: 2.4720242211968233

Epoch: 5| Step: 6
Training loss: 2.4520080356061738
Validation loss: 2.478295726911053

Epoch: 5| Step: 7
Training loss: 2.895049467043003
Validation loss: 2.494791006264188

Epoch: 5| Step: 8
Training loss: 2.394783044118957
Validation loss: 2.5091470346684646

Epoch: 5| Step: 9
Training loss: 2.776196378269915
Validation loss: 2.503909086080839

Epoch: 5| Step: 10
Training loss: 3.2777205604113897
Validation loss: 2.5008136322546908

Epoch: 77| Step: 0
Training loss: 2.4817637990162695
Validation loss: 2.5003925076889133

Epoch: 5| Step: 1
Training loss: 3.0534668651961145
Validation loss: 2.4961596525555767

Epoch: 5| Step: 2
Training loss: 3.0695580873313775
Validation loss: 2.4922332085700822

Epoch: 5| Step: 3
Training loss: 2.060503947457168
Validation loss: 2.4938314907672403

Epoch: 5| Step: 4
Training loss: 2.9742223797218132
Validation loss: 2.5048161753313627

Epoch: 5| Step: 5
Training loss: 3.119269189830446
Validation loss: 2.482968849356933

Epoch: 5| Step: 6
Training loss: 3.0711449812189757
Validation loss: 2.5080956116606936

Epoch: 5| Step: 7
Training loss: 3.03232924921737
Validation loss: 2.505285995623927

Epoch: 5| Step: 8
Training loss: 2.2266094002050614
Validation loss: 2.5090289877049856

Epoch: 5| Step: 9
Training loss: 2.301169603923298
Validation loss: 2.512487564154092

Epoch: 5| Step: 10
Training loss: 2.901167989522526
Validation loss: 2.520968298747015

Epoch: 78| Step: 0
Training loss: 3.3010028471288737
Validation loss: 2.4770016694739474

Epoch: 5| Step: 1
Training loss: 2.333042864657934
Validation loss: 2.519561626470293

Epoch: 5| Step: 2
Training loss: 2.712392103448829
Validation loss: 2.514987504788988

Epoch: 5| Step: 3
Training loss: 2.7601925357060657
Validation loss: 2.4981118619436864

Epoch: 5| Step: 4
Training loss: 2.4885681082809894
Validation loss: 2.495096642778643

Epoch: 5| Step: 5
Training loss: 2.4902114926951144
Validation loss: 2.4798583853536575

Epoch: 5| Step: 6
Training loss: 2.5230950752092007
Validation loss: 2.513539142429822

Epoch: 5| Step: 7
Training loss: 3.0628658776778903
Validation loss: 2.527237697276309

Epoch: 5| Step: 8
Training loss: 3.206169951333824
Validation loss: 2.4829651303249816

Epoch: 5| Step: 9
Training loss: 2.294956054432974
Validation loss: 2.520641493169425

Epoch: 5| Step: 10
Training loss: 3.2660217044200235
Validation loss: 2.4910850754717995

Epoch: 79| Step: 0
Training loss: 2.691382686251619
Validation loss: 2.513880562094774

Epoch: 5| Step: 1
Training loss: 2.4810440477660944
Validation loss: 2.5017902383716875

Epoch: 5| Step: 2
Training loss: 2.435011742972819
Validation loss: 2.49388611873044

Epoch: 5| Step: 3
Training loss: 2.806011514364098
Validation loss: 2.504762573848905

Epoch: 5| Step: 4
Training loss: 2.9539051135610084
Validation loss: 2.503875538212724

Epoch: 5| Step: 5
Training loss: 2.336194078522153
Validation loss: 2.507295245623172

Epoch: 5| Step: 6
Training loss: 2.54241168458605
Validation loss: 2.4986659212861966

Epoch: 5| Step: 7
Training loss: 3.1086427986242606
Validation loss: 2.4910273881701857

Epoch: 5| Step: 8
Training loss: 2.861059141047129
Validation loss: 2.5015848509675633

Epoch: 5| Step: 9
Training loss: 2.766964517975934
Validation loss: 2.4927520138320194

Epoch: 5| Step: 10
Training loss: 3.437960507151074
Validation loss: 2.498753376316386

Epoch: 80| Step: 0
Training loss: 3.3880813831701824
Validation loss: 2.501260472502703

Epoch: 5| Step: 1
Training loss: 2.770913364334971
Validation loss: 2.4996221749073797

Epoch: 5| Step: 2
Training loss: 2.340911876175142
Validation loss: 2.511961223391444

Epoch: 5| Step: 3
Training loss: 2.9390438162388755
Validation loss: 2.490552795757647

Epoch: 5| Step: 4
Training loss: 2.9389484162322286
Validation loss: 2.5191847864193475

Epoch: 5| Step: 5
Training loss: 3.258791988967071
Validation loss: 2.4862558215012247

Epoch: 5| Step: 6
Training loss: 2.3870719485999934
Validation loss: 2.5039226705563586

Epoch: 5| Step: 7
Training loss: 2.5766224499651296
Validation loss: 2.5277571659479077

Epoch: 5| Step: 8
Training loss: 2.8169313065695083
Validation loss: 2.4984883178270243

Epoch: 5| Step: 9
Training loss: 2.0479904513359988
Validation loss: 2.4787261218505545

Epoch: 5| Step: 10
Training loss: 2.8178000632048947
Validation loss: 2.5060661373269286

Epoch: 81| Step: 0
Training loss: 2.398601613347753
Validation loss: 2.4927985090756635

Epoch: 5| Step: 1
Training loss: 2.4100555448343948
Validation loss: 2.4918383384820904

Epoch: 5| Step: 2
Training loss: 3.223936476296988
Validation loss: 2.494396112507003

Epoch: 5| Step: 3
Training loss: 2.722596877995492
Validation loss: 2.5035919984882082

Epoch: 5| Step: 4
Training loss: 2.4867290164640905
Validation loss: 2.493342017450433

Epoch: 5| Step: 5
Training loss: 2.838811757714792
Validation loss: 2.515166778808141

Epoch: 5| Step: 6
Training loss: 2.888751108193278
Validation loss: 2.4896060477293354

Epoch: 5| Step: 7
Training loss: 2.8881467350907792
Validation loss: 2.5269126369070385

Epoch: 5| Step: 8
Training loss: 2.9797778447441883
Validation loss: 2.4930441162743926

Epoch: 5| Step: 9
Training loss: 3.3508200367705876
Validation loss: 2.484733444754968

Epoch: 5| Step: 10
Training loss: 1.9982774588393608
Validation loss: 2.5114846704573464

Epoch: 82| Step: 0
Training loss: 2.615527272649044
Validation loss: 2.5039708760107753

Epoch: 5| Step: 1
Training loss: 2.845268766181262
Validation loss: 2.5237502576019115

Epoch: 5| Step: 2
Training loss: 2.223588208407494
Validation loss: 2.5252465411929776

Epoch: 5| Step: 3
Training loss: 3.2779623364000723
Validation loss: 2.512199124098846

Epoch: 5| Step: 4
Training loss: 3.5483564736283797
Validation loss: 2.5013189425673796

Epoch: 5| Step: 5
Training loss: 2.6031646835398075
Validation loss: 2.4970481201324284

Epoch: 5| Step: 6
Training loss: 2.2076605245735257
Validation loss: 2.499453975156163

Epoch: 5| Step: 7
Training loss: 2.6161670118676246
Validation loss: 2.4924195763686523

Epoch: 5| Step: 8
Training loss: 3.0260594554034657
Validation loss: 2.494288125478183

Epoch: 5| Step: 9
Training loss: 2.692802255395635
Validation loss: 2.4941625811343213

Epoch: 5| Step: 10
Training loss: 2.549476558591751
Validation loss: 2.501043469049956

Epoch: 83| Step: 0
Training loss: 3.322947742153421
Validation loss: 2.5040902302499926

Epoch: 5| Step: 1
Training loss: 3.053692043283809
Validation loss: 2.5151626160953113

Epoch: 5| Step: 2
Training loss: 2.268590630432544
Validation loss: 2.4929617281798566

Epoch: 5| Step: 3
Training loss: 3.0164273632528866
Validation loss: 2.502758163817737

Epoch: 5| Step: 4
Training loss: 2.9326510076513066
Validation loss: 2.5077283562289665

Epoch: 5| Step: 5
Training loss: 2.786701645730467
Validation loss: 2.4837058955290687

Epoch: 5| Step: 6
Training loss: 2.5402220909763726
Validation loss: 2.512946240729634

Epoch: 5| Step: 7
Training loss: 2.351848800314556
Validation loss: 2.5054369533409053

Epoch: 5| Step: 8
Training loss: 2.949744009775351
Validation loss: 2.4998828183675257

Epoch: 5| Step: 9
Training loss: 2.5179581336857817
Validation loss: 2.5090229766481187

Epoch: 5| Step: 10
Training loss: 2.665164037383232
Validation loss: 2.5081685581144852

Epoch: 84| Step: 0
Training loss: 2.830255032967125
Validation loss: 2.4761112208663256

Epoch: 5| Step: 1
Training loss: 2.707542206073334
Validation loss: 2.5120172155026905

Epoch: 5| Step: 2
Training loss: 2.9313753276133596
Validation loss: 2.5272834596804605

Epoch: 5| Step: 3
Training loss: 2.4479645311802924
Validation loss: 2.4936547447983406

Epoch: 5| Step: 4
Training loss: 2.751335253367375
Validation loss: 2.4945034679545057

Epoch: 5| Step: 5
Training loss: 2.3848275091466404
Validation loss: 2.5154482372328135

Epoch: 5| Step: 6
Training loss: 2.8324144406708394
Validation loss: 2.4987514372363924

Epoch: 5| Step: 7
Training loss: 3.3376424751874327
Validation loss: 2.521815844219149

Epoch: 5| Step: 8
Training loss: 3.0261095644522418
Validation loss: 2.5239016873846403

Epoch: 5| Step: 9
Training loss: 2.4460380867077185
Validation loss: 2.50903581973437

Epoch: 5| Step: 10
Training loss: 2.453015173136161
Validation loss: 2.484087166261976

Epoch: 85| Step: 0
Training loss: 2.879853174387589
Validation loss: 2.47965682421753

Epoch: 5| Step: 1
Training loss: 2.941111353546057
Validation loss: 2.507931889145009

Epoch: 5| Step: 2
Training loss: 2.708709944924865
Validation loss: 2.5232762105778415

Epoch: 5| Step: 3
Training loss: 2.737262008285278
Validation loss: 2.5055959149005287

Epoch: 5| Step: 4
Training loss: 2.525978155746907
Validation loss: 2.497094260241646

Epoch: 5| Step: 5
Training loss: 2.779738626336928
Validation loss: 2.5113238613339823

Epoch: 5| Step: 6
Training loss: 3.1443236477957233
Validation loss: 2.49452199143537

Epoch: 5| Step: 7
Training loss: 2.824869547844875
Validation loss: 2.5009925697207986

Epoch: 5| Step: 8
Training loss: 2.5824122068506625
Validation loss: 2.4959268449471756

Epoch: 5| Step: 9
Training loss: 2.0990259681829095
Validation loss: 2.473868032123238

Epoch: 5| Step: 10
Training loss: 2.959031430112653
Validation loss: 2.5068787328956486

Epoch: 86| Step: 0
Training loss: 2.70892804781022
Validation loss: 2.479409652043421

Epoch: 5| Step: 1
Training loss: 3.3471511228264084
Validation loss: 2.508021364921349

Epoch: 5| Step: 2
Training loss: 2.7793483447887004
Validation loss: 2.48861511641559

Epoch: 5| Step: 3
Training loss: 2.6841954163420314
Validation loss: 2.5033988705414707

Epoch: 5| Step: 4
Training loss: 2.044668857839874
Validation loss: 2.5206922113478694

Epoch: 5| Step: 5
Training loss: 2.6503349416417095
Validation loss: 2.4897077291389342

Epoch: 5| Step: 6
Training loss: 3.198671100771864
Validation loss: 2.520659956787425

Epoch: 5| Step: 7
Training loss: 2.541423650494967
Validation loss: 2.5036821229052317

Epoch: 5| Step: 8
Training loss: 2.969647723540405
Validation loss: 2.494450884321201

Epoch: 5| Step: 9
Training loss: 2.5041748474122874
Validation loss: 2.5205435759648327

Epoch: 5| Step: 10
Training loss: 2.7149212064602533
Validation loss: 2.497535618933478

Epoch: 87| Step: 0
Training loss: 3.4535127309893427
Validation loss: 2.49156162538395

Epoch: 5| Step: 1
Training loss: 2.559220797745628
Validation loss: 2.5052509772829143

Epoch: 5| Step: 2
Training loss: 2.5665321261165674
Validation loss: 2.478551758550356

Epoch: 5| Step: 3
Training loss: 2.6645776692425436
Validation loss: 2.4989909509629413

Epoch: 5| Step: 4
Training loss: 2.493498645629882
Validation loss: 2.4943829838657683

Epoch: 5| Step: 5
Training loss: 2.807262630465827
Validation loss: 2.479735812628481

Epoch: 5| Step: 6
Training loss: 2.797027498488534
Validation loss: 2.5111059424538644

Epoch: 5| Step: 7
Training loss: 2.52304159076171
Validation loss: 2.4838682620008883

Epoch: 5| Step: 8
Training loss: 2.8133611420376416
Validation loss: 2.500094923657895

Epoch: 5| Step: 9
Training loss: 2.890281698100128
Validation loss: 2.5002109633413516

Epoch: 5| Step: 10
Training loss: 2.571985784209552
Validation loss: 2.5058431236636505

Epoch: 88| Step: 0
Training loss: 2.7075142917977932
Validation loss: 2.519675550742789

Epoch: 5| Step: 1
Training loss: 2.8495528154727974
Validation loss: 2.462729040712452

Epoch: 5| Step: 2
Training loss: 2.6805268243843217
Validation loss: 2.4890376635290288

Epoch: 5| Step: 3
Training loss: 3.3859154123554926
Validation loss: 2.4805950943616373

Epoch: 5| Step: 4
Training loss: 3.155733576157297
Validation loss: 2.5052588864095346

Epoch: 5| Step: 5
Training loss: 2.1122505085804892
Validation loss: 2.495853303430216

Epoch: 5| Step: 6
Training loss: 3.2159201024127664
Validation loss: 2.5108288471808664

Epoch: 5| Step: 7
Training loss: 2.8236068125942935
Validation loss: 2.490805922758383

Epoch: 5| Step: 8
Training loss: 1.825229536279594
Validation loss: 2.494606802638214

Epoch: 5| Step: 9
Training loss: 2.503175816395174
Validation loss: 2.520033254213558

Epoch: 5| Step: 10
Training loss: 2.7560988335016754
Validation loss: 2.492968161537794

Epoch: 89| Step: 0
Training loss: 2.941882820580945
Validation loss: 2.4870221082376145

Epoch: 5| Step: 1
Training loss: 2.8132809720281555
Validation loss: 2.4966580459836036

Epoch: 5| Step: 2
Training loss: 2.849366060658377
Validation loss: 2.5020508404113126

Epoch: 5| Step: 3
Training loss: 2.3055159809234587
Validation loss: 2.517802906941076

Epoch: 5| Step: 4
Training loss: 2.8163287910042225
Validation loss: 2.515116328384501

Epoch: 5| Step: 5
Training loss: 2.78419938309633
Validation loss: 2.510809974324737

Epoch: 5| Step: 6
Training loss: 3.5349126405186637
Validation loss: 2.492976261827557

Epoch: 5| Step: 7
Training loss: 2.3070316096382104
Validation loss: 2.5141208416426566

Epoch: 5| Step: 8
Training loss: 2.300780420999426
Validation loss: 2.4909640997919293

Epoch: 5| Step: 9
Training loss: 2.4241851617451364
Validation loss: 2.498010757640466

Epoch: 5| Step: 10
Training loss: 2.9998281747566753
Validation loss: 2.500615226251899

Epoch: 90| Step: 0
Training loss: 2.5766656617840793
Validation loss: 2.484621670994705

Epoch: 5| Step: 1
Training loss: 2.480992828032811
Validation loss: 2.5099058694057494

Epoch: 5| Step: 2
Training loss: 3.550324900628732
Validation loss: 2.4837166137010422

Epoch: 5| Step: 3
Training loss: 2.472069934435955
Validation loss: 2.506015127741063

Epoch: 5| Step: 4
Training loss: 2.9554452006293976
Validation loss: 2.4957382568063116

Epoch: 5| Step: 5
Training loss: 2.806024004495712
Validation loss: 2.5092069761028397

Epoch: 5| Step: 6
Training loss: 2.986263296896902
Validation loss: 2.479725516632447

Epoch: 5| Step: 7
Training loss: 2.4936569808399955
Validation loss: 2.4936463886672278

Epoch: 5| Step: 8
Training loss: 1.757761975727891
Validation loss: 2.500445853233255

Epoch: 5| Step: 9
Training loss: 3.1433541505622515
Validation loss: 2.5028645378278713

Epoch: 5| Step: 10
Training loss: 2.52409207856517
Validation loss: 2.493442992334667

Epoch: 91| Step: 0
Training loss: 2.6111279841028923
Validation loss: 2.4811550620739773

Epoch: 5| Step: 1
Training loss: 2.243547831063509
Validation loss: 2.495414228899022

Epoch: 5| Step: 2
Training loss: 2.4157209409386975
Validation loss: 2.50198769767052

Epoch: 5| Step: 3
Training loss: 3.131522885917006
Validation loss: 2.502365428892674

Epoch: 5| Step: 4
Training loss: 2.883475044016815
Validation loss: 2.510609561448598

Epoch: 5| Step: 5
Training loss: 2.3988323073109203
Validation loss: 2.4895739660517187

Epoch: 5| Step: 6
Training loss: 2.9581006634692617
Validation loss: 2.488600131844972

Epoch: 5| Step: 7
Training loss: 3.3570883842153445
Validation loss: 2.4950702391906314

Epoch: 5| Step: 8
Training loss: 3.1560146130705795
Validation loss: 2.4866111589182665

Epoch: 5| Step: 9
Training loss: 2.176175039053188
Validation loss: 2.493810854755854

Epoch: 5| Step: 10
Training loss: 2.7836016881563506
Validation loss: 2.5181996041694075

Epoch: 92| Step: 0
Training loss: 2.7474918198051546
Validation loss: 2.4888781547986345

Epoch: 5| Step: 1
Training loss: 3.1834092162776138
Validation loss: 2.5162911765807316

Epoch: 5| Step: 2
Training loss: 3.016235605988856
Validation loss: 2.4930526492375473

Epoch: 5| Step: 3
Training loss: 2.9107001903570437
Validation loss: 2.5036542846725727

Epoch: 5| Step: 4
Training loss: 2.8274734336623584
Validation loss: 2.5112609992224377

Epoch: 5| Step: 5
Training loss: 3.230387270359996
Validation loss: 2.501380198968841

Epoch: 5| Step: 6
Training loss: 3.0415841357038653
Validation loss: 2.4909877357373493

Epoch: 5| Step: 7
Training loss: 2.075443918932122
Validation loss: 2.490764830984807

Epoch: 5| Step: 8
Training loss: 2.5059258800788533
Validation loss: 2.527925171022487

Epoch: 5| Step: 9
Training loss: 2.338591531902991
Validation loss: 2.5278070375189277

Epoch: 5| Step: 10
Training loss: 2.1419201573469584
Validation loss: 2.4938752211944415

Epoch: 93| Step: 0
Training loss: 2.5947873902001675
Validation loss: 2.500313232651769

Epoch: 5| Step: 1
Training loss: 2.2040085339805033
Validation loss: 2.484197877397782

Epoch: 5| Step: 2
Training loss: 2.865924109902972
Validation loss: 2.4789069406681215

Epoch: 5| Step: 3
Training loss: 2.412710953418348
Validation loss: 2.5175883109978625

Epoch: 5| Step: 4
Training loss: 3.4248479879017077
Validation loss: 2.5225724137160923

Epoch: 5| Step: 5
Training loss: 2.6331164809966796
Validation loss: 2.48150571852336

Epoch: 5| Step: 6
Training loss: 3.1146753269928675
Validation loss: 2.5018424207937855

Epoch: 5| Step: 7
Training loss: 2.5620141848157325
Validation loss: 2.5130146760826335

Epoch: 5| Step: 8
Training loss: 2.8690658362231787
Validation loss: 2.5206097383592616

Epoch: 5| Step: 9
Training loss: 2.2914472532716887
Validation loss: 2.5156941308522747

Epoch: 5| Step: 10
Training loss: 3.298236872987887
Validation loss: 2.530274002858389

Epoch: 94| Step: 0
Training loss: 3.2971855125822573
Validation loss: 2.503378351287213

Epoch: 5| Step: 1
Training loss: 2.883553758549055
Validation loss: 2.4987273063372566

Epoch: 5| Step: 2
Training loss: 2.6671967178301648
Validation loss: 2.525581903780265

Epoch: 5| Step: 3
Training loss: 2.9603870051215893
Validation loss: 2.498129981018176

Epoch: 5| Step: 4
Training loss: 2.667709494375393
Validation loss: 2.52012131460335

Epoch: 5| Step: 5
Training loss: 2.4427266936977947
Validation loss: 2.503557834019788

Epoch: 5| Step: 6
Training loss: 2.7541057108617966
Validation loss: 2.488164788928397

Epoch: 5| Step: 7
Training loss: 2.8354624620972153
Validation loss: 2.4577852451226203

Epoch: 5| Step: 8
Training loss: 2.24154643288213
Validation loss: 2.5172805194639305

Epoch: 5| Step: 9
Training loss: 3.005557634404236
Validation loss: 2.4775869731637656

Epoch: 5| Step: 10
Training loss: 2.2986597924841448
Validation loss: 2.494845425171313

Epoch: 95| Step: 0
Training loss: 1.9290227942101346
Validation loss: 2.510515243670614

Epoch: 5| Step: 1
Training loss: 2.9043487564717068
Validation loss: 2.4918427716419393

Epoch: 5| Step: 2
Training loss: 2.3281714927588184
Validation loss: 2.529842536877322

Epoch: 5| Step: 3
Training loss: 3.089062617315928
Validation loss: 2.482795192912425

Epoch: 5| Step: 4
Training loss: 3.180494501304341
Validation loss: 2.5207914794549806

Epoch: 5| Step: 5
Training loss: 2.9520413464180875
Validation loss: 2.516137371241358

Epoch: 5| Step: 6
Training loss: 3.2025793587755746
Validation loss: 2.4987724797647752

Epoch: 5| Step: 7
Training loss: 2.908742512626503
Validation loss: 2.4921597123593977

Epoch: 5| Step: 8
Training loss: 2.905698170108851
Validation loss: 2.5193028866642058

Epoch: 5| Step: 9
Training loss: 2.1950081719526615
Validation loss: 2.479726371618382

Epoch: 5| Step: 10
Training loss: 2.351201533497936
Validation loss: 2.509910182812572

Epoch: 96| Step: 0
Training loss: 3.1258742063354066
Validation loss: 2.5327796987910545

Epoch: 5| Step: 1
Training loss: 3.1622289548980795
Validation loss: 2.4851166478572684

Epoch: 5| Step: 2
Training loss: 2.2327795134364115
Validation loss: 2.4977024349576937

Epoch: 5| Step: 3
Training loss: 3.2086580450704485
Validation loss: 2.507087736451085

Epoch: 5| Step: 4
Training loss: 2.5666782461458393
Validation loss: 2.4959096753877605

Epoch: 5| Step: 5
Training loss: 2.497458692176593
Validation loss: 2.513336235978338

Epoch: 5| Step: 6
Training loss: 2.317000057281375
Validation loss: 2.485179049450705

Epoch: 5| Step: 7
Training loss: 3.0578872819663294
Validation loss: 2.50998260771795

Epoch: 5| Step: 8
Training loss: 2.5571752911494996
Validation loss: 2.491545497894684

Epoch: 5| Step: 9
Training loss: 2.439699403350941
Validation loss: 2.4955993775926077

Epoch: 5| Step: 10
Training loss: 2.8246787133276965
Validation loss: 2.521582543392055

Epoch: 97| Step: 0
Training loss: 2.150177961569334
Validation loss: 2.4912931715116464

Epoch: 5| Step: 1
Training loss: 2.4762097417340465
Validation loss: 2.506422350960748

Epoch: 5| Step: 2
Training loss: 2.887111528695415
Validation loss: 2.482603655549167

Epoch: 5| Step: 3
Training loss: 2.812264241827755
Validation loss: 2.5171925542173716

Epoch: 5| Step: 4
Training loss: 2.697495436218191
Validation loss: 2.507737994417012

Epoch: 5| Step: 5
Training loss: 2.6281249201680463
Validation loss: 2.5270191466057392

Epoch: 5| Step: 6
Training loss: 2.498573373006899
Validation loss: 2.4829653827691645

Epoch: 5| Step: 7
Training loss: 2.8004371506174004
Validation loss: 2.5133743403894697

Epoch: 5| Step: 8
Training loss: 2.8891318924091784
Validation loss: 2.5060410646189344

Epoch: 5| Step: 9
Training loss: 2.8517820508909324
Validation loss: 2.501213489860125

Epoch: 5| Step: 10
Training loss: 3.444585814360722
Validation loss: 2.4882300422123014

Epoch: 98| Step: 0
Training loss: 3.130045060878498
Validation loss: 2.4981265852410575

Epoch: 5| Step: 1
Training loss: 3.0725291551986773
Validation loss: 2.513448243368598

Epoch: 5| Step: 2
Training loss: 2.626557660027469
Validation loss: 2.5051899106988174

Epoch: 5| Step: 3
Training loss: 2.997046606343602
Validation loss: 2.4990533882408963

Epoch: 5| Step: 4
Training loss: 2.785838681542134
Validation loss: 2.5167741840422684

Epoch: 5| Step: 5
Training loss: 2.7920471805094764
Validation loss: 2.512107882131699

Epoch: 5| Step: 6
Training loss: 2.738608086381375
Validation loss: 2.49716796745646

Epoch: 5| Step: 7
Training loss: 1.9568615381051326
Validation loss: 2.5009569879570432

Epoch: 5| Step: 8
Training loss: 2.694001606035214
Validation loss: 2.525997725166833

Epoch: 5| Step: 9
Training loss: 2.8692039446403843
Validation loss: 2.507904671553393

Epoch: 5| Step: 10
Training loss: 2.4437720958754707
Validation loss: 2.504597552562885

Epoch: 99| Step: 0
Training loss: 2.155071655285852
Validation loss: 2.52740645503205

Epoch: 5| Step: 1
Training loss: 2.758402904389926
Validation loss: 2.5078426994729073

Epoch: 5| Step: 2
Training loss: 2.5561949222665588
Validation loss: 2.5240225810040036

Epoch: 5| Step: 3
Training loss: 2.53031018553255
Validation loss: 2.5175160086650146

Epoch: 5| Step: 4
Training loss: 3.25648628885858
Validation loss: 2.471298419599358

Epoch: 5| Step: 5
Training loss: 2.88026311361266
Validation loss: 2.493268339026058

Epoch: 5| Step: 6
Training loss: 2.5954990234961057
Validation loss: 2.5121212993003983

Epoch: 5| Step: 7
Training loss: 2.1903697127670427
Validation loss: 2.5272320399375308

Epoch: 5| Step: 8
Training loss: 3.194761793065128
Validation loss: 2.5227013204963944

Epoch: 5| Step: 9
Training loss: 3.1888427897926697
Validation loss: 2.5273542628225183

Epoch: 5| Step: 10
Training loss: 2.677795097836751
Validation loss: 2.5360705193385527

Epoch: 100| Step: 0
Training loss: 2.725240742259569
Validation loss: 2.5383408624498345

Epoch: 5| Step: 1
Training loss: 2.5283950906586083
Validation loss: 2.5150477157744215

Epoch: 5| Step: 2
Training loss: 2.9376853722053586
Validation loss: 2.500927743739068

Epoch: 5| Step: 3
Training loss: 2.546089753402097
Validation loss: 2.521048991627008

Epoch: 5| Step: 4
Training loss: 2.551019490961961
Validation loss: 2.53203174587402

Epoch: 5| Step: 5
Training loss: 2.061175065306513
Validation loss: 2.501647707714746

Epoch: 5| Step: 6
Training loss: 3.1592909261231052
Validation loss: 2.4925193507818038

Epoch: 5| Step: 7
Training loss: 3.181785997005032
Validation loss: 2.5154273382803023

Epoch: 5| Step: 8
Training loss: 2.4874954300268164
Validation loss: 2.4851158669376816

Epoch: 5| Step: 9
Training loss: 3.2230879800773877
Validation loss: 2.486508033236111

Epoch: 5| Step: 10
Training loss: 2.325243196791435
Validation loss: 2.502168802663595

Epoch: 101| Step: 0
Training loss: 2.2604449808014504
Validation loss: 2.4912937467450096

Epoch: 5| Step: 1
Training loss: 3.044576863922879
Validation loss: 2.502915949117181

Epoch: 5| Step: 2
Training loss: 2.442206704716456
Validation loss: 2.503120440732847

Epoch: 5| Step: 3
Training loss: 3.0063219216481176
Validation loss: 2.5183303874934526

Epoch: 5| Step: 4
Training loss: 2.1787213334229225
Validation loss: 2.4923625736294017

Epoch: 5| Step: 5
Training loss: 2.9298068009563663
Validation loss: 2.4985226449870397

Epoch: 5| Step: 6
Training loss: 2.696150408989281
Validation loss: 2.5067574297367052

Epoch: 5| Step: 7
Training loss: 3.4227451280705896
Validation loss: 2.4922965264386505

Epoch: 5| Step: 8
Training loss: 2.911200460206551
Validation loss: 2.5217475175864124

Epoch: 5| Step: 9
Training loss: 2.720340658060758
Validation loss: 2.49506623097876

Epoch: 5| Step: 10
Training loss: 2.284395531432935
Validation loss: 2.4854971431430974

Epoch: 102| Step: 0
Training loss: 2.5566425833465094
Validation loss: 2.5051664916398795

Epoch: 5| Step: 1
Training loss: 2.864407139763672
Validation loss: 2.481547812810949

Epoch: 5| Step: 2
Training loss: 2.7157751886870685
Validation loss: 2.4979013042686904

Epoch: 5| Step: 3
Training loss: 3.2304451329245536
Validation loss: 2.490919269508214

Epoch: 5| Step: 4
Training loss: 2.4051985982634827
Validation loss: 2.522963503952244

Epoch: 5| Step: 5
Training loss: 3.4033602434440104
Validation loss: 2.489699075048771

Epoch: 5| Step: 6
Training loss: 2.311157042809051
Validation loss: 2.4951119803119917

Epoch: 5| Step: 7
Training loss: 2.3940494917722934
Validation loss: 2.505908315592738

Epoch: 5| Step: 8
Training loss: 2.7565461187824094
Validation loss: 2.493234952339408

Epoch: 5| Step: 9
Training loss: 2.544296269727288
Validation loss: 2.5175555900007427

Epoch: 5| Step: 10
Training loss: 2.846988552605112
Validation loss: 2.5074922591465665

Epoch: 103| Step: 0
Training loss: 3.024259076136621
Validation loss: 2.50387653699677

Epoch: 5| Step: 1
Training loss: 2.7192728701758426
Validation loss: 2.496753536164718

Epoch: 5| Step: 2
Training loss: 3.0027945536159457
Validation loss: 2.509829457651023

Epoch: 5| Step: 3
Training loss: 3.034454068097595
Validation loss: 2.470057939443803

Epoch: 5| Step: 4
Training loss: 2.703664736803216
Validation loss: 2.532314010570607

Epoch: 5| Step: 5
Training loss: 2.537463156897756
Validation loss: 2.5125604019736785

Epoch: 5| Step: 6
Training loss: 2.4895669678558487
Validation loss: 2.5069395614878105

Epoch: 5| Step: 7
Training loss: 3.0195922055821867
Validation loss: 2.5194616312105254

Epoch: 5| Step: 8
Training loss: 2.1152472244675504
Validation loss: 2.5163337322137407

Epoch: 5| Step: 9
Training loss: 2.7871772955656238
Validation loss: 2.5307805314555782

Epoch: 5| Step: 10
Training loss: 2.5482363192859925
Validation loss: 2.515400514425155

Epoch: 104| Step: 0
Training loss: 3.278838661266176
Validation loss: 2.497781552686921

Epoch: 5| Step: 1
Training loss: 2.4547917237667995
Validation loss: 2.5009562365851172

Epoch: 5| Step: 2
Training loss: 2.880448196292278
Validation loss: 2.516628306066005

Epoch: 5| Step: 3
Training loss: 3.259782739666351
Validation loss: 2.513682881507827

Epoch: 5| Step: 4
Training loss: 2.1780092621843665
Validation loss: 2.4920716895448174

Epoch: 5| Step: 5
Training loss: 2.8720550381054224
Validation loss: 2.4940036489348802

Epoch: 5| Step: 6
Training loss: 2.133933083848121
Validation loss: 2.4964498415816974

Epoch: 5| Step: 7
Training loss: 2.049033853767848
Validation loss: 2.498726744100944

Epoch: 5| Step: 8
Training loss: 3.1145075317820865
Validation loss: 2.5346492779501077

Epoch: 5| Step: 9
Training loss: 2.7139801627820734
Validation loss: 2.511419248649175

Epoch: 5| Step: 10
Training loss: 2.7169254363059974
Validation loss: 2.5049135554338733

Epoch: 105| Step: 0
Training loss: 3.0236284851157587
Validation loss: 2.5032401704109155

Epoch: 5| Step: 1
Training loss: 2.3620563958498733
Validation loss: 2.495142943809996

Epoch: 5| Step: 2
Training loss: 2.451395579308832
Validation loss: 2.51024696723864

Epoch: 5| Step: 3
Training loss: 2.65905326573567
Validation loss: 2.49581555193387

Epoch: 5| Step: 4
Training loss: 2.280063477351978
Validation loss: 2.4935319270023557

Epoch: 5| Step: 5
Training loss: 3.004916930105712
Validation loss: 2.496920226816133

Epoch: 5| Step: 6
Training loss: 2.957061888360925
Validation loss: 2.5068840818213314

Epoch: 5| Step: 7
Training loss: 3.3603348181434027
Validation loss: 2.5160995628884817

Epoch: 5| Step: 8
Training loss: 2.9508836101768816
Validation loss: 2.50357787769533

Epoch: 5| Step: 9
Training loss: 2.2208590087933264
Validation loss: 2.5222643379883887

Epoch: 5| Step: 10
Training loss: 2.627554331906452
Validation loss: 2.504391086130477

Epoch: 106| Step: 0
Training loss: 3.1118565150821116
Validation loss: 2.5251857008013188

Epoch: 5| Step: 1
Training loss: 2.612905341283868
Validation loss: 2.5198907156786174

Epoch: 5| Step: 2
Training loss: 2.4267000433264845
Validation loss: 2.519594304118607

Epoch: 5| Step: 3
Training loss: 2.9865704993819113
Validation loss: 2.5022463940004354

Epoch: 5| Step: 4
Training loss: 2.2119905909084645
Validation loss: 2.5024009885807934

Epoch: 5| Step: 5
Training loss: 2.8516833972124274
Validation loss: 2.481639071468638

Epoch: 5| Step: 6
Training loss: 2.3107058808150067
Validation loss: 2.5036803166600734

Epoch: 5| Step: 7
Training loss: 3.2514395826681466
Validation loss: 2.4738798478548536

Epoch: 5| Step: 8
Training loss: 2.508016607707156
Validation loss: 2.484988323073725

Epoch: 5| Step: 9
Training loss: 3.0433991780283653
Validation loss: 2.52620399561602

Epoch: 5| Step: 10
Training loss: 2.638240663206651
Validation loss: 2.529257400881861

Epoch: 107| Step: 0
Training loss: 2.8519467447666957
Validation loss: 2.5049371411188943

Epoch: 5| Step: 1
Training loss: 2.2588305438595437
Validation loss: 2.48900889571261

Epoch: 5| Step: 2
Training loss: 3.2179182144497855
Validation loss: 2.4925043043140427

Epoch: 5| Step: 3
Training loss: 2.389172181130964
Validation loss: 2.5059739375368535

Epoch: 5| Step: 4
Training loss: 2.269283524090262
Validation loss: 2.483036156471135

Epoch: 5| Step: 5
Training loss: 2.735762587380213
Validation loss: 2.514517311271879

Epoch: 5| Step: 6
Training loss: 3.3432244574129393
Validation loss: 2.516229882774922

Epoch: 5| Step: 7
Training loss: 2.3088435572001744
Validation loss: 2.4826591470411374

Epoch: 5| Step: 8
Training loss: 2.8718923275562855
Validation loss: 2.519467425048706

Epoch: 5| Step: 9
Training loss: 2.584465599086459
Validation loss: 2.5255341950729178

Epoch: 5| Step: 10
Training loss: 3.388529609090369
Validation loss: 2.4801659090812294

Epoch: 108| Step: 0
Training loss: 2.6292107733056147
Validation loss: 2.490823038984459

Epoch: 5| Step: 1
Training loss: 2.7934021086712093
Validation loss: 2.5226381092839922

Epoch: 5| Step: 2
Training loss: 2.6883957722888745
Validation loss: 2.49979627353419

Epoch: 5| Step: 3
Training loss: 2.6356321907623816
Validation loss: 2.4981986991025398

Epoch: 5| Step: 4
Training loss: 2.609004833896848
Validation loss: 2.519419171148208

Epoch: 5| Step: 5
Training loss: 2.9857543633640007
Validation loss: 2.5090263091438585

Epoch: 5| Step: 6
Training loss: 2.8747956576498073
Validation loss: 2.5235928809832555

Epoch: 5| Step: 7
Training loss: 1.9740566608293681
Validation loss: 2.497742722867598

Epoch: 5| Step: 8
Training loss: 2.8424847481485336
Validation loss: 2.509608180462054

Epoch: 5| Step: 9
Training loss: 2.8669030986545736
Validation loss: 2.5067647685633716

Epoch: 5| Step: 10
Training loss: 3.0317107174947866
Validation loss: 2.5060787500537858

Epoch: 109| Step: 0
Training loss: 3.7849448571163005
Validation loss: 2.5208625900237287

Epoch: 5| Step: 1
Training loss: 2.5110336959443553
Validation loss: 2.4846047648414618

Epoch: 5| Step: 2
Training loss: 2.721328126822311
Validation loss: 2.498507750617977

Epoch: 5| Step: 3
Training loss: 2.6979766505187524
Validation loss: 2.5176334433418943

Epoch: 5| Step: 4
Training loss: 2.2482961985370613
Validation loss: 2.5335750700353463

Epoch: 5| Step: 5
Training loss: 2.9591239266803524
Validation loss: 2.5061852398772793

Epoch: 5| Step: 6
Training loss: 2.903987372914755
Validation loss: 2.524647548464282

Epoch: 5| Step: 7
Training loss: 2.34741270607848
Validation loss: 2.5187648743746216

Epoch: 5| Step: 8
Training loss: 2.4902837770835022
Validation loss: 2.511974864337561

Epoch: 5| Step: 9
Training loss: 2.8071822013579903
Validation loss: 2.485868793651673

Epoch: 5| Step: 10
Training loss: 2.2728762638499935
Validation loss: 2.530943839495671

Epoch: 110| Step: 0
Training loss: 2.215731649697056
Validation loss: 2.4988767643716323

Epoch: 5| Step: 1
Training loss: 3.149120474445721
Validation loss: 2.481925807064935

Epoch: 5| Step: 2
Training loss: 2.8148373534134925
Validation loss: 2.5053650304282806

Epoch: 5| Step: 3
Training loss: 2.8469192116211444
Validation loss: 2.4975737950431935

Epoch: 5| Step: 4
Training loss: 2.927670692529972
Validation loss: 2.5170920223074957

Epoch: 5| Step: 5
Training loss: 2.6631635564355443
Validation loss: 2.508990046876907

Epoch: 5| Step: 6
Training loss: 3.0629474546562747
Validation loss: 2.4861780002453417

Epoch: 5| Step: 7
Training loss: 2.7829870735770186
Validation loss: 2.5212744646608276

Epoch: 5| Step: 8
Training loss: 2.3816210159863473
Validation loss: 2.505686281852993

Epoch: 5| Step: 9
Training loss: 2.296795071618969
Validation loss: 2.5398455415897296

Epoch: 5| Step: 10
Training loss: 2.525339549433957
Validation loss: 2.5061663944510713

Epoch: 111| Step: 0
Training loss: 2.400325764958495
Validation loss: 2.524994342764722

Epoch: 5| Step: 1
Training loss: 2.76392187059448
Validation loss: 2.5101635178565824

Epoch: 5| Step: 2
Training loss: 3.100391387843235
Validation loss: 2.516599987602439

Epoch: 5| Step: 3
Training loss: 3.401396346863957
Validation loss: 2.483945838770396

Epoch: 5| Step: 4
Training loss: 2.7987610834881047
Validation loss: 2.523027380684721

Epoch: 5| Step: 5
Training loss: 2.6121643142775604
Validation loss: 2.493895941994414

Epoch: 5| Step: 6
Training loss: 2.1478848943077833
Validation loss: 2.4922089898700874

Epoch: 5| Step: 7
Training loss: 2.712702459699032
Validation loss: 2.488028751249504

Epoch: 5| Step: 8
Training loss: 2.6581763070664564
Validation loss: 2.522940064939694

Epoch: 5| Step: 9
Training loss: 2.5883605300086936
Validation loss: 2.5041882717662545

Epoch: 5| Step: 10
Training loss: 2.5646327377836995
Validation loss: 2.5121155288295904

Epoch: 112| Step: 0
Training loss: 2.4653702791676793
Validation loss: 2.5241791391457755

Epoch: 5| Step: 1
Training loss: 2.4444959940917506
Validation loss: 2.513001515150961

Epoch: 5| Step: 2
Training loss: 3.122799976315748
Validation loss: 2.491237191099919

Epoch: 5| Step: 3
Training loss: 2.8075383820462005
Validation loss: 2.5047659033131553

Epoch: 5| Step: 4
Training loss: 2.8939592256975564
Validation loss: 2.5229916239767576

Epoch: 5| Step: 5
Training loss: 2.650478240710529
Validation loss: 2.502336083317445

Epoch: 5| Step: 6
Training loss: 2.289860609051721
Validation loss: 2.4959572868321027

Epoch: 5| Step: 7
Training loss: 2.994397495147856
Validation loss: 2.521619158829207

Epoch: 5| Step: 8
Training loss: 2.9938939261034747
Validation loss: 2.4768378995931912

Epoch: 5| Step: 9
Training loss: 2.712055426523515
Validation loss: 2.484303729381079

Epoch: 5| Step: 10
Training loss: 2.497677868990245
Validation loss: 2.533673557169479

Epoch: 113| Step: 0
Training loss: 2.2570187978641987
Validation loss: 2.48454562077464

Epoch: 5| Step: 1
Training loss: 3.088862093192527
Validation loss: 2.4879569577710963

Epoch: 5| Step: 2
Training loss: 2.734466638391895
Validation loss: 2.508720353483331

Epoch: 5| Step: 3
Training loss: 2.6499499838085647
Validation loss: 2.483890409051258

Epoch: 5| Step: 4
Training loss: 2.602426196544193
Validation loss: 2.505681510997299

Epoch: 5| Step: 5
Training loss: 2.867202467710421
Validation loss: 2.4943968113837287

Epoch: 5| Step: 6
Training loss: 2.8276894587040005
Validation loss: 2.513489762925521

Epoch: 5| Step: 7
Training loss: 2.39650845068642
Validation loss: 2.529011082455941

Epoch: 5| Step: 8
Training loss: 2.997323908910947
Validation loss: 2.4945508267045966

Epoch: 5| Step: 9
Training loss: 2.6700828743692124
Validation loss: 2.484288290549557

Epoch: 5| Step: 10
Training loss: 2.833523313847477
Validation loss: 2.50797056836528

Epoch: 114| Step: 0
Training loss: 2.884141073112454
Validation loss: 2.485402202454949

Epoch: 5| Step: 1
Training loss: 2.600787439679853
Validation loss: 2.495061906294849

Epoch: 5| Step: 2
Training loss: 2.3532155458981108
Validation loss: 2.5177722455337417

Epoch: 5| Step: 3
Training loss: 2.658343757760427
Validation loss: 2.4904526888148957

Epoch: 5| Step: 4
Training loss: 2.6266064950502366
Validation loss: 2.5056294300145763

Epoch: 5| Step: 5
Training loss: 3.093934487130705
Validation loss: 2.504872011931679

Epoch: 5| Step: 6
Training loss: 2.4221377322522857
Validation loss: 2.5011783038039317

Epoch: 5| Step: 7
Training loss: 3.048115482655713
Validation loss: 2.5062403227838903

Epoch: 5| Step: 8
Training loss: 2.6663616919964905
Validation loss: 2.505305147495139

Epoch: 5| Step: 9
Training loss: 3.251020711391048
Validation loss: 2.518019870046465

Epoch: 5| Step: 10
Training loss: 2.150406479668789
Validation loss: 2.499710053888588

Epoch: 115| Step: 0
Training loss: 2.459764764284926
Validation loss: 2.498668876175284

Epoch: 5| Step: 1
Training loss: 2.9245723574774303
Validation loss: 2.5103136818547394

Epoch: 5| Step: 2
Training loss: 2.9039381122457515
Validation loss: 2.486644279887044

Epoch: 5| Step: 3
Training loss: 3.31735248344062
Validation loss: 2.530740535485247

Epoch: 5| Step: 4
Training loss: 2.332370854734751
Validation loss: 2.5206290616289446

Epoch: 5| Step: 5
Training loss: 3.081011198435152
Validation loss: 2.4984333533721226

Epoch: 5| Step: 6
Training loss: 2.537628520097448
Validation loss: 2.5322884784515645

Epoch: 5| Step: 7
Training loss: 2.8021962782398036
Validation loss: 2.5224946132109567

Epoch: 5| Step: 8
Training loss: 2.5477196164689366
Validation loss: 2.5135474487475893

Epoch: 5| Step: 9
Training loss: 2.3384479823955093
Validation loss: 2.512832299072337

Epoch: 5| Step: 10
Training loss: 2.436409241593701
Validation loss: 2.514580809204206

Epoch: 116| Step: 0
Training loss: 2.24714246067899
Validation loss: 2.5111249192605647

Epoch: 5| Step: 1
Training loss: 2.906572877729834
Validation loss: 2.50274935357301

Epoch: 5| Step: 2
Training loss: 2.9952230568487415
Validation loss: 2.4901087961497193

Epoch: 5| Step: 3
Training loss: 1.9342514614904847
Validation loss: 2.5356308589054133

Epoch: 5| Step: 4
Training loss: 2.8782297320368397
Validation loss: 2.5319511134331285

Epoch: 5| Step: 5
Training loss: 3.0882976536371842
Validation loss: 2.5006507498294352

Epoch: 5| Step: 6
Training loss: 2.9952197136633694
Validation loss: 2.520043999975842

Epoch: 5| Step: 7
Training loss: 2.7059228783082587
Validation loss: 2.525508807582746

Epoch: 5| Step: 8
Training loss: 2.4508274277096334
Validation loss: 2.4900162304552174

Epoch: 5| Step: 9
Training loss: 2.5572621848173824
Validation loss: 2.5003868080659575

Epoch: 5| Step: 10
Training loss: 3.134831945365428
Validation loss: 2.503671617175345

Epoch: 117| Step: 0
Training loss: 2.861652072105746
Validation loss: 2.5046648925832002

Epoch: 5| Step: 1
Training loss: 2.9563676096968305
Validation loss: 2.5289728993963805

Epoch: 5| Step: 2
Training loss: 2.5049887473030674
Validation loss: 2.5168289929291214

Epoch: 5| Step: 3
Training loss: 2.725725455354058
Validation loss: 2.4799458399630048

Epoch: 5| Step: 4
Training loss: 2.5623856495720094
Validation loss: 2.503007677230325

Epoch: 5| Step: 5
Training loss: 2.9577171507800664
Validation loss: 2.5051786652798365

Epoch: 5| Step: 6
Training loss: 2.5028380497392666
Validation loss: 2.5145601038875065

Epoch: 5| Step: 7
Training loss: 1.6347417066275929
Validation loss: 2.518890712036786

Epoch: 5| Step: 8
Training loss: 3.2524318399991614
Validation loss: 2.4961106337992867

Epoch: 5| Step: 9
Training loss: 2.7971720617654787
Validation loss: 2.496034455007928

Epoch: 5| Step: 10
Training loss: 2.898575360497532
Validation loss: 2.494300470407848

Epoch: 118| Step: 0
Training loss: 2.554645502987657
Validation loss: 2.502671003412207

Epoch: 5| Step: 1
Training loss: 3.0995992216870567
Validation loss: 2.5071125568593278

Epoch: 5| Step: 2
Training loss: 2.3466352886392388
Validation loss: 2.530862415719867

Epoch: 5| Step: 3
Training loss: 2.079158439951225
Validation loss: 2.5054403166987824

Epoch: 5| Step: 4
Training loss: 2.7146636244482645
Validation loss: 2.5159636065604563

Epoch: 5| Step: 5
Training loss: 2.3253118941597597
Validation loss: 2.5077188693042607

Epoch: 5| Step: 6
Training loss: 3.0847419064476904
Validation loss: 2.4884687580266562

Epoch: 5| Step: 7
Training loss: 2.711872829938391
Validation loss: 2.52666342039314

Epoch: 5| Step: 8
Training loss: 2.485273282780004
Validation loss: 2.4959812699032717

Epoch: 5| Step: 9
Training loss: 3.5023291875777725
Validation loss: 2.4842529318481588

Epoch: 5| Step: 10
Training loss: 2.680789287261823
Validation loss: 2.4818526920147947

Epoch: 119| Step: 0
Training loss: 3.355855828408672
Validation loss: 2.4928720358156378

Epoch: 5| Step: 1
Training loss: 2.435453680805212
Validation loss: 2.520358343349366

Epoch: 5| Step: 2
Training loss: 2.6559799954683627
Validation loss: 2.474466662856513

Epoch: 5| Step: 3
Training loss: 2.0881475392243836
Validation loss: 2.490447562460333

Epoch: 5| Step: 4
Training loss: 3.264205112875246
Validation loss: 2.521054045587177

Epoch: 5| Step: 5
Training loss: 2.796853433025044
Validation loss: 2.5352603424487863

Epoch: 5| Step: 6
Training loss: 2.508379245308304
Validation loss: 2.490982835871768

Epoch: 5| Step: 7
Training loss: 2.989742545076389
Validation loss: 2.4860899007278996

Epoch: 5| Step: 8
Training loss: 2.71617925714182
Validation loss: 2.5161641105712973

Epoch: 5| Step: 9
Training loss: 1.9230100179918135
Validation loss: 2.4910870133154672

Epoch: 5| Step: 10
Training loss: 2.870227667521049
Validation loss: 2.52672034583736

Epoch: 120| Step: 0
Training loss: 2.604414559327754
Validation loss: 2.5212747361473404

Epoch: 5| Step: 1
Training loss: 2.8727389857225685
Validation loss: 2.4937393202640243

Epoch: 5| Step: 2
Training loss: 3.422316709950733
Validation loss: 2.533419403703817

Epoch: 5| Step: 3
Training loss: 2.4255503668996328
Validation loss: 2.5120853097969063

Epoch: 5| Step: 4
Training loss: 2.2997789774306003
Validation loss: 2.4878286465626496

Epoch: 5| Step: 5
Training loss: 2.7025938008251074
Validation loss: 2.4897305223723234

Epoch: 5| Step: 6
Training loss: 2.5198421789128815
Validation loss: 2.503730058066226

Epoch: 5| Step: 7
Training loss: 2.201906773741019
Validation loss: 2.5168053180199843

Epoch: 5| Step: 8
Training loss: 3.0750318758173028
Validation loss: 2.5319568746417644

Epoch: 5| Step: 9
Training loss: 2.540986162816804
Validation loss: 2.538406308985985

Epoch: 5| Step: 10
Training loss: 2.9812869727443183
Validation loss: 2.511968761845049

Epoch: 121| Step: 0
Training loss: 3.381149905374973
Validation loss: 2.501037559754133

Epoch: 5| Step: 1
Training loss: 2.5561043546265325
Validation loss: 2.521288709020462

Epoch: 5| Step: 2
Training loss: 2.9806269732432953
Validation loss: 2.500631898575739

Epoch: 5| Step: 3
Training loss: 2.661388946245825
Validation loss: 2.5153517475634732

Epoch: 5| Step: 4
Training loss: 2.3519435839925955
Validation loss: 2.5135758903345327

Epoch: 5| Step: 5
Training loss: 2.5298385452500636
Validation loss: 2.5112698367737467

Epoch: 5| Step: 6
Training loss: 2.458038366261981
Validation loss: 2.5077505297308984

Epoch: 5| Step: 7
Training loss: 2.7791090021818685
Validation loss: 2.522155909699307

Epoch: 5| Step: 8
Training loss: 2.856006242964303
Validation loss: 2.4920984360863048

Epoch: 5| Step: 9
Training loss: 2.892899561710622
Validation loss: 2.495641398263473

Epoch: 5| Step: 10
Training loss: 2.136360877715936
Validation loss: 2.5420175152529683

Epoch: 122| Step: 0
Training loss: 2.0363894659887487
Validation loss: 2.501960975899977

Epoch: 5| Step: 1
Training loss: 3.0655121295460637
Validation loss: 2.519136984037103

Epoch: 5| Step: 2
Training loss: 2.8908498315751827
Validation loss: 2.5087778720449587

Epoch: 5| Step: 3
Training loss: 2.688104339782747
Validation loss: 2.4949012023430712

Epoch: 5| Step: 4
Training loss: 3.0418506375072596
Validation loss: 2.5099910963748946

Epoch: 5| Step: 5
Training loss: 2.7023694520485146
Validation loss: 2.5186166871182363

Epoch: 5| Step: 6
Training loss: 2.760865852708681
Validation loss: 2.507079725725121

Epoch: 5| Step: 7
Training loss: 2.6655793556160403
Validation loss: 2.5017209323578964

Epoch: 5| Step: 8
Training loss: 2.287016595510861
Validation loss: 2.5160911809368582

Epoch: 5| Step: 9
Training loss: 2.8360061006682167
Validation loss: 2.5169791590387627

Epoch: 5| Step: 10
Training loss: 2.705824017200776
Validation loss: 2.5070587483204925

Epoch: 123| Step: 0
Training loss: 3.3295823609155724
Validation loss: 2.4916926931180536

Epoch: 5| Step: 1
Training loss: 2.903975386228892
Validation loss: 2.5024472533246995

Epoch: 5| Step: 2
Training loss: 2.737458675542916
Validation loss: 2.499620841612393

Epoch: 5| Step: 3
Training loss: 2.1124501735973316
Validation loss: 2.4935852753826633

Epoch: 5| Step: 4
Training loss: 3.112667315172215
Validation loss: 2.5096348841418674

Epoch: 5| Step: 5
Training loss: 2.3608448426944233
Validation loss: 2.502462198006498

Epoch: 5| Step: 6
Training loss: 2.16069236573109
Validation loss: 2.5109710823229685

Epoch: 5| Step: 7
Training loss: 2.99568517651953
Validation loss: 2.5150632114426106

Epoch: 5| Step: 8
Training loss: 2.6967811895257072
Validation loss: 2.5147533900366374

Epoch: 5| Step: 9
Training loss: 2.37303290971328
Validation loss: 2.508416553240106

Epoch: 5| Step: 10
Training loss: 2.9196738045228434
Validation loss: 2.49685121172469

Epoch: 124| Step: 0
Training loss: 3.610157010793038
Validation loss: 2.5054054724196986

Epoch: 5| Step: 1
Training loss: 2.842571307707917
Validation loss: 2.502681923085435

Epoch: 5| Step: 2
Training loss: 2.835266538331765
Validation loss: 2.520075136283064

Epoch: 5| Step: 3
Training loss: 2.4910884335079575
Validation loss: 2.519732883833967

Epoch: 5| Step: 4
Training loss: 2.5337088616093895
Validation loss: 2.490534371424888

Epoch: 5| Step: 5
Training loss: 2.656964553763112
Validation loss: 2.492532484096505

Epoch: 5| Step: 6
Training loss: 1.7583879673260634
Validation loss: 2.4807740175846233

Epoch: 5| Step: 7
Training loss: 2.6110444353487128
Validation loss: 2.539972125384841

Epoch: 5| Step: 8
Training loss: 2.6639892031075654
Validation loss: 2.5134644995904734

Epoch: 5| Step: 9
Training loss: 2.890803481081921
Validation loss: 2.4806836520336026

Epoch: 5| Step: 10
Training loss: 2.602788962556503
Validation loss: 2.5264133035790683

Epoch: 125| Step: 0
Training loss: 3.4656920829864135
Validation loss: 2.49677439120176

Epoch: 5| Step: 1
Training loss: 2.2544249362560045
Validation loss: 2.482923079683587

Epoch: 5| Step: 2
Training loss: 3.0476401908742816
Validation loss: 2.530381361924249

Epoch: 5| Step: 3
Training loss: 2.740950346092328
Validation loss: 2.4958738629797463

Epoch: 5| Step: 4
Training loss: 2.384761825920909
Validation loss: 2.511860885251212

Epoch: 5| Step: 5
Training loss: 2.6120579797347245
Validation loss: 2.4982653824582317

Epoch: 5| Step: 6
Training loss: 2.197655347382502
Validation loss: 2.502485209035894

Epoch: 5| Step: 7
Training loss: 2.7994912979691122
Validation loss: 2.479096413128222

Epoch: 5| Step: 8
Training loss: 2.4017432478008414
Validation loss: 2.4732370675982045

Epoch: 5| Step: 9
Training loss: 2.9055368512412465
Validation loss: 2.4981901385637686

Epoch: 5| Step: 10
Training loss: 2.8262548849678595
Validation loss: 2.524019532389434

Epoch: 126| Step: 0
Training loss: 2.3007586596275313
Validation loss: 2.512309250508483

Epoch: 5| Step: 1
Training loss: 3.2222599780037497
Validation loss: 2.4899878626108904

Epoch: 5| Step: 2
Training loss: 2.5218263567046724
Validation loss: 2.517844873965249

Epoch: 5| Step: 3
Training loss: 2.989505053480043
Validation loss: 2.5064374928706163

Epoch: 5| Step: 4
Training loss: 2.945370296649847
Validation loss: 2.518076509334155

Epoch: 5| Step: 5
Training loss: 2.8240053299375383
Validation loss: 2.4858989070081545

Epoch: 5| Step: 6
Training loss: 2.543870335387431
Validation loss: 2.515705653325506

Epoch: 5| Step: 7
Training loss: 2.805230388325653
Validation loss: 2.5309788933343627

Epoch: 5| Step: 8
Training loss: 2.542064500117967
Validation loss: 2.493322773687259

Epoch: 5| Step: 9
Training loss: 2.245849065306795
Validation loss: 2.496596768190157

Epoch: 5| Step: 10
Training loss: 2.5700585144150105
Validation loss: 2.5000290222944477

Epoch: 127| Step: 0
Training loss: 2.518823994574315
Validation loss: 2.4914125424514504

Epoch: 5| Step: 1
Training loss: 2.37433444284462
Validation loss: 2.5246890478356603

Epoch: 5| Step: 2
Training loss: 3.168670990389648
Validation loss: 2.515250693103946

Epoch: 5| Step: 3
Training loss: 2.7734154928704338
Validation loss: 2.528586826519087

Epoch: 5| Step: 4
Training loss: 2.863783309656219
Validation loss: 2.517667136784277

Epoch: 5| Step: 5
Training loss: 2.5524359530821106
Validation loss: 2.50297768060112

Epoch: 5| Step: 6
Training loss: 2.1986743531001185
Validation loss: 2.4951631105644374

Epoch: 5| Step: 7
Training loss: 2.6920527552328517
Validation loss: 2.518374865723897

Epoch: 5| Step: 8
Training loss: 2.7528211687938646
Validation loss: 2.5084321021359597

Epoch: 5| Step: 9
Training loss: 2.98288741659619
Validation loss: 2.50876305797615

Epoch: 5| Step: 10
Training loss: 2.724551970721445
Validation loss: 2.5408491261839368

Epoch: 128| Step: 0
Training loss: 3.0152631947790334
Validation loss: 2.4957037526735246

Epoch: 5| Step: 1
Training loss: 3.316665046218655
Validation loss: 2.4786177344849882

Epoch: 5| Step: 2
Training loss: 2.0654336122155383
Validation loss: 2.5169129450051724

Epoch: 5| Step: 3
Training loss: 2.2311082981964927
Validation loss: 2.4903347820490174

Epoch: 5| Step: 4
Training loss: 2.477082495746733
Validation loss: 2.5067333176127145

Epoch: 5| Step: 5
Training loss: 2.995185485598454
Validation loss: 2.4866318928242044

Epoch: 5| Step: 6
Training loss: 2.590579565590823
Validation loss: 2.4867074101638065

Epoch: 5| Step: 7
Training loss: 3.181206267830089
Validation loss: 2.510873318926831

Epoch: 5| Step: 8
Training loss: 2.6308119783047306
Validation loss: 2.5055902337646834

Epoch: 5| Step: 9
Training loss: 2.6908891289026813
Validation loss: 2.518697724048845

Epoch: 5| Step: 10
Training loss: 2.312815567342381
Validation loss: 2.497675611914433

Epoch: 129| Step: 0
Training loss: 2.4578314662233094
Validation loss: 2.5012320722931145

Epoch: 5| Step: 1
Training loss: 2.6113706712245466
Validation loss: 2.4692722057459813

Epoch: 5| Step: 2
Training loss: 2.3211116763115713
Validation loss: 2.5186957056639594

Epoch: 5| Step: 3
Training loss: 2.1526979684563265
Validation loss: 2.5236724355049613

Epoch: 5| Step: 4
Training loss: 3.0881843210068753
Validation loss: 2.5122058918911083

Epoch: 5| Step: 5
Training loss: 2.939699850785369
Validation loss: 2.48982399551176

Epoch: 5| Step: 6
Training loss: 2.5058949587667394
Validation loss: 2.5077875321562804

Epoch: 5| Step: 7
Training loss: 2.8393759151913214
Validation loss: 2.510978135213686

Epoch: 5| Step: 8
Training loss: 2.7219691894211366
Validation loss: 2.5024985984031307

Epoch: 5| Step: 9
Training loss: 3.135392570191788
Validation loss: 2.5398762544753515

Epoch: 5| Step: 10
Training loss: 2.941033693101791
Validation loss: 2.5252603986908846

Epoch: 130| Step: 0
Training loss: 3.293800692376306
Validation loss: 2.4937163169424785

Epoch: 5| Step: 1
Training loss: 2.935770865071828
Validation loss: 2.4968358473984855

Epoch: 5| Step: 2
Training loss: 2.652054109334938
Validation loss: 2.484588277490954

Epoch: 5| Step: 3
Training loss: 2.4028371412800014
Validation loss: 2.518548368359459

Epoch: 5| Step: 4
Training loss: 2.679486503514408
Validation loss: 2.508109300206514

Epoch: 5| Step: 5
Training loss: 2.1020610459062676
Validation loss: 2.5215423649248874

Epoch: 5| Step: 6
Training loss: 2.497109554192781
Validation loss: 2.502223211724898

Epoch: 5| Step: 7
Training loss: 2.143294292092402
Validation loss: 2.4941046730958134

Epoch: 5| Step: 8
Training loss: 3.2450334306825805
Validation loss: 2.4974804292399595

Epoch: 5| Step: 9
Training loss: 2.4470927914952445
Validation loss: 2.499467128445374

Epoch: 5| Step: 10
Training loss: 3.0178115112517956
Validation loss: 2.523906727506526

Epoch: 131| Step: 0
Training loss: 3.035497462118738
Validation loss: 2.5314927394294773

Epoch: 5| Step: 1
Training loss: 3.0151384188380836
Validation loss: 2.524049692334412

Epoch: 5| Step: 2
Training loss: 2.8154712664669526
Validation loss: 2.5092515700767097

Epoch: 5| Step: 3
Training loss: 2.6874117282298946
Validation loss: 2.5129235927805254

Epoch: 5| Step: 4
Training loss: 2.434420474292454
Validation loss: 2.469191620095924

Epoch: 5| Step: 5
Training loss: 2.5663993754069834
Validation loss: 2.500563066918579

Epoch: 5| Step: 6
Training loss: 2.835463975618673
Validation loss: 2.509538557103085

Epoch: 5| Step: 7
Training loss: 2.5033880164637123
Validation loss: 2.500791389557618

Epoch: 5| Step: 8
Training loss: 2.5492887701857483
Validation loss: 2.4911940976746294

Epoch: 5| Step: 9
Training loss: 2.290474101634858
Validation loss: 2.4800530926831312

Epoch: 5| Step: 10
Training loss: 2.8164245350914756
Validation loss: 2.5101721090531197

Epoch: 132| Step: 0
Training loss: 3.3045739409142048
Validation loss: 2.48788466451365

Epoch: 5| Step: 1
Training loss: 2.6067587705797375
Validation loss: 2.5304198003147693

Epoch: 5| Step: 2
Training loss: 2.4886892035208397
Validation loss: 2.5185810367608195

Epoch: 5| Step: 3
Training loss: 3.5275889635661954
Validation loss: 2.500149791085771

Epoch: 5| Step: 4
Training loss: 2.104800427868639
Validation loss: 2.4996864583686262

Epoch: 5| Step: 5
Training loss: 2.363954054216532
Validation loss: 2.496755158491804

Epoch: 5| Step: 6
Training loss: 2.7500732585512484
Validation loss: 2.509276701633516

Epoch: 5| Step: 7
Training loss: 2.947833290313906
Validation loss: 2.516663318896116

Epoch: 5| Step: 8
Training loss: 2.487141730036816
Validation loss: 2.4969593640903125

Epoch: 5| Step: 9
Training loss: 2.4771333150951715
Validation loss: 2.500173572954634

Epoch: 5| Step: 10
Training loss: 2.4582000523876397
Validation loss: 2.512534539027099

Epoch: 133| Step: 0
Training loss: 3.2214436047082105
Validation loss: 2.5080270778596017

Epoch: 5| Step: 1
Training loss: 2.6737147015296494
Validation loss: 2.5037107861212458

Epoch: 5| Step: 2
Training loss: 2.8051965618110843
Validation loss: 2.490668019116355

Epoch: 5| Step: 3
Training loss: 2.8465418263680395
Validation loss: 2.5261776061164376

Epoch: 5| Step: 4
Training loss: 2.748585163636724
Validation loss: 2.496063644605331

Epoch: 5| Step: 5
Training loss: 2.9054902426983023
Validation loss: 2.5022628162284786

Epoch: 5| Step: 6
Training loss: 2.418931119382059
Validation loss: 2.5209053171311497

Epoch: 5| Step: 7
Training loss: 2.3547962550897306
Validation loss: 2.502624778657981

Epoch: 5| Step: 8
Training loss: 2.4677571098774753
Validation loss: 2.5120727726415497

Epoch: 5| Step: 9
Training loss: 2.539682353725502
Validation loss: 2.4938017425362697

Epoch: 5| Step: 10
Training loss: 2.7612317207529213
Validation loss: 2.4983637592721815

Epoch: 134| Step: 0
Training loss: 2.3352552967883358
Validation loss: 2.4895312825176146

Epoch: 5| Step: 1
Training loss: 1.8620920284896494
Validation loss: 2.485841396368034

Epoch: 5| Step: 2
Training loss: 2.5195638018730513
Validation loss: 2.545205375339702

Epoch: 5| Step: 3
Training loss: 2.6691297738865027
Validation loss: 2.505691487528619

Epoch: 5| Step: 4
Training loss: 2.4957998278814895
Validation loss: 2.5186731470747175

Epoch: 5| Step: 5
Training loss: 2.88711169385604
Validation loss: 2.494459099013256

Epoch: 5| Step: 6
Training loss: 2.7913336389142254
Validation loss: 2.517727950631316

Epoch: 5| Step: 7
Training loss: 3.105078868263608
Validation loss: 2.4747925715875936

Epoch: 5| Step: 8
Training loss: 2.9890984508627674
Validation loss: 2.4898709011689912

Epoch: 5| Step: 9
Training loss: 3.0091581430862915
Validation loss: 2.4853517677685315

Epoch: 5| Step: 10
Training loss: 2.6582191797538224
Validation loss: 2.5068941271966603

Epoch: 135| Step: 0
Training loss: 2.5128679983412185
Validation loss: 2.5024831570859845

Epoch: 5| Step: 1
Training loss: 2.9497548405562055
Validation loss: 2.4855115915095918

Epoch: 5| Step: 2
Training loss: 3.1509823796183056
Validation loss: 2.48514962988029

Epoch: 5| Step: 3
Training loss: 2.551624760332425
Validation loss: 2.499181458590621

Epoch: 5| Step: 4
Training loss: 3.069227808407969
Validation loss: 2.4923894836805074

Epoch: 5| Step: 5
Training loss: 3.10239535663212
Validation loss: 2.5072289701196295

Epoch: 5| Step: 6
Training loss: 2.5024615567024076
Validation loss: 2.544318835904718

Epoch: 5| Step: 7
Training loss: 2.1729019262070497
Validation loss: 2.523068076058787

Epoch: 5| Step: 8
Training loss: 2.6523576828783075
Validation loss: 2.4890415763919242

Epoch: 5| Step: 9
Training loss: 2.557129232578865
Validation loss: 2.5023849166068666

Epoch: 5| Step: 10
Training loss: 2.2540999251643066
Validation loss: 2.5069488764946506

Epoch: 136| Step: 0
Training loss: 2.556107899043531
Validation loss: 2.511425501002045

Epoch: 5| Step: 1
Training loss: 2.7820747095712997
Validation loss: 2.5007707761235785

Epoch: 5| Step: 2
Training loss: 2.27612816641147
Validation loss: 2.5003464274185467

Epoch: 5| Step: 3
Training loss: 3.1498871677111744
Validation loss: 2.4884870029449697

Epoch: 5| Step: 4
Training loss: 3.2349229431408535
Validation loss: 2.4973459573804897

Epoch: 5| Step: 5
Training loss: 2.752310562475102
Validation loss: 2.5263707655192698

Epoch: 5| Step: 6
Training loss: 2.5822354003718075
Validation loss: 2.512729563924264

Epoch: 5| Step: 7
Training loss: 2.5662577918557314
Validation loss: 2.526550926343169

Epoch: 5| Step: 8
Training loss: 2.5980004104132326
Validation loss: 2.526590295619541

Epoch: 5| Step: 9
Training loss: 2.2334283277131903
Validation loss: 2.5094722693347147

Epoch: 5| Step: 10
Training loss: 2.757090184875464
Validation loss: 2.520940308693904

Epoch: 137| Step: 0
Training loss: 2.3013112311062516
Validation loss: 2.5019942225796132

Epoch: 5| Step: 1
Training loss: 3.155675552516295
Validation loss: 2.5073183779360844

Epoch: 5| Step: 2
Training loss: 2.4926874980595097
Validation loss: 2.502563812919732

Epoch: 5| Step: 3
Training loss: 2.9487326922521215
Validation loss: 2.500810742944903

Epoch: 5| Step: 4
Training loss: 2.8682697966338067
Validation loss: 2.5168375394733205

Epoch: 5| Step: 5
Training loss: 2.915879733783135
Validation loss: 2.526830656098144

Epoch: 5| Step: 6
Training loss: 2.926657287072841
Validation loss: 2.4865102808596795

Epoch: 5| Step: 7
Training loss: 1.9928627216243446
Validation loss: 2.514942759210648

Epoch: 5| Step: 8
Training loss: 2.7135168112252863
Validation loss: 2.5187018554730747

Epoch: 5| Step: 9
Training loss: 2.8937669329219924
Validation loss: 2.5180195768285456

Epoch: 5| Step: 10
Training loss: 2.1088996634204187
Validation loss: 2.4945052962602494

Epoch: 138| Step: 0
Training loss: 2.9715882236170854
Validation loss: 2.5266053339123937

Epoch: 5| Step: 1
Training loss: 2.1698046359881604
Validation loss: 2.529733166647311

Epoch: 5| Step: 2
Training loss: 3.0558661408991314
Validation loss: 2.4981580444918112

Epoch: 5| Step: 3
Training loss: 2.8939671346383995
Validation loss: 2.5159662089569217

Epoch: 5| Step: 4
Training loss: 2.370324602391648
Validation loss: 2.4899798411435317

Epoch: 5| Step: 5
Training loss: 3.0210194146733
Validation loss: 2.470840412284625

Epoch: 5| Step: 6
Training loss: 2.779630811176486
Validation loss: 2.502536191716403

Epoch: 5| Step: 7
Training loss: 2.3143474313287427
Validation loss: 2.520486701219325

Epoch: 5| Step: 8
Training loss: 2.7181454567348866
Validation loss: 2.5156897427805816

Epoch: 5| Step: 9
Training loss: 2.5755371052093308
Validation loss: 2.516460005221849

Epoch: 5| Step: 10
Training loss: 2.4903409329223822
Validation loss: 2.4930212998635866

Epoch: 139| Step: 0
Training loss: 2.6227846334088984
Validation loss: 2.503917952652201

Epoch: 5| Step: 1
Training loss: 3.1046895519109663
Validation loss: 2.5217425514283223

Epoch: 5| Step: 2
Training loss: 2.399869609310705
Validation loss: 2.50433812558647

Epoch: 5| Step: 3
Training loss: 2.586596540388594
Validation loss: 2.4968365640739165

Epoch: 5| Step: 4
Training loss: 2.454663322810448
Validation loss: 2.525895991351974

Epoch: 5| Step: 5
Training loss: 2.961948997022385
Validation loss: 2.491205041927546

Epoch: 5| Step: 6
Training loss: 2.87514147203088
Validation loss: 2.5048250049169427

Epoch: 5| Step: 7
Training loss: 2.7953321580957913
Validation loss: 2.501470554752163

Epoch: 5| Step: 8
Training loss: 2.5965286446234046
Validation loss: 2.5076742496078483

Epoch: 5| Step: 9
Training loss: 2.238119442402092
Validation loss: 2.4997441837726324

Epoch: 5| Step: 10
Training loss: 2.8864973961563827
Validation loss: 2.5356228417997353

Epoch: 140| Step: 0
Training loss: 2.504770115033034
Validation loss: 2.4914151211011113

Epoch: 5| Step: 1
Training loss: 3.160310003550677
Validation loss: 2.4565989461283255

Epoch: 5| Step: 2
Training loss: 2.3217434051311567
Validation loss: 2.523672437536636

Epoch: 5| Step: 3
Training loss: 2.82489039453204
Validation loss: 2.524997211001121

Epoch: 5| Step: 4
Training loss: 3.3051173153830447
Validation loss: 2.5264446749392864

Epoch: 5| Step: 5
Training loss: 2.2259742361258903
Validation loss: 2.504176869311124

Epoch: 5| Step: 6
Training loss: 2.8691514276621857
Validation loss: 2.4846124487204277

Epoch: 5| Step: 7
Training loss: 2.6701330563255956
Validation loss: 2.5067572794009845

Epoch: 5| Step: 8
Training loss: 2.31674742477865
Validation loss: 2.5195655845216196

Epoch: 5| Step: 9
Training loss: 2.5408176400698914
Validation loss: 2.528729081691063

Epoch: 5| Step: 10
Training loss: 2.4525347929031285
Validation loss: 2.510691860554178

Epoch: 141| Step: 0
Training loss: 2.591455202787461
Validation loss: 2.5075525795633764

Epoch: 5| Step: 1
Training loss: 2.350726920172281
Validation loss: 2.494583233868973

Epoch: 5| Step: 2
Training loss: 2.605346036248815
Validation loss: 2.4819561893043627

Epoch: 5| Step: 3
Training loss: 2.429178558721818
Validation loss: 2.517073532008194

Epoch: 5| Step: 4
Training loss: 2.524938461762436
Validation loss: 2.496620265582025

Epoch: 5| Step: 5
Training loss: 2.4905140199908034
Validation loss: 2.4993000588866834

Epoch: 5| Step: 6
Training loss: 3.74334100135387
Validation loss: 2.4986254871767777

Epoch: 5| Step: 7
Training loss: 2.237604008819895
Validation loss: 2.494608206439454

Epoch: 5| Step: 8
Training loss: 3.172442906845194
Validation loss: 2.5119956256623146

Epoch: 5| Step: 9
Training loss: 2.8168360875507856
Validation loss: 2.5110423862583735

Epoch: 5| Step: 10
Training loss: 2.2602905613285342
Validation loss: 2.502338033962644

Epoch: 142| Step: 0
Training loss: 2.735631163749
Validation loss: 2.4785647817661625

Epoch: 5| Step: 1
Training loss: 1.8889857981013163
Validation loss: 2.491863664691998

Epoch: 5| Step: 2
Training loss: 2.765027170168499
Validation loss: 2.515845098887767

Epoch: 5| Step: 3
Training loss: 2.7174085618176003
Validation loss: 2.4900741893023106

Epoch: 5| Step: 4
Training loss: 2.8683637238450963
Validation loss: 2.4990966785116457

Epoch: 5| Step: 5
Training loss: 2.038129688153436
Validation loss: 2.4915229003017405

Epoch: 5| Step: 6
Training loss: 3.0733013020112976
Validation loss: 2.4848695823674287

Epoch: 5| Step: 7
Training loss: 2.7331649282571537
Validation loss: 2.5165240307325636

Epoch: 5| Step: 8
Training loss: 3.182877423724955
Validation loss: 2.5234876438681493

Epoch: 5| Step: 9
Training loss: 2.191255996095295
Validation loss: 2.4890027750220676

Epoch: 5| Step: 10
Training loss: 2.917619349793267
Validation loss: 2.4776393300928814

Epoch: 143| Step: 0
Training loss: 3.0004980945349087
Validation loss: 2.516854471537575

Epoch: 5| Step: 1
Training loss: 2.4772922150813352
Validation loss: 2.5216651604440803

Epoch: 5| Step: 2
Training loss: 2.7141947677261666
Validation loss: 2.5288000780332904

Epoch: 5| Step: 3
Training loss: 2.9367229976151443
Validation loss: 2.500280595229944

Epoch: 5| Step: 4
Training loss: 2.3277892824352486
Validation loss: 2.5339524945681218

Epoch: 5| Step: 5
Training loss: 3.2490709884369764
Validation loss: 2.533998761948216

Epoch: 5| Step: 6
Training loss: 2.7798542420851438
Validation loss: 2.488646239037188

Epoch: 5| Step: 7
Training loss: 2.6269971425505956
Validation loss: 2.501538292546205

Epoch: 5| Step: 8
Training loss: 2.326199753191468
Validation loss: 2.5152112390869203

Epoch: 5| Step: 9
Training loss: 2.6600865202291786
Validation loss: 2.5272395810242805

Epoch: 5| Step: 10
Training loss: 1.9924012910905724
Validation loss: 2.5156828814353034

Epoch: 144| Step: 0
Training loss: 3.1506813705053873
Validation loss: 2.5174072918435457

Epoch: 5| Step: 1
Training loss: 3.0159597260495428
Validation loss: 2.543080560141501

Epoch: 5| Step: 2
Training loss: 1.9802647472401227
Validation loss: 2.51292424977796

Epoch: 5| Step: 3
Training loss: 3.0714635656904297
Validation loss: 2.504844985232047

Epoch: 5| Step: 4
Training loss: 2.8788443032047994
Validation loss: 2.504178652675731

Epoch: 5| Step: 5
Training loss: 2.0274899233415957
Validation loss: 2.5142726138115497

Epoch: 5| Step: 6
Training loss: 2.2855256654195024
Validation loss: 2.5125885772070107

Epoch: 5| Step: 7
Training loss: 2.843913314657143
Validation loss: 2.513284023928721

Epoch: 5| Step: 8
Training loss: 2.4599332183209026
Validation loss: 2.525653610302326

Epoch: 5| Step: 9
Training loss: 2.748538062168143
Validation loss: 2.5211303215303267

Epoch: 5| Step: 10
Training loss: 2.63312091775465
Validation loss: 2.503654415739388

Epoch: 145| Step: 0
Training loss: 2.781289603990762
Validation loss: 2.5155311056896865

Epoch: 5| Step: 1
Training loss: 2.623022151782221
Validation loss: 2.516530729845377

Epoch: 5| Step: 2
Training loss: 2.903265949026435
Validation loss: 2.5181285909629043

Epoch: 5| Step: 3
Training loss: 2.407626959442883
Validation loss: 2.508114841225214

Epoch: 5| Step: 4
Training loss: 2.873310090020408
Validation loss: 2.5312022968447496

Epoch: 5| Step: 5
Training loss: 2.5907150344940706
Validation loss: 2.519923344296056

Epoch: 5| Step: 6
Training loss: 3.1754530095398827
Validation loss: 2.52306393755893

Epoch: 5| Step: 7
Training loss: 2.217803968305922
Validation loss: 2.4782947814355136

Epoch: 5| Step: 8
Training loss: 2.7175320933814837
Validation loss: 2.5204696257295973

Epoch: 5| Step: 9
Training loss: 2.3923630722867113
Validation loss: 2.4856939639726696

Epoch: 5| Step: 10
Training loss: 2.5868268745334686
Validation loss: 2.493139324307546

Epoch: 146| Step: 0
Training loss: 2.4384194620617317
Validation loss: 2.5025322241461896

Epoch: 5| Step: 1
Training loss: 2.649956101827683
Validation loss: 2.5262341944290134

Epoch: 5| Step: 2
Training loss: 2.888895207993207
Validation loss: 2.5170811901017576

Epoch: 5| Step: 3
Training loss: 2.834130249896159
Validation loss: 2.5087395506683206

Epoch: 5| Step: 4
Training loss: 2.3399674473641983
Validation loss: 2.5036902192500285

Epoch: 5| Step: 5
Training loss: 3.1021647985524448
Validation loss: 2.516539602882493

Epoch: 5| Step: 6
Training loss: 2.916861409543297
Validation loss: 2.5131053357988278

Epoch: 5| Step: 7
Training loss: 2.6896277587751665
Validation loss: 2.494505241791351

Epoch: 5| Step: 8
Training loss: 2.6740815270377656
Validation loss: 2.500657546825903

Epoch: 5| Step: 9
Training loss: 2.2963195959684297
Validation loss: 2.497293810349649

Epoch: 5| Step: 10
Training loss: 2.583308332588881
Validation loss: 2.488077655152236

Epoch: 147| Step: 0
Training loss: 3.473431975806027
Validation loss: 2.4959852889709833

Epoch: 5| Step: 1
Training loss: 2.3677571936244233
Validation loss: 2.4634941752268276

Epoch: 5| Step: 2
Training loss: 2.5483479365380934
Validation loss: 2.539145190436156

Epoch: 5| Step: 3
Training loss: 2.266674140843055
Validation loss: 2.5235511375509434

Epoch: 5| Step: 4
Training loss: 2.2244449651850697
Validation loss: 2.5071683126642257

Epoch: 5| Step: 5
Training loss: 3.030499709566899
Validation loss: 2.5286515719954608

Epoch: 5| Step: 6
Training loss: 2.739236488191285
Validation loss: 2.4595670140376598

Epoch: 5| Step: 7
Training loss: 2.7696334325020975
Validation loss: 2.502561220147561

Epoch: 5| Step: 8
Training loss: 2.8286730830599067
Validation loss: 2.512178303226751

Epoch: 5| Step: 9
Training loss: 2.474853503582945
Validation loss: 2.49993283068755

Epoch: 5| Step: 10
Training loss: 2.7636417670345415
Validation loss: 2.519903314656051

Epoch: 148| Step: 0
Training loss: 2.9176149370815785
Validation loss: 2.4896385758938084

Epoch: 5| Step: 1
Training loss: 2.481214228067126
Validation loss: 2.4917005578271105

Epoch: 5| Step: 2
Training loss: 2.9089588953538685
Validation loss: 2.5192941861759084

Epoch: 5| Step: 3
Training loss: 2.601199837915426
Validation loss: 2.4594535628604066

Epoch: 5| Step: 4
Training loss: 2.6844209287398
Validation loss: 2.5170535642268095

Epoch: 5| Step: 5
Training loss: 2.895351195964599
Validation loss: 2.497726633236079

Epoch: 5| Step: 6
Training loss: 2.178779877957339
Validation loss: 2.514553133429615

Epoch: 5| Step: 7
Training loss: 2.6516688616072392
Validation loss: 2.520536503561745

Epoch: 5| Step: 8
Training loss: 2.6298146371826174
Validation loss: 2.533869034705898

Epoch: 5| Step: 9
Training loss: 2.737964040365437
Validation loss: 2.5111364116544217

Epoch: 5| Step: 10
Training loss: 2.682504046775702
Validation loss: 2.498663017693863

Epoch: 149| Step: 0
Training loss: 2.209218141849919
Validation loss: 2.501418992820689

Epoch: 5| Step: 1
Training loss: 2.306164904836239
Validation loss: 2.512454888458135

Epoch: 5| Step: 2
Training loss: 3.1099397539393467
Validation loss: 2.5180406222543277

Epoch: 5| Step: 3
Training loss: 3.059235058585194
Validation loss: 2.5102954689384496

Epoch: 5| Step: 4
Training loss: 2.876114670654646
Validation loss: 2.50858129264346

Epoch: 5| Step: 5
Training loss: 2.8374340637881286
Validation loss: 2.5167557805378937

Epoch: 5| Step: 6
Training loss: 2.5442890542717453
Validation loss: 2.5157537033144566

Epoch: 5| Step: 7
Training loss: 2.014740742553391
Validation loss: 2.544439705029005

Epoch: 5| Step: 8
Training loss: 2.61911349812341
Validation loss: 2.518925619632676

Epoch: 5| Step: 9
Training loss: 2.767331561275544
Validation loss: 2.498013202221214

Epoch: 5| Step: 10
Training loss: 2.6259856417191503
Validation loss: 2.539806524142281

Epoch: 150| Step: 0
Training loss: 2.6050789926161118
Validation loss: 2.5177343532896397

Epoch: 5| Step: 1
Training loss: 2.5887994976828317
Validation loss: 2.506305010332038

Epoch: 5| Step: 2
Training loss: 2.7662999250937577
Validation loss: 2.5030778550535246

Epoch: 5| Step: 3
Training loss: 2.7875950476346394
Validation loss: 2.5056922998913316

Epoch: 5| Step: 4
Training loss: 3.22775490366596
Validation loss: 2.5158506463057058

Epoch: 5| Step: 5
Training loss: 2.8814718959535957
Validation loss: 2.4732671948198215

Epoch: 5| Step: 6
Training loss: 2.1103656844231917
Validation loss: 2.5071955627899176

Epoch: 5| Step: 7
Training loss: 2.6593769293126996
Validation loss: 2.4945543989743504

Epoch: 5| Step: 8
Training loss: 2.3796528864426496
Validation loss: 2.5190169270912035

Epoch: 5| Step: 9
Training loss: 2.6178530629642376
Validation loss: 2.502743858037834

Epoch: 5| Step: 10
Training loss: 2.3773492939032264
Validation loss: 2.5211381142372247

Epoch: 151| Step: 0
Training loss: 2.936746216503722
Validation loss: 2.505224973896081

Epoch: 5| Step: 1
Training loss: 3.1273883085485705
Validation loss: 2.521222097721263

Epoch: 5| Step: 2
Training loss: 3.0948512111513597
Validation loss: 2.5233497250056875

Epoch: 5| Step: 3
Training loss: 2.2602810679839402
Validation loss: 2.5121472466104207

Epoch: 5| Step: 4
Training loss: 2.3068613952880463
Validation loss: 2.5092922983256973

Epoch: 5| Step: 5
Training loss: 2.088052541736731
Validation loss: 2.5014437106226803

Epoch: 5| Step: 6
Training loss: 2.4135070951968784
Validation loss: 2.5003827899213684

Epoch: 5| Step: 7
Training loss: 2.945731621424706
Validation loss: 2.4955937851584284

Epoch: 5| Step: 8
Training loss: 2.558110175407843
Validation loss: 2.503433068924823

Epoch: 5| Step: 9
Training loss: 2.443317513598984
Validation loss: 2.537864656189597

Epoch: 5| Step: 10
Training loss: 3.089634016516854
Validation loss: 2.502467895975879

Epoch: 152| Step: 0
Training loss: 3.200168640938214
Validation loss: 2.5070979752954994

Epoch: 5| Step: 1
Training loss: 3.238997836831558
Validation loss: 2.497209713551553

Epoch: 5| Step: 2
Training loss: 2.350077213885613
Validation loss: 2.5207643346073483

Epoch: 5| Step: 3
Training loss: 2.538807641956926
Validation loss: 2.5131430081310286

Epoch: 5| Step: 4
Training loss: 3.520982381761974
Validation loss: 2.513953185684581

Epoch: 5| Step: 5
Training loss: 2.2624708647985945
Validation loss: 2.4992398229160124

Epoch: 5| Step: 6
Training loss: 2.3546205831333284
Validation loss: 2.5125737131629777

Epoch: 5| Step: 7
Training loss: 2.4518747241515726
Validation loss: 2.503699305719889

Epoch: 5| Step: 8
Training loss: 2.5755296069935296
Validation loss: 2.513858046979192

Epoch: 5| Step: 9
Training loss: 1.9890729905396474
Validation loss: 2.5170621869056244

Epoch: 5| Step: 10
Training loss: 2.3799418182634406
Validation loss: 2.5160140287864836

Epoch: 153| Step: 0
Training loss: 3.0602195189779273
Validation loss: 2.493633728993

Epoch: 5| Step: 1
Training loss: 1.9015511304755242
Validation loss: 2.5083329622203467

Epoch: 5| Step: 2
Training loss: 2.6053428333516635
Validation loss: 2.507806544296343

Epoch: 5| Step: 3
Training loss: 3.3383501605941173
Validation loss: 2.531225545915202

Epoch: 5| Step: 4
Training loss: 2.795680467621179
Validation loss: 2.4956183480139433

Epoch: 5| Step: 5
Training loss: 2.845514274200742
Validation loss: 2.4846242917734966

Epoch: 5| Step: 6
Training loss: 2.5516299928520914
Validation loss: 2.513269559774064

Epoch: 5| Step: 7
Training loss: 2.5594370143955407
Validation loss: 2.4851397235592403

Epoch: 5| Step: 8
Training loss: 2.081078173443553
Validation loss: 2.5097142314472882

Epoch: 5| Step: 9
Training loss: 2.58860304904874
Validation loss: 2.5397461218721133

Epoch: 5| Step: 10
Training loss: 2.8038617036755973
Validation loss: 2.4963187771464184

Epoch: 154| Step: 0
Training loss: 2.507221092770286
Validation loss: 2.5070436842995516

Epoch: 5| Step: 1
Training loss: 2.602371502433122
Validation loss: 2.5056770695813357

Epoch: 5| Step: 2
Training loss: 2.6916728780416936
Validation loss: 2.523932573971009

Epoch: 5| Step: 3
Training loss: 2.473072758166953
Validation loss: 2.503121333815816

Epoch: 5| Step: 4
Training loss: 2.57055097128806
Validation loss: 2.5317587108984116

Epoch: 5| Step: 5
Training loss: 2.714894509698582
Validation loss: 2.5044137917915363

Epoch: 5| Step: 6
Training loss: 2.6580285793516034
Validation loss: 2.552362343305447

Epoch: 5| Step: 7
Training loss: 2.6591829152110416
Validation loss: 2.515098511078585

Epoch: 5| Step: 8
Training loss: 2.959432335109852
Validation loss: 2.535127203097871

Epoch: 5| Step: 9
Training loss: 3.21070196396994
Validation loss: 2.518847063248771

Epoch: 5| Step: 10
Training loss: 2.2693712503102303
Validation loss: 2.515544255425179

Epoch: 155| Step: 0
Training loss: 2.7146552809468383
Validation loss: 2.4667006938697

Epoch: 5| Step: 1
Training loss: 2.344202023467912
Validation loss: 2.5118409689087167

Epoch: 5| Step: 2
Training loss: 2.6879219788456608
Validation loss: 2.5148086879414953

Epoch: 5| Step: 3
Training loss: 1.969901399129685
Validation loss: 2.479353078126424

Epoch: 5| Step: 4
Training loss: 2.628109044447284
Validation loss: 2.5204074092663493

Epoch: 5| Step: 5
Training loss: 2.3247254404365876
Validation loss: 2.5148265083201906

Epoch: 5| Step: 6
Training loss: 3.16833509027418
Validation loss: 2.491502811093831

Epoch: 5| Step: 7
Training loss: 3.113893073067154
Validation loss: 2.498175677323272

Epoch: 5| Step: 8
Training loss: 2.824615999302926
Validation loss: 2.4911451458663367

Epoch: 5| Step: 9
Training loss: 2.2000878143124276
Validation loss: 2.5047537491607983

Epoch: 5| Step: 10
Training loss: 3.219824898502116
Validation loss: 2.5028813523948092

Epoch: 156| Step: 0
Training loss: 2.523879068672604
Validation loss: 2.4867905075157486

Epoch: 5| Step: 1
Training loss: 2.451157479414899
Validation loss: 2.4962794624304734

Epoch: 5| Step: 2
Training loss: 2.612595997191961
Validation loss: 2.4947761050304633

Epoch: 5| Step: 3
Training loss: 2.1996573354715165
Validation loss: 2.5301006608949717

Epoch: 5| Step: 4
Training loss: 3.579581684628285
Validation loss: 2.520618370231339

Epoch: 5| Step: 5
Training loss: 2.4758510590591443
Validation loss: 2.493491435344125

Epoch: 5| Step: 6
Training loss: 2.562467435304228
Validation loss: 2.4978954737503174

Epoch: 5| Step: 7
Training loss: 2.4553890592804395
Validation loss: 2.499785542262416

Epoch: 5| Step: 8
Training loss: 2.8778534702114875
Validation loss: 2.535540425252061

Epoch: 5| Step: 9
Training loss: 2.5387251879307424
Validation loss: 2.504955673413435

Epoch: 5| Step: 10
Training loss: 2.7915878189870624
Validation loss: 2.513967732585481

Epoch: 157| Step: 0
Training loss: 2.2128294273863567
Validation loss: 2.522798127601567

Epoch: 5| Step: 1
Training loss: 2.7485842094713373
Validation loss: 2.503718612055001

Epoch: 5| Step: 2
Training loss: 2.840579434775334
Validation loss: 2.5148803570857563

Epoch: 5| Step: 3
Training loss: 2.343748168944597
Validation loss: 2.512258418196914

Epoch: 5| Step: 4
Training loss: 3.0946197828395325
Validation loss: 2.5063155909447925

Epoch: 5| Step: 5
Training loss: 2.8933439097526135
Validation loss: 2.491909360683981

Epoch: 5| Step: 6
Training loss: 3.0393690724425864
Validation loss: 2.5110454317407678

Epoch: 5| Step: 7
Training loss: 2.7261486012571794
Validation loss: 2.5044926811289856

Epoch: 5| Step: 8
Training loss: 2.084202191053776
Validation loss: 2.5344823841715702

Epoch: 5| Step: 9
Training loss: 2.342534780172875
Validation loss: 2.5323907957031504

Epoch: 5| Step: 10
Training loss: 2.6968454617930373
Validation loss: 2.51088917524784

Epoch: 158| Step: 0
Training loss: 2.4141205715861154
Validation loss: 2.501708902778823

Epoch: 5| Step: 1
Training loss: 2.203809699398319
Validation loss: 2.530135357088647

Epoch: 5| Step: 2
Training loss: 2.8207204423306003
Validation loss: 2.52472817858399

Epoch: 5| Step: 3
Training loss: 2.1477102817525697
Validation loss: 2.47943417774254

Epoch: 5| Step: 4
Training loss: 2.7659093850684826
Validation loss: 2.5025551034073117

Epoch: 5| Step: 5
Training loss: 2.960484291358406
Validation loss: 2.502928929550479

Epoch: 5| Step: 6
Training loss: 2.3918579512427867
Validation loss: 2.5178564395415868

Epoch: 5| Step: 7
Training loss: 2.865796159564359
Validation loss: 2.507886522920773

Epoch: 5| Step: 8
Training loss: 2.524456656887993
Validation loss: 2.5337369665949567

Epoch: 5| Step: 9
Training loss: 2.4786669337002487
Validation loss: 2.5386531826160494

Epoch: 5| Step: 10
Training loss: 3.4816833500320126
Validation loss: 2.5267565793992146

Epoch: 159| Step: 0
Training loss: 2.9508808631232757
Validation loss: 2.508124629203986

Epoch: 5| Step: 1
Training loss: 1.879433032637748
Validation loss: 2.5017458695453847

Epoch: 5| Step: 2
Training loss: 2.5475369394785647
Validation loss: 2.5030614770925124

Epoch: 5| Step: 3
Training loss: 2.129461317582988
Validation loss: 2.527180598859836

Epoch: 5| Step: 4
Training loss: 2.6134795839232217
Validation loss: 2.507690494700118

Epoch: 5| Step: 5
Training loss: 2.1266386782240434
Validation loss: 2.5513185387722763

Epoch: 5| Step: 6
Training loss: 2.764881616027524
Validation loss: 2.5027289191352793

Epoch: 5| Step: 7
Training loss: 2.8424495196661956
Validation loss: 2.5328688190659885

Epoch: 5| Step: 8
Training loss: 2.6471221268009564
Validation loss: 2.5154769773403833

Epoch: 5| Step: 9
Training loss: 2.654137523097873
Validation loss: 2.522837376594414

Epoch: 5| Step: 10
Training loss: 3.7230481865095792
Validation loss: 2.5249190547090894

Epoch: 160| Step: 0
Training loss: 2.274891810936257
Validation loss: 2.510664782140574

Epoch: 5| Step: 1
Training loss: 2.687131634683932
Validation loss: 2.509457737238036

Epoch: 5| Step: 2
Training loss: 3.0258977771544244
Validation loss: 2.5346556651731276

Epoch: 5| Step: 3
Training loss: 2.2280624958703807
Validation loss: 2.501546117077894

Epoch: 5| Step: 4
Training loss: 2.4681590857896727
Validation loss: 2.505817869174499

Epoch: 5| Step: 5
Training loss: 2.5098477005062136
Validation loss: 2.488769526614624

Epoch: 5| Step: 6
Training loss: 3.0327325715072146
Validation loss: 2.494311978651669

Epoch: 5| Step: 7
Training loss: 3.055154515930567
Validation loss: 2.500237672029369

Epoch: 5| Step: 8
Training loss: 2.297355549684785
Validation loss: 2.5042596797660894

Epoch: 5| Step: 9
Training loss: 2.266189925696298
Validation loss: 2.5069684144786817

Epoch: 5| Step: 10
Training loss: 2.8871044267796013
Validation loss: 2.5133784356842295

Epoch: 161| Step: 0
Training loss: 2.508298927738633
Validation loss: 2.5128507670187528

Epoch: 5| Step: 1
Training loss: 3.4443132331084687
Validation loss: 2.548926285283013

Epoch: 5| Step: 2
Training loss: 2.7624357121094416
Validation loss: 2.502888880810135

Epoch: 5| Step: 3
Training loss: 2.883479674342899
Validation loss: 2.5325489405531245

Epoch: 5| Step: 4
Training loss: 3.034820970159995
Validation loss: 2.4863793967040704

Epoch: 5| Step: 5
Training loss: 2.959129244339387
Validation loss: 2.4903027365251083

Epoch: 5| Step: 6
Training loss: 1.9443698422183593
Validation loss: 2.503647059603786

Epoch: 5| Step: 7
Training loss: 2.225883407096177
Validation loss: 2.4776772147113024

Epoch: 5| Step: 8
Training loss: 2.6869601217532675
Validation loss: 2.4961475212014226

Epoch: 5| Step: 9
Training loss: 1.944813001611356
Validation loss: 2.509909389178958

Epoch: 5| Step: 10
Training loss: 2.435532974411515
Validation loss: 2.52348157378841

Epoch: 162| Step: 0
Training loss: 2.8515026347525922
Validation loss: 2.517164011419621

Epoch: 5| Step: 1
Training loss: 2.6579957498555187
Validation loss: 2.5268485732992834

Epoch: 5| Step: 2
Training loss: 2.1158339336685383
Validation loss: 2.520866977226792

Epoch: 5| Step: 3
Training loss: 2.459138533628328
Validation loss: 2.5059681125015145

Epoch: 5| Step: 4
Training loss: 2.8540446308712277
Validation loss: 2.511481289164432

Epoch: 5| Step: 5
Training loss: 2.6490858516584144
Validation loss: 2.532546732776377

Epoch: 5| Step: 6
Training loss: 2.594381783995079
Validation loss: 2.5146744871876017

Epoch: 5| Step: 7
Training loss: 2.3591385274448817
Validation loss: 2.5074476190590897

Epoch: 5| Step: 8
Training loss: 3.3130653906487937
Validation loss: 2.521286184310435

Epoch: 5| Step: 9
Training loss: 2.760590275517359
Validation loss: 2.526783248965512

Epoch: 5| Step: 10
Training loss: 2.1174514437065795
Validation loss: 2.5523216358970755

Epoch: 163| Step: 0
Training loss: 2.469783035664391
Validation loss: 2.479136246449512

Epoch: 5| Step: 1
Training loss: 2.5833957315928124
Validation loss: 2.528091666149672

Epoch: 5| Step: 2
Training loss: 2.617286885210685
Validation loss: 2.515509478745116

Epoch: 5| Step: 3
Training loss: 3.2785272836903987
Validation loss: 2.5220181365580356

Epoch: 5| Step: 4
Training loss: 2.364385274470989
Validation loss: 2.5333144098437548

Epoch: 5| Step: 5
Training loss: 2.4252986212845595
Validation loss: 2.4893559088422674

Epoch: 5| Step: 6
Training loss: 2.535333518485739
Validation loss: 2.5118001513440613

Epoch: 5| Step: 7
Training loss: 2.1441377650523488
Validation loss: 2.540351599752011

Epoch: 5| Step: 8
Training loss: 2.8619398276923196
Validation loss: 2.526734107996255

Epoch: 5| Step: 9
Training loss: 2.9376866707434726
Validation loss: 2.5342147461486615

Epoch: 5| Step: 10
Training loss: 2.729994485730761
Validation loss: 2.485863208202708

Epoch: 164| Step: 0
Training loss: 3.1158909599020026
Validation loss: 2.5118426820224817

Epoch: 5| Step: 1
Training loss: 2.276302564203636
Validation loss: 2.5083375031824935

Epoch: 5| Step: 2
Training loss: 2.8517536256047613
Validation loss: 2.4873518225788964

Epoch: 5| Step: 3
Training loss: 2.330968669044197
Validation loss: 2.504114983110806

Epoch: 5| Step: 4
Training loss: 2.0094666550587417
Validation loss: 2.519483032935323

Epoch: 5| Step: 5
Training loss: 2.177450474593032
Validation loss: 2.473768309121102

Epoch: 5| Step: 6
Training loss: 2.6610834463597697
Validation loss: 2.485256432636386

Epoch: 5| Step: 7
Training loss: 3.246599031823533
Validation loss: 2.4994437983357765

Epoch: 5| Step: 8
Training loss: 3.180458369058915
Validation loss: 2.4890539308633794

Epoch: 5| Step: 9
Training loss: 2.7685416838594525
Validation loss: 2.540593108327279

Epoch: 5| Step: 10
Training loss: 2.2958959452081324
Validation loss: 2.5102395405501414

Epoch: 165| Step: 0
Training loss: 3.0581250763407217
Validation loss: 2.475301708689122

Epoch: 5| Step: 1
Training loss: 2.2529736048696845
Validation loss: 2.5098803023849436

Epoch: 5| Step: 2
Training loss: 2.3546421504827086
Validation loss: 2.5131783010752122

Epoch: 5| Step: 3
Training loss: 2.735192923148797
Validation loss: 2.5488569554177354

Epoch: 5| Step: 4
Training loss: 2.4736974853061184
Validation loss: 2.495090196927999

Epoch: 5| Step: 5
Training loss: 2.1615696399632016
Validation loss: 2.50441060619387

Epoch: 5| Step: 6
Training loss: 2.8106470573973006
Validation loss: 2.5264880793277937

Epoch: 5| Step: 7
Training loss: 3.0859980710036554
Validation loss: 2.530059855718261

Epoch: 5| Step: 8
Training loss: 2.296843859403059
Validation loss: 2.531020745201207

Epoch: 5| Step: 9
Training loss: 2.7772972221071903
Validation loss: 2.5325448013497485

Epoch: 5| Step: 10
Training loss: 2.943221992065851
Validation loss: 2.521472359388276

Epoch: 166| Step: 0
Training loss: 3.222356312983514
Validation loss: 2.5091341977709485

Epoch: 5| Step: 1
Training loss: 2.5732681302060385
Validation loss: 2.5128349985718144

Epoch: 5| Step: 2
Training loss: 2.626592970199897
Validation loss: 2.5374834207328285

Epoch: 5| Step: 3
Training loss: 2.9527313131474733
Validation loss: 2.532895659090891

Epoch: 5| Step: 4
Training loss: 2.134424962454553
Validation loss: 2.5457257868221053

Epoch: 5| Step: 5
Training loss: 2.4685446738314583
Validation loss: 2.509856520051786

Epoch: 5| Step: 6
Training loss: 2.1676191168308687
Validation loss: 2.4966063795260625

Epoch: 5| Step: 7
Training loss: 2.9806727268319784
Validation loss: 2.49720024928923

Epoch: 5| Step: 8
Training loss: 2.9248397391993977
Validation loss: 2.4965398325883337

Epoch: 5| Step: 9
Training loss: 2.3574005353541714
Validation loss: 2.5449977649975706

Epoch: 5| Step: 10
Training loss: 2.446484757017873
Validation loss: 2.5187826321577926

Epoch: 167| Step: 0
Training loss: 2.3481946381799053
Validation loss: 2.482767304281494

Epoch: 5| Step: 1
Training loss: 2.5071773497180954
Validation loss: 2.5208691194686295

Epoch: 5| Step: 2
Training loss: 2.452496004558268
Validation loss: 2.5302938480736326

Epoch: 5| Step: 3
Training loss: 3.035925651052051
Validation loss: 2.50413171454655

Epoch: 5| Step: 4
Training loss: 2.8595024038812653
Validation loss: 2.5222639055082685

Epoch: 5| Step: 5
Training loss: 3.2054806862705805
Validation loss: 2.541491129391521

Epoch: 5| Step: 6
Training loss: 2.315424333081114
Validation loss: 2.5402454507587087

Epoch: 5| Step: 7
Training loss: 3.0864394926452476
Validation loss: 2.515003302552479

Epoch: 5| Step: 8
Training loss: 2.569076844001226
Validation loss: 2.496551477352269

Epoch: 5| Step: 9
Training loss: 2.233068764611361
Validation loss: 2.5165051068649906

Epoch: 5| Step: 10
Training loss: 2.102372024215587
Validation loss: 2.4907212317318406

Epoch: 168| Step: 0
Training loss: 2.6698463278562823
Validation loss: 2.4984626904040588

Epoch: 5| Step: 1
Training loss: 2.8422035791446634
Validation loss: 2.5376165566821065

Epoch: 5| Step: 2
Training loss: 2.964805954603051
Validation loss: 2.5217494847312834

Epoch: 5| Step: 3
Training loss: 2.7588121369333702
Validation loss: 2.4991868716897527

Epoch: 5| Step: 4
Training loss: 2.6182989237284966
Validation loss: 2.5101772768295505

Epoch: 5| Step: 5
Training loss: 2.441459862692589
Validation loss: 2.5099878484022193

Epoch: 5| Step: 6
Training loss: 2.712473673187332
Validation loss: 2.5100723790971915

Epoch: 5| Step: 7
Training loss: 2.476137816782704
Validation loss: 2.508196368729968

Epoch: 5| Step: 8
Training loss: 2.5715447808300858
Validation loss: 2.4773059848365886

Epoch: 5| Step: 9
Training loss: 2.4136495391311064
Validation loss: 2.508888577794568

Epoch: 5| Step: 10
Training loss: 2.391796448361927
Validation loss: 2.529383368245966

Epoch: 169| Step: 0
Training loss: 3.1802505631969247
Validation loss: 2.528720747178462

Epoch: 5| Step: 1
Training loss: 2.8599109251649657
Validation loss: 2.5307928401963884

Epoch: 5| Step: 2
Training loss: 3.350188429358419
Validation loss: 2.5073006166658756

Epoch: 5| Step: 3
Training loss: 2.3151734852720516
Validation loss: 2.5246930938063654

Epoch: 5| Step: 4
Training loss: 1.8777748555882356
Validation loss: 2.493092276026183

Epoch: 5| Step: 5
Training loss: 2.2700646408893115
Validation loss: 2.507339054100562

Epoch: 5| Step: 6
Training loss: 2.3173525647915336
Validation loss: 2.5197450354268187

Epoch: 5| Step: 7
Training loss: 2.7368030340189593
Validation loss: 2.521886465403356

Epoch: 5| Step: 8
Training loss: 2.4028622447647043
Validation loss: 2.512387347033751

Epoch: 5| Step: 9
Training loss: 3.0445950316183557
Validation loss: 2.5432121329626405

Epoch: 5| Step: 10
Training loss: 2.3169648653213946
Validation loss: 2.525903333439482

Epoch: 170| Step: 0
Training loss: 3.2291273217214114
Validation loss: 2.5105773131627114

Epoch: 5| Step: 1
Training loss: 2.329770115002191
Validation loss: 2.535491478779748

Epoch: 5| Step: 2
Training loss: 2.816775738186237
Validation loss: 2.5205035945298917

Epoch: 5| Step: 3
Training loss: 2.700323163225478
Validation loss: 2.497434230568591

Epoch: 5| Step: 4
Training loss: 2.9777072097077655
Validation loss: 2.5691609891901437

Epoch: 5| Step: 5
Training loss: 2.2982190410180765
Validation loss: 2.4992815636383154

Epoch: 5| Step: 6
Training loss: 1.9675250405410982
Validation loss: 2.538100271341495

Epoch: 5| Step: 7
Training loss: 2.8158469736070484
Validation loss: 2.4979696909945557

Epoch: 5| Step: 8
Training loss: 2.823355684008023
Validation loss: 2.490515242872627

Epoch: 5| Step: 9
Training loss: 2.184130444023156
Validation loss: 2.5319170400204523

Epoch: 5| Step: 10
Training loss: 2.432979304108436
Validation loss: 2.528767094567039

Epoch: 171| Step: 0
Training loss: 2.652927879316591
Validation loss: 2.486800477361947

Epoch: 5| Step: 1
Training loss: 2.1753071622888513
Validation loss: 2.5073008405868804

Epoch: 5| Step: 2
Training loss: 3.360311829992508
Validation loss: 2.5485152752903533

Epoch: 5| Step: 3
Training loss: 2.6809934764584917
Validation loss: 2.494829178131051

Epoch: 5| Step: 4
Training loss: 2.1758368055281103
Validation loss: 2.5023553848028133

Epoch: 5| Step: 5
Training loss: 2.752208343215559
Validation loss: 2.521004987171012

Epoch: 5| Step: 6
Training loss: 2.4192360559652757
Validation loss: 2.4970889380848384

Epoch: 5| Step: 7
Training loss: 2.764183746490597
Validation loss: 2.489906643931408

Epoch: 5| Step: 8
Training loss: 2.7027721726020837
Validation loss: 2.4751563906447682

Epoch: 5| Step: 9
Training loss: 2.4590934505010416
Validation loss: 2.5059765503073503

Epoch: 5| Step: 10
Training loss: 2.5869874234596084
Validation loss: 2.527932859117976

Epoch: 172| Step: 0
Training loss: 2.86646130587713
Validation loss: 2.5510985178035934

Epoch: 5| Step: 1
Training loss: 2.7180820389942473
Validation loss: 2.5411913397210197

Epoch: 5| Step: 2
Training loss: 2.7601317252638697
Validation loss: 2.498991159727542

Epoch: 5| Step: 3
Training loss: 2.4591021763321175
Validation loss: 2.510858858242334

Epoch: 5| Step: 4
Training loss: 2.482327943430882
Validation loss: 2.5291931990103014

Epoch: 5| Step: 5
Training loss: 3.387870126471121
Validation loss: 2.5157016188863417

Epoch: 5| Step: 6
Training loss: 2.6751270691825453
Validation loss: 2.5231307501827223

Epoch: 5| Step: 7
Training loss: 2.3372852940813527
Validation loss: 2.5328120419316233

Epoch: 5| Step: 8
Training loss: 2.2933712139808433
Validation loss: 2.5165671192857917

Epoch: 5| Step: 9
Training loss: 2.133128048536669
Validation loss: 2.538184690985351

Epoch: 5| Step: 10
Training loss: 2.586921804206989
Validation loss: 2.5019636369211735

Epoch: 173| Step: 0
Training loss: 2.929151969283136
Validation loss: 2.532228553901252

Epoch: 5| Step: 1
Training loss: 2.9173656897531757
Validation loss: 2.5075232742458424

Epoch: 5| Step: 2
Training loss: 2.4605801761915416
Validation loss: 2.533514636578597

Epoch: 5| Step: 3
Training loss: 2.38515479859034
Validation loss: 2.5082419501207935

Epoch: 5| Step: 4
Training loss: 2.7767228560545862
Validation loss: 2.5297032609310373

Epoch: 5| Step: 5
Training loss: 3.112584896538435
Validation loss: 2.490136796107983

Epoch: 5| Step: 6
Training loss: 2.196818639431121
Validation loss: 2.517617714014534

Epoch: 5| Step: 7
Training loss: 2.3239586949116626
Validation loss: 2.5173053900964253

Epoch: 5| Step: 8
Training loss: 2.5673202211013297
Validation loss: 2.530198188994813

Epoch: 5| Step: 9
Training loss: 2.750828704814682
Validation loss: 2.5306943959451336

Epoch: 5| Step: 10
Training loss: 2.472117481322678
Validation loss: 2.481493547039735

Epoch: 174| Step: 0
Training loss: 3.215766783499602
Validation loss: 2.5061847007955156

Epoch: 5| Step: 1
Training loss: 1.818523657698634
Validation loss: 2.520172875359272

Epoch: 5| Step: 2
Training loss: 2.4808163857342977
Validation loss: 2.546912678129648

Epoch: 5| Step: 3
Training loss: 2.437108326279026
Validation loss: 2.524662881636655

Epoch: 5| Step: 4
Training loss: 2.6703750236963715
Validation loss: 2.533734725452094

Epoch: 5| Step: 5
Training loss: 2.817402022112805
Validation loss: 2.5366418266813073

Epoch: 5| Step: 6
Training loss: 2.8257192421907833
Validation loss: 2.5171532533626255

Epoch: 5| Step: 7
Training loss: 2.313718938469604
Validation loss: 2.49836144586587

Epoch: 5| Step: 8
Training loss: 2.781855913661119
Validation loss: 2.527777475136696

Epoch: 5| Step: 9
Training loss: 2.652298175493256
Validation loss: 2.5182164995883363

Epoch: 5| Step: 10
Training loss: 2.8321058381880313
Validation loss: 2.484488961047839

Epoch: 175| Step: 0
Training loss: 2.6225843668004902
Validation loss: 2.5246994473228828

Epoch: 5| Step: 1
Training loss: 2.4480041704703317
Validation loss: 2.5084680438973046

Epoch: 5| Step: 2
Training loss: 2.1336469310500727
Validation loss: 2.5254899693113404

Epoch: 5| Step: 3
Training loss: 2.6015876104385947
Validation loss: 2.550523338325101

Epoch: 5| Step: 4
Training loss: 1.573841665081407
Validation loss: 2.5186857969280125

Epoch: 5| Step: 5
Training loss: 2.977730749559153
Validation loss: 2.5083420155191356

Epoch: 5| Step: 6
Training loss: 2.9973010002046236
Validation loss: 2.5244808830585557

Epoch: 5| Step: 7
Training loss: 2.8222483070132593
Validation loss: 2.546180626918621

Epoch: 5| Step: 8
Training loss: 2.9096856267949884
Validation loss: 2.5208411349246442

Epoch: 5| Step: 9
Training loss: 2.864923315969256
Validation loss: 2.5088122750498854

Epoch: 5| Step: 10
Training loss: 2.65104569370486
Validation loss: 2.5227969366273464

Epoch: 176| Step: 0
Training loss: 2.4634719634461155
Validation loss: 2.5443278951671

Epoch: 5| Step: 1
Training loss: 2.506720759826056
Validation loss: 2.5376316448005083

Epoch: 5| Step: 2
Training loss: 3.1980389665874185
Validation loss: 2.5356372497221122

Epoch: 5| Step: 3
Training loss: 2.633891713621126
Validation loss: 2.5030322840919337

Epoch: 5| Step: 4
Training loss: 2.581082860971142
Validation loss: 2.5431190485245745

Epoch: 5| Step: 5
Training loss: 2.601012025622735
Validation loss: 2.532769948397924

Epoch: 5| Step: 6
Training loss: 2.2457526702644164
Validation loss: 2.478475211770858

Epoch: 5| Step: 7
Training loss: 2.352224364556272
Validation loss: 2.498909715588697

Epoch: 5| Step: 8
Training loss: 2.7135094306968894
Validation loss: 2.5052030021490173

Epoch: 5| Step: 9
Training loss: 2.760409507502263
Validation loss: 2.5143014774765935

Epoch: 5| Step: 10
Training loss: 2.7422747910563388
Validation loss: 2.5255230717089963

Epoch: 177| Step: 0
Training loss: 2.4506561101423885
Validation loss: 2.529904617574819

Epoch: 5| Step: 1
Training loss: 3.232018095768418
Validation loss: 2.5064660632083737

Epoch: 5| Step: 2
Training loss: 2.5606715494235295
Validation loss: 2.5006934301502035

Epoch: 5| Step: 3
Training loss: 2.4616630332401694
Validation loss: 2.51633082048185

Epoch: 5| Step: 4
Training loss: 2.585861804234589
Validation loss: 2.5134411188713006

Epoch: 5| Step: 5
Training loss: 2.601421913724409
Validation loss: 2.527933607542327

Epoch: 5| Step: 6
Training loss: 2.6122275653043308
Validation loss: 2.5331116351294716

Epoch: 5| Step: 7
Training loss: 3.1787244383353843
Validation loss: 2.528331289714055

Epoch: 5| Step: 8
Training loss: 2.23643675960896
Validation loss: 2.5583927704656397

Epoch: 5| Step: 9
Training loss: 2.4437890715536636
Validation loss: 2.5267711246255606

Epoch: 5| Step: 10
Training loss: 2.3017329529045756
Validation loss: 2.5110947214867587

Epoch: 178| Step: 0
Training loss: 3.276692304100205
Validation loss: 2.5348341115081436

Epoch: 5| Step: 1
Training loss: 2.3089101610049267
Validation loss: 2.5094478686449664

Epoch: 5| Step: 2
Training loss: 2.9892777520467777
Validation loss: 2.545029895449822

Epoch: 5| Step: 3
Training loss: 2.637314205043739
Validation loss: 2.5243726302046734

Epoch: 5| Step: 4
Training loss: 2.5350394435123835
Validation loss: 2.5331074260018065

Epoch: 5| Step: 5
Training loss: 2.3541045279164927
Validation loss: 2.4939470355010545

Epoch: 5| Step: 6
Training loss: 3.2333429873869663
Validation loss: 2.5343858160090043

Epoch: 5| Step: 7
Training loss: 2.1636660656882882
Validation loss: 2.52644740454174

Epoch: 5| Step: 8
Training loss: 2.881475702080392
Validation loss: 2.4952152230128255

Epoch: 5| Step: 9
Training loss: 2.056991503744795
Validation loss: 2.528396541606172

Epoch: 5| Step: 10
Training loss: 2.1834263609463767
Validation loss: 2.506894622152523

Epoch: 179| Step: 0
Training loss: 2.832735971047256
Validation loss: 2.5056658345338216

Epoch: 5| Step: 1
Training loss: 2.6221847878584046
Validation loss: 2.499404710221459

Epoch: 5| Step: 2
Training loss: 2.135418874848007
Validation loss: 2.5364230877148084

Epoch: 5| Step: 3
Training loss: 2.831732035648202
Validation loss: 2.5400302453114008

Epoch: 5| Step: 4
Training loss: 2.092523357848918
Validation loss: 2.5328928159928896

Epoch: 5| Step: 5
Training loss: 2.4667257387803225
Validation loss: 2.54742490527954

Epoch: 5| Step: 6
Training loss: 2.6065507783844595
Validation loss: 2.515373906861565

Epoch: 5| Step: 7
Training loss: 2.318537588749761
Validation loss: 2.513416061083805

Epoch: 5| Step: 8
Training loss: 2.5895746473891488
Validation loss: 2.536410321143444

Epoch: 5| Step: 9
Training loss: 3.1254299630968587
Validation loss: 2.4732279459173556

Epoch: 5| Step: 10
Training loss: 2.942501760788539
Validation loss: 2.4993216394097097

Epoch: 180| Step: 0
Training loss: 2.5227752855935393
Validation loss: 2.514287649305939

Epoch: 5| Step: 1
Training loss: 2.9720554621926425
Validation loss: 2.5521050640400693

Epoch: 5| Step: 2
Training loss: 1.7057624483622917
Validation loss: 2.493215841421915

Epoch: 5| Step: 3
Training loss: 2.545292087423904
Validation loss: 2.5290817348520545

Epoch: 5| Step: 4
Training loss: 2.705773087341787
Validation loss: 2.532082703661199

Epoch: 5| Step: 5
Training loss: 2.9670250951144754
Validation loss: 2.515958888818419

Epoch: 5| Step: 6
Training loss: 2.46674564939637
Validation loss: 2.5023192988952125

Epoch: 5| Step: 7
Training loss: 3.1322751618941997
Validation loss: 2.509832015335913

Epoch: 5| Step: 8
Training loss: 2.2398001159313687
Validation loss: 2.5152641928831883

Epoch: 5| Step: 9
Training loss: 2.738612265176845
Validation loss: 2.534961486602808

Epoch: 5| Step: 10
Training loss: 2.4856934317918262
Validation loss: 2.533658681237588

Epoch: 181| Step: 0
Training loss: 2.164502921888706
Validation loss: 2.537909162287307

Epoch: 5| Step: 1
Training loss: 3.278269404020871
Validation loss: 2.476023245652296

Epoch: 5| Step: 2
Training loss: 2.400509017371205
Validation loss: 2.514066795608998

Epoch: 5| Step: 3
Training loss: 2.7298999024649286
Validation loss: 2.5082985086925866

Epoch: 5| Step: 4
Training loss: 2.4855983768962453
Validation loss: 2.526107500692315

Epoch: 5| Step: 5
Training loss: 2.8295185175571356
Validation loss: 2.4958316415593416

Epoch: 5| Step: 6
Training loss: 2.4488890211474934
Validation loss: 2.5160915558913475

Epoch: 5| Step: 7
Training loss: 2.596949063747163
Validation loss: 2.4942716014100137

Epoch: 5| Step: 8
Training loss: 2.1638257279303414
Validation loss: 2.499713878255579

Epoch: 5| Step: 9
Training loss: 2.6609591758145337
Validation loss: 2.515992167561482

Epoch: 5| Step: 10
Training loss: 2.848613562402818
Validation loss: 2.5305984004766273

Epoch: 182| Step: 0
Training loss: 2.6343849987414973
Validation loss: 2.507252278401069

Epoch: 5| Step: 1
Training loss: 2.570294133732349
Validation loss: 2.4933378810203886

Epoch: 5| Step: 2
Training loss: 2.2094585742817823
Validation loss: 2.5322116628813043

Epoch: 5| Step: 3
Training loss: 2.2983661404546445
Validation loss: 2.5367654294155084

Epoch: 5| Step: 4
Training loss: 2.670729720733818
Validation loss: 2.508070740673744

Epoch: 5| Step: 5
Training loss: 3.0509834955169772
Validation loss: 2.508803386945355

Epoch: 5| Step: 6
Training loss: 2.453786287044284
Validation loss: 2.510272385506071

Epoch: 5| Step: 7
Training loss: 2.2016925889750496
Validation loss: 2.523781731138534

Epoch: 5| Step: 8
Training loss: 2.4935258960652775
Validation loss: 2.5298418184051474

Epoch: 5| Step: 9
Training loss: 3.1016415218404725
Validation loss: 2.513166543616113

Epoch: 5| Step: 10
Training loss: 2.9356599279627886
Validation loss: 2.48389429905943

Epoch: 183| Step: 0
Training loss: 2.7487029571462895
Validation loss: 2.5410526772309265

Epoch: 5| Step: 1
Training loss: 2.4781606433513086
Validation loss: 2.5103816712175453

Epoch: 5| Step: 2
Training loss: 2.783606227661569
Validation loss: 2.5309892522904147

Epoch: 5| Step: 3
Training loss: 2.245496162861459
Validation loss: 2.521679426996133

Epoch: 5| Step: 4
Training loss: 2.408138079356503
Validation loss: 2.517038333403518

Epoch: 5| Step: 5
Training loss: 2.8002672987462267
Validation loss: 2.5154437417203317

Epoch: 5| Step: 6
Training loss: 2.952014209599398
Validation loss: 2.5322453121843678

Epoch: 5| Step: 7
Training loss: 2.5643506694237286
Validation loss: 2.5339008176042026

Epoch: 5| Step: 8
Training loss: 2.8052793425591003
Validation loss: 2.5265733628471962

Epoch: 5| Step: 9
Training loss: 2.696831670348934
Validation loss: 2.5237226630812644

Epoch: 5| Step: 10
Training loss: 2.0956889042722895
Validation loss: 2.5191399027021575

Epoch: 184| Step: 0
Training loss: 2.6745953013095933
Validation loss: 2.5248164255295893

Epoch: 5| Step: 1
Training loss: 3.014058867630814
Validation loss: 2.540784307104061

Epoch: 5| Step: 2
Training loss: 2.1283164230945464
Validation loss: 2.5194207809153464

Epoch: 5| Step: 3
Training loss: 2.907514399642908
Validation loss: 2.526154517615258

Epoch: 5| Step: 4
Training loss: 2.476667624567941
Validation loss: 2.5081616772163193

Epoch: 5| Step: 5
Training loss: 2.3243199943481767
Validation loss: 2.5227619306765945

Epoch: 5| Step: 6
Training loss: 2.856794349668668
Validation loss: 2.4913381586816277

Epoch: 5| Step: 7
Training loss: 2.778704303291924
Validation loss: 2.5426633169495623

Epoch: 5| Step: 8
Training loss: 2.4907573554697984
Validation loss: 2.4917084101649203

Epoch: 5| Step: 9
Training loss: 2.5225626370807137
Validation loss: 2.5145281438173375

Epoch: 5| Step: 10
Training loss: 2.430283648101491
Validation loss: 2.528929139261009

Epoch: 185| Step: 0
Training loss: 2.423661391481463
Validation loss: 2.512689137787088

Epoch: 5| Step: 1
Training loss: 2.508441596583273
Validation loss: 2.511165574758748

Epoch: 5| Step: 2
Training loss: 2.7627061861861835
Validation loss: 2.5375982512947477

Epoch: 5| Step: 3
Training loss: 2.8951194670013964
Validation loss: 2.5041580661008123

Epoch: 5| Step: 4
Training loss: 2.44941635186481
Validation loss: 2.4995089551168235

Epoch: 5| Step: 5
Training loss: 2.3371487032223945
Validation loss: 2.509917066067069

Epoch: 5| Step: 6
Training loss: 2.5464967786168233
Validation loss: 2.5180172392289157

Epoch: 5| Step: 7
Training loss: 2.854528436681827
Validation loss: 2.5241430940591307

Epoch: 5| Step: 8
Training loss: 2.5887260959761256
Validation loss: 2.506029988743567

Epoch: 5| Step: 9
Training loss: 2.8460931870624613
Validation loss: 2.521407744754312

Epoch: 5| Step: 10
Training loss: 2.3480167461233497
Validation loss: 2.5490980996766894

Epoch: 186| Step: 0
Training loss: 2.7093021616225115
Validation loss: 2.5177427323164654

Epoch: 5| Step: 1
Training loss: 3.025380695442469
Validation loss: 2.527674850957322

Epoch: 5| Step: 2
Training loss: 2.906217513364296
Validation loss: 2.51090949835124

Epoch: 5| Step: 3
Training loss: 2.4523918854411977
Validation loss: 2.47819207623154

Epoch: 5| Step: 4
Training loss: 1.8921995305908188
Validation loss: 2.5225964537119085

Epoch: 5| Step: 5
Training loss: 2.0423597080791276
Validation loss: 2.4968549757853764

Epoch: 5| Step: 6
Training loss: 2.771375894607703
Validation loss: 2.4927010130750458

Epoch: 5| Step: 7
Training loss: 2.344550441115537
Validation loss: 2.528774864754141

Epoch: 5| Step: 8
Training loss: 2.7201796532653533
Validation loss: 2.5299992673636864

Epoch: 5| Step: 9
Training loss: 3.15802646914328
Validation loss: 2.525882503737488

Epoch: 5| Step: 10
Training loss: 2.344252977442348
Validation loss: 2.5254935993286582

Epoch: 187| Step: 0
Training loss: 3.020410723009198
Validation loss: 2.5076549440795803

Epoch: 5| Step: 1
Training loss: 2.3323046142255084
Validation loss: 2.507575461069331

Epoch: 5| Step: 2
Training loss: 2.1499312323284796
Validation loss: 2.540869464920529

Epoch: 5| Step: 3
Training loss: 2.6116940363959356
Validation loss: 2.536040949161976

Epoch: 5| Step: 4
Training loss: 2.608707548197284
Validation loss: 2.5542422493626953

Epoch: 5| Step: 5
Training loss: 3.0140428889513147
Validation loss: 2.542697879529324

Epoch: 5| Step: 6
Training loss: 2.993962570639394
Validation loss: 2.517009103897887

Epoch: 5| Step: 7
Training loss: 2.4042911235080475
Validation loss: 2.5249245172096293

Epoch: 5| Step: 8
Training loss: 2.492485674297521
Validation loss: 2.5317383455501608

Epoch: 5| Step: 9
Training loss: 2.5556762834955697
Validation loss: 2.5151503317713497

Epoch: 5| Step: 10
Training loss: 2.416888215882416
Validation loss: 2.5068632004425186

Epoch: 188| Step: 0
Training loss: 2.8532865146408533
Validation loss: 2.547773874856503

Epoch: 5| Step: 1
Training loss: 2.1489967311942553
Validation loss: 2.5266128575912026

Epoch: 5| Step: 2
Training loss: 2.2987671408913934
Validation loss: 2.5181464942353164

Epoch: 5| Step: 3
Training loss: 2.5991586571028096
Validation loss: 2.5519237331957356

Epoch: 5| Step: 4
Training loss: 2.2215323397222657
Validation loss: 2.522346129775556

Epoch: 5| Step: 5
Training loss: 2.2495420837671394
Validation loss: 2.529949431913729

Epoch: 5| Step: 6
Training loss: 3.3028686423957128
Validation loss: 2.5556658340113105

Epoch: 5| Step: 7
Training loss: 2.831563303203951
Validation loss: 2.5225781882141165

Epoch: 5| Step: 8
Training loss: 2.6019381231915806
Validation loss: 2.537970127475044

Epoch: 5| Step: 9
Training loss: 2.8495466239770915
Validation loss: 2.5250135675011167

Epoch: 5| Step: 10
Training loss: 2.533564980690856
Validation loss: 2.54298555696769

Epoch: 189| Step: 0
Training loss: 2.934620521357083
Validation loss: 2.5216489113397436

Epoch: 5| Step: 1
Training loss: 2.7558841177020916
Validation loss: 2.4939361115045493

Epoch: 5| Step: 2
Training loss: 2.290820179283183
Validation loss: 2.5331878313767415

Epoch: 5| Step: 3
Training loss: 2.4764101962360705
Validation loss: 2.4997649225851153

Epoch: 5| Step: 4
Training loss: 2.6443503922300478
Validation loss: 2.5264289751016653

Epoch: 5| Step: 5
Training loss: 2.4187248169526896
Validation loss: 2.53119860816842

Epoch: 5| Step: 6
Training loss: 2.144522355969717
Validation loss: 2.5233045719700096

Epoch: 5| Step: 7
Training loss: 2.7584704081732205
Validation loss: 2.492379007494936

Epoch: 5| Step: 8
Training loss: 2.2753052265693836
Validation loss: 2.5325834245411407

Epoch: 5| Step: 9
Training loss: 3.161550471279288
Validation loss: 2.510107970547157

Epoch: 5| Step: 10
Training loss: 2.4827844098412437
Validation loss: 2.5090584440255004

Epoch: 190| Step: 0
Training loss: 2.3324527327643394
Validation loss: 2.5115056726502525

Epoch: 5| Step: 1
Training loss: 2.6482803163049087
Validation loss: 2.5165602404678507

Epoch: 5| Step: 2
Training loss: 2.4246657504937525
Validation loss: 2.5331922711113215

Epoch: 5| Step: 3
Training loss: 2.9135890709070296
Validation loss: 2.527779429475495

Epoch: 5| Step: 4
Training loss: 1.932302887944819
Validation loss: 2.522489392412663

Epoch: 5| Step: 5
Training loss: 3.0298738797066638
Validation loss: 2.527503066709153

Epoch: 5| Step: 6
Training loss: 2.527848866852257
Validation loss: 2.5328565234501252

Epoch: 5| Step: 7
Training loss: 2.5954541961737707
Validation loss: 2.535079533461426

Epoch: 5| Step: 8
Training loss: 2.7038006241389163
Validation loss: 2.533869363524452

Epoch: 5| Step: 9
Training loss: 2.150495729294496
Validation loss: 2.514714703003863

Epoch: 5| Step: 10
Training loss: 2.9791693698541786
Validation loss: 2.4969069389565397

Epoch: 191| Step: 0
Training loss: 2.277375366619618
Validation loss: 2.4985354779189928

Epoch: 5| Step: 1
Training loss: 3.3547955194005112
Validation loss: 2.52733203308115

Epoch: 5| Step: 2
Training loss: 1.9387128171915315
Validation loss: 2.5127354977567564

Epoch: 5| Step: 3
Training loss: 2.504871009962448
Validation loss: 2.489287374043802

Epoch: 5| Step: 4
Training loss: 2.2866981977211025
Validation loss: 2.528179182205691

Epoch: 5| Step: 5
Training loss: 3.116118054035272
Validation loss: 2.5100970198569175

Epoch: 5| Step: 6
Training loss: 2.487689895665915
Validation loss: 2.467374490871693

Epoch: 5| Step: 7
Training loss: 2.727687395967663
Validation loss: 2.5306725014782128

Epoch: 5| Step: 8
Training loss: 2.9503921700706766
Validation loss: 2.5349579641956295

Epoch: 5| Step: 9
Training loss: 2.494921007301057
Validation loss: 2.494352130156313

Epoch: 5| Step: 10
Training loss: 2.394474097311924
Validation loss: 2.511557360263969

Epoch: 192| Step: 0
Training loss: 1.9925009088262882
Validation loss: 2.5068658756903432

Epoch: 5| Step: 1
Training loss: 2.5991759938517784
Validation loss: 2.5051037590020235

Epoch: 5| Step: 2
Training loss: 2.5804711041856976
Validation loss: 2.5429420929123014

Epoch: 5| Step: 3
Training loss: 3.008422472646716
Validation loss: 2.5393630689952613

Epoch: 5| Step: 4
Training loss: 2.415933717096318
Validation loss: 2.4928325052812568

Epoch: 5| Step: 5
Training loss: 2.3911955906709594
Validation loss: 2.4997121265752056

Epoch: 5| Step: 6
Training loss: 2.7799650502923896
Validation loss: 2.557938461724671

Epoch: 5| Step: 7
Training loss: 2.6933454771838226
Validation loss: 2.511589537784967

Epoch: 5| Step: 8
Training loss: 2.7278823936931005
Validation loss: 2.5633833168364952

Epoch: 5| Step: 9
Training loss: 2.864445594019232
Validation loss: 2.5504047477938445

Epoch: 5| Step: 10
Training loss: 2.234318339022887
Validation loss: 2.5116084425497784

Epoch: 193| Step: 0
Training loss: 2.476080814534081
Validation loss: 2.5197967798924306

Epoch: 5| Step: 1
Training loss: 2.158674452740343
Validation loss: 2.536754458885568

Epoch: 5| Step: 2
Training loss: 2.7895974893664217
Validation loss: 2.548104900251345

Epoch: 5| Step: 3
Training loss: 2.262409532961799
Validation loss: 2.5443658921290107

Epoch: 5| Step: 4
Training loss: 2.317803975964338
Validation loss: 2.508046371323896

Epoch: 5| Step: 5
Training loss: 3.5144822361456876
Validation loss: 2.504149009960796

Epoch: 5| Step: 6
Training loss: 2.529669939608117
Validation loss: 2.520742383384203

Epoch: 5| Step: 7
Training loss: 2.8264827280507117
Validation loss: 2.484670953554846

Epoch: 5| Step: 8
Training loss: 2.500135608809843
Validation loss: 2.51900783074051

Epoch: 5| Step: 9
Training loss: 2.8770645026811428
Validation loss: 2.5344782653214195

Epoch: 5| Step: 10
Training loss: 1.6653885550087262
Validation loss: 2.5273460160829626

Epoch: 194| Step: 0
Training loss: 3.0438809282471415
Validation loss: 2.524482555606269

Epoch: 5| Step: 1
Training loss: 2.163736587385878
Validation loss: 2.5249540571518483

Epoch: 5| Step: 2
Training loss: 3.1243509763040906
Validation loss: 2.4973273947924994

Epoch: 5| Step: 3
Training loss: 2.9674540049998335
Validation loss: 2.5281645690278634

Epoch: 5| Step: 4
Training loss: 2.0226905651872604
Validation loss: 2.5019109938751307

Epoch: 5| Step: 5
Training loss: 2.762091669482568
Validation loss: 2.555074757189365

Epoch: 5| Step: 6
Training loss: 2.6630877280430356
Validation loss: 2.5096406169020016

Epoch: 5| Step: 7
Training loss: 2.3547056363223042
Validation loss: 2.495495534400599

Epoch: 5| Step: 8
Training loss: 2.6921788672133338
Validation loss: 2.497203721268141

Epoch: 5| Step: 9
Training loss: 1.888904829363163
Validation loss: 2.5089639872158087

Epoch: 5| Step: 10
Training loss: 2.472062315275788
Validation loss: 2.5248362374887154

Epoch: 195| Step: 0
Training loss: 2.7622311560535002
Validation loss: 2.512039749668782

Epoch: 5| Step: 1
Training loss: 2.9616640352041745
Validation loss: 2.495754410616532

Epoch: 5| Step: 2
Training loss: 2.2262959638645268
Validation loss: 2.515305682464661

Epoch: 5| Step: 3
Training loss: 3.1907640088742304
Validation loss: 2.5358744077986093

Epoch: 5| Step: 4
Training loss: 2.5676862755705607
Validation loss: 2.5323873704482605

Epoch: 5| Step: 5
Training loss: 2.5628279499378546
Validation loss: 2.505891976080376

Epoch: 5| Step: 6
Training loss: 2.2769450497905357
Validation loss: 2.5490825272933217

Epoch: 5| Step: 7
Training loss: 2.341404873297372
Validation loss: 2.502719220683169

Epoch: 5| Step: 8
Training loss: 2.386058759824341
Validation loss: 2.558383377220118

Epoch: 5| Step: 9
Training loss: 2.3878679521240294
Validation loss: 2.5272615884120415

Epoch: 5| Step: 10
Training loss: 2.731088723455714
Validation loss: 2.5330918717013886

Epoch: 196| Step: 0
Training loss: 2.264609694714957
Validation loss: 2.52733101414992

Epoch: 5| Step: 1
Training loss: 2.205989625603775
Validation loss: 2.5111530391369428

Epoch: 5| Step: 2
Training loss: 2.517101731073409
Validation loss: 2.5268633675765133

Epoch: 5| Step: 3
Training loss: 2.5023492265796787
Validation loss: 2.4943582875676524

Epoch: 5| Step: 4
Training loss: 2.158606306019513
Validation loss: 2.5279798856983584

Epoch: 5| Step: 5
Training loss: 3.3650916850280645
Validation loss: 2.5334090587322393

Epoch: 5| Step: 6
Training loss: 2.4346987938670996
Validation loss: 2.5041766031371937

Epoch: 5| Step: 7
Training loss: 2.5357499801303276
Validation loss: 2.5352153570518685

Epoch: 5| Step: 8
Training loss: 2.5291968602028416
Validation loss: 2.51357060307542

Epoch: 5| Step: 9
Training loss: 2.9547786220497576
Validation loss: 2.539944676822277

Epoch: 5| Step: 10
Training loss: 2.9307816967081948
Validation loss: 2.510681237118455

Epoch: 197| Step: 0
Training loss: 3.0577402300278966
Validation loss: 2.5163815552469133

Epoch: 5| Step: 1
Training loss: 2.969835905942875
Validation loss: 2.5374428241987927

Epoch: 5| Step: 2
Training loss: 2.331555597560693
Validation loss: 2.551836742134544

Epoch: 5| Step: 3
Training loss: 2.399704291087105
Validation loss: 2.549527538749483

Epoch: 5| Step: 4
Training loss: 2.2623916178503514
Validation loss: 2.5462781683818356

Epoch: 5| Step: 5
Training loss: 2.3824181402339453
Validation loss: 2.4967409877371365

Epoch: 5| Step: 6
Training loss: 2.5035736291540256
Validation loss: 2.4925128535247225

Epoch: 5| Step: 7
Training loss: 2.7675379802024023
Validation loss: 2.5175930287413806

Epoch: 5| Step: 8
Training loss: 2.4528192220229545
Validation loss: 2.50844004517873

Epoch: 5| Step: 9
Training loss: 2.9946223379722725
Validation loss: 2.55770422051264

Epoch: 5| Step: 10
Training loss: 2.0337969730816456
Validation loss: 2.532179758551396

Epoch: 198| Step: 0
Training loss: 2.910167064262625
Validation loss: 2.5368853467303385

Epoch: 5| Step: 1
Training loss: 2.912591066696758
Validation loss: 2.5004757049155404

Epoch: 5| Step: 2
Training loss: 1.8886333094765073
Validation loss: 2.5218296636403372

Epoch: 5| Step: 3
Training loss: 2.6349446071180638
Validation loss: 2.5413953198195416

Epoch: 5| Step: 4
Training loss: 2.007842423627939
Validation loss: 2.5322736773987042

Epoch: 5| Step: 5
Training loss: 2.6052596481579466
Validation loss: 2.5528604552713747

Epoch: 5| Step: 6
Training loss: 2.895498754992157
Validation loss: 2.5433424904084214

Epoch: 5| Step: 7
Training loss: 2.543674915902051
Validation loss: 2.520396320237017

Epoch: 5| Step: 8
Training loss: 2.411851283794841
Validation loss: 2.517259086792269

Epoch: 5| Step: 9
Training loss: 2.3358516613552758
Validation loss: 2.4858700043806463

Epoch: 5| Step: 10
Training loss: 3.254962653489338
Validation loss: 2.5437604072863627

Epoch: 199| Step: 0
Training loss: 2.07347033085879
Validation loss: 2.500444773620126

Epoch: 5| Step: 1
Training loss: 2.8183165697004906
Validation loss: 2.5368395544124573

Epoch: 5| Step: 2
Training loss: 2.44282566160219
Validation loss: 2.5137575678349595

Epoch: 5| Step: 3
Training loss: 2.9280047250511525
Validation loss: 2.5207788666105775

Epoch: 5| Step: 4
Training loss: 2.653512508997554
Validation loss: 2.555539567119215

Epoch: 5| Step: 5
Training loss: 2.866067028169603
Validation loss: 2.5043257031999113

Epoch: 5| Step: 6
Training loss: 2.6626438155756107
Validation loss: 2.5530658647950073

Epoch: 5| Step: 7
Training loss: 2.380059725228402
Validation loss: 2.496374218449727

Epoch: 5| Step: 8
Training loss: 2.684703436444423
Validation loss: 2.510158908706331

Epoch: 5| Step: 9
Training loss: 2.2242121555349863
Validation loss: 2.52124222365012

Epoch: 5| Step: 10
Training loss: 2.565170571230942
Validation loss: 2.468920765011509

Epoch: 200| Step: 0
Training loss: 2.6497613079608247
Validation loss: 2.5308439718335105

Epoch: 5| Step: 1
Training loss: 2.3813682306529955
Validation loss: 2.511045567526521

Epoch: 5| Step: 2
Training loss: 3.075561075272994
Validation loss: 2.501962251592047

Epoch: 5| Step: 3
Training loss: 2.653323727051999
Validation loss: 2.5385804895561663

Epoch: 5| Step: 4
Training loss: 2.8436698483081257
Validation loss: 2.5033336050685753

Epoch: 5| Step: 5
Training loss: 2.0717921313806156
Validation loss: 2.5176069833533856

Epoch: 5| Step: 6
Training loss: 3.10687155079348
Validation loss: 2.50310913480748

Epoch: 5| Step: 7
Training loss: 2.409247080057862
Validation loss: 2.5215101192059897

Epoch: 5| Step: 8
Training loss: 2.6268335932087346
Validation loss: 2.507398976387952

Epoch: 5| Step: 9
Training loss: 2.1550798419933797
Validation loss: 2.5166788952774906

Epoch: 5| Step: 10
Training loss: 2.3855665956603103
Validation loss: 2.5416843555573907

Epoch: 201| Step: 0
Training loss: 2.4072242845133744
Validation loss: 2.5095230314078165

Epoch: 5| Step: 1
Training loss: 2.8360952118035527
Validation loss: 2.524631059615133

Epoch: 5| Step: 2
Training loss: 2.327348413171415
Validation loss: 2.494279899944963

Epoch: 5| Step: 3
Training loss: 2.436541735746671
Validation loss: 2.5401085977170985

Epoch: 5| Step: 4
Training loss: 2.9052317486504755
Validation loss: 2.5520050063595736

Epoch: 5| Step: 5
Training loss: 2.4926446477457036
Validation loss: 2.538788179861272

Epoch: 5| Step: 6
Training loss: 2.6474206823583333
Validation loss: 2.5347953971998423

Epoch: 5| Step: 7
Training loss: 2.8976895171781027
Validation loss: 2.509637100837913

Epoch: 5| Step: 8
Training loss: 2.5356853855719703
Validation loss: 2.5104591787445067

Epoch: 5| Step: 9
Training loss: 2.269538708672931
Validation loss: 2.5102519152882934

Epoch: 5| Step: 10
Training loss: 2.571843395757414
Validation loss: 2.53690714109332

Epoch: 202| Step: 0
Training loss: 2.1253694325368384
Validation loss: 2.5010012446978194

Epoch: 5| Step: 1
Training loss: 3.1420491344123698
Validation loss: 2.524014159343298

Epoch: 5| Step: 2
Training loss: 1.922474961334797
Validation loss: 2.510777143548706

Epoch: 5| Step: 3
Training loss: 1.9889946577634265
Validation loss: 2.5447499579606894

Epoch: 5| Step: 4
Training loss: 3.764216369296262
Validation loss: 2.5332002124179342

Epoch: 5| Step: 5
Training loss: 2.344375018387024
Validation loss: 2.525726312544867

Epoch: 5| Step: 6
Training loss: 2.1178742030593156
Validation loss: 2.5240166163198783

Epoch: 5| Step: 7
Training loss: 2.8749588673178494
Validation loss: 2.51904557356258

Epoch: 5| Step: 8
Training loss: 2.096446905197519
Validation loss: 2.5468492534943348

Epoch: 5| Step: 9
Training loss: 2.6167594901303044
Validation loss: 2.548364482183234

Epoch: 5| Step: 10
Training loss: 2.611957665326715
Validation loss: 2.5124227393665612

Epoch: 203| Step: 0
Training loss: 2.563051769119247
Validation loss: 2.5586126200789443

Epoch: 5| Step: 1
Training loss: 2.346399970812428
Validation loss: 2.525760297938086

Epoch: 5| Step: 2
Training loss: 2.637206081989854
Validation loss: 2.543884508649706

Epoch: 5| Step: 3
Training loss: 2.428648109988534
Validation loss: 2.5352577780589165

Epoch: 5| Step: 4
Training loss: 2.5642922809302715
Validation loss: 2.5344722761857676

Epoch: 5| Step: 5
Training loss: 2.1510479967764633
Validation loss: 2.5448482070452547

Epoch: 5| Step: 6
Training loss: 2.9033984890038274
Validation loss: 2.5323588845189007

Epoch: 5| Step: 7
Training loss: 3.172233072749649
Validation loss: 2.4942015458331195

Epoch: 5| Step: 8
Training loss: 2.218760100865542
Validation loss: 2.5134409158967794

Epoch: 5| Step: 9
Training loss: 2.3562807926017615
Validation loss: 2.5293053414060593

Epoch: 5| Step: 10
Training loss: 2.7548801296346825
Validation loss: 2.5008516163474144

Epoch: 204| Step: 0
Training loss: 2.049836789589024
Validation loss: 2.498145790973204

Epoch: 5| Step: 1
Training loss: 2.958827089466589
Validation loss: 2.516941518660318

Epoch: 5| Step: 2
Training loss: 2.73931264567445
Validation loss: 2.526752888291207

Epoch: 5| Step: 3
Training loss: 2.6537559918171123
Validation loss: 2.4992184370970225

Epoch: 5| Step: 4
Training loss: 2.9103017476212036
Validation loss: 2.5646315142568996

Epoch: 5| Step: 5
Training loss: 2.446167427739502
Validation loss: 2.523951557942204

Epoch: 5| Step: 6
Training loss: 2.893684211790554
Validation loss: 2.5071541527071166

Epoch: 5| Step: 7
Training loss: 2.8966491611187335
Validation loss: 2.5259426153764855

Epoch: 5| Step: 8
Training loss: 2.1432786072922396
Validation loss: 2.514671185115102

Epoch: 5| Step: 9
Training loss: 2.1478561447107163
Validation loss: 2.5143419867881693

Epoch: 5| Step: 10
Training loss: 2.487747111099064
Validation loss: 2.521049320083882

Epoch: 205| Step: 0
Training loss: 3.2043250836390156
Validation loss: 2.515757037594195

Epoch: 5| Step: 1
Training loss: 2.5217718999083236
Validation loss: 2.4945214210572693

Epoch: 5| Step: 2
Training loss: 2.5201748284745364
Validation loss: 2.535180323364001

Epoch: 5| Step: 3
Training loss: 1.8238770126029442
Validation loss: 2.5447582077374777

Epoch: 5| Step: 4
Training loss: 2.1635400024270526
Validation loss: 2.523487765269595

Epoch: 5| Step: 5
Training loss: 2.2766298513195844
Validation loss: 2.5336688926403115

Epoch: 5| Step: 6
Training loss: 2.5740712981764324
Validation loss: 2.508782804598502

Epoch: 5| Step: 7
Training loss: 3.0447436580903564
Validation loss: 2.510716777052038

Epoch: 5| Step: 8
Training loss: 2.813797037078037
Validation loss: 2.501734230514248

Epoch: 5| Step: 9
Training loss: 2.178515813238236
Validation loss: 2.507906132822341

Epoch: 5| Step: 10
Training loss: 2.978970252189124
Validation loss: 2.546173951949182

Epoch: 206| Step: 0
Training loss: 2.3532739032377146
Validation loss: 2.5133710855688753

Epoch: 5| Step: 1
Training loss: 2.679855652807676
Validation loss: 2.572597723194504

Epoch: 5| Step: 2
Training loss: 2.7893852666879178
Validation loss: 2.4989944137857925

Epoch: 5| Step: 3
Training loss: 2.834864053309193
Validation loss: 2.5137971660268694

Epoch: 5| Step: 4
Training loss: 2.2854311525018485
Validation loss: 2.4955670976516005

Epoch: 5| Step: 5
Training loss: 2.8194293808391118
Validation loss: 2.5470091588585237

Epoch: 5| Step: 6
Training loss: 2.746505337470893
Validation loss: 2.506180892440395

Epoch: 5| Step: 7
Training loss: 2.435771427035629
Validation loss: 2.541989217417669

Epoch: 5| Step: 8
Training loss: 2.0002580714616576
Validation loss: 2.5089580362891137

Epoch: 5| Step: 9
Training loss: 2.7349225177285215
Validation loss: 2.536660628118433

Epoch: 5| Step: 10
Training loss: 2.272415927888755
Validation loss: 2.53816972230857

Epoch: 207| Step: 0
Training loss: 2.777208284703979
Validation loss: 2.5488723109219364

Epoch: 5| Step: 1
Training loss: 2.6938264592553525
Validation loss: 2.5175766922566165

Epoch: 5| Step: 2
Training loss: 2.829054874539251
Validation loss: 2.4882612510435496

Epoch: 5| Step: 3
Training loss: 2.7519616153280135
Validation loss: 2.539154680091729

Epoch: 5| Step: 4
Training loss: 2.0970114741705004
Validation loss: 2.498726071058769

Epoch: 5| Step: 5
Training loss: 2.7237633270035673
Validation loss: 2.534365953269691

Epoch: 5| Step: 6
Training loss: 2.8358441802505023
Validation loss: 2.530090022693878

Epoch: 5| Step: 7
Training loss: 2.86264068391069
Validation loss: 2.5258685217683783

Epoch: 5| Step: 8
Training loss: 2.403919032239233
Validation loss: 2.494782082592811

Epoch: 5| Step: 9
Training loss: 2.403047486482537
Validation loss: 2.4897276866154945

Epoch: 5| Step: 10
Training loss: 1.9187934174735486
Validation loss: 2.502807113837123

Epoch: 208| Step: 0
Training loss: 2.6669768113342913
Validation loss: 2.5354227916648164

Epoch: 5| Step: 1
Training loss: 2.123378359298757
Validation loss: 2.5077929133895998

Epoch: 5| Step: 2
Training loss: 2.7208912627599484
Validation loss: 2.5039603633017196

Epoch: 5| Step: 3
Training loss: 2.50676555705643
Validation loss: 2.5281828915118316

Epoch: 5| Step: 4
Training loss: 2.1727971376610893
Validation loss: 2.521168068167545

Epoch: 5| Step: 5
Training loss: 2.5709507854058593
Validation loss: 2.547555785793798

Epoch: 5| Step: 6
Training loss: 2.5231684018669243
Validation loss: 2.526748505220269

Epoch: 5| Step: 7
Training loss: 2.5507700337138544
Validation loss: 2.5459924212107095

Epoch: 5| Step: 8
Training loss: 2.829874919917474
Validation loss: 2.516884572703883

Epoch: 5| Step: 9
Training loss: 2.8033428741123383
Validation loss: 2.5098736662138035

Epoch: 5| Step: 10
Training loss: 2.8772231089904534
Validation loss: 2.5199617285686253

Epoch: 209| Step: 0
Training loss: 2.0194460114839266
Validation loss: 2.5138520556278903

Epoch: 5| Step: 1
Training loss: 2.107403321135888
Validation loss: 2.523405515213517

Epoch: 5| Step: 2
Training loss: 2.8741817139139214
Validation loss: 2.545187363754273

Epoch: 5| Step: 3
Training loss: 2.5162641767622653
Validation loss: 2.529620218270564

Epoch: 5| Step: 4
Training loss: 2.9668007323872225
Validation loss: 2.5295251215395576

Epoch: 5| Step: 5
Training loss: 1.9312528369475332
Validation loss: 2.5319989290426808

Epoch: 5| Step: 6
Training loss: 2.852903453168043
Validation loss: 2.5652194141170837

Epoch: 5| Step: 7
Training loss: 3.0392670942539493
Validation loss: 2.4718279324425243

Epoch: 5| Step: 8
Training loss: 2.9097616657829826
Validation loss: 2.5347712251095027

Epoch: 5| Step: 9
Training loss: 2.0248036136295022
Validation loss: 2.5394452832423657

Epoch: 5| Step: 10
Training loss: 2.4495157308172653
Validation loss: 2.53474276243046

Epoch: 210| Step: 0
Training loss: 2.244120014252067
Validation loss: 2.5316623102287927

Epoch: 5| Step: 1
Training loss: 2.3276622747607174
Validation loss: 2.556678585369594

Epoch: 5| Step: 2
Training loss: 2.8250914263489286
Validation loss: 2.5401485945418814

Epoch: 5| Step: 3
Training loss: 2.777009109531581
Validation loss: 2.5038925569060155

Epoch: 5| Step: 4
Training loss: 2.5315147544013463
Validation loss: 2.5522033468978766

Epoch: 5| Step: 5
Training loss: 2.7828005636774207
Validation loss: 2.5268073696341884

Epoch: 5| Step: 6
Training loss: 2.9800945162025463
Validation loss: 2.5260558144558334

Epoch: 5| Step: 7
Training loss: 2.376522178734216
Validation loss: 2.535278384112083

Epoch: 5| Step: 8
Training loss: 2.0384611799685493
Validation loss: 2.53238888845377

Epoch: 5| Step: 9
Training loss: 2.590055845387617
Validation loss: 2.5331012524669725

Epoch: 5| Step: 10
Training loss: 2.404952752329301
Validation loss: 2.5340235453847675

Epoch: 211| Step: 0
Training loss: 3.073123334411331
Validation loss: 2.4910467350843883

Epoch: 5| Step: 1
Training loss: 2.462590416347246
Validation loss: 2.5203141411973804

Epoch: 5| Step: 2
Training loss: 2.46457164006
Validation loss: 2.5207665404994377

Epoch: 5| Step: 3
Training loss: 2.539847384696338
Validation loss: 2.552037113885359

Epoch: 5| Step: 4
Training loss: 2.700250497429979
Validation loss: 2.531508709138912

Epoch: 5| Step: 5
Training loss: 2.460065996168674
Validation loss: 2.5130122583366146

Epoch: 5| Step: 6
Training loss: 2.471828231658448
Validation loss: 2.508879302177032

Epoch: 5| Step: 7
Training loss: 2.4320638632984855
Validation loss: 2.5128402751361145

Epoch: 5| Step: 8
Training loss: 2.8917356264831127
Validation loss: 2.5216925883856023

Epoch: 5| Step: 9
Training loss: 2.1194859939619968
Validation loss: 2.515773695169742

Epoch: 5| Step: 10
Training loss: 2.289510116818051
Validation loss: 2.5109843713084326

Epoch: 212| Step: 0
Training loss: 2.7566276793238784
Validation loss: 2.533636870061595

Epoch: 5| Step: 1
Training loss: 2.4659565440399605
Validation loss: 2.517101089425205

Epoch: 5| Step: 2
Training loss: 2.6527528966920766
Validation loss: 2.527639236569161

Epoch: 5| Step: 3
Training loss: 2.319142364455039
Validation loss: 2.5290912338852207

Epoch: 5| Step: 4
Training loss: 2.9124790829410836
Validation loss: 2.5029466347816443

Epoch: 5| Step: 5
Training loss: 1.8566645894589724
Validation loss: 2.482645371867451

Epoch: 5| Step: 6
Training loss: 3.1906218854718973
Validation loss: 2.5051511179345507

Epoch: 5| Step: 7
Training loss: 2.694708095729741
Validation loss: 2.509849666763485

Epoch: 5| Step: 8
Training loss: 2.1791416154616514
Validation loss: 2.5083228142695986

Epoch: 5| Step: 9
Training loss: 2.6715280407949877
Validation loss: 2.514829755140648

Epoch: 5| Step: 10
Training loss: 2.237962630197693
Validation loss: 2.5357271880669625

Epoch: 213| Step: 0
Training loss: 2.711830629652619
Validation loss: 2.516555738282788

Epoch: 5| Step: 1
Training loss: 3.076091733827103
Validation loss: 2.4908048605810067

Epoch: 5| Step: 2
Training loss: 2.647018637694953
Validation loss: 2.517915989353246

Epoch: 5| Step: 3
Training loss: 2.5389516013942472
Validation loss: 2.509364473397464

Epoch: 5| Step: 4
Training loss: 2.1734476227733692
Validation loss: 2.523277994667647

Epoch: 5| Step: 5
Training loss: 2.768521446284127
Validation loss: 2.504548039757743

Epoch: 5| Step: 6
Training loss: 2.214007399687079
Validation loss: 2.5348643035857092

Epoch: 5| Step: 7
Training loss: 2.0710195809419027
Validation loss: 2.540030127223846

Epoch: 5| Step: 8
Training loss: 2.830810957460756
Validation loss: 2.5518713884240003

Epoch: 5| Step: 9
Training loss: 2.1685165675407534
Validation loss: 2.552787632013232

Epoch: 5| Step: 10
Training loss: 2.9273284773253847
Validation loss: 2.540398988308759

Epoch: 214| Step: 0
Training loss: 2.3034851041146176
Validation loss: 2.531693287445055

Epoch: 5| Step: 1
Training loss: 2.7162837977617342
Validation loss: 2.536504444165504

Epoch: 5| Step: 2
Training loss: 2.823152670666624
Validation loss: 2.5107093114204924

Epoch: 5| Step: 3
Training loss: 2.2920781084102937
Validation loss: 2.5189597095014586

Epoch: 5| Step: 4
Training loss: 2.8214966884757873
Validation loss: 2.522545471981613

Epoch: 5| Step: 5
Training loss: 2.2773367356573475
Validation loss: 2.509303395559378

Epoch: 5| Step: 6
Training loss: 2.8706501105481212
Validation loss: 2.553662505451629

Epoch: 5| Step: 7
Training loss: 2.0290647048973467
Validation loss: 2.5432924295526593

Epoch: 5| Step: 8
Training loss: 3.069293835964432
Validation loss: 2.5431273257694067

Epoch: 5| Step: 9
Training loss: 2.232139696391456
Validation loss: 2.5141613875141666

Epoch: 5| Step: 10
Training loss: 2.3911083455859568
Validation loss: 2.5205889686540943

Epoch: 215| Step: 0
Training loss: 1.9637539156092234
Validation loss: 2.5179605212292278

Epoch: 5| Step: 1
Training loss: 2.499240187576567
Validation loss: 2.5276710496249146

Epoch: 5| Step: 2
Training loss: 2.6937235253398293
Validation loss: 2.5449316080486635

Epoch: 5| Step: 3
Training loss: 2.6376154074346436
Validation loss: 2.4913298709283374

Epoch: 5| Step: 4
Training loss: 2.6034545433394105
Validation loss: 2.522532823190263

Epoch: 5| Step: 5
Training loss: 2.634127234847944
Validation loss: 2.5430976209099487

Epoch: 5| Step: 6
Training loss: 2.1626088462293755
Validation loss: 2.4989336769927664

Epoch: 5| Step: 7
Training loss: 2.6053120853386678
Validation loss: 2.487120589105333

Epoch: 5| Step: 8
Training loss: 2.6966168329784246
Validation loss: 2.5018143479254427

Epoch: 5| Step: 9
Training loss: 2.8008899534616827
Validation loss: 2.5282584210491374

Epoch: 5| Step: 10
Training loss: 2.881866217066019
Validation loss: 2.515591003029268

Epoch: 216| Step: 0
Training loss: 2.84844783879432
Validation loss: 2.549701317529075

Epoch: 5| Step: 1
Training loss: 2.534549493579972
Validation loss: 2.524887578088648

Epoch: 5| Step: 2
Training loss: 2.5501943850758444
Validation loss: 2.5182357414551633

Epoch: 5| Step: 3
Training loss: 2.328446846035621
Validation loss: 2.485294546703915

Epoch: 5| Step: 4
Training loss: 2.6683395820590574
Validation loss: 2.501620250611061

Epoch: 5| Step: 5
Training loss: 2.544747241945774
Validation loss: 2.5076113915950646

Epoch: 5| Step: 6
Training loss: 2.2743035728180634
Validation loss: 2.5402574285371315

Epoch: 5| Step: 7
Training loss: 2.0043685409589327
Validation loss: 2.5298511139398228

Epoch: 5| Step: 8
Training loss: 3.060303503705154
Validation loss: 2.5403383907223946

Epoch: 5| Step: 9
Training loss: 2.737766451475046
Validation loss: 2.5133718332293844

Epoch: 5| Step: 10
Training loss: 2.3519639594502153
Validation loss: 2.542115729261289

Epoch: 217| Step: 0
Training loss: 1.9825218137909562
Validation loss: 2.508054490378169

Epoch: 5| Step: 1
Training loss: 2.012558371129789
Validation loss: 2.5554392792493594

Epoch: 5| Step: 2
Training loss: 2.916927126199437
Validation loss: 2.521160082860239

Epoch: 5| Step: 3
Training loss: 2.4082563878563428
Validation loss: 2.5495380867958275

Epoch: 5| Step: 4
Training loss: 2.4384486968709695
Validation loss: 2.5256100322087827

Epoch: 5| Step: 5
Training loss: 2.352576357243819
Validation loss: 2.5255961015145485

Epoch: 5| Step: 6
Training loss: 2.514999596233601
Validation loss: 2.559426521669064

Epoch: 5| Step: 7
Training loss: 2.6569746936228977
Validation loss: 2.5327070481986023

Epoch: 5| Step: 8
Training loss: 2.8167556778727056
Validation loss: 2.544348051935362

Epoch: 5| Step: 9
Training loss: 3.304099172613961
Validation loss: 2.5271762515285063

Epoch: 5| Step: 10
Training loss: 2.3420005881539248
Validation loss: 2.559993310201464

Epoch: 218| Step: 0
Training loss: 1.701164587204539
Validation loss: 2.536696879879233

Epoch: 5| Step: 1
Training loss: 2.7578617772354774
Validation loss: 2.5503171641096407

Epoch: 5| Step: 2
Training loss: 2.9817410174660135
Validation loss: 2.5216459935454196

Epoch: 5| Step: 3
Training loss: 2.3061609762734103
Validation loss: 2.495621384582862

Epoch: 5| Step: 4
Training loss: 2.849849991447775
Validation loss: 2.53835916450177

Epoch: 5| Step: 5
Training loss: 2.8785259352763513
Validation loss: 2.504293112952473

Epoch: 5| Step: 6
Training loss: 2.069017343447505
Validation loss: 2.539646372210864

Epoch: 5| Step: 7
Training loss: 2.544879342087497
Validation loss: 2.5541262775834372

Epoch: 5| Step: 8
Training loss: 2.6299299539731424
Validation loss: 2.5385078868205415

Epoch: 5| Step: 9
Training loss: 2.73452121888628
Validation loss: 2.5070388965980084

Epoch: 5| Step: 10
Training loss: 1.9983404546085295
Validation loss: 2.548840234941672

Epoch: 219| Step: 0
Training loss: 2.740068535330477
Validation loss: 2.5262467130595474

Epoch: 5| Step: 1
Training loss: 2.5165988150875087
Validation loss: 2.501788330337748

Epoch: 5| Step: 2
Training loss: 2.404970894238895
Validation loss: 2.5042777021506484

Epoch: 5| Step: 3
Training loss: 2.6580900214445844
Validation loss: 2.534370549753663

Epoch: 5| Step: 4
Training loss: 2.682990438062511
Validation loss: 2.5143912904198142

Epoch: 5| Step: 5
Training loss: 2.1929674758064857
Validation loss: 2.508638380075354

Epoch: 5| Step: 6
Training loss: 2.814671081108825
Validation loss: 2.5032390080243294

Epoch: 5| Step: 7
Training loss: 2.0279116854878527
Validation loss: 2.536300468969048

Epoch: 5| Step: 8
Training loss: 2.6047573691220935
Validation loss: 2.4977762073617056

Epoch: 5| Step: 9
Training loss: 2.53018279007108
Validation loss: 2.4961070555402722

Epoch: 5| Step: 10
Training loss: 2.8653099294528834
Validation loss: 2.5270637037147883

Epoch: 220| Step: 0
Training loss: 3.0867365707929633
Validation loss: 2.516181066525611

Epoch: 5| Step: 1
Training loss: 2.1973899704399176
Validation loss: 2.53435432040549

Epoch: 5| Step: 2
Training loss: 2.6097483110931248
Validation loss: 2.5282549785347923

Epoch: 5| Step: 3
Training loss: 2.6928923868010153
Validation loss: 2.5346562093253504

Epoch: 5| Step: 4
Training loss: 2.6064455869180727
Validation loss: 2.522633082887551

Epoch: 5| Step: 5
Training loss: 2.6525304444891202
Validation loss: 2.52052678768406

Epoch: 5| Step: 6
Training loss: 2.434001270052501
Validation loss: 2.530231969434859

Epoch: 5| Step: 7
Training loss: 2.3182902659244546
Validation loss: 2.500892693074872

Epoch: 5| Step: 8
Training loss: 2.2716294272662028
Validation loss: 2.5413499941170246

Epoch: 5| Step: 9
Training loss: 2.8992319997465694
Validation loss: 2.5593050335883003

Epoch: 5| Step: 10
Training loss: 1.9250991572814116
Validation loss: 2.532216100277761

Epoch: 221| Step: 0
Training loss: 3.0727575918284944
Validation loss: 2.565504747020449

Epoch: 5| Step: 1
Training loss: 2.5538096188211346
Validation loss: 2.4972698532292514

Epoch: 5| Step: 2
Training loss: 1.7827834505594742
Validation loss: 2.5176399022454867

Epoch: 5| Step: 3
Training loss: 2.335419970693528
Validation loss: 2.53281552177549

Epoch: 5| Step: 4
Training loss: 2.3585132768365242
Validation loss: 2.5404802764683585

Epoch: 5| Step: 5
Training loss: 2.9711403308700612
Validation loss: 2.5338390341332166

Epoch: 5| Step: 6
Training loss: 2.5713197537512706
Validation loss: 2.5349697712690165

Epoch: 5| Step: 7
Training loss: 2.384108394251564
Validation loss: 2.55323679014758

Epoch: 5| Step: 8
Training loss: 2.4405344146446577
Validation loss: 2.559279539345943

Epoch: 5| Step: 9
Training loss: 2.605194946726486
Validation loss: 2.5340322570132

Epoch: 5| Step: 10
Training loss: 2.497097333001783
Validation loss: 2.4930551850582785

Epoch: 222| Step: 0
Training loss: 2.546238076543068
Validation loss: 2.495828141992454

Epoch: 5| Step: 1
Training loss: 2.2907105850114386
Validation loss: 2.5212896292222395

Epoch: 5| Step: 2
Training loss: 2.7062682470539032
Validation loss: 2.5482966853005182

Epoch: 5| Step: 3
Training loss: 2.943406841905328
Validation loss: 2.5250196988768843

Epoch: 5| Step: 4
Training loss: 2.9670995039343655
Validation loss: 2.530728056305177

Epoch: 5| Step: 5
Training loss: 3.0350528733802755
Validation loss: 2.5006802248760915

Epoch: 5| Step: 6
Training loss: 2.065380281619498
Validation loss: 2.5260715024044766

Epoch: 5| Step: 7
Training loss: 2.6146437396079034
Validation loss: 2.5750908810596655

Epoch: 5| Step: 8
Training loss: 2.1949060681519503
Validation loss: 2.5060035566193037

Epoch: 5| Step: 9
Training loss: 2.4909955944388322
Validation loss: 2.5176710759213834

Epoch: 5| Step: 10
Training loss: 1.706349740938319
Validation loss: 2.494189877763787

Epoch: 223| Step: 0
Training loss: 2.469468217508117
Validation loss: 2.5321523733350464

Epoch: 5| Step: 1
Training loss: 2.3866526193400732
Validation loss: 2.5422344120012137

Epoch: 5| Step: 2
Training loss: 2.8605124290608357
Validation loss: 2.530481152611939

Epoch: 5| Step: 3
Training loss: 2.7313338452351807
Validation loss: 2.5335610060589078

Epoch: 5| Step: 4
Training loss: 2.737676404033297
Validation loss: 2.5442440693091273

Epoch: 5| Step: 5
Training loss: 1.8011025495885906
Validation loss: 2.513728486814375

Epoch: 5| Step: 6
Training loss: 3.1182148323262706
Validation loss: 2.54502435522459

Epoch: 5| Step: 7
Training loss: 2.5603283309493654
Validation loss: 2.585754355330331

Epoch: 5| Step: 8
Training loss: 1.938502513798266
Validation loss: 2.510015475441915

Epoch: 5| Step: 9
Training loss: 2.7236023494621246
Validation loss: 2.5634229415074894

Epoch: 5| Step: 10
Training loss: 2.3072783826412584
Validation loss: 2.5550995378691463

Epoch: 224| Step: 0
Training loss: 2.5355712362884253
Validation loss: 2.501976152494845

Epoch: 5| Step: 1
Training loss: 3.161793439137038
Validation loss: 2.5282098441524408

Epoch: 5| Step: 2
Training loss: 2.2520113537978173
Validation loss: 2.5355609354838275

Epoch: 5| Step: 3
Training loss: 2.218960604276263
Validation loss: 2.495499645680796

Epoch: 5| Step: 4
Training loss: 2.181282362383605
Validation loss: 2.5247281146129996

Epoch: 5| Step: 5
Training loss: 2.149051980662259
Validation loss: 2.5342839181834687

Epoch: 5| Step: 6
Training loss: 2.426458635827748
Validation loss: 2.498611273676228

Epoch: 5| Step: 7
Training loss: 2.41383918791032
Validation loss: 2.5453124752631497

Epoch: 5| Step: 8
Training loss: 2.5787262186644857
Validation loss: 2.494250608275061

Epoch: 5| Step: 9
Training loss: 2.806712235271859
Validation loss: 2.5342602368953355

Epoch: 5| Step: 10
Training loss: 2.9457434381979914
Validation loss: 2.5456127735890064

Epoch: 225| Step: 0
Training loss: 2.261387090792254
Validation loss: 2.536443576153699

Epoch: 5| Step: 1
Training loss: 3.0511391560425647
Validation loss: 2.5236503958022967

Epoch: 5| Step: 2
Training loss: 2.3509060269700366
Validation loss: 2.517040047053979

Epoch: 5| Step: 3
Training loss: 3.1301183364972123
Validation loss: 2.531569788461772

Epoch: 5| Step: 4
Training loss: 2.2091653683933323
Validation loss: 2.503236382155199

Epoch: 5| Step: 5
Training loss: 2.3515432363335766
Validation loss: 2.490508866999013

Epoch: 5| Step: 6
Training loss: 1.9513071374145963
Validation loss: 2.5086671266649243

Epoch: 5| Step: 7
Training loss: 2.572898051288511
Validation loss: 2.4857373734565886

Epoch: 5| Step: 8
Training loss: 3.1791592845772714
Validation loss: 2.519891082946212

Epoch: 5| Step: 9
Training loss: 2.324553342184606
Validation loss: 2.5137276862274263

Epoch: 5| Step: 10
Training loss: 2.3231512615534995
Validation loss: 2.511669525576107

Epoch: 226| Step: 0
Training loss: 2.5068477307864394
Validation loss: 2.5325314098821563

Epoch: 5| Step: 1
Training loss: 2.2529119086587186
Validation loss: 2.526359354096105

Epoch: 5| Step: 2
Training loss: 2.1864757864880833
Validation loss: 2.512999133097594

Epoch: 5| Step: 3
Training loss: 2.6103747616931128
Validation loss: 2.5181138772089424

Epoch: 5| Step: 4
Training loss: 2.6483671015832635
Validation loss: 2.521245296467641

Epoch: 5| Step: 5
Training loss: 2.303928159633498
Validation loss: 2.526293898889974

Epoch: 5| Step: 6
Training loss: 2.4755744768287475
Validation loss: 2.547111421240465

Epoch: 5| Step: 7
Training loss: 2.5581249943334083
Validation loss: 2.5492891704263587

Epoch: 5| Step: 8
Training loss: 3.312420826091693
Validation loss: 2.5437711677074675

Epoch: 5| Step: 9
Training loss: 2.3042998424303343
Validation loss: 2.538692380876433

Epoch: 5| Step: 10
Training loss: 2.7526269849819696
Validation loss: 2.481311992535088

Epoch: 227| Step: 0
Training loss: 2.8533486820711293
Validation loss: 2.5614032554298816

Epoch: 5| Step: 1
Training loss: 2.3730727959618267
Validation loss: 2.505574116764934

Epoch: 5| Step: 2
Training loss: 2.234438381763295
Validation loss: 2.5067486330364916

Epoch: 5| Step: 3
Training loss: 2.318718565036299
Validation loss: 2.5165564381364987

Epoch: 5| Step: 4
Training loss: 2.8131774086552666
Validation loss: 2.4951142725857154

Epoch: 5| Step: 5
Training loss: 2.552805822958861
Validation loss: 2.547755996140073

Epoch: 5| Step: 6
Training loss: 2.7618295088899925
Validation loss: 2.545436728572538

Epoch: 5| Step: 7
Training loss: 2.196799212650233
Validation loss: 2.529723487611247

Epoch: 5| Step: 8
Training loss: 2.2727097857409415
Validation loss: 2.5348344381787795

Epoch: 5| Step: 9
Training loss: 2.8290137480438466
Validation loss: 2.5418817747511486

Epoch: 5| Step: 10
Training loss: 2.427231507151026
Validation loss: 2.5174605741972833

Epoch: 228| Step: 0
Training loss: 2.7234451267575546
Validation loss: 2.5371311906788603

Epoch: 5| Step: 1
Training loss: 2.32951078198802
Validation loss: 2.528815325707896

Epoch: 5| Step: 2
Training loss: 1.7227804610609994
Validation loss: 2.540090827540422

Epoch: 5| Step: 3
Training loss: 2.019188739353163
Validation loss: 2.50837575915911

Epoch: 5| Step: 4
Training loss: 2.7728799608773733
Validation loss: 2.4955347751741153

Epoch: 5| Step: 5
Training loss: 2.5570911916763603
Validation loss: 2.531922191765188

Epoch: 5| Step: 6
Training loss: 2.7756553700809965
Validation loss: 2.5424741369800556

Epoch: 5| Step: 7
Training loss: 2.3314926062132706
Validation loss: 2.530561970681682

Epoch: 5| Step: 8
Training loss: 2.5228150725023757
Validation loss: 2.52558373090433

Epoch: 5| Step: 9
Training loss: 2.9359591074702154
Validation loss: 2.5555992740971414

Epoch: 5| Step: 10
Training loss: 2.8604622530007777
Validation loss: 2.5255781825334984

Epoch: 229| Step: 0
Training loss: 2.9235624448743334
Validation loss: 2.52788689955632

Epoch: 5| Step: 1
Training loss: 2.1701131576708037
Validation loss: 2.5089058189587217

Epoch: 5| Step: 2
Training loss: 2.043160365730094
Validation loss: 2.52241408040743

Epoch: 5| Step: 3
Training loss: 2.1849135230298926
Validation loss: 2.521440174795041

Epoch: 5| Step: 4
Training loss: 2.4204217303693665
Validation loss: 2.507822181821743

Epoch: 5| Step: 5
Training loss: 2.973733994840546
Validation loss: 2.5113551409735915

Epoch: 5| Step: 6
Training loss: 2.546725496924109
Validation loss: 2.5271278090407576

Epoch: 5| Step: 7
Training loss: 2.667955166738848
Validation loss: 2.532554233743183

Epoch: 5| Step: 8
Training loss: 2.645532595946805
Validation loss: 2.5062580097364986

Epoch: 5| Step: 9
Training loss: 2.635090643176038
Validation loss: 2.550968557704788

Epoch: 5| Step: 10
Training loss: 2.2134669631619257
Validation loss: 2.5303679225337086

Epoch: 230| Step: 0
Training loss: 2.4576381303806962
Validation loss: 2.498272941202185

Epoch: 5| Step: 1
Training loss: 2.137773494066285
Validation loss: 2.5373441519696254

Epoch: 5| Step: 2
Training loss: 2.595159124886928
Validation loss: 2.534284528168446

Epoch: 5| Step: 3
Training loss: 1.8525890611045777
Validation loss: 2.5141629343685836

Epoch: 5| Step: 4
Training loss: 2.884585447889654
Validation loss: 2.5386896760528193

Epoch: 5| Step: 5
Training loss: 2.3145575777458385
Validation loss: 2.5552688483578723

Epoch: 5| Step: 6
Training loss: 2.488624441293271
Validation loss: 2.4868936101448877

Epoch: 5| Step: 7
Training loss: 2.5934587797732225
Validation loss: 2.543580251907914

Epoch: 5| Step: 8
Training loss: 2.965978191797153
Validation loss: 2.5387652933930194

Epoch: 5| Step: 9
Training loss: 2.866757061738122
Validation loss: 2.5074290918909723

Epoch: 5| Step: 10
Training loss: 2.1660604240111883
Validation loss: 2.4938197089147622

Epoch: 231| Step: 0
Training loss: 2.505973450583241
Validation loss: 2.530153830458185

Epoch: 5| Step: 1
Training loss: 2.2579778590911816
Validation loss: 2.5242347541101378

Epoch: 5| Step: 2
Training loss: 3.035813818830552
Validation loss: 2.543480752901381

Epoch: 5| Step: 3
Training loss: 2.338919175113763
Validation loss: 2.5658363294719

Epoch: 5| Step: 4
Training loss: 2.2784136553960552
Validation loss: 2.5625504449480654

Epoch: 5| Step: 5
Training loss: 2.3378729823569375
Validation loss: 2.5364472167735927

Epoch: 5| Step: 6
Training loss: 3.0832258841548033
Validation loss: 2.509740084130375

Epoch: 5| Step: 7
Training loss: 2.985517193383301
Validation loss: 2.5166280238914407

Epoch: 5| Step: 8
Training loss: 2.4561249679308386
Validation loss: 2.568702659153733

Epoch: 5| Step: 9
Training loss: 1.9805865431446978
Validation loss: 2.5215369642329026

Epoch: 5| Step: 10
Training loss: 2.2170771350235072
Validation loss: 2.535549671079426

Epoch: 232| Step: 0
Training loss: 3.2056086145950227
Validation loss: 2.5325406641641677

Epoch: 5| Step: 1
Training loss: 2.689607282000549
Validation loss: 2.5383561649194832

Epoch: 5| Step: 2
Training loss: 2.9399880768410904
Validation loss: 2.519965446918592

Epoch: 5| Step: 3
Training loss: 2.620052943968732
Validation loss: 2.5244128336976535

Epoch: 5| Step: 4
Training loss: 2.2376527020224035
Validation loss: 2.505807349891088

Epoch: 5| Step: 5
Training loss: 2.6330059218175283
Validation loss: 2.53540703619688

Epoch: 5| Step: 6
Training loss: 2.133260267715126
Validation loss: 2.5588851671322703

Epoch: 5| Step: 7
Training loss: 2.640877976799058
Validation loss: 2.4926762785148804

Epoch: 5| Step: 8
Training loss: 1.576965283603773
Validation loss: 2.4847387882177054

Epoch: 5| Step: 9
Training loss: 2.4559072279602527
Validation loss: 2.534932198796234

Epoch: 5| Step: 10
Training loss: 2.396444878412048
Validation loss: 2.536502235788838

Epoch: 233| Step: 0
Training loss: 2.4734953651238287
Validation loss: 2.5570914142449563

Epoch: 5| Step: 1
Training loss: 2.25872984733099
Validation loss: 2.5236161168557074

Epoch: 5| Step: 2
Training loss: 2.7157094329947724
Validation loss: 2.509105770205166

Epoch: 5| Step: 3
Training loss: 2.8770514093976307
Validation loss: 2.4974617665413468

Epoch: 5| Step: 4
Training loss: 2.022933366931164
Validation loss: 2.5286291407513666

Epoch: 5| Step: 5
Training loss: 2.2169665838810944
Validation loss: 2.5199379462590543

Epoch: 5| Step: 6
Training loss: 2.4926944802953144
Validation loss: 2.514777746383343

Epoch: 5| Step: 7
Training loss: 2.531027513310024
Validation loss: 2.560161935060576

Epoch: 5| Step: 8
Training loss: 3.3119638836867926
Validation loss: 2.547076455558856

Epoch: 5| Step: 9
Training loss: 2.4172139260660557
Validation loss: 2.5263079972337903

Epoch: 5| Step: 10
Training loss: 2.1083206367361673
Validation loss: 2.5347395664021946

Epoch: 234| Step: 0
Training loss: 1.9954064188027814
Validation loss: 2.545957778746408

Epoch: 5| Step: 1
Training loss: 2.474183874724606
Validation loss: 2.5406047398702687

Epoch: 5| Step: 2
Training loss: 2.6039768505854672
Validation loss: 2.522811344125871

Epoch: 5| Step: 3
Training loss: 1.945379784580919
Validation loss: 2.54431704742457

Epoch: 5| Step: 4
Training loss: 2.2704305262383824
Validation loss: 2.5514070466561343

Epoch: 5| Step: 5
Training loss: 2.579925648113232
Validation loss: 2.5625518605496604

Epoch: 5| Step: 6
Training loss: 2.4681548354856413
Validation loss: 2.5411234362040194

Epoch: 5| Step: 7
Training loss: 2.8187855314396337
Validation loss: 2.516520175882192

Epoch: 5| Step: 8
Training loss: 2.7254669699269147
Validation loss: 2.5402669786266063

Epoch: 5| Step: 9
Training loss: 3.3782615443466955
Validation loss: 2.531521785500882

Epoch: 5| Step: 10
Training loss: 2.228958179552193
Validation loss: 2.544927371124789

Epoch: 235| Step: 0
Training loss: 2.8670534523543902
Validation loss: 2.5136786265885362

Epoch: 5| Step: 1
Training loss: 2.04989820088027
Validation loss: 2.5089106776900962

Epoch: 5| Step: 2
Training loss: 2.055389980429303
Validation loss: 2.512249159613411

Epoch: 5| Step: 3
Training loss: 2.5704712978111806
Validation loss: 2.530338728466553

Epoch: 5| Step: 4
Training loss: 2.4559206249134444
Validation loss: 2.545887468563773

Epoch: 5| Step: 5
Training loss: 2.495880834247386
Validation loss: 2.514359444438245

Epoch: 5| Step: 6
Training loss: 2.2251131393299093
Validation loss: 2.494299426163395

Epoch: 5| Step: 7
Training loss: 2.7329591409676675
Validation loss: 2.523930429758546

Epoch: 5| Step: 8
Training loss: 3.038364987385456
Validation loss: 2.5318335459693952

Epoch: 5| Step: 9
Training loss: 2.9225185725892158
Validation loss: 2.518580322201329

Epoch: 5| Step: 10
Training loss: 2.0849429842245186
Validation loss: 2.498415252915465

Epoch: 236| Step: 0
Training loss: 2.2341592324387074
Validation loss: 2.539609625013989

Epoch: 5| Step: 1
Training loss: 3.1143038995394337
Validation loss: 2.492639488873681

Epoch: 5| Step: 2
Training loss: 2.4957955291211564
Validation loss: 2.519482716484576

Epoch: 5| Step: 3
Training loss: 2.004285274599177
Validation loss: 2.5009107981527636

Epoch: 5| Step: 4
Training loss: 3.0655937916511635
Validation loss: 2.5449467948343436

Epoch: 5| Step: 5
Training loss: 2.3164916770582993
Validation loss: 2.522740258001888

Epoch: 5| Step: 6
Training loss: 2.5387860426417386
Validation loss: 2.5102854953857374

Epoch: 5| Step: 7
Training loss: 2.525562442796816
Validation loss: 2.542399073122239

Epoch: 5| Step: 8
Training loss: 2.101258323239936
Validation loss: 2.51759482907804

Epoch: 5| Step: 9
Training loss: 2.6145354085433334
Validation loss: 2.5199641091271014

Epoch: 5| Step: 10
Training loss: 2.3095765063341895
Validation loss: 2.5020073343370814

Epoch: 237| Step: 0
Training loss: 2.703004161801876
Validation loss: 2.5329156178729093

Epoch: 5| Step: 1
Training loss: 2.0688224756735534
Validation loss: 2.5362584070510406

Epoch: 5| Step: 2
Training loss: 2.5617039071898167
Validation loss: 2.5371665389556584

Epoch: 5| Step: 3
Training loss: 2.5147244754887303
Validation loss: 2.518082093578018

Epoch: 5| Step: 4
Training loss: 2.2707761938156525
Validation loss: 2.5514744725229503

Epoch: 5| Step: 5
Training loss: 2.79256392526158
Validation loss: 2.5387822801615902

Epoch: 5| Step: 6
Training loss: 2.2909155105869683
Validation loss: 2.5415172277448987

Epoch: 5| Step: 7
Training loss: 2.770533543098484
Validation loss: 2.5430601312227465

Epoch: 5| Step: 8
Training loss: 2.2401644522040565
Validation loss: 2.5475676733514088

Epoch: 5| Step: 9
Training loss: 2.76534058568562
Validation loss: 2.5416744769329567

Epoch: 5| Step: 10
Training loss: 2.2493324349105177
Validation loss: 2.5282186473012307

Epoch: 238| Step: 0
Training loss: 2.4116126410024723
Validation loss: 2.506006918193734

Epoch: 5| Step: 1
Training loss: 2.3296642975192245
Validation loss: 2.5265210671790497

Epoch: 5| Step: 2
Training loss: 2.566833274767826
Validation loss: 2.548087582245241

Epoch: 5| Step: 3
Training loss: 2.954854468878455
Validation loss: 2.5227942457551937

Epoch: 5| Step: 4
Training loss: 2.7222053231041325
Validation loss: 2.5123463072215686

Epoch: 5| Step: 5
Training loss: 2.047333877028444
Validation loss: 2.5435721746912985

Epoch: 5| Step: 6
Training loss: 2.775752345331097
Validation loss: 2.541702563433946

Epoch: 5| Step: 7
Training loss: 1.9073856910462443
Validation loss: 2.5194931450929263

Epoch: 5| Step: 8
Training loss: 2.433037806118807
Validation loss: 2.515491683587575

Epoch: 5| Step: 9
Training loss: 2.604192738720399
Validation loss: 2.5466895223078465

Epoch: 5| Step: 10
Training loss: 2.5991597578522136
Validation loss: 2.5333915795504605

Epoch: 239| Step: 0
Training loss: 2.08419555623703
Validation loss: 2.521912863210123

Epoch: 5| Step: 1
Training loss: 3.0474417917327026
Validation loss: 2.4950102170596553

Epoch: 5| Step: 2
Training loss: 2.7482138815468504
Validation loss: 2.5519254460234975

Epoch: 5| Step: 3
Training loss: 2.200212542063863
Validation loss: 2.5059841154594986

Epoch: 5| Step: 4
Training loss: 2.5025691183112304
Validation loss: 2.5129522250590313

Epoch: 5| Step: 5
Training loss: 2.423724249889404
Validation loss: 2.5345369532467457

Epoch: 5| Step: 6
Training loss: 2.4349655277389157
Validation loss: 2.5441610407686888

Epoch: 5| Step: 7
Training loss: 2.692602946262353
Validation loss: 2.5063600742407584

Epoch: 5| Step: 8
Training loss: 2.401170695403718
Validation loss: 2.52867401774108

Epoch: 5| Step: 9
Training loss: 2.113791131014756
Validation loss: 2.520107986313068

Epoch: 5| Step: 10
Training loss: 2.8221750634259113
Validation loss: 2.5122809257088696

Epoch: 240| Step: 0
Training loss: 2.7453245819468597
Validation loss: 2.506643322331066

Epoch: 5| Step: 1
Training loss: 2.7595688195595436
Validation loss: 2.5197331275073767

Epoch: 5| Step: 2
Training loss: 2.712019910384828
Validation loss: 2.5202808783265187

Epoch: 5| Step: 3
Training loss: 2.415987895044734
Validation loss: 2.5172048835711496

Epoch: 5| Step: 4
Training loss: 2.2117258560244375
Validation loss: 2.5651170825940195

Epoch: 5| Step: 5
Training loss: 2.4014466137993207
Validation loss: 2.520472909017163

Epoch: 5| Step: 6
Training loss: 2.38437858771258
Validation loss: 2.5476226343448687

Epoch: 5| Step: 7
Training loss: 2.402447259425286
Validation loss: 2.5246752628515288

Epoch: 5| Step: 8
Training loss: 2.259669718112546
Validation loss: 2.5170074997180367

Epoch: 5| Step: 9
Training loss: 2.6749613821504217
Validation loss: 2.5012033253236132

Epoch: 5| Step: 10
Training loss: 2.333251327254317
Validation loss: 2.5154179374659558

Epoch: 241| Step: 0
Training loss: 1.8884678664378591
Validation loss: 2.5284979253926436

Epoch: 5| Step: 1
Training loss: 2.483742783434693
Validation loss: 2.520375672867395

Epoch: 5| Step: 2
Training loss: 3.075286330871599
Validation loss: 2.493796831751597

Epoch: 5| Step: 3
Training loss: 2.0766782385359295
Validation loss: 2.5444542690680967

Epoch: 5| Step: 4
Training loss: 2.7248791414109785
Validation loss: 2.5051984115021044

Epoch: 5| Step: 5
Training loss: 2.6083701934484984
Validation loss: 2.549709161165386

Epoch: 5| Step: 6
Training loss: 2.540665809894792
Validation loss: 2.525640138649239

Epoch: 5| Step: 7
Training loss: 2.4367071965400195
Validation loss: 2.512674602869268

Epoch: 5| Step: 8
Training loss: 2.212984249763963
Validation loss: 2.5207866954904636

Epoch: 5| Step: 9
Training loss: 2.420076945634276
Validation loss: 2.486382726039119

Epoch: 5| Step: 10
Training loss: 2.8121492802972807
Validation loss: 2.5463770864039033

Epoch: 242| Step: 0
Training loss: 1.7539487973768162
Validation loss: 2.5172192365086907

Epoch: 5| Step: 1
Training loss: 2.2878090613195647
Validation loss: 2.532552361034253

Epoch: 5| Step: 2
Training loss: 2.5447761921380256
Validation loss: 2.5007167414253884

Epoch: 5| Step: 3
Training loss: 3.1226118499294504
Validation loss: 2.518748433529842

Epoch: 5| Step: 4
Training loss: 2.2029218647693916
Validation loss: 2.5300835702418953

Epoch: 5| Step: 5
Training loss: 2.896364360028358
Validation loss: 2.4912486332278974

Epoch: 5| Step: 6
Training loss: 2.097159271755104
Validation loss: 2.507829704605167

Epoch: 5| Step: 7
Training loss: 2.4784456909028947
Validation loss: 2.5574225377676254

Epoch: 5| Step: 8
Training loss: 2.2570379175897752
Validation loss: 2.545227662510919

Epoch: 5| Step: 9
Training loss: 2.8619156686659486
Validation loss: 2.528539266772167

Epoch: 5| Step: 10
Training loss: 2.4141088191159583
Validation loss: 2.4979067889051296

Epoch: 243| Step: 0
Training loss: 2.5801400372847034
Validation loss: 2.531868562682612

Epoch: 5| Step: 1
Training loss: 2.6970643473223643
Validation loss: 2.5600029849475976

Epoch: 5| Step: 2
Training loss: 2.5804756314598487
Validation loss: 2.5461385449686316

Epoch: 5| Step: 3
Training loss: 3.2981975488018986
Validation loss: 2.5093447752828117

Epoch: 5| Step: 4
Training loss: 1.9864238464637105
Validation loss: 2.5060470183804213

Epoch: 5| Step: 5
Training loss: 2.3673179263200206
Validation loss: 2.540690567649202

Epoch: 5| Step: 6
Training loss: 2.602595310426405
Validation loss: 2.509658622096627

Epoch: 5| Step: 7
Training loss: 2.4609108575256733
Validation loss: 2.5106174516519837

Epoch: 5| Step: 8
Training loss: 2.414457023505134
Validation loss: 2.5518749296788656

Epoch: 5| Step: 9
Training loss: 2.1883076947761713
Validation loss: 2.512325646755603

Epoch: 5| Step: 10
Training loss: 2.1153868728572296
Validation loss: 2.5459848420240534

Epoch: 244| Step: 0
Training loss: 2.886798036800191
Validation loss: 2.48743823560107

Epoch: 5| Step: 1
Training loss: 2.2473900810748613
Validation loss: 2.4998094270733926

Epoch: 5| Step: 2
Training loss: 2.2412091290501963
Validation loss: 2.51853448003803

Epoch: 5| Step: 3
Training loss: 2.154051281650628
Validation loss: 2.513803106517717

Epoch: 5| Step: 4
Training loss: 2.088603056071229
Validation loss: 2.5398145679124187

Epoch: 5| Step: 5
Training loss: 2.64327797429666
Validation loss: 2.533327486498853

Epoch: 5| Step: 6
Training loss: 2.5909464748246913
Validation loss: 2.5063754241649776

Epoch: 5| Step: 7
Training loss: 2.209314404294673
Validation loss: 2.52869739701463

Epoch: 5| Step: 8
Training loss: 2.2060020545195957
Validation loss: 2.5016961588835955

Epoch: 5| Step: 9
Training loss: 2.874604571141862
Validation loss: 2.540387778154384

Epoch: 5| Step: 10
Training loss: 3.3203664977226865
Validation loss: 2.5200330853410406

Epoch: 245| Step: 0
Training loss: 1.9067900471126076
Validation loss: 2.5195315537258156

Epoch: 5| Step: 1
Training loss: 1.7436837925527824
Validation loss: 2.5005525234788935

Epoch: 5| Step: 2
Training loss: 2.404989630821541
Validation loss: 2.541448665154605

Epoch: 5| Step: 3
Training loss: 2.757574746579173
Validation loss: 2.4782908919481024

Epoch: 5| Step: 4
Training loss: 2.599295329922747
Validation loss: 2.5480929176081824

Epoch: 5| Step: 5
Training loss: 2.5616622113511958
Validation loss: 2.5151763013445785

Epoch: 5| Step: 6
Training loss: 2.145005470749074
Validation loss: 2.5311522855524786

Epoch: 5| Step: 7
Training loss: 2.7540034716604342
Validation loss: 2.510461578015065

Epoch: 5| Step: 8
Training loss: 2.9145981856197887
Validation loss: 2.5133887998611555

Epoch: 5| Step: 9
Training loss: 2.8528519732731827
Validation loss: 2.574619821721589

Epoch: 5| Step: 10
Training loss: 2.3686799736039257
Validation loss: 2.5272891767527677

Epoch: 246| Step: 0
Training loss: 2.5257982484131647
Validation loss: 2.5195753834700105

Epoch: 5| Step: 1
Training loss: 2.3721226780255846
Validation loss: 2.5389023193115206

Epoch: 5| Step: 2
Training loss: 2.445304309965318
Validation loss: 2.512900587560185

Epoch: 5| Step: 3
Training loss: 2.335497148019188
Validation loss: 2.558974240813563

Epoch: 5| Step: 4
Training loss: 2.8462682619711033
Validation loss: 2.5099039624342794

Epoch: 5| Step: 5
Training loss: 2.641064849877747
Validation loss: 2.5465523878900878

Epoch: 5| Step: 6
Training loss: 2.675292033003692
Validation loss: 2.534636514581656

Epoch: 5| Step: 7
Training loss: 2.5262204346207904
Validation loss: 2.5159646530216917

Epoch: 5| Step: 8
Training loss: 2.6616128079151204
Validation loss: 2.525178846476413

Epoch: 5| Step: 9
Training loss: 1.533133380056775
Validation loss: 2.5138155024667133

Epoch: 5| Step: 10
Training loss: 2.4504625000667524
Validation loss: 2.5236510327377766

Epoch: 247| Step: 0
Training loss: 2.695690626074804
Validation loss: 2.532203691139276

Epoch: 5| Step: 1
Training loss: 3.124289317382194
Validation loss: 2.562945535516382

Epoch: 5| Step: 2
Training loss: 2.28389701382597
Validation loss: 2.544073649242433

Epoch: 5| Step: 3
Training loss: 2.1237749046405683
Validation loss: 2.544595033690359

Epoch: 5| Step: 4
Training loss: 2.2425377336302215
Validation loss: 2.5328442955892134

Epoch: 5| Step: 5
Training loss: 2.5490019172670224
Validation loss: 2.48725752782154

Epoch: 5| Step: 6
Training loss: 2.3464260845332894
Validation loss: 2.5201042264651132

Epoch: 5| Step: 7
Training loss: 2.130163091227301
Validation loss: 2.532478623790895

Epoch: 5| Step: 8
Training loss: 2.734990862564361
Validation loss: 2.5204067267564136

Epoch: 5| Step: 9
Training loss: 2.004800399966858
Validation loss: 2.549390669617671

Epoch: 5| Step: 10
Training loss: 2.992475610313359
Validation loss: 2.5630671666098

Epoch: 248| Step: 0
Training loss: 3.2119563730015743
Validation loss: 2.530884125201231

Epoch: 5| Step: 1
Training loss: 2.718266323518082
Validation loss: 2.477512663744344

Epoch: 5| Step: 2
Training loss: 1.936462616843058
Validation loss: 2.568354884261899

Epoch: 5| Step: 3
Training loss: 2.4216935612794677
Validation loss: 2.546187972939126

Epoch: 5| Step: 4
Training loss: 2.0030287221067185
Validation loss: 2.506269950992892

Epoch: 5| Step: 5
Training loss: 2.5277650178393953
Validation loss: 2.5251787479989733

Epoch: 5| Step: 6
Training loss: 2.4804999882690946
Validation loss: 2.5083572930145013

Epoch: 5| Step: 7
Training loss: 2.6886267850443306
Validation loss: 2.5374960061124767

Epoch: 5| Step: 8
Training loss: 2.4518146295284193
Validation loss: 2.5353496910079136

Epoch: 5| Step: 9
Training loss: 2.2026203199726226
Validation loss: 2.5235457797617302

Epoch: 5| Step: 10
Training loss: 2.5576139248320637
Validation loss: 2.516529503305983

Epoch: 249| Step: 0
Training loss: 1.9382299463323795
Validation loss: 2.48510756565446

Epoch: 5| Step: 1
Training loss: 2.764698800208005
Validation loss: 2.5490059110690355

Epoch: 5| Step: 2
Training loss: 2.764065663889556
Validation loss: 2.5301397114944773

Epoch: 5| Step: 3
Training loss: 2.523923466895945
Validation loss: 2.522795458070684

Epoch: 5| Step: 4
Training loss: 1.942999939769797
Validation loss: 2.5244990809680403

Epoch: 5| Step: 5
Training loss: 3.083470384455866
Validation loss: 2.524226527139657

Epoch: 5| Step: 6
Training loss: 2.2816844160765637
Validation loss: 2.532862350413487

Epoch: 5| Step: 7
Training loss: 2.6168828530714205
Validation loss: 2.52250477681503

Epoch: 5| Step: 8
Training loss: 2.590941321706386
Validation loss: 2.525704336440569

Epoch: 5| Step: 9
Training loss: 2.6596858523156097
Validation loss: 2.5213050448398677

Epoch: 5| Step: 10
Training loss: 2.140533668073285
Validation loss: 2.5311049654403024

Epoch: 250| Step: 0
Training loss: 2.982168770213323
Validation loss: 2.552862679623874

Epoch: 5| Step: 1
Training loss: 2.5368638129033467
Validation loss: 2.5300795435306385

Epoch: 5| Step: 2
Training loss: 2.2911135497307877
Validation loss: 2.5267154635199813

Epoch: 5| Step: 3
Training loss: 2.198379275073515
Validation loss: 2.541765370125936

Epoch: 5| Step: 4
Training loss: 2.655414045847241
Validation loss: 2.5371258686405525

Epoch: 5| Step: 5
Training loss: 2.316625472143919
Validation loss: 2.518179648371316

Epoch: 5| Step: 6
Training loss: 2.4538685831885068
Validation loss: 2.5432385987197805

Epoch: 5| Step: 7
Training loss: 1.864872666683306
Validation loss: 2.5002878987244443

Epoch: 5| Step: 8
Training loss: 2.738193222132912
Validation loss: 2.484022442988353

Epoch: 5| Step: 9
Training loss: 2.123445952386714
Validation loss: 2.527371029588439

Epoch: 5| Step: 10
Training loss: 2.7431641494137136
Validation loss: 2.5247152757039597

Epoch: 251| Step: 0
Training loss: 2.3790884464943027
Validation loss: 2.533632419975812

Epoch: 5| Step: 1
Training loss: 2.1046514676527726
Validation loss: 2.5034406335707478

Epoch: 5| Step: 2
Training loss: 1.9006085952005658
Validation loss: 2.5466045067647762

Epoch: 5| Step: 3
Training loss: 2.621888723780801
Validation loss: 2.540690059096517

Epoch: 5| Step: 4
Training loss: 2.495353003778094
Validation loss: 2.5063557179014326

Epoch: 5| Step: 5
Training loss: 2.17747839547968
Validation loss: 2.522204781067931

Epoch: 5| Step: 6
Training loss: 2.179138989634443
Validation loss: 2.513482728302

Epoch: 5| Step: 7
Training loss: 2.8279251955382514
Validation loss: 2.5168427944045684

Epoch: 5| Step: 8
Training loss: 2.7402815321917906
Validation loss: 2.5478942279147745

Epoch: 5| Step: 9
Training loss: 2.932248392457706
Validation loss: 2.5462621800496845

Epoch: 5| Step: 10
Training loss: 2.6484894423891014
Validation loss: 2.5501839201662166

Epoch: 252| Step: 0
Training loss: 2.3411317569590957
Validation loss: 2.51307866287491

Epoch: 5| Step: 1
Training loss: 2.5766624232360456
Validation loss: 2.522014312468414

Epoch: 5| Step: 2
Training loss: 1.98783608719892
Validation loss: 2.5082664611722496

Epoch: 5| Step: 3
Training loss: 2.641305598744813
Validation loss: 2.5352992185241727

Epoch: 5| Step: 4
Training loss: 2.341510465668206
Validation loss: 2.545580974778328

Epoch: 5| Step: 5
Training loss: 2.6974926078914296
Validation loss: 2.574299340201356

Epoch: 5| Step: 6
Training loss: 2.302349598763567
Validation loss: 2.5374303991977545

Epoch: 5| Step: 7
Training loss: 3.005081006575214
Validation loss: 2.539977658462356

Epoch: 5| Step: 8
Training loss: 2.7260095423631467
Validation loss: 2.556736388693777

Epoch: 5| Step: 9
Training loss: 2.2917833009574364
Validation loss: 2.5732726183473464

Epoch: 5| Step: 10
Training loss: 2.4274974900771893
Validation loss: 2.5591318789032798

Epoch: 253| Step: 0
Training loss: 2.0816317921209673
Validation loss: 2.5272569272643244

Epoch: 5| Step: 1
Training loss: 2.5936144138425146
Validation loss: 2.518185947058062

Epoch: 5| Step: 2
Training loss: 2.2934479350834893
Validation loss: 2.523401093818005

Epoch: 5| Step: 3
Training loss: 2.501664275291701
Validation loss: 2.52942961379619

Epoch: 5| Step: 4
Training loss: 1.732054661793452
Validation loss: 2.560731432077375

Epoch: 5| Step: 5
Training loss: 2.1775008414230737
Validation loss: 2.5236070452097192

Epoch: 5| Step: 6
Training loss: 3.5850023035018097
Validation loss: 2.5346854881838468

Epoch: 5| Step: 7
Training loss: 2.3301490331637913
Validation loss: 2.519161279683501

Epoch: 5| Step: 8
Training loss: 2.5929713171899955
Validation loss: 2.527420028846737

Epoch: 5| Step: 9
Training loss: 2.577565820336409
Validation loss: 2.5276782014599486

Epoch: 5| Step: 10
Training loss: 2.127194225423377
Validation loss: 2.4999638195906346

Epoch: 254| Step: 0
Training loss: 2.3694233926084087
Validation loss: 2.5249842790365826

Epoch: 5| Step: 1
Training loss: 2.541784617287612
Validation loss: 2.540424377861562

Epoch: 5| Step: 2
Training loss: 2.8639856073241643
Validation loss: 2.557489197584037

Epoch: 5| Step: 3
Training loss: 2.6042866691914637
Validation loss: 2.525432316709298

Epoch: 5| Step: 4
Training loss: 2.492662820959819
Validation loss: 2.512406725379851

Epoch: 5| Step: 5
Training loss: 2.0777344300796665
Validation loss: 2.524420833088649

Epoch: 5| Step: 6
Training loss: 2.5714579989248074
Validation loss: 2.5200928034510826

Epoch: 5| Step: 7
Training loss: 2.806598235615217
Validation loss: 2.511229457577751

Epoch: 5| Step: 8
Training loss: 1.7188025726600944
Validation loss: 2.5574367562149702

Epoch: 5| Step: 9
Training loss: 2.3267519185242858
Validation loss: 2.507727851214698

Epoch: 5| Step: 10
Training loss: 2.549535660447373
Validation loss: 2.488506110000892

Epoch: 255| Step: 0
Training loss: 2.342537935289733
Validation loss: 2.4995111531003333

Epoch: 5| Step: 1
Training loss: 2.8819287607361166
Validation loss: 2.513353198770379

Epoch: 5| Step: 2
Training loss: 2.1287370247033843
Validation loss: 2.5307801151190468

Epoch: 5| Step: 3
Training loss: 2.215100039769704
Validation loss: 2.507912402622465

Epoch: 5| Step: 4
Training loss: 2.576009911571413
Validation loss: 2.542245198545426

Epoch: 5| Step: 5
Training loss: 2.1714485902508813
Validation loss: 2.531837977446907

Epoch: 5| Step: 6
Training loss: 2.455887035313006
Validation loss: 2.54723491046987

Epoch: 5| Step: 7
Training loss: 2.47198187865865
Validation loss: 2.515263375458072

Epoch: 5| Step: 8
Training loss: 2.4537389679406667
Validation loss: 2.5557878346196956

Epoch: 5| Step: 9
Training loss: 2.7495910167013484
Validation loss: 2.5064603681912003

Epoch: 5| Step: 10
Training loss: 2.444375343020363
Validation loss: 2.498086726333492

Epoch: 256| Step: 0
Training loss: 2.1930175949761552
Validation loss: 2.5221007921976906

Epoch: 5| Step: 1
Training loss: 2.8461017316381185
Validation loss: 2.5583722243246134

Epoch: 5| Step: 2
Training loss: 2.8059808410838776
Validation loss: 2.5110038268443766

Epoch: 5| Step: 3
Training loss: 2.2167368607652755
Validation loss: 2.5151586307296085

Epoch: 5| Step: 4
Training loss: 1.7382106123727032
Validation loss: 2.5329880696779146

Epoch: 5| Step: 5
Training loss: 2.4472412692697647
Validation loss: 2.5153054582370578

Epoch: 5| Step: 6
Training loss: 2.184915705436267
Validation loss: 2.5282250117310685

Epoch: 5| Step: 7
Training loss: 2.5175120224424132
Validation loss: 2.5075312896890747

Epoch: 5| Step: 8
Training loss: 2.91530126673558
Validation loss: 2.5381131809211532

Epoch: 5| Step: 9
Training loss: 2.637698928056574
Validation loss: 2.5067829467935923

Epoch: 5| Step: 10
Training loss: 2.393944025766818
Validation loss: 2.5119394228299

Epoch: 257| Step: 0
Training loss: 2.5820014247816485
Validation loss: 2.5135324394235163

Epoch: 5| Step: 1
Training loss: 2.2392467393696998
Validation loss: 2.5023122784593688

Epoch: 5| Step: 2
Training loss: 2.467704841436318
Validation loss: 2.5129694046776097

Epoch: 5| Step: 3
Training loss: 2.35147723173247
Validation loss: 2.537022120513564

Epoch: 5| Step: 4
Training loss: 2.791461329713461
Validation loss: 2.5355902827581973

Epoch: 5| Step: 5
Training loss: 2.7944007030406453
Validation loss: 2.530356359940246

Epoch: 5| Step: 6
Training loss: 2.9410726046454374
Validation loss: 2.5512507359826593

Epoch: 5| Step: 7
Training loss: 1.9010415133820215
Validation loss: 2.550405126750341

Epoch: 5| Step: 8
Training loss: 1.9944503199963934
Validation loss: 2.517304856451266

Epoch: 5| Step: 9
Training loss: 2.2857604703324395
Validation loss: 2.5245834431176384

Epoch: 5| Step: 10
Training loss: 2.181913162461547
Validation loss: 2.5089573378921726

Epoch: 258| Step: 0
Training loss: 2.554250230609771
Validation loss: 2.4851313109438165

Epoch: 5| Step: 1
Training loss: 2.0828308516750593
Validation loss: 2.5222891259377147

Epoch: 5| Step: 2
Training loss: 2.044053557364272
Validation loss: 2.5423643088400456

Epoch: 5| Step: 3
Training loss: 2.77227174140908
Validation loss: 2.5342459096591554

Epoch: 5| Step: 4
Training loss: 3.327690418507007
Validation loss: 2.545168725527207

Epoch: 5| Step: 5
Training loss: 2.460732200172952
Validation loss: 2.522335705848254

Epoch: 5| Step: 6
Training loss: 2.6162883067892087
Validation loss: 2.4981778046455507

Epoch: 5| Step: 7
Training loss: 2.1637390115283694
Validation loss: 2.5301124055224076

Epoch: 5| Step: 8
Training loss: 2.6983146423044353
Validation loss: 2.5483957754617945

Epoch: 5| Step: 9
Training loss: 1.8061329391192007
Validation loss: 2.5367348031709445

Epoch: 5| Step: 10
Training loss: 2.0229208739603948
Validation loss: 2.587472909226057

Epoch: 259| Step: 0
Training loss: 2.3460870916098697
Validation loss: 2.561721457388219

Epoch: 5| Step: 1
Training loss: 1.6117812010980315
Validation loss: 2.5487937058981296

Epoch: 5| Step: 2
Training loss: 2.510010323674222
Validation loss: 2.526209593353219

Epoch: 5| Step: 3
Training loss: 2.4966780526377343
Validation loss: 2.54327798284511

Epoch: 5| Step: 4
Training loss: 2.9387548485395056
Validation loss: 2.5400595389298073

Epoch: 5| Step: 5
Training loss: 2.666048534595415
Validation loss: 2.533921988107732

Epoch: 5| Step: 6
Training loss: 2.2865574380053
Validation loss: 2.5201256268018515

Epoch: 5| Step: 7
Training loss: 2.3524828152327864
Validation loss: 2.54887139665497

Epoch: 5| Step: 8
Training loss: 2.6862998766770816
Validation loss: 2.5237881682126235

Epoch: 5| Step: 9
Training loss: 2.792553765471766
Validation loss: 2.5220090052892377

Epoch: 5| Step: 10
Training loss: 2.4028733576860417
Validation loss: 2.5385645921058337

Epoch: 260| Step: 0
Training loss: 2.4979851232655306
Validation loss: 2.5316004741525577

Epoch: 5| Step: 1
Training loss: 2.9144478305369246
Validation loss: 2.5204711666782904

Epoch: 5| Step: 2
Training loss: 2.6860911202785376
Validation loss: 2.5259535481177897

Epoch: 5| Step: 3
Training loss: 2.187336724863598
Validation loss: 2.5321774107380666

Epoch: 5| Step: 4
Training loss: 2.198305092669474
Validation loss: 2.545663402115616

Epoch: 5| Step: 5
Training loss: 2.3520586371216377
Validation loss: 2.5439147737019585

Epoch: 5| Step: 6
Training loss: 2.6044180379981996
Validation loss: 2.5450340395304107

Epoch: 5| Step: 7
Training loss: 2.0885347919557082
Validation loss: 2.524337092619158

Epoch: 5| Step: 8
Training loss: 2.6947949783389387
Validation loss: 2.5308694891496315

Epoch: 5| Step: 9
Training loss: 2.7854627785661736
Validation loss: 2.5347353144646725

Epoch: 5| Step: 10
Training loss: 1.756157328919897
Validation loss: 2.5457061052104715

Epoch: 261| Step: 0
Training loss: 2.137958731699971
Validation loss: 2.559996442155423

Epoch: 5| Step: 1
Training loss: 2.8571471827338035
Validation loss: 2.5556864124427245

Epoch: 5| Step: 2
Training loss: 2.2606159479805314
Validation loss: 2.4882959047409052

Epoch: 5| Step: 3
Training loss: 2.099638671670606
Validation loss: 2.539486940056252

Epoch: 5| Step: 4
Training loss: 2.4425486584973486
Validation loss: 2.5548213158395834

Epoch: 5| Step: 5
Training loss: 2.996724247646197
Validation loss: 2.5143640683195354

Epoch: 5| Step: 6
Training loss: 2.430713400181021
Validation loss: 2.596974656107413

Epoch: 5| Step: 7
Training loss: 2.4241485752738923
Validation loss: 2.5180987505352386

Epoch: 5| Step: 8
Training loss: 2.4598922205008726
Validation loss: 2.546490815734251

Epoch: 5| Step: 9
Training loss: 2.7997207229845236
Validation loss: 2.5279449626742974

Epoch: 5| Step: 10
Training loss: 1.8996593169907816
Validation loss: 2.5340401572435387

Epoch: 262| Step: 0
Training loss: 2.1486334694004086
Validation loss: 2.4921792109565013

Epoch: 5| Step: 1
Training loss: 2.4266853060722626
Validation loss: 2.513107895250271

Epoch: 5| Step: 2
Training loss: 2.027174632050867
Validation loss: 2.5641055685909993

Epoch: 5| Step: 3
Training loss: 2.711192709922951
Validation loss: 2.5381677153679343

Epoch: 5| Step: 4
Training loss: 2.764317952584499
Validation loss: 2.5472240741008636

Epoch: 5| Step: 5
Training loss: 2.734606400643952
Validation loss: 2.518698919505998

Epoch: 5| Step: 6
Training loss: 2.2064054699116955
Validation loss: 2.5248807727066325

Epoch: 5| Step: 7
Training loss: 2.722935929019881
Validation loss: 2.5182867412096006

Epoch: 5| Step: 8
Training loss: 1.9638104916682464
Validation loss: 2.5553927499750673

Epoch: 5| Step: 9
Training loss: 2.2036910175429676
Validation loss: 2.5371320394555346

Epoch: 5| Step: 10
Training loss: 2.4986457017482473
Validation loss: 2.542080338367057

Epoch: 263| Step: 0
Training loss: 1.76468511901122
Validation loss: 2.550350216673724

Epoch: 5| Step: 1
Training loss: 2.6145558349460227
Validation loss: 2.528650995122117

Epoch: 5| Step: 2
Training loss: 2.3924622301331167
Validation loss: 2.517010973911965

Epoch: 5| Step: 3
Training loss: 2.8525022865440035
Validation loss: 2.513524549191119

Epoch: 5| Step: 4
Training loss: 2.5448047672475314
Validation loss: 2.5408134305912484

Epoch: 5| Step: 5
Training loss: 2.574599103367416
Validation loss: 2.507484955165744

Epoch: 5| Step: 6
Training loss: 2.3050764369909937
Validation loss: 2.571591943984135

Epoch: 5| Step: 7
Training loss: 2.860191020321806
Validation loss: 2.5068247608248355

Epoch: 5| Step: 8
Training loss: 1.803938408817329
Validation loss: 2.5259846613119987

Epoch: 5| Step: 9
Training loss: 2.747717864099835
Validation loss: 2.4974820623862577

Epoch: 5| Step: 10
Training loss: 1.9708594268727448
Validation loss: 2.5127476337064993

Epoch: 264| Step: 0
Training loss: 2.113944296905072
Validation loss: 2.5132169525948074

Epoch: 5| Step: 1
Training loss: 1.9477808967914019
Validation loss: 2.523480462378086

Epoch: 5| Step: 2
Training loss: 2.677080226159179
Validation loss: 2.5142852470588357

Epoch: 5| Step: 3
Training loss: 2.3085977776971527
Validation loss: 2.5249532926144953

Epoch: 5| Step: 4
Training loss: 2.99533576777201
Validation loss: 2.5129736669187146

Epoch: 5| Step: 5
Training loss: 2.4531608627516412
Validation loss: 2.508813773087856

Epoch: 5| Step: 6
Training loss: 2.763742528221213
Validation loss: 2.526493738332453

Epoch: 5| Step: 7
Training loss: 2.483929960108057
Validation loss: 2.5102197155144315

Epoch: 5| Step: 8
Training loss: 2.0310728729487457
Validation loss: 2.4929536360697075

Epoch: 5| Step: 9
Training loss: 2.391794355043177
Validation loss: 2.537815188340652

Epoch: 5| Step: 10
Training loss: 2.4093727557101356
Validation loss: 2.531771453334108

Epoch: 265| Step: 0
Training loss: 1.6911601885331322
Validation loss: 2.4917660672962505

Epoch: 5| Step: 1
Training loss: 2.10586221447447
Validation loss: 2.51245452826651

Epoch: 5| Step: 2
Training loss: 2.0541984643338584
Validation loss: 2.547207345925533

Epoch: 5| Step: 3
Training loss: 2.8399344197612946
Validation loss: 2.4965471608890097

Epoch: 5| Step: 4
Training loss: 2.3977367856199803
Validation loss: 2.5452790158342955

Epoch: 5| Step: 5
Training loss: 2.17877188973037
Validation loss: 2.4945491916392597

Epoch: 5| Step: 6
Training loss: 2.4347090760005643
Validation loss: 2.5095616626085966

Epoch: 5| Step: 7
Training loss: 2.2875603964915188
Validation loss: 2.5003771230859115

Epoch: 5| Step: 8
Training loss: 2.544473088846829
Validation loss: 2.559425964252722

Epoch: 5| Step: 9
Training loss: 3.2878978415998383
Validation loss: 2.536413910263619

Epoch: 5| Step: 10
Training loss: 2.676785334960887
Validation loss: 2.5390400001910973

Epoch: 266| Step: 0
Training loss: 2.3216979132542064
Validation loss: 2.5022754097063453

Epoch: 5| Step: 1
Training loss: 2.4410556388868145
Validation loss: 2.5020680098381045

Epoch: 5| Step: 2
Training loss: 2.4328522019279717
Validation loss: 2.546955753840166

Epoch: 5| Step: 3
Training loss: 2.4283941328422385
Validation loss: 2.5225575028075427

Epoch: 5| Step: 4
Training loss: 2.3490358891057594
Validation loss: 2.5337187439718174

Epoch: 5| Step: 5
Training loss: 2.1093905978155947
Validation loss: 2.511710846925394

Epoch: 5| Step: 6
Training loss: 2.3023082801615935
Validation loss: 2.517711066189314

Epoch: 5| Step: 7
Training loss: 3.2534758247636906
Validation loss: 2.5258939300017547

Epoch: 5| Step: 8
Training loss: 2.030115133318504
Validation loss: 2.538466885535001

Epoch: 5| Step: 9
Training loss: 2.660413105085275
Validation loss: 2.5324716732956007

Epoch: 5| Step: 10
Training loss: 2.214331727494697
Validation loss: 2.5062059734672286

Epoch: 267| Step: 0
Training loss: 3.04762955150043
Validation loss: 2.536458524695676

Epoch: 5| Step: 1
Training loss: 2.1660707705798536
Validation loss: 2.5201116896967823

Epoch: 5| Step: 2
Training loss: 2.0088048479037655
Validation loss: 2.500270243364043

Epoch: 5| Step: 3
Training loss: 2.298870646975571
Validation loss: 2.5462660432346045

Epoch: 5| Step: 4
Training loss: 2.530982015104989
Validation loss: 2.517601795187567

Epoch: 5| Step: 5
Training loss: 2.4002955691804897
Validation loss: 2.5272080125906986

Epoch: 5| Step: 6
Training loss: 2.3421986850015935
Validation loss: 2.545104317637192

Epoch: 5| Step: 7
Training loss: 2.6495028803245146
Validation loss: 2.5033590679299587

Epoch: 5| Step: 8
Training loss: 2.492949844522976
Validation loss: 2.513116607974764

Epoch: 5| Step: 9
Training loss: 2.5239645581726906
Validation loss: 2.5204834199839707

Epoch: 5| Step: 10
Training loss: 2.153467345462009
Validation loss: 2.49055787042841

Epoch: 268| Step: 0
Training loss: 2.5594760450973646
Validation loss: 2.5002048372624066

Epoch: 5| Step: 1
Training loss: 2.244023863674031
Validation loss: 2.5595831788958443

Epoch: 5| Step: 2
Training loss: 2.4634260885750296
Validation loss: 2.5425052113548734

Epoch: 5| Step: 3
Training loss: 2.055685402947424
Validation loss: 2.4977489950861536

Epoch: 5| Step: 4
Training loss: 2.051944773170646
Validation loss: 2.538477725959976

Epoch: 5| Step: 5
Training loss: 2.5730240731208434
Validation loss: 2.549061365032157

Epoch: 5| Step: 6
Training loss: 2.331880037398918
Validation loss: 2.5088639190351514

Epoch: 5| Step: 7
Training loss: 2.9612222096792493
Validation loss: 2.529462134569973

Epoch: 5| Step: 8
Training loss: 2.6088791793037465
Validation loss: 2.5141085206176728

Epoch: 5| Step: 9
Training loss: 2.3340778411920833
Validation loss: 2.5467111341167405

Epoch: 5| Step: 10
Training loss: 2.252244571509453
Validation loss: 2.539356196907677

Epoch: 269| Step: 0
Training loss: 2.048525777932512
Validation loss: 2.5229956249123546

Epoch: 5| Step: 1
Training loss: 3.056861669573345
Validation loss: 2.5120603946267828

Epoch: 5| Step: 2
Training loss: 2.1895853184752414
Validation loss: 2.538186308041574

Epoch: 5| Step: 3
Training loss: 2.840131196766049
Validation loss: 2.534045057822243

Epoch: 5| Step: 4
Training loss: 2.1182747051770736
Validation loss: 2.5369012102398667

Epoch: 5| Step: 5
Training loss: 2.7719476701054844
Validation loss: 2.5156313162930526

Epoch: 5| Step: 6
Training loss: 2.476366390321713
Validation loss: 2.5440257753983326

Epoch: 5| Step: 7
Training loss: 2.287401136752953
Validation loss: 2.567622753027476

Epoch: 5| Step: 8
Training loss: 2.111328802540941
Validation loss: 2.4894804546902605

Epoch: 5| Step: 9
Training loss: 2.2859779380407916
Validation loss: 2.5307268771668703

Epoch: 5| Step: 10
Training loss: 1.8066895844295123
Validation loss: 2.5402401085009476

Epoch: 270| Step: 0
Training loss: 2.561901022524611
Validation loss: 2.5329705673488645

Epoch: 5| Step: 1
Training loss: 2.830265815571391
Validation loss: 2.5184168639352094

Epoch: 5| Step: 2
Training loss: 2.3005427963962193
Validation loss: 2.526735486845997

Epoch: 5| Step: 3
Training loss: 2.5903032680572005
Validation loss: 2.5458337006581147

Epoch: 5| Step: 4
Training loss: 2.291666886300741
Validation loss: 2.4977936945793826

Epoch: 5| Step: 5
Training loss: 2.3016672808484975
Validation loss: 2.534692273815469

Epoch: 5| Step: 6
Training loss: 2.0847260461216313
Validation loss: 2.4908054390148666

Epoch: 5| Step: 7
Training loss: 1.9487170106886202
Validation loss: 2.541663882131142

Epoch: 5| Step: 8
Training loss: 2.4441152938644586
Validation loss: 2.5036171146661372

Epoch: 5| Step: 9
Training loss: 2.4748723854533967
Validation loss: 2.51461215588713

Epoch: 5| Step: 10
Training loss: 2.810866496115455
Validation loss: 2.5141571201488264

Epoch: 271| Step: 0
Training loss: 2.755669731249485
Validation loss: 2.4896786009446186

Epoch: 5| Step: 1
Training loss: 1.9979214596284796
Validation loss: 2.5586891380100525

Epoch: 5| Step: 2
Training loss: 2.523248057148574
Validation loss: 2.54547259198068

Epoch: 5| Step: 3
Training loss: 1.8491463005980964
Validation loss: 2.5426357240183672

Epoch: 5| Step: 4
Training loss: 1.8249490652423042
Validation loss: 2.527268888999796

Epoch: 5| Step: 5
Training loss: 2.539383806292704
Validation loss: 2.510241278756707

Epoch: 5| Step: 6
Training loss: 2.7748675890425383
Validation loss: 2.572083714556776

Epoch: 5| Step: 7
Training loss: 2.395599674496045
Validation loss: 2.5506693693582316

Epoch: 5| Step: 8
Training loss: 2.922745029433816
Validation loss: 2.5089574845197835

Epoch: 5| Step: 9
Training loss: 2.1200605092320304
Validation loss: 2.534657865044313

Epoch: 5| Step: 10
Training loss: 2.5629842347171095
Validation loss: 2.505856709931292

Epoch: 272| Step: 0
Training loss: 2.246280138326221
Validation loss: 2.545091011392301

Epoch: 5| Step: 1
Training loss: 2.248064162041211
Validation loss: 2.4674957191970495

Epoch: 5| Step: 2
Training loss: 2.321805839484044
Validation loss: 2.5355563836229993

Epoch: 5| Step: 3
Training loss: 2.0680666852414875
Validation loss: 2.5106058384321512

Epoch: 5| Step: 4
Training loss: 2.5677882266559924
Validation loss: 2.5064422418309347

Epoch: 5| Step: 5
Training loss: 2.332048630130482
Validation loss: 2.5386374800168836

Epoch: 5| Step: 6
Training loss: 1.9793906503389294
Validation loss: 2.547782904727843

Epoch: 5| Step: 7
Training loss: 1.9631482918373788
Validation loss: 2.5220122672591443

Epoch: 5| Step: 8
Training loss: 3.151615479401775
Validation loss: 2.5119017406116666

Epoch: 5| Step: 9
Training loss: 2.3180777837491195
Validation loss: 2.531805915509378

Epoch: 5| Step: 10
Training loss: 2.9551889785780006
Validation loss: 2.5506474041265332

Epoch: 273| Step: 0
Training loss: 2.687024717665155
Validation loss: 2.559483153384801

Epoch: 5| Step: 1
Training loss: 1.9325091778536017
Validation loss: 2.526389801186623

Epoch: 5| Step: 2
Training loss: 2.7500951923887484
Validation loss: 2.5259840838295973

Epoch: 5| Step: 3
Training loss: 1.889422704338594
Validation loss: 2.546739123799278

Epoch: 5| Step: 4
Training loss: 2.0992814060708964
Validation loss: 2.551040549549704

Epoch: 5| Step: 5
Training loss: 1.8581114250172246
Validation loss: 2.547175019504913

Epoch: 5| Step: 6
Training loss: 2.8414112576641672
Validation loss: 2.549719173555706

Epoch: 5| Step: 7
Training loss: 2.447692492886696
Validation loss: 2.505300711551675

Epoch: 5| Step: 8
Training loss: 2.178918737113791
Validation loss: 2.5480596355463376

Epoch: 5| Step: 9
Training loss: 2.9783299122431197
Validation loss: 2.543589398463019

Epoch: 5| Step: 10
Training loss: 2.7156463973384306
Validation loss: 2.54448030680309

Epoch: 274| Step: 0
Training loss: 2.409516532491346
Validation loss: 2.5598913901725315

Epoch: 5| Step: 1
Training loss: 2.2846263825458872
Validation loss: 2.490106393226546

Epoch: 5| Step: 2
Training loss: 2.93511119053532
Validation loss: 2.5251759703244656

Epoch: 5| Step: 3
Training loss: 2.2870242056556025
Validation loss: 2.491645396308462

Epoch: 5| Step: 4
Training loss: 2.0756107121004255
Validation loss: 2.53529801825474

Epoch: 5| Step: 5
Training loss: 3.2773468053937633
Validation loss: 2.5414033514997474

Epoch: 5| Step: 6
Training loss: 2.225840026357917
Validation loss: 2.531582487291204

Epoch: 5| Step: 7
Training loss: 2.133553959445078
Validation loss: 2.5113423368002827

Epoch: 5| Step: 8
Training loss: 2.483406117885292
Validation loss: 2.518253162949791

Epoch: 5| Step: 9
Training loss: 1.9063825717540788
Validation loss: 2.5327468390166676

Epoch: 5| Step: 10
Training loss: 2.0025074261207374
Validation loss: 2.5209111142614664

Epoch: 275| Step: 0
Training loss: 2.703457144909605
Validation loss: 2.503047680028998

Epoch: 5| Step: 1
Training loss: 2.23607448155616
Validation loss: 2.5494369615126686

Epoch: 5| Step: 2
Training loss: 1.750247120438991
Validation loss: 2.52103715291445

Epoch: 5| Step: 3
Training loss: 2.3613230765945827
Validation loss: 2.5363700237989715

Epoch: 5| Step: 4
Training loss: 2.488690544732592
Validation loss: 2.4963454761295107

Epoch: 5| Step: 5
Training loss: 2.28335777000475
Validation loss: 2.539940085379047

Epoch: 5| Step: 6
Training loss: 2.4442242525610984
Validation loss: 2.5286232290082093

Epoch: 5| Step: 7
Training loss: 2.6715410704271427
Validation loss: 2.5391158953558985

Epoch: 5| Step: 8
Training loss: 2.319048193499478
Validation loss: 2.5195307005461705

Epoch: 5| Step: 9
Training loss: 2.564798394324168
Validation loss: 2.5144777213622165

Epoch: 5| Step: 10
Training loss: 2.4716891405760557
Validation loss: 2.503240155048982

Epoch: 276| Step: 0
Training loss: 1.8670790892217008
Validation loss: 2.5444891478648324

Epoch: 5| Step: 1
Training loss: 2.6910655300138298
Validation loss: 2.514715606241591

Epoch: 5| Step: 2
Training loss: 2.066846256246567
Validation loss: 2.5092089827082105

Epoch: 5| Step: 3
Training loss: 2.412426934593501
Validation loss: 2.5315499289445933

Epoch: 5| Step: 4
Training loss: 1.9649259576606812
Validation loss: 2.5435782371416584

Epoch: 5| Step: 5
Training loss: 2.527925828177586
Validation loss: 2.5388701830049696

Epoch: 5| Step: 6
Training loss: 2.6778739820463366
Validation loss: 2.512796688056637

Epoch: 5| Step: 7
Training loss: 2.6782732643207345
Validation loss: 2.514583846323082

Epoch: 5| Step: 8
Training loss: 2.8499630975843835
Validation loss: 2.5730279120666593

Epoch: 5| Step: 9
Training loss: 2.3617244921029887
Validation loss: 2.5036828898422656

Epoch: 5| Step: 10
Training loss: 2.028167498456287
Validation loss: 2.534878822516569

Epoch: 277| Step: 0
Training loss: 2.4639668544670217
Validation loss: 2.5528900425158265

Epoch: 5| Step: 1
Training loss: 1.847100978910166
Validation loss: 2.5676914154542407

Epoch: 5| Step: 2
Training loss: 2.141291827735846
Validation loss: 2.5027130623309515

Epoch: 5| Step: 3
Training loss: 2.5369645592030055
Validation loss: 2.5447958497121044

Epoch: 5| Step: 4
Training loss: 2.6169035344723985
Validation loss: 2.5196631225761617

Epoch: 5| Step: 5
Training loss: 2.58801020507923
Validation loss: 2.493256578161698

Epoch: 5| Step: 6
Training loss: 1.9371850772995745
Validation loss: 2.540081351475014

Epoch: 5| Step: 7
Training loss: 2.924519693439744
Validation loss: 2.540313173385054

Epoch: 5| Step: 8
Training loss: 2.5312015858482475
Validation loss: 2.533949621292656

Epoch: 5| Step: 9
Training loss: 2.1150111875846895
Validation loss: 2.5181216655066483

Epoch: 5| Step: 10
Training loss: 2.670813366304013
Validation loss: 2.492400711716224

Epoch: 278| Step: 0
Training loss: 2.486514339980215
Validation loss: 2.5269435506057687

Epoch: 5| Step: 1
Training loss: 1.9582497463920134
Validation loss: 2.5191783050177845

Epoch: 5| Step: 2
Training loss: 2.353226488009522
Validation loss: 2.5043951735945957

Epoch: 5| Step: 3
Training loss: 2.264977724416302
Validation loss: 2.508714115848327

Epoch: 5| Step: 4
Training loss: 2.353963544966811
Validation loss: 2.5161017438317494

Epoch: 5| Step: 5
Training loss: 2.6664457428335377
Validation loss: 2.5342330820455334

Epoch: 5| Step: 6
Training loss: 2.4219421377412993
Validation loss: 2.540848425958635

Epoch: 5| Step: 7
Training loss: 2.285825347756643
Validation loss: 2.5148277214184347

Epoch: 5| Step: 8
Training loss: 2.4723835534117
Validation loss: 2.567403776812423

Epoch: 5| Step: 9
Training loss: 2.755001288688898
Validation loss: 2.5202799435155607

Epoch: 5| Step: 10
Training loss: 2.0307745743950205
Validation loss: 2.5507271088528416

Epoch: 279| Step: 0
Training loss: 2.413414729345695
Validation loss: 2.5135375084971874

Epoch: 5| Step: 1
Training loss: 2.3614187925236982
Validation loss: 2.533712539548512

Epoch: 5| Step: 2
Training loss: 2.8162312658290434
Validation loss: 2.5417626105775257

Epoch: 5| Step: 3
Training loss: 2.0948500519034092
Validation loss: 2.542765406275877

Epoch: 5| Step: 4
Training loss: 2.347822186640327
Validation loss: 2.574121136913542

Epoch: 5| Step: 5
Training loss: 2.3419718800264695
Validation loss: 2.5160870625471876

Epoch: 5| Step: 6
Training loss: 2.457489601648787
Validation loss: 2.512220833626051

Epoch: 5| Step: 7
Training loss: 2.3222689103214775
Validation loss: 2.5479721583953205

Epoch: 5| Step: 8
Training loss: 2.0619352318834308
Validation loss: 2.5294301458968595

Epoch: 5| Step: 9
Training loss: 1.9693925807970802
Validation loss: 2.516273566264462

Epoch: 5| Step: 10
Training loss: 2.8883704388658766
Validation loss: 2.5350066828091005

Epoch: 280| Step: 0
Training loss: 1.9018179854297255
Validation loss: 2.5470400148493644

Epoch: 5| Step: 1
Training loss: 2.480668475903483
Validation loss: 2.5573342932121323

Epoch: 5| Step: 2
Training loss: 2.353914117910743
Validation loss: 2.5673123563774802

Epoch: 5| Step: 3
Training loss: 2.0678335643546912
Validation loss: 2.5186896708565376

Epoch: 5| Step: 4
Training loss: 2.270864072352486
Validation loss: 2.54002848913694

Epoch: 5| Step: 5
Training loss: 2.2163361864710827
Validation loss: 2.54742293884052

Epoch: 5| Step: 6
Training loss: 2.91903074821647
Validation loss: 2.543641109392918

Epoch: 5| Step: 7
Training loss: 2.51691664239514
Validation loss: 2.5183883141451253

Epoch: 5| Step: 8
Training loss: 2.0528279872059794
Validation loss: 2.5472079608673206

Epoch: 5| Step: 9
Training loss: 2.4960027209474944
Validation loss: 2.5654999864775836

Epoch: 5| Step: 10
Training loss: 2.7039944347516185
Validation loss: 2.5667609647995238

Epoch: 281| Step: 0
Training loss: 2.4713677157053073
Validation loss: 2.5138758950026157

Epoch: 5| Step: 1
Training loss: 2.4343587735263323
Validation loss: 2.5299513754548877

Epoch: 5| Step: 2
Training loss: 2.6732586406759693
Validation loss: 2.525378366065026

Epoch: 5| Step: 3
Training loss: 2.292627780394108
Validation loss: 2.513834918754629

Epoch: 5| Step: 4
Training loss: 3.1892810408357057
Validation loss: 2.5395271384760743

Epoch: 5| Step: 5
Training loss: 2.184515961340535
Validation loss: 2.552990618306193

Epoch: 5| Step: 6
Training loss: 2.5424982388620645
Validation loss: 2.5379560656309867

Epoch: 5| Step: 7
Training loss: 2.470913385785202
Validation loss: 2.520992257432411

Epoch: 5| Step: 8
Training loss: 1.616443850050917
Validation loss: 2.5384124049826116

Epoch: 5| Step: 9
Training loss: 1.8520086209732998
Validation loss: 2.5288715164043865

Epoch: 5| Step: 10
Training loss: 2.2789497797656373
Validation loss: 2.530435897863677

Epoch: 282| Step: 0
Training loss: 2.592243078554596
Validation loss: 2.519903045056499

Epoch: 5| Step: 1
Training loss: 2.3808320367008675
Validation loss: 2.51275485199265

Epoch: 5| Step: 2
Training loss: 2.129151720366551
Validation loss: 2.516285571042462

Epoch: 5| Step: 3
Training loss: 2.019359824838766
Validation loss: 2.5091328777042197

Epoch: 5| Step: 4
Training loss: 2.339829382748827
Validation loss: 2.5926419651594648

Epoch: 5| Step: 5
Training loss: 2.0993686271859215
Validation loss: 2.5060942398010795

Epoch: 5| Step: 6
Training loss: 2.620077695204142
Validation loss: 2.5069708063526885

Epoch: 5| Step: 7
Training loss: 3.158594148547619
Validation loss: 2.5682573507597874

Epoch: 5| Step: 8
Training loss: 2.520687624500759
Validation loss: 2.5332640708717573

Epoch: 5| Step: 9
Training loss: 1.928085774373556
Validation loss: 2.5102469815364237

Epoch: 5| Step: 10
Training loss: 2.586670647729517
Validation loss: 2.5526043917288828

Epoch: 283| Step: 0
Training loss: 3.0218894603111073
Validation loss: 2.516455572641873

Epoch: 5| Step: 1
Training loss: 1.805448693593638
Validation loss: 2.555107273630155

Epoch: 5| Step: 2
Training loss: 2.6377090515886166
Validation loss: 2.475962829087118

Epoch: 5| Step: 3
Training loss: 2.328920881192771
Validation loss: 2.538210095112485

Epoch: 5| Step: 4
Training loss: 2.3075516829070395
Validation loss: 2.552852806094964

Epoch: 5| Step: 5
Training loss: 2.5260531920075078
Validation loss: 2.509794541518716

Epoch: 5| Step: 6
Training loss: 2.5056026621598564
Validation loss: 2.5343446822841647

Epoch: 5| Step: 7
Training loss: 2.2531654555330207
Validation loss: 2.5451584051445373

Epoch: 5| Step: 8
Training loss: 2.2779038854388935
Validation loss: 2.5635876437026517

Epoch: 5| Step: 9
Training loss: 1.9547761575305251
Validation loss: 2.4958472349616616

Epoch: 5| Step: 10
Training loss: 2.1001635578585494
Validation loss: 2.516008719139838

Epoch: 284| Step: 0
Training loss: 1.923590785843771
Validation loss: 2.5437510577667246

Epoch: 5| Step: 1
Training loss: 2.5648691344014463
Validation loss: 2.513380389999377

Epoch: 5| Step: 2
Training loss: 2.4979540082119875
Validation loss: 2.5401773518999873

Epoch: 5| Step: 3
Training loss: 2.4495296493888095
Validation loss: 2.5316215646530758

Epoch: 5| Step: 4
Training loss: 2.653821665460562
Validation loss: 2.5312974834963806

Epoch: 5| Step: 5
Training loss: 2.2016286976745914
Validation loss: 2.521357545287085

Epoch: 5| Step: 6
Training loss: 1.7578626837454583
Validation loss: 2.511423005166725

Epoch: 5| Step: 7
Training loss: 2.670735434068501
Validation loss: 2.5515805678196406

Epoch: 5| Step: 8
Training loss: 2.1577450641588443
Validation loss: 2.5585886960456015

Epoch: 5| Step: 9
Training loss: 2.065316906458373
Validation loss: 2.5054049454490825

Epoch: 5| Step: 10
Training loss: 2.9372370176081164
Validation loss: 2.482529145185059

Epoch: 285| Step: 0
Training loss: 2.394851837353613
Validation loss: 2.5405902496255126

Epoch: 5| Step: 1
Training loss: 2.651818022501335
Validation loss: 2.573667061022437

Epoch: 5| Step: 2
Training loss: 1.8019643608320173
Validation loss: 2.493140531505775

Epoch: 5| Step: 3
Training loss: 2.3014484985874417
Validation loss: 2.526536121104248

Epoch: 5| Step: 4
Training loss: 2.1454549165646037
Validation loss: 2.561792953914572

Epoch: 5| Step: 5
Training loss: 2.3649063449889187
Validation loss: 2.5629773719507645

Epoch: 5| Step: 6
Training loss: 2.430467486526813
Validation loss: 2.5237749136324275

Epoch: 5| Step: 7
Training loss: 3.1472991324178987
Validation loss: 2.5381906673210506

Epoch: 5| Step: 8
Training loss: 1.8573324059600231
Validation loss: 2.533074684842336

Epoch: 5| Step: 9
Training loss: 2.0421789914853594
Validation loss: 2.516202246534452

Epoch: 5| Step: 10
Training loss: 2.579494782890816
Validation loss: 2.519940988112083

Epoch: 286| Step: 0
Training loss: 2.4914895159496773
Validation loss: 2.5509684320838404

Epoch: 5| Step: 1
Training loss: 1.9710060393435902
Validation loss: 2.551572804286097

Epoch: 5| Step: 2
Training loss: 2.5486744333751394
Validation loss: 2.5229345615617027

Epoch: 5| Step: 3
Training loss: 2.302228954651872
Validation loss: 2.545236790051895

Epoch: 5| Step: 4
Training loss: 2.408513775393906
Validation loss: 2.565083325812915

Epoch: 5| Step: 5
Training loss: 2.5966650886024834
Validation loss: 2.524760455295867

Epoch: 5| Step: 6
Training loss: 2.615783223570176
Validation loss: 2.5185713810295445

Epoch: 5| Step: 7
Training loss: 1.3554711245645177
Validation loss: 2.4938408321196577

Epoch: 5| Step: 8
Training loss: 2.3726891770023446
Validation loss: 2.5291777138912135

Epoch: 5| Step: 9
Training loss: 2.5813244012265635
Validation loss: 2.5246447062322317

Epoch: 5| Step: 10
Training loss: 2.394388365721931
Validation loss: 2.5192739256241325

Epoch: 287| Step: 0
Training loss: 2.58671203262162
Validation loss: 2.537247932191834

Epoch: 5| Step: 1
Training loss: 2.463116362449371
Validation loss: 2.541105498589998

Epoch: 5| Step: 2
Training loss: 2.401144184122298
Validation loss: 2.5787756950463785

Epoch: 5| Step: 3
Training loss: 2.305461999100587
Validation loss: 2.5511245118426364

Epoch: 5| Step: 4
Training loss: 1.8065883649536056
Validation loss: 2.568913297585257

Epoch: 5| Step: 5
Training loss: 2.456568445427298
Validation loss: 2.5322930159389525

Epoch: 5| Step: 6
Training loss: 2.5238223889546525
Validation loss: 2.5048658680833964

Epoch: 5| Step: 7
Training loss: 2.4218582644961093
Validation loss: 2.537458644820713

Epoch: 5| Step: 8
Training loss: 2.334057207447568
Validation loss: 2.5110220938382053

Epoch: 5| Step: 9
Training loss: 2.7496099195386323
Validation loss: 2.5530753549233074

Epoch: 5| Step: 10
Training loss: 1.9498851913497857
Validation loss: 2.5374222124850916

Epoch: 288| Step: 0
Training loss: 2.2353165783358966
Validation loss: 2.56074200505372

Epoch: 5| Step: 1
Training loss: 2.8641774022871664
Validation loss: 2.538749978747255

Epoch: 5| Step: 2
Training loss: 1.9971381812466773
Validation loss: 2.552947012786894

Epoch: 5| Step: 3
Training loss: 2.0488948029322214
Validation loss: 2.5153455997556264

Epoch: 5| Step: 4
Training loss: 3.0866358485925103
Validation loss: 2.528774615362376

Epoch: 5| Step: 5
Training loss: 2.640869129339957
Validation loss: 2.5372453910292836

Epoch: 5| Step: 6
Training loss: 1.958739853998818
Validation loss: 2.546877290981482

Epoch: 5| Step: 7
Training loss: 2.520397421818613
Validation loss: 2.5658087469472592

Epoch: 5| Step: 8
Training loss: 2.03435349694767
Validation loss: 2.530932464391813

Epoch: 5| Step: 9
Training loss: 2.0236878700450402
Validation loss: 2.5277539894847476

Epoch: 5| Step: 10
Training loss: 2.141075142637095
Validation loss: 2.4860555282210193

Epoch: 289| Step: 0
Training loss: 2.5086944075175954
Validation loss: 2.5514285893665587

Epoch: 5| Step: 1
Training loss: 2.283081155852543
Validation loss: 2.5229346453927906

Epoch: 5| Step: 2
Training loss: 1.99256289068163
Validation loss: 2.545152909518654

Epoch: 5| Step: 3
Training loss: 2.490789134744936
Validation loss: 2.4962247415222554

Epoch: 5| Step: 4
Training loss: 1.7567576316188926
Validation loss: 2.532135980940844

Epoch: 5| Step: 5
Training loss: 2.5142623338293455
Validation loss: 2.4958934270580966

Epoch: 5| Step: 6
Training loss: 2.9024120954267825
Validation loss: 2.536772679408521

Epoch: 5| Step: 7
Training loss: 2.261017633058069
Validation loss: 2.540098241131544

Epoch: 5| Step: 8
Training loss: 2.466830702645631
Validation loss: 2.544052499731559

Epoch: 5| Step: 9
Training loss: 2.4124646871087316
Validation loss: 2.522896450136468

Epoch: 5| Step: 10
Training loss: 1.9849676613851912
Validation loss: 2.5502777067425013

Epoch: 290| Step: 0
Training loss: 2.411542941779471
Validation loss: 2.5320667937640025

Epoch: 5| Step: 1
Training loss: 2.2010602000356347
Validation loss: 2.5351000959624304

Epoch: 5| Step: 2
Training loss: 2.280301458607275
Validation loss: 2.5160586625924424

Epoch: 5| Step: 3
Training loss: 2.123749308818954
Validation loss: 2.536015834660833

Epoch: 5| Step: 4
Training loss: 2.7601165224439823
Validation loss: 2.522743356940549

Epoch: 5| Step: 5
Training loss: 2.7135422914666587
Validation loss: 2.5083152490166367

Epoch: 5| Step: 6
Training loss: 2.4324662488299356
Validation loss: 2.5993681915398943

Epoch: 5| Step: 7
Training loss: 1.6006833524542632
Validation loss: 2.5120814430325864

Epoch: 5| Step: 8
Training loss: 2.2183473248497885
Validation loss: 2.5208876846408264

Epoch: 5| Step: 9
Training loss: 2.385190583777565
Validation loss: 2.5365176751819547

Epoch: 5| Step: 10
Training loss: 2.6476431136313336
Validation loss: 2.501767568334098

Epoch: 291| Step: 0
Training loss: 2.3166557293457624
Validation loss: 2.5358896882523023

Epoch: 5| Step: 1
Training loss: 2.5421309958979643
Validation loss: 2.518461706587536

Epoch: 5| Step: 2
Training loss: 2.5141124087371014
Validation loss: 2.5579210764966556

Epoch: 5| Step: 3
Training loss: 2.0364194380093807
Validation loss: 2.524322649651258

Epoch: 5| Step: 4
Training loss: 2.506288439677063
Validation loss: 2.539284161530602

Epoch: 5| Step: 5
Training loss: 2.117854052132208
Validation loss: 2.551777292719455

Epoch: 5| Step: 6
Training loss: 2.020816947110259
Validation loss: 2.53396601712996

Epoch: 5| Step: 7
Training loss: 2.4813301092711417
Validation loss: 2.5340070396450067

Epoch: 5| Step: 8
Training loss: 2.550112673196244
Validation loss: 2.5541500517053435

Epoch: 5| Step: 9
Training loss: 2.6481585060288553
Validation loss: 2.546398384738358

Epoch: 5| Step: 10
Training loss: 2.2582938661211696
Validation loss: 2.47633217634393

Epoch: 292| Step: 0
Training loss: 2.367477348887959
Validation loss: 2.532991992579695

Epoch: 5| Step: 1
Training loss: 2.496443985081218
Validation loss: 2.5335597857404135

Epoch: 5| Step: 2
Training loss: 2.0659280667185556
Validation loss: 2.523596886552886

Epoch: 5| Step: 3
Training loss: 2.136934203281433
Validation loss: 2.5359524660419024

Epoch: 5| Step: 4
Training loss: 2.450194339440321
Validation loss: 2.558522151047608

Epoch: 5| Step: 5
Training loss: 2.1352042736092165
Validation loss: 2.5465900199548295

Epoch: 5| Step: 6
Training loss: 2.5075954450277806
Validation loss: 2.5376488048373838

Epoch: 5| Step: 7
Training loss: 2.143991649120351
Validation loss: 2.5268762057167184

Epoch: 5| Step: 8
Training loss: 2.5119834748532464
Validation loss: 2.5491899309550723

Epoch: 5| Step: 9
Training loss: 2.435302722137375
Validation loss: 2.5202865990772074

Epoch: 5| Step: 10
Training loss: 2.663337496999733
Validation loss: 2.5191878729405612

Epoch: 293| Step: 0
Training loss: 2.5386294890688115
Validation loss: 2.540720929270877

Epoch: 5| Step: 1
Training loss: 2.415901742655022
Validation loss: 2.5133065829476378

Epoch: 5| Step: 2
Training loss: 2.3889100150226437
Validation loss: 2.516463720596016

Epoch: 5| Step: 3
Training loss: 2.0370494508204486
Validation loss: 2.535125668023947

Epoch: 5| Step: 4
Training loss: 2.281284070740331
Validation loss: 2.5432787086096575

Epoch: 5| Step: 5
Training loss: 2.4046099139035446
Validation loss: 2.5576380273800114

Epoch: 5| Step: 6
Training loss: 2.0009706049356164
Validation loss: 2.5479527899459287

Epoch: 5| Step: 7
Training loss: 2.2514848048446905
Validation loss: 2.560454670571049

Epoch: 5| Step: 8
Training loss: 2.2505962853267056
Validation loss: 2.4993751791041983

Epoch: 5| Step: 9
Training loss: 2.7390455194307064
Validation loss: 2.5212517908582

Epoch: 5| Step: 10
Training loss: 2.6320278005784017
Validation loss: 2.5164268325044543

Epoch: 294| Step: 0
Training loss: 2.6280432725824583
Validation loss: 2.508785433859148

Epoch: 5| Step: 1
Training loss: 2.629593417864048
Validation loss: 2.52159400134111

Epoch: 5| Step: 2
Training loss: 2.2082584176461832
Validation loss: 2.5506798212202675

Epoch: 5| Step: 3
Training loss: 2.769177412880285
Validation loss: 2.525826174483094

Epoch: 5| Step: 4
Training loss: 2.464647965431546
Validation loss: 2.5421564392483096

Epoch: 5| Step: 5
Training loss: 1.9092408777758025
Validation loss: 2.5101461362195994

Epoch: 5| Step: 6
Training loss: 2.3919452686618743
Validation loss: 2.4562910727647598

Epoch: 5| Step: 7
Training loss: 1.969360075385303
Validation loss: 2.5291612059220747

Epoch: 5| Step: 8
Training loss: 2.1667998590856277
Validation loss: 2.516409114129206

Epoch: 5| Step: 9
Training loss: 2.5171110135658017
Validation loss: 2.5117978916487917

Epoch: 5| Step: 10
Training loss: 1.7853546366233721
Validation loss: 2.5155111368751983

Epoch: 295| Step: 0
Training loss: 2.252103775689164
Validation loss: 2.5051405712909505

Epoch: 5| Step: 1
Training loss: 2.1038425938792464
Validation loss: 2.5186975001232184

Epoch: 5| Step: 2
Training loss: 2.8640660229217456
Validation loss: 2.5349412106984484

Epoch: 5| Step: 3
Training loss: 2.680483596925191
Validation loss: 2.5198079946650127

Epoch: 5| Step: 4
Training loss: 1.6513097968525696
Validation loss: 2.4966792725003946

Epoch: 5| Step: 5
Training loss: 2.5277423809586743
Validation loss: 2.5208048041314193

Epoch: 5| Step: 6
Training loss: 2.265669302671642
Validation loss: 2.533068037073239

Epoch: 5| Step: 7
Training loss: 2.5413994466254906
Validation loss: 2.5182167744586397

Epoch: 5| Step: 8
Training loss: 2.2321246358945186
Validation loss: 2.56032616515017

Epoch: 5| Step: 9
Training loss: 2.143720296314747
Validation loss: 2.5577087670366256

Epoch: 5| Step: 10
Training loss: 2.689530160281298
Validation loss: 2.565683327948203

Epoch: 296| Step: 0
Training loss: 1.840029826544462
Validation loss: 2.542165237465317

Epoch: 5| Step: 1
Training loss: 2.6079123960712858
Validation loss: 2.5639650452245126

Epoch: 5| Step: 2
Training loss: 2.4288269677877685
Validation loss: 2.530789223857879

Epoch: 5| Step: 3
Training loss: 2.2374718818815786
Validation loss: 2.551306399395821

Epoch: 5| Step: 4
Training loss: 2.876297533553488
Validation loss: 2.5394649972249193

Epoch: 5| Step: 5
Training loss: 2.9214580054737365
Validation loss: 2.5108059514188623

Epoch: 5| Step: 6
Training loss: 2.5703211265349633
Validation loss: 2.4915205285818267

Epoch: 5| Step: 7
Training loss: 2.18119961918139
Validation loss: 2.5398669582848696

Epoch: 5| Step: 8
Training loss: 2.1101712454778876
Validation loss: 2.5407933698879646

Epoch: 5| Step: 9
Training loss: 1.5786816210221042
Validation loss: 2.5427059070951166

Epoch: 5| Step: 10
Training loss: 2.0829342141899994
Validation loss: 2.5185227994973256

Epoch: 297| Step: 0
Training loss: 2.05933738755189
Validation loss: 2.5197205052955094

Epoch: 5| Step: 1
Training loss: 2.477429355572632
Validation loss: 2.5143625297456462

Epoch: 5| Step: 2
Training loss: 2.4853197136957386
Validation loss: 2.5159797171243

Epoch: 5| Step: 3
Training loss: 2.1921278909421735
Validation loss: 2.517553855825925

Epoch: 5| Step: 4
Training loss: 2.092460349013769
Validation loss: 2.479523877490292

Epoch: 5| Step: 5
Training loss: 2.940020676883986
Validation loss: 2.5830706649072463

Epoch: 5| Step: 6
Training loss: 2.2951523945062053
Validation loss: 2.4881608582013035

Epoch: 5| Step: 7
Training loss: 2.1296554507043153
Validation loss: 2.505639689142171

Epoch: 5| Step: 8
Training loss: 1.7183451782666843
Validation loss: 2.5604854201006204

Epoch: 5| Step: 9
Training loss: 2.248819995445995
Validation loss: 2.506583053672107

Epoch: 5| Step: 10
Training loss: 2.9732134543687336
Validation loss: 2.4803786968343

Epoch: 298| Step: 0
Training loss: 2.243905183743915
Validation loss: 2.534917502176842

Epoch: 5| Step: 1
Training loss: 2.3879712902880024
Validation loss: 2.540608358382282

Epoch: 5| Step: 2
Training loss: 2.5951435987251554
Validation loss: 2.476091860789426

Epoch: 5| Step: 3
Training loss: 2.0733739709500276
Validation loss: 2.5520456183641294

Epoch: 5| Step: 4
Training loss: 2.230396062464912
Validation loss: 2.513785476731615

Epoch: 5| Step: 5
Training loss: 2.206397905876267
Validation loss: 2.5762319446718416

Epoch: 5| Step: 6
Training loss: 2.576216019837133
Validation loss: 2.4958156556785953

Epoch: 5| Step: 7
Training loss: 1.9333615558581292
Validation loss: 2.5363337759579383

Epoch: 5| Step: 8
Training loss: 2.4216538851305063
Validation loss: 2.5101134458743615

Epoch: 5| Step: 9
Training loss: 2.5852084788916923
Validation loss: 2.5527540064410683

Epoch: 5| Step: 10
Training loss: 2.1562829498869447
Validation loss: 2.5460486647769174

Epoch: 299| Step: 0
Training loss: 2.313477490007465
Validation loss: 2.552437044853589

Epoch: 5| Step: 1
Training loss: 2.1192835043278917
Validation loss: 2.5582741679385066

Epoch: 5| Step: 2
Training loss: 2.4509763601681325
Validation loss: 2.4900507197094814

Epoch: 5| Step: 3
Training loss: 2.9904285968317357
Validation loss: 2.5085464766638057

Epoch: 5| Step: 4
Training loss: 1.8785262328268997
Validation loss: 2.489741883901604

Epoch: 5| Step: 5
Training loss: 2.3314414756214763
Validation loss: 2.5070053149402014

Epoch: 5| Step: 6
Training loss: 2.1300407536507686
Validation loss: 2.5166511396898734

Epoch: 5| Step: 7
Training loss: 1.529387684509529
Validation loss: 2.509020650080173

Epoch: 5| Step: 8
Training loss: 2.531295022446341
Validation loss: 2.517772891083774

Epoch: 5| Step: 9
Training loss: 2.6514509943016304
Validation loss: 2.5051380896611004

Epoch: 5| Step: 10
Training loss: 2.4787490770854763
Validation loss: 2.5127513209014785

Epoch: 300| Step: 0
Training loss: 2.3505341064925886
Validation loss: 2.522582169988053

Epoch: 5| Step: 1
Training loss: 2.0259693462993895
Validation loss: 2.4939402644174873

Epoch: 5| Step: 2
Training loss: 2.739016707582132
Validation loss: 2.520862841215209

Epoch: 5| Step: 3
Training loss: 2.2077938956457497
Validation loss: 2.5260461294483427

Epoch: 5| Step: 4
Training loss: 2.1977136045064793
Validation loss: 2.54292008815395

Epoch: 5| Step: 5
Training loss: 2.329517332190633
Validation loss: 2.5297795821320492

Epoch: 5| Step: 6
Training loss: 2.2971678047648787
Validation loss: 2.5393155778159526

Epoch: 5| Step: 7
Training loss: 2.1173101298160204
Validation loss: 2.512352116448275

Epoch: 5| Step: 8
Training loss: 2.851718678835234
Validation loss: 2.528029720424921

Epoch: 5| Step: 9
Training loss: 2.3389552599545054
Validation loss: 2.486911362531894

Epoch: 5| Step: 10
Training loss: 2.3569487165618264
Validation loss: 2.5245558714130847

Epoch: 301| Step: 0
Training loss: 2.348652100037747
Validation loss: 2.547631389030475

Epoch: 5| Step: 1
Training loss: 2.5865282380859513
Validation loss: 2.5585927901101426

Epoch: 5| Step: 2
Training loss: 3.1118186664558127
Validation loss: 2.5787321159554626

Epoch: 5| Step: 3
Training loss: 1.9621528415623293
Validation loss: 2.5339420005207347

Epoch: 5| Step: 4
Training loss: 2.3134842917175127
Validation loss: 2.557054146768477

Epoch: 5| Step: 5
Training loss: 1.974528053488185
Validation loss: 2.53620247300973

Epoch: 5| Step: 6
Training loss: 2.4462855538896995
Validation loss: 2.4875635627997776

Epoch: 5| Step: 7
Training loss: 2.156215280446812
Validation loss: 2.5640927578822974

Epoch: 5| Step: 8
Training loss: 1.8822255466193625
Validation loss: 2.5279437102352547

Epoch: 5| Step: 9
Training loss: 2.3975552107228637
Validation loss: 2.546731983716359

Epoch: 5| Step: 10
Training loss: 2.2327946762964577
Validation loss: 2.5120007458033804

Epoch: 302| Step: 0
Training loss: 2.3351449291660593
Validation loss: 2.545330842509767

Epoch: 5| Step: 1
Training loss: 1.8147907250975988
Validation loss: 2.529655069522097

Epoch: 5| Step: 2
Training loss: 2.056614657362179
Validation loss: 2.502367104952704

Epoch: 5| Step: 3
Training loss: 2.3332669611982335
Validation loss: 2.5688709842622437

Epoch: 5| Step: 4
Training loss: 2.528552937921092
Validation loss: 2.5425463138870095

Epoch: 5| Step: 5
Training loss: 2.006135707939075
Validation loss: 2.5364037564061315

Epoch: 5| Step: 6
Training loss: 2.966068864091116
Validation loss: 2.537265383796865

Epoch: 5| Step: 7
Training loss: 2.4055410554530585
Validation loss: 2.526891937270114

Epoch: 5| Step: 8
Training loss: 2.3162561789366913
Validation loss: 2.5381256652030064

Epoch: 5| Step: 9
Training loss: 2.34188331018159
Validation loss: 2.53086090844773

Epoch: 5| Step: 10
Training loss: 2.4667406234307836
Validation loss: 2.542042121174424

Epoch: 303| Step: 0
Training loss: 2.6329227956426946
Validation loss: 2.5328275888410094

Epoch: 5| Step: 1
Training loss: 2.329982554161673
Validation loss: 2.579723172304422

Epoch: 5| Step: 2
Training loss: 1.8913125293427
Validation loss: 2.5351855069039417

Epoch: 5| Step: 3
Training loss: 2.417039140958073
Validation loss: 2.5754456041831872

Epoch: 5| Step: 4
Training loss: 2.0145680813243247
Validation loss: 2.516017960831921

Epoch: 5| Step: 5
Training loss: 2.0723614612102357
Validation loss: 2.555332372012769

Epoch: 5| Step: 6
Training loss: 3.3713016733205854
Validation loss: 2.543031888337731

Epoch: 5| Step: 7
Training loss: 2.2594416987069965
Validation loss: 2.522300335727048

Epoch: 5| Step: 8
Training loss: 2.0904609695655885
Validation loss: 2.5253245706047664

Epoch: 5| Step: 9
Training loss: 2.247410131403828
Validation loss: 2.569600927112288

Epoch: 5| Step: 10
Training loss: 1.9556448588547062
Validation loss: 2.5375711064034623

Epoch: 304| Step: 0
Training loss: 2.452307109188382
Validation loss: 2.5965133764477852

Epoch: 5| Step: 1
Training loss: 2.0750962752102855
Validation loss: 2.534977643294927

Epoch: 5| Step: 2
Training loss: 2.0182025604135028
Validation loss: 2.526269659661903

Epoch: 5| Step: 3
Training loss: 2.3119227745727966
Validation loss: 2.4988918596716143

Epoch: 5| Step: 4
Training loss: 1.552895130976744
Validation loss: 2.561026057486598

Epoch: 5| Step: 5
Training loss: 2.272765699408533
Validation loss: 2.5021898451407942

Epoch: 5| Step: 6
Training loss: 2.687310944050924
Validation loss: 2.5369682152434896

Epoch: 5| Step: 7
Training loss: 2.458025465831025
Validation loss: 2.443068126622719

Epoch: 5| Step: 8
Training loss: 2.5914820671778522
Validation loss: 2.5232442786113687

Epoch: 5| Step: 9
Training loss: 2.7184039367014114
Validation loss: 2.541036093560374

Epoch: 5| Step: 10
Training loss: 1.9733816493838072
Validation loss: 2.5146961202938214

Epoch: 305| Step: 0
Training loss: 2.1766276879006754
Validation loss: 2.584356175619824

Epoch: 5| Step: 1
Training loss: 2.581019955191017
Validation loss: 2.5443774741825687

Epoch: 5| Step: 2
Training loss: 1.863011626563084
Validation loss: 2.479830807949136

Epoch: 5| Step: 3
Training loss: 2.4010242342919463
Validation loss: 2.5011021307384826

Epoch: 5| Step: 4
Training loss: 2.140989397873479
Validation loss: 2.513969518182448

Epoch: 5| Step: 5
Training loss: 1.898794321192078
Validation loss: 2.5225090986591603

Epoch: 5| Step: 6
Training loss: 2.5125890383909355
Validation loss: 2.5365013868014157

Epoch: 5| Step: 7
Training loss: 2.4906488051287967
Validation loss: 2.524781363301473

Epoch: 5| Step: 8
Training loss: 2.3207567605262556
Validation loss: 2.508128247557395

Epoch: 5| Step: 9
Training loss: 1.9827082685485469
Validation loss: 2.548186072874668

Epoch: 5| Step: 10
Training loss: 2.813769922715522
Validation loss: 2.5278594729046495

Epoch: 306| Step: 0
Training loss: 2.1652940901894313
Validation loss: 2.5211434908706307

Epoch: 5| Step: 1
Training loss: 2.3224542154617946
Validation loss: 2.5289543231248848

Epoch: 5| Step: 2
Training loss: 2.6970868890476543
Validation loss: 2.539712464950515

Epoch: 5| Step: 3
Training loss: 2.018072726841814
Validation loss: 2.511647937850531

Epoch: 5| Step: 4
Training loss: 2.1941724104274276
Validation loss: 2.5238795633448263

Epoch: 5| Step: 5
Training loss: 2.6953222302247375
Validation loss: 2.5155488536889345

Epoch: 5| Step: 6
Training loss: 2.0863468754277017
Validation loss: 2.5037320368073264

Epoch: 5| Step: 7
Training loss: 1.9998443662170229
Validation loss: 2.51003089186994

Epoch: 5| Step: 8
Training loss: 2.418492077227524
Validation loss: 2.5079988534260766

Epoch: 5| Step: 9
Training loss: 1.8941229626097011
Validation loss: 2.5597295513799705

Epoch: 5| Step: 10
Training loss: 2.874845251811442
Validation loss: 2.5426642354652707

Epoch: 307| Step: 0
Training loss: 2.20414688543759
Validation loss: 2.5219476278299013

Epoch: 5| Step: 1
Training loss: 2.1681352431142487
Validation loss: 2.537462742667999

Epoch: 5| Step: 2
Training loss: 2.5580500600180023
Validation loss: 2.5379226056845496

Epoch: 5| Step: 3
Training loss: 2.793392293333603
Validation loss: 2.5475221656330045

Epoch: 5| Step: 4
Training loss: 2.1606194273788804
Validation loss: 2.520159195372008

Epoch: 5| Step: 5
Training loss: 2.2738848373924183
Validation loss: 2.540639746689162

Epoch: 5| Step: 6
Training loss: 2.2246248078920345
Validation loss: 2.498274222882133

Epoch: 5| Step: 7
Training loss: 2.2201173893933555
Validation loss: 2.5145614007147494

Epoch: 5| Step: 8
Training loss: 2.431579245899536
Validation loss: 2.561295356992477

Epoch: 5| Step: 9
Training loss: 1.8343230595944213
Validation loss: 2.536993313243191

Epoch: 5| Step: 10
Training loss: 2.268213306346733
Validation loss: 2.545181113758732

Epoch: 308| Step: 0
Training loss: 2.22140151074407
Validation loss: 2.56109586272845

Epoch: 5| Step: 1
Training loss: 2.4347086843010373
Validation loss: 2.5521486482848905

Epoch: 5| Step: 2
Training loss: 2.380005831350668
Validation loss: 2.5393123986485087

Epoch: 5| Step: 3
Training loss: 2.068708727099324
Validation loss: 2.503819017956237

Epoch: 5| Step: 4
Training loss: 2.1335186470527456
Validation loss: 2.5186847302225273

Epoch: 5| Step: 5
Training loss: 2.6735886103576374
Validation loss: 2.5360705233820373

Epoch: 5| Step: 6
Training loss: 2.525227953752751
Validation loss: 2.5214537349752737

Epoch: 5| Step: 7
Training loss: 2.006131548370564
Validation loss: 2.5325079106159327

Epoch: 5| Step: 8
Training loss: 2.6329184491038355
Validation loss: 2.5361307867630747

Epoch: 5| Step: 9
Training loss: 1.8934708291932727
Validation loss: 2.503923579734784

Epoch: 5| Step: 10
Training loss: 2.2493005301106073
Validation loss: 2.5142352999877815

Epoch: 309| Step: 0
Training loss: 2.251103554409926
Validation loss: 2.5330448023835452

Epoch: 5| Step: 1
Training loss: 2.401085699398952
Validation loss: 2.5148325156992963

Epoch: 5| Step: 2
Training loss: 2.0789969773190293
Validation loss: 2.574014771542674

Epoch: 5| Step: 3
Training loss: 2.4211363619722372
Validation loss: 2.551696661326668

Epoch: 5| Step: 4
Training loss: 1.8956791182734507
Validation loss: 2.5202285873779924

Epoch: 5| Step: 5
Training loss: 2.5557750755049367
Validation loss: 2.5242977882367272

Epoch: 5| Step: 6
Training loss: 1.9859300662786226
Validation loss: 2.579564667754106

Epoch: 5| Step: 7
Training loss: 2.5315353797822686
Validation loss: 2.5539130132317083

Epoch: 5| Step: 8
Training loss: 2.183478992155819
Validation loss: 2.543853731286046

Epoch: 5| Step: 9
Training loss: 2.5154870036878854
Validation loss: 2.5051857866680525

Epoch: 5| Step: 10
Training loss: 2.2691101629044996
Validation loss: 2.5147683436503816

Epoch: 310| Step: 0
Training loss: 2.1241711514728543
Validation loss: 2.5722853146813693

Epoch: 5| Step: 1
Training loss: 2.383296329593389
Validation loss: 2.547079941077097

Epoch: 5| Step: 2
Training loss: 2.1813769065862156
Validation loss: 2.534387313092438

Epoch: 5| Step: 3
Training loss: 2.5771020882946085
Validation loss: 2.5134748450532625

Epoch: 5| Step: 4
Training loss: 1.7727235541715947
Validation loss: 2.5626120714140685

Epoch: 5| Step: 5
Training loss: 2.3571562787288998
Validation loss: 2.5343357259198416

Epoch: 5| Step: 6
Training loss: 1.9319223906209504
Validation loss: 2.528354200160147

Epoch: 5| Step: 7
Training loss: 2.561588218181042
Validation loss: 2.5377785409019737

Epoch: 5| Step: 8
Training loss: 3.0916030061513466
Validation loss: 2.5824818708084867

Epoch: 5| Step: 9
Training loss: 2.0741909334145876
Validation loss: 2.542079864380774

Epoch: 5| Step: 10
Training loss: 2.054949725573302
Validation loss: 2.5423184458003987

Epoch: 311| Step: 0
Training loss: 2.7550185101505167
Validation loss: 2.5131598528771515

Epoch: 5| Step: 1
Training loss: 1.927752555599109
Validation loss: 2.524219632124547

Epoch: 5| Step: 2
Training loss: 2.134739937588477
Validation loss: 2.533866316133632

Epoch: 5| Step: 3
Training loss: 2.2866394967595722
Validation loss: 2.524317378300302

Epoch: 5| Step: 4
Training loss: 1.8205957151467935
Validation loss: 2.509023985133423

Epoch: 5| Step: 5
Training loss: 2.255933672849804
Validation loss: 2.485167666545564

Epoch: 5| Step: 6
Training loss: 2.7818422008492907
Validation loss: 2.5231373682509215

Epoch: 5| Step: 7
Training loss: 1.97670350306873
Validation loss: 2.5248971761591035

Epoch: 5| Step: 8
Training loss: 2.4992494410126613
Validation loss: 2.518462021130697

Epoch: 5| Step: 9
Training loss: 2.5062866322415878
Validation loss: 2.5576890633696645

Epoch: 5| Step: 10
Training loss: 2.152387725879301
Validation loss: 2.52294553375726

Epoch: 312| Step: 0
Training loss: 2.1328082521277523
Validation loss: 2.5620805240450046

Epoch: 5| Step: 1
Training loss: 2.306725690211472
Validation loss: 2.5169121265876786

Epoch: 5| Step: 2
Training loss: 2.0538637083573303
Validation loss: 2.575620011147157

Epoch: 5| Step: 3
Training loss: 2.5623892783458446
Validation loss: 2.519581205027503

Epoch: 5| Step: 4
Training loss: 2.500496242862862
Validation loss: 2.5605510059818744

Epoch: 5| Step: 5
Training loss: 1.757472908277874
Validation loss: 2.494482724452483

Epoch: 5| Step: 6
Training loss: 2.5177645854692248
Validation loss: 2.5720471088524457

Epoch: 5| Step: 7
Training loss: 2.1956123337351814
Validation loss: 2.49393411214177

Epoch: 5| Step: 8
Training loss: 2.0297348240128676
Validation loss: 2.508874116910512

Epoch: 5| Step: 9
Training loss: 2.5459181971747094
Validation loss: 2.5306325888961436

Epoch: 5| Step: 10
Training loss: 2.4527083121985345
Validation loss: 2.505087724835822

Epoch: 313| Step: 0
Training loss: 2.558280075297572
Validation loss: 2.5633397420924706

Epoch: 5| Step: 1
Training loss: 2.4013250904962
Validation loss: 2.562993710125705

Epoch: 5| Step: 2
Training loss: 1.8498765698059008
Validation loss: 2.51892755183339

Epoch: 5| Step: 3
Training loss: 2.2152071323377767
Validation loss: 2.50866119751618

Epoch: 5| Step: 4
Training loss: 1.8755297866038365
Validation loss: 2.5311543780695485

Epoch: 5| Step: 5
Training loss: 2.240358144705134
Validation loss: 2.564517434811803

Epoch: 5| Step: 6
Training loss: 2.2873218154298507
Validation loss: 2.5218095149518223

Epoch: 5| Step: 7
Training loss: 1.7826512497002496
Validation loss: 2.564401086964164

Epoch: 5| Step: 8
Training loss: 2.6868164612666052
Validation loss: 2.5270574951257685

Epoch: 5| Step: 9
Training loss: 2.64472426551092
Validation loss: 2.5004162841734026

Epoch: 5| Step: 10
Training loss: 2.590540175205362
Validation loss: 2.53013697675624

Epoch: 314| Step: 0
Training loss: 1.6895650308403998
Validation loss: 2.5171347360142686

Epoch: 5| Step: 1
Training loss: 1.6591526004585222
Validation loss: 2.5294370155598385

Epoch: 5| Step: 2
Training loss: 2.4105794031263224
Validation loss: 2.5630581535778028

Epoch: 5| Step: 3
Training loss: 2.5350394435123835
Validation loss: 2.5312177736293724

Epoch: 5| Step: 4
Training loss: 2.031541304607578
Validation loss: 2.5505352974882705

Epoch: 5| Step: 5
Training loss: 2.0333617750377857
Validation loss: 2.596631529684037

Epoch: 5| Step: 6
Training loss: 2.0933795430414346
Validation loss: 2.5204514587380404

Epoch: 5| Step: 7
Training loss: 2.580531436390896
Validation loss: 2.5238766735231843

Epoch: 5| Step: 8
Training loss: 2.501837055453167
Validation loss: 2.5408199102795916

Epoch: 5| Step: 9
Training loss: 3.2703528243639393
Validation loss: 2.544410924308136

Epoch: 5| Step: 10
Training loss: 1.7331141794873224
Validation loss: 2.5455790854683182

Epoch: 315| Step: 0
Training loss: 1.8749890009239563
Validation loss: 2.584550256995589

Epoch: 5| Step: 1
Training loss: 2.0718479436658384
Validation loss: 2.560571523627074

Epoch: 5| Step: 2
Training loss: 2.0873363819073654
Validation loss: 2.5467124709443945

Epoch: 5| Step: 3
Training loss: 2.076303242845322
Validation loss: 2.552239939890728

Epoch: 5| Step: 4
Training loss: 2.10445412161049
Validation loss: 2.5004685608855337

Epoch: 5| Step: 5
Training loss: 2.1896687247493642
Validation loss: 2.5299452043518924

Epoch: 5| Step: 6
Training loss: 2.3060956370893084
Validation loss: 2.543025337669459

Epoch: 5| Step: 7
Training loss: 2.2359262696736555
Validation loss: 2.5024755690569016

Epoch: 5| Step: 8
Training loss: 2.8032968627909955
Validation loss: 2.575530665086369

Epoch: 5| Step: 9
Training loss: 2.5397605523311624
Validation loss: 2.545195719888718

Epoch: 5| Step: 10
Training loss: 2.4679568984473765
Validation loss: 2.476850780704528

Epoch: 316| Step: 0
Training loss: 2.2542218759184154
Validation loss: 2.566591053975489

Epoch: 5| Step: 1
Training loss: 2.6875054115418355
Validation loss: 2.5282534636241962

Epoch: 5| Step: 2
Training loss: 2.5536199083023066
Validation loss: 2.541413154513359

Epoch: 5| Step: 3
Training loss: 2.344521052367911
Validation loss: 2.5450772971238775

Epoch: 5| Step: 4
Training loss: 1.9257515369158074
Validation loss: 2.5067045427101706

Epoch: 5| Step: 5
Training loss: 1.7609554421865576
Validation loss: 2.5530804810439602

Epoch: 5| Step: 6
Training loss: 2.0309773188742146
Validation loss: 2.5315030081783916

Epoch: 5| Step: 7
Training loss: 2.0091068830525907
Validation loss: 2.5597850244093205

Epoch: 5| Step: 8
Training loss: 2.363411084856837
Validation loss: 2.552387994023004

Epoch: 5| Step: 9
Training loss: 2.879211326801123
Validation loss: 2.515406010081229

Epoch: 5| Step: 10
Training loss: 2.1426526789530103
Validation loss: 2.589830997314197

Epoch: 317| Step: 0
Training loss: 2.0659909615258942
Validation loss: 2.5215138129050696

Epoch: 5| Step: 1
Training loss: 2.383940682908546
Validation loss: 2.509885432969752

Epoch: 5| Step: 2
Training loss: 2.15707481199363
Validation loss: 2.5081374804677377

Epoch: 5| Step: 3
Training loss: 2.6226980924748546
Validation loss: 2.549271701574815

Epoch: 5| Step: 4
Training loss: 2.2076329854133165
Validation loss: 2.542909253560786

Epoch: 5| Step: 5
Training loss: 1.8834457282340267
Validation loss: 2.5760009975649885

Epoch: 5| Step: 6
Training loss: 2.1946338405510377
Validation loss: 2.5278719591468195

Epoch: 5| Step: 7
Training loss: 2.3792875638888265
Validation loss: 2.5541331571059596

Epoch: 5| Step: 8
Training loss: 2.270169245590621
Validation loss: 2.52272945716231

Epoch: 5| Step: 9
Training loss: 2.7047084514438913
Validation loss: 2.533941630736927

Epoch: 5| Step: 10
Training loss: 2.2573252221397566
Validation loss: 2.546724214461984

Epoch: 318| Step: 0
Training loss: 2.201732980315203
Validation loss: 2.497598879361168

Epoch: 5| Step: 1
Training loss: 2.0686364641180215
Validation loss: 2.5058425865544174

Epoch: 5| Step: 2
Training loss: 2.4317255334698844
Validation loss: 2.5389810892057962

Epoch: 5| Step: 3
Training loss: 1.5040758706090394
Validation loss: 2.5485215553346294

Epoch: 5| Step: 4
Training loss: 2.439941943681775
Validation loss: 2.541289105976659

Epoch: 5| Step: 5
Training loss: 2.0986203157346632
Validation loss: 2.5409599793036723

Epoch: 5| Step: 6
Training loss: 2.3990598983124447
Validation loss: 2.5476639541842716

Epoch: 5| Step: 7
Training loss: 2.577618635908702
Validation loss: 2.5450446797336475

Epoch: 5| Step: 8
Training loss: 2.328228429762592
Validation loss: 2.5707431144125876

Epoch: 5| Step: 9
Training loss: 2.2255886156535554
Validation loss: 2.527789008452063

Epoch: 5| Step: 10
Training loss: 2.5169738565207984
Validation loss: 2.5528627358603004

Epoch: 319| Step: 0
Training loss: 2.332206067764401
Validation loss: 2.5034203972980467

Epoch: 5| Step: 1
Training loss: 2.606900806724543
Validation loss: 2.528821715500914

Epoch: 5| Step: 2
Training loss: 2.1739102713940404
Validation loss: 2.494827457958808

Epoch: 5| Step: 3
Training loss: 2.3967472047320957
Validation loss: 2.536966805071506

Epoch: 5| Step: 4
Training loss: 1.8192430227800347
Validation loss: 2.5335865688641808

Epoch: 5| Step: 5
Training loss: 2.8599617778118005
Validation loss: 2.521874779040217

Epoch: 5| Step: 6
Training loss: 1.958124338996744
Validation loss: 2.5604288318297344

Epoch: 5| Step: 7
Training loss: 2.106953679383548
Validation loss: 2.5500345748931634

Epoch: 5| Step: 8
Training loss: 2.221017994697426
Validation loss: 2.5008947073763386

Epoch: 5| Step: 9
Training loss: 2.548667043221729
Validation loss: 2.5324697944517682

Epoch: 5| Step: 10
Training loss: 1.9166008136327577
Validation loss: 2.5643936301652257

Epoch: 320| Step: 0
Training loss: 2.5695740354924497
Validation loss: 2.5297889133637512

Epoch: 5| Step: 1
Training loss: 2.277902106119997
Validation loss: 2.5022627880539328

Epoch: 5| Step: 2
Training loss: 1.768090476288623
Validation loss: 2.533776277840851

Epoch: 5| Step: 3
Training loss: 2.852447121720989
Validation loss: 2.568508268616659

Epoch: 5| Step: 4
Training loss: 2.367477248182208
Validation loss: 2.5299600960388084

Epoch: 5| Step: 5
Training loss: 2.1174346666942303
Validation loss: 2.5161061525816493

Epoch: 5| Step: 6
Training loss: 2.3395415096558625
Validation loss: 2.5738349235147973

Epoch: 5| Step: 7
Training loss: 1.9148714808273524
Validation loss: 2.5511276220251826

Epoch: 5| Step: 8
Training loss: 2.210455097100506
Validation loss: 2.5431816700362506

Epoch: 5| Step: 9
Training loss: 2.308636815013144
Validation loss: 2.535367100065702

Epoch: 5| Step: 10
Training loss: 1.9593392352136116
Validation loss: 2.538174021014527

Epoch: 321| Step: 0
Training loss: 2.0988395663627055
Validation loss: 2.5197853392061735

Epoch: 5| Step: 1
Training loss: 2.1612787624053644
Validation loss: 2.5631525272832865

Epoch: 5| Step: 2
Training loss: 3.0003986093826844
Validation loss: 2.5293527869131185

Epoch: 5| Step: 3
Training loss: 2.4730774820470653
Validation loss: 2.553007532516339

Epoch: 5| Step: 4
Training loss: 2.4996884151838104
Validation loss: 2.5270577183106053

Epoch: 5| Step: 5
Training loss: 2.096161322085685
Validation loss: 2.5310021788953825

Epoch: 5| Step: 6
Training loss: 2.06261871458626
Validation loss: 2.5442114210839883

Epoch: 5| Step: 7
Training loss: 2.2986877968997805
Validation loss: 2.5422313035439243

Epoch: 5| Step: 8
Training loss: 2.0375635476529013
Validation loss: 2.5303328551651467

Epoch: 5| Step: 9
Training loss: 2.044233874981069
Validation loss: 2.5038179976475026

Epoch: 5| Step: 10
Training loss: 2.151344247246338
Validation loss: 2.464774207548708

Epoch: 322| Step: 0
Training loss: 2.200009354658179
Validation loss: 2.542291982565055

Epoch: 5| Step: 1
Training loss: 2.57433359355926
Validation loss: 2.505853716457264

Epoch: 5| Step: 2
Training loss: 2.657822267042331
Validation loss: 2.5252342257220417

Epoch: 5| Step: 3
Training loss: 2.228480319546694
Validation loss: 2.5056202431127983

Epoch: 5| Step: 4
Training loss: 2.0171845782529916
Validation loss: 2.5873738898240224

Epoch: 5| Step: 5
Training loss: 2.4464856340994983
Validation loss: 2.5609633567733177

Epoch: 5| Step: 6
Training loss: 2.2489651313409253
Validation loss: 2.4918916953426655

Epoch: 5| Step: 7
Training loss: 2.38810377625192
Validation loss: 2.4975611450116846

Epoch: 5| Step: 8
Training loss: 2.1561158732839707
Validation loss: 2.5366092756658256

Epoch: 5| Step: 9
Training loss: 2.1256448104011527
Validation loss: 2.5607530144781014

Epoch: 5| Step: 10
Training loss: 1.9203329335080797
Validation loss: 2.553661143650905

Epoch: 323| Step: 0
Training loss: 2.6973707218674527
Validation loss: 2.5590077385680585

Epoch: 5| Step: 1
Training loss: 2.374956030187655
Validation loss: 2.509851315354108

Epoch: 5| Step: 2
Training loss: 2.206766352327461
Validation loss: 2.5550234341903795

Epoch: 5| Step: 3
Training loss: 1.8874122498179722
Validation loss: 2.566860362890423

Epoch: 5| Step: 4
Training loss: 2.054910625918187
Validation loss: 2.5274175051898013

Epoch: 5| Step: 5
Training loss: 2.300485277811561
Validation loss: 2.5819310637417248

Epoch: 5| Step: 6
Training loss: 2.3641796579722274
Validation loss: 2.536779113835759

Epoch: 5| Step: 7
Training loss: 2.2725970100872632
Validation loss: 2.530047345822314

Epoch: 5| Step: 8
Training loss: 1.9932126268734438
Validation loss: 2.573084004061101

Epoch: 5| Step: 9
Training loss: 2.3459903436382357
Validation loss: 2.570599435194709

Epoch: 5| Step: 10
Training loss: 2.332151579188576
Validation loss: 2.5624398485312514

Epoch: 324| Step: 0
Training loss: 2.0839768242453416
Validation loss: 2.5447970233389205

Epoch: 5| Step: 1
Training loss: 2.288007994564468
Validation loss: 2.5504804304205355

Epoch: 5| Step: 2
Training loss: 2.1748642144623367
Validation loss: 2.5268373207842343

Epoch: 5| Step: 3
Training loss: 2.5519848447726368
Validation loss: 2.5420986271107227

Epoch: 5| Step: 4
Training loss: 2.42405769681092
Validation loss: 2.5557293788949336

Epoch: 5| Step: 5
Training loss: 2.3727324854435756
Validation loss: 2.5752127488526915

Epoch: 5| Step: 6
Training loss: 1.926319287023751
Validation loss: 2.5182073799854745

Epoch: 5| Step: 7
Training loss: 2.820856184610944
Validation loss: 2.483237228576586

Epoch: 5| Step: 8
Training loss: 2.040620522837379
Validation loss: 2.5459183099543523

Epoch: 5| Step: 9
Training loss: 2.0043861454034384
Validation loss: 2.5708073922771417

Epoch: 5| Step: 10
Training loss: 1.7391511604898533
Validation loss: 2.5682595448077117

Epoch: 325| Step: 0
Training loss: 1.9794546687405485
Validation loss: 2.550482136176303

Epoch: 5| Step: 1
Training loss: 1.8457974848771554
Validation loss: 2.5233774699022953

Epoch: 5| Step: 2
Training loss: 1.9245011909542626
Validation loss: 2.5235432684845995

Epoch: 5| Step: 3
Training loss: 2.595905006198897
Validation loss: 2.587347807155218

Epoch: 5| Step: 4
Training loss: 2.020476778436448
Validation loss: 2.4983990516642174

Epoch: 5| Step: 5
Training loss: 2.9949815419031105
Validation loss: 2.52911734159795

Epoch: 5| Step: 6
Training loss: 2.3592709145734094
Validation loss: 2.534772159633095

Epoch: 5| Step: 7
Training loss: 2.2700808150236154
Validation loss: 2.5499298162652395

Epoch: 5| Step: 8
Training loss: 2.36790128213437
Validation loss: 2.549428147665003

Epoch: 5| Step: 9
Training loss: 2.1392623016692034
Validation loss: 2.52092915438199

Epoch: 5| Step: 10
Training loss: 2.3625369074123475
Validation loss: 2.5175074674790867

Epoch: 326| Step: 0
Training loss: 2.0546510642414626
Validation loss: 2.5134801314938513

Epoch: 5| Step: 1
Training loss: 2.1041084382212105
Validation loss: 2.567459026117204

Epoch: 5| Step: 2
Training loss: 2.259528224281716
Validation loss: 2.5826137342989206

Epoch: 5| Step: 3
Training loss: 2.3776946592014334
Validation loss: 2.5648181973045134

Epoch: 5| Step: 4
Training loss: 2.150048778779019
Validation loss: 2.5174064221592922

Epoch: 5| Step: 5
Training loss: 2.187610623423551
Validation loss: 2.5629836925782414

Epoch: 5| Step: 6
Training loss: 2.2645246267093553
Validation loss: 2.4691840335843103

Epoch: 5| Step: 7
Training loss: 1.8521020803228636
Validation loss: 2.5612210999849827

Epoch: 5| Step: 8
Training loss: 2.8280725632332344
Validation loss: 2.5276424385325753

Epoch: 5| Step: 9
Training loss: 2.2415257982806955
Validation loss: 2.547484639418436

Epoch: 5| Step: 10
Training loss: 2.006561839744175
Validation loss: 2.546601706152372

Epoch: 327| Step: 0
Training loss: 2.1230929175808884
Validation loss: 2.522892922062016

Epoch: 5| Step: 1
Training loss: 1.86413426736715
Validation loss: 2.5147460816594043

Epoch: 5| Step: 2
Training loss: 2.148667645698693
Validation loss: 2.5390056967869343

Epoch: 5| Step: 3
Training loss: 1.6472727923093717
Validation loss: 2.5347035309046264

Epoch: 5| Step: 4
Training loss: 2.4382907856244773
Validation loss: 2.531432934785352

Epoch: 5| Step: 5
Training loss: 2.24573727639985
Validation loss: 2.579091884846193

Epoch: 5| Step: 6
Training loss: 2.2039348655879443
Validation loss: 2.547232926774672

Epoch: 5| Step: 7
Training loss: 2.2246677836452595
Validation loss: 2.5190935252435853

Epoch: 5| Step: 8
Training loss: 2.152911933355762
Validation loss: 2.531499002966191

Epoch: 5| Step: 9
Training loss: 2.9802847589219885
Validation loss: 2.459880941004161

Epoch: 5| Step: 10
Training loss: 2.732356519919577
Validation loss: 2.5653023227184586

Epoch: 328| Step: 0
Training loss: 1.838163349538885
Validation loss: 2.5531571226004153

Epoch: 5| Step: 1
Training loss: 2.5527988183454253
Validation loss: 2.5334918304768017

Epoch: 5| Step: 2
Training loss: 2.029547696955538
Validation loss: 2.5068729452439626

Epoch: 5| Step: 3
Training loss: 1.9601943595042994
Validation loss: 2.5245821336677703

Epoch: 5| Step: 4
Training loss: 2.497256490236304
Validation loss: 2.499243328476242

Epoch: 5| Step: 5
Training loss: 1.988739080872642
Validation loss: 2.5207095863710767

Epoch: 5| Step: 6
Training loss: 2.416172130452847
Validation loss: 2.5543872854668987

Epoch: 5| Step: 7
Training loss: 2.414002254191107
Validation loss: 2.539770845187536

Epoch: 5| Step: 8
Training loss: 2.186353764631573
Validation loss: 2.5071531209740137

Epoch: 5| Step: 9
Training loss: 2.0466406302188704
Validation loss: 2.5329095496384473

Epoch: 5| Step: 10
Training loss: 2.6690433064074233
Validation loss: 2.5466278497795436

Epoch: 329| Step: 0
Training loss: 2.1101955372028236
Validation loss: 2.5245606979936452

Epoch: 5| Step: 1
Training loss: 2.0038379560883297
Validation loss: 2.5578534276775633

Epoch: 5| Step: 2
Training loss: 1.5371883231492542
Validation loss: 2.549120572558103

Epoch: 5| Step: 3
Training loss: 1.9364964131726634
Validation loss: 2.541793293238737

Epoch: 5| Step: 4
Training loss: 2.3948753321301117
Validation loss: 2.5607012466454266

Epoch: 5| Step: 5
Training loss: 1.9165184613300803
Validation loss: 2.564078457364444

Epoch: 5| Step: 6
Training loss: 2.6155948176858694
Validation loss: 2.495194675502656

Epoch: 5| Step: 7
Training loss: 2.4651334323323923
Validation loss: 2.596580897754553

Epoch: 5| Step: 8
Training loss: 1.9264572226168195
Validation loss: 2.4969939360880584

Epoch: 5| Step: 9
Training loss: 2.876421701279016
Validation loss: 2.4976173408805242

Epoch: 5| Step: 10
Training loss: 2.495162861922951
Validation loss: 2.506792916896064

Epoch: 330| Step: 0
Training loss: 2.540976123077613
Validation loss: 2.531683361734506

Epoch: 5| Step: 1
Training loss: 2.0674063384348718
Validation loss: 2.5119048248554168

Epoch: 5| Step: 2
Training loss: 1.9422869459672671
Validation loss: 2.56243918221907

Epoch: 5| Step: 3
Training loss: 2.7922370005416095
Validation loss: 2.5224135874804996

Epoch: 5| Step: 4
Training loss: 2.1199338773096295
Validation loss: 2.521717029186248

Epoch: 5| Step: 5
Training loss: 2.6671404914311307
Validation loss: 2.5097864566942505

Epoch: 5| Step: 6
Training loss: 1.7071102307377595
Validation loss: 2.5131130467887166

Epoch: 5| Step: 7
Training loss: 1.9406827196269532
Validation loss: 2.500000565026332

Epoch: 5| Step: 8
Training loss: 2.7161173735188537
Validation loss: 2.543988687363053

Epoch: 5| Step: 9
Training loss: 2.0352043980853827
Validation loss: 2.5353443298393663

Epoch: 5| Step: 10
Training loss: 1.9571647065547075
Validation loss: 2.5142025496283127

Epoch: 331| Step: 0
Training loss: 2.573002390392274
Validation loss: 2.510921770751003

Epoch: 5| Step: 1
Training loss: 2.239859512215096
Validation loss: 2.5334587745205988

Epoch: 5| Step: 2
Training loss: 2.0241107777899363
Validation loss: 2.5293000748649295

Epoch: 5| Step: 3
Training loss: 2.3914159326566065
Validation loss: 2.5193248880807255

Epoch: 5| Step: 4
Training loss: 1.9703668887854666
Validation loss: 2.5441591141285618

Epoch: 5| Step: 5
Training loss: 2.0567688354060025
Validation loss: 2.517203981226638

Epoch: 5| Step: 6
Training loss: 1.8261617568444628
Validation loss: 2.5166861196052843

Epoch: 5| Step: 7
Training loss: 2.625481697572297
Validation loss: 2.5171708050737904

Epoch: 5| Step: 8
Training loss: 2.548448883723521
Validation loss: 2.5216993408654176

Epoch: 5| Step: 9
Training loss: 1.7611123540628555
Validation loss: 2.5145607839062776

Epoch: 5| Step: 10
Training loss: 2.24835717307597
Validation loss: 2.5295817586087748

Epoch: 332| Step: 0
Training loss: 2.468064514794585
Validation loss: 2.573856471239956

Epoch: 5| Step: 1
Training loss: 1.911402633091038
Validation loss: 2.5152117568682058

Epoch: 5| Step: 2
Training loss: 2.6148489909579706
Validation loss: 2.5208777946904575

Epoch: 5| Step: 3
Training loss: 2.5218011138567453
Validation loss: 2.504433443727643

Epoch: 5| Step: 4
Training loss: 1.8684898527103102
Validation loss: 2.542559635465916

Epoch: 5| Step: 5
Training loss: 2.3973188245494814
Validation loss: 2.557482766143773

Epoch: 5| Step: 6
Training loss: 2.1055611499901055
Validation loss: 2.5457946118509827

Epoch: 5| Step: 7
Training loss: 2.0835201815421205
Validation loss: 2.541682351391948

Epoch: 5| Step: 8
Training loss: 2.1338645939148937
Validation loss: 2.5169712347953417

Epoch: 5| Step: 9
Training loss: 1.9208247098363684
Validation loss: 2.505719516959367

Epoch: 5| Step: 10
Training loss: 2.2291630064556935
Validation loss: 2.5276190205950018

Epoch: 333| Step: 0
Training loss: 2.7094428699620847
Validation loss: 2.494363404857215

Epoch: 5| Step: 1
Training loss: 2.044079218021733
Validation loss: 2.5332176119593752

Epoch: 5| Step: 2
Training loss: 2.4408943799339045
Validation loss: 2.535404041211089

Epoch: 5| Step: 3
Training loss: 2.163491073798043
Validation loss: 2.564180681868323

Epoch: 5| Step: 4
Training loss: 2.0493351951612175
Validation loss: 2.5438286959338683

Epoch: 5| Step: 5
Training loss: 2.1029428252947677
Validation loss: 2.515821202256733

Epoch: 5| Step: 6
Training loss: 2.558553214880481
Validation loss: 2.5052272804527345

Epoch: 5| Step: 7
Training loss: 1.9216329530712533
Validation loss: 2.561174642718191

Epoch: 5| Step: 8
Training loss: 2.577520218630207
Validation loss: 2.5001418155521695

Epoch: 5| Step: 9
Training loss: 1.9512577133466131
Validation loss: 2.56622413399525

Epoch: 5| Step: 10
Training loss: 1.9499368510658317
Validation loss: 2.583770950741806

Epoch: 334| Step: 0
Training loss: 1.8672049932578167
Validation loss: 2.541452352067449

Epoch: 5| Step: 1
Training loss: 2.169538379914351
Validation loss: 2.564973224908009

Epoch: 5| Step: 2
Training loss: 2.201957339096165
Validation loss: 2.5341064852260704

Epoch: 5| Step: 3
Training loss: 2.2946656688767075
Validation loss: 2.571836338329021

Epoch: 5| Step: 4
Training loss: 1.8732651632039667
Validation loss: 2.51352742235643

Epoch: 5| Step: 5
Training loss: 2.1768405054882245
Validation loss: 2.5146683927756337

Epoch: 5| Step: 6
Training loss: 2.2638528140989664
Validation loss: 2.558034653374173

Epoch: 5| Step: 7
Training loss: 1.9353285896399943
Validation loss: 2.560022534612846

Epoch: 5| Step: 8
Training loss: 2.5514020879887798
Validation loss: 2.6092300743220322

Epoch: 5| Step: 9
Training loss: 2.529714613186618
Validation loss: 2.5464067993184005

Epoch: 5| Step: 10
Training loss: 2.5772438161762654
Validation loss: 2.5526629079682324

Epoch: 335| Step: 0
Training loss: 1.654817357429573
Validation loss: 2.513035202346588

Epoch: 5| Step: 1
Training loss: 1.5961059659470798
Validation loss: 2.5561373012673783

Epoch: 5| Step: 2
Training loss: 2.240971039209985
Validation loss: 2.5465837426974933

Epoch: 5| Step: 3
Training loss: 1.9713864309139026
Validation loss: 2.5324607312377743

Epoch: 5| Step: 4
Training loss: 2.7066629002299045
Validation loss: 2.5142580890674404

Epoch: 5| Step: 5
Training loss: 2.5306657658499323
Validation loss: 2.5689282587708

Epoch: 5| Step: 6
Training loss: 2.9121761813262577
Validation loss: 2.519902064324301

Epoch: 5| Step: 7
Training loss: 2.1904190206076652
Validation loss: 2.5381579240605654

Epoch: 5| Step: 8
Training loss: 2.1875088282815716
Validation loss: 2.527984872054715

Epoch: 5| Step: 9
Training loss: 2.1179992696096224
Validation loss: 2.551065490008722

Epoch: 5| Step: 10
Training loss: 1.8273448094384888
Validation loss: 2.4855610730215902

Epoch: 336| Step: 0
Training loss: 1.960855429098347
Validation loss: 2.537195728219956

Epoch: 5| Step: 1
Training loss: 1.843399919798399
Validation loss: 2.5392971832131046

Epoch: 5| Step: 2
Training loss: 2.57718035413284
Validation loss: 2.5375306724134434

Epoch: 5| Step: 3
Training loss: 2.678723131152752
Validation loss: 2.504762446934103

Epoch: 5| Step: 4
Training loss: 2.5972714705623043
Validation loss: 2.513432665835606

Epoch: 5| Step: 5
Training loss: 1.973807001142409
Validation loss: 2.583898802630342

Epoch: 5| Step: 6
Training loss: 2.0720656547454483
Validation loss: 2.497507224611555

Epoch: 5| Step: 7
Training loss: 1.9355150329865356
Validation loss: 2.510978448652348

Epoch: 5| Step: 8
Training loss: 2.2490637208724062
Validation loss: 2.4903360235486978

Epoch: 5| Step: 9
Training loss: 2.31661888548978
Validation loss: 2.515012334898026

Epoch: 5| Step: 10
Training loss: 2.255069320188402
Validation loss: 2.57982850137773

Epoch: 337| Step: 0
Training loss: 2.8140302098109244
Validation loss: 2.4966772383688087

Epoch: 5| Step: 1
Training loss: 1.6845375478018363
Validation loss: 2.5301550387407374

Epoch: 5| Step: 2
Training loss: 2.1863893141506674
Validation loss: 2.525412451563605

Epoch: 5| Step: 3
Training loss: 2.435021044661741
Validation loss: 2.5465209330310628

Epoch: 5| Step: 4
Training loss: 1.774099621286121
Validation loss: 2.5729845933208177

Epoch: 5| Step: 5
Training loss: 2.5641503950695164
Validation loss: 2.52001448691417

Epoch: 5| Step: 6
Training loss: 1.6558807249283414
Validation loss: 2.5528256034817303

Epoch: 5| Step: 7
Training loss: 1.7969038587823527
Validation loss: 2.460642851004374

Epoch: 5| Step: 8
Training loss: 2.5576045096812554
Validation loss: 2.4930472217909965

Epoch: 5| Step: 9
Training loss: 2.279517992501311
Validation loss: 2.511050697772344

Epoch: 5| Step: 10
Training loss: 2.132761972129272
Validation loss: 2.5081724605525015

Epoch: 338| Step: 0
Training loss: 1.7950179081610569
Validation loss: 2.5606049143840104

Epoch: 5| Step: 1
Training loss: 2.845171395018024
Validation loss: 2.528100160929276

Epoch: 5| Step: 2
Training loss: 2.0357248167372672
Validation loss: 2.571818039762404

Epoch: 5| Step: 3
Training loss: 2.6929323163513077
Validation loss: 2.5555871299759607

Epoch: 5| Step: 4
Training loss: 2.25122132532475
Validation loss: 2.596331317467122

Epoch: 5| Step: 5
Training loss: 2.513319487276397
Validation loss: 2.5068621614311257

Epoch: 5| Step: 6
Training loss: 1.840206555921653
Validation loss: 2.522273020100049

Epoch: 5| Step: 7
Training loss: 1.8205344265409609
Validation loss: 2.5034937226715868

Epoch: 5| Step: 8
Training loss: 1.9480707920182783
Validation loss: 2.573825826174128

Epoch: 5| Step: 9
Training loss: 2.1809999076636855
Validation loss: 2.537519066180938

Epoch: 5| Step: 10
Training loss: 2.1672254233146644
Validation loss: 2.461269149921178

Epoch: 339| Step: 0
Training loss: 2.2832642115504975
Validation loss: 2.5539464569141557

Epoch: 5| Step: 1
Training loss: 1.946209436482697
Validation loss: 2.5355888672700897

Epoch: 5| Step: 2
Training loss: 2.651293449711279
Validation loss: 2.517484672172149

Epoch: 5| Step: 3
Training loss: 1.9852237238070383
Validation loss: 2.547034284738149

Epoch: 5| Step: 4
Training loss: 2.7440579113423937
Validation loss: 2.5533715424620866

Epoch: 5| Step: 5
Training loss: 2.4440512039826845
Validation loss: 2.5292180346039097

Epoch: 5| Step: 6
Training loss: 1.9959590142271482
Validation loss: 2.562291523766403

Epoch: 5| Step: 7
Training loss: 1.6662914410050174
Validation loss: 2.545976248828311

Epoch: 5| Step: 8
Training loss: 2.460409634607286
Validation loss: 2.5352330441023256

Epoch: 5| Step: 9
Training loss: 2.03313663604812
Validation loss: 2.548574741448224

Epoch: 5| Step: 10
Training loss: 2.150316561082626
Validation loss: 2.5362663589731347

Epoch: 340| Step: 0
Training loss: 2.6890490303832646
Validation loss: 2.5579555642077962

Epoch: 5| Step: 1
Training loss: 2.033882079052992
Validation loss: 2.5288612237911905

Epoch: 5| Step: 2
Training loss: 2.0931735027954983
Validation loss: 2.492203273588906

Epoch: 5| Step: 3
Training loss: 2.005466025171929
Validation loss: 2.520997909452419

Epoch: 5| Step: 4
Training loss: 1.671506252800888
Validation loss: 2.5163019505491553

Epoch: 5| Step: 5
Training loss: 2.405238347604882
Validation loss: 2.5917130878576096

Epoch: 5| Step: 6
Training loss: 2.0171453375513564
Validation loss: 2.5250999044088926

Epoch: 5| Step: 7
Training loss: 2.4925705187893272
Validation loss: 2.5194134301118964

Epoch: 5| Step: 8
Training loss: 2.494922822970307
Validation loss: 2.5523997495950295

Epoch: 5| Step: 9
Training loss: 2.0535133400988332
Validation loss: 2.4981808062911264

Epoch: 5| Step: 10
Training loss: 2.1724874607158893
Validation loss: 2.535141938951252

Epoch: 341| Step: 0
Training loss: 2.663490390594833
Validation loss: 2.5455829164558113

Epoch: 5| Step: 1
Training loss: 2.1093612105307376
Validation loss: 2.5480347843883804

Epoch: 5| Step: 2
Training loss: 2.5337367146561967
Validation loss: 2.5157107139440145

Epoch: 5| Step: 3
Training loss: 1.983667442752817
Validation loss: 2.473500555632375

Epoch: 5| Step: 4
Training loss: 2.286292577715181
Validation loss: 2.561106777539695

Epoch: 5| Step: 5
Training loss: 2.009080894387195
Validation loss: 2.5175913363422837

Epoch: 5| Step: 6
Training loss: 2.6187007344057003
Validation loss: 2.5350421497024964

Epoch: 5| Step: 7
Training loss: 2.0731236212343145
Validation loss: 2.5251492188072007

Epoch: 5| Step: 8
Training loss: 1.8782026278024382
Validation loss: 2.5027569202854814

Epoch: 5| Step: 9
Training loss: 1.8045528741469563
Validation loss: 2.491583478716462

Epoch: 5| Step: 10
Training loss: 1.90641502541557
Validation loss: 2.499875437802023

Epoch: 342| Step: 0
Training loss: 2.023043678871896
Validation loss: 2.5157343436163555

Epoch: 5| Step: 1
Training loss: 2.287011591566273
Validation loss: 2.5355391371325866

Epoch: 5| Step: 2
Training loss: 2.3666164603303166
Validation loss: 2.5325188271626935

Epoch: 5| Step: 3
Training loss: 2.4532247146458714
Validation loss: 2.528490882842806

Epoch: 5| Step: 4
Training loss: 1.9721574511510833
Validation loss: 2.571776066304152

Epoch: 5| Step: 5
Training loss: 1.948894466112818
Validation loss: 2.541781447259952

Epoch: 5| Step: 6
Training loss: 2.222759438853034
Validation loss: 2.52338978732352

Epoch: 5| Step: 7
Training loss: 2.1084953451921638
Validation loss: 2.5710935964563832

Epoch: 5| Step: 8
Training loss: 1.770154157056976
Validation loss: 2.512287325411866

Epoch: 5| Step: 9
Training loss: 2.424160180719729
Validation loss: 2.5447221468785477

Epoch: 5| Step: 10
Training loss: 2.2889738619050717
Validation loss: 2.5401267472501097

Epoch: 343| Step: 0
Training loss: 2.239264626706815
Validation loss: 2.533517217911199

Epoch: 5| Step: 1
Training loss: 1.9584129466113513
Validation loss: 2.570261845328141

Epoch: 5| Step: 2
Training loss: 1.9907312194175957
Validation loss: 2.536895939256751

Epoch: 5| Step: 3
Training loss: 2.2717765692333343
Validation loss: 2.5985438097893434

Epoch: 5| Step: 4
Training loss: 1.9633393187612456
Validation loss: 2.54921173677718

Epoch: 5| Step: 5
Training loss: 2.5012204052472065
Validation loss: 2.5337766157775197

Epoch: 5| Step: 6
Training loss: 2.1257317349051736
Validation loss: 2.556300122646952

Epoch: 5| Step: 7
Training loss: 2.0610626298401353
Validation loss: 2.5352672959163884

Epoch: 5| Step: 8
Training loss: 1.6889307526508468
Validation loss: 2.4792844141684376

Epoch: 5| Step: 9
Training loss: 2.6002402854806186
Validation loss: 2.53312801108956

Epoch: 5| Step: 10
Training loss: 2.4450498202188133
Validation loss: 2.5735958844068603

Epoch: 344| Step: 0
Training loss: 2.302566845779872
Validation loss: 2.5581840707549226

Epoch: 5| Step: 1
Training loss: 2.0694703890591493
Validation loss: 2.56974238582755

Epoch: 5| Step: 2
Training loss: 2.6607544348257823
Validation loss: 2.5319544476456293

Epoch: 5| Step: 3
Training loss: 2.243046187416357
Validation loss: 2.584148866403295

Epoch: 5| Step: 4
Training loss: 2.089283634599296
Validation loss: 2.527479124097719

Epoch: 5| Step: 5
Training loss: 2.1470884214262362
Validation loss: 2.472108697729292

Epoch: 5| Step: 6
Training loss: 2.139153190345455
Validation loss: 2.5493708312696928

Epoch: 5| Step: 7
Training loss: 2.1574963271020278
Validation loss: 2.487034786104734

Epoch: 5| Step: 8
Training loss: 2.160433373774417
Validation loss: 2.543195800766671

Epoch: 5| Step: 9
Training loss: 2.538809895787923
Validation loss: 2.510224196893092

Epoch: 5| Step: 10
Training loss: 1.3958501055644494
Validation loss: 2.56029944596633

Epoch: 345| Step: 0
Training loss: 1.8836928086436533
Validation loss: 2.508844194509903

Epoch: 5| Step: 1
Training loss: 2.18940488437182
Validation loss: 2.569633433331436

Epoch: 5| Step: 2
Training loss: 2.4767233618831166
Validation loss: 2.5183962054266087

Epoch: 5| Step: 3
Training loss: 2.918860691103607
Validation loss: 2.4855151148849135

Epoch: 5| Step: 4
Training loss: 1.726302666768806
Validation loss: 2.545811439939497

Epoch: 5| Step: 5
Training loss: 2.011988234756684
Validation loss: 2.547824348750211

Epoch: 5| Step: 6
Training loss: 1.989833563069754
Validation loss: 2.520913611889505

Epoch: 5| Step: 7
Training loss: 2.103791143566949
Validation loss: 2.5523227849702117

Epoch: 5| Step: 8
Training loss: 2.40695358492796
Validation loss: 2.510133311070076

Epoch: 5| Step: 9
Training loss: 2.039954680893097
Validation loss: 2.529160600783249

Epoch: 5| Step: 10
Training loss: 1.9127570858366556
Validation loss: 2.5556580076536557

Epoch: 346| Step: 0
Training loss: 2.007281281372296
Validation loss: 2.561375014627583

Epoch: 5| Step: 1
Training loss: 2.434755589871326
Validation loss: 2.527276901667291

Epoch: 5| Step: 2
Training loss: 2.4460580682482145
Validation loss: 2.56297628867027

Epoch: 5| Step: 3
Training loss: 1.971051157983708
Validation loss: 2.5252391540495585

Epoch: 5| Step: 4
Training loss: 2.2511193352227186
Validation loss: 2.510143407274299

Epoch: 5| Step: 5
Training loss: 2.2067004470698204
Validation loss: 2.545153376889059

Epoch: 5| Step: 6
Training loss: 2.1490271296716896
Validation loss: 2.554071388286929

Epoch: 5| Step: 7
Training loss: 2.428268263430915
Validation loss: 2.575463142363955

Epoch: 5| Step: 8
Training loss: 2.078111920996789
Validation loss: 2.5422448788775465

Epoch: 5| Step: 9
Training loss: 2.1266338574659964
Validation loss: 2.545979723266056

Epoch: 5| Step: 10
Training loss: 1.8710981460551503
Validation loss: 2.533641683390239

Epoch: 347| Step: 0
Training loss: 2.4407438554531136
Validation loss: 2.5135019268518235

Epoch: 5| Step: 1
Training loss: 2.0268041226971656
Validation loss: 2.5264702204528504

Epoch: 5| Step: 2
Training loss: 2.3631076213013014
Validation loss: 2.491868494924602

Epoch: 5| Step: 3
Training loss: 2.125669373943887
Validation loss: 2.5308332992772455

Epoch: 5| Step: 4
Training loss: 1.9116479708559155
Validation loss: 2.534153479184264

Epoch: 5| Step: 5
Training loss: 1.6611233396445066
Validation loss: 2.522795684681143

Epoch: 5| Step: 6
Training loss: 2.7664069670466453
Validation loss: 2.549630715169719

Epoch: 5| Step: 7
Training loss: 1.8551738946435898
Validation loss: 2.531370425705035

Epoch: 5| Step: 8
Training loss: 2.689034223657214
Validation loss: 2.5322864243297674

Epoch: 5| Step: 9
Training loss: 1.661489799305187
Validation loss: 2.563870513443925

Epoch: 5| Step: 10
Training loss: 2.129455271630689
Validation loss: 2.5656486635841884

Epoch: 348| Step: 0
Training loss: 2.16267719755576
Validation loss: 2.5036091819214095

Epoch: 5| Step: 1
Training loss: 2.094633798390337
Validation loss: 2.548212783758485

Epoch: 5| Step: 2
Training loss: 1.9073200036913898
Validation loss: 2.577867460143534

Epoch: 5| Step: 3
Training loss: 2.522166401454991
Validation loss: 2.520040745885525

Epoch: 5| Step: 4
Training loss: 2.489701612740651
Validation loss: 2.602110826410827

Epoch: 5| Step: 5
Training loss: 2.091387198371737
Validation loss: 2.4886223995477432

Epoch: 5| Step: 6
Training loss: 2.2446998052247813
Validation loss: 2.559112638993239

Epoch: 5| Step: 7
Training loss: 2.2608747472273087
Validation loss: 2.523911392809894

Epoch: 5| Step: 8
Training loss: 2.0642914361351163
Validation loss: 2.5450585593752413

Epoch: 5| Step: 9
Training loss: 2.051147195772548
Validation loss: 2.505404078761245

Epoch: 5| Step: 10
Training loss: 1.9924893618004131
Validation loss: 2.5714881807131786

Epoch: 349| Step: 0
Training loss: 2.150588744527786
Validation loss: 2.516923586954783

Epoch: 5| Step: 1
Training loss: 1.8976342028377178
Validation loss: 2.543197236213849

Epoch: 5| Step: 2
Training loss: 2.153228743978508
Validation loss: 2.539768414555018

Epoch: 5| Step: 3
Training loss: 1.753351680359862
Validation loss: 2.5176094526925374

Epoch: 5| Step: 4
Training loss: 1.9821822900175894
Validation loss: 2.5538840612110496

Epoch: 5| Step: 5
Training loss: 2.1804824527978273
Validation loss: 2.594510699896323

Epoch: 5| Step: 6
Training loss: 2.1169071926916123
Validation loss: 2.5347989481515194

Epoch: 5| Step: 7
Training loss: 3.032161457634401
Validation loss: 2.5591771621444273

Epoch: 5| Step: 8
Training loss: 2.1320178888726287
Validation loss: 2.5328564784092755

Epoch: 5| Step: 9
Training loss: 2.267927065737916
Validation loss: 2.5354577613354494

Epoch: 5| Step: 10
Training loss: 2.144971680709879
Validation loss: 2.5380784064181503

Epoch: 350| Step: 0
Training loss: 1.9115111493567047
Validation loss: 2.4833542211424535

Epoch: 5| Step: 1
Training loss: 2.136102172486721
Validation loss: 2.545651746354442

Epoch: 5| Step: 2
Training loss: 1.9435734463203225
Validation loss: 2.5239592571257785

Epoch: 5| Step: 3
Training loss: 1.9446517251052837
Validation loss: 2.518702840743977

Epoch: 5| Step: 4
Training loss: 2.580923515159075
Validation loss: 2.568065138198801

Epoch: 5| Step: 5
Training loss: 1.5915199834663802
Validation loss: 2.509772469835351

Epoch: 5| Step: 6
Training loss: 2.625377809492974
Validation loss: 2.5196343885016095

Epoch: 5| Step: 7
Training loss: 2.3254307255618705
Validation loss: 2.541193853734508

Epoch: 5| Step: 8
Training loss: 2.317364807959188
Validation loss: 2.5111565540993497

Epoch: 5| Step: 9
Training loss: 2.125160884376725
Validation loss: 2.513182960792178

Epoch: 5| Step: 10
Training loss: 2.2489731882820054
Validation loss: 2.5573021308937625

Epoch: 351| Step: 0
Training loss: 2.1348569803331205
Validation loss: 2.5469184739412243

Epoch: 5| Step: 1
Training loss: 2.0333210877013297
Validation loss: 2.495503682988341

Epoch: 5| Step: 2
Training loss: 2.638226113549519
Validation loss: 2.556126816559004

Epoch: 5| Step: 3
Training loss: 2.25308334163931
Validation loss: 2.5572155172817417

Epoch: 5| Step: 4
Training loss: 1.83984375
Validation loss: 2.4466324795369783

Epoch: 5| Step: 5
Training loss: 2.246380543850602
Validation loss: 2.5378524883195617

Epoch: 5| Step: 6
Training loss: 2.078257276871275
Validation loss: 2.5248489224627066

Epoch: 5| Step: 7
Training loss: 2.2828224719780805
Validation loss: 2.5677727007276325

Epoch: 5| Step: 8
Training loss: 1.9382987068125115
Validation loss: 2.5475027862148445

Epoch: 5| Step: 9
Training loss: 2.042623282812639
Validation loss: 2.5214423943301703

Epoch: 5| Step: 10
Training loss: 1.9142642790645545
Validation loss: 2.5490985502324777

Epoch: 352| Step: 0
Training loss: 1.8430141338276285
Validation loss: 2.5002843202916467

Epoch: 5| Step: 1
Training loss: 2.055211917689105
Validation loss: 2.51635139406738

Epoch: 5| Step: 2
Training loss: 2.2007590501645344
Validation loss: 2.5194494523035122

Epoch: 5| Step: 3
Training loss: 2.4586278340292633
Validation loss: 2.517450816407061

Epoch: 5| Step: 4
Training loss: 1.6563794067499222
Validation loss: 2.5591805310076348

Epoch: 5| Step: 5
Training loss: 1.7266793880337683
Validation loss: 2.545731673954924

Epoch: 5| Step: 6
Training loss: 2.394090422086684
Validation loss: 2.5429741142489446

Epoch: 5| Step: 7
Training loss: 1.660700091874134
Validation loss: 2.5196089313904406

Epoch: 5| Step: 8
Training loss: 2.7713136949734265
Validation loss: 2.5150731976478595

Epoch: 5| Step: 9
Training loss: 2.472263877555819
Validation loss: 2.5431565847218187

Epoch: 5| Step: 10
Training loss: 2.167189229402079
Validation loss: 2.5260133647612397

Epoch: 353| Step: 0
Training loss: 1.9509236862375485
Validation loss: 2.521344692265135

Epoch: 5| Step: 1
Training loss: 2.017782077285249
Validation loss: 2.5294260796313752

Epoch: 5| Step: 2
Training loss: 2.830502517081824
Validation loss: 2.4928032809339267

Epoch: 5| Step: 3
Training loss: 2.143221874077875
Validation loss: 2.5483639228502346

Epoch: 5| Step: 4
Training loss: 1.7908932842706602
Validation loss: 2.4868577761414525

Epoch: 5| Step: 5
Training loss: 2.158551632459575
Validation loss: 2.573063884095597

Epoch: 5| Step: 6
Training loss: 2.032850485937185
Validation loss: 2.526234664284701

Epoch: 5| Step: 7
Training loss: 2.3592080568783347
Validation loss: 2.4749917932703496

Epoch: 5| Step: 8
Training loss: 2.2416925714785183
Validation loss: 2.533852347867057

Epoch: 5| Step: 9
Training loss: 2.197368378673785
Validation loss: 2.507674108527954

Epoch: 5| Step: 10
Training loss: 1.708844581336062
Validation loss: 2.54658150984046

Epoch: 354| Step: 0
Training loss: 2.0966133920949437
Validation loss: 2.5476479544233794

Epoch: 5| Step: 1
Training loss: 2.996355704303791
Validation loss: 2.4958002890861604

Epoch: 5| Step: 2
Training loss: 2.2092201923268795
Validation loss: 2.543730579810131

Epoch: 5| Step: 3
Training loss: 1.5877586394351095
Validation loss: 2.5495662958180367

Epoch: 5| Step: 4
Training loss: 1.9520374169203019
Validation loss: 2.531046826933789

Epoch: 5| Step: 5
Training loss: 2.3767728713686496
Validation loss: 2.549947652092463

Epoch: 5| Step: 6
Training loss: 1.8686488350625212
Validation loss: 2.5450036568364265

Epoch: 5| Step: 7
Training loss: 2.591908732043654
Validation loss: 2.536514462186902

Epoch: 5| Step: 8
Training loss: 1.7811532914528154
Validation loss: 2.568364019447038

Epoch: 5| Step: 9
Training loss: 1.910138089146317
Validation loss: 2.5722553086869517

Epoch: 5| Step: 10
Training loss: 2.4429836700930503
Validation loss: 2.513349755220655

Epoch: 355| Step: 0
Training loss: 2.6876350191487655
Validation loss: 2.5627012921579797

Epoch: 5| Step: 1
Training loss: 2.2889157401159053
Validation loss: 2.570515621330736

Epoch: 5| Step: 2
Training loss: 1.908273279780466
Validation loss: 2.5174007574930894

Epoch: 5| Step: 3
Training loss: 1.861426816167214
Validation loss: 2.5452183103231434

Epoch: 5| Step: 4
Training loss: 2.358754562753571
Validation loss: 2.5365925411604087

Epoch: 5| Step: 5
Training loss: 1.9295438025712865
Validation loss: 2.5607222726669705

Epoch: 5| Step: 6
Training loss: 1.7915957311146309
Validation loss: 2.531941063180848

Epoch: 5| Step: 7
Training loss: 1.9485346447941054
Validation loss: 2.488397210076747

Epoch: 5| Step: 8
Training loss: 2.1702727850403543
Validation loss: 2.569844475310499

Epoch: 5| Step: 9
Training loss: 2.4421491057342655
Validation loss: 2.512478373248795

Epoch: 5| Step: 10
Training loss: 2.11831128464856
Validation loss: 2.5615837616092954

Epoch: 356| Step: 0
Training loss: 1.700404593061778
Validation loss: 2.538829376397903

Epoch: 5| Step: 1
Training loss: 1.8734846985688152
Validation loss: 2.4960979979208346

Epoch: 5| Step: 2
Training loss: 1.9788921634309753
Validation loss: 2.520036070110254

Epoch: 5| Step: 3
Training loss: 2.5948739431704237
Validation loss: 2.5418445606267333

Epoch: 5| Step: 4
Training loss: 1.8521546008626888
Validation loss: 2.580643531391183

Epoch: 5| Step: 5
Training loss: 2.7166626031139227
Validation loss: 2.5747871715579693

Epoch: 5| Step: 6
Training loss: 2.3602906528200704
Validation loss: 2.530130574072978

Epoch: 5| Step: 7
Training loss: 1.5331497863432986
Validation loss: 2.5409519341148634

Epoch: 5| Step: 8
Training loss: 2.4885568032031244
Validation loss: 2.534586523513022

Epoch: 5| Step: 9
Training loss: 2.2237639390616852
Validation loss: 2.539396722976117

Epoch: 5| Step: 10
Training loss: 2.1557233969024496
Validation loss: 2.5553006550279562

Epoch: 357| Step: 0
Training loss: 2.282285063568782
Validation loss: 2.470641071682189

Epoch: 5| Step: 1
Training loss: 2.210032139540123
Validation loss: 2.5090476583665304

Epoch: 5| Step: 2
Training loss: 2.287497340133038
Validation loss: 2.512057500393409

Epoch: 5| Step: 3
Training loss: 1.8576226191139968
Validation loss: 2.4634893845797623

Epoch: 5| Step: 4
Training loss: 2.186102720592166
Validation loss: 2.534792912238675

Epoch: 5| Step: 5
Training loss: 2.6758439773669425
Validation loss: 2.538503663412723

Epoch: 5| Step: 6
Training loss: 2.2088170751329606
Validation loss: 2.487666789000816

Epoch: 5| Step: 7
Training loss: 1.0359209223322718
Validation loss: 2.548447529699419

Epoch: 5| Step: 8
Training loss: 2.419964929279276
Validation loss: 2.527072300353552

Epoch: 5| Step: 9
Training loss: 2.3384885604934214
Validation loss: 2.5498165927247594

Epoch: 5| Step: 10
Training loss: 1.7248982827977235
Validation loss: 2.530842160662554

Epoch: 358| Step: 0
Training loss: 2.1264104089437685
Validation loss: 2.5005626194076758

Epoch: 5| Step: 1
Training loss: 1.8250574965107451
Validation loss: 2.5584578328250354

Epoch: 5| Step: 2
Training loss: 1.752870181463001
Validation loss: 2.5144993928648343

Epoch: 5| Step: 3
Training loss: 2.4345911715976145
Validation loss: 2.550943770059602

Epoch: 5| Step: 4
Training loss: 1.943981895229035
Validation loss: 2.5520791769255458

Epoch: 5| Step: 5
Training loss: 2.664331864417877
Validation loss: 2.515908491980587

Epoch: 5| Step: 6
Training loss: 2.121866159322353
Validation loss: 2.5239530104285013

Epoch: 5| Step: 7
Training loss: 1.942148845653153
Validation loss: 2.54916510891829

Epoch: 5| Step: 8
Training loss: 2.703122618569444
Validation loss: 2.5890442966059366

Epoch: 5| Step: 9
Training loss: 1.7894407313962117
Validation loss: 2.4918963228491067

Epoch: 5| Step: 10
Training loss: 2.066017619114182
Validation loss: 2.5047185585910476

Epoch: 359| Step: 0
Training loss: 2.0769398687232705
Validation loss: 2.548305801848845

Epoch: 5| Step: 1
Training loss: 1.7629501877064213
Validation loss: 2.5248509420208434

Epoch: 5| Step: 2
Training loss: 2.25680160331277
Validation loss: 2.558751634956872

Epoch: 5| Step: 3
Training loss: 2.329788126009996
Validation loss: 2.560013131324612

Epoch: 5| Step: 4
Training loss: 2.400135743752828
Validation loss: 2.5770283374927883

Epoch: 5| Step: 5
Training loss: 2.208333345329237
Validation loss: 2.5225506388005217

Epoch: 5| Step: 6
Training loss: 2.3154712867941725
Validation loss: 2.5310810366435383

Epoch: 5| Step: 7
Training loss: 1.8848219788976412
Validation loss: 2.5469512515339594

Epoch: 5| Step: 8
Training loss: 2.067496979975311
Validation loss: 2.591259817204315

Epoch: 5| Step: 9
Training loss: 1.9820751168791297
Validation loss: 2.565914311496203

Epoch: 5| Step: 10
Training loss: 1.8620748713157316
Validation loss: 2.583703774346689

Epoch: 360| Step: 0
Training loss: 2.1144752161608094
Validation loss: 2.4956595940835835

Epoch: 5| Step: 1
Training loss: 2.2423069088072918
Validation loss: 2.5148865396706648

Epoch: 5| Step: 2
Training loss: 2.232674972324332
Validation loss: 2.606923427903503

Epoch: 5| Step: 3
Training loss: 2.178411841968538
Validation loss: 2.5191737072729814

Epoch: 5| Step: 4
Training loss: 1.9566436810202104
Validation loss: 2.538832660176652

Epoch: 5| Step: 5
Training loss: 2.4012810069936297
Validation loss: 2.5211246342169322

Epoch: 5| Step: 6
Training loss: 2.8840076481245536
Validation loss: 2.5525574140638105

Epoch: 5| Step: 7
Training loss: 1.6213664733177846
Validation loss: 2.5183158795361416

Epoch: 5| Step: 8
Training loss: 1.7474476048114516
Validation loss: 2.5727672373258175

Epoch: 5| Step: 9
Training loss: 2.1306013445829266
Validation loss: 2.534847143914547

Epoch: 5| Step: 10
Training loss: 2.110093962037115
Validation loss: 2.556322284006136

Epoch: 361| Step: 0
Training loss: 2.6225630938246858
Validation loss: 2.5615033728509697

Epoch: 5| Step: 1
Training loss: 2.251015010348164
Validation loss: 2.52789350567991

Epoch: 5| Step: 2
Training loss: 2.0577080285180016
Validation loss: 2.526941967950453

Epoch: 5| Step: 3
Training loss: 2.0227556294839193
Validation loss: 2.563871924317026

Epoch: 5| Step: 4
Training loss: 2.3464159235869504
Validation loss: 2.493293208578137

Epoch: 5| Step: 5
Training loss: 1.3960693596330118
Validation loss: 2.5238264327594933

Epoch: 5| Step: 6
Training loss: 1.750196445883184
Validation loss: 2.5444818130602247

Epoch: 5| Step: 7
Training loss: 2.710186505251901
Validation loss: 2.4716581176729897

Epoch: 5| Step: 8
Training loss: 1.774849485006402
Validation loss: 2.5128302020101785

Epoch: 5| Step: 9
Training loss: 2.3499389315847625
Validation loss: 2.575203442842548

Epoch: 5| Step: 10
Training loss: 1.9977110042534938
Validation loss: 2.5483521375949096

Epoch: 362| Step: 0
Training loss: 2.252904712421169
Validation loss: 2.545154367029094

Epoch: 5| Step: 1
Training loss: 1.9646381247826499
Validation loss: 2.5360041861141305

Epoch: 5| Step: 2
Training loss: 2.162047070826282
Validation loss: 2.5379590939694765

Epoch: 5| Step: 3
Training loss: 2.354226058165778
Validation loss: 2.5435355940732127

Epoch: 5| Step: 4
Training loss: 2.285387128594446
Validation loss: 2.545011098927628

Epoch: 5| Step: 5
Training loss: 1.9243350527793295
Validation loss: 2.5589249075413925

Epoch: 5| Step: 6
Training loss: 1.5493614173407666
Validation loss: 2.518418235632193

Epoch: 5| Step: 7
Training loss: 2.2701701907918515
Validation loss: 2.4814525603706348

Epoch: 5| Step: 8
Training loss: 1.7082039233558477
Validation loss: 2.5398207856919304

Epoch: 5| Step: 9
Training loss: 2.8035769163152633
Validation loss: 2.509793195241478

Epoch: 5| Step: 10
Training loss: 1.84712698777812
Validation loss: 2.5293545145186913

Epoch: 363| Step: 0
Training loss: 2.2505829373840975
Validation loss: 2.525407214464317

Epoch: 5| Step: 1
Training loss: 2.1263868630757625
Validation loss: 2.533424266018132

Epoch: 5| Step: 2
Training loss: 1.7667996710367828
Validation loss: 2.5495595658618684

Epoch: 5| Step: 3
Training loss: 2.1348264917629396
Validation loss: 2.5645396171291863

Epoch: 5| Step: 4
Training loss: 2.7085184082960585
Validation loss: 2.5398853941821176

Epoch: 5| Step: 5
Training loss: 1.8933892337623937
Validation loss: 2.519048359014583

Epoch: 5| Step: 6
Training loss: 1.9272597635971689
Validation loss: 2.4956528964716926

Epoch: 5| Step: 7
Training loss: 1.7771158260879552
Validation loss: 2.5008101945036048

Epoch: 5| Step: 8
Training loss: 2.2570064386183843
Validation loss: 2.519538895535854

Epoch: 5| Step: 9
Training loss: 2.5073031564810337
Validation loss: 2.5386352593578616

Epoch: 5| Step: 10
Training loss: 1.7199945278967816
Validation loss: 2.5465634344987547

Epoch: 364| Step: 0
Training loss: 1.9386288215549856
Validation loss: 2.5147588776771106

Epoch: 5| Step: 1
Training loss: 2.4114464470479082
Validation loss: 2.5545924282130015

Epoch: 5| Step: 2
Training loss: 1.7874262627818251
Validation loss: 2.483923412516986

Epoch: 5| Step: 3
Training loss: 1.8475243035396856
Validation loss: 2.531360851166217

Epoch: 5| Step: 4
Training loss: 2.1017513828411434
Validation loss: 2.5281337858606885

Epoch: 5| Step: 5
Training loss: 2.7308789383082877
Validation loss: 2.5868425427778723

Epoch: 5| Step: 6
Training loss: 2.0421046221960286
Validation loss: 2.520437703977245

Epoch: 5| Step: 7
Training loss: 1.8651322421727197
Validation loss: 2.5153594526860426

Epoch: 5| Step: 8
Training loss: 1.8661630285991369
Validation loss: 2.562747627216876

Epoch: 5| Step: 9
Training loss: 1.965618246336768
Validation loss: 2.5354788591836392

Epoch: 5| Step: 10
Training loss: 2.710708652478279
Validation loss: 2.5559399891757777

Epoch: 365| Step: 0
Training loss: 1.6618088339566783
Validation loss: 2.5558503714161662

Epoch: 5| Step: 1
Training loss: 1.913998412013018
Validation loss: 2.532091556624215

Epoch: 5| Step: 2
Training loss: 2.3415468160383255
Validation loss: 2.5619989856278544

Epoch: 5| Step: 3
Training loss: 1.959372332752122
Validation loss: 2.477864202939148

Epoch: 5| Step: 4
Training loss: 1.716940325926964
Validation loss: 2.541318431488308

Epoch: 5| Step: 5
Training loss: 2.3639673671503294
Validation loss: 2.5236935374053218

Epoch: 5| Step: 6
Training loss: 2.529546659058497
Validation loss: 2.5840873596976546

Epoch: 5| Step: 7
Training loss: 2.550136794366708
Validation loss: 2.5489898342429234

Epoch: 5| Step: 8
Training loss: 1.7719830165548602
Validation loss: 2.584674993581739

Epoch: 5| Step: 9
Training loss: 2.302377868958731
Validation loss: 2.6027115239212413

Epoch: 5| Step: 10
Training loss: 1.955741838260918
Validation loss: 2.545982308574937

Epoch: 366| Step: 0
Training loss: 2.324814151186054
Validation loss: 2.537330182641511

Epoch: 5| Step: 1
Training loss: 2.2298176845726885
Validation loss: 2.505301606927286

Epoch: 5| Step: 2
Training loss: 2.546558009354455
Validation loss: 2.54521979599878

Epoch: 5| Step: 3
Training loss: 2.1272175381947815
Validation loss: 2.494550438235368

Epoch: 5| Step: 4
Training loss: 1.8159042485070884
Validation loss: 2.5203073488959244

Epoch: 5| Step: 5
Training loss: 2.332522239947009
Validation loss: 2.581812243715871

Epoch: 5| Step: 6
Training loss: 2.0747961472719134
Validation loss: 2.539203853285268

Epoch: 5| Step: 7
Training loss: 1.226796753497161
Validation loss: 2.546164140583276

Epoch: 5| Step: 8
Training loss: 1.7144432903710864
Validation loss: 2.5307097897298103

Epoch: 5| Step: 9
Training loss: 2.07787292787322
Validation loss: 2.4972343395603382

Epoch: 5| Step: 10
Training loss: 1.9277729003519635
Validation loss: 2.534963735762913

Epoch: 367| Step: 0
Training loss: 2.45507686253821
Validation loss: 2.551486402108935

Epoch: 5| Step: 1
Training loss: 2.40192103194657
Validation loss: 2.5826208536002127

Epoch: 5| Step: 2
Training loss: 2.2548536296292596
Validation loss: 2.541739814938947

Epoch: 5| Step: 3
Training loss: 2.7948131100266447
Validation loss: 2.4842866311867793

Epoch: 5| Step: 4
Training loss: 2.0485492876569897
Validation loss: 2.542115904230363

Epoch: 5| Step: 5
Training loss: 1.8740180941332107
Validation loss: 2.520457140450497

Epoch: 5| Step: 6
Training loss: 1.7421498658088357
Validation loss: 2.531189992120697

Epoch: 5| Step: 7
Training loss: 1.646881236692487
Validation loss: 2.4919775291474893

Epoch: 5| Step: 8
Training loss: 1.8576032387549977
Validation loss: 2.5746429147182615

Epoch: 5| Step: 9
Training loss: 2.0094958421788007
Validation loss: 2.5185109987879883

Epoch: 5| Step: 10
Training loss: 2.2062767697188015
Validation loss: 2.539314886253986

Epoch: 368| Step: 0
Training loss: 2.666573423503844
Validation loss: 2.532737678610523

Epoch: 5| Step: 1
Training loss: 2.0602740211081687
Validation loss: 2.5509974192047444

Epoch: 5| Step: 2
Training loss: 1.8636389814810965
Validation loss: 2.535184370287819

Epoch: 5| Step: 3
Training loss: 2.482893304008075
Validation loss: 2.5158295438381746

Epoch: 5| Step: 4
Training loss: 1.9013755888280621
Validation loss: 2.5439379962822786

Epoch: 5| Step: 5
Training loss: 1.8495913286144434
Validation loss: 2.553258056362583

Epoch: 5| Step: 6
Training loss: 1.8720857224603766
Validation loss: 2.524283094192837

Epoch: 5| Step: 7
Training loss: 2.0939456222017307
Validation loss: 2.5273843829732776

Epoch: 5| Step: 8
Training loss: 1.93392762663536
Validation loss: 2.531461398221072

Epoch: 5| Step: 9
Training loss: 1.9948272569102592
Validation loss: 2.482160256302721

Epoch: 5| Step: 10
Training loss: 1.8207180242741121
Validation loss: 2.5350294955084274

Epoch: 369| Step: 0
Training loss: 2.416759083614087
Validation loss: 2.53714674547678

Epoch: 5| Step: 1
Training loss: 1.5234363262465431
Validation loss: 2.55046665567217

Epoch: 5| Step: 2
Training loss: 1.7975742472248228
Validation loss: 2.5150466791248793

Epoch: 5| Step: 3
Training loss: 2.0545275955927793
Validation loss: 2.6000940993297834

Epoch: 5| Step: 4
Training loss: 2.1081762227661547
Validation loss: 2.604979688826491

Epoch: 5| Step: 5
Training loss: 2.0467834452180456
Validation loss: 2.534441543332063

Epoch: 5| Step: 6
Training loss: 2.7861590833792547
Validation loss: 2.5319765426410212

Epoch: 5| Step: 7
Training loss: 2.002360143456717
Validation loss: 2.58752538288022

Epoch: 5| Step: 8
Training loss: 2.3884327130118113
Validation loss: 2.568926431039925

Epoch: 5| Step: 9
Training loss: 2.196955056176585
Validation loss: 2.5290546424930693

Epoch: 5| Step: 10
Training loss: 1.9465438438669167
Validation loss: 2.5204674053378437

Epoch: 370| Step: 0
Training loss: 2.100717594520089
Validation loss: 2.5155581052233895

Epoch: 5| Step: 1
Training loss: 2.099941266464688
Validation loss: 2.4923349226886518

Epoch: 5| Step: 2
Training loss: 1.8454468241357946
Validation loss: 2.592945118792702

Epoch: 5| Step: 3
Training loss: 2.129629477748159
Validation loss: 2.51887106501058

Epoch: 5| Step: 4
Training loss: 1.9832295994384375
Validation loss: 2.5342900433161653

Epoch: 5| Step: 5
Training loss: 2.805778524983058
Validation loss: 2.5303671180929905

Epoch: 5| Step: 6
Training loss: 2.118180608618812
Validation loss: 2.5232954311327

Epoch: 5| Step: 7
Training loss: 2.1665911172264103
Validation loss: 2.5008616264977728

Epoch: 5| Step: 8
Training loss: 1.6351770683089677
Validation loss: 2.5188741122230893

Epoch: 5| Step: 9
Training loss: 2.189197208853165
Validation loss: 2.511072199769219

Epoch: 5| Step: 10
Training loss: 1.9876395578390456
Validation loss: 2.551556784827614

Epoch: 371| Step: 0
Training loss: 2.635342794194679
Validation loss: 2.533164151986211

Epoch: 5| Step: 1
Training loss: 1.5281061089406995
Validation loss: 2.4996283080551596

Epoch: 5| Step: 2
Training loss: 1.8983888973089853
Validation loss: 2.549058561084743

Epoch: 5| Step: 3
Training loss: 2.4478756082757367
Validation loss: 2.483246124565875

Epoch: 5| Step: 4
Training loss: 1.577282066707329
Validation loss: 2.4996930087706697

Epoch: 5| Step: 5
Training loss: 1.9673858033597464
Validation loss: 2.5392483268240507

Epoch: 5| Step: 6
Training loss: 1.9502064375543346
Validation loss: 2.579016130305087

Epoch: 5| Step: 7
Training loss: 2.138774433899368
Validation loss: 2.5543314990010875

Epoch: 5| Step: 8
Training loss: 2.374292368624594
Validation loss: 2.577187597865256

Epoch: 5| Step: 9
Training loss: 2.4351984553371047
Validation loss: 2.584214543170791

Epoch: 5| Step: 10
Training loss: 1.9975067930141859
Validation loss: 2.544718728651324

Epoch: 372| Step: 0
Training loss: 2.5179698748797614
Validation loss: 2.502550487414904

Epoch: 5| Step: 1
Training loss: 2.105157776127513
Validation loss: 2.546236164563415

Epoch: 5| Step: 2
Training loss: 1.6868537089080837
Validation loss: 2.554209221067181

Epoch: 5| Step: 3
Training loss: 2.073046681785251
Validation loss: 2.5562104924405324

Epoch: 5| Step: 4
Training loss: 1.7099078141287627
Validation loss: 2.5879836374889527

Epoch: 5| Step: 5
Training loss: 2.3011907397694746
Validation loss: 2.5146038133258046

Epoch: 5| Step: 6
Training loss: 2.437752441636624
Validation loss: 2.5412241367079824

Epoch: 5| Step: 7
Training loss: 2.2177287155607543
Validation loss: 2.603264807950918

Epoch: 5| Step: 8
Training loss: 2.013570285310219
Validation loss: 2.497622500761484

Epoch: 5| Step: 9
Training loss: 2.046030350759252
Validation loss: 2.5893833128064214

Epoch: 5| Step: 10
Training loss: 2.2005721648660383
Validation loss: 2.56144495948728

Epoch: 373| Step: 0
Training loss: 1.636782260290763
Validation loss: 2.5487412646563983

Epoch: 5| Step: 1
Training loss: 2.1969426846014506
Validation loss: 2.5353342596696096

Epoch: 5| Step: 2
Training loss: 2.3411140369014185
Validation loss: 2.5099788745791383

Epoch: 5| Step: 3
Training loss: 2.0342210608865603
Validation loss: 2.553554840138912

Epoch: 5| Step: 4
Training loss: 2.169697610028555
Validation loss: 2.5084291546597535

Epoch: 5| Step: 5
Training loss: 2.128866716770267
Validation loss: 2.5319575753010417

Epoch: 5| Step: 6
Training loss: 1.6426430053235037
Validation loss: 2.471952101865426

Epoch: 5| Step: 7
Training loss: 1.7972385204636798
Validation loss: 2.5126007934508436

Epoch: 5| Step: 8
Training loss: 2.5041360972776547
Validation loss: 2.563841649869595

Epoch: 5| Step: 9
Training loss: 2.0996164153224988
Validation loss: 2.5505477355414596

Epoch: 5| Step: 10
Training loss: 2.1398862134683228
Validation loss: 2.5467203992843412

Epoch: 374| Step: 0
Training loss: 1.875585973092718
Validation loss: 2.472345831354365

Epoch: 5| Step: 1
Training loss: 2.208712803128578
Validation loss: 2.55413134739385

Epoch: 5| Step: 2
Training loss: 2.3799499326937332
Validation loss: 2.579062970949309

Epoch: 5| Step: 3
Training loss: 1.814105999512948
Validation loss: 2.514548825948171

Epoch: 5| Step: 4
Training loss: 2.1224948477710606
Validation loss: 2.5440996112661107

Epoch: 5| Step: 5
Training loss: 2.2342221934746
Validation loss: 2.5778941558577055

Epoch: 5| Step: 6
Training loss: 2.192876040704312
Validation loss: 2.557648753472063

Epoch: 5| Step: 7
Training loss: 2.171673442901243
Validation loss: 2.5113313925133416

Epoch: 5| Step: 8
Training loss: 1.9614333783421145
Validation loss: 2.5784564827185434

Epoch: 5| Step: 9
Training loss: 1.482535577768495
Validation loss: 2.55082769253807

Epoch: 5| Step: 10
Training loss: 2.7322346184830124
Validation loss: 2.4956855029890392

Epoch: 375| Step: 0
Training loss: 1.9553865690561523
Validation loss: 2.5916375291295153

Epoch: 5| Step: 1
Training loss: 2.558489661975078
Validation loss: 2.532971424604483

Epoch: 5| Step: 2
Training loss: 2.623919491684212
Validation loss: 2.5343840174846286

Epoch: 5| Step: 3
Training loss: 2.010036320524249
Validation loss: 2.5240792089977

Epoch: 5| Step: 4
Training loss: 1.9839241536932357
Validation loss: 2.5285776601670547

Epoch: 5| Step: 5
Training loss: 2.3194050154186776
Validation loss: 2.5631382875325404

Epoch: 5| Step: 6
Training loss: 1.8053544698719408
Validation loss: 2.5250732591971428

Epoch: 5| Step: 7
Training loss: 2.1648374196031925
Validation loss: 2.5535929036044434

Epoch: 5| Step: 8
Training loss: 1.9794259420186762
Validation loss: 2.512132630998999

Epoch: 5| Step: 9
Training loss: 1.7401569661778375
Validation loss: 2.5222485999331634

Epoch: 5| Step: 10
Training loss: 1.8116462275180605
Validation loss: 2.605756144785199

Epoch: 376| Step: 0
Training loss: 1.5343619662661643
Validation loss: 2.482353026897122

Epoch: 5| Step: 1
Training loss: 3.132225076677798
Validation loss: 2.5491239421406817

Epoch: 5| Step: 2
Training loss: 1.2324205691758385
Validation loss: 2.508362266254558

Epoch: 5| Step: 3
Training loss: 2.163531296738402
Validation loss: 2.5447736917377144

Epoch: 5| Step: 4
Training loss: 1.9746592408778352
Validation loss: 2.556105684535694

Epoch: 5| Step: 5
Training loss: 2.34162256961811
Validation loss: 2.555467509405168

Epoch: 5| Step: 6
Training loss: 1.7414669719393099
Validation loss: 2.533053754203636

Epoch: 5| Step: 7
Training loss: 1.7872864015377687
Validation loss: 2.576290848688326

Epoch: 5| Step: 8
Training loss: 1.8589407149203938
Validation loss: 2.5349117588216243

Epoch: 5| Step: 9
Training loss: 2.3377212297327317
Validation loss: 2.5064897595776787

Epoch: 5| Step: 10
Training loss: 2.1231043719215186
Validation loss: 2.6038856036372895

Epoch: 377| Step: 0
Training loss: 2.000743131859109
Validation loss: 2.5333393234345105

Epoch: 5| Step: 1
Training loss: 2.6333074359183715
Validation loss: 2.5095714306427572

Epoch: 5| Step: 2
Training loss: 2.061007219571236
Validation loss: 2.5381694647495943

Epoch: 5| Step: 3
Training loss: 1.835533194968907
Validation loss: 2.493224387164507

Epoch: 5| Step: 4
Training loss: 2.3701477677518343
Validation loss: 2.484405621611881

Epoch: 5| Step: 5
Training loss: 1.8782977032716295
Validation loss: 2.5384407134033347

Epoch: 5| Step: 6
Training loss: 1.7705389862766816
Validation loss: 2.5565451766016825

Epoch: 5| Step: 7
Training loss: 2.0815285940119126
Validation loss: 2.5376800342711716

Epoch: 5| Step: 8
Training loss: 2.124290572281918
Validation loss: 2.595031070049423

Epoch: 5| Step: 9
Training loss: 2.0416927984732185
Validation loss: 2.508869696473837

Epoch: 5| Step: 10
Training loss: 2.416723469910674
Validation loss: 2.578565812545991

Epoch: 378| Step: 0
Training loss: 1.6322259899073126
Validation loss: 2.4899616452586706

Epoch: 5| Step: 1
Training loss: 2.2759661163663885
Validation loss: 2.569181529877062

Epoch: 5| Step: 2
Training loss: 2.3462602523880496
Validation loss: 2.5329800123262816

Epoch: 5| Step: 3
Training loss: 1.8287656916625026
Validation loss: 2.524414712444801

Epoch: 5| Step: 4
Training loss: 2.1751231323114912
Validation loss: 2.5121013993097367

Epoch: 5| Step: 5
Training loss: 2.184793814701137
Validation loss: 2.4963318986878704

Epoch: 5| Step: 6
Training loss: 1.8334182011583569
Validation loss: 2.5389244295731626

Epoch: 5| Step: 7
Training loss: 1.709378163336524
Validation loss: 2.5093736006183307

Epoch: 5| Step: 8
Training loss: 2.1317903074308124
Validation loss: 2.549358946086522

Epoch: 5| Step: 9
Training loss: 2.1081923949085377
Validation loss: 2.5464301199833352

Epoch: 5| Step: 10
Training loss: 2.460553142262865
Validation loss: 2.538986210461817

Epoch: 379| Step: 0
Training loss: 2.3646992614381004
Validation loss: 2.5157499043497595

Epoch: 5| Step: 1
Training loss: 1.68015513453149
Validation loss: 2.4969730561905004

Epoch: 5| Step: 2
Training loss: 2.5145478400691323
Validation loss: 2.524504505788221

Epoch: 5| Step: 3
Training loss: 1.8362225250411526
Validation loss: 2.561811284060047

Epoch: 5| Step: 4
Training loss: 2.4719785029640144
Validation loss: 2.5220422723051583

Epoch: 5| Step: 5
Training loss: 2.027775771722135
Validation loss: 2.534702179146292

Epoch: 5| Step: 6
Training loss: 2.2780418307555546
Validation loss: 2.4854803821901

Epoch: 5| Step: 7
Training loss: 1.599363575962018
Validation loss: 2.5615127946884786

Epoch: 5| Step: 8
Training loss: 2.100593655552999
Validation loss: 2.483565550712894

Epoch: 5| Step: 9
Training loss: 2.0716576003318443
Validation loss: 2.556654587085398

Epoch: 5| Step: 10
Training loss: 1.7516553406692532
Validation loss: 2.4829793270438696

Epoch: 380| Step: 0
Training loss: 1.875169873489695
Validation loss: 2.5355799698981754

Epoch: 5| Step: 1
Training loss: 1.9200786476120573
Validation loss: 2.5150738612189376

Epoch: 5| Step: 2
Training loss: 2.464735315903052
Validation loss: 2.543415218213978

Epoch: 5| Step: 3
Training loss: 2.1574832872293754
Validation loss: 2.56950151431283

Epoch: 5| Step: 4
Training loss: 1.4076884224562647
Validation loss: 2.507957279765735

Epoch: 5| Step: 5
Training loss: 1.8003107147128485
Validation loss: 2.5025129199270486

Epoch: 5| Step: 6
Training loss: 2.310818344252853
Validation loss: 2.531107349698283

Epoch: 5| Step: 7
Training loss: 1.8172314153926141
Validation loss: 2.579483951352674

Epoch: 5| Step: 8
Training loss: 2.477058433191537
Validation loss: 2.5037248078671888

Epoch: 5| Step: 9
Training loss: 2.1004035334929148
Validation loss: 2.5369969864207733

Epoch: 5| Step: 10
Training loss: 2.5677445868872493
Validation loss: 2.5482592992643065

Epoch: 381| Step: 0
Training loss: 2.028175492091646
Validation loss: 2.5231883359897225

Epoch: 5| Step: 1
Training loss: 2.278580449210734
Validation loss: 2.5161484668139944

Epoch: 5| Step: 2
Training loss: 2.056025312490536
Validation loss: 2.5463206034254537

Epoch: 5| Step: 3
Training loss: 1.3471141664795554
Validation loss: 2.536367580810629

Epoch: 5| Step: 4
Training loss: 2.212657569403747
Validation loss: 2.5499281312529316

Epoch: 5| Step: 5
Training loss: 2.1633252151446656
Validation loss: 2.58138734626453

Epoch: 5| Step: 6
Training loss: 1.6083388465167543
Validation loss: 2.532095310821967

Epoch: 5| Step: 7
Training loss: 2.2953971208381994
Validation loss: 2.559649298690534

Epoch: 5| Step: 8
Training loss: 1.6019581375843608
Validation loss: 2.5072323786197512

Epoch: 5| Step: 9
Training loss: 2.7199585081189515
Validation loss: 2.535065121863659

Epoch: 5| Step: 10
Training loss: 2.0745028716072293
Validation loss: 2.544532045973062

Epoch: 382| Step: 0
Training loss: 2.1661859003390918
Validation loss: 2.509460366813119

Epoch: 5| Step: 1
Training loss: 2.445108715987002
Validation loss: 2.524013159894513

Epoch: 5| Step: 2
Training loss: 2.1366037062336702
Validation loss: 2.535167212783078

Epoch: 5| Step: 3
Training loss: 1.9935003405346567
Validation loss: 2.632770126954585

Epoch: 5| Step: 4
Training loss: 1.670953728515169
Validation loss: 2.536147540488778

Epoch: 5| Step: 5
Training loss: 2.479376028073682
Validation loss: 2.5302289916271516

Epoch: 5| Step: 6
Training loss: 1.8728934852712875
Validation loss: 2.531317116108242

Epoch: 5| Step: 7
Training loss: 2.1095512033972152
Validation loss: 2.523567558281158

Epoch: 5| Step: 8
Training loss: 1.9220141228664072
Validation loss: 2.5490137910403

Epoch: 5| Step: 9
Training loss: 1.9167318609455826
Validation loss: 2.496542945052161

Epoch: 5| Step: 10
Training loss: 2.046404369499308
Validation loss: 2.491783190816339

Epoch: 383| Step: 0
Training loss: 2.2882418154063013
Validation loss: 2.502587222529307

Epoch: 5| Step: 1
Training loss: 2.220697112733726
Validation loss: 2.5323596498575105

Epoch: 5| Step: 2
Training loss: 1.6724543770809888
Validation loss: 2.480827237295739

Epoch: 5| Step: 3
Training loss: 2.5625250280134937
Validation loss: 2.5395208271038006

Epoch: 5| Step: 4
Training loss: 1.8116991312626989
Validation loss: 2.5615380345134744

Epoch: 5| Step: 5
Training loss: 2.2894217043316623
Validation loss: 2.542990481136656

Epoch: 5| Step: 6
Training loss: 1.6169582333428543
Validation loss: 2.553570917338921

Epoch: 5| Step: 7
Training loss: 2.2426788110793545
Validation loss: 2.5312707794564053

Epoch: 5| Step: 8
Training loss: 1.8484054240186993
Validation loss: 2.4885308272897295

Epoch: 5| Step: 9
Training loss: 2.409456271966722
Validation loss: 2.5851519914963874

Epoch: 5| Step: 10
Training loss: 1.5317430286376463
Validation loss: 2.61205883753404

Epoch: 384| Step: 0
Training loss: 1.8477381875578374
Validation loss: 2.640030689837979

Epoch: 5| Step: 1
Training loss: 2.0014820568110454
Validation loss: 2.5248672273780746

Epoch: 5| Step: 2
Training loss: 1.3925918214613973
Validation loss: 2.5655050188227975

Epoch: 5| Step: 3
Training loss: 2.216065515541258
Validation loss: 2.5326534094172946

Epoch: 5| Step: 4
Training loss: 1.8901312947965319
Validation loss: 2.515486357551225

Epoch: 5| Step: 5
Training loss: 2.6889115108855486
Validation loss: 2.572638495416476

Epoch: 5| Step: 6
Training loss: 1.9155110385968037
Validation loss: 2.56693943935714

Epoch: 5| Step: 7
Training loss: 2.1584672446912485
Validation loss: 2.54269907529745

Epoch: 5| Step: 8
Training loss: 2.1099588222011056
Validation loss: 2.5231345918852828

Epoch: 5| Step: 9
Training loss: 2.4663202424832558
Validation loss: 2.4868415717574193

Epoch: 5| Step: 10
Training loss: 1.8140615773753104
Validation loss: 2.5859888290596573

Epoch: 385| Step: 0
Training loss: 1.5782840006583128
Validation loss: 2.5685921764261606

Epoch: 5| Step: 1
Training loss: 2.1798890817054932
Validation loss: 2.5663911142834883

Epoch: 5| Step: 2
Training loss: 1.7024918525489645
Validation loss: 2.552553489092231

Epoch: 5| Step: 3
Training loss: 2.470942911566939
Validation loss: 2.5342309050725245

Epoch: 5| Step: 4
Training loss: 2.045948430363241
Validation loss: 2.527939854544525

Epoch: 5| Step: 5
Training loss: 2.1229172766188276
Validation loss: 2.4764852809697535

Epoch: 5| Step: 6
Training loss: 2.230564416012941
Validation loss: 2.543058873122608

Epoch: 5| Step: 7
Training loss: 2.411226353428027
Validation loss: 2.5690716310500066

Epoch: 5| Step: 8
Training loss: 2.0009513023051753
Validation loss: 2.5433015428709664

Epoch: 5| Step: 9
Training loss: 1.9909290602503191
Validation loss: 2.5439025617080233

Epoch: 5| Step: 10
Training loss: 1.674309713551074
Validation loss: 2.499717595957222

Epoch: 386| Step: 0
Training loss: 1.9013682533421832
Validation loss: 2.5044044960178535

Epoch: 5| Step: 1
Training loss: 1.8005363645390409
Validation loss: 2.547371543194349

Epoch: 5| Step: 2
Training loss: 2.3881498001755697
Validation loss: 2.5378917161193124

Epoch: 5| Step: 3
Training loss: 2.0694618636841122
Validation loss: 2.5031315479175253

Epoch: 5| Step: 4
Training loss: 2.682896597093485
Validation loss: 2.549196450697201

Epoch: 5| Step: 5
Training loss: 1.6362559681689568
Validation loss: 2.549419069319772

Epoch: 5| Step: 6
Training loss: 1.835453700176592
Validation loss: 2.490618808902459

Epoch: 5| Step: 7
Training loss: 2.4705019179126158
Validation loss: 2.5157817062356047

Epoch: 5| Step: 8
Training loss: 1.951808638432459
Validation loss: 2.5011269992710834

Epoch: 5| Step: 9
Training loss: 1.292659664954165
Validation loss: 2.556269858813405

Epoch: 5| Step: 10
Training loss: 1.9236470558428542
Validation loss: 2.5534929880562274

Epoch: 387| Step: 0
Training loss: 1.8347829231939512
Validation loss: 2.5743476399332823

Epoch: 5| Step: 1
Training loss: 2.2287948393362838
Validation loss: 2.5646159912097524

Epoch: 5| Step: 2
Training loss: 2.0003027686782406
Validation loss: 2.5717001710260257

Epoch: 5| Step: 3
Training loss: 2.03940798584019
Validation loss: 2.6057953159812124

Epoch: 5| Step: 4
Training loss: 2.616222237750885
Validation loss: 2.511508840061723

Epoch: 5| Step: 5
Training loss: 2.315048051174758
Validation loss: 2.4886297176833914

Epoch: 5| Step: 6
Training loss: 2.368264837578742
Validation loss: 2.529562623318226

Epoch: 5| Step: 7
Training loss: 1.85843698899599
Validation loss: 2.520325429448228

Epoch: 5| Step: 8
Training loss: 1.4446734691073029
Validation loss: 2.5757296773534684

Epoch: 5| Step: 9
Training loss: 1.1049017109029318
Validation loss: 2.5486265353049524

Epoch: 5| Step: 10
Training loss: 2.3648465608013627
Validation loss: 2.5558204733891836

Epoch: 388| Step: 0
Training loss: 2.0068987834213745
Validation loss: 2.5774057582648964

Epoch: 5| Step: 1
Training loss: 1.512827464193001
Validation loss: 2.5595546455775673

Epoch: 5| Step: 2
Training loss: 2.6825234223522645
Validation loss: 2.529036675031665

Epoch: 5| Step: 3
Training loss: 2.1488402942728264
Validation loss: 2.5574211408790983

Epoch: 5| Step: 4
Training loss: 1.9538356251175886
Validation loss: 2.4697956151830334

Epoch: 5| Step: 5
Training loss: 2.7451221380525
Validation loss: 2.5321448033444387

Epoch: 5| Step: 6
Training loss: 1.8360303490068908
Validation loss: 2.470209386362677

Epoch: 5| Step: 7
Training loss: 1.6105936121815005
Validation loss: 2.5473870374756187

Epoch: 5| Step: 8
Training loss: 1.508242056738602
Validation loss: 2.516183180153416

Epoch: 5| Step: 9
Training loss: 2.337087902931302
Validation loss: 2.5601815100478795

Epoch: 5| Step: 10
Training loss: 1.675151502105984
Validation loss: 2.5344333773105396

Epoch: 389| Step: 0
Training loss: 1.8327251494813017
Validation loss: 2.534391089178009

Epoch: 5| Step: 1
Training loss: 2.678047323268901
Validation loss: 2.5738723399556958

Epoch: 5| Step: 2
Training loss: 2.484155417281099
Validation loss: 2.5406919096627427

Epoch: 5| Step: 3
Training loss: 1.6799209787312896
Validation loss: 2.531287149095697

Epoch: 5| Step: 4
Training loss: 2.189007267061163
Validation loss: 2.563641891750028

Epoch: 5| Step: 5
Training loss: 2.0028089824520037
Validation loss: 2.566525462623558

Epoch: 5| Step: 6
Training loss: 2.2529129669270076
Validation loss: 2.535206427021423

Epoch: 5| Step: 7
Training loss: 2.0419272691139305
Validation loss: 2.513889417971382

Epoch: 5| Step: 8
Training loss: 1.5992097273862325
Validation loss: 2.474527208674288

Epoch: 5| Step: 9
Training loss: 1.6848800949312845
Validation loss: 2.6017603103202487

Epoch: 5| Step: 10
Training loss: 2.108313286224871
Validation loss: 2.509768338012633

Epoch: 390| Step: 0
Training loss: 1.7561541385214026
Validation loss: 2.537657891952269

Epoch: 5| Step: 1
Training loss: 2.343610632249577
Validation loss: 2.5103011389151155

Epoch: 5| Step: 2
Training loss: 2.293642741093999
Validation loss: 2.5524237597608184

Epoch: 5| Step: 3
Training loss: 2.1802019722146015
Validation loss: 2.5244785605815387

Epoch: 5| Step: 4
Training loss: 1.8921949315574864
Validation loss: 2.529600265411425

Epoch: 5| Step: 5
Training loss: 1.4050225304938613
Validation loss: 2.5178207061275892

Epoch: 5| Step: 6
Training loss: 2.5015463814820733
Validation loss: 2.5697393734954663

Epoch: 5| Step: 7
Training loss: 2.092348683126162
Validation loss: 2.532640175421236

Epoch: 5| Step: 8
Training loss: 2.1849233438414113
Validation loss: 2.4976402384766496

Epoch: 5| Step: 9
Training loss: 1.6997398542058453
Validation loss: 2.492829613405596

Epoch: 5| Step: 10
Training loss: 2.176507414307641
Validation loss: 2.5111520948026085

Epoch: 391| Step: 0
Training loss: 1.5322496693256487
Validation loss: 2.5489771738595715

Epoch: 5| Step: 1
Training loss: 2.0823643401839593
Validation loss: 2.541181073803852

Epoch: 5| Step: 2
Training loss: 2.2208712471403
Validation loss: 2.542878516817837

Epoch: 5| Step: 3
Training loss: 2.194829161302138
Validation loss: 2.5506005431942342

Epoch: 5| Step: 4
Training loss: 1.4156194724676077
Validation loss: 2.5073569326799494

Epoch: 5| Step: 5
Training loss: 1.7358286496430548
Validation loss: 2.5098580680272002

Epoch: 5| Step: 6
Training loss: 2.1308143953633767
Validation loss: 2.5583167857962064

Epoch: 5| Step: 7
Training loss: 1.9140299268792482
Validation loss: 2.514161048980311

Epoch: 5| Step: 8
Training loss: 1.9181294733208494
Validation loss: 2.5067383850949314

Epoch: 5| Step: 9
Training loss: 2.748581693942821
Validation loss: 2.508088965656682

Epoch: 5| Step: 10
Training loss: 2.2525764125518064
Validation loss: 2.5165082893772213

Epoch: 392| Step: 0
Training loss: 2.578800182362759
Validation loss: 2.520214645247537

Epoch: 5| Step: 1
Training loss: 2.098282988562685
Validation loss: 2.527701578787626

Epoch: 5| Step: 2
Training loss: 1.8396395106250394
Validation loss: 2.446160760205724

Epoch: 5| Step: 3
Training loss: 2.076325519435402
Validation loss: 2.557143743393885

Epoch: 5| Step: 4
Training loss: 1.7941703011558185
Validation loss: 2.5261403362124395

Epoch: 5| Step: 5
Training loss: 2.0999968982855277
Validation loss: 2.5576725529871283

Epoch: 5| Step: 6
Training loss: 1.7181016566139842
Validation loss: 2.5022647689798494

Epoch: 5| Step: 7
Training loss: 2.070153572172347
Validation loss: 2.483816388331858

Epoch: 5| Step: 8
Training loss: 2.0543122039472532
Validation loss: 2.514295347493206

Epoch: 5| Step: 9
Training loss: 1.9345219397623157
Validation loss: 2.550645656267309

Epoch: 5| Step: 10
Training loss: 2.1007196374088375
Validation loss: 2.535873757758081

Epoch: 393| Step: 0
Training loss: 2.8204423446564637
Validation loss: 2.5363798270619964

Epoch: 5| Step: 1
Training loss: 1.5476073255898475
Validation loss: 2.4755402270519564

Epoch: 5| Step: 2
Training loss: 1.9810767209304758
Validation loss: 2.5133257318420212

Epoch: 5| Step: 3
Training loss: 1.8265779910642155
Validation loss: 2.5660240148538036

Epoch: 5| Step: 4
Training loss: 1.9648806377004575
Validation loss: 2.5781659980365506

Epoch: 5| Step: 5
Training loss: 2.261050848765756
Validation loss: 2.5399714794209745

Epoch: 5| Step: 6
Training loss: 1.6660000262586723
Validation loss: 2.5256638154986253

Epoch: 5| Step: 7
Training loss: 1.8657220812000226
Validation loss: 2.5337086030910467

Epoch: 5| Step: 8
Training loss: 1.8149793701470682
Validation loss: 2.4834187171755815

Epoch: 5| Step: 9
Training loss: 2.2132565901944825
Validation loss: 2.530278037365664

Epoch: 5| Step: 10
Training loss: 1.9958274350115666
Validation loss: 2.4961484103602025

Epoch: 394| Step: 0
Training loss: 2.370464008797517
Validation loss: 2.535880431027804

Epoch: 5| Step: 1
Training loss: 1.9647143342188043
Validation loss: 2.542169890438654

Epoch: 5| Step: 2
Training loss: 2.108003523691551
Validation loss: 2.503910373066644

Epoch: 5| Step: 3
Training loss: 1.6401139689597055
Validation loss: 2.530386957512245

Epoch: 5| Step: 4
Training loss: 1.6654605634011959
Validation loss: 2.4989415327624056

Epoch: 5| Step: 5
Training loss: 2.060377242351104
Validation loss: 2.528988890593113

Epoch: 5| Step: 6
Training loss: 1.8741343089231066
Validation loss: 2.5310309910494118

Epoch: 5| Step: 7
Training loss: 2.298233149693817
Validation loss: 2.5413313489308846

Epoch: 5| Step: 8
Training loss: 1.7380775589488608
Validation loss: 2.566263101429822

Epoch: 5| Step: 9
Training loss: 2.188756854157143
Validation loss: 2.5287057610048365

Epoch: 5| Step: 10
Training loss: 2.0663493676820646
Validation loss: 2.559566481414477

Epoch: 395| Step: 0
Training loss: 2.0511209261103627
Validation loss: 2.5414083649823116

Epoch: 5| Step: 1
Training loss: 1.6198780327082747
Validation loss: 2.5393687003174557

Epoch: 5| Step: 2
Training loss: 2.157032921226376
Validation loss: 2.5184002589622567

Epoch: 5| Step: 3
Training loss: 1.7383542163407684
Validation loss: 2.58239568676136

Epoch: 5| Step: 4
Training loss: 1.2804147277198326
Validation loss: 2.5003773373739344

Epoch: 5| Step: 5
Training loss: 2.169833424410999
Validation loss: 2.581758489175464

Epoch: 5| Step: 6
Training loss: 1.9408351741381846
Validation loss: 2.5337119172840836

Epoch: 5| Step: 7
Training loss: 2.670896562927816
Validation loss: 2.534815927619137

Epoch: 5| Step: 8
Training loss: 2.1786104774995687
Validation loss: 2.5339843158760518

Epoch: 5| Step: 9
Training loss: 1.946796693650701
Validation loss: 2.512677067873185

Epoch: 5| Step: 10
Training loss: 2.41276678478034
Validation loss: 2.5277830998150095

Epoch: 396| Step: 0
Training loss: 2.0813855284590153
Validation loss: 2.540606911886255

Epoch: 5| Step: 1
Training loss: 1.8773737822062058
Validation loss: 2.540301824088719

Epoch: 5| Step: 2
Training loss: 1.71990775215819
Validation loss: 2.5199452680642906

Epoch: 5| Step: 3
Training loss: 1.7113042290331197
Validation loss: 2.5378779417339237

Epoch: 5| Step: 4
Training loss: 2.156478759130338
Validation loss: 2.5300740404833255

Epoch: 5| Step: 5
Training loss: 1.939782551642387
Validation loss: 2.531013257921759

Epoch: 5| Step: 6
Training loss: 2.783917808459476
Validation loss: 2.5419384471306987

Epoch: 5| Step: 7
Training loss: 1.917122150976916
Validation loss: 2.5881283770314227

Epoch: 5| Step: 8
Training loss: 1.7461736263976189
Validation loss: 2.4873713047554404

Epoch: 5| Step: 9
Training loss: 2.3767414735396564
Validation loss: 2.5462290764325313

Epoch: 5| Step: 10
Training loss: 2.0266366067129415
Validation loss: 2.504606011363148

Epoch: 397| Step: 0
Training loss: 2.239572947869876
Validation loss: 2.564302062425277

Epoch: 5| Step: 1
Training loss: 2.152262774430998
Validation loss: 2.6039849550572356

Epoch: 5| Step: 2
Training loss: 2.067779949751245
Validation loss: 2.5391479881667918

Epoch: 5| Step: 3
Training loss: 1.8870064652276077
Validation loss: 2.5586301774537388

Epoch: 5| Step: 4
Training loss: 1.6628860828426337
Validation loss: 2.533169258689461

Epoch: 5| Step: 5
Training loss: 1.7321394525643374
Validation loss: 2.5361114481720826

Epoch: 5| Step: 6
Training loss: 2.1047360874109957
Validation loss: 2.4683613105776994

Epoch: 5| Step: 7
Training loss: 1.6712285868857149
Validation loss: 2.504660047110042

Epoch: 5| Step: 8
Training loss: 2.5439947961838
Validation loss: 2.586762901325761

Epoch: 5| Step: 9
Training loss: 2.4537521824022988
Validation loss: 2.5352904495670905

Epoch: 5| Step: 10
Training loss: 2.0383460880025006
Validation loss: 2.525307243577188

Epoch: 398| Step: 0
Training loss: 1.5757006161683167
Validation loss: 2.47408221432807

Epoch: 5| Step: 1
Training loss: 2.3547892689624486
Validation loss: 2.5179822075543026

Epoch: 5| Step: 2
Training loss: 1.741524129568413
Validation loss: 2.580013408133193

Epoch: 5| Step: 3
Training loss: 2.4210143498180976
Validation loss: 2.518069045670012

Epoch: 5| Step: 4
Training loss: 2.0526960461900914
Validation loss: 2.522834238648512

Epoch: 5| Step: 5
Training loss: 1.7574963772819157
Validation loss: 2.5068234323833263

Epoch: 5| Step: 6
Training loss: 2.4063012253894547
Validation loss: 2.595983779596159

Epoch: 5| Step: 7
Training loss: 1.522948122895566
Validation loss: 2.5301985466605026

Epoch: 5| Step: 8
Training loss: 1.8090229225540986
Validation loss: 2.5440668352253946

Epoch: 5| Step: 9
Training loss: 2.026417662210219
Validation loss: 2.533305020253728

Epoch: 5| Step: 10
Training loss: 2.0948500519034092
Validation loss: 2.5280945379704423

Epoch: 399| Step: 0
Training loss: 3.0219999143548697
Validation loss: 2.554714156956886

Epoch: 5| Step: 1
Training loss: 2.1797958948672305
Validation loss: 2.525161594591782

Epoch: 5| Step: 2
Training loss: 1.8032153842427157
Validation loss: 2.530656991980884

Epoch: 5| Step: 3
Training loss: 2.062513293599145
Validation loss: 2.5470398205914573

Epoch: 5| Step: 4
Training loss: 1.8958488365908825
Validation loss: 2.5293998078717257

Epoch: 5| Step: 5
Training loss: 2.030789601895166
Validation loss: 2.503234110632801

Epoch: 5| Step: 6
Training loss: 1.5798227978579864
Validation loss: 2.5416370257648566

Epoch: 5| Step: 7
Training loss: 1.8210472621409164
Validation loss: 2.4733073080782857

Epoch: 5| Step: 8
Training loss: 2.1340603374470803
Validation loss: 2.551853285251433

Epoch: 5| Step: 9
Training loss: 1.563979707064285
Validation loss: 2.5174734002061125

Epoch: 5| Step: 10
Training loss: 1.7765885645582424
Validation loss: 2.515349792741586

Epoch: 400| Step: 0
Training loss: 1.7082264641930123
Validation loss: 2.523858767728537

Epoch: 5| Step: 1
Training loss: 2.0119187931486224
Validation loss: 2.572051927048497

Epoch: 5| Step: 2
Training loss: 1.569236196732233
Validation loss: 2.5110295253588673

Epoch: 5| Step: 3
Training loss: 2.1102399394935842
Validation loss: 2.567901194401915

Epoch: 5| Step: 4
Training loss: 1.9300765290183266
Validation loss: 2.5301825975586096

Epoch: 5| Step: 5
Training loss: 1.660633691686727
Validation loss: 2.5612900040899276

Epoch: 5| Step: 6
Training loss: 2.3983516118579367
Validation loss: 2.564823462880459

Epoch: 5| Step: 7
Training loss: 1.601838846323329
Validation loss: 2.5649089849952764

Epoch: 5| Step: 8
Training loss: 2.164087729186476
Validation loss: 2.489268280193825

Epoch: 5| Step: 9
Training loss: 2.4965223920395903
Validation loss: 2.5162792889940047

Epoch: 5| Step: 10
Training loss: 2.171578366447671
Validation loss: 2.5253221138855677

Testing loss: 2.6640531726821792
