Epoch: 1| Step: 0
Training loss: 5.071811918664341
Validation loss: 4.555092302731209

Epoch: 5| Step: 1
Training loss: 5.012992952607804
Validation loss: 4.55317729171319

Epoch: 5| Step: 2
Training loss: 4.378224084074626
Validation loss: 4.5467184231724795

Epoch: 5| Step: 3
Training loss: 4.655542511922994
Validation loss: 4.542965140674706

Epoch: 5| Step: 4
Training loss: 4.364060375897375
Validation loss: 4.540970677384789

Epoch: 5| Step: 5
Training loss: 4.008845562368289
Validation loss: 4.534587201784378

Epoch: 5| Step: 6
Training loss: 4.174574532215758
Validation loss: 4.533101562321416

Epoch: 5| Step: 7
Training loss: 4.783331723273845
Validation loss: 4.5266615218491335

Epoch: 5| Step: 8
Training loss: 4.761585762601507
Validation loss: 4.522683667118997

Epoch: 5| Step: 9
Training loss: 5.1485921694687224
Validation loss: 4.519855614511432

Epoch: 5| Step: 10
Training loss: 4.50337622403027
Validation loss: 4.513804178802444

Epoch: 2| Step: 0
Training loss: 4.93378801484367
Validation loss: 4.509871767399885

Epoch: 5| Step: 1
Training loss: 3.3886717342849395
Validation loss: 4.50378122150747

Epoch: 5| Step: 2
Training loss: 4.819267171970143
Validation loss: 4.5033849862380695

Epoch: 5| Step: 3
Training loss: 5.028899407837702
Validation loss: 4.499637634745757

Epoch: 5| Step: 4
Training loss: 4.166618092571684
Validation loss: 4.494280118399097

Epoch: 5| Step: 5
Training loss: 5.0098874558772915
Validation loss: 4.488012108517887

Epoch: 5| Step: 6
Training loss: 4.403804235543983
Validation loss: 4.487772745113855

Epoch: 5| Step: 7
Training loss: 4.739847275088313
Validation loss: 4.4844384998034545

Epoch: 5| Step: 8
Training loss: 5.1395715254374945
Validation loss: 4.477255007448233

Epoch: 5| Step: 9
Training loss: 4.094574124614535
Validation loss: 4.472165692686622

Epoch: 5| Step: 10
Training loss: 4.553259283741753
Validation loss: 4.470312979797371

Epoch: 3| Step: 0
Training loss: 3.8474869589184904
Validation loss: 4.465272757175157

Epoch: 5| Step: 1
Training loss: 5.318561820478995
Validation loss: 4.462276272720592

Epoch: 5| Step: 2
Training loss: 4.022989488861515
Validation loss: 4.455304658234914

Epoch: 5| Step: 3
Training loss: 4.247233893111828
Validation loss: 4.450662309821855

Epoch: 5| Step: 4
Training loss: 4.425125922011619
Validation loss: 4.44580411280464

Epoch: 5| Step: 5
Training loss: 4.760704627255679
Validation loss: 4.445222765868951

Epoch: 5| Step: 6
Training loss: 5.408878811844531
Validation loss: 4.44016443888336

Epoch: 5| Step: 7
Training loss: 4.216588575723145
Validation loss: 4.43358083924302

Epoch: 5| Step: 8
Training loss: 5.0305865306428394
Validation loss: 4.43027720682441

Epoch: 5| Step: 9
Training loss: 3.6211767094562504
Validation loss: 4.427259378232533

Epoch: 5| Step: 10
Training loss: 4.848027069884915
Validation loss: 4.422138283526679

Epoch: 4| Step: 0
Training loss: 5.508829658681962
Validation loss: 4.41720836766845

Epoch: 5| Step: 1
Training loss: 4.356368364562252
Validation loss: 4.410029123999917

Epoch: 5| Step: 2
Training loss: 4.528089802501877
Validation loss: 4.411601627367128

Epoch: 5| Step: 3
Training loss: 3.4387146624375635
Validation loss: 4.403710395537308

Epoch: 5| Step: 4
Training loss: 3.7647026483613035
Validation loss: 4.394918346059728

Epoch: 5| Step: 5
Training loss: 4.719006866133202
Validation loss: 4.394309362864525

Epoch: 5| Step: 6
Training loss: 5.145756070976566
Validation loss: 4.3880118578980944

Epoch: 5| Step: 7
Training loss: 3.93329626055127
Validation loss: 4.384308781040196

Epoch: 5| Step: 8
Training loss: 4.856703045110313
Validation loss: 4.376975407828555

Epoch: 5| Step: 9
Training loss: 4.948069209374181
Validation loss: 4.372566009000534

Epoch: 5| Step: 10
Training loss: 3.7601180587658325
Validation loss: 4.366765139822958

Epoch: 5| Step: 0
Training loss: 4.662186492934132
Validation loss: 4.360970875906591

Epoch: 5| Step: 1
Training loss: 3.207729101049179
Validation loss: 4.35732583821225

Epoch: 5| Step: 2
Training loss: 4.7364008129087285
Validation loss: 4.352584522374199

Epoch: 5| Step: 3
Training loss: 4.387848651650934
Validation loss: 4.344770338681961

Epoch: 5| Step: 4
Training loss: 4.937573203015003
Validation loss: 4.339457533030347

Epoch: 5| Step: 5
Training loss: 5.223968820253941
Validation loss: 4.3312175975683065

Epoch: 5| Step: 6
Training loss: 4.264816934250052
Validation loss: 4.327746710499756

Epoch: 5| Step: 7
Training loss: 4.569379871122143
Validation loss: 4.322787801415859

Epoch: 5| Step: 8
Training loss: 4.093747903371958
Validation loss: 4.323614129403232

Epoch: 5| Step: 9
Training loss: 4.372035738953371
Validation loss: 4.307092307603807

Epoch: 5| Step: 10
Training loss: 4.1514380571682485
Validation loss: 4.3067692336917185

Epoch: 6| Step: 0
Training loss: 3.9870651438500113
Validation loss: 4.298822130404988

Epoch: 5| Step: 1
Training loss: 5.388580376794323
Validation loss: 4.292943379670764

Epoch: 5| Step: 2
Training loss: 4.265529757264321
Validation loss: 4.287996829129067

Epoch: 5| Step: 3
Training loss: 4.269722671615205
Validation loss: 4.282350710493177

Epoch: 5| Step: 4
Training loss: 3.670670981538922
Validation loss: 4.274616709631085

Epoch: 5| Step: 5
Training loss: 5.0432232852349825
Validation loss: 4.270409140341256

Epoch: 5| Step: 6
Training loss: 4.664606161716217
Validation loss: 4.266576875394271

Epoch: 5| Step: 7
Training loss: 4.4891941878444905
Validation loss: 4.259242018045068

Epoch: 5| Step: 8
Training loss: 4.892817094338633
Validation loss: 4.253847512364221

Epoch: 5| Step: 9
Training loss: 3.2032467702654164
Validation loss: 4.245827756844219

Epoch: 5| Step: 10
Training loss: 3.8810214357754753
Validation loss: 4.242138334621016

Epoch: 7| Step: 0
Training loss: 4.116027784515113
Validation loss: 4.235041214747382

Epoch: 5| Step: 1
Training loss: 5.1025998987103
Validation loss: 4.226095711102058

Epoch: 5| Step: 2
Training loss: 3.8263055954252425
Validation loss: 4.2209871425875045

Epoch: 5| Step: 3
Training loss: 4.888954340371398
Validation loss: 4.211410463937491

Epoch: 5| Step: 4
Training loss: 3.5193744925117705
Validation loss: 4.2083904043588225

Epoch: 5| Step: 5
Training loss: 3.8344017419605367
Validation loss: 4.201215465255422

Epoch: 5| Step: 6
Training loss: 4.270924612170845
Validation loss: 4.19391340413568

Epoch: 5| Step: 7
Training loss: 4.454937054224727
Validation loss: 4.189325702669556

Epoch: 5| Step: 8
Training loss: 4.139906795760973
Validation loss: 4.172737445690985

Epoch: 5| Step: 9
Training loss: 4.7623718164369695
Validation loss: 4.172576735896655

Epoch: 5| Step: 10
Training loss: 4.345498810154896
Validation loss: 4.16735643563585

Epoch: 8| Step: 0
Training loss: 4.027902558831022
Validation loss: 4.15840511006485

Epoch: 5| Step: 1
Training loss: 4.132203949687324
Validation loss: 4.149910390365549

Epoch: 5| Step: 2
Training loss: 4.780547246212153
Validation loss: 4.1451533829699905

Epoch: 5| Step: 3
Training loss: 3.6537879414110477
Validation loss: 4.1348505793754375

Epoch: 5| Step: 4
Training loss: 4.417457989512897
Validation loss: 4.133657367884611

Epoch: 5| Step: 5
Training loss: 2.623930031832153
Validation loss: 4.122715682639109

Epoch: 5| Step: 6
Training loss: 4.428469212842265
Validation loss: 4.110255128076572

Epoch: 5| Step: 7
Training loss: 4.521845667598259
Validation loss: 4.106652000728938

Epoch: 5| Step: 8
Training loss: 4.243316331596106
Validation loss: 4.098854665405193

Epoch: 5| Step: 9
Training loss: 4.1322988035837405
Validation loss: 4.092420386972533

Epoch: 5| Step: 10
Training loss: 5.417564943608235
Validation loss: 4.083981786239525

Epoch: 9| Step: 0
Training loss: 4.218797019413902
Validation loss: 4.076121859393463

Epoch: 5| Step: 1
Training loss: 2.497818853665397
Validation loss: 4.067877538026613

Epoch: 5| Step: 2
Training loss: 4.818566004385853
Validation loss: 4.060093845988408

Epoch: 5| Step: 3
Training loss: 4.667795907495657
Validation loss: 4.048551244520643

Epoch: 5| Step: 4
Training loss: 4.619231467129985
Validation loss: 4.042681510906427

Epoch: 5| Step: 5
Training loss: 4.016333610265128
Validation loss: 4.034767505645627

Epoch: 5| Step: 6
Training loss: 3.6806066705445226
Validation loss: 4.027228123820899

Epoch: 5| Step: 7
Training loss: 4.891832683980171
Validation loss: 4.016120600115994

Epoch: 5| Step: 8
Training loss: 3.662053384988651
Validation loss: 3.9975959926798503

Epoch: 5| Step: 9
Training loss: 4.039002054673437
Validation loss: 3.9964891235979323

Epoch: 5| Step: 10
Training loss: 4.10092838290119
Validation loss: 3.986821780365582

Epoch: 10| Step: 0
Training loss: 4.029522192863963
Validation loss: 3.9780598119867476

Epoch: 5| Step: 1
Training loss: 4.063226722860439
Validation loss: 3.976061775698513

Epoch: 5| Step: 2
Training loss: 4.373179029518315
Validation loss: 3.96691044452759

Epoch: 5| Step: 3
Training loss: 3.925285649687246
Validation loss: 3.951810583980043

Epoch: 5| Step: 4
Training loss: 3.3210360826911565
Validation loss: 3.944199477099397

Epoch: 5| Step: 5
Training loss: 3.93888382587786
Validation loss: 3.9372343347127874

Epoch: 5| Step: 6
Training loss: 4.113273830715056
Validation loss: 3.9206062097761336

Epoch: 5| Step: 7
Training loss: 4.333161326197932
Validation loss: 3.91092842553985

Epoch: 5| Step: 8
Training loss: 3.593499747146124
Validation loss: 3.9063304815717816

Epoch: 5| Step: 9
Training loss: 4.441613668062359
Validation loss: 3.8951719239284954

Epoch: 5| Step: 10
Training loss: 4.53599773160686
Validation loss: 3.8804757868920383

Epoch: 11| Step: 0
Training loss: 4.161582336997242
Validation loss: 3.8725818984591145

Epoch: 5| Step: 1
Training loss: 3.2822894675149494
Validation loss: 3.867123885557002

Epoch: 5| Step: 2
Training loss: 4.65738167547442
Validation loss: 3.8564693584056076

Epoch: 5| Step: 3
Training loss: 4.0302453970205185
Validation loss: 3.8451412633368967

Epoch: 5| Step: 4
Training loss: 4.73388870813683
Validation loss: 3.830364778336018

Epoch: 5| Step: 5
Training loss: 3.5320817086088288
Validation loss: 3.823371579607016

Epoch: 5| Step: 6
Training loss: 3.404506972324976
Validation loss: 3.8121242906272355

Epoch: 5| Step: 7
Training loss: 4.4562773672924765
Validation loss: 3.7969071905811544

Epoch: 5| Step: 8
Training loss: 4.268457611034373
Validation loss: 3.7855605990966814

Epoch: 5| Step: 9
Training loss: 3.152642936642511
Validation loss: 3.772211873343782

Epoch: 5| Step: 10
Training loss: 3.4947523559239273
Validation loss: 3.766308916704122

Epoch: 12| Step: 0
Training loss: 4.233702433757883
Validation loss: 3.755489896168486

Epoch: 5| Step: 1
Training loss: 4.306982740450452
Validation loss: 3.7377576747340986

Epoch: 5| Step: 2
Training loss: 3.31168384214138
Validation loss: 3.7266511850451716

Epoch: 5| Step: 3
Training loss: 4.3470014300084046
Validation loss: 3.7155540909190776

Epoch: 5| Step: 4
Training loss: 2.855225934977915
Validation loss: 3.6965830349485547

Epoch: 5| Step: 5
Training loss: 3.744270525426565
Validation loss: 3.6877373225681414

Epoch: 5| Step: 6
Training loss: 3.738117593114697
Validation loss: 3.68018705061194

Epoch: 5| Step: 7
Training loss: 4.1690778749201165
Validation loss: 3.672087346213809

Epoch: 5| Step: 8
Training loss: 3.339743522344784
Validation loss: 3.6579322026748966

Epoch: 5| Step: 9
Training loss: 4.154647632994368
Validation loss: 3.640006495058327

Epoch: 5| Step: 10
Training loss: 3.878753075163566
Validation loss: 3.633854721443602

Epoch: 13| Step: 0
Training loss: 3.5137880400475012
Validation loss: 3.6233847643605257

Epoch: 5| Step: 1
Training loss: 3.9627929194152913
Validation loss: 3.610015347819443

Epoch: 5| Step: 2
Training loss: 3.854895459253081
Validation loss: 3.5964031824584497

Epoch: 5| Step: 3
Training loss: 3.4827951176698635
Validation loss: 3.582328783403513

Epoch: 5| Step: 4
Training loss: 4.330074601092386
Validation loss: 3.571129383821781

Epoch: 5| Step: 5
Training loss: 3.811145979780782
Validation loss: 3.550072895152624

Epoch: 5| Step: 6
Training loss: 3.548362386455244
Validation loss: 3.537905565093222

Epoch: 5| Step: 7
Training loss: 4.172343595669257
Validation loss: 3.524202915272221

Epoch: 5| Step: 8
Training loss: 2.9742970894430725
Validation loss: 3.512199782742331

Epoch: 5| Step: 9
Training loss: 3.7352648835939806
Validation loss: 3.5023381206702204

Epoch: 5| Step: 10
Training loss: 3.2861909994384133
Validation loss: 3.4793022271319534

Epoch: 14| Step: 0
Training loss: 3.8400245538562316
Validation loss: 3.472045923057391

Epoch: 5| Step: 1
Training loss: 3.799550938424066
Validation loss: 3.4615318850709063

Epoch: 5| Step: 2
Training loss: 4.020529990868207
Validation loss: 3.4331550516214544

Epoch: 5| Step: 3
Training loss: 3.3242442828227716
Validation loss: 3.419365682457036

Epoch: 5| Step: 4
Training loss: 3.2125499973785216
Validation loss: 3.4069970049295617

Epoch: 5| Step: 5
Training loss: 3.859206222982751
Validation loss: 3.393095106177398

Epoch: 5| Step: 6
Training loss: 3.7052343614100356
Validation loss: 3.3820279187820432

Epoch: 5| Step: 7
Training loss: 3.8531676501213137
Validation loss: 3.3691561758506725

Epoch: 5| Step: 8
Training loss: 3.13519835530574
Validation loss: 3.3547841912963916

Epoch: 5| Step: 9
Training loss: 3.2998266521353914
Validation loss: 3.335327209423679

Epoch: 5| Step: 10
Training loss: 3.081584554774556
Validation loss: 3.3180661621449845

Epoch: 15| Step: 0
Training loss: 3.836978809861882
Validation loss: 3.308833305729962

Epoch: 5| Step: 1
Training loss: 3.9186417219422203
Validation loss: 3.29308599451799

Epoch: 5| Step: 2
Training loss: 4.161987474751724
Validation loss: 3.264664325106927

Epoch: 5| Step: 3
Training loss: 3.19049679370618
Validation loss: 3.2526515228605506

Epoch: 5| Step: 4
Training loss: 3.5842666888979613
Validation loss: 3.232702906449912

Epoch: 5| Step: 5
Training loss: 3.2788866523773255
Validation loss: 3.2189092312979852

Epoch: 5| Step: 6
Training loss: 3.3791033913316535
Validation loss: 3.207176011478886

Epoch: 5| Step: 7
Training loss: 3.035205109152669
Validation loss: 3.1888080545398307

Epoch: 5| Step: 8
Training loss: 2.910524403883779
Validation loss: 3.1743935858973473

Epoch: 5| Step: 9
Training loss: 2.8807233151132903
Validation loss: 3.1580456645689123

Epoch: 5| Step: 10
Training loss: 3.336025406619506
Validation loss: 3.1482175823859864

Epoch: 16| Step: 0
Training loss: 3.1101749483805072
Validation loss: 3.1307357603908637

Epoch: 5| Step: 1
Training loss: 2.812658941228323
Validation loss: 3.1121965916323218

Epoch: 5| Step: 2
Training loss: 3.188011278024825
Validation loss: 3.107792968437855

Epoch: 5| Step: 3
Training loss: 3.358956386300054
Validation loss: 3.085776950184751

Epoch: 5| Step: 4
Training loss: 3.485970033693013
Validation loss: 3.077926933362861

Epoch: 5| Step: 5
Training loss: 3.6194541865312284
Validation loss: 3.0660492197421743

Epoch: 5| Step: 6
Training loss: 3.108145926163641
Validation loss: 3.0474843205016953

Epoch: 5| Step: 7
Training loss: 3.411195017817797
Validation loss: 3.023346040001673

Epoch: 5| Step: 8
Training loss: 3.5128610554361246
Validation loss: 3.0152980264392064

Epoch: 5| Step: 9
Training loss: 3.428778664819912
Validation loss: 3.0052146923638916

Epoch: 5| Step: 10
Training loss: 2.9957337243963043
Validation loss: 3.001347138508857

Epoch: 17| Step: 0
Training loss: 3.1624420160699995
Validation loss: 2.974216747713969

Epoch: 5| Step: 1
Training loss: 3.3468963935802303
Validation loss: 2.960372910371733

Epoch: 5| Step: 2
Training loss: 2.964474138584272
Validation loss: 2.940228872291143

Epoch: 5| Step: 3
Training loss: 3.232730760826993
Validation loss: 2.933976173776335

Epoch: 5| Step: 4
Training loss: 3.5716040213949434
Validation loss: 2.9242052182550795

Epoch: 5| Step: 5
Training loss: 3.1690122717790987
Validation loss: 2.916894116886681

Epoch: 5| Step: 6
Training loss: 3.5118667520431988
Validation loss: 2.8874947735954395

Epoch: 5| Step: 7
Training loss: 3.1953638347801796
Validation loss: 2.8756781737228314

Epoch: 5| Step: 8
Training loss: 2.706944760128512
Validation loss: 2.865997214917052

Epoch: 5| Step: 9
Training loss: 2.8988805057022153
Validation loss: 2.8517169554883206

Epoch: 5| Step: 10
Training loss: 2.8119583456012003
Validation loss: 2.834911844714971

Epoch: 18| Step: 0
Training loss: 3.1100305220893953
Validation loss: 2.8222207633380685

Epoch: 5| Step: 1
Training loss: 2.7498339689592246
Validation loss: 2.8073250983962037

Epoch: 5| Step: 2
Training loss: 3.1801280623267125
Validation loss: 2.809833349868863

Epoch: 5| Step: 3
Training loss: 3.5662381820937505
Validation loss: 2.7844438666819253

Epoch: 5| Step: 4
Training loss: 2.7151997504333667
Validation loss: 2.7791675690926225

Epoch: 5| Step: 5
Training loss: 3.3675752137754205
Validation loss: 2.761946593674067

Epoch: 5| Step: 6
Training loss: 2.669334051112416
Validation loss: 2.76218546692112

Epoch: 5| Step: 7
Training loss: 2.529780773872507
Validation loss: 2.754861946011083

Epoch: 5| Step: 8
Training loss: 2.9974993774311605
Validation loss: 2.7423517737557286

Epoch: 5| Step: 9
Training loss: 3.6562100921800402
Validation loss: 2.7245841111692193

Epoch: 5| Step: 10
Training loss: 2.8145995886215855
Validation loss: 2.723821552622493

Epoch: 19| Step: 0
Training loss: 3.2872819951518326
Validation loss: 2.710831804665814

Epoch: 5| Step: 1
Training loss: 2.6430273019662907
Validation loss: 2.7112709722850634

Epoch: 5| Step: 2
Training loss: 3.3674452255993876
Validation loss: 2.6799445704490594

Epoch: 5| Step: 3
Training loss: 3.4207437117093016
Validation loss: 2.6688464447090885

Epoch: 5| Step: 4
Training loss: 2.819816566886263
Validation loss: 2.677579513373662

Epoch: 5| Step: 5
Training loss: 2.4500015686964347
Validation loss: 2.6605725725380194

Epoch: 5| Step: 6
Training loss: 3.0451898071563432
Validation loss: 2.649215630878974

Epoch: 5| Step: 7
Training loss: 2.8829218319058523
Validation loss: 2.6520251383085793

Epoch: 5| Step: 8
Training loss: 2.6785887308924297
Validation loss: 2.6485586431187738

Epoch: 5| Step: 9
Training loss: 2.6923392440707716
Validation loss: 2.631208294573101

Epoch: 5| Step: 10
Training loss: 3.407735658082747
Validation loss: 2.6274549545408132

Epoch: 20| Step: 0
Training loss: 3.3876695541233905
Validation loss: 2.6246560081812227

Epoch: 5| Step: 1
Training loss: 2.0890559627912864
Validation loss: 2.6163697058618625

Epoch: 5| Step: 2
Training loss: 2.8735344510008693
Validation loss: 2.60987251622601

Epoch: 5| Step: 3
Training loss: 2.986938653663974
Validation loss: 2.604080627660816

Epoch: 5| Step: 4
Training loss: 2.7533878785457926
Validation loss: 2.5944329380853777

Epoch: 5| Step: 5
Training loss: 3.03735523271355
Validation loss: 2.584300170557903

Epoch: 5| Step: 6
Training loss: 2.8018867300801906
Validation loss: 2.596443247726675

Epoch: 5| Step: 7
Training loss: 3.146354952044179
Validation loss: 2.5982409472790082

Epoch: 5| Step: 8
Training loss: 3.3436052522791693
Validation loss: 2.5766899005203383

Epoch: 5| Step: 9
Training loss: 2.942501922840148
Validation loss: 2.5825124062095806

Epoch: 5| Step: 10
Training loss: 2.6265633786737266
Validation loss: 2.5656208479704814

Epoch: 21| Step: 0
Training loss: 2.801697989324076
Validation loss: 2.578446914000428

Epoch: 5| Step: 1
Training loss: 2.8893621211968616
Validation loss: 2.5766568007886086

Epoch: 5| Step: 2
Training loss: 2.1160667240028443
Validation loss: 2.577829072884743

Epoch: 5| Step: 3
Training loss: 3.5540305400388457
Validation loss: 2.578883213033851

Epoch: 5| Step: 4
Training loss: 2.7024320033832776
Validation loss: 2.5671247951469613

Epoch: 5| Step: 5
Training loss: 3.1331354673961456
Validation loss: 2.5628974750348728

Epoch: 5| Step: 6
Training loss: 3.114157980427934
Validation loss: 2.560021023479718

Epoch: 5| Step: 7
Training loss: 2.845148434378681
Validation loss: 2.5573548406748343

Epoch: 5| Step: 8
Training loss: 2.8801407671011274
Validation loss: 2.54140324305912

Epoch: 5| Step: 9
Training loss: 2.3705490969900276
Validation loss: 2.5502411609879534

Epoch: 5| Step: 10
Training loss: 3.506827099203914
Validation loss: 2.558061772532931

Epoch: 22| Step: 0
Training loss: 3.003626538809969
Validation loss: 2.552484261765536

Epoch: 5| Step: 1
Training loss: 2.3646897839575125
Validation loss: 2.5462971146268285

Epoch: 5| Step: 2
Training loss: 3.020505128767398
Validation loss: 2.549757848281221

Epoch: 5| Step: 3
Training loss: 3.5580561176268204
Validation loss: 2.535829738101781

Epoch: 5| Step: 4
Training loss: 3.1158788701950573
Validation loss: 2.5444813143330447

Epoch: 5| Step: 5
Training loss: 3.1628263342835314
Validation loss: 2.5446770013276434

Epoch: 5| Step: 6
Training loss: 2.4376022121811265
Validation loss: 2.5387992920611224

Epoch: 5| Step: 7
Training loss: 2.684786113836777
Validation loss: 2.527949966339553

Epoch: 5| Step: 8
Training loss: 2.886108168681161
Validation loss: 2.5413998228897916

Epoch: 5| Step: 9
Training loss: 2.8352892426376015
Validation loss: 2.518309445780295

Epoch: 5| Step: 10
Training loss: 2.753426757625293
Validation loss: 2.5321727262415767

Epoch: 23| Step: 0
Training loss: 3.551582069863318
Validation loss: 2.5393710778260346

Epoch: 5| Step: 1
Training loss: 2.9315155429574435
Validation loss: 2.531195850266598

Epoch: 5| Step: 2
Training loss: 2.199521194720103
Validation loss: 2.536585051124665

Epoch: 5| Step: 3
Training loss: 3.4034490706005687
Validation loss: 2.529530001474391

Epoch: 5| Step: 4
Training loss: 2.7636711848497373
Validation loss: 2.5145315439525713

Epoch: 5| Step: 5
Training loss: 3.069935083852325
Validation loss: 2.5306634287883742

Epoch: 5| Step: 6
Training loss: 3.030162026130294
Validation loss: 2.5219762227148417

Epoch: 5| Step: 7
Training loss: 3.014981690409721
Validation loss: 2.5272790055081726

Epoch: 5| Step: 8
Training loss: 2.113066205772556
Validation loss: 2.5324302159180476

Epoch: 5| Step: 9
Training loss: 2.796310794119998
Validation loss: 2.5238645321731163

Epoch: 5| Step: 10
Training loss: 2.7112627961070914
Validation loss: 2.5215338704201407

Epoch: 24| Step: 0
Training loss: 2.074661581179475
Validation loss: 2.517743900225755

Epoch: 5| Step: 1
Training loss: 2.711320217941575
Validation loss: 2.5324223076282992

Epoch: 5| Step: 2
Training loss: 2.7604772213225957
Validation loss: 2.519099432382194

Epoch: 5| Step: 3
Training loss: 2.2463775720813492
Validation loss: 2.516498122438637

Epoch: 5| Step: 4
Training loss: 3.2451534814495386
Validation loss: 2.522823857385163

Epoch: 5| Step: 5
Training loss: 3.435456379386583
Validation loss: 2.5341927708180125

Epoch: 5| Step: 6
Training loss: 2.8564895496040363
Validation loss: 2.5342130800240676

Epoch: 5| Step: 7
Training loss: 3.2531760908909813
Validation loss: 2.523147320975903

Epoch: 5| Step: 8
Training loss: 2.6707771231875457
Validation loss: 2.5358774406449065

Epoch: 5| Step: 9
Training loss: 3.1712576730505257
Validation loss: 2.5346349230754246

Epoch: 5| Step: 10
Training loss: 3.2048884306009935
Validation loss: 2.5173379442739954

Epoch: 25| Step: 0
Training loss: 2.4460696672139193
Validation loss: 2.5242301254586663

Epoch: 5| Step: 1
Training loss: 3.1908947687684726
Validation loss: 2.5236551804333085

Epoch: 5| Step: 2
Training loss: 3.0441735444894937
Validation loss: 2.531963924763775

Epoch: 5| Step: 3
Training loss: 2.875798819316492
Validation loss: 2.5221618386342284

Epoch: 5| Step: 4
Training loss: 2.3120914820091354
Validation loss: 2.534411887388296

Epoch: 5| Step: 5
Training loss: 2.9927837684083096
Validation loss: 2.511551282785886

Epoch: 5| Step: 6
Training loss: 3.518356821646473
Validation loss: 2.5269229455734252

Epoch: 5| Step: 7
Training loss: 2.7811816775041707
Validation loss: 2.544240919475476

Epoch: 5| Step: 8
Training loss: 2.5226866369700316
Validation loss: 2.528301003397905

Epoch: 5| Step: 9
Training loss: 3.17314716252478
Validation loss: 2.526071724661556

Epoch: 5| Step: 10
Training loss: 2.8521791392346234
Validation loss: 2.5391258313884277

Epoch: 26| Step: 0
Training loss: 2.7713818305994145
Validation loss: 2.532275499694424

Epoch: 5| Step: 1
Training loss: 2.7280980024717016
Validation loss: 2.5294566078821186

Epoch: 5| Step: 2
Training loss: 3.3015651516919515
Validation loss: 2.53778680829034

Epoch: 5| Step: 3
Training loss: 3.2960933102112175
Validation loss: 2.525039106171983

Epoch: 5| Step: 4
Training loss: 2.2557736599313523
Validation loss: 2.538698485274558

Epoch: 5| Step: 5
Training loss: 2.6827592065724457
Validation loss: 2.5226791991403794

Epoch: 5| Step: 6
Training loss: 3.1818006837041684
Validation loss: 2.5340102730181253

Epoch: 5| Step: 7
Training loss: 2.5173988485613554
Validation loss: 2.537669027790875

Epoch: 5| Step: 8
Training loss: 3.2815961382719965
Validation loss: 2.52420703031605

Epoch: 5| Step: 9
Training loss: 2.745144111449698
Validation loss: 2.532793952334647

Epoch: 5| Step: 10
Training loss: 2.866803135691573
Validation loss: 2.518876833745107

Epoch: 27| Step: 0
Training loss: 2.540249591038591
Validation loss: 2.524783691592291

Epoch: 5| Step: 1
Training loss: 2.882768832240407
Validation loss: 2.525665052827659

Epoch: 5| Step: 2
Training loss: 2.7390250639198706
Validation loss: 2.523870424589994

Epoch: 5| Step: 3
Training loss: 3.0076663291390093
Validation loss: 2.521401730672506

Epoch: 5| Step: 4
Training loss: 3.333662557238244
Validation loss: 2.522086823823675

Epoch: 5| Step: 5
Training loss: 2.877399604166176
Validation loss: 2.520645489190319

Epoch: 5| Step: 6
Training loss: 2.83261493850321
Validation loss: 2.5297600348736182

Epoch: 5| Step: 7
Training loss: 2.4019969658876135
Validation loss: 2.5237781504645245

Epoch: 5| Step: 8
Training loss: 3.177471766672826
Validation loss: 2.5294424693170594

Epoch: 5| Step: 9
Training loss: 2.836119086386883
Validation loss: 2.517922874139851

Epoch: 5| Step: 10
Training loss: 3.061130295232009
Validation loss: 2.5381902734105624

Epoch: 28| Step: 0
Training loss: 2.7017105900345224
Validation loss: 2.5239698500670102

Epoch: 5| Step: 1
Training loss: 3.4147965189910336
Validation loss: 2.5278269741074926

Epoch: 5| Step: 2
Training loss: 3.0550007769244965
Validation loss: 2.534847852877152

Epoch: 5| Step: 3
Training loss: 3.0754406062856305
Validation loss: 2.525672480849266

Epoch: 5| Step: 4
Training loss: 2.7073424849829495
Validation loss: 2.5197179729095818

Epoch: 5| Step: 5
Training loss: 1.93982796633779
Validation loss: 2.525679312011372

Epoch: 5| Step: 6
Training loss: 2.58140327792865
Validation loss: 2.526850492846933

Epoch: 5| Step: 7
Training loss: 3.131521820026448
Validation loss: 2.5133132926764485

Epoch: 5| Step: 8
Training loss: 2.826854947525278
Validation loss: 2.524606564772937

Epoch: 5| Step: 9
Training loss: 3.108161267656374
Validation loss: 2.515153847263152

Epoch: 5| Step: 10
Training loss: 2.976394608536082
Validation loss: 2.5144475455024207

Epoch: 29| Step: 0
Training loss: 2.6426618496529835
Validation loss: 2.504849832394396

Epoch: 5| Step: 1
Training loss: 2.752071120884549
Validation loss: 2.52499814914216

Epoch: 5| Step: 2
Training loss: 2.9350150128424133
Validation loss: 2.5253478179532527

Epoch: 5| Step: 3
Training loss: 3.30021057613022
Validation loss: 2.512888846145045

Epoch: 5| Step: 4
Training loss: 2.5472956585001993
Validation loss: 2.5169095735511844

Epoch: 5| Step: 5
Training loss: 3.096123141607195
Validation loss: 2.510630861979601

Epoch: 5| Step: 6
Training loss: 3.3532188608590405
Validation loss: 2.5074566806664884

Epoch: 5| Step: 7
Training loss: 2.3817177180519664
Validation loss: 2.5121125443444403

Epoch: 5| Step: 8
Training loss: 2.773340099934735
Validation loss: 2.51103026350706

Epoch: 5| Step: 9
Training loss: 2.634956460408462
Validation loss: 2.5103360367676117

Epoch: 5| Step: 10
Training loss: 3.198457769451757
Validation loss: 2.5173029021276663

Epoch: 30| Step: 0
Training loss: 2.8435402258329625
Validation loss: 2.5075847123727026

Epoch: 5| Step: 1
Training loss: 3.088993461890941
Validation loss: 2.5201387413738896

Epoch: 5| Step: 2
Training loss: 2.6873539729699916
Validation loss: 2.5269431103030433

Epoch: 5| Step: 3
Training loss: 2.8976473900975024
Validation loss: 2.5159612884485734

Epoch: 5| Step: 4
Training loss: 2.707113861981235
Validation loss: 2.5137532431826517

Epoch: 5| Step: 5
Training loss: 3.1066147710970755
Validation loss: 2.519202432355116

Epoch: 5| Step: 6
Training loss: 2.958557944210816
Validation loss: 2.5077505532434983

Epoch: 5| Step: 7
Training loss: 3.287788198624369
Validation loss: 2.5343302796579783

Epoch: 5| Step: 8
Training loss: 2.3573606873467203
Validation loss: 2.5195815814975933

Epoch: 5| Step: 9
Training loss: 2.863407813966085
Validation loss: 2.5210653574725765

Epoch: 5| Step: 10
Training loss: 2.865093578787604
Validation loss: 2.504944016546573

Epoch: 31| Step: 0
Training loss: 3.1234151254513765
Validation loss: 2.5277231850900947

Epoch: 5| Step: 1
Training loss: 1.8282024008512825
Validation loss: 2.5332089435759997

Epoch: 5| Step: 2
Training loss: 3.027819865534038
Validation loss: 2.531694520814653

Epoch: 5| Step: 3
Training loss: 3.2623731858903136
Validation loss: 2.5241161355729305

Epoch: 5| Step: 4
Training loss: 2.666312959180742
Validation loss: 2.514788037511177

Epoch: 5| Step: 5
Training loss: 2.493414119577854
Validation loss: 2.5269863783026105

Epoch: 5| Step: 6
Training loss: 3.2561024813633592
Validation loss: 2.506700476397903

Epoch: 5| Step: 7
Training loss: 2.750797329535775
Validation loss: 2.5172203333699903

Epoch: 5| Step: 8
Training loss: 3.2204943624540987
Validation loss: 2.5296259006717383

Epoch: 5| Step: 9
Training loss: 2.5684633415269094
Validation loss: 2.5255713632787393

Epoch: 5| Step: 10
Training loss: 3.225048532046862
Validation loss: 2.5172101183850697

Epoch: 32| Step: 0
Training loss: 2.8032642887002726
Validation loss: 2.519580446490974

Epoch: 5| Step: 1
Training loss: 2.1833714353231244
Validation loss: 2.5304931659709258

Epoch: 5| Step: 2
Training loss: 2.2945332948950283
Validation loss: 2.5157185789769003

Epoch: 5| Step: 3
Training loss: 3.030610951182411
Validation loss: 2.5293024699464834

Epoch: 5| Step: 4
Training loss: 2.903878834132925
Validation loss: 2.521140358951289

Epoch: 5| Step: 5
Training loss: 3.3891672965027975
Validation loss: 2.516956869239547

Epoch: 5| Step: 6
Training loss: 3.1385687174339796
Validation loss: 2.5149002717846867

Epoch: 5| Step: 7
Training loss: 3.0879417381423537
Validation loss: 2.5006543359393762

Epoch: 5| Step: 8
Training loss: 3.1586101507968336
Validation loss: 2.536355613469238

Epoch: 5| Step: 9
Training loss: 2.532016967620163
Validation loss: 2.5159710071820323

Epoch: 5| Step: 10
Training loss: 2.9939823195878903
Validation loss: 2.533329172433222

Epoch: 33| Step: 0
Training loss: 3.0570380881759704
Validation loss: 2.517620842169812

Epoch: 5| Step: 1
Training loss: 3.324911079078184
Validation loss: 2.527794207148766

Epoch: 5| Step: 2
Training loss: 2.6084336278806
Validation loss: 2.50682090230879

Epoch: 5| Step: 3
Training loss: 2.69659428732378
Validation loss: 2.5033762580823855

Epoch: 5| Step: 4
Training loss: 2.6145227331507113
Validation loss: 2.5037026601487047

Epoch: 5| Step: 5
Training loss: 2.6049589147274883
Validation loss: 2.519895158493822

Epoch: 5| Step: 6
Training loss: 2.6468340765841907
Validation loss: 2.5236980558078814

Epoch: 5| Step: 7
Training loss: 2.826577959498129
Validation loss: 2.504030923947225

Epoch: 5| Step: 8
Training loss: 3.2095607209815302
Validation loss: 2.5085775451558825

Epoch: 5| Step: 9
Training loss: 2.9776346673627163
Validation loss: 2.514015173355219

Epoch: 5| Step: 10
Training loss: 2.8748840640368147
Validation loss: 2.5160708884795833

Epoch: 34| Step: 0
Training loss: 3.0078546694487107
Validation loss: 2.4852988522807964

Epoch: 5| Step: 1
Training loss: 2.6096157488291003
Validation loss: 2.52068863950667

Epoch: 5| Step: 2
Training loss: 2.590984110681538
Validation loss: 2.5062748905280063

Epoch: 5| Step: 3
Training loss: 2.881058322050026
Validation loss: 2.510453357478616

Epoch: 5| Step: 4
Training loss: 3.1758644308948156
Validation loss: 2.5105839137765216

Epoch: 5| Step: 5
Training loss: 2.8725897595862664
Validation loss: 2.5200171176812773

Epoch: 5| Step: 6
Training loss: 3.173550468624108
Validation loss: 2.5008512406456505

Epoch: 5| Step: 7
Training loss: 2.826266104624037
Validation loss: 2.5046175290628545

Epoch: 5| Step: 8
Training loss: 3.1402962735592292
Validation loss: 2.520290068750931

Epoch: 5| Step: 9
Training loss: 2.615034715411093
Validation loss: 2.517991742351261

Epoch: 5| Step: 10
Training loss: 2.666576731675251
Validation loss: 2.51517022292797

Epoch: 35| Step: 0
Training loss: 2.9920705269441776
Validation loss: 2.5200004245730354

Epoch: 5| Step: 1
Training loss: 3.168038138160023
Validation loss: 2.517425243525873

Epoch: 5| Step: 2
Training loss: 2.906078374573721
Validation loss: 2.507401451690436

Epoch: 5| Step: 3
Training loss: 3.0958382080642157
Validation loss: 2.5138631153962927

Epoch: 5| Step: 4
Training loss: 3.370064694380736
Validation loss: 2.514366852840197

Epoch: 5| Step: 5
Training loss: 1.9160897865680588
Validation loss: 2.49624742441242

Epoch: 5| Step: 6
Training loss: 2.797517159335203
Validation loss: 2.515469366339606

Epoch: 5| Step: 7
Training loss: 2.721366237388501
Validation loss: 2.5401803251100614

Epoch: 5| Step: 8
Training loss: 2.8464001055352384
Validation loss: 2.5015368752119134

Epoch: 5| Step: 9
Training loss: 3.258130540577802
Validation loss: 2.4902981163519553

Epoch: 5| Step: 10
Training loss: 2.1039254330377783
Validation loss: 2.5290370764499683

Epoch: 36| Step: 0
Training loss: 2.959841402032059
Validation loss: 2.509554740581869

Epoch: 5| Step: 1
Training loss: 2.3948447689647328
Validation loss: 2.500443457168158

Epoch: 5| Step: 2
Training loss: 2.9077666232401618
Validation loss: 2.5227441582231345

Epoch: 5| Step: 3
Training loss: 2.5726768495144485
Validation loss: 2.52881088335775

Epoch: 5| Step: 4
Training loss: 3.0723314320669894
Validation loss: 2.5131851274352144

Epoch: 5| Step: 5
Training loss: 2.692583820309877
Validation loss: 2.5108229588731477

Epoch: 5| Step: 6
Training loss: 2.9893921227177107
Validation loss: 2.5136695384566012

Epoch: 5| Step: 7
Training loss: 2.9023775943307655
Validation loss: 2.516006118825208

Epoch: 5| Step: 8
Training loss: 2.7459022162156588
Validation loss: 2.5035191798083827

Epoch: 5| Step: 9
Training loss: 3.224808703522801
Validation loss: 2.5134865174339778

Epoch: 5| Step: 10
Training loss: 3.0697270968536787
Validation loss: 2.5181611034474845

Epoch: 37| Step: 0
Training loss: 2.7625747497940147
Validation loss: 2.5219886730277015

Epoch: 5| Step: 1
Training loss: 3.193410591858009
Validation loss: 2.522672198272076

Epoch: 5| Step: 2
Training loss: 2.9858530588551586
Validation loss: 2.5162790791166687

Epoch: 5| Step: 3
Training loss: 3.0102747759439787
Validation loss: 2.5060948351652317

Epoch: 5| Step: 4
Training loss: 2.897277435365068
Validation loss: 2.5142492691573093

Epoch: 5| Step: 5
Training loss: 3.028193082723168
Validation loss: 2.5192470218832024

Epoch: 5| Step: 6
Training loss: 2.4542367930558697
Validation loss: 2.5175851013386823

Epoch: 5| Step: 7
Training loss: 2.9634559408883447
Validation loss: 2.507336143170301

Epoch: 5| Step: 8
Training loss: 2.70657534152399
Validation loss: 2.5139272437573443

Epoch: 5| Step: 9
Training loss: 2.7261999375593016
Validation loss: 2.5214884174708145

Epoch: 5| Step: 10
Training loss: 2.6655204117393607
Validation loss: 2.5112136998782457

Epoch: 38| Step: 0
Training loss: 2.5095263177799367
Validation loss: 2.5162940700198084

Epoch: 5| Step: 1
Training loss: 2.628666088816558
Validation loss: 2.5160811916396204

Epoch: 5| Step: 2
Training loss: 2.9726220829487673
Validation loss: 2.520054771124695

Epoch: 5| Step: 3
Training loss: 3.0859019603372815
Validation loss: 2.5060124219181548

Epoch: 5| Step: 4
Training loss: 2.356817615248454
Validation loss: 2.5127758956015356

Epoch: 5| Step: 5
Training loss: 3.2996746307419778
Validation loss: 2.517026116289601

Epoch: 5| Step: 6
Training loss: 2.6891325494308016
Validation loss: 2.5171892747987155

Epoch: 5| Step: 7
Training loss: 3.3955743765045865
Validation loss: 2.520593344128469

Epoch: 5| Step: 8
Training loss: 2.5967263299684595
Validation loss: 2.527090220913738

Epoch: 5| Step: 9
Training loss: 2.630572444275679
Validation loss: 2.5102872121141506

Epoch: 5| Step: 10
Training loss: 3.172167684647053
Validation loss: 2.506729288164448

Epoch: 39| Step: 0
Training loss: 3.369422825590802
Validation loss: 2.5150867462871505

Epoch: 5| Step: 1
Training loss: 2.9068760351434677
Validation loss: 2.5035490194211643

Epoch: 5| Step: 2
Training loss: 2.5627182658211076
Validation loss: 2.496788377974071

Epoch: 5| Step: 3
Training loss: 2.5843305406355666
Validation loss: 2.520178822183642

Epoch: 5| Step: 4
Training loss: 3.6118518868343976
Validation loss: 2.4863408538358747

Epoch: 5| Step: 5
Training loss: 2.590510908129267
Validation loss: 2.510015896244043

Epoch: 5| Step: 6
Training loss: 2.922933621310933
Validation loss: 2.503302660953075

Epoch: 5| Step: 7
Training loss: 1.918252461692715
Validation loss: 2.4968456713784524

Epoch: 5| Step: 8
Training loss: 2.796233716362242
Validation loss: 2.5199626177176526

Epoch: 5| Step: 9
Training loss: 2.750726343813318
Validation loss: 2.511199582639168

Epoch: 5| Step: 10
Training loss: 3.130611569312392
Validation loss: 2.502188068555197

Epoch: 40| Step: 0
Training loss: 2.990814451716242
Validation loss: 2.515882125938563

Epoch: 5| Step: 1
Training loss: 2.654981781633016
Validation loss: 2.505849810408195

Epoch: 5| Step: 2
Training loss: 3.292179904633873
Validation loss: 2.4964021964001377

Epoch: 5| Step: 3
Training loss: 2.43602698396041
Validation loss: 2.513494174217018

Epoch: 5| Step: 4
Training loss: 2.542121242041914
Validation loss: 2.5067909605133023

Epoch: 5| Step: 5
Training loss: 2.821799691886217
Validation loss: 2.508120656164159

Epoch: 5| Step: 6
Training loss: 3.3584296737243213
Validation loss: 2.510580682908935

Epoch: 5| Step: 7
Training loss: 2.5357986835273234
Validation loss: 2.5131314851293873

Epoch: 5| Step: 8
Training loss: 2.9128246797655484
Validation loss: 2.4947108749908735

Epoch: 5| Step: 9
Training loss: 2.754940536743476
Validation loss: 2.5040990818470683

Epoch: 5| Step: 10
Training loss: 2.8656710322519383
Validation loss: 2.481062901123153

Epoch: 41| Step: 0
Training loss: 2.946903679264193
Validation loss: 2.5141678798097415

Epoch: 5| Step: 1
Training loss: 3.5707541428416216
Validation loss: 2.494595051167127

Epoch: 5| Step: 2
Training loss: 3.048189163455657
Validation loss: 2.520970665134947

Epoch: 5| Step: 3
Training loss: 2.2813597352272423
Validation loss: 2.519442331548419

Epoch: 5| Step: 4
Training loss: 3.0899368059924552
Validation loss: 2.4991666830373114

Epoch: 5| Step: 5
Training loss: 1.988520579744986
Validation loss: 2.505438234425728

Epoch: 5| Step: 6
Training loss: 2.947412041022257
Validation loss: 2.521645222921826

Epoch: 5| Step: 7
Training loss: 2.431609739544065
Validation loss: 2.5126762261399174

Epoch: 5| Step: 8
Training loss: 3.119230055318217
Validation loss: 2.5217132066732604

Epoch: 5| Step: 9
Training loss: 2.7177173801991397
Validation loss: 2.5093209352593155

Epoch: 5| Step: 10
Training loss: 2.788613675973365
Validation loss: 2.5077202432748886

Epoch: 42| Step: 0
Training loss: 3.383919268328219
Validation loss: 2.5033589982924993

Epoch: 5| Step: 1
Training loss: 2.8254920125918273
Validation loss: 2.5204297305959957

Epoch: 5| Step: 2
Training loss: 2.240526175347977
Validation loss: 2.4959772600730696

Epoch: 5| Step: 3
Training loss: 2.6014293373096606
Validation loss: 2.4918701307201023

Epoch: 5| Step: 4
Training loss: 1.6961177899780011
Validation loss: 2.527996753274194

Epoch: 5| Step: 5
Training loss: 3.136115333217155
Validation loss: 2.5138382831142905

Epoch: 5| Step: 6
Training loss: 2.8449456352845495
Validation loss: 2.5154064034830115

Epoch: 5| Step: 7
Training loss: 3.3749829044615494
Validation loss: 2.501429369653866

Epoch: 5| Step: 8
Training loss: 3.4863396139516576
Validation loss: 2.501635444132393

Epoch: 5| Step: 9
Training loss: 2.8365566954343735
Validation loss: 2.488041506418054

Epoch: 5| Step: 10
Training loss: 2.4015279237520413
Validation loss: 2.5182114643662805

Epoch: 43| Step: 0
Training loss: 1.9176453358505834
Validation loss: 2.5205922487349692

Epoch: 5| Step: 1
Training loss: 2.6960110408771953
Validation loss: 2.512503403655361

Epoch: 5| Step: 2
Training loss: 2.975758842049395
Validation loss: 2.515366207898423

Epoch: 5| Step: 3
Training loss: 3.318853511022219
Validation loss: 2.487951573820714

Epoch: 5| Step: 4
Training loss: 2.799641269455853
Validation loss: 2.500692119980172

Epoch: 5| Step: 5
Training loss: 2.4726265518309343
Validation loss: 2.498276538934622

Epoch: 5| Step: 6
Training loss: 2.8914660080942256
Validation loss: 2.5072771385908927

Epoch: 5| Step: 7
Training loss: 3.661958590645789
Validation loss: 2.508452382804141

Epoch: 5| Step: 8
Training loss: 2.943830284109154
Validation loss: 2.509492416964265

Epoch: 5| Step: 9
Training loss: 2.7892427786897467
Validation loss: 2.505902973280098

Epoch: 5| Step: 10
Training loss: 2.354801722479233
Validation loss: 2.514063617654019

Epoch: 44| Step: 0
Training loss: 2.66353640018122
Validation loss: 2.501466114058383

Epoch: 5| Step: 1
Training loss: 2.8286548771459317
Validation loss: 2.5028718132967165

Epoch: 5| Step: 2
Training loss: 2.5984485765910375
Validation loss: 2.496877661677455

Epoch: 5| Step: 3
Training loss: 2.6489521078040834
Validation loss: 2.5135936796767626

Epoch: 5| Step: 4
Training loss: 3.82101078321647
Validation loss: 2.50380036359568

Epoch: 5| Step: 5
Training loss: 2.409128523315393
Validation loss: 2.5127788859303766

Epoch: 5| Step: 6
Training loss: 2.8007052316817074
Validation loss: 2.5045579972615046

Epoch: 5| Step: 7
Training loss: 3.166043186714932
Validation loss: 2.5301252783455785

Epoch: 5| Step: 8
Training loss: 2.824266953010798
Validation loss: 2.5040613369287565

Epoch: 5| Step: 9
Training loss: 3.0332097276368897
Validation loss: 2.5145995609843124

Epoch: 5| Step: 10
Training loss: 2.261935156185374
Validation loss: 2.5076512228104884

Epoch: 45| Step: 0
Training loss: 2.4544341852033087
Validation loss: 2.4978133062282795

Epoch: 5| Step: 1
Training loss: 2.4959724408731248
Validation loss: 2.5011415951457194

Epoch: 5| Step: 2
Training loss: 2.9026430779151187
Validation loss: 2.522274690554419

Epoch: 5| Step: 3
Training loss: 2.8144397404370323
Validation loss: 2.5013781927450136

Epoch: 5| Step: 4
Training loss: 2.8177675721621824
Validation loss: 2.534183019792001

Epoch: 5| Step: 5
Training loss: 3.0914635734651656
Validation loss: 2.5002968171

Epoch: 5| Step: 6
Training loss: 3.380983065012435
Validation loss: 2.5172344896614205

Epoch: 5| Step: 7
Training loss: 2.599996009236721
Validation loss: 2.509468137017719

Epoch: 5| Step: 8
Training loss: 2.6777688322625735
Validation loss: 2.511965034209375

Epoch: 5| Step: 9
Training loss: 3.4997087084943974
Validation loss: 2.517020889241174

Epoch: 5| Step: 10
Training loss: 2.2427024117152565
Validation loss: 2.510523341465481

Epoch: 46| Step: 0
Training loss: 3.1585665218322307
Validation loss: 2.504918459264608

Epoch: 5| Step: 1
Training loss: 2.889937695422317
Validation loss: 2.516044022832106

Epoch: 5| Step: 2
Training loss: 3.033201710147368
Validation loss: 2.5032726709309965

Epoch: 5| Step: 3
Training loss: 2.6280318417180535
Validation loss: 2.515735148659934

Epoch: 5| Step: 4
Training loss: 2.5742466278187455
Validation loss: 2.496294177022857

Epoch: 5| Step: 5
Training loss: 2.4901923441612275
Validation loss: 2.516807066971089

Epoch: 5| Step: 6
Training loss: 3.0178657073724096
Validation loss: 2.490734811453284

Epoch: 5| Step: 7
Training loss: 2.7442003997048454
Validation loss: 2.5114453154986522

Epoch: 5| Step: 8
Training loss: 3.2148163100192098
Validation loss: 2.488934427232717

Epoch: 5| Step: 9
Training loss: 2.6588526821350276
Validation loss: 2.4951808606257053

Epoch: 5| Step: 10
Training loss: 2.666890721047916
Validation loss: 2.5044770832085184

Epoch: 47| Step: 0
Training loss: 2.8230639110793825
Validation loss: 2.491376179708485

Epoch: 5| Step: 1
Training loss: 2.492489500492369
Validation loss: 2.5275356619709837

Epoch: 5| Step: 2
Training loss: 3.7216106279262418
Validation loss: 2.510605146109779

Epoch: 5| Step: 3
Training loss: 2.928703936460038
Validation loss: 2.502835739956458

Epoch: 5| Step: 4
Training loss: 2.897803059775144
Validation loss: 2.492711992878481

Epoch: 5| Step: 5
Training loss: 3.1856119884803773
Validation loss: 2.502778523241494

Epoch: 5| Step: 6
Training loss: 2.5361207793563203
Validation loss: 2.4967074708766672

Epoch: 5| Step: 7
Training loss: 2.476330189684628
Validation loss: 2.5046151702545503

Epoch: 5| Step: 8
Training loss: 2.862132092949708
Validation loss: 2.515760601151732

Epoch: 5| Step: 9
Training loss: 2.457518415566382
Validation loss: 2.4984963201863524

Epoch: 5| Step: 10
Training loss: 2.3877915688675553
Validation loss: 2.5039182987140496

Epoch: 48| Step: 0
Training loss: 2.8410930587850793
Validation loss: 2.51032692989646

Epoch: 5| Step: 1
Training loss: 2.68243809766351
Validation loss: 2.4991136528119586

Epoch: 5| Step: 2
Training loss: 3.1432390104875547
Validation loss: 2.488582247282309

Epoch: 5| Step: 3
Training loss: 2.908426433774578
Validation loss: 2.5016569532703863

Epoch: 5| Step: 4
Training loss: 3.3204305470743303
Validation loss: 2.5161813609766384

Epoch: 5| Step: 5
Training loss: 2.6597288799506895
Validation loss: 2.5036481409079245

Epoch: 5| Step: 6
Training loss: 2.3888901542936223
Validation loss: 2.49009383704015

Epoch: 5| Step: 7
Training loss: 2.678605108503496
Validation loss: 2.4968931356067103

Epoch: 5| Step: 8
Training loss: 2.6204451143557796
Validation loss: 2.4993461738347413

Epoch: 5| Step: 9
Training loss: 2.761075518212595
Validation loss: 2.525026725725886

Epoch: 5| Step: 10
Training loss: 3.0698931458606102
Validation loss: 2.505647202619413

Epoch: 49| Step: 0
Training loss: 2.722414375408914
Validation loss: 2.522251708115376

Epoch: 5| Step: 1
Training loss: 2.494611464159639
Validation loss: 2.4925526411160592

Epoch: 5| Step: 2
Training loss: 2.8323758882433396
Validation loss: 2.505392223423845

Epoch: 5| Step: 3
Training loss: 2.7499169423825225
Validation loss: 2.506044894669184

Epoch: 5| Step: 4
Training loss: 2.969697660476755
Validation loss: 2.4868053256761824

Epoch: 5| Step: 5
Training loss: 3.1713695405255504
Validation loss: 2.500249593847417

Epoch: 5| Step: 6
Training loss: 2.231336007477444
Validation loss: 2.4864805306134627

Epoch: 5| Step: 7
Training loss: 2.688681231993289
Validation loss: 2.4896309785784183

Epoch: 5| Step: 8
Training loss: 3.108289672981286
Validation loss: 2.519786815459493

Epoch: 5| Step: 9
Training loss: 3.2850880292596956
Validation loss: 2.4947077499649906

Epoch: 5| Step: 10
Training loss: 2.7922427214128795
Validation loss: 2.4993063138623426

Epoch: 50| Step: 0
Training loss: 2.485940404059478
Validation loss: 2.5187387479054784

Epoch: 5| Step: 1
Training loss: 2.924521650015382
Validation loss: 2.5129601170884204

Epoch: 5| Step: 2
Training loss: 2.5453252465366263
Validation loss: 2.4952440369146642

Epoch: 5| Step: 3
Training loss: 3.3144207549888827
Validation loss: 2.500337143181451

Epoch: 5| Step: 4
Training loss: 2.188498677759466
Validation loss: 2.494959708410921

Epoch: 5| Step: 5
Training loss: 2.9335412479177556
Validation loss: 2.503064377630969

Epoch: 5| Step: 6
Training loss: 2.463343627798055
Validation loss: 2.496425392680659

Epoch: 5| Step: 7
Training loss: 2.7895457813412436
Validation loss: 2.510329451841826

Epoch: 5| Step: 8
Training loss: 3.12867795037506
Validation loss: 2.498495530109703

Epoch: 5| Step: 9
Training loss: 2.6152810512078126
Validation loss: 2.495776692554285

Epoch: 5| Step: 10
Training loss: 3.5169206054507325
Validation loss: 2.507476958999969

Epoch: 51| Step: 0
Training loss: 2.8074047983525183
Validation loss: 2.5187525475679284

Epoch: 5| Step: 1
Training loss: 2.6831317265122125
Validation loss: 2.5011691313022832

Epoch: 5| Step: 2
Training loss: 3.120418699975883
Validation loss: 2.4944752770368663

Epoch: 5| Step: 3
Training loss: 2.5910540438293514
Validation loss: 2.510561476316019

Epoch: 5| Step: 4
Training loss: 2.429059502499045
Validation loss: 2.5082924550025036

Epoch: 5| Step: 5
Training loss: 2.806631110805029
Validation loss: 2.494771200274178

Epoch: 5| Step: 6
Training loss: 2.5370339139386475
Validation loss: 2.5084831790797306

Epoch: 5| Step: 7
Training loss: 3.065403865572989
Validation loss: 2.478273707271416

Epoch: 5| Step: 8
Training loss: 3.239068794888435
Validation loss: 2.5004857852630007

Epoch: 5| Step: 9
Training loss: 2.5933090202773945
Validation loss: 2.494465607644714

Epoch: 5| Step: 10
Training loss: 3.0788997701379732
Validation loss: 2.486354867337537

Epoch: 52| Step: 0
Training loss: 2.3489210939239653
Validation loss: 2.4945689531459423

Epoch: 5| Step: 1
Training loss: 2.848419212830851
Validation loss: 2.5008734131037382

Epoch: 5| Step: 2
Training loss: 2.6894908894067036
Validation loss: 2.4752066892100144

Epoch: 5| Step: 3
Training loss: 3.050993185460205
Validation loss: 2.484957240266993

Epoch: 5| Step: 4
Training loss: 2.86083346833487
Validation loss: 2.4884584888912693

Epoch: 5| Step: 5
Training loss: 2.638959822342737
Validation loss: 2.5139039519840787

Epoch: 5| Step: 6
Training loss: 3.6002385484285373
Validation loss: 2.503539463410923

Epoch: 5| Step: 7
Training loss: 2.953161007293297
Validation loss: 2.484243742775675

Epoch: 5| Step: 8
Training loss: 2.605063708619111
Validation loss: 2.500757025880371

Epoch: 5| Step: 9
Training loss: 2.8052344678777366
Validation loss: 2.498172391412362

Epoch: 5| Step: 10
Training loss: 2.302152111930501
Validation loss: 2.4975568113039093

Epoch: 53| Step: 0
Training loss: 2.8294740273024597
Validation loss: 2.5087181658676108

Epoch: 5| Step: 1
Training loss: 2.6906962350947796
Validation loss: 2.5005138915013227

Epoch: 5| Step: 2
Training loss: 2.240515853372854
Validation loss: 2.512804118409929

Epoch: 5| Step: 3
Training loss: 2.8203069206034668
Validation loss: 2.496734284811757

Epoch: 5| Step: 4
Training loss: 3.5756642238077188
Validation loss: 2.4936509142230117

Epoch: 5| Step: 5
Training loss: 2.7594023274400197
Validation loss: 2.495463919847269

Epoch: 5| Step: 6
Training loss: 2.914005555115525
Validation loss: 2.4765374551908517

Epoch: 5| Step: 7
Training loss: 2.904376010291242
Validation loss: 2.5150229084399696

Epoch: 5| Step: 8
Training loss: 2.8645934133641306
Validation loss: 2.493000492612123

Epoch: 5| Step: 9
Training loss: 2.262453160933928
Validation loss: 2.4924240120946863

Epoch: 5| Step: 10
Training loss: 2.777316794821287
Validation loss: 2.5106383937060883

Epoch: 54| Step: 0
Training loss: 2.8639041904748206
Validation loss: 2.498861589984359

Epoch: 5| Step: 1
Training loss: 3.0176798880494733
Validation loss: 2.4864534277313615

Epoch: 5| Step: 2
Training loss: 2.458591857075455
Validation loss: 2.4963941246847705

Epoch: 5| Step: 3
Training loss: 1.8912979693736545
Validation loss: 2.488857891796294

Epoch: 5| Step: 4
Training loss: 2.9802122793179286
Validation loss: 2.4968656010635466

Epoch: 5| Step: 5
Training loss: 3.1378586765459353
Validation loss: 2.50493516588834

Epoch: 5| Step: 6
Training loss: 2.530151599820159
Validation loss: 2.496068127776803

Epoch: 5| Step: 7
Training loss: 2.6830141643785828
Validation loss: 2.4924459998077997

Epoch: 5| Step: 8
Training loss: 3.3918667114898815
Validation loss: 2.4854259655587874

Epoch: 5| Step: 9
Training loss: 2.7583714423951666
Validation loss: 2.500262543008103

Epoch: 5| Step: 10
Training loss: 3.0996682943261966
Validation loss: 2.4937495059716226

Epoch: 55| Step: 0
Training loss: 2.6468675849747636
Validation loss: 2.491224967856672

Epoch: 5| Step: 1
Training loss: 2.642527600219139
Validation loss: 2.4934625672608313

Epoch: 5| Step: 2
Training loss: 2.995274796146616
Validation loss: 2.4956992287857918

Epoch: 5| Step: 3
Training loss: 2.5170179029334983
Validation loss: 2.4990704223338343

Epoch: 5| Step: 4
Training loss: 2.344126149828766
Validation loss: 2.510944315258524

Epoch: 5| Step: 5
Training loss: 2.599377330165368
Validation loss: 2.516118293670402

Epoch: 5| Step: 6
Training loss: 2.6992857023511756
Validation loss: 2.4927215657137243

Epoch: 5| Step: 7
Training loss: 2.9363610514836913
Validation loss: 2.4856981368440914

Epoch: 5| Step: 8
Training loss: 2.811518349465698
Validation loss: 2.504856522814012

Epoch: 5| Step: 9
Training loss: 2.780682366556011
Validation loss: 2.5086140438319537

Epoch: 5| Step: 10
Training loss: 3.9567539611245115
Validation loss: 2.5019017871713163

Epoch: 56| Step: 0
Training loss: 2.27617593073905
Validation loss: 2.4925544996512916

Epoch: 5| Step: 1
Training loss: 2.1507277609883557
Validation loss: 2.5102311793716567

Epoch: 5| Step: 2
Training loss: 3.370974930915874
Validation loss: 2.5158817081555767

Epoch: 5| Step: 3
Training loss: 2.5399391890928316
Validation loss: 2.5035423449635017

Epoch: 5| Step: 4
Training loss: 3.0869727607318613
Validation loss: 2.5005715998545752

Epoch: 5| Step: 5
Training loss: 2.9200716216304796
Validation loss: 2.5019964952276856

Epoch: 5| Step: 6
Training loss: 3.0819339325870603
Validation loss: 2.4960941074172154

Epoch: 5| Step: 7
Training loss: 2.7304762593222027
Validation loss: 2.503830449685986

Epoch: 5| Step: 8
Training loss: 2.4512284838458225
Validation loss: 2.501675054866727

Epoch: 5| Step: 9
Training loss: 3.338182323872828
Validation loss: 2.5188691750041747

Epoch: 5| Step: 10
Training loss: 2.7056602980826336
Validation loss: 2.4848455467298383

Epoch: 57| Step: 0
Training loss: 2.775895182243951
Validation loss: 2.5049161299078273

Epoch: 5| Step: 1
Training loss: 2.9439133778972675
Validation loss: 2.5046398268309495

Epoch: 5| Step: 2
Training loss: 2.997423496113165
Validation loss: 2.4822024365744015

Epoch: 5| Step: 3
Training loss: 2.368407183879825
Validation loss: 2.490581394943571

Epoch: 5| Step: 4
Training loss: 2.7552027470917246
Validation loss: 2.494788020064492

Epoch: 5| Step: 5
Training loss: 2.648821597533572
Validation loss: 2.5181896364706207

Epoch: 5| Step: 6
Training loss: 2.6590530864097497
Validation loss: 2.499609615240399

Epoch: 5| Step: 7
Training loss: 3.036222960224887
Validation loss: 2.4891546090225014

Epoch: 5| Step: 8
Training loss: 2.673158482361281
Validation loss: 2.496921846981474

Epoch: 5| Step: 9
Training loss: 3.2969986589571927
Validation loss: 2.5004923371594816

Epoch: 5| Step: 10
Training loss: 2.6648300720776392
Validation loss: 2.4998484104097107

Epoch: 58| Step: 0
Training loss: 2.3304955619372
Validation loss: 2.4883015228494982

Epoch: 5| Step: 1
Training loss: 2.79417425428984
Validation loss: 2.4886620762763676

Epoch: 5| Step: 2
Training loss: 2.9593740074534702
Validation loss: 2.5001821338798647

Epoch: 5| Step: 3
Training loss: 3.3037973923157966
Validation loss: 2.4900736312894667

Epoch: 5| Step: 4
Training loss: 2.8021671797865486
Validation loss: 2.518127254740744

Epoch: 5| Step: 5
Training loss: 2.574383234028013
Validation loss: 2.500179619643036

Epoch: 5| Step: 6
Training loss: 2.411505866903927
Validation loss: 2.5155831987437476

Epoch: 5| Step: 7
Training loss: 2.5733541098762323
Validation loss: 2.496714144096665

Epoch: 5| Step: 8
Training loss: 3.0967714602255807
Validation loss: 2.492440163727902

Epoch: 5| Step: 9
Training loss: 2.9848766604297934
Validation loss: 2.492826942634091

Epoch: 5| Step: 10
Training loss: 2.926890592010172
Validation loss: 2.4949248893585474

Epoch: 59| Step: 0
Training loss: 2.4554981973929246
Validation loss: 2.5128125669285613

Epoch: 5| Step: 1
Training loss: 3.037083940307484
Validation loss: 2.506771726929347

Epoch: 5| Step: 2
Training loss: 2.428802819809012
Validation loss: 2.4885366045458674

Epoch: 5| Step: 3
Training loss: 2.7845044757781703
Validation loss: 2.5076378936700023

Epoch: 5| Step: 4
Training loss: 2.971516013299838
Validation loss: 2.4967331892185354

Epoch: 5| Step: 5
Training loss: 2.6309306949953846
Validation loss: 2.496402460322197

Epoch: 5| Step: 6
Training loss: 2.6644519510058253
Validation loss: 2.5119245294298596

Epoch: 5| Step: 7
Training loss: 3.1805195387606076
Validation loss: 2.5090956355974017

Epoch: 5| Step: 8
Training loss: 2.6467250813044143
Validation loss: 2.4916914450922123

Epoch: 5| Step: 9
Training loss: 3.008299156551359
Validation loss: 2.4905364908631427

Epoch: 5| Step: 10
Training loss: 2.9391972934247357
Validation loss: 2.490248375856699

Epoch: 60| Step: 0
Training loss: 2.933181022533336
Validation loss: 2.5045380269400903

Epoch: 5| Step: 1
Training loss: 3.09312740958662
Validation loss: 2.495862574558999

Epoch: 5| Step: 2
Training loss: 3.3491338720437995
Validation loss: 2.5010056544406427

Epoch: 5| Step: 3
Training loss: 2.858661833664144
Validation loss: 2.4870866405782888

Epoch: 5| Step: 4
Training loss: 2.6383817274611774
Validation loss: 2.50188522014249

Epoch: 5| Step: 5
Training loss: 2.661015264032245
Validation loss: 2.508015277852585

Epoch: 5| Step: 6
Training loss: 2.3734419882294318
Validation loss: 2.509143418805934

Epoch: 5| Step: 7
Training loss: 2.75972139251531
Validation loss: 2.5016405639573214

Epoch: 5| Step: 8
Training loss: 2.8344443517778215
Validation loss: 2.48687839665764

Epoch: 5| Step: 9
Training loss: 2.5954988397791516
Validation loss: 2.4991805523031227

Epoch: 5| Step: 10
Training loss: 2.6577593834540654
Validation loss: 2.4987385171797967

Epoch: 61| Step: 0
Training loss: 2.7446486684959446
Validation loss: 2.499120129317804

Epoch: 5| Step: 1
Training loss: 2.616702544417904
Validation loss: 2.5089975406142244

Epoch: 5| Step: 2
Training loss: 2.7772816840210286
Validation loss: 2.5030853726359164

Epoch: 5| Step: 3
Training loss: 3.3020330639852555
Validation loss: 2.493760075089915

Epoch: 5| Step: 4
Training loss: 2.6571228388429247
Validation loss: 2.492952584062608

Epoch: 5| Step: 5
Training loss: 2.3216284927804427
Validation loss: 2.4936461378183705

Epoch: 5| Step: 6
Training loss: 2.957652018002579
Validation loss: 2.4840659332840955

Epoch: 5| Step: 7
Training loss: 2.208506835263647
Validation loss: 2.5140138548316693

Epoch: 5| Step: 8
Training loss: 2.6926767924150576
Validation loss: 2.5016108440268168

Epoch: 5| Step: 9
Training loss: 3.11548983205141
Validation loss: 2.491335726073513

Epoch: 5| Step: 10
Training loss: 3.2142781424054774
Validation loss: 2.493478693660267

Epoch: 62| Step: 0
Training loss: 3.116880779425459
Validation loss: 2.505456241170082

Epoch: 5| Step: 1
Training loss: 2.3586879513033376
Validation loss: 2.4942245272064545

Epoch: 5| Step: 2
Training loss: 2.617849693220829
Validation loss: 2.4874890866068284

Epoch: 5| Step: 3
Training loss: 3.1116006064966926
Validation loss: 2.4808365573447584

Epoch: 5| Step: 4
Training loss: 2.964108502840908
Validation loss: 2.502203530135318

Epoch: 5| Step: 5
Training loss: 2.7590997301571702
Validation loss: 2.4910697949607976

Epoch: 5| Step: 6
Training loss: 2.866618502751949
Validation loss: 2.4978461262471496

Epoch: 5| Step: 7
Training loss: 3.0933318192653676
Validation loss: 2.495840572776925

Epoch: 5| Step: 8
Training loss: 2.7232974376982004
Validation loss: 2.4933882950287787

Epoch: 5| Step: 9
Training loss: 1.8562475878767275
Validation loss: 2.4886867291789816

Epoch: 5| Step: 10
Training loss: 3.030993106613954
Validation loss: 2.479305565047788

Epoch: 63| Step: 0
Training loss: 3.5749170840591464
Validation loss: 2.4990774211016915

Epoch: 5| Step: 1
Training loss: 2.6628902238887773
Validation loss: 2.491578888699107

Epoch: 5| Step: 2
Training loss: 2.813645447492117
Validation loss: 2.47147886436083

Epoch: 5| Step: 3
Training loss: 2.316756480920778
Validation loss: 2.4947476012019885

Epoch: 5| Step: 4
Training loss: 2.5600890005555237
Validation loss: 2.4965834970924545

Epoch: 5| Step: 5
Training loss: 3.0780915389202863
Validation loss: 2.495298638063456

Epoch: 5| Step: 6
Training loss: 3.0294120958503443
Validation loss: 2.4923127046135267

Epoch: 5| Step: 7
Training loss: 2.8021780704711023
Validation loss: 2.492143244129721

Epoch: 5| Step: 8
Training loss: 2.583374135915459
Validation loss: 2.4771177518839593

Epoch: 5| Step: 9
Training loss: 2.5985611565597417
Validation loss: 2.4953056006642775

Epoch: 5| Step: 10
Training loss: 2.3428489478895034
Validation loss: 2.510126595394269

Epoch: 64| Step: 0
Training loss: 2.401787422086379
Validation loss: 2.4852821374408434

Epoch: 5| Step: 1
Training loss: 2.8137087449752674
Validation loss: 2.475367841154362

Epoch: 5| Step: 2
Training loss: 2.591485103204457
Validation loss: 2.484608955019308

Epoch: 5| Step: 3
Training loss: 3.1543171318041505
Validation loss: 2.485715797728025

Epoch: 5| Step: 4
Training loss: 3.0253264763312924
Validation loss: 2.4802531192489443

Epoch: 5| Step: 5
Training loss: 3.0013928358985766
Validation loss: 2.4966186020934797

Epoch: 5| Step: 6
Training loss: 2.626442830606417
Validation loss: 2.495451869351559

Epoch: 5| Step: 7
Training loss: 2.724751217886018
Validation loss: 2.5101484944263035

Epoch: 5| Step: 8
Training loss: 2.5001210183416642
Validation loss: 2.4960799010705577

Epoch: 5| Step: 9
Training loss: 2.9938306952891747
Validation loss: 2.483904144293008

Epoch: 5| Step: 10
Training loss: 2.67176649085219
Validation loss: 2.496918016284666

Epoch: 65| Step: 0
Training loss: 3.5679536535563043
Validation loss: 2.489142271529616

Epoch: 5| Step: 1
Training loss: 2.200902372310368
Validation loss: 2.491027471016753

Epoch: 5| Step: 2
Training loss: 2.4219995282060083
Validation loss: 2.4807406182742917

Epoch: 5| Step: 3
Training loss: 2.38197687223979
Validation loss: 2.502491505735385

Epoch: 5| Step: 4
Training loss: 3.219112338809867
Validation loss: 2.473653135963566

Epoch: 5| Step: 5
Training loss: 3.0382201294797224
Validation loss: 2.4985117389438867

Epoch: 5| Step: 6
Training loss: 2.6072078088332664
Validation loss: 2.5036709833487105

Epoch: 5| Step: 7
Training loss: 2.719712799420966
Validation loss: 2.477865895572119

Epoch: 5| Step: 8
Training loss: 2.966658327183807
Validation loss: 2.495862412268319

Epoch: 5| Step: 9
Training loss: 2.6066593498198833
Validation loss: 2.4988237228639094

Epoch: 5| Step: 10
Training loss: 2.616088454229712
Validation loss: 2.4844905253445777

Epoch: 66| Step: 0
Training loss: 2.8702941196208243
Validation loss: 2.4846792924090586

Epoch: 5| Step: 1
Training loss: 2.5585522830311014
Validation loss: 2.47995865117679

Epoch: 5| Step: 2
Training loss: 2.9236588362188543
Validation loss: 2.4789520926377095

Epoch: 5| Step: 3
Training loss: 2.7721331040764094
Validation loss: 2.4987513710614135

Epoch: 5| Step: 4
Training loss: 2.5121911347741714
Validation loss: 2.494359059427024

Epoch: 5| Step: 5
Training loss: 2.3199739048575463
Validation loss: 2.485162679383831

Epoch: 5| Step: 6
Training loss: 2.9679753949361323
Validation loss: 2.4884199699840814

Epoch: 5| Step: 7
Training loss: 2.6093499645014373
Validation loss: 2.47314268559812

Epoch: 5| Step: 8
Training loss: 3.1939288363617564
Validation loss: 2.4823106679342803

Epoch: 5| Step: 9
Training loss: 2.916342490209721
Validation loss: 2.4838610856866845

Epoch: 5| Step: 10
Training loss: 2.775896642354838
Validation loss: 2.4838387329813

Epoch: 67| Step: 0
Training loss: 2.381338895805472
Validation loss: 2.4917195280946065

Epoch: 5| Step: 1
Training loss: 2.672338077503682
Validation loss: 2.4944125771684225

Epoch: 5| Step: 2
Training loss: 2.6945210497301675
Validation loss: 2.482733051504909

Epoch: 5| Step: 3
Training loss: 2.371015519135204
Validation loss: 2.483691124937009

Epoch: 5| Step: 4
Training loss: 2.19062908351806
Validation loss: 2.4665501249259556

Epoch: 5| Step: 5
Training loss: 2.550017121201426
Validation loss: 2.4868253909782414

Epoch: 5| Step: 6
Training loss: 3.124555785078087
Validation loss: 2.4880541718781775

Epoch: 5| Step: 7
Training loss: 2.8148592060987156
Validation loss: 2.4936763649239664

Epoch: 5| Step: 8
Training loss: 4.014344482495929
Validation loss: 2.491926659654938

Epoch: 5| Step: 9
Training loss: 2.399085836352924
Validation loss: 2.4965860673206146

Epoch: 5| Step: 10
Training loss: 2.8684127642642103
Validation loss: 2.4886012948882286

Epoch: 68| Step: 0
Training loss: 2.5874545438892476
Validation loss: 2.5056702647152074

Epoch: 5| Step: 1
Training loss: 2.713543170091404
Validation loss: 2.466118114369497

Epoch: 5| Step: 2
Training loss: 3.0903469597053115
Validation loss: 2.490759134033024

Epoch: 5| Step: 3
Training loss: 2.732182435675994
Validation loss: 2.490502796831004

Epoch: 5| Step: 4
Training loss: 3.1474695729306763
Validation loss: 2.484691763494036

Epoch: 5| Step: 5
Training loss: 2.0631334892498137
Validation loss: 2.498513604333135

Epoch: 5| Step: 6
Training loss: 2.8447617627842776
Validation loss: 2.493030799528539

Epoch: 5| Step: 7
Training loss: 2.8073649682906474
Validation loss: 2.5025595718765388

Epoch: 5| Step: 8
Training loss: 3.037464653406014
Validation loss: 2.487730873348392

Epoch: 5| Step: 9
Training loss: 2.651469158087467
Validation loss: 2.4984176683694743

Epoch: 5| Step: 10
Training loss: 2.950821558460126
Validation loss: 2.485336177626889

Epoch: 69| Step: 0
Training loss: 2.4301232440919187
Validation loss: 2.4970215046365185

Epoch: 5| Step: 1
Training loss: 3.0164102905530923
Validation loss: 2.4698200785770474

Epoch: 5| Step: 2
Training loss: 2.531438844017804
Validation loss: 2.4783710565671115

Epoch: 5| Step: 3
Training loss: 2.6793387049785427
Validation loss: 2.4723748547536397

Epoch: 5| Step: 4
Training loss: 2.070905032026424
Validation loss: 2.484171385317474

Epoch: 5| Step: 5
Training loss: 2.63623168967894
Validation loss: 2.4842937711857815

Epoch: 5| Step: 6
Training loss: 3.729235955701041
Validation loss: 2.496657214252056

Epoch: 5| Step: 7
Training loss: 2.5114661485721013
Validation loss: 2.501141945691661

Epoch: 5| Step: 8
Training loss: 3.0227084599272587
Validation loss: 2.488328601481078

Epoch: 5| Step: 9
Training loss: 2.8627992565197236
Validation loss: 2.4758789603624436

Epoch: 5| Step: 10
Training loss: 2.6665216545571897
Validation loss: 2.4791518062960685

Epoch: 70| Step: 0
Training loss: 2.5118522074648415
Validation loss: 2.4873553670528965

Epoch: 5| Step: 1
Training loss: 2.8588012786789787
Validation loss: 2.4907023449525427

Epoch: 5| Step: 2
Training loss: 2.868729761255883
Validation loss: 2.489559742064104

Epoch: 5| Step: 3
Training loss: 2.3994895789652824
Validation loss: 2.5026667625506596

Epoch: 5| Step: 4
Training loss: 2.7581661527127874
Validation loss: 2.470061663897929

Epoch: 5| Step: 5
Training loss: 2.828077115659886
Validation loss: 2.510295243242067

Epoch: 5| Step: 6
Training loss: 3.020450032788778
Validation loss: 2.4950930728264384

Epoch: 5| Step: 7
Training loss: 2.319243008006705
Validation loss: 2.494782279892201

Epoch: 5| Step: 8
Training loss: 2.625069208595185
Validation loss: 2.4990940205926964

Epoch: 5| Step: 9
Training loss: 3.0359275358294733
Validation loss: 2.474640633104908

Epoch: 5| Step: 10
Training loss: 3.276953509152588
Validation loss: 2.466684236508259

Epoch: 71| Step: 0
Training loss: 2.9401043648912597
Validation loss: 2.4811789557455777

Epoch: 5| Step: 1
Training loss: 2.989706818869196
Validation loss: 2.477133106040848

Epoch: 5| Step: 2
Training loss: 1.8116924854791248
Validation loss: 2.4919567440437698

Epoch: 5| Step: 3
Training loss: 2.5952509937657458
Validation loss: 2.4748216377691383

Epoch: 5| Step: 4
Training loss: 2.278408632557299
Validation loss: 2.5136047762787204

Epoch: 5| Step: 5
Training loss: 2.8448512701166773
Validation loss: 2.4988461220890406

Epoch: 5| Step: 6
Training loss: 2.847531665227387
Validation loss: 2.488648320938374

Epoch: 5| Step: 7
Training loss: 2.940372766750211
Validation loss: 2.4841306141443056

Epoch: 5| Step: 8
Training loss: 3.033602087111097
Validation loss: 2.4971750685715204

Epoch: 5| Step: 9
Training loss: 3.1610587473463387
Validation loss: 2.4846026176434273

Epoch: 5| Step: 10
Training loss: 2.7892472235363304
Validation loss: 2.484264666196318

Epoch: 72| Step: 0
Training loss: 2.4247563111867834
Validation loss: 2.4820163876787738

Epoch: 5| Step: 1
Training loss: 2.6176286467933965
Validation loss: 2.4988491547356104

Epoch: 5| Step: 2
Training loss: 2.836047293899533
Validation loss: 2.501760659583162

Epoch: 5| Step: 3
Training loss: 3.1313879717431434
Validation loss: 2.50716549867565

Epoch: 5| Step: 4
Training loss: 2.8206753906779873
Validation loss: 2.4885866481266543

Epoch: 5| Step: 5
Training loss: 2.1741493447041287
Validation loss: 2.5006506801165553

Epoch: 5| Step: 6
Training loss: 2.3079735040515637
Validation loss: 2.489162158355634

Epoch: 5| Step: 7
Training loss: 3.1842178201114835
Validation loss: 2.491946046910842

Epoch: 5| Step: 8
Training loss: 2.7891987572305466
Validation loss: 2.489117832216534

Epoch: 5| Step: 9
Training loss: 3.2750554786234574
Validation loss: 2.494794088026748

Epoch: 5| Step: 10
Training loss: 2.760180874716569
Validation loss: 2.49487368948748

Epoch: 73| Step: 0
Training loss: 2.8016925430540094
Validation loss: 2.48653589950073

Epoch: 5| Step: 1
Training loss: 2.3209485553330746
Validation loss: 2.496187121453689

Epoch: 5| Step: 2
Training loss: 2.3664172842600326
Validation loss: 2.511545170077484

Epoch: 5| Step: 3
Training loss: 3.054404477327881
Validation loss: 2.485905731964064

Epoch: 5| Step: 4
Training loss: 3.404696749096475
Validation loss: 2.4801966147033903

Epoch: 5| Step: 5
Training loss: 2.7567510966787165
Validation loss: 2.4890842878927626

Epoch: 5| Step: 6
Training loss: 2.5090883996320197
Validation loss: 2.485819728724807

Epoch: 5| Step: 7
Training loss: 2.7416395199561254
Validation loss: 2.475181175993073

Epoch: 5| Step: 8
Training loss: 3.193034136247099
Validation loss: 2.475891743954082

Epoch: 5| Step: 9
Training loss: 2.3044812126296
Validation loss: 2.483732803379081

Epoch: 5| Step: 10
Training loss: 2.8097890716342384
Validation loss: 2.4773349822048036

Epoch: 74| Step: 0
Training loss: 3.1999883413102435
Validation loss: 2.4753945682999645

Epoch: 5| Step: 1
Training loss: 3.06611420036385
Validation loss: 2.4839707356067757

Epoch: 5| Step: 2
Training loss: 3.512272707281213
Validation loss: 2.4724360723741756

Epoch: 5| Step: 3
Training loss: 2.7154251464068246
Validation loss: 2.4871603866822767

Epoch: 5| Step: 4
Training loss: 2.606897148453453
Validation loss: 2.4864488210265496

Epoch: 5| Step: 5
Training loss: 2.244691095658643
Validation loss: 2.479138952134636

Epoch: 5| Step: 6
Training loss: 2.7292220034825334
Validation loss: 2.480990080453637

Epoch: 5| Step: 7
Training loss: 3.0125120233952716
Validation loss: 2.4851981009615436

Epoch: 5| Step: 8
Training loss: 2.352440958285508
Validation loss: 2.4760531132617802

Epoch: 5| Step: 9
Training loss: 2.508655632156297
Validation loss: 2.4828263430555166

Epoch: 5| Step: 10
Training loss: 2.0780358546360733
Validation loss: 2.4791174870203787

Epoch: 75| Step: 0
Training loss: 2.648956428034121
Validation loss: 2.4667513908947734

Epoch: 5| Step: 1
Training loss: 2.635658333494998
Validation loss: 2.4875700121796203

Epoch: 5| Step: 2
Training loss: 2.870513234519782
Validation loss: 2.482902789764668

Epoch: 5| Step: 3
Training loss: 2.878432670989276
Validation loss: 2.4839891921105126

Epoch: 5| Step: 4
Training loss: 2.9361436025441163
Validation loss: 2.4919347057187995

Epoch: 5| Step: 5
Training loss: 2.8498056512788787
Validation loss: 2.4848164069345025

Epoch: 5| Step: 6
Training loss: 2.8431449497987975
Validation loss: 2.4825886491512557

Epoch: 5| Step: 7
Training loss: 2.5055950498134973
Validation loss: 2.4910728977930496

Epoch: 5| Step: 8
Training loss: 2.7555909975739588
Validation loss: 2.4934203677275297

Epoch: 5| Step: 9
Training loss: 2.829517674945175
Validation loss: 2.5050554351439915

Epoch: 5| Step: 10
Training loss: 2.738996077764181
Validation loss: 2.5038410294929068

Epoch: 76| Step: 0
Training loss: 2.952419620618136
Validation loss: 2.4873721699965627

Epoch: 5| Step: 1
Training loss: 2.380527388698972
Validation loss: 2.49360307265838

Epoch: 5| Step: 2
Training loss: 2.562775945924893
Validation loss: 2.502951604432951

Epoch: 5| Step: 3
Training loss: 3.274389160498435
Validation loss: 2.4933248681348115

Epoch: 5| Step: 4
Training loss: 3.0633128119090216
Validation loss: 2.4916435412107045

Epoch: 5| Step: 5
Training loss: 3.000006039931257
Validation loss: 2.4703306322727663

Epoch: 5| Step: 6
Training loss: 2.575789347280977
Validation loss: 2.4794785446535257

Epoch: 5| Step: 7
Training loss: 2.399757444522572
Validation loss: 2.511083838397339

Epoch: 5| Step: 8
Training loss: 2.4614909200708146
Validation loss: 2.503826518978886

Epoch: 5| Step: 9
Training loss: 2.8299308617439713
Validation loss: 2.488246925794548

Epoch: 5| Step: 10
Training loss: 2.6469269442274737
Validation loss: 2.482697387720529

Epoch: 77| Step: 0
Training loss: 2.9590099975685193
Validation loss: 2.4794277775097138

Epoch: 5| Step: 1
Training loss: 2.3891007294973594
Validation loss: 2.4909542845204395

Epoch: 5| Step: 2
Training loss: 2.538379377756107
Validation loss: 2.4838932844996475

Epoch: 5| Step: 3
Training loss: 2.931331407274671
Validation loss: 2.5045476190605265

Epoch: 5| Step: 4
Training loss: 2.7461368128735923
Validation loss: 2.4784214615998295

Epoch: 5| Step: 5
Training loss: 2.636116648557542
Validation loss: 2.4721700411956133

Epoch: 5| Step: 6
Training loss: 2.768786417633355
Validation loss: 2.4981739471408644

Epoch: 5| Step: 7
Training loss: 3.050345767073965
Validation loss: 2.4766361713046

Epoch: 5| Step: 8
Training loss: 2.666160585144411
Validation loss: 2.4917023624677332

Epoch: 5| Step: 9
Training loss: 3.245897197625598
Validation loss: 2.5041725967042443

Epoch: 5| Step: 10
Training loss: 2.1770385177842537
Validation loss: 2.503966494526229

Epoch: 78| Step: 0
Training loss: 2.940840424806284
Validation loss: 2.4861178655168477

Epoch: 5| Step: 1
Training loss: 2.8976842513265213
Validation loss: 2.490084817261075

Epoch: 5| Step: 2
Training loss: 2.5229075911778946
Validation loss: 2.495543614998275

Epoch: 5| Step: 3
Training loss: 2.3569884703802892
Validation loss: 2.4755237916923845

Epoch: 5| Step: 4
Training loss: 2.8583138586628345
Validation loss: 2.473176798578465

Epoch: 5| Step: 5
Training loss: 2.167617356974266
Validation loss: 2.4826085915726956

Epoch: 5| Step: 6
Training loss: 3.3291370840910726
Validation loss: 2.4877375551899585

Epoch: 5| Step: 7
Training loss: 2.746453512618165
Validation loss: 2.4957492355741255

Epoch: 5| Step: 8
Training loss: 2.171057567864606
Validation loss: 2.485938283796504

Epoch: 5| Step: 9
Training loss: 3.066739476072123
Validation loss: 2.4816288350213878

Epoch: 5| Step: 10
Training loss: 3.0718847233879365
Validation loss: 2.4773556198951456

Epoch: 79| Step: 0
Training loss: 3.172219995236956
Validation loss: 2.493352618113551

Epoch: 5| Step: 1
Training loss: 3.059298963839017
Validation loss: 2.4757267936912584

Epoch: 5| Step: 2
Training loss: 2.296577693874933
Validation loss: 2.4984754856789246

Epoch: 5| Step: 3
Training loss: 3.2877867482959577
Validation loss: 2.479837240223183

Epoch: 5| Step: 4
Training loss: 2.3675567036880496
Validation loss: 2.475822021530547

Epoch: 5| Step: 5
Training loss: 2.627494172036253
Validation loss: 2.4704226550151027

Epoch: 5| Step: 6
Training loss: 2.7201730796498875
Validation loss: 2.469499754800645

Epoch: 5| Step: 7
Training loss: 1.9953720669379826
Validation loss: 2.4833753817491093

Epoch: 5| Step: 8
Training loss: 3.12670516222889
Validation loss: 2.4747043650988845

Epoch: 5| Step: 9
Training loss: 2.1967119528116306
Validation loss: 2.480488711531869

Epoch: 5| Step: 10
Training loss: 3.1216258334292895
Validation loss: 2.4909232041160227

Epoch: 80| Step: 0
Training loss: 2.8825486638774342
Validation loss: 2.481792806277961

Epoch: 5| Step: 1
Training loss: 3.284633381676921
Validation loss: 2.4904755122879014

Epoch: 5| Step: 2
Training loss: 2.6283449024275605
Validation loss: 2.473104123027762

Epoch: 5| Step: 3
Training loss: 3.1382580088447356
Validation loss: 2.5073502243934302

Epoch: 5| Step: 4
Training loss: 2.4114331984943687
Validation loss: 2.468248474469209

Epoch: 5| Step: 5
Training loss: 2.7752351334763588
Validation loss: 2.467665446923964

Epoch: 5| Step: 6
Training loss: 2.5115223477049216
Validation loss: 2.4863073813431447

Epoch: 5| Step: 7
Training loss: 2.8216081427603488
Validation loss: 2.49811858682848

Epoch: 5| Step: 8
Training loss: 2.8327501108123916
Validation loss: 2.4857571091024284

Epoch: 5| Step: 9
Training loss: 2.6272142245069046
Validation loss: 2.465501659934008

Epoch: 5| Step: 10
Training loss: 2.16999461054682
Validation loss: 2.464082980803181

Epoch: 81| Step: 0
Training loss: 2.6443314582487543
Validation loss: 2.479889904227105

Epoch: 5| Step: 1
Training loss: 2.7310661131805265
Validation loss: 2.48428984155742

Epoch: 5| Step: 2
Training loss: 2.8208489158872383
Validation loss: 2.4805747487121366

Epoch: 5| Step: 3
Training loss: 2.8381216502553146
Validation loss: 2.494432699982033

Epoch: 5| Step: 4
Training loss: 3.144494249588216
Validation loss: 2.4783250550934954

Epoch: 5| Step: 5
Training loss: 2.1384404305417504
Validation loss: 2.490988340887061

Epoch: 5| Step: 6
Training loss: 2.409735100302851
Validation loss: 2.4777664038292873

Epoch: 5| Step: 7
Training loss: 3.044194220804496
Validation loss: 2.4870137437374153

Epoch: 5| Step: 8
Training loss: 2.691535492605082
Validation loss: 2.4867522906044415

Epoch: 5| Step: 9
Training loss: 2.6983546683316444
Validation loss: 2.4965665805507236

Epoch: 5| Step: 10
Training loss: 3.0592511129574422
Validation loss: 2.481321578355793

Epoch: 82| Step: 0
Training loss: 2.2647356063430855
Validation loss: 2.4736947700419476

Epoch: 5| Step: 1
Training loss: 2.5623463840495506
Validation loss: 2.4820949126477614

Epoch: 5| Step: 2
Training loss: 2.7324960410882553
Validation loss: 2.4837175457586875

Epoch: 5| Step: 3
Training loss: 3.0466635606222647
Validation loss: 2.4841343489754903

Epoch: 5| Step: 4
Training loss: 3.3450923613839074
Validation loss: 2.4905074670633254

Epoch: 5| Step: 5
Training loss: 2.292139790564381
Validation loss: 2.469437950505592

Epoch: 5| Step: 6
Training loss: 2.6249002710198903
Validation loss: 2.4650658256732245

Epoch: 5| Step: 7
Training loss: 2.8899396754110023
Validation loss: 2.5013988191089265

Epoch: 5| Step: 8
Training loss: 3.406237680955361
Validation loss: 2.50790464599779

Epoch: 5| Step: 9
Training loss: 2.393037264618651
Validation loss: 2.4838666838947394

Epoch: 5| Step: 10
Training loss: 2.5319809976621017
Validation loss: 2.4609946832037366

Epoch: 83| Step: 0
Training loss: 2.8382910008240674
Validation loss: 2.480093394921449

Epoch: 5| Step: 1
Training loss: 2.6918748245611193
Validation loss: 2.4857978288468443

Epoch: 5| Step: 2
Training loss: 2.8120990043456326
Validation loss: 2.4696850597916913

Epoch: 5| Step: 3
Training loss: 2.608799671089552
Validation loss: 2.472156752003326

Epoch: 5| Step: 4
Training loss: 2.7645496066426247
Validation loss: 2.479052973189735

Epoch: 5| Step: 5
Training loss: 2.7082923494808213
Validation loss: 2.4734512588354303

Epoch: 5| Step: 6
Training loss: 3.0268288057509514
Validation loss: 2.494323417980465

Epoch: 5| Step: 7
Training loss: 2.209527958130426
Validation loss: 2.4892685726789314

Epoch: 5| Step: 8
Training loss: 3.230740186365105
Validation loss: 2.4728877635320385

Epoch: 5| Step: 9
Training loss: 2.5420872908280416
Validation loss: 2.489425607501524

Epoch: 5| Step: 10
Training loss: 2.6596517882774986
Validation loss: 2.488863503486091

Epoch: 84| Step: 0
Training loss: 2.8664930786389933
Validation loss: 2.4823452864523454

Epoch: 5| Step: 1
Training loss: 2.6812364199990273
Validation loss: 2.484527373741019

Epoch: 5| Step: 2
Training loss: 2.47782812661343
Validation loss: 2.4773658181187104

Epoch: 5| Step: 3
Training loss: 2.6009969010560123
Validation loss: 2.4943088788209233

Epoch: 5| Step: 4
Training loss: 2.78891503721579
Validation loss: 2.49630066751901

Epoch: 5| Step: 5
Training loss: 3.0284812316161815
Validation loss: 2.489718496640614

Epoch: 5| Step: 6
Training loss: 2.4024240371809986
Validation loss: 2.4701011328028697

Epoch: 5| Step: 7
Training loss: 3.089980632387963
Validation loss: 2.4781942041563982

Epoch: 5| Step: 8
Training loss: 2.9776148099888675
Validation loss: 2.4873422311389017

Epoch: 5| Step: 9
Training loss: 2.3817682698464933
Validation loss: 2.4850381729806608

Epoch: 5| Step: 10
Training loss: 2.9019039020992827
Validation loss: 2.46934279934701

Epoch: 85| Step: 0
Training loss: 2.0661540174951214
Validation loss: 2.5055250171882193

Epoch: 5| Step: 1
Training loss: 2.96776186911615
Validation loss: 2.4990444849190165

Epoch: 5| Step: 2
Training loss: 2.9288571414407123
Validation loss: 2.502524727439418

Epoch: 5| Step: 3
Training loss: 3.0368121526087077
Validation loss: 2.4915700687630724

Epoch: 5| Step: 4
Training loss: 3.222870938634864
Validation loss: 2.5095120490503677

Epoch: 5| Step: 5
Training loss: 2.896720274709754
Validation loss: 2.48219825576067

Epoch: 5| Step: 6
Training loss: 2.5950808500362945
Validation loss: 2.4849120375028293

Epoch: 5| Step: 7
Training loss: 2.405322701262908
Validation loss: 2.494287813025586

Epoch: 5| Step: 8
Training loss: 2.941021208872455
Validation loss: 2.4956718567274843

Epoch: 5| Step: 9
Training loss: 2.117011031225238
Validation loss: 2.5218308388061015

Epoch: 5| Step: 10
Training loss: 2.8225518210209413
Validation loss: 2.506039700980507

Epoch: 86| Step: 0
Training loss: 2.606887636924594
Validation loss: 2.48358243090872

Epoch: 5| Step: 1
Training loss: 2.9846053908329755
Validation loss: 2.509725282891561

Epoch: 5| Step: 2
Training loss: 2.1117827061075536
Validation loss: 2.488043726896728

Epoch: 5| Step: 3
Training loss: 2.672262063349567
Validation loss: 2.5110317602218175

Epoch: 5| Step: 4
Training loss: 3.0156115595859
Validation loss: 2.478570135424738

Epoch: 5| Step: 5
Training loss: 2.8357335377218447
Validation loss: 2.4866882583587784

Epoch: 5| Step: 6
Training loss: 3.0573314726976784
Validation loss: 2.484408080611554

Epoch: 5| Step: 7
Training loss: 2.4884022633875684
Validation loss: 2.4672783145944557

Epoch: 5| Step: 8
Training loss: 2.489672692476186
Validation loss: 2.4824748445834186

Epoch: 5| Step: 9
Training loss: 3.151233576875931
Validation loss: 2.4860263505317817

Epoch: 5| Step: 10
Training loss: 2.4750859524993314
Validation loss: 2.4788487186472015

Epoch: 87| Step: 0
Training loss: 2.855230110101184
Validation loss: 2.47242381735812

Epoch: 5| Step: 1
Training loss: 2.5544256140256527
Validation loss: 2.479364360545776

Epoch: 5| Step: 2
Training loss: 2.545507707598018
Validation loss: 2.4607481066331154

Epoch: 5| Step: 3
Training loss: 2.425720214075877
Validation loss: 2.4678631704897

Epoch: 5| Step: 4
Training loss: 2.5577681978615066
Validation loss: 2.4829869643288083

Epoch: 5| Step: 5
Training loss: 2.7745669362086396
Validation loss: 2.493197353480052

Epoch: 5| Step: 6
Training loss: 2.7154673786314616
Validation loss: 2.4813948924385967

Epoch: 5| Step: 7
Training loss: 2.669209360794947
Validation loss: 2.4549349332592323

Epoch: 5| Step: 8
Training loss: 2.998974306877361
Validation loss: 2.4846244940067055

Epoch: 5| Step: 9
Training loss: 2.708012038515455
Validation loss: 2.477814550133198

Epoch: 5| Step: 10
Training loss: 3.3033329056458207
Validation loss: 2.4861392758618885

Epoch: 88| Step: 0
Training loss: 2.710152724069395
Validation loss: 2.4832926078370114

Epoch: 5| Step: 1
Training loss: 2.4832752600755854
Validation loss: 2.472517541438496

Epoch: 5| Step: 2
Training loss: 2.8452680958231995
Validation loss: 2.486719431900287

Epoch: 5| Step: 3
Training loss: 2.816232366392396
Validation loss: 2.4797558007369047

Epoch: 5| Step: 4
Training loss: 3.3165304747052207
Validation loss: 2.4717414616713693

Epoch: 5| Step: 5
Training loss: 2.6666730244878636
Validation loss: 2.4835764119393176

Epoch: 5| Step: 6
Training loss: 2.7144488809058056
Validation loss: 2.471320635726976

Epoch: 5| Step: 7
Training loss: 2.265557965569459
Validation loss: 2.479048462350012

Epoch: 5| Step: 8
Training loss: 2.492617005076508
Validation loss: 2.490161882246546

Epoch: 5| Step: 9
Training loss: 3.267318359556551
Validation loss: 2.4852146477071333

Epoch: 5| Step: 10
Training loss: 2.366642955428428
Validation loss: 2.4910743498966337

Epoch: 89| Step: 0
Training loss: 2.7062523892504426
Validation loss: 2.4816091119988224

Epoch: 5| Step: 1
Training loss: 2.6751480132892405
Validation loss: 2.4878217650534005

Epoch: 5| Step: 2
Training loss: 2.817301402907438
Validation loss: 2.4731994663620767

Epoch: 5| Step: 3
Training loss: 2.475910955457948
Validation loss: 2.49549347362142

Epoch: 5| Step: 4
Training loss: 2.5026380924991107
Validation loss: 2.478047698934653

Epoch: 5| Step: 5
Training loss: 2.755330295182953
Validation loss: 2.5052613034516584

Epoch: 5| Step: 6
Training loss: 2.5107814054271276
Validation loss: 2.4788911920964565

Epoch: 5| Step: 7
Training loss: 2.478108401922415
Validation loss: 2.4952112746244595

Epoch: 5| Step: 8
Training loss: 2.7529005879315167
Validation loss: 2.467823358818869

Epoch: 5| Step: 9
Training loss: 3.2550505495614344
Validation loss: 2.467232871056494

Epoch: 5| Step: 10
Training loss: 2.9721180332100743
Validation loss: 2.49573737340785

Epoch: 90| Step: 0
Training loss: 2.6869233865722406
Validation loss: 2.4763640972577066

Epoch: 5| Step: 1
Training loss: 2.8800831515176366
Validation loss: 2.4992279029486792

Epoch: 5| Step: 2
Training loss: 2.8239629479265846
Validation loss: 2.4892335916284263

Epoch: 5| Step: 3
Training loss: 2.855272696009805
Validation loss: 2.506294893551049

Epoch: 5| Step: 4
Training loss: 2.353453829258742
Validation loss: 2.492564702542766

Epoch: 5| Step: 5
Training loss: 2.36393458895868
Validation loss: 2.4942417762022493

Epoch: 5| Step: 6
Training loss: 2.7699650907554605
Validation loss: 2.4845426274200797

Epoch: 5| Step: 7
Training loss: 2.783492138228801
Validation loss: 2.48256587295865

Epoch: 5| Step: 8
Training loss: 2.6981255488497857
Validation loss: 2.4790577156639118

Epoch: 5| Step: 9
Training loss: 2.982691424766561
Validation loss: 2.4746444187764522

Epoch: 5| Step: 10
Training loss: 2.851663331639807
Validation loss: 2.4859146049974936

Epoch: 91| Step: 0
Training loss: 2.4414098632785763
Validation loss: 2.489988729516738

Epoch: 5| Step: 1
Training loss: 2.7812501714470628
Validation loss: 2.5034714438804184

Epoch: 5| Step: 2
Training loss: 2.917131786498897
Validation loss: 2.498303563835009

Epoch: 5| Step: 3
Training loss: 2.5187591552567987
Validation loss: 2.5041508967446466

Epoch: 5| Step: 4
Training loss: 2.3938005088477334
Validation loss: 2.4799423086751418

Epoch: 5| Step: 5
Training loss: 2.248977110729716
Validation loss: 2.4811452007657415

Epoch: 5| Step: 6
Training loss: 2.6481494127975482
Validation loss: 2.493115381764665

Epoch: 5| Step: 7
Training loss: 2.7646908664176233
Validation loss: 2.486794544529944

Epoch: 5| Step: 8
Training loss: 2.4153236625611854
Validation loss: 2.476635135139158

Epoch: 5| Step: 9
Training loss: 3.2011477438649654
Validation loss: 2.490151209832922

Epoch: 5| Step: 10
Training loss: 3.6172946724555755
Validation loss: 2.4890776694039047

Epoch: 92| Step: 0
Training loss: 2.738680517933606
Validation loss: 2.48750009817584

Epoch: 5| Step: 1
Training loss: 2.9168514374835084
Validation loss: 2.4938483796025688

Epoch: 5| Step: 2
Training loss: 2.741506725697509
Validation loss: 2.4883227964398946

Epoch: 5| Step: 3
Training loss: 2.6592503376127006
Validation loss: 2.509144802213689

Epoch: 5| Step: 4
Training loss: 3.0250164315273964
Validation loss: 2.4662872643625806

Epoch: 5| Step: 5
Training loss: 3.2349238275583834
Validation loss: 2.4788959617689916

Epoch: 5| Step: 6
Training loss: 2.0820899940777586
Validation loss: 2.485953881505916

Epoch: 5| Step: 7
Training loss: 3.201120931279355
Validation loss: 2.4644144726867845

Epoch: 5| Step: 8
Training loss: 1.873746452913496
Validation loss: 2.4642837559394932

Epoch: 5| Step: 9
Training loss: 2.5685392715633117
Validation loss: 2.483179074016759

Epoch: 5| Step: 10
Training loss: 2.4562221341093364
Validation loss: 2.5022132059970374

Epoch: 93| Step: 0
Training loss: 2.427471659187486
Validation loss: 2.480984775416266

Epoch: 5| Step: 1
Training loss: 3.1026572498243654
Validation loss: 2.4765450595479575

Epoch: 5| Step: 2
Training loss: 2.8443557597117093
Validation loss: 2.4720987121871687

Epoch: 5| Step: 3
Training loss: 3.0067333316672413
Validation loss: 2.484191587476356

Epoch: 5| Step: 4
Training loss: 2.165529160353663
Validation loss: 2.4795968487441735

Epoch: 5| Step: 5
Training loss: 2.8033707697028443
Validation loss: 2.4873172814720124

Epoch: 5| Step: 6
Training loss: 2.0285679643513133
Validation loss: 2.4960750245529337

Epoch: 5| Step: 7
Training loss: 2.7254276045129884
Validation loss: 2.4899911078435832

Epoch: 5| Step: 8
Training loss: 2.60643762878223
Validation loss: 2.4939940697135454

Epoch: 5| Step: 9
Training loss: 2.72011698415173
Validation loss: 2.4910084527688525

Epoch: 5| Step: 10
Training loss: 3.4442152148711753
Validation loss: 2.480148463475336

Epoch: 94| Step: 0
Training loss: 2.043896320483081
Validation loss: 2.4784894445514367

Epoch: 5| Step: 1
Training loss: 2.7870479542220474
Validation loss: 2.479116711449722

Epoch: 5| Step: 2
Training loss: 2.8252640052247773
Validation loss: 2.490996973516944

Epoch: 5| Step: 3
Training loss: 2.9693264050322226
Validation loss: 2.4923345513604125

Epoch: 5| Step: 4
Training loss: 2.739374875645914
Validation loss: 2.500813024869462

Epoch: 5| Step: 5
Training loss: 2.7002961455517505
Validation loss: 2.4848022052356993

Epoch: 5| Step: 6
Training loss: 3.13890324554611
Validation loss: 2.4833695914536937

Epoch: 5| Step: 7
Training loss: 3.1689787170812562
Validation loss: 2.4932722997452994

Epoch: 5| Step: 8
Training loss: 1.9745696504334411
Validation loss: 2.477557031953035

Epoch: 5| Step: 9
Training loss: 2.6427588334080725
Validation loss: 2.500253029805926

Epoch: 5| Step: 10
Training loss: 2.7231477269206414
Validation loss: 2.4885729294576784

Epoch: 95| Step: 0
Training loss: 2.3214599649172025
Validation loss: 2.4783265756973285

Epoch: 5| Step: 1
Training loss: 2.6816066620322894
Validation loss: 2.497301803191325

Epoch: 5| Step: 2
Training loss: 2.980150358259951
Validation loss: 2.481097729755811

Epoch: 5| Step: 3
Training loss: 2.9327796182227024
Validation loss: 2.48709773690659

Epoch: 5| Step: 4
Training loss: 2.7677187133487218
Validation loss: 2.467654282953329

Epoch: 5| Step: 5
Training loss: 2.36853552982223
Validation loss: 2.4951145797974976

Epoch: 5| Step: 6
Training loss: 2.646967387022633
Validation loss: 2.4977508040809693

Epoch: 5| Step: 7
Training loss: 2.505087539605194
Validation loss: 2.4909866798125

Epoch: 5| Step: 8
Training loss: 2.8879121164280455
Validation loss: 2.488910771788049

Epoch: 5| Step: 9
Training loss: 2.171711757754871
Validation loss: 2.487178168087429

Epoch: 5| Step: 10
Training loss: 3.5820594711606395
Validation loss: 2.477950308484478

Epoch: 96| Step: 0
Training loss: 3.052176221317197
Validation loss: 2.4797719821577915

Epoch: 5| Step: 1
Training loss: 2.6539427666317765
Validation loss: 2.49397553203232

Epoch: 5| Step: 2
Training loss: 2.669032319120136
Validation loss: 2.4966032722755744

Epoch: 5| Step: 3
Training loss: 2.4571500182443486
Validation loss: 2.487813308952926

Epoch: 5| Step: 4
Training loss: 2.3953624981404293
Validation loss: 2.4801341518365962

Epoch: 5| Step: 5
Training loss: 2.4063910901209056
Validation loss: 2.4852212022118447

Epoch: 5| Step: 6
Training loss: 2.860251037144012
Validation loss: 2.493881990398662

Epoch: 5| Step: 7
Training loss: 2.6811933818254565
Validation loss: 2.4790966902677667

Epoch: 5| Step: 8
Training loss: 2.790338817245471
Validation loss: 2.4988641845433484

Epoch: 5| Step: 9
Training loss: 3.2132873104751534
Validation loss: 2.4766932911948145

Epoch: 5| Step: 10
Training loss: 2.665724876115842
Validation loss: 2.481272198275114

Epoch: 97| Step: 0
Training loss: 2.812519666814919
Validation loss: 2.4882969752012323

Epoch: 5| Step: 1
Training loss: 2.900349688000243
Validation loss: 2.4850624099843532

Epoch: 5| Step: 2
Training loss: 1.9535170504956307
Validation loss: 2.4852722440263677

Epoch: 5| Step: 3
Training loss: 2.223876296472657
Validation loss: 2.4744560848894595

Epoch: 5| Step: 4
Training loss: 2.9073633501998764
Validation loss: 2.489787199762792

Epoch: 5| Step: 5
Training loss: 2.9805332241859133
Validation loss: 2.481799008278025

Epoch: 5| Step: 6
Training loss: 2.974938778287396
Validation loss: 2.4845610786437033

Epoch: 5| Step: 7
Training loss: 2.9276210159842107
Validation loss: 2.474477380642829

Epoch: 5| Step: 8
Training loss: 2.3810389187390553
Validation loss: 2.4852007897313846

Epoch: 5| Step: 9
Training loss: 2.939365200616074
Validation loss: 2.4813467877096693

Epoch: 5| Step: 10
Training loss: 2.5298370373679067
Validation loss: 2.4859898682708272

Epoch: 98| Step: 0
Training loss: 2.901168318243326
Validation loss: 2.4945634848077125

Epoch: 5| Step: 1
Training loss: 2.7859566970822747
Validation loss: 2.492496595394045

Epoch: 5| Step: 2
Training loss: 2.1770207762666463
Validation loss: 2.4737894273663663

Epoch: 5| Step: 3
Training loss: 2.122788007267237
Validation loss: 2.4893494893204746

Epoch: 5| Step: 4
Training loss: 2.2503132072313066
Validation loss: 2.495390250651556

Epoch: 5| Step: 5
Training loss: 2.034172655112664
Validation loss: 2.4932576814519964

Epoch: 5| Step: 6
Training loss: 3.475024073675184
Validation loss: 2.4888454529174897

Epoch: 5| Step: 7
Training loss: 3.3391505185612567
Validation loss: 2.4843669841438656

Epoch: 5| Step: 8
Training loss: 2.9841885333701277
Validation loss: 2.5037456033008954

Epoch: 5| Step: 9
Training loss: 2.8148475174742345
Validation loss: 2.4980022980589864

Epoch: 5| Step: 10
Training loss: 2.471957959351557
Validation loss: 2.4770860067903526

Epoch: 99| Step: 0
Training loss: 2.5876366141554197
Validation loss: 2.496923026682952

Epoch: 5| Step: 1
Training loss: 2.3944597591412915
Validation loss: 2.4888973350739887

Epoch: 5| Step: 2
Training loss: 2.749183273411739
Validation loss: 2.498118590933394

Epoch: 5| Step: 3
Training loss: 2.415774630197074
Validation loss: 2.488275894569072

Epoch: 5| Step: 4
Training loss: 2.1981543341646055
Validation loss: 2.4684360398491494

Epoch: 5| Step: 5
Training loss: 2.7591527864488596
Validation loss: 2.503533189315353

Epoch: 5| Step: 6
Training loss: 3.198010935103262
Validation loss: 2.480179261825278

Epoch: 5| Step: 7
Training loss: 2.8057396065632405
Validation loss: 2.4937415058563834

Epoch: 5| Step: 8
Training loss: 2.6174383697978336
Validation loss: 2.472287872192942

Epoch: 5| Step: 9
Training loss: 2.8930452679211935
Validation loss: 2.5020731625899204

Epoch: 5| Step: 10
Training loss: 3.223267135518945
Validation loss: 2.4739166739841667

Epoch: 100| Step: 0
Training loss: 2.410157535991604
Validation loss: 2.4901368692037598

Epoch: 5| Step: 1
Training loss: 2.444208060259928
Validation loss: 2.4888315147276536

Epoch: 5| Step: 2
Training loss: 2.1200332941283944
Validation loss: 2.4836620180463975

Epoch: 5| Step: 3
Training loss: 3.031430897771524
Validation loss: 2.4898029576685814

Epoch: 5| Step: 4
Training loss: 2.896296201163736
Validation loss: 2.488168260636193

Epoch: 5| Step: 5
Training loss: 2.581436065544127
Validation loss: 2.4795728291993258

Epoch: 5| Step: 6
Training loss: 3.136914846863033
Validation loss: 2.4736804340195326

Epoch: 5| Step: 7
Training loss: 3.0040222859882975
Validation loss: 2.4962164879657207

Epoch: 5| Step: 8
Training loss: 2.3611931269245
Validation loss: 2.485351329896694

Epoch: 5| Step: 9
Training loss: 2.7459353839470624
Validation loss: 2.476981472843509

Epoch: 5| Step: 10
Training loss: 3.0525658305299883
Validation loss: 2.4697416553533986

Epoch: 101| Step: 0
Training loss: 2.865245025968615
Validation loss: 2.49179352907112

Epoch: 5| Step: 1
Training loss: 2.157820972423232
Validation loss: 2.4829348223816354

Epoch: 5| Step: 2
Training loss: 2.6720284758095505
Validation loss: 2.485715794118303

Epoch: 5| Step: 3
Training loss: 2.6020866530442777
Validation loss: 2.4838999013210405

Epoch: 5| Step: 4
Training loss: 2.616985802920602
Validation loss: 2.4797010465412264

Epoch: 5| Step: 5
Training loss: 3.159800128651707
Validation loss: 2.4715798274521603

Epoch: 5| Step: 6
Training loss: 3.3474331829305526
Validation loss: 2.456676018012361

Epoch: 5| Step: 7
Training loss: 2.56816238402105
Validation loss: 2.473062467602936

Epoch: 5| Step: 8
Training loss: 2.4854383771981485
Validation loss: 2.4855685239397727

Epoch: 5| Step: 9
Training loss: 3.0645268797888265
Validation loss: 2.4835368717682225

Epoch: 5| Step: 10
Training loss: 1.8734320124274562
Validation loss: 2.4702819353666503

Epoch: 102| Step: 0
Training loss: 2.8611871365648796
Validation loss: 2.472491448860416

Epoch: 5| Step: 1
Training loss: 2.635494326526583
Validation loss: 2.497100273320673

Epoch: 5| Step: 2
Training loss: 2.980631612625194
Validation loss: 2.4855471509664913

Epoch: 5| Step: 3
Training loss: 2.570370195199254
Validation loss: 2.46764131020225

Epoch: 5| Step: 4
Training loss: 2.9105781402976985
Validation loss: 2.4824251838248235

Epoch: 5| Step: 5
Training loss: 2.7889703473593452
Validation loss: 2.510581862319045

Epoch: 5| Step: 6
Training loss: 2.3056480345760675
Validation loss: 2.486378761562533

Epoch: 5| Step: 7
Training loss: 2.503879493415689
Validation loss: 2.506424842570146

Epoch: 5| Step: 8
Training loss: 2.312321217817212
Validation loss: 2.4953077992681445

Epoch: 5| Step: 9
Training loss: 2.8755585501077277
Validation loss: 2.485568446584009

Epoch: 5| Step: 10
Training loss: 2.887831869499009
Validation loss: 2.475132973285957

Epoch: 103| Step: 0
Training loss: 2.2815130421777554
Validation loss: 2.4900669124755535

Epoch: 5| Step: 1
Training loss: 3.023407534270915
Validation loss: 2.4835744052688624

Epoch: 5| Step: 2
Training loss: 2.9261697630899466
Validation loss: 2.491243161203199

Epoch: 5| Step: 3
Training loss: 2.70833627749552
Validation loss: 2.505600473101065

Epoch: 5| Step: 4
Training loss: 3.3894386853047553
Validation loss: 2.497358464786279

Epoch: 5| Step: 5
Training loss: 2.468452145921428
Validation loss: 2.490123423662872

Epoch: 5| Step: 6
Training loss: 2.3241081660273517
Validation loss: 2.493656531575695

Epoch: 5| Step: 7
Training loss: 2.574933938225283
Validation loss: 2.480226529217326

Epoch: 5| Step: 8
Training loss: 2.4796410328502057
Validation loss: 2.488613169436057

Epoch: 5| Step: 9
Training loss: 2.495750821574765
Validation loss: 2.479917580215461

Epoch: 5| Step: 10
Training loss: 2.833244789834358
Validation loss: 2.4821946398881742

Epoch: 104| Step: 0
Training loss: 3.4314002276888376
Validation loss: 2.4905487843929333

Epoch: 5| Step: 1
Training loss: 2.582307232349093
Validation loss: 2.487093748831082

Epoch: 5| Step: 2
Training loss: 2.1736684296687643
Validation loss: 2.469367007682658

Epoch: 5| Step: 3
Training loss: 2.71146258015446
Validation loss: 2.4921609848391033

Epoch: 5| Step: 4
Training loss: 2.295904252837169
Validation loss: 2.5104256423287987

Epoch: 5| Step: 5
Training loss: 2.9215234555189626
Validation loss: 2.485151226771834

Epoch: 5| Step: 6
Training loss: 3.107720783274597
Validation loss: 2.4911992760050863

Epoch: 5| Step: 7
Training loss: 2.6055527520543107
Validation loss: 2.482584352298485

Epoch: 5| Step: 8
Training loss: 2.490490374402735
Validation loss: 2.4838031500979163

Epoch: 5| Step: 9
Training loss: 2.645919728307849
Validation loss: 2.487781150571063

Epoch: 5| Step: 10
Training loss: 2.6343992981067306
Validation loss: 2.494664511988718

Epoch: 105| Step: 0
Training loss: 2.6548239975403756
Validation loss: 2.483567026818495

Epoch: 5| Step: 1
Training loss: 2.7332054906891825
Validation loss: 2.495511570615126

Epoch: 5| Step: 2
Training loss: 2.2998899018846566
Validation loss: 2.485643086556287

Epoch: 5| Step: 3
Training loss: 2.421750071595176
Validation loss: 2.4809728633237422

Epoch: 5| Step: 4
Training loss: 2.9658246534891677
Validation loss: 2.47424369232748

Epoch: 5| Step: 5
Training loss: 2.8722615676077186
Validation loss: 2.4754022310572257

Epoch: 5| Step: 6
Training loss: 2.991026650685323
Validation loss: 2.4845987865257464

Epoch: 5| Step: 7
Training loss: 2.373771148796343
Validation loss: 2.4919941116348636

Epoch: 5| Step: 8
Training loss: 3.0571343263932347
Validation loss: 2.4970103877268155

Epoch: 5| Step: 9
Training loss: 2.499151276526955
Validation loss: 2.50312351940972

Epoch: 5| Step: 10
Training loss: 2.7497127556337357
Validation loss: 2.4779515546371385

Epoch: 106| Step: 0
Training loss: 2.747778515431501
Validation loss: 2.481572320477563

Epoch: 5| Step: 1
Training loss: 2.8872451405531794
Validation loss: 2.4884381493259755

Epoch: 5| Step: 2
Training loss: 2.8948328682153486
Validation loss: 2.4795600521789347

Epoch: 5| Step: 3
Training loss: 1.6843071154218487
Validation loss: 2.480971402207831

Epoch: 5| Step: 4
Training loss: 2.661160406967022
Validation loss: 2.4730520152817785

Epoch: 5| Step: 5
Training loss: 2.476644520649873
Validation loss: 2.4770285704592747

Epoch: 5| Step: 6
Training loss: 2.9251362760701496
Validation loss: 2.475279133173829

Epoch: 5| Step: 7
Training loss: 2.4997415409000325
Validation loss: 2.470151206346183

Epoch: 5| Step: 8
Training loss: 2.509151683480959
Validation loss: 2.4790564726525868

Epoch: 5| Step: 9
Training loss: 3.367666967114118
Validation loss: 2.472425866259187

Epoch: 5| Step: 10
Training loss: 2.8396051403690707
Validation loss: 2.478139359594311

Epoch: 107| Step: 0
Training loss: 2.7120196466493853
Validation loss: 2.50322418370753

Epoch: 5| Step: 1
Training loss: 2.407433157019646
Validation loss: 2.471759001358929

Epoch: 5| Step: 2
Training loss: 2.8347042544406715
Validation loss: 2.4803326984869862

Epoch: 5| Step: 3
Training loss: 2.2136726849246355
Validation loss: 2.4791234527017587

Epoch: 5| Step: 4
Training loss: 2.391380739122698
Validation loss: 2.479109828508036

Epoch: 5| Step: 5
Training loss: 2.8477131820869253
Validation loss: 2.5015161295682695

Epoch: 5| Step: 6
Training loss: 2.752948220993396
Validation loss: 2.4875196575167835

Epoch: 5| Step: 7
Training loss: 2.7829115972593166
Validation loss: 2.4917417596897384

Epoch: 5| Step: 8
Training loss: 2.9332288167135427
Validation loss: 2.486486282733532

Epoch: 5| Step: 9
Training loss: 3.1402936921992826
Validation loss: 2.498888831180521

Epoch: 5| Step: 10
Training loss: 2.565433590773106
Validation loss: 2.4703617382630387

Epoch: 108| Step: 0
Training loss: 2.1158147774666825
Validation loss: 2.5148135536177487

Epoch: 5| Step: 1
Training loss: 2.772470224975638
Validation loss: 2.505726264397423

Epoch: 5| Step: 2
Training loss: 2.9527293752644863
Validation loss: 2.5179072117830112

Epoch: 5| Step: 3
Training loss: 2.68122610512781
Validation loss: 2.4752541105935517

Epoch: 5| Step: 4
Training loss: 2.228453251653691
Validation loss: 2.4782482478698147

Epoch: 5| Step: 5
Training loss: 2.5904724370671444
Validation loss: 2.4940102430442925

Epoch: 5| Step: 6
Training loss: 2.962236346008991
Validation loss: 2.4865166762655355

Epoch: 5| Step: 7
Training loss: 3.59385296217994
Validation loss: 2.4879929542033534

Epoch: 5| Step: 8
Training loss: 2.7813862970794876
Validation loss: 2.508888690195121

Epoch: 5| Step: 9
Training loss: 2.478709352345644
Validation loss: 2.476186780558883

Epoch: 5| Step: 10
Training loss: 2.172587984364428
Validation loss: 2.507521326611953

Epoch: 109| Step: 0
Training loss: 2.272899865619535
Validation loss: 2.4988993021318486

Epoch: 5| Step: 1
Training loss: 2.2575525048318927
Validation loss: 2.492081872809973

Epoch: 5| Step: 2
Training loss: 2.607385848007192
Validation loss: 2.4794929526138354

Epoch: 5| Step: 3
Training loss: 3.0025161681744406
Validation loss: 2.47726480004274

Epoch: 5| Step: 4
Training loss: 2.8311897658789107
Validation loss: 2.484706105628674

Epoch: 5| Step: 5
Training loss: 3.0653839545409847
Validation loss: 2.4840335622930376

Epoch: 5| Step: 6
Training loss: 2.7431807498824936
Validation loss: 2.481433518328717

Epoch: 5| Step: 7
Training loss: 2.7316955517243846
Validation loss: 2.496895384149263

Epoch: 5| Step: 8
Training loss: 2.5177213096889255
Validation loss: 2.500614925354518

Epoch: 5| Step: 9
Training loss: 2.887113510622292
Validation loss: 2.4928576342231588

Epoch: 5| Step: 10
Training loss: 2.805700007791625
Validation loss: 2.4959994229320515

Epoch: 110| Step: 0
Training loss: 2.4980031621835086
Validation loss: 2.470095696440671

Epoch: 5| Step: 1
Training loss: 2.619734523951361
Validation loss: 2.5001820549254843

Epoch: 5| Step: 2
Training loss: 2.1804178306459363
Validation loss: 2.4937050095026194

Epoch: 5| Step: 3
Training loss: 2.74761512688696
Validation loss: 2.49172629492425

Epoch: 5| Step: 4
Training loss: 3.1291269136452775
Validation loss: 2.4985743261995172

Epoch: 5| Step: 5
Training loss: 2.5892127003264407
Validation loss: 2.4906030546145264

Epoch: 5| Step: 6
Training loss: 2.8910833871665296
Validation loss: 2.495533013369277

Epoch: 5| Step: 7
Training loss: 2.7701924856904583
Validation loss: 2.480525541862531

Epoch: 5| Step: 8
Training loss: 2.599172232979549
Validation loss: 2.4858978138584438

Epoch: 5| Step: 9
Training loss: 2.4725588618138654
Validation loss: 2.502837378826963

Epoch: 5| Step: 10
Training loss: 3.0029690673230913
Validation loss: 2.4827450098790402

Epoch: 111| Step: 0
Training loss: 2.702470556869823
Validation loss: 2.4810289637373386

Epoch: 5| Step: 1
Training loss: 3.0727499878932787
Validation loss: 2.5092130163479607

Epoch: 5| Step: 2
Training loss: 2.0426076420372765
Validation loss: 2.4671575005813224

Epoch: 5| Step: 3
Training loss: 2.6261354443033156
Validation loss: 2.481526132472123

Epoch: 5| Step: 4
Training loss: 3.007474806022871
Validation loss: 2.4818852448424558

Epoch: 5| Step: 5
Training loss: 2.756539199431365
Validation loss: 2.486533457039453

Epoch: 5| Step: 6
Training loss: 2.6163709590852045
Validation loss: 2.4872077378570214

Epoch: 5| Step: 7
Training loss: 2.346352518287839
Validation loss: 2.5122408367575435

Epoch: 5| Step: 8
Training loss: 2.6022598202677947
Validation loss: 2.477690499126918

Epoch: 5| Step: 9
Training loss: 2.8523137187395537
Validation loss: 2.505856925285318

Epoch: 5| Step: 10
Training loss: 2.815596931139789
Validation loss: 2.4764092831678473

Epoch: 112| Step: 0
Training loss: 2.728683215314408
Validation loss: 2.4724310569392087

Epoch: 5| Step: 1
Training loss: 2.893752267395845
Validation loss: 2.475790664179198

Epoch: 5| Step: 2
Training loss: 2.631598580437756
Validation loss: 2.4910585341686295

Epoch: 5| Step: 3
Training loss: 2.708618403372895
Validation loss: 2.480417324079229

Epoch: 5| Step: 4
Training loss: 2.6250557666486127
Validation loss: 2.492556630742558

Epoch: 5| Step: 5
Training loss: 3.1946505954584437
Validation loss: 2.4774821856213287

Epoch: 5| Step: 6
Training loss: 2.780685710454295
Validation loss: 2.4778882783617253

Epoch: 5| Step: 7
Training loss: 2.8637991276843398
Validation loss: 2.4885245586219904

Epoch: 5| Step: 8
Training loss: 2.3197654824277247
Validation loss: 2.497005246601348

Epoch: 5| Step: 9
Training loss: 2.5132425529956293
Validation loss: 2.4768304700233825

Epoch: 5| Step: 10
Training loss: 2.188708924976152
Validation loss: 2.482812295182368

Epoch: 113| Step: 0
Training loss: 2.596178687213178
Validation loss: 2.5065423371426996

Epoch: 5| Step: 1
Training loss: 2.682555329533447
Validation loss: 2.4814114908900646

Epoch: 5| Step: 2
Training loss: 2.1181307447529476
Validation loss: 2.5046153841799774

Epoch: 5| Step: 3
Training loss: 2.5829875058275507
Validation loss: 2.5009251646468966

Epoch: 5| Step: 4
Training loss: 3.294109902452934
Validation loss: 2.4706284746777056

Epoch: 5| Step: 5
Training loss: 2.4340293825016968
Validation loss: 2.488102679623186

Epoch: 5| Step: 6
Training loss: 2.290443394475912
Validation loss: 2.497500285598686

Epoch: 5| Step: 7
Training loss: 2.563247757646076
Validation loss: 2.5007073811630915

Epoch: 5| Step: 8
Training loss: 2.4517283746390532
Validation loss: 2.467511087513149

Epoch: 5| Step: 9
Training loss: 2.6586267048342758
Validation loss: 2.492389865286436

Epoch: 5| Step: 10
Training loss: 3.7688095113379587
Validation loss: 2.4860759641038483

Epoch: 114| Step: 0
Training loss: 3.1045081614287056
Validation loss: 2.4839029037069653

Epoch: 5| Step: 1
Training loss: 2.3920830163743405
Validation loss: 2.469916073882552

Epoch: 5| Step: 2
Training loss: 2.9169923509687767
Validation loss: 2.4878710666589106

Epoch: 5| Step: 3
Training loss: 2.196484018970605
Validation loss: 2.4878479029399796

Epoch: 5| Step: 4
Training loss: 2.3676462264054283
Validation loss: 2.4811645141796603

Epoch: 5| Step: 5
Training loss: 2.4325459338533357
Validation loss: 2.5004024120216988

Epoch: 5| Step: 6
Training loss: 2.6993607788700555
Validation loss: 2.4772945662729806

Epoch: 5| Step: 7
Training loss: 2.9731382362723844
Validation loss: 2.4785043687132586

Epoch: 5| Step: 8
Training loss: 2.5351063116530352
Validation loss: 2.5011076473059646

Epoch: 5| Step: 9
Training loss: 2.3530622496730045
Validation loss: 2.514106742257346

Epoch: 5| Step: 10
Training loss: 3.4868383894354107
Validation loss: 2.4755881784708103

Epoch: 115| Step: 0
Training loss: 2.190848594061961
Validation loss: 2.4937900571761706

Epoch: 5| Step: 1
Training loss: 2.9657986074588547
Validation loss: 2.475751276140616

Epoch: 5| Step: 2
Training loss: 2.8911467210239943
Validation loss: 2.503370662539949

Epoch: 5| Step: 3
Training loss: 2.0077324639781122
Validation loss: 2.491298032692452

Epoch: 5| Step: 4
Training loss: 3.030998455504071
Validation loss: 2.4889637721967075

Epoch: 5| Step: 5
Training loss: 2.6434350044769945
Validation loss: 2.4774154881966637

Epoch: 5| Step: 6
Training loss: 2.6496908547359608
Validation loss: 2.4862191152410613

Epoch: 5| Step: 7
Training loss: 2.722361128586896
Validation loss: 2.5089800732438867

Epoch: 5| Step: 8
Training loss: 2.1925188527878894
Validation loss: 2.49393108174207

Epoch: 5| Step: 9
Training loss: 2.9918674865590065
Validation loss: 2.501366151781122

Epoch: 5| Step: 10
Training loss: 3.0549948457215526
Validation loss: 2.492417440531608

Epoch: 116| Step: 0
Training loss: 3.0950672158382346
Validation loss: 2.4748483811722473

Epoch: 5| Step: 1
Training loss: 2.786623018811211
Validation loss: 2.4786661124801914

Epoch: 5| Step: 2
Training loss: 3.324588096173165
Validation loss: 2.491864982590257

Epoch: 5| Step: 3
Training loss: 2.4784786861904604
Validation loss: 2.480608136303882

Epoch: 5| Step: 4
Training loss: 1.9333659953065951
Validation loss: 2.489939022995378

Epoch: 5| Step: 5
Training loss: 2.279899092666537
Validation loss: 2.4891649906370557

Epoch: 5| Step: 6
Training loss: 2.7611830217381303
Validation loss: 2.492024349520131

Epoch: 5| Step: 7
Training loss: 2.3707435009859337
Validation loss: 2.4663711162373585

Epoch: 5| Step: 8
Training loss: 2.190080591922359
Validation loss: 2.4916442460039696

Epoch: 5| Step: 9
Training loss: 2.9659778702592634
Validation loss: 2.4935224662588915

Epoch: 5| Step: 10
Training loss: 3.02738517486779
Validation loss: 2.491817182869644

Epoch: 117| Step: 0
Training loss: 3.396162582693287
Validation loss: 2.4977097624132765

Epoch: 5| Step: 1
Training loss: 3.093247652210025
Validation loss: 2.5130628887170436

Epoch: 5| Step: 2
Training loss: 2.4972776849754745
Validation loss: 2.499839144833458

Epoch: 5| Step: 3
Training loss: 2.648003466664376
Validation loss: 2.513546389550811

Epoch: 5| Step: 4
Training loss: 2.208168695418617
Validation loss: 2.4615345459994957

Epoch: 5| Step: 5
Training loss: 2.2908762753669842
Validation loss: 2.493728841524853

Epoch: 5| Step: 6
Training loss: 2.3351823996097223
Validation loss: 2.500290803505812

Epoch: 5| Step: 7
Training loss: 3.0169572012359334
Validation loss: 2.4938543943400293

Epoch: 5| Step: 8
Training loss: 3.148866079991602
Validation loss: 2.4951439743445523

Epoch: 5| Step: 9
Training loss: 2.5032100096327197
Validation loss: 2.4999125260257213

Epoch: 5| Step: 10
Training loss: 1.777469706002219
Validation loss: 2.4880425203166827

Epoch: 118| Step: 0
Training loss: 3.239322435150164
Validation loss: 2.4991399377711483

Epoch: 5| Step: 1
Training loss: 2.5091717325356018
Validation loss: 2.474163974231129

Epoch: 5| Step: 2
Training loss: 2.3333781328896017
Validation loss: 2.4996146335764466

Epoch: 5| Step: 3
Training loss: 3.344552202344
Validation loss: 2.480780687162063

Epoch: 5| Step: 4
Training loss: 2.2128821134614
Validation loss: 2.4939310889377317

Epoch: 5| Step: 5
Training loss: 2.6039375713031485
Validation loss: 2.4861634175758023

Epoch: 5| Step: 6
Training loss: 2.4322858942413994
Validation loss: 2.493890019360349

Epoch: 5| Step: 7
Training loss: 2.298117891725487
Validation loss: 2.495344006091141

Epoch: 5| Step: 8
Training loss: 2.9738972262881602
Validation loss: 2.492785363793009

Epoch: 5| Step: 9
Training loss: 2.217711622081329
Validation loss: 2.481035180046365

Epoch: 5| Step: 10
Training loss: 2.867524420876183
Validation loss: 2.4911521663853136

Epoch: 119| Step: 0
Training loss: 2.7674145269935777
Validation loss: 2.484051379497232

Epoch: 5| Step: 1
Training loss: 2.7370823998889287
Validation loss: 2.4851728466017065

Epoch: 5| Step: 2
Training loss: 3.1607618659304464
Validation loss: 2.4762729309732743

Epoch: 5| Step: 3
Training loss: 2.551040145564116
Validation loss: 2.4908204983181665

Epoch: 5| Step: 4
Training loss: 2.795116873602456
Validation loss: 2.4964134197380936

Epoch: 5| Step: 5
Training loss: 2.708291028988387
Validation loss: 2.512907432017815

Epoch: 5| Step: 6
Training loss: 3.0122790180372276
Validation loss: 2.484837779487035

Epoch: 5| Step: 7
Training loss: 2.7721912431568017
Validation loss: 2.503453553937221

Epoch: 5| Step: 8
Training loss: 2.071980736337317
Validation loss: 2.488720041937341

Epoch: 5| Step: 9
Training loss: 2.770674669890583
Validation loss: 2.513187820435256

Epoch: 5| Step: 10
Training loss: 2.0153043033470435
Validation loss: 2.486708212233276

Epoch: 120| Step: 0
Training loss: 2.511990403454667
Validation loss: 2.4892402467787087

Epoch: 5| Step: 1
Training loss: 2.1539076092881433
Validation loss: 2.481766286458289

Epoch: 5| Step: 2
Training loss: 2.8771486960427723
Validation loss: 2.5130192667332305

Epoch: 5| Step: 3
Training loss: 2.3090432595966495
Validation loss: 2.489488678574991

Epoch: 5| Step: 4
Training loss: 2.9282270122659155
Validation loss: 2.4897368940610707

Epoch: 5| Step: 5
Training loss: 3.3599075250161508
Validation loss: 2.4747615497773827

Epoch: 5| Step: 6
Training loss: 2.592898309434137
Validation loss: 2.4931449397280754

Epoch: 5| Step: 7
Training loss: 2.3723118275502926
Validation loss: 2.48395242655352

Epoch: 5| Step: 8
Training loss: 2.6823494815459643
Validation loss: 2.482942367910873

Epoch: 5| Step: 9
Training loss: 2.541443163524235
Validation loss: 2.472102710971783

Epoch: 5| Step: 10
Training loss: 2.9215363494946383
Validation loss: 2.493776873943559

Epoch: 121| Step: 0
Training loss: 2.9605448520370117
Validation loss: 2.4869180836859357

Epoch: 5| Step: 1
Training loss: 2.8624148027159895
Validation loss: 2.4893146448333816

Epoch: 5| Step: 2
Training loss: 2.410968859920397
Validation loss: 2.4734954076180524

Epoch: 5| Step: 3
Training loss: 2.5020091566471714
Validation loss: 2.4970754519515204

Epoch: 5| Step: 4
Training loss: 2.4038639871962824
Validation loss: 2.4839873937349646

Epoch: 5| Step: 5
Training loss: 3.010009122055273
Validation loss: 2.468090425656957

Epoch: 5| Step: 6
Training loss: 2.670117787538335
Validation loss: 2.486578390107363

Epoch: 5| Step: 7
Training loss: 2.726569320539016
Validation loss: 2.483434124250325

Epoch: 5| Step: 8
Training loss: 2.910194099743375
Validation loss: 2.4786046308713847

Epoch: 5| Step: 9
Training loss: 2.4073664069420238
Validation loss: 2.485339864744445

Epoch: 5| Step: 10
Training loss: 2.4423022769796314
Validation loss: 2.472898298964679

Epoch: 122| Step: 0
Training loss: 2.388407557687987
Validation loss: 2.4807841593861704

Epoch: 5| Step: 1
Training loss: 2.7105341454589222
Validation loss: 2.4832057315422795

Epoch: 5| Step: 2
Training loss: 2.558698858766603
Validation loss: 2.5012355806983675

Epoch: 5| Step: 3
Training loss: 3.11076009753234
Validation loss: 2.4836428350162434

Epoch: 5| Step: 4
Training loss: 2.832633960650281
Validation loss: 2.495917290568255

Epoch: 5| Step: 5
Training loss: 3.073402150915171
Validation loss: 2.4653408904612033

Epoch: 5| Step: 6
Training loss: 2.503823789289106
Validation loss: 2.5008231294852172

Epoch: 5| Step: 7
Training loss: 2.327942501826255
Validation loss: 2.4788529164864848

Epoch: 5| Step: 8
Training loss: 2.803559993133965
Validation loss: 2.4786532501113943

Epoch: 5| Step: 9
Training loss: 2.5557726500622375
Validation loss: 2.5041158983620324

Epoch: 5| Step: 10
Training loss: 2.3450778505786665
Validation loss: 2.486980753965064

Epoch: 123| Step: 0
Training loss: 2.266660466840156
Validation loss: 2.4929804708416676

Epoch: 5| Step: 1
Training loss: 2.560987072430521
Validation loss: 2.468404688893226

Epoch: 5| Step: 2
Training loss: 3.001684987211545
Validation loss: 2.4967947121428615

Epoch: 5| Step: 3
Training loss: 1.807232404134823
Validation loss: 2.4816585587210866

Epoch: 5| Step: 4
Training loss: 3.1316014562790775
Validation loss: 2.4933819707135574

Epoch: 5| Step: 5
Training loss: 2.652406312544549
Validation loss: 2.478502412239735

Epoch: 5| Step: 6
Training loss: 2.6950982492404765
Validation loss: 2.511092669425664

Epoch: 5| Step: 7
Training loss: 2.4313683292257595
Validation loss: 2.475069532767347

Epoch: 5| Step: 8
Training loss: 2.906363536298746
Validation loss: 2.488850621713863

Epoch: 5| Step: 9
Training loss: 2.69891700217312
Validation loss: 2.500739109342529

Epoch: 5| Step: 10
Training loss: 3.105766464453835
Validation loss: 2.5009738081734363

Epoch: 124| Step: 0
Training loss: 2.43428825645007
Validation loss: 2.4863460319633406

Epoch: 5| Step: 1
Training loss: 2.388940454512992
Validation loss: 2.492171701623002

Epoch: 5| Step: 2
Training loss: 2.0017262400015863
Validation loss: 2.4782298261954905

Epoch: 5| Step: 3
Training loss: 2.6253220496851406
Validation loss: 2.4930058255537553

Epoch: 5| Step: 4
Training loss: 2.8130050205764965
Validation loss: 2.4756597600589223

Epoch: 5| Step: 5
Training loss: 2.2879625613610775
Validation loss: 2.5049167235051035

Epoch: 5| Step: 6
Training loss: 2.144493561293652
Validation loss: 2.495083028230679

Epoch: 5| Step: 7
Training loss: 3.075019780537322
Validation loss: 2.501999345768923

Epoch: 5| Step: 8
Training loss: 3.300287731226888
Validation loss: 2.480552574125638

Epoch: 5| Step: 9
Training loss: 2.8603203883479598
Validation loss: 2.483604215099984

Epoch: 5| Step: 10
Training loss: 3.0444570483885007
Validation loss: 2.4734216769689352

Epoch: 125| Step: 0
Training loss: 1.9718843366157044
Validation loss: 2.491902940024357

Epoch: 5| Step: 1
Training loss: 2.4438079983202052
Validation loss: 2.476941950560688

Epoch: 5| Step: 2
Training loss: 2.7743917193750094
Validation loss: 2.48672659274923

Epoch: 5| Step: 3
Training loss: 3.798854735607311
Validation loss: 2.4859719757574728

Epoch: 5| Step: 4
Training loss: 2.3752025718631358
Validation loss: 2.4952027803798056

Epoch: 5| Step: 5
Training loss: 2.3059870789720898
Validation loss: 2.4954565231304566

Epoch: 5| Step: 6
Training loss: 1.9669950019877653
Validation loss: 2.4789287566388425

Epoch: 5| Step: 7
Training loss: 3.141355211383602
Validation loss: 2.483277453845254

Epoch: 5| Step: 8
Training loss: 2.628784086157888
Validation loss: 2.487818963187563

Epoch: 5| Step: 9
Training loss: 2.6984731524950045
Validation loss: 2.4928674882780717

Epoch: 5| Step: 10
Training loss: 2.7510925203529584
Validation loss: 2.4934311634075312

Epoch: 126| Step: 0
Training loss: 2.634832948315195
Validation loss: 2.4922938298945234

Epoch: 5| Step: 1
Training loss: 2.281804265660644
Validation loss: 2.4955655577617284

Epoch: 5| Step: 2
Training loss: 3.5802744443751653
Validation loss: 2.491435714187974

Epoch: 5| Step: 3
Training loss: 3.3315692684203944
Validation loss: 2.4881215660441063

Epoch: 5| Step: 4
Training loss: 2.3941653098042677
Validation loss: 2.4735815678190636

Epoch: 5| Step: 5
Training loss: 2.525867154624823
Validation loss: 2.4839667043239975

Epoch: 5| Step: 6
Training loss: 3.1155017702149364
Validation loss: 2.452758940976799

Epoch: 5| Step: 7
Training loss: 2.03890593062834
Validation loss: 2.4846014248694743

Epoch: 5| Step: 8
Training loss: 2.439139084038251
Validation loss: 2.4959108463234188

Epoch: 5| Step: 9
Training loss: 2.6393450281427375
Validation loss: 2.4819607119024423

Epoch: 5| Step: 10
Training loss: 1.8477297358990734
Validation loss: 2.469280066075156

Epoch: 127| Step: 0
Training loss: 2.853044349558358
Validation loss: 2.495423921839833

Epoch: 5| Step: 1
Training loss: 3.2797221668550303
Validation loss: 2.4780180984858853

Epoch: 5| Step: 2
Training loss: 2.3727449452663185
Validation loss: 2.4973949221206526

Epoch: 5| Step: 3
Training loss: 2.3525833499424658
Validation loss: 2.49682412695376

Epoch: 5| Step: 4
Training loss: 2.9725312897212004
Validation loss: 2.488075160625155

Epoch: 5| Step: 5
Training loss: 2.3953475680835608
Validation loss: 2.497093763343227

Epoch: 5| Step: 6
Training loss: 2.9017911772624143
Validation loss: 2.500481528392179

Epoch: 5| Step: 7
Training loss: 2.39535383871878
Validation loss: 2.506691169672464

Epoch: 5| Step: 8
Training loss: 1.9912381771332932
Validation loss: 2.4953642934766544

Epoch: 5| Step: 9
Training loss: 2.517520545792294
Validation loss: 2.4949711663478924

Epoch: 5| Step: 10
Training loss: 3.1703105507248197
Validation loss: 2.493562164745355

Epoch: 128| Step: 0
Training loss: 2.252629756598385
Validation loss: 2.491829577078232

Epoch: 5| Step: 1
Training loss: 2.832512923747357
Validation loss: 2.4955969666016724

Epoch: 5| Step: 2
Training loss: 2.263226311372068
Validation loss: 2.497789810822398

Epoch: 5| Step: 3
Training loss: 2.520834510319543
Validation loss: 2.5067675865811965

Epoch: 5| Step: 4
Training loss: 2.6925713352398346
Validation loss: 2.466190500980285

Epoch: 5| Step: 5
Training loss: 2.5460801083532023
Validation loss: 2.5054774361231757

Epoch: 5| Step: 6
Training loss: 3.108977939423151
Validation loss: 2.4886208862650374

Epoch: 5| Step: 7
Training loss: 2.7964764529511776
Validation loss: 2.501102635040586

Epoch: 5| Step: 8
Training loss: 2.5634631696078714
Validation loss: 2.5003942383867463

Epoch: 5| Step: 9
Training loss: 2.73392461064728
Validation loss: 2.4986990158443803

Epoch: 5| Step: 10
Training loss: 2.8604810899637214
Validation loss: 2.4986757380709084

Epoch: 129| Step: 0
Training loss: 2.609627899888968
Validation loss: 2.4713833628438064

Epoch: 5| Step: 1
Training loss: 2.190806369647005
Validation loss: 2.4973781147551066

Epoch: 5| Step: 2
Training loss: 3.005531615394803
Validation loss: 2.4972312998197657

Epoch: 5| Step: 3
Training loss: 2.9447500162290607
Validation loss: 2.494554669771921

Epoch: 5| Step: 4
Training loss: 2.7290575039607203
Validation loss: 2.502078031515669

Epoch: 5| Step: 5
Training loss: 2.153064088001334
Validation loss: 2.472912351321824

Epoch: 5| Step: 6
Training loss: 3.0518806225289152
Validation loss: 2.479865820841803

Epoch: 5| Step: 7
Training loss: 2.7016432565298065
Validation loss: 2.4824186219375877

Epoch: 5| Step: 8
Training loss: 2.441721952244263
Validation loss: 2.491159840360044

Epoch: 5| Step: 9
Training loss: 2.973558567166311
Validation loss: 2.4899802344441637

Epoch: 5| Step: 10
Training loss: 2.3220041190348257
Validation loss: 2.495055311882382

Epoch: 130| Step: 0
Training loss: 3.035326703758158
Validation loss: 2.4679892019186305

Epoch: 5| Step: 1
Training loss: 2.945077092403558
Validation loss: 2.473394784432918

Epoch: 5| Step: 2
Training loss: 2.261848090233886
Validation loss: 2.4909008530321457

Epoch: 5| Step: 3
Training loss: 2.5274378952108694
Validation loss: 2.486122292378342

Epoch: 5| Step: 4
Training loss: 2.6771725789394933
Validation loss: 2.5068947295292983

Epoch: 5| Step: 5
Training loss: 2.612755510164699
Validation loss: 2.4830825001633268

Epoch: 5| Step: 6
Training loss: 2.8580554356254027
Validation loss: 2.4978173213218335

Epoch: 5| Step: 7
Training loss: 2.524605684367709
Validation loss: 2.490270862509082

Epoch: 5| Step: 8
Training loss: 2.533041237839932
Validation loss: 2.500947983267313

Epoch: 5| Step: 9
Training loss: 2.4163477676275518
Validation loss: 2.5004301172875105

Epoch: 5| Step: 10
Training loss: 2.990301030547911
Validation loss: 2.47426606125891

Epoch: 131| Step: 0
Training loss: 2.5920950884037146
Validation loss: 2.4948341197662196

Epoch: 5| Step: 1
Training loss: 2.513753348736688
Validation loss: 2.4837585084693883

Epoch: 5| Step: 2
Training loss: 2.4836851877742063
Validation loss: 2.482239457331435

Epoch: 5| Step: 3
Training loss: 3.2423925128141597
Validation loss: 2.486088718979458

Epoch: 5| Step: 4
Training loss: 2.343949373030501
Validation loss: 2.48379097800284

Epoch: 5| Step: 5
Training loss: 2.697487923468708
Validation loss: 2.491959151355295

Epoch: 5| Step: 6
Training loss: 2.437517508419441
Validation loss: 2.498796093148766

Epoch: 5| Step: 7
Training loss: 2.79881636942533
Validation loss: 2.521805660048166

Epoch: 5| Step: 8
Training loss: 2.674336509775292
Validation loss: 2.4778254096679215

Epoch: 5| Step: 9
Training loss: 2.6931164627134643
Validation loss: 2.508765275442524

Epoch: 5| Step: 10
Training loss: 2.679083842356375
Validation loss: 2.4837902534346274

Epoch: 132| Step: 0
Training loss: 2.9707265598393535
Validation loss: 2.490063539677671

Epoch: 5| Step: 1
Training loss: 2.1957470881145165
Validation loss: 2.515346785085132

Epoch: 5| Step: 2
Training loss: 2.6068844359214998
Validation loss: 2.496127145693278

Epoch: 5| Step: 3
Training loss: 1.579285600892312
Validation loss: 2.462055460339252

Epoch: 5| Step: 4
Training loss: 3.178252175036235
Validation loss: 2.4949819101068313

Epoch: 5| Step: 5
Training loss: 3.1212339978462884
Validation loss: 2.4984129739314405

Epoch: 5| Step: 6
Training loss: 2.825629381945511
Validation loss: 2.4899499429065513

Epoch: 5| Step: 7
Training loss: 2.1564159605870254
Validation loss: 2.4905473474231448

Epoch: 5| Step: 8
Training loss: 2.8471314165061727
Validation loss: 2.4956773529404894

Epoch: 5| Step: 9
Training loss: 2.948504511764565
Validation loss: 2.5027065859037756

Epoch: 5| Step: 10
Training loss: 2.183412383980472
Validation loss: 2.4916563612146954

Epoch: 133| Step: 0
Training loss: 2.670002152659945
Validation loss: 2.4955831827152894

Epoch: 5| Step: 1
Training loss: 3.2713668938793945
Validation loss: 2.498391646193152

Epoch: 5| Step: 2
Training loss: 3.2416281343995887
Validation loss: 2.5020635210233904

Epoch: 5| Step: 3
Training loss: 2.6519234820125304
Validation loss: 2.5011924596682173

Epoch: 5| Step: 4
Training loss: 2.306480822086715
Validation loss: 2.488988240832314

Epoch: 5| Step: 5
Training loss: 2.3455941637890327
Validation loss: 2.489787840212815

Epoch: 5| Step: 6
Training loss: 2.6914180317968266
Validation loss: 2.497922913297043

Epoch: 5| Step: 7
Training loss: 2.325113281443597
Validation loss: 2.485412938067109

Epoch: 5| Step: 8
Training loss: 2.7512018871823356
Validation loss: 2.5029772473491216

Epoch: 5| Step: 9
Training loss: 2.2745609195087293
Validation loss: 2.4725382380020973

Epoch: 5| Step: 10
Training loss: 2.357059277047643
Validation loss: 2.4683541816153967

Epoch: 134| Step: 0
Training loss: 2.8213766103585014
Validation loss: 2.482905321496341

Epoch: 5| Step: 1
Training loss: 2.483815832009553
Validation loss: 2.4906874810146817

Epoch: 5| Step: 2
Training loss: 2.4128560134606283
Validation loss: 2.4798312504140374

Epoch: 5| Step: 3
Training loss: 2.592545470939783
Validation loss: 2.4804552954606893

Epoch: 5| Step: 4
Training loss: 2.8124636329842794
Validation loss: 2.4773641230744152

Epoch: 5| Step: 5
Training loss: 2.6605772785963766
Validation loss: 2.480017869488342

Epoch: 5| Step: 6
Training loss: 3.026224906656633
Validation loss: 2.4777287994191304

Epoch: 5| Step: 7
Training loss: 2.3322844759200008
Validation loss: 2.4838328395208267

Epoch: 5| Step: 8
Training loss: 2.338062557313559
Validation loss: 2.5003214280833452

Epoch: 5| Step: 9
Training loss: 3.276331675943914
Validation loss: 2.4674930194461306

Epoch: 5| Step: 10
Training loss: 2.156300419756983
Validation loss: 2.4999212139799987

Epoch: 135| Step: 0
Training loss: 3.065379443429826
Validation loss: 2.4982330774464345

Epoch: 5| Step: 1
Training loss: 2.0959437250852813
Validation loss: 2.479751745026889

Epoch: 5| Step: 2
Training loss: 2.4371584139410296
Validation loss: 2.510081922492338

Epoch: 5| Step: 3
Training loss: 2.6946026295724623
Validation loss: 2.4989610902643267

Epoch: 5| Step: 4
Training loss: 2.2064497730270483
Validation loss: 2.4865476591604034

Epoch: 5| Step: 5
Training loss: 3.091385679680267
Validation loss: 2.5079785271804944

Epoch: 5| Step: 6
Training loss: 2.5193823008903493
Validation loss: 2.4564563001508883

Epoch: 5| Step: 7
Training loss: 2.064286007789218
Validation loss: 2.5175057129046072

Epoch: 5| Step: 8
Training loss: 2.9417907544585113
Validation loss: 2.5150573911495457

Epoch: 5| Step: 9
Training loss: 2.6192314706816724
Validation loss: 2.4830176133832236

Epoch: 5| Step: 10
Training loss: 3.088406659027972
Validation loss: 2.4949354226715106

Epoch: 136| Step: 0
Training loss: 2.4626034864958792
Validation loss: 2.4840999344453394

Epoch: 5| Step: 1
Training loss: 2.413351799997874
Validation loss: 2.51375348131663

Epoch: 5| Step: 2
Training loss: 2.5454455149478
Validation loss: 2.4874653277529184

Epoch: 5| Step: 3
Training loss: 2.354845258646349
Validation loss: 2.5205412661334905

Epoch: 5| Step: 4
Training loss: 2.5777619077296285
Validation loss: 2.4999948501533873

Epoch: 5| Step: 5
Training loss: 3.074702339962377
Validation loss: 2.5161632261931866

Epoch: 5| Step: 6
Training loss: 2.9645371913111482
Validation loss: 2.4956983053117887

Epoch: 5| Step: 7
Training loss: 2.492853057864227
Validation loss: 2.512255155807833

Epoch: 5| Step: 8
Training loss: 2.339063714994779
Validation loss: 2.511805110622985

Epoch: 5| Step: 9
Training loss: 3.0607520584240357
Validation loss: 2.4792866590344436

Epoch: 5| Step: 10
Training loss: 2.837012053223729
Validation loss: 2.4986271647195117

Epoch: 137| Step: 0
Training loss: 2.432733815512637
Validation loss: 2.499106790067089

Epoch: 5| Step: 1
Training loss: 2.396444281481292
Validation loss: 2.506888826867733

Epoch: 5| Step: 2
Training loss: 2.6665666283280807
Validation loss: 2.503428283534597

Epoch: 5| Step: 3
Training loss: 2.9403341702872794
Validation loss: 2.5207604526800664

Epoch: 5| Step: 4
Training loss: 2.884603962019777
Validation loss: 2.522633664185832

Epoch: 5| Step: 5
Training loss: 2.288420603459382
Validation loss: 2.5027176708531083

Epoch: 5| Step: 6
Training loss: 2.770853907764505
Validation loss: 2.487343607089207

Epoch: 5| Step: 7
Training loss: 2.068448822133426
Validation loss: 2.5085244328340472

Epoch: 5| Step: 8
Training loss: 2.831242650171976
Validation loss: 2.4827334490513002

Epoch: 5| Step: 9
Training loss: 3.1331750369837192
Validation loss: 2.47038593868918

Epoch: 5| Step: 10
Training loss: 2.3341222746265275
Validation loss: 2.5015743425787393

Epoch: 138| Step: 0
Training loss: 2.2558573669160435
Validation loss: 2.497356449685656

Epoch: 5| Step: 1
Training loss: 2.9618071635218186
Validation loss: 2.4999898038676722

Epoch: 5| Step: 2
Training loss: 2.073299685672307
Validation loss: 2.522630325783915

Epoch: 5| Step: 3
Training loss: 2.600241294081199
Validation loss: 2.511091818993883

Epoch: 5| Step: 4
Training loss: 2.660680598761661
Validation loss: 2.518439462484153

Epoch: 5| Step: 5
Training loss: 2.9668614855744377
Validation loss: 2.472247148211236

Epoch: 5| Step: 6
Training loss: 2.929287244793895
Validation loss: 2.4861070040503925

Epoch: 5| Step: 7
Training loss: 2.5760788629615012
Validation loss: 2.4923554906894285

Epoch: 5| Step: 8
Training loss: 2.134614399878684
Validation loss: 2.4989314215641683

Epoch: 5| Step: 9
Training loss: 3.236162806485948
Validation loss: 2.4898960270527244

Epoch: 5| Step: 10
Training loss: 2.4151241597547837
Validation loss: 2.5033922171888876

Epoch: 139| Step: 0
Training loss: 2.220390680320559
Validation loss: 2.496571608084141

Epoch: 5| Step: 1
Training loss: 2.95122454815254
Validation loss: 2.4503722585476857

Epoch: 5| Step: 2
Training loss: 2.3427379203161744
Validation loss: 2.508492084159587

Epoch: 5| Step: 3
Training loss: 2.3097620039701345
Validation loss: 2.5085435201243125

Epoch: 5| Step: 4
Training loss: 3.0147251506173243
Validation loss: 2.5005005766024575

Epoch: 5| Step: 5
Training loss: 2.664359604721458
Validation loss: 2.503306501849734

Epoch: 5| Step: 6
Training loss: 2.7413777517042526
Validation loss: 2.4945317217573635

Epoch: 5| Step: 7
Training loss: 2.630594015013752
Validation loss: 2.497393841188618

Epoch: 5| Step: 8
Training loss: 2.5285868822815516
Validation loss: 2.492813758421703

Epoch: 5| Step: 9
Training loss: 2.7522571144036307
Validation loss: 2.507140783090156

Epoch: 5| Step: 10
Training loss: 2.889198074749587
Validation loss: 2.486077222167089

Epoch: 140| Step: 0
Training loss: 3.089814582619524
Validation loss: 2.506086049949262

Epoch: 5| Step: 1
Training loss: 2.43504797040306
Validation loss: 2.4913285373116247

Epoch: 5| Step: 2
Training loss: 2.6574445843234438
Validation loss: 2.465167542790666

Epoch: 5| Step: 3
Training loss: 2.537950195815838
Validation loss: 2.508717061967841

Epoch: 5| Step: 4
Training loss: 2.1964366925983287
Validation loss: 2.473004356781466

Epoch: 5| Step: 5
Training loss: 3.461826046791934
Validation loss: 2.4961132301906757

Epoch: 5| Step: 6
Training loss: 2.531043244383182
Validation loss: 2.4860636381440133

Epoch: 5| Step: 7
Training loss: 2.3835760175307303
Validation loss: 2.5010575877515624

Epoch: 5| Step: 8
Training loss: 2.360048614744777
Validation loss: 2.4819250943472997

Epoch: 5| Step: 9
Training loss: 2.004868304334379
Validation loss: 2.502563141933908

Epoch: 5| Step: 10
Training loss: 3.042669122363389
Validation loss: 2.5126001884048357

Epoch: 141| Step: 0
Training loss: 1.999357954920298
Validation loss: 2.4748152722227386

Epoch: 5| Step: 1
Training loss: 2.6511071177698833
Validation loss: 2.5066889759392925

Epoch: 5| Step: 2
Training loss: 2.6450591469048477
Validation loss: 2.4915948374554033

Epoch: 5| Step: 3
Training loss: 3.2171038519946853
Validation loss: 2.4947182852223966

Epoch: 5| Step: 4
Training loss: 2.3158431759909157
Validation loss: 2.4949605982498984

Epoch: 5| Step: 5
Training loss: 3.2319046390364297
Validation loss: 2.489035599463049

Epoch: 5| Step: 6
Training loss: 2.4096700960128654
Validation loss: 2.496963776864454

Epoch: 5| Step: 7
Training loss: 2.652977397214193
Validation loss: 2.498604217171059

Epoch: 5| Step: 8
Training loss: 2.540356491182866
Validation loss: 2.4726998935514124

Epoch: 5| Step: 9
Training loss: 2.5511231361257867
Validation loss: 2.5000756447125356

Epoch: 5| Step: 10
Training loss: 2.4762252433575314
Validation loss: 2.5088549248425407

Epoch: 142| Step: 0
Training loss: 2.6290943367546125
Validation loss: 2.489835198049536

Epoch: 5| Step: 1
Training loss: 3.2250081675817874
Validation loss: 2.483006719770736

Epoch: 5| Step: 2
Training loss: 2.5666401609893463
Validation loss: 2.4821708758010232

Epoch: 5| Step: 3
Training loss: 2.703751507960167
Validation loss: 2.484803713621946

Epoch: 5| Step: 4
Training loss: 3.0029978079163806
Validation loss: 2.487649194525726

Epoch: 5| Step: 5
Training loss: 2.2838005543893285
Validation loss: 2.482906446939037

Epoch: 5| Step: 6
Training loss: 2.3826830219048305
Validation loss: 2.501480237548469

Epoch: 5| Step: 7
Training loss: 2.572132614045127
Validation loss: 2.4806495627086806

Epoch: 5| Step: 8
Training loss: 2.1704054876391012
Validation loss: 2.481244096216599

Epoch: 5| Step: 9
Training loss: 2.238192305204015
Validation loss: 2.5094477532046726

Epoch: 5| Step: 10
Training loss: 2.89771716274191
Validation loss: 2.5246342471156766

Epoch: 143| Step: 0
Training loss: 2.681187246161803
Validation loss: 2.48235513576395

Epoch: 5| Step: 1
Training loss: 2.8392563413075744
Validation loss: 2.501424730061775

Epoch: 5| Step: 2
Training loss: 2.6893063174800824
Validation loss: 2.4917601167078605

Epoch: 5| Step: 3
Training loss: 2.411235549116165
Validation loss: 2.495639486812516

Epoch: 5| Step: 4
Training loss: 2.4636427769198375
Validation loss: 2.5236048966572087

Epoch: 5| Step: 5
Training loss: 1.9364203859919984
Validation loss: 2.4914272477158637

Epoch: 5| Step: 6
Training loss: 2.300330022271749
Validation loss: 2.4973979185480335

Epoch: 5| Step: 7
Training loss: 3.3518219960730873
Validation loss: 2.5210090660024

Epoch: 5| Step: 8
Training loss: 2.179763847299215
Validation loss: 2.5161672283073195

Epoch: 5| Step: 9
Training loss: 2.831999764102991
Validation loss: 2.475316244011719

Epoch: 5| Step: 10
Training loss: 2.9371472410675037
Validation loss: 2.5218305033349617

Epoch: 144| Step: 0
Training loss: 2.6178182724316077
Validation loss: 2.486170897623599

Epoch: 5| Step: 1
Training loss: 2.408741540423802
Validation loss: 2.4974264208700565

Epoch: 5| Step: 2
Training loss: 2.6910582651034596
Validation loss: 2.5200992204467254

Epoch: 5| Step: 3
Training loss: 2.1043693772170897
Validation loss: 2.4980826203372892

Epoch: 5| Step: 4
Training loss: 2.9025331745995393
Validation loss: 2.483541054457526

Epoch: 5| Step: 5
Training loss: 3.032206905381131
Validation loss: 2.5106117364391944

Epoch: 5| Step: 6
Training loss: 2.112779709395504
Validation loss: 2.4915411022765968

Epoch: 5| Step: 7
Training loss: 3.5385233824246956
Validation loss: 2.488219587666003

Epoch: 5| Step: 8
Training loss: 2.1392810250141507
Validation loss: 2.490056985564692

Epoch: 5| Step: 9
Training loss: 2.266868618308551
Validation loss: 2.5109749273147766

Epoch: 5| Step: 10
Training loss: 2.7474008762018047
Validation loss: 2.5266468437427094

Epoch: 145| Step: 0
Training loss: 2.2611842339158197
Validation loss: 2.501886857586271

Epoch: 5| Step: 1
Training loss: 2.9356643135503466
Validation loss: 2.4980741158443083

Epoch: 5| Step: 2
Training loss: 2.0502876777698757
Validation loss: 2.511433337602591

Epoch: 5| Step: 3
Training loss: 3.0627455320997488
Validation loss: 2.499183816885582

Epoch: 5| Step: 4
Training loss: 2.6230241514629093
Validation loss: 2.470725827929715

Epoch: 5| Step: 5
Training loss: 1.6997728869253284
Validation loss: 2.5270902158414206

Epoch: 5| Step: 6
Training loss: 2.905242088853979
Validation loss: 2.494658235097927

Epoch: 5| Step: 7
Training loss: 3.013362529945151
Validation loss: 2.492492151054549

Epoch: 5| Step: 8
Training loss: 2.9311379872862853
Validation loss: 2.496544068967954

Epoch: 5| Step: 9
Training loss: 2.6748367758891245
Validation loss: 2.4705763230183533

Epoch: 5| Step: 10
Training loss: 2.419284936859007
Validation loss: 2.473937795107983

Epoch: 146| Step: 0
Training loss: 2.2471863850535234
Validation loss: 2.51499610600973

Epoch: 5| Step: 1
Training loss: 2.083608863412449
Validation loss: 2.4806647022670654

Epoch: 5| Step: 2
Training loss: 3.432669557521914
Validation loss: 2.4896763067553347

Epoch: 5| Step: 3
Training loss: 2.7109564964662236
Validation loss: 2.4991944789360265

Epoch: 5| Step: 4
Training loss: 2.777124495510061
Validation loss: 2.4967081249536425

Epoch: 5| Step: 5
Training loss: 2.88171746357202
Validation loss: 2.4908644210662767

Epoch: 5| Step: 6
Training loss: 2.3062420273723134
Validation loss: 2.491085433607652

Epoch: 5| Step: 7
Training loss: 2.60065341221609
Validation loss: 2.489820224940373

Epoch: 5| Step: 8
Training loss: 2.335981795997758
Validation loss: 2.5226529221563005

Epoch: 5| Step: 9
Training loss: 2.8341038348142416
Validation loss: 2.4900551086925296

Epoch: 5| Step: 10
Training loss: 2.4263094758453434
Validation loss: 2.5070704582424064

Epoch: 147| Step: 0
Training loss: 2.7359042877499418
Validation loss: 2.512059713931152

Epoch: 5| Step: 1
Training loss: 2.8593166324515824
Validation loss: 2.492976789368684

Epoch: 5| Step: 2
Training loss: 2.2765972818140745
Validation loss: 2.5049110986535386

Epoch: 5| Step: 3
Training loss: 2.5161875220253545
Validation loss: 2.5068717968135648

Epoch: 5| Step: 4
Training loss: 2.8304910615214856
Validation loss: 2.5002962121525605

Epoch: 5| Step: 5
Training loss: 2.8147341014163354
Validation loss: 2.4996775521736656

Epoch: 5| Step: 6
Training loss: 2.3894906937042197
Validation loss: 2.4903780076975655

Epoch: 5| Step: 7
Training loss: 2.3232971928912973
Validation loss: 2.5257239973031322

Epoch: 5| Step: 8
Training loss: 2.6284530271643662
Validation loss: 2.5151671579775274

Epoch: 5| Step: 9
Training loss: 2.9704400321636144
Validation loss: 2.5083930467731212

Epoch: 5| Step: 10
Training loss: 2.568018390952119
Validation loss: 2.4989115940176014

Epoch: 148| Step: 0
Training loss: 3.0214386081496647
Validation loss: 2.4843781070660134

Epoch: 5| Step: 1
Training loss: 3.4079163001621873
Validation loss: 2.502819155550862

Epoch: 5| Step: 2
Training loss: 2.7828674756488003
Validation loss: 2.507774282455647

Epoch: 5| Step: 3
Training loss: 2.276931542179566
Validation loss: 2.513079097445794

Epoch: 5| Step: 4
Training loss: 2.606012153292676
Validation loss: 2.5101769683973427

Epoch: 5| Step: 5
Training loss: 2.3320490390731687
Validation loss: 2.5246820439094435

Epoch: 5| Step: 6
Training loss: 2.2310663014079335
Validation loss: 2.487278417128737

Epoch: 5| Step: 7
Training loss: 2.235048632679364
Validation loss: 2.4846067077393816

Epoch: 5| Step: 8
Training loss: 2.9945545047341735
Validation loss: 2.506242730696293

Epoch: 5| Step: 9
Training loss: 2.679955116009991
Validation loss: 2.504533109569473

Epoch: 5| Step: 10
Training loss: 2.116197530565803
Validation loss: 2.5113169344665276

Epoch: 149| Step: 0
Training loss: 2.5330775692308993
Validation loss: 2.4851987854040947

Epoch: 5| Step: 1
Training loss: 2.117579575161489
Validation loss: 2.500337306207005

Epoch: 5| Step: 2
Training loss: 3.340358832722565
Validation loss: 2.5053793713806924

Epoch: 5| Step: 3
Training loss: 2.938774643976815
Validation loss: 2.4971848214073487

Epoch: 5| Step: 4
Training loss: 2.743439912761284
Validation loss: 2.4926101820406315

Epoch: 5| Step: 5
Training loss: 2.698336731796842
Validation loss: 2.487388931600509

Epoch: 5| Step: 6
Training loss: 2.0844968471343126
Validation loss: 2.4966647809452756

Epoch: 5| Step: 7
Training loss: 2.7781548583203715
Validation loss: 2.495808405863552

Epoch: 5| Step: 8
Training loss: 2.7509361754334822
Validation loss: 2.4801544034194514

Epoch: 5| Step: 9
Training loss: 2.1546763330603147
Validation loss: 2.4979276086560636

Epoch: 5| Step: 10
Training loss: 2.3908304363067865
Validation loss: 2.4869229462027733

Epoch: 150| Step: 0
Training loss: 2.4556892745067005
Validation loss: 2.5113357779921306

Epoch: 5| Step: 1
Training loss: 2.563618485654649
Validation loss: 2.480949014167174

Epoch: 5| Step: 2
Training loss: 2.3248083056107904
Validation loss: 2.502701695153001

Epoch: 5| Step: 3
Training loss: 2.027887231087882
Validation loss: 2.5084630156791463

Epoch: 5| Step: 4
Training loss: 2.924716485784015
Validation loss: 2.486983558321473

Epoch: 5| Step: 5
Training loss: 3.2265709237272757
Validation loss: 2.5057567048879106

Epoch: 5| Step: 6
Training loss: 2.6532982975197754
Validation loss: 2.4990581758534547

Epoch: 5| Step: 7
Training loss: 2.7093476572383994
Validation loss: 2.48477164112999

Epoch: 5| Step: 8
Training loss: 2.9563924484934807
Validation loss: 2.500084032676821

Epoch: 5| Step: 9
Training loss: 2.1357696489575377
Validation loss: 2.506244454285526

Epoch: 5| Step: 10
Training loss: 2.5960341358027113
Validation loss: 2.521846247049116

Epoch: 151| Step: 0
Training loss: 2.7459504916290873
Validation loss: 2.5116299499788948

Epoch: 5| Step: 1
Training loss: 2.360228529388097
Validation loss: 2.4900891238210083

Epoch: 5| Step: 2
Training loss: 2.057497604943477
Validation loss: 2.4913547917303203

Epoch: 5| Step: 3
Training loss: 2.4166136659093875
Validation loss: 2.518816089366129

Epoch: 5| Step: 4
Training loss: 2.4884720134820775
Validation loss: 2.491518269014898

Epoch: 5| Step: 5
Training loss: 2.495183118930767
Validation loss: 2.481791488196004

Epoch: 5| Step: 6
Training loss: 1.8124822418395283
Validation loss: 2.4886831330349515

Epoch: 5| Step: 7
Training loss: 3.238604889493163
Validation loss: 2.5205036799675042

Epoch: 5| Step: 8
Training loss: 3.0149092541350138
Validation loss: 2.5001388890643157

Epoch: 5| Step: 9
Training loss: 2.7914814009801
Validation loss: 2.503038379181855

Epoch: 5| Step: 10
Training loss: 3.1203202875505287
Validation loss: 2.4993339830691808

Epoch: 152| Step: 0
Training loss: 2.473211385834417
Validation loss: 2.515686363572918

Epoch: 5| Step: 1
Training loss: 2.339717804284637
Validation loss: 2.5091308076910623

Epoch: 5| Step: 2
Training loss: 2.533704721265481
Validation loss: 2.499808767654667

Epoch: 5| Step: 3
Training loss: 2.9969409605211794
Validation loss: 2.517764504011548

Epoch: 5| Step: 4
Training loss: 2.073543690173562
Validation loss: 2.5100903331920343

Epoch: 5| Step: 5
Training loss: 2.5538003763616075
Validation loss: 2.5206996357168556

Epoch: 5| Step: 6
Training loss: 2.637892714637574
Validation loss: 2.5198839695432778

Epoch: 5| Step: 7
Training loss: 3.0087936584576225
Validation loss: 2.5224452331940093

Epoch: 5| Step: 8
Training loss: 2.780599539484374
Validation loss: 2.4951273860770726

Epoch: 5| Step: 9
Training loss: 2.9432101651691442
Validation loss: 2.5078406764405754

Epoch: 5| Step: 10
Training loss: 2.337353229504757
Validation loss: 2.5105398075819267

Epoch: 153| Step: 0
Training loss: 2.2975826081709507
Validation loss: 2.4907210397717807

Epoch: 5| Step: 1
Training loss: 2.0659326829163134
Validation loss: 2.487433957431957

Epoch: 5| Step: 2
Training loss: 2.5453505370949308
Validation loss: 2.5055516375107607

Epoch: 5| Step: 3
Training loss: 2.6799179289478245
Validation loss: 2.50572166140867

Epoch: 5| Step: 4
Training loss: 2.7700504736312737
Validation loss: 2.4934659087292745

Epoch: 5| Step: 5
Training loss: 2.984432519488237
Validation loss: 2.4996448490181638

Epoch: 5| Step: 6
Training loss: 2.500184147728421
Validation loss: 2.51141819927316

Epoch: 5| Step: 7
Training loss: 2.5765988543405363
Validation loss: 2.500675641304121

Epoch: 5| Step: 8
Training loss: 3.204501419207538
Validation loss: 2.486285596089619

Epoch: 5| Step: 9
Training loss: 2.0749178353093676
Validation loss: 2.5142991201061746

Epoch: 5| Step: 10
Training loss: 2.7584806070646937
Validation loss: 2.5082902412063985

Epoch: 154| Step: 0
Training loss: 2.7847259745542168
Validation loss: 2.493983007152474

Epoch: 5| Step: 1
Training loss: 1.8696024452741937
Validation loss: 2.4944789609230757

Epoch: 5| Step: 2
Training loss: 2.552831039408088
Validation loss: 2.5084874842020453

Epoch: 5| Step: 3
Training loss: 2.696235653446036
Validation loss: 2.4915060440637533

Epoch: 5| Step: 4
Training loss: 2.910180827811482
Validation loss: 2.5019249273397413

Epoch: 5| Step: 5
Training loss: 2.762812245531505
Validation loss: 2.48428176144596

Epoch: 5| Step: 6
Training loss: 2.496772399245725
Validation loss: 2.505960002032851

Epoch: 5| Step: 7
Training loss: 2.4444579559973856
Validation loss: 2.5160841107927006

Epoch: 5| Step: 8
Training loss: 2.486875223647283
Validation loss: 2.5109827622586183

Epoch: 5| Step: 9
Training loss: 2.713196179050082
Validation loss: 2.5058616605115596

Epoch: 5| Step: 10
Training loss: 3.001670690092885
Validation loss: 2.4920417310200857

Epoch: 155| Step: 0
Training loss: 2.8886997719346827
Validation loss: 2.5120657279267973

Epoch: 5| Step: 1
Training loss: 2.2207690441376164
Validation loss: 2.4924103968335527

Epoch: 5| Step: 2
Training loss: 2.651470596797859
Validation loss: 2.515046261203114

Epoch: 5| Step: 3
Training loss: 2.611227143417256
Validation loss: 2.5019083246005507

Epoch: 5| Step: 4
Training loss: 3.0543743470598916
Validation loss: 2.514343483570768

Epoch: 5| Step: 5
Training loss: 2.5336935234832887
Validation loss: 2.504829833695335

Epoch: 5| Step: 6
Training loss: 2.6140575310841707
Validation loss: 2.5243901931612633

Epoch: 5| Step: 7
Training loss: 2.6828726920038983
Validation loss: 2.500500557122689

Epoch: 5| Step: 8
Training loss: 2.741895089494347
Validation loss: 2.486884659166202

Epoch: 5| Step: 9
Training loss: 2.3212652337596893
Validation loss: 2.50443859365998

Epoch: 5| Step: 10
Training loss: 2.3879866658258604
Validation loss: 2.5074471303468497

Epoch: 156| Step: 0
Training loss: 2.8884841827017613
Validation loss: 2.502253950963978

Epoch: 5| Step: 1
Training loss: 2.7059926604448408
Validation loss: 2.5024161097470765

Epoch: 5| Step: 2
Training loss: 2.534737621475426
Validation loss: 2.530177800953699

Epoch: 5| Step: 3
Training loss: 2.440054899442322
Validation loss: 2.503026525954365

Epoch: 5| Step: 4
Training loss: 2.54984442666395
Validation loss: 2.5175583312775833

Epoch: 5| Step: 5
Training loss: 2.4987406419709512
Validation loss: 2.5035333239725395

Epoch: 5| Step: 6
Training loss: 2.263900837414914
Validation loss: 2.506729435433737

Epoch: 5| Step: 7
Training loss: 2.8167703210692374
Validation loss: 2.4986699965698165

Epoch: 5| Step: 8
Training loss: 2.822735788854352
Validation loss: 2.498639483081384

Epoch: 5| Step: 9
Training loss: 2.48990222585744
Validation loss: 2.4889325690843536

Epoch: 5| Step: 10
Training loss: 2.8579623375473924
Validation loss: 2.5204325897868913

Epoch: 157| Step: 0
Training loss: 2.7145851945224178
Validation loss: 2.4927482991115726

Epoch: 5| Step: 1
Training loss: 2.2773702368005706
Validation loss: 2.5102619798669363

Epoch: 5| Step: 2
Training loss: 3.102930185401153
Validation loss: 2.5090326772994755

Epoch: 5| Step: 3
Training loss: 2.6603429339494182
Validation loss: 2.4735964205427914

Epoch: 5| Step: 4
Training loss: 2.9400255425310275
Validation loss: 2.4961840496271446

Epoch: 5| Step: 5
Training loss: 2.2398729240611805
Validation loss: 2.4965885718272505

Epoch: 5| Step: 6
Training loss: 2.5156353304633097
Validation loss: 2.5196016615167163

Epoch: 5| Step: 7
Training loss: 2.3377182720904433
Validation loss: 2.496718170199073

Epoch: 5| Step: 8
Training loss: 2.3722185612317
Validation loss: 2.522748179367283

Epoch: 5| Step: 9
Training loss: 2.551869742869003
Validation loss: 2.476069782724594

Epoch: 5| Step: 10
Training loss: 2.9777323509028277
Validation loss: 2.485239330165347

Epoch: 158| Step: 0
Training loss: 2.1674432340974166
Validation loss: 2.490448692729776

Epoch: 5| Step: 1
Training loss: 2.3749578371822846
Validation loss: 2.525309109476777

Epoch: 5| Step: 2
Training loss: 2.69358597895545
Validation loss: 2.4822936081665796

Epoch: 5| Step: 3
Training loss: 2.651706714563478
Validation loss: 2.494789244961703

Epoch: 5| Step: 4
Training loss: 2.9211090226244734
Validation loss: 2.4966168882883815

Epoch: 5| Step: 5
Training loss: 2.7754303126010895
Validation loss: 2.490986067458216

Epoch: 5| Step: 6
Training loss: 2.467138802819065
Validation loss: 2.502882046853661

Epoch: 5| Step: 7
Training loss: 2.813256225644136
Validation loss: 2.49758494023857

Epoch: 5| Step: 8
Training loss: 2.6121872235565093
Validation loss: 2.4890335848341247

Epoch: 5| Step: 9
Training loss: 2.471881377432562
Validation loss: 2.4883192414958395

Epoch: 5| Step: 10
Training loss: 2.704744416182897
Validation loss: 2.499433379411426

Epoch: 159| Step: 0
Training loss: 2.8807292740750032
Validation loss: 2.5044980766070144

Epoch: 5| Step: 1
Training loss: 1.996557909604532
Validation loss: 2.503468324669988

Epoch: 5| Step: 2
Training loss: 3.09046715621641
Validation loss: 2.502819958602865

Epoch: 5| Step: 3
Training loss: 2.455828980527329
Validation loss: 2.508116541040893

Epoch: 5| Step: 4
Training loss: 2.6071970181895527
Validation loss: 2.5154138322424253

Epoch: 5| Step: 5
Training loss: 2.609521736085192
Validation loss: 2.495954098658308

Epoch: 5| Step: 6
Training loss: 2.412800480605515
Validation loss: 2.500592871066996

Epoch: 5| Step: 7
Training loss: 2.7210076265070486
Validation loss: 2.494278735438318

Epoch: 5| Step: 8
Training loss: 2.200566747664177
Validation loss: 2.505011287895722

Epoch: 5| Step: 9
Training loss: 2.9780772602622014
Validation loss: 2.504057913362401

Epoch: 5| Step: 10
Training loss: 2.4589039953788334
Validation loss: 2.4992511848112144

Epoch: 160| Step: 0
Training loss: 2.7360788322993175
Validation loss: 2.501739128792447

Epoch: 5| Step: 1
Training loss: 2.7840340213944037
Validation loss: 2.493803347251543

Epoch: 5| Step: 2
Training loss: 2.755638411089768
Validation loss: 2.4796249715390206

Epoch: 5| Step: 3
Training loss: 2.2188903334389045
Validation loss: 2.5002132386357427

Epoch: 5| Step: 4
Training loss: 2.30265817038878
Validation loss: 2.4991931618254655

Epoch: 5| Step: 5
Training loss: 2.637619203883924
Validation loss: 2.5033448741371487

Epoch: 5| Step: 6
Training loss: 3.134149965097896
Validation loss: 2.479536113440313

Epoch: 5| Step: 7
Training loss: 2.2602542754408046
Validation loss: 2.475740398188416

Epoch: 5| Step: 8
Training loss: 2.3796712212309465
Validation loss: 2.4898730639015305

Epoch: 5| Step: 9
Training loss: 2.75647363771827
Validation loss: 2.498208003601163

Epoch: 5| Step: 10
Training loss: 2.567015971735569
Validation loss: 2.503646388908276

Epoch: 161| Step: 0
Training loss: 2.1334327103396347
Validation loss: 2.4939480089648742

Epoch: 5| Step: 1
Training loss: 2.679264669173329
Validation loss: 2.509413255729319

Epoch: 5| Step: 2
Training loss: 2.414661024641372
Validation loss: 2.507307613420981

Epoch: 5| Step: 3
Training loss: 2.5513806887417405
Validation loss: 2.4843377775939515

Epoch: 5| Step: 4
Training loss: 2.8645920816923707
Validation loss: 2.498323723547162

Epoch: 5| Step: 5
Training loss: 2.939614042522273
Validation loss: 2.517119422166622

Epoch: 5| Step: 6
Training loss: 2.073837331412627
Validation loss: 2.5111731998245848

Epoch: 5| Step: 7
Training loss: 3.055402979268472
Validation loss: 2.505575745658902

Epoch: 5| Step: 8
Training loss: 2.542229564016288
Validation loss: 2.514882076793917

Epoch: 5| Step: 9
Training loss: 2.7106551757146127
Validation loss: 2.525954865483534

Epoch: 5| Step: 10
Training loss: 2.352165068925778
Validation loss: 2.5188242622537773

Epoch: 162| Step: 0
Training loss: 2.7373516338676227
Validation loss: 2.5051319137179977

Epoch: 5| Step: 1
Training loss: 2.748882933798387
Validation loss: 2.488349246898065

Epoch: 5| Step: 2
Training loss: 2.6862700553276744
Validation loss: 2.491281459978461

Epoch: 5| Step: 3
Training loss: 2.7168260980017562
Validation loss: 2.536484221023344

Epoch: 5| Step: 4
Training loss: 2.4931713302870957
Validation loss: 2.515223132740774

Epoch: 5| Step: 5
Training loss: 2.8157840628790107
Validation loss: 2.516332647191579

Epoch: 5| Step: 6
Training loss: 2.4761182705513685
Validation loss: 2.5222373736512522

Epoch: 5| Step: 7
Training loss: 2.256898899759977
Validation loss: 2.505204096084814

Epoch: 5| Step: 8
Training loss: 2.213746675459758
Validation loss: 2.5074805598848355

Epoch: 5| Step: 9
Training loss: 2.5592243378464854
Validation loss: 2.4988859770910423

Epoch: 5| Step: 10
Training loss: 2.8079210942857027
Validation loss: 2.484998283643962

Epoch: 163| Step: 0
Training loss: 2.7653044606463864
Validation loss: 2.507210270577092

Epoch: 5| Step: 1
Training loss: 2.3928569273145373
Validation loss: 2.4972111692728496

Epoch: 5| Step: 2
Training loss: 2.6487507592668655
Validation loss: 2.498510359909355

Epoch: 5| Step: 3
Training loss: 2.6491869200917946
Validation loss: 2.5129327182962844

Epoch: 5| Step: 4
Training loss: 2.8758800652317142
Validation loss: 2.511687679535892

Epoch: 5| Step: 5
Training loss: 2.657269719680082
Validation loss: 2.4922053432606988

Epoch: 5| Step: 6
Training loss: 3.118315299094277
Validation loss: 2.5072868327046796

Epoch: 5| Step: 7
Training loss: 2.4721110196290907
Validation loss: 2.4888932159778574

Epoch: 5| Step: 8
Training loss: 1.5357444354674823
Validation loss: 2.4989699692622303

Epoch: 5| Step: 9
Training loss: 2.6378858455805028
Validation loss: 2.502218630979376

Epoch: 5| Step: 10
Training loss: 2.5800189835197465
Validation loss: 2.5207241146218284

Epoch: 164| Step: 0
Training loss: 2.975288338672773
Validation loss: 2.507420431995564

Epoch: 5| Step: 1
Training loss: 2.2570353823868583
Validation loss: 2.5102579622104484

Epoch: 5| Step: 2
Training loss: 2.6962495363648022
Validation loss: 2.510927086049623

Epoch: 5| Step: 3
Training loss: 2.3780206243841406
Validation loss: 2.4793991468636842

Epoch: 5| Step: 4
Training loss: 2.433353320348862
Validation loss: 2.506478303155695

Epoch: 5| Step: 5
Training loss: 2.286780668462342
Validation loss: 2.498556062596305

Epoch: 5| Step: 6
Training loss: 3.0425402984834085
Validation loss: 2.5072959603314025

Epoch: 5| Step: 7
Training loss: 2.7418176993962255
Validation loss: 2.478761831395815

Epoch: 5| Step: 8
Training loss: 2.6442302042286943
Validation loss: 2.471360354752534

Epoch: 5| Step: 9
Training loss: 2.3376663597596647
Validation loss: 2.5059671334768594

Epoch: 5| Step: 10
Training loss: 2.6852042572640094
Validation loss: 2.490003563649846

Epoch: 165| Step: 0
Training loss: 2.745919407917026
Validation loss: 2.506474305004495

Epoch: 5| Step: 1
Training loss: 2.5286582582419275
Validation loss: 2.507891425538319

Epoch: 5| Step: 2
Training loss: 1.7997528250844714
Validation loss: 2.507398812799102

Epoch: 5| Step: 3
Training loss: 2.38225771589708
Validation loss: 2.4844732065848736

Epoch: 5| Step: 4
Training loss: 2.305924216316322
Validation loss: 2.497398506746614

Epoch: 5| Step: 5
Training loss: 2.692009712853559
Validation loss: 2.487425214010452

Epoch: 5| Step: 6
Training loss: 2.436116926572212
Validation loss: 2.512053213125503

Epoch: 5| Step: 7
Training loss: 2.9016212601224898
Validation loss: 2.51856906989841

Epoch: 5| Step: 8
Training loss: 2.645154149948495
Validation loss: 2.5118317531837286

Epoch: 5| Step: 9
Training loss: 3.209927513753961
Validation loss: 2.512636117477955

Epoch: 5| Step: 10
Training loss: 2.4180657732452677
Validation loss: 2.5281341570010167

Epoch: 166| Step: 0
Training loss: 1.9225640031059612
Validation loss: 2.517151944121367

Epoch: 5| Step: 1
Training loss: 2.90387998358152
Validation loss: 2.4873574953839412

Epoch: 5| Step: 2
Training loss: 1.773188838246551
Validation loss: 2.525413408837994

Epoch: 5| Step: 3
Training loss: 2.9897382388151144
Validation loss: 2.5044211190602508

Epoch: 5| Step: 4
Training loss: 2.739504292052545
Validation loss: 2.5326495345784306

Epoch: 5| Step: 5
Training loss: 2.856417434425925
Validation loss: 2.5166185185629937

Epoch: 5| Step: 6
Training loss: 3.344492892156967
Validation loss: 2.488647775997559

Epoch: 5| Step: 7
Training loss: 2.4928599439957346
Validation loss: 2.497833112728914

Epoch: 5| Step: 8
Training loss: 2.505204029568619
Validation loss: 2.505319119386613

Epoch: 5| Step: 9
Training loss: 1.9860687236516108
Validation loss: 2.4992066816656675

Epoch: 5| Step: 10
Training loss: 2.5128232150210508
Validation loss: 2.508433077132528

Epoch: 167| Step: 0
Training loss: 2.938550882867052
Validation loss: 2.4964330627686766

Epoch: 5| Step: 1
Training loss: 2.7533629402280657
Validation loss: 2.5141996792738497

Epoch: 5| Step: 2
Training loss: 2.3533399587579384
Validation loss: 2.5091557049522484

Epoch: 5| Step: 3
Training loss: 2.8732787245527165
Validation loss: 2.502012588140049

Epoch: 5| Step: 4
Training loss: 2.608701150653407
Validation loss: 2.4995127849197853

Epoch: 5| Step: 5
Training loss: 2.641572680641556
Validation loss: 2.5007293560162105

Epoch: 5| Step: 6
Training loss: 2.6093179845006014
Validation loss: 2.4923659237727662

Epoch: 5| Step: 7
Training loss: 2.257389860624239
Validation loss: 2.4937328364658278

Epoch: 5| Step: 8
Training loss: 2.5871330332721865
Validation loss: 2.526040417681784

Epoch: 5| Step: 9
Training loss: 2.128344652488838
Validation loss: 2.513199383981422

Epoch: 5| Step: 10
Training loss: 2.6741770146796684
Validation loss: 2.475926674320882

Epoch: 168| Step: 0
Training loss: 2.5436342367688494
Validation loss: 2.512421861834569

Epoch: 5| Step: 1
Training loss: 2.7871289643506127
Validation loss: 2.5158476942738397

Epoch: 5| Step: 2
Training loss: 2.921111634437679
Validation loss: 2.4974103435720276

Epoch: 5| Step: 3
Training loss: 2.319424032044073
Validation loss: 2.5144398640941987

Epoch: 5| Step: 4
Training loss: 3.1279920368727376
Validation loss: 2.4898699297148448

Epoch: 5| Step: 5
Training loss: 2.639006982358287
Validation loss: 2.5075500941863895

Epoch: 5| Step: 6
Training loss: 2.739090956231649
Validation loss: 2.5137033288850326

Epoch: 5| Step: 7
Training loss: 2.2567541684532357
Validation loss: 2.4783914177212036

Epoch: 5| Step: 8
Training loss: 2.7533853674059707
Validation loss: 2.4904990324341516

Epoch: 5| Step: 9
Training loss: 2.1480310783908387
Validation loss: 2.523279705604522

Epoch: 5| Step: 10
Training loss: 2.0631512856275167
Validation loss: 2.5178071319810353

Epoch: 169| Step: 0
Training loss: 1.946197982318347
Validation loss: 2.52313930230657

Epoch: 5| Step: 1
Training loss: 3.2128944837552815
Validation loss: 2.514161865744144

Epoch: 5| Step: 2
Training loss: 2.2766028322772107
Validation loss: 2.4919167987932576

Epoch: 5| Step: 3
Training loss: 2.5556116328329495
Validation loss: 2.532255542447671

Epoch: 5| Step: 4
Training loss: 2.669713088203981
Validation loss: 2.520540144272766

Epoch: 5| Step: 5
Training loss: 3.039510738001796
Validation loss: 2.4981955527846984

Epoch: 5| Step: 6
Training loss: 2.765122017677347
Validation loss: 2.515887469478738

Epoch: 5| Step: 7
Training loss: 2.349144792169618
Validation loss: 2.5077863320088247

Epoch: 5| Step: 8
Training loss: 2.5394371343208086
Validation loss: 2.508472818651234

Epoch: 5| Step: 9
Training loss: 1.7667746387931984
Validation loss: 2.49556046451014

Epoch: 5| Step: 10
Training loss: 3.025198647778441
Validation loss: 2.486171781327787

Epoch: 170| Step: 0
Training loss: 3.4404619807152454
Validation loss: 2.496905549795138

Epoch: 5| Step: 1
Training loss: 2.608598330831604
Validation loss: 2.517761567460535

Epoch: 5| Step: 2
Training loss: 2.507207779748236
Validation loss: 2.494979337198613

Epoch: 5| Step: 3
Training loss: 2.0997541510768825
Validation loss: 2.5154703559340734

Epoch: 5| Step: 4
Training loss: 2.5749311604603373
Validation loss: 2.4948727749559776

Epoch: 5| Step: 5
Training loss: 2.4111900647250435
Validation loss: 2.515319795513639

Epoch: 5| Step: 6
Training loss: 2.5705499510379584
Validation loss: 2.5130768389005205

Epoch: 5| Step: 7
Training loss: 2.459208725927554
Validation loss: 2.5048255770427192

Epoch: 5| Step: 8
Training loss: 2.5881635874617057
Validation loss: 2.502396424552287

Epoch: 5| Step: 9
Training loss: 2.2655688048661244
Validation loss: 2.5129675745029303

Epoch: 5| Step: 10
Training loss: 2.71077197886036
Validation loss: 2.5232658158928456

Epoch: 171| Step: 0
Training loss: 1.880950957194842
Validation loss: 2.5031512764911175

Epoch: 5| Step: 1
Training loss: 2.570419633945783
Validation loss: 2.5180648806283377

Epoch: 5| Step: 2
Training loss: 2.7713508600679937
Validation loss: 2.527770951873471

Epoch: 5| Step: 3
Training loss: 2.6972602330401845
Validation loss: 2.501922563431186

Epoch: 5| Step: 4
Training loss: 2.782180630434295
Validation loss: 2.507686000103923

Epoch: 5| Step: 5
Training loss: 2.9257458836209445
Validation loss: 2.503095936132475

Epoch: 5| Step: 6
Training loss: 2.3343098050452036
Validation loss: 2.4999582810151155

Epoch: 5| Step: 7
Training loss: 3.1338452090151776
Validation loss: 2.5036023417392586

Epoch: 5| Step: 8
Training loss: 1.908755422608193
Validation loss: 2.4979509898731234

Epoch: 5| Step: 9
Training loss: 2.7497801259313075
Validation loss: 2.5015133625129375

Epoch: 5| Step: 10
Training loss: 2.401341174815901
Validation loss: 2.5266824396508922

Epoch: 172| Step: 0
Training loss: 2.986550541760305
Validation loss: 2.4989137289206114

Epoch: 5| Step: 1
Training loss: 2.6439054078222
Validation loss: 2.501840286340521

Epoch: 5| Step: 2
Training loss: 2.667179108099761
Validation loss: 2.4919953060141165

Epoch: 5| Step: 3
Training loss: 3.1066318085424376
Validation loss: 2.510475941933769

Epoch: 5| Step: 4
Training loss: 2.620874159777451
Validation loss: 2.5138232000602203

Epoch: 5| Step: 5
Training loss: 2.3041387389584727
Validation loss: 2.523024561013879

Epoch: 5| Step: 6
Training loss: 2.3624089420269505
Validation loss: 2.477454816663404

Epoch: 5| Step: 7
Training loss: 2.6743329437507892
Validation loss: 2.5008918566011142

Epoch: 5| Step: 8
Training loss: 2.2840869977720013
Validation loss: 2.492224286026798

Epoch: 5| Step: 9
Training loss: 2.5236546095287684
Validation loss: 2.4705240571497837

Epoch: 5| Step: 10
Training loss: 1.7796040342081567
Validation loss: 2.5066689520268874

Epoch: 173| Step: 0
Training loss: 2.5751097646484493
Validation loss: 2.50707504648402

Epoch: 5| Step: 1
Training loss: 2.3511968689613743
Validation loss: 2.5030514470619782

Epoch: 5| Step: 2
Training loss: 1.4853515625
Validation loss: 2.5151307472628917

Epoch: 5| Step: 3
Training loss: 2.6455830633388993
Validation loss: 2.480890686100145

Epoch: 5| Step: 4
Training loss: 2.40458056513904
Validation loss: 2.526742196425651

Epoch: 5| Step: 5
Training loss: 3.2417234525307657
Validation loss: 2.485263148982194

Epoch: 5| Step: 6
Training loss: 3.286378032269551
Validation loss: 2.507943561768344

Epoch: 5| Step: 7
Training loss: 2.437670383856191
Validation loss: 2.5000061096608968

Epoch: 5| Step: 8
Training loss: 3.269894961382044
Validation loss: 2.5033754715940137

Epoch: 5| Step: 9
Training loss: 2.019161935827759
Validation loss: 2.5111389179836636

Epoch: 5| Step: 10
Training loss: 1.827950624153859
Validation loss: 2.5147803892550105

Epoch: 174| Step: 0
Training loss: 2.673792279423257
Validation loss: 2.5194428779688924

Epoch: 5| Step: 1
Training loss: 2.8301426555682134
Validation loss: 2.508342331331294

Epoch: 5| Step: 2
Training loss: 1.7092884774077848
Validation loss: 2.5368110088293006

Epoch: 5| Step: 3
Training loss: 3.300172142394029
Validation loss: 2.535852471113343

Epoch: 5| Step: 4
Training loss: 2.53317244253055
Validation loss: 2.510840118345561

Epoch: 5| Step: 5
Training loss: 2.410669800685995
Validation loss: 2.5220878413159094

Epoch: 5| Step: 6
Training loss: 2.3436687201075572
Validation loss: 2.5382019553556345

Epoch: 5| Step: 7
Training loss: 2.644858854165846
Validation loss: 2.527899854195063

Epoch: 5| Step: 8
Training loss: 2.9215657279608496
Validation loss: 2.506015720566524

Epoch: 5| Step: 9
Training loss: 2.388366829459107
Validation loss: 2.5311516687356455

Epoch: 5| Step: 10
Training loss: 2.248667640386499
Validation loss: 2.5154577653282657

Epoch: 175| Step: 0
Training loss: 3.067277412826216
Validation loss: 2.4908348998528873

Epoch: 5| Step: 1
Training loss: 3.036071403719195
Validation loss: 2.5112086878769726

Epoch: 5| Step: 2
Training loss: 2.2394919325045968
Validation loss: 2.5143129828807798

Epoch: 5| Step: 3
Training loss: 2.322997520875696
Validation loss: 2.4957200166190674

Epoch: 5| Step: 4
Training loss: 2.363286395106744
Validation loss: 2.5308216967717954

Epoch: 5| Step: 5
Training loss: 2.829910810433312
Validation loss: 2.508844314065333

Epoch: 5| Step: 6
Training loss: 2.5371063678773558
Validation loss: 2.51648705489487

Epoch: 5| Step: 7
Training loss: 1.9995814719976097
Validation loss: 2.51031682166482

Epoch: 5| Step: 8
Training loss: 2.4493895840727764
Validation loss: 2.5053210011961284

Epoch: 5| Step: 9
Training loss: 2.5367785701389107
Validation loss: 2.5308393334909822

Epoch: 5| Step: 10
Training loss: 2.877239681767984
Validation loss: 2.499046566364431

Testing loss: 2.451886684556162
