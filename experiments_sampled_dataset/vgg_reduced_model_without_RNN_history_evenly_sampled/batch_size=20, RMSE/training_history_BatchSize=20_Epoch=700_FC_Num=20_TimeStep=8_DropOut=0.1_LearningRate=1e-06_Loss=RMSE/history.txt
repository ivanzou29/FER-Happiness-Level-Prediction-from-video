Epoch: 1| Step: 0
Training loss: 6.975170513516279
Validation loss: 7.293549241956243

Epoch: 5| Step: 1
Training loss: 7.528357492469644
Validation loss: 7.290517482880168

Epoch: 5| Step: 2
Training loss: 6.797590546925605
Validation loss: 7.289354819117341

Epoch: 5| Step: 3
Training loss: 6.434200293015794
Validation loss: 7.286647527805213

Epoch: 5| Step: 4
Training loss: 7.4930453798800265
Validation loss: 7.2848867915786775

Epoch: 5| Step: 5
Training loss: 7.851478447155818
Validation loss: 7.281347868535079

Epoch: 5| Step: 6
Training loss: 6.964019675291117
Validation loss: 7.279654832897187

Epoch: 5| Step: 7
Training loss: 7.591465735960591
Validation loss: 7.279045846288358

Epoch: 5| Step: 8
Training loss: 7.612559441395469
Validation loss: 7.277190569904891

Epoch: 5| Step: 9
Training loss: 7.276945094002225
Validation loss: 7.273420956629178

Epoch: 5| Step: 10
Training loss: 7.263613055186689
Validation loss: 7.270675507497444

Epoch: 2| Step: 0
Training loss: 7.779640613482809
Validation loss: 7.269864998384749

Epoch: 5| Step: 1
Training loss: 6.896501798777905
Validation loss: 7.2673478036000905

Epoch: 5| Step: 2
Training loss: 7.444266438926048
Validation loss: 7.26572823329294

Epoch: 5| Step: 3
Training loss: 7.7569108729108915
Validation loss: 7.262940024018938

Epoch: 5| Step: 4
Training loss: 6.823869369812814
Validation loss: 7.261910863438957

Epoch: 5| Step: 5
Training loss: 6.40982953063624
Validation loss: 7.260471830765952

Epoch: 5| Step: 6
Training loss: 6.7660098065545675
Validation loss: 7.25818532362361

Epoch: 5| Step: 7
Training loss: 7.981006486563848
Validation loss: 7.25582135483588

Epoch: 5| Step: 8
Training loss: 6.239096935166679
Validation loss: 7.253970989718763

Epoch: 5| Step: 9
Training loss: 7.8844479999345465
Validation loss: 7.2513395351307555

Epoch: 5| Step: 10
Training loss: 7.448074645032014
Validation loss: 7.247042314662953

Epoch: 3| Step: 0
Training loss: 7.5740391993771174
Validation loss: 7.249000537001835

Epoch: 5| Step: 1
Training loss: 7.893277226755561
Validation loss: 7.245705073191703

Epoch: 5| Step: 2
Training loss: 7.329546499756301
Validation loss: 7.2421235838150375

Epoch: 5| Step: 3
Training loss: 6.492218641810086
Validation loss: 7.240150071703513

Epoch: 5| Step: 4
Training loss: 7.826635161839535
Validation loss: 7.238504840592225

Epoch: 5| Step: 5
Training loss: 6.77426026307053
Validation loss: 7.236315226592157

Epoch: 5| Step: 6
Training loss: 7.477202544524637
Validation loss: 7.233908297545704

Epoch: 5| Step: 7
Training loss: 6.596872467228463
Validation loss: 7.230488548646816

Epoch: 5| Step: 8
Training loss: 7.990456133487712
Validation loss: 7.229589354588111

Epoch: 5| Step: 9
Training loss: 6.433081434519857
Validation loss: 7.228000029572728

Epoch: 5| Step: 10
Training loss: 6.6907851091779404
Validation loss: 7.223547548158128

Epoch: 4| Step: 0
Training loss: 6.667603172645407
Validation loss: 7.222805628891771

Epoch: 5| Step: 1
Training loss: 8.275850428649784
Validation loss: 7.2195657475966994

Epoch: 5| Step: 2
Training loss: 6.982185583851503
Validation loss: 7.217745075968746

Epoch: 5| Step: 3
Training loss: 6.895305263741104
Validation loss: 7.21523037131566

Epoch: 5| Step: 4
Training loss: 6.992343257256105
Validation loss: 7.214812105783018

Epoch: 5| Step: 5
Training loss: 7.858835251098362
Validation loss: 7.212131431666857

Epoch: 5| Step: 6
Training loss: 7.655719847716395
Validation loss: 7.208486473462164

Epoch: 5| Step: 7
Training loss: 7.4718391701586295
Validation loss: 7.207399168221314

Epoch: 5| Step: 8
Training loss: 6.688380103265791
Validation loss: 7.204582088513808

Epoch: 5| Step: 9
Training loss: 6.975324736661711
Validation loss: 7.20153036420379

Epoch: 5| Step: 10
Training loss: 6.31352331346283
Validation loss: 7.199341922456113

Epoch: 5| Step: 0
Training loss: 6.806785496575217
Validation loss: 7.197206060154411

Epoch: 5| Step: 1
Training loss: 6.230733855057411
Validation loss: 7.195379337436244

Epoch: 5| Step: 2
Training loss: 7.704629809121621
Validation loss: 7.193845810809928

Epoch: 5| Step: 3
Training loss: 7.0062266312821135
Validation loss: 7.190220240751805

Epoch: 5| Step: 4
Training loss: 7.130009011454191
Validation loss: 7.188656225027393

Epoch: 5| Step: 5
Training loss: 6.920401457238279
Validation loss: 7.184605460477012

Epoch: 5| Step: 6
Training loss: 6.921232103238866
Validation loss: 7.182122286126137

Epoch: 5| Step: 7
Training loss: 7.780216991075677
Validation loss: 7.17930425237679

Epoch: 5| Step: 8
Training loss: 7.985332872001026
Validation loss: 7.177255991299879

Epoch: 5| Step: 9
Training loss: 6.937960222804874
Validation loss: 7.173596663354385

Epoch: 5| Step: 10
Training loss: 7.248663417340512
Validation loss: 7.171500268924051

Epoch: 6| Step: 0
Training loss: 6.861776500703405
Validation loss: 7.168538573357649

Epoch: 5| Step: 1
Training loss: 8.00605068271365
Validation loss: 7.165462216210926

Epoch: 5| Step: 2
Training loss: 7.651634101618348
Validation loss: 7.161941926411043

Epoch: 5| Step: 3
Training loss: 7.020078201510455
Validation loss: 7.159429446877536

Epoch: 5| Step: 4
Training loss: 7.797655819494528
Validation loss: 7.155302893637381

Epoch: 5| Step: 5
Training loss: 6.401310500440271
Validation loss: 7.15429751713771

Epoch: 5| Step: 6
Training loss: 7.585515082214259
Validation loss: 7.14984864816862

Epoch: 5| Step: 7
Training loss: 6.7500186496053125
Validation loss: 7.1470084538244265

Epoch: 5| Step: 8
Training loss: 6.989927947583032
Validation loss: 7.144131954949999

Epoch: 5| Step: 9
Training loss: 5.655727636337835
Validation loss: 7.139104233901586

Epoch: 5| Step: 10
Training loss: 7.519416851808375
Validation loss: 7.135782697675767

Epoch: 7| Step: 0
Training loss: 7.196262491575488
Validation loss: 7.134577211192992

Epoch: 5| Step: 1
Training loss: 7.007660624921988
Validation loss: 7.131620568383361

Epoch: 5| Step: 2
Training loss: 6.989314506655801
Validation loss: 7.1255809559320085

Epoch: 5| Step: 3
Training loss: 7.360947750686054
Validation loss: 7.122575429034957

Epoch: 5| Step: 4
Training loss: 7.500971667607601
Validation loss: 7.121557063401573

Epoch: 5| Step: 5
Training loss: 6.963666079276912
Validation loss: 7.116329075924676

Epoch: 5| Step: 6
Training loss: 7.145097729900146
Validation loss: 7.109538225880497

Epoch: 5| Step: 7
Training loss: 6.550350896157623
Validation loss: 7.107719503233234

Epoch: 5| Step: 8
Training loss: 7.2559066914675245
Validation loss: 7.102234592070608

Epoch: 5| Step: 9
Training loss: 6.084948634461362
Validation loss: 7.099359948603246

Epoch: 5| Step: 10
Training loss: 8.01129449830514
Validation loss: 7.093262277323277

Epoch: 8| Step: 0
Training loss: 6.664637765506101
Validation loss: 7.089218281555819

Epoch: 5| Step: 1
Training loss: 7.42665630323873
Validation loss: 7.084689972282315

Epoch: 5| Step: 2
Training loss: 7.512544440774335
Validation loss: 7.083377339505687

Epoch: 5| Step: 3
Training loss: 7.702246192185062
Validation loss: 7.077872512864308

Epoch: 5| Step: 4
Training loss: 6.010411130835387
Validation loss: 7.072856152225606

Epoch: 5| Step: 5
Training loss: 6.811018196427779
Validation loss: 7.068087681210361

Epoch: 5| Step: 6
Training loss: 6.094976839642728
Validation loss: 7.0653696490900995

Epoch: 5| Step: 7
Training loss: 8.189150578345975
Validation loss: 7.059074675437151

Epoch: 5| Step: 8
Training loss: 6.477133510620597
Validation loss: 7.052167424970692

Epoch: 5| Step: 9
Training loss: 6.612601716786196
Validation loss: 7.047547770506497

Epoch: 5| Step: 10
Training loss: 7.797418793270404
Validation loss: 7.044078128808203

Epoch: 9| Step: 0
Training loss: 6.832273571674595
Validation loss: 7.040193201035463

Epoch: 5| Step: 1
Training loss: 7.311556763418274
Validation loss: 7.033469103947254

Epoch: 5| Step: 2
Training loss: 6.784599074885236
Validation loss: 7.027638830783676

Epoch: 5| Step: 3
Training loss: 6.78465445710354
Validation loss: 7.023638662663415

Epoch: 5| Step: 4
Training loss: 6.315954188658466
Validation loss: 7.017744584834332

Epoch: 5| Step: 5
Training loss: 7.07893094154382
Validation loss: 7.012339903050051

Epoch: 5| Step: 6
Training loss: 6.70017132895886
Validation loss: 7.007516139482501

Epoch: 5| Step: 7
Training loss: 6.898352340570061
Validation loss: 7.00247197664093

Epoch: 5| Step: 8
Training loss: 7.134902764815993
Validation loss: 6.9961843272374376

Epoch: 5| Step: 9
Training loss: 7.456863968952689
Validation loss: 6.9921492017736435

Epoch: 5| Step: 10
Training loss: 7.655837939325953
Validation loss: 6.987300800562524

Epoch: 10| Step: 0
Training loss: 7.127550973485821
Validation loss: 6.9812833918457216

Epoch: 5| Step: 1
Training loss: 7.059337887069055
Validation loss: 6.976249016147545

Epoch: 5| Step: 2
Training loss: 6.88122415563735
Validation loss: 6.967793778751127

Epoch: 5| Step: 3
Training loss: 7.598100334466961
Validation loss: 6.9626089715444905

Epoch: 5| Step: 4
Training loss: 6.54203788854111
Validation loss: 6.956763312616977

Epoch: 5| Step: 5
Training loss: 7.333167189825659
Validation loss: 6.949534919872592

Epoch: 5| Step: 6
Training loss: 6.2779656928790875
Validation loss: 6.942726520426226

Epoch: 5| Step: 7
Training loss: 6.968433869038164
Validation loss: 6.940502947289551

Epoch: 5| Step: 8
Training loss: 6.375159467310804
Validation loss: 6.933736729225857

Epoch: 5| Step: 9
Training loss: 7.291061928512893
Validation loss: 6.928172363813237

Epoch: 5| Step: 10
Training loss: 6.68781144317138
Validation loss: 6.920981985273522

Epoch: 11| Step: 0
Training loss: 7.152814948552242
Validation loss: 6.916014050343833

Epoch: 5| Step: 1
Training loss: 7.549641925328882
Validation loss: 6.909714453787259

Epoch: 5| Step: 2
Training loss: 6.12815526539489
Validation loss: 6.905842056442442

Epoch: 5| Step: 3
Training loss: 7.1109644192559305
Validation loss: 6.897782146069215

Epoch: 5| Step: 4
Training loss: 6.282165157018605
Validation loss: 6.8895884211721965

Epoch: 5| Step: 5
Training loss: 7.6833015700516025
Validation loss: 6.883006765650765

Epoch: 5| Step: 6
Training loss: 7.67639250905821
Validation loss: 6.878194594390483

Epoch: 5| Step: 7
Training loss: 5.783561615556413
Validation loss: 6.86891872194268

Epoch: 5| Step: 8
Training loss: 6.871362452108183
Validation loss: 6.866148616452936

Epoch: 5| Step: 9
Training loss: 6.723329766341426
Validation loss: 6.858908675973682

Epoch: 5| Step: 10
Training loss: 6.206688921294723
Validation loss: 6.853133101385794

Epoch: 12| Step: 0
Training loss: 6.479286053734106
Validation loss: 6.84798131086425

Epoch: 5| Step: 1
Training loss: 7.029300131112055
Validation loss: 6.840057999934033

Epoch: 5| Step: 2
Training loss: 6.417225140465151
Validation loss: 6.831851808629398

Epoch: 5| Step: 3
Training loss: 7.243924192978764
Validation loss: 6.824100317380101

Epoch: 5| Step: 4
Training loss: 6.842466190409312
Validation loss: 6.818956852401877

Epoch: 5| Step: 5
Training loss: 7.554336555479709
Validation loss: 6.814311985958717

Epoch: 5| Step: 6
Training loss: 6.739648298827953
Validation loss: 6.806250711977348

Epoch: 5| Step: 7
Training loss: 7.5537502650277135
Validation loss: 6.795678466815667

Epoch: 5| Step: 8
Training loss: 5.924350352022225
Validation loss: 6.790404840152862

Epoch: 5| Step: 9
Training loss: 5.893461399556835
Validation loss: 6.781312498671605

Epoch: 5| Step: 10
Training loss: 6.861164945664919
Validation loss: 6.773599286536478

Epoch: 13| Step: 0
Training loss: 7.003614037668198
Validation loss: 6.7681458738861595

Epoch: 5| Step: 1
Training loss: 6.054874619084365
Validation loss: 6.756520724073152

Epoch: 5| Step: 2
Training loss: 7.239606839880528
Validation loss: 6.752694543519759

Epoch: 5| Step: 3
Training loss: 6.937052944316203
Validation loss: 6.745481600537557

Epoch: 5| Step: 4
Training loss: 6.880905112234452
Validation loss: 6.738121166114036

Epoch: 5| Step: 5
Training loss: 6.747487483597772
Validation loss: 6.726181217841294

Epoch: 5| Step: 6
Training loss: 7.395390657599883
Validation loss: 6.717060690425596

Epoch: 5| Step: 7
Training loss: 6.604898438290096
Validation loss: 6.715445611897018

Epoch: 5| Step: 8
Training loss: 6.7301533293581
Validation loss: 6.705434658147401

Epoch: 5| Step: 9
Training loss: 6.4910997932460495
Validation loss: 6.697991552942025

Epoch: 5| Step: 10
Training loss: 5.40841507969908
Validation loss: 6.687823307999693

Epoch: 14| Step: 0
Training loss: 6.893371173206314
Validation loss: 6.6777828824617975

Epoch: 5| Step: 1
Training loss: 7.079861526859261
Validation loss: 6.669488544465261

Epoch: 5| Step: 2
Training loss: 6.282778729450244
Validation loss: 6.659255363822682

Epoch: 5| Step: 3
Training loss: 6.401575085415991
Validation loss: 6.653042035788825

Epoch: 5| Step: 4
Training loss: 5.647323055256329
Validation loss: 6.643469124917117

Epoch: 5| Step: 5
Training loss: 6.636554646385645
Validation loss: 6.633199792190609

Epoch: 5| Step: 6
Training loss: 6.13975025576163
Validation loss: 6.628028624690765

Epoch: 5| Step: 7
Training loss: 6.850044874058223
Validation loss: 6.617510793785513

Epoch: 5| Step: 8
Training loss: 6.436713902151803
Validation loss: 6.607823852584868

Epoch: 5| Step: 9
Training loss: 7.200155245908629
Validation loss: 6.60222877751226

Epoch: 5| Step: 10
Training loss: 7.234019853678051
Validation loss: 6.588197833318625

Epoch: 15| Step: 0
Training loss: 6.23157409620978
Validation loss: 6.5773562765826235

Epoch: 5| Step: 1
Training loss: 6.279773443715508
Validation loss: 6.574789043404684

Epoch: 5| Step: 2
Training loss: 6.782524024366834
Validation loss: 6.564751367304005

Epoch: 5| Step: 3
Training loss: 5.750921424346181
Validation loss: 6.553944838886071

Epoch: 5| Step: 4
Training loss: 6.112414138284512
Validation loss: 6.540719733888659

Epoch: 5| Step: 5
Training loss: 6.930247321841734
Validation loss: 6.535998935797127

Epoch: 5| Step: 6
Training loss: 6.99099069933954
Validation loss: 6.52699289495659

Epoch: 5| Step: 7
Training loss: 6.580268564975675
Validation loss: 6.512972527333714

Epoch: 5| Step: 8
Training loss: 6.763207970753529
Validation loss: 6.501850445343833

Epoch: 5| Step: 9
Training loss: 6.650030678126194
Validation loss: 6.489565767227465

Epoch: 5| Step: 10
Training loss: 6.598043047609304
Validation loss: 6.48284264437543

Epoch: 16| Step: 0
Training loss: 6.392407455520383
Validation loss: 6.473215201290059

Epoch: 5| Step: 1
Training loss: 5.674094026148855
Validation loss: 6.46692042718169

Epoch: 5| Step: 2
Training loss: 6.902233492062919
Validation loss: 6.4547741098821145

Epoch: 5| Step: 3
Training loss: 6.672966110740252
Validation loss: 6.442026651280116

Epoch: 5| Step: 4
Training loss: 7.2818857332948905
Validation loss: 6.426559302693921

Epoch: 5| Step: 5
Training loss: 5.798473209814926
Validation loss: 6.419365708227587

Epoch: 5| Step: 6
Training loss: 6.478460569840683
Validation loss: 6.406163189587699

Epoch: 5| Step: 7
Training loss: 6.463730785995664
Validation loss: 6.395474682144515

Epoch: 5| Step: 8
Training loss: 5.851747639761401
Validation loss: 6.381689269465474

Epoch: 5| Step: 9
Training loss: 6.541581009549006
Validation loss: 6.372670616092646

Epoch: 5| Step: 10
Training loss: 6.220695459669532
Validation loss: 6.363563798182512

Epoch: 17| Step: 0
Training loss: 7.150235109531856
Validation loss: 6.347784402138964

Epoch: 5| Step: 1
Training loss: 7.407504076150319
Validation loss: 6.337844276255589

Epoch: 5| Step: 2
Training loss: 6.118752231928698
Validation loss: 6.321921318798191

Epoch: 5| Step: 3
Training loss: 6.784256369784885
Validation loss: 6.315484883577816

Epoch: 5| Step: 4
Training loss: 5.570688285831947
Validation loss: 6.301701612581027

Epoch: 5| Step: 5
Training loss: 6.624543084276791
Validation loss: 6.284726572481868

Epoch: 5| Step: 6
Training loss: 5.163494038421508
Validation loss: 6.273488881814021

Epoch: 5| Step: 7
Training loss: 5.879427600948491
Validation loss: 6.266447252103516

Epoch: 5| Step: 8
Training loss: 7.164500448803685
Validation loss: 6.253527640449183

Epoch: 5| Step: 9
Training loss: 5.259234889267012
Validation loss: 6.238458174280934

Epoch: 5| Step: 10
Training loss: 5.369359272500992
Validation loss: 6.229501981150919

Epoch: 18| Step: 0
Training loss: 7.117041710910773
Validation loss: 6.214035851946216

Epoch: 5| Step: 1
Training loss: 6.039184411164373
Validation loss: 6.201552202639299

Epoch: 5| Step: 2
Training loss: 5.640847156831012
Validation loss: 6.186540250984156

Epoch: 5| Step: 3
Training loss: 6.251898515362091
Validation loss: 6.181665212780645

Epoch: 5| Step: 4
Training loss: 5.894354896612249
Validation loss: 6.164553004273061

Epoch: 5| Step: 5
Training loss: 6.403513551896816
Validation loss: 6.150112365902014

Epoch: 5| Step: 6
Training loss: 5.864999904258577
Validation loss: 6.13640039291469

Epoch: 5| Step: 7
Training loss: 5.52223755834144
Validation loss: 6.1173974897203856

Epoch: 5| Step: 8
Training loss: 5.413961038010317
Validation loss: 6.108090268157549

Epoch: 5| Step: 9
Training loss: 6.9182215708496315
Validation loss: 6.089271480266093

Epoch: 5| Step: 10
Training loss: 6.319882146002049
Validation loss: 6.0803409026027975

Epoch: 19| Step: 0
Training loss: 6.607983309634654
Validation loss: 6.068794216346688

Epoch: 5| Step: 1
Training loss: 5.491801827619308
Validation loss: 6.051562086263205

Epoch: 5| Step: 2
Training loss: 5.313490292868448
Validation loss: 6.044389757590208

Epoch: 5| Step: 3
Training loss: 6.602003960830993
Validation loss: 6.022778315227489

Epoch: 5| Step: 4
Training loss: 6.464158644778397
Validation loss: 6.012491715910967

Epoch: 5| Step: 5
Training loss: 5.520799149701316
Validation loss: 6.001733515811387

Epoch: 5| Step: 6
Training loss: 5.547653788308319
Validation loss: 5.975375250217063

Epoch: 5| Step: 7
Training loss: 5.677110845749944
Validation loss: 5.967951105160919

Epoch: 5| Step: 8
Training loss: 5.296280098875265
Validation loss: 5.94991509409813

Epoch: 5| Step: 9
Training loss: 7.1585055465618135
Validation loss: 5.9437920331803085

Epoch: 5| Step: 10
Training loss: 5.960590957427592
Validation loss: 5.929671340841031

Epoch: 20| Step: 0
Training loss: 6.189488871583427
Validation loss: 5.905583134953503

Epoch: 5| Step: 1
Training loss: 6.302245923511706
Validation loss: 5.88750882551841

Epoch: 5| Step: 2
Training loss: 6.087235161818804
Validation loss: 5.87255187334224

Epoch: 5| Step: 3
Training loss: 5.7004682649709935
Validation loss: 5.861273194785904

Epoch: 5| Step: 4
Training loss: 5.792022072112458
Validation loss: 5.845354645267905

Epoch: 5| Step: 5
Training loss: 5.596459781957202
Validation loss: 5.8318907798407755

Epoch: 5| Step: 6
Training loss: 6.087188474607191
Validation loss: 5.810129430936491

Epoch: 5| Step: 7
Training loss: 5.638962096358684
Validation loss: 5.789646883918933

Epoch: 5| Step: 8
Training loss: 5.725757412178343
Validation loss: 5.774839585090856

Epoch: 5| Step: 9
Training loss: 5.815662139167247
Validation loss: 5.760431754242261

Epoch: 5| Step: 10
Training loss: 5.127054314477614
Validation loss: 5.751381157581113

Epoch: 21| Step: 0
Training loss: 5.656617716433396
Validation loss: 5.7447834401029985

Epoch: 5| Step: 1
Training loss: 6.1086497156799675
Validation loss: 5.719866699127246

Epoch: 5| Step: 2
Training loss: 6.071436636783147
Validation loss: 5.701310466717816

Epoch: 5| Step: 3
Training loss: 6.024270560400828
Validation loss: 5.6744165929904415

Epoch: 5| Step: 4
Training loss: 5.037398662447099
Validation loss: 5.666236934738603

Epoch: 5| Step: 5
Training loss: 6.054427917822573
Validation loss: 5.653269239169904

Epoch: 5| Step: 6
Training loss: 5.261982096288911
Validation loss: 5.627887581706554

Epoch: 5| Step: 7
Training loss: 4.607208673930097
Validation loss: 5.61735738486849

Epoch: 5| Step: 8
Training loss: 5.512529839328962
Validation loss: 5.591374451814703

Epoch: 5| Step: 9
Training loss: 5.768597257995324
Validation loss: 5.587744211928946

Epoch: 5| Step: 10
Training loss: 6.07492522519407
Validation loss: 5.5565749188246265

Epoch: 22| Step: 0
Training loss: 5.157163411934652
Validation loss: 5.546295243867266

Epoch: 5| Step: 1
Training loss: 6.071985433990739
Validation loss: 5.526639184210411

Epoch: 5| Step: 2
Training loss: 5.679783879318956
Validation loss: 5.510758357171425

Epoch: 5| Step: 3
Training loss: 3.7516951226525537
Validation loss: 5.484120938058735

Epoch: 5| Step: 4
Training loss: 4.6619905249696965
Validation loss: 5.485180399996926

Epoch: 5| Step: 5
Training loss: 5.841610440334163
Validation loss: 5.460149100253146

Epoch: 5| Step: 6
Training loss: 5.76424170133049
Validation loss: 5.4254974711778

Epoch: 5| Step: 7
Training loss: 6.154109059733326
Validation loss: 5.416613708060512

Epoch: 5| Step: 8
Training loss: 5.48396512752383
Validation loss: 5.400898803235335

Epoch: 5| Step: 9
Training loss: 5.872515863402837
Validation loss: 5.37950380570733

Epoch: 5| Step: 10
Training loss: 5.266232599808718
Validation loss: 5.365383855546074

Epoch: 23| Step: 0
Training loss: 6.150739498183265
Validation loss: 5.339091018836401

Epoch: 5| Step: 1
Training loss: 5.896871558483031
Validation loss: 5.316220602437998

Epoch: 5| Step: 2
Training loss: 4.519052227882532
Validation loss: 5.2986965175875325

Epoch: 5| Step: 3
Training loss: 4.283681805359767
Validation loss: 5.2838214677625635

Epoch: 5| Step: 4
Training loss: 5.112146028608951
Validation loss: 5.271271672768579

Epoch: 5| Step: 5
Training loss: 5.803373000556982
Validation loss: 5.245091717785389

Epoch: 5| Step: 6
Training loss: 5.543115507714083
Validation loss: 5.234244664662841

Epoch: 5| Step: 7
Training loss: 4.64229689770594
Validation loss: 5.197703594273164

Epoch: 5| Step: 8
Training loss: 4.994605014828539
Validation loss: 5.179818946790064

Epoch: 5| Step: 9
Training loss: 5.959715711738782
Validation loss: 5.171282136065364

Epoch: 5| Step: 10
Training loss: 4.530961020890286
Validation loss: 5.14678808851265

Epoch: 24| Step: 0
Training loss: 6.138625889702084
Validation loss: 5.128968721820346

Epoch: 5| Step: 1
Training loss: 5.014646820989272
Validation loss: 5.098206017035872

Epoch: 5| Step: 2
Training loss: 4.024994247148087
Validation loss: 5.0838111956770975

Epoch: 5| Step: 3
Training loss: 3.8848992924543366
Validation loss: 5.063270203381414

Epoch: 5| Step: 4
Training loss: 5.7284803314630475
Validation loss: 5.029567022510178

Epoch: 5| Step: 5
Training loss: 4.830684440248078
Validation loss: 5.012638395179411

Epoch: 5| Step: 6
Training loss: 5.073199233606658
Validation loss: 5.001969142496938

Epoch: 5| Step: 7
Training loss: 5.050761235338341
Validation loss: 4.977649695337558

Epoch: 5| Step: 8
Training loss: 5.259052102143648
Validation loss: 4.96205631553056

Epoch: 5| Step: 9
Training loss: 4.950200995786094
Validation loss: 4.932423686317778

Epoch: 5| Step: 10
Training loss: 5.215722765043402
Validation loss: 4.909616805773401

Epoch: 25| Step: 0
Training loss: 4.423324509137303
Validation loss: 4.891282784706378

Epoch: 5| Step: 1
Training loss: 4.184695543086746
Validation loss: 4.871724200034006

Epoch: 5| Step: 2
Training loss: 5.944756500673087
Validation loss: 4.835767760188632

Epoch: 5| Step: 3
Training loss: 4.670065845294865
Validation loss: 4.817821991124937

Epoch: 5| Step: 4
Training loss: 4.922966148890829
Validation loss: 4.796711608299463

Epoch: 5| Step: 5
Training loss: 4.361003612535184
Validation loss: 4.777932498338021

Epoch: 5| Step: 6
Training loss: 4.203588297102037
Validation loss: 4.764684234132851

Epoch: 5| Step: 7
Training loss: 5.8520432645250535
Validation loss: 4.727835261756911

Epoch: 5| Step: 8
Training loss: 4.452849155381972
Validation loss: 4.704699115678418

Epoch: 5| Step: 9
Training loss: 5.295963175112572
Validation loss: 4.675843141709371

Epoch: 5| Step: 10
Training loss: 4.368637035475652
Validation loss: 4.659428088570596

Epoch: 26| Step: 0
Training loss: 3.911053077370752
Validation loss: 4.643467297015328

Epoch: 5| Step: 1
Training loss: 4.752425528178102
Validation loss: 4.615934847315926

Epoch: 5| Step: 2
Training loss: 4.141014915677116
Validation loss: 4.596457705696467

Epoch: 5| Step: 3
Training loss: 3.749482945717915
Validation loss: 4.561251341482959

Epoch: 5| Step: 4
Training loss: 4.700676670467596
Validation loss: 4.5455131209468975

Epoch: 5| Step: 5
Training loss: 5.169826505247575
Validation loss: 4.530075949711514

Epoch: 5| Step: 6
Training loss: 4.462396546775492
Validation loss: 4.51021810668295

Epoch: 5| Step: 7
Training loss: 5.212457026389102
Validation loss: 4.478678288583961

Epoch: 5| Step: 8
Training loss: 4.90641560852066
Validation loss: 4.437744720842407

Epoch: 5| Step: 9
Training loss: 4.856432842803969
Validation loss: 4.435928609557714

Epoch: 5| Step: 10
Training loss: 4.401414964483035
Validation loss: 4.404787085912484

Epoch: 27| Step: 0
Training loss: 4.687911765768722
Validation loss: 4.366165654731672

Epoch: 5| Step: 1
Training loss: 4.662991552546091
Validation loss: 4.356602131247371

Epoch: 5| Step: 2
Training loss: 4.164382893616239
Validation loss: 4.319167839195545

Epoch: 5| Step: 3
Training loss: 3.9591152958048688
Validation loss: 4.30046744275331

Epoch: 5| Step: 4
Training loss: 5.304875006753719
Validation loss: 4.267731213402121

Epoch: 5| Step: 5
Training loss: 4.194477474147159
Validation loss: 4.262871791103894

Epoch: 5| Step: 6
Training loss: 4.2504296927054135
Validation loss: 4.217334826251717

Epoch: 5| Step: 7
Training loss: 4.63171126607859
Validation loss: 4.202160747646998

Epoch: 5| Step: 8
Training loss: 3.4867378742053394
Validation loss: 4.175940049999378

Epoch: 5| Step: 9
Training loss: 3.7329143396906743
Validation loss: 4.132174624272358

Epoch: 5| Step: 10
Training loss: 4.566382441527968
Validation loss: 4.115955999944527

Epoch: 28| Step: 0
Training loss: 3.290546870594699
Validation loss: 4.092940889852429

Epoch: 5| Step: 1
Training loss: 5.284106142501277
Validation loss: 4.051140439079622

Epoch: 5| Step: 2
Training loss: 3.7759602013931346
Validation loss: 4.063160562884562

Epoch: 5| Step: 3
Training loss: 4.223080369398206
Validation loss: 4.026976344670163

Epoch: 5| Step: 4
Training loss: 4.345282414677516
Validation loss: 4.005461665982723

Epoch: 5| Step: 5
Training loss: 3.851233416072472
Validation loss: 3.9697158332010405

Epoch: 5| Step: 6
Training loss: 3.315535108550394
Validation loss: 3.94946276494084

Epoch: 5| Step: 7
Training loss: 4.179400910151291
Validation loss: 3.9300779208521512

Epoch: 5| Step: 8
Training loss: 4.6244347716664205
Validation loss: 3.9148982412143933

Epoch: 5| Step: 9
Training loss: 4.0067939281934395
Validation loss: 3.8736645001191765

Epoch: 5| Step: 10
Training loss: 3.4996858183308923
Validation loss: 3.8468083978873926

Epoch: 29| Step: 0
Training loss: 4.113974894030218
Validation loss: 3.8560976724685414

Epoch: 5| Step: 1
Training loss: 4.4830111779016795
Validation loss: 3.810256853539391

Epoch: 5| Step: 2
Training loss: 3.112335176201856
Validation loss: 3.7703333833549566

Epoch: 5| Step: 3
Training loss: 3.6683539207628364
Validation loss: 3.7574584635888413

Epoch: 5| Step: 4
Training loss: 4.360984587133262
Validation loss: 3.751619491079004

Epoch: 5| Step: 5
Training loss: 3.658107970181961
Validation loss: 3.7197902538099434

Epoch: 5| Step: 6
Training loss: 3.571618306705853
Validation loss: 3.7300001308251223

Epoch: 5| Step: 7
Training loss: 3.842753087223752
Validation loss: 3.685815997064806

Epoch: 5| Step: 8
Training loss: 4.28477900608438
Validation loss: 3.647282643117307

Epoch: 5| Step: 9
Training loss: 3.8178573239316367
Validation loss: 3.611084350968486

Epoch: 5| Step: 10
Training loss: 3.3572552757804064
Validation loss: 3.5849633102334724

Epoch: 30| Step: 0
Training loss: 3.694691386052614
Validation loss: 3.5827218345025518

Epoch: 5| Step: 1
Training loss: 3.2171038519946853
Validation loss: 3.555462797768327

Epoch: 5| Step: 2
Training loss: 3.544906540514354
Validation loss: 3.562583217861447

Epoch: 5| Step: 3
Training loss: 4.7788528716290015
Validation loss: 3.5162754243803

Epoch: 5| Step: 4
Training loss: 4.1339499741670815
Validation loss: 3.4794408817753335

Epoch: 5| Step: 5
Training loss: 3.722100423525026
Validation loss: 3.4777314810333957

Epoch: 5| Step: 6
Training loss: 3.546242275182562
Validation loss: 3.4623778441930857

Epoch: 5| Step: 7
Training loss: 3.1236992226847433
Validation loss: 3.4375725045859276

Epoch: 5| Step: 8
Training loss: 3.3777711582397827
Validation loss: 3.3760589220600705

Epoch: 5| Step: 9
Training loss: 3.751697791733178
Validation loss: 3.4058793163428858

Epoch: 5| Step: 10
Training loss: 3.1618953865692507
Validation loss: 3.380495972160698

Epoch: 31| Step: 0
Training loss: 3.059943864594214
Validation loss: 3.3740790738871405

Epoch: 5| Step: 1
Training loss: 3.2157762734704702
Validation loss: 3.3506583442226026

Epoch: 5| Step: 2
Training loss: 4.109947483813163
Validation loss: 3.331722709228199

Epoch: 5| Step: 3
Training loss: 3.5023790176048886
Validation loss: 3.3222667192056514

Epoch: 5| Step: 4
Training loss: 2.9162533785150075
Validation loss: 3.2742894707362904

Epoch: 5| Step: 5
Training loss: 3.4626848963317727
Validation loss: 3.3002622771734416

Epoch: 5| Step: 6
Training loss: 3.4381937887400507
Validation loss: 3.282452355111611

Epoch: 5| Step: 7
Training loss: 3.1183902265400443
Validation loss: 3.2500665435415352

Epoch: 5| Step: 8
Training loss: 4.0321614026204635
Validation loss: 3.238786615575138

Epoch: 5| Step: 9
Training loss: 3.529512771395279
Validation loss: 3.2345088728717744

Epoch: 5| Step: 10
Training loss: 3.7083780235998014
Validation loss: 3.2317026464662417

Epoch: 32| Step: 0
Training loss: 3.1267620459556573
Validation loss: 3.2081104936841105

Epoch: 5| Step: 1
Training loss: 3.514520768424829
Validation loss: 3.200761343834356

Epoch: 5| Step: 2
Training loss: 3.4752337370279913
Validation loss: 3.1689559086149828

Epoch: 5| Step: 3
Training loss: 3.9778120254898717
Validation loss: 3.1563590433068915

Epoch: 5| Step: 4
Training loss: 3.187718402635646
Validation loss: 3.1574180380562615

Epoch: 5| Step: 5
Training loss: 3.5266808851228264
Validation loss: 3.1045065577636026

Epoch: 5| Step: 6
Training loss: 3.3034540133432957
Validation loss: 3.10896630604702

Epoch: 5| Step: 7
Training loss: 3.060093303828693
Validation loss: 3.118177875638133

Epoch: 5| Step: 8
Training loss: 3.5990717750847807
Validation loss: 3.103198536746715

Epoch: 5| Step: 9
Training loss: 2.990589800939425
Validation loss: 3.0933320330863543

Epoch: 5| Step: 10
Training loss: 3.7072818136803307
Validation loss: 3.065667201225412

Epoch: 33| Step: 0
Training loss: 2.7375384532718603
Validation loss: 3.083893397205435

Epoch: 5| Step: 1
Training loss: 3.4882025117093347
Validation loss: 3.0467159207625354

Epoch: 5| Step: 2
Training loss: 3.006259269462142
Validation loss: 3.041020993354251

Epoch: 5| Step: 3
Training loss: 4.114440580700402
Validation loss: 3.054392543769627

Epoch: 5| Step: 4
Training loss: 3.071690218733934
Validation loss: 3.03609096742196

Epoch: 5| Step: 5
Training loss: 3.5317069239089927
Validation loss: 3.0213719946771467

Epoch: 5| Step: 6
Training loss: 3.330518551337131
Validation loss: 3.0237496660493637

Epoch: 5| Step: 7
Training loss: 2.682609010954048
Validation loss: 3.0086157529652984

Epoch: 5| Step: 8
Training loss: 3.956212342190012
Validation loss: 3.024815207681052

Epoch: 5| Step: 9
Training loss: 2.4688471521504023
Validation loss: 3.001337863989201

Epoch: 5| Step: 10
Training loss: 3.7446470838427137
Validation loss: 2.9752396846603704

Epoch: 34| Step: 0
Training loss: 2.4980783706600307
Validation loss: 3.0018168744926346

Epoch: 5| Step: 1
Training loss: 3.235290987349847
Validation loss: 2.9786743461753065

Epoch: 5| Step: 2
Training loss: 3.2614579330601665
Validation loss: 2.9690238079406206

Epoch: 5| Step: 3
Training loss: 3.4357933662995803
Validation loss: 2.980795370267369

Epoch: 5| Step: 4
Training loss: 2.695866005496617
Validation loss: 2.9563070033365144

Epoch: 5| Step: 5
Training loss: 4.036335421095699
Validation loss: 2.96410808942139

Epoch: 5| Step: 6
Training loss: 2.640218850225754
Validation loss: 2.958120501042102

Epoch: 5| Step: 7
Training loss: 3.3110852369226307
Validation loss: 2.96228216123311

Epoch: 5| Step: 8
Training loss: 3.7455930882441884
Validation loss: 2.9589795275323265

Epoch: 5| Step: 9
Training loss: 3.112622276263598
Validation loss: 2.9227386851127566

Epoch: 5| Step: 10
Training loss: 3.900945372808461
Validation loss: 2.933821636143458

Epoch: 35| Step: 0
Training loss: 2.956866603687003
Validation loss: 2.9233074781914485

Epoch: 5| Step: 1
Training loss: 3.070337038209037
Validation loss: 2.961723309728434

Epoch: 5| Step: 2
Training loss: 3.168437880694649
Validation loss: 2.9479946722005677

Epoch: 5| Step: 3
Training loss: 3.132794996103298
Validation loss: 2.950165430098561

Epoch: 5| Step: 4
Training loss: 3.0239896048412582
Validation loss: 2.9262297338178076

Epoch: 5| Step: 5
Training loss: 3.046959509044362
Validation loss: 2.920843424308663

Epoch: 5| Step: 6
Training loss: 3.3436645782112286
Validation loss: 2.932475095418528

Epoch: 5| Step: 7
Training loss: 3.572585302766672
Validation loss: 2.8897142708891113

Epoch: 5| Step: 8
Training loss: 3.743866673149673
Validation loss: 2.8974603960092775

Epoch: 5| Step: 9
Training loss: 3.4878890446067508
Validation loss: 2.9294828942609845

Epoch: 5| Step: 10
Training loss: 3.333136568619834
Validation loss: 2.9226613285483616

Epoch: 36| Step: 0
Training loss: 3.4635407794387176
Validation loss: 2.9038648341303355

Epoch: 5| Step: 1
Training loss: 3.136939016092923
Validation loss: 2.9168178771122406

Epoch: 5| Step: 2
Training loss: 3.315792966106236
Validation loss: 2.923457025095418

Epoch: 5| Step: 3
Training loss: 3.1273361629076715
Validation loss: 2.9177232091459397

Epoch: 5| Step: 4
Training loss: 3.7106965639301457
Validation loss: 2.9182250071569085

Epoch: 5| Step: 5
Training loss: 3.36167963507412
Validation loss: 2.9171890043038418

Epoch: 5| Step: 6
Training loss: 3.215055252478448
Validation loss: 2.910711650838748

Epoch: 5| Step: 7
Training loss: 3.675351189681426
Validation loss: 2.905041931695779

Epoch: 5| Step: 8
Training loss: 3.580184543690775
Validation loss: 2.8883405416903187

Epoch: 5| Step: 9
Training loss: 1.9986327385396803
Validation loss: 2.9000612228403475

Epoch: 5| Step: 10
Training loss: 2.980021231914896
Validation loss: 2.889583564336753

Epoch: 37| Step: 0
Training loss: 3.541763723202904
Validation loss: 2.8851538526938705

Epoch: 5| Step: 1
Training loss: 3.030361713939372
Validation loss: 2.9043077666904327

Epoch: 5| Step: 2
Training loss: 3.085029719625352
Validation loss: 2.8959004862174305

Epoch: 5| Step: 3
Training loss: 3.5466499425259514
Validation loss: 2.9141260435047167

Epoch: 5| Step: 4
Training loss: 3.2225553369616904
Validation loss: 2.918272294302263

Epoch: 5| Step: 5
Training loss: 3.291281488472954
Validation loss: 2.9106098912451435

Epoch: 5| Step: 6
Training loss: 3.2845857648797336
Validation loss: 2.907018687087064

Epoch: 5| Step: 7
Training loss: 3.408889028178111
Validation loss: 2.902898932300738

Epoch: 5| Step: 8
Training loss: 3.6818075693664705
Validation loss: 2.8644468237306584

Epoch: 5| Step: 9
Training loss: 2.477660793009912
Validation loss: 2.8906837499535496

Epoch: 5| Step: 10
Training loss: 2.652471030865385
Validation loss: 2.8740596303377015

Epoch: 38| Step: 0
Training loss: 3.8526799126660456
Validation loss: 2.892171012734939

Epoch: 5| Step: 1
Training loss: 2.9678929748260754
Validation loss: 2.8768014542816016

Epoch: 5| Step: 2
Training loss: 3.1298799178516257
Validation loss: 2.896016563437393

Epoch: 5| Step: 3
Training loss: 3.5033924827579095
Validation loss: 2.8843090389131394

Epoch: 5| Step: 4
Training loss: 3.6531262217471494
Validation loss: 2.8857838007769363

Epoch: 5| Step: 5
Training loss: 2.9801154770974794
Validation loss: 2.887206217461121

Epoch: 5| Step: 6
Training loss: 3.1087164253290056
Validation loss: 2.892234212863624

Epoch: 5| Step: 7
Training loss: 2.8479372155416263
Validation loss: 2.8752928901634727

Epoch: 5| Step: 8
Training loss: 2.9888366581994696
Validation loss: 2.896097766213924

Epoch: 5| Step: 9
Training loss: 3.1162011443163258
Validation loss: 2.8878753053481114

Epoch: 5| Step: 10
Training loss: 3.0927239460142575
Validation loss: 2.9001627620726267

Epoch: 39| Step: 0
Training loss: 3.5989135798290746
Validation loss: 2.888949139074289

Epoch: 5| Step: 1
Training loss: 3.0287452653004805
Validation loss: 2.8767832619912874

Epoch: 5| Step: 2
Training loss: 2.8134346150823384
Validation loss: 2.8953589567778937

Epoch: 5| Step: 3
Training loss: 3.356521032887157
Validation loss: 2.885309018258294

Epoch: 5| Step: 4
Training loss: 3.0113116631185957
Validation loss: 2.883310779988587

Epoch: 5| Step: 5
Training loss: 2.968428584317445
Validation loss: 2.880879764029362

Epoch: 5| Step: 6
Training loss: 2.965818704724622
Validation loss: 2.868604772630184

Epoch: 5| Step: 7
Training loss: 3.2215396680697226
Validation loss: 2.858484208443264

Epoch: 5| Step: 8
Training loss: 3.362534000267373
Validation loss: 2.9066192757542133

Epoch: 5| Step: 9
Training loss: 3.271643536240257
Validation loss: 2.878824802743205

Epoch: 5| Step: 10
Training loss: 3.885826491490923
Validation loss: 2.873201725401153

Epoch: 40| Step: 0
Training loss: 2.8105160815558126
Validation loss: 2.902824912598126

Epoch: 5| Step: 1
Training loss: 2.981813939656118
Validation loss: 2.8869303142707063

Epoch: 5| Step: 2
Training loss: 3.8100695758384115
Validation loss: 2.9005469897573217

Epoch: 5| Step: 3
Training loss: 2.340297954206971
Validation loss: 2.8941440640778904

Epoch: 5| Step: 4
Training loss: 3.505886033150736
Validation loss: 2.872454766322595

Epoch: 5| Step: 5
Training loss: 3.1970823278532845
Validation loss: 2.890437246498117

Epoch: 5| Step: 6
Training loss: 2.956666790411372
Validation loss: 2.877425087218532

Epoch: 5| Step: 7
Training loss: 3.4197548346734536
Validation loss: 2.8717968481991334

Epoch: 5| Step: 8
Training loss: 3.4462655407953315
Validation loss: 2.871059004708932

Epoch: 5| Step: 9
Training loss: 2.6470920442229393
Validation loss: 2.8967884359862186

Epoch: 5| Step: 10
Training loss: 4.128286959454792
Validation loss: 2.884296633581806

Epoch: 41| Step: 0
Training loss: 2.6177576155804503
Validation loss: 2.8676582087068003

Epoch: 5| Step: 1
Training loss: 3.7453846822251355
Validation loss: 2.892635532476493

Epoch: 5| Step: 2
Training loss: 2.8052426269641053
Validation loss: 2.8852673119465133

Epoch: 5| Step: 3
Training loss: 2.579430914074773
Validation loss: 2.878864329822305

Epoch: 5| Step: 4
Training loss: 3.383914336380564
Validation loss: 2.8649179335170203

Epoch: 5| Step: 5
Training loss: 3.8201903029169224
Validation loss: 2.8554802992794106

Epoch: 5| Step: 6
Training loss: 3.8334326247472466
Validation loss: 2.868390872696118

Epoch: 5| Step: 7
Training loss: 3.627681398174343
Validation loss: 2.864708911160559

Epoch: 5| Step: 8
Training loss: 2.4343418300263955
Validation loss: 2.907113102235294

Epoch: 5| Step: 9
Training loss: 3.1476768161596986
Validation loss: 2.858726797829866

Epoch: 5| Step: 10
Training loss: 2.9220319899544878
Validation loss: 2.8841921091915834

Epoch: 42| Step: 0
Training loss: 2.949960456195173
Validation loss: 2.875827197704012

Epoch: 5| Step: 1
Training loss: 2.219684672600225
Validation loss: 2.868406155877534

Epoch: 5| Step: 2
Training loss: 3.1464699780959426
Validation loss: 2.8955623287136327

Epoch: 5| Step: 3
Training loss: 3.062566639700665
Validation loss: 2.880961712020158

Epoch: 5| Step: 4
Training loss: 2.8726709302704
Validation loss: 2.864771277264866

Epoch: 5| Step: 5
Training loss: 2.797104980560764
Validation loss: 2.877807915254016

Epoch: 5| Step: 6
Training loss: 3.3275802238073875
Validation loss: 2.877017235949912

Epoch: 5| Step: 7
Training loss: 4.1331618509303905
Validation loss: 2.886577680183811

Epoch: 5| Step: 8
Training loss: 3.784392887139357
Validation loss: 2.8810878801388498

Epoch: 5| Step: 9
Training loss: 3.460751634002853
Validation loss: 2.8673638672394968

Epoch: 5| Step: 10
Training loss: 3.193408202751702
Validation loss: 2.837286685371779

Epoch: 43| Step: 0
Training loss: 3.771429629449572
Validation loss: 2.8366145579444497

Epoch: 5| Step: 1
Training loss: 2.8141217112732306
Validation loss: 2.8450148026996995

Epoch: 5| Step: 2
Training loss: 3.283540634607876
Validation loss: 2.8585539110221263

Epoch: 5| Step: 3
Training loss: 3.01580462143164
Validation loss: 2.846908000868552

Epoch: 5| Step: 4
Training loss: 3.121654550827908
Validation loss: 2.8382742566247336

Epoch: 5| Step: 5
Training loss: 2.266345731603784
Validation loss: 2.8490805066088507

Epoch: 5| Step: 6
Training loss: 3.28653980925938
Validation loss: 2.868702077629537

Epoch: 5| Step: 7
Training loss: 3.0824990733347146
Validation loss: 2.8582481568067317

Epoch: 5| Step: 8
Training loss: 3.8798260323368536
Validation loss: 2.8652881823863225

Epoch: 5| Step: 9
Training loss: 3.373750808676149
Validation loss: 2.889039966131533

Epoch: 5| Step: 10
Training loss: 3.223968719482126
Validation loss: 2.846589464944463

Epoch: 44| Step: 0
Training loss: 2.901640487222675
Validation loss: 2.8585877016323327

Epoch: 5| Step: 1
Training loss: 2.876280126434603
Validation loss: 2.8673090384110984

Epoch: 5| Step: 2
Training loss: 3.9866594534801263
Validation loss: 2.9030533410361503

Epoch: 5| Step: 3
Training loss: 3.3022313290392424
Validation loss: 2.8720432502018967

Epoch: 5| Step: 4
Training loss: 3.0736052350505547
Validation loss: 2.8750067359021476

Epoch: 5| Step: 5
Training loss: 3.7835769429248067
Validation loss: 2.8703396366350122

Epoch: 5| Step: 6
Training loss: 3.1678069387332344
Validation loss: 2.8590312203968256

Epoch: 5| Step: 7
Training loss: 2.458054467456759
Validation loss: 2.8641276180345328

Epoch: 5| Step: 8
Training loss: 3.299564801042971
Validation loss: 2.867424779976562

Epoch: 5| Step: 9
Training loss: 3.0324531605649754
Validation loss: 2.8684863671134364

Epoch: 5| Step: 10
Training loss: 3.1027363974660567
Validation loss: 2.885344479566599

Epoch: 45| Step: 0
Training loss: 3.3167025699940558
Validation loss: 2.8677337927192674

Epoch: 5| Step: 1
Training loss: 2.8457939431930517
Validation loss: 2.868203836603281

Epoch: 5| Step: 2
Training loss: 3.193686372306041
Validation loss: 2.8589553350208807

Epoch: 5| Step: 3
Training loss: 3.2301838575065505
Validation loss: 2.858855542524112

Epoch: 5| Step: 4
Training loss: 3.2633717625517504
Validation loss: 2.846070572547309

Epoch: 5| Step: 5
Training loss: 3.6332514015782493
Validation loss: 2.8482357373884684

Epoch: 5| Step: 6
Training loss: 3.0839931881701967
Validation loss: 2.8797377169038416

Epoch: 5| Step: 7
Training loss: 3.0554217068418925
Validation loss: 2.8415603005281285

Epoch: 5| Step: 8
Training loss: 3.1938915124286957
Validation loss: 2.87662073422122

Epoch: 5| Step: 9
Training loss: 2.12521652913658
Validation loss: 2.8559321820348833

Epoch: 5| Step: 10
Training loss: 3.9649403226770183
Validation loss: 2.89077285703296

Epoch: 46| Step: 0
Training loss: 3.38235872321842
Validation loss: 2.8183373156796345

Epoch: 5| Step: 1
Training loss: 3.0022838164677275
Validation loss: 2.8799776570388893

Epoch: 5| Step: 2
Training loss: 3.9171183034889094
Validation loss: 2.836815931932193

Epoch: 5| Step: 3
Training loss: 2.516974424866516
Validation loss: 2.8335869155076177

Epoch: 5| Step: 4
Training loss: 3.1281065186708203
Validation loss: 2.871138332864323

Epoch: 5| Step: 5
Training loss: 2.802570532286376
Validation loss: 2.8502179459528354

Epoch: 5| Step: 6
Training loss: 2.7767024205147166
Validation loss: 2.839543586617517

Epoch: 5| Step: 7
Training loss: 3.500666418663146
Validation loss: 2.8537637258327164

Epoch: 5| Step: 8
Training loss: 3.5271580035707673
Validation loss: 2.8629293564790137

Epoch: 5| Step: 9
Training loss: 3.1044471835858034
Validation loss: 2.8508383831265256

Epoch: 5| Step: 10
Training loss: 3.100668675077197
Validation loss: 2.862754516026532

Epoch: 47| Step: 0
Training loss: 3.501916360741906
Validation loss: 2.871799595022422

Epoch: 5| Step: 1
Training loss: 2.1680103194916676
Validation loss: 2.8690383229342533

Epoch: 5| Step: 2
Training loss: 2.572897773292352
Validation loss: 2.849988833155305

Epoch: 5| Step: 3
Training loss: 2.9681691454787202
Validation loss: 2.8386265396084274

Epoch: 5| Step: 4
Training loss: 4.055041935300534
Validation loss: 2.842474180100628

Epoch: 5| Step: 5
Training loss: 3.4797895563008026
Validation loss: 2.8323538566268214

Epoch: 5| Step: 6
Training loss: 3.331877549484786
Validation loss: 2.8257681753339017

Epoch: 5| Step: 7
Training loss: 3.1174631403233004
Validation loss: 2.863103526340269

Epoch: 5| Step: 8
Training loss: 3.946807638455812
Validation loss: 2.858824680267856

Epoch: 5| Step: 9
Training loss: 2.6201403002265153
Validation loss: 2.8617358781666717

Epoch: 5| Step: 10
Training loss: 2.7153103873356272
Validation loss: 2.856088716138603

Epoch: 48| Step: 0
Training loss: 3.589438862844394
Validation loss: 2.817003850152866

Epoch: 5| Step: 1
Training loss: 3.2910432989841647
Validation loss: 2.8599301153551604

Epoch: 5| Step: 2
Training loss: 3.147942818903937
Validation loss: 2.855599075305388

Epoch: 5| Step: 3
Training loss: 3.7921154189833297
Validation loss: 2.841561290235539

Epoch: 5| Step: 4
Training loss: 3.4038517059585933
Validation loss: 2.86243347636624

Epoch: 5| Step: 5
Training loss: 2.8913322614486474
Validation loss: 2.841637083477044

Epoch: 5| Step: 6
Training loss: 2.3568561573635938
Validation loss: 2.845737191621185

Epoch: 5| Step: 7
Training loss: 3.0455715423533043
Validation loss: 2.8424210064627102

Epoch: 5| Step: 8
Training loss: 3.3469767465094233
Validation loss: 2.8630973910104442

Epoch: 5| Step: 9
Training loss: 2.333227007577784
Validation loss: 2.8410695725025525

Epoch: 5| Step: 10
Training loss: 3.5176482079793168
Validation loss: 2.8012365313621563

Epoch: 49| Step: 0
Training loss: 3.1170586963324634
Validation loss: 2.8289115880178315

Epoch: 5| Step: 1
Training loss: 2.4427530464900613
Validation loss: 2.8320251206786775

Epoch: 5| Step: 2
Training loss: 3.7971294302130443
Validation loss: 2.858971145686456

Epoch: 5| Step: 3
Training loss: 2.8112736041416797
Validation loss: 2.8437031189088753

Epoch: 5| Step: 4
Training loss: 2.9958653568117874
Validation loss: 2.874811349094655

Epoch: 5| Step: 5
Training loss: 2.8051249978404744
Validation loss: 2.8471138472748656

Epoch: 5| Step: 6
Training loss: 3.381384850032353
Validation loss: 2.8037254833252825

Epoch: 5| Step: 7
Training loss: 3.166218792881656
Validation loss: 2.8317215981255175

Epoch: 5| Step: 8
Training loss: 3.5352533653787637
Validation loss: 2.830942542882692

Epoch: 5| Step: 9
Training loss: 3.603448138341632
Validation loss: 2.8141258298622684

Epoch: 5| Step: 10
Training loss: 2.8045453643911227
Validation loss: 2.834901521991466

Epoch: 50| Step: 0
Training loss: 3.0318203419020873
Validation loss: 2.842974342778241

Epoch: 5| Step: 1
Training loss: 3.143949504611807
Validation loss: 2.861976344430512

Epoch: 5| Step: 2
Training loss: 3.924153065269382
Validation loss: 2.871728559738606

Epoch: 5| Step: 3
Training loss: 3.0598746744060104
Validation loss: 2.8145302184427154

Epoch: 5| Step: 4
Training loss: 3.0598232482525645
Validation loss: 2.8204349567024374

Epoch: 5| Step: 5
Training loss: 3.4115184671862946
Validation loss: 2.8221878753545258

Epoch: 5| Step: 6
Training loss: 2.745423844347813
Validation loss: 2.8470913903402164

Epoch: 5| Step: 7
Training loss: 3.8029056582990397
Validation loss: 2.840079289480183

Epoch: 5| Step: 8
Training loss: 3.0021677132863065
Validation loss: 2.8020790125376718

Epoch: 5| Step: 9
Training loss: 2.539658884286462
Validation loss: 2.840264911991703

Epoch: 5| Step: 10
Training loss: 2.997745779617796
Validation loss: 2.84810327940408

Epoch: 51| Step: 0
Training loss: 2.375120461069258
Validation loss: 2.8349901126153023

Epoch: 5| Step: 1
Training loss: 2.6242869180613817
Validation loss: 2.8752811306917336

Epoch: 5| Step: 2
Training loss: 3.9626096547835847
Validation loss: 2.812136465480238

Epoch: 5| Step: 3
Training loss: 3.329839989881696
Validation loss: 2.8370578150462222

Epoch: 5| Step: 4
Training loss: 2.9164298006788365
Validation loss: 2.800593798676231

Epoch: 5| Step: 5
Training loss: 2.391777608427219
Validation loss: 2.834909439247938

Epoch: 5| Step: 6
Training loss: 3.1374978965965
Validation loss: 2.8343939656900465

Epoch: 5| Step: 7
Training loss: 3.537234611126725
Validation loss: 2.83644766690521

Epoch: 5| Step: 8
Training loss: 3.4831883073273198
Validation loss: 2.8842757807368975

Epoch: 5| Step: 9
Training loss: 3.7370720863974065
Validation loss: 2.8192324583341697

Epoch: 5| Step: 10
Training loss: 2.797699620247073
Validation loss: 2.8273641972211503

Epoch: 52| Step: 0
Training loss: 3.6095331330771487
Validation loss: 2.8033009808226805

Epoch: 5| Step: 1
Training loss: 3.7458246510326907
Validation loss: 2.825682117177664

Epoch: 5| Step: 2
Training loss: 2.340248544160129
Validation loss: 2.837758056339232

Epoch: 5| Step: 3
Training loss: 2.446169766926549
Validation loss: 2.8324648411548337

Epoch: 5| Step: 4
Training loss: 4.012928097903738
Validation loss: 2.796509880743257

Epoch: 5| Step: 5
Training loss: 3.222762782330073
Validation loss: 2.802110560170116

Epoch: 5| Step: 6
Training loss: 3.3956136964005648
Validation loss: 2.8248523946567556

Epoch: 5| Step: 7
Training loss: 2.823641431797559
Validation loss: 2.8249493581240364

Epoch: 5| Step: 8
Training loss: 2.918204546980067
Validation loss: 2.8238688529768927

Epoch: 5| Step: 9
Training loss: 2.7376011590251776
Validation loss: 2.8280115335387705

Epoch: 5| Step: 10
Training loss: 2.9162255816494045
Validation loss: 2.8296379992047793

Epoch: 53| Step: 0
Training loss: 2.502029072355546
Validation loss: 2.8341779767894195

Epoch: 5| Step: 1
Training loss: 3.455758863875827
Validation loss: 2.831023830062038

Epoch: 5| Step: 2
Training loss: 3.2248470003961978
Validation loss: 2.850040532075589

Epoch: 5| Step: 3
Training loss: 2.9703133733066838
Validation loss: 2.830703646634087

Epoch: 5| Step: 4
Training loss: 2.9663678700996066
Validation loss: 2.837982059953618

Epoch: 5| Step: 5
Training loss: 3.4310493285486414
Validation loss: 2.8381258360878503

Epoch: 5| Step: 6
Training loss: 2.5116441398206106
Validation loss: 2.8396170141788004

Epoch: 5| Step: 7
Training loss: 3.3483591131949284
Validation loss: 2.8182507713624214

Epoch: 5| Step: 8
Training loss: 3.696119288951148
Validation loss: 2.8248154624482433

Epoch: 5| Step: 9
Training loss: 2.9443176370181683
Validation loss: 2.832423145985071

Epoch: 5| Step: 10
Training loss: 3.4434558943594626
Validation loss: 2.843951788207533

Epoch: 54| Step: 0
Training loss: 2.4173044700407322
Validation loss: 2.824428525085558

Epoch: 5| Step: 1
Training loss: 3.61251469909423
Validation loss: 2.8413846856101608

Epoch: 5| Step: 2
Training loss: 3.067177917185664
Validation loss: 2.800834140960961

Epoch: 5| Step: 3
Training loss: 4.1882159631639775
Validation loss: 2.844563599153648

Epoch: 5| Step: 4
Training loss: 2.9647636553534062
Validation loss: 2.826665241969944

Epoch: 5| Step: 5
Training loss: 2.5914293501488217
Validation loss: 2.8119310940760567

Epoch: 5| Step: 6
Training loss: 2.704466294047391
Validation loss: 2.8387941153195375

Epoch: 5| Step: 7
Training loss: 2.606605110400999
Validation loss: 2.82604751694864

Epoch: 5| Step: 8
Training loss: 3.3682389531667556
Validation loss: 2.807120977765648

Epoch: 5| Step: 9
Training loss: 3.625068400822877
Validation loss: 2.808304409816463

Epoch: 5| Step: 10
Training loss: 3.228620487086364
Validation loss: 2.822122425264807

Epoch: 55| Step: 0
Training loss: 3.0570096996628924
Validation loss: 2.8431069504468316

Epoch: 5| Step: 1
Training loss: 3.0227862304757522
Validation loss: 2.8108120610117275

Epoch: 5| Step: 2
Training loss: 3.3853111994038425
Validation loss: 2.823668910771714

Epoch: 5| Step: 3
Training loss: 2.932042835760566
Validation loss: 2.802615358148768

Epoch: 5| Step: 4
Training loss: 2.9191204285251593
Validation loss: 2.7958259377269337

Epoch: 5| Step: 5
Training loss: 3.4332634915652265
Validation loss: 2.804338454332581

Epoch: 5| Step: 6
Training loss: 3.156804102235769
Validation loss: 2.800693834568531

Epoch: 5| Step: 7
Training loss: 2.4599279845946893
Validation loss: 2.82781707078979

Epoch: 5| Step: 8
Training loss: 3.327302786401842
Validation loss: 2.811519951559213

Epoch: 5| Step: 9
Training loss: 3.4644062234764283
Validation loss: 2.8181697525354577

Epoch: 5| Step: 10
Training loss: 3.256286410020168
Validation loss: 2.807277884805183

Epoch: 56| Step: 0
Training loss: 3.171137982511322
Validation loss: 2.8074776255343425

Epoch: 5| Step: 1
Training loss: 3.6377746163754976
Validation loss: 2.821861085775769

Epoch: 5| Step: 2
Training loss: 3.4346716602547795
Validation loss: 2.8111685970713243

Epoch: 5| Step: 3
Training loss: 2.9739935895674985
Validation loss: 2.814032672299629

Epoch: 5| Step: 4
Training loss: 2.80247669696903
Validation loss: 2.7970879879766146

Epoch: 5| Step: 5
Training loss: 2.126783744295884
Validation loss: 2.8301319839127728

Epoch: 5| Step: 6
Training loss: 3.2686557851018043
Validation loss: 2.8090406191817574

Epoch: 5| Step: 7
Training loss: 3.5815822107704474
Validation loss: 2.855058503013888

Epoch: 5| Step: 8
Training loss: 3.4830870022592912
Validation loss: 2.831822173902051

Epoch: 5| Step: 9
Training loss: 3.1593589955876316
Validation loss: 2.813636693191689

Epoch: 5| Step: 10
Training loss: 2.547333284113322
Validation loss: 2.8480534113043907

Epoch: 57| Step: 0
Training loss: 2.93310136383567
Validation loss: 2.8176836124884197

Epoch: 5| Step: 1
Training loss: 2.989458797045204
Validation loss: 2.8330263650743976

Epoch: 5| Step: 2
Training loss: 3.6484922613245083
Validation loss: 2.7990635915664517

Epoch: 5| Step: 3
Training loss: 3.345502162583165
Validation loss: 2.7886778744162406

Epoch: 5| Step: 4
Training loss: 2.7670803228092997
Validation loss: 2.768482459713098

Epoch: 5| Step: 5
Training loss: 3.7596770992013115
Validation loss: 2.8238721312102113

Epoch: 5| Step: 6
Training loss: 2.6019519594582476
Validation loss: 2.8018838342005257

Epoch: 5| Step: 7
Training loss: 3.05733178462796
Validation loss: 2.8041777670730377

Epoch: 5| Step: 8
Training loss: 3.000035762573705
Validation loss: 2.81380818796602

Epoch: 5| Step: 9
Training loss: 3.114301143523026
Validation loss: 2.822379631291468

Epoch: 5| Step: 10
Training loss: 3.0496051782926323
Validation loss: 2.8196409360637933

Epoch: 58| Step: 0
Training loss: 3.5073789740718397
Validation loss: 2.7952851445589513

Epoch: 5| Step: 1
Training loss: 2.8601840182771814
Validation loss: 2.796713486090988

Epoch: 5| Step: 2
Training loss: 2.8549473569596238
Validation loss: 2.788526524495644

Epoch: 5| Step: 3
Training loss: 2.8298776159344756
Validation loss: 2.814552902387868

Epoch: 5| Step: 4
Training loss: 3.2787704545087286
Validation loss: 2.8125517262723485

Epoch: 5| Step: 5
Training loss: 3.144193074303958
Validation loss: 2.8056316506709145

Epoch: 5| Step: 6
Training loss: 3.6807263764541363
Validation loss: 2.77521042843083

Epoch: 5| Step: 7
Training loss: 3.2656141947152277
Validation loss: 2.8108569396771546

Epoch: 5| Step: 8
Training loss: 3.0062790962444925
Validation loss: 2.8287399657675985

Epoch: 5| Step: 9
Training loss: 2.8466910779146044
Validation loss: 2.802754279556875

Epoch: 5| Step: 10
Training loss: 2.914059227335629
Validation loss: 2.818686092150549

Epoch: 59| Step: 0
Training loss: 2.779359324886931
Validation loss: 2.844891726103096

Epoch: 5| Step: 1
Training loss: 3.207637975732582
Validation loss: 2.8472302900337256

Epoch: 5| Step: 2
Training loss: 3.378014948602353
Validation loss: 2.822175286890281

Epoch: 5| Step: 3
Training loss: 2.6354942360621187
Validation loss: 2.817417591894242

Epoch: 5| Step: 4
Training loss: 2.5646341322436785
Validation loss: 2.8089564488561463

Epoch: 5| Step: 5
Training loss: 3.5477133948976807
Validation loss: 2.807706511187205

Epoch: 5| Step: 6
Training loss: 4.010294779456948
Validation loss: 2.800182441731439

Epoch: 5| Step: 7
Training loss: 3.1309333930544043
Validation loss: 2.83991374579392

Epoch: 5| Step: 8
Training loss: 3.3080913067616606
Validation loss: 2.8099852080560335

Epoch: 5| Step: 9
Training loss: 2.9236387753379636
Validation loss: 2.8675826714254957

Epoch: 5| Step: 10
Training loss: 2.2073580069576675
Validation loss: 2.826220432027101

Epoch: 60| Step: 0
Training loss: 2.4921223503374614
Validation loss: 2.799951204117921

Epoch: 5| Step: 1
Training loss: 3.2199019065273853
Validation loss: 2.816443679331246

Epoch: 5| Step: 2
Training loss: 2.700424874396305
Validation loss: 2.8374813384779185

Epoch: 5| Step: 3
Training loss: 3.3431035067469463
Validation loss: 2.809772546267191

Epoch: 5| Step: 4
Training loss: 3.0038333879025036
Validation loss: 2.814469433421891

Epoch: 5| Step: 5
Training loss: 3.250056779805616
Validation loss: 2.812800960321351

Epoch: 5| Step: 6
Training loss: 3.381369902059043
Validation loss: 2.7848492863269825

Epoch: 5| Step: 7
Training loss: 3.0424973559779493
Validation loss: 2.828188610658934

Epoch: 5| Step: 8
Training loss: 2.681472495213074
Validation loss: 2.830230980292752

Epoch: 5| Step: 9
Training loss: 3.7127002906073603
Validation loss: 2.801124637172564

Epoch: 5| Step: 10
Training loss: 3.2909976585192076
Validation loss: 2.7797914565538617

Epoch: 61| Step: 0
Training loss: 3.0548559274119054
Validation loss: 2.8201716436747075

Epoch: 5| Step: 1
Training loss: 3.2575908923990458
Validation loss: 2.798332526159038

Epoch: 5| Step: 2
Training loss: 3.4079122424669266
Validation loss: 2.809646115598941

Epoch: 5| Step: 3
Training loss: 3.0427747476066727
Validation loss: 2.8032513738222153

Epoch: 5| Step: 4
Training loss: 2.6134794926967264
Validation loss: 2.7827158198387942

Epoch: 5| Step: 5
Training loss: 3.3995043954350934
Validation loss: 2.816019659285683

Epoch: 5| Step: 6
Training loss: 2.965956809451585
Validation loss: 2.813722143037827

Epoch: 5| Step: 7
Training loss: 3.5423334429021676
Validation loss: 2.812093198973776

Epoch: 5| Step: 8
Training loss: 2.9627095659390803
Validation loss: 2.8100016482383445

Epoch: 5| Step: 9
Training loss: 2.186151034087433
Validation loss: 2.8221607889213463

Epoch: 5| Step: 10
Training loss: 3.448461084324087
Validation loss: 2.7673093175286967

Epoch: 62| Step: 0
Training loss: 2.65290361431065
Validation loss: 2.7862910781236514

Epoch: 5| Step: 1
Training loss: 3.1374772272385387
Validation loss: 2.828182907205111

Epoch: 5| Step: 2
Training loss: 2.71488959184543
Validation loss: 2.8101801229444034

Epoch: 5| Step: 3
Training loss: 3.05160921513222
Validation loss: 2.80819327744402

Epoch: 5| Step: 4
Training loss: 3.057196559867236
Validation loss: 2.7798919892665745

Epoch: 5| Step: 5
Training loss: 3.192993217731062
Validation loss: 2.800542593020864

Epoch: 5| Step: 6
Training loss: 2.969237598732141
Validation loss: 2.8501712117259412

Epoch: 5| Step: 7
Training loss: 2.845576108717342
Validation loss: 2.8333335191218723

Epoch: 5| Step: 8
Training loss: 3.107845677907838
Validation loss: 2.78458439619523

Epoch: 5| Step: 9
Training loss: 3.658230758538182
Validation loss: 2.8031906560878075

Epoch: 5| Step: 10
Training loss: 3.485075328565563
Validation loss: 2.7832330333323934

Epoch: 63| Step: 0
Training loss: 3.8232537865006044
Validation loss: 2.8138800148794862

Epoch: 5| Step: 1
Training loss: 2.363848354929939
Validation loss: 2.8309959443417916

Epoch: 5| Step: 2
Training loss: 3.2224286733092216
Validation loss: 2.8071983364961213

Epoch: 5| Step: 3
Training loss: 2.547482002801187
Validation loss: 2.7708154721408764

Epoch: 5| Step: 4
Training loss: 2.9186845792508547
Validation loss: 2.8025592442960163

Epoch: 5| Step: 5
Training loss: 3.4007948843824867
Validation loss: 2.8224016998922608

Epoch: 5| Step: 6
Training loss: 2.4060958218412325
Validation loss: 2.8045699262053505

Epoch: 5| Step: 7
Training loss: 3.548517729013076
Validation loss: 2.7658919996983093

Epoch: 5| Step: 8
Training loss: 2.780053985263636
Validation loss: 2.8052612379633306

Epoch: 5| Step: 9
Training loss: 3.5745794729174962
Validation loss: 2.7994893098701317

Epoch: 5| Step: 10
Training loss: 3.199007989184798
Validation loss: 2.7607409942415555

Epoch: 64| Step: 0
Training loss: 3.2247211661043025
Validation loss: 2.8324967174027513

Epoch: 5| Step: 1
Training loss: 2.865881682270303
Validation loss: 2.8073212017822384

Epoch: 5| Step: 2
Training loss: 2.53082469616738
Validation loss: 2.81822995106346

Epoch: 5| Step: 3
Training loss: 2.3644345834692944
Validation loss: 2.807573566456368

Epoch: 5| Step: 4
Training loss: 3.8462038968570984
Validation loss: 2.779152706552909

Epoch: 5| Step: 5
Training loss: 3.1739866246480664
Validation loss: 2.80654239048039

Epoch: 5| Step: 6
Training loss: 2.8775422839016787
Validation loss: 2.798225309233064

Epoch: 5| Step: 7
Training loss: 3.4281178838609057
Validation loss: 2.7503337415211573

Epoch: 5| Step: 8
Training loss: 3.375525539594839
Validation loss: 2.801959929421366

Epoch: 5| Step: 9
Training loss: 3.0499776057687566
Validation loss: 2.826549157396093

Epoch: 5| Step: 10
Training loss: 3.2236138787879294
Validation loss: 2.8189126144268006

Epoch: 65| Step: 0
Training loss: 2.8827160661483444
Validation loss: 2.7763348851875915

Epoch: 5| Step: 1
Training loss: 3.0841202805610974
Validation loss: 2.7991908912824406

Epoch: 5| Step: 2
Training loss: 2.8432707330297813
Validation loss: 2.806954595435647

Epoch: 5| Step: 3
Training loss: 3.4919974256158626
Validation loss: 2.7923634170369676

Epoch: 5| Step: 4
Training loss: 3.276562639708509
Validation loss: 2.794905331439423

Epoch: 5| Step: 5
Training loss: 2.8499108953098964
Validation loss: 2.773289579392376

Epoch: 5| Step: 6
Training loss: 2.8443646447922153
Validation loss: 2.796646907229658

Epoch: 5| Step: 7
Training loss: 3.548358623748379
Validation loss: 2.767654402031088

Epoch: 5| Step: 8
Training loss: 3.172657536532459
Validation loss: 2.8096289999496618

Epoch: 5| Step: 9
Training loss: 2.954396614914005
Validation loss: 2.800611747621388

Epoch: 5| Step: 10
Training loss: 2.8251451843223916
Validation loss: 2.78473739651258

Epoch: 66| Step: 0
Training loss: 2.6968158454639988
Validation loss: 2.773534825471971

Epoch: 5| Step: 1
Training loss: 3.2094703905291144
Validation loss: 2.7885502280770855

Epoch: 5| Step: 2
Training loss: 3.7167183591614963
Validation loss: 2.8300100419252487

Epoch: 5| Step: 3
Training loss: 3.94945153400236
Validation loss: 2.757860235069355

Epoch: 5| Step: 4
Training loss: 3.039519680124519
Validation loss: 2.80698849757495

Epoch: 5| Step: 5
Training loss: 2.6995525236550617
Validation loss: 2.7561455015991494

Epoch: 5| Step: 6
Training loss: 3.3348771493866853
Validation loss: 2.783188342962066

Epoch: 5| Step: 7
Training loss: 1.9941811552795352
Validation loss: 2.770614663198097

Epoch: 5| Step: 8
Training loss: 3.3479300067654036
Validation loss: 2.8070275457196385

Epoch: 5| Step: 9
Training loss: 2.7500421347424635
Validation loss: 2.7845334061899925

Epoch: 5| Step: 10
Training loss: 2.8948277618877594
Validation loss: 2.7705288359722973

Epoch: 67| Step: 0
Training loss: 3.3813449416166903
Validation loss: 2.7895070426580024

Epoch: 5| Step: 1
Training loss: 2.4730100935974093
Validation loss: 2.803388841697989

Epoch: 5| Step: 2
Training loss: 2.6344266295888774
Validation loss: 2.778075709892455

Epoch: 5| Step: 3
Training loss: 2.9156962460627134
Validation loss: 2.7853640272432787

Epoch: 5| Step: 4
Training loss: 3.251043298963931
Validation loss: 2.821213546791413

Epoch: 5| Step: 5
Training loss: 3.0165607799120853
Validation loss: 2.7413910609407974

Epoch: 5| Step: 6
Training loss: 3.2560277939905946
Validation loss: 2.7669526640875537

Epoch: 5| Step: 7
Training loss: 3.2298621792516857
Validation loss: 2.8010396450473847

Epoch: 5| Step: 8
Training loss: 2.7039521115085945
Validation loss: 2.8003158481286667

Epoch: 5| Step: 9
Training loss: 3.71755808473833
Validation loss: 2.793669299290468

Epoch: 5| Step: 10
Training loss: 2.7080466387689492
Validation loss: 2.8148834083370464

Epoch: 68| Step: 0
Training loss: 2.970111574845095
Validation loss: 2.8024464131197884

Epoch: 5| Step: 1
Training loss: 2.496063757583405
Validation loss: 2.769940086501773

Epoch: 5| Step: 2
Training loss: 2.894793499843863
Validation loss: 2.752828390842022

Epoch: 5| Step: 3
Training loss: 3.2184836268154453
Validation loss: 2.7957608507371994

Epoch: 5| Step: 4
Training loss: 2.85314913987041
Validation loss: 2.7994796587329995

Epoch: 5| Step: 5
Training loss: 3.43342376392367
Validation loss: 2.803879488153267

Epoch: 5| Step: 6
Training loss: 3.5969708149043864
Validation loss: 2.8007357036969407

Epoch: 5| Step: 7
Training loss: 3.291534292400259
Validation loss: 2.784758048347543

Epoch: 5| Step: 8
Training loss: 3.239050687482229
Validation loss: 2.805806781022066

Epoch: 5| Step: 9
Training loss: 2.8186012211885694
Validation loss: 2.799674057850458

Epoch: 5| Step: 10
Training loss: 2.7808854796455247
Validation loss: 2.7682029602411227

Epoch: 69| Step: 0
Training loss: 3.524262798949876
Validation loss: 2.7658574770361706

Epoch: 5| Step: 1
Training loss: 2.4390368385113574
Validation loss: 2.7697294264326042

Epoch: 5| Step: 2
Training loss: 2.86145010938783
Validation loss: 2.811815458826131

Epoch: 5| Step: 3
Training loss: 2.6307310485128226
Validation loss: 2.7624086764234597

Epoch: 5| Step: 4
Training loss: 2.72138419735536
Validation loss: 2.790153142416495

Epoch: 5| Step: 5
Training loss: 3.403385462746209
Validation loss: 2.780948291179237

Epoch: 5| Step: 6
Training loss: 2.812534840685893
Validation loss: 2.793953027418616

Epoch: 5| Step: 7
Training loss: 3.7784110517099108
Validation loss: 2.7792653562018392

Epoch: 5| Step: 8
Training loss: 3.598831564643762
Validation loss: 2.767975565796152

Epoch: 5| Step: 9
Training loss: 2.1515003912887907
Validation loss: 2.7674115163001973

Epoch: 5| Step: 10
Training loss: 3.416981163127043
Validation loss: 2.767371561772965

Epoch: 70| Step: 0
Training loss: 3.1455052354169046
Validation loss: 2.8094044028228926

Epoch: 5| Step: 1
Training loss: 3.142508478145649
Validation loss: 2.792990056920487

Epoch: 5| Step: 2
Training loss: 3.344470507990884
Validation loss: 2.7830352547203523

Epoch: 5| Step: 3
Training loss: 2.8642979335218497
Validation loss: 2.790480345267605

Epoch: 5| Step: 4
Training loss: 3.244948496123271
Validation loss: 2.7698220692823683

Epoch: 5| Step: 5
Training loss: 2.144039688333718
Validation loss: 2.7756398200328505

Epoch: 5| Step: 6
Training loss: 3.076010040385871
Validation loss: 2.800613895115995

Epoch: 5| Step: 7
Training loss: 2.9689846548401473
Validation loss: 2.7928500917211183

Epoch: 5| Step: 8
Training loss: 2.917148622929047
Validation loss: 2.771521295457387

Epoch: 5| Step: 9
Training loss: 3.564721870219881
Validation loss: 2.765688841272766

Epoch: 5| Step: 10
Training loss: 3.086528634540885
Validation loss: 2.7452463939026384

Epoch: 71| Step: 0
Training loss: 3.333581454261291
Validation loss: 2.753287885552952

Epoch: 5| Step: 1
Training loss: 3.133258435862468
Validation loss: 2.7793864133711788

Epoch: 5| Step: 2
Training loss: 2.26581756825754
Validation loss: 2.798890465176213

Epoch: 5| Step: 3
Training loss: 3.3197293835389114
Validation loss: 2.7627922220927674

Epoch: 5| Step: 4
Training loss: 2.687363732010425
Validation loss: 2.8355997462370666

Epoch: 5| Step: 5
Training loss: 3.785527103865664
Validation loss: 2.8030438679646092

Epoch: 5| Step: 6
Training loss: 2.6308250283404315
Validation loss: 2.7649151504212024

Epoch: 5| Step: 7
Training loss: 2.8571079626677314
Validation loss: 2.789260812627374

Epoch: 5| Step: 8
Training loss: 2.0867989008059173
Validation loss: 2.7787872172996915

Epoch: 5| Step: 9
Training loss: 3.4824265305107693
Validation loss: 2.782801332916748

Epoch: 5| Step: 10
Training loss: 3.59985430210709
Validation loss: 2.7740565333462985

Epoch: 72| Step: 0
Training loss: 3.65139591749529
Validation loss: 2.784108658810736

Epoch: 5| Step: 1
Training loss: 2.8043191396932263
Validation loss: 2.7800989205906466

Epoch: 5| Step: 2
Training loss: 2.8059883182578838
Validation loss: 2.7719558531816317

Epoch: 5| Step: 3
Training loss: 2.7773513042706686
Validation loss: 2.758914764761007

Epoch: 5| Step: 4
Training loss: 2.9379119584179234
Validation loss: 2.7368692233713454

Epoch: 5| Step: 5
Training loss: 2.8320854655370917
Validation loss: 2.7580788543089563

Epoch: 5| Step: 6
Training loss: 3.0117899964213883
Validation loss: 2.768661425607128

Epoch: 5| Step: 7
Training loss: 3.0183564302714703
Validation loss: 2.744049155521947

Epoch: 5| Step: 8
Training loss: 3.1753091496420915
Validation loss: 2.8414188491183903

Epoch: 5| Step: 9
Training loss: 3.4676984963125217
Validation loss: 2.776100324453407

Epoch: 5| Step: 10
Training loss: 2.7288337582128666
Validation loss: 2.7603361582764996

Epoch: 73| Step: 0
Training loss: 1.978478027468534
Validation loss: 2.7721582859904155

Epoch: 5| Step: 1
Training loss: 2.637654908318136
Validation loss: 2.758178929217394

Epoch: 5| Step: 2
Training loss: 2.662685900005369
Validation loss: 2.7383674719300872

Epoch: 5| Step: 3
Training loss: 2.9370493441714007
Validation loss: 2.795884800897183

Epoch: 5| Step: 4
Training loss: 3.533560478058867
Validation loss: 2.740353377849498

Epoch: 5| Step: 5
Training loss: 3.139043457216536
Validation loss: 2.761813222871097

Epoch: 5| Step: 6
Training loss: 2.5419892799457537
Validation loss: 2.791991812869493

Epoch: 5| Step: 7
Training loss: 4.128637617281166
Validation loss: 2.7409617353490523

Epoch: 5| Step: 8
Training loss: 3.06585105194781
Validation loss: 2.76209400842437

Epoch: 5| Step: 9
Training loss: 3.6657466312141396
Validation loss: 2.7546012667577044

Epoch: 5| Step: 10
Training loss: 2.760961706706277
Validation loss: 2.7667762358321055

Epoch: 74| Step: 0
Training loss: 2.1435009647667087
Validation loss: 2.8077872585382084

Epoch: 5| Step: 1
Training loss: 2.2443692428697744
Validation loss: 2.7714777704468183

Epoch: 5| Step: 2
Training loss: 2.8890894754985563
Validation loss: 2.756014796005796

Epoch: 5| Step: 3
Training loss: 3.700519143877532
Validation loss: 2.7730184924582657

Epoch: 5| Step: 4
Training loss: 2.1819858260843845
Validation loss: 2.775678845538067

Epoch: 5| Step: 5
Training loss: 3.3444514029153423
Validation loss: 2.768074997653514

Epoch: 5| Step: 6
Training loss: 3.3514704480456836
Validation loss: 2.773968878309072

Epoch: 5| Step: 7
Training loss: 3.0093898055840365
Validation loss: 2.7639918032397417

Epoch: 5| Step: 8
Training loss: 2.9712891010155786
Validation loss: 2.7806989172920025

Epoch: 5| Step: 9
Training loss: 3.549206207071855
Validation loss: 2.796929700853543

Epoch: 5| Step: 10
Training loss: 3.6169301676823435
Validation loss: 2.7612089487875426

Epoch: 75| Step: 0
Training loss: 3.4671297155363927
Validation loss: 2.7750117094293034

Epoch: 5| Step: 1
Training loss: 3.004049429190948
Validation loss: 2.7713824392760444

Epoch: 5| Step: 2
Training loss: 3.2432749200038646
Validation loss: 2.747082896106251

Epoch: 5| Step: 3
Training loss: 3.4815473501438903
Validation loss: 2.792878386767286

Epoch: 5| Step: 4
Training loss: 2.5010531114737153
Validation loss: 2.7561448839766136

Epoch: 5| Step: 5
Training loss: 2.5344491216354474
Validation loss: 2.78866968249294

Epoch: 5| Step: 6
Training loss: 3.2238873713771694
Validation loss: 2.7423255655904093

Epoch: 5| Step: 7
Training loss: 3.119131758264636
Validation loss: 2.802728413026727

Epoch: 5| Step: 8
Training loss: 2.6239590170206832
Validation loss: 2.765909749328682

Epoch: 5| Step: 9
Training loss: 2.8960362278690304
Validation loss: 2.759370534943849

Epoch: 5| Step: 10
Training loss: 2.647396006644513
Validation loss: 2.790289898570194

Epoch: 76| Step: 0
Training loss: 2.7731445157746637
Validation loss: 2.760292609211905

Epoch: 5| Step: 1
Training loss: 2.98431140771989
Validation loss: 2.751495207482272

Epoch: 5| Step: 2
Training loss: 3.3231212269989574
Validation loss: 2.791108429300431

Epoch: 5| Step: 3
Training loss: 3.5179258150364823
Validation loss: 2.799172991841237

Epoch: 5| Step: 4
Training loss: 2.5742874715196336
Validation loss: 2.7616978794641436

Epoch: 5| Step: 5
Training loss: 3.5006141123834773
Validation loss: 2.7351331390509444

Epoch: 5| Step: 6
Training loss: 3.169118801828442
Validation loss: 2.76898661108259

Epoch: 5| Step: 7
Training loss: 2.637524019828005
Validation loss: 2.722301971449669

Epoch: 5| Step: 8
Training loss: 3.2330328326506477
Validation loss: 2.7485564182098257

Epoch: 5| Step: 9
Training loss: 2.912104135223321
Validation loss: 2.753904929968393

Epoch: 5| Step: 10
Training loss: 1.8561666681870195
Validation loss: 2.7336414915532785

Epoch: 77| Step: 0
Training loss: 2.9160638640413006
Validation loss: 2.766616453547088

Epoch: 5| Step: 1
Training loss: 3.2823667533193026
Validation loss: 2.7725485717870764

Epoch: 5| Step: 2
Training loss: 3.347059519406943
Validation loss: 2.772651566782118

Epoch: 5| Step: 3
Training loss: 2.7175390243184823
Validation loss: 2.742704519608632

Epoch: 5| Step: 4
Training loss: 2.9180239834339106
Validation loss: 2.803008151102276

Epoch: 5| Step: 5
Training loss: 2.780521340233236
Validation loss: 2.7659339664996523

Epoch: 5| Step: 6
Training loss: 2.4889235214064245
Validation loss: 2.798971946804074

Epoch: 5| Step: 7
Training loss: 3.482359298854143
Validation loss: 2.7868713437770456

Epoch: 5| Step: 8
Training loss: 3.1160279222934135
Validation loss: 2.763278025353658

Epoch: 5| Step: 9
Training loss: 2.6322533441030145
Validation loss: 2.757484967601117

Epoch: 5| Step: 10
Training loss: 3.2949745522241423
Validation loss: 2.7178533516085532

Epoch: 78| Step: 0
Training loss: 3.7476911430651
Validation loss: 2.7905997620776977

Epoch: 5| Step: 1
Training loss: 3.740139649787766
Validation loss: 2.7980360896910215

Epoch: 5| Step: 2
Training loss: 2.7568853186719315
Validation loss: 2.7667357032021247

Epoch: 5| Step: 3
Training loss: 3.1170433986311763
Validation loss: 2.7654007485376746

Epoch: 5| Step: 4
Training loss: 3.456940213314042
Validation loss: 2.7666872280136157

Epoch: 5| Step: 5
Training loss: 1.8496510099178143
Validation loss: 2.782069666278297

Epoch: 5| Step: 6
Training loss: 3.104333365314584
Validation loss: 2.7251256495883607

Epoch: 5| Step: 7
Training loss: 2.663904269265423
Validation loss: 2.797826629248679

Epoch: 5| Step: 8
Training loss: 2.4798686105009478
Validation loss: 2.7667563652440412

Epoch: 5| Step: 9
Training loss: 3.2565297773544
Validation loss: 2.8300812927734285

Epoch: 5| Step: 10
Training loss: 2.488154768910635
Validation loss: 2.7661319029660496

Epoch: 79| Step: 0
Training loss: 3.6504807560602495
Validation loss: 2.765017423776801

Epoch: 5| Step: 1
Training loss: 3.193154051359773
Validation loss: 2.758665895230876

Epoch: 5| Step: 2
Training loss: 2.3622849058700486
Validation loss: 2.7864168838915777

Epoch: 5| Step: 3
Training loss: 3.259458277105702
Validation loss: 2.7606924834382145

Epoch: 5| Step: 4
Training loss: 2.531708381498346
Validation loss: 2.694342936670281

Epoch: 5| Step: 5
Training loss: 2.9701643937463977
Validation loss: 2.744874144644718

Epoch: 5| Step: 6
Training loss: 2.886569255421601
Validation loss: 2.7933987781598653

Epoch: 5| Step: 7
Training loss: 3.159615110787298
Validation loss: 2.7615222350728996

Epoch: 5| Step: 8
Training loss: 3.509772010419553
Validation loss: 2.736282327520851

Epoch: 5| Step: 9
Training loss: 2.6796104486804135
Validation loss: 2.7997165749634063

Epoch: 5| Step: 10
Training loss: 3.02159437042229
Validation loss: 2.7421816223472324

Epoch: 80| Step: 0
Training loss: 2.6583497667751375
Validation loss: 2.7354916956460817

Epoch: 5| Step: 1
Training loss: 3.1857658605658967
Validation loss: 2.7571527909261535

Epoch: 5| Step: 2
Training loss: 3.358872628906794
Validation loss: 2.782785918609803

Epoch: 5| Step: 3
Training loss: 3.1084999885233877
Validation loss: 2.76701750499589

Epoch: 5| Step: 4
Training loss: 3.5861249887158677
Validation loss: 2.771246800987598

Epoch: 5| Step: 5
Training loss: 3.185409608429365
Validation loss: 2.7509245907649147

Epoch: 5| Step: 6
Training loss: 2.594932470453634
Validation loss: 2.76999672278203

Epoch: 5| Step: 7
Training loss: 3.2522369902382313
Validation loss: 2.7573541674449364

Epoch: 5| Step: 8
Training loss: 2.9392157880202268
Validation loss: 2.733504709250661

Epoch: 5| Step: 9
Training loss: 2.8598637397691498
Validation loss: 2.759402560633188

Epoch: 5| Step: 10
Training loss: 2.4845100222189873
Validation loss: 2.75196805059539

Epoch: 81| Step: 0
Training loss: 3.000504451301526
Validation loss: 2.739047424111312

Epoch: 5| Step: 1
Training loss: 3.052535682113507
Validation loss: 2.771917062892907

Epoch: 5| Step: 2
Training loss: 3.4279872703182357
Validation loss: 2.769884327401712

Epoch: 5| Step: 3
Training loss: 2.3093022067892055
Validation loss: 2.740245787814638

Epoch: 5| Step: 4
Training loss: 2.922882396001333
Validation loss: 2.759052638150275

Epoch: 5| Step: 5
Training loss: 3.5175572489490188
Validation loss: 2.7386412975193357

Epoch: 5| Step: 6
Training loss: 2.409277262603992
Validation loss: 2.7727910343444226

Epoch: 5| Step: 7
Training loss: 3.727039490568595
Validation loss: 2.7802833129827755

Epoch: 5| Step: 8
Training loss: 2.754343677166933
Validation loss: 2.7792929280211194

Epoch: 5| Step: 9
Training loss: 2.8564054150525626
Validation loss: 2.762144725848299

Epoch: 5| Step: 10
Training loss: 2.686481016511227
Validation loss: 2.754361196859415

Epoch: 82| Step: 0
Training loss: 3.058867187749419
Validation loss: 2.7682418516568763

Epoch: 5| Step: 1
Training loss: 3.04795497436508
Validation loss: 2.7544987295084526

Epoch: 5| Step: 2
Training loss: 3.698719607296346
Validation loss: 2.7178134420116606

Epoch: 5| Step: 3
Training loss: 3.526132436886536
Validation loss: 2.79383820478498

Epoch: 5| Step: 4
Training loss: 2.891486457097731
Validation loss: 2.7359890956840074

Epoch: 5| Step: 5
Training loss: 2.0920213993794197
Validation loss: 2.7483742216039646

Epoch: 5| Step: 6
Training loss: 3.194859852709441
Validation loss: 2.747563667266218

Epoch: 5| Step: 7
Training loss: 3.2875709322975366
Validation loss: 2.7697707454968006

Epoch: 5| Step: 8
Training loss: 2.4569826348715416
Validation loss: 2.7622078308193525

Epoch: 5| Step: 9
Training loss: 2.417568487954667
Validation loss: 2.754047868587375

Epoch: 5| Step: 10
Training loss: 2.8541771176186304
Validation loss: 2.7344843529371103

Epoch: 83| Step: 0
Training loss: 2.6471624765484445
Validation loss: 2.683200079665796

Epoch: 5| Step: 1
Training loss: 2.730487435949563
Validation loss: 2.7837869545554113

Epoch: 5| Step: 2
Training loss: 2.8830821006853053
Validation loss: 2.760022543232077

Epoch: 5| Step: 3
Training loss: 2.8805865866611184
Validation loss: 2.7705591170797286

Epoch: 5| Step: 4
Training loss: 3.2686308392309136
Validation loss: 2.7662764339899355

Epoch: 5| Step: 5
Training loss: 3.216153180606908
Validation loss: 2.7546764289682297

Epoch: 5| Step: 6
Training loss: 3.1594812452674534
Validation loss: 2.7805419081328417

Epoch: 5| Step: 7
Training loss: 3.0156299017831762
Validation loss: 2.771754096963374

Epoch: 5| Step: 8
Training loss: 2.6329785755878063
Validation loss: 2.709523164125304

Epoch: 5| Step: 9
Training loss: 2.513120458864911
Validation loss: 2.7841110971198186

Epoch: 5| Step: 10
Training loss: 3.9377978984222084
Validation loss: 2.776667222543672

Epoch: 84| Step: 0
Training loss: 3.3659072176770195
Validation loss: 2.7553724209877335

Epoch: 5| Step: 1
Training loss: 3.248561687581891
Validation loss: 2.767955736234327

Epoch: 5| Step: 2
Training loss: 3.0727305900141317
Validation loss: 2.773605914204177

Epoch: 5| Step: 3
Training loss: 2.7382271798056346
Validation loss: 2.7689821318614274

Epoch: 5| Step: 4
Training loss: 2.8775464266454502
Validation loss: 2.7125247796733256

Epoch: 5| Step: 5
Training loss: 3.445443425534596
Validation loss: 2.7079338410145186

Epoch: 5| Step: 6
Training loss: 3.2224995522983377
Validation loss: 2.7817203446176912

Epoch: 5| Step: 7
Training loss: 2.6791987293118518
Validation loss: 2.7821597659613206

Epoch: 5| Step: 8
Training loss: 2.52398770124096
Validation loss: 2.7210492614423885

Epoch: 5| Step: 9
Training loss: 3.2195224760917664
Validation loss: 2.7584780754680325

Epoch: 5| Step: 10
Training loss: 2.3098946406129484
Validation loss: 2.7242451815193083

Epoch: 85| Step: 0
Training loss: 3.1544323210083722
Validation loss: 2.724776257653359

Epoch: 5| Step: 1
Training loss: 2.518279860471818
Validation loss: 2.746561156301347

Epoch: 5| Step: 2
Training loss: 2.613087554276492
Validation loss: 2.7957646901056377

Epoch: 5| Step: 3
Training loss: 3.8443481476127666
Validation loss: 2.687267798055457

Epoch: 5| Step: 4
Training loss: 3.1585419142265283
Validation loss: 2.7501177040110703

Epoch: 5| Step: 5
Training loss: 2.89245976135699
Validation loss: 2.703714069797909

Epoch: 5| Step: 6
Training loss: 2.5699688991935807
Validation loss: 2.7697616498205857

Epoch: 5| Step: 7
Training loss: 2.5519028165124777
Validation loss: 2.730495102954275

Epoch: 5| Step: 8
Training loss: 3.7677970731643575
Validation loss: 2.7675773598662397

Epoch: 5| Step: 9
Training loss: 2.8134354625111073
Validation loss: 2.7855202105501693

Epoch: 5| Step: 10
Training loss: 2.896779699311422
Validation loss: 2.730852792770991

Epoch: 86| Step: 0
Training loss: 2.2583739958571023
Validation loss: 2.692931556664366

Epoch: 5| Step: 1
Training loss: 2.69022391029074
Validation loss: 2.716354446266122

Epoch: 5| Step: 2
Training loss: 3.0127106652262783
Validation loss: 2.7967956902033992

Epoch: 5| Step: 3
Training loss: 2.922469134791852
Validation loss: 2.719353399194973

Epoch: 5| Step: 4
Training loss: 2.767905292004293
Validation loss: 2.7393450172278624

Epoch: 5| Step: 5
Training loss: 3.4100747289887354
Validation loss: 2.741143933639795

Epoch: 5| Step: 6
Training loss: 2.3221549480170562
Validation loss: 2.7737401339320593

Epoch: 5| Step: 7
Training loss: 3.2432586003704595
Validation loss: 2.700002543282232

Epoch: 5| Step: 8
Training loss: 3.5884684355433065
Validation loss: 2.7476530379927246

Epoch: 5| Step: 9
Training loss: 2.7069037161065563
Validation loss: 2.747666827197314

Epoch: 5| Step: 10
Training loss: 3.407491055404779
Validation loss: 2.73427999351918

Epoch: 87| Step: 0
Training loss: 2.582957414737544
Validation loss: 2.7732472704743607

Epoch: 5| Step: 1
Training loss: 3.1058159016361477
Validation loss: 2.7477780638659315

Epoch: 5| Step: 2
Training loss: 3.1781737077219487
Validation loss: 2.7522591971662704

Epoch: 5| Step: 3
Training loss: 3.929806292275996
Validation loss: 2.73431838579064

Epoch: 5| Step: 4
Training loss: 2.667432337352351
Validation loss: 2.745071019269082

Epoch: 5| Step: 5
Training loss: 2.3416422203480307
Validation loss: 2.7256326586941846

Epoch: 5| Step: 6
Training loss: 2.6573945216350023
Validation loss: 2.7523472427454467

Epoch: 5| Step: 7
Training loss: 3.2275941691116308
Validation loss: 2.710834926428238

Epoch: 5| Step: 8
Training loss: 2.451433120727129
Validation loss: 2.73690011574657

Epoch: 5| Step: 9
Training loss: 2.8094620297607653
Validation loss: 2.7284752399583088

Epoch: 5| Step: 10
Training loss: 3.7332841245496247
Validation loss: 2.732423502828857

Epoch: 88| Step: 0
Training loss: 2.807647757985742
Validation loss: 2.734614729209525

Epoch: 5| Step: 1
Training loss: 3.454641156034556
Validation loss: 2.7954231903507405

Epoch: 5| Step: 2
Training loss: 2.46642947688991
Validation loss: 2.803312187178962

Epoch: 5| Step: 3
Training loss: 2.6708937956998056
Validation loss: 2.7227750899298315

Epoch: 5| Step: 4
Training loss: 3.5088375777243646
Validation loss: 2.801231049417929

Epoch: 5| Step: 5
Training loss: 2.9692698776403277
Validation loss: 2.7447895122347687

Epoch: 5| Step: 6
Training loss: 3.1773991328811353
Validation loss: 2.7385334211652927

Epoch: 5| Step: 7
Training loss: 3.0267686260655706
Validation loss: 2.733354993859921

Epoch: 5| Step: 8
Training loss: 2.6852478526708548
Validation loss: 2.746060297575288

Epoch: 5| Step: 9
Training loss: 3.2417436043076164
Validation loss: 2.781912020290534

Epoch: 5| Step: 10
Training loss: 2.4124572750122986
Validation loss: 2.7275601295564114

Epoch: 89| Step: 0
Training loss: 3.5588353365014718
Validation loss: 2.7332665419002637

Epoch: 5| Step: 1
Training loss: 2.7712629362844527
Validation loss: 2.709980735451512

Epoch: 5| Step: 2
Training loss: 2.659582852086589
Validation loss: 2.7966979825456786

Epoch: 5| Step: 3
Training loss: 2.643745429573888
Validation loss: 2.746725555819157

Epoch: 5| Step: 4
Training loss: 2.779379397766875
Validation loss: 2.8060209621382945

Epoch: 5| Step: 5
Training loss: 2.9049308818532547
Validation loss: 2.753965693588412

Epoch: 5| Step: 6
Training loss: 3.0328607114156485
Validation loss: 2.751828289747089

Epoch: 5| Step: 7
Training loss: 2.6731058598373405
Validation loss: 2.8115129878712013

Epoch: 5| Step: 8
Training loss: 2.900689332524392
Validation loss: 2.7403662402097555

Epoch: 5| Step: 9
Training loss: 3.6311807228610418
Validation loss: 2.753898476885168

Epoch: 5| Step: 10
Training loss: 3.2498769003223082
Validation loss: 2.7481304481078057

Epoch: 90| Step: 0
Training loss: 3.559723156655074
Validation loss: 2.772463300057735

Epoch: 5| Step: 1
Training loss: 2.9022252917342466
Validation loss: 2.740794090476167

Epoch: 5| Step: 2
Training loss: 2.9229535238960684
Validation loss: 2.7449439470937658

Epoch: 5| Step: 3
Training loss: 2.7946091322994606
Validation loss: 2.709967960643084

Epoch: 5| Step: 4
Training loss: 3.2450028662529324
Validation loss: 2.794824250432904

Epoch: 5| Step: 5
Training loss: 2.6258274772318053
Validation loss: 2.7288062120546432

Epoch: 5| Step: 6
Training loss: 3.0722223219393423
Validation loss: 2.751956340782356

Epoch: 5| Step: 7
Training loss: 2.969443631704862
Validation loss: 2.763774176738807

Epoch: 5| Step: 8
Training loss: 2.6033202868569
Validation loss: 2.7156004361027115

Epoch: 5| Step: 9
Training loss: 2.2466675133330942
Validation loss: 2.753834667626764

Epoch: 5| Step: 10
Training loss: 3.492978546190272
Validation loss: 2.7610485880561693

Epoch: 91| Step: 0
Training loss: 2.4973258020939517
Validation loss: 2.701734107354702

Epoch: 5| Step: 1
Training loss: 2.6882299274754855
Validation loss: 2.7285609346102486

Epoch: 5| Step: 2
Training loss: 3.144060523773109
Validation loss: 2.7216310588188106

Epoch: 5| Step: 3
Training loss: 2.8361241302872235
Validation loss: 2.7618398726701967

Epoch: 5| Step: 4
Training loss: 2.4400419039332992
Validation loss: 2.718908442754388

Epoch: 5| Step: 5
Training loss: 3.256652771976417
Validation loss: 2.6776145987913407

Epoch: 5| Step: 6
Training loss: 3.4411472738378546
Validation loss: 2.7741703519330723

Epoch: 5| Step: 7
Training loss: 2.4511389984722496
Validation loss: 2.76726209564127

Epoch: 5| Step: 8
Training loss: 3.3113931210074514
Validation loss: 2.73381789665922

Epoch: 5| Step: 9
Training loss: 3.0076358891939985
Validation loss: 2.7523501665275756

Epoch: 5| Step: 10
Training loss: 3.1628723166615353
Validation loss: 2.674134658595178

Epoch: 92| Step: 0
Training loss: 3.1178560615578874
Validation loss: 2.7575450266575015

Epoch: 5| Step: 1
Training loss: 3.208081536919218
Validation loss: 2.7354790109223415

Epoch: 5| Step: 2
Training loss: 3.197263537052617
Validation loss: 2.751041205920319

Epoch: 5| Step: 3
Training loss: 3.616385912801965
Validation loss: 2.7417584739723933

Epoch: 5| Step: 4
Training loss: 2.8595327531833448
Validation loss: 2.713629106719627

Epoch: 5| Step: 5
Training loss: 2.8607154580854255
Validation loss: 2.738030764372848

Epoch: 5| Step: 6
Training loss: 3.1509699705600327
Validation loss: 2.729208150205665

Epoch: 5| Step: 7
Training loss: 2.9757357673243763
Validation loss: 2.741322264060198

Epoch: 5| Step: 8
Training loss: 2.483879375803108
Validation loss: 2.759926011973954

Epoch: 5| Step: 9
Training loss: 2.7897317548207
Validation loss: 2.7327811344281834

Epoch: 5| Step: 10
Training loss: 2.26448472366015
Validation loss: 2.7561086132924046

Epoch: 93| Step: 0
Training loss: 2.87218603000265
Validation loss: 2.730256514381502

Epoch: 5| Step: 1
Training loss: 3.3938854380185024
Validation loss: 2.767099828820474

Epoch: 5| Step: 2
Training loss: 3.018544735455529
Validation loss: 2.7244221743304737

Epoch: 5| Step: 3
Training loss: 2.86042041116142
Validation loss: 2.7777681202019875

Epoch: 5| Step: 4
Training loss: 3.3595094165968096
Validation loss: 2.7553111626943703

Epoch: 5| Step: 5
Training loss: 2.6109590576304638
Validation loss: 2.7468374643207953

Epoch: 5| Step: 6
Training loss: 3.081491865527081
Validation loss: 2.7476758448648995

Epoch: 5| Step: 7
Training loss: 2.5953158512357954
Validation loss: 2.696243830504301

Epoch: 5| Step: 8
Training loss: 2.643755980861383
Validation loss: 2.733495875547144

Epoch: 5| Step: 9
Training loss: 3.3922819668246693
Validation loss: 2.7338788769929097

Epoch: 5| Step: 10
Training loss: 2.5234482708869397
Validation loss: 2.721174214242186

Epoch: 94| Step: 0
Training loss: 2.090728629470454
Validation loss: 2.7472243522561324

Epoch: 5| Step: 1
Training loss: 3.059511088538676
Validation loss: 2.7027853850161043

Epoch: 5| Step: 2
Training loss: 2.2989652296227012
Validation loss: 2.7239775527078116

Epoch: 5| Step: 3
Training loss: 2.605653679045489
Validation loss: 2.7394970938343373

Epoch: 5| Step: 4
Training loss: 3.3734439512317453
Validation loss: 2.7186065200325786

Epoch: 5| Step: 5
Training loss: 3.4006793465431833
Validation loss: 2.669167029610667

Epoch: 5| Step: 6
Training loss: 3.1377143087562995
Validation loss: 2.734985020999871

Epoch: 5| Step: 7
Training loss: 3.470953439112841
Validation loss: 2.6917567975938326

Epoch: 5| Step: 8
Training loss: 2.8493533421434045
Validation loss: 2.7219843312295082

Epoch: 5| Step: 9
Training loss: 3.317695142559057
Validation loss: 2.6747377769865897

Epoch: 5| Step: 10
Training loss: 2.5619416907983643
Validation loss: 2.692524300291538

Epoch: 95| Step: 0
Training loss: 3.0959557270758364
Validation loss: 2.724384671111723

Epoch: 5| Step: 1
Training loss: 3.0569697681213674
Validation loss: 2.720674881211636

Epoch: 5| Step: 2
Training loss: 3.2258944431732566
Validation loss: 2.750571953071615

Epoch: 5| Step: 3
Training loss: 2.4649246130010387
Validation loss: 2.720502366679724

Epoch: 5| Step: 4
Training loss: 3.6700115263963187
Validation loss: 2.6940746716137736

Epoch: 5| Step: 5
Training loss: 2.7754347795682763
Validation loss: 2.75097677776936

Epoch: 5| Step: 6
Training loss: 2.4251910734112707
Validation loss: 2.718711926310715

Epoch: 5| Step: 7
Training loss: 3.1603110597317308
Validation loss: 2.7256775976832213

Epoch: 5| Step: 8
Training loss: 2.6676315608379397
Validation loss: 2.722123651786181

Epoch: 5| Step: 9
Training loss: 3.205549262437496
Validation loss: 2.7283466149442597

Epoch: 5| Step: 10
Training loss: 2.634408076792504
Validation loss: 2.7800624681543824

Epoch: 96| Step: 0
Training loss: 2.6162688052052463
Validation loss: 2.7297913519700505

Epoch: 5| Step: 1
Training loss: 3.3189185952791678
Validation loss: 2.7558579879955745

Epoch: 5| Step: 2
Training loss: 3.4509267585032446
Validation loss: 2.7393940988482575

Epoch: 5| Step: 3
Training loss: 2.402434060484913
Validation loss: 2.750542000899691

Epoch: 5| Step: 4
Training loss: 3.198188066097416
Validation loss: 2.741451589471107

Epoch: 5| Step: 5
Training loss: 2.4913791792586992
Validation loss: 2.770553194130405

Epoch: 5| Step: 6
Training loss: 2.9876585467417365
Validation loss: 2.7165966660070735

Epoch: 5| Step: 7
Training loss: 2.7091228116945887
Validation loss: 2.7590626555595605

Epoch: 5| Step: 8
Training loss: 3.230626094358159
Validation loss: 2.7156127171162114

Epoch: 5| Step: 9
Training loss: 2.683011143061602
Validation loss: 2.697685100312923

Epoch: 5| Step: 10
Training loss: 3.190879376739179
Validation loss: 2.714630949129294

Epoch: 97| Step: 0
Training loss: 3.0085183640601576
Validation loss: 2.764505022270523

Epoch: 5| Step: 1
Training loss: 3.085127403064523
Validation loss: 2.7372632726560426

Epoch: 5| Step: 2
Training loss: 2.8775175930250967
Validation loss: 2.728822733582459

Epoch: 5| Step: 3
Training loss: 2.921934076211772
Validation loss: 2.8090207673833287

Epoch: 5| Step: 4
Training loss: 2.810502508580721
Validation loss: 2.7207503908054265

Epoch: 5| Step: 5
Training loss: 2.249606098027599
Validation loss: 2.7593019066841267

Epoch: 5| Step: 6
Training loss: 3.3310977750712993
Validation loss: 2.740190585986995

Epoch: 5| Step: 7
Training loss: 2.940121231953122
Validation loss: 2.734050740647277

Epoch: 5| Step: 8
Training loss: 3.2192811990564962
Validation loss: 2.7161189573192352

Epoch: 5| Step: 9
Training loss: 3.3237892527878845
Validation loss: 2.733681699928894

Epoch: 5| Step: 10
Training loss: 2.6823809463802686
Validation loss: 2.708914345324962

Epoch: 98| Step: 0
Training loss: 2.8513133319007236
Validation loss: 2.734772916984069

Epoch: 5| Step: 1
Training loss: 2.660073344861514
Validation loss: 2.7144672634705764

Epoch: 5| Step: 2
Training loss: 2.837787287616586
Validation loss: 2.8034126976139833

Epoch: 5| Step: 3
Training loss: 1.9707388142131965
Validation loss: 2.7533287344030106

Epoch: 5| Step: 4
Training loss: 2.565771758961754
Validation loss: 2.736206945798089

Epoch: 5| Step: 5
Training loss: 3.090044056106119
Validation loss: 2.69992445183373

Epoch: 5| Step: 6
Training loss: 3.236047726848585
Validation loss: 2.7400738121763206

Epoch: 5| Step: 7
Training loss: 2.7313287824009804
Validation loss: 2.7389913529421213

Epoch: 5| Step: 8
Training loss: 3.418295882782609
Validation loss: 2.743179114418826

Epoch: 5| Step: 9
Training loss: 3.446615859222272
Validation loss: 2.7495406877529613

Epoch: 5| Step: 10
Training loss: 3.3359795239412477
Validation loss: 2.743817123573846

Epoch: 99| Step: 0
Training loss: 2.979613335121028
Validation loss: 2.7484710503826264

Epoch: 5| Step: 1
Training loss: 2.5160191387121773
Validation loss: 2.723963212540014

Epoch: 5| Step: 2
Training loss: 3.6564766577214622
Validation loss: 2.723342068801847

Epoch: 5| Step: 3
Training loss: 2.2961820218776197
Validation loss: 2.6970814083317816

Epoch: 5| Step: 4
Training loss: 2.408098080858608
Validation loss: 2.715166587753565

Epoch: 5| Step: 5
Training loss: 3.738251657079838
Validation loss: 2.755511814141683

Epoch: 5| Step: 6
Training loss: 2.9025622525632215
Validation loss: 2.704082834530169

Epoch: 5| Step: 7
Training loss: 2.3964002076830364
Validation loss: 2.6855906929923568

Epoch: 5| Step: 8
Training loss: 2.842795746380603
Validation loss: 2.768895867943985

Epoch: 5| Step: 9
Training loss: 3.2711046596333326
Validation loss: 2.6930921314409195

Epoch: 5| Step: 10
Training loss: 2.7422052366547116
Validation loss: 2.762109824074101

Epoch: 100| Step: 0
Training loss: 3.3477468400447035
Validation loss: 2.7229389813569536

Epoch: 5| Step: 1
Training loss: 2.635604690860679
Validation loss: 2.72931991844492

Epoch: 5| Step: 2
Training loss: 2.9280890821861574
Validation loss: 2.7018504213291434

Epoch: 5| Step: 3
Training loss: 2.7327587473551955
Validation loss: 2.7334899604480483

Epoch: 5| Step: 4
Training loss: 2.810043958001091
Validation loss: 2.7090403925157145

Epoch: 5| Step: 5
Training loss: 2.9140674089896654
Validation loss: 2.754056410170933

Epoch: 5| Step: 6
Training loss: 2.9428036474585113
Validation loss: 2.7313606638331294

Epoch: 5| Step: 7
Training loss: 2.904329383119176
Validation loss: 2.697394507975449

Epoch: 5| Step: 8
Training loss: 3.007451023327702
Validation loss: 2.7108957674510026

Epoch: 5| Step: 9
Training loss: 2.3265911400276638
Validation loss: 2.7284272604514728

Epoch: 5| Step: 10
Training loss: 3.7669720911298987
Validation loss: 2.7113757636086326

Epoch: 101| Step: 0
Training loss: 3.8483499434156587
Validation loss: 2.6980502279687686

Epoch: 5| Step: 1
Training loss: 2.7368719416895484
Validation loss: 2.7221600998269446

Epoch: 5| Step: 2
Training loss: 2.654484869199085
Validation loss: 2.715009109773976

Epoch: 5| Step: 3
Training loss: 3.0051390817862167
Validation loss: 2.701826990418292

Epoch: 5| Step: 4
Training loss: 3.3376086156651597
Validation loss: 2.708955117562188

Epoch: 5| Step: 5
Training loss: 2.3551184044166487
Validation loss: 2.786466797033886

Epoch: 5| Step: 6
Training loss: 2.5068426901143472
Validation loss: 2.7249851367142806

Epoch: 5| Step: 7
Training loss: 2.8546086175686276
Validation loss: 2.7116517244385854

Epoch: 5| Step: 8
Training loss: 2.7200267906833036
Validation loss: 2.7153199203283114

Epoch: 5| Step: 9
Training loss: 3.227536403175909
Validation loss: 2.7738281492516577

Epoch: 5| Step: 10
Training loss: 3.0956696998885564
Validation loss: 2.736732286705696

Epoch: 102| Step: 0
Training loss: 3.3785012063045023
Validation loss: 2.721287035959226

Epoch: 5| Step: 1
Training loss: 2.860772630325492
Validation loss: 2.7396025123394305

Epoch: 5| Step: 2
Training loss: 2.842183782188161
Validation loss: 2.7159912101859147

Epoch: 5| Step: 3
Training loss: 2.3153685228240395
Validation loss: 2.7237321524487177

Epoch: 5| Step: 4
Training loss: 2.586118478579008
Validation loss: 2.739640058958519

Epoch: 5| Step: 5
Training loss: 2.551777246505598
Validation loss: 2.730394870613493

Epoch: 5| Step: 6
Training loss: 3.114715437282999
Validation loss: 2.695810887723732

Epoch: 5| Step: 7
Training loss: 3.4519506330352696
Validation loss: 2.7156600129903907

Epoch: 5| Step: 8
Training loss: 2.7941305665110177
Validation loss: 2.7223383356454858

Epoch: 5| Step: 9
Training loss: 2.3512604478262213
Validation loss: 2.708319867639378

Epoch: 5| Step: 10
Training loss: 3.723610786634962
Validation loss: 2.716139984588623

Epoch: 103| Step: 0
Training loss: 2.8621259286661322
Validation loss: 2.719126857107274

Epoch: 5| Step: 1
Training loss: 2.605915997735894
Validation loss: 2.7195547287497592

Epoch: 5| Step: 2
Training loss: 2.8509863702561313
Validation loss: 2.7754700144135174

Epoch: 5| Step: 3
Training loss: 2.9568098380924224
Validation loss: 2.6837613065301764

Epoch: 5| Step: 4
Training loss: 3.4133801509457755
Validation loss: 2.708189672883243

Epoch: 5| Step: 5
Training loss: 2.9075881994486843
Validation loss: 2.7207405291468163

Epoch: 5| Step: 6
Training loss: 3.1610159064245384
Validation loss: 2.668197200942425

Epoch: 5| Step: 7
Training loss: 3.501326173486916
Validation loss: 2.6921184754797

Epoch: 5| Step: 8
Training loss: 2.5071517691882748
Validation loss: 2.7541452639679935

Epoch: 5| Step: 9
Training loss: 2.7950151109372254
Validation loss: 2.681632994220366

Epoch: 5| Step: 10
Training loss: 2.184385534869591
Validation loss: 2.730123935506484

Epoch: 104| Step: 0
Training loss: 2.784212399240049
Validation loss: 2.7325139898234707

Epoch: 5| Step: 1
Training loss: 2.76431614136311
Validation loss: 2.7032101515977627

Epoch: 5| Step: 2
Training loss: 3.3747995105109605
Validation loss: 2.7223022078208645

Epoch: 5| Step: 3
Training loss: 2.3591189213912287
Validation loss: 2.7152969483743656

Epoch: 5| Step: 4
Training loss: 3.319760696335297
Validation loss: 2.6846757459243

Epoch: 5| Step: 5
Training loss: 2.9936779483415097
Validation loss: 2.7302475387116383

Epoch: 5| Step: 6
Training loss: 2.40128309204239
Validation loss: 2.755711037852177

Epoch: 5| Step: 7
Training loss: 3.36447225255433
Validation loss: 2.7533504886753706

Epoch: 5| Step: 8
Training loss: 2.584406096745302
Validation loss: 2.7286166286777433

Epoch: 5| Step: 9
Training loss: 2.717073032979907
Validation loss: 2.7361386172839373

Epoch: 5| Step: 10
Training loss: 3.231184560677575
Validation loss: 2.6818995022525107

Epoch: 105| Step: 0
Training loss: 2.7557262277644554
Validation loss: 2.715373420406897

Epoch: 5| Step: 1
Training loss: 2.5944982161884274
Validation loss: 2.708408282420613

Epoch: 5| Step: 2
Training loss: 3.413954953522764
Validation loss: 2.731304802329185

Epoch: 5| Step: 3
Training loss: 2.8595639359219596
Validation loss: 2.7307451466730073

Epoch: 5| Step: 4
Training loss: 2.7776843585094064
Validation loss: 2.762584839806503

Epoch: 5| Step: 5
Training loss: 3.041543844869923
Validation loss: 2.733637845339439

Epoch: 5| Step: 6
Training loss: 3.0540602252170683
Validation loss: 2.6879404608022925

Epoch: 5| Step: 7
Training loss: 2.517041109873159
Validation loss: 2.7256709385692135

Epoch: 5| Step: 8
Training loss: 3.1660446928126595
Validation loss: 2.6761764954219918

Epoch: 5| Step: 9
Training loss: 2.764277587940639
Validation loss: 2.727216086618282

Epoch: 5| Step: 10
Training loss: 3.1421705400112594
Validation loss: 2.7205313246613128

Epoch: 106| Step: 0
Training loss: 2.4329978249975626
Validation loss: 2.7497526973078514

Epoch: 5| Step: 1
Training loss: 3.246184530262659
Validation loss: 2.6993415269993735

Epoch: 5| Step: 2
Training loss: 2.539981523131202
Validation loss: 2.7035816704770177

Epoch: 5| Step: 3
Training loss: 3.223501309656842
Validation loss: 2.7180861842672153

Epoch: 5| Step: 4
Training loss: 2.3646675016460694
Validation loss: 2.7338090883493056

Epoch: 5| Step: 5
Training loss: 3.007269317328969
Validation loss: 2.6917044672332007

Epoch: 5| Step: 6
Training loss: 3.09568402498051
Validation loss: 2.6718604675062787

Epoch: 5| Step: 7
Training loss: 3.080558628103293
Validation loss: 2.75764227156443

Epoch: 5| Step: 8
Training loss: 3.25687385777212
Validation loss: 2.719971706324959

Epoch: 5| Step: 9
Training loss: 2.6188896451512087
Validation loss: 2.7286320544485734

Epoch: 5| Step: 10
Training loss: 2.742804824594096
Validation loss: 2.780097126105476

Epoch: 107| Step: 0
Training loss: 3.2765885438916365
Validation loss: 2.737378646371642

Epoch: 5| Step: 1
Training loss: 3.461619428356107
Validation loss: 2.716505518570958

Epoch: 5| Step: 2
Training loss: 2.5643683344703008
Validation loss: 2.6884680881429786

Epoch: 5| Step: 3
Training loss: 3.095693729037397
Validation loss: 2.729871895633325

Epoch: 5| Step: 4
Training loss: 1.9831064329531498
Validation loss: 2.700438381673654

Epoch: 5| Step: 5
Training loss: 3.3777657938069803
Validation loss: 2.7227367062560615

Epoch: 5| Step: 6
Training loss: 3.362237606659115
Validation loss: 2.751186535311029

Epoch: 5| Step: 7
Training loss: 2.6238398031611205
Validation loss: 2.687140077956188

Epoch: 5| Step: 8
Training loss: 2.5265943309357075
Validation loss: 2.7099326867609244

Epoch: 5| Step: 9
Training loss: 2.6306375184852264
Validation loss: 2.692743080089361

Epoch: 5| Step: 10
Training loss: 2.7273010303011276
Validation loss: 2.7262438450302726

Epoch: 108| Step: 0
Training loss: 3.2531403261789253
Validation loss: 2.700606018944879

Epoch: 5| Step: 1
Training loss: 2.2518984944316722
Validation loss: 2.72770942146656

Epoch: 5| Step: 2
Training loss: 2.723402055256924
Validation loss: 2.735701416633356

Epoch: 5| Step: 3
Training loss: 3.2399668246796005
Validation loss: 2.667233485372899

Epoch: 5| Step: 4
Training loss: 2.6005813535563242
Validation loss: 2.7247579865068388

Epoch: 5| Step: 5
Training loss: 3.2990179103285353
Validation loss: 2.7172592360712637

Epoch: 5| Step: 6
Training loss: 2.9726225641775677
Validation loss: 2.6425621061878886

Epoch: 5| Step: 7
Training loss: 3.6355534539635057
Validation loss: 2.6691873798585597

Epoch: 5| Step: 8
Training loss: 2.5769696970509846
Validation loss: 2.6995785734860465

Epoch: 5| Step: 9
Training loss: 2.4821043374188556
Validation loss: 2.6725361208859106

Epoch: 5| Step: 10
Training loss: 2.6692107006215795
Validation loss: 2.7142467390929577

Epoch: 109| Step: 0
Training loss: 3.860264849298047
Validation loss: 2.704297892152874

Epoch: 5| Step: 1
Training loss: 2.9849207513918765
Validation loss: 2.7207815745556543

Epoch: 5| Step: 2
Training loss: 2.1998556783328227
Validation loss: 2.7090311128079634

Epoch: 5| Step: 3
Training loss: 2.8486326451084114
Validation loss: 2.6908813309489195

Epoch: 5| Step: 4
Training loss: 3.170780989172672
Validation loss: 2.6631207344666814

Epoch: 5| Step: 5
Training loss: 3.0527334377997604
Validation loss: 2.6760492691051287

Epoch: 5| Step: 6
Training loss: 2.499241141540635
Validation loss: 2.694100581241411

Epoch: 5| Step: 7
Training loss: 3.0655813480422998
Validation loss: 2.7142138556825817

Epoch: 5| Step: 8
Training loss: 3.0512247972021864
Validation loss: 2.7473370280074407

Epoch: 5| Step: 9
Training loss: 2.732343867553841
Validation loss: 2.702132508081562

Epoch: 5| Step: 10
Training loss: 2.379544277477379
Validation loss: 2.751581057273942

Epoch: 110| Step: 0
Training loss: 2.5390581805852683
Validation loss: 2.7615126963291265

Epoch: 5| Step: 1
Training loss: 2.8001264713880016
Validation loss: 2.751746354975176

Epoch: 5| Step: 2
Training loss: 2.411606313780256
Validation loss: 2.7423966135835705

Epoch: 5| Step: 3
Training loss: 2.72576044303757
Validation loss: 2.6982528629721023

Epoch: 5| Step: 4
Training loss: 3.5240080174886406
Validation loss: 2.720879832832448

Epoch: 5| Step: 5
Training loss: 2.8087073291207716
Validation loss: 2.7366081585724493

Epoch: 5| Step: 6
Training loss: 3.020138540058628
Validation loss: 2.7598027914065333

Epoch: 5| Step: 7
Training loss: 3.5379534535211494
Validation loss: 2.7253628332953483

Epoch: 5| Step: 8
Training loss: 2.8881843779716814
Validation loss: 2.6871857026507513

Epoch: 5| Step: 9
Training loss: 2.851755799313121
Validation loss: 2.68502318788181

Epoch: 5| Step: 10
Training loss: 2.544933585478861
Validation loss: 2.7476251440088717

Epoch: 111| Step: 0
Training loss: 2.307137948477651
Validation loss: 2.7024586449152874

Epoch: 5| Step: 1
Training loss: 2.934756032236751
Validation loss: 2.6831766444950134

Epoch: 5| Step: 2
Training loss: 3.2739886636974678
Validation loss: 2.7312684697516265

Epoch: 5| Step: 3
Training loss: 2.2446943883034733
Validation loss: 2.709997762444448

Epoch: 5| Step: 4
Training loss: 2.9249561404338893
Validation loss: 2.717372507134652

Epoch: 5| Step: 5
Training loss: 3.15658597763148
Validation loss: 2.6992594939336247

Epoch: 5| Step: 6
Training loss: 3.467235062536406
Validation loss: 2.7300864777467235

Epoch: 5| Step: 7
Training loss: 2.5302979362476665
Validation loss: 2.7214902826201333

Epoch: 5| Step: 8
Training loss: 3.3074705701284213
Validation loss: 2.7069571002995536

Epoch: 5| Step: 9
Training loss: 2.8986043136590904
Validation loss: 2.7112174262394557

Epoch: 5| Step: 10
Training loss: 3.065307575867056
Validation loss: 2.7086901944720996

Epoch: 112| Step: 0
Training loss: 2.465241752206073
Validation loss: 2.72279837352694

Epoch: 5| Step: 1
Training loss: 3.3140672538899483
Validation loss: 2.728337812461436

Epoch: 5| Step: 2
Training loss: 2.703024801701472
Validation loss: 2.6663589085243395

Epoch: 5| Step: 3
Training loss: 3.109773696565018
Validation loss: 2.6562932599071982

Epoch: 5| Step: 4
Training loss: 2.845656541850194
Validation loss: 2.721464136375281

Epoch: 5| Step: 5
Training loss: 3.174433536008611
Validation loss: 2.7354959218437096

Epoch: 5| Step: 6
Training loss: 3.597644851451134
Validation loss: 2.765387224826489

Epoch: 5| Step: 7
Training loss: 3.2040872756653442
Validation loss: 2.720202945883897

Epoch: 5| Step: 8
Training loss: 2.026548137628607
Validation loss: 2.7169740539088743

Epoch: 5| Step: 9
Training loss: 2.3545462603314924
Validation loss: 2.6851963879040364

Epoch: 5| Step: 10
Training loss: 3.1828206440030655
Validation loss: 2.7103442360069345

Epoch: 113| Step: 0
Training loss: 3.0750928166965674
Validation loss: 2.7284568719047004

Epoch: 5| Step: 1
Training loss: 2.98138277729823
Validation loss: 2.7735491247041395

Epoch: 5| Step: 2
Training loss: 2.685804497586407
Validation loss: 2.7112214099148177

Epoch: 5| Step: 3
Training loss: 2.3940798659168467
Validation loss: 2.7247803329975553

Epoch: 5| Step: 4
Training loss: 3.4882749619379214
Validation loss: 2.72185625469873

Epoch: 5| Step: 5
Training loss: 2.491882114175401
Validation loss: 2.6745698228918777

Epoch: 5| Step: 6
Training loss: 3.0897613398657673
Validation loss: 2.7096251534513414

Epoch: 5| Step: 7
Training loss: 3.1493802989953745
Validation loss: 2.7171192787786937

Epoch: 5| Step: 8
Training loss: 2.9125982701827726
Validation loss: 2.7132624094975872

Epoch: 5| Step: 9
Training loss: 2.3585300574685117
Validation loss: 2.6953793020888615

Epoch: 5| Step: 10
Training loss: 2.6708184545839484
Validation loss: 2.7258332601841615

Epoch: 114| Step: 0
Training loss: 2.587310334409177
Validation loss: 2.6972185445484693

Epoch: 5| Step: 1
Training loss: 2.8283873378413587
Validation loss: 2.7307090305573913

Epoch: 5| Step: 2
Training loss: 3.073761766681899
Validation loss: 2.697240015708664

Epoch: 5| Step: 3
Training loss: 3.048304921624908
Validation loss: 2.7583956579023807

Epoch: 5| Step: 4
Training loss: 3.4096560466393493
Validation loss: 2.7221143644104075

Epoch: 5| Step: 5
Training loss: 3.1375415145741528
Validation loss: 2.71802503071045

Epoch: 5| Step: 6
Training loss: 2.7513836067615864
Validation loss: 2.749256487519598

Epoch: 5| Step: 7
Training loss: 2.2211545352890263
Validation loss: 2.7170196975212058

Epoch: 5| Step: 8
Training loss: 3.0684423599336768
Validation loss: 2.7027543649791053

Epoch: 5| Step: 9
Training loss: 3.0711844179311134
Validation loss: 2.742466516483568

Epoch: 5| Step: 10
Training loss: 2.539154051083844
Validation loss: 2.6884768733625943

Epoch: 115| Step: 0
Training loss: 2.6802072271252597
Validation loss: 2.721699971957282

Epoch: 5| Step: 1
Training loss: 3.2818136548520456
Validation loss: 2.689148054405111

Epoch: 5| Step: 2
Training loss: 2.6521855392799396
Validation loss: 2.692978915785906

Epoch: 5| Step: 3
Training loss: 2.522908158186896
Validation loss: 2.7005959308906693

Epoch: 5| Step: 4
Training loss: 2.8460258348033602
Validation loss: 2.7101027855688247

Epoch: 5| Step: 5
Training loss: 3.421702480757392
Validation loss: 2.688639175917425

Epoch: 5| Step: 6
Training loss: 3.048763843863111
Validation loss: 2.6702937117416257

Epoch: 5| Step: 7
Training loss: 3.00957185887672
Validation loss: 2.7054744896967273

Epoch: 5| Step: 8
Training loss: 3.1054979238999145
Validation loss: 2.678535760426202

Epoch: 5| Step: 9
Training loss: 2.427038779006682
Validation loss: 2.7311561964655198

Epoch: 5| Step: 10
Training loss: 2.5154711753302275
Validation loss: 2.73045676114309

Epoch: 116| Step: 0
Training loss: 2.6248831950040272
Validation loss: 2.7082013968111727

Epoch: 5| Step: 1
Training loss: 3.885104264832619
Validation loss: 2.676572872075416

Epoch: 5| Step: 2
Training loss: 2.8182921213227026
Validation loss: 2.7175745254005967

Epoch: 5| Step: 3
Training loss: 3.0393425584427027
Validation loss: 2.6851875389637914

Epoch: 5| Step: 4
Training loss: 2.4954049797334337
Validation loss: 2.727363922078099

Epoch: 5| Step: 5
Training loss: 3.13579236860346
Validation loss: 2.687530748249123

Epoch: 5| Step: 6
Training loss: 2.7033956756019872
Validation loss: 2.7200062505799822

Epoch: 5| Step: 7
Training loss: 2.955854980659067
Validation loss: 2.7138719692879683

Epoch: 5| Step: 8
Training loss: 2.544446946253465
Validation loss: 2.710773017264512

Epoch: 5| Step: 9
Training loss: 3.2356334946867014
Validation loss: 2.7012010060457086

Epoch: 5| Step: 10
Training loss: 2.0652603404644325
Validation loss: 2.7295793041182272

Epoch: 117| Step: 0
Training loss: 2.3925802176330135
Validation loss: 2.6993029573139085

Epoch: 5| Step: 1
Training loss: 2.882250392458834
Validation loss: 2.723884710618366

Epoch: 5| Step: 2
Training loss: 2.8495017770660263
Validation loss: 2.7024998456165603

Epoch: 5| Step: 3
Training loss: 3.4325753742563574
Validation loss: 2.7462593173052983

Epoch: 5| Step: 4
Training loss: 3.029691944640403
Validation loss: 2.6984331120744645

Epoch: 5| Step: 5
Training loss: 2.5455648410730816
Validation loss: 2.73836584014509

Epoch: 5| Step: 6
Training loss: 3.2905354225884835
Validation loss: 2.670522097231063

Epoch: 5| Step: 7
Training loss: 2.720807404173075
Validation loss: 2.6716686995017125

Epoch: 5| Step: 8
Training loss: 2.6507533028386034
Validation loss: 2.707782780905183

Epoch: 5| Step: 9
Training loss: 2.860216527625121
Validation loss: 2.6959076103003183

Epoch: 5| Step: 10
Training loss: 2.8055580084593807
Validation loss: 2.6713178929733052

Epoch: 118| Step: 0
Training loss: 2.9755292085173264
Validation loss: 2.710639528946457

Epoch: 5| Step: 1
Training loss: 2.7001424222046526
Validation loss: 2.701978319929669

Epoch: 5| Step: 2
Training loss: 2.486329755160748
Validation loss: 2.661206674550808

Epoch: 5| Step: 3
Training loss: 2.736587849719906
Validation loss: 2.7206660557921407

Epoch: 5| Step: 4
Training loss: 3.095694807264062
Validation loss: 2.6871347753935018

Epoch: 5| Step: 5
Training loss: 2.2531658787927613
Validation loss: 2.7100098777578565

Epoch: 5| Step: 6
Training loss: 3.3657435885959592
Validation loss: 2.6792884744109227

Epoch: 5| Step: 7
Training loss: 2.6087672273864895
Validation loss: 2.7177701878739837

Epoch: 5| Step: 8
Training loss: 3.220313275895634
Validation loss: 2.725573721176627

Epoch: 5| Step: 9
Training loss: 3.426620050130528
Validation loss: 2.719576845565934

Epoch: 5| Step: 10
Training loss: 2.9016536338845054
Validation loss: 2.6822968434037837

Epoch: 119| Step: 0
Training loss: 1.6096438581459995
Validation loss: 2.684389873644266

Epoch: 5| Step: 1
Training loss: 2.5159087406097744
Validation loss: 2.701248227777164

Epoch: 5| Step: 2
Training loss: 2.6345269934269906
Validation loss: 2.6893909876801727

Epoch: 5| Step: 3
Training loss: 3.689240384367419
Validation loss: 2.681241197354328

Epoch: 5| Step: 4
Training loss: 2.752621355006105
Validation loss: 2.680127755405953

Epoch: 5| Step: 5
Training loss: 3.181681689517838
Validation loss: 2.744185486045363

Epoch: 5| Step: 6
Training loss: 2.955076672742125
Validation loss: 2.681793268535078

Epoch: 5| Step: 7
Training loss: 3.2121377822378787
Validation loss: 2.721844036705621

Epoch: 5| Step: 8
Training loss: 2.601194980081627
Validation loss: 2.722476459602048

Epoch: 5| Step: 9
Training loss: 3.0377823749418464
Validation loss: 2.7230390503612423

Epoch: 5| Step: 10
Training loss: 2.849240211801367
Validation loss: 2.698021720436963

Epoch: 120| Step: 0
Training loss: 1.9950699242788061
Validation loss: 2.7041223172697877

Epoch: 5| Step: 1
Training loss: 2.5502812361369744
Validation loss: 2.705164996764246

Epoch: 5| Step: 2
Training loss: 2.8981597849601317
Validation loss: 2.683052428366222

Epoch: 5| Step: 3
Training loss: 3.239862477009492
Validation loss: 2.69974557664577

Epoch: 5| Step: 4
Training loss: 2.2816870283839554
Validation loss: 2.7070950047500455

Epoch: 5| Step: 5
Training loss: 3.6659714010718307
Validation loss: 2.7001293919701412

Epoch: 5| Step: 6
Training loss: 3.2491059173856023
Validation loss: 2.6884470542290555

Epoch: 5| Step: 7
Training loss: 1.9322262638947447
Validation loss: 2.7315419229810725

Epoch: 5| Step: 8
Training loss: 3.302469289147398
Validation loss: 2.689665725656033

Epoch: 5| Step: 9
Training loss: 3.3393395829718835
Validation loss: 2.668296511688873

Epoch: 5| Step: 10
Training loss: 2.957571244917391
Validation loss: 2.663822579826671

Epoch: 121| Step: 0
Training loss: 3.1263537717097516
Validation loss: 2.678157097081401

Epoch: 5| Step: 1
Training loss: 3.089506842261617
Validation loss: 2.6749975781587425

Epoch: 5| Step: 2
Training loss: 3.198547665516195
Validation loss: 2.713519522704691

Epoch: 5| Step: 3
Training loss: 2.73656136432906
Validation loss: 2.727210735072972

Epoch: 5| Step: 4
Training loss: 2.8302186413744432
Validation loss: 2.6812530109099764

Epoch: 5| Step: 5
Training loss: 2.377249706262275
Validation loss: 2.697555351190855

Epoch: 5| Step: 6
Training loss: 2.579793771441377
Validation loss: 2.7151063305913423

Epoch: 5| Step: 7
Training loss: 3.1658097329046186
Validation loss: 2.681552794196948

Epoch: 5| Step: 8
Training loss: 2.6574391115665
Validation loss: 2.7096365438108907

Epoch: 5| Step: 9
Training loss: 2.843792757823728
Validation loss: 2.716889011927964

Epoch: 5| Step: 10
Training loss: 2.8307472843735595
Validation loss: 2.738776159919913

Epoch: 122| Step: 0
Training loss: 3.659135380953405
Validation loss: 2.7112876228860587

Epoch: 5| Step: 1
Training loss: 2.4683819267062557
Validation loss: 2.7254444484647133

Epoch: 5| Step: 2
Training loss: 3.579419697235506
Validation loss: 2.7283122636767763

Epoch: 5| Step: 3
Training loss: 3.192105276250382
Validation loss: 2.721039634521361

Epoch: 5| Step: 4
Training loss: 2.19756486677617
Validation loss: 2.6875314779839625

Epoch: 5| Step: 5
Training loss: 2.265889961271146
Validation loss: 2.7248450776055018

Epoch: 5| Step: 6
Training loss: 1.9857455349156035
Validation loss: 2.7322932668877504

Epoch: 5| Step: 7
Training loss: 2.787756007459926
Validation loss: 2.7203672900671254

Epoch: 5| Step: 8
Training loss: 3.0904183992735286
Validation loss: 2.656515415353976

Epoch: 5| Step: 9
Training loss: 3.0993229157367166
Validation loss: 2.7411609625243885

Epoch: 5| Step: 10
Training loss: 3.08011961469361
Validation loss: 2.7396919350301667

Epoch: 123| Step: 0
Training loss: 2.693672809247179
Validation loss: 2.7131810203225535

Epoch: 5| Step: 1
Training loss: 3.369953904331894
Validation loss: 2.689080641817489

Epoch: 5| Step: 2
Training loss: 2.4178243911369894
Validation loss: 2.7000063032823376

Epoch: 5| Step: 3
Training loss: 2.5035320127286815
Validation loss: 2.7174502820841537

Epoch: 5| Step: 4
Training loss: 2.9274167632299384
Validation loss: 2.6725182930931433

Epoch: 5| Step: 5
Training loss: 3.0562271959823133
Validation loss: 2.734636038934661

Epoch: 5| Step: 6
Training loss: 2.8898994153744253
Validation loss: 2.733509574856246

Epoch: 5| Step: 7
Training loss: 3.2256669471170056
Validation loss: 2.734607444997217

Epoch: 5| Step: 8
Training loss: 2.749431204493429
Validation loss: 2.739727230933562

Epoch: 5| Step: 9
Training loss: 2.9063525438163476
Validation loss: 2.747230507470458

Epoch: 5| Step: 10
Training loss: 2.746240820819445
Validation loss: 2.7025963620040883

Epoch: 124| Step: 0
Training loss: 3.5116640283990797
Validation loss: 2.6968193893641232

Epoch: 5| Step: 1
Training loss: 3.82016271753921
Validation loss: 2.684832113689556

Epoch: 5| Step: 2
Training loss: 2.099378734606879
Validation loss: 2.697784561861324

Epoch: 5| Step: 3
Training loss: 3.0049123282187056
Validation loss: 2.766091224653358

Epoch: 5| Step: 4
Training loss: 2.302918353185099
Validation loss: 2.74555105211474

Epoch: 5| Step: 5
Training loss: 2.536263669251164
Validation loss: 2.6926614600935364

Epoch: 5| Step: 6
Training loss: 2.7041042075759
Validation loss: 2.7045730874577933

Epoch: 5| Step: 7
Training loss: 3.149295207301846
Validation loss: 2.6824209005108504

Epoch: 5| Step: 8
Training loss: 3.084840990169728
Validation loss: 2.706744822576966

Epoch: 5| Step: 9
Training loss: 2.376270957986796
Validation loss: 2.7063107926836363

Epoch: 5| Step: 10
Training loss: 2.2471005513570006
Validation loss: 2.7052802421179716

Epoch: 125| Step: 0
Training loss: 2.9174309047175857
Validation loss: 2.728185442696232

Epoch: 5| Step: 1
Training loss: 3.1266350092908577
Validation loss: 2.665131565120143

Epoch: 5| Step: 2
Training loss: 2.60904257478552
Validation loss: 2.7096161747223433

Epoch: 5| Step: 3
Training loss: 3.435003449106498
Validation loss: 2.723785301407836

Epoch: 5| Step: 4
Training loss: 2.680026997672216
Validation loss: 2.6857020895395176

Epoch: 5| Step: 5
Training loss: 2.3800774558470357
Validation loss: 2.7427249439389048

Epoch: 5| Step: 6
Training loss: 3.1124727546694397
Validation loss: 2.699319233938445

Epoch: 5| Step: 7
Training loss: 2.557062101192591
Validation loss: 2.6763417920831216

Epoch: 5| Step: 8
Training loss: 3.0802273614369007
Validation loss: 2.689016314569527

Epoch: 5| Step: 9
Training loss: 3.0018427275670794
Validation loss: 2.7018660857864463

Epoch: 5| Step: 10
Training loss: 2.5582861329569515
Validation loss: 2.6829948802533132

Epoch: 126| Step: 0
Training loss: 2.6003969806434744
Validation loss: 2.6947066363413175

Epoch: 5| Step: 1
Training loss: 3.411103456787512
Validation loss: 2.7296289149416415

Epoch: 5| Step: 2
Training loss: 3.1945831287152275
Validation loss: 2.653448686583747

Epoch: 5| Step: 3
Training loss: 2.4380910108006675
Validation loss: 2.7178088143093055

Epoch: 5| Step: 4
Training loss: 2.770166407658021
Validation loss: 2.736064992189466

Epoch: 5| Step: 5
Training loss: 2.5118006667665913
Validation loss: 2.6938053824814294

Epoch: 5| Step: 6
Training loss: 2.336468792462646
Validation loss: 2.711746759361869

Epoch: 5| Step: 7
Training loss: 2.584302494826336
Validation loss: 2.7370994118941794

Epoch: 5| Step: 8
Training loss: 2.9023711869392073
Validation loss: 2.688560112203769

Epoch: 5| Step: 9
Training loss: 3.5489360181985656
Validation loss: 2.7103542584555917

Epoch: 5| Step: 10
Training loss: 2.983971373740331
Validation loss: 2.681089220887543

Epoch: 127| Step: 0
Training loss: 2.548669475426483
Validation loss: 2.6835915184152026

Epoch: 5| Step: 1
Training loss: 2.18527129944102
Validation loss: 2.659083359538983

Epoch: 5| Step: 2
Training loss: 2.999101663238175
Validation loss: 2.696583337188296

Epoch: 5| Step: 3
Training loss: 3.6393198448900645
Validation loss: 2.6905036142647116

Epoch: 5| Step: 4
Training loss: 2.6526198770110394
Validation loss: 2.727998582338477

Epoch: 5| Step: 5
Training loss: 2.9865736925889923
Validation loss: 2.7103282563863407

Epoch: 5| Step: 6
Training loss: 2.56710494704503
Validation loss: 2.688068746571509

Epoch: 5| Step: 7
Training loss: 2.4829026183667535
Validation loss: 2.7183039422713287

Epoch: 5| Step: 8
Training loss: 2.7027293009351308
Validation loss: 2.6719430491300864

Epoch: 5| Step: 9
Training loss: 3.3195176553212153
Validation loss: 2.6967447649472702

Epoch: 5| Step: 10
Training loss: 3.0067910577906742
Validation loss: 2.6620740467067145

Epoch: 128| Step: 0
Training loss: 2.8924745982908497
Validation loss: 2.6429917220020323

Epoch: 5| Step: 1
Training loss: 2.9821943534797106
Validation loss: 2.7397768858479714

Epoch: 5| Step: 2
Training loss: 3.297880625010749
Validation loss: 2.6658908621729958

Epoch: 5| Step: 3
Training loss: 2.408920688569796
Validation loss: 2.7026760580410443

Epoch: 5| Step: 4
Training loss: 2.672669588137665
Validation loss: 2.6839524741477607

Epoch: 5| Step: 5
Training loss: 2.877441530536757
Validation loss: 2.6514119203723103

Epoch: 5| Step: 6
Training loss: 2.408584057209657
Validation loss: 2.668551769552013

Epoch: 5| Step: 7
Training loss: 2.774876095179281
Validation loss: 2.664009323457877

Epoch: 5| Step: 8
Training loss: 3.5109971167439284
Validation loss: 2.640161562811446

Epoch: 5| Step: 9
Training loss: 2.546128052313327
Validation loss: 2.6813168111468038

Epoch: 5| Step: 10
Training loss: 3.016290937036032
Validation loss: 2.734905538113807

Epoch: 129| Step: 0
Training loss: 2.8112184783810235
Validation loss: 2.6903326974664634

Epoch: 5| Step: 1
Training loss: 2.6627997037170252
Validation loss: 2.7423475604606544

Epoch: 5| Step: 2
Training loss: 2.7816257865862477
Validation loss: 2.6717259676654694

Epoch: 5| Step: 3
Training loss: 3.1752038785100054
Validation loss: 2.720626924332504

Epoch: 5| Step: 4
Training loss: 3.096831511375954
Validation loss: 2.692364945682446

Epoch: 5| Step: 5
Training loss: 2.8907327167957977
Validation loss: 2.6768410695435834

Epoch: 5| Step: 6
Training loss: 2.8907381602639237
Validation loss: 2.733570676483939

Epoch: 5| Step: 7
Training loss: 2.3726785256172596
Validation loss: 2.690017548387321

Epoch: 5| Step: 8
Training loss: 2.7982606492212665
Validation loss: 2.709998539105112

Epoch: 5| Step: 9
Training loss: 2.8158201329972803
Validation loss: 2.729077676278623

Epoch: 5| Step: 10
Training loss: 3.5850156043656103
Validation loss: 2.7389633136511113

Epoch: 130| Step: 0
Training loss: 3.3776678208250313
Validation loss: 2.7274497470508754

Epoch: 5| Step: 1
Training loss: 2.8092630196426063
Validation loss: 2.7171375177905697

Epoch: 5| Step: 2
Training loss: 3.1525588405360483
Validation loss: 2.753338650663013

Epoch: 5| Step: 3
Training loss: 3.0100442904638793
Validation loss: 2.7127523191566447

Epoch: 5| Step: 4
Training loss: 2.6693107391103665
Validation loss: 2.6302227697683915

Epoch: 5| Step: 5
Training loss: 2.824958672685385
Validation loss: 2.7089717809779756

Epoch: 5| Step: 6
Training loss: 3.142498463438352
Validation loss: 2.7419163220681253

Epoch: 5| Step: 7
Training loss: 2.7592935448587594
Validation loss: 2.702289813377561

Epoch: 5| Step: 8
Training loss: 2.4019264913296112
Validation loss: 2.714393384902656

Epoch: 5| Step: 9
Training loss: 2.9747839392413793
Validation loss: 2.699923094015356

Epoch: 5| Step: 10
Training loss: 2.9097406897089053
Validation loss: 2.711107676659815

Epoch: 131| Step: 0
Training loss: 2.7295259913772134
Validation loss: 2.7109278551382676

Epoch: 5| Step: 1
Training loss: 2.809507261224431
Validation loss: 2.722375175852079

Epoch: 5| Step: 2
Training loss: 3.4663954983317313
Validation loss: 2.6645709045757084

Epoch: 5| Step: 3
Training loss: 2.4250205992777434
Validation loss: 2.653788992584136

Epoch: 5| Step: 4
Training loss: 2.7428793183917572
Validation loss: 2.7136445151849737

Epoch: 5| Step: 5
Training loss: 2.7751991372354263
Validation loss: 2.7482079132375037

Epoch: 5| Step: 6
Training loss: 2.5008755104536133
Validation loss: 2.7214971723907833

Epoch: 5| Step: 7
Training loss: 2.897035161830425
Validation loss: 2.7161400827494773

Epoch: 5| Step: 8
Training loss: 3.2304885291678347
Validation loss: 2.679087136036664

Epoch: 5| Step: 9
Training loss: 2.4261030146528237
Validation loss: 2.7164921402586777

Epoch: 5| Step: 10
Training loss: 3.184576451571436
Validation loss: 2.667129528024711

Epoch: 132| Step: 0
Training loss: 3.118531666301169
Validation loss: 2.683841037457637

Epoch: 5| Step: 1
Training loss: 2.261439489013465
Validation loss: 2.712279345578271

Epoch: 5| Step: 2
Training loss: 3.229625956369282
Validation loss: 2.6785549043769765

Epoch: 5| Step: 3
Training loss: 3.34611954911765
Validation loss: 2.655673059568994

Epoch: 5| Step: 4
Training loss: 2.817207296580125
Validation loss: 2.696653309670651

Epoch: 5| Step: 5
Training loss: 2.41215760958858
Validation loss: 2.7039290372876827

Epoch: 5| Step: 6
Training loss: 3.0370073209340847
Validation loss: 2.708467360620228

Epoch: 5| Step: 7
Training loss: 2.7221135346995866
Validation loss: 2.655780429823684

Epoch: 5| Step: 8
Training loss: 2.8702344789320424
Validation loss: 2.7179589417841554

Epoch: 5| Step: 9
Training loss: 2.938337815299883
Validation loss: 2.7334083435286844

Epoch: 5| Step: 10
Training loss: 2.778598678937156
Validation loss: 2.753466229240725

Epoch: 133| Step: 0
Training loss: 2.3498680118262283
Validation loss: 2.677356396891293

Epoch: 5| Step: 1
Training loss: 3.262755086580187
Validation loss: 2.69178733197736

Epoch: 5| Step: 2
Training loss: 2.7311076670556753
Validation loss: 2.7276628147933697

Epoch: 5| Step: 3
Training loss: 3.8009562594198516
Validation loss: 2.679304951560822

Epoch: 5| Step: 4
Training loss: 2.762561459095001
Validation loss: 2.672458581351676

Epoch: 5| Step: 5
Training loss: 2.357793113472062
Validation loss: 2.683498842957439

Epoch: 5| Step: 6
Training loss: 2.8401174295352303
Validation loss: 2.708634720559316

Epoch: 5| Step: 7
Training loss: 2.1428972422163044
Validation loss: 2.7108156586375576

Epoch: 5| Step: 8
Training loss: 3.169666141294005
Validation loss: 2.7032835458246036

Epoch: 5| Step: 9
Training loss: 3.208081388282981
Validation loss: 2.647444890131456

Epoch: 5| Step: 10
Training loss: 2.1346676761252317
Validation loss: 2.694060106616727

Epoch: 134| Step: 0
Training loss: 3.071185038977648
Validation loss: 2.7309177745442983

Epoch: 5| Step: 1
Training loss: 2.280566805606445
Validation loss: 2.7209133027582704

Epoch: 5| Step: 2
Training loss: 3.084567845276589
Validation loss: 2.716464956865345

Epoch: 5| Step: 3
Training loss: 2.903890821217336
Validation loss: 2.717303028561471

Epoch: 5| Step: 4
Training loss: 2.469224811718626
Validation loss: 2.695662027968727

Epoch: 5| Step: 5
Training loss: 1.9023441259865517
Validation loss: 2.657114383162235

Epoch: 5| Step: 6
Training loss: 3.663009785140514
Validation loss: 2.7244067854169063

Epoch: 5| Step: 7
Training loss: 3.4099305592735143
Validation loss: 2.7138932784650662

Epoch: 5| Step: 8
Training loss: 2.8500544492640016
Validation loss: 2.6725383712945585

Epoch: 5| Step: 9
Training loss: 2.3268111445138575
Validation loss: 2.6860399775640538

Epoch: 5| Step: 10
Training loss: 3.2028165343087336
Validation loss: 2.6523311982649296

Epoch: 135| Step: 0
Training loss: 3.1628322140347156
Validation loss: 2.6898896319490175

Epoch: 5| Step: 1
Training loss: 2.9078058159703706
Validation loss: 2.6952598096997926

Epoch: 5| Step: 2
Training loss: 2.897017550124607
Validation loss: 2.732512054319198

Epoch: 5| Step: 3
Training loss: 3.164848926910031
Validation loss: 2.614715710746623

Epoch: 5| Step: 4
Training loss: 2.4948431234023882
Validation loss: 2.707882415933211

Epoch: 5| Step: 5
Training loss: 3.025480462372587
Validation loss: 2.717090506160678

Epoch: 5| Step: 6
Training loss: 2.400270339522052
Validation loss: 2.714002650912454

Epoch: 5| Step: 7
Training loss: 2.5373583899761045
Validation loss: 2.675243396743444

Epoch: 5| Step: 8
Training loss: 2.9965318660381586
Validation loss: 2.730489235810428

Epoch: 5| Step: 9
Training loss: 2.8464627584047806
Validation loss: 2.696382829094577

Epoch: 5| Step: 10
Training loss: 2.9124122835629302
Validation loss: 2.7302996880773853

Epoch: 136| Step: 0
Training loss: 3.4328244403115766
Validation loss: 2.669328193598485

Epoch: 5| Step: 1
Training loss: 2.9208359120167566
Validation loss: 2.680378770454494

Epoch: 5| Step: 2
Training loss: 2.3835602134363336
Validation loss: 2.6806748500539452

Epoch: 5| Step: 3
Training loss: 2.3257993821067426
Validation loss: 2.6929245919054225

Epoch: 5| Step: 4
Training loss: 2.605623758214635
Validation loss: 2.7209165900871115

Epoch: 5| Step: 5
Training loss: 2.941354697942165
Validation loss: 2.704081118535761

Epoch: 5| Step: 6
Training loss: 2.90677334575115
Validation loss: 2.7283617063252983

Epoch: 5| Step: 7
Training loss: 3.2407867714978456
Validation loss: 2.6677289110962334

Epoch: 5| Step: 8
Training loss: 2.602855189377876
Validation loss: 2.6816734948465166

Epoch: 5| Step: 9
Training loss: 3.043288560547019
Validation loss: 2.645355511547358

Epoch: 5| Step: 10
Training loss: 2.575365473912149
Validation loss: 2.7055081407269035

Epoch: 137| Step: 0
Training loss: 2.9274705153364162
Validation loss: 2.6903021060740624

Epoch: 5| Step: 1
Training loss: 2.8365651006330515
Validation loss: 2.7570809664698097

Epoch: 5| Step: 2
Training loss: 2.838047388187889
Validation loss: 2.7155410127342274

Epoch: 5| Step: 3
Training loss: 2.902409302496171
Validation loss: 2.6495021381805235

Epoch: 5| Step: 4
Training loss: 2.2830080547817264
Validation loss: 2.71738810192631

Epoch: 5| Step: 5
Training loss: 3.1830506031113885
Validation loss: 2.707306425974506

Epoch: 5| Step: 6
Training loss: 3.285359162041252
Validation loss: 2.6962068595445055

Epoch: 5| Step: 7
Training loss: 2.931384599600736
Validation loss: 2.7010313821489733

Epoch: 5| Step: 8
Training loss: 2.6569875254253854
Validation loss: 2.7070915050797066

Epoch: 5| Step: 9
Training loss: 2.3195576579876707
Validation loss: 2.73489696109048

Epoch: 5| Step: 10
Training loss: 2.794462047527359
Validation loss: 2.7364420391807602

Epoch: 138| Step: 0
Training loss: 3.020997790540678
Validation loss: 2.722386385738051

Epoch: 5| Step: 1
Training loss: 2.6765885743197813
Validation loss: 2.7427942131688225

Epoch: 5| Step: 2
Training loss: 2.323089684399355
Validation loss: 2.6869732759592564

Epoch: 5| Step: 3
Training loss: 3.1038579253883536
Validation loss: 2.716753212122528

Epoch: 5| Step: 4
Training loss: 2.784104842963233
Validation loss: 2.69767765936518

Epoch: 5| Step: 5
Training loss: 2.9423338705272477
Validation loss: 2.693508026985391

Epoch: 5| Step: 6
Training loss: 2.6026820617667332
Validation loss: 2.722620461606339

Epoch: 5| Step: 7
Training loss: 2.6878844584995933
Validation loss: 2.7241969562377744

Epoch: 5| Step: 8
Training loss: 3.1592827758006568
Validation loss: 2.7567706078902634

Epoch: 5| Step: 9
Training loss: 2.8106846354789052
Validation loss: 2.733494031710746

Epoch: 5| Step: 10
Training loss: 3.150836948438775
Validation loss: 2.7075867484461673

Epoch: 139| Step: 0
Training loss: 3.2597416350600166
Validation loss: 2.694704851586213

Epoch: 5| Step: 1
Training loss: 2.2887388658070438
Validation loss: 2.6978768349594007

Epoch: 5| Step: 2
Training loss: 3.566169187724564
Validation loss: 2.6572472183723477

Epoch: 5| Step: 3
Training loss: 2.9740240531826054
Validation loss: 2.6795030756009153

Epoch: 5| Step: 4
Training loss: 1.7673009159784896
Validation loss: 2.7198545244119754

Epoch: 5| Step: 5
Training loss: 2.8149209517226272
Validation loss: 2.7449646489533075

Epoch: 5| Step: 6
Training loss: 3.3786248415149838
Validation loss: 2.7272575656734186

Epoch: 5| Step: 7
Training loss: 2.548492666801633
Validation loss: 2.720636890997574

Epoch: 5| Step: 8
Training loss: 3.2265874755483885
Validation loss: 2.6914645460060234

Epoch: 5| Step: 9
Training loss: 2.464556161876358
Validation loss: 2.7408981552492477

Epoch: 5| Step: 10
Training loss: 2.4555435407161452
Validation loss: 2.6862568938607003

Epoch: 140| Step: 0
Training loss: 3.4265859565679984
Validation loss: 2.7239012281150736

Epoch: 5| Step: 1
Training loss: 2.466564128222255
Validation loss: 2.7388314716906645

Epoch: 5| Step: 2
Training loss: 2.7175980681663208
Validation loss: 2.707504584557839

Epoch: 5| Step: 3
Training loss: 2.548665733572054
Validation loss: 2.715874657937095

Epoch: 5| Step: 4
Training loss: 2.8381564284287513
Validation loss: 2.7304347240051907

Epoch: 5| Step: 5
Training loss: 2.8825049921209245
Validation loss: 2.7334928162411076

Epoch: 5| Step: 6
Training loss: 2.9213194293421516
Validation loss: 2.635617793035541

Epoch: 5| Step: 7
Training loss: 2.398152586077633
Validation loss: 2.6341604902831386

Epoch: 5| Step: 8
Training loss: 3.73947051293389
Validation loss: 2.689920567319711

Epoch: 5| Step: 9
Training loss: 2.195063783939766
Validation loss: 2.6666937725422546

Epoch: 5| Step: 10
Training loss: 2.573734683657737
Validation loss: 2.6749445490379515

Epoch: 141| Step: 0
Training loss: 3.738986308576518
Validation loss: 2.6607009744132744

Epoch: 5| Step: 1
Training loss: 2.62518001120829
Validation loss: 2.6918405783401687

Epoch: 5| Step: 2
Training loss: 2.866689529623487
Validation loss: 2.647457544436701

Epoch: 5| Step: 3
Training loss: 3.2273635424097313
Validation loss: 2.7052295161930338

Epoch: 5| Step: 4
Training loss: 2.3188208720848635
Validation loss: 2.692615683492456

Epoch: 5| Step: 5
Training loss: 2.65053455071633
Validation loss: 2.70038816194344

Epoch: 5| Step: 6
Training loss: 2.7528334672181107
Validation loss: 2.688628329734973

Epoch: 5| Step: 7
Training loss: 2.7452450304854
Validation loss: 2.7319131201779934

Epoch: 5| Step: 8
Training loss: 2.699904358900643
Validation loss: 2.694164747129614

Epoch: 5| Step: 9
Training loss: 2.7344198168760254
Validation loss: 2.7399901542609433

Epoch: 5| Step: 10
Training loss: 2.454116523718323
Validation loss: 2.7209955205902987

Epoch: 142| Step: 0
Training loss: 2.231231505587141
Validation loss: 2.6934405445809673

Epoch: 5| Step: 1
Training loss: 2.681698058778167
Validation loss: 2.6769344639091903

Epoch: 5| Step: 2
Training loss: 3.233986504115512
Validation loss: 2.719121870540458

Epoch: 5| Step: 3
Training loss: 2.4314309883906127
Validation loss: 2.684433533846898

Epoch: 5| Step: 4
Training loss: 2.525510426664608
Validation loss: 2.70807259458562

Epoch: 5| Step: 5
Training loss: 2.7315846183639847
Validation loss: 2.7472262988581515

Epoch: 5| Step: 6
Training loss: 3.822490422378427
Validation loss: 2.731836544327216

Epoch: 5| Step: 7
Training loss: 2.69517308855942
Validation loss: 2.6697187825884536

Epoch: 5| Step: 8
Training loss: 2.370018905532052
Validation loss: 2.63139334761131

Epoch: 5| Step: 9
Training loss: 3.35820490841598
Validation loss: 2.7129110554962854

Epoch: 5| Step: 10
Training loss: 2.4478555441726373
Validation loss: 2.6778573778590857

Epoch: 143| Step: 0
Training loss: 2.61933451026637
Validation loss: 2.6912330395368196

Epoch: 5| Step: 1
Training loss: 3.6325428852403587
Validation loss: 2.739428072517444

Epoch: 5| Step: 2
Training loss: 3.143177418676572
Validation loss: 2.676835403718211

Epoch: 5| Step: 3
Training loss: 2.6696828136561477
Validation loss: 2.686971657805527

Epoch: 5| Step: 4
Training loss: 3.519298346769802
Validation loss: 2.6928270567320527

Epoch: 5| Step: 5
Training loss: 2.3879996450989425
Validation loss: 2.723959338790064

Epoch: 5| Step: 6
Training loss: 2.676678093742913
Validation loss: 2.6751436126925547

Epoch: 5| Step: 7
Training loss: 2.217463483025925
Validation loss: 2.6609718429261355

Epoch: 5| Step: 8
Training loss: 2.8316618158823923
Validation loss: 2.7421591194310198

Epoch: 5| Step: 9
Training loss: 1.5478595721401596
Validation loss: 2.6760642109045287

Epoch: 5| Step: 10
Training loss: 3.2970267166013243
Validation loss: 2.6884323071239917

Epoch: 144| Step: 0
Training loss: 2.4034955992748652
Validation loss: 2.7027733563580973

Epoch: 5| Step: 1
Training loss: 2.736168235229828
Validation loss: 2.741587058431752

Epoch: 5| Step: 2
Training loss: 2.6171704647591576
Validation loss: 2.7167550720389686

Epoch: 5| Step: 3
Training loss: 3.213755463959401
Validation loss: 2.728678412506083

Epoch: 5| Step: 4
Training loss: 2.7282583651984633
Validation loss: 2.6967619971918375

Epoch: 5| Step: 5
Training loss: 2.6367126916886416
Validation loss: 2.7056566151081154

Epoch: 5| Step: 6
Training loss: 3.7823581805623454
Validation loss: 2.7401126958546973

Epoch: 5| Step: 7
Training loss: 2.4961367321343304
Validation loss: 2.7124287866951002

Epoch: 5| Step: 8
Training loss: 2.9774748437749228
Validation loss: 2.729392953406067

Epoch: 5| Step: 9
Training loss: 1.8792202185579625
Validation loss: 2.7080758028352747

Epoch: 5| Step: 10
Training loss: 3.111112942770767
Validation loss: 2.7227798683137885

Epoch: 145| Step: 0
Training loss: 2.346345913470646
Validation loss: 2.6747963327627646

Epoch: 5| Step: 1
Training loss: 2.255732439441431
Validation loss: 2.728907613163054

Epoch: 5| Step: 2
Training loss: 2.844336145379121
Validation loss: 2.680351171073445

Epoch: 5| Step: 3
Training loss: 2.575030232224254
Validation loss: 2.703828011655606

Epoch: 5| Step: 4
Training loss: 2.4842347879250193
Validation loss: 2.7474742982980813

Epoch: 5| Step: 5
Training loss: 2.7128876369561477
Validation loss: 2.717094738806925

Epoch: 5| Step: 6
Training loss: 3.336500491089215
Validation loss: 2.7221528039479774

Epoch: 5| Step: 7
Training loss: 3.9085594979401286
Validation loss: 2.659251024013628

Epoch: 5| Step: 8
Training loss: 2.976158294867052
Validation loss: 2.7045253957946844

Epoch: 5| Step: 9
Training loss: 2.6031615695468324
Validation loss: 2.7461833646039353

Epoch: 5| Step: 10
Training loss: 2.7294320906845604
Validation loss: 2.735458525929913

Epoch: 146| Step: 0
Training loss: 1.9049280930011518
Validation loss: 2.6656089006392274

Epoch: 5| Step: 1
Training loss: 3.098721757508496
Validation loss: 2.69333076927368

Epoch: 5| Step: 2
Training loss: 2.7002290416632078
Validation loss: 2.6989819217225017

Epoch: 5| Step: 3
Training loss: 2.885319640436781
Validation loss: 2.681662133892282

Epoch: 5| Step: 4
Training loss: 2.5600196184956316
Validation loss: 2.721803515939824

Epoch: 5| Step: 5
Training loss: 3.119456753508809
Validation loss: 2.66926054745705

Epoch: 5| Step: 6
Training loss: 2.930379801015261
Validation loss: 2.695384628379437

Epoch: 5| Step: 7
Training loss: 2.5999412640025983
Validation loss: 2.721184628286686

Epoch: 5| Step: 8
Training loss: 2.863749342226896
Validation loss: 2.679145646510792

Epoch: 5| Step: 9
Training loss: 3.3809634610818997
Validation loss: 2.714403717294169

Epoch: 5| Step: 10
Training loss: 2.8922335711189073
Validation loss: 2.696004892341822

Epoch: 147| Step: 0
Training loss: 2.8490303397740653
Validation loss: 2.7398776563763882

Epoch: 5| Step: 1
Training loss: 2.8070558202375824
Validation loss: 2.646078651791795

Epoch: 5| Step: 2
Training loss: 2.5833468180478816
Validation loss: 2.678123876798504

Epoch: 5| Step: 3
Training loss: 1.9442738897212894
Validation loss: 2.73421502133177

Epoch: 5| Step: 4
Training loss: 2.872017349849564
Validation loss: 2.705980116922022

Epoch: 5| Step: 5
Training loss: 3.0617246619476766
Validation loss: 2.687754308750169

Epoch: 5| Step: 6
Training loss: 3.360402646462191
Validation loss: 2.7014762577548344

Epoch: 5| Step: 7
Training loss: 2.2858846954275265
Validation loss: 2.7546014445167697

Epoch: 5| Step: 8
Training loss: 2.9845844614709445
Validation loss: 2.695995785523098

Epoch: 5| Step: 9
Training loss: 3.2969603324079713
Validation loss: 2.677127936558125

Epoch: 5| Step: 10
Training loss: 2.7078445776059095
Validation loss: 2.7352876214323496

Epoch: 148| Step: 0
Training loss: 3.489666944422577
Validation loss: 2.7152068147881274

Epoch: 5| Step: 1
Training loss: 3.036517570707332
Validation loss: 2.753946189500571

Epoch: 5| Step: 2
Training loss: 2.437622654103048
Validation loss: 2.689786521643537

Epoch: 5| Step: 3
Training loss: 2.4690740831337825
Validation loss: 2.737817760954792

Epoch: 5| Step: 4
Training loss: 2.7882930431506696
Validation loss: 2.7167883200716543

Epoch: 5| Step: 5
Training loss: 2.439722270793534
Validation loss: 2.73658273102966

Epoch: 5| Step: 6
Training loss: 2.505726644995359
Validation loss: 2.7294364826509363

Epoch: 5| Step: 7
Training loss: 2.964881544915145
Validation loss: 2.716892300351661

Epoch: 5| Step: 8
Training loss: 3.3195459535649734
Validation loss: 2.698622077580137

Epoch: 5| Step: 9
Training loss: 2.799323006939388
Validation loss: 2.6537987204916504

Epoch: 5| Step: 10
Training loss: 2.5483118228574173
Validation loss: 2.7093694363110057

Epoch: 149| Step: 0
Training loss: 2.4356563148903287
Validation loss: 2.6876293264771762

Epoch: 5| Step: 1
Training loss: 3.0278482127576196
Validation loss: 2.668597727419385

Epoch: 5| Step: 2
Training loss: 2.769919643957993
Validation loss: 2.7175567444940762

Epoch: 5| Step: 3
Training loss: 2.76622649295298
Validation loss: 2.6696803956722546

Epoch: 5| Step: 4
Training loss: 2.7839671374606665
Validation loss: 2.7254377652651867

Epoch: 5| Step: 5
Training loss: 3.096925435199253
Validation loss: 2.698626743884477

Epoch: 5| Step: 6
Training loss: 2.6887712355253517
Validation loss: 2.7027353345767073

Epoch: 5| Step: 7
Training loss: 3.1326059477867445
Validation loss: 2.677656707866364

Epoch: 5| Step: 8
Training loss: 2.7190989127930765
Validation loss: 2.7244184856664377

Epoch: 5| Step: 9
Training loss: 2.6863473593924785
Validation loss: 2.6948804996905635

Epoch: 5| Step: 10
Training loss: 3.024880550327566
Validation loss: 2.6890767540448777

Epoch: 150| Step: 0
Training loss: 2.8161314514105222
Validation loss: 2.7343934689321427

Epoch: 5| Step: 1
Training loss: 3.126896702235332
Validation loss: 2.695418140016954

Epoch: 5| Step: 2
Training loss: 2.468415925805409
Validation loss: 2.743908963296135

Epoch: 5| Step: 3
Training loss: 2.593837782511868
Validation loss: 2.720418817453021

Epoch: 5| Step: 4
Training loss: 2.64842975806621
Validation loss: 2.723013401962721

Epoch: 5| Step: 5
Training loss: 2.450783553652886
Validation loss: 2.681329603902115

Epoch: 5| Step: 6
Training loss: 3.233171026999893
Validation loss: 2.74249615396015

Epoch: 5| Step: 7
Training loss: 2.342224234813973
Validation loss: 2.7020502513965643

Epoch: 5| Step: 8
Training loss: 3.5480968370608394
Validation loss: 2.7186242917156616

Epoch: 5| Step: 9
Training loss: 2.897802566121308
Validation loss: 2.690517570591252

Epoch: 5| Step: 10
Training loss: 3.0163519580996905
Validation loss: 2.6716923881857935

Epoch: 151| Step: 0
Training loss: 2.6498268106835647
Validation loss: 2.6924599229685593

Epoch: 5| Step: 1
Training loss: 2.4822464947759797
Validation loss: 2.6479342756299595

Epoch: 5| Step: 2
Training loss: 3.333041146505959
Validation loss: 2.694245336756833

Epoch: 5| Step: 3
Training loss: 3.158506738604504
Validation loss: 2.73673698545188

Epoch: 5| Step: 4
Training loss: 3.0525397435755686
Validation loss: 2.7284452068251257

Epoch: 5| Step: 5
Training loss: 2.395891360257441
Validation loss: 2.69421884047337

Epoch: 5| Step: 6
Training loss: 2.897122889573806
Validation loss: 2.67768854091672

Epoch: 5| Step: 7
Training loss: 2.974814875637058
Validation loss: 2.6764451904634203

Epoch: 5| Step: 8
Training loss: 2.41642818151142
Validation loss: 2.7202814730060667

Epoch: 5| Step: 9
Training loss: 2.8426407547509918
Validation loss: 2.687832476231936

Epoch: 5| Step: 10
Training loss: 2.436013771218647
Validation loss: 2.6048238037550493

Epoch: 152| Step: 0
Training loss: 2.263390642919073
Validation loss: 2.647773829160182

Epoch: 5| Step: 1
Training loss: 3.5840370610909478
Validation loss: 2.7149755207931996

Epoch: 5| Step: 2
Training loss: 2.893182066846784
Validation loss: 2.7266136865347543

Epoch: 5| Step: 3
Training loss: 2.901277944552685
Validation loss: 2.6862796484322855

Epoch: 5| Step: 4
Training loss: 2.91391146270991
Validation loss: 2.7308632938236617

Epoch: 5| Step: 5
Training loss: 2.492250639017004
Validation loss: 2.717469232079388

Epoch: 5| Step: 6
Training loss: 2.696767044116784
Validation loss: 2.7043502072857906

Epoch: 5| Step: 7
Training loss: 2.797641670382938
Validation loss: 2.694261594456585

Epoch: 5| Step: 8
Training loss: 2.7725462435141304
Validation loss: 2.686575217986726

Epoch: 5| Step: 9
Training loss: 2.9419413329394453
Validation loss: 2.679896705000041

Epoch: 5| Step: 10
Training loss: 2.894975182883141
Validation loss: 2.694750039014395

Epoch: 153| Step: 0
Training loss: 3.0760763874068715
Validation loss: 2.7040191580832835

Epoch: 5| Step: 1
Training loss: 2.9914820862963287
Validation loss: 2.7373364459483915

Epoch: 5| Step: 2
Training loss: 2.3293044411771295
Validation loss: 2.710536782365979

Epoch: 5| Step: 3
Training loss: 2.7329197962326632
Validation loss: 2.6773837226530746

Epoch: 5| Step: 4
Training loss: 2.8060090503179618
Validation loss: 2.6731317693910164

Epoch: 5| Step: 5
Training loss: 2.851196432785303
Validation loss: 2.7390466173131043

Epoch: 5| Step: 6
Training loss: 2.463925343181331
Validation loss: 2.7558283193293156

Epoch: 5| Step: 7
Training loss: 2.440847787689445
Validation loss: 2.6977775592664437

Epoch: 5| Step: 8
Training loss: 3.7439172366686226
Validation loss: 2.6483718990267424

Epoch: 5| Step: 9
Training loss: 2.5416963502578476
Validation loss: 2.7216935093936403

Epoch: 5| Step: 10
Training loss: 3.0712274251068603
Validation loss: 2.6891918289724512

Epoch: 154| Step: 0
Training loss: 2.456034107766662
Validation loss: 2.7380693062920085

Epoch: 5| Step: 1
Training loss: 2.344016606743999
Validation loss: 2.73125008763075

Epoch: 5| Step: 2
Training loss: 2.88020020265909
Validation loss: 2.7012946154248394

Epoch: 5| Step: 3
Training loss: 3.1017860312829937
Validation loss: 2.698238768033602

Epoch: 5| Step: 4
Training loss: 3.368432188878348
Validation loss: 2.7240917010264907

Epoch: 5| Step: 5
Training loss: 2.789490055255903
Validation loss: 2.6939390844896267

Epoch: 5| Step: 6
Training loss: 2.6958578691343744
Validation loss: 2.7337430537224967

Epoch: 5| Step: 7
Training loss: 2.5540229329608306
Validation loss: 2.6792800427556376

Epoch: 5| Step: 8
Training loss: 3.2207321434032328
Validation loss: 2.6913578582694373

Epoch: 5| Step: 9
Training loss: 2.713624793089435
Validation loss: 2.7043049499107052

Epoch: 5| Step: 10
Training loss: 2.4159658884836115
Validation loss: 2.7256278335802575

Epoch: 155| Step: 0
Training loss: 2.8448242841201163
Validation loss: 2.7482399001644704

Epoch: 5| Step: 1
Training loss: 3.1347288135494384
Validation loss: 2.656417513251674

Epoch: 5| Step: 2
Training loss: 3.181980215628527
Validation loss: 2.728018962652141

Epoch: 5| Step: 3
Training loss: 2.9472703168969447
Validation loss: 2.675192217226373

Epoch: 5| Step: 4
Training loss: 2.8677400893228917
Validation loss: 2.649813839717317

Epoch: 5| Step: 5
Training loss: 3.0268009215952287
Validation loss: 2.6489397248476294

Epoch: 5| Step: 6
Training loss: 2.159393010154068
Validation loss: 2.683009780505772

Epoch: 5| Step: 7
Training loss: 2.279399487066048
Validation loss: 2.7181142597186576

Epoch: 5| Step: 8
Training loss: 3.1526022501373054
Validation loss: 2.7399929050371363

Epoch: 5| Step: 9
Training loss: 2.590569994150377
Validation loss: 2.6716246320604404

Epoch: 5| Step: 10
Training loss: 2.315920593916523
Validation loss: 2.72023475885851

Epoch: 156| Step: 0
Training loss: 2.97536366267569
Validation loss: 2.6872091076285884

Epoch: 5| Step: 1
Training loss: 3.050677777634685
Validation loss: 2.7201838462341463

Epoch: 5| Step: 2
Training loss: 2.844029674820529
Validation loss: 2.6857517037983154

Epoch: 5| Step: 3
Training loss: 2.978431255208754
Validation loss: 2.726369720102346

Epoch: 5| Step: 4
Training loss: 2.4369701885643105
Validation loss: 2.676566653984173

Epoch: 5| Step: 5
Training loss: 3.005339956238475
Validation loss: 2.6931876142415634

Epoch: 5| Step: 6
Training loss: 2.8626013725354764
Validation loss: 2.663802613974461

Epoch: 5| Step: 7
Training loss: 2.4430954117445864
Validation loss: 2.7123269906935636

Epoch: 5| Step: 8
Training loss: 2.761633541190144
Validation loss: 2.7342946461767705

Epoch: 5| Step: 9
Training loss: 2.8049570448199224
Validation loss: 2.667849096540638

Epoch: 5| Step: 10
Training loss: 2.6560723638041033
Validation loss: 2.670383001535315

Epoch: 157| Step: 0
Training loss: 3.0405400075138758
Validation loss: 2.739034624819378

Epoch: 5| Step: 1
Training loss: 2.835193210591094
Validation loss: 2.652751048920048

Epoch: 5| Step: 2
Training loss: 1.959524489058717
Validation loss: 2.6740598200754766

Epoch: 5| Step: 3
Training loss: 3.0648360393037244
Validation loss: 2.66168984856943

Epoch: 5| Step: 4
Training loss: 3.078985258616598
Validation loss: 2.7259225890982113

Epoch: 5| Step: 5
Training loss: 2.488608442081001
Validation loss: 2.6659958928948972

Epoch: 5| Step: 6
Training loss: 2.409037177204782
Validation loss: 2.663629206188355

Epoch: 5| Step: 7
Training loss: 2.177488578302186
Validation loss: 2.706103310934739

Epoch: 5| Step: 8
Training loss: 3.495334649388848
Validation loss: 2.7101527146099995

Epoch: 5| Step: 9
Training loss: 2.6182588576472328
Validation loss: 2.6840064523773175

Epoch: 5| Step: 10
Training loss: 3.564395600991311
Validation loss: 2.6959199315741187

Epoch: 158| Step: 0
Training loss: 2.4080092699373075
Validation loss: 2.6838359423450955

Epoch: 5| Step: 1
Training loss: 3.2942047152713085
Validation loss: 2.6828169231445345

Epoch: 5| Step: 2
Training loss: 2.892695165065473
Validation loss: 2.7083755799083598

Epoch: 5| Step: 3
Training loss: 2.2096014400485773
Validation loss: 2.693770096811945

Epoch: 5| Step: 4
Training loss: 3.070298211838573
Validation loss: 2.7005109778599863

Epoch: 5| Step: 5
Training loss: 1.8952764245080507
Validation loss: 2.766574947449423

Epoch: 5| Step: 6
Training loss: 2.723580552424182
Validation loss: 2.703116671148487

Epoch: 5| Step: 7
Training loss: 2.5250585681430224
Validation loss: 2.766397692576622

Epoch: 5| Step: 8
Training loss: 2.4470140673408807
Validation loss: 2.6600522767627144

Epoch: 5| Step: 9
Training loss: 3.5788985170065577
Validation loss: 2.7144348615665095

Epoch: 5| Step: 10
Training loss: 3.5261204014396927
Validation loss: 2.7229916425769387

Epoch: 159| Step: 0
Training loss: 3.140033723200583
Validation loss: 2.689282558021727

Epoch: 5| Step: 1
Training loss: 3.056326892096148
Validation loss: 2.706090425928038

Epoch: 5| Step: 2
Training loss: 2.7769898780690485
Validation loss: 2.7011258240734484

Epoch: 5| Step: 3
Training loss: 2.6448351461455712
Validation loss: 2.7250878098530733

Epoch: 5| Step: 4
Training loss: 2.437723883103894
Validation loss: 2.7528033440832806

Epoch: 5| Step: 5
Training loss: 3.035440124826021
Validation loss: 2.6896172416075084

Epoch: 5| Step: 6
Training loss: 2.711705959139336
Validation loss: 2.6665240042605727

Epoch: 5| Step: 7
Training loss: 2.6483210985378443
Validation loss: 2.70446932741684

Epoch: 5| Step: 8
Training loss: 2.3784044860946376
Validation loss: 2.7119294438423016

Epoch: 5| Step: 9
Training loss: 2.9015326823488103
Validation loss: 2.7226677308486615

Epoch: 5| Step: 10
Training loss: 2.991856330094538
Validation loss: 2.6775488394664735

Epoch: 160| Step: 0
Training loss: 3.0294681306363027
Validation loss: 2.7339220366198798

Epoch: 5| Step: 1
Training loss: 3.1444555806598182
Validation loss: 2.694246752625021

Epoch: 5| Step: 2
Training loss: 2.845359095485697
Validation loss: 2.756472212891123

Epoch: 5| Step: 3
Training loss: 2.8459650153491536
Validation loss: 2.711351713437024

Epoch: 5| Step: 4
Training loss: 2.988996831448746
Validation loss: 2.729596184437696

Epoch: 5| Step: 5
Training loss: 3.103910772712537
Validation loss: 2.720333147147001

Epoch: 5| Step: 6
Training loss: 2.6617871185291424
Validation loss: 2.751827632027815

Epoch: 5| Step: 7
Training loss: 2.4950022333169546
Validation loss: 2.731222390316694

Epoch: 5| Step: 8
Training loss: 2.167667402338995
Validation loss: 2.6852349554239656

Epoch: 5| Step: 9
Training loss: 2.751355097425875
Validation loss: 2.734345489202071

Epoch: 5| Step: 10
Training loss: 2.865740252291459
Validation loss: 2.7041934731042456

Epoch: 161| Step: 0
Training loss: 2.7115387263612676
Validation loss: 2.707564449892877

Epoch: 5| Step: 1
Training loss: 2.977489257075662
Validation loss: 2.705239853259984

Epoch: 5| Step: 2
Training loss: 3.1403161651441134
Validation loss: 2.6884422481978816

Epoch: 5| Step: 3
Training loss: 2.4657512753330657
Validation loss: 2.741671574165517

Epoch: 5| Step: 4
Training loss: 2.091768950232316
Validation loss: 2.702750383051833

Epoch: 5| Step: 5
Training loss: 3.0520984184925215
Validation loss: 2.734105187858632

Epoch: 5| Step: 6
Training loss: 2.7638758931155296
Validation loss: 2.7376098624252743

Epoch: 5| Step: 7
Training loss: 2.3320857413872855
Validation loss: 2.7068436159587406

Epoch: 5| Step: 8
Training loss: 3.630038213187186
Validation loss: 2.7602191770045104

Epoch: 5| Step: 9
Training loss: 2.360342774633258
Validation loss: 2.727490064563155

Epoch: 5| Step: 10
Training loss: 3.1009448611152775
Validation loss: 2.673497153093868

Epoch: 162| Step: 0
Training loss: 2.7852385991617044
Validation loss: 2.642727930923694

Epoch: 5| Step: 1
Training loss: 2.951714557307299
Validation loss: 2.713355612212736

Epoch: 5| Step: 2
Training loss: 2.6699130344872386
Validation loss: 2.6630959293886143

Epoch: 5| Step: 3
Training loss: 2.9238737888885713
Validation loss: 2.7035850310327074

Epoch: 5| Step: 4
Training loss: 2.635728076333104
Validation loss: 2.674372267535517

Epoch: 5| Step: 5
Training loss: 3.5510714405020516
Validation loss: 2.659863866927357

Epoch: 5| Step: 6
Training loss: 2.7610116185514104
Validation loss: 2.720500016480516

Epoch: 5| Step: 7
Training loss: 2.2100870498498058
Validation loss: 2.635099623863834

Epoch: 5| Step: 8
Training loss: 2.602158028655718
Validation loss: 2.6814225144757744

Epoch: 5| Step: 9
Training loss: 2.529057624724523
Validation loss: 2.718537234254264

Epoch: 5| Step: 10
Training loss: 2.830204151998966
Validation loss: 2.751878928069539

Epoch: 163| Step: 0
Training loss: 3.2655865972715814
Validation loss: 2.679517522633871

Epoch: 5| Step: 1
Training loss: 2.7826769307959704
Validation loss: 2.7125171403195427

Epoch: 5| Step: 2
Training loss: 1.9844281647536413
Validation loss: 2.706630844384513

Epoch: 5| Step: 3
Training loss: 3.5038587552086966
Validation loss: 2.643909566611696

Epoch: 5| Step: 4
Training loss: 2.3239996285889637
Validation loss: 2.6891892569336444

Epoch: 5| Step: 5
Training loss: 2.473648426655714
Validation loss: 2.7451471353579042

Epoch: 5| Step: 6
Training loss: 2.4833402578099464
Validation loss: 2.7068996417871602

Epoch: 5| Step: 7
Training loss: 3.3002026293417734
Validation loss: 2.7037435337622884

Epoch: 5| Step: 8
Training loss: 2.7165306065037766
Validation loss: 2.778309931763517

Epoch: 5| Step: 9
Training loss: 2.4993540883125482
Validation loss: 2.702869301473695

Epoch: 5| Step: 10
Training loss: 2.9482502742933145
Validation loss: 2.6694043071439517

Epoch: 164| Step: 0
Training loss: 3.158569390190972
Validation loss: 2.7213331536228877

Epoch: 5| Step: 1
Training loss: 2.6513319374958777
Validation loss: 2.6986594685869054

Epoch: 5| Step: 2
Training loss: 2.9631238127687753
Validation loss: 2.7196235144555434

Epoch: 5| Step: 3
Training loss: 2.400889879395175
Validation loss: 2.7444030806705335

Epoch: 5| Step: 4
Training loss: 3.290916808141821
Validation loss: 2.6728701841512184

Epoch: 5| Step: 5
Training loss: 2.860358397429099
Validation loss: 2.761996581467948

Epoch: 5| Step: 6
Training loss: 2.9766360296343723
Validation loss: 2.6726504154598882

Epoch: 5| Step: 7
Training loss: 2.540681575131157
Validation loss: 2.725060960566267

Epoch: 5| Step: 8
Training loss: 2.474170287572777
Validation loss: 2.737188640064164

Epoch: 5| Step: 9
Training loss: 2.897112191210743
Validation loss: 2.700836859628866

Epoch: 5| Step: 10
Training loss: 2.693844248811172
Validation loss: 2.7225594645120355

Epoch: 165| Step: 0
Training loss: 3.316918934440721
Validation loss: 2.7095531486948836

Epoch: 5| Step: 1
Training loss: 2.641418969688716
Validation loss: 2.775376470117107

Epoch: 5| Step: 2
Training loss: 2.307827740143061
Validation loss: 2.7379322114804054

Epoch: 5| Step: 3
Training loss: 2.986305451291459
Validation loss: 2.699362825518847

Epoch: 5| Step: 4
Training loss: 3.1037371720207556
Validation loss: 2.6822314196585686

Epoch: 5| Step: 5
Training loss: 3.072780093159211
Validation loss: 2.7101778377020254

Epoch: 5| Step: 6
Training loss: 3.066003935839372
Validation loss: 2.71792541189596

Epoch: 5| Step: 7
Training loss: 2.013346248905279
Validation loss: 2.669256177492323

Epoch: 5| Step: 8
Training loss: 2.612834259260148
Validation loss: 2.704903527686089

Epoch: 5| Step: 9
Training loss: 2.618403365835421
Validation loss: 2.7465106980917517

Epoch: 5| Step: 10
Training loss: 2.670326899829518
Validation loss: 2.6555232251143557

Epoch: 166| Step: 0
Training loss: 3.011944041255383
Validation loss: 2.6868399696463423

Epoch: 5| Step: 1
Training loss: 2.6853517329669376
Validation loss: 2.6777392366305826

Epoch: 5| Step: 2
Training loss: 2.716069884562687
Validation loss: 2.7019001366197726

Epoch: 5| Step: 3
Training loss: 3.1676863651502787
Validation loss: 2.6832924396479263

Epoch: 5| Step: 4
Training loss: 2.3774190930259387
Validation loss: 2.6896072333891126

Epoch: 5| Step: 5
Training loss: 2.7104546284540008
Validation loss: 2.69688936332669

Epoch: 5| Step: 6
Training loss: 3.1075570624368702
Validation loss: 2.7293883547296067

Epoch: 5| Step: 7
Training loss: 2.551586263607861
Validation loss: 2.742477490005772

Epoch: 5| Step: 8
Training loss: 2.800383769710843
Validation loss: 2.7252802947476438

Epoch: 5| Step: 9
Training loss: 3.0048258431693378
Validation loss: 2.692967356916575

Epoch: 5| Step: 10
Training loss: 2.492974327509136
Validation loss: 2.6785108037905747

Epoch: 167| Step: 0
Training loss: 2.8665478068114183
Validation loss: 2.7464599439898287

Epoch: 5| Step: 1
Training loss: 2.3268111445138575
Validation loss: 2.763018522392761

Epoch: 5| Step: 2
Training loss: 2.9624066495070283
Validation loss: 2.7442867570186986

Epoch: 5| Step: 3
Training loss: 2.4325767094120736
Validation loss: 2.695960259412223

Epoch: 5| Step: 4
Training loss: 3.0901352543534
Validation loss: 2.733044823535075

Epoch: 5| Step: 5
Training loss: 2.909371781065704
Validation loss: 2.702971341741743

Epoch: 5| Step: 6
Training loss: 2.946679888159087
Validation loss: 2.7423194844375973

Epoch: 5| Step: 7
Training loss: 2.5664855851869044
Validation loss: 2.700248802735367

Epoch: 5| Step: 8
Training loss: 2.493825153184024
Validation loss: 2.672442716703681

Epoch: 5| Step: 9
Training loss: 3.213102849658777
Validation loss: 2.7098734598139504

Epoch: 5| Step: 10
Training loss: 2.881596171669797
Validation loss: 2.6906027962769863

Epoch: 168| Step: 0
Training loss: 2.410588106758759
Validation loss: 2.664689112997006

Epoch: 5| Step: 1
Training loss: 3.3736357580730933
Validation loss: 2.718173634377274

Epoch: 5| Step: 2
Training loss: 2.1373272296170285
Validation loss: 2.72172677810429

Epoch: 5| Step: 3
Training loss: 2.2722233941972356
Validation loss: 2.682414208558026

Epoch: 5| Step: 4
Training loss: 3.15388112827111
Validation loss: 2.7058215320308494

Epoch: 5| Step: 5
Training loss: 2.892623952519317
Validation loss: 2.7176884384564395

Epoch: 5| Step: 6
Training loss: 3.0609092473531825
Validation loss: 2.71270259295114

Epoch: 5| Step: 7
Training loss: 2.4827522400156514
Validation loss: 2.6782438819773957

Epoch: 5| Step: 8
Training loss: 2.7116976944598594
Validation loss: 2.655840317694534

Epoch: 5| Step: 9
Training loss: 3.307481094502389
Validation loss: 2.6990271714707426

Epoch: 5| Step: 10
Training loss: 2.3831903877161773
Validation loss: 2.6416218077569384

Epoch: 169| Step: 0
Training loss: 3.064916785947892
Validation loss: 2.7048389303443447

Epoch: 5| Step: 1
Training loss: 2.7968747442660935
Validation loss: 2.677548427759489

Epoch: 5| Step: 2
Training loss: 2.092000999428563
Validation loss: 2.729545655872371

Epoch: 5| Step: 3
Training loss: 2.5053510618626422
Validation loss: 2.732430790048515

Epoch: 5| Step: 4
Training loss: 3.4556203258232343
Validation loss: 2.701694445480677

Epoch: 5| Step: 5
Training loss: 2.91485339520734
Validation loss: 2.7144766105376887

Epoch: 5| Step: 6
Training loss: 2.437350733172512
Validation loss: 2.7263177278253736

Epoch: 5| Step: 7
Training loss: 3.18805196134372
Validation loss: 2.719341452779512

Epoch: 5| Step: 8
Training loss: 2.961353926954439
Validation loss: 2.7664227246780184

Epoch: 5| Step: 9
Training loss: 2.1631809463474445
Validation loss: 2.726003928888039

Epoch: 5| Step: 10
Training loss: 2.6395594687362816
Validation loss: 2.7020702278030075

Epoch: 170| Step: 0
Training loss: 2.24195940405974
Validation loss: 2.6677708557279827

Epoch: 5| Step: 1
Training loss: 2.759624631483321
Validation loss: 2.7093419288126754

Epoch: 5| Step: 2
Training loss: 2.80993696623998
Validation loss: 2.7011021923096687

Epoch: 5| Step: 3
Training loss: 2.81732357498383
Validation loss: 2.7188548179961076

Epoch: 5| Step: 4
Training loss: 2.538160146147251
Validation loss: 2.6827814145893356

Epoch: 5| Step: 5
Training loss: 2.735084746754647
Validation loss: 2.688028087658196

Epoch: 5| Step: 6
Training loss: 2.648248266250675
Validation loss: 2.712851337913917

Epoch: 5| Step: 7
Training loss: 3.315200856195435
Validation loss: 2.716856901228561

Epoch: 5| Step: 8
Training loss: 2.1213103406840124
Validation loss: 2.6733228781583174

Epoch: 5| Step: 9
Training loss: 3.080826092203257
Validation loss: 2.6976055414534836

Epoch: 5| Step: 10
Training loss: 3.7122549830286435
Validation loss: 2.6753412869289623

Epoch: 171| Step: 0
Training loss: 3.5240207367026035
Validation loss: 2.7011365517382995

Epoch: 5| Step: 1
Training loss: 3.0480220885089686
Validation loss: 2.6784200458163525

Epoch: 5| Step: 2
Training loss: 2.8515701920915086
Validation loss: 2.687584191978413

Epoch: 5| Step: 3
Training loss: 3.103631009645116
Validation loss: 2.7443151622927373

Epoch: 5| Step: 4
Training loss: 2.7433098998368686
Validation loss: 2.671056041794422

Epoch: 5| Step: 5
Training loss: 2.516790842525364
Validation loss: 2.679540519088037

Epoch: 5| Step: 6
Training loss: 2.720905720875777
Validation loss: 2.7248593980789466

Epoch: 5| Step: 7
Training loss: 2.6835082816516276
Validation loss: 2.7011623528173985

Epoch: 5| Step: 8
Training loss: 2.1697824400731416
Validation loss: 2.636685857411945

Epoch: 5| Step: 9
Training loss: 1.8888475874829695
Validation loss: 2.688037388372106

Epoch: 5| Step: 10
Training loss: 3.18146032451259
Validation loss: 2.6923803634846957

Epoch: 172| Step: 0
Training loss: 2.79676972089849
Validation loss: 2.684851602325438

Epoch: 5| Step: 1
Training loss: 2.8632566026821165
Validation loss: 2.7222487808166993

Epoch: 5| Step: 2
Training loss: 2.9174282896092247
Validation loss: 2.6962181744254248

Epoch: 5| Step: 3
Training loss: 2.794235774398296
Validation loss: 2.6436995701113535

Epoch: 5| Step: 4
Training loss: 2.673400800175482
Validation loss: 2.6665633230283468

Epoch: 5| Step: 5
Training loss: 2.306272007286703
Validation loss: 2.6342681602685865

Epoch: 5| Step: 6
Training loss: 2.810265479935749
Validation loss: 2.720652965548555

Epoch: 5| Step: 7
Training loss: 2.121389238489245
Validation loss: 2.7140516212487116

Epoch: 5| Step: 8
Training loss: 3.0687898155473006
Validation loss: 2.7016255667237687

Epoch: 5| Step: 9
Training loss: 3.0965497228128034
Validation loss: 2.6900669391505643

Epoch: 5| Step: 10
Training loss: 3.1282136795934052
Validation loss: 2.6751917428671033

Epoch: 173| Step: 0
Training loss: 3.0368694639969993
Validation loss: 2.744336476097509

Epoch: 5| Step: 1
Training loss: 2.3238049050545038
Validation loss: 2.7089784271993294

Epoch: 5| Step: 2
Training loss: 2.4065609025126378
Validation loss: 2.6860861773683857

Epoch: 5| Step: 3
Training loss: 3.2755727427287757
Validation loss: 2.7351951669953323

Epoch: 5| Step: 4
Training loss: 2.7059280767870355
Validation loss: 2.6647118198817163

Epoch: 5| Step: 5
Training loss: 3.661255238933989
Validation loss: 2.6990363383490976

Epoch: 5| Step: 6
Training loss: 3.047260905549319
Validation loss: 2.672363722055628

Epoch: 5| Step: 7
Training loss: 1.9939142859047156
Validation loss: 2.695332318043327

Epoch: 5| Step: 8
Training loss: 2.9149232467570845
Validation loss: 2.662768926947115

Epoch: 5| Step: 9
Training loss: 2.5773300332418128
Validation loss: 2.694528919924527

Epoch: 5| Step: 10
Training loss: 2.705353892898586
Validation loss: 2.7713162398214393

Epoch: 174| Step: 0
Training loss: 1.9075176214201646
Validation loss: 2.6976695503243

Epoch: 5| Step: 1
Training loss: 2.9169810716016857
Validation loss: 2.681786090351912

Epoch: 5| Step: 2
Training loss: 3.1090428160537873
Validation loss: 2.7068755726817653

Epoch: 5| Step: 3
Training loss: 2.9041310450933846
Validation loss: 2.6980411185518984

Epoch: 5| Step: 4
Training loss: 3.007467829785114
Validation loss: 2.6736647478837217

Epoch: 5| Step: 5
Training loss: 2.7618458245163575
Validation loss: 2.7075485632274283

Epoch: 5| Step: 6
Training loss: 2.96920548006724
Validation loss: 2.683261766079954

Epoch: 5| Step: 7
Training loss: 2.817639635039505
Validation loss: 2.7081000562844944

Epoch: 5| Step: 8
Training loss: 2.276290519140045
Validation loss: 2.7166526067694434

Epoch: 5| Step: 9
Training loss: 2.271736583664643
Validation loss: 2.7349218971879825

Epoch: 5| Step: 10
Training loss: 3.2203736885695053
Validation loss: 2.751019929150922

Epoch: 175| Step: 0
Training loss: 3.1321287098596304
Validation loss: 2.7142274095708236

Epoch: 5| Step: 1
Training loss: 2.501046724538099
Validation loss: 2.748241370304162

Epoch: 5| Step: 2
Training loss: 2.531460035110725
Validation loss: 2.7155260983927434

Epoch: 5| Step: 3
Training loss: 2.8306676067734657
Validation loss: 2.687951220107623

Epoch: 5| Step: 4
Training loss: 3.0709982535712226
Validation loss: 2.7479387465496448

Epoch: 5| Step: 5
Training loss: 2.4854741574012342
Validation loss: 2.668043383674157

Epoch: 5| Step: 6
Training loss: 3.1817907926693465
Validation loss: 2.6666747395588084

Epoch: 5| Step: 7
Training loss: 2.424114840484497
Validation loss: 2.7304043537566574

Epoch: 5| Step: 8
Training loss: 3.233616836808288
Validation loss: 2.662836999867742

Epoch: 5| Step: 9
Training loss: 2.664760643550289
Validation loss: 2.7269374332114316

Epoch: 5| Step: 10
Training loss: 2.626535239183152
Validation loss: 2.7578022205517123

Epoch: 176| Step: 0
Training loss: 2.732965771066801
Validation loss: 2.685647040474543

Epoch: 5| Step: 1
Training loss: 2.735134084786608
Validation loss: 2.661033836526875

Epoch: 5| Step: 2
Training loss: 2.3235868733047598
Validation loss: 2.6743590446395205

Epoch: 5| Step: 3
Training loss: 3.4982803752417087
Validation loss: 2.7443266403427256

Epoch: 5| Step: 4
Training loss: 2.188738009399824
Validation loss: 2.6990056033957277

Epoch: 5| Step: 5
Training loss: 3.1787106374807848
Validation loss: 2.76264103622384

Epoch: 5| Step: 6
Training loss: 2.857292375739484
Validation loss: 2.693537932856998

Epoch: 5| Step: 7
Training loss: 2.5705563507819016
Validation loss: 2.7218794500856314

Epoch: 5| Step: 8
Training loss: 3.15023336000258
Validation loss: 2.7109220156254437

Epoch: 5| Step: 9
Training loss: 2.1432380042622
Validation loss: 2.6432785969542505

Epoch: 5| Step: 10
Training loss: 2.6355904884964545
Validation loss: 2.677450409056914

Epoch: 177| Step: 0
Training loss: 3.701094702567808
Validation loss: 2.71412491121611

Epoch: 5| Step: 1
Training loss: 2.1776350742845207
Validation loss: 2.7035407176359985

Epoch: 5| Step: 2
Training loss: 2.486701499790447
Validation loss: 2.7084833105193398

Epoch: 5| Step: 3
Training loss: 2.58292566179618
Validation loss: 2.7479054789177138

Epoch: 5| Step: 4
Training loss: 2.644130028359528
Validation loss: 2.6989694007089398

Epoch: 5| Step: 5
Training loss: 2.4804890308902685
Validation loss: 2.759390668685521

Epoch: 5| Step: 6
Training loss: 2.8791868158528815
Validation loss: 2.7345991285967406

Epoch: 5| Step: 7
Training loss: 2.7376356465772878
Validation loss: 2.7563372276399014

Epoch: 5| Step: 8
Training loss: 2.7402580407032238
Validation loss: 2.68400117514394

Epoch: 5| Step: 9
Training loss: 2.9267578125
Validation loss: 2.7264642782090722

Epoch: 5| Step: 10
Training loss: 2.9923398449712786
Validation loss: 2.6978540603710073

Epoch: 178| Step: 0
Training loss: 2.6083840870007244
Validation loss: 2.71055526807172

Epoch: 5| Step: 1
Training loss: 3.2778602165875386
Validation loss: 2.7487996111329602

Epoch: 5| Step: 2
Training loss: 2.26182089461298
Validation loss: 2.69640541644932

Epoch: 5| Step: 3
Training loss: 2.5863426789999333
Validation loss: 2.733448126723677

Epoch: 5| Step: 4
Training loss: 3.0570858177191256
Validation loss: 2.692919719609822

Epoch: 5| Step: 5
Training loss: 3.364923765047297
Validation loss: 2.6978095682653254

Epoch: 5| Step: 6
Training loss: 3.4483897335061173
Validation loss: 2.7079442132003475

Epoch: 5| Step: 7
Training loss: 2.4811044914569953
Validation loss: 2.691903205766343

Epoch: 5| Step: 8
Training loss: 1.7239925538630225
Validation loss: 2.7187250749338676

Epoch: 5| Step: 9
Training loss: 2.8203357473667485
Validation loss: 2.7184212881600667

Epoch: 5| Step: 10
Training loss: 2.0252663142902536
Validation loss: 2.714839166339467

Epoch: 179| Step: 0
Training loss: 2.2441552861384664
Validation loss: 2.7243556929229693

Epoch: 5| Step: 1
Training loss: 3.1272262272896008
Validation loss: 2.666618667030827

Epoch: 5| Step: 2
Training loss: 2.436622168121156
Validation loss: 2.726972462691398

Epoch: 5| Step: 3
Training loss: 2.798544358897504
Validation loss: 2.72248639407155

Epoch: 5| Step: 4
Training loss: 2.456661129776587
Validation loss: 2.6405583806671395

Epoch: 5| Step: 5
Training loss: 2.2521614712814464
Validation loss: 2.7530679043875357

Epoch: 5| Step: 6
Training loss: 3.1351247421343023
Validation loss: 2.709332971854489

Epoch: 5| Step: 7
Training loss: 2.2730541627055474
Validation loss: 2.726569103342627

Epoch: 5| Step: 8
Training loss: 2.4790862788997
Validation loss: 2.7465189756240087

Epoch: 5| Step: 9
Training loss: 3.4691284248198517
Validation loss: 2.719106168782152

Epoch: 5| Step: 10
Training loss: 3.393893727443261
Validation loss: 2.6643187697011075

Epoch: 180| Step: 0
Training loss: 2.806251196234433
Validation loss: 2.7509768961209056

Epoch: 5| Step: 1
Training loss: 2.2273836462113277
Validation loss: 2.664432113027747

Epoch: 5| Step: 2
Training loss: 2.9286031521929816
Validation loss: 2.718426928609838

Epoch: 5| Step: 3
Training loss: 2.665295804839478
Validation loss: 2.7277596438261775

Epoch: 5| Step: 4
Training loss: 2.6538865289412987
Validation loss: 2.711884224092027

Epoch: 5| Step: 5
Training loss: 3.485797129993329
Validation loss: 2.6941562326196236

Epoch: 5| Step: 6
Training loss: 2.67101992482502
Validation loss: 2.6892230917263444

Epoch: 5| Step: 7
Training loss: 2.232851375938132
Validation loss: 2.7497621761564193

Epoch: 5| Step: 8
Training loss: 3.4248502155603004
Validation loss: 2.7029745029329515

Epoch: 5| Step: 9
Training loss: 2.564761582684282
Validation loss: 2.7376820132395756

Epoch: 5| Step: 10
Training loss: 2.2675471077833964
Validation loss: 2.737813241039793

Epoch: 181| Step: 0
Training loss: 3.158677631088084
Validation loss: 2.7385773986248463

Epoch: 5| Step: 1
Training loss: 3.1327392873984996
Validation loss: 2.6766959943949833

Epoch: 5| Step: 2
Training loss: 3.401151568675384
Validation loss: 2.7648954370647725

Epoch: 5| Step: 3
Training loss: 2.5212528940996495
Validation loss: 2.7185222477060704

Epoch: 5| Step: 4
Training loss: 2.8345619417596724
Validation loss: 2.711969949548482

Epoch: 5| Step: 5
Training loss: 2.2926975590269136
Validation loss: 2.693584347642615

Epoch: 5| Step: 6
Training loss: 3.1837489178059974
Validation loss: 2.7483727403419174

Epoch: 5| Step: 7
Training loss: 2.79631761505818
Validation loss: 2.6846756284695923

Epoch: 5| Step: 8
Training loss: 2.403041632784939
Validation loss: 2.725530594897502

Epoch: 5| Step: 9
Training loss: 1.824497569175851
Validation loss: 2.7493147942604157

Epoch: 5| Step: 10
Training loss: 2.5824664004596793
Validation loss: 2.707543413308839

Epoch: 182| Step: 0
Training loss: 3.563540524227283
Validation loss: 2.7375854771027393

Epoch: 5| Step: 1
Training loss: 2.7915153936897403
Validation loss: 2.6510731697849903

Epoch: 5| Step: 2
Training loss: 2.0595473916309923
Validation loss: 2.7175481579966734

Epoch: 5| Step: 3
Training loss: 2.3109266754165114
Validation loss: 2.7019915793957834

Epoch: 5| Step: 4
Training loss: 2.1287793602881484
Validation loss: 2.703384469471693

Epoch: 5| Step: 5
Training loss: 2.031953191082893
Validation loss: 2.7086955409645435

Epoch: 5| Step: 6
Training loss: 3.5255832270795215
Validation loss: 2.7140806083848

Epoch: 5| Step: 7
Training loss: 3.0032847224065073
Validation loss: 2.70092328121979

Epoch: 5| Step: 8
Training loss: 2.923224316097155
Validation loss: 2.758800957970179

Epoch: 5| Step: 9
Training loss: 2.542458666200089
Validation loss: 2.724681638612861

Epoch: 5| Step: 10
Training loss: 3.5120871141704293
Validation loss: 2.7528219696924667

Epoch: 183| Step: 0
Training loss: 2.818366311765978
Validation loss: 2.6599110167796085

Epoch: 5| Step: 1
Training loss: 2.541517274145319
Validation loss: 2.7323703881962067

Epoch: 5| Step: 2
Training loss: 2.5099774579255554
Validation loss: 2.689258206360969

Epoch: 5| Step: 3
Training loss: 2.385246559530011
Validation loss: 2.6671383373935003

Epoch: 5| Step: 4
Training loss: 2.605094459563705
Validation loss: 2.693033442288468

Epoch: 5| Step: 5
Training loss: 2.5821021643060647
Validation loss: 2.672401355747911

Epoch: 5| Step: 6
Training loss: 3.4959700408018493
Validation loss: 2.7247606030625913

Epoch: 5| Step: 7
Training loss: 2.2693637910869175
Validation loss: 2.691821070780237

Epoch: 5| Step: 8
Training loss: 3.5828141716122626
Validation loss: 2.7624718291903183

Epoch: 5| Step: 9
Training loss: 2.8125042385493235
Validation loss: 2.7403770752677508

Epoch: 5| Step: 10
Training loss: 2.8471486668790296
Validation loss: 2.6808229297088735

Epoch: 184| Step: 0
Training loss: 2.0416604515551993
Validation loss: 2.7069241690593797

Epoch: 5| Step: 1
Training loss: 2.424242204066469
Validation loss: 2.667688163207657

Epoch: 5| Step: 2
Training loss: 3.068340415580349
Validation loss: 2.6763053939371266

Epoch: 5| Step: 3
Training loss: 2.430818447851673
Validation loss: 2.699046436031825

Epoch: 5| Step: 4
Training loss: 2.3897472091484513
Validation loss: 2.7036401486704116

Epoch: 5| Step: 5
Training loss: 2.7819247338145896
Validation loss: 2.6800089002123832

Epoch: 5| Step: 6
Training loss: 2.9281332140047045
Validation loss: 2.6938687560087846

Epoch: 5| Step: 7
Training loss: 2.859776036223109
Validation loss: 2.691508221938549

Epoch: 5| Step: 8
Training loss: 2.7661154791611966
Validation loss: 2.729169985698632

Epoch: 5| Step: 9
Training loss: 3.2629266569526725
Validation loss: 2.7318680378966187

Epoch: 5| Step: 10
Training loss: 2.710988860509508
Validation loss: 2.6902305618521383

Epoch: 185| Step: 0
Training loss: 3.26684095021572
Validation loss: 2.7167986990287782

Epoch: 5| Step: 1
Training loss: 2.4125009566389175
Validation loss: 2.7354540199232558

Epoch: 5| Step: 2
Training loss: 2.8230983680345547
Validation loss: 2.7316746273023758

Epoch: 5| Step: 3
Training loss: 2.2393771645921174
Validation loss: 2.703435839766588

Epoch: 5| Step: 4
Training loss: 1.9072069986475793
Validation loss: 2.7464529040173375

Epoch: 5| Step: 5
Training loss: 2.5822345693989393
Validation loss: 2.6825794046920737

Epoch: 5| Step: 6
Training loss: 2.979388159852266
Validation loss: 2.6794624799781084

Epoch: 5| Step: 7
Training loss: 3.451754336813236
Validation loss: 2.7627152317836225

Epoch: 5| Step: 8
Training loss: 2.162144440984274
Validation loss: 2.701567206243457

Epoch: 5| Step: 9
Training loss: 3.1003461706015147
Validation loss: 2.694533062423301

Epoch: 5| Step: 10
Training loss: 2.9083126500950898
Validation loss: 2.7469101604510215

Epoch: 186| Step: 0
Training loss: 2.658722119815135
Validation loss: 2.7241589530303822

Epoch: 5| Step: 1
Training loss: 2.8249554655902736
Validation loss: 2.733395848908667

Epoch: 5| Step: 2
Training loss: 2.4411470565537816
Validation loss: 2.678214858269204

Epoch: 5| Step: 3
Training loss: 2.651676863821177
Validation loss: 2.697850116823219

Epoch: 5| Step: 4
Training loss: 2.7577808583635406
Validation loss: 2.6785966775683696

Epoch: 5| Step: 5
Training loss: 2.750134291404341
Validation loss: 2.7516596867439205

Epoch: 5| Step: 6
Training loss: 3.2623125278205345
Validation loss: 2.7011213205864775

Epoch: 5| Step: 7
Training loss: 3.4039443025526097
Validation loss: 2.7331136083439254

Epoch: 5| Step: 8
Training loss: 2.289017296042035
Validation loss: 2.7053946031867913

Epoch: 5| Step: 9
Training loss: 3.076647718652947
Validation loss: 2.7073790321160405

Epoch: 5| Step: 10
Training loss: 2.40289865923487
Validation loss: 2.70876815151469

Epoch: 187| Step: 0
Training loss: 2.829361450351623
Validation loss: 2.7295077468593254

Epoch: 5| Step: 1
Training loss: 3.3892016257840556
Validation loss: 2.711199711909318

Epoch: 5| Step: 2
Training loss: 3.3294226753684075
Validation loss: 2.712923321279993

Epoch: 5| Step: 3
Training loss: 2.336050075510315
Validation loss: 2.7565190467224867

Epoch: 5| Step: 4
Training loss: 3.148266354587666
Validation loss: 2.6794091431113505

Epoch: 5| Step: 5
Training loss: 2.943954195039426
Validation loss: 2.646241280058241

Epoch: 5| Step: 6
Training loss: 2.8408515327865076
Validation loss: 2.7181721998484467

Epoch: 5| Step: 7
Training loss: 1.9772550553196802
Validation loss: 2.7219835156064724

Epoch: 5| Step: 8
Training loss: 2.767196467431916
Validation loss: 2.6519304374810075

Epoch: 5| Step: 9
Training loss: 2.249176616479444
Validation loss: 2.7308865366233013

Epoch: 5| Step: 10
Training loss: 2.2385637194963017
Validation loss: 2.733847506926393

Epoch: 188| Step: 0
Training loss: 2.9379372778547195
Validation loss: 2.7099274202827734

Epoch: 5| Step: 1
Training loss: 2.6008319000693247
Validation loss: 2.712190053156929

Epoch: 5| Step: 2
Training loss: 2.951406796469621
Validation loss: 2.6626801713243444

Epoch: 5| Step: 3
Training loss: 2.766369563163526
Validation loss: 2.7143729882307936

Epoch: 5| Step: 4
Training loss: 2.198621760321337
Validation loss: 2.6913199686030524

Epoch: 5| Step: 5
Training loss: 2.494346520536824
Validation loss: 2.715347036821837

Epoch: 5| Step: 6
Training loss: 3.174995878922799
Validation loss: 2.6756714534486012

Epoch: 5| Step: 7
Training loss: 2.4965480814818357
Validation loss: 2.7696014047826614

Epoch: 5| Step: 8
Training loss: 2.4658689467666717
Validation loss: 2.691258229698614

Epoch: 5| Step: 9
Training loss: 2.825104929232813
Validation loss: 2.6999888296819163

Epoch: 5| Step: 10
Training loss: 3.0748920018529238
Validation loss: 2.742686225351449

Epoch: 189| Step: 0
Training loss: 2.727964986017105
Validation loss: 2.7291747707336484

Epoch: 5| Step: 1
Training loss: 3.072608923723377
Validation loss: 2.6935096335980533

Epoch: 5| Step: 2
Training loss: 1.8767399026709113
Validation loss: 2.7437639632121895

Epoch: 5| Step: 3
Training loss: 2.896461821125525
Validation loss: 2.776951339043234

Epoch: 5| Step: 4
Training loss: 3.1813915288653996
Validation loss: 2.683545434245804

Epoch: 5| Step: 5
Training loss: 2.620901359398988
Validation loss: 2.731075915964494

Epoch: 5| Step: 6
Training loss: 2.640207923590727
Validation loss: 2.7103810566895077

Epoch: 5| Step: 7
Training loss: 2.606626330679046
Validation loss: 2.698979177590908

Epoch: 5| Step: 8
Training loss: 3.1416261510150596
Validation loss: 2.7107510385707885

Epoch: 5| Step: 9
Training loss: 2.9281947694525243
Validation loss: 2.756753472699899

Epoch: 5| Step: 10
Training loss: 2.2583022065029286
Validation loss: 2.6929868352296724

Epoch: 190| Step: 0
Training loss: 3.0245914277888364
Validation loss: 2.7583724257041102

Epoch: 5| Step: 1
Training loss: 2.1544515877554393
Validation loss: 2.692437832869382

Epoch: 5| Step: 2
Training loss: 3.3158770926490457
Validation loss: 2.715442139260957

Epoch: 5| Step: 3
Training loss: 2.918469734540803
Validation loss: 2.769184525615502

Epoch: 5| Step: 4
Training loss: 2.4302504889969714
Validation loss: 2.7218248977100865

Epoch: 5| Step: 5
Training loss: 2.255291650185998
Validation loss: 2.7123578828218564

Epoch: 5| Step: 6
Training loss: 2.621056091674798
Validation loss: 2.749431763016436

Epoch: 5| Step: 7
Training loss: 3.238720172728538
Validation loss: 2.690962790583925

Epoch: 5| Step: 8
Training loss: 2.718924505837708
Validation loss: 2.665779769665486

Epoch: 5| Step: 9
Training loss: 2.335084893523346
Validation loss: 2.7830376707104287

Epoch: 5| Step: 10
Training loss: 3.2074763817337586
Validation loss: 2.672271543651731

Epoch: 191| Step: 0
Training loss: 2.815959752174505
Validation loss: 2.7162139024828487

Epoch: 5| Step: 1
Training loss: 2.8535806281631895
Validation loss: 2.6589776045492575

Epoch: 5| Step: 2
Training loss: 2.6373465687747837
Validation loss: 2.733786327087443

Epoch: 5| Step: 3
Training loss: 2.822787142288874
Validation loss: 2.674060924506043

Epoch: 5| Step: 4
Training loss: 2.9645873751761327
Validation loss: 2.7359276057898434

Epoch: 5| Step: 5
Training loss: 3.026818408299191
Validation loss: 2.7083836389102425

Epoch: 5| Step: 6
Training loss: 2.563255384803592
Validation loss: 2.7969184377604637

Epoch: 5| Step: 7
Training loss: 3.209540961412301
Validation loss: 2.71171680944728

Epoch: 5| Step: 8
Training loss: 2.1017368627205473
Validation loss: 2.678173779818156

Epoch: 5| Step: 9
Training loss: 2.502501380759972
Validation loss: 2.708706221613991

Epoch: 5| Step: 10
Training loss: 2.9867084428158863
Validation loss: 2.7515737192162404

Epoch: 192| Step: 0
Training loss: 2.404491128519231
Validation loss: 2.72682949716595

Epoch: 5| Step: 1
Training loss: 3.3025098619450977
Validation loss: 2.716094212928397

Epoch: 5| Step: 2
Training loss: 2.6416427186026845
Validation loss: 2.71379140797757

Epoch: 5| Step: 3
Training loss: 2.6246430290552394
Validation loss: 2.695354763922465

Epoch: 5| Step: 4
Training loss: 3.334097504442307
Validation loss: 2.7245163916560844

Epoch: 5| Step: 5
Training loss: 2.612731145827055
Validation loss: 2.710364579760736

Epoch: 5| Step: 6
Training loss: 2.071957952757634
Validation loss: 2.7170033476586593

Epoch: 5| Step: 7
Training loss: 3.4214762973613833
Validation loss: 2.7382874571484255

Epoch: 5| Step: 8
Training loss: 2.3989192714870713
Validation loss: 2.6698231480376737

Epoch: 5| Step: 9
Training loss: 2.170083164432128
Validation loss: 2.72179636133085

Epoch: 5| Step: 10
Training loss: 2.734585127249885
Validation loss: 2.7545613637453523

Epoch: 193| Step: 0
Training loss: 1.935002039531254
Validation loss: 2.7555921530578473

Epoch: 5| Step: 1
Training loss: 3.1764271209585058
Validation loss: 2.7534534895253824

Epoch: 5| Step: 2
Training loss: 2.765675086306039
Validation loss: 2.746814430225407

Epoch: 5| Step: 3
Training loss: 2.4081674837691027
Validation loss: 2.704422768612849

Epoch: 5| Step: 4
Training loss: 3.614483937299432
Validation loss: 2.724219431549843

Epoch: 5| Step: 5
Training loss: 3.060032687542426
Validation loss: 2.793325278297742

Epoch: 5| Step: 6
Training loss: 2.309908058681771
Validation loss: 2.7128976953676966

Epoch: 5| Step: 7
Training loss: 2.452533529132137
Validation loss: 2.6699590783837195

Epoch: 5| Step: 8
Training loss: 3.0583558361531815
Validation loss: 2.6794042519796903

Epoch: 5| Step: 9
Training loss: 2.3955811630446027
Validation loss: 2.7278732701821435

Epoch: 5| Step: 10
Training loss: 2.7937108901185783
Validation loss: 2.7343407057151214

Epoch: 194| Step: 0
Training loss: 2.748833408868332
Validation loss: 2.7064286064755985

Epoch: 5| Step: 1
Training loss: 2.2594262925864297
Validation loss: 2.6982476734589884

Epoch: 5| Step: 2
Training loss: 2.4993582855604375
Validation loss: 2.669572760520961

Epoch: 5| Step: 3
Training loss: 2.899130684356189
Validation loss: 2.7139477588409635

Epoch: 5| Step: 4
Training loss: 3.016153239892846
Validation loss: 2.7402764054324926

Epoch: 5| Step: 5
Training loss: 2.534727933229838
Validation loss: 2.7128182029904444

Epoch: 5| Step: 6
Training loss: 3.125685502206454
Validation loss: 2.671649762892758

Epoch: 5| Step: 7
Training loss: 2.7070708829282166
Validation loss: 2.698969446302176

Epoch: 5| Step: 8
Training loss: 2.698396637590057
Validation loss: 2.668264887492989

Epoch: 5| Step: 9
Training loss: 3.1042528759209636
Validation loss: 2.723152248583432

Epoch: 5| Step: 10
Training loss: 2.068637270895702
Validation loss: 2.743726334273678

Epoch: 195| Step: 0
Training loss: 3.6505587372254547
Validation loss: 2.743319414964446

Epoch: 5| Step: 1
Training loss: 3.7801626864750495
Validation loss: 2.6976059429718195

Epoch: 5| Step: 2
Training loss: 2.825633432046231
Validation loss: 2.7419555180762942

Epoch: 5| Step: 3
Training loss: 2.7906101751841494
Validation loss: 2.6811882678172285

Epoch: 5| Step: 4
Training loss: 2.837906587349723
Validation loss: 2.790194457643817

Epoch: 5| Step: 5
Training loss: 2.1914144097650556
Validation loss: 2.712956321443715

Epoch: 5| Step: 6
Training loss: 2.204810505550752
Validation loss: 2.751026074941044

Epoch: 5| Step: 7
Training loss: 2.894220209333973
Validation loss: 2.733262141081185

Epoch: 5| Step: 8
Training loss: 2.3606608341679687
Validation loss: 2.7284846001107597

Epoch: 5| Step: 9
Training loss: 2.2288306746588105
Validation loss: 2.6833081589393477

Epoch: 5| Step: 10
Training loss: 2.37000492240298
Validation loss: 2.770288011427295

Epoch: 196| Step: 0
Training loss: 2.68646246821152
Validation loss: 2.7691542933558555

Epoch: 5| Step: 1
Training loss: 2.9550137408819723
Validation loss: 2.6907743028217745

Epoch: 5| Step: 2
Training loss: 2.84394014163006
Validation loss: 2.687604358895277

Epoch: 5| Step: 3
Training loss: 3.4015135425554295
Validation loss: 2.7470764540610975

Epoch: 5| Step: 4
Training loss: 2.368444329420673
Validation loss: 2.733075554652829

Epoch: 5| Step: 5
Training loss: 2.50175538424403
Validation loss: 2.7402570097300565

Epoch: 5| Step: 6
Training loss: 2.451511119452414
Validation loss: 2.6610387016936374

Epoch: 5| Step: 7
Training loss: 3.2263728864249868
Validation loss: 2.756458599802457

Epoch: 5| Step: 8
Training loss: 2.759942288693763
Validation loss: 2.7321073612084126

Epoch: 5| Step: 9
Training loss: 2.52460322897988
Validation loss: 2.7079388131552897

Epoch: 5| Step: 10
Training loss: 1.836751749187658
Validation loss: 2.6580215462849193

Epoch: 197| Step: 0
Training loss: 2.448036796922819
Validation loss: 2.6584762904610346

Epoch: 5| Step: 1
Training loss: 3.0614639398126102
Validation loss: 2.718843191867191

Epoch: 5| Step: 2
Training loss: 2.389627784730175
Validation loss: 2.7343885523962705

Epoch: 5| Step: 3
Training loss: 2.5389224908813914
Validation loss: 2.717546902377168

Epoch: 5| Step: 4
Training loss: 2.5644404809760646
Validation loss: 2.749129485714191

Epoch: 5| Step: 5
Training loss: 2.6086970379383443
Validation loss: 2.7006698669958897

Epoch: 5| Step: 6
Training loss: 3.148853965457332
Validation loss: 2.6854575552755446

Epoch: 5| Step: 7
Training loss: 2.44655385059597
Validation loss: 2.7405221624082583

Epoch: 5| Step: 8
Training loss: 3.1625943015291185
Validation loss: 2.8087647768618744

Epoch: 5| Step: 9
Training loss: 2.442567692485317
Validation loss: 2.6996004570111047

Epoch: 5| Step: 10
Training loss: 3.4690436161627956
Validation loss: 2.768891694113965

Epoch: 198| Step: 0
Training loss: 2.36572784643716
Validation loss: 2.7238155125124117

Epoch: 5| Step: 1
Training loss: 2.8153385672906412
Validation loss: 2.7405507241002205

Epoch: 5| Step: 2
Training loss: 2.6781679521675055
Validation loss: 2.701860761835769

Epoch: 5| Step: 3
Training loss: 1.7279796739283484
Validation loss: 2.7759730168124284

Epoch: 5| Step: 4
Training loss: 2.239061575740988
Validation loss: 2.729904205403701

Epoch: 5| Step: 5
Training loss: 3.046085666235827
Validation loss: 2.7290045765155737

Epoch: 5| Step: 6
Training loss: 2.829703717577595
Validation loss: 2.7500427966176435

Epoch: 5| Step: 7
Training loss: 2.2102289041583125
Validation loss: 2.672131722573535

Epoch: 5| Step: 8
Training loss: 2.8827818995560026
Validation loss: 2.6505925211679133

Epoch: 5| Step: 9
Training loss: 3.3893559625602006
Validation loss: 2.6999696041281553

Epoch: 5| Step: 10
Training loss: 3.2943899904596483
Validation loss: 2.7088097322925715

Epoch: 199| Step: 0
Training loss: 2.74064893027007
Validation loss: 2.7109915291262694

Epoch: 5| Step: 1
Training loss: 2.247868269810945
Validation loss: 2.6710587224737448

Epoch: 5| Step: 2
Training loss: 3.0088316936995234
Validation loss: 2.702625284186412

Epoch: 5| Step: 3
Training loss: 3.398812389523683
Validation loss: 2.6845043224710885

Epoch: 5| Step: 4
Training loss: 2.3718605372775774
Validation loss: 2.737667768267874

Epoch: 5| Step: 5
Training loss: 2.2390735016344228
Validation loss: 2.750455052378175

Epoch: 5| Step: 6
Training loss: 2.2259115773450415
Validation loss: 2.6801325897382196

Epoch: 5| Step: 7
Training loss: 2.6078901806159003
Validation loss: 2.726616951007093

Epoch: 5| Step: 8
Training loss: 2.9894154110489386
Validation loss: 2.6757694185140743

Epoch: 5| Step: 9
Training loss: 3.257484181644563
Validation loss: 2.698043327258125

Epoch: 5| Step: 10
Training loss: 2.7212593512315286
Validation loss: 2.6963847439452246

Epoch: 200| Step: 0
Training loss: 2.4841248008410455
Validation loss: 2.7070234786581464

Epoch: 5| Step: 1
Training loss: 3.1427859942321863
Validation loss: 2.749599724106137

Epoch: 5| Step: 2
Training loss: 2.5958417248373395
Validation loss: 2.715928267910888

Epoch: 5| Step: 3
Training loss: 2.3692189177732126
Validation loss: 2.7530085457098457

Epoch: 5| Step: 4
Training loss: 2.8570423721626894
Validation loss: 2.710632154770359

Epoch: 5| Step: 5
Training loss: 2.3105590510430445
Validation loss: 2.7226083995838315

Epoch: 5| Step: 6
Training loss: 3.277436138028471
Validation loss: 2.796431899969658

Epoch: 5| Step: 7
Training loss: 2.961151839980751
Validation loss: 2.671540037885331

Epoch: 5| Step: 8
Training loss: 2.932253108383718
Validation loss: 2.7105587448268498

Epoch: 5| Step: 9
Training loss: 2.61549163077271
Validation loss: 2.7041592378405426

Epoch: 5| Step: 10
Training loss: 2.9126398535946816
Validation loss: 2.7257447710562612

Epoch: 201| Step: 0
Training loss: 2.1530677422383246
Validation loss: 2.7025627145588627

Epoch: 5| Step: 1
Training loss: 2.4072091308953034
Validation loss: 2.727253152337959

Epoch: 5| Step: 2
Training loss: 2.8762401725538154
Validation loss: 2.745721998432837

Epoch: 5| Step: 3
Training loss: 2.750713775942645
Validation loss: 2.695755134512544

Epoch: 5| Step: 4
Training loss: 1.8533779209705947
Validation loss: 2.740904713766059

Epoch: 5| Step: 5
Training loss: 2.3770225345504703
Validation loss: 2.689344319403179

Epoch: 5| Step: 6
Training loss: 3.067257047574989
Validation loss: 2.669369397608379

Epoch: 5| Step: 7
Training loss: 3.092782379802355
Validation loss: 2.7766680931963457

Epoch: 5| Step: 8
Training loss: 3.034936452637091
Validation loss: 2.704061433347427

Epoch: 5| Step: 9
Training loss: 2.3350575298271643
Validation loss: 2.733993327374627

Epoch: 5| Step: 10
Training loss: 3.4485911989723275
Validation loss: 2.70460938480637

Epoch: 202| Step: 0
Training loss: 2.6454148049126944
Validation loss: 2.728449660514232

Epoch: 5| Step: 1
Training loss: 3.4219482971423503
Validation loss: 2.733422772952362

Epoch: 5| Step: 2
Training loss: 2.5702451563769935
Validation loss: 2.7439923111443036

Epoch: 5| Step: 3
Training loss: 2.7215799971090435
Validation loss: 2.6428498227126593

Epoch: 5| Step: 4
Training loss: 2.5284620402230438
Validation loss: 2.7362489584562986

Epoch: 5| Step: 5
Training loss: 3.1558473537937126
Validation loss: 2.7313332811341704

Epoch: 5| Step: 6
Training loss: 2.0735778393141118
Validation loss: 2.727791319799715

Epoch: 5| Step: 7
Training loss: 3.1581131374393774
Validation loss: 2.7309203166697604

Epoch: 5| Step: 8
Training loss: 2.5618888312229555
Validation loss: 2.7203775281476803

Epoch: 5| Step: 9
Training loss: 2.2622996162490105
Validation loss: 2.762509049205095

Epoch: 5| Step: 10
Training loss: 2.492936455288217
Validation loss: 2.693897172354407

Epoch: 203| Step: 0
Training loss: 2.8975111311270028
Validation loss: 2.7415801532240347

Epoch: 5| Step: 1
Training loss: 3.017499746150375
Validation loss: 2.744700786154462

Epoch: 5| Step: 2
Training loss: 1.6813981682248447
Validation loss: 2.716422187108904

Epoch: 5| Step: 3
Training loss: 2.5517137117075093
Validation loss: 2.7220465509621983

Epoch: 5| Step: 4
Training loss: 2.945518911399088
Validation loss: 2.7227550601712087

Epoch: 5| Step: 5
Training loss: 2.821252639762512
Validation loss: 2.723514375220637

Epoch: 5| Step: 6
Training loss: 2.9119559438852125
Validation loss: 2.7815810703930337

Epoch: 5| Step: 7
Training loss: 2.9444794222915434
Validation loss: 2.701764202090275

Epoch: 5| Step: 8
Training loss: 3.1715087679194953
Validation loss: 2.725905621137167

Epoch: 5| Step: 9
Training loss: 2.632911929282094
Validation loss: 2.7291017731446905

Epoch: 5| Step: 10
Training loss: 2.300475328505078
Validation loss: 2.7145358144928746

Epoch: 204| Step: 0
Training loss: 2.887562382011818
Validation loss: 2.753007127470262

Epoch: 5| Step: 1
Training loss: 2.932310999822941
Validation loss: 2.746439916144838

Epoch: 5| Step: 2
Training loss: 2.148331851095552
Validation loss: 2.6928531106940743

Epoch: 5| Step: 3
Training loss: 3.2274349040019867
Validation loss: 2.742713032958321

Epoch: 5| Step: 4
Training loss: 2.974210355449721
Validation loss: 2.6938951277388767

Epoch: 5| Step: 5
Training loss: 2.899583615632246
Validation loss: 2.6940973506399866

Epoch: 5| Step: 6
Training loss: 2.5029841732266984
Validation loss: 2.7405611131576757

Epoch: 5| Step: 7
Training loss: 2.4214304854477473
Validation loss: 2.742761672953414

Epoch: 5| Step: 8
Training loss: 2.5297425102110194
Validation loss: 2.765061762535195

Epoch: 5| Step: 9
Training loss: 2.995635831969694
Validation loss: 2.7128611346964053

Epoch: 5| Step: 10
Training loss: 2.5117071694304376
Validation loss: 2.74293943275057

Epoch: 205| Step: 0
Training loss: 2.639209435608952
Validation loss: 2.7419932381653744

Epoch: 5| Step: 1
Training loss: 2.992300484618245
Validation loss: 2.6875611432067754

Epoch: 5| Step: 2
Training loss: 3.102437162662058
Validation loss: 2.738909707141461

Epoch: 5| Step: 3
Training loss: 2.813889223956278
Validation loss: 2.68874750995422

Epoch: 5| Step: 4
Training loss: 2.1213074184867233
Validation loss: 2.7420523304324607

Epoch: 5| Step: 5
Training loss: 2.684143099021621
Validation loss: 2.733303496495313

Epoch: 5| Step: 6
Training loss: 3.188889593271258
Validation loss: 2.7583242547713893

Epoch: 5| Step: 7
Training loss: 1.8162667825951317
Validation loss: 2.7456820364054564

Epoch: 5| Step: 8
Training loss: 2.4524881301577084
Validation loss: 2.694302414305095

Epoch: 5| Step: 9
Training loss: 2.9870092140466866
Validation loss: 2.7606179019870782

Epoch: 5| Step: 10
Training loss: 2.80184631101517
Validation loss: 2.681378182352495

Epoch: 206| Step: 0
Training loss: 2.5609294451341924
Validation loss: 2.6943848504347523

Epoch: 5| Step: 1
Training loss: 2.4204863474145064
Validation loss: 2.771291004927532

Epoch: 5| Step: 2
Training loss: 3.2679494953431836
Validation loss: 2.740403931657477

Epoch: 5| Step: 3
Training loss: 2.243023121864714
Validation loss: 2.6745196350380045

Epoch: 5| Step: 4
Training loss: 2.340090526883785
Validation loss: 2.7070995442291035

Epoch: 5| Step: 5
Training loss: 3.3375134642825905
Validation loss: 2.736853174747826

Epoch: 5| Step: 6
Training loss: 2.8477813316472207
Validation loss: 2.7253091257660076

Epoch: 5| Step: 7
Training loss: 2.333256742946095
Validation loss: 2.7022605631485623

Epoch: 5| Step: 8
Training loss: 3.0660650561573
Validation loss: 2.6706458325606155

Epoch: 5| Step: 9
Training loss: 2.2386807656032564
Validation loss: 2.747937196015833

Epoch: 5| Step: 10
Training loss: 3.01384496778918
Validation loss: 2.6990385999065687

Epoch: 207| Step: 0
Training loss: 3.3131243998957496
Validation loss: 2.723544843948951

Epoch: 5| Step: 1
Training loss: 2.3132557020802493
Validation loss: 2.712834340171384

Epoch: 5| Step: 2
Training loss: 2.10037016103948
Validation loss: 2.701630048493866

Epoch: 5| Step: 3
Training loss: 2.7816696707600927
Validation loss: 2.7798016270208374

Epoch: 5| Step: 4
Training loss: 1.679725398146224
Validation loss: 2.7290101396665114

Epoch: 5| Step: 5
Training loss: 2.958207857578249
Validation loss: 2.7239717119949085

Epoch: 5| Step: 6
Training loss: 3.139443550128487
Validation loss: 2.706974693706304

Epoch: 5| Step: 7
Training loss: 3.282314454853769
Validation loss: 2.7009034700300547

Epoch: 5| Step: 8
Training loss: 2.5145412029623344
Validation loss: 2.7485305667492073

Epoch: 5| Step: 9
Training loss: 2.458937252886957
Validation loss: 2.7267460242836443

Epoch: 5| Step: 10
Training loss: 3.1213809610497574
Validation loss: 2.7392601625157034

Epoch: 208| Step: 0
Training loss: 2.4835017366935075
Validation loss: 2.6669670430589405

Epoch: 5| Step: 1
Training loss: 3.1430043179867413
Validation loss: 2.702187705629551

Epoch: 5| Step: 2
Training loss: 2.9973690894574627
Validation loss: 2.730136116445123

Epoch: 5| Step: 3
Training loss: 2.5132229158783828
Validation loss: 2.673939685601593

Epoch: 5| Step: 4
Training loss: 2.996655984618342
Validation loss: 2.7207464757331214

Epoch: 5| Step: 5
Training loss: 3.1129032226185047
Validation loss: 2.7127609690304872

Epoch: 5| Step: 6
Training loss: 2.6340491223400044
Validation loss: 2.7438001382700654

Epoch: 5| Step: 7
Training loss: 2.472415472423684
Validation loss: 2.7163863892516527

Epoch: 5| Step: 8
Training loss: 2.2603443561947687
Validation loss: 2.7478076617794502

Epoch: 5| Step: 9
Training loss: 2.6879672154459504
Validation loss: 2.7224524905441108

Epoch: 5| Step: 10
Training loss: 2.4281200983299946
Validation loss: 2.7624589166317928

Epoch: 209| Step: 0
Training loss: 2.4249553165055104
Validation loss: 2.7796873998776546

Epoch: 5| Step: 1
Training loss: 2.414751960542702
Validation loss: 2.717398432836862

Epoch: 5| Step: 2
Training loss: 3.0088424702639816
Validation loss: 2.748486349330989

Epoch: 5| Step: 3
Training loss: 2.2957462988924044
Validation loss: 2.779850984797804

Epoch: 5| Step: 4
Training loss: 2.5326177410384894
Validation loss: 2.7751910163775397

Epoch: 5| Step: 5
Training loss: 2.8014365564175407
Validation loss: 2.7074404867371245

Epoch: 5| Step: 6
Training loss: 3.2884097504924457
Validation loss: 2.725955693340711

Epoch: 5| Step: 7
Training loss: 2.9662837978001697
Validation loss: 2.6707142422581347

Epoch: 5| Step: 8
Training loss: 2.9025798306259794
Validation loss: 2.6630513566794836

Epoch: 5| Step: 9
Training loss: 2.6822086852240465
Validation loss: 2.739534454739389

Epoch: 5| Step: 10
Training loss: 2.687296127748196
Validation loss: 2.6907898669336574

Epoch: 210| Step: 0
Training loss: 2.4919920459026432
Validation loss: 2.6998430422938697

Epoch: 5| Step: 1
Training loss: 2.893599346020967
Validation loss: 2.7788457125751242

Epoch: 5| Step: 2
Training loss: 2.6454650943048836
Validation loss: 2.735935201327862

Epoch: 5| Step: 3
Training loss: 3.105999058002985
Validation loss: 2.6964935839504416

Epoch: 5| Step: 4
Training loss: 2.9366125836048793
Validation loss: 2.6830143335034364

Epoch: 5| Step: 5
Training loss: 3.234614266653835
Validation loss: 2.772724335030427

Epoch: 5| Step: 6
Training loss: 3.0417849548192497
Validation loss: 2.799064213457217

Epoch: 5| Step: 7
Training loss: 2.326292609757719
Validation loss: 2.791553284410804

Epoch: 5| Step: 8
Training loss: 2.0707991118133156
Validation loss: 2.693816081246448

Epoch: 5| Step: 9
Training loss: 2.2597388263455263
Validation loss: 2.709259820992564

Epoch: 5| Step: 10
Training loss: 2.688057686362706
Validation loss: 2.6911935286874686

Epoch: 211| Step: 0
Training loss: 2.983621711929557
Validation loss: 2.734265293903187

Epoch: 5| Step: 1
Training loss: 2.273304938682508
Validation loss: 2.7640525946104613

Epoch: 5| Step: 2
Training loss: 2.149631570697637
Validation loss: 2.7191962711664743

Epoch: 5| Step: 3
Training loss: 2.8276041299413928
Validation loss: 2.7597178076985003

Epoch: 5| Step: 4
Training loss: 2.906728233449478
Validation loss: 2.6813012322037664

Epoch: 5| Step: 5
Training loss: 2.72999073040964
Validation loss: 2.7330647478670067

Epoch: 5| Step: 6
Training loss: 3.226665652198737
Validation loss: 2.6880116415672646

Epoch: 5| Step: 7
Training loss: 2.6951783077724665
Validation loss: 2.710119817470657

Epoch: 5| Step: 8
Training loss: 2.7076699740524157
Validation loss: 2.7788152173209966

Epoch: 5| Step: 9
Training loss: 2.2353186048725373
Validation loss: 2.7243927608598613

Epoch: 5| Step: 10
Training loss: 3.3316776137166575
Validation loss: 2.7367820502896514

Epoch: 212| Step: 0
Training loss: 2.261645063870098
Validation loss: 2.6630129198622243

Epoch: 5| Step: 1
Training loss: 2.474022173141502
Validation loss: 2.7271127923248124

Epoch: 5| Step: 2
Training loss: 2.1994881337915184
Validation loss: 2.7362393672109184

Epoch: 5| Step: 3
Training loss: 3.2372635920751334
Validation loss: 2.7579520254517087

Epoch: 5| Step: 4
Training loss: 2.7538307558357884
Validation loss: 2.7060353259877057

Epoch: 5| Step: 5
Training loss: 2.662373922165747
Validation loss: 2.7108893065557136

Epoch: 5| Step: 6
Training loss: 2.871839859740211
Validation loss: 2.7368915206198157

Epoch: 5| Step: 7
Training loss: 2.35090308591538
Validation loss: 2.749914182888237

Epoch: 5| Step: 8
Training loss: 3.1208948255795326
Validation loss: 2.7095927059440164

Epoch: 5| Step: 9
Training loss: 3.248586200431773
Validation loss: 2.7228761262487855

Epoch: 5| Step: 10
Training loss: 3.151458124220568
Validation loss: 2.717103985313909

Epoch: 213| Step: 0
Training loss: 2.7645318408608177
Validation loss: 2.7176973754232754

Epoch: 5| Step: 1
Training loss: 2.19004869485307
Validation loss: 2.7437765844064765

Epoch: 5| Step: 2
Training loss: 2.5690618098371383
Validation loss: 2.7259459821776058

Epoch: 5| Step: 3
Training loss: 2.4755584895852625
Validation loss: 2.721574057995786

Epoch: 5| Step: 4
Training loss: 3.504687576191902
Validation loss: 2.781034901195951

Epoch: 5| Step: 5
Training loss: 2.7323834823517923
Validation loss: 2.7300124574861058

Epoch: 5| Step: 6
Training loss: 3.0460264931802157
Validation loss: 2.71675302056333

Epoch: 5| Step: 7
Training loss: 2.941700468508536
Validation loss: 2.753235191121702

Epoch: 5| Step: 8
Training loss: 2.24220844750804
Validation loss: 2.777658296360314

Epoch: 5| Step: 9
Training loss: 2.59574592733004
Validation loss: 2.7081446150413586

Epoch: 5| Step: 10
Training loss: 2.4713484211658274
Validation loss: 2.7616113100316158

Epoch: 214| Step: 0
Training loss: 3.1787686906715855
Validation loss: 2.746954091529934

Epoch: 5| Step: 1
Training loss: 2.9315082232968126
Validation loss: 2.678681643699629

Epoch: 5| Step: 2
Training loss: 2.402478619022875
Validation loss: 2.751081444210041

Epoch: 5| Step: 3
Training loss: 2.759522337560278
Validation loss: 2.6924569617631975

Epoch: 5| Step: 4
Training loss: 2.1326700798803127
Validation loss: 2.736407441025261

Epoch: 5| Step: 5
Training loss: 2.693892306576106
Validation loss: 2.736669029424523

Epoch: 5| Step: 6
Training loss: 2.9587034790868523
Validation loss: 2.6775514600278174

Epoch: 5| Step: 7
Training loss: 3.057209349547068
Validation loss: 2.747107797179728

Epoch: 5| Step: 8
Training loss: 2.727215270679855
Validation loss: 2.776139795978163

Epoch: 5| Step: 9
Training loss: 2.1838961751803323
Validation loss: 2.7038379041840965

Epoch: 5| Step: 10
Training loss: 2.871093916082053
Validation loss: 2.7322711422894628

Epoch: 215| Step: 0
Training loss: 2.590727642312925
Validation loss: 2.685841890450583

Epoch: 5| Step: 1
Training loss: 2.500224866290839
Validation loss: 2.7443038869091874

Epoch: 5| Step: 2
Training loss: 2.631130960630528
Validation loss: 2.7792134771604884

Epoch: 5| Step: 3
Training loss: 2.4501964801711047
Validation loss: 2.6961198360641094

Epoch: 5| Step: 4
Training loss: 2.265683719268706
Validation loss: 2.7057090802037167

Epoch: 5| Step: 5
Training loss: 3.065322509525277
Validation loss: 2.7105480383740335

Epoch: 5| Step: 6
Training loss: 2.523632880521534
Validation loss: 2.750080108408019

Epoch: 5| Step: 7
Training loss: 3.4218086689133265
Validation loss: 2.7720287839657036

Epoch: 5| Step: 8
Training loss: 3.2158588646907162
Validation loss: 2.696141009798579

Epoch: 5| Step: 9
Training loss: 2.3923301848572045
Validation loss: 2.7599524422047095

Epoch: 5| Step: 10
Training loss: 2.5335188693150754
Validation loss: 2.7219128022322

Epoch: 216| Step: 0
Training loss: 2.670919414765657
Validation loss: 2.769408608154797

Epoch: 5| Step: 1
Training loss: 2.775462268438869
Validation loss: 2.7173546027317275

Epoch: 5| Step: 2
Training loss: 2.5797506120194726
Validation loss: 2.7333429604497606

Epoch: 5| Step: 3
Training loss: 2.4079687742382165
Validation loss: 2.739294766754858

Epoch: 5| Step: 4
Training loss: 2.3448019083127885
Validation loss: 2.689951386063335

Epoch: 5| Step: 5
Training loss: 2.739410994491466
Validation loss: 2.6769387734556993

Epoch: 5| Step: 6
Training loss: 2.5910758515433177
Validation loss: 2.756114785872151

Epoch: 5| Step: 7
Training loss: 3.424725742914981
Validation loss: 2.6588784577161193

Epoch: 5| Step: 8
Training loss: 3.353664352682615
Validation loss: 2.728818710779087

Epoch: 5| Step: 9
Training loss: 2.277810730992987
Validation loss: 2.6618044615113114

Epoch: 5| Step: 10
Training loss: 2.4998457861066523
Validation loss: 2.731749176862674

Epoch: 217| Step: 0
Training loss: 1.910578581570887
Validation loss: 2.69940733381049

Epoch: 5| Step: 1
Training loss: 3.1235084025668574
Validation loss: 2.702255275077131

Epoch: 5| Step: 2
Training loss: 2.826812945605591
Validation loss: 2.674325575868973

Epoch: 5| Step: 3
Training loss: 1.9024712678441518
Validation loss: 2.697536782101342

Epoch: 5| Step: 4
Training loss: 2.6634292521131404
Validation loss: 2.7564359548845925

Epoch: 5| Step: 5
Training loss: 2.041447789922508
Validation loss: 2.6761315193378405

Epoch: 5| Step: 6
Training loss: 2.796784468736014
Validation loss: 2.6834859955802606

Epoch: 5| Step: 7
Training loss: 2.9028677999925177
Validation loss: 2.7813584888513736

Epoch: 5| Step: 8
Training loss: 3.1173499502430384
Validation loss: 2.721563833836115

Epoch: 5| Step: 9
Training loss: 3.135944427649844
Validation loss: 2.754343056348075

Epoch: 5| Step: 10
Training loss: 3.3471522625110164
Validation loss: 2.7192925456512564

Epoch: 218| Step: 0
Training loss: 2.3328148629137604
Validation loss: 2.741477694710942

Epoch: 5| Step: 1
Training loss: 2.3221196288343275
Validation loss: 2.7177845399665377

Epoch: 5| Step: 2
Training loss: 2.621320325265523
Validation loss: 2.754591035820043

Epoch: 5| Step: 3
Training loss: 2.1898050425249225
Validation loss: 2.7266732023664106

Epoch: 5| Step: 4
Training loss: 3.0158335559258473
Validation loss: 2.66615366968423

Epoch: 5| Step: 5
Training loss: 2.8809916216997578
Validation loss: 2.743303763861039

Epoch: 5| Step: 6
Training loss: 3.0431476976226275
Validation loss: 2.7049011980535043

Epoch: 5| Step: 7
Training loss: 2.837578416992737
Validation loss: 2.739949189824202

Epoch: 5| Step: 8
Training loss: 2.135885965525091
Validation loss: 2.74511561482686

Epoch: 5| Step: 9
Training loss: 3.534614917764356
Validation loss: 2.748192107136504

Epoch: 5| Step: 10
Training loss: 2.539330477144667
Validation loss: 2.6934045735794734

Epoch: 219| Step: 0
Training loss: 1.9212716869155277
Validation loss: 2.74515774889447

Epoch: 5| Step: 1
Training loss: 3.0462893192100133
Validation loss: 2.715800817654857

Epoch: 5| Step: 2
Training loss: 2.9658738509223483
Validation loss: 2.7024526002209757

Epoch: 5| Step: 3
Training loss: 2.969695251962121
Validation loss: 2.6711112768740337

Epoch: 5| Step: 4
Training loss: 2.2061895605351234
Validation loss: 2.750846752940177

Epoch: 5| Step: 5
Training loss: 1.961878334278337
Validation loss: 2.6663387972507846

Epoch: 5| Step: 6
Training loss: 2.653184805152202
Validation loss: 2.7123726765900584

Epoch: 5| Step: 7
Training loss: 3.648558392043209
Validation loss: 2.6546948377323187

Epoch: 5| Step: 8
Training loss: 2.2512966234631113
Validation loss: 2.734377792052266

Epoch: 5| Step: 9
Training loss: 3.18839161688148
Validation loss: 2.709796147619094

Epoch: 5| Step: 10
Training loss: 2.956938365450033
Validation loss: 2.665081256763649

Epoch: 220| Step: 0
Training loss: 2.4051346609122706
Validation loss: 2.724614673317812

Epoch: 5| Step: 1
Training loss: 2.5243828009730196
Validation loss: 2.682706334698425

Epoch: 5| Step: 2
Training loss: 2.3252175629250917
Validation loss: 2.723793947304225

Epoch: 5| Step: 3
Training loss: 2.212248612255032
Validation loss: 2.701128904852834

Epoch: 5| Step: 4
Training loss: 2.6307670276862565
Validation loss: 2.698652001826647

Epoch: 5| Step: 5
Training loss: 2.750036239385243
Validation loss: 2.7386208249476582

Epoch: 5| Step: 6
Training loss: 3.23733002205396
Validation loss: 2.726974588268131

Epoch: 5| Step: 7
Training loss: 2.6178678169248477
Validation loss: 2.7124821127138303

Epoch: 5| Step: 8
Training loss: 3.5701646502910744
Validation loss: 2.689832325424497

Epoch: 5| Step: 9
Training loss: 2.5343621983892737
Validation loss: 2.733643596001645

Epoch: 5| Step: 10
Training loss: 2.643755439770741
Validation loss: 2.6914146150905816

Epoch: 221| Step: 0
Training loss: 2.9529467332106902
Validation loss: 2.6919623157297434

Epoch: 5| Step: 1
Training loss: 2.3502540369907066
Validation loss: 2.6974510042496838

Epoch: 5| Step: 2
Training loss: 3.0671856903988073
Validation loss: 2.7310254795476756

Epoch: 5| Step: 3
Training loss: 2.6831527858515436
Validation loss: 2.7600389169110473

Epoch: 5| Step: 4
Training loss: 2.332706832792138
Validation loss: 2.6603950466910837

Epoch: 5| Step: 5
Training loss: 2.8897637811235297
Validation loss: 2.755978072457321

Epoch: 5| Step: 6
Training loss: 2.1198058881602826
Validation loss: 2.7038506174072507

Epoch: 5| Step: 7
Training loss: 2.977640432381933
Validation loss: 2.7540966444338846

Epoch: 5| Step: 8
Training loss: 2.645796908230496
Validation loss: 2.8014028076352346

Epoch: 5| Step: 9
Training loss: 3.1873411251191763
Validation loss: 2.72261290707656

Epoch: 5| Step: 10
Training loss: 2.6985603556362188
Validation loss: 2.6809618346921185

Epoch: 222| Step: 0
Training loss: 2.8697008140476936
Validation loss: 2.7082207731295322

Epoch: 5| Step: 1
Training loss: 2.5470127934350613
Validation loss: 2.7202861247744528

Epoch: 5| Step: 2
Training loss: 2.8754041636453618
Validation loss: 2.7100271155219966

Epoch: 5| Step: 3
Training loss: 2.24441789552621
Validation loss: 2.7300403041765033

Epoch: 5| Step: 4
Training loss: 2.5849924809772626
Validation loss: 2.6690152930097653

Epoch: 5| Step: 5
Training loss: 2.7012794677313314
Validation loss: 2.7788274007018146

Epoch: 5| Step: 6
Training loss: 2.785092132386749
Validation loss: 2.6643318466170345

Epoch: 5| Step: 7
Training loss: 2.7788384086901003
Validation loss: 2.7071233281907463

Epoch: 5| Step: 8
Training loss: 1.677162508151971
Validation loss: 2.7352784148377136

Epoch: 5| Step: 9
Training loss: 2.9139620275281515
Validation loss: 2.720798837356726

Epoch: 5| Step: 10
Training loss: 3.6224865585509525
Validation loss: 2.7108238437297945

Epoch: 223| Step: 0
Training loss: 3.1270947874004724
Validation loss: 2.685910997393202

Epoch: 5| Step: 1
Training loss: 2.806916267806854
Validation loss: 2.732627345310837

Epoch: 5| Step: 2
Training loss: 2.846862598647608
Validation loss: 2.7216560288593437

Epoch: 5| Step: 3
Training loss: 2.6604599744298376
Validation loss: 2.728727733431454

Epoch: 5| Step: 4
Training loss: 2.5540974253426767
Validation loss: 2.7387582138460376

Epoch: 5| Step: 5
Training loss: 2.987010012231527
Validation loss: 2.755913442511833

Epoch: 5| Step: 6
Training loss: 2.689375821556056
Validation loss: 2.6832529475434073

Epoch: 5| Step: 7
Training loss: 2.4699068859634346
Validation loss: 2.719789793908766

Epoch: 5| Step: 8
Training loss: 2.056301165005061
Validation loss: 2.7193371595236364

Epoch: 5| Step: 9
Training loss: 2.240919119924831
Validation loss: 2.7131900675693

Epoch: 5| Step: 10
Training loss: 3.112390637295707
Validation loss: 2.7039752556920513

Epoch: 224| Step: 0
Training loss: 3.002160089390894
Validation loss: 2.7244701547375403

Epoch: 5| Step: 1
Training loss: 2.2647058135047944
Validation loss: 2.710761646811948

Epoch: 5| Step: 2
Training loss: 2.7704473145326762
Validation loss: 2.6997921334969175

Epoch: 5| Step: 3
Training loss: 2.6394025693045693
Validation loss: 2.7488686927794532

Epoch: 5| Step: 4
Training loss: 1.6727373982771385
Validation loss: 2.732337953713858

Epoch: 5| Step: 5
Training loss: 2.5937288582181472
Validation loss: 2.731828590172819

Epoch: 5| Step: 6
Training loss: 3.2858362027171144
Validation loss: 2.74679838184259

Epoch: 5| Step: 7
Training loss: 2.638244187645685
Validation loss: 2.7267252085495013

Epoch: 5| Step: 8
Training loss: 3.231770816939254
Validation loss: 2.7457208201215666

Epoch: 5| Step: 9
Training loss: 2.5658423792832497
Validation loss: 2.704669100008192

Epoch: 5| Step: 10
Training loss: 3.063537733241287
Validation loss: 2.717781107356621

Epoch: 225| Step: 0
Training loss: 2.852365375521452
Validation loss: 2.744015071832766

Epoch: 5| Step: 1
Training loss: 3.022400670845034
Validation loss: 2.7100255120796777

Epoch: 5| Step: 2
Training loss: 2.272182786915917
Validation loss: 2.744500904257541

Epoch: 5| Step: 3
Training loss: 2.982971500497167
Validation loss: 2.711077924883966

Epoch: 5| Step: 4
Training loss: 2.2582584983372698
Validation loss: 2.716211534415609

Epoch: 5| Step: 5
Training loss: 2.5435002909698228
Validation loss: 2.6571449282651827

Epoch: 5| Step: 6
Training loss: 3.092993595633427
Validation loss: 2.720534475813899

Epoch: 5| Step: 7
Training loss: 1.934067854893135
Validation loss: 2.705542301121283

Epoch: 5| Step: 8
Training loss: 3.163217540051344
Validation loss: 2.7283695728660176

Epoch: 5| Step: 9
Training loss: 3.0680003693740803
Validation loss: 2.6720229734377323

Epoch: 5| Step: 10
Training loss: 2.5187559369114276
Validation loss: 2.6898757514692737

Epoch: 226| Step: 0
Training loss: 2.3726798319217766
Validation loss: 2.6951546447859123

Epoch: 5| Step: 1
Training loss: 2.6908613962848613
Validation loss: 2.689203566132398

Epoch: 5| Step: 2
Training loss: 2.177392003811656
Validation loss: 2.7231082357185694

Epoch: 5| Step: 3
Training loss: 2.121603888606482
Validation loss: 2.733317918031184

Epoch: 5| Step: 4
Training loss: 2.3140173393134
Validation loss: 2.7544575350270595

Epoch: 5| Step: 5
Training loss: 3.0753742455485162
Validation loss: 2.6860523679626507

Epoch: 5| Step: 6
Training loss: 3.3125365633116215
Validation loss: 2.7303555368130112

Epoch: 5| Step: 7
Training loss: 2.944174144341994
Validation loss: 2.679634278590857

Epoch: 5| Step: 8
Training loss: 2.8946590832939365
Validation loss: 2.7493419661648906

Epoch: 5| Step: 9
Training loss: 3.191875222532714
Validation loss: 2.699842454521284

Epoch: 5| Step: 10
Training loss: 2.6774852366890816
Validation loss: 2.7098410682585414

Epoch: 227| Step: 0
Training loss: 3.060149400093256
Validation loss: 2.738970834315636

Epoch: 5| Step: 1
Training loss: 3.211539627384236
Validation loss: 2.7245500850765145

Epoch: 5| Step: 2
Training loss: 2.9178566457925084
Validation loss: 2.72098808497367

Epoch: 5| Step: 3
Training loss: 2.169839907247421
Validation loss: 2.7326495167472227

Epoch: 5| Step: 4
Training loss: 2.629534483348924
Validation loss: 2.7181006865421917

Epoch: 5| Step: 5
Training loss: 3.088547156051895
Validation loss: 2.7264987091755057

Epoch: 5| Step: 6
Training loss: 2.352535110033261
Validation loss: 2.749509175631882

Epoch: 5| Step: 7
Training loss: 2.5158365291016245
Validation loss: 2.765079168887

Epoch: 5| Step: 8
Training loss: 2.7182786905708944
Validation loss: 2.7621348040772356

Epoch: 5| Step: 9
Training loss: 2.8287472540909087
Validation loss: 2.791888917963179

Epoch: 5| Step: 10
Training loss: 2.7263556896573675
Validation loss: 2.73176912190594

Epoch: 228| Step: 0
Training loss: 2.2172780056762313
Validation loss: 2.70987113303488

Epoch: 5| Step: 1
Training loss: 2.682258106997026
Validation loss: 2.7334184783661724

Epoch: 5| Step: 2
Training loss: 2.9775896678013516
Validation loss: 2.776139831069459

Epoch: 5| Step: 3
Training loss: 2.821083534072215
Validation loss: 2.742402271093883

Epoch: 5| Step: 4
Training loss: 2.7548521757535207
Validation loss: 2.7634844761762887

Epoch: 5| Step: 5
Training loss: 2.897509485448101
Validation loss: 2.693638040538891

Epoch: 5| Step: 6
Training loss: 3.0038356103019788
Validation loss: 2.7553849406274593

Epoch: 5| Step: 7
Training loss: 2.8004010526356806
Validation loss: 2.711825220330154

Epoch: 5| Step: 8
Training loss: 2.4890624157078807
Validation loss: 2.7868435212877727

Epoch: 5| Step: 9
Training loss: 2.1926499915497493
Validation loss: 2.751136469444687

Epoch: 5| Step: 10
Training loss: 2.95434496672851
Validation loss: 2.7597578767490742

Epoch: 229| Step: 0
Training loss: 2.4272631358943313
Validation loss: 2.70854901968671

Epoch: 5| Step: 1
Training loss: 3.1197335689444268
Validation loss: 2.768517439495207

Epoch: 5| Step: 2
Training loss: 2.3214889267002743
Validation loss: 2.706867865294915

Epoch: 5| Step: 3
Training loss: 3.3352398824135854
Validation loss: 2.7102982014102204

Epoch: 5| Step: 4
Training loss: 2.6475571150918236
Validation loss: 2.7151915539837526

Epoch: 5| Step: 5
Training loss: 2.5596856269927373
Validation loss: 2.7157169387604028

Epoch: 5| Step: 6
Training loss: 2.5786869245868913
Validation loss: 2.726280315565929

Epoch: 5| Step: 7
Training loss: 3.097706432344939
Validation loss: 2.6563009268060775

Epoch: 5| Step: 8
Training loss: 2.3785151518747476
Validation loss: 2.6729045190091445

Epoch: 5| Step: 9
Training loss: 2.614637903705344
Validation loss: 2.6832871915834313

Epoch: 5| Step: 10
Training loss: 2.651001445912327
Validation loss: 2.7574552606574927

Epoch: 230| Step: 0
Training loss: 2.820938167755768
Validation loss: 2.706070488672651

Epoch: 5| Step: 1
Training loss: 2.615659353014682
Validation loss: 2.6689736167135365

Epoch: 5| Step: 2
Training loss: 2.259261039508519
Validation loss: 2.709353429178068

Epoch: 5| Step: 3
Training loss: 2.6042236830509635
Validation loss: 2.7250687632559307

Epoch: 5| Step: 4
Training loss: 2.992490588741434
Validation loss: 2.7545830319671265

Epoch: 5| Step: 5
Training loss: 2.806527556900666
Validation loss: 2.7584943756013045

Epoch: 5| Step: 6
Training loss: 2.87209886875892
Validation loss: 2.6970484296996315

Epoch: 5| Step: 7
Training loss: 3.1035383642574756
Validation loss: 2.6965497031289374

Epoch: 5| Step: 8
Training loss: 2.867271318171986
Validation loss: 2.700277943739332

Epoch: 5| Step: 9
Training loss: 2.5197540894369297
Validation loss: 2.7365258280487823

Epoch: 5| Step: 10
Training loss: 2.6031161414610486
Validation loss: 2.77294466133625

Epoch: 231| Step: 0
Training loss: 3.0070801475000244
Validation loss: 2.7417731595956414

Epoch: 5| Step: 1
Training loss: 2.3085389106549745
Validation loss: 2.733868651964288

Epoch: 5| Step: 2
Training loss: 2.1514725765366176
Validation loss: 2.6946846702619345

Epoch: 5| Step: 3
Training loss: 3.6211177162603603
Validation loss: 2.6950958597661288

Epoch: 5| Step: 4
Training loss: 2.6209865951806584
Validation loss: 2.7393407197600523

Epoch: 5| Step: 5
Training loss: 3.118831038712208
Validation loss: 2.7220136831360278

Epoch: 5| Step: 6
Training loss: 2.4849721322905207
Validation loss: 2.7304705846125072

Epoch: 5| Step: 7
Training loss: 2.5860569860046163
Validation loss: 2.703323259302118

Epoch: 5| Step: 8
Training loss: 2.294251792964378
Validation loss: 2.72485633848474

Epoch: 5| Step: 9
Training loss: 2.704255413446741
Validation loss: 2.753475376884207

Epoch: 5| Step: 10
Training loss: 2.4304049987181537
Validation loss: 2.7525270863580107

Epoch: 232| Step: 0
Training loss: 1.967121601288693
Validation loss: 2.7321678308045834

Epoch: 5| Step: 1
Training loss: 2.7182221174224845
Validation loss: 2.768113601913715

Epoch: 5| Step: 2
Training loss: 3.265028173491593
Validation loss: 2.785030877916866

Epoch: 5| Step: 3
Training loss: 3.1526545828689
Validation loss: 2.705128301256783

Epoch: 5| Step: 4
Training loss: 2.5551709758786987
Validation loss: 2.762202778168271

Epoch: 5| Step: 5
Training loss: 2.785718007836283
Validation loss: 2.721983172781013

Epoch: 5| Step: 6
Training loss: 2.31784409257564
Validation loss: 2.7566654162654496

Epoch: 5| Step: 7
Training loss: 2.3519203699476536
Validation loss: 2.753018818845672

Epoch: 5| Step: 8
Training loss: 3.041052943633413
Validation loss: 2.734980561080714

Epoch: 5| Step: 9
Training loss: 2.6321951937662105
Validation loss: 2.724317572420202

Epoch: 5| Step: 10
Training loss: 2.526111331778703
Validation loss: 2.757144721519233

Epoch: 233| Step: 0
Training loss: 2.367639781688452
Validation loss: 2.758780143419187

Epoch: 5| Step: 1
Training loss: 1.80288798131384
Validation loss: 2.723363413076092

Epoch: 5| Step: 2
Training loss: 3.4316830054387153
Validation loss: 2.8038419002421615

Epoch: 5| Step: 3
Training loss: 2.125498320549028
Validation loss: 2.7947969639263377

Epoch: 5| Step: 4
Training loss: 2.7742896261913024
Validation loss: 2.75197253887806

Epoch: 5| Step: 5
Training loss: 2.519768093125545
Validation loss: 2.6826640693226955

Epoch: 5| Step: 6
Training loss: 2.9634921444653126
Validation loss: 2.7512379001464424

Epoch: 5| Step: 7
Training loss: 2.322843564740709
Validation loss: 2.7814377447945025

Epoch: 5| Step: 8
Training loss: 2.1386114521287567
Validation loss: 2.684459992059736

Epoch: 5| Step: 9
Training loss: 3.4135500176267164
Validation loss: 2.769039318694735

Epoch: 5| Step: 10
Training loss: 3.0673226511829434
Validation loss: 2.6766957913491995

Epoch: 234| Step: 0
Training loss: 3.035581502494798
Validation loss: 2.7069657923678445

Epoch: 5| Step: 1
Training loss: 2.420405674342103
Validation loss: 2.7435144762172077

Epoch: 5| Step: 2
Training loss: 2.6710229597058195
Validation loss: 2.7693175238264303

Epoch: 5| Step: 3
Training loss: 2.515421983570973
Validation loss: 2.769439141727251

Epoch: 5| Step: 4
Training loss: 2.5854574720270773
Validation loss: 2.688363468112219

Epoch: 5| Step: 5
Training loss: 2.644975227715888
Validation loss: 2.7261508290382257

Epoch: 5| Step: 6
Training loss: 2.810339373257846
Validation loss: 2.6738600391055254

Epoch: 5| Step: 7
Training loss: 2.830294456664497
Validation loss: 2.743316914232876

Epoch: 5| Step: 8
Training loss: 2.322339338282894
Validation loss: 2.7494864361819054

Epoch: 5| Step: 9
Training loss: 2.6376855504724945
Validation loss: 2.695576738742209

Epoch: 5| Step: 10
Training loss: 3.0102156909704245
Validation loss: 2.745572963253874

Epoch: 235| Step: 0
Training loss: 3.487300858913468
Validation loss: 2.6934588668396415

Epoch: 5| Step: 1
Training loss: 2.8526784725005836
Validation loss: 2.726057812693636

Epoch: 5| Step: 2
Training loss: 2.3739080428492887
Validation loss: 2.702589699139343

Epoch: 5| Step: 3
Training loss: 3.041319021624727
Validation loss: 2.6927460038499587

Epoch: 5| Step: 4
Training loss: 2.551982882851861
Validation loss: 2.7056560285984617

Epoch: 5| Step: 5
Training loss: 2.2281233820969537
Validation loss: 2.767219174375537

Epoch: 5| Step: 6
Training loss: 2.3850933227834568
Validation loss: 2.7238682146685553

Epoch: 5| Step: 7
Training loss: 3.0058431940963115
Validation loss: 2.763618415672896

Epoch: 5| Step: 8
Training loss: 2.51077789198164
Validation loss: 2.6769477181367543

Epoch: 5| Step: 9
Training loss: 2.5812298198954844
Validation loss: 2.771070765474484

Epoch: 5| Step: 10
Training loss: 2.764712080632257
Validation loss: 2.7808005142678356

Epoch: 236| Step: 0
Training loss: 2.226416546237388
Validation loss: 2.7146579044070966

Epoch: 5| Step: 1
Training loss: 2.748932197642184
Validation loss: 2.760479015560222

Epoch: 5| Step: 2
Training loss: 2.9737272601482845
Validation loss: 2.6749653153561503

Epoch: 5| Step: 3
Training loss: 2.7744407021446316
Validation loss: 2.680592362416851

Epoch: 5| Step: 4
Training loss: 2.9858367695328614
Validation loss: 2.766826089114887

Epoch: 5| Step: 5
Training loss: 2.8192638021978462
Validation loss: 2.7756373410316164

Epoch: 5| Step: 6
Training loss: 2.7976489141816
Validation loss: 2.696383074393296

Epoch: 5| Step: 7
Training loss: 2.1773266329330316
Validation loss: 2.7374775891096763

Epoch: 5| Step: 8
Training loss: 2.384438582106312
Validation loss: 2.731752093598555

Epoch: 5| Step: 9
Training loss: 3.0385548773212365
Validation loss: 2.7073592454404993

Epoch: 5| Step: 10
Training loss: 2.6101744563527616
Validation loss: 2.7244537018533777

Epoch: 237| Step: 0
Training loss: 3.077364600121357
Validation loss: 2.729107726875249

Epoch: 5| Step: 1
Training loss: 2.8684235696675646
Validation loss: 2.705017944486285

Epoch: 5| Step: 2
Training loss: 2.4524572155999267
Validation loss: 2.730863529453828

Epoch: 5| Step: 3
Training loss: 2.8155966771063508
Validation loss: 2.743965796320462

Epoch: 5| Step: 4
Training loss: 2.8537886617533803
Validation loss: 2.696314897604474

Epoch: 5| Step: 5
Training loss: 2.985045672247792
Validation loss: 2.721697673656273

Epoch: 5| Step: 6
Training loss: 2.030146137483352
Validation loss: 2.7577966615647997

Epoch: 5| Step: 7
Training loss: 3.214599006764606
Validation loss: 2.6900202054058844

Epoch: 5| Step: 8
Training loss: 2.4428184392280303
Validation loss: 2.729996582660762

Epoch: 5| Step: 9
Training loss: 2.361053173127244
Validation loss: 2.7040912353025472

Epoch: 5| Step: 10
Training loss: 2.390829040197288
Validation loss: 2.741923042705862

Epoch: 238| Step: 0
Training loss: 2.5844350639476246
Validation loss: 2.732108717106739

Epoch: 5| Step: 1
Training loss: 2.558842258178489
Validation loss: 2.7323740914579515

Epoch: 5| Step: 2
Training loss: 2.4227498105019243
Validation loss: 2.7340493247634003

Epoch: 5| Step: 3
Training loss: 2.536088063958319
Validation loss: 2.7302511810024015

Epoch: 5| Step: 4
Training loss: 3.3120766135214095
Validation loss: 2.75164114736672

Epoch: 5| Step: 5
Training loss: 2.8536549872924413
Validation loss: 2.744312737201727

Epoch: 5| Step: 6
Training loss: 2.2706667871092523
Validation loss: 2.760542490144994

Epoch: 5| Step: 7
Training loss: 3.04357935370307
Validation loss: 2.7115956639618797

Epoch: 5| Step: 8
Training loss: 3.0323355392554823
Validation loss: 2.7079648277544015

Epoch: 5| Step: 9
Training loss: 2.522991129130441
Validation loss: 2.740307255655324

Epoch: 5| Step: 10
Training loss: 2.1717892636728
Validation loss: 2.7540203512154755

Epoch: 239| Step: 0
Training loss: 3.089721214285657
Validation loss: 2.731255918410839

Epoch: 5| Step: 1
Training loss: 2.3270399394097545
Validation loss: 2.802137239334652

Epoch: 5| Step: 2
Training loss: 2.4275118295399
Validation loss: 2.7836258923185007

Epoch: 5| Step: 3
Training loss: 2.323788899654762
Validation loss: 2.6623858488081784

Epoch: 5| Step: 4
Training loss: 2.7021597312964203
Validation loss: 2.698691778711372

Epoch: 5| Step: 5
Training loss: 2.783559633142823
Validation loss: 2.720880123033163

Epoch: 5| Step: 6
Training loss: 2.269571589572647
Validation loss: 2.736587076858248

Epoch: 5| Step: 7
Training loss: 2.301540696299153
Validation loss: 2.7680978576123554

Epoch: 5| Step: 8
Training loss: 3.2781057642689624
Validation loss: 2.753778743010269

Epoch: 5| Step: 9
Training loss: 2.569607994670949
Validation loss: 2.7403767235172745

Epoch: 5| Step: 10
Training loss: 3.1023658461541554
Validation loss: 2.6786685368250285

Epoch: 240| Step: 0
Training loss: 2.3501920540431267
Validation loss: 2.741527946317265

Epoch: 5| Step: 1
Training loss: 2.395178951514444
Validation loss: 2.7213993122736455

Epoch: 5| Step: 2
Training loss: 2.7935461767888867
Validation loss: 2.7091162320685536

Epoch: 5| Step: 3
Training loss: 2.5602784179743354
Validation loss: 2.7512633683553283

Epoch: 5| Step: 4
Training loss: 2.7093569850652703
Validation loss: 2.7268840885625982

Epoch: 5| Step: 5
Training loss: 3.570733444140232
Validation loss: 2.7667429528638943

Epoch: 5| Step: 6
Training loss: 2.2058525786540866
Validation loss: 2.7324653315993648

Epoch: 5| Step: 7
Training loss: 2.717848792832203
Validation loss: 2.759449594642131

Epoch: 5| Step: 8
Training loss: 3.080721462021924
Validation loss: 2.774499196658319

Epoch: 5| Step: 9
Training loss: 2.174644625340195
Validation loss: 2.7593980370538223

Epoch: 5| Step: 10
Training loss: 2.9706361902284204
Validation loss: 2.7162439557100417

Epoch: 241| Step: 0
Training loss: 2.858077124706232
Validation loss: 2.6687339670609806

Epoch: 5| Step: 1
Training loss: 3.290774228442755
Validation loss: 2.6909680655971413

Epoch: 5| Step: 2
Training loss: 2.803041703125237
Validation loss: 2.7010645029248797

Epoch: 5| Step: 3
Training loss: 2.2596945129125334
Validation loss: 2.7331740275384115

Epoch: 5| Step: 4
Training loss: 2.6590264563763237
Validation loss: 2.744238980155002

Epoch: 5| Step: 5
Training loss: 2.491193136512744
Validation loss: 2.800486691208985

Epoch: 5| Step: 6
Training loss: 2.2418850684810585
Validation loss: 2.740511284424966

Epoch: 5| Step: 7
Training loss: 3.1292582681779337
Validation loss: 2.7368297428203787

Epoch: 5| Step: 8
Training loss: 2.772597494655617
Validation loss: 2.7722268428927426

Epoch: 5| Step: 9
Training loss: 2.632096914965193
Validation loss: 2.7667245627403236

Epoch: 5| Step: 10
Training loss: 2.4104133357555573
Validation loss: 2.769707275065599

Epoch: 242| Step: 0
Training loss: 2.9867861928467168
Validation loss: 2.7542204674776958

Epoch: 5| Step: 1
Training loss: 2.6052451888544144
Validation loss: 2.6975457297593364

Epoch: 5| Step: 2
Training loss: 2.9798610562697134
Validation loss: 2.7459148835989713

Epoch: 5| Step: 3
Training loss: 2.2625363046673406
Validation loss: 2.686215395355077

Epoch: 5| Step: 4
Training loss: 2.91033140333851
Validation loss: 2.7688593902344985

Epoch: 5| Step: 5
Training loss: 2.224983378144659
Validation loss: 2.6772949804147474

Epoch: 5| Step: 6
Training loss: 2.4615292761016905
Validation loss: 2.7435737786675176

Epoch: 5| Step: 7
Training loss: 2.7692979464167147
Validation loss: 2.778982018718276

Epoch: 5| Step: 8
Training loss: 3.0119008208381346
Validation loss: 2.74454428729467

Epoch: 5| Step: 9
Training loss: 1.8489117540393467
Validation loss: 2.698720337111869

Epoch: 5| Step: 10
Training loss: 3.032875490394285
Validation loss: 2.7825974379005194

Epoch: 243| Step: 0
Training loss: 2.3653542246485504
Validation loss: 2.724974734371813

Epoch: 5| Step: 1
Training loss: 2.9888821265779533
Validation loss: 2.6752872387960194

Epoch: 5| Step: 2
Training loss: 1.9929802009376174
Validation loss: 2.7434027508206036

Epoch: 5| Step: 3
Training loss: 2.919737171467949
Validation loss: 2.697342550260087

Epoch: 5| Step: 4
Training loss: 2.7631473110828058
Validation loss: 2.7375804576699148

Epoch: 5| Step: 5
Training loss: 2.7411439654381184
Validation loss: 2.757789045362698

Epoch: 5| Step: 6
Training loss: 2.618795145961213
Validation loss: 2.7192424968828464

Epoch: 5| Step: 7
Training loss: 2.6387713545563583
Validation loss: 2.7099399512107576

Epoch: 5| Step: 8
Training loss: 2.787243674771058
Validation loss: 2.6963186494358786

Epoch: 5| Step: 9
Training loss: 3.0192869415739674
Validation loss: 2.7365431226855566

Epoch: 5| Step: 10
Training loss: 2.67124521072094
Validation loss: 2.7280123261688773

Epoch: 244| Step: 0
Training loss: 2.725556108618351
Validation loss: 2.7627146675945786

Epoch: 5| Step: 1
Training loss: 2.3042661119998464
Validation loss: 2.6789078504026915

Epoch: 5| Step: 2
Training loss: 3.5665285856191558
Validation loss: 2.692103604691843

Epoch: 5| Step: 3
Training loss: 2.743794201470955
Validation loss: 2.757764556801755

Epoch: 5| Step: 4
Training loss: 2.725630811419608
Validation loss: 2.691582228613922

Epoch: 5| Step: 5
Training loss: 2.6811581682604966
Validation loss: 2.7289504418241863

Epoch: 5| Step: 6
Training loss: 2.3955826559088926
Validation loss: 2.766680975704154

Epoch: 5| Step: 7
Training loss: 2.45800635754948
Validation loss: 2.761928105711556

Epoch: 5| Step: 8
Training loss: 2.9610423368952747
Validation loss: 2.7911281301953696

Epoch: 5| Step: 9
Training loss: 1.8601643145184934
Validation loss: 2.776369280800611

Epoch: 5| Step: 10
Training loss: 2.379327445490635
Validation loss: 2.7087896806608414

Epoch: 245| Step: 0
Training loss: 2.857985528929308
Validation loss: 2.7997453078956718

Epoch: 5| Step: 1
Training loss: 2.775443369869583
Validation loss: 2.753808394658383

Epoch: 5| Step: 2
Training loss: 2.8779250482444794
Validation loss: 2.778981143255488

Epoch: 5| Step: 3
Training loss: 2.8461583597460702
Validation loss: 2.6986646269092165

Epoch: 5| Step: 4
Training loss: 2.759286113962018
Validation loss: 2.7411599468546473

Epoch: 5| Step: 5
Training loss: 2.027148404568419
Validation loss: 2.8004955186559295

Epoch: 5| Step: 6
Training loss: 2.586838210978617
Validation loss: 2.758023098479497

Epoch: 5| Step: 7
Training loss: 2.37738950887788
Validation loss: 2.719482651303221

Epoch: 5| Step: 8
Training loss: 2.782218164529709
Validation loss: 2.721569080622686

Epoch: 5| Step: 9
Training loss: 2.854081219881483
Validation loss: 2.6909074428107895

Epoch: 5| Step: 10
Training loss: 3.025176895896312
Validation loss: 2.741642267207308

Epoch: 246| Step: 0
Training loss: 3.2611783796395017
Validation loss: 2.7704806723678574

Epoch: 5| Step: 1
Training loss: 2.3608533257274043
Validation loss: 2.726426811543012

Epoch: 5| Step: 2
Training loss: 3.0830843713273004
Validation loss: 2.681775356977329

Epoch: 5| Step: 3
Training loss: 2.1223592618510057
Validation loss: 2.692104616966957

Epoch: 5| Step: 4
Training loss: 2.3475028954306265
Validation loss: 2.7253327733888484

Epoch: 5| Step: 5
Training loss: 2.6904910099635764
Validation loss: 2.7425706150125686

Epoch: 5| Step: 6
Training loss: 2.5438816758175493
Validation loss: 2.8062364762229266

Epoch: 5| Step: 7
Training loss: 2.274966535217308
Validation loss: 2.682633681952336

Epoch: 5| Step: 8
Training loss: 2.0867865616760377
Validation loss: 2.7675945892192786

Epoch: 5| Step: 9
Training loss: 3.532758407482347
Validation loss: 2.7069783796227567

Epoch: 5| Step: 10
Training loss: 2.324397950516852
Validation loss: 2.7140872477631333

Epoch: 247| Step: 0
Training loss: 2.578824497465232
Validation loss: 2.7750501580672307

Epoch: 5| Step: 1
Training loss: 2.545053029285441
Validation loss: 2.748338182309086

Epoch: 5| Step: 2
Training loss: 3.073904018941316
Validation loss: 2.7664520916073045

Epoch: 5| Step: 3
Training loss: 2.2522400196018175
Validation loss: 2.7442642293263884

Epoch: 5| Step: 4
Training loss: 2.484719114643407
Validation loss: 2.711926563451301

Epoch: 5| Step: 5
Training loss: 2.470573427919952
Validation loss: 2.8023127413029134

Epoch: 5| Step: 6
Training loss: 2.5254487800245213
Validation loss: 2.781561994042396

Epoch: 5| Step: 7
Training loss: 2.7060082554490386
Validation loss: 2.713863502437977

Epoch: 5| Step: 8
Training loss: 3.351431748478473
Validation loss: 2.7193094285475294

Epoch: 5| Step: 9
Training loss: 3.118276152610674
Validation loss: 2.7223950068849163

Epoch: 5| Step: 10
Training loss: 2.1363776176998615
Validation loss: 2.7357954769732564

Epoch: 248| Step: 0
Training loss: 1.9978409676900677
Validation loss: 2.715948182830021

Epoch: 5| Step: 1
Training loss: 2.969719015887731
Validation loss: 2.7464462364690756

Epoch: 5| Step: 2
Training loss: 2.620264959842388
Validation loss: 2.7384673225895138

Epoch: 5| Step: 3
Training loss: 2.345388526370445
Validation loss: 2.7695024405751236

Epoch: 5| Step: 4
Training loss: 3.1971267735293303
Validation loss: 2.7025106370760636

Epoch: 5| Step: 5
Training loss: 2.8435268104916585
Validation loss: 2.719925367643734

Epoch: 5| Step: 6
Training loss: 2.2589151930237845
Validation loss: 2.7036798853560287

Epoch: 5| Step: 7
Training loss: 2.6421632518591838
Validation loss: 2.7693910980273277

Epoch: 5| Step: 8
Training loss: 2.4456768312915864
Validation loss: 2.7250722713544806

Epoch: 5| Step: 9
Training loss: 2.9598911822137777
Validation loss: 2.6989787625039554

Epoch: 5| Step: 10
Training loss: 3.291449978291441
Validation loss: 2.7543481122481084

Epoch: 249| Step: 0
Training loss: 2.8035941795557564
Validation loss: 2.771590669140939

Epoch: 5| Step: 1
Training loss: 1.9088825121375734
Validation loss: 2.7356376814768337

Epoch: 5| Step: 2
Training loss: 2.7774403229353175
Validation loss: 2.7929376929882914

Epoch: 5| Step: 3
Training loss: 2.6907571970577475
Validation loss: 2.7681340582580956

Epoch: 5| Step: 4
Training loss: 3.851611773502644
Validation loss: 2.7794115295690407

Epoch: 5| Step: 5
Training loss: 2.6746157147329748
Validation loss: 2.7280619800541785

Epoch: 5| Step: 6
Training loss: 2.2025476876161263
Validation loss: 2.713467888869052

Epoch: 5| Step: 7
Training loss: 2.030376657391462
Validation loss: 2.727835132109887

Epoch: 5| Step: 8
Training loss: 2.672441924332168
Validation loss: 2.750287470703286

Epoch: 5| Step: 9
Training loss: 2.6472672209017896
Validation loss: 2.7261647072550117

Epoch: 5| Step: 10
Training loss: 2.6776071374937676
Validation loss: 2.7298721858172397

Epoch: 250| Step: 0
Training loss: 2.680364317542647
Validation loss: 2.7396657079705684

Epoch: 5| Step: 1
Training loss: 3.3433794903698826
Validation loss: 2.6988846377516165

Epoch: 5| Step: 2
Training loss: 2.7771193444525424
Validation loss: 2.749096529039272

Epoch: 5| Step: 3
Training loss: 2.321364860918008
Validation loss: 2.7330469040544707

Epoch: 5| Step: 4
Training loss: 2.5030761866387854
Validation loss: 2.7211396744508765

Epoch: 5| Step: 5
Training loss: 2.3851269097621173
Validation loss: 2.7094026850862902

Epoch: 5| Step: 6
Training loss: 2.6207179611679936
Validation loss: 2.7459521749233287

Epoch: 5| Step: 7
Training loss: 2.7871786642249963
Validation loss: 2.7824079760587686

Epoch: 5| Step: 8
Training loss: 2.7000597735252327
Validation loss: 2.7855613193135764

Epoch: 5| Step: 9
Training loss: 2.1797756601094895
Validation loss: 2.734886680812981

Epoch: 5| Step: 10
Training loss: 2.9654596666530297
Validation loss: 2.763758281564509

Epoch: 251| Step: 0
Training loss: 2.6452569909532904
Validation loss: 2.76152653608401

Epoch: 5| Step: 1
Training loss: 2.7604357640787405
Validation loss: 2.7108979425147464

Epoch: 5| Step: 2
Training loss: 2.675638860547655
Validation loss: 2.7306882581763676

Epoch: 5| Step: 3
Training loss: 3.018248370649558
Validation loss: 2.7841583720854413

Epoch: 5| Step: 4
Training loss: 3.042879742359997
Validation loss: 2.730402912508804

Epoch: 5| Step: 5
Training loss: 2.5963171698339385
Validation loss: 2.7598996321145446

Epoch: 5| Step: 6
Training loss: 2.332070406228799
Validation loss: 2.7320142520780886

Epoch: 5| Step: 7
Training loss: 2.211865449417506
Validation loss: 2.771416345498335

Epoch: 5| Step: 8
Training loss: 2.6278885888125436
Validation loss: 2.7237787694365623

Epoch: 5| Step: 9
Training loss: 2.6016534096353396
Validation loss: 2.7571503529514647

Epoch: 5| Step: 10
Training loss: 2.8177959172333185
Validation loss: 2.745810360066809

Epoch: 252| Step: 0
Training loss: 2.2703488267590104
Validation loss: 2.7621915164031567

Epoch: 5| Step: 1
Training loss: 2.1365759207290207
Validation loss: 2.691680476549034

Epoch: 5| Step: 2
Training loss: 2.8937118956197203
Validation loss: 2.7137902356403347

Epoch: 5| Step: 3
Training loss: 2.9654218791061657
Validation loss: 2.7868740565583767

Epoch: 5| Step: 4
Training loss: 2.2350569531312248
Validation loss: 2.6958012011056733

Epoch: 5| Step: 5
Training loss: 3.4183147146336963
Validation loss: 2.745773729720662

Epoch: 5| Step: 6
Training loss: 2.9439428570011485
Validation loss: 2.7223790772818437

Epoch: 5| Step: 7
Training loss: 1.8963331325265143
Validation loss: 2.7109550571727166

Epoch: 5| Step: 8
Training loss: 2.8156013343824133
Validation loss: 2.738775235099034

Epoch: 5| Step: 9
Training loss: 2.51544473132488
Validation loss: 2.6925173468568993

Epoch: 5| Step: 10
Training loss: 2.6525773632333953
Validation loss: 2.726451713214539

Epoch: 253| Step: 0
Training loss: 2.6075303187303778
Validation loss: 2.692313394621605

Epoch: 5| Step: 1
Training loss: 3.697416517077409
Validation loss: 2.685649970528463

Epoch: 5| Step: 2
Training loss: 2.3331067338540636
Validation loss: 2.7175161475367586

Epoch: 5| Step: 3
Training loss: 1.5963686205493268
Validation loss: 2.6530879078019014

Epoch: 5| Step: 4
Training loss: 2.0445419876813706
Validation loss: 2.6330345412910656

Epoch: 5| Step: 5
Training loss: 2.2812204228404207
Validation loss: 2.703925670522713

Epoch: 5| Step: 6
Training loss: 3.11349490400626
Validation loss: 2.704534084303343

Epoch: 5| Step: 7
Training loss: 2.503835691984367
Validation loss: 2.7079760944530755

Epoch: 5| Step: 8
Training loss: 2.844366656504703
Validation loss: 2.7563276551409444

Epoch: 5| Step: 9
Training loss: 2.5770381601784855
Validation loss: 2.7255366815288755

Epoch: 5| Step: 10
Training loss: 2.7360187058785317
Validation loss: 2.7317725266162265

Epoch: 254| Step: 0
Training loss: 2.8610429745392927
Validation loss: 2.708121051151907

Epoch: 5| Step: 1
Training loss: 3.1345590493656297
Validation loss: 2.7878285046744153

Epoch: 5| Step: 2
Training loss: 2.5980233528197694
Validation loss: 2.741932209225267

Epoch: 5| Step: 3
Training loss: 2.952215145365657
Validation loss: 2.735789298842641

Epoch: 5| Step: 4
Training loss: 2.2345243817525207
Validation loss: 2.7096401220334028

Epoch: 5| Step: 5
Training loss: 2.909168050024978
Validation loss: 2.7166809791924234

Epoch: 5| Step: 6
Training loss: 2.456506718622295
Validation loss: 2.7085677361789076

Epoch: 5| Step: 7
Training loss: 2.6636788995384166
Validation loss: 2.7004616746381513

Epoch: 5| Step: 8
Training loss: 2.257290578530024
Validation loss: 2.74409806518459

Epoch: 5| Step: 9
Training loss: 2.455458873276201
Validation loss: 2.7924593865378085

Epoch: 5| Step: 10
Training loss: 2.700535322032136
Validation loss: 2.737894105845472

Epoch: 255| Step: 0
Training loss: 3.4005597383097794
Validation loss: 2.7847790480125147

Epoch: 5| Step: 1
Training loss: 2.4173220261051416
Validation loss: 2.764677198286826

Epoch: 5| Step: 2
Training loss: 2.2759801534782986
Validation loss: 2.6849591510789717

Epoch: 5| Step: 3
Training loss: 3.026158412097328
Validation loss: 2.7126364168807062

Epoch: 5| Step: 4
Training loss: 2.2930445487964013
Validation loss: 2.6886865181572053

Epoch: 5| Step: 5
Training loss: 2.577551575671017
Validation loss: 2.7753063578597343

Epoch: 5| Step: 6
Training loss: 2.9416808548568034
Validation loss: 2.733094536071643

Epoch: 5| Step: 7
Training loss: 2.4045864150902787
Validation loss: 2.721777746638049

Epoch: 5| Step: 8
Training loss: 2.5090064893374824
Validation loss: 2.791934997000172

Epoch: 5| Step: 9
Training loss: 2.799647826799214
Validation loss: 2.8023706183596664

Epoch: 5| Step: 10
Training loss: 2.3655806019495653
Validation loss: 2.696896165752292

Epoch: 256| Step: 0
Training loss: 2.7102518671256473
Validation loss: 2.7254401384848546

Epoch: 5| Step: 1
Training loss: 2.6810411420807747
Validation loss: 2.7434849357105207

Epoch: 5| Step: 2
Training loss: 2.700657241794799
Validation loss: 2.7494491778747188

Epoch: 5| Step: 3
Training loss: 3.702937769281162
Validation loss: 2.7575205052497282

Epoch: 5| Step: 4
Training loss: 2.0137990324940387
Validation loss: 2.7781777497625257

Epoch: 5| Step: 5
Training loss: 2.6450247142192387
Validation loss: 2.7466823687056294

Epoch: 5| Step: 6
Training loss: 2.7099441335346124
Validation loss: 2.779415186756299

Epoch: 5| Step: 7
Training loss: 2.8495258740014986
Validation loss: 2.761939869780342

Epoch: 5| Step: 8
Training loss: 1.9376460604833865
Validation loss: 2.758779056177733

Epoch: 5| Step: 9
Training loss: 2.4248552259508793
Validation loss: 2.7264948559527946

Epoch: 5| Step: 10
Training loss: 3.008000197065631
Validation loss: 2.7174199780435595

Epoch: 257| Step: 0
Training loss: 2.895184359568681
Validation loss: 2.740936555834263

Epoch: 5| Step: 1
Training loss: 2.6488403194019092
Validation loss: 2.70965006855889

Epoch: 5| Step: 2
Training loss: 2.5496801362724395
Validation loss: 2.6928344996588978

Epoch: 5| Step: 3
Training loss: 3.0701730322768643
Validation loss: 2.7311619955315165

Epoch: 5| Step: 4
Training loss: 2.6187036478315022
Validation loss: 2.7781170580064436

Epoch: 5| Step: 5
Training loss: 2.6023324737716798
Validation loss: 2.707395132356014

Epoch: 5| Step: 6
Training loss: 2.5797784300593456
Validation loss: 2.72800941295249

Epoch: 5| Step: 7
Training loss: 2.764304842764797
Validation loss: 2.707437261637534

Epoch: 5| Step: 8
Training loss: 2.2588553478709037
Validation loss: 2.6992704189664414

Epoch: 5| Step: 9
Training loss: 2.829426334320732
Validation loss: 2.7223714203792855

Epoch: 5| Step: 10
Training loss: 2.2837804059623315
Validation loss: 2.7069338537570675

Epoch: 258| Step: 0
Training loss: 2.7955739495545417
Validation loss: 2.73857230986473

Epoch: 5| Step: 1
Training loss: 3.323500307939658
Validation loss: 2.7196395111011844

Epoch: 5| Step: 2
Training loss: 2.423421157004603
Validation loss: 2.7938065063902147

Epoch: 5| Step: 3
Training loss: 2.430941439075076
Validation loss: 2.81003049769759

Epoch: 5| Step: 4
Training loss: 2.8646862959419686
Validation loss: 2.7586355551306583

Epoch: 5| Step: 5
Training loss: 2.7511439111716434
Validation loss: 2.778922587176221

Epoch: 5| Step: 6
Training loss: 2.4522991369588065
Validation loss: 2.785430838979069

Epoch: 5| Step: 7
Training loss: 2.7192370975907596
Validation loss: 2.763808866414833

Epoch: 5| Step: 8
Training loss: 2.2436299751503292
Validation loss: 2.7200340555072007

Epoch: 5| Step: 9
Training loss: 2.8220397225226304
Validation loss: 2.792652213903715

Epoch: 5| Step: 10
Training loss: 2.558979407212349
Validation loss: 2.724098770554825

Epoch: 259| Step: 0
Training loss: 2.5761548461813986
Validation loss: 2.766924595908314

Epoch: 5| Step: 1
Training loss: 3.058746684843885
Validation loss: 2.7472346768831217

Epoch: 5| Step: 2
Training loss: 2.447432991022315
Validation loss: 2.74572216649621

Epoch: 5| Step: 3
Training loss: 2.225104031648893
Validation loss: 2.733061791259535

Epoch: 5| Step: 4
Training loss: 3.0372858419392355
Validation loss: 2.7342504179388607

Epoch: 5| Step: 5
Training loss: 2.456769435014961
Validation loss: 2.77919234043048

Epoch: 5| Step: 6
Training loss: 2.804337928685079
Validation loss: 2.771682504277391

Epoch: 5| Step: 7
Training loss: 2.943707663845149
Validation loss: 2.7816693869013136

Epoch: 5| Step: 8
Training loss: 2.5061385132305753
Validation loss: 2.7450522271310724

Epoch: 5| Step: 9
Training loss: 2.2448588019744142
Validation loss: 2.7845899311656206

Epoch: 5| Step: 10
Training loss: 2.934023971605309
Validation loss: 2.7616055832606468

Epoch: 260| Step: 0
Training loss: 2.0661300157256135
Validation loss: 2.722371592709269

Epoch: 5| Step: 1
Training loss: 2.508877917090138
Validation loss: 2.735479861883115

Epoch: 5| Step: 2
Training loss: 1.9845254195265603
Validation loss: 2.759370298960772

Epoch: 5| Step: 3
Training loss: 3.608290472209234
Validation loss: 2.755663806997776

Epoch: 5| Step: 4
Training loss: 2.785340975805559
Validation loss: 2.706828681161449

Epoch: 5| Step: 5
Training loss: 2.485684991140894
Validation loss: 2.7462172346787255

Epoch: 5| Step: 6
Training loss: 2.4176758818370794
Validation loss: 2.6829023676510104

Epoch: 5| Step: 7
Training loss: 2.68588066107508
Validation loss: 2.707434349007591

Epoch: 5| Step: 8
Training loss: 3.036163752003421
Validation loss: 2.7637877584323727

Epoch: 5| Step: 9
Training loss: 2.6317884678001016
Validation loss: 2.7432159074428126

Epoch: 5| Step: 10
Training loss: 2.6456259598652525
Validation loss: 2.7693851735056416

Epoch: 261| Step: 0
Training loss: 2.7337917904827607
Validation loss: 2.7459561250124183

Epoch: 5| Step: 1
Training loss: 2.611875603633098
Validation loss: 2.752702389226222

Epoch: 5| Step: 2
Training loss: 2.2174995014658885
Validation loss: 2.729844363707144

Epoch: 5| Step: 3
Training loss: 2.89367069934918
Validation loss: 2.7182220608346

Epoch: 5| Step: 4
Training loss: 2.4491507050767574
Validation loss: 2.7235981033973773

Epoch: 5| Step: 5
Training loss: 2.2310421502249396
Validation loss: 2.7409550507019347

Epoch: 5| Step: 6
Training loss: 3.309139778631892
Validation loss: 2.708493443024703

Epoch: 5| Step: 7
Training loss: 2.289553644915169
Validation loss: 2.7799966478419784

Epoch: 5| Step: 8
Training loss: 2.828351175105464
Validation loss: 2.7035886324362277

Epoch: 5| Step: 9
Training loss: 2.8802392738340563
Validation loss: 2.7286271979967056

Epoch: 5| Step: 10
Training loss: 2.788867334541762
Validation loss: 2.7466962421183707

Epoch: 262| Step: 0
Training loss: 2.5500131943305244
Validation loss: 2.715539932726429

Epoch: 5| Step: 1
Training loss: 3.6844980984508315
Validation loss: 2.7199583686246087

Epoch: 5| Step: 2
Training loss: 2.9662109760815167
Validation loss: 2.7493282217278994

Epoch: 5| Step: 3
Training loss: 2.0766589507586732
Validation loss: 2.6835414047092883

Epoch: 5| Step: 4
Training loss: 2.555681321140856
Validation loss: 2.710448856021843

Epoch: 5| Step: 5
Training loss: 2.3670785205292777
Validation loss: 2.7133428721902604

Epoch: 5| Step: 6
Training loss: 2.580164801782613
Validation loss: 2.7579977847154975

Epoch: 5| Step: 7
Training loss: 2.749145895363085
Validation loss: 2.805118308445164

Epoch: 5| Step: 8
Training loss: 2.126028373062412
Validation loss: 2.7575651737277114

Epoch: 5| Step: 9
Training loss: 2.5060370985057094
Validation loss: 2.72328148889796

Epoch: 5| Step: 10
Training loss: 2.520598145750254
Validation loss: 2.7371886719084366

Epoch: 263| Step: 0
Training loss: 2.4611980966313576
Validation loss: 2.768888594291148

Epoch: 5| Step: 1
Training loss: 3.4683566858500527
Validation loss: 2.749713936896026

Epoch: 5| Step: 2
Training loss: 3.0551782394333444
Validation loss: 2.817829089384092

Epoch: 5| Step: 3
Training loss: 2.7591431085043028
Validation loss: 2.790855400647271

Epoch: 5| Step: 4
Training loss: 2.271921602844212
Validation loss: 2.7232335176725635

Epoch: 5| Step: 5
Training loss: 2.8057470843801244
Validation loss: 2.7557732640508106

Epoch: 5| Step: 6
Training loss: 2.027987868458956
Validation loss: 2.740086104193774

Epoch: 5| Step: 7
Training loss: 2.2357977758824954
Validation loss: 2.738934821985508

Epoch: 5| Step: 8
Training loss: 3.161471287775705
Validation loss: 2.7838384757795986

Epoch: 5| Step: 9
Training loss: 2.6146637092384264
Validation loss: 2.793497418899448

Epoch: 5| Step: 10
Training loss: 2.019051884143708
Validation loss: 2.8110533818883665

Epoch: 264| Step: 0
Training loss: 2.4647371538088443
Validation loss: 2.7236709858839205

Epoch: 5| Step: 1
Training loss: 2.918978964342652
Validation loss: 2.718752632710322

Epoch: 5| Step: 2
Training loss: 3.4537847242566797
Validation loss: 2.752878912054584

Epoch: 5| Step: 3
Training loss: 2.4584183651286264
Validation loss: 2.6986258912775583

Epoch: 5| Step: 4
Training loss: 2.883062749819534
Validation loss: 2.7708165764022463

Epoch: 5| Step: 5
Training loss: 2.6369001312034777
Validation loss: 2.7528856729796924

Epoch: 5| Step: 6
Training loss: 2.3980523710410018
Validation loss: 2.764196286505873

Epoch: 5| Step: 7
Training loss: 2.807265518057259
Validation loss: 2.74152953414005

Epoch: 5| Step: 8
Training loss: 2.1698674865553897
Validation loss: 2.7143010338650018

Epoch: 5| Step: 9
Training loss: 2.5154000886635477
Validation loss: 2.7344624241976625

Epoch: 5| Step: 10
Training loss: 2.4333709565829267
Validation loss: 2.7297045069634884

Epoch: 265| Step: 0
Training loss: 2.870929324054464
Validation loss: 2.7428938363198117

Epoch: 5| Step: 1
Training loss: 1.8791715628933046
Validation loss: 2.762051650995274

Epoch: 5| Step: 2
Training loss: 2.633008276115418
Validation loss: 2.7088360271795313

Epoch: 5| Step: 3
Training loss: 2.678751167443075
Validation loss: 2.761741375736559

Epoch: 5| Step: 4
Training loss: 3.1419380441794065
Validation loss: 2.7262967301568857

Epoch: 5| Step: 5
Training loss: 2.7992451603990633
Validation loss: 2.7258953737241045

Epoch: 5| Step: 6
Training loss: 2.7774637574613337
Validation loss: 2.682011799598574

Epoch: 5| Step: 7
Training loss: 2.3663143146397405
Validation loss: 2.7735709754892417

Epoch: 5| Step: 8
Training loss: 2.30648412989183
Validation loss: 2.763641925659491

Epoch: 5| Step: 9
Training loss: 2.7361854880906806
Validation loss: 2.7053699009532957

Epoch: 5| Step: 10
Training loss: 3.0631092010570073
Validation loss: 2.713985684940309

Epoch: 266| Step: 0
Training loss: 2.3902625513512294
Validation loss: 2.707211623906223

Epoch: 5| Step: 1
Training loss: 2.8262112712948224
Validation loss: 2.6572282971749512

Epoch: 5| Step: 2
Training loss: 1.8909045556570898
Validation loss: 2.7136396885941725

Epoch: 5| Step: 3
Training loss: 3.325303435283244
Validation loss: 2.731978519647305

Epoch: 5| Step: 4
Training loss: 2.1848371374333957
Validation loss: 2.7111153464620736

Epoch: 5| Step: 5
Training loss: 2.8879033653280617
Validation loss: 2.798872817533171

Epoch: 5| Step: 6
Training loss: 2.223110588312289
Validation loss: 2.711235524351956

Epoch: 5| Step: 7
Training loss: 3.0265041048307895
Validation loss: 2.7586813820469285

Epoch: 5| Step: 8
Training loss: 2.514459375477706
Validation loss: 2.780743712205659

Epoch: 5| Step: 9
Training loss: 2.9291894107838172
Validation loss: 2.699562125588767

Epoch: 5| Step: 10
Training loss: 2.551130799532482
Validation loss: 2.7102509221664453

Epoch: 267| Step: 0
Training loss: 1.8364351937200623
Validation loss: 2.801010294781399

Epoch: 5| Step: 1
Training loss: 3.136011787450786
Validation loss: 2.7462807121715747

Epoch: 5| Step: 2
Training loss: 2.9248708777986137
Validation loss: 2.84714834812896

Epoch: 5| Step: 3
Training loss: 2.3056419335950995
Validation loss: 2.7499584137055204

Epoch: 5| Step: 4
Training loss: 2.015516529565294
Validation loss: 2.7527778146873043

Epoch: 5| Step: 5
Training loss: 2.6558339410196052
Validation loss: 2.754465152995141

Epoch: 5| Step: 6
Training loss: 2.7524541827831235
Validation loss: 2.7177230390893072

Epoch: 5| Step: 7
Training loss: 2.7390462157858333
Validation loss: 2.734959849263315

Epoch: 5| Step: 8
Training loss: 2.8451737413502953
Validation loss: 2.7257305380013404

Epoch: 5| Step: 9
Training loss: 2.5397653399226785
Validation loss: 2.7389794467849344

Epoch: 5| Step: 10
Training loss: 2.9317998569660504
Validation loss: 2.7161994826296993

Epoch: 268| Step: 0
Training loss: 2.536342255262021
Validation loss: 2.7047343691555157

Epoch: 5| Step: 1
Training loss: 2.1790238877659394
Validation loss: 2.765338094670399

Epoch: 5| Step: 2
Training loss: 2.783120715611088
Validation loss: 2.6827263815636435

Epoch: 5| Step: 3
Training loss: 2.9764799972674605
Validation loss: 2.702875817582308

Epoch: 5| Step: 4
Training loss: 3.0183308375527482
Validation loss: 2.7357977212626614

Epoch: 5| Step: 5
Training loss: 2.247928407465761
Validation loss: 2.7338392079067866

Epoch: 5| Step: 6
Training loss: 3.010808389030518
Validation loss: 2.6857321014217654

Epoch: 5| Step: 7
Training loss: 2.3101741332109222
Validation loss: 2.6706448390299427

Epoch: 5| Step: 8
Training loss: 2.564791515421502
Validation loss: 2.7280708210160753

Epoch: 5| Step: 9
Training loss: 2.699761122273615
Validation loss: 2.7158382850713623

Epoch: 5| Step: 10
Training loss: 2.696741582193743
Validation loss: 2.8182080644771017

Epoch: 269| Step: 0
Training loss: 2.370590533632794
Validation loss: 2.7658785794191307

Epoch: 5| Step: 1
Training loss: 3.1858459369697156
Validation loss: 2.7323842779820384

Epoch: 5| Step: 2
Training loss: 2.9370840873903097
Validation loss: 2.7339843189634085

Epoch: 5| Step: 3
Training loss: 2.6089315437351437
Validation loss: 2.7217868293581318

Epoch: 5| Step: 4
Training loss: 2.1987557880960846
Validation loss: 2.7021806755473032

Epoch: 5| Step: 5
Training loss: 2.6007771724303423
Validation loss: 2.7462123654494306

Epoch: 5| Step: 6
Training loss: 3.0242913984650337
Validation loss: 2.737715768432412

Epoch: 5| Step: 7
Training loss: 2.8119107794790517
Validation loss: 2.783230918482122

Epoch: 5| Step: 8
Training loss: 2.443336248860131
Validation loss: 2.7898735350957615

Epoch: 5| Step: 9
Training loss: 2.574354338946209
Validation loss: 2.7879464231104607

Epoch: 5| Step: 10
Training loss: 2.0546508321644965
Validation loss: 2.727967966004039

Epoch: 270| Step: 0
Training loss: 2.9109300237570896
Validation loss: 2.7687480440491425

Epoch: 5| Step: 1
Training loss: 2.6801268993054443
Validation loss: 2.739092149562265

Epoch: 5| Step: 2
Training loss: 3.2885414127562824
Validation loss: 2.791993501461014

Epoch: 5| Step: 3
Training loss: 2.8451720653988706
Validation loss: 2.706667163863632

Epoch: 5| Step: 4
Training loss: 2.3656503451764688
Validation loss: 2.679876032857761

Epoch: 5| Step: 5
Training loss: 2.1468843151706682
Validation loss: 2.7265513260886225

Epoch: 5| Step: 6
Training loss: 2.6895037433678355
Validation loss: 2.753047997247735

Epoch: 5| Step: 7
Training loss: 3.0266810325528097
Validation loss: 2.7962318662205736

Epoch: 5| Step: 8
Training loss: 2.3079062533851027
Validation loss: 2.7131331161836965

Epoch: 5| Step: 9
Training loss: 2.441179872317144
Validation loss: 2.7563164158760687

Epoch: 5| Step: 10
Training loss: 2.082541111681121
Validation loss: 2.7671736509811837

Epoch: 271| Step: 0
Training loss: 2.8267461460863554
Validation loss: 2.7718997651457795

Epoch: 5| Step: 1
Training loss: 2.5091706873281803
Validation loss: 2.7737414288117233

Epoch: 5| Step: 2
Training loss: 2.6057126961908774
Validation loss: 2.6832615320021644

Epoch: 5| Step: 3
Training loss: 2.924576596646653
Validation loss: 2.8068994515258288

Epoch: 5| Step: 4
Training loss: 2.942696216299491
Validation loss: 2.744531891944297

Epoch: 5| Step: 5
Training loss: 2.292864457574168
Validation loss: 2.7700091263472006

Epoch: 5| Step: 6
Training loss: 2.544231985856963
Validation loss: 2.738095745731068

Epoch: 5| Step: 7
Training loss: 2.4647568870267906
Validation loss: 2.7935421783619643

Epoch: 5| Step: 8
Training loss: 2.3647009754464916
Validation loss: 2.7783374032600503

Epoch: 5| Step: 9
Training loss: 3.0853530523493746
Validation loss: 2.772711908476905

Epoch: 5| Step: 10
Training loss: 2.456190198796415
Validation loss: 2.7341405455691072

Epoch: 272| Step: 0
Training loss: 3.351098373039224
Validation loss: 2.6985795788799694

Epoch: 5| Step: 1
Training loss: 2.9265487743896967
Validation loss: 2.7826254728252544

Epoch: 5| Step: 2
Training loss: 1.9148745935478104
Validation loss: 2.7550160954116176

Epoch: 5| Step: 3
Training loss: 2.5474997848196193
Validation loss: 2.682907368981935

Epoch: 5| Step: 4
Training loss: 2.475789042611346
Validation loss: 2.7545051057980756

Epoch: 5| Step: 5
Training loss: 2.038566441321242
Validation loss: 2.709985058666141

Epoch: 5| Step: 6
Training loss: 2.527761056399903
Validation loss: 2.785742208334959

Epoch: 5| Step: 7
Training loss: 3.022242110162011
Validation loss: 2.768005107041522

Epoch: 5| Step: 8
Training loss: 2.807295837587975
Validation loss: 2.757544565535072

Epoch: 5| Step: 9
Training loss: 2.849933148319472
Validation loss: 2.7233880537661195

Epoch: 5| Step: 10
Training loss: 1.9081666409958986
Validation loss: 2.708671950634761

Epoch: 273| Step: 0
Training loss: 2.808578639725956
Validation loss: 2.7892431628806533

Epoch: 5| Step: 1
Training loss: 2.5368892817954
Validation loss: 2.7128873685801316

Epoch: 5| Step: 2
Training loss: 2.8553042592734146
Validation loss: 2.718577585869568

Epoch: 5| Step: 3
Training loss: 2.826960202606606
Validation loss: 2.762069449436667

Epoch: 5| Step: 4
Training loss: 3.0938833188702657
Validation loss: 2.7307556988349706

Epoch: 5| Step: 5
Training loss: 2.010711951304051
Validation loss: 2.759718867630568

Epoch: 5| Step: 6
Training loss: 2.224047287554892
Validation loss: 2.8064862199525344

Epoch: 5| Step: 7
Training loss: 2.838065365834965
Validation loss: 2.756525108640074

Epoch: 5| Step: 8
Training loss: 2.1409480832614665
Validation loss: 2.752552185924454

Epoch: 5| Step: 9
Training loss: 2.241007530938516
Validation loss: 2.7731608711416906

Epoch: 5| Step: 10
Training loss: 3.118453072458284
Validation loss: 2.7785815980879773

Epoch: 274| Step: 0
Training loss: 2.3242546527557892
Validation loss: 2.695076595503035

Epoch: 5| Step: 1
Training loss: 2.6948571746574954
Validation loss: 2.777263409835545

Epoch: 5| Step: 2
Training loss: 2.9191410105023663
Validation loss: 2.733973981805438

Epoch: 5| Step: 3
Training loss: 2.7295292232505246
Validation loss: 2.754622222704146

Epoch: 5| Step: 4
Training loss: 2.9043999803066844
Validation loss: 2.768384317650897

Epoch: 5| Step: 5
Training loss: 2.2402522544513195
Validation loss: 2.707617455110708

Epoch: 5| Step: 6
Training loss: 2.2803362753989043
Validation loss: 2.76732394352339

Epoch: 5| Step: 7
Training loss: 2.128489602290917
Validation loss: 2.766467389346502

Epoch: 5| Step: 8
Training loss: 2.69778558910977
Validation loss: 2.7190633000877935

Epoch: 5| Step: 9
Training loss: 2.2444574117548215
Validation loss: 2.771170646890907

Epoch: 5| Step: 10
Training loss: 3.3741715438730897
Validation loss: 2.7346546926592

Epoch: 275| Step: 0
Training loss: 2.139117524558787
Validation loss: 2.791493129586196

Epoch: 5| Step: 1
Training loss: 2.683966687093787
Validation loss: 2.744137054395493

Epoch: 5| Step: 2
Training loss: 2.9523928102937815
Validation loss: 2.8146013337841853

Epoch: 5| Step: 3
Training loss: 2.6465905875538556
Validation loss: 2.75597008100454

Epoch: 5| Step: 4
Training loss: 3.002701973073439
Validation loss: 2.76106161863011

Epoch: 5| Step: 5
Training loss: 2.2688075370953924
Validation loss: 2.7475138647591115

Epoch: 5| Step: 6
Training loss: 2.0907276031451296
Validation loss: 2.690663030518859

Epoch: 5| Step: 7
Training loss: 2.5202250626893754
Validation loss: 2.7373055191620903

Epoch: 5| Step: 8
Training loss: 2.5311573152880738
Validation loss: 2.730895768350456

Epoch: 5| Step: 9
Training loss: 2.8049267000082967
Validation loss: 2.8080773075080985

Epoch: 5| Step: 10
Training loss: 2.9755244009267097
Validation loss: 2.7320398338054677

Epoch: 276| Step: 0
Training loss: 2.3078878649968897
Validation loss: 2.733224957066102

Epoch: 5| Step: 1
Training loss: 3.2626966278338414
Validation loss: 2.7556118110951764

Epoch: 5| Step: 2
Training loss: 2.562588108687937
Validation loss: 2.7588017599205847

Epoch: 5| Step: 3
Training loss: 3.2807817397462666
Validation loss: 2.715441620007586

Epoch: 5| Step: 4
Training loss: 2.5564481401948798
Validation loss: 2.6773018843328007

Epoch: 5| Step: 5
Training loss: 2.771124678665811
Validation loss: 2.663973874085539

Epoch: 5| Step: 6
Training loss: 1.9614745236817663
Validation loss: 2.7367189660536417

Epoch: 5| Step: 7
Training loss: 1.7510734399397354
Validation loss: 2.7364463908538865

Epoch: 5| Step: 8
Training loss: 2.1767211199030037
Validation loss: 2.7485524364142444

Epoch: 5| Step: 9
Training loss: 2.2943085325667605
Validation loss: 2.7568010317506983

Epoch: 5| Step: 10
Training loss: 3.446117073625305
Validation loss: 2.7862606321545376

Epoch: 277| Step: 0
Training loss: 2.33298635173522
Validation loss: 2.7854027453138843

Epoch: 5| Step: 1
Training loss: 3.18970204005156
Validation loss: 2.759154445893317

Epoch: 5| Step: 2
Training loss: 2.747428385223825
Validation loss: 2.706096192499536

Epoch: 5| Step: 3
Training loss: 2.624484511123508
Validation loss: 2.7353903820956593

Epoch: 5| Step: 4
Training loss: 3.1814406901767485
Validation loss: 2.753027017212641

Epoch: 5| Step: 5
Training loss: 2.457450988529161
Validation loss: 2.7199018728277053

Epoch: 5| Step: 6
Training loss: 2.8687428925203857
Validation loss: 2.746378340061205

Epoch: 5| Step: 7
Training loss: 2.0791938728993733
Validation loss: 2.70754279690866

Epoch: 5| Step: 8
Training loss: 2.48542485157167
Validation loss: 2.7871807779194007

Epoch: 5| Step: 9
Training loss: 1.991547246036865
Validation loss: 2.6851982529706904

Epoch: 5| Step: 10
Training loss: 2.709463548808243
Validation loss: 2.7500881747730017

Epoch: 278| Step: 0
Training loss: 2.8066261837985294
Validation loss: 2.71433416839603

Epoch: 5| Step: 1
Training loss: 2.2637064209508058
Validation loss: 2.7325895381547176

Epoch: 5| Step: 2
Training loss: 2.2896249750554576
Validation loss: 2.7487288144469098

Epoch: 5| Step: 3
Training loss: 2.7411364853400144
Validation loss: 2.774895541771057

Epoch: 5| Step: 4
Training loss: 2.6897936946788468
Validation loss: 2.7063826658355405

Epoch: 5| Step: 5
Training loss: 2.4891533154373366
Validation loss: 2.7871326849963314

Epoch: 5| Step: 6
Training loss: 3.1545136462859835
Validation loss: 2.7663617342504905

Epoch: 5| Step: 7
Training loss: 2.557547085832916
Validation loss: 2.7061221736553844

Epoch: 5| Step: 8
Training loss: 3.243351077207334
Validation loss: 2.752053023964743

Epoch: 5| Step: 9
Training loss: 2.317226837091823
Validation loss: 2.7813307826574443

Epoch: 5| Step: 10
Training loss: 2.099592114754636
Validation loss: 2.742955439221911

Epoch: 279| Step: 0
Training loss: 2.542141593795289
Validation loss: 2.7701482531157517

Epoch: 5| Step: 1
Training loss: 2.669027495418747
Validation loss: 2.7991987762870085

Epoch: 5| Step: 2
Training loss: 2.535427084916797
Validation loss: 2.7429254291144582

Epoch: 5| Step: 3
Training loss: 2.8718413540900065
Validation loss: 2.7636327829106913

Epoch: 5| Step: 4
Training loss: 2.5423101225612394
Validation loss: 2.8090570156101045

Epoch: 5| Step: 5
Training loss: 2.4918720679532598
Validation loss: 2.800384476446235

Epoch: 5| Step: 6
Training loss: 2.444805641172302
Validation loss: 2.7595682008451843

Epoch: 5| Step: 7
Training loss: 2.8302417231333346
Validation loss: 2.7684532309997665

Epoch: 5| Step: 8
Training loss: 2.3901178158566863
Validation loss: 2.7402152484418694

Epoch: 5| Step: 9
Training loss: 3.028165368597421
Validation loss: 2.678921002040873

Epoch: 5| Step: 10
Training loss: 2.397084802151575
Validation loss: 2.69015858879695

Epoch: 280| Step: 0
Training loss: 2.873687776387203
Validation loss: 2.702548287321231

Epoch: 5| Step: 1
Training loss: 2.2695346116584396
Validation loss: 2.7348172891008415

Epoch: 5| Step: 2
Training loss: 2.3369402822194476
Validation loss: 2.7456718273213565

Epoch: 5| Step: 3
Training loss: 2.7662268377093686
Validation loss: 2.778810984584642

Epoch: 5| Step: 4
Training loss: 2.1907653415364337
Validation loss: 2.7541609595762773

Epoch: 5| Step: 5
Training loss: 2.461313854685312
Validation loss: 2.7099271241790635

Epoch: 5| Step: 6
Training loss: 2.2933733971371275
Validation loss: 2.793468296827674

Epoch: 5| Step: 7
Training loss: 2.984460160403493
Validation loss: 2.762238136322626

Epoch: 5| Step: 8
Training loss: 2.7011498086928585
Validation loss: 2.798947575839199

Epoch: 5| Step: 9
Training loss: 3.2356815371364385
Validation loss: 2.7884331699757365

Epoch: 5| Step: 10
Training loss: 2.261228834467532
Validation loss: 2.760640100285265

Epoch: 281| Step: 0
Training loss: 2.3566950046430843
Validation loss: 2.761559869853404

Epoch: 5| Step: 1
Training loss: 2.4951825456214864
Validation loss: 2.7605084410766443

Epoch: 5| Step: 2
Training loss: 2.3258547370533558
Validation loss: 2.7476917854909697

Epoch: 5| Step: 3
Training loss: 2.366342425186195
Validation loss: 2.736350273008787

Epoch: 5| Step: 4
Training loss: 2.8226443132348193
Validation loss: 2.7664268725787635

Epoch: 5| Step: 5
Training loss: 2.299231948322104
Validation loss: 2.716672847606644

Epoch: 5| Step: 6
Training loss: 3.086384646698776
Validation loss: 2.753557849548451

Epoch: 5| Step: 7
Training loss: 3.0913335437337204
Validation loss: 2.785282905953863

Epoch: 5| Step: 8
Training loss: 3.0010846084723224
Validation loss: 2.7998001751740906

Epoch: 5| Step: 9
Training loss: 1.9122057569953559
Validation loss: 2.7601645492485085

Epoch: 5| Step: 10
Training loss: 3.080812317131024
Validation loss: 2.71325987917365

Epoch: 282| Step: 0
Training loss: 1.808349263286596
Validation loss: 2.739308861013393

Epoch: 5| Step: 1
Training loss: 2.94152069882339
Validation loss: 2.7612602135306017

Epoch: 5| Step: 2
Training loss: 3.0282203242018535
Validation loss: 2.745529304207164

Epoch: 5| Step: 3
Training loss: 2.003794646548061
Validation loss: 2.810924452417749

Epoch: 5| Step: 4
Training loss: 3.3029876016354676
Validation loss: 2.7420532971550577

Epoch: 5| Step: 5
Training loss: 2.204501973003111
Validation loss: 2.777048905090153

Epoch: 5| Step: 6
Training loss: 2.7015778628828655
Validation loss: 2.75093143384227

Epoch: 5| Step: 7
Training loss: 2.152205281035317
Validation loss: 2.711900281514585

Epoch: 5| Step: 8
Training loss: 2.572121583559532
Validation loss: 2.7841271946943986

Epoch: 5| Step: 9
Training loss: 2.6766580523411276
Validation loss: 2.7316402531293282

Epoch: 5| Step: 10
Training loss: 2.8275671983148922
Validation loss: 2.696376333424255

Epoch: 283| Step: 0
Training loss: 3.217505353257736
Validation loss: 2.7246505249035144

Epoch: 5| Step: 1
Training loss: 2.240520748336057
Validation loss: 2.7026239068563127

Epoch: 5| Step: 2
Training loss: 2.6856692976357732
Validation loss: 2.7796597757117625

Epoch: 5| Step: 3
Training loss: 2.4480032939327745
Validation loss: 2.7455232590967653

Epoch: 5| Step: 4
Training loss: 2.0322664505335797
Validation loss: 2.7527489584457983

Epoch: 5| Step: 5
Training loss: 3.6254756220843802
Validation loss: 2.6928260913777926

Epoch: 5| Step: 6
Training loss: 2.2480565260639382
Validation loss: 2.731995166970042

Epoch: 5| Step: 7
Training loss: 2.517732578508596
Validation loss: 2.707565771213089

Epoch: 5| Step: 8
Training loss: 2.8055020905321864
Validation loss: 2.743927882853813

Epoch: 5| Step: 9
Training loss: 2.599217087905944
Validation loss: 2.7024107219380555

Epoch: 5| Step: 10
Training loss: 2.2141281128976
Validation loss: 2.762808822470029

Epoch: 284| Step: 0
Training loss: 2.4604550812188295
Validation loss: 2.7922312906762183

Epoch: 5| Step: 1
Training loss: 2.1250177270486463
Validation loss: 2.730207789632539

Epoch: 5| Step: 2
Training loss: 2.2054742502920255
Validation loss: 2.7388053973906517

Epoch: 5| Step: 3
Training loss: 3.0630841379294753
Validation loss: 2.6676994606658497

Epoch: 5| Step: 4
Training loss: 2.9793841587163548
Validation loss: 2.7838068859210474

Epoch: 5| Step: 5
Training loss: 3.169182296849467
Validation loss: 2.723664794369837

Epoch: 5| Step: 6
Training loss: 2.834954714135866
Validation loss: 2.6706233805970725

Epoch: 5| Step: 7
Training loss: 2.1455223697659878
Validation loss: 2.741762954657327

Epoch: 5| Step: 8
Training loss: 2.370462801850832
Validation loss: 2.768003556171028

Epoch: 5| Step: 9
Training loss: 2.9681293039457373
Validation loss: 2.76491576144863

Epoch: 5| Step: 10
Training loss: 2.28799496908235
Validation loss: 2.761597514332523

Epoch: 285| Step: 0
Training loss: 2.852865511906988
Validation loss: 2.745698572165365

Epoch: 5| Step: 1
Training loss: 2.675974417069518
Validation loss: 2.774904266778443

Epoch: 5| Step: 2
Training loss: 2.606498732006907
Validation loss: 2.7538311803426456

Epoch: 5| Step: 3
Training loss: 3.109768176500021
Validation loss: 2.7868499643184337

Epoch: 5| Step: 4
Training loss: 2.6460315499936904
Validation loss: 2.7533573955557182

Epoch: 5| Step: 5
Training loss: 2.71482882049627
Validation loss: 2.7384041189623805

Epoch: 5| Step: 6
Training loss: 2.4921897959922807
Validation loss: 2.779584233947621

Epoch: 5| Step: 7
Training loss: 2.061223646635113
Validation loss: 2.7750668495564152

Epoch: 5| Step: 8
Training loss: 2.3789579639545324
Validation loss: 2.743849903539399

Epoch: 5| Step: 9
Training loss: 2.980835738280189
Validation loss: 2.724986647623703

Epoch: 5| Step: 10
Training loss: 2.3521103331708697
Validation loss: 2.76901829132008

Epoch: 286| Step: 0
Training loss: 2.6842225072532315
Validation loss: 2.788620797051189

Epoch: 5| Step: 1
Training loss: 2.63525947031618
Validation loss: 2.7085869697966207

Epoch: 5| Step: 2
Training loss: 1.6998081631971746
Validation loss: 2.709002983913649

Epoch: 5| Step: 3
Training loss: 3.351038040350479
Validation loss: 2.7827577263843053

Epoch: 5| Step: 4
Training loss: 2.920701877685052
Validation loss: 2.7277398085622995

Epoch: 5| Step: 5
Training loss: 2.671748108109377
Validation loss: 2.7329475035476407

Epoch: 5| Step: 6
Training loss: 2.6422456361588598
Validation loss: 2.737267984539282

Epoch: 5| Step: 7
Training loss: 2.97414382026543
Validation loss: 2.7390009682459424

Epoch: 5| Step: 8
Training loss: 2.5267536117001006
Validation loss: 2.7517855763298553

Epoch: 5| Step: 9
Training loss: 2.4169695982214603
Validation loss: 2.70864385492279

Epoch: 5| Step: 10
Training loss: 2.2470956707269183
Validation loss: 2.7927570028974893

Epoch: 287| Step: 0
Training loss: 2.6321821505236214
Validation loss: 2.741112075275477

Epoch: 5| Step: 1
Training loss: 2.354531982794396
Validation loss: 2.70559604191779

Epoch: 5| Step: 2
Training loss: 2.964100298441946
Validation loss: 2.6756400256474673

Epoch: 5| Step: 3
Training loss: 2.6999809193819972
Validation loss: 2.790185839252997

Epoch: 5| Step: 4
Training loss: 3.1807217802082
Validation loss: 2.7331985666510135

Epoch: 5| Step: 5
Training loss: 2.3360806934776908
Validation loss: 2.7482475251063407

Epoch: 5| Step: 6
Training loss: 2.084831030057151
Validation loss: 2.773652324707545

Epoch: 5| Step: 7
Training loss: 2.172360372852206
Validation loss: 2.772326195327717

Epoch: 5| Step: 8
Training loss: 1.7851974515939038
Validation loss: 2.6921571776151105

Epoch: 5| Step: 9
Training loss: 2.660789739210034
Validation loss: 2.712764887122247

Epoch: 5| Step: 10
Training loss: 3.171193768488038
Validation loss: 2.7746323854649697

Epoch: 288| Step: 0
Training loss: 2.6967721718360917
Validation loss: 2.696846025503031

Epoch: 5| Step: 1
Training loss: 3.0683326452925486
Validation loss: 2.7101302181822855

Epoch: 5| Step: 2
Training loss: 2.75669436170634
Validation loss: 2.759245901481585

Epoch: 5| Step: 3
Training loss: 2.5143271942866146
Validation loss: 2.689636891921113

Epoch: 5| Step: 4
Training loss: 2.314410889316632
Validation loss: 2.6881160340063044

Epoch: 5| Step: 5
Training loss: 3.0338078354775506
Validation loss: 2.732903106231907

Epoch: 5| Step: 6
Training loss: 3.532647860510876
Validation loss: 2.737593796605085

Epoch: 5| Step: 7
Training loss: 2.197360349520704
Validation loss: 2.687778884829317

Epoch: 5| Step: 8
Training loss: 2.068689480267999
Validation loss: 2.8294130024673025

Epoch: 5| Step: 9
Training loss: 2.3335021729917935
Validation loss: 2.755671323948149

Epoch: 5| Step: 10
Training loss: 1.9467488696539734
Validation loss: 2.7663587168510095

Epoch: 289| Step: 0
Training loss: 2.656609903524489
Validation loss: 2.7452575804353563

Epoch: 5| Step: 1
Training loss: 2.1779971113930174
Validation loss: 2.6711229543161905

Epoch: 5| Step: 2
Training loss: 2.9211850907276573
Validation loss: 2.7508738351577033

Epoch: 5| Step: 3
Training loss: 1.929120061433653
Validation loss: 2.7385529217518214

Epoch: 5| Step: 4
Training loss: 2.6562376134247043
Validation loss: 2.7285959535828472

Epoch: 5| Step: 5
Training loss: 1.787746561825145
Validation loss: 2.7316636704467725

Epoch: 5| Step: 6
Training loss: 3.08663368580983
Validation loss: 2.802976784605005

Epoch: 5| Step: 7
Training loss: 2.2109723307423703
Validation loss: 2.7671292608278555

Epoch: 5| Step: 8
Training loss: 3.217471859682176
Validation loss: 2.7160456654699745

Epoch: 5| Step: 9
Training loss: 2.4745740157855107
Validation loss: 2.737800206563204

Epoch: 5| Step: 10
Training loss: 2.72993396329833
Validation loss: 2.745087153396452

Epoch: 290| Step: 0
Training loss: 3.368650185091804
Validation loss: 2.783616857571584

Epoch: 5| Step: 1
Training loss: 2.873101976230623
Validation loss: 2.747374232843482

Epoch: 5| Step: 2
Training loss: 2.0630520168593853
Validation loss: 2.694796369659426

Epoch: 5| Step: 3
Training loss: 2.715403371531252
Validation loss: 2.721504376769986

Epoch: 5| Step: 4
Training loss: 2.787879415101771
Validation loss: 2.7412608367481424

Epoch: 5| Step: 5
Training loss: 1.8093907225457737
Validation loss: 2.7097380898864607

Epoch: 5| Step: 6
Training loss: 2.7181901026385242
Validation loss: 2.7509264210544653

Epoch: 5| Step: 7
Training loss: 2.7794439045021084
Validation loss: 2.7714212351975918

Epoch: 5| Step: 8
Training loss: 2.757684115698591
Validation loss: 2.7560246309762446

Epoch: 5| Step: 9
Training loss: 2.6896372436352554
Validation loss: 2.729706497990778

Epoch: 5| Step: 10
Training loss: 1.9213097213963777
Validation loss: 2.704581198549383

Epoch: 291| Step: 0
Training loss: 3.427519023683872
Validation loss: 2.78132819719894

Epoch: 5| Step: 1
Training loss: 2.0093343585281103
Validation loss: 2.7663259107597153

Epoch: 5| Step: 2
Training loss: 2.391191303272583
Validation loss: 2.735562045827483

Epoch: 5| Step: 3
Training loss: 2.7811966794506997
Validation loss: 2.800450772376372

Epoch: 5| Step: 4
Training loss: 2.464920647293708
Validation loss: 2.6947348954405164

Epoch: 5| Step: 5
Training loss: 2.8533414961201973
Validation loss: 2.8058961751335283

Epoch: 5| Step: 6
Training loss: 2.1795206860660876
Validation loss: 2.777422219630907

Epoch: 5| Step: 7
Training loss: 2.300086339076386
Validation loss: 2.7821659682815807

Epoch: 5| Step: 8
Training loss: 1.8652773228039836
Validation loss: 2.688374507990959

Epoch: 5| Step: 9
Training loss: 2.82869112028505
Validation loss: 2.785606201692733

Epoch: 5| Step: 10
Training loss: 2.970683381806928
Validation loss: 2.772965953856658

Epoch: 292| Step: 0
Training loss: 2.81223211072274
Validation loss: 2.693646593804573

Epoch: 5| Step: 1
Training loss: 2.6502227617599776
Validation loss: 2.721855512503365

Epoch: 5| Step: 2
Training loss: 2.8010092074574175
Validation loss: 2.6873043310540954

Epoch: 5| Step: 3
Training loss: 2.1434516899372205
Validation loss: 2.765049527771716

Epoch: 5| Step: 4
Training loss: 2.442170388228299
Validation loss: 2.7492631631721283

Epoch: 5| Step: 5
Training loss: 2.4551057047724942
Validation loss: 2.7371341783231893

Epoch: 5| Step: 6
Training loss: 2.5747145781613505
Validation loss: 2.776744944069056

Epoch: 5| Step: 7
Training loss: 2.7871723341697634
Validation loss: 2.733350303368621

Epoch: 5| Step: 8
Training loss: 2.6992927684654986
Validation loss: 2.719024853644397

Epoch: 5| Step: 9
Training loss: 2.5068753116429625
Validation loss: 2.7410648893498215

Epoch: 5| Step: 10
Training loss: 2.7188348866507397
Validation loss: 2.8285882289790147

Epoch: 293| Step: 0
Training loss: 2.687164108222466
Validation loss: 2.736048742081482

Epoch: 5| Step: 1
Training loss: 2.5470644640513522
Validation loss: 2.753145377716775

Epoch: 5| Step: 2
Training loss: 1.8250877385408606
Validation loss: 2.771792130649417

Epoch: 5| Step: 3
Training loss: 2.2705501298139823
Validation loss: 2.7512462957733277

Epoch: 5| Step: 4
Training loss: 2.679685364658406
Validation loss: 2.8063556382219876

Epoch: 5| Step: 5
Training loss: 3.129561033088612
Validation loss: 2.7618134493629847

Epoch: 5| Step: 6
Training loss: 2.868113355282528
Validation loss: 2.752340456280277

Epoch: 5| Step: 7
Training loss: 2.584507941778656
Validation loss: 2.7171524280045505

Epoch: 5| Step: 8
Training loss: 2.389916607986028
Validation loss: 2.797830707684431

Epoch: 5| Step: 9
Training loss: 2.3936659476959052
Validation loss: 2.7727510334402377

Epoch: 5| Step: 10
Training loss: 3.293982516049537
Validation loss: 2.7244972751970935

Epoch: 294| Step: 0
Training loss: 2.215317878904955
Validation loss: 2.7832625176411443

Epoch: 5| Step: 1
Training loss: 2.9240921502680584
Validation loss: 2.7553995657201673

Epoch: 5| Step: 2
Training loss: 2.4954577189344938
Validation loss: 2.7352107707694526

Epoch: 5| Step: 3
Training loss: 2.44111384967752
Validation loss: 2.7802809266415056

Epoch: 5| Step: 4
Training loss: 2.9270873878604777
Validation loss: 2.734922406649901

Epoch: 5| Step: 5
Training loss: 2.96321923904847
Validation loss: 2.753742170249511

Epoch: 5| Step: 6
Training loss: 2.310181976680811
Validation loss: 2.782611630216275

Epoch: 5| Step: 7
Training loss: 2.7824143961910757
Validation loss: 2.7619140182799997

Epoch: 5| Step: 8
Training loss: 2.5671490620517563
Validation loss: 2.775061935794927

Epoch: 5| Step: 9
Training loss: 2.494531659067409
Validation loss: 2.799692377135381

Epoch: 5| Step: 10
Training loss: 2.5304055394766007
Validation loss: 2.7534918742216155

Epoch: 295| Step: 0
Training loss: 2.7266615710253617
Validation loss: 2.690774820166068

Epoch: 5| Step: 1
Training loss: 2.90429506898271
Validation loss: 2.724814566965355

Epoch: 5| Step: 2
Training loss: 2.4894068401349045
Validation loss: 2.778373105095991

Epoch: 5| Step: 3
Training loss: 2.689037947512158
Validation loss: 2.7580090347895556

Epoch: 5| Step: 4
Training loss: 2.734764638115136
Validation loss: 2.748113486664832

Epoch: 5| Step: 5
Training loss: 2.6149868495457333
Validation loss: 2.7774373627997453

Epoch: 5| Step: 6
Training loss: 2.664203360404994
Validation loss: 2.6919918368934854

Epoch: 5| Step: 7
Training loss: 2.8037980988552453
Validation loss: 2.702786906912835

Epoch: 5| Step: 8
Training loss: 2.4710465384793565
Validation loss: 2.755926088065321

Epoch: 5| Step: 9
Training loss: 2.452910104073978
Validation loss: 2.7242716925444745

Epoch: 5| Step: 10
Training loss: 2.597664051474422
Validation loss: 2.7658601446191002

Epoch: 296| Step: 0
Training loss: 2.584338659102487
Validation loss: 2.748493492293325

Epoch: 5| Step: 1
Training loss: 2.3811948194142727
Validation loss: 2.7258477993034353

Epoch: 5| Step: 2
Training loss: 2.961667094261927
Validation loss: 2.7749606396057374

Epoch: 5| Step: 3
Training loss: 2.579530829715481
Validation loss: 2.802120575522216

Epoch: 5| Step: 4
Training loss: 2.1414046155665165
Validation loss: 2.7947711448320667

Epoch: 5| Step: 5
Training loss: 2.282167642050719
Validation loss: 2.71938841229782

Epoch: 5| Step: 6
Training loss: 3.2326039058450946
Validation loss: 2.7461607955244323

Epoch: 5| Step: 7
Training loss: 2.2316235226977925
Validation loss: 2.750719654935941

Epoch: 5| Step: 8
Training loss: 2.1313200818841995
Validation loss: 2.7542957806275163

Epoch: 5| Step: 9
Training loss: 2.675890487334547
Validation loss: 2.7617328848412326

Epoch: 5| Step: 10
Training loss: 3.368439550019598
Validation loss: 2.742715246350135

Epoch: 297| Step: 0
Training loss: 3.2505059948748416
Validation loss: 2.7620798800719535

Epoch: 5| Step: 1
Training loss: 2.8542284065492955
Validation loss: 2.7893330391206637

Epoch: 5| Step: 2
Training loss: 2.0127190038331513
Validation loss: 2.747601464317268

Epoch: 5| Step: 3
Training loss: 2.2306532374310493
Validation loss: 2.753033707002401

Epoch: 5| Step: 4
Training loss: 3.0782563622033354
Validation loss: 2.7764401021306955

Epoch: 5| Step: 5
Training loss: 2.7877459156716986
Validation loss: 2.749025877552949

Epoch: 5| Step: 6
Training loss: 2.289901423435676
Validation loss: 2.7531125920305133

Epoch: 5| Step: 7
Training loss: 2.4681331974607277
Validation loss: 2.772557947735384

Epoch: 5| Step: 8
Training loss: 2.660538834943484
Validation loss: 2.756627308257198

Epoch: 5| Step: 9
Training loss: 2.3908149793347406
Validation loss: 2.7592707894163504

Epoch: 5| Step: 10
Training loss: 2.4203392820311005
Validation loss: 2.7572662966243064

Epoch: 298| Step: 0
Training loss: 2.6436041104079706
Validation loss: 2.7397190779196996

Epoch: 5| Step: 1
Training loss: 2.785816087714092
Validation loss: 2.7108911331408887

Epoch: 5| Step: 2
Training loss: 2.595735640139182
Validation loss: 2.7110969515713754

Epoch: 5| Step: 3
Training loss: 2.4906381795766603
Validation loss: 2.7483039335340744

Epoch: 5| Step: 4
Training loss: 2.9084456158872443
Validation loss: 2.7544836929100645

Epoch: 5| Step: 5
Training loss: 2.716036176555758
Validation loss: 2.712373796610752

Epoch: 5| Step: 6
Training loss: 2.7864642181809693
Validation loss: 2.7439906257135145

Epoch: 5| Step: 7
Training loss: 2.5299734970634584
Validation loss: 2.6971949270253237

Epoch: 5| Step: 8
Training loss: 2.773697703875484
Validation loss: 2.69782360652993

Epoch: 5| Step: 9
Training loss: 2.005638281236458
Validation loss: 2.744999232646308

Epoch: 5| Step: 10
Training loss: 2.254132819729559
Validation loss: 2.663166140132708

Epoch: 299| Step: 0
Training loss: 2.4032215034543793
Validation loss: 2.703955215614835

Epoch: 5| Step: 1
Training loss: 2.6537892331256754
Validation loss: 2.7780582963820044

Epoch: 5| Step: 2
Training loss: 2.9243339758431333
Validation loss: 2.800586103882078

Epoch: 5| Step: 3
Training loss: 2.8797193851454725
Validation loss: 2.718574745527741

Epoch: 5| Step: 4
Training loss: 2.6070828906812795
Validation loss: 2.710233507048532

Epoch: 5| Step: 5
Training loss: 2.3050378565461966
Validation loss: 2.7960725954227508

Epoch: 5| Step: 6
Training loss: 2.8307307763023446
Validation loss: 2.7770526050843456

Epoch: 5| Step: 7
Training loss: 2.7509220484869807
Validation loss: 2.7715119252520846

Epoch: 5| Step: 8
Training loss: 2.577780220790597
Validation loss: 2.7465502691002484

Epoch: 5| Step: 9
Training loss: 2.4171317628575593
Validation loss: 2.7304051171013035

Epoch: 5| Step: 10
Training loss: 2.1611576346080716
Validation loss: 2.7656005891668465

Epoch: 300| Step: 0
Training loss: 2.273293821638442
Validation loss: 2.7277600987056854

Epoch: 5| Step: 1
Training loss: 2.4224055539706217
Validation loss: 2.756700744077037

Epoch: 5| Step: 2
Training loss: 2.1073339689656674
Validation loss: 2.722001774296213

Epoch: 5| Step: 3
Training loss: 2.75519573783279
Validation loss: 2.7400199148928785

Epoch: 5| Step: 4
Training loss: 2.444066324273695
Validation loss: 2.734904376702059

Epoch: 5| Step: 5
Training loss: 2.372334038061877
Validation loss: 2.7482668233721523

Epoch: 5| Step: 6
Training loss: 2.135318276224317
Validation loss: 2.72975574352245

Epoch: 5| Step: 7
Training loss: 3.067221446925536
Validation loss: 2.7517069742143403

Epoch: 5| Step: 8
Training loss: 3.1862733762114797
Validation loss: 2.6840846210770426

Epoch: 5| Step: 9
Training loss: 2.720457308276681
Validation loss: 2.7254696939737117

Epoch: 5| Step: 10
Training loss: 2.7383528195332327
Validation loss: 2.760609659300455

Epoch: 301| Step: 0
Training loss: 2.2982030649130385
Validation loss: 2.6154005375629277

Epoch: 5| Step: 1
Training loss: 2.1230660782465813
Validation loss: 2.7575170328535

Epoch: 5| Step: 2
Training loss: 2.12152926924827
Validation loss: 2.7321557142850352

Epoch: 5| Step: 3
Training loss: 2.8824725687222132
Validation loss: 2.804039193212163

Epoch: 5| Step: 4
Training loss: 3.2623492151252327
Validation loss: 2.7018754081307046

Epoch: 5| Step: 5
Training loss: 2.7417487421089404
Validation loss: 2.7735420314807966

Epoch: 5| Step: 6
Training loss: 2.8723644947729943
Validation loss: 2.7786823544823576

Epoch: 5| Step: 7
Training loss: 1.8482258021678386
Validation loss: 2.7464481136147074

Epoch: 5| Step: 8
Training loss: 2.945671727461218
Validation loss: 2.6959431741910707

Epoch: 5| Step: 9
Training loss: 1.890943579196693
Validation loss: 2.739447263528477

Epoch: 5| Step: 10
Training loss: 2.6304886067442266
Validation loss: 2.807695850128163

Epoch: 302| Step: 0
Training loss: 2.378366393421119
Validation loss: 2.824108309237273

Epoch: 5| Step: 1
Training loss: 3.2804728723051766
Validation loss: 2.7434873157454103

Epoch: 5| Step: 2
Training loss: 2.734952767503017
Validation loss: 2.8170113335607936

Epoch: 5| Step: 3
Training loss: 2.94051952598561
Validation loss: 2.7828660403834937

Epoch: 5| Step: 4
Training loss: 2.6719049820137983
Validation loss: 2.787533290838432

Epoch: 5| Step: 5
Training loss: 2.113702023512695
Validation loss: 2.712655447757852

Epoch: 5| Step: 6
Training loss: 3.1045077006434516
Validation loss: 2.7579528062694347

Epoch: 5| Step: 7
Training loss: 2.6954351867174764
Validation loss: 2.7963928478023843

Epoch: 5| Step: 8
Training loss: 2.4696149638684943
Validation loss: 2.725239246542267

Epoch: 5| Step: 9
Training loss: 2.46138766576507
Validation loss: 2.7031258715784006

Epoch: 5| Step: 10
Training loss: 1.6284413211640785
Validation loss: 2.7545915141891206

Epoch: 303| Step: 0
Training loss: 2.332745160039873
Validation loss: 2.7502030011497807

Epoch: 5| Step: 1
Training loss: 2.9450413100967308
Validation loss: 2.730086273037575

Epoch: 5| Step: 2
Training loss: 2.394843673860364
Validation loss: 2.807667592099558

Epoch: 5| Step: 3
Training loss: 2.253634590160259
Validation loss: 2.7483475195876403

Epoch: 5| Step: 4
Training loss: 2.9965266147541034
Validation loss: 2.737156540849023

Epoch: 5| Step: 5
Training loss: 2.5306860213060487
Validation loss: 2.741302329606232

Epoch: 5| Step: 6
Training loss: 2.0962184190731237
Validation loss: 2.7589237386950654

Epoch: 5| Step: 7
Training loss: 3.134261939918235
Validation loss: 2.7675312041240465

Epoch: 5| Step: 8
Training loss: 2.7505065278081746
Validation loss: 2.7516145786068282

Epoch: 5| Step: 9
Training loss: 2.359373585277411
Validation loss: 2.730208299504623

Epoch: 5| Step: 10
Training loss: 2.861509599887196
Validation loss: 2.766863949175455

Epoch: 304| Step: 0
Training loss: 3.174506538070745
Validation loss: 2.779331649495735

Epoch: 5| Step: 1
Training loss: 2.3464049497154824
Validation loss: 2.7633385568902376

Epoch: 5| Step: 2
Training loss: 2.488994502152302
Validation loss: 2.77609335502943

Epoch: 5| Step: 3
Training loss: 2.6615051345044693
Validation loss: 2.7740747122150777

Epoch: 5| Step: 4
Training loss: 2.7350596415486756
Validation loss: 2.763657216690842

Epoch: 5| Step: 5
Training loss: 2.4096223063524373
Validation loss: 2.751943814860369

Epoch: 5| Step: 6
Training loss: 2.025053579304497
Validation loss: 2.6922090106748215

Epoch: 5| Step: 7
Training loss: 2.2933102926863733
Validation loss: 2.7667852273537115

Epoch: 5| Step: 8
Training loss: 2.117592860756236
Validation loss: 2.7731564485830473

Epoch: 5| Step: 9
Training loss: 2.947869685756835
Validation loss: 2.766974535463399

Epoch: 5| Step: 10
Training loss: 3.0706935966372013
Validation loss: 2.7346624951618805

Epoch: 305| Step: 0
Training loss: 2.6797363454743275
Validation loss: 2.779087405264394

Epoch: 5| Step: 1
Training loss: 2.4714697813131052
Validation loss: 2.763164316627326

Epoch: 5| Step: 2
Training loss: 2.5022613788139827
Validation loss: 2.7259308012449535

Epoch: 5| Step: 3
Training loss: 2.017138954955417
Validation loss: 2.7511179600883513

Epoch: 5| Step: 4
Training loss: 3.598457371486668
Validation loss: 2.750042257795326

Epoch: 5| Step: 5
Training loss: 2.154661284377832
Validation loss: 2.758288956583119

Epoch: 5| Step: 6
Training loss: 2.6135639670677344
Validation loss: 2.8095365619620782

Epoch: 5| Step: 7
Training loss: 2.7257090984579597
Validation loss: 2.730349689087043

Epoch: 5| Step: 8
Training loss: 2.2618403953820723
Validation loss: 2.7239339945792107

Epoch: 5| Step: 9
Training loss: 2.637381011303714
Validation loss: 2.7593134794086316

Epoch: 5| Step: 10
Training loss: 2.5845067425398383
Validation loss: 2.7860844677667584

Epoch: 306| Step: 0
Training loss: 2.3676713002155214
Validation loss: 2.695792703176072

Epoch: 5| Step: 1
Training loss: 2.4151105364979504
Validation loss: 2.6891049641025515

Epoch: 5| Step: 2
Training loss: 1.612981070977974
Validation loss: 2.781916749625057

Epoch: 5| Step: 3
Training loss: 2.82663168920013
Validation loss: 2.737881839568452

Epoch: 5| Step: 4
Training loss: 2.566906373691652
Validation loss: 2.7114963686548914

Epoch: 5| Step: 5
Training loss: 2.4745632248619374
Validation loss: 2.763705970434701

Epoch: 5| Step: 6
Training loss: 2.913216557581112
Validation loss: 2.773880552300142

Epoch: 5| Step: 7
Training loss: 2.480556600621957
Validation loss: 2.7223328605649466

Epoch: 5| Step: 8
Training loss: 2.82297903369735
Validation loss: 2.78407607476697

Epoch: 5| Step: 9
Training loss: 3.254193754649199
Validation loss: 2.765777342683588

Epoch: 5| Step: 10
Training loss: 2.268932270052953
Validation loss: 2.7578111018931697

Epoch: 307| Step: 0
Training loss: 2.6920588661321476
Validation loss: 2.7307957591270107

Epoch: 5| Step: 1
Training loss: 1.9368152023494027
Validation loss: 2.7321027511490685

Epoch: 5| Step: 2
Training loss: 2.6780721616929712
Validation loss: 2.7612507472280066

Epoch: 5| Step: 3
Training loss: 2.4912553437094793
Validation loss: 2.735086138669607

Epoch: 5| Step: 4
Training loss: 2.5589493133188013
Validation loss: 2.753759609982421

Epoch: 5| Step: 5
Training loss: 2.5643405352105018
Validation loss: 2.821785487255627

Epoch: 5| Step: 6
Training loss: 2.767629123559761
Validation loss: 2.7636121151406137

Epoch: 5| Step: 7
Training loss: 2.3909460114016077
Validation loss: 2.7771209913149817

Epoch: 5| Step: 8
Training loss: 3.044575454355767
Validation loss: 2.6991985824798173

Epoch: 5| Step: 9
Training loss: 2.369316729787777
Validation loss: 2.7383673343097032

Epoch: 5| Step: 10
Training loss: 2.8845229618231776
Validation loss: 2.808134209422511

Epoch: 308| Step: 0
Training loss: 2.81493645144024
Validation loss: 2.727590873594528

Epoch: 5| Step: 1
Training loss: 2.874397048749505
Validation loss: 2.678404864471134

Epoch: 5| Step: 2
Training loss: 2.8771128975916604
Validation loss: 2.7215704436551724

Epoch: 5| Step: 3
Training loss: 2.3429387023566126
Validation loss: 2.724593776376394

Epoch: 5| Step: 4
Training loss: 2.827984463903979
Validation loss: 2.7242720736644586

Epoch: 5| Step: 5
Training loss: 2.75745352767284
Validation loss: 2.7755119555442818

Epoch: 5| Step: 6
Training loss: 2.5773115319686526
Validation loss: 2.7352818648540542

Epoch: 5| Step: 7
Training loss: 1.9725826438541725
Validation loss: 2.741644970507265

Epoch: 5| Step: 8
Training loss: 2.393021024854719
Validation loss: 2.7499337733731894

Epoch: 5| Step: 9
Training loss: 2.021047115488326
Validation loss: 2.787802541957207

Epoch: 5| Step: 10
Training loss: 2.6584051028840654
Validation loss: 2.776224791337406

Epoch: 309| Step: 0
Training loss: 2.534846070862353
Validation loss: 2.7017881943267565

Epoch: 5| Step: 1
Training loss: 2.585204513251455
Validation loss: 2.790473231691343

Epoch: 5| Step: 2
Training loss: 2.5068142529253006
Validation loss: 2.6785287754629885

Epoch: 5| Step: 3
Training loss: 1.9496530419796088
Validation loss: 2.748245754599336

Epoch: 5| Step: 4
Training loss: 2.718187032707921
Validation loss: 2.7921995809250677

Epoch: 5| Step: 5
Training loss: 2.5113957080181923
Validation loss: 2.759723967560945

Epoch: 5| Step: 6
Training loss: 2.820834716465966
Validation loss: 2.7385169095428687

Epoch: 5| Step: 7
Training loss: 3.269073417812357
Validation loss: 2.7044893826429317

Epoch: 5| Step: 8
Training loss: 2.306001967244827
Validation loss: 2.7532316081021273

Epoch: 5| Step: 9
Training loss: 2.5636330867392223
Validation loss: 2.74949975744967

Epoch: 5| Step: 10
Training loss: 2.4320279835483904
Validation loss: 2.7658547834977742

Epoch: 310| Step: 0
Training loss: 2.7855926214625466
Validation loss: 2.8638325860619664

Epoch: 5| Step: 1
Training loss: 2.224705078638552
Validation loss: 2.7206017102124105

Epoch: 5| Step: 2
Training loss: 1.9904829324902316
Validation loss: 2.8216286555676953

Epoch: 5| Step: 3
Training loss: 2.590393836518201
Validation loss: 2.7571276607152178

Epoch: 5| Step: 4
Training loss: 2.413129014943302
Validation loss: 2.7005957168264403

Epoch: 5| Step: 5
Training loss: 3.196519246074915
Validation loss: 2.788239487670123

Epoch: 5| Step: 6
Training loss: 3.211283050283878
Validation loss: 2.7071380804868785

Epoch: 5| Step: 7
Training loss: 2.2806425984300307
Validation loss: 2.7168191425991535

Epoch: 5| Step: 8
Training loss: 2.6212642972353426
Validation loss: 2.8748968426003474

Epoch: 5| Step: 9
Training loss: 2.4960692976110583
Validation loss: 2.8034157455453848

Epoch: 5| Step: 10
Training loss: 1.8980168634033334
Validation loss: 2.762469182464108

Epoch: 311| Step: 0
Training loss: 1.8088566566345434
Validation loss: 2.7256539144891034

Epoch: 5| Step: 1
Training loss: 2.7186012665853903
Validation loss: 2.6886255016155043

Epoch: 5| Step: 2
Training loss: 1.3981642642623324
Validation loss: 2.779172380582987

Epoch: 5| Step: 3
Training loss: 2.5882352549124525
Validation loss: 2.8119257305334457

Epoch: 5| Step: 4
Training loss: 2.699848725355001
Validation loss: 2.7608864323958784

Epoch: 5| Step: 5
Training loss: 3.085006689376627
Validation loss: 2.6889424289071604

Epoch: 5| Step: 6
Training loss: 2.6702243100642966
Validation loss: 2.7040384686143715

Epoch: 5| Step: 7
Training loss: 2.7071357916039878
Validation loss: 2.8053487980191085

Epoch: 5| Step: 8
Training loss: 2.8727434673664956
Validation loss: 2.7595987387853813

Epoch: 5| Step: 9
Training loss: 2.610384077846498
Validation loss: 2.778562249260866

Epoch: 5| Step: 10
Training loss: 2.1226432297257785
Validation loss: 2.735372271351407

Epoch: 312| Step: 0
Training loss: 2.9465855445167013
Validation loss: 2.799087136309357

Epoch: 5| Step: 1
Training loss: 2.1999462814708504
Validation loss: 2.770620084506223

Epoch: 5| Step: 2
Training loss: 2.986599078463823
Validation loss: 2.7255531786677083

Epoch: 5| Step: 3
Training loss: 2.5060185465876073
Validation loss: 2.7283210869141175

Epoch: 5| Step: 4
Training loss: 2.316406044147862
Validation loss: 2.694506102767295

Epoch: 5| Step: 5
Training loss: 2.979494588095149
Validation loss: 2.7730597819289144

Epoch: 5| Step: 6
Training loss: 2.0192621815512264
Validation loss: 2.7216913278864014

Epoch: 5| Step: 7
Training loss: 2.421845663569802
Validation loss: 2.716764370658432

Epoch: 5| Step: 8
Training loss: 2.384844004649711
Validation loss: 2.727572553159609

Epoch: 5| Step: 9
Training loss: 2.8231357803797623
Validation loss: 2.768754634743577

Epoch: 5| Step: 10
Training loss: 2.3215516759907917
Validation loss: 2.710149588277988

Epoch: 313| Step: 0
Training loss: 2.346165747209456
Validation loss: 2.7510080661995455

Epoch: 5| Step: 1
Training loss: 3.0333323454243932
Validation loss: 2.7145550143242145

Epoch: 5| Step: 2
Training loss: 2.812533484365562
Validation loss: 2.7051721536616964

Epoch: 5| Step: 3
Training loss: 2.9096997203781276
Validation loss: 2.724066905771911

Epoch: 5| Step: 4
Training loss: 2.7248850036994643
Validation loss: 2.781685878311028

Epoch: 5| Step: 5
Training loss: 2.2381204011385707
Validation loss: 2.7024992897262172

Epoch: 5| Step: 6
Training loss: 2.240412843840605
Validation loss: 2.74866699118034

Epoch: 5| Step: 7
Training loss: 2.2575823920708906
Validation loss: 2.7315211813359688

Epoch: 5| Step: 8
Training loss: 2.913601999995861
Validation loss: 2.781549764574764

Epoch: 5| Step: 9
Training loss: 2.458518640894002
Validation loss: 2.707147212324346

Epoch: 5| Step: 10
Training loss: 2.033160792779473
Validation loss: 2.7359547091890444

Epoch: 314| Step: 0
Training loss: 2.252721729775557
Validation loss: 2.7313384171710156

Epoch: 5| Step: 1
Training loss: 2.4166412900271954
Validation loss: 2.7747031079177886

Epoch: 5| Step: 2
Training loss: 2.251916387147482
Validation loss: 2.751669943487257

Epoch: 5| Step: 3
Training loss: 2.0112208074201976
Validation loss: 2.7366252775093707

Epoch: 5| Step: 4
Training loss: 3.344235964248084
Validation loss: 2.7812533081890405

Epoch: 5| Step: 5
Training loss: 2.9711286151053033
Validation loss: 2.6797357886885798

Epoch: 5| Step: 6
Training loss: 1.8954468078072797
Validation loss: 2.711507885410224

Epoch: 5| Step: 7
Training loss: 3.0558118385187987
Validation loss: 2.7261583389697

Epoch: 5| Step: 8
Training loss: 3.303322368055737
Validation loss: 2.75824919707596

Epoch: 5| Step: 9
Training loss: 2.270735770646597
Validation loss: 2.70938430790022

Epoch: 5| Step: 10
Training loss: 2.0845806838186554
Validation loss: 2.716862327897357

Epoch: 315| Step: 0
Training loss: 2.1288286387444217
Validation loss: 2.721588753627329

Epoch: 5| Step: 1
Training loss: 2.0949962949151026
Validation loss: 2.733268157032854

Epoch: 5| Step: 2
Training loss: 2.4887233083951923
Validation loss: 2.7350156178363796

Epoch: 5| Step: 3
Training loss: 2.259935272100073
Validation loss: 2.800906632833231

Epoch: 5| Step: 4
Training loss: 3.0189879645467492
Validation loss: 2.7095916576261763

Epoch: 5| Step: 5
Training loss: 2.73932961762505
Validation loss: 2.7422704748083215

Epoch: 5| Step: 6
Training loss: 3.0366609395626036
Validation loss: 2.747186419370324

Epoch: 5| Step: 7
Training loss: 2.62348794530793
Validation loss: 2.763891749583998

Epoch: 5| Step: 8
Training loss: 2.5331416655697443
Validation loss: 2.781673818044143

Epoch: 5| Step: 9
Training loss: 2.8604234117917864
Validation loss: 2.7292542504976054

Epoch: 5| Step: 10
Training loss: 2.2496032365018697
Validation loss: 2.7231028045508396

Epoch: 316| Step: 0
Training loss: 2.903049963236991
Validation loss: 2.7934033439604367

Epoch: 5| Step: 1
Training loss: 2.9360135152334195
Validation loss: 2.7307749902220992

Epoch: 5| Step: 2
Training loss: 2.427763247452509
Validation loss: 2.8077938132921645

Epoch: 5| Step: 3
Training loss: 2.656335627353766
Validation loss: 2.7780125214915787

Epoch: 5| Step: 4
Training loss: 2.3994780529216424
Validation loss: 2.735769056066665

Epoch: 5| Step: 5
Training loss: 2.311818821562994
Validation loss: 2.69353677645077

Epoch: 5| Step: 6
Training loss: 2.693346893525059
Validation loss: 2.760891934091078

Epoch: 5| Step: 7
Training loss: 2.396687617928826
Validation loss: 2.644441197836461

Epoch: 5| Step: 8
Training loss: 2.1823043155227726
Validation loss: 2.785966105203237

Epoch: 5| Step: 9
Training loss: 2.403822727382657
Validation loss: 2.753916216776754

Epoch: 5| Step: 10
Training loss: 3.0302090774767763
Validation loss: 2.6985812380480105

Epoch: 317| Step: 0
Training loss: 2.382596565843418
Validation loss: 2.756236138066076

Epoch: 5| Step: 1
Training loss: 2.9308580018510213
Validation loss: 2.819198193288183

Epoch: 5| Step: 2
Training loss: 2.7666036307572575
Validation loss: 2.718146110343303

Epoch: 5| Step: 3
Training loss: 2.756897771927646
Validation loss: 2.759696306131513

Epoch: 5| Step: 4
Training loss: 2.431979064675621
Validation loss: 2.7969357989269232

Epoch: 5| Step: 5
Training loss: 2.527098182410264
Validation loss: 2.6672874847700294

Epoch: 5| Step: 6
Training loss: 2.0705969273224114
Validation loss: 2.6599984032353725

Epoch: 5| Step: 7
Training loss: 2.265674669444771
Validation loss: 2.7421014383873783

Epoch: 5| Step: 8
Training loss: 2.0836537178372354
Validation loss: 2.7416790004402554

Epoch: 5| Step: 9
Training loss: 3.358882992222911
Validation loss: 2.826360577823174

Epoch: 5| Step: 10
Training loss: 2.2074176281328044
Validation loss: 2.7205348442648156

Epoch: 318| Step: 0
Training loss: 3.0439592544094416
Validation loss: 2.75917837764733

Epoch: 5| Step: 1
Training loss: 1.9425239645953776
Validation loss: 2.761818686518577

Epoch: 5| Step: 2
Training loss: 2.988303430013683
Validation loss: 2.7711600580493974

Epoch: 5| Step: 3
Training loss: 2.3249182409862303
Validation loss: 2.8181165828918497

Epoch: 5| Step: 4
Training loss: 2.7276390595480855
Validation loss: 2.7506914863542526

Epoch: 5| Step: 5
Training loss: 2.222863159203066
Validation loss: 2.7846864617843035

Epoch: 5| Step: 6
Training loss: 2.8820338244283197
Validation loss: 2.7657940882801326

Epoch: 5| Step: 7
Training loss: 2.415637443875613
Validation loss: 2.7068413192500786

Epoch: 5| Step: 8
Training loss: 2.4699223306158644
Validation loss: 2.7412575971963675

Epoch: 5| Step: 9
Training loss: 2.698231849277833
Validation loss: 2.7311798169285573

Epoch: 5| Step: 10
Training loss: 2.2797639788217774
Validation loss: 2.7290177901547845

Epoch: 319| Step: 0
Training loss: 2.5310231801828773
Validation loss: 2.7986710794896323

Epoch: 5| Step: 1
Training loss: 2.728868880781881
Validation loss: 2.7314911206876027

Epoch: 5| Step: 2
Training loss: 2.179547486542505
Validation loss: 2.743675045122324

Epoch: 5| Step: 3
Training loss: 3.4252618898380676
Validation loss: 2.7545045818092793

Epoch: 5| Step: 4
Training loss: 2.2966401894883632
Validation loss: 2.8172096743924224

Epoch: 5| Step: 5
Training loss: 2.315400032101318
Validation loss: 2.7639942528026924

Epoch: 5| Step: 6
Training loss: 2.0883606969446666
Validation loss: 2.7461035168772714

Epoch: 5| Step: 7
Training loss: 2.5449831436288495
Validation loss: 2.7455541446716953

Epoch: 5| Step: 8
Training loss: 2.834652444031647
Validation loss: 2.759192587753945

Epoch: 5| Step: 9
Training loss: 2.7757754505374965
Validation loss: 2.751153798964786

Epoch: 5| Step: 10
Training loss: 2.3215843337066095
Validation loss: 2.7328569455416476

Epoch: 320| Step: 0
Training loss: 2.769294158299705
Validation loss: 2.7926880687203868

Epoch: 5| Step: 1
Training loss: 2.0773108472223285
Validation loss: 2.768025907330777

Epoch: 5| Step: 2
Training loss: 2.543396803870941
Validation loss: 2.7735652216507245

Epoch: 5| Step: 3
Training loss: 2.8998503416183703
Validation loss: 2.7567820536098853

Epoch: 5| Step: 4
Training loss: 2.4387304672639964
Validation loss: 2.7599272288067525

Epoch: 5| Step: 5
Training loss: 2.269281422821849
Validation loss: 2.716272358828162

Epoch: 5| Step: 6
Training loss: 2.7214249353774287
Validation loss: 2.709778149637417

Epoch: 5| Step: 7
Training loss: 2.7115592133705557
Validation loss: 2.771282701478787

Epoch: 5| Step: 8
Training loss: 2.386506466079734
Validation loss: 2.7056149716592057

Epoch: 5| Step: 9
Training loss: 2.379113099073601
Validation loss: 2.7734915391116512

Epoch: 5| Step: 10
Training loss: 2.067417063404575
Validation loss: 2.773641987503404

Epoch: 321| Step: 0
Training loss: 2.535597658449516
Validation loss: 2.816844063774471

Epoch: 5| Step: 1
Training loss: 2.3414891846574215
Validation loss: 2.7345241054776497

Epoch: 5| Step: 2
Training loss: 2.4967706804122813
Validation loss: 2.710683153166924

Epoch: 5| Step: 3
Training loss: 2.4262723318150217
Validation loss: 2.733484640880739

Epoch: 5| Step: 4
Training loss: 3.131028273721316
Validation loss: 2.726916588854417

Epoch: 5| Step: 5
Training loss: 2.8070728072783093
Validation loss: 2.7390672710852075

Epoch: 5| Step: 6
Training loss: 3.2759532502114252
Validation loss: 2.777510657302177

Epoch: 5| Step: 7
Training loss: 2.250670650986373
Validation loss: 2.763075124725966

Epoch: 5| Step: 8
Training loss: 1.9013906985858595
Validation loss: 2.7585072100646

Epoch: 5| Step: 9
Training loss: 2.5150366622345754
Validation loss: 2.7151389586444346

Epoch: 5| Step: 10
Training loss: 2.469869046156815
Validation loss: 2.8061913181113582

Epoch: 322| Step: 0
Training loss: 2.9197388046184582
Validation loss: 2.783191553972245

Epoch: 5| Step: 1
Training loss: 3.027106373001986
Validation loss: 2.7385297870816356

Epoch: 5| Step: 2
Training loss: 2.408468734560452
Validation loss: 2.8215264516627214

Epoch: 5| Step: 3
Training loss: 2.5847594928827253
Validation loss: 2.7635251974979362

Epoch: 5| Step: 4
Training loss: 2.730151767913697
Validation loss: 2.810043753642892

Epoch: 5| Step: 5
Training loss: 2.1091396624362315
Validation loss: 2.7592307058594674

Epoch: 5| Step: 6
Training loss: 2.740231416772726
Validation loss: 2.816446144260992

Epoch: 5| Step: 7
Training loss: 2.83865621259827
Validation loss: 2.8332382134305716

Epoch: 5| Step: 8
Training loss: 2.8262546318923945
Validation loss: 2.7930464171775933

Epoch: 5| Step: 9
Training loss: 2.0813351267225095
Validation loss: 2.7803424618721793

Epoch: 5| Step: 10
Training loss: 1.9355171886519476
Validation loss: 2.7333666558064054

Epoch: 323| Step: 0
Training loss: 2.6142102060126504
Validation loss: 2.7358253708507774

Epoch: 5| Step: 1
Training loss: 2.5864509925528147
Validation loss: 2.7757863062330106

Epoch: 5| Step: 2
Training loss: 2.175699393412239
Validation loss: 2.761556812858921

Epoch: 5| Step: 3
Training loss: 2.5423456650424825
Validation loss: 2.765677056999587

Epoch: 5| Step: 4
Training loss: 3.056855430002224
Validation loss: 2.772887369212844

Epoch: 5| Step: 5
Training loss: 2.2375280367836883
Validation loss: 2.818463003557746

Epoch: 5| Step: 6
Training loss: 2.3581691464624916
Validation loss: 2.7660182540965423

Epoch: 5| Step: 7
Training loss: 2.777218586479538
Validation loss: 2.767589540844686

Epoch: 5| Step: 8
Training loss: 2.294277876728748
Validation loss: 2.771211518921571

Epoch: 5| Step: 9
Training loss: 2.6219997517275018
Validation loss: 2.7700027644598704

Epoch: 5| Step: 10
Training loss: 2.5080005420763323
Validation loss: 2.729043195183249

Epoch: 324| Step: 0
Training loss: 2.3611092162280487
Validation loss: 2.7640714041133236

Epoch: 5| Step: 1
Training loss: 2.1978020178616626
Validation loss: 2.793535374507358

Epoch: 5| Step: 2
Training loss: 2.1624011331349915
Validation loss: 2.718827265027079

Epoch: 5| Step: 3
Training loss: 2.7582880317986236
Validation loss: 2.699287087083101

Epoch: 5| Step: 4
Training loss: 2.4282445026383783
Validation loss: 2.700968026713525

Epoch: 5| Step: 5
Training loss: 2.890211251005617
Validation loss: 2.7645873782553196

Epoch: 5| Step: 6
Training loss: 2.218741403482466
Validation loss: 2.752708611353175

Epoch: 5| Step: 7
Training loss: 2.259193077519323
Validation loss: 2.817125803653773

Epoch: 5| Step: 8
Training loss: 2.9095894280729047
Validation loss: 2.8134111717298995

Epoch: 5| Step: 9
Training loss: 2.2545746815372754
Validation loss: 2.7148053967798944

Epoch: 5| Step: 10
Training loss: 3.027415573744765
Validation loss: 2.759897627106733

Epoch: 325| Step: 0
Training loss: 2.6840140334272697
Validation loss: 2.7478203772900245

Epoch: 5| Step: 1
Training loss: 2.053882861956452
Validation loss: 2.7978143682493197

Epoch: 5| Step: 2
Training loss: 2.3787678394861453
Validation loss: 2.743950771139888

Epoch: 5| Step: 3
Training loss: 2.2922494205154185
Validation loss: 2.771712172501221

Epoch: 5| Step: 4
Training loss: 3.218541258922772
Validation loss: 2.754013187214678

Epoch: 5| Step: 5
Training loss: 2.687409421592005
Validation loss: 2.7193677636719125

Epoch: 5| Step: 6
Training loss: 2.26782099091043
Validation loss: 2.777248049715943

Epoch: 5| Step: 7
Training loss: 2.883159668236636
Validation loss: 2.7802444563055455

Epoch: 5| Step: 8
Training loss: 2.594732535071457
Validation loss: 2.852657006586635

Epoch: 5| Step: 9
Training loss: 2.1244577950271366
Validation loss: 2.738826345025133

Epoch: 5| Step: 10
Training loss: 3.1835922522044022
Validation loss: 2.8031434021259063

Epoch: 326| Step: 0
Training loss: 2.7954297300761213
Validation loss: 2.815252039152656

Epoch: 5| Step: 1
Training loss: 2.3314311471058002
Validation loss: 2.7020233430242806

Epoch: 5| Step: 2
Training loss: 2.685057483817851
Validation loss: 2.7980742888322627

Epoch: 5| Step: 3
Training loss: 2.1953181473737415
Validation loss: 2.7296020844946933

Epoch: 5| Step: 4
Training loss: 2.7771452713450726
Validation loss: 2.7691010833698573

Epoch: 5| Step: 5
Training loss: 2.3979128782594277
Validation loss: 2.7551248682267104

Epoch: 5| Step: 6
Training loss: 3.0384090868500135
Validation loss: 2.762187279539635

Epoch: 5| Step: 7
Training loss: 2.0267871835077913
Validation loss: 2.753924177418794

Epoch: 5| Step: 8
Training loss: 2.394335790127402
Validation loss: 2.78315157727625

Epoch: 5| Step: 9
Training loss: 2.499534754377759
Validation loss: 2.801798346301498

Epoch: 5| Step: 10
Training loss: 2.871676970950647
Validation loss: 2.747277486717477

Epoch: 327| Step: 0
Training loss: 2.955790613462795
Validation loss: 2.7163477718467095

Epoch: 5| Step: 1
Training loss: 2.6133390913465218
Validation loss: 2.755109522396256

Epoch: 5| Step: 2
Training loss: 2.2439971957673692
Validation loss: 2.7494296286933477

Epoch: 5| Step: 3
Training loss: 2.3770197261108947
Validation loss: 2.776353141938404

Epoch: 5| Step: 4
Training loss: 2.61694890543146
Validation loss: 2.7426120319704306

Epoch: 5| Step: 5
Training loss: 2.296314196989686
Validation loss: 2.753128501177794

Epoch: 5| Step: 6
Training loss: 2.6507871214568044
Validation loss: 2.785510892958036

Epoch: 5| Step: 7
Training loss: 2.429174829101808
Validation loss: 2.8171367748327234

Epoch: 5| Step: 8
Training loss: 2.788934784858171
Validation loss: 2.7582850548269326

Epoch: 5| Step: 9
Training loss: 2.266001176845585
Validation loss: 2.713641835951054

Epoch: 5| Step: 10
Training loss: 3.2506237898583956
Validation loss: 2.754480355362301

Epoch: 328| Step: 0
Training loss: 2.3977047673869887
Validation loss: 2.727040597835292

Epoch: 5| Step: 1
Training loss: 2.521838647138418
Validation loss: 2.782995091543095

Epoch: 5| Step: 2
Training loss: 3.17175758783421
Validation loss: 2.744474034714976

Epoch: 5| Step: 3
Training loss: 2.8037887450834957
Validation loss: 2.8036828697324587

Epoch: 5| Step: 4
Training loss: 2.9137278510405187
Validation loss: 2.74432326335164

Epoch: 5| Step: 5
Training loss: 2.3401290388474374
Validation loss: 2.747770020575043

Epoch: 5| Step: 6
Training loss: 2.6076113285572897
Validation loss: 2.8763088655045306

Epoch: 5| Step: 7
Training loss: 2.7080332565350367
Validation loss: 2.7207654027705312

Epoch: 5| Step: 8
Training loss: 2.2835608496630364
Validation loss: 2.6885590294626707

Epoch: 5| Step: 9
Training loss: 2.200569564610809
Validation loss: 2.7339790388035117

Epoch: 5| Step: 10
Training loss: 1.773654201896546
Validation loss: 2.7709914100762427

Epoch: 329| Step: 0
Training loss: 1.6732632586382634
Validation loss: 2.7148880762610093

Epoch: 5| Step: 1
Training loss: 2.0608914200242077
Validation loss: 2.814864620518338

Epoch: 5| Step: 2
Training loss: 2.7338578961381397
Validation loss: 2.776638881403647

Epoch: 5| Step: 3
Training loss: 3.0828596387025016
Validation loss: 2.7584351392719713

Epoch: 5| Step: 4
Training loss: 2.818308363867232
Validation loss: 2.7971281256874465

Epoch: 5| Step: 5
Training loss: 2.3598535317697684
Validation loss: 2.781735987855832

Epoch: 5| Step: 6
Training loss: 2.621399362771843
Validation loss: 2.7150901873214623

Epoch: 5| Step: 7
Training loss: 2.759366988692097
Validation loss: 2.7835302100044546

Epoch: 5| Step: 8
Training loss: 2.684140523100049
Validation loss: 2.7376369613434046

Epoch: 5| Step: 9
Training loss: 2.0545938564761603
Validation loss: 2.7326006020018077

Epoch: 5| Step: 10
Training loss: 2.765676293193788
Validation loss: 2.7929914695434683

Epoch: 330| Step: 0
Training loss: 2.7870439335946724
Validation loss: 2.7427595212888654

Epoch: 5| Step: 1
Training loss: 2.1196395357046023
Validation loss: 2.772222135867433

Epoch: 5| Step: 2
Training loss: 2.8878982467478553
Validation loss: 2.7502832872759004

Epoch: 5| Step: 3
Training loss: 2.324183359597943
Validation loss: 2.7477270336795994

Epoch: 5| Step: 4
Training loss: 2.0481244416129893
Validation loss: 2.7762355344651017

Epoch: 5| Step: 5
Training loss: 2.865717789240734
Validation loss: 2.81637184133767

Epoch: 5| Step: 6
Training loss: 2.6099382352280527
Validation loss: 2.8545642633035357

Epoch: 5| Step: 7
Training loss: 1.575612097584829
Validation loss: 2.76387762578349

Epoch: 5| Step: 8
Training loss: 3.005429758325182
Validation loss: 2.6807054126417174

Epoch: 5| Step: 9
Training loss: 2.4399830812899506
Validation loss: 2.7691958339288822

Epoch: 5| Step: 10
Training loss: 3.1872091721644042
Validation loss: 2.7963373791826887

Epoch: 331| Step: 0
Training loss: 2.363688586731845
Validation loss: 2.7606082013193

Epoch: 5| Step: 1
Training loss: 3.137574189665369
Validation loss: 2.7720515650784576

Epoch: 5| Step: 2
Training loss: 2.289827707130981
Validation loss: 2.721445420498556

Epoch: 5| Step: 3
Training loss: 2.280368373291411
Validation loss: 2.7560712817265904

Epoch: 5| Step: 4
Training loss: 2.4195137572649257
Validation loss: 2.7971489573291906

Epoch: 5| Step: 5
Training loss: 2.5572182721847305
Validation loss: 2.8174220823739247

Epoch: 5| Step: 6
Training loss: 2.169940114051947
Validation loss: 2.7289228592664587

Epoch: 5| Step: 7
Training loss: 3.272878230351011
Validation loss: 2.7235602113768196

Epoch: 5| Step: 8
Training loss: 2.577564340374838
Validation loss: 2.7362005905789957

Epoch: 5| Step: 9
Training loss: 2.5430929736663543
Validation loss: 2.778862472598455

Epoch: 5| Step: 10
Training loss: 2.8818584403772394
Validation loss: 2.7785392290464235

Epoch: 332| Step: 0
Training loss: 2.8010868347392432
Validation loss: 2.7861676304939826

Epoch: 5| Step: 1
Training loss: 2.6119562048519214
Validation loss: 2.813567097903283

Epoch: 5| Step: 2
Training loss: 2.651056665604186
Validation loss: 2.758024628470786

Epoch: 5| Step: 3
Training loss: 2.894211806818404
Validation loss: 2.8025777020576155

Epoch: 5| Step: 4
Training loss: 2.3033025168507195
Validation loss: 2.7334292734367702

Epoch: 5| Step: 5
Training loss: 2.6451024124711955
Validation loss: 2.7244051095124853

Epoch: 5| Step: 6
Training loss: 2.693621384101461
Validation loss: 2.7710145947621743

Epoch: 5| Step: 7
Training loss: 2.02531269626178
Validation loss: 2.672691617171279

Epoch: 5| Step: 8
Training loss: 2.302958522043797
Validation loss: 2.805912627396443

Epoch: 5| Step: 9
Training loss: 2.5949481816345874
Validation loss: 2.805995744248711

Epoch: 5| Step: 10
Training loss: 2.4910063141781458
Validation loss: 2.7336029603553134

Epoch: 333| Step: 0
Training loss: 2.45977368158866
Validation loss: 2.7608822069936663

Epoch: 5| Step: 1
Training loss: 2.8667139810900983
Validation loss: 2.7499438025585943

Epoch: 5| Step: 2
Training loss: 2.5553755927183857
Validation loss: 2.7371296301174906

Epoch: 5| Step: 3
Training loss: 2.1798019105697954
Validation loss: 2.8138029774209543

Epoch: 5| Step: 4
Training loss: 2.134112063474876
Validation loss: 2.772628540950598

Epoch: 5| Step: 5
Training loss: 2.678781962522216
Validation loss: 2.7554517963642327

Epoch: 5| Step: 6
Training loss: 1.9067068959484819
Validation loss: 2.6396972760506965

Epoch: 5| Step: 7
Training loss: 2.858862158639701
Validation loss: 2.6890106782112646

Epoch: 5| Step: 8
Training loss: 2.8741742482412107
Validation loss: 2.7580867048741995

Epoch: 5| Step: 9
Training loss: 2.8749023089189722
Validation loss: 2.7342536057862583

Epoch: 5| Step: 10
Training loss: 2.3723069030195605
Validation loss: 2.768437565489925

Epoch: 334| Step: 0
Training loss: 2.715491874776789
Validation loss: 2.773770616588372

Epoch: 5| Step: 1
Training loss: 2.0211668493074137
Validation loss: 2.7551054858666255

Epoch: 5| Step: 2
Training loss: 2.6577339963627593
Validation loss: 2.7606753326594675

Epoch: 5| Step: 3
Training loss: 1.8238247235516245
Validation loss: 2.7241023796586616

Epoch: 5| Step: 4
Training loss: 1.860434863210487
Validation loss: 2.790017236857839

Epoch: 5| Step: 5
Training loss: 2.874513667893109
Validation loss: 2.721738591601269

Epoch: 5| Step: 6
Training loss: 2.915511765483942
Validation loss: 2.7588119678089114

Epoch: 5| Step: 7
Training loss: 2.1660845292382236
Validation loss: 2.779829788359098

Epoch: 5| Step: 8
Training loss: 3.086769629203711
Validation loss: 2.7576858215789284

Epoch: 5| Step: 9
Training loss: 2.694893978630846
Validation loss: 2.7790989020554244

Epoch: 5| Step: 10
Training loss: 2.849672961293651
Validation loss: 2.761225235585185

Epoch: 335| Step: 0
Training loss: 2.19676144389181
Validation loss: 2.775653936628077

Epoch: 5| Step: 1
Training loss: 2.7044825149509726
Validation loss: 2.735487548633525

Epoch: 5| Step: 2
Training loss: 2.311998467573562
Validation loss: 2.754524506343293

Epoch: 5| Step: 3
Training loss: 3.0606317855264304
Validation loss: 2.7000031955856563

Epoch: 5| Step: 4
Training loss: 2.2588662193304576
Validation loss: 2.7477907841783837

Epoch: 5| Step: 5
Training loss: 2.614433730102077
Validation loss: 2.7334750708855595

Epoch: 5| Step: 6
Training loss: 3.044400976231145
Validation loss: 2.7834216593545658

Epoch: 5| Step: 7
Training loss: 3.0196638978787598
Validation loss: 2.7496500165445754

Epoch: 5| Step: 8
Training loss: 2.5179977126531536
Validation loss: 2.7536171684547566

Epoch: 5| Step: 9
Training loss: 2.276627337933821
Validation loss: 2.7616380054094796

Epoch: 5| Step: 10
Training loss: 1.7842551196124963
Validation loss: 2.7666849392854482

Epoch: 336| Step: 0
Training loss: 2.85174509796366
Validation loss: 2.804535135570655

Epoch: 5| Step: 1
Training loss: 2.470721459603414
Validation loss: 2.8297667999090246

Epoch: 5| Step: 2
Training loss: 2.6370594397953324
Validation loss: 2.7395652431335415

Epoch: 5| Step: 3
Training loss: 2.0625478565559385
Validation loss: 2.8171724982095956

Epoch: 5| Step: 4
Training loss: 2.5299724604498692
Validation loss: 2.787191324292333

Epoch: 5| Step: 5
Training loss: 2.7332123818812533
Validation loss: 2.7216380028660554

Epoch: 5| Step: 6
Training loss: 2.365393232433662
Validation loss: 2.803050510636201

Epoch: 5| Step: 7
Training loss: 2.229768178719227
Validation loss: 2.734269276814981

Epoch: 5| Step: 8
Training loss: 2.139498114691802
Validation loss: 2.738325582587211

Epoch: 5| Step: 9
Training loss: 2.8023022042675856
Validation loss: 2.746338702165618

Epoch: 5| Step: 10
Training loss: 2.5490331574622163
Validation loss: 2.713133550837857

Epoch: 337| Step: 0
Training loss: 2.358613958837633
Validation loss: 2.7756229731254227

Epoch: 5| Step: 1
Training loss: 2.4353070297776966
Validation loss: 2.742453446165821

Epoch: 5| Step: 2
Training loss: 2.9733252355297077
Validation loss: 2.7722186633907904

Epoch: 5| Step: 3
Training loss: 2.485064908567275
Validation loss: 2.739197151261556

Epoch: 5| Step: 4
Training loss: 2.0885384449414706
Validation loss: 2.755399679229712

Epoch: 5| Step: 5
Training loss: 2.127546579678093
Validation loss: 2.7570555966334633

Epoch: 5| Step: 6
Training loss: 2.3098585146556165
Validation loss: 2.7396717950138743

Epoch: 5| Step: 7
Training loss: 3.210424526105135
Validation loss: 2.734424726792883

Epoch: 5| Step: 8
Training loss: 2.0957844657079794
Validation loss: 2.7715879377006103

Epoch: 5| Step: 9
Training loss: 2.2970980581329083
Validation loss: 2.7122596702682356

Epoch: 5| Step: 10
Training loss: 3.3351428047958227
Validation loss: 2.8095671152132624

Epoch: 338| Step: 0
Training loss: 2.3933068485264513
Validation loss: 2.7481070190493107

Epoch: 5| Step: 1
Training loss: 2.4587604884363685
Validation loss: 2.7159667024977

Epoch: 5| Step: 2
Training loss: 1.8813669821021082
Validation loss: 2.767271441327427

Epoch: 5| Step: 3
Training loss: 2.0411476202085215
Validation loss: 2.75749085726009

Epoch: 5| Step: 4
Training loss: 2.7861371767348837
Validation loss: 2.72926789970926

Epoch: 5| Step: 5
Training loss: 2.2940920624090277
Validation loss: 2.681638464445705

Epoch: 5| Step: 6
Training loss: 2.8631821598325353
Validation loss: 2.781345882424488

Epoch: 5| Step: 7
Training loss: 2.3964962139008206
Validation loss: 2.7595657408503826

Epoch: 5| Step: 8
Training loss: 2.774378141541925
Validation loss: 2.7872327974754745

Epoch: 5| Step: 9
Training loss: 2.59278300080628
Validation loss: 2.739067779308116

Epoch: 5| Step: 10
Training loss: 2.746848381182573
Validation loss: 2.7330333346870948

Epoch: 339| Step: 0
Training loss: 2.382557839715255
Validation loss: 2.7527859681388485

Epoch: 5| Step: 1
Training loss: 2.154633731738259
Validation loss: 2.8102610628592126

Epoch: 5| Step: 2
Training loss: 2.7948961983173715
Validation loss: 2.7565551869190643

Epoch: 5| Step: 3
Training loss: 2.947573009360042
Validation loss: 2.831048063448098

Epoch: 5| Step: 4
Training loss: 1.90798820917417
Validation loss: 2.7703772524251002

Epoch: 5| Step: 5
Training loss: 1.955315056314942
Validation loss: 2.7261994278779187

Epoch: 5| Step: 6
Training loss: 3.145457180010063
Validation loss: 2.705280496086358

Epoch: 5| Step: 7
Training loss: 2.8816941322384206
Validation loss: 2.7871470496775856

Epoch: 5| Step: 8
Training loss: 2.514858342270883
Validation loss: 2.7934235003894248

Epoch: 5| Step: 9
Training loss: 2.591990598037528
Validation loss: 2.819592548497875

Epoch: 5| Step: 10
Training loss: 2.2708007623512287
Validation loss: 2.7231578387528677

Epoch: 340| Step: 0
Training loss: 3.125531876123965
Validation loss: 2.757960087384088

Epoch: 5| Step: 1
Training loss: 2.3660132388133914
Validation loss: 2.7465112264059

Epoch: 5| Step: 2
Training loss: 2.4089473122123564
Validation loss: 2.7782812862660293

Epoch: 5| Step: 3
Training loss: 2.7372471139537073
Validation loss: 2.829145369935187

Epoch: 5| Step: 4
Training loss: 2.029648251994653
Validation loss: 2.7382770098448197

Epoch: 5| Step: 5
Training loss: 2.5653848923691926
Validation loss: 2.744503058293262

Epoch: 5| Step: 6
Training loss: 2.3698274602736977
Validation loss: 2.779137056153639

Epoch: 5| Step: 7
Training loss: 3.0597646525515496
Validation loss: 2.844572566498982

Epoch: 5| Step: 8
Training loss: 2.6949524569873886
Validation loss: 2.7741968368206487

Epoch: 5| Step: 9
Training loss: 2.2760060276293594
Validation loss: 2.7544880728536705

Epoch: 5| Step: 10
Training loss: 1.7819934431227287
Validation loss: 2.739185441136865

Epoch: 341| Step: 0
Training loss: 2.9111500112184845
Validation loss: 2.8229279689125892

Epoch: 5| Step: 1
Training loss: 1.7974047336083505
Validation loss: 2.756760843467258

Epoch: 5| Step: 2
Training loss: 2.7908882555185293
Validation loss: 2.7528511119990355

Epoch: 5| Step: 3
Training loss: 3.0023254282797063
Validation loss: 2.7929975064563703

Epoch: 5| Step: 4
Training loss: 2.672697687928957
Validation loss: 2.7741908661916903

Epoch: 5| Step: 5
Training loss: 2.456793308108081
Validation loss: 2.7383800533997795

Epoch: 5| Step: 6
Training loss: 2.282745915981705
Validation loss: 2.7381631102099053

Epoch: 5| Step: 7
Training loss: 2.6481135797603237
Validation loss: 2.7850097742916398

Epoch: 5| Step: 8
Training loss: 2.5691504358931097
Validation loss: 2.7634721769129946

Epoch: 5| Step: 9
Training loss: 2.278226547175752
Validation loss: 2.747300322835485

Epoch: 5| Step: 10
Training loss: 2.1594856421560156
Validation loss: 2.7345651464959726

Epoch: 342| Step: 0
Training loss: 2.5554248550642944
Validation loss: 2.788937664768454

Epoch: 5| Step: 1
Training loss: 2.288863762570503
Validation loss: 2.752431661396733

Epoch: 5| Step: 2
Training loss: 2.3759185620874876
Validation loss: 2.795721862555306

Epoch: 5| Step: 3
Training loss: 2.2302443730523107
Validation loss: 2.7283150656919823

Epoch: 5| Step: 4
Training loss: 2.5012391833939365
Validation loss: 2.825541214604554

Epoch: 5| Step: 5
Training loss: 2.4890358827057373
Validation loss: 2.7113786039277574

Epoch: 5| Step: 6
Training loss: 2.2248479298262276
Validation loss: 2.6780275716417226

Epoch: 5| Step: 7
Training loss: 2.899625056791085
Validation loss: 2.7616434526941647

Epoch: 5| Step: 8
Training loss: 2.7657112065042515
Validation loss: 2.742161253803621

Epoch: 5| Step: 9
Training loss: 2.8718488258273207
Validation loss: 2.8128224852248485

Epoch: 5| Step: 10
Training loss: 2.417300426210077
Validation loss: 2.798575265748599

Epoch: 343| Step: 0
Training loss: 2.4570010718598314
Validation loss: 2.75882791099598

Epoch: 5| Step: 1
Training loss: 2.4529689083127257
Validation loss: 2.816155425145389

Epoch: 5| Step: 2
Training loss: 2.5303454254522117
Validation loss: 2.7739801634220265

Epoch: 5| Step: 3
Training loss: 2.54579963682593
Validation loss: 2.769298272276

Epoch: 5| Step: 4
Training loss: 3.200598934866741
Validation loss: 2.741696913369964

Epoch: 5| Step: 5
Training loss: 2.4490108127939414
Validation loss: 2.7395564430090262

Epoch: 5| Step: 6
Training loss: 1.9280102193292474
Validation loss: 2.7772007678914803

Epoch: 5| Step: 7
Training loss: 2.9383460916324045
Validation loss: 2.7129889885834317

Epoch: 5| Step: 8
Training loss: 2.3248298418680315
Validation loss: 2.7425412522277828

Epoch: 5| Step: 9
Training loss: 1.929528975056419
Validation loss: 2.808143472033572

Epoch: 5| Step: 10
Training loss: 2.745474125506945
Validation loss: 2.7865893528178267

Epoch: 344| Step: 0
Training loss: 2.9401938889595858
Validation loss: 2.7299558279319394

Epoch: 5| Step: 1
Training loss: 2.7122784466949565
Validation loss: 2.6792148725902076

Epoch: 5| Step: 2
Training loss: 2.1288982986161717
Validation loss: 2.7123467978396714

Epoch: 5| Step: 3
Training loss: 3.189488706839949
Validation loss: 2.7434504319810316

Epoch: 5| Step: 4
Training loss: 2.506945879211673
Validation loss: 2.759206920431521

Epoch: 5| Step: 5
Training loss: 1.8895310949516186
Validation loss: 2.8152285549305742

Epoch: 5| Step: 6
Training loss: 2.1597953067146753
Validation loss: 2.7629295772378195

Epoch: 5| Step: 7
Training loss: 2.8076573536529064
Validation loss: 2.7784139126959158

Epoch: 5| Step: 8
Training loss: 2.4161703542813786
Validation loss: 2.7249048042358948

Epoch: 5| Step: 9
Training loss: 2.0416064999596495
Validation loss: 2.7397703798384514

Epoch: 5| Step: 10
Training loss: 2.2194661878471096
Validation loss: 2.826649923563287

Epoch: 345| Step: 0
Training loss: 1.6685049012740603
Validation loss: 2.7549061848644345

Epoch: 5| Step: 1
Training loss: 1.8812925289580964
Validation loss: 2.721192600364381

Epoch: 5| Step: 2
Training loss: 2.7201719402215914
Validation loss: 2.773064963639179

Epoch: 5| Step: 3
Training loss: 2.900661057731216
Validation loss: 2.7025096391334804

Epoch: 5| Step: 4
Training loss: 2.465354612582882
Validation loss: 2.7778984376549833

Epoch: 5| Step: 5
Training loss: 2.9242217895263725
Validation loss: 2.711042854569557

Epoch: 5| Step: 6
Training loss: 2.3680261316146334
Validation loss: 2.7942149494798993

Epoch: 5| Step: 7
Training loss: 3.0255082010924923
Validation loss: 2.7956551766305373

Epoch: 5| Step: 8
Training loss: 2.534171032017974
Validation loss: 2.7762754953216966

Epoch: 5| Step: 9
Training loss: 3.033137726677465
Validation loss: 2.8039310854496033

Epoch: 5| Step: 10
Training loss: 2.320218684807708
Validation loss: 2.778513717443689

Epoch: 346| Step: 0
Training loss: 2.5021012059149634
Validation loss: 2.75681568931786

Epoch: 5| Step: 1
Training loss: 2.2304906626892644
Validation loss: 2.6982098947948705

Epoch: 5| Step: 2
Training loss: 2.0113142180874215
Validation loss: 2.7527394973324295

Epoch: 5| Step: 3
Training loss: 3.3365912411066314
Validation loss: 2.7550499471592946

Epoch: 5| Step: 4
Training loss: 2.499948214948281
Validation loss: 2.7353204192638634

Epoch: 5| Step: 5
Training loss: 2.5494931109900727
Validation loss: 2.7887684656836487

Epoch: 5| Step: 6
Training loss: 2.5183074107961874
Validation loss: 2.762099168939752

Epoch: 5| Step: 7
Training loss: 1.7984219733528284
Validation loss: 2.7062193537560786

Epoch: 5| Step: 8
Training loss: 2.049754556058307
Validation loss: 2.765074062145096

Epoch: 5| Step: 9
Training loss: 3.1499640689798762
Validation loss: 2.7530701057295475

Epoch: 5| Step: 10
Training loss: 2.5345894719261204
Validation loss: 2.750230287323341

Epoch: 347| Step: 0
Training loss: 3.0843630093821672
Validation loss: 2.7957204650667515

Epoch: 5| Step: 1
Training loss: 2.6103036107583604
Validation loss: 2.797213659168063

Epoch: 5| Step: 2
Training loss: 2.42160544587384
Validation loss: 2.774542159610287

Epoch: 5| Step: 3
Training loss: 2.1177213214026276
Validation loss: 2.763925000103566

Epoch: 5| Step: 4
Training loss: 2.655234198720507
Validation loss: 2.761973663585293

Epoch: 5| Step: 5
Training loss: 2.159863305534911
Validation loss: 2.741703259588895

Epoch: 5| Step: 6
Training loss: 3.1037067524926947
Validation loss: 2.7619695498372487

Epoch: 5| Step: 7
Training loss: 2.0069919200709863
Validation loss: 2.746579189533327

Epoch: 5| Step: 8
Training loss: 2.731474989783361
Validation loss: 2.71355314340708

Epoch: 5| Step: 9
Training loss: 2.334432978593082
Validation loss: 2.8102627897344474

Epoch: 5| Step: 10
Training loss: 2.3266704547089763
Validation loss: 2.7569418925639484

Epoch: 348| Step: 0
Training loss: 2.750562436935839
Validation loss: 2.757007932250096

Epoch: 5| Step: 1
Training loss: 2.3870305982976996
Validation loss: 2.7211634421553086

Epoch: 5| Step: 2
Training loss: 2.1992260134968307
Validation loss: 2.7144528536998846

Epoch: 5| Step: 3
Training loss: 2.9949793129335474
Validation loss: 2.7051752213038136

Epoch: 5| Step: 4
Training loss: 2.187816705938077
Validation loss: 2.7888305646674256

Epoch: 5| Step: 5
Training loss: 2.688407123859209
Validation loss: 2.7921636968817225

Epoch: 5| Step: 6
Training loss: 2.2984229859516883
Validation loss: 2.750917291028743

Epoch: 5| Step: 7
Training loss: 2.021532376958759
Validation loss: 2.718355794523485

Epoch: 5| Step: 8
Training loss: 2.651777923411071
Validation loss: 2.754275720405745

Epoch: 5| Step: 9
Training loss: 3.1582588374898153
Validation loss: 2.7218692336661787

Epoch: 5| Step: 10
Training loss: 2.9641926368374323
Validation loss: 2.7634252531158277

Epoch: 349| Step: 0
Training loss: 2.401387242888497
Validation loss: 2.803337481335198

Epoch: 5| Step: 1
Training loss: 2.2753803564011856
Validation loss: 2.7082867428264277

Epoch: 5| Step: 2
Training loss: 3.041818815284219
Validation loss: 2.776051009884933

Epoch: 5| Step: 3
Training loss: 2.637486867284396
Validation loss: 2.7641547802382807

Epoch: 5| Step: 4
Training loss: 2.108079978989161
Validation loss: 2.790555004110218

Epoch: 5| Step: 5
Training loss: 2.6369626984950685
Validation loss: 2.714739943395276

Epoch: 5| Step: 6
Training loss: 2.6745018789384982
Validation loss: 2.8058897246725842

Epoch: 5| Step: 7
Training loss: 2.1312814883593605
Validation loss: 2.819743299228347

Epoch: 5| Step: 8
Training loss: 2.268767394112148
Validation loss: 2.8004409918136677

Epoch: 5| Step: 9
Training loss: 2.3732349462510918
Validation loss: 2.738821975604613

Epoch: 5| Step: 10
Training loss: 2.76590179954748
Validation loss: 2.793389427193451

Epoch: 350| Step: 0
Training loss: 2.9001191805323283
Validation loss: 2.722295843684063

Epoch: 5| Step: 1
Training loss: 2.7716685496691076
Validation loss: 2.754335954617148

Epoch: 5| Step: 2
Training loss: 2.237353706905157
Validation loss: 2.778275992482275

Epoch: 5| Step: 3
Training loss: 1.8242912196400514
Validation loss: 2.8124579660061535

Epoch: 5| Step: 4
Training loss: 2.07327013181091
Validation loss: 2.7460120390296576

Epoch: 5| Step: 5
Training loss: 2.6099587889593043
Validation loss: 2.713064522160015

Epoch: 5| Step: 6
Training loss: 2.656735633886638
Validation loss: 2.7893835884653844

Epoch: 5| Step: 7
Training loss: 3.2997129257643087
Validation loss: 2.774918172779677

Epoch: 5| Step: 8
Training loss: 2.182576333160708
Validation loss: 2.797164404300598

Epoch: 5| Step: 9
Training loss: 2.0098345478721766
Validation loss: 2.743545529242148

Epoch: 5| Step: 10
Training loss: 2.4391464150538043
Validation loss: 2.7877907352918054

Epoch: 351| Step: 0
Training loss: 2.596322220453042
Validation loss: 2.7850118040243874

Epoch: 5| Step: 1
Training loss: 1.9043678622586202
Validation loss: 2.752729329323368

Epoch: 5| Step: 2
Training loss: 2.9992428459914606
Validation loss: 2.699404920609012

Epoch: 5| Step: 3
Training loss: 2.64405861354155
Validation loss: 2.7627836926706455

Epoch: 5| Step: 4
Training loss: 2.6594150311587095
Validation loss: 2.7258143636335395

Epoch: 5| Step: 5
Training loss: 3.1563335445413516
Validation loss: 2.7832398513187115

Epoch: 5| Step: 6
Training loss: 2.4639163441390473
Validation loss: 2.757448255729732

Epoch: 5| Step: 7
Training loss: 2.9109881754470894
Validation loss: 2.7204839796620415

Epoch: 5| Step: 8
Training loss: 1.9435033390260852
Validation loss: 2.7711062269580613

Epoch: 5| Step: 9
Training loss: 2.169422658772098
Validation loss: 2.769469842973851

Epoch: 5| Step: 10
Training loss: 1.6852857402910115
Validation loss: 2.7130192173854595

Epoch: 352| Step: 0
Training loss: 2.604663364090334
Validation loss: 2.783406430849722

Epoch: 5| Step: 1
Training loss: 2.4648236305636875
Validation loss: 2.763553638799597

Epoch: 5| Step: 2
Training loss: 2.228387131860651
Validation loss: 2.7697705418694927

Epoch: 5| Step: 3
Training loss: 2.713782936152861
Validation loss: 2.772016369553801

Epoch: 5| Step: 4
Training loss: 2.810399606331033
Validation loss: 2.706950313685972

Epoch: 5| Step: 5
Training loss: 1.7973744900620001
Validation loss: 2.7124422587696664

Epoch: 5| Step: 6
Training loss: 2.0130976719438847
Validation loss: 2.844784929308215

Epoch: 5| Step: 7
Training loss: 2.759409844425826
Validation loss: 2.758041285429171

Epoch: 5| Step: 8
Training loss: 3.2660525101448443
Validation loss: 2.7555283160334776

Epoch: 5| Step: 9
Training loss: 2.056154604846922
Validation loss: 2.796205930186029

Epoch: 5| Step: 10
Training loss: 2.553936209142639
Validation loss: 2.732379975195894

Epoch: 353| Step: 0
Training loss: 2.299352231235696
Validation loss: 2.764949027469494

Epoch: 5| Step: 1
Training loss: 2.9939789750170656
Validation loss: 2.7210138061662565

Epoch: 5| Step: 2
Training loss: 1.6726962060267399
Validation loss: 2.772680870049962

Epoch: 5| Step: 3
Training loss: 2.510583695254003
Validation loss: 2.777744134029247

Epoch: 5| Step: 4
Training loss: 3.0766779407640445
Validation loss: 2.759248858834449

Epoch: 5| Step: 5
Training loss: 2.8483227864161877
Validation loss: 2.7010907536227324

Epoch: 5| Step: 6
Training loss: 2.355724415734613
Validation loss: 2.7261309736050925

Epoch: 5| Step: 7
Training loss: 2.5856724168147087
Validation loss: 2.775712920018111

Epoch: 5| Step: 8
Training loss: 2.33403514343974
Validation loss: 2.78479793984269

Epoch: 5| Step: 9
Training loss: 2.2017917792526545
Validation loss: 2.7830459789275728

Epoch: 5| Step: 10
Training loss: 2.055504698023975
Validation loss: 2.7779967705393873

Epoch: 354| Step: 0
Training loss: 2.0131430315348884
Validation loss: 2.7268344451938473

Epoch: 5| Step: 1
Training loss: 2.9551092676915656
Validation loss: 2.781975976210386

Epoch: 5| Step: 2
Training loss: 2.4594072700913574
Validation loss: 2.7620285015262858

Epoch: 5| Step: 3
Training loss: 2.275233657072368
Validation loss: 2.7572779866759425

Epoch: 5| Step: 4
Training loss: 2.537234919189835
Validation loss: 2.8185848329847643

Epoch: 5| Step: 5
Training loss: 2.7720421948159606
Validation loss: 2.761630787369399

Epoch: 5| Step: 6
Training loss: 3.131751434927571
Validation loss: 2.7659009533119927

Epoch: 5| Step: 7
Training loss: 2.2611504929612374
Validation loss: 2.7152388014881463

Epoch: 5| Step: 8
Training loss: 2.6010981881433834
Validation loss: 2.7356680133065936

Epoch: 5| Step: 9
Training loss: 2.44614725215837
Validation loss: 2.6989291567787186

Epoch: 5| Step: 10
Training loss: 1.5897237746500177
Validation loss: 2.75910979942816

Epoch: 355| Step: 0
Training loss: 1.6528648474631833
Validation loss: 2.739003210844802

Epoch: 5| Step: 1
Training loss: 2.3329080693674213
Validation loss: 2.7859503532081287

Epoch: 5| Step: 2
Training loss: 2.484799810593273
Validation loss: 2.779450752074964

Epoch: 5| Step: 3
Training loss: 2.288257652674185
Validation loss: 2.6595765451123383

Epoch: 5| Step: 4
Training loss: 2.2731008378706865
Validation loss: 2.7430532536865426

Epoch: 5| Step: 5
Training loss: 2.0073703620448966
Validation loss: 2.771964925935604

Epoch: 5| Step: 6
Training loss: 2.3157867581064098
Validation loss: 2.748575772135234

Epoch: 5| Step: 7
Training loss: 3.1801742443594665
Validation loss: 2.757772793118396

Epoch: 5| Step: 8
Training loss: 3.196849499970849
Validation loss: 2.767933989311933

Epoch: 5| Step: 9
Training loss: 2.974120412352676
Validation loss: 2.697114203111792

Epoch: 5| Step: 10
Training loss: 2.1019165421531376
Validation loss: 2.816473486813733

Epoch: 356| Step: 0
Training loss: 2.4587946205764193
Validation loss: 2.7432965886955323

Epoch: 5| Step: 1
Training loss: 2.6323685540605326
Validation loss: 2.7647266934761374

Epoch: 5| Step: 2
Training loss: 1.8525850072139356
Validation loss: 2.72203578562381

Epoch: 5| Step: 3
Training loss: 1.9711060731119319
Validation loss: 2.77084873302201

Epoch: 5| Step: 4
Training loss: 2.9192591090424878
Validation loss: 2.779421788128533

Epoch: 5| Step: 5
Training loss: 2.2836890572370057
Validation loss: 2.8534025374929137

Epoch: 5| Step: 6
Training loss: 2.520697272125595
Validation loss: 2.818271860763945

Epoch: 5| Step: 7
Training loss: 2.2596805856541162
Validation loss: 2.814776060434808

Epoch: 5| Step: 8
Training loss: 2.9773976513546176
Validation loss: 2.790707293100213

Epoch: 5| Step: 9
Training loss: 3.114131490705916
Validation loss: 2.7424634213796235

Epoch: 5| Step: 10
Training loss: 2.220486673158348
Validation loss: 2.7529652960580684

Epoch: 357| Step: 0
Training loss: 2.927364639032589
Validation loss: 2.788167482025564

Epoch: 5| Step: 1
Training loss: 2.2369511831633058
Validation loss: 2.8284172514898

Epoch: 5| Step: 2
Training loss: 2.5057027623628843
Validation loss: 2.788135100808469

Epoch: 5| Step: 3
Training loss: 2.862567391081203
Validation loss: 2.7902854517094684

Epoch: 5| Step: 4
Training loss: 2.588705373662132
Validation loss: 2.7335726103008207

Epoch: 5| Step: 5
Training loss: 2.305764156949523
Validation loss: 2.7451467711443067

Epoch: 5| Step: 6
Training loss: 3.3621249986021615
Validation loss: 2.7423406136979733

Epoch: 5| Step: 7
Training loss: 2.294250026324196
Validation loss: 2.7916532401978955

Epoch: 5| Step: 8
Training loss: 2.2385919431848316
Validation loss: 2.849141939802235

Epoch: 5| Step: 9
Training loss: 2.1167490600209002
Validation loss: 2.7652623443011586

Epoch: 5| Step: 10
Training loss: 2.285963858024197
Validation loss: 2.7856673579241362

Epoch: 358| Step: 0
Training loss: 1.8765782389747059
Validation loss: 2.7249617748998287

Epoch: 5| Step: 1
Training loss: 2.748931937448145
Validation loss: 2.7161955166375535

Epoch: 5| Step: 2
Training loss: 2.205087315394101
Validation loss: 2.7661113752800532

Epoch: 5| Step: 3
Training loss: 2.8570623999575115
Validation loss: 2.8000287288885404

Epoch: 5| Step: 4
Training loss: 2.9662892633758013
Validation loss: 2.7751818590217403

Epoch: 5| Step: 5
Training loss: 2.1881807630374817
Validation loss: 2.7625410255181357

Epoch: 5| Step: 6
Training loss: 2.6133722081342126
Validation loss: 2.7484640687283988

Epoch: 5| Step: 7
Training loss: 2.611483515793136
Validation loss: 2.769543796349303

Epoch: 5| Step: 8
Training loss: 2.2440695489927562
Validation loss: 2.7660517107593283

Epoch: 5| Step: 9
Training loss: 2.351442352976951
Validation loss: 2.7709143219136645

Epoch: 5| Step: 10
Training loss: 2.9381375534026386
Validation loss: 2.7425792110363902

Epoch: 359| Step: 0
Training loss: 2.1934252463255413
Validation loss: 2.772273422592491

Epoch: 5| Step: 1
Training loss: 1.9995146997077902
Validation loss: 2.709519921635322

Epoch: 5| Step: 2
Training loss: 2.2034983217195334
Validation loss: 2.6855399044539303

Epoch: 5| Step: 3
Training loss: 1.9534937396060248
Validation loss: 2.7565653208205982

Epoch: 5| Step: 4
Training loss: 2.3117123886387003
Validation loss: 2.8169787851872976

Epoch: 5| Step: 5
Training loss: 2.057019321104262
Validation loss: 2.7026958410606374

Epoch: 5| Step: 6
Training loss: 2.5482711241842133
Validation loss: 2.7626704401042708

Epoch: 5| Step: 7
Training loss: 3.3942934222911383
Validation loss: 2.7803660793988847

Epoch: 5| Step: 8
Training loss: 3.1450646747677036
Validation loss: 2.7157929194274724

Epoch: 5| Step: 9
Training loss: 3.0534293859551833
Validation loss: 2.777902197427025

Epoch: 5| Step: 10
Training loss: 2.1570803384193327
Validation loss: 2.7456077447038942

Epoch: 360| Step: 0
Training loss: 2.6938512406939856
Validation loss: 2.7638764375889298

Epoch: 5| Step: 1
Training loss: 2.1652363922533677
Validation loss: 2.761424722957184

Epoch: 5| Step: 2
Training loss: 2.1989023851740046
Validation loss: 2.7985745438994836

Epoch: 5| Step: 3
Training loss: 2.5064562401139097
Validation loss: 2.7418990444932487

Epoch: 5| Step: 4
Training loss: 2.976278296491937
Validation loss: 2.8236538902488335

Epoch: 5| Step: 5
Training loss: 2.3757670318368738
Validation loss: 2.7911646594694712

Epoch: 5| Step: 6
Training loss: 2.3005906756347656
Validation loss: 2.7867172159285207

Epoch: 5| Step: 7
Training loss: 2.2707705241158473
Validation loss: 2.739293321761704

Epoch: 5| Step: 8
Training loss: 3.159582210880808
Validation loss: 2.729731844016921

Epoch: 5| Step: 9
Training loss: 2.1881318405990213
Validation loss: 2.7695699256008375

Epoch: 5| Step: 10
Training loss: 2.252242771919162
Validation loss: 2.6793177768858425

Epoch: 361| Step: 0
Training loss: 2.3290547812060245
Validation loss: 2.807295996485891

Epoch: 5| Step: 1
Training loss: 2.501777875064717
Validation loss: 2.783794335246165

Epoch: 5| Step: 2
Training loss: 2.8133367353421774
Validation loss: 2.7828436508858516

Epoch: 5| Step: 3
Training loss: 2.05862953690579
Validation loss: 2.7510978487389903

Epoch: 5| Step: 4
Training loss: 1.9527027741859113
Validation loss: 2.704072176385953

Epoch: 5| Step: 5
Training loss: 2.210644813817653
Validation loss: 2.745523814679756

Epoch: 5| Step: 6
Training loss: 2.4978952130649676
Validation loss: 2.742016305281235

Epoch: 5| Step: 7
Training loss: 2.780096779380561
Validation loss: 2.82351827066634

Epoch: 5| Step: 8
Training loss: 2.3507157635782456
Validation loss: 2.822482768001024

Epoch: 5| Step: 9
Training loss: 2.1586356855827455
Validation loss: 2.854102291539585

Epoch: 5| Step: 10
Training loss: 3.172700220257513
Validation loss: 2.7423995339522147

Epoch: 362| Step: 0
Training loss: 2.734763243224261
Validation loss: 2.7391941975295824

Epoch: 5| Step: 1
Training loss: 2.6023030644640235
Validation loss: 2.6640815728166136

Epoch: 5| Step: 2
Training loss: 2.3133585599060673
Validation loss: 2.7397996066994814

Epoch: 5| Step: 3
Training loss: 2.0941206191263078
Validation loss: 2.7958015365874567

Epoch: 5| Step: 4
Training loss: 2.3657096051465336
Validation loss: 2.7870072362483307

Epoch: 5| Step: 5
Training loss: 1.8860945843980828
Validation loss: 2.8056935705855994

Epoch: 5| Step: 6
Training loss: 2.617324051212688
Validation loss: 2.7386131619694862

Epoch: 5| Step: 7
Training loss: 2.3862334162204273
Validation loss: 2.7230022728004997

Epoch: 5| Step: 8
Training loss: 3.199272257784753
Validation loss: 2.7606230847633495

Epoch: 5| Step: 9
Training loss: 2.1510910016206704
Validation loss: 2.762015518210048

Epoch: 5| Step: 10
Training loss: 2.98346684403981
Validation loss: 2.7610911326434127

Epoch: 363| Step: 0
Training loss: 2.0155774487941174
Validation loss: 2.7877297727808568

Epoch: 5| Step: 1
Training loss: 2.389440305287868
Validation loss: 2.808946206893274

Epoch: 5| Step: 2
Training loss: 2.685238085940618
Validation loss: 2.815040613084483

Epoch: 5| Step: 3
Training loss: 2.831253092176757
Validation loss: 2.8222148488887506

Epoch: 5| Step: 4
Training loss: 2.8468878903814234
Validation loss: 2.7276511030838546

Epoch: 5| Step: 5
Training loss: 2.3527979852778667
Validation loss: 2.692643661771267

Epoch: 5| Step: 6
Training loss: 2.0601348031019486
Validation loss: 2.797562323672583

Epoch: 5| Step: 7
Training loss: 2.59055904217033
Validation loss: 2.7208168576028817

Epoch: 5| Step: 8
Training loss: 2.1247055747319146
Validation loss: 2.74957675137853

Epoch: 5| Step: 9
Training loss: 2.6982179765584986
Validation loss: 2.766998485746559

Epoch: 5| Step: 10
Training loss: 2.510218811680254
Validation loss: 2.710307893442186

Epoch: 364| Step: 0
Training loss: 2.7331039526299303
Validation loss: 2.7515686787158007

Epoch: 5| Step: 1
Training loss: 2.6669145905957907
Validation loss: 2.7612287822357127

Epoch: 5| Step: 2
Training loss: 1.6335311111415984
Validation loss: 2.8299924714829574

Epoch: 5| Step: 3
Training loss: 2.330150363310747
Validation loss: 2.760295494857892

Epoch: 5| Step: 4
Training loss: 2.023939740509008
Validation loss: 2.8087531304176445

Epoch: 5| Step: 5
Training loss: 2.770640679643573
Validation loss: 2.7528018251592936

Epoch: 5| Step: 6
Training loss: 2.391871108866074
Validation loss: 2.785213395602659

Epoch: 5| Step: 7
Training loss: 2.645689041728767
Validation loss: 2.8263117964382825

Epoch: 5| Step: 8
Training loss: 2.831225976568368
Validation loss: 2.8639086402911733

Epoch: 5| Step: 9
Training loss: 2.641481790982763
Validation loss: 2.7423860332975023

Epoch: 5| Step: 10
Training loss: 2.3943907554942525
Validation loss: 2.755353727020273

Epoch: 365| Step: 0
Training loss: 2.198495098734067
Validation loss: 2.8246289308547445

Epoch: 5| Step: 1
Training loss: 2.793573572788014
Validation loss: 2.795418860789172

Epoch: 5| Step: 2
Training loss: 2.2594106753158987
Validation loss: 2.793944209580541

Epoch: 5| Step: 3
Training loss: 3.042896353138303
Validation loss: 2.754390826414583

Epoch: 5| Step: 4
Training loss: 1.8531165060070605
Validation loss: 2.7374106624416026

Epoch: 5| Step: 5
Training loss: 2.2053205223418675
Validation loss: 2.772793226500077

Epoch: 5| Step: 6
Training loss: 2.69663787541936
Validation loss: 2.7467420320966323

Epoch: 5| Step: 7
Training loss: 2.5039211992838153
Validation loss: 2.781607358455278

Epoch: 5| Step: 8
Training loss: 2.453372043877804
Validation loss: 2.7968006088621347

Epoch: 5| Step: 9
Training loss: 2.4437295586006673
Validation loss: 2.7203177482953604

Epoch: 5| Step: 10
Training loss: 2.1747556834187733
Validation loss: 2.6568801991274986

Epoch: 366| Step: 0
Training loss: 2.1984799162047324
Validation loss: 2.7748201844293865

Epoch: 5| Step: 1
Training loss: 2.466993068887896
Validation loss: 2.7650316270543973

Epoch: 5| Step: 2
Training loss: 2.493381704415426
Validation loss: 2.7578188393458474

Epoch: 5| Step: 3
Training loss: 2.482137380125427
Validation loss: 2.74377946780117

Epoch: 5| Step: 4
Training loss: 2.3238836992614047
Validation loss: 2.6531720061697492

Epoch: 5| Step: 5
Training loss: 2.4786333637814977
Validation loss: 2.80210157038447

Epoch: 5| Step: 6
Training loss: 1.9425429272909998
Validation loss: 2.7874113706969856

Epoch: 5| Step: 7
Training loss: 3.2541681117902437
Validation loss: 2.760540951333789

Epoch: 5| Step: 8
Training loss: 2.5228527797061977
Validation loss: 2.7736431280730622

Epoch: 5| Step: 9
Training loss: 2.1935308971920215
Validation loss: 2.8027829438461427

Epoch: 5| Step: 10
Training loss: 2.6992294377558395
Validation loss: 2.8414461065485224

Epoch: 367| Step: 0
Training loss: 2.5047536478333012
Validation loss: 2.8365271306279864

Epoch: 5| Step: 1
Training loss: 2.734071115228838
Validation loss: 2.813145954146

Epoch: 5| Step: 2
Training loss: 2.9635174062548195
Validation loss: 2.703310032446945

Epoch: 5| Step: 3
Training loss: 2.2636661875063364
Validation loss: 2.754522097686245

Epoch: 5| Step: 4
Training loss: 2.3253677733580274
Validation loss: 2.8252256691881468

Epoch: 5| Step: 5
Training loss: 1.979764011653813
Validation loss: 2.742328851557454

Epoch: 5| Step: 6
Training loss: 2.554378105816914
Validation loss: 2.8121272224027987

Epoch: 5| Step: 7
Training loss: 1.80398790415073
Validation loss: 2.763307416425664

Epoch: 5| Step: 8
Training loss: 2.927746427280897
Validation loss: 2.8138231981813564

Epoch: 5| Step: 9
Training loss: 2.8465542224173617
Validation loss: 2.765593503366316

Epoch: 5| Step: 10
Training loss: 2.0048728232824695
Validation loss: 2.7146924747281074

Epoch: 368| Step: 0
Training loss: 2.4244287624234624
Validation loss: 2.717890845909815

Epoch: 5| Step: 1
Training loss: 2.8517628220518803
Validation loss: 2.7639455022888404

Epoch: 5| Step: 2
Training loss: 2.228135580543339
Validation loss: 2.737960849815661

Epoch: 5| Step: 3
Training loss: 2.3352755115693102
Validation loss: 2.760758867063271

Epoch: 5| Step: 4
Training loss: 2.646744538642147
Validation loss: 2.758955306361112

Epoch: 5| Step: 5
Training loss: 2.3537627917411634
Validation loss: 2.7214124667530903

Epoch: 5| Step: 6
Training loss: 2.5609284210509635
Validation loss: 2.80726070175035

Epoch: 5| Step: 7
Training loss: 2.2520726512146267
Validation loss: 2.776330580800484

Epoch: 5| Step: 8
Training loss: 2.2890555215670614
Validation loss: 2.8224761701547756

Epoch: 5| Step: 9
Training loss: 3.040344281778892
Validation loss: 2.7921138791526765

Epoch: 5| Step: 10
Training loss: 1.9538402620968403
Validation loss: 2.7347682387676606

Epoch: 369| Step: 0
Training loss: 2.3104825885564915
Validation loss: 2.792541966959788

Epoch: 5| Step: 1
Training loss: 2.4804239584415484
Validation loss: 2.715412605859633

Epoch: 5| Step: 2
Training loss: 2.4914859752991396
Validation loss: 2.7475905681756356

Epoch: 5| Step: 3
Training loss: 3.056262768677794
Validation loss: 2.781713293427445

Epoch: 5| Step: 4
Training loss: 2.7219282843611214
Validation loss: 2.7414593852534046

Epoch: 5| Step: 5
Training loss: 1.9731315417901756
Validation loss: 2.770536394019655

Epoch: 5| Step: 6
Training loss: 2.2130938147971184
Validation loss: 2.7020647344245545

Epoch: 5| Step: 7
Training loss: 2.141530979870275
Validation loss: 2.8208112332800415

Epoch: 5| Step: 8
Training loss: 2.485371707617276
Validation loss: 2.8262807838110384

Epoch: 5| Step: 9
Training loss: 2.679041125578154
Validation loss: 2.7451685444953733

Epoch: 5| Step: 10
Training loss: 2.0460244078536696
Validation loss: 2.818784725636602

Epoch: 370| Step: 0
Training loss: 2.6658601037800214
Validation loss: 2.758384864810802

Epoch: 5| Step: 1
Training loss: 2.284638174946655
Validation loss: 2.7108878634438014

Epoch: 5| Step: 2
Training loss: 2.507297451095554
Validation loss: 2.8041384369724773

Epoch: 5| Step: 3
Training loss: 2.1641850075319744
Validation loss: 2.7676078613058386

Epoch: 5| Step: 4
Training loss: 1.9800293564787619
Validation loss: 2.765302917995561

Epoch: 5| Step: 5
Training loss: 2.9189273429105627
Validation loss: 2.8029024877298903

Epoch: 5| Step: 6
Training loss: 2.596577401673376
Validation loss: 2.712067749112159

Epoch: 5| Step: 7
Training loss: 3.1214413025650325
Validation loss: 2.718703157697725

Epoch: 5| Step: 8
Training loss: 2.263495977379199
Validation loss: 2.770046858683838

Epoch: 5| Step: 9
Training loss: 2.429550804880374
Validation loss: 2.7519828121550485

Epoch: 5| Step: 10
Training loss: 2.098635084631157
Validation loss: 2.7300553707008377

Epoch: 371| Step: 0
Training loss: 2.958873341305798
Validation loss: 2.741300215139087

Epoch: 5| Step: 1
Training loss: 2.2631986055833035
Validation loss: 2.694091634511863

Epoch: 5| Step: 2
Training loss: 2.0722735635819314
Validation loss: 2.686972300869095

Epoch: 5| Step: 3
Training loss: 2.025366846458175
Validation loss: 2.793266893051121

Epoch: 5| Step: 4
Training loss: 2.3438694224132304
Validation loss: 2.7653381095033955

Epoch: 5| Step: 5
Training loss: 2.891458587049124
Validation loss: 2.817164182573007

Epoch: 5| Step: 6
Training loss: 2.705038815429634
Validation loss: 2.78102417292093

Epoch: 5| Step: 7
Training loss: 2.3049500396676215
Validation loss: 2.715480816749261

Epoch: 5| Step: 8
Training loss: 2.325752534391139
Validation loss: 2.7868778299785437

Epoch: 5| Step: 9
Training loss: 2.35063928877188
Validation loss: 2.8053664131483855

Epoch: 5| Step: 10
Training loss: 2.499393198758353
Validation loss: 2.8236479769855256

Epoch: 372| Step: 0
Training loss: 2.7862625386027418
Validation loss: 2.759400249139873

Epoch: 5| Step: 1
Training loss: 2.173064530469071
Validation loss: 2.780270532939567

Epoch: 5| Step: 2
Training loss: 2.1224909162383145
Validation loss: 2.752334724191115

Epoch: 5| Step: 3
Training loss: 3.163534388797056
Validation loss: 2.786411434434815

Epoch: 5| Step: 4
Training loss: 2.711463987032174
Validation loss: 2.7384329400646896

Epoch: 5| Step: 5
Training loss: 2.368327052219696
Validation loss: 2.791410265115541

Epoch: 5| Step: 6
Training loss: 1.747196472286848
Validation loss: 2.796875570130704

Epoch: 5| Step: 7
Training loss: 2.240986678594975
Validation loss: 2.8618564822205053

Epoch: 5| Step: 8
Training loss: 2.744423327019391
Validation loss: 2.760656403439775

Epoch: 5| Step: 9
Training loss: 2.6019334499988
Validation loss: 2.7399819543117157

Epoch: 5| Step: 10
Training loss: 2.151825165627197
Validation loss: 2.7978415107915153

Epoch: 373| Step: 0
Training loss: 1.7926646122171743
Validation loss: 2.777999256663509

Epoch: 5| Step: 1
Training loss: 3.1820034431424506
Validation loss: 2.804828123946242

Epoch: 5| Step: 2
Training loss: 2.29442252712337
Validation loss: 2.76534556863639

Epoch: 5| Step: 3
Training loss: 2.421636163563635
Validation loss: 2.729565169482322

Epoch: 5| Step: 4
Training loss: 2.617663804168995
Validation loss: 2.738755982279288

Epoch: 5| Step: 5
Training loss: 2.9481236325637465
Validation loss: 2.7744667538618932

Epoch: 5| Step: 6
Training loss: 2.504803620215023
Validation loss: 2.816752856438808

Epoch: 5| Step: 7
Training loss: 2.3432032646810255
Validation loss: 2.805282862756673

Epoch: 5| Step: 8
Training loss: 2.524966128282637
Validation loss: 2.803578428761896

Epoch: 5| Step: 9
Training loss: 2.1071458128384233
Validation loss: 2.755507741916953

Epoch: 5| Step: 10
Training loss: 2.064183097510099
Validation loss: 2.744537097624637

Epoch: 374| Step: 0
Training loss: 2.480262663682896
Validation loss: 2.737040228617364

Epoch: 5| Step: 1
Training loss: 2.05094121399938
Validation loss: 2.7462007897929817

Epoch: 5| Step: 2
Training loss: 2.297812134436489
Validation loss: 2.76677094319979

Epoch: 5| Step: 3
Training loss: 2.518224948273327
Validation loss: 2.782060008157774

Epoch: 5| Step: 4
Training loss: 2.371582785235751
Validation loss: 2.767105189382531

Epoch: 5| Step: 5
Training loss: 3.1086676478320636
Validation loss: 2.7693921079718695

Epoch: 5| Step: 6
Training loss: 2.3986784475368377
Validation loss: 2.749501967242869

Epoch: 5| Step: 7
Training loss: 3.0836438890376776
Validation loss: 2.7561249674359627

Epoch: 5| Step: 8
Training loss: 1.830740337600016
Validation loss: 2.7259397431649655

Epoch: 5| Step: 9
Training loss: 1.9957770826128518
Validation loss: 2.7953191836418845

Epoch: 5| Step: 10
Training loss: 2.029592453960845
Validation loss: 2.7698764454860316

Epoch: 375| Step: 0
Training loss: 1.4372759934744082
Validation loss: 2.7868586758167866

Epoch: 5| Step: 1
Training loss: 2.957389698954457
Validation loss: 2.7592919932728206

Epoch: 5| Step: 2
Training loss: 2.4872061474395
Validation loss: 2.7631773084625233

Epoch: 5| Step: 3
Training loss: 2.252075403736516
Validation loss: 2.7799982579573204

Epoch: 5| Step: 4
Training loss: 2.5018897543631016
Validation loss: 2.799107877353815

Epoch: 5| Step: 5
Training loss: 2.701019172462003
Validation loss: 2.7527655709609093

Epoch: 5| Step: 6
Training loss: 2.3177655045105245
Validation loss: 2.8241493637422526

Epoch: 5| Step: 7
Training loss: 2.438862444281195
Validation loss: 2.78971990118253

Epoch: 5| Step: 8
Training loss: 2.7448812008079826
Validation loss: 2.781271101735704

Epoch: 5| Step: 9
Training loss: 2.575689101371481
Validation loss: 2.750351983977964

Epoch: 5| Step: 10
Training loss: 2.785404830903667
Validation loss: 2.750582548471812

Epoch: 376| Step: 0
Training loss: 1.852270449728983
Validation loss: 2.8210616123734837

Epoch: 5| Step: 1
Training loss: 2.5346448761680427
Validation loss: 2.752790852747881

Epoch: 5| Step: 2
Training loss: 2.817003501600121
Validation loss: 2.7580961299845783

Epoch: 5| Step: 3
Training loss: 2.714681716584318
Validation loss: 2.767181746266096

Epoch: 5| Step: 4
Training loss: 2.1969200031994256
Validation loss: 2.770851528568436

Epoch: 5| Step: 5
Training loss: 2.695893598194418
Validation loss: 2.8082676570887295

Epoch: 5| Step: 6
Training loss: 2.0979267421911056
Validation loss: 2.787488037581076

Epoch: 5| Step: 7
Training loss: 2.1493916560196276
Validation loss: 2.740354238055052

Epoch: 5| Step: 8
Training loss: 2.9294046087378125
Validation loss: 2.789581650353102

Epoch: 5| Step: 9
Training loss: 2.7197420787539888
Validation loss: 2.774012360536826

Epoch: 5| Step: 10
Training loss: 2.6513248334842237
Validation loss: 2.8057840775341902

Epoch: 377| Step: 0
Training loss: 2.688261412170702
Validation loss: 2.783600829803142

Epoch: 5| Step: 1
Training loss: 2.332901937478328
Validation loss: 2.7794086766829276

Epoch: 5| Step: 2
Training loss: 2.067784446513328
Validation loss: 2.7380928437111614

Epoch: 5| Step: 3
Training loss: 2.6688391855958233
Validation loss: 2.8004520558209456

Epoch: 5| Step: 4
Training loss: 2.3875353426089907
Validation loss: 2.7918165592462296

Epoch: 5| Step: 5
Training loss: 2.3812020284471376
Validation loss: 2.818630708437077

Epoch: 5| Step: 6
Training loss: 2.4834007416180817
Validation loss: 2.751308249769052

Epoch: 5| Step: 7
Training loss: 2.6152520610048913
Validation loss: 2.7826673180837305

Epoch: 5| Step: 8
Training loss: 2.7165817735041604
Validation loss: 2.762023904280954

Epoch: 5| Step: 9
Training loss: 2.5351697924330123
Validation loss: 2.8516006096330053

Epoch: 5| Step: 10
Training loss: 2.208528102227005
Validation loss: 2.7818428699033717

Epoch: 378| Step: 0
Training loss: 2.211034442407326
Validation loss: 2.8018483550855633

Epoch: 5| Step: 1
Training loss: 2.225553263767125
Validation loss: 2.784837430318045

Epoch: 5| Step: 2
Training loss: 2.331200430908111
Validation loss: 2.8021206066285793

Epoch: 5| Step: 3
Training loss: 2.3025916963722937
Validation loss: 2.7514874853233002

Epoch: 5| Step: 4
Training loss: 2.228754617511889
Validation loss: 2.7933150891549072

Epoch: 5| Step: 5
Training loss: 2.34876518273027
Validation loss: 2.8053475899220435

Epoch: 5| Step: 6
Training loss: 2.9970081033275724
Validation loss: 2.8392104596145686

Epoch: 5| Step: 7
Training loss: 2.2667860541972042
Validation loss: 2.8403302870042584

Epoch: 5| Step: 8
Training loss: 2.851472534432696
Validation loss: 2.742523178890454

Epoch: 5| Step: 9
Training loss: 2.25829418284509
Validation loss: 2.7452389810136224

Epoch: 5| Step: 10
Training loss: 2.7147964144086
Validation loss: 2.7617737879369124

Epoch: 379| Step: 0
Training loss: 2.236080772346783
Validation loss: 2.7309853634857686

Epoch: 5| Step: 1
Training loss: 2.0605621481957654
Validation loss: 2.8183388502229096

Epoch: 5| Step: 2
Training loss: 2.239468298035061
Validation loss: 2.786504916488967

Epoch: 5| Step: 3
Training loss: 1.8250661184796866
Validation loss: 2.879899272051648

Epoch: 5| Step: 4
Training loss: 3.178880893833963
Validation loss: 2.778530768262363

Epoch: 5| Step: 5
Training loss: 2.877324532893419
Validation loss: 2.7095234176959937

Epoch: 5| Step: 6
Training loss: 2.056865277749855
Validation loss: 2.7514458134289854

Epoch: 5| Step: 7
Training loss: 2.382902750276005
Validation loss: 2.804496551831566

Epoch: 5| Step: 8
Training loss: 2.178971367783123
Validation loss: 2.8047287857646235

Epoch: 5| Step: 9
Training loss: 2.73311381001235
Validation loss: 2.78810363594956

Epoch: 5| Step: 10
Training loss: 2.843591035864343
Validation loss: 2.7856430656650195

Epoch: 380| Step: 0
Training loss: 2.627803758363296
Validation loss: 2.7177852530885818

Epoch: 5| Step: 1
Training loss: 2.284455542442603
Validation loss: 2.7762957188510824

Epoch: 5| Step: 2
Training loss: 2.655012672810743
Validation loss: 2.8138307857122435

Epoch: 5| Step: 3
Training loss: 2.1894987511623643
Validation loss: 2.7855391410698083

Epoch: 5| Step: 4
Training loss: 2.445815159623463
Validation loss: 2.791410919018674

Epoch: 5| Step: 5
Training loss: 2.5562636619892976
Validation loss: 2.745010259550734

Epoch: 5| Step: 6
Training loss: 2.5502213101560276
Validation loss: 2.7921180127597203

Epoch: 5| Step: 7
Training loss: 2.0581176902254272
Validation loss: 2.7346576503568767

Epoch: 5| Step: 8
Training loss: 1.7700702444243654
Validation loss: 2.800641878303122

Epoch: 5| Step: 9
Training loss: 2.1096421814295883
Validation loss: 2.7128900901385022

Epoch: 5| Step: 10
Training loss: 3.0472967393917703
Validation loss: 2.713722031381184

Epoch: 381| Step: 0
Training loss: 2.8193684950330478
Validation loss: 2.7779986457453156

Epoch: 5| Step: 1
Training loss: 2.350938479742647
Validation loss: 2.797273157583381

Epoch: 5| Step: 2
Training loss: 2.534526917294138
Validation loss: 2.739026881569708

Epoch: 5| Step: 3
Training loss: 2.3241036522840495
Validation loss: 2.7599207953778016

Epoch: 5| Step: 4
Training loss: 2.084154374143439
Validation loss: 2.708463331246841

Epoch: 5| Step: 5
Training loss: 2.4621101613007927
Validation loss: 2.7773506138274286

Epoch: 5| Step: 6
Training loss: 2.9842385465573606
Validation loss: 2.7437792856036043

Epoch: 5| Step: 7
Training loss: 3.100341864163147
Validation loss: 2.846092523203886

Epoch: 5| Step: 8
Training loss: 1.828304314581555
Validation loss: 2.7222581925135296

Epoch: 5| Step: 9
Training loss: 2.2972275859068505
Validation loss: 2.7201277961966133

Epoch: 5| Step: 10
Training loss: 1.7004760300097428
Validation loss: 2.778256169077975

Epoch: 382| Step: 0
Training loss: 2.799943657716912
Validation loss: 2.7919832239003997

Epoch: 5| Step: 1
Training loss: 2.209150367119327
Validation loss: 2.735100545182161

Epoch: 5| Step: 2
Training loss: 2.2826159842396505
Validation loss: 2.843742330027625

Epoch: 5| Step: 3
Training loss: 2.30335965455727
Validation loss: 2.8623432165745233

Epoch: 5| Step: 4
Training loss: 3.056888655571785
Validation loss: 2.787758140028323

Epoch: 5| Step: 5
Training loss: 2.8188549724241407
Validation loss: 2.841776106326877

Epoch: 5| Step: 6
Training loss: 2.0688874720509274
Validation loss: 2.799404688438472

Epoch: 5| Step: 7
Training loss: 2.4805574656563762
Validation loss: 2.732932080090653

Epoch: 5| Step: 8
Training loss: 2.6461829207346557
Validation loss: 2.7773266605098166

Epoch: 5| Step: 9
Training loss: 1.6881219636055826
Validation loss: 2.804858699238318

Epoch: 5| Step: 10
Training loss: 2.3130674954604995
Validation loss: 2.810690737457412

Epoch: 383| Step: 0
Training loss: 2.243951083977803
Validation loss: 2.7556614737619802

Epoch: 5| Step: 1
Training loss: 2.816549818636158
Validation loss: 2.762309533411488

Epoch: 5| Step: 2
Training loss: 2.3786100757557076
Validation loss: 2.7906105444881377

Epoch: 5| Step: 3
Training loss: 1.9991232619265207
Validation loss: 2.674030713563833

Epoch: 5| Step: 4
Training loss: 2.9619791015567754
Validation loss: 2.779509728680422

Epoch: 5| Step: 5
Training loss: 1.5134081013872644
Validation loss: 2.770851333810122

Epoch: 5| Step: 6
Training loss: 3.259534202484012
Validation loss: 2.792883445882152

Epoch: 5| Step: 7
Training loss: 2.5706909272142613
Validation loss: 2.7353706640217474

Epoch: 5| Step: 8
Training loss: 2.7072952824316845
Validation loss: 2.7969586338158976

Epoch: 5| Step: 9
Training loss: 1.6622612028784312
Validation loss: 2.761317421022875

Epoch: 5| Step: 10
Training loss: 2.219239301859639
Validation loss: 2.780927753941221

Epoch: 384| Step: 0
Training loss: 2.9987486772745005
Validation loss: 2.8282210617507277

Epoch: 5| Step: 1
Training loss: 2.5404988612994726
Validation loss: 2.751246500771666

Epoch: 5| Step: 2
Training loss: 2.035381517005912
Validation loss: 2.710535101669059

Epoch: 5| Step: 3
Training loss: 2.717176837253105
Validation loss: 2.7441369506965483

Epoch: 5| Step: 4
Training loss: 2.3591846111355816
Validation loss: 2.765386505438848

Epoch: 5| Step: 5
Training loss: 2.396084205650721
Validation loss: 2.740184741473766

Epoch: 5| Step: 6
Training loss: 1.8722627368747935
Validation loss: 2.7224279882875067

Epoch: 5| Step: 7
Training loss: 2.41484960668243
Validation loss: 2.732445818528988

Epoch: 5| Step: 8
Training loss: 2.320441862154367
Validation loss: 2.768284608894283

Epoch: 5| Step: 9
Training loss: 2.5071071690529503
Validation loss: 2.7469468101739007

Epoch: 5| Step: 10
Training loss: 2.8023959603509474
Validation loss: 2.791642000814562

Epoch: 385| Step: 0
Training loss: 2.3072600925831184
Validation loss: 2.7169144577128197

Epoch: 5| Step: 1
Training loss: 2.980165398635226
Validation loss: 2.736949482874263

Epoch: 5| Step: 2
Training loss: 2.9620552469545096
Validation loss: 2.770838117044079

Epoch: 5| Step: 3
Training loss: 2.2357010541077766
Validation loss: 2.7968086898898346

Epoch: 5| Step: 4
Training loss: 2.0311927200457363
Validation loss: 2.7859748102633874

Epoch: 5| Step: 5
Training loss: 2.652542219194517
Validation loss: 2.7832503002510105

Epoch: 5| Step: 6
Training loss: 2.5125381770483584
Validation loss: 2.7404629440663664

Epoch: 5| Step: 7
Training loss: 2.292417079711346
Validation loss: 2.787994090967235

Epoch: 5| Step: 8
Training loss: 2.0921235101100453
Validation loss: 2.732568461087769

Epoch: 5| Step: 9
Training loss: 2.365597433234465
Validation loss: 2.777830052106107

Epoch: 5| Step: 10
Training loss: 2.294609769335578
Validation loss: 2.8171435726469487

Epoch: 386| Step: 0
Training loss: 2.524420201425079
Validation loss: 2.7717809411425747

Epoch: 5| Step: 1
Training loss: 2.6941387772190812
Validation loss: 2.7672035111439093

Epoch: 5| Step: 2
Training loss: 1.8731490854134656
Validation loss: 2.797636974503691

Epoch: 5| Step: 3
Training loss: 2.9694428287981864
Validation loss: 2.781684573305305

Epoch: 5| Step: 4
Training loss: 2.8324444068240817
Validation loss: 2.7604719649054443

Epoch: 5| Step: 5
Training loss: 2.3537665395616467
Validation loss: 2.7816078662788772

Epoch: 5| Step: 6
Training loss: 1.921032046164443
Validation loss: 2.7422584786507977

Epoch: 5| Step: 7
Training loss: 1.8115954279411708
Validation loss: 2.778483897635427

Epoch: 5| Step: 8
Training loss: 2.6496401956400266
Validation loss: 2.802489294331885

Epoch: 5| Step: 9
Training loss: 2.072471558084652
Validation loss: 2.7932382875931743

Epoch: 5| Step: 10
Training loss: 2.073473320474072
Validation loss: 2.7174581745510564

Epoch: 387| Step: 0
Training loss: 2.351581357962696
Validation loss: 2.759437985326697

Epoch: 5| Step: 1
Training loss: 2.4271554786099285
Validation loss: 2.7837158426303765

Epoch: 5| Step: 2
Training loss: 2.4404050681531295
Validation loss: 2.736769134551445

Epoch: 5| Step: 3
Training loss: 3.0717181611018085
Validation loss: 2.8118567493398032

Epoch: 5| Step: 4
Training loss: 2.5935159600617874
Validation loss: 2.7957185944116874

Epoch: 5| Step: 5
Training loss: 2.396725817318723
Validation loss: 2.7751746249387135

Epoch: 5| Step: 6
Training loss: 1.7117673350777223
Validation loss: 2.74554349158266

Epoch: 5| Step: 7
Training loss: 1.924800290238667
Validation loss: 2.7301874153290604

Epoch: 5| Step: 8
Training loss: 2.615391721543199
Validation loss: 2.776701772380468

Epoch: 5| Step: 9
Training loss: 2.39306057795212
Validation loss: 2.7653967863604274

Epoch: 5| Step: 10
Training loss: 2.6258127679950674
Validation loss: 2.7384617486935787

Epoch: 388| Step: 0
Training loss: 1.898179590107817
Validation loss: 2.776479530044668

Epoch: 5| Step: 1
Training loss: 2.7184247227907976
Validation loss: 2.7506604804498216

Epoch: 5| Step: 2
Training loss: 2.415206687407003
Validation loss: 2.7891750030930758

Epoch: 5| Step: 3
Training loss: 2.25419754975529
Validation loss: 2.6796867212510675

Epoch: 5| Step: 4
Training loss: 2.1106005463949997
Validation loss: 2.7688329746582943

Epoch: 5| Step: 5
Training loss: 2.458632003830836
Validation loss: 2.747249560925505

Epoch: 5| Step: 6
Training loss: 2.3169854454798435
Validation loss: 2.755707388279078

Epoch: 5| Step: 7
Training loss: 2.716078135938147
Validation loss: 2.8620604379315333

Epoch: 5| Step: 8
Training loss: 2.3925334817263564
Validation loss: 2.840218653951378

Epoch: 5| Step: 9
Training loss: 3.3299730211602725
Validation loss: 2.8123765369146874

Epoch: 5| Step: 10
Training loss: 1.947034265362635
Validation loss: 2.8157550984708086

Epoch: 389| Step: 0
Training loss: 2.0550193373612595
Validation loss: 2.7307032812257694

Epoch: 5| Step: 1
Training loss: 2.6299774572182315
Validation loss: 2.808297478321679

Epoch: 5| Step: 2
Training loss: 2.2965708420929376
Validation loss: 2.7013160693713063

Epoch: 5| Step: 3
Training loss: 2.060721121557335
Validation loss: 2.755141198433858

Epoch: 5| Step: 4
Training loss: 3.078337686229603
Validation loss: 2.77015060746592

Epoch: 5| Step: 5
Training loss: 2.4189007616002387
Validation loss: 2.740614631240247

Epoch: 5| Step: 6
Training loss: 2.2392361985505618
Validation loss: 2.8044314667924994

Epoch: 5| Step: 7
Training loss: 2.423173125829374
Validation loss: 2.8377271335714416

Epoch: 5| Step: 8
Training loss: 2.511087436151818
Validation loss: 2.8027146687914803

Epoch: 5| Step: 9
Training loss: 2.690054898889483
Validation loss: 2.760435500325465

Epoch: 5| Step: 10
Training loss: 1.898083186739443
Validation loss: 2.7251845967963537

Epoch: 390| Step: 0
Training loss: 2.9292322237393984
Validation loss: 2.78343074815518

Epoch: 5| Step: 1
Training loss: 2.3905577805985723
Validation loss: 2.7349559104758003

Epoch: 5| Step: 2
Training loss: 2.2966711252258754
Validation loss: 2.765490147245038

Epoch: 5| Step: 3
Training loss: 2.401754068094229
Validation loss: 2.7187569844089365

Epoch: 5| Step: 4
Training loss: 2.3538022954948565
Validation loss: 2.8154685867031524

Epoch: 5| Step: 5
Training loss: 2.4965069209468354
Validation loss: 2.79758289824474

Epoch: 5| Step: 6
Training loss: 1.9079898336287626
Validation loss: 2.7595800251400475

Epoch: 5| Step: 7
Training loss: 2.183443176864903
Validation loss: 2.81446123732221

Epoch: 5| Step: 8
Training loss: 2.2086944524734986
Validation loss: 2.7072888101030834

Epoch: 5| Step: 9
Training loss: 2.926121201774729
Validation loss: 2.7973398049370206

Epoch: 5| Step: 10
Training loss: 2.266765228634321
Validation loss: 2.685826755829074

Epoch: 391| Step: 0
Training loss: 2.4090111483723313
Validation loss: 2.750381488945284

Epoch: 5| Step: 1
Training loss: 2.7846261438890623
Validation loss: 2.770277365538342

Epoch: 5| Step: 2
Training loss: 2.9105178505946965
Validation loss: 2.7509646136262567

Epoch: 5| Step: 3
Training loss: 2.337179714842274
Validation loss: 2.773460690119616

Epoch: 5| Step: 4
Training loss: 2.4888849169930296
Validation loss: 2.804914336603826

Epoch: 5| Step: 5
Training loss: 2.1848817687705346
Validation loss: 2.765901409333777

Epoch: 5| Step: 6
Training loss: 1.2829107360768843
Validation loss: 2.685345370044394

Epoch: 5| Step: 7
Training loss: 2.5597370417963896
Validation loss: 2.7656559753259176

Epoch: 5| Step: 8
Training loss: 2.1882711958458447
Validation loss: 2.80454866338344

Epoch: 5| Step: 9
Training loss: 2.0793398411045483
Validation loss: 2.742713660148497

Epoch: 5| Step: 10
Training loss: 3.2122783599273763
Validation loss: 2.737907451445632

Epoch: 392| Step: 0
Training loss: 2.2699178080866167
Validation loss: 2.795737906114024

Epoch: 5| Step: 1
Training loss: 2.5245456211186066
Validation loss: 2.7812513798720286

Epoch: 5| Step: 2
Training loss: 2.4447427396642105
Validation loss: 2.7704639782322467

Epoch: 5| Step: 3
Training loss: 3.0247274796233743
Validation loss: 2.7022631834628648

Epoch: 5| Step: 4
Training loss: 2.5930954440462837
Validation loss: 2.7181592418972738

Epoch: 5| Step: 5
Training loss: 2.0371699996222308
Validation loss: 2.7779567421581883

Epoch: 5| Step: 6
Training loss: 2.305461688856573
Validation loss: 2.764336238156599

Epoch: 5| Step: 7
Training loss: 2.293429638685015
Validation loss: 2.7200499733961387

Epoch: 5| Step: 8
Training loss: 2.4819150057555714
Validation loss: 2.8502290406993747

Epoch: 5| Step: 9
Training loss: 2.4894376789298
Validation loss: 2.816461444435818

Epoch: 5| Step: 10
Training loss: 2.0359922950613827
Validation loss: 2.8046533991161677

Epoch: 393| Step: 0
Training loss: 3.066465651793271
Validation loss: 2.84027418806017

Epoch: 5| Step: 1
Training loss: 2.261280498309511
Validation loss: 2.829839726513697

Epoch: 5| Step: 2
Training loss: 2.6048628118198662
Validation loss: 2.7161858791203684

Epoch: 5| Step: 3
Training loss: 2.2614303167766896
Validation loss: 2.859470349927667

Epoch: 5| Step: 4
Training loss: 2.823325283605036
Validation loss: 2.753005560235519

Epoch: 5| Step: 5
Training loss: 1.6912607742721986
Validation loss: 2.8164238205478656

Epoch: 5| Step: 6
Training loss: 2.7479016361206297
Validation loss: 2.8034301904821426

Epoch: 5| Step: 7
Training loss: 2.4653869127166494
Validation loss: 2.7993227816507664

Epoch: 5| Step: 8
Training loss: 2.2146941173137566
Validation loss: 2.81975133359801

Epoch: 5| Step: 9
Training loss: 2.455755973230022
Validation loss: 2.775680011131777

Epoch: 5| Step: 10
Training loss: 2.0994661788015057
Validation loss: 2.737541444376408

Epoch: 394| Step: 0
Training loss: 3.122961523859107
Validation loss: 2.7328162691172695

Epoch: 5| Step: 1
Training loss: 2.116479846889939
Validation loss: 2.765562843443254

Epoch: 5| Step: 2
Training loss: 2.250877844906931
Validation loss: 2.7549813676030626

Epoch: 5| Step: 3
Training loss: 1.8724219082080957
Validation loss: 2.7877069147142306

Epoch: 5| Step: 4
Training loss: 2.73215939813303
Validation loss: 2.7128898444423726

Epoch: 5| Step: 5
Training loss: 2.0379552648499284
Validation loss: 2.7859253916622997

Epoch: 5| Step: 6
Training loss: 2.983754358116646
Validation loss: 2.7855765654882885

Epoch: 5| Step: 7
Training loss: 1.9097806409127278
Validation loss: 2.753342067807247

Epoch: 5| Step: 8
Training loss: 1.7247229395074892
Validation loss: 2.832484507825774

Epoch: 5| Step: 9
Training loss: 2.883120967416447
Validation loss: 2.829250856949166

Epoch: 5| Step: 10
Training loss: 2.281812833567662
Validation loss: 2.7898136087034406

Epoch: 395| Step: 0
Training loss: 2.9591498703203745
Validation loss: 2.7954985755542343

Epoch: 5| Step: 1
Training loss: 2.4255483027114964
Validation loss: 2.786637617953758

Epoch: 5| Step: 2
Training loss: 2.7718568407773443
Validation loss: 2.801319537119813

Epoch: 5| Step: 3
Training loss: 2.4373249088881885
Validation loss: 2.8243635789479153

Epoch: 5| Step: 4
Training loss: 2.79320067396444
Validation loss: 2.797947047348277

Epoch: 5| Step: 5
Training loss: 1.3814958672891406
Validation loss: 2.838115538603541

Epoch: 5| Step: 6
Training loss: 2.559390717063405
Validation loss: 2.775163652301751

Epoch: 5| Step: 7
Training loss: 2.2958742413854205
Validation loss: 2.7701160203429858

Epoch: 5| Step: 8
Training loss: 2.6712419083311616
Validation loss: 2.854629754484645

Epoch: 5| Step: 9
Training loss: 2.4023916844493685
Validation loss: 2.783846084256229

Epoch: 5| Step: 10
Training loss: 2.4885721321098706
Validation loss: 2.7083839342361418

Epoch: 396| Step: 0
Training loss: 2.473629439058349
Validation loss: 2.745212313871686

Epoch: 5| Step: 1
Training loss: 2.6753314231842293
Validation loss: 2.702761031232021

Epoch: 5| Step: 2
Training loss: 2.0704160268558285
Validation loss: 2.785381235852432

Epoch: 5| Step: 3
Training loss: 2.4749433838505035
Validation loss: 2.731824543642723

Epoch: 5| Step: 4
Training loss: 2.4696081094629063
Validation loss: 2.7457800039613978

Epoch: 5| Step: 5
Training loss: 2.871378068405265
Validation loss: 2.7785649055691293

Epoch: 5| Step: 6
Training loss: 1.6643305459641267
Validation loss: 2.812878348767454

Epoch: 5| Step: 7
Training loss: 2.5886479950116117
Validation loss: 2.772684923062566

Epoch: 5| Step: 8
Training loss: 2.0180238155778185
Validation loss: 2.82734030492732

Epoch: 5| Step: 9
Training loss: 2.6273608717302372
Validation loss: 2.72883789466901

Epoch: 5| Step: 10
Training loss: 2.440061152895682
Validation loss: 2.730341306197913

Epoch: 397| Step: 0
Training loss: 2.6302029046232396
Validation loss: 2.892840489869869

Epoch: 5| Step: 1
Training loss: 2.1609929207999636
Validation loss: 2.7665974815792636

Epoch: 5| Step: 2
Training loss: 1.9531268310538292
Validation loss: 2.781988829973

Epoch: 5| Step: 3
Training loss: 2.2498728398312107
Validation loss: 2.7518945937508232

Epoch: 5| Step: 4
Training loss: 2.2215513355781105
Validation loss: 2.7440310696940413

Epoch: 5| Step: 5
Training loss: 2.134057656150121
Validation loss: 2.7980516105601327

Epoch: 5| Step: 6
Training loss: 2.4397246161601425
Validation loss: 2.7835748589675435

Epoch: 5| Step: 7
Training loss: 2.493229471821179
Validation loss: 2.835686333340866

Epoch: 5| Step: 8
Training loss: 3.2683103189107126
Validation loss: 2.7200808089161024

Epoch: 5| Step: 9
Training loss: 2.2329444840906283
Validation loss: 2.7601296540146207

Epoch: 5| Step: 10
Training loss: 2.776030368078164
Validation loss: 2.8186063710195945

Epoch: 398| Step: 0
Training loss: 3.1144292957059823
Validation loss: 2.797168814563003

Epoch: 5| Step: 1
Training loss: 2.4083484565585622
Validation loss: 2.8505808535369996

Epoch: 5| Step: 2
Training loss: 2.125803515041832
Validation loss: 2.846083702067031

Epoch: 5| Step: 3
Training loss: 1.998732522836775
Validation loss: 2.7231570498411366

Epoch: 5| Step: 4
Training loss: 2.0657092471118763
Validation loss: 2.7567929645689193

Epoch: 5| Step: 5
Training loss: 2.4685671774856606
Validation loss: 2.7964272987766394

Epoch: 5| Step: 6
Training loss: 2.440543792975682
Validation loss: 2.8036575942369177

Epoch: 5| Step: 7
Training loss: 2.5211689202846714
Validation loss: 2.809267843467456

Epoch: 5| Step: 8
Training loss: 2.2028924264639027
Validation loss: 2.7852422625042355

Epoch: 5| Step: 9
Training loss: 2.074717431189367
Validation loss: 2.8643669468805464

Epoch: 5| Step: 10
Training loss: 2.8574430682634255
Validation loss: 2.8042589003474134

Epoch: 399| Step: 0
Training loss: 2.3576069453426767
Validation loss: 2.8030319105673165

Epoch: 5| Step: 1
Training loss: 2.1453504543739514
Validation loss: 2.758387928108803

Epoch: 5| Step: 2
Training loss: 1.6783295575995656
Validation loss: 2.7581976700285784

Epoch: 5| Step: 3
Training loss: 2.123512532843245
Validation loss: 2.768499694545423

Epoch: 5| Step: 4
Training loss: 2.4516933661519134
Validation loss: 2.814813811996378

Epoch: 5| Step: 5
Training loss: 2.4754665127752347
Validation loss: 2.8121190769099242

Epoch: 5| Step: 6
Training loss: 2.6985039875650623
Validation loss: 2.774536113033362

Epoch: 5| Step: 7
Training loss: 1.9705887941857032
Validation loss: 2.7720233025244005

Epoch: 5| Step: 8
Training loss: 3.2644470134448293
Validation loss: 2.7399767624324984

Epoch: 5| Step: 9
Training loss: 2.6651054421583895
Validation loss: 2.737227519771864

Epoch: 5| Step: 10
Training loss: 2.300918031004232
Validation loss: 2.675176226001941

Epoch: 400| Step: 0
Training loss: 2.3757172555530506
Validation loss: 2.7921111246354777

Epoch: 5| Step: 1
Training loss: 2.6793389719308696
Validation loss: 2.689681686969846

Epoch: 5| Step: 2
Training loss: 2.165707950737348
Validation loss: 2.7520872735914423

Epoch: 5| Step: 3
Training loss: 2.314187954548431
Validation loss: 2.7699601762733623

Epoch: 5| Step: 4
Training loss: 2.4025795425442116
Validation loss: 2.8111772131463724

Epoch: 5| Step: 5
Training loss: 1.6017925562426156
Validation loss: 2.790085395365878

Epoch: 5| Step: 6
Training loss: 2.1936950155035047
Validation loss: 2.738832917863522

Epoch: 5| Step: 7
Training loss: 3.327334457853822
Validation loss: 2.7629769789474987

Epoch: 5| Step: 8
Training loss: 2.3193288445615226
Validation loss: 2.812136782729028

Epoch: 5| Step: 9
Training loss: 3.0855876482858022
Validation loss: 2.7739244859942964

Epoch: 5| Step: 10
Training loss: 1.75255541192798
Validation loss: 2.789836524860776

Epoch: 401| Step: 0
Training loss: 1.2887967384809762
Validation loss: 2.7480628881050526

Epoch: 5| Step: 1
Training loss: 2.061440513601929
Validation loss: 2.7810459967772903

Epoch: 5| Step: 2
Training loss: 2.26443871320291
Validation loss: 2.808567180545238

Epoch: 5| Step: 3
Training loss: 2.7921585294974234
Validation loss: 2.760689099536437

Epoch: 5| Step: 4
Training loss: 2.2588351880355866
Validation loss: 2.779884865195078

Epoch: 5| Step: 5
Training loss: 2.28457952541396
Validation loss: 2.7994224939049572

Epoch: 5| Step: 6
Training loss: 2.7688895747910345
Validation loss: 2.716023297139897

Epoch: 5| Step: 7
Training loss: 2.5609160389213352
Validation loss: 2.823808179099835

Epoch: 5| Step: 8
Training loss: 2.208827437299282
Validation loss: 2.7590524611425766

Epoch: 5| Step: 9
Training loss: 2.7201238208524705
Validation loss: 2.824712069662174

Epoch: 5| Step: 10
Training loss: 2.8041695034093994
Validation loss: 2.7732580547177355

Epoch: 402| Step: 0
Training loss: 1.696596705200277
Validation loss: 2.7866593440299607

Epoch: 5| Step: 1
Training loss: 2.9090836359605037
Validation loss: 2.7145143724744796

Epoch: 5| Step: 2
Training loss: 1.7815014845686388
Validation loss: 2.7115687217333235

Epoch: 5| Step: 3
Training loss: 2.606980189942838
Validation loss: 2.737753413030079

Epoch: 5| Step: 4
Training loss: 2.567266543582559
Validation loss: 2.801189804536285

Epoch: 5| Step: 5
Training loss: 1.8416411413895073
Validation loss: 2.7993403284663576

Epoch: 5| Step: 6
Training loss: 2.129941915875276
Validation loss: 2.7668204667206053

Epoch: 5| Step: 7
Training loss: 2.6495827868259534
Validation loss: 2.7516694368931693

Epoch: 5| Step: 8
Training loss: 2.895554746405032
Validation loss: 2.7991410392590867

Epoch: 5| Step: 9
Training loss: 2.313450798255123
Validation loss: 2.809894659428023

Epoch: 5| Step: 10
Training loss: 2.5885023783127026
Validation loss: 2.7511521328308

Epoch: 403| Step: 0
Training loss: 3.2266451106914626
Validation loss: 2.7627154145882717

Epoch: 5| Step: 1
Training loss: 2.390940028358671
Validation loss: 2.8062423804979715

Epoch: 5| Step: 2
Training loss: 1.727801400595891
Validation loss: 2.847863758549681

Epoch: 5| Step: 3
Training loss: 2.242283729322501
Validation loss: 2.804274270672841

Epoch: 5| Step: 4
Training loss: 2.513029667076173
Validation loss: 2.7291249820995476

Epoch: 5| Step: 5
Training loss: 1.4476596229048673
Validation loss: 2.7891168228006094

Epoch: 5| Step: 6
Training loss: 2.3301604928665043
Validation loss: 2.693020615646347

Epoch: 5| Step: 7
Training loss: 2.1722646679299054
Validation loss: 2.755702826073331

Epoch: 5| Step: 8
Training loss: 2.2758467974195247
Validation loss: 2.7684171919529295

Epoch: 5| Step: 9
Training loss: 2.483432999046762
Validation loss: 2.7138346575153234

Epoch: 5| Step: 10
Training loss: 3.305273125886353
Validation loss: 2.8161542936006163

Epoch: 404| Step: 0
Training loss: 2.2872160146400105
Validation loss: 2.729125462114299

Epoch: 5| Step: 1
Training loss: 2.4532041111721172
Validation loss: 2.805712174024992

Epoch: 5| Step: 2
Training loss: 2.6432707584409885
Validation loss: 2.732354407912136

Epoch: 5| Step: 3
Training loss: 2.4166038000765018
Validation loss: 2.743068336120243

Epoch: 5| Step: 4
Training loss: 2.3497900889370205
Validation loss: 2.7430877605427453

Epoch: 5| Step: 5
Training loss: 2.10496795303705
Validation loss: 2.7202677937828854

Epoch: 5| Step: 6
Training loss: 2.4078384704971603
Validation loss: 2.8143771453088675

Epoch: 5| Step: 7
Training loss: 2.5463494068605055
Validation loss: 2.796891038318983

Epoch: 5| Step: 8
Training loss: 1.882630525397884
Validation loss: 2.798237137835349

Epoch: 5| Step: 9
Training loss: 2.2276512295027637
Validation loss: 2.7407612842517066

Epoch: 5| Step: 10
Training loss: 2.90439209977549
Validation loss: 2.6844155319901177

Epoch: 405| Step: 0
Training loss: 1.962976436732026
Validation loss: 2.7586653269611148

Epoch: 5| Step: 1
Training loss: 2.380752223093809
Validation loss: 2.844791099626475

Epoch: 5| Step: 2
Training loss: 2.1591854293795203
Validation loss: 2.718802140768092

Epoch: 5| Step: 3
Training loss: 1.950394881442663
Validation loss: 2.7779743856322927

Epoch: 5| Step: 4
Training loss: 2.403994208838268
Validation loss: 2.8329668049251757

Epoch: 5| Step: 5
Training loss: 2.224533066349262
Validation loss: 2.8204895460270105

Epoch: 5| Step: 6
Training loss: 2.7133712178084117
Validation loss: 2.735120744165995

Epoch: 5| Step: 7
Training loss: 2.950356937086321
Validation loss: 2.7468654064351727

Epoch: 5| Step: 8
Training loss: 2.328934496759785
Validation loss: 2.7251207793617596

Epoch: 5| Step: 9
Training loss: 2.4947962963297554
Validation loss: 2.735529411148077

Epoch: 5| Step: 10
Training loss: 2.1440642635336538
Validation loss: 2.7213597631988153

Epoch: 406| Step: 0
Training loss: 1.7168831136349993
Validation loss: 2.7995651762280165

Epoch: 5| Step: 1
Training loss: 2.813792122619218
Validation loss: 2.728657802236747

Epoch: 5| Step: 2
Training loss: 1.6893198302501344
Validation loss: 2.7787057573137064

Epoch: 5| Step: 3
Training loss: 2.873475209455949
Validation loss: 2.7572906780383324

Epoch: 5| Step: 4
Training loss: 2.3233251055768354
Validation loss: 2.717749567515006

Epoch: 5| Step: 5
Training loss: 2.5625158169886277
Validation loss: 2.774509494632776

Epoch: 5| Step: 6
Training loss: 2.828077790092841
Validation loss: 2.7975904281044506

Epoch: 5| Step: 7
Training loss: 1.6975665599375156
Validation loss: 2.7799184076542685

Epoch: 5| Step: 8
Training loss: 2.275271066299658
Validation loss: 2.785886967045143

Epoch: 5| Step: 9
Training loss: 2.0364934295465886
Validation loss: 2.7826233952866684

Epoch: 5| Step: 10
Training loss: 3.272750600336725
Validation loss: 2.831347955826809

Epoch: 407| Step: 0
Training loss: 2.488874188116724
Validation loss: 2.7887818732537815

Epoch: 5| Step: 1
Training loss: 2.3806040050314903
Validation loss: 2.761570188229167

Epoch: 5| Step: 2
Training loss: 2.624370953710516
Validation loss: 2.7424380261582177

Epoch: 5| Step: 3
Training loss: 1.8938129125034229
Validation loss: 2.8386851989155875

Epoch: 5| Step: 4
Training loss: 2.482270314942124
Validation loss: 2.7352316662655616

Epoch: 5| Step: 5
Training loss: 2.968903708243297
Validation loss: 2.803891480337243

Epoch: 5| Step: 6
Training loss: 1.8736207975767623
Validation loss: 2.8178937048577417

Epoch: 5| Step: 7
Training loss: 2.254304159863576
Validation loss: 2.7351373011289866

Epoch: 5| Step: 8
Training loss: 2.543840156475878
Validation loss: 2.758960156352884

Epoch: 5| Step: 9
Training loss: 1.9312075909646311
Validation loss: 2.7499289741181543

Epoch: 5| Step: 10
Training loss: 2.944816891688468
Validation loss: 2.811432011961602

Epoch: 408| Step: 0
Training loss: 2.286843953095205
Validation loss: 2.715719881211222

Epoch: 5| Step: 1
Training loss: 2.2565870292206274
Validation loss: 2.788464621003095

Epoch: 5| Step: 2
Training loss: 2.54567591986432
Validation loss: 2.7614305039489286

Epoch: 5| Step: 3
Training loss: 2.0912945141475325
Validation loss: 2.7623571736004444

Epoch: 5| Step: 4
Training loss: 3.2056306296522448
Validation loss: 2.8222424616577912

Epoch: 5| Step: 5
Training loss: 2.157753351217122
Validation loss: 2.815297927024953

Epoch: 5| Step: 6
Training loss: 2.774861402744894
Validation loss: 2.7467112280134707

Epoch: 5| Step: 7
Training loss: 2.101036601579796
Validation loss: 2.8479223662233397

Epoch: 5| Step: 8
Training loss: 1.9008104854394077
Validation loss: 2.849054180648448

Epoch: 5| Step: 9
Training loss: 2.6418842270209217
Validation loss: 2.7743117742370234

Epoch: 5| Step: 10
Training loss: 1.9295258859764801
Validation loss: 2.7606415712505257

Epoch: 409| Step: 0
Training loss: 2.452485310921732
Validation loss: 2.8223398490598433

Epoch: 5| Step: 1
Training loss: 2.630408120200114
Validation loss: 2.784523681119623

Epoch: 5| Step: 2
Training loss: 2.0412275140461733
Validation loss: 2.7651137902715766

Epoch: 5| Step: 3
Training loss: 2.2477180777416983
Validation loss: 2.8091294248750716

Epoch: 5| Step: 4
Training loss: 2.057355765458785
Validation loss: 2.772936221387446

Epoch: 5| Step: 5
Training loss: 2.122142216481991
Validation loss: 2.6941026385472804

Epoch: 5| Step: 6
Training loss: 2.5536963730464217
Validation loss: 2.7793902504546555

Epoch: 5| Step: 7
Training loss: 2.607886340888381
Validation loss: 2.827817592072883

Epoch: 5| Step: 8
Training loss: 2.291724210074481
Validation loss: 2.7245459938623675

Epoch: 5| Step: 9
Training loss: 2.7667404770101705
Validation loss: 2.766004809405285

Epoch: 5| Step: 10
Training loss: 2.3410731987864914
Validation loss: 2.7392208511952902

Epoch: 410| Step: 0
Training loss: 2.3377301026371455
Validation loss: 2.7736597337529054

Epoch: 5| Step: 1
Training loss: 2.252530476388301
Validation loss: 2.778170691426488

Epoch: 5| Step: 2
Training loss: 2.510517408531321
Validation loss: 2.7835043269270994

Epoch: 5| Step: 3
Training loss: 2.6285392879215204
Validation loss: 2.751912442979275

Epoch: 5| Step: 4
Training loss: 2.604850272417097
Validation loss: 2.8373110477832504

Epoch: 5| Step: 5
Training loss: 1.8496165935049216
Validation loss: 2.7395969725693954

Epoch: 5| Step: 6
Training loss: 2.3475910501423574
Validation loss: 2.7099353289833084

Epoch: 5| Step: 7
Training loss: 2.3463297569933017
Validation loss: 2.769957956886687

Epoch: 5| Step: 8
Training loss: 2.2178125684570715
Validation loss: 2.7362495131116407

Epoch: 5| Step: 9
Training loss: 2.741353660811797
Validation loss: 2.726952119681929

Epoch: 5| Step: 10
Training loss: 2.4223801608997912
Validation loss: 2.671297431315981

Epoch: 411| Step: 0
Training loss: 2.855833100793
Validation loss: 2.73725891010615

Epoch: 5| Step: 1
Training loss: 2.777319541857841
Validation loss: 2.70288671946165

Epoch: 5| Step: 2
Training loss: 2.252438177854423
Validation loss: 2.781027309917813

Epoch: 5| Step: 3
Training loss: 2.0462222623721957
Validation loss: 2.8368701671824526

Epoch: 5| Step: 4
Training loss: 2.229778764296476
Validation loss: 2.809546617452948

Epoch: 5| Step: 5
Training loss: 2.836111520519553
Validation loss: 2.773790107899976

Epoch: 5| Step: 6
Training loss: 2.392567063909381
Validation loss: 2.796706854034439

Epoch: 5| Step: 7
Training loss: 2.2104434482439315
Validation loss: 2.828995733718364

Epoch: 5| Step: 8
Training loss: 2.0309682797425253
Validation loss: 2.7646014483551413

Epoch: 5| Step: 9
Training loss: 2.1754966563411924
Validation loss: 2.689290204750428

Epoch: 5| Step: 10
Training loss: 1.891892000745159
Validation loss: 2.731979945988223

Epoch: 412| Step: 0
Training loss: 3.0145312287406703
Validation loss: 2.731942666165437

Epoch: 5| Step: 1
Training loss: 2.146171678948075
Validation loss: 2.829783962263508

Epoch: 5| Step: 2
Training loss: 3.0307273807488686
Validation loss: 2.762094325852033

Epoch: 5| Step: 3
Training loss: 2.426722836770088
Validation loss: 2.835978108454913

Epoch: 5| Step: 4
Training loss: 2.628594253867425
Validation loss: 2.735188579791502

Epoch: 5| Step: 5
Training loss: 2.0193227516435246
Validation loss: 2.76694770719405

Epoch: 5| Step: 6
Training loss: 2.3162005945938646
Validation loss: 2.8020526795716303

Epoch: 5| Step: 7
Training loss: 2.656569338283661
Validation loss: 2.796240302783301

Epoch: 5| Step: 8
Training loss: 2.121652996601537
Validation loss: 2.7698368291720885

Epoch: 5| Step: 9
Training loss: 2.024619681354001
Validation loss: 2.80415755355469

Epoch: 5| Step: 10
Training loss: 1.698048085312536
Validation loss: 2.8091422926517753

Epoch: 413| Step: 0
Training loss: 2.602868196384097
Validation loss: 2.8538969595275048

Epoch: 5| Step: 1
Training loss: 2.3174514342386834
Validation loss: 2.8218529474850342

Epoch: 5| Step: 2
Training loss: 1.9694896701174807
Validation loss: 2.808358611452615

Epoch: 5| Step: 3
Training loss: 2.1900430338912087
Validation loss: 2.8546032996374513

Epoch: 5| Step: 4
Training loss: 2.8057232912572245
Validation loss: 2.824562685977461

Epoch: 5| Step: 5
Training loss: 2.432454192934847
Validation loss: 2.752945933880268

Epoch: 5| Step: 6
Training loss: 2.393748816746352
Validation loss: 2.7391569573972863

Epoch: 5| Step: 7
Training loss: 2.5555778608408364
Validation loss: 2.8055040862495217

Epoch: 5| Step: 8
Training loss: 1.6663440233103777
Validation loss: 2.726408253852939

Epoch: 5| Step: 9
Training loss: 2.094501189799095
Validation loss: 2.7937942360064993

Epoch: 5| Step: 10
Training loss: 2.6453039485750365
Validation loss: 2.7994404375393085

Epoch: 414| Step: 0
Training loss: 1.766987097968864
Validation loss: 2.7753275408122136

Epoch: 5| Step: 1
Training loss: 1.9480316277781777
Validation loss: 2.798486198421644

Epoch: 5| Step: 2
Training loss: 2.5895329399658094
Validation loss: 2.7378291651156963

Epoch: 5| Step: 3
Training loss: 2.317085050863384
Validation loss: 2.769018082082457

Epoch: 5| Step: 4
Training loss: 2.060168827323726
Validation loss: 2.715384603495222

Epoch: 5| Step: 5
Training loss: 2.0525739699682353
Validation loss: 2.7430035571442524

Epoch: 5| Step: 6
Training loss: 2.314520906510106
Validation loss: 2.7848970210043547

Epoch: 5| Step: 7
Training loss: 2.6590963036068227
Validation loss: 2.7502077178963216

Epoch: 5| Step: 8
Training loss: 2.8298811544528926
Validation loss: 2.785253648289332

Epoch: 5| Step: 9
Training loss: 2.5647692053399576
Validation loss: 2.73396902325643

Epoch: 5| Step: 10
Training loss: 2.7027324766374856
Validation loss: 2.7993071799117097

Epoch: 415| Step: 0
Training loss: 2.205676609990986
Validation loss: 2.754800180352007

Epoch: 5| Step: 1
Training loss: 2.218614923368212
Validation loss: 2.795975566678095

Epoch: 5| Step: 2
Training loss: 2.5627134280759756
Validation loss: 2.7554173457238695

Epoch: 5| Step: 3
Training loss: 1.8921092488924265
Validation loss: 2.755635086104486

Epoch: 5| Step: 4
Training loss: 2.1568907739310643
Validation loss: 2.7660097874521115

Epoch: 5| Step: 5
Training loss: 3.072034823508377
Validation loss: 2.790234080766538

Epoch: 5| Step: 6
Training loss: 2.0213941471032104
Validation loss: 2.8244072865049965

Epoch: 5| Step: 7
Training loss: 2.375509709323318
Validation loss: 2.7997796828232797

Epoch: 5| Step: 8
Training loss: 1.9926123670916154
Validation loss: 2.812070671592504

Epoch: 5| Step: 9
Training loss: 2.606170697000543
Validation loss: 2.7816592988364226

Epoch: 5| Step: 10
Training loss: 2.4546232082754558
Validation loss: 2.7633778590956366

Epoch: 416| Step: 0
Training loss: 2.818423158765851
Validation loss: 2.8253246442084365

Epoch: 5| Step: 1
Training loss: 2.166083098341825
Validation loss: 2.8420326973188805

Epoch: 5| Step: 2
Training loss: 2.900870646304622
Validation loss: 2.7771963905365498

Epoch: 5| Step: 3
Training loss: 1.9630391686253672
Validation loss: 2.70874049405249

Epoch: 5| Step: 4
Training loss: 2.624822519751168
Validation loss: 2.7821688505912077

Epoch: 5| Step: 5
Training loss: 2.586151390795458
Validation loss: 2.7889278300418243

Epoch: 5| Step: 6
Training loss: 2.2657835806233595
Validation loss: 2.7926379500617213

Epoch: 5| Step: 7
Training loss: 2.109967635932508
Validation loss: 2.7624763208236653

Epoch: 5| Step: 8
Training loss: 2.2891764433431785
Validation loss: 2.7953122171964617

Epoch: 5| Step: 9
Training loss: 2.4210947071823194
Validation loss: 2.8145058801806826

Epoch: 5| Step: 10
Training loss: 1.7188433535105725
Validation loss: 2.8419302015395265

Epoch: 417| Step: 0
Training loss: 2.394311493439901
Validation loss: 2.7769173711558155

Epoch: 5| Step: 1
Training loss: 2.292054704123162
Validation loss: 2.772898942559407

Epoch: 5| Step: 2
Training loss: 2.2524013420625324
Validation loss: 2.769827968805009

Epoch: 5| Step: 3
Training loss: 2.3026843660083394
Validation loss: 2.790250012548755

Epoch: 5| Step: 4
Training loss: 2.3639206706967584
Validation loss: 2.7780321214649253

Epoch: 5| Step: 5
Training loss: 1.9408892244333797
Validation loss: 2.782192542915756

Epoch: 5| Step: 6
Training loss: 1.9437252447876299
Validation loss: 2.8286299163283943

Epoch: 5| Step: 7
Training loss: 2.3972790433481093
Validation loss: 2.8694133936172483

Epoch: 5| Step: 8
Training loss: 2.157899750665758
Validation loss: 2.739131051855617

Epoch: 5| Step: 9
Training loss: 2.6972130308334026
Validation loss: 2.7457663229236737

Epoch: 5| Step: 10
Training loss: 3.0422713492994924
Validation loss: 2.742047589373088

Epoch: 418| Step: 0
Training loss: 2.9599469221356576
Validation loss: 2.7324108901791098

Epoch: 5| Step: 1
Training loss: 2.4265597410364426
Validation loss: 2.835258457960175

Epoch: 5| Step: 2
Training loss: 2.606712399087244
Validation loss: 2.7600818811017143

Epoch: 5| Step: 3
Training loss: 2.963199928750847
Validation loss: 2.841020907419305

Epoch: 5| Step: 4
Training loss: 1.8845684047155205
Validation loss: 2.8185652639730034

Epoch: 5| Step: 5
Training loss: 2.1683535122744897
Validation loss: 2.7601335624513643

Epoch: 5| Step: 6
Training loss: 2.2953151674300574
Validation loss: 2.729227518284534

Epoch: 5| Step: 7
Training loss: 1.8977811330172032
Validation loss: 2.7429318192227794

Epoch: 5| Step: 8
Training loss: 2.698154620621473
Validation loss: 2.7476017899505667

Epoch: 5| Step: 9
Training loss: 1.8602253868587915
Validation loss: 2.7884121454248527

Epoch: 5| Step: 10
Training loss: 1.9477133279294951
Validation loss: 2.770292901267307

Epoch: 419| Step: 0
Training loss: 2.253985583728901
Validation loss: 2.750557548369449

Epoch: 5| Step: 1
Training loss: 2.5658471182089153
Validation loss: 2.766558231598953

Epoch: 5| Step: 2
Training loss: 2.167635725407183
Validation loss: 2.779380256501406

Epoch: 5| Step: 3
Training loss: 2.3836935446924685
Validation loss: 2.8287185719560703

Epoch: 5| Step: 4
Training loss: 2.3745063469473218
Validation loss: 2.8487958211399924

Epoch: 5| Step: 5
Training loss: 2.9038379463083697
Validation loss: 2.8221357770246702

Epoch: 5| Step: 6
Training loss: 2.887154304981624
Validation loss: 2.7467625715379236

Epoch: 5| Step: 7
Training loss: 2.536805919562837
Validation loss: 2.747737102641584

Epoch: 5| Step: 8
Training loss: 2.182064278226639
Validation loss: 2.808557200960965

Epoch: 5| Step: 9
Training loss: 2.3575454591027167
Validation loss: 2.759844855446242

Epoch: 5| Step: 10
Training loss: 1.7079188223896007
Validation loss: 2.7313119409478253

Epoch: 420| Step: 0
Training loss: 2.022979213115646
Validation loss: 2.781584179112432

Epoch: 5| Step: 1
Training loss: 2.6546854235824537
Validation loss: 2.7665585114482707

Epoch: 5| Step: 2
Training loss: 2.4046833833952945
Validation loss: 2.745434434403856

Epoch: 5| Step: 3
Training loss: 2.091694064423157
Validation loss: 2.819681978332053

Epoch: 5| Step: 4
Training loss: 3.308544316198369
Validation loss: 2.706120002331876

Epoch: 5| Step: 5
Training loss: 1.766471187405166
Validation loss: 2.7280640859874343

Epoch: 5| Step: 6
Training loss: 1.9439018680819626
Validation loss: 2.825337503556292

Epoch: 5| Step: 7
Training loss: 2.477731903955393
Validation loss: 2.7613986466069727

Epoch: 5| Step: 8
Training loss: 2.5208239174238747
Validation loss: 2.7589875505854535

Epoch: 5| Step: 9
Training loss: 2.2750716481087623
Validation loss: 2.7348655745800645

Epoch: 5| Step: 10
Training loss: 2.3181408310732996
Validation loss: 2.817269799707809

Epoch: 421| Step: 0
Training loss: 2.651498471657609
Validation loss: 2.72304621770997

Epoch: 5| Step: 1
Training loss: 2.291272447375167
Validation loss: 2.806086391281463

Epoch: 5| Step: 2
Training loss: 2.385720601493627
Validation loss: 2.7607646977364038

Epoch: 5| Step: 3
Training loss: 2.4403847472352744
Validation loss: 2.765154031454004

Epoch: 5| Step: 4
Training loss: 2.0251909707525306
Validation loss: 2.793767426700642

Epoch: 5| Step: 5
Training loss: 1.7025184601218466
Validation loss: 2.7527227915288814

Epoch: 5| Step: 6
Training loss: 3.1932336438359745
Validation loss: 2.8253647001764635

Epoch: 5| Step: 7
Training loss: 2.4012389084789674
Validation loss: 2.811438959436691

Epoch: 5| Step: 8
Training loss: 2.3157625638844794
Validation loss: 2.780429949170734

Epoch: 5| Step: 9
Training loss: 2.217053369143846
Validation loss: 2.7940391379711147

Epoch: 5| Step: 10
Training loss: 1.998961238517724
Validation loss: 2.8002936384309662

Epoch: 422| Step: 0
Training loss: 2.330998637784464
Validation loss: 2.8044692241423417

Epoch: 5| Step: 1
Training loss: 1.8007445093738759
Validation loss: 2.7374656843288845

Epoch: 5| Step: 2
Training loss: 2.124843591655975
Validation loss: 2.772565721241661

Epoch: 5| Step: 3
Training loss: 3.0444034822713975
Validation loss: 2.742259178864365

Epoch: 5| Step: 4
Training loss: 1.5937532911079684
Validation loss: 2.7993791398734116

Epoch: 5| Step: 5
Training loss: 2.1909495811145643
Validation loss: 2.7714534625030214

Epoch: 5| Step: 6
Training loss: 2.458664198339772
Validation loss: 2.7228696222251574

Epoch: 5| Step: 7
Training loss: 2.362226670212065
Validation loss: 2.8101598905663345

Epoch: 5| Step: 8
Training loss: 2.3312290671382896
Validation loss: 2.7069816942915397

Epoch: 5| Step: 9
Training loss: 3.1333718121648193
Validation loss: 2.7712828328392436

Epoch: 5| Step: 10
Training loss: 2.042979136453342
Validation loss: 2.7477732739075766

Epoch: 423| Step: 0
Training loss: 2.3220543280003287
Validation loss: 2.7773120161158067

Epoch: 5| Step: 1
Training loss: 1.9668346958255352
Validation loss: 2.8224068246224987

Epoch: 5| Step: 2
Training loss: 2.2792832767241107
Validation loss: 2.75135387307481

Epoch: 5| Step: 3
Training loss: 2.0390315144841007
Validation loss: 2.7865138379099554

Epoch: 5| Step: 4
Training loss: 2.0313910802118236
Validation loss: 2.753606679694468

Epoch: 5| Step: 5
Training loss: 2.3220454978723937
Validation loss: 2.828000194800943

Epoch: 5| Step: 6
Training loss: 2.791126502619594
Validation loss: 2.7299995707597544

Epoch: 5| Step: 7
Training loss: 2.14530544516007
Validation loss: 2.7862500960603604

Epoch: 5| Step: 8
Training loss: 2.1253113238097643
Validation loss: 2.7304541791519807

Epoch: 5| Step: 9
Training loss: 2.4864042619553297
Validation loss: 2.779371194117715

Epoch: 5| Step: 10
Training loss: 3.359811160139706
Validation loss: 2.7100460332317846

Epoch: 424| Step: 0
Training loss: 2.6501103971985938
Validation loss: 2.8296247245206283

Epoch: 5| Step: 1
Training loss: 2.208801639732573
Validation loss: 2.7725375906065155

Epoch: 5| Step: 2
Training loss: 2.2971537933346853
Validation loss: 2.7476578136987575

Epoch: 5| Step: 3
Training loss: 2.2389994961804893
Validation loss: 2.7700513047168323

Epoch: 5| Step: 4
Training loss: 3.0321757682440453
Validation loss: 2.713882951687307

Epoch: 5| Step: 5
Training loss: 2.2402166018325596
Validation loss: 2.807934063464645

Epoch: 5| Step: 6
Training loss: 2.0912531298279355
Validation loss: 2.8097317525007948

Epoch: 5| Step: 7
Training loss: 2.3482535264167312
Validation loss: 2.750144304011371

Epoch: 5| Step: 8
Training loss: 2.2190689072639334
Validation loss: 2.8081143183504222

Epoch: 5| Step: 9
Training loss: 2.1938577087565982
Validation loss: 2.6957009873569096

Epoch: 5| Step: 10
Training loss: 1.8063546939062505
Validation loss: 2.818677199796732

Epoch: 425| Step: 0
Training loss: 2.888798316937751
Validation loss: 2.777117692973477

Epoch: 5| Step: 1
Training loss: 2.180462005725081
Validation loss: 2.76840048074384

Epoch: 5| Step: 2
Training loss: 1.838832309937098
Validation loss: 2.78954557088629

Epoch: 5| Step: 3
Training loss: 1.7956494339722138
Validation loss: 2.78859400052283

Epoch: 5| Step: 4
Training loss: 2.0829878965732154
Validation loss: 2.8533594349081404

Epoch: 5| Step: 5
Training loss: 2.606524618120724
Validation loss: 2.7488223697878205

Epoch: 5| Step: 6
Training loss: 1.9227673079599863
Validation loss: 2.791177128783099

Epoch: 5| Step: 7
Training loss: 2.987172997107539
Validation loss: 2.8381997248616258

Epoch: 5| Step: 8
Training loss: 2.4321117021418974
Validation loss: 2.7999517827782605

Epoch: 5| Step: 9
Training loss: 2.670607595282114
Validation loss: 2.7149626590080596

Epoch: 5| Step: 10
Training loss: 2.2181670806668072
Validation loss: 2.764634735776705

Epoch: 426| Step: 0
Training loss: 2.584910301113179
Validation loss: 2.809801631651098

Epoch: 5| Step: 1
Training loss: 2.3115574745988954
Validation loss: 2.7594000001525356

Epoch: 5| Step: 2
Training loss: 2.5095396185022216
Validation loss: 2.8000653709377787

Epoch: 5| Step: 3
Training loss: 2.6435846299560275
Validation loss: 2.7987709468643973

Epoch: 5| Step: 4
Training loss: 2.7950564817887242
Validation loss: 2.8009687107452867

Epoch: 5| Step: 5
Training loss: 2.280693090733844
Validation loss: 2.8444567548892845

Epoch: 5| Step: 6
Training loss: 2.379709793958224
Validation loss: 2.8163256441732645

Epoch: 5| Step: 7
Training loss: 2.057994197855816
Validation loss: 2.779359756563294

Epoch: 5| Step: 8
Training loss: 2.009102373627906
Validation loss: 2.7827562606608303

Epoch: 5| Step: 9
Training loss: 1.417163294340468
Validation loss: 2.7691351286207713

Epoch: 5| Step: 10
Training loss: 2.3798516560652914
Validation loss: 2.7510821421779608

Epoch: 427| Step: 0
Training loss: 2.330518068667091
Validation loss: 2.7865247014517776

Epoch: 5| Step: 1
Training loss: 2.646779129111604
Validation loss: 2.78002075152156

Epoch: 5| Step: 2
Training loss: 2.1975554279371887
Validation loss: 2.7299540117550665

Epoch: 5| Step: 3
Training loss: 1.9664871896326037
Validation loss: 2.870082857350035

Epoch: 5| Step: 4
Training loss: 2.336646339266413
Validation loss: 2.771738181419879

Epoch: 5| Step: 5
Training loss: 2.5958383265202865
Validation loss: 2.7199287485354873

Epoch: 5| Step: 6
Training loss: 2.540836219406449
Validation loss: 2.852241039584791

Epoch: 5| Step: 7
Training loss: 1.9919709331008024
Validation loss: 2.7918846352608773

Epoch: 5| Step: 8
Training loss: 2.854455269657349
Validation loss: 2.8284221414434536

Epoch: 5| Step: 9
Training loss: 2.257346874125847
Validation loss: 2.8088511507154905

Epoch: 5| Step: 10
Training loss: 2.273285221623661
Validation loss: 2.7484721109209356

Epoch: 428| Step: 0
Training loss: 2.587192104283436
Validation loss: 2.800717588036888

Epoch: 5| Step: 1
Training loss: 2.1211182538438424
Validation loss: 2.835107953948124

Epoch: 5| Step: 2
Training loss: 2.517305843287359
Validation loss: 2.786086045838958

Epoch: 5| Step: 3
Training loss: 2.365012803476529
Validation loss: 2.7479619167569402

Epoch: 5| Step: 4
Training loss: 2.2969092541690035
Validation loss: 2.78275901246159

Epoch: 5| Step: 5
Training loss: 2.0495618119272825
Validation loss: 2.7526274860446067

Epoch: 5| Step: 6
Training loss: 1.8372657678487847
Validation loss: 2.783120498222309

Epoch: 5| Step: 7
Training loss: 2.656607749633468
Validation loss: 2.808734253217928

Epoch: 5| Step: 8
Training loss: 2.1594648858669214
Validation loss: 2.756852112504755

Epoch: 5| Step: 9
Training loss: 2.223387049989286
Validation loss: 2.783552873041516

Epoch: 5| Step: 10
Training loss: 2.7630442846934695
Validation loss: 2.7843470578779064

Epoch: 429| Step: 0
Training loss: 1.979676759806631
Validation loss: 2.7586742357261715

Epoch: 5| Step: 1
Training loss: 2.0401558119043073
Validation loss: 2.7629897647529864

Epoch: 5| Step: 2
Training loss: 2.2403047213031564
Validation loss: 2.806776723964985

Epoch: 5| Step: 3
Training loss: 2.513014582229245
Validation loss: 2.770145339789739

Epoch: 5| Step: 4
Training loss: 2.117764777841571
Validation loss: 2.7578500496865144

Epoch: 5| Step: 5
Training loss: 2.026717307855112
Validation loss: 2.8232977168395386

Epoch: 5| Step: 6
Training loss: 2.864457413188867
Validation loss: 2.744055395401543

Epoch: 5| Step: 7
Training loss: 2.601279211801425
Validation loss: 2.7700823212438905

Epoch: 5| Step: 8
Training loss: 2.482048240653897
Validation loss: 2.8432604054894504

Epoch: 5| Step: 9
Training loss: 2.6230915034538813
Validation loss: 2.8468860443427983

Epoch: 5| Step: 10
Training loss: 2.322226919456408
Validation loss: 2.8144051884044874

Epoch: 430| Step: 0
Training loss: 2.180801927075336
Validation loss: 2.7055339105398386

Epoch: 5| Step: 1
Training loss: 2.4638194813987826
Validation loss: 2.8093192432434377

Epoch: 5| Step: 2
Training loss: 2.8103387794042187
Validation loss: 2.744135522266546

Epoch: 5| Step: 3
Training loss: 1.9731861573614344
Validation loss: 2.855615472383101

Epoch: 5| Step: 4
Training loss: 2.4055049783246405
Validation loss: 2.862761467008302

Epoch: 5| Step: 5
Training loss: 2.323086810758966
Validation loss: 2.7240548623886647

Epoch: 5| Step: 6
Training loss: 2.5181313107454777
Validation loss: 2.784067170396571

Epoch: 5| Step: 7
Training loss: 2.4552849657423654
Validation loss: 2.8311036017723086

Epoch: 5| Step: 8
Training loss: 1.9710575083796316
Validation loss: 2.799264960634962

Epoch: 5| Step: 9
Training loss: 2.2426722198664026
Validation loss: 2.7759712769178253

Epoch: 5| Step: 10
Training loss: 2.4676741175106436
Validation loss: 2.7567796078678097

Epoch: 431| Step: 0
Training loss: 2.3581393208133328
Validation loss: 2.80030104839668

Epoch: 5| Step: 1
Training loss: 2.149087925336615
Validation loss: 2.717162575357075

Epoch: 5| Step: 2
Training loss: 3.2310821430575776
Validation loss: 2.8556183914292212

Epoch: 5| Step: 3
Training loss: 2.1526674003060324
Validation loss: 2.770373793367432

Epoch: 5| Step: 4
Training loss: 1.8024902839769141
Validation loss: 2.748578603859591

Epoch: 5| Step: 5
Training loss: 2.7612354335858327
Validation loss: 2.749475542848342

Epoch: 5| Step: 6
Training loss: 1.9294181357734168
Validation loss: 2.812863739082635

Epoch: 5| Step: 7
Training loss: 2.835143427374386
Validation loss: 2.7485799469689374

Epoch: 5| Step: 8
Training loss: 2.140230908280524
Validation loss: 2.831216621052761

Epoch: 5| Step: 9
Training loss: 2.461583225365909
Validation loss: 2.755422084247618

Epoch: 5| Step: 10
Training loss: 1.5207638485158965
Validation loss: 2.764383072299721

Epoch: 432| Step: 0
Training loss: 3.1490490037939862
Validation loss: 2.7636130427817216

Epoch: 5| Step: 1
Training loss: 2.09001806369988
Validation loss: 2.778886797839184

Epoch: 5| Step: 2
Training loss: 2.330389777395061
Validation loss: 2.737418792362193

Epoch: 5| Step: 3
Training loss: 2.9758024271529213
Validation loss: 2.771346410569544

Epoch: 5| Step: 4
Training loss: 2.2998187864482906
Validation loss: 2.7251762572845886

Epoch: 5| Step: 5
Training loss: 2.5657735244934807
Validation loss: 2.742775024545675

Epoch: 5| Step: 6
Training loss: 1.3033214430173146
Validation loss: 2.781550640150765

Epoch: 5| Step: 7
Training loss: 1.8297826310599603
Validation loss: 2.780187308156353

Epoch: 5| Step: 8
Training loss: 2.654825524238448
Validation loss: 2.7970381259695696

Epoch: 5| Step: 9
Training loss: 1.5558540146850528
Validation loss: 2.7877626672476747

Epoch: 5| Step: 10
Training loss: 2.378938020140124
Validation loss: 2.7947117068972793

Epoch: 433| Step: 0
Training loss: 2.5741516011905485
Validation loss: 2.8068021613528464

Epoch: 5| Step: 1
Training loss: 2.199814927379501
Validation loss: 2.8306373972027123

Epoch: 5| Step: 2
Training loss: 2.3191354765344148
Validation loss: 2.8537447555939597

Epoch: 5| Step: 3
Training loss: 2.404410315408697
Validation loss: 2.8560267896711626

Epoch: 5| Step: 4
Training loss: 2.7252540399969196
Validation loss: 2.7849973418010876

Epoch: 5| Step: 5
Training loss: 1.8755250195731328
Validation loss: 2.806142553368214

Epoch: 5| Step: 6
Training loss: 2.8915397227746653
Validation loss: 2.8011138270503033

Epoch: 5| Step: 7
Training loss: 2.3017841219460546
Validation loss: 2.7688203852745046

Epoch: 5| Step: 8
Training loss: 1.682928391966932
Validation loss: 2.784386877460415

Epoch: 5| Step: 9
Training loss: 2.346407794798199
Validation loss: 2.8483301128358036

Epoch: 5| Step: 10
Training loss: 2.317529312820809
Validation loss: 2.7789352175115676

Epoch: 434| Step: 0
Training loss: 1.9567139876631439
Validation loss: 2.740324804277642

Epoch: 5| Step: 1
Training loss: 2.591484367198334
Validation loss: 2.791841326707501

Epoch: 5| Step: 2
Training loss: 2.6070497854532406
Validation loss: 2.7675862385543053

Epoch: 5| Step: 3
Training loss: 2.139361711840271
Validation loss: 2.75347233791472

Epoch: 5| Step: 4
Training loss: 1.5964937714294831
Validation loss: 2.72647397812334

Epoch: 5| Step: 5
Training loss: 2.292329611400212
Validation loss: 2.7292472563186543

Epoch: 5| Step: 6
Training loss: 1.7971000198779457
Validation loss: 2.7786882490325646

Epoch: 5| Step: 7
Training loss: 2.3005883956936204
Validation loss: 2.780088175793694

Epoch: 5| Step: 8
Training loss: 2.3017592626347785
Validation loss: 2.796586343115156

Epoch: 5| Step: 9
Training loss: 2.9545749556128986
Validation loss: 2.713965976659339

Epoch: 5| Step: 10
Training loss: 2.400341359339838
Validation loss: 2.7587097413274377

Epoch: 435| Step: 0
Training loss: 2.256114070105202
Validation loss: 2.765390733692648

Epoch: 5| Step: 1
Training loss: 2.1973413615419584
Validation loss: 2.750459028623137

Epoch: 5| Step: 2
Training loss: 2.2252569286005857
Validation loss: 2.862050130718757

Epoch: 5| Step: 3
Training loss: 2.6575014644414217
Validation loss: 2.8038125582802973

Epoch: 5| Step: 4
Training loss: 3.037938711877918
Validation loss: 2.6931435543177518

Epoch: 5| Step: 5
Training loss: 2.472457034024093
Validation loss: 2.8011393190666682

Epoch: 5| Step: 6
Training loss: 2.115361400957041
Validation loss: 2.7729388960284003

Epoch: 5| Step: 7
Training loss: 2.4080589727740103
Validation loss: 2.868372191354056

Epoch: 5| Step: 8
Training loss: 2.3649108816699558
Validation loss: 2.7386848398395003

Epoch: 5| Step: 9
Training loss: 2.3359692421482032
Validation loss: 2.8403008770094695

Epoch: 5| Step: 10
Training loss: 1.8313282998697111
Validation loss: 2.801910299592941

Epoch: 436| Step: 0
Training loss: 2.294297413377942
Validation loss: 2.7824829454747624

Epoch: 5| Step: 1
Training loss: 2.5679139421844597
Validation loss: 2.786420330393764

Epoch: 5| Step: 2
Training loss: 2.079980695708266
Validation loss: 2.7329373716538536

Epoch: 5| Step: 3
Training loss: 2.5223074352006454
Validation loss: 2.770263970205305

Epoch: 5| Step: 4
Training loss: 1.6757696547029275
Validation loss: 2.801861925149811

Epoch: 5| Step: 5
Training loss: 2.8341623851097344
Validation loss: 2.7676072110417738

Epoch: 5| Step: 6
Training loss: 2.6767951325323858
Validation loss: 2.856035331456518

Epoch: 5| Step: 7
Training loss: 2.381872373132551
Validation loss: 2.8182834023778796

Epoch: 5| Step: 8
Training loss: 1.6897224343923165
Validation loss: 2.771832044578691

Epoch: 5| Step: 9
Training loss: 1.7695264668852644
Validation loss: 2.736037989203694

Epoch: 5| Step: 10
Training loss: 2.110851082208256
Validation loss: 2.7806992740831875

Epoch: 437| Step: 0
Training loss: 2.077785263399363
Validation loss: 2.8196953971084957

Epoch: 5| Step: 1
Training loss: 2.4959239155715016
Validation loss: 2.6571761541651164

Epoch: 5| Step: 2
Training loss: 2.76226999697601
Validation loss: 2.717726640623871

Epoch: 5| Step: 3
Training loss: 2.1189237000147916
Validation loss: 2.850995075512446

Epoch: 5| Step: 4
Training loss: 1.9770153868736842
Validation loss: 2.762514731414705

Epoch: 5| Step: 5
Training loss: 2.3404149041404922
Validation loss: 2.8088636054027187

Epoch: 5| Step: 6
Training loss: 3.1615690225562383
Validation loss: 2.7544358593029217

Epoch: 5| Step: 7
Training loss: 1.9098155336028522
Validation loss: 2.8600470303845626

Epoch: 5| Step: 8
Training loss: 2.1005829864722414
Validation loss: 2.863153719685391

Epoch: 5| Step: 9
Training loss: 2.4035642423382653
Validation loss: 2.809576079742747

Epoch: 5| Step: 10
Training loss: 2.0818585580058007
Validation loss: 2.766724412631491

Epoch: 438| Step: 0
Training loss: 2.4562172807450713
Validation loss: 2.8184660388518705

Epoch: 5| Step: 1
Training loss: 2.4093381213422247
Validation loss: 2.7441874544213745

Epoch: 5| Step: 2
Training loss: 2.1091290365856588
Validation loss: 2.7859674100437957

Epoch: 5| Step: 3
Training loss: 2.518037480366994
Validation loss: 2.828972690728659

Epoch: 5| Step: 4
Training loss: 2.2049589707759134
Validation loss: 2.844569851063625

Epoch: 5| Step: 5
Training loss: 2.2870733061177013
Validation loss: 2.800486335107928

Epoch: 5| Step: 6
Training loss: 2.5284994746293075
Validation loss: 2.802561173502776

Epoch: 5| Step: 7
Training loss: 2.144562045294886
Validation loss: 2.6979047814837225

Epoch: 5| Step: 8
Training loss: 2.0431600156568397
Validation loss: 2.774997516584038

Epoch: 5| Step: 9
Training loss: 1.5386343423372415
Validation loss: 2.7927896105002747

Epoch: 5| Step: 10
Training loss: 3.0162575804405267
Validation loss: 2.791095034743379

Epoch: 439| Step: 0
Training loss: 1.9995436147677295
Validation loss: 2.7737006421225945

Epoch: 5| Step: 1
Training loss: 2.3425081141767965
Validation loss: 2.773012645948221

Epoch: 5| Step: 2
Training loss: 2.1603542464780814
Validation loss: 2.758465480647172

Epoch: 5| Step: 3
Training loss: 2.7015247348950022
Validation loss: 2.8719060120934574

Epoch: 5| Step: 4
Training loss: 2.016738583987473
Validation loss: 2.7505161681011017

Epoch: 5| Step: 5
Training loss: 2.070004076746368
Validation loss: 2.766382259152009

Epoch: 5| Step: 6
Training loss: 2.2743993867602947
Validation loss: 2.8425716170506194

Epoch: 5| Step: 7
Training loss: 2.7227240270773887
Validation loss: 2.7724410632702403

Epoch: 5| Step: 8
Training loss: 1.9444080992738142
Validation loss: 2.7776637897552336

Epoch: 5| Step: 9
Training loss: 2.473586547756258
Validation loss: 2.7090675198168483

Epoch: 5| Step: 10
Training loss: 2.622412814426592
Validation loss: 2.8396236850496646

Epoch: 440| Step: 0
Training loss: 2.3139151289928783
Validation loss: 2.7998843872722037

Epoch: 5| Step: 1
Training loss: 2.192962800858069
Validation loss: 2.7885469634799

Epoch: 5| Step: 2
Training loss: 2.4426031245909505
Validation loss: 2.814602680910525

Epoch: 5| Step: 3
Training loss: 2.165634410667064
Validation loss: 2.852510203480346

Epoch: 5| Step: 4
Training loss: 1.7684622055299049
Validation loss: 2.824906926750384

Epoch: 5| Step: 5
Training loss: 2.4281706659645113
Validation loss: 2.837037372230167

Epoch: 5| Step: 6
Training loss: 2.5562056483965705
Validation loss: 2.7752289378366712

Epoch: 5| Step: 7
Training loss: 2.069327757217491
Validation loss: 2.7395391589731277

Epoch: 5| Step: 8
Training loss: 2.5561271134290884
Validation loss: 2.7827830240418043

Epoch: 5| Step: 9
Training loss: 2.575817948584109
Validation loss: 2.767282247469304

Epoch: 5| Step: 10
Training loss: 2.2077136579824135
Validation loss: 2.750129238011604

Epoch: 441| Step: 0
Training loss: 2.3727912670980555
Validation loss: 2.7692520998547905

Epoch: 5| Step: 1
Training loss: 1.9663173844903759
Validation loss: 2.78177774972823

Epoch: 5| Step: 2
Training loss: 2.7697133164492245
Validation loss: 2.7650216535221666

Epoch: 5| Step: 3
Training loss: 1.981000900252945
Validation loss: 2.6639674976329224

Epoch: 5| Step: 4
Training loss: 2.133321847984073
Validation loss: 2.7373804885279838

Epoch: 5| Step: 5
Training loss: 3.0496774158922806
Validation loss: 2.806362097660636

Epoch: 5| Step: 6
Training loss: 1.7964393419302025
Validation loss: 2.811750527701668

Epoch: 5| Step: 7
Training loss: 2.1474058691495443
Validation loss: 2.7704468648112743

Epoch: 5| Step: 8
Training loss: 2.809842782967819
Validation loss: 2.784168426233882

Epoch: 5| Step: 9
Training loss: 1.8943396402581028
Validation loss: 2.8349838911237892

Epoch: 5| Step: 10
Training loss: 2.665920292194329
Validation loss: 2.723082176558893

Epoch: 442| Step: 0
Training loss: 2.976712440859279
Validation loss: 2.6834978704261307

Epoch: 5| Step: 1
Training loss: 2.6586623065011032
Validation loss: 2.729776110717274

Epoch: 5| Step: 2
Training loss: 1.77071383203938
Validation loss: 2.726405751714511

Epoch: 5| Step: 3
Training loss: 2.2231700015185196
Validation loss: 2.777821467339727

Epoch: 5| Step: 4
Training loss: 2.28652792949957
Validation loss: 2.803636271003559

Epoch: 5| Step: 5
Training loss: 2.3449701820543734
Validation loss: 2.7731028762684025

Epoch: 5| Step: 6
Training loss: 1.876371581365373
Validation loss: 2.7817694121492886

Epoch: 5| Step: 7
Training loss: 2.1109172693013036
Validation loss: 2.7085220760210795

Epoch: 5| Step: 8
Training loss: 1.8531350326909792
Validation loss: 2.7275930616620507

Epoch: 5| Step: 9
Training loss: 2.503131335913632
Validation loss: 2.7562768809047817

Epoch: 5| Step: 10
Training loss: 2.0445452528209103
Validation loss: 2.7775347327138586

Epoch: 443| Step: 0
Training loss: 1.7330626600398116
Validation loss: 2.7661474466854465

Epoch: 5| Step: 1
Training loss: 2.091767696458492
Validation loss: 2.8002412655086113

Epoch: 5| Step: 2
Training loss: 2.751601966345254
Validation loss: 2.7915397441322036

Epoch: 5| Step: 3
Training loss: 1.967189412498605
Validation loss: 2.8161742152765554

Epoch: 5| Step: 4
Training loss: 1.9352296632802766
Validation loss: 2.8901470291355196

Epoch: 5| Step: 5
Training loss: 2.040925559653062
Validation loss: 2.8363346056976106

Epoch: 5| Step: 6
Training loss: 2.5422941798620493
Validation loss: 2.7810299048743587

Epoch: 5| Step: 7
Training loss: 2.4249621004898727
Validation loss: 2.8620444320422083

Epoch: 5| Step: 8
Training loss: 2.381393360217939
Validation loss: 2.864643929624599

Epoch: 5| Step: 9
Training loss: 2.944266783754641
Validation loss: 2.8064158289076273

Epoch: 5| Step: 10
Training loss: 2.6321224587484338
Validation loss: 2.784742111382433

Epoch: 444| Step: 0
Training loss: 2.443506128186776
Validation loss: 2.8120647754522117

Epoch: 5| Step: 1
Training loss: 1.7000197353339468
Validation loss: 2.7749211513082166

Epoch: 5| Step: 2
Training loss: 2.493053895553655
Validation loss: 2.8193265425290686

Epoch: 5| Step: 3
Training loss: 2.17937508261713
Validation loss: 2.738592737865515

Epoch: 5| Step: 4
Training loss: 2.2373734209283245
Validation loss: 2.805894468412444

Epoch: 5| Step: 5
Training loss: 1.836763431552403
Validation loss: 2.840729737796356

Epoch: 5| Step: 6
Training loss: 1.4962282444034352
Validation loss: 2.727434634644726

Epoch: 5| Step: 7
Training loss: 3.0868890381775946
Validation loss: 2.801865453300852

Epoch: 5| Step: 8
Training loss: 2.6854131713876006
Validation loss: 2.7336182215356

Epoch: 5| Step: 9
Training loss: 2.454271279541103
Validation loss: 2.7639211730863407

Epoch: 5| Step: 10
Training loss: 2.5524841512847467
Validation loss: 2.7842087547996037

Epoch: 445| Step: 0
Training loss: 2.726409470600371
Validation loss: 2.7512991475665

Epoch: 5| Step: 1
Training loss: 2.3373053892996354
Validation loss: 2.719373582220358

Epoch: 5| Step: 2
Training loss: 2.0387728547499795
Validation loss: 2.7488195779514966

Epoch: 5| Step: 3
Training loss: 2.428915017530262
Validation loss: 2.7672929099758394

Epoch: 5| Step: 4
Training loss: 2.314163537559642
Validation loss: 2.753278096673971

Epoch: 5| Step: 5
Training loss: 2.8060382788637668
Validation loss: 2.7504420368000777

Epoch: 5| Step: 6
Training loss: 2.2806851458491746
Validation loss: 2.7729907325198164

Epoch: 5| Step: 7
Training loss: 1.6688605968387258
Validation loss: 2.794398503982717

Epoch: 5| Step: 8
Training loss: 1.9832155940693423
Validation loss: 2.76715717499285

Epoch: 5| Step: 9
Training loss: 2.2177312956971478
Validation loss: 2.78414441002753

Epoch: 5| Step: 10
Training loss: 2.285020403614393
Validation loss: 2.7348767360817634

Epoch: 446| Step: 0
Training loss: 1.9586307286293099
Validation loss: 2.7632711933690355

Epoch: 5| Step: 1
Training loss: 2.3351032719452505
Validation loss: 2.7022791595457822

Epoch: 5| Step: 2
Training loss: 2.1002365524030395
Validation loss: 2.7937488520026346

Epoch: 5| Step: 3
Training loss: 2.3944478106001785
Validation loss: 2.787067026137544

Epoch: 5| Step: 4
Training loss: 1.6769171290840676
Validation loss: 2.7072504483364295

Epoch: 5| Step: 5
Training loss: 2.995102540618735
Validation loss: 2.7303221328713154

Epoch: 5| Step: 6
Training loss: 2.5330809576242164
Validation loss: 2.741038553840555

Epoch: 5| Step: 7
Training loss: 2.6374803587557323
Validation loss: 2.784568910740579

Epoch: 5| Step: 8
Training loss: 2.3375195915502713
Validation loss: 2.8055953102161064

Epoch: 5| Step: 9
Training loss: 2.0281908915062496
Validation loss: 2.8104709393019913

Epoch: 5| Step: 10
Training loss: 2.827279823425897
Validation loss: 2.7674717119448986

Epoch: 447| Step: 0
Training loss: 2.653893176909312
Validation loss: 2.7274701831619126

Epoch: 5| Step: 1
Training loss: 2.552156460291735
Validation loss: 2.854958357898341

Epoch: 5| Step: 2
Training loss: 2.123843495431035
Validation loss: 2.7554028370261645

Epoch: 5| Step: 3
Training loss: 1.7452185568802827
Validation loss: 2.7458513024176154

Epoch: 5| Step: 4
Training loss: 1.8708285022268243
Validation loss: 2.838391316723832

Epoch: 5| Step: 5
Training loss: 2.044714449880245
Validation loss: 2.785682172821935

Epoch: 5| Step: 6
Training loss: 1.5599078993630486
Validation loss: 2.7920351723440837

Epoch: 5| Step: 7
Training loss: 1.72381891645353
Validation loss: 2.8432112612476828

Epoch: 5| Step: 8
Training loss: 3.6569716564620776
Validation loss: 2.803806984452332

Epoch: 5| Step: 9
Training loss: 2.2101391540491813
Validation loss: 2.778112236383141

Epoch: 5| Step: 10
Training loss: 2.418735561278468
Validation loss: 2.8110357723003028

Epoch: 448| Step: 0
Training loss: 2.45285236763166
Validation loss: 2.825150236925838

Epoch: 5| Step: 1
Training loss: 2.1254233892180303
Validation loss: 2.7213651653447686

Epoch: 5| Step: 2
Training loss: 2.5732281042071916
Validation loss: 2.8467981571110483

Epoch: 5| Step: 3
Training loss: 1.9243027774431738
Validation loss: 2.747799463700603

Epoch: 5| Step: 4
Training loss: 2.0850217716534862
Validation loss: 2.864896047010862

Epoch: 5| Step: 5
Training loss: 3.0151344651433885
Validation loss: 2.763863394314205

Epoch: 5| Step: 6
Training loss: 2.4246259263169563
Validation loss: 2.7590423609994637

Epoch: 5| Step: 7
Training loss: 2.2757470633508676
Validation loss: 2.852595713800078

Epoch: 5| Step: 8
Training loss: 2.2780689373888783
Validation loss: 2.738449850999689

Epoch: 5| Step: 9
Training loss: 2.3686669891225502
Validation loss: 2.726797030622224

Epoch: 5| Step: 10
Training loss: 2.0921717146718852
Validation loss: 2.8094454217131015

Epoch: 449| Step: 0
Training loss: 2.590919052755865
Validation loss: 2.782381924063897

Epoch: 5| Step: 1
Training loss: 1.860939009223025
Validation loss: 2.762871533693821

Epoch: 5| Step: 2
Training loss: 1.8720126832181883
Validation loss: 2.835323903651353

Epoch: 5| Step: 3
Training loss: 2.1385802366925524
Validation loss: 2.7265554970356543

Epoch: 5| Step: 4
Training loss: 2.398944217200302
Validation loss: 2.734032829193367

Epoch: 5| Step: 5
Training loss: 2.2691777228082444
Validation loss: 2.7650064182494427

Epoch: 5| Step: 6
Training loss: 2.1790653557747066
Validation loss: 2.754895056122391

Epoch: 5| Step: 7
Training loss: 2.3885053824591087
Validation loss: 2.8037035027144213

Epoch: 5| Step: 8
Training loss: 2.215512129433397
Validation loss: 2.847855410103225

Epoch: 5| Step: 9
Training loss: 2.691025838557062
Validation loss: 2.7915939700549033

Epoch: 5| Step: 10
Training loss: 3.0025179151116497
Validation loss: 2.8363347096411533

Epoch: 450| Step: 0
Training loss: 2.6999893965336312
Validation loss: 2.845715110299131

Epoch: 5| Step: 1
Training loss: 2.5983102075682605
Validation loss: 2.8269722174919125

Epoch: 5| Step: 2
Training loss: 1.922298539795961
Validation loss: 2.70239604012387

Epoch: 5| Step: 3
Training loss: 1.4985263261134025
Validation loss: 2.767885039587645

Epoch: 5| Step: 4
Training loss: 2.5901101552153922
Validation loss: 2.9020204211737664

Epoch: 5| Step: 5
Training loss: 2.5149904955462534
Validation loss: 2.822640679361172

Epoch: 5| Step: 6
Training loss: 2.228558097789005
Validation loss: 2.7445949712718734

Epoch: 5| Step: 7
Training loss: 2.313401330100622
Validation loss: 2.7033266675954493

Epoch: 5| Step: 8
Training loss: 1.7847220061714777
Validation loss: 2.753915780646662

Epoch: 5| Step: 9
Training loss: 2.498687113304035
Validation loss: 2.7460965292038457

Epoch: 5| Step: 10
Training loss: 2.578367926972332
Validation loss: 2.7175854923653633

Epoch: 451| Step: 0
Training loss: 2.0176889660532193
Validation loss: 2.7299768960588064

Epoch: 5| Step: 1
Training loss: 1.658830611592191
Validation loss: 2.7481851229079353

Epoch: 5| Step: 2
Training loss: 2.761192865225272
Validation loss: 2.716917882925422

Epoch: 5| Step: 3
Training loss: 2.0829569921718964
Validation loss: 2.8187007371421964

Epoch: 5| Step: 4
Training loss: 3.006964388089389
Validation loss: 2.8592911780892436

Epoch: 5| Step: 5
Training loss: 2.0948326386311895
Validation loss: 2.7886160478293465

Epoch: 5| Step: 6
Training loss: 2.5206237789939006
Validation loss: 2.8048360685089246

Epoch: 5| Step: 7
Training loss: 2.306957407233667
Validation loss: 2.7812867954313982

Epoch: 5| Step: 8
Training loss: 1.85230520297599
Validation loss: 2.771393517537367

Epoch: 5| Step: 9
Training loss: 2.4449205175793085
Validation loss: 2.7314900038130294

Epoch: 5| Step: 10
Training loss: 2.1887153519045364
Validation loss: 2.774992476134118

Epoch: 452| Step: 0
Training loss: 2.597878536953033
Validation loss: 2.759857992025101

Epoch: 5| Step: 1
Training loss: 1.935371829835409
Validation loss: 2.824643456089826

Epoch: 5| Step: 2
Training loss: 2.5303423160672773
Validation loss: 2.758715475039124

Epoch: 5| Step: 3
Training loss: 2.279863955471147
Validation loss: 2.774389170879759

Epoch: 5| Step: 4
Training loss: 2.4245008446488785
Validation loss: 2.7615539684492334

Epoch: 5| Step: 5
Training loss: 1.8106177850065315
Validation loss: 2.7781215031204556

Epoch: 5| Step: 6
Training loss: 1.8612324388852775
Validation loss: 2.8356411279952285

Epoch: 5| Step: 7
Training loss: 2.4393872510996766
Validation loss: 2.8248473124795415

Epoch: 5| Step: 8
Training loss: 2.199204222934369
Validation loss: 2.7876411783357273

Epoch: 5| Step: 9
Training loss: 2.9050333080910042
Validation loss: 2.8279100099669874

Epoch: 5| Step: 10
Training loss: 2.1699632972039318
Validation loss: 2.7849921169350966

Epoch: 453| Step: 0
Training loss: 2.2211608683360473
Validation loss: 2.7563677892851857

Epoch: 5| Step: 1
Training loss: 2.5740762071984364
Validation loss: 2.7778849249516484

Epoch: 5| Step: 2
Training loss: 2.2732788240305872
Validation loss: 2.7677628726744814

Epoch: 5| Step: 3
Training loss: 3.091541156808876
Validation loss: 2.77761983306204

Epoch: 5| Step: 4
Training loss: 1.5062053594661797
Validation loss: 2.8155327728555393

Epoch: 5| Step: 5
Training loss: 1.868748543014724
Validation loss: 2.820910071461601

Epoch: 5| Step: 6
Training loss: 2.041970470427917
Validation loss: 2.77266033213695

Epoch: 5| Step: 7
Training loss: 2.3487200112126088
Validation loss: 2.82558540749437

Epoch: 5| Step: 8
Training loss: 1.9778362286368276
Validation loss: 2.770625617764203

Epoch: 5| Step: 9
Training loss: 2.2383185311985723
Validation loss: 2.6445746143566566

Epoch: 5| Step: 10
Training loss: 2.1819828758791586
Validation loss: 2.7470044053406477

Epoch: 454| Step: 0
Training loss: 2.887157112669365
Validation loss: 2.6874111091200845

Epoch: 5| Step: 1
Training loss: 2.2034549330813102
Validation loss: 2.800191459650851

Epoch: 5| Step: 2
Training loss: 2.089300980005631
Validation loss: 2.8156118043479217

Epoch: 5| Step: 3
Training loss: 2.127261473107968
Validation loss: 2.7756807906569323

Epoch: 5| Step: 4
Training loss: 1.7830468868738156
Validation loss: 2.7847222166303744

Epoch: 5| Step: 5
Training loss: 2.0486475134882243
Validation loss: 2.8025499238943428

Epoch: 5| Step: 6
Training loss: 2.7547275481880407
Validation loss: 2.7729236737460115

Epoch: 5| Step: 7
Training loss: 2.3337463512913152
Validation loss: 2.840148110546386

Epoch: 5| Step: 8
Training loss: 2.2018725575529094
Validation loss: 2.8388637550027034

Epoch: 5| Step: 9
Training loss: 2.3212433562956574
Validation loss: 2.8566451350946718

Epoch: 5| Step: 10
Training loss: 1.6652293524419184
Validation loss: 2.7389367042791304

Epoch: 455| Step: 0
Training loss: 2.6991881880844883
Validation loss: 2.786807755941392

Epoch: 5| Step: 1
Training loss: 2.4642418369786117
Validation loss: 2.7940999316267887

Epoch: 5| Step: 2
Training loss: 2.14302040341019
Validation loss: 2.7570441083464368

Epoch: 5| Step: 3
Training loss: 2.1561215127450883
Validation loss: 2.816770796159552

Epoch: 5| Step: 4
Training loss: 2.4500661841036124
Validation loss: 2.8512852238258644

Epoch: 5| Step: 5
Training loss: 1.8746354066504323
Validation loss: 2.7885494659397008

Epoch: 5| Step: 6
Training loss: 2.0796147793065085
Validation loss: 2.7938755533634807

Epoch: 5| Step: 7
Training loss: 2.601951776196918
Validation loss: 2.724281943241929

Epoch: 5| Step: 8
Training loss: 1.7470769311684649
Validation loss: 2.7595717747083475

Epoch: 5| Step: 9
Training loss: 2.3203442503943537
Validation loss: 2.7872915422772797

Epoch: 5| Step: 10
Training loss: 2.1756604912768958
Validation loss: 2.7581949346197954

Epoch: 456| Step: 0
Training loss: 2.247263409782391
Validation loss: 2.8576706441479343

Epoch: 5| Step: 1
Training loss: 2.1693673785929444
Validation loss: 2.7325051895069956

Epoch: 5| Step: 2
Training loss: 2.4467322764664376
Validation loss: 2.7557055239528463

Epoch: 5| Step: 3
Training loss: 1.9788780671231403
Validation loss: 2.7096766902126164

Epoch: 5| Step: 4
Training loss: 2.690747538931853
Validation loss: 2.726489161673245

Epoch: 5| Step: 5
Training loss: 2.6335337751694956
Validation loss: 2.811595899956895

Epoch: 5| Step: 6
Training loss: 1.7180050709464183
Validation loss: 2.7642224820720127

Epoch: 5| Step: 7
Training loss: 2.3231886175649197
Validation loss: 2.7920243265702545

Epoch: 5| Step: 8
Training loss: 2.6524812777880475
Validation loss: 2.7626822413780214

Epoch: 5| Step: 9
Training loss: 2.1910896276530294
Validation loss: 2.814081839630821

Epoch: 5| Step: 10
Training loss: 1.9519415359809564
Validation loss: 2.7811619706767563

Epoch: 457| Step: 0
Training loss: 2.8352359292761165
Validation loss: 2.806444575465121

Epoch: 5| Step: 1
Training loss: 2.4963912667161905
Validation loss: 2.7580799566984626

Epoch: 5| Step: 2
Training loss: 2.5046535096982576
Validation loss: 2.8154869543704235

Epoch: 5| Step: 3
Training loss: 2.1428825558563305
Validation loss: 2.7813431172431495

Epoch: 5| Step: 4
Training loss: 2.716557726011664
Validation loss: 2.761943048873493

Epoch: 5| Step: 5
Training loss: 2.2932613257628853
Validation loss: 2.8420490152613174

Epoch: 5| Step: 6
Training loss: 1.855805055356882
Validation loss: 2.749685327270588

Epoch: 5| Step: 7
Training loss: 2.1021625555539574
Validation loss: 2.8499497421617357

Epoch: 5| Step: 8
Training loss: 2.3949039038570454
Validation loss: 2.7959970129758407

Epoch: 5| Step: 9
Training loss: 1.897129126027573
Validation loss: 2.7624696204919026

Epoch: 5| Step: 10
Training loss: 1.8372312491967098
Validation loss: 2.786687947564056

Epoch: 458| Step: 0
Training loss: 1.838779603368439
Validation loss: 2.839560620363019

Epoch: 5| Step: 1
Training loss: 2.050432331738796
Validation loss: 2.7418775546621803

Epoch: 5| Step: 2
Training loss: 2.5839244002275508
Validation loss: 2.804666262749135

Epoch: 5| Step: 3
Training loss: 2.3869374076713594
Validation loss: 2.821181969241831

Epoch: 5| Step: 4
Training loss: 2.1437985917970845
Validation loss: 2.785127082132007

Epoch: 5| Step: 5
Training loss: 1.941545938113883
Validation loss: 2.834983210195183

Epoch: 5| Step: 6
Training loss: 2.4945174181298126
Validation loss: 2.7706638866952735

Epoch: 5| Step: 7
Training loss: 2.9376092444052087
Validation loss: 2.815928862243003

Epoch: 5| Step: 8
Training loss: 2.2242751837573094
Validation loss: 2.8592832064070173

Epoch: 5| Step: 9
Training loss: 2.422496986505388
Validation loss: 2.8052544378575752

Epoch: 5| Step: 10
Training loss: 1.9680422767269556
Validation loss: 2.789091961288754

Epoch: 459| Step: 0
Training loss: 2.4883091324661812
Validation loss: 2.740132561309274

Epoch: 5| Step: 1
Training loss: 2.750282099733188
Validation loss: 2.8042910094492273

Epoch: 5| Step: 2
Training loss: 1.7129398282334134
Validation loss: 2.8395500617460416

Epoch: 5| Step: 3
Training loss: 2.2957553340264587
Validation loss: 2.7920649043496986

Epoch: 5| Step: 4
Training loss: 2.1741750051392854
Validation loss: 2.79599714867656

Epoch: 5| Step: 5
Training loss: 1.7679180008182471
Validation loss: 2.7938812892314018

Epoch: 5| Step: 6
Training loss: 2.716113686790432
Validation loss: 2.793686945850758

Epoch: 5| Step: 7
Training loss: 2.0596136067788335
Validation loss: 2.8165722751498663

Epoch: 5| Step: 8
Training loss: 1.8995319869201692
Validation loss: 2.7593876826837365

Epoch: 5| Step: 9
Training loss: 2.717470766978877
Validation loss: 2.796815443616489

Epoch: 5| Step: 10
Training loss: 2.252258968180017
Validation loss: 2.757877677577917

Epoch: 460| Step: 0
Training loss: 2.141149414871129
Validation loss: 2.8224340004336685

Epoch: 5| Step: 1
Training loss: 2.629005917704623
Validation loss: 2.8446799534452047

Epoch: 5| Step: 2
Training loss: 2.236919208355155
Validation loss: 2.815049760080299

Epoch: 5| Step: 3
Training loss: 1.9234450215394798
Validation loss: 2.7794757975930846

Epoch: 5| Step: 4
Training loss: 1.9092566745387143
Validation loss: 2.7551608373570606

Epoch: 5| Step: 5
Training loss: 2.211583235296996
Validation loss: 2.772887332231311

Epoch: 5| Step: 6
Training loss: 2.5387502625022464
Validation loss: 2.715384556289374

Epoch: 5| Step: 7
Training loss: 2.6523068050457588
Validation loss: 2.793345495862672

Epoch: 5| Step: 8
Training loss: 2.2661699363170746
Validation loss: 2.7935423508900286

Epoch: 5| Step: 9
Training loss: 2.004152041227888
Validation loss: 2.803006157266272

Epoch: 5| Step: 10
Training loss: 2.2771449321245747
Validation loss: 2.764088117380758

Epoch: 461| Step: 0
Training loss: 1.957541576250899
Validation loss: 2.7392409177837536

Epoch: 5| Step: 1
Training loss: 2.0124808932516913
Validation loss: 2.829990598117342

Epoch: 5| Step: 2
Training loss: 2.2580053121742494
Validation loss: 2.764297431831147

Epoch: 5| Step: 3
Training loss: 2.723404506498817
Validation loss: 2.821345409910142

Epoch: 5| Step: 4
Training loss: 1.8671882022872306
Validation loss: 2.7376073883175818

Epoch: 5| Step: 5
Training loss: 2.5779620494786664
Validation loss: 2.7790867807482664

Epoch: 5| Step: 6
Training loss: 2.0206884614068406
Validation loss: 2.787930113103

Epoch: 5| Step: 7
Training loss: 1.925626427421796
Validation loss: 2.784603543905277

Epoch: 5| Step: 8
Training loss: 2.741810482006056
Validation loss: 2.7691237043351262

Epoch: 5| Step: 9
Training loss: 2.5301483959659623
Validation loss: 2.782571926191397

Epoch: 5| Step: 10
Training loss: 2.2646372779614006
Validation loss: 2.760989183681423

Epoch: 462| Step: 0
Training loss: 2.077646185991209
Validation loss: 2.8205637232071497

Epoch: 5| Step: 1
Training loss: 2.3229740175657154
Validation loss: 2.783678173548293

Epoch: 5| Step: 2
Training loss: 2.1535621143999104
Validation loss: 2.744941753244137

Epoch: 5| Step: 3
Training loss: 3.379325920018082
Validation loss: 2.757437339925885

Epoch: 5| Step: 4
Training loss: 2.469309489917096
Validation loss: 2.7526405127098217

Epoch: 5| Step: 5
Training loss: 2.464844427093558
Validation loss: 2.7796397731061773

Epoch: 5| Step: 6
Training loss: 1.9636377231837232
Validation loss: 2.8295786105454486

Epoch: 5| Step: 7
Training loss: 2.205831069724153
Validation loss: 2.762467963038907

Epoch: 5| Step: 8
Training loss: 1.836604350302694
Validation loss: 2.807929259260465

Epoch: 5| Step: 9
Training loss: 2.325611062914108
Validation loss: 2.7335594796385476

Epoch: 5| Step: 10
Training loss: 1.6047638693877395
Validation loss: 2.7985241257590774

Epoch: 463| Step: 0
Training loss: 1.7758489002611788
Validation loss: 2.8580971147530043

Epoch: 5| Step: 1
Training loss: 2.254304582909518
Validation loss: 2.740781545342984

Epoch: 5| Step: 2
Training loss: 2.4385790270572767
Validation loss: 2.747765191417038

Epoch: 5| Step: 3
Training loss: 2.792149392899543
Validation loss: 2.7777128532643136

Epoch: 5| Step: 4
Training loss: 2.198841123530652
Validation loss: 2.77249257803766

Epoch: 5| Step: 5
Training loss: 2.6236875977167324
Validation loss: 2.771911935915915

Epoch: 5| Step: 6
Training loss: 2.086520795669604
Validation loss: 2.7768486650927624

Epoch: 5| Step: 7
Training loss: 2.5879690251980456
Validation loss: 2.765588304876307

Epoch: 5| Step: 8
Training loss: 1.584199827242797
Validation loss: 2.8030369847390797

Epoch: 5| Step: 9
Training loss: 2.367812373209267
Validation loss: 2.7724018738270026

Epoch: 5| Step: 10
Training loss: 2.2783291028013024
Validation loss: 2.828781901917701

Epoch: 464| Step: 0
Training loss: 1.875607900621009
Validation loss: 2.82837525554902

Epoch: 5| Step: 1
Training loss: 2.5578222611322032
Validation loss: 2.792022442420353

Epoch: 5| Step: 2
Training loss: 2.5345577715010594
Validation loss: 2.7856180636327945

Epoch: 5| Step: 3
Training loss: 2.2902584141681945
Validation loss: 2.7821260137075523

Epoch: 5| Step: 4
Training loss: 2.6180461329103104
Validation loss: 2.801764313191703

Epoch: 5| Step: 5
Training loss: 1.9842913752679798
Validation loss: 2.7553985869327486

Epoch: 5| Step: 6
Training loss: 1.989841051702688
Validation loss: 2.7343389440172117

Epoch: 5| Step: 7
Training loss: 1.7430116218140046
Validation loss: 2.7874398202799653

Epoch: 5| Step: 8
Training loss: 2.259403499777029
Validation loss: 2.7878849453694743

Epoch: 5| Step: 9
Training loss: 2.7630025208082376
Validation loss: 2.8326985922780388

Epoch: 5| Step: 10
Training loss: 2.4600088153464066
Validation loss: 2.790283854880478

Epoch: 465| Step: 0
Training loss: 2.9835323721981952
Validation loss: 2.802070286144752

Epoch: 5| Step: 1
Training loss: 2.728495352689544
Validation loss: 2.778024079023549

Epoch: 5| Step: 2
Training loss: 2.3387412911379872
Validation loss: 2.7706137573324687

Epoch: 5| Step: 3
Training loss: 1.6057431619953801
Validation loss: 2.780443093603494

Epoch: 5| Step: 4
Training loss: 1.935387413315735
Validation loss: 2.8516420504714115

Epoch: 5| Step: 5
Training loss: 2.956135340719184
Validation loss: 2.8072609948932707

Epoch: 5| Step: 6
Training loss: 1.6188469080840704
Validation loss: 2.7638812274661433

Epoch: 5| Step: 7
Training loss: 2.1351345961443142
Validation loss: 2.8263428286803842

Epoch: 5| Step: 8
Training loss: 2.069852727543847
Validation loss: 2.694222142294076

Epoch: 5| Step: 9
Training loss: 2.153821600522532
Validation loss: 2.8013973699425905

Epoch: 5| Step: 10
Training loss: 1.8253792251175434
Validation loss: 2.767975536158426

Epoch: 466| Step: 0
Training loss: 2.3329015286851487
Validation loss: 2.772983416911124

Epoch: 5| Step: 1
Training loss: 2.4904345622660804
Validation loss: 2.8302511597702824

Epoch: 5| Step: 2
Training loss: 2.33980074987878
Validation loss: 2.748658913183172

Epoch: 5| Step: 3
Training loss: 2.458903704494854
Validation loss: 2.7444601594099884

Epoch: 5| Step: 4
Training loss: 1.9666801349803724
Validation loss: 2.765880582408506

Epoch: 5| Step: 5
Training loss: 2.21603442284465
Validation loss: 2.823827631886713

Epoch: 5| Step: 6
Training loss: 1.8821555610035665
Validation loss: 2.86124726151494

Epoch: 5| Step: 7
Training loss: 1.7790192137222602
Validation loss: 2.749695407708327

Epoch: 5| Step: 8
Training loss: 2.3658553299839213
Validation loss: 2.8115957595381857

Epoch: 5| Step: 9
Training loss: 2.3863944724596635
Validation loss: 2.7167502254960527

Epoch: 5| Step: 10
Training loss: 2.5650643334305383
Validation loss: 2.739303631359392

Epoch: 467| Step: 0
Training loss: 1.7934285822937606
Validation loss: 2.803923164837607

Epoch: 5| Step: 1
Training loss: 2.014879073875782
Validation loss: 2.81755717467654

Epoch: 5| Step: 2
Training loss: 2.3410864381536585
Validation loss: 2.8206934372372574

Epoch: 5| Step: 3
Training loss: 2.2443388609816917
Validation loss: 2.7564008710774326

Epoch: 5| Step: 4
Training loss: 2.255543661112291
Validation loss: 2.730505599749227

Epoch: 5| Step: 5
Training loss: 2.985199499827771
Validation loss: 2.7977255745060727

Epoch: 5| Step: 6
Training loss: 1.8624238734720837
Validation loss: 2.7256434620274543

Epoch: 5| Step: 7
Training loss: 2.820631944312675
Validation loss: 2.7484889321044434

Epoch: 5| Step: 8
Training loss: 1.6264015902356181
Validation loss: 2.8272701791989343

Epoch: 5| Step: 9
Training loss: 2.6656001958553888
Validation loss: 2.7810776479553883

Epoch: 5| Step: 10
Training loss: 2.2111450744887344
Validation loss: 2.7847716832802147

Epoch: 468| Step: 0
Training loss: 1.9992834834254443
Validation loss: 2.793005402979428

Epoch: 5| Step: 1
Training loss: 2.4013775130674713
Validation loss: 2.758035127385685

Epoch: 5| Step: 2
Training loss: 2.1039934244379483
Validation loss: 2.8034737333407893

Epoch: 5| Step: 3
Training loss: 2.5673909845581235
Validation loss: 2.752848185023884

Epoch: 5| Step: 4
Training loss: 2.8805960221259745
Validation loss: 2.751583333409499

Epoch: 5| Step: 5
Training loss: 2.1030208250094873
Validation loss: 2.784302024455391

Epoch: 5| Step: 6
Training loss: 1.808536141386433
Validation loss: 2.775699145455536

Epoch: 5| Step: 7
Training loss: 2.650422739102834
Validation loss: 2.752506696575493

Epoch: 5| Step: 8
Training loss: 2.0672296567324873
Validation loss: 2.8183917446092726

Epoch: 5| Step: 9
Training loss: 1.8800857870332977
Validation loss: 2.7304906939128046

Epoch: 5| Step: 10
Training loss: 2.255796489417044
Validation loss: 2.79379416993788

Epoch: 469| Step: 0
Training loss: 2.1618131660381654
Validation loss: 2.737405555591682

Epoch: 5| Step: 1
Training loss: 2.2465268986218905
Validation loss: 2.8587582099644173

Epoch: 5| Step: 2
Training loss: 2.4442057191954616
Validation loss: 2.790663825722263

Epoch: 5| Step: 3
Training loss: 1.7536771832858777
Validation loss: 2.827602793542443

Epoch: 5| Step: 4
Training loss: 2.714172016716723
Validation loss: 2.7944566045854105

Epoch: 5| Step: 5
Training loss: 1.9789675227580117
Validation loss: 2.808577230378866

Epoch: 5| Step: 6
Training loss: 1.7669695570546373
Validation loss: 2.803626319130463

Epoch: 5| Step: 7
Training loss: 1.7014753419186257
Validation loss: 2.853754886186079

Epoch: 5| Step: 8
Training loss: 1.6784294207486266
Validation loss: 2.8030337617081877

Epoch: 5| Step: 9
Training loss: 3.160257344933487
Validation loss: 2.7728718868508806

Epoch: 5| Step: 10
Training loss: 2.758280684630387
Validation loss: 2.8915161603831185

Epoch: 470| Step: 0
Training loss: 1.9440486126618166
Validation loss: 2.870126162541487

Epoch: 5| Step: 1
Training loss: 2.136631045032159
Validation loss: 2.7711440405688794

Epoch: 5| Step: 2
Training loss: 2.1957477396063347
Validation loss: 2.7850982839934577

Epoch: 5| Step: 3
Training loss: 2.3764140286488553
Validation loss: 2.750152117566918

Epoch: 5| Step: 4
Training loss: 1.7369331532969876
Validation loss: 2.7036656698412203

Epoch: 5| Step: 5
Training loss: 2.0086304894570004
Validation loss: 2.783106662681203

Epoch: 5| Step: 6
Training loss: 3.1728883825098877
Validation loss: 2.853780431252752

Epoch: 5| Step: 7
Training loss: 2.2433430422175555
Validation loss: 2.7041378472169324

Epoch: 5| Step: 8
Training loss: 2.3155960801927447
Validation loss: 2.810627909247395

Epoch: 5| Step: 9
Training loss: 2.1522367419661896
Validation loss: 2.8124579732983954

Epoch: 5| Step: 10
Training loss: 1.94843626657063
Validation loss: 2.839172495190056

Epoch: 471| Step: 0
Training loss: 2.47270465339423
Validation loss: 2.8597055933646325

Epoch: 5| Step: 1
Training loss: 1.8281844691849727
Validation loss: 2.7766750750268927

Epoch: 5| Step: 2
Training loss: 2.2977802802174114
Validation loss: 2.752291188239641

Epoch: 5| Step: 3
Training loss: 2.51491086312718
Validation loss: 2.71177104804591

Epoch: 5| Step: 4
Training loss: 2.2727741964871417
Validation loss: 2.779507697696798

Epoch: 5| Step: 5
Training loss: 2.128901098402597
Validation loss: 2.7743103604192942

Epoch: 5| Step: 6
Training loss: 2.604996988803639
Validation loss: 2.8291270229810843

Epoch: 5| Step: 7
Training loss: 1.8635545446193638
Validation loss: 2.733663288083032

Epoch: 5| Step: 8
Training loss: 2.7415157701733417
Validation loss: 2.830227886057243

Epoch: 5| Step: 9
Training loss: 2.121612766337355
Validation loss: 2.764250991320909

Epoch: 5| Step: 10
Training loss: 2.0502062763547104
Validation loss: 2.8041721363749015

Epoch: 472| Step: 0
Training loss: 1.760076192702129
Validation loss: 2.765828944489794

Epoch: 5| Step: 1
Training loss: 2.4503886517918585
Validation loss: 2.8322381627100732

Epoch: 5| Step: 2
Training loss: 2.1532289654306576
Validation loss: 2.801373255268296

Epoch: 5| Step: 3
Training loss: 2.497426234044687
Validation loss: 2.791633468623996

Epoch: 5| Step: 4
Training loss: 3.2503166044517577
Validation loss: 2.7519477209494028

Epoch: 5| Step: 5
Training loss: 1.637771013269785
Validation loss: 2.876853111132686

Epoch: 5| Step: 6
Training loss: 2.201339755895539
Validation loss: 2.804177703991728

Epoch: 5| Step: 7
Training loss: 2.2040143754216825
Validation loss: 2.7403357105990414

Epoch: 5| Step: 8
Training loss: 1.5023449211889692
Validation loss: 2.7549303498717275

Epoch: 5| Step: 9
Training loss: 2.7420634271532625
Validation loss: 2.7378927078672093

Epoch: 5| Step: 10
Training loss: 2.0844393146892797
Validation loss: 2.7549729889419017

Epoch: 473| Step: 0
Training loss: 2.9435576617018517
Validation loss: 2.8376699866798307

Epoch: 5| Step: 1
Training loss: 2.543910073532325
Validation loss: 2.7487127716452244

Epoch: 5| Step: 2
Training loss: 2.1090911674275135
Validation loss: 2.825882259862268

Epoch: 5| Step: 3
Training loss: 1.8562902940685952
Validation loss: 2.7760284933896493

Epoch: 5| Step: 4
Training loss: 2.1711915402182242
Validation loss: 2.9255395019946033

Epoch: 5| Step: 5
Training loss: 2.103130337168481
Validation loss: 2.8052110825691607

Epoch: 5| Step: 6
Training loss: 1.9077583973904348
Validation loss: 2.7016855760882135

Epoch: 5| Step: 7
Training loss: 2.0549816312688285
Validation loss: 2.707543200740744

Epoch: 5| Step: 8
Training loss: 2.639110333927851
Validation loss: 2.8436461074387873

Epoch: 5| Step: 9
Training loss: 2.1805752822836784
Validation loss: 2.811638007017176

Epoch: 5| Step: 10
Training loss: 2.485096089061527
Validation loss: 2.765193365336597

Epoch: 474| Step: 0
Training loss: 2.3316868922365486
Validation loss: 2.8166546523955693

Epoch: 5| Step: 1
Training loss: 2.555772556775934
Validation loss: 2.803709035601249

Epoch: 5| Step: 2
Training loss: 2.981259942188119
Validation loss: 2.7332229470288794

Epoch: 5| Step: 3
Training loss: 2.182422630974956
Validation loss: 2.856226877604644

Epoch: 5| Step: 4
Training loss: 2.128389348264071
Validation loss: 2.80681876997031

Epoch: 5| Step: 5
Training loss: 2.3420428352901626
Validation loss: 2.733898719290769

Epoch: 5| Step: 6
Training loss: 2.1357377221889764
Validation loss: 2.784464348063754

Epoch: 5| Step: 7
Training loss: 2.3772646496889327
Validation loss: 2.722911510200124

Epoch: 5| Step: 8
Training loss: 1.747304407069285
Validation loss: 2.730368809639737

Epoch: 5| Step: 9
Training loss: 1.7224820626353308
Validation loss: 2.827666102255643

Epoch: 5| Step: 10
Training loss: 1.560687730755941
Validation loss: 2.799720023407

Epoch: 475| Step: 0
Training loss: 2.003120848462449
Validation loss: 2.846600943978605

Epoch: 5| Step: 1
Training loss: 1.838031629611922
Validation loss: 2.7122912356686997

Epoch: 5| Step: 2
Training loss: 2.4512794501419024
Validation loss: 2.7744461279888677

Epoch: 5| Step: 3
Training loss: 2.3313246891442168
Validation loss: 2.839527187466897

Epoch: 5| Step: 4
Training loss: 2.226438498808591
Validation loss: 2.707584391770311

Epoch: 5| Step: 5
Training loss: 2.1116593036759093
Validation loss: 2.828355931025176

Epoch: 5| Step: 6
Training loss: 2.586436335920389
Validation loss: 2.7702134116092894

Epoch: 5| Step: 7
Training loss: 2.300154232990569
Validation loss: 2.718587967425723

Epoch: 5| Step: 8
Training loss: 2.6587918853688737
Validation loss: 2.7692076634028657

Epoch: 5| Step: 9
Training loss: 1.8462939411737682
Validation loss: 2.7476774365991155

Epoch: 5| Step: 10
Training loss: 2.1102882951240565
Validation loss: 2.765063785586505

Epoch: 476| Step: 0
Training loss: 2.364965321163589
Validation loss: 2.72941719683151

Epoch: 5| Step: 1
Training loss: 2.410388310913245
Validation loss: 2.713026750909903

Epoch: 5| Step: 2
Training loss: 2.36538335455407
Validation loss: 2.7098782316205208

Epoch: 5| Step: 3
Training loss: 2.0025513587871044
Validation loss: 2.753646154316833

Epoch: 5| Step: 4
Training loss: 2.4843249046025395
Validation loss: 2.8468496915461055

Epoch: 5| Step: 5
Training loss: 2.086640657358299
Validation loss: 2.85573660333232

Epoch: 5| Step: 6
Training loss: 1.7827355063125683
Validation loss: 2.818220199454955

Epoch: 5| Step: 7
Training loss: 1.6718988149497624
Validation loss: 2.82441717650195

Epoch: 5| Step: 8
Training loss: 2.0847433150843337
Validation loss: 2.856012679871199

Epoch: 5| Step: 9
Training loss: 2.1881771674389334
Validation loss: 2.801879572265389

Epoch: 5| Step: 10
Training loss: 2.9181617356384204
Validation loss: 2.7726682172341612

Epoch: 477| Step: 0
Training loss: 2.200770425279001
Validation loss: 2.7356832929544255

Epoch: 5| Step: 1
Training loss: 2.5218283420864878
Validation loss: 2.8130096374871334

Epoch: 5| Step: 2
Training loss: 2.1416538856609852
Validation loss: 2.7551311267551455

Epoch: 5| Step: 3
Training loss: 2.20177196321159
Validation loss: 2.7424267051971962

Epoch: 5| Step: 4
Training loss: 1.5078840485827605
Validation loss: 2.8234668224804733

Epoch: 5| Step: 5
Training loss: 2.472285961610542
Validation loss: 2.8046932174126638

Epoch: 5| Step: 6
Training loss: 2.3305901910418148
Validation loss: 2.823941533357995

Epoch: 5| Step: 7
Training loss: 1.865028825388833
Validation loss: 2.781696668546755

Epoch: 5| Step: 8
Training loss: 2.02724202218734
Validation loss: 2.8586111067632536

Epoch: 5| Step: 9
Training loss: 2.496225464021675
Validation loss: 2.7793080591525254

Epoch: 5| Step: 10
Training loss: 2.5886848353828085
Validation loss: 2.7324974230634327

Epoch: 478| Step: 0
Training loss: 2.1186219033197204
Validation loss: 2.8159990300584012

Epoch: 5| Step: 1
Training loss: 2.3900695354928416
Validation loss: 2.696137549633022

Epoch: 5| Step: 2
Training loss: 2.0815707443571134
Validation loss: 2.730844688364007

Epoch: 5| Step: 3
Training loss: 2.763374921932867
Validation loss: 2.8473286505202418

Epoch: 5| Step: 4
Training loss: 2.2982135427606942
Validation loss: 2.7467911402066396

Epoch: 5| Step: 5
Training loss: 2.0552462554181083
Validation loss: 2.761072886860799

Epoch: 5| Step: 6
Training loss: 2.0841060985421227
Validation loss: 2.8230067116415793

Epoch: 5| Step: 7
Training loss: 2.6280976138689525
Validation loss: 2.742952338127261

Epoch: 5| Step: 8
Training loss: 1.933603984150631
Validation loss: 2.7930775858765524

Epoch: 5| Step: 9
Training loss: 1.889858815707537
Validation loss: 2.7524747909010383

Epoch: 5| Step: 10
Training loss: 1.8290385384605623
Validation loss: 2.819245256355242

Epoch: 479| Step: 0
Training loss: 2.310927603947392
Validation loss: 2.816796671168129

Epoch: 5| Step: 1
Training loss: 2.746344998452471
Validation loss: 2.7642853875145392

Epoch: 5| Step: 2
Training loss: 1.7268435564467826
Validation loss: 2.762731447529681

Epoch: 5| Step: 3
Training loss: 1.738673888020838
Validation loss: 2.7995711980498448

Epoch: 5| Step: 4
Training loss: 1.673467786498844
Validation loss: 2.7650406131232805

Epoch: 5| Step: 5
Training loss: 2.0561119334703024
Validation loss: 2.7992335897430927

Epoch: 5| Step: 6
Training loss: 2.8003767032625775
Validation loss: 2.843001597017579

Epoch: 5| Step: 7
Training loss: 2.1440056606687716
Validation loss: 2.778267067677065

Epoch: 5| Step: 8
Training loss: 2.7441574802084667
Validation loss: 2.7565694007831008

Epoch: 5| Step: 9
Training loss: 2.368725267749193
Validation loss: 2.7775994438091747

Epoch: 5| Step: 10
Training loss: 1.9329312509308745
Validation loss: 2.801675889407144

Epoch: 480| Step: 0
Training loss: 1.611219811700505
Validation loss: 2.82247564152711

Epoch: 5| Step: 1
Training loss: 1.9305177825171962
Validation loss: 2.8347326191713083

Epoch: 5| Step: 2
Training loss: 2.671773897455538
Validation loss: 2.851812345713253

Epoch: 5| Step: 3
Training loss: 2.2344268579400595
Validation loss: 2.8465885832561826

Epoch: 5| Step: 4
Training loss: 3.047603265829323
Validation loss: 2.758294986728083

Epoch: 5| Step: 5
Training loss: 2.4125839693151785
Validation loss: 2.7738679941430218

Epoch: 5| Step: 6
Training loss: 2.318475580557009
Validation loss: 2.8042898904866256

Epoch: 5| Step: 7
Training loss: 2.4875132574753693
Validation loss: 2.802365120337659

Epoch: 5| Step: 8
Training loss: 2.0515567730070483
Validation loss: 2.8164082416316147

Epoch: 5| Step: 9
Training loss: 2.0601147817836596
Validation loss: 2.8472557558782317

Epoch: 5| Step: 10
Training loss: 1.5898705932450543
Validation loss: 2.8634305028486375

Epoch: 481| Step: 0
Training loss: 2.0182513492144523
Validation loss: 2.8168766164349437

Epoch: 5| Step: 1
Training loss: 1.929773490935752
Validation loss: 2.873382216627477

Epoch: 5| Step: 2
Training loss: 2.4041364230452467
Validation loss: 2.7748100455944846

Epoch: 5| Step: 3
Training loss: 1.7956880712801342
Validation loss: 2.7251118610953924

Epoch: 5| Step: 4
Training loss: 2.531787956434673
Validation loss: 2.7328169717501583

Epoch: 5| Step: 5
Training loss: 2.311381714009273
Validation loss: 2.8401128891868033

Epoch: 5| Step: 6
Training loss: 1.7061277743986418
Validation loss: 2.781954464213557

Epoch: 5| Step: 7
Training loss: 2.5176919537033666
Validation loss: 2.8299741707856594

Epoch: 5| Step: 8
Training loss: 2.3453301761375345
Validation loss: 2.825325844670779

Epoch: 5| Step: 9
Training loss: 2.212345173908915
Validation loss: 2.8170427485502305

Epoch: 5| Step: 10
Training loss: 2.751554309977918
Validation loss: 2.839469721979449

Epoch: 482| Step: 0
Training loss: 2.1673830633067914
Validation loss: 2.837014612334113

Epoch: 5| Step: 1
Training loss: 2.2972295578277375
Validation loss: 2.775303691966505

Epoch: 5| Step: 2
Training loss: 2.2877949925724446
Validation loss: 2.7929174724713297

Epoch: 5| Step: 3
Training loss: 1.7285560387666041
Validation loss: 2.7649004504884855

Epoch: 5| Step: 4
Training loss: 2.6124546357373175
Validation loss: 2.857194795224343

Epoch: 5| Step: 5
Training loss: 1.7388329476948077
Validation loss: 2.81668736379288

Epoch: 5| Step: 6
Training loss: 1.5841313492665707
Validation loss: 2.767137576739979

Epoch: 5| Step: 7
Training loss: 2.292404391292905
Validation loss: 2.780441999158497

Epoch: 5| Step: 8
Training loss: 2.7373133974620614
Validation loss: 2.813404820964766

Epoch: 5| Step: 9
Training loss: 2.4220952087702705
Validation loss: 2.7863322702818416

Epoch: 5| Step: 10
Training loss: 2.52633698824722
Validation loss: 2.7756125545920263

Epoch: 483| Step: 0
Training loss: 2.7795622773293363
Validation loss: 2.840382827819349

Epoch: 5| Step: 1
Training loss: 2.033141326698022
Validation loss: 2.8086425159974073

Epoch: 5| Step: 2
Training loss: 2.219902813648534
Validation loss: 2.784044169916918

Epoch: 5| Step: 3
Training loss: 2.0773851038334
Validation loss: 2.7496359543153734

Epoch: 5| Step: 4
Training loss: 2.0274159560088303
Validation loss: 2.760559858128466

Epoch: 5| Step: 5
Training loss: 1.937020334734745
Validation loss: 2.8661676160866008

Epoch: 5| Step: 6
Training loss: 2.3307601045796407
Validation loss: 2.811584569785755

Epoch: 5| Step: 7
Training loss: 2.1023740654967167
Validation loss: 2.7751954246086576

Epoch: 5| Step: 8
Training loss: 2.30318461409581
Validation loss: 2.830313350841114

Epoch: 5| Step: 9
Training loss: 2.0228268206281133
Validation loss: 2.7889729854817444

Epoch: 5| Step: 10
Training loss: 2.988506074314285
Validation loss: 2.724876207909935

Epoch: 484| Step: 0
Training loss: 2.256277228954573
Validation loss: 2.8392451052642738

Epoch: 5| Step: 1
Training loss: 2.1848468494645648
Validation loss: 2.787864853727538

Epoch: 5| Step: 2
Training loss: 2.145396685077222
Validation loss: 2.6895558167714375

Epoch: 5| Step: 3
Training loss: 1.802534792877772
Validation loss: 2.7674975495101055

Epoch: 5| Step: 4
Training loss: 1.9102770683288859
Validation loss: 2.833552811378053

Epoch: 5| Step: 5
Training loss: 1.8042014652387908
Validation loss: 2.7784206696148397

Epoch: 5| Step: 6
Training loss: 2.520310581535276
Validation loss: 2.7853801120544373

Epoch: 5| Step: 7
Training loss: 2.714997343480056
Validation loss: 2.7827353452278483

Epoch: 5| Step: 8
Training loss: 1.927667216606574
Validation loss: 2.8242155511420095

Epoch: 5| Step: 9
Training loss: 1.4422192438833175
Validation loss: 2.8197957263280005

Epoch: 5| Step: 10
Training loss: 2.8093999095656845
Validation loss: 2.7343323575634018

Epoch: 485| Step: 0
Training loss: 2.2277831897474316
Validation loss: 2.788134744049347

Epoch: 5| Step: 1
Training loss: 2.4236936570337746
Validation loss: 2.8018613972077406

Epoch: 5| Step: 2
Training loss: 2.6516907102916196
Validation loss: 2.8086785591717462

Epoch: 5| Step: 3
Training loss: 1.6905440672507328
Validation loss: 2.7525605952385654

Epoch: 5| Step: 4
Training loss: 2.0719698048530777
Validation loss: 2.7737942688137567

Epoch: 5| Step: 5
Training loss: 2.7086120657663293
Validation loss: 2.7882329209662724

Epoch: 5| Step: 6
Training loss: 2.3856738311431163
Validation loss: 2.825700105450578

Epoch: 5| Step: 7
Training loss: 1.5588421539989175
Validation loss: 2.7905264282713116

Epoch: 5| Step: 8
Training loss: 1.3601157263997168
Validation loss: 2.8245022829602426

Epoch: 5| Step: 9
Training loss: 2.610007660514727
Validation loss: 2.7863523407723596

Epoch: 5| Step: 10
Training loss: 1.9344943944909467
Validation loss: 2.768535280634391

Epoch: 486| Step: 0
Training loss: 2.8452756373422967
Validation loss: 2.8147146058207073

Epoch: 5| Step: 1
Training loss: 2.484287476347437
Validation loss: 2.7719092330005326

Epoch: 5| Step: 2
Training loss: 2.133456960711992
Validation loss: 2.8171572373869336

Epoch: 5| Step: 3
Training loss: 2.2358693281080333
Validation loss: 2.6734726969654057

Epoch: 5| Step: 4
Training loss: 2.112781966312784
Validation loss: 2.7708957947889

Epoch: 5| Step: 5
Training loss: 1.8165163068346555
Validation loss: 2.791484373774515

Epoch: 5| Step: 6
Training loss: 2.178000833264236
Validation loss: 2.759144787466588

Epoch: 5| Step: 7
Training loss: 1.8776746111461957
Validation loss: 2.751487908328226

Epoch: 5| Step: 8
Training loss: 1.9796375584493962
Validation loss: 2.695210413272403

Epoch: 5| Step: 9
Training loss: 2.418252117949913
Validation loss: 2.7653870375632295

Epoch: 5| Step: 10
Training loss: 1.616378803121553
Validation loss: 2.773772247878416

Epoch: 487| Step: 0
Training loss: 2.1125343681113016
Validation loss: 2.6693747796389258

Epoch: 5| Step: 1
Training loss: 1.6310803292266187
Validation loss: 2.779403635931312

Epoch: 5| Step: 2
Training loss: 1.94708557214764
Validation loss: 2.740713129768592

Epoch: 5| Step: 3
Training loss: 2.261453721721017
Validation loss: 2.7669286541098876

Epoch: 5| Step: 4
Training loss: 1.8651774292886083
Validation loss: 2.8667725593094784

Epoch: 5| Step: 5
Training loss: 2.253183867258252
Validation loss: 2.816029473136877

Epoch: 5| Step: 6
Training loss: 2.9105714233002145
Validation loss: 2.7393262288585345

Epoch: 5| Step: 7
Training loss: 2.4953721127110473
Validation loss: 2.8076105401101765

Epoch: 5| Step: 8
Training loss: 2.047655379067024
Validation loss: 2.8411766930263105

Epoch: 5| Step: 9
Training loss: 2.1916659332196806
Validation loss: 2.794335109453592

Epoch: 5| Step: 10
Training loss: 2.212055907427624
Validation loss: 2.7857849251945077

Epoch: 488| Step: 0
Training loss: 2.3657479016164604
Validation loss: 2.7790555741351497

Epoch: 5| Step: 1
Training loss: 2.1649749705076973
Validation loss: 2.7733778451884525

Epoch: 5| Step: 2
Training loss: 2.5309051467140797
Validation loss: 2.7273223050528146

Epoch: 5| Step: 3
Training loss: 2.477072485752165
Validation loss: 2.821761766226223

Epoch: 5| Step: 4
Training loss: 1.6885238649660284
Validation loss: 2.837130104245578

Epoch: 5| Step: 5
Training loss: 2.198658629617678
Validation loss: 2.813670051048857

Epoch: 5| Step: 6
Training loss: 1.9397207884085412
Validation loss: 2.825002881040564

Epoch: 5| Step: 7
Training loss: 2.0448655609858815
Validation loss: 2.7536613360686837

Epoch: 5| Step: 8
Training loss: 2.419182246420067
Validation loss: 2.7897541625529465

Epoch: 5| Step: 9
Training loss: 2.235318924851839
Validation loss: 2.7550321182580215

Epoch: 5| Step: 10
Training loss: 1.8799304351719548
Validation loss: 2.7455226348828004

Epoch: 489| Step: 0
Training loss: 1.4985024606190012
Validation loss: 2.7961523942373994

Epoch: 5| Step: 1
Training loss: 2.7796055078877613
Validation loss: 2.8110520613326857

Epoch: 5| Step: 2
Training loss: 2.302969806468247
Validation loss: 2.74211188701366

Epoch: 5| Step: 3
Training loss: 2.0178932615922585
Validation loss: 2.7484660750813497

Epoch: 5| Step: 4
Training loss: 2.6945741388452995
Validation loss: 2.7571323591066914

Epoch: 5| Step: 5
Training loss: 1.9223265078755116
Validation loss: 2.7439439442880276

Epoch: 5| Step: 6
Training loss: 1.9149760654636987
Validation loss: 2.7717936484158776

Epoch: 5| Step: 7
Training loss: 1.7681965288868362
Validation loss: 2.722994830424443

Epoch: 5| Step: 8
Training loss: 2.705816527575752
Validation loss: 2.7672483123641367

Epoch: 5| Step: 9
Training loss: 1.6191049164629592
Validation loss: 2.728739570640323

Epoch: 5| Step: 10
Training loss: 2.0170032609148194
Validation loss: 2.78847737314485

Epoch: 490| Step: 0
Training loss: 1.8500421132629812
Validation loss: 2.7678647925801063

Epoch: 5| Step: 1
Training loss: 2.250358764867877
Validation loss: 2.7788036501635305

Epoch: 5| Step: 2
Training loss: 2.027105004984426
Validation loss: 2.7169965880260754

Epoch: 5| Step: 3
Training loss: 2.2361788637415683
Validation loss: 2.7769086192383927

Epoch: 5| Step: 4
Training loss: 1.9352032984903775
Validation loss: 2.828446478694087

Epoch: 5| Step: 5
Training loss: 2.5231762446693686
Validation loss: 2.8501473774968553

Epoch: 5| Step: 6
Training loss: 2.3109421508824797
Validation loss: 2.723800976192582

Epoch: 5| Step: 7
Training loss: 2.7849387235081258
Validation loss: 2.8923848469734708

Epoch: 5| Step: 8
Training loss: 1.8624645178570487
Validation loss: 2.7604400825706925

Epoch: 5| Step: 9
Training loss: 2.4328378939421107
Validation loss: 2.8717143070314703

Epoch: 5| Step: 10
Training loss: 2.202660802541659
Validation loss: 2.730112971488413

Epoch: 491| Step: 0
Training loss: 1.7967076762702678
Validation loss: 2.8398451781343703

Epoch: 5| Step: 1
Training loss: 1.9819753961508366
Validation loss: 2.7960704316040252

Epoch: 5| Step: 2
Training loss: 2.37032943045618
Validation loss: 2.877891524768944

Epoch: 5| Step: 3
Training loss: 2.138402745980306
Validation loss: 2.8102316866605683

Epoch: 5| Step: 4
Training loss: 2.1677563812439975
Validation loss: 2.769734335770589

Epoch: 5| Step: 5
Training loss: 2.8880795380267403
Validation loss: 2.7604175901188914

Epoch: 5| Step: 6
Training loss: 2.2317149727654577
Validation loss: 2.8349740949598417

Epoch: 5| Step: 7
Training loss: 2.6474378831760865
Validation loss: 2.790933593264618

Epoch: 5| Step: 8
Training loss: 2.1238772848423553
Validation loss: 2.81980091398038

Epoch: 5| Step: 9
Training loss: 1.6264526036906215
Validation loss: 2.8810507514003736

Epoch: 5| Step: 10
Training loss: 2.5771084717676027
Validation loss: 2.7598575303602235

Epoch: 492| Step: 0
Training loss: 2.12821929767536
Validation loss: 2.7889083112378024

Epoch: 5| Step: 1
Training loss: 1.7455537716339555
Validation loss: 2.7768098572929385

Epoch: 5| Step: 2
Training loss: 2.298800226008223
Validation loss: 2.811160995059387

Epoch: 5| Step: 3
Training loss: 1.6147764357077095
Validation loss: 2.7431737912114746

Epoch: 5| Step: 4
Training loss: 1.9658661565537463
Validation loss: 2.8246005595079677

Epoch: 5| Step: 5
Training loss: 2.04382119710957
Validation loss: 2.801386058922396

Epoch: 5| Step: 6
Training loss: 2.479067525297145
Validation loss: 2.824852406454656

Epoch: 5| Step: 7
Training loss: 2.2757864546397104
Validation loss: 2.762981048514358

Epoch: 5| Step: 8
Training loss: 2.2519917679156842
Validation loss: 2.6861376713756133

Epoch: 5| Step: 9
Training loss: 2.244578505542077
Validation loss: 2.778689472410803

Epoch: 5| Step: 10
Training loss: 3.066517588543984
Validation loss: 2.8120342165185144

Epoch: 493| Step: 0
Training loss: 2.7130457351097346
Validation loss: 2.736914235450477

Epoch: 5| Step: 1
Training loss: 1.949976588377652
Validation loss: 2.7427637133878715

Epoch: 5| Step: 2
Training loss: 2.2077970273392937
Validation loss: 2.7420254490502063

Epoch: 5| Step: 3
Training loss: 2.3090488353205663
Validation loss: 2.7572929996680475

Epoch: 5| Step: 4
Training loss: 2.2594602703291335
Validation loss: 2.7451671997169527

Epoch: 5| Step: 5
Training loss: 2.3257798025416956
Validation loss: 2.7574335080882335

Epoch: 5| Step: 6
Training loss: 1.8709003770648744
Validation loss: 2.7271951729489072

Epoch: 5| Step: 7
Training loss: 1.9541257201936282
Validation loss: 2.773755518098557

Epoch: 5| Step: 8
Training loss: 2.0218315674068625
Validation loss: 2.75086746629405

Epoch: 5| Step: 9
Training loss: 2.006438144881581
Validation loss: 2.796211223489015

Epoch: 5| Step: 10
Training loss: 2.6152543401205337
Validation loss: 2.7715825793338937

Epoch: 494| Step: 0
Training loss: 2.0875098770730265
Validation loss: 2.8316865046269912

Epoch: 5| Step: 1
Training loss: 2.398485413113139
Validation loss: 2.7855903510286084

Epoch: 5| Step: 2
Training loss: 2.0700658111430608
Validation loss: 2.7071179075682217

Epoch: 5| Step: 3
Training loss: 1.8236709850573685
Validation loss: 2.802408580031906

Epoch: 5| Step: 4
Training loss: 2.2347007460662365
Validation loss: 2.8644349722976896

Epoch: 5| Step: 5
Training loss: 2.9765551309168954
Validation loss: 2.8168654358289045

Epoch: 5| Step: 6
Training loss: 1.8305169783395898
Validation loss: 2.7162892831474443

Epoch: 5| Step: 7
Training loss: 1.9322501398304401
Validation loss: 2.813288716847101

Epoch: 5| Step: 8
Training loss: 1.6866684736963375
Validation loss: 2.8341598397058347

Epoch: 5| Step: 9
Training loss: 2.4563194905708623
Validation loss: 2.7370563857311594

Epoch: 5| Step: 10
Training loss: 1.8646278233965474
Validation loss: 2.8053292755820065

Epoch: 495| Step: 0
Training loss: 1.9263196583306643
Validation loss: 2.790335624566414

Epoch: 5| Step: 1
Training loss: 2.4718277493866636
Validation loss: 2.801946346107512

Epoch: 5| Step: 2
Training loss: 2.38149477684318
Validation loss: 2.8393735026714957

Epoch: 5| Step: 3
Training loss: 2.089737534720515
Validation loss: 2.7633004156639585

Epoch: 5| Step: 4
Training loss: 2.7902126985915157
Validation loss: 2.7235328839147668

Epoch: 5| Step: 5
Training loss: 2.294271641592922
Validation loss: 2.7671923688596953

Epoch: 5| Step: 6
Training loss: 1.7211535207488273
Validation loss: 2.7557089865377877

Epoch: 5| Step: 7
Training loss: 2.769541752503447
Validation loss: 2.776118561045412

Epoch: 5| Step: 8
Training loss: 1.765512851090332
Validation loss: 2.8001341555431822

Epoch: 5| Step: 9
Training loss: 2.3255954800223617
Validation loss: 2.771400976560532

Epoch: 5| Step: 10
Training loss: 1.7826101898761526
Validation loss: 2.7976254114000763

Epoch: 496| Step: 0
Training loss: 2.5209396802259847
Validation loss: 2.878342549512787

Epoch: 5| Step: 1
Training loss: 1.9737844130528048
Validation loss: 2.7761832663662944

Epoch: 5| Step: 2
Training loss: 1.6484079945893177
Validation loss: 2.776599249856057

Epoch: 5| Step: 3
Training loss: 2.1609417278830434
Validation loss: 2.7837746998672537

Epoch: 5| Step: 4
Training loss: 2.6299329456150393
Validation loss: 2.767766563778666

Epoch: 5| Step: 5
Training loss: 2.3103055078190913
Validation loss: 2.7354885917132075

Epoch: 5| Step: 6
Training loss: 1.9725246272223775
Validation loss: 2.7700616775320923

Epoch: 5| Step: 7
Training loss: 2.307436063796152
Validation loss: 2.80081092485915

Epoch: 5| Step: 8
Training loss: 2.104122375425004
Validation loss: 2.7577006808211233

Epoch: 5| Step: 9
Training loss: 2.262729873360354
Validation loss: 2.8161503791622566

Epoch: 5| Step: 10
Training loss: 2.5817469268629827
Validation loss: 2.8033610894047207

Epoch: 497| Step: 0
Training loss: 2.5566321388144586
Validation loss: 2.7722457014308852

Epoch: 5| Step: 1
Training loss: 2.241404539568339
Validation loss: 2.7900166010053074

Epoch: 5| Step: 2
Training loss: 2.496330047072794
Validation loss: 2.8026323373440007

Epoch: 5| Step: 3
Training loss: 1.6247151198463528
Validation loss: 2.80996853330672

Epoch: 5| Step: 4
Training loss: 2.087426729115604
Validation loss: 2.8457911649625345

Epoch: 5| Step: 5
Training loss: 1.8304855886442741
Validation loss: 2.7305493647526413

Epoch: 5| Step: 6
Training loss: 2.0662357137362712
Validation loss: 2.841993328205722

Epoch: 5| Step: 7
Training loss: 2.248197363250112
Validation loss: 2.8563737975406838

Epoch: 5| Step: 8
Training loss: 2.0816621435323444
Validation loss: 2.772762195917762

Epoch: 5| Step: 9
Training loss: 1.7250804495364982
Validation loss: 2.8443125894342445

Epoch: 5| Step: 10
Training loss: 2.8863622628538432
Validation loss: 2.8316778821504047

Epoch: 498| Step: 0
Training loss: 1.9639664923146143
Validation loss: 2.7853340212197497

Epoch: 5| Step: 1
Training loss: 2.1003281609397315
Validation loss: 2.773780621510792

Epoch: 5| Step: 2
Training loss: 1.9224176028567672
Validation loss: 2.7403668950668343

Epoch: 5| Step: 3
Training loss: 2.1192039656072414
Validation loss: 2.831768047476824

Epoch: 5| Step: 4
Training loss: 2.9119864015052115
Validation loss: 2.7776202262442964

Epoch: 5| Step: 5
Training loss: 1.6842450433255836
Validation loss: 2.710456539038374

Epoch: 5| Step: 6
Training loss: 1.5206876536928924
Validation loss: 2.7309301298338684

Epoch: 5| Step: 7
Training loss: 1.938457006552805
Validation loss: 2.8270155791138465

Epoch: 5| Step: 8
Training loss: 2.295287537357878
Validation loss: 2.785755657157933

Epoch: 5| Step: 9
Training loss: 2.98667379789977
Validation loss: 2.835805786549048

Epoch: 5| Step: 10
Training loss: 2.33338078950125
Validation loss: 2.720814926968884

Epoch: 499| Step: 0
Training loss: 2.084148883136144
Validation loss: 2.7514906094088056

Epoch: 5| Step: 1
Training loss: 2.8749832484545093
Validation loss: 2.798735997123584

Epoch: 5| Step: 2
Training loss: 1.8803450375328887
Validation loss: 2.79936109510871

Epoch: 5| Step: 3
Training loss: 2.3636821312241336
Validation loss: 2.775716141523218

Epoch: 5| Step: 4
Training loss: 2.074461612025358
Validation loss: 2.7687552004796117

Epoch: 5| Step: 5
Training loss: 2.2680926334765874
Validation loss: 2.7260461787268766

Epoch: 5| Step: 6
Training loss: 1.5410829246532969
Validation loss: 2.7583685435834906

Epoch: 5| Step: 7
Training loss: 2.1001066816571057
Validation loss: 2.761727368112371

Epoch: 5| Step: 8
Training loss: 2.1714369517358247
Validation loss: 2.7867537846229276

Epoch: 5| Step: 9
Training loss: 1.8985572431814104
Validation loss: 2.7504391734391973

Epoch: 5| Step: 10
Training loss: 2.2990808599189276
Validation loss: 2.7942922664145615

Epoch: 500| Step: 0
Training loss: 2.4919391376784374
Validation loss: 2.794010938176833

Epoch: 5| Step: 1
Training loss: 2.062622644650459
Validation loss: 2.775627413921033

Epoch: 5| Step: 2
Training loss: 1.8259476957570226
Validation loss: 2.7515775717921436

Epoch: 5| Step: 3
Training loss: 2.1987449447287455
Validation loss: 2.7721969979975456

Epoch: 5| Step: 4
Training loss: 2.1926690201546153
Validation loss: 2.8001493003992333

Epoch: 5| Step: 5
Training loss: 2.261700513169945
Validation loss: 2.764527808815519

Epoch: 5| Step: 6
Training loss: 2.1872999917283176
Validation loss: 2.7464956364286937

Epoch: 5| Step: 7
Training loss: 2.1840208451390644
Validation loss: 2.801608603090662

Epoch: 5| Step: 8
Training loss: 2.3302879782582644
Validation loss: 2.8385863781640452

Epoch: 5| Step: 9
Training loss: 2.167637705228983
Validation loss: 2.7991678877685953

Epoch: 5| Step: 10
Training loss: 2.139349230099288
Validation loss: 2.722870865033421

Epoch: 501| Step: 0
Training loss: 2.5286924840445755
Validation loss: 2.806743063141857

Epoch: 5| Step: 1
Training loss: 2.9847463007324975
Validation loss: 2.7959135007706624

Epoch: 5| Step: 2
Training loss: 1.689132607105193
Validation loss: 2.7685085082334924

Epoch: 5| Step: 3
Training loss: 2.0787423729770964
Validation loss: 2.79059763489621

Epoch: 5| Step: 4
Training loss: 1.609953174620941
Validation loss: 2.653011148828747

Epoch: 5| Step: 5
Training loss: 1.789098081276566
Validation loss: 2.8584532139263827

Epoch: 5| Step: 6
Training loss: 2.1909194378372887
Validation loss: 2.7840967287450282

Epoch: 5| Step: 7
Training loss: 2.263783620819549
Validation loss: 2.810805890891649

Epoch: 5| Step: 8
Training loss: 2.192286350362581
Validation loss: 2.7956918384053586

Epoch: 5| Step: 9
Training loss: 2.287900870796697
Validation loss: 2.7345299649018813

Epoch: 5| Step: 10
Training loss: 2.2410290214160775
Validation loss: 2.813461822885638

Epoch: 502| Step: 0
Training loss: 1.728625553751948
Validation loss: 2.7962137736408477

Epoch: 5| Step: 1
Training loss: 2.0018352194700353
Validation loss: 2.7447887799766053

Epoch: 5| Step: 2
Training loss: 2.4971512776519975
Validation loss: 2.7952894642392128

Epoch: 5| Step: 3
Training loss: 1.7589588411643629
Validation loss: 2.75327358351696

Epoch: 5| Step: 4
Training loss: 2.1723265693016436
Validation loss: 2.682851875090713

Epoch: 5| Step: 5
Training loss: 2.37936782743647
Validation loss: 2.8510256871225352

Epoch: 5| Step: 6
Training loss: 2.3506130190003613
Validation loss: 2.7913817531368506

Epoch: 5| Step: 7
Training loss: 2.1404867754115346
Validation loss: 2.817794217719836

Epoch: 5| Step: 8
Training loss: 2.7725039348110005
Validation loss: 2.826375286451896

Epoch: 5| Step: 9
Training loss: 2.259544262804721
Validation loss: 2.824255852493933

Epoch: 5| Step: 10
Training loss: 1.977682708420989
Validation loss: 2.764523337207347

Epoch: 503| Step: 0
Training loss: 1.9670724533653916
Validation loss: 2.8052302768324346

Epoch: 5| Step: 1
Training loss: 3.0233450784283353
Validation loss: 2.8111779791805556

Epoch: 5| Step: 2
Training loss: 2.2863658866064602
Validation loss: 2.70326809632098

Epoch: 5| Step: 3
Training loss: 2.132589587066108
Validation loss: 2.803134656182469

Epoch: 5| Step: 4
Training loss: 2.0685629307738687
Validation loss: 2.744111330397616

Epoch: 5| Step: 5
Training loss: 1.9016850954656725
Validation loss: 2.8186981250240595

Epoch: 5| Step: 6
Training loss: 2.457330294363813
Validation loss: 2.7951324675466345

Epoch: 5| Step: 7
Training loss: 2.2779026294492284
Validation loss: 2.77646929108446

Epoch: 5| Step: 8
Training loss: 1.5401738216097867
Validation loss: 2.8197553989603352

Epoch: 5| Step: 9
Training loss: 1.9144664104680194
Validation loss: 2.848836686353656

Epoch: 5| Step: 10
Training loss: 2.0007468259710675
Validation loss: 2.7200872046249516

Epoch: 504| Step: 0
Training loss: 2.898451977305488
Validation loss: 2.789563760936379

Epoch: 5| Step: 1
Training loss: 1.7645409556062566
Validation loss: 2.7569954515959454

Epoch: 5| Step: 2
Training loss: 2.520001224184496
Validation loss: 2.778943799298591

Epoch: 5| Step: 3
Training loss: 2.591206141909004
Validation loss: 2.802671324523914

Epoch: 5| Step: 4
Training loss: 2.105075551758958
Validation loss: 2.7418727581358215

Epoch: 5| Step: 5
Training loss: 2.078165269045638
Validation loss: 2.743852155255642

Epoch: 5| Step: 6
Training loss: 1.6783752283261082
Validation loss: 2.73290732095451

Epoch: 5| Step: 7
Training loss: 2.691354692959103
Validation loss: 2.798513619346297

Epoch: 5| Step: 8
Training loss: 1.4899455699323663
Validation loss: 2.8451126585904953

Epoch: 5| Step: 9
Training loss: 1.5050866188900685
Validation loss: 2.807391951833556

Epoch: 5| Step: 10
Training loss: 2.5998288355019588
Validation loss: 2.7725063241473924

Epoch: 505| Step: 0
Training loss: 1.7665293580203536
Validation loss: 2.779763221969405

Epoch: 5| Step: 1
Training loss: 2.0616583985533197
Validation loss: 2.7971343039823484

Epoch: 5| Step: 2
Training loss: 1.7565689774675284
Validation loss: 2.760059904949729

Epoch: 5| Step: 3
Training loss: 2.071760024250757
Validation loss: 2.7660350390150703

Epoch: 5| Step: 4
Training loss: 1.9079070471627813
Validation loss: 2.7703581414939187

Epoch: 5| Step: 5
Training loss: 2.530732561135212
Validation loss: 2.8154266152413454

Epoch: 5| Step: 6
Training loss: 1.9123066848091461
Validation loss: 2.7955541736134126

Epoch: 5| Step: 7
Training loss: 2.5671374529129594
Validation loss: 2.8038217446487637

Epoch: 5| Step: 8
Training loss: 1.7696192300579436
Validation loss: 2.768884292679422

Epoch: 5| Step: 9
Training loss: 2.375027706586949
Validation loss: 2.8109766217354575

Epoch: 5| Step: 10
Training loss: 2.4237566129723094
Validation loss: 2.8393467427052106

Epoch: 506| Step: 0
Training loss: 1.741569512074371
Validation loss: 2.805163015456163

Epoch: 5| Step: 1
Training loss: 2.4109911098688137
Validation loss: 2.8564008072536944

Epoch: 5| Step: 2
Training loss: 2.202834306301331
Validation loss: 2.7851994903788007

Epoch: 5| Step: 3
Training loss: 2.2395447365443815
Validation loss: 2.7884025157083756

Epoch: 5| Step: 4
Training loss: 1.853998376588409
Validation loss: 2.711363623196412

Epoch: 5| Step: 5
Training loss: 1.8804753784012151
Validation loss: 2.881690877971205

Epoch: 5| Step: 6
Training loss: 2.445860195066561
Validation loss: 2.810960637791239

Epoch: 5| Step: 7
Training loss: 2.505314899380146
Validation loss: 2.812511211632699

Epoch: 5| Step: 8
Training loss: 2.0031675051555067
Validation loss: 2.786986903714358

Epoch: 5| Step: 9
Training loss: 2.1160548935532173
Validation loss: 2.7959954184919

Epoch: 5| Step: 10
Training loss: 1.9573586926666795
Validation loss: 2.77754339405153

Epoch: 507| Step: 0
Training loss: 2.226183621478814
Validation loss: 2.822259259187485

Epoch: 5| Step: 1
Training loss: 1.845187515819565
Validation loss: 2.78942711347446

Epoch: 5| Step: 2
Training loss: 2.172054036397352
Validation loss: 2.790115969582315

Epoch: 5| Step: 3
Training loss: 3.1380711130675394
Validation loss: 2.7379178713667285

Epoch: 5| Step: 4
Training loss: 1.7013613467247062
Validation loss: 2.797591463607487

Epoch: 5| Step: 5
Training loss: 1.9984816509795025
Validation loss: 2.8414167595306843

Epoch: 5| Step: 6
Training loss: 1.5201341859665272
Validation loss: 2.7883815580426266

Epoch: 5| Step: 7
Training loss: 2.1288679486950235
Validation loss: 2.8294604945300326

Epoch: 5| Step: 8
Training loss: 2.1928208081415708
Validation loss: 2.8033654684280442

Epoch: 5| Step: 9
Training loss: 2.1662029601557196
Validation loss: 2.8391739372063696

Epoch: 5| Step: 10
Training loss: 2.327584223058252
Validation loss: 2.778713513621364

Epoch: 508| Step: 0
Training loss: 2.1085820721037547
Validation loss: 2.753180508130078

Epoch: 5| Step: 1
Training loss: 2.0172767672595393
Validation loss: 2.872872751127521

Epoch: 5| Step: 2
Training loss: 2.1569708020210854
Validation loss: 2.8360852332673447

Epoch: 5| Step: 3
Training loss: 1.3190383632017768
Validation loss: 2.8160365421838236

Epoch: 5| Step: 4
Training loss: 2.1489068645675293
Validation loss: 2.829421161598054

Epoch: 5| Step: 5
Training loss: 2.2251468909992074
Validation loss: 2.766316026226673

Epoch: 5| Step: 6
Training loss: 1.7154855417850325
Validation loss: 2.7709660177191924

Epoch: 5| Step: 7
Training loss: 2.6771291192044386
Validation loss: 2.7630976345128175

Epoch: 5| Step: 8
Training loss: 1.754785669829736
Validation loss: 2.7740157993466266

Epoch: 5| Step: 9
Training loss: 2.740373060070803
Validation loss: 2.810960220087952

Epoch: 5| Step: 10
Training loss: 2.3721920279021327
Validation loss: 2.800533237529852

Epoch: 509| Step: 0
Training loss: 2.256075497797872
Validation loss: 2.794624831819687

Epoch: 5| Step: 1
Training loss: 2.1150060021425756
Validation loss: 2.8044361727769656

Epoch: 5| Step: 2
Training loss: 1.8634729826544656
Validation loss: 2.8438149739690037

Epoch: 5| Step: 3
Training loss: 2.961132516201093
Validation loss: 2.7924839770812646

Epoch: 5| Step: 4
Training loss: 2.197661965122379
Validation loss: 2.762217013552818

Epoch: 5| Step: 5
Training loss: 1.7026006608913111
Validation loss: 2.8247340991664074

Epoch: 5| Step: 6
Training loss: 1.5329600536320227
Validation loss: 2.797949503834197

Epoch: 5| Step: 7
Training loss: 2.464337522147724
Validation loss: 2.7455429873596984

Epoch: 5| Step: 8
Training loss: 2.1221028942937066
Validation loss: 2.855922016078544

Epoch: 5| Step: 9
Training loss: 1.8727356271229154
Validation loss: 2.733982205400362

Epoch: 5| Step: 10
Training loss: 2.710844450571237
Validation loss: 2.7658907947584375

Epoch: 510| Step: 0
Training loss: 1.6947879946746467
Validation loss: 2.7838293781802075

Epoch: 5| Step: 1
Training loss: 2.2674605727632056
Validation loss: 2.7539391630799837

Epoch: 5| Step: 2
Training loss: 1.9650278782504933
Validation loss: 2.7463114099989117

Epoch: 5| Step: 3
Training loss: 2.1893531579124086
Validation loss: 2.7910924647593007

Epoch: 5| Step: 4
Training loss: 2.0161891413926494
Validation loss: 2.7759994752663606

Epoch: 5| Step: 5
Training loss: 1.9984132313391862
Validation loss: 2.813659305071239

Epoch: 5| Step: 6
Training loss: 2.4550869622143554
Validation loss: 2.7935206398013026

Epoch: 5| Step: 7
Training loss: 2.276050442490292
Validation loss: 2.804737107193006

Epoch: 5| Step: 8
Training loss: 2.0458712846870597
Validation loss: 2.738360560007968

Epoch: 5| Step: 9
Training loss: 2.9844948310161814
Validation loss: 2.7950300138698907

Epoch: 5| Step: 10
Training loss: 2.2788725705644652
Validation loss: 2.787369407193022

Epoch: 511| Step: 0
Training loss: 1.7080068353788658
Validation loss: 2.7931382719638256

Epoch: 5| Step: 1
Training loss: 2.1799683748803593
Validation loss: 2.739919162695818

Epoch: 5| Step: 2
Training loss: 2.423627453165664
Validation loss: 2.856234505076118

Epoch: 5| Step: 3
Training loss: 2.4811035305195337
Validation loss: 2.7884912339824357

Epoch: 5| Step: 4
Training loss: 1.5152028862596392
Validation loss: 2.703948835790906

Epoch: 5| Step: 5
Training loss: 1.97336352671043
Validation loss: 2.8290393053711327

Epoch: 5| Step: 6
Training loss: 2.2059222920859938
Validation loss: 2.725710504566104

Epoch: 5| Step: 7
Training loss: 1.8411857748128098
Validation loss: 2.792982712921664

Epoch: 5| Step: 8
Training loss: 2.7662392489107583
Validation loss: 2.7858217831208147

Epoch: 5| Step: 9
Training loss: 2.172511494631368
Validation loss: 2.8786166842145318

Epoch: 5| Step: 10
Training loss: 2.2657602204057894
Validation loss: 2.795966466393022

Epoch: 512| Step: 0
Training loss: 2.3235626576928916
Validation loss: 2.860692946616847

Epoch: 5| Step: 1
Training loss: 1.9240550260784346
Validation loss: 2.8009906812407257

Epoch: 5| Step: 2
Training loss: 1.6906597084529982
Validation loss: 2.7213244283120597

Epoch: 5| Step: 3
Training loss: 2.881005359119011
Validation loss: 2.81955193499693

Epoch: 5| Step: 4
Training loss: 1.5331989263975154
Validation loss: 2.871571735448484

Epoch: 5| Step: 5
Training loss: 2.3497869435578083
Validation loss: 2.7882529308838557

Epoch: 5| Step: 6
Training loss: 1.7470641032109124
Validation loss: 2.6713173411507305

Epoch: 5| Step: 7
Training loss: 2.1433589211573465
Validation loss: 2.7868692767628445

Epoch: 5| Step: 8
Training loss: 2.3025218033974943
Validation loss: 2.807570273757768

Epoch: 5| Step: 9
Training loss: 1.9853623704667693
Validation loss: 2.7733498096829536

Epoch: 5| Step: 10
Training loss: 2.513184115519302
Validation loss: 2.8432005926584987

Epoch: 513| Step: 0
Training loss: 1.8809015857559035
Validation loss: 2.7569206292523005

Epoch: 5| Step: 1
Training loss: 2.3622824836182628
Validation loss: 2.7628606439563055

Epoch: 5| Step: 2
Training loss: 2.088373140938529
Validation loss: 2.8167132705130964

Epoch: 5| Step: 3
Training loss: 2.6741509810388173
Validation loss: 2.834372354063852

Epoch: 5| Step: 4
Training loss: 1.9199205710948968
Validation loss: 2.799313436736032

Epoch: 5| Step: 5
Training loss: 2.220184185016903
Validation loss: 2.7656046437494077

Epoch: 5| Step: 6
Training loss: 2.800366656956034
Validation loss: 2.8258853633920658

Epoch: 5| Step: 7
Training loss: 2.120224692115473
Validation loss: 2.740807836553785

Epoch: 5| Step: 8
Training loss: 1.690914655258629
Validation loss: 2.823994169384859

Epoch: 5| Step: 9
Training loss: 1.8413956691614364
Validation loss: 2.832563527927701

Epoch: 5| Step: 10
Training loss: 2.0640675916471785
Validation loss: 2.7881326972809255

Epoch: 514| Step: 0
Training loss: 1.625385605470387
Validation loss: 2.802578378967961

Epoch: 5| Step: 1
Training loss: 1.684630178963403
Validation loss: 2.791304716529463

Epoch: 5| Step: 2
Training loss: 2.3459318051129965
Validation loss: 2.7388373930382524

Epoch: 5| Step: 3
Training loss: 1.8577579551242058
Validation loss: 2.793466602703544

Epoch: 5| Step: 4
Training loss: 2.2167088965884436
Validation loss: 2.7756104219281963

Epoch: 5| Step: 5
Training loss: 1.9980813598640037
Validation loss: 2.804151312110063

Epoch: 5| Step: 6
Training loss: 2.399678061668294
Validation loss: 2.7813330823769817

Epoch: 5| Step: 7
Training loss: 2.05853340885681
Validation loss: 2.735970964540596

Epoch: 5| Step: 8
Training loss: 2.702256432495875
Validation loss: 2.7824469480977805

Epoch: 5| Step: 9
Training loss: 1.942569253833366
Validation loss: 2.7693496474009085

Epoch: 5| Step: 10
Training loss: 2.2461475664408765
Validation loss: 2.7674503854894685

Epoch: 515| Step: 0
Training loss: 2.5842670681059405
Validation loss: 2.8179848725393004

Epoch: 5| Step: 1
Training loss: 2.727444044425552
Validation loss: 2.752854742077162

Epoch: 5| Step: 2
Training loss: 2.2516436401402062
Validation loss: 2.7876002501483814

Epoch: 5| Step: 3
Training loss: 2.0250588773480325
Validation loss: 2.8510108179222025

Epoch: 5| Step: 4
Training loss: 2.2937926285859676
Validation loss: 2.8256257818511084

Epoch: 5| Step: 5
Training loss: 2.353578229522637
Validation loss: 2.7918732195866274

Epoch: 5| Step: 6
Training loss: 2.1248462845799603
Validation loss: 2.6983559632842273

Epoch: 5| Step: 7
Training loss: 1.069792349622311
Validation loss: 2.7572251155982066

Epoch: 5| Step: 8
Training loss: 1.5952998087020431
Validation loss: 2.792176440851876

Epoch: 5| Step: 9
Training loss: 2.2045152755073096
Validation loss: 2.6737045455720345

Epoch: 5| Step: 10
Training loss: 2.416742016724754
Validation loss: 2.802403991396242

Epoch: 516| Step: 0
Training loss: 2.024346224894504
Validation loss: 2.771338484709287

Epoch: 5| Step: 1
Training loss: 1.8560400795966374
Validation loss: 2.793902222158992

Epoch: 5| Step: 2
Training loss: 2.277972021840391
Validation loss: 2.8378780167579776

Epoch: 5| Step: 3
Training loss: 2.3759971332404315
Validation loss: 2.7957934829084534

Epoch: 5| Step: 4
Training loss: 2.4547634605926776
Validation loss: 2.866195898423089

Epoch: 5| Step: 5
Training loss: 2.1171594596779566
Validation loss: 2.7753446703237885

Epoch: 5| Step: 6
Training loss: 2.010492458463127
Validation loss: 2.8114984166834844

Epoch: 5| Step: 7
Training loss: 1.8344719414383421
Validation loss: 2.7384557956403626

Epoch: 5| Step: 8
Training loss: 2.394617872553823
Validation loss: 2.7912148532611223

Epoch: 5| Step: 9
Training loss: 1.8801742367457492
Validation loss: 2.7898348634502925

Epoch: 5| Step: 10
Training loss: 1.922598725798786
Validation loss: 2.7499158926563063

Epoch: 517| Step: 0
Training loss: 2.2702953739662357
Validation loss: 2.785620243853539

Epoch: 5| Step: 1
Training loss: 1.8828474492671767
Validation loss: 2.813209581818182

Epoch: 5| Step: 2
Training loss: 1.8918239480506875
Validation loss: 2.7985269747315926

Epoch: 5| Step: 3
Training loss: 1.6998003786355245
Validation loss: 2.825503929378338

Epoch: 5| Step: 4
Training loss: 1.9591834745844916
Validation loss: 2.8504461103736776

Epoch: 5| Step: 5
Training loss: 1.9070369159343958
Validation loss: 2.793358700664704

Epoch: 5| Step: 6
Training loss: 2.9793836785796843
Validation loss: 2.8585738932506

Epoch: 5| Step: 7
Training loss: 2.0081257260389824
Validation loss: 2.8644935076250944

Epoch: 5| Step: 8
Training loss: 2.2859500908130057
Validation loss: 2.8165235263019874

Epoch: 5| Step: 9
Training loss: 2.418965813523339
Validation loss: 2.8431309843610935

Epoch: 5| Step: 10
Training loss: 2.2419742921483405
Validation loss: 2.7878684658014445

Epoch: 518| Step: 0
Training loss: 2.053741933722046
Validation loss: 2.762456978907582

Epoch: 5| Step: 1
Training loss: 2.323848611546106
Validation loss: 2.813288337762448

Epoch: 5| Step: 2
Training loss: 2.031710059078351
Validation loss: 2.695288518603076

Epoch: 5| Step: 3
Training loss: 2.2950065434846696
Validation loss: 2.751774740076835

Epoch: 5| Step: 4
Training loss: 1.8275574675368373
Validation loss: 2.7633561522201235

Epoch: 5| Step: 5
Training loss: 2.429634020054261
Validation loss: 2.7725341416413687

Epoch: 5| Step: 6
Training loss: 2.146302205929931
Validation loss: 2.822486302165902

Epoch: 5| Step: 7
Training loss: 1.7008595930007095
Validation loss: 2.7547396780331495

Epoch: 5| Step: 8
Training loss: 2.5364424582943492
Validation loss: 2.8438556664582855

Epoch: 5| Step: 9
Training loss: 2.393670529473138
Validation loss: 2.7784823429257943

Epoch: 5| Step: 10
Training loss: 1.87872605441145
Validation loss: 2.7308196849950637

Epoch: 519| Step: 0
Training loss: 2.4423469867237024
Validation loss: 2.7516356588523254

Epoch: 5| Step: 1
Training loss: 1.9643327112892228
Validation loss: 2.739631324577607

Epoch: 5| Step: 2
Training loss: 1.964419309606085
Validation loss: 2.7945383540170567

Epoch: 5| Step: 3
Training loss: 2.823815281329944
Validation loss: 2.848506479450332

Epoch: 5| Step: 4
Training loss: 2.298236158150235
Validation loss: 2.759468958566875

Epoch: 5| Step: 5
Training loss: 2.4375871496026473
Validation loss: 2.7534514863410706

Epoch: 5| Step: 6
Training loss: 1.7476216230513306
Validation loss: 2.767159489271087

Epoch: 5| Step: 7
Training loss: 2.3867069624939075
Validation loss: 2.8388659539326517

Epoch: 5| Step: 8
Training loss: 1.9455156335136379
Validation loss: 2.8616507193562932

Epoch: 5| Step: 9
Training loss: 2.057542912718226
Validation loss: 2.7573404397023578

Epoch: 5| Step: 10
Training loss: 1.8255319055356611
Validation loss: 2.802936584305986

Epoch: 520| Step: 0
Training loss: 2.8081668110122053
Validation loss: 2.7946094386950544

Epoch: 5| Step: 1
Training loss: 2.4546020337529266
Validation loss: 2.8057915652832097

Epoch: 5| Step: 2
Training loss: 2.37262948843516
Validation loss: 2.8231038501968713

Epoch: 5| Step: 3
Training loss: 2.3480527926916053
Validation loss: 2.8251609273991405

Epoch: 5| Step: 4
Training loss: 1.8439629641886957
Validation loss: 2.8946003626568664

Epoch: 5| Step: 5
Training loss: 2.685814617335196
Validation loss: 2.782927319473121

Epoch: 5| Step: 6
Training loss: 1.5419991452601893
Validation loss: 2.764616545836641

Epoch: 5| Step: 7
Training loss: 1.7108460841731112
Validation loss: 2.8362644103974217

Epoch: 5| Step: 8
Training loss: 1.660495786165877
Validation loss: 2.7760674072308484

Epoch: 5| Step: 9
Training loss: 1.880838396028672
Validation loss: 2.7922640696802508

Epoch: 5| Step: 10
Training loss: 1.8267100800740896
Validation loss: 2.7853263431748565

Epoch: 521| Step: 0
Training loss: 1.8274421394675693
Validation loss: 2.7725711563030444

Epoch: 5| Step: 1
Training loss: 2.429439912306148
Validation loss: 2.7581485224148663

Epoch: 5| Step: 2
Training loss: 1.8292567996307576
Validation loss: 2.8368832326485367

Epoch: 5| Step: 3
Training loss: 2.583707003076506
Validation loss: 2.721894944648424

Epoch: 5| Step: 4
Training loss: 1.8626828302343383
Validation loss: 2.7831946931317995

Epoch: 5| Step: 5
Training loss: 2.2798268307626746
Validation loss: 2.7561977841472456

Epoch: 5| Step: 6
Training loss: 2.095752612380236
Validation loss: 2.7471857194794436

Epoch: 5| Step: 7
Training loss: 2.857850715961504
Validation loss: 2.791806281952505

Epoch: 5| Step: 8
Training loss: 1.8673037568614255
Validation loss: 2.8643378302266433

Epoch: 5| Step: 9
Training loss: 1.888600171531856
Validation loss: 2.6775515844972366

Epoch: 5| Step: 10
Training loss: 2.029647077315012
Validation loss: 2.732075591708107

Epoch: 522| Step: 0
Training loss: 2.1814747254653764
Validation loss: 2.757638158792173

Epoch: 5| Step: 1
Training loss: 1.8164460208599644
Validation loss: 2.82861857916308

Epoch: 5| Step: 2
Training loss: 2.354915826026157
Validation loss: 2.7804759746978673

Epoch: 5| Step: 3
Training loss: 2.0949943602492866
Validation loss: 2.8013061209203345

Epoch: 5| Step: 4
Training loss: 2.3759734517871642
Validation loss: 2.8034203197224463

Epoch: 5| Step: 5
Training loss: 2.7800704512142493
Validation loss: 2.789730800944245

Epoch: 5| Step: 6
Training loss: 1.0916319911972725
Validation loss: 2.8288202649798397

Epoch: 5| Step: 7
Training loss: 2.0342013705412416
Validation loss: 2.764390322567025

Epoch: 5| Step: 8
Training loss: 2.2305288223220683
Validation loss: 2.7934579576987564

Epoch: 5| Step: 9
Training loss: 2.1593210216350642
Validation loss: 2.8143320768290163

Epoch: 5| Step: 10
Training loss: 2.025104204487261
Validation loss: 2.77581192048191

Epoch: 523| Step: 0
Training loss: 1.501389575095093
Validation loss: 2.7487460309056084

Epoch: 5| Step: 1
Training loss: 2.3130695569522053
Validation loss: 2.7861153637734417

Epoch: 5| Step: 2
Training loss: 2.1516725909532957
Validation loss: 2.7558005806561003

Epoch: 5| Step: 3
Training loss: 2.282670192995794
Validation loss: 2.7703718417463126

Epoch: 5| Step: 4
Training loss: 1.772556909742465
Validation loss: 2.7990548305854754

Epoch: 5| Step: 5
Training loss: 2.3982029902721016
Validation loss: 2.7856139783602027

Epoch: 5| Step: 6
Training loss: 2.095651929928626
Validation loss: 2.838754117898439

Epoch: 5| Step: 7
Training loss: 2.578850199111377
Validation loss: 2.8016523069418153

Epoch: 5| Step: 8
Training loss: 2.07791870928931
Validation loss: 2.8754379256378066

Epoch: 5| Step: 9
Training loss: 2.135427360197755
Validation loss: 2.731088896174329

Epoch: 5| Step: 10
Training loss: 2.5537980424018913
Validation loss: 2.8255779105025547

Epoch: 524| Step: 0
Training loss: 1.4662059096319648
Validation loss: 2.714089132176133

Epoch: 5| Step: 1
Training loss: 2.001029703189554
Validation loss: 2.7470588636453015

Epoch: 5| Step: 2
Training loss: 2.126719396270324
Validation loss: 2.8126123093726454

Epoch: 5| Step: 3
Training loss: 1.928830840814089
Validation loss: 2.846848734294846

Epoch: 5| Step: 4
Training loss: 2.349235320976329
Validation loss: 2.8165660075141257

Epoch: 5| Step: 5
Training loss: 2.715198082064624
Validation loss: 2.7716201330064556

Epoch: 5| Step: 6
Training loss: 1.513799531537363
Validation loss: 2.7459406961991975

Epoch: 5| Step: 7
Training loss: 2.6122796800789008
Validation loss: 2.7436223996653797

Epoch: 5| Step: 8
Training loss: 2.0595957798330606
Validation loss: 2.71105341627884

Epoch: 5| Step: 9
Training loss: 2.3855158245239028
Validation loss: 2.811838285020585

Epoch: 5| Step: 10
Training loss: 2.0846624585092832
Validation loss: 2.789329227662932

Epoch: 525| Step: 0
Training loss: 2.1180045602909665
Validation loss: 2.7517367087439317

Epoch: 5| Step: 1
Training loss: 1.9147630927453458
Validation loss: 2.814080043129783

Epoch: 5| Step: 2
Training loss: 1.1335457894861933
Validation loss: 2.8094540800292584

Epoch: 5| Step: 3
Training loss: 2.3016700776461834
Validation loss: 2.717599965238437

Epoch: 5| Step: 4
Training loss: 2.2551966102301275
Validation loss: 2.8042589862817815

Epoch: 5| Step: 5
Training loss: 1.9518386266753482
Validation loss: 2.7819255645781467

Epoch: 5| Step: 6
Training loss: 1.8919563334952483
Validation loss: 2.8148720076096243

Epoch: 5| Step: 7
Training loss: 2.275931442233824
Validation loss: 2.7489475122095874

Epoch: 5| Step: 8
Training loss: 2.3693429934373236
Validation loss: 2.791582561457151

Epoch: 5| Step: 9
Training loss: 2.638437843815213
Validation loss: 2.7963471768486206

Epoch: 5| Step: 10
Training loss: 2.5337386907053183
Validation loss: 2.8550838900556457

Epoch: 526| Step: 0
Training loss: 2.0330532579402787
Validation loss: 2.799215766589847

Epoch: 5| Step: 1
Training loss: 2.1930889122538515
Validation loss: 2.843605301962085

Epoch: 5| Step: 2
Training loss: 2.322219527342884
Validation loss: 2.798437140010438

Epoch: 5| Step: 3
Training loss: 2.0350685027493713
Validation loss: 2.83316239004789

Epoch: 5| Step: 4
Training loss: 2.5352284754734753
Validation loss: 2.7781344628434437

Epoch: 5| Step: 5
Training loss: 1.5322693526430242
Validation loss: 2.822755511502773

Epoch: 5| Step: 6
Training loss: 1.5266515231457272
Validation loss: 2.7581502354438006

Epoch: 5| Step: 7
Training loss: 2.0455873821936077
Validation loss: 2.7928859146240725

Epoch: 5| Step: 8
Training loss: 2.168586161908231
Validation loss: 2.6664950596931347

Epoch: 5| Step: 9
Training loss: 2.145995371604685
Validation loss: 2.8307717148381726

Epoch: 5| Step: 10
Training loss: 2.660998598966405
Validation loss: 2.859410374996011

Epoch: 527| Step: 0
Training loss: 1.9547101111747076
Validation loss: 2.8038085397489465

Epoch: 5| Step: 1
Training loss: 2.0857663888078215
Validation loss: 2.7701612260785664

Epoch: 5| Step: 2
Training loss: 2.368589986665666
Validation loss: 2.841301326369768

Epoch: 5| Step: 3
Training loss: 1.6231413261758787
Validation loss: 2.794108060836031

Epoch: 5| Step: 4
Training loss: 1.8116682709327387
Validation loss: 2.8372362286822788

Epoch: 5| Step: 5
Training loss: 2.479316407711678
Validation loss: 2.7849987373062723

Epoch: 5| Step: 6
Training loss: 2.5182108413255686
Validation loss: 2.817229167281633

Epoch: 5| Step: 7
Training loss: 1.9634371324095927
Validation loss: 2.6897680676213085

Epoch: 5| Step: 8
Training loss: 2.346841527951582
Validation loss: 2.7140347793235255

Epoch: 5| Step: 9
Training loss: 1.934791394406168
Validation loss: 2.8166833549833266

Epoch: 5| Step: 10
Training loss: 2.1989241787275713
Validation loss: 2.753839447042085

Epoch: 528| Step: 0
Training loss: 2.180612894048131
Validation loss: 2.7940627700126544

Epoch: 5| Step: 1
Training loss: 2.1930183559959335
Validation loss: 2.775245878587569

Epoch: 5| Step: 2
Training loss: 2.9064137402420482
Validation loss: 2.7769302898771855

Epoch: 5| Step: 3
Training loss: 2.0456942581587723
Validation loss: 2.859745770184071

Epoch: 5| Step: 4
Training loss: 1.9257767930665972
Validation loss: 2.7358462152685092

Epoch: 5| Step: 5
Training loss: 1.8239880565034778
Validation loss: 2.785174795480009

Epoch: 5| Step: 6
Training loss: 1.4976882604800754
Validation loss: 2.7434230494063114

Epoch: 5| Step: 7
Training loss: 1.570554268667813
Validation loss: 2.7573087173380326

Epoch: 5| Step: 8
Training loss: 2.5070502052529653
Validation loss: 2.8297191988348986

Epoch: 5| Step: 9
Training loss: 2.2722360903817522
Validation loss: 2.788365749817992

Epoch: 5| Step: 10
Training loss: 2.09209376631567
Validation loss: 2.7861031910987224

Epoch: 529| Step: 0
Training loss: 2.1180923611582023
Validation loss: 2.7555658633536284

Epoch: 5| Step: 1
Training loss: 2.5810877566577157
Validation loss: 2.7953957840486936

Epoch: 5| Step: 2
Training loss: 2.3353811768946935
Validation loss: 2.8655627741826364

Epoch: 5| Step: 3
Training loss: 1.947664057489898
Validation loss: 2.7742610131087884

Epoch: 5| Step: 4
Training loss: 1.9550886735050408
Validation loss: 2.7746684509627744

Epoch: 5| Step: 5
Training loss: 2.1649685832292414
Validation loss: 2.802335471084629

Epoch: 5| Step: 6
Training loss: 1.3693774313754945
Validation loss: 2.787672343785434

Epoch: 5| Step: 7
Training loss: 2.162886427382147
Validation loss: 2.856781020797728

Epoch: 5| Step: 8
Training loss: 2.3403661077968487
Validation loss: 2.779129201402175

Epoch: 5| Step: 9
Training loss: 2.0207271613581668
Validation loss: 2.8418361006933512

Epoch: 5| Step: 10
Training loss: 2.0111726778955905
Validation loss: 2.8793004247620337

Epoch: 530| Step: 0
Training loss: 2.0351940891021085
Validation loss: 2.7876621240945307

Epoch: 5| Step: 1
Training loss: 1.8430272641662035
Validation loss: 2.792652922595728

Epoch: 5| Step: 2
Training loss: 2.344659857573649
Validation loss: 2.7567978848551618

Epoch: 5| Step: 3
Training loss: 2.22991391310864
Validation loss: 2.8026468530931234

Epoch: 5| Step: 4
Training loss: 2.145447248768264
Validation loss: 2.8031312649842595

Epoch: 5| Step: 5
Training loss: 2.149541065115737
Validation loss: 2.7161405858238

Epoch: 5| Step: 6
Training loss: 2.4005502348214094
Validation loss: 2.820688785642221

Epoch: 5| Step: 7
Training loss: 2.099956026070995
Validation loss: 2.8018521119988784

Epoch: 5| Step: 8
Training loss: 2.625513934733212
Validation loss: 2.8021417186207995

Epoch: 5| Step: 9
Training loss: 1.8621920875150966
Validation loss: 2.8058780233523968

Epoch: 5| Step: 10
Training loss: 1.9620575764536299
Validation loss: 2.771453596167926

Epoch: 531| Step: 0
Training loss: 2.9321391109444614
Validation loss: 2.75656616899201

Epoch: 5| Step: 1
Training loss: 1.8744801118436187
Validation loss: 2.811258986117248

Epoch: 5| Step: 2
Training loss: 1.8092109170940653
Validation loss: 2.8028969687998195

Epoch: 5| Step: 3
Training loss: 1.8494928438079654
Validation loss: 2.743947923428189

Epoch: 5| Step: 4
Training loss: 2.158608515023132
Validation loss: 2.7758682979650486

Epoch: 5| Step: 5
Training loss: 2.0094501629619925
Validation loss: 2.7438110298430916

Epoch: 5| Step: 6
Training loss: 2.1680969750228027
Validation loss: 2.7322909268305686

Epoch: 5| Step: 7
Training loss: 1.4986007044661336
Validation loss: 2.7371634745436446

Epoch: 5| Step: 8
Training loss: 1.892051284889363
Validation loss: 2.788225672013399

Epoch: 5| Step: 9
Training loss: 2.000529695938317
Validation loss: 2.744169172852955

Epoch: 5| Step: 10
Training loss: 2.4738594008624655
Validation loss: 2.809479415613778

Epoch: 532| Step: 0
Training loss: 2.1916101262253593
Validation loss: 2.69934768407995

Epoch: 5| Step: 1
Training loss: 1.5977011676620512
Validation loss: 2.831520817025781

Epoch: 5| Step: 2
Training loss: 2.311407398168665
Validation loss: 2.768175715087466

Epoch: 5| Step: 3
Training loss: 2.1378747578078614
Validation loss: 2.810906682416145

Epoch: 5| Step: 4
Training loss: 2.3475974483393576
Validation loss: 2.7050367114729768

Epoch: 5| Step: 5
Training loss: 1.6833330204777694
Validation loss: 2.7980186281522426

Epoch: 5| Step: 6
Training loss: 2.314022078795348
Validation loss: 2.7868334565523014

Epoch: 5| Step: 7
Training loss: 1.822303109228118
Validation loss: 2.8210612788620972

Epoch: 5| Step: 8
Training loss: 2.8458468912080006
Validation loss: 2.813456734712009

Epoch: 5| Step: 9
Training loss: 2.003865797441354
Validation loss: 2.822494682051882

Epoch: 5| Step: 10
Training loss: 2.1013399027529687
Validation loss: 2.833156596166173

Epoch: 533| Step: 0
Training loss: 1.7582070141054105
Validation loss: 2.776716956408884

Epoch: 5| Step: 1
Training loss: 1.836843583551237
Validation loss: 2.767620590518343

Epoch: 5| Step: 2
Training loss: 2.4176769665994335
Validation loss: 2.7508670711518914

Epoch: 5| Step: 3
Training loss: 1.7442724641564682
Validation loss: 2.7647299787822024

Epoch: 5| Step: 4
Training loss: 1.867596186518825
Validation loss: 2.7563619344297474

Epoch: 5| Step: 5
Training loss: 2.169200870138251
Validation loss: 2.810648800453485

Epoch: 5| Step: 6
Training loss: 1.8141067223493887
Validation loss: 2.7867144533171584

Epoch: 5| Step: 7
Training loss: 2.489749110194412
Validation loss: 2.8118884744623482

Epoch: 5| Step: 8
Training loss: 2.3885176601831084
Validation loss: 2.77330827771603

Epoch: 5| Step: 9
Training loss: 2.033292477098245
Validation loss: 2.744368744486833

Epoch: 5| Step: 10
Training loss: 2.493981173324191
Validation loss: 2.714826508823836

Epoch: 534| Step: 0
Training loss: 2.1931126116894384
Validation loss: 2.7528557552946253

Epoch: 5| Step: 1
Training loss: 1.5758883801546806
Validation loss: 2.75056619865613

Epoch: 5| Step: 2
Training loss: 1.9159265277768005
Validation loss: 2.775558382206191

Epoch: 5| Step: 3
Training loss: 2.2882611952059477
Validation loss: 2.804268823921109

Epoch: 5| Step: 4
Training loss: 2.556563968543785
Validation loss: 2.8105755154553123

Epoch: 5| Step: 5
Training loss: 1.8712982511956715
Validation loss: 2.7037656139836423

Epoch: 5| Step: 6
Training loss: 1.8211157995040423
Validation loss: 2.7692865135453455

Epoch: 5| Step: 7
Training loss: 2.219430523593847
Validation loss: 2.7597268119988936

Epoch: 5| Step: 8
Training loss: 2.1793184138818433
Validation loss: 2.79042396809331

Epoch: 5| Step: 9
Training loss: 2.359460690186458
Validation loss: 2.8315421099908225

Epoch: 5| Step: 10
Training loss: 2.4494184932755356
Validation loss: 2.821981548448688

Epoch: 535| Step: 0
Training loss: 1.6339234583563986
Validation loss: 2.8154004307929466

Epoch: 5| Step: 1
Training loss: 2.0156136445901067
Validation loss: 2.7359451970275073

Epoch: 5| Step: 2
Training loss: 2.018186139704321
Validation loss: 2.8195753823003824

Epoch: 5| Step: 3
Training loss: 1.9671439022841468
Validation loss: 2.7754239224978132

Epoch: 5| Step: 4
Training loss: 1.7492270806383807
Validation loss: 2.8435095110992394

Epoch: 5| Step: 5
Training loss: 1.5343117757229363
Validation loss: 2.806612159046358

Epoch: 5| Step: 6
Training loss: 2.4640422309811068
Validation loss: 2.739211966200919

Epoch: 5| Step: 7
Training loss: 1.7580372984513075
Validation loss: 2.762865579417814

Epoch: 5| Step: 8
Training loss: 2.925340036043169
Validation loss: 2.731531388872943

Epoch: 5| Step: 9
Training loss: 2.6519637587071845
Validation loss: 2.760462772652242

Epoch: 5| Step: 10
Training loss: 2.2678200447300796
Validation loss: 2.768509910198098

Epoch: 536| Step: 0
Training loss: 2.3271871636386474
Validation loss: 2.7385278155751918

Epoch: 5| Step: 1
Training loss: 1.6288225989508953
Validation loss: 2.8154189555231897

Epoch: 5| Step: 2
Training loss: 2.0415325769520183
Validation loss: 2.8416487485153326

Epoch: 5| Step: 3
Training loss: 3.003856246790015
Validation loss: 2.7428750638475834

Epoch: 5| Step: 4
Training loss: 2.0434080858646904
Validation loss: 2.7551917312047123

Epoch: 5| Step: 5
Training loss: 1.9452200258634975
Validation loss: 2.827480536659427

Epoch: 5| Step: 6
Training loss: 1.7070119057962516
Validation loss: 2.785458579860851

Epoch: 5| Step: 7
Training loss: 1.9299163064944662
Validation loss: 2.7689957815200144

Epoch: 5| Step: 8
Training loss: 1.9008882504225446
Validation loss: 2.7193314276299514

Epoch: 5| Step: 9
Training loss: 2.497454109877662
Validation loss: 2.7575462240879656

Epoch: 5| Step: 10
Training loss: 1.9465783837736421
Validation loss: 2.7675014049299214

Epoch: 537| Step: 0
Training loss: 1.679027267929865
Validation loss: 2.7739710963350617

Epoch: 5| Step: 1
Training loss: 2.449906102152242
Validation loss: 2.7942512741729293

Epoch: 5| Step: 2
Training loss: 2.114652009296651
Validation loss: 2.769152786177978

Epoch: 5| Step: 3
Training loss: 2.8813265974409434
Validation loss: 2.724074123118132

Epoch: 5| Step: 4
Training loss: 2.3042474876241945
Validation loss: 2.8052750300368947

Epoch: 5| Step: 5
Training loss: 2.5782069337714475
Validation loss: 2.773526532438129

Epoch: 5| Step: 6
Training loss: 1.8607166482728938
Validation loss: 2.7904831206874428

Epoch: 5| Step: 7
Training loss: 1.7705020220620287
Validation loss: 2.8314428896374784

Epoch: 5| Step: 8
Training loss: 1.626915975927356
Validation loss: 2.823873254215322

Epoch: 5| Step: 9
Training loss: 2.1090107921253676
Validation loss: 2.782765828845526

Epoch: 5| Step: 10
Training loss: 1.87997317406609
Validation loss: 2.828596638823138

Epoch: 538| Step: 0
Training loss: 1.256013994205776
Validation loss: 2.8716652198828663

Epoch: 5| Step: 1
Training loss: 2.1979288278638
Validation loss: 2.7967984483565584

Epoch: 5| Step: 2
Training loss: 1.769899443663377
Validation loss: 2.862909170037996

Epoch: 5| Step: 3
Training loss: 2.094223424423433
Validation loss: 2.8330618745186293

Epoch: 5| Step: 4
Training loss: 2.4250962031837098
Validation loss: 2.801250068698338

Epoch: 5| Step: 5
Training loss: 2.1767924234574543
Validation loss: 2.747559741881709

Epoch: 5| Step: 6
Training loss: 2.2594492962072303
Validation loss: 2.7974239820456948

Epoch: 5| Step: 7
Training loss: 1.8975608277151883
Validation loss: 2.7142315522300597

Epoch: 5| Step: 8
Training loss: 1.7172889047798154
Validation loss: 2.7632485356261265

Epoch: 5| Step: 9
Training loss: 2.401336806245898
Validation loss: 2.749680094043194

Epoch: 5| Step: 10
Training loss: 2.6528608354633314
Validation loss: 2.804886874058441

Epoch: 539| Step: 0
Training loss: 2.255130217317418
Validation loss: 2.7551676550249953

Epoch: 5| Step: 1
Training loss: 2.404195329395007
Validation loss: 2.7983451165262174

Epoch: 5| Step: 2
Training loss: 1.6001988257610875
Validation loss: 2.733401684490445

Epoch: 5| Step: 3
Training loss: 2.5410106521076914
Validation loss: 2.821232189647272

Epoch: 5| Step: 4
Training loss: 2.076626574444115
Validation loss: 2.8119376583162223

Epoch: 5| Step: 5
Training loss: 1.6419882786898135
Validation loss: 2.767302196268057

Epoch: 5| Step: 6
Training loss: 1.8589408431754635
Validation loss: 2.778998990095723

Epoch: 5| Step: 7
Training loss: 2.1788893027756138
Validation loss: 2.834805783383266

Epoch: 5| Step: 8
Training loss: 2.244525607480725
Validation loss: 2.793212524762692

Epoch: 5| Step: 9
Training loss: 2.5241300500594335
Validation loss: 2.786625560717955

Epoch: 5| Step: 10
Training loss: 1.6601898548988552
Validation loss: 2.773570897847163

Epoch: 540| Step: 0
Training loss: 1.934849248627381
Validation loss: 2.7223852166312152

Epoch: 5| Step: 1
Training loss: 1.893913813389352
Validation loss: 2.803249611991192

Epoch: 5| Step: 2
Training loss: 2.0748193593275372
Validation loss: 2.863136980311094

Epoch: 5| Step: 3
Training loss: 2.506634872451323
Validation loss: 2.7819461290072898

Epoch: 5| Step: 4
Training loss: 1.739192560889961
Validation loss: 2.805073841085182

Epoch: 5| Step: 5
Training loss: 2.3763229299527944
Validation loss: 2.7642536790026617

Epoch: 5| Step: 6
Training loss: 2.3778227043760105
Validation loss: 2.7142378710483173

Epoch: 5| Step: 7
Training loss: 2.6318515189705733
Validation loss: 2.747790767384699

Epoch: 5| Step: 8
Training loss: 1.4620034312196224
Validation loss: 2.7340152533127795

Epoch: 5| Step: 9
Training loss: 1.8636038638873798
Validation loss: 2.818088106409097

Epoch: 5| Step: 10
Training loss: 2.0197736052370705
Validation loss: 2.7722286073316043

Epoch: 541| Step: 0
Training loss: 1.9284484221069238
Validation loss: 2.8153087104571335

Epoch: 5| Step: 1
Training loss: 2.0653894010181553
Validation loss: 2.739669276916585

Epoch: 5| Step: 2
Training loss: 2.2484738154126216
Validation loss: 2.745687503207795

Epoch: 5| Step: 3
Training loss: 2.1948091737700426
Validation loss: 2.810338705514588

Epoch: 5| Step: 4
Training loss: 2.385658340760796
Validation loss: 2.7881954549677612

Epoch: 5| Step: 5
Training loss: 2.2165968212319327
Validation loss: 2.7946426548972285

Epoch: 5| Step: 6
Training loss: 1.9708210179251273
Validation loss: 2.7645024238580116

Epoch: 5| Step: 7
Training loss: 2.11312397426252
Validation loss: 2.7708959622506075

Epoch: 5| Step: 8
Training loss: 2.4522476085083778
Validation loss: 2.768465172916632

Epoch: 5| Step: 9
Training loss: 1.5242665700288676
Validation loss: 2.82593209373811

Epoch: 5| Step: 10
Training loss: 1.747635674728535
Validation loss: 2.7677862353821325

Epoch: 542| Step: 0
Training loss: 1.9076992841739735
Validation loss: 2.7853814364977265

Epoch: 5| Step: 1
Training loss: 1.7819738423132705
Validation loss: 2.663836489237023

Epoch: 5| Step: 2
Training loss: 2.448630327666343
Validation loss: 2.8469655904123847

Epoch: 5| Step: 3
Training loss: 2.2959183757375428
Validation loss: 2.7094481288664087

Epoch: 5| Step: 4
Training loss: 1.7534883336836735
Validation loss: 2.789501910789806

Epoch: 5| Step: 5
Training loss: 2.4068706752329136
Validation loss: 2.7944297025538196

Epoch: 5| Step: 6
Training loss: 1.5995573564019758
Validation loss: 2.7620969562307405

Epoch: 5| Step: 7
Training loss: 2.3880349883003555
Validation loss: 2.747709053698429

Epoch: 5| Step: 8
Training loss: 1.4187154353968596
Validation loss: 2.696474194668226

Epoch: 5| Step: 9
Training loss: 2.8684495024695438
Validation loss: 2.797085348342629

Epoch: 5| Step: 10
Training loss: 1.6259803015863539
Validation loss: 2.7391087981080413

Epoch: 543| Step: 0
Training loss: 1.6238286124589567
Validation loss: 2.8062288955650216

Epoch: 5| Step: 1
Training loss: 1.7287140295957617
Validation loss: 2.7454176169163644

Epoch: 5| Step: 2
Training loss: 1.9408965948115573
Validation loss: 2.768900077876631

Epoch: 5| Step: 3
Training loss: 2.2468679669393468
Validation loss: 2.767883266822636

Epoch: 5| Step: 4
Training loss: 1.997870443987513
Validation loss: 2.7862091474386275

Epoch: 5| Step: 5
Training loss: 2.368664774707769
Validation loss: 2.851051763786372

Epoch: 5| Step: 6
Training loss: 2.809750972451324
Validation loss: 2.8422428785991727

Epoch: 5| Step: 7
Training loss: 2.532937041038234
Validation loss: 2.810834231377249

Epoch: 5| Step: 8
Training loss: 1.8351721933840752
Validation loss: 2.7567053418298975

Epoch: 5| Step: 9
Training loss: 1.1795343969163896
Validation loss: 2.8356211785408725

Epoch: 5| Step: 10
Training loss: 2.2899444235175386
Validation loss: 2.7883702834060613

Epoch: 544| Step: 0
Training loss: 2.0808667904088116
Validation loss: 2.7947631368007637

Epoch: 5| Step: 1
Training loss: 1.650474049643542
Validation loss: 2.8067959550168187

Epoch: 5| Step: 2
Training loss: 1.6734704934223807
Validation loss: 2.7920840035140437

Epoch: 5| Step: 3
Training loss: 2.3799528378534087
Validation loss: 2.7929822172630048

Epoch: 5| Step: 4
Training loss: 1.6544310460182536
Validation loss: 2.7374793553431966

Epoch: 5| Step: 5
Training loss: 2.434060237255115
Validation loss: 2.793751738879623

Epoch: 5| Step: 6
Training loss: 2.4991308608823295
Validation loss: 2.7749387692761

Epoch: 5| Step: 7
Training loss: 2.169748816125808
Validation loss: 2.8484984910864815

Epoch: 5| Step: 8
Training loss: 2.2607109710317808
Validation loss: 2.731587416083949

Epoch: 5| Step: 9
Training loss: 1.7575907249421259
Validation loss: 2.8334296178171297

Epoch: 5| Step: 10
Training loss: 1.9774341696718356
Validation loss: 2.7624569696272903

Epoch: 545| Step: 0
Training loss: 1.711261178670502
Validation loss: 2.7844332408498222

Epoch: 5| Step: 1
Training loss: 1.872471821551305
Validation loss: 2.782805881097506

Epoch: 5| Step: 2
Training loss: 2.3436766549396135
Validation loss: 2.7573721468258827

Epoch: 5| Step: 3
Training loss: 1.8747066268288555
Validation loss: 2.7268302276657885

Epoch: 5| Step: 4
Training loss: 2.601650018909602
Validation loss: 2.7947982958317903

Epoch: 5| Step: 5
Training loss: 2.2523588954748437
Validation loss: 2.796234884389603

Epoch: 5| Step: 6
Training loss: 2.116211726140543
Validation loss: 2.837962130568197

Epoch: 5| Step: 7
Training loss: 2.222980602981157
Validation loss: 2.767022975044173

Epoch: 5| Step: 8
Training loss: 2.771543129855315
Validation loss: 2.8136243516592345

Epoch: 5| Step: 9
Training loss: 1.7416636958241412
Validation loss: 2.835524785240816

Epoch: 5| Step: 10
Training loss: 1.7226916804746468
Validation loss: 2.7803618250501394

Epoch: 546| Step: 0
Training loss: 2.177747293613588
Validation loss: 2.773246349753542

Epoch: 5| Step: 1
Training loss: 1.7620335739565582
Validation loss: 2.8006170120010188

Epoch: 5| Step: 2
Training loss: 1.683635454480023
Validation loss: 2.7754376439286883

Epoch: 5| Step: 3
Training loss: 2.468021719986911
Validation loss: 2.791117190883959

Epoch: 5| Step: 4
Training loss: 2.665375506228509
Validation loss: 2.820342672908872

Epoch: 5| Step: 5
Training loss: 1.5741286334802602
Validation loss: 2.836816127132154

Epoch: 5| Step: 6
Training loss: 1.73245283957143
Validation loss: 2.714180716849177

Epoch: 5| Step: 7
Training loss: 2.0978519625441847
Validation loss: 2.7967750374254257

Epoch: 5| Step: 8
Training loss: 2.8548546586061323
Validation loss: 2.828511176096249

Epoch: 5| Step: 9
Training loss: 2.0641978817939517
Validation loss: 2.7263348417929225

Epoch: 5| Step: 10
Training loss: 1.3736941465594246
Validation loss: 2.741147483826792

Epoch: 547| Step: 0
Training loss: 1.9810728096173056
Validation loss: 2.7417541484962262

Epoch: 5| Step: 1
Training loss: 2.7170511835617375
Validation loss: 2.775497356071786

Epoch: 5| Step: 2
Training loss: 1.5225438553580806
Validation loss: 2.756537370078528

Epoch: 5| Step: 3
Training loss: 1.804470957525766
Validation loss: 2.7549340879471553

Epoch: 5| Step: 4
Training loss: 3.0233619542503822
Validation loss: 2.7632838627720044

Epoch: 5| Step: 5
Training loss: 2.0158940808385526
Validation loss: 2.746414207182321

Epoch: 5| Step: 6
Training loss: 1.7239309425905571
Validation loss: 2.7270038168954107

Epoch: 5| Step: 7
Training loss: 1.6167372661919057
Validation loss: 2.7621927211005137

Epoch: 5| Step: 8
Training loss: 2.1805446675778613
Validation loss: 2.8327345954390974

Epoch: 5| Step: 9
Training loss: 1.8038599668358415
Validation loss: 2.767923738190625

Epoch: 5| Step: 10
Training loss: 1.651535233170582
Validation loss: 2.770131045198457

Epoch: 548| Step: 0
Training loss: 1.9994255075278995
Validation loss: 2.8293576375453586

Epoch: 5| Step: 1
Training loss: 1.5431179312524392
Validation loss: 2.8311619669108405

Epoch: 5| Step: 2
Training loss: 2.2168837744531387
Validation loss: 2.757657279784395

Epoch: 5| Step: 3
Training loss: 1.433469595457282
Validation loss: 2.7106654249419186

Epoch: 5| Step: 4
Training loss: 2.2650635122190255
Validation loss: 2.8233605418676535

Epoch: 5| Step: 5
Training loss: 1.7312295244569156
Validation loss: 2.7633632845775487

Epoch: 5| Step: 6
Training loss: 1.7023319182700352
Validation loss: 2.7609884000083045

Epoch: 5| Step: 7
Training loss: 3.147175651969649
Validation loss: 2.796005142170803

Epoch: 5| Step: 8
Training loss: 2.3175860997803337
Validation loss: 2.725116809419787

Epoch: 5| Step: 9
Training loss: 1.879877485787908
Validation loss: 2.8387982369454434

Epoch: 5| Step: 10
Training loss: 1.945981075496729
Validation loss: 2.7654540380648736

Epoch: 549| Step: 0
Training loss: 2.291530697574712
Validation loss: 2.844579915194876

Epoch: 5| Step: 1
Training loss: 2.122346904791331
Validation loss: 2.8415015959171597

Epoch: 5| Step: 2
Training loss: 1.4018948402310376
Validation loss: 2.730058663454737

Epoch: 5| Step: 3
Training loss: 2.484414826079907
Validation loss: 2.7865524480039436

Epoch: 5| Step: 4
Training loss: 1.7345553467608241
Validation loss: 2.7840628682955186

Epoch: 5| Step: 5
Training loss: 2.508502995866945
Validation loss: 2.715267789168569

Epoch: 5| Step: 6
Training loss: 2.621157513225209
Validation loss: 2.8303001232550256

Epoch: 5| Step: 7
Training loss: 1.5427389625670036
Validation loss: 2.7114042479792397

Epoch: 5| Step: 8
Training loss: 2.3399867044380875
Validation loss: 2.796075011379392

Epoch: 5| Step: 9
Training loss: 1.693979961366819
Validation loss: 2.714976216712147

Epoch: 5| Step: 10
Training loss: 2.08880030171375
Validation loss: 2.8574870817785496

Epoch: 550| Step: 0
Training loss: 2.0029870615106584
Validation loss: 2.802180317401425

Epoch: 5| Step: 1
Training loss: 2.134539341778249
Validation loss: 2.7490824933539852

Epoch: 5| Step: 2
Training loss: 2.2654245222118132
Validation loss: 2.748190646298926

Epoch: 5| Step: 3
Training loss: 1.7819296226304602
Validation loss: 2.792946706762741

Epoch: 5| Step: 4
Training loss: 1.2615810354561146
Validation loss: 2.7182390031946513

Epoch: 5| Step: 5
Training loss: 2.1918504234221836
Validation loss: 2.7093719996008634

Epoch: 5| Step: 6
Training loss: 2.6009734348874995
Validation loss: 2.7270539507213716

Epoch: 5| Step: 7
Training loss: 2.3208486021168535
Validation loss: 2.7259689104734153

Epoch: 5| Step: 8
Training loss: 2.0956710429015697
Validation loss: 2.8135832383393846

Epoch: 5| Step: 9
Training loss: 2.466262239946868
Validation loss: 2.7023109843045408

Epoch: 5| Step: 10
Training loss: 1.8721041887747407
Validation loss: 2.67273834025997

Epoch: 551| Step: 0
Training loss: 2.563301705345938
Validation loss: 2.8041880557070615

Epoch: 5| Step: 1
Training loss: 1.6452117744182133
Validation loss: 2.769194380468349

Epoch: 5| Step: 2
Training loss: 1.8579091938031345
Validation loss: 2.7772337686054565

Epoch: 5| Step: 3
Training loss: 2.4637557105429324
Validation loss: 2.810445155652145

Epoch: 5| Step: 4
Training loss: 1.5181070041964055
Validation loss: 2.8207061768243267

Epoch: 5| Step: 5
Training loss: 1.901980951011246
Validation loss: 2.74911294448009

Epoch: 5| Step: 6
Training loss: 1.158771034716448
Validation loss: 2.836084818360513

Epoch: 5| Step: 7
Training loss: 2.740579421600672
Validation loss: 2.7704457275525067

Epoch: 5| Step: 8
Training loss: 2.281147053107092
Validation loss: 2.845137383795368

Epoch: 5| Step: 9
Training loss: 1.5857089775320632
Validation loss: 2.8428741218671982

Epoch: 5| Step: 10
Training loss: 2.4268342464698462
Validation loss: 2.810107436047468

Epoch: 552| Step: 0
Training loss: 1.9485140885608994
Validation loss: 2.8098673340583287

Epoch: 5| Step: 1
Training loss: 1.6275230774070994
Validation loss: 2.852412571713239

Epoch: 5| Step: 2
Training loss: 2.117381407244022
Validation loss: 2.8446046936967093

Epoch: 5| Step: 3
Training loss: 1.2135673269197564
Validation loss: 2.8236386009014622

Epoch: 5| Step: 4
Training loss: 1.5257124909252102
Validation loss: 2.81524180643396

Epoch: 5| Step: 5
Training loss: 2.744848280919387
Validation loss: 2.823194120455231

Epoch: 5| Step: 6
Training loss: 2.029046139541721
Validation loss: 2.8007087072839747

Epoch: 5| Step: 7
Training loss: 2.3993981639939297
Validation loss: 2.828520334817947

Epoch: 5| Step: 8
Training loss: 2.333387941902193
Validation loss: 2.783474329407564

Epoch: 5| Step: 9
Training loss: 2.149542839771617
Validation loss: 2.7984262237740296

Epoch: 5| Step: 10
Training loss: 1.9728877469943902
Validation loss: 2.8298231370494658

Epoch: 553| Step: 0
Training loss: 1.9471401223896248
Validation loss: 2.793335342586632

Epoch: 5| Step: 1
Training loss: 1.9860141022057614
Validation loss: 2.7376742633548825

Epoch: 5| Step: 2
Training loss: 1.8585317286260719
Validation loss: 2.7075226061745354

Epoch: 5| Step: 3
Training loss: 1.9870226160767614
Validation loss: 2.8430326770278374

Epoch: 5| Step: 4
Training loss: 1.6196239012490499
Validation loss: 2.8062870362573413

Epoch: 5| Step: 5
Training loss: 2.3098411739954052
Validation loss: 2.7772167933640928

Epoch: 5| Step: 6
Training loss: 2.652060941695035
Validation loss: 2.785550140020889

Epoch: 5| Step: 7
Training loss: 1.6015580340067306
Validation loss: 2.798270324718062

Epoch: 5| Step: 8
Training loss: 1.8007951516630574
Validation loss: 2.815110407808488

Epoch: 5| Step: 9
Training loss: 1.5033704719833678
Validation loss: 2.7273482409812333

Epoch: 5| Step: 10
Training loss: 2.8579186237834793
Validation loss: 2.801174048459622

Epoch: 554| Step: 0
Training loss: 2.9545613988699544
Validation loss: 2.7940927052353746

Epoch: 5| Step: 1
Training loss: 1.6293913852934494
Validation loss: 2.795650673196277

Epoch: 5| Step: 2
Training loss: 2.021681564959639
Validation loss: 2.7440526720541305

Epoch: 5| Step: 3
Training loss: 1.5743327892258643
Validation loss: 2.7550220489721395

Epoch: 5| Step: 4
Training loss: 2.1024139834849085
Validation loss: 2.7081804338053694

Epoch: 5| Step: 5
Training loss: 1.8829817953014754
Validation loss: 2.7263012362532457

Epoch: 5| Step: 6
Training loss: 2.001089752853332
Validation loss: 2.8351696112345635

Epoch: 5| Step: 7
Training loss: 1.8147911849109037
Validation loss: 2.803697978960458

Epoch: 5| Step: 8
Training loss: 2.4133016134077834
Validation loss: 2.7296123865534527

Epoch: 5| Step: 9
Training loss: 1.878383381314173
Validation loss: 2.7638218116243785

Epoch: 5| Step: 10
Training loss: 2.2004696691460084
Validation loss: 2.7607934172666244

Epoch: 555| Step: 0
Training loss: 1.4235582553800077
Validation loss: 2.8211120548351265

Epoch: 5| Step: 1
Training loss: 1.98188715897039
Validation loss: 2.8118204040918435

Epoch: 5| Step: 2
Training loss: 2.3082030299714926
Validation loss: 2.758502408997197

Epoch: 5| Step: 3
Training loss: 2.066862521069013
Validation loss: 2.7987288907908248

Epoch: 5| Step: 4
Training loss: 2.14004063113135
Validation loss: 2.8075206522492047

Epoch: 5| Step: 5
Training loss: 2.34577406903802
Validation loss: 2.7756020842960156

Epoch: 5| Step: 6
Training loss: 2.3590718257718204
Validation loss: 2.7400426889307754

Epoch: 5| Step: 7
Training loss: 2.2136242181680825
Validation loss: 2.7524763705461215

Epoch: 5| Step: 8
Training loss: 2.1432734902404045
Validation loss: 2.774329733355731

Epoch: 5| Step: 9
Training loss: 2.4091426752198446
Validation loss: 2.7740473888802097

Epoch: 5| Step: 10
Training loss: 1.1450892315372974
Validation loss: 2.7558295565766637

Epoch: 556| Step: 0
Training loss: 1.7412398288317466
Validation loss: 2.7281205057868476

Epoch: 5| Step: 1
Training loss: 2.3979999752028767
Validation loss: 2.820846233052751

Epoch: 5| Step: 2
Training loss: 1.9777262883978834
Validation loss: 2.7884730452102673

Epoch: 5| Step: 3
Training loss: 3.087582384006513
Validation loss: 2.7959950260598303

Epoch: 5| Step: 4
Training loss: 1.602066556183764
Validation loss: 2.78368767962328

Epoch: 5| Step: 5
Training loss: 1.8520623671121266
Validation loss: 2.765111347263234

Epoch: 5| Step: 6
Training loss: 1.9763404208784472
Validation loss: 2.7328320234353405

Epoch: 5| Step: 7
Training loss: 2.0202571663650923
Validation loss: 2.860426837238733

Epoch: 5| Step: 8
Training loss: 2.127081580788703
Validation loss: 2.856111490091845

Epoch: 5| Step: 9
Training loss: 1.8271664445765534
Validation loss: 2.7874477909488347

Epoch: 5| Step: 10
Training loss: 1.8647372716798385
Validation loss: 2.7013541728153077

Epoch: 557| Step: 0
Training loss: 1.7096568152508964
Validation loss: 2.860219663812042

Epoch: 5| Step: 1
Training loss: 2.187521580180942
Validation loss: 2.8637291606707516

Epoch: 5| Step: 2
Training loss: 1.5487942589692831
Validation loss: 2.867152496354014

Epoch: 5| Step: 3
Training loss: 2.347011788720982
Validation loss: 2.9290252020067262

Epoch: 5| Step: 4
Training loss: 2.7743570012391534
Validation loss: 2.7778690191549567

Epoch: 5| Step: 5
Training loss: 1.9174975031870038
Validation loss: 2.7734927315060256

Epoch: 5| Step: 6
Training loss: 2.001836648669552
Validation loss: 2.813057326285734

Epoch: 5| Step: 7
Training loss: 2.0953999181798575
Validation loss: 2.7245901199362006

Epoch: 5| Step: 8
Training loss: 1.7801361616968823
Validation loss: 2.871083118942788

Epoch: 5| Step: 9
Training loss: 1.8857378887994765
Validation loss: 2.788625475477264

Epoch: 5| Step: 10
Training loss: 2.1321792500848016
Validation loss: 2.7523842271030934

Epoch: 558| Step: 0
Training loss: 1.7479625830759353
Validation loss: 2.8070493468694204

Epoch: 5| Step: 1
Training loss: 2.1175872312771133
Validation loss: 2.7809115060188745

Epoch: 5| Step: 2
Training loss: 2.077034570956332
Validation loss: 2.735320531732175

Epoch: 5| Step: 3
Training loss: 1.849641020201009
Validation loss: 2.8388904129626362

Epoch: 5| Step: 4
Training loss: 2.3535575641361817
Validation loss: 2.7761487664071502

Epoch: 5| Step: 5
Training loss: 2.0439768067479234
Validation loss: 2.762367057914464

Epoch: 5| Step: 6
Training loss: 2.058220903772675
Validation loss: 2.7751288163398944

Epoch: 5| Step: 7
Training loss: 1.9870633515355636
Validation loss: 2.759911593857775

Epoch: 5| Step: 8
Training loss: 2.4858341370582453
Validation loss: 2.758546204719659

Epoch: 5| Step: 9
Training loss: 2.101327649008781
Validation loss: 2.7903984411190277

Epoch: 5| Step: 10
Training loss: 1.277855726757756
Validation loss: 2.761878287471468

Epoch: 559| Step: 0
Training loss: 2.211406860135852
Validation loss: 2.874067990974507

Epoch: 5| Step: 1
Training loss: 2.545587881423138
Validation loss: 2.7906590551737374

Epoch: 5| Step: 2
Training loss: 2.116854370485198
Validation loss: 2.7969032900753197

Epoch: 5| Step: 3
Training loss: 1.6356138446618405
Validation loss: 2.803912187671718

Epoch: 5| Step: 4
Training loss: 1.8581104626746103
Validation loss: 2.735162335794032

Epoch: 5| Step: 5
Training loss: 2.457641525772557
Validation loss: 2.754045745288572

Epoch: 5| Step: 6
Training loss: 1.4491810755189753
Validation loss: 2.7767178150435448

Epoch: 5| Step: 7
Training loss: 2.0497879383844055
Validation loss: 2.7645964714816453

Epoch: 5| Step: 8
Training loss: 1.8187850634154317
Validation loss: 2.7438877545504696

Epoch: 5| Step: 9
Training loss: 1.8948079015348422
Validation loss: 2.799763297991271

Epoch: 5| Step: 10
Training loss: 2.345472491231309
Validation loss: 2.7277342089862193

Epoch: 560| Step: 0
Training loss: 2.3088839327592052
Validation loss: 2.746946711247372

Epoch: 5| Step: 1
Training loss: 2.0700456555256683
Validation loss: 2.819182715182689

Epoch: 5| Step: 2
Training loss: 2.597345824085622
Validation loss: 2.748411331248524

Epoch: 5| Step: 3
Training loss: 2.0198212937347373
Validation loss: 2.868358254003347

Epoch: 5| Step: 4
Training loss: 1.908103542013556
Validation loss: 2.7523255504018675

Epoch: 5| Step: 5
Training loss: 2.2601625032994423
Validation loss: 2.7258074800725187

Epoch: 5| Step: 6
Training loss: 1.9359886673761135
Validation loss: 2.7183561043268973

Epoch: 5| Step: 7
Training loss: 1.9593896722320285
Validation loss: 2.8402513710616546

Epoch: 5| Step: 8
Training loss: 2.187658140733271
Validation loss: 2.742825124800809

Epoch: 5| Step: 9
Training loss: 1.2534672334007582
Validation loss: 2.746604235181307

Epoch: 5| Step: 10
Training loss: 1.752630980816964
Validation loss: 2.771511900277161

Epoch: 561| Step: 0
Training loss: 2.017580488412217
Validation loss: 2.829215824322897

Epoch: 5| Step: 1
Training loss: 1.9188264067406728
Validation loss: 2.7657297933867744

Epoch: 5| Step: 2
Training loss: 1.7375171825190536
Validation loss: 2.7355400638744722

Epoch: 5| Step: 3
Training loss: 1.7142691724978218
Validation loss: 2.7472831789679875

Epoch: 5| Step: 4
Training loss: 1.9732065169829387
Validation loss: 2.8063876758320108

Epoch: 5| Step: 5
Training loss: 2.200963251606968
Validation loss: 2.740031050720277

Epoch: 5| Step: 6
Training loss: 2.8307274072963904
Validation loss: 2.7025590757415117

Epoch: 5| Step: 7
Training loss: 2.1384562623191643
Validation loss: 2.823944599984291

Epoch: 5| Step: 8
Training loss: 1.9945459505010854
Validation loss: 2.789425529020903

Epoch: 5| Step: 9
Training loss: 1.801536285924309
Validation loss: 2.8541416436279534

Epoch: 5| Step: 10
Training loss: 2.2432363363139163
Validation loss: 2.8088696510993705

Epoch: 562| Step: 0
Training loss: 1.8020246271997233
Validation loss: 2.729812163106363

Epoch: 5| Step: 1
Training loss: 1.7995189951248938
Validation loss: 2.839808140293468

Epoch: 5| Step: 2
Training loss: 2.3319798245023446
Validation loss: 2.7465411991999202

Epoch: 5| Step: 3
Training loss: 1.796788487217639
Validation loss: 2.802298797424628

Epoch: 5| Step: 4
Training loss: 1.9175862165860422
Validation loss: 2.7738024233363663

Epoch: 5| Step: 5
Training loss: 2.1208102491680094
Validation loss: 2.8490098559889665

Epoch: 5| Step: 6
Training loss: 1.9312116649983333
Validation loss: 2.8066163060104654

Epoch: 5| Step: 7
Training loss: 1.975120108610023
Validation loss: 2.773353913021207

Epoch: 5| Step: 8
Training loss: 2.1003925229121285
Validation loss: 2.842341779671537

Epoch: 5| Step: 9
Training loss: 1.9162279608268464
Validation loss: 2.7434151101559796

Epoch: 5| Step: 10
Training loss: 2.8373690268248093
Validation loss: 2.8150695138106623

Epoch: 563| Step: 0
Training loss: 1.8759720507859918
Validation loss: 2.7585256967912093

Epoch: 5| Step: 1
Training loss: 2.38715105153031
Validation loss: 2.690289098695006

Epoch: 5| Step: 2
Training loss: 2.3332135192445413
Validation loss: 2.7428792492274274

Epoch: 5| Step: 3
Training loss: 2.0817873241110845
Validation loss: 2.8088236737241217

Epoch: 5| Step: 4
Training loss: 1.747541744623126
Validation loss: 2.8067475624791185

Epoch: 5| Step: 5
Training loss: 1.793890622571544
Validation loss: 2.7914122507029524

Epoch: 5| Step: 6
Training loss: 1.8530411751171876
Validation loss: 2.7744434991538762

Epoch: 5| Step: 7
Training loss: 2.670820239943032
Validation loss: 2.7180320858357154

Epoch: 5| Step: 8
Training loss: 1.422794589628068
Validation loss: 2.7971430961829693

Epoch: 5| Step: 9
Training loss: 2.054069164920535
Validation loss: 2.7386992433349864

Epoch: 5| Step: 10
Training loss: 1.5729221655473735
Validation loss: 2.748513311165002

Epoch: 564| Step: 0
Training loss: 1.9617608762021275
Validation loss: 2.7588943766548795

Epoch: 5| Step: 1
Training loss: 2.274423811331887
Validation loss: 2.723878981705943

Epoch: 5| Step: 2
Training loss: 1.834832431095934
Validation loss: 2.736238695438345

Epoch: 5| Step: 3
Training loss: 1.6485769926956209
Validation loss: 2.7828361225794715

Epoch: 5| Step: 4
Training loss: 1.9306384998070603
Validation loss: 2.755246423594138

Epoch: 5| Step: 5
Training loss: 2.4135406819027234
Validation loss: 2.850775249984788

Epoch: 5| Step: 6
Training loss: 1.768760597547723
Validation loss: 2.794037336840944

Epoch: 5| Step: 7
Training loss: 2.4192163456480658
Validation loss: 2.846295783700373

Epoch: 5| Step: 8
Training loss: 2.3774331328317997
Validation loss: 2.756367327965812

Epoch: 5| Step: 9
Training loss: 1.7605889666806895
Validation loss: 2.7431891383939546

Epoch: 5| Step: 10
Training loss: 2.0070014235677265
Validation loss: 2.768110567901195

Epoch: 565| Step: 0
Training loss: 2.6361043482663447
Validation loss: 2.743707252147196

Epoch: 5| Step: 1
Training loss: 1.62446453368786
Validation loss: 2.8421811068644356

Epoch: 5| Step: 2
Training loss: 2.2727856307773546
Validation loss: 2.7460104220568167

Epoch: 5| Step: 3
Training loss: 2.041105803181274
Validation loss: 2.7972241695470172

Epoch: 5| Step: 4
Training loss: 1.8662111930108407
Validation loss: 2.786827345572338

Epoch: 5| Step: 5
Training loss: 1.497307745512501
Validation loss: 2.7045877332828194

Epoch: 5| Step: 6
Training loss: 2.186167283758982
Validation loss: 2.8170655560498856

Epoch: 5| Step: 7
Training loss: 1.6642222439739371
Validation loss: 2.8417870689431237

Epoch: 5| Step: 8
Training loss: 2.0576043257562544
Validation loss: 2.821370222549797

Epoch: 5| Step: 9
Training loss: 2.276245689995512
Validation loss: 2.6993948679539077

Epoch: 5| Step: 10
Training loss: 2.0714655130596924
Validation loss: 2.765995772712022

Epoch: 566| Step: 0
Training loss: 2.1113259794522516
Validation loss: 2.854069880518242

Epoch: 5| Step: 1
Training loss: 1.9199612400990458
Validation loss: 2.7445642308942646

Epoch: 5| Step: 2
Training loss: 1.7364059791231763
Validation loss: 2.7214505883843665

Epoch: 5| Step: 3
Training loss: 2.085830742893701
Validation loss: 2.796182759089247

Epoch: 5| Step: 4
Training loss: 2.0101605056142406
Validation loss: 2.824799553180013

Epoch: 5| Step: 5
Training loss: 1.8625828615740154
Validation loss: 2.785171877621825

Epoch: 5| Step: 6
Training loss: 1.740463361648724
Validation loss: 2.875935447350648

Epoch: 5| Step: 7
Training loss: 2.2162215103753815
Validation loss: 2.8509859170533396

Epoch: 5| Step: 8
Training loss: 1.8948991870485217
Validation loss: 2.779741468739564

Epoch: 5| Step: 9
Training loss: 2.4003669855553835
Validation loss: 2.854190098470444

Epoch: 5| Step: 10
Training loss: 2.750687946621263
Validation loss: 2.815336349984532

Epoch: 567| Step: 0
Training loss: 2.081134882312164
Validation loss: 2.8139263360116304

Epoch: 5| Step: 1
Training loss: 1.6977654216157503
Validation loss: 2.78433161069501

Epoch: 5| Step: 2
Training loss: 1.8956229613683386
Validation loss: 2.835677880334133

Epoch: 5| Step: 3
Training loss: 1.9448931751481975
Validation loss: 2.805047113994146

Epoch: 5| Step: 4
Training loss: 2.547921463053928
Validation loss: 2.8201496330736577

Epoch: 5| Step: 5
Training loss: 2.3974943512182745
Validation loss: 2.7164270899186165

Epoch: 5| Step: 6
Training loss: 2.1911573081641342
Validation loss: 2.771813929617627

Epoch: 5| Step: 7
Training loss: 1.692697573896594
Validation loss: 2.762919360437702

Epoch: 5| Step: 8
Training loss: 1.7661673463999672
Validation loss: 2.771195720987844

Epoch: 5| Step: 9
Training loss: 1.8372723860124966
Validation loss: 2.7512915236275473

Epoch: 5| Step: 10
Training loss: 2.4596717122302727
Validation loss: 2.7019715881758155

Epoch: 568| Step: 0
Training loss: 1.7863954879635426
Validation loss: 2.663659608730822

Epoch: 5| Step: 1
Training loss: 2.0749701164575587
Validation loss: 2.7653420662023493

Epoch: 5| Step: 2
Training loss: 1.7600633917576296
Validation loss: 2.8065713412660624

Epoch: 5| Step: 3
Training loss: 1.9093269779141284
Validation loss: 2.6983218601253496

Epoch: 5| Step: 4
Training loss: 1.9288438813952198
Validation loss: 2.7896677892385022

Epoch: 5| Step: 5
Training loss: 1.882453536008611
Validation loss: 2.809308168530533

Epoch: 5| Step: 6
Training loss: 2.183769969619603
Validation loss: 2.760937672485567

Epoch: 5| Step: 7
Training loss: 2.2935225745604315
Validation loss: 2.7193542174923433

Epoch: 5| Step: 8
Training loss: 2.7771970385553657
Validation loss: 2.7154805958337125

Epoch: 5| Step: 9
Training loss: 1.5183320400485167
Validation loss: 2.786826863537521

Epoch: 5| Step: 10
Training loss: 1.9571095829741592
Validation loss: 2.76561667212397

Epoch: 569| Step: 0
Training loss: 2.0840484409084006
Validation loss: 2.8033110092973663

Epoch: 5| Step: 1
Training loss: 2.297519515559648
Validation loss: 2.7805836676557014

Epoch: 5| Step: 2
Training loss: 1.87452876209203
Validation loss: 2.8011762339616095

Epoch: 5| Step: 3
Training loss: 1.7814168349989568
Validation loss: 2.767137923235775

Epoch: 5| Step: 4
Training loss: 2.251461613954119
Validation loss: 2.7865451357990287

Epoch: 5| Step: 5
Training loss: 1.836254141265998
Validation loss: 2.766883488214536

Epoch: 5| Step: 6
Training loss: 2.376521877766782
Validation loss: 2.7570878881805494

Epoch: 5| Step: 7
Training loss: 2.3603629765769223
Validation loss: 2.8584346407322707

Epoch: 5| Step: 8
Training loss: 1.5983776897975501
Validation loss: 2.806055907936999

Epoch: 5| Step: 9
Training loss: 1.8589155767559045
Validation loss: 2.828474724905724

Epoch: 5| Step: 10
Training loss: 1.9789410780452146
Validation loss: 2.801097985887769

Epoch: 570| Step: 0
Training loss: 2.1745634934450466
Validation loss: 2.730650951800032

Epoch: 5| Step: 1
Training loss: 1.8505318908046107
Validation loss: 2.7822452979726013

Epoch: 5| Step: 2
Training loss: 1.7679294637444207
Validation loss: 2.8015571158381936

Epoch: 5| Step: 3
Training loss: 1.3820465466573042
Validation loss: 2.7583395590168354

Epoch: 5| Step: 4
Training loss: 1.57816450617224
Validation loss: 2.810291849975409

Epoch: 5| Step: 5
Training loss: 2.6319113980659163
Validation loss: 2.71386436489975

Epoch: 5| Step: 6
Training loss: 2.4474852053201936
Validation loss: 2.7458069662273785

Epoch: 5| Step: 7
Training loss: 1.8414566518677564
Validation loss: 2.822771652075674

Epoch: 5| Step: 8
Training loss: 2.26966424181394
Validation loss: 2.8407775731076876

Epoch: 5| Step: 9
Training loss: 1.939796932053394
Validation loss: 2.731036300973882

Epoch: 5| Step: 10
Training loss: 2.5286713640447798
Validation loss: 2.830070028455747

Epoch: 571| Step: 0
Training loss: 1.4784738592701483
Validation loss: 2.817099241866743

Epoch: 5| Step: 1
Training loss: 2.390301651373338
Validation loss: 2.8092434112477376

Epoch: 5| Step: 2
Training loss: 2.4256275269579484
Validation loss: 2.6844673512260924

Epoch: 5| Step: 3
Training loss: 1.7795259263373249
Validation loss: 2.7839723716171614

Epoch: 5| Step: 4
Training loss: 2.013598465714535
Validation loss: 2.769579541192213

Epoch: 5| Step: 5
Training loss: 1.9789848712614664
Validation loss: 2.781229716631769

Epoch: 5| Step: 6
Training loss: 1.7791684352440125
Validation loss: 2.758743367471445

Epoch: 5| Step: 7
Training loss: 1.8741332912003417
Validation loss: 2.7507464103478587

Epoch: 5| Step: 8
Training loss: 1.795513665704182
Validation loss: 2.7662314548459004

Epoch: 5| Step: 9
Training loss: 2.263652284683889
Validation loss: 2.7855560835411017

Epoch: 5| Step: 10
Training loss: 2.1191427626357306
Validation loss: 2.7426282291697572

Epoch: 572| Step: 0
Training loss: 2.229950478863509
Validation loss: 2.8127579437432164

Epoch: 5| Step: 1
Training loss: 2.832914059602196
Validation loss: 2.9075505415022724

Epoch: 5| Step: 2
Training loss: 1.965216478066491
Validation loss: 2.7886199558713707

Epoch: 5| Step: 3
Training loss: 1.7858803780833132
Validation loss: 2.7698931829608227

Epoch: 5| Step: 4
Training loss: 1.9236780408224323
Validation loss: 2.7785045322866933

Epoch: 5| Step: 5
Training loss: 1.8712313607408149
Validation loss: 2.6359072625049698

Epoch: 5| Step: 6
Training loss: 1.8751237828403517
Validation loss: 2.7954134426374364

Epoch: 5| Step: 7
Training loss: 1.202201042604732
Validation loss: 2.8025973438254796

Epoch: 5| Step: 8
Training loss: 2.0162581994303257
Validation loss: 2.7739263343789906

Epoch: 5| Step: 9
Training loss: 2.346832689495643
Validation loss: 2.8490088724684313

Epoch: 5| Step: 10
Training loss: 1.5437341264534123
Validation loss: 2.7465919461999952

Epoch: 573| Step: 0
Training loss: 1.9368803202336604
Validation loss: 2.8136989403410837

Epoch: 5| Step: 1
Training loss: 2.304211066187888
Validation loss: 2.705826111070731

Epoch: 5| Step: 2
Training loss: 2.0922285786727604
Validation loss: 2.750415818108616

Epoch: 5| Step: 3
Training loss: 1.9241869906407671
Validation loss: 2.8296174656375195

Epoch: 5| Step: 4
Training loss: 2.574270615467643
Validation loss: 2.7955954530379574

Epoch: 5| Step: 5
Training loss: 1.470625066015499
Validation loss: 2.7481897759527967

Epoch: 5| Step: 6
Training loss: 1.9869513420133278
Validation loss: 2.7594319804411493

Epoch: 5| Step: 7
Training loss: 2.0176809308724093
Validation loss: 2.7885334288292296

Epoch: 5| Step: 8
Training loss: 1.8655110897899134
Validation loss: 2.7874233776281354

Epoch: 5| Step: 9
Training loss: 1.765938114995787
Validation loss: 2.7928425031842368

Epoch: 5| Step: 10
Training loss: 2.037364852261187
Validation loss: 2.7586223197986297

Epoch: 574| Step: 0
Training loss: 1.8112687499956193
Validation loss: 2.8474102802200063

Epoch: 5| Step: 1
Training loss: 2.5508072342067605
Validation loss: 2.741460089879189

Epoch: 5| Step: 2
Training loss: 2.137456177379383
Validation loss: 2.8328117062956166

Epoch: 5| Step: 3
Training loss: 2.2807773466234282
Validation loss: 2.807771535831579

Epoch: 5| Step: 4
Training loss: 2.3047286725003477
Validation loss: 2.768212312937949

Epoch: 5| Step: 5
Training loss: 1.8930396431602197
Validation loss: 2.673195912102365

Epoch: 5| Step: 6
Training loss: 1.908919482048282
Validation loss: 2.8149817524936025

Epoch: 5| Step: 7
Training loss: 2.393505878799069
Validation loss: 2.8383837054306063

Epoch: 5| Step: 8
Training loss: 1.8314062813481475
Validation loss: 2.8366105253300735

Epoch: 5| Step: 9
Training loss: 1.8365276930144185
Validation loss: 2.8295292866595174

Epoch: 5| Step: 10
Training loss: 1.4491971160836812
Validation loss: 2.743193018632558

Epoch: 575| Step: 0
Training loss: 1.4611077031014024
Validation loss: 2.826555007450016

Epoch: 5| Step: 1
Training loss: 2.252685427807823
Validation loss: 2.7461702671668338

Epoch: 5| Step: 2
Training loss: 1.636804473744242
Validation loss: 2.7854179417357083

Epoch: 5| Step: 3
Training loss: 2.6658789742909197
Validation loss: 2.850302408851846

Epoch: 5| Step: 4
Training loss: 2.0073239218141654
Validation loss: 2.827199844985937

Epoch: 5| Step: 5
Training loss: 2.626778408891341
Validation loss: 2.7876618757922

Epoch: 5| Step: 6
Training loss: 1.6397409873048205
Validation loss: 2.814649009276873

Epoch: 5| Step: 7
Training loss: 1.5450753426313386
Validation loss: 2.7474914493707847

Epoch: 5| Step: 8
Training loss: 1.988201986655277
Validation loss: 2.827901850102434

Epoch: 5| Step: 9
Training loss: 2.173648137869698
Validation loss: 2.733555473184361

Epoch: 5| Step: 10
Training loss: 1.7931221291754083
Validation loss: 2.721190824501778

Epoch: 576| Step: 0
Training loss: 1.6725685606219791
Validation loss: 2.7903848649181278

Epoch: 5| Step: 1
Training loss: 2.2402354392570487
Validation loss: 2.7374777698536676

Epoch: 5| Step: 2
Training loss: 1.6244257866089025
Validation loss: 2.749838351647474

Epoch: 5| Step: 3
Training loss: 2.074700883195027
Validation loss: 2.733748458124479

Epoch: 5| Step: 4
Training loss: 1.9857597625696073
Validation loss: 2.8033438306730476

Epoch: 5| Step: 5
Training loss: 1.9988262785574455
Validation loss: 2.748442296300149

Epoch: 5| Step: 6
Training loss: 1.7462003193193616
Validation loss: 2.7519262713937938

Epoch: 5| Step: 7
Training loss: 1.9760330154425296
Validation loss: 2.779955690104119

Epoch: 5| Step: 8
Training loss: 2.135740736274941
Validation loss: 2.807397241852358

Epoch: 5| Step: 9
Training loss: 1.9630080762046989
Validation loss: 2.8139258722847824

Epoch: 5| Step: 10
Training loss: 2.677093852179577
Validation loss: 2.79218746507366

Epoch: 577| Step: 0
Training loss: 2.554570839927618
Validation loss: 2.7939684773783133

Epoch: 5| Step: 1
Training loss: 1.196944126692642
Validation loss: 2.8144976996719224

Epoch: 5| Step: 2
Training loss: 1.8060209954098556
Validation loss: 2.7473955770372975

Epoch: 5| Step: 3
Training loss: 2.337801186644225
Validation loss: 2.7361360579882836

Epoch: 5| Step: 4
Training loss: 1.653840741863506
Validation loss: 2.768033506943303

Epoch: 5| Step: 5
Training loss: 1.919366144913246
Validation loss: 2.7419722717164983

Epoch: 5| Step: 6
Training loss: 2.1980564982934223
Validation loss: 2.694461938812304

Epoch: 5| Step: 7
Training loss: 1.9336463381619287
Validation loss: 2.75122997599297

Epoch: 5| Step: 8
Training loss: 2.547980694552455
Validation loss: 2.7615665621808634

Epoch: 5| Step: 9
Training loss: 2.2049409132672366
Validation loss: 2.753799250913969

Epoch: 5| Step: 10
Training loss: 1.5052173794625263
Validation loss: 2.784464322744659

Epoch: 578| Step: 0
Training loss: 1.3197879990925923
Validation loss: 2.7772917002950472

Epoch: 5| Step: 1
Training loss: 1.8574821390189171
Validation loss: 2.7266595773045377

Epoch: 5| Step: 2
Training loss: 2.2051551068825423
Validation loss: 2.7820335925983923

Epoch: 5| Step: 3
Training loss: 2.26559048330388
Validation loss: 2.7526911901073228

Epoch: 5| Step: 4
Training loss: 2.5970509677214406
Validation loss: 2.8115892072651536

Epoch: 5| Step: 5
Training loss: 1.7885324284250694
Validation loss: 2.770469429908956

Epoch: 5| Step: 6
Training loss: 1.959679127624954
Validation loss: 2.7970417871480575

Epoch: 5| Step: 7
Training loss: 1.8468055621679142
Validation loss: 2.7712103292460295

Epoch: 5| Step: 8
Training loss: 2.2394098495595216
Validation loss: 2.792450421683705

Epoch: 5| Step: 9
Training loss: 1.6554869567532395
Validation loss: 2.778155203442075

Epoch: 5| Step: 10
Training loss: 2.7323236236467996
Validation loss: 2.8497233489151386

Epoch: 579| Step: 0
Training loss: 2.395116737562901
Validation loss: 2.7198420957168548

Epoch: 5| Step: 1
Training loss: 2.2610129933648215
Validation loss: 2.696704136074914

Epoch: 5| Step: 2
Training loss: 2.1004524560971873
Validation loss: 2.7460947040971697

Epoch: 5| Step: 3
Training loss: 1.371181952527658
Validation loss: 2.7832591888129294

Epoch: 5| Step: 4
Training loss: 1.611338186521617
Validation loss: 2.792086550549115

Epoch: 5| Step: 5
Training loss: 1.900671127647714
Validation loss: 2.8253855286924674

Epoch: 5| Step: 6
Training loss: 1.5230276485696164
Validation loss: 2.812008766289133

Epoch: 5| Step: 7
Training loss: 2.07626592327996
Validation loss: 2.7432902751324506

Epoch: 5| Step: 8
Training loss: 2.631657468728566
Validation loss: 2.761680972571408

Epoch: 5| Step: 9
Training loss: 2.3184365032320904
Validation loss: 2.7547445061321776

Epoch: 5| Step: 10
Training loss: 1.4563369528551642
Validation loss: 2.7237515062876163

Epoch: 580| Step: 0
Training loss: 1.9848753531113523
Validation loss: 2.7872136807049834

Epoch: 5| Step: 1
Training loss: 2.7716521198244988
Validation loss: 2.7247234140518737

Epoch: 5| Step: 2
Training loss: 1.6949302136844024
Validation loss: 2.851301878131934

Epoch: 5| Step: 3
Training loss: 1.498395538538102
Validation loss: 2.7846299829588435

Epoch: 5| Step: 4
Training loss: 2.017000778621737
Validation loss: 2.8463781878733694

Epoch: 5| Step: 5
Training loss: 1.9664638506304106
Validation loss: 2.819844402696813

Epoch: 5| Step: 6
Training loss: 1.7296204565161812
Validation loss: 2.6734224827616986

Epoch: 5| Step: 7
Training loss: 2.381255995374927
Validation loss: 2.761249913493642

Epoch: 5| Step: 8
Training loss: 2.1455150355832555
Validation loss: 2.72259529419701

Epoch: 5| Step: 9
Training loss: 1.9345085677220681
Validation loss: 2.791511091128608

Epoch: 5| Step: 10
Training loss: 1.6594712942456014
Validation loss: 2.706617916424768

Epoch: 581| Step: 0
Training loss: 2.3852362640884155
Validation loss: 2.774287309544296

Epoch: 5| Step: 1
Training loss: 1.4936193816085472
Validation loss: 2.8098636608514767

Epoch: 5| Step: 2
Training loss: 2.2293955129883347
Validation loss: 2.8087332674598877

Epoch: 5| Step: 3
Training loss: 1.50932710307007
Validation loss: 2.736184341276326

Epoch: 5| Step: 4
Training loss: 2.240231607929307
Validation loss: 2.746205418194374

Epoch: 5| Step: 5
Training loss: 2.071484734098003
Validation loss: 2.752241742337069

Epoch: 5| Step: 6
Training loss: 1.482602878622618
Validation loss: 2.8178853494998153

Epoch: 5| Step: 7
Training loss: 2.148215320542968
Validation loss: 2.7174434443175803

Epoch: 5| Step: 8
Training loss: 1.708515142054967
Validation loss: 2.8183766468424984

Epoch: 5| Step: 9
Training loss: 2.4593956370863226
Validation loss: 2.7045830128068116

Epoch: 5| Step: 10
Training loss: 1.8606618707531952
Validation loss: 2.7229675095276176

Epoch: 582| Step: 0
Training loss: 2.2933998027676012
Validation loss: 2.7946594348507006

Epoch: 5| Step: 1
Training loss: 2.2039503350728604
Validation loss: 2.7690467604510145

Epoch: 5| Step: 2
Training loss: 1.8891080965987006
Validation loss: 2.8054471291616143

Epoch: 5| Step: 3
Training loss: 2.199743611394651
Validation loss: 2.77910774301202

Epoch: 5| Step: 4
Training loss: 1.623546170075424
Validation loss: 2.7730239220097648

Epoch: 5| Step: 5
Training loss: 2.4018793417032485
Validation loss: 2.732194097935819

Epoch: 5| Step: 6
Training loss: 1.6985960773181525
Validation loss: 2.817882002436919

Epoch: 5| Step: 7
Training loss: 2.257553983361853
Validation loss: 2.7572549152101042

Epoch: 5| Step: 8
Training loss: 1.45077653020318
Validation loss: 2.825403885424561

Epoch: 5| Step: 9
Training loss: 1.8413425180430314
Validation loss: 2.7893949150692894

Epoch: 5| Step: 10
Training loss: 2.10453886259145
Validation loss: 2.73000867589604

Epoch: 583| Step: 0
Training loss: 1.7120841725727152
Validation loss: 2.8054023211317305

Epoch: 5| Step: 1
Training loss: 1.3434370696729745
Validation loss: 2.7911909436080258

Epoch: 5| Step: 2
Training loss: 2.0433680652863138
Validation loss: 2.8239612593870764

Epoch: 5| Step: 3
Training loss: 2.411019985051275
Validation loss: 2.7720411109264664

Epoch: 5| Step: 4
Training loss: 1.873531529450653
Validation loss: 2.728170567409068

Epoch: 5| Step: 5
Training loss: 2.223801034788832
Validation loss: 2.785224833050568

Epoch: 5| Step: 6
Training loss: 2.691235186672947
Validation loss: 2.791734549208736

Epoch: 5| Step: 7
Training loss: 2.1332011445138788
Validation loss: 2.860924176309393

Epoch: 5| Step: 8
Training loss: 1.5910398590542492
Validation loss: 2.839722151925428

Epoch: 5| Step: 9
Training loss: 1.6236606360109234
Validation loss: 2.787025828281756

Epoch: 5| Step: 10
Training loss: 1.8455536635499723
Validation loss: 2.7005755192442504

Epoch: 584| Step: 0
Training loss: 2.028366036925939
Validation loss: 2.774757083576955

Epoch: 5| Step: 1
Training loss: 1.7406301337394137
Validation loss: 2.791563020807659

Epoch: 5| Step: 2
Training loss: 2.465336818316431
Validation loss: 2.8076131954155814

Epoch: 5| Step: 3
Training loss: 1.8185931423227866
Validation loss: 2.8506030014906654

Epoch: 5| Step: 4
Training loss: 1.9614453512995573
Validation loss: 2.797816970543489

Epoch: 5| Step: 5
Training loss: 1.6578938226051965
Validation loss: 2.7588944593561293

Epoch: 5| Step: 6
Training loss: 1.1221167386296824
Validation loss: 2.7645260005136243

Epoch: 5| Step: 7
Training loss: 2.3638860764009224
Validation loss: 2.8354587027017124

Epoch: 5| Step: 8
Training loss: 1.967869455725771
Validation loss: 2.853915894619575

Epoch: 5| Step: 9
Training loss: 2.4894142146640905
Validation loss: 2.781717168773401

Epoch: 5| Step: 10
Training loss: 1.885172461049917
Validation loss: 2.787146483995502

Epoch: 585| Step: 0
Training loss: 1.6676620451559236
Validation loss: 2.8239103739582885

Epoch: 5| Step: 1
Training loss: 1.3674156652524347
Validation loss: 2.749840189186034

Epoch: 5| Step: 2
Training loss: 2.3697550229324085
Validation loss: 2.7834713324008984

Epoch: 5| Step: 3
Training loss: 1.8143725752017656
Validation loss: 2.742726432924679

Epoch: 5| Step: 4
Training loss: 2.5013253513559928
Validation loss: 2.7648118802099106

Epoch: 5| Step: 5
Training loss: 2.0695677371352956
Validation loss: 2.718974322856098

Epoch: 5| Step: 6
Training loss: 2.1690460003081165
Validation loss: 2.759446114453946

Epoch: 5| Step: 7
Training loss: 2.3302453133779757
Validation loss: 2.7649889187217194

Epoch: 5| Step: 8
Training loss: 2.0050588048364193
Validation loss: 2.656713660717168

Epoch: 5| Step: 9
Training loss: 2.1192583042642235
Validation loss: 2.7951295875987836

Epoch: 5| Step: 10
Training loss: 1.886426567373296
Validation loss: 2.7592578860345833

Epoch: 586| Step: 0
Training loss: 1.430328558943553
Validation loss: 2.7808223209805125

Epoch: 5| Step: 1
Training loss: 1.781345431799739
Validation loss: 2.7798447044566834

Epoch: 5| Step: 2
Training loss: 1.590812669036656
Validation loss: 2.7398963651750745

Epoch: 5| Step: 3
Training loss: 1.7742886286370014
Validation loss: 2.8153321084142213

Epoch: 5| Step: 4
Training loss: 1.3846481983665548
Validation loss: 2.811871245732993

Epoch: 5| Step: 5
Training loss: 2.2166511386910663
Validation loss: 2.7599090728625817

Epoch: 5| Step: 6
Training loss: 1.9680581466644587
Validation loss: 2.731372542661788

Epoch: 5| Step: 7
Training loss: 2.219181717255633
Validation loss: 2.7474021965590407

Epoch: 5| Step: 8
Training loss: 2.40918136986286
Validation loss: 2.8056703965216183

Epoch: 5| Step: 9
Training loss: 2.261270798249594
Validation loss: 2.8506928092430224

Epoch: 5| Step: 10
Training loss: 2.693137886616756
Validation loss: 2.8143456695935294

Epoch: 587| Step: 0
Training loss: 2.4377762075577745
Validation loss: 2.809307102669242

Epoch: 5| Step: 1
Training loss: 2.1693079206052412
Validation loss: 2.745700925071725

Epoch: 5| Step: 2
Training loss: 1.6090040797957719
Validation loss: 2.85775253462724

Epoch: 5| Step: 3
Training loss: 2.3023456636905646
Validation loss: 2.7751523655349493

Epoch: 5| Step: 4
Training loss: 2.061182699591123
Validation loss: 2.7822195780147427

Epoch: 5| Step: 5
Training loss: 2.2191994440186678
Validation loss: 2.717317191602001

Epoch: 5| Step: 6
Training loss: 1.8286611960720147
Validation loss: 2.8293665081109403

Epoch: 5| Step: 7
Training loss: 1.5272789670663995
Validation loss: 2.8292248040685077

Epoch: 5| Step: 8
Training loss: 1.2563836173742269
Validation loss: 2.813585327641636

Epoch: 5| Step: 9
Training loss: 1.7736628721101362
Validation loss: 2.7912867389639544

Epoch: 5| Step: 10
Training loss: 1.7247415321320272
Validation loss: 2.7089654016121982

Epoch: 588| Step: 0
Training loss: 2.0482072062054666
Validation loss: 2.805048706074613

Epoch: 5| Step: 1
Training loss: 1.2838476875972207
Validation loss: 2.721866180129477

Epoch: 5| Step: 2
Training loss: 2.1616430977286716
Validation loss: 2.7500310208089607

Epoch: 5| Step: 3
Training loss: 2.1806083019488667
Validation loss: 2.714746686454871

Epoch: 5| Step: 4
Training loss: 1.5647774692311687
Validation loss: 2.7040284758489066

Epoch: 5| Step: 5
Training loss: 2.1886032592104963
Validation loss: 2.7703379505019936

Epoch: 5| Step: 6
Training loss: 1.6602534007649516
Validation loss: 2.755359995263492

Epoch: 5| Step: 7
Training loss: 1.996822873481389
Validation loss: 2.840548142906986

Epoch: 5| Step: 8
Training loss: 1.79337188244386
Validation loss: 2.7045684039240387

Epoch: 5| Step: 9
Training loss: 2.8589582295843883
Validation loss: 2.674277225438269

Epoch: 5| Step: 10
Training loss: 1.9929635125977034
Validation loss: 2.829767838132962

Epoch: 589| Step: 0
Training loss: 1.7848446363266397
Validation loss: 2.7697138380235526

Epoch: 5| Step: 1
Training loss: 1.6866390716546995
Validation loss: 2.797930889096392

Epoch: 5| Step: 2
Training loss: 2.2893579702449487
Validation loss: 2.708351149078409

Epoch: 5| Step: 3
Training loss: 2.357667823230674
Validation loss: 2.7312073560429493

Epoch: 5| Step: 4
Training loss: 1.8503295398733517
Validation loss: 2.7435403581230626

Epoch: 5| Step: 5
Training loss: 1.8737514153310406
Validation loss: 2.7644369100422876

Epoch: 5| Step: 6
Training loss: 2.1595051837990527
Validation loss: 2.71771761319585

Epoch: 5| Step: 7
Training loss: 1.7034899119444282
Validation loss: 2.6758547517785995

Epoch: 5| Step: 8
Training loss: 2.5035582968672787
Validation loss: 2.791821065192154

Epoch: 5| Step: 9
Training loss: 1.7004558400872731
Validation loss: 2.7662222242721946

Epoch: 5| Step: 10
Training loss: 1.5657860343790728
Validation loss: 2.8168186114965676

Epoch: 590| Step: 0
Training loss: 1.8717464192701256
Validation loss: 2.7800726394742017

Epoch: 5| Step: 1
Training loss: 2.258057683283932
Validation loss: 2.701684573096349

Epoch: 5| Step: 2
Training loss: 1.8377557070563975
Validation loss: 2.809635880712339

Epoch: 5| Step: 3
Training loss: 1.2828649252286213
Validation loss: 2.77139373399594

Epoch: 5| Step: 4
Training loss: 1.6955540919988494
Validation loss: 2.8135735407857694

Epoch: 5| Step: 5
Training loss: 2.4945462822274522
Validation loss: 2.7663155230097676

Epoch: 5| Step: 6
Training loss: 1.7100573501116203
Validation loss: 2.7568001232058723

Epoch: 5| Step: 7
Training loss: 2.050272676894852
Validation loss: 2.860214049326936

Epoch: 5| Step: 8
Training loss: 2.029934618606385
Validation loss: 2.774316387158877

Epoch: 5| Step: 9
Training loss: 2.0359552905226885
Validation loss: 2.7814505351434393

Epoch: 5| Step: 10
Training loss: 2.480768621145502
Validation loss: 2.7691507670397444

Epoch: 591| Step: 0
Training loss: 1.906976092524263
Validation loss: 2.7806182610265298

Epoch: 5| Step: 1
Training loss: 2.4078657002051855
Validation loss: 2.773428663152759

Epoch: 5| Step: 2
Training loss: 1.6120677753143728
Validation loss: 2.7790866820433413

Epoch: 5| Step: 3
Training loss: 1.3010815797806714
Validation loss: 2.805900401730632

Epoch: 5| Step: 4
Training loss: 1.9218722087560713
Validation loss: 2.7867383682596882

Epoch: 5| Step: 5
Training loss: 1.8044171151405064
Validation loss: 2.8391105681603177

Epoch: 5| Step: 6
Training loss: 2.1009211926648
Validation loss: 2.709085764775548

Epoch: 5| Step: 7
Training loss: 2.5097345610006068
Validation loss: 2.7571183847856457

Epoch: 5| Step: 8
Training loss: 2.093746697722151
Validation loss: 2.809440695375392

Epoch: 5| Step: 9
Training loss: 1.9077583973904348
Validation loss: 2.7897661548061836

Epoch: 5| Step: 10
Training loss: 1.8347701886619578
Validation loss: 2.797091225191005

Epoch: 592| Step: 0
Training loss: 1.5726804576968216
Validation loss: 2.7515002919083633

Epoch: 5| Step: 1
Training loss: 2.619515365884635
Validation loss: 2.7016816533156396

Epoch: 5| Step: 2
Training loss: 2.128668143579624
Validation loss: 2.754566204721206

Epoch: 5| Step: 3
Training loss: 1.952799167157175
Validation loss: 2.76979350630758

Epoch: 5| Step: 4
Training loss: 1.5076270112894892
Validation loss: 2.7042809875866918

Epoch: 5| Step: 5
Training loss: 1.606944127890115
Validation loss: 2.6886211974522487

Epoch: 5| Step: 6
Training loss: 2.1694531007345197
Validation loss: 2.7602617483071774

Epoch: 5| Step: 7
Training loss: 2.0138102797443347
Validation loss: 2.7533623955378257

Epoch: 5| Step: 8
Training loss: 2.0306712573211003
Validation loss: 2.7537517591837464

Epoch: 5| Step: 9
Training loss: 2.048294507003486
Validation loss: 2.7133263489987387

Epoch: 5| Step: 10
Training loss: 1.8587117013788808
Validation loss: 2.7617961078279407

Epoch: 593| Step: 0
Training loss: 1.7622886801576847
Validation loss: 2.7060803403193665

Epoch: 5| Step: 1
Training loss: 2.1198859666349144
Validation loss: 2.7833679032998893

Epoch: 5| Step: 2
Training loss: 1.5110559710948408
Validation loss: 2.746318580088197

Epoch: 5| Step: 3
Training loss: 1.9850502367172624
Validation loss: 2.7415766484819857

Epoch: 5| Step: 4
Training loss: 2.658059345423869
Validation loss: 2.8380886601868816

Epoch: 5| Step: 5
Training loss: 2.1858328869909234
Validation loss: 2.7524464987079815

Epoch: 5| Step: 6
Training loss: 2.134016430785286
Validation loss: 2.74991108591196

Epoch: 5| Step: 7
Training loss: 2.079864691588119
Validation loss: 2.7520693938248106

Epoch: 5| Step: 8
Training loss: 2.384826009549794
Validation loss: 2.765924393846573

Epoch: 5| Step: 9
Training loss: 1.4261959779155478
Validation loss: 2.8421686087577314

Epoch: 5| Step: 10
Training loss: 1.6952477368057146
Validation loss: 2.79276594749035

Epoch: 594| Step: 0
Training loss: 1.7069187432756223
Validation loss: 2.7844226343120404

Epoch: 5| Step: 1
Training loss: 1.7455604643455578
Validation loss: 2.734475734279089

Epoch: 5| Step: 2
Training loss: 1.6073812338232545
Validation loss: 2.8229791090723944

Epoch: 5| Step: 3
Training loss: 2.061790228584322
Validation loss: 2.7823976483492947

Epoch: 5| Step: 4
Training loss: 2.3938176397025064
Validation loss: 2.7251808593059685

Epoch: 5| Step: 5
Training loss: 2.580562110110544
Validation loss: 2.8626300017588133

Epoch: 5| Step: 6
Training loss: 1.4803081817918302
Validation loss: 2.847605062364786

Epoch: 5| Step: 7
Training loss: 2.2578151399273603
Validation loss: 2.689415858604053

Epoch: 5| Step: 8
Training loss: 1.83334901831882
Validation loss: 2.7103430328565863

Epoch: 5| Step: 9
Training loss: 2.0267229544619725
Validation loss: 2.8463686344760135

Epoch: 5| Step: 10
Training loss: 1.7921639425098015
Validation loss: 2.7125889236892653

Epoch: 595| Step: 0
Training loss: 1.9606117494699005
Validation loss: 2.7971563435474143

Epoch: 5| Step: 1
Training loss: 2.118160573165925
Validation loss: 2.835552049603213

Epoch: 5| Step: 2
Training loss: 2.119365064979605
Validation loss: 2.804868530204263

Epoch: 5| Step: 3
Training loss: 1.0352849340525576
Validation loss: 2.78106427883226

Epoch: 5| Step: 4
Training loss: 2.2519858391826424
Validation loss: 2.8244170385360046

Epoch: 5| Step: 5
Training loss: 2.0174743684750034
Validation loss: 2.738830311943724

Epoch: 5| Step: 6
Training loss: 1.8190829991409605
Validation loss: 2.7389835440513455

Epoch: 5| Step: 7
Training loss: 2.2024392217245463
Validation loss: 2.767483065237163

Epoch: 5| Step: 8
Training loss: 1.82715267831299
Validation loss: 2.7582104882127987

Epoch: 5| Step: 9
Training loss: 1.5784880720913734
Validation loss: 2.7575751407601663

Epoch: 5| Step: 10
Training loss: 1.9456027017474238
Validation loss: 2.7463485661863682

Epoch: 596| Step: 0
Training loss: 1.4950345027093461
Validation loss: 2.8102689199961235

Epoch: 5| Step: 1
Training loss: 1.8789997672364567
Validation loss: 2.777770535927907

Epoch: 5| Step: 2
Training loss: 1.6569619717789636
Validation loss: 2.796271026985689

Epoch: 5| Step: 3
Training loss: 1.5231094398376817
Validation loss: 2.7760934132080783

Epoch: 5| Step: 4
Training loss: 1.7770741687939344
Validation loss: 2.7402131116179476

Epoch: 5| Step: 5
Training loss: 2.0564902631926563
Validation loss: 2.8051018748284497

Epoch: 5| Step: 6
Training loss: 2.6924891625543106
Validation loss: 2.7514172861027855

Epoch: 5| Step: 7
Training loss: 2.1093824598392397
Validation loss: 2.7517264708824167

Epoch: 5| Step: 8
Training loss: 2.000505860251205
Validation loss: 2.8444967135818087

Epoch: 5| Step: 9
Training loss: 2.2235590437093897
Validation loss: 2.8331830752762395

Epoch: 5| Step: 10
Training loss: 1.9102704534734913
Validation loss: 2.7109731721672117

Epoch: 597| Step: 0
Training loss: 1.3156807821956806
Validation loss: 2.812746683876411

Epoch: 5| Step: 1
Training loss: 2.143360700931907
Validation loss: 2.755462596292657

Epoch: 5| Step: 2
Training loss: 1.50241744425562
Validation loss: 2.8164483534114826

Epoch: 5| Step: 3
Training loss: 1.9624754813053669
Validation loss: 2.777668799515188

Epoch: 5| Step: 4
Training loss: 1.6687115839847526
Validation loss: 2.7256156955122277

Epoch: 5| Step: 5
Training loss: 1.630580270606259
Validation loss: 2.791265339136072

Epoch: 5| Step: 6
Training loss: 2.0948157942824226
Validation loss: 2.759494309002683

Epoch: 5| Step: 7
Training loss: 2.005039898292275
Validation loss: 2.7386565802364524

Epoch: 5| Step: 8
Training loss: 1.8971292517009224
Validation loss: 2.7566980741405755

Epoch: 5| Step: 9
Training loss: 2.700200786895445
Validation loss: 2.678970699778914

Epoch: 5| Step: 10
Training loss: 2.346010567546176
Validation loss: 2.748783164908935

Epoch: 598| Step: 0
Training loss: 2.523607844694276
Validation loss: 2.7805778840734203

Epoch: 5| Step: 1
Training loss: 1.6723101753657532
Validation loss: 2.711488368541932

Epoch: 5| Step: 2
Training loss: 1.9150613475166265
Validation loss: 2.7226871030820763

Epoch: 5| Step: 3
Training loss: 1.6991663431438881
Validation loss: 2.79075413297328

Epoch: 5| Step: 4
Training loss: 1.817036705943793
Validation loss: 2.8852394404673163

Epoch: 5| Step: 5
Training loss: 2.18686012718723
Validation loss: 2.7819199252415054

Epoch: 5| Step: 6
Training loss: 1.6939276739306364
Validation loss: 2.729744418330946

Epoch: 5| Step: 7
Training loss: 2.10563758074115
Validation loss: 2.7875873371916065

Epoch: 5| Step: 8
Training loss: 1.8966953777001685
Validation loss: 2.726907001449629

Epoch: 5| Step: 9
Training loss: 2.1234821059459064
Validation loss: 2.837749368294218

Epoch: 5| Step: 10
Training loss: 2.020569053226997
Validation loss: 2.8124028315559264

Epoch: 599| Step: 0
Training loss: 1.9781417267440207
Validation loss: 2.8122732693195847

Epoch: 5| Step: 1
Training loss: 1.829963476931793
Validation loss: 2.7620751047059087

Epoch: 5| Step: 2
Training loss: 2.086641685693808
Validation loss: 2.7865490265053157

Epoch: 5| Step: 3
Training loss: 2.540694055873902
Validation loss: 2.7426387019617073

Epoch: 5| Step: 4
Training loss: 1.775839502308067
Validation loss: 2.7996063562199884

Epoch: 5| Step: 5
Training loss: 1.5367753127548283
Validation loss: 2.7724984829738153

Epoch: 5| Step: 6
Training loss: 1.7734176029652
Validation loss: 2.788761621684878

Epoch: 5| Step: 7
Training loss: 1.7698145759571153
Validation loss: 2.7790325395573023

Epoch: 5| Step: 8
Training loss: 1.9578765444620077
Validation loss: 2.8017853706810065

Epoch: 5| Step: 9
Training loss: 2.172200240338067
Validation loss: 2.7474626337159465

Epoch: 5| Step: 10
Training loss: 1.988669906432407
Validation loss: 2.7181188774693075

Epoch: 600| Step: 0
Training loss: 1.3993153294342113
Validation loss: 2.835760919410447

Epoch: 5| Step: 1
Training loss: 2.703582195801179
Validation loss: 2.857754370955134

Epoch: 5| Step: 2
Training loss: 2.4377670141836556
Validation loss: 2.748158901341634

Epoch: 5| Step: 3
Training loss: 2.059104552042925
Validation loss: 2.8004482311177634

Epoch: 5| Step: 4
Training loss: 2.055427563036077
Validation loss: 2.718189046318708

Epoch: 5| Step: 5
Training loss: 1.6847191255601623
Validation loss: 2.6615391555579535

Epoch: 5| Step: 6
Training loss: 2.1914980728033018
Validation loss: 2.7743769827935987

Epoch: 5| Step: 7
Training loss: 1.7590892986642404
Validation loss: 2.7101126074223076

Epoch: 5| Step: 8
Training loss: 1.647352829005129
Validation loss: 2.7860898424101626

Epoch: 5| Step: 9
Training loss: 1.334729814369996
Validation loss: 2.7930688882676464

Epoch: 5| Step: 10
Training loss: 2.311897302392626
Validation loss: 2.731472273602647

Epoch: 601| Step: 0
Training loss: 2.4027142991027444
Validation loss: 2.6991680858714084

Epoch: 5| Step: 1
Training loss: 1.855501258966856
Validation loss: 2.749245896333742

Epoch: 5| Step: 2
Training loss: 2.058415269443528
Validation loss: 2.8095020700774813

Epoch: 5| Step: 3
Training loss: 1.4968758473563135
Validation loss: 2.824811645321092

Epoch: 5| Step: 4
Training loss: 2.252517774979616
Validation loss: 2.751570687463478

Epoch: 5| Step: 5
Training loss: 2.16111383718511
Validation loss: 2.747428616633988

Epoch: 5| Step: 6
Training loss: 1.3799988305736508
Validation loss: 2.8473578474702608

Epoch: 5| Step: 7
Training loss: 2.03406388442578
Validation loss: 2.750308156576903

Epoch: 5| Step: 8
Training loss: 1.659989005247726
Validation loss: 2.785311675491539

Epoch: 5| Step: 9
Training loss: 1.4982011658392687
Validation loss: 2.742841810506728

Epoch: 5| Step: 10
Training loss: 2.2986988948515843
Validation loss: 2.78877783582155

Epoch: 602| Step: 0
Training loss: 2.39129609306328
Validation loss: 2.745269158201247

Epoch: 5| Step: 1
Training loss: 1.57903845005681
Validation loss: 2.7466192878484175

Epoch: 5| Step: 2
Training loss: 1.584433081651391
Validation loss: 2.7377690687078444

Epoch: 5| Step: 3
Training loss: 1.491472882020771
Validation loss: 2.7429988093174895

Epoch: 5| Step: 4
Training loss: 1.9288890592196068
Validation loss: 2.7552327174508373

Epoch: 5| Step: 5
Training loss: 1.7540289956961714
Validation loss: 2.8188008016363906

Epoch: 5| Step: 6
Training loss: 2.453976623050736
Validation loss: 2.7653510804647783

Epoch: 5| Step: 7
Training loss: 1.9030953866944096
Validation loss: 2.7935870316291758

Epoch: 5| Step: 8
Training loss: 2.4810279996707307
Validation loss: 2.7899764344952827

Epoch: 5| Step: 9
Training loss: 1.56421803435638
Validation loss: 2.7880637517536693

Epoch: 5| Step: 10
Training loss: 1.5387742600438223
Validation loss: 2.7112300883119453

Epoch: 603| Step: 0
Training loss: 2.303046311337292
Validation loss: 2.789854541176627

Epoch: 5| Step: 1
Training loss: 1.738416070746033
Validation loss: 2.7332130168792945

Epoch: 5| Step: 2
Training loss: 2.28605021409414
Validation loss: 2.8173158094081856

Epoch: 5| Step: 3
Training loss: 2.2954899770575623
Validation loss: 2.6585778109472575

Epoch: 5| Step: 4
Training loss: 1.8240439353679136
Validation loss: 2.783879054081338

Epoch: 5| Step: 5
Training loss: 2.1849022836025416
Validation loss: 2.7536057719576985

Epoch: 5| Step: 6
Training loss: 1.2873371947230765
Validation loss: 2.7033974299636148

Epoch: 5| Step: 7
Training loss: 1.59904870721185
Validation loss: 2.7308980007076955

Epoch: 5| Step: 8
Training loss: 2.009159334038299
Validation loss: 2.7802043376457384

Epoch: 5| Step: 9
Training loss: 1.8269510656985066
Validation loss: 2.8015006788074333

Epoch: 5| Step: 10
Training loss: 2.260758533789446
Validation loss: 2.772938253486132

Epoch: 604| Step: 0
Training loss: 1.7760320161648626
Validation loss: 2.799496297972284

Epoch: 5| Step: 1
Training loss: 2.3707294215630963
Validation loss: 2.8530522622948475

Epoch: 5| Step: 2
Training loss: 1.7523599788001016
Validation loss: 2.761762597755223

Epoch: 5| Step: 3
Training loss: 1.8167091691297743
Validation loss: 2.7675754183152157

Epoch: 5| Step: 4
Training loss: 2.111111074860333
Validation loss: 2.726340355852771

Epoch: 5| Step: 5
Training loss: 1.9815146789892641
Validation loss: 2.8110653261403993

Epoch: 5| Step: 6
Training loss: 1.1864455711654087
Validation loss: 2.8135974816460805

Epoch: 5| Step: 7
Training loss: 2.0345120572801387
Validation loss: 2.7290460697204595

Epoch: 5| Step: 8
Training loss: 2.463559549171327
Validation loss: 2.83810564846699

Epoch: 5| Step: 9
Training loss: 1.5115648137063644
Validation loss: 2.754234662208803

Epoch: 5| Step: 10
Training loss: 1.8753645224682503
Validation loss: 2.791520440121722

Epoch: 605| Step: 0
Training loss: 1.9493704146282036
Validation loss: 2.8197825362288094

Epoch: 5| Step: 1
Training loss: 1.9534316165574894
Validation loss: 2.80465263038586

Epoch: 5| Step: 2
Training loss: 1.9252508024841388
Validation loss: 2.820694737828401

Epoch: 5| Step: 3
Training loss: 1.773177073174253
Validation loss: 2.725307321543389

Epoch: 5| Step: 4
Training loss: 1.7849365366277923
Validation loss: 2.8523542621211546

Epoch: 5| Step: 5
Training loss: 2.03944562915359
Validation loss: 2.879312013340029

Epoch: 5| Step: 6
Training loss: 2.186490070996529
Validation loss: 2.7475456535586757

Epoch: 5| Step: 7
Training loss: 2.4624085888621727
Validation loss: 2.75724126879442

Epoch: 5| Step: 8
Training loss: 1.7801208263278911
Validation loss: 2.777842747396796

Epoch: 5| Step: 9
Training loss: 1.393112272783744
Validation loss: 2.727911346635407

Epoch: 5| Step: 10
Training loss: 1.90795334554609
Validation loss: 2.780011273483184

Epoch: 606| Step: 0
Training loss: 2.336953647021617
Validation loss: 2.7925367681442985

Epoch: 5| Step: 1
Training loss: 1.4796375366927652
Validation loss: 2.7603126136329497

Epoch: 5| Step: 2
Training loss: 1.200484263538206
Validation loss: 2.7416459542048237

Epoch: 5| Step: 3
Training loss: 1.6747325826087407
Validation loss: 2.745169367237957

Epoch: 5| Step: 4
Training loss: 2.2442737403745157
Validation loss: 2.7711293172457663

Epoch: 5| Step: 5
Training loss: 2.1614426822938313
Validation loss: 2.779213261772172

Epoch: 5| Step: 6
Training loss: 1.7920029642472273
Validation loss: 2.72584431665582

Epoch: 5| Step: 7
Training loss: 2.2338130217522463
Validation loss: 2.710861224367779

Epoch: 5| Step: 8
Training loss: 2.4295142010770103
Validation loss: 2.7850995763538164

Epoch: 5| Step: 9
Training loss: 1.7615329280724075
Validation loss: 2.7758330690989497

Epoch: 5| Step: 10
Training loss: 1.937528425438849
Validation loss: 2.725826018340207

Epoch: 607| Step: 0
Training loss: 2.078895254009286
Validation loss: 2.8207220201115217

Epoch: 5| Step: 1
Training loss: 2.175554410933931
Validation loss: 2.735079742416156

Epoch: 5| Step: 2
Training loss: 1.6667940885790073
Validation loss: 2.800572283224407

Epoch: 5| Step: 3
Training loss: 2.025309400116123
Validation loss: 2.7659384562182465

Epoch: 5| Step: 4
Training loss: 2.2610903906387008
Validation loss: 2.796729395629285

Epoch: 5| Step: 5
Training loss: 1.8127111114678245
Validation loss: 2.760183145618028

Epoch: 5| Step: 6
Training loss: 1.60414272967558
Validation loss: 2.755700226803466

Epoch: 5| Step: 7
Training loss: 2.280905188015295
Validation loss: 2.7597573444682397

Epoch: 5| Step: 8
Training loss: 2.040630337064111
Validation loss: 2.834544669957052

Epoch: 5| Step: 9
Training loss: 1.8036419370430892
Validation loss: 2.705699853500352

Epoch: 5| Step: 10
Training loss: 1.5812665433357522
Validation loss: 2.860065187057977

Epoch: 608| Step: 0
Training loss: 1.7091697723097588
Validation loss: 2.765561385292414

Epoch: 5| Step: 1
Training loss: 1.8421166507469353
Validation loss: 2.7863537171975117

Epoch: 5| Step: 2
Training loss: 1.95605736902275
Validation loss: 2.7245966047979433

Epoch: 5| Step: 3
Training loss: 2.1141781974761717
Validation loss: 2.8041041346770914

Epoch: 5| Step: 4
Training loss: 2.4076730062686558
Validation loss: 2.742452823590127

Epoch: 5| Step: 5
Training loss: 1.8204237613319991
Validation loss: 2.772173024193644

Epoch: 5| Step: 6
Training loss: 1.511873774502381
Validation loss: 2.722142826823025

Epoch: 5| Step: 7
Training loss: 1.8166279319110084
Validation loss: 2.750757421669502

Epoch: 5| Step: 8
Training loss: 1.8106366148666002
Validation loss: 2.8027240700532476

Epoch: 5| Step: 9
Training loss: 1.588547386617733
Validation loss: 2.748333863923626

Epoch: 5| Step: 10
Training loss: 2.8156865188364235
Validation loss: 2.8047887956531175

Epoch: 609| Step: 0
Training loss: 2.1109567998516323
Validation loss: 2.7443283769459286

Epoch: 5| Step: 1
Training loss: 1.8176830111454962
Validation loss: 2.812482393088883

Epoch: 5| Step: 2
Training loss: 1.7237082662087746
Validation loss: 2.7967376345272377

Epoch: 5| Step: 3
Training loss: 1.7073046292954708
Validation loss: 2.7482501752677497

Epoch: 5| Step: 4
Training loss: 2.3073480282021372
Validation loss: 2.7757477357191993

Epoch: 5| Step: 5
Training loss: 1.9422546006854167
Validation loss: 2.7942273923368433

Epoch: 5| Step: 6
Training loss: 2.340528181082824
Validation loss: 2.8415233608283335

Epoch: 5| Step: 7
Training loss: 2.074464715142226
Validation loss: 2.7871856647968016

Epoch: 5| Step: 8
Training loss: 1.3664357761793906
Validation loss: 2.736646357992512

Epoch: 5| Step: 9
Training loss: 1.5747031704167787
Validation loss: 2.791433064845655

Epoch: 5| Step: 10
Training loss: 1.9552257988918056
Validation loss: 2.8572781968217686

Epoch: 610| Step: 0
Training loss: 1.9166788086990325
Validation loss: 2.7400431501917377

Epoch: 5| Step: 1
Training loss: 1.7425256922618815
Validation loss: 2.768510060210121

Epoch: 5| Step: 2
Training loss: 2.512118721495111
Validation loss: 2.756867894527415

Epoch: 5| Step: 3
Training loss: 2.2767534226977926
Validation loss: 2.726042568434801

Epoch: 5| Step: 4
Training loss: 1.9552233601072118
Validation loss: 2.745657939395323

Epoch: 5| Step: 5
Training loss: 1.8500997825725112
Validation loss: 2.8264274862276557

Epoch: 5| Step: 6
Training loss: 2.4034118758906304
Validation loss: 2.704603402739594

Epoch: 5| Step: 7
Training loss: 1.6320754582547272
Validation loss: 2.7748137781387063

Epoch: 5| Step: 8
Training loss: 1.0826981895626833
Validation loss: 2.749819552932837

Epoch: 5| Step: 9
Training loss: 2.028361217690565
Validation loss: 2.752596655621077

Epoch: 5| Step: 10
Training loss: 1.967724245275322
Validation loss: 2.731105800955929

Epoch: 611| Step: 0
Training loss: 1.9494263685575848
Validation loss: 2.7387336103477113

Epoch: 5| Step: 1
Training loss: 2.0799502051335175
Validation loss: 2.6876224376416453

Epoch: 5| Step: 2
Training loss: 2.2656636201921194
Validation loss: 2.7445472997206495

Epoch: 5| Step: 3
Training loss: 1.6393935895557359
Validation loss: 2.818114952708991

Epoch: 5| Step: 4
Training loss: 2.0122957161473196
Validation loss: 2.8163135338022864

Epoch: 5| Step: 5
Training loss: 1.6837627565032367
Validation loss: 2.800397530878782

Epoch: 5| Step: 6
Training loss: 1.6067010832433597
Validation loss: 2.7689601707962694

Epoch: 5| Step: 7
Training loss: 1.612474438368587
Validation loss: 2.7608284731118786

Epoch: 5| Step: 8
Training loss: 1.739753562532207
Validation loss: 2.819363735773506

Epoch: 5| Step: 9
Training loss: 1.81917277662597
Validation loss: 2.7680406279432956

Epoch: 5| Step: 10
Training loss: 2.90582058923361
Validation loss: 2.7769393653041696

Epoch: 612| Step: 0
Training loss: 2.4406560370783312
Validation loss: 2.7506688163267006

Epoch: 5| Step: 1
Training loss: 1.7832846816131938
Validation loss: 2.880003575708193

Epoch: 5| Step: 2
Training loss: 1.7918429029269087
Validation loss: 2.796523438209911

Epoch: 5| Step: 3
Training loss: 2.288459047317382
Validation loss: 2.7619748739468184

Epoch: 5| Step: 4
Training loss: 1.7667009569235135
Validation loss: 2.7608787021473904

Epoch: 5| Step: 5
Training loss: 2.212409941138881
Validation loss: 2.8118399571350707

Epoch: 5| Step: 6
Training loss: 1.901910689486357
Validation loss: 2.732673406683718

Epoch: 5| Step: 7
Training loss: 1.852358940509499
Validation loss: 2.835064197050785

Epoch: 5| Step: 8
Training loss: 1.2226335322307873
Validation loss: 2.783045888653539

Epoch: 5| Step: 9
Training loss: 1.7057558790449718
Validation loss: 2.768731137614706

Epoch: 5| Step: 10
Training loss: 2.203141773782278
Validation loss: 2.8240379707151613

Epoch: 613| Step: 0
Training loss: 1.4232849005797763
Validation loss: 2.6821382384121275

Epoch: 5| Step: 1
Training loss: 2.141781014483382
Validation loss: 2.7624422083559494

Epoch: 5| Step: 2
Training loss: 1.5420204821956764
Validation loss: 2.765268733782028

Epoch: 5| Step: 3
Training loss: 1.665379679007236
Validation loss: 2.7415392050643854

Epoch: 5| Step: 4
Training loss: 1.9644104496873096
Validation loss: 2.7215179405069536

Epoch: 5| Step: 5
Training loss: 2.3567514548725637
Validation loss: 2.8179859960710782

Epoch: 5| Step: 6
Training loss: 2.2423871845288796
Validation loss: 2.7433858129459985

Epoch: 5| Step: 7
Training loss: 1.5988568782201427
Validation loss: 2.722558749815617

Epoch: 5| Step: 8
Training loss: 2.309207118311129
Validation loss: 2.6954914239909855

Epoch: 5| Step: 9
Training loss: 2.0985382896640306
Validation loss: 2.7822007290313997

Epoch: 5| Step: 10
Training loss: 2.0483919303009546
Validation loss: 2.744354239966106

Epoch: 614| Step: 0
Training loss: 2.327423911812607
Validation loss: 2.7492559699903336

Epoch: 5| Step: 1
Training loss: 2.056772892566873
Validation loss: 2.7869170853878797

Epoch: 5| Step: 2
Training loss: 1.85010654812788
Validation loss: 2.6724439062197973

Epoch: 5| Step: 3
Training loss: 2.0818794009031323
Validation loss: 2.7990356338160622

Epoch: 5| Step: 4
Training loss: 2.537335462826216
Validation loss: 2.8306069681335844

Epoch: 5| Step: 5
Training loss: 1.9742965676867206
Validation loss: 2.7497132926559607

Epoch: 5| Step: 6
Training loss: 1.659227681490228
Validation loss: 2.7290846398927227

Epoch: 5| Step: 7
Training loss: 1.4323757724921335
Validation loss: 2.830136704229806

Epoch: 5| Step: 8
Training loss: 1.5238556116945492
Validation loss: 2.7915992220532813

Epoch: 5| Step: 9
Training loss: 1.9166826648320912
Validation loss: 2.7889978976908463

Epoch: 5| Step: 10
Training loss: 1.9418240563886957
Validation loss: 2.769551554248673

Epoch: 615| Step: 0
Training loss: 1.2093682242112502
Validation loss: 2.757853386874595

Epoch: 5| Step: 1
Training loss: 1.7381252947508374
Validation loss: 2.6382440020467244

Epoch: 5| Step: 2
Training loss: 2.1402944045012715
Validation loss: 2.758847083213861

Epoch: 5| Step: 3
Training loss: 2.1463480828901043
Validation loss: 2.8221864001325834

Epoch: 5| Step: 4
Training loss: 1.9579207479474035
Validation loss: 2.6634685583339603

Epoch: 5| Step: 5
Training loss: 2.0508577459691493
Validation loss: 2.7586065083167677

Epoch: 5| Step: 6
Training loss: 1.69960989122464
Validation loss: 2.7371312523366997

Epoch: 5| Step: 7
Training loss: 1.7538729454225876
Validation loss: 2.8140229343877574

Epoch: 5| Step: 8
Training loss: 1.9472726651507326
Validation loss: 2.7329524170476476

Epoch: 5| Step: 9
Training loss: 2.086324020178863
Validation loss: 2.7547606506084885

Epoch: 5| Step: 10
Training loss: 1.5552697553043737
Validation loss: 2.7638021683860052

Epoch: 616| Step: 0
Training loss: 1.6809964070278895
Validation loss: 2.7971279185525644

Epoch: 5| Step: 1
Training loss: 1.4832315960116365
Validation loss: 2.760648046645728

Epoch: 5| Step: 2
Training loss: 1.8606672524756878
Validation loss: 2.772886690139363

Epoch: 5| Step: 3
Training loss: 2.130892269954045
Validation loss: 2.7643480244360426

Epoch: 5| Step: 4
Training loss: 1.6650706358122658
Validation loss: 2.782601102416908

Epoch: 5| Step: 5
Training loss: 1.5888438536672065
Validation loss: 2.7938285710601356

Epoch: 5| Step: 6
Training loss: 2.634159094672788
Validation loss: 2.764258251208888

Epoch: 5| Step: 7
Training loss: 1.588409451678515
Validation loss: 2.812476672368628

Epoch: 5| Step: 8
Training loss: 1.9864102236905212
Validation loss: 2.8184643361041157

Epoch: 5| Step: 9
Training loss: 1.6589131087806048
Validation loss: 2.814024970524236

Epoch: 5| Step: 10
Training loss: 2.00947401120213
Validation loss: 2.802039229370743

Epoch: 617| Step: 0
Training loss: 1.4348925286432095
Validation loss: 2.8332094482709276

Epoch: 5| Step: 1
Training loss: 1.5898877636864797
Validation loss: 2.716780876714774

Epoch: 5| Step: 2
Training loss: 2.403429831032675
Validation loss: 2.6875440427467536

Epoch: 5| Step: 3
Training loss: 2.4166581603152646
Validation loss: 2.7115513538425824

Epoch: 5| Step: 4
Training loss: 1.4555956438641466
Validation loss: 2.7661567419204434

Epoch: 5| Step: 5
Training loss: 1.7869728911765979
Validation loss: 2.7280259581007376

Epoch: 5| Step: 6
Training loss: 1.9763746813170138
Validation loss: 2.820777567253176

Epoch: 5| Step: 7
Training loss: 1.811106836993915
Validation loss: 2.775104815207051

Epoch: 5| Step: 8
Training loss: 2.5681155012841206
Validation loss: 2.774056075892673

Epoch: 5| Step: 9
Training loss: 1.5057564587683356
Validation loss: 2.8216860959953776

Epoch: 5| Step: 10
Training loss: 1.5605513819699859
Validation loss: 2.7713888090967083

Epoch: 618| Step: 0
Training loss: 2.3739890908534544
Validation loss: 2.81874688355714

Epoch: 5| Step: 1
Training loss: 1.669806368218342
Validation loss: 2.8201579944497115

Epoch: 5| Step: 2
Training loss: 1.555512789108099
Validation loss: 2.8458053029206134

Epoch: 5| Step: 3
Training loss: 2.4242248948142593
Validation loss: 2.769089677459879

Epoch: 5| Step: 4
Training loss: 1.5835731057099731
Validation loss: 2.7414991016450245

Epoch: 5| Step: 5
Training loss: 1.875814006857816
Validation loss: 2.7952580909191598

Epoch: 5| Step: 6
Training loss: 2.063153481273868
Validation loss: 2.748277863284916

Epoch: 5| Step: 7
Training loss: 2.180602507143137
Validation loss: 2.7682859646685265

Epoch: 5| Step: 8
Training loss: 1.8805509415380064
Validation loss: 2.7337947237945195

Epoch: 5| Step: 9
Training loss: 1.8907109390777628
Validation loss: 2.774167278339026

Epoch: 5| Step: 10
Training loss: 1.451437185275861
Validation loss: 2.8070559718428094

Epoch: 619| Step: 0
Training loss: 1.7491836005934898
Validation loss: 2.8397700015010354

Epoch: 5| Step: 1
Training loss: 1.5751796468581285
Validation loss: 2.7780596713796446

Epoch: 5| Step: 2
Training loss: 2.115877203509701
Validation loss: 2.767856804881863

Epoch: 5| Step: 3
Training loss: 1.5185758828404263
Validation loss: 2.8512140038338467

Epoch: 5| Step: 4
Training loss: 1.954417724044792
Validation loss: 2.7300831150683456

Epoch: 5| Step: 5
Training loss: 2.0973397980574404
Validation loss: 2.802082880760187

Epoch: 5| Step: 6
Training loss: 2.7133717450165307
Validation loss: 2.714765904153654

Epoch: 5| Step: 7
Training loss: 1.9500460350275854
Validation loss: 2.823564388283759

Epoch: 5| Step: 8
Training loss: 2.0412154834489735
Validation loss: 2.7078048774208585

Epoch: 5| Step: 9
Training loss: 1.6168868665403506
Validation loss: 2.7842619762313148

Epoch: 5| Step: 10
Training loss: 1.6452278600877408
Validation loss: 2.7097162532269885

Epoch: 620| Step: 0
Training loss: 1.2235886793405402
Validation loss: 2.8039329853691357

Epoch: 5| Step: 1
Training loss: 1.9339116615428662
Validation loss: 2.7296783346808398

Epoch: 5| Step: 2
Training loss: 1.699885796469521
Validation loss: 2.762396129221301

Epoch: 5| Step: 3
Training loss: 2.713876411941187
Validation loss: 2.6673471238931348

Epoch: 5| Step: 4
Training loss: 1.9812816027699058
Validation loss: 2.781556397747353

Epoch: 5| Step: 5
Training loss: 2.355156873106787
Validation loss: 2.786829725388046

Epoch: 5| Step: 6
Training loss: 1.9451743693507157
Validation loss: 2.7919726065611625

Epoch: 5| Step: 7
Training loss: 1.4938908785861178
Validation loss: 2.7780648188479886

Epoch: 5| Step: 8
Training loss: 1.6418654339253558
Validation loss: 2.7835086400225304

Epoch: 5| Step: 9
Training loss: 1.8144495772048872
Validation loss: 2.7852507673311315

Epoch: 5| Step: 10
Training loss: 2.178299875778337
Validation loss: 2.779998906245193

Epoch: 621| Step: 0
Training loss: 1.2493737082310115
Validation loss: 2.727395042901778

Epoch: 5| Step: 1
Training loss: 1.5441982344426701
Validation loss: 2.8113232218734625

Epoch: 5| Step: 2
Training loss: 1.990507307421052
Validation loss: 2.7811637718491555

Epoch: 5| Step: 3
Training loss: 1.3339065819505624
Validation loss: 2.782583704328096

Epoch: 5| Step: 4
Training loss: 1.593171482178804
Validation loss: 2.757686287325911

Epoch: 5| Step: 5
Training loss: 2.0143590692499154
Validation loss: 2.742151994559773

Epoch: 5| Step: 6
Training loss: 2.053400136781582
Validation loss: 2.8038456828285314

Epoch: 5| Step: 7
Training loss: 2.9103219004343743
Validation loss: 2.8083063843719014

Epoch: 5| Step: 8
Training loss: 2.259630151378873
Validation loss: 2.7358642441632006

Epoch: 5| Step: 9
Training loss: 2.20704280884003
Validation loss: 2.8044335784531724

Epoch: 5| Step: 10
Training loss: 0.72459917498296
Validation loss: 2.754821479107839

Epoch: 622| Step: 0
Training loss: 2.0333289438210724
Validation loss: 2.6929893684186332

Epoch: 5| Step: 1
Training loss: 1.8254882838621074
Validation loss: 2.768962277103283

Epoch: 5| Step: 2
Training loss: 1.5626682953798923
Validation loss: 2.754595197814369

Epoch: 5| Step: 3
Training loss: 1.870218920617358
Validation loss: 2.7443955889044354

Epoch: 5| Step: 4
Training loss: 1.9496273613942534
Validation loss: 2.7892241177935584

Epoch: 5| Step: 5
Training loss: 1.65914922352845
Validation loss: 2.739350531771355

Epoch: 5| Step: 6
Training loss: 1.541956161261783
Validation loss: 2.7951713630612125

Epoch: 5| Step: 7
Training loss: 2.178620107852863
Validation loss: 2.7638715651510934

Epoch: 5| Step: 8
Training loss: 1.9674657841461662
Validation loss: 2.756433261440221

Epoch: 5| Step: 9
Training loss: 1.7061601943531464
Validation loss: 2.7720690574759366

Epoch: 5| Step: 10
Training loss: 2.5303712426219755
Validation loss: 2.7601723492992853

Epoch: 623| Step: 0
Training loss: 1.5100774800715
Validation loss: 2.78377792585675

Epoch: 5| Step: 1
Training loss: 1.863881524278797
Validation loss: 2.763253109031628

Epoch: 5| Step: 2
Training loss: 2.621482854350159
Validation loss: 2.8344336764200984

Epoch: 5| Step: 3
Training loss: 1.6860373480699988
Validation loss: 2.7119633739941023

Epoch: 5| Step: 4
Training loss: 2.0595369729698434
Validation loss: 2.67443711476149

Epoch: 5| Step: 5
Training loss: 2.0602809644033298
Validation loss: 2.7732320822394594

Epoch: 5| Step: 6
Training loss: 1.6660383788653534
Validation loss: 2.75782767973196

Epoch: 5| Step: 7
Training loss: 2.153570417554411
Validation loss: 2.7139721411801663

Epoch: 5| Step: 8
Training loss: 1.3094697212427022
Validation loss: 2.7191663646486326

Epoch: 5| Step: 9
Training loss: 1.7142871135751372
Validation loss: 2.7272635995703425

Epoch: 5| Step: 10
Training loss: 1.8655595905332771
Validation loss: 2.7327320982063488

Epoch: 624| Step: 0
Training loss: 1.627642976425317
Validation loss: 2.7367341152458398

Epoch: 5| Step: 1
Training loss: 1.7514170631376418
Validation loss: 2.7904573250702116

Epoch: 5| Step: 2
Training loss: 1.7136113424155504
Validation loss: 2.854347330771814

Epoch: 5| Step: 3
Training loss: 1.737030676707559
Validation loss: 2.7698584158435198

Epoch: 5| Step: 4
Training loss: 1.8617992465361204
Validation loss: 2.864194061290449

Epoch: 5| Step: 5
Training loss: 1.8571293196341958
Validation loss: 2.826359037657698

Epoch: 5| Step: 6
Training loss: 2.229516248535572
Validation loss: 2.7810550246660206

Epoch: 5| Step: 7
Training loss: 1.7187291230754456
Validation loss: 2.762264938870079

Epoch: 5| Step: 8
Training loss: 1.9197726652543876
Validation loss: 2.7623442925242747

Epoch: 5| Step: 9
Training loss: 1.9990204558096352
Validation loss: 2.738397461774498

Epoch: 5| Step: 10
Training loss: 2.3808426516088734
Validation loss: 2.848743049424372

Epoch: 625| Step: 0
Training loss: 2.2426454295756675
Validation loss: 2.8653132613759253

Epoch: 5| Step: 1
Training loss: 2.6088232496402988
Validation loss: 2.8230205005653466

Epoch: 5| Step: 2
Training loss: 1.8763144653956538
Validation loss: 2.7963639768275055

Epoch: 5| Step: 3
Training loss: 1.6638715034444111
Validation loss: 2.7451109406950183

Epoch: 5| Step: 4
Training loss: 1.5941142993520896
Validation loss: 2.7374890630517332

Epoch: 5| Step: 5
Training loss: 2.1084961367185686
Validation loss: 2.7539565336101797

Epoch: 5| Step: 6
Training loss: 1.5648474797524823
Validation loss: 2.8450152352272946

Epoch: 5| Step: 7
Training loss: 1.7842770337470997
Validation loss: 2.7446580977201864

Epoch: 5| Step: 8
Training loss: 1.5673818998245006
Validation loss: 2.753312286368118

Epoch: 5| Step: 9
Training loss: 1.9125074648243947
Validation loss: 2.7327477479404196

Epoch: 5| Step: 10
Training loss: 1.7464441549490184
Validation loss: 2.709327769500296

Epoch: 626| Step: 0
Training loss: 1.8781443615516804
Validation loss: 2.7644836219245454

Epoch: 5| Step: 1
Training loss: 2.3618674344711086
Validation loss: 2.799244944262506

Epoch: 5| Step: 2
Training loss: 1.8233087463162432
Validation loss: 2.7996787599276773

Epoch: 5| Step: 3
Training loss: 1.327670120430784
Validation loss: 2.7581198264659625

Epoch: 5| Step: 4
Training loss: 2.2717997626396436
Validation loss: 2.824882445565254

Epoch: 5| Step: 5
Training loss: 2.1893868074743943
Validation loss: 2.821811057356224

Epoch: 5| Step: 6
Training loss: 1.629260932491161
Validation loss: 2.810011200286775

Epoch: 5| Step: 7
Training loss: 2.0484558290873456
Validation loss: 2.6702739565258384

Epoch: 5| Step: 8
Training loss: 1.5026910008595682
Validation loss: 2.7588852070222734

Epoch: 5| Step: 9
Training loss: 2.356388247858573
Validation loss: 2.7306631252241678

Epoch: 5| Step: 10
Training loss: 1.7805322238241839
Validation loss: 2.7687757576376018

Epoch: 627| Step: 0
Training loss: 1.5409532735029263
Validation loss: 2.7852426730192037

Epoch: 5| Step: 1
Training loss: 2.325707223449005
Validation loss: 2.8189573614006505

Epoch: 5| Step: 2
Training loss: 1.5399266639191047
Validation loss: 2.8290053747814174

Epoch: 5| Step: 3
Training loss: 1.9614480862288206
Validation loss: 2.7159347498564697

Epoch: 5| Step: 4
Training loss: 2.3526708075916707
Validation loss: 2.8537612527107608

Epoch: 5| Step: 5
Training loss: 1.7329233641455664
Validation loss: 2.892649983871877

Epoch: 5| Step: 6
Training loss: 2.540593457466067
Validation loss: 2.834304886090573

Epoch: 5| Step: 7
Training loss: 1.7125085733018104
Validation loss: 2.7249406435371393

Epoch: 5| Step: 8
Training loss: 2.0130574040876477
Validation loss: 2.7641400391632867

Epoch: 5| Step: 9
Training loss: 1.397644628025477
Validation loss: 2.79565602944867

Epoch: 5| Step: 10
Training loss: 1.583508816414161
Validation loss: 2.7182803410159964

Epoch: 628| Step: 0
Training loss: 1.4538884772147609
Validation loss: 2.7759050769968185

Epoch: 5| Step: 1
Training loss: 2.1105691426041675
Validation loss: 2.734685563178194

Epoch: 5| Step: 2
Training loss: 1.6453645094777851
Validation loss: 2.83768385432046

Epoch: 5| Step: 3
Training loss: 1.8540093715969945
Validation loss: 2.788699638376125

Epoch: 5| Step: 4
Training loss: 1.740869202938961
Validation loss: 2.8018166416321435

Epoch: 5| Step: 5
Training loss: 1.5771469257926192
Validation loss: 2.7320297417103165

Epoch: 5| Step: 6
Training loss: 1.9743767515478428
Validation loss: 2.7761190643322813

Epoch: 5| Step: 7
Training loss: 1.9369693152380676
Validation loss: 2.769713630226871

Epoch: 5| Step: 8
Training loss: 1.7058446325770538
Validation loss: 2.7619010186459207

Epoch: 5| Step: 9
Training loss: 1.8691759574524311
Validation loss: 2.7593817083478154

Epoch: 5| Step: 10
Training loss: 2.915936478539099
Validation loss: 2.7950750661408494

Epoch: 629| Step: 0
Training loss: 2.2783291028013024
Validation loss: 2.757828983477356

Epoch: 5| Step: 1
Training loss: 2.1995602168160575
Validation loss: 2.7621235847294714

Epoch: 5| Step: 2
Training loss: 2.0193653739527395
Validation loss: 2.744080529481661

Epoch: 5| Step: 3
Training loss: 1.4613243855518012
Validation loss: 2.8014339291170227

Epoch: 5| Step: 4
Training loss: 2.0933277216712587
Validation loss: 2.7482409607919798

Epoch: 5| Step: 5
Training loss: 1.653246044782392
Validation loss: 2.8560171769904037

Epoch: 5| Step: 6
Training loss: 1.6793029344923678
Validation loss: 2.751080145187834

Epoch: 5| Step: 7
Training loss: 2.49926527671041
Validation loss: 2.7649553564798213

Epoch: 5| Step: 8
Training loss: 1.750059194926057
Validation loss: 2.7160799547863554

Epoch: 5| Step: 9
Training loss: 1.8309641253646103
Validation loss: 2.7288225362942486

Epoch: 5| Step: 10
Training loss: 1.7110479310510638
Validation loss: 2.802684703088184

Epoch: 630| Step: 0
Training loss: 1.1254826146312067
Validation loss: 2.7989617379162475

Epoch: 5| Step: 1
Training loss: 1.4929214989068225
Validation loss: 2.7952001161178646

Epoch: 5| Step: 2
Training loss: 2.0177562003562093
Validation loss: 2.6936212489536704

Epoch: 5| Step: 3
Training loss: 1.842274608930681
Validation loss: 2.7433820876368262

Epoch: 5| Step: 4
Training loss: 1.92356060511101
Validation loss: 2.753682308478006

Epoch: 5| Step: 5
Training loss: 1.6583310135229297
Validation loss: 2.7858283104162203

Epoch: 5| Step: 6
Training loss: 1.7017681071165864
Validation loss: 2.8246278108728817

Epoch: 5| Step: 7
Training loss: 1.7994009425104092
Validation loss: 2.753321190572656

Epoch: 5| Step: 8
Training loss: 2.7122322970014845
Validation loss: 2.878980576558687

Epoch: 5| Step: 9
Training loss: 2.559282469328562
Validation loss: 2.794308633784411

Epoch: 5| Step: 10
Training loss: 1.372708926115585
Validation loss: 2.740887145473321

Epoch: 631| Step: 0
Training loss: 1.7679593344322648
Validation loss: 2.777577589642295

Epoch: 5| Step: 1
Training loss: 2.6882895263615425
Validation loss: 2.6899372685931895

Epoch: 5| Step: 2
Training loss: 1.9148660024270567
Validation loss: 2.7681293257507207

Epoch: 5| Step: 3
Training loss: 1.6562753351541053
Validation loss: 2.8387270838741254

Epoch: 5| Step: 4
Training loss: 1.606679863314955
Validation loss: 2.7499386546581803

Epoch: 5| Step: 5
Training loss: 1.5271808508128557
Validation loss: 2.797455305415662

Epoch: 5| Step: 6
Training loss: 1.7839957373657962
Validation loss: 2.7556112156810557

Epoch: 5| Step: 7
Training loss: 2.0471651293889517
Validation loss: 2.7775526617636856

Epoch: 5| Step: 8
Training loss: 1.6811044793097258
Validation loss: 2.7426692508038037

Epoch: 5| Step: 9
Training loss: 1.969352690468357
Validation loss: 2.6925687178712843

Epoch: 5| Step: 10
Training loss: 2.008848880216569
Validation loss: 2.7542988596426827

Epoch: 632| Step: 0
Training loss: 2.2171128371331412
Validation loss: 2.7529653742812883

Epoch: 5| Step: 1
Training loss: 1.6124365121334268
Validation loss: 2.7983991327086333

Epoch: 5| Step: 2
Training loss: 1.874140351640641
Validation loss: 2.792266219004336

Epoch: 5| Step: 3
Training loss: 2.384771823484471
Validation loss: 2.7282617954323354

Epoch: 5| Step: 4
Training loss: 2.0752894050359676
Validation loss: 2.773693968905098

Epoch: 5| Step: 5
Training loss: 1.4157874614131796
Validation loss: 2.799502507670751

Epoch: 5| Step: 6
Training loss: 1.7333589619184588
Validation loss: 2.721586355384051

Epoch: 5| Step: 7
Training loss: 1.3927427304265954
Validation loss: 2.8705025262923534

Epoch: 5| Step: 8
Training loss: 1.9604709267750502
Validation loss: 2.791606339188664

Epoch: 5| Step: 9
Training loss: 1.8972233158677492
Validation loss: 2.7197695564737465

Epoch: 5| Step: 10
Training loss: 2.0113707602540805
Validation loss: 2.8033813333569015

Epoch: 633| Step: 0
Training loss: 2.015710163535151
Validation loss: 2.7732987933762945

Epoch: 5| Step: 1
Training loss: 1.8455977152439456
Validation loss: 2.7923709343469065

Epoch: 5| Step: 2
Training loss: 1.3591749109797384
Validation loss: 2.647341580204708

Epoch: 5| Step: 3
Training loss: 1.9409367014622738
Validation loss: 2.69736406130144

Epoch: 5| Step: 4
Training loss: 1.9938214949940094
Validation loss: 2.784013418518369

Epoch: 5| Step: 5
Training loss: 1.8350798206483103
Validation loss: 2.792505999184017

Epoch: 5| Step: 6
Training loss: 2.1408279211387464
Validation loss: 2.711910644202013

Epoch: 5| Step: 7
Training loss: 2.028012791896106
Validation loss: 2.7641911206311653

Epoch: 5| Step: 8
Training loss: 1.7412143606686066
Validation loss: 2.74292912653744

Epoch: 5| Step: 9
Training loss: 2.025309282396536
Validation loss: 2.7763500587568353

Epoch: 5| Step: 10
Training loss: 1.6245172223616196
Validation loss: 2.718829615729319

Epoch: 634| Step: 0
Training loss: 1.8878120745421751
Validation loss: 2.704758166332428

Epoch: 5| Step: 1
Training loss: 1.6868440271440692
Validation loss: 2.8090734685257166

Epoch: 5| Step: 2
Training loss: 1.7093982478762897
Validation loss: 2.640435940359678

Epoch: 5| Step: 3
Training loss: 2.063214842866221
Validation loss: 2.7631363389300625

Epoch: 5| Step: 4
Training loss: 1.8803936628335918
Validation loss: 2.7551337200484443

Epoch: 5| Step: 5
Training loss: 2.664210698544737
Validation loss: 2.7427956114528773

Epoch: 5| Step: 6
Training loss: 2.02498211322938
Validation loss: 2.7600925941801586

Epoch: 5| Step: 7
Training loss: 1.3647301961283362
Validation loss: 2.7375597393016613

Epoch: 5| Step: 8
Training loss: 1.6771636453989445
Validation loss: 2.7364462343998808

Epoch: 5| Step: 9
Training loss: 1.6993497249944596
Validation loss: 2.728768309679738

Epoch: 5| Step: 10
Training loss: 1.9865625893876502
Validation loss: 2.782015757853323

Epoch: 635| Step: 0
Training loss: 1.53740157145716
Validation loss: 2.7855742922802813

Epoch: 5| Step: 1
Training loss: 1.5202849806111118
Validation loss: 2.7325548039697423

Epoch: 5| Step: 2
Training loss: 2.2932779600792093
Validation loss: 2.7458294448502585

Epoch: 5| Step: 3
Training loss: 1.445692682524854
Validation loss: 2.7653068320995216

Epoch: 5| Step: 4
Training loss: 2.2874730551545
Validation loss: 2.7079881932504755

Epoch: 5| Step: 5
Training loss: 1.8508274856788747
Validation loss: 2.769283034610424

Epoch: 5| Step: 6
Training loss: 2.0037812013630107
Validation loss: 2.8061229697614025

Epoch: 5| Step: 7
Training loss: 1.7548374346352058
Validation loss: 2.716765197284723

Epoch: 5| Step: 8
Training loss: 1.7667025763382915
Validation loss: 2.719691197439397

Epoch: 5| Step: 9
Training loss: 1.7627698380627128
Validation loss: 2.7604987697422088

Epoch: 5| Step: 10
Training loss: 1.9867115832164655
Validation loss: 2.689735432037372

Epoch: 636| Step: 0
Training loss: 2.3416651290218784
Validation loss: 2.696453341099055

Epoch: 5| Step: 1
Training loss: 1.4618131084151373
Validation loss: 2.7348613797484247

Epoch: 5| Step: 2
Training loss: 1.70126479165558
Validation loss: 2.7124154402586313

Epoch: 5| Step: 3
Training loss: 1.7658384075995006
Validation loss: 2.769423251296319

Epoch: 5| Step: 4
Training loss: 1.9153608006159715
Validation loss: 2.7763332309334197

Epoch: 5| Step: 5
Training loss: 1.5440449112502408
Validation loss: 2.7609336389055383

Epoch: 5| Step: 6
Training loss: 1.5032117156395943
Validation loss: 2.8392742029492988

Epoch: 5| Step: 7
Training loss: 2.295577532669305
Validation loss: 2.7562213546398766

Epoch: 5| Step: 8
Training loss: 1.960431037333967
Validation loss: 2.734474582060049

Epoch: 5| Step: 9
Training loss: 1.4850688717987444
Validation loss: 2.6716289520912824

Epoch: 5| Step: 10
Training loss: 2.4745892386155375
Validation loss: 2.7731906996549065

Epoch: 637| Step: 0
Training loss: 1.628045236460483
Validation loss: 2.8786883314356553

Epoch: 5| Step: 1
Training loss: 1.4910492874994727
Validation loss: 2.7424544856612587

Epoch: 5| Step: 2
Training loss: 1.2954193586532354
Validation loss: 2.796734694816434

Epoch: 5| Step: 3
Training loss: 2.319781207258206
Validation loss: 2.782326064631976

Epoch: 5| Step: 4
Training loss: 1.9240879870894074
Validation loss: 2.7602551967754194

Epoch: 5| Step: 5
Training loss: 1.5981486338216895
Validation loss: 2.7421946341278605

Epoch: 5| Step: 6
Training loss: 2.2412220009258523
Validation loss: 2.8364754859236645

Epoch: 5| Step: 7
Training loss: 1.7790730876865533
Validation loss: 2.783452382291725

Epoch: 5| Step: 8
Training loss: 1.9969336129482886
Validation loss: 2.7955439540785054

Epoch: 5| Step: 9
Training loss: 2.338884109085446
Validation loss: 2.804062742803894

Epoch: 5| Step: 10
Training loss: 1.642443421200774
Validation loss: 2.7576796580934895

Epoch: 638| Step: 0
Training loss: 1.7654557948772809
Validation loss: 2.782007167573116

Epoch: 5| Step: 1
Training loss: 2.386083640149034
Validation loss: 2.7900209665159377

Epoch: 5| Step: 2
Training loss: 2.1840939844470864
Validation loss: 2.7667981252809213

Epoch: 5| Step: 3
Training loss: 2.3162387832394713
Validation loss: 2.7564953811215838

Epoch: 5| Step: 4
Training loss: 1.6948257661689854
Validation loss: 2.7126704875094023

Epoch: 5| Step: 5
Training loss: 1.9605857260032187
Validation loss: 2.8255267738282486

Epoch: 5| Step: 6
Training loss: 1.6205682477271304
Validation loss: 2.752577275948425

Epoch: 5| Step: 7
Training loss: 1.8740208294300182
Validation loss: 2.8122546600565173

Epoch: 5| Step: 8
Training loss: 1.8076039318420976
Validation loss: 2.803668594344922

Epoch: 5| Step: 9
Training loss: 1.2547752245191477
Validation loss: 2.7960667549420957

Epoch: 5| Step: 10
Training loss: 1.7620605678475367
Validation loss: 2.733100166875363

Epoch: 639| Step: 0
Training loss: 1.5978812733112033
Validation loss: 2.6672715076673885

Epoch: 5| Step: 1
Training loss: 2.3243587676115127
Validation loss: 2.731772012343831

Epoch: 5| Step: 2
Training loss: 1.9242218699025344
Validation loss: 2.747729829891516

Epoch: 5| Step: 3
Training loss: 1.251964789230594
Validation loss: 2.7626030189965443

Epoch: 5| Step: 4
Training loss: 1.673941929975595
Validation loss: 2.7798884562827197

Epoch: 5| Step: 5
Training loss: 1.4587841790255822
Validation loss: 2.751123331290318

Epoch: 5| Step: 6
Training loss: 2.6782177155691667
Validation loss: 2.7358536095660413

Epoch: 5| Step: 7
Training loss: 1.7593397499469534
Validation loss: 2.777350154147208

Epoch: 5| Step: 8
Training loss: 2.1728996220106405
Validation loss: 2.7393608645500724

Epoch: 5| Step: 9
Training loss: 2.044689147006396
Validation loss: 2.7422944206907425

Epoch: 5| Step: 10
Training loss: 2.146439944945085
Validation loss: 2.734689992642538

Epoch: 640| Step: 0
Training loss: 1.3171694662685505
Validation loss: 2.637660791460549

Epoch: 5| Step: 1
Training loss: 1.6207658918744026
Validation loss: 2.8541891104475408

Epoch: 5| Step: 2
Training loss: 1.8871578234812048
Validation loss: 2.7081503384265933

Epoch: 5| Step: 3
Training loss: 2.2228100661435124
Validation loss: 2.7727213541420106

Epoch: 5| Step: 4
Training loss: 2.1137566164027093
Validation loss: 2.68694274459255

Epoch: 5| Step: 5
Training loss: 2.053967019593578
Validation loss: 2.7775939978200372

Epoch: 5| Step: 6
Training loss: 1.6958600403778294
Validation loss: 2.8113317088973644

Epoch: 5| Step: 7
Training loss: 2.361066906334453
Validation loss: 2.7888755442692497

Epoch: 5| Step: 8
Training loss: 1.7524963013178694
Validation loss: 2.8620481350187985

Epoch: 5| Step: 9
Training loss: 1.3516014402215335
Validation loss: 2.6917789609020764

Epoch: 5| Step: 10
Training loss: 2.323159266463657
Validation loss: 2.742474589350752

Epoch: 641| Step: 0
Training loss: 1.8832914764119049
Validation loss: 2.6860694464233097

Epoch: 5| Step: 1
Training loss: 1.9929224790243378
Validation loss: 2.756366311388775

Epoch: 5| Step: 2
Training loss: 1.8012165197243042
Validation loss: 2.808931980158946

Epoch: 5| Step: 3
Training loss: 2.41457837959771
Validation loss: 2.7989946185352856

Epoch: 5| Step: 4
Training loss: 1.7929430193083242
Validation loss: 2.7076719481440987

Epoch: 5| Step: 5
Training loss: 1.6323143596163145
Validation loss: 2.778645400008355

Epoch: 5| Step: 6
Training loss: 2.0843758327133597
Validation loss: 2.7410425530981883

Epoch: 5| Step: 7
Training loss: 2.0209186444185225
Validation loss: 2.769840262059226

Epoch: 5| Step: 8
Training loss: 1.90934639517527
Validation loss: 2.8075613836348823

Epoch: 5| Step: 9
Training loss: 1.7960603276976446
Validation loss: 2.758257335283455

Epoch: 5| Step: 10
Training loss: 1.3967756487784015
Validation loss: 2.6526880460818973

Epoch: 642| Step: 0
Training loss: 1.9637665421671207
Validation loss: 2.8107694025402847

Epoch: 5| Step: 1
Training loss: 2.6724676177700983
Validation loss: 2.7829149126852037

Epoch: 5| Step: 2
Training loss: 1.6324317889837892
Validation loss: 2.747204821303968

Epoch: 5| Step: 3
Training loss: 1.5584112457273036
Validation loss: 2.7334966502206615

Epoch: 5| Step: 4
Training loss: 1.49502310030132
Validation loss: 2.64180829342753

Epoch: 5| Step: 5
Training loss: 2.1288695165982277
Validation loss: 2.7534001232292584

Epoch: 5| Step: 6
Training loss: 1.88391770971185
Validation loss: 2.7911632808243487

Epoch: 5| Step: 7
Training loss: 1.1262922282881105
Validation loss: 2.748008030821545

Epoch: 5| Step: 8
Training loss: 2.3559274305944866
Validation loss: 2.816910207131638

Epoch: 5| Step: 9
Training loss: 1.5513596693152367
Validation loss: 2.701012113711546

Epoch: 5| Step: 10
Training loss: 2.1095335724178366
Validation loss: 2.6678343936507023

Epoch: 643| Step: 0
Training loss: 2.1221017707919065
Validation loss: 2.73558092002716

Epoch: 5| Step: 1
Training loss: 1.523154990582276
Validation loss: 2.784281659275734

Epoch: 5| Step: 2
Training loss: 1.6909383430542304
Validation loss: 2.7835901804912666

Epoch: 5| Step: 3
Training loss: 1.6554235879769543
Validation loss: 2.7291760820609796

Epoch: 5| Step: 4
Training loss: 1.4461639370776926
Validation loss: 2.8224956952479863

Epoch: 5| Step: 5
Training loss: 2.2792226065047796
Validation loss: 2.7954583346606294

Epoch: 5| Step: 6
Training loss: 2.5889542146644198
Validation loss: 2.7584347954005204

Epoch: 5| Step: 7
Training loss: 1.9792666426721792
Validation loss: 2.71570782913146

Epoch: 5| Step: 8
Training loss: 1.2913143949155501
Validation loss: 2.7450917995518034

Epoch: 5| Step: 9
Training loss: 1.4207733413843677
Validation loss: 2.7680253632105005

Epoch: 5| Step: 10
Training loss: 2.027094772426821
Validation loss: 2.7459175201401553

Epoch: 644| Step: 0
Training loss: 2.450524962878151
Validation loss: 2.756773918486784

Epoch: 5| Step: 1
Training loss: 1.5788867735947367
Validation loss: 2.77948676980908

Epoch: 5| Step: 2
Training loss: 1.6639370579965587
Validation loss: 2.7841243770270414

Epoch: 5| Step: 3
Training loss: 1.73612035960807
Validation loss: 2.786653136071204

Epoch: 5| Step: 4
Training loss: 2.433353418328293
Validation loss: 2.724866446798896

Epoch: 5| Step: 5
Training loss: 1.8687695301272915
Validation loss: 2.751054938071636

Epoch: 5| Step: 6
Training loss: 1.57141863832183
Validation loss: 2.8034360101355538

Epoch: 5| Step: 7
Training loss: 2.317559043848163
Validation loss: 2.7892107242979285

Epoch: 5| Step: 8
Training loss: 1.4587574569132373
Validation loss: 2.652667192829543

Epoch: 5| Step: 9
Training loss: 1.44158942653301
Validation loss: 2.7586975676050915

Epoch: 5| Step: 10
Training loss: 1.8265930016600247
Validation loss: 2.7014138769366673

Epoch: 645| Step: 0
Training loss: 1.7171534665929051
Validation loss: 2.7676012160074723

Epoch: 5| Step: 1
Training loss: 2.6268865981062643
Validation loss: 2.7051434141307253

Epoch: 5| Step: 2
Training loss: 2.015186350797956
Validation loss: 2.7867373140047365

Epoch: 5| Step: 3
Training loss: 1.8251849929901556
Validation loss: 2.761759771194484

Epoch: 5| Step: 4
Training loss: 2.1348273852070867
Validation loss: 2.730121651809194

Epoch: 5| Step: 5
Training loss: 1.6820365625732552
Validation loss: 2.7035080615014557

Epoch: 5| Step: 6
Training loss: 1.4157639694211765
Validation loss: 2.737066752459798

Epoch: 5| Step: 7
Training loss: 1.4943139069249136
Validation loss: 2.785557293779418

Epoch: 5| Step: 8
Training loss: 1.4235938445907559
Validation loss: 2.805836600085787

Epoch: 5| Step: 9
Training loss: 1.9409880465926062
Validation loss: 2.7842759450657306

Epoch: 5| Step: 10
Training loss: 2.051292254043539
Validation loss: 2.7344992323163924

Epoch: 646| Step: 0
Training loss: 1.4605316577576735
Validation loss: 2.7135780522087063

Epoch: 5| Step: 1
Training loss: 2.0833264414355406
Validation loss: 2.7685122511255273

Epoch: 5| Step: 2
Training loss: 1.7811020906843564
Validation loss: 2.7564282205255197

Epoch: 5| Step: 3
Training loss: 1.5093673042432887
Validation loss: 2.8050081241915477

Epoch: 5| Step: 4
Training loss: 1.9428621969237425
Validation loss: 2.7539692942707004

Epoch: 5| Step: 5
Training loss: 2.0289041912081633
Validation loss: 2.85526415463655

Epoch: 5| Step: 6
Training loss: 2.636891632063792
Validation loss: 2.8217764047946132

Epoch: 5| Step: 7
Training loss: 1.8080201526759319
Validation loss: 2.809869810231326

Epoch: 5| Step: 8
Training loss: 1.7522671183183856
Validation loss: 2.8101423967126897

Epoch: 5| Step: 9
Training loss: 1.473017964348727
Validation loss: 2.747792507396467

Epoch: 5| Step: 10
Training loss: 1.4642500424442868
Validation loss: 2.762727539056418

Epoch: 647| Step: 0
Training loss: 1.8414036319861335
Validation loss: 2.7576342375221348

Epoch: 5| Step: 1
Training loss: 1.130684741936986
Validation loss: 2.7756786340317077

Epoch: 5| Step: 2
Training loss: 1.8282496744012406
Validation loss: 2.771272122316202

Epoch: 5| Step: 3
Training loss: 2.1263417888297225
Validation loss: 2.6894118769457953

Epoch: 5| Step: 4
Training loss: 2.1366613962680763
Validation loss: 2.775847688971031

Epoch: 5| Step: 5
Training loss: 2.332306352040676
Validation loss: 2.7290221996970985

Epoch: 5| Step: 6
Training loss: 2.0106952322710763
Validation loss: 2.6480204129496285

Epoch: 5| Step: 7
Training loss: 1.4793097556666248
Validation loss: 2.6788346572895683

Epoch: 5| Step: 8
Training loss: 1.4466841503850596
Validation loss: 2.6906724974377014

Epoch: 5| Step: 9
Training loss: 2.3876594649980296
Validation loss: 2.7855177375810563

Epoch: 5| Step: 10
Training loss: 1.999040134883856
Validation loss: 2.7934615799773734

Epoch: 648| Step: 0
Training loss: 2.770570460496305
Validation loss: 2.7579278264994276

Epoch: 5| Step: 1
Training loss: 1.3606036542095081
Validation loss: 2.8011358815224985

Epoch: 5| Step: 2
Training loss: 1.735577278291612
Validation loss: 2.790208130326279

Epoch: 5| Step: 3
Training loss: 2.188059054189713
Validation loss: 2.7274672073307817

Epoch: 5| Step: 4
Training loss: 1.754486056116137
Validation loss: 2.706402794030263

Epoch: 5| Step: 5
Training loss: 1.7407519665747648
Validation loss: 2.675715300463821

Epoch: 5| Step: 6
Training loss: 2.0587446530243136
Validation loss: 2.769728996957676

Epoch: 5| Step: 7
Training loss: 1.41723008265339
Validation loss: 2.8548413449249703

Epoch: 5| Step: 8
Training loss: 1.4096482648486537
Validation loss: 2.670825668963106

Epoch: 5| Step: 9
Training loss: 1.966855545456843
Validation loss: 2.7754530971991027

Epoch: 5| Step: 10
Training loss: 1.6056113075394174
Validation loss: 2.8044005595770654

Epoch: 649| Step: 0
Training loss: 1.6726488835735152
Validation loss: 2.756198065978643

Epoch: 5| Step: 1
Training loss: 1.7724968520379998
Validation loss: 2.719728226676914

Epoch: 5| Step: 2
Training loss: 2.3214752674646246
Validation loss: 2.7715604298282592

Epoch: 5| Step: 3
Training loss: 1.8371980925123401
Validation loss: 2.746190001984063

Epoch: 5| Step: 4
Training loss: 1.7158142680288027
Validation loss: 2.730016409979287

Epoch: 5| Step: 5
Training loss: 1.5811594880626918
Validation loss: 2.7229090698125167

Epoch: 5| Step: 6
Training loss: 1.7757575366228016
Validation loss: 2.7896972937591844

Epoch: 5| Step: 7
Training loss: 1.8307611743919885
Validation loss: 2.734110741568903

Epoch: 5| Step: 8
Training loss: 2.11655813624767
Validation loss: 2.7277230347055044

Epoch: 5| Step: 9
Training loss: 1.944546713485936
Validation loss: 2.746518053410328

Epoch: 5| Step: 10
Training loss: 1.686195929291682
Validation loss: 2.8058327352109202

Epoch: 650| Step: 0
Training loss: 1.70425335664378
Validation loss: 2.7241154373281646

Epoch: 5| Step: 1
Training loss: 1.184480039422739
Validation loss: 2.7006709681384495

Epoch: 5| Step: 2
Training loss: 1.9971507758087461
Validation loss: 2.6555694210065623

Epoch: 5| Step: 3
Training loss: 2.21347493388992
Validation loss: 2.7045925087278753

Epoch: 5| Step: 4
Training loss: 2.104403366020047
Validation loss: 2.7530665643988756

Epoch: 5| Step: 5
Training loss: 1.8978156181873902
Validation loss: 2.762344590433772

Epoch: 5| Step: 6
Training loss: 1.6996241995625885
Validation loss: 2.6905702479967553

Epoch: 5| Step: 7
Training loss: 2.3312301921258656
Validation loss: 2.764177918392245

Epoch: 5| Step: 8
Training loss: 1.6557730941809183
Validation loss: 2.7676824581776853

Epoch: 5| Step: 9
Training loss: 1.8181862917758351
Validation loss: 2.723733509222016

Epoch: 5| Step: 10
Training loss: 1.9782198866614678
Validation loss: 2.7874196868014156

Epoch: 651| Step: 0
Training loss: 2.0033678071308305
Validation loss: 2.8081560238909375

Epoch: 5| Step: 1
Training loss: 2.0594568632812655
Validation loss: 2.7773868194056384

Epoch: 5| Step: 2
Training loss: 1.9354314529078598
Validation loss: 2.7800887143255286

Epoch: 5| Step: 3
Training loss: 1.4124492484233346
Validation loss: 2.8056455190486718

Epoch: 5| Step: 4
Training loss: 1.5302981318055777
Validation loss: 2.7787754133840936

Epoch: 5| Step: 5
Training loss: 1.7237225128261668
Validation loss: 2.8263616644647427

Epoch: 5| Step: 6
Training loss: 2.408564457698238
Validation loss: 2.746804543611362

Epoch: 5| Step: 7
Training loss: 1.7026902090016844
Validation loss: 2.738939017130437

Epoch: 5| Step: 8
Training loss: 1.6158080183659123
Validation loss: 2.8122475386580588

Epoch: 5| Step: 9
Training loss: 2.272737060872588
Validation loss: 2.7448624718148897

Epoch: 5| Step: 10
Training loss: 1.5868014533362957
Validation loss: 2.7960791345461136

Epoch: 652| Step: 0
Training loss: 2.3971430861091214
Validation loss: 2.6928650803711225

Epoch: 5| Step: 1
Training loss: 2.061344863624122
Validation loss: 2.7653999679688113

Epoch: 5| Step: 2
Training loss: 1.371395501734319
Validation loss: 2.7778227944640204

Epoch: 5| Step: 3
Training loss: 2.1774697455177794
Validation loss: 2.834765699844599

Epoch: 5| Step: 4
Training loss: 1.8912075185700532
Validation loss: 2.8388157637225184

Epoch: 5| Step: 5
Training loss: 1.874729391279537
Validation loss: 2.7577385564665318

Epoch: 5| Step: 6
Training loss: 2.033213209554121
Validation loss: 2.786824274898739

Epoch: 5| Step: 7
Training loss: 1.9324820973898251
Validation loss: 2.692405616229577

Epoch: 5| Step: 8
Training loss: 1.8565088830104026
Validation loss: 2.712750622821765

Epoch: 5| Step: 9
Training loss: 1.1769596923887982
Validation loss: 2.862492656255024

Epoch: 5| Step: 10
Training loss: 1.383260363450519
Validation loss: 2.808662867924655

Epoch: 653| Step: 0
Training loss: 2.4854938219047753
Validation loss: 2.7480305399507863

Epoch: 5| Step: 1
Training loss: 1.9510044029847031
Validation loss: 2.7707142631217243

Epoch: 5| Step: 2
Training loss: 1.6940467433763144
Validation loss: 2.719094067599361

Epoch: 5| Step: 3
Training loss: 1.760784028075042
Validation loss: 2.697491412314239

Epoch: 5| Step: 4
Training loss: 1.3830400699925791
Validation loss: 2.68437948398339

Epoch: 5| Step: 5
Training loss: 1.975035428079504
Validation loss: 2.7865562678597766

Epoch: 5| Step: 6
Training loss: 1.6016326144618072
Validation loss: 2.796749419922405

Epoch: 5| Step: 7
Training loss: 1.9527398301849812
Validation loss: 2.772129440056491

Epoch: 5| Step: 8
Training loss: 1.5271191834339544
Validation loss: 2.693702174142042

Epoch: 5| Step: 9
Training loss: 1.5748363258451
Validation loss: 2.769034659023026

Epoch: 5| Step: 10
Training loss: 2.1743664619034746
Validation loss: 2.6901720332651906

Epoch: 654| Step: 0
Training loss: 1.5966728186969992
Validation loss: 2.7565180804229468

Epoch: 5| Step: 1
Training loss: 1.9161886434567506
Validation loss: 2.7032843841598844

Epoch: 5| Step: 2
Training loss: 1.806877096010653
Validation loss: 2.7578447492195974

Epoch: 5| Step: 3
Training loss: 1.7951030452977637
Validation loss: 2.7322966240312425

Epoch: 5| Step: 4
Training loss: 2.069658514410523
Validation loss: 2.840617604214856

Epoch: 5| Step: 5
Training loss: 1.762309649854825
Validation loss: 2.7855316154466765

Epoch: 5| Step: 6
Training loss: 1.6884519929350343
Validation loss: 2.744327339094442

Epoch: 5| Step: 7
Training loss: 1.3806661122574393
Validation loss: 2.7785676366093637

Epoch: 5| Step: 8
Training loss: 2.1353327913016638
Validation loss: 2.670805695950856

Epoch: 5| Step: 9
Training loss: 2.20635035991693
Validation loss: 2.8627959306257305

Epoch: 5| Step: 10
Training loss: 1.671273881032595
Validation loss: 2.835842355047219

Epoch: 655| Step: 0
Training loss: 2.288280991606016
Validation loss: 2.79233323650476

Epoch: 5| Step: 1
Training loss: 1.6610311200087653
Validation loss: 2.777269228935591

Epoch: 5| Step: 2
Training loss: 1.7362926295013235
Validation loss: 2.7053888284866097

Epoch: 5| Step: 3
Training loss: 1.2270524813924504
Validation loss: 2.7709228364853105

Epoch: 5| Step: 4
Training loss: 1.820692161947725
Validation loss: 2.765839443440722

Epoch: 5| Step: 5
Training loss: 2.2305864346484636
Validation loss: 2.798989990413904

Epoch: 5| Step: 6
Training loss: 2.36325844998041
Validation loss: 2.7033774216387805

Epoch: 5| Step: 7
Training loss: 1.7085699832416223
Validation loss: 2.7211159592980354

Epoch: 5| Step: 8
Training loss: 1.7829406478254437
Validation loss: 2.7428580568208187

Epoch: 5| Step: 9
Training loss: 1.7298825478787763
Validation loss: 2.676409118440114

Epoch: 5| Step: 10
Training loss: 2.096165075521064
Validation loss: 2.7365433016176337

Epoch: 656| Step: 0
Training loss: 2.0183992441358147
Validation loss: 2.7746929280018704

Epoch: 5| Step: 1
Training loss: 1.944537579107349
Validation loss: 2.834469119393528

Epoch: 5| Step: 2
Training loss: 1.7926327592109774
Validation loss: 2.670757015427251

Epoch: 5| Step: 3
Training loss: 1.8599400022530836
Validation loss: 2.763612864674653

Epoch: 5| Step: 4
Training loss: 1.3102534913728194
Validation loss: 2.748599005992918

Epoch: 5| Step: 5
Training loss: 2.2538319910996036
Validation loss: 2.7921313711916387

Epoch: 5| Step: 6
Training loss: 2.029332356147347
Validation loss: 2.714965700479674

Epoch: 5| Step: 7
Training loss: 1.964510273173271
Validation loss: 2.7298929982155204

Epoch: 5| Step: 8
Training loss: 1.535157026528509
Validation loss: 2.6855444445706254

Epoch: 5| Step: 9
Training loss: 2.108232768177099
Validation loss: 2.671616398841491

Epoch: 5| Step: 10
Training loss: 1.1425312782530284
Validation loss: 2.692873268616328

Epoch: 657| Step: 0
Training loss: 2.0999359302737983
Validation loss: 2.7371876585111106

Epoch: 5| Step: 1
Training loss: 1.7063205383028723
Validation loss: 2.8248552379494116

Epoch: 5| Step: 2
Training loss: 1.6736890986603843
Validation loss: 2.7274218663915604

Epoch: 5| Step: 3
Training loss: 1.9224154945125338
Validation loss: 2.7507971384834056

Epoch: 5| Step: 4
Training loss: 1.6152037464268443
Validation loss: 2.7271841219538513

Epoch: 5| Step: 5
Training loss: 1.4012207805435324
Validation loss: 2.75700337405618

Epoch: 5| Step: 6
Training loss: 2.6727728868695815
Validation loss: 2.749335810082951

Epoch: 5| Step: 7
Training loss: 1.8841456841514261
Validation loss: 2.7644623058022977

Epoch: 5| Step: 8
Training loss: 1.992727288812221
Validation loss: 2.709333895370668

Epoch: 5| Step: 9
Training loss: 1.3004929506579412
Validation loss: 2.7217817760803995

Epoch: 5| Step: 10
Training loss: 1.8636130751235254
Validation loss: 2.778099697354979

Epoch: 658| Step: 0
Training loss: 1.5772308989423494
Validation loss: 2.7508247645183084

Epoch: 5| Step: 1
Training loss: 1.3774784465841319
Validation loss: 2.845155596870984

Epoch: 5| Step: 2
Training loss: 2.053653819640811
Validation loss: 2.697321979031751

Epoch: 5| Step: 3
Training loss: 2.1473087189187496
Validation loss: 2.721082012315636

Epoch: 5| Step: 4
Training loss: 2.5896409359512647
Validation loss: 2.7609437312014005

Epoch: 5| Step: 5
Training loss: 1.4693801826570627
Validation loss: 2.6761834070152037

Epoch: 5| Step: 6
Training loss: 1.775334423422016
Validation loss: 2.780126592032395

Epoch: 5| Step: 7
Training loss: 1.405387105049375
Validation loss: 2.7467247876766927

Epoch: 5| Step: 8
Training loss: 1.6881965329981872
Validation loss: 2.750719158185725

Epoch: 5| Step: 9
Training loss: 1.7748594255256378
Validation loss: 2.761385101438964

Epoch: 5| Step: 10
Training loss: 1.9308272482367679
Validation loss: 2.723324939792517

Epoch: 659| Step: 0
Training loss: 1.6833586561860325
Validation loss: 2.779766658276148

Epoch: 5| Step: 1
Training loss: 1.266732190763002
Validation loss: 2.775819935160842

Epoch: 5| Step: 2
Training loss: 1.8939903509625344
Validation loss: 2.752796265387461

Epoch: 5| Step: 3
Training loss: 2.3943235422378804
Validation loss: 2.6859697629530976

Epoch: 5| Step: 4
Training loss: 2.1326573353871607
Validation loss: 2.746507287382773

Epoch: 5| Step: 5
Training loss: 1.2477108020835543
Validation loss: 2.722233118754378

Epoch: 5| Step: 6
Training loss: 1.7685641915683683
Validation loss: 2.718509530010451

Epoch: 5| Step: 7
Training loss: 1.5320521997617444
Validation loss: 2.772999894337932

Epoch: 5| Step: 8
Training loss: 1.5976841558057233
Validation loss: 2.7328008993294204

Epoch: 5| Step: 9
Training loss: 2.1381846530490924
Validation loss: 2.800897171468937

Epoch: 5| Step: 10
Training loss: 1.8534053854120962
Validation loss: 2.6853068208173942

Epoch: 660| Step: 0
Training loss: 2.301377431313661
Validation loss: 2.7528603631943396

Epoch: 5| Step: 1
Training loss: 1.6839385420849797
Validation loss: 2.7622546203052587

Epoch: 5| Step: 2
Training loss: 2.0047389153943422
Validation loss: 2.794800309282699

Epoch: 5| Step: 3
Training loss: 1.633791105516505
Validation loss: 2.684666039182542

Epoch: 5| Step: 4
Training loss: 1.5879806361663336
Validation loss: 2.7434983720877173

Epoch: 5| Step: 5
Training loss: 2.20072492446836
Validation loss: 2.6931106902436546

Epoch: 5| Step: 6
Training loss: 1.5286897547930718
Validation loss: 2.7513695137925716

Epoch: 5| Step: 7
Training loss: 1.329010298130043
Validation loss: 2.7820144336507338

Epoch: 5| Step: 8
Training loss: 2.6177251007437667
Validation loss: 2.824429076947055

Epoch: 5| Step: 9
Training loss: 1.3794821166192501
Validation loss: 2.731436053534566

Epoch: 5| Step: 10
Training loss: 2.217630775663891
Validation loss: 2.683124887279209

Epoch: 661| Step: 0
Training loss: 1.7337326372373207
Validation loss: 2.7006644524055976

Epoch: 5| Step: 1
Training loss: 1.8177946301572654
Validation loss: 2.7370682229810095

Epoch: 5| Step: 2
Training loss: 2.3487012317866847
Validation loss: 2.78316040167466

Epoch: 5| Step: 3
Training loss: 1.815937662697389
Validation loss: 2.7821539299071896

Epoch: 5| Step: 4
Training loss: 1.6984774671693275
Validation loss: 2.7118211132272725

Epoch: 5| Step: 5
Training loss: 1.8674207725213638
Validation loss: 2.8225979153739087

Epoch: 5| Step: 6
Training loss: 1.4398998462763022
Validation loss: 2.7100904199910247

Epoch: 5| Step: 7
Training loss: 1.2284652141665622
Validation loss: 2.722400939027955

Epoch: 5| Step: 8
Training loss: 1.9347209072663871
Validation loss: 2.804588237277249

Epoch: 5| Step: 9
Training loss: 1.4824619212414558
Validation loss: 2.7432982194166136

Epoch: 5| Step: 10
Training loss: 2.284676891161916
Validation loss: 2.7893801584915456

Epoch: 662| Step: 0
Training loss: 2.0936363530986255
Validation loss: 2.8034180719570423

Epoch: 5| Step: 1
Training loss: 2.5437972305749454
Validation loss: 2.7072695918833007

Epoch: 5| Step: 2
Training loss: 1.8086777208250335
Validation loss: 2.798729950604679

Epoch: 5| Step: 3
Training loss: 1.680627675080928
Validation loss: 2.8149928977779233

Epoch: 5| Step: 4
Training loss: 1.4732904257646904
Validation loss: 2.789168006135626

Epoch: 5| Step: 5
Training loss: 1.5270447889653085
Validation loss: 2.760551875296034

Epoch: 5| Step: 6
Training loss: 1.4159566932780006
Validation loss: 2.8839699587274326

Epoch: 5| Step: 7
Training loss: 1.354744841562106
Validation loss: 2.765338628194689

Epoch: 5| Step: 8
Training loss: 1.5144730742495731
Validation loss: 2.8074153198890164

Epoch: 5| Step: 9
Training loss: 2.009003757099229
Validation loss: 2.8218994402664848

Epoch: 5| Step: 10
Training loss: 1.6821069369936918
Validation loss: 2.7511864952423

Epoch: 663| Step: 0
Training loss: 1.689727302309652
Validation loss: 2.7770656187223643

Epoch: 5| Step: 1
Training loss: 2.0743865611554995
Validation loss: 2.711535130789607

Epoch: 5| Step: 2
Training loss: 1.944509685269574
Validation loss: 2.760763545346019

Epoch: 5| Step: 3
Training loss: 1.5212225045922056
Validation loss: 2.7590781540860663

Epoch: 5| Step: 4
Training loss: 1.8030159214816865
Validation loss: 2.757829639765358

Epoch: 5| Step: 5
Training loss: 1.7051610413061664
Validation loss: 2.7571639914488344

Epoch: 5| Step: 6
Training loss: 2.127333874071882
Validation loss: 2.694392028354859

Epoch: 5| Step: 7
Training loss: 1.6975529364982245
Validation loss: 2.6890990109427153

Epoch: 5| Step: 8
Training loss: 1.3913826753567247
Validation loss: 2.768335916707456

Epoch: 5| Step: 9
Training loss: 1.3375170555096847
Validation loss: 2.7673824467291603

Epoch: 5| Step: 10
Training loss: 2.2565373710582377
Validation loss: 2.7000954061565956

Epoch: 664| Step: 0
Training loss: 1.8282759514459572
Validation loss: 2.741500806374901

Epoch: 5| Step: 1
Training loss: 2.063429882931548
Validation loss: 2.6968214864230013

Epoch: 5| Step: 2
Training loss: 1.2158810029719445
Validation loss: 2.6745583167393288

Epoch: 5| Step: 3
Training loss: 1.1855305351627017
Validation loss: 2.7830333119781687

Epoch: 5| Step: 4
Training loss: 1.5872843618442238
Validation loss: 2.811531002058708

Epoch: 5| Step: 5
Training loss: 1.8861720712792232
Validation loss: 2.7505080479997024

Epoch: 5| Step: 6
Training loss: 2.170331118059597
Validation loss: 2.730932133579358

Epoch: 5| Step: 7
Training loss: 2.1319547053064976
Validation loss: 2.8105592309582024

Epoch: 5| Step: 8
Training loss: 2.225615289887069
Validation loss: 2.724409956552715

Epoch: 5| Step: 9
Training loss: 1.663454688021207
Validation loss: 2.7391024243513464

Epoch: 5| Step: 10
Training loss: 1.5011761345903414
Validation loss: 2.7582984423446715

Epoch: 665| Step: 0
Training loss: 2.08250882681525
Validation loss: 2.8305266978712487

Epoch: 5| Step: 1
Training loss: 2.6638749132086996
Validation loss: 2.691339318813827

Epoch: 5| Step: 2
Training loss: 1.7824300905832948
Validation loss: 2.7482235457401885

Epoch: 5| Step: 3
Training loss: 1.1213975023021745
Validation loss: 2.770168514898759

Epoch: 5| Step: 4
Training loss: 1.7247905355241593
Validation loss: 2.726578075137498

Epoch: 5| Step: 5
Training loss: 2.0303692595533356
Validation loss: 2.752981542228197

Epoch: 5| Step: 6
Training loss: 1.3796800382073224
Validation loss: 2.6800180058738423

Epoch: 5| Step: 7
Training loss: 2.315852647471822
Validation loss: 2.6824886725565515

Epoch: 5| Step: 8
Training loss: 0.745576289617113
Validation loss: 2.7617328207904306

Epoch: 5| Step: 9
Training loss: 2.020488460516315
Validation loss: 2.7205226749925555

Epoch: 5| Step: 10
Training loss: 1.430284469293153
Validation loss: 2.819606455041516

Epoch: 666| Step: 0
Training loss: 2.368591194566669
Validation loss: 2.8083449121163917

Epoch: 5| Step: 1
Training loss: 1.695148161205058
Validation loss: 2.6937445608793666

Epoch: 5| Step: 2
Training loss: 1.5684443506614527
Validation loss: 2.781800144118542

Epoch: 5| Step: 3
Training loss: 2.1473455810094952
Validation loss: 2.70225292228996

Epoch: 5| Step: 4
Training loss: 1.1886067503289262
Validation loss: 2.812665563014925

Epoch: 5| Step: 5
Training loss: 1.4054978372427613
Validation loss: 2.7165763472186275

Epoch: 5| Step: 6
Training loss: 2.1785962507633974
Validation loss: 2.726826675761262

Epoch: 5| Step: 7
Training loss: 1.6806219296269513
Validation loss: 2.7337158439951152

Epoch: 5| Step: 8
Training loss: 1.374849831443782
Validation loss: 2.7460406178405457

Epoch: 5| Step: 9
Training loss: 1.3948637835676132
Validation loss: 2.722096521333973

Epoch: 5| Step: 10
Training loss: 2.0850484146242034
Validation loss: 2.768033149445698

Epoch: 667| Step: 0
Training loss: 2.473800611320381
Validation loss: 2.7137049219494225

Epoch: 5| Step: 1
Training loss: 1.3747352431900164
Validation loss: 2.79241789687795

Epoch: 5| Step: 2
Training loss: 1.613075742032308
Validation loss: 2.723756952162489

Epoch: 5| Step: 3
Training loss: 2.052632163249768
Validation loss: 2.7583144489124316

Epoch: 5| Step: 4
Training loss: 1.934349020443
Validation loss: 2.71291331777212

Epoch: 5| Step: 5
Training loss: 1.2790692075865249
Validation loss: 2.7464656211329688

Epoch: 5| Step: 6
Training loss: 2.044125756301325
Validation loss: 2.7256300293373523

Epoch: 5| Step: 7
Training loss: 1.575612324561915
Validation loss: 2.7759023858196255

Epoch: 5| Step: 8
Training loss: 1.9814626994716764
Validation loss: 2.704454159587638

Epoch: 5| Step: 9
Training loss: 1.8422593378582792
Validation loss: 2.6964054468737135

Epoch: 5| Step: 10
Training loss: 1.8693229562445977
Validation loss: 2.6821606905235127

Epoch: 668| Step: 0
Training loss: 1.4996281798789202
Validation loss: 2.7233532784733048

Epoch: 5| Step: 1
Training loss: 1.8582543594389276
Validation loss: 2.6911354249564376

Epoch: 5| Step: 2
Training loss: 2.086106425671057
Validation loss: 2.7527467652286934

Epoch: 5| Step: 3
Training loss: 2.0251047931447332
Validation loss: 2.7637017247615625

Epoch: 5| Step: 4
Training loss: 1.6187846088023676
Validation loss: 2.74932235934096

Epoch: 5| Step: 5
Training loss: 1.1233314220023567
Validation loss: 2.7863542453176766

Epoch: 5| Step: 6
Training loss: 2.345807304260502
Validation loss: 2.801452710006286

Epoch: 5| Step: 7
Training loss: 1.5257142098617127
Validation loss: 2.809564759219394

Epoch: 5| Step: 8
Training loss: 1.7422700186718034
Validation loss: 2.7839184475467333

Epoch: 5| Step: 9
Training loss: 2.2650447760191907
Validation loss: 2.8027912344647237

Epoch: 5| Step: 10
Training loss: 1.4743538136110175
Validation loss: 2.7298220032625933

Epoch: 669| Step: 0
Training loss: 1.3351815745282882
Validation loss: 2.7395913766416693

Epoch: 5| Step: 1
Training loss: 2.2097840012852896
Validation loss: 2.8497360073043394

Epoch: 5| Step: 2
Training loss: 2.1214276748185603
Validation loss: 2.748950403702995

Epoch: 5| Step: 3
Training loss: 1.1354537164551948
Validation loss: 2.7651011042203164

Epoch: 5| Step: 4
Training loss: 1.590914578861828
Validation loss: 2.7578989618624226

Epoch: 5| Step: 5
Training loss: 2.216086387210533
Validation loss: 2.7443923427774872

Epoch: 5| Step: 6
Training loss: 1.7308441512691621
Validation loss: 2.7361392412963528

Epoch: 5| Step: 7
Training loss: 1.332463258734163
Validation loss: 2.7635419919925477

Epoch: 5| Step: 8
Training loss: 1.690078813532173
Validation loss: 2.791353138003645

Epoch: 5| Step: 9
Training loss: 2.3416266423217964
Validation loss: 2.8094057095527223

Epoch: 5| Step: 10
Training loss: 1.6716386859766847
Validation loss: 2.6999069330756975

Epoch: 670| Step: 0
Training loss: 1.385636673096529
Validation loss: 2.681182920496146

Epoch: 5| Step: 1
Training loss: 2.2382745393183106
Validation loss: 2.6947809537883156

Epoch: 5| Step: 2
Training loss: 2.596730461642791
Validation loss: 2.7632672188607037

Epoch: 5| Step: 3
Training loss: 1.3651136527762195
Validation loss: 2.782718318329741

Epoch: 5| Step: 4
Training loss: 1.6960458883159493
Validation loss: 2.7291075333651196

Epoch: 5| Step: 5
Training loss: 1.7565054548196768
Validation loss: 2.702386942510229

Epoch: 5| Step: 6
Training loss: 1.686489650474027
Validation loss: 2.6861003589817547

Epoch: 5| Step: 7
Training loss: 1.9272758456461756
Validation loss: 2.740877292663789

Epoch: 5| Step: 8
Training loss: 2.1409849435062154
Validation loss: 2.7486883999498155

Epoch: 5| Step: 9
Training loss: 1.558027886563475
Validation loss: 2.7839435689007934

Epoch: 5| Step: 10
Training loss: 1.4901000596058405
Validation loss: 2.7392778872406405

Epoch: 671| Step: 0
Training loss: 1.5488747665482678
Validation loss: 2.7307622835886876

Epoch: 5| Step: 1
Training loss: 1.2725226737889612
Validation loss: 2.79572377722353

Epoch: 5| Step: 2
Training loss: 1.9678748471465308
Validation loss: 2.7601423536273795

Epoch: 5| Step: 3
Training loss: 1.2931138156058726
Validation loss: 2.758527849168982

Epoch: 5| Step: 4
Training loss: 1.7079682386469266
Validation loss: 2.799441030041758

Epoch: 5| Step: 5
Training loss: 2.5658541801211188
Validation loss: 2.7358225432618175

Epoch: 5| Step: 6
Training loss: 1.7589709724256217
Validation loss: 2.757798362727536

Epoch: 5| Step: 7
Training loss: 1.4346264022550406
Validation loss: 2.7909313685108263

Epoch: 5| Step: 8
Training loss: 1.6504821390816722
Validation loss: 2.7628187645543107

Epoch: 5| Step: 9
Training loss: 2.3408173587734287
Validation loss: 2.748703182853111

Epoch: 5| Step: 10
Training loss: 1.4435884657819964
Validation loss: 2.7697847031875003

Epoch: 672| Step: 0
Training loss: 1.4596289828246871
Validation loss: 2.7731133541516133

Epoch: 5| Step: 1
Training loss: 1.626477083717266
Validation loss: 2.7619585089601646

Epoch: 5| Step: 2
Training loss: 2.0321237885473367
Validation loss: 2.703395885177139

Epoch: 5| Step: 3
Training loss: 1.950197818699097
Validation loss: 2.6878981432478666

Epoch: 5| Step: 4
Training loss: 1.2298375039420024
Validation loss: 2.796575531492559

Epoch: 5| Step: 5
Training loss: 1.7199144060439262
Validation loss: 2.8291728770041553

Epoch: 5| Step: 6
Training loss: 2.296678184329064
Validation loss: 2.7010550610394346

Epoch: 5| Step: 7
Training loss: 1.7190155517735666
Validation loss: 2.6363272033709926

Epoch: 5| Step: 8
Training loss: 2.1325767302935668
Validation loss: 2.8091778457386116

Epoch: 5| Step: 9
Training loss: 1.396341895457778
Validation loss: 2.7175610933908922

Epoch: 5| Step: 10
Training loss: 1.6391854646448802
Validation loss: 2.720394857123233

Epoch: 673| Step: 0
Training loss: 1.525219154244839
Validation loss: 2.7245079193061867

Epoch: 5| Step: 1
Training loss: 1.8188381527646016
Validation loss: 2.691411059311119

Epoch: 5| Step: 2
Training loss: 1.7758274862812842
Validation loss: 2.761844486001854

Epoch: 5| Step: 3
Training loss: 1.3407161975065676
Validation loss: 2.6797594395441515

Epoch: 5| Step: 4
Training loss: 1.8108514984221562
Validation loss: 2.72268209572981

Epoch: 5| Step: 5
Training loss: 2.040808036505152
Validation loss: 2.7452848784095067

Epoch: 5| Step: 6
Training loss: 1.5840290782937436
Validation loss: 2.797477356197933

Epoch: 5| Step: 7
Training loss: 1.0616723371161674
Validation loss: 2.7191374779267043

Epoch: 5| Step: 8
Training loss: 2.1468172379320682
Validation loss: 2.741894346178314

Epoch: 5| Step: 9
Training loss: 2.18093081874346
Validation loss: 2.7180754348398177

Epoch: 5| Step: 10
Training loss: 1.8182424145050828
Validation loss: 2.7170497531579785

Epoch: 674| Step: 0
Training loss: 2.0726344493146494
Validation loss: 2.7429422815092797

Epoch: 5| Step: 1
Training loss: 1.3903704206629102
Validation loss: 2.815866926590869

Epoch: 5| Step: 2
Training loss: 1.8316019364507752
Validation loss: 2.7648036704260734

Epoch: 5| Step: 3
Training loss: 1.1161636249063516
Validation loss: 2.7489494650521062

Epoch: 5| Step: 4
Training loss: 2.0702740359781866
Validation loss: 2.749449834298124

Epoch: 5| Step: 5
Training loss: 1.8715236862726101
Validation loss: 2.752226788418618

Epoch: 5| Step: 6
Training loss: 1.6963523804613532
Validation loss: 2.720167276005997

Epoch: 5| Step: 7
Training loss: 2.1204839852125668
Validation loss: 2.8076378637036705

Epoch: 5| Step: 8
Training loss: 1.7103577071268234
Validation loss: 2.7141557932707205

Epoch: 5| Step: 9
Training loss: 1.3588128078371386
Validation loss: 2.7875647060352655

Epoch: 5| Step: 10
Training loss: 1.7475334905381266
Validation loss: 2.7625609069384773

Epoch: 675| Step: 0
Training loss: 2.206050796809318
Validation loss: 2.706763223366193

Epoch: 5| Step: 1
Training loss: 2.056436816602025
Validation loss: 2.794352257311031

Epoch: 5| Step: 2
Training loss: 1.1951518231276381
Validation loss: 2.7352037224634778

Epoch: 5| Step: 3
Training loss: 1.6126246559397583
Validation loss: 2.7418319022370645

Epoch: 5| Step: 4
Training loss: 1.5133309060271931
Validation loss: 2.666529611236712

Epoch: 5| Step: 5
Training loss: 1.7735295208823112
Validation loss: 2.7531504833057077

Epoch: 5| Step: 6
Training loss: 1.7418783965691889
Validation loss: 2.7031409491763716

Epoch: 5| Step: 7
Training loss: 2.315012417589009
Validation loss: 2.7468023036485487

Epoch: 5| Step: 8
Training loss: 1.5237483563308676
Validation loss: 2.7854268528325163

Epoch: 5| Step: 9
Training loss: 1.639759743816391
Validation loss: 2.711280316188113

Epoch: 5| Step: 10
Training loss: 1.8326181476179477
Validation loss: 2.785738402087245

Epoch: 676| Step: 0
Training loss: 1.6735878129799844
Validation loss: 2.8772015214680495

Epoch: 5| Step: 1
Training loss: 2.3181009252989453
Validation loss: 2.745895101990384

Epoch: 5| Step: 2
Training loss: 1.8080535807054792
Validation loss: 2.7429844466241935

Epoch: 5| Step: 3
Training loss: 2.0065972476286
Validation loss: 2.756204076514652

Epoch: 5| Step: 4
Training loss: 1.6180906123709944
Validation loss: 2.775365074293948

Epoch: 5| Step: 5
Training loss: 1.245617335975907
Validation loss: 2.723293522522091

Epoch: 5| Step: 6
Training loss: 1.4327409998901104
Validation loss: 2.7106275157535693

Epoch: 5| Step: 7
Training loss: 1.6084540241134553
Validation loss: 2.821492038205015

Epoch: 5| Step: 8
Training loss: 1.8324972182352932
Validation loss: 2.741171020066136

Epoch: 5| Step: 9
Training loss: 2.089616367412393
Validation loss: 2.6808297183936562

Epoch: 5| Step: 10
Training loss: 1.9680709273226242
Validation loss: 2.737147882837995

Epoch: 677| Step: 0
Training loss: 1.5897368224081192
Validation loss: 2.746433021738232

Epoch: 5| Step: 1
Training loss: 2.0814298580684474
Validation loss: 2.8547229109547336

Epoch: 5| Step: 2
Training loss: 2.2486072044137035
Validation loss: 2.735902001381302

Epoch: 5| Step: 3
Training loss: 1.675180038341597
Validation loss: 2.7270276528812034

Epoch: 5| Step: 4
Training loss: 1.3662568766987144
Validation loss: 2.7384886875252463

Epoch: 5| Step: 5
Training loss: 2.340898330273184
Validation loss: 2.766218516279045

Epoch: 5| Step: 6
Training loss: 1.4146993478085517
Validation loss: 2.7311571003997313

Epoch: 5| Step: 7
Training loss: 1.5020140001835658
Validation loss: 2.762642190614961

Epoch: 5| Step: 8
Training loss: 1.5359685170950614
Validation loss: 2.7441206362813784

Epoch: 5| Step: 9
Training loss: 1.9598885576523855
Validation loss: 2.7429596338253703

Epoch: 5| Step: 10
Training loss: 1.5091824015754278
Validation loss: 2.6901092378359093

Epoch: 678| Step: 0
Training loss: 1.2985691816300624
Validation loss: 2.7739942921597667

Epoch: 5| Step: 1
Training loss: 1.6250035946146015
Validation loss: 2.6883416294831224

Epoch: 5| Step: 2
Training loss: 1.2476961840101075
Validation loss: 2.8472176979389823

Epoch: 5| Step: 3
Training loss: 2.262006408635108
Validation loss: 2.7535529588517766

Epoch: 5| Step: 4
Training loss: 1.6970185867172878
Validation loss: 2.7615819055498387

Epoch: 5| Step: 5
Training loss: 1.2217041305914302
Validation loss: 2.71833932632294

Epoch: 5| Step: 6
Training loss: 1.697934913147161
Validation loss: 2.737077273693847

Epoch: 5| Step: 7
Training loss: 2.685459781968456
Validation loss: 2.8147153308170103

Epoch: 5| Step: 8
Training loss: 1.5187309923277672
Validation loss: 2.7699979564774266

Epoch: 5| Step: 9
Training loss: 1.6849934364440045
Validation loss: 2.748032579271772

Epoch: 5| Step: 10
Training loss: 1.5983109380262208
Validation loss: 2.7637590737281377

Epoch: 679| Step: 0
Training loss: 1.5639576025969972
Validation loss: 2.8158458337444223

Epoch: 5| Step: 1
Training loss: 1.6703016061311609
Validation loss: 2.729361900918211

Epoch: 5| Step: 2
Training loss: 2.065683970569039
Validation loss: 2.7962161042107923

Epoch: 5| Step: 3
Training loss: 1.8260783941648677
Validation loss: 2.7855971752093502

Epoch: 5| Step: 4
Training loss: 1.4429213255321356
Validation loss: 2.746424476981197

Epoch: 5| Step: 5
Training loss: 2.1458544930707975
Validation loss: 2.7633415590329062

Epoch: 5| Step: 6
Training loss: 1.704437939692097
Validation loss: 2.781723892785346

Epoch: 5| Step: 7
Training loss: 1.6105110825089517
Validation loss: 2.7433553183405355

Epoch: 5| Step: 8
Training loss: 2.1827670530204237
Validation loss: 2.692096510184831

Epoch: 5| Step: 9
Training loss: 1.6353634706175486
Validation loss: 2.6900883673274123

Epoch: 5| Step: 10
Training loss: 1.7633878324964791
Validation loss: 2.7031589695364877

Epoch: 680| Step: 0
Training loss: 1.9415439119405484
Validation loss: 2.8078274323016066

Epoch: 5| Step: 1
Training loss: 1.4071905169877172
Validation loss: 2.7824416106431142

Epoch: 5| Step: 2
Training loss: 1.556997758397012
Validation loss: 2.728181633202116

Epoch: 5| Step: 3
Training loss: 2.0567012535208247
Validation loss: 2.726360518184715

Epoch: 5| Step: 4
Training loss: 1.418271623532342
Validation loss: 2.73170164057345

Epoch: 5| Step: 5
Training loss: 1.9392354637546383
Validation loss: 2.768313501373959

Epoch: 5| Step: 6
Training loss: 1.7119171264412114
Validation loss: 2.7338830630170716

Epoch: 5| Step: 7
Training loss: 2.204941778300965
Validation loss: 2.798827011181111

Epoch: 5| Step: 8
Training loss: 1.797344842933814
Validation loss: 2.7761099294305347

Epoch: 5| Step: 9
Training loss: 1.9765518851617148
Validation loss: 2.705154402587988

Epoch: 5| Step: 10
Training loss: 1.3005319534007638
Validation loss: 2.7587024185146327

Epoch: 681| Step: 0
Training loss: 1.7872058279555467
Validation loss: 2.74787164551234

Epoch: 5| Step: 1
Training loss: 1.8094813761958315
Validation loss: 2.7584567529007264

Epoch: 5| Step: 2
Training loss: 1.6439674842756071
Validation loss: 2.8297365299874713

Epoch: 5| Step: 3
Training loss: 2.084937266588405
Validation loss: 2.799645876355161

Epoch: 5| Step: 4
Training loss: 1.7861866053869948
Validation loss: 2.80314684269557

Epoch: 5| Step: 5
Training loss: 1.9901881937915202
Validation loss: 2.7595774276641545

Epoch: 5| Step: 6
Training loss: 1.623552264360049
Validation loss: 2.7555349122967945

Epoch: 5| Step: 7
Training loss: 1.660968106293773
Validation loss: 2.7811649197041923

Epoch: 5| Step: 8
Training loss: 1.7250297267397992
Validation loss: 2.7202639289068835

Epoch: 5| Step: 9
Training loss: 1.813432322154064
Validation loss: 2.8098285324891563

Epoch: 5| Step: 10
Training loss: 1.627479422302946
Validation loss: 2.730593423856166

Epoch: 682| Step: 0
Training loss: 1.6094802525740735
Validation loss: 2.7128964338158696

Epoch: 5| Step: 1
Training loss: 2.1972531466659566
Validation loss: 2.7171540074276006

Epoch: 5| Step: 2
Training loss: 1.3980324867277685
Validation loss: 2.743523472959081

Epoch: 5| Step: 3
Training loss: 2.1649051499237797
Validation loss: 2.6818045849606085

Epoch: 5| Step: 4
Training loss: 1.6111908085429245
Validation loss: 2.727062836314487

Epoch: 5| Step: 5
Training loss: 1.7063617571886314
Validation loss: 2.777160576646185

Epoch: 5| Step: 6
Training loss: 1.761417608468974
Validation loss: 2.763004923928144

Epoch: 5| Step: 7
Training loss: 2.0292529339112946
Validation loss: 2.6489404903763543

Epoch: 5| Step: 8
Training loss: 1.5600195460439932
Validation loss: 2.7433748491312424

Epoch: 5| Step: 9
Training loss: 1.4659889729021343
Validation loss: 2.7143681837136877

Epoch: 5| Step: 10
Training loss: 1.6723607863804384
Validation loss: 2.741190841377097

Epoch: 683| Step: 0
Training loss: 1.4879830930323592
Validation loss: 2.795803944525689

Epoch: 5| Step: 1
Training loss: 1.790143548441434
Validation loss: 2.699676244581606

Epoch: 5| Step: 2
Training loss: 1.5295371771761992
Validation loss: 2.6983796514010923

Epoch: 5| Step: 3
Training loss: 2.1690576516523037
Validation loss: 2.7757147191848417

Epoch: 5| Step: 4
Training loss: 1.7446000027124016
Validation loss: 2.7829360943772317

Epoch: 5| Step: 5
Training loss: 1.9728113094612056
Validation loss: 2.7491093150562933

Epoch: 5| Step: 6
Training loss: 2.179354296958703
Validation loss: 2.7339127025854393

Epoch: 5| Step: 7
Training loss: 1.6941901504282526
Validation loss: 2.7787258007788305

Epoch: 5| Step: 8
Training loss: 2.1092435442617834
Validation loss: 2.790172099388105

Epoch: 5| Step: 9
Training loss: 1.3390316295292508
Validation loss: 2.7829673500559586

Epoch: 5| Step: 10
Training loss: 1.5215820751235474
Validation loss: 2.7991911220767802

Epoch: 684| Step: 0
Training loss: 2.02629612074176
Validation loss: 2.6997461179097426

Epoch: 5| Step: 1
Training loss: 1.8372322224758602
Validation loss: 2.769531217601946

Epoch: 5| Step: 2
Training loss: 1.9188816360896634
Validation loss: 2.669212390050762

Epoch: 5| Step: 3
Training loss: 1.754080782831907
Validation loss: 2.7504490143655733

Epoch: 5| Step: 4
Training loss: 1.8800688574741071
Validation loss: 2.7577485423942343

Epoch: 5| Step: 5
Training loss: 1.470406754459313
Validation loss: 2.7714711140772943

Epoch: 5| Step: 6
Training loss: 1.8210138762446557
Validation loss: 2.686059288503189

Epoch: 5| Step: 7
Training loss: 1.8054585316664742
Validation loss: 2.6997345899132554

Epoch: 5| Step: 8
Training loss: 1.4831428634140065
Validation loss: 2.81394403045915

Epoch: 5| Step: 9
Training loss: 1.9792848919810073
Validation loss: 2.809959567748417

Epoch: 5| Step: 10
Training loss: 1.69153839370405
Validation loss: 2.7468966073025824

Epoch: 685| Step: 0
Training loss: 2.6872971923954276
Validation loss: 2.7659449553603284

Epoch: 5| Step: 1
Training loss: 1.5880713178200745
Validation loss: 2.6425380700265038

Epoch: 5| Step: 2
Training loss: 1.3641846295158466
Validation loss: 2.7863234255662253

Epoch: 5| Step: 3
Training loss: 1.267065664659717
Validation loss: 2.7085866129712377

Epoch: 5| Step: 4
Training loss: 1.7097237518879402
Validation loss: 2.7266576362342185

Epoch: 5| Step: 5
Training loss: 2.170944563443845
Validation loss: 2.796582401287102

Epoch: 5| Step: 6
Training loss: 1.7094174953387957
Validation loss: 2.6684213589893053

Epoch: 5| Step: 7
Training loss: 1.7736222763261067
Validation loss: 2.6639440154879983

Epoch: 5| Step: 8
Training loss: 2.013305275492075
Validation loss: 2.767936712317536

Epoch: 5| Step: 9
Training loss: 1.4348546441657541
Validation loss: 2.7098149761197976

Epoch: 5| Step: 10
Training loss: 0.9992331306192201
Validation loss: 2.768615503687274

Epoch: 686| Step: 0
Training loss: 2.2302565598978807
Validation loss: 2.6627389036809324

Epoch: 5| Step: 1
Training loss: 1.6568782262723947
Validation loss: 2.658473142895635

Epoch: 5| Step: 2
Training loss: 2.3131230520195376
Validation loss: 2.7668611111482018

Epoch: 5| Step: 3
Training loss: 1.080974627582579
Validation loss: 2.7366314378273295

Epoch: 5| Step: 4
Training loss: 1.9228697892657598
Validation loss: 2.8272051550688055

Epoch: 5| Step: 5
Training loss: 1.4778962746693831
Validation loss: 2.8027110959744483

Epoch: 5| Step: 6
Training loss: 1.4368164261622374
Validation loss: 2.7641679037540614

Epoch: 5| Step: 7
Training loss: 1.7703064826667787
Validation loss: 2.7516212466750742

Epoch: 5| Step: 8
Training loss: 1.8603513061843655
Validation loss: 2.738263674237794

Epoch: 5| Step: 9
Training loss: 1.1162869218143066
Validation loss: 2.7314000554299285

Epoch: 5| Step: 10
Training loss: 2.0497167531162375
Validation loss: 2.64823857410159

Epoch: 687| Step: 0
Training loss: 1.473336869461396
Validation loss: 2.7363540224128364

Epoch: 5| Step: 1
Training loss: 1.7699853849077019
Validation loss: 2.7235365097704385

Epoch: 5| Step: 2
Training loss: 2.017018154609162
Validation loss: 2.69780089135923

Epoch: 5| Step: 3
Training loss: 1.8076624934177434
Validation loss: 2.8017566412850274

Epoch: 5| Step: 4
Training loss: 1.9332585207944868
Validation loss: 2.706657696532322

Epoch: 5| Step: 5
Training loss: 1.9668030573000526
Validation loss: 2.729291652049098

Epoch: 5| Step: 6
Training loss: 1.694970021615729
Validation loss: 2.775586080442436

Epoch: 5| Step: 7
Training loss: 1.534329179440901
Validation loss: 2.733903000932182

Epoch: 5| Step: 8
Training loss: 1.4381863158150974
Validation loss: 2.7871106310147553

Epoch: 5| Step: 9
Training loss: 2.0039754933669065
Validation loss: 2.7751885388229454

Epoch: 5| Step: 10
Training loss: 1.3655995765955782
Validation loss: 2.785339122110086

Epoch: 688| Step: 0
Training loss: 1.222053208489789
Validation loss: 2.771146566145191

Epoch: 5| Step: 1
Training loss: 1.6965073273239402
Validation loss: 2.6950244903654084

Epoch: 5| Step: 2
Training loss: 1.5847233977978858
Validation loss: 2.7242632711907713

Epoch: 5| Step: 3
Training loss: 1.6783136471323334
Validation loss: 2.8099571942929384

Epoch: 5| Step: 4
Training loss: 2.0815337483118856
Validation loss: 2.814293236613749

Epoch: 5| Step: 5
Training loss: 1.4397136395554913
Validation loss: 2.8211176135559475

Epoch: 5| Step: 6
Training loss: 1.6596559735656184
Validation loss: 2.721702482189568

Epoch: 5| Step: 7
Training loss: 1.7801226344350352
Validation loss: 2.757538312484195

Epoch: 5| Step: 8
Training loss: 1.6824821466686184
Validation loss: 2.757834789668621

Epoch: 5| Step: 9
Training loss: 1.5923839024933408
Validation loss: 2.747353160025003

Epoch: 5| Step: 10
Training loss: 2.6737501022959473
Validation loss: 2.7863721976634777

Epoch: 689| Step: 0
Training loss: 1.5940712997591482
Validation loss: 2.7526707829137975

Epoch: 5| Step: 1
Training loss: 1.734805285716168
Validation loss: 2.778098549386959

Epoch: 5| Step: 2
Training loss: 0.9079615774217644
Validation loss: 2.7982729604857965

Epoch: 5| Step: 3
Training loss: 1.7067578269161034
Validation loss: 2.7622685714263584

Epoch: 5| Step: 4
Training loss: 1.722157793309711
Validation loss: 2.798687802313532

Epoch: 5| Step: 5
Training loss: 1.8119834295319357
Validation loss: 2.687317695358222

Epoch: 5| Step: 6
Training loss: 2.358142556156228
Validation loss: 2.6899572920673096

Epoch: 5| Step: 7
Training loss: 1.5937836587380974
Validation loss: 2.7109327915263415

Epoch: 5| Step: 8
Training loss: 2.102369982932476
Validation loss: 2.71637773204695

Epoch: 5| Step: 9
Training loss: 1.6084846329884337
Validation loss: 2.743794532227806

Epoch: 5| Step: 10
Training loss: 1.5719113537203928
Validation loss: 2.7033239971022076

Epoch: 690| Step: 0
Training loss: 1.4478159899209486
Validation loss: 2.672193162741736

Epoch: 5| Step: 1
Training loss: 1.8198746576220453
Validation loss: 2.8196624569395516

Epoch: 5| Step: 2
Training loss: 1.7034287488058608
Validation loss: 2.7024453811003544

Epoch: 5| Step: 3
Training loss: 1.9200526335575032
Validation loss: 2.745093109812886

Epoch: 5| Step: 4
Training loss: 1.9689610080568303
Validation loss: 2.7585720543248073

Epoch: 5| Step: 5
Training loss: 2.0209521491394415
Validation loss: 2.7821871469218094

Epoch: 5| Step: 6
Training loss: 1.9524126508567454
Validation loss: 2.823421644855947

Epoch: 5| Step: 7
Training loss: 1.24567858437654
Validation loss: 2.719951326036072

Epoch: 5| Step: 8
Training loss: 2.1358265801227607
Validation loss: 2.771104691237564

Epoch: 5| Step: 9
Training loss: 1.8493924844578595
Validation loss: 2.7596545723993824

Epoch: 5| Step: 10
Training loss: 1.6813701629240119
Validation loss: 2.8044162956979046

Epoch: 691| Step: 0
Training loss: 1.5838361075702594
Validation loss: 2.754445261538015

Epoch: 5| Step: 1
Training loss: 1.8045109914358768
Validation loss: 2.7471893029188705

Epoch: 5| Step: 2
Training loss: 1.6726385494259532
Validation loss: 2.777251541750595

Epoch: 5| Step: 3
Training loss: 1.955759575645921
Validation loss: 2.7785770374567296

Epoch: 5| Step: 4
Training loss: 1.533763224351201
Validation loss: 2.7524432490362942

Epoch: 5| Step: 5
Training loss: 1.8105010486716684
Validation loss: 2.815833191435191

Epoch: 5| Step: 6
Training loss: 1.604086919346366
Validation loss: 2.784561397225876

Epoch: 5| Step: 7
Training loss: 1.9112553155200158
Validation loss: 2.75545978838977

Epoch: 5| Step: 8
Training loss: 1.9199452209605508
Validation loss: 2.745180323418758

Epoch: 5| Step: 9
Training loss: 2.176046413515671
Validation loss: 2.719456634703094

Epoch: 5| Step: 10
Training loss: 1.4626029410365147
Validation loss: 2.6784623283907316

Epoch: 692| Step: 0
Training loss: 1.8630652472413616
Validation loss: 2.7128490169964357

Epoch: 5| Step: 1
Training loss: 1.1950298299218627
Validation loss: 2.745229542578344

Epoch: 5| Step: 2
Training loss: 1.702935724502575
Validation loss: 2.810179051940216

Epoch: 5| Step: 3
Training loss: 1.7018471920166556
Validation loss: 2.7157995371561845

Epoch: 5| Step: 4
Training loss: 1.467817862949397
Validation loss: 2.681520474505987

Epoch: 5| Step: 5
Training loss: 1.2755084837687822
Validation loss: 2.778261649294986

Epoch: 5| Step: 6
Training loss: 1.9740119732200865
Validation loss: 2.684481195686686

Epoch: 5| Step: 7
Training loss: 1.9056889067806633
Validation loss: 2.6705587709926535

Epoch: 5| Step: 8
Training loss: 2.4317153367664033
Validation loss: 2.7512159353507832

Epoch: 5| Step: 9
Training loss: 1.6850683565169229
Validation loss: 2.7478698458415245

Epoch: 5| Step: 10
Training loss: 1.6996458722568393
Validation loss: 2.7502195078629645

Epoch: 693| Step: 0
Training loss: 1.461485652799655
Validation loss: 2.7915842062156075

Epoch: 5| Step: 1
Training loss: 1.3015851352001102
Validation loss: 2.6891853416719247

Epoch: 5| Step: 2
Training loss: 1.3206144811425267
Validation loss: 2.739696806490754

Epoch: 5| Step: 3
Training loss: 1.8225336889599046
Validation loss: 2.844558786516455

Epoch: 5| Step: 4
Training loss: 1.9607601617513069
Validation loss: 2.7586039043482677

Epoch: 5| Step: 5
Training loss: 1.66959974963301
Validation loss: 2.682201732764958

Epoch: 5| Step: 6
Training loss: 1.7932043647952953
Validation loss: 2.7197120170508446

Epoch: 5| Step: 7
Training loss: 1.603861577470537
Validation loss: 2.622632712764681

Epoch: 5| Step: 8
Training loss: 2.049042696849127
Validation loss: 2.6984326674520243

Epoch: 5| Step: 9
Training loss: 2.210196003399609
Validation loss: 2.78987232121636

Epoch: 5| Step: 10
Training loss: 1.9062733257930262
Validation loss: 2.7635887162183153

Epoch: 694| Step: 0
Training loss: 1.901961207847633
Validation loss: 2.6907187930113756

Epoch: 5| Step: 1
Training loss: 1.7151057362561342
Validation loss: 2.718643246729388

Epoch: 5| Step: 2
Training loss: 1.6127614807325792
Validation loss: 2.7627559180470223

Epoch: 5| Step: 3
Training loss: 1.9804539425990455
Validation loss: 2.738125333612335

Epoch: 5| Step: 4
Training loss: 1.4048913962585763
Validation loss: 2.707134141940398

Epoch: 5| Step: 5
Training loss: 1.4927062086723346
Validation loss: 2.739774143276304

Epoch: 5| Step: 6
Training loss: 1.735091053005357
Validation loss: 2.7553879486447888

Epoch: 5| Step: 7
Training loss: 1.4464059353626475
Validation loss: 2.764510879354149

Epoch: 5| Step: 8
Training loss: 2.0504352386673297
Validation loss: 2.6853979465212046

Epoch: 5| Step: 9
Training loss: 2.0584832583458472
Validation loss: 2.7231596142741368

Epoch: 5| Step: 10
Training loss: 1.4354949734186906
Validation loss: 2.836355187348658

Epoch: 695| Step: 0
Training loss: 1.8635139879787148
Validation loss: 2.7011157227749236

Epoch: 5| Step: 1
Training loss: 1.4958629778773136
Validation loss: 2.744790614357656

Epoch: 5| Step: 2
Training loss: 1.7036732482414818
Validation loss: 2.713403478882885

Epoch: 5| Step: 3
Training loss: 1.3999994175773498
Validation loss: 2.761826617420865

Epoch: 5| Step: 4
Training loss: 1.981027136942719
Validation loss: 2.7306123737088193

Epoch: 5| Step: 5
Training loss: 1.1599017034187111
Validation loss: 2.7381238514872566

Epoch: 5| Step: 6
Training loss: 1.3552533509002451
Validation loss: 2.7478307789798815

Epoch: 5| Step: 7
Training loss: 1.6245205245196415
Validation loss: 2.776159072114371

Epoch: 5| Step: 8
Training loss: 2.237030585293499
Validation loss: 2.7212137994580696

Epoch: 5| Step: 9
Training loss: 1.7179338771720667
Validation loss: 2.79197907448412

Epoch: 5| Step: 10
Training loss: 2.0559573582706183
Validation loss: 2.702427083721129

Epoch: 696| Step: 0
Training loss: 2.5081738363188824
Validation loss: 2.7602523417367264

Epoch: 5| Step: 1
Training loss: 1.7648593288914407
Validation loss: 2.7030804400612576

Epoch: 5| Step: 2
Training loss: 1.5079995469211536
Validation loss: 2.756171622999039

Epoch: 5| Step: 3
Training loss: 1.7614641026681195
Validation loss: 2.711074128230146

Epoch: 5| Step: 4
Training loss: 1.4722944467850367
Validation loss: 2.702206974222758

Epoch: 5| Step: 5
Training loss: 1.7055808044053014
Validation loss: 2.771629427924342

Epoch: 5| Step: 6
Training loss: 1.770366614677073
Validation loss: 2.7208222641245703

Epoch: 5| Step: 7
Training loss: 1.5809171544952763
Validation loss: 2.717869302077666

Epoch: 5| Step: 8
Training loss: 1.6264346465505837
Validation loss: 2.7571407321355714

Epoch: 5| Step: 9
Training loss: 1.5004022376840858
Validation loss: 2.780077135868092

Epoch: 5| Step: 10
Training loss: 1.689682502830909
Validation loss: 2.7949245148427555

Epoch: 697| Step: 0
Training loss: 2.216682868076097
Validation loss: 2.709805680143388

Epoch: 5| Step: 1
Training loss: 1.3682066688193288
Validation loss: 2.7482314981517857

Epoch: 5| Step: 2
Training loss: 1.7532320829656616
Validation loss: 2.7410916725969066

Epoch: 5| Step: 3
Training loss: 2.0264413107678023
Validation loss: 2.8001741955740247

Epoch: 5| Step: 4
Training loss: 1.6447833450168072
Validation loss: 2.8198721709566987

Epoch: 5| Step: 5
Training loss: 1.390136547242701
Validation loss: 2.750415518907061

Epoch: 5| Step: 6
Training loss: 2.316441656295596
Validation loss: 2.7376882760593175

Epoch: 5| Step: 7
Training loss: 1.8910747024773324
Validation loss: 2.848801653407025

Epoch: 5| Step: 8
Training loss: 1.3771050551986181
Validation loss: 2.773030678194878

Epoch: 5| Step: 9
Training loss: 2.196152930071297
Validation loss: 2.758331787242282

Epoch: 5| Step: 10
Training loss: 1.4098291413967576
Validation loss: 2.749519497273584

Epoch: 698| Step: 0
Training loss: 2.069921607776804
Validation loss: 2.751332663948049

Epoch: 5| Step: 1
Training loss: 1.860871041726306
Validation loss: 2.7815567719400276

Epoch: 5| Step: 2
Training loss: 1.6794079925056173
Validation loss: 2.817429590148792

Epoch: 5| Step: 3
Training loss: 1.7642191463419674
Validation loss: 2.723561083945922

Epoch: 5| Step: 4
Training loss: 1.6452262660194028
Validation loss: 2.851778339977812

Epoch: 5| Step: 5
Training loss: 1.7137074105321959
Validation loss: 2.771673863472352

Epoch: 5| Step: 6
Training loss: 1.9717686232998932
Validation loss: 2.8391021000654137

Epoch: 5| Step: 7
Training loss: 1.1089603562557258
Validation loss: 2.7599318109669717

Epoch: 5| Step: 8
Training loss: 2.186124859865873
Validation loss: 2.7660120257629295

Epoch: 5| Step: 9
Training loss: 1.7498725435981048
Validation loss: 2.7503738801726323

Epoch: 5| Step: 10
Training loss: 1.5639943415741868
Validation loss: 2.7830731153535826

Epoch: 699| Step: 0
Training loss: 1.6029441270425386
Validation loss: 2.7482213591727787

Epoch: 5| Step: 1
Training loss: 1.7458187970608579
Validation loss: 2.8138063976679204

Epoch: 5| Step: 2
Training loss: 2.212449166958584
Validation loss: 2.737923885515615

Epoch: 5| Step: 3
Training loss: 1.0603502066619912
Validation loss: 2.7791023294976434

Epoch: 5| Step: 4
Training loss: 2.16433879314192
Validation loss: 2.7666080072660604

Epoch: 5| Step: 5
Training loss: 1.760808197662911
Validation loss: 2.735567321994727

Epoch: 5| Step: 6
Training loss: 1.2806252142485723
Validation loss: 2.7348908081142254

Epoch: 5| Step: 7
Training loss: 1.2187740616990743
Validation loss: 2.797422063959011

Epoch: 5| Step: 8
Training loss: 2.0049340659166566
Validation loss: 2.773339612782534

Epoch: 5| Step: 9
Training loss: 1.7283543743200354
Validation loss: 2.8070175387424876

Epoch: 5| Step: 10
Training loss: 1.1381614417788828
Validation loss: 2.75066049256594

Epoch: 700| Step: 0
Training loss: 1.6068611882141801
Validation loss: 2.77885999093682

Epoch: 5| Step: 1
Training loss: 1.8127702971860795
Validation loss: 2.6881988734680373

Epoch: 5| Step: 2
Training loss: 1.1728618789714629
Validation loss: 2.802547326909692

Epoch: 5| Step: 3
Training loss: 1.2414826126571032
Validation loss: 2.7624624273614193

Epoch: 5| Step: 4
Training loss: 1.7060955634458161
Validation loss: 2.7771102793066103

Epoch: 5| Step: 5
Training loss: 1.2108755772663
Validation loss: 2.772389075946355

Epoch: 5| Step: 6
Training loss: 1.992837956771258
Validation loss: 2.7420214587056972

Epoch: 5| Step: 7
Training loss: 2.574144191559441
Validation loss: 2.7312726672855705

Epoch: 5| Step: 8
Training loss: 1.629266639562456
Validation loss: 2.7848453030302855

Epoch: 5| Step: 9
Training loss: 1.721881649052959
Validation loss: 2.764248844326879

Epoch: 5| Step: 10
Training loss: 1.8140317429622028
Validation loss: 2.7355197499037587

Testing loss: 2.932357895748588
