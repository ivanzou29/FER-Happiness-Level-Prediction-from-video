Epoch: 1| Step: 0
Training loss: 6.676676610341557
Validation loss: 6.877660737263934

Epoch: 5| Step: 1
Training loss: 5.396263998904614
Validation loss: 6.873840780216652

Epoch: 5| Step: 2
Training loss: 6.053403971815865
Validation loss: 6.870461215083669

Epoch: 5| Step: 3
Training loss: 7.552490924929508
Validation loss: 6.867199216183528

Epoch: 5| Step: 4
Training loss: 7.225616492134512
Validation loss: 6.865475580012344

Epoch: 5| Step: 5
Training loss: 7.311420328364221
Validation loss: 6.862978492870573

Epoch: 5| Step: 6
Training loss: 6.444923638837719
Validation loss: 6.858709998953968

Epoch: 5| Step: 7
Training loss: 7.971709057296901
Validation loss: 6.857062423178643

Epoch: 5| Step: 8
Training loss: 7.458438410809063
Validation loss: 6.8536589371764

Epoch: 5| Step: 9
Training loss: 6.7898864597271675
Validation loss: 6.84988527332888

Epoch: 5| Step: 10
Training loss: 5.97673738510467
Validation loss: 6.847200310676117

Epoch: 2| Step: 0
Training loss: 6.591011237904514
Validation loss: 6.845021634912124

Epoch: 5| Step: 1
Training loss: 7.208981464626207
Validation loss: 6.841038008729066

Epoch: 5| Step: 2
Training loss: 6.826371375840072
Validation loss: 6.839991807273665

Epoch: 5| Step: 3
Training loss: 7.595927864137962
Validation loss: 6.837342489544891

Epoch: 5| Step: 4
Training loss: 6.9508231135288145
Validation loss: 6.831617394512693

Epoch: 5| Step: 5
Training loss: 5.998281232701751
Validation loss: 6.830276253622861

Epoch: 5| Step: 6
Training loss: 7.601543932242225
Validation loss: 6.828142054559898

Epoch: 5| Step: 7
Training loss: 6.716277763270978
Validation loss: 6.8253609586289405

Epoch: 5| Step: 8
Training loss: 5.455561664592554
Validation loss: 6.823111323103827

Epoch: 5| Step: 9
Training loss: 6.84808268201237
Validation loss: 6.820059071855983

Epoch: 5| Step: 10
Training loss: 7.041652732097976
Validation loss: 6.8166609482187495

Epoch: 3| Step: 0
Training loss: 6.536212988475276
Validation loss: 6.813586034550574

Epoch: 5| Step: 1
Training loss: 6.17323184007521
Validation loss: 6.812402573056591

Epoch: 5| Step: 2
Training loss: 6.611543917268546
Validation loss: 6.8092298031682

Epoch: 5| Step: 3
Training loss: 7.427764162279216
Validation loss: 6.806841737769753

Epoch: 5| Step: 4
Training loss: 7.05201875177185
Validation loss: 6.803038673630013

Epoch: 5| Step: 5
Training loss: 6.291491306042146
Validation loss: 6.801569822242766

Epoch: 5| Step: 6
Training loss: 6.561674520255148
Validation loss: 6.796410558719113

Epoch: 5| Step: 7
Training loss: 7.067942994695807
Validation loss: 6.794903439187454

Epoch: 5| Step: 8
Training loss: 8.000926917737017
Validation loss: 6.792173001230518

Epoch: 5| Step: 9
Training loss: 5.1327534153990895
Validation loss: 6.788545325224211

Epoch: 5| Step: 10
Training loss: 7.58687804939403
Validation loss: 6.785540486942081

Epoch: 4| Step: 0
Training loss: 6.53041356037512
Validation loss: 6.783173195146306

Epoch: 5| Step: 1
Training loss: 6.304484802542416
Validation loss: 6.780181650902165

Epoch: 5| Step: 2
Training loss: 6.841026565524713
Validation loss: 6.776894947916128

Epoch: 5| Step: 3
Training loss: 7.192471053960562
Validation loss: 6.774403368820283

Epoch: 5| Step: 4
Training loss: 6.683773535534878
Validation loss: 6.7730952354517

Epoch: 5| Step: 5
Training loss: 5.819006774678132
Validation loss: 6.768933891127202

Epoch: 5| Step: 6
Training loss: 7.8293833682482274
Validation loss: 6.765999133692949

Epoch: 5| Step: 7
Training loss: 7.432013531626362
Validation loss: 6.762334186641864

Epoch: 5| Step: 8
Training loss: 7.326844841708651
Validation loss: 6.760062674323911

Epoch: 5| Step: 9
Training loss: 6.451083472278792
Validation loss: 6.757721128361132

Epoch: 5| Step: 10
Training loss: 5.449012582905467
Validation loss: 6.754735087211761

Epoch: 5| Step: 0
Training loss: 6.259498397669712
Validation loss: 6.750791068078688

Epoch: 5| Step: 1
Training loss: 6.760523187379054
Validation loss: 6.748245989726295

Epoch: 5| Step: 2
Training loss: 6.153789202720034
Validation loss: 6.74405153747632

Epoch: 5| Step: 3
Training loss: 6.704883833752908
Validation loss: 6.7407848147315

Epoch: 5| Step: 4
Training loss: 6.089978425186602
Validation loss: 6.738217210814596

Epoch: 5| Step: 5
Training loss: 6.664324094550552
Validation loss: 6.732800994333872

Epoch: 5| Step: 6
Training loss: 6.608790306399866
Validation loss: 6.732393949308019

Epoch: 5| Step: 7
Training loss: 7.60371254039582
Validation loss: 6.729749647137193

Epoch: 5| Step: 8
Training loss: 6.7558458233818985
Validation loss: 6.7241051377955765

Epoch: 5| Step: 9
Training loss: 7.328788678468792
Validation loss: 6.7205827095015644

Epoch: 5| Step: 10
Training loss: 6.999645496656057
Validation loss: 6.717833295948706

Epoch: 6| Step: 0
Training loss: 6.467729423473409
Validation loss: 6.712727094212355

Epoch: 5| Step: 1
Training loss: 7.112474373769603
Validation loss: 6.710903705842894

Epoch: 5| Step: 2
Training loss: 7.104712531484247
Validation loss: 6.70829172897915

Epoch: 5| Step: 3
Training loss: 6.241338297308926
Validation loss: 6.704309727252282

Epoch: 5| Step: 4
Training loss: 6.367902507304057
Validation loss: 6.700331321682562

Epoch: 5| Step: 5
Training loss: 6.77328262240032
Validation loss: 6.694914191657717

Epoch: 5| Step: 6
Training loss: 6.9414688991967415
Validation loss: 6.692480214603117

Epoch: 5| Step: 7
Training loss: 6.4293306235443906
Validation loss: 6.688460362253903

Epoch: 5| Step: 8
Training loss: 7.049499429016718
Validation loss: 6.683494305870685

Epoch: 5| Step: 9
Training loss: 6.546605507486632
Validation loss: 6.68327069463256

Epoch: 5| Step: 10
Training loss: 6.494899509231052
Validation loss: 6.678630302630522

Epoch: 7| Step: 0
Training loss: 5.827002695957946
Validation loss: 6.672709222551257

Epoch: 5| Step: 1
Training loss: 7.179241179000048
Validation loss: 6.6712971521351205

Epoch: 5| Step: 2
Training loss: 6.179043626578482
Validation loss: 6.664759625681695

Epoch: 5| Step: 3
Training loss: 7.591307447402347
Validation loss: 6.6617973921437015

Epoch: 5| Step: 4
Training loss: 7.005454799093251
Validation loss: 6.657088451120803

Epoch: 5| Step: 5
Training loss: 6.678554648545111
Validation loss: 6.651583024379148

Epoch: 5| Step: 6
Training loss: 5.880945322250564
Validation loss: 6.648672419080955

Epoch: 5| Step: 7
Training loss: 6.442938720070674
Validation loss: 6.644338784277604

Epoch: 5| Step: 8
Training loss: 6.172024263918953
Validation loss: 6.641671775819715

Epoch: 5| Step: 9
Training loss: 6.7704235089813105
Validation loss: 6.6352478439617535

Epoch: 5| Step: 10
Training loss: 7.269828515634225
Validation loss: 6.631293742181629

Epoch: 8| Step: 0
Training loss: 7.539536851576448
Validation loss: 6.625699533194436

Epoch: 5| Step: 1
Training loss: 5.746197313818587
Validation loss: 6.6213322658364415

Epoch: 5| Step: 2
Training loss: 6.646203711382413
Validation loss: 6.617333325391414

Epoch: 5| Step: 3
Training loss: 5.896439412196077
Validation loss: 6.610990348373152

Epoch: 5| Step: 4
Training loss: 7.047406567742114
Validation loss: 6.60648362936445

Epoch: 5| Step: 5
Training loss: 7.218823188972187
Validation loss: 6.600200565257665

Epoch: 5| Step: 6
Training loss: 6.352827520953668
Validation loss: 6.598220051071447

Epoch: 5| Step: 7
Training loss: 5.580795546395161
Validation loss: 6.591353146778631

Epoch: 5| Step: 8
Training loss: 5.83840028408444
Validation loss: 6.587304731181451

Epoch: 5| Step: 9
Training loss: 6.774435390017062
Validation loss: 6.579994034931357

Epoch: 5| Step: 10
Training loss: 7.700704012306684
Validation loss: 6.58006846587072

Epoch: 9| Step: 0
Training loss: 6.188318371839012
Validation loss: 6.569329820820566

Epoch: 5| Step: 1
Training loss: 6.866853083083141
Validation loss: 6.567670338028057

Epoch: 5| Step: 2
Training loss: 7.1789207671729915
Validation loss: 6.56172539221243

Epoch: 5| Step: 3
Training loss: 6.850075502745247
Validation loss: 6.555247609950735

Epoch: 5| Step: 4
Training loss: 5.695258916071661
Validation loss: 6.551555592793029

Epoch: 5| Step: 5
Training loss: 6.449198047551569
Validation loss: 6.544225917003722

Epoch: 5| Step: 6
Training loss: 6.504971290425332
Validation loss: 6.537251265869566

Epoch: 5| Step: 7
Training loss: 7.534163675149057
Validation loss: 6.532171902733334

Epoch: 5| Step: 8
Training loss: 5.960754791699419
Validation loss: 6.525894527797862

Epoch: 5| Step: 9
Training loss: 6.259021808869678
Validation loss: 6.518938164696141

Epoch: 5| Step: 10
Training loss: 6.216872962344626
Validation loss: 6.513874681224366

Epoch: 10| Step: 0
Training loss: 7.306724419377171
Validation loss: 6.510016343013847

Epoch: 5| Step: 1
Training loss: 6.677986008621735
Validation loss: 6.503603296979081

Epoch: 5| Step: 2
Training loss: 6.757497226659479
Validation loss: 6.498605564377658

Epoch: 5| Step: 3
Training loss: 6.035486818414395
Validation loss: 6.491104782215114

Epoch: 5| Step: 4
Training loss: 6.491281971859149
Validation loss: 6.483811291831376

Epoch: 5| Step: 5
Training loss: 6.24942227554485
Validation loss: 6.481186104310781

Epoch: 5| Step: 6
Training loss: 6.0041387906332995
Validation loss: 6.473804922864063

Epoch: 5| Step: 7
Training loss: 6.265589992206596
Validation loss: 6.466944104734134

Epoch: 5| Step: 8
Training loss: 6.658705280913581
Validation loss: 6.461395386720231

Epoch: 5| Step: 9
Training loss: 5.780099125312429
Validation loss: 6.454238378816637

Epoch: 5| Step: 10
Training loss: 6.954125081694711
Validation loss: 6.44938904499227

Epoch: 11| Step: 0
Training loss: 6.308805083050809
Validation loss: 6.441550159816223

Epoch: 5| Step: 1
Training loss: 6.857709747678042
Validation loss: 6.434832552237081

Epoch: 5| Step: 2
Training loss: 6.478401686799557
Validation loss: 6.426622439205769

Epoch: 5| Step: 3
Training loss: 5.925556578428743
Validation loss: 6.422651325756431

Epoch: 5| Step: 4
Training loss: 6.612400958467875
Validation loss: 6.412642686528477

Epoch: 5| Step: 5
Training loss: 6.957405744236957
Validation loss: 6.403113513822665

Epoch: 5| Step: 6
Training loss: 7.053480211878759
Validation loss: 6.395781897576897

Epoch: 5| Step: 7
Training loss: 7.263817346956844
Validation loss: 6.3901616699333

Epoch: 5| Step: 8
Training loss: 5.16633904351513
Validation loss: 6.381734499559163

Epoch: 5| Step: 9
Training loss: 5.324593276846859
Validation loss: 6.372757223003313

Epoch: 5| Step: 10
Training loss: 6.106129127953821
Validation loss: 6.366851379432986

Epoch: 12| Step: 0
Training loss: 6.780454808737396
Validation loss: 6.360601880020508

Epoch: 5| Step: 1
Training loss: 6.052160826125096
Validation loss: 6.352616022032287

Epoch: 5| Step: 2
Training loss: 6.058314815669595
Validation loss: 6.342394657491469

Epoch: 5| Step: 3
Training loss: 5.4932631067459825
Validation loss: 6.3373497347925385

Epoch: 5| Step: 4
Training loss: 6.541044201564929
Validation loss: 6.330857553466488

Epoch: 5| Step: 5
Training loss: 5.980600147560444
Validation loss: 6.324445505969382

Epoch: 5| Step: 6
Training loss: 6.622619489122494
Validation loss: 6.314758423116423

Epoch: 5| Step: 7
Training loss: 6.60939116058899
Validation loss: 6.303387494675789

Epoch: 5| Step: 8
Training loss: 6.605379235976858
Validation loss: 6.297711871401245

Epoch: 5| Step: 9
Training loss: 6.222652878314372
Validation loss: 6.28526797446072

Epoch: 5| Step: 10
Training loss: 6.481835734460215
Validation loss: 6.279815279781658

Epoch: 13| Step: 0
Training loss: 5.995512237681406
Validation loss: 6.268405483427284

Epoch: 5| Step: 1
Training loss: 5.649466984005583
Validation loss: 6.260983378098791

Epoch: 5| Step: 2
Training loss: 7.96514859067508
Validation loss: 6.252049924963199

Epoch: 5| Step: 3
Training loss: 7.162228947648571
Validation loss: 6.246072879961536

Epoch: 5| Step: 4
Training loss: 5.132446833435966
Validation loss: 6.235296977679178

Epoch: 5| Step: 5
Training loss: 6.662091624499953
Validation loss: 6.224117672401593

Epoch: 5| Step: 6
Training loss: 5.430197185497841
Validation loss: 6.217208954163396

Epoch: 5| Step: 7
Training loss: 6.565684100125189
Validation loss: 6.2048990755469715

Epoch: 5| Step: 8
Training loss: 5.151637748374639
Validation loss: 6.197469377048283

Epoch: 5| Step: 9
Training loss: 6.152964998395844
Validation loss: 6.185812678533172

Epoch: 5| Step: 10
Training loss: 5.983735610629045
Validation loss: 6.175408576148086

Epoch: 14| Step: 0
Training loss: 5.732605871727657
Validation loss: 6.1633623921479055

Epoch: 5| Step: 1
Training loss: 6.516935440855863
Validation loss: 6.1518614602310215

Epoch: 5| Step: 2
Training loss: 6.098740319433737
Validation loss: 6.140288401484866

Epoch: 5| Step: 3
Training loss: 6.828377236741967
Validation loss: 6.135512638314661

Epoch: 5| Step: 4
Training loss: 6.28558048502216
Validation loss: 6.119932007097909

Epoch: 5| Step: 5
Training loss: 6.657537631287691
Validation loss: 6.111516916045943

Epoch: 5| Step: 6
Training loss: 5.70655197230321
Validation loss: 6.099255647100592

Epoch: 5| Step: 7
Training loss: 4.600811986161447
Validation loss: 6.089184583302405

Epoch: 5| Step: 8
Training loss: 6.140005609466277
Validation loss: 6.083116633991342

Epoch: 5| Step: 9
Training loss: 5.332505916944495
Validation loss: 6.069132012374714

Epoch: 5| Step: 10
Training loss: 7.125517976905888
Validation loss: 6.0569584473860445

Epoch: 15| Step: 0
Training loss: 6.144370143012684
Validation loss: 6.042102706614049

Epoch: 5| Step: 1
Training loss: 5.851119835768152
Validation loss: 6.0351718531628995

Epoch: 5| Step: 2
Training loss: 5.40211637491502
Validation loss: 6.0254067793347525

Epoch: 5| Step: 3
Training loss: 6.403454575404402
Validation loss: 6.0150802734305975

Epoch: 5| Step: 4
Training loss: 6.102590242349197
Validation loss: 5.995141762853699

Epoch: 5| Step: 5
Training loss: 6.184662447625129
Validation loss: 5.989625753615415

Epoch: 5| Step: 6
Training loss: 5.411039491023244
Validation loss: 5.976975762651939

Epoch: 5| Step: 7
Training loss: 6.475296320081524
Validation loss: 5.9669129071571785

Epoch: 5| Step: 8
Training loss: 6.491979198579962
Validation loss: 5.956755872978533

Epoch: 5| Step: 9
Training loss: 5.622405068226648
Validation loss: 5.937552092085659

Epoch: 5| Step: 10
Training loss: 5.613421922167398
Validation loss: 5.92142603076482

Epoch: 16| Step: 0
Training loss: 4.887459897708521
Validation loss: 5.9118209984210495

Epoch: 5| Step: 1
Training loss: 6.197356109487556
Validation loss: 5.899334700282173

Epoch: 5| Step: 2
Training loss: 5.537524269343597
Validation loss: 5.88171855213501

Epoch: 5| Step: 3
Training loss: 5.25877736549883
Validation loss: 5.86967335180746

Epoch: 5| Step: 4
Training loss: 6.041666315889897
Validation loss: 5.860527851626056

Epoch: 5| Step: 5
Training loss: 4.568707567427568
Validation loss: 5.8465253543481825

Epoch: 5| Step: 6
Training loss: 6.758035186450188
Validation loss: 5.828357028914363

Epoch: 5| Step: 7
Training loss: 6.088511871273688
Validation loss: 5.814325341316345

Epoch: 5| Step: 8
Training loss: 5.835264848910767
Validation loss: 5.804449622398638

Epoch: 5| Step: 9
Training loss: 6.870325614842071
Validation loss: 5.7856197286874576

Epoch: 5| Step: 10
Training loss: 5.910771975114323
Validation loss: 5.775511216342268

Epoch: 17| Step: 0
Training loss: 5.791077874349242
Validation loss: 5.7667020933329285

Epoch: 5| Step: 1
Training loss: 6.2010174685501145
Validation loss: 5.744090549322563

Epoch: 5| Step: 2
Training loss: 6.636411806836724
Validation loss: 5.720873771819543

Epoch: 5| Step: 3
Training loss: 4.35572908589951
Validation loss: 5.70997051596543

Epoch: 5| Step: 4
Training loss: 6.008338220658698
Validation loss: 5.692256204044223

Epoch: 5| Step: 5
Training loss: 4.501522442455081
Validation loss: 5.681222665552829

Epoch: 5| Step: 6
Training loss: 6.498008422921247
Validation loss: 5.660226893573125

Epoch: 5| Step: 7
Training loss: 5.993314196959522
Validation loss: 5.651542859180246

Epoch: 5| Step: 8
Training loss: 5.8198330470518345
Validation loss: 5.635177542026751

Epoch: 5| Step: 9
Training loss: 5.298118242855967
Validation loss: 5.6156725226442195

Epoch: 5| Step: 10
Training loss: 5.000480628755069
Validation loss: 5.602155112230287

Epoch: 18| Step: 0
Training loss: 6.186425626323273
Validation loss: 5.580444276603477

Epoch: 5| Step: 1
Training loss: 5.480557496051775
Validation loss: 5.566847625487062

Epoch: 5| Step: 2
Training loss: 4.8989450292172085
Validation loss: 5.551070727727577

Epoch: 5| Step: 3
Training loss: 5.290159216000937
Validation loss: 5.525519550888256

Epoch: 5| Step: 4
Training loss: 5.077722903251234
Validation loss: 5.5133039170162546

Epoch: 5| Step: 5
Training loss: 5.921286520995307
Validation loss: 5.4943484526249895

Epoch: 5| Step: 6
Training loss: 5.117154140218074
Validation loss: 5.480423160203406

Epoch: 5| Step: 7
Training loss: 5.490773698663652
Validation loss: 5.457967866023769

Epoch: 5| Step: 8
Training loss: 5.786210854563356
Validation loss: 5.445563276864438

Epoch: 5| Step: 9
Training loss: 4.997055521859829
Validation loss: 5.426997861019262

Epoch: 5| Step: 10
Training loss: 6.356462341182636
Validation loss: 5.414001143452805

Epoch: 19| Step: 0
Training loss: 5.82909264598183
Validation loss: 5.3865529792259075

Epoch: 5| Step: 1
Training loss: 5.716757171774498
Validation loss: 5.372369107580408

Epoch: 5| Step: 2
Training loss: 5.936594361956037
Validation loss: 5.354553190828755

Epoch: 5| Step: 3
Training loss: 5.431367243828123
Validation loss: 5.343906001402318

Epoch: 5| Step: 4
Training loss: 5.02634811916555
Validation loss: 5.308930253421359

Epoch: 5| Step: 5
Training loss: 4.2570231134648795
Validation loss: 5.2892313960375015

Epoch: 5| Step: 6
Training loss: 5.33137963194399
Validation loss: 5.2739180433058035

Epoch: 5| Step: 7
Training loss: 5.040406229814007
Validation loss: 5.251866963330808

Epoch: 5| Step: 8
Training loss: 5.654773161071435
Validation loss: 5.233811489108364

Epoch: 5| Step: 9
Training loss: 4.276966931889304
Validation loss: 5.2103259633046735

Epoch: 5| Step: 10
Training loss: 5.7704016274976
Validation loss: 5.194721424602367

Epoch: 20| Step: 0
Training loss: 4.476119360701857
Validation loss: 5.172427356215627

Epoch: 5| Step: 1
Training loss: 4.947185432877506
Validation loss: 5.157127849074069

Epoch: 5| Step: 2
Training loss: 5.351647681233578
Validation loss: 5.126230973926708

Epoch: 5| Step: 3
Training loss: 4.698998348556459
Validation loss: 5.101276569783077

Epoch: 5| Step: 4
Training loss: 5.076820745970725
Validation loss: 5.077004957594146

Epoch: 5| Step: 5
Training loss: 5.283585793673774
Validation loss: 5.06918345092438

Epoch: 5| Step: 6
Training loss: 5.021748355201478
Validation loss: 5.050395987332763

Epoch: 5| Step: 7
Training loss: 5.872325856763875
Validation loss: 5.025055671783073

Epoch: 5| Step: 8
Training loss: 4.686665575145813
Validation loss: 4.999913368705147

Epoch: 5| Step: 9
Training loss: 5.351657125931208
Validation loss: 4.980222863488041

Epoch: 5| Step: 10
Training loss: 5.228084051926088
Validation loss: 4.951106194621193

Epoch: 21| Step: 0
Training loss: 3.854243276023703
Validation loss: 4.937085374271986

Epoch: 5| Step: 1
Training loss: 4.9260660402282905
Validation loss: 4.902408646652153

Epoch: 5| Step: 2
Training loss: 4.131883368944548
Validation loss: 4.885277970886792

Epoch: 5| Step: 3
Training loss: 4.68633733953416
Validation loss: 4.851753873509942

Epoch: 5| Step: 4
Training loss: 5.3287473074655445
Validation loss: 4.846316021174921

Epoch: 5| Step: 5
Training loss: 5.2073004753871075
Validation loss: 4.814813508208078

Epoch: 5| Step: 6
Training loss: 4.955984355258341
Validation loss: 4.78950968698431

Epoch: 5| Step: 7
Training loss: 4.552828217876679
Validation loss: 4.781900137422188

Epoch: 5| Step: 8
Training loss: 5.258714981053178
Validation loss: 4.742012486290586

Epoch: 5| Step: 9
Training loss: 5.078233171924809
Validation loss: 4.721437450219839

Epoch: 5| Step: 10
Training loss: 5.309595368624207
Validation loss: 4.693723917257906

Epoch: 22| Step: 0
Training loss: 3.9207611325974345
Validation loss: 4.67655309534588

Epoch: 5| Step: 1
Training loss: 4.4943615238654475
Validation loss: 4.638942528005337

Epoch: 5| Step: 2
Training loss: 5.3651568751228265
Validation loss: 4.62647527985469

Epoch: 5| Step: 3
Training loss: 5.1366702929629815
Validation loss: 4.588352779929206

Epoch: 5| Step: 4
Training loss: 5.412808535902401
Validation loss: 4.563377272431068

Epoch: 5| Step: 5
Training loss: 4.265200192045229
Validation loss: 4.536119050834117

Epoch: 5| Step: 6
Training loss: 4.368184694053389
Validation loss: 4.525463823201494

Epoch: 5| Step: 7
Training loss: 5.058921773872389
Validation loss: 4.492484001800302

Epoch: 5| Step: 8
Training loss: 4.128557462946776
Validation loss: 4.453472067076482

Epoch: 5| Step: 9
Training loss: 3.4932339527709138
Validation loss: 4.438253630752932

Epoch: 5| Step: 10
Training loss: 4.519861682362143
Validation loss: 4.416248071065803

Epoch: 23| Step: 0
Training loss: 3.579787488629055
Validation loss: 4.394580887563153

Epoch: 5| Step: 1
Training loss: 3.828127615791517
Validation loss: 4.341706742115169

Epoch: 5| Step: 2
Training loss: 4.300787680583862
Validation loss: 4.32537332830167

Epoch: 5| Step: 3
Training loss: 4.03443345338536
Validation loss: 4.312532060696304

Epoch: 5| Step: 4
Training loss: 4.656964752843693
Validation loss: 4.2569754503368635

Epoch: 5| Step: 5
Training loss: 3.856791384391285
Validation loss: 4.252841323004813

Epoch: 5| Step: 6
Training loss: 5.444041209090844
Validation loss: 4.224833291163912

Epoch: 5| Step: 7
Training loss: 4.6006094653200655
Validation loss: 4.1891471342777455

Epoch: 5| Step: 8
Training loss: 4.764061843406605
Validation loss: 4.162004943496233

Epoch: 5| Step: 9
Training loss: 3.764921130485261
Validation loss: 4.150655836324051

Epoch: 5| Step: 10
Training loss: 4.347899506405116
Validation loss: 4.1133018037925835

Epoch: 24| Step: 0
Training loss: 3.8411227295606376
Validation loss: 4.0810520654720515

Epoch: 5| Step: 1
Training loss: 4.004027723004899
Validation loss: 4.046307961992893

Epoch: 5| Step: 2
Training loss: 4.281194310626627
Validation loss: 4.032786272543602

Epoch: 5| Step: 3
Training loss: 4.094329560001055
Validation loss: 4.008492678069006

Epoch: 5| Step: 4
Training loss: 2.761951657932194
Validation loss: 3.9514051551026763

Epoch: 5| Step: 5
Training loss: 5.0281853671625765
Validation loss: 3.950798945991076

Epoch: 5| Step: 6
Training loss: 3.7415799023962624
Validation loss: 3.934136561838163

Epoch: 5| Step: 7
Training loss: 4.506483070388292
Validation loss: 3.893801803637984

Epoch: 5| Step: 8
Training loss: 4.781341152942884
Validation loss: 3.869665118161545

Epoch: 5| Step: 9
Training loss: 2.8996459415950917
Validation loss: 3.824687404273276

Epoch: 5| Step: 10
Training loss: 4.145440522311644
Validation loss: 3.793424844843853

Epoch: 25| Step: 0
Training loss: 4.405785285846934
Validation loss: 3.795681048183275

Epoch: 5| Step: 1
Training loss: 2.980909002543572
Validation loss: 3.752738641722191

Epoch: 5| Step: 2
Training loss: 3.8829127093457094
Validation loss: 3.7386439918046928

Epoch: 5| Step: 3
Training loss: 4.351717441067336
Validation loss: 3.7083351344488698

Epoch: 5| Step: 4
Training loss: 3.3614555126391528
Validation loss: 3.681115534455307

Epoch: 5| Step: 5
Training loss: 3.6711017200215412
Validation loss: 3.6605773607186105

Epoch: 5| Step: 6
Training loss: 4.073085199301812
Validation loss: 3.6198102507782215

Epoch: 5| Step: 7
Training loss: 3.6387241623910245
Validation loss: 3.594486726395518

Epoch: 5| Step: 8
Training loss: 3.1555800529508127
Validation loss: 3.5932243772443995

Epoch: 5| Step: 9
Training loss: 3.904097062952345
Validation loss: 3.544246096680402

Epoch: 5| Step: 10
Training loss: 4.116713321025024
Validation loss: 3.5259321010375975

Epoch: 26| Step: 0
Training loss: 3.391387994238616
Validation loss: 3.4811293339699256

Epoch: 5| Step: 1
Training loss: 3.212534115383817
Validation loss: 3.478501144537217

Epoch: 5| Step: 2
Training loss: 3.6788453517303825
Validation loss: 3.4534771703058156

Epoch: 5| Step: 3
Training loss: 4.118564556386964
Validation loss: 3.4438092462509067

Epoch: 5| Step: 4
Training loss: 3.826280297324843
Validation loss: 3.3961250612194895

Epoch: 5| Step: 5
Training loss: 4.02911343991384
Validation loss: 3.3722997883188706

Epoch: 5| Step: 6
Training loss: 2.6150930649952833
Validation loss: 3.3733263366510253

Epoch: 5| Step: 7
Training loss: 4.058321168060138
Validation loss: 3.3453472463888483

Epoch: 5| Step: 8
Training loss: 3.7275054186571164
Validation loss: 3.331595534410218

Epoch: 5| Step: 9
Training loss: 3.1167972482943282
Validation loss: 3.297029662002507

Epoch: 5| Step: 10
Training loss: 3.2138125873704464
Validation loss: 3.27349050259018

Epoch: 27| Step: 0
Training loss: 3.6855653763363785
Validation loss: 3.2479232340212856

Epoch: 5| Step: 1
Training loss: 3.932357821213326
Validation loss: 3.2475835132127084

Epoch: 5| Step: 2
Training loss: 3.1205733418023334
Validation loss: 3.2017335556186874

Epoch: 5| Step: 3
Training loss: 3.069264473297056
Validation loss: 3.1914930094988487

Epoch: 5| Step: 4
Training loss: 3.281788518402214
Validation loss: 3.187002499075823

Epoch: 5| Step: 5
Training loss: 4.131090926947033
Validation loss: 3.1635543238927997

Epoch: 5| Step: 6
Training loss: 3.2408448897888356
Validation loss: 3.147993206192743

Epoch: 5| Step: 7
Training loss: 3.1788795438194524
Validation loss: 3.1168764267419022

Epoch: 5| Step: 8
Training loss: 3.9202607620857344
Validation loss: 3.137104052288376

Epoch: 5| Step: 9
Training loss: 2.468145562069621
Validation loss: 3.093137310634318

Epoch: 5| Step: 10
Training loss: 2.967248315976361
Validation loss: 3.077802360603035

Epoch: 28| Step: 0
Training loss: 3.1415337154140186
Validation loss: 3.049302360622977

Epoch: 5| Step: 1
Training loss: 3.7644301928876334
Validation loss: 3.04239062314425

Epoch: 5| Step: 2
Training loss: 3.867046438399503
Validation loss: 3.036717657789434

Epoch: 5| Step: 3
Training loss: 3.5590028161308123
Validation loss: 3.0175566597149297

Epoch: 5| Step: 4
Training loss: 2.845419927891143
Validation loss: 3.0240070738915046

Epoch: 5| Step: 5
Training loss: 3.4287548839215836
Validation loss: 3.0088659488629537

Epoch: 5| Step: 6
Training loss: 2.798822247218837
Validation loss: 2.9894015449260114

Epoch: 5| Step: 7
Training loss: 2.862383651034649
Validation loss: 2.9860628107134013

Epoch: 5| Step: 8
Training loss: 3.168829296556975
Validation loss: 2.9641278790052366

Epoch: 5| Step: 9
Training loss: 2.9223927737781854
Validation loss: 2.9534680055058025

Epoch: 5| Step: 10
Training loss: 3.657942551325987
Validation loss: 2.9735546995783317

Epoch: 29| Step: 0
Training loss: 3.2891602127892017
Validation loss: 2.942871264057062

Epoch: 5| Step: 1
Training loss: 2.589069325467438
Validation loss: 2.9240482993889185

Epoch: 5| Step: 2
Training loss: 3.2470281658448914
Validation loss: 2.9172887153439873

Epoch: 5| Step: 3
Training loss: 3.0545710470729293
Validation loss: 2.92632718143918

Epoch: 5| Step: 4
Training loss: 2.924808111172871
Validation loss: 2.9160071463807427

Epoch: 5| Step: 5
Training loss: 2.9134619045329972
Validation loss: 2.9153659158490823

Epoch: 5| Step: 6
Training loss: 2.9786609851825094
Validation loss: 2.9376529085659615

Epoch: 5| Step: 7
Training loss: 3.6569200211568336
Validation loss: 2.879178609874153

Epoch: 5| Step: 8
Training loss: 3.18703307677509
Validation loss: 2.9103135840464804

Epoch: 5| Step: 9
Training loss: 3.4166033824239137
Validation loss: 2.915054880303597

Epoch: 5| Step: 10
Training loss: 3.944879066151156
Validation loss: 2.8736732055458614

Epoch: 30| Step: 0
Training loss: 3.323652243839008
Validation loss: 2.8935794541663915

Epoch: 5| Step: 1
Training loss: 3.0644346082236136
Validation loss: 2.8975953231664473

Epoch: 5| Step: 2
Training loss: 3.1739538737108086
Validation loss: 2.8896629623876833

Epoch: 5| Step: 3
Training loss: 3.061500230424403
Validation loss: 2.876133538806018

Epoch: 5| Step: 4
Training loss: 2.9689660244697254
Validation loss: 2.844181461230551

Epoch: 5| Step: 5
Training loss: 3.4344460532949364
Validation loss: 2.8541013331278893

Epoch: 5| Step: 6
Training loss: 3.9627001450109773
Validation loss: 2.8579648043429176

Epoch: 5| Step: 7
Training loss: 2.2353101787344434
Validation loss: 2.8602612800326064

Epoch: 5| Step: 8
Training loss: 3.5062405944806865
Validation loss: 2.846248541023882

Epoch: 5| Step: 9
Training loss: 3.098311019524356
Validation loss: 2.8367239587233026

Epoch: 5| Step: 10
Training loss: 2.728857085939716
Validation loss: 2.858571755218914

Epoch: 31| Step: 0
Training loss: 2.696780924299972
Validation loss: 2.855324972643889

Epoch: 5| Step: 1
Training loss: 3.330988122548412
Validation loss: 2.800304737808917

Epoch: 5| Step: 2
Training loss: 2.8021053232986954
Validation loss: 2.8331828056272523

Epoch: 5| Step: 3
Training loss: 3.3527323497386985
Validation loss: 2.849712026396709

Epoch: 5| Step: 4
Training loss: 3.303634295362475
Validation loss: 2.851363976446051

Epoch: 5| Step: 5
Training loss: 3.0064036054487064
Validation loss: 2.837041435864927

Epoch: 5| Step: 6
Training loss: 2.9630895358000857
Validation loss: 2.8341912021064544

Epoch: 5| Step: 7
Training loss: 2.9802546793002795
Validation loss: 2.7871455200361743

Epoch: 5| Step: 8
Training loss: 3.120115812059556
Validation loss: 2.831656496955254

Epoch: 5| Step: 9
Training loss: 3.770580149769067
Validation loss: 2.837794608713908

Epoch: 5| Step: 10
Training loss: 3.251824087154597
Validation loss: 2.852704380383643

Epoch: 32| Step: 0
Training loss: 3.5541876472906324
Validation loss: 2.819168261841836

Epoch: 5| Step: 1
Training loss: 2.9598850604242815
Validation loss: 2.837328606335513

Epoch: 5| Step: 2
Training loss: 2.83524332929788
Validation loss: 2.8190635251947076

Epoch: 5| Step: 3
Training loss: 3.2517818554748876
Validation loss: 2.8256064312651077

Epoch: 5| Step: 4
Training loss: 3.1636335670873383
Validation loss: 2.7808791131400987

Epoch: 5| Step: 5
Training loss: 2.92259150405053
Validation loss: 2.8163057681724477

Epoch: 5| Step: 6
Training loss: 3.3553372980199603
Validation loss: 2.8034186270400414

Epoch: 5| Step: 7
Training loss: 3.0806809091322007
Validation loss: 2.7980928430624297

Epoch: 5| Step: 8
Training loss: 3.256197082909605
Validation loss: 2.8102448987811988

Epoch: 5| Step: 9
Training loss: 3.11224278992026
Validation loss: 2.846096435193232

Epoch: 5| Step: 10
Training loss: 3.250068223677332
Validation loss: 2.799120210536478

Epoch: 33| Step: 0
Training loss: 3.507188771280009
Validation loss: 2.820672085098591

Epoch: 5| Step: 1
Training loss: 3.1097155820559763
Validation loss: 2.8207414005696885

Epoch: 5| Step: 2
Training loss: 3.303156937920262
Validation loss: 2.8213450491725327

Epoch: 5| Step: 3
Training loss: 2.6176839329201793
Validation loss: 2.8048257200992097

Epoch: 5| Step: 4
Training loss: 2.975348277502404
Validation loss: 2.7983965272913873

Epoch: 5| Step: 5
Training loss: 3.3916303840464845
Validation loss: 2.8220764748521585

Epoch: 5| Step: 6
Training loss: 3.8163760134261526
Validation loss: 2.8382188116466893

Epoch: 5| Step: 7
Training loss: 2.535358344488416
Validation loss: 2.789947364802555

Epoch: 5| Step: 8
Training loss: 3.412558077922319
Validation loss: 2.818956468341558

Epoch: 5| Step: 9
Training loss: 2.9998529716066624
Validation loss: 2.8312164091679035

Epoch: 5| Step: 10
Training loss: 2.8941108099675614
Validation loss: 2.8251431044765374

Epoch: 34| Step: 0
Training loss: 3.1081979335172494
Validation loss: 2.788005320229339

Epoch: 5| Step: 1
Training loss: 3.8943737920307115
Validation loss: 2.844273247371627

Epoch: 5| Step: 2
Training loss: 2.9469096662114613
Validation loss: 2.804467601566702

Epoch: 5| Step: 3
Training loss: 3.1546268633021373
Validation loss: 2.802000951617621

Epoch: 5| Step: 4
Training loss: 2.930413646988434
Validation loss: 2.781504395535869

Epoch: 5| Step: 5
Training loss: 3.3298850979613395
Validation loss: 2.805411002435004

Epoch: 5| Step: 6
Training loss: 3.059283377314832
Validation loss: 2.8003903527793286

Epoch: 5| Step: 7
Training loss: 2.7734342333277415
Validation loss: 2.8059405486037035

Epoch: 5| Step: 8
Training loss: 3.00569486508682
Validation loss: 2.7902886747654283

Epoch: 5| Step: 9
Training loss: 3.673177155453333
Validation loss: 2.803031294129818

Epoch: 5| Step: 10
Training loss: 2.564026168761114
Validation loss: 2.812599982486421

Epoch: 35| Step: 0
Training loss: 2.396574906284614
Validation loss: 2.789076647009238

Epoch: 5| Step: 1
Training loss: 3.820222256770604
Validation loss: 2.803635977024445

Epoch: 5| Step: 2
Training loss: 3.3303338542753664
Validation loss: 2.8265173800544643

Epoch: 5| Step: 3
Training loss: 2.164279307167537
Validation loss: 2.8399165821317722

Epoch: 5| Step: 4
Training loss: 2.9208215456591855
Validation loss: 2.777764182587309

Epoch: 5| Step: 5
Training loss: 3.6953282426494742
Validation loss: 2.8111932888771007

Epoch: 5| Step: 6
Training loss: 3.4450992163557013
Validation loss: 2.8320420892074507

Epoch: 5| Step: 7
Training loss: 3.088995777387811
Validation loss: 2.7732685523517033

Epoch: 5| Step: 8
Training loss: 3.5309584505698846
Validation loss: 2.774184276398858

Epoch: 5| Step: 9
Training loss: 2.6535501559563146
Validation loss: 2.7942697482799885

Epoch: 5| Step: 10
Training loss: 3.2843915160369104
Validation loss: 2.793499370883255

Epoch: 36| Step: 0
Training loss: 2.6679577582874328
Validation loss: 2.7992154368865445

Epoch: 5| Step: 1
Training loss: 3.599712699446261
Validation loss: 2.8217841099432235

Epoch: 5| Step: 2
Training loss: 3.3753058683466035
Validation loss: 2.8065425402864483

Epoch: 5| Step: 3
Training loss: 2.6203839723942677
Validation loss: 2.8178232512376047

Epoch: 5| Step: 4
Training loss: 3.535064932133759
Validation loss: 2.8154447528099316

Epoch: 5| Step: 5
Training loss: 2.812227108749886
Validation loss: 2.797303814536829

Epoch: 5| Step: 6
Training loss: 3.5015364408055305
Validation loss: 2.7992384345146313

Epoch: 5| Step: 7
Training loss: 3.10602285372057
Validation loss: 2.8324215566200692

Epoch: 5| Step: 8
Training loss: 2.584768624640516
Validation loss: 2.8315504485902743

Epoch: 5| Step: 9
Training loss: 3.2975669966247847
Validation loss: 2.7877948973792632

Epoch: 5| Step: 10
Training loss: 3.4983087268077244
Validation loss: 2.797093840989477

Epoch: 37| Step: 0
Training loss: 3.2686178556321366
Validation loss: 2.795548313708788

Epoch: 5| Step: 1
Training loss: 3.750653273582843
Validation loss: 2.7948068568866047

Epoch: 5| Step: 2
Training loss: 3.359673349306162
Validation loss: 2.778778855063987

Epoch: 5| Step: 3
Training loss: 2.423214449723372
Validation loss: 2.790841030251246

Epoch: 5| Step: 4
Training loss: 3.5620071337894585
Validation loss: 2.794970800659018

Epoch: 5| Step: 5
Training loss: 2.376230222408017
Validation loss: 2.8017133563132814

Epoch: 5| Step: 6
Training loss: 2.2984025507797603
Validation loss: 2.790426823498478

Epoch: 5| Step: 7
Training loss: 3.867514979821103
Validation loss: 2.797929609076646

Epoch: 5| Step: 8
Training loss: 3.2006615074204596
Validation loss: 2.7962356288463472

Epoch: 5| Step: 9
Training loss: 3.0186335128518182
Validation loss: 2.8282174595166194

Epoch: 5| Step: 10
Training loss: 3.244428995028891
Validation loss: 2.7765351091469896

Epoch: 38| Step: 0
Training loss: 3.38907879851429
Validation loss: 2.8003214307364366

Epoch: 5| Step: 1
Training loss: 3.475204099520659
Validation loss: 2.802822882925631

Epoch: 5| Step: 2
Training loss: 3.590091999755915
Validation loss: 2.8013915094488318

Epoch: 5| Step: 3
Training loss: 2.81163206483556
Validation loss: 2.7992148067867912

Epoch: 5| Step: 4
Training loss: 2.563382903795004
Validation loss: 2.8052437976375213

Epoch: 5| Step: 5
Training loss: 2.913143882469292
Validation loss: 2.787326138853411

Epoch: 5| Step: 6
Training loss: 3.35286233945111
Validation loss: 2.806333830769575

Epoch: 5| Step: 7
Training loss: 2.612885449461816
Validation loss: 2.798792370826011

Epoch: 5| Step: 8
Training loss: 3.5742350260046085
Validation loss: 2.7940259896024155

Epoch: 5| Step: 9
Training loss: 3.5340013166510436
Validation loss: 2.769061732781877

Epoch: 5| Step: 10
Training loss: 2.3590996183647897
Validation loss: 2.801867862432555

Epoch: 39| Step: 0
Training loss: 3.4182239023067624
Validation loss: 2.7960110854720823

Epoch: 5| Step: 1
Training loss: 3.019731482890452
Validation loss: 2.8026931604738916

Epoch: 5| Step: 2
Training loss: 3.518709855333416
Validation loss: 2.792263236024842

Epoch: 5| Step: 3
Training loss: 3.424844228724546
Validation loss: 2.8070177889858483

Epoch: 5| Step: 4
Training loss: 2.9768184842149625
Validation loss: 2.7972060338945735

Epoch: 5| Step: 5
Training loss: 3.1636133699368765
Validation loss: 2.7639440219515667

Epoch: 5| Step: 6
Training loss: 3.466707057595313
Validation loss: 2.7875081126255368

Epoch: 5| Step: 7
Training loss: 2.8431997919716916
Validation loss: 2.7970847434261565

Epoch: 5| Step: 8
Training loss: 3.1180972346914126
Validation loss: 2.8034438443356415

Epoch: 5| Step: 9
Training loss: 2.8813472838951846
Validation loss: 2.8034999825469282

Epoch: 5| Step: 10
Training loss: 2.593803037537793
Validation loss: 2.7992974759451528

Epoch: 40| Step: 0
Training loss: 3.057050254600875
Validation loss: 2.739664557466398

Epoch: 5| Step: 1
Training loss: 3.0243818991468667
Validation loss: 2.7901738763678874

Epoch: 5| Step: 2
Training loss: 3.328732000883161
Validation loss: 2.8015991459271388

Epoch: 5| Step: 3
Training loss: 3.305762005796068
Validation loss: 2.7913402984320324

Epoch: 5| Step: 4
Training loss: 3.0173432984074475
Validation loss: 2.7897009751398247

Epoch: 5| Step: 5
Training loss: 3.6500243303716053
Validation loss: 2.8138749566163317

Epoch: 5| Step: 6
Training loss: 2.597674606373112
Validation loss: 2.8059685855652083

Epoch: 5| Step: 7
Training loss: 3.09589858536133
Validation loss: 2.8000724143671247

Epoch: 5| Step: 8
Training loss: 3.3864074352753226
Validation loss: 2.7769788719849196

Epoch: 5| Step: 9
Training loss: 2.925105303311562
Validation loss: 2.8163742435221586

Epoch: 5| Step: 10
Training loss: 3.1083539503571154
Validation loss: 2.7959992602889256

Epoch: 41| Step: 0
Training loss: 3.815356950771998
Validation loss: 2.80335066101914

Epoch: 5| Step: 1
Training loss: 3.0727288829949044
Validation loss: 2.8061801250798974

Epoch: 5| Step: 2
Training loss: 3.696575053954214
Validation loss: 2.7989761838571168

Epoch: 5| Step: 3
Training loss: 2.7520064923409464
Validation loss: 2.809012053428972

Epoch: 5| Step: 4
Training loss: 2.9977946122493857
Validation loss: 2.784851758048553

Epoch: 5| Step: 5
Training loss: 2.759431963253789
Validation loss: 2.8011755310867845

Epoch: 5| Step: 6
Training loss: 3.8967266724477385
Validation loss: 2.786475897062692

Epoch: 5| Step: 7
Training loss: 2.71269402227564
Validation loss: 2.799154854161365

Epoch: 5| Step: 8
Training loss: 3.280957308839412
Validation loss: 2.7833256863297486

Epoch: 5| Step: 9
Training loss: 2.658934190662386
Validation loss: 2.791678803450739

Epoch: 5| Step: 10
Training loss: 2.1948035250866784
Validation loss: 2.788966031679866

Epoch: 42| Step: 0
Training loss: 2.9857503707592934
Validation loss: 2.7798205734280996

Epoch: 5| Step: 1
Training loss: 3.727113183237673
Validation loss: 2.7892309744443065

Epoch: 5| Step: 2
Training loss: 2.92999640298564
Validation loss: 2.8065213609188797

Epoch: 5| Step: 3
Training loss: 2.613422840428065
Validation loss: 2.804555317116461

Epoch: 5| Step: 4
Training loss: 3.3425792890686883
Validation loss: 2.7898750990788894

Epoch: 5| Step: 5
Training loss: 3.0612958759625877
Validation loss: 2.8001252180071807

Epoch: 5| Step: 6
Training loss: 3.4717397091769953
Validation loss: 2.787701009805839

Epoch: 5| Step: 7
Training loss: 3.0359066461476605
Validation loss: 2.7847011161896806

Epoch: 5| Step: 8
Training loss: 3.077411704512782
Validation loss: 2.8002685886833785

Epoch: 5| Step: 9
Training loss: 2.860959140564488
Validation loss: 2.8050276616590284

Epoch: 5| Step: 10
Training loss: 3.3087078916999695
Validation loss: 2.799441009894845

Epoch: 43| Step: 0
Training loss: 3.30498443784527
Validation loss: 2.8189322910691064

Epoch: 5| Step: 1
Training loss: 3.2823057383618317
Validation loss: 2.7884231606249683

Epoch: 5| Step: 2
Training loss: 2.7532620589642445
Validation loss: 2.7955488144147336

Epoch: 5| Step: 3
Training loss: 3.0192195045451693
Validation loss: 2.771618913907539

Epoch: 5| Step: 4
Training loss: 3.837253321569224
Validation loss: 2.798782783236459

Epoch: 5| Step: 5
Training loss: 2.686520242637141
Validation loss: 2.792384440298326

Epoch: 5| Step: 6
Training loss: 3.141184894510972
Validation loss: 2.7755846857466056

Epoch: 5| Step: 7
Training loss: 3.0230494996919735
Validation loss: 2.792955740701794

Epoch: 5| Step: 8
Training loss: 2.743151894552935
Validation loss: 2.8134553879481796

Epoch: 5| Step: 9
Training loss: 2.9332532011993426
Validation loss: 2.8025387840115377

Epoch: 5| Step: 10
Training loss: 3.4458816992345556
Validation loss: 2.7688379670641092

Epoch: 44| Step: 0
Training loss: 3.737968726731989
Validation loss: 2.7704535773120185

Epoch: 5| Step: 1
Training loss: 3.0355400323944077
Validation loss: 2.781329410198666

Epoch: 5| Step: 2
Training loss: 3.643220950106703
Validation loss: 2.767069911949963

Epoch: 5| Step: 3
Training loss: 2.34317843779453
Validation loss: 2.7649292429602497

Epoch: 5| Step: 4
Training loss: 3.9075394600250464
Validation loss: 2.79316340217866

Epoch: 5| Step: 5
Training loss: 2.6322527100720015
Validation loss: 2.792983989701249

Epoch: 5| Step: 6
Training loss: 2.9364885252642807
Validation loss: 2.7614713938846474

Epoch: 5| Step: 7
Training loss: 3.271047953632875
Validation loss: 2.8075094247961006

Epoch: 5| Step: 8
Training loss: 2.9400008898363907
Validation loss: 2.7837126133456325

Epoch: 5| Step: 9
Training loss: 3.1699862564703554
Validation loss: 2.798906406305427

Epoch: 5| Step: 10
Training loss: 2.269677792675043
Validation loss: 2.7805837506338387

Epoch: 45| Step: 0
Training loss: 3.163784740171353
Validation loss: 2.7716158846571517

Epoch: 5| Step: 1
Training loss: 3.3341311135875826
Validation loss: 2.7530984380733017

Epoch: 5| Step: 2
Training loss: 2.94835992902107
Validation loss: 2.7829066153615876

Epoch: 5| Step: 3
Training loss: 2.369726349206442
Validation loss: 2.778764545840149

Epoch: 5| Step: 4
Training loss: 3.070553835636813
Validation loss: 2.7738459044765578

Epoch: 5| Step: 5
Training loss: 3.4555436031575053
Validation loss: 2.798860101305563

Epoch: 5| Step: 6
Training loss: 2.913703630455639
Validation loss: 2.7824336187230965

Epoch: 5| Step: 7
Training loss: 3.248282785846043
Validation loss: 2.7834961676706333

Epoch: 5| Step: 8
Training loss: 3.4076321098931017
Validation loss: 2.7862727259332005

Epoch: 5| Step: 9
Training loss: 3.4737348050900128
Validation loss: 2.7897094884288194

Epoch: 5| Step: 10
Training loss: 2.681595370583874
Validation loss: 2.797518064736812

Epoch: 46| Step: 0
Training loss: 3.257493110936361
Validation loss: 2.7373482183023317

Epoch: 5| Step: 1
Training loss: 2.8596496450132
Validation loss: 2.804033964514041

Epoch: 5| Step: 2
Training loss: 3.3909783948267984
Validation loss: 2.77722370873705

Epoch: 5| Step: 3
Training loss: 2.818859032258246
Validation loss: 2.8005812074335354

Epoch: 5| Step: 4
Training loss: 3.0715981623571946
Validation loss: 2.766608940389104

Epoch: 5| Step: 5
Training loss: 2.376381121152748
Validation loss: 2.80073153429539

Epoch: 5| Step: 6
Training loss: 3.3038923601069166
Validation loss: 2.7983250358576917

Epoch: 5| Step: 7
Training loss: 3.376460006831767
Validation loss: 2.7429087191491686

Epoch: 5| Step: 8
Training loss: 3.2937445218874926
Validation loss: 2.790492370229556

Epoch: 5| Step: 9
Training loss: 3.607467477589739
Validation loss: 2.789711945735599

Epoch: 5| Step: 10
Training loss: 2.7374348985429746
Validation loss: 2.7729668783686243

Epoch: 47| Step: 0
Training loss: 2.4968654054688937
Validation loss: 2.7896684343603066

Epoch: 5| Step: 1
Training loss: 3.694134837078777
Validation loss: 2.770550166490741

Epoch: 5| Step: 2
Training loss: 3.3266966714314936
Validation loss: 2.7754313203480367

Epoch: 5| Step: 3
Training loss: 3.2058101657248126
Validation loss: 2.7922367957982863

Epoch: 5| Step: 4
Training loss: 3.114349526567757
Validation loss: 2.7711637233510285

Epoch: 5| Step: 5
Training loss: 3.221694932377162
Validation loss: 2.763540409395942

Epoch: 5| Step: 6
Training loss: 3.805514204693182
Validation loss: 2.795128648404958

Epoch: 5| Step: 7
Training loss: 2.7512656680488132
Validation loss: 2.781788016150119

Epoch: 5| Step: 8
Training loss: 2.1580804988494195
Validation loss: 2.7652139155982467

Epoch: 5| Step: 9
Training loss: 3.256939594958359
Validation loss: 2.7708589030056023

Epoch: 5| Step: 10
Training loss: 2.9373972448679315
Validation loss: 2.777046162401655

Epoch: 48| Step: 0
Training loss: 3.1090497177433334
Validation loss: 2.7665485119142

Epoch: 5| Step: 1
Training loss: 3.4899368031198654
Validation loss: 2.797525128325541

Epoch: 5| Step: 2
Training loss: 3.002115139780618
Validation loss: 2.736110874822382

Epoch: 5| Step: 3
Training loss: 3.4036149498088792
Validation loss: 2.7690916846071842

Epoch: 5| Step: 4
Training loss: 3.3344637543468267
Validation loss: 2.7938749817029866

Epoch: 5| Step: 5
Training loss: 2.176158495649445
Validation loss: 2.777207634841587

Epoch: 5| Step: 6
Training loss: 3.351625384116504
Validation loss: 2.797151598736186

Epoch: 5| Step: 7
Training loss: 2.557044012712096
Validation loss: 2.7538475647678355

Epoch: 5| Step: 8
Training loss: 3.2564504140730297
Validation loss: 2.76803973628535

Epoch: 5| Step: 9
Training loss: 3.002116569283886
Validation loss: 2.793011040585741

Epoch: 5| Step: 10
Training loss: 3.3441549751108415
Validation loss: 2.7855341031289216

Epoch: 49| Step: 0
Training loss: 3.0356847040353934
Validation loss: 2.785346912408877

Epoch: 5| Step: 1
Training loss: 3.1387493548892023
Validation loss: 2.7789838932593773

Epoch: 5| Step: 2
Training loss: 3.104625659436173
Validation loss: 2.759088904511647

Epoch: 5| Step: 3
Training loss: 3.0718296175735165
Validation loss: 2.779558733780886

Epoch: 5| Step: 4
Training loss: 3.68237077267435
Validation loss: 2.7639432984781744

Epoch: 5| Step: 5
Training loss: 2.5921613125113505
Validation loss: 2.793833454797308

Epoch: 5| Step: 6
Training loss: 2.342713800890083
Validation loss: 2.7623900876117684

Epoch: 5| Step: 7
Training loss: 3.066586162367388
Validation loss: 2.7922599179269487

Epoch: 5| Step: 8
Training loss: 3.1631444281987853
Validation loss: 2.7756870093017856

Epoch: 5| Step: 9
Training loss: 3.3915460276100426
Validation loss: 2.7661360272062248

Epoch: 5| Step: 10
Training loss: 3.278656143200546
Validation loss: 2.792366557820731

Epoch: 50| Step: 0
Training loss: 2.7759291940393265
Validation loss: 2.766789239430903

Epoch: 5| Step: 1
Training loss: 3.072556469167912
Validation loss: 2.7846096330667525

Epoch: 5| Step: 2
Training loss: 3.5258230181941124
Validation loss: 2.754978889554331

Epoch: 5| Step: 3
Training loss: 3.1098476031580975
Validation loss: 2.77339545817027

Epoch: 5| Step: 4
Training loss: 3.8691965760562024
Validation loss: 2.7719182356176186

Epoch: 5| Step: 5
Training loss: 3.042938349795996
Validation loss: 2.7737233106082777

Epoch: 5| Step: 6
Training loss: 2.5621312504128357
Validation loss: 2.756100524550338

Epoch: 5| Step: 7
Training loss: 2.73872030223796
Validation loss: 2.760021329227845

Epoch: 5| Step: 8
Training loss: 3.4324295101165507
Validation loss: 2.768542142224236

Epoch: 5| Step: 9
Training loss: 3.0414204606695048
Validation loss: 2.762383024201749

Epoch: 5| Step: 10
Training loss: 2.7026020051265434
Validation loss: 2.7753979259502692

Testing loss: 2.805754231719301
