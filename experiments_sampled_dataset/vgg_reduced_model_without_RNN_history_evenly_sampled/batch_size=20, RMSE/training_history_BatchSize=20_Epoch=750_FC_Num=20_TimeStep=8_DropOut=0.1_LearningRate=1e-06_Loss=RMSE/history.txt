Epoch: 1| Step: 0
Training loss: 3.403527247788745
Validation loss: 3.471586490200123

Epoch: 5| Step: 1
Training loss: 2.9530432957240738
Validation loss: 3.46761308637187

Epoch: 5| Step: 2
Training loss: 3.0522188714216583
Validation loss: 3.463866407424614

Epoch: 5| Step: 3
Training loss: 4.090259024478658
Validation loss: 3.4641075267264427

Epoch: 5| Step: 4
Training loss: 3.7423475386577416
Validation loss: 3.457299548074078

Epoch: 5| Step: 5
Training loss: 3.559553835481412
Validation loss: 3.455976749025106

Epoch: 5| Step: 6
Training loss: 4.424760396041568
Validation loss: 3.450434850579968

Epoch: 5| Step: 7
Training loss: 3.7967222834513787
Validation loss: 3.4461993533383315

Epoch: 5| Step: 8
Training loss: 3.6643339597436086
Validation loss: 3.4442332432966505

Epoch: 5| Step: 9
Training loss: 3.2999910932478493
Validation loss: 3.4356336462285357

Epoch: 5| Step: 10
Training loss: 4.213695521742307
Validation loss: 3.43228911320184

Epoch: 2| Step: 0
Training loss: 3.5983114733141677
Validation loss: 3.4283740216438576

Epoch: 5| Step: 1
Training loss: 2.665935227296214
Validation loss: 3.4270482833710196

Epoch: 5| Step: 2
Training loss: 3.970849990943215
Validation loss: 3.422764467230162

Epoch: 5| Step: 3
Training loss: 3.88687259235421
Validation loss: 3.422503687965964

Epoch: 5| Step: 4
Training loss: 3.2658367179612315
Validation loss: 3.419236279109881

Epoch: 5| Step: 5
Training loss: 3.8132120937023184
Validation loss: 3.411077379894724

Epoch: 5| Step: 6
Training loss: 2.982536348695362
Validation loss: 3.4085392337354667

Epoch: 5| Step: 7
Training loss: 3.916539183361337
Validation loss: 3.4011791485196325

Epoch: 5| Step: 8
Training loss: 4.032953419933525
Validation loss: 3.4012836107109097

Epoch: 5| Step: 9
Training loss: 3.9543738522263405
Validation loss: 3.3938291307302935

Epoch: 5| Step: 10
Training loss: 3.5946732371757895
Validation loss: 3.3940619438539663

Epoch: 3| Step: 0
Training loss: 4.271930882298397
Validation loss: 3.387841182128648

Epoch: 5| Step: 1
Training loss: 3.3162099827358893
Validation loss: 3.382415833864238

Epoch: 5| Step: 2
Training loss: 3.553711340040167
Validation loss: 3.3826626718867865

Epoch: 5| Step: 3
Training loss: 4.032887680612193
Validation loss: 3.374802119121787

Epoch: 5| Step: 4
Training loss: 3.913097513903827
Validation loss: 3.3732363514778823

Epoch: 5| Step: 5
Training loss: 3.0505761774865476
Validation loss: 3.3689341998132463

Epoch: 5| Step: 6
Training loss: 3.556252606597106
Validation loss: 3.366645968347272

Epoch: 5| Step: 7
Training loss: 3.402594048001196
Validation loss: 3.361520217438792

Epoch: 5| Step: 8
Training loss: 4.023355486876508
Validation loss: 3.353434918077403

Epoch: 5| Step: 9
Training loss: 2.734417985850736
Validation loss: 3.3474039088501506

Epoch: 5| Step: 10
Training loss: 3.402273534319594
Validation loss: 3.3492474082983024

Epoch: 4| Step: 0
Training loss: 4.024605413014889
Validation loss: 3.3407733292591852

Epoch: 5| Step: 1
Training loss: 3.3714248653742485
Validation loss: 3.3370297491981047

Epoch: 5| Step: 2
Training loss: 3.182166930072904
Validation loss: 3.33768358360539

Epoch: 5| Step: 3
Training loss: 3.872611755768074
Validation loss: 3.3336632508908175

Epoch: 5| Step: 4
Training loss: 4.415823418113652
Validation loss: 3.325550139186092

Epoch: 5| Step: 5
Training loss: 3.259492655867969
Validation loss: 3.3222300762384065

Epoch: 5| Step: 6
Training loss: 3.642608233370875
Validation loss: 3.319807300485575

Epoch: 5| Step: 7
Training loss: 4.11611675548391
Validation loss: 3.3159407725717682

Epoch: 5| Step: 8
Training loss: 2.992397211360257
Validation loss: 3.313226322623939

Epoch: 5| Step: 9
Training loss: 3.259243365049942
Validation loss: 3.306825749208961

Epoch: 5| Step: 10
Training loss: 2.44310409712614
Validation loss: 3.3000655640384386

Epoch: 5| Step: 0
Training loss: 3.3243980493838383
Validation loss: 3.304801730070651

Epoch: 5| Step: 1
Training loss: 3.8516434666787607
Validation loss: 3.2945496465433775

Epoch: 5| Step: 2
Training loss: 3.690915352610612
Validation loss: 3.2900830565620134

Epoch: 5| Step: 3
Training loss: 3.2256307295652467
Validation loss: 3.2890023154461585

Epoch: 5| Step: 4
Training loss: 3.6567841490167288
Validation loss: 3.2812439714836374

Epoch: 5| Step: 5
Training loss: 2.969366712259535
Validation loss: 3.282185828012747

Epoch: 5| Step: 6
Training loss: 3.507854639832491
Validation loss: 3.2754107707935693

Epoch: 5| Step: 7
Training loss: 3.5733538805907004
Validation loss: 3.2770823804789826

Epoch: 5| Step: 8
Training loss: 3.992694143257964
Validation loss: 3.2681865675471777

Epoch: 5| Step: 9
Training loss: 3.3378326250263703
Validation loss: 3.264654001155252

Epoch: 5| Step: 10
Training loss: 3.457953757784942
Validation loss: 3.2589153591906252

Epoch: 6| Step: 0
Training loss: 3.0737313607648624
Validation loss: 3.257368515748673

Epoch: 5| Step: 1
Training loss: 3.9845132242797803
Validation loss: 3.249692629406117

Epoch: 5| Step: 2
Training loss: 3.631377824907037
Validation loss: 3.247124296558885

Epoch: 5| Step: 3
Training loss: 3.931220603068807
Validation loss: 3.244757267513131

Epoch: 5| Step: 4
Training loss: 3.2137909251055095
Validation loss: 3.2403235835953286

Epoch: 5| Step: 5
Training loss: 3.218469403822992
Validation loss: 3.236494518668277

Epoch: 5| Step: 6
Training loss: 3.326943487780673
Validation loss: 3.228902311483375

Epoch: 5| Step: 7
Training loss: 2.9510582852167766
Validation loss: 3.229794225667678

Epoch: 5| Step: 8
Training loss: 3.842283884199259
Validation loss: 3.2244211619743544

Epoch: 5| Step: 9
Training loss: 3.328476435056007
Validation loss: 3.218643952934598

Epoch: 5| Step: 10
Training loss: 3.655603335324999
Validation loss: 3.2142200462286064

Epoch: 7| Step: 0
Training loss: 3.33735673003988
Validation loss: 3.2112774460525837

Epoch: 5| Step: 1
Training loss: 2.8413325503936124
Validation loss: 3.207199125260365

Epoch: 5| Step: 2
Training loss: 3.859503492926786
Validation loss: 3.201657515066454

Epoch: 5| Step: 3
Training loss: 3.8041801349336017
Validation loss: 3.1943294897405736

Epoch: 5| Step: 4
Training loss: 4.162648488738378
Validation loss: 3.1923231518073516

Epoch: 5| Step: 5
Training loss: 3.013525988347585
Validation loss: 3.184607624927011

Epoch: 5| Step: 6
Training loss: 2.9749511201834005
Validation loss: 3.17803730527212

Epoch: 5| Step: 7
Training loss: 3.2817428945274263
Validation loss: 3.1759345038044193

Epoch: 5| Step: 8
Training loss: 3.0099508239683117
Validation loss: 3.1691237266775993

Epoch: 5| Step: 9
Training loss: 3.2890013192981127
Validation loss: 3.170306462237208

Epoch: 5| Step: 10
Training loss: 4.030813267434231
Validation loss: 3.1588923049552076

Epoch: 8| Step: 0
Training loss: 3.9242531910288108
Validation loss: 3.153272811966887

Epoch: 5| Step: 1
Training loss: 3.7803294424778047
Validation loss: 3.1514973563747373

Epoch: 5| Step: 2
Training loss: 3.2501957174204272
Validation loss: 3.1448293082115946

Epoch: 5| Step: 3
Training loss: 3.341540881395308
Validation loss: 3.1384094983386968

Epoch: 5| Step: 4
Training loss: 2.939480702216984
Validation loss: 3.1325404232358505

Epoch: 5| Step: 5
Training loss: 3.0908062734179578
Validation loss: 3.1267085796436365

Epoch: 5| Step: 6
Training loss: 2.599603963913649
Validation loss: 3.11937404745467

Epoch: 5| Step: 7
Training loss: 3.054325794551907
Validation loss: 3.1201398649252874

Epoch: 5| Step: 8
Training loss: 3.9070956115974513
Validation loss: 3.1152438601537393

Epoch: 5| Step: 9
Training loss: 3.647889580109556
Validation loss: 3.1102868953264604

Epoch: 5| Step: 10
Training loss: 3.4740315686484227
Validation loss: 3.0997391717048446

Epoch: 9| Step: 0
Training loss: 4.0320632469121325
Validation loss: 3.0953035237941338

Epoch: 5| Step: 1
Training loss: 2.4952521061859247
Validation loss: 3.092741653490073

Epoch: 5| Step: 2
Training loss: 3.871243532672391
Validation loss: 3.084879292780372

Epoch: 5| Step: 3
Training loss: 3.304367735342284
Validation loss: 3.079459873338725

Epoch: 5| Step: 4
Training loss: 3.069902465463836
Validation loss: 3.07186387292616

Epoch: 5| Step: 5
Training loss: 2.5494549561475472
Validation loss: 3.0660790036735435

Epoch: 5| Step: 6
Training loss: 2.9751037066680026
Validation loss: 3.0632876366300903

Epoch: 5| Step: 7
Training loss: 4.0103544684536905
Validation loss: 3.0573999347618375

Epoch: 5| Step: 8
Training loss: 3.101338952605825
Validation loss: 3.0493414803897716

Epoch: 5| Step: 9
Training loss: 3.7161349550590095
Validation loss: 3.0464967823690126

Epoch: 5| Step: 10
Training loss: 3.040889710433127
Validation loss: 3.0363507485075867

Epoch: 10| Step: 0
Training loss: 3.5167717313815707
Validation loss: 3.037479700320879

Epoch: 5| Step: 1
Training loss: 2.74948834948058
Validation loss: 3.0258878255385273

Epoch: 5| Step: 2
Training loss: 3.7469425453034604
Validation loss: 3.0218987837385494

Epoch: 5| Step: 3
Training loss: 3.7428095226940075
Validation loss: 3.010963458127013

Epoch: 5| Step: 4
Training loss: 3.24130626789982
Validation loss: 3.0091217545431577

Epoch: 5| Step: 5
Training loss: 3.7063116213225498
Validation loss: 2.9981079544270006

Epoch: 5| Step: 6
Training loss: 3.3269479308805
Validation loss: 2.9976542874861494

Epoch: 5| Step: 7
Training loss: 3.2124978982050214
Validation loss: 2.9913466152416444

Epoch: 5| Step: 8
Training loss: 2.39808677072205
Validation loss: 2.979316080071123

Epoch: 5| Step: 9
Training loss: 2.906157297276118
Validation loss: 2.9736135681026425

Epoch: 5| Step: 10
Training loss: 3.3002368726391964
Validation loss: 2.9672085070066627

Epoch: 11| Step: 0
Training loss: 3.3877212114353052
Validation loss: 2.9622905913510182

Epoch: 5| Step: 1
Training loss: 3.1747663877553713
Validation loss: 2.9559959757758874

Epoch: 5| Step: 2
Training loss: 3.0016123889150936
Validation loss: 2.9507361040280293

Epoch: 5| Step: 3
Training loss: 3.240288235594396
Validation loss: 2.9482819438754118

Epoch: 5| Step: 4
Training loss: 3.471906171190093
Validation loss: 2.9377068364082004

Epoch: 5| Step: 5
Training loss: 3.353343001617792
Validation loss: 2.9340317935183537

Epoch: 5| Step: 6
Training loss: 2.6895569315194874
Validation loss: 2.9273767173566316

Epoch: 5| Step: 7
Training loss: 3.4475883181561593
Validation loss: 2.9137301826395263

Epoch: 5| Step: 8
Training loss: 3.444036892054231
Validation loss: 2.909774275319257

Epoch: 5| Step: 9
Training loss: 2.858493856773428
Validation loss: 2.9027723203173594

Epoch: 5| Step: 10
Training loss: 3.23337144993079
Validation loss: 2.8939051594289453

Epoch: 12| Step: 0
Training loss: 3.213662135474712
Validation loss: 2.8936114235313726

Epoch: 5| Step: 1
Training loss: 3.189292553272033
Validation loss: 2.8893746990908817

Epoch: 5| Step: 2
Training loss: 2.9849848099262957
Validation loss: 2.882163927840335

Epoch: 5| Step: 3
Training loss: 3.7220133079114612
Validation loss: 2.872069234226096

Epoch: 5| Step: 4
Training loss: 3.7286626947651094
Validation loss: 2.8657183403077253

Epoch: 5| Step: 5
Training loss: 3.047266695325331
Validation loss: 2.852114055591551

Epoch: 5| Step: 6
Training loss: 3.2761410130577353
Validation loss: 2.8487235921891947

Epoch: 5| Step: 7
Training loss: 2.4416429572749876
Validation loss: 2.836776863654893

Epoch: 5| Step: 8
Training loss: 2.509587690524945
Validation loss: 2.838558423136873

Epoch: 5| Step: 9
Training loss: 2.6411307488243088
Validation loss: 2.8279794326817904

Epoch: 5| Step: 10
Training loss: 3.74138325309576
Validation loss: 2.8256376427294674

Epoch: 13| Step: 0
Training loss: 3.5582252420510065
Validation loss: 2.8144193701650444

Epoch: 5| Step: 1
Training loss: 2.9122737682052766
Validation loss: 2.8108139508078063

Epoch: 5| Step: 2
Training loss: 3.0279480558649143
Validation loss: 2.8036201844028343

Epoch: 5| Step: 3
Training loss: 2.8618371920765577
Validation loss: 2.800216158530568

Epoch: 5| Step: 4
Training loss: 3.091322129237564
Validation loss: 2.7885601873272834

Epoch: 5| Step: 5
Training loss: 3.2460267648774526
Validation loss: 2.779944807347079

Epoch: 5| Step: 6
Training loss: 2.6103913846102023
Validation loss: 2.7761556221076833

Epoch: 5| Step: 7
Training loss: 3.6077766347286175
Validation loss: 2.763267090830228

Epoch: 5| Step: 8
Training loss: 3.104284058128348
Validation loss: 2.7654561016182164

Epoch: 5| Step: 9
Training loss: 2.8250646735696288
Validation loss: 2.753918623636457

Epoch: 5| Step: 10
Training loss: 3.13889899200644
Validation loss: 2.73794641200476

Epoch: 14| Step: 0
Training loss: 2.8772285780175917
Validation loss: 2.7438797755349933

Epoch: 5| Step: 1
Training loss: 3.271365582031649
Validation loss: 2.738415415829605

Epoch: 5| Step: 2
Training loss: 3.1386461998697053
Validation loss: 2.7293585608292057

Epoch: 5| Step: 3
Training loss: 2.5449036065453767
Validation loss: 2.7236649948553873

Epoch: 5| Step: 4
Training loss: 3.393237254713036
Validation loss: 2.7194042576055626

Epoch: 5| Step: 5
Training loss: 2.80642196026456
Validation loss: 2.709571174663093

Epoch: 5| Step: 6
Training loss: 2.824310174625637
Validation loss: 2.70313465657982

Epoch: 5| Step: 7
Training loss: 2.682585992065843
Validation loss: 2.704334759135989

Epoch: 5| Step: 8
Training loss: 3.435884685726283
Validation loss: 2.691254277438407

Epoch: 5| Step: 9
Training loss: 3.1295413778762926
Validation loss: 2.680523797394583

Epoch: 5| Step: 10
Training loss: 3.1952989200219526
Validation loss: 2.6818104563293264

Epoch: 15| Step: 0
Training loss: 3.0995412240952245
Validation loss: 2.676749690844216

Epoch: 5| Step: 1
Training loss: 2.7195293142678403
Validation loss: 2.665536477241593

Epoch: 5| Step: 2
Training loss: 2.8572157748318125
Validation loss: 2.657749643999438

Epoch: 5| Step: 3
Training loss: 2.6347107878026708
Validation loss: 2.654256338155722

Epoch: 5| Step: 4
Training loss: 2.9629965193049226
Validation loss: 2.6394343042615267

Epoch: 5| Step: 5
Training loss: 3.27819943993546
Validation loss: 2.64460278970771

Epoch: 5| Step: 6
Training loss: 3.0200395440045273
Validation loss: 2.6409760356087815

Epoch: 5| Step: 7
Training loss: 2.7355168165674186
Validation loss: 2.6247676418380537

Epoch: 5| Step: 8
Training loss: 2.9571963708851943
Validation loss: 2.626647322946675

Epoch: 5| Step: 9
Training loss: 3.1324528133312053
Validation loss: 2.617444374776934

Epoch: 5| Step: 10
Training loss: 3.4786043150453105
Validation loss: 2.609560522634594

Epoch: 16| Step: 0
Training loss: 3.2332664469718946
Validation loss: 2.6030109352902393

Epoch: 5| Step: 1
Training loss: 2.8315442738642664
Validation loss: 2.600623874992081

Epoch: 5| Step: 2
Training loss: 2.928402387412382
Validation loss: 2.5946921288013134

Epoch: 5| Step: 3
Training loss: 3.080904872050976
Validation loss: 2.5906314350182194

Epoch: 5| Step: 4
Training loss: 2.804154539341845
Validation loss: 2.582545186692486

Epoch: 5| Step: 5
Training loss: 3.236910945370867
Validation loss: 2.5699756205932127

Epoch: 5| Step: 6
Training loss: 2.9692223424096333
Validation loss: 2.575295473105906

Epoch: 5| Step: 7
Training loss: 3.167039765580789
Validation loss: 2.577932020057881

Epoch: 5| Step: 8
Training loss: 2.634271868115834
Validation loss: 2.5684455110075732

Epoch: 5| Step: 9
Training loss: 2.5489184834917418
Validation loss: 2.5654101490605625

Epoch: 5| Step: 10
Training loss: 2.823676810496034
Validation loss: 2.5489852626127028

Epoch: 17| Step: 0
Training loss: 2.847347792257427
Validation loss: 2.5542164416208117

Epoch: 5| Step: 1
Training loss: 3.185509901925611
Validation loss: 2.5463475946367886

Epoch: 5| Step: 2
Training loss: 2.740190088263607
Validation loss: 2.5479095006777297

Epoch: 5| Step: 3
Training loss: 2.9485428395580393
Validation loss: 2.541693820603228

Epoch: 5| Step: 4
Training loss: 2.5785229924811426
Validation loss: 2.534180770950612

Epoch: 5| Step: 5
Training loss: 3.1493457780872607
Validation loss: 2.5294351415565477

Epoch: 5| Step: 6
Training loss: 3.2606844238575596
Validation loss: 2.534850866724529

Epoch: 5| Step: 7
Training loss: 2.6808464724766465
Validation loss: 2.522725851113603

Epoch: 5| Step: 8
Training loss: 2.576998932879297
Validation loss: 2.521403538457184

Epoch: 5| Step: 9
Training loss: 3.2709690883835396
Validation loss: 2.512947174188022

Epoch: 5| Step: 10
Training loss: 2.468695434739898
Validation loss: 2.508335937404892

Epoch: 18| Step: 0
Training loss: 2.8520694647805467
Validation loss: 2.507652408710029

Epoch: 5| Step: 1
Training loss: 2.8310604141456395
Validation loss: 2.507082681945712

Epoch: 5| Step: 2
Training loss: 3.374856592593061
Validation loss: 2.498394827151959

Epoch: 5| Step: 3
Training loss: 2.8682684666689076
Validation loss: 2.497893808032043

Epoch: 5| Step: 4
Training loss: 2.415395226845428
Validation loss: 2.502457192551997

Epoch: 5| Step: 5
Training loss: 2.6258877660819007
Validation loss: 2.483424111985291

Epoch: 5| Step: 6
Training loss: 2.9692314962125446
Validation loss: 2.4834324746397893

Epoch: 5| Step: 7
Training loss: 3.0618226216950637
Validation loss: 2.4895959305381252

Epoch: 5| Step: 8
Training loss: 3.0185984445125964
Validation loss: 2.475823412167021

Epoch: 5| Step: 9
Training loss: 3.1626844631271176
Validation loss: 2.4804093037016486

Epoch: 5| Step: 10
Training loss: 2.4884726841465734
Validation loss: 2.4798480836637924

Epoch: 19| Step: 0
Training loss: 2.743520385588585
Validation loss: 2.4755109497604004

Epoch: 5| Step: 1
Training loss: 3.1288230399164965
Validation loss: 2.4691236552509745

Epoch: 5| Step: 2
Training loss: 2.340517179605778
Validation loss: 2.4740002113169965

Epoch: 5| Step: 3
Training loss: 3.1884261637000764
Validation loss: 2.461681759055326

Epoch: 5| Step: 4
Training loss: 2.8742895492456624
Validation loss: 2.4724613484769753

Epoch: 5| Step: 5
Training loss: 3.0445513349951745
Validation loss: 2.4681250374496932

Epoch: 5| Step: 6
Training loss: 3.1398639421081884
Validation loss: 2.4741670350588802

Epoch: 5| Step: 7
Training loss: 2.7091954155246003
Validation loss: 2.4604819953614916

Epoch: 5| Step: 8
Training loss: 3.073812028864801
Validation loss: 2.4763109477870833

Epoch: 5| Step: 9
Training loss: 2.540763214968796
Validation loss: 2.469553553820009

Epoch: 5| Step: 10
Training loss: 2.691018219147937
Validation loss: 2.455835657304639

Epoch: 20| Step: 0
Training loss: 3.208650020145891
Validation loss: 2.4588155410836006

Epoch: 5| Step: 1
Training loss: 2.3472908230700447
Validation loss: 2.452143622073584

Epoch: 5| Step: 2
Training loss: 3.0629876196222185
Validation loss: 2.4597899569395265

Epoch: 5| Step: 3
Training loss: 3.1139207898639416
Validation loss: 2.4489584415475356

Epoch: 5| Step: 4
Training loss: 2.760821896924774
Validation loss: 2.4617526755014274

Epoch: 5| Step: 5
Training loss: 3.2629488698336107
Validation loss: 2.4592120284565318

Epoch: 5| Step: 6
Training loss: 2.7924251000614366
Validation loss: 2.4597273437742895

Epoch: 5| Step: 7
Training loss: 3.1797063953484948
Validation loss: 2.456985444773486

Epoch: 5| Step: 8
Training loss: 3.0023794274812268
Validation loss: 2.449914698510631

Epoch: 5| Step: 9
Training loss: 1.9310497464054754
Validation loss: 2.455583520156009

Epoch: 5| Step: 10
Training loss: 2.4876047888685626
Validation loss: 2.4465651831522726

Epoch: 21| Step: 0
Training loss: 3.0329471831409553
Validation loss: 2.4560797512028394

Epoch: 5| Step: 1
Training loss: 2.7280849807792857
Validation loss: 2.443199531454369

Epoch: 5| Step: 2
Training loss: 2.3858524129968273
Validation loss: 2.445032795625869

Epoch: 5| Step: 3
Training loss: 3.0498970889880805
Validation loss: 2.4492504014922436

Epoch: 5| Step: 4
Training loss: 2.8176310887681124
Validation loss: 2.4501355826603426

Epoch: 5| Step: 5
Training loss: 3.0844195918267707
Validation loss: 2.4487204595894574

Epoch: 5| Step: 6
Training loss: 3.0202149558461233
Validation loss: 2.442973298957749

Epoch: 5| Step: 7
Training loss: 2.606555168892503
Validation loss: 2.454499118418396

Epoch: 5| Step: 8
Training loss: 3.153205687565158
Validation loss: 2.434756874978785

Epoch: 5| Step: 9
Training loss: 2.899147954275326
Validation loss: 2.4458532615112927

Epoch: 5| Step: 10
Training loss: 2.545557722873987
Validation loss: 2.4452153658060003

Epoch: 22| Step: 0
Training loss: 3.1940845471050348
Validation loss: 2.4383415408095126

Epoch: 5| Step: 1
Training loss: 2.210221137465992
Validation loss: 2.454015340982602

Epoch: 5| Step: 2
Training loss: 2.923027749555315
Validation loss: 2.4541818408722236

Epoch: 5| Step: 3
Training loss: 3.1006383792317105
Validation loss: 2.444335116282702

Epoch: 5| Step: 4
Training loss: 3.6271747774052363
Validation loss: 2.432811800460909

Epoch: 5| Step: 5
Training loss: 2.76023434210794
Validation loss: 2.4519994251533457

Epoch: 5| Step: 6
Training loss: 2.948471196906427
Validation loss: 2.444677525287519

Epoch: 5| Step: 7
Training loss: 2.5273952567322038
Validation loss: 2.4401409922848623

Epoch: 5| Step: 8
Training loss: 2.243619029863531
Validation loss: 2.450713666096828

Epoch: 5| Step: 9
Training loss: 2.766472034808713
Validation loss: 2.4414460608733277

Epoch: 5| Step: 10
Training loss: 2.914487587858331
Validation loss: 2.441274969693657

Epoch: 23| Step: 0
Training loss: 2.948017204017077
Validation loss: 2.435297834451213

Epoch: 5| Step: 1
Training loss: 2.4960369169305032
Validation loss: 2.4523771269567916

Epoch: 5| Step: 2
Training loss: 3.171457648420148
Validation loss: 2.4352238979219094

Epoch: 5| Step: 3
Training loss: 3.2039713415990607
Validation loss: 2.4509127268876028

Epoch: 5| Step: 4
Training loss: 2.761042100601279
Validation loss: 2.4303887639240247

Epoch: 5| Step: 5
Training loss: 2.589814475053716
Validation loss: 2.438980834886178

Epoch: 5| Step: 6
Training loss: 3.4780268981753366
Validation loss: 2.443543145588269

Epoch: 5| Step: 7
Training loss: 2.846277476141672
Validation loss: 2.444341474154508

Epoch: 5| Step: 8
Training loss: 2.3030386506124034
Validation loss: 2.4372459113011633

Epoch: 5| Step: 9
Training loss: 2.747811313447986
Validation loss: 2.4432414179609645

Epoch: 5| Step: 10
Training loss: 2.6897060300309064
Validation loss: 2.4301125247960917

Epoch: 24| Step: 0
Training loss: 2.866415725488563
Validation loss: 2.4413091788077743

Epoch: 5| Step: 1
Training loss: 2.9450213948688644
Validation loss: 2.4409425067794204

Epoch: 5| Step: 2
Training loss: 2.677644089526878
Validation loss: 2.4495783716156447

Epoch: 5| Step: 3
Training loss: 2.6993157332093016
Validation loss: 2.4401517174306613

Epoch: 5| Step: 4
Training loss: 2.816479220351081
Validation loss: 2.4288515556678907

Epoch: 5| Step: 5
Training loss: 2.926831941680928
Validation loss: 2.435363035777239

Epoch: 5| Step: 6
Training loss: 2.4914098022473894
Validation loss: 2.4405665233038727

Epoch: 5| Step: 7
Training loss: 2.7718195104366914
Validation loss: 2.440020645951276

Epoch: 5| Step: 8
Training loss: 3.1614658579770847
Validation loss: 2.435875393567778

Epoch: 5| Step: 9
Training loss: 3.1301256487309357
Validation loss: 2.4280621493449264

Epoch: 5| Step: 10
Training loss: 2.8572147734991598
Validation loss: 2.443195666892426

Epoch: 25| Step: 0
Training loss: 2.9705154791060906
Validation loss: 2.4330375637726447

Epoch: 5| Step: 1
Training loss: 2.5047411783788167
Validation loss: 2.4471245731510907

Epoch: 5| Step: 2
Training loss: 3.2271265455931495
Validation loss: 2.4462691352452945

Epoch: 5| Step: 3
Training loss: 2.413629486852671
Validation loss: 2.436579994220788

Epoch: 5| Step: 4
Training loss: 2.6974541600303588
Validation loss: 2.441653349810445

Epoch: 5| Step: 5
Training loss: 3.106530656934379
Validation loss: 2.4431746504098615

Epoch: 5| Step: 6
Training loss: 2.949736250385512
Validation loss: 2.457333204021304

Epoch: 5| Step: 7
Training loss: 3.3741360724235014
Validation loss: 2.4305143832358933

Epoch: 5| Step: 8
Training loss: 2.540656988827002
Validation loss: 2.433166407392718

Epoch: 5| Step: 9
Training loss: 2.615217600534329
Validation loss: 2.4405728773376056

Epoch: 5| Step: 10
Training loss: 2.8731028060603565
Validation loss: 2.436292234980792

Epoch: 26| Step: 0
Training loss: 3.1041124753040727
Validation loss: 2.4363083788750886

Epoch: 5| Step: 1
Training loss: 2.428704262154075
Validation loss: 2.435506929804412

Epoch: 5| Step: 2
Training loss: 2.9338455193747293
Validation loss: 2.4386658605699383

Epoch: 5| Step: 3
Training loss: 2.990303103543521
Validation loss: 2.4455771590166773

Epoch: 5| Step: 4
Training loss: 3.1531963117265067
Validation loss: 2.4428444667508558

Epoch: 5| Step: 5
Training loss: 2.890864676771768
Validation loss: 2.436377007646546

Epoch: 5| Step: 6
Training loss: 2.5375192500544648
Validation loss: 2.4520370132616174

Epoch: 5| Step: 7
Training loss: 2.326835736177321
Validation loss: 2.4454516855080564

Epoch: 5| Step: 8
Training loss: 2.8634857479411537
Validation loss: 2.4420707791211864

Epoch: 5| Step: 9
Training loss: 2.937538633701233
Validation loss: 2.4247483181546343

Epoch: 5| Step: 10
Training loss: 3.2234328195498163
Validation loss: 2.4420230960069373

Epoch: 27| Step: 0
Training loss: 2.803678113106792
Validation loss: 2.4408497328580823

Epoch: 5| Step: 1
Training loss: 3.0352324447985066
Validation loss: 2.4453169221040962

Epoch: 5| Step: 2
Training loss: 2.846965271641818
Validation loss: 2.4425424428999203

Epoch: 5| Step: 3
Training loss: 2.4487657630027506
Validation loss: 2.437692860182536

Epoch: 5| Step: 4
Training loss: 3.364644588389204
Validation loss: 2.4457833955426858

Epoch: 5| Step: 5
Training loss: 2.937544964385336
Validation loss: 2.450266553020596

Epoch: 5| Step: 6
Training loss: 2.796232011078092
Validation loss: 2.4381201591207797

Epoch: 5| Step: 7
Training loss: 2.9505762474914525
Validation loss: 2.4477711627543934

Epoch: 5| Step: 8
Training loss: 2.964069411089235
Validation loss: 2.4343885962851006

Epoch: 5| Step: 9
Training loss: 2.7448427218491025
Validation loss: 2.439602467056518

Epoch: 5| Step: 10
Training loss: 2.283168874048058
Validation loss: 2.44493372098428

Epoch: 28| Step: 0
Training loss: 3.0182290964507827
Validation loss: 2.4366882672236296

Epoch: 5| Step: 1
Training loss: 2.189088517115423
Validation loss: 2.437920808819108

Epoch: 5| Step: 2
Training loss: 2.6311469087316977
Validation loss: 2.4416747752192927

Epoch: 5| Step: 3
Training loss: 2.7037595323878696
Validation loss: 2.44152115405007

Epoch: 5| Step: 4
Training loss: 2.9284681707381366
Validation loss: 2.4436381347337357

Epoch: 5| Step: 5
Training loss: 2.514546986727811
Validation loss: 2.4277507933323474

Epoch: 5| Step: 6
Training loss: 3.1482318214649583
Validation loss: 2.4406809395968323

Epoch: 5| Step: 7
Training loss: 2.521808299112592
Validation loss: 2.445356075932967

Epoch: 5| Step: 8
Training loss: 3.0250060278462025
Validation loss: 2.4423630701281134

Epoch: 5| Step: 9
Training loss: 2.956989968337999
Validation loss: 2.4376118873303794

Epoch: 5| Step: 10
Training loss: 3.4968245951792727
Validation loss: 2.4362024956232418

Epoch: 29| Step: 0
Training loss: 2.932908223154413
Validation loss: 2.441051296231412

Epoch: 5| Step: 1
Training loss: 2.7148853765356376
Validation loss: 2.4387171451248957

Epoch: 5| Step: 2
Training loss: 3.1189460096514345
Validation loss: 2.4473312428450416

Epoch: 5| Step: 3
Training loss: 2.4905910819889936
Validation loss: 2.4366204899749606

Epoch: 5| Step: 4
Training loss: 2.8374787653325932
Validation loss: 2.430651108542819

Epoch: 5| Step: 5
Training loss: 2.923806108227476
Validation loss: 2.4424543764075652

Epoch: 5| Step: 6
Training loss: 2.674137964123349
Validation loss: 2.4427618149487054

Epoch: 5| Step: 7
Training loss: 3.0321056298851548
Validation loss: 2.4479827187728636

Epoch: 5| Step: 8
Training loss: 3.573818230206135
Validation loss: 2.4326771546192836

Epoch: 5| Step: 9
Training loss: 2.2762661145984215
Validation loss: 2.443862735315396

Epoch: 5| Step: 10
Training loss: 2.4828478840058454
Validation loss: 2.4377226389975917

Epoch: 30| Step: 0
Training loss: 3.160804106857733
Validation loss: 2.453832687945464

Epoch: 5| Step: 1
Training loss: 3.2304274200046605
Validation loss: 2.4386406368143914

Epoch: 5| Step: 2
Training loss: 2.5492077774901287
Validation loss: 2.4404361038685995

Epoch: 5| Step: 3
Training loss: 2.67103492067304
Validation loss: 2.4331989767758486

Epoch: 5| Step: 4
Training loss: 2.911562422436808
Validation loss: 2.4424931993174757

Epoch: 5| Step: 5
Training loss: 2.711878456593544
Validation loss: 2.4403660765074866

Epoch: 5| Step: 6
Training loss: 2.6140597200350393
Validation loss: 2.436918517980645

Epoch: 5| Step: 7
Training loss: 2.508482846422494
Validation loss: 2.424849467187645

Epoch: 5| Step: 8
Training loss: 3.3243583174744304
Validation loss: 2.4390365631264705

Epoch: 5| Step: 9
Training loss: 3.001625574294175
Validation loss: 2.427982579022683

Epoch: 5| Step: 10
Training loss: 2.2830556751736
Validation loss: 2.4466850676949274

Epoch: 31| Step: 0
Training loss: 2.9969075476636187
Validation loss: 2.440580956148805

Epoch: 5| Step: 1
Training loss: 2.7430392515661026
Validation loss: 2.4384510907728254

Epoch: 5| Step: 2
Training loss: 3.112750650754013
Validation loss: 2.4350558032900844

Epoch: 5| Step: 3
Training loss: 2.8191417684046627
Validation loss: 2.4355701129942626

Epoch: 5| Step: 4
Training loss: 2.8629907978534876
Validation loss: 2.440984424664092

Epoch: 5| Step: 5
Training loss: 2.413691026074847
Validation loss: 2.4321637077916662

Epoch: 5| Step: 6
Training loss: 2.9909354595846565
Validation loss: 2.4497983400812373

Epoch: 5| Step: 7
Training loss: 2.6821477067456185
Validation loss: 2.4343631544481434

Epoch: 5| Step: 8
Training loss: 2.918218109220659
Validation loss: 2.4504854124888227

Epoch: 5| Step: 9
Training loss: 2.868275947713442
Validation loss: 2.4344821155768415

Epoch: 5| Step: 10
Training loss: 2.867478192220706
Validation loss: 2.4410474125151516

Epoch: 32| Step: 0
Training loss: 2.5412142512503855
Validation loss: 2.4339209459265887

Epoch: 5| Step: 1
Training loss: 2.664381080887164
Validation loss: 2.4312072375603613

Epoch: 5| Step: 2
Training loss: 3.5675567074968906
Validation loss: 2.439645254930938

Epoch: 5| Step: 3
Training loss: 2.383350149064219
Validation loss: 2.4264999502554865

Epoch: 5| Step: 4
Training loss: 2.5850404410823535
Validation loss: 2.450299892190573

Epoch: 5| Step: 5
Training loss: 2.735892436093751
Validation loss: 2.4336127565846204

Epoch: 5| Step: 6
Training loss: 2.9156749855982005
Validation loss: 2.4381665753216213

Epoch: 5| Step: 7
Training loss: 2.5808109048524313
Validation loss: 2.4325268277707104

Epoch: 5| Step: 8
Training loss: 3.1493242780322137
Validation loss: 2.4377682530091396

Epoch: 5| Step: 9
Training loss: 2.9260977356154774
Validation loss: 2.4449084538913213

Epoch: 5| Step: 10
Training loss: 2.9963089170619313
Validation loss: 2.449232872274597

Epoch: 33| Step: 0
Training loss: 2.8130305319660494
Validation loss: 2.425355266405484

Epoch: 5| Step: 1
Training loss: 2.6707140090004198
Validation loss: 2.4275268902144744

Epoch: 5| Step: 2
Training loss: 3.051367318766799
Validation loss: 2.4301078007375114

Epoch: 5| Step: 3
Training loss: 2.930671221563232
Validation loss: 2.444419782019433

Epoch: 5| Step: 4
Training loss: 2.5377725464224503
Validation loss: 2.437115847488511

Epoch: 5| Step: 5
Training loss: 2.7420099532421833
Validation loss: 2.4288811272908566

Epoch: 5| Step: 6
Training loss: 2.796734001825224
Validation loss: 2.440669730974028

Epoch: 5| Step: 7
Training loss: 2.6112943431692033
Validation loss: 2.438904343256764

Epoch: 5| Step: 8
Training loss: 3.0799322873883868
Validation loss: 2.438920014718231

Epoch: 5| Step: 9
Training loss: 2.867554186414605
Validation loss: 2.431866889722696

Epoch: 5| Step: 10
Training loss: 3.0995238399902605
Validation loss: 2.43617194897244

Epoch: 34| Step: 0
Training loss: 3.3339180115685703
Validation loss: 2.434963686312778

Epoch: 5| Step: 1
Training loss: 2.9224055007523573
Validation loss: 2.438649097324617

Epoch: 5| Step: 2
Training loss: 2.9461480936092705
Validation loss: 2.4399519378948935

Epoch: 5| Step: 3
Training loss: 2.8065969613753015
Validation loss: 2.431610016824353

Epoch: 5| Step: 4
Training loss: 3.0519582746660765
Validation loss: 2.436878265987243

Epoch: 5| Step: 5
Training loss: 2.9200363493969244
Validation loss: 2.4427203767516636

Epoch: 5| Step: 6
Training loss: 2.957351485817833
Validation loss: 2.428941663714261

Epoch: 5| Step: 7
Training loss: 2.588096524090915
Validation loss: 2.4388457349455623

Epoch: 5| Step: 8
Training loss: 2.1500314798933693
Validation loss: 2.436829765354945

Epoch: 5| Step: 9
Training loss: 2.5888331125751667
Validation loss: 2.4366961695367193

Epoch: 5| Step: 10
Training loss: 2.7341987771060596
Validation loss: 2.439626520747908

Epoch: 35| Step: 0
Training loss: 2.6220866794181927
Validation loss: 2.4308066073690817

Epoch: 5| Step: 1
Training loss: 3.2055092474554585
Validation loss: 2.4406556652402513

Epoch: 5| Step: 2
Training loss: 3.09694160212738
Validation loss: 2.4377295073398453

Epoch: 5| Step: 3
Training loss: 2.501495200305629
Validation loss: 2.4417992118015728

Epoch: 5| Step: 4
Training loss: 2.6008165911137975
Validation loss: 2.443190894679887

Epoch: 5| Step: 5
Training loss: 2.868224411233082
Validation loss: 2.4326765992481088

Epoch: 5| Step: 6
Training loss: 2.524699270639085
Validation loss: 2.435115781418692

Epoch: 5| Step: 7
Training loss: 3.359404523852823
Validation loss: 2.432147512142752

Epoch: 5| Step: 8
Training loss: 2.8565770202007275
Validation loss: 2.4220334131232493

Epoch: 5| Step: 9
Training loss: 2.5288935866346716
Validation loss: 2.4324036363587007

Epoch: 5| Step: 10
Training loss: 2.8888957031691302
Validation loss: 2.441130298794792

Epoch: 36| Step: 0
Training loss: 3.528168135211221
Validation loss: 2.4163804162311044

Epoch: 5| Step: 1
Training loss: 2.8407392388633235
Validation loss: 2.4305533050979844

Epoch: 5| Step: 2
Training loss: 2.756343547591601
Validation loss: 2.4260404868131347

Epoch: 5| Step: 3
Training loss: 2.289501265309491
Validation loss: 2.4349170574434322

Epoch: 5| Step: 4
Training loss: 3.095055815111777
Validation loss: 2.43672050126166

Epoch: 5| Step: 5
Training loss: 3.031474154334963
Validation loss: 2.432463286240745

Epoch: 5| Step: 6
Training loss: 2.422451910401779
Validation loss: 2.4274769227591646

Epoch: 5| Step: 7
Training loss: 2.98373805733677
Validation loss: 2.4310124455285993

Epoch: 5| Step: 8
Training loss: 2.7578945417871554
Validation loss: 2.433476005416672

Epoch: 5| Step: 9
Training loss: 2.972273492420426
Validation loss: 2.4283854201856587

Epoch: 5| Step: 10
Training loss: 1.9689924302776591
Validation loss: 2.435150540273938

Epoch: 37| Step: 0
Training loss: 2.6466535563428484
Validation loss: 2.44392118554909

Epoch: 5| Step: 1
Training loss: 2.8288753631093972
Validation loss: 2.428660652398136

Epoch: 5| Step: 2
Training loss: 2.7234967766426332
Validation loss: 2.4438903850097264

Epoch: 5| Step: 3
Training loss: 2.789076177312402
Validation loss: 2.432841848720811

Epoch: 5| Step: 4
Training loss: 3.0518393739100933
Validation loss: 2.4332227344919364

Epoch: 5| Step: 5
Training loss: 2.872897664856306
Validation loss: 2.4333673956331814

Epoch: 5| Step: 6
Training loss: 2.899783909080184
Validation loss: 2.430111615431353

Epoch: 5| Step: 7
Training loss: 3.058496310458999
Validation loss: 2.4386110636944682

Epoch: 5| Step: 8
Training loss: 3.1443868852730805
Validation loss: 2.429626585420318

Epoch: 5| Step: 9
Training loss: 2.502262808032247
Validation loss: 2.4361823385387567

Epoch: 5| Step: 10
Training loss: 2.54287592986562
Validation loss: 2.4381064877072225

Epoch: 38| Step: 0
Training loss: 2.66032931175194
Validation loss: 2.4438374665906064

Epoch: 5| Step: 1
Training loss: 2.89804757263858
Validation loss: 2.428587207868309

Epoch: 5| Step: 2
Training loss: 3.1395498684468834
Validation loss: 2.4429333492647323

Epoch: 5| Step: 3
Training loss: 2.366659476936416
Validation loss: 2.4319844776663015

Epoch: 5| Step: 4
Training loss: 2.839959605292368
Validation loss: 2.427062288591188

Epoch: 5| Step: 5
Training loss: 3.0935228052428543
Validation loss: 2.4397116651268624

Epoch: 5| Step: 6
Training loss: 3.3260528847807573
Validation loss: 2.436979559572204

Epoch: 5| Step: 7
Training loss: 2.7789285808499287
Validation loss: 2.436855518088438

Epoch: 5| Step: 8
Training loss: 2.4460760027601958
Validation loss: 2.4303889791088022

Epoch: 5| Step: 9
Training loss: 2.439905007186099
Validation loss: 2.436045684787426

Epoch: 5| Step: 10
Training loss: 2.849187661564353
Validation loss: 2.428572790833668

Epoch: 39| Step: 0
Training loss: 2.7458823327500466
Validation loss: 2.4318378240528244

Epoch: 5| Step: 1
Training loss: 2.887075193128223
Validation loss: 2.4257355469162336

Epoch: 5| Step: 2
Training loss: 2.3717454394914594
Validation loss: 2.432107817853492

Epoch: 5| Step: 3
Training loss: 2.9823623981053697
Validation loss: 2.4375139566826003

Epoch: 5| Step: 4
Training loss: 3.218630001460825
Validation loss: 2.4469797478287973

Epoch: 5| Step: 5
Training loss: 2.460132576231016
Validation loss: 2.427067465380187

Epoch: 5| Step: 6
Training loss: 3.158857873388738
Validation loss: 2.432728350444825

Epoch: 5| Step: 7
Training loss: 3.3566662180451057
Validation loss: 2.4254580696555514

Epoch: 5| Step: 8
Training loss: 2.493238843191566
Validation loss: 2.4370958694219937

Epoch: 5| Step: 9
Training loss: 2.48822232211056
Validation loss: 2.4252859959512576

Epoch: 5| Step: 10
Training loss: 2.662109195879946
Validation loss: 2.426966536601104

Epoch: 40| Step: 0
Training loss: 2.7346322074900127
Validation loss: 2.4424346435359476

Epoch: 5| Step: 1
Training loss: 2.1745918899526644
Validation loss: 2.4345785375913334

Epoch: 5| Step: 2
Training loss: 2.804587019711682
Validation loss: 2.436479811972748

Epoch: 5| Step: 3
Training loss: 2.609187410658577
Validation loss: 2.4391157570731306

Epoch: 5| Step: 4
Training loss: 2.8516104916231213
Validation loss: 2.442781444427722

Epoch: 5| Step: 5
Training loss: 2.8290956633417097
Validation loss: 2.433773677441573

Epoch: 5| Step: 6
Training loss: 2.5730982007272747
Validation loss: 2.443487563144989

Epoch: 5| Step: 7
Training loss: 3.083785066934836
Validation loss: 2.4357852746912783

Epoch: 5| Step: 8
Training loss: 3.41619568966889
Validation loss: 2.4363378694593782

Epoch: 5| Step: 9
Training loss: 2.642872773496145
Validation loss: 2.4252134888609422

Epoch: 5| Step: 10
Training loss: 3.115941613733761
Validation loss: 2.4282800835626235

Epoch: 41| Step: 0
Training loss: 2.2841377270755805
Validation loss: 2.4220721960747795

Epoch: 5| Step: 1
Training loss: 3.0902966578522384
Validation loss: 2.433417974326883

Epoch: 5| Step: 2
Training loss: 2.829026895103292
Validation loss: 2.4288322875305184

Epoch: 5| Step: 3
Training loss: 3.118755051603029
Validation loss: 2.4432610262738317

Epoch: 5| Step: 4
Training loss: 2.3708325011168654
Validation loss: 2.4314324655698774

Epoch: 5| Step: 5
Training loss: 2.85527536804564
Validation loss: 2.444194048452189

Epoch: 5| Step: 6
Training loss: 2.8861071773727023
Validation loss: 2.4474613786522066

Epoch: 5| Step: 7
Training loss: 3.243200819386707
Validation loss: 2.4343795807285233

Epoch: 5| Step: 8
Training loss: 2.582955384037861
Validation loss: 2.4278709136883916

Epoch: 5| Step: 9
Training loss: 2.4879945503003458
Validation loss: 2.4405248324909925

Epoch: 5| Step: 10
Training loss: 3.0964955179190357
Validation loss: 2.4405130664119934

Epoch: 42| Step: 0
Training loss: 2.4440474970583526
Validation loss: 2.430609508175376

Epoch: 5| Step: 1
Training loss: 2.9400761447829176
Validation loss: 2.428191781691874

Epoch: 5| Step: 2
Training loss: 2.9824586477554536
Validation loss: 2.425450106417392

Epoch: 5| Step: 3
Training loss: 2.857304224498233
Validation loss: 2.430953437088301

Epoch: 5| Step: 4
Training loss: 2.584398993273505
Validation loss: 2.4321803860878526

Epoch: 5| Step: 5
Training loss: 3.3685639791846542
Validation loss: 2.4335116689244685

Epoch: 5| Step: 6
Training loss: 2.890179738985972
Validation loss: 2.4316172988470597

Epoch: 5| Step: 7
Training loss: 2.6778080079397917
Validation loss: 2.4338043400408416

Epoch: 5| Step: 8
Training loss: 2.3657669488403936
Validation loss: 2.4343660030961973

Epoch: 5| Step: 9
Training loss: 3.0278442756591035
Validation loss: 2.443060995209969

Epoch: 5| Step: 10
Training loss: 2.764501656018301
Validation loss: 2.432870239059062

Epoch: 43| Step: 0
Training loss: 2.828312061509312
Validation loss: 2.433294167444329

Epoch: 5| Step: 1
Training loss: 2.9311672695173248
Validation loss: 2.4390431124433585

Epoch: 5| Step: 2
Training loss: 2.98349832970042
Validation loss: 2.4221831412485337

Epoch: 5| Step: 3
Training loss: 3.2380558022867896
Validation loss: 2.4261374075798607

Epoch: 5| Step: 4
Training loss: 2.5034107783292243
Validation loss: 2.440599363679588

Epoch: 5| Step: 5
Training loss: 2.741385839934754
Validation loss: 2.430909344599564

Epoch: 5| Step: 6
Training loss: 2.5877297635735976
Validation loss: 2.43383384516637

Epoch: 5| Step: 7
Training loss: 3.1547172526089704
Validation loss: 2.432407323612671

Epoch: 5| Step: 8
Training loss: 2.5590892515788477
Validation loss: 2.4384051057885503

Epoch: 5| Step: 9
Training loss: 2.6328757077561935
Validation loss: 2.4248471380933614

Epoch: 5| Step: 10
Training loss: 2.7747391346155834
Validation loss: 2.4426305261584074

Epoch: 44| Step: 0
Training loss: 2.809331168404596
Validation loss: 2.4191759093236778

Epoch: 5| Step: 1
Training loss: 2.864206203720186
Validation loss: 2.4279799900213273

Epoch: 5| Step: 2
Training loss: 2.8421044252070926
Validation loss: 2.4229715924507564

Epoch: 5| Step: 3
Training loss: 2.9278908879216634
Validation loss: 2.436440186160558

Epoch: 5| Step: 4
Training loss: 3.0711401680422687
Validation loss: 2.4337199286107234

Epoch: 5| Step: 5
Training loss: 2.8438363533742494
Validation loss: 2.4209701874991643

Epoch: 5| Step: 6
Training loss: 2.7247751055666094
Validation loss: 2.4318610553219

Epoch: 5| Step: 7
Training loss: 2.6063102953040174
Validation loss: 2.4303420029760017

Epoch: 5| Step: 8
Training loss: 2.8809413057735163
Validation loss: 2.4384791224842814

Epoch: 5| Step: 9
Training loss: 2.7420513412710754
Validation loss: 2.442300969075562

Epoch: 5| Step: 10
Training loss: 2.521314927013609
Validation loss: 2.4294246118147638

Epoch: 45| Step: 0
Training loss: 2.6519115247510467
Validation loss: 2.4248204955483894

Epoch: 5| Step: 1
Training loss: 2.8435522995860225
Validation loss: 2.439755078400658

Epoch: 5| Step: 2
Training loss: 2.6158361789493045
Validation loss: 2.425516786895874

Epoch: 5| Step: 3
Training loss: 2.5930321860649457
Validation loss: 2.4377098634719645

Epoch: 5| Step: 4
Training loss: 2.9004468507807726
Validation loss: 2.4293434625686867

Epoch: 5| Step: 5
Training loss: 2.948194636706634
Validation loss: 2.4346229016395093

Epoch: 5| Step: 6
Training loss: 2.425770733452697
Validation loss: 2.43346793883667

Epoch: 5| Step: 7
Training loss: 2.9152600484180384
Validation loss: 2.4348766976083245

Epoch: 5| Step: 8
Training loss: 2.6526470207579145
Validation loss: 2.4420665899646647

Epoch: 5| Step: 9
Training loss: 2.9186048516526406
Validation loss: 2.4282846739305235

Epoch: 5| Step: 10
Training loss: 3.3258756818172444
Validation loss: 2.430150983650368

Epoch: 46| Step: 0
Training loss: 2.68060536137914
Validation loss: 2.4218991757713506

Epoch: 5| Step: 1
Training loss: 3.2036194954619845
Validation loss: 2.4408106852964977

Epoch: 5| Step: 2
Training loss: 2.686184050831932
Validation loss: 2.432312588870607

Epoch: 5| Step: 3
Training loss: 2.8336899102919553
Validation loss: 2.428719315434284

Epoch: 5| Step: 4
Training loss: 2.4780131522838706
Validation loss: 2.430429099133869

Epoch: 5| Step: 5
Training loss: 3.294510269007771
Validation loss: 2.4281665726595136

Epoch: 5| Step: 6
Training loss: 2.49520700670037
Validation loss: 2.4305824488857675

Epoch: 5| Step: 7
Training loss: 2.520453421808776
Validation loss: 2.4382781560680487

Epoch: 5| Step: 8
Training loss: 2.9025215104757476
Validation loss: 2.4349588321636184

Epoch: 5| Step: 9
Training loss: 3.043738682782637
Validation loss: 2.4372990096498377

Epoch: 5| Step: 10
Training loss: 2.518557716773091
Validation loss: 2.435229121577607

Epoch: 47| Step: 0
Training loss: 3.1746690592665336
Validation loss: 2.4231489659421674

Epoch: 5| Step: 1
Training loss: 2.4899291326403827
Validation loss: 2.4273684015289687

Epoch: 5| Step: 2
Training loss: 2.6425586369846825
Validation loss: 2.434186945658508

Epoch: 5| Step: 3
Training loss: 2.649752670118302
Validation loss: 2.424461665953387

Epoch: 5| Step: 4
Training loss: 2.7161263269813305
Validation loss: 2.4292586660735096

Epoch: 5| Step: 5
Training loss: 2.7969932318050805
Validation loss: 2.4297786954434892

Epoch: 5| Step: 6
Training loss: 2.4867526978174848
Validation loss: 2.424044891570004

Epoch: 5| Step: 7
Training loss: 3.3323423502005958
Validation loss: 2.4327997115034172

Epoch: 5| Step: 8
Training loss: 3.345855477823124
Validation loss: 2.4309553943923903

Epoch: 5| Step: 9
Training loss: 2.3037921782848207
Validation loss: 2.4144808663598583

Epoch: 5| Step: 10
Training loss: 2.730283629946012
Validation loss: 2.4277984711261578

Epoch: 48| Step: 0
Training loss: 2.9471117589992644
Validation loss: 2.432047407674125

Epoch: 5| Step: 1
Training loss: 3.0038024328817188
Validation loss: 2.4256838230281197

Epoch: 5| Step: 2
Training loss: 2.9667742127487817
Validation loss: 2.4269181114793

Epoch: 5| Step: 3
Training loss: 2.5187191149614168
Validation loss: 2.435925963335924

Epoch: 5| Step: 4
Training loss: 2.7779403024387643
Validation loss: 2.424720993627217

Epoch: 5| Step: 5
Training loss: 2.457861149155467
Validation loss: 2.4204122147579117

Epoch: 5| Step: 6
Training loss: 2.7906367456545667
Validation loss: 2.433209581328544

Epoch: 5| Step: 7
Training loss: 2.60714297285285
Validation loss: 2.4415406307522884

Epoch: 5| Step: 8
Training loss: 2.9134209875309707
Validation loss: 2.428034039603281

Epoch: 5| Step: 9
Training loss: 2.7866231899276985
Validation loss: 2.427865922343229

Epoch: 5| Step: 10
Training loss: 2.950527441427581
Validation loss: 2.430437137826699

Epoch: 49| Step: 0
Training loss: 2.5267198314290535
Validation loss: 2.422059646008842

Epoch: 5| Step: 1
Training loss: 2.0183980629094065
Validation loss: 2.4423113598607222

Epoch: 5| Step: 2
Training loss: 3.322026355700868
Validation loss: 2.4209351027395734

Epoch: 5| Step: 3
Training loss: 2.4092180846656412
Validation loss: 2.4229019067951483

Epoch: 5| Step: 4
Training loss: 2.815442389897204
Validation loss: 2.4120367885437584

Epoch: 5| Step: 5
Training loss: 3.1965902520501364
Validation loss: 2.431482838849005

Epoch: 5| Step: 6
Training loss: 2.2430313064424463
Validation loss: 2.434277703987856

Epoch: 5| Step: 7
Training loss: 3.160991167036228
Validation loss: 2.4284948861686146

Epoch: 5| Step: 8
Training loss: 2.998383086298705
Validation loss: 2.43484531201237

Epoch: 5| Step: 9
Training loss: 3.126080898270507
Validation loss: 2.4349144463351133

Epoch: 5| Step: 10
Training loss: 2.6173916409715576
Validation loss: 2.4344963286024504

Epoch: 50| Step: 0
Training loss: 3.1164686095873737
Validation loss: 2.42701805147013

Epoch: 5| Step: 1
Training loss: 2.998849330209481
Validation loss: 2.4335532639260755

Epoch: 5| Step: 2
Training loss: 3.087623463992251
Validation loss: 2.4213415155712066

Epoch: 5| Step: 3
Training loss: 2.9272929667457577
Validation loss: 2.4205671332409366

Epoch: 5| Step: 4
Training loss: 2.857490961122276
Validation loss: 2.4335923341786385

Epoch: 5| Step: 5
Training loss: 2.4777614447089102
Validation loss: 2.4321668731245727

Epoch: 5| Step: 6
Training loss: 3.045075653088479
Validation loss: 2.4228377604890907

Epoch: 5| Step: 7
Training loss: 2.8631318640153034
Validation loss: 2.433147136547632

Epoch: 5| Step: 8
Training loss: 2.5622257923326694
Validation loss: 2.425438179479798

Epoch: 5| Step: 9
Training loss: 2.442028338712304
Validation loss: 2.434997999359715

Epoch: 5| Step: 10
Training loss: 2.271530977461541
Validation loss: 2.433605773913986

Epoch: 51| Step: 0
Training loss: 2.260322627442143
Validation loss: 2.4265569434443615

Epoch: 5| Step: 1
Training loss: 3.0228928659467407
Validation loss: 2.427196276305764

Epoch: 5| Step: 2
Training loss: 2.7529401667335582
Validation loss: 2.434570219834621

Epoch: 5| Step: 3
Training loss: 2.460071132685955
Validation loss: 2.425054430353393

Epoch: 5| Step: 4
Training loss: 3.0629599089656177
Validation loss: 2.4256055867152493

Epoch: 5| Step: 5
Training loss: 2.816209339131074
Validation loss: 2.4372439432709605

Epoch: 5| Step: 6
Training loss: 3.1369469204547418
Validation loss: 2.4365502593094557

Epoch: 5| Step: 7
Training loss: 3.037559000078036
Validation loss: 2.4202008216916466

Epoch: 5| Step: 8
Training loss: 2.743501788406248
Validation loss: 2.433100371714658

Epoch: 5| Step: 9
Training loss: 2.6249331511205316
Validation loss: 2.4398754551702857

Epoch: 5| Step: 10
Training loss: 2.582193020414573
Validation loss: 2.428375834432623

Epoch: 52| Step: 0
Training loss: 2.626374384436949
Validation loss: 2.4273672334379515

Epoch: 5| Step: 1
Training loss: 2.3018459583183266
Validation loss: 2.42738212391598

Epoch: 5| Step: 2
Training loss: 3.0140311817462297
Validation loss: 2.4308570716597067

Epoch: 5| Step: 3
Training loss: 2.657753014277268
Validation loss: 2.4257408427899807

Epoch: 5| Step: 4
Training loss: 3.143167102688752
Validation loss: 2.4261411608893253

Epoch: 5| Step: 5
Training loss: 2.746729900533428
Validation loss: 2.4260648361153083

Epoch: 5| Step: 6
Training loss: 2.508042559662635
Validation loss: 2.430985538363672

Epoch: 5| Step: 7
Training loss: 3.1061151179727116
Validation loss: 2.412721726118874

Epoch: 5| Step: 8
Training loss: 2.8648627312548687
Validation loss: 2.4190711604378428

Epoch: 5| Step: 9
Training loss: 2.82696298574067
Validation loss: 2.4247202936991226

Epoch: 5| Step: 10
Training loss: 2.7838567454817094
Validation loss: 2.430671863107253

Epoch: 53| Step: 0
Training loss: 2.5779923838405994
Validation loss: 2.423466914312821

Epoch: 5| Step: 1
Training loss: 3.015530283334835
Validation loss: 2.430443392820572

Epoch: 5| Step: 2
Training loss: 2.65185416510797
Validation loss: 2.429429757716496

Epoch: 5| Step: 3
Training loss: 2.8801273566802985
Validation loss: 2.422786347200701

Epoch: 5| Step: 4
Training loss: 2.5560355173428184
Validation loss: 2.4433302262280066

Epoch: 5| Step: 5
Training loss: 3.05033216700092
Validation loss: 2.43066269032461

Epoch: 5| Step: 6
Training loss: 2.838008576243738
Validation loss: 2.4299612089945253

Epoch: 5| Step: 7
Training loss: 2.4803708995832685
Validation loss: 2.4187985169596082

Epoch: 5| Step: 8
Training loss: 3.3950848056723886
Validation loss: 2.4226823194881257

Epoch: 5| Step: 9
Training loss: 2.47785449096955
Validation loss: 2.433787108275357

Epoch: 5| Step: 10
Training loss: 2.571344510475548
Validation loss: 2.415219732691485

Epoch: 54| Step: 0
Training loss: 2.475308940371032
Validation loss: 2.430174296449878

Epoch: 5| Step: 1
Training loss: 3.0648954715297894
Validation loss: 2.4277041948841123

Epoch: 5| Step: 2
Training loss: 2.7039718624377778
Validation loss: 2.4131679431255595

Epoch: 5| Step: 3
Training loss: 2.980569060351219
Validation loss: 2.428370131525034

Epoch: 5| Step: 4
Training loss: 3.0914574037319933
Validation loss: 2.4186337368157265

Epoch: 5| Step: 5
Training loss: 2.888936802474891
Validation loss: 2.4110223732247666

Epoch: 5| Step: 6
Training loss: 2.85007368962908
Validation loss: 2.429390113994795

Epoch: 5| Step: 7
Training loss: 3.167923293157997
Validation loss: 2.423562211672663

Epoch: 5| Step: 8
Training loss: 2.597191606999614
Validation loss: 2.4161138365449633

Epoch: 5| Step: 9
Training loss: 2.005685117111224
Validation loss: 2.418309388206013

Epoch: 5| Step: 10
Training loss: 2.62314113013012
Validation loss: 2.4340485821141455

Epoch: 55| Step: 0
Training loss: 2.5007964772812823
Validation loss: 2.428324053820774

Epoch: 5| Step: 1
Training loss: 2.759160822573454
Validation loss: 2.434588045218934

Epoch: 5| Step: 2
Training loss: 2.939506819225122
Validation loss: 2.429207186055888

Epoch: 5| Step: 3
Training loss: 2.4905747124969073
Validation loss: 2.4240383408614723

Epoch: 5| Step: 4
Training loss: 2.918667424931028
Validation loss: 2.425828890413332

Epoch: 5| Step: 5
Training loss: 2.584138088599312
Validation loss: 2.4226062047946346

Epoch: 5| Step: 6
Training loss: 3.1294399001650626
Validation loss: 2.4210021124730847

Epoch: 5| Step: 7
Training loss: 2.8033085145278807
Validation loss: 2.4216688255598147

Epoch: 5| Step: 8
Training loss: 2.731788676409395
Validation loss: 2.4356291995721913

Epoch: 5| Step: 9
Training loss: 2.936122165331507
Validation loss: 2.4225974252897235

Epoch: 5| Step: 10
Training loss: 2.7268931890594055
Validation loss: 2.4337510558967494

Epoch: 56| Step: 0
Training loss: 2.4255049543548357
Validation loss: 2.4341111338413057

Epoch: 5| Step: 1
Training loss: 2.743240632414131
Validation loss: 2.415524834264257

Epoch: 5| Step: 2
Training loss: 3.349554425114146
Validation loss: 2.42482740466505

Epoch: 5| Step: 3
Training loss: 2.713875709127724
Validation loss: 2.422430182687925

Epoch: 5| Step: 4
Training loss: 3.1446701493003033
Validation loss: 2.438141539871814

Epoch: 5| Step: 5
Training loss: 2.6650734155215368
Validation loss: 2.4252840097596358

Epoch: 5| Step: 6
Training loss: 3.0239675288904295
Validation loss: 2.416005192216003

Epoch: 5| Step: 7
Training loss: 2.76207043514174
Validation loss: 2.427496541713803

Epoch: 5| Step: 8
Training loss: 2.3459970510843124
Validation loss: 2.422929159784756

Epoch: 5| Step: 9
Training loss: 2.637652467777263
Validation loss: 2.4225554755051313

Epoch: 5| Step: 10
Training loss: 2.6780223955866065
Validation loss: 2.434596537713467

Epoch: 57| Step: 0
Training loss: 2.960123478659485
Validation loss: 2.4242735746561186

Epoch: 5| Step: 1
Training loss: 2.672785286017219
Validation loss: 2.431415056728519

Epoch: 5| Step: 2
Training loss: 2.73996655548178
Validation loss: 2.4275117450536983

Epoch: 5| Step: 3
Training loss: 2.4517440310506977
Validation loss: 2.438915216270171

Epoch: 5| Step: 4
Training loss: 2.7031793313271786
Validation loss: 2.4414191195897357

Epoch: 5| Step: 5
Training loss: 2.1072711766960106
Validation loss: 2.415524508439526

Epoch: 5| Step: 6
Training loss: 2.903595070616157
Validation loss: 2.4256067028092683

Epoch: 5| Step: 7
Training loss: 2.85080288737421
Validation loss: 2.444541377892307

Epoch: 5| Step: 8
Training loss: 2.8009762662830626
Validation loss: 2.429306183416787

Epoch: 5| Step: 9
Training loss: 3.089302333846933
Validation loss: 2.4278078986546068

Epoch: 5| Step: 10
Training loss: 3.2698656501351984
Validation loss: 2.419710987908026

Epoch: 58| Step: 0
Training loss: 2.839536626650439
Validation loss: 2.434631732021975

Epoch: 5| Step: 1
Training loss: 2.6302051707837317
Validation loss: 2.4188115184952617

Epoch: 5| Step: 2
Training loss: 2.467066999975263
Validation loss: 2.4239616748923867

Epoch: 5| Step: 3
Training loss: 2.9725393104360123
Validation loss: 2.421422899636783

Epoch: 5| Step: 4
Training loss: 3.0339398591651023
Validation loss: 2.428058722091889

Epoch: 5| Step: 5
Training loss: 2.7187025570292556
Validation loss: 2.4268177902453303

Epoch: 5| Step: 6
Training loss: 2.886662422012603
Validation loss: 2.4271780248453556

Epoch: 5| Step: 7
Training loss: 2.736513097529935
Validation loss: 2.4224074938404323

Epoch: 5| Step: 8
Training loss: 3.002381015678334
Validation loss: 2.4322061342939962

Epoch: 5| Step: 9
Training loss: 2.5151565779070615
Validation loss: 2.4130338638462487

Epoch: 5| Step: 10
Training loss: 2.6249857402595853
Validation loss: 2.418371857809167

Epoch: 59| Step: 0
Training loss: 2.5285651956593784
Validation loss: 2.4288200199117593

Epoch: 5| Step: 1
Training loss: 2.966320288364293
Validation loss: 2.424882840759134

Epoch: 5| Step: 2
Training loss: 2.763709401661078
Validation loss: 2.4317771731283053

Epoch: 5| Step: 3
Training loss: 3.0374508386723025
Validation loss: 2.418834438208378

Epoch: 5| Step: 4
Training loss: 3.0440057791957056
Validation loss: 2.4218750381072773

Epoch: 5| Step: 5
Training loss: 2.8316424504128306
Validation loss: 2.4270868204102247

Epoch: 5| Step: 6
Training loss: 2.8032041574654167
Validation loss: 2.418988484841459

Epoch: 5| Step: 7
Training loss: 2.1958606619343723
Validation loss: 2.429358112994274

Epoch: 5| Step: 8
Training loss: 3.0338631603888064
Validation loss: 2.428004064882146

Epoch: 5| Step: 9
Training loss: 2.531158351416416
Validation loss: 2.4285900142055366

Epoch: 5| Step: 10
Training loss: 2.5732978713436703
Validation loss: 2.425186472959475

Epoch: 60| Step: 0
Training loss: 2.8043057917809033
Validation loss: 2.4236067154942784

Epoch: 5| Step: 1
Training loss: 2.893661636090953
Validation loss: 2.4255530197962965

Epoch: 5| Step: 2
Training loss: 3.1171466566579396
Validation loss: 2.4288477273845643

Epoch: 5| Step: 3
Training loss: 2.4933403959871243
Validation loss: 2.4214641994050843

Epoch: 5| Step: 4
Training loss: 2.9476317323038623
Validation loss: 2.4215967977194586

Epoch: 5| Step: 5
Training loss: 2.8613314579758744
Validation loss: 2.4366151777666243

Epoch: 5| Step: 6
Training loss: 2.1954041594243585
Validation loss: 2.416024939341301

Epoch: 5| Step: 7
Training loss: 2.883797330033865
Validation loss: 2.425937953941318

Epoch: 5| Step: 8
Training loss: 2.698787848033603
Validation loss: 2.4194565886290547

Epoch: 5| Step: 9
Training loss: 2.3167307531517074
Validation loss: 2.4297583874708204

Epoch: 5| Step: 10
Training loss: 3.114536161714054
Validation loss: 2.4232741173899064

Epoch: 61| Step: 0
Training loss: 2.588759159235866
Validation loss: 2.4234315271853317

Epoch: 5| Step: 1
Training loss: 3.210571268176739
Validation loss: 2.418642341507434

Epoch: 5| Step: 2
Training loss: 3.03147226678871
Validation loss: 2.429642948759991

Epoch: 5| Step: 3
Training loss: 1.960003877558084
Validation loss: 2.4323107865417732

Epoch: 5| Step: 4
Training loss: 2.9676992062532865
Validation loss: 2.4294661791824765

Epoch: 5| Step: 5
Training loss: 2.5064331254147825
Validation loss: 2.4319572639576834

Epoch: 5| Step: 6
Training loss: 2.134597199297111
Validation loss: 2.4142421431630057

Epoch: 5| Step: 7
Training loss: 2.8073952867473126
Validation loss: 2.4233911463845765

Epoch: 5| Step: 8
Training loss: 2.943776506762213
Validation loss: 2.4098355624780408

Epoch: 5| Step: 9
Training loss: 3.190049741112048
Validation loss: 2.428724409525089

Epoch: 5| Step: 10
Training loss: 2.8444300247197756
Validation loss: 2.427168831465174

Epoch: 62| Step: 0
Training loss: 2.987506601493916
Validation loss: 2.429960695203146

Epoch: 5| Step: 1
Training loss: 2.6445454043484298
Validation loss: 2.4260306809786965

Epoch: 5| Step: 2
Training loss: 2.4869860477585326
Validation loss: 2.41862476587795

Epoch: 5| Step: 3
Training loss: 2.8058558503725863
Validation loss: 2.424804243452209

Epoch: 5| Step: 4
Training loss: 2.6050745996201687
Validation loss: 2.4023708520389815

Epoch: 5| Step: 5
Training loss: 3.24743815468154
Validation loss: 2.425983669063082

Epoch: 5| Step: 6
Training loss: 2.6345211110712654
Validation loss: 2.429330579660878

Epoch: 5| Step: 7
Training loss: 2.5239279066753237
Validation loss: 2.4192466719179744

Epoch: 5| Step: 8
Training loss: 3.0492544419870145
Validation loss: 2.424884298668487

Epoch: 5| Step: 9
Training loss: 2.510870189512302
Validation loss: 2.405403667035329

Epoch: 5| Step: 10
Training loss: 2.8272231545070614
Validation loss: 2.4186239205613083

Epoch: 63| Step: 0
Training loss: 2.5227459884186754
Validation loss: 2.4331858708966947

Epoch: 5| Step: 1
Training loss: 3.065870804415554
Validation loss: 2.42137311325845

Epoch: 5| Step: 2
Training loss: 2.795644990477289
Validation loss: 2.4081384232138063

Epoch: 5| Step: 3
Training loss: 3.202075321052635
Validation loss: 2.4307539673044634

Epoch: 5| Step: 4
Training loss: 2.9241567260132575
Validation loss: 2.4225453031695148

Epoch: 5| Step: 5
Training loss: 2.3129458641976965
Validation loss: 2.432270312840794

Epoch: 5| Step: 6
Training loss: 2.487809691967222
Validation loss: 2.421635989946687

Epoch: 5| Step: 7
Training loss: 2.029704870747273
Validation loss: 2.4229726811905623

Epoch: 5| Step: 8
Training loss: 3.254153898232809
Validation loss: 2.430832820455816

Epoch: 5| Step: 9
Training loss: 2.959429595991493
Validation loss: 2.424917277422248

Epoch: 5| Step: 10
Training loss: 2.497750796383122
Validation loss: 2.4254217824873097

Epoch: 64| Step: 0
Training loss: 2.609557276772368
Validation loss: 2.421514654063452

Epoch: 5| Step: 1
Training loss: 2.6914466445172573
Validation loss: 2.4253718086579443

Epoch: 5| Step: 2
Training loss: 3.0882088716162
Validation loss: 2.4212072917414447

Epoch: 5| Step: 3
Training loss: 2.3182602357435806
Validation loss: 2.4133851233001438

Epoch: 5| Step: 4
Training loss: 2.4737044247616176
Validation loss: 2.422896334903413

Epoch: 5| Step: 5
Training loss: 3.2684009197845865
Validation loss: 2.413441971558096

Epoch: 5| Step: 6
Training loss: 3.0453600124764924
Validation loss: 2.423878860441731

Epoch: 5| Step: 7
Training loss: 2.721770176582608
Validation loss: 2.4168452696171574

Epoch: 5| Step: 8
Training loss: 2.684045745232372
Validation loss: 2.4323429373580017

Epoch: 5| Step: 9
Training loss: 2.574241256036622
Validation loss: 2.4310558296070517

Epoch: 5| Step: 10
Training loss: 2.7120236905900237
Validation loss: 2.423484601335803

Epoch: 65| Step: 0
Training loss: 2.357207660692507
Validation loss: 2.4220758625404013

Epoch: 5| Step: 1
Training loss: 2.6239869115549563
Validation loss: 2.423899026768297

Epoch: 5| Step: 2
Training loss: 2.7425802878743606
Validation loss: 2.4125280232082167

Epoch: 5| Step: 3
Training loss: 2.5058162741994323
Validation loss: 2.4299913009436533

Epoch: 5| Step: 4
Training loss: 2.403605704973103
Validation loss: 2.4208748680571435

Epoch: 5| Step: 5
Training loss: 3.1761058533562183
Validation loss: 2.416895004478147

Epoch: 5| Step: 6
Training loss: 2.3688940563030236
Validation loss: 2.4204754901175325

Epoch: 5| Step: 7
Training loss: 3.559666359943894
Validation loss: 2.4142679106577267

Epoch: 5| Step: 8
Training loss: 3.1148198440893515
Validation loss: 2.4150859817474526

Epoch: 5| Step: 9
Training loss: 2.513605859418677
Validation loss: 2.4081179779906687

Epoch: 5| Step: 10
Training loss: 2.612566338385887
Validation loss: 2.4379665894738243

Epoch: 66| Step: 0
Training loss: 2.8335238186999834
Validation loss: 2.424553652197526

Epoch: 5| Step: 1
Training loss: 2.69695207788468
Validation loss: 2.427499007669054

Epoch: 5| Step: 2
Training loss: 2.8037334721588736
Validation loss: 2.417652904483776

Epoch: 5| Step: 3
Training loss: 2.702606768903045
Validation loss: 2.4328537699213064

Epoch: 5| Step: 4
Training loss: 2.8681680525380826
Validation loss: 2.4178087663750714

Epoch: 5| Step: 5
Training loss: 2.9802949987239424
Validation loss: 2.425065234378492

Epoch: 5| Step: 6
Training loss: 2.270447747861431
Validation loss: 2.4309725365545622

Epoch: 5| Step: 7
Training loss: 2.9446975511251643
Validation loss: 2.4425165055722227

Epoch: 5| Step: 8
Training loss: 2.810542972819129
Validation loss: 2.444200194819841

Epoch: 5| Step: 9
Training loss: 2.6850927350387837
Validation loss: 2.423235010901676

Epoch: 5| Step: 10
Training loss: 2.594144584332216
Validation loss: 2.428308982254345

Epoch: 67| Step: 0
Training loss: 2.4360215031280803
Validation loss: 2.4195430075369617

Epoch: 5| Step: 1
Training loss: 3.122045264503056
Validation loss: 2.4171747597138316

Epoch: 5| Step: 2
Training loss: 2.9118472108581392
Validation loss: 2.4310765648983708

Epoch: 5| Step: 3
Training loss: 2.5355996330483626
Validation loss: 2.429757192568583

Epoch: 5| Step: 4
Training loss: 2.7948242852896015
Validation loss: 2.428305785499315

Epoch: 5| Step: 5
Training loss: 2.8010318489701813
Validation loss: 2.427588928309862

Epoch: 5| Step: 6
Training loss: 2.617583651950263
Validation loss: 2.4271218775072665

Epoch: 5| Step: 7
Training loss: 2.4445367624690664
Validation loss: 2.4243428058320973

Epoch: 5| Step: 8
Training loss: 2.822614580908484
Validation loss: 2.4358703396905823

Epoch: 5| Step: 9
Training loss: 2.8205067575607403
Validation loss: 2.412505126468211

Epoch: 5| Step: 10
Training loss: 2.8609078056256965
Validation loss: 2.4395589260143047

Epoch: 68| Step: 0
Training loss: 2.5937294097450803
Validation loss: 2.4209670837701065

Epoch: 5| Step: 1
Training loss: 3.0173745886049654
Validation loss: 2.4384844590178227

Epoch: 5| Step: 2
Training loss: 2.803465340492769
Validation loss: 2.41991695201043

Epoch: 5| Step: 3
Training loss: 2.843107046027444
Validation loss: 2.4336110747830775

Epoch: 5| Step: 4
Training loss: 2.9386420769063646
Validation loss: 2.423876966171251

Epoch: 5| Step: 5
Training loss: 2.2892167491824686
Validation loss: 2.413101762292346

Epoch: 5| Step: 6
Training loss: 2.5268828783990447
Validation loss: 2.4207810677242403

Epoch: 5| Step: 7
Training loss: 2.7840943097605133
Validation loss: 2.420306895497073

Epoch: 5| Step: 8
Training loss: 2.455218060009841
Validation loss: 2.408875971426328

Epoch: 5| Step: 9
Training loss: 2.792816883573307
Validation loss: 2.4324678697683493

Epoch: 5| Step: 10
Training loss: 3.1636080945405176
Validation loss: 2.415096810198155

Epoch: 69| Step: 0
Training loss: 2.7291924764174733
Validation loss: 2.425958150705127

Epoch: 5| Step: 1
Training loss: 2.5575970521114617
Validation loss: 2.4236733472599123

Epoch: 5| Step: 2
Training loss: 3.022964795441717
Validation loss: 2.4050474673873556

Epoch: 5| Step: 3
Training loss: 3.106791741086832
Validation loss: 2.4074844264504915

Epoch: 5| Step: 4
Training loss: 2.885931545183268
Validation loss: 2.406274697121495

Epoch: 5| Step: 5
Training loss: 2.945148331901029
Validation loss: 2.4199471995814905

Epoch: 5| Step: 6
Training loss: 2.516318563255831
Validation loss: 2.422619987489655

Epoch: 5| Step: 7
Training loss: 3.0513729444814635
Validation loss: 2.435401269609009

Epoch: 5| Step: 8
Training loss: 1.743741082609612
Validation loss: 2.414931050290843

Epoch: 5| Step: 9
Training loss: 2.5786993138430465
Validation loss: 2.4176716657863957

Epoch: 5| Step: 10
Training loss: 2.7368110486538773
Validation loss: 2.409770840691266

Epoch: 70| Step: 0
Training loss: 2.645874854134998
Validation loss: 2.4267634156690363

Epoch: 5| Step: 1
Training loss: 2.855427669955015
Validation loss: 2.4170351868391906

Epoch: 5| Step: 2
Training loss: 2.721360805570301
Validation loss: 2.4143749363687266

Epoch: 5| Step: 3
Training loss: 2.705843754466245
Validation loss: 2.415335239295945

Epoch: 5| Step: 4
Training loss: 2.657822984678118
Validation loss: 2.41248846729822

Epoch: 5| Step: 5
Training loss: 2.711468647309387
Validation loss: 2.4148611984291115

Epoch: 5| Step: 6
Training loss: 2.683719992965151
Validation loss: 2.4301741572003706

Epoch: 5| Step: 7
Training loss: 2.7918818566430486
Validation loss: 2.424421580412897

Epoch: 5| Step: 8
Training loss: 2.3042088932999114
Validation loss: 2.4246669368032836

Epoch: 5| Step: 9
Training loss: 2.979562444118001
Validation loss: 2.42568696405374

Epoch: 5| Step: 10
Training loss: 3.063366203034904
Validation loss: 2.4273927919014207

Epoch: 71| Step: 0
Training loss: 2.4448415284394467
Validation loss: 2.4239034636126147

Epoch: 5| Step: 1
Training loss: 2.634078267718157
Validation loss: 2.420490682482017

Epoch: 5| Step: 2
Training loss: 2.8818081395855186
Validation loss: 2.4234155069670287

Epoch: 5| Step: 3
Training loss: 3.6041843362422874
Validation loss: 2.427921901481207

Epoch: 5| Step: 4
Training loss: 2.4719995286441097
Validation loss: 2.409763502225827

Epoch: 5| Step: 5
Training loss: 2.326375419109566
Validation loss: 2.423489074905074

Epoch: 5| Step: 6
Training loss: 3.010113675578513
Validation loss: 2.4170237518897864

Epoch: 5| Step: 7
Training loss: 2.364986189303892
Validation loss: 2.4187571568367425

Epoch: 5| Step: 8
Training loss: 2.7970604861678
Validation loss: 2.4244974583580934

Epoch: 5| Step: 9
Training loss: 2.7527967449997113
Validation loss: 2.422446501509301

Epoch: 5| Step: 10
Training loss: 2.71407512514717
Validation loss: 2.423016327721044

Epoch: 72| Step: 0
Training loss: 3.129589220580745
Validation loss: 2.41083659582151

Epoch: 5| Step: 1
Training loss: 2.587169157982168
Validation loss: 2.4240170705020865

Epoch: 5| Step: 2
Training loss: 2.807858685265934
Validation loss: 2.425717712492851

Epoch: 5| Step: 3
Training loss: 2.5747983798007867
Validation loss: 2.40988822544032

Epoch: 5| Step: 4
Training loss: 2.8837189528600864
Validation loss: 2.4270772802291596

Epoch: 5| Step: 5
Training loss: 2.7799819455829806
Validation loss: 2.4154417103871952

Epoch: 5| Step: 6
Training loss: 2.9855561640204504
Validation loss: 2.418091089700656

Epoch: 5| Step: 7
Training loss: 3.0264070501468754
Validation loss: 2.4152214957631775

Epoch: 5| Step: 8
Training loss: 2.3512479755528775
Validation loss: 2.4174713535513828

Epoch: 5| Step: 9
Training loss: 2.2117218675123187
Validation loss: 2.423419124854429

Epoch: 5| Step: 10
Training loss: 2.5840736886964506
Validation loss: 2.4137911908440532

Epoch: 73| Step: 0
Training loss: 2.8381713812322196
Validation loss: 2.403780604059579

Epoch: 5| Step: 1
Training loss: 2.522389764257945
Validation loss: 2.425290338295344

Epoch: 5| Step: 2
Training loss: 2.582543395897369
Validation loss: 2.4197105164384167

Epoch: 5| Step: 3
Training loss: 2.7833370136381324
Validation loss: 2.4090965617755615

Epoch: 5| Step: 4
Training loss: 2.799689810464823
Validation loss: 2.4098006773126315

Epoch: 5| Step: 5
Training loss: 2.2306996241063657
Validation loss: 2.4121037718008798

Epoch: 5| Step: 6
Training loss: 2.382205072743729
Validation loss: 2.427097426318164

Epoch: 5| Step: 7
Training loss: 2.8297849388766223
Validation loss: 2.420930654101445

Epoch: 5| Step: 8
Training loss: 2.675913118329088
Validation loss: 2.412102953426626

Epoch: 5| Step: 9
Training loss: 3.36617977348136
Validation loss: 2.4270366548199496

Epoch: 5| Step: 10
Training loss: 2.8862499222852485
Validation loss: 2.417020314287983

Epoch: 74| Step: 0
Training loss: 2.48211221391791
Validation loss: 2.415505840837844

Epoch: 5| Step: 1
Training loss: 2.521113881875093
Validation loss: 2.426180590364623

Epoch: 5| Step: 2
Training loss: 2.327781088600849
Validation loss: 2.408900512852543

Epoch: 5| Step: 3
Training loss: 2.3394629370763407
Validation loss: 2.4387126542872024

Epoch: 5| Step: 4
Training loss: 2.7996973895990327
Validation loss: 2.4242964374426315

Epoch: 5| Step: 5
Training loss: 3.4255092604220625
Validation loss: 2.4158741875459513

Epoch: 5| Step: 6
Training loss: 3.0697822404105537
Validation loss: 2.4206266988281135

Epoch: 5| Step: 7
Training loss: 2.7256660627330467
Validation loss: 2.4166974501369496

Epoch: 5| Step: 8
Training loss: 2.366995221376934
Validation loss: 2.4213070714625107

Epoch: 5| Step: 9
Training loss: 2.849432999275189
Validation loss: 2.4143565752427194

Epoch: 5| Step: 10
Training loss: 2.9442875138534617
Validation loss: 2.4245446159307154

Epoch: 75| Step: 0
Training loss: 2.3640155754802636
Validation loss: 2.4328246965472142

Epoch: 5| Step: 1
Training loss: 2.7015858937668717
Validation loss: 2.402535543948523

Epoch: 5| Step: 2
Training loss: 2.6447077682387374
Validation loss: 2.419477825969698

Epoch: 5| Step: 3
Training loss: 3.0827954484687448
Validation loss: 2.419923576379477

Epoch: 5| Step: 4
Training loss: 2.836851703004383
Validation loss: 2.4355596050316564

Epoch: 5| Step: 5
Training loss: 2.3681766470348617
Validation loss: 2.415989646944718

Epoch: 5| Step: 6
Training loss: 2.7509463155896197
Validation loss: 2.4115605015173105

Epoch: 5| Step: 7
Training loss: 2.813479613196888
Validation loss: 2.433501691454237

Epoch: 5| Step: 8
Training loss: 2.283425848077448
Validation loss: 2.4113886161837708

Epoch: 5| Step: 9
Training loss: 3.3730796719598355
Validation loss: 2.4336495046852766

Epoch: 5| Step: 10
Training loss: 2.502306065318799
Validation loss: 2.430773744375396

Epoch: 76| Step: 0
Training loss: 2.590155535265961
Validation loss: 2.427121215240195

Epoch: 5| Step: 1
Training loss: 3.1503888087022043
Validation loss: 2.4245096643148707

Epoch: 5| Step: 2
Training loss: 2.635298644628463
Validation loss: 2.4213075277982736

Epoch: 5| Step: 3
Training loss: 2.7700766388244453
Validation loss: 2.430981656494132

Epoch: 5| Step: 4
Training loss: 2.7395531153493025
Validation loss: 2.4346971996850173

Epoch: 5| Step: 5
Training loss: 2.877761509709013
Validation loss: 2.429190308992583

Epoch: 5| Step: 6
Training loss: 2.9714855239723525
Validation loss: 2.4203160831652597

Epoch: 5| Step: 7
Training loss: 2.438461211999891
Validation loss: 2.4139038675241893

Epoch: 5| Step: 8
Training loss: 2.581313687109206
Validation loss: 2.439793743567421

Epoch: 5| Step: 9
Training loss: 2.282942992860024
Validation loss: 2.4287545780191535

Epoch: 5| Step: 10
Training loss: 2.9367817751450684
Validation loss: 2.4306851185976965

Epoch: 77| Step: 0
Training loss: 2.802128211209195
Validation loss: 2.411899213174111

Epoch: 5| Step: 1
Training loss: 2.8523075332369325
Validation loss: 2.4293134190530195

Epoch: 5| Step: 2
Training loss: 2.582948738100465
Validation loss: 2.420955277703296

Epoch: 5| Step: 3
Training loss: 2.623157944816627
Validation loss: 2.4240487464749685

Epoch: 5| Step: 4
Training loss: 2.9114269784912046
Validation loss: 2.4330110467419295

Epoch: 5| Step: 5
Training loss: 2.6475783673467865
Validation loss: 2.3992755613909797

Epoch: 5| Step: 6
Training loss: 3.0030570349013694
Validation loss: 2.4200652835308007

Epoch: 5| Step: 7
Training loss: 2.6448959031560193
Validation loss: 2.4203918218419407

Epoch: 5| Step: 8
Training loss: 2.460228711948138
Validation loss: 2.4268053534572616

Epoch: 5| Step: 9
Training loss: 2.421803134959469
Validation loss: 2.4300097918569517

Epoch: 5| Step: 10
Training loss: 2.912932066733248
Validation loss: 2.4347725115392147

Epoch: 78| Step: 0
Training loss: 3.0284691078710217
Validation loss: 2.4264667521228844

Epoch: 5| Step: 1
Training loss: 2.734863063306209
Validation loss: 2.417900980274478

Epoch: 5| Step: 2
Training loss: 2.8358867209856418
Validation loss: 2.416390492511315

Epoch: 5| Step: 3
Training loss: 2.255620611857191
Validation loss: 2.424324099328339

Epoch: 5| Step: 4
Training loss: 2.4882726264935933
Validation loss: 2.423275687349096

Epoch: 5| Step: 5
Training loss: 2.8478367542886214
Validation loss: 2.4278887856187437

Epoch: 5| Step: 6
Training loss: 2.489772667063157
Validation loss: 2.4162227401807135

Epoch: 5| Step: 7
Training loss: 2.9842104242293472
Validation loss: 2.4282054761986935

Epoch: 5| Step: 8
Training loss: 2.705241262426209
Validation loss: 2.414283074125355

Epoch: 5| Step: 9
Training loss: 2.7172229907112886
Validation loss: 2.425161536075574

Epoch: 5| Step: 10
Training loss: 2.76777169056138
Validation loss: 2.4265267259691927

Epoch: 79| Step: 0
Training loss: 2.8013796200396923
Validation loss: 2.4167112198549856

Epoch: 5| Step: 1
Training loss: 2.967100950307624
Validation loss: 2.4167647513349393

Epoch: 5| Step: 2
Training loss: 2.8605509356728143
Validation loss: 2.4223077689730923

Epoch: 5| Step: 3
Training loss: 2.739804615516821
Validation loss: 2.408293208308067

Epoch: 5| Step: 4
Training loss: 2.584708852549453
Validation loss: 2.4107050917381145

Epoch: 5| Step: 5
Training loss: 3.04113824164729
Validation loss: 2.4179013715160242

Epoch: 5| Step: 6
Training loss: 2.3872098776413537
Validation loss: 2.425248869014725

Epoch: 5| Step: 7
Training loss: 2.7481272129226046
Validation loss: 2.4051600228783414

Epoch: 5| Step: 8
Training loss: 2.6446514243201213
Validation loss: 2.429778367309782

Epoch: 5| Step: 9
Training loss: 2.3014167982962106
Validation loss: 2.420277553829765

Epoch: 5| Step: 10
Training loss: 2.6808284188003086
Validation loss: 2.411976775925938

Epoch: 80| Step: 0
Training loss: 2.883072838748663
Validation loss: 2.4215933253216915

Epoch: 5| Step: 1
Training loss: 2.8439294108712603
Validation loss: 2.4207574018264513

Epoch: 5| Step: 2
Training loss: 2.6381118823974528
Validation loss: 2.4175552443192734

Epoch: 5| Step: 3
Training loss: 2.741507334461242
Validation loss: 2.420978209947923

Epoch: 5| Step: 4
Training loss: 3.1702151912008287
Validation loss: 2.4327819330817113

Epoch: 5| Step: 5
Training loss: 2.2179952062928225
Validation loss: 2.407248137769938

Epoch: 5| Step: 6
Training loss: 2.797959101609125
Validation loss: 2.427657912345636

Epoch: 5| Step: 7
Training loss: 2.8874299408311206
Validation loss: 2.415467303761073

Epoch: 5| Step: 8
Training loss: 2.1958425296057635
Validation loss: 2.4190707015606843

Epoch: 5| Step: 9
Training loss: 2.7803190580644213
Validation loss: 2.4151717482003616

Epoch: 5| Step: 10
Training loss: 2.493185770169647
Validation loss: 2.4342037543770614

Epoch: 81| Step: 0
Training loss: 2.666829392316079
Validation loss: 2.4223866409522903

Epoch: 5| Step: 1
Training loss: 2.4881969299881277
Validation loss: 2.427515665210367

Epoch: 5| Step: 2
Training loss: 2.990725486286926
Validation loss: 2.415763937436297

Epoch: 5| Step: 3
Training loss: 2.5307702445803475
Validation loss: 2.4108590107499355

Epoch: 5| Step: 4
Training loss: 2.4288737906234625
Validation loss: 2.4274099169775143

Epoch: 5| Step: 5
Training loss: 2.2724675472279787
Validation loss: 2.4117863237862736

Epoch: 5| Step: 6
Training loss: 3.095851146155582
Validation loss: 2.407905934662698

Epoch: 5| Step: 7
Training loss: 2.4992077525815986
Validation loss: 2.4192120029985245

Epoch: 5| Step: 8
Training loss: 2.701097554958689
Validation loss: 2.4188578929315723

Epoch: 5| Step: 9
Training loss: 2.647250199100603
Validation loss: 2.4171181742495027

Epoch: 5| Step: 10
Training loss: 3.2905628107901803
Validation loss: 2.4206443420003247

Epoch: 82| Step: 0
Training loss: 3.226841801338308
Validation loss: 2.417141316837843

Epoch: 5| Step: 1
Training loss: 2.4551606691697363
Validation loss: 2.414635185960361

Epoch: 5| Step: 2
Training loss: 2.014562282301051
Validation loss: 2.414987532014636

Epoch: 5| Step: 3
Training loss: 2.7399053831540376
Validation loss: 2.423058751454429

Epoch: 5| Step: 4
Training loss: 3.1883845878292703
Validation loss: 2.4288171030117454

Epoch: 5| Step: 5
Training loss: 2.570221409444504
Validation loss: 2.409697993356873

Epoch: 5| Step: 6
Training loss: 2.7304095478761607
Validation loss: 2.4267639977471287

Epoch: 5| Step: 7
Training loss: 3.198628167310161
Validation loss: 2.419571277377998

Epoch: 5| Step: 8
Training loss: 1.9280618468689126
Validation loss: 2.414090508001407

Epoch: 5| Step: 9
Training loss: 2.89484159836746
Validation loss: 2.4267956589932744

Epoch: 5| Step: 10
Training loss: 2.3673980921370306
Validation loss: 2.4301629507536298

Epoch: 83| Step: 0
Training loss: 2.5457998241294137
Validation loss: 2.420905798866552

Epoch: 5| Step: 1
Training loss: 2.520964458827879
Validation loss: 2.439166813554319

Epoch: 5| Step: 2
Training loss: 2.5023946737252256
Validation loss: 2.417756564348158

Epoch: 5| Step: 3
Training loss: 2.3714889875683505
Validation loss: 2.428666691352087

Epoch: 5| Step: 4
Training loss: 3.1200111239797406
Validation loss: 2.419248911032414

Epoch: 5| Step: 5
Training loss: 2.7102561776110408
Validation loss: 2.4132215298332467

Epoch: 5| Step: 6
Training loss: 2.7534112580135237
Validation loss: 2.420262405674793

Epoch: 5| Step: 7
Training loss: 3.099166444260611
Validation loss: 2.4281502690533103

Epoch: 5| Step: 8
Training loss: 2.424017370860489
Validation loss: 2.4450393246871363

Epoch: 5| Step: 9
Training loss: 2.74925542635138
Validation loss: 2.4205967404080706

Epoch: 5| Step: 10
Training loss: 2.8944841347590886
Validation loss: 2.426307544378235

Epoch: 84| Step: 0
Training loss: 2.821357005282622
Validation loss: 2.4186328517539293

Epoch: 5| Step: 1
Training loss: 2.650147192843785
Validation loss: 2.427757491363366

Epoch: 5| Step: 2
Training loss: 2.7085849547264003
Validation loss: 2.422292422902109

Epoch: 5| Step: 3
Training loss: 1.8994202130764815
Validation loss: 2.4255969496521224

Epoch: 5| Step: 4
Training loss: 2.638642238221795
Validation loss: 2.436347465975872

Epoch: 5| Step: 5
Training loss: 2.7695303891372958
Validation loss: 2.4076927812705904

Epoch: 5| Step: 6
Training loss: 2.1336451431727963
Validation loss: 2.4010654973509626

Epoch: 5| Step: 7
Training loss: 3.114098722761136
Validation loss: 2.41083326743304

Epoch: 5| Step: 8
Training loss: 2.75472226870141
Validation loss: 2.428482376683852

Epoch: 5| Step: 9
Training loss: 3.177587617135867
Validation loss: 2.429581126665557

Epoch: 5| Step: 10
Training loss: 2.7089169582567414
Validation loss: 2.4088020742560157

Epoch: 85| Step: 0
Training loss: 2.918950049918789
Validation loss: 2.4264667140877196

Epoch: 5| Step: 1
Training loss: 2.7723738229037798
Validation loss: 2.4057547234423233

Epoch: 5| Step: 2
Training loss: 2.4529958314358686
Validation loss: 2.4078582281697254

Epoch: 5| Step: 3
Training loss: 2.466456929732276
Validation loss: 2.427312942988967

Epoch: 5| Step: 4
Training loss: 3.0875153575932255
Validation loss: 2.4214355345249428

Epoch: 5| Step: 5
Training loss: 2.631986222373127
Validation loss: 2.421462599686088

Epoch: 5| Step: 6
Training loss: 2.897300312050093
Validation loss: 2.412520636809731

Epoch: 5| Step: 7
Training loss: 2.7160004491229803
Validation loss: 2.4164263737004905

Epoch: 5| Step: 8
Training loss: 2.4642298397893216
Validation loss: 2.4218022409995577

Epoch: 5| Step: 9
Training loss: 2.666302050061445
Validation loss: 2.4336665204233023

Epoch: 5| Step: 10
Training loss: 2.369294591619506
Validation loss: 2.4316178924147653

Epoch: 86| Step: 0
Training loss: 1.8327045301552798
Validation loss: 2.4097934442584608

Epoch: 5| Step: 1
Training loss: 2.9527510148856444
Validation loss: 2.417974788090935

Epoch: 5| Step: 2
Training loss: 3.2754415782224897
Validation loss: 2.428916170628131

Epoch: 5| Step: 3
Training loss: 2.766815360412932
Validation loss: 2.4242713972869905

Epoch: 5| Step: 4
Training loss: 2.9533717138180338
Validation loss: 2.4399901513032534

Epoch: 5| Step: 5
Training loss: 2.268525995803009
Validation loss: 2.428446650929618

Epoch: 5| Step: 6
Training loss: 2.3369230404915298
Validation loss: 2.4288482741317665

Epoch: 5| Step: 7
Training loss: 2.3489587506098633
Validation loss: 2.4209772484414747

Epoch: 5| Step: 8
Training loss: 2.570361290558482
Validation loss: 2.4359559837058438

Epoch: 5| Step: 9
Training loss: 2.9967859853625565
Validation loss: 2.4361334409996154

Epoch: 5| Step: 10
Training loss: 2.999757280067647
Validation loss: 2.4317230960483753

Epoch: 87| Step: 0
Training loss: 2.142142544531364
Validation loss: 2.426633969019833

Epoch: 5| Step: 1
Training loss: 2.622569366643183
Validation loss: 2.42191962532798

Epoch: 5| Step: 2
Training loss: 2.3435601729767455
Validation loss: 2.4366154955104475

Epoch: 5| Step: 3
Training loss: 3.145647426610927
Validation loss: 2.431374035644927

Epoch: 5| Step: 4
Training loss: 2.8529216714797188
Validation loss: 2.433180444774444

Epoch: 5| Step: 5
Training loss: 2.5920625275970206
Validation loss: 2.432649099258785

Epoch: 5| Step: 6
Training loss: 2.7747353539269786
Validation loss: 2.4334541780765115

Epoch: 5| Step: 7
Training loss: 3.1094446222379726
Validation loss: 2.4206502039658724

Epoch: 5| Step: 8
Training loss: 2.4762465218255283
Validation loss: 2.441784450712993

Epoch: 5| Step: 9
Training loss: 2.4991580499049157
Validation loss: 2.4337499967328657

Epoch: 5| Step: 10
Training loss: 2.855858980955468
Validation loss: 2.4297539523494924

Epoch: 88| Step: 0
Training loss: 2.8899720150341706
Validation loss: 2.4370489121158583

Epoch: 5| Step: 1
Training loss: 2.6818514169417536
Validation loss: 2.4235045678409084

Epoch: 5| Step: 2
Training loss: 2.909774939626738
Validation loss: 2.4293192637935404

Epoch: 5| Step: 3
Training loss: 2.751438978153157
Validation loss: 2.4424282618071804

Epoch: 5| Step: 4
Training loss: 2.1774429194680405
Validation loss: 2.4260915706649153

Epoch: 5| Step: 5
Training loss: 2.711153313129392
Validation loss: 2.4237686592439878

Epoch: 5| Step: 6
Training loss: 2.6493944447877644
Validation loss: 2.4250132033582035

Epoch: 5| Step: 7
Training loss: 2.5933063541306707
Validation loss: 2.429955292474487

Epoch: 5| Step: 8
Training loss: 3.061127958657145
Validation loss: 2.430881633732668

Epoch: 5| Step: 9
Training loss: 2.1982230986787807
Validation loss: 2.433630596882641

Epoch: 5| Step: 10
Training loss: 2.811689132784587
Validation loss: 2.416606646320381

Epoch: 89| Step: 0
Training loss: 2.829718378025981
Validation loss: 2.422510868768889

Epoch: 5| Step: 1
Training loss: 2.741278081872717
Validation loss: 2.4300114861733446

Epoch: 5| Step: 2
Training loss: 2.915455339571528
Validation loss: 2.4434253558499384

Epoch: 5| Step: 3
Training loss: 2.644425676004963
Validation loss: 2.4187876202898124

Epoch: 5| Step: 4
Training loss: 2.103057896534072
Validation loss: 2.4385936672030035

Epoch: 5| Step: 5
Training loss: 2.5071870493303026
Validation loss: 2.404811406187752

Epoch: 5| Step: 6
Training loss: 2.6419199640595816
Validation loss: 2.4304566664338387

Epoch: 5| Step: 7
Training loss: 3.1028027877171525
Validation loss: 2.4253528912881523

Epoch: 5| Step: 8
Training loss: 2.428831875884174
Validation loss: 2.411408574404591

Epoch: 5| Step: 9
Training loss: 2.660205543722341
Validation loss: 2.4285250680703157

Epoch: 5| Step: 10
Training loss: 2.7888593840167633
Validation loss: 2.4119955664991743

Epoch: 90| Step: 0
Training loss: 2.502391434333366
Validation loss: 2.4127107717212555

Epoch: 5| Step: 1
Training loss: 2.298327758575753
Validation loss: 2.4251170401729434

Epoch: 5| Step: 2
Training loss: 3.1074065298568314
Validation loss: 2.4184197130831238

Epoch: 5| Step: 3
Training loss: 3.2786165841605537
Validation loss: 2.4224672607538094

Epoch: 5| Step: 4
Training loss: 2.483138442445976
Validation loss: 2.430640842994255

Epoch: 5| Step: 5
Training loss: 2.5510262200814817
Validation loss: 2.4169924760032955

Epoch: 5| Step: 6
Training loss: 2.6840274465894365
Validation loss: 2.4069163232629367

Epoch: 5| Step: 7
Training loss: 2.3307080372681974
Validation loss: 2.4315925597018193

Epoch: 5| Step: 8
Training loss: 2.8901003799693235
Validation loss: 2.4120222667389455

Epoch: 5| Step: 9
Training loss: 2.4518738489977263
Validation loss: 2.433395267827222

Epoch: 5| Step: 10
Training loss: 2.698208963670772
Validation loss: 2.4149394760304626

Epoch: 91| Step: 0
Training loss: 2.5872894164560747
Validation loss: 2.433824351445934

Epoch: 5| Step: 1
Training loss: 2.46227613099542
Validation loss: 2.4382443675824783

Epoch: 5| Step: 2
Training loss: 2.909881947538147
Validation loss: 2.428402841244799

Epoch: 5| Step: 3
Training loss: 2.4220077970459584
Validation loss: 2.4194259640619813

Epoch: 5| Step: 4
Training loss: 2.848933097174325
Validation loss: 2.415909718265483

Epoch: 5| Step: 5
Training loss: 2.924577248825988
Validation loss: 2.4118848882440895

Epoch: 5| Step: 6
Training loss: 2.923841661155624
Validation loss: 2.408647839136036

Epoch: 5| Step: 7
Training loss: 2.55937693017088
Validation loss: 2.440761103225361

Epoch: 5| Step: 8
Training loss: 2.6430762837111064
Validation loss: 2.414696892778176

Epoch: 5| Step: 9
Training loss: 2.2482851699221227
Validation loss: 2.425375551525101

Epoch: 5| Step: 10
Training loss: 2.9027053381861676
Validation loss: 2.425823719435672

Epoch: 92| Step: 0
Training loss: 3.167763135378078
Validation loss: 2.4258577908288226

Epoch: 5| Step: 1
Training loss: 2.9122454421493775
Validation loss: 2.4216101833427954

Epoch: 5| Step: 2
Training loss: 3.250711656562127
Validation loss: 2.433321364094213

Epoch: 5| Step: 3
Training loss: 2.371005966346342
Validation loss: 2.412774254365002

Epoch: 5| Step: 4
Training loss: 2.27749586169875
Validation loss: 2.4222996440343794

Epoch: 5| Step: 5
Training loss: 2.8291357773755172
Validation loss: 2.4192594654672694

Epoch: 5| Step: 6
Training loss: 2.1017247247302584
Validation loss: 2.41763601144608

Epoch: 5| Step: 7
Training loss: 3.136050104344318
Validation loss: 2.4260533391116876

Epoch: 5| Step: 8
Training loss: 2.7476312666021023
Validation loss: 2.423118580595777

Epoch: 5| Step: 9
Training loss: 1.8573308013826644
Validation loss: 2.4256491943249894

Epoch: 5| Step: 10
Training loss: 2.338400878293228
Validation loss: 2.432936939560183

Epoch: 93| Step: 0
Training loss: 2.52250923586044
Validation loss: 2.445043925531144

Epoch: 5| Step: 1
Training loss: 2.432507414850615
Validation loss: 2.440641201325224

Epoch: 5| Step: 2
Training loss: 2.971975561901469
Validation loss: 2.417894690713345

Epoch: 5| Step: 3
Training loss: 2.0620754845434437
Validation loss: 2.4217947738543812

Epoch: 5| Step: 4
Training loss: 2.646840832342238
Validation loss: 2.4376367762505744

Epoch: 5| Step: 5
Training loss: 2.494240611677805
Validation loss: 2.4252537325563135

Epoch: 5| Step: 6
Training loss: 2.2284714396022225
Validation loss: 2.4272395891759277

Epoch: 5| Step: 7
Training loss: 2.9273516078382325
Validation loss: 2.428923107674464

Epoch: 5| Step: 8
Training loss: 3.451980884591902
Validation loss: 2.4244196929110067

Epoch: 5| Step: 9
Training loss: 2.5232721516672343
Validation loss: 2.4257341307357025

Epoch: 5| Step: 10
Training loss: 2.678101896277605
Validation loss: 2.445215053373415

Epoch: 94| Step: 0
Training loss: 2.45007776409441
Validation loss: 2.4468904444382686

Epoch: 5| Step: 1
Training loss: 2.7361659696945653
Validation loss: 2.4313829474168815

Epoch: 5| Step: 2
Training loss: 2.864145603836863
Validation loss: 2.4196820214922634

Epoch: 5| Step: 3
Training loss: 2.478938362016983
Validation loss: 2.432417275534352

Epoch: 5| Step: 4
Training loss: 2.2955723396656844
Validation loss: 2.4336555760297096

Epoch: 5| Step: 5
Training loss: 2.853994006946583
Validation loss: 2.4384792402329802

Epoch: 5| Step: 6
Training loss: 2.3097473463796137
Validation loss: 2.4273778428732973

Epoch: 5| Step: 7
Training loss: 2.5894196912558187
Validation loss: 2.435190162858262

Epoch: 5| Step: 8
Training loss: 2.496831220832659
Validation loss: 2.4367889732424173

Epoch: 5| Step: 9
Training loss: 3.234855874107086
Validation loss: 2.4354197489212996

Epoch: 5| Step: 10
Training loss: 2.669629676082785
Validation loss: 2.428365264723627

Epoch: 95| Step: 0
Training loss: 2.274079851464632
Validation loss: 2.432339253695362

Epoch: 5| Step: 1
Training loss: 2.935881797988927
Validation loss: 2.4288363374935265

Epoch: 5| Step: 2
Training loss: 2.677596363431469
Validation loss: 2.4303210504461172

Epoch: 5| Step: 3
Training loss: 2.6644891749595385
Validation loss: 2.4282757518436506

Epoch: 5| Step: 4
Training loss: 2.5748871787826886
Validation loss: 2.4229902723647476

Epoch: 5| Step: 5
Training loss: 2.5593577401833314
Validation loss: 2.437839451815973

Epoch: 5| Step: 6
Training loss: 2.6699234823628117
Validation loss: 2.4289502255568496

Epoch: 5| Step: 7
Training loss: 2.675894140382053
Validation loss: 2.4254615090391543

Epoch: 5| Step: 8
Training loss: 3.1339641936982643
Validation loss: 2.4392952745726872

Epoch: 5| Step: 9
Training loss: 2.3469342789357257
Validation loss: 2.421862948014212

Epoch: 5| Step: 10
Training loss: 2.659838955815563
Validation loss: 2.4470080516653603

Epoch: 96| Step: 0
Training loss: 2.398026123553621
Validation loss: 2.4429035731012836

Epoch: 5| Step: 1
Training loss: 2.3308409140168873
Validation loss: 2.437022336692534

Epoch: 5| Step: 2
Training loss: 2.422824205999831
Validation loss: 2.4342694726143144

Epoch: 5| Step: 3
Training loss: 2.2902939123918484
Validation loss: 2.437625395875802

Epoch: 5| Step: 4
Training loss: 3.6093739431140226
Validation loss: 2.427837501996402

Epoch: 5| Step: 5
Training loss: 2.724109059546707
Validation loss: 2.4165033593620375

Epoch: 5| Step: 6
Training loss: 2.8850588433200017
Validation loss: 2.429899919352083

Epoch: 5| Step: 7
Training loss: 2.4636925186736685
Validation loss: 2.4360876195809387

Epoch: 5| Step: 8
Training loss: 2.285948526351942
Validation loss: 2.4200164501794164

Epoch: 5| Step: 9
Training loss: 2.7195656090165587
Validation loss: 2.42694936455905

Epoch: 5| Step: 10
Training loss: 2.819850218021375
Validation loss: 2.418898144861159

Epoch: 97| Step: 0
Training loss: 2.394748596981094
Validation loss: 2.4329688365878885

Epoch: 5| Step: 1
Training loss: 2.199006471840363
Validation loss: 2.4277023405582496

Epoch: 5| Step: 2
Training loss: 2.5482009525314955
Validation loss: 2.4321216642328665

Epoch: 5| Step: 3
Training loss: 3.049686953629293
Validation loss: 2.4251838043340244

Epoch: 5| Step: 4
Training loss: 2.76321314586766
Validation loss: 2.426108946907491

Epoch: 5| Step: 5
Training loss: 2.557924232535931
Validation loss: 2.441325756821591

Epoch: 5| Step: 6
Training loss: 2.576776695254564
Validation loss: 2.4351709053963746

Epoch: 5| Step: 7
Training loss: 2.7837818922623487
Validation loss: 2.441011126040134

Epoch: 5| Step: 8
Training loss: 2.670153861023841
Validation loss: 2.4410280642065674

Epoch: 5| Step: 9
Training loss: 3.103173747837065
Validation loss: 2.4466305274397793

Epoch: 5| Step: 10
Training loss: 2.346619845360325
Validation loss: 2.423215857854912

Epoch: 98| Step: 0
Training loss: 2.397304503393035
Validation loss: 2.4276693658459827

Epoch: 5| Step: 1
Training loss: 2.7731278367508416
Validation loss: 2.4395767601341256

Epoch: 5| Step: 2
Training loss: 2.1143030315963993
Validation loss: 2.4477735957163986

Epoch: 5| Step: 3
Training loss: 2.555000029412734
Validation loss: 2.4381753266280053

Epoch: 5| Step: 4
Training loss: 3.0282990554216047
Validation loss: 2.423186311253879

Epoch: 5| Step: 5
Training loss: 2.9540460351186297
Validation loss: 2.422309130006142

Epoch: 5| Step: 6
Training loss: 2.514423154350377
Validation loss: 2.4171149282239184

Epoch: 5| Step: 7
Training loss: 2.0690621685056043
Validation loss: 2.4165553232440655

Epoch: 5| Step: 8
Training loss: 2.9605851177599933
Validation loss: 2.426565273878052

Epoch: 5| Step: 9
Training loss: 2.8595374222781524
Validation loss: 2.4213675643176886

Epoch: 5| Step: 10
Training loss: 2.779791374474316
Validation loss: 2.431680246264191

Epoch: 99| Step: 0
Training loss: 2.248698811990147
Validation loss: 2.431814001150543

Epoch: 5| Step: 1
Training loss: 2.644897075013421
Validation loss: 2.43146989979754

Epoch: 5| Step: 2
Training loss: 3.0080922975076256
Validation loss: 2.4291760401208173

Epoch: 5| Step: 3
Training loss: 2.630907405196777
Validation loss: 2.434758124285796

Epoch: 5| Step: 4
Training loss: 2.4245441126225638
Validation loss: 2.4369126062540447

Epoch: 5| Step: 5
Training loss: 1.7316864069577482
Validation loss: 2.4359331798351374

Epoch: 5| Step: 6
Training loss: 2.910396284406575
Validation loss: 2.421176060366857

Epoch: 5| Step: 7
Training loss: 2.7842584690493704
Validation loss: 2.431750793109493

Epoch: 5| Step: 8
Training loss: 2.7253641812612326
Validation loss: 2.4279116307285973

Epoch: 5| Step: 9
Training loss: 2.566250173621676
Validation loss: 2.4288243353552015

Epoch: 5| Step: 10
Training loss: 3.1518667774898788
Validation loss: 2.418328629935909

Epoch: 100| Step: 0
Training loss: 2.1503919554662096
Validation loss: 2.4401299829001966

Epoch: 5| Step: 1
Training loss: 2.6126201802769535
Validation loss: 2.443895274393114

Epoch: 5| Step: 2
Training loss: 2.9743955238501494
Validation loss: 2.4200896066171347

Epoch: 5| Step: 3
Training loss: 2.8688833434253813
Validation loss: 2.437087972612651

Epoch: 5| Step: 4
Training loss: 2.528876050899005
Validation loss: 2.4502006140990114

Epoch: 5| Step: 5
Training loss: 2.424726517977069
Validation loss: 2.4346137490079975

Epoch: 5| Step: 6
Training loss: 2.885060661378964
Validation loss: 2.4403842198808317

Epoch: 5| Step: 7
Training loss: 2.6897181738381613
Validation loss: 2.461014859985205

Epoch: 5| Step: 8
Training loss: 2.7283141185322344
Validation loss: 2.4397196149153175

Epoch: 5| Step: 9
Training loss: 2.7292028720774066
Validation loss: 2.4450687980388315

Epoch: 5| Step: 10
Training loss: 2.1433632593552487
Validation loss: 2.4382069469401575

Epoch: 101| Step: 0
Training loss: 2.2575571516370774
Validation loss: 2.4508160855729253

Epoch: 5| Step: 1
Training loss: 2.686800311182506
Validation loss: 2.4508680782160783

Epoch: 5| Step: 2
Training loss: 2.7936305829155845
Validation loss: 2.451069562432393

Epoch: 5| Step: 3
Training loss: 2.3359540345490273
Validation loss: 2.435118282295755

Epoch: 5| Step: 4
Training loss: 2.931781315588542
Validation loss: 2.423709322130312

Epoch: 5| Step: 5
Training loss: 2.528392544654267
Validation loss: 2.4558124210808727

Epoch: 5| Step: 6
Training loss: 2.8173190051808343
Validation loss: 2.447701183950744

Epoch: 5| Step: 7
Training loss: 2.327878183684389
Validation loss: 2.450783785875839

Epoch: 5| Step: 8
Training loss: 2.628499740754409
Validation loss: 2.4520706326004365

Epoch: 5| Step: 9
Training loss: 2.7066780509458765
Validation loss: 2.4367719203925744

Epoch: 5| Step: 10
Training loss: 2.9280701916103498
Validation loss: 2.440853083333904

Epoch: 102| Step: 0
Training loss: 3.010757233430212
Validation loss: 2.437612305381781

Epoch: 5| Step: 1
Training loss: 2.411580905861368
Validation loss: 2.434952932524777

Epoch: 5| Step: 2
Training loss: 2.590211775969787
Validation loss: 2.4445244997264486

Epoch: 5| Step: 3
Training loss: 2.9793827183061112
Validation loss: 2.4298757060726563

Epoch: 5| Step: 4
Training loss: 2.1793568131279013
Validation loss: 2.43545262606601

Epoch: 5| Step: 5
Training loss: 2.8499711286186673
Validation loss: 2.431496823216587

Epoch: 5| Step: 6
Training loss: 2.9943040179854856
Validation loss: 2.4339213198468497

Epoch: 5| Step: 7
Training loss: 2.5184477139578365
Validation loss: 2.454062801008438

Epoch: 5| Step: 8
Training loss: 2.2282363756761154
Validation loss: 2.4319726470772918

Epoch: 5| Step: 9
Training loss: 2.3499566865541204
Validation loss: 2.424623750321584

Epoch: 5| Step: 10
Training loss: 2.736952259186737
Validation loss: 2.4241898740797176

Epoch: 103| Step: 0
Training loss: 2.9525016651584925
Validation loss: 2.4340419730156473

Epoch: 5| Step: 1
Training loss: 2.586539852369947
Validation loss: 2.4514773815906326

Epoch: 5| Step: 2
Training loss: 2.653965854284261
Validation loss: 2.4340496416747213

Epoch: 5| Step: 3
Training loss: 2.7208519187709195
Validation loss: 2.442563724065876

Epoch: 5| Step: 4
Training loss: 2.266419264904946
Validation loss: 2.4119890213294104

Epoch: 5| Step: 5
Training loss: 2.328119162737806
Validation loss: 2.413248050787081

Epoch: 5| Step: 6
Training loss: 2.589287469421694
Validation loss: 2.4340500861423404

Epoch: 5| Step: 7
Training loss: 2.8824548680394253
Validation loss: 2.422497640512269

Epoch: 5| Step: 8
Training loss: 2.5058246470399013
Validation loss: 2.434829732249803

Epoch: 5| Step: 9
Training loss: 2.446833810666651
Validation loss: 2.4505292688679883

Epoch: 5| Step: 10
Training loss: 2.864233673025196
Validation loss: 2.4390118035856583

Epoch: 104| Step: 0
Training loss: 2.394776373758113
Validation loss: 2.433165075612598

Epoch: 5| Step: 1
Training loss: 2.428952808246785
Validation loss: 2.428760913344742

Epoch: 5| Step: 2
Training loss: 2.5854534145533705
Validation loss: 2.42809015951351

Epoch: 5| Step: 3
Training loss: 2.7547419152643604
Validation loss: 2.4132326853478805

Epoch: 5| Step: 4
Training loss: 2.5219648569730566
Validation loss: 2.44738897755138

Epoch: 5| Step: 5
Training loss: 2.884420799148005
Validation loss: 2.4502601142659306

Epoch: 5| Step: 6
Training loss: 2.4965790230613356
Validation loss: 2.4376291988052112

Epoch: 5| Step: 7
Training loss: 2.4403820117141795
Validation loss: 2.4399256767305353

Epoch: 5| Step: 8
Training loss: 2.2921761957785654
Validation loss: 2.442371751291227

Epoch: 5| Step: 9
Training loss: 2.661957655996221
Validation loss: 2.452687112782437

Epoch: 5| Step: 10
Training loss: 3.4674365331978856
Validation loss: 2.432459069472035

Epoch: 105| Step: 0
Training loss: 2.721006925535519
Validation loss: 2.441972869815195

Epoch: 5| Step: 1
Training loss: 3.0627220229030248
Validation loss: 2.42723455956558

Epoch: 5| Step: 2
Training loss: 3.250758449380055
Validation loss: 2.4359588904788962

Epoch: 5| Step: 3
Training loss: 1.9718365165231846
Validation loss: 2.4551822795163645

Epoch: 5| Step: 4
Training loss: 1.9029731101072178
Validation loss: 2.446261425245767

Epoch: 5| Step: 5
Training loss: 2.5572276887575804
Validation loss: 2.4356826441895363

Epoch: 5| Step: 6
Training loss: 2.2887019892292026
Validation loss: 2.44986985898761

Epoch: 5| Step: 7
Training loss: 3.005130989406081
Validation loss: 2.422198402281956

Epoch: 5| Step: 8
Training loss: 2.4749922241705304
Validation loss: 2.4427178411528088

Epoch: 5| Step: 9
Training loss: 2.5666342159383158
Validation loss: 2.4459806031030102

Epoch: 5| Step: 10
Training loss: 2.5482264016742024
Validation loss: 2.438683501485243

Epoch: 106| Step: 0
Training loss: 2.3435416574065844
Validation loss: 2.4415203975121385

Epoch: 5| Step: 1
Training loss: 2.688691518263726
Validation loss: 2.4458043351033334

Epoch: 5| Step: 2
Training loss: 2.884606937493892
Validation loss: 2.4396352867830275

Epoch: 5| Step: 3
Training loss: 2.7387197799094802
Validation loss: 2.443531489516043

Epoch: 5| Step: 4
Training loss: 2.116255551560179
Validation loss: 2.4466149902413266

Epoch: 5| Step: 5
Training loss: 3.0443344087817743
Validation loss: 2.4434696085852687

Epoch: 5| Step: 6
Training loss: 2.3237823333050294
Validation loss: 2.435548277054043

Epoch: 5| Step: 7
Training loss: 2.6437286556455444
Validation loss: 2.4370668697973112

Epoch: 5| Step: 8
Training loss: 2.6619314132842606
Validation loss: 2.434323730080503

Epoch: 5| Step: 9
Training loss: 2.5951150266699066
Validation loss: 2.435802189205883

Epoch: 5| Step: 10
Training loss: 2.710785435525969
Validation loss: 2.4203646679153628

Epoch: 107| Step: 0
Training loss: 2.761481678241798
Validation loss: 2.435263092962701

Epoch: 5| Step: 1
Training loss: 2.874790515731256
Validation loss: 2.439843891681734

Epoch: 5| Step: 2
Training loss: 2.507549046258292
Validation loss: 2.4434748020231636

Epoch: 5| Step: 3
Training loss: 2.605091896998853
Validation loss: 2.4203372049250182

Epoch: 5| Step: 4
Training loss: 2.7039271581194666
Validation loss: 2.4373146178051903

Epoch: 5| Step: 5
Training loss: 2.398477759007851
Validation loss: 2.4516243891859824

Epoch: 5| Step: 6
Training loss: 1.9791973780876007
Validation loss: 2.43482796653007

Epoch: 5| Step: 7
Training loss: 2.252421030233141
Validation loss: 2.4369687094818646

Epoch: 5| Step: 8
Training loss: 2.6517424990466174
Validation loss: 2.4251545496851366

Epoch: 5| Step: 9
Training loss: 2.246831039826337
Validation loss: 2.4426077709562093

Epoch: 5| Step: 10
Training loss: 3.493475145368662
Validation loss: 2.4513505190173763

Epoch: 108| Step: 0
Training loss: 2.6348785534546137
Validation loss: 2.4377058902992914

Epoch: 5| Step: 1
Training loss: 2.6827529856190906
Validation loss: 2.4258837149916634

Epoch: 5| Step: 2
Training loss: 2.2953122590170696
Validation loss: 2.4349294849119274

Epoch: 5| Step: 3
Training loss: 3.576911420621724
Validation loss: 2.452629580143183

Epoch: 5| Step: 4
Training loss: 2.5458343813863324
Validation loss: 2.4485957177595505

Epoch: 5| Step: 5
Training loss: 2.3908605521846473
Validation loss: 2.4452612667514892

Epoch: 5| Step: 6
Training loss: 2.016650271808828
Validation loss: 2.4333913855877016

Epoch: 5| Step: 7
Training loss: 2.430997047896419
Validation loss: 2.4368630200897248

Epoch: 5| Step: 8
Training loss: 2.402787429652983
Validation loss: 2.4286217097041467

Epoch: 5| Step: 9
Training loss: 2.5327654411184866
Validation loss: 2.439747865850723

Epoch: 5| Step: 10
Training loss: 2.988048110543954
Validation loss: 2.436959306872748

Epoch: 109| Step: 0
Training loss: 2.813116896049185
Validation loss: 2.447266963772466

Epoch: 5| Step: 1
Training loss: 2.7542439571583364
Validation loss: 2.4380018897086395

Epoch: 5| Step: 2
Training loss: 2.8472004173705097
Validation loss: 2.4207541347346346

Epoch: 5| Step: 3
Training loss: 2.538952070915913
Validation loss: 2.434885825035203

Epoch: 5| Step: 4
Training loss: 2.2770506995801063
Validation loss: 2.432314889736411

Epoch: 5| Step: 5
Training loss: 2.7527925877365718
Validation loss: 2.4656776073565387

Epoch: 5| Step: 6
Training loss: 2.371389153820997
Validation loss: 2.4508743595179667

Epoch: 5| Step: 7
Training loss: 3.0838441339729155
Validation loss: 2.4428629611202326

Epoch: 5| Step: 8
Training loss: 2.2016742880971107
Validation loss: 2.448881909826412

Epoch: 5| Step: 9
Training loss: 2.3621008076551058
Validation loss: 2.442815127129513

Epoch: 5| Step: 10
Training loss: 2.348187733945073
Validation loss: 2.4470459977374226

Epoch: 110| Step: 0
Training loss: 2.732724634484324
Validation loss: 2.441529715880081

Epoch: 5| Step: 1
Training loss: 2.708409254526066
Validation loss: 2.4474441665762905

Epoch: 5| Step: 2
Training loss: 2.281418781046237
Validation loss: 2.436745352469104

Epoch: 5| Step: 3
Training loss: 2.6918602105188993
Validation loss: 2.4503716653380576

Epoch: 5| Step: 4
Training loss: 2.5745755818041385
Validation loss: 2.4459104284280793

Epoch: 5| Step: 5
Training loss: 2.274603056599985
Validation loss: 2.4375966959774242

Epoch: 5| Step: 6
Training loss: 2.4653075155216735
Validation loss: 2.4646100105573625

Epoch: 5| Step: 7
Training loss: 2.4140977579153104
Validation loss: 2.4300956582402007

Epoch: 5| Step: 8
Training loss: 3.541198355435841
Validation loss: 2.4395052620871067

Epoch: 5| Step: 9
Training loss: 1.9044041686520605
Validation loss: 2.4518760374045474

Epoch: 5| Step: 10
Training loss: 2.6525291861205664
Validation loss: 2.4547115682110485

Epoch: 111| Step: 0
Training loss: 2.2460836659080696
Validation loss: 2.4317771172543723

Epoch: 5| Step: 1
Training loss: 1.8719347375880764
Validation loss: 2.462635362585005

Epoch: 5| Step: 2
Training loss: 2.893483496107855
Validation loss: 2.458275617718357

Epoch: 5| Step: 3
Training loss: 2.8853688884502313
Validation loss: 2.4460466809386894

Epoch: 5| Step: 4
Training loss: 3.0595054777881545
Validation loss: 2.4693845060981143

Epoch: 5| Step: 5
Training loss: 2.910073994747767
Validation loss: 2.438421065375167

Epoch: 5| Step: 6
Training loss: 2.5048010502311384
Validation loss: 2.4421440144521593

Epoch: 5| Step: 7
Training loss: 1.8590999367760341
Validation loss: 2.450854270801468

Epoch: 5| Step: 8
Training loss: 2.631313723700886
Validation loss: 2.454569144680341

Epoch: 5| Step: 9
Training loss: 2.7720259392035254
Validation loss: 2.4344679129988536

Epoch: 5| Step: 10
Training loss: 2.5899447368190334
Validation loss: 2.4488956299571836

Epoch: 112| Step: 0
Training loss: 2.8486798491467185
Validation loss: 2.4345655286452104

Epoch: 5| Step: 1
Training loss: 2.7979291069642307
Validation loss: 2.4459298219651737

Epoch: 5| Step: 2
Training loss: 2.8603265565226517
Validation loss: 2.442768907354587

Epoch: 5| Step: 3
Training loss: 2.2655717514620783
Validation loss: 2.444917634043482

Epoch: 5| Step: 4
Training loss: 2.682221840748957
Validation loss: 2.4139605665670545

Epoch: 5| Step: 5
Training loss: 2.384264394212095
Validation loss: 2.4400265821928384

Epoch: 5| Step: 6
Training loss: 2.675755142864199
Validation loss: 2.4521610071193147

Epoch: 5| Step: 7
Training loss: 2.4315867958085593
Validation loss: 2.4473812553671443

Epoch: 5| Step: 8
Training loss: 2.571639903784892
Validation loss: 2.420528703222775

Epoch: 5| Step: 9
Training loss: 2.0944147905003794
Validation loss: 2.4519118766013497

Epoch: 5| Step: 10
Training loss: 2.705585484488208
Validation loss: 2.456901288225706

Epoch: 113| Step: 0
Training loss: 2.754450058508394
Validation loss: 2.4317494278727407

Epoch: 5| Step: 1
Training loss: 2.439147979000937
Validation loss: 2.4263146679763263

Epoch: 5| Step: 2
Training loss: 2.552236425258495
Validation loss: 2.4556696020513376

Epoch: 5| Step: 3
Training loss: 2.715541568787026
Validation loss: 2.432717092535049

Epoch: 5| Step: 4
Training loss: 1.9982881968949653
Validation loss: 2.4414494892844374

Epoch: 5| Step: 5
Training loss: 3.091921950200291
Validation loss: 2.437455063566854

Epoch: 5| Step: 6
Training loss: 2.642803309418881
Validation loss: 2.4398041618426123

Epoch: 5| Step: 7
Training loss: 2.59401002982266
Validation loss: 2.4430843810451432

Epoch: 5| Step: 8
Training loss: 2.707082244260629
Validation loss: 2.445977531109957

Epoch: 5| Step: 9
Training loss: 2.26152193204647
Validation loss: 2.433110487804755

Epoch: 5| Step: 10
Training loss: 2.588070637901914
Validation loss: 2.4511279673644086

Epoch: 114| Step: 0
Training loss: 2.3689198214165654
Validation loss: 2.4373694227911957

Epoch: 5| Step: 1
Training loss: 2.87860014697289
Validation loss: 2.408542272612975

Epoch: 5| Step: 2
Training loss: 2.0370041553977414
Validation loss: 2.443485003162069

Epoch: 5| Step: 3
Training loss: 2.4125818940330834
Validation loss: 2.4525135480840548

Epoch: 5| Step: 4
Training loss: 2.2853127450419923
Validation loss: 2.437769624339841

Epoch: 5| Step: 5
Training loss: 2.1633577266467934
Validation loss: 2.4358411286643133

Epoch: 5| Step: 6
Training loss: 2.549253137457693
Validation loss: 2.4282732212209233

Epoch: 5| Step: 7
Training loss: 2.682132506355107
Validation loss: 2.4444200054079994

Epoch: 5| Step: 8
Training loss: 2.816466522630032
Validation loss: 2.445147413924166

Epoch: 5| Step: 9
Training loss: 3.0286632394112805
Validation loss: 2.4351621522413804

Epoch: 5| Step: 10
Training loss: 3.0551868235501463
Validation loss: 2.4444196960200735

Epoch: 115| Step: 0
Training loss: 3.150818636649004
Validation loss: 2.444832602810252

Epoch: 5| Step: 1
Training loss: 2.87011087422749
Validation loss: 2.436755903713715

Epoch: 5| Step: 2
Training loss: 2.489215956732993
Validation loss: 2.4316392396699804

Epoch: 5| Step: 3
Training loss: 2.2217084476160447
Validation loss: 2.452624294247274

Epoch: 5| Step: 4
Training loss: 2.336984151131098
Validation loss: 2.4444863739811513

Epoch: 5| Step: 5
Training loss: 2.8947137731335615
Validation loss: 2.4385142171271954

Epoch: 5| Step: 6
Training loss: 2.09657552431058
Validation loss: 2.455449950743262

Epoch: 5| Step: 7
Training loss: 2.3767891218392942
Validation loss: 2.448899083532089

Epoch: 5| Step: 8
Training loss: 2.339103670847274
Validation loss: 2.4531490182886264

Epoch: 5| Step: 9
Training loss: 2.8272452487742035
Validation loss: 2.4368457878605274

Epoch: 5| Step: 10
Training loss: 2.4590253879559807
Validation loss: 2.4497664235827266

Epoch: 116| Step: 0
Training loss: 2.864345045871583
Validation loss: 2.4434233099100777

Epoch: 5| Step: 1
Training loss: 2.331624926979008
Validation loss: 2.4534220450662887

Epoch: 5| Step: 2
Training loss: 2.4865849100876654
Validation loss: 2.442854969613676

Epoch: 5| Step: 3
Training loss: 2.4875454615746984
Validation loss: 2.4681450603818065

Epoch: 5| Step: 4
Training loss: 2.644930337518538
Validation loss: 2.4513481690869092

Epoch: 5| Step: 5
Training loss: 2.6696580757913893
Validation loss: 2.460098654398462

Epoch: 5| Step: 6
Training loss: 2.6582631280252533
Validation loss: 2.477322176050169

Epoch: 5| Step: 7
Training loss: 2.5670165290018017
Validation loss: 2.4562077816919046

Epoch: 5| Step: 8
Training loss: 2.6484016708606126
Validation loss: 2.473067240224029

Epoch: 5| Step: 9
Training loss: 2.5050914417259684
Validation loss: 2.4764817261138745

Epoch: 5| Step: 10
Training loss: 2.396178433539052
Validation loss: 2.4644780767024153

Epoch: 117| Step: 0
Training loss: 2.5641632264859795
Validation loss: 2.460876951630093

Epoch: 5| Step: 1
Training loss: 2.7150512616005793
Validation loss: 2.4799254233433534

Epoch: 5| Step: 2
Training loss: 2.388248134654237
Validation loss: 2.471857757402435

Epoch: 5| Step: 3
Training loss: 2.617438460886349
Validation loss: 2.453329951012907

Epoch: 5| Step: 4
Training loss: 2.616164642414208
Validation loss: 2.4312677846046626

Epoch: 5| Step: 5
Training loss: 2.318274428137815
Validation loss: 2.447549262890257

Epoch: 5| Step: 6
Training loss: 2.534180816473737
Validation loss: 2.4476089772893017

Epoch: 5| Step: 7
Training loss: 2.4658774552475426
Validation loss: 2.4397459282098395

Epoch: 5| Step: 8
Training loss: 2.350249167685741
Validation loss: 2.4463714772396616

Epoch: 5| Step: 9
Training loss: 2.9594036548036886
Validation loss: 2.463615835912162

Epoch: 5| Step: 10
Training loss: 2.6218024260851123
Validation loss: 2.444141567702392

Epoch: 118| Step: 0
Training loss: 2.6896722575487417
Validation loss: 2.458103895734557

Epoch: 5| Step: 1
Training loss: 2.771821402770204
Validation loss: 2.448279220204308

Epoch: 5| Step: 2
Training loss: 2.2268732222197465
Validation loss: 2.434434338583785

Epoch: 5| Step: 3
Training loss: 1.9742209092956013
Validation loss: 2.4637614376779715

Epoch: 5| Step: 4
Training loss: 2.521264241697971
Validation loss: 2.441525451769084

Epoch: 5| Step: 5
Training loss: 3.1933565378905593
Validation loss: 2.4330267983102813

Epoch: 5| Step: 6
Training loss: 2.8279005773028625
Validation loss: 2.4308471191509864

Epoch: 5| Step: 7
Training loss: 2.490624873641141
Validation loss: 2.4272562495537415

Epoch: 5| Step: 8
Training loss: 2.38602378704176
Validation loss: 2.431244951523359

Epoch: 5| Step: 9
Training loss: 2.4638450279857156
Validation loss: 2.4500754851414794

Epoch: 5| Step: 10
Training loss: 2.7846744329252737
Validation loss: 2.4405118730987865

Epoch: 119| Step: 0
Training loss: 2.410746052446924
Validation loss: 2.4240275322594522

Epoch: 5| Step: 1
Training loss: 2.6236341646966665
Validation loss: 2.4255576459760873

Epoch: 5| Step: 2
Training loss: 2.1608333802532758
Validation loss: 2.4319755080126733

Epoch: 5| Step: 3
Training loss: 3.0172706027565357
Validation loss: 2.432477426748692

Epoch: 5| Step: 4
Training loss: 2.7207638527691813
Validation loss: 2.4374855920341085

Epoch: 5| Step: 5
Training loss: 2.6846438467557183
Validation loss: 2.4488121710955917

Epoch: 5| Step: 6
Training loss: 2.7312105014485164
Validation loss: 2.4822052406488364

Epoch: 5| Step: 7
Training loss: 2.6789908434977296
Validation loss: 2.4382696858593564

Epoch: 5| Step: 8
Training loss: 2.4958358416494293
Validation loss: 2.445676383695797

Epoch: 5| Step: 9
Training loss: 1.8410607461723802
Validation loss: 2.429914874492371

Epoch: 5| Step: 10
Training loss: 2.6511866162037685
Validation loss: 2.4591317907587675

Epoch: 120| Step: 0
Training loss: 3.2952784428435087
Validation loss: 2.4609913226477818

Epoch: 5| Step: 1
Training loss: 2.305805930620584
Validation loss: 2.461472872907845

Epoch: 5| Step: 2
Training loss: 2.2488572079525757
Validation loss: 2.473079845020356

Epoch: 5| Step: 3
Training loss: 2.249039338917407
Validation loss: 2.454001413378577

Epoch: 5| Step: 4
Training loss: 2.7698519888214292
Validation loss: 2.460545272809305

Epoch: 5| Step: 5
Training loss: 1.9875283605123581
Validation loss: 2.4719319282782872

Epoch: 5| Step: 6
Training loss: 2.446563985456015
Validation loss: 2.435748830885807

Epoch: 5| Step: 7
Training loss: 2.657778760010755
Validation loss: 2.4429125078773817

Epoch: 5| Step: 8
Training loss: 2.333573692294324
Validation loss: 2.4389571027768286

Epoch: 5| Step: 9
Training loss: 2.6206517308748514
Validation loss: 2.4487003594843695

Epoch: 5| Step: 10
Training loss: 3.085614846660807
Validation loss: 2.449670258214919

Epoch: 121| Step: 0
Training loss: 2.4887646934577514
Validation loss: 2.4621315180239183

Epoch: 5| Step: 1
Training loss: 2.416967230773932
Validation loss: 2.4515062002915124

Epoch: 5| Step: 2
Training loss: 2.0320601974942165
Validation loss: 2.4717887255088846

Epoch: 5| Step: 3
Training loss: 2.41975743410088
Validation loss: 2.4351466839936267

Epoch: 5| Step: 4
Training loss: 2.811059710150384
Validation loss: 2.454936496546616

Epoch: 5| Step: 5
Training loss: 3.0377009070244405
Validation loss: 2.4437468660777903

Epoch: 5| Step: 6
Training loss: 3.0813330958305913
Validation loss: 2.46247351272852

Epoch: 5| Step: 7
Training loss: 2.4695520184713735
Validation loss: 2.444072961857852

Epoch: 5| Step: 8
Training loss: 2.2939223430030844
Validation loss: 2.44341125037129

Epoch: 5| Step: 9
Training loss: 2.6053765093304833
Validation loss: 2.4409442449701926

Epoch: 5| Step: 10
Training loss: 2.2791708263333685
Validation loss: 2.435365799041997

Epoch: 122| Step: 0
Training loss: 2.665722103519217
Validation loss: 2.4406051987244206

Epoch: 5| Step: 1
Training loss: 2.150970408542454
Validation loss: 2.4370518323125374

Epoch: 5| Step: 2
Training loss: 2.6339392359335263
Validation loss: 2.4246106054916825

Epoch: 5| Step: 3
Training loss: 2.8768017969259523
Validation loss: 2.457059486044715

Epoch: 5| Step: 4
Training loss: 2.5026662913433775
Validation loss: 2.4401744466833644

Epoch: 5| Step: 5
Training loss: 2.5701351394449605
Validation loss: 2.4441362603029058

Epoch: 5| Step: 6
Training loss: 2.8854687039931024
Validation loss: 2.437199681631027

Epoch: 5| Step: 7
Training loss: 2.262581721563429
Validation loss: 2.436067629924872

Epoch: 5| Step: 8
Training loss: 1.7264365586137154
Validation loss: 2.4447196968696066

Epoch: 5| Step: 9
Training loss: 2.391362294712525
Validation loss: 2.4655490766597747

Epoch: 5| Step: 10
Training loss: 3.092724254374876
Validation loss: 2.4575031276767225

Epoch: 123| Step: 0
Training loss: 2.703399732442985
Validation loss: 2.4504897719030723

Epoch: 5| Step: 1
Training loss: 2.2853372616276015
Validation loss: 2.4581761585405943

Epoch: 5| Step: 2
Training loss: 2.662224904923882
Validation loss: 2.4466485028116436

Epoch: 5| Step: 3
Training loss: 2.696128743734117
Validation loss: 2.457413357523097

Epoch: 5| Step: 4
Training loss: 2.5037262802790683
Validation loss: 2.47230866659632

Epoch: 5| Step: 5
Training loss: 2.507171073478436
Validation loss: 2.4553568437541755

Epoch: 5| Step: 6
Training loss: 2.502499284772742
Validation loss: 2.468137393270563

Epoch: 5| Step: 7
Training loss: 2.0510523444330944
Validation loss: 2.4545409614547

Epoch: 5| Step: 8
Training loss: 2.7078212449537364
Validation loss: 2.4316757714230985

Epoch: 5| Step: 9
Training loss: 2.6079777614370854
Validation loss: 2.461129828752355

Epoch: 5| Step: 10
Training loss: 2.5968017090371665
Validation loss: 2.440129125597044

Epoch: 124| Step: 0
Training loss: 2.2883034967791276
Validation loss: 2.4572650144732977

Epoch: 5| Step: 1
Training loss: 2.509454967702014
Validation loss: 2.4617078381163173

Epoch: 5| Step: 2
Training loss: 2.509264279175831
Validation loss: 2.4595247113683865

Epoch: 5| Step: 3
Training loss: 2.619174578714714
Validation loss: 2.446606833906125

Epoch: 5| Step: 4
Training loss: 2.695925524008361
Validation loss: 2.4655299882151698

Epoch: 5| Step: 5
Training loss: 2.126095994039969
Validation loss: 2.447055533402719

Epoch: 5| Step: 6
Training loss: 2.738829379652849
Validation loss: 2.4708361033018233

Epoch: 5| Step: 7
Training loss: 2.8028839177766107
Validation loss: 2.467069985437388

Epoch: 5| Step: 8
Training loss: 1.7770728271579281
Validation loss: 2.4470477965468267

Epoch: 5| Step: 9
Training loss: 2.8073540977278406
Validation loss: 2.468467653680728

Epoch: 5| Step: 10
Training loss: 3.054412126934103
Validation loss: 2.472693036292786

Epoch: 125| Step: 0
Training loss: 2.7864568597427226
Validation loss: 2.4519044457382018

Epoch: 5| Step: 1
Training loss: 2.561573605440626
Validation loss: 2.4496467112941307

Epoch: 5| Step: 2
Training loss: 2.9966413452583573
Validation loss: 2.4535686994843084

Epoch: 5| Step: 3
Training loss: 2.092217411115187
Validation loss: 2.4665897825371013

Epoch: 5| Step: 4
Training loss: 2.404768053952511
Validation loss: 2.4452184298449264

Epoch: 5| Step: 5
Training loss: 2.6177240988796404
Validation loss: 2.4636766530758587

Epoch: 5| Step: 6
Training loss: 2.0381857203727045
Validation loss: 2.451580217770443

Epoch: 5| Step: 7
Training loss: 2.245136939547193
Validation loss: 2.469292879676604

Epoch: 5| Step: 8
Training loss: 2.30568060733687
Validation loss: 2.4651733165629928

Epoch: 5| Step: 9
Training loss: 2.75368374405858
Validation loss: 2.4420658162742765

Epoch: 5| Step: 10
Training loss: 3.067170765812173
Validation loss: 2.45645194715077

Epoch: 126| Step: 0
Training loss: 2.6499343288129773
Validation loss: 2.4487114245608104

Epoch: 5| Step: 1
Training loss: 2.2025246309425115
Validation loss: 2.459967955307133

Epoch: 5| Step: 2
Training loss: 2.272805561971388
Validation loss: 2.4545921127672536

Epoch: 5| Step: 3
Training loss: 2.9599739862278365
Validation loss: 2.4709033798495468

Epoch: 5| Step: 4
Training loss: 2.222475389788452
Validation loss: 2.455267229014703

Epoch: 5| Step: 5
Training loss: 2.0518810992305667
Validation loss: 2.4706640574180923

Epoch: 5| Step: 6
Training loss: 2.6405850018062127
Validation loss: 2.445585192993232

Epoch: 5| Step: 7
Training loss: 2.735724938815475
Validation loss: 2.455774894412753

Epoch: 5| Step: 8
Training loss: 2.269972215053898
Validation loss: 2.4681622994799928

Epoch: 5| Step: 9
Training loss: 3.077419296929453
Validation loss: 2.4509212271451877

Epoch: 5| Step: 10
Training loss: 2.7823304210169413
Validation loss: 2.4699918272429495

Epoch: 127| Step: 0
Training loss: 2.515482928132261
Validation loss: 2.4413513823219657

Epoch: 5| Step: 1
Training loss: 2.683543553222991
Validation loss: 2.466917679654883

Epoch: 5| Step: 2
Training loss: 2.3623629212347446
Validation loss: 2.457856316759323

Epoch: 5| Step: 3
Training loss: 2.350758564041832
Validation loss: 2.449988056712101

Epoch: 5| Step: 4
Training loss: 2.659795392133601
Validation loss: 2.4533118668052207

Epoch: 5| Step: 5
Training loss: 2.664242467087295
Validation loss: 2.451800914230425

Epoch: 5| Step: 6
Training loss: 2.2624630666848007
Validation loss: 2.4428278119387583

Epoch: 5| Step: 7
Training loss: 2.8008788875229897
Validation loss: 2.4586160659539753

Epoch: 5| Step: 8
Training loss: 2.255532456526633
Validation loss: 2.4465179360527247

Epoch: 5| Step: 9
Training loss: 2.2647537134596765
Validation loss: 2.445784104117624

Epoch: 5| Step: 10
Training loss: 3.221856257238918
Validation loss: 2.440619879236362

Epoch: 128| Step: 0
Training loss: 2.235495973041195
Validation loss: 2.4576317954327425

Epoch: 5| Step: 1
Training loss: 1.9423648915871374
Validation loss: 2.4227979390672347

Epoch: 5| Step: 2
Training loss: 2.916235719360495
Validation loss: 2.427852553259231

Epoch: 5| Step: 3
Training loss: 2.9209736948575564
Validation loss: 2.4621542068012925

Epoch: 5| Step: 4
Training loss: 2.3532078458632846
Validation loss: 2.4497647199066677

Epoch: 5| Step: 5
Training loss: 2.253348719565024
Validation loss: 2.4473203150399496

Epoch: 5| Step: 6
Training loss: 2.530606977003364
Validation loss: 2.416039766556829

Epoch: 5| Step: 7
Training loss: 2.4120655874378305
Validation loss: 2.442111358611382

Epoch: 5| Step: 8
Training loss: 3.0255102499651265
Validation loss: 2.4556232525638753

Epoch: 5| Step: 9
Training loss: 2.517237081578099
Validation loss: 2.449753135296641

Epoch: 5| Step: 10
Training loss: 2.7870327271345667
Validation loss: 2.466348564480588

Epoch: 129| Step: 0
Training loss: 2.6900480743990665
Validation loss: 2.455157115807423

Epoch: 5| Step: 1
Training loss: 2.3777583317045656
Validation loss: 2.430032736767352

Epoch: 5| Step: 2
Training loss: 2.4565180741415245
Validation loss: 2.4656317735230613

Epoch: 5| Step: 3
Training loss: 2.5110880058298357
Validation loss: 2.4208779973197427

Epoch: 5| Step: 4
Training loss: 2.6876887765276427
Validation loss: 2.4387254066888366

Epoch: 5| Step: 5
Training loss: 2.540149538188861
Validation loss: 2.4593211240908386

Epoch: 5| Step: 6
Training loss: 2.5742128224514453
Validation loss: 2.445454561075859

Epoch: 5| Step: 7
Training loss: 2.9865326596180615
Validation loss: 2.447386933877483

Epoch: 5| Step: 8
Training loss: 2.1941960981601887
Validation loss: 2.435871458448558

Epoch: 5| Step: 9
Training loss: 2.006549720123424
Validation loss: 2.436173607433481

Epoch: 5| Step: 10
Training loss: 2.633413002965819
Validation loss: 2.4436919733208025

Epoch: 130| Step: 0
Training loss: 2.902511982001808
Validation loss: 2.4562131892993593

Epoch: 5| Step: 1
Training loss: 2.47744128884231
Validation loss: 2.4491011819387465

Epoch: 5| Step: 2
Training loss: 1.982202857936954
Validation loss: 2.43432939481883

Epoch: 5| Step: 3
Training loss: 2.296769120247752
Validation loss: 2.445314856779091

Epoch: 5| Step: 4
Training loss: 2.536593789329105
Validation loss: 2.4690982712616805

Epoch: 5| Step: 5
Training loss: 2.3649340690148963
Validation loss: 2.4577409236601757

Epoch: 5| Step: 6
Training loss: 2.7685547736166214
Validation loss: 2.473268329830975

Epoch: 5| Step: 7
Training loss: 3.018500503749783
Validation loss: 2.441934059629668

Epoch: 5| Step: 8
Training loss: 2.7066758488121945
Validation loss: 2.4772844753814534

Epoch: 5| Step: 9
Training loss: 2.0574624936287926
Validation loss: 2.4842458887359555

Epoch: 5| Step: 10
Training loss: 2.461157991734444
Validation loss: 2.4587237877245163

Epoch: 131| Step: 0
Training loss: 2.7043719640388137
Validation loss: 2.4609697112257254

Epoch: 5| Step: 1
Training loss: 2.568715999777361
Validation loss: 2.465122893353287

Epoch: 5| Step: 2
Training loss: 2.4864943958911994
Validation loss: 2.4582020985436586

Epoch: 5| Step: 3
Training loss: 3.109966739341759
Validation loss: 2.4696163419100285

Epoch: 5| Step: 4
Training loss: 2.4727080280975384
Validation loss: 2.4639972615056323

Epoch: 5| Step: 5
Training loss: 2.4609240334763
Validation loss: 2.4747710527180677

Epoch: 5| Step: 6
Training loss: 2.3729184716418477
Validation loss: 2.4506939380094495

Epoch: 5| Step: 7
Training loss: 1.9220920223114388
Validation loss: 2.463222553670346

Epoch: 5| Step: 8
Training loss: 2.355449214620224
Validation loss: 2.458857047927276

Epoch: 5| Step: 9
Training loss: 2.6733227649996696
Validation loss: 2.4410079459198886

Epoch: 5| Step: 10
Training loss: 2.498099749306042
Validation loss: 2.4570273884123837

Epoch: 132| Step: 0
Training loss: 1.6632784576894275
Validation loss: 2.442814072420392

Epoch: 5| Step: 1
Training loss: 3.1511981683544175
Validation loss: 2.458033042456635

Epoch: 5| Step: 2
Training loss: 2.30002974200714
Validation loss: 2.45702250742373

Epoch: 5| Step: 3
Training loss: 2.7394244845405473
Validation loss: 2.440356129162748

Epoch: 5| Step: 4
Training loss: 3.1873608727104847
Validation loss: 2.44351567871535

Epoch: 5| Step: 5
Training loss: 2.4567888440513914
Validation loss: 2.4247246539729663

Epoch: 5| Step: 6
Training loss: 2.3179701982216576
Validation loss: 2.473308439443201

Epoch: 5| Step: 7
Training loss: 2.416208541680214
Validation loss: 2.467062293682522

Epoch: 5| Step: 8
Training loss: 2.7115141065745147
Validation loss: 2.463239590446091

Epoch: 5| Step: 9
Training loss: 2.2263543282619467
Validation loss: 2.435283399771365

Epoch: 5| Step: 10
Training loss: 2.245731012659237
Validation loss: 2.4723374405317857

Epoch: 133| Step: 0
Training loss: 2.531822139929281
Validation loss: 2.45115285657757

Epoch: 5| Step: 1
Training loss: 2.664199780817297
Validation loss: 2.4603802825081647

Epoch: 5| Step: 2
Training loss: 2.2628188019280038
Validation loss: 2.445888213137855

Epoch: 5| Step: 3
Training loss: 2.7663330206326355
Validation loss: 2.4491449877391247

Epoch: 5| Step: 4
Training loss: 2.2681141826742746
Validation loss: 2.4591363975543037

Epoch: 5| Step: 5
Training loss: 2.1705827779532543
Validation loss: 2.448780638520736

Epoch: 5| Step: 6
Training loss: 2.537654075266957
Validation loss: 2.4537293057086256

Epoch: 5| Step: 7
Training loss: 2.1079655212101645
Validation loss: 2.42474001848358

Epoch: 5| Step: 8
Training loss: 3.2493824005189427
Validation loss: 2.4450757495459894

Epoch: 5| Step: 9
Training loss: 2.520626900367389
Validation loss: 2.44629745883134

Epoch: 5| Step: 10
Training loss: 2.3036840290925307
Validation loss: 2.4467436867795693

Epoch: 134| Step: 0
Training loss: 2.432763804669307
Validation loss: 2.4464384881585644

Epoch: 5| Step: 1
Training loss: 2.3960451999916095
Validation loss: 2.4570812080253064

Epoch: 5| Step: 2
Training loss: 2.35656864430024
Validation loss: 2.4432689729076826

Epoch: 5| Step: 3
Training loss: 2.997677539852239
Validation loss: 2.446721193009402

Epoch: 5| Step: 4
Training loss: 2.3377403013362494
Validation loss: 2.4645563480728274

Epoch: 5| Step: 5
Training loss: 2.4590051239568402
Validation loss: 2.4621848678936615

Epoch: 5| Step: 6
Training loss: 2.469929763320424
Validation loss: 2.4681145455221345

Epoch: 5| Step: 7
Training loss: 2.6776234320676084
Validation loss: 2.44409718028598

Epoch: 5| Step: 8
Training loss: 1.9728469001118987
Validation loss: 2.467906925293223

Epoch: 5| Step: 9
Training loss: 2.8796281465901594
Validation loss: 2.471568845048495

Epoch: 5| Step: 10
Training loss: 2.579324986329043
Validation loss: 2.478974899964505

Epoch: 135| Step: 0
Training loss: 2.623374799168823
Validation loss: 2.466887446829931

Epoch: 5| Step: 1
Training loss: 2.3629372086223728
Validation loss: 2.439168675981049

Epoch: 5| Step: 2
Training loss: 2.0204890505185573
Validation loss: 2.464491796346565

Epoch: 5| Step: 3
Training loss: 2.8713812236501726
Validation loss: 2.4605455030690613

Epoch: 5| Step: 4
Training loss: 2.414596350445245
Validation loss: 2.4215036346321948

Epoch: 5| Step: 5
Training loss: 2.507936088392588
Validation loss: 2.448040793122832

Epoch: 5| Step: 6
Training loss: 2.555375499417587
Validation loss: 2.4450478762945673

Epoch: 5| Step: 7
Training loss: 2.9141066806092875
Validation loss: 2.4422619930029117

Epoch: 5| Step: 8
Training loss: 2.5302931307427863
Validation loss: 2.453711885803364

Epoch: 5| Step: 9
Training loss: 1.982846910735719
Validation loss: 2.458676760715509

Epoch: 5| Step: 10
Training loss: 2.592543171860678
Validation loss: 2.4518935069480694

Epoch: 136| Step: 0
Training loss: 2.4446127380853158
Validation loss: 2.4739200190549457

Epoch: 5| Step: 1
Training loss: 2.4495693606826916
Validation loss: 2.4690333253530454

Epoch: 5| Step: 2
Training loss: 2.6361197236213734
Validation loss: 2.4646923869692885

Epoch: 5| Step: 3
Training loss: 2.758761926028042
Validation loss: 2.483570325343609

Epoch: 5| Step: 4
Training loss: 2.84016175306431
Validation loss: 2.474572231805425

Epoch: 5| Step: 5
Training loss: 1.8196460993919863
Validation loss: 2.4488199201741794

Epoch: 5| Step: 6
Training loss: 1.8649172208685667
Validation loss: 2.4752050869384288

Epoch: 5| Step: 7
Training loss: 2.6244094729356777
Validation loss: 2.4748786814499315

Epoch: 5| Step: 8
Training loss: 1.976156381492406
Validation loss: 2.480286482229217

Epoch: 5| Step: 9
Training loss: 2.585697497153031
Validation loss: 2.458341917256225

Epoch: 5| Step: 10
Training loss: 3.185068437209322
Validation loss: 2.459269617677538

Epoch: 137| Step: 0
Training loss: 2.5661755694759556
Validation loss: 2.482810393215043

Epoch: 5| Step: 1
Training loss: 2.90086029051898
Validation loss: 2.468162675483564

Epoch: 5| Step: 2
Training loss: 2.380229913681887
Validation loss: 2.4443386444735853

Epoch: 5| Step: 3
Training loss: 2.556024324113326
Validation loss: 2.460458431045898

Epoch: 5| Step: 4
Training loss: 2.425567568399122
Validation loss: 2.4579388667153417

Epoch: 5| Step: 5
Training loss: 2.8778504877548112
Validation loss: 2.4506299532237263

Epoch: 5| Step: 6
Training loss: 1.9954706402680735
Validation loss: 2.451490995169684

Epoch: 5| Step: 7
Training loss: 2.416933099814364
Validation loss: 2.433813129152804

Epoch: 5| Step: 8
Training loss: 2.6472030958739157
Validation loss: 2.46387737080013

Epoch: 5| Step: 9
Training loss: 2.0567304658603174
Validation loss: 2.456672650505233

Epoch: 5| Step: 10
Training loss: 2.530323282779249
Validation loss: 2.438073650555544

Epoch: 138| Step: 0
Training loss: 2.092290682879953
Validation loss: 2.437646778863062

Epoch: 5| Step: 1
Training loss: 2.22244792692716
Validation loss: 2.4200446742351445

Epoch: 5| Step: 2
Training loss: 2.6477875488719222
Validation loss: 2.467336688076814

Epoch: 5| Step: 3
Training loss: 2.94410628250295
Validation loss: 2.4720912362262797

Epoch: 5| Step: 4
Training loss: 2.3528189613353883
Validation loss: 2.4412476458478634

Epoch: 5| Step: 5
Training loss: 2.625074567189832
Validation loss: 2.4519831498459435

Epoch: 5| Step: 6
Training loss: 2.55400547641176
Validation loss: 2.4577990845287503

Epoch: 5| Step: 7
Training loss: 2.7382104622347683
Validation loss: 2.449833117174161

Epoch: 5| Step: 8
Training loss: 2.6451514459242214
Validation loss: 2.477118521870907

Epoch: 5| Step: 9
Training loss: 2.2757854070078753
Validation loss: 2.467840471350695

Epoch: 5| Step: 10
Training loss: 2.2281994607904045
Validation loss: 2.452962269717635

Epoch: 139| Step: 0
Training loss: 2.785977492631091
Validation loss: 2.4695663556215024

Epoch: 5| Step: 1
Training loss: 2.021413844255682
Validation loss: 2.452236063331657

Epoch: 5| Step: 2
Training loss: 2.0378208399255233
Validation loss: 2.4688229979063925

Epoch: 5| Step: 3
Training loss: 2.8365807342363483
Validation loss: 2.4794719243046868

Epoch: 5| Step: 4
Training loss: 2.1445703832950436
Validation loss: 2.4820626140730764

Epoch: 5| Step: 5
Training loss: 2.7012005609297938
Validation loss: 2.4512156322904013

Epoch: 5| Step: 6
Training loss: 2.3943276248746823
Validation loss: 2.465148414993335

Epoch: 5| Step: 7
Training loss: 2.5227661184495913
Validation loss: 2.440525286283815

Epoch: 5| Step: 8
Training loss: 2.655262931979723
Validation loss: 2.4625073549985217

Epoch: 5| Step: 9
Training loss: 2.048837085336996
Validation loss: 2.4559585637614165

Epoch: 5| Step: 10
Training loss: 3.1367543219690637
Validation loss: 2.4806947894041764

Epoch: 140| Step: 0
Training loss: 2.9604999148435343
Validation loss: 2.4610558547288472

Epoch: 5| Step: 1
Training loss: 2.8525138208721446
Validation loss: 2.4529114408108903

Epoch: 5| Step: 2
Training loss: 2.6765288930409854
Validation loss: 2.447776561245594

Epoch: 5| Step: 3
Training loss: 2.1497881718456293
Validation loss: 2.4723626253571243

Epoch: 5| Step: 4
Training loss: 2.521310198948898
Validation loss: 2.468165700128994

Epoch: 5| Step: 5
Training loss: 2.712470596786966
Validation loss: 2.4665897612305048

Epoch: 5| Step: 6
Training loss: 1.7167425743776812
Validation loss: 2.4539962108779476

Epoch: 5| Step: 7
Training loss: 2.598443254841793
Validation loss: 2.4817291605072636

Epoch: 5| Step: 8
Training loss: 2.380238628125098
Validation loss: 2.4770445751235672

Epoch: 5| Step: 9
Training loss: 2.1369024054841543
Validation loss: 2.4507108102988986

Epoch: 5| Step: 10
Training loss: 2.366916250670735
Validation loss: 2.439406349690468

Epoch: 141| Step: 0
Training loss: 2.5029113983188602
Validation loss: 2.4781836669277237

Epoch: 5| Step: 1
Training loss: 2.662590358436611
Validation loss: 2.4536709574723896

Epoch: 5| Step: 2
Training loss: 2.763478453644487
Validation loss: 2.4783599346142915

Epoch: 5| Step: 3
Training loss: 2.7612119476749535
Validation loss: 2.480012299806194

Epoch: 5| Step: 4
Training loss: 2.1987200047809243
Validation loss: 2.465924264882708

Epoch: 5| Step: 5
Training loss: 2.3984255712753035
Validation loss: 2.449128039763666

Epoch: 5| Step: 6
Training loss: 2.0648726485471247
Validation loss: 2.457852437693251

Epoch: 5| Step: 7
Training loss: 2.6831084455312193
Validation loss: 2.4663843087531605

Epoch: 5| Step: 8
Training loss: 2.8930709800201186
Validation loss: 2.4396310487841273

Epoch: 5| Step: 9
Training loss: 2.257746817613491
Validation loss: 2.4585709044255517

Epoch: 5| Step: 10
Training loss: 2.083298860900506
Validation loss: 2.4458832113942943

Epoch: 142| Step: 0
Training loss: 2.034941034048516
Validation loss: 2.461463943012691

Epoch: 5| Step: 1
Training loss: 2.166818894638374
Validation loss: 2.458249747842094

Epoch: 5| Step: 2
Training loss: 2.9069081863480695
Validation loss: 2.4534252582068117

Epoch: 5| Step: 3
Training loss: 2.6145416094324476
Validation loss: 2.4727235392322195

Epoch: 5| Step: 4
Training loss: 2.459235095997382
Validation loss: 2.487231150787942

Epoch: 5| Step: 5
Training loss: 2.439879014502095
Validation loss: 2.4675922111450688

Epoch: 5| Step: 6
Training loss: 2.566775035634625
Validation loss: 2.46010987870861

Epoch: 5| Step: 7
Training loss: 2.3892522124068374
Validation loss: 2.4650747186006683

Epoch: 5| Step: 8
Training loss: 2.531191789876111
Validation loss: 2.4507531364400355

Epoch: 5| Step: 9
Training loss: 2.64955120244955
Validation loss: 2.454492639065622

Epoch: 5| Step: 10
Training loss: 2.510159543958652
Validation loss: 2.461884197257946

Epoch: 143| Step: 0
Training loss: 2.546852720198274
Validation loss: 2.481452265414585

Epoch: 5| Step: 1
Training loss: 2.6410766757001753
Validation loss: 2.474474338847583

Epoch: 5| Step: 2
Training loss: 2.514968502082538
Validation loss: 2.467773569433648

Epoch: 5| Step: 3
Training loss: 2.4509068075989573
Validation loss: 2.483905518535476

Epoch: 5| Step: 4
Training loss: 2.4823684746665946
Validation loss: 2.45499140103259

Epoch: 5| Step: 5
Training loss: 2.8440801407887584
Validation loss: 2.474899501216487

Epoch: 5| Step: 6
Training loss: 2.511534403773982
Validation loss: 2.4866754405775136

Epoch: 5| Step: 7
Training loss: 2.0901089794091803
Validation loss: 2.4772917255944136

Epoch: 5| Step: 8
Training loss: 1.9778763697668345
Validation loss: 2.4330003327932976

Epoch: 5| Step: 9
Training loss: 2.5047123365783084
Validation loss: 2.4599116872293556

Epoch: 5| Step: 10
Training loss: 2.4834020856859755
Validation loss: 2.435248860199605

Epoch: 144| Step: 0
Training loss: 2.175613479035822
Validation loss: 2.4534891084446464

Epoch: 5| Step: 1
Training loss: 2.476990864286797
Validation loss: 2.4323454089396788

Epoch: 5| Step: 2
Training loss: 2.9762805394668987
Validation loss: 2.4526060187780256

Epoch: 5| Step: 3
Training loss: 2.6853825411368177
Validation loss: 2.471218904744884

Epoch: 5| Step: 4
Training loss: 2.834796266047195
Validation loss: 2.447141832521942

Epoch: 5| Step: 5
Training loss: 2.0935767941927454
Validation loss: 2.449675425948847

Epoch: 5| Step: 6
Training loss: 2.3833494488186844
Validation loss: 2.4432586953192885

Epoch: 5| Step: 7
Training loss: 2.4231042511066168
Validation loss: 2.4587631868278366

Epoch: 5| Step: 8
Training loss: 2.072262173433153
Validation loss: 2.4554427143426905

Epoch: 5| Step: 9
Training loss: 2.7854566157996783
Validation loss: 2.4678390455706136

Epoch: 5| Step: 10
Training loss: 2.1199606438348546
Validation loss: 2.4925669333911946

Epoch: 145| Step: 0
Training loss: 2.7480702999068236
Validation loss: 2.44957768297641

Epoch: 5| Step: 1
Training loss: 2.5604950108865956
Validation loss: 2.4485576857689586

Epoch: 5| Step: 2
Training loss: 2.4304203020035176
Validation loss: 2.4785081073679915

Epoch: 5| Step: 3
Training loss: 2.3093646677738464
Validation loss: 2.4708639439916724

Epoch: 5| Step: 4
Training loss: 1.9687244474175707
Validation loss: 2.462162107034373

Epoch: 5| Step: 5
Training loss: 2.507042407102832
Validation loss: 2.432526133250345

Epoch: 5| Step: 6
Training loss: 1.4530365619614423
Validation loss: 2.474352307558073

Epoch: 5| Step: 7
Training loss: 2.6890973511675615
Validation loss: 2.4661682739823845

Epoch: 5| Step: 8
Training loss: 2.888420295205982
Validation loss: 2.465761458130005

Epoch: 5| Step: 9
Training loss: 2.533516798988721
Validation loss: 2.4626430827409975

Epoch: 5| Step: 10
Training loss: 2.950713772819045
Validation loss: 2.4690557165694997

Epoch: 146| Step: 0
Training loss: 2.0229961841903656
Validation loss: 2.44398335504863

Epoch: 5| Step: 1
Training loss: 2.3955374714710014
Validation loss: 2.461193687437093

Epoch: 5| Step: 2
Training loss: 2.088861138191042
Validation loss: 2.472645162476442

Epoch: 5| Step: 3
Training loss: 2.883217718492907
Validation loss: 2.477863521126396

Epoch: 5| Step: 4
Training loss: 2.8077789525409202
Validation loss: 2.470446782203863

Epoch: 5| Step: 5
Training loss: 2.454936336771799
Validation loss: 2.4531740333009875

Epoch: 5| Step: 6
Training loss: 2.5149805416317594
Validation loss: 2.434124479609626

Epoch: 5| Step: 7
Training loss: 2.2466212441053193
Validation loss: 2.4585171617409567

Epoch: 5| Step: 8
Training loss: 2.5386288316549286
Validation loss: 2.4542330618220554

Epoch: 5| Step: 9
Training loss: 2.6376729863283654
Validation loss: 2.455384845340313

Epoch: 5| Step: 10
Training loss: 2.3893421196577327
Validation loss: 2.481301257777065

Epoch: 147| Step: 0
Training loss: 1.4233251868617134
Validation loss: 2.464434898177641

Epoch: 5| Step: 1
Training loss: 2.771062473392708
Validation loss: 2.4951416368901858

Epoch: 5| Step: 2
Training loss: 2.34981413572928
Validation loss: 2.4344897996982713

Epoch: 5| Step: 3
Training loss: 2.775797610740642
Validation loss: 2.4943170806193495

Epoch: 5| Step: 4
Training loss: 2.4888395105394827
Validation loss: 2.4622205330914584

Epoch: 5| Step: 5
Training loss: 2.7501675814805915
Validation loss: 2.4744651336644634

Epoch: 5| Step: 6
Training loss: 2.3785667740961633
Validation loss: 2.4772851687370214

Epoch: 5| Step: 7
Training loss: 3.2119219308109006
Validation loss: 2.45979849791209

Epoch: 5| Step: 8
Training loss: 2.1634490868625806
Validation loss: 2.4794308731978965

Epoch: 5| Step: 9
Training loss: 2.1169543824179984
Validation loss: 2.4854403307905204

Epoch: 5| Step: 10
Training loss: 2.3283346196987758
Validation loss: 2.4707693338591983

Epoch: 148| Step: 0
Training loss: 2.21227943484804
Validation loss: 2.4738904479751067

Epoch: 5| Step: 1
Training loss: 1.912055695728104
Validation loss: 2.4896239259671145

Epoch: 5| Step: 2
Training loss: 2.4138296070533247
Validation loss: 2.4391779413226886

Epoch: 5| Step: 3
Training loss: 2.738416551411675
Validation loss: 2.467514977369216

Epoch: 5| Step: 4
Training loss: 2.0671443089869768
Validation loss: 2.470785657658637

Epoch: 5| Step: 5
Training loss: 2.837101300834838
Validation loss: 2.452045347044782

Epoch: 5| Step: 6
Training loss: 2.9845798282335543
Validation loss: 2.4692934268123756

Epoch: 5| Step: 7
Training loss: 2.9543020334870835
Validation loss: 2.4473108495435705

Epoch: 5| Step: 8
Training loss: 2.6605745006354167
Validation loss: 2.4615654163343086

Epoch: 5| Step: 9
Training loss: 1.9092327608112203
Validation loss: 2.4909116606609913

Epoch: 5| Step: 10
Training loss: 1.9762779905591794
Validation loss: 2.460555698032584

Epoch: 149| Step: 0
Training loss: 2.128420713159936
Validation loss: 2.444560922817974

Epoch: 5| Step: 1
Training loss: 2.3537617788156844
Validation loss: 2.4735610416661733

Epoch: 5| Step: 2
Training loss: 2.4579007258407284
Validation loss: 2.48704150331743

Epoch: 5| Step: 3
Training loss: 2.486751547311601
Validation loss: 2.4481203586623668

Epoch: 5| Step: 4
Training loss: 2.06312412875578
Validation loss: 2.421200803238408

Epoch: 5| Step: 5
Training loss: 2.4536577363043666
Validation loss: 2.4483171863646547

Epoch: 5| Step: 6
Training loss: 2.7106583421313193
Validation loss: 2.44414784636208

Epoch: 5| Step: 7
Training loss: 3.1196307022440637
Validation loss: 2.4559704583490256

Epoch: 5| Step: 8
Training loss: 2.3961669910681254
Validation loss: 2.4680908764588896

Epoch: 5| Step: 9
Training loss: 2.490028618184671
Validation loss: 2.4608942739372592

Epoch: 5| Step: 10
Training loss: 2.4770681544919775
Validation loss: 2.4317742529229087

Epoch: 150| Step: 0
Training loss: 2.40166244149967
Validation loss: 2.4491486168160237

Epoch: 5| Step: 1
Training loss: 3.0365621680973724
Validation loss: 2.472391443251625

Epoch: 5| Step: 2
Training loss: 2.3975993627298533
Validation loss: 2.461459500966238

Epoch: 5| Step: 3
Training loss: 2.4949744256492
Validation loss: 2.448746323875914

Epoch: 5| Step: 4
Training loss: 2.2853421649131627
Validation loss: 2.457860783049379

Epoch: 5| Step: 5
Training loss: 1.9452523218368285
Validation loss: 2.477914689669263

Epoch: 5| Step: 6
Training loss: 2.6890121464112733
Validation loss: 2.4964711941243682

Epoch: 5| Step: 7
Training loss: 2.3969447557228567
Validation loss: 2.462180050230707

Epoch: 5| Step: 8
Training loss: 2.3834801910966448
Validation loss: 2.4800752185002635

Epoch: 5| Step: 9
Training loss: 2.8007150213905163
Validation loss: 2.478116132841923

Epoch: 5| Step: 10
Training loss: 1.9227940912603887
Validation loss: 2.4919252697747623

Epoch: 151| Step: 0
Training loss: 1.7764972389601283
Validation loss: 2.4782299896408673

Epoch: 5| Step: 1
Training loss: 2.2591495976588294
Validation loss: 2.4584429031517687

Epoch: 5| Step: 2
Training loss: 2.221420507718662
Validation loss: 2.468748826566235

Epoch: 5| Step: 3
Training loss: 2.5526581616396555
Validation loss: 2.4621082245988806

Epoch: 5| Step: 4
Training loss: 2.631395813442355
Validation loss: 2.4614632264533363

Epoch: 5| Step: 5
Training loss: 2.466915946255298
Validation loss: 2.455699951059332

Epoch: 5| Step: 6
Training loss: 2.7806243192706623
Validation loss: 2.440861920585685

Epoch: 5| Step: 7
Training loss: 2.6951860038817395
Validation loss: 2.484463006579643

Epoch: 5| Step: 8
Training loss: 2.8331978335423837
Validation loss: 2.4777974764811286

Epoch: 5| Step: 9
Training loss: 2.5151337327533962
Validation loss: 2.4573014250333256

Epoch: 5| Step: 10
Training loss: 1.9479865879286433
Validation loss: 2.495269365544202

Epoch: 152| Step: 0
Training loss: 2.576161232001565
Validation loss: 2.4740003128678274

Epoch: 5| Step: 1
Training loss: 2.4618056930544343
Validation loss: 2.4446880391509938

Epoch: 5| Step: 2
Training loss: 2.5961128410948375
Validation loss: 2.4455976611190935

Epoch: 5| Step: 3
Training loss: 2.021335998102275
Validation loss: 2.4525022691469474

Epoch: 5| Step: 4
Training loss: 2.751192961209437
Validation loss: 2.46264968587032

Epoch: 5| Step: 5
Training loss: 2.365312192284091
Validation loss: 2.4564230956759205

Epoch: 5| Step: 6
Training loss: 2.023825118595166
Validation loss: 2.4662578044637913

Epoch: 5| Step: 7
Training loss: 2.081671420667894
Validation loss: 2.4679650475879042

Epoch: 5| Step: 8
Training loss: 2.772462657405243
Validation loss: 2.474229196812078

Epoch: 5| Step: 9
Training loss: 2.6920383192852215
Validation loss: 2.452126986511215

Epoch: 5| Step: 10
Training loss: 2.412988516409116
Validation loss: 2.47979320951589

Epoch: 153| Step: 0
Training loss: 2.4808958632029716
Validation loss: 2.465864281852736

Epoch: 5| Step: 1
Training loss: 2.2840878328313865
Validation loss: 2.4702373892687253

Epoch: 5| Step: 2
Training loss: 2.9655985920476953
Validation loss: 2.4611658363128583

Epoch: 5| Step: 3
Training loss: 2.8011326270172616
Validation loss: 2.46798827015358

Epoch: 5| Step: 4
Training loss: 1.4538910190085805
Validation loss: 2.472616282219776

Epoch: 5| Step: 5
Training loss: 2.3911860187942406
Validation loss: 2.4626514555850867

Epoch: 5| Step: 6
Training loss: 2.335502048080745
Validation loss: 2.483375207286849

Epoch: 5| Step: 7
Training loss: 2.2888505336280276
Validation loss: 2.476572843305989

Epoch: 5| Step: 8
Training loss: 2.622264799438692
Validation loss: 2.46759697980137

Epoch: 5| Step: 9
Training loss: 2.2197146400705443
Validation loss: 2.461107202926786

Epoch: 5| Step: 10
Training loss: 2.8470431532542144
Validation loss: 2.4745922056786216

Epoch: 154| Step: 0
Training loss: 2.6989991558309665
Validation loss: 2.4739151796852874

Epoch: 5| Step: 1
Training loss: 2.5151688061405677
Validation loss: 2.458206917745372

Epoch: 5| Step: 2
Training loss: 2.7654234387068324
Validation loss: 2.4562013418118687

Epoch: 5| Step: 3
Training loss: 2.627346624803289
Validation loss: 2.4610049513092305

Epoch: 5| Step: 4
Training loss: 2.6945294555764265
Validation loss: 2.472275928047471

Epoch: 5| Step: 5
Training loss: 2.720486930149726
Validation loss: 2.4618368015830443

Epoch: 5| Step: 6
Training loss: 1.7031966728038193
Validation loss: 2.446694539279552

Epoch: 5| Step: 7
Training loss: 1.9755309658727682
Validation loss: 2.4638589342825856

Epoch: 5| Step: 8
Training loss: 2.039351753385287
Validation loss: 2.472194759006963

Epoch: 5| Step: 9
Training loss: 2.569920657821949
Validation loss: 2.4546940607598247

Epoch: 5| Step: 10
Training loss: 2.4612541842679345
Validation loss: 2.462347784627055

Epoch: 155| Step: 0
Training loss: 2.4153748929334107
Validation loss: 2.438796904472629

Epoch: 5| Step: 1
Training loss: 2.0815817399589704
Validation loss: 2.466458951368629

Epoch: 5| Step: 2
Training loss: 2.310397352086872
Validation loss: 2.4680214364100164

Epoch: 5| Step: 3
Training loss: 2.27250720519213
Validation loss: 2.479341328287465

Epoch: 5| Step: 4
Training loss: 2.671409700267282
Validation loss: 2.481242723083116

Epoch: 5| Step: 5
Training loss: 1.9321335953237895
Validation loss: 2.4553771169803844

Epoch: 5| Step: 6
Training loss: 2.967637345462644
Validation loss: 2.474383005545976

Epoch: 5| Step: 7
Training loss: 2.6252887203745665
Validation loss: 2.4744086274907326

Epoch: 5| Step: 8
Training loss: 2.4933372404540486
Validation loss: 2.475210017001532

Epoch: 5| Step: 9
Training loss: 2.26214679890608
Validation loss: 2.502362338013746

Epoch: 5| Step: 10
Training loss: 2.8027549609980045
Validation loss: 2.4875236778886456

Epoch: 156| Step: 0
Training loss: 2.54543895840517
Validation loss: 2.459403684296389

Epoch: 5| Step: 1
Training loss: 2.4479924832770936
Validation loss: 2.4907510985813213

Epoch: 5| Step: 2
Training loss: 2.0707402777023907
Validation loss: 2.473447243574629

Epoch: 5| Step: 3
Training loss: 2.410351613935509
Validation loss: 2.4569502346857326

Epoch: 5| Step: 4
Training loss: 2.1796876093819977
Validation loss: 2.4829566958867906

Epoch: 5| Step: 5
Training loss: 2.6358351745824167
Validation loss: 2.488440384904015

Epoch: 5| Step: 6
Training loss: 2.7698425204135027
Validation loss: 2.4870592484640373

Epoch: 5| Step: 7
Training loss: 2.643666158298124
Validation loss: 2.469840872479042

Epoch: 5| Step: 8
Training loss: 2.351422074392885
Validation loss: 2.495815232482263

Epoch: 5| Step: 9
Training loss: 2.518842262868964
Validation loss: 2.4712087926750166

Epoch: 5| Step: 10
Training loss: 2.2524652750638916
Validation loss: 2.4668410379121264

Epoch: 157| Step: 0
Training loss: 2.4415963793154027
Validation loss: 2.4739685946102234

Epoch: 5| Step: 1
Training loss: 2.4583756933495944
Validation loss: 2.460640431808724

Epoch: 5| Step: 2
Training loss: 2.820238614369355
Validation loss: 2.473934279078245

Epoch: 5| Step: 3
Training loss: 1.6750872404239148
Validation loss: 2.461392687037854

Epoch: 5| Step: 4
Training loss: 2.073426980952794
Validation loss: 2.4500242866181274

Epoch: 5| Step: 5
Training loss: 2.6020857367849333
Validation loss: 2.4429911889549696

Epoch: 5| Step: 6
Training loss: 2.7204708046730386
Validation loss: 2.453143777403778

Epoch: 5| Step: 7
Training loss: 2.2972627688725655
Validation loss: 2.464202416754241

Epoch: 5| Step: 8
Training loss: 2.818588279263307
Validation loss: 2.4702060175862393

Epoch: 5| Step: 9
Training loss: 2.603225680415793
Validation loss: 2.46906490246448

Epoch: 5| Step: 10
Training loss: 2.0646850109244115
Validation loss: 2.4650831923835677

Epoch: 158| Step: 0
Training loss: 2.503680476396092
Validation loss: 2.4497286640667943

Epoch: 5| Step: 1
Training loss: 2.871593613480404
Validation loss: 2.447451063152888

Epoch: 5| Step: 2
Training loss: 2.4448426986675496
Validation loss: 2.4524661281143643

Epoch: 5| Step: 3
Training loss: 2.0117324976775404
Validation loss: 2.437229153541511

Epoch: 5| Step: 4
Training loss: 2.237485521152471
Validation loss: 2.4516141811328658

Epoch: 5| Step: 5
Training loss: 2.149693901983001
Validation loss: 2.4674118535904888

Epoch: 5| Step: 6
Training loss: 2.701926875431577
Validation loss: 2.4628856265584536

Epoch: 5| Step: 7
Training loss: 2.3894660484135355
Validation loss: 2.4325581394726083

Epoch: 5| Step: 8
Training loss: 2.7001772998947122
Validation loss: 2.4796978581436515

Epoch: 5| Step: 9
Training loss: 2.467781263126937
Validation loss: 2.434963582081068

Epoch: 5| Step: 10
Training loss: 2.133317265847416
Validation loss: 2.4860730442603574

Epoch: 159| Step: 0
Training loss: 1.9264612448165552
Validation loss: 2.4508732442088776

Epoch: 5| Step: 1
Training loss: 2.558073174319558
Validation loss: 2.4629257657770767

Epoch: 5| Step: 2
Training loss: 2.5164134999277064
Validation loss: 2.480914464516618

Epoch: 5| Step: 3
Training loss: 2.2443675431945884
Validation loss: 2.455748140600651

Epoch: 5| Step: 4
Training loss: 2.5218759907811523
Validation loss: 2.4679168607941326

Epoch: 5| Step: 5
Training loss: 2.341954675341728
Validation loss: 2.4656767079893434

Epoch: 5| Step: 6
Training loss: 2.3811330411127303
Validation loss: 2.4575634796016006

Epoch: 5| Step: 7
Training loss: 2.6187317804326393
Validation loss: 2.4718616948676435

Epoch: 5| Step: 8
Training loss: 2.6494407891494274
Validation loss: 2.4609422768635834

Epoch: 5| Step: 9
Training loss: 2.405110076796143
Validation loss: 2.4696187528320688

Epoch: 5| Step: 10
Training loss: 2.4932961225367882
Validation loss: 2.4474052818389054

Epoch: 160| Step: 0
Training loss: 2.0852034630974092
Validation loss: 2.4653743533369004

Epoch: 5| Step: 1
Training loss: 2.708348953984525
Validation loss: 2.4535540374148446

Epoch: 5| Step: 2
Training loss: 2.360347118065737
Validation loss: 2.445382958116914

Epoch: 5| Step: 3
Training loss: 2.716976157113635
Validation loss: 2.462708756179997

Epoch: 5| Step: 4
Training loss: 2.501331356313503
Validation loss: 2.470315307442075

Epoch: 5| Step: 5
Training loss: 2.4050830141519355
Validation loss: 2.4837131166754394

Epoch: 5| Step: 6
Training loss: 2.3543106192628613
Validation loss: 2.45001229619416

Epoch: 5| Step: 7
Training loss: 1.8981399616936752
Validation loss: 2.488196321068559

Epoch: 5| Step: 8
Training loss: 2.606395093506234
Validation loss: 2.4545071242364784

Epoch: 5| Step: 9
Training loss: 2.3047911539852737
Validation loss: 2.4649863026935686

Epoch: 5| Step: 10
Training loss: 2.4261138245752036
Validation loss: 2.462523763235987

Epoch: 161| Step: 0
Training loss: 2.1495689048610664
Validation loss: 2.4533612276207344

Epoch: 5| Step: 1
Training loss: 2.554115067957
Validation loss: 2.460887910910041

Epoch: 5| Step: 2
Training loss: 2.2316571759038033
Validation loss: 2.466759276404559

Epoch: 5| Step: 3
Training loss: 2.1452249818913884
Validation loss: 2.4414402992417314

Epoch: 5| Step: 4
Training loss: 2.754488662926289
Validation loss: 2.467190347574126

Epoch: 5| Step: 5
Training loss: 2.411171475205158
Validation loss: 2.4458991672559303

Epoch: 5| Step: 6
Training loss: 2.2680949460832194
Validation loss: 2.458812660810036

Epoch: 5| Step: 7
Training loss: 2.4247846291457926
Validation loss: 2.454137300251252

Epoch: 5| Step: 8
Training loss: 2.5803223464739142
Validation loss: 2.4621068366282395

Epoch: 5| Step: 9
Training loss: 2.754261096791758
Validation loss: 2.449308722108149

Epoch: 5| Step: 10
Training loss: 2.3651598817039257
Validation loss: 2.443095325698608

Epoch: 162| Step: 0
Training loss: 2.293997382770299
Validation loss: 2.474352135567868

Epoch: 5| Step: 1
Training loss: 2.265849240485591
Validation loss: 2.4724561858563106

Epoch: 5| Step: 2
Training loss: 2.419750832585222
Validation loss: 2.4760666641976

Epoch: 5| Step: 3
Training loss: 2.7630637857955795
Validation loss: 2.474994011991153

Epoch: 5| Step: 4
Training loss: 2.513432749983613
Validation loss: 2.4432536430739225

Epoch: 5| Step: 5
Training loss: 2.588523931205879
Validation loss: 2.459728253654755

Epoch: 5| Step: 6
Training loss: 2.3758561448369453
Validation loss: 2.4754587456190924

Epoch: 5| Step: 7
Training loss: 2.363520435177928
Validation loss: 2.464604076317312

Epoch: 5| Step: 8
Training loss: 2.0859748751260123
Validation loss: 2.4234282488885803

Epoch: 5| Step: 9
Training loss: 2.72528640921795
Validation loss: 2.458354322768997

Epoch: 5| Step: 10
Training loss: 2.2810497457321888
Validation loss: 2.4630916544935406

Epoch: 163| Step: 0
Training loss: 2.260967861306489
Validation loss: 2.4399867502606236

Epoch: 5| Step: 1
Training loss: 2.4626073591191893
Validation loss: 2.470732278719537

Epoch: 5| Step: 2
Training loss: 2.5814544448985393
Validation loss: 2.481461397154977

Epoch: 5| Step: 3
Training loss: 2.3931558215193127
Validation loss: 2.455110931027192

Epoch: 5| Step: 4
Training loss: 2.236010293155515
Validation loss: 2.4766192468697175

Epoch: 5| Step: 5
Training loss: 2.039782283796314
Validation loss: 2.493661192817382

Epoch: 5| Step: 6
Training loss: 2.361508245043038
Validation loss: 2.4622019977483567

Epoch: 5| Step: 7
Training loss: 2.523147424612872
Validation loss: 2.4667372104243284

Epoch: 5| Step: 8
Training loss: 2.8735790887810935
Validation loss: 2.481595397112396

Epoch: 5| Step: 9
Training loss: 2.490085971374568
Validation loss: 2.478219277739121

Epoch: 5| Step: 10
Training loss: 2.2012793202481036
Validation loss: 2.47070499478299

Epoch: 164| Step: 0
Training loss: 2.899135783104923
Validation loss: 2.4565735454271795

Epoch: 5| Step: 1
Training loss: 2.4367416375868842
Validation loss: 2.4877920397649547

Epoch: 5| Step: 2
Training loss: 2.2337946638307407
Validation loss: 2.4800527696506314

Epoch: 5| Step: 3
Training loss: 2.6775603902152256
Validation loss: 2.463873513699372

Epoch: 5| Step: 4
Training loss: 2.6158175854443337
Validation loss: 2.4588849669066493

Epoch: 5| Step: 5
Training loss: 2.7017694503212537
Validation loss: 2.458706081017381

Epoch: 5| Step: 6
Training loss: 2.07961432072426
Validation loss: 2.478609287838847

Epoch: 5| Step: 7
Training loss: 2.1393581456359922
Validation loss: 2.436984338688197

Epoch: 5| Step: 8
Training loss: 2.337714804505064
Validation loss: 2.4926812151618774

Epoch: 5| Step: 9
Training loss: 2.1538212684356997
Validation loss: 2.4777438875013087

Epoch: 5| Step: 10
Training loss: 2.1556085931779037
Validation loss: 2.4742758360112544

Epoch: 165| Step: 0
Training loss: 2.758386222662672
Validation loss: 2.4608396522093003

Epoch: 5| Step: 1
Training loss: 2.020629348160242
Validation loss: 2.489788073946143

Epoch: 5| Step: 2
Training loss: 2.2863339771930375
Validation loss: 2.462059432744135

Epoch: 5| Step: 3
Training loss: 2.6437072822600656
Validation loss: 2.4442332496360906

Epoch: 5| Step: 4
Training loss: 2.3403488913075403
Validation loss: 2.4520124111328157

Epoch: 5| Step: 5
Training loss: 2.2508524233665126
Validation loss: 2.4800681893662695

Epoch: 5| Step: 6
Training loss: 2.456666370462566
Validation loss: 2.479164351719635

Epoch: 5| Step: 7
Training loss: 2.7517777678782607
Validation loss: 2.454277845654479

Epoch: 5| Step: 8
Training loss: 2.3034944194033047
Validation loss: 2.466044492177323

Epoch: 5| Step: 9
Training loss: 1.8712423819040938
Validation loss: 2.469296153145552

Epoch: 5| Step: 10
Training loss: 2.6535905876560864
Validation loss: 2.4863703294246013

Epoch: 166| Step: 0
Training loss: 2.685957532522827
Validation loss: 2.4622460192206903

Epoch: 5| Step: 1
Training loss: 2.389128372352067
Validation loss: 2.4800645755566855

Epoch: 5| Step: 2
Training loss: 2.2526090118414897
Validation loss: 2.4758608720784157

Epoch: 5| Step: 3
Training loss: 2.2709760941826582
Validation loss: 2.459106050299287

Epoch: 5| Step: 4
Training loss: 2.279548219291693
Validation loss: 2.4390110058020813

Epoch: 5| Step: 5
Training loss: 2.222879569528552
Validation loss: 2.4730722875407025

Epoch: 5| Step: 6
Training loss: 2.1590373502595255
Validation loss: 2.462279986433777

Epoch: 5| Step: 7
Training loss: 2.3243399965092366
Validation loss: 2.436063727739656

Epoch: 5| Step: 8
Training loss: 2.6020797810913305
Validation loss: 2.4387139467704806

Epoch: 5| Step: 9
Training loss: 2.548880787740196
Validation loss: 2.477116773876

Epoch: 5| Step: 10
Training loss: 2.805954670817948
Validation loss: 2.459215249147739

Epoch: 167| Step: 0
Training loss: 2.277687112301198
Validation loss: 2.4605834518745984

Epoch: 5| Step: 1
Training loss: 2.2793489661062325
Validation loss: 2.453553134648538

Epoch: 5| Step: 2
Training loss: 2.2461754825482534
Validation loss: 2.458900841527398

Epoch: 5| Step: 3
Training loss: 2.490356059373783
Validation loss: 2.4734195459746666

Epoch: 5| Step: 4
Training loss: 2.819233357671213
Validation loss: 2.4647737056947334

Epoch: 5| Step: 5
Training loss: 2.5887906564331717
Validation loss: 2.466702265809593

Epoch: 5| Step: 6
Training loss: 2.434571193873938
Validation loss: 2.4706242836172465

Epoch: 5| Step: 7
Training loss: 2.79430062075781
Validation loss: 2.4831153853134578

Epoch: 5| Step: 8
Training loss: 1.9194248988212501
Validation loss: 2.4884276740192637

Epoch: 5| Step: 9
Training loss: 2.1402895031057114
Validation loss: 2.465728410153261

Epoch: 5| Step: 10
Training loss: 1.996618750522123
Validation loss: 2.4900812313724736

Epoch: 168| Step: 0
Training loss: 2.5423981807279707
Validation loss: 2.477425961430625

Epoch: 5| Step: 1
Training loss: 1.9439227797080876
Validation loss: 2.4821502368336166

Epoch: 5| Step: 2
Training loss: 2.300754514580977
Validation loss: 2.500958978630276

Epoch: 5| Step: 3
Training loss: 2.2242402397594194
Validation loss: 2.46403572938334

Epoch: 5| Step: 4
Training loss: 2.033840229867489
Validation loss: 2.4731025183573587

Epoch: 5| Step: 5
Training loss: 2.3666494028599017
Validation loss: 2.479181423196766

Epoch: 5| Step: 6
Training loss: 2.1771098109434557
Validation loss: 2.5021779904550687

Epoch: 5| Step: 7
Training loss: 3.144460433257318
Validation loss: 2.4582766496294486

Epoch: 5| Step: 8
Training loss: 2.7707162320816443
Validation loss: 2.477283977614127

Epoch: 5| Step: 9
Training loss: 2.6052984499429517
Validation loss: 2.4633515372254404

Epoch: 5| Step: 10
Training loss: 2.0482811211226504
Validation loss: 2.454908209976248

Epoch: 169| Step: 0
Training loss: 2.244145724537287
Validation loss: 2.4560928069400676

Epoch: 5| Step: 1
Training loss: 2.4107075807185505
Validation loss: 2.475624611566564

Epoch: 5| Step: 2
Training loss: 2.508097789853501
Validation loss: 2.46033160330646

Epoch: 5| Step: 3
Training loss: 2.075519391054987
Validation loss: 2.45411718601285

Epoch: 5| Step: 4
Training loss: 2.254603762271192
Validation loss: 2.4841905771659176

Epoch: 5| Step: 5
Training loss: 2.274124828143405
Validation loss: 2.476329018807555

Epoch: 5| Step: 6
Training loss: 2.6318016941765774
Validation loss: 2.4666458120132413

Epoch: 5| Step: 7
Training loss: 2.5807398626809652
Validation loss: 2.474112397574255

Epoch: 5| Step: 8
Training loss: 2.841768853223099
Validation loss: 2.4807107993513635

Epoch: 5| Step: 9
Training loss: 2.3296609202863667
Validation loss: 2.477174579175483

Epoch: 5| Step: 10
Training loss: 2.280734382780815
Validation loss: 2.491725098358326

Epoch: 170| Step: 0
Training loss: 1.6061499419756546
Validation loss: 2.456718334254029

Epoch: 5| Step: 1
Training loss: 2.314673562155325
Validation loss: 2.481678274119487

Epoch: 5| Step: 2
Training loss: 2.5232060093002024
Validation loss: 2.486551463562331

Epoch: 5| Step: 3
Training loss: 2.341954573538484
Validation loss: 2.4708076205601133

Epoch: 5| Step: 4
Training loss: 2.618721401449926
Validation loss: 2.5112190405912735

Epoch: 5| Step: 5
Training loss: 2.7088980355011416
Validation loss: 2.4697107356653185

Epoch: 5| Step: 6
Training loss: 2.2818074002645043
Validation loss: 2.477199280167546

Epoch: 5| Step: 7
Training loss: 2.0475049396310916
Validation loss: 2.476476787195271

Epoch: 5| Step: 8
Training loss: 2.869988593367927
Validation loss: 2.5003285838122817

Epoch: 5| Step: 9
Training loss: 2.5244638345855
Validation loss: 2.4742092542011718

Epoch: 5| Step: 10
Training loss: 2.4324546830130482
Validation loss: 2.4941816919926447

Epoch: 171| Step: 0
Training loss: 2.2772174885265724
Validation loss: 2.493850977321245

Epoch: 5| Step: 1
Training loss: 2.7304957310731046
Validation loss: 2.502305997701058

Epoch: 5| Step: 2
Training loss: 2.1586714706760146
Validation loss: 2.464158712693273

Epoch: 5| Step: 3
Training loss: 2.0486723019644164
Validation loss: 2.4601955724558513

Epoch: 5| Step: 4
Training loss: 1.9975689179296574
Validation loss: 2.465819459450208

Epoch: 5| Step: 5
Training loss: 2.0870574344981017
Validation loss: 2.474356425994649

Epoch: 5| Step: 6
Training loss: 2.1163925423922785
Validation loss: 2.47163124121429

Epoch: 5| Step: 7
Training loss: 2.6300682911872446
Validation loss: 2.471562897436265

Epoch: 5| Step: 8
Training loss: 3.1273120719378302
Validation loss: 2.469687681888295

Epoch: 5| Step: 9
Training loss: 2.1508817328478873
Validation loss: 2.4777661172290264

Epoch: 5| Step: 10
Training loss: 2.7971643053170725
Validation loss: 2.484333545939792

Epoch: 172| Step: 0
Training loss: 2.600710892692493
Validation loss: 2.4629912401594916

Epoch: 5| Step: 1
Training loss: 2.261403643279035
Validation loss: 2.4779758780252346

Epoch: 5| Step: 2
Training loss: 2.2292546644103193
Validation loss: 2.451779644231009

Epoch: 5| Step: 3
Training loss: 2.309255437375612
Validation loss: 2.460287829964133

Epoch: 5| Step: 4
Training loss: 2.252949900178889
Validation loss: 2.4607861481595825

Epoch: 5| Step: 5
Training loss: 1.9312309856775014
Validation loss: 2.479309753324445

Epoch: 5| Step: 6
Training loss: 2.1962561700307623
Validation loss: 2.4462234533793428

Epoch: 5| Step: 7
Training loss: 2.9555219983782814
Validation loss: 2.47184828578422

Epoch: 5| Step: 8
Training loss: 2.4880382473081797
Validation loss: 2.468631456487799

Epoch: 5| Step: 9
Training loss: 2.4234866778599984
Validation loss: 2.4714145115992108

Epoch: 5| Step: 10
Training loss: 2.306513899924393
Validation loss: 2.4570788604455167

Epoch: 173| Step: 0
Training loss: 2.0391395525057883
Validation loss: 2.4589433498916007

Epoch: 5| Step: 1
Training loss: 2.3883314911683726
Validation loss: 2.464496688547854

Epoch: 5| Step: 2
Training loss: 2.2362016800361246
Validation loss: 2.4582150491491324

Epoch: 5| Step: 3
Training loss: 2.5794545762228727
Validation loss: 2.4711275709459124

Epoch: 5| Step: 4
Training loss: 2.3799043512758917
Validation loss: 2.4625519873140678

Epoch: 5| Step: 5
Training loss: 1.7730918244897838
Validation loss: 2.5058027352858456

Epoch: 5| Step: 6
Training loss: 2.4690035919126245
Validation loss: 2.475223901394337

Epoch: 5| Step: 7
Training loss: 2.6972627964322604
Validation loss: 2.47065010122529

Epoch: 5| Step: 8
Training loss: 3.1588344756810187
Validation loss: 2.5102851287553056

Epoch: 5| Step: 9
Training loss: 2.1908693794931016
Validation loss: 2.485818759297041

Epoch: 5| Step: 10
Training loss: 2.1117096590614874
Validation loss: 2.4644760576020794

Epoch: 174| Step: 0
Training loss: 2.0843026258723234
Validation loss: 2.5099464016548456

Epoch: 5| Step: 1
Training loss: 2.253207463674646
Validation loss: 2.4837037496183174

Epoch: 5| Step: 2
Training loss: 2.3025991514977218
Validation loss: 2.4999999815417873

Epoch: 5| Step: 3
Training loss: 2.5889836835173927
Validation loss: 2.4441612930865033

Epoch: 5| Step: 4
Training loss: 2.728106916614564
Validation loss: 2.4638567096965605

Epoch: 5| Step: 5
Training loss: 2.017516438962006
Validation loss: 2.4676766373357464

Epoch: 5| Step: 6
Training loss: 2.506781820820968
Validation loss: 2.476913070722927

Epoch: 5| Step: 7
Training loss: 2.860848302612196
Validation loss: 2.48040739679105

Epoch: 5| Step: 8
Training loss: 2.1108544706763923
Validation loss: 2.467171097258986

Epoch: 5| Step: 9
Training loss: 2.508948333305566
Validation loss: 2.4500760135490283

Epoch: 5| Step: 10
Training loss: 2.165922061423187
Validation loss: 2.480953189852781

Epoch: 175| Step: 0
Training loss: 1.9729633356661893
Validation loss: 2.48993113624868

Epoch: 5| Step: 1
Training loss: 2.3304278358297763
Validation loss: 2.4783791497424774

Epoch: 5| Step: 2
Training loss: 2.465050158193473
Validation loss: 2.4808842782579132

Epoch: 5| Step: 3
Training loss: 2.287377059217644
Validation loss: 2.480479374156211

Epoch: 5| Step: 4
Training loss: 2.629825516341137
Validation loss: 2.4745199954281065

Epoch: 5| Step: 5
Training loss: 2.9746784645518014
Validation loss: 2.4673732243113276

Epoch: 5| Step: 6
Training loss: 2.398522589848524
Validation loss: 2.4691096114416347

Epoch: 5| Step: 7
Training loss: 2.1311725277957203
Validation loss: 2.4791016880811845

Epoch: 5| Step: 8
Training loss: 2.1673631526773485
Validation loss: 2.490966073750844

Epoch: 5| Step: 9
Training loss: 2.424034484882368
Validation loss: 2.4390216870409245

Epoch: 5| Step: 10
Training loss: 2.448058125622384
Validation loss: 2.4446998879042416

Epoch: 176| Step: 0
Training loss: 2.6095654994845128
Validation loss: 2.4901950259943297

Epoch: 5| Step: 1
Training loss: 1.9758053260383137
Validation loss: 2.4653017503827557

Epoch: 5| Step: 2
Training loss: 2.062153411412378
Validation loss: 2.462947930439453

Epoch: 5| Step: 3
Training loss: 2.705949223038443
Validation loss: 2.4579678954376583

Epoch: 5| Step: 4
Training loss: 2.7697919929985284
Validation loss: 2.470726897701558

Epoch: 5| Step: 5
Training loss: 2.183811893383025
Validation loss: 2.456925118300271

Epoch: 5| Step: 6
Training loss: 2.132354910812861
Validation loss: 2.463948170989464

Epoch: 5| Step: 7
Training loss: 2.1439635145442137
Validation loss: 2.4370170479772497

Epoch: 5| Step: 8
Training loss: 2.0917643910511714
Validation loss: 2.459929687745466

Epoch: 5| Step: 9
Training loss: 2.268957804261042
Validation loss: 2.459740936707209

Epoch: 5| Step: 10
Training loss: 3.0708751211510688
Validation loss: 2.467793534964794

Epoch: 177| Step: 0
Training loss: 2.6526721868976075
Validation loss: 2.49963157359125

Epoch: 5| Step: 1
Training loss: 2.3285225138428753
Validation loss: 2.475214732659846

Epoch: 5| Step: 2
Training loss: 2.6309865171753257
Validation loss: 2.4361105503926583

Epoch: 5| Step: 3
Training loss: 1.595123073529187
Validation loss: 2.4873856458691783

Epoch: 5| Step: 4
Training loss: 2.4893137467970314
Validation loss: 2.452755920849524

Epoch: 5| Step: 5
Training loss: 2.245717954296359
Validation loss: 2.4809873432045673

Epoch: 5| Step: 6
Training loss: 2.003797026217434
Validation loss: 2.4746202092332115

Epoch: 5| Step: 7
Training loss: 2.055910160075997
Validation loss: 2.4526365248544453

Epoch: 5| Step: 8
Training loss: 2.2240662619304477
Validation loss: 2.4603906995738427

Epoch: 5| Step: 9
Training loss: 2.920076683814223
Validation loss: 2.5214496111102283

Epoch: 5| Step: 10
Training loss: 2.739949674492216
Validation loss: 2.469498249524102

Epoch: 178| Step: 0
Training loss: 2.769506457046995
Validation loss: 2.49372417835354

Epoch: 5| Step: 1
Training loss: 2.5264706172053635
Validation loss: 2.4634918119045452

Epoch: 5| Step: 2
Training loss: 2.2033431574169144
Validation loss: 2.4858506233646684

Epoch: 5| Step: 3
Training loss: 2.1333716920543266
Validation loss: 2.499627988065213

Epoch: 5| Step: 4
Training loss: 2.8304519774961068
Validation loss: 2.4597053449925936

Epoch: 5| Step: 5
Training loss: 2.2007284995661074
Validation loss: 2.4665348743073063

Epoch: 5| Step: 6
Training loss: 2.023631436395633
Validation loss: 2.485859025295486

Epoch: 5| Step: 7
Training loss: 2.6886265190141856
Validation loss: 2.490737955873622

Epoch: 5| Step: 8
Training loss: 2.123183427646241
Validation loss: 2.4760243607631285

Epoch: 5| Step: 9
Training loss: 2.138861939506791
Validation loss: 2.466426157000257

Epoch: 5| Step: 10
Training loss: 2.2851909928248326
Validation loss: 2.4687643163662347

Epoch: 179| Step: 0
Training loss: 2.2471123284859384
Validation loss: 2.460951261258914

Epoch: 5| Step: 1
Training loss: 2.5561337358294764
Validation loss: 2.484776685306339

Epoch: 5| Step: 2
Training loss: 2.5000048637342824
Validation loss: 2.4668675560644857

Epoch: 5| Step: 3
Training loss: 2.306132338915854
Validation loss: 2.4837148600279564

Epoch: 5| Step: 4
Training loss: 2.4106415147242877
Validation loss: 2.48481957019323

Epoch: 5| Step: 5
Training loss: 1.7452939653223536
Validation loss: 2.472419586828278

Epoch: 5| Step: 6
Training loss: 2.5662522175403497
Validation loss: 2.461916308626464

Epoch: 5| Step: 7
Training loss: 2.029135204700534
Validation loss: 2.476525221505551

Epoch: 5| Step: 8
Training loss: 2.7785384429419455
Validation loss: 2.4438371288053187

Epoch: 5| Step: 9
Training loss: 2.2954357594529076
Validation loss: 2.4732348597399034

Epoch: 5| Step: 10
Training loss: 2.4728529431542823
Validation loss: 2.472754507298425

Epoch: 180| Step: 0
Training loss: 2.872668108424157
Validation loss: 2.4418547502606245

Epoch: 5| Step: 1
Training loss: 2.3673102721553207
Validation loss: 2.4777260270096044

Epoch: 5| Step: 2
Training loss: 1.7795192273894664
Validation loss: 2.4767739329374945

Epoch: 5| Step: 3
Training loss: 2.030560890094495
Validation loss: 2.4566613301375466

Epoch: 5| Step: 4
Training loss: 2.4399404779584737
Validation loss: 2.461528277319392

Epoch: 5| Step: 5
Training loss: 2.5440365941516667
Validation loss: 2.485182724938325

Epoch: 5| Step: 6
Training loss: 2.554714844350266
Validation loss: 2.482262410543185

Epoch: 5| Step: 7
Training loss: 2.2176791548582546
Validation loss: 2.4728164225695086

Epoch: 5| Step: 8
Training loss: 2.2372676025407463
Validation loss: 2.4903029938874424

Epoch: 5| Step: 9
Training loss: 2.174681791508272
Validation loss: 2.4938909399060614

Epoch: 5| Step: 10
Training loss: 2.604509031043211
Validation loss: 2.4698850868346764

Epoch: 181| Step: 0
Training loss: 2.344219211658925
Validation loss: 2.460026766953808

Epoch: 5| Step: 1
Training loss: 2.1472755202894156
Validation loss: 2.4627193939734457

Epoch: 5| Step: 2
Training loss: 2.3669462679077347
Validation loss: 2.4754441774753095

Epoch: 5| Step: 3
Training loss: 2.773776095500935
Validation loss: 2.476212467699446

Epoch: 5| Step: 4
Training loss: 2.4485405525960804
Validation loss: 2.498348209795401

Epoch: 5| Step: 5
Training loss: 2.416835143256605
Validation loss: 2.495773423001559

Epoch: 5| Step: 6
Training loss: 2.5262126956471187
Validation loss: 2.445268572073627

Epoch: 5| Step: 7
Training loss: 2.0447724004438
Validation loss: 2.4776054720486376

Epoch: 5| Step: 8
Training loss: 2.4212301072468865
Validation loss: 2.4752410331911734

Epoch: 5| Step: 9
Training loss: 2.0119382275603184
Validation loss: 2.488420870403439

Epoch: 5| Step: 10
Training loss: 2.42633531910771
Validation loss: 2.486475282655779

Epoch: 182| Step: 0
Training loss: 2.2316661500063644
Validation loss: 2.481948039620694

Epoch: 5| Step: 1
Training loss: 2.372987396373948
Validation loss: 2.461261470244254

Epoch: 5| Step: 2
Training loss: 1.920187480634355
Validation loss: 2.4982664424898173

Epoch: 5| Step: 3
Training loss: 2.2353736406388394
Validation loss: 2.481888847737499

Epoch: 5| Step: 4
Training loss: 2.426420904524668
Validation loss: 2.4705435667016693

Epoch: 5| Step: 5
Training loss: 2.3262909699388095
Validation loss: 2.449802284223749

Epoch: 5| Step: 6
Training loss: 2.6159597677117707
Validation loss: 2.462602944119924

Epoch: 5| Step: 7
Training loss: 2.020283129272805
Validation loss: 2.4768513375562033

Epoch: 5| Step: 8
Training loss: 2.8232379650716437
Validation loss: 2.4903770122498936

Epoch: 5| Step: 9
Training loss: 2.5367763145031565
Validation loss: 2.4681264500808258

Epoch: 5| Step: 10
Training loss: 2.3729413797924197
Validation loss: 2.4643413597969324

Epoch: 183| Step: 0
Training loss: 2.2881323060349144
Validation loss: 2.4585036449416404

Epoch: 5| Step: 1
Training loss: 1.9511964966344095
Validation loss: 2.487342624856595

Epoch: 5| Step: 2
Training loss: 2.2864711010923298
Validation loss: 2.4764154820869906

Epoch: 5| Step: 3
Training loss: 2.319773704574606
Validation loss: 2.4440074285607083

Epoch: 5| Step: 4
Training loss: 2.5866198604648636
Validation loss: 2.475864648377146

Epoch: 5| Step: 5
Training loss: 2.9462223823039513
Validation loss: 2.4592820487412546

Epoch: 5| Step: 6
Training loss: 1.8919140543339188
Validation loss: 2.4936870176244925

Epoch: 5| Step: 7
Training loss: 1.8256566917230976
Validation loss: 2.4540812092675943

Epoch: 5| Step: 8
Training loss: 2.684971795670968
Validation loss: 2.514078135363949

Epoch: 5| Step: 9
Training loss: 2.669980632411706
Validation loss: 2.4961844696798776

Epoch: 5| Step: 10
Training loss: 2.1951483940067025
Validation loss: 2.488876466564754

Epoch: 184| Step: 0
Training loss: 1.8539812088130332
Validation loss: 2.4505646203818796

Epoch: 5| Step: 1
Training loss: 2.1799726402245705
Validation loss: 2.4818561818487503

Epoch: 5| Step: 2
Training loss: 2.819044594267532
Validation loss: 2.4736320165547347

Epoch: 5| Step: 3
Training loss: 2.5014729928772446
Validation loss: 2.508469752671587

Epoch: 5| Step: 4
Training loss: 2.1361510587919064
Validation loss: 2.5045796072013267

Epoch: 5| Step: 5
Training loss: 2.4522121213044183
Validation loss: 2.4982552654448913

Epoch: 5| Step: 6
Training loss: 2.373452937544944
Validation loss: 2.493037247104719

Epoch: 5| Step: 7
Training loss: 2.043843011168661
Validation loss: 2.518695606933038

Epoch: 5| Step: 8
Training loss: 2.308707452288021
Validation loss: 2.505269175706898

Epoch: 5| Step: 9
Training loss: 2.5147599338146054
Validation loss: 2.5253173831716182

Epoch: 5| Step: 10
Training loss: 2.6596782327660176
Validation loss: 2.4605746031444116

Epoch: 185| Step: 0
Training loss: 2.3475175204044714
Validation loss: 2.4869032280556738

Epoch: 5| Step: 1
Training loss: 2.5667671402756196
Validation loss: 2.452000578373419

Epoch: 5| Step: 2
Training loss: 2.3277363292713416
Validation loss: 2.465157272264538

Epoch: 5| Step: 3
Training loss: 2.7958361864904484
Validation loss: 2.4802598667148277

Epoch: 5| Step: 4
Training loss: 3.0471701454604965
Validation loss: 2.4360440757010893

Epoch: 5| Step: 5
Training loss: 2.213539344935976
Validation loss: 2.4844122272657923

Epoch: 5| Step: 6
Training loss: 1.8292413547129625
Validation loss: 2.4600372569013014

Epoch: 5| Step: 7
Training loss: 2.411437944253257
Validation loss: 2.4573417055429405

Epoch: 5| Step: 8
Training loss: 1.8648401293102157
Validation loss: 2.472705153120172

Epoch: 5| Step: 9
Training loss: 2.2577121804729576
Validation loss: 2.4482335035921725

Epoch: 5| Step: 10
Training loss: 1.9328178929937518
Validation loss: 2.464281174387124

Epoch: 186| Step: 0
Training loss: 2.6186072299249994
Validation loss: 2.473473975926465

Epoch: 5| Step: 1
Training loss: 2.722882779958097
Validation loss: 2.455188120625913

Epoch: 5| Step: 2
Training loss: 2.523283868134343
Validation loss: 2.488600562449182

Epoch: 5| Step: 3
Training loss: 2.0964168815630373
Validation loss: 2.4762182607541954

Epoch: 5| Step: 4
Training loss: 2.2773907560074305
Validation loss: 2.459119643538934

Epoch: 5| Step: 5
Training loss: 1.7640173690874994
Validation loss: 2.441203187959807

Epoch: 5| Step: 6
Training loss: 2.59872465032312
Validation loss: 2.4744237591292917

Epoch: 5| Step: 7
Training loss: 2.1109475384748126
Validation loss: 2.493053290905324

Epoch: 5| Step: 8
Training loss: 2.8559077352051125
Validation loss: 2.466453471638899

Epoch: 5| Step: 9
Training loss: 1.8968938509210227
Validation loss: 2.461734839577997

Epoch: 5| Step: 10
Training loss: 2.1727141810501953
Validation loss: 2.4725850915784213

Epoch: 187| Step: 0
Training loss: 2.1438034851697867
Validation loss: 2.472437972990144

Epoch: 5| Step: 1
Training loss: 2.0354085754837605
Validation loss: 2.484976354861901

Epoch: 5| Step: 2
Training loss: 2.14018545719728
Validation loss: 2.466933332676012

Epoch: 5| Step: 3
Training loss: 2.581175969796411
Validation loss: 2.447590728788054

Epoch: 5| Step: 4
Training loss: 1.5335584095222001
Validation loss: 2.4679036390742546

Epoch: 5| Step: 5
Training loss: 2.5800979001300264
Validation loss: 2.4783788686436865

Epoch: 5| Step: 6
Training loss: 2.361044791792417
Validation loss: 2.48564729664271

Epoch: 5| Step: 7
Training loss: 2.3114148248603557
Validation loss: 2.4917257856378776

Epoch: 5| Step: 8
Training loss: 2.8146478716615646
Validation loss: 2.486586426671398

Epoch: 5| Step: 9
Training loss: 2.59401002982266
Validation loss: 2.464975444837218

Epoch: 5| Step: 10
Training loss: 2.6145246481420266
Validation loss: 2.4792491940124055

Epoch: 188| Step: 0
Training loss: 2.3788347906896066
Validation loss: 2.480326055611844

Epoch: 5| Step: 1
Training loss: 2.909313105366308
Validation loss: 2.488556240729347

Epoch: 5| Step: 2
Training loss: 1.7227632312036827
Validation loss: 2.4837296820875543

Epoch: 5| Step: 3
Training loss: 2.3635591706095305
Validation loss: 2.469537943878685

Epoch: 5| Step: 4
Training loss: 2.475271183146353
Validation loss: 2.4548255925692306

Epoch: 5| Step: 5
Training loss: 2.2753233543569853
Validation loss: 2.4975393573274913

Epoch: 5| Step: 6
Training loss: 1.826196093067188
Validation loss: 2.4762539904178076

Epoch: 5| Step: 7
Training loss: 2.5280429633449315
Validation loss: 2.472330980450017

Epoch: 5| Step: 8
Training loss: 2.5033163961894935
Validation loss: 2.4582310167408616

Epoch: 5| Step: 9
Training loss: 2.264366800249685
Validation loss: 2.468294497558988

Epoch: 5| Step: 10
Training loss: 2.339525510006034
Validation loss: 2.4467670122697283

Epoch: 189| Step: 0
Training loss: 2.3828141009215935
Validation loss: 2.4830181430401614

Epoch: 5| Step: 1
Training loss: 1.8620070093025027
Validation loss: 2.485312320828068

Epoch: 5| Step: 2
Training loss: 1.802906164578497
Validation loss: 2.46226939567693

Epoch: 5| Step: 3
Training loss: 2.5071397871403107
Validation loss: 2.4813220959766586

Epoch: 5| Step: 4
Training loss: 3.0874514185986848
Validation loss: 2.4858494595501144

Epoch: 5| Step: 5
Training loss: 1.9178924856153967
Validation loss: 2.495695792721169

Epoch: 5| Step: 6
Training loss: 2.4258956513633705
Validation loss: 2.4840009215122048

Epoch: 5| Step: 7
Training loss: 2.4625895450015376
Validation loss: 2.4846965870333233

Epoch: 5| Step: 8
Training loss: 2.246836557709378
Validation loss: 2.4699851420258176

Epoch: 5| Step: 9
Training loss: 2.0665033963016537
Validation loss: 2.4905416396803757

Epoch: 5| Step: 10
Training loss: 2.5288406019437173
Validation loss: 2.4780455677803648

Epoch: 190| Step: 0
Training loss: 2.3434201834995587
Validation loss: 2.455250624013664

Epoch: 5| Step: 1
Training loss: 2.134620096144628
Validation loss: 2.4844246867927953

Epoch: 5| Step: 2
Training loss: 2.492930238833349
Validation loss: 2.4862044296980454

Epoch: 5| Step: 3
Training loss: 2.9106331863271815
Validation loss: 2.44542746581758

Epoch: 5| Step: 4
Training loss: 2.4613162763437826
Validation loss: 2.467584709063855

Epoch: 5| Step: 5
Training loss: 1.894623555559812
Validation loss: 2.4952257304421384

Epoch: 5| Step: 6
Training loss: 2.1066395294678917
Validation loss: 2.4713634989276874

Epoch: 5| Step: 7
Training loss: 2.158854142124987
Validation loss: 2.46543453025745

Epoch: 5| Step: 8
Training loss: 2.3190365760751415
Validation loss: 2.4675441012249393

Epoch: 5| Step: 9
Training loss: 2.603835753714934
Validation loss: 2.4607599093101267

Epoch: 5| Step: 10
Training loss: 2.1066663517328017
Validation loss: 2.4727768077982324

Epoch: 191| Step: 0
Training loss: 2.0317565286408716
Validation loss: 2.4940727942177303

Epoch: 5| Step: 1
Training loss: 2.6789010453639475
Validation loss: 2.4952541229859593

Epoch: 5| Step: 2
Training loss: 1.790089275115775
Validation loss: 2.454155399268719

Epoch: 5| Step: 3
Training loss: 2.132848718356627
Validation loss: 2.496126937202668

Epoch: 5| Step: 4
Training loss: 2.0670722219974245
Validation loss: 2.496137498308553

Epoch: 5| Step: 5
Training loss: 2.9221364276638218
Validation loss: 2.4772829391324915

Epoch: 5| Step: 6
Training loss: 2.463269875328063
Validation loss: 2.4701102577275686

Epoch: 5| Step: 7
Training loss: 2.1745890393547436
Validation loss: 2.4831547329403785

Epoch: 5| Step: 8
Training loss: 2.4566006669798033
Validation loss: 2.4513035775005325

Epoch: 5| Step: 9
Training loss: 2.533987096035565
Validation loss: 2.4659046595250014

Epoch: 5| Step: 10
Training loss: 2.2898491559051037
Validation loss: 2.489578363083498

Epoch: 192| Step: 0
Training loss: 2.1967294267633326
Validation loss: 2.4638636498156385

Epoch: 5| Step: 1
Training loss: 2.5017202181064566
Validation loss: 2.474313102806908

Epoch: 5| Step: 2
Training loss: 2.462024460783362
Validation loss: 2.4427145572545195

Epoch: 5| Step: 3
Training loss: 2.4216014092253815
Validation loss: 2.5034365158747516

Epoch: 5| Step: 4
Training loss: 2.1546644932968837
Validation loss: 2.516574518132586

Epoch: 5| Step: 5
Training loss: 2.6210026050075843
Validation loss: 2.496803564447959

Epoch: 5| Step: 6
Training loss: 1.9742539988768666
Validation loss: 2.498563116672358

Epoch: 5| Step: 7
Training loss: 2.3733295790324718
Validation loss: 2.500178490696558

Epoch: 5| Step: 8
Training loss: 2.6480776562036303
Validation loss: 2.5138075641712434

Epoch: 5| Step: 9
Training loss: 2.1247785116217894
Validation loss: 2.4819267821449627

Epoch: 5| Step: 10
Training loss: 2.331534430203606
Validation loss: 2.490979543560117

Epoch: 193| Step: 0
Training loss: 2.1076042372152175
Validation loss: 2.4631452323185727

Epoch: 5| Step: 1
Training loss: 2.2223250908354273
Validation loss: 2.467121131568167

Epoch: 5| Step: 2
Training loss: 2.1036786057885926
Validation loss: 2.4933987351004547

Epoch: 5| Step: 3
Training loss: 2.018301318119739
Validation loss: 2.473957753378385

Epoch: 5| Step: 4
Training loss: 2.8565836972354797
Validation loss: 2.5168141014703638

Epoch: 5| Step: 5
Training loss: 2.3803520131446807
Validation loss: 2.443009491226807

Epoch: 5| Step: 6
Training loss: 1.900390813186495
Validation loss: 2.414584465450929

Epoch: 5| Step: 7
Training loss: 2.332770608984485
Validation loss: 2.4725651118597014

Epoch: 5| Step: 8
Training loss: 2.1196556203863977
Validation loss: 2.486220575335247

Epoch: 5| Step: 9
Training loss: 2.680377126321339
Validation loss: 2.4556474197177676

Epoch: 5| Step: 10
Training loss: 2.949593344639677
Validation loss: 2.450257526831804

Epoch: 194| Step: 0
Training loss: 2.623689415147258
Validation loss: 2.4732833575368525

Epoch: 5| Step: 1
Training loss: 2.0877796282762024
Validation loss: 2.4279521348528994

Epoch: 5| Step: 2
Training loss: 2.3710993809138246
Validation loss: 2.471336508268494

Epoch: 5| Step: 3
Training loss: 2.298793691994671
Validation loss: 2.489508666641377

Epoch: 5| Step: 4
Training loss: 1.5384424190066788
Validation loss: 2.4692722265103235

Epoch: 5| Step: 5
Training loss: 2.430883377008191
Validation loss: 2.4685161142813525

Epoch: 5| Step: 6
Training loss: 2.2112823325252213
Validation loss: 2.4922559447611836

Epoch: 5| Step: 7
Training loss: 1.9109812322121176
Validation loss: 2.4955735284022365

Epoch: 5| Step: 8
Training loss: 2.467102660060647
Validation loss: 2.4661182037703613

Epoch: 5| Step: 9
Training loss: 2.646030829159922
Validation loss: 2.480074213748801

Epoch: 5| Step: 10
Training loss: 2.9312144458298177
Validation loss: 2.5041966879282844

Epoch: 195| Step: 0
Training loss: 2.0000760540806777
Validation loss: 2.4881500654128024

Epoch: 5| Step: 1
Training loss: 2.3500194873407643
Validation loss: 2.5211133449686054

Epoch: 5| Step: 2
Training loss: 2.120553581908247
Validation loss: 2.4748401842571965

Epoch: 5| Step: 3
Training loss: 2.2352790337458126
Validation loss: 2.5065157570027594

Epoch: 5| Step: 4
Training loss: 2.110825216722251
Validation loss: 2.4868652592551044

Epoch: 5| Step: 5
Training loss: 2.673358170956014
Validation loss: 2.4735474795947563

Epoch: 5| Step: 6
Training loss: 2.317194117962987
Validation loss: 2.455750839170302

Epoch: 5| Step: 7
Training loss: 2.5441797891580986
Validation loss: 2.465174341946938

Epoch: 5| Step: 8
Training loss: 2.370919788395502
Validation loss: 2.488397148262484

Epoch: 5| Step: 9
Training loss: 1.8116839314643836
Validation loss: 2.4900896179990566

Epoch: 5| Step: 10
Training loss: 2.7470543430703622
Validation loss: 2.487808505883301

Epoch: 196| Step: 0
Training loss: 1.9959811124729805
Validation loss: 2.5175550951042345

Epoch: 5| Step: 1
Training loss: 2.172182020263609
Validation loss: 2.4704931794227503

Epoch: 5| Step: 2
Training loss: 2.6250739314249376
Validation loss: 2.515193405125889

Epoch: 5| Step: 3
Training loss: 2.5813236623233458
Validation loss: 2.5050157560771975

Epoch: 5| Step: 4
Training loss: 2.166460051833166
Validation loss: 2.498859133922478

Epoch: 5| Step: 5
Training loss: 1.752098732365429
Validation loss: 2.5157910618728017

Epoch: 5| Step: 6
Training loss: 2.2239934723435804
Validation loss: 2.488947689674875

Epoch: 5| Step: 7
Training loss: 2.362817236375041
Validation loss: 2.4796821280353

Epoch: 5| Step: 8
Training loss: 2.602097923007824
Validation loss: 2.478677343726889

Epoch: 5| Step: 9
Training loss: 2.143219426728957
Validation loss: 2.4787070707575105

Epoch: 5| Step: 10
Training loss: 2.6151067404907504
Validation loss: 2.466508374405178

Epoch: 197| Step: 0
Training loss: 2.4673993242590475
Validation loss: 2.494785115041605

Epoch: 5| Step: 1
Training loss: 1.9972614374085158
Validation loss: 2.4558668164026254

Epoch: 5| Step: 2
Training loss: 2.167725475511744
Validation loss: 2.473850431739194

Epoch: 5| Step: 3
Training loss: 2.49329134133961
Validation loss: 2.4914217519022697

Epoch: 5| Step: 4
Training loss: 2.134279298661453
Validation loss: 2.467723474655359

Epoch: 5| Step: 5
Training loss: 2.503757514047227
Validation loss: 2.4575281536573628

Epoch: 5| Step: 6
Training loss: 2.340795154778504
Validation loss: 2.4703685397275104

Epoch: 5| Step: 7
Training loss: 2.6969193685866766
Validation loss: 2.4657590148448048

Epoch: 5| Step: 8
Training loss: 2.0258237693787873
Validation loss: 2.4485884150349855

Epoch: 5| Step: 9
Training loss: 2.3319207297866162
Validation loss: 2.451646137363101

Epoch: 5| Step: 10
Training loss: 2.3453625027525336
Validation loss: 2.453403125069119

Epoch: 198| Step: 0
Training loss: 2.433203211227222
Validation loss: 2.476130567332417

Epoch: 5| Step: 1
Training loss: 2.495916464752664
Validation loss: 2.452394250574672

Epoch: 5| Step: 2
Training loss: 2.084951217592976
Validation loss: 2.5016649752122806

Epoch: 5| Step: 3
Training loss: 2.3863580059629133
Validation loss: 2.493082058840965

Epoch: 5| Step: 4
Training loss: 2.518822764062659
Validation loss: 2.475013843662148

Epoch: 5| Step: 5
Training loss: 2.687474716422447
Validation loss: 2.476193257499543

Epoch: 5| Step: 6
Training loss: 2.2848109840329394
Validation loss: 2.5200952052486065

Epoch: 5| Step: 7
Training loss: 2.080988352598621
Validation loss: 2.4616017132956247

Epoch: 5| Step: 8
Training loss: 2.1644878313758364
Validation loss: 2.505007861534029

Epoch: 5| Step: 9
Training loss: 1.4630694006353353
Validation loss: 2.4891302470756282

Epoch: 5| Step: 10
Training loss: 2.5780616521277437
Validation loss: 2.482095486397863

Epoch: 199| Step: 0
Training loss: 2.5170747358754895
Validation loss: 2.474387483966089

Epoch: 5| Step: 1
Training loss: 2.5546312238461844
Validation loss: 2.4905261026133236

Epoch: 5| Step: 2
Training loss: 2.0010731917172895
Validation loss: 2.5120926407126047

Epoch: 5| Step: 3
Training loss: 2.3196543778104353
Validation loss: 2.456904991408167

Epoch: 5| Step: 4
Training loss: 2.4383390889737595
Validation loss: 2.4897390893450138

Epoch: 5| Step: 5
Training loss: 2.827548310721302
Validation loss: 2.448014105587947

Epoch: 5| Step: 6
Training loss: 2.1308816406876927
Validation loss: 2.5080040226139797

Epoch: 5| Step: 7
Training loss: 1.9761688684824061
Validation loss: 2.5006499963151145

Epoch: 5| Step: 8
Training loss: 1.9746256751228188
Validation loss: 2.4827576362735564

Epoch: 5| Step: 9
Training loss: 2.406901283804142
Validation loss: 2.4778495392678317

Epoch: 5| Step: 10
Training loss: 2.162874632561485
Validation loss: 2.5014368481211697

Epoch: 200| Step: 0
Training loss: 1.8021063242715432
Validation loss: 2.494467220154762

Epoch: 5| Step: 1
Training loss: 2.4604819224266574
Validation loss: 2.4739213910715163

Epoch: 5| Step: 2
Training loss: 2.6469212695764917
Validation loss: 2.4899974953387245

Epoch: 5| Step: 3
Training loss: 1.950384185309755
Validation loss: 2.468736629052673

Epoch: 5| Step: 4
Training loss: 2.1570319264489273
Validation loss: 2.4758049610600152

Epoch: 5| Step: 5
Training loss: 2.3486748388261742
Validation loss: 2.4706286407012468

Epoch: 5| Step: 6
Training loss: 2.2425740935504175
Validation loss: 2.480664726553118

Epoch: 5| Step: 7
Training loss: 2.6390337240616346
Validation loss: 2.463623847484775

Epoch: 5| Step: 8
Training loss: 2.3411658727844085
Validation loss: 2.505674141373278

Epoch: 5| Step: 9
Training loss: 2.509410123472376
Validation loss: 2.4605113879238036

Epoch: 5| Step: 10
Training loss: 2.548609605096366
Validation loss: 2.4822299793679137

Epoch: 201| Step: 0
Training loss: 2.205810425277563
Validation loss: 2.4916536593477514

Epoch: 5| Step: 1
Training loss: 2.5991096732823724
Validation loss: 2.490985179286944

Epoch: 5| Step: 2
Training loss: 2.6682563950619174
Validation loss: 2.458692435442435

Epoch: 5| Step: 3
Training loss: 2.0554537776574255
Validation loss: 2.4677894170028116

Epoch: 5| Step: 4
Training loss: 2.266327952808012
Validation loss: 2.444275975326121

Epoch: 5| Step: 5
Training loss: 1.5698257375089855
Validation loss: 2.4745562588067878

Epoch: 5| Step: 6
Training loss: 2.4316519005448916
Validation loss: 2.483858060543563

Epoch: 5| Step: 7
Training loss: 2.4417392351044644
Validation loss: 2.4563721421730587

Epoch: 5| Step: 8
Training loss: 1.862726476839998
Validation loss: 2.4802242810674717

Epoch: 5| Step: 9
Training loss: 2.3810278040429282
Validation loss: 2.4894081964073074

Epoch: 5| Step: 10
Training loss: 2.7315931720013173
Validation loss: 2.5006294473282096

Epoch: 202| Step: 0
Training loss: 1.8482834636517924
Validation loss: 2.484096680484375

Epoch: 5| Step: 1
Training loss: 2.3879834709170513
Validation loss: 2.509166027312082

Epoch: 5| Step: 2
Training loss: 2.7883853891837265
Validation loss: 2.484012802570766

Epoch: 5| Step: 3
Training loss: 2.267023536226775
Validation loss: 2.495131709620034

Epoch: 5| Step: 4
Training loss: 1.9733843073619077
Validation loss: 2.4738517747780935

Epoch: 5| Step: 5
Training loss: 2.094467950965025
Validation loss: 2.492308289776122

Epoch: 5| Step: 6
Training loss: 2.1632470753327153
Validation loss: 2.4837321716894456

Epoch: 5| Step: 7
Training loss: 2.31678200258541
Validation loss: 2.471957271761393

Epoch: 5| Step: 8
Training loss: 1.9923175245749956
Validation loss: 2.4727306804798834

Epoch: 5| Step: 9
Training loss: 2.746691881483812
Validation loss: 2.4962622172450293

Epoch: 5| Step: 10
Training loss: 2.6313993470492316
Validation loss: 2.4820306445669384

Epoch: 203| Step: 0
Training loss: 2.385197880691183
Validation loss: 2.459603480157864

Epoch: 5| Step: 1
Training loss: 2.333684645045678
Validation loss: 2.4772662504090066

Epoch: 5| Step: 2
Training loss: 2.242778421084335
Validation loss: 2.514039561327377

Epoch: 5| Step: 3
Training loss: 2.633065050277049
Validation loss: 2.4959144207551884

Epoch: 5| Step: 4
Training loss: 1.871376924051691
Validation loss: 2.488304465319797

Epoch: 5| Step: 5
Training loss: 2.2209700102793057
Validation loss: 2.475919279809919

Epoch: 5| Step: 6
Training loss: 2.369037572470177
Validation loss: 2.456821089843786

Epoch: 5| Step: 7
Training loss: 2.444479315923242
Validation loss: 2.4751514149018057

Epoch: 5| Step: 8
Training loss: 2.211521246852664
Validation loss: 2.4432334329387015

Epoch: 5| Step: 9
Training loss: 2.302613854591015
Validation loss: 2.4789825661327454

Epoch: 5| Step: 10
Training loss: 2.218874645761566
Validation loss: 2.4840548698544

Epoch: 204| Step: 0
Training loss: 1.6206808644474044
Validation loss: 2.458662301674047

Epoch: 5| Step: 1
Training loss: 2.028995495207906
Validation loss: 2.4797883226804966

Epoch: 5| Step: 2
Training loss: 2.381645442137524
Validation loss: 2.4736039987036658

Epoch: 5| Step: 3
Training loss: 2.4743020123467594
Validation loss: 2.4763256128047875

Epoch: 5| Step: 4
Training loss: 2.137413344383471
Validation loss: 2.465382046198557

Epoch: 5| Step: 5
Training loss: 2.1034074930859723
Validation loss: 2.4922189226103786

Epoch: 5| Step: 6
Training loss: 2.7090277637398135
Validation loss: 2.475100571432882

Epoch: 5| Step: 7
Training loss: 2.571291566029687
Validation loss: 2.4736394930409187

Epoch: 5| Step: 8
Training loss: 2.6812278835567134
Validation loss: 2.542431168857021

Epoch: 5| Step: 9
Training loss: 2.1365859637242077
Validation loss: 2.502298793327605

Epoch: 5| Step: 10
Training loss: 2.1357984496190223
Validation loss: 2.4491343904269707

Epoch: 205| Step: 0
Training loss: 2.3946392787940343
Validation loss: 2.4794224649937306

Epoch: 5| Step: 1
Training loss: 2.6011480511068292
Validation loss: 2.473971132375945

Epoch: 5| Step: 2
Training loss: 2.237728669826162
Validation loss: 2.4799185178359835

Epoch: 5| Step: 3
Training loss: 2.2143358189763496
Validation loss: 2.469863042552907

Epoch: 5| Step: 4
Training loss: 2.7489446869270884
Validation loss: 2.48667308588422

Epoch: 5| Step: 5
Training loss: 2.431932007516775
Validation loss: 2.50121815649293

Epoch: 5| Step: 6
Training loss: 2.417613260639766
Validation loss: 2.4676234534681725

Epoch: 5| Step: 7
Training loss: 1.8824091435730366
Validation loss: 2.4814607380260685

Epoch: 5| Step: 8
Training loss: 1.9906215122737303
Validation loss: 2.5084289717198884

Epoch: 5| Step: 9
Training loss: 1.92618517866242
Validation loss: 2.511636010935337

Epoch: 5| Step: 10
Training loss: 2.2475741342574564
Validation loss: 2.49535504463966

Epoch: 206| Step: 0
Training loss: 2.3301876071172454
Validation loss: 2.4676514145548025

Epoch: 5| Step: 1
Training loss: 2.4998471213327025
Validation loss: 2.498435584623985

Epoch: 5| Step: 2
Training loss: 2.139214043721085
Validation loss: 2.5302001531158314

Epoch: 5| Step: 3
Training loss: 2.563827821916548
Validation loss: 2.505196715846403

Epoch: 5| Step: 4
Training loss: 2.3588358281970336
Validation loss: 2.5096646571687002

Epoch: 5| Step: 5
Training loss: 2.600838591979664
Validation loss: 2.44899877867592

Epoch: 5| Step: 6
Training loss: 1.999401956789693
Validation loss: 2.490631745346894

Epoch: 5| Step: 7
Training loss: 2.0974768876267547
Validation loss: 2.4692551280538018

Epoch: 5| Step: 8
Training loss: 2.27274996399389
Validation loss: 2.4473812365120797

Epoch: 5| Step: 9
Training loss: 2.2668260219132494
Validation loss: 2.4919180518501456

Epoch: 5| Step: 10
Training loss: 2.334182743596861
Validation loss: 2.4969521884388364

Epoch: 207| Step: 0
Training loss: 2.7324904568881596
Validation loss: 2.476935659808672

Epoch: 5| Step: 1
Training loss: 2.4429106692932865
Validation loss: 2.4453149112953065

Epoch: 5| Step: 2
Training loss: 2.380533097451906
Validation loss: 2.4836589111167577

Epoch: 5| Step: 3
Training loss: 1.8780063052127443
Validation loss: 2.4831279447819568

Epoch: 5| Step: 4
Training loss: 2.6924242549857276
Validation loss: 2.4434621300153085

Epoch: 5| Step: 5
Training loss: 2.097145856711862
Validation loss: 2.5029364711379922

Epoch: 5| Step: 6
Training loss: 1.9770769497681584
Validation loss: 2.4801393227661204

Epoch: 5| Step: 7
Training loss: 1.856299670033322
Validation loss: 2.481450062799473

Epoch: 5| Step: 8
Training loss: 2.2542637586102896
Validation loss: 2.461744962966989

Epoch: 5| Step: 9
Training loss: 2.2938785859947246
Validation loss: 2.4495729598270186

Epoch: 5| Step: 10
Training loss: 2.52163499637877
Validation loss: 2.4805963112817686

Epoch: 208| Step: 0
Training loss: 2.527412897074996
Validation loss: 2.4602604088387343

Epoch: 5| Step: 1
Training loss: 2.1397833735906016
Validation loss: 2.4778705927260183

Epoch: 5| Step: 2
Training loss: 2.307298532537459
Validation loss: 2.455180122249296

Epoch: 5| Step: 3
Training loss: 2.4823158415592204
Validation loss: 2.483606043687521

Epoch: 5| Step: 4
Training loss: 2.8468212269165165
Validation loss: 2.4774390247126616

Epoch: 5| Step: 5
Training loss: 2.2945865986804668
Validation loss: 2.499716464750935

Epoch: 5| Step: 6
Training loss: 2.2127651034223184
Validation loss: 2.5006201354362485

Epoch: 5| Step: 7
Training loss: 2.309400491741548
Validation loss: 2.4792906286474308

Epoch: 5| Step: 8
Training loss: 1.90511519626938
Validation loss: 2.4823820355354096

Epoch: 5| Step: 9
Training loss: 2.09906583625877
Validation loss: 2.4625570488957216

Epoch: 5| Step: 10
Training loss: 1.6253134351836573
Validation loss: 2.4716618723880877

Epoch: 209| Step: 0
Training loss: 1.9463257506224416
Validation loss: 2.491677493499446

Epoch: 5| Step: 1
Training loss: 1.8638986008655276
Validation loss: 2.5139088948753674

Epoch: 5| Step: 2
Training loss: 2.2454048493466567
Validation loss: 2.4667258203644984

Epoch: 5| Step: 3
Training loss: 2.4273115604698496
Validation loss: 2.497753641505944

Epoch: 5| Step: 4
Training loss: 2.6514425418044105
Validation loss: 2.4668645724358362

Epoch: 5| Step: 5
Training loss: 1.6501312955001235
Validation loss: 2.4752463930029034

Epoch: 5| Step: 6
Training loss: 2.3710212507900468
Validation loss: 2.4841941736215314

Epoch: 5| Step: 7
Training loss: 2.4851114393149873
Validation loss: 2.4945211589916116

Epoch: 5| Step: 8
Training loss: 2.901689786897415
Validation loss: 2.4556789549433944

Epoch: 5| Step: 9
Training loss: 1.6723165909312612
Validation loss: 2.4979788136672925

Epoch: 5| Step: 10
Training loss: 2.61358823241897
Validation loss: 2.478138399576077

Epoch: 210| Step: 0
Training loss: 2.2572183322187067
Validation loss: 2.502080722125876

Epoch: 5| Step: 1
Training loss: 1.923279411952837
Validation loss: 2.4697793933114016

Epoch: 5| Step: 2
Training loss: 1.6476920372235915
Validation loss: 2.496135725631643

Epoch: 5| Step: 3
Training loss: 2.2075744500571584
Validation loss: 2.4588754374975355

Epoch: 5| Step: 4
Training loss: 2.2850001616029245
Validation loss: 2.4781070073956277

Epoch: 5| Step: 5
Training loss: 2.642460202266582
Validation loss: 2.4885456752642225

Epoch: 5| Step: 6
Training loss: 2.3009743989915346
Validation loss: 2.5207416785905594

Epoch: 5| Step: 7
Training loss: 2.5222143273456417
Validation loss: 2.4896549010848514

Epoch: 5| Step: 8
Training loss: 2.3313128260924203
Validation loss: 2.4745997217390547

Epoch: 5| Step: 9
Training loss: 2.3761326949830646
Validation loss: 2.47451505570211

Epoch: 5| Step: 10
Training loss: 2.342396256175984
Validation loss: 2.4905248344450985

Epoch: 211| Step: 0
Training loss: 2.599899906285832
Validation loss: 2.4748772281306657

Epoch: 5| Step: 1
Training loss: 2.2749183262846753
Validation loss: 2.4964158453444423

Epoch: 5| Step: 2
Training loss: 2.433773517857478
Validation loss: 2.5055507626881894

Epoch: 5| Step: 3
Training loss: 2.0509864341179322
Validation loss: 2.4807693042266297

Epoch: 5| Step: 4
Training loss: 1.90179504376892
Validation loss: 2.4891882739280424

Epoch: 5| Step: 5
Training loss: 2.8255299839041537
Validation loss: 2.485893445379895

Epoch: 5| Step: 6
Training loss: 2.9111585286414474
Validation loss: 2.4720628389836152

Epoch: 5| Step: 7
Training loss: 1.7743130845691704
Validation loss: 2.5232832747939242

Epoch: 5| Step: 8
Training loss: 2.4943874299751174
Validation loss: 2.488120794310458

Epoch: 5| Step: 9
Training loss: 2.014754587946656
Validation loss: 2.453004542901375

Epoch: 5| Step: 10
Training loss: 1.3139968238774762
Validation loss: 2.4772966515049015

Epoch: 212| Step: 0
Training loss: 2.704256559581406
Validation loss: 2.461323124676884

Epoch: 5| Step: 1
Training loss: 2.435993413668844
Validation loss: 2.5060572512470567

Epoch: 5| Step: 2
Training loss: 2.364851097597088
Validation loss: 2.4935447784220695

Epoch: 5| Step: 3
Training loss: 2.0994927520299793
Validation loss: 2.490052348462714

Epoch: 5| Step: 4
Training loss: 1.953266108183901
Validation loss: 2.4588940312796894

Epoch: 5| Step: 5
Training loss: 2.9870966938358716
Validation loss: 2.470649427798082

Epoch: 5| Step: 6
Training loss: 2.361615361491177
Validation loss: 2.512682944693959

Epoch: 5| Step: 7
Training loss: 1.721598951639686
Validation loss: 2.458830487172969

Epoch: 5| Step: 8
Training loss: 1.7759956361356166
Validation loss: 2.5095799809614703

Epoch: 5| Step: 9
Training loss: 2.2373169424519777
Validation loss: 2.4670364354104946

Epoch: 5| Step: 10
Training loss: 2.0422559264086897
Validation loss: 2.469296538320332

Epoch: 213| Step: 0
Training loss: 2.4714706495279835
Validation loss: 2.4923802016897416

Epoch: 5| Step: 1
Training loss: 2.4681267253360626
Validation loss: 2.4930482511352157

Epoch: 5| Step: 2
Training loss: 2.396053956419336
Validation loss: 2.459072263387119

Epoch: 5| Step: 3
Training loss: 2.1383745378710177
Validation loss: 2.498672507195666

Epoch: 5| Step: 4
Training loss: 2.195876514027134
Validation loss: 2.490119928428064

Epoch: 5| Step: 5
Training loss: 2.287295965048265
Validation loss: 2.509428070556989

Epoch: 5| Step: 6
Training loss: 2.2447979448294118
Validation loss: 2.458701333696352

Epoch: 5| Step: 7
Training loss: 2.494826781809537
Validation loss: 2.5149928339204517

Epoch: 5| Step: 8
Training loss: 2.1782278553828616
Validation loss: 2.4950641020310003

Epoch: 5| Step: 9
Training loss: 2.0682566673994867
Validation loss: 2.4947905315141656

Epoch: 5| Step: 10
Training loss: 2.0164008015230537
Validation loss: 2.5193342061381134

Epoch: 214| Step: 0
Training loss: 2.9927697474260193
Validation loss: 2.4797288063106944

Epoch: 5| Step: 1
Training loss: 2.3100566843847794
Validation loss: 2.4835132619446707

Epoch: 5| Step: 2
Training loss: 1.8305658201561146
Validation loss: 2.498771925746309

Epoch: 5| Step: 3
Training loss: 2.4469607712095884
Validation loss: 2.488228036203916

Epoch: 5| Step: 4
Training loss: 1.7306138229698012
Validation loss: 2.4878852054998166

Epoch: 5| Step: 5
Training loss: 2.5260818845293618
Validation loss: 2.4772109221891596

Epoch: 5| Step: 6
Training loss: 2.7660598844002156
Validation loss: 2.4826093226816224

Epoch: 5| Step: 7
Training loss: 1.8485115120291704
Validation loss: 2.4435512596924918

Epoch: 5| Step: 8
Training loss: 2.165388231421687
Validation loss: 2.4895086604627106

Epoch: 5| Step: 9
Training loss: 2.1154991258958864
Validation loss: 2.4625858030002425

Epoch: 5| Step: 10
Training loss: 1.9899449910175913
Validation loss: 2.4816801263361876

Epoch: 215| Step: 0
Training loss: 1.8601946266442047
Validation loss: 2.48081305719613

Epoch: 5| Step: 1
Training loss: 2.540876005003537
Validation loss: 2.465242659011347

Epoch: 5| Step: 2
Training loss: 2.859263933870092
Validation loss: 2.492718915395485

Epoch: 5| Step: 3
Training loss: 1.8524825630963244
Validation loss: 2.484016718188631

Epoch: 5| Step: 4
Training loss: 2.5296832286664355
Validation loss: 2.484832896898189

Epoch: 5| Step: 5
Training loss: 2.3785588554203847
Validation loss: 2.467841483160614

Epoch: 5| Step: 6
Training loss: 2.4405389084327704
Validation loss: 2.513290177289445

Epoch: 5| Step: 7
Training loss: 2.329393386952487
Validation loss: 2.46776057861029

Epoch: 5| Step: 8
Training loss: 1.7024482992559287
Validation loss: 2.4690856684625895

Epoch: 5| Step: 9
Training loss: 1.9255587002373344
Validation loss: 2.515465666822341

Epoch: 5| Step: 10
Training loss: 2.2591360891822787
Validation loss: 2.454657128489764

Epoch: 216| Step: 0
Training loss: 1.6395005505355278
Validation loss: 2.4837810776166145

Epoch: 5| Step: 1
Training loss: 2.3694338573812086
Validation loss: 2.490879796495356

Epoch: 5| Step: 2
Training loss: 2.3723706196276666
Validation loss: 2.4776505142586918

Epoch: 5| Step: 3
Training loss: 2.77707770638684
Validation loss: 2.513287422686975

Epoch: 5| Step: 4
Training loss: 1.889435385982957
Validation loss: 2.5028054216828464

Epoch: 5| Step: 5
Training loss: 1.8635631164146504
Validation loss: 2.4728520816450104

Epoch: 5| Step: 6
Training loss: 2.153151898707444
Validation loss: 2.4711033518466547

Epoch: 5| Step: 7
Training loss: 2.249828120130379
Validation loss: 2.4837929855304717

Epoch: 5| Step: 8
Training loss: 2.253108208920454
Validation loss: 2.4833538732472773

Epoch: 5| Step: 9
Training loss: 2.895951431025205
Validation loss: 2.4919556658966577

Epoch: 5| Step: 10
Training loss: 1.9335289530059867
Validation loss: 2.484484008122908

Epoch: 217| Step: 0
Training loss: 2.303075401155108
Validation loss: 2.480224745168459

Epoch: 5| Step: 1
Training loss: 2.5306974208170323
Validation loss: 2.49245347437237

Epoch: 5| Step: 2
Training loss: 2.4747745064403444
Validation loss: 2.479804864687979

Epoch: 5| Step: 3
Training loss: 2.052872585068275
Validation loss: 2.4730317666993686

Epoch: 5| Step: 4
Training loss: 1.6030718134632906
Validation loss: 2.4823868460062957

Epoch: 5| Step: 5
Training loss: 2.251455472034415
Validation loss: 2.451699429933733

Epoch: 5| Step: 6
Training loss: 1.9892645841847494
Validation loss: 2.483657409260671

Epoch: 5| Step: 7
Training loss: 2.3786644021858816
Validation loss: 2.5028080049832857

Epoch: 5| Step: 8
Training loss: 2.317297829839258
Validation loss: 2.476802796801592

Epoch: 5| Step: 9
Training loss: 1.8855697892817638
Validation loss: 2.4830342304124073

Epoch: 5| Step: 10
Training loss: 2.939339406801546
Validation loss: 2.450421438997397

Epoch: 218| Step: 0
Training loss: 2.468250755338535
Validation loss: 2.4690925336631504

Epoch: 5| Step: 1
Training loss: 2.599590482005445
Validation loss: 2.4933986816355547

Epoch: 5| Step: 2
Training loss: 2.4561800065878647
Validation loss: 2.4594936111200743

Epoch: 5| Step: 3
Training loss: 1.9860959137673768
Validation loss: 2.483568839433683

Epoch: 5| Step: 4
Training loss: 2.109607598937912
Validation loss: 2.4852551782838135

Epoch: 5| Step: 5
Training loss: 1.8563879045322145
Validation loss: 2.4945725284728013

Epoch: 5| Step: 6
Training loss: 2.2546637202731836
Validation loss: 2.522626863394063

Epoch: 5| Step: 7
Training loss: 2.6949202542369926
Validation loss: 2.4886584028369962

Epoch: 5| Step: 8
Training loss: 2.359809885934438
Validation loss: 2.5157577030229663

Epoch: 5| Step: 9
Training loss: 2.2111462605726766
Validation loss: 2.4971651760772358

Epoch: 5| Step: 10
Training loss: 1.8575715366722705
Validation loss: 2.491462257646904

Epoch: 219| Step: 0
Training loss: 1.7457443672885786
Validation loss: 2.474906238417731

Epoch: 5| Step: 1
Training loss: 2.1605995647686695
Validation loss: 2.534267551715815

Epoch: 5| Step: 2
Training loss: 1.7506363256783364
Validation loss: 2.472482479959137

Epoch: 5| Step: 3
Training loss: 2.5310177166641625
Validation loss: 2.4664228443820506

Epoch: 5| Step: 4
Training loss: 2.292753297213803
Validation loss: 2.482125120332823

Epoch: 5| Step: 5
Training loss: 2.746358801692353
Validation loss: 2.4825541822138897

Epoch: 5| Step: 6
Training loss: 1.821585803364688
Validation loss: 2.484243326379705

Epoch: 5| Step: 7
Training loss: 2.4410234074827932
Validation loss: 2.500844296047221

Epoch: 5| Step: 8
Training loss: 2.464291276392376
Validation loss: 2.5132062572072758

Epoch: 5| Step: 9
Training loss: 2.2916740648554823
Validation loss: 2.515271629197226

Epoch: 5| Step: 10
Training loss: 2.6103286371105616
Validation loss: 2.4537463274266558

Epoch: 220| Step: 0
Training loss: 1.4344737498878923
Validation loss: 2.481017811334053

Epoch: 5| Step: 1
Training loss: 1.8347612874315011
Validation loss: 2.4613577285179105

Epoch: 5| Step: 2
Training loss: 2.615058328915275
Validation loss: 2.4525931075431036

Epoch: 5| Step: 3
Training loss: 2.77044593760766
Validation loss: 2.478714984942715

Epoch: 5| Step: 4
Training loss: 2.4345624780509723
Validation loss: 2.455891485350801

Epoch: 5| Step: 5
Training loss: 1.724999250881751
Validation loss: 2.4798219048769123

Epoch: 5| Step: 6
Training loss: 2.2480706313905494
Validation loss: 2.487051644300248

Epoch: 5| Step: 7
Training loss: 3.1771309437337285
Validation loss: 2.467054090641653

Epoch: 5| Step: 8
Training loss: 1.9081345294973078
Validation loss: 2.479010288445597

Epoch: 5| Step: 9
Training loss: 1.5481406534548592
Validation loss: 2.493457753482113

Epoch: 5| Step: 10
Training loss: 2.640481888544068
Validation loss: 2.471801489805247

Epoch: 221| Step: 0
Training loss: 1.972671599375617
Validation loss: 2.4560007712806673

Epoch: 5| Step: 1
Training loss: 2.2563199188304037
Validation loss: 2.4638630130319137

Epoch: 5| Step: 2
Training loss: 2.6480646911913106
Validation loss: 2.531222109461823

Epoch: 5| Step: 3
Training loss: 1.9710134785470483
Validation loss: 2.475409730159186

Epoch: 5| Step: 4
Training loss: 1.7989882274706872
Validation loss: 2.4868885011945134

Epoch: 5| Step: 5
Training loss: 2.0462928701301433
Validation loss: 2.4986396759721248

Epoch: 5| Step: 6
Training loss: 2.350461277431586
Validation loss: 2.5248512674447157

Epoch: 5| Step: 7
Training loss: 2.1554779660897916
Validation loss: 2.48677299034453

Epoch: 5| Step: 8
Training loss: 2.854400309631519
Validation loss: 2.4758585133125353

Epoch: 5| Step: 9
Training loss: 1.8097643102340155
Validation loss: 2.498095599203011

Epoch: 5| Step: 10
Training loss: 2.8078915456982245
Validation loss: 2.5031088285768863

Epoch: 222| Step: 0
Training loss: 2.420059015484485
Validation loss: 2.4974359489453533

Epoch: 5| Step: 1
Training loss: 2.207830719761273
Validation loss: 2.4702425923309272

Epoch: 5| Step: 2
Training loss: 2.2467795743030448
Validation loss: 2.5024349260463894

Epoch: 5| Step: 3
Training loss: 2.9985088775233644
Validation loss: 2.4747550426737694

Epoch: 5| Step: 4
Training loss: 2.606822427143148
Validation loss: 2.4719778910864596

Epoch: 5| Step: 5
Training loss: 1.6157779171146334
Validation loss: 2.5080832078847393

Epoch: 5| Step: 6
Training loss: 1.5957593032491617
Validation loss: 2.478613630369084

Epoch: 5| Step: 7
Training loss: 2.3057178327857617
Validation loss: 2.488573046896481

Epoch: 5| Step: 8
Training loss: 1.7403252060944039
Validation loss: 2.4834633545892015

Epoch: 5| Step: 9
Training loss: 2.2690179083408712
Validation loss: 2.4995683420441512

Epoch: 5| Step: 10
Training loss: 2.1014338457512403
Validation loss: 2.497422142873552

Epoch: 223| Step: 0
Training loss: 2.350615047564607
Validation loss: 2.4998608611980524

Epoch: 5| Step: 1
Training loss: 1.955923471225272
Validation loss: 2.471594818748547

Epoch: 5| Step: 2
Training loss: 2.1803138407259812
Validation loss: 2.479232712925236

Epoch: 5| Step: 3
Training loss: 1.9133337385174969
Validation loss: 2.475687942074847

Epoch: 5| Step: 4
Training loss: 2.6478656162610186
Validation loss: 2.5023781714284645

Epoch: 5| Step: 5
Training loss: 2.384601759220886
Validation loss: 2.504544163403828

Epoch: 5| Step: 6
Training loss: 2.5577000578701665
Validation loss: 2.5092317050521737

Epoch: 5| Step: 7
Training loss: 2.206970754148765
Validation loss: 2.461075093501401

Epoch: 5| Step: 8
Training loss: 2.3548344253032445
Validation loss: 2.5104804371515033

Epoch: 5| Step: 9
Training loss: 1.8629466142197584
Validation loss: 2.5439448942870193

Epoch: 5| Step: 10
Training loss: 2.2652755994050184
Validation loss: 2.5413634631941435

Epoch: 224| Step: 0
Training loss: 2.1996746776373466
Validation loss: 2.502019336353282

Epoch: 5| Step: 1
Training loss: 2.2153385423745786
Validation loss: 2.474642802673279

Epoch: 5| Step: 2
Training loss: 1.8167821351665026
Validation loss: 2.5126452450580725

Epoch: 5| Step: 3
Training loss: 1.6927447584096702
Validation loss: 2.4438687629292684

Epoch: 5| Step: 4
Training loss: 2.452042456204878
Validation loss: 2.493039018899846

Epoch: 5| Step: 5
Training loss: 2.5396153244327673
Validation loss: 2.4947073964596784

Epoch: 5| Step: 6
Training loss: 2.302393298332741
Validation loss: 2.506852354205917

Epoch: 5| Step: 7
Training loss: 2.709166550234891
Validation loss: 2.4953977770105964

Epoch: 5| Step: 8
Training loss: 1.9255822873973292
Validation loss: 2.5200217749258265

Epoch: 5| Step: 9
Training loss: 2.311735387641052
Validation loss: 2.4852747681866343

Epoch: 5| Step: 10
Training loss: 2.365738529116642
Validation loss: 2.47914664313059

Epoch: 225| Step: 0
Training loss: 2.030301151205752
Validation loss: 2.480223351314787

Epoch: 5| Step: 1
Training loss: 2.5626155548092826
Validation loss: 2.4690782643659976

Epoch: 5| Step: 2
Training loss: 1.9577774787565347
Validation loss: 2.4888855947565123

Epoch: 5| Step: 3
Training loss: 2.0337038916746093
Validation loss: 2.492812549008401

Epoch: 5| Step: 4
Training loss: 2.9468527088151473
Validation loss: 2.448781833039022

Epoch: 5| Step: 5
Training loss: 1.715417648598062
Validation loss: 2.489749857740747

Epoch: 5| Step: 6
Training loss: 1.8771509548571652
Validation loss: 2.468526308520868

Epoch: 5| Step: 7
Training loss: 2.2922607576590224
Validation loss: 2.47457720353302

Epoch: 5| Step: 8
Training loss: 2.2375693795300404
Validation loss: 2.490635181192661

Epoch: 5| Step: 9
Training loss: 2.3597991764163186
Validation loss: 2.479501597349835

Epoch: 5| Step: 10
Training loss: 2.4628412542756806
Validation loss: 2.4932098621609446

Epoch: 226| Step: 0
Training loss: 1.9658791333801084
Validation loss: 2.463872300485422

Epoch: 5| Step: 1
Training loss: 2.863147685642465
Validation loss: 2.5083560103544

Epoch: 5| Step: 2
Training loss: 1.733245894476313
Validation loss: 2.4944293346288915

Epoch: 5| Step: 3
Training loss: 2.106802155427281
Validation loss: 2.4506474755865257

Epoch: 5| Step: 4
Training loss: 2.4593933104787125
Validation loss: 2.4943091383393945

Epoch: 5| Step: 5
Training loss: 2.3541203272036912
Validation loss: 2.476290632160559

Epoch: 5| Step: 6
Training loss: 2.2593960076459494
Validation loss: 2.4515644411009956

Epoch: 5| Step: 7
Training loss: 2.3114511327873486
Validation loss: 2.475892433557911

Epoch: 5| Step: 8
Training loss: 2.281411570222826
Validation loss: 2.482113836519056

Epoch: 5| Step: 9
Training loss: 1.566211640785593
Validation loss: 2.476154019776094

Epoch: 5| Step: 10
Training loss: 2.3817296303536413
Validation loss: 2.4865200909910574

Epoch: 227| Step: 0
Training loss: 1.8822346033912376
Validation loss: 2.489076135798855

Epoch: 5| Step: 1
Training loss: 1.9100094604257896
Validation loss: 2.5070029609350155

Epoch: 5| Step: 2
Training loss: 1.9253827470032772
Validation loss: 2.4863852408234615

Epoch: 5| Step: 3
Training loss: 1.977942426069254
Validation loss: 2.5317604687588977

Epoch: 5| Step: 4
Training loss: 2.976483521702793
Validation loss: 2.484612596268831

Epoch: 5| Step: 5
Training loss: 2.0916239634051745
Validation loss: 2.5005123064712644

Epoch: 5| Step: 6
Training loss: 2.24428967544485
Validation loss: 2.5062100784296915

Epoch: 5| Step: 7
Training loss: 2.1524723519954296
Validation loss: 2.4797883216466823

Epoch: 5| Step: 8
Training loss: 2.137347754694942
Validation loss: 2.469579951493872

Epoch: 5| Step: 9
Training loss: 2.323353736255147
Validation loss: 2.4993814338918607

Epoch: 5| Step: 10
Training loss: 2.751952605183148
Validation loss: 2.4566260454857276

Epoch: 228| Step: 0
Training loss: 1.9810970596344801
Validation loss: 2.5038496515980513

Epoch: 5| Step: 1
Training loss: 2.897445796956566
Validation loss: 2.4706392091143203

Epoch: 5| Step: 2
Training loss: 2.3090439823764353
Validation loss: 2.4933017005885745

Epoch: 5| Step: 3
Training loss: 2.341010361692106
Validation loss: 2.49772292232173

Epoch: 5| Step: 4
Training loss: 2.320835966408935
Validation loss: 2.5018993761057207

Epoch: 5| Step: 5
Training loss: 2.151597130634574
Validation loss: 2.4801087037806675

Epoch: 5| Step: 6
Training loss: 2.3896605098093606
Validation loss: 2.493871420769075

Epoch: 5| Step: 7
Training loss: 1.855923052935646
Validation loss: 2.502136192519239

Epoch: 5| Step: 8
Training loss: 2.230641159636113
Validation loss: 2.485978297267638

Epoch: 5| Step: 9
Training loss: 2.2788320817670766
Validation loss: 2.4898956713198372

Epoch: 5| Step: 10
Training loss: 1.4506005950676162
Validation loss: 2.4815847555231834

Epoch: 229| Step: 0
Training loss: 1.9699128970142614
Validation loss: 2.475245093702749

Epoch: 5| Step: 1
Training loss: 2.107210532295478
Validation loss: 2.474586861025757

Epoch: 5| Step: 2
Training loss: 2.140787048888839
Validation loss: 2.5017421036207392

Epoch: 5| Step: 3
Training loss: 2.2134731027792713
Validation loss: 2.512779825572379

Epoch: 5| Step: 4
Training loss: 2.626292137741198
Validation loss: 2.4369726459852235

Epoch: 5| Step: 5
Training loss: 2.0546562859662667
Validation loss: 2.5065980647210675

Epoch: 5| Step: 6
Training loss: 2.3114786727947885
Validation loss: 2.479305902136851

Epoch: 5| Step: 7
Training loss: 2.0745297645976692
Validation loss: 2.511353386184028

Epoch: 5| Step: 8
Training loss: 2.1575421870451095
Validation loss: 2.504425440378069

Epoch: 5| Step: 9
Training loss: 2.084551404268399
Validation loss: 2.500949452701222

Epoch: 5| Step: 10
Training loss: 2.8664887535716983
Validation loss: 2.4869854519431813

Epoch: 230| Step: 0
Training loss: 2.3998522236151185
Validation loss: 2.482902287961102

Epoch: 5| Step: 1
Training loss: 2.345509288443359
Validation loss: 2.524577772214881

Epoch: 5| Step: 2
Training loss: 2.258788218087823
Validation loss: 2.4874272253041583

Epoch: 5| Step: 3
Training loss: 2.3183320195706023
Validation loss: 2.4929293513547393

Epoch: 5| Step: 4
Training loss: 1.6720379901476001
Validation loss: 2.4923967393260793

Epoch: 5| Step: 5
Training loss: 2.2374974554462987
Validation loss: 2.4674788531080165

Epoch: 5| Step: 6
Training loss: 1.9301807838720588
Validation loss: 2.467674950699851

Epoch: 5| Step: 7
Training loss: 1.8395349198822142
Validation loss: 2.480537665904107

Epoch: 5| Step: 8
Training loss: 2.1757284325809847
Validation loss: 2.4739171879730315

Epoch: 5| Step: 9
Training loss: 2.429196617853507
Validation loss: 2.476239179516844

Epoch: 5| Step: 10
Training loss: 2.8182944054361836
Validation loss: 2.507282829707907

Epoch: 231| Step: 0
Training loss: 1.915618388676397
Validation loss: 2.4654550512799167

Epoch: 5| Step: 1
Training loss: 2.331805705500689
Validation loss: 2.4975372150908592

Epoch: 5| Step: 2
Training loss: 1.8443787359434456
Validation loss: 2.5305751334876256

Epoch: 5| Step: 3
Training loss: 2.3052457488951306
Validation loss: 2.5244817117162133

Epoch: 5| Step: 4
Training loss: 2.0457604555200564
Validation loss: 2.4980954673314244

Epoch: 5| Step: 5
Training loss: 2.430232437696631
Validation loss: 2.500438438444992

Epoch: 5| Step: 6
Training loss: 2.021977431755258
Validation loss: 2.50853896727151

Epoch: 5| Step: 7
Training loss: 2.4701202066800754
Validation loss: 2.477329413734709

Epoch: 5| Step: 8
Training loss: 2.648947877572011
Validation loss: 2.475478399583808

Epoch: 5| Step: 9
Training loss: 2.1512461665915645
Validation loss: 2.4929894832291213

Epoch: 5| Step: 10
Training loss: 2.695374772831345
Validation loss: 2.4738158658536817

Epoch: 232| Step: 0
Training loss: 2.291516235500472
Validation loss: 2.5195820719261133

Epoch: 5| Step: 1
Training loss: 2.302351773406288
Validation loss: 2.4899002603216633

Epoch: 5| Step: 2
Training loss: 1.8166918458272752
Validation loss: 2.4643288845543307

Epoch: 5| Step: 3
Training loss: 1.857915096802728
Validation loss: 2.5252092270906945

Epoch: 5| Step: 4
Training loss: 2.673004536263455
Validation loss: 2.493744878305933

Epoch: 5| Step: 5
Training loss: 2.090431772377324
Validation loss: 2.4831745009850477

Epoch: 5| Step: 6
Training loss: 1.897249768610875
Validation loss: 2.472449143875033

Epoch: 5| Step: 7
Training loss: 2.4428997385044795
Validation loss: 2.472140740583515

Epoch: 5| Step: 8
Training loss: 2.328119982003558
Validation loss: 2.4664217119374983

Epoch: 5| Step: 9
Training loss: 2.166876000293273
Validation loss: 2.481793537627209

Epoch: 5| Step: 10
Training loss: 2.4590207340379355
Validation loss: 2.4951330761375203

Epoch: 233| Step: 0
Training loss: 2.3797337387912756
Validation loss: 2.5033679733161653

Epoch: 5| Step: 1
Training loss: 1.8920889616933427
Validation loss: 2.523513362557821

Epoch: 5| Step: 2
Training loss: 1.7383315175535545
Validation loss: 2.5089144900760965

Epoch: 5| Step: 3
Training loss: 2.416199759618676
Validation loss: 2.467889999167147

Epoch: 5| Step: 4
Training loss: 2.591215250948019
Validation loss: 2.4675297440132526

Epoch: 5| Step: 5
Training loss: 1.8974295243957886
Validation loss: 2.471914694727294

Epoch: 5| Step: 6
Training loss: 1.6997705024193046
Validation loss: 2.5015365411185364

Epoch: 5| Step: 7
Training loss: 2.231833125832328
Validation loss: 2.444827760391116

Epoch: 5| Step: 8
Training loss: 2.6636549114868076
Validation loss: 2.4796568056078856

Epoch: 5| Step: 9
Training loss: 2.0661909427499325
Validation loss: 2.4607154247261085

Epoch: 5| Step: 10
Training loss: 2.3455169121029456
Validation loss: 2.4741242328624704

Epoch: 234| Step: 0
Training loss: 2.206548425305131
Validation loss: 2.49037886108517

Epoch: 5| Step: 1
Training loss: 2.3282385676801782
Validation loss: 2.4831113371555733

Epoch: 5| Step: 2
Training loss: 2.39171430914697
Validation loss: 2.507162355430317

Epoch: 5| Step: 3
Training loss: 2.169934180883198
Validation loss: 2.471501141621932

Epoch: 5| Step: 4
Training loss: 2.3230573557400302
Validation loss: 2.43561305486009

Epoch: 5| Step: 5
Training loss: 1.3224788251598647
Validation loss: 2.479006958516541

Epoch: 5| Step: 6
Training loss: 2.6342018151967848
Validation loss: 2.4981866048444425

Epoch: 5| Step: 7
Training loss: 2.684754321972151
Validation loss: 2.474290635352126

Epoch: 5| Step: 8
Training loss: 2.1941307932867895
Validation loss: 2.5122459982376153

Epoch: 5| Step: 9
Training loss: 1.8737761636018184
Validation loss: 2.4934490697390332

Epoch: 5| Step: 10
Training loss: 2.3954728781403487
Validation loss: 2.477333227118758

Epoch: 235| Step: 0
Training loss: 1.8335143635699276
Validation loss: 2.480086540015741

Epoch: 5| Step: 1
Training loss: 2.63840251143517
Validation loss: 2.5120430753559617

Epoch: 5| Step: 2
Training loss: 2.3435262954763516
Validation loss: 2.4877393482782564

Epoch: 5| Step: 3
Training loss: 1.340644397017287
Validation loss: 2.5076062768044625

Epoch: 5| Step: 4
Training loss: 1.8186495146898134
Validation loss: 2.4648585456479615

Epoch: 5| Step: 5
Training loss: 3.032156739836198
Validation loss: 2.478686520855694

Epoch: 5| Step: 6
Training loss: 2.089105037007918
Validation loss: 2.4732919695590345

Epoch: 5| Step: 7
Training loss: 2.0322964833598602
Validation loss: 2.4636406759688803

Epoch: 5| Step: 8
Training loss: 2.5969136259325607
Validation loss: 2.506852791901457

Epoch: 5| Step: 9
Training loss: 1.709600195966182
Validation loss: 2.4524689316924344

Epoch: 5| Step: 10
Training loss: 2.2933076936190453
Validation loss: 2.4901152162878346

Epoch: 236| Step: 0
Training loss: 1.8643753390387017
Validation loss: 2.485799979137729

Epoch: 5| Step: 1
Training loss: 2.868835806965798
Validation loss: 2.487618154241645

Epoch: 5| Step: 2
Training loss: 1.9415687170685887
Validation loss: 2.481789998638592

Epoch: 5| Step: 3
Training loss: 2.3608851368296127
Validation loss: 2.495379565155236

Epoch: 5| Step: 4
Training loss: 1.930294420189444
Validation loss: 2.503998860201248

Epoch: 5| Step: 5
Training loss: 2.6761119777361357
Validation loss: 2.5249011491992768

Epoch: 5| Step: 6
Training loss: 2.242283091351642
Validation loss: 2.505203765550475

Epoch: 5| Step: 7
Training loss: 2.2587388194260805
Validation loss: 2.5019410299343874

Epoch: 5| Step: 8
Training loss: 2.0082653440413787
Validation loss: 2.48092053541125

Epoch: 5| Step: 9
Training loss: 1.9098526727068013
Validation loss: 2.4549383762495673

Epoch: 5| Step: 10
Training loss: 2.1418608279353486
Validation loss: 2.5074733519755315

Epoch: 237| Step: 0
Training loss: 2.684740912441507
Validation loss: 2.4907511160788105

Epoch: 5| Step: 1
Training loss: 2.09524551045563
Validation loss: 2.496146516757164

Epoch: 5| Step: 2
Training loss: 2.169371774682604
Validation loss: 2.5052250005023367

Epoch: 5| Step: 3
Training loss: 1.9314175776888636
Validation loss: 2.476692500373535

Epoch: 5| Step: 4
Training loss: 1.8164827720356433
Validation loss: 2.4776470055670905

Epoch: 5| Step: 5
Training loss: 2.4348035716700407
Validation loss: 2.4760756413411302

Epoch: 5| Step: 6
Training loss: 2.0057296933873694
Validation loss: 2.5170901793437155

Epoch: 5| Step: 7
Training loss: 2.0658614769183306
Validation loss: 2.509758439996802

Epoch: 5| Step: 8
Training loss: 2.1132020494776413
Validation loss: 2.509233529778245

Epoch: 5| Step: 9
Training loss: 2.329133909628627
Validation loss: 2.4761081199924853

Epoch: 5| Step: 10
Training loss: 2.4527435978137238
Validation loss: 2.459934812823091

Epoch: 238| Step: 0
Training loss: 2.3281434333634765
Validation loss: 2.5082182314656327

Epoch: 5| Step: 1
Training loss: 2.278388122517455
Validation loss: 2.5207688775835564

Epoch: 5| Step: 2
Training loss: 2.904450382365071
Validation loss: 2.482168253464634

Epoch: 5| Step: 3
Training loss: 1.806849122259618
Validation loss: 2.4712776052842025

Epoch: 5| Step: 4
Training loss: 2.0529460997420377
Validation loss: 2.4864358648812694

Epoch: 5| Step: 5
Training loss: 2.2345861588582983
Validation loss: 2.464201215666289

Epoch: 5| Step: 6
Training loss: 2.3435950673075023
Validation loss: 2.4948988995980526

Epoch: 5| Step: 7
Training loss: 2.477082784495976
Validation loss: 2.4638316605944173

Epoch: 5| Step: 8
Training loss: 2.1521341599121424
Validation loss: 2.482341444621559

Epoch: 5| Step: 9
Training loss: 2.0848031263461206
Validation loss: 2.4993124359892334

Epoch: 5| Step: 10
Training loss: 1.8333101343363263
Validation loss: 2.500907188833632

Epoch: 239| Step: 0
Training loss: 2.145479475553936
Validation loss: 2.488693086028147

Epoch: 5| Step: 1
Training loss: 1.7315706142090155
Validation loss: 2.464315703921697

Epoch: 5| Step: 2
Training loss: 2.581892924563986
Validation loss: 2.4953194497815394

Epoch: 5| Step: 3
Training loss: 2.1531347354840453
Validation loss: 2.5149761411021636

Epoch: 5| Step: 4
Training loss: 2.2614918860206217
Validation loss: 2.543472977243598

Epoch: 5| Step: 5
Training loss: 1.8599746121960687
Validation loss: 2.527487719323531

Epoch: 5| Step: 6
Training loss: 1.8882366890121824
Validation loss: 2.516614460120106

Epoch: 5| Step: 7
Training loss: 2.9018087599960554
Validation loss: 2.509308242282756

Epoch: 5| Step: 8
Training loss: 2.3090304560315142
Validation loss: 2.5146632586961437

Epoch: 5| Step: 9
Training loss: 2.1707414921267962
Validation loss: 2.5140344626740494

Epoch: 5| Step: 10
Training loss: 2.202678662262058
Validation loss: 2.5218874738274217

Epoch: 240| Step: 0
Training loss: 2.779374679795305
Validation loss: 2.517787079905856

Epoch: 5| Step: 1
Training loss: 1.7085764021967396
Validation loss: 2.4571058032230724

Epoch: 5| Step: 2
Training loss: 1.94208046701849
Validation loss: 2.5042496309891313

Epoch: 5| Step: 3
Training loss: 2.260094251946021
Validation loss: 2.5052952175199206

Epoch: 5| Step: 4
Training loss: 2.320088077057148
Validation loss: 2.4615650101619098

Epoch: 5| Step: 5
Training loss: 2.351217352292154
Validation loss: 2.469836851348767

Epoch: 5| Step: 6
Training loss: 1.8482839796301054
Validation loss: 2.490722040228338

Epoch: 5| Step: 7
Training loss: 2.451501880331483
Validation loss: 2.494274045544181

Epoch: 5| Step: 8
Training loss: 2.4676606877500284
Validation loss: 2.5019443498328378

Epoch: 5| Step: 9
Training loss: 2.0397532962772904
Validation loss: 2.4772976739405568

Epoch: 5| Step: 10
Training loss: 1.9031999920882312
Validation loss: 2.493744234246037

Epoch: 241| Step: 0
Training loss: 2.650722541912235
Validation loss: 2.509928098233041

Epoch: 5| Step: 1
Training loss: 2.2166119872306957
Validation loss: 2.489558940913321

Epoch: 5| Step: 2
Training loss: 2.368456409145823
Validation loss: 2.484525196552646

Epoch: 5| Step: 3
Training loss: 2.148604507890958
Validation loss: 2.4842071084349255

Epoch: 5| Step: 4
Training loss: 2.3450641254043143
Validation loss: 2.5029655310804677

Epoch: 5| Step: 5
Training loss: 2.1855613837557404
Validation loss: 2.4836385146980957

Epoch: 5| Step: 6
Training loss: 1.7902126030427272
Validation loss: 2.4659018327559874

Epoch: 5| Step: 7
Training loss: 2.0727889310755465
Validation loss: 2.489026008331609

Epoch: 5| Step: 8
Training loss: 1.7776920857572371
Validation loss: 2.4833105144937537

Epoch: 5| Step: 9
Training loss: 1.9560263484553169
Validation loss: 2.491167345540036

Epoch: 5| Step: 10
Training loss: 2.588488838582902
Validation loss: 2.467712514566417

Epoch: 242| Step: 0
Training loss: 2.0908638719335677
Validation loss: 2.5116435559788988

Epoch: 5| Step: 1
Training loss: 2.6597546961976235
Validation loss: 2.478071604980562

Epoch: 5| Step: 2
Training loss: 2.049367653617477
Validation loss: 2.468592009259933

Epoch: 5| Step: 3
Training loss: 2.273982136826487
Validation loss: 2.5188286753985225

Epoch: 5| Step: 4
Training loss: 2.2705637803921865
Validation loss: 2.493004215183458

Epoch: 5| Step: 5
Training loss: 1.9955305585249037
Validation loss: 2.5109702144934136

Epoch: 5| Step: 6
Training loss: 2.340163067409592
Validation loss: 2.486450197471249

Epoch: 5| Step: 7
Training loss: 2.0908752747767743
Validation loss: 2.5067246778131556

Epoch: 5| Step: 8
Training loss: 2.070685586961195
Validation loss: 2.522207410566898

Epoch: 5| Step: 9
Training loss: 1.7774253071947215
Validation loss: 2.5387080250713163

Epoch: 5| Step: 10
Training loss: 2.6459569426570453
Validation loss: 2.5303233516746197

Epoch: 243| Step: 0
Training loss: 2.200851782716984
Validation loss: 2.513436998179322

Epoch: 5| Step: 1
Training loss: 2.003054432213624
Validation loss: 2.499683190853064

Epoch: 5| Step: 2
Training loss: 2.456997578546358
Validation loss: 2.5024634170984847

Epoch: 5| Step: 3
Training loss: 2.5784055614978394
Validation loss: 2.4706986881507933

Epoch: 5| Step: 4
Training loss: 1.9808452782480064
Validation loss: 2.512071598013532

Epoch: 5| Step: 5
Training loss: 2.447905119740192
Validation loss: 2.4725826031946476

Epoch: 5| Step: 6
Training loss: 2.3173494782684703
Validation loss: 2.497037863693099

Epoch: 5| Step: 7
Training loss: 1.7143824484757546
Validation loss: 2.4619578517040583

Epoch: 5| Step: 8
Training loss: 1.8564318275664236
Validation loss: 2.4610376356215493

Epoch: 5| Step: 9
Training loss: 1.9423071384792308
Validation loss: 2.4864262173241767

Epoch: 5| Step: 10
Training loss: 2.4897853072423066
Validation loss: 2.5017923790159804

Epoch: 244| Step: 0
Training loss: 2.2329410673463146
Validation loss: 2.45073140230579

Epoch: 5| Step: 1
Training loss: 2.279486510193159
Validation loss: 2.474585332943973

Epoch: 5| Step: 2
Training loss: 2.3313500513283314
Validation loss: 2.4651444678452594

Epoch: 5| Step: 3
Training loss: 2.452806488546858
Validation loss: 2.474820421635094

Epoch: 5| Step: 4
Training loss: 1.5752302758344627
Validation loss: 2.4862285749038495

Epoch: 5| Step: 5
Training loss: 2.711038812948369
Validation loss: 2.469840353489958

Epoch: 5| Step: 6
Training loss: 2.10147741209312
Validation loss: 2.466568905102295

Epoch: 5| Step: 7
Training loss: 2.145292553458175
Validation loss: 2.4823395159582975

Epoch: 5| Step: 8
Training loss: 1.9828725819243809
Validation loss: 2.4758180463561543

Epoch: 5| Step: 9
Training loss: 2.0485830387699298
Validation loss: 2.4789224781679646

Epoch: 5| Step: 10
Training loss: 2.0082192806713746
Validation loss: 2.48923231456258

Epoch: 245| Step: 0
Training loss: 2.364666493391718
Validation loss: 2.457068886858195

Epoch: 5| Step: 1
Training loss: 1.9832202825730136
Validation loss: 2.479118544898363

Epoch: 5| Step: 2
Training loss: 1.926777177839992
Validation loss: 2.502488894960662

Epoch: 5| Step: 3
Training loss: 2.1158476809535656
Validation loss: 2.549022513793102

Epoch: 5| Step: 4
Training loss: 2.3915050607061863
Validation loss: 2.5170480576541827

Epoch: 5| Step: 5
Training loss: 2.4140852152425434
Validation loss: 2.4715605138234396

Epoch: 5| Step: 6
Training loss: 2.4077532147653526
Validation loss: 2.5235857790307037

Epoch: 5| Step: 7
Training loss: 1.9517651516079617
Validation loss: 2.5255649693224886

Epoch: 5| Step: 8
Training loss: 2.3921006578744892
Validation loss: 2.50518250176524

Epoch: 5| Step: 9
Training loss: 1.972767620908592
Validation loss: 2.5106598318412976

Epoch: 5| Step: 10
Training loss: 2.2644910408124113
Validation loss: 2.48771352046843

Epoch: 246| Step: 0
Training loss: 1.5507106812993672
Validation loss: 2.5098233555600116

Epoch: 5| Step: 1
Training loss: 2.6977225765290527
Validation loss: 2.5052009841483343

Epoch: 5| Step: 2
Training loss: 2.1640234988447435
Validation loss: 2.4863143531407528

Epoch: 5| Step: 3
Training loss: 2.5634047608992
Validation loss: 2.5011688771079936

Epoch: 5| Step: 4
Training loss: 2.3248875785637906
Validation loss: 2.4946795896160125

Epoch: 5| Step: 5
Training loss: 1.7857396614451537
Validation loss: 2.4844673817008243

Epoch: 5| Step: 6
Training loss: 2.1255113323073793
Validation loss: 2.520060506630772

Epoch: 5| Step: 7
Training loss: 2.1838090548202787
Validation loss: 2.4619689056163145

Epoch: 5| Step: 8
Training loss: 2.3374054547941223
Validation loss: 2.483151305327644

Epoch: 5| Step: 9
Training loss: 2.0863121353505183
Validation loss: 2.4759316019117397

Epoch: 5| Step: 10
Training loss: 2.4777572108766077
Validation loss: 2.47149980975305

Epoch: 247| Step: 0
Training loss: 1.6228456888931573
Validation loss: 2.5350399693791488

Epoch: 5| Step: 1
Training loss: 2.6939093876746236
Validation loss: 2.4847403977543356

Epoch: 5| Step: 2
Training loss: 2.3940002947992767
Validation loss: 2.473862414397683

Epoch: 5| Step: 3
Training loss: 1.9559362702275165
Validation loss: 2.51414186158182

Epoch: 5| Step: 4
Training loss: 2.4618509202037613
Validation loss: 2.472954333753388

Epoch: 5| Step: 5
Training loss: 1.614683562418465
Validation loss: 2.4746812210966884

Epoch: 5| Step: 6
Training loss: 1.9306349802793503
Validation loss: 2.476542321526615

Epoch: 5| Step: 7
Training loss: 2.1547308836532784
Validation loss: 2.4936972066298693

Epoch: 5| Step: 8
Training loss: 2.3098573792592285
Validation loss: 2.4893294850431227

Epoch: 5| Step: 9
Training loss: 2.5481922511118955
Validation loss: 2.490600546662269

Epoch: 5| Step: 10
Training loss: 2.5737543222577273
Validation loss: 2.481514248805675

Epoch: 248| Step: 0
Training loss: 2.5168706996474604
Validation loss: 2.4547552321182255

Epoch: 5| Step: 1
Training loss: 2.36587558563043
Validation loss: 2.4875014292073434

Epoch: 5| Step: 2
Training loss: 2.3273306906117006
Validation loss: 2.5182381796368825

Epoch: 5| Step: 3
Training loss: 1.881933806585985
Validation loss: 2.4856367992605914

Epoch: 5| Step: 4
Training loss: 2.2513767904429427
Validation loss: 2.5062657172440304

Epoch: 5| Step: 5
Training loss: 2.1302800496782983
Validation loss: 2.506154789247835

Epoch: 5| Step: 6
Training loss: 2.399346791226031
Validation loss: 2.5289518496574313

Epoch: 5| Step: 7
Training loss: 2.3294471212470214
Validation loss: 2.513251375418643

Epoch: 5| Step: 8
Training loss: 1.9638597819275463
Validation loss: 2.4987952580250714

Epoch: 5| Step: 9
Training loss: 2.064216824002891
Validation loss: 2.512080574566095

Epoch: 5| Step: 10
Training loss: 2.012378295630352
Validation loss: 2.5271037984559275

Epoch: 249| Step: 0
Training loss: 2.196344967711949
Validation loss: 2.5018358596241543

Epoch: 5| Step: 1
Training loss: 2.0637369781397545
Validation loss: 2.5284053050684094

Epoch: 5| Step: 2
Training loss: 2.031005140364738
Validation loss: 2.497437292645355

Epoch: 5| Step: 3
Training loss: 2.482360598980652
Validation loss: 2.5163823162758843

Epoch: 5| Step: 4
Training loss: 2.214259371622786
Validation loss: 2.5112863980386027

Epoch: 5| Step: 5
Training loss: 2.2142020882139852
Validation loss: 2.499049959865608

Epoch: 5| Step: 6
Training loss: 2.1567744847291093
Validation loss: 2.5085246852610106

Epoch: 5| Step: 7
Training loss: 2.088872551966873
Validation loss: 2.5341178116863348

Epoch: 5| Step: 8
Training loss: 2.1661817179119276
Validation loss: 2.484510057301873

Epoch: 5| Step: 9
Training loss: 1.6649904484517828
Validation loss: 2.5008059094814707

Epoch: 5| Step: 10
Training loss: 2.6542667839135476
Validation loss: 2.4985008313140207

Epoch: 250| Step: 0
Training loss: 2.024464939212358
Validation loss: 2.446138798717524

Epoch: 5| Step: 1
Training loss: 1.8570288594334436
Validation loss: 2.4747034078918584

Epoch: 5| Step: 2
Training loss: 2.1254178926541263
Validation loss: 2.431451333530153

Epoch: 5| Step: 3
Training loss: 2.4656850403799084
Validation loss: 2.4617551529631414

Epoch: 5| Step: 4
Training loss: 1.9251036777072228
Validation loss: 2.4648365931825253

Epoch: 5| Step: 5
Training loss: 2.2914966751397468
Validation loss: 2.4788404346419504

Epoch: 5| Step: 6
Training loss: 2.2137063956206937
Validation loss: 2.5048364990931993

Epoch: 5| Step: 7
Training loss: 2.515767348153764
Validation loss: 2.4553478749098563

Epoch: 5| Step: 8
Training loss: 1.5158559092384878
Validation loss: 2.5096715073869515

Epoch: 5| Step: 9
Training loss: 2.572070787099394
Validation loss: 2.53978738917348

Epoch: 5| Step: 10
Training loss: 2.2426115160105558
Validation loss: 2.469345981389409

Epoch: 251| Step: 0
Training loss: 1.928941713843758
Validation loss: 2.486955500183391

Epoch: 5| Step: 1
Training loss: 2.0795226022418856
Validation loss: 2.5011408253794585

Epoch: 5| Step: 2
Training loss: 2.232582814046531
Validation loss: 2.5014058098247633

Epoch: 5| Step: 3
Training loss: 2.159367174059851
Validation loss: 2.5248882045585512

Epoch: 5| Step: 4
Training loss: 2.0406087223355973
Validation loss: 2.501193506159674

Epoch: 5| Step: 5
Training loss: 1.8947500830042672
Validation loss: 2.4650669675805665

Epoch: 5| Step: 6
Training loss: 2.4455237739138984
Validation loss: 2.465518684600382

Epoch: 5| Step: 7
Training loss: 2.5936850114516896
Validation loss: 2.4991491182333467

Epoch: 5| Step: 8
Training loss: 2.353775351980892
Validation loss: 2.46505558124312

Epoch: 5| Step: 9
Training loss: 2.012535625640007
Validation loss: 2.4613245531898964

Epoch: 5| Step: 10
Training loss: 2.3261577307898067
Validation loss: 2.4931218517443807

Epoch: 252| Step: 0
Training loss: 2.009866932501937
Validation loss: 2.468121570267795

Epoch: 5| Step: 1
Training loss: 2.3653550310175446
Validation loss: 2.531431567608784

Epoch: 5| Step: 2
Training loss: 1.8375926247431715
Validation loss: 2.514903972133669

Epoch: 5| Step: 3
Training loss: 2.1176874337679465
Validation loss: 2.533282902943712

Epoch: 5| Step: 4
Training loss: 2.0454857457796534
Validation loss: 2.5004323452196493

Epoch: 5| Step: 5
Training loss: 2.36522106919771
Validation loss: 2.519304342848259

Epoch: 5| Step: 6
Training loss: 2.210218980046615
Validation loss: 2.54473429046386

Epoch: 5| Step: 7
Training loss: 2.1969247782508905
Validation loss: 2.4947070763523547

Epoch: 5| Step: 8
Training loss: 2.351475102520943
Validation loss: 2.4729735983991707

Epoch: 5| Step: 9
Training loss: 2.431987103515864
Validation loss: 2.4971388010340387

Epoch: 5| Step: 10
Training loss: 2.16979804316582
Validation loss: 2.4867514648380404

Epoch: 253| Step: 0
Training loss: 1.8681289661578502
Validation loss: 2.527862877419778

Epoch: 5| Step: 1
Training loss: 2.174116884916394
Validation loss: 2.471223485377022

Epoch: 5| Step: 2
Training loss: 1.6310711934393383
Validation loss: 2.493456125925181

Epoch: 5| Step: 3
Training loss: 2.2386897115507702
Validation loss: 2.458683968829246

Epoch: 5| Step: 4
Training loss: 2.198513100740129
Validation loss: 2.454535843653691

Epoch: 5| Step: 5
Training loss: 1.912617850568331
Validation loss: 2.485526784482852

Epoch: 5| Step: 6
Training loss: 2.274038438584518
Validation loss: 2.505243265630174

Epoch: 5| Step: 7
Training loss: 2.2485039293603917
Validation loss: 2.4624151072494325

Epoch: 5| Step: 8
Training loss: 2.6999272301368915
Validation loss: 2.4415739950983073

Epoch: 5| Step: 9
Training loss: 2.107548693075171
Validation loss: 2.4681312987232977

Epoch: 5| Step: 10
Training loss: 2.5017986503041802
Validation loss: 2.4782590020588846

Epoch: 254| Step: 0
Training loss: 1.9043200369184359
Validation loss: 2.4853710990370157

Epoch: 5| Step: 1
Training loss: 2.29357902035121
Validation loss: 2.48029207093415

Epoch: 5| Step: 2
Training loss: 1.919566000226792
Validation loss: 2.496961040698996

Epoch: 5| Step: 3
Training loss: 2.2670222742091117
Validation loss: 2.4306363593839246

Epoch: 5| Step: 4
Training loss: 1.7623263577897466
Validation loss: 2.482467828440182

Epoch: 5| Step: 5
Training loss: 2.5004663032529777
Validation loss: 2.509087591434082

Epoch: 5| Step: 6
Training loss: 2.23722295058162
Validation loss: 2.4891899629803573

Epoch: 5| Step: 7
Training loss: 2.022232226928071
Validation loss: 2.484831158456949

Epoch: 5| Step: 8
Training loss: 2.6525367363229346
Validation loss: 2.4857865544854874

Epoch: 5| Step: 9
Training loss: 1.7858070839883977
Validation loss: 2.4825557487624246

Epoch: 5| Step: 10
Training loss: 2.3073088657493024
Validation loss: 2.4750885284789397

Epoch: 255| Step: 0
Training loss: 2.1908515323285926
Validation loss: 2.477144102067355

Epoch: 5| Step: 1
Training loss: 2.081596744280299
Validation loss: 2.4885249954203856

Epoch: 5| Step: 2
Training loss: 2.771660979909868
Validation loss: 2.498189280661119

Epoch: 5| Step: 3
Training loss: 2.067389616596916
Validation loss: 2.4897606003480677

Epoch: 5| Step: 4
Training loss: 1.97972914750536
Validation loss: 2.55082472520578

Epoch: 5| Step: 5
Training loss: 1.6227146364083826
Validation loss: 2.533732470141993

Epoch: 5| Step: 6
Training loss: 2.5058763106525332
Validation loss: 2.5096489340798978

Epoch: 5| Step: 7
Training loss: 2.1128257500309617
Validation loss: 2.5296062468264924

Epoch: 5| Step: 8
Training loss: 1.7359156596048533
Validation loss: 2.486223501707876

Epoch: 5| Step: 9
Training loss: 2.5574511590285844
Validation loss: 2.481057519778366

Epoch: 5| Step: 10
Training loss: 2.0475621125764167
Validation loss: 2.4761005318945117

Epoch: 256| Step: 0
Training loss: 1.99533550395565
Validation loss: 2.477118684354681

Epoch: 5| Step: 1
Training loss: 2.0068288092939097
Validation loss: 2.479627661699586

Epoch: 5| Step: 2
Training loss: 1.9741645108113635
Validation loss: 2.5394140664315534

Epoch: 5| Step: 3
Training loss: 2.4985898809383347
Validation loss: 2.435796097426091

Epoch: 5| Step: 4
Training loss: 1.8674648190699248
Validation loss: 2.50231817706111

Epoch: 5| Step: 5
Training loss: 2.235276793849766
Validation loss: 2.4885552558848447

Epoch: 5| Step: 6
Training loss: 2.116980961371194
Validation loss: 2.45293834470731

Epoch: 5| Step: 7
Training loss: 2.240259384906984
Validation loss: 2.513772765504677

Epoch: 5| Step: 8
Training loss: 2.043793666734746
Validation loss: 2.4848481301309766

Epoch: 5| Step: 9
Training loss: 2.397585043249106
Validation loss: 2.4602323559364465

Epoch: 5| Step: 10
Training loss: 2.6478793025788376
Validation loss: 2.504492791679591

Epoch: 257| Step: 0
Training loss: 2.699108778484039
Validation loss: 2.5149728394257247

Epoch: 5| Step: 1
Training loss: 1.7000516406798922
Validation loss: 2.459954214601239

Epoch: 5| Step: 2
Training loss: 2.082926774091693
Validation loss: 2.4332112270582624

Epoch: 5| Step: 3
Training loss: 1.7399933002606023
Validation loss: 2.4950165577977215

Epoch: 5| Step: 4
Training loss: 2.044666758949088
Validation loss: 2.496976698917168

Epoch: 5| Step: 5
Training loss: 2.277106716062708
Validation loss: 2.4631951319103758

Epoch: 5| Step: 6
Training loss: 1.983968978554713
Validation loss: 2.472916520880821

Epoch: 5| Step: 7
Training loss: 2.695065252048468
Validation loss: 2.498927013290523

Epoch: 5| Step: 8
Training loss: 2.3676905333597706
Validation loss: 2.5013320676012514

Epoch: 5| Step: 9
Training loss: 1.9787893906104759
Validation loss: 2.4898283107599912

Epoch: 5| Step: 10
Training loss: 1.9992635086135542
Validation loss: 2.505178989677469

Epoch: 258| Step: 0
Training loss: 1.5289394306837616
Validation loss: 2.493341912574588

Epoch: 5| Step: 1
Training loss: 2.133393708010527
Validation loss: 2.5068002586868627

Epoch: 5| Step: 2
Training loss: 2.0515882666219767
Validation loss: 2.537646405510347

Epoch: 5| Step: 3
Training loss: 1.7460181712748573
Validation loss: 2.4724734145961476

Epoch: 5| Step: 4
Training loss: 1.8790874433487592
Validation loss: 2.5142998195683894

Epoch: 5| Step: 5
Training loss: 2.828389192328172
Validation loss: 2.4802134010270165

Epoch: 5| Step: 6
Training loss: 2.0846288340597847
Validation loss: 2.501769608574162

Epoch: 5| Step: 7
Training loss: 1.6850902164203512
Validation loss: 2.4756113429896818

Epoch: 5| Step: 8
Training loss: 2.335039865778349
Validation loss: 2.5061853800180605

Epoch: 5| Step: 9
Training loss: 2.345201170208551
Validation loss: 2.4928006636119373

Epoch: 5| Step: 10
Training loss: 2.5034055402613515
Validation loss: 2.4849520788472264

Epoch: 259| Step: 0
Training loss: 2.5332186543290867
Validation loss: 2.4751325890194305

Epoch: 5| Step: 1
Training loss: 2.2230386254253562
Validation loss: 2.516987500347478

Epoch: 5| Step: 2
Training loss: 2.108466058506289
Validation loss: 2.5052638596604786

Epoch: 5| Step: 3
Training loss: 2.2052897105986142
Validation loss: 2.43371295414798

Epoch: 5| Step: 4
Training loss: 2.29814289416997
Validation loss: 2.479407148795478

Epoch: 5| Step: 5
Training loss: 1.7510812688733137
Validation loss: 2.4650505159518383

Epoch: 5| Step: 6
Training loss: 1.9799959419671291
Validation loss: 2.516210412629359

Epoch: 5| Step: 7
Training loss: 2.4944032009578914
Validation loss: 2.5060714307005796

Epoch: 5| Step: 8
Training loss: 1.9810490407019863
Validation loss: 2.490077214100385

Epoch: 5| Step: 9
Training loss: 2.167344671929437
Validation loss: 2.476178774432189

Epoch: 5| Step: 10
Training loss: 1.7851864334326026
Validation loss: 2.474572342656722

Epoch: 260| Step: 0
Training loss: 2.7468699935850105
Validation loss: 2.4752677901878215

Epoch: 5| Step: 1
Training loss: 2.182478235929324
Validation loss: 2.4740906717669464

Epoch: 5| Step: 2
Training loss: 2.106021957051147
Validation loss: 2.5067823832960023

Epoch: 5| Step: 3
Training loss: 2.284580569013108
Validation loss: 2.4627629965792273

Epoch: 5| Step: 4
Training loss: 1.8692730863665117
Validation loss: 2.5016041357036016

Epoch: 5| Step: 5
Training loss: 1.6989491917566735
Validation loss: 2.4417861704560604

Epoch: 5| Step: 6
Training loss: 2.1657089415296293
Validation loss: 2.472215694185974

Epoch: 5| Step: 7
Training loss: 2.028971171377806
Validation loss: 2.5185641417515394

Epoch: 5| Step: 8
Training loss: 2.0359475616417244
Validation loss: 2.5083021094201094

Epoch: 5| Step: 9
Training loss: 2.287111772622302
Validation loss: 2.511812361216079

Epoch: 5| Step: 10
Training loss: 2.2685349291541623
Validation loss: 2.465960977985687

Epoch: 261| Step: 0
Training loss: 2.064979450040449
Validation loss: 2.5167270988353416

Epoch: 5| Step: 1
Training loss: 2.111265338595804
Validation loss: 2.4919726456307325

Epoch: 5| Step: 2
Training loss: 1.695014962662003
Validation loss: 2.4928218592131905

Epoch: 5| Step: 3
Training loss: 2.2434175420357705
Validation loss: 2.517188337821172

Epoch: 5| Step: 4
Training loss: 1.9887773235944812
Validation loss: 2.514132348893177

Epoch: 5| Step: 5
Training loss: 2.3072716659700867
Validation loss: 2.5107199597538346

Epoch: 5| Step: 6
Training loss: 2.099965222388623
Validation loss: 2.5036051459090065

Epoch: 5| Step: 7
Training loss: 2.3046560511625493
Validation loss: 2.508557086656899

Epoch: 5| Step: 8
Training loss: 2.594855015697454
Validation loss: 2.526381939439905

Epoch: 5| Step: 9
Training loss: 2.4168488554407297
Validation loss: 2.5245008824727027

Epoch: 5| Step: 10
Training loss: 2.127928567074625
Validation loss: 2.476923436887715

Epoch: 262| Step: 0
Training loss: 2.3860458699155522
Validation loss: 2.494005705805486

Epoch: 5| Step: 1
Training loss: 2.4092765698940584
Validation loss: 2.4816313133012686

Epoch: 5| Step: 2
Training loss: 1.8847108506856267
Validation loss: 2.4781517446237786

Epoch: 5| Step: 3
Training loss: 2.239665031421532
Validation loss: 2.4738633107889836

Epoch: 5| Step: 4
Training loss: 1.336847720231217
Validation loss: 2.449783409000806

Epoch: 5| Step: 5
Training loss: 2.362358379660596
Validation loss: 2.5048238381484063

Epoch: 5| Step: 6
Training loss: 2.102527609517982
Validation loss: 2.4657431861969186

Epoch: 5| Step: 7
Training loss: 2.6202766975591034
Validation loss: 2.5110189145822313

Epoch: 5| Step: 8
Training loss: 1.9129805017366
Validation loss: 2.467306572602907

Epoch: 5| Step: 9
Training loss: 1.7000651038550203
Validation loss: 2.466767956412017

Epoch: 5| Step: 10
Training loss: 2.6077098901673965
Validation loss: 2.4864345884405754

Epoch: 263| Step: 0
Training loss: 2.1981347022603064
Validation loss: 2.482089361053519

Epoch: 5| Step: 1
Training loss: 1.9588555458129582
Validation loss: 2.489134178331773

Epoch: 5| Step: 2
Training loss: 1.961162782167865
Validation loss: 2.5124051815257316

Epoch: 5| Step: 3
Training loss: 2.9056838930118323
Validation loss: 2.477723858330313

Epoch: 5| Step: 4
Training loss: 2.3824453602596645
Validation loss: 2.4792661356513355

Epoch: 5| Step: 5
Training loss: 2.0390463642051935
Validation loss: 2.463994591735849

Epoch: 5| Step: 6
Training loss: 2.1903088655794054
Validation loss: 2.5193600089484525

Epoch: 5| Step: 7
Training loss: 2.1101997176110054
Validation loss: 2.4894595828307846

Epoch: 5| Step: 8
Training loss: 2.087233465847697
Validation loss: 2.5212548036721887

Epoch: 5| Step: 9
Training loss: 2.158877113014801
Validation loss: 2.490411282391625

Epoch: 5| Step: 10
Training loss: 1.7204590363419265
Validation loss: 2.478672560188035

Epoch: 264| Step: 0
Training loss: 2.5767954779435147
Validation loss: 2.4916579878894587

Epoch: 5| Step: 1
Training loss: 2.0165869021864204
Validation loss: 2.5077169683369602

Epoch: 5| Step: 2
Training loss: 2.676849018534625
Validation loss: 2.5017291908113126

Epoch: 5| Step: 3
Training loss: 2.2242623209998476
Validation loss: 2.5168688152689933

Epoch: 5| Step: 4
Training loss: 2.107462263029636
Validation loss: 2.4869729975141897

Epoch: 5| Step: 5
Training loss: 2.208659801703156
Validation loss: 2.4571722756961014

Epoch: 5| Step: 6
Training loss: 1.501055187382405
Validation loss: 2.4901471653916145

Epoch: 5| Step: 7
Training loss: 1.9972249687021488
Validation loss: 2.497738388448485

Epoch: 5| Step: 8
Training loss: 1.5569593230160548
Validation loss: 2.4525418131443564

Epoch: 5| Step: 9
Training loss: 2.4139608713627605
Validation loss: 2.509974465280535

Epoch: 5| Step: 10
Training loss: 2.203970888765964
Validation loss: 2.461827316923512

Epoch: 265| Step: 0
Training loss: 2.412790105108315
Validation loss: 2.4962913754237337

Epoch: 5| Step: 1
Training loss: 1.7842222479059286
Validation loss: 2.5058305491390076

Epoch: 5| Step: 2
Training loss: 2.349821238110299
Validation loss: 2.487907765033449

Epoch: 5| Step: 3
Training loss: 1.8966342226459267
Validation loss: 2.49905543890358

Epoch: 5| Step: 4
Training loss: 2.089492454593688
Validation loss: 2.5218182870721737

Epoch: 5| Step: 5
Training loss: 1.8763436906919173
Validation loss: 2.5019201441882584

Epoch: 5| Step: 6
Training loss: 2.176334988656186
Validation loss: 2.5049842647455938

Epoch: 5| Step: 7
Training loss: 1.8224159497632302
Validation loss: 2.4650086339504695

Epoch: 5| Step: 8
Training loss: 2.2417059723576385
Validation loss: 2.479611862909325

Epoch: 5| Step: 9
Training loss: 2.527320165981056
Validation loss: 2.473926711255463

Epoch: 5| Step: 10
Training loss: 2.3094131900174473
Validation loss: 2.465701035496466

Epoch: 266| Step: 0
Training loss: 2.1842974516674327
Validation loss: 2.4725113327466905

Epoch: 5| Step: 1
Training loss: 1.8968678331318287
Validation loss: 2.5395620980661557

Epoch: 5| Step: 2
Training loss: 2.7400432147495537
Validation loss: 2.5215703716787616

Epoch: 5| Step: 3
Training loss: 1.9871180641219806
Validation loss: 2.512616578672192

Epoch: 5| Step: 4
Training loss: 1.6899252524013046
Validation loss: 2.490224007108991

Epoch: 5| Step: 5
Training loss: 2.269230571532956
Validation loss: 2.5111224078127794

Epoch: 5| Step: 6
Training loss: 2.0751549858214067
Validation loss: 2.5098763055673325

Epoch: 5| Step: 7
Training loss: 1.9408470284795152
Validation loss: 2.5016646626562626

Epoch: 5| Step: 8
Training loss: 2.6597162406550896
Validation loss: 2.491607097468299

Epoch: 5| Step: 9
Training loss: 2.145203309638753
Validation loss: 2.4784214352230256

Epoch: 5| Step: 10
Training loss: 1.937753783801955
Validation loss: 2.4783765182220985

Epoch: 267| Step: 0
Training loss: 2.411302884215558
Validation loss: 2.4851694712880468

Epoch: 5| Step: 1
Training loss: 2.088287743966123
Validation loss: 2.45232471365284

Epoch: 5| Step: 2
Training loss: 1.8887691374136786
Validation loss: 2.504493531754353

Epoch: 5| Step: 3
Training loss: 2.4168140322598926
Validation loss: 2.551406376457888

Epoch: 5| Step: 4
Training loss: 2.047669118340848
Validation loss: 2.4902736863233033

Epoch: 5| Step: 5
Training loss: 2.1733130215746863
Validation loss: 2.458837531144245

Epoch: 5| Step: 6
Training loss: 1.6800407570481788
Validation loss: 2.4953408911044943

Epoch: 5| Step: 7
Training loss: 2.298400787330012
Validation loss: 2.485410439834061

Epoch: 5| Step: 8
Training loss: 2.562059876396666
Validation loss: 2.502783658141447

Epoch: 5| Step: 9
Training loss: 1.8119991531285882
Validation loss: 2.4794982567073114

Epoch: 5| Step: 10
Training loss: 2.3134578061581377
Validation loss: 2.474591890221141

Epoch: 268| Step: 0
Training loss: 1.9516817787925307
Validation loss: 2.4795569354568587

Epoch: 5| Step: 1
Training loss: 2.327829022122929
Validation loss: 2.514215972443131

Epoch: 5| Step: 2
Training loss: 1.9774592480035205
Validation loss: 2.457014334511013

Epoch: 5| Step: 3
Training loss: 1.720646453513057
Validation loss: 2.467456318228982

Epoch: 5| Step: 4
Training loss: 1.9704131110547738
Validation loss: 2.4565051041535306

Epoch: 5| Step: 5
Training loss: 2.121125447579109
Validation loss: 2.492238933011801

Epoch: 5| Step: 6
Training loss: 2.0226240842876195
Validation loss: 2.490919764550762

Epoch: 5| Step: 7
Training loss: 2.609216376868419
Validation loss: 2.5045114700555926

Epoch: 5| Step: 8
Training loss: 2.222337535674327
Validation loss: 2.5167235193294015

Epoch: 5| Step: 9
Training loss: 2.129538681864829
Validation loss: 2.495693415721828

Epoch: 5| Step: 10
Training loss: 1.9945350727622921
Validation loss: 2.462126983471167

Epoch: 269| Step: 0
Training loss: 2.41600851984606
Validation loss: 2.47701795582406

Epoch: 5| Step: 1
Training loss: 1.7824717564639145
Validation loss: 2.486796103252772

Epoch: 5| Step: 2
Training loss: 2.0384328754331067
Validation loss: 2.488493259344939

Epoch: 5| Step: 3
Training loss: 2.0486533324062894
Validation loss: 2.5006612149409064

Epoch: 5| Step: 4
Training loss: 1.5860543795206874
Validation loss: 2.491565286311533

Epoch: 5| Step: 5
Training loss: 2.175450407725018
Validation loss: 2.5002631489890375

Epoch: 5| Step: 6
Training loss: 2.294141011600991
Validation loss: 2.460683864447737

Epoch: 5| Step: 7
Training loss: 2.3870929231171942
Validation loss: 2.4856637326198303

Epoch: 5| Step: 8
Training loss: 1.5515429262153975
Validation loss: 2.4944566262838257

Epoch: 5| Step: 9
Training loss: 2.0436767751659115
Validation loss: 2.4898156924218258

Epoch: 5| Step: 10
Training loss: 3.0320905326270973
Validation loss: 2.48961065888946

Epoch: 270| Step: 0
Training loss: 2.442312917582458
Validation loss: 2.5166410828360073

Epoch: 5| Step: 1
Training loss: 2.392946101326513
Validation loss: 2.532335787078004

Epoch: 5| Step: 2
Training loss: 2.3667934580764243
Validation loss: 2.4981932653906687

Epoch: 5| Step: 3
Training loss: 2.2750765735189566
Validation loss: 2.501033015788283

Epoch: 5| Step: 4
Training loss: 2.3624023821003934
Validation loss: 2.4783118061466074

Epoch: 5| Step: 5
Training loss: 2.0457985646491106
Validation loss: 2.4570509731127737

Epoch: 5| Step: 6
Training loss: 1.9994186510124892
Validation loss: 2.517623446926352

Epoch: 5| Step: 7
Training loss: 1.8072353064757263
Validation loss: 2.5074693543885314

Epoch: 5| Step: 8
Training loss: 1.751553731278752
Validation loss: 2.475460518604081

Epoch: 5| Step: 9
Training loss: 1.9208468656690747
Validation loss: 2.51745578390299

Epoch: 5| Step: 10
Training loss: 2.2627179667820925
Validation loss: 2.5206234433621124

Epoch: 271| Step: 0
Training loss: 1.6190700906775504
Validation loss: 2.547745369775762

Epoch: 5| Step: 1
Training loss: 1.5605568819835207
Validation loss: 2.442325842225895

Epoch: 5| Step: 2
Training loss: 1.6642133617519834
Validation loss: 2.478002658771357

Epoch: 5| Step: 3
Training loss: 2.3382488540357844
Validation loss: 2.516753135156772

Epoch: 5| Step: 4
Training loss: 2.526944112651072
Validation loss: 2.478608987372915

Epoch: 5| Step: 5
Training loss: 2.7533848478595147
Validation loss: 2.52148785217599

Epoch: 5| Step: 6
Training loss: 2.0144877219433113
Validation loss: 2.504053897013488

Epoch: 5| Step: 7
Training loss: 1.950270986067808
Validation loss: 2.482239317904316

Epoch: 5| Step: 8
Training loss: 2.356333205476665
Validation loss: 2.494902590565391

Epoch: 5| Step: 9
Training loss: 2.121289548038799
Validation loss: 2.4947735874006396

Epoch: 5| Step: 10
Training loss: 2.0666324945926644
Validation loss: 2.487144375990576

Epoch: 272| Step: 0
Training loss: 1.6693726110352018
Validation loss: 2.510371546866813

Epoch: 5| Step: 1
Training loss: 1.7417728632015925
Validation loss: 2.502171113062061

Epoch: 5| Step: 2
Training loss: 2.7435546249310345
Validation loss: 2.492281526971355

Epoch: 5| Step: 3
Training loss: 2.3741542916618656
Validation loss: 2.488615872543739

Epoch: 5| Step: 4
Training loss: 2.038028849673638
Validation loss: 2.4548838256404535

Epoch: 5| Step: 5
Training loss: 1.9756492344384495
Validation loss: 2.486460396541869

Epoch: 5| Step: 6
Training loss: 2.300416668177529
Validation loss: 2.527689024257977

Epoch: 5| Step: 7
Training loss: 2.022534378759219
Validation loss: 2.493068594221535

Epoch: 5| Step: 8
Training loss: 2.190903441055996
Validation loss: 2.504600235860375

Epoch: 5| Step: 9
Training loss: 2.3137185262871274
Validation loss: 2.523194776609717

Epoch: 5| Step: 10
Training loss: 1.7892166137949066
Validation loss: 2.467448513390141

Epoch: 273| Step: 0
Training loss: 2.5417388426324856
Validation loss: 2.557822599901042

Epoch: 5| Step: 1
Training loss: 2.5491406245510606
Validation loss: 2.5086168602833894

Epoch: 5| Step: 2
Training loss: 1.9439388465524687
Validation loss: 2.4730447816650143

Epoch: 5| Step: 3
Training loss: 2.0664372865476994
Validation loss: 2.5065809447337233

Epoch: 5| Step: 4
Training loss: 2.5832296986455456
Validation loss: 2.5033793313242927

Epoch: 5| Step: 5
Training loss: 1.674498594022054
Validation loss: 2.500508622759105

Epoch: 5| Step: 6
Training loss: 1.8489642362545151
Validation loss: 2.5231462500603126

Epoch: 5| Step: 7
Training loss: 1.8719590004237747
Validation loss: 2.528674091243612

Epoch: 5| Step: 8
Training loss: 1.8279098644989429
Validation loss: 2.5208690630269617

Epoch: 5| Step: 9
Training loss: 2.121053396722786
Validation loss: 2.472838248730002

Epoch: 5| Step: 10
Training loss: 2.0684140119819774
Validation loss: 2.5084336412813126

Epoch: 274| Step: 0
Training loss: 2.1574993107906226
Validation loss: 2.501657394436868

Epoch: 5| Step: 1
Training loss: 2.3235219215391636
Validation loss: 2.509556671314384

Epoch: 5| Step: 2
Training loss: 1.6578741207769054
Validation loss: 2.501636429463805

Epoch: 5| Step: 3
Training loss: 2.1555229841089547
Validation loss: 2.4610888159700277

Epoch: 5| Step: 4
Training loss: 1.9696634988897577
Validation loss: 2.4950884163146925

Epoch: 5| Step: 5
Training loss: 2.301309159081545
Validation loss: 2.459087020263057

Epoch: 5| Step: 6
Training loss: 2.7910345889729244
Validation loss: 2.4552040081856297

Epoch: 5| Step: 7
Training loss: 1.621633931437586
Validation loss: 2.519444459229707

Epoch: 5| Step: 8
Training loss: 2.0441314714555947
Validation loss: 2.466764802222227

Epoch: 5| Step: 9
Training loss: 2.3880369850757845
Validation loss: 2.4877624444796593

Epoch: 5| Step: 10
Training loss: 1.5483590915509715
Validation loss: 2.498729650697159

Epoch: 275| Step: 0
Training loss: 2.462060290741098
Validation loss: 2.5237639973563666

Epoch: 5| Step: 1
Training loss: 2.0308013420522815
Validation loss: 2.5013287351036646

Epoch: 5| Step: 2
Training loss: 2.259829138652053
Validation loss: 2.5131199171903886

Epoch: 5| Step: 3
Training loss: 1.832990253020915
Validation loss: 2.456172224367177

Epoch: 5| Step: 4
Training loss: 2.146897863630017
Validation loss: 2.458877214099147

Epoch: 5| Step: 5
Training loss: 2.20641227752141
Validation loss: 2.5107075975334023

Epoch: 5| Step: 6
Training loss: 2.299062712050907
Validation loss: 2.4809982580834924

Epoch: 5| Step: 7
Training loss: 1.8529467981094723
Validation loss: 2.4939992771797774

Epoch: 5| Step: 8
Training loss: 1.983280090076838
Validation loss: 2.4624365206704146

Epoch: 5| Step: 9
Training loss: 2.7184501570299395
Validation loss: 2.4792203689705463

Epoch: 5| Step: 10
Training loss: 0.8524863804710914
Validation loss: 2.479764530363998

Epoch: 276| Step: 0
Training loss: 2.2727850013683804
Validation loss: 2.4718057908822186

Epoch: 5| Step: 1
Training loss: 2.9363943413488034
Validation loss: 2.511963162480026

Epoch: 5| Step: 2
Training loss: 1.846708348947992
Validation loss: 2.4848091611378376

Epoch: 5| Step: 3
Training loss: 1.9614223169662275
Validation loss: 2.4677446051538987

Epoch: 5| Step: 4
Training loss: 1.9352281848903488
Validation loss: 2.5027451056739056

Epoch: 5| Step: 5
Training loss: 2.2277060265955595
Validation loss: 2.5129683702312153

Epoch: 5| Step: 6
Training loss: 2.373495327996557
Validation loss: 2.512534137523098

Epoch: 5| Step: 7
Training loss: 1.7548897413521394
Validation loss: 2.5206827274474586

Epoch: 5| Step: 8
Training loss: 1.8330290137209564
Validation loss: 2.509941774742185

Epoch: 5| Step: 9
Training loss: 1.930772360589603
Validation loss: 2.5220472022958513

Epoch: 5| Step: 10
Training loss: 1.7153222322387702
Validation loss: 2.466150784971825

Epoch: 277| Step: 0
Training loss: 1.738322945426901
Validation loss: 2.5060462716035534

Epoch: 5| Step: 1
Training loss: 2.297291101665663
Validation loss: 2.5038243544764316

Epoch: 5| Step: 2
Training loss: 1.9682545114099932
Validation loss: 2.4830669463639135

Epoch: 5| Step: 3
Training loss: 1.963604576121671
Validation loss: 2.520876500095625

Epoch: 5| Step: 4
Training loss: 2.795584013084323
Validation loss: 2.4524517087662314

Epoch: 5| Step: 5
Training loss: 2.388149101337374
Validation loss: 2.503013731411304

Epoch: 5| Step: 6
Training loss: 2.2884237290004115
Validation loss: 2.4409041906488818

Epoch: 5| Step: 7
Training loss: 1.8009272783033357
Validation loss: 2.5198379842457603

Epoch: 5| Step: 8
Training loss: 2.352959100921461
Validation loss: 2.499251434071732

Epoch: 5| Step: 9
Training loss: 1.7278783970625364
Validation loss: 2.480590129011271

Epoch: 5| Step: 10
Training loss: 1.8291619775084897
Validation loss: 2.5007831597864456

Epoch: 278| Step: 0
Training loss: 2.2700192686767164
Validation loss: 2.4926136089883295

Epoch: 5| Step: 1
Training loss: 1.8269289456786746
Validation loss: 2.500325427870736

Epoch: 5| Step: 2
Training loss: 1.67247191138979
Validation loss: 2.5278620539271137

Epoch: 5| Step: 3
Training loss: 2.2521304534678395
Validation loss: 2.516875985066887

Epoch: 5| Step: 4
Training loss: 2.229575597979789
Validation loss: 2.4869103574497817

Epoch: 5| Step: 5
Training loss: 2.4088000372226275
Validation loss: 2.4862259743766373

Epoch: 5| Step: 6
Training loss: 1.928884733071565
Validation loss: 2.4855113161167552

Epoch: 5| Step: 7
Training loss: 1.961070569147348
Validation loss: 2.4864629968239047

Epoch: 5| Step: 8
Training loss: 2.778942565423292
Validation loss: 2.455616714059787

Epoch: 5| Step: 9
Training loss: 1.7689813091957574
Validation loss: 2.4731626689435173

Epoch: 5| Step: 10
Training loss: 2.0736457909814487
Validation loss: 2.4840909971366854

Epoch: 279| Step: 0
Training loss: 1.5920255719052825
Validation loss: 2.4718043606479045

Epoch: 5| Step: 1
Training loss: 1.8917877152934226
Validation loss: 2.461521312910598

Epoch: 5| Step: 2
Training loss: 1.6320192153070594
Validation loss: 2.466331040367556

Epoch: 5| Step: 3
Training loss: 1.7267435246499854
Validation loss: 2.4574319915779976

Epoch: 5| Step: 4
Training loss: 2.773733719601328
Validation loss: 2.4585231727172503

Epoch: 5| Step: 5
Training loss: 2.4860486804740995
Validation loss: 2.5171034380605346

Epoch: 5| Step: 6
Training loss: 2.1268831772244914
Validation loss: 2.489543484213437

Epoch: 5| Step: 7
Training loss: 2.3089234815353246
Validation loss: 2.4926652265609706

Epoch: 5| Step: 8
Training loss: 2.1219571711454353
Validation loss: 2.5050721336905553

Epoch: 5| Step: 9
Training loss: 2.2982020274997805
Validation loss: 2.488543996076379

Epoch: 5| Step: 10
Training loss: 1.9297828187451052
Validation loss: 2.4760626562841317

Epoch: 280| Step: 0
Training loss: 2.3153867488308246
Validation loss: 2.4625909576849265

Epoch: 5| Step: 1
Training loss: 2.552636959724323
Validation loss: 2.4726862484796484

Epoch: 5| Step: 2
Training loss: 2.3395986794851344
Validation loss: 2.4825506825181733

Epoch: 5| Step: 3
Training loss: 1.7263849089414565
Validation loss: 2.482388431249597

Epoch: 5| Step: 4
Training loss: 2.3915449379525744
Validation loss: 2.478402608837029

Epoch: 5| Step: 5
Training loss: 1.9592768107608742
Validation loss: 2.5362526010303985

Epoch: 5| Step: 6
Training loss: 2.5264153168130026
Validation loss: 2.5273602809981277

Epoch: 5| Step: 7
Training loss: 1.8527280462753297
Validation loss: 2.5292491714971517

Epoch: 5| Step: 8
Training loss: 1.8405870365703094
Validation loss: 2.4766009165928975

Epoch: 5| Step: 9
Training loss: 1.3902191684338203
Validation loss: 2.460230224980256

Epoch: 5| Step: 10
Training loss: 2.1233317614818525
Validation loss: 2.5028771426180003

Epoch: 281| Step: 0
Training loss: 1.7566364338328364
Validation loss: 2.475521321278726

Epoch: 5| Step: 1
Training loss: 2.534280352347955
Validation loss: 2.4749080977743163

Epoch: 5| Step: 2
Training loss: 2.2602828611743067
Validation loss: 2.4714124691209163

Epoch: 5| Step: 3
Training loss: 1.8142280233670363
Validation loss: 2.442376331968692

Epoch: 5| Step: 4
Training loss: 2.3693342389198224
Validation loss: 2.50160445646557

Epoch: 5| Step: 5
Training loss: 2.0035073996955353
Validation loss: 2.511286670094467

Epoch: 5| Step: 6
Training loss: 2.2362063712080213
Validation loss: 2.493784321902862

Epoch: 5| Step: 7
Training loss: 2.2200735738092603
Validation loss: 2.4571798533875024

Epoch: 5| Step: 8
Training loss: 1.5992029439930535
Validation loss: 2.5184124378533173

Epoch: 5| Step: 9
Training loss: 1.9235518668638443
Validation loss: 2.4749086923537873

Epoch: 5| Step: 10
Training loss: 2.4291526475592353
Validation loss: 2.505577641600108

Epoch: 282| Step: 0
Training loss: 2.6614147463897893
Validation loss: 2.4811150100814383

Epoch: 5| Step: 1
Training loss: 2.0558746737418847
Validation loss: 2.5373315830130374

Epoch: 5| Step: 2
Training loss: 2.1387700863936714
Validation loss: 2.4652480935965166

Epoch: 5| Step: 3
Training loss: 1.6632633349814245
Validation loss: 2.4549204699319502

Epoch: 5| Step: 4
Training loss: 1.715886313960731
Validation loss: 2.4692383046102058

Epoch: 5| Step: 5
Training loss: 2.4237722533346973
Validation loss: 2.50597228639544

Epoch: 5| Step: 6
Training loss: 2.166902737105756
Validation loss: 2.4970175755312174

Epoch: 5| Step: 7
Training loss: 2.5231262581977796
Validation loss: 2.476344280541154

Epoch: 5| Step: 8
Training loss: 1.5885064876809345
Validation loss: 2.4793894574502757

Epoch: 5| Step: 9
Training loss: 2.0304723571533945
Validation loss: 2.450736505037974

Epoch: 5| Step: 10
Training loss: 1.9908608600772737
Validation loss: 2.4619601821359227

Epoch: 283| Step: 0
Training loss: 2.1177765987393404
Validation loss: 2.4703513409316757

Epoch: 5| Step: 1
Training loss: 1.9523123309296595
Validation loss: 2.4599485411315336

Epoch: 5| Step: 2
Training loss: 2.039307795126611
Validation loss: 2.5439925731471327

Epoch: 5| Step: 3
Training loss: 1.9504861323517113
Validation loss: 2.5259788946013213

Epoch: 5| Step: 4
Training loss: 1.9728975960421753
Validation loss: 2.504784902565967

Epoch: 5| Step: 5
Training loss: 1.763436573169606
Validation loss: 2.5202723582086044

Epoch: 5| Step: 6
Training loss: 2.4228342433127463
Validation loss: 2.509646607070731

Epoch: 5| Step: 7
Training loss: 2.317799038487267
Validation loss: 2.4804163422045007

Epoch: 5| Step: 8
Training loss: 2.3236974820855516
Validation loss: 2.507563563857339

Epoch: 5| Step: 9
Training loss: 2.1884556453987
Validation loss: 2.467722756796995

Epoch: 5| Step: 10
Training loss: 2.1492040757760242
Validation loss: 2.502237182383452

Epoch: 284| Step: 0
Training loss: 2.32114701083157
Validation loss: 2.485249219068906

Epoch: 5| Step: 1
Training loss: 2.358623561816035
Validation loss: 2.4866998482236378

Epoch: 5| Step: 2
Training loss: 1.8048349295502912
Validation loss: 2.504741316553363

Epoch: 5| Step: 3
Training loss: 1.8042446104954708
Validation loss: 2.5116779013595303

Epoch: 5| Step: 4
Training loss: 1.9160091543914695
Validation loss: 2.4894687016758574

Epoch: 5| Step: 5
Training loss: 2.268794926810679
Validation loss: 2.4750701164322937

Epoch: 5| Step: 6
Training loss: 1.8000137116651687
Validation loss: 2.482099235652688

Epoch: 5| Step: 7
Training loss: 2.8883512885197247
Validation loss: 2.4968892874113795

Epoch: 5| Step: 8
Training loss: 1.6561971691990478
Validation loss: 2.484698175961862

Epoch: 5| Step: 9
Training loss: 2.0672774037989705
Validation loss: 2.4664362943950717

Epoch: 5| Step: 10
Training loss: 2.2523190944564613
Validation loss: 2.4717425029997995

Epoch: 285| Step: 0
Training loss: 1.9814697384445057
Validation loss: 2.4546893521547584

Epoch: 5| Step: 1
Training loss: 1.423513621065113
Validation loss: 2.491949068408033

Epoch: 5| Step: 2
Training loss: 2.3952797844550626
Validation loss: 2.5141087796218815

Epoch: 5| Step: 3
Training loss: 1.9040458318098774
Validation loss: 2.476744200300902

Epoch: 5| Step: 4
Training loss: 2.4413016579158398
Validation loss: 2.527651729984696

Epoch: 5| Step: 5
Training loss: 2.184729210945533
Validation loss: 2.495983978383808

Epoch: 5| Step: 6
Training loss: 1.927813898396151
Validation loss: 2.560064810929403

Epoch: 5| Step: 7
Training loss: 2.0865249092448943
Validation loss: 2.5409198973835965

Epoch: 5| Step: 8
Training loss: 2.5995222459689775
Validation loss: 2.5188663242163867

Epoch: 5| Step: 9
Training loss: 2.0305262523345218
Validation loss: 2.51900933289243

Epoch: 5| Step: 10
Training loss: 2.197578645238449
Validation loss: 2.5356703081153267

Epoch: 286| Step: 0
Training loss: 1.9653158360163465
Validation loss: 2.479106085073195

Epoch: 5| Step: 1
Training loss: 2.6693913030963876
Validation loss: 2.520874587185625

Epoch: 5| Step: 2
Training loss: 1.8474077698807978
Validation loss: 2.4922419901566015

Epoch: 5| Step: 3
Training loss: 2.5157221425889142
Validation loss: 2.523120367091178

Epoch: 5| Step: 4
Training loss: 2.197610758484515
Validation loss: 2.479619225213941

Epoch: 5| Step: 5
Training loss: 2.079613059622555
Validation loss: 2.4953776635204346

Epoch: 5| Step: 6
Training loss: 2.1429927011028247
Validation loss: 2.4853494964042393

Epoch: 5| Step: 7
Training loss: 1.8986307681570749
Validation loss: 2.496161224944015

Epoch: 5| Step: 8
Training loss: 2.010488426495843
Validation loss: 2.491211714450819

Epoch: 5| Step: 9
Training loss: 1.9392275952826017
Validation loss: 2.47740990438542

Epoch: 5| Step: 10
Training loss: 2.1286109089504546
Validation loss: 2.4732680624037364

Epoch: 287| Step: 0
Training loss: 2.5679211841027505
Validation loss: 2.5047741517270437

Epoch: 5| Step: 1
Training loss: 1.966376311749091
Validation loss: 2.486664087718728

Epoch: 5| Step: 2
Training loss: 1.8307337609383105
Validation loss: 2.469188203209563

Epoch: 5| Step: 3
Training loss: 1.9941669279301057
Validation loss: 2.496113322625446

Epoch: 5| Step: 4
Training loss: 2.600569160226815
Validation loss: 2.454504512034388

Epoch: 5| Step: 5
Training loss: 1.9146373897499536
Validation loss: 2.4469316401940784

Epoch: 5| Step: 6
Training loss: 2.3183558784593474
Validation loss: 2.514190829588434

Epoch: 5| Step: 7
Training loss: 1.750158711457137
Validation loss: 2.482942763874999

Epoch: 5| Step: 8
Training loss: 1.7946751936633918
Validation loss: 2.4650279541933258

Epoch: 5| Step: 9
Training loss: 1.9169239065065107
Validation loss: 2.4596879090439

Epoch: 5| Step: 10
Training loss: 2.366323684858996
Validation loss: 2.4528307001764738

Epoch: 288| Step: 0
Training loss: 2.0927128286837164
Validation loss: 2.4859878743764754

Epoch: 5| Step: 1
Training loss: 1.6981357674929491
Validation loss: 2.4983240847499277

Epoch: 5| Step: 2
Training loss: 1.8595695714365121
Validation loss: 2.4963172839338394

Epoch: 5| Step: 3
Training loss: 2.370363729548203
Validation loss: 2.4755785352400412

Epoch: 5| Step: 4
Training loss: 2.1160521894411586
Validation loss: 2.475348675147403

Epoch: 5| Step: 5
Training loss: 2.276193423125812
Validation loss: 2.5386099897573304

Epoch: 5| Step: 6
Training loss: 2.752611740713006
Validation loss: 2.5128118915378255

Epoch: 5| Step: 7
Training loss: 1.535248265893923
Validation loss: 2.475676832920912

Epoch: 5| Step: 8
Training loss: 2.103579776108024
Validation loss: 2.4647360668754765

Epoch: 5| Step: 9
Training loss: 1.775575533764964
Validation loss: 2.492115617501643

Epoch: 5| Step: 10
Training loss: 2.043658925864914
Validation loss: 2.48793861159037

Epoch: 289| Step: 0
Training loss: 1.3817910770103312
Validation loss: 2.4470476792104354

Epoch: 5| Step: 1
Training loss: 1.6659810642892778
Validation loss: 2.4806096565416675

Epoch: 5| Step: 2
Training loss: 1.6780062045595312
Validation loss: 2.4939683950808256

Epoch: 5| Step: 3
Training loss: 1.9743730080966737
Validation loss: 2.4676534414459574

Epoch: 5| Step: 4
Training loss: 2.7063500013662347
Validation loss: 2.434374518480448

Epoch: 5| Step: 5
Training loss: 2.1790339539514165
Validation loss: 2.48168225540231

Epoch: 5| Step: 6
Training loss: 1.746999962010244
Validation loss: 2.5104135020471015

Epoch: 5| Step: 7
Training loss: 2.431147783577391
Validation loss: 2.498943743042732

Epoch: 5| Step: 8
Training loss: 2.1086611069517422
Validation loss: 2.4787169541767176

Epoch: 5| Step: 9
Training loss: 2.8487298979642097
Validation loss: 2.4939789468245865

Epoch: 5| Step: 10
Training loss: 1.7412791257504967
Validation loss: 2.4804574245445927

Epoch: 290| Step: 0
Training loss: 1.6854058446485634
Validation loss: 2.4742253361622755

Epoch: 5| Step: 1
Training loss: 1.7487148606953404
Validation loss: 2.480425353732814

Epoch: 5| Step: 2
Training loss: 1.9355986094561834
Validation loss: 2.4786069580633256

Epoch: 5| Step: 3
Training loss: 1.9839407978953991
Validation loss: 2.4839413719070396

Epoch: 5| Step: 4
Training loss: 2.337058420341501
Validation loss: 2.4614937873162313

Epoch: 5| Step: 5
Training loss: 1.6095661679401878
Validation loss: 2.4625230386565247

Epoch: 5| Step: 6
Training loss: 2.913041250338188
Validation loss: 2.522513390514916

Epoch: 5| Step: 7
Training loss: 1.990934808358328
Validation loss: 2.5147514500412362

Epoch: 5| Step: 8
Training loss: 1.8640723638281564
Validation loss: 2.496553294916343

Epoch: 5| Step: 9
Training loss: 2.172456622288767
Validation loss: 2.4773952028414765

Epoch: 5| Step: 10
Training loss: 2.3969663401163217
Validation loss: 2.4768292331396466

Epoch: 291| Step: 0
Training loss: 1.7232673927667947
Validation loss: 2.500271090299214

Epoch: 5| Step: 1
Training loss: 2.1855152390332093
Validation loss: 2.464932166860214

Epoch: 5| Step: 2
Training loss: 2.3112181126244953
Validation loss: 2.46765439515429

Epoch: 5| Step: 3
Training loss: 2.028626376161973
Validation loss: 2.4962213672880127

Epoch: 5| Step: 4
Training loss: 2.3682608106848235
Validation loss: 2.4993089315516746

Epoch: 5| Step: 5
Training loss: 1.9044194421693574
Validation loss: 2.4671299952656396

Epoch: 5| Step: 6
Training loss: 1.7882820659350613
Validation loss: 2.514240889704202

Epoch: 5| Step: 7
Training loss: 2.037223249491283
Validation loss: 2.4838619547308713

Epoch: 5| Step: 8
Training loss: 2.2828724983158595
Validation loss: 2.4709089171501355

Epoch: 5| Step: 9
Training loss: 1.8520483353365078
Validation loss: 2.517829668292631

Epoch: 5| Step: 10
Training loss: 2.2469892491353805
Validation loss: 2.5382876947025257

Epoch: 292| Step: 0
Training loss: 1.8973804560863774
Validation loss: 2.492788949905394

Epoch: 5| Step: 1
Training loss: 2.518235078717261
Validation loss: 2.4818911191700748

Epoch: 5| Step: 2
Training loss: 2.3881350246958815
Validation loss: 2.5142002125584257

Epoch: 5| Step: 3
Training loss: 1.8139318532497997
Validation loss: 2.4735235811276155

Epoch: 5| Step: 4
Training loss: 2.2194167733672305
Validation loss: 2.490348000488744

Epoch: 5| Step: 5
Training loss: 2.008263563260625
Validation loss: 2.4698572434147366

Epoch: 5| Step: 6
Training loss: 1.64298529006679
Validation loss: 2.4823141385346545

Epoch: 5| Step: 7
Training loss: 1.9873937038571043
Validation loss: 2.4987986764903205

Epoch: 5| Step: 8
Training loss: 1.9994413668560624
Validation loss: 2.4772018570542396

Epoch: 5| Step: 9
Training loss: 2.3095993201468525
Validation loss: 2.4947372643989527

Epoch: 5| Step: 10
Training loss: 1.7835668921902639
Validation loss: 2.536735290283222

Epoch: 293| Step: 0
Training loss: 1.959598829027127
Validation loss: 2.462932718928288

Epoch: 5| Step: 1
Training loss: 2.363372145236781
Validation loss: 2.47566705852249

Epoch: 5| Step: 2
Training loss: 2.143731974089438
Validation loss: 2.461346372412292

Epoch: 5| Step: 3
Training loss: 2.658617109341251
Validation loss: 2.498698458731654

Epoch: 5| Step: 4
Training loss: 1.9787531236634748
Validation loss: 2.5162663876182583

Epoch: 5| Step: 5
Training loss: 2.0166852661199886
Validation loss: 2.467341027068705

Epoch: 5| Step: 6
Training loss: 2.3392443263262415
Validation loss: 2.479703304987028

Epoch: 5| Step: 7
Training loss: 2.0282162826520964
Validation loss: 2.4962833444293495

Epoch: 5| Step: 8
Training loss: 1.7303917310121217
Validation loss: 2.4714782736240295

Epoch: 5| Step: 9
Training loss: 1.6417544155906663
Validation loss: 2.4938449584635944

Epoch: 5| Step: 10
Training loss: 1.9860763465251492
Validation loss: 2.475888650053461

Epoch: 294| Step: 0
Training loss: 1.8820540930730258
Validation loss: 2.4748372361372977

Epoch: 5| Step: 1
Training loss: 2.1869134389023515
Validation loss: 2.477503119063859

Epoch: 5| Step: 2
Training loss: 2.5665890702577236
Validation loss: 2.507381706458632

Epoch: 5| Step: 3
Training loss: 2.507678162015953
Validation loss: 2.5150341536736285

Epoch: 5| Step: 4
Training loss: 1.8117944067472327
Validation loss: 2.4975615566211506

Epoch: 5| Step: 5
Training loss: 1.601459332376447
Validation loss: 2.5254262888636254

Epoch: 5| Step: 6
Training loss: 2.0030088441589697
Validation loss: 2.5130912623396955

Epoch: 5| Step: 7
Training loss: 1.942590241170992
Validation loss: 2.5247459807337598

Epoch: 5| Step: 8
Training loss: 1.923359925280732
Validation loss: 2.5237814304636923

Epoch: 5| Step: 9
Training loss: 2.4099384129043004
Validation loss: 2.5103620535914297

Epoch: 5| Step: 10
Training loss: 2.1954358700877528
Validation loss: 2.4645979641911504

Epoch: 295| Step: 0
Training loss: 2.288168358223973
Validation loss: 2.5035097516865745

Epoch: 5| Step: 1
Training loss: 1.7453843965125149
Validation loss: 2.4813955381541146

Epoch: 5| Step: 2
Training loss: 1.8123082684361176
Validation loss: 2.518643469341233

Epoch: 5| Step: 3
Training loss: 2.5818047359216556
Validation loss: 2.482307441061643

Epoch: 5| Step: 4
Training loss: 1.8036706875542596
Validation loss: 2.459411468800449

Epoch: 5| Step: 5
Training loss: 2.0504940740150412
Validation loss: 2.4373046043630167

Epoch: 5| Step: 6
Training loss: 2.14297134004298
Validation loss: 2.526456701403509

Epoch: 5| Step: 7
Training loss: 2.374725225515154
Validation loss: 2.4436002490472357

Epoch: 5| Step: 8
Training loss: 2.3237631471455913
Validation loss: 2.465883508061493

Epoch: 5| Step: 9
Training loss: 2.0607964387155056
Validation loss: 2.465570605311595

Epoch: 5| Step: 10
Training loss: 1.792072013719303
Validation loss: 2.4527242518813983

Epoch: 296| Step: 0
Training loss: 1.9538218361405835
Validation loss: 2.483217990387485

Epoch: 5| Step: 1
Training loss: 2.4500222964148075
Validation loss: 2.4806848601260456

Epoch: 5| Step: 2
Training loss: 2.101334229732135
Validation loss: 2.4902705258748

Epoch: 5| Step: 3
Training loss: 1.7708068022890937
Validation loss: 2.503987555170623

Epoch: 5| Step: 4
Training loss: 1.9969159428036252
Validation loss: 2.403825601557738

Epoch: 5| Step: 5
Training loss: 2.061566112515724
Validation loss: 2.4642006497138587

Epoch: 5| Step: 6
Training loss: 2.047357051083861
Validation loss: 2.5002648244076413

Epoch: 5| Step: 7
Training loss: 2.2812324418737826
Validation loss: 2.4813198498525972

Epoch: 5| Step: 8
Training loss: 2.0715009625004717
Validation loss: 2.480619822784949

Epoch: 5| Step: 9
Training loss: 2.047169787895575
Validation loss: 2.472144905740364

Epoch: 5| Step: 10
Training loss: 2.1878505970787723
Validation loss: 2.465430730704071

Epoch: 297| Step: 0
Training loss: 1.9553083499561401
Validation loss: 2.484823725962111

Epoch: 5| Step: 1
Training loss: 1.7911432152148745
Validation loss: 2.4915228488544776

Epoch: 5| Step: 2
Training loss: 1.9414717665119325
Validation loss: 2.477741996646054

Epoch: 5| Step: 3
Training loss: 2.0574920427949537
Validation loss: 2.5205319718633934

Epoch: 5| Step: 4
Training loss: 1.7730146399688023
Validation loss: 2.4977518556067158

Epoch: 5| Step: 5
Training loss: 2.172753135937855
Validation loss: 2.4554145588931746

Epoch: 5| Step: 6
Training loss: 1.629097174929089
Validation loss: 2.472658443859813

Epoch: 5| Step: 7
Training loss: 2.2421463487417643
Validation loss: 2.4904788073246142

Epoch: 5| Step: 8
Training loss: 1.9683553512056697
Validation loss: 2.4766315918848254

Epoch: 5| Step: 9
Training loss: 2.477955808311673
Validation loss: 2.502155525259167

Epoch: 5| Step: 10
Training loss: 2.6980722645158264
Validation loss: 2.4836840255254455

Epoch: 298| Step: 0
Training loss: 2.279940712810459
Validation loss: 2.520767302238581

Epoch: 5| Step: 1
Training loss: 2.461675817756285
Validation loss: 2.4826140377094434

Epoch: 5| Step: 2
Training loss: 2.0610002787227524
Validation loss: 2.4913462272264786

Epoch: 5| Step: 3
Training loss: 2.1240624996408113
Validation loss: 2.4954216740260695

Epoch: 5| Step: 4
Training loss: 2.266696965725664
Validation loss: 2.500079713596525

Epoch: 5| Step: 5
Training loss: 1.7194039227886295
Validation loss: 2.4922402075083565

Epoch: 5| Step: 6
Training loss: 2.32055066873985
Validation loss: 2.501779864060041

Epoch: 5| Step: 7
Training loss: 1.7002790278158524
Validation loss: 2.510422115109818

Epoch: 5| Step: 8
Training loss: 1.7327270239067754
Validation loss: 2.4848377377026387

Epoch: 5| Step: 9
Training loss: 2.0815151927722506
Validation loss: 2.5209844993584047

Epoch: 5| Step: 10
Training loss: 1.968671040238275
Validation loss: 2.4598365270271256

Epoch: 299| Step: 0
Training loss: 1.831921539600481
Validation loss: 2.4931260810783713

Epoch: 5| Step: 1
Training loss: 2.328475413737575
Validation loss: 2.4631529186118146

Epoch: 5| Step: 2
Training loss: 1.7602626424670518
Validation loss: 2.5285570491873304

Epoch: 5| Step: 3
Training loss: 1.4746573939304943
Validation loss: 2.4932024330505964

Epoch: 5| Step: 4
Training loss: 1.886747055947087
Validation loss: 2.491576556131566

Epoch: 5| Step: 5
Training loss: 2.7352677114178423
Validation loss: 2.50262915275994

Epoch: 5| Step: 6
Training loss: 2.214061888356148
Validation loss: 2.5021948347371956

Epoch: 5| Step: 7
Training loss: 1.904308518594211
Validation loss: 2.4992985746354877

Epoch: 5| Step: 8
Training loss: 1.8263327135053793
Validation loss: 2.4931013928954355

Epoch: 5| Step: 9
Training loss: 2.2198117361917253
Validation loss: 2.50736654366731

Epoch: 5| Step: 10
Training loss: 2.543552126674832
Validation loss: 2.4848167680373003

Epoch: 300| Step: 0
Training loss: 2.3760536266016423
Validation loss: 2.4837242734910983

Epoch: 5| Step: 1
Training loss: 1.4822703649724258
Validation loss: 2.485377687168279

Epoch: 5| Step: 2
Training loss: 1.9583541449665185
Validation loss: 2.5252137874507676

Epoch: 5| Step: 3
Training loss: 2.4072569684628884
Validation loss: 2.5176650249114125

Epoch: 5| Step: 4
Training loss: 1.9206976036502905
Validation loss: 2.488326195808542

Epoch: 5| Step: 5
Training loss: 2.0023472839872003
Validation loss: 2.450447462136744

Epoch: 5| Step: 6
Training loss: 2.0777652974130723
Validation loss: 2.4937896027957946

Epoch: 5| Step: 7
Training loss: 1.925012028644186
Validation loss: 2.5198242312231853

Epoch: 5| Step: 8
Training loss: 1.971836335155266
Validation loss: 2.4853754354259894

Epoch: 5| Step: 9
Training loss: 2.7684612493877485
Validation loss: 2.4544645035298602

Epoch: 5| Step: 10
Training loss: 1.9032250464189158
Validation loss: 2.4813943665677543

Epoch: 301| Step: 0
Training loss: 1.998199785185531
Validation loss: 2.4876328984248772

Epoch: 5| Step: 1
Training loss: 1.4494439538737407
Validation loss: 2.4637580746526146

Epoch: 5| Step: 2
Training loss: 1.8446201275583236
Validation loss: 2.5099793025370567

Epoch: 5| Step: 3
Training loss: 1.6357276847538051
Validation loss: 2.461891336624912

Epoch: 5| Step: 4
Training loss: 2.2745457206150985
Validation loss: 2.464927525134538

Epoch: 5| Step: 5
Training loss: 2.16438472841452
Validation loss: 2.500136671124673

Epoch: 5| Step: 6
Training loss: 1.8631074132540355
Validation loss: 2.4791108874233854

Epoch: 5| Step: 7
Training loss: 2.96912871505061
Validation loss: 2.5195519938294257

Epoch: 5| Step: 8
Training loss: 2.3685071433186895
Validation loss: 2.4793894160910512

Epoch: 5| Step: 9
Training loss: 2.0121923981624867
Validation loss: 2.498458776904338

Epoch: 5| Step: 10
Training loss: 1.9784350665940194
Validation loss: 2.45509003116272

Epoch: 302| Step: 0
Training loss: 1.8149613078383229
Validation loss: 2.4498099966835927

Epoch: 5| Step: 1
Training loss: 1.9689317649615141
Validation loss: 2.4579995510813437

Epoch: 5| Step: 2
Training loss: 2.043997569357067
Validation loss: 2.47923097727844

Epoch: 5| Step: 3
Training loss: 2.3612794579222856
Validation loss: 2.4616699962065933

Epoch: 5| Step: 4
Training loss: 1.8801218014686027
Validation loss: 2.4748089128753326

Epoch: 5| Step: 5
Training loss: 1.6435190016736358
Validation loss: 2.4803747796075903

Epoch: 5| Step: 6
Training loss: 1.8080375590642974
Validation loss: 2.4880098383640763

Epoch: 5| Step: 7
Training loss: 2.5972896460645662
Validation loss: 2.436123893626368

Epoch: 5| Step: 8
Training loss: 2.2167699871029054
Validation loss: 2.5149491159528603

Epoch: 5| Step: 9
Training loss: 2.1272443251503286
Validation loss: 2.5027110566634017

Epoch: 5| Step: 10
Training loss: 2.1525453448863723
Validation loss: 2.511900102552146

Epoch: 303| Step: 0
Training loss: 2.260288240736871
Validation loss: 2.4762421963676893

Epoch: 5| Step: 1
Training loss: 1.9482244428624864
Validation loss: 2.472019005291547

Epoch: 5| Step: 2
Training loss: 2.4185180040233134
Validation loss: 2.4486484799517587

Epoch: 5| Step: 3
Training loss: 1.9989836017495182
Validation loss: 2.4789455060445484

Epoch: 5| Step: 4
Training loss: 1.8500663410354505
Validation loss: 2.4619724465439403

Epoch: 5| Step: 5
Training loss: 1.739527223637714
Validation loss: 2.4473358786624937

Epoch: 5| Step: 6
Training loss: 2.0013518533038255
Validation loss: 2.4890319760137407

Epoch: 5| Step: 7
Training loss: 2.0643751694497
Validation loss: 2.4425336232737904

Epoch: 5| Step: 8
Training loss: 2.474427563522594
Validation loss: 2.426446131693266

Epoch: 5| Step: 9
Training loss: 2.3938222211894007
Validation loss: 2.484460644630124

Epoch: 5| Step: 10
Training loss: 1.5479774784894393
Validation loss: 2.501023993434147

Epoch: 304| Step: 0
Training loss: 1.9814572246977438
Validation loss: 2.515331772229061

Epoch: 5| Step: 1
Training loss: 2.774101500207476
Validation loss: 2.4647394368874194

Epoch: 5| Step: 2
Training loss: 1.8103337332192961
Validation loss: 2.50880793216531

Epoch: 5| Step: 3
Training loss: 1.5788821679590508
Validation loss: 2.491673911960708

Epoch: 5| Step: 4
Training loss: 2.20367035304792
Validation loss: 2.481836569093816

Epoch: 5| Step: 5
Training loss: 1.6312742151092718
Validation loss: 2.4836522007547948

Epoch: 5| Step: 6
Training loss: 1.9014340209186809
Validation loss: 2.478070131808704

Epoch: 5| Step: 7
Training loss: 2.0427530732832597
Validation loss: 2.497220738206737

Epoch: 5| Step: 8
Training loss: 1.9394806613100588
Validation loss: 2.5255404500403085

Epoch: 5| Step: 9
Training loss: 2.0091768965057897
Validation loss: 2.516718178582986

Epoch: 5| Step: 10
Training loss: 2.648087289886955
Validation loss: 2.516943831795194

Epoch: 305| Step: 0
Training loss: 1.9494098577290653
Validation loss: 2.5191041070973643

Epoch: 5| Step: 1
Training loss: 2.1172755599623696
Validation loss: 2.4670252280660634

Epoch: 5| Step: 2
Training loss: 2.3061950925167922
Validation loss: 2.511252862461346

Epoch: 5| Step: 3
Training loss: 1.769906650495414
Validation loss: 2.450707816414859

Epoch: 5| Step: 4
Training loss: 1.9995725294095392
Validation loss: 2.51481010493178

Epoch: 5| Step: 5
Training loss: 1.9164774704585992
Validation loss: 2.5036248200640525

Epoch: 5| Step: 6
Training loss: 2.3092359240289695
Validation loss: 2.4811002168323344

Epoch: 5| Step: 7
Training loss: 1.4676105056045656
Validation loss: 2.4937419047319223

Epoch: 5| Step: 8
Training loss: 2.4182327939812227
Validation loss: 2.49158151759374

Epoch: 5| Step: 9
Training loss: 2.3710663996569203
Validation loss: 2.5133023671724097

Epoch: 5| Step: 10
Training loss: 1.664153620414554
Validation loss: 2.466890449136866

Epoch: 306| Step: 0
Training loss: 1.5026484790881507
Validation loss: 2.461920067785781

Epoch: 5| Step: 1
Training loss: 2.064249279456829
Validation loss: 2.476060653360335

Epoch: 5| Step: 2
Training loss: 2.3973408033801262
Validation loss: 2.4739315081158324

Epoch: 5| Step: 3
Training loss: 2.263802472774996
Validation loss: 2.4943480200680765

Epoch: 5| Step: 4
Training loss: 1.9413165373001373
Validation loss: 2.4577054698785314

Epoch: 5| Step: 5
Training loss: 2.054671602949137
Validation loss: 2.467280363612276

Epoch: 5| Step: 6
Training loss: 2.1533918373183494
Validation loss: 2.529562210835129

Epoch: 5| Step: 7
Training loss: 2.4423325391229866
Validation loss: 2.449835363912472

Epoch: 5| Step: 8
Training loss: 1.9133935498964343
Validation loss: 2.4631588771638704

Epoch: 5| Step: 9
Training loss: 2.1189743328331203
Validation loss: 2.5021319476774937

Epoch: 5| Step: 10
Training loss: 1.191471485790842
Validation loss: 2.48765976070671

Epoch: 307| Step: 0
Training loss: 2.07463503465997
Validation loss: 2.4829427633587486

Epoch: 5| Step: 1
Training loss: 2.016231593445908
Validation loss: 2.4523403244418795

Epoch: 5| Step: 2
Training loss: 1.6925787616924863
Validation loss: 2.477743299292866

Epoch: 5| Step: 3
Training loss: 2.770200834051608
Validation loss: 2.4991900362495714

Epoch: 5| Step: 4
Training loss: 1.972856386815332
Validation loss: 2.4735742020538263

Epoch: 5| Step: 5
Training loss: 2.3213120693275098
Validation loss: 2.531695851394975

Epoch: 5| Step: 6
Training loss: 1.9753737663347746
Validation loss: 2.4842432015124984

Epoch: 5| Step: 7
Training loss: 1.6075688569552145
Validation loss: 2.496060123795148

Epoch: 5| Step: 8
Training loss: 1.862887294875896
Validation loss: 2.46969995774772

Epoch: 5| Step: 9
Training loss: 2.126539682326152
Validation loss: 2.4728689354488003

Epoch: 5| Step: 10
Training loss: 1.9960801334999123
Validation loss: 2.4627668892504233

Epoch: 308| Step: 0
Training loss: 2.1090852891688674
Validation loss: 2.477763185006405

Epoch: 5| Step: 1
Training loss: 1.6767167190199614
Validation loss: 2.4721169379230012

Epoch: 5| Step: 2
Training loss: 1.7367124185862857
Validation loss: 2.489272427505837

Epoch: 5| Step: 3
Training loss: 2.3535699228694984
Validation loss: 2.487694666502892

Epoch: 5| Step: 4
Training loss: 2.015107909122113
Validation loss: 2.478505677682655

Epoch: 5| Step: 5
Training loss: 2.0690470732860065
Validation loss: 2.5142323292350426

Epoch: 5| Step: 6
Training loss: 2.1946832698589516
Validation loss: 2.499346556429955

Epoch: 5| Step: 7
Training loss: 1.9692088606623246
Validation loss: 2.4580839172057125

Epoch: 5| Step: 8
Training loss: 1.757293217569182
Validation loss: 2.5106069146969356

Epoch: 5| Step: 9
Training loss: 2.658499987728685
Validation loss: 2.4626867965226955

Epoch: 5| Step: 10
Training loss: 1.7224181826002514
Validation loss: 2.4901016779721057

Epoch: 309| Step: 0
Training loss: 2.0759992698197745
Validation loss: 2.4796456697784333

Epoch: 5| Step: 1
Training loss: 1.7033381897371243
Validation loss: 2.5204598094065993

Epoch: 5| Step: 2
Training loss: 2.0820175084560595
Validation loss: 2.5038268440636484

Epoch: 5| Step: 3
Training loss: 1.967655907237622
Validation loss: 2.47373162328061

Epoch: 5| Step: 4
Training loss: 1.5804062020582013
Validation loss: 2.4912414390693853

Epoch: 5| Step: 5
Training loss: 2.312711654462309
Validation loss: 2.456739875592686

Epoch: 5| Step: 6
Training loss: 2.4763574364899905
Validation loss: 2.491931806628588

Epoch: 5| Step: 7
Training loss: 1.8629217860726655
Validation loss: 2.5025943082672235

Epoch: 5| Step: 8
Training loss: 2.499172073600935
Validation loss: 2.4936173733060563

Epoch: 5| Step: 9
Training loss: 1.918170926068472
Validation loss: 2.5196913353926145

Epoch: 5| Step: 10
Training loss: 1.791132766071058
Validation loss: 2.4646442593207425

Epoch: 310| Step: 0
Training loss: 1.952777434895128
Validation loss: 2.511620952422276

Epoch: 5| Step: 1
Training loss: 2.2007589418298283
Validation loss: 2.4461780756337843

Epoch: 5| Step: 2
Training loss: 1.9400279872881168
Validation loss: 2.4673334961698625

Epoch: 5| Step: 3
Training loss: 2.105389708555197
Validation loss: 2.5208771845123006

Epoch: 5| Step: 4
Training loss: 2.517962394609281
Validation loss: 2.5398077505438166

Epoch: 5| Step: 5
Training loss: 1.9233354431396408
Validation loss: 2.5014091673291925

Epoch: 5| Step: 6
Training loss: 2.118390406698362
Validation loss: 2.485953807255895

Epoch: 5| Step: 7
Training loss: 1.937979546544312
Validation loss: 2.4437000848326917

Epoch: 5| Step: 8
Training loss: 2.2693599038763184
Validation loss: 2.4580022742966463

Epoch: 5| Step: 9
Training loss: 1.9160477910661666
Validation loss: 2.4615307268869353

Epoch: 5| Step: 10
Training loss: 1.3479631157506704
Validation loss: 2.4956795460806984

Epoch: 311| Step: 0
Training loss: 1.9873655717600778
Validation loss: 2.4777031192040457

Epoch: 5| Step: 1
Training loss: 1.507456366823258
Validation loss: 2.490937165594049

Epoch: 5| Step: 2
Training loss: 2.6413625556154763
Validation loss: 2.4831501118565575

Epoch: 5| Step: 3
Training loss: 1.7501053778392517
Validation loss: 2.443722771115576

Epoch: 5| Step: 4
Training loss: 1.6603951315957095
Validation loss: 2.5115883802832704

Epoch: 5| Step: 5
Training loss: 2.438621751941401
Validation loss: 2.512071753133858

Epoch: 5| Step: 6
Training loss: 1.9009915349612325
Validation loss: 2.515306740410993

Epoch: 5| Step: 7
Training loss: 2.325173266937963
Validation loss: 2.4932636431184316

Epoch: 5| Step: 8
Training loss: 1.8095037753805476
Validation loss: 2.487805598893297

Epoch: 5| Step: 9
Training loss: 1.6632710755316085
Validation loss: 2.507494812058698

Epoch: 5| Step: 10
Training loss: 2.4559436325538373
Validation loss: 2.5025508879596337

Epoch: 312| Step: 0
Training loss: 1.8434283735712513
Validation loss: 2.492491223306679

Epoch: 5| Step: 1
Training loss: 2.0013538784918437
Validation loss: 2.505388551491332

Epoch: 5| Step: 2
Training loss: 2.1699393449383946
Validation loss: 2.5201466515885014

Epoch: 5| Step: 3
Training loss: 2.1384786718882305
Validation loss: 2.4749118454871324

Epoch: 5| Step: 4
Training loss: 1.959570419568546
Validation loss: 2.4898139687858465

Epoch: 5| Step: 5
Training loss: 2.225703130484573
Validation loss: 2.47599135451239

Epoch: 5| Step: 6
Training loss: 2.185684104340626
Validation loss: 2.47442487703305

Epoch: 5| Step: 7
Training loss: 2.044887014126505
Validation loss: 2.4947085443241277

Epoch: 5| Step: 8
Training loss: 2.0063764728362252
Validation loss: 2.4921219728053616

Epoch: 5| Step: 9
Training loss: 1.6035000873514502
Validation loss: 2.480427421863091

Epoch: 5| Step: 10
Training loss: 2.3770590439630075
Validation loss: 2.485564733504535

Epoch: 313| Step: 0
Training loss: 1.5389683883474155
Validation loss: 2.4578094932378645

Epoch: 5| Step: 1
Training loss: 2.1187349977215337
Validation loss: 2.4934445438169055

Epoch: 5| Step: 2
Training loss: 1.4771385078545338
Validation loss: 2.5084494905398786

Epoch: 5| Step: 3
Training loss: 1.8323617730564012
Validation loss: 2.4700084151387496

Epoch: 5| Step: 4
Training loss: 1.8834181954948543
Validation loss: 2.501388953567601

Epoch: 5| Step: 5
Training loss: 2.886381095991801
Validation loss: 2.5067436110850347

Epoch: 5| Step: 6
Training loss: 2.1220159334956175
Validation loss: 2.515867128504881

Epoch: 5| Step: 7
Training loss: 2.327260618591507
Validation loss: 2.452723525452203

Epoch: 5| Step: 8
Training loss: 1.888509086528448
Validation loss: 2.4845386641346745

Epoch: 5| Step: 9
Training loss: 2.413682728743146
Validation loss: 2.465710491738944

Epoch: 5| Step: 10
Training loss: 1.7316042100488174
Validation loss: 2.5013919872308255

Epoch: 314| Step: 0
Training loss: 2.1174006618721757
Validation loss: 2.4743470571890516

Epoch: 5| Step: 1
Training loss: 2.1705095128938607
Validation loss: 2.4811693146122002

Epoch: 5| Step: 2
Training loss: 2.365110587826998
Validation loss: 2.4933727757002195

Epoch: 5| Step: 3
Training loss: 2.5810598603570942
Validation loss: 2.5070222980711137

Epoch: 5| Step: 4
Training loss: 1.5758286188634387
Validation loss: 2.5094203579491055

Epoch: 5| Step: 5
Training loss: 1.9419628550456873
Validation loss: 2.474797966555249

Epoch: 5| Step: 6
Training loss: 1.8037797370516095
Validation loss: 2.4716345188468516

Epoch: 5| Step: 7
Training loss: 1.4511013912370654
Validation loss: 2.5022618613673373

Epoch: 5| Step: 8
Training loss: 2.222580303376248
Validation loss: 2.5435909299408492

Epoch: 5| Step: 9
Training loss: 2.145229316315642
Validation loss: 2.4575863915389347

Epoch: 5| Step: 10
Training loss: 2.1600170677005237
Validation loss: 2.4766356506341074

Epoch: 315| Step: 0
Training loss: 2.280229418572715
Validation loss: 2.450231370889577

Epoch: 5| Step: 1
Training loss: 1.820154273233217
Validation loss: 2.4387197185225435

Epoch: 5| Step: 2
Training loss: 2.1056984968937402
Validation loss: 2.5028989780695867

Epoch: 5| Step: 3
Training loss: 1.8611860030875444
Validation loss: 2.4763797666586385

Epoch: 5| Step: 4
Training loss: 1.762262027988956
Validation loss: 2.4466960025284457

Epoch: 5| Step: 5
Training loss: 2.3236349959538365
Validation loss: 2.5006908467156808

Epoch: 5| Step: 6
Training loss: 2.103887583539663
Validation loss: 2.507429697162355

Epoch: 5| Step: 7
Training loss: 1.9306339923405942
Validation loss: 2.4480218812790446

Epoch: 5| Step: 8
Training loss: 1.7904449185930025
Validation loss: 2.464910792800582

Epoch: 5| Step: 9
Training loss: 2.348987068851974
Validation loss: 2.468901702635292

Epoch: 5| Step: 10
Training loss: 1.9733885359560528
Validation loss: 2.4485542552700674

Epoch: 316| Step: 0
Training loss: 2.555628518661648
Validation loss: 2.4669483018075278

Epoch: 5| Step: 1
Training loss: 2.34452908600679
Validation loss: 2.4720044391735057

Epoch: 5| Step: 2
Training loss: 2.207767438057477
Validation loss: 2.4813279933341126

Epoch: 5| Step: 3
Training loss: 1.8921052166714196
Validation loss: 2.483710684856622

Epoch: 5| Step: 4
Training loss: 1.8193757098401964
Validation loss: 2.457154880199644

Epoch: 5| Step: 5
Training loss: 1.7514022250184103
Validation loss: 2.4841814564898557

Epoch: 5| Step: 6
Training loss: 1.9402438392968977
Validation loss: 2.510746586260748

Epoch: 5| Step: 7
Training loss: 2.0734906831545357
Validation loss: 2.53533765515857

Epoch: 5| Step: 8
Training loss: 2.39909925247072
Validation loss: 2.4485364127244207

Epoch: 5| Step: 9
Training loss: 1.698676502919925
Validation loss: 2.450297686682215

Epoch: 5| Step: 10
Training loss: 1.7266249839557914
Validation loss: 2.4474232997048375

Epoch: 317| Step: 0
Training loss: 2.4355109486687194
Validation loss: 2.4548877793654844

Epoch: 5| Step: 1
Training loss: 1.7775282543957411
Validation loss: 2.489159381686792

Epoch: 5| Step: 2
Training loss: 2.2180029457629966
Validation loss: 2.519795494916208

Epoch: 5| Step: 3
Training loss: 1.6069479112616116
Validation loss: 2.4946564058766176

Epoch: 5| Step: 4
Training loss: 1.7132484471163634
Validation loss: 2.534072088734181

Epoch: 5| Step: 5
Training loss: 2.181989541151958
Validation loss: 2.509692602386878

Epoch: 5| Step: 6
Training loss: 2.4434809543967213
Validation loss: 2.5580711759789807

Epoch: 5| Step: 7
Training loss: 1.6475164362271322
Validation loss: 2.501857878361855

Epoch: 5| Step: 8
Training loss: 2.1467301676620294
Validation loss: 2.534797951943704

Epoch: 5| Step: 9
Training loss: 2.0960437110390675
Validation loss: 2.494627086770001

Epoch: 5| Step: 10
Training loss: 2.121326974653444
Validation loss: 2.4894478832675944

Epoch: 318| Step: 0
Training loss: 2.263307530570203
Validation loss: 2.529161564748044

Epoch: 5| Step: 1
Training loss: 2.1050807616627347
Validation loss: 2.4938944694324543

Epoch: 5| Step: 2
Training loss: 1.9573488263332108
Validation loss: 2.4580634316401713

Epoch: 5| Step: 3
Training loss: 1.901768152781404
Validation loss: 2.459700641290472

Epoch: 5| Step: 4
Training loss: 2.32988431880767
Validation loss: 2.440732599853173

Epoch: 5| Step: 5
Training loss: 2.659345640565068
Validation loss: 2.4886895578810044

Epoch: 5| Step: 6
Training loss: 2.360689719002024
Validation loss: 2.482411308211544

Epoch: 5| Step: 7
Training loss: 1.554554382452711
Validation loss: 2.491079947331231

Epoch: 5| Step: 8
Training loss: 1.7015377662899769
Validation loss: 2.5100716866276813

Epoch: 5| Step: 9
Training loss: 1.8080733603135783
Validation loss: 2.4580633409034003

Epoch: 5| Step: 10
Training loss: 1.6461696844415419
Validation loss: 2.4528996233624456

Epoch: 319| Step: 0
Training loss: 2.0898917789822673
Validation loss: 2.519943758331563

Epoch: 5| Step: 1
Training loss: 1.8773390485345118
Validation loss: 2.4955896021245234

Epoch: 5| Step: 2
Training loss: 2.362911378274604
Validation loss: 2.4948978453285395

Epoch: 5| Step: 3
Training loss: 2.303515740922288
Validation loss: 2.4926643071053105

Epoch: 5| Step: 4
Training loss: 2.354737125473718
Validation loss: 2.467409439992572

Epoch: 5| Step: 5
Training loss: 1.9806809772491063
Validation loss: 2.436582272118249

Epoch: 5| Step: 6
Training loss: 1.896873552048459
Validation loss: 2.4515253916559

Epoch: 5| Step: 7
Training loss: 1.7283118866068343
Validation loss: 2.488476903868657

Epoch: 5| Step: 8
Training loss: 2.389494185931326
Validation loss: 2.46500443541505

Epoch: 5| Step: 9
Training loss: 1.76421340283435
Validation loss: 2.5072206040138907

Epoch: 5| Step: 10
Training loss: 1.5364238756701778
Validation loss: 2.5022963539581164

Epoch: 320| Step: 0
Training loss: 2.317158105809117
Validation loss: 2.530503448907047

Epoch: 5| Step: 1
Training loss: 1.458232394766975
Validation loss: 2.5213774627153573

Epoch: 5| Step: 2
Training loss: 2.276909343451047
Validation loss: 2.4885450901240476

Epoch: 5| Step: 3
Training loss: 2.275178851967722
Validation loss: 2.459267318054168

Epoch: 5| Step: 4
Training loss: 1.3731847398113914
Validation loss: 2.4969229640530353

Epoch: 5| Step: 5
Training loss: 2.0011617147592458
Validation loss: 2.465839961154482

Epoch: 5| Step: 6
Training loss: 2.2929254946942237
Validation loss: 2.5404756900296

Epoch: 5| Step: 7
Training loss: 1.9467088827472048
Validation loss: 2.488289397486123

Epoch: 5| Step: 8
Training loss: 1.8716113941368389
Validation loss: 2.4675280255889467

Epoch: 5| Step: 9
Training loss: 2.2904784734680774
Validation loss: 2.470865658020837

Epoch: 5| Step: 10
Training loss: 2.1933640491031565
Validation loss: 2.54889330175758

Epoch: 321| Step: 0
Training loss: 1.7744331421820938
Validation loss: 2.492305083562415

Epoch: 5| Step: 1
Training loss: 1.5149511038566281
Validation loss: 2.480721788820245

Epoch: 5| Step: 2
Training loss: 1.9870770898156824
Validation loss: 2.4729413877690574

Epoch: 5| Step: 3
Training loss: 2.6330050163177794
Validation loss: 2.486999048455185

Epoch: 5| Step: 4
Training loss: 1.7076756289011947
Validation loss: 2.426122508405626

Epoch: 5| Step: 5
Training loss: 2.087911407681294
Validation loss: 2.51472484453029

Epoch: 5| Step: 6
Training loss: 2.00147264622854
Validation loss: 2.5083646138739044

Epoch: 5| Step: 7
Training loss: 2.3061677995624623
Validation loss: 2.488071460559935

Epoch: 5| Step: 8
Training loss: 2.003163339423523
Validation loss: 2.484703574184215

Epoch: 5| Step: 9
Training loss: 2.3585047853868923
Validation loss: 2.4909439371219975

Epoch: 5| Step: 10
Training loss: 1.7752389370920467
Validation loss: 2.492537758384946

Epoch: 322| Step: 0
Training loss: 2.168624311427355
Validation loss: 2.4327048229031702

Epoch: 5| Step: 1
Training loss: 1.7269007148719548
Validation loss: 2.5163876770919127

Epoch: 5| Step: 2
Training loss: 2.1818047635070403
Validation loss: 2.513380023820402

Epoch: 5| Step: 3
Training loss: 1.8221014834091087
Validation loss: 2.5024272856235164

Epoch: 5| Step: 4
Training loss: 1.881308560394616
Validation loss: 2.4827964991033507

Epoch: 5| Step: 5
Training loss: 2.471748751998344
Validation loss: 2.49048720084736

Epoch: 5| Step: 6
Training loss: 2.26803481754442
Validation loss: 2.510281932225873

Epoch: 5| Step: 7
Training loss: 1.8535206415813963
Validation loss: 2.4765488834562523

Epoch: 5| Step: 8
Training loss: 1.9611159771554798
Validation loss: 2.5010037273573342

Epoch: 5| Step: 9
Training loss: 1.8525509670520572
Validation loss: 2.580967349274989

Epoch: 5| Step: 10
Training loss: 2.317607806022279
Validation loss: 2.4844032848892064

Epoch: 323| Step: 0
Training loss: 1.775539614360918
Validation loss: 2.493963022052016

Epoch: 5| Step: 1
Training loss: 2.066788578539505
Validation loss: 2.4846561897315778

Epoch: 5| Step: 2
Training loss: 1.8738117903585316
Validation loss: 2.481331622867568

Epoch: 5| Step: 3
Training loss: 2.5891454799617284
Validation loss: 2.522937821318801

Epoch: 5| Step: 4
Training loss: 1.841736421371659
Validation loss: 2.4330683921180993

Epoch: 5| Step: 5
Training loss: 2.319293276745817
Validation loss: 2.463188962167458

Epoch: 5| Step: 6
Training loss: 1.7051118932572202
Validation loss: 2.457925708138751

Epoch: 5| Step: 7
Training loss: 1.5991532230789485
Validation loss: 2.4856426688476665

Epoch: 5| Step: 8
Training loss: 2.03774081252218
Validation loss: 2.463084468646139

Epoch: 5| Step: 9
Training loss: 1.888451327649361
Validation loss: 2.423149884267735

Epoch: 5| Step: 10
Training loss: 2.63415520272621
Validation loss: 2.5006902275111367

Epoch: 324| Step: 0
Training loss: 1.8310257810218298
Validation loss: 2.5114379617672915

Epoch: 5| Step: 1
Training loss: 1.5965072118713943
Validation loss: 2.5260693955281774

Epoch: 5| Step: 2
Training loss: 2.3262895350963158
Validation loss: 2.4587720243519593

Epoch: 5| Step: 3
Training loss: 2.1059058024178636
Validation loss: 2.495869163757112

Epoch: 5| Step: 4
Training loss: 2.027237788318016
Validation loss: 2.4969151414614377

Epoch: 5| Step: 5
Training loss: 1.999365884868024
Validation loss: 2.472877245678473

Epoch: 5| Step: 6
Training loss: 2.0102583537910785
Validation loss: 2.513997375778314

Epoch: 5| Step: 7
Training loss: 2.042005147578134
Validation loss: 2.491347298434205

Epoch: 5| Step: 8
Training loss: 2.390561769933314
Validation loss: 2.47528219055123

Epoch: 5| Step: 9
Training loss: 2.1130112565440777
Validation loss: 2.501064750599469

Epoch: 5| Step: 10
Training loss: 1.668243457051347
Validation loss: 2.4963108345597584

Epoch: 325| Step: 0
Training loss: 2.6733328428133216
Validation loss: 2.499907856955667

Epoch: 5| Step: 1
Training loss: 1.4949128991209661
Validation loss: 2.506022283580006

Epoch: 5| Step: 2
Training loss: 1.914588077554508
Validation loss: 2.5417793433195897

Epoch: 5| Step: 3
Training loss: 1.8364146160505441
Validation loss: 2.4687172827961237

Epoch: 5| Step: 4
Training loss: 1.5736275218180114
Validation loss: 2.498004556892172

Epoch: 5| Step: 5
Training loss: 2.035134459981118
Validation loss: 2.473871081917989

Epoch: 5| Step: 6
Training loss: 2.1026709373920993
Validation loss: 2.487352330699498

Epoch: 5| Step: 7
Training loss: 1.596800484010474
Validation loss: 2.476811251160978

Epoch: 5| Step: 8
Training loss: 2.116009035851957
Validation loss: 2.471639442548104

Epoch: 5| Step: 9
Training loss: 2.3145847717701873
Validation loss: 2.534933511495913

Epoch: 5| Step: 10
Training loss: 2.178077020759784
Validation loss: 2.51961158598291

Epoch: 326| Step: 0
Training loss: 2.3131651050767488
Validation loss: 2.5031276693700253

Epoch: 5| Step: 1
Training loss: 1.5481842357405045
Validation loss: 2.4583015290363934

Epoch: 5| Step: 2
Training loss: 2.122210298319412
Validation loss: 2.4754033764815335

Epoch: 5| Step: 3
Training loss: 1.4089536320330909
Validation loss: 2.4898127939532317

Epoch: 5| Step: 4
Training loss: 2.086881159807307
Validation loss: 2.527295248845566

Epoch: 5| Step: 5
Training loss: 1.4323959127694337
Validation loss: 2.5130936820499348

Epoch: 5| Step: 6
Training loss: 2.119998768680143
Validation loss: 2.488213898280772

Epoch: 5| Step: 7
Training loss: 2.385043141356737
Validation loss: 2.465259139515138

Epoch: 5| Step: 8
Training loss: 2.337186957628432
Validation loss: 2.502463440660761

Epoch: 5| Step: 9
Training loss: 2.2648206664241677
Validation loss: 2.4842801031107657

Epoch: 5| Step: 10
Training loss: 1.8086568273498604
Validation loss: 2.493311515872995

Epoch: 327| Step: 0
Training loss: 1.9302970757407791
Validation loss: 2.459597632857201

Epoch: 5| Step: 1
Training loss: 1.6980860650994294
Validation loss: 2.4734778346396484

Epoch: 5| Step: 2
Training loss: 1.7172045608797601
Validation loss: 2.5052334116465755

Epoch: 5| Step: 3
Training loss: 1.710871865045637
Validation loss: 2.49066738712705

Epoch: 5| Step: 4
Training loss: 1.7588903216877414
Validation loss: 2.459866473408041

Epoch: 5| Step: 5
Training loss: 1.9183225596722224
Validation loss: 2.4618777139117225

Epoch: 5| Step: 6
Training loss: 1.935158576086107
Validation loss: 2.4864070602600448

Epoch: 5| Step: 7
Training loss: 1.881733312020691
Validation loss: 2.477364801920133

Epoch: 5| Step: 8
Training loss: 1.913869482156402
Validation loss: 2.481172676769279

Epoch: 5| Step: 9
Training loss: 2.966745121236383
Validation loss: 2.496267962230117

Epoch: 5| Step: 10
Training loss: 2.3433995302743384
Validation loss: 2.4722504862082646

Epoch: 328| Step: 0
Training loss: 2.1263284457726086
Validation loss: 2.5272411249459115

Epoch: 5| Step: 1
Training loss: 1.9737389945073083
Validation loss: 2.522959521255948

Epoch: 5| Step: 2
Training loss: 2.027468874089166
Validation loss: 2.4801049143041274

Epoch: 5| Step: 3
Training loss: 1.797540955905923
Validation loss: 2.4896042889371133

Epoch: 5| Step: 4
Training loss: 1.75822382882757
Validation loss: 2.492472065544541

Epoch: 5| Step: 5
Training loss: 2.6999671439538253
Validation loss: 2.483017070304063

Epoch: 5| Step: 6
Training loss: 1.7592035511558672
Validation loss: 2.458029269530496

Epoch: 5| Step: 7
Training loss: 2.0754324313059445
Validation loss: 2.502411240454656

Epoch: 5| Step: 8
Training loss: 1.893627966042775
Validation loss: 2.4998892031492828

Epoch: 5| Step: 9
Training loss: 1.804782485113649
Validation loss: 2.4661383355149904

Epoch: 5| Step: 10
Training loss: 2.3877262667344255
Validation loss: 2.4805313325957736

Epoch: 329| Step: 0
Training loss: 1.9522556659051074
Validation loss: 2.514721906468639

Epoch: 5| Step: 1
Training loss: 2.0568469633256607
Validation loss: 2.517378743842727

Epoch: 5| Step: 2
Training loss: 1.5960891611534622
Validation loss: 2.4634354807028216

Epoch: 5| Step: 3
Training loss: 1.8868739220286648
Validation loss: 2.4618186903086037

Epoch: 5| Step: 4
Training loss: 2.137468224004832
Validation loss: 2.4823209361672736

Epoch: 5| Step: 5
Training loss: 1.9246696684157338
Validation loss: 2.472650722833212

Epoch: 5| Step: 6
Training loss: 1.9231978415107356
Validation loss: 2.492825566625168

Epoch: 5| Step: 7
Training loss: 1.8139567604757652
Validation loss: 2.476260303607298

Epoch: 5| Step: 8
Training loss: 2.5506753475993995
Validation loss: 2.499134811284623

Epoch: 5| Step: 9
Training loss: 1.9750023515904587
Validation loss: 2.46469901412243

Epoch: 5| Step: 10
Training loss: 1.8682723465130129
Validation loss: 2.491242201603835

Epoch: 330| Step: 0
Training loss: 2.1573083464012828
Validation loss: 2.4886696353445887

Epoch: 5| Step: 1
Training loss: 1.9255279931604365
Validation loss: 2.4587964597948524

Epoch: 5| Step: 2
Training loss: 1.5087068109406758
Validation loss: 2.474874308023303

Epoch: 5| Step: 3
Training loss: 2.1777244122880295
Validation loss: 2.4860450928885967

Epoch: 5| Step: 4
Training loss: 1.6613080505837339
Validation loss: 2.48991796656153

Epoch: 5| Step: 5
Training loss: 2.14214221063398
Validation loss: 2.5323419923435546

Epoch: 5| Step: 6
Training loss: 1.9341368249741142
Validation loss: 2.4887505936063214

Epoch: 5| Step: 7
Training loss: 2.0995218232109223
Validation loss: 2.471224878601238

Epoch: 5| Step: 8
Training loss: 2.885680883179202
Validation loss: 2.5335611254598565

Epoch: 5| Step: 9
Training loss: 1.5050675305395353
Validation loss: 2.499086179664033

Epoch: 5| Step: 10
Training loss: 1.860178028733805
Validation loss: 2.5072566101766403

Epoch: 331| Step: 0
Training loss: 2.2671493137963727
Validation loss: 2.5122993380129346

Epoch: 5| Step: 1
Training loss: 2.0812361524883034
Validation loss: 2.4833446782671897

Epoch: 5| Step: 2
Training loss: 1.6045856506653189
Validation loss: 2.48449694194329

Epoch: 5| Step: 3
Training loss: 1.850370063369537
Validation loss: 2.4904929622421728

Epoch: 5| Step: 4
Training loss: 2.0709267910515967
Validation loss: 2.4626288786138244

Epoch: 5| Step: 5
Training loss: 1.9985686783317373
Validation loss: 2.4461176838524032

Epoch: 5| Step: 6
Training loss: 1.3243501761154604
Validation loss: 2.4675088319340794

Epoch: 5| Step: 7
Training loss: 1.900045647825707
Validation loss: 2.4755696085904497

Epoch: 5| Step: 8
Training loss: 2.112243510368709
Validation loss: 2.4590260520560228

Epoch: 5| Step: 9
Training loss: 2.178215815266802
Validation loss: 2.497397601351883

Epoch: 5| Step: 10
Training loss: 2.301625949997608
Validation loss: 2.450531890538367

Epoch: 332| Step: 0
Training loss: 1.9282101060580115
Validation loss: 2.4745918254720634

Epoch: 5| Step: 1
Training loss: 1.9982485851147769
Validation loss: 2.4872526381295827

Epoch: 5| Step: 2
Training loss: 2.2704012281770725
Validation loss: 2.4518320043596913

Epoch: 5| Step: 3
Training loss: 2.070243632772637
Validation loss: 2.504715184028728

Epoch: 5| Step: 4
Training loss: 1.7961728921903721
Validation loss: 2.486972778463296

Epoch: 5| Step: 5
Training loss: 1.8565344390263854
Validation loss: 2.4829044696701077

Epoch: 5| Step: 6
Training loss: 1.884281455987188
Validation loss: 2.515367473734331

Epoch: 5| Step: 7
Training loss: 2.2079465875315765
Validation loss: 2.4643155249891824

Epoch: 5| Step: 8
Training loss: 2.014164358423647
Validation loss: 2.514636852071652

Epoch: 5| Step: 9
Training loss: 1.9940675727697215
Validation loss: 2.4991915554420183

Epoch: 5| Step: 10
Training loss: 2.305083573785343
Validation loss: 2.490479366276052

Epoch: 333| Step: 0
Training loss: 1.3979666146206324
Validation loss: 2.474791014627576

Epoch: 5| Step: 1
Training loss: 2.3636946387543123
Validation loss: 2.5182835711250218

Epoch: 5| Step: 2
Training loss: 2.1728906246488826
Validation loss: 2.424843500134537

Epoch: 5| Step: 3
Training loss: 1.8976198798346064
Validation loss: 2.452503267423825

Epoch: 5| Step: 4
Training loss: 1.7708552714466188
Validation loss: 2.496762703325691

Epoch: 5| Step: 5
Training loss: 2.413015885611839
Validation loss: 2.497386569265222

Epoch: 5| Step: 6
Training loss: 2.3710734383783025
Validation loss: 2.4577465010466253

Epoch: 5| Step: 7
Training loss: 1.642716083334971
Validation loss: 2.491635597096479

Epoch: 5| Step: 8
Training loss: 1.6491451100615486
Validation loss: 2.457378554171591

Epoch: 5| Step: 9
Training loss: 2.2194292345137208
Validation loss: 2.4690877543974463

Epoch: 5| Step: 10
Training loss: 1.920948146221496
Validation loss: 2.4548955948982907

Epoch: 334| Step: 0
Training loss: 1.9478739837485204
Validation loss: 2.4389484204964735

Epoch: 5| Step: 1
Training loss: 2.012970588586713
Validation loss: 2.4697760094163788

Epoch: 5| Step: 2
Training loss: 2.293640766089404
Validation loss: 2.4844698292888414

Epoch: 5| Step: 3
Training loss: 2.104927517148158
Validation loss: 2.48658127997424

Epoch: 5| Step: 4
Training loss: 1.9629913152423881
Validation loss: 2.4616150730087956

Epoch: 5| Step: 5
Training loss: 1.8294436923502797
Validation loss: 2.4532210231506304

Epoch: 5| Step: 6
Training loss: 2.136021250915541
Validation loss: 2.4834413658005086

Epoch: 5| Step: 7
Training loss: 1.6897529115568548
Validation loss: 2.4793208539553335

Epoch: 5| Step: 8
Training loss: 2.3313066900074593
Validation loss: 2.4957039971522375

Epoch: 5| Step: 9
Training loss: 1.6610448276871344
Validation loss: 2.5041422848905706

Epoch: 5| Step: 10
Training loss: 2.0140672918933005
Validation loss: 2.466037151720358

Epoch: 335| Step: 0
Training loss: 1.4408032156048973
Validation loss: 2.5281779557403667

Epoch: 5| Step: 1
Training loss: 1.773472319273753
Validation loss: 2.526855233879885

Epoch: 5| Step: 2
Training loss: 1.9336263018093305
Validation loss: 2.493133444606281

Epoch: 5| Step: 3
Training loss: 1.9024919456080853
Validation loss: 2.5112498381581907

Epoch: 5| Step: 4
Training loss: 2.210939009702996
Validation loss: 2.4611942051246154

Epoch: 5| Step: 5
Training loss: 1.7399864491121395
Validation loss: 2.49422315299638

Epoch: 5| Step: 6
Training loss: 2.109546569628448
Validation loss: 2.4465373111519035

Epoch: 5| Step: 7
Training loss: 2.163497134836908
Validation loss: 2.469085085978723

Epoch: 5| Step: 8
Training loss: 2.01917173627699
Validation loss: 2.4482503530468724

Epoch: 5| Step: 9
Training loss: 1.897952987317779
Validation loss: 2.5032872440538045

Epoch: 5| Step: 10
Training loss: 2.50601474104897
Validation loss: 2.4680104901092554

Epoch: 336| Step: 0
Training loss: 2.2862573302137394
Validation loss: 2.530188568224737

Epoch: 5| Step: 1
Training loss: 1.647801136286571
Validation loss: 2.4802265033765343

Epoch: 5| Step: 2
Training loss: 2.464825178218465
Validation loss: 2.479450287851585

Epoch: 5| Step: 3
Training loss: 1.3594894361011884
Validation loss: 2.4663560214679663

Epoch: 5| Step: 4
Training loss: 2.140683138538159
Validation loss: 2.5083804022468077

Epoch: 5| Step: 5
Training loss: 1.4180190232457621
Validation loss: 2.470884606679275

Epoch: 5| Step: 6
Training loss: 1.729616596867298
Validation loss: 2.5031413277297876

Epoch: 5| Step: 7
Training loss: 2.027561065845471
Validation loss: 2.4800645388603657

Epoch: 5| Step: 8
Training loss: 1.6222218460506428
Validation loss: 2.489131684863505

Epoch: 5| Step: 9
Training loss: 2.4865923888675487
Validation loss: 2.4776197677697422

Epoch: 5| Step: 10
Training loss: 2.4051965166090485
Validation loss: 2.4649101427666684

Epoch: 337| Step: 0
Training loss: 1.7937917378849806
Validation loss: 2.484135448061244

Epoch: 5| Step: 1
Training loss: 1.6892210343426346
Validation loss: 2.4406602522896637

Epoch: 5| Step: 2
Training loss: 1.8979360915138062
Validation loss: 2.5223495651087737

Epoch: 5| Step: 3
Training loss: 2.2683684477469455
Validation loss: 2.483624968947535

Epoch: 5| Step: 4
Training loss: 2.328062223061708
Validation loss: 2.465273753287172

Epoch: 5| Step: 5
Training loss: 1.9687262639628171
Validation loss: 2.4904525982288024

Epoch: 5| Step: 6
Training loss: 1.5436348937824431
Validation loss: 2.543011201959379

Epoch: 5| Step: 7
Training loss: 1.840969899218975
Validation loss: 2.4635794697672333

Epoch: 5| Step: 8
Training loss: 2.114542191830249
Validation loss: 2.4806568030865037

Epoch: 5| Step: 9
Training loss: 2.145250877167696
Validation loss: 2.495611663132101

Epoch: 5| Step: 10
Training loss: 2.3359472982654035
Validation loss: 2.484195972879366

Epoch: 338| Step: 0
Training loss: 2.483541864775345
Validation loss: 2.485478660704896

Epoch: 5| Step: 1
Training loss: 1.988979973770367
Validation loss: 2.464350243895508

Epoch: 5| Step: 2
Training loss: 1.9585648122566213
Validation loss: 2.462924995516603

Epoch: 5| Step: 3
Training loss: 1.886085988593579
Validation loss: 2.4702729055155963

Epoch: 5| Step: 4
Training loss: 2.033851717964942
Validation loss: 2.446704659935518

Epoch: 5| Step: 5
Training loss: 2.1419453134118465
Validation loss: 2.4773665197301127

Epoch: 5| Step: 6
Training loss: 1.766341140134229
Validation loss: 2.4539338531395374

Epoch: 5| Step: 7
Training loss: 1.9462345496552385
Validation loss: 2.464360166168211

Epoch: 5| Step: 8
Training loss: 1.8788875967515477
Validation loss: 2.4922300012311314

Epoch: 5| Step: 9
Training loss: 2.198296199289252
Validation loss: 2.4609623139630004

Epoch: 5| Step: 10
Training loss: 1.4745455090163886
Validation loss: 2.4982463320849724

Epoch: 339| Step: 0
Training loss: 2.2670417302366803
Validation loss: 2.4856207287326266

Epoch: 5| Step: 1
Training loss: 2.212971321378654
Validation loss: 2.50157789867001

Epoch: 5| Step: 2
Training loss: 2.100435883834498
Validation loss: 2.493505957679359

Epoch: 5| Step: 3
Training loss: 2.065580321967123
Validation loss: 2.4977313233189444

Epoch: 5| Step: 4
Training loss: 2.275463551674691
Validation loss: 2.497434008842471

Epoch: 5| Step: 5
Training loss: 1.722660886451208
Validation loss: 2.5119106555150053

Epoch: 5| Step: 6
Training loss: 2.4016873587202947
Validation loss: 2.4944510513285345

Epoch: 5| Step: 7
Training loss: 1.9073463164048434
Validation loss: 2.4882447518607442

Epoch: 5| Step: 8
Training loss: 1.6721988257415084
Validation loss: 2.4595192974914473

Epoch: 5| Step: 9
Training loss: 1.3748479672391218
Validation loss: 2.4714888726343966

Epoch: 5| Step: 10
Training loss: 1.7444280065111637
Validation loss: 2.4838802789005654

Epoch: 340| Step: 0
Training loss: 2.220992016684772
Validation loss: 2.513691304635776

Epoch: 5| Step: 1
Training loss: 1.685716534294402
Validation loss: 2.489078786905982

Epoch: 5| Step: 2
Training loss: 2.0048088435423232
Validation loss: 2.5029239455145342

Epoch: 5| Step: 3
Training loss: 2.125423277043399
Validation loss: 2.453446568275209

Epoch: 5| Step: 4
Training loss: 1.9959261650311877
Validation loss: 2.458713934461344

Epoch: 5| Step: 5
Training loss: 2.000866940475745
Validation loss: 2.4829242061507424

Epoch: 5| Step: 6
Training loss: 2.1446515381366127
Validation loss: 2.44826761495264

Epoch: 5| Step: 7
Training loss: 2.4472268505632404
Validation loss: 2.4874236922696036

Epoch: 5| Step: 8
Training loss: 1.7129360701862297
Validation loss: 2.492368576523559

Epoch: 5| Step: 9
Training loss: 1.885981634930447
Validation loss: 2.5051683367237807

Epoch: 5| Step: 10
Training loss: 1.5777009450908315
Validation loss: 2.4673230060715774

Epoch: 341| Step: 0
Training loss: 1.889727103397295
Validation loss: 2.500011832711715

Epoch: 5| Step: 1
Training loss: 1.51087048607811
Validation loss: 2.4743384291534043

Epoch: 5| Step: 2
Training loss: 1.9687039808919682
Validation loss: 2.491441587606026

Epoch: 5| Step: 3
Training loss: 2.269237715997719
Validation loss: 2.4673796880223486

Epoch: 5| Step: 4
Training loss: 2.2344256842139876
Validation loss: 2.4866753261419454

Epoch: 5| Step: 5
Training loss: 1.7387613040822631
Validation loss: 2.4647748154939557

Epoch: 5| Step: 6
Training loss: 2.1849225800020986
Validation loss: 2.5002835061718365

Epoch: 5| Step: 7
Training loss: 1.8191254637882814
Validation loss: 2.4753973428028666

Epoch: 5| Step: 8
Training loss: 1.7040092202774395
Validation loss: 2.51744931332518

Epoch: 5| Step: 9
Training loss: 2.1557998187282963
Validation loss: 2.5254623846636357

Epoch: 5| Step: 10
Training loss: 2.2063451730230184
Validation loss: 2.4758261841184073

Epoch: 342| Step: 0
Training loss: 2.033203125
Validation loss: 2.505843057164418

Epoch: 5| Step: 1
Training loss: 1.6487823414902238
Validation loss: 2.484316286969621

Epoch: 5| Step: 2
Training loss: 1.4902204560396013
Validation loss: 2.500458169812343

Epoch: 5| Step: 3
Training loss: 1.7539031914427328
Validation loss: 2.482480293078971

Epoch: 5| Step: 4
Training loss: 1.8899289575979983
Validation loss: 2.5268611385992634

Epoch: 5| Step: 5
Training loss: 2.681839237512535
Validation loss: 2.460571422261414

Epoch: 5| Step: 6
Training loss: 1.6125905033706727
Validation loss: 2.514190641969464

Epoch: 5| Step: 7
Training loss: 2.2323712520917143
Validation loss: 2.510367698908398

Epoch: 5| Step: 8
Training loss: 1.8583822725748618
Validation loss: 2.4575500801293146

Epoch: 5| Step: 9
Training loss: 1.8773131407339034
Validation loss: 2.4577209651289005

Epoch: 5| Step: 10
Training loss: 2.349792219675385
Validation loss: 2.471385997661148

Epoch: 343| Step: 0
Training loss: 1.9000577566503545
Validation loss: 2.4669373517842508

Epoch: 5| Step: 1
Training loss: 1.6708423598403195
Validation loss: 2.4681464350892703

Epoch: 5| Step: 2
Training loss: 1.5525859641878892
Validation loss: 2.4353906661784124

Epoch: 5| Step: 3
Training loss: 2.112275792249197
Validation loss: 2.4539385981918516

Epoch: 5| Step: 4
Training loss: 2.2397036734489766
Validation loss: 2.406354710389231

Epoch: 5| Step: 5
Training loss: 1.822577642976824
Validation loss: 2.445868017959023

Epoch: 5| Step: 6
Training loss: 2.020595602098361
Validation loss: 2.4911238845433505

Epoch: 5| Step: 7
Training loss: 2.159779189797337
Validation loss: 2.470398865895144

Epoch: 5| Step: 8
Training loss: 1.5986559288856317
Validation loss: 2.500977342567374

Epoch: 5| Step: 9
Training loss: 2.431795732691105
Validation loss: 2.4935007903080337

Epoch: 5| Step: 10
Training loss: 2.0097528129147015
Validation loss: 2.479259601594225

Epoch: 344| Step: 0
Training loss: 1.478572224550316
Validation loss: 2.4638448282089374

Epoch: 5| Step: 1
Training loss: 1.9363219463656907
Validation loss: 2.5148030892929336

Epoch: 5| Step: 2
Training loss: 2.1715572865778054
Validation loss: 2.514110639556832

Epoch: 5| Step: 3
Training loss: 1.6740466123264606
Validation loss: 2.4683188397715408

Epoch: 5| Step: 4
Training loss: 1.890687232136128
Validation loss: 2.496749474181644

Epoch: 5| Step: 5
Training loss: 1.7974664792687647
Validation loss: 2.499739510285892

Epoch: 5| Step: 6
Training loss: 2.293562388218359
Validation loss: 2.5134355508356596

Epoch: 5| Step: 7
Training loss: 2.048366090881449
Validation loss: 2.5254724850608814

Epoch: 5| Step: 8
Training loss: 2.0799025197295062
Validation loss: 2.489226049721199

Epoch: 5| Step: 9
Training loss: 1.6049409541739807
Validation loss: 2.468253070481064

Epoch: 5| Step: 10
Training loss: 2.6082119662615053
Validation loss: 2.502162253620073

Epoch: 345| Step: 0
Training loss: 1.9437294765750428
Validation loss: 2.474709111244919

Epoch: 5| Step: 1
Training loss: 1.532378267615348
Validation loss: 2.4712474252791536

Epoch: 5| Step: 2
Training loss: 2.0315028106647475
Validation loss: 2.4710210772386176

Epoch: 5| Step: 3
Training loss: 2.109702077868067
Validation loss: 2.528358952568795

Epoch: 5| Step: 4
Training loss: 1.539868293926588
Validation loss: 2.4613435872785074

Epoch: 5| Step: 5
Training loss: 2.831697683750114
Validation loss: 2.463083160328387

Epoch: 5| Step: 6
Training loss: 1.7619746460059307
Validation loss: 2.4868645747557694

Epoch: 5| Step: 7
Training loss: 1.6421949595128584
Validation loss: 2.4526177853777917

Epoch: 5| Step: 8
Training loss: 2.3210059776903034
Validation loss: 2.5176807844908407

Epoch: 5| Step: 9
Training loss: 1.778102704329065
Validation loss: 2.4744627000093145

Epoch: 5| Step: 10
Training loss: 2.190783624715098
Validation loss: 2.4709434583373473

Epoch: 346| Step: 0
Training loss: 1.9954232061946329
Validation loss: 2.469589420911952

Epoch: 5| Step: 1
Training loss: 1.9641372897066443
Validation loss: 2.4333069598321915

Epoch: 5| Step: 2
Training loss: 2.1806213128716654
Validation loss: 2.431098651379792

Epoch: 5| Step: 3
Training loss: 2.0630757077443884
Validation loss: 2.4618212249786504

Epoch: 5| Step: 4
Training loss: 1.896705245288815
Validation loss: 2.4779677447362425

Epoch: 5| Step: 5
Training loss: 2.335965261645233
Validation loss: 2.507813503860775

Epoch: 5| Step: 6
Training loss: 1.4987125434680957
Validation loss: 2.509853720823614

Epoch: 5| Step: 7
Training loss: 1.8602110321552825
Validation loss: 2.479634266124445

Epoch: 5| Step: 8
Training loss: 2.1482197599179313
Validation loss: 2.494083932444313

Epoch: 5| Step: 9
Training loss: 1.6841585490870907
Validation loss: 2.5059209347406215

Epoch: 5| Step: 10
Training loss: 1.9775538917268065
Validation loss: 2.4915262248216017

Epoch: 347| Step: 0
Training loss: 1.974700291745058
Validation loss: 2.441002934176403

Epoch: 5| Step: 1
Training loss: 1.6222139096301116
Validation loss: 2.4883451547116526

Epoch: 5| Step: 2
Training loss: 2.0827762494720816
Validation loss: 2.4868636593407016

Epoch: 5| Step: 3
Training loss: 1.8198520585600264
Validation loss: 2.4785699337318596

Epoch: 5| Step: 4
Training loss: 1.6263907423406099
Validation loss: 2.4687023519100397

Epoch: 5| Step: 5
Training loss: 2.1400466471784227
Validation loss: 2.4495943651550833

Epoch: 5| Step: 6
Training loss: 2.4147895779761224
Validation loss: 2.4748184928079837

Epoch: 5| Step: 7
Training loss: 1.6578842593382235
Validation loss: 2.5071508448199977

Epoch: 5| Step: 8
Training loss: 1.8886528132521145
Validation loss: 2.4902971249901555

Epoch: 5| Step: 9
Training loss: 2.3348753692889703
Validation loss: 2.4945554718875123

Epoch: 5| Step: 10
Training loss: 1.9511189038300394
Validation loss: 2.4890517947132165

Epoch: 348| Step: 0
Training loss: 1.9999321091573092
Validation loss: 2.477144099997519

Epoch: 5| Step: 1
Training loss: 1.622319137532035
Validation loss: 2.503231292221622

Epoch: 5| Step: 2
Training loss: 1.7572250401820058
Validation loss: 2.504789219673943

Epoch: 5| Step: 3
Training loss: 2.11989530142877
Validation loss: 2.4587737541090395

Epoch: 5| Step: 4
Training loss: 1.8422214184616006
Validation loss: 2.4868328978997156

Epoch: 5| Step: 5
Training loss: 2.699733657415836
Validation loss: 2.488112972894916

Epoch: 5| Step: 6
Training loss: 1.7285630731482038
Validation loss: 2.4934956722762966

Epoch: 5| Step: 7
Training loss: 2.129644479408029
Validation loss: 2.5002035519579726

Epoch: 5| Step: 8
Training loss: 2.0682761488065777
Validation loss: 2.44959749226602

Epoch: 5| Step: 9
Training loss: 1.9307150633833419
Validation loss: 2.442902210949085

Epoch: 5| Step: 10
Training loss: 1.7286956176147945
Validation loss: 2.488918210618405

Epoch: 349| Step: 0
Training loss: 2.211531596348546
Validation loss: 2.4494029695753174

Epoch: 5| Step: 1
Training loss: 1.8777278131061235
Validation loss: 2.4535984820492676

Epoch: 5| Step: 2
Training loss: 1.9324909186304058
Validation loss: 2.4971293303431428

Epoch: 5| Step: 3
Training loss: 1.7680949261758403
Validation loss: 2.481957522792514

Epoch: 5| Step: 4
Training loss: 1.7550881530488815
Validation loss: 2.5211022915842536

Epoch: 5| Step: 5
Training loss: 2.200822750048292
Validation loss: 2.495837687468149

Epoch: 5| Step: 6
Training loss: 1.4743754018125679
Validation loss: 2.4697172212854466

Epoch: 5| Step: 7
Training loss: 2.5018291457560493
Validation loss: 2.497245964660364

Epoch: 5| Step: 8
Training loss: 2.2315058927430425
Validation loss: 2.5171656180458846

Epoch: 5| Step: 9
Training loss: 1.8941397665552486
Validation loss: 2.4900575945440284

Epoch: 5| Step: 10
Training loss: 1.766816606396668
Validation loss: 2.473320753303635

Epoch: 350| Step: 0
Training loss: 1.866579092332969
Validation loss: 2.4887877600573654

Epoch: 5| Step: 1
Training loss: 1.8888810997534327
Validation loss: 2.4707156438030866

Epoch: 5| Step: 2
Training loss: 1.9957014620332179
Validation loss: 2.4655904919832436

Epoch: 5| Step: 3
Training loss: 2.3172675810214973
Validation loss: 2.5011581312257762

Epoch: 5| Step: 4
Training loss: 2.1231894914581186
Validation loss: 2.496606778970739

Epoch: 5| Step: 5
Training loss: 2.127087185140392
Validation loss: 2.4426324825018573

Epoch: 5| Step: 6
Training loss: 1.9836393780022263
Validation loss: 2.4871551566511414

Epoch: 5| Step: 7
Training loss: 1.7488857536713287
Validation loss: 2.416197297516318

Epoch: 5| Step: 8
Training loss: 1.4428082189399343
Validation loss: 2.5311189731769885

Epoch: 5| Step: 9
Training loss: 2.284632852720217
Validation loss: 2.475484047817328

Epoch: 5| Step: 10
Training loss: 1.5180354662736388
Validation loss: 2.461999309736659

Epoch: 351| Step: 0
Training loss: 1.7616508792228736
Validation loss: 2.497947398342749

Epoch: 5| Step: 1
Training loss: 1.6156541124447306
Validation loss: 2.459317564230753

Epoch: 5| Step: 2
Training loss: 2.299186840607183
Validation loss: 2.4901833041489834

Epoch: 5| Step: 3
Training loss: 1.4758630135192332
Validation loss: 2.5154830371807217

Epoch: 5| Step: 4
Training loss: 2.2981823165589024
Validation loss: 2.4772040758653735

Epoch: 5| Step: 5
Training loss: 2.409976797981483
Validation loss: 2.502338372047004

Epoch: 5| Step: 6
Training loss: 2.038762797696136
Validation loss: 2.442558989452813

Epoch: 5| Step: 7
Training loss: 2.186634219363072
Validation loss: 2.4821707570264926

Epoch: 5| Step: 8
Training loss: 1.8405717514962587
Validation loss: 2.4819129409307283

Epoch: 5| Step: 9
Training loss: 1.694116829988027
Validation loss: 2.43532136325916

Epoch: 5| Step: 10
Training loss: 1.7897300307780635
Validation loss: 2.481221426501746

Epoch: 352| Step: 0
Training loss: 1.905258671377301
Validation loss: 2.4604924411703544

Epoch: 5| Step: 1
Training loss: 2.0803693540625208
Validation loss: 2.506075347656897

Epoch: 5| Step: 2
Training loss: 1.8724216535447697
Validation loss: 2.4730671448546273

Epoch: 5| Step: 3
Training loss: 2.3174636768840107
Validation loss: 2.489126845200288

Epoch: 5| Step: 4
Training loss: 1.926179361106422
Validation loss: 2.489910546162208

Epoch: 5| Step: 5
Training loss: 1.6850876696500803
Validation loss: 2.452556692937046

Epoch: 5| Step: 6
Training loss: 1.4438252813355505
Validation loss: 2.4550886538433945

Epoch: 5| Step: 7
Training loss: 2.248984319534696
Validation loss: 2.444677142525827

Epoch: 5| Step: 8
Training loss: 2.171999042728557
Validation loss: 2.5178817331364813

Epoch: 5| Step: 9
Training loss: 1.8479573365401945
Validation loss: 2.5028220215439467

Epoch: 5| Step: 10
Training loss: 1.868172230281413
Validation loss: 2.495942828061536

Epoch: 353| Step: 0
Training loss: 1.6538813225584434
Validation loss: 2.513587791726438

Epoch: 5| Step: 1
Training loss: 2.027487924259974
Validation loss: 2.4959167009934706

Epoch: 5| Step: 2
Training loss: 1.9065214495388925
Validation loss: 2.4686700505013275

Epoch: 5| Step: 3
Training loss: 2.088027421486226
Validation loss: 2.4770141926682823

Epoch: 5| Step: 4
Training loss: 1.6134430663304469
Validation loss: 2.44270071949463

Epoch: 5| Step: 5
Training loss: 2.195880639895522
Validation loss: 2.4301609864817317

Epoch: 5| Step: 6
Training loss: 2.3800879739482133
Validation loss: 2.468042415818495

Epoch: 5| Step: 7
Training loss: 2.1303883844094047
Validation loss: 2.4767066264323714

Epoch: 5| Step: 8
Training loss: 0.8081700786105012
Validation loss: 2.511009599359471

Epoch: 5| Step: 9
Training loss: 1.8308417193857807
Validation loss: 2.4587103549539497

Epoch: 5| Step: 10
Training loss: 2.416521024151964
Validation loss: 2.502035672978765

Epoch: 354| Step: 0
Training loss: 2.073435145062717
Validation loss: 2.445578030134148

Epoch: 5| Step: 1
Training loss: 1.3415982961510773
Validation loss: 2.4942608417437997

Epoch: 5| Step: 2
Training loss: 2.033498839641359
Validation loss: 2.461244261973002

Epoch: 5| Step: 3
Training loss: 1.497464261910194
Validation loss: 2.498619434675311

Epoch: 5| Step: 4
Training loss: 1.9406978919058229
Validation loss: 2.453160492808982

Epoch: 5| Step: 5
Training loss: 1.9669708205338958
Validation loss: 2.412650122379826

Epoch: 5| Step: 6
Training loss: 2.4975036555388526
Validation loss: 2.5061125906596593

Epoch: 5| Step: 7
Training loss: 2.1259496474237927
Validation loss: 2.4873308885382865

Epoch: 5| Step: 8
Training loss: 2.1690683136765774
Validation loss: 2.4425911491656094

Epoch: 5| Step: 9
Training loss: 1.8755216508641288
Validation loss: 2.496235574883576

Epoch: 5| Step: 10
Training loss: 1.654834502321009
Validation loss: 2.49087217466238

Epoch: 355| Step: 0
Training loss: 2.0255040989488022
Validation loss: 2.504868347936016

Epoch: 5| Step: 1
Training loss: 1.180317085465262
Validation loss: 2.4636641099514

Epoch: 5| Step: 2
Training loss: 2.4180469407856866
Validation loss: 2.4700098355149636

Epoch: 5| Step: 3
Training loss: 2.247542628816452
Validation loss: 2.485711707909988

Epoch: 5| Step: 4
Training loss: 1.553838450092414
Validation loss: 2.473527693689009

Epoch: 5| Step: 5
Training loss: 1.9741203691177869
Validation loss: 2.530244750968459

Epoch: 5| Step: 6
Training loss: 2.0820953760059013
Validation loss: 2.5534913104150787

Epoch: 5| Step: 7
Training loss: 1.8125860917264163
Validation loss: 2.4563075705373105

Epoch: 5| Step: 8
Training loss: 1.8323885115865601
Validation loss: 2.4754274924076958

Epoch: 5| Step: 9
Training loss: 1.5532299474492888
Validation loss: 2.5009334872324667

Epoch: 5| Step: 10
Training loss: 1.9243857877700896
Validation loss: 2.4734479950113872

Epoch: 356| Step: 0
Training loss: 1.5207264570890615
Validation loss: 2.548693250156014

Epoch: 5| Step: 1
Training loss: 1.5571788206859531
Validation loss: 2.5018059801085193

Epoch: 5| Step: 2
Training loss: 2.559900966159232
Validation loss: 2.4622411527418424

Epoch: 5| Step: 3
Training loss: 2.3543641899312364
Validation loss: 2.447006429881968

Epoch: 5| Step: 4
Training loss: 1.6901185946639752
Validation loss: 2.5070444635017144

Epoch: 5| Step: 5
Training loss: 1.946776119066269
Validation loss: 2.4714512520619345

Epoch: 5| Step: 6
Training loss: 1.6889636438679245
Validation loss: 2.5019662651507284

Epoch: 5| Step: 7
Training loss: 1.7404319916424051
Validation loss: 2.4746103690206

Epoch: 5| Step: 8
Training loss: 1.8355228036883953
Validation loss: 2.4849038954500173

Epoch: 5| Step: 9
Training loss: 2.010234396253546
Validation loss: 2.4752476964452192

Epoch: 5| Step: 10
Training loss: 2.21207272126893
Validation loss: 2.4668099197433673

Epoch: 357| Step: 0
Training loss: 1.6083060853590279
Validation loss: 2.461467103995144

Epoch: 5| Step: 1
Training loss: 1.709274668425283
Validation loss: 2.5044981134571374

Epoch: 5| Step: 2
Training loss: 1.8426870741263872
Validation loss: 2.4840947640201194

Epoch: 5| Step: 3
Training loss: 1.88463798446519
Validation loss: 2.463914556604247

Epoch: 5| Step: 4
Training loss: 1.8530713464390103
Validation loss: 2.444906171168522

Epoch: 5| Step: 5
Training loss: 1.8326480046933304
Validation loss: 2.4579608093403924

Epoch: 5| Step: 6
Training loss: 1.7808225687737276
Validation loss: 2.46218609130992

Epoch: 5| Step: 7
Training loss: 2.0349363475470468
Validation loss: 2.523945687045015

Epoch: 5| Step: 8
Training loss: 1.9496696118920454
Validation loss: 2.4938693977109594

Epoch: 5| Step: 9
Training loss: 2.3508101872608815
Validation loss: 2.4226890050775056

Epoch: 5| Step: 10
Training loss: 2.212932320292041
Validation loss: 2.464635635284387

Epoch: 358| Step: 0
Training loss: 1.921473205248556
Validation loss: 2.453246534325944

Epoch: 5| Step: 1
Training loss: 2.020626870321723
Validation loss: 2.4450289989692497

Epoch: 5| Step: 2
Training loss: 1.718144119283981
Validation loss: 2.490220714823579

Epoch: 5| Step: 3
Training loss: 2.083114142013348
Validation loss: 2.47991956606843

Epoch: 5| Step: 4
Training loss: 1.9954852764988658
Validation loss: 2.473977978838307

Epoch: 5| Step: 5
Training loss: 2.21845436813061
Validation loss: 2.5198141361638373

Epoch: 5| Step: 6
Training loss: 1.9119020686707198
Validation loss: 2.4911868580789296

Epoch: 5| Step: 7
Training loss: 2.2257343023509937
Validation loss: 2.4807866261090936

Epoch: 5| Step: 8
Training loss: 1.4695361853703757
Validation loss: 2.4774108439898237

Epoch: 5| Step: 9
Training loss: 1.837902170402432
Validation loss: 2.45029271591108

Epoch: 5| Step: 10
Training loss: 1.8024844640096669
Validation loss: 2.486824817803959

Epoch: 359| Step: 0
Training loss: 2.177167851269189
Validation loss: 2.4691346755256878

Epoch: 5| Step: 1
Training loss: 2.1114494013648364
Validation loss: 2.4835037248418605

Epoch: 5| Step: 2
Training loss: 2.161216544603348
Validation loss: 2.4577552566937824

Epoch: 5| Step: 3
Training loss: 1.9466063092076105
Validation loss: 2.4566300485848087

Epoch: 5| Step: 4
Training loss: 1.7364552711989192
Validation loss: 2.4821800431119776

Epoch: 5| Step: 5
Training loss: 1.6881230934694407
Validation loss: 2.5234191776017965

Epoch: 5| Step: 6
Training loss: 2.1032418840642366
Validation loss: 2.5142814091686327

Epoch: 5| Step: 7
Training loss: 1.7116161376616714
Validation loss: 2.479973821313293

Epoch: 5| Step: 8
Training loss: 1.740191286797341
Validation loss: 2.484736286211579

Epoch: 5| Step: 9
Training loss: 1.8960454493761096
Validation loss: 2.478314739788985

Epoch: 5| Step: 10
Training loss: 1.893461259540801
Validation loss: 2.508157024524628

Epoch: 360| Step: 0
Training loss: 1.9578279560084868
Validation loss: 2.4829880535976265

Epoch: 5| Step: 1
Training loss: 2.486429097057385
Validation loss: 2.4921944651205963

Epoch: 5| Step: 2
Training loss: 1.7032077314248835
Validation loss: 2.4791433407878887

Epoch: 5| Step: 3
Training loss: 1.9530747063837113
Validation loss: 2.5070473614771864

Epoch: 5| Step: 4
Training loss: 2.1288615650771985
Validation loss: 2.48769142085078

Epoch: 5| Step: 5
Training loss: 1.7716172072838667
Validation loss: 2.5389660939229763

Epoch: 5| Step: 6
Training loss: 1.993342584580012
Validation loss: 2.454877772857309

Epoch: 5| Step: 7
Training loss: 1.7803809739789132
Validation loss: 2.479193671177578

Epoch: 5| Step: 8
Training loss: 1.5993534391082092
Validation loss: 2.4818629177257203

Epoch: 5| Step: 9
Training loss: 1.8075613943729518
Validation loss: 2.4968947773509926

Epoch: 5| Step: 10
Training loss: 2.0880785751320023
Validation loss: 2.526938989309298

Epoch: 361| Step: 0
Training loss: 2.1373707336243988
Validation loss: 2.497815697631915

Epoch: 5| Step: 1
Training loss: 1.6530640387156725
Validation loss: 2.511258243925448

Epoch: 5| Step: 2
Training loss: 1.8565334116556453
Validation loss: 2.466016346016656

Epoch: 5| Step: 3
Training loss: 2.0481630887868874
Validation loss: 2.5092182249238406

Epoch: 5| Step: 4
Training loss: 2.1601712604021883
Validation loss: 2.4792726066154365

Epoch: 5| Step: 5
Training loss: 1.63928465814969
Validation loss: 2.447856014934222

Epoch: 5| Step: 6
Training loss: 2.381128935852755
Validation loss: 2.4438352332205553

Epoch: 5| Step: 7
Training loss: 1.7202695198476161
Validation loss: 2.445850679896804

Epoch: 5| Step: 8
Training loss: 2.2240585435599227
Validation loss: 2.4897596571669176

Epoch: 5| Step: 9
Training loss: 1.648881391447958
Validation loss: 2.4690533580514455

Epoch: 5| Step: 10
Training loss: 1.4217286925445614
Validation loss: 2.4685371642595926

Epoch: 362| Step: 0
Training loss: 2.172739858434884
Validation loss: 2.4656591603859517

Epoch: 5| Step: 1
Training loss: 2.2278273887955455
Validation loss: 2.4235104927043634

Epoch: 5| Step: 2
Training loss: 1.7028776216647088
Validation loss: 2.5013506189187065

Epoch: 5| Step: 3
Training loss: 1.8994992901428456
Validation loss: 2.4251616438998713

Epoch: 5| Step: 4
Training loss: 2.446740851494608
Validation loss: 2.4616516566729314

Epoch: 5| Step: 5
Training loss: 1.225381172977921
Validation loss: 2.4996520774502673

Epoch: 5| Step: 6
Training loss: 2.2112383418748953
Validation loss: 2.487567505807082

Epoch: 5| Step: 7
Training loss: 1.917600452621814
Validation loss: 2.504287239988363

Epoch: 5| Step: 8
Training loss: 1.8801512846036688
Validation loss: 2.46113389952473

Epoch: 5| Step: 9
Training loss: 1.672589158445803
Validation loss: 2.4683673116025586

Epoch: 5| Step: 10
Training loss: 1.793445000321238
Validation loss: 2.515900710078393

Epoch: 363| Step: 0
Training loss: 1.7092344962054793
Validation loss: 2.503993008047228

Epoch: 5| Step: 1
Training loss: 2.2149085518105034
Validation loss: 2.502662170324605

Epoch: 5| Step: 2
Training loss: 1.6712618264897587
Validation loss: 2.5000410732874028

Epoch: 5| Step: 3
Training loss: 1.6496576069549482
Validation loss: 2.4919458812787822

Epoch: 5| Step: 4
Training loss: 2.0413103246797846
Validation loss: 2.5006541575566703

Epoch: 5| Step: 5
Training loss: 2.112769327544963
Validation loss: 2.451483112312183

Epoch: 5| Step: 6
Training loss: 2.3062165958290737
Validation loss: 2.5124869815287316

Epoch: 5| Step: 7
Training loss: 1.5963135092340677
Validation loss: 2.4704431470558332

Epoch: 5| Step: 8
Training loss: 1.873605018488306
Validation loss: 2.4949349068474453

Epoch: 5| Step: 9
Training loss: 2.0526128818262737
Validation loss: 2.47194517926964

Epoch: 5| Step: 10
Training loss: 2.1960846435618624
Validation loss: 2.4651600842880965

Epoch: 364| Step: 0
Training loss: 1.3801030484715007
Validation loss: 2.467053404802189

Epoch: 5| Step: 1
Training loss: 1.9756994360972633
Validation loss: 2.461999936589583

Epoch: 5| Step: 2
Training loss: 1.9009095725234741
Validation loss: 2.4297464072963684

Epoch: 5| Step: 3
Training loss: 2.5041252433240895
Validation loss: 2.519129516391244

Epoch: 5| Step: 4
Training loss: 1.9773603796589336
Validation loss: 2.4856301499330273

Epoch: 5| Step: 5
Training loss: 1.8950287155954968
Validation loss: 2.472083442909649

Epoch: 5| Step: 6
Training loss: 1.8585117163238802
Validation loss: 2.4763935166419198

Epoch: 5| Step: 7
Training loss: 2.1565329324607685
Validation loss: 2.5169482675895045

Epoch: 5| Step: 8
Training loss: 1.7177266629060202
Validation loss: 2.518722198999777

Epoch: 5| Step: 9
Training loss: 1.8997434668776882
Validation loss: 2.526537629941765

Epoch: 5| Step: 10
Training loss: 1.7402523223944755
Validation loss: 2.4441305029152143

Epoch: 365| Step: 0
Training loss: 2.568751640969005
Validation loss: 2.456699166759639

Epoch: 5| Step: 1
Training loss: 1.6400246384560941
Validation loss: 2.481735557903984

Epoch: 5| Step: 2
Training loss: 1.5422115737597502
Validation loss: 2.4623597384090083

Epoch: 5| Step: 3
Training loss: 2.2932146450682964
Validation loss: 2.425323918791839

Epoch: 5| Step: 4
Training loss: 1.9518695305739404
Validation loss: 2.5210159230206983

Epoch: 5| Step: 5
Training loss: 1.8403284685682881
Validation loss: 2.4546696215548387

Epoch: 5| Step: 6
Training loss: 1.9461383828244432
Validation loss: 2.499099632891414

Epoch: 5| Step: 7
Training loss: 1.704770124829906
Validation loss: 2.4254015083243146

Epoch: 5| Step: 8
Training loss: 2.1547600947620604
Validation loss: 2.44538283860392

Epoch: 5| Step: 9
Training loss: 1.9373418681925265
Validation loss: 2.5019352785072937

Epoch: 5| Step: 10
Training loss: 1.6144916713496231
Validation loss: 2.5090511302993264

Epoch: 366| Step: 0
Training loss: 1.7986285733717622
Validation loss: 2.474191185831021

Epoch: 5| Step: 1
Training loss: 1.699630512026331
Validation loss: 2.4675411064664616

Epoch: 5| Step: 2
Training loss: 1.4418421967358583
Validation loss: 2.4832066059777755

Epoch: 5| Step: 3
Training loss: 1.87366590722166
Validation loss: 2.4820065938318896

Epoch: 5| Step: 4
Training loss: 2.0080734855154034
Validation loss: 2.493689025409796

Epoch: 5| Step: 5
Training loss: 2.758516994327859
Validation loss: 2.467402332177159

Epoch: 5| Step: 6
Training loss: 2.085728667017408
Validation loss: 2.5386208346204997

Epoch: 5| Step: 7
Training loss: 2.114263901910977
Validation loss: 2.50773455235729

Epoch: 5| Step: 8
Training loss: 1.7930084423583414
Validation loss: 2.4797865269444026

Epoch: 5| Step: 9
Training loss: 1.3760727685632794
Validation loss: 2.443131155716579

Epoch: 5| Step: 10
Training loss: 1.8177636109903492
Validation loss: 2.493977637238942

Epoch: 367| Step: 0
Training loss: 2.10761045897273
Validation loss: 2.4570446877767713

Epoch: 5| Step: 1
Training loss: 1.7379291306369358
Validation loss: 2.477462079830071

Epoch: 5| Step: 2
Training loss: 1.581228245521441
Validation loss: 2.460457732948565

Epoch: 5| Step: 3
Training loss: 2.122115926871121
Validation loss: 2.4789794512699985

Epoch: 5| Step: 4
Training loss: 2.1465728991427775
Validation loss: 2.450504630678641

Epoch: 5| Step: 5
Training loss: 1.7381086285206584
Validation loss: 2.4781768444982606

Epoch: 5| Step: 6
Training loss: 2.0221098443596603
Validation loss: 2.4842165190008147

Epoch: 5| Step: 7
Training loss: 1.7063275246247755
Validation loss: 2.483734747991263

Epoch: 5| Step: 8
Training loss: 2.2306804923917194
Validation loss: 2.46760353331225

Epoch: 5| Step: 9
Training loss: 2.3977075515981348
Validation loss: 2.471286107073173

Epoch: 5| Step: 10
Training loss: 1.0934347515829366
Validation loss: 2.4550877840120653

Epoch: 368| Step: 0
Training loss: 2.077516394962478
Validation loss: 2.5197578579466637

Epoch: 5| Step: 1
Training loss: 1.8222482236826572
Validation loss: 2.479890794304599

Epoch: 5| Step: 2
Training loss: 1.9587041287385336
Validation loss: 2.469075510796435

Epoch: 5| Step: 3
Training loss: 1.6528980957531707
Validation loss: 2.4739698847364466

Epoch: 5| Step: 4
Training loss: 1.703977808789924
Validation loss: 2.4508560689078216

Epoch: 5| Step: 5
Training loss: 2.126239415164281
Validation loss: 2.510451297744956

Epoch: 5| Step: 6
Training loss: 1.8148495145682366
Validation loss: 2.4990734916383257

Epoch: 5| Step: 7
Training loss: 1.5487439973359243
Validation loss: 2.4876138918403865

Epoch: 5| Step: 8
Training loss: 2.0474724516453406
Validation loss: 2.456476709367204

Epoch: 5| Step: 9
Training loss: 2.073180892692305
Validation loss: 2.5024649435237487

Epoch: 5| Step: 10
Training loss: 2.420735835761876
Validation loss: 2.4916431594904735

Epoch: 369| Step: 0
Training loss: 2.469390013583227
Validation loss: 2.5056566007010224

Epoch: 5| Step: 1
Training loss: 2.120152048380482
Validation loss: 2.4792203255403984

Epoch: 5| Step: 2
Training loss: 1.59540329991411
Validation loss: 2.430183115569089

Epoch: 5| Step: 3
Training loss: 1.7416664336476635
Validation loss: 2.5001882138723817

Epoch: 5| Step: 4
Training loss: 2.1483520490819084
Validation loss: 2.4859064120867034

Epoch: 5| Step: 5
Training loss: 1.946720578849332
Validation loss: 2.499832508670245

Epoch: 5| Step: 6
Training loss: 1.674565156317692
Validation loss: 2.5123579440289685

Epoch: 5| Step: 7
Training loss: 1.9346323017816394
Validation loss: 2.4885564879705835

Epoch: 5| Step: 8
Training loss: 1.6020681187866719
Validation loss: 2.5084436896492774

Epoch: 5| Step: 9
Training loss: 2.217244241753238
Validation loss: 2.531863999120772

Epoch: 5| Step: 10
Training loss: 1.5899381492388789
Validation loss: 2.4573791790734982

Epoch: 370| Step: 0
Training loss: 2.1676578333146406
Validation loss: 2.478078816423493

Epoch: 5| Step: 1
Training loss: 2.067997397356591
Validation loss: 2.534447535574895

Epoch: 5| Step: 2
Training loss: 2.4489363366073067
Validation loss: 2.4966864017026573

Epoch: 5| Step: 3
Training loss: 1.8076904545819763
Validation loss: 2.484769905741118

Epoch: 5| Step: 4
Training loss: 1.6988698316109125
Validation loss: 2.4804877245177845

Epoch: 5| Step: 5
Training loss: 2.102625808308365
Validation loss: 2.478039944007142

Epoch: 5| Step: 6
Training loss: 1.649131231185902
Validation loss: 2.4550303786398815

Epoch: 5| Step: 7
Training loss: 1.60251168757088
Validation loss: 2.473281860782271

Epoch: 5| Step: 8
Training loss: 1.759549516116073
Validation loss: 2.440889030814266

Epoch: 5| Step: 9
Training loss: 1.7848701498207626
Validation loss: 2.5341342114936656

Epoch: 5| Step: 10
Training loss: 1.8103287286622014
Validation loss: 2.4514289543670986

Epoch: 371| Step: 0
Training loss: 2.1275981278880476
Validation loss: 2.5144570631159744

Epoch: 5| Step: 1
Training loss: 1.5221446493590507
Validation loss: 2.4502847768854568

Epoch: 5| Step: 2
Training loss: 1.917783957473024
Validation loss: 2.4647702233973967

Epoch: 5| Step: 3
Training loss: 1.4892208307395987
Validation loss: 2.4995810003788224

Epoch: 5| Step: 4
Training loss: 1.8292909474249335
Validation loss: 2.4636323283392034

Epoch: 5| Step: 5
Training loss: 2.2840563091278203
Validation loss: 2.4669639499580094

Epoch: 5| Step: 6
Training loss: 2.0465891398223457
Validation loss: 2.462383735335274

Epoch: 5| Step: 7
Training loss: 2.276929866811379
Validation loss: 2.4829098903775124

Epoch: 5| Step: 8
Training loss: 1.5697449374906312
Validation loss: 2.4562972994944885

Epoch: 5| Step: 9
Training loss: 1.8955000140714129
Validation loss: 2.517341160358659

Epoch: 5| Step: 10
Training loss: 1.89388253028354
Validation loss: 2.504520330911759

Epoch: 372| Step: 0
Training loss: 2.3065122460437757
Validation loss: 2.414630461349349

Epoch: 5| Step: 1
Training loss: 1.4698814741346156
Validation loss: 2.477389105716078

Epoch: 5| Step: 2
Training loss: 2.6112280564689527
Validation loss: 2.5001173443070557

Epoch: 5| Step: 3
Training loss: 1.6308868588627272
Validation loss: 2.4658331388815906

Epoch: 5| Step: 4
Training loss: 1.1900568089428978
Validation loss: 2.4449616374787144

Epoch: 5| Step: 5
Training loss: 1.7349012109296542
Validation loss: 2.4611088904178473

Epoch: 5| Step: 6
Training loss: 1.7269417876928665
Validation loss: 2.4901044901385743

Epoch: 5| Step: 7
Training loss: 2.2251297473581455
Validation loss: 2.5173915677225485

Epoch: 5| Step: 8
Training loss: 1.6557566789771427
Validation loss: 2.4378171461509095

Epoch: 5| Step: 9
Training loss: 1.9260227137104686
Validation loss: 2.4696978899765853

Epoch: 5| Step: 10
Training loss: 1.9501740402413947
Validation loss: 2.439562305585294

Epoch: 373| Step: 0
Training loss: 1.7599573232071561
Validation loss: 2.448443627087563

Epoch: 5| Step: 1
Training loss: 2.2902451932815233
Validation loss: 2.443019189559871

Epoch: 5| Step: 2
Training loss: 1.8230781992233351
Validation loss: 2.4883654043749965

Epoch: 5| Step: 3
Training loss: 1.811944613374439
Validation loss: 2.5068170396961356

Epoch: 5| Step: 4
Training loss: 1.5773672418606868
Validation loss: 2.5276216201195014

Epoch: 5| Step: 5
Training loss: 1.8564274609955091
Validation loss: 2.4814100765236677

Epoch: 5| Step: 6
Training loss: 1.9798039330594188
Validation loss: 2.466048043886123

Epoch: 5| Step: 7
Training loss: 2.0228254062589146
Validation loss: 2.510281242877938

Epoch: 5| Step: 8
Training loss: 1.5472298417435475
Validation loss: 2.48039292696096

Epoch: 5| Step: 9
Training loss: 2.157147317573173
Validation loss: 2.5139871645235665

Epoch: 5| Step: 10
Training loss: 2.059950090377777
Validation loss: 2.493325785290476

Epoch: 374| Step: 0
Training loss: 1.8782125925466753
Validation loss: 2.499466748945641

Epoch: 5| Step: 1
Training loss: 2.300957198612393
Validation loss: 2.466035683314469

Epoch: 5| Step: 2
Training loss: 1.9489854814469165
Validation loss: 2.501362742974076

Epoch: 5| Step: 3
Training loss: 2.5368322348813983
Validation loss: 2.4773250084150815

Epoch: 5| Step: 4
Training loss: 1.936522021656221
Validation loss: 2.5245632305992363

Epoch: 5| Step: 5
Training loss: 1.788036602012587
Validation loss: 2.4816413513941713

Epoch: 5| Step: 6
Training loss: 1.4339228364089702
Validation loss: 2.481571944439656

Epoch: 5| Step: 7
Training loss: 1.9041412446420878
Validation loss: 2.526570164602286

Epoch: 5| Step: 8
Training loss: 2.10129134119906
Validation loss: 2.476567375602981

Epoch: 5| Step: 9
Training loss: 1.367691034506383
Validation loss: 2.483935383737969

Epoch: 5| Step: 10
Training loss: 1.7526850537646002
Validation loss: 2.4262173469556108

Epoch: 375| Step: 0
Training loss: 1.9054062023274512
Validation loss: 2.447094159695807

Epoch: 5| Step: 1
Training loss: 2.077503771175997
Validation loss: 2.5143802299158717

Epoch: 5| Step: 2
Training loss: 1.926790417928471
Validation loss: 2.4760173439431488

Epoch: 5| Step: 3
Training loss: 1.8256696204165712
Validation loss: 2.5311646259089002

Epoch: 5| Step: 4
Training loss: 1.8641775602529156
Validation loss: 2.4734524072361337

Epoch: 5| Step: 5
Training loss: 1.993574489892434
Validation loss: 2.493052061556097

Epoch: 5| Step: 6
Training loss: 2.2501788598071593
Validation loss: 2.491224587101373

Epoch: 5| Step: 7
Training loss: 1.662154343889877
Validation loss: 2.4784033639433103

Epoch: 5| Step: 8
Training loss: 1.8006892977260653
Validation loss: 2.477656690412993

Epoch: 5| Step: 9
Training loss: 1.9346637270007068
Validation loss: 2.468989167389364

Epoch: 5| Step: 10
Training loss: 2.1031526696934235
Validation loss: 2.4710329714258426

Epoch: 376| Step: 0
Training loss: 1.6982057555438421
Validation loss: 2.474515830642998

Epoch: 5| Step: 1
Training loss: 1.9656982990419576
Validation loss: 2.4557490540433213

Epoch: 5| Step: 2
Training loss: 1.8890196234520342
Validation loss: 2.5017045701076714

Epoch: 5| Step: 3
Training loss: 1.6204582715286515
Validation loss: 2.4662230250935937

Epoch: 5| Step: 4
Training loss: 1.807595622275636
Validation loss: 2.470442018010766

Epoch: 5| Step: 5
Training loss: 1.4755365753501073
Validation loss: 2.459353915215613

Epoch: 5| Step: 6
Training loss: 2.042412355706704
Validation loss: 2.536650236232133

Epoch: 5| Step: 7
Training loss: 2.220467882940697
Validation loss: 2.444824300016434

Epoch: 5| Step: 8
Training loss: 1.541417986771475
Validation loss: 2.501496094993684

Epoch: 5| Step: 9
Training loss: 2.414826701167929
Validation loss: 2.4570488863496154

Epoch: 5| Step: 10
Training loss: 1.830461557580133
Validation loss: 2.5011918190635343

Epoch: 377| Step: 0
Training loss: 2.0613168733111524
Validation loss: 2.4630944033036095

Epoch: 5| Step: 1
Training loss: 2.0869602167919177
Validation loss: 2.4897486303642773

Epoch: 5| Step: 2
Training loss: 1.8337179849712393
Validation loss: 2.5000320412007913

Epoch: 5| Step: 3
Training loss: 1.6891837726712375
Validation loss: 2.537997078199122

Epoch: 5| Step: 4
Training loss: 2.0015088588605265
Validation loss: 2.476342814623736

Epoch: 5| Step: 5
Training loss: 1.8408488709033073
Validation loss: 2.557966858228282

Epoch: 5| Step: 6
Training loss: 1.6447238401601758
Validation loss: 2.557017511383319

Epoch: 5| Step: 7
Training loss: 2.0069580634981232
Validation loss: 2.495782214729746

Epoch: 5| Step: 8
Training loss: 1.9901580646174477
Validation loss: 2.467433861587932

Epoch: 5| Step: 9
Training loss: 2.046072649765021
Validation loss: 2.499105822716035

Epoch: 5| Step: 10
Training loss: 1.826413453794696
Validation loss: 2.4998805673845244

Epoch: 378| Step: 0
Training loss: 2.2037707525478134
Validation loss: 2.4707500538423735

Epoch: 5| Step: 1
Training loss: 1.5611696301703604
Validation loss: 2.4980847405551163

Epoch: 5| Step: 2
Training loss: 1.554859094399322
Validation loss: 2.5026923622894692

Epoch: 5| Step: 3
Training loss: 1.8597014965978718
Validation loss: 2.4428485134227733

Epoch: 5| Step: 4
Training loss: 1.6738906545988799
Validation loss: 2.498631011264319

Epoch: 5| Step: 5
Training loss: 1.811583517471534
Validation loss: 2.5110913565140542

Epoch: 5| Step: 6
Training loss: 2.2974340057026845
Validation loss: 2.4921469576946698

Epoch: 5| Step: 7
Training loss: 1.9202783666918495
Validation loss: 2.4928593012497964

Epoch: 5| Step: 8
Training loss: 2.6439782695656375
Validation loss: 2.4645957225890056

Epoch: 5| Step: 9
Training loss: 1.8780621002378632
Validation loss: 2.429940792297413

Epoch: 5| Step: 10
Training loss: 1.740394867454646
Validation loss: 2.494727855497159

Epoch: 379| Step: 0
Training loss: 2.3408750066944095
Validation loss: 2.4519251845549386

Epoch: 5| Step: 1
Training loss: 1.5176803966805745
Validation loss: 2.5176955868178843

Epoch: 5| Step: 2
Training loss: 1.9767263593339541
Validation loss: 2.46207956019121

Epoch: 5| Step: 3
Training loss: 1.6485140091194068
Validation loss: 2.473380432679098

Epoch: 5| Step: 4
Training loss: 1.5756155022376885
Validation loss: 2.4957513937263025

Epoch: 5| Step: 5
Training loss: 1.7149423905419703
Validation loss: 2.4520982493359185

Epoch: 5| Step: 6
Training loss: 1.3814135873161961
Validation loss: 2.429346438460023

Epoch: 5| Step: 7
Training loss: 1.8900103870489908
Validation loss: 2.4929117559720027

Epoch: 5| Step: 8
Training loss: 1.9713563167370485
Validation loss: 2.482559986803078

Epoch: 5| Step: 9
Training loss: 2.3503695785799956
Validation loss: 2.5129386179832456

Epoch: 5| Step: 10
Training loss: 2.083362719010692
Validation loss: 2.5134004665215364

Epoch: 380| Step: 0
Training loss: 1.8852468874310875
Validation loss: 2.4657431032806016

Epoch: 5| Step: 1
Training loss: 2.297757349056693
Validation loss: 2.504996980655429

Epoch: 5| Step: 2
Training loss: 1.9080670561053357
Validation loss: 2.469720750585019

Epoch: 5| Step: 3
Training loss: 1.8264573144443936
Validation loss: 2.5155990233392527

Epoch: 5| Step: 4
Training loss: 1.3026270328890592
Validation loss: 2.5138977598441214

Epoch: 5| Step: 5
Training loss: 1.911451590904658
Validation loss: 2.4758176145642303

Epoch: 5| Step: 6
Training loss: 2.0388964589065335
Validation loss: 2.5263777693301837

Epoch: 5| Step: 7
Training loss: 2.210816073368862
Validation loss: 2.5416429627145485

Epoch: 5| Step: 8
Training loss: 1.8912670211883278
Validation loss: 2.4804917438847243

Epoch: 5| Step: 9
Training loss: 1.473628929542598
Validation loss: 2.543948961027435

Epoch: 5| Step: 10
Training loss: 1.9785840699538142
Validation loss: 2.4969300514908324

Epoch: 381| Step: 0
Training loss: 2.0879663323432154
Validation loss: 2.5244497391443717

Epoch: 5| Step: 1
Training loss: 1.7555155348474762
Validation loss: 2.482547595883658

Epoch: 5| Step: 2
Training loss: 2.5320900359093024
Validation loss: 2.465080507150166

Epoch: 5| Step: 3
Training loss: 1.5106762191681433
Validation loss: 2.4493342975822863

Epoch: 5| Step: 4
Training loss: 2.2432008374080645
Validation loss: 2.4359812626226076

Epoch: 5| Step: 5
Training loss: 1.8668489668020425
Validation loss: 2.5062247265339876

Epoch: 5| Step: 6
Training loss: 1.6387828111891904
Validation loss: 2.49848010714782

Epoch: 5| Step: 7
Training loss: 1.8144750029165755
Validation loss: 2.4457322743589662

Epoch: 5| Step: 8
Training loss: 2.0321897240324023
Validation loss: 2.4865871060923626

Epoch: 5| Step: 9
Training loss: 1.6985582493004117
Validation loss: 2.489659807682784

Epoch: 5| Step: 10
Training loss: 1.8623667138046744
Validation loss: 2.46726658466202

Epoch: 382| Step: 0
Training loss: 1.3152454363292938
Validation loss: 2.4785012620415205

Epoch: 5| Step: 1
Training loss: 1.4060378020510362
Validation loss: 2.4742200984755782

Epoch: 5| Step: 2
Training loss: 2.0105280342946155
Validation loss: 2.466923906581475

Epoch: 5| Step: 3
Training loss: 1.7627124901777274
Validation loss: 2.448531872887462

Epoch: 5| Step: 4
Training loss: 1.607396214814551
Validation loss: 2.480025942817579

Epoch: 5| Step: 5
Training loss: 1.75600927474716
Validation loss: 2.4987597609061756

Epoch: 5| Step: 6
Training loss: 2.1441085204231323
Validation loss: 2.462329004011154

Epoch: 5| Step: 7
Training loss: 2.5943075293229327
Validation loss: 2.512231092368572

Epoch: 5| Step: 8
Training loss: 1.957686263244139
Validation loss: 2.415859974262885

Epoch: 5| Step: 9
Training loss: 1.8585753444355178
Validation loss: 2.4852953038423165

Epoch: 5| Step: 10
Training loss: 1.954953977623633
Validation loss: 2.486924891413016

Epoch: 383| Step: 0
Training loss: 1.8817777837488912
Validation loss: 2.5017947850610898

Epoch: 5| Step: 1
Training loss: 1.3078492281369871
Validation loss: 2.510600357030912

Epoch: 5| Step: 2
Training loss: 1.7313409333843826
Validation loss: 2.4561224884432376

Epoch: 5| Step: 3
Training loss: 2.64970993037897
Validation loss: 2.4860964725176693

Epoch: 5| Step: 4
Training loss: 1.486673202257944
Validation loss: 2.465900589870682

Epoch: 5| Step: 5
Training loss: 2.030532710266786
Validation loss: 2.4745846999552428

Epoch: 5| Step: 6
Training loss: 1.9090361948553574
Validation loss: 2.432120209607801

Epoch: 5| Step: 7
Training loss: 2.1874362391307436
Validation loss: 2.4798681732116172

Epoch: 5| Step: 8
Training loss: 1.7768089747498084
Validation loss: 2.438921535713926

Epoch: 5| Step: 9
Training loss: 1.434059171458721
Validation loss: 2.4696825664098365

Epoch: 5| Step: 10
Training loss: 1.809671760428715
Validation loss: 2.4626111349210533

Epoch: 384| Step: 0
Training loss: 2.2817010303005967
Validation loss: 2.5202808976534006

Epoch: 5| Step: 1
Training loss: 1.454605332951897
Validation loss: 2.5372190269491477

Epoch: 5| Step: 2
Training loss: 1.824081448405435
Validation loss: 2.455797985887618

Epoch: 5| Step: 3
Training loss: 2.2717566290114615
Validation loss: 2.452079482744689

Epoch: 5| Step: 4
Training loss: 2.2357589597082077
Validation loss: 2.4856305707379045

Epoch: 5| Step: 5
Training loss: 1.6798468225901828
Validation loss: 2.4905245451955995

Epoch: 5| Step: 6
Training loss: 1.836614086393123
Validation loss: 2.5146860224886547

Epoch: 5| Step: 7
Training loss: 1.3233933028190177
Validation loss: 2.4707023561265617

Epoch: 5| Step: 8
Training loss: 1.930729511330588
Validation loss: 2.4193905300153395

Epoch: 5| Step: 9
Training loss: 1.5956754833801572
Validation loss: 2.431030590164692

Epoch: 5| Step: 10
Training loss: 1.8449765667551472
Validation loss: 2.52467305123571

Epoch: 385| Step: 0
Training loss: 2.1508237591362502
Validation loss: 2.4400249389585666

Epoch: 5| Step: 1
Training loss: 1.660361674445924
Validation loss: 2.5093327776545578

Epoch: 5| Step: 2
Training loss: 2.0728194119691734
Validation loss: 2.45676461508048

Epoch: 5| Step: 3
Training loss: 1.9193888144460225
Validation loss: 2.4965561321620227

Epoch: 5| Step: 4
Training loss: 1.6509780470406936
Validation loss: 2.5001064329153992

Epoch: 5| Step: 5
Training loss: 1.6634768319518831
Validation loss: 2.449367646301545

Epoch: 5| Step: 6
Training loss: 2.193491550447543
Validation loss: 2.471843792910855

Epoch: 5| Step: 7
Training loss: 1.9936275887056039
Validation loss: 2.516109654511297

Epoch: 5| Step: 8
Training loss: 1.5722715389543278
Validation loss: 2.459749808238927

Epoch: 5| Step: 9
Training loss: 1.9228661935229292
Validation loss: 2.4693747275565805

Epoch: 5| Step: 10
Training loss: 1.6825344355376564
Validation loss: 2.474534432259537

Epoch: 386| Step: 0
Training loss: 2.1826929953977046
Validation loss: 2.484122989663542

Epoch: 5| Step: 1
Training loss: 1.527909586258666
Validation loss: 2.4626713533375826

Epoch: 5| Step: 2
Training loss: 2.150574221556158
Validation loss: 2.474392482484645

Epoch: 5| Step: 3
Training loss: 1.7671217524189764
Validation loss: 2.421616256817372

Epoch: 5| Step: 4
Training loss: 2.045766282649985
Validation loss: 2.462679080667726

Epoch: 5| Step: 5
Training loss: 1.9627283437270506
Validation loss: 2.4789513997483748

Epoch: 5| Step: 6
Training loss: 1.7719401621736481
Validation loss: 2.503070598619134

Epoch: 5| Step: 7
Training loss: 1.7056342023277642
Validation loss: 2.4830779708326562

Epoch: 5| Step: 8
Training loss: 2.376046803318499
Validation loss: 2.455017076031971

Epoch: 5| Step: 9
Training loss: 1.5394235565048435
Validation loss: 2.4614660614442134

Epoch: 5| Step: 10
Training loss: 1.907661603229119
Validation loss: 2.502368064896115

Epoch: 387| Step: 0
Training loss: 1.5537832879868485
Validation loss: 2.4748881036616166

Epoch: 5| Step: 1
Training loss: 1.6240438435936102
Validation loss: 2.492554382400078

Epoch: 5| Step: 2
Training loss: 1.9613617213991406
Validation loss: 2.4566218065348036

Epoch: 5| Step: 3
Training loss: 2.1641056868998487
Validation loss: 2.4784278840845957

Epoch: 5| Step: 4
Training loss: 2.0878779497466633
Validation loss: 2.4961378536654184

Epoch: 5| Step: 5
Training loss: 2.2732564847529173
Validation loss: 2.478195093808447

Epoch: 5| Step: 6
Training loss: 1.800458171601203
Validation loss: 2.5183127980541817

Epoch: 5| Step: 7
Training loss: 1.926951271549604
Validation loss: 2.4862055124014826

Epoch: 5| Step: 8
Training loss: 1.4040220625738806
Validation loss: 2.479451196698081

Epoch: 5| Step: 9
Training loss: 2.012670199382386
Validation loss: 2.540391829901535

Epoch: 5| Step: 10
Training loss: 2.132527650249147
Validation loss: 2.4947950190286265

Epoch: 388| Step: 0
Training loss: 2.4170469335655933
Validation loss: 2.5067503619026983

Epoch: 5| Step: 1
Training loss: 1.9282061493303007
Validation loss: 2.4346702289984963

Epoch: 5| Step: 2
Training loss: 2.09502053498831
Validation loss: 2.4481513248432214

Epoch: 5| Step: 3
Training loss: 1.9726861026129165
Validation loss: 2.5070209768923686

Epoch: 5| Step: 4
Training loss: 1.8709830169722503
Validation loss: 2.465492704078388

Epoch: 5| Step: 5
Training loss: 1.743944112166578
Validation loss: 2.4696108354486883

Epoch: 5| Step: 6
Training loss: 1.7497758721832792
Validation loss: 2.473223747859751

Epoch: 5| Step: 7
Training loss: 1.8312937994917045
Validation loss: 2.4555699256117114

Epoch: 5| Step: 8
Training loss: 1.6163962819754045
Validation loss: 2.5098285669550338

Epoch: 5| Step: 9
Training loss: 1.9240816055843681
Validation loss: 2.4900010617860073

Epoch: 5| Step: 10
Training loss: 1.3968669234006057
Validation loss: 2.430202157794966

Epoch: 389| Step: 0
Training loss: 1.7604532031118236
Validation loss: 2.4984019730072338

Epoch: 5| Step: 1
Training loss: 1.2849443719007427
Validation loss: 2.480330645781552

Epoch: 5| Step: 2
Training loss: 1.8556531312582596
Validation loss: 2.492503749930865

Epoch: 5| Step: 3
Training loss: 1.6721384429151733
Validation loss: 2.486731922650764

Epoch: 5| Step: 4
Training loss: 2.037084328779993
Validation loss: 2.480729061023356

Epoch: 5| Step: 5
Training loss: 2.1378541262672144
Validation loss: 2.517950943551929

Epoch: 5| Step: 6
Training loss: 2.0408082701562953
Validation loss: 2.4741862454485544

Epoch: 5| Step: 7
Training loss: 1.6191108802115541
Validation loss: 2.4608646900964826

Epoch: 5| Step: 8
Training loss: 2.441076051889244
Validation loss: 2.4709420701420317

Epoch: 5| Step: 9
Training loss: 1.9657123685745066
Validation loss: 2.462419596504031

Epoch: 5| Step: 10
Training loss: 1.681272601574853
Validation loss: 2.4530571888411346

Epoch: 390| Step: 0
Training loss: 2.2920130959115035
Validation loss: 2.454887403417261

Epoch: 5| Step: 1
Training loss: 1.8121161876631813
Validation loss: 2.467158935587676

Epoch: 5| Step: 2
Training loss: 2.208309701277285
Validation loss: 2.5177638951153294

Epoch: 5| Step: 3
Training loss: 1.6371219839321833
Validation loss: 2.4545621615706135

Epoch: 5| Step: 4
Training loss: 1.8166542458182535
Validation loss: 2.3935635098047956

Epoch: 5| Step: 5
Training loss: 1.865007156992416
Validation loss: 2.509240828669259

Epoch: 5| Step: 6
Training loss: 2.2352930063799996
Validation loss: 2.4583511796835014

Epoch: 5| Step: 7
Training loss: 1.6297365994979944
Validation loss: 2.447512236947752

Epoch: 5| Step: 8
Training loss: 1.6235434533387612
Validation loss: 2.5084578872950405

Epoch: 5| Step: 9
Training loss: 1.6469700505371472
Validation loss: 2.4349126301391673

Epoch: 5| Step: 10
Training loss: 1.4123028929926755
Validation loss: 2.4561437432749664

Epoch: 391| Step: 0
Training loss: 1.9075778026387593
Validation loss: 2.4755371047510923

Epoch: 5| Step: 1
Training loss: 1.5836139062277153
Validation loss: 2.465956388097996

Epoch: 5| Step: 2
Training loss: 1.7617102240041056
Validation loss: 2.4712114774738003

Epoch: 5| Step: 3
Training loss: 1.631417878965069
Validation loss: 2.442937954074974

Epoch: 5| Step: 4
Training loss: 2.0752015165348436
Validation loss: 2.4501369847368206

Epoch: 5| Step: 5
Training loss: 1.7929837760212555
Validation loss: 2.52146365825208

Epoch: 5| Step: 6
Training loss: 1.8487020037277604
Validation loss: 2.4755380492086845

Epoch: 5| Step: 7
Training loss: 1.4343112740250241
Validation loss: 2.4877111873681463

Epoch: 5| Step: 8
Training loss: 2.566487071537026
Validation loss: 2.5059629984489655

Epoch: 5| Step: 9
Training loss: 2.048078343427778
Validation loss: 2.4856447532645527

Epoch: 5| Step: 10
Training loss: 1.9636387552261239
Validation loss: 2.5009701815192447

Epoch: 392| Step: 0
Training loss: 2.1884665397472407
Validation loss: 2.49327142472713

Epoch: 5| Step: 1
Training loss: 1.9859800080582952
Validation loss: 2.4936798932119832

Epoch: 5| Step: 2
Training loss: 1.6093872958704287
Validation loss: 2.4669571619692063

Epoch: 5| Step: 3
Training loss: 1.710719125128186
Validation loss: 2.4837036154343224

Epoch: 5| Step: 4
Training loss: 2.0414816584420667
Validation loss: 2.469297558358373

Epoch: 5| Step: 5
Training loss: 1.5294275922193632
Validation loss: 2.438330852385686

Epoch: 5| Step: 6
Training loss: 1.9011666731472265
Validation loss: 2.462014914370121

Epoch: 5| Step: 7
Training loss: 1.6729753385004187
Validation loss: 2.4928167433869715

Epoch: 5| Step: 8
Training loss: 1.9124117837145096
Validation loss: 2.4584082979091

Epoch: 5| Step: 9
Training loss: 1.603739677508963
Validation loss: 2.455405936894311

Epoch: 5| Step: 10
Training loss: 2.2347698796402975
Validation loss: 2.4733275839455717

Epoch: 393| Step: 0
Training loss: 1.970153974044227
Validation loss: 2.501872302948281

Epoch: 5| Step: 1
Training loss: 1.7902749296918217
Validation loss: 2.507952987533037

Epoch: 5| Step: 2
Training loss: 2.1252680216789006
Validation loss: 2.442504347092651

Epoch: 5| Step: 3
Training loss: 1.4318756701610633
Validation loss: 2.5093318351893132

Epoch: 5| Step: 4
Training loss: 1.9280770566349317
Validation loss: 2.4746086860745975

Epoch: 5| Step: 5
Training loss: 1.7778480568875694
Validation loss: 2.4290839782644125

Epoch: 5| Step: 6
Training loss: 1.4695437295435516
Validation loss: 2.4092807293428815

Epoch: 5| Step: 7
Training loss: 2.229535069431287
Validation loss: 2.4601519514399364

Epoch: 5| Step: 8
Training loss: 1.9835942452044355
Validation loss: 2.481017513743063

Epoch: 5| Step: 9
Training loss: 1.7576533944921215
Validation loss: 2.480137154646558

Epoch: 5| Step: 10
Training loss: 1.645368204505182
Validation loss: 2.473974545765179

Epoch: 394| Step: 0
Training loss: 1.58698377250735
Validation loss: 2.4480843917019324

Epoch: 5| Step: 1
Training loss: 1.6423044963359574
Validation loss: 2.4708257110793

Epoch: 5| Step: 2
Training loss: 1.3558094574870363
Validation loss: 2.447539873694671

Epoch: 5| Step: 3
Training loss: 1.968063476996437
Validation loss: 2.4640690289523235

Epoch: 5| Step: 4
Training loss: 1.844413637889575
Validation loss: 2.47548446413326

Epoch: 5| Step: 5
Training loss: 2.494578777831759
Validation loss: 2.484273309807001

Epoch: 5| Step: 6
Training loss: 1.5941746463898296
Validation loss: 2.5302337769897854

Epoch: 5| Step: 7
Training loss: 1.9164181285541335
Validation loss: 2.496009565522473

Epoch: 5| Step: 8
Training loss: 1.990931575049615
Validation loss: 2.4993603954646444

Epoch: 5| Step: 9
Training loss: 1.974711158008243
Validation loss: 2.460332176400828

Epoch: 5| Step: 10
Training loss: 1.9204769476927503
Validation loss: 2.4644301358858156

Epoch: 395| Step: 0
Training loss: 1.3940314671564715
Validation loss: 2.470124573993953

Epoch: 5| Step: 1
Training loss: 1.7793595170049883
Validation loss: 2.533346122791452

Epoch: 5| Step: 2
Training loss: 1.8957180435282226
Validation loss: 2.4399675385359862

Epoch: 5| Step: 3
Training loss: 2.4955293736717263
Validation loss: 2.4766999727964647

Epoch: 5| Step: 4
Training loss: 1.7472814834253716
Validation loss: 2.4908243996319004

Epoch: 5| Step: 5
Training loss: 2.506323066083954
Validation loss: 2.4507367367423503

Epoch: 5| Step: 6
Training loss: 1.537506401234769
Validation loss: 2.4876210748479624

Epoch: 5| Step: 7
Training loss: 1.3645781548477027
Validation loss: 2.452159075105166

Epoch: 5| Step: 8
Training loss: 1.8687461827471987
Validation loss: 2.477188828742987

Epoch: 5| Step: 9
Training loss: 1.8299690140774298
Validation loss: 2.4585812139357532

Epoch: 5| Step: 10
Training loss: 1.6182548207423815
Validation loss: 2.4996407814775146

Epoch: 396| Step: 0
Training loss: 1.8118607939537932
Validation loss: 2.478572736744234

Epoch: 5| Step: 1
Training loss: 1.5518341717858941
Validation loss: 2.5076650763312553

Epoch: 5| Step: 2
Training loss: 1.7204685289408603
Validation loss: 2.482342823343775

Epoch: 5| Step: 3
Training loss: 1.8816366995876832
Validation loss: 2.505033109861729

Epoch: 5| Step: 4
Training loss: 2.199520219158834
Validation loss: 2.4863414487746045

Epoch: 5| Step: 5
Training loss: 1.6675919904599321
Validation loss: 2.5146878075755876

Epoch: 5| Step: 6
Training loss: 1.7050914086592381
Validation loss: 2.518997435743258

Epoch: 5| Step: 7
Training loss: 1.8910722439994583
Validation loss: 2.453383675141126

Epoch: 5| Step: 8
Training loss: 2.0261989293848788
Validation loss: 2.5027488178484902

Epoch: 5| Step: 9
Training loss: 1.7656210165063264
Validation loss: 2.4937484933652914

Epoch: 5| Step: 10
Training loss: 2.085247254199132
Validation loss: 2.4474183487591956

Epoch: 397| Step: 0
Training loss: 1.6475773596654433
Validation loss: 2.4790262182679355

Epoch: 5| Step: 1
Training loss: 1.8335271068240961
Validation loss: 2.4862003123272407

Epoch: 5| Step: 2
Training loss: 1.6477876801613738
Validation loss: 2.4459480791895496

Epoch: 5| Step: 3
Training loss: 1.624919742656376
Validation loss: 2.454694465458186

Epoch: 5| Step: 4
Training loss: 1.7621784160316964
Validation loss: 2.4739776648568697

Epoch: 5| Step: 5
Training loss: 2.01192009668211
Validation loss: 2.456456245881934

Epoch: 5| Step: 6
Training loss: 1.633969275915251
Validation loss: 2.4699925278352204

Epoch: 5| Step: 7
Training loss: 1.9107181526114394
Validation loss: 2.511384420972461

Epoch: 5| Step: 8
Training loss: 2.2345302501175017
Validation loss: 2.4576700249735044

Epoch: 5| Step: 9
Training loss: 1.923825646413378
Validation loss: 2.4554909026680716

Epoch: 5| Step: 10
Training loss: 1.9142003846620606
Validation loss: 2.4505258238674923

Epoch: 398| Step: 0
Training loss: 1.675554522490977
Validation loss: 2.4534851169391776

Epoch: 5| Step: 1
Training loss: 1.7011991338812416
Validation loss: 2.49536979807228

Epoch: 5| Step: 2
Training loss: 2.0057740309406245
Validation loss: 2.423411722989545

Epoch: 5| Step: 3
Training loss: 1.8029976070893838
Validation loss: 2.4718057338388064

Epoch: 5| Step: 4
Training loss: 1.6089751848781226
Validation loss: 2.4326810411601234

Epoch: 5| Step: 5
Training loss: 1.6718506142807579
Validation loss: 2.449183953716068

Epoch: 5| Step: 6
Training loss: 1.9538976743098866
Validation loss: 2.477860953204757

Epoch: 5| Step: 7
Training loss: 1.918028789753682
Validation loss: 2.4986008953996404

Epoch: 5| Step: 8
Training loss: 2.0414000226760525
Validation loss: 2.469610234403339

Epoch: 5| Step: 9
Training loss: 1.4408135578275907
Validation loss: 2.510774194741193

Epoch: 5| Step: 10
Training loss: 2.43251858836459
Validation loss: 2.4576952380571653

Epoch: 399| Step: 0
Training loss: 1.808131577037739
Validation loss: 2.4991938142261105

Epoch: 5| Step: 1
Training loss: 1.8527147273148465
Validation loss: 2.4322332545717007

Epoch: 5| Step: 2
Training loss: 2.120403479561778
Validation loss: 2.4524951703935756

Epoch: 5| Step: 3
Training loss: 1.898319130806157
Validation loss: 2.4990890689160064

Epoch: 5| Step: 4
Training loss: 1.9183807862768032
Validation loss: 2.461691901408059

Epoch: 5| Step: 5
Training loss: 1.657441412464206
Validation loss: 2.4254291116279307

Epoch: 5| Step: 6
Training loss: 2.20312337672397
Validation loss: 2.465896772321938

Epoch: 5| Step: 7
Training loss: 1.8839327696570727
Validation loss: 2.506558898959769

Epoch: 5| Step: 8
Training loss: 1.7627034279591576
Validation loss: 2.4490769533278183

Epoch: 5| Step: 9
Training loss: 1.8132813841142978
Validation loss: 2.495947762356225

Epoch: 5| Step: 10
Training loss: 1.2592318091382173
Validation loss: 2.5367287748961163

Epoch: 400| Step: 0
Training loss: 1.9363039077928186
Validation loss: 2.472257317733333

Epoch: 5| Step: 1
Training loss: 2.0911436797463874
Validation loss: 2.5433715382359257

Epoch: 5| Step: 2
Training loss: 1.8602503150762295
Validation loss: 2.4320731161783256

Epoch: 5| Step: 3
Training loss: 1.6426526573226772
Validation loss: 2.498566067578847

Epoch: 5| Step: 4
Training loss: 1.9593192790746268
Validation loss: 2.416094059375258

Epoch: 5| Step: 5
Training loss: 1.8918073125752548
Validation loss: 2.4697826318814378

Epoch: 5| Step: 6
Training loss: 2.0317494878663838
Validation loss: 2.4628348400684557

Epoch: 5| Step: 7
Training loss: 1.5271041174806061
Validation loss: 2.5455488915662046

Epoch: 5| Step: 8
Training loss: 2.1045637857600132
Validation loss: 2.497446805281606

Epoch: 5| Step: 9
Training loss: 1.356292650105914
Validation loss: 2.4380340033299195

Epoch: 5| Step: 10
Training loss: 1.6633759277689752
Validation loss: 2.5008493949394395

Epoch: 401| Step: 0
Training loss: 1.872725378613806
Validation loss: 2.454051743346323

Epoch: 5| Step: 1
Training loss: 1.6792636780209458
Validation loss: 2.502770840846069

Epoch: 5| Step: 2
Training loss: 1.9506670324508175
Validation loss: 2.483614599270989

Epoch: 5| Step: 3
Training loss: 1.8992332392037483
Validation loss: 2.4205100000754722

Epoch: 5| Step: 4
Training loss: 1.5582518238367247
Validation loss: 2.4568700274669673

Epoch: 5| Step: 5
Training loss: 1.9144898229544196
Validation loss: 2.4562305455409486

Epoch: 5| Step: 6
Training loss: 2.163297552431011
Validation loss: 2.4625344007875207

Epoch: 5| Step: 7
Training loss: 1.92386443592795
Validation loss: 2.4727892020615934

Epoch: 5| Step: 8
Training loss: 1.9707118356472506
Validation loss: 2.4133804599775956

Epoch: 5| Step: 9
Training loss: 1.8702637936170512
Validation loss: 2.46011524908158

Epoch: 5| Step: 10
Training loss: 1.4440148379020552
Validation loss: 2.4792365383754102

Epoch: 402| Step: 0
Training loss: 1.6902972455428646
Validation loss: 2.504641995746454

Epoch: 5| Step: 1
Training loss: 1.7462660599927822
Validation loss: 2.462388353745894

Epoch: 5| Step: 2
Training loss: 2.1271217076211704
Validation loss: 2.4641167895244074

Epoch: 5| Step: 3
Training loss: 1.6403258277960628
Validation loss: 2.4902786236152834

Epoch: 5| Step: 4
Training loss: 2.1783329299346543
Validation loss: 2.5039610052457757

Epoch: 5| Step: 5
Training loss: 1.9725043209981066
Validation loss: 2.4972464728209554

Epoch: 5| Step: 6
Training loss: 2.4138177543941097
Validation loss: 2.464969656041

Epoch: 5| Step: 7
Training loss: 1.67985398997735
Validation loss: 2.5162795681512105

Epoch: 5| Step: 8
Training loss: 1.8323529251843491
Validation loss: 2.454073659093164

Epoch: 5| Step: 9
Training loss: 1.6179056093576707
Validation loss: 2.455178190522577

Epoch: 5| Step: 10
Training loss: 1.5386404630345922
Validation loss: 2.511571909813325

Epoch: 403| Step: 0
Training loss: 1.5024078434817616
Validation loss: 2.457853696643303

Epoch: 5| Step: 1
Training loss: 1.9121699104428973
Validation loss: 2.507116043742461

Epoch: 5| Step: 2
Training loss: 1.7820175926290551
Validation loss: 2.4721138465572996

Epoch: 5| Step: 3
Training loss: 1.6237695877503013
Validation loss: 2.494045979421895

Epoch: 5| Step: 4
Training loss: 1.7463756222823807
Validation loss: 2.4651939520728274

Epoch: 5| Step: 5
Training loss: 2.270197916519544
Validation loss: 2.4916636766127755

Epoch: 5| Step: 6
Training loss: 1.8134375153560793
Validation loss: 2.5151289410852833

Epoch: 5| Step: 7
Training loss: 2.1103121335901895
Validation loss: 2.42218140652896

Epoch: 5| Step: 8
Training loss: 1.6823473784332388
Validation loss: 2.5042044212311643

Epoch: 5| Step: 9
Training loss: 1.8224222947916295
Validation loss: 2.48298056912385

Epoch: 5| Step: 10
Training loss: 2.106212703929286
Validation loss: 2.5155668013086387

Epoch: 404| Step: 0
Training loss: 1.4098091437983942
Validation loss: 2.4882164091537646

Epoch: 5| Step: 1
Training loss: 1.5093849166007298
Validation loss: 2.5158327669460974

Epoch: 5| Step: 2
Training loss: 2.020125694518852
Validation loss: 2.4864141683935284

Epoch: 5| Step: 3
Training loss: 2.3833445470941825
Validation loss: 2.5070828169235315

Epoch: 5| Step: 4
Training loss: 1.7316317471363332
Validation loss: 2.5131969215299486

Epoch: 5| Step: 5
Training loss: 2.132583326386553
Validation loss: 2.458850315754595

Epoch: 5| Step: 6
Training loss: 1.7487458776135012
Validation loss: 2.494167949621817

Epoch: 5| Step: 7
Training loss: 1.9839317247194745
Validation loss: 2.4745615807337944

Epoch: 5| Step: 8
Training loss: 1.4594555850927422
Validation loss: 2.4713249915832685

Epoch: 5| Step: 9
Training loss: 1.8872880096630313
Validation loss: 2.4764825335655702

Epoch: 5| Step: 10
Training loss: 1.5689580589412047
Validation loss: 2.4762806489880838

Epoch: 405| Step: 0
Training loss: 1.5022056575635596
Validation loss: 2.5108191156906954

Epoch: 5| Step: 1
Training loss: 1.659194128951461
Validation loss: 2.5056335267132304

Epoch: 5| Step: 2
Training loss: 1.7558868711565465
Validation loss: 2.4737526926130675

Epoch: 5| Step: 3
Training loss: 1.7401752568916373
Validation loss: 2.476359829978991

Epoch: 5| Step: 4
Training loss: 1.325105263469394
Validation loss: 2.51835805076995

Epoch: 5| Step: 5
Training loss: 1.99358961841458
Validation loss: 2.4623832210212018

Epoch: 5| Step: 6
Training loss: 1.9939548805703007
Validation loss: 2.4599699197476284

Epoch: 5| Step: 7
Training loss: 1.8402401118552454
Validation loss: 2.492467456592462

Epoch: 5| Step: 8
Training loss: 2.731090905904803
Validation loss: 2.4480776456127105

Epoch: 5| Step: 9
Training loss: 1.4765800999798466
Validation loss: 2.492602550585552

Epoch: 5| Step: 10
Training loss: 1.946774037102158
Validation loss: 2.501878799467111

Epoch: 406| Step: 0
Training loss: 1.4712951198196447
Validation loss: 2.4419261480208148

Epoch: 5| Step: 1
Training loss: 1.9301350186610886
Validation loss: 2.4326446857423742

Epoch: 5| Step: 2
Training loss: 1.3399140809398349
Validation loss: 2.466027383296178

Epoch: 5| Step: 3
Training loss: 1.6008776433247778
Validation loss: 2.5061434121070496

Epoch: 5| Step: 4
Training loss: 2.0122745079569873
Validation loss: 2.480956621535691

Epoch: 5| Step: 5
Training loss: 2.3142789235932093
Validation loss: 2.5014946110206533

Epoch: 5| Step: 6
Training loss: 1.6941456800600452
Validation loss: 2.4766719125361907

Epoch: 5| Step: 7
Training loss: 1.7770515620919658
Validation loss: 2.523463494515451

Epoch: 5| Step: 8
Training loss: 1.904049275269529
Validation loss: 2.4942612544117986

Epoch: 5| Step: 9
Training loss: 2.323529822561834
Validation loss: 2.484974888878367

Epoch: 5| Step: 10
Training loss: 1.9643169933157127
Validation loss: 2.465711766951276

Epoch: 407| Step: 0
Training loss: 1.9490238925571295
Validation loss: 2.4702251010317418

Epoch: 5| Step: 1
Training loss: 2.0692332783717364
Validation loss: 2.4536329153384773

Epoch: 5| Step: 2
Training loss: 1.9149808587893036
Validation loss: 2.409933972688811

Epoch: 5| Step: 3
Training loss: 2.6200878868213504
Validation loss: 2.4698397742980114

Epoch: 5| Step: 4
Training loss: 1.86343767001407
Validation loss: 2.4759770152208156

Epoch: 5| Step: 5
Training loss: 1.4989513864504247
Validation loss: 2.500676914576354

Epoch: 5| Step: 6
Training loss: 1.626078834410301
Validation loss: 2.4647597208295617

Epoch: 5| Step: 7
Training loss: 1.7919077008779152
Validation loss: 2.4673975184674144

Epoch: 5| Step: 8
Training loss: 1.4410090532408937
Validation loss: 2.474585630272503

Epoch: 5| Step: 9
Training loss: 1.0542931843905394
Validation loss: 2.538924581033395

Epoch: 5| Step: 10
Training loss: 1.627034747399202
Validation loss: 2.4962321333952096

Epoch: 408| Step: 0
Training loss: 1.5127072909467634
Validation loss: 2.4702921202435144

Epoch: 5| Step: 1
Training loss: 1.8388074155099083
Validation loss: 2.4784171068374437

Epoch: 5| Step: 2
Training loss: 2.144314669875292
Validation loss: 2.4758184377645964

Epoch: 5| Step: 3
Training loss: 1.4596695727237876
Validation loss: 2.502977393814936

Epoch: 5| Step: 4
Training loss: 1.7257026844437704
Validation loss: 2.474236980779709

Epoch: 5| Step: 5
Training loss: 1.7597022854904123
Validation loss: 2.5482978382006185

Epoch: 5| Step: 6
Training loss: 1.520832828190689
Validation loss: 2.525277575791531

Epoch: 5| Step: 7
Training loss: 1.5768611114773319
Validation loss: 2.4727040017804804

Epoch: 5| Step: 8
Training loss: 2.2317325999762225
Validation loss: 2.5240186527951405

Epoch: 5| Step: 9
Training loss: 2.159007534443305
Validation loss: 2.428548849341599

Epoch: 5| Step: 10
Training loss: 1.6915573510740498
Validation loss: 2.4783767519972137

Epoch: 409| Step: 0
Training loss: 1.4837154328482254
Validation loss: 2.459618313060879

Epoch: 5| Step: 1
Training loss: 2.1880173207701055
Validation loss: 2.4825029254810134

Epoch: 5| Step: 2
Training loss: 1.7534322459214065
Validation loss: 2.4841002584995757

Epoch: 5| Step: 3
Training loss: 1.7103908135725
Validation loss: 2.4346152379451036

Epoch: 5| Step: 4
Training loss: 1.7287300278619468
Validation loss: 2.480137054380673

Epoch: 5| Step: 5
Training loss: 1.851130696740453
Validation loss: 2.4554687891937665

Epoch: 5| Step: 6
Training loss: 1.6398675532473967
Validation loss: 2.507020101559937

Epoch: 5| Step: 7
Training loss: 2.038291463829993
Validation loss: 2.4702155302684417

Epoch: 5| Step: 8
Training loss: 1.7405489071114535
Validation loss: 2.4738085184033927

Epoch: 5| Step: 9
Training loss: 1.8427395395497752
Validation loss: 2.4267874994296603

Epoch: 5| Step: 10
Training loss: 2.24255081051151
Validation loss: 2.509580775720798

Epoch: 410| Step: 0
Training loss: 2.3490115298544016
Validation loss: 2.464922632748294

Epoch: 5| Step: 1
Training loss: 1.7204864746599768
Validation loss: 2.483916813303856

Epoch: 5| Step: 2
Training loss: 1.7515940218427748
Validation loss: 2.503627592977526

Epoch: 5| Step: 3
Training loss: 2.130445571286522
Validation loss: 2.492096050512207

Epoch: 5| Step: 4
Training loss: 1.5804722015147061
Validation loss: 2.4474914754022983

Epoch: 5| Step: 5
Training loss: 1.7813099633547427
Validation loss: 2.4416139439335667

Epoch: 5| Step: 6
Training loss: 2.0438883883317893
Validation loss: 2.42394093161932

Epoch: 5| Step: 7
Training loss: 1.713854250084717
Validation loss: 2.4876943939280483

Epoch: 5| Step: 8
Training loss: 1.9419468946257596
Validation loss: 2.468976785200069

Epoch: 5| Step: 9
Training loss: 1.2845335034210408
Validation loss: 2.5237741025191363

Epoch: 5| Step: 10
Training loss: 1.6319939418708331
Validation loss: 2.4846587568209935

Epoch: 411| Step: 0
Training loss: 1.5356852855035308
Validation loss: 2.4142007283420845

Epoch: 5| Step: 1
Training loss: 1.698444198693451
Validation loss: 2.4598301372931015

Epoch: 5| Step: 2
Training loss: 1.6940332323708143
Validation loss: 2.491959012472001

Epoch: 5| Step: 3
Training loss: 2.018635003088919
Validation loss: 2.465984618630909

Epoch: 5| Step: 4
Training loss: 1.6055636412707701
Validation loss: 2.538612388173652

Epoch: 5| Step: 5
Training loss: 1.542806264313414
Validation loss: 2.4722416170189128

Epoch: 5| Step: 6
Training loss: 1.969790410835381
Validation loss: 2.5016707836232377

Epoch: 5| Step: 7
Training loss: 2.256923513722974
Validation loss: 2.472652672013681

Epoch: 5| Step: 8
Training loss: 2.2104425853632246
Validation loss: 2.4833680336771367

Epoch: 5| Step: 9
Training loss: 2.11463870522548
Validation loss: 2.4646905587814927

Epoch: 5| Step: 10
Training loss: 1.424621110035726
Validation loss: 2.4938122168571164

Epoch: 412| Step: 0
Training loss: 1.6708711123614968
Validation loss: 2.4681695370193397

Epoch: 5| Step: 1
Training loss: 2.223990149050789
Validation loss: 2.4580671236852654

Epoch: 5| Step: 2
Training loss: 1.7332013257206262
Validation loss: 2.475997841282836

Epoch: 5| Step: 3
Training loss: 1.7104840657580054
Validation loss: 2.433118380664922

Epoch: 5| Step: 4
Training loss: 2.117011594327045
Validation loss: 2.502422969563116

Epoch: 5| Step: 5
Training loss: 1.9729942712019102
Validation loss: 2.438027309346707

Epoch: 5| Step: 6
Training loss: 1.8837256532144933
Validation loss: 2.5383353010601755

Epoch: 5| Step: 7
Training loss: 1.6841581243908366
Validation loss: 2.4993318259590787

Epoch: 5| Step: 8
Training loss: 1.5343350065344992
Validation loss: 2.453781966919334

Epoch: 5| Step: 9
Training loss: 1.6704493353295922
Validation loss: 2.472159548806108

Epoch: 5| Step: 10
Training loss: 1.6477154058668866
Validation loss: 2.441648249094892

Epoch: 413| Step: 0
Training loss: 1.975535974328045
Validation loss: 2.481579945563604

Epoch: 5| Step: 1
Training loss: 2.0153886523405133
Validation loss: 2.4812211320348285

Epoch: 5| Step: 2
Training loss: 1.8530600242095139
Validation loss: 2.512057786142974

Epoch: 5| Step: 3
Training loss: 1.9242401456398421
Validation loss: 2.5237627255738673

Epoch: 5| Step: 4
Training loss: 2.093260522819375
Validation loss: 2.50590704804774

Epoch: 5| Step: 5
Training loss: 1.4306331487967687
Validation loss: 2.508432034683353

Epoch: 5| Step: 6
Training loss: 2.1835311853388797
Validation loss: 2.4544991539302368

Epoch: 5| Step: 7
Training loss: 1.5530202542450033
Validation loss: 2.4908064867826196

Epoch: 5| Step: 8
Training loss: 1.8732411718380693
Validation loss: 2.506820518808991

Epoch: 5| Step: 9
Training loss: 1.325435563238271
Validation loss: 2.494773924454902

Epoch: 5| Step: 10
Training loss: 1.7229337230915935
Validation loss: 2.447331278460891

Epoch: 414| Step: 0
Training loss: 1.669822074183334
Validation loss: 2.4775556412548845

Epoch: 5| Step: 1
Training loss: 1.7731811069221206
Validation loss: 2.5115029962201727

Epoch: 5| Step: 2
Training loss: 1.6946845231970027
Validation loss: 2.5211785894551344

Epoch: 5| Step: 3
Training loss: 1.4049253794854382
Validation loss: 2.4842199028330425

Epoch: 5| Step: 4
Training loss: 2.1979494378658475
Validation loss: 2.4514938469215206

Epoch: 5| Step: 5
Training loss: 1.5929373370895037
Validation loss: 2.4616349624755114

Epoch: 5| Step: 6
Training loss: 2.2471772607371934
Validation loss: 2.4716213610965463

Epoch: 5| Step: 7
Training loss: 2.1255404963039926
Validation loss: 2.4342048296677006

Epoch: 5| Step: 8
Training loss: 1.9448153308585827
Validation loss: 2.491524937612488

Epoch: 5| Step: 9
Training loss: 1.3688463882578668
Validation loss: 2.471571233320917

Epoch: 5| Step: 10
Training loss: 1.918960470280465
Validation loss: 2.4959929511674996

Epoch: 415| Step: 0
Training loss: 1.8454023812519775
Validation loss: 2.4529612632665905

Epoch: 5| Step: 1
Training loss: 1.7529354679788047
Validation loss: 2.495123032730262

Epoch: 5| Step: 2
Training loss: 1.4919892024552055
Validation loss: 2.4799433780894002

Epoch: 5| Step: 3
Training loss: 1.8229957418093854
Validation loss: 2.4788921704385354

Epoch: 5| Step: 4
Training loss: 1.7765718565520845
Validation loss: 2.4904585259493466

Epoch: 5| Step: 5
Training loss: 1.83615630448985
Validation loss: 2.4598466738614677

Epoch: 5| Step: 6
Training loss: 1.937939624747443
Validation loss: 2.494266078973573

Epoch: 5| Step: 7
Training loss: 1.6868860046095608
Validation loss: 2.491460734770413

Epoch: 5| Step: 8
Training loss: 1.6020166264979674
Validation loss: 2.462563416979457

Epoch: 5| Step: 9
Training loss: 1.9268389228959921
Validation loss: 2.454182709457744

Epoch: 5| Step: 10
Training loss: 2.160595702573257
Validation loss: 2.4854168205349545

Epoch: 416| Step: 0
Training loss: 1.7493019074014997
Validation loss: 2.4989026070920923

Epoch: 5| Step: 1
Training loss: 1.607858480346534
Validation loss: 2.4669183416303024

Epoch: 5| Step: 2
Training loss: 2.0790070691009164
Validation loss: 2.534942906684095

Epoch: 5| Step: 3
Training loss: 1.5515698174402992
Validation loss: 2.517360540287876

Epoch: 5| Step: 4
Training loss: 1.841254339478475
Validation loss: 2.5044434984207142

Epoch: 5| Step: 5
Training loss: 1.6556906565359306
Validation loss: 2.4902116790322744

Epoch: 5| Step: 6
Training loss: 1.8254301635456838
Validation loss: 2.457610006341685

Epoch: 5| Step: 7
Training loss: 1.6925329107693816
Validation loss: 2.486860354359623

Epoch: 5| Step: 8
Training loss: 1.9325001099501329
Validation loss: 2.4369887948398556

Epoch: 5| Step: 9
Training loss: 1.5755064740327913
Validation loss: 2.5279887956216758

Epoch: 5| Step: 10
Training loss: 2.350256065864798
Validation loss: 2.5472807956964925

Epoch: 417| Step: 0
Training loss: 2.021285986264448
Validation loss: 2.491344716627288

Epoch: 5| Step: 1
Training loss: 2.093425896454841
Validation loss: 2.515809559050269

Epoch: 5| Step: 2
Training loss: 1.7252294995878574
Validation loss: 2.4857822456280596

Epoch: 5| Step: 3
Training loss: 1.52158857779603
Validation loss: 2.424967487913521

Epoch: 5| Step: 4
Training loss: 1.3669654011844186
Validation loss: 2.459720436801292

Epoch: 5| Step: 5
Training loss: 1.5968511740144395
Validation loss: 2.449579993789369

Epoch: 5| Step: 6
Training loss: 1.5477093844894363
Validation loss: 2.4613061199442767

Epoch: 5| Step: 7
Training loss: 1.7727493766037954
Validation loss: 2.4697632543740773

Epoch: 5| Step: 8
Training loss: 2.096833193684865
Validation loss: 2.4554870658032373

Epoch: 5| Step: 9
Training loss: 1.736986136434394
Validation loss: 2.471586287422757

Epoch: 5| Step: 10
Training loss: 2.2283664823970506
Validation loss: 2.4413731842098865

Epoch: 418| Step: 0
Training loss: 1.4465676296338488
Validation loss: 2.4467257435405205

Epoch: 5| Step: 1
Training loss: 1.3969369861751517
Validation loss: 2.463919475963481

Epoch: 5| Step: 2
Training loss: 1.8741003421272433
Validation loss: 2.5406867681325846

Epoch: 5| Step: 3
Training loss: 1.8139547889399998
Validation loss: 2.4837591711171707

Epoch: 5| Step: 4
Training loss: 1.602115889054362
Validation loss: 2.477698564519361

Epoch: 5| Step: 5
Training loss: 2.406210465539928
Validation loss: 2.464707689944014

Epoch: 5| Step: 6
Training loss: 1.628832918341474
Validation loss: 2.4943480889293257

Epoch: 5| Step: 7
Training loss: 2.0351260250724637
Validation loss: 2.4559225049070283

Epoch: 5| Step: 8
Training loss: 2.1362699215106855
Validation loss: 2.476261227083322

Epoch: 5| Step: 9
Training loss: 1.3888883998658061
Validation loss: 2.4749698390140114

Epoch: 5| Step: 10
Training loss: 1.926777177839992
Validation loss: 2.4482037615242045

Epoch: 419| Step: 0
Training loss: 1.9592051966340076
Validation loss: 2.461481380441108

Epoch: 5| Step: 1
Training loss: 1.9883274155449022
Validation loss: 2.4584193182483722

Epoch: 5| Step: 2
Training loss: 1.4267773636686611
Validation loss: 2.4658499138207794

Epoch: 5| Step: 3
Training loss: 1.7101260834774057
Validation loss: 2.486163544408893

Epoch: 5| Step: 4
Training loss: 1.726242864374416
Validation loss: 2.4597470932117647

Epoch: 5| Step: 5
Training loss: 1.6407318080467261
Validation loss: 2.5001761958882485

Epoch: 5| Step: 6
Training loss: 1.9928426226366727
Validation loss: 2.513694632472349

Epoch: 5| Step: 7
Training loss: 1.8733245357406403
Validation loss: 2.581399527908592

Epoch: 5| Step: 8
Training loss: 2.1425801279759327
Validation loss: 2.4937650661325397

Epoch: 5| Step: 9
Training loss: 1.6215119707134427
Validation loss: 2.4390195575239044

Epoch: 5| Step: 10
Training loss: 1.7240934367029113
Validation loss: 2.4765522591321663

Epoch: 420| Step: 0
Training loss: 1.7709145770416106
Validation loss: 2.470730457724599

Epoch: 5| Step: 1
Training loss: 1.5883813078774496
Validation loss: 2.4904113585675587

Epoch: 5| Step: 2
Training loss: 1.9157967943133845
Validation loss: 2.5046030163942987

Epoch: 5| Step: 3
Training loss: 1.6626340797680579
Validation loss: 2.428605432376592

Epoch: 5| Step: 4
Training loss: 1.7029872453607302
Validation loss: 2.4497911665184184

Epoch: 5| Step: 5
Training loss: 1.225823927185636
Validation loss: 2.4571830908272205

Epoch: 5| Step: 6
Training loss: 1.7523571216278864
Validation loss: 2.424543384094403

Epoch: 5| Step: 7
Training loss: 2.455883055011989
Validation loss: 2.481381600993044

Epoch: 5| Step: 8
Training loss: 2.0058529564922867
Validation loss: 2.430233226758144

Epoch: 5| Step: 9
Training loss: 1.5322967377074572
Validation loss: 2.5209422795194696

Epoch: 5| Step: 10
Training loss: 2.235943757054433
Validation loss: 2.457751697694912

Epoch: 421| Step: 0
Training loss: 1.3908580627589493
Validation loss: 2.437093461565829

Epoch: 5| Step: 1
Training loss: 1.6563991263568991
Validation loss: 2.5235914872101355

Epoch: 5| Step: 2
Training loss: 2.0782708138385324
Validation loss: 2.4159006963582423

Epoch: 5| Step: 3
Training loss: 1.7539428843047309
Validation loss: 2.447053298779149

Epoch: 5| Step: 4
Training loss: 1.7856781778772175
Validation loss: 2.5026072155884784

Epoch: 5| Step: 5
Training loss: 1.5658206748890608
Validation loss: 2.509045555586768

Epoch: 5| Step: 6
Training loss: 1.8359807435482356
Validation loss: 2.464099424326133

Epoch: 5| Step: 7
Training loss: 1.6525738783580588
Validation loss: 2.5308179153605432

Epoch: 5| Step: 8
Training loss: 1.8144202090789596
Validation loss: 2.49541281579147

Epoch: 5| Step: 9
Training loss: 2.3623559574841466
Validation loss: 2.501878299420204

Epoch: 5| Step: 10
Training loss: 1.9461382603158957
Validation loss: 2.5108386296848026

Epoch: 422| Step: 0
Training loss: 1.5052450982942016
Validation loss: 2.485180493650811

Epoch: 5| Step: 1
Training loss: 1.9851325684102832
Validation loss: 2.4909710765667175

Epoch: 5| Step: 2
Training loss: 1.7146088389295322
Validation loss: 2.4663654045172074

Epoch: 5| Step: 3
Training loss: 1.649904728075186
Validation loss: 2.4707873333516335

Epoch: 5| Step: 4
Training loss: 1.6604352649267755
Validation loss: 2.488707821782799

Epoch: 5| Step: 5
Training loss: 1.8546416999284594
Validation loss: 2.471318046483684

Epoch: 5| Step: 6
Training loss: 1.9210906250173152
Validation loss: 2.473371071578028

Epoch: 5| Step: 7
Training loss: 2.079046288969942
Validation loss: 2.4154301989056846

Epoch: 5| Step: 8
Training loss: 1.4836718048084439
Validation loss: 2.4833219626904777

Epoch: 5| Step: 9
Training loss: 1.6619452676769793
Validation loss: 2.4031061485570233

Epoch: 5| Step: 10
Training loss: 2.2928068503520396
Validation loss: 2.454161729088095

Epoch: 423| Step: 0
Training loss: 1.7644931912808324
Validation loss: 2.4635928458111866

Epoch: 5| Step: 1
Training loss: 2.0384757999259016
Validation loss: 2.4913476616774504

Epoch: 5| Step: 2
Training loss: 2.2418070081530654
Validation loss: 2.4702803288629807

Epoch: 5| Step: 3
Training loss: 1.7220369294002558
Validation loss: 2.479053097284247

Epoch: 5| Step: 4
Training loss: 2.112842676482948
Validation loss: 2.493648344053765

Epoch: 5| Step: 5
Training loss: 1.7276981123125092
Validation loss: 2.500583940419503

Epoch: 5| Step: 6
Training loss: 1.5736469148380603
Validation loss: 2.475114440385252

Epoch: 5| Step: 7
Training loss: 1.8856569702553687
Validation loss: 2.447579690591414

Epoch: 5| Step: 8
Training loss: 1.657893391180807
Validation loss: 2.4968871990339494

Epoch: 5| Step: 9
Training loss: 1.2235054747502254
Validation loss: 2.4914701693868824

Epoch: 5| Step: 10
Training loss: 1.4843454458406542
Validation loss: 2.462812254889373

Epoch: 424| Step: 0
Training loss: 0.949209550726626
Validation loss: 2.5266569972393707

Epoch: 5| Step: 1
Training loss: 1.9504009323718727
Validation loss: 2.454459896321469

Epoch: 5| Step: 2
Training loss: 1.6812745159871751
Validation loss: 2.4357574235308967

Epoch: 5| Step: 3
Training loss: 2.174837137022173
Validation loss: 2.459620911493609

Epoch: 5| Step: 4
Training loss: 1.6198747210864088
Validation loss: 2.4907826556180743

Epoch: 5| Step: 5
Training loss: 1.604878337919328
Validation loss: 2.408254153424736

Epoch: 5| Step: 6
Training loss: 1.9735294637749439
Validation loss: 2.5275906325586317

Epoch: 5| Step: 7
Training loss: 2.0763099028818353
Validation loss: 2.5152991125875945

Epoch: 5| Step: 8
Training loss: 1.8667550324346243
Validation loss: 2.444294939226672

Epoch: 5| Step: 9
Training loss: 1.4952044122070558
Validation loss: 2.522619567664757

Epoch: 5| Step: 10
Training loss: 1.8972918032088362
Validation loss: 2.501579422561177

Epoch: 425| Step: 0
Training loss: 1.8565540873823796
Validation loss: 2.4395129272336873

Epoch: 5| Step: 1
Training loss: 1.619041964443601
Validation loss: 2.4446126059503874

Epoch: 5| Step: 2
Training loss: 1.9830829288649876
Validation loss: 2.4589000053651158

Epoch: 5| Step: 3
Training loss: 1.7338060700275437
Validation loss: 2.467701068233887

Epoch: 5| Step: 4
Training loss: 1.5700955976550461
Validation loss: 2.506271189713422

Epoch: 5| Step: 5
Training loss: 1.8293825046814152
Validation loss: 2.460725116826879

Epoch: 5| Step: 6
Training loss: 1.670899507666044
Validation loss: 2.4826472626023377

Epoch: 5| Step: 7
Training loss: 1.938930844518241
Validation loss: 2.5109285644480073

Epoch: 5| Step: 8
Training loss: 1.909527571805485
Validation loss: 2.4426797270906397

Epoch: 5| Step: 9
Training loss: 1.5909461995540541
Validation loss: 2.46058726724803

Epoch: 5| Step: 10
Training loss: 1.863684716517243
Validation loss: 2.4698287851949647

Epoch: 426| Step: 0
Training loss: 1.744018687121865
Validation loss: 2.445294098593333

Epoch: 5| Step: 1
Training loss: 1.6381002709109702
Validation loss: 2.4846513310329756

Epoch: 5| Step: 2
Training loss: 2.2787278747321493
Validation loss: 2.518042682906756

Epoch: 5| Step: 3
Training loss: 1.3944255030098287
Validation loss: 2.5182711320166344

Epoch: 5| Step: 4
Training loss: 1.7036383318952149
Validation loss: 2.5025019616124276

Epoch: 5| Step: 5
Training loss: 1.9043706791587416
Validation loss: 2.473935177516027

Epoch: 5| Step: 6
Training loss: 1.7185154147884385
Validation loss: 2.469469525557486

Epoch: 5| Step: 7
Training loss: 1.3897027375689963
Validation loss: 2.5083888406253263

Epoch: 5| Step: 8
Training loss: 1.3837681286183416
Validation loss: 2.5225629074123055

Epoch: 5| Step: 9
Training loss: 2.3936001085806633
Validation loss: 2.472122938127315

Epoch: 5| Step: 10
Training loss: 1.8873257815565785
Validation loss: 2.48870264135862

Epoch: 427| Step: 0
Training loss: 1.860662767708025
Validation loss: 2.4307889504204487

Epoch: 5| Step: 1
Training loss: 1.568541633780588
Validation loss: 2.460598518501865

Epoch: 5| Step: 2
Training loss: 2.2324130107339872
Validation loss: 2.4888443816630126

Epoch: 5| Step: 3
Training loss: 1.7794960488352973
Validation loss: 2.575283224760146

Epoch: 5| Step: 4
Training loss: 1.7897606699263549
Validation loss: 2.495243747184806

Epoch: 5| Step: 5
Training loss: 1.3942564364936747
Validation loss: 2.4258860568289378

Epoch: 5| Step: 6
Training loss: 1.4472367956916916
Validation loss: 2.4374050461601278

Epoch: 5| Step: 7
Training loss: 1.4901308596194776
Validation loss: 2.44182316038738

Epoch: 5| Step: 8
Training loss: 1.6434471924795742
Validation loss: 2.4605212975454798

Epoch: 5| Step: 9
Training loss: 2.27908222197799
Validation loss: 2.4761484020601694

Epoch: 5| Step: 10
Training loss: 1.9091570216245661
Validation loss: 2.4508311745885987

Epoch: 428| Step: 0
Training loss: 1.9086188934206498
Validation loss: 2.4993244571010167

Epoch: 5| Step: 1
Training loss: 1.314319847571464
Validation loss: 2.5186791152524757

Epoch: 5| Step: 2
Training loss: 2.0589215996569505
Validation loss: 2.474395136891265

Epoch: 5| Step: 3
Training loss: 1.7952355244654146
Validation loss: 2.463485733441709

Epoch: 5| Step: 4
Training loss: 1.2154038784665133
Validation loss: 2.477171739394228

Epoch: 5| Step: 5
Training loss: 2.1967440787274963
Validation loss: 2.533561687048989

Epoch: 5| Step: 6
Training loss: 1.4263688222350022
Validation loss: 2.475086121331209

Epoch: 5| Step: 7
Training loss: 1.804479479670151
Validation loss: 2.5061225961634404

Epoch: 5| Step: 8
Training loss: 1.5119489942959514
Validation loss: 2.48604024927903

Epoch: 5| Step: 9
Training loss: 2.0828301648637857
Validation loss: 2.5387736837924377

Epoch: 5| Step: 10
Training loss: 2.0355799374908576
Validation loss: 2.5398657329212844

Epoch: 429| Step: 0
Training loss: 2.405897238498934
Validation loss: 2.4675005264814445

Epoch: 5| Step: 1
Training loss: 2.2913325904324817
Validation loss: 2.4890526609151187

Epoch: 5| Step: 2
Training loss: 1.685220025862569
Validation loss: 2.5003494367138406

Epoch: 5| Step: 3
Training loss: 2.112203665269493
Validation loss: 2.4407256832423547

Epoch: 5| Step: 4
Training loss: 1.7341943595223464
Validation loss: 2.4209021639861312

Epoch: 5| Step: 5
Training loss: 1.4755209019161935
Validation loss: 2.4675689614760286

Epoch: 5| Step: 6
Training loss: 1.621299785711361
Validation loss: 2.473587432847064

Epoch: 5| Step: 7
Training loss: 1.8383929775150392
Validation loss: 2.4305163314006064

Epoch: 5| Step: 8
Training loss: 1.5172696972314985
Validation loss: 2.451039030577633

Epoch: 5| Step: 9
Training loss: 1.8643218199830645
Validation loss: 2.5045356358135358

Epoch: 5| Step: 10
Training loss: 1.135476971112662
Validation loss: 2.510872279532813

Epoch: 430| Step: 0
Training loss: 1.6179433337121283
Validation loss: 2.398043132283201

Epoch: 5| Step: 1
Training loss: 1.4020486590257846
Validation loss: 2.426584919220034

Epoch: 5| Step: 2
Training loss: 2.2783253355334683
Validation loss: 2.4969216554981086

Epoch: 5| Step: 3
Training loss: 1.4263828628265822
Validation loss: 2.469356309242979

Epoch: 5| Step: 4
Training loss: 1.7250489380017533
Validation loss: 2.4793173507296036

Epoch: 5| Step: 5
Training loss: 1.8402059081176867
Validation loss: 2.5219080259709616

Epoch: 5| Step: 6
Training loss: 1.7371763682673538
Validation loss: 2.43342737060279

Epoch: 5| Step: 7
Training loss: 1.673750351442125
Validation loss: 2.5026162066252255

Epoch: 5| Step: 8
Training loss: 2.227708595176212
Validation loss: 2.494825208580053

Epoch: 5| Step: 9
Training loss: 1.5329850934741553
Validation loss: 2.483441391607849

Epoch: 5| Step: 10
Training loss: 1.949350784508484
Validation loss: 2.4659128248042785

Epoch: 431| Step: 0
Training loss: 2.014030002897072
Validation loss: 2.4483394591944263

Epoch: 5| Step: 1
Training loss: 0.8510098194963328
Validation loss: 2.4948947143715214

Epoch: 5| Step: 2
Training loss: 1.7938441713714517
Validation loss: 2.456397858054427

Epoch: 5| Step: 3
Training loss: 2.291578557025707
Validation loss: 2.490750278257715

Epoch: 5| Step: 4
Training loss: 1.899166140029698
Validation loss: 2.5144189934651773

Epoch: 5| Step: 5
Training loss: 1.7029786353257925
Validation loss: 2.4425092382009983

Epoch: 5| Step: 6
Training loss: 1.9187429073836364
Validation loss: 2.4244649914933953

Epoch: 5| Step: 7
Training loss: 1.603165656869966
Validation loss: 2.445674342783748

Epoch: 5| Step: 8
Training loss: 1.5747507866982982
Validation loss: 2.436156035686712

Epoch: 5| Step: 9
Training loss: 1.863961021813942
Validation loss: 2.4872478020251307

Epoch: 5| Step: 10
Training loss: 1.776954692136317
Validation loss: 2.4476068730494913

Epoch: 432| Step: 0
Training loss: 1.8420421643313598
Validation loss: 2.4923562045387784

Epoch: 5| Step: 1
Training loss: 1.4796060348369109
Validation loss: 2.4283429533230825

Epoch: 5| Step: 2
Training loss: 1.4972399113509944
Validation loss: 2.5385822250201175

Epoch: 5| Step: 3
Training loss: 1.3017231048741915
Validation loss: 2.4818023292960047

Epoch: 5| Step: 4
Training loss: 1.5890747009829196
Validation loss: 2.4235014927453817

Epoch: 5| Step: 5
Training loss: 2.0508211259144047
Validation loss: 2.435122871353741

Epoch: 5| Step: 6
Training loss: 1.7455043950196278
Validation loss: 2.448600726526072

Epoch: 5| Step: 7
Training loss: 2.122407116694189
Validation loss: 2.466087557795887

Epoch: 5| Step: 8
Training loss: 2.053313633630225
Validation loss: 2.4079125580055076

Epoch: 5| Step: 9
Training loss: 2.000314449386231
Validation loss: 2.4426047797349533

Epoch: 5| Step: 10
Training loss: 1.788638401988744
Validation loss: 2.504057872410622

Epoch: 433| Step: 0
Training loss: 1.8751463515067541
Validation loss: 2.469476396957835

Epoch: 5| Step: 1
Training loss: 1.9918855326062548
Validation loss: 2.4502229409558254

Epoch: 5| Step: 2
Training loss: 1.8608196640822312
Validation loss: 2.48064485531496

Epoch: 5| Step: 3
Training loss: 2.472145738978294
Validation loss: 2.483341816636262

Epoch: 5| Step: 4
Training loss: 1.3679081352743256
Validation loss: 2.492469159365195

Epoch: 5| Step: 5
Training loss: 1.7325634129796599
Validation loss: 2.4088042954080136

Epoch: 5| Step: 6
Training loss: 1.5143352408548598
Validation loss: 2.462932203687966

Epoch: 5| Step: 7
Training loss: 1.238021775265235
Validation loss: 2.46031203257467

Epoch: 5| Step: 8
Training loss: 1.3158129252050452
Validation loss: 2.4566146669853426

Epoch: 5| Step: 9
Training loss: 2.0794679131716363
Validation loss: 2.5200679135323076

Epoch: 5| Step: 10
Training loss: 1.5542168599768513
Validation loss: 2.448863180352433

Epoch: 434| Step: 0
Training loss: 1.30908148487027
Validation loss: 2.471835829760205

Epoch: 5| Step: 1
Training loss: 1.4939547155071615
Validation loss: 2.485504360632504

Epoch: 5| Step: 2
Training loss: 1.5408978048521482
Validation loss: 2.4360693626488543

Epoch: 5| Step: 3
Training loss: 2.0682465231621956
Validation loss: 2.4453506589935015

Epoch: 5| Step: 4
Training loss: 1.7136886981932236
Validation loss: 2.497250552474155

Epoch: 5| Step: 5
Training loss: 1.8455099983698955
Validation loss: 2.4538492858256826

Epoch: 5| Step: 6
Training loss: 1.6521898563224624
Validation loss: 2.540672841400068

Epoch: 5| Step: 7
Training loss: 1.837558112231125
Validation loss: 2.456774092675939

Epoch: 5| Step: 8
Training loss: 1.423418653344549
Validation loss: 2.4725809297551513

Epoch: 5| Step: 9
Training loss: 2.2235933550792155
Validation loss: 2.4669559949570026

Epoch: 5| Step: 10
Training loss: 2.2434349710227313
Validation loss: 2.44044996917594

Epoch: 435| Step: 0
Training loss: 1.8710023861680751
Validation loss: 2.4823239704129563

Epoch: 5| Step: 1
Training loss: 1.836013337861858
Validation loss: 2.477195766179785

Epoch: 5| Step: 2
Training loss: 1.5719149180627734
Validation loss: 2.4335718036228853

Epoch: 5| Step: 3
Training loss: 1.9314206020222249
Validation loss: 2.479442820615545

Epoch: 5| Step: 4
Training loss: 1.3533575673039786
Validation loss: 2.4961336468941955

Epoch: 5| Step: 5
Training loss: 1.3748177060750415
Validation loss: 2.4671886226788633

Epoch: 5| Step: 6
Training loss: 1.990173638402547
Validation loss: 2.449856331626608

Epoch: 5| Step: 7
Training loss: 2.078174561791512
Validation loss: 2.44539780598848

Epoch: 5| Step: 8
Training loss: 1.630074793146944
Validation loss: 2.499171971021336

Epoch: 5| Step: 9
Training loss: 1.9605154365957251
Validation loss: 2.429995840604082

Epoch: 5| Step: 10
Training loss: 1.5168921296072373
Validation loss: 2.4533032604060123

Epoch: 436| Step: 0
Training loss: 2.399315986911188
Validation loss: 2.4397336949773707

Epoch: 5| Step: 1
Training loss: 1.8393319424389711
Validation loss: 2.4519149207707374

Epoch: 5| Step: 2
Training loss: 1.6356350536277968
Validation loss: 2.527020912835644

Epoch: 5| Step: 3
Training loss: 1.5546924840185894
Validation loss: 2.4412478107191196

Epoch: 5| Step: 4
Training loss: 1.5325746061949046
Validation loss: 2.5041821835701055

Epoch: 5| Step: 5
Training loss: 1.550274590811345
Validation loss: 2.4931774433145915

Epoch: 5| Step: 6
Training loss: 1.411580684562468
Validation loss: 2.4936791961904454

Epoch: 5| Step: 7
Training loss: 1.8171339976732255
Validation loss: 2.3958433150145484

Epoch: 5| Step: 8
Training loss: 1.8167121875670988
Validation loss: 2.450683048212933

Epoch: 5| Step: 9
Training loss: 1.8455119361956522
Validation loss: 2.456943683018228

Epoch: 5| Step: 10
Training loss: 1.8727482308025607
Validation loss: 2.4552570559458973

Epoch: 437| Step: 0
Training loss: 2.018228786017269
Validation loss: 2.5144235932769736

Epoch: 5| Step: 1
Training loss: 1.63640247284435
Validation loss: 2.513319694340811

Epoch: 5| Step: 2
Training loss: 1.6297009768344817
Validation loss: 2.5034283644347

Epoch: 5| Step: 3
Training loss: 1.6465830564057362
Validation loss: 2.4923717404832013

Epoch: 5| Step: 4
Training loss: 1.7613311138115026
Validation loss: 2.472642568399325

Epoch: 5| Step: 5
Training loss: 2.274233544320224
Validation loss: 2.465341096355985

Epoch: 5| Step: 6
Training loss: 1.5809389464324046
Validation loss: 2.477310416061254

Epoch: 5| Step: 7
Training loss: 1.9236638497637308
Validation loss: 2.494733462203942

Epoch: 5| Step: 8
Training loss: 1.8973581518898768
Validation loss: 2.486096040448547

Epoch: 5| Step: 9
Training loss: 1.2277428845490872
Validation loss: 2.485781136957217

Epoch: 5| Step: 10
Training loss: 1.7158490755539502
Validation loss: 2.468809962242147

Epoch: 438| Step: 0
Training loss: 1.5933295798689766
Validation loss: 2.447033808333091

Epoch: 5| Step: 1
Training loss: 2.0360517819607837
Validation loss: 2.465038146218226

Epoch: 5| Step: 2
Training loss: 1.832937508537055
Validation loss: 2.502128702822575

Epoch: 5| Step: 3
Training loss: 1.2493550544127536
Validation loss: 2.424747667926654

Epoch: 5| Step: 4
Training loss: 1.5504396768673763
Validation loss: 2.4985135797075437

Epoch: 5| Step: 5
Training loss: 2.1119605148626976
Validation loss: 2.4860490269609565

Epoch: 5| Step: 6
Training loss: 2.0817172330767617
Validation loss: 2.450091866768843

Epoch: 5| Step: 7
Training loss: 1.3224419570617696
Validation loss: 2.4626901745438747

Epoch: 5| Step: 8
Training loss: 2.3444522060046853
Validation loss: 2.456706844001908

Epoch: 5| Step: 9
Training loss: 1.464453886921731
Validation loss: 2.4705683122001454

Epoch: 5| Step: 10
Training loss: 1.2988328517741763
Validation loss: 2.4881492328979116

Epoch: 439| Step: 0
Training loss: 1.5122138895600452
Validation loss: 2.471771028382789

Epoch: 5| Step: 1
Training loss: 1.9500252501980357
Validation loss: 2.459595050034407

Epoch: 5| Step: 2
Training loss: 1.903272335569323
Validation loss: 2.4673981803140985

Epoch: 5| Step: 3
Training loss: 2.022876322927056
Validation loss: 2.4368788135627293

Epoch: 5| Step: 4
Training loss: 1.885945922023675
Validation loss: 2.4805518548124654

Epoch: 5| Step: 5
Training loss: 1.7070753148587134
Validation loss: 2.4675862544674385

Epoch: 5| Step: 6
Training loss: 1.4657812755045103
Validation loss: 2.5437543503092517

Epoch: 5| Step: 7
Training loss: 1.8742372868882573
Validation loss: 2.5082376890378915

Epoch: 5| Step: 8
Training loss: 1.7714775110551284
Validation loss: 2.4567970730191524

Epoch: 5| Step: 9
Training loss: 1.5330583443285772
Validation loss: 2.465102463163329

Epoch: 5| Step: 10
Training loss: 1.571249231719176
Validation loss: 2.449739176658301

Epoch: 440| Step: 0
Training loss: 1.5145171530990496
Validation loss: 2.485290233383132

Epoch: 5| Step: 1
Training loss: 1.2875412721407498
Validation loss: 2.51993318712511

Epoch: 5| Step: 2
Training loss: 2.029440088147619
Validation loss: 2.486930002350324

Epoch: 5| Step: 3
Training loss: 1.366967755778063
Validation loss: 2.4387473729148472

Epoch: 5| Step: 4
Training loss: 1.8177887936102612
Validation loss: 2.49892632286204

Epoch: 5| Step: 5
Training loss: 1.915404118160789
Validation loss: 2.479795626050883

Epoch: 5| Step: 6
Training loss: 1.9476214574467385
Validation loss: 2.4484908778623002

Epoch: 5| Step: 7
Training loss: 1.5627078108877144
Validation loss: 2.5208545874771953

Epoch: 5| Step: 8
Training loss: 1.6557203921597239
Validation loss: 2.4461721857609824

Epoch: 5| Step: 9
Training loss: 1.5805599199550258
Validation loss: 2.47694240026915

Epoch: 5| Step: 10
Training loss: 2.184396776955781
Validation loss: 2.475766434779827

Epoch: 441| Step: 0
Training loss: 1.5707902323967753
Validation loss: 2.4689188409206206

Epoch: 5| Step: 1
Training loss: 1.9080846743878503
Validation loss: 2.4964151193058712

Epoch: 5| Step: 2
Training loss: 1.835325358180298
Validation loss: 2.484955752607229

Epoch: 5| Step: 3
Training loss: 1.5778661836711623
Validation loss: 2.394975320443673

Epoch: 5| Step: 4
Training loss: 1.3135376869925892
Validation loss: 2.4954054738860996

Epoch: 5| Step: 5
Training loss: 1.8865472624818815
Validation loss: 2.4779201688836414

Epoch: 5| Step: 6
Training loss: 1.711169083481578
Validation loss: 2.4310421479931645

Epoch: 5| Step: 7
Training loss: 2.322065314275416
Validation loss: 2.4305747650684344

Epoch: 5| Step: 8
Training loss: 1.8295275532747597
Validation loss: 2.4637086755265725

Epoch: 5| Step: 9
Training loss: 1.4612126218846389
Validation loss: 2.4947992650504482

Epoch: 5| Step: 10
Training loss: 1.628409257262118
Validation loss: 2.4576784710880544

Epoch: 442| Step: 0
Training loss: 1.5690483204759902
Validation loss: 2.45105078168936

Epoch: 5| Step: 1
Training loss: 1.6938199975446127
Validation loss: 2.4518701340341353

Epoch: 5| Step: 2
Training loss: 2.3394224777927675
Validation loss: 2.464122107988549

Epoch: 5| Step: 3
Training loss: 1.8740110968441384
Validation loss: 2.4473208597553158

Epoch: 5| Step: 4
Training loss: 1.7662542116583348
Validation loss: 2.466167662742309

Epoch: 5| Step: 5
Training loss: 1.4879011334573697
Validation loss: 2.4645133487973183

Epoch: 5| Step: 6
Training loss: 1.5530844239858128
Validation loss: 2.4969954083621935

Epoch: 5| Step: 7
Training loss: 1.951576901116238
Validation loss: 2.5316897807431515

Epoch: 5| Step: 8
Training loss: 1.896655529718044
Validation loss: 2.4571665363331165

Epoch: 5| Step: 9
Training loss: 1.712912547407283
Validation loss: 2.439091755102158

Epoch: 5| Step: 10
Training loss: 1.1730036577361203
Validation loss: 2.472611668397747

Epoch: 443| Step: 0
Training loss: 1.4195384855196205
Validation loss: 2.473718942006397

Epoch: 5| Step: 1
Training loss: 2.0260579583331033
Validation loss: 2.486446672327832

Epoch: 5| Step: 2
Training loss: 1.8875382501629594
Validation loss: 2.4493315123962804

Epoch: 5| Step: 3
Training loss: 1.6607366287908265
Validation loss: 2.4795311252908685

Epoch: 5| Step: 4
Training loss: 1.7082220677063262
Validation loss: 2.448816800445408

Epoch: 5| Step: 5
Training loss: 1.658571811123045
Validation loss: 2.460484569959765

Epoch: 5| Step: 6
Training loss: 1.160124139309278
Validation loss: 2.4508502289799274

Epoch: 5| Step: 7
Training loss: 2.1363694709240693
Validation loss: 2.4413296169928524

Epoch: 5| Step: 8
Training loss: 1.5523803307303283
Validation loss: 2.4476663619034063

Epoch: 5| Step: 9
Training loss: 1.59574832175225
Validation loss: 2.4613135510664583

Epoch: 5| Step: 10
Training loss: 1.9143269881636455
Validation loss: 2.508020415319151

Epoch: 444| Step: 0
Training loss: 1.7779642552021369
Validation loss: 2.4269152889482353

Epoch: 5| Step: 1
Training loss: 1.890642969976099
Validation loss: 2.471604139382794

Epoch: 5| Step: 2
Training loss: 1.389157066945159
Validation loss: 2.4447955860578205

Epoch: 5| Step: 3
Training loss: 1.4877718156212854
Validation loss: 2.457564783555688

Epoch: 5| Step: 4
Training loss: 1.637793358885828
Validation loss: 2.4481838896464834

Epoch: 5| Step: 5
Training loss: 1.4622070997326422
Validation loss: 2.4679783250719143

Epoch: 5| Step: 6
Training loss: 1.4962596353142565
Validation loss: 2.4659153157600815

Epoch: 5| Step: 7
Training loss: 1.9467368063091992
Validation loss: 2.4542689825462913

Epoch: 5| Step: 8
Training loss: 1.9450079131762203
Validation loss: 2.4509479201576823

Epoch: 5| Step: 9
Training loss: 2.0942680515086467
Validation loss: 2.4379254988099377

Epoch: 5| Step: 10
Training loss: 1.8467474672334478
Validation loss: 2.4689146033465708

Epoch: 445| Step: 0
Training loss: 2.0193026798843907
Validation loss: 2.4265839388055546

Epoch: 5| Step: 1
Training loss: 2.2777837259581935
Validation loss: 2.4836040819428375

Epoch: 5| Step: 2
Training loss: 1.8406382017844147
Validation loss: 2.4949473955140697

Epoch: 5| Step: 3
Training loss: 1.5489067836957966
Validation loss: 2.4891514934997665

Epoch: 5| Step: 4
Training loss: 1.2832133903847622
Validation loss: 2.473871628041219

Epoch: 5| Step: 5
Training loss: 1.1314715637396247
Validation loss: 2.496803228181071

Epoch: 5| Step: 6
Training loss: 1.2952745972760498
Validation loss: 2.5012341929161006

Epoch: 5| Step: 7
Training loss: 1.8137062925597343
Validation loss: 2.479734502757677

Epoch: 5| Step: 8
Training loss: 1.9225806824777463
Validation loss: 2.5065445678242466

Epoch: 5| Step: 9
Training loss: 1.5620611718980748
Validation loss: 2.4984719651892227

Epoch: 5| Step: 10
Training loss: 1.788450444568085
Validation loss: 2.4894517110420096

Epoch: 446| Step: 0
Training loss: 1.846008146402356
Validation loss: 2.459601824987536

Epoch: 5| Step: 1
Training loss: 2.3025155905859482
Validation loss: 2.4454616226089834

Epoch: 5| Step: 2
Training loss: 1.5417914812579836
Validation loss: 2.4714989425856975

Epoch: 5| Step: 3
Training loss: 1.358429415450381
Validation loss: 2.483788719661333

Epoch: 5| Step: 4
Training loss: 1.689005074596743
Validation loss: 2.4489372860895657

Epoch: 5| Step: 5
Training loss: 0.9830229117031398
Validation loss: 2.489474774365335

Epoch: 5| Step: 6
Training loss: 1.8437809052544205
Validation loss: 2.5091319867609574

Epoch: 5| Step: 7
Training loss: 1.6456169839295052
Validation loss: 2.464617036970358

Epoch: 5| Step: 8
Training loss: 1.7807828725693793
Validation loss: 2.452293307785294

Epoch: 5| Step: 9
Training loss: 1.9377454786763444
Validation loss: 2.5095553432974693

Epoch: 5| Step: 10
Training loss: 1.942688547260341
Validation loss: 2.506834402486992

Epoch: 447| Step: 0
Training loss: 1.2685928867570666
Validation loss: 2.4045230510552855

Epoch: 5| Step: 1
Training loss: 2.043266551848852
Validation loss: 2.514600817011126

Epoch: 5| Step: 2
Training loss: 1.8987008371323277
Validation loss: 2.4231751613597527

Epoch: 5| Step: 3
Training loss: 1.8011379592008883
Validation loss: 2.5589183725121036

Epoch: 5| Step: 4
Training loss: 1.3622387504344162
Validation loss: 2.4777525455823417

Epoch: 5| Step: 5
Training loss: 1.583967441604733
Validation loss: 2.498844809924516

Epoch: 5| Step: 6
Training loss: 1.8377633613201383
Validation loss: 2.491236051926643

Epoch: 5| Step: 7
Training loss: 1.6463530319517288
Validation loss: 2.459640145855736

Epoch: 5| Step: 8
Training loss: 2.1356064378726036
Validation loss: 2.505938013200815

Epoch: 5| Step: 9
Training loss: 1.6896983062471962
Validation loss: 2.4047015369319586

Epoch: 5| Step: 10
Training loss: 1.775962880047371
Validation loss: 2.5080408996613905

Epoch: 448| Step: 0
Training loss: 1.7802754463356054
Validation loss: 2.4541778698185723

Epoch: 5| Step: 1
Training loss: 1.2431426784357313
Validation loss: 2.4419869164139403

Epoch: 5| Step: 2
Training loss: 1.7382528581336532
Validation loss: 2.456411303470775

Epoch: 5| Step: 3
Training loss: 1.781508443721918
Validation loss: 2.464403879139793

Epoch: 5| Step: 4
Training loss: 1.516451187686442
Validation loss: 2.478693001607127

Epoch: 5| Step: 5
Training loss: 2.170139634874004
Validation loss: 2.465548790718918

Epoch: 5| Step: 6
Training loss: 1.940659131718987
Validation loss: 2.4863553375117804

Epoch: 5| Step: 7
Training loss: 1.7240334885303055
Validation loss: 2.4556105670357553

Epoch: 5| Step: 8
Training loss: 1.6807154149439676
Validation loss: 2.451687516716164

Epoch: 5| Step: 9
Training loss: 1.504105829644723
Validation loss: 2.4486982519946556

Epoch: 5| Step: 10
Training loss: 1.7693961725615504
Validation loss: 2.4600809409135462

Epoch: 449| Step: 0
Training loss: 1.7398628497606279
Validation loss: 2.456131017118563

Epoch: 5| Step: 1
Training loss: 1.750310597785634
Validation loss: 2.450727599832401

Epoch: 5| Step: 2
Training loss: 1.9285217965011643
Validation loss: 2.513838365719003

Epoch: 5| Step: 3
Training loss: 1.5127341633013283
Validation loss: 2.5029362417052696

Epoch: 5| Step: 4
Training loss: 1.716626329164123
Validation loss: 2.4863634490345694

Epoch: 5| Step: 5
Training loss: 1.7802238855041608
Validation loss: 2.492856141508354

Epoch: 5| Step: 6
Training loss: 1.569222978515762
Validation loss: 2.4679466821191043

Epoch: 5| Step: 7
Training loss: 1.6525862856223277
Validation loss: 2.492585948490307

Epoch: 5| Step: 8
Training loss: 2.1431290953500532
Validation loss: 2.4323000273486506

Epoch: 5| Step: 9
Training loss: 1.939950377920986
Validation loss: 2.517075085220968

Epoch: 5| Step: 10
Training loss: 1.6064515458655662
Validation loss: 2.544258451081621

Epoch: 450| Step: 0
Training loss: 1.8442595472819108
Validation loss: 2.487699640344467

Epoch: 5| Step: 1
Training loss: 1.69594411027336
Validation loss: 2.5179484989831935

Epoch: 5| Step: 2
Training loss: 1.2378083297709324
Validation loss: 2.471454380561943

Epoch: 5| Step: 3
Training loss: 1.685305192402099
Validation loss: 2.4292994147294737

Epoch: 5| Step: 4
Training loss: 1.399600009317281
Validation loss: 2.45018105347499

Epoch: 5| Step: 5
Training loss: 2.3059916281767356
Validation loss: 2.4981775439896623

Epoch: 5| Step: 6
Training loss: 1.6389394184807293
Validation loss: 2.4631028922259035

Epoch: 5| Step: 7
Training loss: 2.143626538160839
Validation loss: 2.5006699689812137

Epoch: 5| Step: 8
Training loss: 1.6062900642118603
Validation loss: 2.430596514902168

Epoch: 5| Step: 9
Training loss: 1.6454134860297411
Validation loss: 2.4910158297606264

Epoch: 5| Step: 10
Training loss: 1.5613361601805296
Validation loss: 2.4601269802863084

Epoch: 451| Step: 0
Training loss: 2.1903470721505007
Validation loss: 2.4367131734684784

Epoch: 5| Step: 1
Training loss: 1.2513092337201261
Validation loss: 2.478024189925459

Epoch: 5| Step: 2
Training loss: 1.6725927933295581
Validation loss: 2.503305220698084

Epoch: 5| Step: 3
Training loss: 1.9457853424340457
Validation loss: 2.501752194236551

Epoch: 5| Step: 4
Training loss: 1.472585418373871
Validation loss: 2.480385628966775

Epoch: 5| Step: 5
Training loss: 1.955230310635285
Validation loss: 2.5303113709440685

Epoch: 5| Step: 6
Training loss: 1.2977245260026467
Validation loss: 2.5311431700174722

Epoch: 5| Step: 7
Training loss: 1.5587829627962193
Validation loss: 2.4637999987226333

Epoch: 5| Step: 8
Training loss: 2.2830983864783594
Validation loss: 2.5106642215564303

Epoch: 5| Step: 9
Training loss: 1.7294506927457967
Validation loss: 2.4658117300050924

Epoch: 5| Step: 10
Training loss: 1.3274538027093963
Validation loss: 2.4928249824896107

Epoch: 452| Step: 0
Training loss: 1.772115811462109
Validation loss: 2.498809594618418

Epoch: 5| Step: 1
Training loss: 1.53266794376616
Validation loss: 2.459015751708653

Epoch: 5| Step: 2
Training loss: 1.912959438813243
Validation loss: 2.521598328304601

Epoch: 5| Step: 3
Training loss: 1.701117285850066
Validation loss: 2.471420043605333

Epoch: 5| Step: 4
Training loss: 1.993493344041569
Validation loss: 2.4721234182674734

Epoch: 5| Step: 5
Training loss: 1.460395100316877
Validation loss: 2.475379921068673

Epoch: 5| Step: 6
Training loss: 1.9073129410723046
Validation loss: 2.4428964653449743

Epoch: 5| Step: 7
Training loss: 1.3157144873985631
Validation loss: 2.468692341166616

Epoch: 5| Step: 8
Training loss: 1.9354177791837268
Validation loss: 2.494347847401056

Epoch: 5| Step: 9
Training loss: 1.9707174612531377
Validation loss: 2.4591407614400116

Epoch: 5| Step: 10
Training loss: 1.532603697014349
Validation loss: 2.3927219338107104

Epoch: 453| Step: 0
Training loss: 1.1709961202184187
Validation loss: 2.4532667173572307

Epoch: 5| Step: 1
Training loss: 1.7713445336979952
Validation loss: 2.4617902630867303

Epoch: 5| Step: 2
Training loss: 1.835520335750629
Validation loss: 2.4722460033985425

Epoch: 5| Step: 3
Training loss: 1.9867339043258663
Validation loss: 2.4220169846127932

Epoch: 5| Step: 4
Training loss: 1.2437388970727725
Validation loss: 2.4374249501713128

Epoch: 5| Step: 5
Training loss: 2.1552755392986467
Validation loss: 2.4449525225015125

Epoch: 5| Step: 6
Training loss: 1.6852735737655822
Validation loss: 2.4458172790310146

Epoch: 5| Step: 7
Training loss: 1.7675334777251464
Validation loss: 2.433688524936528

Epoch: 5| Step: 8
Training loss: 1.6096171965342139
Validation loss: 2.480801440862618

Epoch: 5| Step: 9
Training loss: 1.7382823472608897
Validation loss: 2.503778476618371

Epoch: 5| Step: 10
Training loss: 1.8331625887804652
Validation loss: 2.424552947991657

Epoch: 454| Step: 0
Training loss: 1.4332556052904295
Validation loss: 2.4192695504198856

Epoch: 5| Step: 1
Training loss: 1.596207015042029
Validation loss: 2.3832691881305164

Epoch: 5| Step: 2
Training loss: 1.6531992471964128
Validation loss: 2.4474654732062406

Epoch: 5| Step: 3
Training loss: 2.3132695129158614
Validation loss: 2.5170832759835586

Epoch: 5| Step: 4
Training loss: 1.3412264703995789
Validation loss: 2.524369332693648

Epoch: 5| Step: 5
Training loss: 1.5039994644407577
Validation loss: 2.488952190813848

Epoch: 5| Step: 6
Training loss: 2.100595812062739
Validation loss: 2.453348070615793

Epoch: 5| Step: 7
Training loss: 2.0870117393130583
Validation loss: 2.509810434277146

Epoch: 5| Step: 8
Training loss: 1.3941600743692932
Validation loss: 2.5214440475419653

Epoch: 5| Step: 9
Training loss: 1.84436645547199
Validation loss: 2.4794983911188893

Epoch: 5| Step: 10
Training loss: 1.578920447178602
Validation loss: 2.490581317743504

Epoch: 455| Step: 0
Training loss: 1.983110280143096
Validation loss: 2.424761608141985

Epoch: 5| Step: 1
Training loss: 2.4394465767838955
Validation loss: 2.4103005522719063

Epoch: 5| Step: 2
Training loss: 1.5406691786678033
Validation loss: 2.442886699361119

Epoch: 5| Step: 3
Training loss: 1.7856249705185452
Validation loss: 2.4354126887984306

Epoch: 5| Step: 4
Training loss: 1.5680928651110113
Validation loss: 2.423049242495801

Epoch: 5| Step: 5
Training loss: 1.3805742414545867
Validation loss: 2.427381741595465

Epoch: 5| Step: 6
Training loss: 1.5863457516026982
Validation loss: 2.4415618513502313

Epoch: 5| Step: 7
Training loss: 1.5066682891640044
Validation loss: 2.4460955270393865

Epoch: 5| Step: 8
Training loss: 1.7794448673746543
Validation loss: 2.5099495373281133

Epoch: 5| Step: 9
Training loss: 1.9076999090589908
Validation loss: 2.47385130948152

Epoch: 5| Step: 10
Training loss: 1.3787038076345826
Validation loss: 2.4846335140038156

Epoch: 456| Step: 0
Training loss: 1.44301294446018
Validation loss: 2.4518175457315423

Epoch: 5| Step: 1
Training loss: 1.370580550002259
Validation loss: 2.5094663339155874

Epoch: 5| Step: 2
Training loss: 1.7085265151174849
Validation loss: 2.4573894424647236

Epoch: 5| Step: 3
Training loss: 1.810766377563652
Validation loss: 2.474755240533894

Epoch: 5| Step: 4
Training loss: 2.3008895356322268
Validation loss: 2.5092928142633535

Epoch: 5| Step: 5
Training loss: 1.7294121610111333
Validation loss: 2.5244515833362446

Epoch: 5| Step: 6
Training loss: 2.0926073286999896
Validation loss: 2.4383655081101274

Epoch: 5| Step: 7
Training loss: 1.2151829285922415
Validation loss: 2.5438305966217722

Epoch: 5| Step: 8
Training loss: 1.5056837798378992
Validation loss: 2.5111809295085425

Epoch: 5| Step: 9
Training loss: 1.714943363711442
Validation loss: 2.53213490673973

Epoch: 5| Step: 10
Training loss: 1.642101749464348
Validation loss: 2.444296876407943

Epoch: 457| Step: 0
Training loss: 1.461305786059959
Validation loss: 2.4289552906662344

Epoch: 5| Step: 1
Training loss: 1.6360897048056444
Validation loss: 2.4994396155910925

Epoch: 5| Step: 2
Training loss: 1.496241549768384
Validation loss: 2.423877346929255

Epoch: 5| Step: 3
Training loss: 1.361444979978929
Validation loss: 2.418652137548116

Epoch: 5| Step: 4
Training loss: 1.6389429825226767
Validation loss: 2.4761908638495336

Epoch: 5| Step: 5
Training loss: 1.9059504289215141
Validation loss: 2.4757462363566147

Epoch: 5| Step: 6
Training loss: 2.104000110140315
Validation loss: 2.4589570133617267

Epoch: 5| Step: 7
Training loss: 1.851376745507392
Validation loss: 2.4723716807571856

Epoch: 5| Step: 8
Training loss: 1.4849105671883434
Validation loss: 2.4517326711958214

Epoch: 5| Step: 9
Training loss: 2.125476671498703
Validation loss: 2.445305704327999

Epoch: 5| Step: 10
Training loss: 1.4796264990344346
Validation loss: 2.4570973843541335

Epoch: 458| Step: 0
Training loss: 1.6461292033095845
Validation loss: 2.4448941137011615

Epoch: 5| Step: 1
Training loss: 1.9941834866422414
Validation loss: 2.4643472405744324

Epoch: 5| Step: 2
Training loss: 1.4946378391700548
Validation loss: 2.5125714888544812

Epoch: 5| Step: 3
Training loss: 1.6873246561010924
Validation loss: 2.4540859952983394

Epoch: 5| Step: 4
Training loss: 1.3471313338848045
Validation loss: 2.4740094814399547

Epoch: 5| Step: 5
Training loss: 1.9421197512680264
Validation loss: 2.4725125427584906

Epoch: 5| Step: 6
Training loss: 1.5623012416308963
Validation loss: 2.4072567363008495

Epoch: 5| Step: 7
Training loss: 1.790773131949012
Validation loss: 2.429577203510461

Epoch: 5| Step: 8
Training loss: 1.732249220165375
Validation loss: 2.4765485822227595

Epoch: 5| Step: 9
Training loss: 1.7064383937245284
Validation loss: 2.494813924662693

Epoch: 5| Step: 10
Training loss: 1.7755343103125796
Validation loss: 2.4790966292557055

Epoch: 459| Step: 0
Training loss: 1.5457661825780062
Validation loss: 2.4700873654362834

Epoch: 5| Step: 1
Training loss: 1.65424052280976
Validation loss: 2.4461004738501018

Epoch: 5| Step: 2
Training loss: 1.4000465896211245
Validation loss: 2.4581222033334384

Epoch: 5| Step: 3
Training loss: 1.574211025929019
Validation loss: 2.4214973454295876

Epoch: 5| Step: 4
Training loss: 1.3309544660602435
Validation loss: 2.442141626269782

Epoch: 5| Step: 5
Training loss: 1.8127745058746745
Validation loss: 2.4619428340066656

Epoch: 5| Step: 6
Training loss: 2.3825064040395163
Validation loss: 2.4901718231522927

Epoch: 5| Step: 7
Training loss: 1.7592072103657048
Validation loss: 2.4336372228996157

Epoch: 5| Step: 8
Training loss: 1.7850918079990254
Validation loss: 2.477078041345543

Epoch: 5| Step: 9
Training loss: 1.6356265992275958
Validation loss: 2.4283045175645985

Epoch: 5| Step: 10
Training loss: 1.815704406997821
Validation loss: 2.444969696545633

Epoch: 460| Step: 0
Training loss: 1.2989575773276194
Validation loss: 2.4592631899850628

Epoch: 5| Step: 1
Training loss: 1.4500211977231352
Validation loss: 2.5479286551427207

Epoch: 5| Step: 2
Training loss: 1.9874866149259691
Validation loss: 2.4431342139748056

Epoch: 5| Step: 3
Training loss: 1.2049053445416842
Validation loss: 2.4314822146720925

Epoch: 5| Step: 4
Training loss: 1.5854023749383641
Validation loss: 2.447703685061071

Epoch: 5| Step: 5
Training loss: 2.321119277387446
Validation loss: 2.470972589508766

Epoch: 5| Step: 6
Training loss: 1.6399379199769037
Validation loss: 2.4445544124045457

Epoch: 5| Step: 7
Training loss: 1.4166501642649774
Validation loss: 2.4988540956025176

Epoch: 5| Step: 8
Training loss: 2.208193960530138
Validation loss: 2.502315342250684

Epoch: 5| Step: 9
Training loss: 1.7066619962514114
Validation loss: 2.541954722859237

Epoch: 5| Step: 10
Training loss: 1.8236587612450472
Validation loss: 2.4877947262465496

Epoch: 461| Step: 0
Training loss: 1.8327855100864001
Validation loss: 2.4626016605310554

Epoch: 5| Step: 1
Training loss: 2.085277324318669
Validation loss: 2.441223527268403

Epoch: 5| Step: 2
Training loss: 1.63324479946568
Validation loss: 2.4739953933470193

Epoch: 5| Step: 3
Training loss: 1.4684391910326489
Validation loss: 2.4310724743771033

Epoch: 5| Step: 4
Training loss: 1.5781873936169106
Validation loss: 2.4275182568190847

Epoch: 5| Step: 5
Training loss: 1.7123042530761112
Validation loss: 2.40164804590409

Epoch: 5| Step: 6
Training loss: 1.3990430320082248
Validation loss: 2.4815643668504537

Epoch: 5| Step: 7
Training loss: 1.7980070445778806
Validation loss: 2.4892956078352064

Epoch: 5| Step: 8
Training loss: 2.1146896661290997
Validation loss: 2.4380900823303597

Epoch: 5| Step: 9
Training loss: 1.8125101944209199
Validation loss: 2.4602219949912896

Epoch: 5| Step: 10
Training loss: 1.4884379146750748
Validation loss: 2.49264612053177

Epoch: 462| Step: 0
Training loss: 1.401860570948134
Validation loss: 2.4780263376509226

Epoch: 5| Step: 1
Training loss: 1.6702981803715584
Validation loss: 2.5251443436045298

Epoch: 5| Step: 2
Training loss: 1.257839321063758
Validation loss: 2.4470063062576086

Epoch: 5| Step: 3
Training loss: 1.3540041703761463
Validation loss: 2.401895137331428

Epoch: 5| Step: 4
Training loss: 1.6941752332829494
Validation loss: 2.4869032445493797

Epoch: 5| Step: 5
Training loss: 1.6469790981335255
Validation loss: 2.5081978671357934

Epoch: 5| Step: 6
Training loss: 2.0937314388534203
Validation loss: 2.4379238467985025

Epoch: 5| Step: 7
Training loss: 1.9976624298895231
Validation loss: 2.485772944122189

Epoch: 5| Step: 8
Training loss: 1.258287328338058
Validation loss: 2.4767804186934113

Epoch: 5| Step: 9
Training loss: 2.1976563237716062
Validation loss: 2.514412942275809

Epoch: 5| Step: 10
Training loss: 1.8895339339702588
Validation loss: 2.465817902542605

Epoch: 463| Step: 0
Training loss: 1.3394441592633144
Validation loss: 2.444588734504839

Epoch: 5| Step: 1
Training loss: 1.6424225178969394
Validation loss: 2.5040880557376655

Epoch: 5| Step: 2
Training loss: 1.89627328595604
Validation loss: 2.465474911848412

Epoch: 5| Step: 3
Training loss: 1.9451381497977736
Validation loss: 2.4647597078280885

Epoch: 5| Step: 4
Training loss: 2.0943319166778642
Validation loss: 2.4660100242748264

Epoch: 5| Step: 5
Training loss: 1.9598914772273859
Validation loss: 2.462684848302827

Epoch: 5| Step: 6
Training loss: 1.680003220804851
Validation loss: 2.4335194582968245

Epoch: 5| Step: 7
Training loss: 1.5426505617824868
Validation loss: 2.481432355025323

Epoch: 5| Step: 8
Training loss: 1.5169601851577654
Validation loss: 2.5106107347184072

Epoch: 5| Step: 9
Training loss: 1.3316678533123079
Validation loss: 2.5016926705947493

Epoch: 5| Step: 10
Training loss: 1.7298828235258834
Validation loss: 2.461819612953795

Epoch: 464| Step: 0
Training loss: 2.033305609884071
Validation loss: 2.496512687960361

Epoch: 5| Step: 1
Training loss: 2.243730818047522
Validation loss: 2.523848570470013

Epoch: 5| Step: 2
Training loss: 1.4607831904061495
Validation loss: 2.457120688764472

Epoch: 5| Step: 3
Training loss: 1.4926102923052067
Validation loss: 2.512002452684843

Epoch: 5| Step: 4
Training loss: 1.7021135599105304
Validation loss: 2.4978062715881744

Epoch: 5| Step: 5
Training loss: 1.6176427670284192
Validation loss: 2.51524639649989

Epoch: 5| Step: 6
Training loss: 1.5785544538170901
Validation loss: 2.5097221091432043

Epoch: 5| Step: 7
Training loss: 1.7733396259473475
Validation loss: 2.4277188562580885

Epoch: 5| Step: 8
Training loss: 1.3307188846118743
Validation loss: 2.4581938753222103

Epoch: 5| Step: 9
Training loss: 1.8481917462182285
Validation loss: 2.4418508793708784

Epoch: 5| Step: 10
Training loss: 1.634621015599421
Validation loss: 2.457604081277771

Epoch: 465| Step: 0
Training loss: 1.932918299598714
Validation loss: 2.484335182568946

Epoch: 5| Step: 1
Training loss: 1.4690643948021609
Validation loss: 2.4925202240069275

Epoch: 5| Step: 2
Training loss: 1.7453334441674306
Validation loss: 2.4654379710630523

Epoch: 5| Step: 3
Training loss: 1.844633117215368
Validation loss: 2.439704950527577

Epoch: 5| Step: 4
Training loss: 1.6103283919222602
Validation loss: 2.5263610604092888

Epoch: 5| Step: 5
Training loss: 1.6477292243204547
Validation loss: 2.5492352107881207

Epoch: 5| Step: 6
Training loss: 2.3462326125576305
Validation loss: 2.544757981067939

Epoch: 5| Step: 7
Training loss: 1.824606941954898
Validation loss: 2.5447014722257544

Epoch: 5| Step: 8
Training loss: 2.1157753376814408
Validation loss: 2.5200199376652432

Epoch: 5| Step: 9
Training loss: 1.5854538053088494
Validation loss: 2.533179948728747

Epoch: 5| Step: 10
Training loss: 1.1922120917947419
Validation loss: 2.5873307211009338

Epoch: 466| Step: 0
Training loss: 1.9849607549290234
Validation loss: 2.4551667431832693

Epoch: 5| Step: 1
Training loss: 1.5419856162532164
Validation loss: 2.4188182995733527

Epoch: 5| Step: 2
Training loss: 1.0256526357959528
Validation loss: 2.4918463035550134

Epoch: 5| Step: 3
Training loss: 1.6443982285729668
Validation loss: 2.431981178747709

Epoch: 5| Step: 4
Training loss: 1.549806072039788
Validation loss: 2.403859093176107

Epoch: 5| Step: 5
Training loss: 1.535396799746606
Validation loss: 2.5037313384885245

Epoch: 5| Step: 6
Training loss: 2.0968802666633515
Validation loss: 2.482516540863667

Epoch: 5| Step: 7
Training loss: 1.404631085477599
Validation loss: 2.4762718718796264

Epoch: 5| Step: 8
Training loss: 1.9828022408727282
Validation loss: 2.4591789091441294

Epoch: 5| Step: 9
Training loss: 2.202515105110184
Validation loss: 2.445059223170369

Epoch: 5| Step: 10
Training loss: 1.3463114344925267
Validation loss: 2.529985741839346

Epoch: 467| Step: 0
Training loss: 1.7606867370506318
Validation loss: 2.4838357914134597

Epoch: 5| Step: 1
Training loss: 1.7272823438422338
Validation loss: 2.4231354057878285

Epoch: 5| Step: 2
Training loss: 1.1710714509862856
Validation loss: 2.4540969640119736

Epoch: 5| Step: 3
Training loss: 1.7969658870102039
Validation loss: 2.4484257999651082

Epoch: 5| Step: 4
Training loss: 1.410098552844384
Validation loss: 2.4365658564788553

Epoch: 5| Step: 5
Training loss: 1.693679093006308
Validation loss: 2.4338839886285095

Epoch: 5| Step: 6
Training loss: 2.0872021673937677
Validation loss: 2.495090273988558

Epoch: 5| Step: 7
Training loss: 1.7589187193021314
Validation loss: 2.4943785624149086

Epoch: 5| Step: 8
Training loss: 1.702715133204718
Validation loss: 2.5040283178489653

Epoch: 5| Step: 9
Training loss: 1.5884640867540023
Validation loss: 2.4790732408435403

Epoch: 5| Step: 10
Training loss: 1.600700928221411
Validation loss: 2.4925939811124573

Epoch: 468| Step: 0
Training loss: 1.8153663858147462
Validation loss: 2.516157548030008

Epoch: 5| Step: 1
Training loss: 2.2318878202516137
Validation loss: 2.4863238005835773

Epoch: 5| Step: 2
Training loss: 1.5665109651719347
Validation loss: 2.494869098330442

Epoch: 5| Step: 3
Training loss: 1.5269608664054128
Validation loss: 2.4305005551242096

Epoch: 5| Step: 4
Training loss: 1.5538165849580032
Validation loss: 2.523826536368575

Epoch: 5| Step: 5
Training loss: 1.7938351335160576
Validation loss: 2.435465406063846

Epoch: 5| Step: 6
Training loss: 1.8688669353119995
Validation loss: 2.4687978486231725

Epoch: 5| Step: 7
Training loss: 1.1541290419375667
Validation loss: 2.4523952337377724

Epoch: 5| Step: 8
Training loss: 1.8155583197057614
Validation loss: 2.4147939795374365

Epoch: 5| Step: 9
Training loss: 1.5711345134285921
Validation loss: 2.4691633815841194

Epoch: 5| Step: 10
Training loss: 1.5680194263033378
Validation loss: 2.425774156540479

Epoch: 469| Step: 0
Training loss: 1.81839307186319
Validation loss: 2.4717119630609647

Epoch: 5| Step: 1
Training loss: 1.0924736204825247
Validation loss: 2.4466419287970527

Epoch: 5| Step: 2
Training loss: 1.741562051079961
Validation loss: 2.502786920584877

Epoch: 5| Step: 3
Training loss: 1.6989895370053454
Validation loss: 2.4951070695374167

Epoch: 5| Step: 4
Training loss: 1.8435270530261436
Validation loss: 2.4818789795318685

Epoch: 5| Step: 5
Training loss: 2.3104468845584756
Validation loss: 2.4969092531971007

Epoch: 5| Step: 6
Training loss: 1.8576766520273513
Validation loss: 2.444281338010336

Epoch: 5| Step: 7
Training loss: 1.7467051551426975
Validation loss: 2.4348891505518795

Epoch: 5| Step: 8
Training loss: 1.4226639623291522
Validation loss: 2.4431738256543007

Epoch: 5| Step: 9
Training loss: 1.804769274687814
Validation loss: 2.4569856555420877

Epoch: 5| Step: 10
Training loss: 1.5819672748204703
Validation loss: 2.43035932984231

Epoch: 470| Step: 0
Training loss: 1.5631659042454695
Validation loss: 2.479173877595621

Epoch: 5| Step: 1
Training loss: 1.6562321499996258
Validation loss: 2.5350413831511807

Epoch: 5| Step: 2
Training loss: 1.800199667134936
Validation loss: 2.484304947064397

Epoch: 5| Step: 3
Training loss: 1.906541958322928
Validation loss: 2.480332460761872

Epoch: 5| Step: 4
Training loss: 1.7647539538960517
Validation loss: 2.5193834731274185

Epoch: 5| Step: 5
Training loss: 1.53789146526024
Validation loss: 2.471495711451076

Epoch: 5| Step: 6
Training loss: 1.7842832471570216
Validation loss: 2.4876856983111177

Epoch: 5| Step: 7
Training loss: 1.1991510030391939
Validation loss: 2.5311599283968618

Epoch: 5| Step: 8
Training loss: 1.4959047362447362
Validation loss: 2.556849395546508

Epoch: 5| Step: 9
Training loss: 1.7180571806987428
Validation loss: 2.5270574099097347

Epoch: 5| Step: 10
Training loss: 2.137806617205672
Validation loss: 2.4538148028124662

Epoch: 471| Step: 0
Training loss: 1.7519233216267256
Validation loss: 2.451637788629011

Epoch: 5| Step: 1
Training loss: 1.879971969273778
Validation loss: 2.4745704892638205

Epoch: 5| Step: 2
Training loss: 1.4719439739418434
Validation loss: 2.4969166774388314

Epoch: 5| Step: 3
Training loss: 1.4129056466221352
Validation loss: 2.458449588471874

Epoch: 5| Step: 4
Training loss: 1.1098085013152832
Validation loss: 2.464647817728107

Epoch: 5| Step: 5
Training loss: 1.6098134452828008
Validation loss: 2.507994480511717

Epoch: 5| Step: 6
Training loss: 2.0994842350061957
Validation loss: 2.5142574783024063

Epoch: 5| Step: 7
Training loss: 1.5796197289966576
Validation loss: 2.449282703616963

Epoch: 5| Step: 8
Training loss: 2.1149889802758386
Validation loss: 2.455701810342768

Epoch: 5| Step: 9
Training loss: 1.561718707254017
Validation loss: 2.4541964104004603

Epoch: 5| Step: 10
Training loss: 1.6174271263203512
Validation loss: 2.4401810055533666

Epoch: 472| Step: 0
Training loss: 1.4248537992467527
Validation loss: 2.499508357158306

Epoch: 5| Step: 1
Training loss: 1.6770637779596334
Validation loss: 2.5079324758952146

Epoch: 5| Step: 2
Training loss: 1.7564948674883567
Validation loss: 2.492712508134086

Epoch: 5| Step: 3
Training loss: 1.5046408704462784
Validation loss: 2.5325286625423082

Epoch: 5| Step: 4
Training loss: 1.878630492977341
Validation loss: 2.462371942523862

Epoch: 5| Step: 5
Training loss: 1.473784239858989
Validation loss: 2.461916903219636

Epoch: 5| Step: 6
Training loss: 2.2623349208568606
Validation loss: 2.4797299900561987

Epoch: 5| Step: 7
Training loss: 1.3945216758249772
Validation loss: 2.4518015039574035

Epoch: 5| Step: 8
Training loss: 1.5128303009542985
Validation loss: 2.4576544897632164

Epoch: 5| Step: 9
Training loss: 1.360299201828472
Validation loss: 2.467751884433692

Epoch: 5| Step: 10
Training loss: 2.157973885767966
Validation loss: 2.506913835363665

Epoch: 473| Step: 0
Training loss: 1.6983232615917523
Validation loss: 2.5326882867491847

Epoch: 5| Step: 1
Training loss: 1.8439756352352015
Validation loss: 2.440874403385628

Epoch: 5| Step: 2
Training loss: 1.7233441767668087
Validation loss: 2.4341482335586337

Epoch: 5| Step: 3
Training loss: 1.809507201113764
Validation loss: 2.4992989362102382

Epoch: 5| Step: 4
Training loss: 1.7630616206339658
Validation loss: 2.4395146291367658

Epoch: 5| Step: 5
Training loss: 1.485067266360017
Validation loss: 2.444011507922332

Epoch: 5| Step: 6
Training loss: 1.9768689788717015
Validation loss: 2.485421335288688

Epoch: 5| Step: 7
Training loss: 1.6209617469081665
Validation loss: 2.4521898292860147

Epoch: 5| Step: 8
Training loss: 1.3063481435456172
Validation loss: 2.5085353065879104

Epoch: 5| Step: 9
Training loss: 1.6869248010351658
Validation loss: 2.4670150515246

Epoch: 5| Step: 10
Training loss: 1.6839501519244149
Validation loss: 2.4782971658124113

Epoch: 474| Step: 0
Training loss: 1.4812529809334292
Validation loss: 2.5020307322469106

Epoch: 5| Step: 1
Training loss: 1.878898826790657
Validation loss: 2.473598901688282

Epoch: 5| Step: 2
Training loss: 1.8298439356435963
Validation loss: 2.4481198800977073

Epoch: 5| Step: 3
Training loss: 1.4280184816665795
Validation loss: 2.510644981906014

Epoch: 5| Step: 4
Training loss: 2.014170395333823
Validation loss: 2.479713303844701

Epoch: 5| Step: 5
Training loss: 1.531669403560768
Validation loss: 2.4769866974462857

Epoch: 5| Step: 6
Training loss: 1.4676132673128088
Validation loss: 2.447192902784905

Epoch: 5| Step: 7
Training loss: 1.837884917133804
Validation loss: 2.442995931125486

Epoch: 5| Step: 8
Training loss: 1.568757079211064
Validation loss: 2.443220975832146

Epoch: 5| Step: 9
Training loss: 1.3087542990510972
Validation loss: 2.465578184225714

Epoch: 5| Step: 10
Training loss: 2.0512916729010606
Validation loss: 2.488352070832448

Epoch: 475| Step: 0
Training loss: 1.892344677899448
Validation loss: 2.4398578759352163

Epoch: 5| Step: 1
Training loss: 1.9339095657294318
Validation loss: 2.473487927587006

Epoch: 5| Step: 2
Training loss: 1.8497842869133612
Validation loss: 2.459336665451864

Epoch: 5| Step: 3
Training loss: 2.031524756995925
Validation loss: 2.462383528152088

Epoch: 5| Step: 4
Training loss: 1.5586932540145524
Validation loss: 2.475306686719186

Epoch: 5| Step: 5
Training loss: 1.3621770546029812
Validation loss: 2.4424105912590224

Epoch: 5| Step: 6
Training loss: 1.5082664794578013
Validation loss: 2.51235233991905

Epoch: 5| Step: 7
Training loss: 1.6413706220475919
Validation loss: 2.48437981899478

Epoch: 5| Step: 8
Training loss: 1.4113711040423798
Validation loss: 2.4897091954247745

Epoch: 5| Step: 9
Training loss: 1.3561252905822212
Validation loss: 2.471542303692411

Epoch: 5| Step: 10
Training loss: 2.005288760731485
Validation loss: 2.4478660014470175

Epoch: 476| Step: 0
Training loss: 1.3893122102085953
Validation loss: 2.4546091901227927

Epoch: 5| Step: 1
Training loss: 1.4330270255096602
Validation loss: 2.4981109167844613

Epoch: 5| Step: 2
Training loss: 2.0594217853701977
Validation loss: 2.4788268973181036

Epoch: 5| Step: 3
Training loss: 1.4196322852852405
Validation loss: 2.487359186194788

Epoch: 5| Step: 4
Training loss: 1.629638141531983
Validation loss: 2.50752986347369

Epoch: 5| Step: 5
Training loss: 1.8774068008229776
Validation loss: 2.4357690305001682

Epoch: 5| Step: 6
Training loss: 2.315483539909124
Validation loss: 2.4928428972889707

Epoch: 5| Step: 7
Training loss: 1.627279297005104
Validation loss: 2.446972337609041

Epoch: 5| Step: 8
Training loss: 1.7128934088133023
Validation loss: 2.4501176318252256

Epoch: 5| Step: 9
Training loss: 1.4981829445923918
Validation loss: 2.4472145656828315

Epoch: 5| Step: 10
Training loss: 0.9668107773523004
Validation loss: 2.42453996244107

Epoch: 477| Step: 0
Training loss: 1.5531607180504439
Validation loss: 2.5242437437750813

Epoch: 5| Step: 1
Training loss: 1.5788712955854514
Validation loss: 2.456734835418472

Epoch: 5| Step: 2
Training loss: 1.3015410807336592
Validation loss: 2.5202963875932975

Epoch: 5| Step: 3
Training loss: 1.3890305711747604
Validation loss: 2.506830705566397

Epoch: 5| Step: 4
Training loss: 1.450347543041139
Validation loss: 2.4375255568652494

Epoch: 5| Step: 5
Training loss: 1.5580248260429883
Validation loss: 2.504977784467961

Epoch: 5| Step: 6
Training loss: 2.2166835134148086
Validation loss: 2.478295420717701

Epoch: 5| Step: 7
Training loss: 1.4706830229784895
Validation loss: 2.461636086187051

Epoch: 5| Step: 8
Training loss: 1.8423955435885733
Validation loss: 2.450203650454676

Epoch: 5| Step: 9
Training loss: 1.734753816491841
Validation loss: 2.457290068960964

Epoch: 5| Step: 10
Training loss: 1.981041518833937
Validation loss: 2.52304905698961

Epoch: 478| Step: 0
Training loss: 1.7009188861378601
Validation loss: 2.4794192783058517

Epoch: 5| Step: 1
Training loss: 1.7610542075908295
Validation loss: 2.4583553051127436

Epoch: 5| Step: 2
Training loss: 1.8985257226358265
Validation loss: 2.4538409691389247

Epoch: 5| Step: 3
Training loss: 1.8680280126394946
Validation loss: 2.463418985917214

Epoch: 5| Step: 4
Training loss: 1.7337281679127883
Validation loss: 2.455452617274757

Epoch: 5| Step: 5
Training loss: 1.62127022759283
Validation loss: 2.4136051230942672

Epoch: 5| Step: 6
Training loss: 1.3306003615220159
Validation loss: 2.504890652170758

Epoch: 5| Step: 7
Training loss: 1.4980978826520215
Validation loss: 2.440439578869306

Epoch: 5| Step: 8
Training loss: 1.5605624583663424
Validation loss: 2.4914135807029716

Epoch: 5| Step: 9
Training loss: 1.6580868737546168
Validation loss: 2.474223560219898

Epoch: 5| Step: 10
Training loss: 1.134297522218815
Validation loss: 2.4703350967650506

Epoch: 479| Step: 0
Training loss: 1.9016674805800189
Validation loss: 2.4630751194151217

Epoch: 5| Step: 1
Training loss: 1.4887174032311672
Validation loss: 2.474339004184035

Epoch: 5| Step: 2
Training loss: 2.0052514273896778
Validation loss: 2.426275158263898

Epoch: 5| Step: 3
Training loss: 1.6204829156734804
Validation loss: 2.4309805165035567

Epoch: 5| Step: 4
Training loss: 1.7202132498706426
Validation loss: 2.4120311176846925

Epoch: 5| Step: 5
Training loss: 1.9012353319433681
Validation loss: 2.4565315262051017

Epoch: 5| Step: 6
Training loss: 1.6277053028473798
Validation loss: 2.515350813978236

Epoch: 5| Step: 7
Training loss: 1.895300954609022
Validation loss: 2.4837091076825337

Epoch: 5| Step: 8
Training loss: 1.2057586677298253
Validation loss: 2.5080274591305582

Epoch: 5| Step: 9
Training loss: 1.4986353865857032
Validation loss: 2.4819363583607683

Epoch: 5| Step: 10
Training loss: 1.9622894125528332
Validation loss: 2.4512004086321975

Epoch: 480| Step: 0
Training loss: 2.1888303798379765
Validation loss: 2.4449259438602327

Epoch: 5| Step: 1
Training loss: 1.5963524159291693
Validation loss: 2.4500745643518154

Epoch: 5| Step: 2
Training loss: 1.9421498277344982
Validation loss: 2.5090123430808386

Epoch: 5| Step: 3
Training loss: 1.661098078432419
Validation loss: 2.4941759771490513

Epoch: 5| Step: 4
Training loss: 1.237799325057644
Validation loss: 2.483134979708442

Epoch: 5| Step: 5
Training loss: 1.560742877973896
Validation loss: 2.468606560723511

Epoch: 5| Step: 6
Training loss: 1.5275337120618961
Validation loss: 2.4411869903222905

Epoch: 5| Step: 7
Training loss: 1.6184175392948486
Validation loss: 2.495630103911777

Epoch: 5| Step: 8
Training loss: 1.485989305172783
Validation loss: 2.4631103434272346

Epoch: 5| Step: 9
Training loss: 1.7094073834742822
Validation loss: 2.5116951529765426

Epoch: 5| Step: 10
Training loss: 1.3781116995310203
Validation loss: 2.475165586006876

Epoch: 481| Step: 0
Training loss: 1.5938138761996499
Validation loss: 2.4808534395752435

Epoch: 5| Step: 1
Training loss: 1.6480213381209903
Validation loss: 2.4977535327098206

Epoch: 5| Step: 2
Training loss: 1.6733960514296027
Validation loss: 2.4195430446214115

Epoch: 5| Step: 3
Training loss: 1.7120774882552499
Validation loss: 2.441717088957008

Epoch: 5| Step: 4
Training loss: 1.5486427763860002
Validation loss: 2.4346730235857303

Epoch: 5| Step: 5
Training loss: 1.3023165328689306
Validation loss: 2.441804262331716

Epoch: 5| Step: 6
Training loss: 1.6041387167473233
Validation loss: 2.4245062436713365

Epoch: 5| Step: 7
Training loss: 1.7961902142837411
Validation loss: 2.413417960696485

Epoch: 5| Step: 8
Training loss: 1.4991474112772019
Validation loss: 2.4623889024158316

Epoch: 5| Step: 9
Training loss: 2.382697931255682
Validation loss: 2.490913756106695

Epoch: 5| Step: 10
Training loss: 1.5282785818234443
Validation loss: 2.4811354241450596

Epoch: 482| Step: 0
Training loss: 1.4346614676248965
Validation loss: 2.472133256453599

Epoch: 5| Step: 1
Training loss: 2.1111282409285317
Validation loss: 2.462511225690876

Epoch: 5| Step: 2
Training loss: 1.9660426097998447
Validation loss: 2.46084670397254

Epoch: 5| Step: 3
Training loss: 1.703194643049116
Validation loss: 2.476156302681337

Epoch: 5| Step: 4
Training loss: 1.2648106533571835
Validation loss: 2.4890359120599777

Epoch: 5| Step: 5
Training loss: 2.100705904618487
Validation loss: 2.410196782338358

Epoch: 5| Step: 6
Training loss: 1.6486534953415852
Validation loss: 2.4910480513565645

Epoch: 5| Step: 7
Training loss: 1.5157528066330737
Validation loss: 2.462709436983498

Epoch: 5| Step: 8
Training loss: 1.4761208978932394
Validation loss: 2.47566809923525

Epoch: 5| Step: 9
Training loss: 1.4823265798946872
Validation loss: 2.5135526432420368

Epoch: 5| Step: 10
Training loss: 1.5445992269110755
Validation loss: 2.4640599045447944

Epoch: 483| Step: 0
Training loss: 1.5259383582168031
Validation loss: 2.4769145497580287

Epoch: 5| Step: 1
Training loss: 1.2739488943919457
Validation loss: 2.5079839049374315

Epoch: 5| Step: 2
Training loss: 1.3945741192722536
Validation loss: 2.502227293509414

Epoch: 5| Step: 3
Training loss: 1.693663185963429
Validation loss: 2.4689705717577404

Epoch: 5| Step: 4
Training loss: 1.3596281495551885
Validation loss: 2.5207982302806204

Epoch: 5| Step: 5
Training loss: 1.5461286034879373
Validation loss: 2.495631845103052

Epoch: 5| Step: 6
Training loss: 1.5741931544038128
Validation loss: 2.4784065912442785

Epoch: 5| Step: 7
Training loss: 1.9594190577370738
Validation loss: 2.494847994107338

Epoch: 5| Step: 8
Training loss: 1.7084101993046443
Validation loss: 2.4759600603949505

Epoch: 5| Step: 9
Training loss: 2.3367334751186823
Validation loss: 2.440735365441656

Epoch: 5| Step: 10
Training loss: 1.7793017658455352
Validation loss: 2.4730250586007205

Epoch: 484| Step: 0
Training loss: 1.4370534452031063
Validation loss: 2.4324162669061766

Epoch: 5| Step: 1
Training loss: 1.9289108134169768
Validation loss: 2.4838095483456315

Epoch: 5| Step: 2
Training loss: 1.5967535999234221
Validation loss: 2.4311716625688207

Epoch: 5| Step: 3
Training loss: 1.9635506047079982
Validation loss: 2.4605341671785723

Epoch: 5| Step: 4
Training loss: 1.9859662621889156
Validation loss: 2.4439864893389234

Epoch: 5| Step: 5
Training loss: 1.6523021936263658
Validation loss: 2.4642067992377985

Epoch: 5| Step: 6
Training loss: 1.718316526370853
Validation loss: 2.4470269666300797

Epoch: 5| Step: 7
Training loss: 1.5712741924599363
Validation loss: 2.5178864635664486

Epoch: 5| Step: 8
Training loss: 1.9090309494890798
Validation loss: 2.4794403442840336

Epoch: 5| Step: 9
Training loss: 1.4847440561977512
Validation loss: 2.521770569174772

Epoch: 5| Step: 10
Training loss: 1.1428898312798443
Validation loss: 2.442219964781843

Epoch: 485| Step: 0
Training loss: 1.629227348166658
Validation loss: 2.4540801003779866

Epoch: 5| Step: 1
Training loss: 1.2066063981961337
Validation loss: 2.430842189812409

Epoch: 5| Step: 2
Training loss: 1.5463164120522848
Validation loss: 2.4849685235492647

Epoch: 5| Step: 3
Training loss: 1.3503028865402253
Validation loss: 2.479965514189051

Epoch: 5| Step: 4
Training loss: 1.5075554505077386
Validation loss: 2.4835844251858807

Epoch: 5| Step: 5
Training loss: 1.3521962085899233
Validation loss: 2.4845702794403413

Epoch: 5| Step: 6
Training loss: 1.5023127845750877
Validation loss: 2.5220849921333226

Epoch: 5| Step: 7
Training loss: 1.7787063908542418
Validation loss: 2.547084924262809

Epoch: 5| Step: 8
Training loss: 2.0323692172720342
Validation loss: 2.488571899292504

Epoch: 5| Step: 9
Training loss: 1.81158759730973
Validation loss: 2.5124644850460145

Epoch: 5| Step: 10
Training loss: 1.9585136844564985
Validation loss: 2.5295864965496246

Epoch: 486| Step: 0
Training loss: 1.5902291845294576
Validation loss: 2.448819942158831

Epoch: 5| Step: 1
Training loss: 1.9871438001137014
Validation loss: 2.4826533870865055

Epoch: 5| Step: 2
Training loss: 1.7153695588604123
Validation loss: 2.489667938815864

Epoch: 5| Step: 3
Training loss: 1.4080286433763474
Validation loss: 2.4689897571642105

Epoch: 5| Step: 4
Training loss: 1.4119054032320228
Validation loss: 2.471291559489337

Epoch: 5| Step: 5
Training loss: 1.6397413508051455
Validation loss: 2.456781532288841

Epoch: 5| Step: 6
Training loss: 1.326039550651706
Validation loss: 2.4701334647957416

Epoch: 5| Step: 7
Training loss: 1.8927544825597429
Validation loss: 2.4160603627966517

Epoch: 5| Step: 8
Training loss: 1.9555748185680486
Validation loss: 2.4902916400654003

Epoch: 5| Step: 9
Training loss: 1.5123931405647135
Validation loss: 2.4820101769258938

Epoch: 5| Step: 10
Training loss: 1.5019347905303655
Validation loss: 2.5156361304431614

Epoch: 487| Step: 0
Training loss: 2.135741852601997
Validation loss: 2.476064540656552

Epoch: 5| Step: 1
Training loss: 1.4326070357407015
Validation loss: 2.4229807414472995

Epoch: 5| Step: 2
Training loss: 1.7039768993172948
Validation loss: 2.5043407093532384

Epoch: 5| Step: 3
Training loss: 1.2383590336867076
Validation loss: 2.4712851319442044

Epoch: 5| Step: 4
Training loss: 1.488576624437348
Validation loss: 2.4509087395542535

Epoch: 5| Step: 5
Training loss: 1.4161498117993125
Validation loss: 2.5124440479940957

Epoch: 5| Step: 6
Training loss: 2.330556841114747
Validation loss: 2.462145157033625

Epoch: 5| Step: 7
Training loss: 1.7097589622962126
Validation loss: 2.469428526704412

Epoch: 5| Step: 8
Training loss: 1.705616310016417
Validation loss: 2.4818277537881226

Epoch: 5| Step: 9
Training loss: 1.7586297742017052
Validation loss: 2.4313798843943553

Epoch: 5| Step: 10
Training loss: 1.4871673019586238
Validation loss: 2.51252150057276

Epoch: 488| Step: 0
Training loss: 1.8457506607635237
Validation loss: 2.4402523745428506

Epoch: 5| Step: 1
Training loss: 1.702175190507989
Validation loss: 2.5341006560652133

Epoch: 5| Step: 2
Training loss: 2.364561430931883
Validation loss: 2.4800326030359865

Epoch: 5| Step: 3
Training loss: 1.1344750667604535
Validation loss: 2.441752265676514

Epoch: 5| Step: 4
Training loss: 1.4723881242152417
Validation loss: 2.4767833505269103

Epoch: 5| Step: 5
Training loss: 1.1236320762161078
Validation loss: 2.448196820993157

Epoch: 5| Step: 6
Training loss: 1.5288047729561405
Validation loss: 2.5524875631301893

Epoch: 5| Step: 7
Training loss: 1.7148060718472482
Validation loss: 2.4638654904526356

Epoch: 5| Step: 8
Training loss: 1.700730486608573
Validation loss: 2.4954495095844176

Epoch: 5| Step: 9
Training loss: 1.581837357307171
Validation loss: 2.45712970539187

Epoch: 5| Step: 10
Training loss: 1.9979252782907215
Validation loss: 2.4545509338248697

Epoch: 489| Step: 0
Training loss: 1.7898363330542526
Validation loss: 2.5055969365316053

Epoch: 5| Step: 1
Training loss: 1.3268085013502782
Validation loss: 2.4654848067190573

Epoch: 5| Step: 2
Training loss: 2.054765474993816
Validation loss: 2.4266607596297223

Epoch: 5| Step: 3
Training loss: 1.6171156272949767
Validation loss: 2.4223719705881552

Epoch: 5| Step: 4
Training loss: 1.786314073378475
Validation loss: 2.4418001351868788

Epoch: 5| Step: 5
Training loss: 1.2697970068143607
Validation loss: 2.5231929767125996

Epoch: 5| Step: 6
Training loss: 2.202019921589472
Validation loss: 2.4780725339887693

Epoch: 5| Step: 7
Training loss: 1.8525606193354047
Validation loss: 2.4338464229985783

Epoch: 5| Step: 8
Training loss: 1.2708682018978812
Validation loss: 2.480096068034939

Epoch: 5| Step: 9
Training loss: 1.3165653483525017
Validation loss: 2.501711159290013

Epoch: 5| Step: 10
Training loss: 1.6132305589891045
Validation loss: 2.448095643869307

Epoch: 490| Step: 0
Training loss: 1.5329593537547832
Validation loss: 2.498738645426538

Epoch: 5| Step: 1
Training loss: 1.566625108911688
Validation loss: 2.4094105837449122

Epoch: 5| Step: 2
Training loss: 1.9382245954592665
Validation loss: 2.4367248758332156

Epoch: 5| Step: 3
Training loss: 1.4999346718867388
Validation loss: 2.4450207828205737

Epoch: 5| Step: 4
Training loss: 2.0977701337364354
Validation loss: 2.547266969427047

Epoch: 5| Step: 5
Training loss: 1.7953178624802624
Validation loss: 2.4120465348864526

Epoch: 5| Step: 6
Training loss: 1.599761545770624
Validation loss: 2.485686780553035

Epoch: 5| Step: 7
Training loss: 1.5835534578531867
Validation loss: 2.462920249301565

Epoch: 5| Step: 8
Training loss: 1.2866964647486
Validation loss: 2.48331441418525

Epoch: 5| Step: 9
Training loss: 1.3710219752987236
Validation loss: 2.459905665576709

Epoch: 5| Step: 10
Training loss: 1.4297057604014447
Validation loss: 2.4498267589040377

Epoch: 491| Step: 0
Training loss: 1.3695784234791712
Validation loss: 2.4968359295389466

Epoch: 5| Step: 1
Training loss: 1.9634770822064243
Validation loss: 2.45983558592071

Epoch: 5| Step: 2
Training loss: 1.730347226527967
Validation loss: 2.476685873612521

Epoch: 5| Step: 3
Training loss: 1.60557938169043
Validation loss: 2.4985168836389113

Epoch: 5| Step: 4
Training loss: 1.3725572475452532
Validation loss: 2.489933364308634

Epoch: 5| Step: 5
Training loss: 1.633372087732505
Validation loss: 2.481628821591769

Epoch: 5| Step: 6
Training loss: 1.8711496237294694
Validation loss: 2.519692416933584

Epoch: 5| Step: 7
Training loss: 1.5254883093822016
Validation loss: 2.4739455525316925

Epoch: 5| Step: 8
Training loss: 1.3602356214333016
Validation loss: 2.4480605446854287

Epoch: 5| Step: 9
Training loss: 1.9290284177981862
Validation loss: 2.4887447179579203

Epoch: 5| Step: 10
Training loss: 1.5377875919724062
Validation loss: 2.4863976239597734

Epoch: 492| Step: 0
Training loss: 1.6333955152832806
Validation loss: 2.5192067451088564

Epoch: 5| Step: 1
Training loss: 1.7561284114791749
Validation loss: 2.474502927016773

Epoch: 5| Step: 2
Training loss: 1.6757694412918
Validation loss: 2.483448320352775

Epoch: 5| Step: 3
Training loss: 1.5558278870993807
Validation loss: 2.496349838641033

Epoch: 5| Step: 4
Training loss: 1.6288276488736024
Validation loss: 2.4586528720225935

Epoch: 5| Step: 5
Training loss: 1.5067186884774726
Validation loss: 2.492866182222104

Epoch: 5| Step: 6
Training loss: 1.7967679862622523
Validation loss: 2.4388287763665195

Epoch: 5| Step: 7
Training loss: 1.880999123203493
Validation loss: 2.508441572055145

Epoch: 5| Step: 8
Training loss: 1.44899811826048
Validation loss: 2.518343472221917

Epoch: 5| Step: 9
Training loss: 1.7319967786966017
Validation loss: 2.4886986156805255

Epoch: 5| Step: 10
Training loss: 1.808643711133296
Validation loss: 2.4571239909698526

Epoch: 493| Step: 0
Training loss: 1.1840899846704536
Validation loss: 2.4514357937194435

Epoch: 5| Step: 1
Training loss: 1.3377604400335745
Validation loss: 2.5179604194150547

Epoch: 5| Step: 2
Training loss: 1.4115362204520114
Validation loss: 2.514647052277469

Epoch: 5| Step: 3
Training loss: 1.639794929871745
Validation loss: 2.4665666257958057

Epoch: 5| Step: 4
Training loss: 1.8834694630309687
Validation loss: 2.5347189509116466

Epoch: 5| Step: 5
Training loss: 2.0806407185559777
Validation loss: 2.47178923682876

Epoch: 5| Step: 6
Training loss: 1.7230920910658905
Validation loss: 2.4923242786095985

Epoch: 5| Step: 7
Training loss: 2.2190515017831194
Validation loss: 2.507002672564115

Epoch: 5| Step: 8
Training loss: 1.4505430684420064
Validation loss: 2.5336436615371563

Epoch: 5| Step: 9
Training loss: 1.4097011180398342
Validation loss: 2.468423072245153

Epoch: 5| Step: 10
Training loss: 1.4520147861116683
Validation loss: 2.4621667060776606

Epoch: 494| Step: 0
Training loss: 0.9420338671482295
Validation loss: 2.4381462914748497

Epoch: 5| Step: 1
Training loss: 1.4372563362930775
Validation loss: 2.5119178496709447

Epoch: 5| Step: 2
Training loss: 1.535697007002848
Validation loss: 2.4624279867656718

Epoch: 5| Step: 3
Training loss: 1.7145108049641289
Validation loss: 2.421138660752787

Epoch: 5| Step: 4
Training loss: 1.7556381680302686
Validation loss: 2.485476139846041

Epoch: 5| Step: 5
Training loss: 1.7266291955001982
Validation loss: 2.4502670280271763

Epoch: 5| Step: 6
Training loss: 2.258974403334273
Validation loss: 2.4754728455785076

Epoch: 5| Step: 7
Training loss: 1.6126394403773723
Validation loss: 2.411323475730688

Epoch: 5| Step: 8
Training loss: 1.5754470009226158
Validation loss: 2.4449247852060902

Epoch: 5| Step: 9
Training loss: 1.997392564063814
Validation loss: 2.5731137293932087

Epoch: 5| Step: 10
Training loss: 1.3113352284766038
Validation loss: 2.480432336378645

Epoch: 495| Step: 0
Training loss: 1.7086298460389677
Validation loss: 2.4256049980177234

Epoch: 5| Step: 1
Training loss: 1.231300484643731
Validation loss: 2.4498837671757703

Epoch: 5| Step: 2
Training loss: 1.5185167706530331
Validation loss: 2.495150178605665

Epoch: 5| Step: 3
Training loss: 1.45092179824973
Validation loss: 2.4650783668652125

Epoch: 5| Step: 4
Training loss: 1.2932091803458787
Validation loss: 2.5192211354873977

Epoch: 5| Step: 5
Training loss: 2.1510969867627914
Validation loss: 2.49562537752155

Epoch: 5| Step: 6
Training loss: 1.9114908186172914
Validation loss: 2.4956348354293025

Epoch: 5| Step: 7
Training loss: 1.4436935017417774
Validation loss: 2.499809439379806

Epoch: 5| Step: 8
Training loss: 1.4754852725114518
Validation loss: 2.494690433283995

Epoch: 5| Step: 9
Training loss: 1.7444202160553217
Validation loss: 2.43750089293559

Epoch: 5| Step: 10
Training loss: 1.7483594561656557
Validation loss: 2.4643717445298625

Epoch: 496| Step: 0
Training loss: 1.8026822000973244
Validation loss: 2.4317309248857724

Epoch: 5| Step: 1
Training loss: 1.6311287845869065
Validation loss: 2.4760365762154835

Epoch: 5| Step: 2
Training loss: 1.2831484058621883
Validation loss: 2.4409000420267626

Epoch: 5| Step: 3
Training loss: 1.591864948338322
Validation loss: 2.4518510990704616

Epoch: 5| Step: 4
Training loss: 1.5217801199599268
Validation loss: 2.4275142469001048

Epoch: 5| Step: 5
Training loss: 1.5337205536121192
Validation loss: 2.4724090747597955

Epoch: 5| Step: 6
Training loss: 2.1072379130058563
Validation loss: 2.503864113344012

Epoch: 5| Step: 7
Training loss: 1.7746251368594133
Validation loss: 2.51321014978277

Epoch: 5| Step: 8
Training loss: 1.3248326501787364
Validation loss: 2.4666175381203237

Epoch: 5| Step: 9
Training loss: 1.424225007512695
Validation loss: 2.4785943374166464

Epoch: 5| Step: 10
Training loss: 1.3360283803980606
Validation loss: 2.449560733546746

Epoch: 497| Step: 0
Training loss: 1.477184830564924
Validation loss: 2.458248780056384

Epoch: 5| Step: 1
Training loss: 1.9384039954143915
Validation loss: 2.512398354066958

Epoch: 5| Step: 2
Training loss: 1.5617969457105292
Validation loss: 2.552241017181291

Epoch: 5| Step: 3
Training loss: 1.223111686341695
Validation loss: 2.4811891279220992

Epoch: 5| Step: 4
Training loss: 1.6047008747854634
Validation loss: 2.4508210019348557

Epoch: 5| Step: 5
Training loss: 1.2228003468775983
Validation loss: 2.452344329309865

Epoch: 5| Step: 6
Training loss: 1.960553074576302
Validation loss: 2.4545251369705765

Epoch: 5| Step: 7
Training loss: 1.7294224316289772
Validation loss: 2.463729115193248

Epoch: 5| Step: 8
Training loss: 1.9552782320248254
Validation loss: 2.483860931900924

Epoch: 5| Step: 9
Training loss: 1.0521057743411146
Validation loss: 2.4535406923216683

Epoch: 5| Step: 10
Training loss: 1.769885703453699
Validation loss: 2.4868039164393174

Epoch: 498| Step: 0
Training loss: 1.5884732424481933
Validation loss: 2.4290619837540532

Epoch: 5| Step: 1
Training loss: 1.6552140216797668
Validation loss: 2.4797557785096056

Epoch: 5| Step: 2
Training loss: 1.7137884486008235
Validation loss: 2.487416853957719

Epoch: 5| Step: 3
Training loss: 2.1271571262074636
Validation loss: 2.5401731696189622

Epoch: 5| Step: 4
Training loss: 1.4541388635609849
Validation loss: 2.489564673563692

Epoch: 5| Step: 5
Training loss: 1.4229914714908838
Validation loss: 2.5061477094848548

Epoch: 5| Step: 6
Training loss: 1.5762447827197619
Validation loss: 2.5052196751523006

Epoch: 5| Step: 7
Training loss: 1.7206605869192209
Validation loss: 2.5003140703444315

Epoch: 5| Step: 8
Training loss: 1.8914624715939685
Validation loss: 2.4674058242667813

Epoch: 5| Step: 9
Training loss: 1.7388494698698267
Validation loss: 2.483098985122706

Epoch: 5| Step: 10
Training loss: 1.657544116300468
Validation loss: 2.5069301850890704

Epoch: 499| Step: 0
Training loss: 1.9714069905294416
Validation loss: 2.5089814271099304

Epoch: 5| Step: 1
Training loss: 1.7204976993003303
Validation loss: 2.4799652433490413

Epoch: 5| Step: 2
Training loss: 1.6479142791434964
Validation loss: 2.4825653772829295

Epoch: 5| Step: 3
Training loss: 1.3588052191300843
Validation loss: 2.4873480626893536

Epoch: 5| Step: 4
Training loss: 1.3532327023254598
Validation loss: 2.5131696528298035

Epoch: 5| Step: 5
Training loss: 1.3100751093087504
Validation loss: 2.536184836185457

Epoch: 5| Step: 6
Training loss: 1.1426035299492676
Validation loss: 2.504081571605069

Epoch: 5| Step: 7
Training loss: 1.2908778499432552
Validation loss: 2.5347245419811406

Epoch: 5| Step: 8
Training loss: 1.8494646767045344
Validation loss: 2.508831479706277

Epoch: 5| Step: 9
Training loss: 2.41172583615739
Validation loss: 2.5254777534932633

Epoch: 5| Step: 10
Training loss: 1.4943057698256172
Validation loss: 2.525557430341053

Epoch: 500| Step: 0
Training loss: 1.6084638071586221
Validation loss: 2.5144940351598652

Epoch: 5| Step: 1
Training loss: 1.5981870483001575
Validation loss: 2.498518625896612

Epoch: 5| Step: 2
Training loss: 1.4830365219763628
Validation loss: 2.483855347097485

Epoch: 5| Step: 3
Training loss: 1.6946004611593335
Validation loss: 2.4518295816984823

Epoch: 5| Step: 4
Training loss: 1.3824499484723227
Validation loss: 2.4624572946757675

Epoch: 5| Step: 5
Training loss: 1.2755418953559174
Validation loss: 2.473569907161032

Epoch: 5| Step: 6
Training loss: 1.877082177210151
Validation loss: 2.4450981923991293

Epoch: 5| Step: 7
Training loss: 1.866235083119897
Validation loss: 2.429471112368172

Epoch: 5| Step: 8
Training loss: 1.3612590318000115
Validation loss: 2.482033256719923

Epoch: 5| Step: 9
Training loss: 1.258659930297705
Validation loss: 2.3962730845902582

Epoch: 5| Step: 10
Training loss: 2.169512444848393
Validation loss: 2.4476568820344635

Epoch: 501| Step: 0
Training loss: 1.2282854358818684
Validation loss: 2.4843697228288266

Epoch: 5| Step: 1
Training loss: 1.5790207841603299
Validation loss: 2.494966787040378

Epoch: 5| Step: 2
Training loss: 1.8372782255489155
Validation loss: 2.4886325371789533

Epoch: 5| Step: 3
Training loss: 1.6885521752110695
Validation loss: 2.3958402140457484

Epoch: 5| Step: 4
Training loss: 1.7628960915127203
Validation loss: 2.519333456176705

Epoch: 5| Step: 5
Training loss: 1.9907069071113286
Validation loss: 2.4734555228404096

Epoch: 5| Step: 6
Training loss: 1.5721046507510905
Validation loss: 2.542341240284255

Epoch: 5| Step: 7
Training loss: 1.4143969735643969
Validation loss: 2.417911638138089

Epoch: 5| Step: 8
Training loss: 1.3850946506287056
Validation loss: 2.4857131946016504

Epoch: 5| Step: 9
Training loss: 1.8340647784433595
Validation loss: 2.5067291858941028

Epoch: 5| Step: 10
Training loss: 1.5831088693356465
Validation loss: 2.493398323831962

Epoch: 502| Step: 0
Training loss: 2.391432582108324
Validation loss: 2.4730647543986404

Epoch: 5| Step: 1
Training loss: 1.9987237553784993
Validation loss: 2.492845326369535

Epoch: 5| Step: 2
Training loss: 1.1468773969162676
Validation loss: 2.474006389330367

Epoch: 5| Step: 3
Training loss: 0.8117319291396952
Validation loss: 2.507216700094327

Epoch: 5| Step: 4
Training loss: 1.6181855738423827
Validation loss: 2.446017162773283

Epoch: 5| Step: 5
Training loss: 1.788842799927079
Validation loss: 2.518424338784

Epoch: 5| Step: 6
Training loss: 1.3940549833244302
Validation loss: 2.4996971613495163

Epoch: 5| Step: 7
Training loss: 1.3908486775732167
Validation loss: 2.4688478644898524

Epoch: 5| Step: 8
Training loss: 1.6306334927309591
Validation loss: 2.515572908830677

Epoch: 5| Step: 9
Training loss: 1.5176803181335412
Validation loss: 2.4794453093520716

Epoch: 5| Step: 10
Training loss: 1.5774276250084796
Validation loss: 2.4836581508989966

Epoch: 503| Step: 0
Training loss: 1.414709543806789
Validation loss: 2.520104485870388

Epoch: 5| Step: 1
Training loss: 1.7180789677964021
Validation loss: 2.5145980296910335

Epoch: 5| Step: 2
Training loss: 1.4670706542981353
Validation loss: 2.450913839825239

Epoch: 5| Step: 3
Training loss: 2.2709059630745263
Validation loss: 2.5474133280240827

Epoch: 5| Step: 4
Training loss: 1.6842848914678392
Validation loss: 2.455456622286863

Epoch: 5| Step: 5
Training loss: 1.2947372834295061
Validation loss: 2.473750237530271

Epoch: 5| Step: 6
Training loss: 1.5602679522569083
Validation loss: 2.500058372390347

Epoch: 5| Step: 7
Training loss: 1.3174316759145899
Validation loss: 2.496356550814306

Epoch: 5| Step: 8
Training loss: 2.0571820451205474
Validation loss: 2.44093222884784

Epoch: 5| Step: 9
Training loss: 1.1365685117875646
Validation loss: 2.4144114490257365

Epoch: 5| Step: 10
Training loss: 1.6411182933527673
Validation loss: 2.4797392687404702

Epoch: 504| Step: 0
Training loss: 1.770733490167474
Validation loss: 2.4515467757536924

Epoch: 5| Step: 1
Training loss: 1.4978507857321302
Validation loss: 2.479687248731543

Epoch: 5| Step: 2
Training loss: 1.0049036911703688
Validation loss: 2.415361288073019

Epoch: 5| Step: 3
Training loss: 1.5736275218180114
Validation loss: 2.4249463715970103

Epoch: 5| Step: 4
Training loss: 1.5920186830219878
Validation loss: 2.469266521500801

Epoch: 5| Step: 5
Training loss: 1.63363291010721
Validation loss: 2.4259173871393256

Epoch: 5| Step: 6
Training loss: 1.524175298981635
Validation loss: 2.4982350046145996

Epoch: 5| Step: 7
Training loss: 1.9289075997441738
Validation loss: 2.487777743759438

Epoch: 5| Step: 8
Training loss: 1.8767759177940162
Validation loss: 2.491517927404419

Epoch: 5| Step: 9
Training loss: 1.3081116656604803
Validation loss: 2.4689634336519943

Epoch: 5| Step: 10
Training loss: 1.696757882644691
Validation loss: 2.5069019247854105

Epoch: 505| Step: 0
Training loss: 1.4503661186763657
Validation loss: 2.50015388240774

Epoch: 5| Step: 1
Training loss: 1.4437829249207106
Validation loss: 2.5008465379619076

Epoch: 5| Step: 2
Training loss: 1.3899717189464054
Validation loss: 2.445105226652533

Epoch: 5| Step: 3
Training loss: 1.6468977403608915
Validation loss: 2.4707820406480847

Epoch: 5| Step: 4
Training loss: 1.5524097415161369
Validation loss: 2.530209086123655

Epoch: 5| Step: 5
Training loss: 2.0883495087033945
Validation loss: 2.4726104605080863

Epoch: 5| Step: 6
Training loss: 1.7121968968706738
Validation loss: 2.489511496469028

Epoch: 5| Step: 7
Training loss: 1.5131364035225916
Validation loss: 2.460075099958242

Epoch: 5| Step: 8
Training loss: 1.113396300678607
Validation loss: 2.461602713089579

Epoch: 5| Step: 9
Training loss: 1.7851913749194146
Validation loss: 2.4766151487582753

Epoch: 5| Step: 10
Training loss: 2.0103225158887827
Validation loss: 2.525872243602355

Epoch: 506| Step: 0
Training loss: 1.6454650692241586
Validation loss: 2.459091460340012

Epoch: 5| Step: 1
Training loss: 1.4353150057215365
Validation loss: 2.4404684606818954

Epoch: 5| Step: 2
Training loss: 1.6611876391782459
Validation loss: 2.456913221552074

Epoch: 5| Step: 3
Training loss: 1.634376835138228
Validation loss: 2.521413651046557

Epoch: 5| Step: 4
Training loss: 1.6542692756377269
Validation loss: 2.536743090130562

Epoch: 5| Step: 5
Training loss: 1.632957488563112
Validation loss: 2.4577318873702074

Epoch: 5| Step: 6
Training loss: 2.0214732883904922
Validation loss: 2.501538025066693

Epoch: 5| Step: 7
Training loss: 1.9703596891459199
Validation loss: 2.4720606020763385

Epoch: 5| Step: 8
Training loss: 1.162468760080916
Validation loss: 2.5055663713187

Epoch: 5| Step: 9
Training loss: 1.4766686618323586
Validation loss: 2.458170882485887

Epoch: 5| Step: 10
Training loss: 1.2819367870838236
Validation loss: 2.4161561957925906

Epoch: 507| Step: 0
Training loss: 1.7526310488342984
Validation loss: 2.503673630265012

Epoch: 5| Step: 1
Training loss: 1.4876528236679047
Validation loss: 2.50942042128872

Epoch: 5| Step: 2
Training loss: 1.879163379483051
Validation loss: 2.496796922783495

Epoch: 5| Step: 3
Training loss: 1.1445635898434712
Validation loss: 2.5298258417201263

Epoch: 5| Step: 4
Training loss: 1.4764970230036356
Validation loss: 2.500995329664465

Epoch: 5| Step: 5
Training loss: 1.5056598694446415
Validation loss: 2.5611071519096886

Epoch: 5| Step: 6
Training loss: 1.3584862796510395
Validation loss: 2.5096910364332166

Epoch: 5| Step: 7
Training loss: 1.8055998902705763
Validation loss: 2.486362097287789

Epoch: 5| Step: 8
Training loss: 1.6744135897675905
Validation loss: 2.438713970423076

Epoch: 5| Step: 9
Training loss: 1.5373060398728329
Validation loss: 2.4240415834326803

Epoch: 5| Step: 10
Training loss: 1.9806172994245468
Validation loss: 2.4275228422911383

Epoch: 508| Step: 0
Training loss: 1.674213164832429
Validation loss: 2.5350033586788916

Epoch: 5| Step: 1
Training loss: 1.4752092568622197
Validation loss: 2.41999964355816

Epoch: 5| Step: 2
Training loss: 1.9776211643836428
Validation loss: 2.4476599110718196

Epoch: 5| Step: 3
Training loss: 1.2938799917179875
Validation loss: 2.435707394418553

Epoch: 5| Step: 4
Training loss: 1.7181647951714931
Validation loss: 2.4579475152912025

Epoch: 5| Step: 5
Training loss: 2.031568414233251
Validation loss: 2.449288225949165

Epoch: 5| Step: 6
Training loss: 1.6357020313401216
Validation loss: 2.4421948176238724

Epoch: 5| Step: 7
Training loss: 1.4588335360133173
Validation loss: 2.471762651166508

Epoch: 5| Step: 8
Training loss: 1.2206122036452127
Validation loss: 2.460734336945357

Epoch: 5| Step: 9
Training loss: 1.5144362359412606
Validation loss: 2.4650997945905093

Epoch: 5| Step: 10
Training loss: 1.3695380359226936
Validation loss: 2.522728165042026

Epoch: 509| Step: 0
Training loss: 2.129314082567257
Validation loss: 2.439043193376871

Epoch: 5| Step: 1
Training loss: 1.169065235076617
Validation loss: 2.489911413094975

Epoch: 5| Step: 2
Training loss: 1.8696155801668264
Validation loss: 2.4666475902934972

Epoch: 5| Step: 3
Training loss: 1.3914902813236565
Validation loss: 2.4681568089903783

Epoch: 5| Step: 4
Training loss: 1.949442512343592
Validation loss: 2.4819153115023758

Epoch: 5| Step: 5
Training loss: 2.07296732420501
Validation loss: 2.4870389696114654

Epoch: 5| Step: 6
Training loss: 1.1889286482234358
Validation loss: 2.4840463524248153

Epoch: 5| Step: 7
Training loss: 1.4985762833178053
Validation loss: 2.465059110456958

Epoch: 5| Step: 8
Training loss: 1.6536963587774183
Validation loss: 2.463172882046236

Epoch: 5| Step: 9
Training loss: 1.358536648112419
Validation loss: 2.485538809866787

Epoch: 5| Step: 10
Training loss: 1.3306676871573588
Validation loss: 2.4303756650422015

Epoch: 510| Step: 0
Training loss: 1.8384244915704464
Validation loss: 2.45944110556205

Epoch: 5| Step: 1
Training loss: 0.9921491119888316
Validation loss: 2.463852046175278

Epoch: 5| Step: 2
Training loss: 1.617205412392307
Validation loss: 2.413122698071276

Epoch: 5| Step: 3
Training loss: 1.2610013829797697
Validation loss: 2.492593201506986

Epoch: 5| Step: 4
Training loss: 1.5893739948277026
Validation loss: 2.475361578507544

Epoch: 5| Step: 5
Training loss: 1.8110811007079928
Validation loss: 2.524195980322595

Epoch: 5| Step: 6
Training loss: 1.5556075857558698
Validation loss: 2.3935729093740776

Epoch: 5| Step: 7
Training loss: 1.7836958172166921
Validation loss: 2.462384877445289

Epoch: 5| Step: 8
Training loss: 1.617002688550159
Validation loss: 2.476376169206503

Epoch: 5| Step: 9
Training loss: 1.39897763354219
Validation loss: 2.3829949949068228

Epoch: 5| Step: 10
Training loss: 1.5209492242979237
Validation loss: 2.478145048315415

Epoch: 511| Step: 0
Training loss: 2.0044826102564612
Validation loss: 2.5154288619345664

Epoch: 5| Step: 1
Training loss: 1.3871748912811444
Validation loss: 2.495053800446343

Epoch: 5| Step: 2
Training loss: 1.3861402567566412
Validation loss: 2.4910162198102253

Epoch: 5| Step: 3
Training loss: 1.5433003902146352
Validation loss: 2.5172809115543475

Epoch: 5| Step: 4
Training loss: 1.3289624883468474
Validation loss: 2.4636251950580736

Epoch: 5| Step: 5
Training loss: 0.9888632647507927
Validation loss: 2.5255741993925858

Epoch: 5| Step: 6
Training loss: 1.9573648438741056
Validation loss: 2.527974780681478

Epoch: 5| Step: 7
Training loss: 2.232424758548827
Validation loss: 2.5099870333442658

Epoch: 5| Step: 8
Training loss: 1.39633741339091
Validation loss: 2.5009179173426546

Epoch: 5| Step: 9
Training loss: 1.5384047598631765
Validation loss: 2.4757622441331297

Epoch: 5| Step: 10
Training loss: 1.6364206119935363
Validation loss: 2.4163675915243528

Epoch: 512| Step: 0
Training loss: 1.676222451913149
Validation loss: 2.4815606622428668

Epoch: 5| Step: 1
Training loss: 2.0027712457520654
Validation loss: 2.5056245935687578

Epoch: 5| Step: 2
Training loss: 1.343466307390447
Validation loss: 2.3948546098948196

Epoch: 5| Step: 3
Training loss: 1.9025940152772987
Validation loss: 2.4107528881145073

Epoch: 5| Step: 4
Training loss: 1.3640819919587432
Validation loss: 2.449193799262914

Epoch: 5| Step: 5
Training loss: 1.5837386348710996
Validation loss: 2.4605667670999782

Epoch: 5| Step: 6
Training loss: 1.4913805632180146
Validation loss: 2.4868084977448293

Epoch: 5| Step: 7
Training loss: 1.5531693143298415
Validation loss: 2.43184197864694

Epoch: 5| Step: 8
Training loss: 1.3692288662803271
Validation loss: 2.438176595738314

Epoch: 5| Step: 9
Training loss: 1.343901869597413
Validation loss: 2.4399360692255874

Epoch: 5| Step: 10
Training loss: 1.7940523617140207
Validation loss: 2.508725600891986

Epoch: 513| Step: 0
Training loss: 1.6685800615855315
Validation loss: 2.4358633695431844

Epoch: 5| Step: 1
Training loss: 1.5337978108733539
Validation loss: 2.4795846456616872

Epoch: 5| Step: 2
Training loss: 1.4379251929337746
Validation loss: 2.479524559880408

Epoch: 5| Step: 3
Training loss: 1.3060332342011403
Validation loss: 2.4698266033534426

Epoch: 5| Step: 4
Training loss: 1.4068945784966822
Validation loss: 2.4584246584233935

Epoch: 5| Step: 5
Training loss: 1.7284768655170615
Validation loss: 2.4444837888256044

Epoch: 5| Step: 6
Training loss: 1.6837774119025508
Validation loss: 2.4916750087496187

Epoch: 5| Step: 7
Training loss: 1.5189511483820883
Validation loss: 2.5136388368292932

Epoch: 5| Step: 8
Training loss: 1.5038255546025068
Validation loss: 2.4847490603451137

Epoch: 5| Step: 9
Training loss: 1.9955109643178532
Validation loss: 2.484295404745322

Epoch: 5| Step: 10
Training loss: 1.5818614727332627
Validation loss: 2.5167989669846396

Epoch: 514| Step: 0
Training loss: 1.4681847478889418
Validation loss: 2.5193850910578948

Epoch: 5| Step: 1
Training loss: 1.6142999051624123
Validation loss: 2.4704747819001667

Epoch: 5| Step: 2
Training loss: 2.14652547198203
Validation loss: 2.485133539180717

Epoch: 5| Step: 3
Training loss: 1.5114223771273532
Validation loss: 2.490226513896247

Epoch: 5| Step: 4
Training loss: 1.658076592639962
Validation loss: 2.4860504036270092

Epoch: 5| Step: 5
Training loss: 1.1690096092547084
Validation loss: 2.4045525647106083

Epoch: 5| Step: 6
Training loss: 1.607706186173578
Validation loss: 2.4679481218604526

Epoch: 5| Step: 7
Training loss: 1.5045345430677821
Validation loss: 2.4832562407855963

Epoch: 5| Step: 8
Training loss: 1.5134035327919044
Validation loss: 2.471515956021653

Epoch: 5| Step: 9
Training loss: 1.6382561430237426
Validation loss: 2.422437861119809

Epoch: 5| Step: 10
Training loss: 1.4629293316964986
Validation loss: 2.4412681076508784

Epoch: 515| Step: 0
Training loss: 1.6552654434956304
Validation loss: 2.4625908587867054

Epoch: 5| Step: 1
Training loss: 1.7968976226709394
Validation loss: 2.47409189344067

Epoch: 5| Step: 2
Training loss: 1.237601301112166
Validation loss: 2.455498554454899

Epoch: 5| Step: 3
Training loss: 1.5588124057296675
Validation loss: 2.486210938285319

Epoch: 5| Step: 4
Training loss: 1.6176443145851072
Validation loss: 2.420308384761774

Epoch: 5| Step: 5
Training loss: 1.421869969621081
Validation loss: 2.4199394735199453

Epoch: 5| Step: 6
Training loss: 2.0958436206036812
Validation loss: 2.431662850266637

Epoch: 5| Step: 7
Training loss: 1.2213050761927653
Validation loss: 2.4311311772851347

Epoch: 5| Step: 8
Training loss: 1.5088975392082575
Validation loss: 2.4586980534204157

Epoch: 5| Step: 9
Training loss: 1.2121383619269275
Validation loss: 2.419183652659775

Epoch: 5| Step: 10
Training loss: 1.5811420720475757
Validation loss: 2.4782884454987713

Epoch: 516| Step: 0
Training loss: 1.2238674319445004
Validation loss: 2.451840453855514

Epoch: 5| Step: 1
Training loss: 1.6978475014420689
Validation loss: 2.438432772159675

Epoch: 5| Step: 2
Training loss: 2.0948296794986456
Validation loss: 2.503824727172352

Epoch: 5| Step: 3
Training loss: 1.552510332942368
Validation loss: 2.5052614047586226

Epoch: 5| Step: 4
Training loss: 1.3420311336004305
Validation loss: 2.411113224137619

Epoch: 5| Step: 5
Training loss: 1.8112850063145036
Validation loss: 2.4314643823339397

Epoch: 5| Step: 6
Training loss: 1.7591700758088564
Validation loss: 2.5000576607402216

Epoch: 5| Step: 7
Training loss: 1.8287030471750503
Validation loss: 2.4416697186465623

Epoch: 5| Step: 8
Training loss: 1.1589404070478853
Validation loss: 2.499075063219246

Epoch: 5| Step: 9
Training loss: 1.4030148061459111
Validation loss: 2.449284939346587

Epoch: 5| Step: 10
Training loss: 1.3802581298290209
Validation loss: 2.4022957964523997

Epoch: 517| Step: 0
Training loss: 1.8227399104572506
Validation loss: 2.50757054147627

Epoch: 5| Step: 1
Training loss: 1.5685796333602662
Validation loss: 2.42659523203649

Epoch: 5| Step: 2
Training loss: 1.7040213229900358
Validation loss: 2.464492499542585

Epoch: 5| Step: 3
Training loss: 1.363185846439055
Validation loss: 2.488993825705964

Epoch: 5| Step: 4
Training loss: 1.4542160040383847
Validation loss: 2.4878428402594026

Epoch: 5| Step: 5
Training loss: 1.676682734377692
Validation loss: 2.4391831191992064

Epoch: 5| Step: 6
Training loss: 2.0897125488167334
Validation loss: 2.481585935284182

Epoch: 5| Step: 7
Training loss: 1.0890267977889663
Validation loss: 2.4747586756317608

Epoch: 5| Step: 8
Training loss: 1.686114059974959
Validation loss: 2.501344654491188

Epoch: 5| Step: 9
Training loss: 1.622432000097442
Validation loss: 2.5060230989044614

Epoch: 5| Step: 10
Training loss: 1.463252390807581
Validation loss: 2.4696323432256517

Epoch: 518| Step: 0
Training loss: 1.3174071991899383
Validation loss: 2.475999811642465

Epoch: 5| Step: 1
Training loss: 1.4130251119370532
Validation loss: 2.4998898389602577

Epoch: 5| Step: 2
Training loss: 1.3459185467995975
Validation loss: 2.5177571860467443

Epoch: 5| Step: 3
Training loss: 1.5423478434495512
Validation loss: 2.4642235399931494

Epoch: 5| Step: 4
Training loss: 1.4131855642845255
Validation loss: 2.548728185610213

Epoch: 5| Step: 5
Training loss: 2.2151018695354474
Validation loss: 2.510960677537334

Epoch: 5| Step: 6
Training loss: 1.2414388259829143
Validation loss: 2.517187046421116

Epoch: 5| Step: 7
Training loss: 1.9098038611638775
Validation loss: 2.510519615257695

Epoch: 5| Step: 8
Training loss: 1.593978491466919
Validation loss: 2.5008267255991434

Epoch: 5| Step: 9
Training loss: 1.5646478005582822
Validation loss: 2.6094347543096728

Epoch: 5| Step: 10
Training loss: 2.1053266318063373
Validation loss: 2.384774729220084

Epoch: 519| Step: 0
Training loss: 1.3524103757598471
Validation loss: 2.4775703511594687

Epoch: 5| Step: 1
Training loss: 1.354286227694662
Validation loss: 2.42045233386433

Epoch: 5| Step: 2
Training loss: 1.7218586638795517
Validation loss: 2.509587812088032

Epoch: 5| Step: 3
Training loss: 1.1876881600936022
Validation loss: 2.424470307060909

Epoch: 5| Step: 4
Training loss: 1.4853234724188888
Validation loss: 2.4745708953735073

Epoch: 5| Step: 5
Training loss: 2.3086179160775138
Validation loss: 2.4279341477684895

Epoch: 5| Step: 6
Training loss: 1.3862886003463772
Validation loss: 2.4602185510588934

Epoch: 5| Step: 7
Training loss: 1.8641515334834822
Validation loss: 2.474251784497497

Epoch: 5| Step: 8
Training loss: 1.802079467181283
Validation loss: 2.440500699940262

Epoch: 5| Step: 9
Training loss: 1.367701232302909
Validation loss: 2.5189608727755513

Epoch: 5| Step: 10
Training loss: 1.6110043472051425
Validation loss: 2.4160361243555557

Epoch: 520| Step: 0
Training loss: 1.4936332688948324
Validation loss: 2.4960016774152063

Epoch: 5| Step: 1
Training loss: 1.2877039368229413
Validation loss: 2.498822072127562

Epoch: 5| Step: 2
Training loss: 2.091481018439896
Validation loss: 2.5384524366126353

Epoch: 5| Step: 3
Training loss: 2.051572810406427
Validation loss: 2.5190492311850745

Epoch: 5| Step: 4
Training loss: 1.166367929676144
Validation loss: 2.5464704559539086

Epoch: 5| Step: 5
Training loss: 1.7744536996381235
Validation loss: 2.5467262357991687

Epoch: 5| Step: 6
Training loss: 1.6458776041507002
Validation loss: 2.5332846931419866

Epoch: 5| Step: 7
Training loss: 1.0797302900080032
Validation loss: 2.463829737731821

Epoch: 5| Step: 8
Training loss: 0.9742619998144912
Validation loss: 2.5669175014921595

Epoch: 5| Step: 9
Training loss: 1.7809510231073602
Validation loss: 2.392184791068563

Epoch: 5| Step: 10
Training loss: 1.4783128324690618
Validation loss: 2.4297594219971836

Epoch: 521| Step: 0
Training loss: 1.523053634405485
Validation loss: 2.4879450265091814

Epoch: 5| Step: 1
Training loss: 1.7424856709092258
Validation loss: 2.4525745945616713

Epoch: 5| Step: 2
Training loss: 1.9958908664743809
Validation loss: 2.4850702224320154

Epoch: 5| Step: 3
Training loss: 1.2940591783626019
Validation loss: 2.4229244524047564

Epoch: 5| Step: 4
Training loss: 1.2585859112581295
Validation loss: 2.4596504592224897

Epoch: 5| Step: 5
Training loss: 1.356789992106276
Validation loss: 2.4825768996525275

Epoch: 5| Step: 6
Training loss: 1.285994143530531
Validation loss: 2.4799664135430683

Epoch: 5| Step: 7
Training loss: 1.841807230882869
Validation loss: 2.463275017653427

Epoch: 5| Step: 8
Training loss: 1.8206623052356004
Validation loss: 2.410845699419025

Epoch: 5| Step: 9
Training loss: 1.1130582351838485
Validation loss: 2.4389559255202866

Epoch: 5| Step: 10
Training loss: 1.6661092143810998
Validation loss: 2.461671489607237

Epoch: 522| Step: 0
Training loss: 1.8231228593742455
Validation loss: 2.4418439795760536

Epoch: 5| Step: 1
Training loss: 1.412430469523294
Validation loss: 2.4280527819308353

Epoch: 5| Step: 2
Training loss: 1.4906366887623965
Validation loss: 2.487718855469116

Epoch: 5| Step: 3
Training loss: 2.082551758707993
Validation loss: 2.483102240391092

Epoch: 5| Step: 4
Training loss: 1.3466813693959312
Validation loss: 2.4616074246131214

Epoch: 5| Step: 5
Training loss: 1.797827559377722
Validation loss: 2.482380771984888

Epoch: 5| Step: 6
Training loss: 1.0206884488942332
Validation loss: 2.4653404557943857

Epoch: 5| Step: 7
Training loss: 1.464807535359633
Validation loss: 2.4484361720867978

Epoch: 5| Step: 8
Training loss: 1.4528055968010853
Validation loss: 2.5014312410663098

Epoch: 5| Step: 9
Training loss: 1.574356716726767
Validation loss: 2.463729653159072

Epoch: 5| Step: 10
Training loss: 1.4662288373507746
Validation loss: 2.4624231248108646

Epoch: 523| Step: 0
Training loss: 1.695736950596491
Validation loss: 2.496477414084776

Epoch: 5| Step: 1
Training loss: 1.5613576146123629
Validation loss: 2.4741189794189897

Epoch: 5| Step: 2
Training loss: 1.8683742438858615
Validation loss: 2.4557168056575507

Epoch: 5| Step: 3
Training loss: 1.7389897306423114
Validation loss: 2.4591032933822117

Epoch: 5| Step: 4
Training loss: 1.410414104186998
Validation loss: 2.452174904403507

Epoch: 5| Step: 5
Training loss: 1.8775134723855533
Validation loss: 2.429599113163738

Epoch: 5| Step: 6
Training loss: 1.4028890500561968
Validation loss: 2.432087763864185

Epoch: 5| Step: 7
Training loss: 1.6539511651529544
Validation loss: 2.501640551659916

Epoch: 5| Step: 8
Training loss: 1.4175104919260595
Validation loss: 2.456660917936596

Epoch: 5| Step: 9
Training loss: 1.698626325089838
Validation loss: 2.463390670825189

Epoch: 5| Step: 10
Training loss: 1.368595248666956
Validation loss: 2.456017206286398

Epoch: 524| Step: 0
Training loss: 1.9291986626209334
Validation loss: 2.523336469646396

Epoch: 5| Step: 1
Training loss: 1.648170630380655
Validation loss: 2.468400082258544

Epoch: 5| Step: 2
Training loss: 1.4282671434043657
Validation loss: 2.4708924950802893

Epoch: 5| Step: 3
Training loss: 1.2746397556679008
Validation loss: 2.4673341060820895

Epoch: 5| Step: 4
Training loss: 1.43794185647683
Validation loss: 2.4941972145107223

Epoch: 5| Step: 5
Training loss: 2.0722773602842786
Validation loss: 2.447717190803206

Epoch: 5| Step: 6
Training loss: 1.6966748367192803
Validation loss: 2.533350955899682

Epoch: 5| Step: 7
Training loss: 1.1386165965355721
Validation loss: 2.4637637008499396

Epoch: 5| Step: 8
Training loss: 1.2515934324787739
Validation loss: 2.465049939794446

Epoch: 5| Step: 9
Training loss: 1.4631862367169366
Validation loss: 2.4570350583687652

Epoch: 5| Step: 10
Training loss: 1.5243268669258754
Validation loss: 2.473993319321782

Epoch: 525| Step: 0
Training loss: 1.900036111287727
Validation loss: 2.495292187083957

Epoch: 5| Step: 1
Training loss: 1.5216335473246343
Validation loss: 2.4774223137575833

Epoch: 5| Step: 2
Training loss: 1.515823036705531
Validation loss: 2.4832095730682977

Epoch: 5| Step: 3
Training loss: 1.1011245614530651
Validation loss: 2.4899459604289373

Epoch: 5| Step: 4
Training loss: 1.4186574561231196
Validation loss: 2.427657118223011

Epoch: 5| Step: 5
Training loss: 1.9631346289961167
Validation loss: 2.486159747147095

Epoch: 5| Step: 6
Training loss: 1.292686131871003
Validation loss: 2.425649730167378

Epoch: 5| Step: 7
Training loss: 1.466619854237792
Validation loss: 2.4572310593141644

Epoch: 5| Step: 8
Training loss: 1.316339372243494
Validation loss: 2.4863946204620184

Epoch: 5| Step: 9
Training loss: 1.699753389983816
Validation loss: 2.4458391239154804

Epoch: 5| Step: 10
Training loss: 1.9299159976486921
Validation loss: 2.5220303904797396

Epoch: 526| Step: 0
Training loss: 1.304720164364098
Validation loss: 2.5208335462214326

Epoch: 5| Step: 1
Training loss: 1.8339242488604788
Validation loss: 2.5006969177825757

Epoch: 5| Step: 2
Training loss: 2.0451344085396737
Validation loss: 2.4102651069195478

Epoch: 5| Step: 3
Training loss: 1.842864260232051
Validation loss: 2.459666154843389

Epoch: 5| Step: 4
Training loss: 1.0970341015490574
Validation loss: 2.4637229582336615

Epoch: 5| Step: 5
Training loss: 1.4716788774777962
Validation loss: 2.4171553984959298

Epoch: 5| Step: 6
Training loss: 1.152810729499299
Validation loss: 2.452396842549268

Epoch: 5| Step: 7
Training loss: 1.102170303076454
Validation loss: 2.518924822224154

Epoch: 5| Step: 8
Training loss: 1.4536428861771544
Validation loss: 2.4877877910579898

Epoch: 5| Step: 9
Training loss: 1.6841865788030905
Validation loss: 2.449825994989631

Epoch: 5| Step: 10
Training loss: 1.8476228287559362
Validation loss: 2.4538666974424013

Epoch: 527| Step: 0
Training loss: 1.404016713512959
Validation loss: 2.515748880218005

Epoch: 5| Step: 1
Training loss: 1.4870652565249771
Validation loss: 2.512843231721244

Epoch: 5| Step: 2
Training loss: 1.1947861054658826
Validation loss: 2.5130310830292935

Epoch: 5| Step: 3
Training loss: 1.4681249871381854
Validation loss: 2.477764943926531

Epoch: 5| Step: 4
Training loss: 1.793865702549374
Validation loss: 2.466875244269643

Epoch: 5| Step: 5
Training loss: 1.3162261205754995
Validation loss: 2.484252780150568

Epoch: 5| Step: 6
Training loss: 1.6430400693236535
Validation loss: 2.466076222431234

Epoch: 5| Step: 7
Training loss: 1.8732410445620993
Validation loss: 2.5206181780054537

Epoch: 5| Step: 8
Training loss: 1.7570759226071553
Validation loss: 2.5084817385867093

Epoch: 5| Step: 9
Training loss: 1.6278306076205604
Validation loss: 2.5327951790951952

Epoch: 5| Step: 10
Training loss: 1.5536771011744188
Validation loss: 2.5012751198700816

Epoch: 528| Step: 0
Training loss: 1.7774886858187033
Validation loss: 2.4859895191976364

Epoch: 5| Step: 1
Training loss: 1.565096566874184
Validation loss: 2.4719670452723936

Epoch: 5| Step: 2
Training loss: 2.172609273710618
Validation loss: 2.448682043736321

Epoch: 5| Step: 3
Training loss: 1.6993269962603184
Validation loss: 2.4048897838428274

Epoch: 5| Step: 4
Training loss: 1.4409156522664368
Validation loss: 2.487781775049639

Epoch: 5| Step: 5
Training loss: 1.4410274183535778
Validation loss: 2.4816588954905376

Epoch: 5| Step: 6
Training loss: 1.5733099271089286
Validation loss: 2.528156748798357

Epoch: 5| Step: 7
Training loss: 1.40346743476794
Validation loss: 2.5046309884040787

Epoch: 5| Step: 8
Training loss: 1.571465671398608
Validation loss: 2.4943273914133934

Epoch: 5| Step: 9
Training loss: 1.0931261190645347
Validation loss: 2.445725235095657

Epoch: 5| Step: 10
Training loss: 1.162316927286918
Validation loss: 2.4329812429234856

Epoch: 529| Step: 0
Training loss: 1.210964768625686
Validation loss: 2.5097180242259114

Epoch: 5| Step: 1
Training loss: 1.5659089095612213
Validation loss: 2.5215466492758507

Epoch: 5| Step: 2
Training loss: 1.5151965922094772
Validation loss: 2.4942874460992956

Epoch: 5| Step: 3
Training loss: 1.6086046171261297
Validation loss: 2.4861017604601696

Epoch: 5| Step: 4
Training loss: 1.533648966700305
Validation loss: 2.5731359631392725

Epoch: 5| Step: 5
Training loss: 1.5835453276342428
Validation loss: 2.476843254914309

Epoch: 5| Step: 6
Training loss: 1.3499367699120652
Validation loss: 2.4877187987905907

Epoch: 5| Step: 7
Training loss: 1.5920195815736733
Validation loss: 2.4405142802084114

Epoch: 5| Step: 8
Training loss: 2.0371300905661114
Validation loss: 2.4906938626067916

Epoch: 5| Step: 9
Training loss: 1.4956060266945173
Validation loss: 2.488668398679302

Epoch: 5| Step: 10
Training loss: 1.7803174304810185
Validation loss: 2.5204222067686683

Epoch: 530| Step: 0
Training loss: 1.665083522706444
Validation loss: 2.4285097348961706

Epoch: 5| Step: 1
Training loss: 1.5427938241429011
Validation loss: 2.4606336513803333

Epoch: 5| Step: 2
Training loss: 1.8886318577311103
Validation loss: 2.481972792265335

Epoch: 5| Step: 3
Training loss: 1.6410353374500397
Validation loss: 2.46468685689533

Epoch: 5| Step: 4
Training loss: 1.3775766678813608
Validation loss: 2.5048198844365963

Epoch: 5| Step: 5
Training loss: 1.7743982073968305
Validation loss: 2.468432635418302

Epoch: 5| Step: 6
Training loss: 1.4619803556956787
Validation loss: 2.3634018397652774

Epoch: 5| Step: 7
Training loss: 1.292613554048488
Validation loss: 2.4292524101397683

Epoch: 5| Step: 8
Training loss: 1.4681944100644944
Validation loss: 2.4802945505497096

Epoch: 5| Step: 9
Training loss: 1.4381229875095416
Validation loss: 2.4181467046088456

Epoch: 5| Step: 10
Training loss: 1.5039515104542864
Validation loss: 2.4682706178198197

Epoch: 531| Step: 0
Training loss: 1.8681634882015257
Validation loss: 2.4408763642874822

Epoch: 5| Step: 1
Training loss: 1.2499335271326897
Validation loss: 2.468455919014346

Epoch: 5| Step: 2
Training loss: 1.3170956580745838
Validation loss: 2.4081031206292742

Epoch: 5| Step: 3
Training loss: 1.5179519880137973
Validation loss: 2.4299931893927815

Epoch: 5| Step: 4
Training loss: 1.3888998582194865
Validation loss: 2.4811156982335065

Epoch: 5| Step: 5
Training loss: 1.511916509896611
Validation loss: 2.559218924014542

Epoch: 5| Step: 6
Training loss: 1.4358983446496492
Validation loss: 2.4986549645679985

Epoch: 5| Step: 7
Training loss: 1.8241741820288475
Validation loss: 2.519023660282868

Epoch: 5| Step: 8
Training loss: 1.5155361188802514
Validation loss: 2.5250056725333416

Epoch: 5| Step: 9
Training loss: 1.3718240211417003
Validation loss: 2.518483012980649

Epoch: 5| Step: 10
Training loss: 2.1454906992518454
Validation loss: 2.5246659137350775

Epoch: 532| Step: 0
Training loss: 1.4674246469416767
Validation loss: 2.4726630451530416

Epoch: 5| Step: 1
Training loss: 1.676566840145754
Validation loss: 2.417851468623003

Epoch: 5| Step: 2
Training loss: 1.0247553137897158
Validation loss: 2.422775195465894

Epoch: 5| Step: 3
Training loss: 1.379597693141691
Validation loss: 2.465666492610604

Epoch: 5| Step: 4
Training loss: 2.029214044079193
Validation loss: 2.459865500005276

Epoch: 5| Step: 5
Training loss: 1.3525594220884165
Validation loss: 2.5116921878951977

Epoch: 5| Step: 6
Training loss: 1.4406354130101737
Validation loss: 2.432743952095497

Epoch: 5| Step: 7
Training loss: 1.9628097897106858
Validation loss: 2.5050422907296013

Epoch: 5| Step: 8
Training loss: 1.0938492866138194
Validation loss: 2.486450114987693

Epoch: 5| Step: 9
Training loss: 1.5837673880594305
Validation loss: 2.4618214894839197

Epoch: 5| Step: 10
Training loss: 1.5022931848706216
Validation loss: 2.4829343804697976

Epoch: 533| Step: 0
Training loss: 1.5874111300846885
Validation loss: 2.4271475610777733

Epoch: 5| Step: 1
Training loss: 1.771878267046357
Validation loss: 2.494130416220813

Epoch: 5| Step: 2
Training loss: 1.6369939677384238
Validation loss: 2.4607597634569296

Epoch: 5| Step: 3
Training loss: 1.3949248455681493
Validation loss: 2.444170996289197

Epoch: 5| Step: 4
Training loss: 1.600403082261172
Validation loss: 2.475438502224413

Epoch: 5| Step: 5
Training loss: 1.6998619528426195
Validation loss: 2.4183513994542047

Epoch: 5| Step: 6
Training loss: 1.7193953256296584
Validation loss: 2.4335689140141104

Epoch: 5| Step: 7
Training loss: 1.2599019767839583
Validation loss: 2.452206007563688

Epoch: 5| Step: 8
Training loss: 1.7377829533990687
Validation loss: 2.3953221011517396

Epoch: 5| Step: 9
Training loss: 1.0850041172283476
Validation loss: 2.477605109894817

Epoch: 5| Step: 10
Training loss: 1.558351196689864
Validation loss: 2.489883974320567

Epoch: 534| Step: 0
Training loss: 1.6472738778240252
Validation loss: 2.4974338230441795

Epoch: 5| Step: 1
Training loss: 1.0134150008704519
Validation loss: 2.490101243509348

Epoch: 5| Step: 2
Training loss: 1.1377229220597016
Validation loss: 2.4973313701184736

Epoch: 5| Step: 3
Training loss: 1.324106667425469
Validation loss: 2.4330697934930354

Epoch: 5| Step: 4
Training loss: 2.406755864858292
Validation loss: 2.4770466595309775

Epoch: 5| Step: 5
Training loss: 1.5177949139316669
Validation loss: 2.4946894056450026

Epoch: 5| Step: 6
Training loss: 1.5604451973534608
Validation loss: 2.4881974873915276

Epoch: 5| Step: 7
Training loss: 1.3208930189604502
Validation loss: 2.507060825668619

Epoch: 5| Step: 8
Training loss: 1.5625380702149216
Validation loss: 2.484321237133149

Epoch: 5| Step: 9
Training loss: 1.6952023096795255
Validation loss: 2.4737100666821172

Epoch: 5| Step: 10
Training loss: 1.62480830015507
Validation loss: 2.489847162468962

Epoch: 535| Step: 0
Training loss: 1.5442108948918967
Validation loss: 2.4618281791667975

Epoch: 5| Step: 1
Training loss: 1.995920192392019
Validation loss: 2.4263277433485357

Epoch: 5| Step: 2
Training loss: 1.390376808220887
Validation loss: 2.4793990155486556

Epoch: 5| Step: 3
Training loss: 1.4494715878773619
Validation loss: 2.4124255477941983

Epoch: 5| Step: 4
Training loss: 1.5625844551150077
Validation loss: 2.4510838607402112

Epoch: 5| Step: 5
Training loss: 1.4607898005113795
Validation loss: 2.5393308506868166

Epoch: 5| Step: 6
Training loss: 1.392495172927133
Validation loss: 2.420177000761659

Epoch: 5| Step: 7
Training loss: 1.7115427975776893
Validation loss: 2.4421204663470304

Epoch: 5| Step: 8
Training loss: 1.465565007980812
Validation loss: 2.466472311796728

Epoch: 5| Step: 9
Training loss: 1.772175074873303
Validation loss: 2.415879647232649

Epoch: 5| Step: 10
Training loss: 1.430302305345665
Validation loss: 2.443532475720527

Epoch: 536| Step: 0
Training loss: 1.6541243534137318
Validation loss: 2.5065885459038966

Epoch: 5| Step: 1
Training loss: 1.31093890584477
Validation loss: 2.4738409599781024

Epoch: 5| Step: 2
Training loss: 1.7182285558216328
Validation loss: 2.517276278773028

Epoch: 5| Step: 3
Training loss: 1.2072810436151145
Validation loss: 2.5054521861337604

Epoch: 5| Step: 4
Training loss: 1.836240637893649
Validation loss: 2.453294241209994

Epoch: 5| Step: 5
Training loss: 1.330922355986667
Validation loss: 2.4664219193011796

Epoch: 5| Step: 6
Training loss: 1.64517003789358
Validation loss: 2.4317301879682716

Epoch: 5| Step: 7
Training loss: 1.7909939264378743
Validation loss: 2.483820908058912

Epoch: 5| Step: 8
Training loss: 1.5080858684447591
Validation loss: 2.478622878583367

Epoch: 5| Step: 9
Training loss: 1.3248751653488866
Validation loss: 2.526130430291954

Epoch: 5| Step: 10
Training loss: 1.5054136178057673
Validation loss: 2.484364899686823

Epoch: 537| Step: 0
Training loss: 1.5655687333463795
Validation loss: 2.467371106795499

Epoch: 5| Step: 1
Training loss: 1.4641765244741383
Validation loss: 2.469432352808363

Epoch: 5| Step: 2
Training loss: 1.4006826184127148
Validation loss: 2.4908676589816485

Epoch: 5| Step: 3
Training loss: 1.830556637994076
Validation loss: 2.4668997714376903

Epoch: 5| Step: 4
Training loss: 1.4938845745421745
Validation loss: 2.5278293756556223

Epoch: 5| Step: 5
Training loss: 1.3986924008398176
Validation loss: 2.4903025079873324

Epoch: 5| Step: 6
Training loss: 1.9015752661847751
Validation loss: 2.4933927840387584

Epoch: 5| Step: 7
Training loss: 1.5925942512539712
Validation loss: 2.5066938614673733

Epoch: 5| Step: 8
Training loss: 1.4046643112016821
Validation loss: 2.5166802852389543

Epoch: 5| Step: 9
Training loss: 1.398035002170658
Validation loss: 2.4926257925103323

Epoch: 5| Step: 10
Training loss: 1.3899410580412381
Validation loss: 2.409468164168712

Epoch: 538| Step: 0
Training loss: 1.4774101286792285
Validation loss: 2.484760908937526

Epoch: 5| Step: 1
Training loss: 1.8893138658309836
Validation loss: 2.4568960313456674

Epoch: 5| Step: 2
Training loss: 1.090454859975126
Validation loss: 2.497185136577303

Epoch: 5| Step: 3
Training loss: 1.309057899261207
Validation loss: 2.4383528353083688

Epoch: 5| Step: 4
Training loss: 1.502362695218438
Validation loss: 2.4979482486312325

Epoch: 5| Step: 5
Training loss: 1.59371918293199
Validation loss: 2.4253395263210904

Epoch: 5| Step: 6
Training loss: 2.2158749717806656
Validation loss: 2.475357322964226

Epoch: 5| Step: 7
Training loss: 1.2781278204478737
Validation loss: 2.4503431806446465

Epoch: 5| Step: 8
Training loss: 1.5966367569964417
Validation loss: 2.421494031694516

Epoch: 5| Step: 9
Training loss: 1.3428960792714362
Validation loss: 2.438754212090882

Epoch: 5| Step: 10
Training loss: 1.4183080178021332
Validation loss: 2.4102744817740205

Epoch: 539| Step: 0
Training loss: 1.473176656795676
Validation loss: 2.447501501634523

Epoch: 5| Step: 1
Training loss: 1.2228528434479844
Validation loss: 2.442062736207262

Epoch: 5| Step: 2
Training loss: 1.149731899191155
Validation loss: 2.4726776908527213

Epoch: 5| Step: 3
Training loss: 1.9050604438704313
Validation loss: 2.460868572748442

Epoch: 5| Step: 4
Training loss: 1.2183521795228518
Validation loss: 2.4386044101924162

Epoch: 5| Step: 5
Training loss: 1.1662216132369654
Validation loss: 2.4767094139568493

Epoch: 5| Step: 6
Training loss: 1.7781582150432593
Validation loss: 2.514750561088561

Epoch: 5| Step: 7
Training loss: 2.069574188443644
Validation loss: 2.494233414843008

Epoch: 5| Step: 8
Training loss: 1.7157494449472843
Validation loss: 2.536878988363724

Epoch: 5| Step: 9
Training loss: 1.2282551063169014
Validation loss: 2.4978167516962237

Epoch: 5| Step: 10
Training loss: 1.5556991582768285
Validation loss: 2.47991521807178

Epoch: 540| Step: 0
Training loss: 1.7468839559854346
Validation loss: 2.4782853928645276

Epoch: 5| Step: 1
Training loss: 1.4988224652789692
Validation loss: 2.4764666205074617

Epoch: 5| Step: 2
Training loss: 1.5657906785358853
Validation loss: 2.4118723606366785

Epoch: 5| Step: 3
Training loss: 1.8937927694495469
Validation loss: 2.519639323712361

Epoch: 5| Step: 4
Training loss: 1.13142862964502
Validation loss: 2.4499007339910475

Epoch: 5| Step: 5
Training loss: 1.6827933052689676
Validation loss: 2.434939592876445

Epoch: 5| Step: 6
Training loss: 1.7969601154900425
Validation loss: 2.4206156684705347

Epoch: 5| Step: 7
Training loss: 1.4602228548504632
Validation loss: 2.479207581344211

Epoch: 5| Step: 8
Training loss: 1.449712458414395
Validation loss: 2.4750552611584618

Epoch: 5| Step: 9
Training loss: 1.7968088552491153
Validation loss: 2.47280837857568

Epoch: 5| Step: 10
Training loss: 1.2489745225193853
Validation loss: 2.4761045583830152

Epoch: 541| Step: 0
Training loss: 1.303557540498572
Validation loss: 2.4423087419622527

Epoch: 5| Step: 1
Training loss: 1.3181403988426637
Validation loss: 2.4567210860210813

Epoch: 5| Step: 2
Training loss: 1.9436649561489436
Validation loss: 2.496414698265019

Epoch: 5| Step: 3
Training loss: 1.1732859954351924
Validation loss: 2.554119882842864

Epoch: 5| Step: 4
Training loss: 1.6078670066143101
Validation loss: 2.520897987436291

Epoch: 5| Step: 5
Training loss: 1.617418503042164
Validation loss: 2.5875451119934856

Epoch: 5| Step: 6
Training loss: 1.4205632289575958
Validation loss: 2.522653901819048

Epoch: 5| Step: 7
Training loss: 2.086456005789007
Validation loss: 2.467389613697692

Epoch: 5| Step: 8
Training loss: 1.5145827967219951
Validation loss: 2.52561278301443

Epoch: 5| Step: 9
Training loss: 1.9661461701719152
Validation loss: 2.510180416299602

Epoch: 5| Step: 10
Training loss: 1.4335145850502387
Validation loss: 2.4910543918885524

Epoch: 542| Step: 0
Training loss: 1.4135027457238576
Validation loss: 2.4983048049662404

Epoch: 5| Step: 1
Training loss: 1.2543352290502519
Validation loss: 2.5103570679735214

Epoch: 5| Step: 2
Training loss: 1.333899432447853
Validation loss: 2.4144195622846394

Epoch: 5| Step: 3
Training loss: 1.7272423143766604
Validation loss: 2.4167230540802214

Epoch: 5| Step: 4
Training loss: 1.4986627498934144
Validation loss: 2.4549179960156664

Epoch: 5| Step: 5
Training loss: 1.4729099206981284
Validation loss: 2.4532860903612947

Epoch: 5| Step: 6
Training loss: 1.4419230540006105
Validation loss: 2.454616443602483

Epoch: 5| Step: 7
Training loss: 2.0065004091469154
Validation loss: 2.5476576790699004

Epoch: 5| Step: 8
Training loss: 1.2563853252648136
Validation loss: 2.4816508057798305

Epoch: 5| Step: 9
Training loss: 1.6887631104226517
Validation loss: 2.4786370913815685

Epoch: 5| Step: 10
Training loss: 1.7323697844611974
Validation loss: 2.46226398471132

Epoch: 543| Step: 0
Training loss: 1.3801391104367358
Validation loss: 2.4483650228046887

Epoch: 5| Step: 1
Training loss: 1.146197671475805
Validation loss: 2.4851455324252005

Epoch: 5| Step: 2
Training loss: 1.550055269055812
Validation loss: 2.4513087647993297

Epoch: 5| Step: 3
Training loss: 1.0336512151012476
Validation loss: 2.527729062426782

Epoch: 5| Step: 4
Training loss: 2.177402187038181
Validation loss: 2.4698270382687237

Epoch: 5| Step: 5
Training loss: 1.703964096689542
Validation loss: 2.4612621795711753

Epoch: 5| Step: 6
Training loss: 1.4530460787435147
Validation loss: 2.5331121239505285

Epoch: 5| Step: 7
Training loss: 1.843183398067027
Validation loss: 2.5127052040482973

Epoch: 5| Step: 8
Training loss: 1.3970983902669443
Validation loss: 2.5467409412808855

Epoch: 5| Step: 9
Training loss: 1.4864412081756038
Validation loss: 2.414790184173297

Epoch: 5| Step: 10
Training loss: 1.511829618582656
Validation loss: 2.417933390551976

Epoch: 544| Step: 0
Training loss: 1.6657775494139275
Validation loss: 2.464892947487323

Epoch: 5| Step: 1
Training loss: 1.7309436706113426
Validation loss: 2.459202789078482

Epoch: 5| Step: 2
Training loss: 1.530781732699108
Validation loss: 2.463756761489858

Epoch: 5| Step: 3
Training loss: 1.129173695916588
Validation loss: 2.491875340567296

Epoch: 5| Step: 4
Training loss: 1.2805496720909582
Validation loss: 2.4489114353353045

Epoch: 5| Step: 5
Training loss: 1.5653692984638226
Validation loss: 2.508293237904998

Epoch: 5| Step: 6
Training loss: 1.2804967945837784
Validation loss: 2.4027980265215745

Epoch: 5| Step: 7
Training loss: 1.1911853022583876
Validation loss: 2.456670238878916

Epoch: 5| Step: 8
Training loss: 1.5478756683109112
Validation loss: 2.456192786243345

Epoch: 5| Step: 9
Training loss: 2.011297978219523
Validation loss: 2.449703623290832

Epoch: 5| Step: 10
Training loss: 1.7223496629194208
Validation loss: 2.4553671213412582

Epoch: 545| Step: 0
Training loss: 1.9445619782241839
Validation loss: 2.4583235831368877

Epoch: 5| Step: 1
Training loss: 1.0711299809422306
Validation loss: 2.4829291188218767

Epoch: 5| Step: 2
Training loss: 1.3992669400213262
Validation loss: 2.4828994815763243

Epoch: 5| Step: 3
Training loss: 1.3748700340577384
Validation loss: 2.4079420971899412

Epoch: 5| Step: 4
Training loss: 1.6685354087668736
Validation loss: 2.4684868367646597

Epoch: 5| Step: 5
Training loss: 1.3572466620563883
Validation loss: 2.4864692263545014

Epoch: 5| Step: 6
Training loss: 1.3778594368830288
Validation loss: 2.4183977222903374

Epoch: 5| Step: 7
Training loss: 1.6859798648803919
Validation loss: 2.3950143424566392

Epoch: 5| Step: 8
Training loss: 1.5954751793901172
Validation loss: 2.4857873290064587

Epoch: 5| Step: 9
Training loss: 1.409879197566354
Validation loss: 2.4559956784420267

Epoch: 5| Step: 10
Training loss: 1.9076171725021116
Validation loss: 2.4550363725694933

Epoch: 546| Step: 0
Training loss: 1.4496975747786474
Validation loss: 2.5195110900535327

Epoch: 5| Step: 1
Training loss: 1.3490976779602486
Validation loss: 2.468560160239157

Epoch: 5| Step: 2
Training loss: 1.380955629352764
Validation loss: 2.4674398794142594

Epoch: 5| Step: 3
Training loss: 1.9267747030470064
Validation loss: 2.427414400210598

Epoch: 5| Step: 4
Training loss: 1.179448640401329
Validation loss: 2.431773088002449

Epoch: 5| Step: 5
Training loss: 1.9180596168886954
Validation loss: 2.501400680295406

Epoch: 5| Step: 6
Training loss: 1.0624252741846452
Validation loss: 2.4777452035977943

Epoch: 5| Step: 7
Training loss: 1.5249249361668933
Validation loss: 2.4576966462520518

Epoch: 5| Step: 8
Training loss: 1.5138349679021603
Validation loss: 2.5112563379809303

Epoch: 5| Step: 9
Training loss: 1.95116326040938
Validation loss: 2.47806936108291

Epoch: 5| Step: 10
Training loss: 1.3347933147037803
Validation loss: 2.4833569392654025

Epoch: 547| Step: 0
Training loss: 1.3726129619479392
Validation loss: 2.4224373113383337

Epoch: 5| Step: 1
Training loss: 1.341666891362584
Validation loss: 2.473464589267985

Epoch: 5| Step: 2
Training loss: 1.5112726701750958
Validation loss: 2.4136570452830584

Epoch: 5| Step: 3
Training loss: 1.4731391904112665
Validation loss: 2.5207196112290107

Epoch: 5| Step: 4
Training loss: 1.364758322563727
Validation loss: 2.5138871703520373

Epoch: 5| Step: 5
Training loss: 1.5958325859977758
Validation loss: 2.4936191313239413

Epoch: 5| Step: 6
Training loss: 1.5045190924881129
Validation loss: 2.4677107349758183

Epoch: 5| Step: 7
Training loss: 1.5145371455828813
Validation loss: 2.568762095105787

Epoch: 5| Step: 8
Training loss: 2.072493185623433
Validation loss: 2.48206153369393

Epoch: 5| Step: 9
Training loss: 1.1893856236138223
Validation loss: 2.4660480033427175

Epoch: 5| Step: 10
Training loss: 1.4776207093890603
Validation loss: 2.472555551190949

Epoch: 548| Step: 0
Training loss: 1.4876350341540525
Validation loss: 2.474030535453364

Epoch: 5| Step: 1
Training loss: 1.2972044928349111
Validation loss: 2.4323969584993517

Epoch: 5| Step: 2
Training loss: 1.6547281002722738
Validation loss: 2.4839500579260045

Epoch: 5| Step: 3
Training loss: 1.3743888190226563
Validation loss: 2.46093160274051

Epoch: 5| Step: 4
Training loss: 1.7462244859605085
Validation loss: 2.4515788756019785

Epoch: 5| Step: 5
Training loss: 1.5686101083579842
Validation loss: 2.4427305904866214

Epoch: 5| Step: 6
Training loss: 1.6320263005643145
Validation loss: 2.4279552835028704

Epoch: 5| Step: 7
Training loss: 1.5577393295566675
Validation loss: 2.4713091490512613

Epoch: 5| Step: 8
Training loss: 1.9645021418450326
Validation loss: 2.4732095697745087

Epoch: 5| Step: 9
Training loss: 1.2668878824325214
Validation loss: 2.464584869513132

Epoch: 5| Step: 10
Training loss: 1.2405713682329043
Validation loss: 2.4545507886471696

Epoch: 549| Step: 0
Training loss: 0.9328236615968469
Validation loss: 2.511158870521203

Epoch: 5| Step: 1
Training loss: 1.2025673304561353
Validation loss: 2.459855293843668

Epoch: 5| Step: 2
Training loss: 1.5340008063780495
Validation loss: 2.438069554949712

Epoch: 5| Step: 3
Training loss: 1.3882522914873745
Validation loss: 2.480701318647632

Epoch: 5| Step: 4
Training loss: 1.8834156637285169
Validation loss: 2.4656236728175074

Epoch: 5| Step: 5
Training loss: 1.3291201285383558
Validation loss: 2.5172203985502195

Epoch: 5| Step: 6
Training loss: 1.4709271466790605
Validation loss: 2.4490912533245695

Epoch: 5| Step: 7
Training loss: 1.43586937013208
Validation loss: 2.442695582134164

Epoch: 5| Step: 8
Training loss: 1.4396084788325818
Validation loss: 2.406564362511838

Epoch: 5| Step: 9
Training loss: 1.9837235109691576
Validation loss: 2.4857040949827653

Epoch: 5| Step: 10
Training loss: 1.9740510447394561
Validation loss: 2.50721097712949

Epoch: 550| Step: 0
Training loss: 1.544124354019345
Validation loss: 2.5434306579769315

Epoch: 5| Step: 1
Training loss: 1.1213033128054477
Validation loss: 2.4932012690689485

Epoch: 5| Step: 2
Training loss: 1.4356185376192487
Validation loss: 2.425056261332463

Epoch: 5| Step: 3
Training loss: 1.5270675058138792
Validation loss: 2.5096356737762133

Epoch: 5| Step: 4
Training loss: 1.1943263554909982
Validation loss: 2.491516952991139

Epoch: 5| Step: 5
Training loss: 1.215969042892168
Validation loss: 2.4216669443813768

Epoch: 5| Step: 6
Training loss: 1.5135211303465885
Validation loss: 2.4265520434244774

Epoch: 5| Step: 7
Training loss: 2.2099437839383436
Validation loss: 2.4384500415354986

Epoch: 5| Step: 8
Training loss: 1.738074541124215
Validation loss: 2.477978991045783

Epoch: 5| Step: 9
Training loss: 1.7007606263283637
Validation loss: 2.5106267463757472

Epoch: 5| Step: 10
Training loss: 1.124042209233184
Validation loss: 2.4909585576726427

Epoch: 551| Step: 0
Training loss: 1.3401932774832712
Validation loss: 2.44528916692572

Epoch: 5| Step: 1
Training loss: 1.4427523646423708
Validation loss: 2.509988733934809

Epoch: 5| Step: 2
Training loss: 1.4265182471540632
Validation loss: 2.4954973619795138

Epoch: 5| Step: 3
Training loss: 1.4166821404154306
Validation loss: 2.5540359557839145

Epoch: 5| Step: 4
Training loss: 1.5239502655184263
Validation loss: 2.4817846508928616

Epoch: 5| Step: 5
Training loss: 0.7697067060718906
Validation loss: 2.4903040151009233

Epoch: 5| Step: 6
Training loss: 2.0705392389473696
Validation loss: 2.46478903585739

Epoch: 5| Step: 7
Training loss: 1.7490984092844313
Validation loss: 2.4662105375397063

Epoch: 5| Step: 8
Training loss: 1.18258936602803
Validation loss: 2.510972695464168

Epoch: 5| Step: 9
Training loss: 1.7859582747939016
Validation loss: 2.453671256290442

Epoch: 5| Step: 10
Training loss: 1.6519571487835985
Validation loss: 2.488827992957103

Epoch: 552| Step: 0
Training loss: 1.474956628194101
Validation loss: 2.5019619990153155

Epoch: 5| Step: 1
Training loss: 1.5120360364303052
Validation loss: 2.4048279938131314

Epoch: 5| Step: 2
Training loss: 1.8286975061961699
Validation loss: 2.4216851590392556

Epoch: 5| Step: 3
Training loss: 1.4304205677495234
Validation loss: 2.475702299609065

Epoch: 5| Step: 4
Training loss: 1.666923248885737
Validation loss: 2.455429587284306

Epoch: 5| Step: 5
Training loss: 1.3170509910212795
Validation loss: 2.4328351351824717

Epoch: 5| Step: 6
Training loss: 1.3834181068289901
Validation loss: 2.445739198299262

Epoch: 5| Step: 7
Training loss: 2.111467129262912
Validation loss: 2.4517604715869266

Epoch: 5| Step: 8
Training loss: 0.9619972464131463
Validation loss: 2.428201969964653

Epoch: 5| Step: 9
Training loss: 1.082334400223078
Validation loss: 2.4690684295815717

Epoch: 5| Step: 10
Training loss: 1.3456980313452447
Validation loss: 2.452801693225748

Epoch: 553| Step: 0
Training loss: 1.7826797369052465
Validation loss: 2.415081672008443

Epoch: 5| Step: 1
Training loss: 1.5382629486436712
Validation loss: 2.4791249469636107

Epoch: 5| Step: 2
Training loss: 1.552814447989406
Validation loss: 2.454011045288381

Epoch: 5| Step: 3
Training loss: 1.3573276404734191
Validation loss: 2.4133697582025233

Epoch: 5| Step: 4
Training loss: 1.5559821177879438
Validation loss: 2.508035651842348

Epoch: 5| Step: 5
Training loss: 1.2268683179847308
Validation loss: 2.4701891715594733

Epoch: 5| Step: 6
Training loss: 1.3821710941687368
Validation loss: 2.4629771129828506

Epoch: 5| Step: 7
Training loss: 1.994540571406899
Validation loss: 2.476229629927687

Epoch: 5| Step: 8
Training loss: 1.321691977453781
Validation loss: 2.4858082750147243

Epoch: 5| Step: 9
Training loss: 1.5209989152762755
Validation loss: 2.4519597798776114

Epoch: 5| Step: 10
Training loss: 1.1622431830298376
Validation loss: 2.4679264259288423

Epoch: 554| Step: 0
Training loss: 1.2427106991042167
Validation loss: 2.4476785900526843

Epoch: 5| Step: 1
Training loss: 1.9876161673323014
Validation loss: 2.4282511866384895

Epoch: 5| Step: 2
Training loss: 1.4458006987979122
Validation loss: 2.5552592173890316

Epoch: 5| Step: 3
Training loss: 1.3334299390286593
Validation loss: 2.522688325950838

Epoch: 5| Step: 4
Training loss: 1.1906194371371337
Validation loss: 2.458382675012214

Epoch: 5| Step: 5
Training loss: 1.7704909797789876
Validation loss: 2.4737819689508425

Epoch: 5| Step: 6
Training loss: 1.7771501037408732
Validation loss: 2.46203419458807

Epoch: 5| Step: 7
Training loss: 1.317085339984051
Validation loss: 2.456773147787661

Epoch: 5| Step: 8
Training loss: 1.8157845038048466
Validation loss: 2.497242243792441

Epoch: 5| Step: 9
Training loss: 1.4337891489685473
Validation loss: 2.4700599103901304

Epoch: 5| Step: 10
Training loss: 1.1069982616648684
Validation loss: 2.525247646749998

Epoch: 555| Step: 0
Training loss: 1.7641431953888183
Validation loss: 2.4546170953179667

Epoch: 5| Step: 1
Training loss: 1.359595752199119
Validation loss: 2.4748133941503476

Epoch: 5| Step: 2
Training loss: 1.3563049551381863
Validation loss: 2.466068489112849

Epoch: 5| Step: 3
Training loss: 1.6693411190889367
Validation loss: 2.4472679945639126

Epoch: 5| Step: 4
Training loss: 1.4538849514933962
Validation loss: 2.482066648448409

Epoch: 5| Step: 5
Training loss: 1.4744402453712426
Validation loss: 2.4715922495000977

Epoch: 5| Step: 6
Training loss: 1.3765828818502093
Validation loss: 2.4896163337556847

Epoch: 5| Step: 7
Training loss: 1.4709183128958183
Validation loss: 2.5150480480730044

Epoch: 5| Step: 8
Training loss: 1.688504167532981
Validation loss: 2.479621951566669

Epoch: 5| Step: 9
Training loss: 1.422565837335466
Validation loss: 2.5096147948616117

Epoch: 5| Step: 10
Training loss: 1.4606469829375777
Validation loss: 2.474919154443064

Epoch: 556| Step: 0
Training loss: 1.464358236597084
Validation loss: 2.494705973189239

Epoch: 5| Step: 1
Training loss: 1.4721750945619416
Validation loss: 2.4670548305167395

Epoch: 5| Step: 2
Training loss: 1.2403793130123244
Validation loss: 2.449474234187028

Epoch: 5| Step: 3
Training loss: 2.094976151542305
Validation loss: 2.427809321017112

Epoch: 5| Step: 4
Training loss: 1.073637316012362
Validation loss: 2.406252114836125

Epoch: 5| Step: 5
Training loss: 1.3082481269465822
Validation loss: 2.453803909105161

Epoch: 5| Step: 6
Training loss: 1.4741015235534334
Validation loss: 2.4989182141602058

Epoch: 5| Step: 7
Training loss: 1.5433411740267966
Validation loss: 2.4470727356405524

Epoch: 5| Step: 8
Training loss: 1.7734042261169884
Validation loss: 2.457796517548016

Epoch: 5| Step: 9
Training loss: 1.0067436997410928
Validation loss: 2.4680371328095223

Epoch: 5| Step: 10
Training loss: 1.5786665940773363
Validation loss: 2.411641882928749

Epoch: 557| Step: 0
Training loss: 1.5162573999285658
Validation loss: 2.4891046190883404

Epoch: 5| Step: 1
Training loss: 1.6408683233112922
Validation loss: 2.5023560712117066

Epoch: 5| Step: 2
Training loss: 1.3121865216056445
Validation loss: 2.499936961332911

Epoch: 5| Step: 3
Training loss: 1.4836535658185468
Validation loss: 2.500281567253186

Epoch: 5| Step: 4
Training loss: 1.392642925193998
Validation loss: 2.49306765229187

Epoch: 5| Step: 5
Training loss: 0.9784799900533242
Validation loss: 2.419332495384546

Epoch: 5| Step: 6
Training loss: 1.584615899004721
Validation loss: 2.4751545376892015

Epoch: 5| Step: 7
Training loss: 1.8112611153987483
Validation loss: 2.4468514461282354

Epoch: 5| Step: 8
Training loss: 1.5690629836862164
Validation loss: 2.4681239686275123

Epoch: 5| Step: 9
Training loss: 1.4020655789132126
Validation loss: 2.4577138997032275

Epoch: 5| Step: 10
Training loss: 1.6068260228732272
Validation loss: 2.400901204324605

Epoch: 558| Step: 0
Training loss: 1.6421712219418754
Validation loss: 2.4639788123593425

Epoch: 5| Step: 1
Training loss: 1.3517634953452555
Validation loss: 2.4742956703301573

Epoch: 5| Step: 2
Training loss: 1.068287625597165
Validation loss: 2.5041840447353887

Epoch: 5| Step: 3
Training loss: 1.2222995420524827
Validation loss: 2.498400104456299

Epoch: 5| Step: 4
Training loss: 1.410830434325669
Validation loss: 2.4480611834852275

Epoch: 5| Step: 5
Training loss: 2.3309359382391976
Validation loss: 2.455769136125071

Epoch: 5| Step: 6
Training loss: 1.4663898904057557
Validation loss: 2.4507054967275583

Epoch: 5| Step: 7
Training loss: 1.18293053707005
Validation loss: 2.464259696369947

Epoch: 5| Step: 8
Training loss: 0.9921284455274033
Validation loss: 2.4396357974860927

Epoch: 5| Step: 9
Training loss: 1.692630597799381
Validation loss: 2.475955218800159

Epoch: 5| Step: 10
Training loss: 1.3330269054121426
Validation loss: 2.405264563285961

Epoch: 559| Step: 0
Training loss: 1.334179396218151
Validation loss: 2.4446354788195612

Epoch: 5| Step: 1
Training loss: 1.8564301579964042
Validation loss: 2.4295139256679414

Epoch: 5| Step: 2
Training loss: 0.9467958524251326
Validation loss: 2.5491933140224816

Epoch: 5| Step: 3
Training loss: 1.698398365738523
Validation loss: 2.5326530480493443

Epoch: 5| Step: 4
Training loss: 1.1082444676408079
Validation loss: 2.5405082631519855

Epoch: 5| Step: 5
Training loss: 1.735086655884995
Validation loss: 2.512273894333382

Epoch: 5| Step: 6
Training loss: 1.640324301638148
Validation loss: 2.531781177195128

Epoch: 5| Step: 7
Training loss: 1.6285503922683728
Validation loss: 2.4898514622325023

Epoch: 5| Step: 8
Training loss: 1.529348477288329
Validation loss: 2.503128549648233

Epoch: 5| Step: 9
Training loss: 1.1206395096273019
Validation loss: 2.549291988198926

Epoch: 5| Step: 10
Training loss: 2.1580529898641894
Validation loss: 2.4235796774507734

Epoch: 560| Step: 0
Training loss: 1.386125034516319
Validation loss: 2.4677060828934554

Epoch: 5| Step: 1
Training loss: 1.252016491409621
Validation loss: 2.502524249034438

Epoch: 5| Step: 2
Training loss: 1.8523888655260148
Validation loss: 2.4888294901479706

Epoch: 5| Step: 3
Training loss: 1.7024555815561329
Validation loss: 2.5138924824400735

Epoch: 5| Step: 4
Training loss: 1.4031371526043186
Validation loss: 2.459948552595207

Epoch: 5| Step: 5
Training loss: 1.6017534095676667
Validation loss: 2.4707842714498254

Epoch: 5| Step: 6
Training loss: 2.20682674574514
Validation loss: 2.450697476921377

Epoch: 5| Step: 7
Training loss: 1.1298513185534849
Validation loss: 2.4213065314827262

Epoch: 5| Step: 8
Training loss: 1.4524054437741751
Validation loss: 2.422427756021116

Epoch: 5| Step: 9
Training loss: 1.2029448039868262
Validation loss: 2.4810277010476645

Epoch: 5| Step: 10
Training loss: 1.3919352241851384
Validation loss: 2.4852285716248894

Epoch: 561| Step: 0
Training loss: 1.3020177239736659
Validation loss: 2.4281529671482707

Epoch: 5| Step: 1
Training loss: 1.273445082565855
Validation loss: 2.4882229526602724

Epoch: 5| Step: 2
Training loss: 1.3910508093258047
Validation loss: 2.4232703903196424

Epoch: 5| Step: 3
Training loss: 1.732191962949181
Validation loss: 2.5050237867076524

Epoch: 5| Step: 4
Training loss: 1.315224000613993
Validation loss: 2.487149439062147

Epoch: 5| Step: 5
Training loss: 1.423783415418151
Validation loss: 2.46445083535228

Epoch: 5| Step: 6
Training loss: 1.1738627550853162
Validation loss: 2.4667030021526632

Epoch: 5| Step: 7
Training loss: 2.249152765766995
Validation loss: 2.503579868844588

Epoch: 5| Step: 8
Training loss: 1.616383301916346
Validation loss: 2.490117249602661

Epoch: 5| Step: 9
Training loss: 1.4969825594490664
Validation loss: 2.410985056414531

Epoch: 5| Step: 10
Training loss: 1.2332158500974266
Validation loss: 2.4671146266538644

Epoch: 562| Step: 0
Training loss: 1.967488565957025
Validation loss: 2.470372603578029

Epoch: 5| Step: 1
Training loss: 1.5550363427235911
Validation loss: 2.503854979861936

Epoch: 5| Step: 2
Training loss: 1.156804802247127
Validation loss: 2.5336438699760766

Epoch: 5| Step: 3
Training loss: 1.5905902431565322
Validation loss: 2.4399968735230884

Epoch: 5| Step: 4
Training loss: 1.3980491567818503
Validation loss: 2.4658183568790153

Epoch: 5| Step: 5
Training loss: 1.5316629436864149
Validation loss: 2.48079293706437

Epoch: 5| Step: 6
Training loss: 1.0535384523990041
Validation loss: 2.4290786105246407

Epoch: 5| Step: 7
Training loss: 1.4484223596466739
Validation loss: 2.4299271455514337

Epoch: 5| Step: 8
Training loss: 1.7418660093909724
Validation loss: 2.4628853850674766

Epoch: 5| Step: 9
Training loss: 1.109797598711538
Validation loss: 2.4667263332534914

Epoch: 5| Step: 10
Training loss: 1.423473758842873
Validation loss: 2.494020788443515

Epoch: 563| Step: 0
Training loss: 1.6898424350488266
Validation loss: 2.3984122037647513

Epoch: 5| Step: 1
Training loss: 1.5537969444346007
Validation loss: 2.5016963187463053

Epoch: 5| Step: 2
Training loss: 1.408111230653371
Validation loss: 2.4222841264581425

Epoch: 5| Step: 3
Training loss: 1.364219146158722
Validation loss: 2.4616878763393037

Epoch: 5| Step: 4
Training loss: 1.359216439657049
Validation loss: 2.463988796473481

Epoch: 5| Step: 5
Training loss: 2.0496998869633165
Validation loss: 2.4821109104654258

Epoch: 5| Step: 6
Training loss: 1.6284796798885943
Validation loss: 2.473375825983232

Epoch: 5| Step: 7
Training loss: 1.285298997551659
Validation loss: 2.508131219407315

Epoch: 5| Step: 8
Training loss: 1.4149925587596617
Validation loss: 2.5762115209017393

Epoch: 5| Step: 9
Training loss: 1.3547533769440505
Validation loss: 2.545385482169731

Epoch: 5| Step: 10
Training loss: 1.1237289878230117
Validation loss: 2.5733509149795055

Epoch: 564| Step: 0
Training loss: 1.4299072763752068
Validation loss: 2.47155071381061

Epoch: 5| Step: 1
Training loss: 1.8082177448979608
Validation loss: 2.455385480146424

Epoch: 5| Step: 2
Training loss: 1.517686523336646
Validation loss: 2.4848621726849944

Epoch: 5| Step: 3
Training loss: 1.0183117467982472
Validation loss: 2.5057749124276625

Epoch: 5| Step: 4
Training loss: 1.592179291079757
Validation loss: 2.4820167347285347

Epoch: 5| Step: 5
Training loss: 1.1820548852548094
Validation loss: 2.4984150764251063

Epoch: 5| Step: 6
Training loss: 1.7120966359699612
Validation loss: 2.502151674911407

Epoch: 5| Step: 7
Training loss: 1.400008060227761
Validation loss: 2.529536248588027

Epoch: 5| Step: 8
Training loss: 1.2052394072742314
Validation loss: 2.475808392630479

Epoch: 5| Step: 9
Training loss: 1.16133058241691
Validation loss: 2.4637760416039574

Epoch: 5| Step: 10
Training loss: 2.3200393670129276
Validation loss: 2.4632323207284665

Epoch: 565| Step: 0
Training loss: 1.6206091466702766
Validation loss: 2.4453676100845905

Epoch: 5| Step: 1
Training loss: 1.5029649042535786
Validation loss: 2.4585116679595873

Epoch: 5| Step: 2
Training loss: 1.3744328803156143
Validation loss: 2.4837707839392578

Epoch: 5| Step: 3
Training loss: 1.3198866298425813
Validation loss: 2.46724989520681

Epoch: 5| Step: 4
Training loss: 1.181849941913958
Validation loss: 2.4852720820756624

Epoch: 5| Step: 5
Training loss: 1.7287778149047623
Validation loss: 2.525214512315791

Epoch: 5| Step: 6
Training loss: 1.4036370904068676
Validation loss: 2.5009489319671556

Epoch: 5| Step: 7
Training loss: 1.3929306803842878
Validation loss: 2.4771089880909236

Epoch: 5| Step: 8
Training loss: 1.1570269577492813
Validation loss: 2.480836834806597

Epoch: 5| Step: 9
Training loss: 1.7154267521394104
Validation loss: 2.4580168060567518

Epoch: 5| Step: 10
Training loss: 1.61474565079749
Validation loss: 2.4526886043359477

Epoch: 566| Step: 0
Training loss: 1.1124743297915645
Validation loss: 2.4838378567040866

Epoch: 5| Step: 1
Training loss: 1.5612888219571155
Validation loss: 2.5095830639724697

Epoch: 5| Step: 2
Training loss: 1.2621745889357054
Validation loss: 2.5128482858618195

Epoch: 5| Step: 3
Training loss: 1.507563911462315
Validation loss: 2.419472569366446

Epoch: 5| Step: 4
Training loss: 1.6397658505413022
Validation loss: 2.451371574168345

Epoch: 5| Step: 5
Training loss: 0.9984241824985696
Validation loss: 2.5379256999740964

Epoch: 5| Step: 6
Training loss: 1.2883192289270424
Validation loss: 2.4420861074571136

Epoch: 5| Step: 7
Training loss: 2.179577130767256
Validation loss: 2.4513772695801825

Epoch: 5| Step: 8
Training loss: 1.5129095705216653
Validation loss: 2.4215174532461496

Epoch: 5| Step: 9
Training loss: 1.4919975119869155
Validation loss: 2.488218368807495

Epoch: 5| Step: 10
Training loss: 1.1473658226037637
Validation loss: 2.4876949689630337

Epoch: 567| Step: 0
Training loss: 1.2624575692779916
Validation loss: 2.5179313696269827

Epoch: 5| Step: 1
Training loss: 1.5401044697439261
Validation loss: 2.455611080680336

Epoch: 5| Step: 2
Training loss: 1.489405410206418
Validation loss: 2.517309341511259

Epoch: 5| Step: 3
Training loss: 1.5158350690790143
Validation loss: 2.476778952516592

Epoch: 5| Step: 4
Training loss: 1.3602871520162763
Validation loss: 2.4753632801014254

Epoch: 5| Step: 5
Training loss: 1.661483126687519
Validation loss: 2.5014265056522103

Epoch: 5| Step: 6
Training loss: 1.38724071726303
Validation loss: 2.514416913529783

Epoch: 5| Step: 7
Training loss: 1.4167736050504078
Validation loss: 2.57723099716441

Epoch: 5| Step: 8
Training loss: 1.158417603059714
Validation loss: 2.4909071321868472

Epoch: 5| Step: 9
Training loss: 1.9199544723397854
Validation loss: 2.4778485346484946

Epoch: 5| Step: 10
Training loss: 1.6716625756048547
Validation loss: 2.4492623621517153

Epoch: 568| Step: 0
Training loss: 1.6351683199273457
Validation loss: 2.478647771483251

Epoch: 5| Step: 1
Training loss: 1.2827749713793397
Validation loss: 2.4294202900508735

Epoch: 5| Step: 2
Training loss: 1.3443588829049824
Validation loss: 2.4824568105561537

Epoch: 5| Step: 3
Training loss: 1.4389523342845716
Validation loss: 2.5359843876066552

Epoch: 5| Step: 4
Training loss: 1.5893587689577873
Validation loss: 2.4821718456206714

Epoch: 5| Step: 5
Training loss: 1.8961305140831888
Validation loss: 2.4865611539354178

Epoch: 5| Step: 6
Training loss: 1.2925530540453543
Validation loss: 2.3954936902744874

Epoch: 5| Step: 7
Training loss: 1.5846854844303362
Validation loss: 2.483459720945233

Epoch: 5| Step: 8
Training loss: 1.2551102606526523
Validation loss: 2.495373004457678

Epoch: 5| Step: 9
Training loss: 1.2261123803207112
Validation loss: 2.431652365482086

Epoch: 5| Step: 10
Training loss: 1.7994949479982136
Validation loss: 2.439684658454888

Epoch: 569| Step: 0
Training loss: 1.665320122676848
Validation loss: 2.4796379984231374

Epoch: 5| Step: 1
Training loss: 1.3737393148490904
Validation loss: 2.467722353715796

Epoch: 5| Step: 2
Training loss: 1.3043007648657927
Validation loss: 2.510499383966685

Epoch: 5| Step: 3
Training loss: 1.594640221392965
Validation loss: 2.4962644992195946

Epoch: 5| Step: 4
Training loss: 1.2417257638389734
Validation loss: 2.5376231647535743

Epoch: 5| Step: 5
Training loss: 1.5056505268699376
Validation loss: 2.514700624279052

Epoch: 5| Step: 6
Training loss: 0.9179024530373209
Validation loss: 2.5168608947525053

Epoch: 5| Step: 7
Training loss: 1.7938252981510951
Validation loss: 2.5353495079882014

Epoch: 5| Step: 8
Training loss: 1.088917218756692
Validation loss: 2.485112410050275

Epoch: 5| Step: 9
Training loss: 1.9355989789830397
Validation loss: 2.4794257705835463

Epoch: 5| Step: 10
Training loss: 1.5132724554921997
Validation loss: 2.4976318730980624

Epoch: 570| Step: 0
Training loss: 1.5504318343318244
Validation loss: 2.5180183958115823

Epoch: 5| Step: 1
Training loss: 1.545778136111888
Validation loss: 2.5273088110850175

Epoch: 5| Step: 2
Training loss: 1.8199268636575756
Validation loss: 2.4656276711860254

Epoch: 5| Step: 3
Training loss: 1.453361409963114
Validation loss: 2.476848341113092

Epoch: 5| Step: 4
Training loss: 1.1897134229853348
Validation loss: 2.4385691670388545

Epoch: 5| Step: 5
Training loss: 1.5922617227701068
Validation loss: 2.4532671604332013

Epoch: 5| Step: 6
Training loss: 1.2385203133751022
Validation loss: 2.4595151312788426

Epoch: 5| Step: 7
Training loss: 1.323394969270301
Validation loss: 2.4638805453341517

Epoch: 5| Step: 8
Training loss: 1.4354161624695327
Validation loss: 2.5187951633959336

Epoch: 5| Step: 9
Training loss: 1.2966203094782986
Validation loss: 2.468540641243017

Epoch: 5| Step: 10
Training loss: 1.3720320835421609
Validation loss: 2.484366249424553

Epoch: 571| Step: 0
Training loss: 1.2238203850241751
Validation loss: 2.4666505180612956

Epoch: 5| Step: 1
Training loss: 1.7071545030455435
Validation loss: 2.5382077175264475

Epoch: 5| Step: 2
Training loss: 1.4533427085632402
Validation loss: 2.4854249629704044

Epoch: 5| Step: 3
Training loss: 1.591422382136263
Validation loss: 2.4717232010140737

Epoch: 5| Step: 4
Training loss: 1.4283559466381728
Validation loss: 2.5128270755428157

Epoch: 5| Step: 5
Training loss: 1.214594579331607
Validation loss: 2.474397377904473

Epoch: 5| Step: 6
Training loss: 1.9785172518001395
Validation loss: 2.535288623371336

Epoch: 5| Step: 7
Training loss: 1.2842958114975123
Validation loss: 2.4832056024933316

Epoch: 5| Step: 8
Training loss: 1.4871933532843336
Validation loss: 2.413752943958951

Epoch: 5| Step: 9
Training loss: 1.505662561362188
Validation loss: 2.4859102798617236

Epoch: 5| Step: 10
Training loss: 1.5182319322651385
Validation loss: 2.4417911921408826

Epoch: 572| Step: 0
Training loss: 1.4300390759711152
Validation loss: 2.522737040670495

Epoch: 5| Step: 1
Training loss: 1.6032127252264063
Validation loss: 2.456250784419114

Epoch: 5| Step: 2
Training loss: 1.3271299786157669
Validation loss: 2.5010885668187597

Epoch: 5| Step: 3
Training loss: 1.05656791056049
Validation loss: 2.4259299204183056

Epoch: 5| Step: 4
Training loss: 1.6718429134534154
Validation loss: 2.4220709915591696

Epoch: 5| Step: 5
Training loss: 1.4437617049630362
Validation loss: 2.4488996593019086

Epoch: 5| Step: 6
Training loss: 1.2763499088766868
Validation loss: 2.4230893851242503

Epoch: 5| Step: 7
Training loss: 1.3513300701347237
Validation loss: 2.5070873775334794

Epoch: 5| Step: 8
Training loss: 1.2560500597909328
Validation loss: 2.5141456884684925

Epoch: 5| Step: 9
Training loss: 1.8921856704564468
Validation loss: 2.477839767232377

Epoch: 5| Step: 10
Training loss: 1.8694737694556234
Validation loss: 2.4368125455151435

Epoch: 573| Step: 0
Training loss: 1.2360162085393183
Validation loss: 2.476938167624364

Epoch: 5| Step: 1
Training loss: 1.4047446777112578
Validation loss: 2.4725359849353685

Epoch: 5| Step: 2
Training loss: 1.2942801103572856
Validation loss: 2.470284300495152

Epoch: 5| Step: 3
Training loss: 1.1772441191559808
Validation loss: 2.453176659460152

Epoch: 5| Step: 4
Training loss: 1.9840654747526525
Validation loss: 2.525122963465674

Epoch: 5| Step: 5
Training loss: 1.928171280316293
Validation loss: 2.477733479760847

Epoch: 5| Step: 6
Training loss: 1.6485975287260992
Validation loss: 2.4394558831063047

Epoch: 5| Step: 7
Training loss: 1.4993407867204542
Validation loss: 2.5345025019070717

Epoch: 5| Step: 8
Training loss: 1.3396322456000893
Validation loss: 2.509529805395502

Epoch: 5| Step: 9
Training loss: 1.1184373813063118
Validation loss: 2.451795675691998

Epoch: 5| Step: 10
Training loss: 1.4556491217901493
Validation loss: 2.5081083618811615

Epoch: 574| Step: 0
Training loss: 1.0110790925900794
Validation loss: 2.503622609308459

Epoch: 5| Step: 1
Training loss: 1.49698208165068
Validation loss: 2.4820345674433386

Epoch: 5| Step: 2
Training loss: 1.1645733013414774
Validation loss: 2.457843356440819

Epoch: 5| Step: 3
Training loss: 1.6173337418780291
Validation loss: 2.487423061517282

Epoch: 5| Step: 4
Training loss: 1.428195362319329
Validation loss: 2.4882871906203614

Epoch: 5| Step: 5
Training loss: 1.0595165889498035
Validation loss: 2.5151205829101624

Epoch: 5| Step: 6
Training loss: 1.9941573632683904
Validation loss: 2.502952090950222

Epoch: 5| Step: 7
Training loss: 1.139501044018055
Validation loss: 2.4219089237077376

Epoch: 5| Step: 8
Training loss: 1.6962591244389613
Validation loss: 2.414088906582012

Epoch: 5| Step: 9
Training loss: 1.6281884530675166
Validation loss: 2.504690871078655

Epoch: 5| Step: 10
Training loss: 1.4118276818980844
Validation loss: 2.4320951266752644

Epoch: 575| Step: 0
Training loss: 1.33813999942674
Validation loss: 2.483718495363017

Epoch: 5| Step: 1
Training loss: 1.7306482639588268
Validation loss: 2.405953391004326

Epoch: 5| Step: 2
Training loss: 1.1520586081272335
Validation loss: 2.518531483310139

Epoch: 5| Step: 3
Training loss: 1.4943988651681794
Validation loss: 2.461584133518922

Epoch: 5| Step: 4
Training loss: 1.4900453380113048
Validation loss: 2.4655898514864374

Epoch: 5| Step: 5
Training loss: 1.3004996879955653
Validation loss: 2.5180651392256017

Epoch: 5| Step: 6
Training loss: 1.2901811312142368
Validation loss: 2.441871147667892

Epoch: 5| Step: 7
Training loss: 1.4578274348925997
Validation loss: 2.4507091553990885

Epoch: 5| Step: 8
Training loss: 1.5778764585669425
Validation loss: 2.460805663031285

Epoch: 5| Step: 9
Training loss: 1.926677193673402
Validation loss: 2.4917828055165683

Epoch: 5| Step: 10
Training loss: 1.4564714353453447
Validation loss: 2.4128065284425935

Epoch: 576| Step: 0
Training loss: 1.3871038197755559
Validation loss: 2.506814058618228

Epoch: 5| Step: 1
Training loss: 1.4513578436946906
Validation loss: 2.5057244289323726

Epoch: 5| Step: 2
Training loss: 1.4776315200025443
Validation loss: 2.466777715148297

Epoch: 5| Step: 3
Training loss: 1.5230319534827055
Validation loss: 2.538413627008006

Epoch: 5| Step: 4
Training loss: 1.1966697616501705
Validation loss: 2.4673638586019493

Epoch: 5| Step: 5
Training loss: 2.0893358986105848
Validation loss: 2.495945953595295

Epoch: 5| Step: 6
Training loss: 1.7056068046496708
Validation loss: 2.4742328585178384

Epoch: 5| Step: 7
Training loss: 1.0695237643618725
Validation loss: 2.4669536131280663

Epoch: 5| Step: 8
Training loss: 1.2356226446489142
Validation loss: 2.479416527431986

Epoch: 5| Step: 9
Training loss: 1.524024107064043
Validation loss: 2.491577925113354

Epoch: 5| Step: 10
Training loss: 0.9735389289243312
Validation loss: 2.423051224700158

Epoch: 577| Step: 0
Training loss: 1.3681155297590712
Validation loss: 2.4293805754719116

Epoch: 5| Step: 1
Training loss: 1.4628946994373333
Validation loss: 2.48274631712895

Epoch: 5| Step: 2
Training loss: 1.3422523847002092
Validation loss: 2.45610890836372

Epoch: 5| Step: 3
Training loss: 1.4627982137137676
Validation loss: 2.457845989605907

Epoch: 5| Step: 4
Training loss: 0.9111556758649194
Validation loss: 2.4522116999920627

Epoch: 5| Step: 5
Training loss: 1.2323605481349058
Validation loss: 2.4806940690988046

Epoch: 5| Step: 6
Training loss: 1.9502231250168438
Validation loss: 2.496468699769044

Epoch: 5| Step: 7
Training loss: 1.785859685155437
Validation loss: 2.4654166694980835

Epoch: 5| Step: 8
Training loss: 1.1604462335039814
Validation loss: 2.457789647914708

Epoch: 5| Step: 9
Training loss: 1.3780697454677007
Validation loss: 2.4897689890843457

Epoch: 5| Step: 10
Training loss: 1.3103827702070745
Validation loss: 2.4576340496454696

Epoch: 578| Step: 0
Training loss: 1.0372071300923535
Validation loss: 2.4746855813972544

Epoch: 5| Step: 1
Training loss: 1.4933379367064867
Validation loss: 2.524586694652877

Epoch: 5| Step: 2
Training loss: 1.6812853642824923
Validation loss: 2.51187093981089

Epoch: 5| Step: 3
Training loss: 1.5870519771801692
Validation loss: 2.4709473210022717

Epoch: 5| Step: 4
Training loss: 2.230287881923516
Validation loss: 2.489556394323068

Epoch: 5| Step: 5
Training loss: 1.205504751502237
Validation loss: 2.4361274542300686

Epoch: 5| Step: 6
Training loss: 1.127820188813757
Validation loss: 2.5025122345856037

Epoch: 5| Step: 7
Training loss: 1.5332471318823777
Validation loss: 2.4713685683959956

Epoch: 5| Step: 8
Training loss: 1.382886981574631
Validation loss: 2.477311424003357

Epoch: 5| Step: 9
Training loss: 0.9750954251175495
Validation loss: 2.4229651732139863

Epoch: 5| Step: 10
Training loss: 1.4410980639475337
Validation loss: 2.481498218214575

Epoch: 579| Step: 0
Training loss: 1.9146857045076349
Validation loss: 2.460418130708649

Epoch: 5| Step: 1
Training loss: 1.744181223500407
Validation loss: 2.471169976881048

Epoch: 5| Step: 2
Training loss: 1.2451284370662148
Validation loss: 2.41007160173672

Epoch: 5| Step: 3
Training loss: 1.299045171743689
Validation loss: 2.4512389758860316

Epoch: 5| Step: 4
Training loss: 1.155236650721235
Validation loss: 2.483304523771101

Epoch: 5| Step: 5
Training loss: 1.4110266200041124
Validation loss: 2.431218300003868

Epoch: 5| Step: 6
Training loss: 1.2493027172771447
Validation loss: 2.516991275036494

Epoch: 5| Step: 7
Training loss: 1.6300017334630443
Validation loss: 2.4671691182898123

Epoch: 5| Step: 8
Training loss: 1.612583850188622
Validation loss: 2.437639953406986

Epoch: 5| Step: 9
Training loss: 1.0269797953221864
Validation loss: 2.525240214433117

Epoch: 5| Step: 10
Training loss: 1.56019223495955
Validation loss: 2.47059768334382

Epoch: 580| Step: 0
Training loss: 1.2450221126385115
Validation loss: 2.487713038184628

Epoch: 5| Step: 1
Training loss: 1.5535405974938419
Validation loss: 2.4107476592771855

Epoch: 5| Step: 2
Training loss: 1.27272973548044
Validation loss: 2.4811328136299666

Epoch: 5| Step: 3
Training loss: 1.8591340493909352
Validation loss: 2.44903766742273

Epoch: 5| Step: 4
Training loss: 1.498478753851595
Validation loss: 2.447059774257967

Epoch: 5| Step: 5
Training loss: 1.6323115114110525
Validation loss: 2.44000339084358

Epoch: 5| Step: 6
Training loss: 1.340740782177372
Validation loss: 2.439496478770531

Epoch: 5| Step: 7
Training loss: 1.3838750776157007
Validation loss: 2.5084607264057515

Epoch: 5| Step: 8
Training loss: 1.4085394131065472
Validation loss: 2.522467437907651

Epoch: 5| Step: 9
Training loss: 1.3316390727116072
Validation loss: 2.499397383632122

Epoch: 5| Step: 10
Training loss: 1.7269294314343522
Validation loss: 2.50572629611392

Epoch: 581| Step: 0
Training loss: 1.8307302446936466
Validation loss: 2.506026412372136

Epoch: 5| Step: 1
Training loss: 1.701805443492831
Validation loss: 2.512540798297825

Epoch: 5| Step: 2
Training loss: 1.5006667880365117
Validation loss: 2.433775105271077

Epoch: 5| Step: 3
Training loss: 1.7393928316924603
Validation loss: 2.4590011956178808

Epoch: 5| Step: 4
Training loss: 1.3168212960784254
Validation loss: 2.488197342116347

Epoch: 5| Step: 5
Training loss: 1.4173863583715292
Validation loss: 2.4675994150331904

Epoch: 5| Step: 6
Training loss: 1.489831552520574
Validation loss: 2.534208935445873

Epoch: 5| Step: 7
Training loss: 0.9515113929591654
Validation loss: 2.4877787639485263

Epoch: 5| Step: 8
Training loss: 1.177250549232029
Validation loss: 2.533556380785621

Epoch: 5| Step: 9
Training loss: 1.163499427149377
Validation loss: 2.5473078200093613

Epoch: 5| Step: 10
Training loss: 1.198285612704485
Validation loss: 2.5164413223180704

Epoch: 582| Step: 0
Training loss: 1.6886345616775247
Validation loss: 2.5080312258391775

Epoch: 5| Step: 1
Training loss: 1.3687987070692857
Validation loss: 2.50350837847721

Epoch: 5| Step: 2
Training loss: 1.370953240218365
Validation loss: 2.484169523606375

Epoch: 5| Step: 3
Training loss: 1.3452762984346167
Validation loss: 2.487518050293761

Epoch: 5| Step: 4
Training loss: 1.3874809641863972
Validation loss: 2.4811934364901354

Epoch: 5| Step: 5
Training loss: 1.6307749469398063
Validation loss: 2.520087677370692

Epoch: 5| Step: 6
Training loss: 1.3141815222362343
Validation loss: 2.4663298844930974

Epoch: 5| Step: 7
Training loss: 1.4935437973900498
Validation loss: 2.4626509590240717

Epoch: 5| Step: 8
Training loss: 1.1750112147506226
Validation loss: 2.4793257737663463

Epoch: 5| Step: 9
Training loss: 1.6617073263144224
Validation loss: 2.520478344537114

Epoch: 5| Step: 10
Training loss: 1.2141139055167571
Validation loss: 2.436298441269591

Epoch: 583| Step: 0
Training loss: 1.1402055674641984
Validation loss: 2.5192549532148605

Epoch: 5| Step: 1
Training loss: 1.2254666334953743
Validation loss: 2.4591170768941772

Epoch: 5| Step: 2
Training loss: 1.3707431442754419
Validation loss: 2.471260670604401

Epoch: 5| Step: 3
Training loss: 1.7715808038847658
Validation loss: 2.4324696798852306

Epoch: 5| Step: 4
Training loss: 1.5611738299075189
Validation loss: 2.505984447936926

Epoch: 5| Step: 5
Training loss: 1.6275826984261244
Validation loss: 2.518877268333429

Epoch: 5| Step: 6
Training loss: 1.7332332392671332
Validation loss: 2.4589800947630467

Epoch: 5| Step: 7
Training loss: 1.589397620888803
Validation loss: 2.489830334012671

Epoch: 5| Step: 8
Training loss: 1.171219706107947
Validation loss: 2.572603459147278

Epoch: 5| Step: 9
Training loss: 1.1839608104831374
Validation loss: 2.505626474125698

Epoch: 5| Step: 10
Training loss: 1.5773407904420989
Validation loss: 2.4679503323707874

Epoch: 584| Step: 0
Training loss: 1.64505474973431
Validation loss: 2.556285171794343

Epoch: 5| Step: 1
Training loss: 1.3338675720105257
Validation loss: 2.481671691662783

Epoch: 5| Step: 2
Training loss: 1.9692822902386191
Validation loss: 2.476505032376573

Epoch: 5| Step: 3
Training loss: 1.5427799930281108
Validation loss: 2.4424215000954477

Epoch: 5| Step: 4
Training loss: 1.2972635813039082
Validation loss: 2.466457375635758

Epoch: 5| Step: 5
Training loss: 1.273162858987198
Validation loss: 2.475651275878642

Epoch: 5| Step: 6
Training loss: 1.2296988364330879
Validation loss: 2.459528376204002

Epoch: 5| Step: 7
Training loss: 1.4541819020578068
Validation loss: 2.513144471964654

Epoch: 5| Step: 8
Training loss: 1.212833716490266
Validation loss: 2.488969272407687

Epoch: 5| Step: 9
Training loss: 1.1195859439158318
Validation loss: 2.464179047711812

Epoch: 5| Step: 10
Training loss: 1.6092158859261518
Validation loss: 2.4956614636591534

Epoch: 585| Step: 0
Training loss: 1.215917866787804
Validation loss: 2.4604903151280677

Epoch: 5| Step: 1
Training loss: 1.178685855677632
Validation loss: 2.4133817569982794

Epoch: 5| Step: 2
Training loss: 1.454387895357268
Validation loss: 2.4755795961836675

Epoch: 5| Step: 3
Training loss: 0.9574539807966348
Validation loss: 2.502521880569894

Epoch: 5| Step: 4
Training loss: 1.134122630228371
Validation loss: 2.488307007009653

Epoch: 5| Step: 5
Training loss: 1.8355422872910985
Validation loss: 2.476751422078038

Epoch: 5| Step: 6
Training loss: 1.6429327583089288
Validation loss: 2.5139337315587387

Epoch: 5| Step: 7
Training loss: 1.6307568911942363
Validation loss: 2.487390511594613

Epoch: 5| Step: 8
Training loss: 1.311127353601728
Validation loss: 2.4769087505691556

Epoch: 5| Step: 9
Training loss: 1.4658170594567501
Validation loss: 2.54565650171809

Epoch: 5| Step: 10
Training loss: 1.8224943125862367
Validation loss: 2.4651006972881073

Epoch: 586| Step: 0
Training loss: 1.3197211572147705
Validation loss: 2.435702102321831

Epoch: 5| Step: 1
Training loss: 1.476975398386295
Validation loss: 2.4500807210797637

Epoch: 5| Step: 2
Training loss: 1.1176513029245276
Validation loss: 2.4949105258184137

Epoch: 5| Step: 3
Training loss: 1.4646163560482495
Validation loss: 2.46346240078826

Epoch: 5| Step: 4
Training loss: 1.492862568687023
Validation loss: 2.4577613368121094

Epoch: 5| Step: 5
Training loss: 1.4025447775752609
Validation loss: 2.4886926853132927

Epoch: 5| Step: 6
Training loss: 1.8621123864237763
Validation loss: 2.53848535280846

Epoch: 5| Step: 7
Training loss: 1.133596425280053
Validation loss: 2.4783878397394146

Epoch: 5| Step: 8
Training loss: 1.5456343019716916
Validation loss: 2.5070324262328794

Epoch: 5| Step: 9
Training loss: 1.6316242183401997
Validation loss: 2.504120450042693

Epoch: 5| Step: 10
Training loss: 1.519618250065057
Validation loss: 2.4864638195929913

Epoch: 587| Step: 0
Training loss: 1.251276223044133
Validation loss: 2.513184001270705

Epoch: 5| Step: 1
Training loss: 1.5771515364956008
Validation loss: 2.458707422944593

Epoch: 5| Step: 2
Training loss: 1.566776070258126
Validation loss: 2.4732382731087363

Epoch: 5| Step: 3
Training loss: 1.252082282439863
Validation loss: 2.4859950806444466

Epoch: 5| Step: 4
Training loss: 1.470447208991381
Validation loss: 2.430644278208336

Epoch: 5| Step: 5
Training loss: 1.8458999771016487
Validation loss: 2.4717565971917432

Epoch: 5| Step: 6
Training loss: 1.421364241867542
Validation loss: 2.4912487731798523

Epoch: 5| Step: 7
Training loss: 1.2187938193244325
Validation loss: 2.5119746153190077

Epoch: 5| Step: 8
Training loss: 1.6035086367939229
Validation loss: 2.469301500944194

Epoch: 5| Step: 9
Training loss: 1.0367291861772783
Validation loss: 2.451684591470223

Epoch: 5| Step: 10
Training loss: 1.222217566428324
Validation loss: 2.4502729844344704

Epoch: 588| Step: 0
Training loss: 1.2645753817279488
Validation loss: 2.497569773399422

Epoch: 5| Step: 1
Training loss: 1.36657116757882
Validation loss: 2.4357888100039906

Epoch: 5| Step: 2
Training loss: 1.7400890079840132
Validation loss: 2.415921631758041

Epoch: 5| Step: 3
Training loss: 2.039266524941582
Validation loss: 2.4642765132296027

Epoch: 5| Step: 4
Training loss: 1.1997446901204305
Validation loss: 2.4315759480126338

Epoch: 5| Step: 5
Training loss: 1.2477632537608698
Validation loss: 2.508837827408628

Epoch: 5| Step: 6
Training loss: 1.3416823514570444
Validation loss: 2.4439230259954297

Epoch: 5| Step: 7
Training loss: 1.280955722788103
Validation loss: 2.527717719509685

Epoch: 5| Step: 8
Training loss: 1.332608766178346
Validation loss: 2.487647153010309

Epoch: 5| Step: 9
Training loss: 1.4041064561712693
Validation loss: 2.467251230408944

Epoch: 5| Step: 10
Training loss: 1.3173674744433508
Validation loss: 2.4597357922047043

Epoch: 589| Step: 0
Training loss: 1.3328759432112014
Validation loss: 2.4336929386667205

Epoch: 5| Step: 1
Training loss: 1.3176364301079535
Validation loss: 2.5077018111508695

Epoch: 5| Step: 2
Training loss: 1.761961317596854
Validation loss: 2.5005623923202105

Epoch: 5| Step: 3
Training loss: 0.7948844582189476
Validation loss: 2.5248501926827185

Epoch: 5| Step: 4
Training loss: 1.5291404985203576
Validation loss: 2.5213890070039735

Epoch: 5| Step: 5
Training loss: 1.1181324517058793
Validation loss: 2.502491336191337

Epoch: 5| Step: 6
Training loss: 1.9110171634416333
Validation loss: 2.52076435901557

Epoch: 5| Step: 7
Training loss: 1.425324081912466
Validation loss: 2.486055401898022

Epoch: 5| Step: 8
Training loss: 1.3368450896567332
Validation loss: 2.4766747130386646

Epoch: 5| Step: 9
Training loss: 1.3324638849914539
Validation loss: 2.4521896818776305

Epoch: 5| Step: 10
Training loss: 1.250042723879243
Validation loss: 2.4464385232634567

Epoch: 590| Step: 0
Training loss: 1.322837311574856
Validation loss: 2.401006386085531

Epoch: 5| Step: 1
Training loss: 1.2817961296469518
Validation loss: 2.4698580686016864

Epoch: 5| Step: 2
Training loss: 1.2034492551139826
Validation loss: 2.4126041832982468

Epoch: 5| Step: 3
Training loss: 1.3090197424918848
Validation loss: 2.482765948511637

Epoch: 5| Step: 4
Training loss: 1.6197593988309864
Validation loss: 2.461420101277667

Epoch: 5| Step: 5
Training loss: 1.1219772419788892
Validation loss: 2.4127579232516174

Epoch: 5| Step: 6
Training loss: 1.8547334840468273
Validation loss: 2.471727214926797

Epoch: 5| Step: 7
Training loss: 1.7599130244872232
Validation loss: 2.4098092752464146

Epoch: 5| Step: 8
Training loss: 1.6636167833746025
Validation loss: 2.4775546789409755

Epoch: 5| Step: 9
Training loss: 1.0290561227980246
Validation loss: 2.4517818358587857

Epoch: 5| Step: 10
Training loss: 1.0437050267198549
Validation loss: 2.4715497346369983

Epoch: 591| Step: 0
Training loss: 1.238114402914359
Validation loss: 2.5047976466104296

Epoch: 5| Step: 1
Training loss: 1.351388556251777
Validation loss: 2.485431941884854

Epoch: 5| Step: 2
Training loss: 1.8165709062004787
Validation loss: 2.565709249163299

Epoch: 5| Step: 3
Training loss: 1.167852542671486
Validation loss: 2.535910179989765

Epoch: 5| Step: 4
Training loss: 1.25202010953006
Validation loss: 2.546821179460781

Epoch: 5| Step: 5
Training loss: 1.1776759194817603
Validation loss: 2.512440766458861

Epoch: 5| Step: 6
Training loss: 1.5724115718606917
Validation loss: 2.5146382915874765

Epoch: 5| Step: 7
Training loss: 1.4367264864092533
Validation loss: 2.5188094858978105

Epoch: 5| Step: 8
Training loss: 1.6021695358968668
Validation loss: 2.5011922618495084

Epoch: 5| Step: 9
Training loss: 1.5546973913443587
Validation loss: 2.5162620351847003

Epoch: 5| Step: 10
Training loss: 1.1741889995529435
Validation loss: 2.4769596304070154

Epoch: 592| Step: 0
Training loss: 1.744884234198124
Validation loss: 2.42773549486727

Epoch: 5| Step: 1
Training loss: 1.5873126752973234
Validation loss: 2.5172977836054087

Epoch: 5| Step: 2
Training loss: 1.2026761691661845
Validation loss: 2.4210074764119205

Epoch: 5| Step: 3
Training loss: 1.8037728638234214
Validation loss: 2.4328077423630656

Epoch: 5| Step: 4
Training loss: 0.9588014385444948
Validation loss: 2.486878676537989

Epoch: 5| Step: 5
Training loss: 1.4513695891505076
Validation loss: 2.4780697092027113

Epoch: 5| Step: 6
Training loss: 1.7513760197760173
Validation loss: 2.5095705357690075

Epoch: 5| Step: 7
Training loss: 0.9542226568116771
Validation loss: 2.475065876960435

Epoch: 5| Step: 8
Training loss: 1.1888799680145394
Validation loss: 2.4682946325806694

Epoch: 5| Step: 9
Training loss: 1.3121628101094678
Validation loss: 2.4516344738056115

Epoch: 5| Step: 10
Training loss: 1.5812895366565936
Validation loss: 2.5010992330494255

Epoch: 593| Step: 0
Training loss: 1.4639582284377501
Validation loss: 2.394513663879245

Epoch: 5| Step: 1
Training loss: 1.4769088096800682
Validation loss: 2.4845127772558517

Epoch: 5| Step: 2
Training loss: 1.8345069019003764
Validation loss: 2.462716353270174

Epoch: 5| Step: 3
Training loss: 1.279469345930055
Validation loss: 2.51439053286657

Epoch: 5| Step: 4
Training loss: 1.2489805833087637
Validation loss: 2.4850729293934943

Epoch: 5| Step: 5
Training loss: 1.5396040530051573
Validation loss: 2.504085158432525

Epoch: 5| Step: 6
Training loss: 1.239877628471695
Validation loss: 2.4708662369723076

Epoch: 5| Step: 7
Training loss: 1.122991252019274
Validation loss: 2.4107937368858208

Epoch: 5| Step: 8
Training loss: 1.3373909789957301
Validation loss: 2.466608281790152

Epoch: 5| Step: 9
Training loss: 1.501859862925573
Validation loss: 2.5018792534030485

Epoch: 5| Step: 10
Training loss: 1.0565477707656148
Validation loss: 2.4915459629736723

Epoch: 594| Step: 0
Training loss: 1.4476084850025714
Validation loss: 2.42399972262598

Epoch: 5| Step: 1
Training loss: 1.7052609410110424
Validation loss: 2.4984881957238945

Epoch: 5| Step: 2
Training loss: 1.4984147914402846
Validation loss: 2.4554357222325995

Epoch: 5| Step: 3
Training loss: 1.6029899376680106
Validation loss: 2.5058370885953827

Epoch: 5| Step: 4
Training loss: 1.0068169933353566
Validation loss: 2.416869776263023

Epoch: 5| Step: 5
Training loss: 1.156899089593337
Validation loss: 2.5031078279502363

Epoch: 5| Step: 6
Training loss: 1.1818872115675862
Validation loss: 2.5284913183134523

Epoch: 5| Step: 7
Training loss: 1.3277690185983302
Validation loss: 2.518900164009354

Epoch: 5| Step: 8
Training loss: 1.325032886960699
Validation loss: 2.4639710287591794

Epoch: 5| Step: 9
Training loss: 1.9296073124707462
Validation loss: 2.461006027390039

Epoch: 5| Step: 10
Training loss: 1.4669539650661056
Validation loss: 2.4555735801675325

Epoch: 595| Step: 0
Training loss: 1.6229782732662765
Validation loss: 2.516332548367941

Epoch: 5| Step: 1
Training loss: 1.4516232021027973
Validation loss: 2.5411223183856526

Epoch: 5| Step: 2
Training loss: 1.5919972673900673
Validation loss: 2.552375268133405

Epoch: 5| Step: 3
Training loss: 1.9368468383435526
Validation loss: 2.5288459627075794

Epoch: 5| Step: 4
Training loss: 1.2757461309417297
Validation loss: 2.5024335788831493

Epoch: 5| Step: 5
Training loss: 1.582789637258337
Validation loss: 2.456724305281999

Epoch: 5| Step: 6
Training loss: 1.4211952345201566
Validation loss: 2.473881089322063

Epoch: 5| Step: 7
Training loss: 1.1891862040471703
Validation loss: 2.4822261559490437

Epoch: 5| Step: 8
Training loss: 1.4748512322354965
Validation loss: 2.520694316616365

Epoch: 5| Step: 9
Training loss: 1.3292149278893635
Validation loss: 2.4194763181808185

Epoch: 5| Step: 10
Training loss: 1.3270476066455377
Validation loss: 2.4744020117082868

Epoch: 596| Step: 0
Training loss: 1.0420317709357063
Validation loss: 2.477468912506103

Epoch: 5| Step: 1
Training loss: 1.3204396203596835
Validation loss: 2.4909993570561193

Epoch: 5| Step: 2
Training loss: 1.6092641847846687
Validation loss: 2.404519724589228

Epoch: 5| Step: 3
Training loss: 1.396611945454287
Validation loss: 2.4663790845586036

Epoch: 5| Step: 4
Training loss: 1.2960524650744842
Validation loss: 2.481270125682971

Epoch: 5| Step: 5
Training loss: 1.2713110083360333
Validation loss: 2.4350334942350558

Epoch: 5| Step: 6
Training loss: 1.261527221125935
Validation loss: 2.4876833641542073

Epoch: 5| Step: 7
Training loss: 1.5132606390719763
Validation loss: 2.5030305828719497

Epoch: 5| Step: 8
Training loss: 1.7876793457971965
Validation loss: 2.5029464811442868

Epoch: 5| Step: 9
Training loss: 1.28741979256575
Validation loss: 2.484249583147484

Epoch: 5| Step: 10
Training loss: 1.3853077331777628
Validation loss: 2.5075585921003114

Epoch: 597| Step: 0
Training loss: 2.0496723192283537
Validation loss: 2.548167168844568

Epoch: 5| Step: 1
Training loss: 1.4153942770652106
Validation loss: 2.5760184105507116

Epoch: 5| Step: 2
Training loss: 1.0488809185131591
Validation loss: 2.480277094995735

Epoch: 5| Step: 3
Training loss: 1.238382618121458
Validation loss: 2.550815357860317

Epoch: 5| Step: 4
Training loss: 1.6484346796526894
Validation loss: 2.492082140275716

Epoch: 5| Step: 5
Training loss: 1.4326166882348312
Validation loss: 2.5328526064114616

Epoch: 5| Step: 6
Training loss: 1.2710431295771116
Validation loss: 2.5018470975251526

Epoch: 5| Step: 7
Training loss: 1.326164324237525
Validation loss: 2.46413429921339

Epoch: 5| Step: 8
Training loss: 1.497501756542876
Validation loss: 2.4224419709837286

Epoch: 5| Step: 9
Training loss: 1.3551547871400003
Validation loss: 2.5086644594694465

Epoch: 5| Step: 10
Training loss: 1.2346928826989334
Validation loss: 2.475314928695149

Epoch: 598| Step: 0
Training loss: 1.1797940540822847
Validation loss: 2.5074867055057517

Epoch: 5| Step: 1
Training loss: 1.5274624595461834
Validation loss: 2.508357352292801

Epoch: 5| Step: 2
Training loss: 1.8442511443198824
Validation loss: 2.5021872150969617

Epoch: 5| Step: 3
Training loss: 1.1644099184329981
Validation loss: 2.373688748721293

Epoch: 5| Step: 4
Training loss: 1.4569278301935817
Validation loss: 2.4633527382073255

Epoch: 5| Step: 5
Training loss: 1.4982774698764918
Validation loss: 2.4882508295979235

Epoch: 5| Step: 6
Training loss: 1.5038510795481073
Validation loss: 2.4648955996431137

Epoch: 5| Step: 7
Training loss: 1.3398430382195632
Validation loss: 2.512835410229927

Epoch: 5| Step: 8
Training loss: 1.0157255269697618
Validation loss: 2.4876574914497387

Epoch: 5| Step: 9
Training loss: 1.384378268752534
Validation loss: 2.4446547482408842

Epoch: 5| Step: 10
Training loss: 1.6384885410330705
Validation loss: 2.420777862087248

Epoch: 599| Step: 0
Training loss: 1.1655859483001483
Validation loss: 2.5001031382625474

Epoch: 5| Step: 1
Training loss: 1.1319803799084778
Validation loss: 2.461173112134384

Epoch: 5| Step: 2
Training loss: 1.7598427132203203
Validation loss: 2.4403575846564762

Epoch: 5| Step: 3
Training loss: 1.3082621139936494
Validation loss: 2.527376402091342

Epoch: 5| Step: 4
Training loss: 1.1805436015303017
Validation loss: 2.485074536650477

Epoch: 5| Step: 5
Training loss: 1.2622841905514244
Validation loss: 2.4207220042137654

Epoch: 5| Step: 6
Training loss: 1.7626554109490042
Validation loss: 2.488324183696065

Epoch: 5| Step: 7
Training loss: 1.0552552567066158
Validation loss: 2.456794057334192

Epoch: 5| Step: 8
Training loss: 1.487933981922974
Validation loss: 2.463148151239393

Epoch: 5| Step: 9
Training loss: 1.5649187821346302
Validation loss: 2.5004966785952405

Epoch: 5| Step: 10
Training loss: 1.493612677355162
Validation loss: 2.433983236036614

Epoch: 600| Step: 0
Training loss: 1.313832288028763
Validation loss: 2.4492648313135756

Epoch: 5| Step: 1
Training loss: 1.315741124770644
Validation loss: 2.513576598667302

Epoch: 5| Step: 2
Training loss: 1.1057963071334038
Validation loss: 2.4801036408071653

Epoch: 5| Step: 3
Training loss: 1.1018012038438458
Validation loss: 2.450420164720631

Epoch: 5| Step: 4
Training loss: 1.3328059116929643
Validation loss: 2.518439050215144

Epoch: 5| Step: 5
Training loss: 1.3835841466655492
Validation loss: 2.5431430671780424

Epoch: 5| Step: 6
Training loss: 1.2958823392050678
Validation loss: 2.489236187983663

Epoch: 5| Step: 7
Training loss: 1.377619718621295
Validation loss: 2.494594840493113

Epoch: 5| Step: 8
Training loss: 2.21940517154726
Validation loss: 2.474119037445251

Epoch: 5| Step: 9
Training loss: 1.5651386106977943
Validation loss: 2.5372893477306437

Epoch: 5| Step: 10
Training loss: 1.1155628582399602
Validation loss: 2.485455698515616

Epoch: 601| Step: 0
Training loss: 1.592781071553977
Validation loss: 2.4604603846754425

Epoch: 5| Step: 1
Training loss: 1.7888268727885734
Validation loss: 2.4736539091017185

Epoch: 5| Step: 2
Training loss: 1.170143424885929
Validation loss: 2.4953481628251812

Epoch: 5| Step: 3
Training loss: 1.4249179682627615
Validation loss: 2.456450246024197

Epoch: 5| Step: 4
Training loss: 1.2372278973988295
Validation loss: 2.465132250937332

Epoch: 5| Step: 5
Training loss: 1.3766222400670522
Validation loss: 2.4367429063918133

Epoch: 5| Step: 6
Training loss: 1.1300970746431767
Validation loss: 2.494548045756879

Epoch: 5| Step: 7
Training loss: 1.3225155119536065
Validation loss: 2.4889330202313675

Epoch: 5| Step: 8
Training loss: 1.0953410973400453
Validation loss: 2.4740869300636046

Epoch: 5| Step: 9
Training loss: 1.7320411719699176
Validation loss: 2.4803513836096998

Epoch: 5| Step: 10
Training loss: 1.5056479932803648
Validation loss: 2.5436683598347956

Epoch: 602| Step: 0
Training loss: 1.6138603888946341
Validation loss: 2.435836718826636

Epoch: 5| Step: 1
Training loss: 1.1561403995840709
Validation loss: 2.5335594609291734

Epoch: 5| Step: 2
Training loss: 1.1299258580823714
Validation loss: 2.4850168903567718

Epoch: 5| Step: 3
Training loss: 1.5555646712550748
Validation loss: 2.4660965946555646

Epoch: 5| Step: 4
Training loss: 1.5608567561591553
Validation loss: 2.504482670137253

Epoch: 5| Step: 5
Training loss: 1.2772608738882674
Validation loss: 2.455305551754817

Epoch: 5| Step: 6
Training loss: 1.0408904553252387
Validation loss: 2.457543248404503

Epoch: 5| Step: 7
Training loss: 0.9591078358286065
Validation loss: 2.5124305799992688

Epoch: 5| Step: 8
Training loss: 1.0349170336434068
Validation loss: 2.4837338422604596

Epoch: 5| Step: 9
Training loss: 1.6030675004013073
Validation loss: 2.524694060492345

Epoch: 5| Step: 10
Training loss: 2.1347400492735438
Validation loss: 2.531710208251408

Epoch: 603| Step: 0
Training loss: 0.7085814789337235
Validation loss: 2.4981727156935807

Epoch: 5| Step: 1
Training loss: 1.1934591648066193
Validation loss: 2.4932658188455084

Epoch: 5| Step: 2
Training loss: 1.769188449825539
Validation loss: 2.496746145322034

Epoch: 5| Step: 3
Training loss: 1.2494023801809924
Validation loss: 2.4828037197969923

Epoch: 5| Step: 4
Training loss: 1.9913861027892306
Validation loss: 2.500683938065565

Epoch: 5| Step: 5
Training loss: 1.28879798718419
Validation loss: 2.4842662399218494

Epoch: 5| Step: 6
Training loss: 1.4487876559375672
Validation loss: 2.5045745640116066

Epoch: 5| Step: 7
Training loss: 1.7309251446066896
Validation loss: 2.4939528351605667

Epoch: 5| Step: 8
Training loss: 0.9232974312501034
Validation loss: 2.48662213777548

Epoch: 5| Step: 9
Training loss: 1.4851703320055851
Validation loss: 2.485851769131056

Epoch: 5| Step: 10
Training loss: 1.4867312552587166
Validation loss: 2.4724984518388653

Epoch: 604| Step: 0
Training loss: 1.5938467108611098
Validation loss: 2.5240427704283412

Epoch: 5| Step: 1
Training loss: 1.5946242982366898
Validation loss: 2.4535197952770855

Epoch: 5| Step: 2
Training loss: 1.2343448683525688
Validation loss: 2.4305771609243108

Epoch: 5| Step: 3
Training loss: 0.8923811079490314
Validation loss: 2.4747470640287466

Epoch: 5| Step: 4
Training loss: 1.234194199080891
Validation loss: 2.505096520716445

Epoch: 5| Step: 5
Training loss: 1.8909836105854883
Validation loss: 2.552899737151823

Epoch: 5| Step: 6
Training loss: 1.1140836266952798
Validation loss: 2.5306223307979105

Epoch: 5| Step: 7
Training loss: 1.106982054657114
Validation loss: 2.466822833472512

Epoch: 5| Step: 8
Training loss: 1.8791012732157948
Validation loss: 2.4481669224516027

Epoch: 5| Step: 9
Training loss: 1.0701868582163694
Validation loss: 2.4821015239347712

Epoch: 5| Step: 10
Training loss: 1.4227933328478228
Validation loss: 2.4761940060323537

Epoch: 605| Step: 0
Training loss: 1.3945195387233646
Validation loss: 2.491653946408392

Epoch: 5| Step: 1
Training loss: 1.5290426576450755
Validation loss: 2.468230752998295

Epoch: 5| Step: 2
Training loss: 1.3139436139589293
Validation loss: 2.489168076532736

Epoch: 5| Step: 3
Training loss: 0.9888315289687357
Validation loss: 2.4457992661046477

Epoch: 5| Step: 4
Training loss: 1.296592727643445
Validation loss: 2.441926561659174

Epoch: 5| Step: 5
Training loss: 1.8742277462398722
Validation loss: 2.4623045297025556

Epoch: 5| Step: 6
Training loss: 1.3889153075354694
Validation loss: 2.5133757337084357

Epoch: 5| Step: 7
Training loss: 1.5008966626932516
Validation loss: 2.5156294106044994

Epoch: 5| Step: 8
Training loss: 0.905471895227244
Validation loss: 2.4816228629662045

Epoch: 5| Step: 9
Training loss: 1.3252343078588078
Validation loss: 2.501393922214096

Epoch: 5| Step: 10
Training loss: 1.5147354032144025
Validation loss: 2.489167764209885

Epoch: 606| Step: 0
Training loss: 1.2901722148412453
Validation loss: 2.4135975849158684

Epoch: 5| Step: 1
Training loss: 1.5225817502127539
Validation loss: 2.527172465169785

Epoch: 5| Step: 2
Training loss: 1.1608680057390923
Validation loss: 2.4854086883875945

Epoch: 5| Step: 3
Training loss: 1.3061323103749884
Validation loss: 2.5426691405956796

Epoch: 5| Step: 4
Training loss: 1.6533890251937025
Validation loss: 2.5198636903339855

Epoch: 5| Step: 5
Training loss: 2.0327480953959687
Validation loss: 2.536955574698603

Epoch: 5| Step: 6
Training loss: 1.1515178242147417
Validation loss: 2.496928081220052

Epoch: 5| Step: 7
Training loss: 1.565673809090178
Validation loss: 2.500070977997972

Epoch: 5| Step: 8
Training loss: 0.8881586961575288
Validation loss: 2.4810788033007736

Epoch: 5| Step: 9
Training loss: 1.3243835256679266
Validation loss: 2.510755422559537

Epoch: 5| Step: 10
Training loss: 1.0955992732751392
Validation loss: 2.488807098629771

Epoch: 607| Step: 0
Training loss: 1.5215993894068378
Validation loss: 2.4613573702227987

Epoch: 5| Step: 1
Training loss: 1.1837176771091353
Validation loss: 2.483416636567978

Epoch: 5| Step: 2
Training loss: 1.012654229179618
Validation loss: 2.4958940890519754

Epoch: 5| Step: 3
Training loss: 1.8898655650853737
Validation loss: 2.3950597369260813

Epoch: 5| Step: 4
Training loss: 1.4644673995703341
Validation loss: 2.4723395921604094

Epoch: 5| Step: 5
Training loss: 1.359548711091368
Validation loss: 2.4509978505139536

Epoch: 5| Step: 6
Training loss: 1.1381747958556367
Validation loss: 2.4302984384310076

Epoch: 5| Step: 7
Training loss: 1.4679472332443846
Validation loss: 2.475563613633347

Epoch: 5| Step: 8
Training loss: 0.9887060827926025
Validation loss: 2.5020640066887356

Epoch: 5| Step: 9
Training loss: 1.3211498877961823
Validation loss: 2.4558144306016985

Epoch: 5| Step: 10
Training loss: 1.2582452160043038
Validation loss: 2.4360737894294298

Epoch: 608| Step: 0
Training loss: 1.2774987549598436
Validation loss: 2.4619330415272667

Epoch: 5| Step: 1
Training loss: 1.2621683081584274
Validation loss: 2.4632534710198497

Epoch: 5| Step: 2
Training loss: 1.6811563855736702
Validation loss: 2.457342725848751

Epoch: 5| Step: 3
Training loss: 1.4469527551178762
Validation loss: 2.518675743618019

Epoch: 5| Step: 4
Training loss: 0.8213287597932469
Validation loss: 2.558860836885015

Epoch: 5| Step: 5
Training loss: 1.20272359716202
Validation loss: 2.4875994732040385

Epoch: 5| Step: 6
Training loss: 1.29471210144226
Validation loss: 2.551560385798445

Epoch: 5| Step: 7
Training loss: 1.1827187907943901
Validation loss: 2.444953718890081

Epoch: 5| Step: 8
Training loss: 1.409174358016819
Validation loss: 2.4859774996032526

Epoch: 5| Step: 9
Training loss: 1.2101393007060561
Validation loss: 2.5492188789654984

Epoch: 5| Step: 10
Training loss: 2.013591953471266
Validation loss: 2.497774512825537

Epoch: 609| Step: 0
Training loss: 1.382397476243987
Validation loss: 2.442711997510988

Epoch: 5| Step: 1
Training loss: 1.400234580822941
Validation loss: 2.525772119079948

Epoch: 5| Step: 2
Training loss: 1.3913432634459586
Validation loss: 2.4899741876974764

Epoch: 5| Step: 3
Training loss: 1.8864782586845525
Validation loss: 2.468606841117699

Epoch: 5| Step: 4
Training loss: 0.8902595841176563
Validation loss: 2.4171296045097597

Epoch: 5| Step: 5
Training loss: 1.295004081130501
Validation loss: 2.5125589862654705

Epoch: 5| Step: 6
Training loss: 1.4478580636805174
Validation loss: 2.4967884098041053

Epoch: 5| Step: 7
Training loss: 1.2956214269505064
Validation loss: 2.4747318825706905

Epoch: 5| Step: 8
Training loss: 1.2595100557592929
Validation loss: 2.465443795153704

Epoch: 5| Step: 9
Training loss: 1.5895280454260772
Validation loss: 2.480065111012786

Epoch: 5| Step: 10
Training loss: 1.2162016611402497
Validation loss: 2.4641319271415982

Epoch: 610| Step: 0
Training loss: 1.6169334617518019
Validation loss: 2.4728342469879285

Epoch: 5| Step: 1
Training loss: 1.2783217113187055
Validation loss: 2.5643037304943674

Epoch: 5| Step: 2
Training loss: 2.1159375995167786
Validation loss: 2.5474527039631223

Epoch: 5| Step: 3
Training loss: 1.205045579072008
Validation loss: 2.5187532895597333

Epoch: 5| Step: 4
Training loss: 1.4531013732958271
Validation loss: 2.483102783451625

Epoch: 5| Step: 5
Training loss: 1.249088145496925
Validation loss: 2.456443292265716

Epoch: 5| Step: 6
Training loss: 0.9908032109585456
Validation loss: 2.526306459845337

Epoch: 5| Step: 7
Training loss: 1.3037764057766061
Validation loss: 2.4373891861523815

Epoch: 5| Step: 8
Training loss: 1.4987964570112782
Validation loss: 2.566429596707638

Epoch: 5| Step: 9
Training loss: 0.827222152001445
Validation loss: 2.5031281353695802

Epoch: 5| Step: 10
Training loss: 1.6261042730907853
Validation loss: 2.467139171704819

Epoch: 611| Step: 0
Training loss: 1.0378562407564214
Validation loss: 2.582110540969566

Epoch: 5| Step: 1
Training loss: 1.0937795362571638
Validation loss: 2.499935498994991

Epoch: 5| Step: 2
Training loss: 1.4249808795382346
Validation loss: 2.460374153637312

Epoch: 5| Step: 3
Training loss: 1.8811892401429513
Validation loss: 2.514076320272399

Epoch: 5| Step: 4
Training loss: 1.3657701393358939
Validation loss: 2.481562704633177

Epoch: 5| Step: 5
Training loss: 1.359314577360222
Validation loss: 2.4633946046526485

Epoch: 5| Step: 6
Training loss: 1.1698425979374212
Validation loss: 2.4357446198050425

Epoch: 5| Step: 7
Training loss: 1.7137232010830745
Validation loss: 2.4924766076322493

Epoch: 5| Step: 8
Training loss: 1.2501403729775458
Validation loss: 2.503260893061638

Epoch: 5| Step: 9
Training loss: 0.9929241239422701
Validation loss: 2.4698266967720057

Epoch: 5| Step: 10
Training loss: 1.5570002849924052
Validation loss: 2.4114301484038085

Epoch: 612| Step: 0
Training loss: 1.1800212261747762
Validation loss: 2.4437306790059763

Epoch: 5| Step: 1
Training loss: 1.175504937132767
Validation loss: 2.4394542221476327

Epoch: 5| Step: 2
Training loss: 1.8052453173946585
Validation loss: 2.519599080172322

Epoch: 5| Step: 3
Training loss: 1.2508714499226399
Validation loss: 2.4761669810591407

Epoch: 5| Step: 4
Training loss: 1.419220679093994
Validation loss: 2.495481374984709

Epoch: 5| Step: 5
Training loss: 1.4614938094966887
Validation loss: 2.5349731449974002

Epoch: 5| Step: 6
Training loss: 1.3657379313198774
Validation loss: 2.470019318334573

Epoch: 5| Step: 7
Training loss: 1.8408677153213644
Validation loss: 2.409317781000278

Epoch: 5| Step: 8
Training loss: 1.3326763034295295
Validation loss: 2.5140905748240843

Epoch: 5| Step: 9
Training loss: 1.321756194346751
Validation loss: 2.5304935550009935

Epoch: 5| Step: 10
Training loss: 1.001144112311066
Validation loss: 2.498415281646453

Epoch: 613| Step: 0
Training loss: 0.953512550733487
Validation loss: 2.4702398545885837

Epoch: 5| Step: 1
Training loss: 0.9517192479709894
Validation loss: 2.418968708918547

Epoch: 5| Step: 2
Training loss: 1.7447737583740668
Validation loss: 2.502672015481485

Epoch: 5| Step: 3
Training loss: 1.419936147248165
Validation loss: 2.485086405354873

Epoch: 5| Step: 4
Training loss: 1.3587549044916236
Validation loss: 2.4764595707788555

Epoch: 5| Step: 5
Training loss: 1.4177855486259903
Validation loss: 2.472746672528367

Epoch: 5| Step: 6
Training loss: 1.2792032222101257
Validation loss: 2.4511609078393053

Epoch: 5| Step: 7
Training loss: 1.4014836385903513
Validation loss: 2.4555260459829222

Epoch: 5| Step: 8
Training loss: 1.3409181074359497
Validation loss: 2.514435892876472

Epoch: 5| Step: 9
Training loss: 1.694970021615729
Validation loss: 2.484028420627056

Epoch: 5| Step: 10
Training loss: 1.0573367154651376
Validation loss: 2.4371061835190124

Epoch: 614| Step: 0
Training loss: 1.6069726884155426
Validation loss: 2.4408577214771694

Epoch: 5| Step: 1
Training loss: 1.161839917142151
Validation loss: 2.501894200453028

Epoch: 5| Step: 2
Training loss: 1.7257304538557678
Validation loss: 2.4428611592293104

Epoch: 5| Step: 3
Training loss: 1.315834306028432
Validation loss: 2.4623989460733338

Epoch: 5| Step: 4
Training loss: 1.1425860543261184
Validation loss: 2.4876397557233507

Epoch: 5| Step: 5
Training loss: 1.1032285603874057
Validation loss: 2.511082419304342

Epoch: 5| Step: 6
Training loss: 1.4181883250489604
Validation loss: 2.48961462748716

Epoch: 5| Step: 7
Training loss: 1.447333083337393
Validation loss: 2.49525336784197

Epoch: 5| Step: 8
Training loss: 1.5993890668839983
Validation loss: 2.4890400963231603

Epoch: 5| Step: 9
Training loss: 1.309656332378307
Validation loss: 2.4787463849371423

Epoch: 5| Step: 10
Training loss: 1.2241846348841992
Validation loss: 2.4969568147805243

Epoch: 615| Step: 0
Training loss: 1.7633847227822952
Validation loss: 2.4589595859076985

Epoch: 5| Step: 1
Training loss: 1.450478800285028
Validation loss: 2.5341299595520828

Epoch: 5| Step: 2
Training loss: 1.0887962968270015
Validation loss: 2.490302620197324

Epoch: 5| Step: 3
Training loss: 1.2630743061295189
Validation loss: 2.4981373646880622

Epoch: 5| Step: 4
Training loss: 0.9908880299731301
Validation loss: 2.497258946847808

Epoch: 5| Step: 5
Training loss: 1.2303634356283022
Validation loss: 2.5530355485642238

Epoch: 5| Step: 6
Training loss: 1.6093078895575992
Validation loss: 2.4891654664600185

Epoch: 5| Step: 7
Training loss: 1.6782480858925846
Validation loss: 2.5212430493049642

Epoch: 5| Step: 8
Training loss: 0.9483338615190301
Validation loss: 2.459373473766206

Epoch: 5| Step: 9
Training loss: 1.7596918528819183
Validation loss: 2.4562165052496345

Epoch: 5| Step: 10
Training loss: 1.256647790966051
Validation loss: 2.5137431064050895

Epoch: 616| Step: 0
Training loss: 1.786627232284822
Validation loss: 2.479146205713914

Epoch: 5| Step: 1
Training loss: 1.4519016489710699
Validation loss: 2.503253702189673

Epoch: 5| Step: 2
Training loss: 1.0418360127441177
Validation loss: 2.3933737582810184

Epoch: 5| Step: 3
Training loss: 1.3219665008692434
Validation loss: 2.4649509697639607

Epoch: 5| Step: 4
Training loss: 1.672965148882002
Validation loss: 2.439762865702997

Epoch: 5| Step: 5
Training loss: 1.5835987002535787
Validation loss: 2.4392237041634064

Epoch: 5| Step: 6
Training loss: 1.0646600084755489
Validation loss: 2.4649370883487403

Epoch: 5| Step: 7
Training loss: 1.0758421681871413
Validation loss: 2.489181070725

Epoch: 5| Step: 8
Training loss: 1.5587467128104122
Validation loss: 2.466428694211255

Epoch: 5| Step: 9
Training loss: 1.2691848986679741
Validation loss: 2.5702175633144977

Epoch: 5| Step: 10
Training loss: 0.9992771218126286
Validation loss: 2.545756719796656

Epoch: 617| Step: 0
Training loss: 1.1731194056121967
Validation loss: 2.4716647236858806

Epoch: 5| Step: 1
Training loss: 1.0262807125462892
Validation loss: 2.5070187180023287

Epoch: 5| Step: 2
Training loss: 1.7711208184945582
Validation loss: 2.4947615561778114

Epoch: 5| Step: 3
Training loss: 1.8410176219480139
Validation loss: 2.3873929556015563

Epoch: 5| Step: 4
Training loss: 1.411009469631112
Validation loss: 2.5222487401978455

Epoch: 5| Step: 5
Training loss: 1.5977369815043558
Validation loss: 2.4755771175411136

Epoch: 5| Step: 6
Training loss: 1.292305583240374
Validation loss: 2.448279609732689

Epoch: 5| Step: 7
Training loss: 0.9638592720672959
Validation loss: 2.419079457303369

Epoch: 5| Step: 8
Training loss: 1.4575808718248007
Validation loss: 2.49706823864721

Epoch: 5| Step: 9
Training loss: 0.8828632711479123
Validation loss: 2.4466200460238405

Epoch: 5| Step: 10
Training loss: 1.5421137118634873
Validation loss: 2.5316457698542085

Epoch: 618| Step: 0
Training loss: 1.2600491936480924
Validation loss: 2.4363234072692554

Epoch: 5| Step: 1
Training loss: 1.3518994743681931
Validation loss: 2.5218306873358043

Epoch: 5| Step: 2
Training loss: 1.7763203451681926
Validation loss: 2.511602923528616

Epoch: 5| Step: 3
Training loss: 1.4538505137653364
Validation loss: 2.5121674983068187

Epoch: 5| Step: 4
Training loss: 1.5174212478992277
Validation loss: 2.5132616717765086

Epoch: 5| Step: 5
Training loss: 1.2908518538717384
Validation loss: 2.5593711485486863

Epoch: 5| Step: 6
Training loss: 1.1440766248583891
Validation loss: 2.500563688205062

Epoch: 5| Step: 7
Training loss: 1.3530476078868674
Validation loss: 2.4846470723123817

Epoch: 5| Step: 8
Training loss: 1.1335282268030062
Validation loss: 2.4868351710017897

Epoch: 5| Step: 9
Training loss: 1.06206155594271
Validation loss: 2.4519576469596025

Epoch: 5| Step: 10
Training loss: 1.1615339120585328
Validation loss: 2.485076171244205

Epoch: 619| Step: 0
Training loss: 1.3679508367092155
Validation loss: 2.4390198329107116

Epoch: 5| Step: 1
Training loss: 1.4540065429466824
Validation loss: 2.4245943213255052

Epoch: 5| Step: 2
Training loss: 1.4402273262250804
Validation loss: 2.503672413810208

Epoch: 5| Step: 3
Training loss: 1.3850257102012207
Validation loss: 2.4446413881249143

Epoch: 5| Step: 4
Training loss: 1.035934328560556
Validation loss: 2.42847880803801

Epoch: 5| Step: 5
Training loss: 0.9825329272258708
Validation loss: 2.4749646940558505

Epoch: 5| Step: 6
Training loss: 1.5440788042434845
Validation loss: 2.470905730895307

Epoch: 5| Step: 7
Training loss: 1.3072630535910437
Validation loss: 2.4675823901774696

Epoch: 5| Step: 8
Training loss: 2.0233488910376485
Validation loss: 2.46864331493756

Epoch: 5| Step: 9
Training loss: 1.1602030015766869
Validation loss: 2.531812176246172

Epoch: 5| Step: 10
Training loss: 1.0429478332479467
Validation loss: 2.5517971264239407

Epoch: 620| Step: 0
Training loss: 1.1305533144837792
Validation loss: 2.5033788510344865

Epoch: 5| Step: 1
Training loss: 1.1573670635962736
Validation loss: 2.4995266158545704

Epoch: 5| Step: 2
Training loss: 1.315275844535405
Validation loss: 2.506706579954682

Epoch: 5| Step: 3
Training loss: 1.1212417558007604
Validation loss: 2.447714020442979

Epoch: 5| Step: 4
Training loss: 1.1260201808821662
Validation loss: 2.5335844419288143

Epoch: 5| Step: 5
Training loss: 2.026351891885043
Validation loss: 2.5571812962870544

Epoch: 5| Step: 6
Training loss: 1.0833648835992102
Validation loss: 2.478325026129604

Epoch: 5| Step: 7
Training loss: 1.2631896807358414
Validation loss: 2.4944936907610495

Epoch: 5| Step: 8
Training loss: 1.1602207255830457
Validation loss: 2.4489093070902395

Epoch: 5| Step: 9
Training loss: 1.2791129642525356
Validation loss: 2.5092678478674375

Epoch: 5| Step: 10
Training loss: 1.8258947478353535
Validation loss: 2.500848495919592

Epoch: 621| Step: 0
Training loss: 1.3515352455875163
Validation loss: 2.432475194541602

Epoch: 5| Step: 1
Training loss: 1.2531307591332115
Validation loss: 2.4629095501819225

Epoch: 5| Step: 2
Training loss: 1.3391840342115726
Validation loss: 2.463757969557998

Epoch: 5| Step: 3
Training loss: 1.8646979554249048
Validation loss: 2.490467245339677

Epoch: 5| Step: 4
Training loss: 1.0869804149572384
Validation loss: 2.449568502496872

Epoch: 5| Step: 5
Training loss: 1.3741638936018084
Validation loss: 2.480569216452473

Epoch: 5| Step: 6
Training loss: 1.0476017038139946
Validation loss: 2.478385631814857

Epoch: 5| Step: 7
Training loss: 1.4744621557046986
Validation loss: 2.4335258296772597

Epoch: 5| Step: 8
Training loss: 1.3137126044006198
Validation loss: 2.476043014204688

Epoch: 5| Step: 9
Training loss: 1.2969181099586045
Validation loss: 2.5312724211851987

Epoch: 5| Step: 10
Training loss: 1.4123534523214658
Validation loss: 2.4782062216734286

Epoch: 622| Step: 0
Training loss: 1.598570396589075
Validation loss: 2.488419796905724

Epoch: 5| Step: 1
Training loss: 1.214481115647453
Validation loss: 2.499883526990912

Epoch: 5| Step: 2
Training loss: 1.278401115084342
Validation loss: 2.4669321755249536

Epoch: 5| Step: 3
Training loss: 1.040561942174669
Validation loss: 2.5055487388284856

Epoch: 5| Step: 4
Training loss: 1.2539359115942657
Validation loss: 2.4808492502879016

Epoch: 5| Step: 5
Training loss: 1.2775266557215554
Validation loss: 2.5139086817407876

Epoch: 5| Step: 6
Training loss: 1.3996916107710142
Validation loss: 2.4787846022065887

Epoch: 5| Step: 7
Training loss: 1.2888369738648526
Validation loss: 2.5608947021561685

Epoch: 5| Step: 8
Training loss: 1.1404152246163426
Validation loss: 2.5368900962944934

Epoch: 5| Step: 9
Training loss: 1.841680690947885
Validation loss: 2.4983728928194884

Epoch: 5| Step: 10
Training loss: 1.4572323412359451
Validation loss: 2.5361568715402227

Epoch: 623| Step: 0
Training loss: 1.1230958082070432
Validation loss: 2.484383090127238

Epoch: 5| Step: 1
Training loss: 1.4775363193443636
Validation loss: 2.5346296590109945

Epoch: 5| Step: 2
Training loss: 0.838349650099704
Validation loss: 2.5647870554198247

Epoch: 5| Step: 3
Training loss: 1.9763046518643301
Validation loss: 2.5406760476227848

Epoch: 5| Step: 4
Training loss: 1.3576534375611495
Validation loss: 2.5259620632817734

Epoch: 5| Step: 5
Training loss: 1.2628197840966928
Validation loss: 2.4696504729766153

Epoch: 5| Step: 6
Training loss: 1.4140121282383815
Validation loss: 2.5114405770195845

Epoch: 5| Step: 7
Training loss: 1.2576024134740167
Validation loss: 2.528972178649728

Epoch: 5| Step: 8
Training loss: 1.5311106404317776
Validation loss: 2.4599192387653024

Epoch: 5| Step: 9
Training loss: 1.3059015165119638
Validation loss: 2.5093605493156956

Epoch: 5| Step: 10
Training loss: 1.0116871714726658
Validation loss: 2.4539827992401184

Epoch: 624| Step: 0
Training loss: 1.85053427430359
Validation loss: 2.500515324794132

Epoch: 5| Step: 1
Training loss: 1.2716819972909448
Validation loss: 2.4846689333233956

Epoch: 5| Step: 2
Training loss: 1.2834628465043052
Validation loss: 2.5079915580759207

Epoch: 5| Step: 3
Training loss: 1.1207154596074769
Validation loss: 2.419519634684424

Epoch: 5| Step: 4
Training loss: 1.0680021424504196
Validation loss: 2.4860633494066664

Epoch: 5| Step: 5
Training loss: 1.1089589588011353
Validation loss: 2.5126842006585606

Epoch: 5| Step: 6
Training loss: 1.6992489165335891
Validation loss: 2.4799513022847948

Epoch: 5| Step: 7
Training loss: 1.4783061394381865
Validation loss: 2.5378571183901384

Epoch: 5| Step: 8
Training loss: 1.3355429440373836
Validation loss: 2.5654112792801964

Epoch: 5| Step: 9
Training loss: 1.240726163184364
Validation loss: 2.456634652766823

Epoch: 5| Step: 10
Training loss: 1.2334405283266154
Validation loss: 2.4375684311534513

Epoch: 625| Step: 0
Training loss: 1.3395217197105442
Validation loss: 2.46061291094659

Epoch: 5| Step: 1
Training loss: 1.2370003895863049
Validation loss: 2.506695182818528

Epoch: 5| Step: 2
Training loss: 1.272882960987192
Validation loss: 2.482222815874904

Epoch: 5| Step: 3
Training loss: 1.2287695399425596
Validation loss: 2.544924676453653

Epoch: 5| Step: 4
Training loss: 1.5121676150719494
Validation loss: 2.4741279776179366

Epoch: 5| Step: 5
Training loss: 1.1509876094684788
Validation loss: 2.469077783633675

Epoch: 5| Step: 6
Training loss: 1.278809339501978
Validation loss: 2.462756510862155

Epoch: 5| Step: 7
Training loss: 1.259838439256502
Validation loss: 2.5125136051249397

Epoch: 5| Step: 8
Training loss: 0.8517876423679407
Validation loss: 2.5734285029262205

Epoch: 5| Step: 9
Training loss: 1.4132186732400864
Validation loss: 2.566060580598391

Epoch: 5| Step: 10
Training loss: 2.128947910286185
Validation loss: 2.4354109719233525

Epoch: 626| Step: 0
Training loss: 1.1369495485263033
Validation loss: 2.5532002224867734

Epoch: 5| Step: 1
Training loss: 1.4834771904498434
Validation loss: 2.465170595029703

Epoch: 5| Step: 2
Training loss: 0.9709858473032174
Validation loss: 2.4737155894092466

Epoch: 5| Step: 3
Training loss: 1.5602597771050826
Validation loss: 2.5219127005627446

Epoch: 5| Step: 4
Training loss: 1.6492372715071266
Validation loss: 2.4954580959619364

Epoch: 5| Step: 5
Training loss: 1.209936897587051
Validation loss: 2.421541350977895

Epoch: 5| Step: 6
Training loss: 1.591638100785499
Validation loss: 2.4812097252894536

Epoch: 5| Step: 7
Training loss: 1.0525449111671215
Validation loss: 2.4390766791243803

Epoch: 5| Step: 8
Training loss: 1.2828438312454014
Validation loss: 2.453145810011494

Epoch: 5| Step: 9
Training loss: 1.1679343023929538
Validation loss: 2.466790192556147

Epoch: 5| Step: 10
Training loss: 1.321103508009197
Validation loss: 2.4962191612727165

Epoch: 627| Step: 0
Training loss: 1.5034399325236731
Validation loss: 2.5256367879805426

Epoch: 5| Step: 1
Training loss: 0.9741678097644514
Validation loss: 2.4873310524163013

Epoch: 5| Step: 2
Training loss: 1.3160745446186182
Validation loss: 2.3961494554690117

Epoch: 5| Step: 3
Training loss: 1.823845770075044
Validation loss: 2.5257276533743798

Epoch: 5| Step: 4
Training loss: 1.3751731243383378
Validation loss: 2.5049741380251507

Epoch: 5| Step: 5
Training loss: 1.5876690661897908
Validation loss: 2.4847546256001016

Epoch: 5| Step: 6
Training loss: 1.1227583274014348
Validation loss: 2.5127988764576306

Epoch: 5| Step: 7
Training loss: 1.0699162550267127
Validation loss: 2.505031169502335

Epoch: 5| Step: 8
Training loss: 1.107802337470742
Validation loss: 2.520767972446796

Epoch: 5| Step: 9
Training loss: 1.3866252169160562
Validation loss: 2.5415366785251914

Epoch: 5| Step: 10
Training loss: 1.2411115773167005
Validation loss: 2.4259260695593787

Epoch: 628| Step: 0
Training loss: 0.943942566987427
Validation loss: 2.43295758189833

Epoch: 5| Step: 1
Training loss: 1.4845634742341438
Validation loss: 2.5075595613023314

Epoch: 5| Step: 2
Training loss: 1.6034688629134293
Validation loss: 2.515020775998764

Epoch: 5| Step: 3
Training loss: 1.279411811615825
Validation loss: 2.4517571841158805

Epoch: 5| Step: 4
Training loss: 1.186664638830088
Validation loss: 2.464935637488288

Epoch: 5| Step: 5
Training loss: 0.9992801936676935
Validation loss: 2.4340563887265763

Epoch: 5| Step: 6
Training loss: 1.5739363424135338
Validation loss: 2.501575984325251

Epoch: 5| Step: 7
Training loss: 1.2707237394427386
Validation loss: 2.5039000638515154

Epoch: 5| Step: 8
Training loss: 1.4344420872376806
Validation loss: 2.4549387887397445

Epoch: 5| Step: 9
Training loss: 1.5521290492892603
Validation loss: 2.4367546254469077

Epoch: 5| Step: 10
Training loss: 1.229669074922642
Validation loss: 2.4277905081729036

Epoch: 629| Step: 0
Training loss: 0.9563437658975011
Validation loss: 2.4598123343289275

Epoch: 5| Step: 1
Training loss: 1.6956608146375027
Validation loss: 2.531930780008169

Epoch: 5| Step: 2
Training loss: 1.6402648530487303
Validation loss: 2.518003334742369

Epoch: 5| Step: 3
Training loss: 1.1431590111596603
Validation loss: 2.5265955637503996

Epoch: 5| Step: 4
Training loss: 1.4584775399252992
Validation loss: 2.440939759280183

Epoch: 5| Step: 5
Training loss: 1.2753050981384857
Validation loss: 2.500776903379004

Epoch: 5| Step: 6
Training loss: 1.255243129432594
Validation loss: 2.4914054917963737

Epoch: 5| Step: 7
Training loss: 0.8197116649583701
Validation loss: 2.4592453026479846

Epoch: 5| Step: 8
Training loss: 1.438275998513634
Validation loss: 2.5015905150671625

Epoch: 5| Step: 9
Training loss: 1.5633306202868336
Validation loss: 2.448170336215006

Epoch: 5| Step: 10
Training loss: 1.2996961403568936
Validation loss: 2.4494153879153826

Epoch: 630| Step: 0
Training loss: 0.989818959877886
Validation loss: 2.470388194754562

Epoch: 5| Step: 1
Training loss: 1.0120851302546483
Validation loss: 2.4409361127473663

Epoch: 5| Step: 2
Training loss: 1.5096386539024647
Validation loss: 2.4926705581629442

Epoch: 5| Step: 3
Training loss: 1.734637953611255
Validation loss: 2.449255213186637

Epoch: 5| Step: 4
Training loss: 1.5529893965595567
Validation loss: 2.5336539539472427

Epoch: 5| Step: 5
Training loss: 1.2211241461447937
Validation loss: 2.5784962058420606

Epoch: 5| Step: 6
Training loss: 1.2096039350811463
Validation loss: 2.501102123563452

Epoch: 5| Step: 7
Training loss: 1.0843895507188042
Validation loss: 2.4530918152273715

Epoch: 5| Step: 8
Training loss: 1.1178106957331198
Validation loss: 2.49412997423688

Epoch: 5| Step: 9
Training loss: 1.4537815538624461
Validation loss: 2.4811101465147556

Epoch: 5| Step: 10
Training loss: 1.3833142248618715
Validation loss: 2.4526734953900093

Epoch: 631| Step: 0
Training loss: 1.3947098561520224
Validation loss: 2.521116827740663

Epoch: 5| Step: 1
Training loss: 1.2942311557800155
Validation loss: 2.527765735887671

Epoch: 5| Step: 2
Training loss: 1.2081673716432846
Validation loss: 2.513966217223496

Epoch: 5| Step: 3
Training loss: 1.7867171727462499
Validation loss: 2.4689115640430854

Epoch: 5| Step: 4
Training loss: 1.4042661024178578
Validation loss: 2.492366358869348

Epoch: 5| Step: 5
Training loss: 1.7344563095691046
Validation loss: 2.458991143295183

Epoch: 5| Step: 6
Training loss: 1.1018711496373508
Validation loss: 2.4967121561997896

Epoch: 5| Step: 7
Training loss: 1.1269201211046798
Validation loss: 2.439190608786592

Epoch: 5| Step: 8
Training loss: 1.3769192738802216
Validation loss: 2.4519287216897863

Epoch: 5| Step: 9
Training loss: 1.1434273978780374
Validation loss: 2.4783144284258363

Epoch: 5| Step: 10
Training loss: 0.9233460408471308
Validation loss: 2.4911777619884967

Epoch: 632| Step: 0
Training loss: 0.8540124909115051
Validation loss: 2.4491990130113797

Epoch: 5| Step: 1
Training loss: 1.7147495530658055
Validation loss: 2.4921838646745624

Epoch: 5| Step: 2
Training loss: 1.7448881967136924
Validation loss: 2.4959090385628735

Epoch: 5| Step: 3
Training loss: 1.3188874719930477
Validation loss: 2.5008863969628288

Epoch: 5| Step: 4
Training loss: 1.1065533712334266
Validation loss: 2.4585532497972613

Epoch: 5| Step: 5
Training loss: 1.3604187739980518
Validation loss: 2.4924738799120916

Epoch: 5| Step: 6
Training loss: 1.0037225339939282
Validation loss: 2.4678809018717835

Epoch: 5| Step: 7
Training loss: 1.4739516654610756
Validation loss: 2.4881704124846977

Epoch: 5| Step: 8
Training loss: 1.2237922826364978
Validation loss: 2.4413729122387817

Epoch: 5| Step: 9
Training loss: 1.3357498751052492
Validation loss: 2.5167733202509734

Epoch: 5| Step: 10
Training loss: 1.1130220881187114
Validation loss: 2.4398765368924873

Epoch: 633| Step: 0
Training loss: 1.279775375683964
Validation loss: 2.4515585348888203

Epoch: 5| Step: 1
Training loss: 1.4599882907920454
Validation loss: 2.5214040875028925

Epoch: 5| Step: 2
Training loss: 0.8420807255876479
Validation loss: 2.45316220248702

Epoch: 5| Step: 3
Training loss: 1.6850148020923328
Validation loss: 2.482028482747463

Epoch: 5| Step: 4
Training loss: 1.1164891654657818
Validation loss: 2.499650132913834

Epoch: 5| Step: 5
Training loss: 0.9378865716569371
Validation loss: 2.467214668468953

Epoch: 5| Step: 6
Training loss: 1.367586088661296
Validation loss: 2.5468491588745907

Epoch: 5| Step: 7
Training loss: 1.4441224843857419
Validation loss: 2.4536706732817604

Epoch: 5| Step: 8
Training loss: 1.022648747637385
Validation loss: 2.515071567769768

Epoch: 5| Step: 9
Training loss: 1.4364438530863146
Validation loss: 2.4412704231789855

Epoch: 5| Step: 10
Training loss: 1.566357162353319
Validation loss: 2.536466494183234

Epoch: 634| Step: 0
Training loss: 1.2541958958629968
Validation loss: 2.498387074840419

Epoch: 5| Step: 1
Training loss: 1.3020389651050834
Validation loss: 2.4975698852829122

Epoch: 5| Step: 2
Training loss: 1.7938344689660697
Validation loss: 2.509989420298954

Epoch: 5| Step: 3
Training loss: 0.9950627095862169
Validation loss: 2.5298525529053997

Epoch: 5| Step: 4
Training loss: 1.570713276748467
Validation loss: 2.5299756787131535

Epoch: 5| Step: 5
Training loss: 1.2412165559871116
Validation loss: 2.5238393163130475

Epoch: 5| Step: 6
Training loss: 1.393003337300199
Validation loss: 2.435578075774558

Epoch: 5| Step: 7
Training loss: 1.1241658084961312
Validation loss: 2.4764723565493663

Epoch: 5| Step: 8
Training loss: 0.991031965061635
Validation loss: 2.5459418352254906

Epoch: 5| Step: 9
Training loss: 1.1484627234355373
Validation loss: 2.421031240461118

Epoch: 5| Step: 10
Training loss: 1.4166833184703465
Validation loss: 2.391215852517915

Epoch: 635| Step: 0
Training loss: 1.117139215026134
Validation loss: 2.52249647204426

Epoch: 5| Step: 1
Training loss: 1.4130825630574775
Validation loss: 2.4918524105737903

Epoch: 5| Step: 2
Training loss: 1.226998027087975
Validation loss: 2.4845466835642576

Epoch: 5| Step: 3
Training loss: 1.2732795664202365
Validation loss: 2.5453804221332668

Epoch: 5| Step: 4
Training loss: 1.411551675372859
Validation loss: 2.4812469757649334

Epoch: 5| Step: 5
Training loss: 1.5061267659913609
Validation loss: 2.4910429684220903

Epoch: 5| Step: 6
Training loss: 1.4890881050846487
Validation loss: 2.545150810379829

Epoch: 5| Step: 7
Training loss: 1.6063529222814772
Validation loss: 2.440331179207446

Epoch: 5| Step: 8
Training loss: 1.3608123371367877
Validation loss: 2.5691365107832667

Epoch: 5| Step: 9
Training loss: 0.7866346948869727
Validation loss: 2.4957308033787826

Epoch: 5| Step: 10
Training loss: 1.363553301492258
Validation loss: 2.4687430268876236

Epoch: 636| Step: 0
Training loss: 1.3805272243790003
Validation loss: 2.5184568387980697

Epoch: 5| Step: 1
Training loss: 1.275515773644257
Validation loss: 2.484173392021694

Epoch: 5| Step: 2
Training loss: 2.012765082677473
Validation loss: 2.4826442989702797

Epoch: 5| Step: 3
Training loss: 1.1660472156328332
Validation loss: 2.5188327200958875

Epoch: 5| Step: 4
Training loss: 1.0909049497330698
Validation loss: 2.5009524530703944

Epoch: 5| Step: 5
Training loss: 1.3428517821604973
Validation loss: 2.4481519604778113

Epoch: 5| Step: 6
Training loss: 1.400331376230939
Validation loss: 2.451310185029626

Epoch: 5| Step: 7
Training loss: 1.2294571366286788
Validation loss: 2.5522904108418873

Epoch: 5| Step: 8
Training loss: 0.8755583344158325
Validation loss: 2.493383866673178

Epoch: 5| Step: 9
Training loss: 1.159494487435157
Validation loss: 2.546579691741717

Epoch: 5| Step: 10
Training loss: 1.2012119689700784
Validation loss: 2.47296261363272

Epoch: 637| Step: 0
Training loss: 1.2719653460682452
Validation loss: 2.551569832294311

Epoch: 5| Step: 1
Training loss: 1.3010574826495038
Validation loss: 2.539957952496139

Epoch: 5| Step: 2
Training loss: 1.1372677765113315
Validation loss: 2.5262965576205887

Epoch: 5| Step: 3
Training loss: 1.0552751952387383
Validation loss: 2.5302537451171343

Epoch: 5| Step: 4
Training loss: 1.8175560378260192
Validation loss: 2.5284393010930306

Epoch: 5| Step: 5
Training loss: 0.9462039621862434
Validation loss: 2.5105319768720475

Epoch: 5| Step: 6
Training loss: 1.6814178780050049
Validation loss: 2.5493043704723695

Epoch: 5| Step: 7
Training loss: 1.123041461433963
Validation loss: 2.549796838124969

Epoch: 5| Step: 8
Training loss: 1.4575220667115718
Validation loss: 2.4919632324631524

Epoch: 5| Step: 9
Training loss: 1.2973643838793771
Validation loss: 2.4029028393259586

Epoch: 5| Step: 10
Training loss: 0.7750752766259533
Validation loss: 2.439839063528418

Epoch: 638| Step: 0
Training loss: 1.269298731711612
Validation loss: 2.442151462416925

Epoch: 5| Step: 1
Training loss: 1.6650566748976858
Validation loss: 2.5140656662704113

Epoch: 5| Step: 2
Training loss: 1.2417245638019903
Validation loss: 2.4725708294765485

Epoch: 5| Step: 3
Training loss: 1.0579017545158158
Validation loss: 2.419173677559692

Epoch: 5| Step: 4
Training loss: 1.183379402517525
Validation loss: 2.438558308251891

Epoch: 5| Step: 5
Training loss: 1.4802849889561984
Validation loss: 2.425209536441829

Epoch: 5| Step: 6
Training loss: 1.3003547587881559
Validation loss: 2.5031384784890243

Epoch: 5| Step: 7
Training loss: 1.3969821282938666
Validation loss: 2.495513526594779

Epoch: 5| Step: 8
Training loss: 1.2605489025684808
Validation loss: 2.532798762204286

Epoch: 5| Step: 9
Training loss: 1.2428375078946012
Validation loss: 2.469909159073583

Epoch: 5| Step: 10
Training loss: 1.5149194707335494
Validation loss: 2.490899202191271

Epoch: 639| Step: 0
Training loss: 1.5639319152890865
Validation loss: 2.460247299670768

Epoch: 5| Step: 1
Training loss: 0.927439496208185
Validation loss: 2.4766045147537135

Epoch: 5| Step: 2
Training loss: 1.3013613212232238
Validation loss: 2.5444184759413515

Epoch: 5| Step: 3
Training loss: 1.363526155613315
Validation loss: 2.568165243975069

Epoch: 5| Step: 4
Training loss: 0.8304580357632879
Validation loss: 2.461642071842982

Epoch: 5| Step: 5
Training loss: 1.4489165039752785
Validation loss: 2.4866315330159634

Epoch: 5| Step: 6
Training loss: 1.0564324531752838
Validation loss: 2.587179881541304

Epoch: 5| Step: 7
Training loss: 1.0044867473694559
Validation loss: 2.487946035295005

Epoch: 5| Step: 8
Training loss: 1.4623597917431954
Validation loss: 2.462336146253001

Epoch: 5| Step: 9
Training loss: 1.2132739752792714
Validation loss: 2.477059354300103

Epoch: 5| Step: 10
Training loss: 1.9727592819047717
Validation loss: 2.5149028385838155

Epoch: 640| Step: 0
Training loss: 0.7752843442860733
Validation loss: 2.454421548888009

Epoch: 5| Step: 1
Training loss: 0.9628266473837022
Validation loss: 2.4588716705557174

Epoch: 5| Step: 2
Training loss: 1.2149576704084795
Validation loss: 2.4841789405065655

Epoch: 5| Step: 3
Training loss: 1.3755493367179006
Validation loss: 2.504082490451753

Epoch: 5| Step: 4
Training loss: 0.9586498663782663
Validation loss: 2.483499823899223

Epoch: 5| Step: 5
Training loss: 1.1909452453217282
Validation loss: 2.474558803221828

Epoch: 5| Step: 6
Training loss: 1.1546102701874512
Validation loss: 2.4270022154833417

Epoch: 5| Step: 7
Training loss: 1.8330134705185386
Validation loss: 2.598400339084046

Epoch: 5| Step: 8
Training loss: 1.4008123169925546
Validation loss: 2.4815445064320523

Epoch: 5| Step: 9
Training loss: 1.5879425002817482
Validation loss: 2.536760588158985

Epoch: 5| Step: 10
Training loss: 1.4644602362540733
Validation loss: 2.533163870641579

Epoch: 641| Step: 0
Training loss: 1.008416342405473
Validation loss: 2.4680690509030625

Epoch: 5| Step: 1
Training loss: 1.4510474992439963
Validation loss: 2.480555359395221

Epoch: 5| Step: 2
Training loss: 1.3645680210720115
Validation loss: 2.5320211674231947

Epoch: 5| Step: 3
Training loss: 0.7469891672383038
Validation loss: 2.579366910494242

Epoch: 5| Step: 4
Training loss: 1.0799665341667046
Validation loss: 2.511278937673426

Epoch: 5| Step: 5
Training loss: 1.6397538551672592
Validation loss: 2.532731619565668

Epoch: 5| Step: 6
Training loss: 1.0413697518937746
Validation loss: 2.547636486859981

Epoch: 5| Step: 7
Training loss: 0.9600432351926544
Validation loss: 2.498430854819155

Epoch: 5| Step: 8
Training loss: 1.2629349931733667
Validation loss: 2.519353167774769

Epoch: 5| Step: 9
Training loss: 1.931656053440976
Validation loss: 2.413680251858774

Epoch: 5| Step: 10
Training loss: 1.524705486312706
Validation loss: 2.489858392702598

Epoch: 642| Step: 0
Training loss: 1.4660229628613322
Validation loss: 2.444402160477694

Epoch: 5| Step: 1
Training loss: 1.6341755119809285
Validation loss: 2.480778186330975

Epoch: 5| Step: 2
Training loss: 1.6452972730201876
Validation loss: 2.5133622656060775

Epoch: 5| Step: 3
Training loss: 1.441661532986418
Validation loss: 2.5250047544472984

Epoch: 5| Step: 4
Training loss: 1.013642415406908
Validation loss: 2.4677242906865744

Epoch: 5| Step: 5
Training loss: 1.1637105729812964
Validation loss: 2.472628668993323

Epoch: 5| Step: 6
Training loss: 1.2971000016601035
Validation loss: 2.4158517034816605

Epoch: 5| Step: 7
Training loss: 1.2893800748872204
Validation loss: 2.502856080312024

Epoch: 5| Step: 8
Training loss: 1.237111884241959
Validation loss: 2.4728504747376236

Epoch: 5| Step: 9
Training loss: 0.9253455959844146
Validation loss: 2.4912785199952694

Epoch: 5| Step: 10
Training loss: 1.2211378132295003
Validation loss: 2.533228226906216

Epoch: 643| Step: 0
Training loss: 1.2759718687729376
Validation loss: 2.536525371597404

Epoch: 5| Step: 1
Training loss: 1.030920033695749
Validation loss: 2.4574297882977167

Epoch: 5| Step: 2
Training loss: 0.9481628887675455
Validation loss: 2.5095744973195577

Epoch: 5| Step: 3
Training loss: 1.0696682626976437
Validation loss: 2.498515562066889

Epoch: 5| Step: 4
Training loss: 1.0424467916654905
Validation loss: 2.5587354670728657

Epoch: 5| Step: 5
Training loss: 1.3364054880772254
Validation loss: 2.4781304080305504

Epoch: 5| Step: 6
Training loss: 1.780000080794429
Validation loss: 2.4933092255405986

Epoch: 5| Step: 7
Training loss: 1.5910197789217349
Validation loss: 2.4955220839877374

Epoch: 5| Step: 8
Training loss: 1.2270670539453965
Validation loss: 2.476727087182377

Epoch: 5| Step: 9
Training loss: 1.4020681721442452
Validation loss: 2.511303959618071

Epoch: 5| Step: 10
Training loss: 1.457637466438855
Validation loss: 2.4372556820058837

Epoch: 644| Step: 0
Training loss: 1.2168124520910537
Validation loss: 2.468179033660833

Epoch: 5| Step: 1
Training loss: 1.1998656575184674
Validation loss: 2.5428953309349405

Epoch: 5| Step: 2
Training loss: 1.0522633703809359
Validation loss: 2.5076830885540846

Epoch: 5| Step: 3
Training loss: 1.142729920305366
Validation loss: 2.4708947506831573

Epoch: 5| Step: 4
Training loss: 1.1020716038580307
Validation loss: 2.5124818414611387

Epoch: 5| Step: 5
Training loss: 1.8266823447847107
Validation loss: 2.5025903469355164

Epoch: 5| Step: 6
Training loss: 1.5449673999198772
Validation loss: 2.536396321403677

Epoch: 5| Step: 7
Training loss: 1.1003234604449688
Validation loss: 2.5070483063350846

Epoch: 5| Step: 8
Training loss: 0.9872926132112823
Validation loss: 2.4488249222008065

Epoch: 5| Step: 9
Training loss: 1.4689319579049078
Validation loss: 2.4392493612058277

Epoch: 5| Step: 10
Training loss: 1.1093088586996693
Validation loss: 2.428538094594527

Epoch: 645| Step: 0
Training loss: 1.1560505875471097
Validation loss: 2.484995469309779

Epoch: 5| Step: 1
Training loss: 1.0364986137090118
Validation loss: 2.4397514059292513

Epoch: 5| Step: 2
Training loss: 1.9593584002167337
Validation loss: 2.4641425494277605

Epoch: 5| Step: 3
Training loss: 1.1950697309507579
Validation loss: 2.5072102981847872

Epoch: 5| Step: 4
Training loss: 1.3061294810353044
Validation loss: 2.5374615555457605

Epoch: 5| Step: 5
Training loss: 1.3206442692619569
Validation loss: 2.4829951446743306

Epoch: 5| Step: 6
Training loss: 0.9052454543906903
Validation loss: 2.441614794940491

Epoch: 5| Step: 7
Training loss: 1.1726434858162436
Validation loss: 2.5065779705343836

Epoch: 5| Step: 8
Training loss: 1.588483598825557
Validation loss: 2.512738073909038

Epoch: 5| Step: 9
Training loss: 1.228088887001601
Validation loss: 2.50734388110462

Epoch: 5| Step: 10
Training loss: 1.2246446619623241
Validation loss: 2.5027785375819436

Epoch: 646| Step: 0
Training loss: 0.9654356959188979
Validation loss: 2.517918284284206

Epoch: 5| Step: 1
Training loss: 1.0790814013776975
Validation loss: 2.5193847328746335

Epoch: 5| Step: 2
Training loss: 1.1598892675361543
Validation loss: 2.4536609992877336

Epoch: 5| Step: 3
Training loss: 1.6507388859163397
Validation loss: 2.5245786780166597

Epoch: 5| Step: 4
Training loss: 1.0799976063631165
Validation loss: 2.556984959078296

Epoch: 5| Step: 5
Training loss: 1.5145540681483936
Validation loss: 2.5179680228861865

Epoch: 5| Step: 6
Training loss: 1.14329847793351
Validation loss: 2.4653999815578698

Epoch: 5| Step: 7
Training loss: 1.2203011056756377
Validation loss: 2.4146072702763424

Epoch: 5| Step: 8
Training loss: 0.7932547443463216
Validation loss: 2.5003980442772935

Epoch: 5| Step: 9
Training loss: 1.3718644717427286
Validation loss: 2.4460407687398686

Epoch: 5| Step: 10
Training loss: 2.0553979841901873
Validation loss: 2.5096143147436205

Epoch: 647| Step: 0
Training loss: 1.135165067088467
Validation loss: 2.528950244943441

Epoch: 5| Step: 1
Training loss: 1.3904843205648507
Validation loss: 2.4957210674596264

Epoch: 5| Step: 2
Training loss: 1.2434276412262413
Validation loss: 2.540739481062259

Epoch: 5| Step: 3
Training loss: 1.0466962633281442
Validation loss: 2.4987256093681474

Epoch: 5| Step: 4
Training loss: 1.359863982551435
Validation loss: 2.469960275474812

Epoch: 5| Step: 5
Training loss: 1.0686271931546212
Validation loss: 2.4489503275627706

Epoch: 5| Step: 6
Training loss: 1.8040210104181917
Validation loss: 2.4859055597419255

Epoch: 5| Step: 7
Training loss: 1.3724762991298898
Validation loss: 2.561093894774224

Epoch: 5| Step: 8
Training loss: 1.0520989759937847
Validation loss: 2.4814932572540767

Epoch: 5| Step: 9
Training loss: 1.369702364061745
Validation loss: 2.497036529018217

Epoch: 5| Step: 10
Training loss: 1.0006414978459086
Validation loss: 2.485670529343164

Epoch: 648| Step: 0
Training loss: 1.330233258178407
Validation loss: 2.485016999710516

Epoch: 5| Step: 1
Training loss: 1.1117339507810922
Validation loss: 2.45673443366501

Epoch: 5| Step: 2
Training loss: 1.1378577644377919
Validation loss: 2.556042091837828

Epoch: 5| Step: 3
Training loss: 1.4414831621693078
Validation loss: 2.5264330177785905

Epoch: 5| Step: 4
Training loss: 1.13902703793848
Validation loss: 2.4020536514191697

Epoch: 5| Step: 5
Training loss: 1.9609852819206532
Validation loss: 2.4831384692888836

Epoch: 5| Step: 6
Training loss: 1.2107543806854968
Validation loss: 2.544331952730839

Epoch: 5| Step: 7
Training loss: 1.1530236776026612
Validation loss: 2.4873560328651285

Epoch: 5| Step: 8
Training loss: 1.0919527819419312
Validation loss: 2.4620047014996147

Epoch: 5| Step: 9
Training loss: 1.2505093967095369
Validation loss: 2.453291569197577

Epoch: 5| Step: 10
Training loss: 1.0209704067040124
Validation loss: 2.563855331760292

Epoch: 649| Step: 0
Training loss: 1.219658586304504
Validation loss: 2.515704773881501

Epoch: 5| Step: 1
Training loss: 1.5574690123486468
Validation loss: 2.507529827690498

Epoch: 5| Step: 2
Training loss: 1.3357375145852883
Validation loss: 2.518430034231314

Epoch: 5| Step: 3
Training loss: 0.9712316045406
Validation loss: 2.4719405185627705

Epoch: 5| Step: 4
Training loss: 0.8861549366271562
Validation loss: 2.4895954125780184

Epoch: 5| Step: 5
Training loss: 1.064784007310173
Validation loss: 2.530715173885488

Epoch: 5| Step: 6
Training loss: 1.7611032159202464
Validation loss: 2.4949254401211114

Epoch: 5| Step: 7
Training loss: 1.6533981818638024
Validation loss: 2.56812946487248

Epoch: 5| Step: 8
Training loss: 1.1526813077329572
Validation loss: 2.503033879816792

Epoch: 5| Step: 9
Training loss: 1.1147862484383886
Validation loss: 2.431574347565908

Epoch: 5| Step: 10
Training loss: 1.1506445301725372
Validation loss: 2.4524508066394874

Epoch: 650| Step: 0
Training loss: 0.8397840966618713
Validation loss: 2.536078208013204

Epoch: 5| Step: 1
Training loss: 1.7503843566605222
Validation loss: 2.4842184508507024

Epoch: 5| Step: 2
Training loss: 1.4478668734910198
Validation loss: 2.514765667124694

Epoch: 5| Step: 3
Training loss: 1.2917583135681001
Validation loss: 2.474180204657091

Epoch: 5| Step: 4
Training loss: 1.7595243129757772
Validation loss: 2.4754585219246343

Epoch: 5| Step: 5
Training loss: 1.00053308106445
Validation loss: 2.524849810906028

Epoch: 5| Step: 6
Training loss: 1.0309814334607326
Validation loss: 2.4493822052165006

Epoch: 5| Step: 7
Training loss: 1.0188370603092503
Validation loss: 2.424410548287206

Epoch: 5| Step: 8
Training loss: 1.5048567505398598
Validation loss: 2.5377803713671154

Epoch: 5| Step: 9
Training loss: 1.097204746772464
Validation loss: 2.5543929489025694

Epoch: 5| Step: 10
Training loss: 1.1568546260809998
Validation loss: 2.4777779567926967

Epoch: 651| Step: 0
Training loss: 1.361843892582958
Validation loss: 2.468385519191847

Epoch: 5| Step: 1
Training loss: 1.6316380269489057
Validation loss: 2.5478684293247245

Epoch: 5| Step: 2
Training loss: 1.2396345956070747
Validation loss: 2.525120855797945

Epoch: 5| Step: 3
Training loss: 1.5431812767745956
Validation loss: 2.572269579691974

Epoch: 5| Step: 4
Training loss: 0.8994230752466454
Validation loss: 2.524942910925668

Epoch: 5| Step: 5
Training loss: 1.025148083294255
Validation loss: 2.5399736080731574

Epoch: 5| Step: 6
Training loss: 1.2287351960913497
Validation loss: 2.514652402520053

Epoch: 5| Step: 7
Training loss: 1.292835516850369
Validation loss: 2.5294206689137897

Epoch: 5| Step: 8
Training loss: 1.2455801069607868
Validation loss: 2.53151093149228

Epoch: 5| Step: 9
Training loss: 1.1142918868208316
Validation loss: 2.528777613130868

Epoch: 5| Step: 10
Training loss: 1.1816514700399792
Validation loss: 2.4695228051414686

Epoch: 652| Step: 0
Training loss: 1.0804848758710526
Validation loss: 2.511222296159408

Epoch: 5| Step: 1
Training loss: 1.2275357606732642
Validation loss: 2.465334522272695

Epoch: 5| Step: 2
Training loss: 1.051779857464679
Validation loss: 2.4845549939442892

Epoch: 5| Step: 3
Training loss: 0.9346062823700975
Validation loss: 2.514002172662416

Epoch: 5| Step: 4
Training loss: 1.4095071159743393
Validation loss: 2.451775016293018

Epoch: 5| Step: 5
Training loss: 1.0502979627815952
Validation loss: 2.4243582187618253

Epoch: 5| Step: 6
Training loss: 1.3914970492552032
Validation loss: 2.589737250326998

Epoch: 5| Step: 7
Training loss: 0.9778980735329953
Validation loss: 2.5408683369008074

Epoch: 5| Step: 8
Training loss: 1.811733938978448
Validation loss: 2.4991696588760606

Epoch: 5| Step: 9
Training loss: 1.1872270672001681
Validation loss: 2.4734955475380516

Epoch: 5| Step: 10
Training loss: 1.3856651064273828
Validation loss: 2.517057467148638

Epoch: 653| Step: 0
Training loss: 1.4745953085525285
Validation loss: 2.511004332220742

Epoch: 5| Step: 1
Training loss: 1.0291946041830082
Validation loss: 2.509994274889997

Epoch: 5| Step: 2
Training loss: 1.201351840796116
Validation loss: 2.5560951986946807

Epoch: 5| Step: 3
Training loss: 1.686184193519708
Validation loss: 2.559559539372741

Epoch: 5| Step: 4
Training loss: 1.1037626546996169
Validation loss: 2.5144842791117346

Epoch: 5| Step: 5
Training loss: 1.1403047817614036
Validation loss: 2.4950110709178834

Epoch: 5| Step: 6
Training loss: 1.109094557439912
Validation loss: 2.4824190639412387

Epoch: 5| Step: 7
Training loss: 1.1759086869334257
Validation loss: 2.565381962361045

Epoch: 5| Step: 8
Training loss: 1.2739704631603292
Validation loss: 2.535186382623845

Epoch: 5| Step: 9
Training loss: 1.3977731160091365
Validation loss: 2.563810781104161

Epoch: 5| Step: 10
Training loss: 1.3483166831693483
Validation loss: 2.5018558781569014

Epoch: 654| Step: 0
Training loss: 1.055132171704102
Validation loss: 2.4877470111398896

Epoch: 5| Step: 1
Training loss: 1.4565194793351928
Validation loss: 2.520704187962971

Epoch: 5| Step: 2
Training loss: 1.0539183461122175
Validation loss: 2.5231741536641823

Epoch: 5| Step: 3
Training loss: 1.304436391090374
Validation loss: 2.481188675367037

Epoch: 5| Step: 4
Training loss: 1.766820587194751
Validation loss: 2.5098698450705137

Epoch: 5| Step: 5
Training loss: 1.3477267481843664
Validation loss: 2.5124730204174064

Epoch: 5| Step: 6
Training loss: 1.5185597116074445
Validation loss: 2.5166924118434326

Epoch: 5| Step: 7
Training loss: 0.9244129354186756
Validation loss: 2.4762381556088413

Epoch: 5| Step: 8
Training loss: 0.9858103082170925
Validation loss: 2.4941098381881184

Epoch: 5| Step: 9
Training loss: 0.8417902899747879
Validation loss: 2.514619648162596

Epoch: 5| Step: 10
Training loss: 1.0922151422890973
Validation loss: 2.510843860414145

Epoch: 655| Step: 0
Training loss: 1.249194314704561
Validation loss: 2.5178253083794706

Epoch: 5| Step: 1
Training loss: 0.88444553673566
Validation loss: 2.5023211296864076

Epoch: 5| Step: 2
Training loss: 1.235041088548159
Validation loss: 2.5879460699356986

Epoch: 5| Step: 3
Training loss: 1.251221250952624
Validation loss: 2.5641678735344797

Epoch: 5| Step: 4
Training loss: 1.0869335299630996
Validation loss: 2.6076413111310446

Epoch: 5| Step: 5
Training loss: 1.201137238289992
Validation loss: 2.550495799268988

Epoch: 5| Step: 6
Training loss: 1.4220868466357424
Validation loss: 2.562908399178341

Epoch: 5| Step: 7
Training loss: 1.0735294974493812
Validation loss: 2.496363411363824

Epoch: 5| Step: 8
Training loss: 1.3233285798308534
Validation loss: 2.4445275137680933

Epoch: 5| Step: 9
Training loss: 1.8975012711632533
Validation loss: 2.522910936325932

Epoch: 5| Step: 10
Training loss: 1.1130499348505003
Validation loss: 2.4811576110876588

Epoch: 656| Step: 0
Training loss: 1.0593245682766872
Validation loss: 2.492840088725893

Epoch: 5| Step: 1
Training loss: 1.2025163770738165
Validation loss: 2.4490903865970357

Epoch: 5| Step: 2
Training loss: 1.2693611852738407
Validation loss: 2.497179395242179

Epoch: 5| Step: 3
Training loss: 1.371983513852599
Validation loss: 2.483680668832366

Epoch: 5| Step: 4
Training loss: 1.2735292366544906
Validation loss: 2.483247337605928

Epoch: 5| Step: 5
Training loss: 1.8012886573725364
Validation loss: 2.485910572741923

Epoch: 5| Step: 6
Training loss: 1.141715273321279
Validation loss: 2.4677346466238843

Epoch: 5| Step: 7
Training loss: 1.4841523656025788
Validation loss: 2.5699721122602166

Epoch: 5| Step: 8
Training loss: 1.2407249621805607
Validation loss: 2.4844475419091365

Epoch: 5| Step: 9
Training loss: 1.2180623780111075
Validation loss: 2.536321685142973

Epoch: 5| Step: 10
Training loss: 1.1147454521187379
Validation loss: 2.4755290178182063

Epoch: 657| Step: 0
Training loss: 1.0331007216243793
Validation loss: 2.4798777827044174

Epoch: 5| Step: 1
Training loss: 1.0324770245524293
Validation loss: 2.5385694657725777

Epoch: 5| Step: 2
Training loss: 1.5874347102638855
Validation loss: 2.587906788059436

Epoch: 5| Step: 3
Training loss: 1.1060623893489847
Validation loss: 2.6199837046290804

Epoch: 5| Step: 4
Training loss: 1.5633872755432956
Validation loss: 2.5614394047237856

Epoch: 5| Step: 5
Training loss: 1.7309106129178071
Validation loss: 2.530939514328634

Epoch: 5| Step: 6
Training loss: 1.072984187152738
Validation loss: 2.523037453742549

Epoch: 5| Step: 7
Training loss: 0.8293445891473052
Validation loss: 2.5226861745833924

Epoch: 5| Step: 8
Training loss: 1.2622317284062279
Validation loss: 2.5031331333373767

Epoch: 5| Step: 9
Training loss: 1.122089754339564
Validation loss: 2.5124688318137895

Epoch: 5| Step: 10
Training loss: 1.3908718618667977
Validation loss: 2.5254419228607015

Epoch: 658| Step: 0
Training loss: 1.0297323677348238
Validation loss: 2.4548644652452047

Epoch: 5| Step: 1
Training loss: 0.8530371610254518
Validation loss: 2.5625323822032335

Epoch: 5| Step: 2
Training loss: 1.192037246455007
Validation loss: 2.5219250820644055

Epoch: 5| Step: 3
Training loss: 1.6997258273791946
Validation loss: 2.4845252945777556

Epoch: 5| Step: 4
Training loss: 1.4430201316322724
Validation loss: 2.479764116834275

Epoch: 5| Step: 5
Training loss: 1.0461719486560443
Validation loss: 2.5246453815038015

Epoch: 5| Step: 6
Training loss: 0.7932999393770384
Validation loss: 2.4683031025798488

Epoch: 5| Step: 7
Training loss: 0.9325989406857823
Validation loss: 2.4579449244764455

Epoch: 5| Step: 8
Training loss: 1.4662846103755804
Validation loss: 2.444203223945517

Epoch: 5| Step: 9
Training loss: 1.369510573444865
Validation loss: 2.4332639003573444

Epoch: 5| Step: 10
Training loss: 1.4601797494890385
Validation loss: 2.5445368598497

Epoch: 659| Step: 0
Training loss: 1.2208341238303548
Validation loss: 2.419297269252442

Epoch: 5| Step: 1
Training loss: 1.404968695240906
Validation loss: 2.4873744003487053

Epoch: 5| Step: 2
Training loss: 1.1875024092800395
Validation loss: 2.5629032997167425

Epoch: 5| Step: 3
Training loss: 1.3031934303959956
Validation loss: 2.475784381892212

Epoch: 5| Step: 4
Training loss: 0.9591864161332093
Validation loss: 2.5612344105127565

Epoch: 5| Step: 5
Training loss: 1.302328249467805
Validation loss: 2.516434429912387

Epoch: 5| Step: 6
Training loss: 1.497340865301096
Validation loss: 2.4877426593051477

Epoch: 5| Step: 7
Training loss: 1.589760743019841
Validation loss: 2.4259405615017706

Epoch: 5| Step: 8
Training loss: 1.1849887294474752
Validation loss: 2.490166974186034

Epoch: 5| Step: 9
Training loss: 0.9572887463502613
Validation loss: 2.478915398193093

Epoch: 5| Step: 10
Training loss: 1.3305792179715763
Validation loss: 2.5222899055121273

Epoch: 660| Step: 0
Training loss: 1.22382389168931
Validation loss: 2.4976207209270838

Epoch: 5| Step: 1
Training loss: 1.142831888302991
Validation loss: 2.476010904851806

Epoch: 5| Step: 2
Training loss: 1.227424755859102
Validation loss: 2.517110180444666

Epoch: 5| Step: 3
Training loss: 1.944502451197952
Validation loss: 2.5137024303828994

Epoch: 5| Step: 4
Training loss: 1.3786252089301476
Validation loss: 2.4680841663570954

Epoch: 5| Step: 5
Training loss: 1.1630473991306252
Validation loss: 2.4674706467766

Epoch: 5| Step: 6
Training loss: 0.8672861266541483
Validation loss: 2.544351659078246

Epoch: 5| Step: 7
Training loss: 0.9421785597748713
Validation loss: 2.48559137782109

Epoch: 5| Step: 8
Training loss: 1.6462119749365696
Validation loss: 2.4941652422527727

Epoch: 5| Step: 9
Training loss: 0.9383734131333783
Validation loss: 2.535184339951083

Epoch: 5| Step: 10
Training loss: 1.2320218411838042
Validation loss: 2.5465057979157963

Epoch: 661| Step: 0
Training loss: 1.1155784062932415
Validation loss: 2.4459781977044788

Epoch: 5| Step: 1
Training loss: 1.6051169796676372
Validation loss: 2.481112889827919

Epoch: 5| Step: 2
Training loss: 1.1597933731537073
Validation loss: 2.5193282369682644

Epoch: 5| Step: 3
Training loss: 1.028974276229473
Validation loss: 2.498377252816984

Epoch: 5| Step: 4
Training loss: 1.4201202463896967
Validation loss: 2.4578763247785034

Epoch: 5| Step: 5
Training loss: 1.067200082283074
Validation loss: 2.5044473539459147

Epoch: 5| Step: 6
Training loss: 1.2762796711998676
Validation loss: 2.392553682953727

Epoch: 5| Step: 7
Training loss: 1.6988339043135412
Validation loss: 2.4587620962109304

Epoch: 5| Step: 8
Training loss: 0.9561472956037423
Validation loss: 2.3945245136295443

Epoch: 5| Step: 9
Training loss: 1.3074760560273986
Validation loss: 2.446216453781543

Epoch: 5| Step: 10
Training loss: 0.8214139900038777
Validation loss: 2.5484877859571884

Epoch: 662| Step: 0
Training loss: 1.9646647620155742
Validation loss: 2.535160692354764

Epoch: 5| Step: 1
Training loss: 1.4191634764591603
Validation loss: 2.5220497882500026

Epoch: 5| Step: 2
Training loss: 1.150094737421468
Validation loss: 2.54126661175837

Epoch: 5| Step: 3
Training loss: 1.0997707865060669
Validation loss: 2.5042217529974513

Epoch: 5| Step: 4
Training loss: 1.4034532923331227
Validation loss: 2.553110414169812

Epoch: 5| Step: 5
Training loss: 1.3355595461168157
Validation loss: 2.421220117813252

Epoch: 5| Step: 6
Training loss: 0.8612059422201601
Validation loss: 2.5382568504852943

Epoch: 5| Step: 7
Training loss: 0.8579092877925848
Validation loss: 2.4197277202520016

Epoch: 5| Step: 8
Training loss: 1.2295475008810812
Validation loss: 2.490849440764122

Epoch: 5| Step: 9
Training loss: 1.287851307910673
Validation loss: 2.4788326852971196

Epoch: 5| Step: 10
Training loss: 1.05716391983369
Validation loss: 2.490676570512877

Epoch: 663| Step: 0
Training loss: 1.1078570551985092
Validation loss: 2.5163736629961555

Epoch: 5| Step: 1
Training loss: 1.0836974167964344
Validation loss: 2.5046407265370427

Epoch: 5| Step: 2
Training loss: 1.2483397902732132
Validation loss: 2.505565660209821

Epoch: 5| Step: 3
Training loss: 1.4249065067339468
Validation loss: 2.483262090190299

Epoch: 5| Step: 4
Training loss: 1.1759148708723852
Validation loss: 2.507973918103454

Epoch: 5| Step: 5
Training loss: 1.4902414144247238
Validation loss: 2.503194270580465

Epoch: 5| Step: 6
Training loss: 1.0828120310068148
Validation loss: 2.516429751256578

Epoch: 5| Step: 7
Training loss: 0.9620183433124172
Validation loss: 2.4335360251154157

Epoch: 5| Step: 8
Training loss: 1.0434673703314696
Validation loss: 2.4798601686323045

Epoch: 5| Step: 9
Training loss: 1.3377927424133185
Validation loss: 2.425140363307629

Epoch: 5| Step: 10
Training loss: 1.9456844969958453
Validation loss: 2.450358991332962

Epoch: 664| Step: 0
Training loss: 1.3992025317983257
Validation loss: 2.505851064682342

Epoch: 5| Step: 1
Training loss: 1.002302261409665
Validation loss: 2.4900298896943047

Epoch: 5| Step: 2
Training loss: 1.22944821619209
Validation loss: 2.522618804452407

Epoch: 5| Step: 3
Training loss: 1.5384794573473939
Validation loss: 2.4523004593931215

Epoch: 5| Step: 4
Training loss: 0.8475293183108319
Validation loss: 2.5964669266379814

Epoch: 5| Step: 5
Training loss: 1.0935418612120917
Validation loss: 2.5870180008127277

Epoch: 5| Step: 6
Training loss: 0.8341086158852603
Validation loss: 2.555421139153103

Epoch: 5| Step: 7
Training loss: 1.5531778338098026
Validation loss: 2.50006541812583

Epoch: 5| Step: 8
Training loss: 1.681532161816825
Validation loss: 2.5436451468871213

Epoch: 5| Step: 9
Training loss: 1.1310818310080772
Validation loss: 2.503156650280589

Epoch: 5| Step: 10
Training loss: 1.2009108841363991
Validation loss: 2.4617277101711568

Epoch: 665| Step: 0
Training loss: 0.9905178108347068
Validation loss: 2.493616541588391

Epoch: 5| Step: 1
Training loss: 1.377963730075913
Validation loss: 2.485524896969841

Epoch: 5| Step: 2
Training loss: 1.2108608098510456
Validation loss: 2.5113919545222254

Epoch: 5| Step: 3
Training loss: 1.7784610799413663
Validation loss: 2.465238144740045

Epoch: 5| Step: 4
Training loss: 1.4407241158305746
Validation loss: 2.4214048608745937

Epoch: 5| Step: 5
Training loss: 1.3251152942087197
Validation loss: 2.4715076443265964

Epoch: 5| Step: 6
Training loss: 1.1498503007065894
Validation loss: 2.534503680300324

Epoch: 5| Step: 7
Training loss: 0.9743154690353628
Validation loss: 2.4259232427037785

Epoch: 5| Step: 8
Training loss: 1.1963546797214726
Validation loss: 2.476146422500766

Epoch: 5| Step: 9
Training loss: 1.1653559110805405
Validation loss: 2.5772552474939623

Epoch: 5| Step: 10
Training loss: 1.0059167345599116
Validation loss: 2.492291433706859

Epoch: 666| Step: 0
Training loss: 1.9022590258019851
Validation loss: 2.489612967555524

Epoch: 5| Step: 1
Training loss: 1.2006759488179248
Validation loss: 2.5219577392541037

Epoch: 5| Step: 2
Training loss: 1.1221498837987707
Validation loss: 2.5091086903214714

Epoch: 5| Step: 3
Training loss: 1.070388735541273
Validation loss: 2.491757981591614

Epoch: 5| Step: 4
Training loss: 1.0365978639059932
Validation loss: 2.533186636179028

Epoch: 5| Step: 5
Training loss: 1.2650095067025107
Validation loss: 2.482774112031664

Epoch: 5| Step: 6
Training loss: 1.2891755950329231
Validation loss: 2.4765445637023507

Epoch: 5| Step: 7
Training loss: 1.2106742326595261
Validation loss: 2.507780568430673

Epoch: 5| Step: 8
Training loss: 1.0302088134167937
Validation loss: 2.4602745172285356

Epoch: 5| Step: 9
Training loss: 1.405154882629944
Validation loss: 2.529518213603249

Epoch: 5| Step: 10
Training loss: 1.1654580986251195
Validation loss: 2.4930627575424666

Epoch: 667| Step: 0
Training loss: 1.4881678260174673
Validation loss: 2.4546682189341653

Epoch: 5| Step: 1
Training loss: 1.1311569217726576
Validation loss: 2.397140566467909

Epoch: 5| Step: 2
Training loss: 2.1183814029156776
Validation loss: 2.480296972281062

Epoch: 5| Step: 3
Training loss: 1.569917695627679
Validation loss: 2.494995375703408

Epoch: 5| Step: 4
Training loss: 1.0336295908093498
Validation loss: 2.481325155206758

Epoch: 5| Step: 5
Training loss: 1.355774331070234
Validation loss: 2.452738256767101

Epoch: 5| Step: 6
Training loss: 1.112661409991513
Validation loss: 2.4865588011958972

Epoch: 5| Step: 7
Training loss: 0.9901648502659592
Validation loss: 2.4577746443852218

Epoch: 5| Step: 8
Training loss: 0.9102187564980952
Validation loss: 2.4637975524517794

Epoch: 5| Step: 9
Training loss: 1.0665270279340238
Validation loss: 2.4798889174915772

Epoch: 5| Step: 10
Training loss: 0.8239698350556126
Validation loss: 2.467504801808628

Epoch: 668| Step: 0
Training loss: 0.8442629914779499
Validation loss: 2.475344710605232

Epoch: 5| Step: 1
Training loss: 1.1049497754347097
Validation loss: 2.4733009122030363

Epoch: 5| Step: 2
Training loss: 1.7978576626899496
Validation loss: 2.5224012713903794

Epoch: 5| Step: 3
Training loss: 1.5947370277710806
Validation loss: 2.547642770076786

Epoch: 5| Step: 4
Training loss: 1.6524883234070316
Validation loss: 2.4991014137241985

Epoch: 5| Step: 5
Training loss: 1.1699000692484756
Validation loss: 2.4749562106003733

Epoch: 5| Step: 6
Training loss: 1.2390083560923528
Validation loss: 2.4867120844313417

Epoch: 5| Step: 7
Training loss: 1.0737731009186577
Validation loss: 2.4626869380977903

Epoch: 5| Step: 8
Training loss: 0.9125517399372153
Validation loss: 2.496462004327856

Epoch: 5| Step: 9
Training loss: 0.6970007043202808
Validation loss: 2.522687499752787

Epoch: 5| Step: 10
Training loss: 1.278194599075379
Validation loss: 2.4911993521569245

Epoch: 669| Step: 0
Training loss: 1.3209381426955629
Validation loss: 2.5148746709291205

Epoch: 5| Step: 1
Training loss: 1.0207495882106812
Validation loss: 2.441480075958717

Epoch: 5| Step: 2
Training loss: 1.7726561719912044
Validation loss: 2.4520977276370783

Epoch: 5| Step: 3
Training loss: 1.5578017744270942
Validation loss: 2.4809572373987883

Epoch: 5| Step: 4
Training loss: 1.4950097840923517
Validation loss: 2.492727133738284

Epoch: 5| Step: 5
Training loss: 0.9867978327842174
Validation loss: 2.4998621225791298

Epoch: 5| Step: 6
Training loss: 1.2461219234330996
Validation loss: 2.4829255649317092

Epoch: 5| Step: 7
Training loss: 0.9487637657805322
Validation loss: 2.500288581599577

Epoch: 5| Step: 8
Training loss: 0.9653785860280786
Validation loss: 2.501274835963489

Epoch: 5| Step: 9
Training loss: 1.397770131025707
Validation loss: 2.5677719159923456

Epoch: 5| Step: 10
Training loss: 1.1214157864793777
Validation loss: 2.4827575918727067

Epoch: 670| Step: 0
Training loss: 1.010274673919576
Validation loss: 2.432988482908853

Epoch: 5| Step: 1
Training loss: 1.2767662586097936
Validation loss: 2.495760150607349

Epoch: 5| Step: 2
Training loss: 1.32938863441495
Validation loss: 2.4859832637152457

Epoch: 5| Step: 3
Training loss: 0.8810798724293029
Validation loss: 2.487054839762989

Epoch: 5| Step: 4
Training loss: 1.36153407023624
Validation loss: 2.4948652552336767

Epoch: 5| Step: 5
Training loss: 1.069009753779563
Validation loss: 2.426695927996866

Epoch: 5| Step: 6
Training loss: 1.2416494871824277
Validation loss: 2.50911637170286

Epoch: 5| Step: 7
Training loss: 1.832390072948527
Validation loss: 2.473062249911485

Epoch: 5| Step: 8
Training loss: 1.215644940210288
Validation loss: 2.4388445618399426

Epoch: 5| Step: 9
Training loss: 1.0320426899855628
Validation loss: 2.5318382731147295

Epoch: 5| Step: 10
Training loss: 1.1378008748471402
Validation loss: 2.4352955300874806

Epoch: 671| Step: 0
Training loss: 1.252283204555188
Validation loss: 2.4931053394838094

Epoch: 5| Step: 1
Training loss: 1.1305388686572975
Validation loss: 2.4903134108629663

Epoch: 5| Step: 2
Training loss: 1.3012049446037808
Validation loss: 2.546701843749151

Epoch: 5| Step: 3
Training loss: 1.2974348583296529
Validation loss: 2.4656292391311347

Epoch: 5| Step: 4
Training loss: 1.10262566522834
Validation loss: 2.491961619361576

Epoch: 5| Step: 5
Training loss: 1.0600073690878034
Validation loss: 2.5355588749134563

Epoch: 5| Step: 6
Training loss: 1.4944029334699114
Validation loss: 2.4133126230183493

Epoch: 5| Step: 7
Training loss: 1.5460380833316152
Validation loss: 2.4640227282171985

Epoch: 5| Step: 8
Training loss: 1.0145899266545075
Validation loss: 2.5065153990260405

Epoch: 5| Step: 9
Training loss: 1.0586796686981936
Validation loss: 2.5763859207948037

Epoch: 5| Step: 10
Training loss: 1.1399232456234853
Validation loss: 2.4741412551861357

Epoch: 672| Step: 0
Training loss: 0.9869094495214432
Validation loss: 2.5556341653028123

Epoch: 5| Step: 1
Training loss: 0.8864904437467153
Validation loss: 2.4669145027939225

Epoch: 5| Step: 2
Training loss: 1.3811622729858566
Validation loss: 2.4984144022728647

Epoch: 5| Step: 3
Training loss: 1.3277866605747952
Validation loss: 2.5459115324679527

Epoch: 5| Step: 4
Training loss: 1.7354429239192501
Validation loss: 2.514749955540343

Epoch: 5| Step: 5
Training loss: 1.0717030979586908
Validation loss: 2.462832593738769

Epoch: 5| Step: 6
Training loss: 1.2867386186984662
Validation loss: 2.451897987236489

Epoch: 5| Step: 7
Training loss: 1.3158178627565513
Validation loss: 2.4518315767084045

Epoch: 5| Step: 8
Training loss: 0.7320657092994359
Validation loss: 2.4658976087107782

Epoch: 5| Step: 9
Training loss: 1.2003229382216762
Validation loss: 2.4285006922366943

Epoch: 5| Step: 10
Training loss: 1.3723126506267627
Validation loss: 2.5063490591009328

Epoch: 673| Step: 0
Training loss: 1.1350290645961572
Validation loss: 2.4660074632422586

Epoch: 5| Step: 1
Training loss: 1.2185746580316532
Validation loss: 2.5561308042434763

Epoch: 5| Step: 2
Training loss: 1.1518342524341627
Validation loss: 2.5127293435478215

Epoch: 5| Step: 3
Training loss: 1.6877676433668871
Validation loss: 2.386560836193922

Epoch: 5| Step: 4
Training loss: 0.8228561202040062
Validation loss: 2.502372045020417

Epoch: 5| Step: 5
Training loss: 1.107356585910921
Validation loss: 2.4697898812805104

Epoch: 5| Step: 6
Training loss: 1.8184674125396776
Validation loss: 2.5126326423364564

Epoch: 5| Step: 7
Training loss: 1.223933956904519
Validation loss: 2.4642885185142007

Epoch: 5| Step: 8
Training loss: 1.182797658366084
Validation loss: 2.5369086215308077

Epoch: 5| Step: 9
Training loss: 0.8121665123476784
Validation loss: 2.47775473492978

Epoch: 5| Step: 10
Training loss: 1.1389680611349835
Validation loss: 2.4845031387408696

Epoch: 674| Step: 0
Training loss: 1.2042570856767711
Validation loss: 2.4580932494391243

Epoch: 5| Step: 1
Training loss: 1.0764466089065807
Validation loss: 2.539737583273549

Epoch: 5| Step: 2
Training loss: 1.0022806743895754
Validation loss: 2.4850756487314007

Epoch: 5| Step: 3
Training loss: 1.0577329394398889
Validation loss: 2.554473036045781

Epoch: 5| Step: 4
Training loss: 1.6053951645668654
Validation loss: 2.508537823691696

Epoch: 5| Step: 5
Training loss: 1.1968229636092942
Validation loss: 2.5411027095722143

Epoch: 5| Step: 6
Training loss: 1.4590630567545104
Validation loss: 2.4899196721073817

Epoch: 5| Step: 7
Training loss: 1.391942717913709
Validation loss: 2.5270683094229316

Epoch: 5| Step: 8
Training loss: 1.1554083983140035
Validation loss: 2.4710788503214536

Epoch: 5| Step: 9
Training loss: 0.9815994065811459
Validation loss: 2.49736212132233

Epoch: 5| Step: 10
Training loss: 1.4635162441810516
Validation loss: 2.458158720088526

Epoch: 675| Step: 0
Training loss: 0.955444827213066
Validation loss: 2.469629757921664

Epoch: 5| Step: 1
Training loss: 1.2881587241476562
Validation loss: 2.484683898267539

Epoch: 5| Step: 2
Training loss: 1.1252987253097628
Validation loss: 2.416093993589027

Epoch: 5| Step: 3
Training loss: 1.0652490282607106
Validation loss: 2.4793236995470886

Epoch: 5| Step: 4
Training loss: 1.098522618171598
Validation loss: 2.485255620814522

Epoch: 5| Step: 5
Training loss: 1.183566606166292
Validation loss: 2.496410253712375

Epoch: 5| Step: 6
Training loss: 1.197814865209492
Validation loss: 2.4798039807824894

Epoch: 5| Step: 7
Training loss: 1.3281852259724836
Validation loss: 2.520783074967064

Epoch: 5| Step: 8
Training loss: 1.3432753855856905
Validation loss: 2.451161294817964

Epoch: 5| Step: 9
Training loss: 1.65405913066683
Validation loss: 2.4321409115811643

Epoch: 5| Step: 10
Training loss: 0.9710310875093268
Validation loss: 2.527278475997759

Epoch: 676| Step: 0
Training loss: 1.4648881015421187
Validation loss: 2.4616044304430376

Epoch: 5| Step: 1
Training loss: 1.0758724176786503
Validation loss: 2.4511812398244883

Epoch: 5| Step: 2
Training loss: 1.1837572545088093
Validation loss: 2.4561536120676943

Epoch: 5| Step: 3
Training loss: 1.0470361727866513
Validation loss: 2.505663718940398

Epoch: 5| Step: 4
Training loss: 0.8948753727820076
Validation loss: 2.4867486359932585

Epoch: 5| Step: 5
Training loss: 1.25800596846179
Validation loss: 2.46932067651213

Epoch: 5| Step: 6
Training loss: 1.1957511844840494
Validation loss: 2.4883709131203284

Epoch: 5| Step: 7
Training loss: 1.1030124833860921
Validation loss: 2.5197305900470024

Epoch: 5| Step: 8
Training loss: 1.9217185600312305
Validation loss: 2.4697241470120805

Epoch: 5| Step: 9
Training loss: 1.285043960813816
Validation loss: 2.462307287720566

Epoch: 5| Step: 10
Training loss: 1.0814445364702832
Validation loss: 2.5357498638654428

Epoch: 677| Step: 0
Training loss: 1.005021837291418
Validation loss: 2.4920851595504763

Epoch: 5| Step: 1
Training loss: 1.1570157273492159
Validation loss: 2.4842232618934132

Epoch: 5| Step: 2
Training loss: 1.174953536880295
Validation loss: 2.5381202351539796

Epoch: 5| Step: 3
Training loss: 0.8681823934501401
Validation loss: 2.5323696842756607

Epoch: 5| Step: 4
Training loss: 1.1541533663335666
Validation loss: 2.52269403209604

Epoch: 5| Step: 5
Training loss: 1.1413690413429267
Validation loss: 2.4292020518191118

Epoch: 5| Step: 6
Training loss: 1.6614395028923683
Validation loss: 2.5079880315224194

Epoch: 5| Step: 7
Training loss: 1.7625160189502602
Validation loss: 2.515396315663462

Epoch: 5| Step: 8
Training loss: 0.9478283027013238
Validation loss: 2.5051817649640182

Epoch: 5| Step: 9
Training loss: 1.2333662522708333
Validation loss: 2.533782074359087

Epoch: 5| Step: 10
Training loss: 1.181879999804802
Validation loss: 2.50703028239348

Epoch: 678| Step: 0
Training loss: 0.9721241916703656
Validation loss: 2.4921199051217284

Epoch: 5| Step: 1
Training loss: 1.4931377161569526
Validation loss: 2.4466699300577526

Epoch: 5| Step: 2
Training loss: 1.766147367461189
Validation loss: 2.506745344556841

Epoch: 5| Step: 3
Training loss: 0.8557800005446934
Validation loss: 2.4758516948304856

Epoch: 5| Step: 4
Training loss: 1.2285962586254175
Validation loss: 2.5377251391268443

Epoch: 5| Step: 5
Training loss: 1.1752160320132379
Validation loss: 2.4797226797725282

Epoch: 5| Step: 6
Training loss: 1.4244751683190096
Validation loss: 2.493840030288205

Epoch: 5| Step: 7
Training loss: 1.1009743926477087
Validation loss: 2.4838265507392636

Epoch: 5| Step: 8
Training loss: 1.1901455572208117
Validation loss: 2.4800393169894113

Epoch: 5| Step: 9
Training loss: 1.0565980913270994
Validation loss: 2.487307365231771

Epoch: 5| Step: 10
Training loss: 0.9700865600740249
Validation loss: 2.4942667845675204

Epoch: 679| Step: 0
Training loss: 1.3895927198208347
Validation loss: 2.5362472043708113

Epoch: 5| Step: 1
Training loss: 1.2374583015737743
Validation loss: 2.482781839781266

Epoch: 5| Step: 2
Training loss: 1.0056021055812536
Validation loss: 2.557433872234262

Epoch: 5| Step: 3
Training loss: 1.181325722341224
Validation loss: 2.5316383315110653

Epoch: 5| Step: 4
Training loss: 1.473603770966525
Validation loss: 2.5201636178775004

Epoch: 5| Step: 5
Training loss: 1.4709783653675517
Validation loss: 2.4540184326868615

Epoch: 5| Step: 6
Training loss: 1.4389174563265315
Validation loss: 2.532430890125939

Epoch: 5| Step: 7
Training loss: 1.1411462925129878
Validation loss: 2.476375402094451

Epoch: 5| Step: 8
Training loss: 0.6210920945631314
Validation loss: 2.506126595898689

Epoch: 5| Step: 9
Training loss: 0.9851531933972272
Validation loss: 2.5262411032269467

Epoch: 5| Step: 10
Training loss: 1.298353203012198
Validation loss: 2.479530666229663

Epoch: 680| Step: 0
Training loss: 1.001202277809536
Validation loss: 2.5076513598023604

Epoch: 5| Step: 1
Training loss: 1.2883303325827042
Validation loss: 2.4704271390579895

Epoch: 5| Step: 2
Training loss: 1.2652818190985489
Validation loss: 2.4339077354448913

Epoch: 5| Step: 3
Training loss: 2.2161382427750502
Validation loss: 2.5146901671303

Epoch: 5| Step: 4
Training loss: 1.419655377383345
Validation loss: 2.459657108949927

Epoch: 5| Step: 5
Training loss: 0.8531916721547416
Validation loss: 2.5681788918513955

Epoch: 5| Step: 6
Training loss: 1.1743839617230418
Validation loss: 2.5210053481748043

Epoch: 5| Step: 7
Training loss: 1.0645919849220882
Validation loss: 2.54205654011254

Epoch: 5| Step: 8
Training loss: 0.7645638956272219
Validation loss: 2.4634303210208723

Epoch: 5| Step: 9
Training loss: 0.9711777200400978
Validation loss: 2.5832860752457902

Epoch: 5| Step: 10
Training loss: 1.0342071212573543
Validation loss: 2.490255490011848

Epoch: 681| Step: 0
Training loss: 0.7282445162806644
Validation loss: 2.4832122727665795

Epoch: 5| Step: 1
Training loss: 1.1950711274626395
Validation loss: 2.51551493925788

Epoch: 5| Step: 2
Training loss: 0.8417242244516232
Validation loss: 2.546609782820252

Epoch: 5| Step: 3
Training loss: 1.5008806186805004
Validation loss: 2.542223503391865

Epoch: 5| Step: 4
Training loss: 1.1997291398330452
Validation loss: 2.517215796210818

Epoch: 5| Step: 5
Training loss: 1.0613493579233038
Validation loss: 2.5025060685530143

Epoch: 5| Step: 6
Training loss: 1.3609978646031093
Validation loss: 2.4635334907532567

Epoch: 5| Step: 7
Training loss: 1.4402563786099714
Validation loss: 2.514622004213038

Epoch: 5| Step: 8
Training loss: 1.2366096453274946
Validation loss: 2.4836827910226145

Epoch: 5| Step: 9
Training loss: 1.3071983527002728
Validation loss: 2.4405681882324792

Epoch: 5| Step: 10
Training loss: 1.3846796652043416
Validation loss: 2.4232833308353396

Epoch: 682| Step: 0
Training loss: 1.9147342048229614
Validation loss: 2.448655748994522

Epoch: 5| Step: 1
Training loss: 1.0398619021831108
Validation loss: 2.4704410612276857

Epoch: 5| Step: 2
Training loss: 0.9191522314633384
Validation loss: 2.4147071369276984

Epoch: 5| Step: 3
Training loss: 0.7015622255796308
Validation loss: 2.4398254710959772

Epoch: 5| Step: 4
Training loss: 0.8485026550566136
Validation loss: 2.5068028378705587

Epoch: 5| Step: 5
Training loss: 1.0672398477564264
Validation loss: 2.453778276784817

Epoch: 5| Step: 6
Training loss: 1.13649697778571
Validation loss: 2.468346090882944

Epoch: 5| Step: 7
Training loss: 1.2169246698321978
Validation loss: 2.4223557793220585

Epoch: 5| Step: 8
Training loss: 1.366676540261555
Validation loss: 2.4849845400067068

Epoch: 5| Step: 9
Training loss: 1.1494322121482836
Validation loss: 2.5364862404137694

Epoch: 5| Step: 10
Training loss: 1.4026454930308916
Validation loss: 2.530060056346252

Epoch: 683| Step: 0
Training loss: 1.0969352662139435
Validation loss: 2.5766821260814576

Epoch: 5| Step: 1
Training loss: 1.4257328391021449
Validation loss: 2.4981673999391747

Epoch: 5| Step: 2
Training loss: 0.9996121667761089
Validation loss: 2.517499532678666

Epoch: 5| Step: 3
Training loss: 1.1449012548853768
Validation loss: 2.54492751618364

Epoch: 5| Step: 4
Training loss: 1.0284980699987483
Validation loss: 2.4845605289370725

Epoch: 5| Step: 5
Training loss: 1.2088673277662636
Validation loss: 2.503556232484892

Epoch: 5| Step: 6
Training loss: 1.5005809930324956
Validation loss: 2.4779704527318214

Epoch: 5| Step: 7
Training loss: 1.1850762980882916
Validation loss: 2.4841482583084398

Epoch: 5| Step: 8
Training loss: 0.7578098257745179
Validation loss: 2.418546640942806

Epoch: 5| Step: 9
Training loss: 1.3787000031800303
Validation loss: 2.445886828540546

Epoch: 5| Step: 10
Training loss: 1.0437507126857128
Validation loss: 2.4333528952445103

Epoch: 684| Step: 0
Training loss: 1.7764851602782166
Validation loss: 2.471862631395387

Epoch: 5| Step: 1
Training loss: 0.8169407897000446
Validation loss: 2.4925365570659395

Epoch: 5| Step: 2
Training loss: 1.3229338226807907
Validation loss: 2.4975555431130134

Epoch: 5| Step: 3
Training loss: 1.2892262210335894
Validation loss: 2.4885676998197575

Epoch: 5| Step: 4
Training loss: 0.7605869198421968
Validation loss: 2.530886973594541

Epoch: 5| Step: 5
Training loss: 1.0970435553695805
Validation loss: 2.5128157469758556

Epoch: 5| Step: 6
Training loss: 0.8742348186253645
Validation loss: 2.526296390181529

Epoch: 5| Step: 7
Training loss: 0.9142393283487162
Validation loss: 2.488976821272968

Epoch: 5| Step: 8
Training loss: 1.3944969279876716
Validation loss: 2.5112414017368216

Epoch: 5| Step: 9
Training loss: 1.4424571106615345
Validation loss: 2.5030243996803665

Epoch: 5| Step: 10
Training loss: 1.0195289699485102
Validation loss: 2.475230844856181

Epoch: 685| Step: 0
Training loss: 1.2772953595902548
Validation loss: 2.4619452998226468

Epoch: 5| Step: 1
Training loss: 1.0370897194244402
Validation loss: 2.5026086487067882

Epoch: 5| Step: 2
Training loss: 1.2924433905712933
Validation loss: 2.524326708396112

Epoch: 5| Step: 3
Training loss: 1.030752293097744
Validation loss: 2.5254264522998464

Epoch: 5| Step: 4
Training loss: 0.8247552725469317
Validation loss: 2.4947654451628725

Epoch: 5| Step: 5
Training loss: 0.9823291651397112
Validation loss: 2.4707714925601096

Epoch: 5| Step: 6
Training loss: 0.7896347992026158
Validation loss: 2.4827354099350374

Epoch: 5| Step: 7
Training loss: 0.8896049212502302
Validation loss: 2.4945683488648402

Epoch: 5| Step: 8
Training loss: 1.4601879951206147
Validation loss: 2.48008852004813

Epoch: 5| Step: 9
Training loss: 1.321943686213584
Validation loss: 2.5000208530786874

Epoch: 5| Step: 10
Training loss: 1.6591283151488134
Validation loss: 2.4699925901100794

Epoch: 686| Step: 0
Training loss: 1.1603646653107678
Validation loss: 2.506726604589217

Epoch: 5| Step: 1
Training loss: 1.2569331536860195
Validation loss: 2.531765466908542

Epoch: 5| Step: 2
Training loss: 1.790058841377532
Validation loss: 2.4638250585518

Epoch: 5| Step: 3
Training loss: 0.7927768268310694
Validation loss: 2.515822094907131

Epoch: 5| Step: 4
Training loss: 0.924871617506544
Validation loss: 2.444852593154463

Epoch: 5| Step: 5
Training loss: 1.1015752155841627
Validation loss: 2.5039576265910015

Epoch: 5| Step: 6
Training loss: 1.1798254273479292
Validation loss: 2.4822947400832422

Epoch: 5| Step: 7
Training loss: 1.1826351803860646
Validation loss: 2.5907091714069495

Epoch: 5| Step: 8
Training loss: 1.0292444089080264
Validation loss: 2.520754437053934

Epoch: 5| Step: 9
Training loss: 1.0683878279389285
Validation loss: 2.4964192824718405

Epoch: 5| Step: 10
Training loss: 1.3556812570523211
Validation loss: 2.510856471093158

Epoch: 687| Step: 0
Training loss: 0.9182602115315684
Validation loss: 2.4617563521203647

Epoch: 5| Step: 1
Training loss: 0.9532799829269214
Validation loss: 2.454774692588101

Epoch: 5| Step: 2
Training loss: 0.9404643558438204
Validation loss: 2.475091832606479

Epoch: 5| Step: 3
Training loss: 0.9693084153329047
Validation loss: 2.4949172999202385

Epoch: 5| Step: 4
Training loss: 1.2365398496877174
Validation loss: 2.5111268967686993

Epoch: 5| Step: 5
Training loss: 1.6102831602172027
Validation loss: 2.5054682916392386

Epoch: 5| Step: 6
Training loss: 1.487979808326848
Validation loss: 2.4595411905777547

Epoch: 5| Step: 7
Training loss: 1.0192936295169455
Validation loss: 2.4341273917294357

Epoch: 5| Step: 8
Training loss: 1.4048102744213367
Validation loss: 2.5678145119954494

Epoch: 5| Step: 9
Training loss: 1.071529448392473
Validation loss: 2.4911221350556443

Epoch: 5| Step: 10
Training loss: 1.0400400367696434
Validation loss: 2.516895437840858

Epoch: 688| Step: 0
Training loss: 1.1371957099452563
Validation loss: 2.492143936437401

Epoch: 5| Step: 1
Training loss: 1.015675822233527
Validation loss: 2.4309454950155036

Epoch: 5| Step: 2
Training loss: 1.4320072885892565
Validation loss: 2.509777623112743

Epoch: 5| Step: 3
Training loss: 1.3184282299004282
Validation loss: 2.499690765821409

Epoch: 5| Step: 4
Training loss: 1.2946098492553424
Validation loss: 2.473911051187715

Epoch: 5| Step: 5
Training loss: 1.1292898720860947
Validation loss: 2.5580185100222423

Epoch: 5| Step: 6
Training loss: 1.6088273681437302
Validation loss: 2.5312177240017215

Epoch: 5| Step: 7
Training loss: 1.0203844497805736
Validation loss: 2.512466864545174

Epoch: 5| Step: 8
Training loss: 1.0708783178615369
Validation loss: 2.4321480296884235

Epoch: 5| Step: 9
Training loss: 1.2426532376086294
Validation loss: 2.492617449385704

Epoch: 5| Step: 10
Training loss: 1.071392377741612
Validation loss: 2.5021515171269395

Epoch: 689| Step: 0
Training loss: 1.1489695140655447
Validation loss: 2.526934856134522

Epoch: 5| Step: 1
Training loss: 1.1267967710671491
Validation loss: 2.4059746644251665

Epoch: 5| Step: 2
Training loss: 1.4297788830511329
Validation loss: 2.5328234450321716

Epoch: 5| Step: 3
Training loss: 1.050859639813863
Validation loss: 2.572602169655187

Epoch: 5| Step: 4
Training loss: 1.261935519561642
Validation loss: 2.588820118235484

Epoch: 5| Step: 5
Training loss: 1.193812307758894
Validation loss: 2.530488151124851

Epoch: 5| Step: 6
Training loss: 1.0299578576586794
Validation loss: 2.595755148829665

Epoch: 5| Step: 7
Training loss: 0.723386776754605
Validation loss: 2.4473245439135627

Epoch: 5| Step: 8
Training loss: 1.18234832000555
Validation loss: 2.4979091668771787

Epoch: 5| Step: 9
Training loss: 1.876211792050447
Validation loss: 2.5026224102885775

Epoch: 5| Step: 10
Training loss: 1.000001609324114
Validation loss: 2.4725223099271787

Epoch: 690| Step: 0
Training loss: 0.9814859410317257
Validation loss: 2.4726771828269305

Epoch: 5| Step: 1
Training loss: 0.8242682130263275
Validation loss: 2.4492378849716654

Epoch: 5| Step: 2
Training loss: 1.305515414944315
Validation loss: 2.517881546810711

Epoch: 5| Step: 3
Training loss: 0.8369320096347258
Validation loss: 2.55035380929607

Epoch: 5| Step: 4
Training loss: 1.0626843236471797
Validation loss: 2.4796996120729804

Epoch: 5| Step: 5
Training loss: 1.3913585142742795
Validation loss: 2.433590137757709

Epoch: 5| Step: 6
Training loss: 1.8749904632325827
Validation loss: 2.4837470173855647

Epoch: 5| Step: 7
Training loss: 0.9210021849491408
Validation loss: 2.5272319222663726

Epoch: 5| Step: 8
Training loss: 0.9879293908552437
Validation loss: 2.540419254459053

Epoch: 5| Step: 9
Training loss: 1.1103903730952176
Validation loss: 2.50720219071192

Epoch: 5| Step: 10
Training loss: 1.3578968561831806
Validation loss: 2.5120063833554407

Epoch: 691| Step: 0
Training loss: 0.9415534446526486
Validation loss: 2.5515058934433554

Epoch: 5| Step: 1
Training loss: 1.4480945926086652
Validation loss: 2.583983835282862

Epoch: 5| Step: 2
Training loss: 1.1143645253012764
Validation loss: 2.5175249907536323

Epoch: 5| Step: 3
Training loss: 0.8467776056007048
Validation loss: 2.5627096126932036

Epoch: 5| Step: 4
Training loss: 1.2769492470491886
Validation loss: 2.528039809550686

Epoch: 5| Step: 5
Training loss: 1.1084774308477334
Validation loss: 2.478225829021661

Epoch: 5| Step: 6
Training loss: 1.783917821783307
Validation loss: 2.5534622150629294

Epoch: 5| Step: 7
Training loss: 1.1294084639623738
Validation loss: 2.5731269634569047

Epoch: 5| Step: 8
Training loss: 0.9394142000061135
Validation loss: 2.558645154681944

Epoch: 5| Step: 9
Training loss: 0.8369691134032824
Validation loss: 2.4687843263253466

Epoch: 5| Step: 10
Training loss: 1.148414663489999
Validation loss: 2.500107629571616

Epoch: 692| Step: 0
Training loss: 0.759210889060774
Validation loss: 2.4988396792417586

Epoch: 5| Step: 1
Training loss: 1.39715790412015
Validation loss: 2.5218822400818066

Epoch: 5| Step: 2
Training loss: 1.010948152795526
Validation loss: 2.463037538427014

Epoch: 5| Step: 3
Training loss: 1.122962377935388
Validation loss: 2.5154134612636034

Epoch: 5| Step: 4
Training loss: 0.8937161325827012
Validation loss: 2.4834121506874056

Epoch: 5| Step: 5
Training loss: 1.1431806491761027
Validation loss: 2.5326895489886367

Epoch: 5| Step: 6
Training loss: 1.174934462484884
Validation loss: 2.539302837901853

Epoch: 5| Step: 7
Training loss: 1.2505260314367324
Validation loss: 2.495804355182007

Epoch: 5| Step: 8
Training loss: 1.5098211320195347
Validation loss: 2.5477768090147745

Epoch: 5| Step: 9
Training loss: 1.7239707032035523
Validation loss: 2.498711507756506

Epoch: 5| Step: 10
Training loss: 0.7741368917386164
Validation loss: 2.5078365404128515

Epoch: 693| Step: 0
Training loss: 1.3314725985255536
Validation loss: 2.5993339731873015

Epoch: 5| Step: 1
Training loss: 1.127325991294394
Validation loss: 2.4757525580893787

Epoch: 5| Step: 2
Training loss: 0.913641938839952
Validation loss: 2.5147445922525393

Epoch: 5| Step: 3
Training loss: 1.7056929800451466
Validation loss: 2.5418521884672924

Epoch: 5| Step: 4
Training loss: 0.7453376573839248
Validation loss: 2.515922943001835

Epoch: 5| Step: 5
Training loss: 1.2272354029589505
Validation loss: 2.552301616428848

Epoch: 5| Step: 6
Training loss: 1.1934913275107548
Validation loss: 2.521655928265442

Epoch: 5| Step: 7
Training loss: 1.3989768240306215
Validation loss: 2.5256513295053535

Epoch: 5| Step: 8
Training loss: 0.9635461274464767
Validation loss: 2.526134054314701

Epoch: 5| Step: 9
Training loss: 1.0701954352965697
Validation loss: 2.569721939909581

Epoch: 5| Step: 10
Training loss: 1.113284515911465
Validation loss: 2.4486354379178756

Epoch: 694| Step: 0
Training loss: 1.182039556077011
Validation loss: 2.5364433335802836

Epoch: 5| Step: 1
Training loss: 1.0152451611863593
Validation loss: 2.528978112892421

Epoch: 5| Step: 2
Training loss: 0.8511055586576772
Validation loss: 2.5010305229075045

Epoch: 5| Step: 3
Training loss: 1.8017859976199955
Validation loss: 2.5117759110561324

Epoch: 5| Step: 4
Training loss: 1.2035542502638787
Validation loss: 2.5096211824652097

Epoch: 5| Step: 5
Training loss: 1.3618357080163366
Validation loss: 2.570391267797054

Epoch: 5| Step: 6
Training loss: 1.2852245185135092
Validation loss: 2.556846282297432

Epoch: 5| Step: 7
Training loss: 0.737744575291813
Validation loss: 2.505671493500851

Epoch: 5| Step: 8
Training loss: 1.0869637449687948
Validation loss: 2.5361248197251944

Epoch: 5| Step: 9
Training loss: 1.0902784567558836
Validation loss: 2.468111682852044

Epoch: 5| Step: 10
Training loss: 1.3039921717964589
Validation loss: 2.5031508401966684

Epoch: 695| Step: 0
Training loss: 1.238071845125321
Validation loss: 2.4975034061039003

Epoch: 5| Step: 1
Training loss: 1.3050371261226523
Validation loss: 2.5382766312676046

Epoch: 5| Step: 2
Training loss: 1.1663419180706114
Validation loss: 2.3659700793485636

Epoch: 5| Step: 3
Training loss: 1.2310437993145038
Validation loss: 2.4680918647950967

Epoch: 5| Step: 4
Training loss: 1.264767391545978
Validation loss: 2.480267536146713

Epoch: 5| Step: 5
Training loss: 1.3853628487519167
Validation loss: 2.476803432328631

Epoch: 5| Step: 6
Training loss: 1.2395841561109018
Validation loss: 2.5043208284072382

Epoch: 5| Step: 7
Training loss: 1.4312188124277996
Validation loss: 2.5520376904951387

Epoch: 5| Step: 8
Training loss: 0.8370393283177163
Validation loss: 2.5236028639115187

Epoch: 5| Step: 9
Training loss: 1.4222802224021738
Validation loss: 2.500951219916025

Epoch: 5| Step: 10
Training loss: 0.8402411297003924
Validation loss: 2.434440681769553

Epoch: 696| Step: 0
Training loss: 1.3246994721379426
Validation loss: 2.54681654706451

Epoch: 5| Step: 1
Training loss: 1.562950527089125
Validation loss: 2.4858488155071785

Epoch: 5| Step: 2
Training loss: 1.0850388355600282
Validation loss: 2.4844827843361847

Epoch: 5| Step: 3
Training loss: 1.3426781748878585
Validation loss: 2.6111292869690463

Epoch: 5| Step: 4
Training loss: 0.9056226926975594
Validation loss: 2.5180170457863404

Epoch: 5| Step: 5
Training loss: 1.0828936063437706
Validation loss: 2.4734833402656577

Epoch: 5| Step: 6
Training loss: 1.2379126737297594
Validation loss: 2.5212058498287235

Epoch: 5| Step: 7
Training loss: 1.1841115794476855
Validation loss: 2.474174352432016

Epoch: 5| Step: 8
Training loss: 0.8860772791263146
Validation loss: 2.4483537875816412

Epoch: 5| Step: 9
Training loss: 1.1052944194165846
Validation loss: 2.493794517706734

Epoch: 5| Step: 10
Training loss: 1.3488263786121224
Validation loss: 2.490553321753413

Epoch: 697| Step: 0
Training loss: 0.9251046585467136
Validation loss: 2.5144689572784786

Epoch: 5| Step: 1
Training loss: 1.261017737500578
Validation loss: 2.4942083881559984

Epoch: 5| Step: 2
Training loss: 1.0073069997657311
Validation loss: 2.615366079048715

Epoch: 5| Step: 3
Training loss: 1.2553144966700285
Validation loss: 2.47403474872147

Epoch: 5| Step: 4
Training loss: 1.3055399776548418
Validation loss: 2.5133302515432674

Epoch: 5| Step: 5
Training loss: 1.6028321234739584
Validation loss: 2.497856872522211

Epoch: 5| Step: 6
Training loss: 0.8216788402323597
Validation loss: 2.4725727657596086

Epoch: 5| Step: 7
Training loss: 0.8064756432536996
Validation loss: 2.456046325568893

Epoch: 5| Step: 8
Training loss: 1.0059260966569188
Validation loss: 2.4059348100383793

Epoch: 5| Step: 9
Training loss: 1.3477918473732602
Validation loss: 2.5047800409489778

Epoch: 5| Step: 10
Training loss: 1.3239021035215792
Validation loss: 2.53706837839605

Epoch: 698| Step: 0
Training loss: 0.8580140174174183
Validation loss: 2.528272931271635

Epoch: 5| Step: 1
Training loss: 1.27466594209278
Validation loss: 2.514291438244498

Epoch: 5| Step: 2
Training loss: 1.292741461653906
Validation loss: 2.5185526822332145

Epoch: 5| Step: 3
Training loss: 1.6652504705644031
Validation loss: 2.541521745729697

Epoch: 5| Step: 4
Training loss: 1.1916800762746953
Validation loss: 2.457942869762317

Epoch: 5| Step: 5
Training loss: 1.0648968532920196
Validation loss: 2.55083546135444

Epoch: 5| Step: 6
Training loss: 0.9971334379503143
Validation loss: 2.4590945336733925

Epoch: 5| Step: 7
Training loss: 1.2562551393925694
Validation loss: 2.573595289716122

Epoch: 5| Step: 8
Training loss: 1.3509518781995895
Validation loss: 2.5618167979887225

Epoch: 5| Step: 9
Training loss: 0.9783542522834562
Validation loss: 2.5317419615455448

Epoch: 5| Step: 10
Training loss: 0.9208799908470264
Validation loss: 2.4687634767948783

Epoch: 699| Step: 0
Training loss: 1.4590146062902893
Validation loss: 2.497828888285846

Epoch: 5| Step: 1
Training loss: 1.1903452667269128
Validation loss: 2.4829465557316546

Epoch: 5| Step: 2
Training loss: 1.1074415740022094
Validation loss: 2.4824500205245372

Epoch: 5| Step: 3
Training loss: 1.5161168195157988
Validation loss: 2.465407568795338

Epoch: 5| Step: 4
Training loss: 0.8483585665184585
Validation loss: 2.5217414738164727

Epoch: 5| Step: 5
Training loss: 0.9263177918453568
Validation loss: 2.52549148892493

Epoch: 5| Step: 6
Training loss: 0.9706328153571926
Validation loss: 2.5064366296082867

Epoch: 5| Step: 7
Training loss: 1.0638395728513423
Validation loss: 2.4592282866753123

Epoch: 5| Step: 8
Training loss: 1.1086485189897393
Validation loss: 2.5268740731330657

Epoch: 5| Step: 9
Training loss: 1.3281850913422077
Validation loss: 2.5438983855514077

Epoch: 5| Step: 10
Training loss: 1.4062706839841683
Validation loss: 2.531010625416593

Epoch: 700| Step: 0
Training loss: 1.3723029214387734
Validation loss: 2.4973040411002856

Epoch: 5| Step: 1
Training loss: 1.3085676503781338
Validation loss: 2.494971188953402

Epoch: 5| Step: 2
Training loss: 1.315111468707167
Validation loss: 2.525073411488203

Epoch: 5| Step: 3
Training loss: 1.1425500589167799
Validation loss: 2.4844689707759495

Epoch: 5| Step: 4
Training loss: 1.1658748369189198
Validation loss: 2.4313312456100586

Epoch: 5| Step: 5
Training loss: 1.01797184859512
Validation loss: 2.4539234217230104

Epoch: 5| Step: 6
Training loss: 1.1791696990999696
Validation loss: 2.5190148590940207

Epoch: 5| Step: 7
Training loss: 0.8958126036145494
Validation loss: 2.4665738170889635

Epoch: 5| Step: 8
Training loss: 1.2026712131548232
Validation loss: 2.4170071068936463

Epoch: 5| Step: 9
Training loss: 1.5222911727832775
Validation loss: 2.649273195703766

Epoch: 5| Step: 10
Training loss: 0.582465195659765
Validation loss: 2.482733729915206

Epoch: 701| Step: 0
Training loss: 1.216712716071595
Validation loss: 2.5015233761642293

Epoch: 5| Step: 1
Training loss: 1.7304903119468256
Validation loss: 2.549806190611842

Epoch: 5| Step: 2
Training loss: 1.0709880172885498
Validation loss: 2.4637474111680957

Epoch: 5| Step: 3
Training loss: 1.2627635208671786
Validation loss: 2.4896006827913304

Epoch: 5| Step: 4
Training loss: 0.7700388439710121
Validation loss: 2.5392280013524173

Epoch: 5| Step: 5
Training loss: 1.0751130976067442
Validation loss: 2.4712612302717734

Epoch: 5| Step: 6
Training loss: 0.9309415293565044
Validation loss: 2.4920760441070775

Epoch: 5| Step: 7
Training loss: 0.8654551687171876
Validation loss: 2.5460501298298457

Epoch: 5| Step: 8
Training loss: 1.6092155896096625
Validation loss: 2.527000364231582

Epoch: 5| Step: 9
Training loss: 1.076107736327416
Validation loss: 2.4809995869199652

Epoch: 5| Step: 10
Training loss: 1.1794578884574605
Validation loss: 2.498005490802615

Epoch: 702| Step: 0
Training loss: 1.1888513405139933
Validation loss: 2.4417131601025885

Epoch: 5| Step: 1
Training loss: 1.135221878748493
Validation loss: 2.4770339450324776

Epoch: 5| Step: 2
Training loss: 1.4470311025033078
Validation loss: 2.533125115625921

Epoch: 5| Step: 3
Training loss: 1.0898730092923543
Validation loss: 2.4684710258681033

Epoch: 5| Step: 4
Training loss: 1.3784688196319088
Validation loss: 2.504675508783554

Epoch: 5| Step: 5
Training loss: 1.002407573234921
Validation loss: 2.4561331907726656

Epoch: 5| Step: 6
Training loss: 1.227698073789585
Validation loss: 2.4930627822218994

Epoch: 5| Step: 7
Training loss: 1.2329073039106857
Validation loss: 2.491283249487007

Epoch: 5| Step: 8
Training loss: 0.9157255319340878
Validation loss: 2.4432360645363067

Epoch: 5| Step: 9
Training loss: 1.1189257563624777
Validation loss: 2.5464227021745502

Epoch: 5| Step: 10
Training loss: 0.907559435398236
Validation loss: 2.5679867557781746

Epoch: 703| Step: 0
Training loss: 1.1280830312091943
Validation loss: 2.549277389448434

Epoch: 5| Step: 1
Training loss: 1.3484865146538347
Validation loss: 2.477257282754386

Epoch: 5| Step: 2
Training loss: 1.086877539501766
Validation loss: 2.538732327306794

Epoch: 5| Step: 3
Training loss: 1.0280234985337628
Validation loss: 2.533303872168149

Epoch: 5| Step: 4
Training loss: 1.50034201219737
Validation loss: 2.506182943408618

Epoch: 5| Step: 5
Training loss: 1.4860199497264859
Validation loss: 2.4542906550611763

Epoch: 5| Step: 6
Training loss: 0.9665741018393875
Validation loss: 2.5340949219869215

Epoch: 5| Step: 7
Training loss: 0.7460982237676734
Validation loss: 2.4979441023816977

Epoch: 5| Step: 8
Training loss: 0.8709134655152261
Validation loss: 2.44527771522806

Epoch: 5| Step: 9
Training loss: 1.01189771564285
Validation loss: 2.4868981314953627

Epoch: 5| Step: 10
Training loss: 1.1816875858275582
Validation loss: 2.449102398282808

Epoch: 704| Step: 0
Training loss: 1.0588796307000157
Validation loss: 2.4968352087563095

Epoch: 5| Step: 1
Training loss: 0.9704861619130809
Validation loss: 2.507901418834147

Epoch: 5| Step: 2
Training loss: 1.5723967882498635
Validation loss: 2.5805982850801064

Epoch: 5| Step: 3
Training loss: 1.1759599822300582
Validation loss: 2.490312019052966

Epoch: 5| Step: 4
Training loss: 1.3353850800839813
Validation loss: 2.5092854102924065

Epoch: 5| Step: 5
Training loss: 1.076168330302692
Validation loss: 2.471366460527481

Epoch: 5| Step: 6
Training loss: 1.1132822672521394
Validation loss: 2.5190799971366964

Epoch: 5| Step: 7
Training loss: 1.1524681929297318
Validation loss: 2.5473507733026266

Epoch: 5| Step: 8
Training loss: 1.165932503809432
Validation loss: 2.5309319721110084

Epoch: 5| Step: 9
Training loss: 0.9688457933870749
Validation loss: 2.50874717595463

Epoch: 5| Step: 10
Training loss: 1.049390702348819
Validation loss: 2.5153799424897425

Epoch: 705| Step: 0
Training loss: 0.9870066508926117
Validation loss: 2.473295184353875

Epoch: 5| Step: 1
Training loss: 1.3802011693612597
Validation loss: 2.4461530205197834

Epoch: 5| Step: 2
Training loss: 1.3669917375193483
Validation loss: 2.512683340562642

Epoch: 5| Step: 3
Training loss: 1.208743760133277
Validation loss: 2.5373626647976804

Epoch: 5| Step: 4
Training loss: 1.0571140772812408
Validation loss: 2.5134533024123993

Epoch: 5| Step: 5
Training loss: 1.1561196743486444
Validation loss: 2.5795740325675416

Epoch: 5| Step: 6
Training loss: 0.8056311398339526
Validation loss: 2.55685935140084

Epoch: 5| Step: 7
Training loss: 0.9990464969483291
Validation loss: 2.4980278132108413

Epoch: 5| Step: 8
Training loss: 1.2094481630890692
Validation loss: 2.5288628751942777

Epoch: 5| Step: 9
Training loss: 0.7987680575817534
Validation loss: 2.5239330371450395

Epoch: 5| Step: 10
Training loss: 1.5220374300711523
Validation loss: 2.423326366651121

Epoch: 706| Step: 0
Training loss: 1.5730103807973783
Validation loss: 2.415920605631619

Epoch: 5| Step: 1
Training loss: 0.7956697662057689
Validation loss: 2.4170037679103755

Epoch: 5| Step: 2
Training loss: 1.0868683262993584
Validation loss: 2.4902559517286167

Epoch: 5| Step: 3
Training loss: 1.1618568979610706
Validation loss: 2.544436674328136

Epoch: 5| Step: 4
Training loss: 1.0733831866653933
Validation loss: 2.437063864411656

Epoch: 5| Step: 5
Training loss: 0.7796779073916339
Validation loss: 2.4051800764853297

Epoch: 5| Step: 6
Training loss: 1.7486899785940764
Validation loss: 2.5537001215841135

Epoch: 5| Step: 7
Training loss: 1.4738295356183615
Validation loss: 2.4917634499136287

Epoch: 5| Step: 8
Training loss: 1.0895189464404509
Validation loss: 2.613701213706746

Epoch: 5| Step: 9
Training loss: 0.808889804766501
Validation loss: 2.546523915948916

Epoch: 5| Step: 10
Training loss: 1.1015811134010312
Validation loss: 2.492771390555102

Epoch: 707| Step: 0
Training loss: 1.2154861174731777
Validation loss: 2.565103235531397

Epoch: 5| Step: 1
Training loss: 1.180626754234388
Validation loss: 2.522886921682126

Epoch: 5| Step: 2
Training loss: 1.1947298312738817
Validation loss: 2.571559153476454

Epoch: 5| Step: 3
Training loss: 1.0426626149055735
Validation loss: 2.4649043444565777

Epoch: 5| Step: 4
Training loss: 1.193025233162562
Validation loss: 2.49743963411017

Epoch: 5| Step: 5
Training loss: 1.586652998357825
Validation loss: 2.5135982529513714

Epoch: 5| Step: 6
Training loss: 1.16448669897061
Validation loss: 2.4993641465150276

Epoch: 5| Step: 7
Training loss: 1.0682221765659918
Validation loss: 2.478409475123767

Epoch: 5| Step: 8
Training loss: 1.0327393152390183
Validation loss: 2.5617722849345874

Epoch: 5| Step: 9
Training loss: 0.920876528013082
Validation loss: 2.5680618613521085

Epoch: 5| Step: 10
Training loss: 0.829969798480781
Validation loss: 2.525134175903535

Epoch: 708| Step: 0
Training loss: 0.9699235698732769
Validation loss: 2.531886325765012

Epoch: 5| Step: 1
Training loss: 1.5171418612340655
Validation loss: 2.5277736399832804

Epoch: 5| Step: 2
Training loss: 0.9320861263059932
Validation loss: 2.4740385122642863

Epoch: 5| Step: 3
Training loss: 0.9436086005583398
Validation loss: 2.5111673751094234

Epoch: 5| Step: 4
Training loss: 1.1904243800832774
Validation loss: 2.453297343750287

Epoch: 5| Step: 5
Training loss: 0.8243715406783421
Validation loss: 2.5060788339372344

Epoch: 5| Step: 6
Training loss: 0.9474365080241844
Validation loss: 2.517118678674707

Epoch: 5| Step: 7
Training loss: 1.4610638895288866
Validation loss: 2.5201882561010076

Epoch: 5| Step: 8
Training loss: 1.3155152336233205
Validation loss: 2.533825355081594

Epoch: 5| Step: 9
Training loss: 0.9883312770560512
Validation loss: 2.3737921922387133

Epoch: 5| Step: 10
Training loss: 0.8399056345295886
Validation loss: 2.4139779770308367

Epoch: 709| Step: 0
Training loss: 1.049393201514517
Validation loss: 2.587737426557281

Epoch: 5| Step: 1
Training loss: 1.0954745185078807
Validation loss: 2.533310505656752

Epoch: 5| Step: 2
Training loss: 1.3420604463599841
Validation loss: 2.5423526722384238

Epoch: 5| Step: 3
Training loss: 0.6500641516059438
Validation loss: 2.573232641235659

Epoch: 5| Step: 4
Training loss: 1.0782106337884607
Validation loss: 2.4834282597663417

Epoch: 5| Step: 5
Training loss: 1.1563840736805924
Validation loss: 2.559940425416109

Epoch: 5| Step: 6
Training loss: 1.8295659312346793
Validation loss: 2.6196610084573435

Epoch: 5| Step: 7
Training loss: 0.7565230578068379
Validation loss: 2.5514656787757475

Epoch: 5| Step: 8
Training loss: 1.4280284156109206
Validation loss: 2.5878569830056155

Epoch: 5| Step: 9
Training loss: 1.1123171195255643
Validation loss: 2.439757861909638

Epoch: 5| Step: 10
Training loss: 1.2781081872407871
Validation loss: 2.526696498285751

Epoch: 710| Step: 0
Training loss: 1.135885451015092
Validation loss: 2.476321045233844

Epoch: 5| Step: 1
Training loss: 1.0061865413392737
Validation loss: 2.5311990922948344

Epoch: 5| Step: 2
Training loss: 0.6843075322726824
Validation loss: 2.572673277103844

Epoch: 5| Step: 3
Training loss: 1.1035452779651156
Validation loss: 2.492786763477866

Epoch: 5| Step: 4
Training loss: 1.2090833681957414
Validation loss: 2.570832102080844

Epoch: 5| Step: 5
Training loss: 0.9130932486338312
Validation loss: 2.4951140640104708

Epoch: 5| Step: 6
Training loss: 1.8245740132058599
Validation loss: 2.5015681383659008

Epoch: 5| Step: 7
Training loss: 1.0160370211051493
Validation loss: 2.4691743196591274

Epoch: 5| Step: 8
Training loss: 0.8622987429456054
Validation loss: 2.49891613106903

Epoch: 5| Step: 9
Training loss: 1.0746310465883182
Validation loss: 2.595153434836516

Epoch: 5| Step: 10
Training loss: 1.291179329192846
Validation loss: 2.4815770385087714

Epoch: 711| Step: 0
Training loss: 1.0714104582754123
Validation loss: 2.416100267677467

Epoch: 5| Step: 1
Training loss: 0.7902617075969125
Validation loss: 2.4842333297595918

Epoch: 5| Step: 2
Training loss: 0.9305719928491695
Validation loss: 2.486104459080157

Epoch: 5| Step: 3
Training loss: 1.3916242631098035
Validation loss: 2.5158374869626425

Epoch: 5| Step: 4
Training loss: 0.9934348128367342
Validation loss: 2.4882947405246276

Epoch: 5| Step: 5
Training loss: 1.1680466233641604
Validation loss: 2.463046257050844

Epoch: 5| Step: 6
Training loss: 1.2420275603198896
Validation loss: 2.5271897510050936

Epoch: 5| Step: 7
Training loss: 1.0288781141230061
Validation loss: 2.48753493510141

Epoch: 5| Step: 8
Training loss: 1.0956400208822634
Validation loss: 2.4609673819393683

Epoch: 5| Step: 9
Training loss: 1.8840030689012028
Validation loss: 2.492448215334024

Epoch: 5| Step: 10
Training loss: 1.0065538101744955
Validation loss: 2.5449043086769905

Epoch: 712| Step: 0
Training loss: 1.0384229254811919
Validation loss: 2.4585227754270513

Epoch: 5| Step: 1
Training loss: 1.6818262013330862
Validation loss: 2.4998701072091345

Epoch: 5| Step: 2
Training loss: 0.8256081535936612
Validation loss: 2.4664944321161366

Epoch: 5| Step: 3
Training loss: 1.0550717819345208
Validation loss: 2.5029299917039998

Epoch: 5| Step: 4
Training loss: 0.9677843695676541
Validation loss: 2.4777087064932233

Epoch: 5| Step: 5
Training loss: 1.3814392598840834
Validation loss: 2.530003886980434

Epoch: 5| Step: 6
Training loss: 1.1225430892796182
Validation loss: 2.515260758065142

Epoch: 5| Step: 7
Training loss: 1.125695172737875
Validation loss: 2.518007774778965

Epoch: 5| Step: 8
Training loss: 1.11275118874508
Validation loss: 2.521105648787946

Epoch: 5| Step: 9
Training loss: 1.0680559414346298
Validation loss: 2.4747192545929693

Epoch: 5| Step: 10
Training loss: 1.4441283452752955
Validation loss: 2.567414849534977

Epoch: 713| Step: 0
Training loss: 1.3259997698609625
Validation loss: 2.5575812889024605

Epoch: 5| Step: 1
Training loss: 0.8406369034729143
Validation loss: 2.530025170141973

Epoch: 5| Step: 2
Training loss: 1.373562364685077
Validation loss: 2.5198802510730824

Epoch: 5| Step: 3
Training loss: 0.7391084749467003
Validation loss: 2.4618363183953

Epoch: 5| Step: 4
Training loss: 1.0237436782958458
Validation loss: 2.4590055117861427

Epoch: 5| Step: 5
Training loss: 1.157577268357239
Validation loss: 2.5099065649852337

Epoch: 5| Step: 6
Training loss: 0.7471264786893123
Validation loss: 2.5815310176784836

Epoch: 5| Step: 7
Training loss: 1.0642054278355202
Validation loss: 2.484337627191443

Epoch: 5| Step: 8
Training loss: 1.5581172511110448
Validation loss: 2.491844309717138

Epoch: 5| Step: 9
Training loss: 1.178087475733074
Validation loss: 2.4699081231999025

Epoch: 5| Step: 10
Training loss: 1.657279504347346
Validation loss: 2.469605667907207

Epoch: 714| Step: 0
Training loss: 1.1796304044738155
Validation loss: 2.4859617360112627

Epoch: 5| Step: 1
Training loss: 0.8361205141320998
Validation loss: 2.5120078917352546

Epoch: 5| Step: 2
Training loss: 1.2410949604826231
Validation loss: 2.4936639295194034

Epoch: 5| Step: 3
Training loss: 1.0656783865255457
Validation loss: 2.4583867357341234

Epoch: 5| Step: 4
Training loss: 0.9527345076307117
Validation loss: 2.4311044412115375

Epoch: 5| Step: 5
Training loss: 1.599393166263354
Validation loss: 2.544913237920676

Epoch: 5| Step: 6
Training loss: 1.2340483414317602
Validation loss: 2.5101538174901994

Epoch: 5| Step: 7
Training loss: 0.7494344963527001
Validation loss: 2.544700660226899

Epoch: 5| Step: 8
Training loss: 1.1628243434828782
Validation loss: 2.575217385917079

Epoch: 5| Step: 9
Training loss: 1.1514957217105128
Validation loss: 2.5493081068641126

Epoch: 5| Step: 10
Training loss: 1.2935711244036763
Validation loss: 2.53247911982027

Epoch: 715| Step: 0
Training loss: 1.3956131358139932
Validation loss: 2.537276971992366

Epoch: 5| Step: 1
Training loss: 1.1974701698904255
Validation loss: 2.5123398408313387

Epoch: 5| Step: 2
Training loss: 0.9848634628121734
Validation loss: 2.497683443414765

Epoch: 5| Step: 3
Training loss: 1.2152268765401193
Validation loss: 2.5189682584848803

Epoch: 5| Step: 4
Training loss: 1.1532530219904489
Validation loss: 2.5473876312400434

Epoch: 5| Step: 5
Training loss: 1.0948767171986293
Validation loss: 2.4648420442642522

Epoch: 5| Step: 6
Training loss: 0.9826096342035708
Validation loss: 2.5144694711343942

Epoch: 5| Step: 7
Training loss: 1.1453940618807037
Validation loss: 2.492571330285779

Epoch: 5| Step: 8
Training loss: 1.039814784264903
Validation loss: 2.5480311915146805

Epoch: 5| Step: 9
Training loss: 1.5425878899758583
Validation loss: 2.462777166622306

Epoch: 5| Step: 10
Training loss: 1.023345651945924
Validation loss: 2.4674239402465634

Epoch: 716| Step: 0
Training loss: 0.8397901651010516
Validation loss: 2.5580606370617254

Epoch: 5| Step: 1
Training loss: 1.0571300339197218
Validation loss: 2.475448715595405

Epoch: 5| Step: 2
Training loss: 1.0899144631692212
Validation loss: 2.6194365377377897

Epoch: 5| Step: 3
Training loss: 0.941552621692757
Validation loss: 2.5098883225578934

Epoch: 5| Step: 4
Training loss: 1.2245269212236176
Validation loss: 2.6355432780465757

Epoch: 5| Step: 5
Training loss: 0.8455811163658713
Validation loss: 2.5648995936244128

Epoch: 5| Step: 6
Training loss: 1.583442265962814
Validation loss: 2.516565033485522

Epoch: 5| Step: 7
Training loss: 1.2541364416913963
Validation loss: 2.503303535537181

Epoch: 5| Step: 8
Training loss: 1.520816445801221
Validation loss: 2.5943458486514066

Epoch: 5| Step: 9
Training loss: 1.0494108659023587
Validation loss: 2.5030535722887954

Epoch: 5| Step: 10
Training loss: 1.2191865090410983
Validation loss: 2.518511528105903

Epoch: 717| Step: 0
Training loss: 1.091953655307475
Validation loss: 2.47334254806441

Epoch: 5| Step: 1
Training loss: 1.0867780547205432
Validation loss: 2.439104888106866

Epoch: 5| Step: 2
Training loss: 0.8180765833272301
Validation loss: 2.4922750568674146

Epoch: 5| Step: 3
Training loss: 0.9132762037517973
Validation loss: 2.5348754921506034

Epoch: 5| Step: 4
Training loss: 1.6508366630991758
Validation loss: 2.563588661223483

Epoch: 5| Step: 5
Training loss: 1.2710189787965638
Validation loss: 2.5146416089954524

Epoch: 5| Step: 6
Training loss: 0.9299517985127336
Validation loss: 2.473219831739345

Epoch: 5| Step: 7
Training loss: 1.174888195643557
Validation loss: 2.5273035708147367

Epoch: 5| Step: 8
Training loss: 0.8284819211673673
Validation loss: 2.461711616339283

Epoch: 5| Step: 9
Training loss: 1.243371075746812
Validation loss: 2.4259687456961734

Epoch: 5| Step: 10
Training loss: 1.1607036904490717
Validation loss: 2.4774530813232385

Epoch: 718| Step: 0
Training loss: 1.3194012629263678
Validation loss: 2.4751323321512073

Epoch: 5| Step: 1
Training loss: 0.8826577042432445
Validation loss: 2.5624577295942266

Epoch: 5| Step: 2
Training loss: 0.9861931434652159
Validation loss: 2.526927985756387

Epoch: 5| Step: 3
Training loss: 0.7708766813375844
Validation loss: 2.5233878417764095

Epoch: 5| Step: 4
Training loss: 1.3401947451463565
Validation loss: 2.5394025243319867

Epoch: 5| Step: 5
Training loss: 0.9790459754637871
Validation loss: 2.5300893260770922

Epoch: 5| Step: 6
Training loss: 0.7804597672717829
Validation loss: 2.6092197980453364

Epoch: 5| Step: 7
Training loss: 1.55788946851176
Validation loss: 2.4889513317870384

Epoch: 5| Step: 8
Training loss: 1.1115264447455915
Validation loss: 2.4861001126196998

Epoch: 5| Step: 9
Training loss: 1.0970509445059098
Validation loss: 2.5598018206151076

Epoch: 5| Step: 10
Training loss: 1.0195010242877958
Validation loss: 2.448437900769474

Epoch: 719| Step: 0
Training loss: 0.7016357969808807
Validation loss: 2.515376495599504

Epoch: 5| Step: 1
Training loss: 1.2748344575711843
Validation loss: 2.4589845261713066

Epoch: 5| Step: 2
Training loss: 1.1489013980559142
Validation loss: 2.5586409274413064

Epoch: 5| Step: 3
Training loss: 1.2518148598816081
Validation loss: 2.4556830472792015

Epoch: 5| Step: 4
Training loss: 1.1091744684928502
Validation loss: 2.4797936447508158

Epoch: 5| Step: 5
Training loss: 0.9983316451956901
Validation loss: 2.4588124402930247

Epoch: 5| Step: 6
Training loss: 0.8510136366624577
Validation loss: 2.504660761546682

Epoch: 5| Step: 7
Training loss: 1.396532391342888
Validation loss: 2.474317715528498

Epoch: 5| Step: 8
Training loss: 1.5849457444492856
Validation loss: 2.492607602570289

Epoch: 5| Step: 9
Training loss: 0.9885169792241388
Validation loss: 2.4852434836849975

Epoch: 5| Step: 10
Training loss: 1.0579955603284654
Validation loss: 2.4630986675439805

Epoch: 720| Step: 0
Training loss: 0.6811069487071496
Validation loss: 2.533739731848859

Epoch: 5| Step: 1
Training loss: 0.9470791033342527
Validation loss: 2.4472536818182276

Epoch: 5| Step: 2
Training loss: 1.169139466697764
Validation loss: 2.4978775243714764

Epoch: 5| Step: 3
Training loss: 1.7358932722965907
Validation loss: 2.441561580450143

Epoch: 5| Step: 4
Training loss: 1.2972237451278021
Validation loss: 2.5487509801022328

Epoch: 5| Step: 5
Training loss: 1.1003509785176195
Validation loss: 2.523781469063843

Epoch: 5| Step: 6
Training loss: 1.4524349912451624
Validation loss: 2.4814516951316854

Epoch: 5| Step: 7
Training loss: 1.107019745007094
Validation loss: 2.4865599693179443

Epoch: 5| Step: 8
Training loss: 1.1489004642211709
Validation loss: 2.4921858921869418

Epoch: 5| Step: 9
Training loss: 0.9506742832568454
Validation loss: 2.5546124728810247

Epoch: 5| Step: 10
Training loss: 0.770100687862674
Validation loss: 2.5340479320011737

Epoch: 721| Step: 0
Training loss: 0.9504549116851484
Validation loss: 2.4889080545802793

Epoch: 5| Step: 1
Training loss: 0.7501911476057381
Validation loss: 2.522724090006359

Epoch: 5| Step: 2
Training loss: 0.8849096117898457
Validation loss: 2.5212992633588067

Epoch: 5| Step: 3
Training loss: 1.0772515781025405
Validation loss: 2.518610672479057

Epoch: 5| Step: 4
Training loss: 1.4443914004310467
Validation loss: 2.4674828256130157

Epoch: 5| Step: 5
Training loss: 1.2199666723795854
Validation loss: 2.527724088750516

Epoch: 5| Step: 6
Training loss: 1.16505231314172
Validation loss: 2.569555187046813

Epoch: 5| Step: 7
Training loss: 1.1113577304108015
Validation loss: 2.4664783589933097

Epoch: 5| Step: 8
Training loss: 0.9940813267977751
Validation loss: 2.4930848938672683

Epoch: 5| Step: 9
Training loss: 1.7188029194401127
Validation loss: 2.5697983714641808

Epoch: 5| Step: 10
Training loss: 0.8626881283682679
Validation loss: 2.4940433120087593

Epoch: 722| Step: 0
Training loss: 0.7974416924330614
Validation loss: 2.5416968878595614

Epoch: 5| Step: 1
Training loss: 1.2163246181294636
Validation loss: 2.4712235621444227

Epoch: 5| Step: 2
Training loss: 0.9016262686405964
Validation loss: 2.5028622864536696

Epoch: 5| Step: 3
Training loss: 0.9931891184059013
Validation loss: 2.4914018872287222

Epoch: 5| Step: 4
Training loss: 1.139006105970941
Validation loss: 2.437258159124174

Epoch: 5| Step: 5
Training loss: 0.9526474178305843
Validation loss: 2.5562920866246874

Epoch: 5| Step: 6
Training loss: 0.995179089239048
Validation loss: 2.5648205882051816

Epoch: 5| Step: 7
Training loss: 1.088110526578595
Validation loss: 2.4997920893281975

Epoch: 5| Step: 8
Training loss: 1.1576628429973213
Validation loss: 2.5578087584512987

Epoch: 5| Step: 9
Training loss: 1.6499945351481249
Validation loss: 2.598716500837758

Epoch: 5| Step: 10
Training loss: 1.1142441717812348
Validation loss: 2.478245659657667

Epoch: 723| Step: 0
Training loss: 1.031097978888758
Validation loss: 2.6064618001553694

Epoch: 5| Step: 1
Training loss: 1.1582382737176875
Validation loss: 2.5532103286240444

Epoch: 5| Step: 2
Training loss: 0.9740199751225401
Validation loss: 2.434384305975341

Epoch: 5| Step: 3
Training loss: 1.0835874088379593
Validation loss: 2.495308637613782

Epoch: 5| Step: 4
Training loss: 0.8333740502582802
Validation loss: 2.516030632440814

Epoch: 5| Step: 5
Training loss: 0.9520168115650116
Validation loss: 2.6116727395008046

Epoch: 5| Step: 6
Training loss: 1.2395570843051802
Validation loss: 2.570712382121147

Epoch: 5| Step: 7
Training loss: 1.1042400311742706
Validation loss: 2.4860454435008026

Epoch: 5| Step: 8
Training loss: 1.0371478804572132
Validation loss: 2.479485475683849

Epoch: 5| Step: 9
Training loss: 1.5810693901561208
Validation loss: 2.5364076962612945

Epoch: 5| Step: 10
Training loss: 1.0540240426262022
Validation loss: 2.509281340499982

Epoch: 724| Step: 0
Training loss: 0.8405903181558154
Validation loss: 2.5445127833228187

Epoch: 5| Step: 1
Training loss: 1.3381336743190793
Validation loss: 2.5119170474863264

Epoch: 5| Step: 2
Training loss: 0.7267502162816238
Validation loss: 2.5161014249179487

Epoch: 5| Step: 3
Training loss: 1.175615723576875
Validation loss: 2.4810313082879016

Epoch: 5| Step: 4
Training loss: 1.4822347369579982
Validation loss: 2.5008684024191052

Epoch: 5| Step: 5
Training loss: 1.1274429393971006
Validation loss: 2.4763236002587012

Epoch: 5| Step: 6
Training loss: 1.1416748649878259
Validation loss: 2.4927284912894865

Epoch: 5| Step: 7
Training loss: 1.2295930198426634
Validation loss: 2.4783239751538804

Epoch: 5| Step: 8
Training loss: 1.7108328451957073
Validation loss: 2.488363875482228

Epoch: 5| Step: 9
Training loss: 0.7853192212461937
Validation loss: 2.4116816780822843

Epoch: 5| Step: 10
Training loss: 1.0786158232272558
Validation loss: 2.547524835417446

Epoch: 725| Step: 0
Training loss: 0.9566633802007477
Validation loss: 2.476898547358629

Epoch: 5| Step: 1
Training loss: 1.2523298485282424
Validation loss: 2.5815472543195654

Epoch: 5| Step: 2
Training loss: 1.3110171524601804
Validation loss: 2.549812393075348

Epoch: 5| Step: 3
Training loss: 0.9577924231561111
Validation loss: 2.6074252936154267

Epoch: 5| Step: 4
Training loss: 1.2827711147458196
Validation loss: 2.4992075033167245

Epoch: 5| Step: 5
Training loss: 1.721226728360966
Validation loss: 2.3999389703059792

Epoch: 5| Step: 6
Training loss: 0.8389414353646747
Validation loss: 2.568009896443543

Epoch: 5| Step: 7
Training loss: 0.8527945958121051
Validation loss: 2.506526096371128

Epoch: 5| Step: 8
Training loss: 0.8912873732982209
Validation loss: 2.5188469472214647

Epoch: 5| Step: 9
Training loss: 1.2330378279347731
Validation loss: 2.501400201675447

Epoch: 5| Step: 10
Training loss: 1.1542740511372436
Validation loss: 2.5105989805519697

Epoch: 726| Step: 0
Training loss: 1.0744548191425274
Validation loss: 2.537751442893117

Epoch: 5| Step: 1
Training loss: 1.118865986357824
Validation loss: 2.549125246526474

Epoch: 5| Step: 2
Training loss: 0.8599820160648809
Validation loss: 2.5503415567644194

Epoch: 5| Step: 3
Training loss: 0.8107956102488567
Validation loss: 2.5202254370288335

Epoch: 5| Step: 4
Training loss: 1.1373170936165935
Validation loss: 2.5514056419525613

Epoch: 5| Step: 5
Training loss: 0.8002836216397595
Validation loss: 2.5841522652117597

Epoch: 5| Step: 6
Training loss: 1.1142870726157912
Validation loss: 2.606134376785197

Epoch: 5| Step: 7
Training loss: 1.4859327474652493
Validation loss: 2.6140264084569567

Epoch: 5| Step: 8
Training loss: 1.0369908611737313
Validation loss: 2.523855715360922

Epoch: 5| Step: 9
Training loss: 1.4736980122981154
Validation loss: 2.479339736959898

Epoch: 5| Step: 10
Training loss: 0.9203375587872978
Validation loss: 2.555953544858406

Epoch: 727| Step: 0
Training loss: 0.6242655491861216
Validation loss: 2.4783229065924757

Epoch: 5| Step: 1
Training loss: 0.9819251258822629
Validation loss: 2.481194487283651

Epoch: 5| Step: 2
Training loss: 0.9488420092028979
Validation loss: 2.582661981772991

Epoch: 5| Step: 3
Training loss: 1.1421358214244897
Validation loss: 2.446858343327714

Epoch: 5| Step: 4
Training loss: 1.0920281617337495
Validation loss: 2.4704196632272755

Epoch: 5| Step: 5
Training loss: 1.1529282978455966
Validation loss: 2.5703135841782014

Epoch: 5| Step: 6
Training loss: 1.203533747213751
Validation loss: 2.4128296836983623

Epoch: 5| Step: 7
Training loss: 1.54526335635212
Validation loss: 2.522187102266361

Epoch: 5| Step: 8
Training loss: 0.7582143524297725
Validation loss: 2.549887176364643

Epoch: 5| Step: 9
Training loss: 1.1436784190307239
Validation loss: 2.5650506609869645

Epoch: 5| Step: 10
Training loss: 1.7003468944938824
Validation loss: 2.5456578169441633

Epoch: 728| Step: 0
Training loss: 1.2369014140002963
Validation loss: 2.484480268658043

Epoch: 5| Step: 1
Training loss: 1.1761742628891092
Validation loss: 2.494729023904652

Epoch: 5| Step: 2
Training loss: 1.738981093209024
Validation loss: 2.4953713206178625

Epoch: 5| Step: 3
Training loss: 0.7057776323031102
Validation loss: 2.4668374109607916

Epoch: 5| Step: 4
Training loss: 0.8604530508432074
Validation loss: 2.585669479059922

Epoch: 5| Step: 5
Training loss: 1.0920200836270086
Validation loss: 2.5095945041779966

Epoch: 5| Step: 6
Training loss: 1.1145974393053004
Validation loss: 2.561972631116047

Epoch: 5| Step: 7
Training loss: 1.183378244049245
Validation loss: 2.479605548948044

Epoch: 5| Step: 8
Training loss: 0.776357782654808
Validation loss: 2.5050065556673475

Epoch: 5| Step: 9
Training loss: 1.0352906337815841
Validation loss: 2.497182655254471

Epoch: 5| Step: 10
Training loss: 1.0380030228381527
Validation loss: 2.5311756019288105

Epoch: 729| Step: 0
Training loss: 0.7835890278241313
Validation loss: 2.545040291901747

Epoch: 5| Step: 1
Training loss: 1.0926409411793279
Validation loss: 2.546995315009944

Epoch: 5| Step: 2
Training loss: 0.8281877961731464
Validation loss: 2.5484321183194183

Epoch: 5| Step: 3
Training loss: 0.9439846201912687
Validation loss: 2.509711814607718

Epoch: 5| Step: 4
Training loss: 0.9347301573666096
Validation loss: 2.4720571704886405

Epoch: 5| Step: 5
Training loss: 0.8951935960460483
Validation loss: 2.521891549198393

Epoch: 5| Step: 6
Training loss: 0.8608604078168081
Validation loss: 2.4793777176065817

Epoch: 5| Step: 7
Training loss: 1.0743719927982587
Validation loss: 2.5774172042815016

Epoch: 5| Step: 8
Training loss: 1.3984154640891069
Validation loss: 2.4664632742348394

Epoch: 5| Step: 9
Training loss: 1.5122414801482618
Validation loss: 2.508304504621604

Epoch: 5| Step: 10
Training loss: 1.539697583836989
Validation loss: 2.5456858333136636

Epoch: 730| Step: 0
Training loss: 1.4906664380725647
Validation loss: 2.5827028224238666

Epoch: 5| Step: 1
Training loss: 1.246943121557416
Validation loss: 2.533149806406246

Epoch: 5| Step: 2
Training loss: 1.439857871141077
Validation loss: 2.5258871364656263

Epoch: 5| Step: 3
Training loss: 1.1875183706368402
Validation loss: 2.5602933144678235

Epoch: 5| Step: 4
Training loss: 0.8455422052308927
Validation loss: 2.5308634448782836

Epoch: 5| Step: 5
Training loss: 1.206753103065334
Validation loss: 2.469238287998504

Epoch: 5| Step: 6
Training loss: 1.2080738293210618
Validation loss: 2.507350478983507

Epoch: 5| Step: 7
Training loss: 0.9060863478651456
Validation loss: 2.4866230532794606

Epoch: 5| Step: 8
Training loss: 1.0374262841015565
Validation loss: 2.4904304642416144

Epoch: 5| Step: 9
Training loss: 0.9746931877104815
Validation loss: 2.543830274129757

Epoch: 5| Step: 10
Training loss: 0.9344159898729685
Validation loss: 2.5122353997421563

Epoch: 731| Step: 0
Training loss: 1.3795338788160327
Validation loss: 2.4581210675862843

Epoch: 5| Step: 1
Training loss: 0.7827017837167799
Validation loss: 2.5191581244378116

Epoch: 5| Step: 2
Training loss: 1.0935113919069828
Validation loss: 2.4362389684203323

Epoch: 5| Step: 3
Training loss: 0.90257200846733
Validation loss: 2.5186363849864466

Epoch: 5| Step: 4
Training loss: 1.0215713726509081
Validation loss: 2.574778164703342

Epoch: 5| Step: 5
Training loss: 1.042665301694814
Validation loss: 2.4959915306843183

Epoch: 5| Step: 6
Training loss: 1.5401278453869043
Validation loss: 2.542107598480522

Epoch: 5| Step: 7
Training loss: 1.2219139502675793
Validation loss: 2.526255676791174

Epoch: 5| Step: 8
Training loss: 1.123519240842295
Validation loss: 2.5451100903702457

Epoch: 5| Step: 9
Training loss: 0.9807916846517133
Validation loss: 2.473728777992404

Epoch: 5| Step: 10
Training loss: 0.8799096377535436
Validation loss: 2.436731595488079

Epoch: 732| Step: 0
Training loss: 1.0084882732763012
Validation loss: 2.5166596700300383

Epoch: 5| Step: 1
Training loss: 1.1173254608121255
Validation loss: 2.55856828173565

Epoch: 5| Step: 2
Training loss: 1.182466278401839
Validation loss: 2.4856015319400364

Epoch: 5| Step: 3
Training loss: 1.2522358448662567
Validation loss: 2.3948454326641064

Epoch: 5| Step: 4
Training loss: 1.6116584947780603
Validation loss: 2.460463005141435

Epoch: 5| Step: 5
Training loss: 0.913967714530381
Validation loss: 2.510556071914336

Epoch: 5| Step: 6
Training loss: 1.0409008199000476
Validation loss: 2.502894291012444

Epoch: 5| Step: 7
Training loss: 1.1913109913250015
Validation loss: 2.4956037896897154

Epoch: 5| Step: 8
Training loss: 1.201246901239215
Validation loss: 2.561966709256215

Epoch: 5| Step: 9
Training loss: 1.055103756742611
Validation loss: 2.5446322035604383

Epoch: 5| Step: 10
Training loss: 1.1221620474053209
Validation loss: 2.5223791733200556

Epoch: 733| Step: 0
Training loss: 0.6619908274522198
Validation loss: 2.4778501486608255

Epoch: 5| Step: 1
Training loss: 0.933409253648637
Validation loss: 2.4936532767202464

Epoch: 5| Step: 2
Training loss: 0.9677360827707386
Validation loss: 2.5509529665904873

Epoch: 5| Step: 3
Training loss: 1.2315598751447652
Validation loss: 2.5092456070610734

Epoch: 5| Step: 4
Training loss: 1.2653675052880984
Validation loss: 2.480409542452954

Epoch: 5| Step: 5
Training loss: 1.0206875729461844
Validation loss: 2.601506659396771

Epoch: 5| Step: 6
Training loss: 1.7193633632342389
Validation loss: 2.433558746103531

Epoch: 5| Step: 7
Training loss: 0.9561941417261705
Validation loss: 2.529565185373889

Epoch: 5| Step: 8
Training loss: 1.0857610765033132
Validation loss: 2.492676430728309

Epoch: 5| Step: 9
Training loss: 1.1438125593242627
Validation loss: 2.5141506257860975

Epoch: 5| Step: 10
Training loss: 0.943081516706926
Validation loss: 2.478374380109733

Epoch: 734| Step: 0
Training loss: 1.2276686521847782
Validation loss: 2.5055893610019253

Epoch: 5| Step: 1
Training loss: 0.8971549125660621
Validation loss: 2.486097309844727

Epoch: 5| Step: 2
Training loss: 1.2174620547638164
Validation loss: 2.4476315833513125

Epoch: 5| Step: 3
Training loss: 0.7473700426992874
Validation loss: 2.4979319314574835

Epoch: 5| Step: 4
Training loss: 1.0395788186280421
Validation loss: 2.503780359585814

Epoch: 5| Step: 5
Training loss: 1.1743404647678466
Validation loss: 2.504406905695349

Epoch: 5| Step: 6
Training loss: 1.0293854706074776
Validation loss: 2.464526459718644

Epoch: 5| Step: 7
Training loss: 1.6204270060294315
Validation loss: 2.5276771223217036

Epoch: 5| Step: 8
Training loss: 1.0298341800023372
Validation loss: 2.4639989740688257

Epoch: 5| Step: 9
Training loss: 1.0447673362467467
Validation loss: 2.5370338553303817

Epoch: 5| Step: 10
Training loss: 1.157332094426598
Validation loss: 2.532168583385936

Epoch: 735| Step: 0
Training loss: 0.9103223133442151
Validation loss: 2.526712484611809

Epoch: 5| Step: 1
Training loss: 0.9108474791656554
Validation loss: 2.5506213831128677

Epoch: 5| Step: 2
Training loss: 0.9160932821122637
Validation loss: 2.515637004815753

Epoch: 5| Step: 3
Training loss: 1.438135669972055
Validation loss: 2.5181550195099143

Epoch: 5| Step: 4
Training loss: 0.798351229431903
Validation loss: 2.5507975336280055

Epoch: 5| Step: 5
Training loss: 1.1499485273866534
Validation loss: 2.526088552205833

Epoch: 5| Step: 6
Training loss: 1.0019729939474296
Validation loss: 2.5627638968325432

Epoch: 5| Step: 7
Training loss: 1.6893582179583388
Validation loss: 2.4960883271118335

Epoch: 5| Step: 8
Training loss: 0.846051961301838
Validation loss: 2.490663986321914

Epoch: 5| Step: 9
Training loss: 0.9793059608454907
Validation loss: 2.56369811860588

Epoch: 5| Step: 10
Training loss: 1.0683362773511516
Validation loss: 2.514417160267307

Epoch: 736| Step: 0
Training loss: 1.150939603167147
Validation loss: 2.554877292797837

Epoch: 5| Step: 1
Training loss: 0.8746670361926104
Validation loss: 2.4547858994678795

Epoch: 5| Step: 2
Training loss: 1.1373639979121208
Validation loss: 2.529937664236651

Epoch: 5| Step: 3
Training loss: 0.7701325753880682
Validation loss: 2.4906781535678957

Epoch: 5| Step: 4
Training loss: 1.0360558397643156
Validation loss: 2.542917770419887

Epoch: 5| Step: 5
Training loss: 1.1427017014669496
Validation loss: 2.520573610699263

Epoch: 5| Step: 6
Training loss: 1.2814004856217656
Validation loss: 2.5393033992307403

Epoch: 5| Step: 7
Training loss: 1.0278050652452828
Validation loss: 2.558230415979211

Epoch: 5| Step: 8
Training loss: 1.56172664577364
Validation loss: 2.5338032195485742

Epoch: 5| Step: 9
Training loss: 0.8249385998736839
Validation loss: 2.5985407763370634

Epoch: 5| Step: 10
Training loss: 1.2368759701162642
Validation loss: 2.5033302614102437

Epoch: 737| Step: 0
Training loss: 0.9612170797398186
Validation loss: 2.535923843751894

Epoch: 5| Step: 1
Training loss: 1.711689613891727
Validation loss: 2.454980457200472

Epoch: 5| Step: 2
Training loss: 1.022027420202398
Validation loss: 2.5681697390377236

Epoch: 5| Step: 3
Training loss: 1.166315190413894
Validation loss: 2.485226560099141

Epoch: 5| Step: 4
Training loss: 1.0629535716693355
Validation loss: 2.454398492510749

Epoch: 5| Step: 5
Training loss: 0.9206797399775853
Validation loss: 2.418238287567579

Epoch: 5| Step: 6
Training loss: 1.0697373564299033
Validation loss: 2.4759172312111875

Epoch: 5| Step: 7
Training loss: 1.0710933092646453
Validation loss: 2.5190205175862173

Epoch: 5| Step: 8
Training loss: 1.1089974419071562
Validation loss: 2.4445572166665794

Epoch: 5| Step: 9
Training loss: 1.180687941190627
Validation loss: 2.5159720526212435

Epoch: 5| Step: 10
Training loss: 0.9910752377381636
Validation loss: 2.4644784366243004

Epoch: 738| Step: 0
Training loss: 1.170671531701533
Validation loss: 2.5122641317045264

Epoch: 5| Step: 1
Training loss: 0.8688194109954176
Validation loss: 2.533097559471484

Epoch: 5| Step: 2
Training loss: 1.2069468052037051
Validation loss: 2.4620713572091057

Epoch: 5| Step: 3
Training loss: 0.9415035909765542
Validation loss: 2.4840476847909243

Epoch: 5| Step: 4
Training loss: 1.5982800597274902
Validation loss: 2.5260794275318137

Epoch: 5| Step: 5
Training loss: 1.4046228107497456
Validation loss: 2.4967971753693416

Epoch: 5| Step: 6
Training loss: 1.1841912099311334
Validation loss: 2.545288216717472

Epoch: 5| Step: 7
Training loss: 0.9154771470614037
Validation loss: 2.550286412104256

Epoch: 5| Step: 8
Training loss: 0.9493753123581091
Validation loss: 2.5033138472089487

Epoch: 5| Step: 9
Training loss: 1.2345427869888468
Validation loss: 2.629936983205191

Epoch: 5| Step: 10
Training loss: 0.7840922723790958
Validation loss: 2.541710521522056

Epoch: 739| Step: 0
Training loss: 0.80743240032155
Validation loss: 2.4689244356286624

Epoch: 5| Step: 1
Training loss: 1.0527260519912465
Validation loss: 2.5146113831079577

Epoch: 5| Step: 2
Training loss: 1.036742754430498
Validation loss: 2.581080656965573

Epoch: 5| Step: 3
Training loss: 0.9961862857695607
Validation loss: 2.539496727248962

Epoch: 5| Step: 4
Training loss: 1.1745411869880662
Validation loss: 2.484563098962852

Epoch: 5| Step: 5
Training loss: 1.1220236188371138
Validation loss: 2.4263922707312973

Epoch: 5| Step: 6
Training loss: 1.1462899714232477
Validation loss: 2.510518925975024

Epoch: 5| Step: 7
Training loss: 1.2033228525742647
Validation loss: 2.4194321182514855

Epoch: 5| Step: 8
Training loss: 1.6988972677658056
Validation loss: 2.517042500143857

Epoch: 5| Step: 9
Training loss: 1.0515342198461766
Validation loss: 2.5360670075695912

Epoch: 5| Step: 10
Training loss: 0.6854468813404013
Validation loss: 2.5002401626245914

Epoch: 740| Step: 0
Training loss: 1.0693970823878476
Validation loss: 2.4850771476671465

Epoch: 5| Step: 1
Training loss: 0.7780238104905572
Validation loss: 2.545025337356306

Epoch: 5| Step: 2
Training loss: 0.8327805990725957
Validation loss: 2.5321290062187933

Epoch: 5| Step: 3
Training loss: 0.7243146271186818
Validation loss: 2.5720989593044865

Epoch: 5| Step: 4
Training loss: 0.9797340467185467
Validation loss: 2.4951058566121107

Epoch: 5| Step: 5
Training loss: 1.0837745257179718
Validation loss: 2.5804959062386215

Epoch: 5| Step: 6
Training loss: 1.4079950737135494
Validation loss: 2.5384539161489

Epoch: 5| Step: 7
Training loss: 0.9989450970284284
Validation loss: 2.6075146283034236

Epoch: 5| Step: 8
Training loss: 1.7180802861151028
Validation loss: 2.5584636766325506

Epoch: 5| Step: 9
Training loss: 1.327262059527528
Validation loss: 2.5019782883691692

Epoch: 5| Step: 10
Training loss: 1.0132494213367074
Validation loss: 2.546085791274

Epoch: 741| Step: 0
Training loss: 0.6827632109356683
Validation loss: 2.480813224604862

Epoch: 5| Step: 1
Training loss: 0.9636878993786071
Validation loss: 2.5126177132534755

Epoch: 5| Step: 2
Training loss: 1.4985047676333882
Validation loss: 2.5098490518613765

Epoch: 5| Step: 3
Training loss: 1.3413151705108148
Validation loss: 2.4895444717562927

Epoch: 5| Step: 4
Training loss: 0.9095349462840683
Validation loss: 2.536017539025845

Epoch: 5| Step: 5
Training loss: 1.139106104975045
Validation loss: 2.492869121361264

Epoch: 5| Step: 6
Training loss: 1.064144992851612
Validation loss: 2.545865324118231

Epoch: 5| Step: 7
Training loss: 1.3112380909628947
Validation loss: 2.5199786849120684

Epoch: 5| Step: 8
Training loss: 1.0411337951808948
Validation loss: 2.4789657632012587

Epoch: 5| Step: 9
Training loss: 0.7801002052326419
Validation loss: 2.5138352807880913

Epoch: 5| Step: 10
Training loss: 0.8873266077577291
Validation loss: 2.49384010019147

Epoch: 742| Step: 0
Training loss: 0.8783147559351768
Validation loss: 2.589906971034728

Epoch: 5| Step: 1
Training loss: 0.9789728554536575
Validation loss: 2.498576178203512

Epoch: 5| Step: 2
Training loss: 1.2894489055981688
Validation loss: 2.480186238962058

Epoch: 5| Step: 3
Training loss: 0.8723725311051959
Validation loss: 2.558478574674036

Epoch: 5| Step: 4
Training loss: 1.6087986182489062
Validation loss: 2.535306090485486

Epoch: 5| Step: 5
Training loss: 1.3357913734872564
Validation loss: 2.4936040462564777

Epoch: 5| Step: 6
Training loss: 0.8235268965951194
Validation loss: 2.5915565294278697

Epoch: 5| Step: 7
Training loss: 1.2214842715505783
Validation loss: 2.535699365983414

Epoch: 5| Step: 8
Training loss: 0.7981354711408797
Validation loss: 2.5141056929833754

Epoch: 5| Step: 9
Training loss: 0.7868771269559709
Validation loss: 2.4617926603250155

Epoch: 5| Step: 10
Training loss: 1.0030104503410455
Validation loss: 2.478101864295428

Epoch: 743| Step: 0
Training loss: 0.823690199758052
Validation loss: 2.5831758753503222

Epoch: 5| Step: 1
Training loss: 1.3036507238991548
Validation loss: 2.529184541667655

Epoch: 5| Step: 2
Training loss: 1.2460724162126064
Validation loss: 2.485892288288682

Epoch: 5| Step: 3
Training loss: 0.9979153003298352
Validation loss: 2.582125325411521

Epoch: 5| Step: 4
Training loss: 1.3915091714806915
Validation loss: 2.5710136593515536

Epoch: 5| Step: 5
Training loss: 1.224643688542518
Validation loss: 2.500004968330615

Epoch: 5| Step: 6
Training loss: 1.5713972453921152
Validation loss: 2.482028629416593

Epoch: 5| Step: 7
Training loss: 0.710910712774986
Validation loss: 2.583601363769834

Epoch: 5| Step: 8
Training loss: 0.7273725690366745
Validation loss: 2.502533635282456

Epoch: 5| Step: 9
Training loss: 0.910092527590096
Validation loss: 2.551924057678737

Epoch: 5| Step: 10
Training loss: 0.9088579667821682
Validation loss: 2.563080277509093

Epoch: 744| Step: 0
Training loss: 1.2010603193878755
Validation loss: 2.497360007676793

Epoch: 5| Step: 1
Training loss: 0.8863624831727891
Validation loss: 2.551124427430521

Epoch: 5| Step: 2
Training loss: 1.1664605753384765
Validation loss: 2.475276838066903

Epoch: 5| Step: 3
Training loss: 1.0743176224029567
Validation loss: 2.459315897401375

Epoch: 5| Step: 4
Training loss: 0.8210377711297477
Validation loss: 2.539883142314846

Epoch: 5| Step: 5
Training loss: 1.217935094068626
Validation loss: 2.5163851444083023

Epoch: 5| Step: 6
Training loss: 1.5429079454247456
Validation loss: 2.4772696587405183

Epoch: 5| Step: 7
Training loss: 1.0905237298418615
Validation loss: 2.589102414544139

Epoch: 5| Step: 8
Training loss: 1.2754253014703516
Validation loss: 2.531924224919424

Epoch: 5| Step: 9
Training loss: 0.9613087564971754
Validation loss: 2.5249436835887713

Epoch: 5| Step: 10
Training loss: 1.0542017630563612
Validation loss: 2.5046312248464777

Epoch: 745| Step: 0
Training loss: 1.072787243095463
Validation loss: 2.5551521746951127

Epoch: 5| Step: 1
Training loss: 1.0917224619829473
Validation loss: 2.4554463288914214

Epoch: 5| Step: 2
Training loss: 1.2512712689858572
Validation loss: 2.4992278926909486

Epoch: 5| Step: 3
Training loss: 0.7727171500710833
Validation loss: 2.5254616649453454

Epoch: 5| Step: 4
Training loss: 1.1020454808869549
Validation loss: 2.509314364016105

Epoch: 5| Step: 5
Training loss: 1.1703480245294122
Validation loss: 2.519544345280813

Epoch: 5| Step: 6
Training loss: 1.0457508257252321
Validation loss: 2.5556468388520703

Epoch: 5| Step: 7
Training loss: 1.1467685639679501
Validation loss: 2.569558126264087

Epoch: 5| Step: 8
Training loss: 1.0237575933153857
Validation loss: 2.4850786352542396

Epoch: 5| Step: 9
Training loss: 1.1786594079360146
Validation loss: 2.602188841522929

Epoch: 5| Step: 10
Training loss: 1.6348730345958542
Validation loss: 2.543077702219735

Epoch: 746| Step: 0
Training loss: 0.7923686194800105
Validation loss: 2.5663008145739172

Epoch: 5| Step: 1
Training loss: 1.2491394895753252
Validation loss: 2.5477174887542726

Epoch: 5| Step: 2
Training loss: 0.8343827236546705
Validation loss: 2.5545921492283274

Epoch: 5| Step: 3
Training loss: 1.117967986527135
Validation loss: 2.458207942906517

Epoch: 5| Step: 4
Training loss: 1.1185687935980302
Validation loss: 2.5312232124089062

Epoch: 5| Step: 5
Training loss: 1.295298894021575
Validation loss: 2.5723949267227106

Epoch: 5| Step: 6
Training loss: 1.4556015404546585
Validation loss: 2.4809628989921455

Epoch: 5| Step: 7
Training loss: 1.0549986768777515
Validation loss: 2.559646585464872

Epoch: 5| Step: 8
Training loss: 1.07136845533566
Validation loss: 2.5315142693226083

Epoch: 5| Step: 9
Training loss: 1.11590353002577
Validation loss: 2.5310708644308484

Epoch: 5| Step: 10
Training loss: 1.5334782639024285
Validation loss: 2.5256216931680187

Epoch: 747| Step: 0
Training loss: 0.916775938948195
Validation loss: 2.582130566615364

Epoch: 5| Step: 1
Training loss: 0.7699181992565495
Validation loss: 2.492867640479825

Epoch: 5| Step: 2
Training loss: 0.906806248925094
Validation loss: 2.49986876174026

Epoch: 5| Step: 3
Training loss: 1.1140764575313977
Validation loss: 2.490591940450239

Epoch: 5| Step: 4
Training loss: 1.1355939195963953
Validation loss: 2.469706457928636

Epoch: 5| Step: 5
Training loss: 0.989223287569279
Validation loss: 2.533166849047375

Epoch: 5| Step: 6
Training loss: 1.0562885706252785
Validation loss: 2.516373238927377

Epoch: 5| Step: 7
Training loss: 1.2914537387615814
Validation loss: 2.4826668297135006

Epoch: 5| Step: 8
Training loss: 1.5574084677213618
Validation loss: 2.495938213193001

Epoch: 5| Step: 9
Training loss: 1.3211040042995825
Validation loss: 2.583274525724931

Epoch: 5| Step: 10
Training loss: 0.8502366479858873
Validation loss: 2.4948108778626685

Epoch: 748| Step: 0
Training loss: 0.8798093098244344
Validation loss: 2.447500077099226

Epoch: 5| Step: 1
Training loss: 1.2037619849031256
Validation loss: 2.487712612579401

Epoch: 5| Step: 2
Training loss: 1.128684368570049
Validation loss: 2.4982883931492768

Epoch: 5| Step: 3
Training loss: 0.8557967162602154
Validation loss: 2.575621175705148

Epoch: 5| Step: 4
Training loss: 1.203494968750869
Validation loss: 2.49837485887249

Epoch: 5| Step: 5
Training loss: 0.8189609838142161
Validation loss: 2.4834984974328127

Epoch: 5| Step: 6
Training loss: 0.8590939148799392
Validation loss: 2.5517459113087355

Epoch: 5| Step: 7
Training loss: 1.785585648126761
Validation loss: 2.4860051495849156

Epoch: 5| Step: 8
Training loss: 0.9812655307974251
Validation loss: 2.5457164666755143

Epoch: 5| Step: 9
Training loss: 0.9868889451204302
Validation loss: 2.514804367645324

Epoch: 5| Step: 10
Training loss: 0.860117089040993
Validation loss: 2.5974252584995994

Epoch: 749| Step: 0
Training loss: 1.1105478561134043
Validation loss: 2.5671429514070923

Epoch: 5| Step: 1
Training loss: 1.024614080024879
Validation loss: 2.4532855124859934

Epoch: 5| Step: 2
Training loss: 1.2429357230583822
Validation loss: 2.6308234350935744

Epoch: 5| Step: 3
Training loss: 0.8242086979402213
Validation loss: 2.4526188316899176

Epoch: 5| Step: 4
Training loss: 1.5555422173034175
Validation loss: 2.496247806455576

Epoch: 5| Step: 5
Training loss: 1.054183161208183
Validation loss: 2.505950038846782

Epoch: 5| Step: 6
Training loss: 0.7535953177021132
Validation loss: 2.54750701734588

Epoch: 5| Step: 7
Training loss: 0.7155256927083833
Validation loss: 2.5278514975792894

Epoch: 5| Step: 8
Training loss: 1.1539019895150802
Validation loss: 2.5100451642888597

Epoch: 5| Step: 9
Training loss: 1.134635878481044
Validation loss: 2.473802121233205

Epoch: 5| Step: 10
Training loss: 1.3997815029757317
Validation loss: 2.5292930781325293

Epoch: 750| Step: 0
Training loss: 0.8300040896441346
Validation loss: 2.492630346659775

Epoch: 5| Step: 1
Training loss: 0.7425299406597582
Validation loss: 2.4972737244493888

Epoch: 5| Step: 2
Training loss: 0.8013625849332016
Validation loss: 2.5063262042446532

Epoch: 5| Step: 3
Training loss: 0.9534761376118005
Validation loss: 2.4962406544336835

Epoch: 5| Step: 4
Training loss: 1.2616456190711154
Validation loss: 2.4888852569048296

Epoch: 5| Step: 5
Training loss: 0.950456730322754
Validation loss: 2.4499185011992894

Epoch: 5| Step: 6
Training loss: 0.8138941761043296
Validation loss: 2.4968444351690526

Epoch: 5| Step: 7
Training loss: 0.9383532773592248
Validation loss: 2.522134042247857

Epoch: 5| Step: 8
Training loss: 1.736579868187922
Validation loss: 2.468061723738581

Epoch: 5| Step: 9
Training loss: 1.1370049604611319
Validation loss: 2.599910695661823

Epoch: 5| Step: 10
Training loss: 1.2251363834054254
Validation loss: 2.540056505021257

Testing loss: 2.6198708969077527
