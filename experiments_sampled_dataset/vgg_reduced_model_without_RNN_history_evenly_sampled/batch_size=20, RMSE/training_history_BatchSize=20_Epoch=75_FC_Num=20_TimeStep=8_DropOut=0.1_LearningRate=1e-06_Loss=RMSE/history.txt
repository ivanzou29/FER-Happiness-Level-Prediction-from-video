Epoch: 1| Step: 0
Training loss: 3.3549096526532307
Validation loss: 4.999552737504919

Epoch: 5| Step: 1
Training loss: 5.605343190558054
Validation loss: 4.998129706109592

Epoch: 5| Step: 2
Training loss: 4.600232383829049
Validation loss: 4.996335542853252

Epoch: 5| Step: 3
Training loss: 5.19968059732605
Validation loss: 4.993421620111827

Epoch: 5| Step: 4
Training loss: 4.707392685812126
Validation loss: 4.9914101658501115

Epoch: 5| Step: 5
Training loss: 5.723257154351356
Validation loss: 4.988141166436661

Epoch: 5| Step: 6
Training loss: 5.446918792461022
Validation loss: 4.9860358847485955

Epoch: 5| Step: 7
Training loss: 4.406793222692478
Validation loss: 4.984554861910398

Epoch: 5| Step: 8
Training loss: 5.649162784088702
Validation loss: 4.982342487475723

Epoch: 5| Step: 9
Training loss: 5.480461441437572
Validation loss: 4.980452163028462

Epoch: 5| Step: 10
Training loss: 5.041930430845156
Validation loss: 4.976169786982265

Epoch: 2| Step: 0
Training loss: 5.114275247756465
Validation loss: 4.976136738880489

Epoch: 5| Step: 1
Training loss: 5.85203055329342
Validation loss: 4.972943634695968

Epoch: 5| Step: 2
Training loss: 4.6680574161296695
Validation loss: 4.970427193100599

Epoch: 5| Step: 3
Training loss: 4.307217887544828
Validation loss: 4.968335150413139

Epoch: 5| Step: 4
Training loss: 4.3589840512002525
Validation loss: 4.964930823849347

Epoch: 5| Step: 5
Training loss: 5.592659103319928
Validation loss: 4.961864447041536

Epoch: 5| Step: 6
Training loss: 4.727071334310304
Validation loss: 4.961076890328982

Epoch: 5| Step: 7
Training loss: 4.482785039414083
Validation loss: 4.9586046943782955

Epoch: 5| Step: 8
Training loss: 5.928719865053607
Validation loss: 4.956128087171327

Epoch: 5| Step: 9
Training loss: 4.852080828855902
Validation loss: 4.953712806075255

Epoch: 5| Step: 10
Training loss: 5.261183679642586
Validation loss: 4.950191276088909

Epoch: 3| Step: 0
Training loss: 4.63460286172538
Validation loss: 4.94765067749432

Epoch: 5| Step: 1
Training loss: 5.527657586883177
Validation loss: 4.945670459599588

Epoch: 5| Step: 2
Training loss: 4.994761392967702
Validation loss: 4.944044472521423

Epoch: 5| Step: 3
Training loss: 5.14079214827279
Validation loss: 4.941642602853884

Epoch: 5| Step: 4
Training loss: 5.1184183052849415
Validation loss: 4.938947069656603

Epoch: 5| Step: 5
Training loss: 4.9697061254553745
Validation loss: 4.935058688034751

Epoch: 5| Step: 6
Training loss: 4.9151577115683525
Validation loss: 4.933388735291864

Epoch: 5| Step: 7
Training loss: 4.6253484646229035
Validation loss: 4.930371431553116

Epoch: 5| Step: 8
Training loss: 4.863622838781799
Validation loss: 4.928588318210385

Epoch: 5| Step: 9
Training loss: 4.9629713319883955
Validation loss: 4.925991902217227

Epoch: 5| Step: 10
Training loss: 5.393686326447836
Validation loss: 4.921626554912777

Epoch: 4| Step: 0
Training loss: 3.9080097354623184
Validation loss: 4.91934982815976

Epoch: 5| Step: 1
Training loss: 5.481200600970208
Validation loss: 4.918507624307679

Epoch: 5| Step: 2
Training loss: 5.367893044908509
Validation loss: 4.916091701091943

Epoch: 5| Step: 3
Training loss: 5.030939128109401
Validation loss: 4.914759351313074

Epoch: 5| Step: 4
Training loss: 4.131071073550015
Validation loss: 4.909952633403299

Epoch: 5| Step: 5
Training loss: 5.206939490411957
Validation loss: 4.907293449757801

Epoch: 5| Step: 6
Training loss: 4.916192155774629
Validation loss: 4.904330526381136

Epoch: 5| Step: 7
Training loss: 4.996646137734032
Validation loss: 4.901091537630728

Epoch: 5| Step: 8
Training loss: 5.5351874351296
Validation loss: 4.898316937570767

Epoch: 5| Step: 9
Training loss: 5.518533517948469
Validation loss: 4.894937926731183

Epoch: 5| Step: 10
Training loss: 4.306073472788378
Validation loss: 4.891690802723809

Epoch: 5| Step: 0
Training loss: 5.655307585887014
Validation loss: 4.888797453537684

Epoch: 5| Step: 1
Training loss: 4.68126925577805
Validation loss: 4.886134171328831

Epoch: 5| Step: 2
Training loss: 4.458026744722943
Validation loss: 4.88180149668661

Epoch: 5| Step: 3
Training loss: 4.795610192767097
Validation loss: 4.879035842041283

Epoch: 5| Step: 4
Training loss: 5.190987942550257
Validation loss: 4.879593047760016

Epoch: 5| Step: 5
Training loss: 5.3961503612022454
Validation loss: 4.875104435553283

Epoch: 5| Step: 6
Training loss: 5.280908155946104
Validation loss: 4.873143404470375

Epoch: 5| Step: 7
Training loss: 4.952694847129116
Validation loss: 4.8694761737226315

Epoch: 5| Step: 8
Training loss: 4.80802769122028
Validation loss: 4.866295278259677

Epoch: 5| Step: 9
Training loss: 4.001265802373073
Validation loss: 4.863421210558097

Epoch: 5| Step: 10
Training loss: 5.091578857530458
Validation loss: 4.8608379458757796

Epoch: 6| Step: 0
Training loss: 5.286627384984308
Validation loss: 4.854628393310708

Epoch: 5| Step: 1
Training loss: 4.467609393334007
Validation loss: 4.853333338784028

Epoch: 5| Step: 2
Training loss: 5.042062076584426
Validation loss: 4.849936422056686

Epoch: 5| Step: 3
Training loss: 5.507315538861023
Validation loss: 4.845674005757466

Epoch: 5| Step: 4
Training loss: 5.058236858489048
Validation loss: 4.843553003598236

Epoch: 5| Step: 5
Training loss: 4.853066621270839
Validation loss: 4.840350552512406

Epoch: 5| Step: 6
Training loss: 4.733588930849379
Validation loss: 4.837315830613617

Epoch: 5| Step: 7
Training loss: 4.387696073231906
Validation loss: 4.832796562751024

Epoch: 5| Step: 8
Training loss: 4.772631088542694
Validation loss: 4.8309833738893

Epoch: 5| Step: 9
Training loss: 5.413167243689622
Validation loss: 4.825360690468882

Epoch: 5| Step: 10
Training loss: 4.368954432429068
Validation loss: 4.822716622447581

Epoch: 7| Step: 0
Training loss: 3.7572771035971426
Validation loss: 4.818307060767993

Epoch: 5| Step: 1
Training loss: 5.210609162608436
Validation loss: 4.81525165299132

Epoch: 5| Step: 2
Training loss: 4.6711214918712285
Validation loss: 4.811866922106772

Epoch: 5| Step: 3
Training loss: 4.473449796552476
Validation loss: 4.807140346315937

Epoch: 5| Step: 4
Training loss: 5.244371030494807
Validation loss: 4.805033666087653

Epoch: 5| Step: 5
Training loss: 4.123545534743082
Validation loss: 4.801282560427321

Epoch: 5| Step: 6
Training loss: 4.338126075259758
Validation loss: 4.798022591311613

Epoch: 5| Step: 7
Training loss: 5.040592594125335
Validation loss: 4.795512275828825

Epoch: 5| Step: 8
Training loss: 4.993899247442174
Validation loss: 4.790950490853429

Epoch: 5| Step: 9
Training loss: 5.865533222177567
Validation loss: 4.787100348097979

Epoch: 5| Step: 10
Training loss: 5.685060418041933
Validation loss: 4.782405661327639

Epoch: 8| Step: 0
Training loss: 5.307179378361123
Validation loss: 4.779276813396064

Epoch: 5| Step: 1
Training loss: 4.6078763950247374
Validation loss: 4.774732816737854

Epoch: 5| Step: 2
Training loss: 4.186043101563161
Validation loss: 4.7691599860531975

Epoch: 5| Step: 3
Training loss: 4.812341464515351
Validation loss: 4.764613264746101

Epoch: 5| Step: 4
Training loss: 4.272464620534127
Validation loss: 4.761146431133222

Epoch: 5| Step: 5
Training loss: 4.335241973353886
Validation loss: 4.75643696744868

Epoch: 5| Step: 6
Training loss: 5.47058667539397
Validation loss: 4.754907356059204

Epoch: 5| Step: 7
Training loss: 4.543384168923083
Validation loss: 4.747426910439976

Epoch: 5| Step: 8
Training loss: 4.912195964072802
Validation loss: 4.7444439070509015

Epoch: 5| Step: 9
Training loss: 5.131372908910231
Validation loss: 4.7389533989947115

Epoch: 5| Step: 10
Training loss: 5.534263005730895
Validation loss: 4.733851477464473

Epoch: 9| Step: 0
Training loss: 4.725737595888637
Validation loss: 4.730033062602502

Epoch: 5| Step: 1
Training loss: 5.716254351606116
Validation loss: 4.726581767826102

Epoch: 5| Step: 2
Training loss: 5.2085339723724005
Validation loss: 4.719573485509465

Epoch: 5| Step: 3
Training loss: 3.969188035235622
Validation loss: 4.712674481573353

Epoch: 5| Step: 4
Training loss: 4.466704213757961
Validation loss: 4.711418707248063

Epoch: 5| Step: 5
Training loss: 5.141834986243417
Validation loss: 4.704953743353286

Epoch: 5| Step: 6
Training loss: 5.656573207325183
Validation loss: 4.698580371832843

Epoch: 5| Step: 7
Training loss: 4.86406518217381
Validation loss: 4.693252103488078

Epoch: 5| Step: 8
Training loss: 4.451045678539627
Validation loss: 4.688876945587185

Epoch: 5| Step: 9
Training loss: 4.029287880958212
Validation loss: 4.685750408095187

Epoch: 5| Step: 10
Training loss: 3.933680301384567
Validation loss: 4.678493058276294

Epoch: 10| Step: 0
Training loss: 5.072473944027884
Validation loss: 4.674148520546032

Epoch: 5| Step: 1
Training loss: 4.067899431664063
Validation loss: 4.669097728991028

Epoch: 5| Step: 2
Training loss: 4.641138530022391
Validation loss: 4.6618345567902795

Epoch: 5| Step: 3
Training loss: 4.711189124123212
Validation loss: 4.65882168578546

Epoch: 5| Step: 4
Training loss: 5.558105104136914
Validation loss: 4.653850688518414

Epoch: 5| Step: 5
Training loss: 4.403103618150267
Validation loss: 4.648969121273177

Epoch: 5| Step: 6
Training loss: 4.285635602319584
Validation loss: 4.641120728104107

Epoch: 5| Step: 7
Training loss: 4.786630831471848
Validation loss: 4.634375508393939

Epoch: 5| Step: 8
Training loss: 4.492978445993494
Validation loss: 4.63351394225766

Epoch: 5| Step: 9
Training loss: 5.172833771591314
Validation loss: 4.625096855269105

Epoch: 5| Step: 10
Training loss: 4.698964049428064
Validation loss: 4.623103659020574

Epoch: 11| Step: 0
Training loss: 3.8395618478826226
Validation loss: 4.614486442579647

Epoch: 5| Step: 1
Training loss: 5.294145899429233
Validation loss: 4.609078942731598

Epoch: 5| Step: 2
Training loss: 3.8483370570752244
Validation loss: 4.60191361508252

Epoch: 5| Step: 3
Training loss: 4.7201584488733745
Validation loss: 4.595244696256937

Epoch: 5| Step: 4
Training loss: 5.038790531359773
Validation loss: 4.587299607858002

Epoch: 5| Step: 5
Training loss: 5.68745372040752
Validation loss: 4.580229851600485

Epoch: 5| Step: 6
Training loss: 5.098643567582269
Validation loss: 4.57631606761617

Epoch: 5| Step: 7
Training loss: 5.375512741827409
Validation loss: 4.570198171381271

Epoch: 5| Step: 8
Training loss: 3.4594833729213863
Validation loss: 4.560227881758717

Epoch: 5| Step: 9
Training loss: 3.572791910171404
Validation loss: 4.553123392287008

Epoch: 5| Step: 10
Training loss: 4.821490126928332
Validation loss: 4.549721665170293

Epoch: 12| Step: 0
Training loss: 4.567965434663475
Validation loss: 4.544272336975163

Epoch: 5| Step: 1
Training loss: 4.440919015642057
Validation loss: 4.532869513928926

Epoch: 5| Step: 2
Training loss: 4.38791994003383
Validation loss: 4.526624822708764

Epoch: 5| Step: 3
Training loss: 4.192789864389083
Validation loss: 4.525971025230736

Epoch: 5| Step: 4
Training loss: 4.59121239567579
Validation loss: 4.511275145257011

Epoch: 5| Step: 5
Training loss: 4.649816382279629
Validation loss: 4.508274644645548

Epoch: 5| Step: 6
Training loss: 5.164956804595268
Validation loss: 4.4993020066678975

Epoch: 5| Step: 7
Training loss: 4.705643191992121
Validation loss: 4.490266383894036

Epoch: 5| Step: 8
Training loss: 3.610350109674782
Validation loss: 4.4851858452078845

Epoch: 5| Step: 9
Training loss: 5.193809624615446
Validation loss: 4.476768078463083

Epoch: 5| Step: 10
Training loss: 4.943559429291066
Validation loss: 4.466558551137992

Epoch: 13| Step: 0
Training loss: 4.27574929257311
Validation loss: 4.461944292336251

Epoch: 5| Step: 1
Training loss: 4.689187115008373
Validation loss: 4.455843098422305

Epoch: 5| Step: 2
Training loss: 4.5417678308448215
Validation loss: 4.447964851610424

Epoch: 5| Step: 3
Training loss: 3.636125395296458
Validation loss: 4.435718093683943

Epoch: 5| Step: 4
Training loss: 4.223044237350023
Validation loss: 4.427124563335223

Epoch: 5| Step: 5
Training loss: 4.561221008794076
Validation loss: 4.4216101469378675

Epoch: 5| Step: 6
Training loss: 4.264374154828941
Validation loss: 4.407804951495544

Epoch: 5| Step: 7
Training loss: 5.25873710585406
Validation loss: 4.404996483171114

Epoch: 5| Step: 8
Training loss: 4.53917343345508
Validation loss: 4.392274618712457

Epoch: 5| Step: 9
Training loss: 4.898510702702628
Validation loss: 4.38308706946719

Epoch: 5| Step: 10
Training loss: 4.611696027453868
Validation loss: 4.3746480375366215

Epoch: 14| Step: 0
Training loss: 3.811565096933172
Validation loss: 4.369318400530454

Epoch: 5| Step: 1
Training loss: 4.546688534822946
Validation loss: 4.356268133300878

Epoch: 5| Step: 2
Training loss: 4.261692344241063
Validation loss: 4.342290687903213

Epoch: 5| Step: 3
Training loss: 5.379170950787663
Validation loss: 4.340118419891064

Epoch: 5| Step: 4
Training loss: 5.313138138086535
Validation loss: 4.32257883901869

Epoch: 5| Step: 5
Training loss: 4.915186039458754
Validation loss: 4.317805408833424

Epoch: 5| Step: 6
Training loss: 4.588704978412346
Validation loss: 4.3093530635148545

Epoch: 5| Step: 7
Training loss: 3.5034862594062837
Validation loss: 4.296599546610689

Epoch: 5| Step: 8
Training loss: 3.0256691121725425
Validation loss: 4.284471143641245

Epoch: 5| Step: 9
Training loss: 4.907824415540395
Validation loss: 4.278593746679114

Epoch: 5| Step: 10
Training loss: 3.541818249020443
Validation loss: 4.26123563996988

Epoch: 15| Step: 0
Training loss: 4.121329321614237
Validation loss: 4.254694601203693

Epoch: 5| Step: 1
Training loss: 4.788287798652521
Validation loss: 4.2412812597460094

Epoch: 5| Step: 2
Training loss: 5.352063944914988
Validation loss: 4.235583259774035

Epoch: 5| Step: 3
Training loss: 4.20176567020514
Validation loss: 4.223142516769223

Epoch: 5| Step: 4
Training loss: 3.0643283290993
Validation loss: 4.207873452196975

Epoch: 5| Step: 5
Training loss: 4.436127356335801
Validation loss: 4.204688135952024

Epoch: 5| Step: 6
Training loss: 4.434789770190481
Validation loss: 4.186975717209501

Epoch: 5| Step: 7
Training loss: 4.12004809379284
Validation loss: 4.1816791379133615

Epoch: 5| Step: 8
Training loss: 3.8663141670908563
Validation loss: 4.163280579643663

Epoch: 5| Step: 9
Training loss: 4.410762991782457
Validation loss: 4.15721319428679

Epoch: 5| Step: 10
Training loss: 4.253935170141019
Validation loss: 4.13781667316053

Epoch: 16| Step: 0
Training loss: 4.237361741412679
Validation loss: 4.128683002855967

Epoch: 5| Step: 1
Training loss: 4.282324217636499
Validation loss: 4.121331267361686

Epoch: 5| Step: 2
Training loss: 3.905326795201566
Validation loss: 4.109630332078555

Epoch: 5| Step: 3
Training loss: 4.454348961454429
Validation loss: 4.091629700384804

Epoch: 5| Step: 4
Training loss: 4.539535208953674
Validation loss: 4.085197692803585

Epoch: 5| Step: 5
Training loss: 3.2310508563361346
Validation loss: 4.0652716963582245

Epoch: 5| Step: 6
Training loss: 4.333719872083047
Validation loss: 4.058791393303909

Epoch: 5| Step: 7
Training loss: 4.389256817382135
Validation loss: 4.043429949227415

Epoch: 5| Step: 8
Training loss: 4.24158429938324
Validation loss: 4.029182002220175

Epoch: 5| Step: 9
Training loss: 4.118740765991048
Validation loss: 4.018249619276469

Epoch: 5| Step: 10
Training loss: 4.153275422069596
Validation loss: 4.000395240022706

Epoch: 17| Step: 0
Training loss: 3.590920437310909
Validation loss: 3.9881179308659465

Epoch: 5| Step: 1
Training loss: 4.724739366235711
Validation loss: 3.977877302273494

Epoch: 5| Step: 2
Training loss: 4.902312235331971
Validation loss: 3.952682460619123

Epoch: 5| Step: 3
Training loss: 4.455751521197333
Validation loss: 3.9504710058766355

Epoch: 5| Step: 4
Training loss: 3.93704911329793
Validation loss: 3.9305844979069913

Epoch: 5| Step: 5
Training loss: 3.7950040501106774
Validation loss: 3.9094996773343045

Epoch: 5| Step: 6
Training loss: 4.093628859729584
Validation loss: 3.8990488176621794

Epoch: 5| Step: 7
Training loss: 3.6884925928795154
Validation loss: 3.8871645861305844

Epoch: 5| Step: 8
Training loss: 3.398208785856235
Validation loss: 3.8656949882661835

Epoch: 5| Step: 9
Training loss: 3.343806186097015
Validation loss: 3.8547764094885837

Epoch: 5| Step: 10
Training loss: 4.273649723006795
Validation loss: 3.8358134494491485

Epoch: 18| Step: 0
Training loss: 4.034721831195672
Validation loss: 3.820295651108445

Epoch: 5| Step: 1
Training loss: 3.571608560658809
Validation loss: 3.8103684132182605

Epoch: 5| Step: 2
Training loss: 4.0678633278962755
Validation loss: 3.796544042906426

Epoch: 5| Step: 3
Training loss: 4.07472478955275
Validation loss: 3.77668072965596

Epoch: 5| Step: 4
Training loss: 4.324731701593925
Validation loss: 3.770423955773385

Epoch: 5| Step: 5
Training loss: 3.7599554791756913
Validation loss: 3.7421038430715847

Epoch: 5| Step: 6
Training loss: 3.907284286900203
Validation loss: 3.7295108324015804

Epoch: 5| Step: 7
Training loss: 3.6088626382318814
Validation loss: 3.711422756140675

Epoch: 5| Step: 8
Training loss: 3.8890624068165542
Validation loss: 3.691629838094273

Epoch: 5| Step: 9
Training loss: 3.41016268210662
Validation loss: 3.685421685609038

Epoch: 5| Step: 10
Training loss: 4.058715935961536
Validation loss: 3.6631802771670388

Epoch: 19| Step: 0
Training loss: 4.824450826275099
Validation loss: 3.639133599794299

Epoch: 5| Step: 1
Training loss: 3.008413121089109
Validation loss: 3.622374823435683

Epoch: 5| Step: 2
Training loss: 3.6876737909258255
Validation loss: 3.6047830224762833

Epoch: 5| Step: 3
Training loss: 4.018853815378196
Validation loss: 3.590636931585835

Epoch: 5| Step: 4
Training loss: 3.552622704745804
Validation loss: 3.575767194856114

Epoch: 5| Step: 5
Training loss: 3.366655135056289
Validation loss: 3.5537042991876624

Epoch: 5| Step: 6
Training loss: 4.230471229728613
Validation loss: 3.536508630170199

Epoch: 5| Step: 7
Training loss: 3.8826546895982994
Validation loss: 3.5186070928367266

Epoch: 5| Step: 8
Training loss: 3.1557636452807247
Validation loss: 3.4995194001142993

Epoch: 5| Step: 9
Training loss: 3.5116599547966714
Validation loss: 3.480211599253743

Epoch: 5| Step: 10
Training loss: 3.313832285005832
Validation loss: 3.4653759819136396

Epoch: 20| Step: 0
Training loss: 3.8301924124808635
Validation loss: 3.451902857107719

Epoch: 5| Step: 1
Training loss: 3.0707636300349477
Validation loss: 3.4365604835757995

Epoch: 5| Step: 2
Training loss: 3.976486115387139
Validation loss: 3.412585407822859

Epoch: 5| Step: 3
Training loss: 3.422467602840482
Validation loss: 3.398356904877682

Epoch: 5| Step: 4
Training loss: 3.480822064654925
Validation loss: 3.3760871579460425

Epoch: 5| Step: 5
Training loss: 3.1315027862054037
Validation loss: 3.369057863469435

Epoch: 5| Step: 6
Training loss: 3.4217403855692137
Validation loss: 3.3418995464900667

Epoch: 5| Step: 7
Training loss: 3.713818012386441
Validation loss: 3.3281984176213864

Epoch: 5| Step: 8
Training loss: 3.9543592614454117
Validation loss: 3.3115698773332114

Epoch: 5| Step: 9
Training loss: 3.163478618483851
Validation loss: 3.2922078740814333

Epoch: 5| Step: 10
Training loss: 3.781569033948806
Validation loss: 3.268312785042239

Epoch: 21| Step: 0
Training loss: 3.247974057737581
Validation loss: 3.2524130250686785

Epoch: 5| Step: 1
Training loss: 3.802095066557595
Validation loss: 3.2377921908197087

Epoch: 5| Step: 2
Training loss: 2.8789893957421757
Validation loss: 3.22567913239981

Epoch: 5| Step: 3
Training loss: 3.404612716406708
Validation loss: 3.208671947222001

Epoch: 5| Step: 4
Training loss: 2.5376232587070726
Validation loss: 3.1994460593575935

Epoch: 5| Step: 5
Training loss: 3.311019854671268
Validation loss: 3.1662768127752647

Epoch: 5| Step: 6
Training loss: 2.9095933613027793
Validation loss: 3.1551951884856475

Epoch: 5| Step: 7
Training loss: 3.809263763180553
Validation loss: 3.1363489881664655

Epoch: 5| Step: 8
Training loss: 3.875894504792445
Validation loss: 3.1258703713791114

Epoch: 5| Step: 9
Training loss: 3.585788831766381
Validation loss: 3.093230242680369

Epoch: 5| Step: 10
Training loss: 3.533460212324814
Validation loss: 3.087085073216179

Epoch: 22| Step: 0
Training loss: 3.543518629375807
Validation loss: 3.0716883141702156

Epoch: 5| Step: 1
Training loss: 3.5806799682936417
Validation loss: 3.0541550430013764

Epoch: 5| Step: 2
Training loss: 3.4715717282791956
Validation loss: 3.0276123605171184

Epoch: 5| Step: 3
Training loss: 3.3933191802273663
Validation loss: 3.018729792423052

Epoch: 5| Step: 4
Training loss: 2.579850422862865
Validation loss: 2.9939801309751464

Epoch: 5| Step: 5
Training loss: 4.0537301111101
Validation loss: 2.9758678983737252

Epoch: 5| Step: 6
Training loss: 3.0946336505360814
Validation loss: 2.9643650756126565

Epoch: 5| Step: 7
Training loss: 3.040186813788247
Validation loss: 2.9466825564782013

Epoch: 5| Step: 8
Training loss: 2.7909365216331317
Validation loss: 2.9275330339773387

Epoch: 5| Step: 9
Training loss: 2.760297482394732
Validation loss: 2.9289049729174548

Epoch: 5| Step: 10
Training loss: 2.7244443344391382
Validation loss: 2.8986221527522904

Epoch: 23| Step: 0
Training loss: 3.2668631364816068
Validation loss: 2.894779730440484

Epoch: 5| Step: 1
Training loss: 2.311236887142105
Validation loss: 2.8733495136274887

Epoch: 5| Step: 2
Training loss: 3.3246945176300158
Validation loss: 2.871956513095066

Epoch: 5| Step: 3
Training loss: 4.024799716302372
Validation loss: 2.842765144445984

Epoch: 5| Step: 4
Training loss: 2.486653560607299
Validation loss: 2.8278715765363187

Epoch: 5| Step: 5
Training loss: 3.4032103248457504
Validation loss: 2.8252140434154662

Epoch: 5| Step: 6
Training loss: 3.2494937795921994
Validation loss: 2.8158330348399057

Epoch: 5| Step: 7
Training loss: 2.876381915141473
Validation loss: 2.791831156023684

Epoch: 5| Step: 8
Training loss: 2.9387997937253396
Validation loss: 2.787584444850307

Epoch: 5| Step: 9
Training loss: 2.7869889274078825
Validation loss: 2.780726863952316

Epoch: 5| Step: 10
Training loss: 3.0258432521323058
Validation loss: 2.7620915831644397

Epoch: 24| Step: 0
Training loss: 2.932946592180882
Validation loss: 2.7508288371518796

Epoch: 5| Step: 1
Training loss: 3.333806020282461
Validation loss: 2.727173689457577

Epoch: 5| Step: 2
Training loss: 2.783225997027731
Validation loss: 2.737650614646522

Epoch: 5| Step: 3
Training loss: 2.832412757169678
Validation loss: 2.7261657078229993

Epoch: 5| Step: 4
Training loss: 3.114144965274753
Validation loss: 2.709682980862295

Epoch: 5| Step: 5
Training loss: 3.428267547787282
Validation loss: 2.7043524899946014

Epoch: 5| Step: 6
Training loss: 2.3026846766265465
Validation loss: 2.696026093604114

Epoch: 5| Step: 7
Training loss: 3.504459129100612
Validation loss: 2.682644260901698

Epoch: 5| Step: 8
Training loss: 2.861620245593862
Validation loss: 2.683992860495457

Epoch: 5| Step: 9
Training loss: 2.889928455457182
Validation loss: 2.6592740299107533

Epoch: 5| Step: 10
Training loss: 3.082923518258861
Validation loss: 2.657969999472271

Epoch: 25| Step: 0
Training loss: 3.0453852214712938
Validation loss: 2.6505818065566955

Epoch: 5| Step: 1
Training loss: 3.5448651101687907
Validation loss: 2.637696227080774

Epoch: 5| Step: 2
Training loss: 2.70160063170069
Validation loss: 2.6320956137119165

Epoch: 5| Step: 3
Training loss: 2.1950547688109823
Validation loss: 2.6279794901040026

Epoch: 5| Step: 4
Training loss: 3.0803106458483627
Validation loss: 2.6190215089634066

Epoch: 5| Step: 5
Training loss: 3.081496198308612
Validation loss: 2.622197829013078

Epoch: 5| Step: 6
Training loss: 2.59899564931578
Validation loss: 2.606169847100008

Epoch: 5| Step: 7
Training loss: 3.637107492355664
Validation loss: 2.6019783253085382

Epoch: 5| Step: 8
Training loss: 3.147647730213867
Validation loss: 2.6019922569317147

Epoch: 5| Step: 9
Training loss: 2.898851390807457
Validation loss: 2.5916383907201497

Epoch: 5| Step: 10
Training loss: 2.2665458123394715
Validation loss: 2.5905007050504376

Epoch: 26| Step: 0
Training loss: 2.6775731233643527
Validation loss: 2.5821214374421073

Epoch: 5| Step: 1
Training loss: 2.5993192698582632
Validation loss: 2.595282542566671

Epoch: 5| Step: 2
Training loss: 2.9403028711028933
Validation loss: 2.5873289286638563

Epoch: 5| Step: 3
Training loss: 3.2857306995337274
Validation loss: 2.580806669714244

Epoch: 5| Step: 4
Training loss: 2.8097447781032736
Validation loss: 2.58193299099094

Epoch: 5| Step: 5
Training loss: 3.3712650401423843
Validation loss: 2.576918840961133

Epoch: 5| Step: 6
Training loss: 2.871133609417193
Validation loss: 2.5824016799097524

Epoch: 5| Step: 7
Training loss: 3.144999176656012
Validation loss: 2.572523880130827

Epoch: 5| Step: 8
Training loss: 2.800217064890533
Validation loss: 2.5530934072570597

Epoch: 5| Step: 9
Training loss: 3.4594800648848865
Validation loss: 2.5712121916857456

Epoch: 5| Step: 10
Training loss: 1.8209199996796
Validation loss: 2.5661965955990502

Epoch: 27| Step: 0
Training loss: 3.220960284088018
Validation loss: 2.565229608318873

Epoch: 5| Step: 1
Training loss: 2.5722469019226524
Validation loss: 2.5705875992949996

Epoch: 5| Step: 2
Training loss: 3.2814367332003496
Validation loss: 2.5519655459564343

Epoch: 5| Step: 3
Training loss: 3.0831038587252495
Validation loss: 2.561395758876413

Epoch: 5| Step: 4
Training loss: 2.9636147506274697
Validation loss: 2.557023177014124

Epoch: 5| Step: 5
Training loss: 2.6719779725337496
Validation loss: 2.541584809059495

Epoch: 5| Step: 6
Training loss: 2.9917869997042104
Validation loss: 2.562701951899631

Epoch: 5| Step: 7
Training loss: 3.0911451991572556
Validation loss: 2.5516335826678453

Epoch: 5| Step: 8
Training loss: 2.417876653196106
Validation loss: 2.5545203026357512

Epoch: 5| Step: 9
Training loss: 3.0873391360488736
Validation loss: 2.5617248259077283

Epoch: 5| Step: 10
Training loss: 2.6799412376452296
Validation loss: 2.5543021271773525

Epoch: 28| Step: 0
Training loss: 2.7756098446585797
Validation loss: 2.545400427549114

Epoch: 5| Step: 1
Training loss: 2.131788965355168
Validation loss: 2.552385814455255

Epoch: 5| Step: 2
Training loss: 3.3089572026795753
Validation loss: 2.5517257004551883

Epoch: 5| Step: 3
Training loss: 2.9777057684863286
Validation loss: 2.5361893606369423

Epoch: 5| Step: 4
Training loss: 3.588648483982425
Validation loss: 2.5456606608916346

Epoch: 5| Step: 5
Training loss: 3.061307713940824
Validation loss: 2.554675158870728

Epoch: 5| Step: 6
Training loss: 3.1061188023451756
Validation loss: 2.547573676481513

Epoch: 5| Step: 7
Training loss: 3.1373214427702676
Validation loss: 2.5240082550735496

Epoch: 5| Step: 8
Training loss: 2.2018148436004483
Validation loss: 2.541252787066908

Epoch: 5| Step: 9
Training loss: 3.0514635795658767
Validation loss: 2.539349068371729

Epoch: 5| Step: 10
Training loss: 2.361329942423308
Validation loss: 2.540667769455225

Epoch: 29| Step: 0
Training loss: 2.8476661294731747
Validation loss: 2.5353103374210697

Epoch: 5| Step: 1
Training loss: 3.0468490208227377
Validation loss: 2.535313646992367

Epoch: 5| Step: 2
Training loss: 2.7387091592087924
Validation loss: 2.5293549341305446

Epoch: 5| Step: 3
Training loss: 3.250079814224279
Validation loss: 2.5360369086594807

Epoch: 5| Step: 4
Training loss: 2.7472261831445515
Validation loss: 2.543956945847495

Epoch: 5| Step: 5
Training loss: 3.0516467167278423
Validation loss: 2.5454279310882404

Epoch: 5| Step: 6
Training loss: 3.13251537711958
Validation loss: 2.536780081979673

Epoch: 5| Step: 7
Training loss: 2.4252724720576664
Validation loss: 2.537631413453404

Epoch: 5| Step: 8
Training loss: 2.802846660424981
Validation loss: 2.545844301267564

Epoch: 5| Step: 9
Training loss: 3.086349112185003
Validation loss: 2.528890271702633

Epoch: 5| Step: 10
Training loss: 2.946814520853408
Validation loss: 2.5570234908241343

Epoch: 30| Step: 0
Training loss: 2.991538831552831
Validation loss: 2.5440912354085206

Epoch: 5| Step: 1
Training loss: 2.643689696433576
Validation loss: 2.529397645996092

Epoch: 5| Step: 2
Training loss: 2.823700199034217
Validation loss: 2.5451478288744918

Epoch: 5| Step: 3
Training loss: 2.8183090406378892
Validation loss: 2.535129773687301

Epoch: 5| Step: 4
Training loss: 2.3080764939773513
Validation loss: 2.535535668609823

Epoch: 5| Step: 5
Training loss: 2.8342180740672775
Validation loss: 2.5296619507354485

Epoch: 5| Step: 6
Training loss: 2.642056229644908
Validation loss: 2.5342927401907067

Epoch: 5| Step: 7
Training loss: 3.320343807297254
Validation loss: 2.53496325640072

Epoch: 5| Step: 8
Training loss: 3.0444650362374928
Validation loss: 2.517605975251345

Epoch: 5| Step: 9
Training loss: 3.4911998743268766
Validation loss: 2.534949617800425

Epoch: 5| Step: 10
Training loss: 3.086283449506977
Validation loss: 2.526905743134129

Epoch: 31| Step: 0
Training loss: 3.1210170540678286
Validation loss: 2.532087527031438

Epoch: 5| Step: 1
Training loss: 3.6160159098351135
Validation loss: 2.528510550427126

Epoch: 5| Step: 2
Training loss: 2.3734621791297363
Validation loss: 2.53402577413195

Epoch: 5| Step: 3
Training loss: 2.8272744264349448
Validation loss: 2.5340802589549445

Epoch: 5| Step: 4
Training loss: 2.9259564458039526
Validation loss: 2.530867873496143

Epoch: 5| Step: 5
Training loss: 3.003385064557707
Validation loss: 2.532759581542007

Epoch: 5| Step: 6
Training loss: 3.1132202908280733
Validation loss: 2.5454330917455663

Epoch: 5| Step: 7
Training loss: 2.744370246592927
Validation loss: 2.5342551647615337

Epoch: 5| Step: 8
Training loss: 3.1390838637510323
Validation loss: 2.5532580955211728

Epoch: 5| Step: 9
Training loss: 2.5425891973852472
Validation loss: 2.5359523780920132

Epoch: 5| Step: 10
Training loss: 2.5213924660098765
Validation loss: 2.516393425031341

Epoch: 32| Step: 0
Training loss: 2.8292669024756814
Validation loss: 2.5299953337417236

Epoch: 5| Step: 1
Training loss: 2.793463133692098
Validation loss: 2.530720208541863

Epoch: 5| Step: 2
Training loss: 2.984748217828118
Validation loss: 2.5353530389518166

Epoch: 5| Step: 3
Training loss: 2.6465711290842893
Validation loss: 2.537821196861887

Epoch: 5| Step: 4
Training loss: 3.478587317437442
Validation loss: 2.544104478360296

Epoch: 5| Step: 5
Training loss: 3.081135009105563
Validation loss: 2.5426876932962568

Epoch: 5| Step: 6
Training loss: 2.167500873288305
Validation loss: 2.524534283192395

Epoch: 5| Step: 7
Training loss: 3.7879929124228084
Validation loss: 2.5454665662705134

Epoch: 5| Step: 8
Training loss: 3.0718965205605846
Validation loss: 2.5347779376917665

Epoch: 5| Step: 9
Training loss: 2.7437395447551367
Validation loss: 2.538500532713727

Epoch: 5| Step: 10
Training loss: 1.9056671377135495
Validation loss: 2.538285878743081

Epoch: 33| Step: 0
Training loss: 2.990596338212478
Validation loss: 2.542447879049028

Epoch: 5| Step: 1
Training loss: 2.5013535649993606
Validation loss: 2.5268673811509825

Epoch: 5| Step: 2
Training loss: 2.3134316294707826
Validation loss: 2.5624959371891225

Epoch: 5| Step: 3
Training loss: 3.029038714015696
Validation loss: 2.526032135191377

Epoch: 5| Step: 4
Training loss: 3.0361510307229223
Validation loss: 2.5248481721086184

Epoch: 5| Step: 5
Training loss: 3.351210355598876
Validation loss: 2.537086362741565

Epoch: 5| Step: 6
Training loss: 2.3879437338815337
Validation loss: 2.537701312657568

Epoch: 5| Step: 7
Training loss: 2.8244530882637675
Validation loss: 2.539784346864688

Epoch: 5| Step: 8
Training loss: 3.6045629617899326
Validation loss: 2.53772568817706

Epoch: 5| Step: 9
Training loss: 3.0325997090752677
Validation loss: 2.5380286861721664

Epoch: 5| Step: 10
Training loss: 2.6341219851807356
Validation loss: 2.5444932676379826

Epoch: 34| Step: 0
Training loss: 3.712033401092344
Validation loss: 2.5345351174047264

Epoch: 5| Step: 1
Training loss: 2.765136158299983
Validation loss: 2.54818058176638

Epoch: 5| Step: 2
Training loss: 3.197795621256485
Validation loss: 2.5392716445797947

Epoch: 5| Step: 3
Training loss: 2.786420409517896
Validation loss: 2.542495591023922

Epoch: 5| Step: 4
Training loss: 3.018138727254452
Validation loss: 2.5340873871374274

Epoch: 5| Step: 5
Training loss: 3.020099384112548
Validation loss: 2.5339469442873015

Epoch: 5| Step: 6
Training loss: 2.442357431895315
Validation loss: 2.5392745522170372

Epoch: 5| Step: 7
Training loss: 2.904929568672913
Validation loss: 2.5359493382589005

Epoch: 5| Step: 8
Training loss: 2.552526183858063
Validation loss: 2.544207987056018

Epoch: 5| Step: 9
Training loss: 2.7775873648760436
Validation loss: 2.5291687088205825

Epoch: 5| Step: 10
Training loss: 2.5939346615423506
Validation loss: 2.5435169568452634

Epoch: 35| Step: 0
Training loss: 2.6641515454040263
Validation loss: 2.5255706405462837

Epoch: 5| Step: 1
Training loss: 2.9982297760780665
Validation loss: 2.529701148972138

Epoch: 5| Step: 2
Training loss: 3.203609374104556
Validation loss: 2.5279645543909885

Epoch: 5| Step: 3
Training loss: 3.4510831708146186
Validation loss: 2.5223827331119715

Epoch: 5| Step: 4
Training loss: 2.9649574549486815
Validation loss: 2.5267716461255643

Epoch: 5| Step: 5
Training loss: 2.4600270358204956
Validation loss: 2.5076913278837885

Epoch: 5| Step: 6
Training loss: 3.10299196140577
Validation loss: 2.517448971160074

Epoch: 5| Step: 7
Training loss: 2.3113103332402094
Validation loss: 2.534440247573436

Epoch: 5| Step: 8
Training loss: 3.115170392661914
Validation loss: 2.531715725969255

Epoch: 5| Step: 9
Training loss: 2.967573233827992
Validation loss: 2.5215219455309024

Epoch: 5| Step: 10
Training loss: 2.5831518006890017
Validation loss: 2.5219749856090394

Epoch: 36| Step: 0
Training loss: 2.9271230638371133
Validation loss: 2.518399034351346

Epoch: 5| Step: 1
Training loss: 3.3225961528610912
Validation loss: 2.5305111869155623

Epoch: 5| Step: 2
Training loss: 3.519610777706861
Validation loss: 2.5288440639360514

Epoch: 5| Step: 3
Training loss: 2.9197726106288346
Validation loss: 2.5223850056845687

Epoch: 5| Step: 4
Training loss: 2.6165217677369434
Validation loss: 2.5288697960719735

Epoch: 5| Step: 5
Training loss: 3.319946268864816
Validation loss: 2.5202787920395635

Epoch: 5| Step: 6
Training loss: 2.853552053690298
Validation loss: 2.5329358072615373

Epoch: 5| Step: 7
Training loss: 2.45687171891177
Validation loss: 2.540980168842023

Epoch: 5| Step: 8
Training loss: 2.632166480431431
Validation loss: 2.5190047572290473

Epoch: 5| Step: 9
Training loss: 2.6962730575799427
Validation loss: 2.513837161321633

Epoch: 5| Step: 10
Training loss: 2.4264304356644253
Validation loss: 2.539600607469627

Epoch: 37| Step: 0
Training loss: 2.8943483858608574
Validation loss: 2.5228840561273382

Epoch: 5| Step: 1
Training loss: 2.632077077600814
Validation loss: 2.533683618762374

Epoch: 5| Step: 2
Training loss: 2.7461790068891028
Validation loss: 2.53885145700187

Epoch: 5| Step: 3
Training loss: 3.5519952996197093
Validation loss: 2.525034488132577

Epoch: 5| Step: 4
Training loss: 2.67284942169717
Validation loss: 2.5256419596409043

Epoch: 5| Step: 5
Training loss: 3.390638922737472
Validation loss: 2.5140575635698377

Epoch: 5| Step: 6
Training loss: 2.475007059106489
Validation loss: 2.534207189399918

Epoch: 5| Step: 7
Training loss: 2.8540573284804442
Validation loss: 2.527426086424565

Epoch: 5| Step: 8
Training loss: 3.114331459569369
Validation loss: 2.517864390526321

Epoch: 5| Step: 9
Training loss: 2.4916434815347697
Validation loss: 2.5312697595786977

Epoch: 5| Step: 10
Training loss: 3.0341928885092617
Validation loss: 2.5196000737409445

Epoch: 38| Step: 0
Training loss: 3.2117563953016783
Validation loss: 2.5395224443187283

Epoch: 5| Step: 1
Training loss: 2.937583759818138
Validation loss: 2.540843260025373

Epoch: 5| Step: 2
Training loss: 2.822027472245383
Validation loss: 2.5346259075555815

Epoch: 5| Step: 3
Training loss: 2.825796106292593
Validation loss: 2.5343402121984506

Epoch: 5| Step: 4
Training loss: 3.0031754853672212
Validation loss: 2.519938614653162

Epoch: 5| Step: 5
Training loss: 2.8508187774253892
Validation loss: 2.535592575847255

Epoch: 5| Step: 6
Training loss: 2.458537163339311
Validation loss: 2.5184819431354817

Epoch: 5| Step: 7
Training loss: 3.0987811553484503
Validation loss: 2.521941461538843

Epoch: 5| Step: 8
Training loss: 3.212464500854521
Validation loss: 2.5245898248354837

Epoch: 5| Step: 9
Training loss: 2.850937197333047
Validation loss: 2.5334949521866856

Epoch: 5| Step: 10
Training loss: 2.4569307194507264
Validation loss: 2.5249130652362717

Epoch: 39| Step: 0
Training loss: 2.4199917269793882
Validation loss: 2.5200059475839134

Epoch: 5| Step: 1
Training loss: 2.9142002758356647
Validation loss: 2.529872544308682

Epoch: 5| Step: 2
Training loss: 2.702151084487771
Validation loss: 2.5321843711528746

Epoch: 5| Step: 3
Training loss: 3.1462420435953757
Validation loss: 2.528984270136007

Epoch: 5| Step: 4
Training loss: 3.2260588098074
Validation loss: 2.5341369115689734

Epoch: 5| Step: 5
Training loss: 3.1174131230513784
Validation loss: 2.533280777777357

Epoch: 5| Step: 6
Training loss: 2.4558287863618635
Validation loss: 2.5308181290970384

Epoch: 5| Step: 7
Training loss: 2.5183927107483726
Validation loss: 2.5318026955222708

Epoch: 5| Step: 8
Training loss: 3.0501669290856994
Validation loss: 2.5359991771113997

Epoch: 5| Step: 9
Training loss: 3.0470061445133565
Validation loss: 2.516856939577855

Epoch: 5| Step: 10
Training loss: 3.2341995560244077
Validation loss: 2.516602282205446

Epoch: 40| Step: 0
Training loss: 2.74947334795249
Validation loss: 2.5258066727526005

Epoch: 5| Step: 1
Training loss: 3.381151033599611
Validation loss: 2.5219663898924756

Epoch: 5| Step: 2
Training loss: 3.1063760835475995
Validation loss: 2.525306575588861

Epoch: 5| Step: 3
Training loss: 2.7862129935283835
Validation loss: 2.5198736768450454

Epoch: 5| Step: 4
Training loss: 3.185430715233457
Validation loss: 2.5206859362134684

Epoch: 5| Step: 5
Training loss: 2.4795402651404226
Validation loss: 2.5320479374600953

Epoch: 5| Step: 6
Training loss: 2.4154311562520805
Validation loss: 2.523375891106082

Epoch: 5| Step: 7
Training loss: 2.5289696676924858
Validation loss: 2.5179886564001053

Epoch: 5| Step: 8
Training loss: 2.8196335923796694
Validation loss: 2.530600603874825

Epoch: 5| Step: 9
Training loss: 2.962742881636952
Validation loss: 2.5212302089180003

Epoch: 5| Step: 10
Training loss: 3.2523617599395505
Validation loss: 2.5296629043748795

Epoch: 41| Step: 0
Training loss: 3.408060695000261
Validation loss: 2.5147515611602986

Epoch: 5| Step: 1
Training loss: 3.189315278998384
Validation loss: 2.5258106859762286

Epoch: 5| Step: 2
Training loss: 3.1762046390973975
Validation loss: 2.507238438448108

Epoch: 5| Step: 3
Training loss: 2.5483235177582277
Validation loss: 2.522826934373312

Epoch: 5| Step: 4
Training loss: 2.8161204453632607
Validation loss: 2.5208805313376765

Epoch: 5| Step: 5
Training loss: 2.955096520204642
Validation loss: 2.52867891199123

Epoch: 5| Step: 6
Training loss: 2.919117651580616
Validation loss: 2.542103592832361

Epoch: 5| Step: 7
Training loss: 2.626752540843472
Validation loss: 2.522645413597807

Epoch: 5| Step: 8
Training loss: 2.5012237414764673
Validation loss: 2.5191111392529693

Epoch: 5| Step: 9
Training loss: 2.792289597961332
Validation loss: 2.528698085397414

Epoch: 5| Step: 10
Training loss: 2.815010306845949
Validation loss: 2.528721828912764

Epoch: 42| Step: 0
Training loss: 2.975835756507242
Validation loss: 2.5354261496234733

Epoch: 5| Step: 1
Training loss: 2.929844071337011
Validation loss: 2.5296547036720853

Epoch: 5| Step: 2
Training loss: 2.957620418415573
Validation loss: 2.5237075842471928

Epoch: 5| Step: 3
Training loss: 2.498197859674358
Validation loss: 2.5329196152783613

Epoch: 5| Step: 4
Training loss: 2.8384462299693554
Validation loss: 2.5263050107417007

Epoch: 5| Step: 5
Training loss: 2.6156945368594267
Validation loss: 2.5326063147421696

Epoch: 5| Step: 6
Training loss: 3.586729273929167
Validation loss: 2.512926677810466

Epoch: 5| Step: 7
Training loss: 2.8048148378670628
Validation loss: 2.531270099875575

Epoch: 5| Step: 8
Training loss: 2.6838022564729624
Validation loss: 2.5368346905596426

Epoch: 5| Step: 9
Training loss: 2.8404886177317064
Validation loss: 2.514055689319497

Epoch: 5| Step: 10
Training loss: 3.053495130486023
Validation loss: 2.5351321197776606

Epoch: 43| Step: 0
Training loss: 2.926372636378662
Validation loss: 2.5191769342434855

Epoch: 5| Step: 1
Training loss: 3.5730827152084905
Validation loss: 2.504077155505467

Epoch: 5| Step: 2
Training loss: 2.3671554714340037
Validation loss: 2.514839852368687

Epoch: 5| Step: 3
Training loss: 2.3337952860446665
Validation loss: 2.522633091017598

Epoch: 5| Step: 4
Training loss: 2.623935847068066
Validation loss: 2.525252509570813

Epoch: 5| Step: 5
Training loss: 3.0016360590121045
Validation loss: 2.5144907185767393

Epoch: 5| Step: 6
Training loss: 3.323949926244771
Validation loss: 2.5273449134725716

Epoch: 5| Step: 7
Training loss: 2.8254609601171268
Validation loss: 2.509675212891641

Epoch: 5| Step: 8
Training loss: 3.2404924856698276
Validation loss: 2.533294746159561

Epoch: 5| Step: 9
Training loss: 2.417662864650863
Validation loss: 2.526017919609983

Epoch: 5| Step: 10
Training loss: 2.9941137104852777
Validation loss: 2.528775426392417

Epoch: 44| Step: 0
Training loss: 2.8789615703428106
Validation loss: 2.5244451195190565

Epoch: 5| Step: 1
Training loss: 2.8037514147200056
Validation loss: 2.5309832984534455

Epoch: 5| Step: 2
Training loss: 2.716797401543353
Validation loss: 2.5292441349261625

Epoch: 5| Step: 3
Training loss: 2.4388984189997465
Validation loss: 2.5298602321036316

Epoch: 5| Step: 4
Training loss: 2.8145054766665556
Validation loss: 2.523101032419236

Epoch: 5| Step: 5
Training loss: 3.1384565924048826
Validation loss: 2.5288993325065783

Epoch: 5| Step: 6
Training loss: 2.928121000468353
Validation loss: 2.5105103655790573

Epoch: 5| Step: 7
Training loss: 3.060191939074981
Validation loss: 2.5197393195511157

Epoch: 5| Step: 8
Training loss: 3.393598105612536
Validation loss: 2.522613663179707

Epoch: 5| Step: 9
Training loss: 2.2713008947553828
Validation loss: 2.513614282804727

Epoch: 5| Step: 10
Training loss: 3.0559391667168097
Validation loss: 2.521646144010157

Epoch: 45| Step: 0
Training loss: 2.4940827914876196
Validation loss: 2.5150578936727532

Epoch: 5| Step: 1
Training loss: 2.755861278292663
Validation loss: 2.51980802722166

Epoch: 5| Step: 2
Training loss: 2.7278826558949114
Validation loss: 2.5208106640378065

Epoch: 5| Step: 3
Training loss: 3.0942833951189863
Validation loss: 2.5022869980678704

Epoch: 5| Step: 4
Training loss: 2.451613330982702
Validation loss: 2.5198761348066534

Epoch: 5| Step: 5
Training loss: 2.6892075547722314
Validation loss: 2.509171080685863

Epoch: 5| Step: 6
Training loss: 2.8884176538320685
Validation loss: 2.5219822476248943

Epoch: 5| Step: 7
Training loss: 3.157540086022096
Validation loss: 2.5191311670502206

Epoch: 5| Step: 8
Training loss: 2.7165328884145485
Validation loss: 2.5254448504811076

Epoch: 5| Step: 9
Training loss: 3.8727177697967496
Validation loss: 2.517243286890763

Epoch: 5| Step: 10
Training loss: 2.6846855863187584
Validation loss: 2.5138258118112207

Epoch: 46| Step: 0
Training loss: 2.915402347285468
Validation loss: 2.5319678603899147

Epoch: 5| Step: 1
Training loss: 2.840541832506904
Validation loss: 2.5120283726471695

Epoch: 5| Step: 2
Training loss: 2.8877005965668596
Validation loss: 2.5296723809571695

Epoch: 5| Step: 3
Training loss: 3.1727062320036388
Validation loss: 2.5220018795628008

Epoch: 5| Step: 4
Training loss: 2.8198731310016534
Validation loss: 2.5239269193812026

Epoch: 5| Step: 5
Training loss: 2.4543320911484976
Validation loss: 2.5108410219560846

Epoch: 5| Step: 6
Training loss: 3.1815988105850357
Validation loss: 2.5213185416893595

Epoch: 5| Step: 7
Training loss: 2.9399900231224545
Validation loss: 2.5220810146568504

Epoch: 5| Step: 8
Training loss: 2.8093269250679285
Validation loss: 2.518357239438966

Epoch: 5| Step: 9
Training loss: 2.4225535764960187
Validation loss: 2.5038243258075124

Epoch: 5| Step: 10
Training loss: 3.110821104913837
Validation loss: 2.5053551446907765

Epoch: 47| Step: 0
Training loss: 3.0442982268045924
Validation loss: 2.508264051114301

Epoch: 5| Step: 1
Training loss: 2.937759712588191
Validation loss: 2.514410835826354

Epoch: 5| Step: 2
Training loss: 2.891417028844574
Validation loss: 2.517701253366357

Epoch: 5| Step: 3
Training loss: 2.6431008193451766
Validation loss: 2.508982726820645

Epoch: 5| Step: 4
Training loss: 2.3533111863359437
Validation loss: 2.519330819607756

Epoch: 5| Step: 5
Training loss: 2.683086497245827
Validation loss: 2.52321748832566

Epoch: 5| Step: 6
Training loss: 3.270255861917349
Validation loss: 2.5208804499806856

Epoch: 5| Step: 7
Training loss: 2.3115671699232307
Validation loss: 2.499624589195108

Epoch: 5| Step: 8
Training loss: 3.012433354443849
Validation loss: 2.52132352901828

Epoch: 5| Step: 9
Training loss: 3.244698822668924
Validation loss: 2.5038618603089025

Epoch: 5| Step: 10
Training loss: 3.156373880806812
Validation loss: 2.515712606323311

Epoch: 48| Step: 0
Training loss: 2.676820873253904
Validation loss: 2.5107369003999334

Epoch: 5| Step: 1
Training loss: 3.09564628669233
Validation loss: 2.512162578521966

Epoch: 5| Step: 2
Training loss: 2.5627640378807763
Validation loss: 2.5215653726378298

Epoch: 5| Step: 3
Training loss: 2.7732512935400537
Validation loss: 2.519615398457121

Epoch: 5| Step: 4
Training loss: 2.5272823367550514
Validation loss: 2.5043580616734316

Epoch: 5| Step: 5
Training loss: 2.920777629878009
Validation loss: 2.5251012521702343

Epoch: 5| Step: 6
Training loss: 2.4182720333070873
Validation loss: 2.527078721944498

Epoch: 5| Step: 7
Training loss: 3.539577960271651
Validation loss: 2.5070223195453756

Epoch: 5| Step: 8
Training loss: 2.55931125510251
Validation loss: 2.5027087928589755

Epoch: 5| Step: 9
Training loss: 3.5743837745800264
Validation loss: 2.514713699859098

Epoch: 5| Step: 10
Training loss: 2.712290225729025
Validation loss: 2.5229178369499277

Epoch: 49| Step: 0
Training loss: 3.0261365095410753
Validation loss: 2.516224712146562

Epoch: 5| Step: 1
Training loss: 2.767089025208874
Validation loss: 2.5190814778741215

Epoch: 5| Step: 2
Training loss: 2.792422794787683
Validation loss: 2.5112261366830886

Epoch: 5| Step: 3
Training loss: 3.2400636633752447
Validation loss: 2.504716702940568

Epoch: 5| Step: 4
Training loss: 3.342682427369028
Validation loss: 2.502008230378953

Epoch: 5| Step: 5
Training loss: 2.9191989986260105
Validation loss: 2.506166134626042

Epoch: 5| Step: 6
Training loss: 2.637798986618376
Validation loss: 2.505972258774106

Epoch: 5| Step: 7
Training loss: 2.436242194752841
Validation loss: 2.526111780345259

Epoch: 5| Step: 8
Training loss: 2.722763606709187
Validation loss: 2.507695696726393

Epoch: 5| Step: 9
Training loss: 2.9265003823013354
Validation loss: 2.5056111400764425

Epoch: 5| Step: 10
Training loss: 2.6505978755557003
Validation loss: 2.483665441857715

Epoch: 50| Step: 0
Training loss: 2.908677266797197
Validation loss: 2.513142095147256

Epoch: 5| Step: 1
Training loss: 3.0092240625480455
Validation loss: 2.513793691470609

Epoch: 5| Step: 2
Training loss: 3.4867627639607996
Validation loss: 2.5169052599169124

Epoch: 5| Step: 3
Training loss: 2.4685372369564287
Validation loss: 2.5222811340155973

Epoch: 5| Step: 4
Training loss: 2.9803197980985177
Validation loss: 2.51473812999036

Epoch: 5| Step: 5
Training loss: 2.761806632320339
Validation loss: 2.5077498028847733

Epoch: 5| Step: 6
Training loss: 2.48769813783624
Validation loss: 2.5144648729358594

Epoch: 5| Step: 7
Training loss: 3.0925578893548993
Validation loss: 2.5085614728979166

Epoch: 5| Step: 8
Training loss: 2.637774220896016
Validation loss: 2.515702552341394

Epoch: 5| Step: 9
Training loss: 2.452570761496786
Validation loss: 2.513015007629902

Epoch: 5| Step: 10
Training loss: 3.2494654582662257
Validation loss: 2.522354119459002

Epoch: 51| Step: 0
Training loss: 2.6840885600162774
Validation loss: 2.4903953986291993

Epoch: 5| Step: 1
Training loss: 3.1985136752615206
Validation loss: 2.506439987533426

Epoch: 5| Step: 2
Training loss: 2.7248702167087693
Validation loss: 2.5091704267925383

Epoch: 5| Step: 3
Training loss: 3.0099926466234184
Validation loss: 2.515432191039484

Epoch: 5| Step: 4
Training loss: 2.576355760560712
Validation loss: 2.5193848855095524

Epoch: 5| Step: 5
Training loss: 2.717505159066084
Validation loss: 2.494232218452005

Epoch: 5| Step: 6
Training loss: 2.979120071864827
Validation loss: 2.5220896557241206

Epoch: 5| Step: 7
Training loss: 3.2759404411910418
Validation loss: 2.501253177997709

Epoch: 5| Step: 8
Training loss: 2.9165932963997574
Validation loss: 2.513241161642936

Epoch: 5| Step: 9
Training loss: 2.385598377042253
Validation loss: 2.499323931925448

Epoch: 5| Step: 10
Training loss: 3.0118208693472535
Validation loss: 2.5009506510042034

Epoch: 52| Step: 0
Training loss: 3.180625083714951
Validation loss: 2.5235424263122193

Epoch: 5| Step: 1
Training loss: 3.300137898424944
Validation loss: 2.5193046684797977

Epoch: 5| Step: 2
Training loss: 2.2312138744175902
Validation loss: 2.5113188924276098

Epoch: 5| Step: 3
Training loss: 3.0758012239497026
Validation loss: 2.5094021835002067

Epoch: 5| Step: 4
Training loss: 2.678630475801228
Validation loss: 2.5175474353973093

Epoch: 5| Step: 5
Training loss: 2.8027529194181797
Validation loss: 2.5318064987518873

Epoch: 5| Step: 6
Training loss: 2.7946122035926986
Validation loss: 2.5147502491394973

Epoch: 5| Step: 7
Training loss: 2.865972859309357
Validation loss: 2.5065764486593536

Epoch: 5| Step: 8
Training loss: 3.0751720535401774
Validation loss: 2.5148123761922405

Epoch: 5| Step: 9
Training loss: 2.534146100301267
Validation loss: 2.506971182671264

Epoch: 5| Step: 10
Training loss: 2.885244279433191
Validation loss: 2.5091249286809076

Epoch: 53| Step: 0
Training loss: 2.3947727896759567
Validation loss: 2.514427377422606

Epoch: 5| Step: 1
Training loss: 2.4711049111301455
Validation loss: 2.5098805199472833

Epoch: 5| Step: 2
Training loss: 2.908724807872785
Validation loss: 2.5027751419660933

Epoch: 5| Step: 3
Training loss: 3.5166201391049885
Validation loss: 2.50740985093282

Epoch: 5| Step: 4
Training loss: 2.75089968789576
Validation loss: 2.5157311234394664

Epoch: 5| Step: 5
Training loss: 2.6277621133224076
Validation loss: 2.5050176749570845

Epoch: 5| Step: 6
Training loss: 3.047028210040196
Validation loss: 2.5016865097154937

Epoch: 5| Step: 7
Training loss: 2.322725319501011
Validation loss: 2.500015765314743

Epoch: 5| Step: 8
Training loss: 3.2046200124403676
Validation loss: 2.500722774498503

Epoch: 5| Step: 9
Training loss: 2.897142146527764
Validation loss: 2.5016956731468385

Epoch: 5| Step: 10
Training loss: 3.2076173123725087
Validation loss: 2.5057964295145587

Epoch: 54| Step: 0
Training loss: 2.9181207211304367
Validation loss: 2.52559823720743

Epoch: 5| Step: 1
Training loss: 2.947791232797982
Validation loss: 2.506504629016848

Epoch: 5| Step: 2
Training loss: 3.0567552831430502
Validation loss: 2.5158748167642573

Epoch: 5| Step: 3
Training loss: 3.224780461135606
Validation loss: 2.516054210455521

Epoch: 5| Step: 4
Training loss: 2.5231651891456313
Validation loss: 2.507006746566949

Epoch: 5| Step: 5
Training loss: 3.0154447353424167
Validation loss: 2.499590700751036

Epoch: 5| Step: 6
Training loss: 3.192111848970122
Validation loss: 2.4946577068847207

Epoch: 5| Step: 7
Training loss: 2.285515755308029
Validation loss: 2.5022390070874962

Epoch: 5| Step: 8
Training loss: 2.211599298106079
Validation loss: 2.5062627835863593

Epoch: 5| Step: 9
Training loss: 3.0803080142192565
Validation loss: 2.5010991520739845

Epoch: 5| Step: 10
Training loss: 2.858191406759838
Validation loss: 2.5109905093747775

Epoch: 55| Step: 0
Training loss: 3.1294501090326263
Validation loss: 2.4947887393833965

Epoch: 5| Step: 1
Training loss: 3.0633073637826294
Validation loss: 2.521089596910825

Epoch: 5| Step: 2
Training loss: 3.341141155395246
Validation loss: 2.5097369890545282

Epoch: 5| Step: 3
Training loss: 2.5688154968673405
Validation loss: 2.5103990604145943

Epoch: 5| Step: 4
Training loss: 2.7065871453779025
Validation loss: 2.5060308531689617

Epoch: 5| Step: 5
Training loss: 3.086986199380557
Validation loss: 2.5063182616627806

Epoch: 5| Step: 6
Training loss: 2.618327515966152
Validation loss: 2.498821166222689

Epoch: 5| Step: 7
Training loss: 2.941068875644809
Validation loss: 2.503322694382602

Epoch: 5| Step: 8
Training loss: 2.33824712063716
Validation loss: 2.5002792161456875

Epoch: 5| Step: 9
Training loss: 3.191159111548612
Validation loss: 2.496197142093271

Epoch: 5| Step: 10
Training loss: 2.177783202577612
Validation loss: 2.501215582825003

Epoch: 56| Step: 0
Training loss: 3.2180349796496968
Validation loss: 2.49853574982417

Epoch: 5| Step: 1
Training loss: 2.716305565579496
Validation loss: 2.497952164983383

Epoch: 5| Step: 2
Training loss: 2.930512579130216
Validation loss: 2.4984232514044042

Epoch: 5| Step: 3
Training loss: 2.709821663791631
Validation loss: 2.5100710237768946

Epoch: 5| Step: 4
Training loss: 2.3158206295924657
Validation loss: 2.4986705813909387

Epoch: 5| Step: 5
Training loss: 3.0262026894427168
Validation loss: 2.5089258853052105

Epoch: 5| Step: 6
Training loss: 2.83773217280675
Validation loss: 2.503326700639631

Epoch: 5| Step: 7
Training loss: 2.5402752136955393
Validation loss: 2.512229464728443

Epoch: 5| Step: 8
Training loss: 2.9441963327185334
Validation loss: 2.5204607512707686

Epoch: 5| Step: 9
Training loss: 3.288091303223644
Validation loss: 2.5009447030489844

Epoch: 5| Step: 10
Training loss: 2.8450260862418264
Validation loss: 2.5076598359043127

Epoch: 57| Step: 0
Training loss: 2.4169047885082002
Validation loss: 2.5042756424561206

Epoch: 5| Step: 1
Training loss: 2.7082020263141433
Validation loss: 2.5072069576514693

Epoch: 5| Step: 2
Training loss: 2.170098325901292
Validation loss: 2.506934738818348

Epoch: 5| Step: 3
Training loss: 3.525860885576179
Validation loss: 2.5018331164906598

Epoch: 5| Step: 4
Training loss: 2.846653723884599
Validation loss: 2.492931355636805

Epoch: 5| Step: 5
Training loss: 2.9682562166449458
Validation loss: 2.492857260915992

Epoch: 5| Step: 6
Training loss: 3.193312487710064
Validation loss: 2.516268609679398

Epoch: 5| Step: 7
Training loss: 2.6135029378012944
Validation loss: 2.501343064863032

Epoch: 5| Step: 8
Training loss: 2.8390269200095766
Validation loss: 2.4989993051238923

Epoch: 5| Step: 9
Training loss: 2.7277768117156675
Validation loss: 2.513954820366812

Epoch: 5| Step: 10
Training loss: 3.3205763050072328
Validation loss: 2.5004784362097934

Epoch: 58| Step: 0
Training loss: 2.7957226814245875
Validation loss: 2.5107473780981286

Epoch: 5| Step: 1
Training loss: 2.77177701860762
Validation loss: 2.499276440006674

Epoch: 5| Step: 2
Training loss: 3.3021428115895177
Validation loss: 2.5037440955750436

Epoch: 5| Step: 3
Training loss: 2.444890970088715
Validation loss: 2.516876425093596

Epoch: 5| Step: 4
Training loss: 3.053330844589396
Validation loss: 2.496681947365505

Epoch: 5| Step: 5
Training loss: 2.850546459879944
Validation loss: 2.510662663867047

Epoch: 5| Step: 6
Training loss: 3.00857510497785
Validation loss: 2.502160551808555

Epoch: 5| Step: 7
Training loss: 3.0351080184894452
Validation loss: 2.517582542365725

Epoch: 5| Step: 8
Training loss: 2.209904082102548
Validation loss: 2.5054187806933164

Epoch: 5| Step: 9
Training loss: 2.785293725514445
Validation loss: 2.5177011108118346

Epoch: 5| Step: 10
Training loss: 2.860555769799601
Validation loss: 2.498195578439622

Epoch: 59| Step: 0
Training loss: 2.8766325586211625
Validation loss: 2.5010369375603347

Epoch: 5| Step: 1
Training loss: 3.107873602065569
Validation loss: 2.5171696470832137

Epoch: 5| Step: 2
Training loss: 2.0731025753010215
Validation loss: 2.4993554248269985

Epoch: 5| Step: 3
Training loss: 2.6913394559813106
Validation loss: 2.507014673673972

Epoch: 5| Step: 4
Training loss: 2.158994945419494
Validation loss: 2.514551122932686

Epoch: 5| Step: 5
Training loss: 3.504376808303467
Validation loss: 2.500317884559615

Epoch: 5| Step: 6
Training loss: 3.0758722262290745
Validation loss: 2.509695849720157

Epoch: 5| Step: 7
Training loss: 2.94921535466485
Validation loss: 2.5013704655654605

Epoch: 5| Step: 8
Training loss: 2.7485664272376145
Validation loss: 2.4852184603389835

Epoch: 5| Step: 9
Training loss: 2.7650909770325987
Validation loss: 2.5091149749969266

Epoch: 5| Step: 10
Training loss: 3.277535506811953
Validation loss: 2.5138938214230575

Epoch: 60| Step: 0
Training loss: 3.0246147604038005
Validation loss: 2.5008850786931425

Epoch: 5| Step: 1
Training loss: 2.9956262813177776
Validation loss: 2.508518271359927

Epoch: 5| Step: 2
Training loss: 2.2583436968050656
Validation loss: 2.5128219560652605

Epoch: 5| Step: 3
Training loss: 2.132421101299033
Validation loss: 2.496939829924789

Epoch: 5| Step: 4
Training loss: 3.2830015321438086
Validation loss: 2.486496630123768

Epoch: 5| Step: 5
Training loss: 3.152077210986202
Validation loss: 2.505352260106877

Epoch: 5| Step: 6
Training loss: 2.8965419935899224
Validation loss: 2.5124040029715515

Epoch: 5| Step: 7
Training loss: 2.78617286051659
Validation loss: 2.521656493522588

Epoch: 5| Step: 8
Training loss: 2.8989777177241858
Validation loss: 2.4961573129712082

Epoch: 5| Step: 9
Training loss: 2.331941995877567
Validation loss: 2.5001970756951852

Epoch: 5| Step: 10
Training loss: 3.3968823612698382
Validation loss: 2.493954736853855

Epoch: 61| Step: 0
Training loss: 3.3792429497164016
Validation loss: 2.494216165789389

Epoch: 5| Step: 1
Training loss: 3.122315894411491
Validation loss: 2.500892223583508

Epoch: 5| Step: 2
Training loss: 2.9616546970083335
Validation loss: 2.504260154768403

Epoch: 5| Step: 3
Training loss: 2.4809295947084324
Validation loss: 2.5090123492114755

Epoch: 5| Step: 4
Training loss: 2.664627865401054
Validation loss: 2.49503642143483

Epoch: 5| Step: 5
Training loss: 2.632750739666472
Validation loss: 2.503670019809045

Epoch: 5| Step: 6
Training loss: 2.835248879301527
Validation loss: 2.5162735703397594

Epoch: 5| Step: 7
Training loss: 2.5333964348346103
Validation loss: 2.5012944505534533

Epoch: 5| Step: 8
Training loss: 2.917711524911697
Validation loss: 2.5171166080994896

Epoch: 5| Step: 9
Training loss: 2.854535118508415
Validation loss: 2.5042363943051313

Epoch: 5| Step: 10
Training loss: 2.776346405842465
Validation loss: 2.49922326439863

Epoch: 62| Step: 0
Training loss: 2.861345456432152
Validation loss: 2.4969715931434853

Epoch: 5| Step: 1
Training loss: 3.3210224424831223
Validation loss: 2.5009771303808717

Epoch: 5| Step: 2
Training loss: 2.305213893970437
Validation loss: 2.507764710855345

Epoch: 5| Step: 3
Training loss: 2.795362265897091
Validation loss: 2.498328503322715

Epoch: 5| Step: 4
Training loss: 2.8838616506378267
Validation loss: 2.4917211547281326

Epoch: 5| Step: 5
Training loss: 2.955003897572382
Validation loss: 2.4971357406445187

Epoch: 5| Step: 6
Training loss: 2.1524582847956997
Validation loss: 2.4919746589123415

Epoch: 5| Step: 7
Training loss: 3.042344387967937
Validation loss: 2.5084764181065573

Epoch: 5| Step: 8
Training loss: 3.3218651585688828
Validation loss: 2.4916700433580687

Epoch: 5| Step: 9
Training loss: 2.4677723747586255
Validation loss: 2.4987961403424803

Epoch: 5| Step: 10
Training loss: 2.9534023901426956
Validation loss: 2.506597320665263

Epoch: 63| Step: 0
Training loss: 2.968067291463466
Validation loss: 2.4904189699727297

Epoch: 5| Step: 1
Training loss: 2.8111197581637763
Validation loss: 2.485275405673374

Epoch: 5| Step: 2
Training loss: 2.9742425803894936
Validation loss: 2.482710828044088

Epoch: 5| Step: 3
Training loss: 2.895785287874721
Validation loss: 2.515717105431538

Epoch: 5| Step: 4
Training loss: 2.5132717712242574
Validation loss: 2.504684834257559

Epoch: 5| Step: 5
Training loss: 2.820743939905166
Validation loss: 2.500303733997101

Epoch: 5| Step: 6
Training loss: 3.0162202712047192
Validation loss: 2.497426513256223

Epoch: 5| Step: 7
Training loss: 3.0095701160340482
Validation loss: 2.499873885183413

Epoch: 5| Step: 8
Training loss: 2.718033093170289
Validation loss: 2.489906267092965

Epoch: 5| Step: 9
Training loss: 2.591576274346251
Validation loss: 2.5001838944593686

Epoch: 5| Step: 10
Training loss: 2.943773105150003
Validation loss: 2.5056921177747764

Epoch: 64| Step: 0
Training loss: 3.4319972991132444
Validation loss: 2.5150838596135765

Epoch: 5| Step: 1
Training loss: 2.787357781720946
Validation loss: 2.506056252820641

Epoch: 5| Step: 2
Training loss: 3.2505039411261842
Validation loss: 2.50222248019956

Epoch: 5| Step: 3
Training loss: 3.0679270089430335
Validation loss: 2.4980869962350303

Epoch: 5| Step: 4
Training loss: 2.599158106727933
Validation loss: 2.5163521500115102

Epoch: 5| Step: 5
Training loss: 2.4897480568332866
Validation loss: 2.4980887131365295

Epoch: 5| Step: 6
Training loss: 2.284408264335441
Validation loss: 2.495327132515372

Epoch: 5| Step: 7
Training loss: 2.7229777820814083
Validation loss: 2.499058267153455

Epoch: 5| Step: 8
Training loss: 2.8161385629874154
Validation loss: 2.4920364556818244

Epoch: 5| Step: 9
Training loss: 2.8656627124230916
Validation loss: 2.5038503038092856

Epoch: 5| Step: 10
Training loss: 2.6977109990224726
Validation loss: 2.502243300925397

Epoch: 65| Step: 0
Training loss: 2.498086673995167
Validation loss: 2.511722867386888

Epoch: 5| Step: 1
Training loss: 2.1681475591379384
Validation loss: 2.498421841537912

Epoch: 5| Step: 2
Training loss: 2.5173441065656075
Validation loss: 2.5059658690306574

Epoch: 5| Step: 3
Training loss: 2.98804284435027
Validation loss: 2.5007589198365734

Epoch: 5| Step: 4
Training loss: 3.2759432067792273
Validation loss: 2.5045298176690105

Epoch: 5| Step: 5
Training loss: 2.8745519869488163
Validation loss: 2.506670342936642

Epoch: 5| Step: 6
Training loss: 3.016285720152065
Validation loss: 2.506717228416618

Epoch: 5| Step: 7
Training loss: 3.0474643235156313
Validation loss: 2.498862587181727

Epoch: 5| Step: 8
Training loss: 3.0376064077820604
Validation loss: 2.5006035250591103

Epoch: 5| Step: 9
Training loss: 3.106808624080369
Validation loss: 2.500535857802475

Epoch: 5| Step: 10
Training loss: 2.5756816961634006
Validation loss: 2.5000534846624567

Epoch: 66| Step: 0
Training loss: 2.395504727149715
Validation loss: 2.4914971816826577

Epoch: 5| Step: 1
Training loss: 2.397987149481746
Validation loss: 2.5045772877652213

Epoch: 5| Step: 2
Training loss: 3.2916335253113482
Validation loss: 2.4843969320261876

Epoch: 5| Step: 3
Training loss: 2.6355008399598736
Validation loss: 2.493886468240287

Epoch: 5| Step: 4
Training loss: 2.931072263880382
Validation loss: 2.498335895641135

Epoch: 5| Step: 5
Training loss: 2.3230873239092964
Validation loss: 2.4979050626417405

Epoch: 5| Step: 6
Training loss: 3.13952890883476
Validation loss: 2.502473810089672

Epoch: 5| Step: 7
Training loss: 2.642045220368525
Validation loss: 2.499307934532393

Epoch: 5| Step: 8
Training loss: 2.9216577785753524
Validation loss: 2.491898782687294

Epoch: 5| Step: 9
Training loss: 3.3929365163137595
Validation loss: 2.5031633739022077

Epoch: 5| Step: 10
Training loss: 2.806228341951458
Validation loss: 2.512598029419916

Epoch: 67| Step: 0
Training loss: 2.12784845513118
Validation loss: 2.505183145442797

Epoch: 5| Step: 1
Training loss: 2.958560200620119
Validation loss: 2.493623131581072

Epoch: 5| Step: 2
Training loss: 2.8326045015186865
Validation loss: 2.4919101250716147

Epoch: 5| Step: 3
Training loss: 3.461645738455467
Validation loss: 2.5005187562865268

Epoch: 5| Step: 4
Training loss: 2.7051926130725
Validation loss: 2.484305391312273

Epoch: 5| Step: 5
Training loss: 2.9803634764951688
Validation loss: 2.478646727884408

Epoch: 5| Step: 6
Training loss: 2.602435357924437
Validation loss: 2.4925505120784237

Epoch: 5| Step: 7
Training loss: 2.9183117359813875
Validation loss: 2.4781855248597715

Epoch: 5| Step: 8
Training loss: 2.7264566920170994
Validation loss: 2.50028816838837

Epoch: 5| Step: 9
Training loss: 2.894652823547596
Validation loss: 2.4970185252110118

Epoch: 5| Step: 10
Training loss: 2.859598953565331
Validation loss: 2.498000015619382

Epoch: 68| Step: 0
Training loss: 2.9248087633005824
Validation loss: 2.49868147853281

Epoch: 5| Step: 1
Training loss: 2.868011439376427
Validation loss: 2.5029196323590996

Epoch: 5| Step: 2
Training loss: 2.1855493840398355
Validation loss: 2.496640936901846

Epoch: 5| Step: 3
Training loss: 3.056635632983144
Validation loss: 2.5086613538692997

Epoch: 5| Step: 4
Training loss: 2.9305233182736004
Validation loss: 2.496337866363056

Epoch: 5| Step: 5
Training loss: 3.3091008722096245
Validation loss: 2.490375249884477

Epoch: 5| Step: 6
Training loss: 2.7296881917549745
Validation loss: 2.4818794841246925

Epoch: 5| Step: 7
Training loss: 2.591291802414624
Validation loss: 2.4905853424371425

Epoch: 5| Step: 8
Training loss: 2.802226397373169
Validation loss: 2.4925016290797974

Epoch: 5| Step: 9
Training loss: 2.6757211942963965
Validation loss: 2.496792860357619

Epoch: 5| Step: 10
Training loss: 2.945884102721538
Validation loss: 2.4941936026713445

Epoch: 69| Step: 0
Training loss: 2.7462329205210656
Validation loss: 2.4968281867618667

Epoch: 5| Step: 1
Training loss: 3.272840349815936
Validation loss: 2.494548709649336

Epoch: 5| Step: 2
Training loss: 2.558325553989905
Validation loss: 2.489412850156427

Epoch: 5| Step: 3
Training loss: 2.9774168695716696
Validation loss: 2.4929948439594227

Epoch: 5| Step: 4
Training loss: 2.571913942063073
Validation loss: 2.4909786769990907

Epoch: 5| Step: 5
Training loss: 3.168843742353376
Validation loss: 2.504847836625561

Epoch: 5| Step: 6
Training loss: 2.5275167556343137
Validation loss: 2.502807881042287

Epoch: 5| Step: 7
Training loss: 2.0709899945424937
Validation loss: 2.486811721869605

Epoch: 5| Step: 8
Training loss: 2.9795077113144424
Validation loss: 2.4936253111068005

Epoch: 5| Step: 9
Training loss: 3.0172111806626694
Validation loss: 2.50442629256174

Epoch: 5| Step: 10
Training loss: 2.9676767115695215
Validation loss: 2.499692227276917

Epoch: 70| Step: 0
Training loss: 2.954994538329575
Validation loss: 2.504819736031553

Epoch: 5| Step: 1
Training loss: 2.8522720917200517
Validation loss: 2.497334616073944

Epoch: 5| Step: 2
Training loss: 2.177274072009207
Validation loss: 2.5103393736476494

Epoch: 5| Step: 3
Training loss: 3.252863136327626
Validation loss: 2.4889113444819544

Epoch: 5| Step: 4
Training loss: 2.6323140292217224
Validation loss: 2.5187801487016364

Epoch: 5| Step: 5
Training loss: 3.6973740873634546
Validation loss: 2.496471866747547

Epoch: 5| Step: 6
Training loss: 2.8777636637724107
Validation loss: 2.476046925859944

Epoch: 5| Step: 7
Training loss: 3.0025496774291156
Validation loss: 2.497295500079164

Epoch: 5| Step: 8
Training loss: 2.258271378609267
Validation loss: 2.493621887605628

Epoch: 5| Step: 9
Training loss: 2.772539364094162
Validation loss: 2.4827545911994986

Epoch: 5| Step: 10
Training loss: 2.127791646652684
Validation loss: 2.4945067967237717

Epoch: 71| Step: 0
Training loss: 2.868840294707191
Validation loss: 2.4936391942297447

Epoch: 5| Step: 1
Training loss: 2.344161747686453
Validation loss: 2.507070453129585

Epoch: 5| Step: 2
Training loss: 3.2040875733083825
Validation loss: 2.491745508834051

Epoch: 5| Step: 3
Training loss: 2.424643331037652
Validation loss: 2.508218670967014

Epoch: 5| Step: 4
Training loss: 2.726633590164962
Validation loss: 2.510887868355883

Epoch: 5| Step: 5
Training loss: 3.1100849510439357
Validation loss: 2.5011398793148745

Epoch: 5| Step: 6
Training loss: 2.5472357558798353
Validation loss: 2.505619992439541

Epoch: 5| Step: 7
Training loss: 3.2443560965657334
Validation loss: 2.5101370894277237

Epoch: 5| Step: 8
Training loss: 2.921198149430275
Validation loss: 2.498724967105052

Epoch: 5| Step: 9
Training loss: 2.841415285269694
Validation loss: 2.506113735346146

Epoch: 5| Step: 10
Training loss: 2.6654765831257365
Validation loss: 2.4921378928831843

Epoch: 72| Step: 0
Training loss: 2.7782654768588992
Validation loss: 2.5026290667121063

Epoch: 5| Step: 1
Training loss: 2.861445776698101
Validation loss: 2.5076066182679217

Epoch: 5| Step: 2
Training loss: 2.392077833536011
Validation loss: 2.49202930700457

Epoch: 5| Step: 3
Training loss: 3.0138092108613406
Validation loss: 2.495973663134861

Epoch: 5| Step: 4
Training loss: 2.8169897059752556
Validation loss: 2.5123450112917687

Epoch: 5| Step: 5
Training loss: 2.402538856088927
Validation loss: 2.5084937632799558

Epoch: 5| Step: 6
Training loss: 3.167003178702404
Validation loss: 2.4905473381590104

Epoch: 5| Step: 7
Training loss: 2.4246721419673865
Validation loss: 2.512453215046182

Epoch: 5| Step: 8
Training loss: 2.6948305445460496
Validation loss: 2.490984469161366

Epoch: 5| Step: 9
Training loss: 3.6532637962164864
Validation loss: 2.5081926840378945

Epoch: 5| Step: 10
Training loss: 2.6059563450761463
Validation loss: 2.5139094103754362

Epoch: 73| Step: 0
Training loss: 2.6819343600508
Validation loss: 2.5179707301154775

Epoch: 5| Step: 1
Training loss: 2.7903890580483357
Validation loss: 2.517170704246136

Epoch: 5| Step: 2
Training loss: 2.4204049848170746
Validation loss: 2.499298048428736

Epoch: 5| Step: 3
Training loss: 2.5671047612960307
Validation loss: 2.5100546679548863

Epoch: 5| Step: 4
Training loss: 2.921671651200175
Validation loss: 2.501162006677557

Epoch: 5| Step: 5
Training loss: 2.5543634518296274
Validation loss: 2.495685661182307

Epoch: 5| Step: 6
Training loss: 2.680395094088295
Validation loss: 2.50753517982799

Epoch: 5| Step: 7
Training loss: 3.0970293639789173
Validation loss: 2.5014843092720036

Epoch: 5| Step: 8
Training loss: 2.5201683953954155
Validation loss: 2.487333835764202

Epoch: 5| Step: 9
Training loss: 3.369027964601887
Validation loss: 2.48606537778582

Epoch: 5| Step: 10
Training loss: 3.390499270872379
Validation loss: 2.4948389843232817

Epoch: 74| Step: 0
Training loss: 2.5247143801053693
Validation loss: 2.5019668717436683

Epoch: 5| Step: 1
Training loss: 3.1831708943196637
Validation loss: 2.49748929707807

Epoch: 5| Step: 2
Training loss: 2.840504901223033
Validation loss: 2.4948785889044722

Epoch: 5| Step: 3
Training loss: 2.216080685176072
Validation loss: 2.4800996373502002

Epoch: 5| Step: 4
Training loss: 2.8615172652397427
Validation loss: 2.4879008888952567

Epoch: 5| Step: 5
Training loss: 2.2339801572842246
Validation loss: 2.5009445005978685

Epoch: 5| Step: 6
Training loss: 2.692235810504495
Validation loss: 2.497645695972952

Epoch: 5| Step: 7
Training loss: 3.264204966794607
Validation loss: 2.5047046222436347

Epoch: 5| Step: 8
Training loss: 3.105209243775987
Validation loss: 2.50046767300667

Epoch: 5| Step: 9
Training loss: 3.0329912041631855
Validation loss: 2.498032107103465

Epoch: 5| Step: 10
Training loss: 2.872253764914144
Validation loss: 2.501177008237519

Epoch: 75| Step: 0
Training loss: 2.0613309841775935
Validation loss: 2.497387390488575

Epoch: 5| Step: 1
Training loss: 2.5185383104292565
Validation loss: 2.4921998234463216

Epoch: 5| Step: 2
Training loss: 3.2726226739351714
Validation loss: 2.503328615693768

Epoch: 5| Step: 3
Training loss: 2.8926615371371427
Validation loss: 2.4849556061108653

Epoch: 5| Step: 4
Training loss: 2.7644473224712134
Validation loss: 2.4890407189409207

Epoch: 5| Step: 5
Training loss: 3.388991423829304
Validation loss: 2.488404607172488

Epoch: 5| Step: 6
Training loss: 2.4650062471198413
Validation loss: 2.5006498456122235

Epoch: 5| Step: 7
Training loss: 3.4529848372377554
Validation loss: 2.508160963776897

Epoch: 5| Step: 8
Training loss: 2.8671865021498606
Validation loss: 2.4896017907909904

Epoch: 5| Step: 9
Training loss: 2.257995598044552
Validation loss: 2.508105732932879

Epoch: 5| Step: 10
Training loss: 2.905102410932422
Validation loss: 2.486962998465475

Testing loss: 2.5459252207188228
