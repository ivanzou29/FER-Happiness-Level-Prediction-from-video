Epoch: 1| Step: 0
Training loss: 6.022237777709961
Validation loss: 5.203605887710407

Epoch: 6| Step: 1
Training loss: 4.548923492431641
Validation loss: 5.186920596707251

Epoch: 6| Step: 2
Training loss: 4.737288475036621
Validation loss: 5.1720940579650225

Epoch: 6| Step: 3
Training loss: 5.930224418640137
Validation loss: 5.155777705613003

Epoch: 6| Step: 4
Training loss: 4.570899963378906
Validation loss: 5.136739187343146

Epoch: 6| Step: 5
Training loss: 4.323402404785156
Validation loss: 5.114642722632295

Epoch: 6| Step: 6
Training loss: 5.648229598999023
Validation loss: 5.090088977608629

Epoch: 6| Step: 7
Training loss: 4.632880687713623
Validation loss: 5.062278306612405

Epoch: 6| Step: 8
Training loss: 4.495336532592773
Validation loss: 5.0324837520558345

Epoch: 6| Step: 9
Training loss: 3.782729148864746
Validation loss: 5.000258917449623

Epoch: 6| Step: 10
Training loss: 5.4233622550964355
Validation loss: 4.966557087436799

Epoch: 6| Step: 11
Training loss: 5.1073198318481445
Validation loss: 4.931460226735761

Epoch: 6| Step: 12
Training loss: 4.609161853790283
Validation loss: 4.894569432863626

Epoch: 6| Step: 13
Training loss: 3.61307954788208
Validation loss: 4.856397418565647

Epoch: 2| Step: 0
Training loss: 5.232302665710449
Validation loss: 4.814626944962368

Epoch: 6| Step: 1
Training loss: 4.771421432495117
Validation loss: 4.770425017162036

Epoch: 6| Step: 2
Training loss: 3.9173178672790527
Validation loss: 4.722066766472273

Epoch: 6| Step: 3
Training loss: 3.913013458251953
Validation loss: 4.669916873337121

Epoch: 6| Step: 4
Training loss: 3.0459299087524414
Validation loss: 4.611266625824795

Epoch: 6| Step: 5
Training loss: 4.189467906951904
Validation loss: 4.550570170084636

Epoch: 6| Step: 6
Training loss: 5.210633277893066
Validation loss: 4.485858286580732

Epoch: 6| Step: 7
Training loss: 4.6265645027160645
Validation loss: 4.420883778602846

Epoch: 6| Step: 8
Training loss: 3.996915578842163
Validation loss: 4.357162544804234

Epoch: 6| Step: 9
Training loss: 4.382020950317383
Validation loss: 4.296240278469619

Epoch: 6| Step: 10
Training loss: 4.277400970458984
Validation loss: 4.2410320876747045

Epoch: 6| Step: 11
Training loss: 4.166150093078613
Validation loss: 4.189677117973246

Epoch: 6| Step: 12
Training loss: 4.308872222900391
Validation loss: 4.138546082281297

Epoch: 6| Step: 13
Training loss: 3.188629388809204
Validation loss: 4.0861990861995245

Epoch: 3| Step: 0
Training loss: 4.187596321105957
Validation loss: 4.040539521043018

Epoch: 6| Step: 1
Training loss: 3.153481960296631
Validation loss: 4.00582201762866

Epoch: 6| Step: 2
Training loss: 3.8470067977905273
Validation loss: 3.987583229618688

Epoch: 6| Step: 3
Training loss: 3.020716667175293
Validation loss: 3.9747240876638763

Epoch: 6| Step: 4
Training loss: 3.1707468032836914
Validation loss: 3.937079155316917

Epoch: 6| Step: 5
Training loss: 3.773178815841675
Validation loss: 3.9205835660298667

Epoch: 6| Step: 6
Training loss: 3.7889037132263184
Validation loss: 3.88958655634234

Epoch: 6| Step: 7
Training loss: 3.6478261947631836
Validation loss: 3.8581832634505404

Epoch: 6| Step: 8
Training loss: 4.589714050292969
Validation loss: 3.8302923838297525

Epoch: 6| Step: 9
Training loss: 3.952502727508545
Validation loss: 3.8040864211256786

Epoch: 6| Step: 10
Training loss: 3.93583083152771
Validation loss: 3.781083901723226

Epoch: 6| Step: 11
Training loss: 2.9745137691497803
Validation loss: 3.7572784398191716

Epoch: 6| Step: 12
Training loss: 3.7762112617492676
Validation loss: 3.7329781747633413

Epoch: 6| Step: 13
Training loss: 5.266835689544678
Validation loss: 3.7104430660124748

Epoch: 4| Step: 0
Training loss: 3.7857015132904053
Validation loss: 3.6875395800477717

Epoch: 6| Step: 1
Training loss: 2.790926694869995
Validation loss: 3.663873213593678

Epoch: 6| Step: 2
Training loss: 2.9226808547973633
Validation loss: 3.6483083642939085

Epoch: 6| Step: 3
Training loss: 3.4806504249572754
Validation loss: 3.6291008918516097

Epoch: 6| Step: 4
Training loss: 3.9984452724456787
Validation loss: 3.610309939230642

Epoch: 6| Step: 5
Training loss: 3.2279062271118164
Validation loss: 3.582407407863166

Epoch: 6| Step: 6
Training loss: 3.231678009033203
Validation loss: 3.5705965231823664

Epoch: 6| Step: 7
Training loss: 3.864107608795166
Validation loss: 3.559148278287662

Epoch: 6| Step: 8
Training loss: 2.928370952606201
Validation loss: 3.553826924293272

Epoch: 6| Step: 9
Training loss: 4.081820487976074
Validation loss: 3.5349555605201313

Epoch: 6| Step: 10
Training loss: 4.167156219482422
Validation loss: 3.5280363867359776

Epoch: 6| Step: 11
Training loss: 3.74312686920166
Validation loss: 3.5100720979834117

Epoch: 6| Step: 12
Training loss: 3.280330181121826
Validation loss: 3.488355685305852

Epoch: 6| Step: 13
Training loss: 3.5684423446655273
Validation loss: 3.4701686546366703

Epoch: 5| Step: 0
Training loss: 3.359438419342041
Validation loss: 3.457174106310773

Epoch: 6| Step: 1
Training loss: 3.3963279724121094
Validation loss: 3.44119776961624

Epoch: 6| Step: 2
Training loss: 2.530034303665161
Validation loss: 3.4281825916741484

Epoch: 6| Step: 3
Training loss: 3.112037420272827
Validation loss: 3.414714761959609

Epoch: 6| Step: 4
Training loss: 3.3706791400909424
Validation loss: 3.4010577330025296

Epoch: 6| Step: 5
Training loss: 3.4929358959198
Validation loss: 3.3925193432838685

Epoch: 6| Step: 6
Training loss: 2.700267791748047
Validation loss: 3.3831478113769204

Epoch: 6| Step: 7
Training loss: 3.285562038421631
Validation loss: 3.373967824443694

Epoch: 6| Step: 8
Training loss: 3.590662717819214
Validation loss: 3.362857216147966

Epoch: 6| Step: 9
Training loss: 3.1163833141326904
Validation loss: 3.3547234894126974

Epoch: 6| Step: 10
Training loss: 3.8512961864471436
Validation loss: 3.344648702170259

Epoch: 6| Step: 11
Training loss: 4.23643159866333
Validation loss: 3.330356505609328

Epoch: 6| Step: 12
Training loss: 3.6605658531188965
Validation loss: 3.3201961107151483

Epoch: 6| Step: 13
Training loss: 2.753793954849243
Validation loss: 3.3145144037021104

Epoch: 6| Step: 0
Training loss: 3.4170145988464355
Validation loss: 3.2959052055112776

Epoch: 6| Step: 1
Training loss: 4.703888416290283
Validation loss: 3.2879018988660587

Epoch: 6| Step: 2
Training loss: 3.6950950622558594
Validation loss: 3.2779601748271654

Epoch: 6| Step: 3
Training loss: 2.103109359741211
Validation loss: 3.264374286897721

Epoch: 6| Step: 4
Training loss: 2.9053969383239746
Validation loss: 3.2645055452982583

Epoch: 6| Step: 5
Training loss: 3.6921753883361816
Validation loss: 3.246044420426892

Epoch: 6| Step: 6
Training loss: 2.3074560165405273
Validation loss: 3.2405174778353785

Epoch: 6| Step: 7
Training loss: 2.665870189666748
Validation loss: 3.2379477331715245

Epoch: 6| Step: 8
Training loss: 2.729090690612793
Validation loss: 3.22640295438869

Epoch: 6| Step: 9
Training loss: 3.8130531311035156
Validation loss: 3.215985316102223

Epoch: 6| Step: 10
Training loss: 3.3796744346618652
Validation loss: 3.201229423604986

Epoch: 6| Step: 11
Training loss: 3.196312427520752
Validation loss: 3.1919608193059124

Epoch: 6| Step: 12
Training loss: 3.232706069946289
Validation loss: 3.1859449904452086

Epoch: 6| Step: 13
Training loss: 3.476592779159546
Validation loss: 3.1737686331554125

Epoch: 7| Step: 0
Training loss: 2.5481276512145996
Validation loss: 3.1728989539607877

Epoch: 6| Step: 1
Training loss: 2.7260189056396484
Validation loss: 3.166017219584475

Epoch: 6| Step: 2
Training loss: 3.7658329010009766
Validation loss: 3.1635349130117767

Epoch: 6| Step: 3
Training loss: 2.9967663288116455
Validation loss: 3.1555962998379945

Epoch: 6| Step: 4
Training loss: 2.5288989543914795
Validation loss: 3.1471282025819183

Epoch: 6| Step: 5
Training loss: 3.3444066047668457
Validation loss: 3.136088643022763

Epoch: 6| Step: 6
Training loss: 2.9727509021759033
Validation loss: 3.1235662916655182

Epoch: 6| Step: 7
Training loss: 3.091601848602295
Validation loss: 3.1079898034372637

Epoch: 6| Step: 8
Training loss: 3.7794554233551025
Validation loss: 3.0924988485151723

Epoch: 6| Step: 9
Training loss: 3.6170098781585693
Validation loss: 3.0980060972193235

Epoch: 6| Step: 10
Training loss: 2.7437796592712402
Validation loss: 3.090556603606029

Epoch: 6| Step: 11
Training loss: 3.0699963569641113
Validation loss: 3.0703770627257643

Epoch: 6| Step: 12
Training loss: 3.02486252784729
Validation loss: 3.0812829591894664

Epoch: 6| Step: 13
Training loss: 4.349393844604492
Validation loss: 3.087898951704784

Epoch: 8| Step: 0
Training loss: 2.5279958248138428
Validation loss: 3.0857530768199632

Epoch: 6| Step: 1
Training loss: 2.921201467514038
Validation loss: 3.0697193914844143

Epoch: 6| Step: 2
Training loss: 2.404256820678711
Validation loss: 3.050967316473684

Epoch: 6| Step: 3
Training loss: 3.3749430179595947
Validation loss: 3.044840089736446

Epoch: 6| Step: 4
Training loss: 2.6443932056427
Validation loss: 3.0320047640031382

Epoch: 6| Step: 5
Training loss: 3.0062193870544434
Validation loss: 2.9988983190187843

Epoch: 6| Step: 6
Training loss: 3.382343292236328
Validation loss: 2.9897520772872435

Epoch: 6| Step: 7
Training loss: 3.126997470855713
Validation loss: 2.9773625455876833

Epoch: 6| Step: 8
Training loss: 2.635498046875
Validation loss: 2.9686005961510444

Epoch: 6| Step: 9
Training loss: 3.1613926887512207
Validation loss: 2.9608715862356205

Epoch: 6| Step: 10
Training loss: 3.5431325435638428
Validation loss: 3.001047395890759

Epoch: 6| Step: 11
Training loss: 3.4916086196899414
Validation loss: 2.9435666709817867

Epoch: 6| Step: 12
Training loss: 2.954226493835449
Validation loss: 2.9425843915631695

Epoch: 6| Step: 13
Training loss: 4.343003273010254
Validation loss: 2.9495329241598807

Epoch: 9| Step: 0
Training loss: 3.460026264190674
Validation loss: 2.9465550786705426

Epoch: 6| Step: 1
Training loss: 3.812668800354004
Validation loss: 2.945000797189692

Epoch: 6| Step: 2
Training loss: 3.1917219161987305
Validation loss: 2.959989211892569

Epoch: 6| Step: 3
Training loss: 3.3518447875976562
Validation loss: 2.9429405504657375

Epoch: 6| Step: 4
Training loss: 2.317039966583252
Validation loss: 2.9241584859868532

Epoch: 6| Step: 5
Training loss: 2.212787628173828
Validation loss: 2.9132741676863803

Epoch: 6| Step: 6
Training loss: 2.8753623962402344
Validation loss: 2.91001614703927

Epoch: 6| Step: 7
Training loss: 4.177890777587891
Validation loss: 2.8992964272857993

Epoch: 6| Step: 8
Training loss: 2.874260425567627
Validation loss: 2.877011324769707

Epoch: 6| Step: 9
Training loss: 2.0777738094329834
Validation loss: 2.859085588045018

Epoch: 6| Step: 10
Training loss: 2.418583869934082
Validation loss: 2.8471196184876146

Epoch: 6| Step: 11
Training loss: 3.358339309692383
Validation loss: 2.8460055679403324

Epoch: 6| Step: 12
Training loss: 2.936436176300049
Validation loss: 2.8239437995418424

Epoch: 6| Step: 13
Training loss: 2.8168559074401855
Validation loss: 2.825557747194844

Epoch: 10| Step: 0
Training loss: 2.6883695125579834
Validation loss: 2.839331470510011

Epoch: 6| Step: 1
Training loss: 2.799747943878174
Validation loss: 2.8207634546423472

Epoch: 6| Step: 2
Training loss: 2.8913683891296387
Validation loss: 2.80738708537112

Epoch: 6| Step: 3
Training loss: 3.1296586990356445
Validation loss: 2.81861287547696

Epoch: 6| Step: 4
Training loss: 2.0787675380706787
Validation loss: 2.823387525414908

Epoch: 6| Step: 5
Training loss: 3.243903636932373
Validation loss: 2.8244083517341205

Epoch: 6| Step: 6
Training loss: 3.504761219024658
Validation loss: 2.815401315689087

Epoch: 6| Step: 7
Training loss: 3.141669273376465
Validation loss: 2.78653545020729

Epoch: 6| Step: 8
Training loss: 2.7308175563812256
Validation loss: 2.7754003437616492

Epoch: 6| Step: 9
Training loss: 3.095426082611084
Validation loss: 2.772598712675033

Epoch: 6| Step: 10
Training loss: 3.1945509910583496
Validation loss: 2.7854409422925723

Epoch: 6| Step: 11
Training loss: 1.907050371170044
Validation loss: 2.797681126543271

Epoch: 6| Step: 12
Training loss: 3.1233673095703125
Validation loss: 2.784368081759381

Epoch: 6| Step: 13
Training loss: 3.945570230484009
Validation loss: 2.759107930685884

Epoch: 11| Step: 0
Training loss: 3.8029541969299316
Validation loss: 2.7437164219476844

Epoch: 6| Step: 1
Training loss: 3.1692934036254883
Validation loss: 2.7415244861315657

Epoch: 6| Step: 2
Training loss: 2.4570274353027344
Validation loss: 2.7529672550898727

Epoch: 6| Step: 3
Training loss: 2.9745192527770996
Validation loss: 2.763965368270874

Epoch: 6| Step: 4
Training loss: 2.89719820022583
Validation loss: 2.751292279971543

Epoch: 6| Step: 5
Training loss: 2.8475935459136963
Validation loss: 2.741730566947691

Epoch: 6| Step: 6
Training loss: 2.4865522384643555
Validation loss: 2.737012732413507

Epoch: 6| Step: 7
Training loss: 2.974419116973877
Validation loss: 2.734974948308801

Epoch: 6| Step: 8
Training loss: 3.858719825744629
Validation loss: 2.7340302877528693

Epoch: 6| Step: 9
Training loss: 2.1844730377197266
Validation loss: 2.7313068374510734

Epoch: 6| Step: 10
Training loss: 2.793720245361328
Validation loss: 2.719078110110375

Epoch: 6| Step: 11
Training loss: 2.826094627380371
Validation loss: 2.711741534612512

Epoch: 6| Step: 12
Training loss: 2.3427646160125732
Validation loss: 2.7070481854100383

Epoch: 6| Step: 13
Training loss: 2.850461006164551
Validation loss: 2.6991429841646584

Epoch: 12| Step: 0
Training loss: 2.3683719635009766
Validation loss: 2.695514361063639

Epoch: 6| Step: 1
Training loss: 3.719975471496582
Validation loss: 2.697672454259729

Epoch: 6| Step: 2
Training loss: 2.6125338077545166
Validation loss: 2.694812890022032

Epoch: 6| Step: 3
Training loss: 2.4159340858459473
Validation loss: 2.712549612086306

Epoch: 6| Step: 4
Training loss: 3.100883960723877
Validation loss: 2.697698482903101

Epoch: 6| Step: 5
Training loss: 3.0662620067596436
Validation loss: 2.6798566977183023

Epoch: 6| Step: 6
Training loss: 2.59657883644104
Validation loss: 2.6777290964639313

Epoch: 6| Step: 7
Training loss: 2.6039254665374756
Validation loss: 2.682110478801112

Epoch: 6| Step: 8
Training loss: 2.288114070892334
Validation loss: 2.6849663437053723

Epoch: 6| Step: 9
Training loss: 3.2816550731658936
Validation loss: 2.6899538501616447

Epoch: 6| Step: 10
Training loss: 2.581735372543335
Validation loss: 2.688035221510036

Epoch: 6| Step: 11
Training loss: 3.307237148284912
Validation loss: 2.687293485928607

Epoch: 6| Step: 12
Training loss: 3.640414237976074
Validation loss: 2.6822355998459684

Epoch: 6| Step: 13
Training loss: 2.191072940826416
Validation loss: 2.6719284647254535

Epoch: 13| Step: 0
Training loss: 3.0757436752319336
Validation loss: 2.6659382081800893

Epoch: 6| Step: 1
Training loss: 3.6367156505584717
Validation loss: 2.6602987550920054

Epoch: 6| Step: 2
Training loss: 2.7798306941986084
Validation loss: 2.656232480079897

Epoch: 6| Step: 3
Training loss: 3.126399517059326
Validation loss: 2.651404478216684

Epoch: 6| Step: 4
Training loss: 2.145327568054199
Validation loss: 2.6473429767034387

Epoch: 6| Step: 5
Training loss: 2.2007336616516113
Validation loss: 2.645365681699527

Epoch: 6| Step: 6
Training loss: 3.4375107288360596
Validation loss: 2.743141051261656

Epoch: 6| Step: 7
Training loss: 2.317117214202881
Validation loss: 2.7145040932522027

Epoch: 6| Step: 8
Training loss: 2.6583409309387207
Validation loss: 2.657535263287124

Epoch: 6| Step: 9
Training loss: 2.3772854804992676
Validation loss: 2.6435022277216755

Epoch: 6| Step: 10
Training loss: 2.325498104095459
Validation loss: 2.654748885862289

Epoch: 6| Step: 11
Training loss: 3.397347927093506
Validation loss: 2.676043136145479

Epoch: 6| Step: 12
Training loss: 2.9321165084838867
Validation loss: 2.6672755031175512

Epoch: 6| Step: 13
Training loss: 3.6810641288757324
Validation loss: 2.6693082086501585

Epoch: 14| Step: 0
Training loss: 2.7743468284606934
Validation loss: 2.6552176244797243

Epoch: 6| Step: 1
Training loss: 3.6418886184692383
Validation loss: 2.654406673164778

Epoch: 6| Step: 2
Training loss: 2.587967872619629
Validation loss: 2.646777929798249

Epoch: 6| Step: 3
Training loss: 3.096771478652954
Validation loss: 2.6425756331413024

Epoch: 6| Step: 4
Training loss: 2.5046119689941406
Validation loss: 2.6462033076952864

Epoch: 6| Step: 5
Training loss: 3.578352451324463
Validation loss: 2.6371337265096684

Epoch: 6| Step: 6
Training loss: 3.2597289085388184
Validation loss: 2.631663235284949

Epoch: 6| Step: 7
Training loss: 2.4495530128479004
Validation loss: 2.635196373026858

Epoch: 6| Step: 8
Training loss: 1.7546188831329346
Validation loss: 2.6239803606464016

Epoch: 6| Step: 9
Training loss: 2.5520071983337402
Validation loss: 2.6235293726767264

Epoch: 6| Step: 10
Training loss: 3.135706901550293
Validation loss: 2.6248914298190864

Epoch: 6| Step: 11
Training loss: 3.2744719982147217
Validation loss: 2.6247458483583186

Epoch: 6| Step: 12
Training loss: 2.2589612007141113
Validation loss: 2.6254959593537035

Epoch: 6| Step: 13
Training loss: 2.674147605895996
Validation loss: 2.623317144250357

Epoch: 15| Step: 0
Training loss: 1.9736547470092773
Validation loss: 2.6214468684247745

Epoch: 6| Step: 1
Training loss: 2.358257293701172
Validation loss: 2.615694627966932

Epoch: 6| Step: 2
Training loss: 2.3422086238861084
Validation loss: 2.613693775669221

Epoch: 6| Step: 3
Training loss: 3.1580166816711426
Validation loss: 2.6090721904590564

Epoch: 6| Step: 4
Training loss: 3.1270997524261475
Validation loss: 2.6035625832055205

Epoch: 6| Step: 5
Training loss: 2.7746810913085938
Validation loss: 2.612369078461842

Epoch: 6| Step: 6
Training loss: 3.4837286472320557
Validation loss: 2.7547693611473165

Epoch: 6| Step: 7
Training loss: 3.1073451042175293
Validation loss: 2.7555871343099945

Epoch: 6| Step: 8
Training loss: 2.5181901454925537
Validation loss: 2.7080321158132246

Epoch: 6| Step: 9
Training loss: 3.36659574508667
Validation loss: 2.661237483383507

Epoch: 6| Step: 10
Training loss: 2.635613203048706
Validation loss: 2.659122372186312

Epoch: 6| Step: 11
Training loss: 2.56732439994812
Validation loss: 2.6513788007920787

Epoch: 6| Step: 12
Training loss: 3.1771321296691895
Validation loss: 2.6525768285156577

Epoch: 6| Step: 13
Training loss: 3.377969741821289
Validation loss: 2.6609557674777125

Epoch: 16| Step: 0
Training loss: 2.8461365699768066
Validation loss: 2.661960781261485

Epoch: 6| Step: 1
Training loss: 3.3949530124664307
Validation loss: 2.651937348868257

Epoch: 6| Step: 2
Training loss: 2.659426212310791
Validation loss: 2.636919698407573

Epoch: 6| Step: 3
Training loss: 2.802525520324707
Validation loss: 2.625271184470064

Epoch: 6| Step: 4
Training loss: 2.3823301792144775
Validation loss: 2.603039497970253

Epoch: 6| Step: 5
Training loss: 2.424762725830078
Validation loss: 2.5854447054606613

Epoch: 6| Step: 6
Training loss: 2.1795661449432373
Validation loss: 2.5781954001354914

Epoch: 6| Step: 7
Training loss: 3.369861125946045
Validation loss: 2.591995123893984

Epoch: 6| Step: 8
Training loss: 2.7343685626983643
Validation loss: 2.670256414721089

Epoch: 6| Step: 9
Training loss: 2.675884962081909
Validation loss: 2.6301698095055035

Epoch: 6| Step: 10
Training loss: 3.5400547981262207
Validation loss: 2.587074923258956

Epoch: 6| Step: 11
Training loss: 2.828340768814087
Validation loss: 2.5956721664756857

Epoch: 6| Step: 12
Training loss: 2.843195915222168
Validation loss: 2.625724620716546

Epoch: 6| Step: 13
Training loss: 2.695887565612793
Validation loss: 2.6418548194311

Epoch: 17| Step: 0
Training loss: 2.5780985355377197
Validation loss: 2.6724163588657173

Epoch: 6| Step: 1
Training loss: 3.6028504371643066
Validation loss: 2.6789108553240375

Epoch: 6| Step: 2
Training loss: 2.8486411571502686
Validation loss: 2.6340123171447427

Epoch: 6| Step: 3
Training loss: 3.011451244354248
Validation loss: 2.599039308486446

Epoch: 6| Step: 4
Training loss: 2.9098024368286133
Validation loss: 2.5761870517525622

Epoch: 6| Step: 5
Training loss: 3.2488865852355957
Validation loss: 2.5656399367957987

Epoch: 6| Step: 6
Training loss: 2.603214740753174
Validation loss: 2.5940849960491223

Epoch: 6| Step: 7
Training loss: 2.511770248413086
Validation loss: 2.6231392839903473

Epoch: 6| Step: 8
Training loss: 3.2228012084960938
Validation loss: 2.669543040696011

Epoch: 6| Step: 9
Training loss: 3.4383459091186523
Validation loss: 2.730377117792765

Epoch: 6| Step: 10
Training loss: 1.8806045055389404
Validation loss: 2.638434843350482

Epoch: 6| Step: 11
Training loss: 1.8196357488632202
Validation loss: 2.6238168567739506

Epoch: 6| Step: 12
Training loss: 3.013294219970703
Validation loss: 2.625674304141793

Epoch: 6| Step: 13
Training loss: 2.6987860202789307
Validation loss: 2.596643768331056

Epoch: 18| Step: 0
Training loss: 2.4120430946350098
Validation loss: 2.5937798664134037

Epoch: 6| Step: 1
Training loss: 2.8026437759399414
Validation loss: 2.5921722894073813

Epoch: 6| Step: 2
Training loss: 1.784719467163086
Validation loss: 2.5854379823130946

Epoch: 6| Step: 3
Training loss: 2.626361608505249
Validation loss: 2.5752014293465564

Epoch: 6| Step: 4
Training loss: 2.5918610095977783
Validation loss: 2.578048854745844

Epoch: 6| Step: 5
Training loss: 2.4599626064300537
Validation loss: 2.5855882142179754

Epoch: 6| Step: 6
Training loss: 3.395559310913086
Validation loss: 2.6022250652313232

Epoch: 6| Step: 7
Training loss: 2.1141443252563477
Validation loss: 2.604521805240262

Epoch: 6| Step: 8
Training loss: 3.7166895866394043
Validation loss: 2.610707954693866

Epoch: 6| Step: 9
Training loss: 3.0451252460479736
Validation loss: 2.6034127127739692

Epoch: 6| Step: 10
Training loss: 3.2735490798950195
Validation loss: 2.5871325359549573

Epoch: 6| Step: 11
Training loss: 2.6090917587280273
Validation loss: 2.5736733200729534

Epoch: 6| Step: 12
Training loss: 2.983294725418091
Validation loss: 2.560413673359861

Epoch: 6| Step: 13
Training loss: 3.7729711532592773
Validation loss: 2.5567022267208306

Epoch: 19| Step: 0
Training loss: 2.9693443775177
Validation loss: 2.5540512915580504

Epoch: 6| Step: 1
Training loss: 2.922011375427246
Validation loss: 2.5631330731094524

Epoch: 6| Step: 2
Training loss: 3.005326271057129
Validation loss: 2.570677957227153

Epoch: 6| Step: 3
Training loss: 2.9071755409240723
Validation loss: 2.5715510845184326

Epoch: 6| Step: 4
Training loss: 2.634174346923828
Validation loss: 2.568869524104621

Epoch: 6| Step: 5
Training loss: 2.785551071166992
Validation loss: 2.571422279521983

Epoch: 6| Step: 6
Training loss: 2.4803361892700195
Validation loss: 2.569174007702899

Epoch: 6| Step: 7
Training loss: 2.827563762664795
Validation loss: 2.565653525372987

Epoch: 6| Step: 8
Training loss: 3.263768196105957
Validation loss: 2.5672292452986523

Epoch: 6| Step: 9
Training loss: 1.9671485424041748
Validation loss: 2.5672164450409594

Epoch: 6| Step: 10
Training loss: 2.5289363861083984
Validation loss: 2.5607316929806947

Epoch: 6| Step: 11
Training loss: 3.3379976749420166
Validation loss: 2.565586761761737

Epoch: 6| Step: 12
Training loss: 2.5018470287323
Validation loss: 2.56503907070365

Epoch: 6| Step: 13
Training loss: 2.9628868103027344
Validation loss: 2.5639794488107004

Epoch: 20| Step: 0
Training loss: 2.351600170135498
Validation loss: 2.5650450311681277

Epoch: 6| Step: 1
Training loss: 3.5058281421661377
Validation loss: 2.554509993522398

Epoch: 6| Step: 2
Training loss: 2.853773593902588
Validation loss: 2.557081443007274

Epoch: 6| Step: 3
Training loss: 2.9211666584014893
Validation loss: 2.544583423163301

Epoch: 6| Step: 4
Training loss: 1.8474246263504028
Validation loss: 2.5551471300022577

Epoch: 6| Step: 5
Training loss: 2.2001819610595703
Validation loss: 2.6215979514583463

Epoch: 6| Step: 6
Training loss: 2.3480000495910645
Validation loss: 2.69055147581203

Epoch: 6| Step: 7
Training loss: 3.53317928314209
Validation loss: 2.6576057608409593

Epoch: 6| Step: 8
Training loss: 3.264712333679199
Validation loss: 2.598487820676578

Epoch: 6| Step: 9
Training loss: 2.960965633392334
Validation loss: 2.5567161447258404

Epoch: 6| Step: 10
Training loss: 2.5920026302337646
Validation loss: 2.5284656760513142

Epoch: 6| Step: 11
Training loss: 2.906228542327881
Validation loss: 2.5340319910357074

Epoch: 6| Step: 12
Training loss: 2.7839534282684326
Validation loss: 2.5579978881343717

Epoch: 6| Step: 13
Training loss: 3.1088504791259766
Validation loss: 2.5975839296976724

Epoch: 21| Step: 0
Training loss: 2.4800302982330322
Validation loss: 2.6487772618570635

Epoch: 6| Step: 1
Training loss: 2.1880850791931152
Validation loss: 2.6883642160764305

Epoch: 6| Step: 2
Training loss: 2.0811171531677246
Validation loss: 2.7593797996479976

Epoch: 6| Step: 3
Training loss: 3.0180118083953857
Validation loss: 2.7656255178554083

Epoch: 6| Step: 4
Training loss: 3.17226505279541
Validation loss: 2.7226001498519734

Epoch: 6| Step: 5
Training loss: 3.0302042961120605
Validation loss: 2.687644274004044

Epoch: 6| Step: 6
Training loss: 2.5274834632873535
Validation loss: 2.671063951266709

Epoch: 6| Step: 7
Training loss: 3.198354721069336
Validation loss: 2.6396545158919467

Epoch: 6| Step: 8
Training loss: 2.4836368560791016
Validation loss: 2.6209674086622012

Epoch: 6| Step: 9
Training loss: 2.4325671195983887
Validation loss: 2.5985169615796817

Epoch: 6| Step: 10
Training loss: 3.9418931007385254
Validation loss: 2.569213528786936

Epoch: 6| Step: 11
Training loss: 3.487903118133545
Validation loss: 2.518938156866258

Epoch: 6| Step: 12
Training loss: 2.782278537750244
Validation loss: 2.5184003870974303

Epoch: 6| Step: 13
Training loss: 2.7925593852996826
Validation loss: 2.536977001415786

Epoch: 22| Step: 0
Training loss: 3.4136013984680176
Validation loss: 2.6515772778500795

Epoch: 6| Step: 1
Training loss: 2.7280261516571045
Validation loss: 2.66565711780261

Epoch: 6| Step: 2
Training loss: 3.0295259952545166
Validation loss: 2.6552449195615706

Epoch: 6| Step: 3
Training loss: 3.1677634716033936
Validation loss: 2.605994616785357

Epoch: 6| Step: 4
Training loss: 2.246293306350708
Validation loss: 2.5304243846606185

Epoch: 6| Step: 5
Training loss: 3.219273090362549
Validation loss: 2.5060732851746264

Epoch: 6| Step: 6
Training loss: 2.0535149574279785
Validation loss: 2.50179616097481

Epoch: 6| Step: 7
Training loss: 2.4688429832458496
Validation loss: 2.505067794553695

Epoch: 6| Step: 8
Training loss: 3.287309169769287
Validation loss: 2.5101072788238525

Epoch: 6| Step: 9
Training loss: 2.6550254821777344
Validation loss: 2.5123448089886735

Epoch: 6| Step: 10
Training loss: 2.2313079833984375
Validation loss: 2.5121218747990106

Epoch: 6| Step: 11
Training loss: 2.5927300453186035
Validation loss: 2.5087524434571624

Epoch: 6| Step: 12
Training loss: 2.831272602081299
Validation loss: 2.5016182084237375

Epoch: 6| Step: 13
Training loss: 3.0824813842773438
Validation loss: 2.496849157476938

Epoch: 23| Step: 0
Training loss: 2.5305185317993164
Validation loss: 2.5039014944466214

Epoch: 6| Step: 1
Training loss: 2.9801340103149414
Validation loss: 2.517238234960905

Epoch: 6| Step: 2
Training loss: 2.5199711322784424
Validation loss: 2.5365393059228056

Epoch: 6| Step: 3
Training loss: 3.1834921836853027
Validation loss: 2.6078655822302705

Epoch: 6| Step: 4
Training loss: 3.2793562412261963
Validation loss: 2.6770038553463515

Epoch: 6| Step: 5
Training loss: 2.317298650741577
Validation loss: 2.6652021972081994

Epoch: 6| Step: 6
Training loss: 2.480759859085083
Validation loss: 2.649569447322558

Epoch: 6| Step: 7
Training loss: 3.297215461730957
Validation loss: 2.5745556739068802

Epoch: 6| Step: 8
Training loss: 2.927283763885498
Validation loss: 2.5396175666521956

Epoch: 6| Step: 9
Training loss: 2.242032051086426
Validation loss: 2.520403826108543

Epoch: 6| Step: 10
Training loss: 2.865626573562622
Validation loss: 2.509896442454348

Epoch: 6| Step: 11
Training loss: 2.623570203781128
Validation loss: 2.5074759119300434

Epoch: 6| Step: 12
Training loss: 2.042958974838257
Validation loss: 2.5277531839186147

Epoch: 6| Step: 13
Training loss: 3.8815221786499023
Validation loss: 2.5589782704589186

Epoch: 24| Step: 0
Training loss: 2.4410250186920166
Validation loss: 2.5804194224778043

Epoch: 6| Step: 1
Training loss: 2.6696412563323975
Validation loss: 2.6127696985839517

Epoch: 6| Step: 2
Training loss: 3.1153392791748047
Validation loss: 2.6068462658953924

Epoch: 6| Step: 3
Training loss: 2.043412446975708
Validation loss: 2.5956032199244343

Epoch: 6| Step: 4
Training loss: 2.740858554840088
Validation loss: 2.575428893489222

Epoch: 6| Step: 5
Training loss: 2.8761589527130127
Validation loss: 2.5522796723150436

Epoch: 6| Step: 6
Training loss: 3.065089464187622
Validation loss: 2.5158953923051075

Epoch: 6| Step: 7
Training loss: 1.9594016075134277
Validation loss: 2.498552999188823

Epoch: 6| Step: 8
Training loss: 2.791731834411621
Validation loss: 2.4858808748183714

Epoch: 6| Step: 9
Training loss: 3.266388416290283
Validation loss: 2.4784509289649224

Epoch: 6| Step: 10
Training loss: 3.2254512310028076
Validation loss: 2.4845324588078324

Epoch: 6| Step: 11
Training loss: 2.4180095195770264
Validation loss: 2.505679258736231

Epoch: 6| Step: 12
Training loss: 2.6783695220947266
Validation loss: 2.5152950927775395

Epoch: 6| Step: 13
Training loss: 3.984989643096924
Validation loss: 2.5395255986080376

Epoch: 25| Step: 0
Training loss: 2.8199462890625
Validation loss: 2.53652758495782

Epoch: 6| Step: 1
Training loss: 2.190044641494751
Validation loss: 2.522180664923883

Epoch: 6| Step: 2
Training loss: 3.17913818359375
Validation loss: 2.517035112586073

Epoch: 6| Step: 3
Training loss: 3.102196216583252
Validation loss: 2.4991645864261094

Epoch: 6| Step: 4
Training loss: 3.003326892852783
Validation loss: 2.490669740143643

Epoch: 6| Step: 5
Training loss: 2.689251661300659
Validation loss: 2.4803705266726914

Epoch: 6| Step: 6
Training loss: 2.617898941040039
Validation loss: 2.4799186850106842

Epoch: 6| Step: 7
Training loss: 2.76271653175354
Validation loss: 2.4803000445006997

Epoch: 6| Step: 8
Training loss: 1.9979538917541504
Validation loss: 2.4877655326679187

Epoch: 6| Step: 9
Training loss: 2.8815975189208984
Validation loss: 2.48866452452957

Epoch: 6| Step: 10
Training loss: 2.639822483062744
Validation loss: 2.501732651905347

Epoch: 6| Step: 11
Training loss: 2.5467212200164795
Validation loss: 2.5089195133537374

Epoch: 6| Step: 12
Training loss: 3.0646255016326904
Validation loss: 2.5007343599873204

Epoch: 6| Step: 13
Training loss: 2.4377355575561523
Validation loss: 2.4952736054697344

Epoch: 26| Step: 0
Training loss: 2.632798194885254
Validation loss: 2.4950970988119803

Epoch: 6| Step: 1
Training loss: 2.4066896438598633
Validation loss: 2.491014947173416

Epoch: 6| Step: 2
Training loss: 2.569364070892334
Validation loss: 2.4998255622002388

Epoch: 6| Step: 3
Training loss: 3.3829233646392822
Validation loss: 2.4944177186617287

Epoch: 6| Step: 4
Training loss: 3.0547919273376465
Validation loss: 2.4614935485265588

Epoch: 6| Step: 5
Training loss: 2.8097915649414062
Validation loss: 2.458867898551367

Epoch: 6| Step: 6
Training loss: 2.9177422523498535
Validation loss: 2.4590849299584665

Epoch: 6| Step: 7
Training loss: 2.7953972816467285
Validation loss: 2.461392051430159

Epoch: 6| Step: 8
Training loss: 2.482494831085205
Validation loss: 2.4668195427104993

Epoch: 6| Step: 9
Training loss: 2.5682311058044434
Validation loss: 2.464438351251746

Epoch: 6| Step: 10
Training loss: 2.7184972763061523
Validation loss: 2.4622716339685584

Epoch: 6| Step: 11
Training loss: 2.4682981967926025
Validation loss: 2.450175985213249

Epoch: 6| Step: 12
Training loss: 2.469604969024658
Validation loss: 2.4492881272428777

Epoch: 6| Step: 13
Training loss: 2.3179566860198975
Validation loss: 2.4741003410790556

Epoch: 27| Step: 0
Training loss: 2.4609546661376953
Validation loss: 2.4953263549394507

Epoch: 6| Step: 1
Training loss: 2.207063913345337
Validation loss: 2.494199042679161

Epoch: 6| Step: 2
Training loss: 3.52715802192688
Validation loss: 2.450001291049424

Epoch: 6| Step: 3
Training loss: 2.5272984504699707
Validation loss: 2.4501149321115143

Epoch: 6| Step: 4
Training loss: 3.2334377765655518
Validation loss: 2.453379241369104

Epoch: 6| Step: 5
Training loss: 2.8285346031188965
Validation loss: 2.4621078198955906

Epoch: 6| Step: 6
Training loss: 3.0370850563049316
Validation loss: 2.467001784232355

Epoch: 6| Step: 7
Training loss: 2.950413227081299
Validation loss: 2.469738760302144

Epoch: 6| Step: 8
Training loss: 2.4332070350646973
Validation loss: 2.4690451724554903

Epoch: 6| Step: 9
Training loss: 2.8271536827087402
Validation loss: 2.4683243023451937

Epoch: 6| Step: 10
Training loss: 2.557191848754883
Validation loss: 2.4654690450237644

Epoch: 6| Step: 11
Training loss: 2.425720691680908
Validation loss: 2.4593053812621744

Epoch: 6| Step: 12
Training loss: 1.8884912729263306
Validation loss: 2.4569197675233245

Epoch: 6| Step: 13
Training loss: 3.263768196105957
Validation loss: 2.4715458321314987

Epoch: 28| Step: 0
Training loss: 3.31309175491333
Validation loss: 2.4636874019458728

Epoch: 6| Step: 1
Training loss: 2.193178653717041
Validation loss: 2.455934416863226

Epoch: 6| Step: 2
Training loss: 2.657510757446289
Validation loss: 2.4538506102818314

Epoch: 6| Step: 3
Training loss: 2.608529567718506
Validation loss: 2.4540838400522866

Epoch: 6| Step: 4
Training loss: 2.653984546661377
Validation loss: 2.4520737971028974

Epoch: 6| Step: 5
Training loss: 3.5544400215148926
Validation loss: 2.4542338976296048

Epoch: 6| Step: 6
Training loss: 2.564915657043457
Validation loss: 2.4481079680945284

Epoch: 6| Step: 7
Training loss: 2.7953109741210938
Validation loss: 2.443838711707823

Epoch: 6| Step: 8
Training loss: 2.6940698623657227
Validation loss: 2.4489107362685667

Epoch: 6| Step: 9
Training loss: 2.8184752464294434
Validation loss: 2.450235516794266

Epoch: 6| Step: 10
Training loss: 2.062910556793213
Validation loss: 2.4480559210623465

Epoch: 6| Step: 11
Training loss: 2.20565128326416
Validation loss: 2.4602985535898516

Epoch: 6| Step: 12
Training loss: 2.3709206581115723
Validation loss: 2.480636909443845

Epoch: 6| Step: 13
Training loss: 3.6944665908813477
Validation loss: 2.515640643335158

Epoch: 29| Step: 0
Training loss: 1.9712468385696411
Validation loss: 2.522398225722774

Epoch: 6| Step: 1
Training loss: 2.943844795227051
Validation loss: 2.498339888870075

Epoch: 6| Step: 2
Training loss: 2.406954288482666
Validation loss: 2.4771555418609292

Epoch: 6| Step: 3
Training loss: 2.6677310466766357
Validation loss: 2.4614524687490156

Epoch: 6| Step: 4
Training loss: 2.5852630138397217
Validation loss: 2.4498865245490946

Epoch: 6| Step: 5
Training loss: 2.63858962059021
Validation loss: 2.444183849519299

Epoch: 6| Step: 6
Training loss: 2.367692470550537
Validation loss: 2.448680398284748

Epoch: 6| Step: 7
Training loss: 2.58988618850708
Validation loss: 2.457270392807581

Epoch: 6| Step: 8
Training loss: 2.7875139713287354
Validation loss: 2.460571937663581

Epoch: 6| Step: 9
Training loss: 2.9640562534332275
Validation loss: 2.454092256484493

Epoch: 6| Step: 10
Training loss: 2.4421520233154297
Validation loss: 2.443199243596805

Epoch: 6| Step: 11
Training loss: 2.866398811340332
Validation loss: 2.437894380220803

Epoch: 6| Step: 12
Training loss: 3.1992084980010986
Validation loss: 2.4434554294873307

Epoch: 6| Step: 13
Training loss: 3.2599050998687744
Validation loss: 2.43806722856337

Epoch: 30| Step: 0
Training loss: 2.6673455238342285
Validation loss: 2.4334309049831924

Epoch: 6| Step: 1
Training loss: 2.756880283355713
Validation loss: 2.4322517559092534

Epoch: 6| Step: 2
Training loss: 2.3327395915985107
Validation loss: 2.429977919465752

Epoch: 6| Step: 3
Training loss: 2.083066463470459
Validation loss: 2.4410657933963242

Epoch: 6| Step: 4
Training loss: 3.0223827362060547
Validation loss: 2.441096495556575

Epoch: 6| Step: 5
Training loss: 2.6812210083007812
Validation loss: 2.426121283602971

Epoch: 6| Step: 6
Training loss: 2.730593681335449
Validation loss: 2.4272360955515215

Epoch: 6| Step: 7
Training loss: 3.303455352783203
Validation loss: 2.4305739351498183

Epoch: 6| Step: 8
Training loss: 3.144038438796997
Validation loss: 2.4514012516185804

Epoch: 6| Step: 9
Training loss: 2.249994993209839
Validation loss: 2.483754324656661

Epoch: 6| Step: 10
Training loss: 1.7692208290100098
Validation loss: 2.5141706492311213

Epoch: 6| Step: 11
Training loss: 2.827552556991577
Validation loss: 2.480939019110895

Epoch: 6| Step: 12
Training loss: 3.3494200706481934
Validation loss: 2.449095738831387

Epoch: 6| Step: 13
Training loss: 2.15092134475708
Validation loss: 2.420317872878044

Epoch: 31| Step: 0
Training loss: 2.921187162399292
Validation loss: 2.424346190626903

Epoch: 6| Step: 1
Training loss: 2.5851621627807617
Validation loss: 2.4325010084336802

Epoch: 6| Step: 2
Training loss: 2.5634326934814453
Validation loss: 2.4361164441672702

Epoch: 6| Step: 3
Training loss: 2.3684120178222656
Validation loss: 2.443943541537049

Epoch: 6| Step: 4
Training loss: 2.6004791259765625
Validation loss: 2.435691028512934

Epoch: 6| Step: 5
Training loss: 3.451723098754883
Validation loss: 2.4348552047565417

Epoch: 6| Step: 6
Training loss: 2.5557758808135986
Validation loss: 2.4337845745907036

Epoch: 6| Step: 7
Training loss: 3.116466760635376
Validation loss: 2.4318411555341495

Epoch: 6| Step: 8
Training loss: 2.3312878608703613
Validation loss: 2.426383913204234

Epoch: 6| Step: 9
Training loss: 3.1078317165374756
Validation loss: 2.4191732073342926

Epoch: 6| Step: 10
Training loss: 1.8062469959259033
Validation loss: 2.415174079197709

Epoch: 6| Step: 11
Training loss: 3.3835177421569824
Validation loss: 2.4172434230004587

Epoch: 6| Step: 12
Training loss: 2.077862024307251
Validation loss: 2.423314622653428

Epoch: 6| Step: 13
Training loss: 2.7450337409973145
Validation loss: 2.4353246945206837

Epoch: 32| Step: 0
Training loss: 3.041642427444458
Validation loss: 2.4585250962165093

Epoch: 6| Step: 1
Training loss: 2.53116512298584
Validation loss: 2.4789582837012505

Epoch: 6| Step: 2
Training loss: 3.323529005050659
Validation loss: 2.4929391594343286

Epoch: 6| Step: 3
Training loss: 2.8510448932647705
Validation loss: 2.49727205563617

Epoch: 6| Step: 4
Training loss: 2.378847599029541
Validation loss: 2.4892163533036427

Epoch: 6| Step: 5
Training loss: 2.2680234909057617
Validation loss: 2.570590939573062

Epoch: 6| Step: 6
Training loss: 3.0024423599243164
Validation loss: 2.57748774046539

Epoch: 6| Step: 7
Training loss: 2.860914707183838
Validation loss: 2.5125761442286993

Epoch: 6| Step: 8
Training loss: 3.0345475673675537
Validation loss: 2.4151285925219135

Epoch: 6| Step: 9
Training loss: 2.619042158126831
Validation loss: 2.4026424295158795

Epoch: 6| Step: 10
Training loss: 2.386776924133301
Validation loss: 2.4043023150454284

Epoch: 6| Step: 11
Training loss: 2.7542247772216797
Validation loss: 2.4208559810474353

Epoch: 6| Step: 12
Training loss: 2.172024726867676
Validation loss: 2.442564977112637

Epoch: 6| Step: 13
Training loss: 2.255223512649536
Validation loss: 2.45709091360851

Epoch: 33| Step: 0
Training loss: 3.1755237579345703
Validation loss: 2.4946406707968762

Epoch: 6| Step: 1
Training loss: 2.591365337371826
Validation loss: 2.5074059424861783

Epoch: 6| Step: 2
Training loss: 2.2935361862182617
Validation loss: 2.5068818907583914

Epoch: 6| Step: 3
Training loss: 2.6499533653259277
Validation loss: 2.495203620644026

Epoch: 6| Step: 4
Training loss: 2.6515893936157227
Validation loss: 2.4692729160349858

Epoch: 6| Step: 5
Training loss: 2.312588691711426
Validation loss: 2.4427280938753517

Epoch: 6| Step: 6
Training loss: 3.1006500720977783
Validation loss: 2.4332995568552325

Epoch: 6| Step: 7
Training loss: 2.993724822998047
Validation loss: 2.412230068637479

Epoch: 6| Step: 8
Training loss: 1.9161447286605835
Validation loss: 2.4064384237412484

Epoch: 6| Step: 9
Training loss: 2.672736406326294
Validation loss: 2.40862714347019

Epoch: 6| Step: 10
Training loss: 2.7073726654052734
Validation loss: 2.4078511025315974

Epoch: 6| Step: 11
Training loss: 2.843167304992676
Validation loss: 2.395539194025019

Epoch: 6| Step: 12
Training loss: 3.5392608642578125
Validation loss: 2.3991073792980564

Epoch: 6| Step: 13
Training loss: 2.1061642169952393
Validation loss: 2.398623797201341

Epoch: 34| Step: 0
Training loss: 2.5612049102783203
Validation loss: 2.404205294065578

Epoch: 6| Step: 1
Training loss: 2.9133191108703613
Validation loss: 2.412931578133696

Epoch: 6| Step: 2
Training loss: 3.071784019470215
Validation loss: 2.4350333059987714

Epoch: 6| Step: 3
Training loss: 3.1995725631713867
Validation loss: 2.471675172928841

Epoch: 6| Step: 4
Training loss: 2.472522497177124
Validation loss: 2.452520469183563

Epoch: 6| Step: 5
Training loss: 2.6671972274780273
Validation loss: 2.4297900558799825

Epoch: 6| Step: 6
Training loss: 2.8587746620178223
Validation loss: 2.4089155427871214

Epoch: 6| Step: 7
Training loss: 2.394171953201294
Validation loss: 2.3861028250827583

Epoch: 6| Step: 8
Training loss: 2.469426155090332
Validation loss: 2.3815337047781995

Epoch: 6| Step: 9
Training loss: 2.584516763687134
Validation loss: 2.3864925343503236

Epoch: 6| Step: 10
Training loss: 2.1779685020446777
Validation loss: 2.3799499234845563

Epoch: 6| Step: 11
Training loss: 2.7336466312408447
Validation loss: 2.3838513384583178

Epoch: 6| Step: 12
Training loss: 2.285574197769165
Validation loss: 2.388955987909789

Epoch: 6| Step: 13
Training loss: 2.658203125
Validation loss: 2.374305543079171

Epoch: 35| Step: 0
Training loss: 2.8877463340759277
Validation loss: 2.3748343195966495

Epoch: 6| Step: 1
Training loss: 2.2735557556152344
Validation loss: 2.379833859782065

Epoch: 6| Step: 2
Training loss: 2.7523584365844727
Validation loss: 2.377657744192308

Epoch: 6| Step: 3
Training loss: 2.8368759155273438
Validation loss: 2.381627713480303

Epoch: 6| Step: 4
Training loss: 2.217388153076172
Validation loss: 2.3837965380760933

Epoch: 6| Step: 5
Training loss: 1.9911845922470093
Validation loss: 2.392065832691808

Epoch: 6| Step: 6
Training loss: 2.1669044494628906
Validation loss: 2.3995878593896025

Epoch: 6| Step: 7
Training loss: 2.780092239379883
Validation loss: 2.389369326253091

Epoch: 6| Step: 8
Training loss: 2.56978440284729
Validation loss: 2.3878213180008756

Epoch: 6| Step: 9
Training loss: 2.9105336666107178
Validation loss: 2.3880471311589724

Epoch: 6| Step: 10
Training loss: 3.6636099815368652
Validation loss: 2.383240061421548

Epoch: 6| Step: 11
Training loss: 2.765291452407837
Validation loss: 2.375827817506688

Epoch: 6| Step: 12
Training loss: 2.1260223388671875
Validation loss: 2.380844505884314

Epoch: 6| Step: 13
Training loss: 3.0988986492156982
Validation loss: 2.3768624823580504

Epoch: 36| Step: 0
Training loss: 2.3222296237945557
Validation loss: 2.3851718646223827

Epoch: 6| Step: 1
Training loss: 2.56478214263916
Validation loss: 2.390316133858055

Epoch: 6| Step: 2
Training loss: 2.599294662475586
Validation loss: 2.379452238800705

Epoch: 6| Step: 3
Training loss: 2.272928237915039
Validation loss: 2.3725074081010717

Epoch: 6| Step: 4
Training loss: 2.40476131439209
Validation loss: 2.3660333387313353

Epoch: 6| Step: 5
Training loss: 3.275063991546631
Validation loss: 2.371862978063604

Epoch: 6| Step: 6
Training loss: 3.129572629928589
Validation loss: 2.37543148122808

Epoch: 6| Step: 7
Training loss: 2.8360414505004883
Validation loss: 2.398704574954125

Epoch: 6| Step: 8
Training loss: 3.084198474884033
Validation loss: 2.461385170618693

Epoch: 6| Step: 9
Training loss: 2.099761962890625
Validation loss: 2.4616126398886404

Epoch: 6| Step: 10
Training loss: 2.870262861251831
Validation loss: 2.4263967596074587

Epoch: 6| Step: 11
Training loss: 2.2060842514038086
Validation loss: 2.40111405106001

Epoch: 6| Step: 12
Training loss: 2.4654088020324707
Validation loss: 2.377038436551248

Epoch: 6| Step: 13
Training loss: 2.6203255653381348
Validation loss: 2.3871631853042112

Epoch: 37| Step: 0
Training loss: 2.9897947311401367
Validation loss: 2.3961777251253844

Epoch: 6| Step: 1
Training loss: 2.638833999633789
Validation loss: 2.4046929510690833

Epoch: 6| Step: 2
Training loss: 2.963116407394409
Validation loss: 2.4074598935342606

Epoch: 6| Step: 3
Training loss: 3.231818199157715
Validation loss: 2.4227576076343493

Epoch: 6| Step: 4
Training loss: 2.853498935699463
Validation loss: 2.415477224575576

Epoch: 6| Step: 5
Training loss: 2.633258819580078
Validation loss: 2.4086073137098745

Epoch: 6| Step: 6
Training loss: 2.5688705444335938
Validation loss: 2.378126246954805

Epoch: 6| Step: 7
Training loss: 2.151378631591797
Validation loss: 2.3611699278636644

Epoch: 6| Step: 8
Training loss: 2.6864452362060547
Validation loss: 2.35003601607456

Epoch: 6| Step: 9
Training loss: 2.352992057800293
Validation loss: 2.350284613588805

Epoch: 6| Step: 10
Training loss: 2.966583251953125
Validation loss: 2.3462461989413024

Epoch: 6| Step: 11
Training loss: 2.022676944732666
Validation loss: 2.3512604672421693

Epoch: 6| Step: 12
Training loss: 2.2303073406219482
Validation loss: 2.352207765784315

Epoch: 6| Step: 13
Training loss: 2.4044101238250732
Validation loss: 2.349507988140147

Epoch: 38| Step: 0
Training loss: 2.488107919692993
Validation loss: 2.3689086193679483

Epoch: 6| Step: 1
Training loss: 3.012936592102051
Validation loss: 2.371211228832122

Epoch: 6| Step: 2
Training loss: 2.5690994262695312
Validation loss: 2.3834996428540958

Epoch: 6| Step: 3
Training loss: 2.708672046661377
Validation loss: 2.3951341029136413

Epoch: 6| Step: 4
Training loss: 2.4547417163848877
Validation loss: 2.386887558044926

Epoch: 6| Step: 5
Training loss: 1.714543104171753
Validation loss: 2.395193443503431

Epoch: 6| Step: 6
Training loss: 3.2237911224365234
Validation loss: 2.4029394965017996

Epoch: 6| Step: 7
Training loss: 2.171480178833008
Validation loss: 2.442480400044431

Epoch: 6| Step: 8
Training loss: 2.1624088287353516
Validation loss: 2.4747695487032653

Epoch: 6| Step: 9
Training loss: 3.2875735759735107
Validation loss: 2.4483763069234867

Epoch: 6| Step: 10
Training loss: 3.1287059783935547
Validation loss: 2.447174446557158

Epoch: 6| Step: 11
Training loss: 2.3547544479370117
Validation loss: 2.418222327386179

Epoch: 6| Step: 12
Training loss: 2.6437301635742188
Validation loss: 2.3902427791267313

Epoch: 6| Step: 13
Training loss: 2.871701955795288
Validation loss: 2.375426100146386

Epoch: 39| Step: 0
Training loss: 3.210679292678833
Validation loss: 2.3533567228624896

Epoch: 6| Step: 1
Training loss: 1.9858853816986084
Validation loss: 2.3506263045854467

Epoch: 6| Step: 2
Training loss: 2.6184732913970947
Validation loss: 2.3368519275419173

Epoch: 6| Step: 3
Training loss: 2.7389426231384277
Validation loss: 2.3394217747513966

Epoch: 6| Step: 4
Training loss: 2.978578805923462
Validation loss: 2.3295019057489212

Epoch: 6| Step: 5
Training loss: 2.5166854858398438
Validation loss: 2.32373647792365

Epoch: 6| Step: 6
Training loss: 1.7862353324890137
Validation loss: 2.3271972927995908

Epoch: 6| Step: 7
Training loss: 2.782938003540039
Validation loss: 2.328763766955304

Epoch: 6| Step: 8
Training loss: 2.9816064834594727
Validation loss: 2.33026227899777

Epoch: 6| Step: 9
Training loss: 2.6514134407043457
Validation loss: 2.3307559874749955

Epoch: 6| Step: 10
Training loss: 2.488939046859741
Validation loss: 2.3269618198435795

Epoch: 6| Step: 11
Training loss: 2.577022075653076
Validation loss: 2.32381300516026

Epoch: 6| Step: 12
Training loss: 2.6358227729797363
Validation loss: 2.323825966927313

Epoch: 6| Step: 13
Training loss: 2.6694579124450684
Validation loss: 2.3270462251478627

Epoch: 40| Step: 0
Training loss: 2.94853138923645
Validation loss: 2.336044244868781

Epoch: 6| Step: 1
Training loss: 2.270333766937256
Validation loss: 2.343372839753346

Epoch: 6| Step: 2
Training loss: 2.3198318481445312
Validation loss: 2.3513751158150296

Epoch: 6| Step: 3
Training loss: 2.857276439666748
Validation loss: 2.370620104574388

Epoch: 6| Step: 4
Training loss: 2.604339838027954
Validation loss: 2.3830316066741943

Epoch: 6| Step: 5
Training loss: 2.6724350452423096
Validation loss: 2.4297001361846924

Epoch: 6| Step: 6
Training loss: 2.597881317138672
Validation loss: 2.454534463984992

Epoch: 6| Step: 7
Training loss: 2.613239049911499
Validation loss: 2.432698162653113

Epoch: 6| Step: 8
Training loss: 2.9655373096466064
Validation loss: 2.361962664511896

Epoch: 6| Step: 9
Training loss: 2.1783907413482666
Validation loss: 2.3206405152556715

Epoch: 6| Step: 10
Training loss: 2.267849922180176
Validation loss: 2.31550129126477

Epoch: 6| Step: 11
Training loss: 2.622267246246338
Validation loss: 2.3205223980770318

Epoch: 6| Step: 12
Training loss: 2.5096042156219482
Validation loss: 2.3277283099389847

Epoch: 6| Step: 13
Training loss: 3.6389193534851074
Validation loss: 2.3297753795500724

Epoch: 41| Step: 0
Training loss: 2.2621376514434814
Validation loss: 2.334066173081757

Epoch: 6| Step: 1
Training loss: 1.7849340438842773
Validation loss: 2.3327000500053487

Epoch: 6| Step: 2
Training loss: 1.8465702533721924
Validation loss: 2.3305713233127388

Epoch: 6| Step: 3
Training loss: 2.815399169921875
Validation loss: 2.325329739560363

Epoch: 6| Step: 4
Training loss: 2.1602439880371094
Validation loss: 2.322749755715811

Epoch: 6| Step: 5
Training loss: 3.1242237091064453
Validation loss: 2.321884142455234

Epoch: 6| Step: 6
Training loss: 3.669309616088867
Validation loss: 2.3245986174511653

Epoch: 6| Step: 7
Training loss: 3.0308501720428467
Validation loss: 2.3350066318306872

Epoch: 6| Step: 8
Training loss: 3.122743606567383
Validation loss: 2.346562247122488

Epoch: 6| Step: 9
Training loss: 3.1384775638580322
Validation loss: 2.372845559991816

Epoch: 6| Step: 10
Training loss: 2.4991888999938965
Validation loss: 2.379444565824283

Epoch: 6| Step: 11
Training loss: 2.856800079345703
Validation loss: 2.358032641872283

Epoch: 6| Step: 12
Training loss: 2.0573537349700928
Validation loss: 2.351451289269232

Epoch: 6| Step: 13
Training loss: 1.7654147148132324
Validation loss: 2.3711670855040192

Epoch: 42| Step: 0
Training loss: 2.8769898414611816
Validation loss: 2.403775971422913

Epoch: 6| Step: 1
Training loss: 2.9046690464019775
Validation loss: 2.423812381682857

Epoch: 6| Step: 2
Training loss: 2.051888942718506
Validation loss: 2.398854322330926

Epoch: 6| Step: 3
Training loss: 2.5691895484924316
Validation loss: 2.373976827949606

Epoch: 6| Step: 4
Training loss: 2.362626075744629
Validation loss: 2.3450923709459204

Epoch: 6| Step: 5
Training loss: 2.388566493988037
Validation loss: 2.3349731635021906

Epoch: 6| Step: 6
Training loss: 2.94305157661438
Validation loss: 2.3170442824722617

Epoch: 6| Step: 7
Training loss: 2.5611257553100586
Validation loss: 2.318801180008919

Epoch: 6| Step: 8
Training loss: 3.386496067047119
Validation loss: 2.3395006169555006

Epoch: 6| Step: 9
Training loss: 1.9500229358673096
Validation loss: 2.3595638557146956

Epoch: 6| Step: 10
Training loss: 2.1937882900238037
Validation loss: 2.3717718996027464

Epoch: 6| Step: 11
Training loss: 3.4237170219421387
Validation loss: 2.373280229107026

Epoch: 6| Step: 12
Training loss: 2.261320114135742
Validation loss: 2.3697814633769374

Epoch: 6| Step: 13
Training loss: 3.4150049686431885
Validation loss: 2.3695492116353845

Epoch: 43| Step: 0
Training loss: 2.7273292541503906
Validation loss: 2.379141938301825

Epoch: 6| Step: 1
Training loss: 2.396768569946289
Validation loss: 2.378596116137761

Epoch: 6| Step: 2
Training loss: 2.7782845497131348
Validation loss: 2.3971958262946016

Epoch: 6| Step: 3
Training loss: 2.214649200439453
Validation loss: 2.4103935867227535

Epoch: 6| Step: 4
Training loss: 2.343644618988037
Validation loss: 2.4182977753300823

Epoch: 6| Step: 5
Training loss: 2.7273693084716797
Validation loss: 2.3842546747576807

Epoch: 6| Step: 6
Training loss: 3.1995553970336914
Validation loss: 2.3636821277679934

Epoch: 6| Step: 7
Training loss: 3.2402877807617188
Validation loss: 2.360205627256824

Epoch: 6| Step: 8
Training loss: 3.084646224975586
Validation loss: 2.3664255462666994

Epoch: 6| Step: 9
Training loss: 2.1402406692504883
Validation loss: 2.3791739761188464

Epoch: 6| Step: 10
Training loss: 2.7082815170288086
Validation loss: 2.3774121935649584

Epoch: 6| Step: 11
Training loss: 2.4077816009521484
Validation loss: 2.4113163230239705

Epoch: 6| Step: 12
Training loss: 2.5895919799804688
Validation loss: 2.468483083991594

Epoch: 6| Step: 13
Training loss: 2.1282265186309814
Validation loss: 2.466845712354106

Epoch: 44| Step: 0
Training loss: 2.7710251808166504
Validation loss: 2.3622111402532107

Epoch: 6| Step: 1
Training loss: 3.061549186706543
Validation loss: 2.319641077390281

Epoch: 6| Step: 2
Training loss: 2.165968418121338
Validation loss: 2.3108882750234296

Epoch: 6| Step: 3
Training loss: 3.0667948722839355
Validation loss: 2.3271645884360037

Epoch: 6| Step: 4
Training loss: 2.440418004989624
Validation loss: 2.3417038404813377

Epoch: 6| Step: 5
Training loss: 2.596052646636963
Validation loss: 2.3249656948992

Epoch: 6| Step: 6
Training loss: 2.3246772289276123
Validation loss: 2.3179917412419475

Epoch: 6| Step: 7
Training loss: 2.443942070007324
Validation loss: 2.3104767081558064

Epoch: 6| Step: 8
Training loss: 2.076347589492798
Validation loss: 2.3077947837050243

Epoch: 6| Step: 9
Training loss: 2.356389045715332
Validation loss: 2.301651909787168

Epoch: 6| Step: 10
Training loss: 3.28497576713562
Validation loss: 2.2981384774690032

Epoch: 6| Step: 11
Training loss: 2.4643752574920654
Validation loss: 2.2962121386681833

Epoch: 6| Step: 12
Training loss: 2.8376212120056152
Validation loss: 2.2965456067874865

Epoch: 6| Step: 13
Training loss: 2.820056915283203
Validation loss: 2.2938683571354037

Epoch: 45| Step: 0
Training loss: 2.9693660736083984
Validation loss: 2.2950495750673356

Epoch: 6| Step: 1
Training loss: 2.5497426986694336
Validation loss: 2.2965144547083045

Epoch: 6| Step: 2
Training loss: 2.185194969177246
Validation loss: 2.3071550515390213

Epoch: 6| Step: 3
Training loss: 2.889862298965454
Validation loss: 2.323073394836918

Epoch: 6| Step: 4
Training loss: 2.2943785190582275
Validation loss: 2.328802021600867

Epoch: 6| Step: 5
Training loss: 2.0411183834075928
Validation loss: 2.3330368200937905

Epoch: 6| Step: 6
Training loss: 1.8821182250976562
Validation loss: 2.3657984502853884

Epoch: 6| Step: 7
Training loss: 2.42201566696167
Validation loss: 2.3976503161973852

Epoch: 6| Step: 8
Training loss: 3.380310535430908
Validation loss: 2.3883547295806227

Epoch: 6| Step: 9
Training loss: 3.6066973209381104
Validation loss: 2.371124498305782

Epoch: 6| Step: 10
Training loss: 2.66467547416687
Validation loss: 2.352018820342197

Epoch: 6| Step: 11
Training loss: 2.238433599472046
Validation loss: 2.3235540620742308

Epoch: 6| Step: 12
Training loss: 2.958827018737793
Validation loss: 2.3019106875183764

Epoch: 6| Step: 13
Training loss: 2.2010583877563477
Validation loss: 2.2961837989027782

Epoch: 46| Step: 0
Training loss: 3.4579403400421143
Validation loss: 2.2849919744717178

Epoch: 6| Step: 1
Training loss: 2.740401268005371
Validation loss: 2.2876537794707925

Epoch: 6| Step: 2
Training loss: 2.4568910598754883
Validation loss: 2.289272200676703

Epoch: 6| Step: 3
Training loss: 2.8214168548583984
Validation loss: 2.289552139979537

Epoch: 6| Step: 4
Training loss: 2.999396324157715
Validation loss: 2.292284470732494

Epoch: 6| Step: 5
Training loss: 1.9482356309890747
Validation loss: 2.2862978443022697

Epoch: 6| Step: 6
Training loss: 2.502209424972534
Validation loss: 2.2935873205943773

Epoch: 6| Step: 7
Training loss: 3.308028221130371
Validation loss: 2.2853341769146662

Epoch: 6| Step: 8
Training loss: 2.6512160301208496
Validation loss: 2.2836187757471555

Epoch: 6| Step: 9
Training loss: 2.4642162322998047
Validation loss: 2.280809812648322

Epoch: 6| Step: 10
Training loss: 1.9603567123413086
Validation loss: 2.2796953737094836

Epoch: 6| Step: 11
Training loss: 3.228569984436035
Validation loss: 2.27871318914557

Epoch: 6| Step: 12
Training loss: 1.336218237876892
Validation loss: 2.2806215734891992

Epoch: 6| Step: 13
Training loss: 2.212416410446167
Validation loss: 2.295785432220787

Epoch: 47| Step: 0
Training loss: 2.405465841293335
Validation loss: 2.318101462497506

Epoch: 6| Step: 1
Training loss: 2.333979368209839
Validation loss: 2.373503956743466

Epoch: 6| Step: 2
Training loss: 3.004523277282715
Validation loss: 2.4218840727242092

Epoch: 6| Step: 3
Training loss: 2.9488108158111572
Validation loss: 2.4490834615563832

Epoch: 6| Step: 4
Training loss: 3.557450294494629
Validation loss: 2.4848269647167576

Epoch: 6| Step: 5
Training loss: 2.3131561279296875
Validation loss: 2.4514787991841636

Epoch: 6| Step: 6
Training loss: 2.1203231811523438
Validation loss: 2.4122259386124147

Epoch: 6| Step: 7
Training loss: 1.8805928230285645
Validation loss: 2.3679306866020284

Epoch: 6| Step: 8
Training loss: 2.9696927070617676
Validation loss: 2.3565015049390894

Epoch: 6| Step: 9
Training loss: 2.5760011672973633
Validation loss: 2.343202555051414

Epoch: 6| Step: 10
Training loss: 2.4896228313446045
Validation loss: 2.315050401995259

Epoch: 6| Step: 11
Training loss: 3.0887625217437744
Validation loss: 2.3111909845823884

Epoch: 6| Step: 12
Training loss: 2.5308899879455566
Validation loss: 2.3052451584928777

Epoch: 6| Step: 13
Training loss: 2.176318883895874
Validation loss: 2.2978517547730477

Epoch: 48| Step: 0
Training loss: 2.635861396789551
Validation loss: 2.29463057620551

Epoch: 6| Step: 1
Training loss: 3.561095714569092
Validation loss: 2.2900864539607877

Epoch: 6| Step: 2
Training loss: 2.394324779510498
Validation loss: 2.279057643746817

Epoch: 6| Step: 3
Training loss: 2.270155906677246
Validation loss: 2.273716349755564

Epoch: 6| Step: 4
Training loss: 2.1399993896484375
Validation loss: 2.2770078848767024

Epoch: 6| Step: 5
Training loss: 2.305903673171997
Validation loss: 2.277996599033315

Epoch: 6| Step: 6
Training loss: 3.4609923362731934
Validation loss: 2.278458305584487

Epoch: 6| Step: 7
Training loss: 2.8824057579040527
Validation loss: 2.274759602803056

Epoch: 6| Step: 8
Training loss: 3.240513801574707
Validation loss: 2.276283000105171

Epoch: 6| Step: 9
Training loss: 3.2448890209198
Validation loss: 2.2749695854802288

Epoch: 6| Step: 10
Training loss: 1.5949881076812744
Validation loss: 2.277156291469451

Epoch: 6| Step: 11
Training loss: 2.594836711883545
Validation loss: 2.275501840858049

Epoch: 6| Step: 12
Training loss: 1.8916987180709839
Validation loss: 2.281729177762103

Epoch: 6| Step: 13
Training loss: 1.2145041227340698
Validation loss: 2.2986014145676807

Epoch: 49| Step: 0
Training loss: 2.2477264404296875
Validation loss: 2.337096373240153

Epoch: 6| Step: 1
Training loss: 3.0058867931365967
Validation loss: 2.4001978392242105

Epoch: 6| Step: 2
Training loss: 2.4021246433258057
Validation loss: 2.483913367794406

Epoch: 6| Step: 3
Training loss: 1.843031883239746
Validation loss: 2.496536911174815

Epoch: 6| Step: 4
Training loss: 2.8638553619384766
Validation loss: 2.488672305178899

Epoch: 6| Step: 5
Training loss: 2.9204630851745605
Validation loss: 2.4803646123537453

Epoch: 6| Step: 6
Training loss: 2.271939754486084
Validation loss: 2.4384848225501274

Epoch: 6| Step: 7
Training loss: 1.7748916149139404
Validation loss: 2.396767488089941

Epoch: 6| Step: 8
Training loss: 2.8850765228271484
Validation loss: 2.3866939621586956

Epoch: 6| Step: 9
Training loss: 3.2941458225250244
Validation loss: 2.3655322341508764

Epoch: 6| Step: 10
Training loss: 3.181169033050537
Validation loss: 2.3216411400866765

Epoch: 6| Step: 11
Training loss: 3.3693594932556152
Validation loss: 2.297784169514974

Epoch: 6| Step: 12
Training loss: 2.411489725112915
Validation loss: 2.27568882255144

Epoch: 6| Step: 13
Training loss: 1.816805362701416
Validation loss: 2.2641433080037436

Epoch: 50| Step: 0
Training loss: 2.5450384616851807
Validation loss: 2.2574665264416764

Epoch: 6| Step: 1
Training loss: 2.5963425636291504
Validation loss: 2.2569201172039075

Epoch: 6| Step: 2
Training loss: 2.5260415077209473
Validation loss: 2.256780944844728

Epoch: 6| Step: 3
Training loss: 3.0364885330200195
Validation loss: 2.256023189072968

Epoch: 6| Step: 4
Training loss: 2.7494633197784424
Validation loss: 2.255635743500084

Epoch: 6| Step: 5
Training loss: 2.3697152137756348
Validation loss: 2.2514278452883483

Epoch: 6| Step: 6
Training loss: 2.718043804168701
Validation loss: 2.2532428285127044

Epoch: 6| Step: 7
Training loss: 2.4312283992767334
Validation loss: 2.2525447158403296

Epoch: 6| Step: 8
Training loss: 2.5329575538635254
Validation loss: 2.2591876317096014

Epoch: 6| Step: 9
Training loss: 2.4889862537384033
Validation loss: 2.2796749889209704

Epoch: 6| Step: 10
Training loss: 2.4600319862365723
Validation loss: 2.297855205433343

Epoch: 6| Step: 11
Training loss: 2.501466989517212
Validation loss: 2.3022641853619645

Epoch: 6| Step: 12
Training loss: 2.8286519050598145
Validation loss: 2.28597286183347

Epoch: 6| Step: 13
Training loss: 1.9263659715652466
Validation loss: 2.275334909398069

Testing loss: 2.4566296365525986
