Epoch: 1| Step: 0
Training loss: 4.0336198806762695
Validation loss: 5.202664416323426

Epoch: 6| Step: 1
Training loss: 5.34227180480957
Validation loss: 5.185102960114838

Epoch: 6| Step: 2
Training loss: 4.987067222595215
Validation loss: 5.1679575827813915

Epoch: 6| Step: 3
Training loss: 4.945130348205566
Validation loss: 5.148499591376192

Epoch: 6| Step: 4
Training loss: 3.954021453857422
Validation loss: 5.126159980732908

Epoch: 6| Step: 5
Training loss: 5.359043121337891
Validation loss: 5.100297194655224

Epoch: 6| Step: 6
Training loss: 4.7500457763671875
Validation loss: 5.071585521903089

Epoch: 6| Step: 7
Training loss: 4.807979583740234
Validation loss: 5.040346273811915

Epoch: 6| Step: 8
Training loss: 4.65579891204834
Validation loss: 5.005113001792662

Epoch: 6| Step: 9
Training loss: 4.538755416870117
Validation loss: 4.967180175165976

Epoch: 6| Step: 10
Training loss: 4.954617023468018
Validation loss: 4.926503878767773

Epoch: 6| Step: 11
Training loss: 5.953822135925293
Validation loss: 4.8825915808318765

Epoch: 6| Step: 12
Training loss: 4.841866493225098
Validation loss: 4.836501803449405

Epoch: 6| Step: 13
Training loss: 4.287408828735352
Validation loss: 4.788552458568286

Epoch: 2| Step: 0
Training loss: 4.482810020446777
Validation loss: 4.739272686742967

Epoch: 6| Step: 1
Training loss: 4.65848445892334
Validation loss: 4.69186722334995

Epoch: 6| Step: 2
Training loss: 5.2633137702941895
Validation loss: 4.643893813574186

Epoch: 6| Step: 3
Training loss: 2.914062976837158
Validation loss: 4.596074468346052

Epoch: 6| Step: 4
Training loss: 4.908608436584473
Validation loss: 4.549779225421208

Epoch: 6| Step: 5
Training loss: 4.008929252624512
Validation loss: 4.5047019271440405

Epoch: 6| Step: 6
Training loss: 4.674564361572266
Validation loss: 4.460248152414958

Epoch: 6| Step: 7
Training loss: 3.672685146331787
Validation loss: 4.420651256397206

Epoch: 6| Step: 8
Training loss: 4.288517475128174
Validation loss: 4.3855945115448325

Epoch: 6| Step: 9
Training loss: 4.776170253753662
Validation loss: 4.353708985031292

Epoch: 6| Step: 10
Training loss: 3.0895605087280273
Validation loss: 4.322979983463083

Epoch: 6| Step: 11
Training loss: 4.3490777015686035
Validation loss: 4.294271843407744

Epoch: 6| Step: 12
Training loss: 5.333901405334473
Validation loss: 4.264546758385115

Epoch: 6| Step: 13
Training loss: 2.7368130683898926
Validation loss: 4.230553380904659

Epoch: 3| Step: 0
Training loss: 5.499788284301758
Validation loss: 4.199659650043775

Epoch: 6| Step: 1
Training loss: 3.1035165786743164
Validation loss: 4.173337372400427

Epoch: 6| Step: 2
Training loss: 3.7187294960021973
Validation loss: 4.14601118077514

Epoch: 6| Step: 3
Training loss: 3.4309325218200684
Validation loss: 4.1171882126920964

Epoch: 6| Step: 4
Training loss: 3.803468704223633
Validation loss: 4.091112880296604

Epoch: 6| Step: 5
Training loss: 2.7037503719329834
Validation loss: 4.077923969555926

Epoch: 6| Step: 6
Training loss: 4.373409271240234
Validation loss: 4.057065820181242

Epoch: 6| Step: 7
Training loss: 4.002414703369141
Validation loss: 4.034584153083063

Epoch: 6| Step: 8
Training loss: 3.3097124099731445
Validation loss: 4.010894539535687

Epoch: 6| Step: 9
Training loss: 4.418948650360107
Validation loss: 3.986545947290236

Epoch: 6| Step: 10
Training loss: 5.088776588439941
Validation loss: 3.96311854803434

Epoch: 6| Step: 11
Training loss: 3.876160144805908
Validation loss: 3.934152700567758

Epoch: 6| Step: 12
Training loss: 4.135851860046387
Validation loss: 3.9085878710592947

Epoch: 6| Step: 13
Training loss: 2.115701675415039
Validation loss: 3.8854566953515493

Epoch: 4| Step: 0
Training loss: 3.2053933143615723
Validation loss: 3.8663825322222967

Epoch: 6| Step: 1
Training loss: 4.091905117034912
Validation loss: 3.8435460521328833

Epoch: 6| Step: 2
Training loss: 3.191206455230713
Validation loss: 3.822576138281053

Epoch: 6| Step: 3
Training loss: 4.510984420776367
Validation loss: 3.8031914618707474

Epoch: 6| Step: 4
Training loss: 4.295126914978027
Validation loss: 3.7863936834437872

Epoch: 6| Step: 5
Training loss: 2.94002103805542
Validation loss: 3.770772816032492

Epoch: 6| Step: 6
Training loss: 3.517643451690674
Validation loss: 3.7557341206458306

Epoch: 6| Step: 7
Training loss: 4.095991611480713
Validation loss: 3.7402420043945312

Epoch: 6| Step: 8
Training loss: 4.107734680175781
Validation loss: 3.727349373602098

Epoch: 6| Step: 9
Training loss: 2.7594492435455322
Validation loss: 3.7145226488831224

Epoch: 6| Step: 10
Training loss: 2.7234668731689453
Validation loss: 3.7074727422447613

Epoch: 6| Step: 11
Training loss: 2.6524875164031982
Validation loss: 3.6994290556958926

Epoch: 6| Step: 12
Training loss: 5.4715576171875
Validation loss: 3.688389890937395

Epoch: 6| Step: 13
Training loss: 3.47635817527771
Validation loss: 3.6778624621770715

Epoch: 5| Step: 0
Training loss: 3.4788198471069336
Validation loss: 3.6695323272417952

Epoch: 6| Step: 1
Training loss: 2.640817165374756
Validation loss: 3.672130633425969

Epoch: 6| Step: 2
Training loss: 3.240863800048828
Validation loss: 3.6574268546155704

Epoch: 6| Step: 3
Training loss: 4.16623592376709
Validation loss: 3.643985358617639

Epoch: 6| Step: 4
Training loss: 3.4402143955230713
Validation loss: 3.6349637790392806

Epoch: 6| Step: 5
Training loss: 2.6802923679351807
Validation loss: 3.6232845244869107

Epoch: 6| Step: 6
Training loss: 3.6279196739196777
Validation loss: 3.6147110795462005

Epoch: 6| Step: 7
Training loss: 4.244414806365967
Validation loss: 3.6037546127073226

Epoch: 6| Step: 8
Training loss: 4.721173286437988
Validation loss: 3.598843733469645

Epoch: 6| Step: 9
Training loss: 3.248417615890503
Validation loss: 3.589301017022902

Epoch: 6| Step: 10
Training loss: 4.236555099487305
Validation loss: 3.5791223177345852

Epoch: 6| Step: 11
Training loss: 2.5283234119415283
Validation loss: 3.566675365612071

Epoch: 6| Step: 12
Training loss: 4.0449395179748535
Validation loss: 3.5584366449745755

Epoch: 6| Step: 13
Training loss: 2.8016152381896973
Validation loss: 3.5461437343269266

Epoch: 6| Step: 0
Training loss: 3.6602203845977783
Validation loss: 3.5460794843653196

Epoch: 6| Step: 1
Training loss: 2.443584442138672
Validation loss: 3.5382495080271075

Epoch: 6| Step: 2
Training loss: 4.090847015380859
Validation loss: 3.5213587719907045

Epoch: 6| Step: 3
Training loss: 3.815000057220459
Validation loss: 3.5092577242082164

Epoch: 6| Step: 4
Training loss: 3.0661985874176025
Validation loss: 3.5124255380322857

Epoch: 6| Step: 5
Training loss: 3.755230665206909
Validation loss: 3.4915941863931637

Epoch: 6| Step: 6
Training loss: 2.5990214347839355
Validation loss: 3.4788675051863476

Epoch: 6| Step: 7
Training loss: 2.727741003036499
Validation loss: 3.474003530317737

Epoch: 6| Step: 8
Training loss: 3.485447883605957
Validation loss: 3.468106928692069

Epoch: 6| Step: 9
Training loss: 3.9899299144744873
Validation loss: 3.4638447530807985

Epoch: 6| Step: 10
Training loss: 2.8931479454040527
Validation loss: 3.455912636172387

Epoch: 6| Step: 11
Training loss: 4.378209114074707
Validation loss: 3.458433461445634

Epoch: 6| Step: 12
Training loss: 4.2093915939331055
Validation loss: 3.4421240821961434

Epoch: 6| Step: 13
Training loss: 2.341290235519409
Validation loss: 3.4318322109919723

Epoch: 7| Step: 0
Training loss: 2.7677595615386963
Validation loss: 3.4274802951402563

Epoch: 6| Step: 1
Training loss: 3.411816120147705
Validation loss: 3.4242484390094714

Epoch: 6| Step: 2
Training loss: 4.442455768585205
Validation loss: 3.412318980821999

Epoch: 6| Step: 3
Training loss: 3.2845356464385986
Validation loss: 3.4022007885799614

Epoch: 6| Step: 4
Training loss: 2.5963821411132812
Validation loss: 3.393031984247187

Epoch: 6| Step: 5
Training loss: 3.379971981048584
Validation loss: 3.3836799667727564

Epoch: 6| Step: 6
Training loss: 3.056119680404663
Validation loss: 3.372074975762316

Epoch: 6| Step: 7
Training loss: 3.9701929092407227
Validation loss: 3.363828597530242

Epoch: 6| Step: 8
Training loss: 2.8880808353424072
Validation loss: 3.3633266597665767

Epoch: 6| Step: 9
Training loss: 2.5773072242736816
Validation loss: 3.3549680017655894

Epoch: 6| Step: 10
Training loss: 3.5515284538269043
Validation loss: 3.3471837966672835

Epoch: 6| Step: 11
Training loss: 3.178730010986328
Validation loss: 3.3442469771190355

Epoch: 6| Step: 12
Training loss: 3.8756062984466553
Validation loss: 3.352767362389513

Epoch: 6| Step: 13
Training loss: 4.0162882804870605
Validation loss: 3.3394624981828915

Epoch: 8| Step: 0
Training loss: 3.0703229904174805
Validation loss: 3.3279382131432973

Epoch: 6| Step: 1
Training loss: 2.627972364425659
Validation loss: 3.3198896172226116

Epoch: 6| Step: 2
Training loss: 3.1734976768493652
Validation loss: 3.3133940363443024

Epoch: 6| Step: 3
Training loss: 4.0237040519714355
Validation loss: 3.310307792437974

Epoch: 6| Step: 4
Training loss: 3.292679786682129
Validation loss: 3.3035403554157545

Epoch: 6| Step: 5
Training loss: 3.0868539810180664
Validation loss: 3.2979916834062144

Epoch: 6| Step: 6
Training loss: 3.8256688117980957
Validation loss: 3.290053541942309

Epoch: 6| Step: 7
Training loss: 2.972429037094116
Validation loss: 3.2822378348278742

Epoch: 6| Step: 8
Training loss: 3.606015920639038
Validation loss: 3.2780616796144875

Epoch: 6| Step: 9
Training loss: 2.9517760276794434
Validation loss: 3.269423330983808

Epoch: 6| Step: 10
Training loss: 2.4918220043182373
Validation loss: 3.2650700666571177

Epoch: 6| Step: 11
Training loss: 3.6325998306274414
Validation loss: 3.257575793932843

Epoch: 6| Step: 12
Training loss: 3.595114231109619
Validation loss: 3.2527301414038545

Epoch: 6| Step: 13
Training loss: 3.2444887161254883
Validation loss: 3.242844189366987

Epoch: 9| Step: 0
Training loss: 2.808330535888672
Validation loss: 3.2402685534569526

Epoch: 6| Step: 1
Training loss: 3.7338404655456543
Validation loss: 3.2351087062589583

Epoch: 6| Step: 2
Training loss: 3.2031683921813965
Validation loss: 3.236318693366102

Epoch: 6| Step: 3
Training loss: 3.0461976528167725
Validation loss: 3.2202403058287916

Epoch: 6| Step: 4
Training loss: 3.1905136108398438
Validation loss: 3.217216096898561

Epoch: 6| Step: 5
Training loss: 3.6712841987609863
Validation loss: 3.214427417324435

Epoch: 6| Step: 6
Training loss: 3.118096113204956
Validation loss: 3.211331452092817

Epoch: 6| Step: 7
Training loss: 2.379082202911377
Validation loss: 3.204210453135993

Epoch: 6| Step: 8
Training loss: 3.9647274017333984
Validation loss: 3.1951005843377884

Epoch: 6| Step: 9
Training loss: 3.1081063747406006
Validation loss: 3.1910129567628265

Epoch: 6| Step: 10
Training loss: 3.175446033477783
Validation loss: 3.1812776391224196

Epoch: 6| Step: 11
Training loss: 2.4497435092926025
Validation loss: 3.1761789937173166

Epoch: 6| Step: 12
Training loss: 3.4594085216522217
Validation loss: 3.1678783944858018

Epoch: 6| Step: 13
Training loss: 3.7860827445983887
Validation loss: 3.1600261093467794

Epoch: 10| Step: 0
Training loss: 2.6235461235046387
Validation loss: 3.1490080202779462

Epoch: 6| Step: 1
Training loss: 1.830835223197937
Validation loss: 3.1344639819155455

Epoch: 6| Step: 2
Training loss: 3.868799924850464
Validation loss: 3.1216628782210813

Epoch: 6| Step: 3
Training loss: 2.585073947906494
Validation loss: 3.0992928576725784

Epoch: 6| Step: 4
Training loss: 3.7524895668029785
Validation loss: 3.110289758251559

Epoch: 6| Step: 5
Training loss: 3.4720687866210938
Validation loss: 3.1009500898340696

Epoch: 6| Step: 6
Training loss: 3.8192787170410156
Validation loss: 3.093244255229991

Epoch: 6| Step: 7
Training loss: 3.3182592391967773
Validation loss: 3.0899635617451002

Epoch: 6| Step: 8
Training loss: 2.7983269691467285
Validation loss: 3.0993337785044024

Epoch: 6| Step: 9
Training loss: 2.8873143196105957
Validation loss: 3.1081914491550897

Epoch: 6| Step: 10
Training loss: 3.012916326522827
Validation loss: 3.1103010459612777

Epoch: 6| Step: 11
Training loss: 3.571516275405884
Validation loss: 3.1096234911231586

Epoch: 6| Step: 12
Training loss: 4.269417762756348
Validation loss: 3.084169603163196

Epoch: 6| Step: 13
Training loss: 1.21965491771698
Validation loss: 3.08845535145011

Epoch: 11| Step: 0
Training loss: 3.1855878829956055
Validation loss: 3.0538855803910123

Epoch: 6| Step: 1
Training loss: 3.6176867485046387
Validation loss: 3.065140534472722

Epoch: 6| Step: 2
Training loss: 3.3262405395507812
Validation loss: 3.055603696453956

Epoch: 6| Step: 3
Training loss: 2.6501200199127197
Validation loss: 3.0403229164820846

Epoch: 6| Step: 4
Training loss: 3.2928686141967773
Validation loss: 3.0217479710937827

Epoch: 6| Step: 5
Training loss: 3.6183359622955322
Validation loss: 3.0135902358639624

Epoch: 6| Step: 6
Training loss: 3.0739691257476807
Validation loss: 3.0263782060274513

Epoch: 6| Step: 7
Training loss: 2.8978042602539062
Validation loss: 2.99975755394146

Epoch: 6| Step: 8
Training loss: 3.88472318649292
Validation loss: 2.994261139182634

Epoch: 6| Step: 9
Training loss: 2.793051242828369
Validation loss: 2.979248341693673

Epoch: 6| Step: 10
Training loss: 3.074026346206665
Validation loss: 2.9795920925755657

Epoch: 6| Step: 11
Training loss: 2.556020498275757
Validation loss: 2.9937694405996673

Epoch: 6| Step: 12
Training loss: 1.651457667350769
Validation loss: 2.9956703493672032

Epoch: 6| Step: 13
Training loss: 3.8476719856262207
Validation loss: 2.9871054157134025

Epoch: 12| Step: 0
Training loss: 3.3493316173553467
Validation loss: 2.9552210607836322

Epoch: 6| Step: 1
Training loss: 2.669407606124878
Validation loss: 2.9639591093986266

Epoch: 6| Step: 2
Training loss: 3.1169626712799072
Validation loss: 2.965936771003149

Epoch: 6| Step: 3
Training loss: 3.448439598083496
Validation loss: 2.9632830440357165

Epoch: 6| Step: 4
Training loss: 2.2755250930786133
Validation loss: 2.929860807234241

Epoch: 6| Step: 5
Training loss: 4.074835300445557
Validation loss: 2.9191640602645053

Epoch: 6| Step: 6
Training loss: 3.7775940895080566
Validation loss: 2.9158779010977796

Epoch: 6| Step: 7
Training loss: 2.54068660736084
Validation loss: 2.9104869058055263

Epoch: 6| Step: 8
Training loss: 2.875504493713379
Validation loss: 2.9055020245172645

Epoch: 6| Step: 9
Training loss: 3.330359935760498
Validation loss: 2.90188753989435

Epoch: 6| Step: 10
Training loss: 2.9309606552124023
Validation loss: 2.9063104609007477

Epoch: 6| Step: 11
Training loss: 2.5102057456970215
Validation loss: 2.8984378640369703

Epoch: 6| Step: 12
Training loss: 2.6223857402801514
Validation loss: 2.8871293862660727

Epoch: 6| Step: 13
Training loss: 2.5395309925079346
Validation loss: 2.8814913431803384

Epoch: 13| Step: 0
Training loss: 2.850076198577881
Validation loss: 2.8766219308299403

Epoch: 6| Step: 1
Training loss: 3.3285727500915527
Validation loss: 2.8730890263793287

Epoch: 6| Step: 2
Training loss: 3.1019535064697266
Validation loss: 2.8653599626274517

Epoch: 6| Step: 3
Training loss: 3.581136703491211
Validation loss: 2.859806006954562

Epoch: 6| Step: 4
Training loss: 2.8872742652893066
Validation loss: 2.854979004911197

Epoch: 6| Step: 5
Training loss: 2.7160377502441406
Validation loss: 2.848570462196104

Epoch: 6| Step: 6
Training loss: 2.984093189239502
Validation loss: 2.8418216218230543

Epoch: 6| Step: 7
Training loss: 2.570622444152832
Validation loss: 2.83956467464406

Epoch: 6| Step: 8
Training loss: 3.474883556365967
Validation loss: 2.836858105915849

Epoch: 6| Step: 9
Training loss: 2.8857388496398926
Validation loss: 2.8330944302261516

Epoch: 6| Step: 10
Training loss: 2.4879040718078613
Validation loss: 2.8350305864887853

Epoch: 6| Step: 11
Training loss: 2.9720821380615234
Validation loss: 2.8316622857124574

Epoch: 6| Step: 12
Training loss: 3.1695034503936768
Validation loss: 2.8280634777520293

Epoch: 6| Step: 13
Training loss: 2.1812493801116943
Validation loss: 2.8183224867748957

Epoch: 14| Step: 0
Training loss: 3.4903388023376465
Validation loss: 2.8187257089922504

Epoch: 6| Step: 1
Training loss: 2.873227119445801
Validation loss: 2.8120987517859346

Epoch: 6| Step: 2
Training loss: 1.9120447635650635
Validation loss: 2.8103079565109743

Epoch: 6| Step: 3
Training loss: 2.6013615131378174
Validation loss: 2.807072808665614

Epoch: 6| Step: 4
Training loss: 2.604299545288086
Validation loss: 2.8077649249825427

Epoch: 6| Step: 5
Training loss: 4.037700653076172
Validation loss: 2.8040868364354616

Epoch: 6| Step: 6
Training loss: 2.362241744995117
Validation loss: 2.7984914728390273

Epoch: 6| Step: 7
Training loss: 3.0366387367248535
Validation loss: 2.797444158984769

Epoch: 6| Step: 8
Training loss: 2.4877872467041016
Validation loss: 2.795167161572364

Epoch: 6| Step: 9
Training loss: 3.281961441040039
Validation loss: 2.7918997785096527

Epoch: 6| Step: 10
Training loss: 3.025667190551758
Validation loss: 2.7886495128754647

Epoch: 6| Step: 11
Training loss: 3.3596017360687256
Validation loss: 2.784960913401778

Epoch: 6| Step: 12
Training loss: 3.228567361831665
Validation loss: 2.7850030622174664

Epoch: 6| Step: 13
Training loss: 2.6413681507110596
Validation loss: 2.7872265461952455

Epoch: 15| Step: 0
Training loss: 3.147136688232422
Validation loss: 2.809745457864577

Epoch: 6| Step: 1
Training loss: 2.728823184967041
Validation loss: 2.8470682508202008

Epoch: 6| Step: 2
Training loss: 2.3554391860961914
Validation loss: 2.7864443153463383

Epoch: 6| Step: 3
Training loss: 3.5026166439056396
Validation loss: 2.7739689273218953

Epoch: 6| Step: 4
Training loss: 2.3242154121398926
Validation loss: 2.7786086733623216

Epoch: 6| Step: 5
Training loss: 3.962841033935547
Validation loss: 2.7867123183383735

Epoch: 6| Step: 6
Training loss: 3.5765628814697266
Validation loss: 2.7780206818734445

Epoch: 6| Step: 7
Training loss: 2.6231627464294434
Validation loss: 2.779597226009574

Epoch: 6| Step: 8
Training loss: 1.8893041610717773
Validation loss: 2.7826145105464484

Epoch: 6| Step: 9
Training loss: 2.793287515640259
Validation loss: 2.796432856590517

Epoch: 6| Step: 10
Training loss: 3.3680450916290283
Validation loss: 2.794595010818974

Epoch: 6| Step: 11
Training loss: 1.9531669616699219
Validation loss: 2.7890029517553185

Epoch: 6| Step: 12
Training loss: 3.883570671081543
Validation loss: 2.787697328034268

Epoch: 6| Step: 13
Training loss: 2.7615339756011963
Validation loss: 2.7812990450089976

Epoch: 16| Step: 0
Training loss: 2.7301084995269775
Validation loss: 2.774337807009297

Epoch: 6| Step: 1
Training loss: 2.908397674560547
Validation loss: 2.7668826169865106

Epoch: 6| Step: 2
Training loss: 2.2970616817474365
Validation loss: 2.769015355776715

Epoch: 6| Step: 3
Training loss: 3.4615590572357178
Validation loss: 2.7689105208202074

Epoch: 6| Step: 4
Training loss: 3.176846742630005
Validation loss: 2.762617798261745

Epoch: 6| Step: 5
Training loss: 2.8303284645080566
Validation loss: 2.7627987553996425

Epoch: 6| Step: 6
Training loss: 3.14207124710083
Validation loss: 2.7608805061668478

Epoch: 6| Step: 7
Training loss: 2.2095179557800293
Validation loss: 2.769166305500974

Epoch: 6| Step: 8
Training loss: 2.839390516281128
Validation loss: 2.766350817936723

Epoch: 6| Step: 9
Training loss: 2.3845832347869873
Validation loss: 2.7522173517493793

Epoch: 6| Step: 10
Training loss: 3.248685359954834
Validation loss: 2.744285081022529

Epoch: 6| Step: 11
Training loss: 3.9181666374206543
Validation loss: 2.738101738755421

Epoch: 6| Step: 12
Training loss: 2.329033851623535
Validation loss: 2.741722627352643

Epoch: 6| Step: 13
Training loss: 3.37054181098938
Validation loss: 2.737504559178506

Epoch: 17| Step: 0
Training loss: 2.420722484588623
Validation loss: 2.7253978585684173

Epoch: 6| Step: 1
Training loss: 2.623715877532959
Validation loss: 2.7191291778318343

Epoch: 6| Step: 2
Training loss: 3.025670051574707
Validation loss: 2.711033326323314

Epoch: 6| Step: 3
Training loss: 2.980515956878662
Validation loss: 2.716052529632404

Epoch: 6| Step: 4
Training loss: 3.5779354572296143
Validation loss: 2.719380945287725

Epoch: 6| Step: 5
Training loss: 3.107762575149536
Validation loss: 2.722984839511174

Epoch: 6| Step: 6
Training loss: 2.557765245437622
Validation loss: 2.720292229806223

Epoch: 6| Step: 7
Training loss: 2.7569656372070312
Validation loss: 2.7056269030417166

Epoch: 6| Step: 8
Training loss: 2.135087490081787
Validation loss: 2.6969664122468684

Epoch: 6| Step: 9
Training loss: 2.6492667198181152
Validation loss: 2.6958593860749276

Epoch: 6| Step: 10
Training loss: 2.9478092193603516
Validation loss: 2.7042219843915714

Epoch: 6| Step: 11
Training loss: 3.2479960918426514
Validation loss: 2.6999139067947224

Epoch: 6| Step: 12
Training loss: 3.4019222259521484
Validation loss: 2.688339300053094

Epoch: 6| Step: 13
Training loss: 2.642554521560669
Validation loss: 2.6872848336414625

Epoch: 18| Step: 0
Training loss: 3.2778611183166504
Validation loss: 2.6831514553357194

Epoch: 6| Step: 1
Training loss: 1.7687976360321045
Validation loss: 2.6856461776200162

Epoch: 6| Step: 2
Training loss: 3.095391273498535
Validation loss: 2.6832578771857807

Epoch: 6| Step: 3
Training loss: 1.8595619201660156
Validation loss: 2.683226252114901

Epoch: 6| Step: 4
Training loss: 2.4616446495056152
Validation loss: 2.682795580997262

Epoch: 6| Step: 5
Training loss: 1.9886499643325806
Validation loss: 2.6768937251901113

Epoch: 6| Step: 6
Training loss: 2.550459384918213
Validation loss: 2.6732762218803487

Epoch: 6| Step: 7
Training loss: 3.010983943939209
Validation loss: 2.6753514530838176

Epoch: 6| Step: 8
Training loss: 3.4990203380584717
Validation loss: 2.672371627182089

Epoch: 6| Step: 9
Training loss: 2.6873342990875244
Validation loss: 2.6781537532806396

Epoch: 6| Step: 10
Training loss: 2.9359915256500244
Validation loss: 2.6749523403824016

Epoch: 6| Step: 11
Training loss: 3.5211405754089355
Validation loss: 2.6696061447102535

Epoch: 6| Step: 12
Training loss: 3.6964609622955322
Validation loss: 2.663451635709373

Epoch: 6| Step: 13
Training loss: 4.088330268859863
Validation loss: 2.6648117419212096

Epoch: 19| Step: 0
Training loss: 3.0118038654327393
Validation loss: 2.6610886460991314

Epoch: 6| Step: 1
Training loss: 2.7669341564178467
Validation loss: 2.6638201359779603

Epoch: 6| Step: 2
Training loss: 2.6667704582214355
Validation loss: 2.6599186594768236

Epoch: 6| Step: 3
Training loss: 2.746741771697998
Validation loss: 2.66764316251201

Epoch: 6| Step: 4
Training loss: 2.3345789909362793
Validation loss: 2.675291610020463

Epoch: 6| Step: 5
Training loss: 3.3744544982910156
Validation loss: 2.660851973359303

Epoch: 6| Step: 6
Training loss: 1.9737796783447266
Validation loss: 2.657516025727795

Epoch: 6| Step: 7
Training loss: 2.008894205093384
Validation loss: 2.6585277562500327

Epoch: 6| Step: 8
Training loss: 3.0015010833740234
Validation loss: 2.6534145775661675

Epoch: 6| Step: 9
Training loss: 2.807680606842041
Validation loss: 2.652360305991224

Epoch: 6| Step: 10
Training loss: 3.1416945457458496
Validation loss: 2.6502434899730067

Epoch: 6| Step: 11
Training loss: 3.0806615352630615
Validation loss: 2.647606466406135

Epoch: 6| Step: 12
Training loss: 3.1561131477355957
Validation loss: 2.650838787837695

Epoch: 6| Step: 13
Training loss: 4.2191667556762695
Validation loss: 2.647439520846131

Epoch: 20| Step: 0
Training loss: 3.5394411087036133
Validation loss: 2.649323373712519

Epoch: 6| Step: 1
Training loss: 2.779294013977051
Validation loss: 2.64410214783043

Epoch: 6| Step: 2
Training loss: 3.3347976207733154
Validation loss: 2.6440326526600826

Epoch: 6| Step: 3
Training loss: 2.096060037612915
Validation loss: 2.640172635355303

Epoch: 6| Step: 4
Training loss: 3.025778293609619
Validation loss: 2.6386027977030766

Epoch: 6| Step: 5
Training loss: 3.171079635620117
Validation loss: 2.638428147121142

Epoch: 6| Step: 6
Training loss: 2.4102587699890137
Validation loss: 2.640284720287528

Epoch: 6| Step: 7
Training loss: 3.070176839828491
Validation loss: 2.6424566622703307

Epoch: 6| Step: 8
Training loss: 2.27712345123291
Validation loss: 2.6684947757310766

Epoch: 6| Step: 9
Training loss: 1.8336330652236938
Validation loss: 2.722917741344821

Epoch: 6| Step: 10
Training loss: 2.6272377967834473
Validation loss: 2.818671252137871

Epoch: 6| Step: 11
Training loss: 3.6873841285705566
Validation loss: 2.855573349101569

Epoch: 6| Step: 12
Training loss: 3.2962381839752197
Validation loss: 2.8291001730067755

Epoch: 6| Step: 13
Training loss: 2.8703463077545166
Validation loss: 2.820029212582496

Epoch: 21| Step: 0
Training loss: 3.0228002071380615
Validation loss: 2.7938587332284577

Epoch: 6| Step: 1
Training loss: 2.4173367023468018
Validation loss: 2.7521494844908356

Epoch: 6| Step: 2
Training loss: 2.0791165828704834
Validation loss: 2.7352628912976993

Epoch: 6| Step: 3
Training loss: 3.5056939125061035
Validation loss: 2.720054554682906

Epoch: 6| Step: 4
Training loss: 3.6262426376342773
Validation loss: 2.7274993850338842

Epoch: 6| Step: 5
Training loss: 3.0727479457855225
Validation loss: 2.7138323322419198

Epoch: 6| Step: 6
Training loss: 2.4108619689941406
Validation loss: 2.713189935171476

Epoch: 6| Step: 7
Training loss: 2.9530396461486816
Validation loss: 2.7286961104280207

Epoch: 6| Step: 8
Training loss: 3.634599208831787
Validation loss: 2.724857617450017

Epoch: 6| Step: 9
Training loss: 2.75494647026062
Validation loss: 2.710017065848074

Epoch: 6| Step: 10
Training loss: 2.7678518295288086
Validation loss: 2.6878765962457143

Epoch: 6| Step: 11
Training loss: 2.2490906715393066
Validation loss: 2.6299031780612085

Epoch: 6| Step: 12
Training loss: 2.633725881576538
Validation loss: 2.6272590801280034

Epoch: 6| Step: 13
Training loss: 3.1675631999969482
Validation loss: 2.6227840351802048

Epoch: 22| Step: 0
Training loss: 1.9521510601043701
Validation loss: 2.6200440596508723

Epoch: 6| Step: 1
Training loss: 3.506826877593994
Validation loss: 2.62036455574856

Epoch: 6| Step: 2
Training loss: 3.566124677658081
Validation loss: 2.627065243259553

Epoch: 6| Step: 3
Training loss: 2.3252153396606445
Validation loss: 2.6216196116580757

Epoch: 6| Step: 4
Training loss: 2.769758701324463
Validation loss: 2.61698842048645

Epoch: 6| Step: 5
Training loss: 2.044604539871216
Validation loss: 2.6127268729671353

Epoch: 6| Step: 6
Training loss: 2.9215030670166016
Validation loss: 2.6135899456598426

Epoch: 6| Step: 7
Training loss: 2.9245681762695312
Validation loss: 2.609615987347018

Epoch: 6| Step: 8
Training loss: 2.369307279586792
Validation loss: 2.6123399067950506

Epoch: 6| Step: 9
Training loss: 2.349118709564209
Validation loss: 2.6072254027089765

Epoch: 6| Step: 10
Training loss: 4.19313907623291
Validation loss: 2.604875146701772

Epoch: 6| Step: 11
Training loss: 2.485011577606201
Validation loss: 2.6080958048502603

Epoch: 6| Step: 12
Training loss: 2.892233371734619
Validation loss: 2.614755645875008

Epoch: 6| Step: 13
Training loss: 3.1808693408966064
Validation loss: 2.6088807634128037

Epoch: 23| Step: 0
Training loss: 2.586439609527588
Validation loss: 2.59700378294914

Epoch: 6| Step: 1
Training loss: 2.442969560623169
Validation loss: 2.59838709779965

Epoch: 6| Step: 2
Training loss: 2.973541498184204
Validation loss: 2.602293501618088

Epoch: 6| Step: 3
Training loss: 2.622360944747925
Validation loss: 2.607491426570441

Epoch: 6| Step: 4
Training loss: 2.2913990020751953
Validation loss: 2.612240165792486

Epoch: 6| Step: 5
Training loss: 2.939574718475342
Validation loss: 2.595640733677854

Epoch: 6| Step: 6
Training loss: 2.814213275909424
Validation loss: 2.594576245994978

Epoch: 6| Step: 7
Training loss: 2.756840229034424
Validation loss: 2.6162602440003426

Epoch: 6| Step: 8
Training loss: 2.6059465408325195
Validation loss: 2.666055869030696

Epoch: 6| Step: 9
Training loss: 2.707543134689331
Validation loss: 2.682782442339005

Epoch: 6| Step: 10
Training loss: 2.992778778076172
Validation loss: 2.66161165442518

Epoch: 6| Step: 11
Training loss: 3.717339515686035
Validation loss: 2.6539011206678165

Epoch: 6| Step: 12
Training loss: 2.6280019283294678
Validation loss: 2.6001050959351244

Epoch: 6| Step: 13
Training loss: 3.2961981296539307
Validation loss: 2.586559272581531

Epoch: 24| Step: 0
Training loss: 2.714843273162842
Validation loss: 2.6018577211646625

Epoch: 6| Step: 1
Training loss: 3.1733431816101074
Validation loss: 2.6318669165334394

Epoch: 6| Step: 2
Training loss: 3.142798900604248
Validation loss: 2.631841295508928

Epoch: 6| Step: 3
Training loss: 3.198474884033203
Validation loss: 2.647698530586817

Epoch: 6| Step: 4
Training loss: 2.5062403678894043
Validation loss: 2.603957099299277

Epoch: 6| Step: 5
Training loss: 2.137260913848877
Validation loss: 2.593037630922051

Epoch: 6| Step: 6
Training loss: 2.7041826248168945
Validation loss: 2.589071863441057

Epoch: 6| Step: 7
Training loss: 2.011967658996582
Validation loss: 2.591180650136804

Epoch: 6| Step: 8
Training loss: 2.6017441749572754
Validation loss: 2.6141515290865334

Epoch: 6| Step: 9
Training loss: 3.5844063758850098
Validation loss: 2.63262858698445

Epoch: 6| Step: 10
Training loss: 2.822561740875244
Validation loss: 2.63061144146868

Epoch: 6| Step: 11
Training loss: 2.809345245361328
Validation loss: 2.624590581463229

Epoch: 6| Step: 12
Training loss: 2.8732619285583496
Validation loss: 2.6196445239487516

Epoch: 6| Step: 13
Training loss: 3.04498028755188
Validation loss: 2.6021256344292754

Epoch: 25| Step: 0
Training loss: 2.9592416286468506
Validation loss: 2.5828247890677503

Epoch: 6| Step: 1
Training loss: 2.7954258918762207
Validation loss: 2.5790873842854656

Epoch: 6| Step: 2
Training loss: 2.153496503829956
Validation loss: 2.58290107019486

Epoch: 6| Step: 3
Training loss: 2.8151137828826904
Validation loss: 2.5821477520850395

Epoch: 6| Step: 4
Training loss: 2.562058925628662
Validation loss: 2.579293233092113

Epoch: 6| Step: 5
Training loss: 2.8672573566436768
Validation loss: 2.580518573843023

Epoch: 6| Step: 6
Training loss: 2.293100357055664
Validation loss: 2.5842881997426352

Epoch: 6| Step: 7
Training loss: 2.177057981491089
Validation loss: 2.5770960802673013

Epoch: 6| Step: 8
Training loss: 3.4902777671813965
Validation loss: 2.581530758129653

Epoch: 6| Step: 9
Training loss: 3.362410545349121
Validation loss: 2.5927259640027116

Epoch: 6| Step: 10
Training loss: 2.116328239440918
Validation loss: 2.6056098989261094

Epoch: 6| Step: 11
Training loss: 3.6766598224639893
Validation loss: 2.5974637923702115

Epoch: 6| Step: 12
Training loss: 3.177544593811035
Validation loss: 2.5843162100802184

Epoch: 6| Step: 13
Training loss: 2.0863542556762695
Validation loss: 2.5747627673610562

Epoch: 26| Step: 0
Training loss: 3.273059606552124
Validation loss: 2.5772590252660934

Epoch: 6| Step: 1
Training loss: 2.824321746826172
Validation loss: 2.5824196697563253

Epoch: 6| Step: 2
Training loss: 3.275787830352783
Validation loss: 2.5723046256649877

Epoch: 6| Step: 3
Training loss: 2.16874098777771
Validation loss: 2.5706247411748415

Epoch: 6| Step: 4
Training loss: 2.739480972290039
Validation loss: 2.5718356819563013

Epoch: 6| Step: 5
Training loss: 2.230541706085205
Validation loss: 2.5693705594667824

Epoch: 6| Step: 6
Training loss: 3.2555034160614014
Validation loss: 2.5684376096212738

Epoch: 6| Step: 7
Training loss: 2.5899782180786133
Validation loss: 2.5668300531243764

Epoch: 6| Step: 8
Training loss: 1.9579360485076904
Validation loss: 2.565850947492866

Epoch: 6| Step: 9
Training loss: 2.7901957035064697
Validation loss: 2.5682138883939354

Epoch: 6| Step: 10
Training loss: 2.771346092224121
Validation loss: 2.561971038900396

Epoch: 6| Step: 11
Training loss: 2.4640305042266846
Validation loss: 2.56317308128521

Epoch: 6| Step: 12
Training loss: 2.3798160552978516
Validation loss: 2.560866435368856

Epoch: 6| Step: 13
Training loss: 4.848475456237793
Validation loss: 2.5633191600922616

Epoch: 27| Step: 0
Training loss: 2.5454413890838623
Validation loss: 2.566940487072032

Epoch: 6| Step: 1
Training loss: 2.403944969177246
Validation loss: 2.5714118455045964

Epoch: 6| Step: 2
Training loss: 2.1684887409210205
Validation loss: 2.576151993966872

Epoch: 6| Step: 3
Training loss: 3.4400205612182617
Validation loss: 2.5687332230229534

Epoch: 6| Step: 4
Training loss: 2.5539650917053223
Validation loss: 2.578427617267896

Epoch: 6| Step: 5
Training loss: 2.5144126415252686
Validation loss: 2.5818278404974166

Epoch: 6| Step: 6
Training loss: 2.6180009841918945
Validation loss: 2.572916805103261

Epoch: 6| Step: 7
Training loss: 3.3430676460266113
Validation loss: 2.5552781986933883

Epoch: 6| Step: 8
Training loss: 2.1722052097320557
Validation loss: 2.5498064564120386

Epoch: 6| Step: 9
Training loss: 2.7992498874664307
Validation loss: 2.5539478589129705

Epoch: 6| Step: 10
Training loss: 3.184910774230957
Validation loss: 2.556409046214114

Epoch: 6| Step: 11
Training loss: 2.5366573333740234
Validation loss: 2.5549876997547765

Epoch: 6| Step: 12
Training loss: 3.268711566925049
Validation loss: 2.5524536512231313

Epoch: 6| Step: 13
Training loss: 3.1184470653533936
Validation loss: 2.548474883520475

Epoch: 28| Step: 0
Training loss: 2.8520591259002686
Validation loss: 2.549718092846614

Epoch: 6| Step: 1
Training loss: 2.704054832458496
Validation loss: 2.5442662597984396

Epoch: 6| Step: 2
Training loss: 1.9739528894424438
Validation loss: 2.540531394302204

Epoch: 6| Step: 3
Training loss: 2.2759625911712646
Validation loss: 2.5454776799806984

Epoch: 6| Step: 4
Training loss: 3.1300671100616455
Validation loss: 2.55115064754281

Epoch: 6| Step: 5
Training loss: 3.0181658267974854
Validation loss: 2.5587947201985184

Epoch: 6| Step: 6
Training loss: 2.97771954536438
Validation loss: 2.5552930011544177

Epoch: 6| Step: 7
Training loss: 2.3196845054626465
Validation loss: 2.574609887215399

Epoch: 6| Step: 8
Training loss: 3.419921875
Validation loss: 2.603806067538518

Epoch: 6| Step: 9
Training loss: 2.584425449371338
Validation loss: 2.5799549125855967

Epoch: 6| Step: 10
Training loss: 2.2738704681396484
Validation loss: 2.556245075759067

Epoch: 6| Step: 11
Training loss: 2.4032464027404785
Validation loss: 2.5404646524818997

Epoch: 6| Step: 12
Training loss: 3.385441541671753
Validation loss: 2.537189778461251

Epoch: 6| Step: 13
Training loss: 3.2436740398406982
Validation loss: 2.5434091975612025

Epoch: 29| Step: 0
Training loss: 3.2885866165161133
Validation loss: 2.5444799418090494

Epoch: 6| Step: 1
Training loss: 2.9073710441589355
Validation loss: 2.5508814498942387

Epoch: 6| Step: 2
Training loss: 2.8062334060668945
Validation loss: 2.5471418903719996

Epoch: 6| Step: 3
Training loss: 2.320680618286133
Validation loss: 2.5411343728342364

Epoch: 6| Step: 4
Training loss: 3.0593643188476562
Validation loss: 2.5385074359114452

Epoch: 6| Step: 5
Training loss: 2.943716526031494
Validation loss: 2.546608886411113

Epoch: 6| Step: 6
Training loss: 1.8679379224777222
Validation loss: 2.567235605691069

Epoch: 6| Step: 7
Training loss: 2.1874008178710938
Validation loss: 2.5640529535150014

Epoch: 6| Step: 8
Training loss: 2.879699945449829
Validation loss: 2.5582103242156324

Epoch: 6| Step: 9
Training loss: 3.1890320777893066
Validation loss: 2.545360521603656

Epoch: 6| Step: 10
Training loss: 2.394192695617676
Validation loss: 2.5494535379512335

Epoch: 6| Step: 11
Training loss: 3.468524932861328
Validation loss: 2.55032044072305

Epoch: 6| Step: 12
Training loss: 2.2759246826171875
Validation loss: 2.555198843761157

Epoch: 6| Step: 13
Training loss: 2.7238645553588867
Validation loss: 2.5467135880583074

Epoch: 30| Step: 0
Training loss: 3.1338863372802734
Validation loss: 2.5616457795584076

Epoch: 6| Step: 1
Training loss: 3.151049852371216
Validation loss: 2.5615158850146877

Epoch: 6| Step: 2
Training loss: 2.927682638168335
Validation loss: 2.569998069476056

Epoch: 6| Step: 3
Training loss: 2.8243207931518555
Validation loss: 2.5479756555249615

Epoch: 6| Step: 4
Training loss: 2.6159353256225586
Validation loss: 2.5337213777726695

Epoch: 6| Step: 5
Training loss: 2.6418497562408447
Validation loss: 2.5260852177937827

Epoch: 6| Step: 6
Training loss: 2.2182059288024902
Validation loss: 2.526372896727695

Epoch: 6| Step: 7
Training loss: 2.667202949523926
Validation loss: 2.5262943877968738

Epoch: 6| Step: 8
Training loss: 3.1270246505737305
Validation loss: 2.5259988359225694

Epoch: 6| Step: 9
Training loss: 2.4515249729156494
Validation loss: 2.524093166474373

Epoch: 6| Step: 10
Training loss: 2.995253086090088
Validation loss: 2.529985563729399

Epoch: 6| Step: 11
Training loss: 2.12935209274292
Validation loss: 2.5338869940850044

Epoch: 6| Step: 12
Training loss: 3.00077748298645
Validation loss: 2.5419401071404897

Epoch: 6| Step: 13
Training loss: 1.7937418222427368
Validation loss: 2.549476738898985

Epoch: 31| Step: 0
Training loss: 2.384425640106201
Validation loss: 2.5514905273273425

Epoch: 6| Step: 1
Training loss: 3.210366725921631
Validation loss: 2.539248046054635

Epoch: 6| Step: 2
Training loss: 3.061446189880371
Validation loss: 2.524499272787443

Epoch: 6| Step: 3
Training loss: 2.6530091762542725
Validation loss: 2.5255336940929456

Epoch: 6| Step: 4
Training loss: 2.357020139694214
Validation loss: 2.522402540329964

Epoch: 6| Step: 5
Training loss: 2.5285634994506836
Validation loss: 2.5166473670672347

Epoch: 6| Step: 6
Training loss: 2.7481698989868164
Validation loss: 2.515056097379295

Epoch: 6| Step: 7
Training loss: 2.4535553455352783
Validation loss: 2.5114670107441563

Epoch: 6| Step: 8
Training loss: 2.8908910751342773
Validation loss: 2.5163849758845505

Epoch: 6| Step: 9
Training loss: 3.612888813018799
Validation loss: 2.5141821317775275

Epoch: 6| Step: 10
Training loss: 2.610992193222046
Validation loss: 2.5196101255314325

Epoch: 6| Step: 11
Training loss: 2.4442152976989746
Validation loss: 2.523718435277221

Epoch: 6| Step: 12
Training loss: 2.594451904296875
Validation loss: 2.5231694559897146

Epoch: 6| Step: 13
Training loss: 2.237295389175415
Validation loss: 2.5265302273534958

Epoch: 32| Step: 0
Training loss: 2.5542731285095215
Validation loss: 2.5200830403194634

Epoch: 6| Step: 1
Training loss: 2.6406993865966797
Validation loss: 2.5152590736266105

Epoch: 6| Step: 2
Training loss: 2.7147536277770996
Validation loss: 2.5085753240892963

Epoch: 6| Step: 3
Training loss: 2.679687023162842
Validation loss: 2.5139400856469267

Epoch: 6| Step: 4
Training loss: 2.4792983531951904
Validation loss: 2.5150147150921565

Epoch: 6| Step: 5
Training loss: 2.9298057556152344
Validation loss: 2.51496361917065

Epoch: 6| Step: 6
Training loss: 2.5618252754211426
Validation loss: 2.513975239569141

Epoch: 6| Step: 7
Training loss: 2.8707265853881836
Validation loss: 2.5135741285098496

Epoch: 6| Step: 8
Training loss: 2.906641960144043
Validation loss: 2.521708029572682

Epoch: 6| Step: 9
Training loss: 2.772794723510742
Validation loss: 2.5313989065026723

Epoch: 6| Step: 10
Training loss: 2.223741054534912
Validation loss: 2.5163344952367965

Epoch: 6| Step: 11
Training loss: 3.0078394412994385
Validation loss: 2.5208252219743628

Epoch: 6| Step: 12
Training loss: 3.1077077388763428
Validation loss: 2.5226027439999323

Epoch: 6| Step: 13
Training loss: 2.4361677169799805
Validation loss: 2.521939234067035

Epoch: 33| Step: 0
Training loss: 2.6082875728607178
Validation loss: 2.529788327473466

Epoch: 6| Step: 1
Training loss: 2.986937999725342
Validation loss: 2.5296381724778043

Epoch: 6| Step: 2
Training loss: 2.461021900177002
Validation loss: 2.5411176655882146

Epoch: 6| Step: 3
Training loss: 3.12325382232666
Validation loss: 2.5264011634293424

Epoch: 6| Step: 4
Training loss: 2.383591651916504
Validation loss: 2.5194241436578895

Epoch: 6| Step: 5
Training loss: 2.264805316925049
Validation loss: 2.509590715490362

Epoch: 6| Step: 6
Training loss: 2.9016988277435303
Validation loss: 2.504514777532188

Epoch: 6| Step: 7
Training loss: 2.717099905014038
Validation loss: 2.5027667655739734

Epoch: 6| Step: 8
Training loss: 1.9567854404449463
Validation loss: 2.5009391205285185

Epoch: 6| Step: 9
Training loss: 2.8296561241149902
Validation loss: 2.49949582417806

Epoch: 6| Step: 10
Training loss: 2.853522300720215
Validation loss: 2.4970268023911344

Epoch: 6| Step: 11
Training loss: 2.88700008392334
Validation loss: 2.495444679772982

Epoch: 6| Step: 12
Training loss: 3.2163703441619873
Validation loss: 2.5016639386453936

Epoch: 6| Step: 13
Training loss: 2.5413923263549805
Validation loss: 2.497878405355638

Epoch: 34| Step: 0
Training loss: 2.9710631370544434
Validation loss: 2.4925720563498874

Epoch: 6| Step: 1
Training loss: 2.9009532928466797
Validation loss: 2.4948733904028453

Epoch: 6| Step: 2
Training loss: 2.600027084350586
Validation loss: 2.498667537525136

Epoch: 6| Step: 3
Training loss: 2.834489345550537
Validation loss: 2.4979835479490218

Epoch: 6| Step: 4
Training loss: 2.6620049476623535
Validation loss: 2.500153831256333

Epoch: 6| Step: 5
Training loss: 2.6892926692962646
Validation loss: 2.515529865859657

Epoch: 6| Step: 6
Training loss: 2.1423542499542236
Validation loss: 2.506921365696897

Epoch: 6| Step: 7
Training loss: 3.80368971824646
Validation loss: 2.507318591558805

Epoch: 6| Step: 8
Training loss: 3.1797244548797607
Validation loss: 2.4965535210024927

Epoch: 6| Step: 9
Training loss: 1.7530510425567627
Validation loss: 2.49613017676979

Epoch: 6| Step: 10
Training loss: 3.1235909461975098
Validation loss: 2.490088068028932

Epoch: 6| Step: 11
Training loss: 2.3385496139526367
Validation loss: 2.4855728226323284

Epoch: 6| Step: 12
Training loss: 2.040807008743286
Validation loss: 2.490034662267213

Epoch: 6| Step: 13
Training loss: 2.475632905960083
Validation loss: 2.489162909087314

Epoch: 35| Step: 0
Training loss: 3.1647751331329346
Validation loss: 2.495521257000585

Epoch: 6| Step: 1
Training loss: 2.5168938636779785
Validation loss: 2.5031090269806566

Epoch: 6| Step: 2
Training loss: 2.1643478870391846
Validation loss: 2.497478569707563

Epoch: 6| Step: 3
Training loss: 3.290316104888916
Validation loss: 2.4965680517176145

Epoch: 6| Step: 4
Training loss: 3.713531970977783
Validation loss: 2.49105481947622

Epoch: 6| Step: 5
Training loss: 2.158954620361328
Validation loss: 2.484489010226342

Epoch: 6| Step: 6
Training loss: 3.061427116394043
Validation loss: 2.484235217494349

Epoch: 6| Step: 7
Training loss: 2.2286629676818848
Validation loss: 2.4827376501534575

Epoch: 6| Step: 8
Training loss: 2.1776790618896484
Validation loss: 2.4882802168528237

Epoch: 6| Step: 9
Training loss: 2.6404755115509033
Validation loss: 2.503167772805819

Epoch: 6| Step: 10
Training loss: 3.0626773834228516
Validation loss: 2.532620914520756

Epoch: 6| Step: 11
Training loss: 2.5211689472198486
Validation loss: 2.558684895115514

Epoch: 6| Step: 12
Training loss: 2.4570116996765137
Validation loss: 2.5520057114221717

Epoch: 6| Step: 13
Training loss: 2.717236042022705
Validation loss: 2.5258527366063928

Epoch: 36| Step: 0
Training loss: 2.2288851737976074
Validation loss: 2.4950055640230895

Epoch: 6| Step: 1
Training loss: 2.763643264770508
Validation loss: 2.4826998428631852

Epoch: 6| Step: 2
Training loss: 2.191274404525757
Validation loss: 2.4796695145227576

Epoch: 6| Step: 3
Training loss: 2.2679715156555176
Validation loss: 2.4847756406312347

Epoch: 6| Step: 4
Training loss: 3.056954860687256
Validation loss: 2.492478632157849

Epoch: 6| Step: 5
Training loss: 3.163825750350952
Validation loss: 2.486683558392268

Epoch: 6| Step: 6
Training loss: 2.8698434829711914
Validation loss: 2.4761471286896737

Epoch: 6| Step: 7
Training loss: 2.61018967628479
Validation loss: 2.4784069650916645

Epoch: 6| Step: 8
Training loss: 3.2707998752593994
Validation loss: 2.4735700161226335

Epoch: 6| Step: 9
Training loss: 1.7407374382019043
Validation loss: 2.475995120181832

Epoch: 6| Step: 10
Training loss: 3.238452434539795
Validation loss: 2.481906185867966

Epoch: 6| Step: 11
Training loss: 2.653531074523926
Validation loss: 2.491718284545406

Epoch: 6| Step: 12
Training loss: 2.4664998054504395
Validation loss: 2.50026790044641

Epoch: 6| Step: 13
Training loss: 3.486140251159668
Validation loss: 2.537552438756471

Epoch: 37| Step: 0
Training loss: 2.9644787311553955
Validation loss: 2.5583096242720083

Epoch: 6| Step: 1
Training loss: 3.5753045082092285
Validation loss: 2.542958546710271

Epoch: 6| Step: 2
Training loss: 2.458831310272217
Validation loss: 2.520877194660966

Epoch: 6| Step: 3
Training loss: 2.133011817932129
Validation loss: 2.4854490731352117

Epoch: 6| Step: 4
Training loss: 3.084465742111206
Validation loss: 2.4720782246640933

Epoch: 6| Step: 5
Training loss: 2.6784310340881348
Validation loss: 2.4656175951803885

Epoch: 6| Step: 6
Training loss: 2.5074462890625
Validation loss: 2.4739598381903862

Epoch: 6| Step: 7
Training loss: 1.9253493547439575
Validation loss: 2.497035106023153

Epoch: 6| Step: 8
Training loss: 3.2616281509399414
Validation loss: 2.5934988349996586

Epoch: 6| Step: 9
Training loss: 2.650815486907959
Validation loss: 2.581828225043512

Epoch: 6| Step: 10
Training loss: 2.239990472793579
Validation loss: 2.5533187979011127

Epoch: 6| Step: 11
Training loss: 3.2870054244995117
Validation loss: 2.5753671789682038

Epoch: 6| Step: 12
Training loss: 2.34163236618042
Validation loss: 2.531419607900804

Epoch: 6| Step: 13
Training loss: 2.9087743759155273
Validation loss: 2.471029309816258

Epoch: 38| Step: 0
Training loss: 2.6425933837890625
Validation loss: 2.496002084465437

Epoch: 6| Step: 1
Training loss: 2.7836623191833496
Validation loss: 2.54957599793711

Epoch: 6| Step: 2
Training loss: 2.4444687366485596
Validation loss: 2.6283870050984044

Epoch: 6| Step: 3
Training loss: 3.008070230484009
Validation loss: 2.652103913727627

Epoch: 6| Step: 4
Training loss: 2.8989524841308594
Validation loss: 2.577169672135384

Epoch: 6| Step: 5
Training loss: 2.3841512203216553
Validation loss: 2.5183462301890054

Epoch: 6| Step: 6
Training loss: 2.2214863300323486
Validation loss: 2.4828959434263167

Epoch: 6| Step: 7
Training loss: 2.077660322189331
Validation loss: 2.4662332688608477

Epoch: 6| Step: 8
Training loss: 2.316164493560791
Validation loss: 2.4604757242305304

Epoch: 6| Step: 9
Training loss: 3.449577808380127
Validation loss: 2.468454036661374

Epoch: 6| Step: 10
Training loss: 2.747072696685791
Validation loss: 2.4884886587819746

Epoch: 6| Step: 11
Training loss: 3.6502158641815186
Validation loss: 2.5271282452408985

Epoch: 6| Step: 12
Training loss: 2.9371492862701416
Validation loss: 2.542476810434813

Epoch: 6| Step: 13
Training loss: 2.096689224243164
Validation loss: 2.561312988240232

Epoch: 39| Step: 0
Training loss: 3.272524356842041
Validation loss: 2.5791809943414505

Epoch: 6| Step: 1
Training loss: 2.311286449432373
Validation loss: 2.5585903390761344

Epoch: 6| Step: 2
Training loss: 2.4473209381103516
Validation loss: 2.5321519579938663

Epoch: 6| Step: 3
Training loss: 2.6065659523010254
Validation loss: 2.507799397232712

Epoch: 6| Step: 4
Training loss: 2.560645341873169
Validation loss: 2.483351920240669

Epoch: 6| Step: 5
Training loss: 2.399235248565674
Validation loss: 2.452592880495133

Epoch: 6| Step: 6
Training loss: 2.828270673751831
Validation loss: 2.4629015281636226

Epoch: 6| Step: 7
Training loss: 2.5331192016601562
Validation loss: 2.537635446876608

Epoch: 6| Step: 8
Training loss: 2.414008617401123
Validation loss: 2.5529796923360517

Epoch: 6| Step: 9
Training loss: 3.0048861503601074
Validation loss: 2.558160153768396

Epoch: 6| Step: 10
Training loss: 3.253110647201538
Validation loss: 2.5747248767524638

Epoch: 6| Step: 11
Training loss: 2.4734344482421875
Validation loss: 2.568637001898981

Epoch: 6| Step: 12
Training loss: 2.6084296703338623
Validation loss: 2.532458887305311

Epoch: 6| Step: 13
Training loss: 3.655938148498535
Validation loss: 2.4944079793909544

Epoch: 40| Step: 0
Training loss: 2.600339651107788
Validation loss: 2.481219544205614

Epoch: 6| Step: 1
Training loss: 3.0509581565856934
Validation loss: 2.4541665072082193

Epoch: 6| Step: 2
Training loss: 2.573850154876709
Validation loss: 2.444454085442328

Epoch: 6| Step: 3
Training loss: 2.7940731048583984
Validation loss: 2.447340647379557

Epoch: 6| Step: 4
Training loss: 2.176617383956909
Validation loss: 2.445596753910024

Epoch: 6| Step: 5
Training loss: 2.3430981636047363
Validation loss: 2.446333110973399

Epoch: 6| Step: 6
Training loss: 2.5771234035491943
Validation loss: 2.4467231176232778

Epoch: 6| Step: 7
Training loss: 2.4433434009552
Validation loss: 2.448165924318375

Epoch: 6| Step: 8
Training loss: 2.6681740283966064
Validation loss: 2.449950579674013

Epoch: 6| Step: 9
Training loss: 2.951446533203125
Validation loss: 2.4493862992973736

Epoch: 6| Step: 10
Training loss: 2.8440797328948975
Validation loss: 2.452375445314633

Epoch: 6| Step: 11
Training loss: 3.130532741546631
Validation loss: 2.4514129559199014

Epoch: 6| Step: 12
Training loss: 2.456569194793701
Validation loss: 2.448908987865653

Epoch: 6| Step: 13
Training loss: 2.997004985809326
Validation loss: 2.4445819572735856

Epoch: 41| Step: 0
Training loss: 2.80991268157959
Validation loss: 2.440570782589656

Epoch: 6| Step: 1
Training loss: 2.566713809967041
Validation loss: 2.446210430514428

Epoch: 6| Step: 2
Training loss: 2.5298898220062256
Validation loss: 2.4540665252234346

Epoch: 6| Step: 3
Training loss: 2.2877659797668457
Validation loss: 2.460851325783678

Epoch: 6| Step: 4
Training loss: 2.219665765762329
Validation loss: 2.4749582249631166

Epoch: 6| Step: 5
Training loss: 2.7862820625305176
Validation loss: 2.453958280624882

Epoch: 6| Step: 6
Training loss: 2.7708640098571777
Validation loss: 2.4518830237850064

Epoch: 6| Step: 7
Training loss: 2.9450736045837402
Validation loss: 2.450600160065518

Epoch: 6| Step: 8
Training loss: 2.5726497173309326
Validation loss: 2.443545804228834

Epoch: 6| Step: 9
Training loss: 2.5106263160705566
Validation loss: 2.4474410959469375

Epoch: 6| Step: 10
Training loss: 2.752840995788574
Validation loss: 2.448415402443178

Epoch: 6| Step: 11
Training loss: 2.9876551628112793
Validation loss: 2.4487719689646075

Epoch: 6| Step: 12
Training loss: 3.3496851921081543
Validation loss: 2.450255851591787

Epoch: 6| Step: 13
Training loss: 1.9045747518539429
Validation loss: 2.451162771512103

Epoch: 42| Step: 0
Training loss: 2.594900369644165
Validation loss: 2.4447239855284333

Epoch: 6| Step: 1
Training loss: 2.449944019317627
Validation loss: 2.4366823806557605

Epoch: 6| Step: 2
Training loss: 2.0938351154327393
Validation loss: 2.434294899304708

Epoch: 6| Step: 3
Training loss: 2.9712324142456055
Validation loss: 2.438094308299403

Epoch: 6| Step: 4
Training loss: 2.465111255645752
Validation loss: 2.435442160534602

Epoch: 6| Step: 5
Training loss: 2.101851463317871
Validation loss: 2.432083909229566

Epoch: 6| Step: 6
Training loss: 3.341972589492798
Validation loss: 2.432496911735945

Epoch: 6| Step: 7
Training loss: 2.2903051376342773
Validation loss: 2.432685411104592

Epoch: 6| Step: 8
Training loss: 2.767422914505005
Validation loss: 2.438061391153643

Epoch: 6| Step: 9
Training loss: 3.285097599029541
Validation loss: 2.4331759663038355

Epoch: 6| Step: 10
Training loss: 2.8068764209747314
Validation loss: 2.4404018002171672

Epoch: 6| Step: 11
Training loss: 3.277722120285034
Validation loss: 2.4512659221567135

Epoch: 6| Step: 12
Training loss: 2.519334554672241
Validation loss: 2.4532702968966578

Epoch: 6| Step: 13
Training loss: 2.183295249938965
Validation loss: 2.4475059150367655

Epoch: 43| Step: 0
Training loss: 2.4039154052734375
Validation loss: 2.4442505182758456

Epoch: 6| Step: 1
Training loss: 3.1162633895874023
Validation loss: 2.4414275794900875

Epoch: 6| Step: 2
Training loss: 2.5710983276367188
Validation loss: 2.4472329437091784

Epoch: 6| Step: 3
Training loss: 3.2402515411376953
Validation loss: 2.457471098951114

Epoch: 6| Step: 4
Training loss: 2.5413830280303955
Validation loss: 2.4528565919527443

Epoch: 6| Step: 5
Training loss: 2.2383689880371094
Validation loss: 2.464317646077884

Epoch: 6| Step: 6
Training loss: 2.529623508453369
Validation loss: 2.458540649824245

Epoch: 6| Step: 7
Training loss: 2.7038991451263428
Validation loss: 2.463106709141885

Epoch: 6| Step: 8
Training loss: 2.3589019775390625
Validation loss: 2.472536171636274

Epoch: 6| Step: 9
Training loss: 2.5769004821777344
Validation loss: 2.463024498313986

Epoch: 6| Step: 10
Training loss: 2.9696450233459473
Validation loss: 2.491891363615631

Epoch: 6| Step: 11
Training loss: 2.846909761428833
Validation loss: 2.46045877856593

Epoch: 6| Step: 12
Training loss: 2.9569010734558105
Validation loss: 2.439651907131236

Epoch: 6| Step: 13
Training loss: 1.8977923393249512
Validation loss: 2.4261769992049023

Epoch: 44| Step: 0
Training loss: 2.257981777191162
Validation loss: 2.427272688957953

Epoch: 6| Step: 1
Training loss: 2.759336471557617
Validation loss: 2.429191179172967

Epoch: 6| Step: 2
Training loss: 3.491863489151001
Validation loss: 2.4242502002305883

Epoch: 6| Step: 3
Training loss: 2.8756346702575684
Validation loss: 2.42242935908738

Epoch: 6| Step: 4
Training loss: 2.6240367889404297
Validation loss: 2.4171914592865975

Epoch: 6| Step: 5
Training loss: 2.6711020469665527
Validation loss: 2.4216548447967856

Epoch: 6| Step: 6
Training loss: 2.102903366088867
Validation loss: 2.4177976962058776

Epoch: 6| Step: 7
Training loss: 2.914144515991211
Validation loss: 2.4201634853116927

Epoch: 6| Step: 8
Training loss: 3.2170724868774414
Validation loss: 2.4206310138907483

Epoch: 6| Step: 9
Training loss: 2.4637298583984375
Validation loss: 2.42171452635078

Epoch: 6| Step: 10
Training loss: 2.3270251750946045
Validation loss: 2.436264063722344

Epoch: 6| Step: 11
Training loss: 2.7758965492248535
Validation loss: 2.440887661390407

Epoch: 6| Step: 12
Training loss: 2.5887198448181152
Validation loss: 2.45558104976531

Epoch: 6| Step: 13
Training loss: 1.8116880655288696
Validation loss: 2.4878377042790896

Epoch: 45| Step: 0
Training loss: 2.5500988960266113
Validation loss: 2.4552137749169463

Epoch: 6| Step: 1
Training loss: 2.3634438514709473
Validation loss: 2.432794519650039

Epoch: 6| Step: 2
Training loss: 2.536231756210327
Validation loss: 2.4229720613007903

Epoch: 6| Step: 3
Training loss: 2.6072206497192383
Validation loss: 2.41711837245572

Epoch: 6| Step: 4
Training loss: 2.754551649093628
Validation loss: 2.4173272425128567

Epoch: 6| Step: 5
Training loss: 2.6265032291412354
Validation loss: 2.423064870219077

Epoch: 6| Step: 6
Training loss: 2.7356157302856445
Validation loss: 2.433761232642717

Epoch: 6| Step: 7
Training loss: 2.155529022216797
Validation loss: 2.4363773586929485

Epoch: 6| Step: 8
Training loss: 2.579270839691162
Validation loss: 2.4456887501542286

Epoch: 6| Step: 9
Training loss: 3.1503849029541016
Validation loss: 2.447846717731927

Epoch: 6| Step: 10
Training loss: 2.779761552810669
Validation loss: 2.4521949521956907

Epoch: 6| Step: 11
Training loss: 2.9275450706481934
Validation loss: 2.436495311798588

Epoch: 6| Step: 12
Training loss: 2.632030487060547
Validation loss: 2.4271540910966936

Epoch: 6| Step: 13
Training loss: 2.740154981613159
Validation loss: 2.424842826781734

Epoch: 46| Step: 0
Training loss: 2.9963064193725586
Validation loss: 2.4158336321512857

Epoch: 6| Step: 1
Training loss: 2.921469211578369
Validation loss: 2.4134328262780302

Epoch: 6| Step: 2
Training loss: 2.627351760864258
Validation loss: 2.4081369317987913

Epoch: 6| Step: 3
Training loss: 2.160914421081543
Validation loss: 2.4073417443101124

Epoch: 6| Step: 4
Training loss: 2.537471294403076
Validation loss: 2.407932068711968

Epoch: 6| Step: 5
Training loss: 2.559885263442993
Validation loss: 2.411749050181399

Epoch: 6| Step: 6
Training loss: 3.034010410308838
Validation loss: 2.4069278547840733

Epoch: 6| Step: 7
Training loss: 2.3632049560546875
Validation loss: 2.4125862659946566

Epoch: 6| Step: 8
Training loss: 3.2911696434020996
Validation loss: 2.4106405127433037

Epoch: 6| Step: 9
Training loss: 2.5316529273986816
Validation loss: 2.4097494643221617

Epoch: 6| Step: 10
Training loss: 2.171565055847168
Validation loss: 2.410761574263214

Epoch: 6| Step: 11
Training loss: 2.9294228553771973
Validation loss: 2.4122871968054

Epoch: 6| Step: 12
Training loss: 2.155458688735962
Validation loss: 2.420467327999812

Epoch: 6| Step: 13
Training loss: 2.9924139976501465
Validation loss: 2.4092054956702778

Epoch: 47| Step: 0
Training loss: 2.193636178970337
Validation loss: 2.4082621810256795

Epoch: 6| Step: 1
Training loss: 2.150627613067627
Validation loss: 2.4099646947717153

Epoch: 6| Step: 2
Training loss: 2.777087688446045
Validation loss: 2.415940200128863

Epoch: 6| Step: 3
Training loss: 2.6447885036468506
Validation loss: 2.432917489800402

Epoch: 6| Step: 4
Training loss: 2.2641725540161133
Validation loss: 2.445890680436165

Epoch: 6| Step: 5
Training loss: 2.548469066619873
Validation loss: 2.451951349935224

Epoch: 6| Step: 6
Training loss: 2.0674068927764893
Validation loss: 2.471196662995123

Epoch: 6| Step: 7
Training loss: 2.6987826824188232
Validation loss: 2.479779238341957

Epoch: 6| Step: 8
Training loss: 2.798696517944336
Validation loss: 2.490562197982624

Epoch: 6| Step: 9
Training loss: 3.9705047607421875
Validation loss: 2.479531905984366

Epoch: 6| Step: 10
Training loss: 3.197700023651123
Validation loss: 2.4451744530790593

Epoch: 6| Step: 11
Training loss: 1.5575031042099
Validation loss: 2.4131065363525064

Epoch: 6| Step: 12
Training loss: 3.4299702644348145
Validation loss: 2.3939713816488943

Epoch: 6| Step: 13
Training loss: 2.800743818283081
Validation loss: 2.3918747709643458

Epoch: 48| Step: 0
Training loss: 2.5923080444335938
Validation loss: 2.389720480929139

Epoch: 6| Step: 1
Training loss: 2.1742844581604004
Validation loss: 2.3948670305231565

Epoch: 6| Step: 2
Training loss: 2.7549500465393066
Validation loss: 2.3990658944652927

Epoch: 6| Step: 3
Training loss: 2.0575804710388184
Validation loss: 2.3970086215644755

Epoch: 6| Step: 4
Training loss: 3.5185351371765137
Validation loss: 2.3863855638811664

Epoch: 6| Step: 5
Training loss: 1.9082615375518799
Validation loss: 2.3856406442580687

Epoch: 6| Step: 6
Training loss: 3.029910087585449
Validation loss: 2.392971482328189

Epoch: 6| Step: 7
Training loss: 2.8223679065704346
Validation loss: 2.389387140991867

Epoch: 6| Step: 8
Training loss: 2.692152976989746
Validation loss: 2.389812869410361

Epoch: 6| Step: 9
Training loss: 2.0361886024475098
Validation loss: 2.4055886704434633

Epoch: 6| Step: 10
Training loss: 2.559760332107544
Validation loss: 2.4355494053133073

Epoch: 6| Step: 11
Training loss: 3.7036895751953125
Validation loss: 2.4502253711864515

Epoch: 6| Step: 12
Training loss: 2.3917901515960693
Validation loss: 2.4187193916689966

Epoch: 6| Step: 13
Training loss: 2.9612836837768555
Validation loss: 2.39119537415043

Epoch: 49| Step: 0
Training loss: 2.510694742202759
Validation loss: 2.389504051977588

Epoch: 6| Step: 1
Training loss: 2.109002113342285
Validation loss: 2.386268231176561

Epoch: 6| Step: 2
Training loss: 3.4658915996551514
Validation loss: 2.384167689149098

Epoch: 6| Step: 3
Training loss: 2.5275325775146484
Validation loss: 2.3899081163508917

Epoch: 6| Step: 4
Training loss: 2.5214076042175293
Validation loss: 2.3887619908137987

Epoch: 6| Step: 5
Training loss: 2.643824815750122
Validation loss: 2.3903638470557427

Epoch: 6| Step: 6
Training loss: 1.6122100353240967
Validation loss: 2.404088694562194

Epoch: 6| Step: 7
Training loss: 3.6045122146606445
Validation loss: 2.401690370293074

Epoch: 6| Step: 8
Training loss: 2.2981183528900146
Validation loss: 2.4076237011981267

Epoch: 6| Step: 9
Training loss: 2.343487501144409
Validation loss: 2.393601761069349

Epoch: 6| Step: 10
Training loss: 2.8642210960388184
Validation loss: 2.3930230935414634

Epoch: 6| Step: 11
Training loss: 3.08522367477417
Validation loss: 2.3830140393267394

Epoch: 6| Step: 12
Training loss: 2.5479660034179688
Validation loss: 2.399115054838119

Epoch: 6| Step: 13
Training loss: 2.604351043701172
Validation loss: 2.3935080318040747

Epoch: 50| Step: 0
Training loss: 2.5361337661743164
Validation loss: 2.3844356331773984

Epoch: 6| Step: 1
Training loss: 2.2165751457214355
Validation loss: 2.383284307295276

Epoch: 6| Step: 2
Training loss: 2.536719560623169
Validation loss: 2.3822144154579408

Epoch: 6| Step: 3
Training loss: 3.1984057426452637
Validation loss: 2.38159030483615

Epoch: 6| Step: 4
Training loss: 2.645081043243408
Validation loss: 2.3826587353983233

Epoch: 6| Step: 5
Training loss: 2.467654228210449
Validation loss: 2.3798637108136247

Epoch: 6| Step: 6
Training loss: 3.153329849243164
Validation loss: 2.3835207108528382

Epoch: 6| Step: 7
Training loss: 2.4349799156188965
Validation loss: 2.374370749278735

Epoch: 6| Step: 8
Training loss: 2.912170886993408
Validation loss: 2.380664356293217

Epoch: 6| Step: 9
Training loss: 2.456066608428955
Validation loss: 2.375297684823313

Epoch: 6| Step: 10
Training loss: 2.948546886444092
Validation loss: 2.3694460494543916

Epoch: 6| Step: 11
Training loss: 2.9385805130004883
Validation loss: 2.3781903366888724

Epoch: 6| Step: 12
Training loss: 1.8167837858200073
Validation loss: 2.36742877703841

Epoch: 6| Step: 13
Training loss: 1.9222692251205444
Validation loss: 2.36845661235112

Epoch: 51| Step: 0
Training loss: 3.2307605743408203
Validation loss: 2.3756253283510924

Epoch: 6| Step: 1
Training loss: 2.324378490447998
Validation loss: 2.3784298307152203

Epoch: 6| Step: 2
Training loss: 2.5172476768493652
Validation loss: 2.372077108711325

Epoch: 6| Step: 3
Training loss: 2.8851518630981445
Validation loss: 2.3695327081987934

Epoch: 6| Step: 4
Training loss: 2.8284037113189697
Validation loss: 2.3674148257060716

Epoch: 6| Step: 5
Training loss: 2.1344594955444336
Validation loss: 2.3795157401792464

Epoch: 6| Step: 6
Training loss: 2.150113821029663
Validation loss: 2.378033181672455

Epoch: 6| Step: 7
Training loss: 3.399749755859375
Validation loss: 2.3805639641259306

Epoch: 6| Step: 8
Training loss: 2.421363592147827
Validation loss: 2.3921921689023256

Epoch: 6| Step: 9
Training loss: 2.682036876678467
Validation loss: 2.3869601295840357

Epoch: 6| Step: 10
Training loss: 2.964080810546875
Validation loss: 2.3970797241375013

Epoch: 6| Step: 11
Training loss: 2.1912026405334473
Validation loss: 2.435139125393283

Epoch: 6| Step: 12
Training loss: 2.2280514240264893
Validation loss: 2.4211938932377803

Epoch: 6| Step: 13
Training loss: 2.5607378482818604
Validation loss: 2.383139717963434

Epoch: 52| Step: 0
Training loss: 2.4339959621429443
Validation loss: 2.3530566769261516

Epoch: 6| Step: 1
Training loss: 2.9031028747558594
Validation loss: 2.3442061972874466

Epoch: 6| Step: 2
Training loss: 2.6659069061279297
Validation loss: 2.3608808235455583

Epoch: 6| Step: 3
Training loss: 2.474456787109375
Validation loss: 2.3697353383546234

Epoch: 6| Step: 4
Training loss: 2.7835826873779297
Validation loss: 2.3751675082791235

Epoch: 6| Step: 5
Training loss: 2.1083388328552246
Validation loss: 2.369427457932503

Epoch: 6| Step: 6
Training loss: 2.064932346343994
Validation loss: 2.3591851624109412

Epoch: 6| Step: 7
Training loss: 2.162891387939453
Validation loss: 2.3460816696125972

Epoch: 6| Step: 8
Training loss: 3.112460136413574
Validation loss: 2.3491467686109644

Epoch: 6| Step: 9
Training loss: 3.100557804107666
Validation loss: 2.3414057967483357

Epoch: 6| Step: 10
Training loss: 2.728764533996582
Validation loss: 2.3401163316542104

Epoch: 6| Step: 11
Training loss: 2.7313194274902344
Validation loss: 2.3414707004383044

Epoch: 6| Step: 12
Training loss: 2.3080244064331055
Validation loss: 2.341052016904277

Epoch: 6| Step: 13
Training loss: 3.296717643737793
Validation loss: 2.34460344365848

Epoch: 53| Step: 0
Training loss: 2.948925256729126
Validation loss: 2.352089879333332

Epoch: 6| Step: 1
Training loss: 2.420872688293457
Validation loss: 2.346046273426343

Epoch: 6| Step: 2
Training loss: 3.3134636878967285
Validation loss: 2.3480599823818413

Epoch: 6| Step: 3
Training loss: 2.143050193786621
Validation loss: 2.3530183710077757

Epoch: 6| Step: 4
Training loss: 2.077479839324951
Validation loss: 2.3508678431152017

Epoch: 6| Step: 5
Training loss: 3.1689305305480957
Validation loss: 2.3599568925878054

Epoch: 6| Step: 6
Training loss: 2.2894082069396973
Validation loss: 2.36153640285615

Epoch: 6| Step: 7
Training loss: 2.0587100982666016
Validation loss: 2.3602563617050007

Epoch: 6| Step: 8
Training loss: 2.6899333000183105
Validation loss: 2.372944977975661

Epoch: 6| Step: 9
Training loss: 3.454603672027588
Validation loss: 2.3739735669987176

Epoch: 6| Step: 10
Training loss: 2.8266775608062744
Validation loss: 2.362200293489682

Epoch: 6| Step: 11
Training loss: 2.5175862312316895
Validation loss: 2.3614388614572506

Epoch: 6| Step: 12
Training loss: 1.8796452283859253
Validation loss: 2.348857928347844

Epoch: 6| Step: 13
Training loss: 2.5347790718078613
Validation loss: 2.357748405907744

Epoch: 54| Step: 0
Training loss: 2.4535789489746094
Validation loss: 2.3487362323268766

Epoch: 6| Step: 1
Training loss: 2.9827322959899902
Validation loss: 2.3416427553340955

Epoch: 6| Step: 2
Training loss: 2.582334518432617
Validation loss: 2.334714181961552

Epoch: 6| Step: 3
Training loss: 2.856334924697876
Validation loss: 2.3322366899059666

Epoch: 6| Step: 4
Training loss: 2.3923346996307373
Validation loss: 2.337240829262682

Epoch: 6| Step: 5
Training loss: 2.0075769424438477
Validation loss: 2.3328591046794767

Epoch: 6| Step: 6
Training loss: 2.5014255046844482
Validation loss: 2.3293363650639853

Epoch: 6| Step: 7
Training loss: 2.878300666809082
Validation loss: 2.3352718712181173

Epoch: 6| Step: 8
Training loss: 2.820376396179199
Validation loss: 2.34515671319859

Epoch: 6| Step: 9
Training loss: 2.844545841217041
Validation loss: 2.34196787880313

Epoch: 6| Step: 10
Training loss: 2.459752082824707
Validation loss: 2.364731906562723

Epoch: 6| Step: 11
Training loss: 2.521487236022949
Validation loss: 2.3933961596540225

Epoch: 6| Step: 12
Training loss: 2.312117576599121
Validation loss: 2.4029047745530323

Epoch: 6| Step: 13
Training loss: 2.8251798152923584
Validation loss: 2.409692261808662

Epoch: 55| Step: 0
Training loss: 2.430431842803955
Validation loss: 2.4279418888912407

Epoch: 6| Step: 1
Training loss: 3.102278709411621
Validation loss: 2.4164785262077086

Epoch: 6| Step: 2
Training loss: 2.343794345855713
Validation loss: 2.3958893796449066

Epoch: 6| Step: 3
Training loss: 3.133535623550415
Validation loss: 2.3750048016989105

Epoch: 6| Step: 4
Training loss: 2.8401856422424316
Validation loss: 2.364479345660056

Epoch: 6| Step: 5
Training loss: 2.7408783435821533
Validation loss: 2.3497567176818848

Epoch: 6| Step: 6
Training loss: 3.1762092113494873
Validation loss: 2.3388502982354935

Epoch: 6| Step: 7
Training loss: 2.129608631134033
Validation loss: 2.3308205168734313

Epoch: 6| Step: 8
Training loss: 2.0245249271392822
Validation loss: 2.3254140038644113

Epoch: 6| Step: 9
Training loss: 3.6436173915863037
Validation loss: 2.3220239352154475

Epoch: 6| Step: 10
Training loss: 1.7913639545440674
Validation loss: 2.3228274160815823

Epoch: 6| Step: 11
Training loss: 1.6954147815704346
Validation loss: 2.3315057087970037

Epoch: 6| Step: 12
Training loss: 2.529783010482788
Validation loss: 2.3253405478692826

Epoch: 6| Step: 13
Training loss: 3.2372426986694336
Validation loss: 2.3216011908746537

Epoch: 56| Step: 0
Training loss: 2.2830252647399902
Validation loss: 2.3199847449538527

Epoch: 6| Step: 1
Training loss: 2.6756954193115234
Validation loss: 2.3197120466539936

Epoch: 6| Step: 2
Training loss: 3.0829782485961914
Validation loss: 2.324508615719375

Epoch: 6| Step: 3
Training loss: 2.410578727722168
Validation loss: 2.3209350929465344

Epoch: 6| Step: 4
Training loss: 2.599971294403076
Validation loss: 2.3332966886540896

Epoch: 6| Step: 5
Training loss: 2.19398832321167
Validation loss: 2.3362416605795584

Epoch: 6| Step: 6
Training loss: 2.5020625591278076
Validation loss: 2.3236408989916564

Epoch: 6| Step: 7
Training loss: 2.867999315261841
Validation loss: 2.334402202278055

Epoch: 6| Step: 8
Training loss: 2.4999637603759766
Validation loss: 2.3474740751328005

Epoch: 6| Step: 9
Training loss: 2.8072469234466553
Validation loss: 2.353112215636879

Epoch: 6| Step: 10
Training loss: 1.658760666847229
Validation loss: 2.4215636817357873

Epoch: 6| Step: 11
Training loss: 2.8667449951171875
Validation loss: 2.438090939675608

Epoch: 6| Step: 12
Training loss: 3.251782178878784
Validation loss: 2.4513201969926075

Epoch: 6| Step: 13
Training loss: 2.868574619293213
Validation loss: 2.4595443920422624

Epoch: 57| Step: 0
Training loss: 2.7490739822387695
Validation loss: 2.4352363642825874

Epoch: 6| Step: 1
Training loss: 2.6971383094787598
Validation loss: 2.406241645095169

Epoch: 6| Step: 2
Training loss: 3.786257743835449
Validation loss: 2.3669497069492134

Epoch: 6| Step: 3
Training loss: 2.262410879135132
Validation loss: 2.3292235161668513

Epoch: 6| Step: 4
Training loss: 2.151139259338379
Validation loss: 2.3393094462733113

Epoch: 6| Step: 5
Training loss: 1.9448411464691162
Validation loss: 2.350685525965947

Epoch: 6| Step: 6
Training loss: 3.0199761390686035
Validation loss: 2.385097490843906

Epoch: 6| Step: 7
Training loss: 2.943830966949463
Validation loss: 2.430590627013996

Epoch: 6| Step: 8
Training loss: 2.4868547916412354
Validation loss: 2.4962723101339033

Epoch: 6| Step: 9
Training loss: 2.2721335887908936
Validation loss: 2.4436626639417423

Epoch: 6| Step: 10
Training loss: 2.4609246253967285
Validation loss: 2.385493140066824

Epoch: 6| Step: 11
Training loss: 2.3906612396240234
Validation loss: 2.359139052770471

Epoch: 6| Step: 12
Training loss: 2.60532283782959
Validation loss: 2.3681292738965762

Epoch: 6| Step: 13
Training loss: 3.0703299045562744
Validation loss: 2.3880975477157103

Epoch: 58| Step: 0
Training loss: 2.526463031768799
Validation loss: 2.375918044838854

Epoch: 6| Step: 1
Training loss: 3.0704870223999023
Validation loss: 2.3625613489458637

Epoch: 6| Step: 2
Training loss: 1.7954808473587036
Validation loss: 2.3380975825812227

Epoch: 6| Step: 3
Training loss: 2.3615567684173584
Validation loss: 2.3465834894487934

Epoch: 6| Step: 4
Training loss: 2.578681468963623
Validation loss: 2.3555460309469574

Epoch: 6| Step: 5
Training loss: 2.0302133560180664
Validation loss: 2.3752649368778354

Epoch: 6| Step: 6
Training loss: 3.290710926055908
Validation loss: 2.421341344874392

Epoch: 6| Step: 7
Training loss: 2.5029850006103516
Validation loss: 2.4864088514799714

Epoch: 6| Step: 8
Training loss: 3.3329625129699707
Validation loss: 2.5136851264584448

Epoch: 6| Step: 9
Training loss: 2.839343547821045
Validation loss: 2.4587570864667176

Epoch: 6| Step: 10
Training loss: 2.828617811203003
Validation loss: 2.4277606343710296

Epoch: 6| Step: 11
Training loss: 2.569885492324829
Validation loss: 2.389555485017838

Epoch: 6| Step: 12
Training loss: 2.3165886402130127
Validation loss: 2.3447358274972565

Epoch: 6| Step: 13
Training loss: 2.719407081604004
Validation loss: 2.315970681046927

Epoch: 59| Step: 0
Training loss: 2.320675849914551
Validation loss: 2.316170971880677

Epoch: 6| Step: 1
Training loss: 2.386739492416382
Validation loss: 2.321358259006213

Epoch: 6| Step: 2
Training loss: 3.2112367153167725
Validation loss: 2.3132471243540444

Epoch: 6| Step: 3
Training loss: 2.7831130027770996
Validation loss: 2.312584812923144

Epoch: 6| Step: 4
Training loss: 1.8363170623779297
Validation loss: 2.3141381330387567

Epoch: 6| Step: 5
Training loss: 2.7573800086975098
Validation loss: 2.3217309546727005

Epoch: 6| Step: 6
Training loss: 2.2750661373138428
Validation loss: 2.340740624294486

Epoch: 6| Step: 7
Training loss: 2.2800841331481934
Validation loss: 2.3765997450838805

Epoch: 6| Step: 8
Training loss: 2.688859701156616
Validation loss: 2.411962982146971

Epoch: 6| Step: 9
Training loss: 3.195012092590332
Validation loss: 2.4646117507770495

Epoch: 6| Step: 10
Training loss: 2.707630157470703
Validation loss: 2.4612147500438075

Epoch: 6| Step: 11
Training loss: 2.5885324478149414
Validation loss: 2.4541651536059637

Epoch: 6| Step: 12
Training loss: 3.2253432273864746
Validation loss: 2.4169658640379548

Epoch: 6| Step: 13
Training loss: 2.387361526489258
Validation loss: 2.362438081413187

Epoch: 60| Step: 0
Training loss: 2.9764108657836914
Validation loss: 2.320183874458395

Epoch: 6| Step: 1
Training loss: 2.304542064666748
Validation loss: 2.309683020396899

Epoch: 6| Step: 2
Training loss: 3.0670323371887207
Validation loss: 2.307660759136241

Epoch: 6| Step: 3
Training loss: 2.3925178050994873
Validation loss: 2.2994703195428334

Epoch: 6| Step: 4
Training loss: 2.189426898956299
Validation loss: 2.30893543458754

Epoch: 6| Step: 5
Training loss: 2.3539419174194336
Validation loss: 2.3065125057774205

Epoch: 6| Step: 6
Training loss: 2.1331937313079834
Validation loss: 2.314681278761997

Epoch: 6| Step: 7
Training loss: 2.972538948059082
Validation loss: 2.3210049547174925

Epoch: 6| Step: 8
Training loss: 2.292179584503174
Validation loss: 2.3234163971357447

Epoch: 6| Step: 9
Training loss: 2.8186306953430176
Validation loss: 2.321050351665866

Epoch: 6| Step: 10
Training loss: 2.7320761680603027
Validation loss: 2.317036697941442

Epoch: 6| Step: 11
Training loss: 2.7917871475219727
Validation loss: 2.316531435135872

Epoch: 6| Step: 12
Training loss: 2.564223289489746
Validation loss: 2.311866234707576

Epoch: 6| Step: 13
Training loss: 2.4173879623413086
Validation loss: 2.3134704815444125

Epoch: 61| Step: 0
Training loss: 2.9468119144439697
Validation loss: 2.3190917250930623

Epoch: 6| Step: 1
Training loss: 2.1935362815856934
Validation loss: 2.3192448949301117

Epoch: 6| Step: 2
Training loss: 2.26312255859375
Validation loss: 2.325151735736478

Epoch: 6| Step: 3
Training loss: 2.757753372192383
Validation loss: 2.3325742137047554

Epoch: 6| Step: 4
Training loss: 2.8264384269714355
Validation loss: 2.345559207342004

Epoch: 6| Step: 5
Training loss: 2.175692558288574
Validation loss: 2.360438500681231

Epoch: 6| Step: 6
Training loss: 2.702895164489746
Validation loss: 2.3787348167870634

Epoch: 6| Step: 7
Training loss: 2.756065607070923
Validation loss: 2.3773920664223294

Epoch: 6| Step: 8
Training loss: 3.39805269241333
Validation loss: 2.34801511995254

Epoch: 6| Step: 9
Training loss: 2.4783473014831543
Validation loss: 2.31842367879806

Epoch: 6| Step: 10
Training loss: 2.2928662300109863
Validation loss: 2.2918077720108854

Epoch: 6| Step: 11
Training loss: 2.666675090789795
Validation loss: 2.2862706581751504

Epoch: 6| Step: 12
Training loss: 2.096444606781006
Validation loss: 2.2852022673494075

Epoch: 6| Step: 13
Training loss: 2.466963529586792
Validation loss: 2.2941766067217757

Epoch: 62| Step: 0
Training loss: 2.332245111465454
Validation loss: 2.301441410536407

Epoch: 6| Step: 1
Training loss: 2.6217334270477295
Validation loss: 2.3341416210256596

Epoch: 6| Step: 2
Training loss: 2.8111412525177
Validation loss: 2.378125482989896

Epoch: 6| Step: 3
Training loss: 3.01922607421875
Validation loss: 2.3980703584609495

Epoch: 6| Step: 4
Training loss: 2.7960941791534424
Validation loss: 2.3776983984055056

Epoch: 6| Step: 5
Training loss: 2.5197744369506836
Validation loss: 2.3411503197044454

Epoch: 6| Step: 6
Training loss: 3.206576347351074
Validation loss: 2.304244887444281

Epoch: 6| Step: 7
Training loss: 2.469078302383423
Validation loss: 2.350536069562358

Epoch: 6| Step: 8
Training loss: 2.3777952194213867
Validation loss: 2.409183409906203

Epoch: 6| Step: 9
Training loss: 2.3005423545837402
Validation loss: 2.515229284122426

Epoch: 6| Step: 10
Training loss: 2.166198492050171
Validation loss: 2.5826635617081837

Epoch: 6| Step: 11
Training loss: 2.978837013244629
Validation loss: 2.5475902301008984

Epoch: 6| Step: 12
Training loss: 2.577949285507202
Validation loss: 2.4688836220772035

Epoch: 6| Step: 13
Training loss: 3.288050651550293
Validation loss: 2.399552799040271

Epoch: 63| Step: 0
Training loss: 2.801603078842163
Validation loss: 2.319158149021928

Epoch: 6| Step: 1
Training loss: 2.8412270545959473
Validation loss: 2.2876012415014286

Epoch: 6| Step: 2
Training loss: 2.8875644207000732
Validation loss: 2.2895135776970976

Epoch: 6| Step: 3
Training loss: 2.261974334716797
Validation loss: 2.3080603589293776

Epoch: 6| Step: 4
Training loss: 2.696436882019043
Validation loss: 2.361645772892942

Epoch: 6| Step: 5
Training loss: 3.046370029449463
Validation loss: 2.351662366620956

Epoch: 6| Step: 6
Training loss: 2.3296866416931152
Validation loss: 2.341734934878606

Epoch: 6| Step: 7
Training loss: 3.3094820976257324
Validation loss: 2.317923322800667

Epoch: 6| Step: 8
Training loss: 2.3847060203552246
Validation loss: 2.3090600723861368

Epoch: 6| Step: 9
Training loss: 2.374089241027832
Validation loss: 2.293703297133087

Epoch: 6| Step: 10
Training loss: 2.4184865951538086
Validation loss: 2.3100391434084986

Epoch: 6| Step: 11
Training loss: 2.714621067047119
Validation loss: 2.323234583741875

Epoch: 6| Step: 12
Training loss: 1.5587224960327148
Validation loss: 2.347529060097151

Epoch: 6| Step: 13
Training loss: 3.4090940952301025
Validation loss: 2.3586532044154342

Epoch: 64| Step: 0
Training loss: 3.2552218437194824
Validation loss: 2.358853365785332

Epoch: 6| Step: 1
Training loss: 2.617030143737793
Validation loss: 2.346080485210624

Epoch: 6| Step: 2
Training loss: 2.113287925720215
Validation loss: 2.334273317808746

Epoch: 6| Step: 3
Training loss: 2.7379937171936035
Validation loss: 2.311662453477101

Epoch: 6| Step: 4
Training loss: 2.700427293777466
Validation loss: 2.2890107682956162

Epoch: 6| Step: 5
Training loss: 1.7238366603851318
Validation loss: 2.284051861814273

Epoch: 6| Step: 6
Training loss: 2.6835432052612305
Validation loss: 2.2808662255605063

Epoch: 6| Step: 7
Training loss: 1.9517710208892822
Validation loss: 2.280237888777128

Epoch: 6| Step: 8
Training loss: 2.036835193634033
Validation loss: 2.292705561525078

Epoch: 6| Step: 9
Training loss: 2.5701868534088135
Validation loss: 2.3092857560803814

Epoch: 6| Step: 10
Training loss: 2.890577554702759
Validation loss: 2.3168149302082677

Epoch: 6| Step: 11
Training loss: 2.8802905082702637
Validation loss: 2.333747156204716

Epoch: 6| Step: 12
Training loss: 3.025101900100708
Validation loss: 2.326028775143367

Epoch: 6| Step: 13
Training loss: 2.9066638946533203
Validation loss: 2.3180370535901798

Epoch: 65| Step: 0
Training loss: 2.86248779296875
Validation loss: 2.3196447254509054

Epoch: 6| Step: 1
Training loss: 2.813899040222168
Validation loss: 2.3013111135011077

Epoch: 6| Step: 2
Training loss: 3.404433250427246
Validation loss: 2.2844876909768708

Epoch: 6| Step: 3
Training loss: 2.2378857135772705
Validation loss: 2.2720748609112156

Epoch: 6| Step: 4
Training loss: 2.579340696334839
Validation loss: 2.2608464764010523

Epoch: 6| Step: 5
Training loss: 2.5695383548736572
Validation loss: 2.2692137149072464

Epoch: 6| Step: 6
Training loss: 2.6033167839050293
Validation loss: 2.2708327616414716

Epoch: 6| Step: 7
Training loss: 2.8459272384643555
Validation loss: 2.2631977322281047

Epoch: 6| Step: 8
Training loss: 2.1358847618103027
Validation loss: 2.273116771892835

Epoch: 6| Step: 9
Training loss: 1.9881607294082642
Validation loss: 2.273919615694272

Epoch: 6| Step: 10
Training loss: 2.335784435272217
Validation loss: 2.268147909513084

Epoch: 6| Step: 11
Training loss: 2.76057767868042
Validation loss: 2.266411191673689

Epoch: 6| Step: 12
Training loss: 2.33302903175354
Validation loss: 2.265588116902177

Epoch: 6| Step: 13
Training loss: 2.597385883331299
Validation loss: 2.2656173808600313

Epoch: 66| Step: 0
Training loss: 2.127696990966797
Validation loss: 2.26143826207807

Epoch: 6| Step: 1
Training loss: 2.6275017261505127
Validation loss: 2.2563517247476885

Epoch: 6| Step: 2
Training loss: 3.088627338409424
Validation loss: 2.2568018231340634

Epoch: 6| Step: 3
Training loss: 3.0123887062072754
Validation loss: 2.2618563252110637

Epoch: 6| Step: 4
Training loss: 1.566406011581421
Validation loss: 2.25423099148658

Epoch: 6| Step: 5
Training loss: 2.13424015045166
Validation loss: 2.2636374709426716

Epoch: 6| Step: 6
Training loss: 2.3160247802734375
Validation loss: 2.2656538255753054

Epoch: 6| Step: 7
Training loss: 1.7396905422210693
Validation loss: 2.2806138838491132

Epoch: 6| Step: 8
Training loss: 2.7510173320770264
Validation loss: 2.30421793589028

Epoch: 6| Step: 9
Training loss: 3.034607410430908
Validation loss: 2.3142127195994058

Epoch: 6| Step: 10
Training loss: 3.167933940887451
Validation loss: 2.3299921815113356

Epoch: 6| Step: 11
Training loss: 2.509492874145508
Validation loss: 2.31558681303455

Epoch: 6| Step: 12
Training loss: 3.0024735927581787
Validation loss: 2.2973657551632134

Epoch: 6| Step: 13
Training loss: 2.4579360485076904
Validation loss: 2.2840050112816597

Epoch: 67| Step: 0
Training loss: 2.4128808975219727
Validation loss: 2.2765796146085187

Epoch: 6| Step: 1
Training loss: 2.954630136489868
Validation loss: 2.2577715689136135

Epoch: 6| Step: 2
Training loss: 2.0678353309631348
Validation loss: 2.251253466452322

Epoch: 6| Step: 3
Training loss: 3.4362568855285645
Validation loss: 2.2514928899785525

Epoch: 6| Step: 4
Training loss: 2.792537212371826
Validation loss: 2.2498512870521954

Epoch: 6| Step: 5
Training loss: 3.2427330017089844
Validation loss: 2.2470819283557195

Epoch: 6| Step: 6
Training loss: 2.4432079792022705
Validation loss: 2.251766047170085

Epoch: 6| Step: 7
Training loss: 2.8905081748962402
Validation loss: 2.2464958865155458

Epoch: 6| Step: 8
Training loss: 1.6843087673187256
Validation loss: 2.2501838771245812

Epoch: 6| Step: 9
Training loss: 2.6244101524353027
Validation loss: 2.2493233270542596

Epoch: 6| Step: 10
Training loss: 2.6102631092071533
Validation loss: 2.252198253908465

Epoch: 6| Step: 11
Training loss: 2.23862361907959
Validation loss: 2.2466378596521195

Epoch: 6| Step: 12
Training loss: 2.0830230712890625
Validation loss: 2.2512590141706568

Epoch: 6| Step: 13
Training loss: 2.2694404125213623
Validation loss: 2.2484585264677643

Epoch: 68| Step: 0
Training loss: 3.1008596420288086
Validation loss: 2.2493852415392475

Epoch: 6| Step: 1
Training loss: 2.2025721073150635
Validation loss: 2.24908265759868

Epoch: 6| Step: 2
Training loss: 3.0642073154449463
Validation loss: 2.2467917101357573

Epoch: 6| Step: 3
Training loss: 3.301535129547119
Validation loss: 2.258310615375478

Epoch: 6| Step: 4
Training loss: 1.7829746007919312
Validation loss: 2.2668564550338255

Epoch: 6| Step: 5
Training loss: 2.1728274822235107
Validation loss: 2.293462263640537

Epoch: 6| Step: 6
Training loss: 2.209432601928711
Validation loss: 2.2998956762334353

Epoch: 6| Step: 7
Training loss: 1.9817354679107666
Validation loss: 2.3443588031235563

Epoch: 6| Step: 8
Training loss: 2.995511054992676
Validation loss: 2.380824387714427

Epoch: 6| Step: 9
Training loss: 3.042051076889038
Validation loss: 2.3888856646835164

Epoch: 6| Step: 10
Training loss: 2.5428457260131836
Validation loss: 2.377040522072905

Epoch: 6| Step: 11
Training loss: 2.934598922729492
Validation loss: 2.309002455844674

Epoch: 6| Step: 12
Training loss: 2.1147890090942383
Validation loss: 2.280705423765285

Epoch: 6| Step: 13
Training loss: 2.1065351963043213
Validation loss: 2.269380038784396

Epoch: 69| Step: 0
Training loss: 2.3525538444519043
Validation loss: 2.252732671717162

Epoch: 6| Step: 1
Training loss: 2.5760908126831055
Validation loss: 2.2726994278610393

Epoch: 6| Step: 2
Training loss: 3.0720672607421875
Validation loss: 2.307074918541857

Epoch: 6| Step: 3
Training loss: 2.783224105834961
Validation loss: 2.3213968866614887

Epoch: 6| Step: 4
Training loss: 2.695108413696289
Validation loss: 2.2815541516068163

Epoch: 6| Step: 5
Training loss: 2.911020517349243
Validation loss: 2.261418127244519

Epoch: 6| Step: 6
Training loss: 2.5135397911071777
Validation loss: 2.23836209312562

Epoch: 6| Step: 7
Training loss: 2.373521327972412
Validation loss: 2.2353050606225127

Epoch: 6| Step: 8
Training loss: 2.79584002494812
Validation loss: 2.2516809996738227

Epoch: 6| Step: 9
Training loss: 1.9810211658477783
Validation loss: 2.3037125654118036

Epoch: 6| Step: 10
Training loss: 2.3291192054748535
Validation loss: 2.3509591933219665

Epoch: 6| Step: 11
Training loss: 2.6219444274902344
Validation loss: 2.3853947013937016

Epoch: 6| Step: 12
Training loss: 2.523055076599121
Validation loss: 2.4090481727353987

Epoch: 6| Step: 13
Training loss: 2.4530460834503174
Validation loss: 2.423178585626746

Epoch: 70| Step: 0
Training loss: 2.545792818069458
Validation loss: 2.340850430150186

Epoch: 6| Step: 1
Training loss: 2.568333625793457
Validation loss: 2.2724543797072543

Epoch: 6| Step: 2
Training loss: 2.2585880756378174
Validation loss: 2.241690807445075

Epoch: 6| Step: 3
Training loss: 2.7837135791778564
Validation loss: 2.2323152583132506

Epoch: 6| Step: 4
Training loss: 2.86710786819458
Validation loss: 2.2352693465448197

Epoch: 6| Step: 5
Training loss: 2.4714293479919434
Validation loss: 2.2438808051488732

Epoch: 6| Step: 6
Training loss: 3.170825481414795
Validation loss: 2.2662151321288078

Epoch: 6| Step: 7
Training loss: 2.411579132080078
Validation loss: 2.33633352095081

Epoch: 6| Step: 8
Training loss: 3.1424756050109863
Validation loss: 2.397012851571524

Epoch: 6| Step: 9
Training loss: 2.518470287322998
Validation loss: 2.4173489975672897

Epoch: 6| Step: 10
Training loss: 2.645263195037842
Validation loss: 2.5429951913895144

Epoch: 6| Step: 11
Training loss: 1.452924370765686
Validation loss: 2.5348884392810125

Epoch: 6| Step: 12
Training loss: 3.0506725311279297
Validation loss: 2.4166695507623817

Epoch: 6| Step: 13
Training loss: 3.0555872917175293
Validation loss: 2.352460453587194

Epoch: 71| Step: 0
Training loss: 2.4397454261779785
Validation loss: 2.3075878645784114

Epoch: 6| Step: 1
Training loss: 2.0512921810150146
Validation loss: 2.307618906421046

Epoch: 6| Step: 2
Training loss: 3.0994319915771484
Validation loss: 2.3156394112494683

Epoch: 6| Step: 3
Training loss: 2.7499468326568604
Validation loss: 2.358016929318828

Epoch: 6| Step: 4
Training loss: 2.3528969287872314
Validation loss: 2.3874271505622455

Epoch: 6| Step: 5
Training loss: 2.3207573890686035
Validation loss: 2.4259382037706274

Epoch: 6| Step: 6
Training loss: 3.0557336807250977
Validation loss: 2.485721734262282

Epoch: 6| Step: 7
Training loss: 2.63254714012146
Validation loss: 2.5365550107853387

Epoch: 6| Step: 8
Training loss: 2.9701082706451416
Validation loss: 2.572714605639058

Epoch: 6| Step: 9
Training loss: 2.895110845565796
Validation loss: 2.561838760170885

Epoch: 6| Step: 10
Training loss: 2.328159809112549
Validation loss: 2.531379322851858

Epoch: 6| Step: 11
Training loss: 3.59950590133667
Validation loss: 2.4852682621248308

Epoch: 6| Step: 12
Training loss: 2.2636194229125977
Validation loss: 2.427075537302161

Epoch: 6| Step: 13
Training loss: 1.8068082332611084
Validation loss: 2.3852842520642024

Epoch: 72| Step: 0
Training loss: 1.8936225175857544
Validation loss: 2.3670830957351194

Epoch: 6| Step: 1
Training loss: 2.469313859939575
Validation loss: 2.375476207784427

Epoch: 6| Step: 2
Training loss: 3.164447069168091
Validation loss: 2.3529310123894804

Epoch: 6| Step: 3
Training loss: 2.349226236343384
Validation loss: 2.3622961685221684

Epoch: 6| Step: 4
Training loss: 2.6197800636291504
Validation loss: 2.3772101838101625

Epoch: 6| Step: 5
Training loss: 2.6442158222198486
Validation loss: 2.3790582559442006

Epoch: 6| Step: 6
Training loss: 2.586648941040039
Validation loss: 2.389321214409285

Epoch: 6| Step: 7
Training loss: 2.014755964279175
Validation loss: 2.3705281467847925

Epoch: 6| Step: 8
Training loss: 3.035629987716675
Validation loss: 2.3781971316183768

Epoch: 6| Step: 9
Training loss: 2.6423707008361816
Validation loss: 2.3459565460041003

Epoch: 6| Step: 10
Training loss: 2.7721314430236816
Validation loss: 2.3290243405167774

Epoch: 6| Step: 11
Training loss: 2.747849941253662
Validation loss: 2.3141580858538227

Epoch: 6| Step: 12
Training loss: 2.9288573265075684
Validation loss: 2.3048962931479178

Epoch: 6| Step: 13
Training loss: 2.293088674545288
Validation loss: 2.295150774781422

Epoch: 73| Step: 0
Training loss: 3.159069538116455
Validation loss: 2.294926239598182

Epoch: 6| Step: 1
Training loss: 1.9954911470413208
Validation loss: 2.296624086236441

Epoch: 6| Step: 2
Training loss: 2.8622543811798096
Validation loss: 2.2949485419898905

Epoch: 6| Step: 3
Training loss: 2.427414894104004
Validation loss: 2.301085320852136

Epoch: 6| Step: 4
Training loss: 1.696584701538086
Validation loss: 2.3019043271259596

Epoch: 6| Step: 5
Training loss: 2.5919456481933594
Validation loss: 2.316957358391054

Epoch: 6| Step: 6
Training loss: 2.996711254119873
Validation loss: 2.35035373831308

Epoch: 6| Step: 7
Training loss: 2.7404136657714844
Validation loss: 2.3587153342462357

Epoch: 6| Step: 8
Training loss: 2.6308422088623047
Validation loss: 2.3407248809773433

Epoch: 6| Step: 9
Training loss: 2.5659117698669434
Validation loss: 2.328531439586352

Epoch: 6| Step: 10
Training loss: 3.406525135040283
Validation loss: 2.3170795979038363

Epoch: 6| Step: 11
Training loss: 2.457740306854248
Validation loss: 2.297266851189316

Epoch: 6| Step: 12
Training loss: 1.8671468496322632
Validation loss: 2.2893134240181214

Epoch: 6| Step: 13
Training loss: 2.7866485118865967
Validation loss: 2.2747648774936633

Epoch: 74| Step: 0
Training loss: 3.1075334548950195
Validation loss: 2.263845564216696

Epoch: 6| Step: 1
Training loss: 2.322009801864624
Validation loss: 2.2263601005718274

Epoch: 6| Step: 2
Training loss: 2.7954516410827637
Validation loss: 2.2133784691492715

Epoch: 6| Step: 3
Training loss: 1.9175865650177002
Validation loss: 2.2209725482489473

Epoch: 6| Step: 4
Training loss: 2.6587018966674805
Validation loss: 2.231183087953957

Epoch: 6| Step: 5
Training loss: 2.3955087661743164
Validation loss: 2.249851647243705

Epoch: 6| Step: 6
Training loss: 2.510209083557129
Validation loss: 2.2456939733156593

Epoch: 6| Step: 7
Training loss: 1.9695481061935425
Validation loss: 2.2513198262901715

Epoch: 6| Step: 8
Training loss: 2.996546745300293
Validation loss: 2.268412431081136

Epoch: 6| Step: 9
Training loss: 2.216977834701538
Validation loss: 2.233009804961502

Epoch: 6| Step: 10
Training loss: 2.9273853302001953
Validation loss: 2.2257099497702812

Epoch: 6| Step: 11
Training loss: 2.633610486984253
Validation loss: 2.2206181095492457

Epoch: 6| Step: 12
Training loss: 2.56638240814209
Validation loss: 2.216512744144727

Epoch: 6| Step: 13
Training loss: 2.2057862281799316
Validation loss: 2.2196583004407984

Epoch: 75| Step: 0
Training loss: 3.0572237968444824
Validation loss: 2.2233233580025296

Epoch: 6| Step: 1
Training loss: 2.640036106109619
Validation loss: 2.239455294865434

Epoch: 6| Step: 2
Training loss: 1.8265602588653564
Validation loss: 2.2459638195653118

Epoch: 6| Step: 3
Training loss: 2.3947348594665527
Validation loss: 2.26066174814778

Epoch: 6| Step: 4
Training loss: 2.726003646850586
Validation loss: 2.25897660563069

Epoch: 6| Step: 5
Training loss: 2.045130968093872
Validation loss: 2.2560005085442656

Epoch: 6| Step: 6
Training loss: 2.301464319229126
Validation loss: 2.253758357417199

Epoch: 6| Step: 7
Training loss: 3.0252561569213867
Validation loss: 2.242388948317497

Epoch: 6| Step: 8
Training loss: 2.223931312561035
Validation loss: 2.2384162872068343

Epoch: 6| Step: 9
Training loss: 2.9450056552886963
Validation loss: 2.2268076148084415

Epoch: 6| Step: 10
Training loss: 2.3749043941497803
Validation loss: 2.2137998534787084

Epoch: 6| Step: 11
Training loss: 2.405121326446533
Validation loss: 2.2152936227859987

Epoch: 6| Step: 12
Training loss: 2.620237350463867
Validation loss: 2.2322869711024786

Epoch: 6| Step: 13
Training loss: 3.3397560119628906
Validation loss: 2.227797451839652

Epoch: 76| Step: 0
Training loss: 2.5000524520874023
Validation loss: 2.2247247747195664

Epoch: 6| Step: 1
Training loss: 2.412341833114624
Validation loss: 2.228865509392113

Epoch: 6| Step: 2
Training loss: 2.414130926132202
Validation loss: 2.2325940388505177

Epoch: 6| Step: 3
Training loss: 2.782557964324951
Validation loss: 2.228993341486941

Epoch: 6| Step: 4
Training loss: 1.944204330444336
Validation loss: 2.2477278376138337

Epoch: 6| Step: 5
Training loss: 2.7221245765686035
Validation loss: 2.2446064308125484

Epoch: 6| Step: 6
Training loss: 3.058335065841675
Validation loss: 2.231642351355604

Epoch: 6| Step: 7
Training loss: 3.348792552947998
Validation loss: 2.2240630657442155

Epoch: 6| Step: 8
Training loss: 1.9737093448638916
Validation loss: 2.2097126796681392

Epoch: 6| Step: 9
Training loss: 1.8980191946029663
Validation loss: 2.1983339683983916

Epoch: 6| Step: 10
Training loss: 2.998851776123047
Validation loss: 2.192787188355641

Epoch: 6| Step: 11
Training loss: 2.0470693111419678
Validation loss: 2.190474287156136

Epoch: 6| Step: 12
Training loss: 2.323507070541382
Validation loss: 2.1906533125908143

Epoch: 6| Step: 13
Training loss: 2.686343193054199
Validation loss: 2.197249750937185

Epoch: 77| Step: 0
Training loss: 2.1899397373199463
Validation loss: 2.203641512060678

Epoch: 6| Step: 1
Training loss: 2.1822190284729004
Validation loss: 2.2095835529347903

Epoch: 6| Step: 2
Training loss: 2.9589719772338867
Validation loss: 2.2319740300537436

Epoch: 6| Step: 3
Training loss: 2.220158100128174
Validation loss: 2.2358054730199997

Epoch: 6| Step: 4
Training loss: 2.1423568725585938
Validation loss: 2.2421016923842894

Epoch: 6| Step: 5
Training loss: 2.898632049560547
Validation loss: 2.253147863572644

Epoch: 6| Step: 6
Training loss: 2.5933589935302734
Validation loss: 2.2764693306338404

Epoch: 6| Step: 7
Training loss: 2.8783974647521973
Validation loss: 2.2761690334607194

Epoch: 6| Step: 8
Training loss: 2.5986313819885254
Validation loss: 2.276521077720068

Epoch: 6| Step: 9
Training loss: 1.9705770015716553
Validation loss: 2.2536769605452016

Epoch: 6| Step: 10
Training loss: 2.661755323410034
Validation loss: 2.2497106726451586

Epoch: 6| Step: 11
Training loss: 2.6323256492614746
Validation loss: 2.2533901968309955

Epoch: 6| Step: 12
Training loss: 2.537092447280884
Validation loss: 2.252047154211229

Epoch: 6| Step: 13
Training loss: 3.0836868286132812
Validation loss: 2.233624212203487

Epoch: 78| Step: 0
Training loss: 2.1881136894226074
Validation loss: 2.2307020823160806

Epoch: 6| Step: 1
Training loss: 2.4011669158935547
Validation loss: 2.231563183569139

Epoch: 6| Step: 2
Training loss: 2.969888925552368
Validation loss: 2.2428149433546167

Epoch: 6| Step: 3
Training loss: 1.9642077684402466
Validation loss: 2.2217883409992343

Epoch: 6| Step: 4
Training loss: 2.54880428314209
Validation loss: 2.2023534185142926

Epoch: 6| Step: 5
Training loss: 2.498143196105957
Validation loss: 2.201794389755495

Epoch: 6| Step: 6
Training loss: 2.2820839881896973
Validation loss: 2.179032528272239

Epoch: 6| Step: 7
Training loss: 2.596069097518921
Validation loss: 2.1849183292799097

Epoch: 6| Step: 8
Training loss: 2.5006766319274902
Validation loss: 2.1806471296536025

Epoch: 6| Step: 9
Training loss: 2.362071990966797
Validation loss: 2.1797374204922746

Epoch: 6| Step: 10
Training loss: 2.426331043243408
Validation loss: 2.1726361423410396

Epoch: 6| Step: 11
Training loss: 2.9422073364257812
Validation loss: 2.1802856255603094

Epoch: 6| Step: 12
Training loss: 2.312324047088623
Validation loss: 2.1819776847798336

Epoch: 6| Step: 13
Training loss: 2.9533889293670654
Validation loss: 2.183618644232391

Epoch: 79| Step: 0
Training loss: 2.3962855339050293
Validation loss: 2.1753579314037035

Epoch: 6| Step: 1
Training loss: 2.226045608520508
Validation loss: 2.1801055503147904

Epoch: 6| Step: 2
Training loss: 2.6249289512634277
Validation loss: 2.186567102709124

Epoch: 6| Step: 3
Training loss: 2.440559148788452
Validation loss: 2.184690861291783

Epoch: 6| Step: 4
Training loss: 2.26117205619812
Validation loss: 2.182071885754985

Epoch: 6| Step: 5
Training loss: 2.3184974193573
Validation loss: 2.1972470104053454

Epoch: 6| Step: 6
Training loss: 2.903012752532959
Validation loss: 2.2135493819431593

Epoch: 6| Step: 7
Training loss: 2.6995863914489746
Validation loss: 2.239251552089568

Epoch: 6| Step: 8
Training loss: 2.2597198486328125
Validation loss: 2.2437623623878724

Epoch: 6| Step: 9
Training loss: 2.7392420768737793
Validation loss: 2.2458989953482025

Epoch: 6| Step: 10
Training loss: 1.392716407775879
Validation loss: 2.257193011622275

Epoch: 6| Step: 11
Training loss: 2.6833481788635254
Validation loss: 2.2553799101101455

Epoch: 6| Step: 12
Training loss: 2.887808322906494
Validation loss: 2.2162231347894155

Epoch: 6| Step: 13
Training loss: 2.9322562217712402
Validation loss: 2.1936801274617515

Epoch: 80| Step: 0
Training loss: 2.3561689853668213
Validation loss: 2.1769110387371433

Epoch: 6| Step: 1
Training loss: 1.7325818538665771
Validation loss: 2.165093655227333

Epoch: 6| Step: 2
Training loss: 3.3290038108825684
Validation loss: 2.1742028959335817

Epoch: 6| Step: 3
Training loss: 2.034212112426758
Validation loss: 2.170219703387189

Epoch: 6| Step: 4
Training loss: 2.7093734741210938
Validation loss: 2.176919194959825

Epoch: 6| Step: 5
Training loss: 2.5199570655822754
Validation loss: 2.187971039484906

Epoch: 6| Step: 6
Training loss: 2.6897809505462646
Validation loss: 2.192018516602055

Epoch: 6| Step: 7
Training loss: 1.869628667831421
Validation loss: 2.2017623814203406

Epoch: 6| Step: 8
Training loss: 2.2819907665252686
Validation loss: 2.2111922361517466

Epoch: 6| Step: 9
Training loss: 2.9613091945648193
Validation loss: 2.22447701936127

Epoch: 6| Step: 10
Training loss: 2.4935808181762695
Validation loss: 2.2338271294870684

Epoch: 6| Step: 11
Training loss: 2.6130828857421875
Validation loss: 2.2527675256934216

Epoch: 6| Step: 12
Training loss: 2.633131265640259
Validation loss: 2.225438546108943

Epoch: 6| Step: 13
Training loss: 2.825800657272339
Validation loss: 2.2008398194466867

Epoch: 81| Step: 0
Training loss: 2.807934522628784
Validation loss: 2.1879217342663835

Epoch: 6| Step: 1
Training loss: 2.166229009628296
Validation loss: 2.173821276234042

Epoch: 6| Step: 2
Training loss: 1.9176063537597656
Validation loss: 2.1718610486676617

Epoch: 6| Step: 3
Training loss: 2.757445812225342
Validation loss: 2.1744207951330368

Epoch: 6| Step: 4
Training loss: 2.1979494094848633
Validation loss: 2.1714398809658584

Epoch: 6| Step: 5
Training loss: 2.1655983924865723
Validation loss: 2.1730762656017015

Epoch: 6| Step: 6
Training loss: 3.056049346923828
Validation loss: 2.1685074221703315

Epoch: 6| Step: 7
Training loss: 1.8003294467926025
Validation loss: 2.1720964267689693

Epoch: 6| Step: 8
Training loss: 2.7060658931732178
Validation loss: 2.1772900435232345

Epoch: 6| Step: 9
Training loss: 2.333815097808838
Validation loss: 2.1904537113763953

Epoch: 6| Step: 10
Training loss: 2.911877155303955
Validation loss: 2.2031252845641105

Epoch: 6| Step: 11
Training loss: 2.5215954780578613
Validation loss: 2.2194158338731333

Epoch: 6| Step: 12
Training loss: 2.90704345703125
Validation loss: 2.2203847977422897

Epoch: 6| Step: 13
Training loss: 2.1911842823028564
Validation loss: 2.2189242814176824

Epoch: 82| Step: 0
Training loss: 2.45951247215271
Validation loss: 2.219999292845367

Epoch: 6| Step: 1
Training loss: 2.5711264610290527
Validation loss: 2.22601310412089

Epoch: 6| Step: 2
Training loss: 2.688934803009033
Validation loss: 2.2193258500868276

Epoch: 6| Step: 3
Training loss: 2.6763458251953125
Validation loss: 2.179606121073487

Epoch: 6| Step: 4
Training loss: 2.717341423034668
Validation loss: 2.1729460403483403

Epoch: 6| Step: 5
Training loss: 2.197237491607666
Validation loss: 2.1625776265257146

Epoch: 6| Step: 6
Training loss: 2.903813362121582
Validation loss: 2.1611166051639024

Epoch: 6| Step: 7
Training loss: 2.0245025157928467
Validation loss: 2.16703176242049

Epoch: 6| Step: 8
Training loss: 2.666736125946045
Validation loss: 2.1640955504550727

Epoch: 6| Step: 9
Training loss: 2.40000581741333
Validation loss: 2.1594027690989996

Epoch: 6| Step: 10
Training loss: 2.334730863571167
Validation loss: 2.164179209739931

Epoch: 6| Step: 11
Training loss: 2.4625797271728516
Validation loss: 2.1699613678839897

Epoch: 6| Step: 12
Training loss: 2.365138292312622
Validation loss: 2.1783775257807907

Epoch: 6| Step: 13
Training loss: 2.213667631149292
Validation loss: 2.184582443647487

Epoch: 83| Step: 0
Training loss: 2.2764997482299805
Validation loss: 2.1954178681937595

Epoch: 6| Step: 1
Training loss: 2.878675937652588
Validation loss: 2.1938090093674196

Epoch: 6| Step: 2
Training loss: 2.4800238609313965
Validation loss: 2.220313564423592

Epoch: 6| Step: 3
Training loss: 2.0517406463623047
Validation loss: 2.2435917521035798

Epoch: 6| Step: 4
Training loss: 2.2917490005493164
Validation loss: 2.2724009649727934

Epoch: 6| Step: 5
Training loss: 2.3908069133758545
Validation loss: 2.253380262723533

Epoch: 6| Step: 6
Training loss: 2.8894920349121094
Validation loss: 2.2326916417767926

Epoch: 6| Step: 7
Training loss: 2.828968048095703
Validation loss: 2.2189666340428014

Epoch: 6| Step: 8
Training loss: 2.4002740383148193
Validation loss: 2.2055929758215465

Epoch: 6| Step: 9
Training loss: 2.529050827026367
Validation loss: 2.18403277602247

Epoch: 6| Step: 10
Training loss: 2.5433549880981445
Validation loss: 2.1762910030221425

Epoch: 6| Step: 11
Training loss: 2.8196797370910645
Validation loss: 2.171531069663263

Epoch: 6| Step: 12
Training loss: 1.9001870155334473
Validation loss: 2.166315096680836

Epoch: 6| Step: 13
Training loss: 1.6061972379684448
Validation loss: 2.1570895679535402

Epoch: 84| Step: 0
Training loss: 2.3522586822509766
Validation loss: 2.148684360647714

Epoch: 6| Step: 1
Training loss: 2.8148787021636963
Validation loss: 2.150339365005493

Epoch: 6| Step: 2
Training loss: 2.849351406097412
Validation loss: 2.148830857328189

Epoch: 6| Step: 3
Training loss: 2.455195426940918
Validation loss: 2.1460079685334237

Epoch: 6| Step: 4
Training loss: 1.7096210718154907
Validation loss: 2.152551917619603

Epoch: 6| Step: 5
Training loss: 2.2632222175598145
Validation loss: 2.1655674595986643

Epoch: 6| Step: 6
Training loss: 1.9377001523971558
Validation loss: 2.1741117687635523

Epoch: 6| Step: 7
Training loss: 3.206118583679199
Validation loss: 2.1977820780969437

Epoch: 6| Step: 8
Training loss: 2.6383309364318848
Validation loss: 2.1930386302291707

Epoch: 6| Step: 9
Training loss: 2.3340001106262207
Validation loss: 2.2019362013827086

Epoch: 6| Step: 10
Training loss: 2.8501105308532715
Validation loss: 2.197100757270731

Epoch: 6| Step: 11
Training loss: 2.0880327224731445
Validation loss: 2.1960350390403502

Epoch: 6| Step: 12
Training loss: 2.191802740097046
Validation loss: 2.193699595748737

Epoch: 6| Step: 13
Training loss: 2.647057294845581
Validation loss: 2.192236759329355

Epoch: 85| Step: 0
Training loss: 2.6524786949157715
Validation loss: 2.179094215875031

Epoch: 6| Step: 1
Training loss: 2.5761473178863525
Validation loss: 2.161682798016456

Epoch: 6| Step: 2
Training loss: 2.3250956535339355
Validation loss: 2.1554990712032525

Epoch: 6| Step: 3
Training loss: 1.5525637865066528
Validation loss: 2.1634286167801067

Epoch: 6| Step: 4
Training loss: 2.721996545791626
Validation loss: 2.154537925156214

Epoch: 6| Step: 5
Training loss: 2.747401237487793
Validation loss: 2.1671765568435832

Epoch: 6| Step: 6
Training loss: 2.5262386798858643
Validation loss: 2.158557700854476

Epoch: 6| Step: 7
Training loss: 2.1044459342956543
Validation loss: 2.1642204061631234

Epoch: 6| Step: 8
Training loss: 2.130545139312744
Validation loss: 2.1821924166012834

Epoch: 6| Step: 9
Training loss: 2.973654270172119
Validation loss: 2.207966277676244

Epoch: 6| Step: 10
Training loss: 2.422001838684082
Validation loss: 2.2254092795874483

Epoch: 6| Step: 11
Training loss: 3.026106834411621
Validation loss: 2.2269079890302432

Epoch: 6| Step: 12
Training loss: 2.10858154296875
Validation loss: 2.197705263732582

Epoch: 6| Step: 13
Training loss: 2.302847385406494
Validation loss: 2.1879804211278118

Epoch: 86| Step: 0
Training loss: 2.361410140991211
Validation loss: 2.1814410148128385

Epoch: 6| Step: 1
Training loss: 2.9755783081054688
Validation loss: 2.165879217527246

Epoch: 6| Step: 2
Training loss: 2.72981858253479
Validation loss: 2.163770660277336

Epoch: 6| Step: 3
Training loss: 2.532036542892456
Validation loss: 2.151999124916651

Epoch: 6| Step: 4
Training loss: 2.5419387817382812
Validation loss: 2.144242953228694

Epoch: 6| Step: 5
Training loss: 2.4545116424560547
Validation loss: 2.1374022012115805

Epoch: 6| Step: 6
Training loss: 1.2095587253570557
Validation loss: 2.1436738109075897

Epoch: 6| Step: 7
Training loss: 1.9861568212509155
Validation loss: 2.137765807490195

Epoch: 6| Step: 8
Training loss: 1.8373959064483643
Validation loss: 2.142852403784311

Epoch: 6| Step: 9
Training loss: 2.539381980895996
Validation loss: 2.155434925069091

Epoch: 6| Step: 10
Training loss: 3.0907928943634033
Validation loss: 2.1669345184039046

Epoch: 6| Step: 11
Training loss: 2.699496030807495
Validation loss: 2.167933189740745

Epoch: 6| Step: 12
Training loss: 2.906161308288574
Validation loss: 2.181356458253758

Epoch: 6| Step: 13
Training loss: 2.217498779296875
Validation loss: 2.1872496169100524

Epoch: 87| Step: 0
Training loss: 2.408707618713379
Validation loss: 2.182324432557629

Epoch: 6| Step: 1
Training loss: 2.8308520317077637
Validation loss: 2.180721172722437

Epoch: 6| Step: 2
Training loss: 2.7553765773773193
Validation loss: 2.188395861656435

Epoch: 6| Step: 3
Training loss: 2.8211965560913086
Validation loss: 2.178113745104882

Epoch: 6| Step: 4
Training loss: 1.9287617206573486
Validation loss: 2.1649500195698073

Epoch: 6| Step: 5
Training loss: 3.322402000427246
Validation loss: 2.158376366861405

Epoch: 6| Step: 6
Training loss: 2.4358534812927246
Validation loss: 2.141699675590761

Epoch: 6| Step: 7
Training loss: 2.9222359657287598
Validation loss: 2.133712440408686

Epoch: 6| Step: 8
Training loss: 1.6034438610076904
Validation loss: 2.126945052095639

Epoch: 6| Step: 9
Training loss: 1.7299706935882568
Validation loss: 2.1301515627932806

Epoch: 6| Step: 10
Training loss: 2.361931324005127
Validation loss: 2.13261850162219

Epoch: 6| Step: 11
Training loss: 1.8147401809692383
Validation loss: 2.1377153960607385

Epoch: 6| Step: 12
Training loss: 2.499760866165161
Validation loss: 2.1496097682624735

Epoch: 6| Step: 13
Training loss: 2.1611766815185547
Validation loss: 2.1676270731033815

Epoch: 88| Step: 0
Training loss: 3.018120765686035
Validation loss: 2.1855402069707073

Epoch: 6| Step: 1
Training loss: 2.2318179607391357
Validation loss: 2.2095581562288347

Epoch: 6| Step: 2
Training loss: 2.4871625900268555
Validation loss: 2.2502233879540556

Epoch: 6| Step: 3
Training loss: 2.6432971954345703
Validation loss: 2.247637197535525

Epoch: 6| Step: 4
Training loss: 2.5374250411987305
Validation loss: 2.210125941102223

Epoch: 6| Step: 5
Training loss: 2.1896448135375977
Validation loss: 2.185833518223096

Epoch: 6| Step: 6
Training loss: 2.696704864501953
Validation loss: 2.1769464785052883

Epoch: 6| Step: 7
Training loss: 2.768305778503418
Validation loss: 2.1583907142762215

Epoch: 6| Step: 8
Training loss: 2.1886074542999268
Validation loss: 2.149055081029092

Epoch: 6| Step: 9
Training loss: 2.3287863731384277
Validation loss: 2.134248193874154

Epoch: 6| Step: 10
Training loss: 2.0002689361572266
Validation loss: 2.138047939987593

Epoch: 6| Step: 11
Training loss: 2.072850227355957
Validation loss: 2.1410281491535965

Epoch: 6| Step: 12
Training loss: 2.5477962493896484
Validation loss: 2.1364724277168192

Epoch: 6| Step: 13
Training loss: 2.04642391204834
Validation loss: 2.144435636458858

Epoch: 89| Step: 0
Training loss: 2.8303780555725098
Validation loss: 2.1387682717333556

Epoch: 6| Step: 1
Training loss: 2.096698522567749
Validation loss: 2.1450664804827784

Epoch: 6| Step: 2
Training loss: 2.8197133541107178
Validation loss: 2.154322838270536

Epoch: 6| Step: 3
Training loss: 2.4653713703155518
Validation loss: 2.1770155814386185

Epoch: 6| Step: 4
Training loss: 1.8776369094848633
Validation loss: 2.1560208028362644

Epoch: 6| Step: 5
Training loss: 2.176417112350464
Validation loss: 2.155619767404372

Epoch: 6| Step: 6
Training loss: 3.160667896270752
Validation loss: 2.1306391044329573

Epoch: 6| Step: 7
Training loss: 2.4257421493530273
Validation loss: 2.1280683368764897

Epoch: 6| Step: 8
Training loss: 3.0013928413391113
Validation loss: 2.124706696438533

Epoch: 6| Step: 9
Training loss: 1.8190138339996338
Validation loss: 2.1198830886553695

Epoch: 6| Step: 10
Training loss: 2.4260711669921875
Validation loss: 2.123142412913743

Epoch: 6| Step: 11
Training loss: 2.4580066204071045
Validation loss: 2.1296721812217467

Epoch: 6| Step: 12
Training loss: 2.133051872253418
Validation loss: 2.164324091326806

Epoch: 6| Step: 13
Training loss: 2.050293207168579
Validation loss: 2.1865580351121965

Epoch: 90| Step: 0
Training loss: 2.8461077213287354
Validation loss: 2.206756084196029

Epoch: 6| Step: 1
Training loss: 2.6742172241210938
Validation loss: 2.2043456979977187

Epoch: 6| Step: 2
Training loss: 2.2327816486358643
Validation loss: 2.2385728436131633

Epoch: 6| Step: 3
Training loss: 2.763965606689453
Validation loss: 2.2059540389686503

Epoch: 6| Step: 4
Training loss: 2.586075782775879
Validation loss: 2.1852133735533683

Epoch: 6| Step: 5
Training loss: 1.8489031791687012
Validation loss: 2.1655636602832424

Epoch: 6| Step: 6
Training loss: 1.701035737991333
Validation loss: 2.1508587316800187

Epoch: 6| Step: 7
Training loss: 2.96838641166687
Validation loss: 2.1340613172900293

Epoch: 6| Step: 8
Training loss: 2.007256031036377
Validation loss: 2.118401071076752

Epoch: 6| Step: 9
Training loss: 2.8856396675109863
Validation loss: 2.1144153482170513

Epoch: 6| Step: 10
Training loss: 1.8919777870178223
Validation loss: 2.1142761015122935

Epoch: 6| Step: 11
Training loss: 2.60611629486084
Validation loss: 2.115060720392453

Epoch: 6| Step: 12
Training loss: 2.7137258052825928
Validation loss: 2.114138049464072

Epoch: 6| Step: 13
Training loss: 1.6920735836029053
Validation loss: 2.1166002417123444

Epoch: 91| Step: 0
Training loss: 2.3331942558288574
Validation loss: 2.117821470383675

Epoch: 6| Step: 1
Training loss: 2.278538227081299
Validation loss: 2.11090826219128

Epoch: 6| Step: 2
Training loss: 1.9776257276535034
Validation loss: 2.1218167248592583

Epoch: 6| Step: 3
Training loss: 2.632631301879883
Validation loss: 2.118854586796094

Epoch: 6| Step: 4
Training loss: 1.39680814743042
Validation loss: 2.115184468607749

Epoch: 6| Step: 5
Training loss: 2.1425275802612305
Validation loss: 2.1076785338822233

Epoch: 6| Step: 6
Training loss: 2.8536810874938965
Validation loss: 2.1167730798003492

Epoch: 6| Step: 7
Training loss: 2.500767469406128
Validation loss: 2.1316849570120535

Epoch: 6| Step: 8
Training loss: 2.7975754737854004
Validation loss: 2.1405622446408836

Epoch: 6| Step: 9
Training loss: 2.8041529655456543
Validation loss: 2.1429608406559115

Epoch: 6| Step: 10
Training loss: 2.6096248626708984
Validation loss: 2.135601326983462

Epoch: 6| Step: 11
Training loss: 2.4407527446746826
Validation loss: 2.1272172953492854

Epoch: 6| Step: 12
Training loss: 1.878962516784668
Validation loss: 2.1211266697094007

Epoch: 6| Step: 13
Training loss: 3.121628761291504
Validation loss: 2.127088487789195

Epoch: 92| Step: 0
Training loss: 2.221691608428955
Validation loss: 2.1235748260251937

Epoch: 6| Step: 1
Training loss: 2.639995574951172
Validation loss: 2.112829044301023

Epoch: 6| Step: 2
Training loss: 2.801344394683838
Validation loss: 2.1118316881118284

Epoch: 6| Step: 3
Training loss: 2.609903335571289
Validation loss: 2.1042695788926977

Epoch: 6| Step: 4
Training loss: 1.9483575820922852
Validation loss: 2.104882860696444

Epoch: 6| Step: 5
Training loss: 2.7793049812316895
Validation loss: 2.099765649405859

Epoch: 6| Step: 6
Training loss: 2.5031776428222656
Validation loss: 2.1011182928598053

Epoch: 6| Step: 7
Training loss: 2.086813449859619
Validation loss: 2.0954173431601575

Epoch: 6| Step: 8
Training loss: 3.035562038421631
Validation loss: 2.094923637246573

Epoch: 6| Step: 9
Training loss: 2.4221320152282715
Validation loss: 2.0946644967602146

Epoch: 6| Step: 10
Training loss: 2.3275434970855713
Validation loss: 2.093955168160059

Epoch: 6| Step: 11
Training loss: 1.531057596206665
Validation loss: 2.1060877525678245

Epoch: 6| Step: 12
Training loss: 2.2695329189300537
Validation loss: 2.108122520549323

Epoch: 6| Step: 13
Training loss: 2.376398801803589
Validation loss: 2.102463751710871

Epoch: 93| Step: 0
Training loss: 1.5988342761993408
Validation loss: 2.1464210915309128

Epoch: 6| Step: 1
Training loss: 1.9980473518371582
Validation loss: 2.147517611903529

Epoch: 6| Step: 2
Training loss: 2.3092291355133057
Validation loss: 2.1579507935431694

Epoch: 6| Step: 3
Training loss: 2.7156190872192383
Validation loss: 2.155563500619704

Epoch: 6| Step: 4
Training loss: 2.6436965465545654
Validation loss: 2.1575658603381087

Epoch: 6| Step: 5
Training loss: 2.7204489707946777
Validation loss: 2.1444155477708384

Epoch: 6| Step: 6
Training loss: 3.1041157245635986
Validation loss: 2.116556772621729

Epoch: 6| Step: 7
Training loss: 2.37276029586792
Validation loss: 2.1143905860121532

Epoch: 6| Step: 8
Training loss: 2.768245220184326
Validation loss: 2.1045658588409424

Epoch: 6| Step: 9
Training loss: 1.9348630905151367
Validation loss: 2.1132164898739068

Epoch: 6| Step: 10
Training loss: 2.2549242973327637
Validation loss: 2.105104507938508

Epoch: 6| Step: 11
Training loss: 2.609724283218384
Validation loss: 2.1125952505296275

Epoch: 6| Step: 12
Training loss: 2.0962703227996826
Validation loss: 2.1084715576582056

Epoch: 6| Step: 13
Training loss: 2.5681400299072266
Validation loss: 2.10607026597505

Epoch: 94| Step: 0
Training loss: 1.6872574090957642
Validation loss: 2.1078192546803463

Epoch: 6| Step: 1
Training loss: 1.9763150215148926
Validation loss: 2.1241984572461856

Epoch: 6| Step: 2
Training loss: 2.1885852813720703
Validation loss: 2.130897811664048

Epoch: 6| Step: 3
Training loss: 3.4492297172546387
Validation loss: 2.1353782710208686

Epoch: 6| Step: 4
Training loss: 1.9043300151824951
Validation loss: 2.134262018306281

Epoch: 6| Step: 5
Training loss: 2.283334970474243
Validation loss: 2.137216418020187

Epoch: 6| Step: 6
Training loss: 2.2363483905792236
Validation loss: 2.1357088883717856

Epoch: 6| Step: 7
Training loss: 2.631221294403076
Validation loss: 2.128169508390529

Epoch: 6| Step: 8
Training loss: 1.74879789352417
Validation loss: 2.112329649668868

Epoch: 6| Step: 9
Training loss: 2.499065399169922
Validation loss: 2.1070673645183606

Epoch: 6| Step: 10
Training loss: 1.6837224960327148
Validation loss: 2.110063027310115

Epoch: 6| Step: 11
Training loss: 3.839714288711548
Validation loss: 2.117727132253749

Epoch: 6| Step: 12
Training loss: 2.81024169921875
Validation loss: 2.111355258572486

Epoch: 6| Step: 13
Training loss: 2.351994514465332
Validation loss: 2.0996520365438154

Epoch: 95| Step: 0
Training loss: 2.5114502906799316
Validation loss: 2.1100782784082557

Epoch: 6| Step: 1
Training loss: 3.0661723613739014
Validation loss: 2.102051483687534

Epoch: 6| Step: 2
Training loss: 1.8987420797348022
Validation loss: 2.1344351550584197

Epoch: 6| Step: 3
Training loss: 2.9218053817749023
Validation loss: 2.1580921424332487

Epoch: 6| Step: 4
Training loss: 2.075503349304199
Validation loss: 2.107014553521269

Epoch: 6| Step: 5
Training loss: 2.258512020111084
Validation loss: 2.0987320843563286

Epoch: 6| Step: 6
Training loss: 2.724252700805664
Validation loss: 2.0893341225962483

Epoch: 6| Step: 7
Training loss: 2.2843329906463623
Validation loss: 2.0930449680615495

Epoch: 6| Step: 8
Training loss: 2.2823376655578613
Validation loss: 2.0895450038294636

Epoch: 6| Step: 9
Training loss: 1.747002363204956
Validation loss: 2.0898900352498537

Epoch: 6| Step: 10
Training loss: 2.4848289489746094
Validation loss: 2.1007655923084547

Epoch: 6| Step: 11
Training loss: 2.050116539001465
Validation loss: 2.115006305838144

Epoch: 6| Step: 12
Training loss: 2.2995660305023193
Validation loss: 2.142969533961306

Epoch: 6| Step: 13
Training loss: 2.393430471420288
Validation loss: 2.1848570146868305

Epoch: 96| Step: 0
Training loss: 2.22865629196167
Validation loss: 2.2243688708992413

Epoch: 6| Step: 1
Training loss: 2.2072243690490723
Validation loss: 2.239926815032959

Epoch: 6| Step: 2
Training loss: 3.0836825370788574
Validation loss: 2.225248752101775

Epoch: 6| Step: 3
Training loss: 2.074516773223877
Validation loss: 2.1830652554829917

Epoch: 6| Step: 4
Training loss: 2.1110172271728516
Validation loss: 2.1451037468448764

Epoch: 6| Step: 5
Training loss: 2.864182949066162
Validation loss: 2.121014941123224

Epoch: 6| Step: 6
Training loss: 1.8732527494430542
Validation loss: 2.094864458166143

Epoch: 6| Step: 7
Training loss: 2.1172797679901123
Validation loss: 2.080292163356658

Epoch: 6| Step: 8
Training loss: 2.648613691329956
Validation loss: 2.0813307685236775

Epoch: 6| Step: 9
Training loss: 2.7737302780151367
Validation loss: 2.086736432967647

Epoch: 6| Step: 10
Training loss: 1.9696425199508667
Validation loss: 2.0858262867055912

Epoch: 6| Step: 11
Training loss: 2.3065602779388428
Validation loss: 2.080725436569542

Epoch: 6| Step: 12
Training loss: 2.556349039077759
Validation loss: 2.0832250502801712

Epoch: 6| Step: 13
Training loss: 3.0730514526367188
Validation loss: 2.0770632682308072

Epoch: 97| Step: 0
Training loss: 1.9155951738357544
Validation loss: 2.08526917939545

Epoch: 6| Step: 1
Training loss: 1.9915568828582764
Validation loss: 2.0930608164879585

Epoch: 6| Step: 2
Training loss: 2.612128734588623
Validation loss: 2.0954586229016705

Epoch: 6| Step: 3
Training loss: 2.68133807182312
Validation loss: 2.1180184964210755

Epoch: 6| Step: 4
Training loss: 1.862778663635254
Validation loss: 2.1190999400231147

Epoch: 6| Step: 5
Training loss: 2.8363454341888428
Validation loss: 2.118469612572783

Epoch: 6| Step: 6
Training loss: 2.226804256439209
Validation loss: 2.1203529398928405

Epoch: 6| Step: 7
Training loss: 2.9043679237365723
Validation loss: 2.125907753103523

Epoch: 6| Step: 8
Training loss: 2.032871723175049
Validation loss: 2.126555319755308

Epoch: 6| Step: 9
Training loss: 2.026179552078247
Validation loss: 2.1141189016321653

Epoch: 6| Step: 10
Training loss: 2.902864456176758
Validation loss: 2.1145265333114134

Epoch: 6| Step: 11
Training loss: 1.6760025024414062
Validation loss: 2.1243225964166785

Epoch: 6| Step: 12
Training loss: 2.352266788482666
Validation loss: 2.1295969486236572

Epoch: 6| Step: 13
Training loss: 3.40878963470459
Validation loss: 2.1196380610107095

Epoch: 98| Step: 0
Training loss: 1.9664840698242188
Validation loss: 2.124057026319606

Epoch: 6| Step: 1
Training loss: 1.9537153244018555
Validation loss: 2.116730423383815

Epoch: 6| Step: 2
Training loss: 2.3265411853790283
Validation loss: 2.122958323006989

Epoch: 6| Step: 3
Training loss: 2.703314781188965
Validation loss: 2.128205140431722

Epoch: 6| Step: 4
Training loss: 2.566258430480957
Validation loss: 2.1216944366373043

Epoch: 6| Step: 5
Training loss: 2.1655731201171875
Validation loss: 2.1306133001081404

Epoch: 6| Step: 6
Training loss: 2.618678569793701
Validation loss: 2.1463921057280673

Epoch: 6| Step: 7
Training loss: 2.132047653198242
Validation loss: 2.1455319184128956

Epoch: 6| Step: 8
Training loss: 2.479609251022339
Validation loss: 2.179097489644122

Epoch: 6| Step: 9
Training loss: 1.7935290336608887
Validation loss: 2.1697536630015217

Epoch: 6| Step: 10
Training loss: 2.98777174949646
Validation loss: 2.156279904868013

Epoch: 6| Step: 11
Training loss: 2.421218156814575
Validation loss: 2.1465741178040862

Epoch: 6| Step: 12
Training loss: 2.6683335304260254
Validation loss: 2.144069048666185

Epoch: 6| Step: 13
Training loss: 2.0043821334838867
Validation loss: 2.124903799385153

Epoch: 99| Step: 0
Training loss: 2.081571578979492
Validation loss: 2.1071635087331138

Epoch: 6| Step: 1
Training loss: 3.158656120300293
Validation loss: 2.0814540668200423

Epoch: 6| Step: 2
Training loss: 3.167276620864868
Validation loss: 2.07875636828843

Epoch: 6| Step: 3
Training loss: 1.802943229675293
Validation loss: 2.0788145629308556

Epoch: 6| Step: 4
Training loss: 1.9950758218765259
Validation loss: 2.10048508644104

Epoch: 6| Step: 5
Training loss: 3.3653597831726074
Validation loss: 2.1249623990827993

Epoch: 6| Step: 6
Training loss: 2.573413372039795
Validation loss: 2.1222023425563687

Epoch: 6| Step: 7
Training loss: 1.9999057054519653
Validation loss: 2.136086085791229

Epoch: 6| Step: 8
Training loss: 2.010612964630127
Validation loss: 2.087573394980482

Epoch: 6| Step: 9
Training loss: 2.796924591064453
Validation loss: 2.0899860653825986

Epoch: 6| Step: 10
Training loss: 2.5562925338745117
Validation loss: 2.0917844003246677

Epoch: 6| Step: 11
Training loss: 1.7938647270202637
Validation loss: 2.0885834540090253

Epoch: 6| Step: 12
Training loss: 1.7113628387451172
Validation loss: 2.1049224253623717

Epoch: 6| Step: 13
Training loss: 2.6623480319976807
Validation loss: 2.1032814659098142

Epoch: 100| Step: 0
Training loss: 2.406146287918091
Validation loss: 2.1124565037347938

Epoch: 6| Step: 1
Training loss: 2.7963273525238037
Validation loss: 2.0989634003690494

Epoch: 6| Step: 2
Training loss: 2.0680289268493652
Validation loss: 2.0820439502757084

Epoch: 6| Step: 3
Training loss: 2.4296998977661133
Validation loss: 2.0898318162528415

Epoch: 6| Step: 4
Training loss: 2.0323543548583984
Validation loss: 2.076318412698725

Epoch: 6| Step: 5
Training loss: 2.5465919971466064
Validation loss: 2.064873844064692

Epoch: 6| Step: 6
Training loss: 2.6449079513549805
Validation loss: 2.0672625623723513

Epoch: 6| Step: 7
Training loss: 2.442934274673462
Validation loss: 2.0708297414164387

Epoch: 6| Step: 8
Training loss: 2.3357532024383545
Validation loss: 2.0771365678438576

Epoch: 6| Step: 9
Training loss: 2.0751657485961914
Validation loss: 2.081866484816356

Epoch: 6| Step: 10
Training loss: 2.2802677154541016
Validation loss: 2.1030853384284565

Epoch: 6| Step: 11
Training loss: 2.294461488723755
Validation loss: 2.108487585539459

Epoch: 6| Step: 12
Training loss: 2.988955497741699
Validation loss: 2.098075512916811

Epoch: 6| Step: 13
Training loss: 0.9769142866134644
Validation loss: 2.0834304658315514

Epoch: 101| Step: 0
Training loss: 1.9905496835708618
Validation loss: 2.0963355289992465

Epoch: 6| Step: 1
Training loss: 2.2704262733459473
Validation loss: 2.1150754677352084

Epoch: 6| Step: 2
Training loss: 2.4964969158172607
Validation loss: 2.1297548791413665

Epoch: 6| Step: 3
Training loss: 2.463552236557007
Validation loss: 2.1341580806239957

Epoch: 6| Step: 4
Training loss: 1.8385807275772095
Validation loss: 2.132435160298501

Epoch: 6| Step: 5
Training loss: 2.6039857864379883
Validation loss: 2.1395754327056227

Epoch: 6| Step: 6
Training loss: 2.2834420204162598
Validation loss: 2.131646938221429

Epoch: 6| Step: 7
Training loss: 2.9663963317871094
Validation loss: 2.1194448855615433

Epoch: 6| Step: 8
Training loss: 2.714364528656006
Validation loss: 2.1059510477127565

Epoch: 6| Step: 9
Training loss: 3.172623634338379
Validation loss: 2.1051266629208802

Epoch: 6| Step: 10
Training loss: 2.0130767822265625
Validation loss: 2.079596932216357

Epoch: 6| Step: 11
Training loss: 1.7784490585327148
Validation loss: 2.0712415197844147

Epoch: 6| Step: 12
Training loss: 1.7742724418640137
Validation loss: 2.0708431659206266

Epoch: 6| Step: 13
Training loss: 1.9722970724105835
Validation loss: 2.051995882423975

Epoch: 102| Step: 0
Training loss: 2.4863853454589844
Validation loss: 2.0515252467124694

Epoch: 6| Step: 1
Training loss: 2.1161704063415527
Validation loss: 2.0574915050178446

Epoch: 6| Step: 2
Training loss: 1.93488609790802
Validation loss: 2.054843515478155

Epoch: 6| Step: 3
Training loss: 2.1558780670166016
Validation loss: 2.06219204138684

Epoch: 6| Step: 4
Training loss: 2.8821306228637695
Validation loss: 2.0771021073864353

Epoch: 6| Step: 5
Training loss: 2.270413398742676
Validation loss: 2.118854381704843

Epoch: 6| Step: 6
Training loss: 1.972338080406189
Validation loss: 2.137087809142246

Epoch: 6| Step: 7
Training loss: 3.0754008293151855
Validation loss: 2.123382220986069

Epoch: 6| Step: 8
Training loss: 2.504441976547241
Validation loss: 2.1138602264465822

Epoch: 6| Step: 9
Training loss: 2.0458498001098633
Validation loss: 2.0893926979393087

Epoch: 6| Step: 10
Training loss: 1.3781299591064453
Validation loss: 2.094220804911788

Epoch: 6| Step: 11
Training loss: 2.4115493297576904
Validation loss: 2.1079743369933097

Epoch: 6| Step: 12
Training loss: 2.5356268882751465
Validation loss: 2.155207384017206

Epoch: 6| Step: 13
Training loss: 3.1403253078460693
Validation loss: 2.1693297381042154

Epoch: 103| Step: 0
Training loss: 2.7420883178710938
Validation loss: 2.2214141994394283

Epoch: 6| Step: 1
Training loss: 2.3344874382019043
Validation loss: 2.207383732641897

Epoch: 6| Step: 2
Training loss: 2.1956658363342285
Validation loss: 2.2158626407705326

Epoch: 6| Step: 3
Training loss: 2.569319248199463
Validation loss: 2.2285236158678607

Epoch: 6| Step: 4
Training loss: 2.721553325653076
Validation loss: 2.2785472177690074

Epoch: 6| Step: 5
Training loss: 3.344892978668213
Validation loss: 2.3299184563339397

Epoch: 6| Step: 6
Training loss: 2.2259926795959473
Validation loss: 2.271721834777504

Epoch: 6| Step: 7
Training loss: 2.760549545288086
Validation loss: 2.220856382000831

Epoch: 6| Step: 8
Training loss: 1.7690349817276
Validation loss: 2.1877736250559487

Epoch: 6| Step: 9
Training loss: 2.0394744873046875
Validation loss: 2.1357877305758897

Epoch: 6| Step: 10
Training loss: 2.040675640106201
Validation loss: 2.1147206649985364

Epoch: 6| Step: 11
Training loss: 2.00528883934021
Validation loss: 2.080257292716734

Epoch: 6| Step: 12
Training loss: 2.0483739376068115
Validation loss: 2.068004874772923

Epoch: 6| Step: 13
Training loss: 1.6932388544082642
Validation loss: 2.0635147992000786

Epoch: 104| Step: 0
Training loss: 2.545233726501465
Validation loss: 2.0701954339140203

Epoch: 6| Step: 1
Training loss: 2.8808326721191406
Validation loss: 2.0625735585407545

Epoch: 6| Step: 2
Training loss: 2.2430362701416016
Validation loss: 2.0457591549042733

Epoch: 6| Step: 3
Training loss: 2.1146459579467773
Validation loss: 2.0464750259153304

Epoch: 6| Step: 4
Training loss: 2.6585516929626465
Validation loss: 2.050852951183114

Epoch: 6| Step: 5
Training loss: 2.621527671813965
Validation loss: 2.038422397387925

Epoch: 6| Step: 6
Training loss: 1.9989250898361206
Validation loss: 2.0503982382435955

Epoch: 6| Step: 7
Training loss: 2.3037781715393066
Validation loss: 2.052356009842247

Epoch: 6| Step: 8
Training loss: 2.7555389404296875
Validation loss: 2.061089478513246

Epoch: 6| Step: 9
Training loss: 2.1057212352752686
Validation loss: 2.0766535215480353

Epoch: 6| Step: 10
Training loss: 1.4960649013519287
Validation loss: 2.078950430757256

Epoch: 6| Step: 11
Training loss: 2.456761360168457
Validation loss: 2.107309836213307

Epoch: 6| Step: 12
Training loss: 2.0213098526000977
Validation loss: 2.125378285684893

Epoch: 6| Step: 13
Training loss: 2.3306360244750977
Validation loss: 2.1243491352245374

Epoch: 105| Step: 0
Training loss: 2.477104663848877
Validation loss: 2.1273471770748014

Epoch: 6| Step: 1
Training loss: 2.138629913330078
Validation loss: 2.0951368667746104

Epoch: 6| Step: 2
Training loss: 2.3042399883270264
Validation loss: 2.0725475024151545

Epoch: 6| Step: 3
Training loss: 2.975243091583252
Validation loss: 2.0680553708025204

Epoch: 6| Step: 4
Training loss: 1.328676700592041
Validation loss: 2.0682397875734555

Epoch: 6| Step: 5
Training loss: 2.078339099884033
Validation loss: 2.0532436704122894

Epoch: 6| Step: 6
Training loss: 2.121279239654541
Validation loss: 2.056344582188514

Epoch: 6| Step: 7
Training loss: 1.8579223155975342
Validation loss: 2.064592276850054

Epoch: 6| Step: 8
Training loss: 2.4988059997558594
Validation loss: 2.0726438312120337

Epoch: 6| Step: 9
Training loss: 2.8035812377929688
Validation loss: 2.054812656935825

Epoch: 6| Step: 10
Training loss: 2.1793434619903564
Validation loss: 2.044642425352527

Epoch: 6| Step: 11
Training loss: 2.254342555999756
Validation loss: 2.044522677698443

Epoch: 6| Step: 12
Training loss: 2.5743308067321777
Validation loss: 2.0460005575610745

Epoch: 6| Step: 13
Training loss: 2.866861343383789
Validation loss: 2.0491826790635304

Epoch: 106| Step: 0
Training loss: 1.8751498460769653
Validation loss: 2.0664609170729116

Epoch: 6| Step: 1
Training loss: 2.5379762649536133
Validation loss: 2.0829249107709495

Epoch: 6| Step: 2
Training loss: 2.5334367752075195
Validation loss: 2.0827883994707497

Epoch: 6| Step: 3
Training loss: 2.3223860263824463
Validation loss: 2.102378172259177

Epoch: 6| Step: 4
Training loss: 2.6951658725738525
Validation loss: 2.1061693494037916

Epoch: 6| Step: 5
Training loss: 1.99248468875885
Validation loss: 2.1117270505556496

Epoch: 6| Step: 6
Training loss: 2.378612518310547
Validation loss: 2.1008410607614825

Epoch: 6| Step: 7
Training loss: 1.5076119899749756
Validation loss: 2.086791851187265

Epoch: 6| Step: 8
Training loss: 1.8863016366958618
Validation loss: 2.0808622772975633

Epoch: 6| Step: 9
Training loss: 2.6842212677001953
Validation loss: 2.084377181145453

Epoch: 6| Step: 10
Training loss: 1.959303855895996
Validation loss: 2.088643476527224

Epoch: 6| Step: 11
Training loss: 2.7424473762512207
Validation loss: 2.0875196713273243

Epoch: 6| Step: 12
Training loss: 2.1942615509033203
Validation loss: 2.0899692350818264

Epoch: 6| Step: 13
Training loss: 2.7258100509643555
Validation loss: 2.0934675714021087

Epoch: 107| Step: 0
Training loss: 2.6559410095214844
Validation loss: 2.092012233631585

Epoch: 6| Step: 1
Training loss: 1.8706953525543213
Validation loss: 2.111711302111226

Epoch: 6| Step: 2
Training loss: 3.2517383098602295
Validation loss: 2.134779933960207

Epoch: 6| Step: 3
Training loss: 2.5592970848083496
Validation loss: 2.1692181248818674

Epoch: 6| Step: 4
Training loss: 2.4146547317504883
Validation loss: 2.169078180866857

Epoch: 6| Step: 5
Training loss: 2.7867658138275146
Validation loss: 2.173270212706699

Epoch: 6| Step: 6
Training loss: 1.7672057151794434
Validation loss: 2.1236671811790875

Epoch: 6| Step: 7
Training loss: 2.1161539554595947
Validation loss: 2.0903861830311437

Epoch: 6| Step: 8
Training loss: 2.545832633972168
Validation loss: 2.0753532045631

Epoch: 6| Step: 9
Training loss: 2.1665029525756836
Validation loss: 2.070489784722687

Epoch: 6| Step: 10
Training loss: 1.9037632942199707
Validation loss: 2.0575405397722797

Epoch: 6| Step: 11
Training loss: 2.234210968017578
Validation loss: 2.045241673787435

Epoch: 6| Step: 12
Training loss: 1.7217803001403809
Validation loss: 2.049871413938461

Epoch: 6| Step: 13
Training loss: 1.419348120689392
Validation loss: 2.046131113524078

Epoch: 108| Step: 0
Training loss: 2.255124092102051
Validation loss: 2.056451374484647

Epoch: 6| Step: 1
Training loss: 2.3779852390289307
Validation loss: 2.067223351488831

Epoch: 6| Step: 2
Training loss: 2.195857048034668
Validation loss: 2.0912832444713962

Epoch: 6| Step: 3
Training loss: 2.929375410079956
Validation loss: 2.1026853592165056

Epoch: 6| Step: 4
Training loss: 2.311872720718384
Validation loss: 2.124661466126801

Epoch: 6| Step: 5
Training loss: 1.631496548652649
Validation loss: 2.1171410724680912

Epoch: 6| Step: 6
Training loss: 2.709873676300049
Validation loss: 2.1267435114870787

Epoch: 6| Step: 7
Training loss: 2.212599039077759
Validation loss: 2.143945311987272

Epoch: 6| Step: 8
Training loss: 2.262831211090088
Validation loss: 2.14203300527347

Epoch: 6| Step: 9
Training loss: 1.8991345167160034
Validation loss: 2.124432235635737

Epoch: 6| Step: 10
Training loss: 1.934949517250061
Validation loss: 2.0984851211629887

Epoch: 6| Step: 11
Training loss: 2.2597172260284424
Validation loss: 2.0911865170283983

Epoch: 6| Step: 12
Training loss: 2.7993111610412598
Validation loss: 2.0852771728269515

Epoch: 6| Step: 13
Training loss: 2.489607572555542
Validation loss: 2.066147123613665

Epoch: 109| Step: 0
Training loss: 2.8330647945404053
Validation loss: 2.0762675757049234

Epoch: 6| Step: 1
Training loss: 2.370232582092285
Validation loss: 2.0677525561342955

Epoch: 6| Step: 2
Training loss: 2.0622410774230957
Validation loss: 2.068432084975704

Epoch: 6| Step: 3
Training loss: 2.3924264907836914
Validation loss: 2.073450582001799

Epoch: 6| Step: 4
Training loss: 1.814990758895874
Validation loss: 2.0688048062785978

Epoch: 6| Step: 5
Training loss: 2.019683599472046
Validation loss: 2.0869351715169926

Epoch: 6| Step: 6
Training loss: 2.9990625381469727
Validation loss: 2.0734174764284523

Epoch: 6| Step: 7
Training loss: 1.6398128271102905
Validation loss: 2.069645579143237

Epoch: 6| Step: 8
Training loss: 1.7796638011932373
Validation loss: 2.0824213899591917

Epoch: 6| Step: 9
Training loss: 2.6500866413116455
Validation loss: 2.078794197369647

Epoch: 6| Step: 10
Training loss: 2.678619384765625
Validation loss: 2.058281034551641

Epoch: 6| Step: 11
Training loss: 2.035311460494995
Validation loss: 2.054185236653974

Epoch: 6| Step: 12
Training loss: 2.004577159881592
Validation loss: 2.055604504000756

Epoch: 6| Step: 13
Training loss: 1.7913856506347656
Validation loss: 2.0584923169946157

Epoch: 110| Step: 0
Training loss: 2.5178980827331543
Validation loss: 2.0759245734060965

Epoch: 6| Step: 1
Training loss: 2.091689109802246
Validation loss: 2.070630096620129

Epoch: 6| Step: 2
Training loss: 1.9971667528152466
Validation loss: 2.081402055678829

Epoch: 6| Step: 3
Training loss: 2.350606918334961
Validation loss: 2.098101121123119

Epoch: 6| Step: 4
Training loss: 1.806378960609436
Validation loss: 2.0821565402451383

Epoch: 6| Step: 5
Training loss: 2.4220633506774902
Validation loss: 2.090359613459597

Epoch: 6| Step: 6
Training loss: 1.621382236480713
Validation loss: 2.0749142862135366

Epoch: 6| Step: 7
Training loss: 1.5009928941726685
Validation loss: 2.070841239344689

Epoch: 6| Step: 8
Training loss: 1.6842377185821533
Validation loss: 2.070266840278461

Epoch: 6| Step: 9
Training loss: 2.8054120540618896
Validation loss: 2.0569610544430312

Epoch: 6| Step: 10
Training loss: 2.3105084896087646
Validation loss: 2.0551446612163256

Epoch: 6| Step: 11
Training loss: 2.333909273147583
Validation loss: 2.060704695281162

Epoch: 6| Step: 12
Training loss: 2.9261467456817627
Validation loss: 2.0568390982125395

Epoch: 6| Step: 13
Training loss: 2.8666250705718994
Validation loss: 2.0675265481395106

Epoch: 111| Step: 0
Training loss: 2.1812539100646973
Validation loss: 2.062016829367607

Epoch: 6| Step: 1
Training loss: 3.004434585571289
Validation loss: 2.0594444121083906

Epoch: 6| Step: 2
Training loss: 1.5455937385559082
Validation loss: 2.0643879213640766

Epoch: 6| Step: 3
Training loss: 1.5442203283309937
Validation loss: 2.047328326009935

Epoch: 6| Step: 4
Training loss: 1.987415075302124
Validation loss: 2.045968755598991

Epoch: 6| Step: 5
Training loss: 1.3401587009429932
Validation loss: 2.0496620619168846

Epoch: 6| Step: 6
Training loss: 2.884011745452881
Validation loss: 2.0794866213234524

Epoch: 6| Step: 7
Training loss: 2.37509822845459
Validation loss: 2.111750025903025

Epoch: 6| Step: 8
Training loss: 2.600687026977539
Validation loss: 2.139615361408521

Epoch: 6| Step: 9
Training loss: 2.8530540466308594
Validation loss: 2.1559891085470877

Epoch: 6| Step: 10
Training loss: 1.835105061531067
Validation loss: 2.1699489214087047

Epoch: 6| Step: 11
Training loss: 2.6011714935302734
Validation loss: 2.1574158412154003

Epoch: 6| Step: 12
Training loss: 2.1318347454071045
Validation loss: 2.1402511391588437

Epoch: 6| Step: 13
Training loss: 3.039318084716797
Validation loss: 2.1061917274228987

Epoch: 112| Step: 0
Training loss: 2.438152313232422
Validation loss: 2.078149676322937

Epoch: 6| Step: 1
Training loss: 2.0855672359466553
Validation loss: 2.072101823745235

Epoch: 6| Step: 2
Training loss: 1.7736704349517822
Validation loss: 2.0772064039784093

Epoch: 6| Step: 3
Training loss: 1.886285424232483
Validation loss: 2.060046920212366

Epoch: 6| Step: 4
Training loss: 2.5338315963745117
Validation loss: 2.0625480400618685

Epoch: 6| Step: 5
Training loss: 2.482455015182495
Validation loss: 2.0697483349871892

Epoch: 6| Step: 6
Training loss: 1.7878873348236084
Validation loss: 2.092342927891721

Epoch: 6| Step: 7
Training loss: 2.1615519523620605
Validation loss: 2.13949982325236

Epoch: 6| Step: 8
Training loss: 2.4117431640625
Validation loss: 2.198267900815574

Epoch: 6| Step: 9
Training loss: 2.1047310829162598
Validation loss: 2.2055902250351442

Epoch: 6| Step: 10
Training loss: 2.7007884979248047
Validation loss: 2.189132607111367

Epoch: 6| Step: 11
Training loss: 1.6184574365615845
Validation loss: 2.1457275664934548

Epoch: 6| Step: 12
Training loss: 2.247124433517456
Validation loss: 2.130208794788648

Epoch: 6| Step: 13
Training loss: 3.076176881790161
Validation loss: 2.1214349974868116

Epoch: 113| Step: 0
Training loss: 2.0415825843811035
Validation loss: 2.117061176607686

Epoch: 6| Step: 1
Training loss: 1.7045745849609375
Validation loss: 2.126537069197624

Epoch: 6| Step: 2
Training loss: 1.7076854705810547
Validation loss: 2.1149262741047847

Epoch: 6| Step: 3
Training loss: 2.2744851112365723
Validation loss: 2.109435824937718

Epoch: 6| Step: 4
Training loss: 2.1431007385253906
Validation loss: 2.108574516029768

Epoch: 6| Step: 5
Training loss: 2.417174816131592
Validation loss: 2.0773863600146387

Epoch: 6| Step: 6
Training loss: 2.4810781478881836
Validation loss: 2.068310183863486

Epoch: 6| Step: 7
Training loss: 2.408489942550659
Validation loss: 2.074166128712316

Epoch: 6| Step: 8
Training loss: 2.9146270751953125
Validation loss: 2.060182508601937

Epoch: 6| Step: 9
Training loss: 3.4113073348999023
Validation loss: 2.0719465222409976

Epoch: 6| Step: 10
Training loss: 2.0200893878936768
Validation loss: 2.0918244443913943

Epoch: 6| Step: 11
Training loss: 1.7217183113098145
Validation loss: 2.082154470105325

Epoch: 6| Step: 12
Training loss: 1.9123255014419556
Validation loss: 2.103510646409886

Epoch: 6| Step: 13
Training loss: 2.0415291786193848
Validation loss: 2.1148076813708068

Epoch: 114| Step: 0
Training loss: 1.9178342819213867
Validation loss: 2.0908766126119964

Epoch: 6| Step: 1
Training loss: 2.625058650970459
Validation loss: 2.076558259225661

Epoch: 6| Step: 2
Training loss: 1.8818957805633545
Validation loss: 2.080115387516637

Epoch: 6| Step: 3
Training loss: 2.1072168350219727
Validation loss: 2.068728616160731

Epoch: 6| Step: 4
Training loss: 1.6961963176727295
Validation loss: 2.085202947739632

Epoch: 6| Step: 5
Training loss: 2.29032564163208
Validation loss: 2.1226055801555677

Epoch: 6| Step: 6
Training loss: 2.4130420684814453
Validation loss: 2.1504259827316448

Epoch: 6| Step: 7
Training loss: 2.6921157836914062
Validation loss: 2.1473034735648864

Epoch: 6| Step: 8
Training loss: 2.419312000274658
Validation loss: 2.1448705170744207

Epoch: 6| Step: 9
Training loss: 2.071382999420166
Validation loss: 2.1331357520113707

Epoch: 6| Step: 10
Training loss: 2.048271656036377
Validation loss: 2.1016463054123746

Epoch: 6| Step: 11
Training loss: 2.407461643218994
Validation loss: 2.0903226406343522

Epoch: 6| Step: 12
Training loss: 1.990098476409912
Validation loss: 2.0775441033865816

Epoch: 6| Step: 13
Training loss: 2.45660138130188
Validation loss: 2.0786752521350818

Epoch: 115| Step: 0
Training loss: 2.416693687438965
Validation loss: 2.062356331015146

Epoch: 6| Step: 1
Training loss: 2.414289951324463
Validation loss: 2.0456032214626187

Epoch: 6| Step: 2
Training loss: 1.4797208309173584
Validation loss: 2.0477186710603776

Epoch: 6| Step: 3
Training loss: 1.9311209917068481
Validation loss: 2.04956712261323

Epoch: 6| Step: 4
Training loss: 2.4672274589538574
Validation loss: 2.0647817375839397

Epoch: 6| Step: 5
Training loss: 1.9637069702148438
Validation loss: 2.0652745231505363

Epoch: 6| Step: 6
Training loss: 2.7988462448120117
Validation loss: 2.0604724858396795

Epoch: 6| Step: 7
Training loss: 1.967020034790039
Validation loss: 2.0582721297458937

Epoch: 6| Step: 8
Training loss: 2.3341598510742188
Validation loss: 2.0437589973531742

Epoch: 6| Step: 9
Training loss: 2.3126869201660156
Validation loss: 2.0520828949507846

Epoch: 6| Step: 10
Training loss: 2.0831494331359863
Validation loss: 2.0630156711865495

Epoch: 6| Step: 11
Training loss: 1.8844666481018066
Validation loss: 2.05115762577262

Epoch: 6| Step: 12
Training loss: 2.342880964279175
Validation loss: 2.080580980547013

Epoch: 6| Step: 13
Training loss: 1.9131137132644653
Validation loss: 2.0820509874692528

Epoch: 116| Step: 0
Training loss: 2.398015022277832
Validation loss: 2.0791791587747555

Epoch: 6| Step: 1
Training loss: 2.577597141265869
Validation loss: 2.1012193849009853

Epoch: 6| Step: 2
Training loss: 1.9825763702392578
Validation loss: 2.1041686022153465

Epoch: 6| Step: 3
Training loss: 1.512672781944275
Validation loss: 2.114921530087789

Epoch: 6| Step: 4
Training loss: 2.37384033203125
Validation loss: 2.0992740482412358

Epoch: 6| Step: 5
Training loss: 2.158064126968384
Validation loss: 2.0901946252392185

Epoch: 6| Step: 6
Training loss: 2.1510074138641357
Validation loss: 2.0748997836984615

Epoch: 6| Step: 7
Training loss: 2.064908504486084
Validation loss: 2.0878891739794003

Epoch: 6| Step: 8
Training loss: 1.2670600414276123
Validation loss: 2.0680266336728166

Epoch: 6| Step: 9
Training loss: 1.9863144159317017
Validation loss: 2.080349155651626

Epoch: 6| Step: 10
Training loss: 2.1577329635620117
Validation loss: 2.0653729464418147

Epoch: 6| Step: 11
Training loss: 2.4349992275238037
Validation loss: 2.057339758001348

Epoch: 6| Step: 12
Training loss: 2.854788303375244
Validation loss: 2.0420263223750617

Epoch: 6| Step: 13
Training loss: 2.0088717937469482
Validation loss: 2.027462161997313

Epoch: 117| Step: 0
Training loss: 2.4156293869018555
Validation loss: 2.042948845894106

Epoch: 6| Step: 1
Training loss: 1.8811852931976318
Validation loss: 2.0440408132409535

Epoch: 6| Step: 2
Training loss: 2.0854263305664062
Validation loss: 2.0534861985073296

Epoch: 6| Step: 3
Training loss: 2.2698330879211426
Validation loss: 2.065965252537881

Epoch: 6| Step: 4
Training loss: 2.192563772201538
Validation loss: 2.077889709062474

Epoch: 6| Step: 5
Training loss: 2.106337547302246
Validation loss: 2.0833650865862445

Epoch: 6| Step: 6
Training loss: 2.152329921722412
Validation loss: 2.075895478648524

Epoch: 6| Step: 7
Training loss: 2.311323642730713
Validation loss: 2.083548069000244

Epoch: 6| Step: 8
Training loss: 1.5068104267120361
Validation loss: 2.092546501467305

Epoch: 6| Step: 9
Training loss: 1.6287380456924438
Validation loss: 2.0998983075541835

Epoch: 6| Step: 10
Training loss: 2.6415185928344727
Validation loss: 2.095031205043998

Epoch: 6| Step: 11
Training loss: 2.194166421890259
Validation loss: 2.1010207386427027

Epoch: 6| Step: 12
Training loss: 1.8926870822906494
Validation loss: 2.1007070285017773

Epoch: 6| Step: 13
Training loss: 2.711787462234497
Validation loss: 2.107397505032119

Epoch: 118| Step: 0
Training loss: 2.6908998489379883
Validation loss: 2.124467998422602

Epoch: 6| Step: 1
Training loss: 1.8423863649368286
Validation loss: 2.081805270205262

Epoch: 6| Step: 2
Training loss: 1.9022071361541748
Validation loss: 2.086102565129598

Epoch: 6| Step: 3
Training loss: 2.440575122833252
Validation loss: 2.087187856756231

Epoch: 6| Step: 4
Training loss: 1.8027535676956177
Validation loss: 2.0926447991401917

Epoch: 6| Step: 5
Training loss: 1.7995491027832031
Validation loss: 2.087314404467101

Epoch: 6| Step: 6
Training loss: 2.0603444576263428
Validation loss: 2.067966849573197

Epoch: 6| Step: 7
Training loss: 2.6480674743652344
Validation loss: 2.0821724348170783

Epoch: 6| Step: 8
Training loss: 3.121062994003296
Validation loss: 2.071817962072229

Epoch: 6| Step: 9
Training loss: 1.6898324489593506
Validation loss: 2.0874387897470945

Epoch: 6| Step: 10
Training loss: 2.0643343925476074
Validation loss: 2.10391515685666

Epoch: 6| Step: 11
Training loss: 2.04753041267395
Validation loss: 2.121561047851398

Epoch: 6| Step: 12
Training loss: 1.7880723476409912
Validation loss: 2.0988385882428897

Epoch: 6| Step: 13
Training loss: 1.5862669944763184
Validation loss: 2.107884833889623

Epoch: 119| Step: 0
Training loss: 1.8344173431396484
Validation loss: 2.1082111109969435

Epoch: 6| Step: 1
Training loss: 1.688575267791748
Validation loss: 2.116489698809962

Epoch: 6| Step: 2
Training loss: 2.3831639289855957
Validation loss: 2.1209150463022213

Epoch: 6| Step: 3
Training loss: 1.915313720703125
Validation loss: 2.1153005066738335

Epoch: 6| Step: 4
Training loss: 2.2569029331207275
Validation loss: 2.1140477388135848

Epoch: 6| Step: 5
Training loss: 2.449838161468506
Validation loss: 2.130459016369235

Epoch: 6| Step: 6
Training loss: 1.5085923671722412
Validation loss: 2.1408810282266266

Epoch: 6| Step: 7
Training loss: 2.431636333465576
Validation loss: 2.17633419652139

Epoch: 6| Step: 8
Training loss: 2.372103691101074
Validation loss: 2.1894002050481816

Epoch: 6| Step: 9
Training loss: 2.31294322013855
Validation loss: 2.195888841024009

Epoch: 6| Step: 10
Training loss: 1.7701609134674072
Validation loss: 2.157151452956661

Epoch: 6| Step: 11
Training loss: 1.9956707954406738
Validation loss: 2.1304812815881546

Epoch: 6| Step: 12
Training loss: 2.1029043197631836
Validation loss: 2.091980239396454

Epoch: 6| Step: 13
Training loss: 2.4689626693725586
Validation loss: 2.0897379818783013

Epoch: 120| Step: 0
Training loss: 2.3145546913146973
Validation loss: 2.0868022723864486

Epoch: 6| Step: 1
Training loss: 2.106254816055298
Validation loss: 2.0915204735212427

Epoch: 6| Step: 2
Training loss: 2.245349407196045
Validation loss: 2.089599791393485

Epoch: 6| Step: 3
Training loss: 2.1663308143615723
Validation loss: 2.087137838845612

Epoch: 6| Step: 4
Training loss: 2.3692169189453125
Validation loss: 2.0905958747351043

Epoch: 6| Step: 5
Training loss: 2.2086572647094727
Validation loss: 2.080409549897717

Epoch: 6| Step: 6
Training loss: 2.6858601570129395
Validation loss: 2.077977139462707

Epoch: 6| Step: 7
Training loss: 1.9198060035705566
Validation loss: 2.0763891332892963

Epoch: 6| Step: 8
Training loss: 2.6307737827301025
Validation loss: 2.0687636765100623

Epoch: 6| Step: 9
Training loss: 2.1783647537231445
Validation loss: 2.087631424268087

Epoch: 6| Step: 10
Training loss: 1.6471998691558838
Validation loss: 2.0910271406173706

Epoch: 6| Step: 11
Training loss: 1.683396816253662
Validation loss: 2.088895285001365

Epoch: 6| Step: 12
Training loss: 1.3697378635406494
Validation loss: 2.09201693278487

Epoch: 6| Step: 13
Training loss: 1.6899182796478271
Validation loss: 2.0981987189221125

Epoch: 121| Step: 0
Training loss: 2.367049217224121
Validation loss: 2.1010902491948937

Epoch: 6| Step: 1
Training loss: 2.4948911666870117
Validation loss: 2.096622713150517

Epoch: 6| Step: 2
Training loss: 2.2612805366516113
Validation loss: 2.103019872019368

Epoch: 6| Step: 3
Training loss: 1.781690239906311
Validation loss: 2.1236180259335424

Epoch: 6| Step: 4
Training loss: 1.5833643674850464
Validation loss: 2.14847061967337

Epoch: 6| Step: 5
Training loss: 2.4403533935546875
Validation loss: 2.1756496326897734

Epoch: 6| Step: 6
Training loss: 1.9439054727554321
Validation loss: 2.1814183753023864

Epoch: 6| Step: 7
Training loss: 2.4527316093444824
Validation loss: 2.196817692889962

Epoch: 6| Step: 8
Training loss: 2.2553675174713135
Validation loss: 2.18425666388645

Epoch: 6| Step: 9
Training loss: 1.7989778518676758
Validation loss: 2.164616541195941

Epoch: 6| Step: 10
Training loss: 1.9545342922210693
Validation loss: 2.1605916612891742

Epoch: 6| Step: 11
Training loss: 2.126023292541504
Validation loss: 2.131980352504279

Epoch: 6| Step: 12
Training loss: 2.1864161491394043
Validation loss: 2.1303307881919284

Epoch: 6| Step: 13
Training loss: 0.9417961835861206
Validation loss: 2.0963442056409773

Epoch: 122| Step: 0
Training loss: 1.9061179161071777
Validation loss: 2.0851390951423237

Epoch: 6| Step: 1
Training loss: 2.032142162322998
Validation loss: 2.093582453266267

Epoch: 6| Step: 2
Training loss: 2.0519306659698486
Validation loss: 2.115779164016888

Epoch: 6| Step: 3
Training loss: 2.131758213043213
Validation loss: 2.140489834611134

Epoch: 6| Step: 4
Training loss: 2.3143131732940674
Validation loss: 2.194701102472121

Epoch: 6| Step: 5
Training loss: 3.0633015632629395
Validation loss: 2.210330834952734

Epoch: 6| Step: 6
Training loss: 3.04555344581604
Validation loss: 2.227172590071155

Epoch: 6| Step: 7
Training loss: 2.30653715133667
Validation loss: 2.2104117357602684

Epoch: 6| Step: 8
Training loss: 1.8399955034255981
Validation loss: 2.1563173417122132

Epoch: 6| Step: 9
Training loss: 1.5971121788024902
Validation loss: 2.117737700862269

Epoch: 6| Step: 10
Training loss: 2.113280773162842
Validation loss: 2.0967143094667824

Epoch: 6| Step: 11
Training loss: 1.252632975578308
Validation loss: 2.08599074937964

Epoch: 6| Step: 12
Training loss: 1.882999300956726
Validation loss: 2.060163273606249

Epoch: 6| Step: 13
Training loss: 1.7872545719146729
Validation loss: 2.062741953839538

Epoch: 123| Step: 0
Training loss: 1.6124135255813599
Validation loss: 2.088095700868996

Epoch: 6| Step: 1
Training loss: 1.5046000480651855
Validation loss: 2.112455403932961

Epoch: 6| Step: 2
Training loss: 2.2064528465270996
Validation loss: 2.145229912573291

Epoch: 6| Step: 3
Training loss: 2.347283363342285
Validation loss: 2.183895395648095

Epoch: 6| Step: 4
Training loss: 2.078645944595337
Validation loss: 2.2006389633301766

Epoch: 6| Step: 5
Training loss: 2.153972864151001
Validation loss: 2.2013510683531403

Epoch: 6| Step: 6
Training loss: 1.9653913974761963
Validation loss: 2.1771926854246404

Epoch: 6| Step: 7
Training loss: 1.8660461902618408
Validation loss: 2.1498283006811656

Epoch: 6| Step: 8
Training loss: 2.241680145263672
Validation loss: 2.139169195646881

Epoch: 6| Step: 9
Training loss: 1.258884072303772
Validation loss: 2.1400677696351083

Epoch: 6| Step: 10
Training loss: 2.6604247093200684
Validation loss: 2.163202929240401

Epoch: 6| Step: 11
Training loss: 2.847929000854492
Validation loss: 2.1893587266245196

Epoch: 6| Step: 12
Training loss: 2.290029525756836
Validation loss: 2.2021366268075924

Epoch: 6| Step: 13
Training loss: 2.3537280559539795
Validation loss: 2.193936760707568

Epoch: 124| Step: 0
Training loss: 1.9526771306991577
Validation loss: 2.1986597379048667

Epoch: 6| Step: 1
Training loss: 1.3862814903259277
Validation loss: 2.214914475717852

Epoch: 6| Step: 2
Training loss: 2.6246891021728516
Validation loss: 2.2037353900171097

Epoch: 6| Step: 3
Training loss: 2.241593837738037
Validation loss: 2.223745520396899

Epoch: 6| Step: 4
Training loss: 2.4858155250549316
Validation loss: 2.2145983442183463

Epoch: 6| Step: 5
Training loss: 2.5220251083374023
Validation loss: 2.147380559675155

Epoch: 6| Step: 6
Training loss: 2.026822328567505
Validation loss: 2.094842167310817

Epoch: 6| Step: 7
Training loss: 1.752319097518921
Validation loss: 2.074415132563601

Epoch: 6| Step: 8
Training loss: 2.241530418395996
Validation loss: 2.0821449102893954

Epoch: 6| Step: 9
Training loss: 1.955376148223877
Validation loss: 2.104839955606768

Epoch: 6| Step: 10
Training loss: 2.201343059539795
Validation loss: 2.1415090330185427

Epoch: 6| Step: 11
Training loss: 2.53043794631958
Validation loss: 2.160197655359904

Epoch: 6| Step: 12
Training loss: 1.3960192203521729
Validation loss: 2.168929628146592

Epoch: 6| Step: 13
Training loss: 2.673311948776245
Validation loss: 2.1656610145363757

Epoch: 125| Step: 0
Training loss: 2.265178680419922
Validation loss: 2.1568453491375013

Epoch: 6| Step: 1
Training loss: 2.272200345993042
Validation loss: 2.1402228442571496

Epoch: 6| Step: 2
Training loss: 2.5556957721710205
Validation loss: 2.134553978520055

Epoch: 6| Step: 3
Training loss: 1.5779614448547363
Validation loss: 2.1428899188195505

Epoch: 6| Step: 4
Training loss: 2.5291731357574463
Validation loss: 2.148407613077471

Epoch: 6| Step: 5
Training loss: 1.784816026687622
Validation loss: 2.1481319781272643

Epoch: 6| Step: 6
Training loss: 1.376784324645996
Validation loss: 2.145803687393024

Epoch: 6| Step: 7
Training loss: 2.5838143825531006
Validation loss: 2.137508176988171

Epoch: 6| Step: 8
Training loss: 1.5471384525299072
Validation loss: 2.1303890546162925

Epoch: 6| Step: 9
Training loss: 1.679147720336914
Validation loss: 2.134249464158089

Epoch: 6| Step: 10
Training loss: 1.5713623762130737
Validation loss: 2.1343420756760465

Epoch: 6| Step: 11
Training loss: 3.025521755218506
Validation loss: 2.1267599777508805

Epoch: 6| Step: 12
Training loss: 2.3714003562927246
Validation loss: 2.1027409902182956

Epoch: 6| Step: 13
Training loss: 1.9978671073913574
Validation loss: 2.091084111121393

Epoch: 126| Step: 0
Training loss: 2.0622427463531494
Validation loss: 2.086808116205277

Epoch: 6| Step: 1
Training loss: 2.242316722869873
Validation loss: 2.0979353356105026

Epoch: 6| Step: 2
Training loss: 1.6026027202606201
Validation loss: 2.096033247568274

Epoch: 6| Step: 3
Training loss: 1.9430644512176514
Validation loss: 2.0806807215495775

Epoch: 6| Step: 4
Training loss: 2.0364983081817627
Validation loss: 2.0789109045459377

Epoch: 6| Step: 5
Training loss: 2.5127642154693604
Validation loss: 2.0835958655162523

Epoch: 6| Step: 6
Training loss: 2.320728302001953
Validation loss: 2.088160619940809

Epoch: 6| Step: 7
Training loss: 1.714817762374878
Validation loss: 2.073366726598432

Epoch: 6| Step: 8
Training loss: 1.9238643646240234
Validation loss: 2.0713851272418933

Epoch: 6| Step: 9
Training loss: 1.6827170848846436
Validation loss: 2.071959800617669

Epoch: 6| Step: 10
Training loss: 2.0264227390289307
Validation loss: 2.0597791928116993

Epoch: 6| Step: 11
Training loss: 1.9244012832641602
Validation loss: 2.0467914406971266

Epoch: 6| Step: 12
Training loss: 2.045391082763672
Validation loss: 2.0572498434333393

Epoch: 6| Step: 13
Training loss: 2.796200752258301
Validation loss: 2.0523487675574517

Epoch: 127| Step: 0
Training loss: 2.062983274459839
Validation loss: 2.052178409791762

Epoch: 6| Step: 1
Training loss: 1.554429531097412
Validation loss: 2.0579524065858577

Epoch: 6| Step: 2
Training loss: 2.533045768737793
Validation loss: 2.044060246918791

Epoch: 6| Step: 3
Training loss: 2.333437919616699
Validation loss: 2.050148215345157

Epoch: 6| Step: 4
Training loss: 1.941263198852539
Validation loss: 2.0555233083745486

Epoch: 6| Step: 5
Training loss: 1.317025899887085
Validation loss: 2.0815337319527902

Epoch: 6| Step: 6
Training loss: 1.7276973724365234
Validation loss: 2.102335217178509

Epoch: 6| Step: 7
Training loss: 1.6089258193969727
Validation loss: 2.11266230511409

Epoch: 6| Step: 8
Training loss: 2.752614736557007
Validation loss: 2.1362049553983953

Epoch: 6| Step: 9
Training loss: 1.806872844696045
Validation loss: 2.148923735464773

Epoch: 6| Step: 10
Training loss: 2.4526185989379883
Validation loss: 2.1508190913866927

Epoch: 6| Step: 11
Training loss: 2.4659016132354736
Validation loss: 2.147660042649956

Epoch: 6| Step: 12
Training loss: 1.8014106750488281
Validation loss: 2.1295456322290565

Epoch: 6| Step: 13
Training loss: 1.6709355115890503
Validation loss: 2.144353202594224

Epoch: 128| Step: 0
Training loss: 2.2240612506866455
Validation loss: 2.1306407759266515

Epoch: 6| Step: 1
Training loss: 1.9664967060089111
Validation loss: 2.125637400534845

Epoch: 6| Step: 2
Training loss: 1.8290594816207886
Validation loss: 2.1086962581962667

Epoch: 6| Step: 3
Training loss: 2.065732002258301
Validation loss: 2.112216716171593

Epoch: 6| Step: 4
Training loss: 1.7878797054290771
Validation loss: 2.136749941815612

Epoch: 6| Step: 5
Training loss: 1.998900055885315
Validation loss: 2.1302461495963474

Epoch: 6| Step: 6
Training loss: 1.7477562427520752
Validation loss: 2.107744604028681

Epoch: 6| Step: 7
Training loss: 2.1376590728759766
Validation loss: 2.0902755798832064

Epoch: 6| Step: 8
Training loss: 2.4986376762390137
Validation loss: 2.083959069303287

Epoch: 6| Step: 9
Training loss: 1.675241231918335
Validation loss: 2.0895809024892826

Epoch: 6| Step: 10
Training loss: 2.2909035682678223
Validation loss: 2.126216034735403

Epoch: 6| Step: 11
Training loss: 2.527409791946411
Validation loss: 2.130315890876196

Epoch: 6| Step: 12
Training loss: 1.5107128620147705
Validation loss: 2.142491784147037

Epoch: 6| Step: 13
Training loss: 1.331447720527649
Validation loss: 2.145121750011239

Epoch: 129| Step: 0
Training loss: 2.040919303894043
Validation loss: 2.1327235980700423

Epoch: 6| Step: 1
Training loss: 2.283811330795288
Validation loss: 2.132686117643951

Epoch: 6| Step: 2
Training loss: 2.2187905311584473
Validation loss: 2.1450632208137104

Epoch: 6| Step: 3
Training loss: 1.8241794109344482
Validation loss: 2.1286924551892024

Epoch: 6| Step: 4
Training loss: 1.6257236003875732
Validation loss: 2.130083965998824

Epoch: 6| Step: 5
Training loss: 1.416388750076294
Validation loss: 2.1082061567614154

Epoch: 6| Step: 6
Training loss: 1.7702689170837402
Validation loss: 2.0778606912141204

Epoch: 6| Step: 7
Training loss: 2.0856986045837402
Validation loss: 2.0805095370097826

Epoch: 6| Step: 8
Training loss: 1.7320556640625
Validation loss: 2.08455724998187

Epoch: 6| Step: 9
Training loss: 1.8840041160583496
Validation loss: 2.0852186987476964

Epoch: 6| Step: 10
Training loss: 1.9584013223648071
Validation loss: 2.083586058309001

Epoch: 6| Step: 11
Training loss: 2.269219160079956
Validation loss: 2.096505715001014

Epoch: 6| Step: 12
Training loss: 2.72770357131958
Validation loss: 2.0906751976218274

Epoch: 6| Step: 13
Training loss: 1.8056381940841675
Validation loss: 2.1157548658309446

Epoch: 130| Step: 0
Training loss: 1.8068183660507202
Validation loss: 2.1373775723159953

Epoch: 6| Step: 1
Training loss: 1.9050865173339844
Validation loss: 2.146184489291201

Epoch: 6| Step: 2
Training loss: 1.7818589210510254
Validation loss: 2.165657438257689

Epoch: 6| Step: 3
Training loss: 2.0544493198394775
Validation loss: 2.1901326551232287

Epoch: 6| Step: 4
Training loss: 1.8053069114685059
Validation loss: 2.1857795382058747

Epoch: 6| Step: 5
Training loss: 2.559192180633545
Validation loss: 2.170353022954797

Epoch: 6| Step: 6
Training loss: 2.405430316925049
Validation loss: 2.1584813235908427

Epoch: 6| Step: 7
Training loss: 1.9341622591018677
Validation loss: 2.148578174652592

Epoch: 6| Step: 8
Training loss: 1.614689826965332
Validation loss: 2.1433514369431363

Epoch: 6| Step: 9
Training loss: 2.657559633255005
Validation loss: 2.1233930959496448

Epoch: 6| Step: 10
Training loss: 1.992240071296692
Validation loss: 2.106965131657098

Epoch: 6| Step: 11
Training loss: 1.94968581199646
Validation loss: 2.092229876466977

Epoch: 6| Step: 12
Training loss: 1.6416473388671875
Validation loss: 2.0907920919438845

Epoch: 6| Step: 13
Training loss: 1.187705636024475
Validation loss: 2.086128402781743

Epoch: 131| Step: 0
Training loss: 2.684535026550293
Validation loss: 2.0910408881402787

Epoch: 6| Step: 1
Training loss: 2.270766496658325
Validation loss: 2.1103852025924192

Epoch: 6| Step: 2
Training loss: 1.7040421962738037
Validation loss: 2.1021339329340125

Epoch: 6| Step: 3
Training loss: 2.270071029663086
Validation loss: 2.1138857333890853

Epoch: 6| Step: 4
Training loss: 2.2018654346466064
Validation loss: 2.123640619298463

Epoch: 6| Step: 5
Training loss: 1.4134727716445923
Validation loss: 2.119848770480002

Epoch: 6| Step: 6
Training loss: 1.836421012878418
Validation loss: 2.1242205545466435

Epoch: 6| Step: 7
Training loss: 1.7542049884796143
Validation loss: 2.1062032035602036

Epoch: 6| Step: 8
Training loss: 1.6447196006774902
Validation loss: 2.098445312951201

Epoch: 6| Step: 9
Training loss: 1.6438498497009277
Validation loss: 2.0909502198619228

Epoch: 6| Step: 10
Training loss: 2.143972396850586
Validation loss: 2.0753960199253534

Epoch: 6| Step: 11
Training loss: 1.8884432315826416
Validation loss: 2.0745919301945674

Epoch: 6| Step: 12
Training loss: 1.957390546798706
Validation loss: 2.0689524553155385

Epoch: 6| Step: 13
Training loss: 1.849162220954895
Validation loss: 2.079271411383024

Epoch: 132| Step: 0
Training loss: 1.858083724975586
Validation loss: 2.077455392447851

Epoch: 6| Step: 1
Training loss: 2.2860522270202637
Validation loss: 2.109086246900661

Epoch: 6| Step: 2
Training loss: 1.6870200634002686
Validation loss: 2.110858819817984

Epoch: 6| Step: 3
Training loss: 2.123929262161255
Validation loss: 2.1126676990139868

Epoch: 6| Step: 4
Training loss: 1.683406114578247
Validation loss: 2.1422903153204147

Epoch: 6| Step: 5
Training loss: 1.2667410373687744
Validation loss: 2.123455532135502

Epoch: 6| Step: 6
Training loss: 2.0331435203552246
Validation loss: 2.11372818229019

Epoch: 6| Step: 7
Training loss: 1.7321116924285889
Validation loss: 2.1174857308787685

Epoch: 6| Step: 8
Training loss: 2.0706396102905273
Validation loss: 2.099080947137648

Epoch: 6| Step: 9
Training loss: 1.6023297309875488
Validation loss: 2.0969127249974076

Epoch: 6| Step: 10
Training loss: 2.0090579986572266
Validation loss: 2.0910543549445366

Epoch: 6| Step: 11
Training loss: 2.4731411933898926
Validation loss: 2.0788696350589877

Epoch: 6| Step: 12
Training loss: 2.3173952102661133
Validation loss: 2.093661845371287

Epoch: 6| Step: 13
Training loss: 2.5256032943725586
Validation loss: 2.080706363083214

Epoch: 133| Step: 0
Training loss: 1.549831748008728
Validation loss: 2.097743688091155

Epoch: 6| Step: 1
Training loss: 2.0170884132385254
Validation loss: 2.1108900013790337

Epoch: 6| Step: 2
Training loss: 2.498119831085205
Validation loss: 2.0944896051960606

Epoch: 6| Step: 3
Training loss: 2.019792318344116
Validation loss: 2.1004581246324765

Epoch: 6| Step: 4
Training loss: 2.105468511581421
Validation loss: 2.102440462317518

Epoch: 6| Step: 5
Training loss: 1.769207239151001
Validation loss: 2.103752661776799

Epoch: 6| Step: 6
Training loss: 1.4806537628173828
Validation loss: 2.1078891600331953

Epoch: 6| Step: 7
Training loss: 1.641049861907959
Validation loss: 2.105138396704069

Epoch: 6| Step: 8
Training loss: 1.9899389743804932
Validation loss: 2.129255376836305

Epoch: 6| Step: 9
Training loss: 1.8616807460784912
Validation loss: 2.1693081445591424

Epoch: 6| Step: 10
Training loss: 2.767127275466919
Validation loss: 2.2316014112964755

Epoch: 6| Step: 11
Training loss: 1.9912943840026855
Validation loss: 2.277179894908782

Epoch: 6| Step: 12
Training loss: 2.0250329971313477
Validation loss: 2.297743243555869

Epoch: 6| Step: 13
Training loss: 1.626943826675415
Validation loss: 2.232234190869075

Epoch: 134| Step: 0
Training loss: 2.522378444671631
Validation loss: 2.1293262538089546

Epoch: 6| Step: 1
Training loss: 2.1336112022399902
Validation loss: 2.100521292737735

Epoch: 6| Step: 2
Training loss: 2.3265187740325928
Validation loss: 2.0994382737785258

Epoch: 6| Step: 3
Training loss: 1.8885654211044312
Validation loss: 2.112657916161322

Epoch: 6| Step: 4
Training loss: 2.051038980484009
Validation loss: 2.1077104845354633

Epoch: 6| Step: 5
Training loss: 1.4842054843902588
Validation loss: 2.1065242700679327

Epoch: 6| Step: 6
Training loss: 1.5473957061767578
Validation loss: 2.098414821009482

Epoch: 6| Step: 7
Training loss: 1.7048416137695312
Validation loss: 2.0611704728936635

Epoch: 6| Step: 8
Training loss: 1.7070019245147705
Validation loss: 2.052401861836833

Epoch: 6| Step: 9
Training loss: 1.5501139163970947
Validation loss: 2.0429402320615706

Epoch: 6| Step: 10
Training loss: 3.1947178840637207
Validation loss: 2.0370518545950613

Epoch: 6| Step: 11
Training loss: 2.0463943481445312
Validation loss: 2.043732614927394

Epoch: 6| Step: 12
Training loss: 1.6053822040557861
Validation loss: 2.056861598004577

Epoch: 6| Step: 13
Training loss: 1.5293644666671753
Validation loss: 2.0873795940030004

Epoch: 135| Step: 0
Training loss: 2.2943172454833984
Validation loss: 2.1069335194044214

Epoch: 6| Step: 1
Training loss: 1.8358595371246338
Validation loss: 2.111703990608133

Epoch: 6| Step: 2
Training loss: 1.682129979133606
Validation loss: 2.1291556435246624

Epoch: 6| Step: 3
Training loss: 2.7560315132141113
Validation loss: 2.1499247025418025

Epoch: 6| Step: 4
Training loss: 1.7378039360046387
Validation loss: 2.1232645665445635

Epoch: 6| Step: 5
Training loss: 1.9050134420394897
Validation loss: 2.1342641025461178

Epoch: 6| Step: 6
Training loss: 1.561100959777832
Validation loss: 2.1184176245043354

Epoch: 6| Step: 7
Training loss: 2.050996780395508
Validation loss: 2.1044605419199955

Epoch: 6| Step: 8
Training loss: 1.65690279006958
Validation loss: 2.0989810497530046

Epoch: 6| Step: 9
Training loss: 1.8776055574417114
Validation loss: 2.090480181478685

Epoch: 6| Step: 10
Training loss: 2.395308017730713
Validation loss: 2.0910424135064565

Epoch: 6| Step: 11
Training loss: 1.5467829704284668
Validation loss: 2.089598135922545

Epoch: 6| Step: 12
Training loss: 1.8877427577972412
Validation loss: 2.0892309117060837

Epoch: 6| Step: 13
Training loss: 2.246819496154785
Validation loss: 2.100508154079478

Epoch: 136| Step: 0
Training loss: 1.8854658603668213
Validation loss: 2.1267484029134116

Epoch: 6| Step: 1
Training loss: 1.7105053663253784
Validation loss: 2.1494578648638982

Epoch: 6| Step: 2
Training loss: 1.9021400213241577
Validation loss: 2.1565230738732124

Epoch: 6| Step: 3
Training loss: 2.1382029056549072
Validation loss: 2.1462120497098534

Epoch: 6| Step: 4
Training loss: 1.8918040990829468
Validation loss: 2.143428128252747

Epoch: 6| Step: 5
Training loss: 1.7485567331314087
Validation loss: 2.1151454640972998

Epoch: 6| Step: 6
Training loss: 1.854048728942871
Validation loss: 2.108852494147516

Epoch: 6| Step: 7
Training loss: 2.4307079315185547
Validation loss: 2.091483603241623

Epoch: 6| Step: 8
Training loss: 1.54756498336792
Validation loss: 2.071960849146689

Epoch: 6| Step: 9
Training loss: 2.056820869445801
Validation loss: 2.065440998282484

Epoch: 6| Step: 10
Training loss: 1.1494801044464111
Validation loss: 2.06545861177547

Epoch: 6| Step: 11
Training loss: 2.3391666412353516
Validation loss: 2.0638831841048373

Epoch: 6| Step: 12
Training loss: 1.8737901449203491
Validation loss: 2.082164499067491

Epoch: 6| Step: 13
Training loss: 2.55794620513916
Validation loss: 2.0795885042477678

Epoch: 137| Step: 0
Training loss: 2.0278854370117188
Validation loss: 2.097514990837343

Epoch: 6| Step: 1
Training loss: 2.212651014328003
Validation loss: 2.109419371492119

Epoch: 6| Step: 2
Training loss: 1.8805806636810303
Validation loss: 2.1475415755343694

Epoch: 6| Step: 3
Training loss: 2.4833333492279053
Validation loss: 2.1616291281997517

Epoch: 6| Step: 4
Training loss: 1.7313971519470215
Validation loss: 2.158230613636714

Epoch: 6| Step: 5
Training loss: 1.8014780282974243
Validation loss: 2.153614713299659

Epoch: 6| Step: 6
Training loss: 1.6045953035354614
Validation loss: 2.128786797164589

Epoch: 6| Step: 7
Training loss: 1.7806305885314941
Validation loss: 2.111384871185467

Epoch: 6| Step: 8
Training loss: 1.2582144737243652
Validation loss: 2.0945850905551704

Epoch: 6| Step: 9
Training loss: 1.8305189609527588
Validation loss: 2.0676332519900416

Epoch: 6| Step: 10
Training loss: 2.1020076274871826
Validation loss: 2.052310129647614

Epoch: 6| Step: 11
Training loss: 2.034149646759033
Validation loss: 2.048013187223865

Epoch: 6| Step: 12
Training loss: 2.4808738231658936
Validation loss: 2.0600831559909287

Epoch: 6| Step: 13
Training loss: 1.2011656761169434
Validation loss: 2.076562458469022

Epoch: 138| Step: 0
Training loss: 1.9983935356140137
Validation loss: 2.0741419279447166

Epoch: 6| Step: 1
Training loss: 1.765049695968628
Validation loss: 2.0837239424387612

Epoch: 6| Step: 2
Training loss: 1.8754874467849731
Validation loss: 2.0967967907587686

Epoch: 6| Step: 3
Training loss: 1.6180495023727417
Validation loss: 2.090293243367185

Epoch: 6| Step: 4
Training loss: 1.991319179534912
Validation loss: 2.0891542870511293

Epoch: 6| Step: 5
Training loss: 1.9637885093688965
Validation loss: 2.096253838590396

Epoch: 6| Step: 6
Training loss: 1.9914772510528564
Validation loss: 2.097641066838336

Epoch: 6| Step: 7
Training loss: 1.6639201641082764
Validation loss: 2.0992726907935193

Epoch: 6| Step: 8
Training loss: 2.2803449630737305
Validation loss: 2.0837232489739694

Epoch: 6| Step: 9
Training loss: 2.157155990600586
Validation loss: 2.0990050133838447

Epoch: 6| Step: 10
Training loss: 1.4932613372802734
Validation loss: 2.105370375417894

Epoch: 6| Step: 11
Training loss: 2.1015877723693848
Validation loss: 2.1174015819385485

Epoch: 6| Step: 12
Training loss: 1.5704357624053955
Validation loss: 2.1292435789621003

Epoch: 6| Step: 13
Training loss: 2.0513081550598145
Validation loss: 2.110753946406867

Epoch: 139| Step: 0
Training loss: 1.9989038705825806
Validation loss: 2.0878814381937825

Epoch: 6| Step: 1
Training loss: 2.5055017471313477
Validation loss: 2.0982581389847623

Epoch: 6| Step: 2
Training loss: 2.046895980834961
Validation loss: 2.0681249505730084

Epoch: 6| Step: 3
Training loss: 1.8645559549331665
Validation loss: 2.0617978265208583

Epoch: 6| Step: 4
Training loss: 1.4997584819793701
Validation loss: 2.0568354386155323

Epoch: 6| Step: 5
Training loss: 1.1444085836410522
Validation loss: 2.058820337377569

Epoch: 6| Step: 6
Training loss: 2.181516170501709
Validation loss: 2.0517219035856185

Epoch: 6| Step: 7
Training loss: 2.6374146938323975
Validation loss: 2.068623471003707

Epoch: 6| Step: 8
Training loss: 1.9082419872283936
Validation loss: 2.102103440992294

Epoch: 6| Step: 9
Training loss: 1.1897733211517334
Validation loss: 2.094919220093758

Epoch: 6| Step: 10
Training loss: 1.7688525915145874
Validation loss: 2.116317618277765

Epoch: 6| Step: 11
Training loss: 2.0134224891662598
Validation loss: 2.1128352034476494

Epoch: 6| Step: 12
Training loss: 1.7797152996063232
Validation loss: 2.128878834427044

Epoch: 6| Step: 13
Training loss: 1.855298399925232
Validation loss: 2.121048968325379

Epoch: 140| Step: 0
Training loss: 1.849877119064331
Validation loss: 2.115741724609047

Epoch: 6| Step: 1
Training loss: 2.2370665073394775
Validation loss: 2.086843289354796

Epoch: 6| Step: 2
Training loss: 2.2378971576690674
Validation loss: 2.0749339916372813

Epoch: 6| Step: 3
Training loss: 1.5517019033432007
Validation loss: 2.091704548046153

Epoch: 6| Step: 4
Training loss: 1.3579316139221191
Validation loss: 2.0888414485480196

Epoch: 6| Step: 5
Training loss: 2.4932374954223633
Validation loss: 2.0960571637717624

Epoch: 6| Step: 6
Training loss: 2.156010627746582
Validation loss: 2.105755013804282

Epoch: 6| Step: 7
Training loss: 2.197422981262207
Validation loss: 2.1323156036356443

Epoch: 6| Step: 8
Training loss: 1.5186303853988647
Validation loss: 2.1436245428618563

Epoch: 6| Step: 9
Training loss: 2.1039648056030273
Validation loss: 2.1372270020105506

Epoch: 6| Step: 10
Training loss: 1.765197515487671
Validation loss: 2.1391198494101085

Epoch: 6| Step: 11
Training loss: 1.6479146480560303
Validation loss: 2.13588906744475

Epoch: 6| Step: 12
Training loss: 1.7379095554351807
Validation loss: 2.13205155762293

Epoch: 6| Step: 13
Training loss: 1.376492977142334
Validation loss: 2.1194817071319907

Epoch: 141| Step: 0
Training loss: 1.5085656642913818
Validation loss: 2.1054356021265828

Epoch: 6| Step: 1
Training loss: 1.8884532451629639
Validation loss: 2.096075686075354

Epoch: 6| Step: 2
Training loss: 2.0761232376098633
Validation loss: 2.1013658251813663

Epoch: 6| Step: 3
Training loss: 2.33614444732666
Validation loss: 2.0938560578130905

Epoch: 6| Step: 4
Training loss: 1.9710984230041504
Validation loss: 2.0960438712950675

Epoch: 6| Step: 5
Training loss: 1.240583896636963
Validation loss: 2.0952252021399875

Epoch: 6| Step: 6
Training loss: 2.3523192405700684
Validation loss: 2.0908700830192974

Epoch: 6| Step: 7
Training loss: 1.7621458768844604
Validation loss: 2.088235383392662

Epoch: 6| Step: 8
Training loss: 1.5499961376190186
Validation loss: 2.1037536282693186

Epoch: 6| Step: 9
Training loss: 1.8231909275054932
Validation loss: 2.1086712011726956

Epoch: 6| Step: 10
Training loss: 1.6205997467041016
Validation loss: 2.144088533616835

Epoch: 6| Step: 11
Training loss: 2.257826089859009
Validation loss: 2.141835102470972

Epoch: 6| Step: 12
Training loss: 1.6942181587219238
Validation loss: 2.1523742932145313

Epoch: 6| Step: 13
Training loss: 2.406322717666626
Validation loss: 2.1583011919452297

Epoch: 142| Step: 0
Training loss: 1.899566888809204
Validation loss: 2.178115201252763

Epoch: 6| Step: 1
Training loss: 1.7047193050384521
Validation loss: 2.180706888116816

Epoch: 6| Step: 2
Training loss: 2.278735637664795
Validation loss: 2.16049381994432

Epoch: 6| Step: 3
Training loss: 1.808830976486206
Validation loss: 2.1518784043609456

Epoch: 6| Step: 4
Training loss: 1.7278854846954346
Validation loss: 2.1198788740301646

Epoch: 6| Step: 5
Training loss: 1.6891745328903198
Validation loss: 2.0830296342090895

Epoch: 6| Step: 6
Training loss: 1.5193625688552856
Validation loss: 2.078875837787505

Epoch: 6| Step: 7
Training loss: 2.5534117221832275
Validation loss: 2.0636537100679133

Epoch: 6| Step: 8
Training loss: 1.8772910833358765
Validation loss: 2.075038561256983

Epoch: 6| Step: 9
Training loss: 1.8519351482391357
Validation loss: 2.080616112678282

Epoch: 6| Step: 10
Training loss: 1.746871829032898
Validation loss: 2.0856675947866132

Epoch: 6| Step: 11
Training loss: 1.8160393238067627
Validation loss: 2.1022154567062215

Epoch: 6| Step: 12
Training loss: 2.0797760486602783
Validation loss: 2.1166576339352514

Epoch: 6| Step: 13
Training loss: 1.696608066558838
Validation loss: 2.1251540132748183

Epoch: 143| Step: 0
Training loss: 1.9659614562988281
Validation loss: 2.118665933609009

Epoch: 6| Step: 1
Training loss: 1.828082799911499
Validation loss: 2.115673530486322

Epoch: 6| Step: 2
Training loss: 1.7209579944610596
Validation loss: 2.1387195817885862

Epoch: 6| Step: 3
Training loss: 1.7583723068237305
Validation loss: 2.168737506353727

Epoch: 6| Step: 4
Training loss: 0.9555159211158752
Validation loss: 2.238984687353975

Epoch: 6| Step: 5
Training loss: 2.1459999084472656
Validation loss: 2.280081631034933

Epoch: 6| Step: 6
Training loss: 2.643641471862793
Validation loss: 2.321606356610534

Epoch: 6| Step: 7
Training loss: 2.5449957847595215
Validation loss: 2.311669445806934

Epoch: 6| Step: 8
Training loss: 1.7252097129821777
Validation loss: 2.2420065761894308

Epoch: 6| Step: 9
Training loss: 2.2470803260803223
Validation loss: 2.1973337383680445

Epoch: 6| Step: 10
Training loss: 2.0383589267730713
Validation loss: 2.1273005547062045

Epoch: 6| Step: 11
Training loss: 1.4960697889328003
Validation loss: 2.1151649144388016

Epoch: 6| Step: 12
Training loss: 1.9691493511199951
Validation loss: 2.098650878475558

Epoch: 6| Step: 13
Training loss: 1.5155786275863647
Validation loss: 2.095617425057196

Epoch: 144| Step: 0
Training loss: 2.4614343643188477
Validation loss: 2.075927185755904

Epoch: 6| Step: 1
Training loss: 1.8800463676452637
Validation loss: 2.0518836949461248

Epoch: 6| Step: 2
Training loss: 2.007145404815674
Validation loss: 2.0443573203138126

Epoch: 6| Step: 3
Training loss: 2.046323776245117
Validation loss: 2.0464641176244265

Epoch: 6| Step: 4
Training loss: 2.0504937171936035
Validation loss: 2.051732784958296

Epoch: 6| Step: 5
Training loss: 1.7104768753051758
Validation loss: 2.0556776959408998

Epoch: 6| Step: 6
Training loss: 1.6415483951568604
Validation loss: 2.0543014567385436

Epoch: 6| Step: 7
Training loss: 1.3687976598739624
Validation loss: 2.0785952716745357

Epoch: 6| Step: 8
Training loss: 1.8897321224212646
Validation loss: 2.089324838371687

Epoch: 6| Step: 9
Training loss: 2.0996947288513184
Validation loss: 2.097702508331627

Epoch: 6| Step: 10
Training loss: 2.008361339569092
Validation loss: 2.114064182004621

Epoch: 6| Step: 11
Training loss: 2.0019192695617676
Validation loss: 2.105244263525932

Epoch: 6| Step: 12
Training loss: 1.079761028289795
Validation loss: 2.087080196667743

Epoch: 6| Step: 13
Training loss: 1.965454339981079
Validation loss: 2.1005858221361713

Epoch: 145| Step: 0
Training loss: 1.4138420820236206
Validation loss: 2.1177475157604424

Epoch: 6| Step: 1
Training loss: 1.9998127222061157
Validation loss: 2.109895495958226

Epoch: 6| Step: 2
Training loss: 1.382419228553772
Validation loss: 2.10979627537471

Epoch: 6| Step: 3
Training loss: 1.325490117073059
Validation loss: 2.1312385451409126

Epoch: 6| Step: 4
Training loss: 1.7576117515563965
Validation loss: 2.1206964023651613

Epoch: 6| Step: 5
Training loss: 2.6908488273620605
Validation loss: 2.1121465313819145

Epoch: 6| Step: 6
Training loss: 1.87012779712677
Validation loss: 2.095649301364858

Epoch: 6| Step: 7
Training loss: 1.9287141561508179
Validation loss: 2.0825039930241083

Epoch: 6| Step: 8
Training loss: 2.057995080947876
Validation loss: 2.0848908385922833

Epoch: 6| Step: 9
Training loss: 1.6534310579299927
Validation loss: 2.080690268547304

Epoch: 6| Step: 10
Training loss: 1.8149569034576416
Validation loss: 2.066249503884264

Epoch: 6| Step: 11
Training loss: 2.0174341201782227
Validation loss: 2.065413368645535

Epoch: 6| Step: 12
Training loss: 1.8708313703536987
Validation loss: 2.0583715733661445

Epoch: 6| Step: 13
Training loss: 1.6707967519760132
Validation loss: 2.067752984262282

Epoch: 146| Step: 0
Training loss: 1.0780819654464722
Validation loss: 2.0862239765864548

Epoch: 6| Step: 1
Training loss: 1.5369930267333984
Validation loss: 2.090970241895286

Epoch: 6| Step: 2
Training loss: 2.0264456272125244
Validation loss: 2.104001232372817

Epoch: 6| Step: 3
Training loss: 2.4477624893188477
Validation loss: 2.1035881644936016

Epoch: 6| Step: 4
Training loss: 2.7775583267211914
Validation loss: 2.0992216897267166

Epoch: 6| Step: 5
Training loss: 2.0224833488464355
Validation loss: 2.105118418252596

Epoch: 6| Step: 6
Training loss: 1.6789953708648682
Validation loss: 2.113392504312659

Epoch: 6| Step: 7
Training loss: 2.363935947418213
Validation loss: 2.1212844284631873

Epoch: 6| Step: 8
Training loss: 1.389896035194397
Validation loss: 2.12611497089427

Epoch: 6| Step: 9
Training loss: 1.1305196285247803
Validation loss: 2.1227935065505323

Epoch: 6| Step: 10
Training loss: 1.910997748374939
Validation loss: 2.1142788740896408

Epoch: 6| Step: 11
Training loss: 1.7582170963287354
Validation loss: 2.1261248255288727

Epoch: 6| Step: 12
Training loss: 1.6015782356262207
Validation loss: 2.1132992723936677

Epoch: 6| Step: 13
Training loss: 1.3127028942108154
Validation loss: 2.090179994542112

Epoch: 147| Step: 0
Training loss: 1.7709640264511108
Validation loss: 2.1111364800442933

Epoch: 6| Step: 1
Training loss: 2.224682331085205
Validation loss: 2.126728524443924

Epoch: 6| Step: 2
Training loss: 2.080136299133301
Validation loss: 2.1169309564816055

Epoch: 6| Step: 3
Training loss: 2.2499794960021973
Validation loss: 2.1310730172741796

Epoch: 6| Step: 4
Training loss: 1.849206566810608
Validation loss: 2.1342534275465113

Epoch: 6| Step: 5
Training loss: 2.0022220611572266
Validation loss: 2.1264251996112127

Epoch: 6| Step: 6
Training loss: 1.6997053623199463
Validation loss: 2.1278064417582687

Epoch: 6| Step: 7
Training loss: 2.0464959144592285
Validation loss: 2.116122755953061

Epoch: 6| Step: 8
Training loss: 1.411219835281372
Validation loss: 2.117485348896314

Epoch: 6| Step: 9
Training loss: 0.9973326921463013
Validation loss: 2.1127565496711322

Epoch: 6| Step: 10
Training loss: 2.123152732849121
Validation loss: 2.099371579385573

Epoch: 6| Step: 11
Training loss: 1.1463212966918945
Validation loss: 2.1024368783479095

Epoch: 6| Step: 12
Training loss: 1.8113555908203125
Validation loss: 2.110276158137988

Epoch: 6| Step: 13
Training loss: 1.3561029434204102
Validation loss: 2.1336860272192184

Epoch: 148| Step: 0
Training loss: 2.5098960399627686
Validation loss: 2.1331119575808124

Epoch: 6| Step: 1
Training loss: 1.8535326719284058
Validation loss: 2.14687208719151

Epoch: 6| Step: 2
Training loss: 2.0509514808654785
Validation loss: 2.1918843753876223

Epoch: 6| Step: 3
Training loss: 2.302704334259033
Validation loss: 2.188050357244348

Epoch: 6| Step: 4
Training loss: 1.4311237335205078
Validation loss: 2.1556036497956965

Epoch: 6| Step: 5
Training loss: 1.6549568176269531
Validation loss: 2.1444255792966453

Epoch: 6| Step: 6
Training loss: 1.2069381475448608
Validation loss: 2.1212917040753108

Epoch: 6| Step: 7
Training loss: 2.128943920135498
Validation loss: 2.1059945232124737

Epoch: 6| Step: 8
Training loss: 1.3512225151062012
Validation loss: 2.1122944380647395

Epoch: 6| Step: 9
Training loss: 1.9254026412963867
Validation loss: 2.100341168783044

Epoch: 6| Step: 10
Training loss: 1.383781909942627
Validation loss: 2.1029043428359495

Epoch: 6| Step: 11
Training loss: 1.5370360612869263
Validation loss: 2.109000790503717

Epoch: 6| Step: 12
Training loss: 1.3850457668304443
Validation loss: 2.106640108170048

Epoch: 6| Step: 13
Training loss: 2.4861536026000977
Validation loss: 2.0893482662016347

Epoch: 149| Step: 0
Training loss: 2.18939208984375
Validation loss: 2.0752243072755876

Epoch: 6| Step: 1
Training loss: 1.7972317934036255
Validation loss: 2.069949988395937

Epoch: 6| Step: 2
Training loss: 1.6502288579940796
Validation loss: 2.064997103906447

Epoch: 6| Step: 3
Training loss: 1.5012530088424683
Validation loss: 2.0737055322175384

Epoch: 6| Step: 4
Training loss: 1.2290120124816895
Validation loss: 2.0711158552477436

Epoch: 6| Step: 5
Training loss: 1.3980398178100586
Validation loss: 2.067029276201802

Epoch: 6| Step: 6
Training loss: 1.7120797634124756
Validation loss: 2.069176582879918

Epoch: 6| Step: 7
Training loss: 1.6411670446395874
Validation loss: 2.0993117209403747

Epoch: 6| Step: 8
Training loss: 2.29532527923584
Validation loss: 2.097029896192653

Epoch: 6| Step: 9
Training loss: 2.2133617401123047
Validation loss: 2.1190711041932464

Epoch: 6| Step: 10
Training loss: 1.8643414974212646
Validation loss: 2.1231324262516473

Epoch: 6| Step: 11
Training loss: 1.8938349485397339
Validation loss: 2.1300536714574343

Epoch: 6| Step: 12
Training loss: 1.8162721395492554
Validation loss: 2.149229495756088

Epoch: 6| Step: 13
Training loss: 1.222592830657959
Validation loss: 2.1757353044325307

Epoch: 150| Step: 0
Training loss: 1.7678887844085693
Validation loss: 2.1723974020250383

Epoch: 6| Step: 1
Training loss: 1.1553254127502441
Validation loss: 2.165369669596354

Epoch: 6| Step: 2
Training loss: 1.5190761089324951
Validation loss: 2.133706990108695

Epoch: 6| Step: 3
Training loss: 1.696904182434082
Validation loss: 2.1270820722785047

Epoch: 6| Step: 4
Training loss: 2.140255928039551
Validation loss: 2.1307629782666444

Epoch: 6| Step: 5
Training loss: 2.077439069747925
Validation loss: 2.1316357992028676

Epoch: 6| Step: 6
Training loss: 1.8320286273956299
Validation loss: 2.1335740781599477

Epoch: 6| Step: 7
Training loss: 2.0934884548187256
Validation loss: 2.124874327772407

Epoch: 6| Step: 8
Training loss: 1.4154224395751953
Validation loss: 2.1430340992507113

Epoch: 6| Step: 9
Training loss: 2.2187819480895996
Validation loss: 2.1345656430849465

Epoch: 6| Step: 10
Training loss: 1.3649187088012695
Validation loss: 2.125289677291788

Epoch: 6| Step: 11
Training loss: 2.112105131149292
Validation loss: 2.1133609484600764

Epoch: 6| Step: 12
Training loss: 1.4345930814743042
Validation loss: 2.1226984813649166

Epoch: 6| Step: 13
Training loss: 1.4418206214904785
Validation loss: 2.115571847525976

Epoch: 151| Step: 0
Training loss: 1.8900187015533447
Validation loss: 2.1207137159121934

Epoch: 6| Step: 1
Training loss: 1.6095433235168457
Validation loss: 2.119168263609691

Epoch: 6| Step: 2
Training loss: 1.717515468597412
Validation loss: 2.1156834043482298

Epoch: 6| Step: 3
Training loss: 1.7752190828323364
Validation loss: 2.124539970069803

Epoch: 6| Step: 4
Training loss: 1.8681252002716064
Validation loss: 2.1166900639892905

Epoch: 6| Step: 5
Training loss: 1.7117888927459717
Validation loss: 2.1168430492442143

Epoch: 6| Step: 6
Training loss: 2.143435478210449
Validation loss: 2.1359749301787345

Epoch: 6| Step: 7
Training loss: 1.1665358543395996
Validation loss: 2.130415338341908

Epoch: 6| Step: 8
Training loss: 1.7739148139953613
Validation loss: 2.1293027785516556

Epoch: 6| Step: 9
Training loss: 2.3085522651672363
Validation loss: 2.134077920708605

Epoch: 6| Step: 10
Training loss: 1.852571725845337
Validation loss: 2.120220139462461

Epoch: 6| Step: 11
Training loss: 1.0770866870880127
Validation loss: 2.119234105592133

Epoch: 6| Step: 12
Training loss: 1.8261209726333618
Validation loss: 2.146446235718266

Epoch: 6| Step: 13
Training loss: 2.007073402404785
Validation loss: 2.1366525132169008

Epoch: 152| Step: 0
Training loss: 2.307349920272827
Validation loss: 2.1468562310741794

Epoch: 6| Step: 1
Training loss: 1.6919296979904175
Validation loss: 2.144872009113271

Epoch: 6| Step: 2
Training loss: 2.1659412384033203
Validation loss: 2.1322311060402983

Epoch: 6| Step: 3
Training loss: 1.8454124927520752
Validation loss: 2.1275814220469487

Epoch: 6| Step: 4
Training loss: 1.8972067832946777
Validation loss: 2.112331368589914

Epoch: 6| Step: 5
Training loss: 2.1409857273101807
Validation loss: 2.132147240382369

Epoch: 6| Step: 6
Training loss: 1.4536200761795044
Validation loss: 2.099078104060183

Epoch: 6| Step: 7
Training loss: 1.486413836479187
Validation loss: 2.1084249340077883

Epoch: 6| Step: 8
Training loss: 1.8795356750488281
Validation loss: 2.0903510291089296

Epoch: 6| Step: 9
Training loss: 1.548961877822876
Validation loss: 2.094240757726854

Epoch: 6| Step: 10
Training loss: 1.2077810764312744
Validation loss: 2.0906961989659134

Epoch: 6| Step: 11
Training loss: 0.8785462975502014
Validation loss: 2.104611567271653

Epoch: 6| Step: 12
Training loss: 2.006258964538574
Validation loss: 2.1147825025743052

Epoch: 6| Step: 13
Training loss: 1.1399338245391846
Validation loss: 2.142812313572053

Epoch: 153| Step: 0
Training loss: 1.1392157077789307
Validation loss: 2.1400306737551125

Epoch: 6| Step: 1
Training loss: 1.7592087984085083
Validation loss: 2.1447536176250828

Epoch: 6| Step: 2
Training loss: 2.0871284008026123
Validation loss: 2.1398239699743127

Epoch: 6| Step: 3
Training loss: 1.0700448751449585
Validation loss: 2.127320808749045

Epoch: 6| Step: 4
Training loss: 1.530287504196167
Validation loss: 2.1519657822065454

Epoch: 6| Step: 5
Training loss: 1.9239262342453003
Validation loss: 2.1468194274492163

Epoch: 6| Step: 6
Training loss: 0.8239271640777588
Validation loss: 2.150178817010695

Epoch: 6| Step: 7
Training loss: 1.7172317504882812
Validation loss: 2.151628931363424

Epoch: 6| Step: 8
Training loss: 2.6259965896606445
Validation loss: 2.1710812737864833

Epoch: 6| Step: 9
Training loss: 2.4824938774108887
Validation loss: 2.152232905869843

Epoch: 6| Step: 10
Training loss: 1.4157564640045166
Validation loss: 2.157271226247152

Epoch: 6| Step: 11
Training loss: 2.012669086456299
Validation loss: 2.140419598548643

Epoch: 6| Step: 12
Training loss: 1.779597282409668
Validation loss: 2.137537699873729

Epoch: 6| Step: 13
Training loss: 1.6316335201263428
Validation loss: 2.1129571045598676

Epoch: 154| Step: 0
Training loss: 1.3228729963302612
Validation loss: 2.088274566076135

Epoch: 6| Step: 1
Training loss: 1.1067886352539062
Validation loss: 2.0662869843103553

Epoch: 6| Step: 2
Training loss: 2.2543020248413086
Validation loss: 2.0552531557698406

Epoch: 6| Step: 3
Training loss: 2.0542643070220947
Validation loss: 2.0532911695459837

Epoch: 6| Step: 4
Training loss: 1.9400978088378906
Validation loss: 2.051279862721761

Epoch: 6| Step: 5
Training loss: 1.4803568124771118
Validation loss: 2.0461747159240065

Epoch: 6| Step: 6
Training loss: 1.1990525722503662
Validation loss: 2.0360985084246566

Epoch: 6| Step: 7
Training loss: 1.9562621116638184
Validation loss: 2.0525824075104087

Epoch: 6| Step: 8
Training loss: 2.336996555328369
Validation loss: 2.055224267385339

Epoch: 6| Step: 9
Training loss: 1.5759344100952148
Validation loss: 2.0553311993998866

Epoch: 6| Step: 10
Training loss: 1.4699018001556396
Validation loss: 2.0493985696505477

Epoch: 6| Step: 11
Training loss: 1.7346402406692505
Validation loss: 2.0329595394031976

Epoch: 6| Step: 12
Training loss: 1.9377964735031128
Validation loss: 2.038261995520643

Epoch: 6| Step: 13
Training loss: 1.3542944192886353
Validation loss: 2.0562058853846725

Epoch: 155| Step: 0
Training loss: 1.2818983793258667
Validation loss: 2.075808660958403

Epoch: 6| Step: 1
Training loss: 2.0630478858947754
Validation loss: 2.087978220755054

Epoch: 6| Step: 2
Training loss: 1.8081353902816772
Validation loss: 2.09730637714427

Epoch: 6| Step: 3
Training loss: 1.374518871307373
Validation loss: 2.117285397744948

Epoch: 6| Step: 4
Training loss: 1.5664992332458496
Validation loss: 2.1257265203742572

Epoch: 6| Step: 5
Training loss: 0.9345773458480835
Validation loss: 2.1282554775156

Epoch: 6| Step: 6
Training loss: 1.4632076025009155
Validation loss: 2.139642643672164

Epoch: 6| Step: 7
Training loss: 1.7363629341125488
Validation loss: 2.1194710090596187

Epoch: 6| Step: 8
Training loss: 1.2792288064956665
Validation loss: 2.0830858599755073

Epoch: 6| Step: 9
Training loss: 1.8345839977264404
Validation loss: 2.0589892300226356

Epoch: 6| Step: 10
Training loss: 2.088818073272705
Validation loss: 2.0388043465152865

Epoch: 6| Step: 11
Training loss: 1.94813871383667
Validation loss: 2.0346008552018033

Epoch: 6| Step: 12
Training loss: 2.3365731239318848
Validation loss: 2.0402593266579414

Epoch: 6| Step: 13
Training loss: 1.6531398296356201
Validation loss: 2.0460090919207503

Epoch: 156| Step: 0
Training loss: 2.437351703643799
Validation loss: 2.06578767043288

Epoch: 6| Step: 1
Training loss: 1.8810715675354004
Validation loss: 2.0859018320678384

Epoch: 6| Step: 2
Training loss: 1.7970423698425293
Validation loss: 2.0717618260332333

Epoch: 6| Step: 3
Training loss: 2.2189953327178955
Validation loss: 2.074162055087346

Epoch: 6| Step: 4
Training loss: 1.3392987251281738
Validation loss: 2.0727630879289363

Epoch: 6| Step: 5
Training loss: 1.8369379043579102
Validation loss: 2.083846171696981

Epoch: 6| Step: 6
Training loss: 1.1683356761932373
Validation loss: 2.0834200125868603

Epoch: 6| Step: 7
Training loss: 1.4047229290008545
Validation loss: 2.0927125279621412

Epoch: 6| Step: 8
Training loss: 0.6318509578704834
Validation loss: 2.093637915067775

Epoch: 6| Step: 9
Training loss: 1.5160486698150635
Validation loss: 2.108348863099211

Epoch: 6| Step: 10
Training loss: 1.2553105354309082
Validation loss: 2.1156044519075783

Epoch: 6| Step: 11
Training loss: 2.7228808403015137
Validation loss: 2.123089808289723

Epoch: 6| Step: 12
Training loss: 1.368118405342102
Validation loss: 2.1055579698213966

Epoch: 6| Step: 13
Training loss: 2.1121981143951416
Validation loss: 2.108600684391555

Epoch: 157| Step: 0
Training loss: 1.5649778842926025
Validation loss: 2.091884538691531

Epoch: 6| Step: 1
Training loss: 1.554598093032837
Validation loss: 2.075205215843775

Epoch: 6| Step: 2
Training loss: 1.260132074356079
Validation loss: 2.0746533652787567

Epoch: 6| Step: 3
Training loss: 1.0659090280532837
Validation loss: 2.0572126706441245

Epoch: 6| Step: 4
Training loss: 1.9760757684707642
Validation loss: 2.042933428159324

Epoch: 6| Step: 5
Training loss: 2.0561485290527344
Validation loss: 2.0701221137918453

Epoch: 6| Step: 6
Training loss: 1.6334893703460693
Validation loss: 2.0834873940355036

Epoch: 6| Step: 7
Training loss: 1.6180524826049805
Validation loss: 2.078047139670259

Epoch: 6| Step: 8
Training loss: 1.7160847187042236
Validation loss: 2.101442269099656

Epoch: 6| Step: 9
Training loss: 1.5325239896774292
Validation loss: 2.100949720669818

Epoch: 6| Step: 10
Training loss: 1.527248740196228
Validation loss: 2.1124444597510883

Epoch: 6| Step: 11
Training loss: 1.9197394847869873
Validation loss: 2.111387073352773

Epoch: 6| Step: 12
Training loss: 1.63893461227417
Validation loss: 2.1046873446433776

Epoch: 6| Step: 13
Training loss: 1.802815318107605
Validation loss: 2.107314699439592

Epoch: 158| Step: 0
Training loss: 1.3844783306121826
Validation loss: 2.11387006057206

Epoch: 6| Step: 1
Training loss: 2.186248302459717
Validation loss: 2.1287179659771662

Epoch: 6| Step: 2
Training loss: 1.5570666790008545
Validation loss: 2.118172037986017

Epoch: 6| Step: 3
Training loss: 1.1270332336425781
Validation loss: 2.1246849106204126

Epoch: 6| Step: 4
Training loss: 2.1273016929626465
Validation loss: 2.1290908898076704

Epoch: 6| Step: 5
Training loss: 2.147653579711914
Validation loss: 2.142685851743144

Epoch: 6| Step: 6
Training loss: 1.3188583850860596
Validation loss: 2.1304392224998883

Epoch: 6| Step: 7
Training loss: 0.8305152654647827
Validation loss: 2.120224516878846

Epoch: 6| Step: 8
Training loss: 1.911435842514038
Validation loss: 2.1223662232839935

Epoch: 6| Step: 9
Training loss: 1.3752206563949585
Validation loss: 2.134200975459109

Epoch: 6| Step: 10
Training loss: 2.1262080669403076
Validation loss: 2.1504207529047483

Epoch: 6| Step: 11
Training loss: 1.76498544216156
Validation loss: 2.1642277804754113

Epoch: 6| Step: 12
Training loss: 1.662333369255066
Validation loss: 2.136232135116413

Epoch: 6| Step: 13
Training loss: 1.7641764879226685
Validation loss: 2.0962213777726695

Epoch: 159| Step: 0
Training loss: 1.0318094491958618
Validation loss: 2.0632582633726058

Epoch: 6| Step: 1
Training loss: 1.6086336374282837
Validation loss: 2.0516594507360972

Epoch: 6| Step: 2
Training loss: 1.6974661350250244
Validation loss: 2.0489416212163944

Epoch: 6| Step: 3
Training loss: 1.4992719888687134
Validation loss: 2.0596084645999375

Epoch: 6| Step: 4
Training loss: 1.362229824066162
Validation loss: 2.0463886799350863

Epoch: 6| Step: 5
Training loss: 2.1236166954040527
Validation loss: 2.040189717405586

Epoch: 6| Step: 6
Training loss: 1.269520878791809
Validation loss: 2.019967045835269

Epoch: 6| Step: 7
Training loss: 1.3905413150787354
Validation loss: 2.035324811935425

Epoch: 6| Step: 8
Training loss: 1.359607219696045
Validation loss: 2.042492961370817

Epoch: 6| Step: 9
Training loss: 2.400136947631836
Validation loss: 2.063290426808019

Epoch: 6| Step: 10
Training loss: 1.2544764280319214
Validation loss: 2.059784032965219

Epoch: 6| Step: 11
Training loss: 1.2941408157348633
Validation loss: 2.0905881671495337

Epoch: 6| Step: 12
Training loss: 1.9257277250289917
Validation loss: 2.0838657771387408

Epoch: 6| Step: 13
Training loss: 2.872542142868042
Validation loss: 2.081948850744514

Epoch: 160| Step: 0
Training loss: 2.2437572479248047
Validation loss: 2.1085036441844

Epoch: 6| Step: 1
Training loss: 1.018605351448059
Validation loss: 2.110181816162602

Epoch: 6| Step: 2
Training loss: 1.1254386901855469
Validation loss: 2.1070164147243706

Epoch: 6| Step: 3
Training loss: 1.6664440631866455
Validation loss: 2.0916103342527985

Epoch: 6| Step: 4
Training loss: 1.5238733291625977
Validation loss: 2.0789844887230986

Epoch: 6| Step: 5
Training loss: 1.7520267963409424
Validation loss: 2.0728835751933437

Epoch: 6| Step: 6
Training loss: 1.438457727432251
Validation loss: 2.0576269754799466

Epoch: 6| Step: 7
Training loss: 2.0980429649353027
Validation loss: 2.0578927481046287

Epoch: 6| Step: 8
Training loss: 1.6366864442825317
Validation loss: 2.0264983728367794

Epoch: 6| Step: 9
Training loss: 2.0579912662506104
Validation loss: 2.0132146214926117

Epoch: 6| Step: 10
Training loss: 2.023055076599121
Validation loss: 2.015395829754491

Epoch: 6| Step: 11
Training loss: 1.3369839191436768
Validation loss: 2.010553211294195

Epoch: 6| Step: 12
Training loss: 1.6472551822662354
Validation loss: 2.0283085338531004

Epoch: 6| Step: 13
Training loss: 1.2818524837493896
Validation loss: 2.0469726657354705

Epoch: 161| Step: 0
Training loss: 1.5177366733551025
Validation loss: 2.04963949418837

Epoch: 6| Step: 1
Training loss: 1.7489030361175537
Validation loss: 2.0364718232103574

Epoch: 6| Step: 2
Training loss: 1.7973356246948242
Validation loss: 2.0652378143802768

Epoch: 6| Step: 3
Training loss: 1.2428920269012451
Validation loss: 2.052908084725821

Epoch: 6| Step: 4
Training loss: 1.9738496541976929
Validation loss: 2.0476699798337874

Epoch: 6| Step: 5
Training loss: 1.0383665561676025
Validation loss: 2.0385273041263705

Epoch: 6| Step: 6
Training loss: 1.6532959938049316
Validation loss: 2.0389388427939465

Epoch: 6| Step: 7
Training loss: 2.1286423206329346
Validation loss: 2.0607225612927507

Epoch: 6| Step: 8
Training loss: 1.474488615989685
Validation loss: 2.0642151063488376

Epoch: 6| Step: 9
Training loss: 1.6998226642608643
Validation loss: 2.083541830380758

Epoch: 6| Step: 10
Training loss: 1.430617094039917
Validation loss: 2.092290437349709

Epoch: 6| Step: 11
Training loss: 1.3204638957977295
Validation loss: 2.1223320884089314

Epoch: 6| Step: 12
Training loss: 1.7069483995437622
Validation loss: 2.125322849519791

Epoch: 6| Step: 13
Training loss: 1.8049108982086182
Validation loss: 2.127635335409513

Epoch: 162| Step: 0
Training loss: 1.5330140590667725
Validation loss: 2.1327533875742266

Epoch: 6| Step: 1
Training loss: 2.2153468132019043
Validation loss: 2.119082425230293

Epoch: 6| Step: 2
Training loss: 1.596684455871582
Validation loss: 2.1114342956132788

Epoch: 6| Step: 3
Training loss: 1.8025130033493042
Validation loss: 2.1193265479098082

Epoch: 6| Step: 4
Training loss: 1.752312183380127
Validation loss: 2.122753015128515

Epoch: 6| Step: 5
Training loss: 1.0801680088043213
Validation loss: 2.120391689321046

Epoch: 6| Step: 6
Training loss: 1.7486484050750732
Validation loss: 2.1217024300688054

Epoch: 6| Step: 7
Training loss: 2.204160213470459
Validation loss: 2.132679372705439

Epoch: 6| Step: 8
Training loss: 1.2835544347763062
Validation loss: 2.0990665702409643

Epoch: 6| Step: 9
Training loss: 1.5666379928588867
Validation loss: 2.113541321087909

Epoch: 6| Step: 10
Training loss: 0.7536754012107849
Validation loss: 2.1030408079906175

Epoch: 6| Step: 11
Training loss: 1.7216897010803223
Validation loss: 2.096306356050635

Epoch: 6| Step: 12
Training loss: 1.3249609470367432
Validation loss: 2.092596894951277

Epoch: 6| Step: 13
Training loss: 1.3891576528549194
Validation loss: 2.0718373752409414

Epoch: 163| Step: 0
Training loss: 1.8579732179641724
Validation loss: 2.0856284697850547

Epoch: 6| Step: 1
Training loss: 1.4041030406951904
Validation loss: 2.0843183391837665

Epoch: 6| Step: 2
Training loss: 1.4162224531173706
Validation loss: 2.0896960881448563

Epoch: 6| Step: 3
Training loss: 2.219029426574707
Validation loss: 2.0940226354906635

Epoch: 6| Step: 4
Training loss: 0.715673565864563
Validation loss: 2.094134379458684

Epoch: 6| Step: 5
Training loss: 1.8692493438720703
Validation loss: 2.081557863502092

Epoch: 6| Step: 6
Training loss: 1.3063702583312988
Validation loss: 2.090135743541102

Epoch: 6| Step: 7
Training loss: 1.6741695404052734
Validation loss: 2.0912307052202124

Epoch: 6| Step: 8
Training loss: 0.9195587635040283
Validation loss: 2.0958083675753687

Epoch: 6| Step: 9
Training loss: 1.4321694374084473
Validation loss: 2.116592022680467

Epoch: 6| Step: 10
Training loss: 1.917733907699585
Validation loss: 2.1495711982891126

Epoch: 6| Step: 11
Training loss: 1.9192402362823486
Validation loss: 2.1207107446526967

Epoch: 6| Step: 12
Training loss: 1.4365689754486084
Validation loss: 2.1298391229362896

Epoch: 6| Step: 13
Training loss: 2.0154528617858887
Validation loss: 2.135521024786016

Epoch: 164| Step: 0
Training loss: 1.5450611114501953
Validation loss: 2.109512347047047

Epoch: 6| Step: 1
Training loss: 1.4726614952087402
Validation loss: 2.0972171419410297

Epoch: 6| Step: 2
Training loss: 1.782046914100647
Validation loss: 2.0825800280417166

Epoch: 6| Step: 3
Training loss: 1.801119089126587
Validation loss: 2.0502818528042046

Epoch: 6| Step: 4
Training loss: 1.0556836128234863
Validation loss: 2.076651665472215

Epoch: 6| Step: 5
Training loss: 0.5905469059944153
Validation loss: 2.053572141995994

Epoch: 6| Step: 6
Training loss: 1.8183679580688477
Validation loss: 2.040390194103282

Epoch: 6| Step: 7
Training loss: 1.9162492752075195
Validation loss: 2.052679584872338

Epoch: 6| Step: 8
Training loss: 2.049941062927246
Validation loss: 2.0439363371941353

Epoch: 6| Step: 9
Training loss: 1.244143009185791
Validation loss: 2.048467666872086

Epoch: 6| Step: 10
Training loss: 1.216799020767212
Validation loss: 2.0427750336226596

Epoch: 6| Step: 11
Training loss: 1.6772793531417847
Validation loss: 2.058031334671923

Epoch: 6| Step: 12
Training loss: 1.3615050315856934
Validation loss: 2.079662731898728

Epoch: 6| Step: 13
Training loss: 1.9099394083023071
Validation loss: 2.1073356443835842

Epoch: 165| Step: 0
Training loss: 1.6743437051773071
Validation loss: 2.1295635315679733

Epoch: 6| Step: 1
Training loss: 1.5827207565307617
Validation loss: 2.1190380742472987

Epoch: 6| Step: 2
Training loss: 1.8306515216827393
Validation loss: 2.133549024981837

Epoch: 6| Step: 3
Training loss: 0.768307089805603
Validation loss: 2.131360479580459

Epoch: 6| Step: 4
Training loss: 1.1608808040618896
Validation loss: 2.10640339825743

Epoch: 6| Step: 5
Training loss: 2.038271427154541
Validation loss: 2.089159865533152

Epoch: 6| Step: 6
Training loss: 1.31052827835083
Validation loss: 2.1043059710533387

Epoch: 6| Step: 7
Training loss: 1.700833797454834
Validation loss: 2.103361455343103

Epoch: 6| Step: 8
Training loss: 1.620144248008728
Validation loss: 2.0839924812316895

Epoch: 6| Step: 9
Training loss: 1.5835230350494385
Validation loss: 2.0721565446546

Epoch: 6| Step: 10
Training loss: 1.60200834274292
Validation loss: 2.0849857561049925

Epoch: 6| Step: 11
Training loss: 1.637740969657898
Validation loss: 2.0912272161053074

Epoch: 6| Step: 12
Training loss: 1.8412474393844604
Validation loss: 2.066425718286986

Epoch: 6| Step: 13
Training loss: 0.907093346118927
Validation loss: 2.081886563249814

Epoch: 166| Step: 0
Training loss: 0.9232438802719116
Validation loss: 2.062556133475355

Epoch: 6| Step: 1
Training loss: 1.735480546951294
Validation loss: 2.066822826221425

Epoch: 6| Step: 2
Training loss: 1.3041424751281738
Validation loss: 2.0360299784650087

Epoch: 6| Step: 3
Training loss: 2.0578672885894775
Validation loss: 2.0623035277089765

Epoch: 6| Step: 4
Training loss: 1.7516818046569824
Validation loss: 2.0721566190001783

Epoch: 6| Step: 5
Training loss: 1.1288799047470093
Validation loss: 2.0577014030948764

Epoch: 6| Step: 6
Training loss: 0.8117960095405579
Validation loss: 2.05696685852543

Epoch: 6| Step: 7
Training loss: 1.4384183883666992
Validation loss: 2.056315073402979

Epoch: 6| Step: 8
Training loss: 1.9952775239944458
Validation loss: 2.049892335809687

Epoch: 6| Step: 9
Training loss: 1.4031450748443604
Validation loss: 2.0646072613295687

Epoch: 6| Step: 10
Training loss: 1.810414433479309
Validation loss: 2.0572680837364605

Epoch: 6| Step: 11
Training loss: 1.3519978523254395
Validation loss: 2.088118863362138

Epoch: 6| Step: 12
Training loss: 1.8751850128173828
Validation loss: 2.0573609682821457

Epoch: 6| Step: 13
Training loss: 1.48734450340271
Validation loss: 2.06178867688743

Epoch: 167| Step: 0
Training loss: 1.7175666093826294
Validation loss: 2.066421872826033

Epoch: 6| Step: 1
Training loss: 1.9603010416030884
Validation loss: 2.0983170053010345

Epoch: 6| Step: 2
Training loss: 1.8513975143432617
Validation loss: 2.077578458734738

Epoch: 6| Step: 3
Training loss: 1.2359027862548828
Validation loss: 2.078806338771697

Epoch: 6| Step: 4
Training loss: 1.5234990119934082
Validation loss: 2.077655728145312

Epoch: 6| Step: 5
Training loss: 1.4899768829345703
Validation loss: 2.0821523025471675

Epoch: 6| Step: 6
Training loss: 1.4484586715698242
Validation loss: 2.0707387078192925

Epoch: 6| Step: 7
Training loss: 1.5869663953781128
Validation loss: 2.074425729372168

Epoch: 6| Step: 8
Training loss: 1.0457897186279297
Validation loss: 2.080952649475426

Epoch: 6| Step: 9
Training loss: 0.9881811141967773
Validation loss: 2.1028022048293904

Epoch: 6| Step: 10
Training loss: 1.088240146636963
Validation loss: 2.136449508769538

Epoch: 6| Step: 11
Training loss: 1.950757622718811
Validation loss: 2.1472971900816886

Epoch: 6| Step: 12
Training loss: 1.8601969480514526
Validation loss: 2.1234110068249445

Epoch: 6| Step: 13
Training loss: 1.4327627420425415
Validation loss: 2.1173439346333986

Epoch: 168| Step: 0
Training loss: 1.3247578144073486
Validation loss: 2.0818364568935928

Epoch: 6| Step: 1
Training loss: 1.592453956604004
Validation loss: 2.075087503720355

Epoch: 6| Step: 2
Training loss: 1.6260888576507568
Validation loss: 2.071743857476019

Epoch: 6| Step: 3
Training loss: 1.4047925472259521
Validation loss: 2.0853924982009397

Epoch: 6| Step: 4
Training loss: 1.4015607833862305
Validation loss: 2.0881065425052436

Epoch: 6| Step: 5
Training loss: 1.0812335014343262
Validation loss: 2.083445523374824

Epoch: 6| Step: 6
Training loss: 1.6675703525543213
Validation loss: 2.0754337785064534

Epoch: 6| Step: 7
Training loss: 1.318913221359253
Validation loss: 2.074289039898944

Epoch: 6| Step: 8
Training loss: 1.038238763809204
Validation loss: 2.0626174173047467

Epoch: 6| Step: 9
Training loss: 1.4748799800872803
Validation loss: 2.0654237565173896

Epoch: 6| Step: 10
Training loss: 1.4166252613067627
Validation loss: 2.0394105731800036

Epoch: 6| Step: 11
Training loss: 1.5513758659362793
Validation loss: 2.038316519029679

Epoch: 6| Step: 12
Training loss: 1.57842218875885
Validation loss: 2.044408198325865

Epoch: 6| Step: 13
Training loss: 3.039276123046875
Validation loss: 2.069718973610991

Epoch: 169| Step: 0
Training loss: 1.8925998210906982
Validation loss: 2.044935682768463

Epoch: 6| Step: 1
Training loss: 1.4104959964752197
Validation loss: 2.040898771696193

Epoch: 6| Step: 2
Training loss: 1.1998788118362427
Validation loss: 2.052355509932323

Epoch: 6| Step: 3
Training loss: 1.5602028369903564
Validation loss: 2.043868634008592

Epoch: 6| Step: 4
Training loss: 1.1156795024871826
Validation loss: 2.0605094919922533

Epoch: 6| Step: 5
Training loss: 1.7428703308105469
Validation loss: 2.0474236242232786

Epoch: 6| Step: 6
Training loss: 1.31474769115448
Validation loss: 2.0447869582842757

Epoch: 6| Step: 7
Training loss: 1.301917314529419
Validation loss: 2.068346074832383

Epoch: 6| Step: 8
Training loss: 1.1323280334472656
Validation loss: 2.0701957518054592

Epoch: 6| Step: 9
Training loss: 1.4608421325683594
Validation loss: 2.0611754335382932

Epoch: 6| Step: 10
Training loss: 1.908900499343872
Validation loss: 2.057131698054652

Epoch: 6| Step: 11
Training loss: 1.9207013845443726
Validation loss: 2.0759738337609077

Epoch: 6| Step: 12
Training loss: 1.0355854034423828
Validation loss: 2.058837595806327

Epoch: 6| Step: 13
Training loss: 1.2656701803207397
Validation loss: 2.0457733561915736

Epoch: 170| Step: 0
Training loss: 1.707848072052002
Validation loss: 2.043791678643996

Epoch: 6| Step: 1
Training loss: 1.4606823921203613
Validation loss: 2.0303389064727293

Epoch: 6| Step: 2
Training loss: 0.910494863986969
Validation loss: 2.034805426033594

Epoch: 6| Step: 3
Training loss: 1.2713217735290527
Validation loss: 2.0296953673003824

Epoch: 6| Step: 4
Training loss: 1.3616982698440552
Validation loss: 2.0393057664235434

Epoch: 6| Step: 5
Training loss: 1.544665813446045
Validation loss: 2.044958065914851

Epoch: 6| Step: 6
Training loss: 2.03849458694458
Validation loss: 2.0507263483539706

Epoch: 6| Step: 7
Training loss: 1.5045005083084106
Validation loss: 2.05796036412639

Epoch: 6| Step: 8
Training loss: 1.2120544910430908
Validation loss: 2.039464568579069

Epoch: 6| Step: 9
Training loss: 1.7496941089630127
Validation loss: 2.04325730569901

Epoch: 6| Step: 10
Training loss: 1.1992806196212769
Validation loss: 2.0780431711545555

Epoch: 6| Step: 11
Training loss: 1.437808632850647
Validation loss: 2.073615889395437

Epoch: 6| Step: 12
Training loss: 1.3425452709197998
Validation loss: 2.081966215564359

Epoch: 6| Step: 13
Training loss: 1.3675363063812256
Validation loss: 2.0547855554088468

Epoch: 171| Step: 0
Training loss: 1.3306972980499268
Validation loss: 2.0496112095412387

Epoch: 6| Step: 1
Training loss: 1.864893913269043
Validation loss: 2.037047529733309

Epoch: 6| Step: 2
Training loss: 1.8955092430114746
Validation loss: 2.040066812628059

Epoch: 6| Step: 3
Training loss: 0.9650038480758667
Validation loss: 2.0340046357083064

Epoch: 6| Step: 4
Training loss: 1.5417102575302124
Validation loss: 2.026776408636442

Epoch: 6| Step: 5
Training loss: 1.59316086769104
Validation loss: 2.021376047083127

Epoch: 6| Step: 6
Training loss: 1.6759623289108276
Validation loss: 2.0064652863369195

Epoch: 6| Step: 7
Training loss: 0.9763167500495911
Validation loss: 2.0283860442458943

Epoch: 6| Step: 8
Training loss: 1.2271116971969604
Validation loss: 2.0273216180903937

Epoch: 6| Step: 9
Training loss: 1.159747838973999
Validation loss: 2.025216673010139

Epoch: 6| Step: 10
Training loss: 1.0924912691116333
Validation loss: 2.0375003776242657

Epoch: 6| Step: 11
Training loss: 1.6208539009094238
Validation loss: 2.0184973260407806

Epoch: 6| Step: 12
Training loss: 1.400270938873291
Validation loss: 2.037306031873149

Epoch: 6| Step: 13
Training loss: 1.0959960222244263
Validation loss: 2.065210711571478

Epoch: 172| Step: 0
Training loss: 1.2467129230499268
Validation loss: 2.086849328010313

Epoch: 6| Step: 1
Training loss: 1.3689110279083252
Validation loss: 2.1146401051552064

Epoch: 6| Step: 2
Training loss: 2.096752882003784
Validation loss: 2.1241101526444957

Epoch: 6| Step: 3
Training loss: 1.601780652999878
Validation loss: 2.0762587106356056

Epoch: 6| Step: 4
Training loss: 1.9505400657653809
Validation loss: 2.077388201990435

Epoch: 6| Step: 5
Training loss: 1.2571892738342285
Validation loss: 2.0513080627687517

Epoch: 6| Step: 6
Training loss: 0.7809249758720398
Validation loss: 2.056883445350073

Epoch: 6| Step: 7
Training loss: 1.252462387084961
Validation loss: 2.0434380167274067

Epoch: 6| Step: 8
Training loss: 1.5296590328216553
Validation loss: 2.0492945101953324

Epoch: 6| Step: 9
Training loss: 0.7771937847137451
Validation loss: 2.0172009903897523

Epoch: 6| Step: 10
Training loss: 1.518075704574585
Validation loss: 2.0432718056504444

Epoch: 6| Step: 11
Training loss: 2.530956268310547
Validation loss: 2.0373594350712274

Epoch: 6| Step: 12
Training loss: 1.0754257440567017
Validation loss: 2.02283211164577

Epoch: 6| Step: 13
Training loss: 0.9969255924224854
Validation loss: 1.9869362026132562

Epoch: 173| Step: 0
Training loss: 0.9712939262390137
Validation loss: 1.9967078906233593

Epoch: 6| Step: 1
Training loss: 1.231022596359253
Validation loss: 1.997184955945579

Epoch: 6| Step: 2
Training loss: 1.8634397983551025
Validation loss: 2.0080827025957007

Epoch: 6| Step: 3
Training loss: 1.2157891988754272
Validation loss: 1.9818163148818477

Epoch: 6| Step: 4
Training loss: 1.5341861248016357
Validation loss: 1.9918704007261543

Epoch: 6| Step: 5
Training loss: 0.9939407110214233
Validation loss: 2.00640425374431

Epoch: 6| Step: 6
Training loss: 1.5074282884597778
Validation loss: 2.009498829482704

Epoch: 6| Step: 7
Training loss: 1.423478126525879
Validation loss: 2.0347767517130864

Epoch: 6| Step: 8
Training loss: 1.7630438804626465
Validation loss: 2.0486641622358754

Epoch: 6| Step: 9
Training loss: 1.8716988563537598
Validation loss: 2.052048288365846

Epoch: 6| Step: 10
Training loss: 1.266270399093628
Validation loss: 2.0219054042652087

Epoch: 6| Step: 11
Training loss: 1.2667909860610962
Validation loss: 2.0290794603286253

Epoch: 6| Step: 12
Training loss: 1.277909278869629
Validation loss: 2.026522522331566

Epoch: 6| Step: 13
Training loss: 1.327441692352295
Validation loss: 2.0300388387454453

Epoch: 174| Step: 0
Training loss: 1.466071605682373
Validation loss: 2.032786435978387

Epoch: 6| Step: 1
Training loss: 1.7413318157196045
Validation loss: 2.0228415484069497

Epoch: 6| Step: 2
Training loss: 1.2939658164978027
Validation loss: 2.0122427748095606

Epoch: 6| Step: 3
Training loss: 1.2407450675964355
Validation loss: 2.025198540379924

Epoch: 6| Step: 4
Training loss: 1.6808671951293945
Validation loss: 2.044787415894129

Epoch: 6| Step: 5
Training loss: 1.759927749633789
Validation loss: 2.0556126474052347

Epoch: 6| Step: 6
Training loss: 1.160055160522461
Validation loss: 2.062947691127818

Epoch: 6| Step: 7
Training loss: 0.8493028879165649
Validation loss: 2.0537345896485033

Epoch: 6| Step: 8
Training loss: 1.3925023078918457
Validation loss: 2.0579230477732997

Epoch: 6| Step: 9
Training loss: 1.7742761373519897
Validation loss: 2.0503071790100424

Epoch: 6| Step: 10
Training loss: 1.2188929319381714
Validation loss: 2.058262924994192

Epoch: 6| Step: 11
Training loss: 1.140866756439209
Validation loss: 2.046616162023237

Epoch: 6| Step: 12
Training loss: 1.1068087816238403
Validation loss: 2.040617122445055

Epoch: 6| Step: 13
Training loss: 1.5020051002502441
Validation loss: 2.0487026886273454

Epoch: 175| Step: 0
Training loss: 0.8883234858512878
Validation loss: 2.067579177118117

Epoch: 6| Step: 1
Training loss: 0.8936032056808472
Validation loss: 2.0839238653900805

Epoch: 6| Step: 2
Training loss: 1.5662095546722412
Validation loss: 2.0936306920102847

Epoch: 6| Step: 3
Training loss: 1.0819251537322998
Validation loss: 2.0659218488201017

Epoch: 6| Step: 4
Training loss: 1.3473280668258667
Validation loss: 2.061541211220526

Epoch: 6| Step: 5
Training loss: 1.1642446517944336
Validation loss: 2.0575759257039716

Epoch: 6| Step: 6
Training loss: 1.0010340213775635
Validation loss: 2.0620019769155853

Epoch: 6| Step: 7
Training loss: 1.2632431983947754
Validation loss: 2.0839586604026055

Epoch: 6| Step: 8
Training loss: 1.4757556915283203
Validation loss: 2.077092598843318

Epoch: 6| Step: 9
Training loss: 1.6249864101409912
Validation loss: 2.1108381389289774

Epoch: 6| Step: 10
Training loss: 1.582634449005127
Validation loss: 2.083602072090231

Epoch: 6| Step: 11
Training loss: 2.3051795959472656
Validation loss: 2.0774290946222123

Epoch: 6| Step: 12
Training loss: 1.5748302936553955
Validation loss: 2.063180920898273

Epoch: 6| Step: 13
Training loss: 1.4364427328109741
Validation loss: 2.080539470077843

Epoch: 176| Step: 0
Training loss: 0.8651219606399536
Validation loss: 2.074184151105983

Epoch: 6| Step: 1
Training loss: 1.4694852828979492
Validation loss: 2.1031440252898843

Epoch: 6| Step: 2
Training loss: 1.594376802444458
Validation loss: 2.0959754220901

Epoch: 6| Step: 3
Training loss: 1.2146177291870117
Validation loss: 2.13467139069752

Epoch: 6| Step: 4
Training loss: 1.3499321937561035
Validation loss: 2.157933524859849

Epoch: 6| Step: 5
Training loss: 1.3788378238677979
Validation loss: 2.1219341011457544

Epoch: 6| Step: 6
Training loss: 1.2837413549423218
Validation loss: 2.141909945395685

Epoch: 6| Step: 7
Training loss: 1.7514400482177734
Validation loss: 2.116811239591209

Epoch: 6| Step: 8
Training loss: 0.7875297665596008
Validation loss: 2.0970682174928728

Epoch: 6| Step: 9
Training loss: 1.6020817756652832
Validation loss: 2.0994269745324248

Epoch: 6| Step: 10
Training loss: 1.6412889957427979
Validation loss: 2.074294494044396

Epoch: 6| Step: 11
Training loss: 1.4934629201889038
Validation loss: 2.0499016854070846

Epoch: 6| Step: 12
Training loss: 1.5098005533218384
Validation loss: 2.0315712241716284

Epoch: 6| Step: 13
Training loss: 0.9548088908195496
Validation loss: 2.007294959919427

Epoch: 177| Step: 0
Training loss: 1.4787253141403198
Validation loss: 1.9926839977182367

Epoch: 6| Step: 1
Training loss: 1.2095541954040527
Validation loss: 2.0122588296090402

Epoch: 6| Step: 2
Training loss: 1.5916322469711304
Validation loss: 1.9941117353336786

Epoch: 6| Step: 3
Training loss: 1.2115601301193237
Validation loss: 2.0182041827068535

Epoch: 6| Step: 4
Training loss: 1.3983145952224731
Validation loss: 2.031216808544692

Epoch: 6| Step: 5
Training loss: 1.343146800994873
Validation loss: 2.017615839999209

Epoch: 6| Step: 6
Training loss: 1.3122776746749878
Validation loss: 2.034836635794691

Epoch: 6| Step: 7
Training loss: 1.1877094507217407
Validation loss: 2.0205826477337907

Epoch: 6| Step: 8
Training loss: 1.2592792510986328
Validation loss: 2.012306854289065

Epoch: 6| Step: 9
Training loss: 1.0504703521728516
Validation loss: 2.0196302231921943

Epoch: 6| Step: 10
Training loss: 1.5933563709259033
Validation loss: 2.020329067783971

Epoch: 6| Step: 11
Training loss: 1.404500961303711
Validation loss: 1.9871503742792274

Epoch: 6| Step: 12
Training loss: 1.599599003791809
Validation loss: 2.000074625015259

Epoch: 6| Step: 13
Training loss: 0.9968990683555603
Validation loss: 2.0005840845005487

Epoch: 178| Step: 0
Training loss: 1.5989723205566406
Validation loss: 1.9961914823901268

Epoch: 6| Step: 1
Training loss: 0.8596698045730591
Validation loss: 2.0157288864094722

Epoch: 6| Step: 2
Training loss: 1.0006847381591797
Validation loss: 2.0174749384644213

Epoch: 6| Step: 3
Training loss: 0.9603524208068848
Validation loss: 2.0401797012616227

Epoch: 6| Step: 4
Training loss: 1.4102494716644287
Validation loss: 2.0748390472063454

Epoch: 6| Step: 5
Training loss: 1.1046195030212402
Validation loss: 2.096246209195865

Epoch: 6| Step: 6
Training loss: 1.6777665615081787
Validation loss: 2.0960851318092755

Epoch: 6| Step: 7
Training loss: 1.6328264474868774
Validation loss: 2.106235557986844

Epoch: 6| Step: 8
Training loss: 1.2498650550842285
Validation loss: 2.104216787122911

Epoch: 6| Step: 9
Training loss: 1.5396606922149658
Validation loss: 2.122961139166227

Epoch: 6| Step: 10
Training loss: 1.1442617177963257
Validation loss: 2.1380801662322013

Epoch: 6| Step: 11
Training loss: 1.544440507888794
Validation loss: 2.089293735001677

Epoch: 6| Step: 12
Training loss: 1.5801137685775757
Validation loss: 2.080589284179031

Epoch: 6| Step: 13
Training loss: 1.0139492750167847
Validation loss: 2.0786654116005026

Epoch: 179| Step: 0
Training loss: 1.5239086151123047
Validation loss: 2.0810917961981987

Epoch: 6| Step: 1
Training loss: 1.4456230401992798
Validation loss: 2.095409684283759

Epoch: 6| Step: 2
Training loss: 1.3841010332107544
Validation loss: 2.076189523102135

Epoch: 6| Step: 3
Training loss: 1.0779714584350586
Validation loss: 2.0540421957610757

Epoch: 6| Step: 4
Training loss: 1.496530294418335
Validation loss: 2.037149762594572

Epoch: 6| Step: 5
Training loss: 0.8338313102722168
Validation loss: 2.034802714983622

Epoch: 6| Step: 6
Training loss: 1.2522798776626587
Validation loss: 2.036478063111664

Epoch: 6| Step: 7
Training loss: 1.1876839399337769
Validation loss: 2.000853782059044

Epoch: 6| Step: 8
Training loss: 1.5201014280319214
Validation loss: 2.023138689738448

Epoch: 6| Step: 9
Training loss: 1.4324452877044678
Validation loss: 1.9953029565913702

Epoch: 6| Step: 10
Training loss: 1.5405547618865967
Validation loss: 1.9742636488329979

Epoch: 6| Step: 11
Training loss: 1.0949058532714844
Validation loss: 1.9727084034232683

Epoch: 6| Step: 12
Training loss: 1.746814489364624
Validation loss: 1.980955118774086

Epoch: 6| Step: 13
Training loss: 0.9320948123931885
Validation loss: 1.9848355195855583

Epoch: 180| Step: 0
Training loss: 1.2312040328979492
Validation loss: 1.981615210092196

Epoch: 6| Step: 1
Training loss: 1.2473413944244385
Validation loss: 1.9923032201746458

Epoch: 6| Step: 2
Training loss: 1.5277506113052368
Validation loss: 1.9873632795067244

Epoch: 6| Step: 3
Training loss: 0.9522562026977539
Validation loss: 1.985731171023461

Epoch: 6| Step: 4
Training loss: 1.5809285640716553
Validation loss: 1.9892187964531682

Epoch: 6| Step: 5
Training loss: 1.4849437475204468
Validation loss: 1.9977583782647246

Epoch: 6| Step: 6
Training loss: 1.3231971263885498
Validation loss: 2.031291123359434

Epoch: 6| Step: 7
Training loss: 1.4347290992736816
Validation loss: 2.0424093225950837

Epoch: 6| Step: 8
Training loss: 0.7772603034973145
Validation loss: 2.0354417011302006

Epoch: 6| Step: 9
Training loss: 1.0276439189910889
Validation loss: 2.063202437534127

Epoch: 6| Step: 10
Training loss: 2.152418613433838
Validation loss: 2.0504553407751103

Epoch: 6| Step: 11
Training loss: 0.902750551700592
Validation loss: 2.06759480250779

Epoch: 6| Step: 12
Training loss: 0.7177504301071167
Validation loss: 2.0928021015659457

Epoch: 6| Step: 13
Training loss: 1.5334476232528687
Validation loss: 2.082176887860862

Epoch: 181| Step: 0
Training loss: 1.2556946277618408
Validation loss: 2.058243824589637

Epoch: 6| Step: 1
Training loss: 0.9259822964668274
Validation loss: 2.057835530209285

Epoch: 6| Step: 2
Training loss: 0.8810551762580872
Validation loss: 2.037277038379382

Epoch: 6| Step: 3
Training loss: 1.3265063762664795
Validation loss: 2.0210570212333434

Epoch: 6| Step: 4
Training loss: 1.2800993919372559
Validation loss: 2.029009760067027

Epoch: 6| Step: 5
Training loss: 1.9013410806655884
Validation loss: 2.009772180229105

Epoch: 6| Step: 6
Training loss: 1.6239770650863647
Validation loss: 2.0108181250992643

Epoch: 6| Step: 7
Training loss: 1.1777970790863037
Validation loss: 1.9889093470829788

Epoch: 6| Step: 8
Training loss: 0.8544977307319641
Validation loss: 1.9827646106802008

Epoch: 6| Step: 9
Training loss: 1.7687737941741943
Validation loss: 1.9911208280953028

Epoch: 6| Step: 10
Training loss: 1.2609248161315918
Validation loss: 1.963872677536421

Epoch: 6| Step: 11
Training loss: 1.454593300819397
Validation loss: 1.9751448233922322

Epoch: 6| Step: 12
Training loss: 1.0203402042388916
Validation loss: 1.9692066997610114

Epoch: 6| Step: 13
Training loss: 1.35287606716156
Validation loss: 2.0304209878367763

Epoch: 182| Step: 0
Training loss: 1.2458901405334473
Validation loss: 2.035879745278307

Epoch: 6| Step: 1
Training loss: 1.1203444004058838
Validation loss: 2.0438664010775986

Epoch: 6| Step: 2
Training loss: 1.2330137491226196
Validation loss: 2.0893616189238844

Epoch: 6| Step: 3
Training loss: 1.3779871463775635
Validation loss: 2.1372722835950952

Epoch: 6| Step: 4
Training loss: 1.5661156177520752
Validation loss: 2.1241530410705076

Epoch: 6| Step: 5
Training loss: 1.200999140739441
Validation loss: 2.123507204876151

Epoch: 6| Step: 6
Training loss: 1.0787663459777832
Validation loss: 2.13499790622342

Epoch: 6| Step: 7
Training loss: 1.3750079870224
Validation loss: 2.0742780213714926

Epoch: 6| Step: 8
Training loss: 1.4372735023498535
Validation loss: 2.043517804914905

Epoch: 6| Step: 9
Training loss: 1.0195903778076172
Validation loss: 2.0298961439440326

Epoch: 6| Step: 10
Training loss: 1.0581480264663696
Validation loss: 2.030760811221215

Epoch: 6| Step: 11
Training loss: 1.1629139184951782
Validation loss: 2.0169340871995494

Epoch: 6| Step: 12
Training loss: 1.4934682846069336
Validation loss: 2.0042668773281958

Epoch: 6| Step: 13
Training loss: 1.2775064706802368
Validation loss: 2.001253648470807

Epoch: 183| Step: 0
Training loss: 1.1651084423065186
Validation loss: 2.014052270561136

Epoch: 6| Step: 1
Training loss: 0.6882668733596802
Validation loss: 1.9858922432827693

Epoch: 6| Step: 2
Training loss: 1.5023219585418701
Validation loss: 2.011081052082841

Epoch: 6| Step: 3
Training loss: 1.0091521739959717
Validation loss: 2.0017526342022802

Epoch: 6| Step: 4
Training loss: 1.0035942792892456
Validation loss: 1.998048625966554

Epoch: 6| Step: 5
Training loss: 0.9833946824073792
Validation loss: 2.0160275069616174

Epoch: 6| Step: 6
Training loss: 1.3003826141357422
Validation loss: 1.997590244457286

Epoch: 6| Step: 7
Training loss: 1.67872154712677
Validation loss: 2.016226681329871

Epoch: 6| Step: 8
Training loss: 1.8078434467315674
Validation loss: 2.0142673677013767

Epoch: 6| Step: 9
Training loss: 1.4869308471679688
Validation loss: 2.020728732949944

Epoch: 6| Step: 10
Training loss: 1.1525838375091553
Validation loss: 2.0305640434706085

Epoch: 6| Step: 11
Training loss: 1.2568564414978027
Validation loss: 2.0132644791756906

Epoch: 6| Step: 12
Training loss: 0.9324770569801331
Validation loss: 2.0068808742748794

Epoch: 6| Step: 13
Training loss: 1.2778358459472656
Validation loss: 2.0233347877379386

Epoch: 184| Step: 0
Training loss: 1.2393383979797363
Validation loss: 2.017568172947053

Epoch: 6| Step: 1
Training loss: 1.1432665586471558
Validation loss: 2.0135745156195854

Epoch: 6| Step: 2
Training loss: 1.0117952823638916
Validation loss: 2.0115683091584073

Epoch: 6| Step: 3
Training loss: 1.066864252090454
Validation loss: 1.9992780762334024

Epoch: 6| Step: 4
Training loss: 1.288667917251587
Validation loss: 1.9923103265864874

Epoch: 6| Step: 5
Training loss: 1.1798038482666016
Validation loss: 2.0004477648324865

Epoch: 6| Step: 6
Training loss: 1.1396548748016357
Validation loss: 1.984123601708361

Epoch: 6| Step: 7
Training loss: 1.1040472984313965
Validation loss: 1.994939265712615

Epoch: 6| Step: 8
Training loss: 0.7840309143066406
Validation loss: 1.9912129640579224

Epoch: 6| Step: 9
Training loss: 1.2840244770050049
Validation loss: 2.0190461681735132

Epoch: 6| Step: 10
Training loss: 1.5370526313781738
Validation loss: 2.033730472287824

Epoch: 6| Step: 11
Training loss: 1.7113072872161865
Validation loss: 2.052007685425461

Epoch: 6| Step: 12
Training loss: 1.5102683305740356
Validation loss: 2.0984584746822232

Epoch: 6| Step: 13
Training loss: 1.4503332376480103
Validation loss: 2.09498082950551

Epoch: 185| Step: 0
Training loss: 1.3894274234771729
Validation loss: 2.0745413713557745

Epoch: 6| Step: 1
Training loss: 1.5653945207595825
Validation loss: 2.0887401693610737

Epoch: 6| Step: 2
Training loss: 1.203115701675415
Validation loss: 2.0724888834902035

Epoch: 6| Step: 3
Training loss: 1.1832917928695679
Validation loss: 2.05318259808325

Epoch: 6| Step: 4
Training loss: 0.9837154150009155
Validation loss: 2.058337410291036

Epoch: 6| Step: 5
Training loss: 1.0446542501449585
Validation loss: 2.053908254510613

Epoch: 6| Step: 6
Training loss: 1.4110405445098877
Validation loss: 2.040636808641495

Epoch: 6| Step: 7
Training loss: 1.7345155477523804
Validation loss: 2.0327817983524774

Epoch: 6| Step: 8
Training loss: 1.1652740240097046
Validation loss: 2.022583979432301

Epoch: 6| Step: 9
Training loss: 1.1299617290496826
Validation loss: 2.0081440812797955

Epoch: 6| Step: 10
Training loss: 0.8255534172058105
Validation loss: 1.998868098822973

Epoch: 6| Step: 11
Training loss: 1.0152852535247803
Validation loss: 1.997626296935543

Epoch: 6| Step: 12
Training loss: 1.2085214853286743
Validation loss: 2.0091504666113083

Epoch: 6| Step: 13
Training loss: 1.2474124431610107
Validation loss: 2.000629937776955

Epoch: 186| Step: 0
Training loss: 0.902475118637085
Validation loss: 2.0162850810635473

Epoch: 6| Step: 1
Training loss: 0.8169721364974976
Validation loss: 1.9998723691509617

Epoch: 6| Step: 2
Training loss: 0.9792568683624268
Validation loss: 2.0468665066585747

Epoch: 6| Step: 3
Training loss: 1.9292881488800049
Validation loss: 2.036519271071239

Epoch: 6| Step: 4
Training loss: 1.1049518585205078
Validation loss: 2.061528326362692

Epoch: 6| Step: 5
Training loss: 1.0396547317504883
Validation loss: 2.0677890431496406

Epoch: 6| Step: 6
Training loss: 1.3341748714447021
Validation loss: 2.0444646496926584

Epoch: 6| Step: 7
Training loss: 0.9550467729568481
Validation loss: 2.022684176762899

Epoch: 6| Step: 8
Training loss: 1.2011902332305908
Validation loss: 2.0152815477822417

Epoch: 6| Step: 9
Training loss: 0.8776782751083374
Validation loss: 1.9846633711168844

Epoch: 6| Step: 10
Training loss: 1.5945900678634644
Validation loss: 1.9984047861509426

Epoch: 6| Step: 11
Training loss: 1.025038480758667
Validation loss: 1.9936065135463592

Epoch: 6| Step: 12
Training loss: 1.8480675220489502
Validation loss: 2.005880637835431

Epoch: 6| Step: 13
Training loss: 1.2398159503936768
Validation loss: 2.013971831208916

Epoch: 187| Step: 0
Training loss: 1.3312571048736572
Validation loss: 2.0094518302589335

Epoch: 6| Step: 1
Training loss: 0.8396740555763245
Validation loss: 2.0360404676006687

Epoch: 6| Step: 2
Training loss: 0.6401653289794922
Validation loss: 2.0213012233857186

Epoch: 6| Step: 3
Training loss: 1.087169885635376
Validation loss: 2.05708570121437

Epoch: 6| Step: 4
Training loss: 0.8173863887786865
Validation loss: 2.0535669762601136

Epoch: 6| Step: 5
Training loss: 1.2417739629745483
Validation loss: 2.0894783235365346

Epoch: 6| Step: 6
Training loss: 1.3845887184143066
Validation loss: 2.105094104684809

Epoch: 6| Step: 7
Training loss: 1.02507483959198
Validation loss: 2.0851138919912358

Epoch: 6| Step: 8
Training loss: 1.2632057666778564
Validation loss: 2.103443189333844

Epoch: 6| Step: 9
Training loss: 1.1958229541778564
Validation loss: 2.0974221691008537

Epoch: 6| Step: 10
Training loss: 1.1835408210754395
Validation loss: 2.1025513807932534

Epoch: 6| Step: 11
Training loss: 2.042374610900879
Validation loss: 2.1001075160118843

Epoch: 6| Step: 12
Training loss: 1.0895893573760986
Validation loss: 2.10525341187754

Epoch: 6| Step: 13
Training loss: 1.3321353197097778
Validation loss: 2.0715258147126887

Epoch: 188| Step: 0
Training loss: 1.2467930316925049
Validation loss: 2.0529683559171614

Epoch: 6| Step: 1
Training loss: 1.205446720123291
Validation loss: 2.0240278320927776

Epoch: 6| Step: 2
Training loss: 1.0724761486053467
Validation loss: 2.0125736446790796

Epoch: 6| Step: 3
Training loss: 1.1643829345703125
Validation loss: 2.005176264752624

Epoch: 6| Step: 4
Training loss: 1.270493984222412
Validation loss: 2.013268207990995

Epoch: 6| Step: 5
Training loss: 1.5014342069625854
Validation loss: 2.0168228815960627

Epoch: 6| Step: 6
Training loss: 0.9277161359786987
Validation loss: 2.006022653272075

Epoch: 6| Step: 7
Training loss: 1.3792661428451538
Validation loss: 2.0017011319437334

Epoch: 6| Step: 8
Training loss: 0.8007420897483826
Validation loss: 1.9916427571286437

Epoch: 6| Step: 9
Training loss: 1.0410356521606445
Validation loss: 1.9885216541187738

Epoch: 6| Step: 10
Training loss: 1.091006875038147
Validation loss: 1.9900322780814221

Epoch: 6| Step: 11
Training loss: 0.8299474716186523
Validation loss: 2.007671353637531

Epoch: 6| Step: 12
Training loss: 1.7423710823059082
Validation loss: 2.0432842341802453

Epoch: 6| Step: 13
Training loss: 1.05348801612854
Validation loss: 2.0781014119425127

Epoch: 189| Step: 0
Training loss: 0.8575235605239868
Validation loss: 2.1026199145983626

Epoch: 6| Step: 1
Training loss: 1.17023503780365
Validation loss: 2.1290708049651115

Epoch: 6| Step: 2
Training loss: 1.1313624382019043
Validation loss: 2.135968795386694

Epoch: 6| Step: 3
Training loss: 0.9615234136581421
Validation loss: 2.1350134265038276

Epoch: 6| Step: 4
Training loss: 1.3061234951019287
Validation loss: 2.0916719821191605

Epoch: 6| Step: 5
Training loss: 1.8152283430099487
Validation loss: 2.023181756337484

Epoch: 6| Step: 6
Training loss: 1.2264200448989868
Validation loss: 2.013457190605902

Epoch: 6| Step: 7
Training loss: 1.6139235496520996
Validation loss: 1.9868060529872935

Epoch: 6| Step: 8
Training loss: 1.7292524576187134
Validation loss: 1.9854312481418732

Epoch: 6| Step: 9
Training loss: 0.7568743824958801
Validation loss: 1.9823061599526355

Epoch: 6| Step: 10
Training loss: 1.388036847114563
Validation loss: 1.9801882133688977

Epoch: 6| Step: 11
Training loss: 1.1189727783203125
Validation loss: 1.9798119580873879

Epoch: 6| Step: 12
Training loss: 1.2871081829071045
Validation loss: 2.0058784472045077

Epoch: 6| Step: 13
Training loss: 1.3205087184906006
Validation loss: 2.008161549927086

Epoch: 190| Step: 0
Training loss: 0.995083212852478
Validation loss: 2.0066866592694352

Epoch: 6| Step: 1
Training loss: 0.902947187423706
Validation loss: 2.043087590125299

Epoch: 6| Step: 2
Training loss: 1.4528950452804565
Validation loss: 2.026650649245067

Epoch: 6| Step: 3
Training loss: 1.4898381233215332
Validation loss: 2.0632580954541444

Epoch: 6| Step: 4
Training loss: 1.2079308032989502
Validation loss: 2.0751253430561354

Epoch: 6| Step: 5
Training loss: 1.4394962787628174
Validation loss: 2.033675750096639

Epoch: 6| Step: 6
Training loss: 1.0074055194854736
Validation loss: 2.0547351068066013

Epoch: 6| Step: 7
Training loss: 0.7354615926742554
Validation loss: 2.064274118792626

Epoch: 6| Step: 8
Training loss: 1.9449808597564697
Validation loss: 2.0899016575146745

Epoch: 6| Step: 9
Training loss: 1.0059236288070679
Validation loss: 2.1187360876349994

Epoch: 6| Step: 10
Training loss: 1.4866067171096802
Validation loss: 2.13906104077575

Epoch: 6| Step: 11
Training loss: 1.4848341941833496
Validation loss: 2.132346301950434

Epoch: 6| Step: 12
Training loss: 0.5588676929473877
Validation loss: 2.117967777354743

Epoch: 6| Step: 13
Training loss: 0.7288143038749695
Validation loss: 2.0867141216031966

Epoch: 191| Step: 0
Training loss: 1.3671380281448364
Validation loss: 2.0693527178097795

Epoch: 6| Step: 1
Training loss: 1.4287781715393066
Validation loss: 2.0567539430433706

Epoch: 6| Step: 2
Training loss: 1.177743911743164
Validation loss: 2.0222650394644788

Epoch: 6| Step: 3
Training loss: 1.2172608375549316
Validation loss: 2.0058179927128617

Epoch: 6| Step: 4
Training loss: 0.8813619017601013
Validation loss: 1.9919325382478776

Epoch: 6| Step: 5
Training loss: 0.9862155914306641
Validation loss: 2.0145543698341615

Epoch: 6| Step: 6
Training loss: 1.0837182998657227
Validation loss: 1.9785929264560822

Epoch: 6| Step: 7
Training loss: 1.25999116897583
Validation loss: 1.9301465993286462

Epoch: 6| Step: 8
Training loss: 0.9656540751457214
Validation loss: 1.9155973478030133

Epoch: 6| Step: 9
Training loss: 1.6494662761688232
Validation loss: 1.9307295942819247

Epoch: 6| Step: 10
Training loss: 1.0479862689971924
Validation loss: 1.951456964656871

Epoch: 6| Step: 11
Training loss: 1.1474740505218506
Validation loss: 1.973108330080586

Epoch: 6| Step: 12
Training loss: 1.1609231233596802
Validation loss: 1.979618501919572

Epoch: 6| Step: 13
Training loss: 1.128801703453064
Validation loss: 2.008372675987982

Epoch: 192| Step: 0
Training loss: 1.5768439769744873
Validation loss: 2.0460044799312467

Epoch: 6| Step: 1
Training loss: 0.6041621565818787
Validation loss: 2.0638964919633764

Epoch: 6| Step: 2
Training loss: 0.832779586315155
Validation loss: 2.0675673228438183

Epoch: 6| Step: 3
Training loss: 1.4684027433395386
Validation loss: 2.056803946853966

Epoch: 6| Step: 4
Training loss: 1.3218193054199219
Validation loss: 2.021672110403738

Epoch: 6| Step: 5
Training loss: 0.7610865831375122
Validation loss: 2.0233403816018054

Epoch: 6| Step: 6
Training loss: 1.3288078308105469
Validation loss: 2.0232509387436735

Epoch: 6| Step: 7
Training loss: 1.3830139636993408
Validation loss: 2.0098667324230237

Epoch: 6| Step: 8
Training loss: 1.1843507289886475
Validation loss: 2.0111915091032624

Epoch: 6| Step: 9
Training loss: 1.342790126800537
Validation loss: 1.988835116868378

Epoch: 6| Step: 10
Training loss: 0.9047860503196716
Validation loss: 1.9656278176974225

Epoch: 6| Step: 11
Training loss: 1.2215991020202637
Validation loss: 1.9893328976887528

Epoch: 6| Step: 12
Training loss: 0.6923303604125977
Validation loss: 1.993225766766456

Epoch: 6| Step: 13
Training loss: 1.0419249534606934
Validation loss: 2.022437139223981

Epoch: 193| Step: 0
Training loss: 0.9226045608520508
Validation loss: 1.999148887972678

Epoch: 6| Step: 1
Training loss: 1.0229334831237793
Validation loss: 2.011896910205964

Epoch: 6| Step: 2
Training loss: 1.1392874717712402
Validation loss: 2.0269197981844664

Epoch: 6| Step: 3
Training loss: 0.9499979019165039
Validation loss: 2.023439643203571

Epoch: 6| Step: 4
Training loss: 1.047914743423462
Validation loss: 2.0389499920670704

Epoch: 6| Step: 5
Training loss: 0.7467982769012451
Validation loss: 2.075358365171699

Epoch: 6| Step: 6
Training loss: 1.372856855392456
Validation loss: 2.071191022472997

Epoch: 6| Step: 7
Training loss: 1.1129331588745117
Validation loss: 2.06757318012176

Epoch: 6| Step: 8
Training loss: 1.0235525369644165
Validation loss: 2.0856142300431446

Epoch: 6| Step: 9
Training loss: 1.4206957817077637
Validation loss: 2.07508611166349

Epoch: 6| Step: 10
Training loss: 1.3425443172454834
Validation loss: 2.038607315350604

Epoch: 6| Step: 11
Training loss: 1.369344711303711
Validation loss: 2.035341934491229

Epoch: 6| Step: 12
Training loss: 0.6648008823394775
Validation loss: 2.0041666607702933

Epoch: 6| Step: 13
Training loss: 1.3179277181625366
Validation loss: 2.0222268386553695

Epoch: 194| Step: 0
Training loss: 1.1630738973617554
Validation loss: 2.027155900514254

Epoch: 6| Step: 1
Training loss: 1.4305121898651123
Validation loss: 2.0303449925555976

Epoch: 6| Step: 2
Training loss: 0.9926743507385254
Validation loss: 2.0697157306055867

Epoch: 6| Step: 3
Training loss: 1.3924131393432617
Validation loss: 2.071560962225801

Epoch: 6| Step: 4
Training loss: 0.8763550519943237
Validation loss: 2.0785803038586854

Epoch: 6| Step: 5
Training loss: 1.1159133911132812
Validation loss: 2.08921839088522

Epoch: 6| Step: 6
Training loss: 1.0891486406326294
Validation loss: 2.076565668147097

Epoch: 6| Step: 7
Training loss: 1.126774549484253
Validation loss: 2.0531903774507585

Epoch: 6| Step: 8
Training loss: 0.78741455078125
Validation loss: 2.0042782086198048

Epoch: 6| Step: 9
Training loss: 0.8283513188362122
Validation loss: 1.991054586184922

Epoch: 6| Step: 10
Training loss: 0.8263691663742065
Validation loss: 1.990536751285676

Epoch: 6| Step: 11
Training loss: 1.135544776916504
Validation loss: 1.9822915984738259

Epoch: 6| Step: 12
Training loss: 1.0839340686798096
Validation loss: 1.9592243074088969

Epoch: 6| Step: 13
Training loss: 0.9598708748817444
Validation loss: 1.9741134079553748

Epoch: 195| Step: 0
Training loss: 1.057073950767517
Validation loss: 1.9698252447189823

Epoch: 6| Step: 1
Training loss: 1.091058373451233
Validation loss: 1.9909006293101976

Epoch: 6| Step: 2
Training loss: 0.8603338599205017
Validation loss: 2.0130194899856404

Epoch: 6| Step: 3
Training loss: 0.7175508737564087
Validation loss: 2.044111277467461

Epoch: 6| Step: 4
Training loss: 1.4982637166976929
Validation loss: 2.097365898470725

Epoch: 6| Step: 5
Training loss: 0.7921584844589233
Validation loss: 2.1227030343906854

Epoch: 6| Step: 6
Training loss: 1.1100802421569824
Validation loss: 2.1082249764473207

Epoch: 6| Step: 7
Training loss: 1.260816216468811
Validation loss: 2.1005610291675856

Epoch: 6| Step: 8
Training loss: 0.9114344120025635
Validation loss: 2.074998850463539

Epoch: 6| Step: 9
Training loss: 0.6605598330497742
Validation loss: 2.0640927360903834

Epoch: 6| Step: 10
Training loss: 1.4330792427062988
Validation loss: 2.048533388363418

Epoch: 6| Step: 11
Training loss: 1.2733585834503174
Validation loss: 2.018273829131998

Epoch: 6| Step: 12
Training loss: 1.7261364459991455
Validation loss: 2.0182210296712895

Epoch: 6| Step: 13
Training loss: 0.31240761280059814
Validation loss: 1.980150807288385

Epoch: 196| Step: 0
Training loss: 0.6035849452018738
Validation loss: 1.9604814116672804

Epoch: 6| Step: 1
Training loss: 1.4180558919906616
Validation loss: 1.9492859353301346

Epoch: 6| Step: 2
Training loss: 1.2452166080474854
Validation loss: 1.9319158497677054

Epoch: 6| Step: 3
Training loss: 1.1026740074157715
Validation loss: 1.9182501390416136

Epoch: 6| Step: 4
Training loss: 1.409914493560791
Validation loss: 1.910216103317917

Epoch: 6| Step: 5
Training loss: 1.0708298683166504
Validation loss: 1.911420960580149

Epoch: 6| Step: 6
Training loss: 0.9673646688461304
Validation loss: 1.9422491147953977

Epoch: 6| Step: 7
Training loss: 0.8652846813201904
Validation loss: 1.9658204637547976

Epoch: 6| Step: 8
Training loss: 0.5759508609771729
Validation loss: 1.962617710072507

Epoch: 6| Step: 9
Training loss: 1.2759591341018677
Validation loss: 1.9988983856734408

Epoch: 6| Step: 10
Training loss: 0.9224362969398499
Validation loss: 1.989961725409313

Epoch: 6| Step: 11
Training loss: 1.1409786939620972
Validation loss: 1.9962840003352011

Epoch: 6| Step: 12
Training loss: 0.9419553279876709
Validation loss: 2.006069771705135

Epoch: 6| Step: 13
Training loss: 1.461430311203003
Validation loss: 1.9921516833766815

Epoch: 197| Step: 0
Training loss: 0.9594162702560425
Validation loss: 1.972848533302225

Epoch: 6| Step: 1
Training loss: 1.2338554859161377
Validation loss: 1.9306409205159833

Epoch: 6| Step: 2
Training loss: 0.5727928280830383
Validation loss: 1.9505826632181804

Epoch: 6| Step: 3
Training loss: 0.900573194026947
Validation loss: 1.9356999653641895

Epoch: 6| Step: 4
Training loss: 1.4280385971069336
Validation loss: 1.9503776334947156

Epoch: 6| Step: 5
Training loss: 1.2980506420135498
Validation loss: 1.9611436795162898

Epoch: 6| Step: 6
Training loss: 0.8603650331497192
Validation loss: 1.9721530663069857

Epoch: 6| Step: 7
Training loss: 1.3202362060546875
Validation loss: 1.957583433838301

Epoch: 6| Step: 8
Training loss: 1.177757978439331
Validation loss: 1.957209449942394

Epoch: 6| Step: 9
Training loss: 0.8340778350830078
Validation loss: 1.974870595880734

Epoch: 6| Step: 10
Training loss: 0.8831506371498108
Validation loss: 1.9865557121974167

Epoch: 6| Step: 11
Training loss: 1.2109482288360596
Validation loss: 2.035445018481183

Epoch: 6| Step: 12
Training loss: 0.8823143243789673
Validation loss: 2.0368092803544897

Epoch: 6| Step: 13
Training loss: 0.6564884185791016
Validation loss: 2.032428474836452

Epoch: 198| Step: 0
Training loss: 0.9208055138587952
Validation loss: 2.037703001370994

Epoch: 6| Step: 1
Training loss: 0.854363739490509
Validation loss: 2.05620305256177

Epoch: 6| Step: 2
Training loss: 1.0108566284179688
Validation loss: 2.047082115245122

Epoch: 6| Step: 3
Training loss: 1.3099212646484375
Validation loss: 2.0549061170188327

Epoch: 6| Step: 4
Training loss: 1.2144691944122314
Validation loss: 2.032997133911297

Epoch: 6| Step: 5
Training loss: 0.9252097010612488
Validation loss: 2.0265439415490754

Epoch: 6| Step: 6
Training loss: 0.948549747467041
Validation loss: 2.041388319384667

Epoch: 6| Step: 7
Training loss: 1.1070307493209839
Validation loss: 2.0162419721644413

Epoch: 6| Step: 8
Training loss: 0.8244109749794006
Validation loss: 2.0475934513153566

Epoch: 6| Step: 9
Training loss: 0.769573450088501
Validation loss: 2.032665019394249

Epoch: 6| Step: 10
Training loss: 0.9100963473320007
Validation loss: 2.0382486286983696

Epoch: 6| Step: 11
Training loss: 0.7306201457977295
Validation loss: 2.059360291368218

Epoch: 6| Step: 12
Training loss: 1.5290684700012207
Validation loss: 2.082552147167985

Epoch: 6| Step: 13
Training loss: 1.2829478979110718
Validation loss: 2.0848082060454995

Epoch: 199| Step: 0
Training loss: 0.6564826965332031
Validation loss: 2.0803008412802093

Epoch: 6| Step: 1
Training loss: 0.7544621825218201
Validation loss: 2.039840159877654

Epoch: 6| Step: 2
Training loss: 0.9268004298210144
Validation loss: 2.0169210844142462

Epoch: 6| Step: 3
Training loss: 1.8213579654693604
Validation loss: 1.983866919753372

Epoch: 6| Step: 4
Training loss: 1.2464616298675537
Validation loss: 1.948563132234799

Epoch: 6| Step: 5
Training loss: 1.1671245098114014
Validation loss: 1.9775362245498165

Epoch: 6| Step: 6
Training loss: 0.8287066221237183
Validation loss: 1.9570833201049476

Epoch: 6| Step: 7
Training loss: 0.9470385313034058
Validation loss: 2.0019655714752855

Epoch: 6| Step: 8
Training loss: 0.8937870860099792
Validation loss: 1.9793830981818579

Epoch: 6| Step: 9
Training loss: 1.0343676805496216
Validation loss: 1.9757435860172394

Epoch: 6| Step: 10
Training loss: 0.9186646938323975
Validation loss: 1.9727299674864738

Epoch: 6| Step: 11
Training loss: 0.4809529483318329
Validation loss: 1.977005700911245

Epoch: 6| Step: 12
Training loss: 0.9749407172203064
Validation loss: 1.9484230369649909

Epoch: 6| Step: 13
Training loss: 1.7401297092437744
Validation loss: 1.964467570345889

Epoch: 200| Step: 0
Training loss: 0.9900809526443481
Validation loss: 2.008925699418591

Epoch: 6| Step: 1
Training loss: 1.6341358423233032
Validation loss: 1.9684147604050175

Epoch: 6| Step: 2
Training loss: 1.2242467403411865
Validation loss: 1.9750211738771009

Epoch: 6| Step: 3
Training loss: 1.0294283628463745
Validation loss: 1.9573266044739754

Epoch: 6| Step: 4
Training loss: 0.6401690244674683
Validation loss: 1.9230987512937157

Epoch: 6| Step: 5
Training loss: 0.6488296985626221
Validation loss: 1.9357182633492254

Epoch: 6| Step: 6
Training loss: 1.2954840660095215
Validation loss: 1.937432530105755

Epoch: 6| Step: 7
Training loss: 0.7885100245475769
Validation loss: 1.9229301970492128

Epoch: 6| Step: 8
Training loss: 0.6956254243850708
Validation loss: 1.9317657152811687

Epoch: 6| Step: 9
Training loss: 0.9191140532493591
Validation loss: 1.9458297862801501

Epoch: 6| Step: 10
Training loss: 0.8958259224891663
Validation loss: 1.9336778656128915

Epoch: 6| Step: 11
Training loss: 0.6643766164779663
Validation loss: 1.9503683377337713

Epoch: 6| Step: 12
Training loss: 1.7641839981079102
Validation loss: 1.974657440698275

Epoch: 6| Step: 13
Training loss: 1.0329231023788452
Validation loss: 1.9527080879416516

Epoch: 201| Step: 0
Training loss: 0.9709134101867676
Validation loss: 1.9615474952164518

Epoch: 6| Step: 1
Training loss: 1.5336639881134033
Validation loss: 1.9767259013268255

Epoch: 6| Step: 2
Training loss: 0.8504399061203003
Validation loss: 1.97533159102163

Epoch: 6| Step: 3
Training loss: 0.9636829495429993
Validation loss: 2.008769399376326

Epoch: 6| Step: 4
Training loss: 1.1259217262268066
Validation loss: 1.9803951991501676

Epoch: 6| Step: 5
Training loss: 1.0079129934310913
Validation loss: 1.9825131790612334

Epoch: 6| Step: 6
Training loss: 1.019304633140564
Validation loss: 1.9899787800286406

Epoch: 6| Step: 7
Training loss: 0.7774978280067444
Validation loss: 1.956972788738948

Epoch: 6| Step: 8
Training loss: 0.9632700681686401
Validation loss: 1.9692325617677422

Epoch: 6| Step: 9
Training loss: 0.8027234077453613
Validation loss: 1.946960199263788

Epoch: 6| Step: 10
Training loss: 0.9001518487930298
Validation loss: 1.939766114757907

Epoch: 6| Step: 11
Training loss: 0.9610152244567871
Validation loss: 1.9541585983768586

Epoch: 6| Step: 12
Training loss: 0.7013343572616577
Validation loss: 1.947667291087489

Epoch: 6| Step: 13
Training loss: 1.129991054534912
Validation loss: 1.9407537111672022

Epoch: 202| Step: 0
Training loss: 0.9681785106658936
Validation loss: 1.9565940287805372

Epoch: 6| Step: 1
Training loss: 0.5990412831306458
Validation loss: 1.9921626737040858

Epoch: 6| Step: 2
Training loss: 0.92425537109375
Validation loss: 2.0219719832943333

Epoch: 6| Step: 3
Training loss: 1.1652851104736328
Validation loss: 1.999510290802166

Epoch: 6| Step: 4
Training loss: 1.1124740839004517
Validation loss: 2.0174097655921854

Epoch: 6| Step: 5
Training loss: 0.6595500707626343
Validation loss: 2.023009113086167

Epoch: 6| Step: 6
Training loss: 1.0564738512039185
Validation loss: 1.9995821599037416

Epoch: 6| Step: 7
Training loss: 0.5681815147399902
Validation loss: 1.9631247725538028

Epoch: 6| Step: 8
Training loss: 1.1809983253479004
Validation loss: 1.9573896931063743

Epoch: 6| Step: 9
Training loss: 0.6674747467041016
Validation loss: 1.962628577345161

Epoch: 6| Step: 10
Training loss: 0.9664259552955627
Validation loss: 1.9415313287447857

Epoch: 6| Step: 11
Training loss: 0.9481691122055054
Validation loss: 1.9317775926282328

Epoch: 6| Step: 12
Training loss: 1.8296631574630737
Validation loss: 1.9255481330297326

Epoch: 6| Step: 13
Training loss: 0.9477148056030273
Validation loss: 1.9459904355387534

Epoch: 203| Step: 0
Training loss: 0.7130319476127625
Validation loss: 1.9298549954609205

Epoch: 6| Step: 1
Training loss: 0.9369601607322693
Validation loss: 1.914243842965813

Epoch: 6| Step: 2
Training loss: 1.0276358127593994
Validation loss: 1.941598435883881

Epoch: 6| Step: 3
Training loss: 0.7582942247390747
Validation loss: 1.9311152363336215

Epoch: 6| Step: 4
Training loss: 0.8264803886413574
Validation loss: 1.9770995763040358

Epoch: 6| Step: 5
Training loss: 1.1708065271377563
Validation loss: 2.0236968404503277

Epoch: 6| Step: 6
Training loss: 0.7305314540863037
Validation loss: 2.0034360475437616

Epoch: 6| Step: 7
Training loss: 0.8883366584777832
Validation loss: 1.9894830744753602

Epoch: 6| Step: 8
Training loss: 1.0986464023590088
Validation loss: 2.012094256698444

Epoch: 6| Step: 9
Training loss: 1.3253071308135986
Validation loss: 2.0234068234761557

Epoch: 6| Step: 10
Training loss: 0.8763309717178345
Validation loss: 2.0339695356225453

Epoch: 6| Step: 11
Training loss: 0.7022028565406799
Validation loss: 2.01096171973854

Epoch: 6| Step: 12
Training loss: 1.164760708808899
Validation loss: 1.9766512199114727

Epoch: 6| Step: 13
Training loss: 1.2071300745010376
Validation loss: 1.9662379193049606

Epoch: 204| Step: 0
Training loss: 0.7490565776824951
Validation loss: 1.9717454679550663

Epoch: 6| Step: 1
Training loss: 0.9035531282424927
Validation loss: 1.9478125482477167

Epoch: 6| Step: 2
Training loss: 1.2095059156417847
Validation loss: 1.9339330042562177

Epoch: 6| Step: 3
Training loss: 1.048854947090149
Validation loss: 1.9395214165410688

Epoch: 6| Step: 4
Training loss: 1.3792245388031006
Validation loss: 1.913031510127488

Epoch: 6| Step: 5
Training loss: 1.2782210111618042
Validation loss: 1.9194128013426257

Epoch: 6| Step: 6
Training loss: 0.7448281645774841
Validation loss: 1.883990187798777

Epoch: 6| Step: 7
Training loss: 1.022930383682251
Validation loss: 1.9212649599198373

Epoch: 6| Step: 8
Training loss: 0.8894767165184021
Validation loss: 1.919933262691703

Epoch: 6| Step: 9
Training loss: 0.5181273221969604
Validation loss: 1.9012868353115615

Epoch: 6| Step: 10
Training loss: 0.7054508328437805
Validation loss: 1.9487644895430534

Epoch: 6| Step: 11
Training loss: 1.0275378227233887
Validation loss: 1.9606492827015538

Epoch: 6| Step: 12
Training loss: 0.7815849781036377
Validation loss: 1.9866542559798046

Epoch: 6| Step: 13
Training loss: 0.6239714026451111
Validation loss: 1.9944613415707824

Epoch: 205| Step: 0
Training loss: 1.3201429843902588
Validation loss: 1.9948428189882668

Epoch: 6| Step: 1
Training loss: 0.7182495594024658
Validation loss: 2.032511018937634

Epoch: 6| Step: 2
Training loss: 0.9412086009979248
Validation loss: 2.0192218557480843

Epoch: 6| Step: 3
Training loss: 0.7634754180908203
Validation loss: 1.986842211856637

Epoch: 6| Step: 4
Training loss: 0.895270586013794
Validation loss: 1.9765229161067674

Epoch: 6| Step: 5
Training loss: 0.8145134449005127
Validation loss: 1.9543509803792483

Epoch: 6| Step: 6
Training loss: 0.7760099172592163
Validation loss: 1.9228011959342546

Epoch: 6| Step: 7
Training loss: 1.0168812274932861
Validation loss: 1.9759277425786501

Epoch: 6| Step: 8
Training loss: 0.6087546348571777
Validation loss: 1.9530748756982947

Epoch: 6| Step: 9
Training loss: 1.297951102256775
Validation loss: 1.9351656513829385

Epoch: 6| Step: 10
Training loss: 0.7729024887084961
Validation loss: 1.9425549519959318

Epoch: 6| Step: 11
Training loss: 1.0800551176071167
Validation loss: 1.9433201198936791

Epoch: 6| Step: 12
Training loss: 1.3848226070404053
Validation loss: 1.9519741881278254

Epoch: 6| Step: 13
Training loss: 1.0292388200759888
Validation loss: 1.973219681811589

Epoch: 206| Step: 0
Training loss: 0.9636322259902954
Validation loss: 1.9849188968699465

Epoch: 6| Step: 1
Training loss: 0.9256613850593567
Validation loss: 2.0038466081824353

Epoch: 6| Step: 2
Training loss: 0.7758932113647461
Validation loss: 1.9950211701854583

Epoch: 6| Step: 3
Training loss: 0.8763946294784546
Validation loss: 2.0381288656624417

Epoch: 6| Step: 4
Training loss: 1.1703224182128906
Validation loss: 2.011744309497136

Epoch: 6| Step: 5
Training loss: 0.9242565631866455
Validation loss: 2.0091533712161485

Epoch: 6| Step: 6
Training loss: 0.9924132227897644
Validation loss: 2.010937927871622

Epoch: 6| Step: 7
Training loss: 0.9872186183929443
Validation loss: 1.9901587796467606

Epoch: 6| Step: 8
Training loss: 1.1077721118927002
Validation loss: 1.9596138538852814

Epoch: 6| Step: 9
Training loss: 0.8324630260467529
Validation loss: 1.942995136783969

Epoch: 6| Step: 10
Training loss: 0.36438149213790894
Validation loss: 1.941921789159057

Epoch: 6| Step: 11
Training loss: 1.2058181762695312
Validation loss: 1.9021935450133456

Epoch: 6| Step: 12
Training loss: 1.0590341091156006
Validation loss: 1.9380760679962814

Epoch: 6| Step: 13
Training loss: 0.4789451062679291
Validation loss: 1.9147285722917127

Epoch: 207| Step: 0
Training loss: 0.8785813450813293
Validation loss: 1.9383452579539309

Epoch: 6| Step: 1
Training loss: 0.6413270235061646
Validation loss: 1.889085477398288

Epoch: 6| Step: 2
Training loss: 0.7115938663482666
Validation loss: 1.8982297912720711

Epoch: 6| Step: 3
Training loss: 0.9489473700523376
Validation loss: 1.8897860127110635

Epoch: 6| Step: 4
Training loss: 1.1527016162872314
Validation loss: 1.8901698281688075

Epoch: 6| Step: 5
Training loss: 1.0619136095046997
Validation loss: 1.8940689051023094

Epoch: 6| Step: 6
Training loss: 0.6414906978607178
Validation loss: 1.870142743151675

Epoch: 6| Step: 7
Training loss: 0.8747198581695557
Validation loss: 1.8925964447759813

Epoch: 6| Step: 8
Training loss: 1.0477253198623657
Validation loss: 1.9086005328803934

Epoch: 6| Step: 9
Training loss: 0.9378398060798645
Validation loss: 1.9509256988443353

Epoch: 6| Step: 10
Training loss: 1.5136842727661133
Validation loss: 1.9906739727143319

Epoch: 6| Step: 11
Training loss: 1.2510294914245605
Validation loss: 2.0166459070738925

Epoch: 6| Step: 12
Training loss: 1.3110883235931396
Validation loss: 2.029580339308708

Epoch: 6| Step: 13
Training loss: 0.40659037232398987
Validation loss: 2.0804409096317906

Epoch: 208| Step: 0
Training loss: 0.9102590680122375
Validation loss: 2.0996052347203737

Epoch: 6| Step: 1
Training loss: 0.9082983732223511
Validation loss: 2.128505722168953

Epoch: 6| Step: 2
Training loss: 0.8675151467323303
Validation loss: 2.1490226291841075

Epoch: 6| Step: 3
Training loss: 0.836033046245575
Validation loss: 2.109332735820483

Epoch: 6| Step: 4
Training loss: 0.7563612461090088
Validation loss: 2.1028712090625556

Epoch: 6| Step: 5
Training loss: 0.8299130201339722
Validation loss: 2.0933159782040502

Epoch: 6| Step: 6
Training loss: 0.8527922630310059
Validation loss: 1.9945120914008028

Epoch: 6| Step: 7
Training loss: 0.9726589918136597
Validation loss: 1.9729316042315574

Epoch: 6| Step: 8
Training loss: 0.738450288772583
Validation loss: 1.94194657059126

Epoch: 6| Step: 9
Training loss: 1.228691577911377
Validation loss: 1.9527072086129138

Epoch: 6| Step: 10
Training loss: 1.1375937461853027
Validation loss: 1.924508297315208

Epoch: 6| Step: 11
Training loss: 0.9782660007476807
Validation loss: 1.9247694066775742

Epoch: 6| Step: 12
Training loss: 1.2492058277130127
Validation loss: 1.900171890053698

Epoch: 6| Step: 13
Training loss: 0.6861165165901184
Validation loss: 1.944450903964299

Epoch: 209| Step: 0
Training loss: 1.084733486175537
Validation loss: 1.971801975721954

Epoch: 6| Step: 1
Training loss: 0.7755507826805115
Validation loss: 1.9488028941615936

Epoch: 6| Step: 2
Training loss: 0.8600106239318848
Validation loss: 1.9679849288796867

Epoch: 6| Step: 3
Training loss: 1.034475564956665
Validation loss: 1.9776342107403664

Epoch: 6| Step: 4
Training loss: 0.6080370545387268
Validation loss: 1.9964912886260657

Epoch: 6| Step: 5
Training loss: 0.9990509152412415
Validation loss: 1.989416435200681

Epoch: 6| Step: 6
Training loss: 0.6644135117530823
Validation loss: 1.9661790709341727

Epoch: 6| Step: 7
Training loss: 1.1809608936309814
Validation loss: 1.9615562859401907

Epoch: 6| Step: 8
Training loss: 1.4233038425445557
Validation loss: 1.9724649665176228

Epoch: 6| Step: 9
Training loss: 0.41284629702568054
Validation loss: 1.983492325710994

Epoch: 6| Step: 10
Training loss: 0.8533551692962646
Validation loss: 1.9933235465839345

Epoch: 6| Step: 11
Training loss: 0.9133007526397705
Validation loss: 2.0080941620693413

Epoch: 6| Step: 12
Training loss: 0.8340260982513428
Validation loss: 1.9777139284277474

Epoch: 6| Step: 13
Training loss: 0.7631948590278625
Validation loss: 1.9884321804969542

Epoch: 210| Step: 0
Training loss: 0.9736239314079285
Validation loss: 2.0069124673002507

Epoch: 6| Step: 1
Training loss: 0.5596426725387573
Validation loss: 1.9659303183196692

Epoch: 6| Step: 2
Training loss: 1.022312879562378
Validation loss: 1.9866907391496884

Epoch: 6| Step: 3
Training loss: 1.2608948945999146
Validation loss: 1.962944261489376

Epoch: 6| Step: 4
Training loss: 0.46035873889923096
Validation loss: 1.987199971752782

Epoch: 6| Step: 5
Training loss: 0.517968475818634
Validation loss: 1.9379480628557102

Epoch: 6| Step: 6
Training loss: 1.2264631986618042
Validation loss: 1.9301469326019287

Epoch: 6| Step: 7
Training loss: 0.9539672136306763
Validation loss: 1.9042833902502572

Epoch: 6| Step: 8
Training loss: 0.9777325987815857
Validation loss: 1.9168312729045909

Epoch: 6| Step: 9
Training loss: 1.0152463912963867
Validation loss: 1.885728939887016

Epoch: 6| Step: 10
Training loss: 1.050433874130249
Validation loss: 1.9305085366772068

Epoch: 6| Step: 11
Training loss: 1.0172111988067627
Validation loss: 1.9184317486260527

Epoch: 6| Step: 12
Training loss: 0.6906851530075073
Validation loss: 1.9382433250386228

Epoch: 6| Step: 13
Training loss: 0.9764111638069153
Validation loss: 1.959989683602446

Epoch: 211| Step: 0
Training loss: 0.44535374641418457
Validation loss: 1.9665178111804429

Epoch: 6| Step: 1
Training loss: 0.5120158791542053
Validation loss: 1.9835531532123525

Epoch: 6| Step: 2
Training loss: 1.3448325395584106
Validation loss: 1.9949552935938681

Epoch: 6| Step: 3
Training loss: 0.6656128168106079
Validation loss: 1.9729465823019705

Epoch: 6| Step: 4
Training loss: 0.9925691485404968
Validation loss: 1.9549827537228983

Epoch: 6| Step: 5
Training loss: 0.6056888103485107
Validation loss: 1.9291298645798878

Epoch: 6| Step: 6
Training loss: 1.1276565790176392
Validation loss: 1.943119595127721

Epoch: 6| Step: 7
Training loss: 0.8365126252174377
Validation loss: 1.9257213813002392

Epoch: 6| Step: 8
Training loss: 0.5751936435699463
Validation loss: 1.9002648553540629

Epoch: 6| Step: 9
Training loss: 1.278440237045288
Validation loss: 1.8998446618357012

Epoch: 6| Step: 10
Training loss: 0.8295570611953735
Validation loss: 1.8728852900125648

Epoch: 6| Step: 11
Training loss: 1.0550857782363892
Validation loss: 1.9005973877445344

Epoch: 6| Step: 12
Training loss: 1.2252665758132935
Validation loss: 1.9064257888383762

Epoch: 6| Step: 13
Training loss: 0.83881676197052
Validation loss: 1.919565680206463

Epoch: 212| Step: 0
Training loss: 1.0160573720932007
Validation loss: 1.9411428448974446

Epoch: 6| Step: 1
Training loss: 0.9256451725959778
Validation loss: 1.943545396609973

Epoch: 6| Step: 2
Training loss: 0.7823162078857422
Validation loss: 1.960806897891465

Epoch: 6| Step: 3
Training loss: 0.7781327962875366
Validation loss: 1.9862155375942108

Epoch: 6| Step: 4
Training loss: 0.8827548623085022
Validation loss: 2.003382077781103

Epoch: 6| Step: 5
Training loss: 0.8682101368904114
Validation loss: 2.015375180270082

Epoch: 6| Step: 6
Training loss: 0.6343290209770203
Validation loss: 2.003448381218859

Epoch: 6| Step: 7
Training loss: 1.1363134384155273
Validation loss: 2.034371168382706

Epoch: 6| Step: 8
Training loss: 0.7283705472946167
Validation loss: 2.0315571459390784

Epoch: 6| Step: 9
Training loss: 0.5803988575935364
Validation loss: 2.003312494165154

Epoch: 6| Step: 10
Training loss: 0.7655482292175293
Validation loss: 1.988824418796006

Epoch: 6| Step: 11
Training loss: 0.762696385383606
Validation loss: 1.9560018508665022

Epoch: 6| Step: 12
Training loss: 0.7153210639953613
Validation loss: 1.9363047756174558

Epoch: 6| Step: 13
Training loss: 1.1572093963623047
Validation loss: 1.9175790432960755

Epoch: 213| Step: 0
Training loss: 0.7570374011993408
Validation loss: 1.881886866784865

Epoch: 6| Step: 1
Training loss: 0.7104471921920776
Validation loss: 1.8658584510126421

Epoch: 6| Step: 2
Training loss: 0.5809463858604431
Validation loss: 1.814243362795922

Epoch: 6| Step: 3
Training loss: 0.6965914368629456
Validation loss: 1.8332390041761502

Epoch: 6| Step: 4
Training loss: 0.8787229061126709
Validation loss: 1.8314266602198284

Epoch: 6| Step: 5
Training loss: 0.4786747992038727
Validation loss: 1.865879399802095

Epoch: 6| Step: 6
Training loss: 0.6181778311729431
Validation loss: 1.8435425540452361

Epoch: 6| Step: 7
Training loss: 1.0613901615142822
Validation loss: 1.8764700505041307

Epoch: 6| Step: 8
Training loss: 0.8540079593658447
Validation loss: 1.8749499231256463

Epoch: 6| Step: 9
Training loss: 0.7929767370223999
Validation loss: 1.897077146396842

Epoch: 6| Step: 10
Training loss: 1.1317932605743408
Validation loss: 1.949079022612623

Epoch: 6| Step: 11
Training loss: 1.0083911418914795
Validation loss: 1.9248236930498512

Epoch: 6| Step: 12
Training loss: 1.1703376770019531
Validation loss: 1.9545098120166409

Epoch: 6| Step: 13
Training loss: 0.9987443089485168
Validation loss: 1.9985551154741676

Epoch: 214| Step: 0
Training loss: 0.7243186235427856
Validation loss: 1.9530606551836895

Epoch: 6| Step: 1
Training loss: 0.5452393889427185
Validation loss: 1.9751530090967815

Epoch: 6| Step: 2
Training loss: 1.3876903057098389
Validation loss: 1.9747242825005644

Epoch: 6| Step: 3
Training loss: 0.7556788921356201
Validation loss: 1.9544559319814045

Epoch: 6| Step: 4
Training loss: 0.6513758301734924
Validation loss: 1.9579073895690262

Epoch: 6| Step: 5
Training loss: 0.7942081093788147
Validation loss: 1.9312298477336924

Epoch: 6| Step: 6
Training loss: 0.29614150524139404
Validation loss: 1.9495089643745012

Epoch: 6| Step: 7
Training loss: 0.9313815236091614
Validation loss: 1.913663802608367

Epoch: 6| Step: 8
Training loss: 1.001144289970398
Validation loss: 1.907359653903592

Epoch: 6| Step: 9
Training loss: 0.6411505937576294
Validation loss: 1.8847976846079673

Epoch: 6| Step: 10
Training loss: 0.8210989236831665
Validation loss: 1.8813780789734216

Epoch: 6| Step: 11
Training loss: 1.1881859302520752
Validation loss: 1.8682715559518466

Epoch: 6| Step: 12
Training loss: 1.2385973930358887
Validation loss: 1.9122811773771882

Epoch: 6| Step: 13
Training loss: 0.9093941450119019
Validation loss: 1.8977853892951884

Epoch: 215| Step: 0
Training loss: 0.5166811347007751
Validation loss: 1.9265915706593504

Epoch: 6| Step: 1
Training loss: 1.4305381774902344
Validation loss: 1.9127744090172552

Epoch: 6| Step: 2
Training loss: 0.47514891624450684
Validation loss: 1.9452765436582669

Epoch: 6| Step: 3
Training loss: 0.8313435316085815
Validation loss: 1.9478331509456839

Epoch: 6| Step: 4
Training loss: 0.9625482559204102
Validation loss: 1.9311311911511164

Epoch: 6| Step: 5
Training loss: 0.6161577701568604
Validation loss: 1.9463987709373556

Epoch: 6| Step: 6
Training loss: 0.809495210647583
Validation loss: 1.9315374000098116

Epoch: 6| Step: 7
Training loss: 0.8043593168258667
Validation loss: 1.941805507547112

Epoch: 6| Step: 8
Training loss: 0.9635683298110962
Validation loss: 1.9236655555745608

Epoch: 6| Step: 9
Training loss: 0.6287133693695068
Validation loss: 1.9291729747608144

Epoch: 6| Step: 10
Training loss: 0.7498231530189514
Validation loss: 1.9222029973101873

Epoch: 6| Step: 11
Training loss: 0.5747685432434082
Validation loss: 1.9234548537961897

Epoch: 6| Step: 12
Training loss: 1.0337750911712646
Validation loss: 1.931121459571264

Epoch: 6| Step: 13
Training loss: 1.165864109992981
Validation loss: 1.9233974872096893

Epoch: 216| Step: 0
Training loss: 0.234162375330925
Validation loss: 1.9340464376634168

Epoch: 6| Step: 1
Training loss: 0.9384323358535767
Validation loss: 1.9451222291556738

Epoch: 6| Step: 2
Training loss: 1.14813232421875
Validation loss: 1.941459446825007

Epoch: 6| Step: 3
Training loss: 0.8645718097686768
Validation loss: 1.9748184809120752

Epoch: 6| Step: 4
Training loss: 0.6051381826400757
Validation loss: 1.937938920913204

Epoch: 6| Step: 5
Training loss: 1.627974033355713
Validation loss: 1.9575432359531362

Epoch: 6| Step: 6
Training loss: 0.6417205929756165
Validation loss: 1.9802793149025208

Epoch: 6| Step: 7
Training loss: 1.071939468383789
Validation loss: 1.9608905417944795

Epoch: 6| Step: 8
Training loss: 0.7008553147315979
Validation loss: 1.9743456071422947

Epoch: 6| Step: 9
Training loss: 0.5705257654190063
Validation loss: 1.9927482886980938

Epoch: 6| Step: 10
Training loss: 0.7314253449440002
Validation loss: 1.97251122613107

Epoch: 6| Step: 11
Training loss: 0.4739237129688263
Validation loss: 1.9796606917535104

Epoch: 6| Step: 12
Training loss: 0.7029030323028564
Validation loss: 1.9559205526946692

Epoch: 6| Step: 13
Training loss: 0.7449759244918823
Validation loss: 1.9733831805567588

Epoch: 217| Step: 0
Training loss: 1.3876006603240967
Validation loss: 1.9939786285482428

Epoch: 6| Step: 1
Training loss: 0.29149913787841797
Validation loss: 1.99653366304213

Epoch: 6| Step: 2
Training loss: 0.8730642795562744
Validation loss: 1.9500963508441884

Epoch: 6| Step: 3
Training loss: 0.8873346447944641
Validation loss: 1.9603413894612303

Epoch: 6| Step: 4
Training loss: 1.0347492694854736
Validation loss: 1.9546517838713944

Epoch: 6| Step: 5
Training loss: 0.4173288345336914
Validation loss: 1.9473116244039228

Epoch: 6| Step: 6
Training loss: 0.4766994118690491
Validation loss: 1.9330967446809173

Epoch: 6| Step: 7
Training loss: 0.9539088010787964
Validation loss: 1.9000766649041125

Epoch: 6| Step: 8
Training loss: 0.6017756462097168
Validation loss: 1.8751997845147246

Epoch: 6| Step: 9
Training loss: 0.8194869756698608
Validation loss: 1.8424520979645431

Epoch: 6| Step: 10
Training loss: 1.0182814598083496
Validation loss: 1.8633684599271385

Epoch: 6| Step: 11
Training loss: 0.6038587689399719
Validation loss: 1.8498997073019705

Epoch: 6| Step: 12
Training loss: 0.9645380973815918
Validation loss: 1.8794386745781027

Epoch: 6| Step: 13
Training loss: 0.7249673008918762
Validation loss: 1.8837404392098869

Epoch: 218| Step: 0
Training loss: 0.5705884099006653
Validation loss: 1.9000793721086235

Epoch: 6| Step: 1
Training loss: 0.7714861631393433
Validation loss: 1.9273765561401204

Epoch: 6| Step: 2
Training loss: 0.8749619722366333
Validation loss: 1.9134538160857333

Epoch: 6| Step: 3
Training loss: 0.7553951144218445
Validation loss: 1.9105017518484464

Epoch: 6| Step: 4
Training loss: 0.6099130511283875
Validation loss: 1.9629580000395417

Epoch: 6| Step: 5
Training loss: 0.9434252977371216
Validation loss: 1.9249637485832296

Epoch: 6| Step: 6
Training loss: 0.9561693668365479
Validation loss: 1.9692928996137393

Epoch: 6| Step: 7
Training loss: 0.528558075428009
Validation loss: 1.9355344797975274

Epoch: 6| Step: 8
Training loss: 1.3214268684387207
Validation loss: 1.9279014000328638

Epoch: 6| Step: 9
Training loss: 0.6611798405647278
Validation loss: 1.9174252133215628

Epoch: 6| Step: 10
Training loss: 0.5494977831840515
Validation loss: 1.915512425925142

Epoch: 6| Step: 11
Training loss: 0.8549489378929138
Validation loss: 1.9302400222388647

Epoch: 6| Step: 12
Training loss: 0.6174805164337158
Validation loss: 1.895053635361374

Epoch: 6| Step: 13
Training loss: 0.49584048986434937
Validation loss: 1.8894560144793602

Epoch: 219| Step: 0
Training loss: 0.8145103454589844
Validation loss: 1.876357606662217

Epoch: 6| Step: 1
Training loss: 0.6162344217300415
Validation loss: 1.911178247902983

Epoch: 6| Step: 2
Training loss: 0.6341633200645447
Validation loss: 1.898449743947675

Epoch: 6| Step: 3
Training loss: 0.5749228596687317
Validation loss: 1.9257759842821347

Epoch: 6| Step: 4
Training loss: 0.7350203990936279
Validation loss: 1.9120655905815862

Epoch: 6| Step: 5
Training loss: 0.7723549008369446
Validation loss: 1.8871522026677285

Epoch: 6| Step: 6
Training loss: 1.028015375137329
Validation loss: 1.8965805640784643

Epoch: 6| Step: 7
Training loss: 0.5676569938659668
Validation loss: 1.903126174403775

Epoch: 6| Step: 8
Training loss: 0.8289070725440979
Validation loss: 1.8618627184180803

Epoch: 6| Step: 9
Training loss: 1.108150839805603
Validation loss: 1.875251550828257

Epoch: 6| Step: 10
Training loss: 0.33225274085998535
Validation loss: 1.8790501753489177

Epoch: 6| Step: 11
Training loss: 1.0371311902999878
Validation loss: 1.852736537174512

Epoch: 6| Step: 12
Training loss: 0.6761925220489502
Validation loss: 1.815862763312555

Epoch: 6| Step: 13
Training loss: 1.096725583076477
Validation loss: 1.8739478421467606

Epoch: 220| Step: 0
Training loss: 0.5429112315177917
Validation loss: 1.850924507264168

Epoch: 6| Step: 1
Training loss: 0.3805834949016571
Validation loss: 1.8809491011404222

Epoch: 6| Step: 2
Training loss: 0.6236075162887573
Validation loss: 1.8651101973748976

Epoch: 6| Step: 3
Training loss: 0.7953246831893921
Validation loss: 1.8803701349484023

Epoch: 6| Step: 4
Training loss: 1.0727643966674805
Validation loss: 1.853106802509677

Epoch: 6| Step: 5
Training loss: 0.9479734897613525
Validation loss: 1.9102490717364895

Epoch: 6| Step: 6
Training loss: 0.6034486293792725
Validation loss: 1.8739812348478584

Epoch: 6| Step: 7
Training loss: 0.39502695202827454
Validation loss: 1.8845513046428721

Epoch: 6| Step: 8
Training loss: 0.6778125762939453
Validation loss: 1.900571596237921

Epoch: 6| Step: 9
Training loss: 0.6250369548797607
Validation loss: 1.8951344874597364

Epoch: 6| Step: 10
Training loss: 0.929584264755249
Validation loss: 1.927475998478551

Epoch: 6| Step: 11
Training loss: 1.0471338033676147
Validation loss: 1.9112178471780592

Epoch: 6| Step: 12
Training loss: 0.5529351234436035
Validation loss: 1.9463323418812086

Epoch: 6| Step: 13
Training loss: 1.58047616481781
Validation loss: 1.9661420173542474

Epoch: 221| Step: 0
Training loss: 0.8790162801742554
Validation loss: 1.987959279808947

Epoch: 6| Step: 1
Training loss: 0.9592803716659546
Validation loss: 1.9906421912613737

Epoch: 6| Step: 2
Training loss: 0.7929804921150208
Validation loss: 1.9815126221667054

Epoch: 6| Step: 3
Training loss: 0.7434823513031006
Validation loss: 1.9557780834936327

Epoch: 6| Step: 4
Training loss: 0.8455786108970642
Validation loss: 1.9460609023289015

Epoch: 6| Step: 5
Training loss: 0.8296852111816406
Validation loss: 1.9292112319700179

Epoch: 6| Step: 6
Training loss: 0.13978365063667297
Validation loss: 1.8809527145918978

Epoch: 6| Step: 7
Training loss: 0.6753987073898315
Validation loss: 1.8689215593440558

Epoch: 6| Step: 8
Training loss: 0.617059051990509
Validation loss: 1.8463270279668993

Epoch: 6| Step: 9
Training loss: 0.7428469657897949
Validation loss: 1.8312652585326985

Epoch: 6| Step: 10
Training loss: 0.8180490732192993
Validation loss: 1.8689993094372492

Epoch: 6| Step: 11
Training loss: 0.7122359275817871
Validation loss: 1.8339802142112487

Epoch: 6| Step: 12
Training loss: 1.0452916622161865
Validation loss: 1.8288191890203824

Epoch: 6| Step: 13
Training loss: 1.0861715078353882
Validation loss: 1.8149803517967142

Epoch: 222| Step: 0
Training loss: 0.7396168112754822
Validation loss: 1.7819828692302908

Epoch: 6| Step: 1
Training loss: 0.6870644092559814
Validation loss: 1.8221199948300597

Epoch: 6| Step: 2
Training loss: 0.7184195518493652
Validation loss: 1.8385584399264345

Epoch: 6| Step: 3
Training loss: 0.6800692081451416
Validation loss: 1.8291259427224436

Epoch: 6| Step: 4
Training loss: 0.6162660121917725
Validation loss: 1.8418927538779475

Epoch: 6| Step: 5
Training loss: 0.3024336099624634
Validation loss: 1.8626591082542174

Epoch: 6| Step: 6
Training loss: 0.7625680565834045
Validation loss: 1.8796813462370185

Epoch: 6| Step: 7
Training loss: 0.7251276969909668
Validation loss: 1.882310082835536

Epoch: 6| Step: 8
Training loss: 1.1503643989562988
Validation loss: 1.8981819281014063

Epoch: 6| Step: 9
Training loss: 0.9665162563323975
Validation loss: 1.9058537534488145

Epoch: 6| Step: 10
Training loss: 0.9912079572677612
Validation loss: 1.8966101715641637

Epoch: 6| Step: 11
Training loss: 0.9633475542068481
Validation loss: 1.9025494437063895

Epoch: 6| Step: 12
Training loss: 0.7615739703178406
Validation loss: 1.8764213054410872

Epoch: 6| Step: 13
Training loss: 0.5859484672546387
Validation loss: 1.8776214481681905

Epoch: 223| Step: 0
Training loss: 0.6834875345230103
Validation loss: 1.8516349190024919

Epoch: 6| Step: 1
Training loss: 1.1769744157791138
Validation loss: 1.8321094679576095

Epoch: 6| Step: 2
Training loss: 0.6404880881309509
Validation loss: 1.809272535385624

Epoch: 6| Step: 3
Training loss: 0.6760731935501099
Validation loss: 1.7700755967888782

Epoch: 6| Step: 4
Training loss: 0.7558262348175049
Validation loss: 1.77498939857688

Epoch: 6| Step: 5
Training loss: 0.745754599571228
Validation loss: 1.7869706102596816

Epoch: 6| Step: 6
Training loss: 0.9342038631439209
Validation loss: 1.7823728181982552

Epoch: 6| Step: 7
Training loss: 0.6932933330535889
Validation loss: 1.779969076956472

Epoch: 6| Step: 8
Training loss: 0.9232398271560669
Validation loss: 1.769637474449732

Epoch: 6| Step: 9
Training loss: 0.4264560341835022
Validation loss: 1.7943379686724754

Epoch: 6| Step: 10
Training loss: 0.8382846117019653
Validation loss: 1.7902340773613221

Epoch: 6| Step: 11
Training loss: 0.7692605257034302
Validation loss: 1.8190527667281449

Epoch: 6| Step: 12
Training loss: 0.5887196660041809
Validation loss: 1.795693071939612

Epoch: 6| Step: 13
Training loss: 0.39623451232910156
Validation loss: 1.776060805525831

Epoch: 224| Step: 0
Training loss: 0.4324899911880493
Validation loss: 1.7977677404239614

Epoch: 6| Step: 1
Training loss: 1.2869898080825806
Validation loss: 1.8100045547690442

Epoch: 6| Step: 2
Training loss: 0.4801193177700043
Validation loss: 1.8802581217981154

Epoch: 6| Step: 3
Training loss: 0.6475076079368591
Validation loss: 1.8653207209802443

Epoch: 6| Step: 4
Training loss: 0.6614890098571777
Validation loss: 1.8683116948732765

Epoch: 6| Step: 5
Training loss: 0.9137981534004211
Validation loss: 1.8509092087386756

Epoch: 6| Step: 6
Training loss: 0.46784669160842896
Validation loss: 1.826203348816082

Epoch: 6| Step: 7
Training loss: 0.9006116390228271
Validation loss: 1.8221508969542801

Epoch: 6| Step: 8
Training loss: 0.697596549987793
Validation loss: 1.8396988094493907

Epoch: 6| Step: 9
Training loss: 0.5481517910957336
Validation loss: 1.78822156178054

Epoch: 6| Step: 10
Training loss: 0.9153289794921875
Validation loss: 1.7836893502102102

Epoch: 6| Step: 11
Training loss: 0.9403398036956787
Validation loss: 1.784774157308763

Epoch: 6| Step: 12
Training loss: 0.7435638904571533
Validation loss: 1.770960702691027

Epoch: 6| Step: 13
Training loss: 0.6782567501068115
Validation loss: 1.8099489340218164

Epoch: 225| Step: 0
Training loss: 0.7672257423400879
Validation loss: 1.782481361460942

Epoch: 6| Step: 1
Training loss: 1.1665802001953125
Validation loss: 1.7991575393625485

Epoch: 6| Step: 2
Training loss: 0.5837889909744263
Validation loss: 1.8001271601646178

Epoch: 6| Step: 3
Training loss: 0.8079333901405334
Validation loss: 1.8180564923952984

Epoch: 6| Step: 4
Training loss: 0.7294427156448364
Validation loss: 1.811667473085465

Epoch: 6| Step: 5
Training loss: 0.39377933740615845
Validation loss: 1.8466352044895131

Epoch: 6| Step: 6
Training loss: 0.7991175651550293
Validation loss: 1.8698601248443767

Epoch: 6| Step: 7
Training loss: 0.5862646698951721
Validation loss: 1.9171950996562999

Epoch: 6| Step: 8
Training loss: 0.9128520488739014
Validation loss: 1.8849720544712518

Epoch: 6| Step: 9
Training loss: 0.7402137517929077
Validation loss: 1.8886510210652505

Epoch: 6| Step: 10
Training loss: 0.9374196529388428
Validation loss: 1.8809869622671476

Epoch: 6| Step: 11
Training loss: 0.5394362807273865
Validation loss: 1.8684540410195627

Epoch: 6| Step: 12
Training loss: 0.781000554561615
Validation loss: 1.8583996924020911

Epoch: 6| Step: 13
Training loss: 0.388882040977478
Validation loss: 1.8294878416163947

Epoch: 226| Step: 0
Training loss: 0.7100732326507568
Validation loss: 1.8564494002249934

Epoch: 6| Step: 1
Training loss: 0.474324107170105
Validation loss: 1.8418321737679102

Epoch: 6| Step: 2
Training loss: 0.6750186085700989
Validation loss: 1.8530231521975609

Epoch: 6| Step: 3
Training loss: 0.4853445291519165
Validation loss: 1.844636486422631

Epoch: 6| Step: 4
Training loss: 0.48781490325927734
Validation loss: 1.8351452799253567

Epoch: 6| Step: 5
Training loss: 0.7016583681106567
Validation loss: 1.8238728187417472

Epoch: 6| Step: 6
Training loss: 0.6822984218597412
Validation loss: 1.8409243809279574

Epoch: 6| Step: 7
Training loss: 1.1299107074737549
Validation loss: 1.8534224687084075

Epoch: 6| Step: 8
Training loss: 0.8086824417114258
Validation loss: 1.8275680900901876

Epoch: 6| Step: 9
Training loss: 0.5755565166473389
Validation loss: 1.7991375615519862

Epoch: 6| Step: 10
Training loss: 1.1151143312454224
Validation loss: 1.815575336897245

Epoch: 6| Step: 11
Training loss: 0.597030520439148
Validation loss: 1.775527331136888

Epoch: 6| Step: 12
Training loss: 0.7146784663200378
Validation loss: 1.7813355922698975

Epoch: 6| Step: 13
Training loss: 0.9088572263717651
Validation loss: 1.8028886677116476

Epoch: 227| Step: 0
Training loss: 0.7437504529953003
Validation loss: 1.7704361292623705

Epoch: 6| Step: 1
Training loss: 1.0828592777252197
Validation loss: 1.7490116114257483

Epoch: 6| Step: 2
Training loss: 0.674362063407898
Validation loss: 1.7813281730938983

Epoch: 6| Step: 3
Training loss: 0.23341688513755798
Validation loss: 1.7997346232014317

Epoch: 6| Step: 4
Training loss: 0.7492624521255493
Validation loss: 1.7963502727529055

Epoch: 6| Step: 5
Training loss: 0.9164032936096191
Validation loss: 1.7918654718706686

Epoch: 6| Step: 6
Training loss: 0.6640167236328125
Validation loss: 1.773098627726237

Epoch: 6| Step: 7
Training loss: 0.8464320302009583
Validation loss: 1.7792588433911722

Epoch: 6| Step: 8
Training loss: 0.32990437746047974
Validation loss: 1.8083365617259857

Epoch: 6| Step: 9
Training loss: 0.9055759906768799
Validation loss: 1.8489410454227078

Epoch: 6| Step: 10
Training loss: 0.7493367195129395
Validation loss: 1.831771045602778

Epoch: 6| Step: 11
Training loss: 0.7987326383590698
Validation loss: 1.801710122375078

Epoch: 6| Step: 12
Training loss: 0.6263761520385742
Validation loss: 1.8418996885258665

Epoch: 6| Step: 13
Training loss: 0.36398568749427795
Validation loss: 1.812474871194491

Epoch: 228| Step: 0
Training loss: 0.7932015657424927
Validation loss: 1.8604660393089376

Epoch: 6| Step: 1
Training loss: 0.966137170791626
Validation loss: 1.8929665627018097

Epoch: 6| Step: 2
Training loss: 0.774529218673706
Validation loss: 1.9079021881985407

Epoch: 6| Step: 3
Training loss: 0.3119436502456665
Validation loss: 1.8961993314886605

Epoch: 6| Step: 4
Training loss: 0.6161959171295166
Validation loss: 1.8788815582952192

Epoch: 6| Step: 5
Training loss: 0.9359806180000305
Validation loss: 1.8851366991637855

Epoch: 6| Step: 6
Training loss: 1.1152276992797852
Validation loss: 1.893292934663834

Epoch: 6| Step: 7
Training loss: 0.5300929546356201
Validation loss: 1.9077425784962152

Epoch: 6| Step: 8
Training loss: 0.8656058311462402
Validation loss: 1.9247641242960447

Epoch: 6| Step: 9
Training loss: 0.6774513721466064
Validation loss: 1.92949447067835

Epoch: 6| Step: 10
Training loss: 0.6546062231063843
Validation loss: 1.9505417193135908

Epoch: 6| Step: 11
Training loss: 0.5022503733634949
Validation loss: 1.9259890138462026

Epoch: 6| Step: 12
Training loss: 1.052229642868042
Validation loss: 1.9121353664705831

Epoch: 6| Step: 13
Training loss: 0.5149254202842712
Validation loss: 1.8986457240196966

Epoch: 229| Step: 0
Training loss: 0.9749488830566406
Validation loss: 1.8829082289049703

Epoch: 6| Step: 1
Training loss: 0.46041709184646606
Validation loss: 1.8482102386413082

Epoch: 6| Step: 2
Training loss: 0.804825484752655
Validation loss: 1.824316668254073

Epoch: 6| Step: 3
Training loss: 0.6701672077178955
Validation loss: 1.7930181129004366

Epoch: 6| Step: 4
Training loss: 0.8416520357131958
Validation loss: 1.8148550871879823

Epoch: 6| Step: 5
Training loss: 0.3597012460231781
Validation loss: 1.7968718903039091

Epoch: 6| Step: 6
Training loss: 0.8554601669311523
Validation loss: 1.7787683099828742

Epoch: 6| Step: 7
Training loss: 0.5706872344017029
Validation loss: 1.7836769575713782

Epoch: 6| Step: 8
Training loss: 0.4620360732078552
Validation loss: 1.7714598307045557

Epoch: 6| Step: 9
Training loss: 1.2866662740707397
Validation loss: 1.787565218505039

Epoch: 6| Step: 10
Training loss: 0.5174626111984253
Validation loss: 1.7771779311600553

Epoch: 6| Step: 11
Training loss: 1.1288142204284668
Validation loss: 1.8085492554531302

Epoch: 6| Step: 12
Training loss: 0.3578171730041504
Validation loss: 1.797981696744119

Epoch: 6| Step: 13
Training loss: 0.8497111797332764
Validation loss: 1.805696746354462

Epoch: 230| Step: 0
Training loss: 1.1574831008911133
Validation loss: 1.8251067925524969

Epoch: 6| Step: 1
Training loss: 0.652298092842102
Validation loss: 1.8331937495098318

Epoch: 6| Step: 2
Training loss: 0.7804684638977051
Validation loss: 1.8480107053633659

Epoch: 6| Step: 3
Training loss: 0.5425320267677307
Validation loss: 1.8196118852143646

Epoch: 6| Step: 4
Training loss: 0.6280720233917236
Validation loss: 1.836743454779348

Epoch: 6| Step: 5
Training loss: 0.3121124505996704
Validation loss: 1.8285120097539758

Epoch: 6| Step: 6
Training loss: 0.6696988940238953
Validation loss: 1.8580891701482958

Epoch: 6| Step: 7
Training loss: 0.5997621417045593
Validation loss: 1.8252078269117622

Epoch: 6| Step: 8
Training loss: 0.9286754131317139
Validation loss: 1.8582425681493615

Epoch: 6| Step: 9
Training loss: 0.5327438116073608
Validation loss: 1.8847845318496868

Epoch: 6| Step: 10
Training loss: 0.9341956973075867
Validation loss: 1.8869109025565527

Epoch: 6| Step: 11
Training loss: 1.0158734321594238
Validation loss: 1.8552266699011608

Epoch: 6| Step: 12
Training loss: 0.7497338056564331
Validation loss: 1.8394690841756842

Epoch: 6| Step: 13
Training loss: 0.4411156177520752
Validation loss: 1.823014509293341

Epoch: 231| Step: 0
Training loss: 0.5802642703056335
Validation loss: 1.7691283072194746

Epoch: 6| Step: 1
Training loss: 0.9410895109176636
Validation loss: 1.7826084629181893

Epoch: 6| Step: 2
Training loss: 0.33859261870384216
Validation loss: 1.757857435493059

Epoch: 6| Step: 3
Training loss: 0.5370793342590332
Validation loss: 1.7802270432954193

Epoch: 6| Step: 4
Training loss: 0.7813968658447266
Validation loss: 1.757198041485202

Epoch: 6| Step: 5
Training loss: 0.7362600564956665
Validation loss: 1.7881789361276934

Epoch: 6| Step: 6
Training loss: 0.8385618925094604
Validation loss: 1.8054478540215442

Epoch: 6| Step: 7
Training loss: 0.9031201601028442
Validation loss: 1.7937926989729687

Epoch: 6| Step: 8
Training loss: 0.7536187171936035
Validation loss: 1.8264967215958463

Epoch: 6| Step: 9
Training loss: 0.4005433917045593
Validation loss: 1.8308445997135614

Epoch: 6| Step: 10
Training loss: 0.9729211330413818
Validation loss: 1.8820472763430687

Epoch: 6| Step: 11
Training loss: 0.6530304551124573
Validation loss: 1.8992822042075537

Epoch: 6| Step: 12
Training loss: 1.0318695306777954
Validation loss: 1.921006234743262

Epoch: 6| Step: 13
Training loss: 0.6589033007621765
Validation loss: 1.9503520483611732

Epoch: 232| Step: 0
Training loss: 0.6609307527542114
Validation loss: 1.910328806087535

Epoch: 6| Step: 1
Training loss: 1.3405461311340332
Validation loss: 1.909262470019761

Epoch: 6| Step: 2
Training loss: 1.1455836296081543
Validation loss: 1.8904409549569572

Epoch: 6| Step: 3
Training loss: 0.6674318909645081
Validation loss: 1.9259328201252928

Epoch: 6| Step: 4
Training loss: 0.7056934833526611
Validation loss: 1.9081666988711203

Epoch: 6| Step: 5
Training loss: 0.6589518785476685
Validation loss: 1.8980377950975973

Epoch: 6| Step: 6
Training loss: 0.7051690816879272
Validation loss: 1.8923296338768416

Epoch: 6| Step: 7
Training loss: 0.7654444575309753
Validation loss: 1.8537918047238422

Epoch: 6| Step: 8
Training loss: 0.6966092586517334
Validation loss: 1.8518529726612953

Epoch: 6| Step: 9
Training loss: 0.4894154667854309
Validation loss: 1.8543823457533313

Epoch: 6| Step: 10
Training loss: 0.44589006900787354
Validation loss: 1.8392858992340744

Epoch: 6| Step: 11
Training loss: 0.23210163414478302
Validation loss: 1.8252273092987716

Epoch: 6| Step: 12
Training loss: 0.8023748397827148
Validation loss: 1.8499577083895284

Epoch: 6| Step: 13
Training loss: 0.29966703057289124
Validation loss: 1.8321887382896997

Epoch: 233| Step: 0
Training loss: 0.7472308874130249
Validation loss: 1.841598423578406

Epoch: 6| Step: 1
Training loss: 0.7992185950279236
Validation loss: 1.8267747240681802

Epoch: 6| Step: 2
Training loss: 1.1041662693023682
Validation loss: 1.8071551233209588

Epoch: 6| Step: 3
Training loss: 0.4914923906326294
Validation loss: 1.7931781635489514

Epoch: 6| Step: 4
Training loss: 0.4575730860233307
Validation loss: 1.759281991630472

Epoch: 6| Step: 5
Training loss: 0.8835013508796692
Validation loss: 1.741061834878819

Epoch: 6| Step: 6
Training loss: 0.7096805572509766
Validation loss: 1.716631700915675

Epoch: 6| Step: 7
Training loss: 0.6716206073760986
Validation loss: 1.7203568297047769

Epoch: 6| Step: 8
Training loss: 0.5501951575279236
Validation loss: 1.7295287783427904

Epoch: 6| Step: 9
Training loss: 0.4311749339103699
Validation loss: 1.7587156564958635

Epoch: 6| Step: 10
Training loss: 0.874563455581665
Validation loss: 1.7270525463165776

Epoch: 6| Step: 11
Training loss: 0.5872355699539185
Validation loss: 1.7323603014792166

Epoch: 6| Step: 12
Training loss: 0.6720697283744812
Validation loss: 1.7268619896263204

Epoch: 6| Step: 13
Training loss: 0.7964030504226685
Validation loss: 1.7298153882385583

Epoch: 234| Step: 0
Training loss: 0.8207352161407471
Validation loss: 1.7569145335946033

Epoch: 6| Step: 1
Training loss: 0.6818379163742065
Validation loss: 1.7712853698320286

Epoch: 6| Step: 2
Training loss: 0.552291750907898
Validation loss: 1.7766901088017288

Epoch: 6| Step: 3
Training loss: 0.4537910223007202
Validation loss: 1.7727169695720877

Epoch: 6| Step: 4
Training loss: 0.5787298679351807
Validation loss: 1.7533263262882028

Epoch: 6| Step: 5
Training loss: 0.9191427230834961
Validation loss: 1.822526511325631

Epoch: 6| Step: 6
Training loss: 0.47055089473724365
Validation loss: 1.7893763152501916

Epoch: 6| Step: 7
Training loss: 0.5912967920303345
Validation loss: 1.7818791738120459

Epoch: 6| Step: 8
Training loss: 0.4978584051132202
Validation loss: 1.7859334074040896

Epoch: 6| Step: 9
Training loss: 0.6467999815940857
Validation loss: 1.784661210993285

Epoch: 6| Step: 10
Training loss: 0.9060208201408386
Validation loss: 1.774888220653739

Epoch: 6| Step: 11
Training loss: 0.6967378854751587
Validation loss: 1.7401259650466263

Epoch: 6| Step: 12
Training loss: 1.1623586416244507
Validation loss: 1.7260772617914344

Epoch: 6| Step: 13
Training loss: 0.545752227306366
Validation loss: 1.7299285409271077

Epoch: 235| Step: 0
Training loss: 0.8847100734710693
Validation loss: 1.7033603293921358

Epoch: 6| Step: 1
Training loss: 0.670893669128418
Validation loss: 1.708959557676828

Epoch: 6| Step: 2
Training loss: 0.4348486661911011
Validation loss: 1.71873079833164

Epoch: 6| Step: 3
Training loss: 0.7540675401687622
Validation loss: 1.744088254949098

Epoch: 6| Step: 4
Training loss: 0.20663446187973022
Validation loss: 1.7427983283996582

Epoch: 6| Step: 5
Training loss: 0.710315465927124
Validation loss: 1.7288087798703102

Epoch: 6| Step: 6
Training loss: 0.7600395679473877
Validation loss: 1.7486265179931477

Epoch: 6| Step: 7
Training loss: 1.0091583728790283
Validation loss: 1.764896321040328

Epoch: 6| Step: 8
Training loss: 0.656859278678894
Validation loss: 1.794055672102077

Epoch: 6| Step: 9
Training loss: 0.6915338039398193
Validation loss: 1.7807301834065428

Epoch: 6| Step: 10
Training loss: 0.4554935693740845
Validation loss: 1.7879475585875972

Epoch: 6| Step: 11
Training loss: 0.2919228672981262
Validation loss: 1.778955626231368

Epoch: 6| Step: 12
Training loss: 0.8787984848022461
Validation loss: 1.7680131299521333

Epoch: 6| Step: 13
Training loss: 0.9889466762542725
Validation loss: 1.7811522573553107

Epoch: 236| Step: 0
Training loss: 0.7477011680603027
Validation loss: 1.7398322936027282

Epoch: 6| Step: 1
Training loss: 1.014323353767395
Validation loss: 1.7123908804308983

Epoch: 6| Step: 2
Training loss: 0.9701451659202576
Validation loss: 1.7107326369131766

Epoch: 6| Step: 3
Training loss: 0.5735212564468384
Validation loss: 1.7217561839729227

Epoch: 6| Step: 4
Training loss: 0.5932071805000305
Validation loss: 1.7196509376648934

Epoch: 6| Step: 5
Training loss: 0.5990990400314331
Validation loss: 1.7125505837061072

Epoch: 6| Step: 6
Training loss: 0.6831389665603638
Validation loss: 1.6995683344461585

Epoch: 6| Step: 7
Training loss: 0.649704098701477
Validation loss: 1.7612963978962233

Epoch: 6| Step: 8
Training loss: 0.4267668128013611
Validation loss: 1.7699021062543314

Epoch: 6| Step: 9
Training loss: 0.6892377138137817
Validation loss: 1.7491230131477438

Epoch: 6| Step: 10
Training loss: 0.600347101688385
Validation loss: 1.7683405286522322

Epoch: 6| Step: 11
Training loss: 0.7369004487991333
Validation loss: 1.7318893568490141

Epoch: 6| Step: 12
Training loss: 0.5302090644836426
Validation loss: 1.7938060068315076

Epoch: 6| Step: 13
Training loss: 0.33451321721076965
Validation loss: 1.7946059370553622

Epoch: 237| Step: 0
Training loss: 0.6914246082305908
Validation loss: 1.7612393850921302

Epoch: 6| Step: 1
Training loss: 0.5182191133499146
Validation loss: 1.7639314243870396

Epoch: 6| Step: 2
Training loss: 0.8869218826293945
Validation loss: 1.707807904930525

Epoch: 6| Step: 3
Training loss: 0.540713906288147
Validation loss: 1.7101446338879165

Epoch: 6| Step: 4
Training loss: 0.5219076871871948
Validation loss: 1.686825620230808

Epoch: 6| Step: 5
Training loss: 0.629148006439209
Validation loss: 1.6810713147604337

Epoch: 6| Step: 6
Training loss: 0.5498975515365601
Validation loss: 1.6938416637400144

Epoch: 6| Step: 7
Training loss: 0.5527265667915344
Validation loss: 1.693017416102912

Epoch: 6| Step: 8
Training loss: 0.839556097984314
Validation loss: 1.7225278398042083

Epoch: 6| Step: 9
Training loss: 0.978175938129425
Validation loss: 1.7059639243669407

Epoch: 6| Step: 10
Training loss: 0.7039990425109863
Validation loss: 1.6871723673676933

Epoch: 6| Step: 11
Training loss: 0.4276611804962158
Validation loss: 1.755242440008348

Epoch: 6| Step: 12
Training loss: 0.728925347328186
Validation loss: 1.7775937767438992

Epoch: 6| Step: 13
Training loss: 0.64499831199646
Validation loss: 1.8050214731565086

Epoch: 238| Step: 0
Training loss: 0.4278663992881775
Validation loss: 1.8363703399576166

Epoch: 6| Step: 1
Training loss: 0.4270784258842468
Validation loss: 1.832651504906275

Epoch: 6| Step: 2
Training loss: 0.6017804145812988
Validation loss: 1.884754962818597

Epoch: 6| Step: 3
Training loss: 1.2834627628326416
Validation loss: 1.850738327990296

Epoch: 6| Step: 4
Training loss: 0.6552587747573853
Validation loss: 1.8720098746720182

Epoch: 6| Step: 5
Training loss: 0.5124487280845642
Validation loss: 1.8266639786381875

Epoch: 6| Step: 6
Training loss: 0.5842756628990173
Validation loss: 1.8468382499551261

Epoch: 6| Step: 7
Training loss: 0.6279057264328003
Validation loss: 1.84680970509847

Epoch: 6| Step: 8
Training loss: 0.40720340609550476
Validation loss: 1.8362299114145257

Epoch: 6| Step: 9
Training loss: 0.7189544439315796
Validation loss: 1.7887507984715123

Epoch: 6| Step: 10
Training loss: 0.5431848764419556
Validation loss: 1.7708585390480616

Epoch: 6| Step: 11
Training loss: 0.6648019552230835
Validation loss: 1.7611869663320563

Epoch: 6| Step: 12
Training loss: 0.777603268623352
Validation loss: 1.7287513722655594

Epoch: 6| Step: 13
Training loss: 1.1214665174484253
Validation loss: 1.7502195271112586

Epoch: 239| Step: 0
Training loss: 0.49720436334609985
Validation loss: 1.7291395209168876

Epoch: 6| Step: 1
Training loss: 0.5117601752281189
Validation loss: 1.7126655040248748

Epoch: 6| Step: 2
Training loss: 0.526171863079071
Validation loss: 1.733932210553077

Epoch: 6| Step: 3
Training loss: 0.7453713417053223
Validation loss: 1.7668075638432656

Epoch: 6| Step: 4
Training loss: 0.9540646076202393
Validation loss: 1.7688758411715109

Epoch: 6| Step: 5
Training loss: 0.7708046436309814
Validation loss: 1.7580755949020386

Epoch: 6| Step: 6
Training loss: 0.5971571803092957
Validation loss: 1.7517222704425934

Epoch: 6| Step: 7
Training loss: 0.7139372229576111
Validation loss: 1.7740174057663127

Epoch: 6| Step: 8
Training loss: 0.7708929777145386
Validation loss: 1.7976270452622445

Epoch: 6| Step: 9
Training loss: 0.5917450189590454
Validation loss: 1.8103971519777853

Epoch: 6| Step: 10
Training loss: 0.25322479009628296
Validation loss: 1.8148832846713323

Epoch: 6| Step: 11
Training loss: 0.8832711577415466
Validation loss: 1.8265722554217103

Epoch: 6| Step: 12
Training loss: 0.7720127105712891
Validation loss: 1.7927665966813282

Epoch: 6| Step: 13
Training loss: 0.2592045068740845
Validation loss: 1.834046063884612

Epoch: 240| Step: 0
Training loss: 0.6109837293624878
Validation loss: 1.8208359197903705

Epoch: 6| Step: 1
Training loss: 0.4165446162223816
Validation loss: 1.8039332230885823

Epoch: 6| Step: 2
Training loss: 0.36718177795410156
Validation loss: 1.791618945137147

Epoch: 6| Step: 3
Training loss: 0.46852636337280273
Validation loss: 1.8296652558029338

Epoch: 6| Step: 4
Training loss: 0.6414824724197388
Validation loss: 1.8259203856991184

Epoch: 6| Step: 5
Training loss: 0.5851550102233887
Validation loss: 1.8176182123922533

Epoch: 6| Step: 6
Training loss: 0.562953770160675
Validation loss: 1.8160641642027004

Epoch: 6| Step: 7
Training loss: 0.3206626772880554
Validation loss: 1.8042954078284643

Epoch: 6| Step: 8
Training loss: 0.5622854232788086
Validation loss: 1.821406824614412

Epoch: 6| Step: 9
Training loss: 0.7817039489746094
Validation loss: 1.8100334726354128

Epoch: 6| Step: 10
Training loss: 1.0172600746154785
Validation loss: 1.819699953961116

Epoch: 6| Step: 11
Training loss: 0.8041319847106934
Validation loss: 1.8205494470493768

Epoch: 6| Step: 12
Training loss: 0.8938273191452026
Validation loss: 1.7757200041124899

Epoch: 6| Step: 13
Training loss: 0.7779328227043152
Validation loss: 1.7696651386958298

Epoch: 241| Step: 0
Training loss: 0.40867042541503906
Validation loss: 1.7377518505178473

Epoch: 6| Step: 1
Training loss: 0.24894066154956818
Validation loss: 1.7555272015192176

Epoch: 6| Step: 2
Training loss: 0.7743140459060669
Validation loss: 1.7292437335496307

Epoch: 6| Step: 3
Training loss: 0.7054041624069214
Validation loss: 1.7406645154440274

Epoch: 6| Step: 4
Training loss: 0.5346111059188843
Validation loss: 1.7078390826461136

Epoch: 6| Step: 5
Training loss: 0.9067132472991943
Validation loss: 1.7405382535790885

Epoch: 6| Step: 6
Training loss: 0.4596481919288635
Validation loss: 1.7218308987156037

Epoch: 6| Step: 7
Training loss: 0.6438783407211304
Validation loss: 1.7397316143076906

Epoch: 6| Step: 8
Training loss: 0.42110511660575867
Validation loss: 1.7483374136750416

Epoch: 6| Step: 9
Training loss: 0.7009003162384033
Validation loss: 1.7747470871094735

Epoch: 6| Step: 10
Training loss: 0.9661194682121277
Validation loss: 1.7942681081833378

Epoch: 6| Step: 11
Training loss: 0.49337685108184814
Validation loss: 1.8360563657617057

Epoch: 6| Step: 12
Training loss: 1.0020105838775635
Validation loss: 1.8264889178737518

Epoch: 6| Step: 13
Training loss: 0.954681396484375
Validation loss: 1.840831865546524

Epoch: 242| Step: 0
Training loss: 0.8235161304473877
Validation loss: 1.858636656115132

Epoch: 6| Step: 1
Training loss: 0.7713698148727417
Validation loss: 1.8596214632834158

Epoch: 6| Step: 2
Training loss: 0.5924609303474426
Validation loss: 1.8579833545992452

Epoch: 6| Step: 3
Training loss: 0.3198767304420471
Validation loss: 1.8077780482589558

Epoch: 6| Step: 4
Training loss: 0.6481671929359436
Validation loss: 1.7829287154700166

Epoch: 6| Step: 5
Training loss: 0.9672561883926392
Validation loss: 1.7568992978783065

Epoch: 6| Step: 6
Training loss: 0.6911173462867737
Validation loss: 1.7362361556740218

Epoch: 6| Step: 7
Training loss: 0.5733271837234497
Validation loss: 1.7238596100961008

Epoch: 6| Step: 8
Training loss: 0.6373921632766724
Validation loss: 1.7473566750044465

Epoch: 6| Step: 9
Training loss: 0.43004122376441956
Validation loss: 1.7386639554013488

Epoch: 6| Step: 10
Training loss: 0.3820481300354004
Validation loss: 1.7577431753117552

Epoch: 6| Step: 11
Training loss: 0.4276669919490814
Validation loss: 1.751767441790591

Epoch: 6| Step: 12
Training loss: 0.6776568293571472
Validation loss: 1.7754857629858039

Epoch: 6| Step: 13
Training loss: 0.7621095180511475
Validation loss: 1.7705903963376117

Epoch: 243| Step: 0
Training loss: 0.653644859790802
Validation loss: 1.7981871097318587

Epoch: 6| Step: 1
Training loss: 0.3463362455368042
Validation loss: 1.790883061706379

Epoch: 6| Step: 2
Training loss: 0.6317012310028076
Validation loss: 1.786485163114404

Epoch: 6| Step: 3
Training loss: 0.512298583984375
Validation loss: 1.8061742141682615

Epoch: 6| Step: 4
Training loss: 0.6708623170852661
Validation loss: 1.773987231716033

Epoch: 6| Step: 5
Training loss: 0.7293000817298889
Validation loss: 1.7791942934836111

Epoch: 6| Step: 6
Training loss: 0.7845107316970825
Validation loss: 1.764144879515453

Epoch: 6| Step: 7
Training loss: 0.7454671859741211
Validation loss: 1.791732741940406

Epoch: 6| Step: 8
Training loss: 0.16816793382167816
Validation loss: 1.7463675596380746

Epoch: 6| Step: 9
Training loss: 0.8920773863792419
Validation loss: 1.767906205628508

Epoch: 6| Step: 10
Training loss: 0.6500338315963745
Validation loss: 1.7755653909457627

Epoch: 6| Step: 11
Training loss: 0.4204227030277252
Validation loss: 1.7689088249719271

Epoch: 6| Step: 12
Training loss: 0.574012041091919
Validation loss: 1.7710894243691557

Epoch: 6| Step: 13
Training loss: 0.5472971796989441
Validation loss: 1.797489768715315

Epoch: 244| Step: 0
Training loss: 0.8987507820129395
Validation loss: 1.8069364947657431

Epoch: 6| Step: 1
Training loss: 0.753408670425415
Validation loss: 1.802806254356138

Epoch: 6| Step: 2
Training loss: 0.38962268829345703
Validation loss: 1.8082220080078288

Epoch: 6| Step: 3
Training loss: 0.5307061076164246
Validation loss: 1.8086420271986274

Epoch: 6| Step: 4
Training loss: 1.0784173011779785
Validation loss: 1.8264394370458459

Epoch: 6| Step: 5
Training loss: 0.40407484769821167
Validation loss: 1.8244062392942366

Epoch: 6| Step: 6
Training loss: 0.44044315814971924
Validation loss: 1.8339890177531908

Epoch: 6| Step: 7
Training loss: 0.7449780106544495
Validation loss: 1.8060118639340965

Epoch: 6| Step: 8
Training loss: 0.4788348376750946
Validation loss: 1.8237598788353704

Epoch: 6| Step: 9
Training loss: 0.3316352367401123
Validation loss: 1.796653010511911

Epoch: 6| Step: 10
Training loss: 0.5166115760803223
Validation loss: 1.7977205271361976

Epoch: 6| Step: 11
Training loss: 0.5182617902755737
Validation loss: 1.7581806182861328

Epoch: 6| Step: 12
Training loss: 0.5001887083053589
Validation loss: 1.7405211707597137

Epoch: 6| Step: 13
Training loss: 0.7927877902984619
Validation loss: 1.6901181167171848

Epoch: 245| Step: 0
Training loss: 0.7907497882843018
Validation loss: 1.673761838225908

Epoch: 6| Step: 1
Training loss: 0.8023408651351929
Validation loss: 1.681033722815975

Epoch: 6| Step: 2
Training loss: 0.47781655192375183
Validation loss: 1.6517146454062512

Epoch: 6| Step: 3
Training loss: 0.5335911512374878
Validation loss: 1.6792758677595405

Epoch: 6| Step: 4
Training loss: 0.7164056897163391
Validation loss: 1.6832751638145858

Epoch: 6| Step: 5
Training loss: 0.612549901008606
Validation loss: 1.6952010252142464

Epoch: 6| Step: 6
Training loss: 0.7779327630996704
Validation loss: 1.653308637680546

Epoch: 6| Step: 7
Training loss: 0.5313705801963806
Validation loss: 1.696137891020826

Epoch: 6| Step: 8
Training loss: 0.4185642600059509
Validation loss: 1.701639808634276

Epoch: 6| Step: 9
Training loss: 0.9049524068832397
Validation loss: 1.7400562186394968

Epoch: 6| Step: 10
Training loss: 0.5405263304710388
Validation loss: 1.7871529607362644

Epoch: 6| Step: 11
Training loss: 0.8919281363487244
Validation loss: 1.7867152613978232

Epoch: 6| Step: 12
Training loss: 0.49561330676078796
Validation loss: 1.7967321680438133

Epoch: 6| Step: 13
Training loss: 0.22440889477729797
Validation loss: 1.8437766105897966

Epoch: 246| Step: 0
Training loss: 0.7144455909729004
Validation loss: 1.8365433882641535

Epoch: 6| Step: 1
Training loss: 0.7373893857002258
Validation loss: 1.8376944590640325

Epoch: 6| Step: 2
Training loss: 0.8255774974822998
Validation loss: 1.8631794247575986

Epoch: 6| Step: 3
Training loss: 0.9393535256385803
Validation loss: 1.8312894170002272

Epoch: 6| Step: 4
Training loss: 0.6605603694915771
Validation loss: 1.854552181818152

Epoch: 6| Step: 5
Training loss: 0.6366738677024841
Validation loss: 1.8716118899724816

Epoch: 6| Step: 6
Training loss: 0.4847371280193329
Validation loss: 1.8252880983455206

Epoch: 6| Step: 7
Training loss: 0.5013735294342041
Validation loss: 1.8438056284381497

Epoch: 6| Step: 8
Training loss: 0.25980326533317566
Validation loss: 1.8709119724970993

Epoch: 6| Step: 9
Training loss: 0.4033978283405304
Validation loss: 1.8317593554014802

Epoch: 6| Step: 10
Training loss: 0.5653671026229858
Validation loss: 1.8652205697951778

Epoch: 6| Step: 11
Training loss: 0.444652795791626
Validation loss: 1.8539646325572845

Epoch: 6| Step: 12
Training loss: 0.44417834281921387
Validation loss: 1.833817115394018

Epoch: 6| Step: 13
Training loss: 0.910676121711731
Validation loss: 1.8468920825630106

Epoch: 247| Step: 0
Training loss: 0.632489800453186
Validation loss: 1.8145054976145427

Epoch: 6| Step: 1
Training loss: 0.8610873222351074
Validation loss: 1.7943339476021387

Epoch: 6| Step: 2
Training loss: 0.6228898763656616
Validation loss: 1.8352754872332337

Epoch: 6| Step: 3
Training loss: 0.4307370185852051
Validation loss: 1.7883972865279003

Epoch: 6| Step: 4
Training loss: 0.3084565997123718
Validation loss: 1.8250186597147295

Epoch: 6| Step: 5
Training loss: 0.6638338565826416
Validation loss: 1.8344033584799817

Epoch: 6| Step: 6
Training loss: 0.8850154876708984
Validation loss: 1.8488014026354718

Epoch: 6| Step: 7
Training loss: 0.6563738584518433
Validation loss: 1.8291578164664648

Epoch: 6| Step: 8
Training loss: 0.40871894359588623
Validation loss: 1.839180725877003

Epoch: 6| Step: 9
Training loss: 0.6537837982177734
Validation loss: 1.8347090392984369

Epoch: 6| Step: 10
Training loss: 0.5377758741378784
Validation loss: 1.82618680051578

Epoch: 6| Step: 11
Training loss: 0.4754994809627533
Validation loss: 1.8031957111051005

Epoch: 6| Step: 12
Training loss: 0.6385542154312134
Validation loss: 1.767662218821946

Epoch: 6| Step: 13
Training loss: 0.48299217224121094
Validation loss: 1.8175495850142611

Epoch: 248| Step: 0
Training loss: 0.8067483901977539
Validation loss: 1.753892014103551

Epoch: 6| Step: 1
Training loss: 0.8238992691040039
Validation loss: 1.7662612084419496

Epoch: 6| Step: 2
Training loss: 0.40937647223472595
Validation loss: 1.7555133142778951

Epoch: 6| Step: 3
Training loss: 0.5295635461807251
Validation loss: 1.7365631839280486

Epoch: 6| Step: 4
Training loss: 0.43139389157295227
Validation loss: 1.7365946231349823

Epoch: 6| Step: 5
Training loss: 0.5067335367202759
Validation loss: 1.748554293827344

Epoch: 6| Step: 6
Training loss: 0.19073981046676636
Validation loss: 1.705088359053417

Epoch: 6| Step: 7
Training loss: 0.8689084649085999
Validation loss: 1.743455889404461

Epoch: 6| Step: 8
Training loss: 0.4371909499168396
Validation loss: 1.7654703035149524

Epoch: 6| Step: 9
Training loss: 0.5126527547836304
Validation loss: 1.747021677673504

Epoch: 6| Step: 10
Training loss: 0.41827699542045593
Validation loss: 1.7256429554313741

Epoch: 6| Step: 11
Training loss: 0.4411660432815552
Validation loss: 1.7343260934275966

Epoch: 6| Step: 12
Training loss: 0.9255508780479431
Validation loss: 1.7400827266836678

Epoch: 6| Step: 13
Training loss: 0.212773397564888
Validation loss: 1.7004170930513771

Epoch: 249| Step: 0
Training loss: 0.23340019583702087
Validation loss: 1.6871456061640093

Epoch: 6| Step: 1
Training loss: 0.4765491485595703
Validation loss: 1.689116306202386

Epoch: 6| Step: 2
Training loss: 1.0160871744155884
Validation loss: 1.6798718411435363

Epoch: 6| Step: 3
Training loss: 0.6386926174163818
Validation loss: 1.6965725607769464

Epoch: 6| Step: 4
Training loss: 0.7014226317405701
Validation loss: 1.7020471378039288

Epoch: 6| Step: 5
Training loss: 0.7523809671401978
Validation loss: 1.7116217203037714

Epoch: 6| Step: 6
Training loss: 0.3735167980194092
Validation loss: 1.698355128688197

Epoch: 6| Step: 7
Training loss: 0.6933557987213135
Validation loss: 1.7217130968647618

Epoch: 6| Step: 8
Training loss: 0.5994758605957031
Validation loss: 1.7247788201096237

Epoch: 6| Step: 9
Training loss: 0.7065353989601135
Validation loss: 1.7396923021603656

Epoch: 6| Step: 10
Training loss: 0.340401291847229
Validation loss: 1.7506428431439143

Epoch: 6| Step: 11
Training loss: 0.546766459941864
Validation loss: 1.7559581392554826

Epoch: 6| Step: 12
Training loss: 0.4600462019443512
Validation loss: 1.7517374510406165

Epoch: 6| Step: 13
Training loss: 0.49580293893814087
Validation loss: 1.7398480010289017

Epoch: 250| Step: 0
Training loss: 0.49294155836105347
Validation loss: 1.7524432341257732

Epoch: 6| Step: 1
Training loss: 0.6800978183746338
Validation loss: 1.7269201009504256

Epoch: 6| Step: 2
Training loss: 0.5149496793746948
Validation loss: 1.7558044361811813

Epoch: 6| Step: 3
Training loss: 0.6546046733856201
Validation loss: 1.7558719035117858

Epoch: 6| Step: 4
Training loss: 0.6866304874420166
Validation loss: 1.7393296969834195

Epoch: 6| Step: 5
Training loss: 0.6838287711143494
Validation loss: 1.7376279933478243

Epoch: 6| Step: 6
Training loss: 0.39943838119506836
Validation loss: 1.6766609325203845

Epoch: 6| Step: 7
Training loss: 0.39027276635169983
Validation loss: 1.7207196015183643

Epoch: 6| Step: 8
Training loss: 0.755955696105957
Validation loss: 1.7049776841235418

Epoch: 6| Step: 9
Training loss: 0.7897766828536987
Validation loss: 1.7165080949824343

Epoch: 6| Step: 10
Training loss: 0.29375964403152466
Validation loss: 1.6876729047426613

Epoch: 6| Step: 11
Training loss: 0.4692923426628113
Validation loss: 1.7429295739819926

Epoch: 6| Step: 12
Training loss: 0.7596568465232849
Validation loss: 1.7259069604258384

Epoch: 6| Step: 13
Training loss: 0.3623841404914856
Validation loss: 1.7457550764083862

Epoch: 251| Step: 0
Training loss: 0.6709455847740173
Validation loss: 1.732011346406834

Epoch: 6| Step: 1
Training loss: 0.6735271215438843
Validation loss: 1.7743490613916868

Epoch: 6| Step: 2
Training loss: 0.42491233348846436
Validation loss: 1.732781938327256

Epoch: 6| Step: 3
Training loss: 0.27901339530944824
Validation loss: 1.742174122923164

Epoch: 6| Step: 4
Training loss: 0.3410966694355011
Validation loss: 1.686129944298857

Epoch: 6| Step: 5
Training loss: 0.9228547811508179
Validation loss: 1.646918894142233

Epoch: 6| Step: 6
Training loss: 0.6410744786262512
Validation loss: 1.6543824441971318

Epoch: 6| Step: 7
Training loss: 0.5135029554367065
Validation loss: 1.649132574758222

Epoch: 6| Step: 8
Training loss: 0.5514649152755737
Validation loss: 1.6534840240273425

Epoch: 6| Step: 9
Training loss: 0.495636522769928
Validation loss: 1.6510343397817304

Epoch: 6| Step: 10
Training loss: 0.49797484278678894
Validation loss: 1.6710346603906283

Epoch: 6| Step: 11
Training loss: 0.7307543754577637
Validation loss: 1.6988876173573155

Epoch: 6| Step: 12
Training loss: 0.5132670998573303
Validation loss: 1.6870868641843078

Epoch: 6| Step: 13
Training loss: 0.7379891872406006
Validation loss: 1.6825301416458622

Epoch: 252| Step: 0
Training loss: 0.7829767465591431
Validation loss: 1.734943918002549

Epoch: 6| Step: 1
Training loss: 0.7623956799507141
Validation loss: 1.7871705947383758

Epoch: 6| Step: 2
Training loss: 0.5291064381599426
Validation loss: 1.7836346087917205

Epoch: 6| Step: 3
Training loss: 0.5480815172195435
Validation loss: 1.7795238943510159

Epoch: 6| Step: 4
Training loss: 0.5851435661315918
Validation loss: 1.7858896704130276

Epoch: 6| Step: 5
Training loss: 0.3808204233646393
Validation loss: 1.8198945547944756

Epoch: 6| Step: 6
Training loss: 0.6777483224868774
Validation loss: 1.8143308983054212

Epoch: 6| Step: 7
Training loss: 0.4861179292201996
Validation loss: 1.8131256744425783

Epoch: 6| Step: 8
Training loss: 0.5599327087402344
Validation loss: 1.793801990888452

Epoch: 6| Step: 9
Training loss: 0.2806835174560547
Validation loss: 1.7659766084404402

Epoch: 6| Step: 10
Training loss: 1.1131396293640137
Validation loss: 1.7423420926576019

Epoch: 6| Step: 11
Training loss: 0.4423665702342987
Validation loss: 1.7410322722568308

Epoch: 6| Step: 12
Training loss: 0.27597784996032715
Validation loss: 1.7701349912151214

Epoch: 6| Step: 13
Training loss: 0.8015524744987488
Validation loss: 1.7555921129001084

Epoch: 253| Step: 0
Training loss: 0.8401440382003784
Validation loss: 1.7336537414981472

Epoch: 6| Step: 1
Training loss: 0.4156309962272644
Validation loss: 1.7510398716054938

Epoch: 6| Step: 2
Training loss: 0.3921431303024292
Validation loss: 1.7515952394854637

Epoch: 6| Step: 3
Training loss: 0.49433809518814087
Validation loss: 1.7297981234006985

Epoch: 6| Step: 4
Training loss: 0.2886445224285126
Validation loss: 1.7501798842542915

Epoch: 6| Step: 5
Training loss: 0.6798865795135498
Validation loss: 1.7401268764208722

Epoch: 6| Step: 6
Training loss: 0.9202568531036377
Validation loss: 1.734238560481738

Epoch: 6| Step: 7
Training loss: 0.5348425507545471
Validation loss: 1.7300602441192956

Epoch: 6| Step: 8
Training loss: 0.5973702669143677
Validation loss: 1.7236893420578332

Epoch: 6| Step: 9
Training loss: 0.4289129674434662
Validation loss: 1.6895146113570019

Epoch: 6| Step: 10
Training loss: 0.2843744158744812
Validation loss: 1.7325730246882285

Epoch: 6| Step: 11
Training loss: 0.3974916636943817
Validation loss: 1.7072388677186863

Epoch: 6| Step: 12
Training loss: 0.9368560314178467
Validation loss: 1.7195747706197924

Epoch: 6| Step: 13
Training loss: 0.29956215620040894
Validation loss: 1.7645908119857951

Epoch: 254| Step: 0
Training loss: 0.8958850502967834
Validation loss: 1.8033225869619718

Epoch: 6| Step: 1
Training loss: 0.46946340799331665
Validation loss: 1.7762743683271511

Epoch: 6| Step: 2
Training loss: 0.3515104353427887
Validation loss: 1.7547089425466393

Epoch: 6| Step: 3
Training loss: 0.512345552444458
Validation loss: 1.7943285024294289

Epoch: 6| Step: 4
Training loss: 0.46523910760879517
Validation loss: 1.765952153872418

Epoch: 6| Step: 5
Training loss: 0.6355984807014465
Validation loss: 1.7780393195408646

Epoch: 6| Step: 6
Training loss: 0.45295703411102295
Validation loss: 1.778786115748908

Epoch: 6| Step: 7
Training loss: 0.663589596748352
Validation loss: 1.779515443309661

Epoch: 6| Step: 8
Training loss: 0.2939753234386444
Validation loss: 1.7799353458548104

Epoch: 6| Step: 9
Training loss: 0.5427300930023193
Validation loss: 1.7792069456910575

Epoch: 6| Step: 10
Training loss: 0.7619560956954956
Validation loss: 1.79818977719994

Epoch: 6| Step: 11
Training loss: 0.2616302967071533
Validation loss: 1.789391145911268

Epoch: 6| Step: 12
Training loss: 0.5049529075622559
Validation loss: 1.814294074171333

Epoch: 6| Step: 13
Training loss: 0.588471531867981
Validation loss: 1.7996293485805552

Epoch: 255| Step: 0
Training loss: 0.4513457417488098
Validation loss: 1.8026774032141573

Epoch: 6| Step: 1
Training loss: 0.594649612903595
Validation loss: 1.8006151953051168

Epoch: 6| Step: 2
Training loss: 0.30905357003211975
Validation loss: 1.7707778138499106

Epoch: 6| Step: 3
Training loss: 0.5781852006912231
Validation loss: 1.800064266368907

Epoch: 6| Step: 4
Training loss: 0.527815580368042
Validation loss: 1.7581709610518588

Epoch: 6| Step: 5
Training loss: 0.3018552362918854
Validation loss: 1.7467386389291415

Epoch: 6| Step: 6
Training loss: 0.5118602514266968
Validation loss: 1.74879329435287

Epoch: 6| Step: 7
Training loss: 0.691801130771637
Validation loss: 1.7457299463210567

Epoch: 6| Step: 8
Training loss: 0.5521567463874817
Validation loss: 1.686706191749983

Epoch: 6| Step: 9
Training loss: 0.4253518283367157
Validation loss: 1.6990590813339397

Epoch: 6| Step: 10
Training loss: 0.6031548380851746
Validation loss: 1.719593213450524

Epoch: 6| Step: 11
Training loss: 0.6801333427429199
Validation loss: 1.6962060671980663

Epoch: 6| Step: 12
Training loss: 0.34164920449256897
Validation loss: 1.6594161705304218

Epoch: 6| Step: 13
Training loss: 0.6114204525947571
Validation loss: 1.6400896438988306

Epoch: 256| Step: 0
Training loss: 0.4390750527381897
Validation loss: 1.62472883091178

Epoch: 6| Step: 1
Training loss: 0.4659796357154846
Validation loss: 1.6699077493400984

Epoch: 6| Step: 2
Training loss: 0.4153757095336914
Validation loss: 1.6402744849522908

Epoch: 6| Step: 3
Training loss: 0.44186586141586304
Validation loss: 1.643560177536421

Epoch: 6| Step: 4
Training loss: 0.5071830749511719
Validation loss: 1.657113476466107

Epoch: 6| Step: 5
Training loss: 0.6524485945701599
Validation loss: 1.6340066720080633

Epoch: 6| Step: 6
Training loss: 0.453233927488327
Validation loss: 1.6527464723074308

Epoch: 6| Step: 7
Training loss: 0.7074443101882935
Validation loss: 1.6934978769671531

Epoch: 6| Step: 8
Training loss: 0.4247454106807709
Validation loss: 1.6967229509866366

Epoch: 6| Step: 9
Training loss: 0.714739203453064
Validation loss: 1.713973952877906

Epoch: 6| Step: 10
Training loss: 0.6189355254173279
Validation loss: 1.7760290458638182

Epoch: 6| Step: 11
Training loss: 0.42989978194236755
Validation loss: 1.7428502113588396

Epoch: 6| Step: 12
Training loss: 0.9688767194747925
Validation loss: 1.7217901573386243

Epoch: 6| Step: 13
Training loss: 0.27045780420303345
Validation loss: 1.7097771590755833

Epoch: 257| Step: 0
Training loss: 0.22507961094379425
Validation loss: 1.719343077751898

Epoch: 6| Step: 1
Training loss: 0.49557146430015564
Validation loss: 1.7159596963595318

Epoch: 6| Step: 2
Training loss: 0.5341259241104126
Validation loss: 1.7367089127981534

Epoch: 6| Step: 3
Training loss: 0.698809027671814
Validation loss: 1.7507903127260105

Epoch: 6| Step: 4
Training loss: 0.5830836296081543
Validation loss: 1.766410171344716

Epoch: 6| Step: 5
Training loss: 0.7664515376091003
Validation loss: 1.7961601775179628

Epoch: 6| Step: 6
Training loss: 0.4030112624168396
Validation loss: 1.8167803441324542

Epoch: 6| Step: 7
Training loss: 0.5203104019165039
Validation loss: 1.7490464346383208

Epoch: 6| Step: 8
Training loss: 0.6251068115234375
Validation loss: 1.7676025282952093

Epoch: 6| Step: 9
Training loss: 0.42459216713905334
Validation loss: 1.7379954681601575

Epoch: 6| Step: 10
Training loss: 0.36803627014160156
Validation loss: 1.7384049994971162

Epoch: 6| Step: 11
Training loss: 0.511298656463623
Validation loss: 1.7333502410560526

Epoch: 6| Step: 12
Training loss: 0.521224319934845
Validation loss: 1.7202400827920565

Epoch: 6| Step: 13
Training loss: 0.45010149478912354
Validation loss: 1.745101059636762

Epoch: 258| Step: 0
Training loss: 0.9631009101867676
Validation loss: 1.7553463584633284

Epoch: 6| Step: 1
Training loss: 0.5545585751533508
Validation loss: 1.7498267363476496

Epoch: 6| Step: 2
Training loss: 0.48913729190826416
Validation loss: 1.742091143003074

Epoch: 6| Step: 3
Training loss: 0.4151208996772766
Validation loss: 1.7141820897338211

Epoch: 6| Step: 4
Training loss: 0.6504598259925842
Validation loss: 1.7420522115563835

Epoch: 6| Step: 5
Training loss: 0.6648617386817932
Validation loss: 1.711543054990871

Epoch: 6| Step: 6
Training loss: 0.37111136317253113
Validation loss: 1.7083770395607076

Epoch: 6| Step: 7
Training loss: 0.5764022469520569
Validation loss: 1.7055220027123728

Epoch: 6| Step: 8
Training loss: 0.3474579453468323
Validation loss: 1.7125177793605353

Epoch: 6| Step: 9
Training loss: 0.3099272847175598
Validation loss: 1.7142001973685397

Epoch: 6| Step: 10
Training loss: 0.3822318911552429
Validation loss: 1.714874017623163

Epoch: 6| Step: 11
Training loss: 0.7055259943008423
Validation loss: 1.731114939976764

Epoch: 6| Step: 12
Training loss: 0.3917115330696106
Validation loss: 1.7763608283894037

Epoch: 6| Step: 13
Training loss: 0.2801781892776489
Validation loss: 1.787722977258826

Epoch: 259| Step: 0
Training loss: 0.3383300006389618
Validation loss: 1.7494936079107306

Epoch: 6| Step: 1
Training loss: 0.4439288377761841
Validation loss: 1.7901347452594387

Epoch: 6| Step: 2
Training loss: 0.2949041724205017
Validation loss: 1.770535938201412

Epoch: 6| Step: 3
Training loss: 0.4608791470527649
Validation loss: 1.7486330116948774

Epoch: 6| Step: 4
Training loss: 0.5589364171028137
Validation loss: 1.7526125805352324

Epoch: 6| Step: 5
Training loss: 0.7249754071235657
Validation loss: 1.7306590669898576

Epoch: 6| Step: 6
Training loss: 0.42679083347320557
Validation loss: 1.7414505097173876

Epoch: 6| Step: 7
Training loss: 0.37615966796875
Validation loss: 1.7299951122653099

Epoch: 6| Step: 8
Training loss: 0.7987451553344727
Validation loss: 1.7422026382979525

Epoch: 6| Step: 9
Training loss: 0.444286584854126
Validation loss: 1.7341904653015958

Epoch: 6| Step: 10
Training loss: 0.37216275930404663
Validation loss: 1.7522050014106176

Epoch: 6| Step: 11
Training loss: 0.6519333124160767
Validation loss: 1.7533056582173994

Epoch: 6| Step: 12
Training loss: 0.3538544774055481
Validation loss: 1.7496121903901458

Epoch: 6| Step: 13
Training loss: 0.5597259998321533
Validation loss: 1.7732818716315812

Epoch: 260| Step: 0
Training loss: 0.42347410321235657
Validation loss: 1.7436472036505257

Epoch: 6| Step: 1
Training loss: 0.5237536430358887
Validation loss: 1.7628763542380383

Epoch: 6| Step: 2
Training loss: 0.3459060788154602
Validation loss: 1.756756099321509

Epoch: 6| Step: 3
Training loss: 0.5533645749092102
Validation loss: 1.7964925612172773

Epoch: 6| Step: 4
Training loss: 0.6968945264816284
Validation loss: 1.7479862051625406

Epoch: 6| Step: 5
Training loss: 0.32373419404029846
Validation loss: 1.7278982054802678

Epoch: 6| Step: 6
Training loss: 0.5144219398498535
Validation loss: 1.7642320048424505

Epoch: 6| Step: 7
Training loss: 0.7853620052337646
Validation loss: 1.755482090416775

Epoch: 6| Step: 8
Training loss: 0.9017891883850098
Validation loss: 1.7218767930102605

Epoch: 6| Step: 9
Training loss: 0.3147488236427307
Validation loss: 1.711919806336844

Epoch: 6| Step: 10
Training loss: 0.6699601411819458
Validation loss: 1.73647823128649

Epoch: 6| Step: 11
Training loss: 0.41671186685562134
Validation loss: 1.7329411916835333

Epoch: 6| Step: 12
Training loss: 0.549302339553833
Validation loss: 1.73291838553644

Epoch: 6| Step: 13
Training loss: 0.395717978477478
Validation loss: 1.7779662609100342

Epoch: 261| Step: 0
Training loss: 0.5575190782546997
Validation loss: 1.7516667932592414

Epoch: 6| Step: 1
Training loss: 0.5750194191932678
Validation loss: 1.739296559364565

Epoch: 6| Step: 2
Training loss: 0.28092890977859497
Validation loss: 1.7053599857514905

Epoch: 6| Step: 3
Training loss: 0.45385274291038513
Validation loss: 1.6925793578547816

Epoch: 6| Step: 4
Training loss: 0.4075593054294586
Validation loss: 1.6812064545128935

Epoch: 6| Step: 5
Training loss: 0.9522006511688232
Validation loss: 1.7062518160830262

Epoch: 6| Step: 6
Training loss: 0.46336764097213745
Validation loss: 1.7349040892816359

Epoch: 6| Step: 7
Training loss: 0.5975451469421387
Validation loss: 1.69576221640392

Epoch: 6| Step: 8
Training loss: 0.5571086406707764
Validation loss: 1.7180389511969782

Epoch: 6| Step: 9
Training loss: 0.4210813343524933
Validation loss: 1.732723456557079

Epoch: 6| Step: 10
Training loss: 0.6829867362976074
Validation loss: 1.7189192489911151

Epoch: 6| Step: 11
Training loss: 0.5168028473854065
Validation loss: 1.7054794898597143

Epoch: 6| Step: 12
Training loss: 0.3378540575504303
Validation loss: 1.727193219687349

Epoch: 6| Step: 13
Training loss: 0.25655436515808105
Validation loss: 1.698371797479609

Epoch: 262| Step: 0
Training loss: 0.6283801198005676
Validation loss: 1.7139413126053349

Epoch: 6| Step: 1
Training loss: 0.5903536081314087
Validation loss: 1.7200140722336308

Epoch: 6| Step: 2
Training loss: 0.6064044237136841
Validation loss: 1.7126443488623506

Epoch: 6| Step: 3
Training loss: 0.48728275299072266
Validation loss: 1.663797592604032

Epoch: 6| Step: 4
Training loss: 0.43563222885131836
Validation loss: 1.6596483492082166

Epoch: 6| Step: 5
Training loss: 0.2522139549255371
Validation loss: 1.663801423964962

Epoch: 6| Step: 6
Training loss: 0.8520002365112305
Validation loss: 1.669815771041378

Epoch: 6| Step: 7
Training loss: 0.19387218356132507
Validation loss: 1.6728691900930097

Epoch: 6| Step: 8
Training loss: 0.43512672185897827
Validation loss: 1.6994736040792158

Epoch: 6| Step: 9
Training loss: 0.46885669231414795
Validation loss: 1.653812261037929

Epoch: 6| Step: 10
Training loss: 0.37915295362472534
Validation loss: 1.6758679471990114

Epoch: 6| Step: 11
Training loss: 0.5677963495254517
Validation loss: 1.7126050726059945

Epoch: 6| Step: 12
Training loss: 0.5657580494880676
Validation loss: 1.711387776559399

Epoch: 6| Step: 13
Training loss: 0.448178768157959
Validation loss: 1.7124482226628128

Epoch: 263| Step: 0
Training loss: 0.348635196685791
Validation loss: 1.7218524358605827

Epoch: 6| Step: 1
Training loss: 0.45541301369667053
Validation loss: 1.719363276676465

Epoch: 6| Step: 2
Training loss: 0.42290011048316956
Validation loss: 1.7378816553341445

Epoch: 6| Step: 3
Training loss: 0.5850942134857178
Validation loss: 1.7045263859533495

Epoch: 6| Step: 4
Training loss: 0.7283892631530762
Validation loss: 1.69169650026547

Epoch: 6| Step: 5
Training loss: 0.4054756164550781
Validation loss: 1.6814863733066026

Epoch: 6| Step: 6
Training loss: 0.8363796472549438
Validation loss: 1.6495088300397318

Epoch: 6| Step: 7
Training loss: 0.4447178542613983
Validation loss: 1.6444304399592902

Epoch: 6| Step: 8
Training loss: 0.3506813943386078
Validation loss: 1.6506097803833664

Epoch: 6| Step: 9
Training loss: 0.6088166236877441
Validation loss: 1.633420410976615

Epoch: 6| Step: 10
Training loss: 0.4129294455051422
Validation loss: 1.691369528411537

Epoch: 6| Step: 11
Training loss: 0.3576250672340393
Validation loss: 1.671913908373925

Epoch: 6| Step: 12
Training loss: 0.41179159283638
Validation loss: 1.6500384474313388

Epoch: 6| Step: 13
Training loss: 0.761093258857727
Validation loss: 1.6866133072042977

Epoch: 264| Step: 0
Training loss: 0.6532312035560608
Validation loss: 1.6812034717170141

Epoch: 6| Step: 1
Training loss: 0.47479212284088135
Validation loss: 1.6722469047833515

Epoch: 6| Step: 2
Training loss: 0.4071633219718933
Validation loss: 1.7259279066516506

Epoch: 6| Step: 3
Training loss: 0.42459946870803833
Validation loss: 1.7080077381544216

Epoch: 6| Step: 4
Training loss: 0.5818687081336975
Validation loss: 1.7360672015015797

Epoch: 6| Step: 5
Training loss: 0.5238910913467407
Validation loss: 1.7401546957672283

Epoch: 6| Step: 6
Training loss: 0.38358598947525024
Validation loss: 1.7160909419418664

Epoch: 6| Step: 7
Training loss: 0.9223524332046509
Validation loss: 1.757689840050154

Epoch: 6| Step: 8
Training loss: 0.4148799777030945
Validation loss: 1.714531740834636

Epoch: 6| Step: 9
Training loss: 0.3756658136844635
Validation loss: 1.746581805649624

Epoch: 6| Step: 10
Training loss: 0.4492074251174927
Validation loss: 1.734634122540874

Epoch: 6| Step: 11
Training loss: 0.3633398115634918
Validation loss: 1.7056585986127135

Epoch: 6| Step: 12
Training loss: 0.17071110010147095
Validation loss: 1.6901368530847694

Epoch: 6| Step: 13
Training loss: 0.5839242339134216
Validation loss: 1.6695667607809908

Epoch: 265| Step: 0
Training loss: 0.6068198680877686
Validation loss: 1.6684683125506166

Epoch: 6| Step: 1
Training loss: 0.5188512802124023
Validation loss: 1.680940306314858

Epoch: 6| Step: 2
Training loss: 0.4613032937049866
Validation loss: 1.6911610916096678

Epoch: 6| Step: 3
Training loss: 0.5824906229972839
Validation loss: 1.6983030303832023

Epoch: 6| Step: 4
Training loss: 0.4065636396408081
Validation loss: 1.6836290795315978

Epoch: 6| Step: 5
Training loss: 0.6846874356269836
Validation loss: 1.6896127507250795

Epoch: 6| Step: 6
Training loss: 0.5111063718795776
Validation loss: 1.669420434582618

Epoch: 6| Step: 7
Training loss: 0.47457200288772583
Validation loss: 1.7080679491002073

Epoch: 6| Step: 8
Training loss: 0.5208338499069214
Validation loss: 1.7089421659387567

Epoch: 6| Step: 9
Training loss: 0.5133544206619263
Validation loss: 1.716798492657241

Epoch: 6| Step: 10
Training loss: 0.46578675508499146
Validation loss: 1.7095250929555585

Epoch: 6| Step: 11
Training loss: 0.2780589759349823
Validation loss: 1.7248105579806912

Epoch: 6| Step: 12
Training loss: 0.44017529487609863
Validation loss: 1.8035666327322684

Epoch: 6| Step: 13
Training loss: 0.22114212810993195
Validation loss: 1.7683977593657791

Epoch: 266| Step: 0
Training loss: 0.34262531995773315
Validation loss: 1.789479765840756

Epoch: 6| Step: 1
Training loss: 0.652627170085907
Validation loss: 1.8104721346209127

Epoch: 6| Step: 2
Training loss: 0.30530035495758057
Validation loss: 1.8124294819370392

Epoch: 6| Step: 3
Training loss: 0.42072510719299316
Validation loss: 1.7908327874316965

Epoch: 6| Step: 4
Training loss: 0.4898543953895569
Validation loss: 1.7614049808953398

Epoch: 6| Step: 5
Training loss: 0.36452972888946533
Validation loss: 1.725099446952984

Epoch: 6| Step: 6
Training loss: 0.39408570528030396
Validation loss: 1.6775102666629258

Epoch: 6| Step: 7
Training loss: 0.316994309425354
Validation loss: 1.6838540851428945

Epoch: 6| Step: 8
Training loss: 0.5782909989356995
Validation loss: 1.6974076481275662

Epoch: 6| Step: 9
Training loss: 0.7309144735336304
Validation loss: 1.6988865393464283

Epoch: 6| Step: 10
Training loss: 0.37287068367004395
Validation loss: 1.6719603102694276

Epoch: 6| Step: 11
Training loss: 0.4915565252304077
Validation loss: 1.6721890946870208

Epoch: 6| Step: 12
Training loss: 0.7467705011367798
Validation loss: 1.6773938402052848

Epoch: 6| Step: 13
Training loss: 0.38064077496528625
Validation loss: 1.6567412755822624

Epoch: 267| Step: 0
Training loss: 0.27525681257247925
Validation loss: 1.6953807146318498

Epoch: 6| Step: 1
Training loss: 0.24275082349777222
Validation loss: 1.7067154543374174

Epoch: 6| Step: 2
Training loss: 0.5539493560791016
Validation loss: 1.733590692602178

Epoch: 6| Step: 3
Training loss: 0.45102325081825256
Validation loss: 1.7279739943883752

Epoch: 6| Step: 4
Training loss: 0.4254070520401001
Validation loss: 1.7494482801806541

Epoch: 6| Step: 5
Training loss: 0.7681995034217834
Validation loss: 1.7756600136397986

Epoch: 6| Step: 6
Training loss: 0.4600285291671753
Validation loss: 1.7767055060273858

Epoch: 6| Step: 7
Training loss: 0.5564144849777222
Validation loss: 1.7728614320037186

Epoch: 6| Step: 8
Training loss: 0.5549882650375366
Validation loss: 1.7746730517315608

Epoch: 6| Step: 9
Training loss: 0.3368734121322632
Validation loss: 1.7771942115599109

Epoch: 6| Step: 10
Training loss: 0.47583234310150146
Validation loss: 1.77450648302673

Epoch: 6| Step: 11
Training loss: 0.524137020111084
Validation loss: 1.7572239983466365

Epoch: 6| Step: 12
Training loss: 0.4086318910121918
Validation loss: 1.7501658701127576

Epoch: 6| Step: 13
Training loss: 0.5650069117546082
Validation loss: 1.7661597562092606

Epoch: 268| Step: 0
Training loss: 0.3020203411579132
Validation loss: 1.7594503574473883

Epoch: 6| Step: 1
Training loss: 0.35428670048713684
Validation loss: 1.7499130259278

Epoch: 6| Step: 2
Training loss: 0.5754456520080566
Validation loss: 1.7267406461059407

Epoch: 6| Step: 3
Training loss: 0.37613171339035034
Validation loss: 1.7484359446392264

Epoch: 6| Step: 4
Training loss: 0.5001220703125
Validation loss: 1.7464143614615164

Epoch: 6| Step: 5
Training loss: 0.474404901266098
Validation loss: 1.748169505467979

Epoch: 6| Step: 6
Training loss: 0.42903459072113037
Validation loss: 1.7088484738462715

Epoch: 6| Step: 7
Training loss: 0.8419221043586731
Validation loss: 1.7258382651113695

Epoch: 6| Step: 8
Training loss: 0.31965795159339905
Validation loss: 1.7153258656942716

Epoch: 6| Step: 9
Training loss: 0.4658581614494324
Validation loss: 1.7324563149482972

Epoch: 6| Step: 10
Training loss: 0.3798282742500305
Validation loss: 1.731002761471656

Epoch: 6| Step: 11
Training loss: 0.38846343755722046
Validation loss: 1.7579837274807755

Epoch: 6| Step: 12
Training loss: 0.4973074793815613
Validation loss: 1.7537002640385781

Epoch: 6| Step: 13
Training loss: 0.4055609703063965
Validation loss: 1.7906663956180695

Epoch: 269| Step: 0
Training loss: 0.5683820247650146
Validation loss: 1.7721005511540238

Epoch: 6| Step: 1
Training loss: 0.2533385753631592
Validation loss: 1.761858492769221

Epoch: 6| Step: 2
Training loss: 0.3288147747516632
Validation loss: 1.8025124226847002

Epoch: 6| Step: 3
Training loss: 0.4176748991012573
Validation loss: 1.7515654461358183

Epoch: 6| Step: 4
Training loss: 0.6028267741203308
Validation loss: 1.7418082093679776

Epoch: 6| Step: 5
Training loss: 0.3609490990638733
Validation loss: 1.7319916422649095

Epoch: 6| Step: 6
Training loss: 0.484337717294693
Validation loss: 1.7055947985700382

Epoch: 6| Step: 7
Training loss: 0.5970565676689148
Validation loss: 1.687239004719642

Epoch: 6| Step: 8
Training loss: 0.3281272053718567
Validation loss: 1.697838464090901

Epoch: 6| Step: 9
Training loss: 0.42564424872398376
Validation loss: 1.702519170699581

Epoch: 6| Step: 10
Training loss: 0.38156771659851074
Validation loss: 1.7014538318880144

Epoch: 6| Step: 11
Training loss: 0.4145559072494507
Validation loss: 1.6875530186519827

Epoch: 6| Step: 12
Training loss: 0.729971170425415
Validation loss: 1.732766216801059

Epoch: 6| Step: 13
Training loss: 0.35380396246910095
Validation loss: 1.6968828042348225

Epoch: 270| Step: 0
Training loss: 0.5183310508728027
Validation loss: 1.722000120788492

Epoch: 6| Step: 1
Training loss: 0.5843633413314819
Validation loss: 1.703068366614721

Epoch: 6| Step: 2
Training loss: 0.38087451457977295
Validation loss: 1.6909562233955628

Epoch: 6| Step: 3
Training loss: 0.40522247552871704
Validation loss: 1.7104786685718003

Epoch: 6| Step: 4
Training loss: 0.29508405923843384
Validation loss: 1.6843970591022122

Epoch: 6| Step: 5
Training loss: 0.4786214232444763
Validation loss: 1.6930738136332522

Epoch: 6| Step: 6
Training loss: 0.39665618538856506
Validation loss: 1.6972193589774511

Epoch: 6| Step: 7
Training loss: 0.5029417872428894
Validation loss: 1.7122057227678196

Epoch: 6| Step: 8
Training loss: 0.304763525724411
Validation loss: 1.7298842912079186

Epoch: 6| Step: 9
Training loss: 0.7932596802711487
Validation loss: 1.694367931735131

Epoch: 6| Step: 10
Training loss: 0.3169318437576294
Validation loss: 1.696875153049346

Epoch: 6| Step: 11
Training loss: 0.44226887822151184
Validation loss: 1.692716948447689

Epoch: 6| Step: 12
Training loss: 0.3297784924507141
Validation loss: 1.709459880346893

Epoch: 6| Step: 13
Training loss: 0.6633962392807007
Validation loss: 1.698974706793344

Epoch: 271| Step: 0
Training loss: 0.7411643266677856
Validation loss: 1.7314040840312999

Epoch: 6| Step: 1
Training loss: 0.5274677872657776
Validation loss: 1.7149347643698416

Epoch: 6| Step: 2
Training loss: 0.18733175098896027
Validation loss: 1.7380869414216729

Epoch: 6| Step: 3
Training loss: 0.2964165210723877
Validation loss: 1.7475761790429392

Epoch: 6| Step: 4
Training loss: 0.4582059383392334
Validation loss: 1.719414020097384

Epoch: 6| Step: 5
Training loss: 0.37633901834487915
Validation loss: 1.7026566010649486

Epoch: 6| Step: 6
Training loss: 0.8011060953140259
Validation loss: 1.6855136309900591

Epoch: 6| Step: 7
Training loss: 0.3782309293746948
Validation loss: 1.6845260191989202

Epoch: 6| Step: 8
Training loss: 0.9496627449989319
Validation loss: 1.6880240568550684

Epoch: 6| Step: 9
Training loss: 0.3781384825706482
Validation loss: 1.6952054615943664

Epoch: 6| Step: 10
Training loss: 0.45278728008270264
Validation loss: 1.7178711352809783

Epoch: 6| Step: 11
Training loss: 0.27132248878479004
Validation loss: 1.7419556930500975

Epoch: 6| Step: 12
Training loss: 0.43186402320861816
Validation loss: 1.7466525570038827

Epoch: 6| Step: 13
Training loss: 0.2449485957622528
Validation loss: 1.775287840956001

Epoch: 272| Step: 0
Training loss: 0.7012867331504822
Validation loss: 1.7662810651204919

Epoch: 6| Step: 1
Training loss: 0.5901278257369995
Validation loss: 1.7468484268393567

Epoch: 6| Step: 2
Training loss: 0.4240391254425049
Validation loss: 1.7554404684292373

Epoch: 6| Step: 3
Training loss: 0.3727118968963623
Validation loss: 1.7630303123945832

Epoch: 6| Step: 4
Training loss: 0.2376643866300583
Validation loss: 1.7240488413841493

Epoch: 6| Step: 5
Training loss: 0.5475466251373291
Validation loss: 1.7128008360503821

Epoch: 6| Step: 6
Training loss: 0.5088529586791992
Validation loss: 1.6890500258373957

Epoch: 6| Step: 7
Training loss: 0.4585959315299988
Validation loss: 1.698859466019497

Epoch: 6| Step: 8
Training loss: 0.3081963360309601
Validation loss: 1.695540197433964

Epoch: 6| Step: 9
Training loss: 0.46200162172317505
Validation loss: 1.7229845229015555

Epoch: 6| Step: 10
Training loss: 0.28798186779022217
Validation loss: 1.6868667858903126

Epoch: 6| Step: 11
Training loss: 0.38140568137168884
Validation loss: 1.691194083101006

Epoch: 6| Step: 12
Training loss: 0.22847984731197357
Validation loss: 1.6696796173690467

Epoch: 6| Step: 13
Training loss: 0.691387951374054
Validation loss: 1.6656666609548754

Epoch: 273| Step: 0
Training loss: 0.36326900124549866
Validation loss: 1.6895594391771542

Epoch: 6| Step: 1
Training loss: 0.37393784523010254
Validation loss: 1.684314509873749

Epoch: 6| Step: 2
Training loss: 0.32578617334365845
Validation loss: 1.6780093203308761

Epoch: 6| Step: 3
Training loss: 0.35675910115242004
Validation loss: 1.6911019157337885

Epoch: 6| Step: 4
Training loss: 0.5169702768325806
Validation loss: 1.6998015552438714

Epoch: 6| Step: 5
Training loss: 0.3560769557952881
Validation loss: 1.7074508948992657

Epoch: 6| Step: 6
Training loss: 0.8301617503166199
Validation loss: 1.7320655084425403

Epoch: 6| Step: 7
Training loss: 0.3055192232131958
Validation loss: 1.7457025153662569

Epoch: 6| Step: 8
Training loss: 0.8955446481704712
Validation loss: 1.7402985506160285

Epoch: 6| Step: 9
Training loss: 0.3846414089202881
Validation loss: 1.7267283111490228

Epoch: 6| Step: 10
Training loss: 0.4534362256526947
Validation loss: 1.686148666566418

Epoch: 6| Step: 11
Training loss: 0.23588457703590393
Validation loss: 1.71642485485282

Epoch: 6| Step: 12
Training loss: 0.3245622515678406
Validation loss: 1.7044566754371888

Epoch: 6| Step: 13
Training loss: 0.2237747758626938
Validation loss: 1.7061206986827235

Epoch: 274| Step: 0
Training loss: 0.33110395073890686
Validation loss: 1.720813088519599

Epoch: 6| Step: 1
Training loss: 0.6694033145904541
Validation loss: 1.7406925321907125

Epoch: 6| Step: 2
Training loss: 0.23756766319274902
Validation loss: 1.7418839636669363

Epoch: 6| Step: 3
Training loss: 0.4179975390434265
Validation loss: 1.7221912222523843

Epoch: 6| Step: 4
Training loss: 0.48979413509368896
Validation loss: 1.7155112630577498

Epoch: 6| Step: 5
Training loss: 0.538407027721405
Validation loss: 1.7500323672448435

Epoch: 6| Step: 6
Training loss: 0.33798468112945557
Validation loss: 1.7276159127553303

Epoch: 6| Step: 7
Training loss: 0.6773730516433716
Validation loss: 1.6905777480012627

Epoch: 6| Step: 8
Training loss: 0.3525780439376831
Validation loss: 1.7297954482416953

Epoch: 6| Step: 9
Training loss: 0.43825361132621765
Validation loss: 1.6803183876058108

Epoch: 6| Step: 10
Training loss: 0.38338685035705566
Validation loss: 1.6855320751026113

Epoch: 6| Step: 11
Training loss: 0.31776654720306396
Validation loss: 1.6667131877714587

Epoch: 6| Step: 12
Training loss: 0.30569392442703247
Validation loss: 1.6570871158312726

Epoch: 6| Step: 13
Training loss: 0.31746208667755127
Validation loss: 1.620251227450627

Epoch: 275| Step: 0
Training loss: 0.580289363861084
Validation loss: 1.6351985316122732

Epoch: 6| Step: 1
Training loss: 0.26826101541519165
Validation loss: 1.6408419045068885

Epoch: 6| Step: 2
Training loss: 0.1914472132921219
Validation loss: 1.6667353991539247

Epoch: 6| Step: 3
Training loss: 0.4612690806388855
Validation loss: 1.6669792846966816

Epoch: 6| Step: 4
Training loss: 0.4141083061695099
Validation loss: 1.646549517108548

Epoch: 6| Step: 5
Training loss: 0.487591952085495
Validation loss: 1.6820649254706599

Epoch: 6| Step: 6
Training loss: 0.2793891429901123
Validation loss: 1.666644122010918

Epoch: 6| Step: 7
Training loss: 0.8532025814056396
Validation loss: 1.661515530719552

Epoch: 6| Step: 8
Training loss: 0.3454485535621643
Validation loss: 1.651758534933931

Epoch: 6| Step: 9
Training loss: 0.3485856354236603
Validation loss: 1.681804282690889

Epoch: 6| Step: 10
Training loss: 0.2982059121131897
Validation loss: 1.6794443630403089

Epoch: 6| Step: 11
Training loss: 0.4621117115020752
Validation loss: 1.680576152698968

Epoch: 6| Step: 12
Training loss: 0.6531097888946533
Validation loss: 1.673295864494898

Epoch: 6| Step: 13
Training loss: 0.14869046211242676
Validation loss: 1.7107335495692428

Epoch: 276| Step: 0
Training loss: 0.43831244111061096
Validation loss: 1.665076535235169

Epoch: 6| Step: 1
Training loss: 0.6377646923065186
Validation loss: 1.6832960997858355

Epoch: 6| Step: 2
Training loss: 0.6156170964241028
Validation loss: 1.6765483874146656

Epoch: 6| Step: 3
Training loss: 0.32637500762939453
Validation loss: 1.6736544434742262

Epoch: 6| Step: 4
Training loss: 0.34823864698410034
Validation loss: 1.7059319711500598

Epoch: 6| Step: 5
Training loss: 0.5628347992897034
Validation loss: 1.70568771003395

Epoch: 6| Step: 6
Training loss: 0.37193435430526733
Validation loss: 1.6840180729025154

Epoch: 6| Step: 7
Training loss: 0.3360902965068817
Validation loss: 1.7143415097267396

Epoch: 6| Step: 8
Training loss: 0.3382100462913513
Validation loss: 1.7087071570017005

Epoch: 6| Step: 9
Training loss: 0.10025083273649216
Validation loss: 1.7077282551796205

Epoch: 6| Step: 10
Training loss: 0.5214582681655884
Validation loss: 1.7375610182362218

Epoch: 6| Step: 11
Training loss: 0.48940059542655945
Validation loss: 1.7521939713467833

Epoch: 6| Step: 12
Training loss: 0.28801438212394714
Validation loss: 1.7560836807374032

Epoch: 6| Step: 13
Training loss: 0.35906586050987244
Validation loss: 1.7693170270612162

Epoch: 277| Step: 0
Training loss: 0.36639726161956787
Validation loss: 1.7859712621217132

Epoch: 6| Step: 1
Training loss: 0.5573899745941162
Validation loss: 1.777505970770313

Epoch: 6| Step: 2
Training loss: 0.48095256090164185
Validation loss: 1.7860832111809843

Epoch: 6| Step: 3
Training loss: 0.24624083936214447
Validation loss: 1.7264545579110422

Epoch: 6| Step: 4
Training loss: 0.4170594811439514
Validation loss: 1.7599249001472228

Epoch: 6| Step: 5
Training loss: 0.6028457283973694
Validation loss: 1.718419180121473

Epoch: 6| Step: 6
Training loss: 0.30897900462150574
Validation loss: 1.700681201873287

Epoch: 6| Step: 7
Training loss: 0.16334006190299988
Validation loss: 1.6721855953175535

Epoch: 6| Step: 8
Training loss: 0.5616689324378967
Validation loss: 1.6863465616779942

Epoch: 6| Step: 9
Training loss: 0.3682558536529541
Validation loss: 1.6319739280208465

Epoch: 6| Step: 10
Training loss: 0.37924763560295105
Validation loss: 1.667052069017964

Epoch: 6| Step: 11
Training loss: 0.49029070138931274
Validation loss: 1.6503835634518695

Epoch: 6| Step: 12
Training loss: 0.5529618263244629
Validation loss: 1.6736695856176398

Epoch: 6| Step: 13
Training loss: 0.6564143896102905
Validation loss: 1.708737378479332

Epoch: 278| Step: 0
Training loss: 0.32419002056121826
Validation loss: 1.6747965658864667

Epoch: 6| Step: 1
Training loss: 0.4510005712509155
Validation loss: 1.6791489367843957

Epoch: 6| Step: 2
Training loss: 0.3006160259246826
Validation loss: 1.7274336789243965

Epoch: 6| Step: 3
Training loss: 0.46147671341896057
Validation loss: 1.7484795316573112

Epoch: 6| Step: 4
Training loss: 0.46506476402282715
Validation loss: 1.7604180843599382

Epoch: 6| Step: 5
Training loss: 0.6247423887252808
Validation loss: 1.7082019659780687

Epoch: 6| Step: 6
Training loss: 0.18504202365875244
Validation loss: 1.7262813839861142

Epoch: 6| Step: 7
Training loss: 0.7599387764930725
Validation loss: 1.7575567640284055

Epoch: 6| Step: 8
Training loss: 0.21929335594177246
Validation loss: 1.7505481294406358

Epoch: 6| Step: 9
Training loss: 0.31692683696746826
Validation loss: 1.773475254735639

Epoch: 6| Step: 10
Training loss: 0.26252344250679016
Validation loss: 1.7618039474692395

Epoch: 6| Step: 11
Training loss: 0.563909113407135
Validation loss: 1.77979483783886

Epoch: 6| Step: 12
Training loss: 0.4015665054321289
Validation loss: 1.7645857693046652

Epoch: 6| Step: 13
Training loss: 0.31865501403808594
Validation loss: 1.7790303230285645

Epoch: 279| Step: 0
Training loss: 0.450511634349823
Validation loss: 1.7441922874860867

Epoch: 6| Step: 1
Training loss: 0.14896340668201447
Validation loss: 1.7628236521956742

Epoch: 6| Step: 2
Training loss: 0.5597279071807861
Validation loss: 1.7570858399073284

Epoch: 6| Step: 3
Training loss: 0.5367388725280762
Validation loss: 1.796803189862159

Epoch: 6| Step: 4
Training loss: 0.25201860070228577
Validation loss: 1.776298015348373

Epoch: 6| Step: 5
Training loss: 0.5652006268501282
Validation loss: 1.7807166243112216

Epoch: 6| Step: 6
Training loss: 0.24259474873542786
Validation loss: 1.7688505213747743

Epoch: 6| Step: 7
Training loss: 0.6893924474716187
Validation loss: 1.7671069329784763

Epoch: 6| Step: 8
Training loss: 0.37840527296066284
Validation loss: 1.7861993979382258

Epoch: 6| Step: 9
Training loss: 0.12332367897033691
Validation loss: 1.744974155579844

Epoch: 6| Step: 10
Training loss: 0.7717784643173218
Validation loss: 1.7341915240851782

Epoch: 6| Step: 11
Training loss: 0.42391437292099
Validation loss: 1.6973500995225803

Epoch: 6| Step: 12
Training loss: 0.49111407995224
Validation loss: 1.673425998739017

Epoch: 6| Step: 13
Training loss: 0.3670389950275421
Validation loss: 1.6366208202095442

Epoch: 280| Step: 0
Training loss: 0.41941404342651367
Validation loss: 1.6226142888428063

Epoch: 6| Step: 1
Training loss: 0.7828619480133057
Validation loss: 1.611057275085039

Epoch: 6| Step: 2
Training loss: 0.3189693093299866
Validation loss: 1.628761404304094

Epoch: 6| Step: 3
Training loss: 0.4464758634567261
Validation loss: 1.629130926183475

Epoch: 6| Step: 4
Training loss: 0.6737298369407654
Validation loss: 1.6368450939014394

Epoch: 6| Step: 5
Training loss: 0.7770824432373047
Validation loss: 1.6486288039915022

Epoch: 6| Step: 6
Training loss: 0.43326452374458313
Validation loss: 1.6129172681480326

Epoch: 6| Step: 7
Training loss: 0.3916141092777252
Validation loss: 1.6769121039298274

Epoch: 6| Step: 8
Training loss: 0.23478572070598602
Validation loss: 1.660235361386371

Epoch: 6| Step: 9
Training loss: 0.28109657764434814
Validation loss: 1.6711220074725408

Epoch: 6| Step: 10
Training loss: 0.17348627746105194
Validation loss: 1.7725255771349835

Epoch: 6| Step: 11
Training loss: 0.22613617777824402
Validation loss: 1.8349309467500257

Epoch: 6| Step: 12
Training loss: 0.6510088443756104
Validation loss: 1.8221350293005667

Epoch: 6| Step: 13
Training loss: 0.5538910627365112
Validation loss: 1.863343829749733

Epoch: 281| Step: 0
Training loss: 0.5141690373420715
Validation loss: 1.8369144893461657

Epoch: 6| Step: 1
Training loss: 0.8475692868232727
Validation loss: 1.81155683917384

Epoch: 6| Step: 2
Training loss: 0.39300602674484253
Validation loss: 1.7732622700352823

Epoch: 6| Step: 3
Training loss: 0.39959144592285156
Validation loss: 1.722704251607259

Epoch: 6| Step: 4
Training loss: 0.6054808497428894
Validation loss: 1.7192749054201188

Epoch: 6| Step: 5
Training loss: 0.3386279344558716
Validation loss: 1.7181139428128478

Epoch: 6| Step: 6
Training loss: 0.48116132616996765
Validation loss: 1.6781712885825866

Epoch: 6| Step: 7
Training loss: 0.40588435530662537
Validation loss: 1.6406140006998533

Epoch: 6| Step: 8
Training loss: 0.4200047552585602
Validation loss: 1.63709391701606

Epoch: 6| Step: 9
Training loss: 0.4493756890296936
Validation loss: 1.6470804688751057

Epoch: 6| Step: 10
Training loss: 0.28807333111763
Validation loss: 1.621029293665322

Epoch: 6| Step: 11
Training loss: 0.35502445697784424
Validation loss: 1.6433026995710147

Epoch: 6| Step: 12
Training loss: 0.33172956109046936
Validation loss: 1.648441272397195

Epoch: 6| Step: 13
Training loss: 0.38717347383499146
Validation loss: 1.6725308946383897

Epoch: 282| Step: 0
Training loss: 0.6635411977767944
Validation loss: 1.697499088061753

Epoch: 6| Step: 1
Training loss: 0.43053239583969116
Validation loss: 1.6543345438536776

Epoch: 6| Step: 2
Training loss: 0.42610636353492737
Validation loss: 1.6832920607700144

Epoch: 6| Step: 3
Training loss: 0.4338845908641815
Validation loss: 1.6591330164222307

Epoch: 6| Step: 4
Training loss: 0.4641464650630951
Validation loss: 1.6503287066695511

Epoch: 6| Step: 5
Training loss: 0.26086729764938354
Validation loss: 1.6278571646700624

Epoch: 6| Step: 6
Training loss: 0.6550531387329102
Validation loss: 1.668437014343918

Epoch: 6| Step: 7
Training loss: 0.30976539850234985
Validation loss: 1.680310594779189

Epoch: 6| Step: 8
Training loss: 0.24854737520217896
Validation loss: 1.6530636587450582

Epoch: 6| Step: 9
Training loss: 0.630401611328125
Validation loss: 1.6989378929138184

Epoch: 6| Step: 10
Training loss: 0.3169773519039154
Validation loss: 1.6754149929169686

Epoch: 6| Step: 11
Training loss: 0.5493841767311096
Validation loss: 1.671145974948842

Epoch: 6| Step: 12
Training loss: 0.20206591486930847
Validation loss: 1.6666579848976546

Epoch: 6| Step: 13
Training loss: 0.24604004621505737
Validation loss: 1.6938544486158638

Epoch: 283| Step: 0
Training loss: 0.6493985652923584
Validation loss: 1.6670310548556748

Epoch: 6| Step: 1
Training loss: 0.4849852919578552
Validation loss: 1.6951068383391186

Epoch: 6| Step: 2
Training loss: 0.3790014386177063
Validation loss: 1.6861039079645628

Epoch: 6| Step: 3
Training loss: 0.2551894187927246
Validation loss: 1.6667264135934974

Epoch: 6| Step: 4
Training loss: 0.39588624238967896
Validation loss: 1.6571531680322462

Epoch: 6| Step: 5
Training loss: 0.3198295831680298
Validation loss: 1.6572925583008797

Epoch: 6| Step: 6
Training loss: 0.30711257457733154
Validation loss: 1.675993445099041

Epoch: 6| Step: 7
Training loss: 0.43547123670578003
Validation loss: 1.6584784484678698

Epoch: 6| Step: 8
Training loss: 0.3518593907356262
Validation loss: 1.6856185825922156

Epoch: 6| Step: 9
Training loss: 0.2155257612466812
Validation loss: 1.7001583422383955

Epoch: 6| Step: 10
Training loss: 0.37753817439079285
Validation loss: 1.7074041725486837

Epoch: 6| Step: 11
Training loss: 0.5048961639404297
Validation loss: 1.6834641861659225

Epoch: 6| Step: 12
Training loss: 0.4230802059173584
Validation loss: 1.6859733673834032

Epoch: 6| Step: 13
Training loss: 0.3896576762199402
Validation loss: 1.6765613543089999

Epoch: 284| Step: 0
Training loss: 0.32937395572662354
Validation loss: 1.6690640154705252

Epoch: 6| Step: 1
Training loss: 0.22231803834438324
Validation loss: 1.6755313873291016

Epoch: 6| Step: 2
Training loss: 0.4116879403591156
Validation loss: 1.64895865930024

Epoch: 6| Step: 3
Training loss: 0.31191521883010864
Validation loss: 1.6534006493065947

Epoch: 6| Step: 4
Training loss: 0.35016846656799316
Validation loss: 1.6676964708553847

Epoch: 6| Step: 5
Training loss: 0.4879243075847626
Validation loss: 1.6657105991917271

Epoch: 6| Step: 6
Training loss: 0.31947678327560425
Validation loss: 1.6543837337083713

Epoch: 6| Step: 7
Training loss: 0.2898767292499542
Validation loss: 1.6742903929884716

Epoch: 6| Step: 8
Training loss: 0.26703739166259766
Validation loss: 1.7062407309009182

Epoch: 6| Step: 9
Training loss: 0.43991798162460327
Validation loss: 1.6932671762281848

Epoch: 6| Step: 10
Training loss: 0.5136046409606934
Validation loss: 1.7006290830591673

Epoch: 6| Step: 11
Training loss: 0.42099234461784363
Validation loss: 1.740006681411497

Epoch: 6| Step: 12
Training loss: 0.7120029330253601
Validation loss: 1.7213775111782936

Epoch: 6| Step: 13
Training loss: 0.46028169989585876
Validation loss: 1.7271600333593224

Epoch: 285| Step: 0
Training loss: 0.4311875104904175
Validation loss: 1.7210236646795785

Epoch: 6| Step: 1
Training loss: 0.571322500705719
Validation loss: 1.7453322807947795

Epoch: 6| Step: 2
Training loss: 0.16152529418468475
Validation loss: 1.7731336201390913

Epoch: 6| Step: 3
Training loss: 0.3643178343772888
Validation loss: 1.7549394779307868

Epoch: 6| Step: 4
Training loss: 0.3291122317314148
Validation loss: 1.7522883889495686

Epoch: 6| Step: 5
Training loss: 0.38468462228775024
Validation loss: 1.7527388680365779

Epoch: 6| Step: 6
Training loss: 0.30664098262786865
Validation loss: 1.7334491924573017

Epoch: 6| Step: 7
Training loss: 0.590703547000885
Validation loss: 1.7696872424053889

Epoch: 6| Step: 8
Training loss: 0.29316896200180054
Validation loss: 1.7359741041737218

Epoch: 6| Step: 9
Training loss: 0.5205540657043457
Validation loss: 1.7055691621636833

Epoch: 6| Step: 10
Training loss: 0.47052663564682007
Validation loss: 1.7156632459291847

Epoch: 6| Step: 11
Training loss: 0.277322918176651
Validation loss: 1.7080562499261671

Epoch: 6| Step: 12
Training loss: 0.46051475405693054
Validation loss: 1.6820370202423425

Epoch: 6| Step: 13
Training loss: 0.40806102752685547
Validation loss: 1.6818778284134404

Epoch: 286| Step: 0
Training loss: 0.5020109415054321
Validation loss: 1.6779180393424085

Epoch: 6| Step: 1
Training loss: 0.3699544370174408
Validation loss: 1.7131876945495605

Epoch: 6| Step: 2
Training loss: 0.27860748767852783
Validation loss: 1.6783247288837229

Epoch: 6| Step: 3
Training loss: 0.40942907333374023
Validation loss: 1.694803027696507

Epoch: 6| Step: 4
Training loss: 0.7339528203010559
Validation loss: 1.6493848946786696

Epoch: 6| Step: 5
Training loss: 0.4493124485015869
Validation loss: 1.6495544397702782

Epoch: 6| Step: 6
Training loss: 0.30914148688316345
Validation loss: 1.6486586447684997

Epoch: 6| Step: 7
Training loss: 0.36153262853622437
Validation loss: 1.626960031447872

Epoch: 6| Step: 8
Training loss: 0.3081320822238922
Validation loss: 1.6633188724517822

Epoch: 6| Step: 9
Training loss: 0.5016177296638489
Validation loss: 1.670134102144549

Epoch: 6| Step: 10
Training loss: 0.3657136559486389
Validation loss: 1.6859065986448718

Epoch: 6| Step: 11
Training loss: 0.3432033061981201
Validation loss: 1.704597045016545

Epoch: 6| Step: 12
Training loss: 0.24388769268989563
Validation loss: 1.7067230375864173

Epoch: 6| Step: 13
Training loss: 0.2756121754646301
Validation loss: 1.7139637957337082

Epoch: 287| Step: 0
Training loss: 0.6010039448738098
Validation loss: 1.6866927800639984

Epoch: 6| Step: 1
Training loss: 0.20246464014053345
Validation loss: 1.732988719017275

Epoch: 6| Step: 2
Training loss: 0.3549051880836487
Validation loss: 1.7243254018086258

Epoch: 6| Step: 3
Training loss: 0.2250257134437561
Validation loss: 1.741469233266769

Epoch: 6| Step: 4
Training loss: 0.5710489749908447
Validation loss: 1.7055402648064397

Epoch: 6| Step: 5
Training loss: 0.4297582507133484
Validation loss: 1.7192125730617072

Epoch: 6| Step: 6
Training loss: 0.33277490735054016
Validation loss: 1.713397374717138

Epoch: 6| Step: 7
Training loss: 0.2823995053768158
Validation loss: 1.6943627019082346

Epoch: 6| Step: 8
Training loss: 0.41794896125793457
Validation loss: 1.6811678768486105

Epoch: 6| Step: 9
Training loss: 0.41421619057655334
Validation loss: 1.655541407164707

Epoch: 6| Step: 10
Training loss: 0.3285808563232422
Validation loss: 1.6822344808168308

Epoch: 6| Step: 11
Training loss: 0.38859105110168457
Validation loss: 1.6770213675755326

Epoch: 6| Step: 12
Training loss: 0.4320927858352661
Validation loss: 1.6698206778495543

Epoch: 6| Step: 13
Training loss: 0.605209469795227
Validation loss: 1.6559000348532071

Epoch: 288| Step: 0
Training loss: 0.32205671072006226
Validation loss: 1.638171458757052

Epoch: 6| Step: 1
Training loss: 0.31080782413482666
Validation loss: 1.6602405386586343

Epoch: 6| Step: 2
Training loss: 0.20193955302238464
Validation loss: 1.6536558046135852

Epoch: 6| Step: 3
Training loss: 0.2919883728027344
Validation loss: 1.6707563028540662

Epoch: 6| Step: 4
Training loss: 0.2964130640029907
Validation loss: 1.6455156495494228

Epoch: 6| Step: 5
Training loss: 0.2782467007637024
Validation loss: 1.6833596421826271

Epoch: 6| Step: 6
Training loss: 0.347118079662323
Validation loss: 1.64847380627868

Epoch: 6| Step: 7
Training loss: 0.4839363694190979
Validation loss: 1.687576916909987

Epoch: 6| Step: 8
Training loss: 0.29072535037994385
Validation loss: 1.7014428877061414

Epoch: 6| Step: 9
Training loss: 0.5900982618331909
Validation loss: 1.6989955748281171

Epoch: 6| Step: 10
Training loss: 0.4077689051628113
Validation loss: 1.7154178696293985

Epoch: 6| Step: 11
Training loss: 0.3865851163864136
Validation loss: 1.6941155028599564

Epoch: 6| Step: 12
Training loss: 0.5560474395751953
Validation loss: 1.733058516697217

Epoch: 6| Step: 13
Training loss: 0.44581207633018494
Validation loss: 1.7627420130596365

Epoch: 289| Step: 0
Training loss: 0.4544100761413574
Validation loss: 1.7343175334315146

Epoch: 6| Step: 1
Training loss: 0.4255048632621765
Validation loss: 1.7158804837093558

Epoch: 6| Step: 2
Training loss: 0.49786901473999023
Validation loss: 1.7067512735243766

Epoch: 6| Step: 3
Training loss: 0.39501798152923584
Validation loss: 1.7427229060921618

Epoch: 6| Step: 4
Training loss: 0.3383074998855591
Validation loss: 1.714895744477549

Epoch: 6| Step: 5
Training loss: 0.404956579208374
Validation loss: 1.6842876134380218

Epoch: 6| Step: 6
Training loss: 0.2932314872741699
Validation loss: 1.72839323166878

Epoch: 6| Step: 7
Training loss: 0.3197380304336548
Validation loss: 1.729473421650548

Epoch: 6| Step: 8
Training loss: 0.2098362147808075
Validation loss: 1.7103269087371005

Epoch: 6| Step: 9
Training loss: 0.1563107818365097
Validation loss: 1.687118221995651

Epoch: 6| Step: 10
Training loss: 0.39499789476394653
Validation loss: 1.6823860419693815

Epoch: 6| Step: 11
Training loss: 0.6358693838119507
Validation loss: 1.6407127777735393

Epoch: 6| Step: 12
Training loss: 0.30112117528915405
Validation loss: 1.632093958957221

Epoch: 6| Step: 13
Training loss: 0.20941194891929626
Validation loss: 1.628778714005665

Epoch: 290| Step: 0
Training loss: 0.3533192276954651
Validation loss: 1.6272801378721833

Epoch: 6| Step: 1
Training loss: 0.18380588293075562
Validation loss: 1.6304322314518753

Epoch: 6| Step: 2
Training loss: 0.42617267370224
Validation loss: 1.6532520747953845

Epoch: 6| Step: 3
Training loss: 0.4246962070465088
Validation loss: 1.6458687795105802

Epoch: 6| Step: 4
Training loss: 0.24093487858772278
Validation loss: 1.6444045843616608

Epoch: 6| Step: 5
Training loss: 0.34351110458374023
Validation loss: 1.6056316757714877

Epoch: 6| Step: 6
Training loss: 0.10498149693012238
Validation loss: 1.6296169962934268

Epoch: 6| Step: 7
Training loss: 0.4211045801639557
Validation loss: 1.6417852563242759

Epoch: 6| Step: 8
Training loss: 0.5670308470726013
Validation loss: 1.627321864968987

Epoch: 6| Step: 9
Training loss: 0.22207842767238617
Validation loss: 1.6219348099923903

Epoch: 6| Step: 10
Training loss: 0.4122732877731323
Validation loss: 1.6676710395402805

Epoch: 6| Step: 11
Training loss: 0.5759885311126709
Validation loss: 1.657068714018791

Epoch: 6| Step: 12
Training loss: 0.6174176931381226
Validation loss: 1.675555912397241

Epoch: 6| Step: 13
Training loss: 0.43914440274238586
Validation loss: 1.679373800113637

Epoch: 291| Step: 0
Training loss: 0.4204748272895813
Validation loss: 1.679859192781551

Epoch: 6| Step: 1
Training loss: 0.4641917943954468
Validation loss: 1.677085090708989

Epoch: 6| Step: 2
Training loss: 0.1073349118232727
Validation loss: 1.6860479475349508

Epoch: 6| Step: 3
Training loss: 0.524071455001831
Validation loss: 1.7061882583043908

Epoch: 6| Step: 4
Training loss: 0.38187509775161743
Validation loss: 1.6882165965213571

Epoch: 6| Step: 5
Training loss: 0.3955615758895874
Validation loss: 1.6839547644379318

Epoch: 6| Step: 6
Training loss: 0.43198564648628235
Validation loss: 1.6940494903954126

Epoch: 6| Step: 7
Training loss: 0.3239873945713043
Validation loss: 1.6909341260951052

Epoch: 6| Step: 8
Training loss: 0.34708279371261597
Validation loss: 1.691258086953112

Epoch: 6| Step: 9
Training loss: 0.2520040273666382
Validation loss: 1.723133489649783

Epoch: 6| Step: 10
Training loss: 0.45236480236053467
Validation loss: 1.6965544762149933

Epoch: 6| Step: 11
Training loss: 0.4887385070323944
Validation loss: 1.7021885392486409

Epoch: 6| Step: 12
Training loss: 0.30879831314086914
Validation loss: 1.7045990549108034

Epoch: 6| Step: 13
Training loss: 0.4924088716506958
Validation loss: 1.6993262960064797

Epoch: 292| Step: 0
Training loss: 0.34768033027648926
Validation loss: 1.7092644245393815

Epoch: 6| Step: 1
Training loss: 0.5529752969741821
Validation loss: 1.7014020002016457

Epoch: 6| Step: 2
Training loss: 0.5181231498718262
Validation loss: 1.692175329372447

Epoch: 6| Step: 3
Training loss: 0.28301751613616943
Validation loss: 1.644475712571093

Epoch: 6| Step: 4
Training loss: 0.1916869580745697
Validation loss: 1.655497335618542

Epoch: 6| Step: 5
Training loss: 0.27425357699394226
Validation loss: 1.656732154148881

Epoch: 6| Step: 6
Training loss: 0.39302536845207214
Validation loss: 1.647004473593927

Epoch: 6| Step: 7
Training loss: 0.2011847198009491
Validation loss: 1.6396716666477982

Epoch: 6| Step: 8
Training loss: 0.3560643792152405
Validation loss: 1.65134689628437

Epoch: 6| Step: 9
Training loss: 0.4581352472305298
Validation loss: 1.6531938352892477

Epoch: 6| Step: 10
Training loss: 0.416925847530365
Validation loss: 1.6849249421909291

Epoch: 6| Step: 11
Training loss: 0.5518254041671753
Validation loss: 1.70469404292363

Epoch: 6| Step: 12
Training loss: 0.25059565901756287
Validation loss: 1.6568293750927012

Epoch: 6| Step: 13
Training loss: 0.3433583080768585
Validation loss: 1.6469036507350143

Epoch: 293| Step: 0
Training loss: 0.357745498418808
Validation loss: 1.64493687306681

Epoch: 6| Step: 1
Training loss: 0.2971937656402588
Validation loss: 1.6536152849915207

Epoch: 6| Step: 2
Training loss: 0.17544546723365784
Validation loss: 1.616337105792056

Epoch: 6| Step: 3
Training loss: 0.3390544056892395
Validation loss: 1.6399917371811406

Epoch: 6| Step: 4
Training loss: 0.49117761850357056
Validation loss: 1.6464677690177836

Epoch: 6| Step: 5
Training loss: 0.4770248532295227
Validation loss: 1.6650672035832559

Epoch: 6| Step: 6
Training loss: 0.4737415611743927
Validation loss: 1.617950318962015

Epoch: 6| Step: 7
Training loss: 0.6952850222587585
Validation loss: 1.6361872226961198

Epoch: 6| Step: 8
Training loss: 0.4109366834163666
Validation loss: 1.6051889055518693

Epoch: 6| Step: 9
Training loss: 0.2883366346359253
Validation loss: 1.58107586573529

Epoch: 6| Step: 10
Training loss: 0.25475719571113586
Validation loss: 1.5823196031713997

Epoch: 6| Step: 11
Training loss: 0.399253249168396
Validation loss: 1.648378570874532

Epoch: 6| Step: 12
Training loss: 0.34758591651916504
Validation loss: 1.659613593932121

Epoch: 6| Step: 13
Training loss: 0.33233001828193665
Validation loss: 1.6638207025425409

Epoch: 294| Step: 0
Training loss: 0.45755454897880554
Validation loss: 1.6619706435870099

Epoch: 6| Step: 1
Training loss: 0.2875560522079468
Validation loss: 1.668070597033347

Epoch: 6| Step: 2
Training loss: 0.4237765371799469
Validation loss: 1.6677623807743032

Epoch: 6| Step: 3
Training loss: 0.4270654022693634
Validation loss: 1.681274325616898

Epoch: 6| Step: 4
Training loss: 0.2743994891643524
Validation loss: 1.6938995751001502

Epoch: 6| Step: 5
Training loss: 0.31080418825149536
Validation loss: 1.713461172196173

Epoch: 6| Step: 6
Training loss: 0.2890833616256714
Validation loss: 1.6825232954435452

Epoch: 6| Step: 7
Training loss: 0.35418492555618286
Validation loss: 1.643682610604071

Epoch: 6| Step: 8
Training loss: 0.5245562791824341
Validation loss: 1.61876001281123

Epoch: 6| Step: 9
Training loss: 0.2356961965560913
Validation loss: 1.6261675998728762

Epoch: 6| Step: 10
Training loss: 0.385375440120697
Validation loss: 1.5968005400831982

Epoch: 6| Step: 11
Training loss: 0.4626454710960388
Validation loss: 1.6180885299559562

Epoch: 6| Step: 12
Training loss: 0.5909039974212646
Validation loss: 1.6226848043421263

Epoch: 6| Step: 13
Training loss: 0.33808183670043945
Validation loss: 1.6450466353406188

Epoch: 295| Step: 0
Training loss: 0.20143966376781464
Validation loss: 1.645881422104374

Epoch: 6| Step: 1
Training loss: 0.21539750695228577
Validation loss: 1.6528642728764524

Epoch: 6| Step: 2
Training loss: 0.36586475372314453
Validation loss: 1.6274634817595124

Epoch: 6| Step: 3
Training loss: 0.4939749836921692
Validation loss: 1.6654658830294045

Epoch: 6| Step: 4
Training loss: 0.29163819551467896
Validation loss: 1.648765649846805

Epoch: 6| Step: 5
Training loss: 0.41565608978271484
Validation loss: 1.6575906122884443

Epoch: 6| Step: 6
Training loss: 0.2249480038881302
Validation loss: 1.6082836530541862

Epoch: 6| Step: 7
Training loss: 0.33780136704444885
Validation loss: 1.5808327198028564

Epoch: 6| Step: 8
Training loss: 0.45866331458091736
Validation loss: 1.615224778011281

Epoch: 6| Step: 9
Training loss: 0.4185768961906433
Validation loss: 1.6333996083146782

Epoch: 6| Step: 10
Training loss: 0.605629563331604
Validation loss: 1.6602701448625135

Epoch: 6| Step: 11
Training loss: 0.2869754135608673
Validation loss: 1.670731129184846

Epoch: 6| Step: 12
Training loss: 0.17813143134117126
Validation loss: 1.714411872689442

Epoch: 6| Step: 13
Training loss: 0.8653489351272583
Validation loss: 1.6679749681103615

Epoch: 296| Step: 0
Training loss: 0.3471881151199341
Validation loss: 1.6631104497499363

Epoch: 6| Step: 1
Training loss: 0.4269593358039856
Validation loss: 1.6636975144827237

Epoch: 6| Step: 2
Training loss: 0.5094771981239319
Validation loss: 1.6704815241598314

Epoch: 6| Step: 3
Training loss: 0.3151606321334839
Validation loss: 1.67990235359438

Epoch: 6| Step: 4
Training loss: 0.22188085317611694
Validation loss: 1.6657185528867988

Epoch: 6| Step: 5
Training loss: 0.2864343822002411
Validation loss: 1.694772433209163

Epoch: 6| Step: 6
Training loss: 0.3391210436820984
Validation loss: 1.6698777009082097

Epoch: 6| Step: 7
Training loss: 0.372005820274353
Validation loss: 1.716790255679879

Epoch: 6| Step: 8
Training loss: 0.38138195872306824
Validation loss: 1.728111174798781

Epoch: 6| Step: 9
Training loss: 0.3224179148674011
Validation loss: 1.7154338821288078

Epoch: 6| Step: 10
Training loss: 0.30062997341156006
Validation loss: 1.7048431839994205

Epoch: 6| Step: 11
Training loss: 0.4879661500453949
Validation loss: 1.7046982754943192

Epoch: 6| Step: 12
Training loss: 0.26066482067108154
Validation loss: 1.7235009093438425

Epoch: 6| Step: 13
Training loss: 0.2250082790851593
Validation loss: 1.685741405333242

Epoch: 297| Step: 0
Training loss: 0.3667774200439453
Validation loss: 1.6593336315565212

Epoch: 6| Step: 1
Training loss: 0.2468436360359192
Validation loss: 1.7172044220791067

Epoch: 6| Step: 2
Training loss: 0.27142515778541565
Validation loss: 1.7010454836712088

Epoch: 6| Step: 3
Training loss: 0.4644119143486023
Validation loss: 1.6997781492048694

Epoch: 6| Step: 4
Training loss: 0.5295013189315796
Validation loss: 1.689215111476119

Epoch: 6| Step: 5
Training loss: 0.4958415925502777
Validation loss: 1.6887241896762644

Epoch: 6| Step: 6
Training loss: 0.3777928948402405
Validation loss: 1.6512971232014317

Epoch: 6| Step: 7
Training loss: 0.34792158007621765
Validation loss: 1.6973210304014144

Epoch: 6| Step: 8
Training loss: 0.6128010749816895
Validation loss: 1.7458107343284033

Epoch: 6| Step: 9
Training loss: 0.36946338415145874
Validation loss: 1.7812359679129817

Epoch: 6| Step: 10
Training loss: 0.48534753918647766
Validation loss: 1.7402445667533464

Epoch: 6| Step: 11
Training loss: 0.13848206400871277
Validation loss: 1.6840840014078284

Epoch: 6| Step: 12
Training loss: 0.20162150263786316
Validation loss: 1.641025794449673

Epoch: 6| Step: 13
Training loss: 0.21713778376579285
Validation loss: 1.6268121580923758

Epoch: 298| Step: 0
Training loss: 0.1964462697505951
Validation loss: 1.6446662923341155

Epoch: 6| Step: 1
Training loss: 0.5282021760940552
Validation loss: 1.6104228458096903

Epoch: 6| Step: 2
Training loss: 0.29592376947402954
Validation loss: 1.6101607917457499

Epoch: 6| Step: 3
Training loss: 0.3103674352169037
Validation loss: 1.5993950168291728

Epoch: 6| Step: 4
Training loss: 0.2409840226173401
Validation loss: 1.5954162766856532

Epoch: 6| Step: 5
Training loss: 0.3641842007637024
Validation loss: 1.6117160089554325

Epoch: 6| Step: 6
Training loss: 0.3571528196334839
Validation loss: 1.5906271537144978

Epoch: 6| Step: 7
Training loss: 0.35973790287971497
Validation loss: 1.6127068765701786

Epoch: 6| Step: 8
Training loss: 0.27743300795555115
Validation loss: 1.5975995935419554

Epoch: 6| Step: 9
Training loss: 0.2954467535018921
Validation loss: 1.5928036653867332

Epoch: 6| Step: 10
Training loss: 0.4818689525127411
Validation loss: 1.6184851046531432

Epoch: 6| Step: 11
Training loss: 0.44742339849472046
Validation loss: 1.6017965244990524

Epoch: 6| Step: 12
Training loss: 0.34568843245506287
Validation loss: 1.628809113656321

Epoch: 6| Step: 13
Training loss: 0.5162774324417114
Validation loss: 1.6227294424528718

Epoch: 299| Step: 0
Training loss: 0.30067071318626404
Validation loss: 1.6596486542814521

Epoch: 6| Step: 1
Training loss: 0.2287147045135498
Validation loss: 1.671010773669007

Epoch: 6| Step: 2
Training loss: 0.27048593759536743
Validation loss: 1.6654946624591787

Epoch: 6| Step: 3
Training loss: 0.3490784764289856
Validation loss: 1.6567697525024414

Epoch: 6| Step: 4
Training loss: 0.39059364795684814
Validation loss: 1.6547939008282078

Epoch: 6| Step: 5
Training loss: 0.42912518978118896
Validation loss: 1.6397206116748113

Epoch: 6| Step: 6
Training loss: 0.2920432984828949
Validation loss: 1.6485820893318421

Epoch: 6| Step: 7
Training loss: 0.3724724352359772
Validation loss: 1.5808493193759714

Epoch: 6| Step: 8
Training loss: 0.31792497634887695
Validation loss: 1.5843849348765549

Epoch: 6| Step: 9
Training loss: 0.30524173378944397
Validation loss: 1.5849130256201631

Epoch: 6| Step: 10
Training loss: 0.4576951861381531
Validation loss: 1.5798976921266126

Epoch: 6| Step: 11
Training loss: 0.33165812492370605
Validation loss: 1.6033264142210766

Epoch: 6| Step: 12
Training loss: 0.22777652740478516
Validation loss: 1.5740096825425343

Epoch: 6| Step: 13
Training loss: 0.23426999151706696
Validation loss: 1.5845172212969871

Epoch: 300| Step: 0
Training loss: 0.316657692193985
Validation loss: 1.5675907699010705

Epoch: 6| Step: 1
Training loss: 0.33909720182418823
Validation loss: 1.5905166543940061

Epoch: 6| Step: 2
Training loss: 0.27453064918518066
Validation loss: 1.5600570837656658

Epoch: 6| Step: 3
Training loss: 0.537490963935852
Validation loss: 1.5995394145288775

Epoch: 6| Step: 4
Training loss: 0.17902079224586487
Validation loss: 1.576183901038221

Epoch: 6| Step: 5
Training loss: 0.5584476590156555
Validation loss: 1.575194622880669

Epoch: 6| Step: 6
Training loss: 0.17880848050117493
Validation loss: 1.5703088096393052

Epoch: 6| Step: 7
Training loss: 0.4107416868209839
Validation loss: 1.5826171328944545

Epoch: 6| Step: 8
Training loss: 0.2602177560329437
Validation loss: 1.5669950951812088

Epoch: 6| Step: 9
Training loss: 0.42196011543273926
Validation loss: 1.5925628780036845

Epoch: 6| Step: 10
Training loss: 0.4873386323451996
Validation loss: 1.573075189385363

Epoch: 6| Step: 11
Training loss: 0.17123255133628845
Validation loss: 1.5898237196348046

Epoch: 6| Step: 12
Training loss: 0.45274949073791504
Validation loss: 1.5971230486387848

Epoch: 6| Step: 13
Training loss: 0.17568030953407288
Validation loss: 1.5726283070861653

Epoch: 301| Step: 0
Training loss: 0.3190818428993225
Validation loss: 1.6112572095727409

Epoch: 6| Step: 1
Training loss: 0.46888142824172974
Validation loss: 1.6198572984305761

Epoch: 6| Step: 2
Training loss: 0.21322230994701385
Validation loss: 1.6107720457097536

Epoch: 6| Step: 3
Training loss: 0.3649641275405884
Validation loss: 1.6282583821204402

Epoch: 6| Step: 4
Training loss: 0.3855045735836029
Validation loss: 1.6023893804960354

Epoch: 6| Step: 5
Training loss: 0.4844363331794739
Validation loss: 1.6255093082304923

Epoch: 6| Step: 6
Training loss: 0.28713613748550415
Validation loss: 1.5989041213066346

Epoch: 6| Step: 7
Training loss: 0.23687492311000824
Validation loss: 1.6013231649193713

Epoch: 6| Step: 8
Training loss: 0.5114802122116089
Validation loss: 1.604665788271094

Epoch: 6| Step: 9
Training loss: 0.21745872497558594
Validation loss: 1.6195524072134366

Epoch: 6| Step: 10
Training loss: 0.3468667268753052
Validation loss: 1.6508735213228451

Epoch: 6| Step: 11
Training loss: 0.20991575717926025
Validation loss: 1.6339849887355682

Epoch: 6| Step: 12
Training loss: 0.27643704414367676
Validation loss: 1.634775798807862

Epoch: 6| Step: 13
Training loss: 0.07612481713294983
Validation loss: 1.6356244369219708

Epoch: 302| Step: 0
Training loss: 0.3717673718929291
Validation loss: 1.6459828192187893

Epoch: 6| Step: 1
Training loss: 0.37138038873672485
Validation loss: 1.6283271389622842

Epoch: 6| Step: 2
Training loss: 0.22663021087646484
Validation loss: 1.6224396715882003

Epoch: 6| Step: 3
Training loss: 0.4083217978477478
Validation loss: 1.6312217379129061

Epoch: 6| Step: 4
Training loss: 0.179487407207489
Validation loss: 1.6628863478219638

Epoch: 6| Step: 5
Training loss: 0.264842689037323
Validation loss: 1.6564068102067517

Epoch: 6| Step: 6
Training loss: 0.29729264974594116
Validation loss: 1.6342541633113739

Epoch: 6| Step: 7
Training loss: 0.4659237265586853
Validation loss: 1.6527786152337187

Epoch: 6| Step: 8
Training loss: 0.29655590653419495
Validation loss: 1.663349711766807

Epoch: 6| Step: 9
Training loss: 0.29478511214256287
Validation loss: 1.69726905386935

Epoch: 6| Step: 10
Training loss: 0.346516489982605
Validation loss: 1.6709497462036789

Epoch: 6| Step: 11
Training loss: 0.20983856916427612
Validation loss: 1.656383869468525

Epoch: 6| Step: 12
Training loss: 0.3255021572113037
Validation loss: 1.6567521108094083

Epoch: 6| Step: 13
Training loss: 0.23508721590042114
Validation loss: 1.6599499640926239

Epoch: 303| Step: 0
Training loss: 0.26923248171806335
Validation loss: 1.6535145941601004

Epoch: 6| Step: 1
Training loss: 0.42836517095565796
Validation loss: 1.636612279440767

Epoch: 6| Step: 2
Training loss: 0.2533893585205078
Validation loss: 1.6432988220645535

Epoch: 6| Step: 3
Training loss: 0.31006795167922974
Validation loss: 1.634783689693738

Epoch: 6| Step: 4
Training loss: 0.10218866169452667
Validation loss: 1.6050818376643683

Epoch: 6| Step: 5
Training loss: 0.49094632267951965
Validation loss: 1.6093909919902842

Epoch: 6| Step: 6
Training loss: 0.3116447329521179
Validation loss: 1.615224669056554

Epoch: 6| Step: 7
Training loss: 0.2390039563179016
Validation loss: 1.6142908962824012

Epoch: 6| Step: 8
Training loss: 0.35370609164237976
Validation loss: 1.618650156964538

Epoch: 6| Step: 9
Training loss: 0.2870456278324127
Validation loss: 1.6148091772551179

Epoch: 6| Step: 10
Training loss: 0.4684794843196869
Validation loss: 1.6434072781634588

Epoch: 6| Step: 11
Training loss: 0.2791382670402527
Validation loss: 1.6355093294574368

Epoch: 6| Step: 12
Training loss: 0.2898121178150177
Validation loss: 1.6343230649989138

Epoch: 6| Step: 13
Training loss: 0.3518247902393341
Validation loss: 1.638497015481354

Epoch: 304| Step: 0
Training loss: 0.464029461145401
Validation loss: 1.6385468090734174

Epoch: 6| Step: 1
Training loss: 0.2904318571090698
Validation loss: 1.6483225886539747

Epoch: 6| Step: 2
Training loss: 0.3477226793766022
Validation loss: 1.6618741532807708

Epoch: 6| Step: 3
Training loss: 0.3192586600780487
Validation loss: 1.679819381365212

Epoch: 6| Step: 4
Training loss: 0.39959049224853516
Validation loss: 1.6936847304785123

Epoch: 6| Step: 5
Training loss: 0.18682841956615448
Validation loss: 1.68314540514382

Epoch: 6| Step: 6
Training loss: 0.416853666305542
Validation loss: 1.6759231020045537

Epoch: 6| Step: 7
Training loss: 0.5304564237594604
Validation loss: 1.6905254010231263

Epoch: 6| Step: 8
Training loss: 0.33496031165122986
Validation loss: 1.6888580194083593

Epoch: 6| Step: 9
Training loss: 0.2187778502702713
Validation loss: 1.6467471193241816

Epoch: 6| Step: 10
Training loss: 0.3960098326206207
Validation loss: 1.6243563454638246

Epoch: 6| Step: 11
Training loss: 0.22015507519245148
Validation loss: 1.6163676272156418

Epoch: 6| Step: 12
Training loss: 0.28950464725494385
Validation loss: 1.6261632993657102

Epoch: 6| Step: 13
Training loss: 0.2913130223751068
Validation loss: 1.603969745738532

Epoch: 305| Step: 0
Training loss: 0.23860563337802887
Validation loss: 1.6179219292056175

Epoch: 6| Step: 1
Training loss: 0.22883489727973938
Validation loss: 1.613582790538829

Epoch: 6| Step: 2
Training loss: 0.3159114122390747
Validation loss: 1.6097945295354372

Epoch: 6| Step: 3
Training loss: 0.5604556798934937
Validation loss: 1.6060632601861031

Epoch: 6| Step: 4
Training loss: 0.1882164031267166
Validation loss: 1.597298458058347

Epoch: 6| Step: 5
Training loss: 0.3098796010017395
Validation loss: 1.6067035710939797

Epoch: 6| Step: 6
Training loss: 0.4099957048892975
Validation loss: 1.5927222787692983

Epoch: 6| Step: 7
Training loss: 0.37997424602508545
Validation loss: 1.6294567841355518

Epoch: 6| Step: 8
Training loss: 0.25336626172065735
Validation loss: 1.6003171782339773

Epoch: 6| Step: 9
Training loss: 0.34732386469841003
Validation loss: 1.582890707959411

Epoch: 6| Step: 10
Training loss: 0.26334571838378906
Validation loss: 1.6077990249920917

Epoch: 6| Step: 11
Training loss: 0.23826071619987488
Validation loss: 1.6155379895241029

Epoch: 6| Step: 12
Training loss: 0.4562855362892151
Validation loss: 1.6343391710712063

Epoch: 6| Step: 13
Training loss: 0.28873610496520996
Validation loss: 1.5985426928407402

Epoch: 306| Step: 0
Training loss: 0.47693249583244324
Validation loss: 1.591967285320323

Epoch: 6| Step: 1
Training loss: 0.2108456790447235
Validation loss: 1.5881009742777834

Epoch: 6| Step: 2
Training loss: 0.31487035751342773
Validation loss: 1.5632754628376295

Epoch: 6| Step: 3
Training loss: 0.2901260256767273
Validation loss: 1.591262186727216

Epoch: 6| Step: 4
Training loss: 0.26666420698165894
Validation loss: 1.5878435052851194

Epoch: 6| Step: 5
Training loss: 0.37409359216690063
Validation loss: 1.6027334543966478

Epoch: 6| Step: 6
Training loss: 0.25048771500587463
Validation loss: 1.5878872025397517

Epoch: 6| Step: 7
Training loss: 0.23605571687221527
Validation loss: 1.6090281804402669

Epoch: 6| Step: 8
Training loss: 0.44112154841423035
Validation loss: 1.6143736006111227

Epoch: 6| Step: 9
Training loss: 0.25469034910202026
Validation loss: 1.6108826296303862

Epoch: 6| Step: 10
Training loss: 0.5021637082099915
Validation loss: 1.623776561470442

Epoch: 6| Step: 11
Training loss: 0.2668340802192688
Validation loss: 1.618783584205053

Epoch: 6| Step: 12
Training loss: 0.40467289090156555
Validation loss: 1.5941094031897924

Epoch: 6| Step: 13
Training loss: 0.275265097618103
Validation loss: 1.6275410459887596

Epoch: 307| Step: 0
Training loss: 0.2198624610900879
Validation loss: 1.6029380880376345

Epoch: 6| Step: 1
Training loss: 0.35460132360458374
Validation loss: 1.5809248250017884

Epoch: 6| Step: 2
Training loss: 0.27796220779418945
Validation loss: 1.6620263668798632

Epoch: 6| Step: 3
Training loss: 0.296048641204834
Validation loss: 1.6599309982792023

Epoch: 6| Step: 4
Training loss: 0.2534016966819763
Validation loss: 1.649984710959978

Epoch: 6| Step: 5
Training loss: 0.3113197386264801
Validation loss: 1.64790008401358

Epoch: 6| Step: 6
Training loss: 0.26592791080474854
Validation loss: 1.6552225312879008

Epoch: 6| Step: 7
Training loss: 0.5405688285827637
Validation loss: 1.654992977778117

Epoch: 6| Step: 8
Training loss: 0.3156771659851074
Validation loss: 1.6570438896456072

Epoch: 6| Step: 9
Training loss: 0.4344449043273926
Validation loss: 1.661743261480844

Epoch: 6| Step: 10
Training loss: 0.2575151026248932
Validation loss: 1.6257903973261516

Epoch: 6| Step: 11
Training loss: 0.48055681586265564
Validation loss: 1.6327613233238139

Epoch: 6| Step: 12
Training loss: 0.32188278436660767
Validation loss: 1.6209758763672204

Epoch: 6| Step: 13
Training loss: 0.13438346982002258
Validation loss: 1.5890836510606992

Epoch: 308| Step: 0
Training loss: 0.2715035080909729
Validation loss: 1.606076031602839

Epoch: 6| Step: 1
Training loss: 0.2364330291748047
Validation loss: 1.5842462983182681

Epoch: 6| Step: 2
Training loss: 0.30153101682662964
Validation loss: 1.5490152438481648

Epoch: 6| Step: 3
Training loss: 0.44829651713371277
Validation loss: 1.5562705839833906

Epoch: 6| Step: 4
Training loss: 0.39443182945251465
Validation loss: 1.58750537262168

Epoch: 6| Step: 5
Training loss: 0.35417598485946655
Validation loss: 1.5997176388258576

Epoch: 6| Step: 6
Training loss: 0.36244460940361023
Validation loss: 1.5742514530817668

Epoch: 6| Step: 7
Training loss: 0.3179631233215332
Validation loss: 1.5838519347611295

Epoch: 6| Step: 8
Training loss: 0.2307685911655426
Validation loss: 1.6013977348163564

Epoch: 6| Step: 9
Training loss: 0.1536199450492859
Validation loss: 1.5766824906872166

Epoch: 6| Step: 10
Training loss: 0.29142969846725464
Validation loss: 1.5911845744297068

Epoch: 6| Step: 11
Training loss: 0.2730385363101959
Validation loss: 1.5973146961581322

Epoch: 6| Step: 12
Training loss: 0.4638928472995758
Validation loss: 1.6026577013795094

Epoch: 6| Step: 13
Training loss: 0.3177012801170349
Validation loss: 1.6286016715470182

Epoch: 309| Step: 0
Training loss: 0.4956202805042267
Validation loss: 1.6302335954481555

Epoch: 6| Step: 1
Training loss: 0.23462778329849243
Validation loss: 1.6428382268515966

Epoch: 6| Step: 2
Training loss: 0.3850715160369873
Validation loss: 1.648868231363194

Epoch: 6| Step: 3
Training loss: 0.20435115694999695
Validation loss: 1.6560734036148235

Epoch: 6| Step: 4
Training loss: 0.3414154648780823
Validation loss: 1.6694973104743547

Epoch: 6| Step: 5
Training loss: 0.33636972308158875
Validation loss: 1.6645097604361914

Epoch: 6| Step: 6
Training loss: 0.2618219256401062
Validation loss: 1.6725707438684279

Epoch: 6| Step: 7
Training loss: 0.2406150996685028
Validation loss: 1.648667162464511

Epoch: 6| Step: 8
Training loss: 0.2935677170753479
Validation loss: 1.6351018515966271

Epoch: 6| Step: 9
Training loss: 0.20949459075927734
Validation loss: 1.6058132033194266

Epoch: 6| Step: 10
Training loss: 0.234828919172287
Validation loss: 1.6257932250217726

Epoch: 6| Step: 11
Training loss: 0.477122962474823
Validation loss: 1.6165408754861483

Epoch: 6| Step: 12
Training loss: 0.35710152983665466
Validation loss: 1.6388529372471634

Epoch: 6| Step: 13
Training loss: 0.295204758644104
Validation loss: 1.5960753271656651

Epoch: 310| Step: 0
Training loss: 0.1505298763513565
Validation loss: 1.6079607932798323

Epoch: 6| Step: 1
Training loss: 0.34235453605651855
Validation loss: 1.5933124121799265

Epoch: 6| Step: 2
Training loss: 0.27399343252182007
Validation loss: 1.5881276669040802

Epoch: 6| Step: 3
Training loss: 0.2808322310447693
Validation loss: 1.560559900858069

Epoch: 6| Step: 4
Training loss: 0.30818986892700195
Validation loss: 1.5867756092420189

Epoch: 6| Step: 5
Training loss: 0.36804187297821045
Validation loss: 1.5362996516689178

Epoch: 6| Step: 6
Training loss: 0.30587321519851685
Validation loss: 1.5432161285031227

Epoch: 6| Step: 7
Training loss: 0.34951141476631165
Validation loss: 1.5535918012742074

Epoch: 6| Step: 8
Training loss: 0.4823125898838043
Validation loss: 1.570846224343905

Epoch: 6| Step: 9
Training loss: 0.360946387052536
Validation loss: 1.617578101414506

Epoch: 6| Step: 10
Training loss: 0.3048109710216522
Validation loss: 1.613524938142428

Epoch: 6| Step: 11
Training loss: 0.34268736839294434
Validation loss: 1.6520077079854987

Epoch: 6| Step: 12
Training loss: 0.3635379672050476
Validation loss: 1.6085424794945666

Epoch: 6| Step: 13
Training loss: 0.13044343888759613
Validation loss: 1.6028201656956826

Epoch: 311| Step: 0
Training loss: 0.16925981640815735
Validation loss: 1.58960888719046

Epoch: 6| Step: 1
Training loss: 0.37896597385406494
Validation loss: 1.5829659097938127

Epoch: 6| Step: 2
Training loss: 0.575103759765625
Validation loss: 1.598578909391998

Epoch: 6| Step: 3
Training loss: 0.22874796390533447
Validation loss: 1.5735225267307733

Epoch: 6| Step: 4
Training loss: 0.26274287700653076
Validation loss: 1.5785982326794696

Epoch: 6| Step: 5
Training loss: 0.4488457441329956
Validation loss: 1.6156092254064416

Epoch: 6| Step: 6
Training loss: 0.2543801963329315
Validation loss: 1.6523715385826685

Epoch: 6| Step: 7
Training loss: 0.30168309807777405
Validation loss: 1.629816888481058

Epoch: 6| Step: 8
Training loss: 0.24029399454593658
Validation loss: 1.6139215269396383

Epoch: 6| Step: 9
Training loss: 0.27584052085876465
Validation loss: 1.6025853567225958

Epoch: 6| Step: 10
Training loss: 0.3789958357810974
Validation loss: 1.6312189832810433

Epoch: 6| Step: 11
Training loss: 0.2667579650878906
Validation loss: 1.599415720150035

Epoch: 6| Step: 12
Training loss: 0.31795990467071533
Validation loss: 1.5734735368400492

Epoch: 6| Step: 13
Training loss: 0.22702908515930176
Validation loss: 1.5738143459443124

Epoch: 312| Step: 0
Training loss: 0.2512020170688629
Validation loss: 1.5539380286329536

Epoch: 6| Step: 1
Training loss: 0.28791743516921997
Validation loss: 1.5689586798350017

Epoch: 6| Step: 2
Training loss: 0.2665844261646271
Validation loss: 1.5451354711286482

Epoch: 6| Step: 3
Training loss: 0.23857083916664124
Validation loss: 1.5602980480399182

Epoch: 6| Step: 4
Training loss: 0.18298153579235077
Validation loss: 1.5561448322829379

Epoch: 6| Step: 5
Training loss: 0.42623287439346313
Validation loss: 1.547551837018741

Epoch: 6| Step: 6
Training loss: 0.40380996465682983
Validation loss: 1.5826246687161025

Epoch: 6| Step: 7
Training loss: 0.25561121106147766
Validation loss: 1.5884251709907287

Epoch: 6| Step: 8
Training loss: 0.23012873530387878
Validation loss: 1.557326284787988

Epoch: 6| Step: 9
Training loss: 0.28583037853240967
Validation loss: 1.5626542568206787

Epoch: 6| Step: 10
Training loss: 0.3464643061161041
Validation loss: 1.5849565100926224

Epoch: 6| Step: 11
Training loss: 0.4507431387901306
Validation loss: 1.5296043093486498

Epoch: 6| Step: 12
Training loss: 0.2648850679397583
Validation loss: 1.5449380413178475

Epoch: 6| Step: 13
Training loss: 0.30556175112724304
Validation loss: 1.5825167138089415

Epoch: 313| Step: 0
Training loss: 0.206023171544075
Validation loss: 1.5889441172281902

Epoch: 6| Step: 1
Training loss: 0.23657864332199097
Validation loss: 1.5956869381730274

Epoch: 6| Step: 2
Training loss: 0.34275829792022705
Validation loss: 1.610366754634406

Epoch: 6| Step: 3
Training loss: 0.2666848599910736
Validation loss: 1.6081676111426404

Epoch: 6| Step: 4
Training loss: 0.3200673758983612
Validation loss: 1.5984976612111574

Epoch: 6| Step: 5
Training loss: 0.35893839597702026
Validation loss: 1.6167929275061494

Epoch: 6| Step: 6
Training loss: 0.30285972356796265
Validation loss: 1.6161256964488695

Epoch: 6| Step: 7
Training loss: 0.2616914212703705
Validation loss: 1.6644865300065728

Epoch: 6| Step: 8
Training loss: 0.2015361189842224
Validation loss: 1.641140253313126

Epoch: 6| Step: 9
Training loss: 0.3028806447982788
Validation loss: 1.626987067602014

Epoch: 6| Step: 10
Training loss: 0.44619181752204895
Validation loss: 1.6039608293964016

Epoch: 6| Step: 11
Training loss: 0.2000347375869751
Validation loss: 1.5890607116042927

Epoch: 6| Step: 12
Training loss: 0.3428488075733185
Validation loss: 1.5918720896526048

Epoch: 6| Step: 13
Training loss: 0.393379807472229
Validation loss: 1.5802565101654298

Epoch: 314| Step: 0
Training loss: 0.25304171442985535
Validation loss: 1.5639502739393583

Epoch: 6| Step: 1
Training loss: 0.2274075150489807
Validation loss: 1.5702203102009271

Epoch: 6| Step: 2
Training loss: 0.14869171380996704
Validation loss: 1.5591409552481867

Epoch: 6| Step: 3
Training loss: 0.31835442781448364
Validation loss: 1.59158553102965

Epoch: 6| Step: 4
Training loss: 0.3532310724258423
Validation loss: 1.5774927728919572

Epoch: 6| Step: 5
Training loss: 0.3293708562850952
Validation loss: 1.6076755305772186

Epoch: 6| Step: 6
Training loss: 0.20807117223739624
Validation loss: 1.5819033832960232

Epoch: 6| Step: 7
Training loss: 0.2571695148944855
Validation loss: 1.5657793578281198

Epoch: 6| Step: 8
Training loss: 0.24100492894649506
Validation loss: 1.6068126347757155

Epoch: 6| Step: 9
Training loss: 0.272680401802063
Validation loss: 1.5988057313426849

Epoch: 6| Step: 10
Training loss: 0.21843016147613525
Validation loss: 1.6089127691843177

Epoch: 6| Step: 11
Training loss: 0.32277169823646545
Validation loss: 1.6054716981867307

Epoch: 6| Step: 12
Training loss: 0.3140307664871216
Validation loss: 1.6033983076772382

Epoch: 6| Step: 13
Training loss: 0.3017136752605438
Validation loss: 1.5920091931537916

Epoch: 315| Step: 0
Training loss: 0.235051691532135
Validation loss: 1.6128885566547353

Epoch: 6| Step: 1
Training loss: 0.24076126515865326
Validation loss: 1.6297826446512693

Epoch: 6| Step: 2
Training loss: 0.28764283657073975
Validation loss: 1.6098791937674246

Epoch: 6| Step: 3
Training loss: 0.34694015979766846
Validation loss: 1.5974762375636766

Epoch: 6| Step: 4
Training loss: 0.21385684609413147
Validation loss: 1.591390254676983

Epoch: 6| Step: 5
Training loss: 0.20064982771873474
Validation loss: 1.5926584530902166

Epoch: 6| Step: 6
Training loss: 0.4185119867324829
Validation loss: 1.6132014784761655

Epoch: 6| Step: 7
Training loss: 0.2864389717578888
Validation loss: 1.569060105149464

Epoch: 6| Step: 8
Training loss: 0.34586507081985474
Validation loss: 1.560686638278346

Epoch: 6| Step: 9
Training loss: 0.2665569484233856
Validation loss: 1.565746791901127

Epoch: 6| Step: 10
Training loss: 0.20472735166549683
Validation loss: 1.5574139023339877

Epoch: 6| Step: 11
Training loss: 0.30883491039276123
Validation loss: 1.5458603828184065

Epoch: 6| Step: 12
Training loss: 0.25674283504486084
Validation loss: 1.5267132623221285

Epoch: 6| Step: 13
Training loss: 0.3807767331600189
Validation loss: 1.571867025026711

Epoch: 316| Step: 0
Training loss: 0.35630249977111816
Validation loss: 1.6157255659821212

Epoch: 6| Step: 1
Training loss: 0.1790737360715866
Validation loss: 1.5991749237942439

Epoch: 6| Step: 2
Training loss: 0.24250516295433044
Validation loss: 1.6038409779148717

Epoch: 6| Step: 3
Training loss: 0.3881071209907532
Validation loss: 1.5905996471322992

Epoch: 6| Step: 4
Training loss: 0.30597004294395447
Validation loss: 1.6256040732065837

Epoch: 6| Step: 5
Training loss: 0.2676534950733185
Validation loss: 1.5850267589733165

Epoch: 6| Step: 6
Training loss: 0.2921593189239502
Validation loss: 1.5901285986746512

Epoch: 6| Step: 7
Training loss: 0.35135915875434875
Validation loss: 1.5871723633940502

Epoch: 6| Step: 8
Training loss: 0.15361082553863525
Validation loss: 1.5949856709408503

Epoch: 6| Step: 9
Training loss: 0.2798079252243042
Validation loss: 1.574789039550289

Epoch: 6| Step: 10
Training loss: 0.3209106922149658
Validation loss: 1.5988706324690132

Epoch: 6| Step: 11
Training loss: 0.40883129835128784
Validation loss: 1.565657219579143

Epoch: 6| Step: 12
Training loss: 0.13129085302352905
Validation loss: 1.582245344756752

Epoch: 6| Step: 13
Training loss: 0.23611661791801453
Validation loss: 1.5815254437026156

Epoch: 317| Step: 0
Training loss: 0.24934518337249756
Validation loss: 1.5741617487322899

Epoch: 6| Step: 1
Training loss: 0.23941397666931152
Validation loss: 1.565895067748203

Epoch: 6| Step: 2
Training loss: 0.22964346408843994
Validation loss: 1.583365826196568

Epoch: 6| Step: 3
Training loss: 0.27182716131210327
Validation loss: 1.5742127767173193

Epoch: 6| Step: 4
Training loss: 0.19414924085140228
Validation loss: 1.55584571566633

Epoch: 6| Step: 5
Training loss: 0.21750274300575256
Validation loss: 1.5839466100097985

Epoch: 6| Step: 6
Training loss: 0.2132129967212677
Validation loss: 1.5800394294082478

Epoch: 6| Step: 7
Training loss: 0.39678704738616943
Validation loss: 1.6092721980105165

Epoch: 6| Step: 8
Training loss: 0.17242565751075745
Validation loss: 1.6132602858287033

Epoch: 6| Step: 9
Training loss: 0.2972809076309204
Validation loss: 1.5992663342465636

Epoch: 6| Step: 10
Training loss: 0.27663084864616394
Validation loss: 1.616805024044488

Epoch: 6| Step: 11
Training loss: 0.20855039358139038
Validation loss: 1.5595102284544258

Epoch: 6| Step: 12
Training loss: 0.32790592312812805
Validation loss: 1.5699984963222215

Epoch: 6| Step: 13
Training loss: 0.40644970536231995
Validation loss: 1.5586562489950528

Epoch: 318| Step: 0
Training loss: 0.30802977085113525
Validation loss: 1.5629764513302875

Epoch: 6| Step: 1
Training loss: 0.30534011125564575
Validation loss: 1.5552936715464438

Epoch: 6| Step: 2
Training loss: 0.35448965430259705
Validation loss: 1.5223049027945406

Epoch: 6| Step: 3
Training loss: 0.167719304561615
Validation loss: 1.6013477015238937

Epoch: 6| Step: 4
Training loss: 0.2924679219722748
Validation loss: 1.556524940716323

Epoch: 6| Step: 5
Training loss: 0.39971572160720825
Validation loss: 1.5793837142247025

Epoch: 6| Step: 6
Training loss: 0.228439062833786
Validation loss: 1.5503237773013372

Epoch: 6| Step: 7
Training loss: 0.25084739923477173
Validation loss: 1.5792784408856464

Epoch: 6| Step: 8
Training loss: 0.1570633053779602
Validation loss: 1.596574253933404

Epoch: 6| Step: 9
Training loss: 0.2898378372192383
Validation loss: 1.6097546636417348

Epoch: 6| Step: 10
Training loss: 0.26096877455711365
Validation loss: 1.6262481276706984

Epoch: 6| Step: 11
Training loss: 0.29145458340644836
Validation loss: 1.628556489944458

Epoch: 6| Step: 12
Training loss: 0.3205793499946594
Validation loss: 1.6131481624418689

Epoch: 6| Step: 13
Training loss: 0.3007100820541382
Validation loss: 1.5773809135601085

Epoch: 319| Step: 0
Training loss: 0.20561833679676056
Validation loss: 1.5760767818779073

Epoch: 6| Step: 1
Training loss: 0.3014177083969116
Validation loss: 1.580005181732998

Epoch: 6| Step: 2
Training loss: 0.27211809158325195
Validation loss: 1.5755752401967202

Epoch: 6| Step: 3
Training loss: 0.16743414103984833
Validation loss: 1.5942786444899857

Epoch: 6| Step: 4
Training loss: 0.2820686399936676
Validation loss: 1.5607223562015

Epoch: 6| Step: 5
Training loss: 0.37181800603866577
Validation loss: 1.5843424527875838

Epoch: 6| Step: 6
Training loss: 0.2335314154624939
Validation loss: 1.5856017451132498

Epoch: 6| Step: 7
Training loss: 0.32695695757865906
Validation loss: 1.574932731607909

Epoch: 6| Step: 8
Training loss: 0.22471462190151215
Validation loss: 1.5667400667744298

Epoch: 6| Step: 9
Training loss: 0.22802221775054932
Validation loss: 1.5672378540039062

Epoch: 6| Step: 10
Training loss: 0.36609286069869995
Validation loss: 1.6016205472330893

Epoch: 6| Step: 11
Training loss: 0.15747761726379395
Validation loss: 1.5783127482219408

Epoch: 6| Step: 12
Training loss: 0.21659955382347107
Validation loss: 1.6058959320027342

Epoch: 6| Step: 13
Training loss: 0.19804586470127106
Validation loss: 1.5793738826628654

Epoch: 320| Step: 0
Training loss: 0.15165823698043823
Validation loss: 1.5732105175654094

Epoch: 6| Step: 1
Training loss: 0.3276151716709137
Validation loss: 1.5604764261553365

Epoch: 6| Step: 2
Training loss: 0.28691181540489197
Validation loss: 1.5511731627166911

Epoch: 6| Step: 3
Training loss: 0.16930341720581055
Validation loss: 1.575433172205443

Epoch: 6| Step: 4
Training loss: 0.30116161704063416
Validation loss: 1.5844010409488474

Epoch: 6| Step: 5
Training loss: 0.27477771043777466
Validation loss: 1.598305804755098

Epoch: 6| Step: 6
Training loss: 0.11480046808719635
Validation loss: 1.5892189741134644

Epoch: 6| Step: 7
Training loss: 0.29082539677619934
Validation loss: 1.5858272198707826

Epoch: 6| Step: 8
Training loss: 0.3479061722755432
Validation loss: 1.5835456771235312

Epoch: 6| Step: 9
Training loss: 0.2591473460197449
Validation loss: 1.5938929434745543

Epoch: 6| Step: 10
Training loss: 0.19325625896453857
Validation loss: 1.5942317747300672

Epoch: 6| Step: 11
Training loss: 0.24223633110523224
Validation loss: 1.6195256248597176

Epoch: 6| Step: 12
Training loss: 0.3019849359989166
Validation loss: 1.6089290854751424

Epoch: 6| Step: 13
Training loss: 0.36339589953422546
Validation loss: 1.6178978591836908

Epoch: 321| Step: 0
Training loss: 0.5781271457672119
Validation loss: 1.6039632238367552

Epoch: 6| Step: 1
Training loss: 0.26416096091270447
Validation loss: 1.6115688944375643

Epoch: 6| Step: 2
Training loss: 0.28498756885528564
Validation loss: 1.5972967019645117

Epoch: 6| Step: 3
Training loss: 0.2011004090309143
Validation loss: 1.5773768873624905

Epoch: 6| Step: 4
Training loss: 0.2885267436504364
Validation loss: 1.5825342773109354

Epoch: 6| Step: 5
Training loss: 0.2043687254190445
Validation loss: 1.5717845783438733

Epoch: 6| Step: 6
Training loss: 0.3172255754470825
Validation loss: 1.561314425160808

Epoch: 6| Step: 7
Training loss: 0.36928778886795044
Validation loss: 1.5168025596167451

Epoch: 6| Step: 8
Training loss: 0.22278691828250885
Validation loss: 1.545204750953182

Epoch: 6| Step: 9
Training loss: 0.07194018363952637
Validation loss: 1.5314565973897134

Epoch: 6| Step: 10
Training loss: 0.3929166793823242
Validation loss: 1.5434512515221872

Epoch: 6| Step: 11
Training loss: 0.2425367683172226
Validation loss: 1.5776868712517522

Epoch: 6| Step: 12
Training loss: 0.16621020436286926
Validation loss: 1.572445741263769

Epoch: 6| Step: 13
Training loss: 0.16569945216178894
Validation loss: 1.5997676298182497

Epoch: 322| Step: 0
Training loss: 0.4145253300666809
Validation loss: 1.5926278983393023

Epoch: 6| Step: 1
Training loss: 0.26714766025543213
Validation loss: 1.596076952513828

Epoch: 6| Step: 2
Training loss: 0.3806646466255188
Validation loss: 1.619575761979626

Epoch: 6| Step: 3
Training loss: 0.23946025967597961
Validation loss: 1.6006675804814985

Epoch: 6| Step: 4
Training loss: 0.26515308022499084
Validation loss: 1.6636605275574552

Epoch: 6| Step: 5
Training loss: 0.23371821641921997
Validation loss: 1.6329981409093386

Epoch: 6| Step: 6
Training loss: 0.20688292384147644
Validation loss: 1.672387316662778

Epoch: 6| Step: 7
Training loss: 0.18190446496009827
Validation loss: 1.650141430157487

Epoch: 6| Step: 8
Training loss: 0.13754194974899292
Validation loss: 1.656765931396074

Epoch: 6| Step: 9
Training loss: 0.2776595950126648
Validation loss: 1.6418473669277724

Epoch: 6| Step: 10
Training loss: 0.2483488917350769
Validation loss: 1.5925683590673632

Epoch: 6| Step: 11
Training loss: 0.27105772495269775
Validation loss: 1.5856114023475236

Epoch: 6| Step: 12
Training loss: 0.2440030872821808
Validation loss: 1.5930030243371123

Epoch: 6| Step: 13
Training loss: 0.32898610830307007
Validation loss: 1.5642792101829284

Epoch: 323| Step: 0
Training loss: 0.33456939458847046
Validation loss: 1.5767826675086893

Epoch: 6| Step: 1
Training loss: 0.18360447883605957
Validation loss: 1.5648727686174455

Epoch: 6| Step: 2
Training loss: 0.26102012395858765
Validation loss: 1.579986895284345

Epoch: 6| Step: 3
Training loss: 0.25264912843704224
Validation loss: 1.5453259509096864

Epoch: 6| Step: 4
Training loss: 0.3891984224319458
Validation loss: 1.5741925419017833

Epoch: 6| Step: 5
Training loss: 0.24650898575782776
Validation loss: 1.5435084681357107

Epoch: 6| Step: 6
Training loss: 0.10517308115959167
Validation loss: 1.5143548256607466

Epoch: 6| Step: 7
Training loss: 0.21899965405464172
Validation loss: 1.5488207776059386

Epoch: 6| Step: 8
Training loss: 0.13970111310482025
Validation loss: 1.5460145114570536

Epoch: 6| Step: 9
Training loss: 0.3038586974143982
Validation loss: 1.5408231904429774

Epoch: 6| Step: 10
Training loss: 0.2419934868812561
Validation loss: 1.523942235977419

Epoch: 6| Step: 11
Training loss: 0.25573453307151794
Validation loss: 1.5480066460947837

Epoch: 6| Step: 12
Training loss: 0.31656309962272644
Validation loss: 1.5603752097775858

Epoch: 6| Step: 13
Training loss: 0.19467024505138397
Validation loss: 1.5437589512076428

Epoch: 324| Step: 0
Training loss: 0.31004923582077026
Validation loss: 1.5416290401130595

Epoch: 6| Step: 1
Training loss: 0.21603065729141235
Validation loss: 1.5564551584182247

Epoch: 6| Step: 2
Training loss: 0.25072920322418213
Validation loss: 1.5982612999536658

Epoch: 6| Step: 3
Training loss: 0.20506373047828674
Validation loss: 1.565525649696268

Epoch: 6| Step: 4
Training loss: 0.13649573922157288
Validation loss: 1.5605194363542783

Epoch: 6| Step: 5
Training loss: 0.2774895429611206
Validation loss: 1.5289917466461018

Epoch: 6| Step: 6
Training loss: 0.2007855623960495
Validation loss: 1.531403688974278

Epoch: 6| Step: 7
Training loss: 0.24017605185508728
Validation loss: 1.5448638957033876

Epoch: 6| Step: 8
Training loss: 0.36709800362586975
Validation loss: 1.5530616224453013

Epoch: 6| Step: 9
Training loss: 0.2581701874732971
Validation loss: 1.5571952090468457

Epoch: 6| Step: 10
Training loss: 0.24489404261112213
Validation loss: 1.533454861692203

Epoch: 6| Step: 11
Training loss: 0.3175855875015259
Validation loss: 1.5175467902614224

Epoch: 6| Step: 12
Training loss: 0.2573835849761963
Validation loss: 1.5642984169785694

Epoch: 6| Step: 13
Training loss: 0.19195817410945892
Validation loss: 1.552583631007902

Epoch: 325| Step: 0
Training loss: 0.3014967441558838
Validation loss: 1.5471208364732805

Epoch: 6| Step: 1
Training loss: 0.21245963871479034
Validation loss: 1.545318227942272

Epoch: 6| Step: 2
Training loss: 0.14939047396183014
Validation loss: 1.536643346150716

Epoch: 6| Step: 3
Training loss: 0.22317394614219666
Validation loss: 1.5753848450158232

Epoch: 6| Step: 4
Training loss: 0.17930547893047333
Validation loss: 1.5521479178500432

Epoch: 6| Step: 5
Training loss: 0.2775095999240875
Validation loss: 1.577473464832511

Epoch: 6| Step: 6
Training loss: 0.19841690361499786
Validation loss: 1.545520741452453

Epoch: 6| Step: 7
Training loss: 0.23863491415977478
Validation loss: 1.579724205437527

Epoch: 6| Step: 8
Training loss: 0.34386372566223145
Validation loss: 1.579198879580344

Epoch: 6| Step: 9
Training loss: 0.12304846942424774
Validation loss: 1.5746026974852367

Epoch: 6| Step: 10
Training loss: 0.4847628176212311
Validation loss: 1.5667745656864618

Epoch: 6| Step: 11
Training loss: 0.2681587338447571
Validation loss: 1.5731729820210447

Epoch: 6| Step: 12
Training loss: 0.20196521282196045
Validation loss: 1.5569289563804545

Epoch: 6| Step: 13
Training loss: 0.19353312253952026
Validation loss: 1.5806729319275066

Epoch: 326| Step: 0
Training loss: 0.16197384893894196
Validation loss: 1.6186314885334303

Epoch: 6| Step: 1
Training loss: 0.28927212953567505
Validation loss: 1.5924951107271257

Epoch: 6| Step: 2
Training loss: 0.2609119713306427
Validation loss: 1.5663885493432321

Epoch: 6| Step: 3
Training loss: 0.23873555660247803
Validation loss: 1.603495438893636

Epoch: 6| Step: 4
Training loss: 0.34735721349716187
Validation loss: 1.5832173388491395

Epoch: 6| Step: 5
Training loss: 0.22015103697776794
Validation loss: 1.5777361508338683

Epoch: 6| Step: 6
Training loss: 0.26270586252212524
Validation loss: 1.5809653625693372

Epoch: 6| Step: 7
Training loss: 0.2833230197429657
Validation loss: 1.561897978987745

Epoch: 6| Step: 8
Training loss: 0.3437442183494568
Validation loss: 1.560515970312139

Epoch: 6| Step: 9
Training loss: 0.23369409143924713
Validation loss: 1.541053314362803

Epoch: 6| Step: 10
Training loss: 0.09565913677215576
Validation loss: 1.5280888657416067

Epoch: 6| Step: 11
Training loss: 0.31066593527793884
Validation loss: 1.5655704704664086

Epoch: 6| Step: 12
Training loss: 0.20893332362174988
Validation loss: 1.5523506044059672

Epoch: 6| Step: 13
Training loss: 0.09927763044834137
Validation loss: 1.581370476753481

Epoch: 327| Step: 0
Training loss: 0.12833638489246368
Validation loss: 1.569433767308471

Epoch: 6| Step: 1
Training loss: 0.3073079586029053
Validation loss: 1.5824681225643362

Epoch: 6| Step: 2
Training loss: 0.16935086250305176
Validation loss: 1.571644522810495

Epoch: 6| Step: 3
Training loss: 0.26098862290382385
Validation loss: 1.573880668609373

Epoch: 6| Step: 4
Training loss: 0.18696433305740356
Validation loss: 1.570049580707345

Epoch: 6| Step: 5
Training loss: 0.22013065218925476
Validation loss: 1.5683186707958099

Epoch: 6| Step: 6
Training loss: 0.12166091799736023
Validation loss: 1.5587809765210716

Epoch: 6| Step: 7
Training loss: 0.2632601857185364
Validation loss: 1.5698184428676483

Epoch: 6| Step: 8
Training loss: 0.489751398563385
Validation loss: 1.5518168608347576

Epoch: 6| Step: 9
Training loss: 0.21482901275157928
Validation loss: 1.5611235813427997

Epoch: 6| Step: 10
Training loss: 0.18439379334449768
Validation loss: 1.5241037209828694

Epoch: 6| Step: 11
Training loss: 0.1500721573829651
Validation loss: 1.5036522137221469

Epoch: 6| Step: 12
Training loss: 0.24893534183502197
Validation loss: 1.5068085353861573

Epoch: 6| Step: 13
Training loss: 0.21485312283039093
Validation loss: 1.5543690983967116

Epoch: 328| Step: 0
Training loss: 0.23168042302131653
Validation loss: 1.5502797070369925

Epoch: 6| Step: 1
Training loss: 0.19163623452186584
Validation loss: 1.5593215586036764

Epoch: 6| Step: 2
Training loss: 0.3395119309425354
Validation loss: 1.5651633444652762

Epoch: 6| Step: 3
Training loss: 0.13284137845039368
Validation loss: 1.5693660205410374

Epoch: 6| Step: 4
Training loss: 0.2486344873905182
Validation loss: 1.5917995347771594

Epoch: 6| Step: 5
Training loss: 0.47246867418289185
Validation loss: 1.6159134193133282

Epoch: 6| Step: 6
Training loss: 0.25772643089294434
Validation loss: 1.6035522671156033

Epoch: 6| Step: 7
Training loss: 0.30977529287338257
Validation loss: 1.600465945018235

Epoch: 6| Step: 8
Training loss: 0.20090147852897644
Validation loss: 1.5880665689386346

Epoch: 6| Step: 9
Training loss: 0.2078787088394165
Validation loss: 1.5703902090749433

Epoch: 6| Step: 10
Training loss: 0.21457086503505707
Validation loss: 1.56946567181618

Epoch: 6| Step: 11
Training loss: 0.19906961917877197
Validation loss: 1.5235512615532003

Epoch: 6| Step: 12
Training loss: 0.21154837310314178
Validation loss: 1.5632871274025208

Epoch: 6| Step: 13
Training loss: 0.1181344985961914
Validation loss: 1.53318408355918

Epoch: 329| Step: 0
Training loss: 0.2278166264295578
Validation loss: 1.5156102052298925

Epoch: 6| Step: 1
Training loss: 0.19310981035232544
Validation loss: 1.567635445184605

Epoch: 6| Step: 2
Training loss: 0.21605786681175232
Validation loss: 1.5179493100412431

Epoch: 6| Step: 3
Training loss: 0.23484069108963013
Validation loss: 1.5339883117265598

Epoch: 6| Step: 4
Training loss: 0.21836771070957184
Validation loss: 1.5360414930569228

Epoch: 6| Step: 5
Training loss: 0.23577238619327545
Validation loss: 1.536292367084052

Epoch: 6| Step: 6
Training loss: 0.2660703957080841
Validation loss: 1.5506605166260914

Epoch: 6| Step: 7
Training loss: 0.3781890273094177
Validation loss: 1.5411239977805846

Epoch: 6| Step: 8
Training loss: 0.24686086177825928
Validation loss: 1.5182036956151326

Epoch: 6| Step: 9
Training loss: 0.22676165401935577
Validation loss: 1.502221748393069

Epoch: 6| Step: 10
Training loss: 0.24155287444591522
Validation loss: 1.4898966179099133

Epoch: 6| Step: 11
Training loss: 0.40891391038894653
Validation loss: 1.512441764595688

Epoch: 6| Step: 12
Training loss: 0.1801513135433197
Validation loss: 1.5439441780890188

Epoch: 6| Step: 13
Training loss: 0.2738431394100189
Validation loss: 1.5021268936895555

Epoch: 330| Step: 0
Training loss: 0.13951635360717773
Validation loss: 1.5264197728967155

Epoch: 6| Step: 1
Training loss: 0.2529681622982025
Validation loss: 1.5340294094495877

Epoch: 6| Step: 2
Training loss: 0.164009228348732
Validation loss: 1.5265920110928115

Epoch: 6| Step: 3
Training loss: 0.39337700605392456
Validation loss: 1.5315109196529593

Epoch: 6| Step: 4
Training loss: 0.3490062952041626
Validation loss: 1.5582397842919955

Epoch: 6| Step: 5
Training loss: 0.24309957027435303
Validation loss: 1.5484079366089196

Epoch: 6| Step: 6
Training loss: 0.24141134321689606
Validation loss: 1.5287546983329199

Epoch: 6| Step: 7
Training loss: 0.23792609572410583
Validation loss: 1.5336499508991037

Epoch: 6| Step: 8
Training loss: 0.3685939908027649
Validation loss: 1.5298602337478309

Epoch: 6| Step: 9
Training loss: 0.16727593541145325
Validation loss: 1.551238331743466

Epoch: 6| Step: 10
Training loss: 0.14627882838249207
Validation loss: 1.5209409511217507

Epoch: 6| Step: 11
Training loss: 0.27742767333984375
Validation loss: 1.564352664896237

Epoch: 6| Step: 12
Training loss: 0.17453104257583618
Validation loss: 1.5656127493868592

Epoch: 6| Step: 13
Training loss: 0.18646414577960968
Validation loss: 1.5347055530035367

Epoch: 331| Step: 0
Training loss: 0.21007594466209412
Validation loss: 1.5504057304833525

Epoch: 6| Step: 1
Training loss: 0.2534445524215698
Validation loss: 1.5637957460136824

Epoch: 6| Step: 2
Training loss: 0.16573452949523926
Validation loss: 1.5622451138752762

Epoch: 6| Step: 3
Training loss: 0.28278395533561707
Validation loss: 1.557227414141419

Epoch: 6| Step: 4
Training loss: 0.35445642471313477
Validation loss: 1.544279480493197

Epoch: 6| Step: 5
Training loss: 0.15911585092544556
Validation loss: 1.5304870708014375

Epoch: 6| Step: 6
Training loss: 0.43747127056121826
Validation loss: 1.5234268839641283

Epoch: 6| Step: 7
Training loss: 0.2060661017894745
Validation loss: 1.5491823611720916

Epoch: 6| Step: 8
Training loss: 0.14439859986305237
Validation loss: 1.5823648719377414

Epoch: 6| Step: 9
Training loss: 0.23949363827705383
Validation loss: 1.5887833692694222

Epoch: 6| Step: 10
Training loss: 0.16262789070606232
Validation loss: 1.5460496307701193

Epoch: 6| Step: 11
Training loss: 0.13653035461902618
Validation loss: 1.5596526912463609

Epoch: 6| Step: 12
Training loss: 0.23198512196540833
Validation loss: 1.5444566190883677

Epoch: 6| Step: 13
Training loss: 0.22418934106826782
Validation loss: 1.5258887224299933

Epoch: 332| Step: 0
Training loss: 0.17529678344726562
Validation loss: 1.5646460927942747

Epoch: 6| Step: 1
Training loss: 0.23221826553344727
Validation loss: 1.5486826050666072

Epoch: 6| Step: 2
Training loss: 0.17135263979434967
Validation loss: 1.5893594116292975

Epoch: 6| Step: 3
Training loss: 0.19556733965873718
Validation loss: 1.573733110581675

Epoch: 6| Step: 4
Training loss: 0.21396231651306152
Validation loss: 1.581182531131211

Epoch: 6| Step: 5
Training loss: 0.22900386154651642
Validation loss: 1.5511664113690775

Epoch: 6| Step: 6
Training loss: 0.13359640538692474
Validation loss: 1.5886293021581506

Epoch: 6| Step: 7
Training loss: 0.3046238422393799
Validation loss: 1.574072237937681

Epoch: 6| Step: 8
Training loss: 0.27610793709754944
Validation loss: 1.5659515293695594

Epoch: 6| Step: 9
Training loss: 0.21024423837661743
Validation loss: 1.5668030438884613

Epoch: 6| Step: 10
Training loss: 0.3882306218147278
Validation loss: 1.6049284319723807

Epoch: 6| Step: 11
Training loss: 0.27679044008255005
Validation loss: 1.5850686437340193

Epoch: 6| Step: 12
Training loss: 0.23209020495414734
Validation loss: 1.5685306595217796

Epoch: 6| Step: 13
Training loss: 0.19978609681129456
Validation loss: 1.5747425799728723

Epoch: 333| Step: 0
Training loss: 0.13858374953269958
Validation loss: 1.5884178902513237

Epoch: 6| Step: 1
Training loss: 0.17898999154567719
Validation loss: 1.5344971021016438

Epoch: 6| Step: 2
Training loss: 0.24474628269672394
Validation loss: 1.555912915096488

Epoch: 6| Step: 3
Training loss: 0.2598037123680115
Validation loss: 1.5686565804225143

Epoch: 6| Step: 4
Training loss: 0.23316974937915802
Validation loss: 1.5754021508719331

Epoch: 6| Step: 5
Training loss: 0.23978695273399353
Validation loss: 1.6192785757844166

Epoch: 6| Step: 6
Training loss: 0.15459579229354858
Validation loss: 1.575856610011029

Epoch: 6| Step: 7
Training loss: 0.35056111216545105
Validation loss: 1.6200022473130176

Epoch: 6| Step: 8
Training loss: 0.17532563209533691
Validation loss: 1.6194391750520276

Epoch: 6| Step: 9
Training loss: 0.17789366841316223
Validation loss: 1.6272596325925601

Epoch: 6| Step: 10
Training loss: 0.24983826279640198
Validation loss: 1.6377644769607052

Epoch: 6| Step: 11
Training loss: 0.33072608709335327
Validation loss: 1.6312025811082573

Epoch: 6| Step: 12
Training loss: 0.14592602849006653
Validation loss: 1.621164034771663

Epoch: 6| Step: 13
Training loss: 0.21401135623455048
Validation loss: 1.6038265920454455

Epoch: 334| Step: 0
Training loss: 0.2761424779891968
Validation loss: 1.617407133502345

Epoch: 6| Step: 1
Training loss: 0.41556352376937866
Validation loss: 1.6198576624675463

Epoch: 6| Step: 2
Training loss: 0.25245094299316406
Validation loss: 1.609947948045628

Epoch: 6| Step: 3
Training loss: 0.45367932319641113
Validation loss: 1.6349576032289894

Epoch: 6| Step: 4
Training loss: 0.24913223087787628
Validation loss: 1.616982053684932

Epoch: 6| Step: 5
Training loss: 0.3420436978340149
Validation loss: 1.5924707330683225

Epoch: 6| Step: 6
Training loss: 0.12779074907302856
Validation loss: 1.5841849901342904

Epoch: 6| Step: 7
Training loss: 0.21723753213882446
Validation loss: 1.5491517359210598

Epoch: 6| Step: 8
Training loss: 0.2171395719051361
Validation loss: 1.564443903584634

Epoch: 6| Step: 9
Training loss: 0.23121336102485657
Validation loss: 1.5930130084355671

Epoch: 6| Step: 10
Training loss: 0.19648166000843048
Validation loss: 1.5669433057949107

Epoch: 6| Step: 11
Training loss: 0.24790629744529724
Validation loss: 1.5866769283048567

Epoch: 6| Step: 12
Training loss: 0.21019260585308075
Validation loss: 1.5700815634060932

Epoch: 6| Step: 13
Training loss: 0.09883566945791245
Validation loss: 1.5556397668776973

Epoch: 335| Step: 0
Training loss: 0.29082611203193665
Validation loss: 1.571380299906577

Epoch: 6| Step: 1
Training loss: 0.2705996036529541
Validation loss: 1.5649054088900167

Epoch: 6| Step: 2
Training loss: 0.13858312368392944
Validation loss: 1.5456092319180887

Epoch: 6| Step: 3
Training loss: 0.23836249113082886
Validation loss: 1.5316871558466265

Epoch: 6| Step: 4
Training loss: 0.2367621660232544
Validation loss: 1.5543478099248742

Epoch: 6| Step: 5
Training loss: 0.24663463234901428
Validation loss: 1.5565137555522304

Epoch: 6| Step: 6
Training loss: 0.20329120755195618
Validation loss: 1.561203630380733

Epoch: 6| Step: 7
Training loss: 0.16540537774562836
Validation loss: 1.5566691865203202

Epoch: 6| Step: 8
Training loss: 0.25039565563201904
Validation loss: 1.5131436676107428

Epoch: 6| Step: 9
Training loss: 0.2646268606185913
Validation loss: 1.5430804144951604

Epoch: 6| Step: 10
Training loss: 0.2055758237838745
Validation loss: 1.5513434051185526

Epoch: 6| Step: 11
Training loss: 0.2049117088317871
Validation loss: 1.5099807388039046

Epoch: 6| Step: 12
Training loss: 0.3307827115058899
Validation loss: 1.5302654825231081

Epoch: 6| Step: 13
Training loss: 0.24964529275894165
Validation loss: 1.524435330462712

Epoch: 336| Step: 0
Training loss: 0.274566650390625
Validation loss: 1.541634778822622

Epoch: 6| Step: 1
Training loss: 0.24909436702728271
Validation loss: 1.5242631217484832

Epoch: 6| Step: 2
Training loss: 0.3155122995376587
Validation loss: 1.5302181378487618

Epoch: 6| Step: 3
Training loss: 0.38008973002433777
Validation loss: 1.5294598917807303

Epoch: 6| Step: 4
Training loss: 0.2712729573249817
Validation loss: 1.5316401143227854

Epoch: 6| Step: 5
Training loss: 0.1189708560705185
Validation loss: 1.5671395986310896

Epoch: 6| Step: 6
Training loss: 0.301565945148468
Validation loss: 1.5375976434317968

Epoch: 6| Step: 7
Training loss: 0.22074216604232788
Validation loss: 1.52871923933747

Epoch: 6| Step: 8
Training loss: 0.1910019814968109
Validation loss: 1.5504698548265683

Epoch: 6| Step: 9
Training loss: 0.098575659096241
Validation loss: 1.5253168331679476

Epoch: 6| Step: 10
Training loss: 0.2602043151855469
Validation loss: 1.5591363522314257

Epoch: 6| Step: 11
Training loss: 0.2256990373134613
Validation loss: 1.5498448930760866

Epoch: 6| Step: 12
Training loss: 0.10660067945718765
Validation loss: 1.536655000461045

Epoch: 6| Step: 13
Training loss: 0.30130407214164734
Validation loss: 1.5436346377095869

Epoch: 337| Step: 0
Training loss: 0.24759307503700256
Validation loss: 1.5332026276537167

Epoch: 6| Step: 1
Training loss: 0.2060026079416275
Validation loss: 1.540632373543196

Epoch: 6| Step: 2
Training loss: 0.2109937220811844
Validation loss: 1.553696766335477

Epoch: 6| Step: 3
Training loss: 0.06155259907245636
Validation loss: 1.5691055418342672

Epoch: 6| Step: 4
Training loss: 0.23888662457466125
Validation loss: 1.5755486975434005

Epoch: 6| Step: 5
Training loss: 0.09362748265266418
Validation loss: 1.5700928549612723

Epoch: 6| Step: 6
Training loss: 0.1698465347290039
Validation loss: 1.564344399718828

Epoch: 6| Step: 7
Training loss: 0.20808127522468567
Validation loss: 1.5900438395879601

Epoch: 6| Step: 8
Training loss: 0.3353211581707001
Validation loss: 1.59225264159582

Epoch: 6| Step: 9
Training loss: 0.25112640857696533
Validation loss: 1.5798721698022657

Epoch: 6| Step: 10
Training loss: 0.21678757667541504
Validation loss: 1.5663031813918904

Epoch: 6| Step: 11
Training loss: 0.23169827461242676
Validation loss: 1.5355498303649247

Epoch: 6| Step: 12
Training loss: 0.20993223786354065
Validation loss: 1.5278190118010326

Epoch: 6| Step: 13
Training loss: 0.2961733043193817
Validation loss: 1.5253836249792447

Epoch: 338| Step: 0
Training loss: 0.17683899402618408
Validation loss: 1.4977511193162651

Epoch: 6| Step: 1
Training loss: 0.19324760138988495
Validation loss: 1.5106629370361246

Epoch: 6| Step: 2
Training loss: 0.10898587852716446
Validation loss: 1.4711244298565773

Epoch: 6| Step: 3
Training loss: 0.21923866868019104
Validation loss: 1.5255146007384024

Epoch: 6| Step: 4
Training loss: 0.27199655771255493
Validation loss: 1.4848327982810237

Epoch: 6| Step: 5
Training loss: 0.23273344337940216
Validation loss: 1.5302383348505983

Epoch: 6| Step: 6
Training loss: 0.21084000170230865
Validation loss: 1.5269969176220637

Epoch: 6| Step: 7
Training loss: 0.16700509190559387
Validation loss: 1.5195514425154655

Epoch: 6| Step: 8
Training loss: 0.4354567527770996
Validation loss: 1.5589588816447923

Epoch: 6| Step: 9
Training loss: 0.2442217320203781
Validation loss: 1.5575697300254658

Epoch: 6| Step: 10
Training loss: 0.18159504234790802
Validation loss: 1.58830048448296

Epoch: 6| Step: 11
Training loss: 0.33359605073928833
Validation loss: 1.5748691289655623

Epoch: 6| Step: 12
Training loss: 0.18947646021842957
Validation loss: 1.571661263383845

Epoch: 6| Step: 13
Training loss: 0.07276719808578491
Validation loss: 1.5461599275630007

Epoch: 339| Step: 0
Training loss: 0.14408743381500244
Validation loss: 1.5611719892870994

Epoch: 6| Step: 1
Training loss: 0.21321484446525574
Validation loss: 1.5571648241371236

Epoch: 6| Step: 2
Training loss: 0.33982428908348083
Validation loss: 1.5794521403569046

Epoch: 6| Step: 3
Training loss: 0.26731836795806885
Validation loss: 1.5631463117496942

Epoch: 6| Step: 4
Training loss: 0.15019935369491577
Validation loss: 1.572933889204456

Epoch: 6| Step: 5
Training loss: 0.1532144546508789
Validation loss: 1.5726298503978278

Epoch: 6| Step: 6
Training loss: 0.08767841011285782
Validation loss: 1.5628314710432483

Epoch: 6| Step: 7
Training loss: 0.1875404417514801
Validation loss: 1.5743614845378424

Epoch: 6| Step: 8
Training loss: 0.3324816823005676
Validation loss: 1.5290440641423708

Epoch: 6| Step: 9
Training loss: 0.25489503145217896
Validation loss: 1.552885655433901

Epoch: 6| Step: 10
Training loss: 0.16772595047950745
Validation loss: 1.5718040671399844

Epoch: 6| Step: 11
Training loss: 0.24572744965553284
Validation loss: 1.5636412071925339

Epoch: 6| Step: 12
Training loss: 0.12384739518165588
Validation loss: 1.5341882026323708

Epoch: 6| Step: 13
Training loss: 0.18602067232131958
Validation loss: 1.520999293173513

Epoch: 340| Step: 0
Training loss: 0.25487732887268066
Validation loss: 1.493499105976474

Epoch: 6| Step: 1
Training loss: 0.17691630125045776
Validation loss: 1.4922229397681452

Epoch: 6| Step: 2
Training loss: 0.2163844257593155
Validation loss: 1.490950092192619

Epoch: 6| Step: 3
Training loss: 0.20837192237377167
Validation loss: 1.5247497622684767

Epoch: 6| Step: 4
Training loss: 0.19967809319496155
Validation loss: 1.496596105637089

Epoch: 6| Step: 5
Training loss: 0.07667472958564758
Validation loss: 1.5162780259245185

Epoch: 6| Step: 6
Training loss: 0.2215733528137207
Validation loss: 1.5146705950460126

Epoch: 6| Step: 7
Training loss: 0.12556082010269165
Validation loss: 1.536079236256179

Epoch: 6| Step: 8
Training loss: 0.15391045808792114
Validation loss: 1.5292679532881706

Epoch: 6| Step: 9
Training loss: 0.16164986789226532
Validation loss: 1.572216174935782

Epoch: 6| Step: 10
Training loss: 0.30716729164123535
Validation loss: 1.582572647320327

Epoch: 6| Step: 11
Training loss: 0.14831560850143433
Validation loss: 1.586299979558555

Epoch: 6| Step: 12
Training loss: 0.2169952243566513
Validation loss: 1.5946297107204315

Epoch: 6| Step: 13
Training loss: 0.22498628497123718
Validation loss: 1.6128933250263173

Epoch: 341| Step: 0
Training loss: 0.2696434259414673
Validation loss: 1.6463120701492473

Epoch: 6| Step: 1
Training loss: 0.3385671377182007
Validation loss: 1.583551331873863

Epoch: 6| Step: 2
Training loss: 0.20263908803462982
Validation loss: 1.594273107026213

Epoch: 6| Step: 3
Training loss: 0.2347436100244522
Validation loss: 1.5753301689701695

Epoch: 6| Step: 4
Training loss: 0.1633380949497223
Validation loss: 1.5703642547771495

Epoch: 6| Step: 5
Training loss: 0.20245037972927094
Validation loss: 1.5670753006012208

Epoch: 6| Step: 6
Training loss: 0.12901467084884644
Validation loss: 1.531526792433954

Epoch: 6| Step: 7
Training loss: 0.2297777235507965
Validation loss: 1.535567407966942

Epoch: 6| Step: 8
Training loss: 0.185805544257164
Validation loss: 1.5397546893806868

Epoch: 6| Step: 9
Training loss: 0.21931013464927673
Validation loss: 1.5260890433865208

Epoch: 6| Step: 10
Training loss: 0.14725074172019958
Validation loss: 1.5404361935072048

Epoch: 6| Step: 11
Training loss: 0.21012431383132935
Validation loss: 1.490875497941048

Epoch: 6| Step: 12
Training loss: 0.290793240070343
Validation loss: 1.516136420670376

Epoch: 6| Step: 13
Training loss: 0.15973445773124695
Validation loss: 1.472549416685617

Epoch: 342| Step: 0
Training loss: 0.11281783133745193
Validation loss: 1.4803733659046951

Epoch: 6| Step: 1
Training loss: 0.25254446268081665
Validation loss: 1.510781591938388

Epoch: 6| Step: 2
Training loss: 0.1656344085931778
Validation loss: 1.5019414399259834

Epoch: 6| Step: 3
Training loss: 0.25984251499176025
Validation loss: 1.5106100587434665

Epoch: 6| Step: 4
Training loss: 0.27505189180374146
Validation loss: 1.5479996024921376

Epoch: 6| Step: 5
Training loss: 0.14410877227783203
Validation loss: 1.5173721313476562

Epoch: 6| Step: 6
Training loss: 0.16887666285037994
Validation loss: 1.4971575031998337

Epoch: 6| Step: 7
Training loss: 0.12787571549415588
Validation loss: 1.5256026765351653

Epoch: 6| Step: 8
Training loss: 0.20353251695632935
Validation loss: 1.5044427200030255

Epoch: 6| Step: 9
Training loss: 0.18334554135799408
Validation loss: 1.505673009862182

Epoch: 6| Step: 10
Training loss: 0.15325282514095306
Validation loss: 1.4994643003709855

Epoch: 6| Step: 11
Training loss: 0.28111907839775085
Validation loss: 1.5237273823830388

Epoch: 6| Step: 12
Training loss: 0.3639375865459442
Validation loss: 1.5184992910713278

Epoch: 6| Step: 13
Training loss: 0.19988217949867249
Validation loss: 1.4869657780534478

Epoch: 343| Step: 0
Training loss: 0.14473208785057068
Validation loss: 1.5378136199007753

Epoch: 6| Step: 1
Training loss: 0.23228132724761963
Validation loss: 1.536970814069112

Epoch: 6| Step: 2
Training loss: 0.2047048807144165
Validation loss: 1.5134997854950607

Epoch: 6| Step: 3
Training loss: 0.21648308634757996
Validation loss: 1.4966493370712444

Epoch: 6| Step: 4
Training loss: 0.27575600147247314
Validation loss: 1.5087322445325955

Epoch: 6| Step: 5
Training loss: 0.14300277829170227
Validation loss: 1.5117304594286027

Epoch: 6| Step: 6
Training loss: 0.24251669645309448
Validation loss: 1.4915682346590105

Epoch: 6| Step: 7
Training loss: 0.19244128465652466
Validation loss: 1.4942186468391008

Epoch: 6| Step: 8
Training loss: 0.32809746265411377
Validation loss: 1.5218940665644984

Epoch: 6| Step: 9
Training loss: 0.18673613667488098
Validation loss: 1.538804304215216

Epoch: 6| Step: 10
Training loss: 0.20899787545204163
Validation loss: 1.5176621919037194

Epoch: 6| Step: 11
Training loss: 0.20645517110824585
Validation loss: 1.526412300525173

Epoch: 6| Step: 12
Training loss: 0.31637662649154663
Validation loss: 1.514044778321379

Epoch: 6| Step: 13
Training loss: 0.31635335087776184
Validation loss: 1.5098186539065452

Epoch: 344| Step: 0
Training loss: 0.16013282537460327
Validation loss: 1.5085472599152596

Epoch: 6| Step: 1
Training loss: 0.15035663545131683
Validation loss: 1.5071225948231195

Epoch: 6| Step: 2
Training loss: 0.16876420378684998
Validation loss: 1.5169492075520177

Epoch: 6| Step: 3
Training loss: 0.2610056400299072
Validation loss: 1.5120169552423621

Epoch: 6| Step: 4
Training loss: 0.14983707666397095
Validation loss: 1.4837845461342924

Epoch: 6| Step: 5
Training loss: 0.12235324084758759
Validation loss: 1.4529101874238701

Epoch: 6| Step: 6
Training loss: 0.15633507072925568
Validation loss: 1.4644055443425332

Epoch: 6| Step: 7
Training loss: 0.17285239696502686
Validation loss: 1.4445501771024478

Epoch: 6| Step: 8
Training loss: 0.2594358026981354
Validation loss: 1.4365108833518079

Epoch: 6| Step: 9
Training loss: 0.21642763912677765
Validation loss: 1.4201544766784997

Epoch: 6| Step: 10
Training loss: 0.21479088068008423
Validation loss: 1.4284780371573664

Epoch: 6| Step: 11
Training loss: 0.3710572123527527
Validation loss: 1.4068955708575506

Epoch: 6| Step: 12
Training loss: 0.20326310396194458
Validation loss: 1.4500704196191603

Epoch: 6| Step: 13
Training loss: 0.4460564851760864
Validation loss: 1.4687367690506803

Epoch: 345| Step: 0
Training loss: 0.11072231829166412
Validation loss: 1.4369732205585768

Epoch: 6| Step: 1
Training loss: 0.1561364084482193
Validation loss: 1.4783162288768317

Epoch: 6| Step: 2
Training loss: 0.2360043227672577
Validation loss: 1.4658273932754353

Epoch: 6| Step: 3
Training loss: 0.3142073154449463
Validation loss: 1.4837044310826126

Epoch: 6| Step: 4
Training loss: 0.19596201181411743
Validation loss: 1.4870716410298501

Epoch: 6| Step: 5
Training loss: 0.09023906290531158
Validation loss: 1.5295431665194932

Epoch: 6| Step: 6
Training loss: 0.27018481492996216
Validation loss: 1.5575345203440676

Epoch: 6| Step: 7
Training loss: 0.17065981030464172
Validation loss: 1.5458384111363401

Epoch: 6| Step: 8
Training loss: 0.21185699105262756
Validation loss: 1.57480550196863

Epoch: 6| Step: 9
Training loss: 0.27437445521354675
Validation loss: 1.559167573528905

Epoch: 6| Step: 10
Training loss: 0.2616279125213623
Validation loss: 1.5559749571225976

Epoch: 6| Step: 11
Training loss: 0.1586698591709137
Validation loss: 1.513808463850329

Epoch: 6| Step: 12
Training loss: 0.22706487774848938
Validation loss: 1.5596619523981565

Epoch: 6| Step: 13
Training loss: 0.36706721782684326
Validation loss: 1.5335610105145363

Epoch: 346| Step: 0
Training loss: 0.25766849517822266
Validation loss: 1.5254553729488003

Epoch: 6| Step: 1
Training loss: 0.19290001690387726
Validation loss: 1.5300213431799283

Epoch: 6| Step: 2
Training loss: 0.18125960230827332
Validation loss: 1.5299790866913334

Epoch: 6| Step: 3
Training loss: 0.15914589166641235
Validation loss: 1.4986376467571463

Epoch: 6| Step: 4
Training loss: 0.2005014717578888
Validation loss: 1.554534412199451

Epoch: 6| Step: 5
Training loss: 0.14470583200454712
Validation loss: 1.5578784019716325

Epoch: 6| Step: 6
Training loss: 0.21883919835090637
Validation loss: 1.5372845562555457

Epoch: 6| Step: 7
Training loss: 0.38041186332702637
Validation loss: 1.5876136556748421

Epoch: 6| Step: 8
Training loss: 0.21052420139312744
Validation loss: 1.57621213441254

Epoch: 6| Step: 9
Training loss: 0.23088599741458893
Validation loss: 1.5560152633215791

Epoch: 6| Step: 10
Training loss: 0.15569812059402466
Validation loss: 1.5394901370489469

Epoch: 6| Step: 11
Training loss: 0.26238691806793213
Validation loss: 1.5603951074743783

Epoch: 6| Step: 12
Training loss: 0.3055502474308014
Validation loss: 1.5510046507722588

Epoch: 6| Step: 13
Training loss: 0.31294143199920654
Validation loss: 1.5653352352880663

Epoch: 347| Step: 0
Training loss: 0.13845452666282654
Validation loss: 1.544667440076028

Epoch: 6| Step: 1
Training loss: 0.23871220648288727
Validation loss: 1.5561635237868114

Epoch: 6| Step: 2
Training loss: 0.19838471710681915
Validation loss: 1.568992696782594

Epoch: 6| Step: 3
Training loss: 0.26212120056152344
Validation loss: 1.5291619364933302

Epoch: 6| Step: 4
Training loss: 0.2977067828178406
Validation loss: 1.526896793355224

Epoch: 6| Step: 5
Training loss: 0.18487045168876648
Validation loss: 1.5189156327196347

Epoch: 6| Step: 6
Training loss: 0.22741834819316864
Validation loss: 1.5054213205973308

Epoch: 6| Step: 7
Training loss: 0.30097514390945435
Validation loss: 1.510994121592532

Epoch: 6| Step: 8
Training loss: 0.28462448716163635
Validation loss: 1.5070766595102125

Epoch: 6| Step: 9
Training loss: 0.19353362917900085
Validation loss: 1.5278231097805886

Epoch: 6| Step: 10
Training loss: 0.247554749250412
Validation loss: 1.4878800466496458

Epoch: 6| Step: 11
Training loss: 0.16680872440338135
Validation loss: 1.5162488106758363

Epoch: 6| Step: 12
Training loss: 0.3242990970611572
Validation loss: 1.4703088742430492

Epoch: 6| Step: 13
Training loss: 0.08992082625627518
Validation loss: 1.4786103553669427

Epoch: 348| Step: 0
Training loss: 0.2146131992340088
Validation loss: 1.530590017636617

Epoch: 6| Step: 1
Training loss: 0.16764256358146667
Validation loss: 1.5177827586409867

Epoch: 6| Step: 2
Training loss: 0.16492074728012085
Validation loss: 1.5426574496812717

Epoch: 6| Step: 3
Training loss: 0.45812320709228516
Validation loss: 1.5451992942440895

Epoch: 6| Step: 4
Training loss: 0.20008409023284912
Validation loss: 1.5855771085267425

Epoch: 6| Step: 5
Training loss: 0.2486286759376526
Validation loss: 1.582860271135966

Epoch: 6| Step: 6
Training loss: 0.21063002943992615
Validation loss: 1.58001035259616

Epoch: 6| Step: 7
Training loss: 0.1520439237356186
Validation loss: 1.5939619509122704

Epoch: 6| Step: 8
Training loss: 0.27922555804252625
Validation loss: 1.5561137507038731

Epoch: 6| Step: 9
Training loss: 0.2282811403274536
Validation loss: 1.5513371421444802

Epoch: 6| Step: 10
Training loss: 0.08320402354001999
Validation loss: 1.5241422948016916

Epoch: 6| Step: 11
Training loss: 0.20328813791275024
Validation loss: 1.5170426868623303

Epoch: 6| Step: 12
Training loss: 0.2224372774362564
Validation loss: 1.5250675652616767

Epoch: 6| Step: 13
Training loss: 0.09324055165052414
Validation loss: 1.5160945544960678

Epoch: 349| Step: 0
Training loss: 0.1508122980594635
Validation loss: 1.5089131606522428

Epoch: 6| Step: 1
Training loss: 0.1452198028564453
Validation loss: 1.501422683397929

Epoch: 6| Step: 2
Training loss: 0.1794268637895584
Validation loss: 1.501535984777635

Epoch: 6| Step: 3
Training loss: 0.1610117256641388
Validation loss: 1.4632971530319543

Epoch: 6| Step: 4
Training loss: 0.15467429161071777
Validation loss: 1.4864836790228402

Epoch: 6| Step: 5
Training loss: 0.19233669340610504
Validation loss: 1.495949152977236

Epoch: 6| Step: 6
Training loss: 0.23255407810211182
Validation loss: 1.4834902940257904

Epoch: 6| Step: 7
Training loss: 0.17421835660934448
Validation loss: 1.5069985466618692

Epoch: 6| Step: 8
Training loss: 0.180080384016037
Validation loss: 1.5161983095189577

Epoch: 6| Step: 9
Training loss: 0.29612985253334045
Validation loss: 1.5135189794724988

Epoch: 6| Step: 10
Training loss: 0.3137778043746948
Validation loss: 1.5017943882173108

Epoch: 6| Step: 11
Training loss: 0.17432290315628052
Validation loss: 1.5176070185117825

Epoch: 6| Step: 12
Training loss: 0.3093388080596924
Validation loss: 1.5409059370717695

Epoch: 6| Step: 13
Training loss: 0.3056093752384186
Validation loss: 1.5505754242661178

Epoch: 350| Step: 0
Training loss: 0.21268944442272186
Validation loss: 1.5252885203207693

Epoch: 6| Step: 1
Training loss: 0.16489362716674805
Validation loss: 1.5046473280076058

Epoch: 6| Step: 2
Training loss: 0.24728916585445404
Validation loss: 1.5033119724642845

Epoch: 6| Step: 3
Training loss: 0.21291857957839966
Validation loss: 1.532107735192904

Epoch: 6| Step: 4
Training loss: 0.3775962293148041
Validation loss: 1.502208153406779

Epoch: 6| Step: 5
Training loss: 0.1529693752527237
Validation loss: 1.4904979621210406

Epoch: 6| Step: 6
Training loss: 0.28950878977775574
Validation loss: 1.4677194709418921

Epoch: 6| Step: 7
Training loss: 0.14470607042312622
Validation loss: 1.4747384619969193

Epoch: 6| Step: 8
Training loss: 0.08550968766212463
Validation loss: 1.450806588254949

Epoch: 6| Step: 9
Training loss: 0.26287034153938293
Validation loss: 1.4769758274478297

Epoch: 6| Step: 10
Training loss: 0.25401484966278076
Validation loss: 1.481366451068591

Epoch: 6| Step: 11
Training loss: 0.11482107639312744
Validation loss: 1.487871459735337

Epoch: 6| Step: 12
Training loss: 0.12702497839927673
Validation loss: 1.474788966999259

Epoch: 6| Step: 13
Training loss: 0.2040882706642151
Validation loss: 1.4667083319797312

Epoch: 351| Step: 0
Training loss: 0.13751739263534546
Validation loss: 1.5113709190840363

Epoch: 6| Step: 1
Training loss: 0.22770510613918304
Validation loss: 1.5079398193667013

Epoch: 6| Step: 2
Training loss: 0.23982325196266174
Validation loss: 1.5326995208699217

Epoch: 6| Step: 3
Training loss: 0.248837411403656
Validation loss: 1.5532316853923183

Epoch: 6| Step: 4
Training loss: 0.2556051015853882
Validation loss: 1.5713727064030145

Epoch: 6| Step: 5
Training loss: 0.1466500163078308
Validation loss: 1.5624131451370895

Epoch: 6| Step: 6
Training loss: 0.3077530860900879
Validation loss: 1.5423544594036636

Epoch: 6| Step: 7
Training loss: 0.26793479919433594
Validation loss: 1.5241441970230432

Epoch: 6| Step: 8
Training loss: 0.13282936811447144
Validation loss: 1.5365686942172307

Epoch: 6| Step: 9
Training loss: 0.1885642409324646
Validation loss: 1.5245610693449616

Epoch: 6| Step: 10
Training loss: 0.3025569021701813
Validation loss: 1.5299870359000338

Epoch: 6| Step: 11
Training loss: 0.11015492677688599
Validation loss: 1.527226875546158

Epoch: 6| Step: 12
Training loss: 0.35979163646698
Validation loss: 1.5117312022434768

Epoch: 6| Step: 13
Training loss: 0.2554944157600403
Validation loss: 1.5136527425499373

Epoch: 352| Step: 0
Training loss: 0.22243022918701172
Validation loss: 1.4913426804286178

Epoch: 6| Step: 1
Training loss: 0.14233435690402985
Validation loss: 1.4533799861067085

Epoch: 6| Step: 2
Training loss: 0.11639436334371567
Validation loss: 1.477942244980925

Epoch: 6| Step: 3
Training loss: 0.26587504148483276
Validation loss: 1.4862028911549559

Epoch: 6| Step: 4
Training loss: 0.12825533747673035
Validation loss: 1.4920695077988408

Epoch: 6| Step: 5
Training loss: 0.23880544304847717
Validation loss: 1.4527501931754492

Epoch: 6| Step: 6
Training loss: 0.25909358263015747
Validation loss: 1.4666895430575135

Epoch: 6| Step: 7
Training loss: 0.15947505831718445
Validation loss: 1.4668634719746088

Epoch: 6| Step: 8
Training loss: 0.2227727174758911
Validation loss: 1.4909865266533309

Epoch: 6| Step: 9
Training loss: 0.2848769426345825
Validation loss: 1.4842601694086546

Epoch: 6| Step: 10
Training loss: 0.19666233658790588
Validation loss: 1.463517265935098

Epoch: 6| Step: 11
Training loss: 0.10826314240694046
Validation loss: 1.4820652546421174

Epoch: 6| Step: 12
Training loss: 0.42663711309432983
Validation loss: 1.4558179096509052

Epoch: 6| Step: 13
Training loss: 0.14455434679985046
Validation loss: 1.4794112687469811

Epoch: 353| Step: 0
Training loss: 0.2768194079399109
Validation loss: 1.5054388751265824

Epoch: 6| Step: 1
Training loss: 0.12785887718200684
Validation loss: 1.5174041614737561

Epoch: 6| Step: 2
Training loss: 0.14942288398742676
Validation loss: 1.5147312354016047

Epoch: 6| Step: 3
Training loss: 0.22919481992721558
Validation loss: 1.561883972537133

Epoch: 6| Step: 4
Training loss: 0.14128181338310242
Validation loss: 1.5347999436880952

Epoch: 6| Step: 5
Training loss: 0.12531983852386475
Validation loss: 1.5835400960778678

Epoch: 6| Step: 6
Training loss: 0.1914128065109253
Validation loss: 1.5440855897882932

Epoch: 6| Step: 7
Training loss: 0.1843327134847641
Validation loss: 1.5111036915932932

Epoch: 6| Step: 8
Training loss: 0.28026360273361206
Validation loss: 1.498821355963266

Epoch: 6| Step: 9
Training loss: 0.20515218377113342
Validation loss: 1.5123728962354763

Epoch: 6| Step: 10
Training loss: 0.1709395945072174
Validation loss: 1.5040080316605107

Epoch: 6| Step: 11
Training loss: 0.208647221326828
Validation loss: 1.5115490139171641

Epoch: 6| Step: 12
Training loss: 0.22335274517536163
Validation loss: 1.5128957379248835

Epoch: 6| Step: 13
Training loss: 0.1816287785768509
Validation loss: 1.4951323655343824

Epoch: 354| Step: 0
Training loss: 0.23452100157737732
Validation loss: 1.511477014069916

Epoch: 6| Step: 1
Training loss: 0.11791927367448807
Validation loss: 1.4900432876361314

Epoch: 6| Step: 2
Training loss: 0.09124378114938736
Validation loss: 1.5017711193330827

Epoch: 6| Step: 3
Training loss: 0.19600170850753784
Validation loss: 1.5048964203044932

Epoch: 6| Step: 4
Training loss: 0.1941797137260437
Validation loss: 1.5085328189275597

Epoch: 6| Step: 5
Training loss: 0.1391158103942871
Validation loss: 1.5144830557607836

Epoch: 6| Step: 6
Training loss: 0.17948171496391296
Validation loss: 1.5100227517466391

Epoch: 6| Step: 7
Training loss: 0.23445385694503784
Validation loss: 1.5357156902231195

Epoch: 6| Step: 8
Training loss: 0.20922836661338806
Validation loss: 1.5309959893585534

Epoch: 6| Step: 9
Training loss: 0.31313037872314453
Validation loss: 1.5413430288273802

Epoch: 6| Step: 10
Training loss: 0.23421794176101685
Validation loss: 1.5245438826981412

Epoch: 6| Step: 11
Training loss: 0.2560773491859436
Validation loss: 1.5271532163825086

Epoch: 6| Step: 12
Training loss: 0.24135306477546692
Validation loss: 1.5309762595802225

Epoch: 6| Step: 13
Training loss: 0.2155541330575943
Validation loss: 1.5249732719954623

Epoch: 355| Step: 0
Training loss: 0.3319196403026581
Validation loss: 1.540118892346659

Epoch: 6| Step: 1
Training loss: 0.26421624422073364
Validation loss: 1.5235744432736469

Epoch: 6| Step: 2
Training loss: 0.21125689148902893
Validation loss: 1.53213712733279

Epoch: 6| Step: 3
Training loss: 0.2711370587348938
Validation loss: 1.5031690148897068

Epoch: 6| Step: 4
Training loss: 0.20227882266044617
Validation loss: 1.5406531813324138

Epoch: 6| Step: 5
Training loss: 0.12813818454742432
Validation loss: 1.5520778791878813

Epoch: 6| Step: 6
Training loss: 0.16107821464538574
Validation loss: 1.5410659236292685

Epoch: 6| Step: 7
Training loss: 0.19702763855457306
Validation loss: 1.612082835166685

Epoch: 6| Step: 8
Training loss: 0.2740057110786438
Validation loss: 1.5990502347228348

Epoch: 6| Step: 9
Training loss: 0.12550291419029236
Validation loss: 1.62656073288251

Epoch: 6| Step: 10
Training loss: 0.11165821552276611
Validation loss: 1.5819677883578884

Epoch: 6| Step: 11
Training loss: 0.12223979830741882
Validation loss: 1.5582571753891565

Epoch: 6| Step: 12
Training loss: 0.10723093152046204
Validation loss: 1.5808805996371853

Epoch: 6| Step: 13
Training loss: 0.1661732792854309
Validation loss: 1.5864031750668761

Epoch: 356| Step: 0
Training loss: 0.1592271327972412
Validation loss: 1.5555703338756357

Epoch: 6| Step: 1
Training loss: 0.18855227530002594
Validation loss: 1.5909140007470244

Epoch: 6| Step: 2
Training loss: 0.11332657933235168
Validation loss: 1.5985691534575595

Epoch: 6| Step: 3
Training loss: 0.1428055763244629
Validation loss: 1.5673594692701935

Epoch: 6| Step: 4
Training loss: 0.18011713027954102
Validation loss: 1.5898362987784929

Epoch: 6| Step: 5
Training loss: 0.07174675166606903
Validation loss: 1.5791735867018342

Epoch: 6| Step: 6
Training loss: 0.22193829715251923
Validation loss: 1.55907944966388

Epoch: 6| Step: 7
Training loss: 0.10730929672718048
Validation loss: 1.5528446762792525

Epoch: 6| Step: 8
Training loss: 0.18186244368553162
Validation loss: 1.5614240566889446

Epoch: 6| Step: 9
Training loss: 0.1842239797115326
Validation loss: 1.5694169741804882

Epoch: 6| Step: 10
Training loss: 0.20267103612422943
Validation loss: 1.5584016435889787

Epoch: 6| Step: 11
Training loss: 0.19834870100021362
Validation loss: 1.5618555494534072

Epoch: 6| Step: 12
Training loss: 0.29594355821609497
Validation loss: 1.5581079913723854

Epoch: 6| Step: 13
Training loss: 0.2964731752872467
Validation loss: 1.5389700102549728

Epoch: 357| Step: 0
Training loss: 0.3632919192314148
Validation loss: 1.5632246745529996

Epoch: 6| Step: 1
Training loss: 0.26065540313720703
Validation loss: 1.511455922998408

Epoch: 6| Step: 2
Training loss: 0.15119445323944092
Validation loss: 1.5335507110882831

Epoch: 6| Step: 3
Training loss: 0.2506656050682068
Validation loss: 1.512410597134662

Epoch: 6| Step: 4
Training loss: 0.195468008518219
Validation loss: 1.5517270513760146

Epoch: 6| Step: 5
Training loss: 0.20137852430343628
Validation loss: 1.538942144763085

Epoch: 6| Step: 6
Training loss: 0.153749018907547
Validation loss: 1.5328373191177205

Epoch: 6| Step: 7
Training loss: 0.12378473579883575
Validation loss: 1.5332612145331599

Epoch: 6| Step: 8
Training loss: 0.2696073055267334
Validation loss: 1.5496227138785905

Epoch: 6| Step: 9
Training loss: 0.16593483090400696
Validation loss: 1.5182578525235575

Epoch: 6| Step: 10
Training loss: 0.15750926733016968
Validation loss: 1.499757082231583

Epoch: 6| Step: 11
Training loss: 0.21852317452430725
Validation loss: 1.4855106107650264

Epoch: 6| Step: 12
Training loss: 0.1313689649105072
Validation loss: 1.4917363735937303

Epoch: 6| Step: 13
Training loss: 0.20914119482040405
Validation loss: 1.4865983557957474

Epoch: 358| Step: 0
Training loss: 0.24438197910785675
Validation loss: 1.4977356631268737

Epoch: 6| Step: 1
Training loss: 0.2100527286529541
Validation loss: 1.4857491754716443

Epoch: 6| Step: 2
Training loss: 0.2626529335975647
Validation loss: 1.5132711613050072

Epoch: 6| Step: 3
Training loss: 0.1026330515742302
Validation loss: 1.5316512776959328

Epoch: 6| Step: 4
Training loss: 0.22012749314308167
Validation loss: 1.5284743911476546

Epoch: 6| Step: 5
Training loss: 0.10204549878835678
Validation loss: 1.5322801259256178

Epoch: 6| Step: 6
Training loss: 0.20058134198188782
Validation loss: 1.5179295860311037

Epoch: 6| Step: 7
Training loss: 0.1592170000076294
Validation loss: 1.5206628281583068

Epoch: 6| Step: 8
Training loss: 0.15169021487236023
Validation loss: 1.4876762320918422

Epoch: 6| Step: 9
Training loss: 0.08444952219724655
Validation loss: 1.50698269567182

Epoch: 6| Step: 10
Training loss: 0.16058024764060974
Validation loss: 1.4801184708072292

Epoch: 6| Step: 11
Training loss: 0.31524166464805603
Validation loss: 1.5001202168003205

Epoch: 6| Step: 12
Training loss: 0.19183464348316193
Validation loss: 1.487030952848414

Epoch: 6| Step: 13
Training loss: 0.12622588872909546
Validation loss: 1.4899668623042364

Epoch: 359| Step: 0
Training loss: 0.15876740217208862
Validation loss: 1.4753869666207222

Epoch: 6| Step: 1
Training loss: 0.2288525104522705
Validation loss: 1.4667047954374743

Epoch: 6| Step: 2
Training loss: 0.16634626686573029
Validation loss: 1.4854983257991012

Epoch: 6| Step: 3
Training loss: 0.1752607673406601
Validation loss: 1.4945416931183106

Epoch: 6| Step: 4
Training loss: 0.2020256221294403
Validation loss: 1.5048761816434963

Epoch: 6| Step: 5
Training loss: 0.28289923071861267
Validation loss: 1.487859332433311

Epoch: 6| Step: 6
Training loss: 0.12489780783653259
Validation loss: 1.48505760136471

Epoch: 6| Step: 7
Training loss: 0.18296882510185242
Validation loss: 1.4871604032413934

Epoch: 6| Step: 8
Training loss: 0.14349879324436188
Validation loss: 1.5313950661690003

Epoch: 6| Step: 9
Training loss: 0.16093875467777252
Validation loss: 1.5335723136060981

Epoch: 6| Step: 10
Training loss: 0.13549666106700897
Validation loss: 1.5385101238886516

Epoch: 6| Step: 11
Training loss: 0.2695777416229248
Validation loss: 1.5402717756968674

Epoch: 6| Step: 12
Training loss: 0.21893168985843658
Validation loss: 1.5535588392647364

Epoch: 6| Step: 13
Training loss: 0.3437771499156952
Validation loss: 1.5030859792104332

Epoch: 360| Step: 0
Training loss: 0.16123731434345245
Validation loss: 1.5408650598218363

Epoch: 6| Step: 1
Training loss: 0.1250574141740799
Validation loss: 1.5512758416514243

Epoch: 6| Step: 2
Training loss: 0.2718135416507721
Validation loss: 1.55738845691886

Epoch: 6| Step: 3
Training loss: 0.312945693731308
Validation loss: 1.574330408086059

Epoch: 6| Step: 4
Training loss: 0.15729951858520508
Validation loss: 1.540987087834266

Epoch: 6| Step: 5
Training loss: 0.0908997654914856
Validation loss: 1.5612587262225408

Epoch: 6| Step: 6
Training loss: 0.18407216668128967
Validation loss: 1.5097835371571202

Epoch: 6| Step: 7
Training loss: 0.15752337872982025
Validation loss: 1.5213873488928682

Epoch: 6| Step: 8
Training loss: 0.16789546608924866
Validation loss: 1.5237909581071587

Epoch: 6| Step: 9
Training loss: 0.22211813926696777
Validation loss: 1.4935274803510277

Epoch: 6| Step: 10
Training loss: 0.10827238112688065
Validation loss: 1.5341833817061556

Epoch: 6| Step: 11
Training loss: 0.2721339166164398
Validation loss: 1.5244364212918025

Epoch: 6| Step: 12
Training loss: 0.20492146909236908
Validation loss: 1.4794748649802258

Epoch: 6| Step: 13
Training loss: 0.13027256727218628
Validation loss: 1.5131782062592045

Epoch: 361| Step: 0
Training loss: 0.25021669268608093
Validation loss: 1.4757742452365097

Epoch: 6| Step: 1
Training loss: 0.17723941802978516
Validation loss: 1.518789134999757

Epoch: 6| Step: 2
Training loss: 0.2657124698162079
Validation loss: 1.5350952097164687

Epoch: 6| Step: 3
Training loss: 0.1669001430273056
Validation loss: 1.4988737003777617

Epoch: 6| Step: 4
Training loss: 0.16915318369865417
Validation loss: 1.526803820363937

Epoch: 6| Step: 5
Training loss: 0.2276977300643921
Validation loss: 1.5274341555051907

Epoch: 6| Step: 6
Training loss: 0.20727914571762085
Validation loss: 1.4980064527962798

Epoch: 6| Step: 7
Training loss: 0.13802669942378998
Validation loss: 1.5214571311909666

Epoch: 6| Step: 8
Training loss: 0.1414368450641632
Validation loss: 1.5169927099699616

Epoch: 6| Step: 9
Training loss: 0.16156655550003052
Validation loss: 1.5477144115714616

Epoch: 6| Step: 10
Training loss: 0.09831763803958893
Validation loss: 1.5626643729466263

Epoch: 6| Step: 11
Training loss: 0.11113280802965164
Validation loss: 1.5378160181865896

Epoch: 6| Step: 12
Training loss: 0.3009558618068695
Validation loss: 1.5299551371605165

Epoch: 6| Step: 13
Training loss: 0.23280280828475952
Validation loss: 1.558917212229903

Epoch: 362| Step: 0
Training loss: 0.13483744859695435
Validation loss: 1.5497281435997254

Epoch: 6| Step: 1
Training loss: 0.15382836759090424
Validation loss: 1.554263707130186

Epoch: 6| Step: 2
Training loss: 0.10703819990158081
Validation loss: 1.527434374696465

Epoch: 6| Step: 3
Training loss: 0.19565002620220184
Validation loss: 1.5490259573023806

Epoch: 6| Step: 4
Training loss: 0.1345449984073639
Validation loss: 1.5508209223388343

Epoch: 6| Step: 5
Training loss: 0.17402434349060059
Validation loss: 1.5495809342271538

Epoch: 6| Step: 6
Training loss: 0.27233389019966125
Validation loss: 1.5568874959022767

Epoch: 6| Step: 7
Training loss: 0.10973061621189117
Validation loss: 1.5439045095956454

Epoch: 6| Step: 8
Training loss: 0.13766992092132568
Validation loss: 1.5676715232992684

Epoch: 6| Step: 9
Training loss: 0.2605501115322113
Validation loss: 1.5635014503232894

Epoch: 6| Step: 10
Training loss: 0.26559901237487793
Validation loss: 1.549046460018363

Epoch: 6| Step: 11
Training loss: 0.24119658768177032
Validation loss: 1.5498903169426868

Epoch: 6| Step: 12
Training loss: 0.28004157543182373
Validation loss: 1.533778106012652

Epoch: 6| Step: 13
Training loss: 0.11143627762794495
Validation loss: 1.4976888433579476

Epoch: 363| Step: 0
Training loss: 0.24520137906074524
Validation loss: 1.5095469336355887

Epoch: 6| Step: 1
Training loss: 0.27933210134506226
Validation loss: 1.506324956493993

Epoch: 6| Step: 2
Training loss: 0.286184161901474
Validation loss: 1.4956724374525008

Epoch: 6| Step: 3
Training loss: 0.1036277487874031
Validation loss: 1.5091490360998339

Epoch: 6| Step: 4
Training loss: 0.19773845374584198
Validation loss: 1.512856452695785

Epoch: 6| Step: 5
Training loss: 0.23766183853149414
Validation loss: 1.5276947175302813

Epoch: 6| Step: 6
Training loss: 0.1993357241153717
Validation loss: 1.5329757890393656

Epoch: 6| Step: 7
Training loss: 0.14756162464618683
Validation loss: 1.5327246112208213

Epoch: 6| Step: 8
Training loss: 0.1319299042224884
Validation loss: 1.5536164535630135

Epoch: 6| Step: 9
Training loss: 0.10887248069047928
Validation loss: 1.514712445838477

Epoch: 6| Step: 10
Training loss: 0.1814274787902832
Validation loss: 1.508112407499744

Epoch: 6| Step: 11
Training loss: 0.1830909103155136
Validation loss: 1.4962404748444915

Epoch: 6| Step: 12
Training loss: 0.14666837453842163
Validation loss: 1.4906804433432959

Epoch: 6| Step: 13
Training loss: 0.15411770343780518
Validation loss: 1.4914444056890344

Epoch: 364| Step: 0
Training loss: 0.2216726541519165
Validation loss: 1.4992959358358895

Epoch: 6| Step: 1
Training loss: 0.30364173650741577
Validation loss: 1.5058041464897893

Epoch: 6| Step: 2
Training loss: 0.21472956240177155
Validation loss: 1.4829733230734383

Epoch: 6| Step: 3
Training loss: 0.20329102873802185
Validation loss: 1.5072619761190107

Epoch: 6| Step: 4
Training loss: 0.19116510450839996
Validation loss: 1.489680547868052

Epoch: 6| Step: 5
Training loss: 0.18376323580741882
Validation loss: 1.4964798752979567

Epoch: 6| Step: 6
Training loss: 0.1289234161376953
Validation loss: 1.5140341494673042

Epoch: 6| Step: 7
Training loss: 0.1758587658405304
Validation loss: 1.4985532094073553

Epoch: 6| Step: 8
Training loss: 0.15158192813396454
Validation loss: 1.5116090877081758

Epoch: 6| Step: 9
Training loss: 0.16547304391860962
Validation loss: 1.5264063317288634

Epoch: 6| Step: 10
Training loss: 0.09012673795223236
Validation loss: 1.5086684842263498

Epoch: 6| Step: 11
Training loss: 0.0987158790230751
Validation loss: 1.532522116937945

Epoch: 6| Step: 12
Training loss: 0.1859728991985321
Validation loss: 1.5811366996457499

Epoch: 6| Step: 13
Training loss: 0.2489369958639145
Validation loss: 1.5794538310779038

Epoch: 365| Step: 0
Training loss: 0.1981683075428009
Validation loss: 1.5757653046679754

Epoch: 6| Step: 1
Training loss: 0.1563681960105896
Validation loss: 1.5787536585202782

Epoch: 6| Step: 2
Training loss: 0.13902346789836884
Validation loss: 1.5737095750788206

Epoch: 6| Step: 3
Training loss: 0.23840546607971191
Validation loss: 1.5926468359526766

Epoch: 6| Step: 4
Training loss: 0.19218285381793976
Validation loss: 1.5855411444940875

Epoch: 6| Step: 5
Training loss: 0.2108633667230606
Validation loss: 1.56338841812585

Epoch: 6| Step: 6
Training loss: 0.0700029730796814
Validation loss: 1.563525479326966

Epoch: 6| Step: 7
Training loss: 0.1472053825855255
Validation loss: 1.559950167132962

Epoch: 6| Step: 8
Training loss: 0.14506004750728607
Validation loss: 1.5197620379027499

Epoch: 6| Step: 9
Training loss: 0.2947530448436737
Validation loss: 1.5082507043756463

Epoch: 6| Step: 10
Training loss: 0.15801186859607697
Validation loss: 1.5205763193868822

Epoch: 6| Step: 11
Training loss: 0.15041494369506836
Validation loss: 1.525917863333097

Epoch: 6| Step: 12
Training loss: 0.1152525395154953
Validation loss: 1.562985570200028

Epoch: 6| Step: 13
Training loss: 0.4401719570159912
Validation loss: 1.503220473566363

Epoch: 366| Step: 0
Training loss: 0.21723419427871704
Validation loss: 1.554837134576613

Epoch: 6| Step: 1
Training loss: 0.20858505368232727
Validation loss: 1.5520853163093649

Epoch: 6| Step: 2
Training loss: 0.26527148485183716
Validation loss: 1.5619790451501006

Epoch: 6| Step: 3
Training loss: 0.22723457217216492
Validation loss: 1.5108042814398324

Epoch: 6| Step: 4
Training loss: 0.31385353207588196
Validation loss: 1.5233737114937074

Epoch: 6| Step: 5
Training loss: 0.10967548191547394
Validation loss: 1.5034410222884147

Epoch: 6| Step: 6
Training loss: 0.14529937505722046
Validation loss: 1.4816269592572284

Epoch: 6| Step: 7
Training loss: 0.16851571202278137
Validation loss: 1.4687175750732422

Epoch: 6| Step: 8
Training loss: 0.1328343003988266
Validation loss: 1.4638477294675765

Epoch: 6| Step: 9
Training loss: 0.18247854709625244
Validation loss: 1.441253169890373

Epoch: 6| Step: 10
Training loss: 0.1359570175409317
Validation loss: 1.447438092641933

Epoch: 6| Step: 11
Training loss: 0.2192414402961731
Validation loss: 1.425983763510181

Epoch: 6| Step: 12
Training loss: 0.2598193883895874
Validation loss: 1.4224622454694522

Epoch: 6| Step: 13
Training loss: 0.22867679595947266
Validation loss: 1.4382911811592758

Epoch: 367| Step: 0
Training loss: 0.19572663307189941
Validation loss: 1.4190343708120368

Epoch: 6| Step: 1
Training loss: 0.2676650881767273
Validation loss: 1.428169277406508

Epoch: 6| Step: 2
Training loss: 0.21879062056541443
Validation loss: 1.449253100220875

Epoch: 6| Step: 3
Training loss: 0.15569642186164856
Validation loss: 1.4404529281841811

Epoch: 6| Step: 4
Training loss: 0.2656325697898865
Validation loss: 1.5002850627386441

Epoch: 6| Step: 5
Training loss: 0.22699743509292603
Validation loss: 1.4677170348423783

Epoch: 6| Step: 6
Training loss: 0.16765108704566956
Validation loss: 1.4987844703018025

Epoch: 6| Step: 7
Training loss: 0.20830659568309784
Validation loss: 1.5086007605316818

Epoch: 6| Step: 8
Training loss: 0.11340118199586868
Validation loss: 1.5283693344362321

Epoch: 6| Step: 9
Training loss: 0.21883267164230347
Validation loss: 1.5379865015706708

Epoch: 6| Step: 10
Training loss: 0.1940404176712036
Validation loss: 1.5467472230234454

Epoch: 6| Step: 11
Training loss: 0.24144572019577026
Validation loss: 1.5655930285812707

Epoch: 6| Step: 12
Training loss: 0.2375432848930359
Validation loss: 1.533341924349467

Epoch: 6| Step: 13
Training loss: 0.20931397378444672
Validation loss: 1.5299640445299045

Epoch: 368| Step: 0
Training loss: 0.1904313862323761
Validation loss: 1.5510549622197305

Epoch: 6| Step: 1
Training loss: 0.15607868134975433
Validation loss: 1.5558542384896228

Epoch: 6| Step: 2
Training loss: 0.2989625334739685
Validation loss: 1.553378394854966

Epoch: 6| Step: 3
Training loss: 0.18308913707733154
Validation loss: 1.5472400637083157

Epoch: 6| Step: 4
Training loss: 0.175510436296463
Validation loss: 1.5289586872182868

Epoch: 6| Step: 5
Training loss: 0.2004164159297943
Validation loss: 1.530390642022574

Epoch: 6| Step: 6
Training loss: 0.20792904496192932
Validation loss: 1.5073520137417702

Epoch: 6| Step: 7
Training loss: 0.2148977518081665
Validation loss: 1.4890781730733893

Epoch: 6| Step: 8
Training loss: 0.12547537684440613
Validation loss: 1.4758516665427917

Epoch: 6| Step: 9
Training loss: 0.23296280205249786
Validation loss: 1.4796824506534043

Epoch: 6| Step: 10
Training loss: 0.19416658580303192
Validation loss: 1.4949567837099875

Epoch: 6| Step: 11
Training loss: 0.15131402015686035
Validation loss: 1.4656301301012757

Epoch: 6| Step: 12
Training loss: 0.15721149742603302
Validation loss: 1.4661884102770077

Epoch: 6| Step: 13
Training loss: 0.2760726809501648
Validation loss: 1.477698524792989

Epoch: 369| Step: 0
Training loss: 0.2683747410774231
Validation loss: 1.4775627095212218

Epoch: 6| Step: 1
Training loss: 0.10984497517347336
Validation loss: 1.496705155218801

Epoch: 6| Step: 2
Training loss: 0.14411264657974243
Validation loss: 1.5265352802891885

Epoch: 6| Step: 3
Training loss: 0.21352733671665192
Validation loss: 1.531119465827942

Epoch: 6| Step: 4
Training loss: 0.22553327679634094
Validation loss: 1.503248691558838

Epoch: 6| Step: 5
Training loss: 0.221023291349411
Validation loss: 1.5426531773741528

Epoch: 6| Step: 6
Training loss: 0.16563019156455994
Validation loss: 1.5217271492045412

Epoch: 6| Step: 7
Training loss: 0.19291624426841736
Validation loss: 1.5523881835322226

Epoch: 6| Step: 8
Training loss: 0.14141348004341125
Validation loss: 1.5277587457369732

Epoch: 6| Step: 9
Training loss: 0.18086275458335876
Validation loss: 1.5211649812677854

Epoch: 6| Step: 10
Training loss: 0.16739922761917114
Validation loss: 1.532835240005165

Epoch: 6| Step: 11
Training loss: 0.2880491316318512
Validation loss: 1.5120877944013125

Epoch: 6| Step: 12
Training loss: 0.20852315425872803
Validation loss: 1.5166007857168875

Epoch: 6| Step: 13
Training loss: 0.1039171889424324
Validation loss: 1.5201901338433708

Epoch: 370| Step: 0
Training loss: 0.2589302361011505
Validation loss: 1.5397256766596148

Epoch: 6| Step: 1
Training loss: 0.1797620803117752
Validation loss: 1.5122176665131764

Epoch: 6| Step: 2
Training loss: 0.1639854609966278
Validation loss: 1.5273515908948836

Epoch: 6| Step: 3
Training loss: 0.11513788253068924
Validation loss: 1.5180791911258493

Epoch: 6| Step: 4
Training loss: 0.1418389230966568
Validation loss: 1.5387560590620963

Epoch: 6| Step: 5
Training loss: 0.2244090437889099
Validation loss: 1.5034651820377638

Epoch: 6| Step: 6
Training loss: 0.1718502789735794
Validation loss: 1.54793898008203

Epoch: 6| Step: 7
Training loss: 0.1255595088005066
Validation loss: 1.5479919654066845

Epoch: 6| Step: 8
Training loss: 0.21388019621372223
Validation loss: 1.5205730776632986

Epoch: 6| Step: 9
Training loss: 0.18665967881679535
Validation loss: 1.5483578911391638

Epoch: 6| Step: 10
Training loss: 0.1913478523492813
Validation loss: 1.5181886284582076

Epoch: 6| Step: 11
Training loss: 0.1655256152153015
Validation loss: 1.550640119019375

Epoch: 6| Step: 12
Training loss: 0.2198270857334137
Validation loss: 1.5127863486607869

Epoch: 6| Step: 13
Training loss: 0.25247764587402344
Validation loss: 1.5102061251158356

Epoch: 371| Step: 0
Training loss: 0.23525574803352356
Validation loss: 1.48578062429223

Epoch: 6| Step: 1
Training loss: 0.20941060781478882
Validation loss: 1.4858669311769548

Epoch: 6| Step: 2
Training loss: 0.1157476082444191
Validation loss: 1.4923485978957145

Epoch: 6| Step: 3
Training loss: 0.3147440254688263
Validation loss: 1.4955692521987423

Epoch: 6| Step: 4
Training loss: 0.1563766747713089
Validation loss: 1.5078365905310518

Epoch: 6| Step: 5
Training loss: 0.21904665231704712
Validation loss: 1.4929191681646532

Epoch: 6| Step: 6
Training loss: 0.17444536089897156
Validation loss: 1.4779820519108926

Epoch: 6| Step: 7
Training loss: 0.2690447270870209
Validation loss: 1.475865243583597

Epoch: 6| Step: 8
Training loss: 0.20505335927009583
Validation loss: 1.4957062890452724

Epoch: 6| Step: 9
Training loss: 0.23552961647510529
Validation loss: 1.465312316853513

Epoch: 6| Step: 10
Training loss: 0.11823900789022446
Validation loss: 1.5037998281499392

Epoch: 6| Step: 11
Training loss: 0.08603620529174805
Validation loss: 1.4803524658244143

Epoch: 6| Step: 12
Training loss: 0.1838870644569397
Validation loss: 1.4972088849672707

Epoch: 6| Step: 13
Training loss: 0.1274574100971222
Validation loss: 1.5030228630188973

Epoch: 372| Step: 0
Training loss: 0.1320117563009262
Validation loss: 1.5099906857295702

Epoch: 6| Step: 1
Training loss: 0.18452763557434082
Validation loss: 1.5443877532917967

Epoch: 6| Step: 2
Training loss: 0.17192265391349792
Validation loss: 1.4987683091112363

Epoch: 6| Step: 3
Training loss: 0.17786899209022522
Validation loss: 1.5135108322225592

Epoch: 6| Step: 4
Training loss: 0.19090399146080017
Validation loss: 1.5281351157414016

Epoch: 6| Step: 5
Training loss: 0.08302649855613708
Validation loss: 1.4899300593201832

Epoch: 6| Step: 6
Training loss: 0.20319178700447083
Validation loss: 1.5130942265192668

Epoch: 6| Step: 7
Training loss: 0.19793817400932312
Validation loss: 1.4651750608157086

Epoch: 6| Step: 8
Training loss: 0.22448214888572693
Validation loss: 1.525280532016549

Epoch: 6| Step: 9
Training loss: 0.09707844257354736
Validation loss: 1.5049109548650763

Epoch: 6| Step: 10
Training loss: 0.22964462637901306
Validation loss: 1.4865670345162834

Epoch: 6| Step: 11
Training loss: 0.18706510961055756
Validation loss: 1.4770237624004323

Epoch: 6| Step: 12
Training loss: 0.11589116603136063
Validation loss: 1.4714462487928328

Epoch: 6| Step: 13
Training loss: 0.11601117253303528
Validation loss: 1.4829705287051458

Epoch: 373| Step: 0
Training loss: 0.201300710439682
Validation loss: 1.4779162650467248

Epoch: 6| Step: 1
Training loss: 0.19454169273376465
Validation loss: 1.4640172168772707

Epoch: 6| Step: 2
Training loss: 0.17261984944343567
Validation loss: 1.4932910088569886

Epoch: 6| Step: 3
Training loss: 0.17642927169799805
Validation loss: 1.4827304988779046

Epoch: 6| Step: 4
Training loss: 0.10033798217773438
Validation loss: 1.480370294663214

Epoch: 6| Step: 5
Training loss: 0.1529172658920288
Validation loss: 1.4659034000929965

Epoch: 6| Step: 6
Training loss: 0.15382474660873413
Validation loss: 1.4512873067650744

Epoch: 6| Step: 7
Training loss: 0.26593708992004395
Validation loss: 1.4955297522647406

Epoch: 6| Step: 8
Training loss: 0.1533929407596588
Validation loss: 1.4749508929508988

Epoch: 6| Step: 9
Training loss: 0.31595128774642944
Validation loss: 1.4929863176038187

Epoch: 6| Step: 10
Training loss: 0.1294066458940506
Validation loss: 1.4885614533578195

Epoch: 6| Step: 11
Training loss: 0.20455268025398254
Validation loss: 1.5095617219965944

Epoch: 6| Step: 12
Training loss: 0.37794482707977295
Validation loss: 1.5198080975522277

Epoch: 6| Step: 13
Training loss: 0.14827367663383484
Validation loss: 1.5274837504151046

Epoch: 374| Step: 0
Training loss: 0.15098997950553894
Validation loss: 1.563983145580497

Epoch: 6| Step: 1
Training loss: 0.23050323128700256
Validation loss: 1.5854524675235953

Epoch: 6| Step: 2
Training loss: 0.23175765573978424
Validation loss: 1.5663082381730438

Epoch: 6| Step: 3
Training loss: 0.21417835354804993
Validation loss: 1.587570458330134

Epoch: 6| Step: 4
Training loss: 0.11519365012645721
Validation loss: 1.5334993985391432

Epoch: 6| Step: 5
Training loss: 0.17599043250083923
Validation loss: 1.5698638731433499

Epoch: 6| Step: 6
Training loss: 0.27740293741226196
Validation loss: 1.556740101306669

Epoch: 6| Step: 7
Training loss: 0.19374866783618927
Validation loss: 1.559895666696692

Epoch: 6| Step: 8
Training loss: 0.1291169822216034
Validation loss: 1.564001044919414

Epoch: 6| Step: 9
Training loss: 0.1707896590232849
Validation loss: 1.5547916043189265

Epoch: 6| Step: 10
Training loss: 0.1980711668729782
Validation loss: 1.5569323044951244

Epoch: 6| Step: 11
Training loss: 0.12552940845489502
Validation loss: 1.5498394632852206

Epoch: 6| Step: 12
Training loss: 0.09792204201221466
Validation loss: 1.5441547106671076

Epoch: 6| Step: 13
Training loss: 0.15841984748840332
Validation loss: 1.541776321267569

Epoch: 375| Step: 0
Training loss: 0.19074097275733948
Validation loss: 1.5551209065221971

Epoch: 6| Step: 1
Training loss: 0.16666123270988464
Validation loss: 1.501705704196807

Epoch: 6| Step: 2
Training loss: 0.1649429202079773
Validation loss: 1.4987156955144738

Epoch: 6| Step: 3
Training loss: 0.13035303354263306
Validation loss: 1.5052414446748712

Epoch: 6| Step: 4
Training loss: 0.1659563183784485
Validation loss: 1.4964911655713153

Epoch: 6| Step: 5
Training loss: 0.22066254913806915
Validation loss: 1.4858664915125857

Epoch: 6| Step: 6
Training loss: 0.21401283144950867
Validation loss: 1.4699277749625586

Epoch: 6| Step: 7
Training loss: 0.17164814472198486
Validation loss: 1.5205566549813876

Epoch: 6| Step: 8
Training loss: 0.12569452822208405
Validation loss: 1.486038851481612

Epoch: 6| Step: 9
Training loss: 0.20948299765586853
Validation loss: 1.4445778131484985

Epoch: 6| Step: 10
Training loss: 0.09110189974308014
Validation loss: 1.4624360056333645

Epoch: 6| Step: 11
Training loss: 0.17636238038539886
Validation loss: 1.4514788478933356

Epoch: 6| Step: 12
Training loss: 0.1256573498249054
Validation loss: 1.4811241729285127

Epoch: 6| Step: 13
Training loss: 0.1505177617073059
Validation loss: 1.474808072531095

Epoch: 376| Step: 0
Training loss: 0.1687982976436615
Validation loss: 1.472179474369172

Epoch: 6| Step: 1
Training loss: 0.21886521577835083
Validation loss: 1.4829027370740009

Epoch: 6| Step: 2
Training loss: 0.16383472084999084
Validation loss: 1.4565851303838915

Epoch: 6| Step: 3
Training loss: 0.11753441393375397
Validation loss: 1.4545246170413109

Epoch: 6| Step: 4
Training loss: 0.17764385044574738
Validation loss: 1.4663522576773038

Epoch: 6| Step: 5
Training loss: 0.1573203057050705
Validation loss: 1.4563102542713124

Epoch: 6| Step: 6
Training loss: 0.18348662555217743
Validation loss: 1.486655455763622

Epoch: 6| Step: 7
Training loss: 0.22067475318908691
Validation loss: 1.4951090530682636

Epoch: 6| Step: 8
Training loss: 0.16942575573921204
Validation loss: 1.5072185929103563

Epoch: 6| Step: 9
Training loss: 0.2465912401676178
Validation loss: 1.4953412445642615

Epoch: 6| Step: 10
Training loss: 0.15817934274673462
Validation loss: 1.4876537771635159

Epoch: 6| Step: 11
Training loss: 0.16978201270103455
Validation loss: 1.4768497937469072

Epoch: 6| Step: 12
Training loss: 0.2000385969877243
Validation loss: 1.5143176586397233

Epoch: 6| Step: 13
Training loss: 0.2920660376548767
Validation loss: 1.509312770699942

Epoch: 377| Step: 0
Training loss: 0.13004624843597412
Validation loss: 1.4883541067441304

Epoch: 6| Step: 1
Training loss: 0.23323002457618713
Validation loss: 1.4824273663182412

Epoch: 6| Step: 2
Training loss: 0.08710802346467972
Validation loss: 1.4922152975554108

Epoch: 6| Step: 3
Training loss: 0.18143638968467712
Validation loss: 1.528717916498902

Epoch: 6| Step: 4
Training loss: 0.21249452233314514
Validation loss: 1.5066361247852285

Epoch: 6| Step: 5
Training loss: 0.22277267277240753
Validation loss: 1.5079161736272997

Epoch: 6| Step: 6
Training loss: 0.16280001401901245
Validation loss: 1.487810214360555

Epoch: 6| Step: 7
Training loss: 0.12603767216205597
Validation loss: 1.4810927965307747

Epoch: 6| Step: 8
Training loss: 0.11855069547891617
Validation loss: 1.4525817466038529

Epoch: 6| Step: 9
Training loss: 0.188669353723526
Validation loss: 1.4724233458119054

Epoch: 6| Step: 10
Training loss: 0.18770866096019745
Validation loss: 1.4975404008742301

Epoch: 6| Step: 11
Training loss: 0.21026907861232758
Validation loss: 1.4749411600892262

Epoch: 6| Step: 12
Training loss: 0.1454891562461853
Validation loss: 1.5039072998108403

Epoch: 6| Step: 13
Training loss: 0.241461381316185
Validation loss: 1.5017161433414747

Epoch: 378| Step: 0
Training loss: 0.1295200139284134
Validation loss: 1.503335370812365

Epoch: 6| Step: 1
Training loss: 0.24985511600971222
Validation loss: 1.4969388041445004

Epoch: 6| Step: 2
Training loss: 0.16940119862556458
Validation loss: 1.5004685463443879

Epoch: 6| Step: 3
Training loss: 0.1191701665520668
Validation loss: 1.5166637647536494

Epoch: 6| Step: 4
Training loss: 0.15283572673797607
Validation loss: 1.533634998465097

Epoch: 6| Step: 5
Training loss: 0.118843212723732
Validation loss: 1.50644419141995

Epoch: 6| Step: 6
Training loss: 0.2570934593677521
Validation loss: 1.526572879924569

Epoch: 6| Step: 7
Training loss: 0.15351331233978271
Validation loss: 1.539588676985874

Epoch: 6| Step: 8
Training loss: 0.13937056064605713
Validation loss: 1.5151367008045156

Epoch: 6| Step: 9
Training loss: 0.2604755461215973
Validation loss: 1.5305735154818463

Epoch: 6| Step: 10
Training loss: 0.13122804462909698
Validation loss: 1.540080847278718

Epoch: 6| Step: 11
Training loss: 0.1905396282672882
Validation loss: 1.540400508911379

Epoch: 6| Step: 12
Training loss: 0.11760805547237396
Validation loss: 1.5550733779066352

Epoch: 6| Step: 13
Training loss: 0.2481401562690735
Validation loss: 1.5611830654964651

Epoch: 379| Step: 0
Training loss: 0.13330227136611938
Validation loss: 1.5392546038473807

Epoch: 6| Step: 1
Training loss: 0.18143436312675476
Validation loss: 1.5574282856397732

Epoch: 6| Step: 2
Training loss: 0.10870860517024994
Validation loss: 1.5457239189455587

Epoch: 6| Step: 3
Training loss: 0.2195817083120346
Validation loss: 1.5670084837944276

Epoch: 6| Step: 4
Training loss: 0.11598305404186249
Validation loss: 1.534854600506444

Epoch: 6| Step: 5
Training loss: 0.0765814259648323
Validation loss: 1.508097835766372

Epoch: 6| Step: 6
Training loss: 0.20673930644989014
Validation loss: 1.5245851688487555

Epoch: 6| Step: 7
Training loss: 0.1597198247909546
Validation loss: 1.5007875645032493

Epoch: 6| Step: 8
Training loss: 0.11541423946619034
Validation loss: 1.4999763555424188

Epoch: 6| Step: 9
Training loss: 0.1517581194639206
Validation loss: 1.511939719159116

Epoch: 6| Step: 10
Training loss: 0.19592440128326416
Validation loss: 1.4435505982368224

Epoch: 6| Step: 11
Training loss: 0.221632182598114
Validation loss: 1.4506190079514698

Epoch: 6| Step: 12
Training loss: 0.20428676903247833
Validation loss: 1.4567400255510885

Epoch: 6| Step: 13
Training loss: 0.14962448179721832
Validation loss: 1.4498301488096996

Epoch: 380| Step: 0
Training loss: 0.16863372921943665
Validation loss: 1.4379412666443856

Epoch: 6| Step: 1
Training loss: 0.11675133556127548
Validation loss: 1.4545565702581917

Epoch: 6| Step: 2
Training loss: 0.2129771113395691
Validation loss: 1.473538589733903

Epoch: 6| Step: 3
Training loss: 0.14092527329921722
Validation loss: 1.4568650120048112

Epoch: 6| Step: 4
Training loss: 0.16178405284881592
Validation loss: 1.446487606212657

Epoch: 6| Step: 5
Training loss: 0.17813149094581604
Validation loss: 1.4519755763392295

Epoch: 6| Step: 6
Training loss: 0.10238884389400482
Validation loss: 1.4581619603659517

Epoch: 6| Step: 7
Training loss: 0.18420079350471497
Validation loss: 1.4828558403958556

Epoch: 6| Step: 8
Training loss: 0.24248215556144714
Validation loss: 1.4777012050792735

Epoch: 6| Step: 9
Training loss: 0.1387057602405548
Validation loss: 1.4502867152613979

Epoch: 6| Step: 10
Training loss: 0.223690465092659
Validation loss: 1.4485266131739463

Epoch: 6| Step: 11
Training loss: 0.12543514370918274
Validation loss: 1.4689428216667586

Epoch: 6| Step: 12
Training loss: 0.17131531238555908
Validation loss: 1.5030129654433138

Epoch: 6| Step: 13
Training loss: 0.16554640233516693
Validation loss: 1.5031375654282109

Epoch: 381| Step: 0
Training loss: 0.19516943395137787
Validation loss: 1.4751582120054512

Epoch: 6| Step: 1
Training loss: 0.22112584114074707
Validation loss: 1.479614173212359

Epoch: 6| Step: 2
Training loss: 0.10418686270713806
Validation loss: 1.4964080766964984

Epoch: 6| Step: 3
Training loss: 0.1526697874069214
Validation loss: 1.4755531216180453

Epoch: 6| Step: 4
Training loss: 0.1813526153564453
Validation loss: 1.5396028821186354

Epoch: 6| Step: 5
Training loss: 0.19259805977344513
Validation loss: 1.4516279825600245

Epoch: 6| Step: 6
Training loss: 0.15849903225898743
Validation loss: 1.5141233667250602

Epoch: 6| Step: 7
Training loss: 0.1145540177822113
Validation loss: 1.5028288005500712

Epoch: 6| Step: 8
Training loss: 0.13955089449882507
Validation loss: 1.5160307102305914

Epoch: 6| Step: 9
Training loss: 0.1108788549900055
Validation loss: 1.5362395906961093

Epoch: 6| Step: 10
Training loss: 0.14760088920593262
Validation loss: 1.514557384675549

Epoch: 6| Step: 11
Training loss: 0.2372194230556488
Validation loss: 1.541800296434792

Epoch: 6| Step: 12
Training loss: 0.2997691333293915
Validation loss: 1.5133418319045857

Epoch: 6| Step: 13
Training loss: 0.13453751802444458
Validation loss: 1.5471670037956649

Epoch: 382| Step: 0
Training loss: 0.21041201055049896
Validation loss: 1.5082156119808074

Epoch: 6| Step: 1
Training loss: 0.15765562653541565
Validation loss: 1.501255791674378

Epoch: 6| Step: 2
Training loss: 0.1349855363368988
Validation loss: 1.4985721598389328

Epoch: 6| Step: 3
Training loss: 0.11751240491867065
Validation loss: 1.5006301454318467

Epoch: 6| Step: 4
Training loss: 0.1508796215057373
Validation loss: 1.4816850667358727

Epoch: 6| Step: 5
Training loss: 0.14844641089439392
Validation loss: 1.4813119724232664

Epoch: 6| Step: 6
Training loss: 0.2866223454475403
Validation loss: 1.4779735918967956

Epoch: 6| Step: 7
Training loss: 0.19005802273750305
Validation loss: 1.4923627979011946

Epoch: 6| Step: 8
Training loss: 0.2033507525920868
Validation loss: 1.4950698998666578

Epoch: 6| Step: 9
Training loss: 0.20976930856704712
Validation loss: 1.5124053596168436

Epoch: 6| Step: 10
Training loss: 0.13618484139442444
Validation loss: 1.494864357415066

Epoch: 6| Step: 11
Training loss: 0.16709358990192413
Validation loss: 1.51310021005651

Epoch: 6| Step: 12
Training loss: 0.12787699699401855
Validation loss: 1.5011675447546027

Epoch: 6| Step: 13
Training loss: 0.3373763859272003
Validation loss: 1.5372053198916937

Epoch: 383| Step: 0
Training loss: 0.21215583384037018
Validation loss: 1.5272667042670711

Epoch: 6| Step: 1
Training loss: 0.28076618909835815
Validation loss: 1.5457180738449097

Epoch: 6| Step: 2
Training loss: 0.1385805606842041
Validation loss: 1.537192249810824

Epoch: 6| Step: 3
Training loss: 0.11785299330949783
Validation loss: 1.5416616547492243

Epoch: 6| Step: 4
Training loss: 0.22305810451507568
Validation loss: 1.565815971743676

Epoch: 6| Step: 5
Training loss: 0.3167686462402344
Validation loss: 1.5873850276393275

Epoch: 6| Step: 6
Training loss: 0.1367921531200409
Validation loss: 1.5696072040065643

Epoch: 6| Step: 7
Training loss: 0.16995562613010406
Validation loss: 1.5629239607882757

Epoch: 6| Step: 8
Training loss: 0.13015463948249817
Validation loss: 1.5729702698287142

Epoch: 6| Step: 9
Training loss: 0.24379074573516846
Validation loss: 1.5787273260854906

Epoch: 6| Step: 10
Training loss: 0.2038804590702057
Validation loss: 1.5974730407038042

Epoch: 6| Step: 11
Training loss: 0.2077137529850006
Validation loss: 1.5752372600698983

Epoch: 6| Step: 12
Training loss: 0.1691267043352127
Validation loss: 1.5905358265804987

Epoch: 6| Step: 13
Training loss: 0.22606772184371948
Validation loss: 1.5475092075204337

Epoch: 384| Step: 0
Training loss: 0.15119655430316925
Validation loss: 1.5290613238529494

Epoch: 6| Step: 1
Training loss: 0.2378937005996704
Validation loss: 1.5081123011086577

Epoch: 6| Step: 2
Training loss: 0.12708337604999542
Validation loss: 1.5361989070010442

Epoch: 6| Step: 3
Training loss: 0.18187899887561798
Validation loss: 1.4975017693734938

Epoch: 6| Step: 4
Training loss: 0.20609059929847717
Validation loss: 1.5175679825967359

Epoch: 6| Step: 5
Training loss: 0.13020263612270355
Validation loss: 1.488723143454521

Epoch: 6| Step: 6
Training loss: 0.14435794949531555
Validation loss: 1.4921512411486717

Epoch: 6| Step: 7
Training loss: 0.18799030780792236
Validation loss: 1.5073391147839126

Epoch: 6| Step: 8
Training loss: 0.12926527857780457
Validation loss: 1.5258268239677593

Epoch: 6| Step: 9
Training loss: 0.3013850450515747
Validation loss: 1.5183388674131004

Epoch: 6| Step: 10
Training loss: 0.2398943305015564
Validation loss: 1.5110524354442474

Epoch: 6| Step: 11
Training loss: 0.17947719991207123
Validation loss: 1.5327895995109313

Epoch: 6| Step: 12
Training loss: 0.26254796981811523
Validation loss: 1.51457259731908

Epoch: 6| Step: 13
Training loss: 0.2561750113964081
Validation loss: 1.5169183413187664

Epoch: 385| Step: 0
Training loss: 0.23743465542793274
Validation loss: 1.4639623331767257

Epoch: 6| Step: 1
Training loss: 0.11357046663761139
Validation loss: 1.4750592375314364

Epoch: 6| Step: 2
Training loss: 0.1646207571029663
Validation loss: 1.4673628935249903

Epoch: 6| Step: 3
Training loss: 0.13966719806194305
Validation loss: 1.4457717493016233

Epoch: 6| Step: 4
Training loss: 0.13403189182281494
Validation loss: 1.4786930212410547

Epoch: 6| Step: 5
Training loss: 0.21465827524662018
Validation loss: 1.490520743913548

Epoch: 6| Step: 6
Training loss: 0.13806189596652985
Validation loss: 1.5143375063455233

Epoch: 6| Step: 7
Training loss: 0.28480517864227295
Validation loss: 1.5134394886673137

Epoch: 6| Step: 8
Training loss: 0.26898282766342163
Validation loss: 1.4952575173429263

Epoch: 6| Step: 9
Training loss: 0.0978773981332779
Validation loss: 1.508271445510208

Epoch: 6| Step: 10
Training loss: 0.22963953018188477
Validation loss: 1.5014415812748734

Epoch: 6| Step: 11
Training loss: 0.19255122542381287
Validation loss: 1.500688164464889

Epoch: 6| Step: 12
Training loss: 0.15595436096191406
Validation loss: 1.4874386966869395

Epoch: 6| Step: 13
Training loss: 0.17386765778064728
Validation loss: 1.543808432676459

Epoch: 386| Step: 0
Training loss: 0.24146747589111328
Validation loss: 1.5364656474000664

Epoch: 6| Step: 1
Training loss: 0.19794249534606934
Validation loss: 1.5055881264389201

Epoch: 6| Step: 2
Training loss: 0.13926531374454498
Validation loss: 1.5395220479657572

Epoch: 6| Step: 3
Training loss: 0.09410899877548218
Validation loss: 1.5511505565335673

Epoch: 6| Step: 4
Training loss: 0.1424957513809204
Validation loss: 1.5510831891849477

Epoch: 6| Step: 5
Training loss: 0.14830677211284637
Validation loss: 1.5236338966636247

Epoch: 6| Step: 6
Training loss: 0.0811120793223381
Validation loss: 1.4761870009924776

Epoch: 6| Step: 7
Training loss: 0.2354184091091156
Validation loss: 1.4819394106506019

Epoch: 6| Step: 8
Training loss: 0.2275150865316391
Validation loss: 1.517568580565914

Epoch: 6| Step: 9
Training loss: 0.14038777351379395
Validation loss: 1.4829940436988749

Epoch: 6| Step: 10
Training loss: 0.20592781901359558
Validation loss: 1.478525492452806

Epoch: 6| Step: 11
Training loss: 0.1730985790491104
Validation loss: 1.4707385186226136

Epoch: 6| Step: 12
Training loss: 0.1203237920999527
Validation loss: 1.479553880230073

Epoch: 6| Step: 13
Training loss: 0.203770712018013
Validation loss: 1.4756266840042607

Epoch: 387| Step: 0
Training loss: 0.13800862431526184
Validation loss: 1.4625837072249381

Epoch: 6| Step: 1
Training loss: 0.21174374222755432
Validation loss: 1.4785012211850894

Epoch: 6| Step: 2
Training loss: 0.1321788728237152
Validation loss: 1.4818259387887933

Epoch: 6| Step: 3
Training loss: 0.18470001220703125
Validation loss: 1.4951517940849386

Epoch: 6| Step: 4
Training loss: 0.15880805253982544
Validation loss: 1.482802015478893

Epoch: 6| Step: 5
Training loss: 0.2010481357574463
Validation loss: 1.5093552284343268

Epoch: 6| Step: 6
Training loss: 0.2154998481273651
Validation loss: 1.5233585155138405

Epoch: 6| Step: 7
Training loss: 0.14569386839866638
Validation loss: 1.494165297477476

Epoch: 6| Step: 8
Training loss: 0.13546377420425415
Validation loss: 1.515208149469027

Epoch: 6| Step: 9
Training loss: 0.1135149896144867
Validation loss: 1.4677770086514053

Epoch: 6| Step: 10
Training loss: 0.14346444606781006
Validation loss: 1.4817075139732772

Epoch: 6| Step: 11
Training loss: 0.1528576910495758
Validation loss: 1.5122710761203562

Epoch: 6| Step: 12
Training loss: 0.18807066977024078
Validation loss: 1.5069818842795588

Epoch: 6| Step: 13
Training loss: 0.20390206575393677
Validation loss: 1.5226412306549728

Epoch: 388| Step: 0
Training loss: 0.095082588493824
Validation loss: 1.477851625411741

Epoch: 6| Step: 1
Training loss: 0.1284133493900299
Validation loss: 1.5092222844400713

Epoch: 6| Step: 2
Training loss: 0.1644461750984192
Validation loss: 1.4915486753627818

Epoch: 6| Step: 3
Training loss: 0.20664846897125244
Validation loss: 1.5063369427957842

Epoch: 6| Step: 4
Training loss: 0.19834549725055695
Validation loss: 1.479441350506198

Epoch: 6| Step: 5
Training loss: 0.20040065050125122
Validation loss: 1.476390427158725

Epoch: 6| Step: 6
Training loss: 0.16459834575653076
Validation loss: 1.4813088011998001

Epoch: 6| Step: 7
Training loss: 0.16248345375061035
Validation loss: 1.465832353920065

Epoch: 6| Step: 8
Training loss: 0.2532263994216919
Validation loss: 1.4728642740557272

Epoch: 6| Step: 9
Training loss: 0.1368689239025116
Validation loss: 1.4495363892406545

Epoch: 6| Step: 10
Training loss: 0.1355922520160675
Validation loss: 1.4666219731812835

Epoch: 6| Step: 11
Training loss: 0.09964603185653687
Validation loss: 1.4741194414836105

Epoch: 6| Step: 12
Training loss: 0.11379977315664291
Validation loss: 1.4915807016434208

Epoch: 6| Step: 13
Training loss: 0.14362989366054535
Validation loss: 1.449674117308791

Epoch: 389| Step: 0
Training loss: 0.1911536306142807
Validation loss: 1.4658570712612522

Epoch: 6| Step: 1
Training loss: 0.0895707830786705
Validation loss: 1.462870951621763

Epoch: 6| Step: 2
Training loss: 0.21131223440170288
Validation loss: 1.4686434922679779

Epoch: 6| Step: 3
Training loss: 0.20507454872131348
Validation loss: 1.5100680794767154

Epoch: 6| Step: 4
Training loss: 0.1751769781112671
Validation loss: 1.5064414367880872

Epoch: 6| Step: 5
Training loss: 0.19005918502807617
Validation loss: 1.493339357837554

Epoch: 6| Step: 6
Training loss: 0.17489127814769745
Validation loss: 1.5042574956852903

Epoch: 6| Step: 7
Training loss: 0.139943927526474
Validation loss: 1.5115613270831365

Epoch: 6| Step: 8
Training loss: 0.15652254223823547
Validation loss: 1.5348279373620146

Epoch: 6| Step: 9
Training loss: 0.22301390767097473
Validation loss: 1.5370222778730496

Epoch: 6| Step: 10
Training loss: 0.14037026464939117
Validation loss: 1.510986743434783

Epoch: 6| Step: 11
Training loss: 0.10047158598899841
Validation loss: 1.496294358725189

Epoch: 6| Step: 12
Training loss: 0.18042472004890442
Validation loss: 1.5290631325014177

Epoch: 6| Step: 13
Training loss: 0.09320176392793655
Validation loss: 1.5011040203032955

Epoch: 390| Step: 0
Training loss: 0.15097682178020477
Validation loss: 1.5022024364881619

Epoch: 6| Step: 1
Training loss: 0.23772495985031128
Validation loss: 1.5102779634537236

Epoch: 6| Step: 2
Training loss: 0.14136376976966858
Validation loss: 1.5082606936013827

Epoch: 6| Step: 3
Training loss: 0.16992047429084778
Validation loss: 1.4903834891575638

Epoch: 6| Step: 4
Training loss: 0.26206791400909424
Validation loss: 1.5081600463518532

Epoch: 6| Step: 5
Training loss: 0.32029110193252563
Validation loss: 1.5105072836722098

Epoch: 6| Step: 6
Training loss: 0.1902831792831421
Validation loss: 1.5246584517981416

Epoch: 6| Step: 7
Training loss: 0.13205450773239136
Validation loss: 1.5066971573778378

Epoch: 6| Step: 8
Training loss: 0.20671582221984863
Validation loss: 1.5201963186264038

Epoch: 6| Step: 9
Training loss: 0.08623792231082916
Validation loss: 1.5037063898578766

Epoch: 6| Step: 10
Training loss: 0.18023157119750977
Validation loss: 1.5303550445905296

Epoch: 6| Step: 11
Training loss: 0.16193845868110657
Validation loss: 1.5304174577036211

Epoch: 6| Step: 12
Training loss: 0.19554463028907776
Validation loss: 1.511081023882794

Epoch: 6| Step: 13
Training loss: 0.2758653163909912
Validation loss: 1.494995303051446

Epoch: 391| Step: 0
Training loss: 0.15056312084197998
Validation loss: 1.492402813126964

Epoch: 6| Step: 1
Training loss: 0.18941394984722137
Validation loss: 1.4878594990699523

Epoch: 6| Step: 2
Training loss: 0.22770632803440094
Validation loss: 1.4534577131271362

Epoch: 6| Step: 3
Training loss: 0.21151892840862274
Validation loss: 1.4579156675646383

Epoch: 6| Step: 4
Training loss: 0.18366149067878723
Validation loss: 1.4812655679641231

Epoch: 6| Step: 5
Training loss: 0.14946690201759338
Validation loss: 1.4856811390128186

Epoch: 6| Step: 6
Training loss: 0.1900310218334198
Validation loss: 1.4975733000745055

Epoch: 6| Step: 7
Training loss: 0.14446468651294708
Validation loss: 1.4930038003511326

Epoch: 6| Step: 8
Training loss: 0.11860150098800659
Validation loss: 1.51485998271614

Epoch: 6| Step: 9
Training loss: 0.14826112985610962
Validation loss: 1.5221884084004227

Epoch: 6| Step: 10
Training loss: 0.1541936695575714
Validation loss: 1.555388125040198

Epoch: 6| Step: 11
Training loss: 0.1881309300661087
Validation loss: 1.5203965517782396

Epoch: 6| Step: 12
Training loss: 0.14376768469810486
Validation loss: 1.5453582809817406

Epoch: 6| Step: 13
Training loss: 0.09144765883684158
Validation loss: 1.5319262217449885

Epoch: 392| Step: 0
Training loss: 0.1338990032672882
Validation loss: 1.5661805624602942

Epoch: 6| Step: 1
Training loss: 0.11337802559137344
Validation loss: 1.5655340661284745

Epoch: 6| Step: 2
Training loss: 0.10339350998401642
Validation loss: 1.5549840260577459

Epoch: 6| Step: 3
Training loss: 0.18337079882621765
Validation loss: 1.536832421056686

Epoch: 6| Step: 4
Training loss: 0.11379500478506088
Validation loss: 1.5672066967974427

Epoch: 6| Step: 5
Training loss: 0.11953114718198776
Validation loss: 1.509018503209596

Epoch: 6| Step: 6
Training loss: 0.1267084777355194
Validation loss: 1.5306649002977597

Epoch: 6| Step: 7
Training loss: 0.12001743167638779
Validation loss: 1.5439473595670474

Epoch: 6| Step: 8
Training loss: 0.17771965265274048
Validation loss: 1.4997578410692112

Epoch: 6| Step: 9
Training loss: 0.21804052591323853
Validation loss: 1.4912022573332633

Epoch: 6| Step: 10
Training loss: 0.20259350538253784
Validation loss: 1.5243841525047057

Epoch: 6| Step: 11
Training loss: 0.16388925909996033
Validation loss: 1.5514975747754496

Epoch: 6| Step: 12
Training loss: 0.2302028238773346
Validation loss: 1.5541859967734224

Epoch: 6| Step: 13
Training loss: 0.17864172160625458
Validation loss: 1.5295607120760026

Epoch: 393| Step: 0
Training loss: 0.1348843276500702
Validation loss: 1.5233681740299347

Epoch: 6| Step: 1
Training loss: 0.1200396940112114
Validation loss: 1.5476106751349665

Epoch: 6| Step: 2
Training loss: 0.2281627357006073
Validation loss: 1.5168074407885153

Epoch: 6| Step: 3
Training loss: 0.1765349954366684
Validation loss: 1.5544285415321268

Epoch: 6| Step: 4
Training loss: 0.13534072041511536
Validation loss: 1.505932960458981

Epoch: 6| Step: 5
Training loss: 0.16901591420173645
Validation loss: 1.5497460275567987

Epoch: 6| Step: 6
Training loss: 0.15748481452465057
Validation loss: 1.527223688299938

Epoch: 6| Step: 7
Training loss: 0.16399985551834106
Validation loss: 1.5512026984204528

Epoch: 6| Step: 8
Training loss: 0.19521743059158325
Validation loss: 1.5570716806637344

Epoch: 6| Step: 9
Training loss: 0.0942627415060997
Validation loss: 1.5165677967891897

Epoch: 6| Step: 10
Training loss: 0.10638076066970825
Validation loss: 1.5368661124219176

Epoch: 6| Step: 11
Training loss: 0.13796398043632507
Validation loss: 1.5107402173421716

Epoch: 6| Step: 12
Training loss: 0.1322477012872696
Validation loss: 1.528203523287209

Epoch: 6| Step: 13
Training loss: 0.10344016551971436
Validation loss: 1.5219928936291767

Epoch: 394| Step: 0
Training loss: 0.18769948184490204
Validation loss: 1.5465322207379084

Epoch: 6| Step: 1
Training loss: 0.1059250682592392
Validation loss: 1.5144368307564848

Epoch: 6| Step: 2
Training loss: 0.160645991563797
Validation loss: 1.5188563600663216

Epoch: 6| Step: 3
Training loss: 0.10806910693645477
Validation loss: 1.5237611621938727

Epoch: 6| Step: 4
Training loss: 0.15543818473815918
Validation loss: 1.5498431645413882

Epoch: 6| Step: 5
Training loss: 0.11823475360870361
Validation loss: 1.5240167379379272

Epoch: 6| Step: 6
Training loss: 0.26000863313674927
Validation loss: 1.5160153014685518

Epoch: 6| Step: 7
Training loss: 0.16748157143592834
Validation loss: 1.5331470825338875

Epoch: 6| Step: 8
Training loss: 0.10298242419958115
Validation loss: 1.516809650646743

Epoch: 6| Step: 9
Training loss: 0.1478966474533081
Validation loss: 1.5722251220415997

Epoch: 6| Step: 10
Training loss: 0.22512805461883545
Validation loss: 1.541110704022069

Epoch: 6| Step: 11
Training loss: 0.1762753427028656
Validation loss: 1.5374373492374216

Epoch: 6| Step: 12
Training loss: 0.12294788658618927
Validation loss: 1.5409479230962775

Epoch: 6| Step: 13
Training loss: 0.11559491604566574
Validation loss: 1.5392463578972766

Epoch: 395| Step: 0
Training loss: 0.11210174858570099
Validation loss: 1.5436394035175283

Epoch: 6| Step: 1
Training loss: 0.1554926335811615
Validation loss: 1.5450661464404034

Epoch: 6| Step: 2
Training loss: 0.07101982831954956
Validation loss: 1.528646848535025

Epoch: 6| Step: 3
Training loss: 0.0818847268819809
Validation loss: 1.5425319005084295

Epoch: 6| Step: 4
Training loss: 0.08781339228153229
Validation loss: 1.5604230191117974

Epoch: 6| Step: 5
Training loss: 0.10373206436634064
Validation loss: 1.5551498833523

Epoch: 6| Step: 6
Training loss: 0.2248317301273346
Validation loss: 1.5595964552253805

Epoch: 6| Step: 7
Training loss: 0.10194747149944305
Validation loss: 1.567553771439419

Epoch: 6| Step: 8
Training loss: 0.2590351998806
Validation loss: 1.5401639438444568

Epoch: 6| Step: 9
Training loss: 0.18190059065818787
Validation loss: 1.5409414973310245

Epoch: 6| Step: 10
Training loss: 0.2013038545846939
Validation loss: 1.5297691822052002

Epoch: 6| Step: 11
Training loss: 0.10584510117769241
Validation loss: 1.5575470898741035

Epoch: 6| Step: 12
Training loss: 0.09814596176147461
Validation loss: 1.5492603689111688

Epoch: 6| Step: 13
Training loss: 0.09796236455440521
Validation loss: 1.5600184676467732

Epoch: 396| Step: 0
Training loss: 0.07129571586847305
Validation loss: 1.5108970954854002

Epoch: 6| Step: 1
Training loss: 0.1137099638581276
Validation loss: 1.5237935922479118

Epoch: 6| Step: 2
Training loss: 0.18415221571922302
Validation loss: 1.5563578323651386

Epoch: 6| Step: 3
Training loss: 0.2104857712984085
Validation loss: 1.5372513199365267

Epoch: 6| Step: 4
Training loss: 0.15791639685630798
Validation loss: 1.5113893612738578

Epoch: 6| Step: 5
Training loss: 0.18077272176742554
Validation loss: 1.4807319807749924

Epoch: 6| Step: 6
Training loss: 0.15193554759025574
Validation loss: 1.5296453391352007

Epoch: 6| Step: 7
Training loss: 0.18541769683361053
Validation loss: 1.515990775118592

Epoch: 6| Step: 8
Training loss: 0.15010730922222137
Validation loss: 1.5112955672766573

Epoch: 6| Step: 9
Training loss: 0.12602464854717255
Validation loss: 1.5105815843869281

Epoch: 6| Step: 10
Training loss: 0.1205296739935875
Validation loss: 1.5210115063575007

Epoch: 6| Step: 11
Training loss: 0.1415221244096756
Validation loss: 1.5190178912173036

Epoch: 6| Step: 12
Training loss: 0.1769779473543167
Validation loss: 1.523334668528649

Epoch: 6| Step: 13
Training loss: 0.12579363584518433
Validation loss: 1.546459053152351

Epoch: 397| Step: 0
Training loss: 0.19406534731388092
Validation loss: 1.5562049317103561

Epoch: 6| Step: 1
Training loss: 0.17367860674858093
Validation loss: 1.5463266103498396

Epoch: 6| Step: 2
Training loss: 0.29145440459251404
Validation loss: 1.5445020083458192

Epoch: 6| Step: 3
Training loss: 0.16262401640415192
Validation loss: 1.5403901710305163

Epoch: 6| Step: 4
Training loss: 0.08725647628307343
Validation loss: 1.497126030665572

Epoch: 6| Step: 5
Training loss: 0.09376491606235504
Validation loss: 1.5031615277772308

Epoch: 6| Step: 6
Training loss: 0.15374380350112915
Validation loss: 1.4958511821685299

Epoch: 6| Step: 7
Training loss: 0.1296241581439972
Validation loss: 1.4831418709088398

Epoch: 6| Step: 8
Training loss: 0.18275503814220428
Validation loss: 1.4910949814704157

Epoch: 6| Step: 9
Training loss: 0.1635534018278122
Validation loss: 1.5086516000891244

Epoch: 6| Step: 10
Training loss: 0.09985695034265518
Validation loss: 1.5007662862859747

Epoch: 6| Step: 11
Training loss: 0.20972827076911926
Validation loss: 1.4978730845194992

Epoch: 6| Step: 12
Training loss: 0.05758360028266907
Validation loss: 1.5092480394148058

Epoch: 6| Step: 13
Training loss: 0.17764891684055328
Validation loss: 1.5172872248516287

Epoch: 398| Step: 0
Training loss: 0.0840158686041832
Validation loss: 1.493860129387148

Epoch: 6| Step: 1
Training loss: 0.19244492053985596
Validation loss: 1.5321762689980127

Epoch: 6| Step: 2
Training loss: 0.19949907064437866
Validation loss: 1.5155494520741124

Epoch: 6| Step: 3
Training loss: 0.11450894176959991
Validation loss: 1.5017148281938286

Epoch: 6| Step: 4
Training loss: 0.14476805925369263
Validation loss: 1.5356589337830902

Epoch: 6| Step: 5
Training loss: 0.1252521276473999
Validation loss: 1.5140291843363034

Epoch: 6| Step: 6
Training loss: 0.11319178342819214
Validation loss: 1.5114850151923396

Epoch: 6| Step: 7
Training loss: 0.18887078762054443
Validation loss: 1.5439719461625623

Epoch: 6| Step: 8
Training loss: 0.16000919044017792
Validation loss: 1.5254074886281004

Epoch: 6| Step: 9
Training loss: 0.2747000455856323
Validation loss: 1.528369822809773

Epoch: 6| Step: 10
Training loss: 0.22205320000648499
Validation loss: 1.5384613685710455

Epoch: 6| Step: 11
Training loss: 0.10632049292325974
Validation loss: 1.5098562830237932

Epoch: 6| Step: 12
Training loss: 0.13177862763404846
Validation loss: 1.508941396590202

Epoch: 6| Step: 13
Training loss: 0.06397870928049088
Validation loss: 1.5192042281550746

Epoch: 399| Step: 0
Training loss: 0.08337599784135818
Validation loss: 1.5218555952913018

Epoch: 6| Step: 1
Training loss: 0.15838810801506042
Validation loss: 1.5092078665251374

Epoch: 6| Step: 2
Training loss: 0.16298004984855652
Validation loss: 1.4866554429454188

Epoch: 6| Step: 3
Training loss: 0.18573492765426636
Validation loss: 1.510777138894604

Epoch: 6| Step: 4
Training loss: 0.2577199935913086
Validation loss: 1.50619399932123

Epoch: 6| Step: 5
Training loss: 0.11557146161794662
Validation loss: 1.4999453777907996

Epoch: 6| Step: 6
Training loss: 0.14045730233192444
Validation loss: 1.505996428510194

Epoch: 6| Step: 7
Training loss: 0.15739956498146057
Validation loss: 1.5136577724128641

Epoch: 6| Step: 8
Training loss: 0.2381482720375061
Validation loss: 1.5309786120409608

Epoch: 6| Step: 9
Training loss: 0.19734443724155426
Validation loss: 1.5138030154730684

Epoch: 6| Step: 10
Training loss: 0.17049819231033325
Validation loss: 1.4833983477725778

Epoch: 6| Step: 11
Training loss: 0.17488300800323486
Validation loss: 1.4806830113933933

Epoch: 6| Step: 12
Training loss: 0.16684725880622864
Validation loss: 1.48236366369391

Epoch: 6| Step: 13
Training loss: 0.056289393454790115
Validation loss: 1.4820235518998996

Epoch: 400| Step: 0
Training loss: 0.1380007416009903
Validation loss: 1.5030664961825135

Epoch: 6| Step: 1
Training loss: 0.1513236165046692
Validation loss: 1.491191542276772

Epoch: 6| Step: 2
Training loss: 0.23758110404014587
Validation loss: 1.5245684180208432

Epoch: 6| Step: 3
Training loss: 0.19543597102165222
Validation loss: 1.5141531754565496

Epoch: 6| Step: 4
Training loss: 0.24817083775997162
Validation loss: 1.4851415439318585

Epoch: 6| Step: 5
Training loss: 0.16688694059848785
Validation loss: 1.4679289261500041

Epoch: 6| Step: 6
Training loss: 0.1680619716644287
Validation loss: 1.454194724559784

Epoch: 6| Step: 7
Training loss: 0.1091889888048172
Validation loss: 1.4319880034333916

Epoch: 6| Step: 8
Training loss: 0.08612142503261566
Validation loss: 1.4245050491825226

Epoch: 6| Step: 9
Training loss: 0.09981575608253479
Validation loss: 1.4343483781301847

Epoch: 6| Step: 10
Training loss: 0.17904157936573029
Validation loss: 1.4350154957463663

Epoch: 6| Step: 11
Training loss: 0.15286800265312195
Validation loss: 1.4395453160808933

Epoch: 6| Step: 12
Training loss: 0.10428808629512787
Validation loss: 1.4506421268627208

Epoch: 6| Step: 13
Training loss: 0.16818350553512573
Validation loss: 1.483549007805445

Epoch: 401| Step: 0
Training loss: 0.1322547346353531
Validation loss: 1.4511437723713536

Epoch: 6| Step: 1
Training loss: 0.1112862154841423
Validation loss: 1.480818046036587

Epoch: 6| Step: 2
Training loss: 0.17712074518203735
Validation loss: 1.4469125616934992

Epoch: 6| Step: 3
Training loss: 0.20940980315208435
Validation loss: 1.4364925840849518

Epoch: 6| Step: 4
Training loss: 0.35119566321372986
Validation loss: 1.4391919297556723

Epoch: 6| Step: 5
Training loss: 0.12541377544403076
Validation loss: 1.4226310791507844

Epoch: 6| Step: 6
Training loss: 0.11251207441091537
Validation loss: 1.3999746409795617

Epoch: 6| Step: 7
Training loss: 0.3290203809738159
Validation loss: 1.4452504496420584

Epoch: 6| Step: 8
Training loss: 0.15700548887252808
Validation loss: 1.450166723420543

Epoch: 6| Step: 9
Training loss: 0.2664797008037567
Validation loss: 1.452898266494915

Epoch: 6| Step: 10
Training loss: 0.12847645580768585
Validation loss: 1.4692753809754566

Epoch: 6| Step: 11
Training loss: 0.18879905343055725
Validation loss: 1.4764109516656527

Epoch: 6| Step: 12
Training loss: 0.1554657220840454
Validation loss: 1.4809117349245216

Epoch: 6| Step: 13
Training loss: 0.14628253877162933
Validation loss: 1.4889371331020067

Epoch: 402| Step: 0
Training loss: 0.09925489127635956
Validation loss: 1.469967935674934

Epoch: 6| Step: 1
Training loss: 0.16163189709186554
Validation loss: 1.4931431162741877

Epoch: 6| Step: 2
Training loss: 0.17808660864830017
Validation loss: 1.5198049673470118

Epoch: 6| Step: 3
Training loss: 0.11443019658327103
Validation loss: 1.537351930013267

Epoch: 6| Step: 4
Training loss: 0.15979476273059845
Validation loss: 1.517293035343129

Epoch: 6| Step: 5
Training loss: 0.22381660342216492
Validation loss: 1.4999103366687734

Epoch: 6| Step: 6
Training loss: 0.12871652841567993
Validation loss: 1.469010797880029

Epoch: 6| Step: 7
Training loss: 0.24508142471313477
Validation loss: 1.4706135180688673

Epoch: 6| Step: 8
Training loss: 0.09633379429578781
Validation loss: 1.4760339042191863

Epoch: 6| Step: 9
Training loss: 0.08007041364908218
Validation loss: 1.4836367394334526

Epoch: 6| Step: 10
Training loss: 0.13560307025909424
Validation loss: 1.473492794139411

Epoch: 6| Step: 11
Training loss: 0.1389535665512085
Validation loss: 1.4638414767480665

Epoch: 6| Step: 12
Training loss: 0.1055927574634552
Validation loss: 1.4831841671338646

Epoch: 6| Step: 13
Training loss: 0.16550438106060028
Validation loss: 1.4581115425273936

Epoch: 403| Step: 0
Training loss: 0.1361990123987198
Validation loss: 1.4479683054390775

Epoch: 6| Step: 1
Training loss: 0.1742892563343048
Validation loss: 1.5148792753937423

Epoch: 6| Step: 2
Training loss: 0.22902816534042358
Validation loss: 1.4903465970869987

Epoch: 6| Step: 3
Training loss: 0.10149023681879044
Validation loss: 1.4611460008928854

Epoch: 6| Step: 4
Training loss: 0.16461274027824402
Validation loss: 1.4782283665031515

Epoch: 6| Step: 5
Training loss: 0.20006486773490906
Validation loss: 1.4657626799357835

Epoch: 6| Step: 6
Training loss: 0.1385841816663742
Validation loss: 1.42412515224949

Epoch: 6| Step: 7
Training loss: 0.23461952805519104
Validation loss: 1.4453753373956169

Epoch: 6| Step: 8
Training loss: 0.19994564354419708
Validation loss: 1.4199401601668327

Epoch: 6| Step: 9
Training loss: 0.12801088392734528
Validation loss: 1.441806839358422

Epoch: 6| Step: 10
Training loss: 0.21240200102329254
Validation loss: 1.458849900512285

Epoch: 6| Step: 11
Training loss: 0.1639312207698822
Validation loss: 1.4389298910735755

Epoch: 6| Step: 12
Training loss: 0.09312210232019424
Validation loss: 1.4418402794868714

Epoch: 6| Step: 13
Training loss: 0.190586656332016
Validation loss: 1.4756425740898296

Epoch: 404| Step: 0
Training loss: 0.1614370346069336
Validation loss: 1.4633267220630441

Epoch: 6| Step: 1
Training loss: 0.08943066000938416
Validation loss: 1.4282943151330436

Epoch: 6| Step: 2
Training loss: 0.13715583086013794
Validation loss: 1.4787843176113662

Epoch: 6| Step: 3
Training loss: 0.11060141772031784
Validation loss: 1.4205705004353677

Epoch: 6| Step: 4
Training loss: 0.1574704945087433
Validation loss: 1.4310176705801358

Epoch: 6| Step: 5
Training loss: 0.1127721518278122
Validation loss: 1.4260098306081628

Epoch: 6| Step: 6
Training loss: 0.12033724039793015
Validation loss: 1.434835728778634

Epoch: 6| Step: 7
Training loss: 0.166643887758255
Validation loss: 1.440929482060094

Epoch: 6| Step: 8
Training loss: 0.09965761005878448
Validation loss: 1.415413313334988

Epoch: 6| Step: 9
Training loss: 0.22418703138828278
Validation loss: 1.4283082921017882

Epoch: 6| Step: 10
Training loss: 0.18880170583724976
Validation loss: 1.3958817976777271

Epoch: 6| Step: 11
Training loss: 0.106244757771492
Validation loss: 1.4230625257697156

Epoch: 6| Step: 12
Training loss: 0.09044080972671509
Validation loss: 1.420924759680225

Epoch: 6| Step: 13
Training loss: 0.12713688611984253
Validation loss: 1.4398074329540294

Epoch: 405| Step: 0
Training loss: 0.09789378196001053
Validation loss: 1.4245460289780811

Epoch: 6| Step: 1
Training loss: 0.12575843930244446
Validation loss: 1.4153318264151131

Epoch: 6| Step: 2
Training loss: 0.1706395447254181
Validation loss: 1.4460502055383497

Epoch: 6| Step: 3
Training loss: 0.21095865964889526
Validation loss: 1.4456859516200198

Epoch: 6| Step: 4
Training loss: 0.12070532143115997
Validation loss: 1.44561344064692

Epoch: 6| Step: 5
Training loss: 0.11400705575942993
Validation loss: 1.4381698049524778

Epoch: 6| Step: 6
Training loss: 0.10110628604888916
Validation loss: 1.4525426856933101

Epoch: 6| Step: 7
Training loss: 0.27779221534729004
Validation loss: 1.4454380978820145

Epoch: 6| Step: 8
Training loss: 0.10763996094465256
Validation loss: 1.4241842377570368

Epoch: 6| Step: 9
Training loss: 0.09020715206861496
Validation loss: 1.4443864271204958

Epoch: 6| Step: 10
Training loss: 0.1581522822380066
Validation loss: 1.4589248293189592

Epoch: 6| Step: 11
Training loss: 0.1395440697669983
Validation loss: 1.4558996051870368

Epoch: 6| Step: 12
Training loss: 0.16848009824752808
Validation loss: 1.4458784262339275

Epoch: 6| Step: 13
Training loss: 0.13585346937179565
Validation loss: 1.4456115050982403

Epoch: 406| Step: 0
Training loss: 0.1435118317604065
Validation loss: 1.43195733844593

Epoch: 6| Step: 1
Training loss: 0.21762937307357788
Validation loss: 1.4487114978092972

Epoch: 6| Step: 2
Training loss: 0.12728935480117798
Validation loss: 1.4280253392393871

Epoch: 6| Step: 3
Training loss: 0.11668825149536133
Validation loss: 1.4258367194924304

Epoch: 6| Step: 4
Training loss: 0.08481603860855103
Validation loss: 1.4684996874101701

Epoch: 6| Step: 5
Training loss: 0.08998039364814758
Validation loss: 1.4794225820931055

Epoch: 6| Step: 6
Training loss: 0.09956426918506622
Validation loss: 1.4765276998601935

Epoch: 6| Step: 7
Training loss: 0.1327960193157196
Validation loss: 1.4805869171696324

Epoch: 6| Step: 8
Training loss: 0.13637660443782806
Validation loss: 1.4925078486883512

Epoch: 6| Step: 9
Training loss: 0.1594744622707367
Validation loss: 1.4716865606205438

Epoch: 6| Step: 10
Training loss: 0.10435833781957626
Validation loss: 1.433993383120465

Epoch: 6| Step: 11
Training loss: 0.20261919498443604
Validation loss: 1.4873510381226898

Epoch: 6| Step: 12
Training loss: 0.10230319201946259
Validation loss: 1.4594944061771515

Epoch: 6| Step: 13
Training loss: 0.15833933651447296
Validation loss: 1.5101035474449076

Epoch: 407| Step: 0
Training loss: 0.07326538860797882
Validation loss: 1.4940220989206785

Epoch: 6| Step: 1
Training loss: 0.12033075094223022
Validation loss: 1.5223377712311283

Epoch: 6| Step: 2
Training loss: 0.15816441178321838
Validation loss: 1.5114152008487332

Epoch: 6| Step: 3
Training loss: 0.16879132390022278
Validation loss: 1.4913899257618894

Epoch: 6| Step: 4
Training loss: 0.13486486673355103
Validation loss: 1.469078016537492

Epoch: 6| Step: 5
Training loss: 0.1009402945637703
Validation loss: 1.4658733465338265

Epoch: 6| Step: 6
Training loss: 0.13367903232574463
Validation loss: 1.4471709600058935

Epoch: 6| Step: 7
Training loss: 0.13895109295845032
Validation loss: 1.4445129133039905

Epoch: 6| Step: 8
Training loss: 0.1077665239572525
Validation loss: 1.4923476365304762

Epoch: 6| Step: 9
Training loss: 0.14716845750808716
Validation loss: 1.4615277045516557

Epoch: 6| Step: 10
Training loss: 0.13004200160503387
Validation loss: 1.4541224997530702

Epoch: 6| Step: 11
Training loss: 0.1394389420747757
Validation loss: 1.4448419142794866

Epoch: 6| Step: 12
Training loss: 0.09973734617233276
Validation loss: 1.474614825299991

Epoch: 6| Step: 13
Training loss: 0.13660161197185516
Validation loss: 1.475306680125575

Epoch: 408| Step: 0
Training loss: 0.09531441330909729
Validation loss: 1.4630204259708364

Epoch: 6| Step: 1
Training loss: 0.1727767288684845
Validation loss: 1.4639538859808316

Epoch: 6| Step: 2
Training loss: 0.10295446217060089
Validation loss: 1.4597832925858036

Epoch: 6| Step: 3
Training loss: 0.10817909240722656
Validation loss: 1.4984739762480541

Epoch: 6| Step: 4
Training loss: 0.19311028718948364
Validation loss: 1.517118416806703

Epoch: 6| Step: 5
Training loss: 0.099896639585495
Validation loss: 1.5329061990143151

Epoch: 6| Step: 6
Training loss: 0.16712582111358643
Validation loss: 1.5057201231679609

Epoch: 6| Step: 7
Training loss: 0.1037660762667656
Validation loss: 1.5237599406191098

Epoch: 6| Step: 8
Training loss: 0.11259178817272186
Validation loss: 1.5184554374346169

Epoch: 6| Step: 9
Training loss: 0.1252661645412445
Validation loss: 1.4949910076715613

Epoch: 6| Step: 10
Training loss: 0.08510446548461914
Validation loss: 1.5146340170214254

Epoch: 6| Step: 11
Training loss: 0.12448197603225708
Validation loss: 1.5333990845628964

Epoch: 6| Step: 12
Training loss: 0.17647045850753784
Validation loss: 1.5126946805625834

Epoch: 6| Step: 13
Training loss: 0.08896639943122864
Validation loss: 1.5094680017040623

Epoch: 409| Step: 0
Training loss: 0.15088628232479095
Validation loss: 1.5332560616154824

Epoch: 6| Step: 1
Training loss: 0.14608384668827057
Validation loss: 1.5235493311318018

Epoch: 6| Step: 2
Training loss: 0.12518072128295898
Validation loss: 1.452915801796862

Epoch: 6| Step: 3
Training loss: 0.125504732131958
Validation loss: 1.4482058940395233

Epoch: 6| Step: 4
Training loss: 0.1322595626115799
Validation loss: 1.4500347811688659

Epoch: 6| Step: 5
Training loss: 0.16377311944961548
Validation loss: 1.425307584065263

Epoch: 6| Step: 6
Training loss: 0.14163067936897278
Validation loss: 1.4421042191084994

Epoch: 6| Step: 7
Training loss: 0.0665389895439148
Validation loss: 1.4208518715314968

Epoch: 6| Step: 8
Training loss: 0.14331567287445068
Validation loss: 1.4589175883159842

Epoch: 6| Step: 9
Training loss: 0.15646079182624817
Validation loss: 1.4445940294573385

Epoch: 6| Step: 10
Training loss: 0.14440977573394775
Validation loss: 1.4480451999172088

Epoch: 6| Step: 11
Training loss: 0.15608155727386475
Validation loss: 1.4683427874759962

Epoch: 6| Step: 12
Training loss: 0.11330048739910126
Validation loss: 1.4434302468453684

Epoch: 6| Step: 13
Training loss: 0.1563582420349121
Validation loss: 1.4657943543567453

Epoch: 410| Step: 0
Training loss: 0.149063378572464
Validation loss: 1.4737548616624647

Epoch: 6| Step: 1
Training loss: 0.11279343068599701
Validation loss: 1.4387067287198958

Epoch: 6| Step: 2
Training loss: 0.18495208024978638
Validation loss: 1.4672751695879045

Epoch: 6| Step: 3
Training loss: 0.08223827183246613
Validation loss: 1.4511409523666545

Epoch: 6| Step: 4
Training loss: 0.11080028116703033
Validation loss: 1.4625259381468578

Epoch: 6| Step: 5
Training loss: 0.1815682053565979
Validation loss: 1.478681225930491

Epoch: 6| Step: 6
Training loss: 0.08786555379629135
Validation loss: 1.469085636959281

Epoch: 6| Step: 7
Training loss: 0.15729030966758728
Validation loss: 1.4600296379417501

Epoch: 6| Step: 8
Training loss: 0.057647738605737686
Validation loss: 1.4650711603062128

Epoch: 6| Step: 9
Training loss: 0.14283156394958496
Validation loss: 1.4847881934976066

Epoch: 6| Step: 10
Training loss: 0.19452430307865143
Validation loss: 1.495358613870477

Epoch: 6| Step: 11
Training loss: 0.08349184691905975
Validation loss: 1.4606625905600927

Epoch: 6| Step: 12
Training loss: 0.18582671880722046
Validation loss: 1.4827850262324016

Epoch: 6| Step: 13
Training loss: 0.16588963568210602
Validation loss: 1.4917397383720643

Epoch: 411| Step: 0
Training loss: 0.12033636122941971
Validation loss: 1.4868493785140335

Epoch: 6| Step: 1
Training loss: 0.08571329712867737
Validation loss: 1.5111655112235778

Epoch: 6| Step: 2
Training loss: 0.13179345428943634
Validation loss: 1.489625600717401

Epoch: 6| Step: 3
Training loss: 0.14735323190689087
Validation loss: 1.4879208341721566

Epoch: 6| Step: 4
Training loss: 0.09231781214475632
Validation loss: 1.4801723187969578

Epoch: 6| Step: 5
Training loss: 0.12437494099140167
Validation loss: 1.482328127789241

Epoch: 6| Step: 6
Training loss: 0.10921335965394974
Validation loss: 1.4806552471653107

Epoch: 6| Step: 7
Training loss: 0.14375296235084534
Validation loss: 1.4706960160245177

Epoch: 6| Step: 8
Training loss: 0.08876033127307892
Validation loss: 1.4682338096762215

Epoch: 6| Step: 9
Training loss: 0.14593011140823364
Validation loss: 1.4749635393901537

Epoch: 6| Step: 10
Training loss: 0.21246254444122314
Validation loss: 1.4355087562273907

Epoch: 6| Step: 11
Training loss: 0.16221299767494202
Validation loss: 1.4605768085807882

Epoch: 6| Step: 12
Training loss: 0.15291425585746765
Validation loss: 1.4695851379825222

Epoch: 6| Step: 13
Training loss: 0.14535462856292725
Validation loss: 1.4715365447023863

Epoch: 412| Step: 0
Training loss: 0.08666013181209564
Validation loss: 1.4924298794038835

Epoch: 6| Step: 1
Training loss: 0.20143690705299377
Validation loss: 1.466846501955422

Epoch: 6| Step: 2
Training loss: 0.1500154733657837
Validation loss: 1.4683842056541032

Epoch: 6| Step: 3
Training loss: 0.12930834293365479
Validation loss: 1.477325253589179

Epoch: 6| Step: 4
Training loss: 0.11283119022846222
Validation loss: 1.4567836510237826

Epoch: 6| Step: 5
Training loss: 0.16331076622009277
Validation loss: 1.4933308362960815

Epoch: 6| Step: 6
Training loss: 0.08338013291358948
Validation loss: 1.4902364797489618

Epoch: 6| Step: 7
Training loss: 0.1446097493171692
Validation loss: 1.4797039557528753

Epoch: 6| Step: 8
Training loss: 0.17579859495162964
Validation loss: 1.495530826430167

Epoch: 6| Step: 9
Training loss: 0.14795124530792236
Validation loss: 1.4899735604563067

Epoch: 6| Step: 10
Training loss: 0.14167994260787964
Validation loss: 1.4974907470005814

Epoch: 6| Step: 11
Training loss: 0.14940837025642395
Validation loss: 1.4605952168023715

Epoch: 6| Step: 12
Training loss: 0.12533770501613617
Validation loss: 1.440301272176927

Epoch: 6| Step: 13
Training loss: 0.050112467259168625
Validation loss: 1.4593445601001862

Epoch: 413| Step: 0
Training loss: 0.1137569397687912
Validation loss: 1.4422370951662782

Epoch: 6| Step: 1
Training loss: 0.15690262615680695
Validation loss: 1.4466998359208465

Epoch: 6| Step: 2
Training loss: 0.13797803223133087
Validation loss: 1.4253843586931947

Epoch: 6| Step: 3
Training loss: 0.14085876941680908
Validation loss: 1.4445818675461637

Epoch: 6| Step: 4
Training loss: 0.17304524779319763
Validation loss: 1.4372391008561658

Epoch: 6| Step: 5
Training loss: 0.1517564356327057
Validation loss: 1.4628013436512282

Epoch: 6| Step: 6
Training loss: 0.12952063977718353
Validation loss: 1.4304720406891198

Epoch: 6| Step: 7
Training loss: 0.06363020092248917
Validation loss: 1.438939735453616

Epoch: 6| Step: 8
Training loss: 0.09983997046947479
Validation loss: 1.459856387107603

Epoch: 6| Step: 9
Training loss: 0.19155040383338928
Validation loss: 1.4403009671036915

Epoch: 6| Step: 10
Training loss: 0.1677626073360443
Validation loss: 1.453566853718091

Epoch: 6| Step: 11
Training loss: 0.10475719720125198
Validation loss: 1.484964830901033

Epoch: 6| Step: 12
Training loss: 0.0640990361571312
Validation loss: 1.468598634965958

Epoch: 6| Step: 13
Training loss: 0.09362820535898209
Validation loss: 1.4773553103528998

Epoch: 414| Step: 0
Training loss: 0.0906849205493927
Validation loss: 1.493857564464692

Epoch: 6| Step: 1
Training loss: 0.11072121560573578
Validation loss: 1.5119676538693008

Epoch: 6| Step: 2
Training loss: 0.11530987173318863
Validation loss: 1.4944125221621605

Epoch: 6| Step: 3
Training loss: 0.16094180941581726
Validation loss: 1.4784597837796776

Epoch: 6| Step: 4
Training loss: 0.08771021664142609
Validation loss: 1.5093301162924817

Epoch: 6| Step: 5
Training loss: 0.14232705533504486
Validation loss: 1.5137658785748225

Epoch: 6| Step: 6
Training loss: 0.09266459196805954
Validation loss: 1.4854070935198056

Epoch: 6| Step: 7
Training loss: 0.07878988981246948
Validation loss: 1.5170887195935814

Epoch: 6| Step: 8
Training loss: 0.27123090624809265
Validation loss: 1.4808798182395198

Epoch: 6| Step: 9
Training loss: 0.14375720918178558
Validation loss: 1.467998448238578

Epoch: 6| Step: 10
Training loss: 0.1549730896949768
Validation loss: 1.4648543455267464

Epoch: 6| Step: 11
Training loss: 0.16733840107917786
Validation loss: 1.4708947276556363

Epoch: 6| Step: 12
Training loss: 0.08129571378231049
Validation loss: 1.4016553278892272

Epoch: 6| Step: 13
Training loss: 0.11897514760494232
Validation loss: 1.4081219370647142

Epoch: 415| Step: 0
Training loss: 0.10448059439659119
Validation loss: 1.4122407256916005

Epoch: 6| Step: 1
Training loss: 0.10190258920192719
Validation loss: 1.4103898027891755

Epoch: 6| Step: 2
Training loss: 0.13377651572227478
Validation loss: 1.4411147320142357

Epoch: 6| Step: 3
Training loss: 0.1309950053691864
Validation loss: 1.4357545914188508

Epoch: 6| Step: 4
Training loss: 0.14177654683589935
Validation loss: 1.4665549749969153

Epoch: 6| Step: 5
Training loss: 0.13903196156024933
Validation loss: 1.487499172969531

Epoch: 6| Step: 6
Training loss: 0.2442067414522171
Validation loss: 1.483256419499715

Epoch: 6| Step: 7
Training loss: 0.20524996519088745
Validation loss: 1.5343280979382095

Epoch: 6| Step: 8
Training loss: 0.20017622411251068
Validation loss: 1.5405524828100716

Epoch: 6| Step: 9
Training loss: 0.10211962461471558
Validation loss: 1.5147758792805415

Epoch: 6| Step: 10
Training loss: 0.201627716422081
Validation loss: 1.5219944741136284

Epoch: 6| Step: 11
Training loss: 0.1853720247745514
Validation loss: 1.4983136038626395

Epoch: 6| Step: 12
Training loss: 0.17928831279277802
Validation loss: 1.510741667080951

Epoch: 6| Step: 13
Training loss: 0.07690710574388504
Validation loss: 1.4896260051317112

Epoch: 416| Step: 0
Training loss: 0.09747567772865295
Validation loss: 1.4850583653296194

Epoch: 6| Step: 1
Training loss: 0.17257022857666016
Validation loss: 1.4940745369080575

Epoch: 6| Step: 2
Training loss: 0.10316981375217438
Validation loss: 1.484958101344365

Epoch: 6| Step: 3
Training loss: 0.13102956116199493
Validation loss: 1.4866307538042787

Epoch: 6| Step: 4
Training loss: 0.08514519780874252
Validation loss: 1.446244316716348

Epoch: 6| Step: 5
Training loss: 0.09777599573135376
Validation loss: 1.4616227085872362

Epoch: 6| Step: 6
Training loss: 0.11552226543426514
Validation loss: 1.4379501727319532

Epoch: 6| Step: 7
Training loss: 0.14436182379722595
Validation loss: 1.4873787433870378

Epoch: 6| Step: 8
Training loss: 0.143214151263237
Validation loss: 1.5194964857511624

Epoch: 6| Step: 9
Training loss: 0.11057307571172714
Validation loss: 1.4973235232855684

Epoch: 6| Step: 10
Training loss: 0.12039663642644882
Validation loss: 1.5074318724293863

Epoch: 6| Step: 11
Training loss: 0.1538359373807907
Validation loss: 1.5045005198447936

Epoch: 6| Step: 12
Training loss: 0.1347193419933319
Validation loss: 1.4852854385170886

Epoch: 6| Step: 13
Training loss: 0.10596825182437897
Validation loss: 1.4883154515297181

Epoch: 417| Step: 0
Training loss: 0.13916230201721191
Validation loss: 1.480923430894011

Epoch: 6| Step: 1
Training loss: 0.0692979097366333
Validation loss: 1.4968026068902784

Epoch: 6| Step: 2
Training loss: 0.1341174691915512
Validation loss: 1.5008326486874652

Epoch: 6| Step: 3
Training loss: 0.15377265214920044
Validation loss: 1.48345382495593

Epoch: 6| Step: 4
Training loss: 0.0804874375462532
Validation loss: 1.467013636583923

Epoch: 6| Step: 5
Training loss: 0.12265558540821075
Validation loss: 1.4594215904512713

Epoch: 6| Step: 6
Training loss: 0.08001865446567535
Validation loss: 1.4441022065378004

Epoch: 6| Step: 7
Training loss: 0.19268517196178436
Validation loss: 1.4247314160869968

Epoch: 6| Step: 8
Training loss: 0.085622638463974
Validation loss: 1.4483073398631106

Epoch: 6| Step: 9
Training loss: 0.17263263463974
Validation loss: 1.4424987518659202

Epoch: 6| Step: 10
Training loss: 0.1350984275341034
Validation loss: 1.4691971027722923

Epoch: 6| Step: 11
Training loss: 0.11101342737674713
Validation loss: 1.4448531744300679

Epoch: 6| Step: 12
Training loss: 0.10507217049598694
Validation loss: 1.4519054428223641

Epoch: 6| Step: 13
Training loss: 0.06536850333213806
Validation loss: 1.4521512882683867

Epoch: 418| Step: 0
Training loss: 0.09916169196367264
Validation loss: 1.45564866065979

Epoch: 6| Step: 1
Training loss: 0.09550216048955917
Validation loss: 1.4482816355202788

Epoch: 6| Step: 2
Training loss: 0.1229945719242096
Validation loss: 1.4919414443354453

Epoch: 6| Step: 3
Training loss: 0.07877697050571442
Validation loss: 1.4688021572687293

Epoch: 6| Step: 4
Training loss: 0.14113909006118774
Validation loss: 1.4712471372337752

Epoch: 6| Step: 5
Training loss: 0.10475146025419235
Validation loss: 1.4702774593907018

Epoch: 6| Step: 6
Training loss: 0.09356603026390076
Validation loss: 1.4359545707702637

Epoch: 6| Step: 7
Training loss: 0.16064903140068054
Validation loss: 1.4427276247291154

Epoch: 6| Step: 8
Training loss: 0.1756868064403534
Validation loss: 1.4612239483864076

Epoch: 6| Step: 9
Training loss: 0.12719795107841492
Validation loss: 1.4788943208673948

Epoch: 6| Step: 10
Training loss: 0.13646160066127777
Validation loss: 1.4548648134354623

Epoch: 6| Step: 11
Training loss: 0.11900173127651215
Validation loss: 1.4514910046772291

Epoch: 6| Step: 12
Training loss: 0.09140489995479584
Validation loss: 1.464392706912051

Epoch: 6| Step: 13
Training loss: 0.1917782574892044
Validation loss: 1.49625015002425

Epoch: 419| Step: 0
Training loss: 0.07676571607589722
Validation loss: 1.4829307025478733

Epoch: 6| Step: 1
Training loss: 0.24247676134109497
Validation loss: 1.4504038749202606

Epoch: 6| Step: 2
Training loss: 0.08388558030128479
Validation loss: 1.451765509061916

Epoch: 6| Step: 3
Training loss: 0.14989107847213745
Validation loss: 1.4499879716545023

Epoch: 6| Step: 4
Training loss: 0.08329597860574722
Validation loss: 1.452843927568005

Epoch: 6| Step: 5
Training loss: 0.08156894892454147
Validation loss: 1.4480279248247865

Epoch: 6| Step: 6
Training loss: 0.12676402926445007
Validation loss: 1.4213383761785363

Epoch: 6| Step: 7
Training loss: 0.12109176814556122
Validation loss: 1.438659844859954

Epoch: 6| Step: 8
Training loss: 0.09430181980133057
Validation loss: 1.3958233530803392

Epoch: 6| Step: 9
Training loss: 0.11454316973686218
Validation loss: 1.4428594022668817

Epoch: 6| Step: 10
Training loss: 0.13114072382450104
Validation loss: 1.440609476899588

Epoch: 6| Step: 11
Training loss: 0.12585437297821045
Validation loss: 1.4253271754069994

Epoch: 6| Step: 12
Training loss: 0.10729978233575821
Validation loss: 1.4292752691494521

Epoch: 6| Step: 13
Training loss: 0.0863865315914154
Validation loss: 1.4359155342143068

Epoch: 420| Step: 0
Training loss: 0.16260552406311035
Validation loss: 1.4608892497195993

Epoch: 6| Step: 1
Training loss: 0.08584318310022354
Validation loss: 1.4558364845091296

Epoch: 6| Step: 2
Training loss: 0.17669400572776794
Validation loss: 1.460560917854309

Epoch: 6| Step: 3
Training loss: 0.12517184019088745
Validation loss: 1.4768594887948805

Epoch: 6| Step: 4
Training loss: 0.09226533770561218
Validation loss: 1.4784597799342165

Epoch: 6| Step: 5
Training loss: 0.157026007771492
Validation loss: 1.470439064887262

Epoch: 6| Step: 6
Training loss: 0.11807151138782501
Validation loss: 1.481713468028653

Epoch: 6| Step: 7
Training loss: 0.10665205121040344
Validation loss: 1.5026576211375575

Epoch: 6| Step: 8
Training loss: 0.0776790976524353
Validation loss: 1.486071958336779

Epoch: 6| Step: 9
Training loss: 0.17428770661354065
Validation loss: 1.475138436081589

Epoch: 6| Step: 10
Training loss: 0.13544237613677979
Validation loss: 1.496407502440996

Epoch: 6| Step: 11
Training loss: 0.13612326979637146
Validation loss: 1.4695427930483254

Epoch: 6| Step: 12
Training loss: 0.15884152054786682
Validation loss: 1.4761270553834978

Epoch: 6| Step: 13
Training loss: 0.10599014163017273
Validation loss: 1.4564544443161256

Epoch: 421| Step: 0
Training loss: 0.11038300395011902
Validation loss: 1.5112667327286096

Epoch: 6| Step: 1
Training loss: 0.11581729352474213
Validation loss: 1.4635171441621677

Epoch: 6| Step: 2
Training loss: 0.1406652331352234
Validation loss: 1.4703421156893495

Epoch: 6| Step: 3
Training loss: 0.13840320706367493
Validation loss: 1.4691093801170267

Epoch: 6| Step: 4
Training loss: 0.12165190279483795
Validation loss: 1.4611439653622207

Epoch: 6| Step: 5
Training loss: 0.13758760690689087
Validation loss: 1.462622578426074

Epoch: 6| Step: 6
Training loss: 0.14223894476890564
Validation loss: 1.4642795439689391

Epoch: 6| Step: 7
Training loss: 0.13891610503196716
Validation loss: 1.4767946081776773

Epoch: 6| Step: 8
Training loss: 0.10651659220457077
Validation loss: 1.4757352022714512

Epoch: 6| Step: 9
Training loss: 0.0667654350399971
Validation loss: 1.4329323666070097

Epoch: 6| Step: 10
Training loss: 0.12375586479902267
Validation loss: 1.4707449674606323

Epoch: 6| Step: 11
Training loss: 0.10597779601812363
Validation loss: 1.501469260902815

Epoch: 6| Step: 12
Training loss: 0.10320903360843658
Validation loss: 1.4576825095761208

Epoch: 6| Step: 13
Training loss: 0.1469038724899292
Validation loss: 1.4913827142407816

Epoch: 422| Step: 0
Training loss: 0.1581631600856781
Validation loss: 1.4898822563950733

Epoch: 6| Step: 1
Training loss: 0.13926711678504944
Validation loss: 1.49655734339068

Epoch: 6| Step: 2
Training loss: 0.20237521827220917
Validation loss: 1.4790926864070277

Epoch: 6| Step: 3
Training loss: 0.16630366444587708
Validation loss: 1.4971327884222871

Epoch: 6| Step: 4
Training loss: 0.08693519234657288
Validation loss: 1.4949137651792137

Epoch: 6| Step: 5
Training loss: 0.11564049869775772
Validation loss: 1.4893064383537538

Epoch: 6| Step: 6
Training loss: 0.10065235197544098
Validation loss: 1.4656892309906662

Epoch: 6| Step: 7
Training loss: 0.14516539871692657
Validation loss: 1.4875298123205862

Epoch: 6| Step: 8
Training loss: 0.12953893840312958
Validation loss: 1.4799671032095467

Epoch: 6| Step: 9
Training loss: 0.13721990585327148
Validation loss: 1.4710008380233601

Epoch: 6| Step: 10
Training loss: 0.07722368836402893
Validation loss: 1.476570026848906

Epoch: 6| Step: 11
Training loss: 0.1724555790424347
Validation loss: 1.497074693761846

Epoch: 6| Step: 12
Training loss: 0.09474892914295197
Validation loss: 1.4813487581027451

Epoch: 6| Step: 13
Training loss: 0.05098501592874527
Validation loss: 1.4946425255908762

Epoch: 423| Step: 0
Training loss: 0.10028666257858276
Validation loss: 1.4816810777110438

Epoch: 6| Step: 1
Training loss: 0.1025005504488945
Validation loss: 1.4542872059729792

Epoch: 6| Step: 2
Training loss: 0.10881048440933228
Validation loss: 1.4673413089526597

Epoch: 6| Step: 3
Training loss: 0.08728156983852386
Validation loss: 1.4429678686203495

Epoch: 6| Step: 4
Training loss: 0.09517604112625122
Validation loss: 1.4822758218293548

Epoch: 6| Step: 5
Training loss: 0.15291838347911835
Validation loss: 1.5119019862144225

Epoch: 6| Step: 6
Training loss: 0.1788361817598343
Validation loss: 1.4921357183046238

Epoch: 6| Step: 7
Training loss: 0.10754692554473877
Validation loss: 1.533211213286205

Epoch: 6| Step: 8
Training loss: 0.14300090074539185
Validation loss: 1.4713928904584659

Epoch: 6| Step: 9
Training loss: 0.0865878164768219
Validation loss: 1.4598988512510895

Epoch: 6| Step: 10
Training loss: 0.25626111030578613
Validation loss: 1.4272286891937256

Epoch: 6| Step: 11
Training loss: 0.11376015096902847
Validation loss: 1.4276135416441067

Epoch: 6| Step: 12
Training loss: 0.12696732580661774
Validation loss: 1.4578269271440403

Epoch: 6| Step: 13
Training loss: 0.18174511194229126
Validation loss: 1.438601392571644

Epoch: 424| Step: 0
Training loss: 0.12045061588287354
Validation loss: 1.4474096842991409

Epoch: 6| Step: 1
Training loss: 0.1108931377530098
Validation loss: 1.4313277506059217

Epoch: 6| Step: 2
Training loss: 0.15962977707386017
Validation loss: 1.4339245384739292

Epoch: 6| Step: 3
Training loss: 0.12163220345973969
Validation loss: 1.4403775968859274

Epoch: 6| Step: 4
Training loss: 0.10619721561670303
Validation loss: 1.4362096427589335

Epoch: 6| Step: 5
Training loss: 0.11175927519798279
Validation loss: 1.4326825141906738

Epoch: 6| Step: 6
Training loss: 0.08723670244216919
Validation loss: 1.4425764827318088

Epoch: 6| Step: 7
Training loss: 0.10811919718980789
Validation loss: 1.4361790892898396

Epoch: 6| Step: 8
Training loss: 0.12284783273935318
Validation loss: 1.4507548360414402

Epoch: 6| Step: 9
Training loss: 0.13346852362155914
Validation loss: 1.440303816590258

Epoch: 6| Step: 10
Training loss: 0.09744038432836533
Validation loss: 1.4424437040923743

Epoch: 6| Step: 11
Training loss: 0.09424850344657898
Validation loss: 1.4559102827502834

Epoch: 6| Step: 12
Training loss: 0.06702914834022522
Validation loss: 1.4520538237787062

Epoch: 6| Step: 13
Training loss: 0.09798678755760193
Validation loss: 1.4633291434216242

Epoch: 425| Step: 0
Training loss: 0.1552574634552002
Validation loss: 1.4651485053441857

Epoch: 6| Step: 1
Training loss: 0.1120910719037056
Validation loss: 1.4814284975810716

Epoch: 6| Step: 2
Training loss: 0.16352833807468414
Validation loss: 1.488567284358445

Epoch: 6| Step: 3
Training loss: 0.12153781950473785
Validation loss: 1.4923207259947253

Epoch: 6| Step: 4
Training loss: 0.13238975405693054
Validation loss: 1.490389702140644

Epoch: 6| Step: 5
Training loss: 0.06794095784425735
Validation loss: 1.5060367532955703

Epoch: 6| Step: 6
Training loss: 0.1275697648525238
Validation loss: 1.4865263559484994

Epoch: 6| Step: 7
Training loss: 0.2140132635831833
Validation loss: 1.5082978663905975

Epoch: 6| Step: 8
Training loss: 0.09365114569664001
Validation loss: 1.490023184848088

Epoch: 6| Step: 9
Training loss: 0.19240066409111023
Validation loss: 1.4804064266143306

Epoch: 6| Step: 10
Training loss: 0.13682717084884644
Validation loss: 1.4829374462045648

Epoch: 6| Step: 11
Training loss: 0.06627210974693298
Validation loss: 1.4739448191017233

Epoch: 6| Step: 12
Training loss: 0.07355573773384094
Validation loss: 1.4723031392661474

Epoch: 6| Step: 13
Training loss: 0.10430925339460373
Validation loss: 1.4672962311775453

Epoch: 426| Step: 0
Training loss: 0.10172399878501892
Validation loss: 1.4311958128406155

Epoch: 6| Step: 1
Training loss: 0.10810210555791855
Validation loss: 1.442327013579748

Epoch: 6| Step: 2
Training loss: 0.11590820550918579
Validation loss: 1.452240228652954

Epoch: 6| Step: 3
Training loss: 0.17150720953941345
Validation loss: 1.475384243073002

Epoch: 6| Step: 4
Training loss: 0.22890150547027588
Validation loss: 1.4515126776951615

Epoch: 6| Step: 5
Training loss: 0.10258062183856964
Validation loss: 1.4698317691843996

Epoch: 6| Step: 6
Training loss: 0.19757121801376343
Validation loss: 1.4547419432670838

Epoch: 6| Step: 7
Training loss: 0.22133252024650574
Validation loss: 1.4546631895085818

Epoch: 6| Step: 8
Training loss: 0.08946090936660767
Validation loss: 1.4222232872439968

Epoch: 6| Step: 9
Training loss: 0.06375384330749512
Validation loss: 1.4339925140462897

Epoch: 6| Step: 10
Training loss: 0.11356626451015472
Validation loss: 1.4456110128792383

Epoch: 6| Step: 11
Training loss: 0.10620149970054626
Validation loss: 1.4806995212390859

Epoch: 6| Step: 12
Training loss: 0.09045928716659546
Validation loss: 1.4939912467874505

Epoch: 6| Step: 13
Training loss: 0.10415530204772949
Validation loss: 1.491408750575076

Epoch: 427| Step: 0
Training loss: 0.14637956023216248
Validation loss: 1.4924896365852767

Epoch: 6| Step: 1
Training loss: 0.12605178356170654
Validation loss: 1.5016541846336857

Epoch: 6| Step: 2
Training loss: 0.16119202971458435
Validation loss: 1.4760938344463226

Epoch: 6| Step: 3
Training loss: 0.08689524978399277
Validation loss: 1.4704911766513702

Epoch: 6| Step: 4
Training loss: 0.14803427457809448
Validation loss: 1.4785517133692259

Epoch: 6| Step: 5
Training loss: 0.10197625309228897
Validation loss: 1.458154527089929

Epoch: 6| Step: 6
Training loss: 0.08537392318248749
Validation loss: 1.4142297339695755

Epoch: 6| Step: 7
Training loss: 0.09045909345149994
Validation loss: 1.4453509360231378

Epoch: 6| Step: 8
Training loss: 0.1743440330028534
Validation loss: 1.4443209863478137

Epoch: 6| Step: 9
Training loss: 0.08868438005447388
Validation loss: 1.4511397859101653

Epoch: 6| Step: 10
Training loss: 0.11421726644039154
Validation loss: 1.4150866218792495

Epoch: 6| Step: 11
Training loss: 0.11451192200183868
Validation loss: 1.4333719668849823

Epoch: 6| Step: 12
Training loss: 0.16073405742645264
Validation loss: 1.4590105266981228

Epoch: 6| Step: 13
Training loss: 0.1387748271226883
Validation loss: 1.4064697206661265

Epoch: 428| Step: 0
Training loss: 0.08116841316223145
Validation loss: 1.4629793423478321

Epoch: 6| Step: 1
Training loss: 0.06944338232278824
Validation loss: 1.441972759462172

Epoch: 6| Step: 2
Training loss: 0.1399884819984436
Validation loss: 1.4474052857327204

Epoch: 6| Step: 3
Training loss: 0.13002172112464905
Validation loss: 1.4548286994298298

Epoch: 6| Step: 4
Training loss: 0.09411865472793579
Validation loss: 1.4523925755613594

Epoch: 6| Step: 5
Training loss: 0.0952330082654953
Validation loss: 1.4404562865534136

Epoch: 6| Step: 6
Training loss: 0.07665075361728668
Validation loss: 1.4535625096290343

Epoch: 6| Step: 7
Training loss: 0.11579249799251556
Validation loss: 1.45198025754703

Epoch: 6| Step: 8
Training loss: 0.06889939308166504
Validation loss: 1.4574399904538227

Epoch: 6| Step: 9
Training loss: 0.1155480146408081
Validation loss: 1.4469200898242254

Epoch: 6| Step: 10
Training loss: 0.10369415581226349
Validation loss: 1.4114505808840516

Epoch: 6| Step: 11
Training loss: 0.13584834337234497
Validation loss: 1.44644877090249

Epoch: 6| Step: 12
Training loss: 0.10529226064682007
Validation loss: 1.4475421033879763

Epoch: 6| Step: 13
Training loss: 0.12289614230394363
Validation loss: 1.402744576495181

Epoch: 429| Step: 0
Training loss: 0.10123521834611893
Validation loss: 1.3965598549894107

Epoch: 6| Step: 1
Training loss: 0.12636122107505798
Validation loss: 1.43850250141595

Epoch: 6| Step: 2
Training loss: 0.10054197162389755
Validation loss: 1.4374322032415738

Epoch: 6| Step: 3
Training loss: 0.08934387564659119
Validation loss: 1.40818969216398

Epoch: 6| Step: 4
Training loss: 0.10937771946191788
Validation loss: 1.4348430428453671

Epoch: 6| Step: 5
Training loss: 0.16188013553619385
Validation loss: 1.4209011780318392

Epoch: 6| Step: 6
Training loss: 0.14995472133159637
Validation loss: 1.3856230628105901

Epoch: 6| Step: 7
Training loss: 0.09384851902723312
Validation loss: 1.398124373087319

Epoch: 6| Step: 8
Training loss: 0.10830411314964294
Validation loss: 1.4311694816876483

Epoch: 6| Step: 9
Training loss: 0.06913437694311142
Validation loss: 1.4480179766173005

Epoch: 6| Step: 10
Training loss: 0.13102202117443085
Validation loss: 1.429439466486695

Epoch: 6| Step: 11
Training loss: 0.14661452174186707
Validation loss: 1.4323909590321202

Epoch: 6| Step: 12
Training loss: 0.14272229373455048
Validation loss: 1.4371720026898127

Epoch: 6| Step: 13
Training loss: 0.17575538158416748
Validation loss: 1.42008505200827

Epoch: 430| Step: 0
Training loss: 0.09692078828811646
Validation loss: 1.4455633445452618

Epoch: 6| Step: 1
Training loss: 0.1829061210155487
Validation loss: 1.4455911215915476

Epoch: 6| Step: 2
Training loss: 0.1333976835012436
Validation loss: 1.393034827324652

Epoch: 6| Step: 3
Training loss: 0.17168064415454865
Validation loss: 1.4427616852585987

Epoch: 6| Step: 4
Training loss: 0.1847917139530182
Validation loss: 1.4445662793292795

Epoch: 6| Step: 5
Training loss: 0.10667100548744202
Validation loss: 1.4663185393938454

Epoch: 6| Step: 6
Training loss: 0.1430845707654953
Validation loss: 1.4268390626035712

Epoch: 6| Step: 7
Training loss: 0.10145775973796844
Validation loss: 1.4742176302017704

Epoch: 6| Step: 8
Training loss: 0.06813416630029678
Validation loss: 1.475929157708281

Epoch: 6| Step: 9
Training loss: 0.07311204075813293
Validation loss: 1.4649511024516115

Epoch: 6| Step: 10
Training loss: 0.09695996344089508
Validation loss: 1.4397716188943515

Epoch: 6| Step: 11
Training loss: 0.12147682160139084
Validation loss: 1.4917242065552743

Epoch: 6| Step: 12
Training loss: 0.11883731186389923
Validation loss: 1.468147696346365

Epoch: 6| Step: 13
Training loss: 0.14810849726200104
Validation loss: 1.4505508112651047

Epoch: 431| Step: 0
Training loss: 0.07130201160907745
Validation loss: 1.4726072857456822

Epoch: 6| Step: 1
Training loss: 0.1591401994228363
Validation loss: 1.4638416395392468

Epoch: 6| Step: 2
Training loss: 0.11719545722007751
Validation loss: 1.445850504982856

Epoch: 6| Step: 3
Training loss: 0.10823198407888412
Validation loss: 1.4508768525174869

Epoch: 6| Step: 4
Training loss: 0.18619400262832642
Validation loss: 1.4396629730860393

Epoch: 6| Step: 5
Training loss: 0.10797889530658722
Validation loss: 1.4595637321472168

Epoch: 6| Step: 6
Training loss: 0.13038289546966553
Validation loss: 1.4280857591218845

Epoch: 6| Step: 7
Training loss: 0.11113077402114868
Validation loss: 1.433964919018489

Epoch: 6| Step: 8
Training loss: 0.09723822772502899
Validation loss: 1.4415051437193347

Epoch: 6| Step: 9
Training loss: 0.08377869427204132
Validation loss: 1.4359595365421747

Epoch: 6| Step: 10
Training loss: 0.13884373009204865
Validation loss: 1.4192076037006993

Epoch: 6| Step: 11
Training loss: 0.13768237829208374
Validation loss: 1.4018223016492781

Epoch: 6| Step: 12
Training loss: 0.09660165011882782
Validation loss: 1.417375914512142

Epoch: 6| Step: 13
Training loss: 0.10854323953390121
Validation loss: 1.4109525808724024

Epoch: 432| Step: 0
Training loss: 0.13143375515937805
Validation loss: 1.4320598738167876

Epoch: 6| Step: 1
Training loss: 0.1754613220691681
Validation loss: 1.4273241771164762

Epoch: 6| Step: 2
Training loss: 0.10117816179990768
Validation loss: 1.417855510147669

Epoch: 6| Step: 3
Training loss: 0.10931792855262756
Validation loss: 1.4398921055178489

Epoch: 6| Step: 4
Training loss: 0.09299251437187195
Validation loss: 1.4363578455422514

Epoch: 6| Step: 5
Training loss: 0.09317055344581604
Validation loss: 1.4779804047717844

Epoch: 6| Step: 6
Training loss: 0.0990416556596756
Validation loss: 1.5119459731604463

Epoch: 6| Step: 7
Training loss: 0.14665630459785461
Validation loss: 1.4926144820387646

Epoch: 6| Step: 8
Training loss: 0.11186204105615616
Validation loss: 1.5040639433809506

Epoch: 6| Step: 9
Training loss: 0.14047250151634216
Validation loss: 1.5067063954568678

Epoch: 6| Step: 10
Training loss: 0.09602262079715729
Validation loss: 1.5177407085254628

Epoch: 6| Step: 11
Training loss: 0.21366916596889496
Validation loss: 1.4872329927259875

Epoch: 6| Step: 12
Training loss: 0.18193915486335754
Validation loss: 1.509565725121447

Epoch: 6| Step: 13
Training loss: 0.11478167027235031
Validation loss: 1.5315466888489262

Epoch: 433| Step: 0
Training loss: 0.0881062000989914
Validation loss: 1.5162062439867245

Epoch: 6| Step: 1
Training loss: 0.21108466386795044
Validation loss: 1.5277598404115247

Epoch: 6| Step: 2
Training loss: 0.13136710226535797
Validation loss: 1.525109928141358

Epoch: 6| Step: 3
Training loss: 0.14546817541122437
Validation loss: 1.5208277176785212

Epoch: 6| Step: 4
Training loss: 0.09937086701393127
Validation loss: 1.4911899259013515

Epoch: 6| Step: 5
Training loss: 0.10505958646535873
Validation loss: 1.5081088619847451

Epoch: 6| Step: 6
Training loss: 0.07801254093647003
Validation loss: 1.4950563048803678

Epoch: 6| Step: 7
Training loss: 0.06555294245481491
Validation loss: 1.4830161935539656

Epoch: 6| Step: 8
Training loss: 0.157445028424263
Validation loss: 1.4724145640609085

Epoch: 6| Step: 9
Training loss: 0.07185836136341095
Validation loss: 1.491850209492509

Epoch: 6| Step: 10
Training loss: 0.29232650995254517
Validation loss: 1.4907871536029282

Epoch: 6| Step: 11
Training loss: 0.11259227991104126
Validation loss: 1.5208613628982215

Epoch: 6| Step: 12
Training loss: 0.1392979621887207
Validation loss: 1.5380005721122987

Epoch: 6| Step: 13
Training loss: 0.1984603852033615
Validation loss: 1.5065796593184113

Epoch: 434| Step: 0
Training loss: 0.10514508187770844
Validation loss: 1.517005362818318

Epoch: 6| Step: 1
Training loss: 0.07489795982837677
Validation loss: 1.480034471839987

Epoch: 6| Step: 2
Training loss: 0.1180986613035202
Validation loss: 1.503043350993946

Epoch: 6| Step: 3
Training loss: 0.11048483103513718
Validation loss: 1.46950287459999

Epoch: 6| Step: 4
Training loss: 0.1754913628101349
Validation loss: 1.4750943299262755

Epoch: 6| Step: 5
Training loss: 0.13303866982460022
Validation loss: 1.4663993748285438

Epoch: 6| Step: 6
Training loss: 0.10605894029140472
Validation loss: 1.4700328098830355

Epoch: 6| Step: 7
Training loss: 0.08681684732437134
Validation loss: 1.4661926774568455

Epoch: 6| Step: 8
Training loss: 0.14522208273410797
Validation loss: 1.4527537976541827

Epoch: 6| Step: 9
Training loss: 0.1515119969844818
Validation loss: 1.457553517433905

Epoch: 6| Step: 10
Training loss: 0.10708300769329071
Validation loss: 1.4150556364367086

Epoch: 6| Step: 11
Training loss: 0.1883544623851776
Validation loss: 1.4420611890413428

Epoch: 6| Step: 12
Training loss: 0.07916571199893951
Validation loss: 1.4268393324267479

Epoch: 6| Step: 13
Training loss: 0.10026592016220093
Validation loss: 1.4202445412194857

Epoch: 435| Step: 0
Training loss: 0.12393949925899506
Validation loss: 1.4613422296380485

Epoch: 6| Step: 1
Training loss: 0.13460305333137512
Validation loss: 1.4349103486666115

Epoch: 6| Step: 2
Training loss: 0.13331633806228638
Validation loss: 1.465001247903352

Epoch: 6| Step: 3
Training loss: 0.1142011508345604
Validation loss: 1.4496478137149607

Epoch: 6| Step: 4
Training loss: 0.1142454594373703
Validation loss: 1.4469062814148523

Epoch: 6| Step: 5
Training loss: 0.08250361680984497
Validation loss: 1.4373710014486825

Epoch: 6| Step: 6
Training loss: 0.15724250674247742
Validation loss: 1.4348644594992361

Epoch: 6| Step: 7
Training loss: 0.11634482443332672
Validation loss: 1.425481532209663

Epoch: 6| Step: 8
Training loss: 0.15719565749168396
Validation loss: 1.4413418167380876

Epoch: 6| Step: 9
Training loss: 0.1306353509426117
Validation loss: 1.3960142174074728

Epoch: 6| Step: 10
Training loss: 0.07953254878520966
Validation loss: 1.4289245464468514

Epoch: 6| Step: 11
Training loss: 0.10291808843612671
Validation loss: 1.426664219107679

Epoch: 6| Step: 12
Training loss: 0.07464432716369629
Validation loss: 1.4317646103520547

Epoch: 6| Step: 13
Training loss: 0.11668048799037933
Validation loss: 1.463201052399092

Epoch: 436| Step: 0
Training loss: 0.08717547357082367
Validation loss: 1.4141026696851176

Epoch: 6| Step: 1
Training loss: 0.05875834822654724
Validation loss: 1.4401178270257928

Epoch: 6| Step: 2
Training loss: 0.0797654315829277
Validation loss: 1.4574993477072766

Epoch: 6| Step: 3
Training loss: 0.11686969548463821
Validation loss: 1.4447462597200948

Epoch: 6| Step: 4
Training loss: 0.059578850865364075
Validation loss: 1.442300727931402

Epoch: 6| Step: 5
Training loss: 0.06276065111160278
Validation loss: 1.444788243180962

Epoch: 6| Step: 6
Training loss: 0.12972381711006165
Validation loss: 1.4421245026332077

Epoch: 6| Step: 7
Training loss: 0.14307038486003876
Validation loss: 1.4446617172610374

Epoch: 6| Step: 8
Training loss: 0.1445368081331253
Validation loss: 1.4515265341727965

Epoch: 6| Step: 9
Training loss: 0.18795928359031677
Validation loss: 1.482218917979989

Epoch: 6| Step: 10
Training loss: 0.12175649404525757
Validation loss: 1.4546014179465592

Epoch: 6| Step: 11
Training loss: 0.06920171529054642
Validation loss: 1.4423696469235163

Epoch: 6| Step: 12
Training loss: 0.06748579442501068
Validation loss: 1.482979230983283

Epoch: 6| Step: 13
Training loss: 0.08602631092071533
Validation loss: 1.4549057522127706

Epoch: 437| Step: 0
Training loss: 0.1307593137025833
Validation loss: 1.452368865730942

Epoch: 6| Step: 1
Training loss: 0.10399745404720306
Validation loss: 1.4353917593597083

Epoch: 6| Step: 2
Training loss: 0.09689608216285706
Validation loss: 1.451421267242842

Epoch: 6| Step: 3
Training loss: 0.09161116927862167
Validation loss: 1.4837259105456773

Epoch: 6| Step: 4
Training loss: 0.11199600994586945
Validation loss: 1.4225088563016666

Epoch: 6| Step: 5
Training loss: 0.12367812544107437
Validation loss: 1.4592492888050694

Epoch: 6| Step: 6
Training loss: 0.11434702575206757
Validation loss: 1.461176389007158

Epoch: 6| Step: 7
Training loss: 0.09903644770383835
Validation loss: 1.4383899742557156

Epoch: 6| Step: 8
Training loss: 0.12407926470041275
Validation loss: 1.4482716873127928

Epoch: 6| Step: 9
Training loss: 0.11571592092514038
Validation loss: 1.4552354094802693

Epoch: 6| Step: 10
Training loss: 0.10693056881427765
Validation loss: 1.450799879207406

Epoch: 6| Step: 11
Training loss: 0.08901536464691162
Validation loss: 1.4793105817610217

Epoch: 6| Step: 12
Training loss: 0.14418277144432068
Validation loss: 1.4539674840947634

Epoch: 6| Step: 13
Training loss: 0.0999736413359642
Validation loss: 1.457818046692879

Epoch: 438| Step: 0
Training loss: 0.15816891193389893
Validation loss: 1.4427458432412916

Epoch: 6| Step: 1
Training loss: 0.07530608028173447
Validation loss: 1.4543785600252048

Epoch: 6| Step: 2
Training loss: 0.0818498507142067
Validation loss: 1.4354965007433327

Epoch: 6| Step: 3
Training loss: 0.08678038418292999
Validation loss: 1.4654496100641066

Epoch: 6| Step: 4
Training loss: 0.12382445484399796
Validation loss: 1.413431353466485

Epoch: 6| Step: 5
Training loss: 0.14315809309482574
Validation loss: 1.471806300583706

Epoch: 6| Step: 6
Training loss: 0.08157003670930862
Validation loss: 1.4548926622636857

Epoch: 6| Step: 7
Training loss: 0.11699629575014114
Validation loss: 1.4448721306298369

Epoch: 6| Step: 8
Training loss: 0.13877543807029724
Validation loss: 1.4664133082153976

Epoch: 6| Step: 9
Training loss: 0.11167497932910919
Validation loss: 1.446505779861122

Epoch: 6| Step: 10
Training loss: 0.11565443873405457
Validation loss: 1.449843898896248

Epoch: 6| Step: 11
Training loss: 0.11785628646612167
Validation loss: 1.4264609358643974

Epoch: 6| Step: 12
Training loss: 0.09618493914604187
Validation loss: 1.4597387672752462

Epoch: 6| Step: 13
Training loss: 0.07163284718990326
Validation loss: 1.4214153610250002

Epoch: 439| Step: 0
Training loss: 0.08344951272010803
Validation loss: 1.4030726404600247

Epoch: 6| Step: 1
Training loss: 0.13319048285484314
Validation loss: 1.4146984495142454

Epoch: 6| Step: 2
Training loss: 0.09360023587942123
Validation loss: 1.4153965416774954

Epoch: 6| Step: 3
Training loss: 0.14534759521484375
Validation loss: 1.4036591309373097

Epoch: 6| Step: 4
Training loss: 0.10904760658740997
Validation loss: 1.4013018736275293

Epoch: 6| Step: 5
Training loss: 0.14041410386562347
Validation loss: 1.4433501484573528

Epoch: 6| Step: 6
Training loss: 0.11671893298625946
Validation loss: 1.439056973303518

Epoch: 6| Step: 7
Training loss: 0.13501203060150146
Validation loss: 1.4330867259733138

Epoch: 6| Step: 8
Training loss: 0.16401685774326324
Validation loss: 1.432589985991037

Epoch: 6| Step: 9
Training loss: 0.11241459846496582
Validation loss: 1.4529915830140472

Epoch: 6| Step: 10
Training loss: 0.14301681518554688
Validation loss: 1.475668361110072

Epoch: 6| Step: 11
Training loss: 0.07540838420391083
Validation loss: 1.4386418852754819

Epoch: 6| Step: 12
Training loss: 0.15585964918136597
Validation loss: 1.4745706909446306

Epoch: 6| Step: 13
Training loss: 0.06653806567192078
Validation loss: 1.3924398242786367

Epoch: 440| Step: 0
Training loss: 0.07975316792726517
Validation loss: 1.3828159698876001

Epoch: 6| Step: 1
Training loss: 0.08534315228462219
Validation loss: 1.4221515027425622

Epoch: 6| Step: 2
Training loss: 0.11839163303375244
Validation loss: 1.3988708475584626

Epoch: 6| Step: 3
Training loss: 0.12125490605831146
Validation loss: 1.422159775610893

Epoch: 6| Step: 4
Training loss: 0.17248579859733582
Validation loss: 1.4361611412417503

Epoch: 6| Step: 5
Training loss: 0.1398339569568634
Validation loss: 1.423431473393594

Epoch: 6| Step: 6
Training loss: 0.14273963868618011
Validation loss: 1.4350847967209355

Epoch: 6| Step: 7
Training loss: 0.07179513573646545
Validation loss: 1.4255243885901667

Epoch: 6| Step: 8
Training loss: 0.17435145378112793
Validation loss: 1.4174185235013244

Epoch: 6| Step: 9
Training loss: 0.14866666495800018
Validation loss: 1.4373027342621998

Epoch: 6| Step: 10
Training loss: 0.09510461986064911
Validation loss: 1.4300017459418184

Epoch: 6| Step: 11
Training loss: 0.11490173637866974
Validation loss: 1.448189627739691

Epoch: 6| Step: 12
Training loss: 0.08676069229841232
Validation loss: 1.4276274993855467

Epoch: 6| Step: 13
Training loss: 0.10348795354366302
Validation loss: 1.4206718462769703

Epoch: 441| Step: 0
Training loss: 0.15912064909934998
Validation loss: 1.4443804961378857

Epoch: 6| Step: 1
Training loss: 0.10799247026443481
Validation loss: 1.4469766796276133

Epoch: 6| Step: 2
Training loss: 0.0638551414012909
Validation loss: 1.3978185166594803

Epoch: 6| Step: 3
Training loss: 0.10197054594755173
Validation loss: 1.4332598665709138

Epoch: 6| Step: 4
Training loss: 0.11744852364063263
Validation loss: 1.3940542795324837

Epoch: 6| Step: 5
Training loss: 0.08178539574146271
Validation loss: 1.4072118484845726

Epoch: 6| Step: 6
Training loss: 0.06806391477584839
Validation loss: 1.4116460149006178

Epoch: 6| Step: 7
Training loss: 0.11542533338069916
Validation loss: 1.4282426090650662

Epoch: 6| Step: 8
Training loss: 0.06517738848924637
Validation loss: 1.4537861475380518

Epoch: 6| Step: 9
Training loss: 0.07989470660686493
Validation loss: 1.4348411252421718

Epoch: 6| Step: 10
Training loss: 0.1891186535358429
Validation loss: 1.4201511734275407

Epoch: 6| Step: 11
Training loss: 0.1287660300731659
Validation loss: 1.467626513332449

Epoch: 6| Step: 12
Training loss: 0.07901901751756668
Validation loss: 1.441062734973046

Epoch: 6| Step: 13
Training loss: 0.18240411579608917
Validation loss: 1.4671447764160812

Epoch: 442| Step: 0
Training loss: 0.08302178978919983
Validation loss: 1.4234396026980491

Epoch: 6| Step: 1
Training loss: 0.0998729020357132
Validation loss: 1.4779665957215011

Epoch: 6| Step: 2
Training loss: 0.10914690047502518
Validation loss: 1.4592069272072083

Epoch: 6| Step: 3
Training loss: 0.11531960964202881
Validation loss: 1.4559637295302523

Epoch: 6| Step: 4
Training loss: 0.10408947616815567
Validation loss: 1.4448188069046184

Epoch: 6| Step: 5
Training loss: 0.09131735563278198
Validation loss: 1.4372369320161882

Epoch: 6| Step: 6
Training loss: 0.10661154240369797
Validation loss: 1.4371793154747254

Epoch: 6| Step: 7
Training loss: 0.12195752561092377
Validation loss: 1.4194270654391217

Epoch: 6| Step: 8
Training loss: 0.07163830101490021
Validation loss: 1.4388210568376767

Epoch: 6| Step: 9
Training loss: 0.0818486213684082
Validation loss: 1.4498794360827374

Epoch: 6| Step: 10
Training loss: 0.14060348272323608
Validation loss: 1.4585414894165531

Epoch: 6| Step: 11
Training loss: 0.11265664547681808
Validation loss: 1.4528117026052167

Epoch: 6| Step: 12
Training loss: 0.09581543505191803
Validation loss: 1.4427913055625012

Epoch: 6| Step: 13
Training loss: 0.17855916917324066
Validation loss: 1.4547040077947802

Epoch: 443| Step: 0
Training loss: 0.14043265581130981
Validation loss: 1.4585481100184943

Epoch: 6| Step: 1
Training loss: 0.0715174674987793
Validation loss: 1.457081243556033

Epoch: 6| Step: 2
Training loss: 0.12921711802482605
Validation loss: 1.4604028130090365

Epoch: 6| Step: 3
Training loss: 0.09858277440071106
Validation loss: 1.4781019162106257

Epoch: 6| Step: 4
Training loss: 0.07115337997674942
Validation loss: 1.4780276693323606

Epoch: 6| Step: 5
Training loss: 0.17048941552639008
Validation loss: 1.498364128733194

Epoch: 6| Step: 6
Training loss: 0.13139820098876953
Validation loss: 1.4896336383717035

Epoch: 6| Step: 7
Training loss: 0.13324378430843353
Validation loss: 1.4794004501834992

Epoch: 6| Step: 8
Training loss: 0.10455255210399628
Validation loss: 1.47187634693679

Epoch: 6| Step: 9
Training loss: 0.10585188865661621
Validation loss: 1.4558734316979685

Epoch: 6| Step: 10
Training loss: 0.12300550937652588
Validation loss: 1.4612532943807623

Epoch: 6| Step: 11
Training loss: 0.118190698325634
Validation loss: 1.4388897220293682

Epoch: 6| Step: 12
Training loss: 0.1498512327671051
Validation loss: 1.468096777956973

Epoch: 6| Step: 13
Training loss: 0.11645841598510742
Validation loss: 1.4440802463921167

Epoch: 444| Step: 0
Training loss: 0.14940744638442993
Validation loss: 1.4518487184278426

Epoch: 6| Step: 1
Training loss: 0.04857734963297844
Validation loss: 1.4387169691824144

Epoch: 6| Step: 2
Training loss: 0.13506236672401428
Validation loss: 1.4320324787529566

Epoch: 6| Step: 3
Training loss: 0.08633725345134735
Validation loss: 1.451628424788034

Epoch: 6| Step: 4
Training loss: 0.188747376203537
Validation loss: 1.4396050104530909

Epoch: 6| Step: 5
Training loss: 0.145150825381279
Validation loss: 1.4428645551845591

Epoch: 6| Step: 6
Training loss: 0.10501459240913391
Validation loss: 1.4492867903042865

Epoch: 6| Step: 7
Training loss: 0.08698970079421997
Validation loss: 1.4819288074329335

Epoch: 6| Step: 8
Training loss: 0.11373300850391388
Validation loss: 1.4604602385592718

Epoch: 6| Step: 9
Training loss: 0.13167539238929749
Validation loss: 1.4299882432465911

Epoch: 6| Step: 10
Training loss: 0.08203917741775513
Validation loss: 1.453608428278277

Epoch: 6| Step: 11
Training loss: 0.14990553259849548
Validation loss: 1.4518134465781591

Epoch: 6| Step: 12
Training loss: 0.1747601330280304
Validation loss: 1.4329753127149356

Epoch: 6| Step: 13
Training loss: 0.08744588494300842
Validation loss: 1.4277881390304976

Epoch: 445| Step: 0
Training loss: 0.11527739465236664
Validation loss: 1.4553439514611357

Epoch: 6| Step: 1
Training loss: 0.09333667159080505
Validation loss: 1.4575464674221572

Epoch: 6| Step: 2
Training loss: 0.09406081587076187
Validation loss: 1.4703409415419384

Epoch: 6| Step: 3
Training loss: 0.1271577775478363
Validation loss: 1.4193590174439132

Epoch: 6| Step: 4
Training loss: 0.14302533864974976
Validation loss: 1.4512040743263819

Epoch: 6| Step: 5
Training loss: 0.17514024674892426
Validation loss: 1.4606979277826124

Epoch: 6| Step: 6
Training loss: 0.12840504944324493
Validation loss: 1.4539873753824542

Epoch: 6| Step: 7
Training loss: 0.1687609851360321
Validation loss: 1.4747308569569741

Epoch: 6| Step: 8
Training loss: 0.11700879782438278
Validation loss: 1.477939651858422

Epoch: 6| Step: 9
Training loss: 0.10593386739492416
Validation loss: 1.456724359143165

Epoch: 6| Step: 10
Training loss: 0.098860964179039
Validation loss: 1.4597982821925994

Epoch: 6| Step: 11
Training loss: 0.08150365203619003
Validation loss: 1.4595167931690012

Epoch: 6| Step: 12
Training loss: 0.14359264075756073
Validation loss: 1.4617875160709504

Epoch: 6| Step: 13
Training loss: 0.1226152554154396
Validation loss: 1.4499334084090365

Epoch: 446| Step: 0
Training loss: 0.1199127733707428
Validation loss: 1.4579680901701733

Epoch: 6| Step: 1
Training loss: 0.05961405113339424
Validation loss: 1.4299405928580993

Epoch: 6| Step: 2
Training loss: 0.13669629395008087
Validation loss: 1.3950157319345782

Epoch: 6| Step: 3
Training loss: 0.1303509622812271
Validation loss: 1.3842940279232558

Epoch: 6| Step: 4
Training loss: 0.12647973001003265
Validation loss: 1.3859347592117965

Epoch: 6| Step: 5
Training loss: 0.10558639466762543
Validation loss: 1.3730551876047605

Epoch: 6| Step: 6
Training loss: 0.10673758387565613
Validation loss: 1.3368824899837535

Epoch: 6| Step: 7
Training loss: 0.14420637488365173
Validation loss: 1.3845595890475857

Epoch: 6| Step: 8
Training loss: 0.1064247414469719
Validation loss: 1.3769163470114432

Epoch: 6| Step: 9
Training loss: 0.172235906124115
Validation loss: 1.372087332510179

Epoch: 6| Step: 10
Training loss: 0.09588409960269928
Validation loss: 1.3618062901240524

Epoch: 6| Step: 11
Training loss: 0.1017407700419426
Validation loss: 1.4202555828197028

Epoch: 6| Step: 12
Training loss: 0.13654494285583496
Validation loss: 1.4093344865306732

Epoch: 6| Step: 13
Training loss: 0.07042974978685379
Validation loss: 1.392828602944651

Epoch: 447| Step: 0
Training loss: 0.1313513219356537
Validation loss: 1.4198635201300345

Epoch: 6| Step: 1
Training loss: 0.14403477311134338
Validation loss: 1.395644562218779

Epoch: 6| Step: 2
Training loss: 0.12320051342248917
Validation loss: 1.436608188895769

Epoch: 6| Step: 3
Training loss: 0.12229441851377487
Validation loss: 1.4378431022808116

Epoch: 6| Step: 4
Training loss: 0.07976852357387543
Validation loss: 1.4447827063580996

Epoch: 6| Step: 5
Training loss: 0.10594382882118225
Validation loss: 1.474456238490279

Epoch: 6| Step: 6
Training loss: 0.13520829379558563
Validation loss: 1.4480883677800496

Epoch: 6| Step: 7
Training loss: 0.10767253488302231
Validation loss: 1.453705810731457

Epoch: 6| Step: 8
Training loss: 0.10904994606971741
Validation loss: 1.4702546455526864

Epoch: 6| Step: 9
Training loss: 0.19654294848442078
Validation loss: 1.4583535373851817

Epoch: 6| Step: 10
Training loss: 0.15131548047065735
Validation loss: 1.4736397804752472

Epoch: 6| Step: 11
Training loss: 0.20313376188278198
Validation loss: 1.488637529393678

Epoch: 6| Step: 12
Training loss: 0.15356427431106567
Validation loss: 1.4696828556317154

Epoch: 6| Step: 13
Training loss: 0.11089435964822769
Validation loss: 1.4638906204572288

Epoch: 448| Step: 0
Training loss: 0.090790756046772
Validation loss: 1.4496476592556122

Epoch: 6| Step: 1
Training loss: 0.10094611346721649
Validation loss: 1.4525052155217817

Epoch: 6| Step: 2
Training loss: 0.15196186304092407
Validation loss: 1.446141989000382

Epoch: 6| Step: 3
Training loss: 0.1966072916984558
Validation loss: 1.4158015853615218

Epoch: 6| Step: 4
Training loss: 0.13969099521636963
Validation loss: 1.4099724690119426

Epoch: 6| Step: 5
Training loss: 0.10559659451246262
Validation loss: 1.3848751078369796

Epoch: 6| Step: 6
Training loss: 0.18125873804092407
Validation loss: 1.3859969685154576

Epoch: 6| Step: 7
Training loss: 0.09794673323631287
Validation loss: 1.3882337565063148

Epoch: 6| Step: 8
Training loss: 0.08997929841279984
Validation loss: 1.406387912329807

Epoch: 6| Step: 9
Training loss: 0.12460792809724808
Validation loss: 1.4093325766183997

Epoch: 6| Step: 10
Training loss: 0.06315568089485168
Validation loss: 1.4195765500427575

Epoch: 6| Step: 11
Training loss: 0.10238336771726608
Validation loss: 1.4281274259731334

Epoch: 6| Step: 12
Training loss: 0.13758832216262817
Validation loss: 1.4421011523533893

Epoch: 6| Step: 13
Training loss: 0.08133576810359955
Validation loss: 1.4536600010369414

Epoch: 449| Step: 0
Training loss: 0.12726669013500214
Validation loss: 1.478556872696005

Epoch: 6| Step: 1
Training loss: 0.16285787522792816
Validation loss: 1.4575678148577291

Epoch: 6| Step: 2
Training loss: 0.15929506719112396
Validation loss: 1.481559480390241

Epoch: 6| Step: 3
Training loss: 0.13774630427360535
Validation loss: 1.436761147232466

Epoch: 6| Step: 4
Training loss: 0.1006031185388565
Validation loss: 1.478050777989049

Epoch: 6| Step: 5
Training loss: 0.109194815158844
Validation loss: 1.4560816813540716

Epoch: 6| Step: 6
Training loss: 0.12534502148628235
Validation loss: 1.4422437772955945

Epoch: 6| Step: 7
Training loss: 0.14747969806194305
Validation loss: 1.4650939049259308

Epoch: 6| Step: 8
Training loss: 0.09193448722362518
Validation loss: 1.470035465814734

Epoch: 6| Step: 9
Training loss: 0.1385737657546997
Validation loss: 1.4679464627337713

Epoch: 6| Step: 10
Training loss: 0.11742085963487625
Validation loss: 1.4551345020212152

Epoch: 6| Step: 11
Training loss: 0.1337338089942932
Validation loss: 1.446258004634611

Epoch: 6| Step: 12
Training loss: 0.13182157278060913
Validation loss: 1.4414635544182153

Epoch: 6| Step: 13
Training loss: 0.11537270992994308
Validation loss: 1.4027304110988494

Epoch: 450| Step: 0
Training loss: 0.1342383325099945
Validation loss: 1.4629689044849847

Epoch: 6| Step: 1
Training loss: 0.1295023113489151
Validation loss: 1.4399874120630243

Epoch: 6| Step: 2
Training loss: 0.13599514961242676
Validation loss: 1.4658555317950506

Epoch: 6| Step: 3
Training loss: 0.1346886157989502
Validation loss: 1.4566105693899176

Epoch: 6| Step: 4
Training loss: 0.10205128788948059
Validation loss: 1.4391841055244528

Epoch: 6| Step: 5
Training loss: 0.11257980763912201
Validation loss: 1.4405586258057625

Epoch: 6| Step: 6
Training loss: 0.09488736093044281
Validation loss: 1.4391886418865574

Epoch: 6| Step: 7
Training loss: 0.07297980785369873
Validation loss: 1.3894906428552443

Epoch: 6| Step: 8
Training loss: 0.14438171684741974
Validation loss: 1.3997073968251545

Epoch: 6| Step: 9
Training loss: 0.1862529069185257
Validation loss: 1.3972284127307195

Epoch: 6| Step: 10
Training loss: 0.13014979660511017
Validation loss: 1.4384691830604308

Epoch: 6| Step: 11
Training loss: 0.08944869041442871
Validation loss: 1.3840481388953425

Epoch: 6| Step: 12
Training loss: 0.10887300223112106
Validation loss: 1.4322370841938963

Epoch: 6| Step: 13
Training loss: 0.11471496522426605
Validation loss: 1.419119369599127

Epoch: 451| Step: 0
Training loss: 0.14644959568977356
Validation loss: 1.4315945871414677

Epoch: 6| Step: 1
Training loss: 0.1203630268573761
Validation loss: 1.4410360269649054

Epoch: 6| Step: 2
Training loss: 0.09440555423498154
Validation loss: 1.4398383389237106

Epoch: 6| Step: 3
Training loss: 0.13122060894966125
Validation loss: 1.4651006280734975

Epoch: 6| Step: 4
Training loss: 0.13533087074756622
Validation loss: 1.4609501054210048

Epoch: 6| Step: 5
Training loss: 0.13638469576835632
Validation loss: 1.4636276127189718

Epoch: 6| Step: 6
Training loss: 0.14245182275772095
Validation loss: 1.441195503357918

Epoch: 6| Step: 7
Training loss: 0.11257023364305496
Validation loss: 1.4380336692256313

Epoch: 6| Step: 8
Training loss: 0.0980880856513977
Validation loss: 1.4620143546853015

Epoch: 6| Step: 9
Training loss: 0.10770115256309509
Validation loss: 1.4533636159794305

Epoch: 6| Step: 10
Training loss: 0.07602829486131668
Validation loss: 1.4636357766325756

Epoch: 6| Step: 11
Training loss: 0.09049142152070999
Validation loss: 1.457804975971099

Epoch: 6| Step: 12
Training loss: 0.10990755259990692
Validation loss: 1.4741655857332292

Epoch: 6| Step: 13
Training loss: 0.1211765855550766
Validation loss: 1.4604192369727678

Epoch: 452| Step: 0
Training loss: 0.07143658399581909
Validation loss: 1.4398311338117045

Epoch: 6| Step: 1
Training loss: 0.15015798807144165
Validation loss: 1.45260267167963

Epoch: 6| Step: 2
Training loss: 0.07253199815750122
Validation loss: 1.4593007103089364

Epoch: 6| Step: 3
Training loss: 0.06083928793668747
Validation loss: 1.4359068505225643

Epoch: 6| Step: 4
Training loss: 0.07249816507101059
Validation loss: 1.4649639937185472

Epoch: 6| Step: 5
Training loss: 0.07511460781097412
Validation loss: 1.4492691332294094

Epoch: 6| Step: 6
Training loss: 0.06472628563642502
Validation loss: 1.4801690347733036

Epoch: 6| Step: 7
Training loss: 0.12075693905353546
Validation loss: 1.4664722757954751

Epoch: 6| Step: 8
Training loss: 0.13398216664791107
Validation loss: 1.4645161397995488

Epoch: 6| Step: 9
Training loss: 0.08940310776233673
Validation loss: 1.4540567756980978

Epoch: 6| Step: 10
Training loss: 0.11011861264705658
Validation loss: 1.4320345899110198

Epoch: 6| Step: 11
Training loss: 0.15705648064613342
Validation loss: 1.474014489881454

Epoch: 6| Step: 12
Training loss: 0.07851532101631165
Validation loss: 1.4523651971611926

Epoch: 6| Step: 13
Training loss: 0.06819619238376617
Validation loss: 1.4682477481903569

Epoch: 453| Step: 0
Training loss: 0.10245871543884277
Validation loss: 1.4717117189079203

Epoch: 6| Step: 1
Training loss: 0.06942816823720932
Validation loss: 1.464663210094616

Epoch: 6| Step: 2
Training loss: 0.11432722210884094
Validation loss: 1.470266165271882

Epoch: 6| Step: 3
Training loss: 0.062219634652137756
Validation loss: 1.4493056702357467

Epoch: 6| Step: 4
Training loss: 0.07196978479623795
Validation loss: 1.4435002457711004

Epoch: 6| Step: 5
Training loss: 0.05326216295361519
Validation loss: 1.4583609770703059

Epoch: 6| Step: 6
Training loss: 0.0771389976143837
Validation loss: 1.4495497749697777

Epoch: 6| Step: 7
Training loss: 0.07376053929328918
Validation loss: 1.4437456092526835

Epoch: 6| Step: 8
Training loss: 0.09211862832307816
Validation loss: 1.4357484796995759

Epoch: 6| Step: 9
Training loss: 0.07781586050987244
Validation loss: 1.4283420514034968

Epoch: 6| Step: 10
Training loss: 0.1109594851732254
Validation loss: 1.4603508416042532

Epoch: 6| Step: 11
Training loss: 0.09808829426765442
Validation loss: 1.4765118783520115

Epoch: 6| Step: 12
Training loss: 0.20392286777496338
Validation loss: 1.4502263812608616

Epoch: 6| Step: 13
Training loss: 0.12935727834701538
Validation loss: 1.4633122785117036

Epoch: 454| Step: 0
Training loss: 0.11104836314916611
Validation loss: 1.442444037365657

Epoch: 6| Step: 1
Training loss: 0.06979157775640488
Validation loss: 1.458358271147615

Epoch: 6| Step: 2
Training loss: 0.07263565063476562
Validation loss: 1.4684868660024417

Epoch: 6| Step: 3
Training loss: 0.11872595548629761
Validation loss: 1.4649922860566007

Epoch: 6| Step: 4
Training loss: 0.1118609756231308
Validation loss: 1.4408675970569733

Epoch: 6| Step: 5
Training loss: 0.0835990458726883
Validation loss: 1.4465783462729505

Epoch: 6| Step: 6
Training loss: 0.06577615439891815
Validation loss: 1.4365606448983634

Epoch: 6| Step: 7
Training loss: 0.15081942081451416
Validation loss: 1.4510150083931543

Epoch: 6| Step: 8
Training loss: 0.0803067684173584
Validation loss: 1.4746179106414958

Epoch: 6| Step: 9
Training loss: 0.14016571640968323
Validation loss: 1.4441693162405362

Epoch: 6| Step: 10
Training loss: 0.07343071699142456
Validation loss: 1.4438722338727725

Epoch: 6| Step: 11
Training loss: 0.10289967060089111
Validation loss: 1.4379473431136018

Epoch: 6| Step: 12
Training loss: 0.0855000913143158
Validation loss: 1.4282135117438532

Epoch: 6| Step: 13
Training loss: 0.0907817929983139
Validation loss: 1.455086213286205

Epoch: 455| Step: 0
Training loss: 0.12837183475494385
Validation loss: 1.43064159347165

Epoch: 6| Step: 1
Training loss: 0.14220944046974182
Validation loss: 1.4596570717391146

Epoch: 6| Step: 2
Training loss: 0.11296823620796204
Validation loss: 1.440051636388225

Epoch: 6| Step: 3
Training loss: 0.10444074124097824
Validation loss: 1.4705235804280927

Epoch: 6| Step: 4
Training loss: 0.11245588213205338
Validation loss: 1.4630123088436742

Epoch: 6| Step: 5
Training loss: 0.09232868254184723
Validation loss: 1.4362950004557127

Epoch: 6| Step: 6
Training loss: 0.0853680744767189
Validation loss: 1.4459753523590744

Epoch: 6| Step: 7
Training loss: 0.09503275156021118
Validation loss: 1.4534398753155944

Epoch: 6| Step: 8
Training loss: 0.07340490072965622
Validation loss: 1.4273344214244554

Epoch: 6| Step: 9
Training loss: 0.061989087611436844
Validation loss: 1.4374692491305772

Epoch: 6| Step: 10
Training loss: 0.06887121498584747
Validation loss: 1.417621394639374

Epoch: 6| Step: 11
Training loss: 0.09628237783908844
Validation loss: 1.41749434573676

Epoch: 6| Step: 12
Training loss: 0.08511614054441452
Validation loss: 1.4343828667876541

Epoch: 6| Step: 13
Training loss: 0.06786511838436127
Validation loss: 1.4080424481822598

Epoch: 456| Step: 0
Training loss: 0.1204865425825119
Validation loss: 1.4213307878022552

Epoch: 6| Step: 1
Training loss: 0.10648732632398605
Validation loss: 1.4159364213225663

Epoch: 6| Step: 2
Training loss: 0.08670932054519653
Validation loss: 1.4312222234664425

Epoch: 6| Step: 3
Training loss: 0.06688632071018219
Validation loss: 1.4268600363885202

Epoch: 6| Step: 4
Training loss: 0.13178306818008423
Validation loss: 1.4297748317000687

Epoch: 6| Step: 5
Training loss: 0.08476616442203522
Validation loss: 1.4534465946177

Epoch: 6| Step: 6
Training loss: 0.10116936266422272
Validation loss: 1.4339408066964918

Epoch: 6| Step: 7
Training loss: 0.09177510440349579
Validation loss: 1.3995852521670762

Epoch: 6| Step: 8
Training loss: 0.08088982850313187
Validation loss: 1.4331610343789543

Epoch: 6| Step: 9
Training loss: 0.10981318354606628
Validation loss: 1.4197060177403111

Epoch: 6| Step: 10
Training loss: 0.07995987683534622
Validation loss: 1.3849312150350181

Epoch: 6| Step: 11
Training loss: 0.07209210097789764
Validation loss: 1.38751418359818

Epoch: 6| Step: 12
Training loss: 0.13705918192863464
Validation loss: 1.4039018654054212

Epoch: 6| Step: 13
Training loss: 0.07749484479427338
Validation loss: 1.373291673198823

Epoch: 457| Step: 0
Training loss: 0.0799795463681221
Validation loss: 1.3835155502442391

Epoch: 6| Step: 1
Training loss: 0.09515036642551422
Validation loss: 1.3796996237129293

Epoch: 6| Step: 2
Training loss: 0.07282545417547226
Validation loss: 1.3777158644891554

Epoch: 6| Step: 3
Training loss: 0.05916975438594818
Validation loss: 1.3889213544066235

Epoch: 6| Step: 4
Training loss: 0.09689275920391083
Validation loss: 1.3716011316545549

Epoch: 6| Step: 5
Training loss: 0.06062101945281029
Validation loss: 1.392320579098117

Epoch: 6| Step: 6
Training loss: 0.12211735546588898
Validation loss: 1.3992206717050204

Epoch: 6| Step: 7
Training loss: 0.09992016851902008
Validation loss: 1.4301788704369658

Epoch: 6| Step: 8
Training loss: 0.07912609726190567
Validation loss: 1.4084741582152664

Epoch: 6| Step: 9
Training loss: 0.09283936023712158
Validation loss: 1.3857685160893265

Epoch: 6| Step: 10
Training loss: 0.08024794608354568
Validation loss: 1.386705795923869

Epoch: 6| Step: 11
Training loss: 0.07644123584032059
Validation loss: 1.401688528317277

Epoch: 6| Step: 12
Training loss: 0.1295105218887329
Validation loss: 1.4056255022684734

Epoch: 6| Step: 13
Training loss: 0.14459384977817535
Validation loss: 1.3843861215858049

Epoch: 458| Step: 0
Training loss: 0.06382980942726135
Validation loss: 1.3794118114697036

Epoch: 6| Step: 1
Training loss: 0.04431847110390663
Validation loss: 1.375303041550421

Epoch: 6| Step: 2
Training loss: 0.07888603955507278
Validation loss: 1.3760490334162148

Epoch: 6| Step: 3
Training loss: 0.1212812140583992
Validation loss: 1.3750732252674718

Epoch: 6| Step: 4
Training loss: 0.11331573128700256
Validation loss: 1.4151724128312961

Epoch: 6| Step: 5
Training loss: 0.13607999682426453
Validation loss: 1.4022117173799904

Epoch: 6| Step: 6
Training loss: 0.05285809561610222
Validation loss: 1.4219732784455823

Epoch: 6| Step: 7
Training loss: 0.13639701902866364
Validation loss: 1.384036167975395

Epoch: 6| Step: 8
Training loss: 0.08004971593618393
Validation loss: 1.4034547651967695

Epoch: 6| Step: 9
Training loss: 0.08605363965034485
Validation loss: 1.3801932713036895

Epoch: 6| Step: 10
Training loss: 0.07949160784482956
Validation loss: 1.3897324396717934

Epoch: 6| Step: 11
Training loss: 0.07011137902736664
Validation loss: 1.383538515977962

Epoch: 6| Step: 12
Training loss: 0.1363188773393631
Validation loss: 1.3866521453344693

Epoch: 6| Step: 13
Training loss: 0.07294727861881256
Validation loss: 1.3977534617147138

Epoch: 459| Step: 0
Training loss: 0.07460716366767883
Validation loss: 1.4115608020495343

Epoch: 6| Step: 1
Training loss: 0.058406151831150055
Validation loss: 1.4142284867584065

Epoch: 6| Step: 2
Training loss: 0.13738024234771729
Validation loss: 1.3937558153624177

Epoch: 6| Step: 3
Training loss: 0.09361770749092102
Validation loss: 1.4092382282339118

Epoch: 6| Step: 4
Training loss: 0.08517452329397202
Validation loss: 1.389060454342955

Epoch: 6| Step: 5
Training loss: 0.07576748728752136
Validation loss: 1.3882644471301828

Epoch: 6| Step: 6
Training loss: 0.0652051642537117
Validation loss: 1.3797329510411909

Epoch: 6| Step: 7
Training loss: 0.12971726059913635
Validation loss: 1.4238422096416514

Epoch: 6| Step: 8
Training loss: 0.08400421589612961
Validation loss: 1.4120091904876053

Epoch: 6| Step: 9
Training loss: 0.09242536127567291
Validation loss: 1.3984008732662405

Epoch: 6| Step: 10
Training loss: 0.07210937142372131
Validation loss: 1.4027847782258065

Epoch: 6| Step: 11
Training loss: 0.14087042212486267
Validation loss: 1.415673921185155

Epoch: 6| Step: 12
Training loss: 0.09933606535196304
Validation loss: 1.418202515571348

Epoch: 6| Step: 13
Training loss: 0.18131892383098602
Validation loss: 1.398460200396917

Epoch: 460| Step: 0
Training loss: 0.09015242755413055
Validation loss: 1.4055475047839585

Epoch: 6| Step: 1
Training loss: 0.1087973564863205
Validation loss: 1.4366507786576466

Epoch: 6| Step: 2
Training loss: 0.05226873978972435
Validation loss: 1.396926542764069

Epoch: 6| Step: 3
Training loss: 0.09764326363801956
Validation loss: 1.3846572227375482

Epoch: 6| Step: 4
Training loss: 0.13707515597343445
Validation loss: 1.442188507767134

Epoch: 6| Step: 5
Training loss: 0.10134146362543106
Validation loss: 1.4413610837792838

Epoch: 6| Step: 6
Training loss: 0.1151438057422638
Validation loss: 1.4615395620305052

Epoch: 6| Step: 7
Training loss: 0.09636552631855011
Validation loss: 1.4515192534333916

Epoch: 6| Step: 8
Training loss: 0.0862860381603241
Validation loss: 1.4411635462955763

Epoch: 6| Step: 9
Training loss: 0.15046031773090363
Validation loss: 1.4545506726029098

Epoch: 6| Step: 10
Training loss: 0.07507294416427612
Validation loss: 1.4416656737686486

Epoch: 6| Step: 11
Training loss: 0.09753598272800446
Validation loss: 1.4329899312347494

Epoch: 6| Step: 12
Training loss: 0.076382577419281
Validation loss: 1.4564932161761868

Epoch: 6| Step: 13
Training loss: 0.12567636370658875
Validation loss: 1.439586680422547

Epoch: 461| Step: 0
Training loss: 0.15541712939739227
Validation loss: 1.4401683634327305

Epoch: 6| Step: 1
Training loss: 0.09381092339754105
Validation loss: 1.4369261815983763

Epoch: 6| Step: 2
Training loss: 0.13059298694133759
Validation loss: 1.4255736630450013

Epoch: 6| Step: 3
Training loss: 0.08633530139923096
Validation loss: 1.4701577495503169

Epoch: 6| Step: 4
Training loss: 0.0785888284444809
Validation loss: 1.433998123292

Epoch: 6| Step: 5
Training loss: 0.08482620120048523
Validation loss: 1.4270852983638804

Epoch: 6| Step: 6
Training loss: 0.06310897320508957
Validation loss: 1.4594372408364409

Epoch: 6| Step: 7
Training loss: 0.11231960356235504
Validation loss: 1.4385841328610656

Epoch: 6| Step: 8
Training loss: 0.08963637053966522
Validation loss: 1.4604365787198466

Epoch: 6| Step: 9
Training loss: 0.15563687682151794
Validation loss: 1.429998408081711

Epoch: 6| Step: 10
Training loss: 0.06466486304998398
Validation loss: 1.3907754575052569

Epoch: 6| Step: 11
Training loss: 0.10952804982662201
Validation loss: 1.4253880503357097

Epoch: 6| Step: 12
Training loss: 0.09349449723958969
Validation loss: 1.4220157464345295

Epoch: 6| Step: 13
Training loss: 0.1451854258775711
Validation loss: 1.437968905254077

Epoch: 462| Step: 0
Training loss: 0.08509357273578644
Validation loss: 1.4009405002799085

Epoch: 6| Step: 1
Training loss: 0.11113789677619934
Validation loss: 1.4116830864260275

Epoch: 6| Step: 2
Training loss: 0.08442606031894684
Validation loss: 1.4356605416984969

Epoch: 6| Step: 3
Training loss: 0.07292109727859497
Validation loss: 1.4170142937732

Epoch: 6| Step: 4
Training loss: 0.133858785033226
Validation loss: 1.4123852483687862

Epoch: 6| Step: 5
Training loss: 0.1195327639579773
Validation loss: 1.4378736999727064

Epoch: 6| Step: 6
Training loss: 0.0863615870475769
Validation loss: 1.4083668685728503

Epoch: 6| Step: 7
Training loss: 0.11661051213741302
Validation loss: 1.4205289233115412

Epoch: 6| Step: 8
Training loss: 0.10037052631378174
Validation loss: 1.4191811546202628

Epoch: 6| Step: 9
Training loss: 0.08734804391860962
Validation loss: 1.4246968300111833

Epoch: 6| Step: 10
Training loss: 0.06500899791717529
Validation loss: 1.420885484705689

Epoch: 6| Step: 11
Training loss: 0.071571484208107
Validation loss: 1.4577079319184827

Epoch: 6| Step: 12
Training loss: 0.13698728382587433
Validation loss: 1.4298841132912585

Epoch: 6| Step: 13
Training loss: 0.06933973729610443
Validation loss: 1.453605499318851

Epoch: 463| Step: 0
Training loss: 0.11055053770542145
Validation loss: 1.4356091842856458

Epoch: 6| Step: 1
Training loss: 0.08139082789421082
Validation loss: 1.4482553159036944

Epoch: 6| Step: 2
Training loss: 0.0625855103135109
Validation loss: 1.4612757800727763

Epoch: 6| Step: 3
Training loss: 0.13092787563800812
Validation loss: 1.458776879054244

Epoch: 6| Step: 4
Training loss: 0.12977074086666107
Validation loss: 1.4664875294572564

Epoch: 6| Step: 5
Training loss: 0.1092817634344101
Validation loss: 1.4434506944430772

Epoch: 6| Step: 6
Training loss: 0.13829296827316284
Validation loss: 1.4532039652588546

Epoch: 6| Step: 7
Training loss: 0.10759566724300385
Validation loss: 1.4457365248792915

Epoch: 6| Step: 8
Training loss: 0.18648642301559448
Validation loss: 1.4604303362548992

Epoch: 6| Step: 9
Training loss: 0.1227104514837265
Validation loss: 1.4116280642888879

Epoch: 6| Step: 10
Training loss: 0.05594022199511528
Validation loss: 1.4415826246302614

Epoch: 6| Step: 11
Training loss: 0.04919653758406639
Validation loss: 1.417742685605121

Epoch: 6| Step: 12
Training loss: 0.08195282518863678
Validation loss: 1.4137669942712272

Epoch: 6| Step: 13
Training loss: 0.07630711048841476
Validation loss: 1.3835194213415987

Epoch: 464| Step: 0
Training loss: 0.12157534062862396
Validation loss: 1.4062721178095827

Epoch: 6| Step: 1
Training loss: 0.10425953567028046
Validation loss: 1.3835754458622267

Epoch: 6| Step: 2
Training loss: 0.05316559225320816
Validation loss: 1.3890717132117159

Epoch: 6| Step: 3
Training loss: 0.06780526041984558
Validation loss: 1.4079491784495692

Epoch: 6| Step: 4
Training loss: 0.14465562999248505
Validation loss: 1.386579550722594

Epoch: 6| Step: 5
Training loss: 0.08583904802799225
Validation loss: 1.3953213858348068

Epoch: 6| Step: 6
Training loss: 0.10739398747682571
Validation loss: 1.4189460662103468

Epoch: 6| Step: 7
Training loss: 0.1073654443025589
Validation loss: 1.4239096885086389

Epoch: 6| Step: 8
Training loss: 0.05356597900390625
Validation loss: 1.4443641779243306

Epoch: 6| Step: 9
Training loss: 0.05249070003628731
Validation loss: 1.4076406340445242

Epoch: 6| Step: 10
Training loss: 0.05868319049477577
Validation loss: 1.4290387220280145

Epoch: 6| Step: 11
Training loss: 0.06465793401002884
Validation loss: 1.4573744048354447

Epoch: 6| Step: 12
Training loss: 0.11694437265396118
Validation loss: 1.4490242696577502

Epoch: 6| Step: 13
Training loss: 0.14602085947990417
Validation loss: 1.4658950451881654

Epoch: 465| Step: 0
Training loss: 0.078074149787426
Validation loss: 1.4608079925660165

Epoch: 6| Step: 1
Training loss: 0.1530902087688446
Validation loss: 1.4704434833218973

Epoch: 6| Step: 2
Training loss: 0.0958787202835083
Validation loss: 1.4393851193048621

Epoch: 6| Step: 3
Training loss: 0.1012205258011818
Validation loss: 1.4518943730221

Epoch: 6| Step: 4
Training loss: 0.07207538932561874
Validation loss: 1.434109035358634

Epoch: 6| Step: 5
Training loss: 0.06567030400037766
Validation loss: 1.4193277012917302

Epoch: 6| Step: 6
Training loss: 0.06395932286977768
Validation loss: 1.4252148943562661

Epoch: 6| Step: 7
Training loss: 0.06748766452074051
Validation loss: 1.4571181420356996

Epoch: 6| Step: 8
Training loss: 0.11450792849063873
Validation loss: 1.419271715225712

Epoch: 6| Step: 9
Training loss: 0.12574928998947144
Validation loss: 1.427196389885359

Epoch: 6| Step: 10
Training loss: 0.10319272428750992
Validation loss: 1.3981254972437376

Epoch: 6| Step: 11
Training loss: 0.08353545516729355
Validation loss: 1.4134031136830647

Epoch: 6| Step: 12
Training loss: 0.1265518218278885
Validation loss: 1.3574738528138848

Epoch: 6| Step: 13
Training loss: 0.11026188731193542
Validation loss: 1.3863826644036077

Epoch: 466| Step: 0
Training loss: 0.15220534801483154
Validation loss: 1.3587836539873512

Epoch: 6| Step: 1
Training loss: 0.11660253256559372
Validation loss: 1.3859529392693632

Epoch: 6| Step: 2
Training loss: 0.08708307147026062
Validation loss: 1.3711607930480794

Epoch: 6| Step: 3
Training loss: 0.1233862116932869
Validation loss: 1.3900011675332182

Epoch: 6| Step: 4
Training loss: 0.17552614212036133
Validation loss: 1.424857690770139

Epoch: 6| Step: 5
Training loss: 0.05786185339093208
Validation loss: 1.3852609767708728

Epoch: 6| Step: 6
Training loss: 0.08045943826436996
Validation loss: 1.4150532599418395

Epoch: 6| Step: 7
Training loss: 0.06980980187654495
Validation loss: 1.4052338766795334

Epoch: 6| Step: 8
Training loss: 0.08905574679374695
Validation loss: 1.4024881765406618

Epoch: 6| Step: 9
Training loss: 0.09451499581336975
Validation loss: 1.4132707272806475

Epoch: 6| Step: 10
Training loss: 0.07728445529937744
Validation loss: 1.4345598579734884

Epoch: 6| Step: 11
Training loss: 0.0843251571059227
Validation loss: 1.4247996871189406

Epoch: 6| Step: 12
Training loss: 0.11112077534198761
Validation loss: 1.4216778714169738

Epoch: 6| Step: 13
Training loss: 0.09902843087911606
Validation loss: 1.4319215782227055

Epoch: 467| Step: 0
Training loss: 0.07204747200012207
Validation loss: 1.4170845541902768

Epoch: 6| Step: 1
Training loss: 0.10556428134441376
Validation loss: 1.4285487064751246

Epoch: 6| Step: 2
Training loss: 0.09756743907928467
Validation loss: 1.42850173160594

Epoch: 6| Step: 3
Training loss: 0.10638240724802017
Validation loss: 1.44736353171769

Epoch: 6| Step: 4
Training loss: 0.07931386679410934
Validation loss: 1.4235822641721336

Epoch: 6| Step: 5
Training loss: 0.06012967228889465
Validation loss: 1.4193001383094377

Epoch: 6| Step: 6
Training loss: 0.0891338437795639
Validation loss: 1.4485651754563855

Epoch: 6| Step: 7
Training loss: 0.10464204847812653
Validation loss: 1.4345405367753838

Epoch: 6| Step: 8
Training loss: 0.08311112225055695
Validation loss: 1.439993219990884

Epoch: 6| Step: 9
Training loss: 0.08127222210168839
Validation loss: 1.465253057018403

Epoch: 6| Step: 10
Training loss: 0.061972957104444504
Validation loss: 1.4483016678082046

Epoch: 6| Step: 11
Training loss: 0.15441028773784637
Validation loss: 1.4415678651102128

Epoch: 6| Step: 12
Training loss: 0.07203970849514008
Validation loss: 1.4673609246489823

Epoch: 6| Step: 13
Training loss: 0.11908027529716492
Validation loss: 1.4622885860422605

Epoch: 468| Step: 0
Training loss: 0.11602235585451126
Validation loss: 1.4649633951084589

Epoch: 6| Step: 1
Training loss: 0.0848887637257576
Validation loss: 1.461793412444412

Epoch: 6| Step: 2
Training loss: 0.08544671535491943
Validation loss: 1.484652671762692

Epoch: 6| Step: 3
Training loss: 0.07037873566150665
Validation loss: 1.4871127252937646

Epoch: 6| Step: 4
Training loss: 0.06400658190250397
Validation loss: 1.5031033356984456

Epoch: 6| Step: 5
Training loss: 0.11053627729415894
Validation loss: 1.5069665460176365

Epoch: 6| Step: 6
Training loss: 0.11284103989601135
Validation loss: 1.4909981559681635

Epoch: 6| Step: 7
Training loss: 0.09153947234153748
Validation loss: 1.4701568375351608

Epoch: 6| Step: 8
Training loss: 0.11178890615701675
Validation loss: 1.4695086697096467

Epoch: 6| Step: 9
Training loss: 0.14288434386253357
Validation loss: 1.4553744562210575

Epoch: 6| Step: 10
Training loss: 0.08316458016633987
Validation loss: 1.457608333197973

Epoch: 6| Step: 11
Training loss: 0.10845980793237686
Validation loss: 1.4635984698931377

Epoch: 6| Step: 12
Training loss: 0.080288827419281
Validation loss: 1.4613214231306506

Epoch: 6| Step: 13
Training loss: 0.08777932077646255
Validation loss: 1.4546356111444452

Epoch: 469| Step: 0
Training loss: 0.12781012058258057
Validation loss: 1.4425211503941526

Epoch: 6| Step: 1
Training loss: 0.12072981894016266
Validation loss: 1.4572226257734402

Epoch: 6| Step: 2
Training loss: 0.11371248960494995
Validation loss: 1.4470066216684156

Epoch: 6| Step: 3
Training loss: 0.15272526443004608
Validation loss: 1.436069938444322

Epoch: 6| Step: 4
Training loss: 0.11279647052288055
Validation loss: 1.4412733252330492

Epoch: 6| Step: 5
Training loss: 0.061523765325546265
Validation loss: 1.4488215907927482

Epoch: 6| Step: 6
Training loss: 0.11760681867599487
Validation loss: 1.4303163020841536

Epoch: 6| Step: 7
Training loss: 0.08598647266626358
Validation loss: 1.4158610631060857

Epoch: 6| Step: 8
Training loss: 0.07234856486320496
Validation loss: 1.3911393547570834

Epoch: 6| Step: 9
Training loss: 0.0797027200460434
Validation loss: 1.4286416435754428

Epoch: 6| Step: 10
Training loss: 0.09188054502010345
Validation loss: 1.4067183790668365

Epoch: 6| Step: 11
Training loss: 0.08821212500333786
Validation loss: 1.3877999949198898

Epoch: 6| Step: 12
Training loss: 0.1353302001953125
Validation loss: 1.423559823984741

Epoch: 6| Step: 13
Training loss: 0.04440278187394142
Validation loss: 1.407022217909495

Epoch: 470| Step: 0
Training loss: 0.08765684068202972
Validation loss: 1.4176751618744226

Epoch: 6| Step: 1
Training loss: 0.06823500990867615
Validation loss: 1.4229732085299749

Epoch: 6| Step: 2
Training loss: 0.08082358539104462
Validation loss: 1.4212761720021565

Epoch: 6| Step: 3
Training loss: 0.07571642100811005
Validation loss: 1.4018493788216704

Epoch: 6| Step: 4
Training loss: 0.08751089870929718
Validation loss: 1.401576453639615

Epoch: 6| Step: 5
Training loss: 0.1294918805360794
Validation loss: 1.4059880830908333

Epoch: 6| Step: 6
Training loss: 0.08467666804790497
Validation loss: 1.4210658913017602

Epoch: 6| Step: 7
Training loss: 0.10424981266260147
Validation loss: 1.3905842035047469

Epoch: 6| Step: 8
Training loss: 0.09084782004356384
Validation loss: 1.4032951465217016

Epoch: 6| Step: 9
Training loss: 0.1547943353652954
Validation loss: 1.4106825808043122

Epoch: 6| Step: 10
Training loss: 0.06854954361915588
Validation loss: 1.4068504828278736

Epoch: 6| Step: 11
Training loss: 0.05690857768058777
Validation loss: 1.4300929102846371

Epoch: 6| Step: 12
Training loss: 0.09985529631376266
Validation loss: 1.4379121565049695

Epoch: 6| Step: 13
Training loss: 0.10909052193164825
Validation loss: 1.4705965019041491

Epoch: 471| Step: 0
Training loss: 0.08392108976840973
Validation loss: 1.4609112073016424

Epoch: 6| Step: 1
Training loss: 0.08818367123603821
Validation loss: 1.4574977736319266

Epoch: 6| Step: 2
Training loss: 0.10095016658306122
Validation loss: 1.4933205689153364

Epoch: 6| Step: 3
Training loss: 0.1011829674243927
Validation loss: 1.4755909737720285

Epoch: 6| Step: 4
Training loss: 0.14919409155845642
Validation loss: 1.473168057780112

Epoch: 6| Step: 5
Training loss: 0.06460610032081604
Validation loss: 1.441842322708458

Epoch: 6| Step: 6
Training loss: 0.15064963698387146
Validation loss: 1.4612644910812378

Epoch: 6| Step: 7
Training loss: 0.08628928661346436
Validation loss: 1.4161080339903473

Epoch: 6| Step: 8
Training loss: 0.11960543692111969
Validation loss: 1.3930969853555002

Epoch: 6| Step: 9
Training loss: 0.09900611639022827
Validation loss: 1.4346334434324695

Epoch: 6| Step: 10
Training loss: 0.12522396445274353
Validation loss: 1.416032104082005

Epoch: 6| Step: 11
Training loss: 0.12377975881099701
Validation loss: 1.383504649644257

Epoch: 6| Step: 12
Training loss: 0.09792215377092361
Validation loss: 1.4262011615178918

Epoch: 6| Step: 13
Training loss: 0.08415171504020691
Validation loss: 1.3948030651256602

Epoch: 472| Step: 0
Training loss: 0.06505673378705978
Validation loss: 1.3787599032925022

Epoch: 6| Step: 1
Training loss: 0.15212777256965637
Validation loss: 1.3691756033128308

Epoch: 6| Step: 2
Training loss: 0.06108580157160759
Validation loss: 1.3899688387429843

Epoch: 6| Step: 3
Training loss: 0.09943802654743195
Validation loss: 1.3910565453190957

Epoch: 6| Step: 4
Training loss: 0.13303609192371368
Validation loss: 1.3968727024652625

Epoch: 6| Step: 5
Training loss: 0.08830273896455765
Validation loss: 1.3760953949343773

Epoch: 6| Step: 6
Training loss: 0.06012999266386032
Validation loss: 1.4019729091275124

Epoch: 6| Step: 7
Training loss: 0.08624108880758286
Validation loss: 1.4168975692923351

Epoch: 6| Step: 8
Training loss: 0.08475992828607559
Validation loss: 1.4074453589736775

Epoch: 6| Step: 9
Training loss: 0.13751652836799622
Validation loss: 1.4190430461719472

Epoch: 6| Step: 10
Training loss: 0.06465175002813339
Validation loss: 1.4043250994015766

Epoch: 6| Step: 11
Training loss: 0.10561143606901169
Validation loss: 1.4166839199681436

Epoch: 6| Step: 12
Training loss: 0.09671693295240402
Validation loss: 1.3909031415498385

Epoch: 6| Step: 13
Training loss: 0.0599086694419384
Validation loss: 1.391432354527135

Epoch: 473| Step: 0
Training loss: 0.052962809801101685
Validation loss: 1.4099138475233508

Epoch: 6| Step: 1
Training loss: 0.04621477425098419
Validation loss: 1.404861432249828

Epoch: 6| Step: 2
Training loss: 0.0966610461473465
Validation loss: 1.3923268061812206

Epoch: 6| Step: 3
Training loss: 0.07055690884590149
Validation loss: 1.4176969515380038

Epoch: 6| Step: 4
Training loss: 0.0691956877708435
Validation loss: 1.3938073547937537

Epoch: 6| Step: 5
Training loss: 0.07764649391174316
Validation loss: 1.370821036318297

Epoch: 6| Step: 6
Training loss: 0.07103845477104187
Validation loss: 1.3989441330714891

Epoch: 6| Step: 7
Training loss: 0.06996272504329681
Validation loss: 1.4043869331318846

Epoch: 6| Step: 8
Training loss: 0.1315302848815918
Validation loss: 1.3297907081983422

Epoch: 6| Step: 9
Training loss: 0.1282813549041748
Validation loss: 1.3772165031843289

Epoch: 6| Step: 10
Training loss: 0.12524153292179108
Validation loss: 1.374343111950864

Epoch: 6| Step: 11
Training loss: 0.11711356043815613
Validation loss: 1.3727807844838789

Epoch: 6| Step: 12
Training loss: 0.13612331449985504
Validation loss: 1.3896567808684481

Epoch: 6| Step: 13
Training loss: 0.07610210031270981
Validation loss: 1.3924803708189277

Epoch: 474| Step: 0
Training loss: 0.09233933687210083
Validation loss: 1.3631916430688673

Epoch: 6| Step: 1
Training loss: 0.08350199460983276
Validation loss: 1.3905171143111361

Epoch: 6| Step: 2
Training loss: 0.11471119523048401
Validation loss: 1.3853483533346524

Epoch: 6| Step: 3
Training loss: 0.11294474452733994
Validation loss: 1.4119955532012447

Epoch: 6| Step: 4
Training loss: 0.09679615497589111
Validation loss: 1.4200145634271766

Epoch: 6| Step: 5
Training loss: 0.09764114022254944
Validation loss: 1.4634069140239427

Epoch: 6| Step: 6
Training loss: 0.12431219220161438
Validation loss: 1.4492728819129288

Epoch: 6| Step: 7
Training loss: 0.08367721736431122
Validation loss: 1.4425395137520247

Epoch: 6| Step: 8
Training loss: 0.21301376819610596
Validation loss: 1.4480670869991343

Epoch: 6| Step: 9
Training loss: 0.11526989936828613
Validation loss: 1.4735093732034006

Epoch: 6| Step: 10
Training loss: 0.07886765897274017
Validation loss: 1.4836007395098287

Epoch: 6| Step: 11
Training loss: 0.10813519358634949
Validation loss: 1.471357617326962

Epoch: 6| Step: 12
Training loss: 0.09179022908210754
Validation loss: 1.4918794606321601

Epoch: 6| Step: 13
Training loss: 0.10373371094465256
Validation loss: 1.4768704778404647

Epoch: 475| Step: 0
Training loss: 0.07920870184898376
Validation loss: 1.5137036000528643

Epoch: 6| Step: 1
Training loss: 0.08258834481239319
Validation loss: 1.5226754257755895

Epoch: 6| Step: 2
Training loss: 0.13987502455711365
Validation loss: 1.5272751815857426

Epoch: 6| Step: 3
Training loss: 0.10996414721012115
Validation loss: 1.548156452435319

Epoch: 6| Step: 4
Training loss: 0.15056033432483673
Validation loss: 1.555908368479821

Epoch: 6| Step: 5
Training loss: 0.1700087934732437
Validation loss: 1.5164510857674383

Epoch: 6| Step: 6
Training loss: 0.07645849883556366
Validation loss: 1.5233714772808937

Epoch: 6| Step: 7
Training loss: 0.13692721724510193
Validation loss: 1.4933560958472631

Epoch: 6| Step: 8
Training loss: 0.12917020916938782
Validation loss: 1.4892883980146019

Epoch: 6| Step: 9
Training loss: 0.0888393223285675
Validation loss: 1.446733244003788

Epoch: 6| Step: 10
Training loss: 0.1329886019229889
Validation loss: 1.4419359173825992

Epoch: 6| Step: 11
Training loss: 0.0785396546125412
Validation loss: 1.4350984737437258

Epoch: 6| Step: 12
Training loss: 0.11727125197649002
Validation loss: 1.4616660943595312

Epoch: 6| Step: 13
Training loss: 0.16633224487304688
Validation loss: 1.4650036929756083

Epoch: 476| Step: 0
Training loss: 0.1187644973397255
Validation loss: 1.4811623852740052

Epoch: 6| Step: 1
Training loss: 0.18897655606269836
Validation loss: 1.445632291096513

Epoch: 6| Step: 2
Training loss: 0.14323660731315613
Validation loss: 1.4508695781871837

Epoch: 6| Step: 3
Training loss: 0.07291707396507263
Validation loss: 1.419676520491159

Epoch: 6| Step: 4
Training loss: 0.1031976267695427
Validation loss: 1.3962706365892965

Epoch: 6| Step: 5
Training loss: 0.14121562242507935
Validation loss: 1.364116963519845

Epoch: 6| Step: 6
Training loss: 0.06658986210823059
Validation loss: 1.415660999154532

Epoch: 6| Step: 7
Training loss: 0.11672183871269226
Validation loss: 1.4262147218950334

Epoch: 6| Step: 8
Training loss: 0.13751700520515442
Validation loss: 1.417283131230262

Epoch: 6| Step: 9
Training loss: 0.0801437497138977
Validation loss: 1.4297380485842306

Epoch: 6| Step: 10
Training loss: 0.08603726327419281
Validation loss: 1.418964382140867

Epoch: 6| Step: 11
Training loss: 0.10800892114639282
Validation loss: 1.4187124211301085

Epoch: 6| Step: 12
Training loss: 0.0911116898059845
Validation loss: 1.4503875522203342

Epoch: 6| Step: 13
Training loss: 0.0973101481795311
Validation loss: 1.427015822420838

Epoch: 477| Step: 0
Training loss: 0.0677260011434555
Validation loss: 1.4133853739307773

Epoch: 6| Step: 1
Training loss: 0.11384919285774231
Validation loss: 1.4299045583253265

Epoch: 6| Step: 2
Training loss: 0.15205374360084534
Validation loss: 1.4206710759029593

Epoch: 6| Step: 3
Training loss: 0.13436850905418396
Validation loss: 1.432582284814568

Epoch: 6| Step: 4
Training loss: 0.11449328064918518
Validation loss: 1.4107539756323701

Epoch: 6| Step: 5
Training loss: 0.14016804099082947
Validation loss: 1.4547865134413525

Epoch: 6| Step: 6
Training loss: 0.10848783701658249
Validation loss: 1.4462855682578137

Epoch: 6| Step: 7
Training loss: 0.07480861246585846
Validation loss: 1.4422122739976453

Epoch: 6| Step: 8
Training loss: 0.1013229712843895
Validation loss: 1.4489090109384188

Epoch: 6| Step: 9
Training loss: 0.055014681071043015
Validation loss: 1.465587705694219

Epoch: 6| Step: 10
Training loss: 0.07123033702373505
Validation loss: 1.4524933548383816

Epoch: 6| Step: 11
Training loss: 0.06337630748748779
Validation loss: 1.469684629030125

Epoch: 6| Step: 12
Training loss: 0.1034199520945549
Validation loss: 1.461667953639902

Epoch: 6| Step: 13
Training loss: 0.1327410489320755
Validation loss: 1.4919991006133377

Epoch: 478| Step: 0
Training loss: 0.06255347281694412
Validation loss: 1.4652384545213433

Epoch: 6| Step: 1
Training loss: 0.12138286978006363
Validation loss: 1.4680587707027313

Epoch: 6| Step: 2
Training loss: 0.10601218044757843
Validation loss: 1.4921689661600257

Epoch: 6| Step: 3
Training loss: 0.08356364071369171
Validation loss: 1.4618206562534455

Epoch: 6| Step: 4
Training loss: 0.0535043329000473
Validation loss: 1.4723708424516904

Epoch: 6| Step: 5
Training loss: 0.06987934559583664
Validation loss: 1.4774547276958343

Epoch: 6| Step: 6
Training loss: 0.13793182373046875
Validation loss: 1.4621880195474113

Epoch: 6| Step: 7
Training loss: 0.09044955670833588
Validation loss: 1.4744855473118443

Epoch: 6| Step: 8
Training loss: 0.1294465959072113
Validation loss: 1.4460995120386924

Epoch: 6| Step: 9
Training loss: 0.0901172012090683
Validation loss: 1.4832555132527505

Epoch: 6| Step: 10
Training loss: 0.09228646755218506
Validation loss: 1.4498020423355924

Epoch: 6| Step: 11
Training loss: 0.08206425607204437
Validation loss: 1.4908344553362938

Epoch: 6| Step: 12
Training loss: 0.10714675486087799
Validation loss: 1.4842578326502154

Epoch: 6| Step: 13
Training loss: 0.07017556577920914
Validation loss: 1.4639884643657233

Epoch: 479| Step: 0
Training loss: 0.12280355393886566
Validation loss: 1.4591433476376277

Epoch: 6| Step: 1
Training loss: 0.0709754079580307
Validation loss: 1.457132112595343

Epoch: 6| Step: 2
Training loss: 0.07414883375167847
Validation loss: 1.4409250315799509

Epoch: 6| Step: 3
Training loss: 0.08458003401756287
Validation loss: 1.4320172827730897

Epoch: 6| Step: 4
Training loss: 0.09884761273860931
Validation loss: 1.4365568930102932

Epoch: 6| Step: 5
Training loss: 0.07579521089792252
Validation loss: 1.415056026110085

Epoch: 6| Step: 6
Training loss: 0.06649231910705566
Validation loss: 1.4333734794329571

Epoch: 6| Step: 7
Training loss: 0.09224659949541092
Validation loss: 1.4011901963141657

Epoch: 6| Step: 8
Training loss: 0.09336617588996887
Validation loss: 1.4057255265533284

Epoch: 6| Step: 9
Training loss: 0.09621667861938477
Validation loss: 1.431305818660285

Epoch: 6| Step: 10
Training loss: 0.10936581343412399
Validation loss: 1.4191961865271292

Epoch: 6| Step: 11
Training loss: 0.08036740124225616
Validation loss: 1.4142512800872966

Epoch: 6| Step: 12
Training loss: 0.07113286107778549
Validation loss: 1.4254683038239837

Epoch: 6| Step: 13
Training loss: 0.0760776475071907
Validation loss: 1.4517837929469284

Epoch: 480| Step: 0
Training loss: 0.09991724789142609
Validation loss: 1.4465619998593484

Epoch: 6| Step: 1
Training loss: 0.12095367908477783
Validation loss: 1.4467715435130621

Epoch: 6| Step: 2
Training loss: 0.05546065792441368
Validation loss: 1.4412092931808964

Epoch: 6| Step: 3
Training loss: 0.08576451241970062
Validation loss: 1.4349848698544245

Epoch: 6| Step: 4
Training loss: 0.10408110916614532
Validation loss: 1.4287313786886071

Epoch: 6| Step: 5
Training loss: 0.08029212057590485
Validation loss: 1.4405767904814852

Epoch: 6| Step: 6
Training loss: 0.05313330143690109
Validation loss: 1.4476931159214308

Epoch: 6| Step: 7
Training loss: 0.08438978344202042
Validation loss: 1.3982506080340313

Epoch: 6| Step: 8
Training loss: 0.08208058774471283
Validation loss: 1.4248386288201937

Epoch: 6| Step: 9
Training loss: 0.1149655357003212
Validation loss: 1.4082323088440845

Epoch: 6| Step: 10
Training loss: 0.10711240023374557
Validation loss: 1.384451554667565

Epoch: 6| Step: 11
Training loss: 0.10602960735559464
Validation loss: 1.366651059478842

Epoch: 6| Step: 12
Training loss: 0.08515234291553497
Validation loss: 1.3935481066344886

Epoch: 6| Step: 13
Training loss: 0.08948183059692383
Validation loss: 1.3823541107998099

Epoch: 481| Step: 0
Training loss: 0.09902580827474594
Validation loss: 1.3891051635947278

Epoch: 6| Step: 1
Training loss: 0.09746189415454865
Validation loss: 1.3731451951047426

Epoch: 6| Step: 2
Training loss: 0.04794677346944809
Validation loss: 1.359796218974616

Epoch: 6| Step: 3
Training loss: 0.0875856876373291
Validation loss: 1.3936205448642853

Epoch: 6| Step: 4
Training loss: 0.07404035329818726
Validation loss: 1.3848099580375097

Epoch: 6| Step: 5
Training loss: 0.08190891146659851
Validation loss: 1.4034842868005075

Epoch: 6| Step: 6
Training loss: 0.1151868924498558
Validation loss: 1.3914584318796794

Epoch: 6| Step: 7
Training loss: 0.1309410184621811
Validation loss: 1.3861299983916744

Epoch: 6| Step: 8
Training loss: 0.06665941327810287
Validation loss: 1.4182257049827165

Epoch: 6| Step: 9
Training loss: 0.11045756936073303
Validation loss: 1.448960995161405

Epoch: 6| Step: 10
Training loss: 0.10393746197223663
Validation loss: 1.452826464047996

Epoch: 6| Step: 11
Training loss: 0.09890561550855637
Validation loss: 1.426778866398719

Epoch: 6| Step: 12
Training loss: 0.0951395034790039
Validation loss: 1.4420215583616687

Epoch: 6| Step: 13
Training loss: 0.04285438358783722
Validation loss: 1.4451637178338983

Epoch: 482| Step: 0
Training loss: 0.05300195887684822
Validation loss: 1.4670924473834295

Epoch: 6| Step: 1
Training loss: 0.14928770065307617
Validation loss: 1.4750844253006803

Epoch: 6| Step: 2
Training loss: 0.11259346455335617
Validation loss: 1.4544661955166889

Epoch: 6| Step: 3
Training loss: 0.10623084753751755
Validation loss: 1.4316976839496243

Epoch: 6| Step: 4
Training loss: 0.145536869764328
Validation loss: 1.4081190395098862

Epoch: 6| Step: 5
Training loss: 0.08539238572120667
Validation loss: 1.437586962535817

Epoch: 6| Step: 6
Training loss: 0.10966097563505173
Validation loss: 1.4761056835933397

Epoch: 6| Step: 7
Training loss: 0.07227732241153717
Validation loss: 1.453312978949598

Epoch: 6| Step: 8
Training loss: 0.08628473430871964
Validation loss: 1.4409829890856178

Epoch: 6| Step: 9
Training loss: 0.12168074399232864
Validation loss: 1.4212408706706057

Epoch: 6| Step: 10
Training loss: 0.09338396787643433
Validation loss: 1.4241995465370916

Epoch: 6| Step: 11
Training loss: 0.051088545471429825
Validation loss: 1.400408959516915

Epoch: 6| Step: 12
Training loss: 0.06942297518253326
Validation loss: 1.411848852711339

Epoch: 6| Step: 13
Training loss: 0.06859362870454788
Validation loss: 1.3886186602295085

Epoch: 483| Step: 0
Training loss: 0.09656403213739395
Validation loss: 1.4081605826654742

Epoch: 6| Step: 1
Training loss: 0.15397435426712036
Validation loss: 1.403471592933901

Epoch: 6| Step: 2
Training loss: 0.06972973793745041
Validation loss: 1.399590394830191

Epoch: 6| Step: 3
Training loss: 0.1070457175374031
Validation loss: 1.4046748389479935

Epoch: 6| Step: 4
Training loss: 0.09446734935045242
Validation loss: 1.4346121190696635

Epoch: 6| Step: 5
Training loss: 0.13339568674564362
Validation loss: 1.4435221187530025

Epoch: 6| Step: 6
Training loss: 0.06481805443763733
Validation loss: 1.440129142935558

Epoch: 6| Step: 7
Training loss: 0.06379792839288712
Validation loss: 1.439450547259341

Epoch: 6| Step: 8
Training loss: 0.07934274524450302
Validation loss: 1.4693268050429642

Epoch: 6| Step: 9
Training loss: 0.11325716972351074
Validation loss: 1.4435327693980227

Epoch: 6| Step: 10
Training loss: 0.08338748663663864
Validation loss: 1.4368399163728118

Epoch: 6| Step: 11
Training loss: 0.10989787429571152
Validation loss: 1.466705568375126

Epoch: 6| Step: 12
Training loss: 0.0642564594745636
Validation loss: 1.4501654153229089

Epoch: 6| Step: 13
Training loss: 0.08083584904670715
Validation loss: 1.4328862499165278

Epoch: 484| Step: 0
Training loss: 0.05559763312339783
Validation loss: 1.4221674383327525

Epoch: 6| Step: 1
Training loss: 0.0764484703540802
Validation loss: 1.4398999739718694

Epoch: 6| Step: 2
Training loss: 0.08707954734563828
Validation loss: 1.458863841590061

Epoch: 6| Step: 3
Training loss: 0.13645464181900024
Validation loss: 1.4256926954433482

Epoch: 6| Step: 4
Training loss: 0.06281191110610962
Validation loss: 1.435619697775892

Epoch: 6| Step: 5
Training loss: 0.08099682629108429
Validation loss: 1.4272007326925955

Epoch: 6| Step: 6
Training loss: 0.08445845544338226
Validation loss: 1.4433708472918438

Epoch: 6| Step: 7
Training loss: 0.06960305571556091
Validation loss: 1.4252713091911808

Epoch: 6| Step: 8
Training loss: 0.07906987518072128
Validation loss: 1.4181002186190697

Epoch: 6| Step: 9
Training loss: 0.12142530083656311
Validation loss: 1.429522886071154

Epoch: 6| Step: 10
Training loss: 0.11540517956018448
Validation loss: 1.4430045427814606

Epoch: 6| Step: 11
Training loss: 0.0593588724732399
Validation loss: 1.4342099005176174

Epoch: 6| Step: 12
Training loss: 0.08141276240348816
Validation loss: 1.4339988987932923

Epoch: 6| Step: 13
Training loss: 0.0889642983675003
Validation loss: 1.4329698970240932

Epoch: 485| Step: 0
Training loss: 0.03473057970404625
Validation loss: 1.4493866979434926

Epoch: 6| Step: 1
Training loss: 0.061520740389823914
Validation loss: 1.406747297574115

Epoch: 6| Step: 2
Training loss: 0.12876258790493011
Validation loss: 1.4492464911553167

Epoch: 6| Step: 3
Training loss: 0.07702287286520004
Validation loss: 1.4618632017925222

Epoch: 6| Step: 4
Training loss: 0.11689348518848419
Validation loss: 1.4629616340001423

Epoch: 6| Step: 5
Training loss: 0.07470227777957916
Validation loss: 1.4409465302703202

Epoch: 6| Step: 6
Training loss: 0.07917296886444092
Validation loss: 1.433875096741543

Epoch: 6| Step: 7
Training loss: 0.08347028493881226
Validation loss: 1.467517407991553

Epoch: 6| Step: 8
Training loss: 0.08194354176521301
Validation loss: 1.4441723092909782

Epoch: 6| Step: 9
Training loss: 0.06765028834342957
Validation loss: 1.4746189091795234

Epoch: 6| Step: 10
Training loss: 0.08724844455718994
Validation loss: 1.4285997242055914

Epoch: 6| Step: 11
Training loss: 0.1165686622262001
Validation loss: 1.4598507701709706

Epoch: 6| Step: 12
Training loss: 0.07166653126478195
Validation loss: 1.4495846417642408

Epoch: 6| Step: 13
Training loss: 0.18651333451271057
Validation loss: 1.4449214140574138

Epoch: 486| Step: 0
Training loss: 0.06929457932710648
Validation loss: 1.4715444311018913

Epoch: 6| Step: 1
Training loss: 0.09905456006526947
Validation loss: 1.4383253435934744

Epoch: 6| Step: 2
Training loss: 0.09771481156349182
Validation loss: 1.4774424927209013

Epoch: 6| Step: 3
Training loss: 0.20541217923164368
Validation loss: 1.4511510954108289

Epoch: 6| Step: 4
Training loss: 0.05634003132581711
Validation loss: 1.4701570285263883

Epoch: 6| Step: 5
Training loss: 0.05502237007021904
Validation loss: 1.4477714633428922

Epoch: 6| Step: 6
Training loss: 0.07796482741832733
Validation loss: 1.465759515762329

Epoch: 6| Step: 7
Training loss: 0.0884520635008812
Validation loss: 1.440513450612304

Epoch: 6| Step: 8
Training loss: 0.04806730896234512
Validation loss: 1.4577768566787883

Epoch: 6| Step: 9
Training loss: 0.05047912895679474
Validation loss: 1.4392114646973149

Epoch: 6| Step: 10
Training loss: 0.0686916634440422
Validation loss: 1.4441825164261686

Epoch: 6| Step: 11
Training loss: 0.09889544546604156
Validation loss: 1.4530549382650724

Epoch: 6| Step: 12
Training loss: 0.08393094688653946
Validation loss: 1.43263792222546

Epoch: 6| Step: 13
Training loss: 0.08597931265830994
Validation loss: 1.4537152333926129

Epoch: 487| Step: 0
Training loss: 0.08325005322694778
Validation loss: 1.4657777932382399

Epoch: 6| Step: 1
Training loss: 0.10965748876333237
Validation loss: 1.4408212207978772

Epoch: 6| Step: 2
Training loss: 0.09389004111289978
Validation loss: 1.4358004370043356

Epoch: 6| Step: 3
Training loss: 0.08524081856012344
Validation loss: 1.4540908785276516

Epoch: 6| Step: 4
Training loss: 0.05180142819881439
Validation loss: 1.4255601629134147

Epoch: 6| Step: 5
Training loss: 0.1062345802783966
Validation loss: 1.44478125597841

Epoch: 6| Step: 6
Training loss: 0.08334887772798538
Validation loss: 1.4320280090455086

Epoch: 6| Step: 7
Training loss: 0.06190301477909088
Validation loss: 1.4566759319715603

Epoch: 6| Step: 8
Training loss: 0.11982756108045578
Validation loss: 1.4485024553473278

Epoch: 6| Step: 9
Training loss: 0.05604362115263939
Validation loss: 1.4677917181804616

Epoch: 6| Step: 10
Training loss: 0.10555972158908844
Validation loss: 1.45342872347883

Epoch: 6| Step: 11
Training loss: 0.14410704374313354
Validation loss: 1.471662291916468

Epoch: 6| Step: 12
Training loss: 0.10925459116697311
Validation loss: 1.4886654179583314

Epoch: 6| Step: 13
Training loss: 0.15097996592521667
Validation loss: 1.461691096905739

Epoch: 488| Step: 0
Training loss: 0.0646432638168335
Validation loss: 1.4473350458247687

Epoch: 6| Step: 1
Training loss: 0.06171344220638275
Validation loss: 1.4677168746148386

Epoch: 6| Step: 2
Training loss: 0.09658308327198029
Validation loss: 1.4321432280284103

Epoch: 6| Step: 3
Training loss: 0.10665055364370346
Validation loss: 1.4214311594604163

Epoch: 6| Step: 4
Training loss: 0.06388142704963684
Validation loss: 1.4678644185425134

Epoch: 6| Step: 5
Training loss: 0.10258553922176361
Validation loss: 1.4458944900061494

Epoch: 6| Step: 6
Training loss: 0.13661059737205505
Validation loss: 1.4643144453725507

Epoch: 6| Step: 7
Training loss: 0.08521764725446701
Validation loss: 1.454876483127635

Epoch: 6| Step: 8
Training loss: 0.09777767211198807
Validation loss: 1.445837179819743

Epoch: 6| Step: 9
Training loss: 0.07941934466362
Validation loss: 1.4387410520225443

Epoch: 6| Step: 10
Training loss: 0.10208875685930252
Validation loss: 1.4611149205956409

Epoch: 6| Step: 11
Training loss: 0.09829771518707275
Validation loss: 1.455829756875192

Epoch: 6| Step: 12
Training loss: 0.07445526123046875
Validation loss: 1.4760172367095947

Epoch: 6| Step: 13
Training loss: 0.0703643262386322
Validation loss: 1.4921186880398822

Epoch: 489| Step: 0
Training loss: 0.06988310068845749
Validation loss: 1.5054419168861963

Epoch: 6| Step: 1
Training loss: 0.11274496465921402
Validation loss: 1.5039850864359128

Epoch: 6| Step: 2
Training loss: 0.13162781298160553
Validation loss: 1.4654365072968185

Epoch: 6| Step: 3
Training loss: 0.05459287762641907
Validation loss: 1.499220126418657

Epoch: 6| Step: 4
Training loss: 0.07281115651130676
Validation loss: 1.513136694508214

Epoch: 6| Step: 5
Training loss: 0.0452851764857769
Validation loss: 1.4666287591380458

Epoch: 6| Step: 6
Training loss: 0.07724298536777496
Validation loss: 1.4527534342581225

Epoch: 6| Step: 7
Training loss: 0.05743658170104027
Validation loss: 1.4881925518794725

Epoch: 6| Step: 8
Training loss: 0.112433522939682
Validation loss: 1.4836149010606992

Epoch: 6| Step: 9
Training loss: 0.11525008827447891
Validation loss: 1.4776407839149557

Epoch: 6| Step: 10
Training loss: 0.042946022003889084
Validation loss: 1.4515832983037478

Epoch: 6| Step: 11
Training loss: 0.039232801645994186
Validation loss: 1.465809210654228

Epoch: 6| Step: 12
Training loss: 0.08973219990730286
Validation loss: 1.437591427756894

Epoch: 6| Step: 13
Training loss: 0.07399031519889832
Validation loss: 1.433506945128082

Epoch: 490| Step: 0
Training loss: 0.059082698076963425
Validation loss: 1.4438230068452897

Epoch: 6| Step: 1
Training loss: 0.09537472575902939
Validation loss: 1.4260844466506795

Epoch: 6| Step: 2
Training loss: 0.10146361589431763
Validation loss: 1.4228264804809325

Epoch: 6| Step: 3
Training loss: 0.0551324188709259
Validation loss: 1.464231200115655

Epoch: 6| Step: 4
Training loss: 0.06564395129680634
Validation loss: 1.4348671372218798

Epoch: 6| Step: 5
Training loss: 0.08362200856208801
Validation loss: 1.4616389011824003

Epoch: 6| Step: 6
Training loss: 0.03833460062742233
Validation loss: 1.4672968490149385

Epoch: 6| Step: 7
Training loss: 0.16929438710212708
Validation loss: 1.468911788796866

Epoch: 6| Step: 8
Training loss: 0.09740343689918518
Validation loss: 1.4639829743293025

Epoch: 6| Step: 9
Training loss: 0.1621771603822708
Validation loss: 1.4624843379502654

Epoch: 6| Step: 10
Training loss: 0.15043696761131287
Validation loss: 1.461242914199829

Epoch: 6| Step: 11
Training loss: 0.09274104237556458
Validation loss: 1.4408014141103274

Epoch: 6| Step: 12
Training loss: 0.1478932797908783
Validation loss: 1.4621674764540888

Epoch: 6| Step: 13
Training loss: 0.051219478249549866
Validation loss: 1.4371240139007568

Epoch: 491| Step: 0
Training loss: 0.09492678940296173
Validation loss: 1.4377896683190459

Epoch: 6| Step: 1
Training loss: 0.08419997990131378
Validation loss: 1.425538860341554

Epoch: 6| Step: 2
Training loss: 0.12572409212589264
Validation loss: 1.442861233988116

Epoch: 6| Step: 3
Training loss: 0.13133062422275543
Validation loss: 1.4237357519006217

Epoch: 6| Step: 4
Training loss: 0.08413761109113693
Validation loss: 1.4237831049068

Epoch: 6| Step: 5
Training loss: 0.0619642548263073
Validation loss: 1.4123809004342684

Epoch: 6| Step: 6
Training loss: 0.0448015034198761
Validation loss: 1.4255537871391541

Epoch: 6| Step: 7
Training loss: 0.08799533545970917
Validation loss: 1.4156148074775614

Epoch: 6| Step: 8
Training loss: 0.14441025257110596
Validation loss: 1.4260480711537022

Epoch: 6| Step: 9
Training loss: 0.11965805292129517
Validation loss: 1.4218147813632924

Epoch: 6| Step: 10
Training loss: 0.06687772274017334
Validation loss: 1.4344303184939968

Epoch: 6| Step: 11
Training loss: 0.07302346080541611
Validation loss: 1.4328416880740915

Epoch: 6| Step: 12
Training loss: 0.07325094193220139
Validation loss: 1.4457383284004786

Epoch: 6| Step: 13
Training loss: 0.09429224580526352
Validation loss: 1.4141846651672034

Epoch: 492| Step: 0
Training loss: 0.0769900530576706
Validation loss: 1.4217940107468636

Epoch: 6| Step: 1
Training loss: 0.12632012367248535
Validation loss: 1.4470376840201757

Epoch: 6| Step: 2
Training loss: 0.08839719742536545
Validation loss: 1.4179133548531482

Epoch: 6| Step: 3
Training loss: 0.07417838275432587
Validation loss: 1.4469164674000075

Epoch: 6| Step: 4
Training loss: 0.10464464873075485
Validation loss: 1.4153096240053895

Epoch: 6| Step: 5
Training loss: 0.06998659670352936
Validation loss: 1.4311140468043666

Epoch: 6| Step: 6
Training loss: 0.14449293911457062
Validation loss: 1.4053069558194888

Epoch: 6| Step: 7
Training loss: 0.07015261054039001
Validation loss: 1.4206218847664454

Epoch: 6| Step: 8
Training loss: 0.10526125133037567
Validation loss: 1.4018650093386251

Epoch: 6| Step: 9
Training loss: 0.12850604951381683
Validation loss: 1.4268516391836188

Epoch: 6| Step: 10
Training loss: 0.1417209506034851
Validation loss: 1.4201400113362137

Epoch: 6| Step: 11
Training loss: 0.07426285743713379
Validation loss: 1.4338475581138366

Epoch: 6| Step: 12
Training loss: 0.09256985783576965
Validation loss: 1.4462837160274546

Epoch: 6| Step: 13
Training loss: 0.1334937959909439
Validation loss: 1.4652008536041423

Epoch: 493| Step: 0
Training loss: 0.10950228571891785
Validation loss: 1.4694301710333875

Epoch: 6| Step: 1
Training loss: 0.07534806430339813
Validation loss: 1.4616630666999406

Epoch: 6| Step: 2
Training loss: 0.09225831925868988
Validation loss: 1.4487004241635721

Epoch: 6| Step: 3
Training loss: 0.1168166846036911
Validation loss: 1.4598702666580037

Epoch: 6| Step: 4
Training loss: 0.0678478330373764
Validation loss: 1.436356076630213

Epoch: 6| Step: 5
Training loss: 0.0637219175696373
Validation loss: 1.4248678222779305

Epoch: 6| Step: 6
Training loss: 0.1025111973285675
Validation loss: 1.4297168229215889

Epoch: 6| Step: 7
Training loss: 0.06115257367491722
Validation loss: 1.4601595555582354

Epoch: 6| Step: 8
Training loss: 0.10665445774793625
Validation loss: 1.4796215808519753

Epoch: 6| Step: 9
Training loss: 0.23004575073719025
Validation loss: 1.4965199155192221

Epoch: 6| Step: 10
Training loss: 0.1497807502746582
Validation loss: 1.5034782271231375

Epoch: 6| Step: 11
Training loss: 0.13588747382164001
Validation loss: 1.4822600631303684

Epoch: 6| Step: 12
Training loss: 0.09198100864887238
Validation loss: 1.4821891041212185

Epoch: 6| Step: 13
Training loss: 0.11387768387794495
Validation loss: 1.4733874067183463

Epoch: 494| Step: 0
Training loss: 0.10675057023763657
Validation loss: 1.480624755223592

Epoch: 6| Step: 1
Training loss: 0.06777583062648773
Validation loss: 1.4730565419761084

Epoch: 6| Step: 2
Training loss: 0.09154593199491501
Validation loss: 1.524722578704998

Epoch: 6| Step: 3
Training loss: 0.18042287230491638
Validation loss: 1.541138328531737

Epoch: 6| Step: 4
Training loss: 0.0798516720533371
Validation loss: 1.5532372049106065

Epoch: 6| Step: 5
Training loss: 0.04007549211382866
Validation loss: 1.5404126695407334

Epoch: 6| Step: 6
Training loss: 0.07028135657310486
Validation loss: 1.5634706417719524

Epoch: 6| Step: 7
Training loss: 0.1191747784614563
Validation loss: 1.5457850976656842

Epoch: 6| Step: 8
Training loss: 0.11252230405807495
Validation loss: 1.5463139510923816

Epoch: 6| Step: 9
Training loss: 0.18239283561706543
Validation loss: 1.5278634653296521

Epoch: 6| Step: 10
Training loss: 0.12951400876045227
Validation loss: 1.5406697680873256

Epoch: 6| Step: 11
Training loss: 0.16592192649841309
Validation loss: 1.5118553625640048

Epoch: 6| Step: 12
Training loss: 0.15747198462486267
Validation loss: 1.531891502359862

Epoch: 6| Step: 13
Training loss: 0.0799495279788971
Validation loss: 1.5099503045441003

Epoch: 495| Step: 0
Training loss: 0.07877320051193237
Validation loss: 1.5102045894950948

Epoch: 6| Step: 1
Training loss: 0.11965016275644302
Validation loss: 1.5225978743645452

Epoch: 6| Step: 2
Training loss: 0.06674009561538696
Validation loss: 1.4946978502376105

Epoch: 6| Step: 3
Training loss: 0.07373814284801483
Validation loss: 1.5186519135711014

Epoch: 6| Step: 4
Training loss: 0.17859575152397156
Validation loss: 1.4804912869648268

Epoch: 6| Step: 5
Training loss: 0.1445046067237854
Validation loss: 1.4758768299574494

Epoch: 6| Step: 6
Training loss: 0.08620799332857132
Validation loss: 1.483647277278285

Epoch: 6| Step: 7
Training loss: 0.07589708268642426
Validation loss: 1.4670254697081864

Epoch: 6| Step: 8
Training loss: 0.12860175967216492
Validation loss: 1.4754560961518237

Epoch: 6| Step: 9
Training loss: 0.14466159045696259
Validation loss: 1.4638080475150899

Epoch: 6| Step: 10
Training loss: 0.15172474086284637
Validation loss: 1.4780060257962955

Epoch: 6| Step: 11
Training loss: 0.13179555535316467
Validation loss: 1.4526495420804588

Epoch: 6| Step: 12
Training loss: 0.10031744837760925
Validation loss: 1.4313194751739502

Epoch: 6| Step: 13
Training loss: 0.07486012578010559
Validation loss: 1.4374000744153095

Epoch: 496| Step: 0
Training loss: 0.11143326014280319
Validation loss: 1.4421930309905802

Epoch: 6| Step: 1
Training loss: 0.13277843594551086
Validation loss: 1.4291193305805165

Epoch: 6| Step: 2
Training loss: 0.07268953323364258
Validation loss: 1.40837800118231

Epoch: 6| Step: 3
Training loss: 0.17041383683681488
Validation loss: 1.3900498792689333

Epoch: 6| Step: 4
Training loss: 0.06221713498234749
Validation loss: 1.3993079559777373

Epoch: 6| Step: 5
Training loss: 0.13912570476531982
Validation loss: 1.4222615995714742

Epoch: 6| Step: 6
Training loss: 0.08332844078540802
Validation loss: 1.4066979981237842

Epoch: 6| Step: 7
Training loss: 0.07114633917808533
Validation loss: 1.4327411087610389

Epoch: 6| Step: 8
Training loss: 0.09824304282665253
Validation loss: 1.4000833816425775

Epoch: 6| Step: 9
Training loss: 0.0658131092786789
Validation loss: 1.4185364823187552

Epoch: 6| Step: 10
Training loss: 0.09132271260023117
Validation loss: 1.4314553077502916

Epoch: 6| Step: 11
Training loss: 0.08559983968734741
Validation loss: 1.4210433972779142

Epoch: 6| Step: 12
Training loss: 0.05297033116221428
Validation loss: 1.4140341820255402

Epoch: 6| Step: 13
Training loss: 0.18562938272953033
Validation loss: 1.426590911803707

Epoch: 497| Step: 0
Training loss: 0.05765245854854584
Validation loss: 1.4498589038848877

Epoch: 6| Step: 1
Training loss: 0.10009829699993134
Validation loss: 1.449043740508377

Epoch: 6| Step: 2
Training loss: 0.09866166114807129
Validation loss: 1.4241789143572572

Epoch: 6| Step: 3
Training loss: 0.08790870010852814
Validation loss: 1.452470769805293

Epoch: 6| Step: 4
Training loss: 0.0544283464550972
Validation loss: 1.439246134091449

Epoch: 6| Step: 5
Training loss: 0.07435759902000427
Validation loss: 1.4238944169013732

Epoch: 6| Step: 6
Training loss: 0.1470249593257904
Validation loss: 1.4288034721087384

Epoch: 6| Step: 7
Training loss: 0.11753314733505249
Validation loss: 1.4554604612370974

Epoch: 6| Step: 8
Training loss: 0.09326466917991638
Validation loss: 1.4239129315140426

Epoch: 6| Step: 9
Training loss: 0.04956236481666565
Validation loss: 1.4160883734303136

Epoch: 6| Step: 10
Training loss: 0.08428362011909485
Validation loss: 1.3989650222562975

Epoch: 6| Step: 11
Training loss: 0.0902106761932373
Validation loss: 1.4299377254260484

Epoch: 6| Step: 12
Training loss: 0.1269398033618927
Validation loss: 1.440427126423005

Epoch: 6| Step: 13
Training loss: 0.11331343650817871
Validation loss: 1.4162885258274693

Epoch: 498| Step: 0
Training loss: 0.06346730887889862
Validation loss: 1.437715663704821

Epoch: 6| Step: 1
Training loss: 0.10269230604171753
Validation loss: 1.4238809513789352

Epoch: 6| Step: 2
Training loss: 0.09313622862100601
Validation loss: 1.4760763734899542

Epoch: 6| Step: 3
Training loss: 0.0696297287940979
Validation loss: 1.477291230232485

Epoch: 6| Step: 4
Training loss: 0.11562929302453995
Validation loss: 1.4589724194618963

Epoch: 6| Step: 5
Training loss: 0.12650468945503235
Validation loss: 1.4547190961017404

Epoch: 6| Step: 6
Training loss: 0.14320512115955353
Validation loss: 1.459113811933866

Epoch: 6| Step: 7
Training loss: 0.0536147803068161
Validation loss: 1.4541756465870848

Epoch: 6| Step: 8
Training loss: 0.09671330451965332
Validation loss: 1.4858093120718514

Epoch: 6| Step: 9
Training loss: 0.06380878388881683
Validation loss: 1.483048863308404

Epoch: 6| Step: 10
Training loss: 0.14563634991645813
Validation loss: 1.4787077403837634

Epoch: 6| Step: 11
Training loss: 0.07630261778831482
Validation loss: 1.483013141539789

Epoch: 6| Step: 12
Training loss: 0.10404373705387115
Validation loss: 1.4633439817736227

Epoch: 6| Step: 13
Training loss: 0.13866204023361206
Validation loss: 1.4314264148794196

Epoch: 499| Step: 0
Training loss: 0.1320885568857193
Validation loss: 1.4793241549563665

Epoch: 6| Step: 1
Training loss: 0.0643061101436615
Validation loss: 1.4417523414857927

Epoch: 6| Step: 2
Training loss: 0.11134812235832214
Validation loss: 1.4290645930074877

Epoch: 6| Step: 3
Training loss: 0.08660607039928436
Validation loss: 1.410054858012866

Epoch: 6| Step: 4
Training loss: 0.09274859726428986
Validation loss: 1.4285427280651626

Epoch: 6| Step: 5
Training loss: 0.07820326089859009
Validation loss: 1.4165502760999946

Epoch: 6| Step: 6
Training loss: 0.09881749749183655
Validation loss: 1.4190779501391995

Epoch: 6| Step: 7
Training loss: 0.057333819568157196
Validation loss: 1.4520868691064979

Epoch: 6| Step: 8
Training loss: 0.07191502302885056
Validation loss: 1.455836437081778

Epoch: 6| Step: 9
Training loss: 0.07262042909860611
Validation loss: 1.4455500110503166

Epoch: 6| Step: 10
Training loss: 0.1259934902191162
Validation loss: 1.4546907364681203

Epoch: 6| Step: 11
Training loss: 0.08682817220687866
Validation loss: 1.4422650106491581

Epoch: 6| Step: 12
Training loss: 0.15023812651634216
Validation loss: 1.4711393643450994

Epoch: 6| Step: 13
Training loss: 0.06927946209907532
Validation loss: 1.429992606562953

Epoch: 500| Step: 0
Training loss: 0.11104875802993774
Validation loss: 1.4525330784500285

Epoch: 6| Step: 1
Training loss: 0.09621348232030869
Validation loss: 1.4288700934379333

Epoch: 6| Step: 2
Training loss: 0.08464566618204117
Validation loss: 1.416392050763612

Epoch: 6| Step: 3
Training loss: 0.09544099122285843
Validation loss: 1.4634419916778483

Epoch: 6| Step: 4
Training loss: 0.06547985225915909
Validation loss: 1.4518754238723426

Epoch: 6| Step: 5
Training loss: 0.09361529350280762
Validation loss: 1.438040796146598

Epoch: 6| Step: 6
Training loss: 0.0625818744301796
Validation loss: 1.465210913329996

Epoch: 6| Step: 7
Training loss: 0.10479654371738434
Validation loss: 1.473205840715798

Epoch: 6| Step: 8
Training loss: 0.05966934561729431
Validation loss: 1.4707681748174852

Epoch: 6| Step: 9
Training loss: 0.0493122860789299
Validation loss: 1.4568159554594307

Epoch: 6| Step: 10
Training loss: 0.14517301321029663
Validation loss: 1.466399234469219

Epoch: 6| Step: 11
Training loss: 0.07978378236293793
Validation loss: 1.4759240970816663

Epoch: 6| Step: 12
Training loss: 0.08464128524065018
Validation loss: 1.4600522197702879

Epoch: 6| Step: 13
Training loss: 0.1149974912405014
Validation loss: 1.466771291148278

Epoch: 501| Step: 0
Training loss: 0.08211412280797958
Validation loss: 1.445576520376308

Epoch: 6| Step: 1
Training loss: 0.06388029456138611
Validation loss: 1.4787540166608748

Epoch: 6| Step: 2
Training loss: 0.07410456240177155
Validation loss: 1.4540235893700713

Epoch: 6| Step: 3
Training loss: 0.09596410393714905
Validation loss: 1.4614763029160038

Epoch: 6| Step: 4
Training loss: 0.10129407793283463
Validation loss: 1.4458681755168463

Epoch: 6| Step: 5
Training loss: 0.11861036717891693
Validation loss: 1.4267907565639866

Epoch: 6| Step: 6
Training loss: 0.09848038852214813
Validation loss: 1.450025563598961

Epoch: 6| Step: 7
Training loss: 0.06278088688850403
Validation loss: 1.4071848007940477

Epoch: 6| Step: 8
Training loss: 0.06654737889766693
Validation loss: 1.4281599880546652

Epoch: 6| Step: 9
Training loss: 0.08739431202411652
Validation loss: 1.3748748097368466

Epoch: 6| Step: 10
Training loss: 0.059911470860242844
Validation loss: 1.401113413995312

Epoch: 6| Step: 11
Training loss: 0.07810438424348831
Validation loss: 1.4376413476082586

Epoch: 6| Step: 12
Training loss: 0.06262180954217911
Validation loss: 1.3915760485074853

Epoch: 6| Step: 13
Training loss: 0.10143416374921799
Validation loss: 1.3824676993072673

Epoch: 502| Step: 0
Training loss: 0.08537805080413818
Validation loss: 1.397804715300119

Epoch: 6| Step: 1
Training loss: 0.09319382160902023
Validation loss: 1.382915396203277

Epoch: 6| Step: 2
Training loss: 0.13045141100883484
Validation loss: 1.3936830169411116

Epoch: 6| Step: 3
Training loss: 0.08343558758497238
Validation loss: 1.4034908426705228

Epoch: 6| Step: 4
Training loss: 0.08496639877557755
Validation loss: 1.4056227200774736

Epoch: 6| Step: 5
Training loss: 0.10432055592536926
Validation loss: 1.4329940862553094

Epoch: 6| Step: 6
Training loss: 0.12202788889408112
Validation loss: 1.4544093416583153

Epoch: 6| Step: 7
Training loss: 0.07897564023733139
Validation loss: 1.4272650480270386

Epoch: 6| Step: 8
Training loss: 0.08200374245643616
Validation loss: 1.4646474687002038

Epoch: 6| Step: 9
Training loss: 0.06574786454439163
Validation loss: 1.4878696690323532

Epoch: 6| Step: 10
Training loss: 0.09572171419858932
Validation loss: 1.4678535307607343

Epoch: 6| Step: 11
Training loss: 0.0595625638961792
Validation loss: 1.5048183100197905

Epoch: 6| Step: 12
Training loss: 0.14716635644435883
Validation loss: 1.4800383596010105

Epoch: 6| Step: 13
Training loss: 0.11206947267055511
Validation loss: 1.5152711470921834

Epoch: 503| Step: 0
Training loss: 0.1459725797176361
Validation loss: 1.4983761643850675

Epoch: 6| Step: 1
Training loss: 0.09545597434043884
Validation loss: 1.491073913471673

Epoch: 6| Step: 2
Training loss: 0.044619955122470856
Validation loss: 1.4584703817162463

Epoch: 6| Step: 3
Training loss: 0.06947337090969086
Validation loss: 1.482941658266129

Epoch: 6| Step: 4
Training loss: 0.11047856509685516
Validation loss: 1.4743356115074568

Epoch: 6| Step: 5
Training loss: 0.06236616522073746
Validation loss: 1.4645930926005046

Epoch: 6| Step: 6
Training loss: 0.11422755569219589
Validation loss: 1.4558255557091004

Epoch: 6| Step: 7
Training loss: 0.09186224639415741
Validation loss: 1.4114510654121317

Epoch: 6| Step: 8
Training loss: 0.06768155097961426
Validation loss: 1.4138424499060518

Epoch: 6| Step: 9
Training loss: 0.08442522585391998
Validation loss: 1.4256852326854583

Epoch: 6| Step: 10
Training loss: 0.10085203498601913
Validation loss: 1.4360738403053694

Epoch: 6| Step: 11
Training loss: 0.05978136509656906
Validation loss: 1.4504940689250987

Epoch: 6| Step: 12
Training loss: 0.16548559069633484
Validation loss: 1.45128466749704

Epoch: 6| Step: 13
Training loss: 0.11477753520011902
Validation loss: 1.4230897785514913

Epoch: 504| Step: 0
Training loss: 0.08698020875453949
Validation loss: 1.421981277004365

Epoch: 6| Step: 1
Training loss: 0.09689715504646301
Validation loss: 1.450719223227552

Epoch: 6| Step: 2
Training loss: 0.06379932165145874
Validation loss: 1.4319394032160442

Epoch: 6| Step: 3
Training loss: 0.04678407683968544
Validation loss: 1.4200700559923727

Epoch: 6| Step: 4
Training loss: 0.06744637340307236
Validation loss: 1.4349465088177753

Epoch: 6| Step: 5
Training loss: 0.09501665085554123
Validation loss: 1.4204267506958337

Epoch: 6| Step: 6
Training loss: 0.04318632930517197
Validation loss: 1.4510459861447733

Epoch: 6| Step: 7
Training loss: 0.09215404093265533
Validation loss: 1.4411711474900604

Epoch: 6| Step: 8
Training loss: 0.1605839729309082
Validation loss: 1.4353540161604523

Epoch: 6| Step: 9
Training loss: 0.09102464467287064
Validation loss: 1.4695882848514024

Epoch: 6| Step: 10
Training loss: 0.08914393186569214
Validation loss: 1.4635556923445834

Epoch: 6| Step: 11
Training loss: 0.09166352450847626
Validation loss: 1.4510036412105765

Epoch: 6| Step: 12
Training loss: 0.08887625485658646
Validation loss: 1.4777418234015023

Epoch: 6| Step: 13
Training loss: 0.1681111603975296
Validation loss: 1.4644384948156213

Epoch: 505| Step: 0
Training loss: 0.07573209702968597
Validation loss: 1.4642753742074455

Epoch: 6| Step: 1
Training loss: 0.09861117601394653
Validation loss: 1.4287084200048958

Epoch: 6| Step: 2
Training loss: 0.13075123727321625
Validation loss: 1.4481055390450261

Epoch: 6| Step: 3
Training loss: 0.0929894745349884
Validation loss: 1.466242100602837

Epoch: 6| Step: 4
Training loss: 0.08946865797042847
Validation loss: 1.4356554438990932

Epoch: 6| Step: 5
Training loss: 0.11395394802093506
Validation loss: 1.4582383683932725

Epoch: 6| Step: 6
Training loss: 0.06421766430139542
Validation loss: 1.4549751102283437

Epoch: 6| Step: 7
Training loss: 0.0960586816072464
Validation loss: 1.4476682127162974

Epoch: 6| Step: 8
Training loss: 0.11111282557249069
Validation loss: 1.4526107682976672

Epoch: 6| Step: 9
Training loss: 0.09546247869729996
Validation loss: 1.4601418920742568

Epoch: 6| Step: 10
Training loss: 0.04867608845233917
Validation loss: 1.4467652241388957

Epoch: 6| Step: 11
Training loss: 0.11019659787416458
Validation loss: 1.41826690653319

Epoch: 6| Step: 12
Training loss: 0.10162711143493652
Validation loss: 1.4359476239450517

Epoch: 6| Step: 13
Training loss: 0.10303931683301926
Validation loss: 1.4753985148604198

Epoch: 506| Step: 0
Training loss: 0.11795365065336227
Validation loss: 1.4360008291018906

Epoch: 6| Step: 1
Training loss: 0.20974919199943542
Validation loss: 1.4245629900245256

Epoch: 6| Step: 2
Training loss: 0.09481578320264816
Validation loss: 1.4183497082802556

Epoch: 6| Step: 3
Training loss: 0.15463441610336304
Validation loss: 1.4106835960060038

Epoch: 6| Step: 4
Training loss: 0.06448475271463394
Validation loss: 1.397695601627391

Epoch: 6| Step: 5
Training loss: 0.07801821082830429
Validation loss: 1.4412361203983266

Epoch: 6| Step: 6
Training loss: 0.07472646236419678
Validation loss: 1.4592086320282311

Epoch: 6| Step: 7
Training loss: 0.11665078997612
Validation loss: 1.4464067970552752

Epoch: 6| Step: 8
Training loss: 0.13723069429397583
Validation loss: 1.4534242358258975

Epoch: 6| Step: 9
Training loss: 0.08596106618642807
Validation loss: 1.4434273960769817

Epoch: 6| Step: 10
Training loss: 0.10964815318584442
Validation loss: 1.4614276270712576

Epoch: 6| Step: 11
Training loss: 0.06609755754470825
Validation loss: 1.466391714670325

Epoch: 6| Step: 12
Training loss: 0.06796801090240479
Validation loss: 1.4565940915897329

Epoch: 6| Step: 13
Training loss: 0.08966615796089172
Validation loss: 1.461357367936001

Epoch: 507| Step: 0
Training loss: 0.08550439774990082
Validation loss: 1.4602590119966896

Epoch: 6| Step: 1
Training loss: 0.0945635586977005
Validation loss: 1.4253658709987518

Epoch: 6| Step: 2
Training loss: 0.1391470730304718
Validation loss: 1.4267306648274904

Epoch: 6| Step: 3
Training loss: 0.0425788052380085
Validation loss: 1.4179717462549928

Epoch: 6| Step: 4
Training loss: 0.0640588328242302
Validation loss: 1.4116996469036225

Epoch: 6| Step: 5
Training loss: 0.10767687112092972
Validation loss: 1.419979246713782

Epoch: 6| Step: 6
Training loss: 0.09862905740737915
Validation loss: 1.4303928036843576

Epoch: 6| Step: 7
Training loss: 0.057454511523246765
Validation loss: 1.4175571664687125

Epoch: 6| Step: 8
Training loss: 0.08343243598937988
Validation loss: 1.419613657459136

Epoch: 6| Step: 9
Training loss: 0.051075153052806854
Validation loss: 1.4517584475137855

Epoch: 6| Step: 10
Training loss: 0.09713739156723022
Validation loss: 1.4467175519594582

Epoch: 6| Step: 11
Training loss: 0.09427772462368011
Validation loss: 1.4138979341394158

Epoch: 6| Step: 12
Training loss: 0.09592106938362122
Validation loss: 1.4246427371937742

Epoch: 6| Step: 13
Training loss: 0.11715410649776459
Validation loss: 1.4298045404495732

Epoch: 508| Step: 0
Training loss: 0.09387269616127014
Validation loss: 1.4519831249790807

Epoch: 6| Step: 1
Training loss: 0.07576999068260193
Validation loss: 1.455184268695052

Epoch: 6| Step: 2
Training loss: 0.08665165305137634
Validation loss: 1.4479709607298656

Epoch: 6| Step: 3
Training loss: 0.11603794991970062
Validation loss: 1.4688611222851662

Epoch: 6| Step: 4
Training loss: 0.15369698405265808
Validation loss: 1.4682367347901868

Epoch: 6| Step: 5
Training loss: 0.08584710955619812
Validation loss: 1.4579185926786034

Epoch: 6| Step: 6
Training loss: 0.13054364919662476
Validation loss: 1.4646597139296993

Epoch: 6| Step: 7
Training loss: 0.05741387978196144
Validation loss: 1.4493031078769314

Epoch: 6| Step: 8
Training loss: 0.11017682403326035
Validation loss: 1.4457296107404976

Epoch: 6| Step: 9
Training loss: 0.05448257923126221
Validation loss: 1.4284292100578226

Epoch: 6| Step: 10
Training loss: 0.08053234219551086
Validation loss: 1.4329843604436485

Epoch: 6| Step: 11
Training loss: 0.08333110064268112
Validation loss: 1.4181679589774019

Epoch: 6| Step: 12
Training loss: 0.04867464676499367
Validation loss: 1.4299312919698737

Epoch: 6| Step: 13
Training loss: 0.1347087025642395
Validation loss: 1.4300492886574037

Epoch: 509| Step: 0
Training loss: 0.08463279157876968
Validation loss: 1.4533835444399106

Epoch: 6| Step: 1
Training loss: 0.07370045781135559
Validation loss: 1.423150138188434

Epoch: 6| Step: 2
Training loss: 0.058396607637405396
Validation loss: 1.4348789709870533

Epoch: 6| Step: 3
Training loss: 0.15542034804821014
Validation loss: 1.4295700468042845

Epoch: 6| Step: 4
Training loss: 0.08379088342189789
Validation loss: 1.4423530864459213

Epoch: 6| Step: 5
Training loss: 0.11944087594747543
Validation loss: 1.4280158729963406

Epoch: 6| Step: 6
Training loss: 0.0956445038318634
Validation loss: 1.4053201745915156

Epoch: 6| Step: 7
Training loss: 0.0723298192024231
Validation loss: 1.4181848277327835

Epoch: 6| Step: 8
Training loss: 0.06390631943941116
Validation loss: 1.42853283497595

Epoch: 6| Step: 9
Training loss: 0.10823865234851837
Validation loss: 1.366810748654027

Epoch: 6| Step: 10
Training loss: 0.08849269151687622
Validation loss: 1.4067521800277054

Epoch: 6| Step: 11
Training loss: 0.11890412867069244
Validation loss: 1.410771328915832

Epoch: 6| Step: 12
Training loss: 0.08964599668979645
Validation loss: 1.407317082728109

Epoch: 6| Step: 13
Training loss: 0.03304089605808258
Validation loss: 1.427957187416733

Epoch: 510| Step: 0
Training loss: 0.06841801851987839
Validation loss: 1.4139286395042174

Epoch: 6| Step: 1
Training loss: 0.07547340542078018
Validation loss: 1.3928825470709032

Epoch: 6| Step: 2
Training loss: 0.09131958335638046
Validation loss: 1.412174573508642

Epoch: 6| Step: 3
Training loss: 0.05774585157632828
Validation loss: 1.3947572605584257

Epoch: 6| Step: 4
Training loss: 0.0610068142414093
Validation loss: 1.412018500348573

Epoch: 6| Step: 5
Training loss: 0.055363282561302185
Validation loss: 1.4043444625792965

Epoch: 6| Step: 6
Training loss: 0.09359563887119293
Validation loss: 1.410392617666593

Epoch: 6| Step: 7
Training loss: 0.1024896427989006
Validation loss: 1.427133273052913

Epoch: 6| Step: 8
Training loss: 0.11820526421070099
Validation loss: 1.4054793145066948

Epoch: 6| Step: 9
Training loss: 0.051793068647384644
Validation loss: 1.3961906458741875

Epoch: 6| Step: 10
Training loss: 0.04950641095638275
Validation loss: 1.4152120133881927

Epoch: 6| Step: 11
Training loss: 0.06741472333669662
Validation loss: 1.4235537872519544

Epoch: 6| Step: 12
Training loss: 0.08714023977518082
Validation loss: 1.4125096727442998

Epoch: 6| Step: 13
Training loss: 0.08716312795877457
Validation loss: 1.4181448144297446

Epoch: 511| Step: 0
Training loss: 0.03840278089046478
Validation loss: 1.4457094233523133

Epoch: 6| Step: 1
Training loss: 0.07139606773853302
Validation loss: 1.4382935608586958

Epoch: 6| Step: 2
Training loss: 0.07938463985919952
Validation loss: 1.4493228748280516

Epoch: 6| Step: 3
Training loss: 0.09255260229110718
Validation loss: 1.413924677397615

Epoch: 6| Step: 4
Training loss: 0.10833585262298584
Validation loss: 1.4388131403153943

Epoch: 6| Step: 5
Training loss: 0.08482254296541214
Validation loss: 1.4637100594018095

Epoch: 6| Step: 6
Training loss: 0.06833633780479431
Validation loss: 1.436470744430378

Epoch: 6| Step: 7
Training loss: 0.10263284295797348
Validation loss: 1.48923707777454

Epoch: 6| Step: 8
Training loss: 0.049488894641399384
Validation loss: 1.4938104729498587

Epoch: 6| Step: 9
Training loss: 0.06673073768615723
Validation loss: 1.4806865088401302

Epoch: 6| Step: 10
Training loss: 0.03728649765253067
Validation loss: 1.4924549018183062

Epoch: 6| Step: 11
Training loss: 0.08513984829187393
Validation loss: 1.490891505313176

Epoch: 6| Step: 12
Training loss: 0.07969040423631668
Validation loss: 1.4689761098995004

Epoch: 6| Step: 13
Training loss: 0.040409285575151443
Validation loss: 1.475870244605567

Epoch: 512| Step: 0
Training loss: 0.06587547808885574
Validation loss: 1.4671182786264727

Epoch: 6| Step: 1
Training loss: 0.07554072141647339
Validation loss: 1.4805304824665029

Epoch: 6| Step: 2
Training loss: 0.06333260983228683
Validation loss: 1.480593857585743

Epoch: 6| Step: 3
Training loss: 0.09743629395961761
Validation loss: 1.4698683843817761

Epoch: 6| Step: 4
Training loss: 0.11327438056468964
Validation loss: 1.4690443751632527

Epoch: 6| Step: 5
Training loss: 0.09968364238739014
Validation loss: 1.4453175055083407

Epoch: 6| Step: 6
Training loss: 0.06726428121328354
Validation loss: 1.4649176892413889

Epoch: 6| Step: 7
Training loss: 0.078626349568367
Validation loss: 1.4444194455300607

Epoch: 6| Step: 8
Training loss: 0.07682967185974121
Validation loss: 1.4185262046834475

Epoch: 6| Step: 9
Training loss: 0.05371711775660515
Validation loss: 1.4410081627548381

Epoch: 6| Step: 10
Training loss: 0.09958864748477936
Validation loss: 1.4191380585393598

Epoch: 6| Step: 11
Training loss: 0.10632754117250443
Validation loss: 1.427998560731129

Epoch: 6| Step: 12
Training loss: 0.09042633324861526
Validation loss: 1.4360588571076751

Epoch: 6| Step: 13
Training loss: 0.05023869872093201
Validation loss: 1.4278695493616083

Epoch: 513| Step: 0
Training loss: 0.037220701575279236
Validation loss: 1.440556142919807

Epoch: 6| Step: 1
Training loss: 0.07476092875003815
Validation loss: 1.4832083320104947

Epoch: 6| Step: 2
Training loss: 0.12190348654985428
Validation loss: 1.448265294233958

Epoch: 6| Step: 3
Training loss: 0.07208354771137238
Validation loss: 1.4607862923094022

Epoch: 6| Step: 4
Training loss: 0.0712459534406662
Validation loss: 1.443261605437084

Epoch: 6| Step: 5
Training loss: 0.11712400615215302
Validation loss: 1.4245855615985008

Epoch: 6| Step: 6
Training loss: 0.0455092117190361
Validation loss: 1.4112849427807717

Epoch: 6| Step: 7
Training loss: 0.09488765895366669
Validation loss: 1.418924811065838

Epoch: 6| Step: 8
Training loss: 0.07785702496767044
Validation loss: 1.4299720564196188

Epoch: 6| Step: 9
Training loss: 0.1115640252828598
Validation loss: 1.4022678905917751

Epoch: 6| Step: 10
Training loss: 0.08602787554264069
Validation loss: 1.3979630636912521

Epoch: 6| Step: 11
Training loss: 0.11910296976566315
Validation loss: 1.4108213609264744

Epoch: 6| Step: 12
Training loss: 0.11499007791280746
Validation loss: 1.403903789417718

Epoch: 6| Step: 13
Training loss: 0.10783108323812485
Validation loss: 1.4071145929316038

Epoch: 514| Step: 0
Training loss: 0.11937890201807022
Validation loss: 1.40117557074434

Epoch: 6| Step: 1
Training loss: 0.07181904464960098
Validation loss: 1.4085688475639588

Epoch: 6| Step: 2
Training loss: 0.11006651818752289
Validation loss: 1.39960180687648

Epoch: 6| Step: 3
Training loss: 0.06833937764167786
Validation loss: 1.4171400384236408

Epoch: 6| Step: 4
Training loss: 0.07150186598300934
Validation loss: 1.4338673160922142

Epoch: 6| Step: 5
Training loss: 0.14611393213272095
Validation loss: 1.4213896669367307

Epoch: 6| Step: 6
Training loss: 0.09465605765581131
Validation loss: 1.438267341224096

Epoch: 6| Step: 7
Training loss: 0.0957685261964798
Validation loss: 1.4678934402363275

Epoch: 6| Step: 8
Training loss: 0.09496354311704636
Validation loss: 1.465797419189125

Epoch: 6| Step: 9
Training loss: 0.09721244871616364
Validation loss: 1.4727507579711177

Epoch: 6| Step: 10
Training loss: 0.09616660326719284
Validation loss: 1.4761581183761678

Epoch: 6| Step: 11
Training loss: 0.08444017171859741
Validation loss: 1.4857556563551708

Epoch: 6| Step: 12
Training loss: 0.09816054999828339
Validation loss: 1.4639742573102315

Epoch: 6| Step: 13
Training loss: 0.11001353710889816
Validation loss: 1.4802040169315953

Epoch: 515| Step: 0
Training loss: 0.06416164338588715
Validation loss: 1.4653381660420408

Epoch: 6| Step: 1
Training loss: 0.0902908518910408
Validation loss: 1.504444485069603

Epoch: 6| Step: 2
Training loss: 0.0694790706038475
Validation loss: 1.4503095508903585

Epoch: 6| Step: 3
Training loss: 0.0761319026350975
Validation loss: 1.4295669255718109

Epoch: 6| Step: 4
Training loss: 0.054683513939380646
Validation loss: 1.4482031310758283

Epoch: 6| Step: 5
Training loss: 0.09303441643714905
Validation loss: 1.4246443484419136

Epoch: 6| Step: 6
Training loss: 0.07887648791074753
Validation loss: 1.4071741257944415

Epoch: 6| Step: 7
Training loss: 0.07733702659606934
Validation loss: 1.4383556996622393

Epoch: 6| Step: 8
Training loss: 0.04480154812335968
Validation loss: 1.4229426134017207

Epoch: 6| Step: 9
Training loss: 0.09597471356391907
Validation loss: 1.4458606307224562

Epoch: 6| Step: 10
Training loss: 0.10178562998771667
Validation loss: 1.4502285347189954

Epoch: 6| Step: 11
Training loss: 0.11604931205511093
Validation loss: 1.4284954481227423

Epoch: 6| Step: 12
Training loss: 0.09772954881191254
Validation loss: 1.4383635956753966

Epoch: 6| Step: 13
Training loss: 0.08250697702169418
Validation loss: 1.426777692251308

Epoch: 516| Step: 0
Training loss: 0.09004151821136475
Validation loss: 1.449975513642834

Epoch: 6| Step: 1
Training loss: 0.08734606206417084
Validation loss: 1.4528124755428684

Epoch: 6| Step: 2
Training loss: 0.06597896665334702
Validation loss: 1.433578731552247

Epoch: 6| Step: 3
Training loss: 0.07779017090797424
Validation loss: 1.4256859389684533

Epoch: 6| Step: 4
Training loss: 0.08532966673374176
Validation loss: 1.4371864923866846

Epoch: 6| Step: 5
Training loss: 0.09661353379487991
Validation loss: 1.4310318731492566

Epoch: 6| Step: 6
Training loss: 0.09415291249752045
Validation loss: 1.44415497010754

Epoch: 6| Step: 7
Training loss: 0.08543798327445984
Validation loss: 1.4144403062840945

Epoch: 6| Step: 8
Training loss: 0.07103478908538818
Validation loss: 1.441597532200557

Epoch: 6| Step: 9
Training loss: 0.06285031139850616
Validation loss: 1.4235060907179309

Epoch: 6| Step: 10
Training loss: 0.08225712925195694
Validation loss: 1.4453596697058728

Epoch: 6| Step: 11
Training loss: 0.11718561500310898
Validation loss: 1.4467028840895622

Epoch: 6| Step: 12
Training loss: 0.0715763121843338
Validation loss: 1.4644151785040413

Epoch: 6| Step: 13
Training loss: 0.08096538484096527
Validation loss: 1.445257056143976

Epoch: 517| Step: 0
Training loss: 0.1230778619647026
Validation loss: 1.4594169252662248

Epoch: 6| Step: 1
Training loss: 0.08908934146165848
Validation loss: 1.4570485827743367

Epoch: 6| Step: 2
Training loss: 0.04929574579000473
Validation loss: 1.4498501823794456

Epoch: 6| Step: 3
Training loss: 0.08855482190847397
Validation loss: 1.4590434566620858

Epoch: 6| Step: 4
Training loss: 0.06193098798394203
Validation loss: 1.454929982462237

Epoch: 6| Step: 5
Training loss: 0.10289779305458069
Validation loss: 1.435278982244512

Epoch: 6| Step: 6
Training loss: 0.08559795469045639
Validation loss: 1.4350551610351892

Epoch: 6| Step: 7
Training loss: 0.04435032233595848
Validation loss: 1.41785511150155

Epoch: 6| Step: 8
Training loss: 0.060950495302677155
Validation loss: 1.4222193876261353

Epoch: 6| Step: 9
Training loss: 0.09463820606470108
Validation loss: 1.4023419426333519

Epoch: 6| Step: 10
Training loss: 0.11256828904151917
Validation loss: 1.4392709885874102

Epoch: 6| Step: 11
Training loss: 0.06626265496015549
Validation loss: 1.409213577547381

Epoch: 6| Step: 12
Training loss: 0.10475136339664459
Validation loss: 1.4072422763352752

Epoch: 6| Step: 13
Training loss: 0.04936034232378006
Validation loss: 1.4214137728496263

Epoch: 518| Step: 0
Training loss: 0.04996425658464432
Validation loss: 1.4233591056639148

Epoch: 6| Step: 1
Training loss: 0.03983739763498306
Validation loss: 1.3943996685807423

Epoch: 6| Step: 2
Training loss: 0.05738017335534096
Validation loss: 1.434893496574894

Epoch: 6| Step: 3
Training loss: 0.06492426991462708
Validation loss: 1.42827275876076

Epoch: 6| Step: 4
Training loss: 0.07713237404823303
Validation loss: 1.397909431047337

Epoch: 6| Step: 5
Training loss: 0.06284186244010925
Validation loss: 1.4250421511229647

Epoch: 6| Step: 6
Training loss: 0.08137661218643188
Validation loss: 1.3913733625924716

Epoch: 6| Step: 7
Training loss: 0.06628899276256561
Validation loss: 1.4292142968023978

Epoch: 6| Step: 8
Training loss: 0.054292961955070496
Validation loss: 1.42328740063534

Epoch: 6| Step: 9
Training loss: 0.12000048905611038
Validation loss: 1.4049863764034805

Epoch: 6| Step: 10
Training loss: 0.06952784955501556
Validation loss: 1.4368017283819055

Epoch: 6| Step: 11
Training loss: 0.08444096148014069
Validation loss: 1.398721843637446

Epoch: 6| Step: 12
Training loss: 0.0813078060746193
Validation loss: 1.431388399934256

Epoch: 6| Step: 13
Training loss: 0.11991409212350845
Validation loss: 1.4138604094905238

Epoch: 519| Step: 0
Training loss: 0.11679887026548386
Validation loss: 1.3937479372947448

Epoch: 6| Step: 1
Training loss: 0.08387574553489685
Validation loss: 1.4515364913530246

Epoch: 6| Step: 2
Training loss: 0.07261932641267776
Validation loss: 1.4313663026337982

Epoch: 6| Step: 3
Training loss: 0.05423076078295708
Validation loss: 1.41372121918586

Epoch: 6| Step: 4
Training loss: 0.050413861870765686
Validation loss: 1.4277551725346556

Epoch: 6| Step: 5
Training loss: 0.06682774424552917
Validation loss: 1.4125205938534071

Epoch: 6| Step: 6
Training loss: 0.043808531016111374
Validation loss: 1.4410872164592947

Epoch: 6| Step: 7
Training loss: 0.11113980412483215
Validation loss: 1.430491506412465

Epoch: 6| Step: 8
Training loss: 0.08978509902954102
Validation loss: 1.4317449568420328

Epoch: 6| Step: 9
Training loss: 0.08857327699661255
Validation loss: 1.444507400194804

Epoch: 6| Step: 10
Training loss: 0.06559009104967117
Validation loss: 1.4260114540335953

Epoch: 6| Step: 11
Training loss: 0.07362529635429382
Validation loss: 1.465073784192403

Epoch: 6| Step: 12
Training loss: 0.09730137884616852
Validation loss: 1.447043175338417

Epoch: 6| Step: 13
Training loss: 0.05511963367462158
Validation loss: 1.4596955955669444

Epoch: 520| Step: 0
Training loss: 0.11230359226465225
Validation loss: 1.447927426266414

Epoch: 6| Step: 1
Training loss: 0.09339900314807892
Validation loss: 1.455487749909842

Epoch: 6| Step: 2
Training loss: 0.06945650279521942
Validation loss: 1.4526073471192391

Epoch: 6| Step: 3
Training loss: 0.08149059116840363
Validation loss: 1.4541480246410574

Epoch: 6| Step: 4
Training loss: 0.11236990243196487
Validation loss: 1.4444538982965613

Epoch: 6| Step: 5
Training loss: 0.05349378287792206
Validation loss: 1.4250868840884137

Epoch: 6| Step: 6
Training loss: 0.06707023084163666
Validation loss: 1.429839539271529

Epoch: 6| Step: 7
Training loss: 0.11550906300544739
Validation loss: 1.4499656872082782

Epoch: 6| Step: 8
Training loss: 0.04692816734313965
Validation loss: 1.418061516618216

Epoch: 6| Step: 9
Training loss: 0.06093089282512665
Validation loss: 1.4281713411372194

Epoch: 6| Step: 10
Training loss: 0.07290557026863098
Validation loss: 1.4220262522338538

Epoch: 6| Step: 11
Training loss: 0.11845571547746658
Validation loss: 1.4148501529488513

Epoch: 6| Step: 12
Training loss: 0.056399159133434296
Validation loss: 1.4088674899070495

Epoch: 6| Step: 13
Training loss: 0.055940210819244385
Validation loss: 1.416800578435262

Epoch: 521| Step: 0
Training loss: 0.08761047571897507
Validation loss: 1.4134011883889475

Epoch: 6| Step: 1
Training loss: 0.06290052086114883
Validation loss: 1.3945304386077388

Epoch: 6| Step: 2
Training loss: 0.10129503905773163
Validation loss: 1.4200863248558455

Epoch: 6| Step: 3
Training loss: 0.0807473361492157
Validation loss: 1.4135474056325934

Epoch: 6| Step: 4
Training loss: 0.09963153302669525
Validation loss: 1.4034881745615313

Epoch: 6| Step: 5
Training loss: 0.10439105331897736
Validation loss: 1.418956099017974

Epoch: 6| Step: 6
Training loss: 0.044080063700675964
Validation loss: 1.4510454708530056

Epoch: 6| Step: 7
Training loss: 0.0985327661037445
Validation loss: 1.431666128097042

Epoch: 6| Step: 8
Training loss: 0.05955562740564346
Validation loss: 1.442210583276646

Epoch: 6| Step: 9
Training loss: 0.08902129530906677
Validation loss: 1.4677522208101006

Epoch: 6| Step: 10
Training loss: 0.06669511646032333
Validation loss: 1.4695885348063644

Epoch: 6| Step: 11
Training loss: 0.053779274225234985
Validation loss: 1.4624992814115299

Epoch: 6| Step: 12
Training loss: 0.08940647542476654
Validation loss: 1.455557224571064

Epoch: 6| Step: 13
Training loss: 0.057718291878700256
Validation loss: 1.48515038464659

Epoch: 522| Step: 0
Training loss: 0.047257453203201294
Validation loss: 1.4446220756858907

Epoch: 6| Step: 1
Training loss: 0.07836787402629852
Validation loss: 1.4894324195000432

Epoch: 6| Step: 2
Training loss: 0.099049873650074
Validation loss: 1.4631589510107552

Epoch: 6| Step: 3
Training loss: 0.05043444037437439
Validation loss: 1.4615201514254335

Epoch: 6| Step: 4
Training loss: 0.1242404356598854
Validation loss: 1.4602269613614647

Epoch: 6| Step: 5
Training loss: 0.05648529902100563
Validation loss: 1.4262439435528171

Epoch: 6| Step: 6
Training loss: 0.03659052401781082
Validation loss: 1.4495495006602297

Epoch: 6| Step: 7
Training loss: 0.064869724214077
Validation loss: 1.4364929865765315

Epoch: 6| Step: 8
Training loss: 0.07364945113658905
Validation loss: 1.439919416622449

Epoch: 6| Step: 9
Training loss: 0.08016637712717056
Validation loss: 1.4492295788180443

Epoch: 6| Step: 10
Training loss: 0.08136023581027985
Validation loss: 1.4195182797729329

Epoch: 6| Step: 11
Training loss: 0.0766618400812149
Validation loss: 1.4148808294726956

Epoch: 6| Step: 12
Training loss: 0.10935242474079132
Validation loss: 1.3979608743421492

Epoch: 6| Step: 13
Training loss: 0.12951120734214783
Validation loss: 1.4171268734880673

Epoch: 523| Step: 0
Training loss: 0.07329767197370529
Validation loss: 1.4055877436873734

Epoch: 6| Step: 1
Training loss: 0.04973559081554413
Validation loss: 1.3954263092369161

Epoch: 6| Step: 2
Training loss: 0.060498617589473724
Validation loss: 1.4301369626034972

Epoch: 6| Step: 3
Training loss: 0.16255158185958862
Validation loss: 1.4415651367556663

Epoch: 6| Step: 4
Training loss: 0.1096067801117897
Validation loss: 1.435337813951636

Epoch: 6| Step: 5
Training loss: 0.09671847522258759
Validation loss: 1.4186518294836885

Epoch: 6| Step: 6
Training loss: 0.12145419418811798
Validation loss: 1.4227740867163545

Epoch: 6| Step: 7
Training loss: 0.08970160782337189
Validation loss: 1.3796501633941487

Epoch: 6| Step: 8
Training loss: 0.07868818938732147
Validation loss: 1.4063161816648257

Epoch: 6| Step: 9
Training loss: 0.0631878525018692
Validation loss: 1.4296229603470012

Epoch: 6| Step: 10
Training loss: 0.1063060313463211
Validation loss: 1.445545796425112

Epoch: 6| Step: 11
Training loss: 0.1109451875090599
Validation loss: 1.464857978205527

Epoch: 6| Step: 12
Training loss: 0.13687512278556824
Validation loss: 1.4812608893199632

Epoch: 6| Step: 13
Training loss: 0.13277462124824524
Validation loss: 1.4655323643838205

Epoch: 524| Step: 0
Training loss: 0.11189712584018707
Validation loss: 1.4356283923631072

Epoch: 6| Step: 1
Training loss: 0.07913287729024887
Validation loss: 1.4418776778764621

Epoch: 6| Step: 2
Training loss: 0.0780223160982132
Validation loss: 1.4281491156547301

Epoch: 6| Step: 3
Training loss: 0.061356231570243835
Validation loss: 1.4437670938430294

Epoch: 6| Step: 4
Training loss: 0.10234834998846054
Validation loss: 1.4616008202234905

Epoch: 6| Step: 5
Training loss: 0.07358654588460922
Validation loss: 1.4354994732846496

Epoch: 6| Step: 6
Training loss: 0.11649714410305023
Validation loss: 1.4255322692214802

Epoch: 6| Step: 7
Training loss: 0.09817071259021759
Validation loss: 1.4713406562805176

Epoch: 6| Step: 8
Training loss: 0.12389754503965378
Validation loss: 1.4360883396158937

Epoch: 6| Step: 9
Training loss: 0.1443488746881485
Validation loss: 1.4653756938954836

Epoch: 6| Step: 10
Training loss: 0.08378835022449493
Validation loss: 1.469688618054954

Epoch: 6| Step: 11
Training loss: 0.062023766338825226
Validation loss: 1.4513365876290105

Epoch: 6| Step: 12
Training loss: 0.06867989897727966
Validation loss: 1.4436572264599543

Epoch: 6| Step: 13
Training loss: 0.1187731921672821
Validation loss: 1.469141960144043

Epoch: 525| Step: 0
Training loss: 0.05663594231009483
Validation loss: 1.47673677116312

Epoch: 6| Step: 1
Training loss: 0.058604080229997635
Validation loss: 1.4249984166955436

Epoch: 6| Step: 2
Training loss: 0.08220570534467697
Validation loss: 1.448630376528668

Epoch: 6| Step: 3
Training loss: 0.12380563467741013
Validation loss: 1.447750174871055

Epoch: 6| Step: 4
Training loss: 0.09379314631223679
Validation loss: 1.43897371907388

Epoch: 6| Step: 5
Training loss: 0.1426444947719574
Validation loss: 1.4592784156081497

Epoch: 6| Step: 6
Training loss: 0.0739489421248436
Validation loss: 1.4230166096841135

Epoch: 6| Step: 7
Training loss: 0.07383677363395691
Validation loss: 1.4403816089835217

Epoch: 6| Step: 8
Training loss: 0.06899899244308472
Validation loss: 1.4483987977427821

Epoch: 6| Step: 9
Training loss: 0.06536645442247391
Validation loss: 1.4346886655335784

Epoch: 6| Step: 10
Training loss: 0.0754852220416069
Validation loss: 1.4421603372020106

Epoch: 6| Step: 11
Training loss: 0.0952623039484024
Validation loss: 1.4447168662983885

Epoch: 6| Step: 12
Training loss: 0.12386564910411835
Validation loss: 1.4256500313358922

Epoch: 6| Step: 13
Training loss: 0.0890175923705101
Validation loss: 1.4206790283162107

Epoch: 526| Step: 0
Training loss: 0.08257381618022919
Validation loss: 1.4130079143790788

Epoch: 6| Step: 1
Training loss: 0.0773712620139122
Validation loss: 1.41962509001455

Epoch: 6| Step: 2
Training loss: 0.09387180209159851
Validation loss: 1.4526602183618853

Epoch: 6| Step: 3
Training loss: 0.05351672321557999
Validation loss: 1.4548812784174436

Epoch: 6| Step: 4
Training loss: 0.07732418924570084
Validation loss: 1.417516707092203

Epoch: 6| Step: 5
Training loss: 0.0517275407910347
Validation loss: 1.4277970149952879

Epoch: 6| Step: 6
Training loss: 0.06339430809020996
Validation loss: 1.4378486012899747

Epoch: 6| Step: 7
Training loss: 0.06692875176668167
Validation loss: 1.4164548945683304

Epoch: 6| Step: 8
Training loss: 0.07301211357116699
Validation loss: 1.425886154815715

Epoch: 6| Step: 9
Training loss: 0.09038946032524109
Validation loss: 1.4386587912036526

Epoch: 6| Step: 10
Training loss: 0.05189603194594383
Validation loss: 1.4109360607721473

Epoch: 6| Step: 11
Training loss: 0.06983054429292679
Validation loss: 1.3984453960131573

Epoch: 6| Step: 12
Training loss: 0.08656739443540573
Validation loss: 1.4073164680952668

Epoch: 6| Step: 13
Training loss: 0.06882432848215103
Validation loss: 1.3939742721537107

Epoch: 527| Step: 0
Training loss: 0.07144198566675186
Validation loss: 1.3765314362382377

Epoch: 6| Step: 1
Training loss: 0.110159732401371
Validation loss: 1.4008621913130566

Epoch: 6| Step: 2
Training loss: 0.049420371651649475
Validation loss: 1.3900828348693026

Epoch: 6| Step: 3
Training loss: 0.06807051599025726
Validation loss: 1.377505902321108

Epoch: 6| Step: 4
Training loss: 0.06931270658969879
Validation loss: 1.3879595206629844

Epoch: 6| Step: 5
Training loss: 0.06051339954137802
Validation loss: 1.367238066529715

Epoch: 6| Step: 6
Training loss: 0.04819005727767944
Validation loss: 1.3672443346310688

Epoch: 6| Step: 7
Training loss: 0.1045345664024353
Validation loss: 1.3836381755849367

Epoch: 6| Step: 8
Training loss: 0.07814398407936096
Validation loss: 1.3821699215519814

Epoch: 6| Step: 9
Training loss: 0.0894140899181366
Validation loss: 1.4012179002966931

Epoch: 6| Step: 10
Training loss: 0.08945882320404053
Validation loss: 1.4186086206025974

Epoch: 6| Step: 11
Training loss: 0.0872754454612732
Validation loss: 1.4272922283859664

Epoch: 6| Step: 12
Training loss: 0.03777388483285904
Validation loss: 1.4385950219246648

Epoch: 6| Step: 13
Training loss: 0.06035690754652023
Validation loss: 1.418643315633138

Epoch: 528| Step: 0
Training loss: 0.09279417991638184
Validation loss: 1.4566003173910163

Epoch: 6| Step: 1
Training loss: 0.10210923850536346
Validation loss: 1.4028680850100774

Epoch: 6| Step: 2
Training loss: 0.07179926335811615
Validation loss: 1.4658086825442571

Epoch: 6| Step: 3
Training loss: 0.07888118922710419
Validation loss: 1.4428945382436116

Epoch: 6| Step: 4
Training loss: 0.06821180880069733
Validation loss: 1.4435459272835844

Epoch: 6| Step: 5
Training loss: 0.06647177785634995
Validation loss: 1.458716445071723

Epoch: 6| Step: 6
Training loss: 0.11215214431285858
Validation loss: 1.4262979415155226

Epoch: 6| Step: 7
Training loss: 0.06400960683822632
Validation loss: 1.4418874748291508

Epoch: 6| Step: 8
Training loss: 0.06488004326820374
Validation loss: 1.43298307541878

Epoch: 6| Step: 9
Training loss: 0.06795301288366318
Validation loss: 1.4212221413530328

Epoch: 6| Step: 10
Training loss: 0.09879380464553833
Validation loss: 1.4220765764995287

Epoch: 6| Step: 11
Training loss: 0.0857052356004715
Validation loss: 1.4474496392793552

Epoch: 6| Step: 12
Training loss: 0.0715397447347641
Validation loss: 1.438240453761111

Epoch: 6| Step: 13
Training loss: 0.09115449339151382
Validation loss: 1.43116371990532

Epoch: 529| Step: 0
Training loss: 0.13632473349571228
Validation loss: 1.4424892804955924

Epoch: 6| Step: 1
Training loss: 0.08389746397733688
Validation loss: 1.4136090586262364

Epoch: 6| Step: 2
Training loss: 0.11049557477235794
Validation loss: 1.445819806027156

Epoch: 6| Step: 3
Training loss: 0.05417030304670334
Validation loss: 1.425545100242861

Epoch: 6| Step: 4
Training loss: 0.09657588601112366
Validation loss: 1.4394217960296138

Epoch: 6| Step: 5
Training loss: 0.03761902451515198
Validation loss: 1.435747032524437

Epoch: 6| Step: 6
Training loss: 0.0747816264629364
Validation loss: 1.393707098499421

Epoch: 6| Step: 7
Training loss: 0.04195967689156532
Validation loss: 1.377072850863139

Epoch: 6| Step: 8
Training loss: 0.03967021778225899
Validation loss: 1.4396060346275248

Epoch: 6| Step: 9
Training loss: 0.07747006416320801
Validation loss: 1.4334619634894914

Epoch: 6| Step: 10
Training loss: 0.07100559771060944
Validation loss: 1.3947988171731271

Epoch: 6| Step: 11
Training loss: 0.07225684076547623
Validation loss: 1.417123580491671

Epoch: 6| Step: 12
Training loss: 0.056279003620147705
Validation loss: 1.4312963934354885

Epoch: 6| Step: 13
Training loss: 0.05973257124423981
Validation loss: 1.4153930756353563

Epoch: 530| Step: 0
Training loss: 0.03726966679096222
Validation loss: 1.4193542324086672

Epoch: 6| Step: 1
Training loss: 0.11305266618728638
Validation loss: 1.4196951017584851

Epoch: 6| Step: 2
Training loss: 0.06095827370882034
Validation loss: 1.433834469446572

Epoch: 6| Step: 3
Training loss: 0.0558500662446022
Validation loss: 1.419725352717984

Epoch: 6| Step: 4
Training loss: 0.13007424771785736
Validation loss: 1.4579735545701877

Epoch: 6| Step: 5
Training loss: 0.1103878766298294
Validation loss: 1.4493014351014168

Epoch: 6| Step: 6
Training loss: 0.06203719973564148
Validation loss: 1.4430411105514855

Epoch: 6| Step: 7
Training loss: 0.06138546019792557
Validation loss: 1.4461390459409325

Epoch: 6| Step: 8
Training loss: 0.06454816460609436
Validation loss: 1.467146691455636

Epoch: 6| Step: 9
Training loss: 0.08686809241771698
Validation loss: 1.4453264115959086

Epoch: 6| Step: 10
Training loss: 0.08445996046066284
Validation loss: 1.4399148238602506

Epoch: 6| Step: 11
Training loss: 0.07097280770540237
Validation loss: 1.4470819734757947

Epoch: 6| Step: 12
Training loss: 0.07722456753253937
Validation loss: 1.434928544106022

Epoch: 6| Step: 13
Training loss: 0.055226881057024
Validation loss: 1.4804586877105057

Epoch: 531| Step: 0
Training loss: 0.08318842947483063
Validation loss: 1.4935702816132577

Epoch: 6| Step: 1
Training loss: 0.06653433293104172
Validation loss: 1.4349448565513856

Epoch: 6| Step: 2
Training loss: 0.06494521349668503
Validation loss: 1.434699740461124

Epoch: 6| Step: 3
Training loss: 0.05047141760587692
Validation loss: 1.4321955173246321

Epoch: 6| Step: 4
Training loss: 0.05510098859667778
Validation loss: 1.4314361528683734

Epoch: 6| Step: 5
Training loss: 0.12623798847198486
Validation loss: 1.446571151415507

Epoch: 6| Step: 6
Training loss: 0.07235249131917953
Validation loss: 1.4352220783951462

Epoch: 6| Step: 7
Training loss: 0.06889405101537704
Validation loss: 1.4287235672755907

Epoch: 6| Step: 8
Training loss: 0.05485828220844269
Validation loss: 1.4426181444557764

Epoch: 6| Step: 9
Training loss: 0.10622315108776093
Validation loss: 1.4289957067017913

Epoch: 6| Step: 10
Training loss: 0.056500524282455444
Validation loss: 1.4418051601738058

Epoch: 6| Step: 11
Training loss: 0.05987032502889633
Validation loss: 1.431499405573773

Epoch: 6| Step: 12
Training loss: 0.081231988966465
Validation loss: 1.4243895699900966

Epoch: 6| Step: 13
Training loss: 0.12024971842765808
Validation loss: 1.456742504591583

Epoch: 532| Step: 0
Training loss: 0.08291223645210266
Validation loss: 1.4129780530929565

Epoch: 6| Step: 1
Training loss: 0.09591154754161835
Validation loss: 1.4048927317383468

Epoch: 6| Step: 2
Training loss: 0.07451719790697098
Validation loss: 1.394377657162246

Epoch: 6| Step: 3
Training loss: 0.08519988507032394
Validation loss: 1.4376386288673646

Epoch: 6| Step: 4
Training loss: 0.12304921448230743
Validation loss: 1.4144886591101204

Epoch: 6| Step: 5
Training loss: 0.07620441913604736
Validation loss: 1.4272876183191936

Epoch: 6| Step: 6
Training loss: 0.04622377082705498
Validation loss: 1.4335273645257438

Epoch: 6| Step: 7
Training loss: 0.07311341911554337
Validation loss: 1.4363843100045317

Epoch: 6| Step: 8
Training loss: 0.04548899084329605
Validation loss: 1.4341202685909886

Epoch: 6| Step: 9
Training loss: 0.07453903555870056
Validation loss: 1.4534173486053303

Epoch: 6| Step: 10
Training loss: 0.10331331193447113
Validation loss: 1.4595280372968285

Epoch: 6| Step: 11
Training loss: 0.04917121306061745
Validation loss: 1.4612383047739665

Epoch: 6| Step: 12
Training loss: 0.08232153952121735
Validation loss: 1.4472863084526473

Epoch: 6| Step: 13
Training loss: 0.07574832439422607
Validation loss: 1.4753128418358423

Epoch: 533| Step: 0
Training loss: 0.05039668828248978
Validation loss: 1.449276376796025

Epoch: 6| Step: 1
Training loss: 0.10784060508012772
Validation loss: 1.4606980771146796

Epoch: 6| Step: 2
Training loss: 0.05333567410707474
Validation loss: 1.4534588116471485

Epoch: 6| Step: 3
Training loss: 0.11150148510932922
Validation loss: 1.4318779501863705

Epoch: 6| Step: 4
Training loss: 0.04246208816766739
Validation loss: 1.4527514698684856

Epoch: 6| Step: 5
Training loss: 0.07132871448993683
Validation loss: 1.4316295859634236

Epoch: 6| Step: 6
Training loss: 0.09151142835617065
Validation loss: 1.4610354361995574

Epoch: 6| Step: 7
Training loss: 0.04350176081061363
Validation loss: 1.4412235047227593

Epoch: 6| Step: 8
Training loss: 0.10749474912881851
Validation loss: 1.4456206778044343

Epoch: 6| Step: 9
Training loss: 0.049231305718421936
Validation loss: 1.4635433304694392

Epoch: 6| Step: 10
Training loss: 0.06972425431013107
Validation loss: 1.4498640798753308

Epoch: 6| Step: 11
Training loss: 0.04616524279117584
Validation loss: 1.4442718631477767

Epoch: 6| Step: 12
Training loss: 0.09349406510591507
Validation loss: 1.4314656539629864

Epoch: 6| Step: 13
Training loss: 0.07743137329816818
Validation loss: 1.4277062185349003

Epoch: 534| Step: 0
Training loss: 0.036150336265563965
Validation loss: 1.4705895518743863

Epoch: 6| Step: 1
Training loss: 0.07425173372030258
Validation loss: 1.4609086513519287

Epoch: 6| Step: 2
Training loss: 0.05719538405537605
Validation loss: 1.4593446626458118

Epoch: 6| Step: 3
Training loss: 0.08135870099067688
Validation loss: 1.4889589407110726

Epoch: 6| Step: 4
Training loss: 0.08952935039997101
Validation loss: 1.4716165322129444

Epoch: 6| Step: 5
Training loss: 0.048905253410339355
Validation loss: 1.471159472260424

Epoch: 6| Step: 6
Training loss: 0.0685959979891777
Validation loss: 1.4554573720501316

Epoch: 6| Step: 7
Training loss: 0.09203192591667175
Validation loss: 1.4809091488520305

Epoch: 6| Step: 8
Training loss: 0.056596484035253525
Validation loss: 1.4493536013428883

Epoch: 6| Step: 9
Training loss: 0.06463870406150818
Validation loss: 1.4450177877180037

Epoch: 6| Step: 10
Training loss: 0.07946749776601791
Validation loss: 1.4512084145699777

Epoch: 6| Step: 11
Training loss: 0.10206311196088791
Validation loss: 1.4426057088759638

Epoch: 6| Step: 12
Training loss: 0.08094735443592072
Validation loss: 1.4540332709589312

Epoch: 6| Step: 13
Training loss: 0.07780782133340836
Validation loss: 1.484232202652962

Epoch: 535| Step: 0
Training loss: 0.06591202318668365
Validation loss: 1.4462449653174287

Epoch: 6| Step: 1
Training loss: 0.1225721687078476
Validation loss: 1.4362745028670116

Epoch: 6| Step: 2
Training loss: 0.03996845334768295
Validation loss: 1.4293068128247415

Epoch: 6| Step: 3
Training loss: 0.06241650506854057
Validation loss: 1.4641754037590438

Epoch: 6| Step: 4
Training loss: 0.07568905502557755
Validation loss: 1.4113394278351978

Epoch: 6| Step: 5
Training loss: 0.05376496538519859
Validation loss: 1.40306774070186

Epoch: 6| Step: 6
Training loss: 0.04232337325811386
Validation loss: 1.4082210948390346

Epoch: 6| Step: 7
Training loss: 0.07115830481052399
Validation loss: 1.4000072633066485

Epoch: 6| Step: 8
Training loss: 0.05062267184257507
Validation loss: 1.453810256014588

Epoch: 6| Step: 9
Training loss: 0.06585057079792023
Validation loss: 1.4475834574750674

Epoch: 6| Step: 10
Training loss: 0.10883888602256775
Validation loss: 1.4050449440556187

Epoch: 6| Step: 11
Training loss: 0.08890379965305328
Validation loss: 1.427767188318314

Epoch: 6| Step: 12
Training loss: 0.0828191488981247
Validation loss: 1.4126962871961697

Epoch: 6| Step: 13
Training loss: 0.0666188895702362
Validation loss: 1.4740308266814037

Epoch: 536| Step: 0
Training loss: 0.06494086980819702
Validation loss: 1.4177814875879595

Epoch: 6| Step: 1
Training loss: 0.06715370714664459
Validation loss: 1.4435847113209386

Epoch: 6| Step: 2
Training loss: 0.04357963800430298
Validation loss: 1.4564141227353005

Epoch: 6| Step: 3
Training loss: 0.05210895836353302
Validation loss: 1.4189101649868874

Epoch: 6| Step: 4
Training loss: 0.05669477581977844
Validation loss: 1.444666023536395

Epoch: 6| Step: 5
Training loss: 0.09269885718822479
Validation loss: 1.4084981667098178

Epoch: 6| Step: 6
Training loss: 0.06817449629306793
Validation loss: 1.403266397855615

Epoch: 6| Step: 7
Training loss: 0.05233223736286163
Validation loss: 1.386412093716283

Epoch: 6| Step: 8
Training loss: 0.04797331988811493
Validation loss: 1.4209716166219404

Epoch: 6| Step: 9
Training loss: 0.09624309837818146
Validation loss: 1.3868672335019676

Epoch: 6| Step: 10
Training loss: 0.07839388400316238
Validation loss: 1.4140917447305494

Epoch: 6| Step: 11
Training loss: 0.1075582206249237
Validation loss: 1.4082640729924685

Epoch: 6| Step: 12
Training loss: 0.09103202074766159
Validation loss: 1.4259834007550312

Epoch: 6| Step: 13
Training loss: 0.03863196820020676
Validation loss: 1.4365876746434036

Epoch: 537| Step: 0
Training loss: 0.0623663030564785
Validation loss: 1.4236308208075903

Epoch: 6| Step: 1
Training loss: 0.07770755887031555
Validation loss: 1.4338483925788634

Epoch: 6| Step: 2
Training loss: 0.026490911841392517
Validation loss: 1.4174412104391283

Epoch: 6| Step: 3
Training loss: 0.0778045803308487
Validation loss: 1.415789904132966

Epoch: 6| Step: 4
Training loss: 0.1078263372182846
Validation loss: 1.4295312217486802

Epoch: 6| Step: 5
Training loss: 0.062346022576093674
Validation loss: 1.4315222924755466

Epoch: 6| Step: 6
Training loss: 0.0661076083779335
Validation loss: 1.4152063483832984

Epoch: 6| Step: 7
Training loss: 0.09147491306066513
Validation loss: 1.4542369073437107

Epoch: 6| Step: 8
Training loss: 0.048903122544288635
Validation loss: 1.3929479147798272

Epoch: 6| Step: 9
Training loss: 0.07258766889572144
Validation loss: 1.4180357699753137

Epoch: 6| Step: 10
Training loss: 0.09644696861505508
Validation loss: 1.424544390811715

Epoch: 6| Step: 11
Training loss: 0.05029546841979027
Validation loss: 1.3968080474484352

Epoch: 6| Step: 12
Training loss: 0.05225139483809471
Validation loss: 1.4321768258207588

Epoch: 6| Step: 13
Training loss: 0.15795455873012543
Validation loss: 1.4259384101436985

Epoch: 538| Step: 0
Training loss: 0.08266446739435196
Validation loss: 1.4379872134936753

Epoch: 6| Step: 1
Training loss: 0.04797976836562157
Validation loss: 1.4550737962927869

Epoch: 6| Step: 2
Training loss: 0.07683716714382172
Validation loss: 1.462230686218508

Epoch: 6| Step: 3
Training loss: 0.06503292918205261
Validation loss: 1.5034026458699217

Epoch: 6| Step: 4
Training loss: 0.08679379522800446
Validation loss: 1.4693810125832916

Epoch: 6| Step: 5
Training loss: 0.05419754236936569
Validation loss: 1.481867951731528

Epoch: 6| Step: 6
Training loss: 0.08651348948478699
Validation loss: 1.4873072870316044

Epoch: 6| Step: 7
Training loss: 0.060737188905477524
Validation loss: 1.4706494551832958

Epoch: 6| Step: 8
Training loss: 0.08341275155544281
Validation loss: 1.4748766332544305

Epoch: 6| Step: 9
Training loss: 0.07131917774677277
Validation loss: 1.4591725103316768

Epoch: 6| Step: 10
Training loss: 0.04870869964361191
Validation loss: 1.4403341316407727

Epoch: 6| Step: 11
Training loss: 0.10131680965423584
Validation loss: 1.4592316086574266

Epoch: 6| Step: 12
Training loss: 0.07663176208734512
Validation loss: 1.4705670187550206

Epoch: 6| Step: 13
Training loss: 0.08256104588508606
Validation loss: 1.4815173508018575

Epoch: 539| Step: 0
Training loss: 0.09552595764398575
Validation loss: 1.489728566138975

Epoch: 6| Step: 1
Training loss: 0.08647507429122925
Validation loss: 1.4708708024794055

Epoch: 6| Step: 2
Training loss: 0.101610466837883
Validation loss: 1.4225935628337245

Epoch: 6| Step: 3
Training loss: 0.06622211635112762
Validation loss: 1.4380939275987688

Epoch: 6| Step: 4
Training loss: 0.02720135822892189
Validation loss: 1.4381560061567573

Epoch: 6| Step: 5
Training loss: 0.10458134859800339
Validation loss: 1.4676374555915914

Epoch: 6| Step: 6
Training loss: 0.07406723499298096
Validation loss: 1.43190477484016

Epoch: 6| Step: 7
Training loss: 0.059652283787727356
Validation loss: 1.4293749313200674

Epoch: 6| Step: 8
Training loss: 0.08640629053115845
Validation loss: 1.4252956490362845

Epoch: 6| Step: 9
Training loss: 0.12448882311582565
Validation loss: 1.4376159560295843

Epoch: 6| Step: 10
Training loss: 0.06669723987579346
Validation loss: 1.4145885244492562

Epoch: 6| Step: 11
Training loss: 0.11200041323900223
Validation loss: 1.3998370138547753

Epoch: 6| Step: 12
Training loss: 0.07660859823226929
Validation loss: 1.4116107686873405

Epoch: 6| Step: 13
Training loss: 0.07045041024684906
Validation loss: 1.3769917526552755

Epoch: 540| Step: 0
Training loss: 0.047400712966918945
Validation loss: 1.3802444601571688

Epoch: 6| Step: 1
Training loss: 0.09464804828166962
Validation loss: 1.3845600915211502

Epoch: 6| Step: 2
Training loss: 0.056954652070999146
Validation loss: 1.4125899255916636

Epoch: 6| Step: 3
Training loss: 0.05093417316675186
Validation loss: 1.3917536645807245

Epoch: 6| Step: 4
Training loss: 0.07507194578647614
Validation loss: 1.3833275764219222

Epoch: 6| Step: 5
Training loss: 0.03402811288833618
Validation loss: 1.40421224024988

Epoch: 6| Step: 6
Training loss: 0.11487701535224915
Validation loss: 1.4117598187538885

Epoch: 6| Step: 7
Training loss: 0.05676344782114029
Validation loss: 1.4136647998645742

Epoch: 6| Step: 8
Training loss: 0.051289625465869904
Validation loss: 1.4050731152616522

Epoch: 6| Step: 9
Training loss: 0.08010353147983551
Validation loss: 1.44194499651591

Epoch: 6| Step: 10
Training loss: 0.04709990322589874
Validation loss: 1.380299734812911

Epoch: 6| Step: 11
Training loss: 0.057627227157354355
Validation loss: 1.4179818796855148

Epoch: 6| Step: 12
Training loss: 0.10666026175022125
Validation loss: 1.4097210194474907

Epoch: 6| Step: 13
Training loss: 0.12215415388345718
Validation loss: 1.418407444031008

Epoch: 541| Step: 0
Training loss: 0.053622759878635406
Validation loss: 1.419491252591533

Epoch: 6| Step: 1
Training loss: 0.07380632311105728
Validation loss: 1.4392779411808136

Epoch: 6| Step: 2
Training loss: 0.06227671355009079
Validation loss: 1.465768519268241

Epoch: 6| Step: 3
Training loss: 0.09610280394554138
Validation loss: 1.4551600961274997

Epoch: 6| Step: 4
Training loss: 0.0652901828289032
Validation loss: 1.4671864201945644

Epoch: 6| Step: 5
Training loss: 0.1248539537191391
Validation loss: 1.474711279715261

Epoch: 6| Step: 6
Training loss: 0.035312533378601074
Validation loss: 1.4761069372136106

Epoch: 6| Step: 7
Training loss: 0.06390268355607986
Validation loss: 1.447451421009597

Epoch: 6| Step: 8
Training loss: 0.07910417020320892
Validation loss: 1.429951520376308

Epoch: 6| Step: 9
Training loss: 0.06859537959098816
Validation loss: 1.4279521472992436

Epoch: 6| Step: 10
Training loss: 0.09963610023260117
Validation loss: 1.4304944097354848

Epoch: 6| Step: 11
Training loss: 0.05737118422985077
Validation loss: 1.41435270924722

Epoch: 6| Step: 12
Training loss: 0.06392329186201096
Validation loss: 1.3868899422307168

Epoch: 6| Step: 13
Training loss: 0.038743261247873306
Validation loss: 1.4211837284026607

Epoch: 542| Step: 0
Training loss: 0.06347224116325378
Validation loss: 1.421842372545632

Epoch: 6| Step: 1
Training loss: 0.08334536850452423
Validation loss: 1.436294671027891

Epoch: 6| Step: 2
Training loss: 0.0861760675907135
Validation loss: 1.454805644609595

Epoch: 6| Step: 3
Training loss: 0.050278253853321075
Validation loss: 1.4189888367088892

Epoch: 6| Step: 4
Training loss: 0.06234285235404968
Validation loss: 1.4341776178729149

Epoch: 6| Step: 5
Training loss: 0.09105677902698517
Validation loss: 1.449249041977749

Epoch: 6| Step: 6
Training loss: 0.05155456066131592
Validation loss: 1.4417613065370949

Epoch: 6| Step: 7
Training loss: 0.05530416592955589
Validation loss: 1.4256413034213486

Epoch: 6| Step: 8
Training loss: 0.05055740475654602
Validation loss: 1.4349453923522786

Epoch: 6| Step: 9
Training loss: 0.06610027700662613
Validation loss: 1.4653611920213188

Epoch: 6| Step: 10
Training loss: 0.07411369681358337
Validation loss: 1.4754186368757678

Epoch: 6| Step: 11
Training loss: 0.07953585684299469
Validation loss: 1.4639473743336175

Epoch: 6| Step: 12
Training loss: 0.12805220484733582
Validation loss: 1.4472819938454577

Epoch: 6| Step: 13
Training loss: 0.1072365939617157
Validation loss: 1.4629833570090673

Epoch: 543| Step: 0
Training loss: 0.06569229066371918
Validation loss: 1.4366058841828377

Epoch: 6| Step: 1
Training loss: 0.05551569163799286
Validation loss: 1.4401322359679847

Epoch: 6| Step: 2
Training loss: 0.05859311297535896
Validation loss: 1.4414054687305162

Epoch: 6| Step: 3
Training loss: 0.0652124360203743
Validation loss: 1.4549359839449647

Epoch: 6| Step: 4
Training loss: 0.0923478901386261
Validation loss: 1.4328992366790771

Epoch: 6| Step: 5
Training loss: 0.07033973932266235
Validation loss: 1.4450363010488532

Epoch: 6| Step: 6
Training loss: 0.05773433297872543
Validation loss: 1.4273750032148054

Epoch: 6| Step: 7
Training loss: 0.08270931988954544
Validation loss: 1.4248570690872848

Epoch: 6| Step: 8
Training loss: 0.045819103717803955
Validation loss: 1.4161207791297667

Epoch: 6| Step: 9
Training loss: 0.04568539559841156
Validation loss: 1.4348203238620554

Epoch: 6| Step: 10
Training loss: 0.097234345972538
Validation loss: 1.424256404240926

Epoch: 6| Step: 11
Training loss: 0.055818285793066025
Validation loss: 1.4120380993812316

Epoch: 6| Step: 12
Training loss: 0.1410548985004425
Validation loss: 1.453823237008946

Epoch: 6| Step: 13
Training loss: 0.1270102709531784
Validation loss: 1.4268556025720411

Epoch: 544| Step: 0
Training loss: 0.06899651885032654
Validation loss: 1.4494643839456702

Epoch: 6| Step: 1
Training loss: 0.08676357567310333
Validation loss: 1.4401421944300334

Epoch: 6| Step: 2
Training loss: 0.09635408222675323
Validation loss: 1.4249421986200477

Epoch: 6| Step: 3
Training loss: 0.13842588663101196
Validation loss: 1.453797148760929

Epoch: 6| Step: 4
Training loss: 0.08470930904150009
Validation loss: 1.4470064370862898

Epoch: 6| Step: 5
Training loss: 0.07948192954063416
Validation loss: 1.4382292942334247

Epoch: 6| Step: 6
Training loss: 0.09159962832927704
Validation loss: 1.4475587382111499

Epoch: 6| Step: 7
Training loss: 0.08219768851995468
Validation loss: 1.4213720137073147

Epoch: 6| Step: 8
Training loss: 0.04180750623345375
Validation loss: 1.437402113791435

Epoch: 6| Step: 9
Training loss: 0.08761069178581238
Validation loss: 1.4486911950572845

Epoch: 6| Step: 10
Training loss: 0.0883493646979332
Validation loss: 1.4290685756232149

Epoch: 6| Step: 11
Training loss: 0.09298528730869293
Validation loss: 1.4558922795839206

Epoch: 6| Step: 12
Training loss: 0.06359149515628815
Validation loss: 1.4798457872483037

Epoch: 6| Step: 13
Training loss: 0.03318987041711807
Validation loss: 1.4699155912604382

Epoch: 545| Step: 0
Training loss: 0.09393493831157684
Validation loss: 1.4583402000447756

Epoch: 6| Step: 1
Training loss: 0.09665781259536743
Validation loss: 1.471303056645137

Epoch: 6| Step: 2
Training loss: 0.06480704247951508
Validation loss: 1.4767787546239874

Epoch: 6| Step: 3
Training loss: 0.036271288990974426
Validation loss: 1.4513688510464084

Epoch: 6| Step: 4
Training loss: 0.06895463913679123
Validation loss: 1.4656799454842844

Epoch: 6| Step: 5
Training loss: 0.09847895801067352
Validation loss: 1.460494879753359

Epoch: 6| Step: 6
Training loss: 0.058868132531642914
Validation loss: 1.468947301628769

Epoch: 6| Step: 7
Training loss: 0.05853838473558426
Validation loss: 1.4426091499226068

Epoch: 6| Step: 8
Training loss: 0.0711723193526268
Validation loss: 1.4439888628580237

Epoch: 6| Step: 9
Training loss: 0.04329362511634827
Validation loss: 1.4320787902801269

Epoch: 6| Step: 10
Training loss: 0.0821145623922348
Validation loss: 1.424917617151814

Epoch: 6| Step: 11
Training loss: 0.04059888795018196
Validation loss: 1.4302519752133278

Epoch: 6| Step: 12
Training loss: 0.058908380568027496
Validation loss: 1.4122149931487216

Epoch: 6| Step: 13
Training loss: 0.0560297966003418
Validation loss: 1.4091721004055393

Epoch: 546| Step: 0
Training loss: 0.029430106282234192
Validation loss: 1.4250731058018182

Epoch: 6| Step: 1
Training loss: 0.05677799880504608
Validation loss: 1.3979218377861926

Epoch: 6| Step: 2
Training loss: 0.11359243839979172
Validation loss: 1.404392288577172

Epoch: 6| Step: 3
Training loss: 0.06922299414873123
Validation loss: 1.3908067916029243

Epoch: 6| Step: 4
Training loss: 0.06131501495838165
Validation loss: 1.3865475577692832

Epoch: 6| Step: 5
Training loss: 0.10605525970458984
Validation loss: 1.4167627737086306

Epoch: 6| Step: 6
Training loss: 0.07903746515512466
Validation loss: 1.395289300590433

Epoch: 6| Step: 7
Training loss: 0.08005216717720032
Validation loss: 1.4018556642275986

Epoch: 6| Step: 8
Training loss: 0.07307077944278717
Validation loss: 1.4017598667452413

Epoch: 6| Step: 9
Training loss: 0.09022758901119232
Validation loss: 1.4136449137041647

Epoch: 6| Step: 10
Training loss: 0.04387542977929115
Validation loss: 1.4376825542860134

Epoch: 6| Step: 11
Training loss: 0.06585127115249634
Validation loss: 1.4331514284174929

Epoch: 6| Step: 12
Training loss: 0.0915641039609909
Validation loss: 1.4413567666084535

Epoch: 6| Step: 13
Training loss: 0.06342276185750961
Validation loss: 1.445086427914199

Epoch: 547| Step: 0
Training loss: 0.0945868194103241
Validation loss: 1.4362379709879558

Epoch: 6| Step: 1
Training loss: 0.0913924127817154
Validation loss: 1.467789388472034

Epoch: 6| Step: 2
Training loss: 0.0763733983039856
Validation loss: 1.4631665932234896

Epoch: 6| Step: 3
Training loss: 0.04063583165407181
Validation loss: 1.4725353140984812

Epoch: 6| Step: 4
Training loss: 0.048161573708057404
Validation loss: 1.4836628155041767

Epoch: 6| Step: 5
Training loss: 0.05927456170320511
Validation loss: 1.4659516375551942

Epoch: 6| Step: 6
Training loss: 0.12214592099189758
Validation loss: 1.4868645206574471

Epoch: 6| Step: 7
Training loss: 0.08120085299015045
Validation loss: 1.4870887783265883

Epoch: 6| Step: 8
Training loss: 0.11210080236196518
Validation loss: 1.4700543521552958

Epoch: 6| Step: 9
Training loss: 0.056371480226516724
Validation loss: 1.4604901139454176

Epoch: 6| Step: 10
Training loss: 0.03890576586127281
Validation loss: 1.4418340267673615

Epoch: 6| Step: 11
Training loss: 0.060312047600746155
Validation loss: 1.4415507790862874

Epoch: 6| Step: 12
Training loss: 0.0458095446228981
Validation loss: 1.4624598103184854

Epoch: 6| Step: 13
Training loss: 0.15896159410476685
Validation loss: 1.4595246077865682

Epoch: 548| Step: 0
Training loss: 0.0707336962223053
Validation loss: 1.4454989561470606

Epoch: 6| Step: 1
Training loss: 0.07170999050140381
Validation loss: 1.4978778618638233

Epoch: 6| Step: 2
Training loss: 0.061126478016376495
Validation loss: 1.4933566470299997

Epoch: 6| Step: 3
Training loss: 0.10706702619791031
Validation loss: 1.4815609878109348

Epoch: 6| Step: 4
Training loss: 0.06966304033994675
Validation loss: 1.4481346472617118

Epoch: 6| Step: 5
Training loss: 0.08205977082252502
Validation loss: 1.4438203073317004

Epoch: 6| Step: 6
Training loss: 0.07559502869844437
Validation loss: 1.4390238933665778

Epoch: 6| Step: 7
Training loss: 0.05756513029336929
Validation loss: 1.4409301748839758

Epoch: 6| Step: 8
Training loss: 0.08724156022071838
Validation loss: 1.4513678960902716

Epoch: 6| Step: 9
Training loss: 0.11687757074832916
Validation loss: 1.4395479399670836

Epoch: 6| Step: 10
Training loss: 0.08013303577899933
Validation loss: 1.4508200435228245

Epoch: 6| Step: 11
Training loss: 0.0819346159696579
Validation loss: 1.4578402971708646

Epoch: 6| Step: 12
Training loss: 0.11086836457252502
Validation loss: 1.462078748210784

Epoch: 6| Step: 13
Training loss: 0.10169966518878937
Validation loss: 1.4787789455024145

Epoch: 549| Step: 0
Training loss: 0.0592770017683506
Validation loss: 1.4876504726307367

Epoch: 6| Step: 1
Training loss: 0.06481124460697174
Validation loss: 1.4769725389378046

Epoch: 6| Step: 2
Training loss: 0.043322909623384476
Validation loss: 1.5103693995424496

Epoch: 6| Step: 3
Training loss: 0.12261853367090225
Validation loss: 1.5055537749362249

Epoch: 6| Step: 4
Training loss: 0.14908945560455322
Validation loss: 1.4866723655372538

Epoch: 6| Step: 5
Training loss: 0.05510925129055977
Validation loss: 1.506454466491617

Epoch: 6| Step: 6
Training loss: 0.07721474766731262
Validation loss: 1.523785404620632

Epoch: 6| Step: 7
Training loss: 0.10308295488357544
Validation loss: 1.4895847914039448

Epoch: 6| Step: 8
Training loss: 0.09119870513677597
Validation loss: 1.4865132967631023

Epoch: 6| Step: 9
Training loss: 0.046764157712459564
Validation loss: 1.4585764664475636

Epoch: 6| Step: 10
Training loss: 0.09164063632488251
Validation loss: 1.4493846957401564

Epoch: 6| Step: 11
Training loss: 0.0808224231004715
Validation loss: 1.4196887343160567

Epoch: 6| Step: 12
Training loss: 0.08296527713537216
Validation loss: 1.4501598714500346

Epoch: 6| Step: 13
Training loss: 0.12321588397026062
Validation loss: 1.424806639712344

Epoch: 550| Step: 0
Training loss: 0.1037813127040863
Validation loss: 1.3968033354769471

Epoch: 6| Step: 1
Training loss: 0.15487128496170044
Validation loss: 1.4284794574142785

Epoch: 6| Step: 2
Training loss: 0.1229725331068039
Validation loss: 1.3943711724332584

Epoch: 6| Step: 3
Training loss: 0.10022645443677902
Validation loss: 1.4195816952695128

Epoch: 6| Step: 4
Training loss: 0.08120371401309967
Validation loss: 1.4361274729492843

Epoch: 6| Step: 5
Training loss: 0.12630397081375122
Validation loss: 1.4177375173055997

Epoch: 6| Step: 6
Training loss: 0.06092764437198639
Validation loss: 1.4632891358867768

Epoch: 6| Step: 7
Training loss: 0.10211227834224701
Validation loss: 1.4530318026901574

Epoch: 6| Step: 8
Training loss: 0.0869523212313652
Validation loss: 1.4232988383180352

Epoch: 6| Step: 9
Training loss: 0.10498617589473724
Validation loss: 1.44191990616501

Epoch: 6| Step: 10
Training loss: 0.10457895696163177
Validation loss: 1.4139014033861057

Epoch: 6| Step: 11
Training loss: 0.0978604406118393
Validation loss: 1.4184617316851051

Epoch: 6| Step: 12
Training loss: 0.08233973383903503
Validation loss: 1.417297786281955

Epoch: 6| Step: 13
Training loss: 0.07312056422233582
Validation loss: 1.4320408298123268

Epoch: 551| Step: 0
Training loss: 0.07580185681581497
Validation loss: 1.412351567258117

Epoch: 6| Step: 1
Training loss: 0.10954752564430237
Validation loss: 1.4131122981348345

Epoch: 6| Step: 2
Training loss: 0.1259208470582962
Validation loss: 1.4480323432594218

Epoch: 6| Step: 3
Training loss: 0.0928640067577362
Validation loss: 1.436059223708286

Epoch: 6| Step: 4
Training loss: 0.07345686107873917
Validation loss: 1.420952793090574

Epoch: 6| Step: 5
Training loss: 0.07862243801355362
Validation loss: 1.4420034193223523

Epoch: 6| Step: 6
Training loss: 0.05242706835269928
Validation loss: 1.4217605949730001

Epoch: 6| Step: 7
Training loss: 0.07601607590913773
Validation loss: 1.4414331746357743

Epoch: 6| Step: 8
Training loss: 0.09185969829559326
Validation loss: 1.45004258360914

Epoch: 6| Step: 9
Training loss: 0.11580105125904083
Validation loss: 1.4731219968488138

Epoch: 6| Step: 10
Training loss: 0.0798243060708046
Validation loss: 1.463261886309552

Epoch: 6| Step: 11
Training loss: 0.08293922245502472
Validation loss: 1.4668491501961984

Epoch: 6| Step: 12
Training loss: 0.11392446607351303
Validation loss: 1.4476667014501428

Epoch: 6| Step: 13
Training loss: 0.07942388951778412
Validation loss: 1.4600926317194456

Epoch: 552| Step: 0
Training loss: 0.06671999394893646
Validation loss: 1.4527982114463724

Epoch: 6| Step: 1
Training loss: 0.08576388657093048
Validation loss: 1.4388215400839364

Epoch: 6| Step: 2
Training loss: 0.08041512221097946
Validation loss: 1.4248296522325086

Epoch: 6| Step: 3
Training loss: 0.0924794152379036
Validation loss: 1.4301932409245481

Epoch: 6| Step: 4
Training loss: 0.06905179470777512
Validation loss: 1.4338095444504932

Epoch: 6| Step: 5
Training loss: 0.08775985240936279
Validation loss: 1.432771223847584

Epoch: 6| Step: 6
Training loss: 0.06213711202144623
Validation loss: 1.4407529254113474

Epoch: 6| Step: 7
Training loss: 0.09287501871585846
Validation loss: 1.4360235032214914

Epoch: 6| Step: 8
Training loss: 0.06075524538755417
Validation loss: 1.4422156669760262

Epoch: 6| Step: 9
Training loss: 0.08015896379947662
Validation loss: 1.4301195836836291

Epoch: 6| Step: 10
Training loss: 0.05882388353347778
Validation loss: 1.4395940854985227

Epoch: 6| Step: 11
Training loss: 0.10430818796157837
Validation loss: 1.454261577257546

Epoch: 6| Step: 12
Training loss: 0.12328793108463287
Validation loss: 1.4214688469004888

Epoch: 6| Step: 13
Training loss: 0.07641085237264633
Validation loss: 1.4518371897359048

Epoch: 553| Step: 0
Training loss: 0.0853116512298584
Validation loss: 1.4581241479483984

Epoch: 6| Step: 1
Training loss: 0.08948979526758194
Validation loss: 1.4489590467945221

Epoch: 6| Step: 2
Training loss: 0.10082557797431946
Validation loss: 1.440959054936645

Epoch: 6| Step: 3
Training loss: 0.09755706042051315
Validation loss: 1.4527398873400945

Epoch: 6| Step: 4
Training loss: 0.04454983025789261
Validation loss: 1.46504968853407

Epoch: 6| Step: 5
Training loss: 0.07546451687812805
Validation loss: 1.453746473917397

Epoch: 6| Step: 6
Training loss: 0.05753938481211662
Validation loss: 1.4602027041937715

Epoch: 6| Step: 7
Training loss: 0.0424472838640213
Validation loss: 1.4490832487742107

Epoch: 6| Step: 8
Training loss: 0.08172032237052917
Validation loss: 1.4686468365371868

Epoch: 6| Step: 9
Training loss: 0.056345824152231216
Validation loss: 1.4689331041869296

Epoch: 6| Step: 10
Training loss: 0.07846100628376007
Validation loss: 1.4699627020025765

Epoch: 6| Step: 11
Training loss: 0.08478547632694244
Validation loss: 1.4753286556531024

Epoch: 6| Step: 12
Training loss: 0.0649610310792923
Validation loss: 1.492860335175709

Epoch: 6| Step: 13
Training loss: 0.06547021865844727
Validation loss: 1.4720486030783704

Epoch: 554| Step: 0
Training loss: 0.04737035185098648
Validation loss: 1.4785707061008742

Epoch: 6| Step: 1
Training loss: 0.12313883751630783
Validation loss: 1.4697229285393991

Epoch: 6| Step: 2
Training loss: 0.1491333246231079
Validation loss: 1.4990849341115644

Epoch: 6| Step: 3
Training loss: 0.05252041667699814
Validation loss: 1.47822005005293

Epoch: 6| Step: 4
Training loss: 0.10452038049697876
Validation loss: 1.4823397744086482

Epoch: 6| Step: 5
Training loss: 0.052673742175102234
Validation loss: 1.4605206161416986

Epoch: 6| Step: 6
Training loss: 0.05637190118432045
Validation loss: 1.4528602560361226

Epoch: 6| Step: 7
Training loss: 0.03661549091339111
Validation loss: 1.4544415217573925

Epoch: 6| Step: 8
Training loss: 0.07405467331409454
Validation loss: 1.4507221765415643

Epoch: 6| Step: 9
Training loss: 0.04469843953847885
Validation loss: 1.4464143354405639

Epoch: 6| Step: 10
Training loss: 0.09171655774116516
Validation loss: 1.4220815243259552

Epoch: 6| Step: 11
Training loss: 0.044881854206323624
Validation loss: 1.4164322794124644

Epoch: 6| Step: 12
Training loss: 0.04069077968597412
Validation loss: 1.4213462234825216

Epoch: 6| Step: 13
Training loss: 0.06080439314246178
Validation loss: 1.4385652888205744

Epoch: 555| Step: 0
Training loss: 0.06797713786363602
Validation loss: 1.4148019872685915

Epoch: 6| Step: 1
Training loss: 0.05367561802268028
Validation loss: 1.4277823381526495

Epoch: 6| Step: 2
Training loss: 0.09202322363853455
Validation loss: 1.441479738040637

Epoch: 6| Step: 3
Training loss: 0.04868701100349426
Validation loss: 1.423822990027807

Epoch: 6| Step: 4
Training loss: 0.13221246004104614
Validation loss: 1.4591652283104517

Epoch: 6| Step: 5
Training loss: 0.061052076518535614
Validation loss: 1.4506607940120082

Epoch: 6| Step: 6
Training loss: 0.03777177259325981
Validation loss: 1.4546094607281428

Epoch: 6| Step: 7
Training loss: 0.08401717245578766
Validation loss: 1.448290660817136

Epoch: 6| Step: 8
Training loss: 0.09518737345933914
Validation loss: 1.4610449665336198

Epoch: 6| Step: 9
Training loss: 0.06512733548879623
Validation loss: 1.4777144642286404

Epoch: 6| Step: 10
Training loss: 0.06903418898582458
Validation loss: 1.4863696380328106

Epoch: 6| Step: 11
Training loss: 0.05692412331700325
Validation loss: 1.4833910785695559

Epoch: 6| Step: 12
Training loss: 0.06521455943584442
Validation loss: 1.4639828730654973

Epoch: 6| Step: 13
Training loss: 0.10554512590169907
Validation loss: 1.481528382147512

Epoch: 556| Step: 0
Training loss: 0.06522632390260696
Validation loss: 1.4630994155842771

Epoch: 6| Step: 1
Training loss: 0.044084977358579636
Validation loss: 1.4657996790383452

Epoch: 6| Step: 2
Training loss: 0.07522153854370117
Validation loss: 1.4602624267660163

Epoch: 6| Step: 3
Training loss: 0.050443731248378754
Validation loss: 1.4917929403243526

Epoch: 6| Step: 4
Training loss: 0.10281883925199509
Validation loss: 1.4954023104841991

Epoch: 6| Step: 5
Training loss: 0.04235870763659477
Validation loss: 1.496468008205455

Epoch: 6| Step: 6
Training loss: 0.10428822785615921
Validation loss: 1.4715279622744488

Epoch: 6| Step: 7
Training loss: 0.05613736808300018
Validation loss: 1.4702597933430825

Epoch: 6| Step: 8
Training loss: 0.09165091067552567
Validation loss: 1.469427090819164

Epoch: 6| Step: 9
Training loss: 0.07314462214708328
Validation loss: 1.4863219453442482

Epoch: 6| Step: 10
Training loss: 0.06303881853818893
Validation loss: 1.4547058305432718

Epoch: 6| Step: 11
Training loss: 0.09521714597940445
Validation loss: 1.4626895791740828

Epoch: 6| Step: 12
Training loss: 0.12172097712755203
Validation loss: 1.4515430427366687

Epoch: 6| Step: 13
Training loss: 0.04922674223780632
Validation loss: 1.4319222229783253

Epoch: 557| Step: 0
Training loss: 0.09382429718971252
Validation loss: 1.446434349142095

Epoch: 6| Step: 1
Training loss: 0.047116540372371674
Validation loss: 1.440915419209388

Epoch: 6| Step: 2
Training loss: 0.10743284225463867
Validation loss: 1.4416144778651576

Epoch: 6| Step: 3
Training loss: 0.12166237086057663
Validation loss: 1.4269994176844114

Epoch: 6| Step: 4
Training loss: 0.05368499457836151
Validation loss: 1.4121417601903279

Epoch: 6| Step: 5
Training loss: 0.09075570106506348
Validation loss: 1.4136589291275188

Epoch: 6| Step: 6
Training loss: 0.08510084450244904
Validation loss: 1.421974282110891

Epoch: 6| Step: 7
Training loss: 0.05736425518989563
Validation loss: 1.4338423795597528

Epoch: 6| Step: 8
Training loss: 0.06755001842975616
Validation loss: 1.4362100785778416

Epoch: 6| Step: 9
Training loss: 0.09521263837814331
Validation loss: 1.4264243559170795

Epoch: 6| Step: 10
Training loss: 0.13275115191936493
Validation loss: 1.4563807992524997

Epoch: 6| Step: 11
Training loss: 0.06627977639436722
Validation loss: 1.4387293688712581

Epoch: 6| Step: 12
Training loss: 0.08788155019283295
Validation loss: 1.419602535104239

Epoch: 6| Step: 13
Training loss: 0.11030864715576172
Validation loss: 1.4031160864778744

Epoch: 558| Step: 0
Training loss: 0.0766160860657692
Validation loss: 1.39391379843476

Epoch: 6| Step: 1
Training loss: 0.07263006269931793
Validation loss: 1.388416906838776

Epoch: 6| Step: 2
Training loss: 0.06779216229915619
Validation loss: 1.4190100944170387

Epoch: 6| Step: 3
Training loss: 0.13435298204421997
Validation loss: 1.4150168575266355

Epoch: 6| Step: 4
Training loss: 0.1062791645526886
Validation loss: 1.4318966032356344

Epoch: 6| Step: 5
Training loss: 0.07865379005670547
Validation loss: 1.4171061925990607

Epoch: 6| Step: 6
Training loss: 0.1173897385597229
Validation loss: 1.4029449186017435

Epoch: 6| Step: 7
Training loss: 0.09053662419319153
Validation loss: 1.4301144948569677

Epoch: 6| Step: 8
Training loss: 0.09317418932914734
Validation loss: 1.424338262568238

Epoch: 6| Step: 9
Training loss: 0.1141713559627533
Validation loss: 1.4396062999643304

Epoch: 6| Step: 10
Training loss: 0.09801389276981354
Validation loss: 1.4073861196476927

Epoch: 6| Step: 11
Training loss: 0.15776212513446808
Validation loss: 1.4521373747497477

Epoch: 6| Step: 12
Training loss: 0.18602025508880615
Validation loss: 1.413626568291777

Epoch: 6| Step: 13
Training loss: 0.08807637542486191
Validation loss: 1.4306235723598029

Epoch: 559| Step: 0
Training loss: 0.07928334176540375
Validation loss: 1.4082737763722737

Epoch: 6| Step: 1
Training loss: 0.07923290133476257
Validation loss: 1.3898949071925173

Epoch: 6| Step: 2
Training loss: 0.0625770092010498
Validation loss: 1.4004937653900476

Epoch: 6| Step: 3
Training loss: 0.0534677654504776
Validation loss: 1.4081383328283987

Epoch: 6| Step: 4
Training loss: 0.08019933104515076
Validation loss: 1.4206101830287645

Epoch: 6| Step: 5
Training loss: 0.06598657369613647
Validation loss: 1.415914563722508

Epoch: 6| Step: 6
Training loss: 0.1306288242340088
Validation loss: 1.451273500919342

Epoch: 6| Step: 7
Training loss: 0.15661612153053284
Validation loss: 1.4525100928480907

Epoch: 6| Step: 8
Training loss: 0.08790607750415802
Validation loss: 1.4504115299511982

Epoch: 6| Step: 9
Training loss: 0.10624442249536514
Validation loss: 1.4780229150608022

Epoch: 6| Step: 10
Training loss: 0.10827906429767609
Validation loss: 1.475683545553556

Epoch: 6| Step: 11
Training loss: 0.07556571811437607
Validation loss: 1.4574241202364686

Epoch: 6| Step: 12
Training loss: 0.10390041768550873
Validation loss: 1.4725385840221117

Epoch: 6| Step: 13
Training loss: 0.09477996826171875
Validation loss: 1.5018673122570079

Epoch: 560| Step: 0
Training loss: 0.053563181310892105
Validation loss: 1.4759551850698327

Epoch: 6| Step: 1
Training loss: 0.05409315600991249
Validation loss: 1.517947664824865

Epoch: 6| Step: 2
Training loss: 0.07772347331047058
Validation loss: 1.4997870281178465

Epoch: 6| Step: 3
Training loss: 0.07219108939170837
Validation loss: 1.4815035391879339

Epoch: 6| Step: 4
Training loss: 0.08572408556938171
Validation loss: 1.4927552118096301

Epoch: 6| Step: 5
Training loss: 0.11074881255626678
Validation loss: 1.4850395148800266

Epoch: 6| Step: 6
Training loss: 0.10801918059587479
Validation loss: 1.4667060785396124

Epoch: 6| Step: 7
Training loss: 0.07078138738870621
Validation loss: 1.4785994496396793

Epoch: 6| Step: 8
Training loss: 0.08452858030796051
Validation loss: 1.4772501337912776

Epoch: 6| Step: 9
Training loss: 0.1212821826338768
Validation loss: 1.4803257219253048

Epoch: 6| Step: 10
Training loss: 0.11745348572731018
Validation loss: 1.4548998263574415

Epoch: 6| Step: 11
Training loss: 0.0696023553609848
Validation loss: 1.4646126262603267

Epoch: 6| Step: 12
Training loss: 0.041780758649110794
Validation loss: 1.4722072180881296

Epoch: 6| Step: 13
Training loss: 0.09039416909217834
Validation loss: 1.4501267453675628

Epoch: 561| Step: 0
Training loss: 0.10113126039505005
Validation loss: 1.4362527965217509

Epoch: 6| Step: 1
Training loss: 0.07996682077646255
Validation loss: 1.4420443536132894

Epoch: 6| Step: 2
Training loss: 0.09064255654811859
Validation loss: 1.4605051599523073

Epoch: 6| Step: 3
Training loss: 0.1065797433257103
Validation loss: 1.4406589769547986

Epoch: 6| Step: 4
Training loss: 0.04964185133576393
Validation loss: 1.4396062948370492

Epoch: 6| Step: 5
Training loss: 0.05233948305249214
Validation loss: 1.4301673276450044

Epoch: 6| Step: 6
Training loss: 0.05010955035686493
Validation loss: 1.4125199093613574

Epoch: 6| Step: 7
Training loss: 0.06040659546852112
Validation loss: 1.4165493967712566

Epoch: 6| Step: 8
Training loss: 0.08093754202127457
Validation loss: 1.4112408571345831

Epoch: 6| Step: 9
Training loss: 0.03878533095121384
Validation loss: 1.4394187734973045

Epoch: 6| Step: 10
Training loss: 0.08611101657152176
Validation loss: 1.4205434899176321

Epoch: 6| Step: 11
Training loss: 0.13444127142429352
Validation loss: 1.4075081342010087

Epoch: 6| Step: 12
Training loss: 0.07733163237571716
Validation loss: 1.4131783445676167

Epoch: 6| Step: 13
Training loss: 0.0720808133482933
Validation loss: 1.3889415943494408

Epoch: 562| Step: 0
Training loss: 0.0475742407143116
Validation loss: 1.4093771429472073

Epoch: 6| Step: 1
Training loss: 0.05270802229642868
Validation loss: 1.412505377364415

Epoch: 6| Step: 2
Training loss: 0.07778614014387131
Validation loss: 1.4547364865579913

Epoch: 6| Step: 3
Training loss: 0.11276699602603912
Validation loss: 1.4412196861800326

Epoch: 6| Step: 4
Training loss: 0.05981644243001938
Validation loss: 1.493883462362392

Epoch: 6| Step: 5
Training loss: 0.09420137107372284
Validation loss: 1.4782350306869836

Epoch: 6| Step: 6
Training loss: 0.11962926387786865
Validation loss: 1.4942378036437496

Epoch: 6| Step: 7
Training loss: 0.09880761802196503
Validation loss: 1.4806184255948631

Epoch: 6| Step: 8
Training loss: 0.0750480517745018
Validation loss: 1.5147784422802668

Epoch: 6| Step: 9
Training loss: 0.104726642370224
Validation loss: 1.4843509594599407

Epoch: 6| Step: 10
Training loss: 0.0913827121257782
Validation loss: 1.486252389928346

Epoch: 6| Step: 11
Training loss: 0.053277041763067245
Validation loss: 1.4573333365942842

Epoch: 6| Step: 12
Training loss: 0.08472459018230438
Validation loss: 1.4872972247421101

Epoch: 6| Step: 13
Training loss: 0.06856242567300797
Validation loss: 1.4881843674567439

Epoch: 563| Step: 0
Training loss: 0.06108316034078598
Validation loss: 1.4900519540232997

Epoch: 6| Step: 1
Training loss: 0.041809797286987305
Validation loss: 1.4800670916034329

Epoch: 6| Step: 2
Training loss: 0.08777904510498047
Validation loss: 1.4574074117086266

Epoch: 6| Step: 3
Training loss: 0.09382428228855133
Validation loss: 1.4726442354981617

Epoch: 6| Step: 4
Training loss: 0.07651954889297485
Validation loss: 1.4740520625986078

Epoch: 6| Step: 5
Training loss: 0.07499665021896362
Validation loss: 1.4604165925774524

Epoch: 6| Step: 6
Training loss: 0.08101944625377655
Validation loss: 1.4291493610669208

Epoch: 6| Step: 7
Training loss: 0.061908967792987823
Validation loss: 1.4342916857811712

Epoch: 6| Step: 8
Training loss: 0.07594402879476547
Validation loss: 1.4226155152884863

Epoch: 6| Step: 9
Training loss: 0.04947926104068756
Validation loss: 1.424963374291697

Epoch: 6| Step: 10
Training loss: 0.06216539070010185
Validation loss: 1.4257484725726548

Epoch: 6| Step: 11
Training loss: 0.09948532283306122
Validation loss: 1.4110553841437063

Epoch: 6| Step: 12
Training loss: 0.12112671136856079
Validation loss: 1.3803697568114086

Epoch: 6| Step: 13
Training loss: 0.05015353858470917
Validation loss: 1.4076394598971131

Epoch: 564| Step: 0
Training loss: 0.05748225748538971
Validation loss: 1.381304963942497

Epoch: 6| Step: 1
Training loss: 0.06994787603616714
Validation loss: 1.3889999569103282

Epoch: 6| Step: 2
Training loss: 0.06159486621618271
Validation loss: 1.3817289138353

Epoch: 6| Step: 3
Training loss: 0.09190616011619568
Validation loss: 1.3907403279376287

Epoch: 6| Step: 4
Training loss: 0.05653585121035576
Validation loss: 1.3929542649176814

Epoch: 6| Step: 5
Training loss: 0.061559177935123444
Validation loss: 1.4154910220894763

Epoch: 6| Step: 6
Training loss: 0.09571428596973419
Validation loss: 1.409209673122693

Epoch: 6| Step: 7
Training loss: 0.07807275652885437
Validation loss: 1.3961781776079567

Epoch: 6| Step: 8
Training loss: 0.062271054834127426
Validation loss: 1.4203896202066892

Epoch: 6| Step: 9
Training loss: 0.0950891301035881
Validation loss: 1.4097136964080155

Epoch: 6| Step: 10
Training loss: 0.056188374757766724
Validation loss: 1.424044293101116

Epoch: 6| Step: 11
Training loss: 0.042989425361156464
Validation loss: 1.4245528892804218

Epoch: 6| Step: 12
Training loss: 0.05677681788802147
Validation loss: 1.420251529703858

Epoch: 6| Step: 13
Training loss: 0.01899462193250656
Validation loss: 1.422475528973405

Epoch: 565| Step: 0
Training loss: 0.05232102423906326
Validation loss: 1.4253115878310254

Epoch: 6| Step: 1
Training loss: 0.06673382222652435
Validation loss: 1.4283250493388022

Epoch: 6| Step: 2
Training loss: 0.09067600220441818
Validation loss: 1.4287427574075677

Epoch: 6| Step: 3
Training loss: 0.05853288248181343
Validation loss: 1.4346778277427918

Epoch: 6| Step: 4
Training loss: 0.06076568365097046
Validation loss: 1.4207718833800285

Epoch: 6| Step: 5
Training loss: 0.061402030289173126
Validation loss: 1.3993768095970154

Epoch: 6| Step: 6
Training loss: 0.04509229212999344
Validation loss: 1.4301234470900668

Epoch: 6| Step: 7
Training loss: 0.04948288947343826
Validation loss: 1.4137970093757875

Epoch: 6| Step: 8
Training loss: 0.08354753255844116
Validation loss: 1.40380351133244

Epoch: 6| Step: 9
Training loss: 0.13333597779273987
Validation loss: 1.432815690194407

Epoch: 6| Step: 10
Training loss: 0.13147655129432678
Validation loss: 1.4080083665027414

Epoch: 6| Step: 11
Training loss: 0.05151812732219696
Validation loss: 1.4335221782807381

Epoch: 6| Step: 12
Training loss: 0.059442803263664246
Validation loss: 1.4121280831675376

Epoch: 6| Step: 13
Training loss: 0.1279439777135849
Validation loss: 1.410690507581157

Epoch: 566| Step: 0
Training loss: 0.06853440403938293
Validation loss: 1.400517540593301

Epoch: 6| Step: 1
Training loss: 0.03516118973493576
Validation loss: 1.4334166665231027

Epoch: 6| Step: 2
Training loss: 0.0686982125043869
Validation loss: 1.424205962047782

Epoch: 6| Step: 3
Training loss: 0.045246534049510956
Validation loss: 1.3873265289491223

Epoch: 6| Step: 4
Training loss: 0.05839601904153824
Validation loss: 1.4233672221501668

Epoch: 6| Step: 5
Training loss: 0.08310690522193909
Validation loss: 1.4066547873199626

Epoch: 6| Step: 6
Training loss: 0.05462251603603363
Validation loss: 1.408204085724328

Epoch: 6| Step: 7
Training loss: 0.1065652146935463
Validation loss: 1.4070090606648435

Epoch: 6| Step: 8
Training loss: 0.08246050029993057
Validation loss: 1.4124651647383166

Epoch: 6| Step: 9
Training loss: 0.03936825692653656
Validation loss: 1.410669090927288

Epoch: 6| Step: 10
Training loss: 0.05757440626621246
Validation loss: 1.419223734127578

Epoch: 6| Step: 11
Training loss: 0.05715695396065712
Validation loss: 1.4083708293976323

Epoch: 6| Step: 12
Training loss: 0.06633607298135757
Validation loss: 1.4384869997219374

Epoch: 6| Step: 13
Training loss: 0.08511396497488022
Validation loss: 1.419884063864267

Epoch: 567| Step: 0
Training loss: 0.04801597446203232
Validation loss: 1.4540147486553396

Epoch: 6| Step: 1
Training loss: 0.050649818032979965
Validation loss: 1.4041982773811585

Epoch: 6| Step: 2
Training loss: 0.03894977271556854
Validation loss: 1.440046477061446

Epoch: 6| Step: 3
Training loss: 0.10964588820934296
Validation loss: 1.4176499971779444

Epoch: 6| Step: 4
Training loss: 0.06111326813697815
Validation loss: 1.4186625531924668

Epoch: 6| Step: 5
Training loss: 0.03791790455579758
Validation loss: 1.4538740240117556

Epoch: 6| Step: 6
Training loss: 0.07783610373735428
Validation loss: 1.4102211344626643

Epoch: 6| Step: 7
Training loss: 0.04143702983856201
Validation loss: 1.416114123918677

Epoch: 6| Step: 8
Training loss: 0.0643235296010971
Validation loss: 1.412600367299972

Epoch: 6| Step: 9
Training loss: 0.05781887099146843
Validation loss: 1.387648796522489

Epoch: 6| Step: 10
Training loss: 0.04979459568858147
Validation loss: 1.4073834964024123

Epoch: 6| Step: 11
Training loss: 0.07297531515359879
Validation loss: 1.419617687502215

Epoch: 6| Step: 12
Training loss: 0.07908552139997482
Validation loss: 1.4181328486370783

Epoch: 6| Step: 13
Training loss: 0.019089046865701675
Validation loss: 1.4310179730897308

Epoch: 568| Step: 0
Training loss: 0.10535120964050293
Validation loss: 1.4416575303641699

Epoch: 6| Step: 1
Training loss: 0.0605144239962101
Validation loss: 1.4116025868282522

Epoch: 6| Step: 2
Training loss: 0.08703293651342392
Validation loss: 1.429973933645474

Epoch: 6| Step: 3
Training loss: 0.05552395433187485
Validation loss: 1.433131242311129

Epoch: 6| Step: 4
Training loss: 0.05860386788845062
Validation loss: 1.4270324835213282

Epoch: 6| Step: 5
Training loss: 0.05255977064371109
Validation loss: 1.4279139887902044

Epoch: 6| Step: 6
Training loss: 0.07157266139984131
Validation loss: 1.39315241254786

Epoch: 6| Step: 7
Training loss: 0.0606522373855114
Validation loss: 1.4214951081942486

Epoch: 6| Step: 8
Training loss: 0.06444995105266571
Validation loss: 1.4572543149353356

Epoch: 6| Step: 9
Training loss: 0.063323013484478
Validation loss: 1.4163434633644678

Epoch: 6| Step: 10
Training loss: 0.06097413972020149
Validation loss: 1.4146846199548373

Epoch: 6| Step: 11
Training loss: 0.07257963716983795
Validation loss: 1.4153212321701871

Epoch: 6| Step: 12
Training loss: 0.07529076188802719
Validation loss: 1.418041826576315

Epoch: 6| Step: 13
Training loss: 0.06637805700302124
Validation loss: 1.429686898826271

Epoch: 569| Step: 0
Training loss: 0.03751186653971672
Validation loss: 1.4207588588037798

Epoch: 6| Step: 1
Training loss: 0.03942045569419861
Validation loss: 1.4104329027155393

Epoch: 6| Step: 2
Training loss: 0.06331519037485123
Validation loss: 1.4192689003482941

Epoch: 6| Step: 3
Training loss: 0.06632442027330399
Validation loss: 1.4166742229974398

Epoch: 6| Step: 4
Training loss: 0.08602916449308395
Validation loss: 1.410703960285392

Epoch: 6| Step: 5
Training loss: 0.06966696679592133
Validation loss: 1.4284325427906488

Epoch: 6| Step: 6
Training loss: 0.0900643914937973
Validation loss: 1.428772109811024

Epoch: 6| Step: 7
Training loss: 0.08581384271383286
Validation loss: 1.4079745059372277

Epoch: 6| Step: 8
Training loss: 0.07128430902957916
Validation loss: 1.3954746953902706

Epoch: 6| Step: 9
Training loss: 0.056844234466552734
Validation loss: 1.4107001032880557

Epoch: 6| Step: 10
Training loss: 0.05464702472090721
Validation loss: 1.4456968833041448

Epoch: 6| Step: 11
Training loss: 0.03883645310997963
Validation loss: 1.4320290011744345

Epoch: 6| Step: 12
Training loss: 0.09389999508857727
Validation loss: 1.4294732501429896

Epoch: 6| Step: 13
Training loss: 0.046588726341724396
Validation loss: 1.4291896755977342

Epoch: 570| Step: 0
Training loss: 0.0687650740146637
Validation loss: 1.4557042083432596

Epoch: 6| Step: 1
Training loss: 0.09487270563840866
Validation loss: 1.4215041283638246

Epoch: 6| Step: 2
Training loss: 0.046697504818439484
Validation loss: 1.41901905562288

Epoch: 6| Step: 3
Training loss: 0.04988614469766617
Validation loss: 1.4326362776499924

Epoch: 6| Step: 4
Training loss: 0.020647943019866943
Validation loss: 1.4300487323473858

Epoch: 6| Step: 5
Training loss: 0.0415455661714077
Validation loss: 1.4347884821635422

Epoch: 6| Step: 6
Training loss: 0.06803800165653229
Validation loss: 1.4109377553386073

Epoch: 6| Step: 7
Training loss: 0.049861613661050797
Validation loss: 1.4256410515436562

Epoch: 6| Step: 8
Training loss: 0.08111541718244553
Validation loss: 1.4159694974140455

Epoch: 6| Step: 9
Training loss: 0.0466928593814373
Validation loss: 1.3942565661604687

Epoch: 6| Step: 10
Training loss: 0.11374758183956146
Validation loss: 1.419229051118256

Epoch: 6| Step: 11
Training loss: 0.07017283141613007
Validation loss: 1.4234451914346347

Epoch: 6| Step: 12
Training loss: 0.10732464492321014
Validation loss: 1.4115820918031918

Epoch: 6| Step: 13
Training loss: 0.027557816356420517
Validation loss: 1.4086173324174778

Epoch: 571| Step: 0
Training loss: 0.057193268090486526
Validation loss: 1.412868002409576

Epoch: 6| Step: 1
Training loss: 0.09580963850021362
Validation loss: 1.4543393837508334

Epoch: 6| Step: 2
Training loss: 0.07129249721765518
Validation loss: 1.456682820473948

Epoch: 6| Step: 3
Training loss: 0.05190259963274002
Validation loss: 1.4447682737022318

Epoch: 6| Step: 4
Training loss: 0.08628100156784058
Validation loss: 1.4213783317996609

Epoch: 6| Step: 5
Training loss: 0.07190395891666412
Validation loss: 1.4477577286381875

Epoch: 6| Step: 6
Training loss: 0.09691587835550308
Validation loss: 1.439757421452512

Epoch: 6| Step: 7
Training loss: 0.11047094315290451
Validation loss: 1.4474595515958724

Epoch: 6| Step: 8
Training loss: 0.08379330486059189
Validation loss: 1.4540062251911368

Epoch: 6| Step: 9
Training loss: 0.0648471862077713
Validation loss: 1.4400246374068721

Epoch: 6| Step: 10
Training loss: 0.07799853384494781
Validation loss: 1.4373446395320277

Epoch: 6| Step: 11
Training loss: 0.0494859516620636
Validation loss: 1.4311871528625488

Epoch: 6| Step: 12
Training loss: 0.0537848100066185
Validation loss: 1.4142260756543887

Epoch: 6| Step: 13
Training loss: 0.05968156084418297
Validation loss: 1.4485449073135213

Epoch: 572| Step: 0
Training loss: 0.061232373118400574
Validation loss: 1.409727123475844

Epoch: 6| Step: 1
Training loss: 0.03677563741803169
Validation loss: 1.43263106448676

Epoch: 6| Step: 2
Training loss: 0.041045181453228
Validation loss: 1.430169682348928

Epoch: 6| Step: 3
Training loss: 0.07259932160377502
Validation loss: 1.4259656411345287

Epoch: 6| Step: 4
Training loss: 0.03684934228658676
Validation loss: 1.4344435314978323

Epoch: 6| Step: 5
Training loss: 0.03490941599011421
Validation loss: 1.405644791100615

Epoch: 6| Step: 6
Training loss: 0.06300601363182068
Validation loss: 1.437183641618298

Epoch: 6| Step: 7
Training loss: 0.05159321799874306
Validation loss: 1.4268731481285506

Epoch: 6| Step: 8
Training loss: 0.1023717075586319
Validation loss: 1.449044568564302

Epoch: 6| Step: 9
Training loss: 0.059271637350320816
Validation loss: 1.4198167234338739

Epoch: 6| Step: 10
Training loss: 0.04089348018169403
Validation loss: 1.4148418711077781

Epoch: 6| Step: 11
Training loss: 0.10260622948408127
Validation loss: 1.402748134828383

Epoch: 6| Step: 12
Training loss: 0.06611346453428268
Validation loss: 1.4100419000912738

Epoch: 6| Step: 13
Training loss: 0.060379788279533386
Validation loss: 1.421819076743177

Epoch: 573| Step: 0
Training loss: 0.04750720411539078
Validation loss: 1.443360528638286

Epoch: 6| Step: 1
Training loss: 0.05173003673553467
Validation loss: 1.44954425801513

Epoch: 6| Step: 2
Training loss: 0.04335630685091019
Validation loss: 1.4254836074767574

Epoch: 6| Step: 3
Training loss: 0.06295053660869598
Validation loss: 1.4349951917125332

Epoch: 6| Step: 4
Training loss: 0.06130800396203995
Validation loss: 1.447790947011722

Epoch: 6| Step: 5
Training loss: 0.10174921154975891
Validation loss: 1.469867456343866

Epoch: 6| Step: 6
Training loss: 0.03913477435708046
Validation loss: 1.455702612476964

Epoch: 6| Step: 7
Training loss: 0.06699289381504059
Validation loss: 1.4568901292739376

Epoch: 6| Step: 8
Training loss: 0.04066199064254761
Validation loss: 1.4546662504955004

Epoch: 6| Step: 9
Training loss: 0.06687043607234955
Validation loss: 1.494936345725931

Epoch: 6| Step: 10
Training loss: 0.033231839537620544
Validation loss: 1.4563127692027757

Epoch: 6| Step: 11
Training loss: 0.0830024778842926
Validation loss: 1.4770156119459419

Epoch: 6| Step: 12
Training loss: 0.058878958225250244
Validation loss: 1.485372366443757

Epoch: 6| Step: 13
Training loss: 0.0670490562915802
Validation loss: 1.4713115128137733

Epoch: 574| Step: 0
Training loss: 0.04180328547954559
Validation loss: 1.4520664509906565

Epoch: 6| Step: 1
Training loss: 0.08434519171714783
Validation loss: 1.4466828812835038

Epoch: 6| Step: 2
Training loss: 0.048085685819387436
Validation loss: 1.4682336199668147

Epoch: 6| Step: 3
Training loss: 0.06165372580289841
Validation loss: 1.4384105807991439

Epoch: 6| Step: 4
Training loss: 0.09477964788675308
Validation loss: 1.4406531139086651

Epoch: 6| Step: 5
Training loss: 0.06194927170872688
Validation loss: 1.445418861604506

Epoch: 6| Step: 6
Training loss: 0.04375788941979408
Validation loss: 1.4060618672319638

Epoch: 6| Step: 7
Training loss: 0.0926566869020462
Validation loss: 1.4046738846327669

Epoch: 6| Step: 8
Training loss: 0.053944289684295654
Validation loss: 1.4439862440991145

Epoch: 6| Step: 9
Training loss: 0.049749478697776794
Validation loss: 1.430665223829208

Epoch: 6| Step: 10
Training loss: 0.05200706794857979
Validation loss: 1.4202395587839105

Epoch: 6| Step: 11
Training loss: 0.09558717906475067
Validation loss: 1.4162641763687134

Epoch: 6| Step: 12
Training loss: 0.04752318933606148
Validation loss: 1.4301190773646038

Epoch: 6| Step: 13
Training loss: 0.04233323037624359
Validation loss: 1.4436373012040251

Epoch: 575| Step: 0
Training loss: 0.044375739991664886
Validation loss: 1.4603455079499112

Epoch: 6| Step: 1
Training loss: 0.06340457499027252
Validation loss: 1.4243561106343423

Epoch: 6| Step: 2
Training loss: 0.10938258469104767
Validation loss: 1.4363444889745405

Epoch: 6| Step: 3
Training loss: 0.06717485934495926
Validation loss: 1.4539554337019562

Epoch: 6| Step: 4
Training loss: 0.06761488318443298
Validation loss: 1.411851562479491

Epoch: 6| Step: 5
Training loss: 0.044128142297267914
Validation loss: 1.43200118823718

Epoch: 6| Step: 6
Training loss: 0.07726949453353882
Validation loss: 1.4246143230827906

Epoch: 6| Step: 7
Training loss: 0.05361294746398926
Validation loss: 1.4204550731566645

Epoch: 6| Step: 8
Training loss: 0.05957593768835068
Validation loss: 1.4463921580263364

Epoch: 6| Step: 9
Training loss: 0.07684486359357834
Validation loss: 1.4315468072891235

Epoch: 6| Step: 10
Training loss: 0.061180539429187775
Validation loss: 1.4407552570425055

Epoch: 6| Step: 11
Training loss: 0.055278509855270386
Validation loss: 1.4393045415160477

Epoch: 6| Step: 12
Training loss: 0.08657661080360413
Validation loss: 1.413465525514336

Epoch: 6| Step: 13
Training loss: 0.050985440611839294
Validation loss: 1.4307986600424654

Epoch: 576| Step: 0
Training loss: 0.06895682960748672
Validation loss: 1.4240848120822702

Epoch: 6| Step: 1
Training loss: 0.03759852796792984
Validation loss: 1.4291009351771364

Epoch: 6| Step: 2
Training loss: 0.04548117145895958
Validation loss: 1.439201339598625

Epoch: 6| Step: 3
Training loss: 0.038349658250808716
Validation loss: 1.4345427713086527

Epoch: 6| Step: 4
Training loss: 0.08805272728204727
Validation loss: 1.4291744039904686

Epoch: 6| Step: 5
Training loss: 0.09822866320610046
Validation loss: 1.447524493740451

Epoch: 6| Step: 6
Training loss: 0.06344324350357056
Validation loss: 1.4177170927806566

Epoch: 6| Step: 7
Training loss: 0.07802550494670868
Validation loss: 1.4510190256180302

Epoch: 6| Step: 8
Training loss: 0.0501336008310318
Validation loss: 1.4669171264094691

Epoch: 6| Step: 9
Training loss: 0.06409116089344025
Validation loss: 1.4289751616857385

Epoch: 6| Step: 10
Training loss: 0.06321298331022263
Validation loss: 1.4199933428918161

Epoch: 6| Step: 11
Training loss: 0.034491442143917084
Validation loss: 1.43621003243231

Epoch: 6| Step: 12
Training loss: 0.04513076692819595
Validation loss: 1.4336134131236742

Epoch: 6| Step: 13
Training loss: 0.08967728912830353
Validation loss: 1.4231039054932133

Epoch: 577| Step: 0
Training loss: 0.08595791459083557
Validation loss: 1.446540081372825

Epoch: 6| Step: 1
Training loss: 0.10076567530632019
Validation loss: 1.4572942692746398

Epoch: 6| Step: 2
Training loss: 0.04533030837774277
Validation loss: 1.4636842127769225

Epoch: 6| Step: 3
Training loss: 0.05079520493745804
Validation loss: 1.4498814139314877

Epoch: 6| Step: 4
Training loss: 0.08231694251298904
Validation loss: 1.41684950295315

Epoch: 6| Step: 5
Training loss: 0.06337389349937439
Validation loss: 1.4260207017262776

Epoch: 6| Step: 6
Training loss: 0.06311385333538055
Validation loss: 1.4236293326142013

Epoch: 6| Step: 7
Training loss: 0.061854708939790726
Validation loss: 1.4267937829417567

Epoch: 6| Step: 8
Training loss: 0.036141037940979004
Validation loss: 1.4270603426041142

Epoch: 6| Step: 9
Training loss: 0.0564945712685585
Validation loss: 1.416727924859652

Epoch: 6| Step: 10
Training loss: 0.0765891969203949
Validation loss: 1.4175031845287611

Epoch: 6| Step: 11
Training loss: 0.0467214360833168
Validation loss: 1.3983000414345854

Epoch: 6| Step: 12
Training loss: 0.04517639800906181
Validation loss: 1.4149461279633224

Epoch: 6| Step: 13
Training loss: 0.03515534847974777
Validation loss: 1.4004976992966027

Epoch: 578| Step: 0
Training loss: 0.04944193363189697
Validation loss: 1.4307231903076172

Epoch: 6| Step: 1
Training loss: 0.07856431603431702
Validation loss: 1.4080962404128043

Epoch: 6| Step: 2
Training loss: 0.03804098069667816
Validation loss: 1.3838099407893356

Epoch: 6| Step: 3
Training loss: 0.03817138075828552
Validation loss: 1.3825740827027189

Epoch: 6| Step: 4
Training loss: 0.044241271913051605
Validation loss: 1.4105096138933653

Epoch: 6| Step: 5
Training loss: 0.07776615768671036
Validation loss: 1.397648899785934

Epoch: 6| Step: 6
Training loss: 0.03983595222234726
Validation loss: 1.4135212757254159

Epoch: 6| Step: 7
Training loss: 0.07536885142326355
Validation loss: 1.4346913599198865

Epoch: 6| Step: 8
Training loss: 0.08201663941144943
Validation loss: 1.414926036711662

Epoch: 6| Step: 9
Training loss: 0.04482356458902359
Validation loss: 1.4214984088815668

Epoch: 6| Step: 10
Training loss: 0.060377560555934906
Validation loss: 1.4429316507872714

Epoch: 6| Step: 11
Training loss: 0.04888347536325455
Validation loss: 1.4494873246838968

Epoch: 6| Step: 12
Training loss: 0.07121779024600983
Validation loss: 1.4559342335629206

Epoch: 6| Step: 13
Training loss: 0.07249724864959717
Validation loss: 1.460808797549176

Epoch: 579| Step: 0
Training loss: 0.0751914456486702
Validation loss: 1.4520912196046563

Epoch: 6| Step: 1
Training loss: 0.058098066598176956
Validation loss: 1.448488958420292

Epoch: 6| Step: 2
Training loss: 0.11256683617830276
Validation loss: 1.426620993562924

Epoch: 6| Step: 3
Training loss: 0.08792690187692642
Validation loss: 1.4293474715243104

Epoch: 6| Step: 4
Training loss: 0.06606150418519974
Validation loss: 1.4438412330483879

Epoch: 6| Step: 5
Training loss: 0.08080001175403595
Validation loss: 1.4463368000522736

Epoch: 6| Step: 6
Training loss: 0.05129963532090187
Validation loss: 1.4498207287121845

Epoch: 6| Step: 7
Training loss: 0.04356699436903
Validation loss: 1.423030440525342

Epoch: 6| Step: 8
Training loss: 0.07500829547643661
Validation loss: 1.4481736953540514

Epoch: 6| Step: 9
Training loss: 0.06345540285110474
Validation loss: 1.43474397864393

Epoch: 6| Step: 10
Training loss: 0.05696519464254379
Validation loss: 1.4149321471491167

Epoch: 6| Step: 11
Training loss: 0.07182818651199341
Validation loss: 1.4517497426720076

Epoch: 6| Step: 12
Training loss: 0.03413227200508118
Validation loss: 1.4388689533356698

Epoch: 6| Step: 13
Training loss: 0.058562152087688446
Validation loss: 1.436301044238511

Epoch: 580| Step: 0
Training loss: 0.10218670964241028
Validation loss: 1.4265364818675543

Epoch: 6| Step: 1
Training loss: 0.04906424507498741
Validation loss: 1.4188584345643238

Epoch: 6| Step: 2
Training loss: 0.0992700457572937
Validation loss: 1.396650330994719

Epoch: 6| Step: 3
Training loss: 0.04777756705880165
Validation loss: 1.4156727893378145

Epoch: 6| Step: 4
Training loss: 0.0582762137055397
Validation loss: 1.3930590370649933

Epoch: 6| Step: 5
Training loss: 0.0742756649851799
Validation loss: 1.4171570013928156

Epoch: 6| Step: 6
Training loss: 0.04211195558309555
Validation loss: 1.4063184645868116

Epoch: 6| Step: 7
Training loss: 0.0481095165014267
Validation loss: 1.4081627527872722

Epoch: 6| Step: 8
Training loss: 0.09794715791940689
Validation loss: 1.4021163473847091

Epoch: 6| Step: 9
Training loss: 0.061330266296863556
Validation loss: 1.4295684599107312

Epoch: 6| Step: 10
Training loss: 0.05605914443731308
Validation loss: 1.4169614231714638

Epoch: 6| Step: 11
Training loss: 0.04032497853040695
Validation loss: 1.4031715995521956

Epoch: 6| Step: 12
Training loss: 0.029425280168652534
Validation loss: 1.4021238562881306

Epoch: 6| Step: 13
Training loss: 0.05045696720480919
Validation loss: 1.4150569541479951

Epoch: 581| Step: 0
Training loss: 0.04403283819556236
Validation loss: 1.414331739948642

Epoch: 6| Step: 1
Training loss: 0.0668618381023407
Validation loss: 1.4151563477772537

Epoch: 6| Step: 2
Training loss: 0.07274984568357468
Validation loss: 1.405485414689587

Epoch: 6| Step: 3
Training loss: 0.05497054010629654
Validation loss: 1.3623535838178409

Epoch: 6| Step: 4
Training loss: 0.03412855044007301
Validation loss: 1.4048652821971523

Epoch: 6| Step: 5
Training loss: 0.06723183393478394
Validation loss: 1.383697332874421

Epoch: 6| Step: 6
Training loss: 0.04928028583526611
Validation loss: 1.3829035419289784

Epoch: 6| Step: 7
Training loss: 0.05389261990785599
Validation loss: 1.4212782011237195

Epoch: 6| Step: 8
Training loss: 0.09697416424751282
Validation loss: 1.3918316973152982

Epoch: 6| Step: 9
Training loss: 0.059922099113464355
Validation loss: 1.3940896270095662

Epoch: 6| Step: 10
Training loss: 0.03165924921631813
Validation loss: 1.3987771759751022

Epoch: 6| Step: 11
Training loss: 0.06101405993103981
Validation loss: 1.3763957741439983

Epoch: 6| Step: 12
Training loss: 0.042315348982810974
Validation loss: 1.426822297034725

Epoch: 6| Step: 13
Training loss: 0.04033401980996132
Validation loss: 1.4139882749126804

Epoch: 582| Step: 0
Training loss: 0.05513285845518112
Validation loss: 1.4177526184307632

Epoch: 6| Step: 1
Training loss: 0.12082278728485107
Validation loss: 1.444387435913086

Epoch: 6| Step: 2
Training loss: 0.06927413493394852
Validation loss: 1.4114669702386344

Epoch: 6| Step: 3
Training loss: 0.06719331443309784
Validation loss: 1.436675101198176

Epoch: 6| Step: 4
Training loss: 0.06088702380657196
Validation loss: 1.4638212496234524

Epoch: 6| Step: 5
Training loss: 0.05005885660648346
Validation loss: 1.4593954009394492

Epoch: 6| Step: 6
Training loss: 0.05455324798822403
Validation loss: 1.4554042585434452

Epoch: 6| Step: 7
Training loss: 0.05739738419651985
Validation loss: 1.4355502423419748

Epoch: 6| Step: 8
Training loss: 0.03371148928999901
Validation loss: 1.4532769931259977

Epoch: 6| Step: 9
Training loss: 0.0722494125366211
Validation loss: 1.456393338018848

Epoch: 6| Step: 10
Training loss: 0.04220297932624817
Validation loss: 1.4160067227578932

Epoch: 6| Step: 11
Training loss: 0.0492994524538517
Validation loss: 1.4008705897997784

Epoch: 6| Step: 12
Training loss: 0.10325482487678528
Validation loss: 1.4118870599295503

Epoch: 6| Step: 13
Training loss: 0.04567919671535492
Validation loss: 1.4174892530646375

Epoch: 583| Step: 0
Training loss: 0.07742206007242203
Validation loss: 1.4077824520808395

Epoch: 6| Step: 1
Training loss: 0.10374598205089569
Validation loss: 1.4027124034461154

Epoch: 6| Step: 2
Training loss: 0.07863110303878784
Validation loss: 1.4209985194667694

Epoch: 6| Step: 3
Training loss: 0.07431581616401672
Validation loss: 1.4185260277922436

Epoch: 6| Step: 4
Training loss: 0.04739196598529816
Validation loss: 1.3798405470386628

Epoch: 6| Step: 5
Training loss: 0.044025812298059464
Validation loss: 1.4407286208163026

Epoch: 6| Step: 6
Training loss: 0.056499868631362915
Validation loss: 1.4394368548547067

Epoch: 6| Step: 7
Training loss: 0.06085307523608208
Validation loss: 1.4409551191073593

Epoch: 6| Step: 8
Training loss: 0.08434970676898956
Validation loss: 1.4124873498434662

Epoch: 6| Step: 9
Training loss: 0.056001946330070496
Validation loss: 1.4585165234022244

Epoch: 6| Step: 10
Training loss: 0.05011942237615585
Validation loss: 1.4322603415417414

Epoch: 6| Step: 11
Training loss: 0.04680267348885536
Validation loss: 1.4266277192741312

Epoch: 6| Step: 12
Training loss: 0.06749770790338516
Validation loss: 1.4360998151122883

Epoch: 6| Step: 13
Training loss: 0.029434600844979286
Validation loss: 1.4434297635991087

Epoch: 584| Step: 0
Training loss: 0.047716595232486725
Validation loss: 1.4496830778737222

Epoch: 6| Step: 1
Training loss: 0.06193763390183449
Validation loss: 1.4534865758752311

Epoch: 6| Step: 2
Training loss: 0.0974927693605423
Validation loss: 1.4453833686408175

Epoch: 6| Step: 3
Training loss: 0.08218839764595032
Validation loss: 1.4199692151879753

Epoch: 6| Step: 4
Training loss: 0.06129757687449455
Validation loss: 1.4511409241666076

Epoch: 6| Step: 5
Training loss: 0.07227830588817596
Validation loss: 1.4329513580568376

Epoch: 6| Step: 6
Training loss: 0.07288959622383118
Validation loss: 1.4211777243562924

Epoch: 6| Step: 7
Training loss: 0.08494037389755249
Validation loss: 1.4262791154205159

Epoch: 6| Step: 8
Training loss: 0.061932697892189026
Validation loss: 1.468842811481927

Epoch: 6| Step: 9
Training loss: 0.07556448876857758
Validation loss: 1.4710561639519149

Epoch: 6| Step: 10
Training loss: 0.05113846808671951
Validation loss: 1.44970182705951

Epoch: 6| Step: 11
Training loss: 0.045533470809459686
Validation loss: 1.473516397578742

Epoch: 6| Step: 12
Training loss: 0.08725433051586151
Validation loss: 1.4636065126747213

Epoch: 6| Step: 13
Training loss: 0.029570791870355606
Validation loss: 1.4676254821080033

Epoch: 585| Step: 0
Training loss: 0.07579763233661652
Validation loss: 1.4688682492061327

Epoch: 6| Step: 1
Training loss: 0.0573524609208107
Validation loss: 1.4675513211116995

Epoch: 6| Step: 2
Training loss: 0.04467540234327316
Validation loss: 1.4653677555822557

Epoch: 6| Step: 3
Training loss: 0.04356084764003754
Validation loss: 1.4485566667331162

Epoch: 6| Step: 4
Training loss: 0.03994501382112503
Validation loss: 1.4331008759878014

Epoch: 6| Step: 5
Training loss: 0.053166210651397705
Validation loss: 1.4362631497844573

Epoch: 6| Step: 6
Training loss: 0.057686030864715576
Validation loss: 1.451609105833115

Epoch: 6| Step: 7
Training loss: 0.07415984570980072
Validation loss: 1.4454249476873746

Epoch: 6| Step: 8
Training loss: 0.06759889423847198
Validation loss: 1.4301391109343498

Epoch: 6| Step: 9
Training loss: 0.09026515483856201
Validation loss: 1.4304468542016961

Epoch: 6| Step: 10
Training loss: 0.057317107915878296
Validation loss: 1.461707595855959

Epoch: 6| Step: 11
Training loss: 0.0790247917175293
Validation loss: 1.4770248384885891

Epoch: 6| Step: 12
Training loss: 0.08039942383766174
Validation loss: 1.4492108360413583

Epoch: 6| Step: 13
Training loss: 0.07831405103206635
Validation loss: 1.4397952659155733

Epoch: 586| Step: 0
Training loss: 0.07212601602077484
Validation loss: 1.433846826194435

Epoch: 6| Step: 1
Training loss: 0.035043008625507355
Validation loss: 1.456468644962516

Epoch: 6| Step: 2
Training loss: 0.04182776063680649
Validation loss: 1.4289063561347224

Epoch: 6| Step: 3
Training loss: 0.05034886673092842
Validation loss: 1.4220595782802952

Epoch: 6| Step: 4
Training loss: 0.04503501206636429
Validation loss: 1.4582839499237716

Epoch: 6| Step: 5
Training loss: 0.08452925086021423
Validation loss: 1.420531202388066

Epoch: 6| Step: 6
Training loss: 0.08276157081127167
Validation loss: 1.4460824522920834

Epoch: 6| Step: 7
Training loss: 0.06441774219274521
Validation loss: 1.418180856653439

Epoch: 6| Step: 8
Training loss: 0.05249869078397751
Validation loss: 1.4078542993914696

Epoch: 6| Step: 9
Training loss: 0.040544211864471436
Validation loss: 1.4061976671218872

Epoch: 6| Step: 10
Training loss: 0.07399280369281769
Validation loss: 1.4188848695447367

Epoch: 6| Step: 11
Training loss: 0.061128467321395874
Validation loss: 1.4327879618572932

Epoch: 6| Step: 12
Training loss: 0.08272206038236618
Validation loss: 1.431246502425081

Epoch: 6| Step: 13
Training loss: 0.07972490042448044
Validation loss: 1.4167913877835838

Epoch: 587| Step: 0
Training loss: 0.05609430745244026
Validation loss: 1.4203423902552614

Epoch: 6| Step: 1
Training loss: 0.06289531290531158
Validation loss: 1.4195944083634244

Epoch: 6| Step: 2
Training loss: 0.05696292966604233
Validation loss: 1.3946061089474668

Epoch: 6| Step: 3
Training loss: 0.07400709390640259
Validation loss: 1.3899622155774025

Epoch: 6| Step: 4
Training loss: 0.06321534514427185
Validation loss: 1.3950129926845591

Epoch: 6| Step: 5
Training loss: 0.05948799103498459
Validation loss: 1.3992708639432025

Epoch: 6| Step: 6
Training loss: 0.0835646539926529
Validation loss: 1.3961601033005664

Epoch: 6| Step: 7
Training loss: 0.06526051461696625
Validation loss: 1.4411315097603747

Epoch: 6| Step: 8
Training loss: 0.09171122312545776
Validation loss: 1.4459591655321018

Epoch: 6| Step: 9
Training loss: 0.12564536929130554
Validation loss: 1.4075999516312794

Epoch: 6| Step: 10
Training loss: 0.0402415469288826
Validation loss: 1.4338526828314668

Epoch: 6| Step: 11
Training loss: 0.08799126744270325
Validation loss: 1.4370444256772277

Epoch: 6| Step: 12
Training loss: 0.06014825403690338
Validation loss: 1.447737898877872

Epoch: 6| Step: 13
Training loss: 0.09832588583230972
Validation loss: 1.437467502009484

Epoch: 588| Step: 0
Training loss: 0.08050131797790527
Validation loss: 1.4499623519118114

Epoch: 6| Step: 1
Training loss: 0.049592383205890656
Validation loss: 1.4496768392542356

Epoch: 6| Step: 2
Training loss: 0.06714946031570435
Validation loss: 1.4623053996793685

Epoch: 6| Step: 3
Training loss: 0.06564982235431671
Validation loss: 1.4435061395809214

Epoch: 6| Step: 4
Training loss: 0.0822901576757431
Validation loss: 1.4539636386338102

Epoch: 6| Step: 5
Training loss: 0.09925020486116409
Validation loss: 1.4375373586531608

Epoch: 6| Step: 6
Training loss: 0.04824632406234741
Validation loss: 1.420159855837463

Epoch: 6| Step: 7
Training loss: 0.07537990808486938
Validation loss: 1.4312848391071442

Epoch: 6| Step: 8
Training loss: 0.05857982113957405
Validation loss: 1.4392302472104308

Epoch: 6| Step: 9
Training loss: 0.05339162051677704
Validation loss: 1.4466613018384544

Epoch: 6| Step: 10
Training loss: 0.04576057940721512
Validation loss: 1.4624843828139766

Epoch: 6| Step: 11
Training loss: 0.05970677733421326
Validation loss: 1.4467441317855672

Epoch: 6| Step: 12
Training loss: 0.050774313509464264
Validation loss: 1.425260639959766

Epoch: 6| Step: 13
Training loss: 0.05549823120236397
Validation loss: 1.452579850791603

Epoch: 589| Step: 0
Training loss: 0.11160468310117722
Validation loss: 1.4240415660283898

Epoch: 6| Step: 1
Training loss: 0.051024481654167175
Validation loss: 1.4433079227324455

Epoch: 6| Step: 2
Training loss: 0.0891232118010521
Validation loss: 1.4388164589481969

Epoch: 6| Step: 3
Training loss: 0.06486772000789642
Validation loss: 1.4184261457894438

Epoch: 6| Step: 4
Training loss: 0.07159385830163956
Validation loss: 1.3984532715171896

Epoch: 6| Step: 5
Training loss: 0.04556187614798546
Validation loss: 1.4036336432221115

Epoch: 6| Step: 6
Training loss: 0.04146672040224075
Validation loss: 1.394410059016238

Epoch: 6| Step: 7
Training loss: 0.04505449905991554
Validation loss: 1.4146030320916125

Epoch: 6| Step: 8
Training loss: 0.0650048553943634
Validation loss: 1.4038242101669312

Epoch: 6| Step: 9
Training loss: 0.0602831169962883
Validation loss: 1.4067611578972108

Epoch: 6| Step: 10
Training loss: 0.051453981548547745
Validation loss: 1.4356525328851515

Epoch: 6| Step: 11
Training loss: 0.058010101318359375
Validation loss: 1.3986453574190858

Epoch: 6| Step: 12
Training loss: 0.10023899376392365
Validation loss: 1.4020250433234758

Epoch: 6| Step: 13
Training loss: 0.05939144641160965
Validation loss: 1.4161123838475955

Epoch: 590| Step: 0
Training loss: 0.08244312554597855
Validation loss: 1.4294862196009646

Epoch: 6| Step: 1
Training loss: 0.04848158359527588
Validation loss: 1.4376251556540047

Epoch: 6| Step: 2
Training loss: 0.056866422295570374
Validation loss: 1.4066719829395253

Epoch: 6| Step: 3
Training loss: 0.061801232397556305
Validation loss: 1.4050178938014533

Epoch: 6| Step: 4
Training loss: 0.04926362261176109
Validation loss: 1.4554108842726676

Epoch: 6| Step: 5
Training loss: 0.05266841500997543
Validation loss: 1.4285905309902724

Epoch: 6| Step: 6
Training loss: 0.07888741791248322
Validation loss: 1.4294157617835588

Epoch: 6| Step: 7
Training loss: 0.06444467604160309
Validation loss: 1.4089387924440446

Epoch: 6| Step: 8
Training loss: 0.08886928111314774
Validation loss: 1.4133590998188141

Epoch: 6| Step: 9
Training loss: 0.06374237686395645
Validation loss: 1.4097421515372492

Epoch: 6| Step: 10
Training loss: 0.0809483453631401
Validation loss: 1.40817323230928

Epoch: 6| Step: 11
Training loss: 0.08357523381710052
Validation loss: 1.3929654846909225

Epoch: 6| Step: 12
Training loss: 0.03496076166629791
Validation loss: 1.4299847554135066

Epoch: 6| Step: 13
Training loss: 0.07147397100925446
Validation loss: 1.420999091158631

Epoch: 591| Step: 0
Training loss: 0.06405746191740036
Validation loss: 1.428707980340527

Epoch: 6| Step: 1
Training loss: 0.036797940731048584
Validation loss: 1.400166335926261

Epoch: 6| Step: 2
Training loss: 0.04446793347597122
Validation loss: 1.4361260655105754

Epoch: 6| Step: 3
Training loss: 0.044784680008888245
Validation loss: 1.4385448758320143

Epoch: 6| Step: 4
Training loss: 0.05876990780234337
Validation loss: 1.4432692976408108

Epoch: 6| Step: 5
Training loss: 0.08491525053977966
Validation loss: 1.4510034284284037

Epoch: 6| Step: 6
Training loss: 0.04819711670279503
Validation loss: 1.4535054135066208

Epoch: 6| Step: 7
Training loss: 0.0449281707406044
Validation loss: 1.4615094738621865

Epoch: 6| Step: 8
Training loss: 0.05245667323470116
Validation loss: 1.4309834844322615

Epoch: 6| Step: 9
Training loss: 0.06650813668966293
Validation loss: 1.4287385491914646

Epoch: 6| Step: 10
Training loss: 0.08354828506708145
Validation loss: 1.4470724239144275

Epoch: 6| Step: 11
Training loss: 0.09286445379257202
Validation loss: 1.4698708582949895

Epoch: 6| Step: 12
Training loss: 0.098544642329216
Validation loss: 1.4416784291626306

Epoch: 6| Step: 13
Training loss: 0.040750134736299515
Validation loss: 1.4329287134191042

Epoch: 592| Step: 0
Training loss: 0.054100435227155685
Validation loss: 1.4502118095274894

Epoch: 6| Step: 1
Training loss: 0.03666938841342926
Validation loss: 1.4364580108273415

Epoch: 6| Step: 2
Training loss: 0.07062653452157974
Validation loss: 1.4373885264960669

Epoch: 6| Step: 3
Training loss: 0.07567301392555237
Validation loss: 1.438150792993525

Epoch: 6| Step: 4
Training loss: 0.03473396971821785
Validation loss: 1.4283491590971589

Epoch: 6| Step: 5
Training loss: 0.0673534944653511
Validation loss: 1.4474268248004298

Epoch: 6| Step: 6
Training loss: 0.06769584864377975
Validation loss: 1.443773373480766

Epoch: 6| Step: 7
Training loss: 0.04430267959833145
Validation loss: 1.41956994482266

Epoch: 6| Step: 8
Training loss: 0.06214841455221176
Validation loss: 1.4260870679732291

Epoch: 6| Step: 9
Training loss: 0.08111551403999329
Validation loss: 1.4359397478001092

Epoch: 6| Step: 10
Training loss: 0.06565013527870178
Validation loss: 1.4151348888233144

Epoch: 6| Step: 11
Training loss: 0.10034437477588654
Validation loss: 1.4153765632260231

Epoch: 6| Step: 12
Training loss: 0.049656543880701065
Validation loss: 1.4328272624682354

Epoch: 6| Step: 13
Training loss: 0.06555494666099548
Validation loss: 1.4470250939810148

Epoch: 593| Step: 0
Training loss: 0.0432557687163353
Validation loss: 1.4488303078118192

Epoch: 6| Step: 1
Training loss: 0.05275920778512955
Validation loss: 1.4452956145809543

Epoch: 6| Step: 2
Training loss: 0.08170326799154282
Validation loss: 1.4420065585003103

Epoch: 6| Step: 3
Training loss: 0.08587295562028885
Validation loss: 1.4263353399051133

Epoch: 6| Step: 4
Training loss: 0.09432746469974518
Validation loss: 1.4348013939396027

Epoch: 6| Step: 5
Training loss: 0.04690399765968323
Validation loss: 1.461431771196345

Epoch: 6| Step: 6
Training loss: 0.07119022309780121
Validation loss: 1.4305134973218363

Epoch: 6| Step: 7
Training loss: 0.11811958253383636
Validation loss: 1.4029299789859402

Epoch: 6| Step: 8
Training loss: 0.04849526658654213
Validation loss: 1.4125617037537277

Epoch: 6| Step: 9
Training loss: 0.08913964033126831
Validation loss: 1.4314822253360544

Epoch: 6| Step: 10
Training loss: 0.07609736919403076
Validation loss: 1.4408352362212313

Epoch: 6| Step: 11
Training loss: 0.0707727000117302
Validation loss: 1.4412919154731176

Epoch: 6| Step: 12
Training loss: 0.051214709877967834
Validation loss: 1.4630752340439828

Epoch: 6| Step: 13
Training loss: 0.06494101136922836
Validation loss: 1.4130181125415269

Epoch: 594| Step: 0
Training loss: 0.06549239158630371
Validation loss: 1.41256627087952

Epoch: 6| Step: 1
Training loss: 0.06210406497120857
Validation loss: 1.4216996649260163

Epoch: 6| Step: 2
Training loss: 0.06387414038181305
Validation loss: 1.3902181527947868

Epoch: 6| Step: 3
Training loss: 0.08601779490709305
Validation loss: 1.3930751790282547

Epoch: 6| Step: 4
Training loss: 0.06934207677841187
Validation loss: 1.3751069358600083

Epoch: 6| Step: 5
Training loss: 0.1227700263261795
Validation loss: 1.3958344203169628

Epoch: 6| Step: 6
Training loss: 0.07528897374868393
Validation loss: 1.4073050316943918

Epoch: 6| Step: 7
Training loss: 0.052638813853263855
Validation loss: 1.426576006797052

Epoch: 6| Step: 8
Training loss: 0.07470757514238358
Validation loss: 1.430951258187653

Epoch: 6| Step: 9
Training loss: 0.046758487820625305
Validation loss: 1.4288872877756755

Epoch: 6| Step: 10
Training loss: 0.07334600389003754
Validation loss: 1.4392495462971349

Epoch: 6| Step: 11
Training loss: 0.048256244510412216
Validation loss: 1.4327998481770998

Epoch: 6| Step: 12
Training loss: 0.053829554468393326
Validation loss: 1.450641042763187

Epoch: 6| Step: 13
Training loss: 0.06445688754320145
Validation loss: 1.4509425804179201

Epoch: 595| Step: 0
Training loss: 0.06249124929308891
Validation loss: 1.4288584532276276

Epoch: 6| Step: 1
Training loss: 0.06974601745605469
Validation loss: 1.4393736386811862

Epoch: 6| Step: 2
Training loss: 0.0536198653280735
Validation loss: 1.440438820469764

Epoch: 6| Step: 3
Training loss: 0.0792461708188057
Validation loss: 1.458231443999916

Epoch: 6| Step: 4
Training loss: 0.06126194819808006
Validation loss: 1.4381898231403802

Epoch: 6| Step: 5
Training loss: 0.10522587597370148
Validation loss: 1.4422022450354792

Epoch: 6| Step: 6
Training loss: 0.10966633260250092
Validation loss: 1.4272502801751579

Epoch: 6| Step: 7
Training loss: 0.05946079269051552
Validation loss: 1.4403460115514777

Epoch: 6| Step: 8
Training loss: 0.04682096838951111
Validation loss: 1.4242734870603007

Epoch: 6| Step: 9
Training loss: 0.0778743177652359
Validation loss: 1.43710740663672

Epoch: 6| Step: 10
Training loss: 0.10194417089223862
Validation loss: 1.4274377694693945

Epoch: 6| Step: 11
Training loss: 0.03578373044729233
Validation loss: 1.4433962119522916

Epoch: 6| Step: 12
Training loss: 0.06432841718196869
Validation loss: 1.448752357113746

Epoch: 6| Step: 13
Training loss: 0.04800338298082352
Validation loss: 1.429476764894301

Epoch: 596| Step: 0
Training loss: 0.05921454727649689
Validation loss: 1.4656451248353528

Epoch: 6| Step: 1
Training loss: 0.04897480458021164
Validation loss: 1.4457460077860023

Epoch: 6| Step: 2
Training loss: 0.04125746339559555
Validation loss: 1.432944780395877

Epoch: 6| Step: 3
Training loss: 0.08689933270215988
Validation loss: 1.4341210549877537

Epoch: 6| Step: 4
Training loss: 0.05663295462727547
Validation loss: 1.4400998200139692

Epoch: 6| Step: 5
Training loss: 0.05216200649738312
Validation loss: 1.4385160823022165

Epoch: 6| Step: 6
Training loss: 0.09435666352510452
Validation loss: 1.4370693506733063

Epoch: 6| Step: 7
Training loss: 0.047605566680431366
Validation loss: 1.453931685416929

Epoch: 6| Step: 8
Training loss: 0.0500345304608345
Validation loss: 1.4297814702474942

Epoch: 6| Step: 9
Training loss: 0.05286908149719238
Validation loss: 1.4554697685344244

Epoch: 6| Step: 10
Training loss: 0.029270363971590996
Validation loss: 1.43966721206583

Epoch: 6| Step: 11
Training loss: 0.08315432816743851
Validation loss: 1.4455491919671335

Epoch: 6| Step: 12
Training loss: 0.07034885138273239
Validation loss: 1.4586301093460412

Epoch: 6| Step: 13
Training loss: 0.04923577606678009
Validation loss: 1.4696479138507639

Epoch: 597| Step: 0
Training loss: 0.04170537739992142
Validation loss: 1.447195460719447

Epoch: 6| Step: 1
Training loss: 0.07252979278564453
Validation loss: 1.481976847494802

Epoch: 6| Step: 2
Training loss: 0.06714227795600891
Validation loss: 1.487712476843147

Epoch: 6| Step: 3
Training loss: 0.06345650553703308
Validation loss: 1.448128293919307

Epoch: 6| Step: 4
Training loss: 0.06634470820426941
Validation loss: 1.4394070268959127

Epoch: 6| Step: 5
Training loss: 0.06412090361118317
Validation loss: 1.4851642359969437

Epoch: 6| Step: 6
Training loss: 0.07249601930379868
Validation loss: 1.4917305848931754

Epoch: 6| Step: 7
Training loss: 0.06516793370246887
Validation loss: 1.481185015811715

Epoch: 6| Step: 8
Training loss: 0.09961944818496704
Validation loss: 1.4855313698450725

Epoch: 6| Step: 9
Training loss: 0.0632106363773346
Validation loss: 1.4712911690435102

Epoch: 6| Step: 10
Training loss: 0.09984879195690155
Validation loss: 1.4805024618743567

Epoch: 6| Step: 11
Training loss: 0.09699949622154236
Validation loss: 1.4617141369850404

Epoch: 6| Step: 12
Training loss: 0.05781920999288559
Validation loss: 1.4748185693576772

Epoch: 6| Step: 13
Training loss: 0.09889966994524002
Validation loss: 1.474728064511412

Epoch: 598| Step: 0
Training loss: 0.10270419716835022
Validation loss: 1.4539350098179233

Epoch: 6| Step: 1
Training loss: 0.05705127492547035
Validation loss: 1.469199913804249

Epoch: 6| Step: 2
Training loss: 0.07597661763429642
Validation loss: 1.4899709583610616

Epoch: 6| Step: 3
Training loss: 0.05666062980890274
Validation loss: 1.4623228273084086

Epoch: 6| Step: 4
Training loss: 0.08334533870220184
Validation loss: 1.4966430535880468

Epoch: 6| Step: 5
Training loss: 0.04768168926239014
Validation loss: 1.4480115175247192

Epoch: 6| Step: 6
Training loss: 0.04264625534415245
Validation loss: 1.4502722691464167

Epoch: 6| Step: 7
Training loss: 0.07778162509202957
Validation loss: 1.4573717450582853

Epoch: 6| Step: 8
Training loss: 0.07117625325918198
Validation loss: 1.4467614632780834

Epoch: 6| Step: 9
Training loss: 0.064418263733387
Validation loss: 1.418065865834554

Epoch: 6| Step: 10
Training loss: 0.07149112969636917
Validation loss: 1.432414657326155

Epoch: 6| Step: 11
Training loss: 0.05335231125354767
Validation loss: 1.4264661842776882

Epoch: 6| Step: 12
Training loss: 0.051450714468955994
Validation loss: 1.432916001607013

Epoch: 6| Step: 13
Training loss: 0.04360249266028404
Validation loss: 1.4084267103543846

Epoch: 599| Step: 0
Training loss: 0.06518346816301346
Validation loss: 1.395393269036406

Epoch: 6| Step: 1
Training loss: 0.05666448175907135
Validation loss: 1.4293194381139611

Epoch: 6| Step: 2
Training loss: 0.03855437785387039
Validation loss: 1.4335507212146636

Epoch: 6| Step: 3
Training loss: 0.07984994351863861
Validation loss: 1.398429883423672

Epoch: 6| Step: 4
Training loss: 0.06758905947208405
Validation loss: 1.424399793788951

Epoch: 6| Step: 5
Training loss: 0.04283514618873596
Validation loss: 1.4042291384871288

Epoch: 6| Step: 6
Training loss: 0.0475543811917305
Validation loss: 1.382522632998805

Epoch: 6| Step: 7
Training loss: 0.0880381315946579
Validation loss: 1.4138525493683354

Epoch: 6| Step: 8
Training loss: 0.07558643072843552
Validation loss: 1.3988080832266039

Epoch: 6| Step: 9
Training loss: 0.08125010132789612
Validation loss: 1.3678138973892375

Epoch: 6| Step: 10
Training loss: 0.06815611571073532
Validation loss: 1.4023962347738204

Epoch: 6| Step: 11
Training loss: 0.07118033617734909
Validation loss: 1.3894610443422872

Epoch: 6| Step: 12
Training loss: 0.04366036877036095
Validation loss: 1.3949964033660067

Epoch: 6| Step: 13
Training loss: 0.02964228391647339
Validation loss: 1.3889944200874658

Epoch: 600| Step: 0
Training loss: 0.07126985490322113
Validation loss: 1.4050102990160707

Epoch: 6| Step: 1
Training loss: 0.06420201063156128
Validation loss: 1.4163758306093113

Epoch: 6| Step: 2
Training loss: 0.06739482283592224
Validation loss: 1.436801266926591

Epoch: 6| Step: 3
Training loss: 0.05523548647761345
Validation loss: 1.4133086832620765

Epoch: 6| Step: 4
Training loss: 0.03887620568275452
Validation loss: 1.4136894569602063

Epoch: 6| Step: 5
Training loss: 0.03841765969991684
Validation loss: 1.4499388625544887

Epoch: 6| Step: 6
Training loss: 0.09672247618436813
Validation loss: 1.4347816744158346

Epoch: 6| Step: 7
Training loss: 0.04630117118358612
Validation loss: 1.4106367557279524

Epoch: 6| Step: 8
Training loss: 0.04296058416366577
Validation loss: 1.4269807120805145

Epoch: 6| Step: 9
Training loss: 0.06262124329805374
Validation loss: 1.4264682390356576

Epoch: 6| Step: 10
Training loss: 0.0936504453420639
Validation loss: 1.4480381063235703

Epoch: 6| Step: 11
Training loss: 0.05154605209827423
Validation loss: 1.4304309391206311

Epoch: 6| Step: 12
Training loss: 0.0516379252076149
Validation loss: 1.4115596868658578

Epoch: 6| Step: 13
Training loss: 0.06076814606785774
Validation loss: 1.42116298983174

Epoch: 601| Step: 0
Training loss: 0.06942105293273926
Validation loss: 1.4344273805618286

Epoch: 6| Step: 1
Training loss: 0.06718070805072784
Validation loss: 1.4198898653830252

Epoch: 6| Step: 2
Training loss: 0.10024109482765198
Validation loss: 1.4074703390880297

Epoch: 6| Step: 3
Training loss: 0.09199993312358856
Validation loss: 1.44539217282367

Epoch: 6| Step: 4
Training loss: 0.06296247243881226
Validation loss: 1.3916311904948244

Epoch: 6| Step: 5
Training loss: 0.08517515659332275
Validation loss: 1.3970400838441746

Epoch: 6| Step: 6
Training loss: 0.06297530978918076
Validation loss: 1.3864079713821411

Epoch: 6| Step: 7
Training loss: 0.07857713103294373
Validation loss: 1.4060604264659267

Epoch: 6| Step: 8
Training loss: 0.0787731260061264
Validation loss: 1.3818471585550616

Epoch: 6| Step: 9
Training loss: 0.07317256182432175
Validation loss: 1.4060812252824024

Epoch: 6| Step: 10
Training loss: 0.0633523240685463
Validation loss: 1.3801784130834764

Epoch: 6| Step: 11
Training loss: 0.04735276475548744
Validation loss: 1.3729308100156887

Epoch: 6| Step: 12
Training loss: 0.1181122362613678
Validation loss: 1.383596251087804

Epoch: 6| Step: 13
Training loss: 0.07140764594078064
Validation loss: 1.4066879544206845

Epoch: 602| Step: 0
Training loss: 0.07829122245311737
Validation loss: 1.3961712327054752

Epoch: 6| Step: 1
Training loss: 0.050300709903240204
Validation loss: 1.3849421842123872

Epoch: 6| Step: 2
Training loss: 0.08180249482393265
Validation loss: 1.409233977717738

Epoch: 6| Step: 3
Training loss: 0.06017462909221649
Validation loss: 1.384518305460612

Epoch: 6| Step: 4
Training loss: 0.08720088750123978
Validation loss: 1.4045444829489595

Epoch: 6| Step: 5
Training loss: 0.053998902440071106
Validation loss: 1.383345421924386

Epoch: 6| Step: 6
Training loss: 0.04945303499698639
Validation loss: 1.4104286836039635

Epoch: 6| Step: 7
Training loss: 0.07124972343444824
Validation loss: 1.3901009508358535

Epoch: 6| Step: 8
Training loss: 0.0675334706902504
Validation loss: 1.3969479901816255

Epoch: 6| Step: 9
Training loss: 0.061893075704574585
Validation loss: 1.4081929358102943

Epoch: 6| Step: 10
Training loss: 0.06487398594617844
Validation loss: 1.4005836530398297

Epoch: 6| Step: 11
Training loss: 0.044742338359355927
Validation loss: 1.4009769142314952

Epoch: 6| Step: 12
Training loss: 0.06453371047973633
Validation loss: 1.4263337427569973

Epoch: 6| Step: 13
Training loss: 0.07847484201192856
Validation loss: 1.4015945567879626

Epoch: 603| Step: 0
Training loss: 0.0561441108584404
Validation loss: 1.4256954000842186

Epoch: 6| Step: 1
Training loss: 0.04700363799929619
Validation loss: 1.4181063739202355

Epoch: 6| Step: 2
Training loss: 0.0681447684764862
Validation loss: 1.4040663588431574

Epoch: 6| Step: 3
Training loss: 0.06558044254779816
Validation loss: 1.4346688588460286

Epoch: 6| Step: 4
Training loss: 0.044549450278282166
Validation loss: 1.3829380901910926

Epoch: 6| Step: 5
Training loss: 0.08700180053710938
Validation loss: 1.4074461101203837

Epoch: 6| Step: 6
Training loss: 0.08900672197341919
Validation loss: 1.4182404484800113

Epoch: 6| Step: 7
Training loss: 0.11583826690912247
Validation loss: 1.4048437815840527

Epoch: 6| Step: 8
Training loss: 0.07877349853515625
Validation loss: 1.4330695957265875

Epoch: 6| Step: 9
Training loss: 0.07802917063236237
Validation loss: 1.4272732209133845

Epoch: 6| Step: 10
Training loss: 0.06232807785272598
Validation loss: 1.4315968533997894

Epoch: 6| Step: 11
Training loss: 0.053102098405361176
Validation loss: 1.4049009834566424

Epoch: 6| Step: 12
Training loss: 0.09730172157287598
Validation loss: 1.3905834619716932

Epoch: 6| Step: 13
Training loss: 0.05106600001454353
Validation loss: 1.3759599757450882

Epoch: 604| Step: 0
Training loss: 0.0701492503285408
Validation loss: 1.4156479835510254

Epoch: 6| Step: 1
Training loss: 0.06236616522073746
Validation loss: 1.4128794593195761

Epoch: 6| Step: 2
Training loss: 0.062281131744384766
Validation loss: 1.3945834841779483

Epoch: 6| Step: 3
Training loss: 0.04942445456981659
Validation loss: 1.4016175398262598

Epoch: 6| Step: 4
Training loss: 0.04094505310058594
Validation loss: 1.3955099069943993

Epoch: 6| Step: 5
Training loss: 0.06604263931512833
Validation loss: 1.4028437278603996

Epoch: 6| Step: 6
Training loss: 0.0701659694314003
Validation loss: 1.406140338349086

Epoch: 6| Step: 7
Training loss: 0.08579845726490021
Validation loss: 1.4211026827494304

Epoch: 6| Step: 8
Training loss: 0.055538058280944824
Validation loss: 1.4143113346510037

Epoch: 6| Step: 9
Training loss: 0.07811778038740158
Validation loss: 1.435494610058364

Epoch: 6| Step: 10
Training loss: 0.06552018225193024
Validation loss: 1.4303473849450388

Epoch: 6| Step: 11
Training loss: 0.06486868113279343
Validation loss: 1.4234214777587562

Epoch: 6| Step: 12
Training loss: 0.05579452961683273
Validation loss: 1.4375604045006536

Epoch: 6| Step: 13
Training loss: 0.06743696331977844
Validation loss: 1.439817658034704

Epoch: 605| Step: 0
Training loss: 0.05480823665857315
Validation loss: 1.4411050036389341

Epoch: 6| Step: 1
Training loss: 0.07698611170053482
Validation loss: 1.4360641138527983

Epoch: 6| Step: 2
Training loss: 0.03571617975831032
Validation loss: 1.4428934358781385

Epoch: 6| Step: 3
Training loss: 0.062260422855615616
Validation loss: 1.4538252571577668

Epoch: 6| Step: 4
Training loss: 0.058828216046094894
Validation loss: 1.443012019639374

Epoch: 6| Step: 5
Training loss: 0.038338303565979004
Validation loss: 1.4590800898049467

Epoch: 6| Step: 6
Training loss: 0.051925502717494965
Validation loss: 1.4546345408244798

Epoch: 6| Step: 7
Training loss: 0.04226458817720413
Validation loss: 1.4757932296363256

Epoch: 6| Step: 8
Training loss: 0.07202587276697159
Validation loss: 1.4553897842284171

Epoch: 6| Step: 9
Training loss: 0.08435512334108353
Validation loss: 1.4475898806766798

Epoch: 6| Step: 10
Training loss: 0.03143204003572464
Validation loss: 1.4255335946236887

Epoch: 6| Step: 11
Training loss: 0.04797101020812988
Validation loss: 1.4132645027611845

Epoch: 6| Step: 12
Training loss: 0.03180745989084244
Validation loss: 1.4371199454030683

Epoch: 6| Step: 13
Training loss: 0.06905171275138855
Validation loss: 1.4170697248110207

Epoch: 606| Step: 0
Training loss: 0.0882067009806633
Validation loss: 1.4462265917049941

Epoch: 6| Step: 1
Training loss: 0.052053894847631454
Validation loss: 1.4068195614763486

Epoch: 6| Step: 2
Training loss: 0.0773327425122261
Validation loss: 1.3949304985743698

Epoch: 6| Step: 3
Training loss: 0.04934413358569145
Validation loss: 1.3883909217772945

Epoch: 6| Step: 4
Training loss: 0.06570166349411011
Validation loss: 1.4026309790149811

Epoch: 6| Step: 5
Training loss: 0.05225802958011627
Validation loss: 1.3898576177576536

Epoch: 6| Step: 6
Training loss: 0.11864133179187775
Validation loss: 1.3781596691377702

Epoch: 6| Step: 7
Training loss: 0.048270463943481445
Validation loss: 1.405562485418012

Epoch: 6| Step: 8
Training loss: 0.05343875288963318
Validation loss: 1.3759052189447547

Epoch: 6| Step: 9
Training loss: 0.05731242150068283
Validation loss: 1.382190510149925

Epoch: 6| Step: 10
Training loss: 0.07679714262485504
Validation loss: 1.3895110045709917

Epoch: 6| Step: 11
Training loss: 0.0384378656744957
Validation loss: 1.4025907311388242

Epoch: 6| Step: 12
Training loss: 0.036300066858530045
Validation loss: 1.3806250505549933

Epoch: 6| Step: 13
Training loss: 0.0658101886510849
Validation loss: 1.3974583943684895

Epoch: 607| Step: 0
Training loss: 0.03788021206855774
Validation loss: 1.4190939722522613

Epoch: 6| Step: 1
Training loss: 0.036356352269649506
Validation loss: 1.3999402458949755

Epoch: 6| Step: 2
Training loss: 0.06506278365850449
Validation loss: 1.4072794568154119

Epoch: 6| Step: 3
Training loss: 0.0516253262758255
Validation loss: 1.4117972575208193

Epoch: 6| Step: 4
Training loss: 0.05668182298541069
Validation loss: 1.4162696676869546

Epoch: 6| Step: 5
Training loss: 0.08676043152809143
Validation loss: 1.4490339076647194

Epoch: 6| Step: 6
Training loss: 0.04416845738887787
Validation loss: 1.4471089327207176

Epoch: 6| Step: 7
Training loss: 0.10808753967285156
Validation loss: 1.4245695298717869

Epoch: 6| Step: 8
Training loss: 0.08169320970773697
Validation loss: 1.4536031388467359

Epoch: 6| Step: 9
Training loss: 0.09547629952430725
Validation loss: 1.4259780119824153

Epoch: 6| Step: 10
Training loss: 0.09367555379867554
Validation loss: 1.4158731122170725

Epoch: 6| Step: 11
Training loss: 0.03405935317277908
Validation loss: 1.41469447458944

Epoch: 6| Step: 12
Training loss: 0.04518531262874603
Validation loss: 1.384311842662032

Epoch: 6| Step: 13
Training loss: 0.0476008802652359
Validation loss: 1.4141630344493414

Epoch: 608| Step: 0
Training loss: 0.05842527747154236
Validation loss: 1.411643543551045

Epoch: 6| Step: 1
Training loss: 0.0648760050535202
Validation loss: 1.4029264834619337

Epoch: 6| Step: 2
Training loss: 0.06259333342313766
Validation loss: 1.4060781367363469

Epoch: 6| Step: 3
Training loss: 0.0550881028175354
Validation loss: 1.423360929694227

Epoch: 6| Step: 4
Training loss: 0.057090990245342255
Validation loss: 1.3826289176940918

Epoch: 6| Step: 5
Training loss: 0.054606836289167404
Validation loss: 1.3993671837673392

Epoch: 6| Step: 6
Training loss: 0.0665287971496582
Validation loss: 1.3805114235929263

Epoch: 6| Step: 7
Training loss: 0.077597975730896
Validation loss: 1.377898766148475

Epoch: 6| Step: 8
Training loss: 0.05217696726322174
Validation loss: 1.3816669294911046

Epoch: 6| Step: 9
Training loss: 0.06678920239210129
Validation loss: 1.3907891473462504

Epoch: 6| Step: 10
Training loss: 0.07740124315023422
Validation loss: 1.3667017054814163

Epoch: 6| Step: 11
Training loss: 0.047089241445064545
Validation loss: 1.3885526157194568

Epoch: 6| Step: 12
Training loss: 0.05382022261619568
Validation loss: 1.4051877926754694

Epoch: 6| Step: 13
Training loss: 0.08152566850185394
Validation loss: 1.4388623352973693

Epoch: 609| Step: 0
Training loss: 0.06615395098924637
Validation loss: 1.456621669312959

Epoch: 6| Step: 1
Training loss: 0.07561815530061722
Validation loss: 1.422120346817919

Epoch: 6| Step: 2
Training loss: 0.05893233045935631
Validation loss: 1.4366826870108163

Epoch: 6| Step: 3
Training loss: 0.09370817244052887
Validation loss: 1.43398581909877

Epoch: 6| Step: 4
Training loss: 0.07796904444694519
Validation loss: 1.4444944736778096

Epoch: 6| Step: 5
Training loss: 0.04878321290016174
Validation loss: 1.4513588182387813

Epoch: 6| Step: 6
Training loss: 0.05704838037490845
Validation loss: 1.459046148484753

Epoch: 6| Step: 7
Training loss: 0.07336234301328659
Validation loss: 1.4239692611079062

Epoch: 6| Step: 8
Training loss: 0.04394764080643654
Validation loss: 1.423532949980869

Epoch: 6| Step: 9
Training loss: 0.10770736634731293
Validation loss: 1.4060349669507755

Epoch: 6| Step: 10
Training loss: 0.052383504807949066
Validation loss: 1.3874666562644384

Epoch: 6| Step: 11
Training loss: 0.057028234004974365
Validation loss: 1.4010329528521466

Epoch: 6| Step: 12
Training loss: 0.0683441162109375
Validation loss: 1.379793103664152

Epoch: 6| Step: 13
Training loss: 0.03479455038905144
Validation loss: 1.3896949650138937

Epoch: 610| Step: 0
Training loss: 0.09340323507785797
Validation loss: 1.3647707431547103

Epoch: 6| Step: 1
Training loss: 0.08177213370800018
Validation loss: 1.3796369080902429

Epoch: 6| Step: 2
Training loss: 0.08239145576953888
Validation loss: 1.3723953372688704

Epoch: 6| Step: 3
Training loss: 0.04628145694732666
Validation loss: 1.4144159619526198

Epoch: 6| Step: 4
Training loss: 0.0859624445438385
Validation loss: 1.398435108123287

Epoch: 6| Step: 5
Training loss: 0.0991813987493515
Validation loss: 1.4056485570887083

Epoch: 6| Step: 6
Training loss: 0.049535155296325684
Validation loss: 1.4133172778673069

Epoch: 6| Step: 7
Training loss: 0.04046780243515968
Validation loss: 1.4282600777123564

Epoch: 6| Step: 8
Training loss: 0.03200288116931915
Validation loss: 1.444920321946503

Epoch: 6| Step: 9
Training loss: 0.09194254130125046
Validation loss: 1.4274626944654731

Epoch: 6| Step: 10
Training loss: 0.08384323120117188
Validation loss: 1.4432185567835325

Epoch: 6| Step: 11
Training loss: 0.0860619768500328
Validation loss: 1.465506774122997

Epoch: 6| Step: 12
Training loss: 0.051776282489299774
Validation loss: 1.4602685436125724

Epoch: 6| Step: 13
Training loss: 0.11869554966688156
Validation loss: 1.4211514457579582

Epoch: 611| Step: 0
Training loss: 0.052233777940273285
Validation loss: 1.446499897587684

Epoch: 6| Step: 1
Training loss: 0.08876027166843414
Validation loss: 1.4407860809756863

Epoch: 6| Step: 2
Training loss: 0.08919428288936615
Validation loss: 1.4543328592854161

Epoch: 6| Step: 3
Training loss: 0.10583030432462692
Validation loss: 1.4518487145823817

Epoch: 6| Step: 4
Training loss: 0.09166967123746872
Validation loss: 1.4599069728646228

Epoch: 6| Step: 5
Training loss: 0.06451374292373657
Validation loss: 1.4560046580529982

Epoch: 6| Step: 6
Training loss: 0.09873142093420029
Validation loss: 1.4508947262199976

Epoch: 6| Step: 7
Training loss: 0.06219816207885742
Validation loss: 1.4245258928627096

Epoch: 6| Step: 8
Training loss: 0.04165947064757347
Validation loss: 1.4209343425689205

Epoch: 6| Step: 9
Training loss: 0.040079791098833084
Validation loss: 1.452323229082169

Epoch: 6| Step: 10
Training loss: 0.08315414190292358
Validation loss: 1.4331730104261828

Epoch: 6| Step: 11
Training loss: 0.05735895782709122
Validation loss: 1.4362575315660047

Epoch: 6| Step: 12
Training loss: 0.09666051715612411
Validation loss: 1.4439580684067101

Epoch: 6| Step: 13
Training loss: 0.06611455976963043
Validation loss: 1.419074975034242

Epoch: 612| Step: 0
Training loss: 0.0766170397400856
Validation loss: 1.4342627756057247

Epoch: 6| Step: 1
Training loss: 0.07112038135528564
Validation loss: 1.4089068187180387

Epoch: 6| Step: 2
Training loss: 0.06486082077026367
Validation loss: 1.4185883947598037

Epoch: 6| Step: 3
Training loss: 0.05021088197827339
Validation loss: 1.4386562480721423

Epoch: 6| Step: 4
Training loss: 0.055113475769758224
Validation loss: 1.431838604711717

Epoch: 6| Step: 5
Training loss: 0.08480982482433319
Validation loss: 1.4477300387556835

Epoch: 6| Step: 6
Training loss: 0.0598975270986557
Validation loss: 1.4394068163569256

Epoch: 6| Step: 7
Training loss: 0.0764579325914383
Validation loss: 1.436407632725213

Epoch: 6| Step: 8
Training loss: 0.03925549238920212
Validation loss: 1.4604224351144606

Epoch: 6| Step: 9
Training loss: 0.06473763287067413
Validation loss: 1.4441207737051032

Epoch: 6| Step: 10
Training loss: 0.0673213005065918
Validation loss: 1.4464608584680865

Epoch: 6| Step: 11
Training loss: 0.041941627860069275
Validation loss: 1.449932179143352

Epoch: 6| Step: 12
Training loss: 0.08962062746286392
Validation loss: 1.4615645062538885

Epoch: 6| Step: 13
Training loss: 0.03865501657128334
Validation loss: 1.4322102262127785

Epoch: 613| Step: 0
Training loss: 0.0956287756562233
Validation loss: 1.4605575402577717

Epoch: 6| Step: 1
Training loss: 0.046721313148736954
Validation loss: 1.4635790932563044

Epoch: 6| Step: 2
Training loss: 0.04907406494021416
Validation loss: 1.4885930181831442

Epoch: 6| Step: 3
Training loss: 0.03805767372250557
Validation loss: 1.4826487597598825

Epoch: 6| Step: 4
Training loss: 0.05571405217051506
Validation loss: 1.447008268807524

Epoch: 6| Step: 5
Training loss: 0.03739343583583832
Validation loss: 1.4571007977249801

Epoch: 6| Step: 6
Training loss: 0.07142870128154755
Validation loss: 1.4605107512525333

Epoch: 6| Step: 7
Training loss: 0.07485485821962357
Validation loss: 1.4818094776522728

Epoch: 6| Step: 8
Training loss: 0.060397133231163025
Validation loss: 1.4497975175098707

Epoch: 6| Step: 9
Training loss: 0.07782981544733047
Validation loss: 1.4506076196188569

Epoch: 6| Step: 10
Training loss: 0.0933694988489151
Validation loss: 1.4648078359583372

Epoch: 6| Step: 11
Training loss: 0.03939490020275116
Validation loss: 1.4308085838953655

Epoch: 6| Step: 12
Training loss: 0.060133568942546844
Validation loss: 1.421508514752952

Epoch: 6| Step: 13
Training loss: 0.04553626477718353
Validation loss: 1.4143559099525533

Epoch: 614| Step: 0
Training loss: 0.07007016241550446
Validation loss: 1.4373554491227674

Epoch: 6| Step: 1
Training loss: 0.045570336282253265
Validation loss: 1.4283769662662218

Epoch: 6| Step: 2
Training loss: 0.07144990563392639
Validation loss: 1.4394687696169781

Epoch: 6| Step: 3
Training loss: 0.04180406779050827
Validation loss: 1.4143463052729124

Epoch: 6| Step: 4
Training loss: 0.1184709370136261
Validation loss: 1.42809409095395

Epoch: 6| Step: 5
Training loss: 0.05659861117601395
Validation loss: 1.4175586482529998

Epoch: 6| Step: 6
Training loss: 0.048263415694236755
Validation loss: 1.4486945444537747

Epoch: 6| Step: 7
Training loss: 0.06539762765169144
Validation loss: 1.4349241897624025

Epoch: 6| Step: 8
Training loss: 0.08780886232852936
Validation loss: 1.4729243017012073

Epoch: 6| Step: 9
Training loss: 0.08217630535364151
Validation loss: 1.4718301232143114

Epoch: 6| Step: 10
Training loss: 0.08798742294311523
Validation loss: 1.4642060251646145

Epoch: 6| Step: 11
Training loss: 0.08006250113248825
Validation loss: 1.4653660315339283

Epoch: 6| Step: 12
Training loss: 0.06470382213592529
Validation loss: 1.435627237443001

Epoch: 6| Step: 13
Training loss: 0.07489017397165298
Validation loss: 1.4503398544044905

Epoch: 615| Step: 0
Training loss: 0.04951480031013489
Validation loss: 1.4368703730644719

Epoch: 6| Step: 1
Training loss: 0.09114481508731842
Validation loss: 1.4225078462272562

Epoch: 6| Step: 2
Training loss: 0.03878064453601837
Validation loss: 1.4365027168745637

Epoch: 6| Step: 3
Training loss: 0.085386723279953
Validation loss: 1.4347517285295712

Epoch: 6| Step: 4
Training loss: 0.06008327752351761
Validation loss: 1.4397850151984923

Epoch: 6| Step: 5
Training loss: 0.07148582488298416
Validation loss: 1.4420914983236661

Epoch: 6| Step: 6
Training loss: 0.06612559407949448
Validation loss: 1.429244649987067

Epoch: 6| Step: 7
Training loss: 0.06551328301429749
Validation loss: 1.4023840158216414

Epoch: 6| Step: 8
Training loss: 0.1218104213476181
Validation loss: 1.4354974979995399

Epoch: 6| Step: 9
Training loss: 0.06513272970914841
Validation loss: 1.4067852907283331

Epoch: 6| Step: 10
Training loss: 0.062183529138565063
Validation loss: 1.4172940023483769

Epoch: 6| Step: 11
Training loss: 0.08247144520282745
Validation loss: 1.4455764857671594

Epoch: 6| Step: 12
Training loss: 0.04910743236541748
Validation loss: 1.4362171055168234

Epoch: 6| Step: 13
Training loss: 0.06642527878284454
Validation loss: 1.4231730571357153

Epoch: 616| Step: 0
Training loss: 0.052702464163303375
Validation loss: 1.4557734907314341

Epoch: 6| Step: 1
Training loss: 0.062794990837574
Validation loss: 1.4576177084317772

Epoch: 6| Step: 2
Training loss: 0.1040927916765213
Validation loss: 1.4603878118658578

Epoch: 6| Step: 3
Training loss: 0.06564269959926605
Validation loss: 1.4359820376160324

Epoch: 6| Step: 4
Training loss: 0.08791714906692505
Validation loss: 1.4425027921635618

Epoch: 6| Step: 5
Training loss: 0.06984373182058334
Validation loss: 1.4376135372346448

Epoch: 6| Step: 6
Training loss: 0.05526439845561981
Validation loss: 1.4381845407588507

Epoch: 6| Step: 7
Training loss: 0.046391308307647705
Validation loss: 1.4830986543368267

Epoch: 6| Step: 8
Training loss: 0.11233820021152496
Validation loss: 1.451694183452155

Epoch: 6| Step: 9
Training loss: 0.09580278396606445
Validation loss: 1.4295128506998862

Epoch: 6| Step: 10
Training loss: 0.05183808505535126
Validation loss: 1.4297213400563886

Epoch: 6| Step: 11
Training loss: 0.046543676406145096
Validation loss: 1.4290118730196388

Epoch: 6| Step: 12
Training loss: 0.08244974911212921
Validation loss: 1.4208724325703037

Epoch: 6| Step: 13
Training loss: 0.10230988264083862
Validation loss: 1.4386500286799606

Epoch: 617| Step: 0
Training loss: 0.08735601603984833
Validation loss: 1.4291571288980462

Epoch: 6| Step: 1
Training loss: 0.06582687795162201
Validation loss: 1.4521829184665476

Epoch: 6| Step: 2
Training loss: 0.0590946301817894
Validation loss: 1.4056281043637184

Epoch: 6| Step: 3
Training loss: 0.05604511499404907
Validation loss: 1.426361443534974

Epoch: 6| Step: 4
Training loss: 0.07546043395996094
Validation loss: 1.421710737289921

Epoch: 6| Step: 5
Training loss: 0.05580264329910278
Validation loss: 1.4114859463066183

Epoch: 6| Step: 6
Training loss: 0.09243972599506378
Validation loss: 1.4022641092218378

Epoch: 6| Step: 7
Training loss: 0.04853776469826698
Validation loss: 1.41034722200004

Epoch: 6| Step: 8
Training loss: 0.06947793066501617
Validation loss: 1.4407217899958293

Epoch: 6| Step: 9
Training loss: 0.07346843183040619
Validation loss: 1.459756447422889

Epoch: 6| Step: 10
Training loss: 0.04342188686132431
Validation loss: 1.4351805217804448

Epoch: 6| Step: 11
Training loss: 0.07849635928869247
Validation loss: 1.469968891912891

Epoch: 6| Step: 12
Training loss: 0.04918421059846878
Validation loss: 1.4581036388233144

Epoch: 6| Step: 13
Training loss: 0.07597018033266068
Validation loss: 1.452158494662213

Epoch: 618| Step: 0
Training loss: 0.06524758040904999
Validation loss: 1.4550498172801027

Epoch: 6| Step: 1
Training loss: 0.12106940150260925
Validation loss: 1.4581179349653182

Epoch: 6| Step: 2
Training loss: 0.11756063997745514
Validation loss: 1.4633965620430567

Epoch: 6| Step: 3
Training loss: 0.04587476700544357
Validation loss: 1.473898228778634

Epoch: 6| Step: 4
Training loss: 0.06710325181484222
Validation loss: 1.4695005692461485

Epoch: 6| Step: 5
Training loss: 0.08224602043628693
Validation loss: 1.464425734294358

Epoch: 6| Step: 6
Training loss: 0.06876344978809357
Validation loss: 1.4620612154724777

Epoch: 6| Step: 7
Training loss: 0.08650543540716171
Validation loss: 1.4541868458512008

Epoch: 6| Step: 8
Training loss: 0.07446014881134033
Validation loss: 1.46594040624557

Epoch: 6| Step: 9
Training loss: 0.05125558748841286
Validation loss: 1.4355981811400382

Epoch: 6| Step: 10
Training loss: 0.05475927144289017
Validation loss: 1.4251063908300092

Epoch: 6| Step: 11
Training loss: 0.07532382756471634
Validation loss: 1.438773593594951

Epoch: 6| Step: 12
Training loss: 0.03759630769491196
Validation loss: 1.420277004600853

Epoch: 6| Step: 13
Training loss: 0.013963337987661362
Validation loss: 1.4197712175307735

Epoch: 619| Step: 0
Training loss: 0.053492408245801926
Validation loss: 1.416914661084452

Epoch: 6| Step: 1
Training loss: 0.10725642740726471
Validation loss: 1.421207615124282

Epoch: 6| Step: 2
Training loss: 0.11482356488704681
Validation loss: 1.4121516628931927

Epoch: 6| Step: 3
Training loss: 0.08438566327095032
Validation loss: 1.4260891317039408

Epoch: 6| Step: 4
Training loss: 0.08594495058059692
Validation loss: 1.4086036688538008

Epoch: 6| Step: 5
Training loss: 0.08130945265293121
Validation loss: 1.4035105307896931

Epoch: 6| Step: 6
Training loss: 0.07321470975875854
Validation loss: 1.3890937374484154

Epoch: 6| Step: 7
Training loss: 0.08409836888313293
Validation loss: 1.3663121897687194

Epoch: 6| Step: 8
Training loss: 0.06215089187026024
Validation loss: 1.3972844628877537

Epoch: 6| Step: 9
Training loss: 0.058402881026268005
Validation loss: 1.4053930813266384

Epoch: 6| Step: 10
Training loss: 0.0898943692445755
Validation loss: 1.421758113368865

Epoch: 6| Step: 11
Training loss: 0.07977966964244843
Validation loss: 1.3888527090831468

Epoch: 6| Step: 12
Training loss: 0.06021460145711899
Validation loss: 1.4243456182941314

Epoch: 6| Step: 13
Training loss: 0.046808820217847824
Validation loss: 1.4427408659329979

Epoch: 620| Step: 0
Training loss: 0.05672261863946915
Validation loss: 1.4170937063873454

Epoch: 6| Step: 1
Training loss: 0.06526844203472137
Validation loss: 1.413544443345839

Epoch: 6| Step: 2
Training loss: 0.0959102213382721
Validation loss: 1.4365697214680333

Epoch: 6| Step: 3
Training loss: 0.06081361696124077
Validation loss: 1.442314742713846

Epoch: 6| Step: 4
Training loss: 0.08046218752861023
Validation loss: 1.4531802554284372

Epoch: 6| Step: 5
Training loss: 0.1255376636981964
Validation loss: 1.4902124238270584

Epoch: 6| Step: 6
Training loss: 0.06041226536035538
Validation loss: 1.4949355535609747

Epoch: 6| Step: 7
Training loss: 0.052413955330848694
Validation loss: 1.4987287604680626

Epoch: 6| Step: 8
Training loss: 0.11627678573131561
Validation loss: 1.4545681265092665

Epoch: 6| Step: 9
Training loss: 0.07677902281284332
Validation loss: 1.4644015527540637

Epoch: 6| Step: 10
Training loss: 0.05887536704540253
Validation loss: 1.452146158423475

Epoch: 6| Step: 11
Training loss: 0.11541427671909332
Validation loss: 1.4445433539728965

Epoch: 6| Step: 12
Training loss: 0.06776607036590576
Validation loss: 1.4646696377825994

Epoch: 6| Step: 13
Training loss: 0.08632992953062057
Validation loss: 1.448824393492873

Epoch: 621| Step: 0
Training loss: 0.11643175780773163
Validation loss: 1.4478349237031833

Epoch: 6| Step: 1
Training loss: 0.04650166258215904
Validation loss: 1.445640362719054

Epoch: 6| Step: 2
Training loss: 0.08695946633815765
Validation loss: 1.442968266625558

Epoch: 6| Step: 3
Training loss: 0.0704536885023117
Validation loss: 1.4352645835568827

Epoch: 6| Step: 4
Training loss: 0.045519500970840454
Validation loss: 1.4451611452205206

Epoch: 6| Step: 5
Training loss: 0.03957163542509079
Validation loss: 1.435554148048483

Epoch: 6| Step: 6
Training loss: 0.04190917685627937
Validation loss: 1.4296927426450996

Epoch: 6| Step: 7
Training loss: 0.06940484791994095
Validation loss: 1.4262281399901195

Epoch: 6| Step: 8
Training loss: 0.04316067323088646
Validation loss: 1.441956127843549

Epoch: 6| Step: 9
Training loss: 0.05630321055650711
Validation loss: 1.4638692640489148

Epoch: 6| Step: 10
Training loss: 0.08665205538272858
Validation loss: 1.4228438843962967

Epoch: 6| Step: 11
Training loss: 0.06777266412973404
Validation loss: 1.4514022168292795

Epoch: 6| Step: 12
Training loss: 0.07500667870044708
Validation loss: 1.4213118040433494

Epoch: 6| Step: 13
Training loss: 0.04349570721387863
Validation loss: 1.4280198453575053

Epoch: 622| Step: 0
Training loss: 0.0517389178276062
Validation loss: 1.4317323212982507

Epoch: 6| Step: 1
Training loss: 0.08175568282604218
Validation loss: 1.4149512578082342

Epoch: 6| Step: 2
Training loss: 0.06595192104578018
Validation loss: 1.4426895482565767

Epoch: 6| Step: 3
Training loss: 0.07706278562545776
Validation loss: 1.4255996442610217

Epoch: 6| Step: 4
Training loss: 0.11037598550319672
Validation loss: 1.4462554416348856

Epoch: 6| Step: 5
Training loss: 0.04674335569143295
Validation loss: 1.4375459019855787

Epoch: 6| Step: 6
Training loss: 0.05098514258861542
Validation loss: 1.4447127734461138

Epoch: 6| Step: 7
Training loss: 0.05188484489917755
Validation loss: 1.4305664441918815

Epoch: 6| Step: 8
Training loss: 0.04536489397287369
Validation loss: 1.4718434605547177

Epoch: 6| Step: 9
Training loss: 0.060479626059532166
Validation loss: 1.4830847171045118

Epoch: 6| Step: 10
Training loss: 0.11610642820596695
Validation loss: 1.4626664679537538

Epoch: 6| Step: 11
Training loss: 0.06499135494232178
Validation loss: 1.4725482322836434

Epoch: 6| Step: 12
Training loss: 0.054658398032188416
Validation loss: 1.487994465776669

Epoch: 6| Step: 13
Training loss: 0.0881616398692131
Validation loss: 1.4784474731773458

Epoch: 623| Step: 0
Training loss: 0.07849910110235214
Validation loss: 1.4822426816468597

Epoch: 6| Step: 1
Training loss: 0.0652455985546112
Validation loss: 1.4770221748659689

Epoch: 6| Step: 2
Training loss: 0.07758773118257523
Validation loss: 1.4608113009442565

Epoch: 6| Step: 3
Training loss: 0.0647931694984436
Validation loss: 1.450402170099238

Epoch: 6| Step: 4
Training loss: 0.07106507569551468
Validation loss: 1.4306585416998914

Epoch: 6| Step: 5
Training loss: 0.05862516164779663
Validation loss: 1.453626089198615

Epoch: 6| Step: 6
Training loss: 0.07942453771829605
Validation loss: 1.4281736035500803

Epoch: 6| Step: 7
Training loss: 0.09979736059904099
Validation loss: 1.436876077805796

Epoch: 6| Step: 8
Training loss: 0.07710190117359161
Validation loss: 1.4662692034116356

Epoch: 6| Step: 9
Training loss: 0.06704799830913544
Validation loss: 1.4481240754486413

Epoch: 6| Step: 10
Training loss: 0.05669201537966728
Validation loss: 1.4413780948167205

Epoch: 6| Step: 11
Training loss: 0.0661197230219841
Validation loss: 1.4509341312992958

Epoch: 6| Step: 12
Training loss: 0.06602996587753296
Validation loss: 1.461149460525923

Epoch: 6| Step: 13
Training loss: 0.06238789111375809
Validation loss: 1.4334980967224284

Epoch: 624| Step: 0
Training loss: 0.05921027809381485
Validation loss: 1.432357018993747

Epoch: 6| Step: 1
Training loss: 0.07182234525680542
Validation loss: 1.4356923116150724

Epoch: 6| Step: 2
Training loss: 0.06295791268348694
Validation loss: 1.4638686808206702

Epoch: 6| Step: 3
Training loss: 0.08004440367221832
Validation loss: 1.4510618358530023

Epoch: 6| Step: 4
Training loss: 0.04963066428899765
Validation loss: 1.4705929192163611

Epoch: 6| Step: 5
Training loss: 0.02925165556371212
Validation loss: 1.4718643144894672

Epoch: 6| Step: 6
Training loss: 0.05360373854637146
Validation loss: 1.4543172851685555

Epoch: 6| Step: 7
Training loss: 0.09028881043195724
Validation loss: 1.4888415182790449

Epoch: 6| Step: 8
Training loss: 0.047839097678661346
Validation loss: 1.4389094934668591

Epoch: 6| Step: 9
Training loss: 0.030749864876270294
Validation loss: 1.467218384947828

Epoch: 6| Step: 10
Training loss: 0.046257756650447845
Validation loss: 1.4656925086052186

Epoch: 6| Step: 11
Training loss: 0.037571556866168976
Validation loss: 1.4555560055599417

Epoch: 6| Step: 12
Training loss: 0.058833468705415726
Validation loss: 1.4579239481238908

Epoch: 6| Step: 13
Training loss: 0.06533025950193405
Validation loss: 1.462869821697153

Epoch: 625| Step: 0
Training loss: 0.13980531692504883
Validation loss: 1.427573727023217

Epoch: 6| Step: 1
Training loss: 0.043382856994867325
Validation loss: 1.465913018872661

Epoch: 6| Step: 2
Training loss: 0.049487899988889694
Validation loss: 1.457267253629623

Epoch: 6| Step: 3
Training loss: 0.05628572776913643
Validation loss: 1.4461147298095047

Epoch: 6| Step: 4
Training loss: 0.05865034461021423
Validation loss: 1.4426154064875778

Epoch: 6| Step: 5
Training loss: 0.055572979152202606
Validation loss: 1.4194507778331797

Epoch: 6| Step: 6
Training loss: 0.05813644453883171
Validation loss: 1.4320800304412842

Epoch: 6| Step: 7
Training loss: 0.0817585214972496
Validation loss: 1.4228883635613225

Epoch: 6| Step: 8
Training loss: 0.057709552347660065
Validation loss: 1.4383102411864905

Epoch: 6| Step: 9
Training loss: 0.042058683931827545
Validation loss: 1.4374824852071784

Epoch: 6| Step: 10
Training loss: 0.07265368103981018
Validation loss: 1.4240597627496208

Epoch: 6| Step: 11
Training loss: 0.06187649071216583
Validation loss: 1.4220047291888986

Epoch: 6| Step: 12
Training loss: 0.06752866506576538
Validation loss: 1.4277303423932803

Epoch: 6| Step: 13
Training loss: 0.0953763872385025
Validation loss: 1.427681230729626

Epoch: 626| Step: 0
Training loss: 0.07767558842897415
Validation loss: 1.4501042019936345

Epoch: 6| Step: 1
Training loss: 0.05668717622756958
Validation loss: 1.4327382118471208

Epoch: 6| Step: 2
Training loss: 0.049371957778930664
Validation loss: 1.4451660917651268

Epoch: 6| Step: 3
Training loss: 0.06638122349977493
Validation loss: 1.4556660729069864

Epoch: 6| Step: 4
Training loss: 0.05046732723712921
Validation loss: 1.4442794258876512

Epoch: 6| Step: 5
Training loss: 0.04953695461153984
Validation loss: 1.4490629665313228

Epoch: 6| Step: 6
Training loss: 0.05892180651426315
Validation loss: 1.4255144467917822

Epoch: 6| Step: 7
Training loss: 0.08991708606481552
Validation loss: 1.4415122437220749

Epoch: 6| Step: 8
Training loss: 0.04068592190742493
Validation loss: 1.4398098350853048

Epoch: 6| Step: 9
Training loss: 0.07886412739753723
Validation loss: 1.418390235593242

Epoch: 6| Step: 10
Training loss: 0.07197707891464233
Validation loss: 1.4289393303214863

Epoch: 6| Step: 11
Training loss: 0.06072457507252693
Validation loss: 1.4429036994134226

Epoch: 6| Step: 12
Training loss: 0.06651018559932709
Validation loss: 1.4428457656214315

Epoch: 6| Step: 13
Training loss: 0.07232046127319336
Validation loss: 1.4376253953544043

Epoch: 627| Step: 0
Training loss: 0.07922989875078201
Validation loss: 1.4442492659373949

Epoch: 6| Step: 1
Training loss: 0.048893410712480545
Validation loss: 1.415826109147841

Epoch: 6| Step: 2
Training loss: 0.09542643278837204
Validation loss: 1.4507319145305182

Epoch: 6| Step: 3
Training loss: 0.0523076094686985
Validation loss: 1.4207136079829226

Epoch: 6| Step: 4
Training loss: 0.06556150317192078
Validation loss: 1.431722020590177

Epoch: 6| Step: 5
Training loss: 0.10366320610046387
Validation loss: 1.430227614218189

Epoch: 6| Step: 6
Training loss: 0.0428256057202816
Validation loss: 1.4398403347179454

Epoch: 6| Step: 7
Training loss: 0.044869564473629
Validation loss: 1.4087808196262648

Epoch: 6| Step: 8
Training loss: 0.07616744935512543
Validation loss: 1.4218480093504793

Epoch: 6| Step: 9
Training loss: 0.04582912474870682
Validation loss: 1.3877113019266436

Epoch: 6| Step: 10
Training loss: 0.06783831864595413
Validation loss: 1.4078990374841998

Epoch: 6| Step: 11
Training loss: 0.042380429804325104
Validation loss: 1.3983406315567672

Epoch: 6| Step: 12
Training loss: 0.03489728644490242
Validation loss: 1.3900244761538763

Epoch: 6| Step: 13
Training loss: 0.0489959716796875
Validation loss: 1.39343455337709

Epoch: 628| Step: 0
Training loss: 0.06326237320899963
Validation loss: 1.4103710933398175

Epoch: 6| Step: 1
Training loss: 0.06275438517332077
Validation loss: 1.3937880569888699

Epoch: 6| Step: 2
Training loss: 0.0468108244240284
Validation loss: 1.4095702568689983

Epoch: 6| Step: 3
Training loss: 0.032607950270175934
Validation loss: 1.4253935813903809

Epoch: 6| Step: 4
Training loss: 0.07108387351036072
Validation loss: 1.4093418544338596

Epoch: 6| Step: 5
Training loss: 0.04670733958482742
Validation loss: 1.4123240414486136

Epoch: 6| Step: 6
Training loss: 0.10793440043926239
Validation loss: 1.4216774753344956

Epoch: 6| Step: 7
Training loss: 0.05618967115879059
Validation loss: 1.4412067115947764

Epoch: 6| Step: 8
Training loss: 0.04436981678009033
Validation loss: 1.4298659883519655

Epoch: 6| Step: 9
Training loss: 0.05716359615325928
Validation loss: 1.4227013370042205

Epoch: 6| Step: 10
Training loss: 0.04673813283443451
Validation loss: 1.434766109271716

Epoch: 6| Step: 11
Training loss: 0.050738103687763214
Validation loss: 1.4351335712658462

Epoch: 6| Step: 12
Training loss: 0.056707993149757385
Validation loss: 1.433746249445023

Epoch: 6| Step: 13
Training loss: 0.04809155687689781
Validation loss: 1.4739048666851495

Epoch: 629| Step: 0
Training loss: 0.04614221304655075
Validation loss: 1.454424968329809

Epoch: 6| Step: 1
Training loss: 0.0916222631931305
Validation loss: 1.4476332972126622

Epoch: 6| Step: 2
Training loss: 0.04342138022184372
Validation loss: 1.4322689444788042

Epoch: 6| Step: 3
Training loss: 0.0702306404709816
Validation loss: 1.448768315776702

Epoch: 6| Step: 4
Training loss: 0.07274799048900604
Validation loss: 1.4301681787736955

Epoch: 6| Step: 5
Training loss: 0.06427483260631561
Validation loss: 1.409601798621557

Epoch: 6| Step: 6
Training loss: 0.04298901557922363
Validation loss: 1.4282615453966203

Epoch: 6| Step: 7
Training loss: 0.07038652896881104
Validation loss: 1.4362502662084435

Epoch: 6| Step: 8
Training loss: 0.09265846759080887
Validation loss: 1.4246482618393437

Epoch: 6| Step: 9
Training loss: 0.051036469638347626
Validation loss: 1.4375825876830726

Epoch: 6| Step: 10
Training loss: 0.05071564018726349
Validation loss: 1.4108781090346716

Epoch: 6| Step: 11
Training loss: 0.06942664831876755
Validation loss: 1.4317821943631737

Epoch: 6| Step: 12
Training loss: 0.04462282732129097
Validation loss: 1.4405547213810745

Epoch: 6| Step: 13
Training loss: 0.04187960922718048
Validation loss: 1.4209446714770408

Epoch: 630| Step: 0
Training loss: 0.03818437457084656
Validation loss: 1.4099189824955438

Epoch: 6| Step: 1
Training loss: 0.0485902763903141
Validation loss: 1.4027225817403486

Epoch: 6| Step: 2
Training loss: 0.06977742910385132
Validation loss: 1.4046367445299703

Epoch: 6| Step: 3
Training loss: 0.06421439349651337
Validation loss: 1.4061446433426232

Epoch: 6| Step: 4
Training loss: 0.05643589794635773
Validation loss: 1.400006773010377

Epoch: 6| Step: 5
Training loss: 0.029310699552297592
Validation loss: 1.4219162579505675

Epoch: 6| Step: 6
Training loss: 0.03739180415868759
Validation loss: 1.4124919752920828

Epoch: 6| Step: 7
Training loss: 0.04823925718665123
Validation loss: 1.4300498193310154

Epoch: 6| Step: 8
Training loss: 0.06056971102952957
Validation loss: 1.4222733615547098

Epoch: 6| Step: 9
Training loss: 0.047888994216918945
Validation loss: 1.422992411480155

Epoch: 6| Step: 10
Training loss: 0.05987662822008133
Validation loss: 1.441325984975343

Epoch: 6| Step: 11
Training loss: 0.07282381504774094
Validation loss: 1.4777334056874758

Epoch: 6| Step: 12
Training loss: 0.029967807233333588
Validation loss: 1.4535074727509611

Epoch: 6| Step: 13
Training loss: 0.042514655739068985
Validation loss: 1.4580664660340996

Epoch: 631| Step: 0
Training loss: 0.04582681506872177
Validation loss: 1.4736895779127717

Epoch: 6| Step: 1
Training loss: 0.03886156529188156
Validation loss: 1.4624969920804423

Epoch: 6| Step: 2
Training loss: 0.07909286767244339
Validation loss: 1.4749585710546023

Epoch: 6| Step: 3
Training loss: 0.06372270733118057
Validation loss: 1.4495403048812703

Epoch: 6| Step: 4
Training loss: 0.05121875926852226
Validation loss: 1.4669163303990518

Epoch: 6| Step: 5
Training loss: 0.09605734050273895
Validation loss: 1.4614507690552743

Epoch: 6| Step: 6
Training loss: 0.03979260474443436
Validation loss: 1.4566758922351304

Epoch: 6| Step: 7
Training loss: 0.04163259267807007
Validation loss: 1.4760970043879684

Epoch: 6| Step: 8
Training loss: 0.03584899380803108
Validation loss: 1.4663368207152172

Epoch: 6| Step: 9
Training loss: 0.03917461633682251
Validation loss: 1.4359373354142713

Epoch: 6| Step: 10
Training loss: 0.04208533465862274
Validation loss: 1.4460180741484447

Epoch: 6| Step: 11
Training loss: 0.058096155524253845
Validation loss: 1.4387596691808393

Epoch: 6| Step: 12
Training loss: 0.047942209988832474
Validation loss: 1.45020096020032

Epoch: 6| Step: 13
Training loss: 0.02872561477124691
Validation loss: 1.4363368159981185

Epoch: 632| Step: 0
Training loss: 0.025283057242631912
Validation loss: 1.4428910324650426

Epoch: 6| Step: 1
Training loss: 0.06862901896238327
Validation loss: 1.4602472679589384

Epoch: 6| Step: 2
Training loss: 0.06199058145284653
Validation loss: 1.4284074614124913

Epoch: 6| Step: 3
Training loss: 0.04468663036823273
Validation loss: 1.4468474772668654

Epoch: 6| Step: 4
Training loss: 0.06839682906866074
Validation loss: 1.4137435228593889

Epoch: 6| Step: 5
Training loss: 0.05443897098302841
Validation loss: 1.4195443917346258

Epoch: 6| Step: 6
Training loss: 0.07074424624443054
Validation loss: 1.420391817246714

Epoch: 6| Step: 7
Training loss: 0.07192361354827881
Validation loss: 1.4465327147514588

Epoch: 6| Step: 8
Training loss: 0.03564836084842682
Validation loss: 1.4324024825967767

Epoch: 6| Step: 9
Training loss: 0.10045193135738373
Validation loss: 1.4451990614655197

Epoch: 6| Step: 10
Training loss: 0.07078723609447479
Validation loss: 1.4736646849622008

Epoch: 6| Step: 11
Training loss: 0.0657062754034996
Validation loss: 1.4618769627745434

Epoch: 6| Step: 12
Training loss: 0.041211701929569244
Validation loss: 1.434792418633738

Epoch: 6| Step: 13
Training loss: 0.05446247383952141
Validation loss: 1.4684216476255847

Epoch: 633| Step: 0
Training loss: 0.05996323376893997
Validation loss: 1.4640552702770437

Epoch: 6| Step: 1
Training loss: 0.07490837574005127
Validation loss: 1.4885164499282837

Epoch: 6| Step: 2
Training loss: 0.09277155995368958
Validation loss: 1.4553324766056512

Epoch: 6| Step: 3
Training loss: 0.09614883363246918
Validation loss: 1.465393086915375

Epoch: 6| Step: 4
Training loss: 0.06194036826491356
Validation loss: 1.433373378169152

Epoch: 6| Step: 5
Training loss: 0.06444473564624786
Validation loss: 1.4497701224460398

Epoch: 6| Step: 6
Training loss: 0.0470598042011261
Validation loss: 1.4302507767113306

Epoch: 6| Step: 7
Training loss: 0.04967407137155533
Validation loss: 1.4515709569377284

Epoch: 6| Step: 8
Training loss: 0.07808465510606766
Validation loss: 1.4454339588842084

Epoch: 6| Step: 9
Training loss: 0.08848229795694351
Validation loss: 1.4360326861822477

Epoch: 6| Step: 10
Training loss: 0.06551077216863632
Validation loss: 1.4268849921482865

Epoch: 6| Step: 11
Training loss: 0.06563058495521545
Validation loss: 1.4339650677096458

Epoch: 6| Step: 12
Training loss: 0.04650765657424927
Validation loss: 1.4210737918012886

Epoch: 6| Step: 13
Training loss: 0.09551545232534409
Validation loss: 1.4117733111945532

Epoch: 634| Step: 0
Training loss: 0.07554742693901062
Validation loss: 1.4338576037396666

Epoch: 6| Step: 1
Training loss: 0.05659753829240799
Validation loss: 1.4251944435540067

Epoch: 6| Step: 2
Training loss: 0.11238783597946167
Validation loss: 1.444826816999784

Epoch: 6| Step: 3
Training loss: 0.061767786741256714
Validation loss: 1.4095999438275573

Epoch: 6| Step: 4
Training loss: 0.08633970469236374
Validation loss: 1.429468075434367

Epoch: 6| Step: 5
Training loss: 0.062213826924562454
Validation loss: 1.4148929798474876

Epoch: 6| Step: 6
Training loss: 0.03766241669654846
Validation loss: 1.4161500084784724

Epoch: 6| Step: 7
Training loss: 0.056018389761447906
Validation loss: 1.4306392951678204

Epoch: 6| Step: 8
Training loss: 0.06007283553481102
Validation loss: 1.4043210949949039

Epoch: 6| Step: 9
Training loss: 0.04942090064287186
Validation loss: 1.4113231358989593

Epoch: 6| Step: 10
Training loss: 0.05486797168850899
Validation loss: 1.4088320514207244

Epoch: 6| Step: 11
Training loss: 0.04766344279050827
Validation loss: 1.4432174685180827

Epoch: 6| Step: 12
Training loss: 0.04560186341404915
Validation loss: 1.4220213813166465

Epoch: 6| Step: 13
Training loss: 0.0576203390955925
Validation loss: 1.4356159362741696

Epoch: 635| Step: 0
Training loss: 0.0572955384850502
Validation loss: 1.434592967392296

Epoch: 6| Step: 1
Training loss: 0.08580467104911804
Validation loss: 1.4184374937447168

Epoch: 6| Step: 2
Training loss: 0.05767769366502762
Validation loss: 1.4413457044991114

Epoch: 6| Step: 3
Training loss: 0.0541054904460907
Validation loss: 1.4367958050902172

Epoch: 6| Step: 4
Training loss: 0.036988526582717896
Validation loss: 1.4535019115735126

Epoch: 6| Step: 5
Training loss: 0.05664737522602081
Validation loss: 1.4715796568060433

Epoch: 6| Step: 6
Training loss: 0.06372645497322083
Validation loss: 1.4494656721750896

Epoch: 6| Step: 7
Training loss: 0.07640725374221802
Validation loss: 1.4290986971188617

Epoch: 6| Step: 8
Training loss: 0.06790193915367126
Validation loss: 1.4516080425631614

Epoch: 6| Step: 9
Training loss: 0.041673995554447174
Validation loss: 1.4420361877769552

Epoch: 6| Step: 10
Training loss: 0.048669397830963135
Validation loss: 1.4252437827407674

Epoch: 6| Step: 11
Training loss: 0.0652989000082016
Validation loss: 1.4311659553999543

Epoch: 6| Step: 12
Training loss: 0.06559713929891586
Validation loss: 1.43436631079643

Epoch: 6| Step: 13
Training loss: 0.1067768931388855
Validation loss: 1.4321613465586016

Epoch: 636| Step: 0
Training loss: 0.05656927078962326
Validation loss: 1.4243486722310383

Epoch: 6| Step: 1
Training loss: 0.048779942095279694
Validation loss: 1.446480579273675

Epoch: 6| Step: 2
Training loss: 0.05274977535009384
Validation loss: 1.4611602329438733

Epoch: 6| Step: 3
Training loss: 0.04509098082780838
Validation loss: 1.4515049239640594

Epoch: 6| Step: 4
Training loss: 0.07197969406843185
Validation loss: 1.4290888623524738

Epoch: 6| Step: 5
Training loss: 0.05093534663319588
Validation loss: 1.4626263495414489

Epoch: 6| Step: 6
Training loss: 0.04973690211772919
Validation loss: 1.4736184702124646

Epoch: 6| Step: 7
Training loss: 0.07632634043693542
Validation loss: 1.4473092671363585

Epoch: 6| Step: 8
Training loss: 0.0348137728869915
Validation loss: 1.4533780992672007

Epoch: 6| Step: 9
Training loss: 0.05478399246931076
Validation loss: 1.437868736123526

Epoch: 6| Step: 10
Training loss: 0.04627540335059166
Validation loss: 1.4512398063495595

Epoch: 6| Step: 11
Training loss: 0.06034756451845169
Validation loss: 1.443903825616324

Epoch: 6| Step: 12
Training loss: 0.06429866701364517
Validation loss: 1.443985330161228

Epoch: 6| Step: 13
Training loss: 0.0908767506480217
Validation loss: 1.4335699440330587

Epoch: 637| Step: 0
Training loss: 0.05414629727602005
Validation loss: 1.4291205201097714

Epoch: 6| Step: 1
Training loss: 0.04953327029943466
Validation loss: 1.4312300694886075

Epoch: 6| Step: 2
Training loss: 0.06783309578895569
Validation loss: 1.4273386078496133

Epoch: 6| Step: 3
Training loss: 0.055033355951309204
Validation loss: 1.4457762113181494

Epoch: 6| Step: 4
Training loss: 0.09878505021333694
Validation loss: 1.4227921924283427

Epoch: 6| Step: 5
Training loss: 0.08974431455135345
Validation loss: 1.416230675994709

Epoch: 6| Step: 6
Training loss: 0.06210419163107872
Validation loss: 1.3906696740017142

Epoch: 6| Step: 7
Training loss: 0.04785703495144844
Validation loss: 1.3905251308154034

Epoch: 6| Step: 8
Training loss: 0.049471236765384674
Validation loss: 1.3974302250851867

Epoch: 6| Step: 9
Training loss: 0.06856781244277954
Validation loss: 1.3794404787402

Epoch: 6| Step: 10
Training loss: 0.05946696549654007
Validation loss: 1.408258891874744

Epoch: 6| Step: 11
Training loss: 0.11295358836650848
Validation loss: 1.4211219510724467

Epoch: 6| Step: 12
Training loss: 0.043756842613220215
Validation loss: 1.38238936854947

Epoch: 6| Step: 13
Training loss: 0.05374378710985184
Validation loss: 1.398318552201794

Epoch: 638| Step: 0
Training loss: 0.04962178319692612
Validation loss: 1.401684896920317

Epoch: 6| Step: 1
Training loss: 0.03574269637465477
Validation loss: 1.4077861924325266

Epoch: 6| Step: 2
Training loss: 0.08847182989120483
Validation loss: 1.4166650003002537

Epoch: 6| Step: 3
Training loss: 0.035814084112644196
Validation loss: 1.4289853829209522

Epoch: 6| Step: 4
Training loss: 0.04940592870116234
Validation loss: 1.4145210276367843

Epoch: 6| Step: 5
Training loss: 0.04582761600613594
Validation loss: 1.4037132237547187

Epoch: 6| Step: 6
Training loss: 0.06803858280181885
Validation loss: 1.4089948176055827

Epoch: 6| Step: 7
Training loss: 0.06276937574148178
Validation loss: 1.4126102309073172

Epoch: 6| Step: 8
Training loss: 0.0693441778421402
Validation loss: 1.411901262498671

Epoch: 6| Step: 9
Training loss: 0.06872443854808807
Validation loss: 1.3992051821883007

Epoch: 6| Step: 10
Training loss: 0.03970704972743988
Validation loss: 1.4249115246598438

Epoch: 6| Step: 11
Training loss: 0.05476328730583191
Validation loss: 1.434497280146486

Epoch: 6| Step: 12
Training loss: 0.07868380844593048
Validation loss: 1.4545210215353197

Epoch: 6| Step: 13
Training loss: 0.03392750769853592
Validation loss: 1.4477446976528372

Epoch: 639| Step: 0
Training loss: 0.07064416259527206
Validation loss: 1.4560838963395806

Epoch: 6| Step: 1
Training loss: 0.03707706183195114
Validation loss: 1.4516160462492256

Epoch: 6| Step: 2
Training loss: 0.04468211531639099
Validation loss: 1.4644295220733972

Epoch: 6| Step: 3
Training loss: 0.05033551901578903
Validation loss: 1.4708479290367455

Epoch: 6| Step: 4
Training loss: 0.025925755500793457
Validation loss: 1.4771226003605833

Epoch: 6| Step: 5
Training loss: 0.05837424471974373
Validation loss: 1.4597251671616749

Epoch: 6| Step: 6
Training loss: 0.04543406888842583
Validation loss: 1.4859148994568856

Epoch: 6| Step: 7
Training loss: 0.06438896059989929
Validation loss: 1.4827665449470602

Epoch: 6| Step: 8
Training loss: 0.07873960584402084
Validation loss: 1.478257656097412

Epoch: 6| Step: 9
Training loss: 0.037125375121831894
Validation loss: 1.4824464513409523

Epoch: 6| Step: 10
Training loss: 0.03929609805345535
Validation loss: 1.4813999270880094

Epoch: 6| Step: 11
Training loss: 0.06246200203895569
Validation loss: 1.46226119226025

Epoch: 6| Step: 12
Training loss: 0.05789049714803696
Validation loss: 1.460079627652322

Epoch: 6| Step: 13
Training loss: 0.05091278254985809
Validation loss: 1.4782421153078797

Epoch: 640| Step: 0
Training loss: 0.07078766822814941
Validation loss: 1.4559816519419353

Epoch: 6| Step: 1
Training loss: 0.034388698637485504
Validation loss: 1.4646518999530422

Epoch: 6| Step: 2
Training loss: 0.06958485394716263
Validation loss: 1.4648240855945054

Epoch: 6| Step: 3
Training loss: 0.044261299073696136
Validation loss: 1.4687866433974235

Epoch: 6| Step: 4
Training loss: 0.07318254560232162
Validation loss: 1.4435205075048632

Epoch: 6| Step: 5
Training loss: 0.0736827626824379
Validation loss: 1.4804198306093934

Epoch: 6| Step: 6
Training loss: 0.05418794974684715
Validation loss: 1.4690631999764392

Epoch: 6| Step: 7
Training loss: 0.0438888743519783
Validation loss: 1.4649209668559413

Epoch: 6| Step: 8
Training loss: 0.08102940022945404
Validation loss: 1.4884192892300185

Epoch: 6| Step: 9
Training loss: 0.038442909717559814
Validation loss: 1.490668301941246

Epoch: 6| Step: 10
Training loss: 0.07799868285655975
Validation loss: 1.4753865849587224

Epoch: 6| Step: 11
Training loss: 0.06666629016399384
Validation loss: 1.4916258037731212

Epoch: 6| Step: 12
Training loss: 0.05887845158576965
Validation loss: 1.4827620393486434

Epoch: 6| Step: 13
Training loss: 0.052467864006757736
Validation loss: 1.461126794097244

Epoch: 641| Step: 0
Training loss: 0.05626297369599342
Validation loss: 1.482405303626932

Epoch: 6| Step: 1
Training loss: 0.054303452372550964
Validation loss: 1.459910160751753

Epoch: 6| Step: 2
Training loss: 0.06964138150215149
Validation loss: 1.4889126669976018

Epoch: 6| Step: 3
Training loss: 0.0906604751944542
Validation loss: 1.4786297146992018

Epoch: 6| Step: 4
Training loss: 0.030107932165265083
Validation loss: 1.468891429644759

Epoch: 6| Step: 5
Training loss: 0.052320271730422974
Validation loss: 1.4737103318655362

Epoch: 6| Step: 6
Training loss: 0.03794153034687042
Validation loss: 1.4627683111416396

Epoch: 6| Step: 7
Training loss: 0.055248528718948364
Validation loss: 1.4582034016168246

Epoch: 6| Step: 8
Training loss: 0.03744005784392357
Validation loss: 1.4143925469408754

Epoch: 6| Step: 9
Training loss: 0.06826169788837433
Validation loss: 1.467107448526608

Epoch: 6| Step: 10
Training loss: 0.03306737542152405
Validation loss: 1.4568289761902184

Epoch: 6| Step: 11
Training loss: 0.056511469185352325
Validation loss: 1.436700508158694

Epoch: 6| Step: 12
Training loss: 0.03864680230617523
Validation loss: 1.4459268457146102

Epoch: 6| Step: 13
Training loss: 0.045428317040205
Validation loss: 1.4320526866502659

Epoch: 642| Step: 0
Training loss: 0.07297210395336151
Validation loss: 1.4538452663729269

Epoch: 6| Step: 1
Training loss: 0.03998107463121414
Validation loss: 1.4646568862340783

Epoch: 6| Step: 2
Training loss: 0.046176668256521225
Validation loss: 1.430688637559132

Epoch: 6| Step: 3
Training loss: 0.05664677545428276
Validation loss: 1.4170330519317298

Epoch: 6| Step: 4
Training loss: 0.06601302325725555
Validation loss: 1.415890319373018

Epoch: 6| Step: 5
Training loss: 0.03633789345622063
Validation loss: 1.4169969622806837

Epoch: 6| Step: 6
Training loss: 0.03153890743851662
Validation loss: 1.4187426932396427

Epoch: 6| Step: 7
Training loss: 0.0441134050488472
Validation loss: 1.410423077562804

Epoch: 6| Step: 8
Training loss: 0.054029617458581924
Validation loss: 1.4243374409214142

Epoch: 6| Step: 9
Training loss: 0.0604853630065918
Validation loss: 1.4545110194913802

Epoch: 6| Step: 10
Training loss: 0.0811462476849556
Validation loss: 1.4456537897868822

Epoch: 6| Step: 11
Training loss: 0.05804810672998428
Validation loss: 1.4507546014683221

Epoch: 6| Step: 12
Training loss: 0.04748208820819855
Validation loss: 1.443071690938806

Epoch: 6| Step: 13
Training loss: 0.10051468759775162
Validation loss: 1.441212192017545

Epoch: 643| Step: 0
Training loss: 0.05061773583292961
Validation loss: 1.4367178781058199

Epoch: 6| Step: 1
Training loss: 0.03632810339331627
Validation loss: 1.4623174936540666

Epoch: 6| Step: 2
Training loss: 0.07664529979228973
Validation loss: 1.443372534167382

Epoch: 6| Step: 3
Training loss: 0.04343167319893837
Validation loss: 1.4501006269967684

Epoch: 6| Step: 4
Training loss: 0.06476885080337524
Validation loss: 1.444801947121979

Epoch: 6| Step: 5
Training loss: 0.059878356754779816
Validation loss: 1.4325827007652612

Epoch: 6| Step: 6
Training loss: 0.06826015561819077
Validation loss: 1.4384235335934548

Epoch: 6| Step: 7
Training loss: 0.06346803903579712
Validation loss: 1.442630023084661

Epoch: 6| Step: 8
Training loss: 0.05791174992918968
Validation loss: 1.445593737786816

Epoch: 6| Step: 9
Training loss: 0.05434378236532211
Validation loss: 1.4540272656307425

Epoch: 6| Step: 10
Training loss: 0.04568411409854889
Validation loss: 1.4256512535515653

Epoch: 6| Step: 11
Training loss: 0.05587425082921982
Validation loss: 1.408372107372489

Epoch: 6| Step: 12
Training loss: 0.08727175742387772
Validation loss: 1.4369790695046867

Epoch: 6| Step: 13
Training loss: 0.051755573600530624
Validation loss: 1.4266564999857256

Epoch: 644| Step: 0
Training loss: 0.05368957668542862
Validation loss: 1.454572380229991

Epoch: 6| Step: 1
Training loss: 0.07828469574451447
Validation loss: 1.4476272726571688

Epoch: 6| Step: 2
Training loss: 0.05261129140853882
Validation loss: 1.4498598626864854

Epoch: 6| Step: 3
Training loss: 0.08424288034439087
Validation loss: 1.4223071464928247

Epoch: 6| Step: 4
Training loss: 0.07687888294458389
Validation loss: 1.4338775591183734

Epoch: 6| Step: 5
Training loss: 0.06459265947341919
Validation loss: 1.4356436338475955

Epoch: 6| Step: 6
Training loss: 0.03678303211927414
Validation loss: 1.4395178261623587

Epoch: 6| Step: 7
Training loss: 0.043953925371170044
Validation loss: 1.437726237440622

Epoch: 6| Step: 8
Training loss: 0.07097060978412628
Validation loss: 1.437225608415501

Epoch: 6| Step: 9
Training loss: 0.025783352553844452
Validation loss: 1.443169342574253

Epoch: 6| Step: 10
Training loss: 0.05886899679899216
Validation loss: 1.4359337411901003

Epoch: 6| Step: 11
Training loss: 0.06301718950271606
Validation loss: 1.446351372426556

Epoch: 6| Step: 12
Training loss: 0.07386215031147003
Validation loss: 1.4453310158944899

Epoch: 6| Step: 13
Training loss: 0.06560000777244568
Validation loss: 1.464087176066573

Epoch: 645| Step: 0
Training loss: 0.06327326595783234
Validation loss: 1.4551253363650332

Epoch: 6| Step: 1
Training loss: 0.07868236303329468
Validation loss: 1.4594891020046767

Epoch: 6| Step: 2
Training loss: 0.03784659504890442
Validation loss: 1.4408081769943237

Epoch: 6| Step: 3
Training loss: 0.060031015425920486
Validation loss: 1.4745346153936079

Epoch: 6| Step: 4
Training loss: 0.07363182306289673
Validation loss: 1.434706618708949

Epoch: 6| Step: 5
Training loss: 0.06554368138313293
Validation loss: 1.4738833096719557

Epoch: 6| Step: 6
Training loss: 0.07644835859537125
Validation loss: 1.4570962293173677

Epoch: 6| Step: 7
Training loss: 0.048702601343393326
Validation loss: 1.4535555852356778

Epoch: 6| Step: 8
Training loss: 0.03783342242240906
Validation loss: 1.4557102418714953

Epoch: 6| Step: 9
Training loss: 0.07727506756782532
Validation loss: 1.4566949695669196

Epoch: 6| Step: 10
Training loss: 0.06676200032234192
Validation loss: 1.452419981520663

Epoch: 6| Step: 11
Training loss: 0.04855911433696747
Validation loss: 1.4730739670415078

Epoch: 6| Step: 12
Training loss: 0.04604088142514229
Validation loss: 1.4564006738765265

Epoch: 6| Step: 13
Training loss: 0.03923393785953522
Validation loss: 1.4513538281122844

Epoch: 646| Step: 0
Training loss: 0.04785533621907234
Validation loss: 1.464892541208575

Epoch: 6| Step: 1
Training loss: 0.042256176471710205
Validation loss: 1.4727678580950665

Epoch: 6| Step: 2
Training loss: 0.05668970197439194
Validation loss: 1.4619057114406298

Epoch: 6| Step: 3
Training loss: 0.10281764715909958
Validation loss: 1.4611046711603801

Epoch: 6| Step: 4
Training loss: 0.04781505838036537
Validation loss: 1.4813535155788544

Epoch: 6| Step: 5
Training loss: 0.05008772388100624
Validation loss: 1.4756410173190537

Epoch: 6| Step: 6
Training loss: 0.037850137799978256
Validation loss: 1.4813251354361092

Epoch: 6| Step: 7
Training loss: 0.046963393688201904
Validation loss: 1.4675071489426397

Epoch: 6| Step: 8
Training loss: 0.03190099447965622
Validation loss: 1.4993044996774325

Epoch: 6| Step: 9
Training loss: 0.04786381125450134
Validation loss: 1.468080045074545

Epoch: 6| Step: 10
Training loss: 0.08307698369026184
Validation loss: 1.4627379730183592

Epoch: 6| Step: 11
Training loss: 0.06455079466104507
Validation loss: 1.4982031186421711

Epoch: 6| Step: 12
Training loss: 0.052498139441013336
Validation loss: 1.4841182654903782

Epoch: 6| Step: 13
Training loss: 0.023246189579367638
Validation loss: 1.4610465598362747

Epoch: 647| Step: 0
Training loss: 0.04207419604063034
Validation loss: 1.4848950460392942

Epoch: 6| Step: 1
Training loss: 0.09687766432762146
Validation loss: 1.4611616711462698

Epoch: 6| Step: 2
Training loss: 0.05891811102628708
Validation loss: 1.44472381120087

Epoch: 6| Step: 3
Training loss: 0.04820985347032547
Validation loss: 1.4422831330248105

Epoch: 6| Step: 4
Training loss: 0.047896724194288254
Validation loss: 1.4357351256955055

Epoch: 6| Step: 5
Training loss: 0.044875748455524445
Validation loss: 1.4428521548548052

Epoch: 6| Step: 6
Training loss: 0.045683808624744415
Validation loss: 1.436765714358258

Epoch: 6| Step: 7
Training loss: 0.07532450556755066
Validation loss: 1.4431513611988356

Epoch: 6| Step: 8
Training loss: 0.061240069568157196
Validation loss: 1.4352140503544961

Epoch: 6| Step: 9
Training loss: 0.052334222942590714
Validation loss: 1.4171656626527027

Epoch: 6| Step: 10
Training loss: 0.06797204166650772
Validation loss: 1.4198753372315438

Epoch: 6| Step: 11
Training loss: 0.035786211490631104
Validation loss: 1.4388198826902656

Epoch: 6| Step: 12
Training loss: 0.03768806904554367
Validation loss: 1.4445386907105804

Epoch: 6| Step: 13
Training loss: 0.03943680599331856
Validation loss: 1.4151419567805466

Epoch: 648| Step: 0
Training loss: 0.043877407908439636
Validation loss: 1.452672625100741

Epoch: 6| Step: 1
Training loss: 0.050501711666584015
Validation loss: 1.4205927925725137

Epoch: 6| Step: 2
Training loss: 0.05367698147892952
Validation loss: 1.4345377606730307

Epoch: 6| Step: 3
Training loss: 0.05740250274538994
Validation loss: 1.4083820504526938

Epoch: 6| Step: 4
Training loss: 0.128177672624588
Validation loss: 1.4087491202098068

Epoch: 6| Step: 5
Training loss: 0.06828564405441284
Validation loss: 1.4203989582677041

Epoch: 6| Step: 6
Training loss: 0.0379018560051918
Validation loss: 1.40726843572432

Epoch: 6| Step: 7
Training loss: 0.04332255572080612
Validation loss: 1.42217936951627

Epoch: 6| Step: 8
Training loss: 0.037441693246364594
Validation loss: 1.446396012460032

Epoch: 6| Step: 9
Training loss: 0.030611269176006317
Validation loss: 1.434708672185098

Epoch: 6| Step: 10
Training loss: 0.030138187110424042
Validation loss: 1.458650295452405

Epoch: 6| Step: 11
Training loss: 0.09673674404621124
Validation loss: 1.445514343118155

Epoch: 6| Step: 12
Training loss: 0.08828176558017731
Validation loss: 1.4554406430131646

Epoch: 6| Step: 13
Training loss: 0.06206870079040527
Validation loss: 1.4444948921921432

Epoch: 649| Step: 0
Training loss: 0.0799572765827179
Validation loss: 1.4488641869637273

Epoch: 6| Step: 1
Training loss: 0.038349468261003494
Validation loss: 1.4645158308808521

Epoch: 6| Step: 2
Training loss: 0.0537007674574852
Validation loss: 1.481840496422142

Epoch: 6| Step: 3
Training loss: 0.07342969626188278
Validation loss: 1.4455635906547628

Epoch: 6| Step: 4
Training loss: 0.04720374196767807
Validation loss: 1.4735012246716408

Epoch: 6| Step: 5
Training loss: 0.05122486874461174
Validation loss: 1.4508830065368323

Epoch: 6| Step: 6
Training loss: 0.05079461634159088
Validation loss: 1.4498108010138235

Epoch: 6| Step: 7
Training loss: 0.06426305323839188
Validation loss: 1.4454336115109023

Epoch: 6| Step: 8
Training loss: 0.04966683313250542
Validation loss: 1.4435200857859787

Epoch: 6| Step: 9
Training loss: 0.0920846089720726
Validation loss: 1.468230757662045

Epoch: 6| Step: 10
Training loss: 0.038671717047691345
Validation loss: 1.4291382951121177

Epoch: 6| Step: 11
Training loss: 0.08670832216739655
Validation loss: 1.4301866472408336

Epoch: 6| Step: 12
Training loss: 0.0791797786951065
Validation loss: 1.4251274037104782

Epoch: 6| Step: 13
Training loss: 0.07865039259195328
Validation loss: 1.4268914153498988

Epoch: 650| Step: 0
Training loss: 0.02985963597893715
Validation loss: 1.4365219864794003

Epoch: 6| Step: 1
Training loss: 0.058230116963386536
Validation loss: 1.4573127313326764

Epoch: 6| Step: 2
Training loss: 0.04304488003253937
Validation loss: 1.4225075193630752

Epoch: 6| Step: 3
Training loss: 0.06266742944717407
Validation loss: 1.431290183016049

Epoch: 6| Step: 4
Training loss: 0.045163094997406006
Validation loss: 1.4359174716857173

Epoch: 6| Step: 5
Training loss: 0.05098661780357361
Validation loss: 1.4395623553183772

Epoch: 6| Step: 6
Training loss: 0.06465914100408554
Validation loss: 1.4370307383998748

Epoch: 6| Step: 7
Training loss: 0.0666959285736084
Validation loss: 1.4334212490307388

Epoch: 6| Step: 8
Training loss: 0.07556892931461334
Validation loss: 1.4524593609635548

Epoch: 6| Step: 9
Training loss: 0.04135087877511978
Validation loss: 1.4380265134637074

Epoch: 6| Step: 10
Training loss: 0.04928071051836014
Validation loss: 1.443707735307755

Epoch: 6| Step: 11
Training loss: 0.05496104434132576
Validation loss: 1.4401216212139334

Epoch: 6| Step: 12
Training loss: 0.1021198183298111
Validation loss: 1.4348237501677645

Epoch: 6| Step: 13
Training loss: 0.03857965022325516
Validation loss: 1.4193655649820964

Epoch: 651| Step: 0
Training loss: 0.04464661702513695
Validation loss: 1.4373118364682762

Epoch: 6| Step: 1
Training loss: 0.039269015192985535
Validation loss: 1.4191265811202347

Epoch: 6| Step: 2
Training loss: 0.0778794139623642
Validation loss: 1.426124349717171

Epoch: 6| Step: 3
Training loss: 0.030952639877796173
Validation loss: 1.4456679974832842

Epoch: 6| Step: 4
Training loss: 0.04724720120429993
Validation loss: 1.4312715491940897

Epoch: 6| Step: 5
Training loss: 0.06947749853134155
Validation loss: 1.4497195379708403

Epoch: 6| Step: 6
Training loss: 0.048997633159160614
Validation loss: 1.4608850235580115

Epoch: 6| Step: 7
Training loss: 0.03660709410905838
Validation loss: 1.4708171967537171

Epoch: 6| Step: 8
Training loss: 0.06967435032129288
Validation loss: 1.4367146492004395

Epoch: 6| Step: 9
Training loss: 0.04869571328163147
Validation loss: 1.4570697815187517

Epoch: 6| Step: 10
Training loss: 0.051061782985925674
Validation loss: 1.4511294377747403

Epoch: 6| Step: 11
Training loss: 0.03020506724715233
Validation loss: 1.448336201329385

Epoch: 6| Step: 12
Training loss: 0.06980811059474945
Validation loss: 1.4549660939042286

Epoch: 6| Step: 13
Training loss: 0.05933675542473793
Validation loss: 1.4560169635280487

Epoch: 652| Step: 0
Training loss: 0.08112107217311859
Validation loss: 1.4802771947717155

Epoch: 6| Step: 1
Training loss: 0.06600586324930191
Validation loss: 1.4611336326086393

Epoch: 6| Step: 2
Training loss: 0.048222318291664124
Validation loss: 1.4548896974132908

Epoch: 6| Step: 3
Training loss: 0.05762723833322525
Validation loss: 1.4436793872105178

Epoch: 6| Step: 4
Training loss: 0.04817904531955719
Validation loss: 1.439698964036921

Epoch: 6| Step: 5
Training loss: 0.03314225375652313
Validation loss: 1.4648099599346038

Epoch: 6| Step: 6
Training loss: 0.061590760946273804
Validation loss: 1.4629774042355117

Epoch: 6| Step: 7
Training loss: 0.05252847447991371
Validation loss: 1.4179271921034782

Epoch: 6| Step: 8
Training loss: 0.069834403693676
Validation loss: 1.4265534582958426

Epoch: 6| Step: 9
Training loss: 0.038715094327926636
Validation loss: 1.4104897540102723

Epoch: 6| Step: 10
Training loss: 0.054197121411561966
Validation loss: 1.4449076126980525

Epoch: 6| Step: 11
Training loss: 0.06520821154117584
Validation loss: 1.3976748220382198

Epoch: 6| Step: 12
Training loss: 0.06281360983848572
Validation loss: 1.4070955514907837

Epoch: 6| Step: 13
Training loss: 0.0246118176728487
Validation loss: 1.4020148374701058

Epoch: 653| Step: 0
Training loss: 0.05317732319235802
Validation loss: 1.4148526063529394

Epoch: 6| Step: 1
Training loss: 0.06644081324338913
Validation loss: 1.406394479095295

Epoch: 6| Step: 2
Training loss: 0.05559026449918747
Validation loss: 1.4009806802195888

Epoch: 6| Step: 3
Training loss: 0.048462845385074615
Validation loss: 1.40462613362138

Epoch: 6| Step: 4
Training loss: 0.07041754573583603
Validation loss: 1.4013708977289097

Epoch: 6| Step: 5
Training loss: 0.09139278531074524
Validation loss: 1.4218357519436908

Epoch: 6| Step: 6
Training loss: 0.0419515036046505
Validation loss: 1.4050887489831576

Epoch: 6| Step: 7
Training loss: 0.06180407106876373
Validation loss: 1.3928879948072537

Epoch: 6| Step: 8
Training loss: 0.05155379697680473
Validation loss: 1.4369640068341327

Epoch: 6| Step: 9
Training loss: 0.07597121596336365
Validation loss: 1.4078639604712044

Epoch: 6| Step: 10
Training loss: 0.059352245181798935
Validation loss: 1.4356707783155545

Epoch: 6| Step: 11
Training loss: 0.03252149373292923
Validation loss: 1.430318364533045

Epoch: 6| Step: 12
Training loss: 0.03778982535004616
Validation loss: 1.4077608687903291

Epoch: 6| Step: 13
Training loss: 0.12906695902347565
Validation loss: 1.4387166718001008

Epoch: 654| Step: 0
Training loss: 0.04666145518422127
Validation loss: 1.4331816633542378

Epoch: 6| Step: 1
Training loss: 0.04555539786815643
Validation loss: 1.4243062734603882

Epoch: 6| Step: 2
Training loss: 0.05151120573282242
Validation loss: 1.4350677562016312

Epoch: 6| Step: 3
Training loss: 0.07111284881830215
Validation loss: 1.4233951312239452

Epoch: 6| Step: 4
Training loss: 0.04612286388874054
Validation loss: 1.4419795697735203

Epoch: 6| Step: 5
Training loss: 0.04233105480670929
Validation loss: 1.4246475062062662

Epoch: 6| Step: 6
Training loss: 0.04459642246365547
Validation loss: 1.4571917903038762

Epoch: 6| Step: 7
Training loss: 0.04573417827486992
Validation loss: 1.456064340888813

Epoch: 6| Step: 8
Training loss: 0.056655142456293106
Validation loss: 1.4458370131831015

Epoch: 6| Step: 9
Training loss: 0.04830382764339447
Validation loss: 1.477864666651654

Epoch: 6| Step: 10
Training loss: 0.04340667277574539
Validation loss: 1.4267792310765994

Epoch: 6| Step: 11
Training loss: 0.07799239456653595
Validation loss: 1.4334102151214436

Epoch: 6| Step: 12
Training loss: 0.06224743276834488
Validation loss: 1.4412042902361961

Epoch: 6| Step: 13
Training loss: 0.03158935531973839
Validation loss: 1.4540249186177407

Epoch: 655| Step: 0
Training loss: 0.05174427479505539
Validation loss: 1.4387499055554789

Epoch: 6| Step: 1
Training loss: 0.06543456763029099
Validation loss: 1.456252601838881

Epoch: 6| Step: 2
Training loss: 0.07099254429340363
Validation loss: 1.4391888456959878

Epoch: 6| Step: 3
Training loss: 0.048214688897132874
Validation loss: 1.4692025710177679

Epoch: 6| Step: 4
Training loss: 0.04804382845759392
Validation loss: 1.4607733475264681

Epoch: 6| Step: 5
Training loss: 0.06771919131278992
Validation loss: 1.4928844846704954

Epoch: 6| Step: 6
Training loss: 0.03589577227830887
Validation loss: 1.4650821531972578

Epoch: 6| Step: 7
Training loss: 0.04856886714696884
Validation loss: 1.4869467314853464

Epoch: 6| Step: 8
Training loss: 0.03702412545681
Validation loss: 1.4608525024947299

Epoch: 6| Step: 9
Training loss: 0.06724153459072113
Validation loss: 1.4669801471053914

Epoch: 6| Step: 10
Training loss: 0.06830543279647827
Validation loss: 1.4887024433382097

Epoch: 6| Step: 11
Training loss: 0.08049352467060089
Validation loss: 1.4837689790674435

Epoch: 6| Step: 12
Training loss: 0.07051010429859161
Validation loss: 1.4652719856590353

Epoch: 6| Step: 13
Training loss: 0.04374367743730545
Validation loss: 1.4704831338697864

Epoch: 656| Step: 0
Training loss: 0.04553673043847084
Validation loss: 1.4617842551200622

Epoch: 6| Step: 1
Training loss: 0.024942874908447266
Validation loss: 1.4542723394209338

Epoch: 6| Step: 2
Training loss: 0.06931255012750626
Validation loss: 1.4607448718881095

Epoch: 6| Step: 3
Training loss: 0.07197041809558868
Validation loss: 1.4431763797677972

Epoch: 6| Step: 4
Training loss: 0.06318803876638412
Validation loss: 1.4365158100281992

Epoch: 6| Step: 5
Training loss: 0.06096819415688515
Validation loss: 1.4325541962859452

Epoch: 6| Step: 6
Training loss: 0.05892542749643326
Validation loss: 1.4532022232650428

Epoch: 6| Step: 7
Training loss: 0.040177635848522186
Validation loss: 1.462936253957851

Epoch: 6| Step: 8
Training loss: 0.09044654667377472
Validation loss: 1.4651207385524627

Epoch: 6| Step: 9
Training loss: 0.03608238697052002
Validation loss: 1.4555094101095711

Epoch: 6| Step: 10
Training loss: 0.04422387108206749
Validation loss: 1.4625094641921341

Epoch: 6| Step: 11
Training loss: 0.04564402252435684
Validation loss: 1.4236411945794218

Epoch: 6| Step: 12
Training loss: 0.07273903489112854
Validation loss: 1.4349677613986436

Epoch: 6| Step: 13
Training loss: 0.03151196986436844
Validation loss: 1.414195328630427

Epoch: 657| Step: 0
Training loss: 0.03941274434328079
Validation loss: 1.4053084094037291

Epoch: 6| Step: 1
Training loss: 0.05602215230464935
Validation loss: 1.4223674702387985

Epoch: 6| Step: 2
Training loss: 0.06250215321779251
Validation loss: 1.4400631484164987

Epoch: 6| Step: 3
Training loss: 0.04425052925944328
Validation loss: 1.4367622758752556

Epoch: 6| Step: 4
Training loss: 0.03701677918434143
Validation loss: 1.4192541965874292

Epoch: 6| Step: 5
Training loss: 0.05482711270451546
Validation loss: 1.429680593552128

Epoch: 6| Step: 6
Training loss: 0.046757958829402924
Validation loss: 1.4317955637490878

Epoch: 6| Step: 7
Training loss: 0.05601564422249794
Validation loss: 1.441974853956571

Epoch: 6| Step: 8
Training loss: 0.07625927776098251
Validation loss: 1.471663768573474

Epoch: 6| Step: 9
Training loss: 0.12998080253601074
Validation loss: 1.4624009452840334

Epoch: 6| Step: 10
Training loss: 0.04308180510997772
Validation loss: 1.439620856315859

Epoch: 6| Step: 11
Training loss: 0.056798145174980164
Validation loss: 1.448813074378557

Epoch: 6| Step: 12
Training loss: 0.08557125180959702
Validation loss: 1.4626967150677916

Epoch: 6| Step: 13
Training loss: 0.06397983431816101
Validation loss: 1.4843409753614856

Epoch: 658| Step: 0
Training loss: 0.032965414226055145
Validation loss: 1.4471502650168635

Epoch: 6| Step: 1
Training loss: 0.05311428755521774
Validation loss: 1.4627732307680192

Epoch: 6| Step: 2
Training loss: 0.04532429575920105
Validation loss: 1.4706607890385452

Epoch: 6| Step: 3
Training loss: 0.06215052306652069
Validation loss: 1.4529817783704368

Epoch: 6| Step: 4
Training loss: 0.046275295317173004
Validation loss: 1.4579441047483874

Epoch: 6| Step: 5
Training loss: 0.04788877069950104
Validation loss: 1.440714620774792

Epoch: 6| Step: 6
Training loss: 0.04745906963944435
Validation loss: 1.463282819076251

Epoch: 6| Step: 7
Training loss: 0.06683617830276489
Validation loss: 1.44439358352333

Epoch: 6| Step: 8
Training loss: 0.06957229971885681
Validation loss: 1.440541918559741

Epoch: 6| Step: 9
Training loss: 0.08446849882602692
Validation loss: 1.466107588942333

Epoch: 6| Step: 10
Training loss: 0.08250491321086884
Validation loss: 1.4584660254498965

Epoch: 6| Step: 11
Training loss: 0.07252638041973114
Validation loss: 1.4553313332219278

Epoch: 6| Step: 12
Training loss: 0.0548492893576622
Validation loss: 1.4487706153623519

Epoch: 6| Step: 13
Training loss: 0.0901591032743454
Validation loss: 1.4641830421263171

Epoch: 659| Step: 0
Training loss: 0.048432499170303345
Validation loss: 1.4930266032936752

Epoch: 6| Step: 1
Training loss: 0.03806384652853012
Validation loss: 1.473601015665198

Epoch: 6| Step: 2
Training loss: 0.05444681644439697
Validation loss: 1.4683998477074407

Epoch: 6| Step: 3
Training loss: 0.06298227608203888
Validation loss: 1.4780428153212353

Epoch: 6| Step: 4
Training loss: 0.08035881817340851
Validation loss: 1.4561160328567668

Epoch: 6| Step: 5
Training loss: 0.04693994298577309
Validation loss: 1.4234034169104792

Epoch: 6| Step: 6
Training loss: 0.026663919910788536
Validation loss: 1.4754412712589386

Epoch: 6| Step: 7
Training loss: 0.047884501516819
Validation loss: 1.4514062968633508

Epoch: 6| Step: 8
Training loss: 0.05254942178726196
Validation loss: 1.4280372024864278

Epoch: 6| Step: 9
Training loss: 0.039586398750543594
Validation loss: 1.443644331988468

Epoch: 6| Step: 10
Training loss: 0.07536324113607407
Validation loss: 1.4447336645536526

Epoch: 6| Step: 11
Training loss: 0.039592623710632324
Validation loss: 1.4426869820523005

Epoch: 6| Step: 12
Training loss: 0.08749829232692719
Validation loss: 1.4807187895621023

Epoch: 6| Step: 13
Training loss: 0.0747738778591156
Validation loss: 1.4824744847513014

Epoch: 660| Step: 0
Training loss: 0.049685463309288025
Validation loss: 1.4983736391990417

Epoch: 6| Step: 1
Training loss: 0.05160889774560928
Validation loss: 1.491232895082043

Epoch: 6| Step: 2
Training loss: 0.07509709894657135
Validation loss: 1.4903773184745543

Epoch: 6| Step: 3
Training loss: 0.047553062438964844
Validation loss: 1.51438489267903

Epoch: 6| Step: 4
Training loss: 0.05019991099834442
Validation loss: 1.5037300407245595

Epoch: 6| Step: 5
Training loss: 0.06903053820133209
Validation loss: 1.5031738422250236

Epoch: 6| Step: 6
Training loss: 0.054208576679229736
Validation loss: 1.509658428930467

Epoch: 6| Step: 7
Training loss: 0.035141270607709885
Validation loss: 1.5094389389919978

Epoch: 6| Step: 8
Training loss: 0.045593105256557465
Validation loss: 1.50537674145032

Epoch: 6| Step: 9
Training loss: 0.05276753380894661
Validation loss: 1.5070374114539034

Epoch: 6| Step: 10
Training loss: 0.08402220904827118
Validation loss: 1.4907570039072344

Epoch: 6| Step: 11
Training loss: 0.06350842118263245
Validation loss: 1.4769820077444917

Epoch: 6| Step: 12
Training loss: 0.05883289873600006
Validation loss: 1.4791422467077933

Epoch: 6| Step: 13
Training loss: 0.09220779687166214
Validation loss: 1.468556108013276

Epoch: 661| Step: 0
Training loss: 0.030637618154287338
Validation loss: 1.4668933973517468

Epoch: 6| Step: 1
Training loss: 0.035912007093429565
Validation loss: 1.487374145497558

Epoch: 6| Step: 2
Training loss: 0.05347215756773949
Validation loss: 1.4475921841077908

Epoch: 6| Step: 3
Training loss: 0.07228703796863556
Validation loss: 1.4659789287915794

Epoch: 6| Step: 4
Training loss: 0.08222667872905731
Validation loss: 1.435350090585729

Epoch: 6| Step: 5
Training loss: 0.030251383781433105
Validation loss: 1.4607452948888142

Epoch: 6| Step: 6
Training loss: 0.05804182216525078
Validation loss: 1.4619063600417106

Epoch: 6| Step: 7
Training loss: 0.051419392228126526
Validation loss: 1.4669811071888093

Epoch: 6| Step: 8
Training loss: 0.07179825752973557
Validation loss: 1.4481307844961844

Epoch: 6| Step: 9
Training loss: 0.042883407324552536
Validation loss: 1.4701531881927161

Epoch: 6| Step: 10
Training loss: 0.06919033825397491
Validation loss: 1.4803159582999446

Epoch: 6| Step: 11
Training loss: 0.03899051621556282
Validation loss: 1.4599180426648868

Epoch: 6| Step: 12
Training loss: 0.04378487169742584
Validation loss: 1.4736285030200917

Epoch: 6| Step: 13
Training loss: 0.1495688259601593
Validation loss: 1.4812459163768317

Epoch: 662| Step: 0
Training loss: 0.08032652735710144
Validation loss: 1.4700551417566114

Epoch: 6| Step: 1
Training loss: 0.03447999060153961
Validation loss: 1.4744202013938659

Epoch: 6| Step: 2
Training loss: 0.05995303392410278
Validation loss: 1.4496555110459686

Epoch: 6| Step: 3
Training loss: 0.05050291866064072
Validation loss: 1.4576287846411429

Epoch: 6| Step: 4
Training loss: 0.04249837249517441
Validation loss: 1.4598679465632285

Epoch: 6| Step: 5
Training loss: 0.047961458563804626
Validation loss: 1.4756969559577204

Epoch: 6| Step: 6
Training loss: 0.07138697057962418
Validation loss: 1.4644260509039766

Epoch: 6| Step: 7
Training loss: 0.037144117057323456
Validation loss: 1.4414649855705999

Epoch: 6| Step: 8
Training loss: 0.05267558619379997
Validation loss: 1.4691498010389266

Epoch: 6| Step: 9
Training loss: 0.05100364610552788
Validation loss: 1.4712702561450262

Epoch: 6| Step: 10
Training loss: 0.053876906633377075
Validation loss: 1.4522272361222135

Epoch: 6| Step: 11
Training loss: 0.0421534962952137
Validation loss: 1.4566911048786615

Epoch: 6| Step: 12
Training loss: 0.1013069674372673
Validation loss: 1.4683376922402331

Epoch: 6| Step: 13
Training loss: 0.04779089242219925
Validation loss: 1.464950374377671

Epoch: 663| Step: 0
Training loss: 0.10690344870090485
Validation loss: 1.4589676190448064

Epoch: 6| Step: 1
Training loss: 0.05904923379421234
Validation loss: 1.4903687033601987

Epoch: 6| Step: 2
Training loss: 0.04247559979557991
Validation loss: 1.488737198614305

Epoch: 6| Step: 3
Training loss: 0.03840436786413193
Validation loss: 1.49083242236927

Epoch: 6| Step: 4
Training loss: 0.07985153794288635
Validation loss: 1.4890805252136723

Epoch: 6| Step: 5
Training loss: 0.07285171747207642
Validation loss: 1.465905383069028

Epoch: 6| Step: 6
Training loss: 0.03844945877790451
Validation loss: 1.43441899489331

Epoch: 6| Step: 7
Training loss: 0.04917777329683304
Validation loss: 1.4240030550187635

Epoch: 6| Step: 8
Training loss: 0.06524975597858429
Validation loss: 1.4356760299333962

Epoch: 6| Step: 9
Training loss: 0.061885617673397064
Validation loss: 1.4478602627272248

Epoch: 6| Step: 10
Training loss: 0.05571962147951126
Validation loss: 1.4378939636291996

Epoch: 6| Step: 11
Training loss: 0.03977210447192192
Validation loss: 1.4102551257738503

Epoch: 6| Step: 12
Training loss: 0.07562708854675293
Validation loss: 1.450163866883965

Epoch: 6| Step: 13
Training loss: 0.05398168787360191
Validation loss: 1.4395003100877166

Epoch: 664| Step: 0
Training loss: 0.05331949144601822
Validation loss: 1.4308733952942716

Epoch: 6| Step: 1
Training loss: 0.07478001713752747
Validation loss: 1.432666536300413

Epoch: 6| Step: 2
Training loss: 0.0374576598405838
Validation loss: 1.4158180272707375

Epoch: 6| Step: 3
Training loss: 0.0715789720416069
Validation loss: 1.4320626745941818

Epoch: 6| Step: 4
Training loss: 0.038610827177762985
Validation loss: 1.4582601272931663

Epoch: 6| Step: 5
Training loss: 0.09372401982545853
Validation loss: 1.4425963291557886

Epoch: 6| Step: 6
Training loss: 0.024709103628993034
Validation loss: 1.4185817933851672

Epoch: 6| Step: 7
Training loss: 0.08814871311187744
Validation loss: 1.4325745016015985

Epoch: 6| Step: 8
Training loss: 0.03422904759645462
Validation loss: 1.4305021019392117

Epoch: 6| Step: 9
Training loss: 0.04414026811718941
Validation loss: 1.4377587021038096

Epoch: 6| Step: 10
Training loss: 0.04256477952003479
Validation loss: 1.437873859559336

Epoch: 6| Step: 11
Training loss: 0.06935767829418182
Validation loss: 1.4593750148691156

Epoch: 6| Step: 12
Training loss: 0.062457989901304245
Validation loss: 1.4482505962412844

Epoch: 6| Step: 13
Training loss: 0.03965755179524422
Validation loss: 1.4604316796025922

Epoch: 665| Step: 0
Training loss: 0.05713203176856041
Validation loss: 1.451444524590687

Epoch: 6| Step: 1
Training loss: 0.034812092781066895
Validation loss: 1.4322987218056955

Epoch: 6| Step: 2
Training loss: 0.052282437682151794
Validation loss: 1.4396348204664005

Epoch: 6| Step: 3
Training loss: 0.03378516808152199
Validation loss: 1.4579207589549403

Epoch: 6| Step: 4
Training loss: 0.04123792424798012
Validation loss: 1.4334207388662523

Epoch: 6| Step: 5
Training loss: 0.0731273740530014
Validation loss: 1.4572700172342279

Epoch: 6| Step: 6
Training loss: 0.06126779317855835
Validation loss: 1.4331248460277435

Epoch: 6| Step: 7
Training loss: 0.06018538400530815
Validation loss: 1.437507083339076

Epoch: 6| Step: 8
Training loss: 0.04819171875715256
Validation loss: 1.4065417064133512

Epoch: 6| Step: 9
Training loss: 0.0435161367058754
Validation loss: 1.3898821799985823

Epoch: 6| Step: 10
Training loss: 0.08971542865037918
Validation loss: 1.3941347816938996

Epoch: 6| Step: 11
Training loss: 0.06294029206037521
Validation loss: 1.4280492785156413

Epoch: 6| Step: 12
Training loss: 0.04458947479724884
Validation loss: 1.4087576058603102

Epoch: 6| Step: 13
Training loss: 0.04184651002287865
Validation loss: 1.4184517450230096

Epoch: 666| Step: 0
Training loss: 0.04664498567581177
Validation loss: 1.417451447697096

Epoch: 6| Step: 1
Training loss: 0.05550001561641693
Validation loss: 1.4257285671849405

Epoch: 6| Step: 2
Training loss: 0.04108251631259918
Validation loss: 1.4263621228997425

Epoch: 6| Step: 3
Training loss: 0.04602153226733208
Validation loss: 1.4116743841478903

Epoch: 6| Step: 4
Training loss: 0.06907516717910767
Validation loss: 1.4081191221872966

Epoch: 6| Step: 5
Training loss: 0.07579103112220764
Validation loss: 1.3967373396760674

Epoch: 6| Step: 6
Training loss: 0.06391829252243042
Validation loss: 1.4076706606854674

Epoch: 6| Step: 7
Training loss: 0.05828658118844032
Validation loss: 1.4075267789184407

Epoch: 6| Step: 8
Training loss: 0.05430380627512932
Validation loss: 1.3815663732508177

Epoch: 6| Step: 9
Training loss: 0.07194280624389648
Validation loss: 1.3987016344583163

Epoch: 6| Step: 10
Training loss: 0.07009945809841156
Validation loss: 1.3953160611532067

Epoch: 6| Step: 11
Training loss: 0.07178084552288055
Validation loss: 1.4174983200206552

Epoch: 6| Step: 12
Training loss: 0.037443578243255615
Validation loss: 1.417408324057056

Epoch: 6| Step: 13
Training loss: 0.05057172104716301
Validation loss: 1.400037338656764

Epoch: 667| Step: 0
Training loss: 0.04910070449113846
Validation loss: 1.3872694956359042

Epoch: 6| Step: 1
Training loss: 0.025323953479528427
Validation loss: 1.3724761111761934

Epoch: 6| Step: 2
Training loss: 0.04350336268544197
Validation loss: 1.4107178923904256

Epoch: 6| Step: 3
Training loss: 0.05937260389328003
Validation loss: 1.4188369768922047

Epoch: 6| Step: 4
Training loss: 0.06428919732570648
Validation loss: 1.4287745491150887

Epoch: 6| Step: 5
Training loss: 0.03754691779613495
Validation loss: 1.4299238644620424

Epoch: 6| Step: 6
Training loss: 0.06051257252693176
Validation loss: 1.4281007679559852

Epoch: 6| Step: 7
Training loss: 0.030743533745408058
Validation loss: 1.4184891511035222

Epoch: 6| Step: 8
Training loss: 0.05612869933247566
Validation loss: 1.4132416863595285

Epoch: 6| Step: 9
Training loss: 0.054554231464862823
Validation loss: 1.379082460557261

Epoch: 6| Step: 10
Training loss: 0.05168711394071579
Validation loss: 1.4064300649909562

Epoch: 6| Step: 11
Training loss: 0.06643649190664291
Validation loss: 1.4308500982099963

Epoch: 6| Step: 12
Training loss: 0.07171319425106049
Validation loss: 1.435292213193832

Epoch: 6| Step: 13
Training loss: 0.10456395149230957
Validation loss: 1.4153424578328286

Epoch: 668| Step: 0
Training loss: 0.10131397098302841
Validation loss: 1.4563729711758193

Epoch: 6| Step: 1
Training loss: 0.04227457568049431
Validation loss: 1.4502869831618441

Epoch: 6| Step: 2
Training loss: 0.05653341859579086
Validation loss: 1.4283117260984195

Epoch: 6| Step: 3
Training loss: 0.10523757338523865
Validation loss: 1.4530865479541082

Epoch: 6| Step: 4
Training loss: 0.04129168018698692
Validation loss: 1.4415212190279396

Epoch: 6| Step: 5
Training loss: 0.03307994455099106
Validation loss: 1.4589328778687345

Epoch: 6| Step: 6
Training loss: 0.05249129980802536
Validation loss: 1.4452197628636514

Epoch: 6| Step: 7
Training loss: 0.053459737449884415
Validation loss: 1.4709812825725925

Epoch: 6| Step: 8
Training loss: 0.03629922866821289
Validation loss: 1.4829835789178007

Epoch: 6| Step: 9
Training loss: 0.04685480520129204
Validation loss: 1.4439913483076199

Epoch: 6| Step: 10
Training loss: 0.08088098466396332
Validation loss: 1.453443483639789

Epoch: 6| Step: 11
Training loss: 0.058767806738615036
Validation loss: 1.4592552915696175

Epoch: 6| Step: 12
Training loss: 0.04264914244413376
Validation loss: 1.4242187020599202

Epoch: 6| Step: 13
Training loss: 0.07939228415489197
Validation loss: 1.4296151309885003

Epoch: 669| Step: 0
Training loss: 0.04625694453716278
Validation loss: 1.4530898973505983

Epoch: 6| Step: 1
Training loss: 0.07207284867763519
Validation loss: 1.4527514173138527

Epoch: 6| Step: 2
Training loss: 0.09272213280200958
Validation loss: 1.4368212761417511

Epoch: 6| Step: 3
Training loss: 0.0647905170917511
Validation loss: 1.4352136920857173

Epoch: 6| Step: 4
Training loss: 0.08605868369340897
Validation loss: 1.4433785202682659

Epoch: 6| Step: 5
Training loss: 0.048049867153167725
Validation loss: 1.4342762372827018

Epoch: 6| Step: 6
Training loss: 0.06767243146896362
Validation loss: 1.4598421114747242

Epoch: 6| Step: 7
Training loss: 0.059406861662864685
Validation loss: 1.446167790761558

Epoch: 6| Step: 8
Training loss: 0.058420129120349884
Validation loss: 1.4575769824366416

Epoch: 6| Step: 9
Training loss: 0.06264892965555191
Validation loss: 1.4463377393061114

Epoch: 6| Step: 10
Training loss: 0.03652505576610565
Validation loss: 1.426401061396445

Epoch: 6| Step: 11
Training loss: 0.04897693172097206
Validation loss: 1.4234436263320267

Epoch: 6| Step: 12
Training loss: 0.04598347842693329
Validation loss: 1.4064324453312864

Epoch: 6| Step: 13
Training loss: 0.06322720646858215
Validation loss: 1.4050970833788636

Epoch: 670| Step: 0
Training loss: 0.05050349608063698
Validation loss: 1.4196661621011712

Epoch: 6| Step: 1
Training loss: 0.09461276233196259
Validation loss: 1.4148136979790145

Epoch: 6| Step: 2
Training loss: 0.08320769667625427
Validation loss: 1.4136295472421954

Epoch: 6| Step: 3
Training loss: 0.07707919925451279
Validation loss: 1.424178651584092

Epoch: 6| Step: 4
Training loss: 0.08526018261909485
Validation loss: 1.4378240409717764

Epoch: 6| Step: 5
Training loss: 0.08315157890319824
Validation loss: 1.4128211416223997

Epoch: 6| Step: 6
Training loss: 0.037803709506988525
Validation loss: 1.4391515575429445

Epoch: 6| Step: 7
Training loss: 0.038365524262189865
Validation loss: 1.4584287225559194

Epoch: 6| Step: 8
Training loss: 0.05481052026152611
Validation loss: 1.440444148996825

Epoch: 6| Step: 9
Training loss: 0.05334065109491348
Validation loss: 1.44391562989963

Epoch: 6| Step: 10
Training loss: 0.07883608341217041
Validation loss: 1.4504098892211914

Epoch: 6| Step: 11
Training loss: 0.05845033749938011
Validation loss: 1.4556671034905218

Epoch: 6| Step: 12
Training loss: 0.05389610677957535
Validation loss: 1.4576059990031744

Epoch: 6| Step: 13
Training loss: 0.03678961470723152
Validation loss: 1.4227162247063012

Epoch: 671| Step: 0
Training loss: 0.038130395114421844
Validation loss: 1.4518660512021793

Epoch: 6| Step: 1
Training loss: 0.06240026652812958
Validation loss: 1.4592941730253157

Epoch: 6| Step: 2
Training loss: 0.09880589693784714
Validation loss: 1.4628983248946488

Epoch: 6| Step: 3
Training loss: 0.059882596135139465
Validation loss: 1.4556679802556192

Epoch: 6| Step: 4
Training loss: 0.03277783840894699
Validation loss: 1.4527068330395607

Epoch: 6| Step: 5
Training loss: 0.062359824776649475
Validation loss: 1.449126438427997

Epoch: 6| Step: 6
Training loss: 0.06382465362548828
Validation loss: 1.4135286884923135

Epoch: 6| Step: 7
Training loss: 0.03624356538057327
Validation loss: 1.4454988138650053

Epoch: 6| Step: 8
Training loss: 0.04907393828034401
Validation loss: 1.439484542415988

Epoch: 6| Step: 9
Training loss: 0.037298329174518585
Validation loss: 1.4321857229355843

Epoch: 6| Step: 10
Training loss: 0.03688106685876846
Validation loss: 1.4564044116645731

Epoch: 6| Step: 11
Training loss: 0.05662176385521889
Validation loss: 1.456580836285827

Epoch: 6| Step: 12
Training loss: 0.06392304599285126
Validation loss: 1.4655518807390684

Epoch: 6| Step: 13
Training loss: 0.1197861060500145
Validation loss: 1.4830121430017615

Epoch: 672| Step: 0
Training loss: 0.05628975108265877
Validation loss: 1.4669732252756755

Epoch: 6| Step: 1
Training loss: 0.05204913392663002
Validation loss: 1.4816770989407775

Epoch: 6| Step: 2
Training loss: 0.03705775737762451
Validation loss: 1.4500713694480158

Epoch: 6| Step: 3
Training loss: 0.05688217654824257
Validation loss: 1.4630127991399458

Epoch: 6| Step: 4
Training loss: 0.05369415879249573
Validation loss: 1.4875864508331462

Epoch: 6| Step: 5
Training loss: 0.04853563755750656
Validation loss: 1.4807462410260273

Epoch: 6| Step: 6
Training loss: 0.043303221464157104
Validation loss: 1.4829966727123465

Epoch: 6| Step: 7
Training loss: 0.047746442258358
Validation loss: 1.4512649313096078

Epoch: 6| Step: 8
Training loss: 0.05378158017992973
Validation loss: 1.4525680503537577

Epoch: 6| Step: 9
Training loss: 0.07312139868736267
Validation loss: 1.4543830528054187

Epoch: 6| Step: 10
Training loss: 0.05462116748094559
Validation loss: 1.4731716404679

Epoch: 6| Step: 11
Training loss: 0.05482859164476395
Validation loss: 1.4202011298107844

Epoch: 6| Step: 12
Training loss: 0.05040883645415306
Validation loss: 1.419229535646336

Epoch: 6| Step: 13
Training loss: 0.03639725223183632
Validation loss: 1.438749824800799

Epoch: 673| Step: 0
Training loss: 0.033973317593336105
Validation loss: 1.424256424750051

Epoch: 6| Step: 1
Training loss: 0.08004768192768097
Validation loss: 1.4419175963247977

Epoch: 6| Step: 2
Training loss: 0.05811028927564621
Validation loss: 1.3953024046395415

Epoch: 6| Step: 3
Training loss: 0.049193356186151505
Validation loss: 1.4020802551700222

Epoch: 6| Step: 4
Training loss: 0.06379424035549164
Validation loss: 1.3920937635565316

Epoch: 6| Step: 5
Training loss: 0.02959468588232994
Validation loss: 1.4059524638678438

Epoch: 6| Step: 6
Training loss: 0.04168405383825302
Validation loss: 1.3880818402895363

Epoch: 6| Step: 7
Training loss: 0.05529148131608963
Validation loss: 1.432364240769417

Epoch: 6| Step: 8
Training loss: 0.08487202227115631
Validation loss: 1.4419675539898615

Epoch: 6| Step: 9
Training loss: 0.07226869463920593
Validation loss: 1.4182763740580568

Epoch: 6| Step: 10
Training loss: 0.032093703746795654
Validation loss: 1.4105644187619608

Epoch: 6| Step: 11
Training loss: 0.04550473392009735
Validation loss: 1.383913468289119

Epoch: 6| Step: 12
Training loss: 0.060940831899642944
Validation loss: 1.3911396329120924

Epoch: 6| Step: 13
Training loss: 0.034680645912885666
Validation loss: 1.4047326785261913

Epoch: 674| Step: 0
Training loss: 0.0662110298871994
Validation loss: 1.3827486743209183

Epoch: 6| Step: 1
Training loss: 0.04166750609874725
Validation loss: 1.377198544881677

Epoch: 6| Step: 2
Training loss: 0.06049605458974838
Validation loss: 1.3762714093731296

Epoch: 6| Step: 3
Training loss: 0.08319979906082153
Validation loss: 1.3792535566514539

Epoch: 6| Step: 4
Training loss: 0.06080969423055649
Validation loss: 1.3999218658734394

Epoch: 6| Step: 5
Training loss: 0.034420669078826904
Validation loss: 1.392190016726012

Epoch: 6| Step: 6
Training loss: 0.0761260986328125
Validation loss: 1.3990622656319731

Epoch: 6| Step: 7
Training loss: 0.041571080684661865
Validation loss: 1.4159353740753666

Epoch: 6| Step: 8
Training loss: 0.05091893672943115
Validation loss: 1.4383934633706206

Epoch: 6| Step: 9
Training loss: 0.040395934134721756
Validation loss: 1.423796139096701

Epoch: 6| Step: 10
Training loss: 0.05422533303499222
Validation loss: 1.4400439903300295

Epoch: 6| Step: 11
Training loss: 0.06972268223762512
Validation loss: 1.4347725606733752

Epoch: 6| Step: 12
Training loss: 0.08106331527233124
Validation loss: 1.4671451045620827

Epoch: 6| Step: 13
Training loss: 0.040740009397268295
Validation loss: 1.4478470907416394

Epoch: 675| Step: 0
Training loss: 0.055259451270103455
Validation loss: 1.4721462688138407

Epoch: 6| Step: 1
Training loss: 0.05823691934347153
Validation loss: 1.4640414484085575

Epoch: 6| Step: 2
Training loss: 0.07575784623622894
Validation loss: 1.489092625597472

Epoch: 6| Step: 3
Training loss: 0.04773438721895218
Validation loss: 1.4589260457664408

Epoch: 6| Step: 4
Training loss: 0.05611010640859604
Validation loss: 1.4638657057157127

Epoch: 6| Step: 5
Training loss: 0.05199960619211197
Validation loss: 1.465320061611873

Epoch: 6| Step: 6
Training loss: 0.03209541738033295
Validation loss: 1.4606550585839055

Epoch: 6| Step: 7
Training loss: 0.053002968430519104
Validation loss: 1.449838840192364

Epoch: 6| Step: 8
Training loss: 0.05711882933974266
Validation loss: 1.449602524439494

Epoch: 6| Step: 9
Training loss: 0.028124747797846794
Validation loss: 1.4562914448399698

Epoch: 6| Step: 10
Training loss: 0.03580364212393761
Validation loss: 1.4203185086609216

Epoch: 6| Step: 11
Training loss: 0.07434017211198807
Validation loss: 1.42974179854957

Epoch: 6| Step: 12
Training loss: 0.07474154233932495
Validation loss: 1.3835126469212193

Epoch: 6| Step: 13
Training loss: 0.056075260043144226
Validation loss: 1.4065918589151034

Epoch: 676| Step: 0
Training loss: 0.051086582243442535
Validation loss: 1.3706827753333635

Epoch: 6| Step: 1
Training loss: 0.046259716153144836
Validation loss: 1.4164996647065686

Epoch: 6| Step: 2
Training loss: 0.062438320368528366
Validation loss: 1.4133189352609778

Epoch: 6| Step: 3
Training loss: 0.10083457082509995
Validation loss: 1.411929916310054

Epoch: 6| Step: 4
Training loss: 0.03283357620239258
Validation loss: 1.4185934034726952

Epoch: 6| Step: 5
Training loss: 0.07533014565706253
Validation loss: 1.4134303030147348

Epoch: 6| Step: 6
Training loss: 0.05643780529499054
Validation loss: 1.387610209885464

Epoch: 6| Step: 7
Training loss: 0.05882260575890541
Validation loss: 1.4059802985960437

Epoch: 6| Step: 8
Training loss: 0.050741784274578094
Validation loss: 1.4376526378816175

Epoch: 6| Step: 9
Training loss: 0.06517809629440308
Validation loss: 1.4275568557041947

Epoch: 6| Step: 10
Training loss: 0.061633989214897156
Validation loss: 1.4290557933110062

Epoch: 6| Step: 11
Training loss: 0.057478249073028564
Validation loss: 1.4123383504088207

Epoch: 6| Step: 12
Training loss: 0.04096079245209694
Validation loss: 1.4409936102487708

Epoch: 6| Step: 13
Training loss: 0.0843692198395729
Validation loss: 1.414727166134824

Epoch: 677| Step: 0
Training loss: 0.05321288853883743
Validation loss: 1.4330273725653206

Epoch: 6| Step: 1
Training loss: 0.041608937084674835
Validation loss: 1.4294509477512811

Epoch: 6| Step: 2
Training loss: 0.07047294825315475
Validation loss: 1.4604475985291183

Epoch: 6| Step: 3
Training loss: 0.05635060369968414
Validation loss: 1.4123369173337055

Epoch: 6| Step: 4
Training loss: 0.07727322727441788
Validation loss: 1.4422982802955053

Epoch: 6| Step: 5
Training loss: 0.06139924377202988
Validation loss: 1.4367672909972489

Epoch: 6| Step: 6
Training loss: 0.03373841941356659
Validation loss: 1.420993261439826

Epoch: 6| Step: 7
Training loss: 0.06002110242843628
Validation loss: 1.4072738796152093

Epoch: 6| Step: 8
Training loss: 0.0328049510717392
Validation loss: 1.3997805669743528

Epoch: 6| Step: 9
Training loss: 0.03312039375305176
Validation loss: 1.4014155172532605

Epoch: 6| Step: 10
Training loss: 0.05921323597431183
Validation loss: 1.4313773980704687

Epoch: 6| Step: 11
Training loss: 0.04009509086608887
Validation loss: 1.3872057827570106

Epoch: 6| Step: 12
Training loss: 0.060250796377658844
Validation loss: 1.383310353884133

Epoch: 6| Step: 13
Training loss: 0.05441359058022499
Validation loss: 1.3672717418721927

Epoch: 678| Step: 0
Training loss: 0.030293984338641167
Validation loss: 1.3816626905113139

Epoch: 6| Step: 1
Training loss: 0.048069387674331665
Validation loss: 1.3818248625724547

Epoch: 6| Step: 2
Training loss: 0.046463169157505035
Validation loss: 1.387800508929837

Epoch: 6| Step: 3
Training loss: 0.032138705253601074
Validation loss: 1.36693395978661

Epoch: 6| Step: 4
Training loss: 0.0764540508389473
Validation loss: 1.3835743883604645

Epoch: 6| Step: 5
Training loss: 0.06922140717506409
Validation loss: 1.449630045121716

Epoch: 6| Step: 6
Training loss: 0.04817408323287964
Validation loss: 1.4300964058086436

Epoch: 6| Step: 7
Training loss: 0.09151911735534668
Validation loss: 1.453660702192655

Epoch: 6| Step: 8
Training loss: 0.09774317592382431
Validation loss: 1.4420856737321424

Epoch: 6| Step: 9
Training loss: 0.05213594809174538
Validation loss: 1.4438157581513928

Epoch: 6| Step: 10
Training loss: 0.08041806519031525
Validation loss: 1.418666813963203

Epoch: 6| Step: 11
Training loss: 0.0746062695980072
Validation loss: 1.427898331355023

Epoch: 6| Step: 12
Training loss: 0.08132360875606537
Validation loss: 1.4363319796900595

Epoch: 6| Step: 13
Training loss: 0.09425057470798492
Validation loss: 1.463550256785526

Epoch: 679| Step: 0
Training loss: 0.07427531480789185
Validation loss: 1.4576884392769105

Epoch: 6| Step: 1
Training loss: 0.06815146654844284
Validation loss: 1.485476520753676

Epoch: 6| Step: 2
Training loss: 0.06667603552341461
Validation loss: 1.486650852746861

Epoch: 6| Step: 3
Training loss: 0.08491808921098709
Validation loss: 1.4924609097101356

Epoch: 6| Step: 4
Training loss: 0.09433652460575104
Validation loss: 1.5264050037630144

Epoch: 6| Step: 5
Training loss: 0.09025366604328156
Validation loss: 1.5169520237112557

Epoch: 6| Step: 6
Training loss: 0.13604456186294556
Validation loss: 1.4859558613069597

Epoch: 6| Step: 7
Training loss: 0.08691171556711197
Validation loss: 1.446961405456707

Epoch: 6| Step: 8
Training loss: 0.04006630927324295
Validation loss: 1.423237987743911

Epoch: 6| Step: 9
Training loss: 0.026790959760546684
Validation loss: 1.4303545477569743

Epoch: 6| Step: 10
Training loss: 0.06725284457206726
Validation loss: 1.4369907430423203

Epoch: 6| Step: 11
Training loss: 0.09457516670227051
Validation loss: 1.4611299832661946

Epoch: 6| Step: 12
Training loss: 0.12078741192817688
Validation loss: 1.476394784065985

Epoch: 6| Step: 13
Training loss: 0.10306169092655182
Validation loss: 1.4928379930475706

Epoch: 680| Step: 0
Training loss: 0.07472154498100281
Validation loss: 1.4647969686856834

Epoch: 6| Step: 1
Training loss: 0.09598423540592194
Validation loss: 1.4812802101976128

Epoch: 6| Step: 2
Training loss: 0.06558731198310852
Validation loss: 1.474429125426918

Epoch: 6| Step: 3
Training loss: 0.04987508803606033
Validation loss: 1.4604542883493568

Epoch: 6| Step: 4
Training loss: 0.08282820880413055
Validation loss: 1.433401483361439

Epoch: 6| Step: 5
Training loss: 0.07307551801204681
Validation loss: 1.4446781681429954

Epoch: 6| Step: 6
Training loss: 0.15411940217018127
Validation loss: 1.4266029442510297

Epoch: 6| Step: 7
Training loss: 0.08718456327915192
Validation loss: 1.433930016333057

Epoch: 6| Step: 8
Training loss: 0.05503685772418976
Validation loss: 1.4070411523183186

Epoch: 6| Step: 9
Training loss: 0.06148447096347809
Validation loss: 1.4199211123169109

Epoch: 6| Step: 10
Training loss: 0.03581490367650986
Validation loss: 1.3955647830040223

Epoch: 6| Step: 11
Training loss: 0.06617648899555206
Validation loss: 1.412320827925077

Epoch: 6| Step: 12
Training loss: 0.10536526888608932
Validation loss: 1.4168085923758886

Epoch: 6| Step: 13
Training loss: 0.0688897892832756
Validation loss: 1.4261362437278993

Epoch: 681| Step: 0
Training loss: 0.08533677458763123
Validation loss: 1.4234460746088335

Epoch: 6| Step: 1
Training loss: 0.09651888906955719
Validation loss: 1.405410228237029

Epoch: 6| Step: 2
Training loss: 0.051898226141929626
Validation loss: 1.383874350978482

Epoch: 6| Step: 3
Training loss: 0.05586231127381325
Validation loss: 1.402172512905572

Epoch: 6| Step: 4
Training loss: 0.05324685573577881
Validation loss: 1.3885414241462626

Epoch: 6| Step: 5
Training loss: 0.07257049530744553
Validation loss: 1.4094943141424527

Epoch: 6| Step: 6
Training loss: 0.08876605331897736
Validation loss: 1.3806302656409561

Epoch: 6| Step: 7
Training loss: 0.06864246726036072
Validation loss: 1.3753402784306517

Epoch: 6| Step: 8
Training loss: 0.0704425796866417
Validation loss: 1.3936133371886386

Epoch: 6| Step: 9
Training loss: 0.028020650148391724
Validation loss: 1.3845652713570544

Epoch: 6| Step: 10
Training loss: 0.06418745219707489
Validation loss: 1.396483805871779

Epoch: 6| Step: 11
Training loss: 0.06308377534151077
Validation loss: 1.3829413934420514

Epoch: 6| Step: 12
Training loss: 0.04770046845078468
Validation loss: 1.4212938495861587

Epoch: 6| Step: 13
Training loss: 0.09267804026603699
Validation loss: 1.3898421833592076

Epoch: 682| Step: 0
Training loss: 0.0719715878367424
Validation loss: 1.4108690113149664

Epoch: 6| Step: 1
Training loss: 0.032985907047986984
Validation loss: 1.425628395490749

Epoch: 6| Step: 2
Training loss: 0.05207741633057594
Validation loss: 1.4155562180344776

Epoch: 6| Step: 3
Training loss: 0.07070723176002502
Validation loss: 1.4100175096142677

Epoch: 6| Step: 4
Training loss: 0.04473435506224632
Validation loss: 1.3825824696530578

Epoch: 6| Step: 5
Training loss: 0.0479605495929718
Validation loss: 1.4253621652562132

Epoch: 6| Step: 6
Training loss: 0.07991071045398712
Validation loss: 1.4170905966912546

Epoch: 6| Step: 7
Training loss: 0.03237201273441315
Validation loss: 1.4403894832057338

Epoch: 6| Step: 8
Training loss: 0.05554720759391785
Validation loss: 1.4223839775208504

Epoch: 6| Step: 9
Training loss: 0.04347210377454758
Validation loss: 1.4267614400514992

Epoch: 6| Step: 10
Training loss: 0.08242104947566986
Validation loss: 1.4186274620794481

Epoch: 6| Step: 11
Training loss: 0.07226648926734924
Validation loss: 1.419834747109362

Epoch: 6| Step: 12
Training loss: 0.030451424419879913
Validation loss: 1.3841458751309303

Epoch: 6| Step: 13
Training loss: 0.034995488822460175
Validation loss: 1.3953062219004477

Epoch: 683| Step: 0
Training loss: 0.03573212772607803
Validation loss: 1.4247741058308592

Epoch: 6| Step: 1
Training loss: 0.04115366190671921
Validation loss: 1.421486262352236

Epoch: 6| Step: 2
Training loss: 0.04663670063018799
Validation loss: 1.4171799549492456

Epoch: 6| Step: 3
Training loss: 0.04366308078169823
Validation loss: 1.431974772484072

Epoch: 6| Step: 4
Training loss: 0.04475562646985054
Validation loss: 1.4092602037614392

Epoch: 6| Step: 5
Training loss: 0.048530399799346924
Validation loss: 1.4219580837475356

Epoch: 6| Step: 6
Training loss: 0.05490699037909508
Validation loss: 1.4483315483216317

Epoch: 6| Step: 7
Training loss: 0.07655143737792969
Validation loss: 1.4490840242755028

Epoch: 6| Step: 8
Training loss: 0.11888797581195831
Validation loss: 1.428988778462974

Epoch: 6| Step: 9
Training loss: 0.0654076635837555
Validation loss: 1.478872171012304

Epoch: 6| Step: 10
Training loss: 0.07037220895290375
Validation loss: 1.4382610103135467

Epoch: 6| Step: 11
Training loss: 0.04084136337041855
Validation loss: 1.4475592541438278

Epoch: 6| Step: 12
Training loss: 0.0707276463508606
Validation loss: 1.4635340282993932

Epoch: 6| Step: 13
Training loss: 0.05470127612352371
Validation loss: 1.4310229894935445

Epoch: 684| Step: 0
Training loss: 0.04094546288251877
Validation loss: 1.4309179244502899

Epoch: 6| Step: 1
Training loss: 0.033080458641052246
Validation loss: 1.4497972021820724

Epoch: 6| Step: 2
Training loss: 0.06100483611226082
Validation loss: 1.4269903090692335

Epoch: 6| Step: 3
Training loss: 0.04663003236055374
Validation loss: 1.4280809202501852

Epoch: 6| Step: 4
Training loss: 0.06642766296863556
Validation loss: 1.4081256453708937

Epoch: 6| Step: 5
Training loss: 0.04184611141681671
Validation loss: 1.4387686752503919

Epoch: 6| Step: 6
Training loss: 0.12325452268123627
Validation loss: 1.4229574459855274

Epoch: 6| Step: 7
Training loss: 0.057907454669475555
Validation loss: 1.399704344810978

Epoch: 6| Step: 8
Training loss: 0.09003626555204391
Validation loss: 1.4333335430391374

Epoch: 6| Step: 9
Training loss: 0.026059607043862343
Validation loss: 1.4072467864200633

Epoch: 6| Step: 10
Training loss: 0.0445016548037529
Validation loss: 1.4346593579938334

Epoch: 6| Step: 11
Training loss: 0.06472083181142807
Validation loss: 1.3874024492438122

Epoch: 6| Step: 12
Training loss: 0.06677553057670593
Validation loss: 1.4277607471712175

Epoch: 6| Step: 13
Training loss: 0.05099907144904137
Validation loss: 1.4538233254545478

Epoch: 685| Step: 0
Training loss: 0.03719579428434372
Validation loss: 1.4240832815888107

Epoch: 6| Step: 1
Training loss: 0.04064376279711723
Validation loss: 1.4382642116597903

Epoch: 6| Step: 2
Training loss: 0.047650597989559174
Validation loss: 1.425377962409809

Epoch: 6| Step: 3
Training loss: 0.0766240581870079
Validation loss: 1.4203093103183213

Epoch: 6| Step: 4
Training loss: 0.04368491470813751
Validation loss: 1.4237366107202345

Epoch: 6| Step: 5
Training loss: 0.05564216524362564
Validation loss: 1.4026274373454433

Epoch: 6| Step: 6
Training loss: 0.050990939140319824
Validation loss: 1.4027496589127408

Epoch: 6| Step: 7
Training loss: 0.04372066259384155
Validation loss: 1.4155048811307518

Epoch: 6| Step: 8
Training loss: 0.04520148038864136
Validation loss: 1.3987237868770477

Epoch: 6| Step: 9
Training loss: 0.0437619611620903
Validation loss: 1.4099359255965038

Epoch: 6| Step: 10
Training loss: 0.06239352375268936
Validation loss: 1.4116740431836856

Epoch: 6| Step: 11
Training loss: 0.05864527076482773
Validation loss: 1.4185529825507954

Epoch: 6| Step: 12
Training loss: 0.047367554157972336
Validation loss: 1.3976081891726422

Epoch: 6| Step: 13
Training loss: 0.048069484531879425
Validation loss: 1.4020308268967496

Epoch: 686| Step: 0
Training loss: 0.07220248878002167
Validation loss: 1.3861242455820884

Epoch: 6| Step: 1
Training loss: 0.03727398067712784
Validation loss: 1.3848274959030973

Epoch: 6| Step: 2
Training loss: 0.04701996222138405
Validation loss: 1.4064415347191594

Epoch: 6| Step: 3
Training loss: 0.057583458721637726
Validation loss: 1.3843411848109255

Epoch: 6| Step: 4
Training loss: 0.0845351591706276
Validation loss: 1.385571615670317

Epoch: 6| Step: 5
Training loss: 0.07282204926013947
Validation loss: 1.4006055324308333

Epoch: 6| Step: 6
Training loss: 0.07577475905418396
Validation loss: 1.397212548922467

Epoch: 6| Step: 7
Training loss: 0.061168842017650604
Validation loss: 1.3974966400413102

Epoch: 6| Step: 8
Training loss: 0.05607938393950462
Validation loss: 1.403569398387786

Epoch: 6| Step: 9
Training loss: 0.0609048455953598
Validation loss: 1.4051345714958765

Epoch: 6| Step: 10
Training loss: 0.03372965008020401
Validation loss: 1.39852762094108

Epoch: 6| Step: 11
Training loss: 0.07574876397848129
Validation loss: 1.4099922404494336

Epoch: 6| Step: 12
Training loss: 0.06368498504161835
Validation loss: 1.4479485564334418

Epoch: 6| Step: 13
Training loss: 0.05412702262401581
Validation loss: 1.4338015330735074

Epoch: 687| Step: 0
Training loss: 0.04783851280808449
Validation loss: 1.441337827713259

Epoch: 6| Step: 1
Training loss: 0.035340845584869385
Validation loss: 1.4819166878218293

Epoch: 6| Step: 2
Training loss: 0.06634301692247391
Validation loss: 1.4548835895394767

Epoch: 6| Step: 3
Training loss: 0.05610843747854233
Validation loss: 1.4306065395314207

Epoch: 6| Step: 4
Training loss: 0.07323773205280304
Validation loss: 1.4527604272288661

Epoch: 6| Step: 5
Training loss: 0.07370740175247192
Validation loss: 1.4379185720156598

Epoch: 6| Step: 6
Training loss: 0.033811621367931366
Validation loss: 1.4437181347159929

Epoch: 6| Step: 7
Training loss: 0.03520481288433075
Validation loss: 1.4506447071670203

Epoch: 6| Step: 8
Training loss: 0.07929264008998871
Validation loss: 1.448884831961765

Epoch: 6| Step: 9
Training loss: 0.047982778400182724
Validation loss: 1.4269337320840487

Epoch: 6| Step: 10
Training loss: 0.056862421333789825
Validation loss: 1.4297749304002332

Epoch: 6| Step: 11
Training loss: 0.09637182205915451
Validation loss: 1.4192304060023317

Epoch: 6| Step: 12
Training loss: 0.06433972716331482
Validation loss: 1.4078521151696481

Epoch: 6| Step: 13
Training loss: 0.06265627592802048
Validation loss: 1.4427511031909654

Epoch: 688| Step: 0
Training loss: 0.03249900043010712
Validation loss: 1.4390707926083637

Epoch: 6| Step: 1
Training loss: 0.05267638713121414
Validation loss: 1.4154489360829836

Epoch: 6| Step: 2
Training loss: 0.06575445830821991
Validation loss: 1.4099730509583668

Epoch: 6| Step: 3
Training loss: 0.07961440831422806
Validation loss: 1.4379226661497546

Epoch: 6| Step: 4
Training loss: 0.06503845006227493
Validation loss: 1.448654777260237

Epoch: 6| Step: 5
Training loss: 0.04102037474513054
Validation loss: 1.4269713342830699

Epoch: 6| Step: 6
Training loss: 0.05137699097394943
Validation loss: 1.4297511430196865

Epoch: 6| Step: 7
Training loss: 0.06590671837329865
Validation loss: 1.4377971182587326

Epoch: 6| Step: 8
Training loss: 0.07252995669841766
Validation loss: 1.4550259196630089

Epoch: 6| Step: 9
Training loss: 0.08540675044059753
Validation loss: 1.4382021145154071

Epoch: 6| Step: 10
Training loss: 0.0631430447101593
Validation loss: 1.4232092929142777

Epoch: 6| Step: 11
Training loss: 0.06745286285877228
Validation loss: 1.4265311097586026

Epoch: 6| Step: 12
Training loss: 0.07624080777168274
Validation loss: 1.440928227158003

Epoch: 6| Step: 13
Training loss: 0.03452865406870842
Validation loss: 1.4345260127898185

Epoch: 689| Step: 0
Training loss: 0.0450170673429966
Validation loss: 1.4199140635869836

Epoch: 6| Step: 1
Training loss: 0.06448637694120407
Validation loss: 1.4273086875997565

Epoch: 6| Step: 2
Training loss: 0.05637357383966446
Validation loss: 1.4337592368484826

Epoch: 6| Step: 3
Training loss: 0.05930865928530693
Validation loss: 1.4246368151839062

Epoch: 6| Step: 4
Training loss: 0.06202244758605957
Validation loss: 1.428574744091239

Epoch: 6| Step: 5
Training loss: 0.07723590731620789
Validation loss: 1.4541401427279237

Epoch: 6| Step: 6
Training loss: 0.05520549789071083
Validation loss: 1.4259947256375385

Epoch: 6| Step: 7
Training loss: 0.06019308418035507
Validation loss: 1.4457585221977645

Epoch: 6| Step: 8
Training loss: 0.04101079702377319
Validation loss: 1.4140745721837527

Epoch: 6| Step: 9
Training loss: 0.03806652873754501
Validation loss: 1.41910606943151

Epoch: 6| Step: 10
Training loss: 0.027697138488292694
Validation loss: 1.4548430224900604

Epoch: 6| Step: 11
Training loss: 0.051062315702438354
Validation loss: 1.4546841421434957

Epoch: 6| Step: 12
Training loss: 0.040426574647426605
Validation loss: 1.4172786794682986

Epoch: 6| Step: 13
Training loss: 0.08794429153203964
Validation loss: 1.4194422870553949

Epoch: 690| Step: 0
Training loss: 0.02782975696027279
Validation loss: 1.3979495642005757

Epoch: 6| Step: 1
Training loss: 0.06277912855148315
Validation loss: 1.4273165137537065

Epoch: 6| Step: 2
Training loss: 0.05233974754810333
Validation loss: 1.4073106255582584

Epoch: 6| Step: 3
Training loss: 0.04722148925065994
Validation loss: 1.4219523040197228

Epoch: 6| Step: 4
Training loss: 0.05465206503868103
Validation loss: 1.4062537326607654

Epoch: 6| Step: 5
Training loss: 0.06157571077346802
Validation loss: 1.424314929592994

Epoch: 6| Step: 6
Training loss: 0.04425767809152603
Validation loss: 1.4187750335662597

Epoch: 6| Step: 7
Training loss: 0.06972449272871017
Validation loss: 1.4355365627555436

Epoch: 6| Step: 8
Training loss: 0.02841908484697342
Validation loss: 1.4316023959908435

Epoch: 6| Step: 9
Training loss: 0.040048327296972275
Validation loss: 1.428953952686761

Epoch: 6| Step: 10
Training loss: 0.049196865409612656
Validation loss: 1.4222517494232423

Epoch: 6| Step: 11
Training loss: 0.022136125713586807
Validation loss: 1.4321027635246195

Epoch: 6| Step: 12
Training loss: 0.041919492185115814
Validation loss: 1.4139495754754672

Epoch: 6| Step: 13
Training loss: 0.10743367671966553
Validation loss: 1.4380207702677736

Epoch: 691| Step: 0
Training loss: 0.07437051087617874
Validation loss: 1.4386961575477355

Epoch: 6| Step: 1
Training loss: 0.05309445783495903
Validation loss: 1.4225416004016835

Epoch: 6| Step: 2
Training loss: 0.062420736998319626
Validation loss: 1.4440840598075622

Epoch: 6| Step: 3
Training loss: 0.061771951615810394
Validation loss: 1.4325090044288225

Epoch: 6| Step: 4
Training loss: 0.04775135964155197
Validation loss: 1.4365701239596131

Epoch: 6| Step: 5
Training loss: 0.0856512039899826
Validation loss: 1.433193843210897

Epoch: 6| Step: 6
Training loss: 0.06519473344087601
Validation loss: 1.4609105023004676

Epoch: 6| Step: 7
Training loss: 0.07884836941957474
Validation loss: 1.4396681734310683

Epoch: 6| Step: 8
Training loss: 0.07036405056715012
Validation loss: 1.4523741147851432

Epoch: 6| Step: 9
Training loss: 0.042311232537031174
Validation loss: 1.4425782272892613

Epoch: 6| Step: 10
Training loss: 0.0483434796333313
Validation loss: 1.4324758629645071

Epoch: 6| Step: 11
Training loss: 0.099649578332901
Validation loss: 1.446401685796758

Epoch: 6| Step: 12
Training loss: 0.03637556731700897
Validation loss: 1.446860505688575

Epoch: 6| Step: 13
Training loss: 0.05054572969675064
Validation loss: 1.449133070566321

Epoch: 692| Step: 0
Training loss: 0.084219790995121
Validation loss: 1.4337021253442253

Epoch: 6| Step: 1
Training loss: 0.0666738748550415
Validation loss: 1.4224203043086554

Epoch: 6| Step: 2
Training loss: 0.05267465114593506
Validation loss: 1.429208565783757

Epoch: 6| Step: 3
Training loss: 0.054205089807510376
Validation loss: 1.4306119462495208

Epoch: 6| Step: 4
Training loss: 0.04505831375718117
Validation loss: 1.4235140008311118

Epoch: 6| Step: 5
Training loss: 0.08278840035200119
Validation loss: 1.4316367718481249

Epoch: 6| Step: 6
Training loss: 0.06615911424160004
Validation loss: 1.4405077247209446

Epoch: 6| Step: 7
Training loss: 0.05516839027404785
Validation loss: 1.461501108702793

Epoch: 6| Step: 8
Training loss: 0.07614996284246445
Validation loss: 1.4697330997836204

Epoch: 6| Step: 9
Training loss: 0.07121139019727707
Validation loss: 1.465857490416496

Epoch: 6| Step: 10
Training loss: 0.07130439579486847
Validation loss: 1.4706299465189698

Epoch: 6| Step: 11
Training loss: 0.07075938582420349
Validation loss: 1.455646102787346

Epoch: 6| Step: 12
Training loss: 0.0798797458410263
Validation loss: 1.4696451284552132

Epoch: 6| Step: 13
Training loss: 0.10154598951339722
Validation loss: 1.4300780270689277

Epoch: 693| Step: 0
Training loss: 0.044035911560058594
Validation loss: 1.4625111728586175

Epoch: 6| Step: 1
Training loss: 0.05865015462040901
Validation loss: 1.4334159179400372

Epoch: 6| Step: 2
Training loss: 0.06115303933620453
Validation loss: 1.4299475633969871

Epoch: 6| Step: 3
Training loss: 0.03382954001426697
Validation loss: 1.4174328721979612

Epoch: 6| Step: 4
Training loss: 0.03987272083759308
Validation loss: 1.4175374597631476

Epoch: 6| Step: 5
Training loss: 0.13550470769405365
Validation loss: 1.4125119883527038

Epoch: 6| Step: 6
Training loss: 0.07569876313209534
Validation loss: 1.4096844952593568

Epoch: 6| Step: 7
Training loss: 0.05621829256415367
Validation loss: 1.41250503447748

Epoch: 6| Step: 8
Training loss: 0.08053460717201233
Validation loss: 1.3985451716248707

Epoch: 6| Step: 9
Training loss: 0.06928446888923645
Validation loss: 1.4096696556255381

Epoch: 6| Step: 10
Training loss: 0.03925444930791855
Validation loss: 1.3518669630891533

Epoch: 6| Step: 11
Training loss: 0.052735161036252975
Validation loss: 1.3967695889934417

Epoch: 6| Step: 12
Training loss: 0.0523601695895195
Validation loss: 1.3706846237182617

Epoch: 6| Step: 13
Training loss: 0.03679633140563965
Validation loss: 1.4088317008428677

Epoch: 694| Step: 0
Training loss: 0.031315337866544724
Validation loss: 1.4081011613210042

Epoch: 6| Step: 1
Training loss: 0.061599548906087875
Validation loss: 1.4256445105357836

Epoch: 6| Step: 2
Training loss: 0.047522544860839844
Validation loss: 1.3982482664687659

Epoch: 6| Step: 3
Training loss: 0.036629099398851395
Validation loss: 1.429532625341928

Epoch: 6| Step: 4
Training loss: 0.04820743948221207
Validation loss: 1.4314104164800336

Epoch: 6| Step: 5
Training loss: 0.09730298817157745
Validation loss: 1.4797742943609915

Epoch: 6| Step: 6
Training loss: 0.06307947635650635
Validation loss: 1.4765719085611322

Epoch: 6| Step: 7
Training loss: 0.07192102819681168
Validation loss: 1.4900015272119993

Epoch: 6| Step: 8
Training loss: 0.09970980882644653
Validation loss: 1.4819196013994114

Epoch: 6| Step: 9
Training loss: 0.056647684425115585
Validation loss: 1.4661581823902745

Epoch: 6| Step: 10
Training loss: 0.05408354103565216
Validation loss: 1.4448392077158856

Epoch: 6| Step: 11
Training loss: 0.06053294986486435
Validation loss: 1.4380007879708403

Epoch: 6| Step: 12
Training loss: 0.052837856113910675
Validation loss: 1.4440500992600636

Epoch: 6| Step: 13
Training loss: 0.09470778703689575
Validation loss: 1.434285713780311

Epoch: 695| Step: 0
Training loss: 0.051189981400966644
Validation loss: 1.4308137124584568

Epoch: 6| Step: 1
Training loss: 0.04994506388902664
Validation loss: 1.4100962774727934

Epoch: 6| Step: 2
Training loss: 0.07153451442718506
Validation loss: 1.425130994089188

Epoch: 6| Step: 3
Training loss: 0.04479796439409256
Validation loss: 1.4076748765924925

Epoch: 6| Step: 4
Training loss: 0.08327798545360565
Validation loss: 1.4031782547632854

Epoch: 6| Step: 5
Training loss: 0.07702247053384781
Validation loss: 1.3802023164687618

Epoch: 6| Step: 6
Training loss: 0.047627806663513184
Validation loss: 1.4020146637834527

Epoch: 6| Step: 7
Training loss: 0.05300672724843025
Validation loss: 1.3887160888282202

Epoch: 6| Step: 8
Training loss: 0.08037784695625305
Validation loss: 1.3910392048538371

Epoch: 6| Step: 9
Training loss: 0.034273602068424225
Validation loss: 1.380188694564245

Epoch: 6| Step: 10
Training loss: 0.05733612924814224
Validation loss: 1.3894500732421875

Epoch: 6| Step: 11
Training loss: 0.09733429551124573
Validation loss: 1.3658754479500554

Epoch: 6| Step: 12
Training loss: 0.05016041919589043
Validation loss: 1.3713873829892886

Epoch: 6| Step: 13
Training loss: 0.07753937691450119
Validation loss: 1.378277023633321

Epoch: 696| Step: 0
Training loss: 0.032783277332782745
Validation loss: 1.368389614166752

Epoch: 6| Step: 1
Training loss: 0.035459306091070175
Validation loss: 1.366883643211857

Epoch: 6| Step: 2
Training loss: 0.08073972910642624
Validation loss: 1.398186372172448

Epoch: 6| Step: 3
Training loss: 0.05976272374391556
Validation loss: 1.4090516733866867

Epoch: 6| Step: 4
Training loss: 0.055854275822639465
Validation loss: 1.3961971837987182

Epoch: 6| Step: 5
Training loss: 0.06273512542247772
Validation loss: 1.4005998398668023

Epoch: 6| Step: 6
Training loss: 0.05381938815116882
Validation loss: 1.416644803298417

Epoch: 6| Step: 7
Training loss: 0.08428607881069183
Validation loss: 1.442463223652173

Epoch: 6| Step: 8
Training loss: 0.06701056659221649
Validation loss: 1.4099961608968756

Epoch: 6| Step: 9
Training loss: 0.07371333241462708
Validation loss: 1.4167390779782367

Epoch: 6| Step: 10
Training loss: 0.05628153681755066
Validation loss: 1.4102759835540608

Epoch: 6| Step: 11
Training loss: 0.03316136449575424
Validation loss: 1.417985882810367

Epoch: 6| Step: 12
Training loss: 0.06768599152565002
Validation loss: 1.4267943418154152

Epoch: 6| Step: 13
Training loss: 0.07059761881828308
Validation loss: 1.416785801610639

Epoch: 697| Step: 0
Training loss: 0.04452378302812576
Validation loss: 1.4440869323668941

Epoch: 6| Step: 1
Training loss: 0.05793284624814987
Validation loss: 1.435779410023843

Epoch: 6| Step: 2
Training loss: 0.04509400576353073
Validation loss: 1.40425528377615

Epoch: 6| Step: 3
Training loss: 0.03932483494281769
Validation loss: 1.402588076488946

Epoch: 6| Step: 4
Training loss: 0.04961945861577988
Validation loss: 1.423511214153741

Epoch: 6| Step: 5
Training loss: 0.07740338146686554
Validation loss: 1.447729036372195

Epoch: 6| Step: 6
Training loss: 0.04475335404276848
Validation loss: 1.4208314816157024

Epoch: 6| Step: 7
Training loss: 0.050103701651096344
Validation loss: 1.451008318572916

Epoch: 6| Step: 8
Training loss: 0.05276681110262871
Validation loss: 1.4289394258171

Epoch: 6| Step: 9
Training loss: 0.06469789147377014
Validation loss: 1.4351334110383065

Epoch: 6| Step: 10
Training loss: 0.05475325137376785
Validation loss: 1.4090659695286905

Epoch: 6| Step: 11
Training loss: 0.05319194868206978
Validation loss: 1.4241710606441702

Epoch: 6| Step: 12
Training loss: 0.062225185334682465
Validation loss: 1.420436066965903

Epoch: 6| Step: 13
Training loss: 0.07725334167480469
Validation loss: 1.4338532795188248

Epoch: 698| Step: 0
Training loss: 0.03770540654659271
Validation loss: 1.4392995334440661

Epoch: 6| Step: 1
Training loss: 0.050278499722480774
Validation loss: 1.4450578106346952

Epoch: 6| Step: 2
Training loss: 0.04968287795782089
Validation loss: 1.4124595657471688

Epoch: 6| Step: 3
Training loss: 0.042172420769929886
Validation loss: 1.419519591075118

Epoch: 6| Step: 4
Training loss: 0.053980663418769836
Validation loss: 1.4289617858907229

Epoch: 6| Step: 5
Training loss: 0.056677769869565964
Validation loss: 1.4397552500488937

Epoch: 6| Step: 6
Training loss: 0.05023355409502983
Validation loss: 1.4379556166228427

Epoch: 6| Step: 7
Training loss: 0.07453350722789764
Validation loss: 1.4004954830292733

Epoch: 6| Step: 8
Training loss: 0.07983414828777313
Validation loss: 1.419747478218489

Epoch: 6| Step: 9
Training loss: 0.05551265925168991
Validation loss: 1.431345623026612

Epoch: 6| Step: 10
Training loss: 0.07690173387527466
Validation loss: 1.4245397378039617

Epoch: 6| Step: 11
Training loss: 0.0367404967546463
Validation loss: 1.4338756556152015

Epoch: 6| Step: 12
Training loss: 0.066901296377182
Validation loss: 1.4218672475507181

Epoch: 6| Step: 13
Training loss: 0.14802761375904083
Validation loss: 1.4434116296870734

Epoch: 699| Step: 0
Training loss: 0.06727567315101624
Validation loss: 1.4457261491847295

Epoch: 6| Step: 1
Training loss: 0.046258457005023956
Validation loss: 1.4473377671293033

Epoch: 6| Step: 2
Training loss: 0.05049853026866913
Validation loss: 1.4770940106402162

Epoch: 6| Step: 3
Training loss: 0.04553033411502838
Validation loss: 1.4326555344366259

Epoch: 6| Step: 4
Training loss: 0.055665723979473114
Validation loss: 1.4524076971956479

Epoch: 6| Step: 5
Training loss: 0.04469866678118706
Validation loss: 1.4478724515566261

Epoch: 6| Step: 6
Training loss: 0.04716363549232483
Validation loss: 1.4269949172132759

Epoch: 6| Step: 7
Training loss: 0.04172639548778534
Validation loss: 1.4375046747986988

Epoch: 6| Step: 8
Training loss: 0.039227914065122604
Validation loss: 1.4143261319847518

Epoch: 6| Step: 9
Training loss: 0.031941190361976624
Validation loss: 1.412137455837701

Epoch: 6| Step: 10
Training loss: 0.08525294065475464
Validation loss: 1.4343998957705755

Epoch: 6| Step: 11
Training loss: 0.055438753217458725
Validation loss: 1.3989888955188055

Epoch: 6| Step: 12
Training loss: 0.039688073098659515
Validation loss: 1.4009104236479728

Epoch: 6| Step: 13
Training loss: 0.08620428293943405
Validation loss: 1.3918573753808134

Epoch: 700| Step: 0
Training loss: 0.029622087255120277
Validation loss: 1.4150455549199095

Epoch: 6| Step: 1
Training loss: 0.07200363278388977
Validation loss: 1.3811598125324454

Epoch: 6| Step: 2
Training loss: 0.04855853319168091
Validation loss: 1.395516207141261

Epoch: 6| Step: 3
Training loss: 0.053099244832992554
Validation loss: 1.3958435032957344

Epoch: 6| Step: 4
Training loss: 0.07945065200328827
Validation loss: 1.354507855830654

Epoch: 6| Step: 5
Training loss: 0.06594715267419815
Validation loss: 1.397102693716685

Epoch: 6| Step: 6
Training loss: 0.05175663158297539
Validation loss: 1.408777311284055

Epoch: 6| Step: 7
Training loss: 0.04880085587501526
Validation loss: 1.3582870908962783

Epoch: 6| Step: 8
Training loss: 0.07495588064193726
Validation loss: 1.3843546246969571

Epoch: 6| Step: 9
Training loss: 0.05208361893892288
Validation loss: 1.3938040983292364

Epoch: 6| Step: 10
Training loss: 0.058606721460819244
Validation loss: 1.4058194551416623

Epoch: 6| Step: 11
Training loss: 0.0613723024725914
Validation loss: 1.404521498628842

Epoch: 6| Step: 12
Training loss: 0.04985830932855606
Validation loss: 1.4101630641568093

Epoch: 6| Step: 13
Training loss: 0.04797359183430672
Validation loss: 1.3695683466490878

Epoch: 701| Step: 0
Training loss: 0.08120757341384888
Validation loss: 1.4293306412235383

Epoch: 6| Step: 1
Training loss: 0.04727635532617569
Validation loss: 1.4323463439941406

Epoch: 6| Step: 2
Training loss: 0.03800998628139496
Validation loss: 1.4074596858793689

Epoch: 6| Step: 3
Training loss: 0.046387962996959686
Validation loss: 1.4361253310275335

Epoch: 6| Step: 4
Training loss: 0.04150748252868652
Validation loss: 1.420468100937464

Epoch: 6| Step: 5
Training loss: 0.03856087476015091
Validation loss: 1.4281683570595198

Epoch: 6| Step: 6
Training loss: 0.05375582352280617
Validation loss: 1.4277799687077921

Epoch: 6| Step: 7
Training loss: 0.06816144287586212
Validation loss: 1.4303836591782109

Epoch: 6| Step: 8
Training loss: 0.07538963854312897
Validation loss: 1.443464716275533

Epoch: 6| Step: 9
Training loss: 0.08045686036348343
Validation loss: 1.4460716183467577

Epoch: 6| Step: 10
Training loss: 0.05767632648348808
Validation loss: 1.4225985991057528

Epoch: 6| Step: 11
Training loss: 0.0922631248831749
Validation loss: 1.4401291544719408

Epoch: 6| Step: 12
Training loss: 0.04044737666845322
Validation loss: 1.421590382053006

Epoch: 6| Step: 13
Training loss: 0.04959256574511528
Validation loss: 1.4184332252830587

Epoch: 702| Step: 0
Training loss: 0.05690539628267288
Validation loss: 1.4167675625893377

Epoch: 6| Step: 1
Training loss: 0.031302932649850845
Validation loss: 1.4168050096881004

Epoch: 6| Step: 2
Training loss: 0.04150070995092392
Validation loss: 1.3888537678667294

Epoch: 6| Step: 3
Training loss: 0.07868078351020813
Validation loss: 1.4055664244518484

Epoch: 6| Step: 4
Training loss: 0.04223208129405975
Validation loss: 1.4003022973255446

Epoch: 6| Step: 5
Training loss: 0.06106358394026756
Validation loss: 1.4097173989460032

Epoch: 6| Step: 6
Training loss: 0.07875997573137283
Validation loss: 1.4389822431789931

Epoch: 6| Step: 7
Training loss: 0.045750249177217484
Validation loss: 1.4011147804157709

Epoch: 6| Step: 8
Training loss: 0.05726926773786545
Validation loss: 1.4163867760730047

Epoch: 6| Step: 9
Training loss: 0.06942357122898102
Validation loss: 1.3863217535839285

Epoch: 6| Step: 10
Training loss: 0.041635870933532715
Validation loss: 1.413374782890402

Epoch: 6| Step: 11
Training loss: 0.043127357959747314
Validation loss: 1.4096437692642212

Epoch: 6| Step: 12
Training loss: 0.0370592400431633
Validation loss: 1.4190693023384258

Epoch: 6| Step: 13
Training loss: 0.06282973289489746
Validation loss: 1.455684063255146

Epoch: 703| Step: 0
Training loss: 0.05888313800096512
Validation loss: 1.4155723407704344

Epoch: 6| Step: 1
Training loss: 0.03196818009018898
Validation loss: 1.4036016848779493

Epoch: 6| Step: 2
Training loss: 0.024474598467350006
Validation loss: 1.4193838604034916

Epoch: 6| Step: 3
Training loss: 0.07134190201759338
Validation loss: 1.420251411776389

Epoch: 6| Step: 4
Training loss: 0.07442606985569
Validation loss: 1.4498569298815984

Epoch: 6| Step: 5
Training loss: 0.031650930643081665
Validation loss: 1.4412155715368127

Epoch: 6| Step: 6
Training loss: 0.06861289590597153
Validation loss: 1.472025413026092

Epoch: 6| Step: 7
Training loss: 0.0743885263800621
Validation loss: 1.4412908630986367

Epoch: 6| Step: 8
Training loss: 0.08302522450685501
Validation loss: 1.4397379621382682

Epoch: 6| Step: 9
Training loss: 0.055551521480083466
Validation loss: 1.458323004425213

Epoch: 6| Step: 10
Training loss: 0.03511287271976471
Validation loss: 1.445552441381639

Epoch: 6| Step: 11
Training loss: 0.06400702893733978
Validation loss: 1.4400154800825222

Epoch: 6| Step: 12
Training loss: 0.04971429705619812
Validation loss: 1.4298826814979635

Epoch: 6| Step: 13
Training loss: 0.046024613082408905
Validation loss: 1.4387945513571463

Epoch: 704| Step: 0
Training loss: 0.05121764540672302
Validation loss: 1.4229507471925469

Epoch: 6| Step: 1
Training loss: 0.04741610586643219
Validation loss: 1.4496305565680228

Epoch: 6| Step: 2
Training loss: 0.042551834136247635
Validation loss: 1.418945695764275

Epoch: 6| Step: 3
Training loss: 0.0431104376912117
Validation loss: 1.4484887417926584

Epoch: 6| Step: 4
Training loss: 0.03299170359969139
Validation loss: 1.444684120916551

Epoch: 6| Step: 5
Training loss: 0.04653923213481903
Validation loss: 1.4553296501918505

Epoch: 6| Step: 6
Training loss: 0.0192549005150795
Validation loss: 1.4389554992798836

Epoch: 6| Step: 7
Training loss: 0.029482141137123108
Validation loss: 1.4422537447303854

Epoch: 6| Step: 8
Training loss: 0.042815692722797394
Validation loss: 1.4553514680554789

Epoch: 6| Step: 9
Training loss: 0.0629575103521347
Validation loss: 1.4571902444285731

Epoch: 6| Step: 10
Training loss: 0.06580448150634766
Validation loss: 1.4616002241770427

Epoch: 6| Step: 11
Training loss: 0.06510797888040543
Validation loss: 1.4572082809222642

Epoch: 6| Step: 12
Training loss: 0.0336410291492939
Validation loss: 1.4543986564041467

Epoch: 6| Step: 13
Training loss: 0.03290800377726555
Validation loss: 1.4578538758139457

Epoch: 705| Step: 0
Training loss: 0.037793904542922974
Validation loss: 1.463037005034826

Epoch: 6| Step: 1
Training loss: 0.04909800365567207
Validation loss: 1.4724943176392586

Epoch: 6| Step: 2
Training loss: 0.05006660148501396
Validation loss: 1.4816908080090758

Epoch: 6| Step: 3
Training loss: 0.07292276620864868
Validation loss: 1.4580802456025155

Epoch: 6| Step: 4
Training loss: 0.04865267872810364
Validation loss: 1.4464706964390253

Epoch: 6| Step: 5
Training loss: 0.06034193933010101
Validation loss: 1.4529340549181866

Epoch: 6| Step: 6
Training loss: 0.05992530286312103
Validation loss: 1.4486490244506507

Epoch: 6| Step: 7
Training loss: 0.06653652340173721
Validation loss: 1.4490623435666483

Epoch: 6| Step: 8
Training loss: 0.04285287857055664
Validation loss: 1.4374001622200012

Epoch: 6| Step: 9
Training loss: 0.056334659457206726
Validation loss: 1.4247953744344815

Epoch: 6| Step: 10
Training loss: 0.06160370260477066
Validation loss: 1.4418838383049093

Epoch: 6| Step: 11
Training loss: 0.04409756511449814
Validation loss: 1.4225251828470538

Epoch: 6| Step: 12
Training loss: 0.06017647311091423
Validation loss: 1.4110905470386628

Epoch: 6| Step: 13
Training loss: 0.04373963177204132
Validation loss: 1.4212062974129953

Epoch: 706| Step: 0
Training loss: 0.03706364333629608
Validation loss: 1.3984608393843456

Epoch: 6| Step: 1
Training loss: 0.05494796112179756
Validation loss: 1.416848369823989

Epoch: 6| Step: 2
Training loss: 0.07887120544910431
Validation loss: 1.4020909211968864

Epoch: 6| Step: 3
Training loss: 0.03219620883464813
Validation loss: 1.4212163020205755

Epoch: 6| Step: 4
Training loss: 0.043146371841430664
Validation loss: 1.4233671849773777

Epoch: 6| Step: 5
Training loss: 0.04889707267284393
Validation loss: 1.4226819763901413

Epoch: 6| Step: 6
Training loss: 0.06881023943424225
Validation loss: 1.4017561174208117

Epoch: 6| Step: 7
Training loss: 0.05943111702799797
Validation loss: 1.4133662728853122

Epoch: 6| Step: 8
Training loss: 0.06151353567838669
Validation loss: 1.4272556394659064

Epoch: 6| Step: 9
Training loss: 0.03598617762327194
Validation loss: 1.4463423887888591

Epoch: 6| Step: 10
Training loss: 0.09694360941648483
Validation loss: 1.4458457949340984

Epoch: 6| Step: 11
Training loss: 0.04415252059698105
Validation loss: 1.4053017811108661

Epoch: 6| Step: 12
Training loss: 0.0500941164791584
Validation loss: 1.4149183496352165

Epoch: 6| Step: 13
Training loss: 0.039543554186820984
Validation loss: 1.4047406552940287

Epoch: 707| Step: 0
Training loss: 0.0706958919763565
Validation loss: 1.4082370842656782

Epoch: 6| Step: 1
Training loss: 0.0253619197756052
Validation loss: 1.4082827273235525

Epoch: 6| Step: 2
Training loss: 0.051404476165771484
Validation loss: 1.4016804336219706

Epoch: 6| Step: 3
Training loss: 0.0651785284280777
Validation loss: 1.4059021152475828

Epoch: 6| Step: 4
Training loss: 0.06545854359865189
Validation loss: 1.4174186119469263

Epoch: 6| Step: 5
Training loss: 0.05600958317518234
Validation loss: 1.4074713318578658

Epoch: 6| Step: 6
Training loss: 0.06295223534107208
Validation loss: 1.4194194834719422

Epoch: 6| Step: 7
Training loss: 0.04456179216504097
Validation loss: 1.4100425845833235

Epoch: 6| Step: 8
Training loss: 0.04626290500164032
Validation loss: 1.3864541553681897

Epoch: 6| Step: 9
Training loss: 0.06293204426765442
Validation loss: 1.3868628112218713

Epoch: 6| Step: 10
Training loss: 0.02526227757334709
Validation loss: 1.397346765764298

Epoch: 6| Step: 11
Training loss: 0.050555430352687836
Validation loss: 1.3944460358670963

Epoch: 6| Step: 12
Training loss: 0.07572421431541443
Validation loss: 1.4289290353816042

Epoch: 6| Step: 13
Training loss: 0.04055015742778778
Validation loss: 1.4320445855458577

Epoch: 708| Step: 0
Training loss: 0.08659590780735016
Validation loss: 1.3800594345215829

Epoch: 6| Step: 1
Training loss: 0.04062114283442497
Validation loss: 1.37678905969025

Epoch: 6| Step: 2
Training loss: 0.03479554504156113
Validation loss: 1.380846913142871

Epoch: 6| Step: 3
Training loss: 0.04644054174423218
Validation loss: 1.385720331181762

Epoch: 6| Step: 4
Training loss: 0.028677230700850487
Validation loss: 1.3637028304479455

Epoch: 6| Step: 5
Training loss: 0.05117807537317276
Validation loss: 1.3453486311820246

Epoch: 6| Step: 6
Training loss: 0.041159261018037796
Validation loss: 1.3759319807893486

Epoch: 6| Step: 7
Training loss: 0.05092479661107063
Validation loss: 1.3669914481460408

Epoch: 6| Step: 8
Training loss: 0.06996577978134155
Validation loss: 1.3641678473000884

Epoch: 6| Step: 9
Training loss: 0.05756181478500366
Validation loss: 1.35562865964828

Epoch: 6| Step: 10
Training loss: 0.07664081454277039
Validation loss: 1.3745859797282884

Epoch: 6| Step: 11
Training loss: 0.060319069772958755
Validation loss: 1.369344408794116

Epoch: 6| Step: 12
Training loss: 0.06833279132843018
Validation loss: 1.376623265204891

Epoch: 6| Step: 13
Training loss: 0.08059097826480865
Validation loss: 1.3850153505161245

Epoch: 709| Step: 0
Training loss: 0.05941719934344292
Validation loss: 1.3902507661491312

Epoch: 6| Step: 1
Training loss: 0.06801575422286987
Validation loss: 1.3939412204168176

Epoch: 6| Step: 2
Training loss: 0.0726519376039505
Validation loss: 1.4100088752726072

Epoch: 6| Step: 3
Training loss: 0.0366731658577919
Validation loss: 1.4202272468997585

Epoch: 6| Step: 4
Training loss: 0.026522094383835793
Validation loss: 1.4232054705260901

Epoch: 6| Step: 5
Training loss: 0.049287401139736176
Validation loss: 1.4257126649220784

Epoch: 6| Step: 6
Training loss: 0.05768847465515137
Validation loss: 1.43951637898722

Epoch: 6| Step: 7
Training loss: 0.04134897142648697
Validation loss: 1.4151630299065703

Epoch: 6| Step: 8
Training loss: 0.04227367043495178
Validation loss: 1.4329513772841422

Epoch: 6| Step: 9
Training loss: 0.03360827639698982
Validation loss: 1.4177448787996847

Epoch: 6| Step: 10
Training loss: 0.04735831171274185
Validation loss: 1.386669829327573

Epoch: 6| Step: 11
Training loss: 0.04942858964204788
Validation loss: 1.4290958969823775

Epoch: 6| Step: 12
Training loss: 0.06415075063705444
Validation loss: 1.4159685386124479

Epoch: 6| Step: 13
Training loss: 0.06555268168449402
Validation loss: 1.4413422192296674

Epoch: 710| Step: 0
Training loss: 0.07056183367967606
Validation loss: 1.448629762536736

Epoch: 6| Step: 1
Training loss: 0.06786184012889862
Validation loss: 1.4254185871411396

Epoch: 6| Step: 2
Training loss: 0.07090561836957932
Validation loss: 1.4400660978850497

Epoch: 6| Step: 3
Training loss: 0.06999614834785461
Validation loss: 1.4168765378254715

Epoch: 6| Step: 4
Training loss: 0.049933791160583496
Validation loss: 1.4270404525982436

Epoch: 6| Step: 5
Training loss: 0.03626294061541557
Validation loss: 1.3984442039202618

Epoch: 6| Step: 6
Training loss: 0.0355374850332737
Validation loss: 1.3889260817599554

Epoch: 6| Step: 7
Training loss: 0.04157833755016327
Validation loss: 1.4087655018734675

Epoch: 6| Step: 8
Training loss: 0.03343471884727478
Validation loss: 1.429439539550453

Epoch: 6| Step: 9
Training loss: 0.05031825602054596
Validation loss: 1.4191683979444607

Epoch: 6| Step: 10
Training loss: 0.03029051050543785
Validation loss: 1.4018343840875933

Epoch: 6| Step: 11
Training loss: 0.055728137493133545
Validation loss: 1.4175500126295193

Epoch: 6| Step: 12
Training loss: 0.05866608768701553
Validation loss: 1.4027985315169058

Epoch: 6| Step: 13
Training loss: 0.03279252350330353
Validation loss: 1.3989948816196893

Epoch: 711| Step: 0
Training loss: 0.023554302752017975
Validation loss: 1.3977634035130984

Epoch: 6| Step: 1
Training loss: 0.038634393364191055
Validation loss: 1.381124714369415

Epoch: 6| Step: 2
Training loss: 0.06748205423355103
Validation loss: 1.381331855250943

Epoch: 6| Step: 3
Training loss: 0.037981487810611725
Validation loss: 1.3700722584160425

Epoch: 6| Step: 4
Training loss: 0.05367520451545715
Validation loss: 1.4025448124895814

Epoch: 6| Step: 5
Training loss: 0.04276244714856148
Validation loss: 1.333213694633976

Epoch: 6| Step: 6
Training loss: 0.04228862375020981
Validation loss: 1.3694364409292898

Epoch: 6| Step: 7
Training loss: 0.06597922742366791
Validation loss: 1.3875441307662635

Epoch: 6| Step: 8
Training loss: 0.0404319129884243
Validation loss: 1.382897078350026

Epoch: 6| Step: 9
Training loss: 0.044678930193185806
Validation loss: 1.3693684531796364

Epoch: 6| Step: 10
Training loss: 0.08123328536748886
Validation loss: 1.369347345444464

Epoch: 6| Step: 11
Training loss: 0.04263162612915039
Validation loss: 1.3630095995882505

Epoch: 6| Step: 12
Training loss: 0.0710831731557846
Validation loss: 1.3718423997202227

Epoch: 6| Step: 13
Training loss: 0.0702069103717804
Validation loss: 1.3566083908081055

Epoch: 712| Step: 0
Training loss: 0.034309498965740204
Validation loss: 1.363030646436958

Epoch: 6| Step: 1
Training loss: 0.03102787584066391
Validation loss: 1.3686720209736978

Epoch: 6| Step: 2
Training loss: 0.04477428272366524
Validation loss: 1.3749001923427786

Epoch: 6| Step: 3
Training loss: 0.05981111526489258
Validation loss: 1.3980574248939432

Epoch: 6| Step: 4
Training loss: 0.064933180809021
Validation loss: 1.4037922300318235

Epoch: 6| Step: 5
Training loss: 0.02758331410586834
Validation loss: 1.4180796736030168

Epoch: 6| Step: 6
Training loss: 0.04622682183980942
Validation loss: 1.4024154524649344

Epoch: 6| Step: 7
Training loss: 0.07113434374332428
Validation loss: 1.4360102312539214

Epoch: 6| Step: 8
Training loss: 0.04317741096019745
Validation loss: 1.448231743228051

Epoch: 6| Step: 9
Training loss: 0.052489373832941055
Validation loss: 1.4434975103665424

Epoch: 6| Step: 10
Training loss: 0.057108908891677856
Validation loss: 1.4436007891931841

Epoch: 6| Step: 11
Training loss: 0.04304893687367439
Validation loss: 1.4340982770407071

Epoch: 6| Step: 12
Training loss: 0.041920047253370285
Validation loss: 1.4390508067864243

Epoch: 6| Step: 13
Training loss: 0.05399608612060547
Validation loss: 1.425628299354225

Epoch: 713| Step: 0
Training loss: 0.027993660420179367
Validation loss: 1.3978979190190632

Epoch: 6| Step: 1
Training loss: 0.02566620521247387
Validation loss: 1.4098228164898452

Epoch: 6| Step: 2
Training loss: 0.023355456069111824
Validation loss: 1.3938200102057507

Epoch: 6| Step: 3
Training loss: 0.056724101305007935
Validation loss: 1.4102077458494453

Epoch: 6| Step: 4
Training loss: 0.03769403323531151
Validation loss: 1.4008754472578726

Epoch: 6| Step: 5
Training loss: 0.049876417964696884
Validation loss: 1.4223184726571525

Epoch: 6| Step: 6
Training loss: 0.04343906790018082
Validation loss: 1.3982875193319013

Epoch: 6| Step: 7
Training loss: 0.061218976974487305
Validation loss: 1.3819936142172864

Epoch: 6| Step: 8
Training loss: 0.03892894834280014
Validation loss: 1.4160055582241347

Epoch: 6| Step: 9
Training loss: 0.08885091543197632
Validation loss: 1.4012805159373949

Epoch: 6| Step: 10
Training loss: 0.040832892060279846
Validation loss: 1.3867597336410193

Epoch: 6| Step: 11
Training loss: 0.03960072621703148
Validation loss: 1.3853435042083904

Epoch: 6| Step: 12
Training loss: 0.03384128212928772
Validation loss: 1.375079849714874

Epoch: 6| Step: 13
Training loss: 0.06680960208177567
Validation loss: 1.384013847638202

Epoch: 714| Step: 0
Training loss: 0.03425954282283783
Validation loss: 1.3984524306430612

Epoch: 6| Step: 1
Training loss: 0.03748403117060661
Validation loss: 1.379500945409139

Epoch: 6| Step: 2
Training loss: 0.05720272660255432
Validation loss: 1.3913508461367698

Epoch: 6| Step: 3
Training loss: 0.03677607327699661
Validation loss: 1.3930107816573112

Epoch: 6| Step: 4
Training loss: 0.03443341329693794
Validation loss: 1.3907065378722323

Epoch: 6| Step: 5
Training loss: 0.05761796236038208
Validation loss: 1.388173202032684

Epoch: 6| Step: 6
Training loss: 0.053390905261039734
Validation loss: 1.3901434970158402

Epoch: 6| Step: 7
Training loss: 0.04700371250510216
Validation loss: 1.3985739651546683

Epoch: 6| Step: 8
Training loss: 0.05035549774765968
Validation loss: 1.3646558100177395

Epoch: 6| Step: 9
Training loss: 0.028228309005498886
Validation loss: 1.398286445166475

Epoch: 6| Step: 10
Training loss: 0.07411005347967148
Validation loss: 1.372469893065832

Epoch: 6| Step: 11
Training loss: 0.02511116862297058
Validation loss: 1.3787575665340628

Epoch: 6| Step: 12
Training loss: 0.06376685202121735
Validation loss: 1.4034441645427416

Epoch: 6| Step: 13
Training loss: 0.04249551519751549
Validation loss: 1.4002161410547072

Epoch: 715| Step: 0
Training loss: 0.04167186841368675
Validation loss: 1.4167892291981687

Epoch: 6| Step: 1
Training loss: 0.05458429455757141
Validation loss: 1.4235675104202763

Epoch: 6| Step: 2
Training loss: 0.06323016434907913
Validation loss: 1.421048996269062

Epoch: 6| Step: 3
Training loss: 0.07107037305831909
Validation loss: 1.4097045826655563

Epoch: 6| Step: 4
Training loss: 0.046519339084625244
Validation loss: 1.4280880792166597

Epoch: 6| Step: 5
Training loss: 0.023232514038681984
Validation loss: 1.4183233373908586

Epoch: 6| Step: 6
Training loss: 0.04986250028014183
Validation loss: 1.4305283946375693

Epoch: 6| Step: 7
Training loss: 0.044216088950634
Validation loss: 1.4261391009053876

Epoch: 6| Step: 8
Training loss: 0.0344153568148613
Validation loss: 1.4178726698762627

Epoch: 6| Step: 9
Training loss: 0.05929047614336014
Validation loss: 1.4156447533638246

Epoch: 6| Step: 10
Training loss: 0.06094720587134361
Validation loss: 1.4006073795339113

Epoch: 6| Step: 11
Training loss: 0.03671818599104881
Validation loss: 1.3982442591779976

Epoch: 6| Step: 12
Training loss: 0.029855072498321533
Validation loss: 1.3814687087971678

Epoch: 6| Step: 13
Training loss: 0.040464162826538086
Validation loss: 1.3818123488016025

Epoch: 716| Step: 0
Training loss: 0.05290257930755615
Validation loss: 1.3842303252989245

Epoch: 6| Step: 1
Training loss: 0.05120278149843216
Validation loss: 1.4369721130658222

Epoch: 6| Step: 2
Training loss: 0.07359710335731506
Validation loss: 1.3971031891402377

Epoch: 6| Step: 3
Training loss: 0.049893707036972046
Validation loss: 1.4291673655151038

Epoch: 6| Step: 4
Training loss: 0.05788972228765488
Validation loss: 1.4035880950189406

Epoch: 6| Step: 5
Training loss: 0.0354253351688385
Validation loss: 1.4077073617648053

Epoch: 6| Step: 6
Training loss: 0.0468311533331871
Validation loss: 1.423540057674531

Epoch: 6| Step: 7
Training loss: 0.04417530074715614
Validation loss: 1.3859944308316836

Epoch: 6| Step: 8
Training loss: 0.08401620388031006
Validation loss: 1.4277342109269993

Epoch: 6| Step: 9
Training loss: 0.05389335751533508
Validation loss: 1.4104743349936701

Epoch: 6| Step: 10
Training loss: 0.03932150453329086
Validation loss: 1.4170444383416125

Epoch: 6| Step: 11
Training loss: 0.03244120627641678
Validation loss: 1.4556213316097055

Epoch: 6| Step: 12
Training loss: 0.05651914328336716
Validation loss: 1.4722560708240797

Epoch: 6| Step: 13
Training loss: 0.020261632278561592
Validation loss: 1.4404776250162432

Epoch: 717| Step: 0
Training loss: 0.07638929039239883
Validation loss: 1.4555410390259118

Epoch: 6| Step: 1
Training loss: 0.032483138144016266
Validation loss: 1.4477628290012319

Epoch: 6| Step: 2
Training loss: 0.050691261887550354
Validation loss: 1.4395905771563131

Epoch: 6| Step: 3
Training loss: 0.03391623497009277
Validation loss: 1.4156154176240325

Epoch: 6| Step: 4
Training loss: 0.0414266474545002
Validation loss: 1.4167102665029547

Epoch: 6| Step: 5
Training loss: 0.047712501138448715
Validation loss: 1.468965445795367

Epoch: 6| Step: 6
Training loss: 0.0557515025138855
Validation loss: 1.4712600913099063

Epoch: 6| Step: 7
Training loss: 0.053691454231739044
Validation loss: 1.4744072844905238

Epoch: 6| Step: 8
Training loss: 0.07736176252365112
Validation loss: 1.4652745557087723

Epoch: 6| Step: 9
Training loss: 0.07013227045536041
Validation loss: 1.4561986397671443

Epoch: 6| Step: 10
Training loss: 0.0610046312212944
Validation loss: 1.4429462545661516

Epoch: 6| Step: 11
Training loss: 0.051170624792575836
Validation loss: 1.4437441287502166

Epoch: 6| Step: 12
Training loss: 0.03599606454372406
Validation loss: 1.4477048503455294

Epoch: 6| Step: 13
Training loss: 0.04427291452884674
Validation loss: 1.462305252270032

Epoch: 718| Step: 0
Training loss: 0.033819302916526794
Validation loss: 1.4253624626385268

Epoch: 6| Step: 1
Training loss: 0.030950063839554787
Validation loss: 1.4510462854498176

Epoch: 6| Step: 2
Training loss: 0.03355690836906433
Validation loss: 1.4425201018651326

Epoch: 6| Step: 3
Training loss: 0.04941672086715698
Validation loss: 1.452784489559871

Epoch: 6| Step: 4
Training loss: 0.02651263400912285
Validation loss: 1.4486637115478516

Epoch: 6| Step: 5
Training loss: 0.07117481529712677
Validation loss: 1.436543071141807

Epoch: 6| Step: 6
Training loss: 0.05500197410583496
Validation loss: 1.4493315322424776

Epoch: 6| Step: 7
Training loss: 0.033481962978839874
Validation loss: 1.4252948299531014

Epoch: 6| Step: 8
Training loss: 0.06475663930177689
Validation loss: 1.424637185629978

Epoch: 6| Step: 9
Training loss: 0.05715268850326538
Validation loss: 1.4369720361566032

Epoch: 6| Step: 10
Training loss: 0.05112036317586899
Validation loss: 1.4159666146001508

Epoch: 6| Step: 11
Training loss: 0.08606418967247009
Validation loss: 1.3779599038503503

Epoch: 6| Step: 12
Training loss: 0.05499235913157463
Validation loss: 1.423577549637005

Epoch: 6| Step: 13
Training loss: 0.056713368743658066
Validation loss: 1.3937395952081169

Epoch: 719| Step: 0
Training loss: 0.036127422004938126
Validation loss: 1.3854310076723817

Epoch: 6| Step: 1
Training loss: 0.0580698624253273
Validation loss: 1.38279894603196

Epoch: 6| Step: 2
Training loss: 0.059932637959718704
Validation loss: 1.383404040849337

Epoch: 6| Step: 3
Training loss: 0.038395773619413376
Validation loss: 1.388172843122995

Epoch: 6| Step: 4
Training loss: 0.05252213776111603
Validation loss: 1.364725500024775

Epoch: 6| Step: 5
Training loss: 0.0445370152592659
Validation loss: 1.3962235514835646

Epoch: 6| Step: 6
Training loss: 0.060314081609249115
Validation loss: 1.4069999328223608

Epoch: 6| Step: 7
Training loss: 0.03696417063474655
Validation loss: 1.3998457654829948

Epoch: 6| Step: 8
Training loss: 0.04447169601917267
Validation loss: 1.3817331226923133

Epoch: 6| Step: 9
Training loss: 0.05153202265501022
Validation loss: 1.3887051766918552

Epoch: 6| Step: 10
Training loss: 0.024673979729413986
Validation loss: 1.3748124196965208

Epoch: 6| Step: 11
Training loss: 0.06268934160470963
Validation loss: 1.4153873535894579

Epoch: 6| Step: 12
Training loss: 0.04120334982872009
Validation loss: 1.401521699402922

Epoch: 6| Step: 13
Training loss: 0.05554652214050293
Validation loss: 1.4310789935050472

Epoch: 720| Step: 0
Training loss: 0.0445975586771965
Validation loss: 1.4491561125683528

Epoch: 6| Step: 1
Training loss: 0.060550399124622345
Validation loss: 1.4600527696712042

Epoch: 6| Step: 2
Training loss: 0.023046789690852165
Validation loss: 1.441995855300657

Epoch: 6| Step: 3
Training loss: 0.03295200318098068
Validation loss: 1.4465689659118652

Epoch: 6| Step: 4
Training loss: 0.07665755599737167
Validation loss: 1.4568775917894097

Epoch: 6| Step: 5
Training loss: 0.026087064296007156
Validation loss: 1.4284928223138214

Epoch: 6| Step: 6
Training loss: 0.04725320637226105
Validation loss: 1.4210702001407582

Epoch: 6| Step: 7
Training loss: 0.04883449897170067
Validation loss: 1.4142788930605816

Epoch: 6| Step: 8
Training loss: 0.04487922042608261
Validation loss: 1.4241223130174863

Epoch: 6| Step: 9
Training loss: 0.05344834923744202
Validation loss: 1.4121651239292596

Epoch: 6| Step: 10
Training loss: 0.04065960273146629
Validation loss: 1.4111220490547918

Epoch: 6| Step: 11
Training loss: 0.0804547443985939
Validation loss: 1.4030678208156298

Epoch: 6| Step: 12
Training loss: 0.08708202838897705
Validation loss: 1.4203880961223314

Epoch: 6| Step: 13
Training loss: 0.05096757039427757
Validation loss: 1.3856730166301932

Epoch: 721| Step: 0
Training loss: 0.07999619096517563
Validation loss: 1.3708390907574726

Epoch: 6| Step: 1
Training loss: 0.058113958686590195
Validation loss: 1.42224165444733

Epoch: 6| Step: 2
Training loss: 0.04845670238137245
Validation loss: 1.4085432701213385

Epoch: 6| Step: 3
Training loss: 0.053406089544296265
Validation loss: 1.3765798563598304

Epoch: 6| Step: 4
Training loss: 0.06204623728990555
Validation loss: 1.422000087717528

Epoch: 6| Step: 5
Training loss: 0.04375792294740677
Validation loss: 1.3768252441959996

Epoch: 6| Step: 6
Training loss: 0.07841424643993378
Validation loss: 1.416763811983088

Epoch: 6| Step: 7
Training loss: 0.08011554181575775
Validation loss: 1.410748976533131

Epoch: 6| Step: 8
Training loss: 0.05080181360244751
Validation loss: 1.4230482283458914

Epoch: 6| Step: 9
Training loss: 0.05845489352941513
Validation loss: 1.391983405236275

Epoch: 6| Step: 10
Training loss: 0.06957268714904785
Validation loss: 1.4209663566722666

Epoch: 6| Step: 11
Training loss: 0.046229660511016846
Validation loss: 1.43199324095121

Epoch: 6| Step: 12
Training loss: 0.05142385885119438
Validation loss: 1.4467342771509641

Epoch: 6| Step: 13
Training loss: 0.039881058037281036
Validation loss: 1.4422150818250512

Epoch: 722| Step: 0
Training loss: 0.05042648687958717
Validation loss: 1.468740047947053

Epoch: 6| Step: 1
Training loss: 0.026307981461286545
Validation loss: 1.4474485478093546

Epoch: 6| Step: 2
Training loss: 0.0759127289056778
Validation loss: 1.4625333368137319

Epoch: 6| Step: 3
Training loss: 0.07245136797428131
Validation loss: 1.4655330373394875

Epoch: 6| Step: 4
Training loss: 0.05664091557264328
Validation loss: 1.463718383542953

Epoch: 6| Step: 5
Training loss: 0.04636275768280029
Validation loss: 1.4155119388334212

Epoch: 6| Step: 6
Training loss: 0.03547542169690132
Validation loss: 1.4135189299942346

Epoch: 6| Step: 7
Training loss: 0.052250802516937256
Validation loss: 1.3883775844368884

Epoch: 6| Step: 8
Training loss: 0.03583599254488945
Validation loss: 1.40431684319691

Epoch: 6| Step: 9
Training loss: 0.0712197944521904
Validation loss: 1.4027878776673348

Epoch: 6| Step: 10
Training loss: 0.06850095093250275
Validation loss: 1.3773663184976066

Epoch: 6| Step: 11
Training loss: 0.03799010068178177
Validation loss: 1.4014312259612545

Epoch: 6| Step: 12
Training loss: 0.047454483807086945
Validation loss: 1.37790673394357

Epoch: 6| Step: 13
Training loss: 0.03941173851490021
Validation loss: 1.4022574963108185

Epoch: 723| Step: 0
Training loss: 0.07012293487787247
Validation loss: 1.3911713246376283

Epoch: 6| Step: 1
Training loss: 0.027042021974921227
Validation loss: 1.3940615871901154

Epoch: 6| Step: 2
Training loss: 0.05070190131664276
Validation loss: 1.3934072281724663

Epoch: 6| Step: 3
Training loss: 0.0641215369105339
Validation loss: 1.3918639908554733

Epoch: 6| Step: 4
Training loss: 0.08118094503879547
Validation loss: 1.3850572109222412

Epoch: 6| Step: 5
Training loss: 0.05245952308177948
Validation loss: 1.3955021058359454

Epoch: 6| Step: 6
Training loss: 0.044784851372241974
Validation loss: 1.3956833859925628

Epoch: 6| Step: 7
Training loss: 0.02697850577533245
Validation loss: 1.4259383293890184

Epoch: 6| Step: 8
Training loss: 0.05335193872451782
Validation loss: 1.3869169117302023

Epoch: 6| Step: 9
Training loss: 0.042198359966278076
Validation loss: 1.4279650686889567

Epoch: 6| Step: 10
Training loss: 0.06619551032781601
Validation loss: 1.4220750024241786

Epoch: 6| Step: 11
Training loss: 0.027147887274622917
Validation loss: 1.394399450030378

Epoch: 6| Step: 12
Training loss: 0.09424325823783875
Validation loss: 1.4264465801177486

Epoch: 6| Step: 13
Training loss: 0.028528869152069092
Validation loss: 1.4104412742840347

Epoch: 724| Step: 0
Training loss: 0.04068628326058388
Validation loss: 1.4418437673199562

Epoch: 6| Step: 1
Training loss: 0.021002694964408875
Validation loss: 1.4652415219173636

Epoch: 6| Step: 2
Training loss: 0.061092302203178406
Validation loss: 1.4368915621952345

Epoch: 6| Step: 3
Training loss: 0.05268382281064987
Validation loss: 1.4718216715320465

Epoch: 6| Step: 4
Training loss: 0.04830164462327957
Validation loss: 1.442762203114007

Epoch: 6| Step: 5
Training loss: 0.04557332396507263
Validation loss: 1.4390011525923205

Epoch: 6| Step: 6
Training loss: 0.06628097593784332
Validation loss: 1.4507389119876328

Epoch: 6| Step: 7
Training loss: 0.03062799945473671
Validation loss: 1.4369502323929981

Epoch: 6| Step: 8
Training loss: 0.06483326852321625
Validation loss: 1.4463986466007848

Epoch: 6| Step: 9
Training loss: 0.05071414262056351
Validation loss: 1.4473129459606704

Epoch: 6| Step: 10
Training loss: 0.06281110644340515
Validation loss: 1.425614341612785

Epoch: 6| Step: 11
Training loss: 0.06699714064598083
Validation loss: 1.4668154665218887

Epoch: 6| Step: 12
Training loss: 0.029063943773508072
Validation loss: 1.437541579687467

Epoch: 6| Step: 13
Training loss: 0.059899840503931046
Validation loss: 1.4384124843023156

Epoch: 725| Step: 0
Training loss: 0.039693817496299744
Validation loss: 1.4219518335916663

Epoch: 6| Step: 1
Training loss: 0.045739490538835526
Validation loss: 1.4093864669081986

Epoch: 6| Step: 2
Training loss: 0.07045933604240417
Validation loss: 1.43074413909707

Epoch: 6| Step: 3
Training loss: 0.04513287916779518
Validation loss: 1.4360092506613782

Epoch: 6| Step: 4
Training loss: 0.049099311232566833
Validation loss: 1.4561751350279777

Epoch: 6| Step: 5
Training loss: 0.056679703295230865
Validation loss: 1.4420059739902455

Epoch: 6| Step: 6
Training loss: 0.07893050462007523
Validation loss: 1.455724282931256

Epoch: 6| Step: 7
Training loss: 0.04373437911272049
Validation loss: 1.4350418147220407

Epoch: 6| Step: 8
Training loss: 0.030342670157551765
Validation loss: 1.4340604928232008

Epoch: 6| Step: 9
Training loss: 0.03144018352031708
Validation loss: 1.4317064413460352

Epoch: 6| Step: 10
Training loss: 0.05420180782675743
Validation loss: 1.3979718685150146

Epoch: 6| Step: 11
Training loss: 0.033547382801771164
Validation loss: 1.4389726846448836

Epoch: 6| Step: 12
Training loss: 0.04312936216592789
Validation loss: 1.4292742065204087

Epoch: 6| Step: 13
Training loss: 0.041993483901023865
Validation loss: 1.4225854117383239

Epoch: 726| Step: 0
Training loss: 0.04149651899933815
Validation loss: 1.4067677310718003

Epoch: 6| Step: 1
Training loss: 0.04363921657204628
Validation loss: 1.4242879318934616

Epoch: 6| Step: 2
Training loss: 0.04271116852760315
Validation loss: 1.4287530824702273

Epoch: 6| Step: 3
Training loss: 0.03840439394116402
Validation loss: 1.4253320309423632

Epoch: 6| Step: 4
Training loss: 0.036204852163791656
Validation loss: 1.415014269531414

Epoch: 6| Step: 5
Training loss: 0.0381791889667511
Validation loss: 1.413187849906183

Epoch: 6| Step: 6
Training loss: 0.057848066091537476
Validation loss: 1.4158305762916483

Epoch: 6| Step: 7
Training loss: 0.051642630249261856
Validation loss: 1.436753442210536

Epoch: 6| Step: 8
Training loss: 0.03999859467148781
Validation loss: 1.4164100936664048

Epoch: 6| Step: 9
Training loss: 0.05273769795894623
Validation loss: 1.4063809020544893

Epoch: 6| Step: 10
Training loss: 0.06518819183111191
Validation loss: 1.4488368944455219

Epoch: 6| Step: 11
Training loss: 0.05554567649960518
Validation loss: 1.456161122168264

Epoch: 6| Step: 12
Training loss: 0.039177149534225464
Validation loss: 1.4307825565338135

Epoch: 6| Step: 13
Training loss: 0.042076773941516876
Validation loss: 1.4228541069133307

Epoch: 727| Step: 0
Training loss: 0.051682546734809875
Validation loss: 1.4132570432078453

Epoch: 6| Step: 1
Training loss: 0.0782158374786377
Validation loss: 1.4090638724706506

Epoch: 6| Step: 2
Training loss: 0.036621928215026855
Validation loss: 1.4138820402083858

Epoch: 6| Step: 3
Training loss: 0.04729850962758064
Validation loss: 1.3857015377731734

Epoch: 6| Step: 4
Training loss: 0.06736911833286285
Validation loss: 1.3774806478972077

Epoch: 6| Step: 5
Training loss: 0.04812367260456085
Validation loss: 1.4051112577479372

Epoch: 6| Step: 6
Training loss: 0.047504641115665436
Validation loss: 1.388515672376079

Epoch: 6| Step: 7
Training loss: 0.02781245857477188
Validation loss: 1.3921830154234363

Epoch: 6| Step: 8
Training loss: 0.035007819533348083
Validation loss: 1.4130533959275933

Epoch: 6| Step: 9
Training loss: 0.062452785670757294
Validation loss: 1.4055255279746106

Epoch: 6| Step: 10
Training loss: 0.03991924598813057
Validation loss: 1.4105548525369296

Epoch: 6| Step: 11
Training loss: 0.03880373388528824
Validation loss: 1.4394089047626784

Epoch: 6| Step: 12
Training loss: 0.04979553818702698
Validation loss: 1.4332314011871174

Epoch: 6| Step: 13
Training loss: 0.04767812788486481
Validation loss: 1.4394651536018617

Epoch: 728| Step: 0
Training loss: 0.07081566005945206
Validation loss: 1.4628852182818997

Epoch: 6| Step: 1
Training loss: 0.04831629991531372
Validation loss: 1.4874784369622507

Epoch: 6| Step: 2
Training loss: 0.07132543623447418
Validation loss: 1.4907804650645102

Epoch: 6| Step: 3
Training loss: 0.03695811703801155
Validation loss: 1.5035379073953117

Epoch: 6| Step: 4
Training loss: 0.03689877316355705
Validation loss: 1.4900520687462182

Epoch: 6| Step: 5
Training loss: 0.0358060859143734
Validation loss: 1.5140756971092635

Epoch: 6| Step: 6
Training loss: 0.07793267071247101
Validation loss: 1.484548904562509

Epoch: 6| Step: 7
Training loss: 0.07538919895887375
Validation loss: 1.484876637817711

Epoch: 6| Step: 8
Training loss: 0.10030859708786011
Validation loss: 1.4986391561005705

Epoch: 6| Step: 9
Training loss: 0.05174665525555611
Validation loss: 1.4802318362779514

Epoch: 6| Step: 10
Training loss: 0.048287808895111084
Validation loss: 1.4740520408076625

Epoch: 6| Step: 11
Training loss: 0.024715660139918327
Validation loss: 1.4528401949072396

Epoch: 6| Step: 12
Training loss: 0.07406973838806152
Validation loss: 1.45108772477796

Epoch: 6| Step: 13
Training loss: 0.05434984713792801
Validation loss: 1.463199450764605

Epoch: 729| Step: 0
Training loss: 0.046985261142253876
Validation loss: 1.4525078214624876

Epoch: 6| Step: 1
Training loss: 0.08254511654376984
Validation loss: 1.4411710231534895

Epoch: 6| Step: 2
Training loss: 0.044713206589221954
Validation loss: 1.4445835569853425

Epoch: 6| Step: 3
Training loss: 0.061274170875549316
Validation loss: 1.4175681388506325

Epoch: 6| Step: 4
Training loss: 0.04022900015115738
Validation loss: 1.4468591392681163

Epoch: 6| Step: 5
Training loss: 0.09673130512237549
Validation loss: 1.427713067300858

Epoch: 6| Step: 6
Training loss: 0.04873481020331383
Validation loss: 1.4261888009245678

Epoch: 6| Step: 7
Training loss: 0.05373538285493851
Validation loss: 1.4188597227937432

Epoch: 6| Step: 8
Training loss: 0.03527442365884781
Validation loss: 1.4366023162359833

Epoch: 6| Step: 9
Training loss: 0.03146880865097046
Validation loss: 1.4520353668479509

Epoch: 6| Step: 10
Training loss: 0.05169998109340668
Validation loss: 1.4490003931906916

Epoch: 6| Step: 11
Training loss: 0.05722080543637276
Validation loss: 1.413820832006393

Epoch: 6| Step: 12
Training loss: 0.09560421854257584
Validation loss: 1.4318967288540256

Epoch: 6| Step: 13
Training loss: 0.021462665870785713
Validation loss: 1.4416106285587433

Epoch: 730| Step: 0
Training loss: 0.04636508226394653
Validation loss: 1.4472643149796354

Epoch: 6| Step: 1
Training loss: 0.02855859510600567
Validation loss: 1.4302933651913878

Epoch: 6| Step: 2
Training loss: 0.045210421085357666
Validation loss: 1.4668290256172098

Epoch: 6| Step: 3
Training loss: 0.06722705066204071
Validation loss: 1.4782609426847069

Epoch: 6| Step: 4
Training loss: 0.0481821671128273
Validation loss: 1.4735535601133942

Epoch: 6| Step: 5
Training loss: 0.04931386932730675
Validation loss: 1.4441095603409635

Epoch: 6| Step: 6
Training loss: 0.08194901794195175
Validation loss: 1.4494480586821032

Epoch: 6| Step: 7
Training loss: 0.045901358127593994
Validation loss: 1.4242620532230665

Epoch: 6| Step: 8
Training loss: 0.054104033857584
Validation loss: 1.445350690554547

Epoch: 6| Step: 9
Training loss: 0.03211496025323868
Validation loss: 1.4281787910769064

Epoch: 6| Step: 10
Training loss: 0.04078178107738495
Validation loss: 1.4429894711381646

Epoch: 6| Step: 11
Training loss: 0.08148231357336044
Validation loss: 1.4416600888775242

Epoch: 6| Step: 12
Training loss: 0.0748148262500763
Validation loss: 1.4414771872182046

Epoch: 6| Step: 13
Training loss: 0.030389918014407158
Validation loss: 1.4374535211952784

Epoch: 731| Step: 0
Training loss: 0.03132013976573944
Validation loss: 1.4459492198882564

Epoch: 6| Step: 1
Training loss: 0.042801521718502045
Validation loss: 1.4141047013703214

Epoch: 6| Step: 2
Training loss: 0.041933462023735046
Validation loss: 1.4426667446731238

Epoch: 6| Step: 3
Training loss: 0.042759791016578674
Validation loss: 1.4582490600565428

Epoch: 6| Step: 4
Training loss: 0.04172605648636818
Validation loss: 1.437100782830228

Epoch: 6| Step: 5
Training loss: 0.03835069760680199
Validation loss: 1.4391354181433236

Epoch: 6| Step: 6
Training loss: 0.05628480017185211
Validation loss: 1.4555919990744641

Epoch: 6| Step: 7
Training loss: 0.05952160060405731
Validation loss: 1.4656269857960362

Epoch: 6| Step: 8
Training loss: 0.061994366347789764
Validation loss: 1.4816518445168771

Epoch: 6| Step: 9
Training loss: 0.0862099900841713
Validation loss: 1.4737002042032057

Epoch: 6| Step: 10
Training loss: 0.0404297299683094
Validation loss: 1.4612570539597542

Epoch: 6| Step: 11
Training loss: 0.0672817975282669
Validation loss: 1.4783927522679812

Epoch: 6| Step: 12
Training loss: 0.06209059804677963
Validation loss: 1.4683757501263772

Epoch: 6| Step: 13
Training loss: 0.03160874918103218
Validation loss: 1.452920175367786

Epoch: 732| Step: 0
Training loss: 0.07415182888507843
Validation loss: 1.4518741317974624

Epoch: 6| Step: 1
Training loss: 0.053149253129959106
Validation loss: 1.4426807447146344

Epoch: 6| Step: 2
Training loss: 0.03042907454073429
Validation loss: 1.4512686780703965

Epoch: 6| Step: 3
Training loss: 0.035405196249485016
Validation loss: 1.4265929678434968

Epoch: 6| Step: 4
Training loss: 0.031850431114435196
Validation loss: 1.441851592832996

Epoch: 6| Step: 5
Training loss: 0.05172686651349068
Validation loss: 1.4336291513135355

Epoch: 6| Step: 6
Training loss: 0.08005712926387787
Validation loss: 1.4534295470483842

Epoch: 6| Step: 7
Training loss: 0.05048244446516037
Validation loss: 1.4405858228283543

Epoch: 6| Step: 8
Training loss: 0.03006364032626152
Validation loss: 1.4249299239086848

Epoch: 6| Step: 9
Training loss: 0.04112345725297928
Validation loss: 1.4072973356452039

Epoch: 6| Step: 10
Training loss: 0.042834457010030746
Validation loss: 1.42807020935961

Epoch: 6| Step: 11
Training loss: 0.03264828398823738
Validation loss: 1.4257671128037155

Epoch: 6| Step: 12
Training loss: 0.06412583589553833
Validation loss: 1.4265199540763773

Epoch: 6| Step: 13
Training loss: 0.03883213549852371
Validation loss: 1.4238277609630297

Epoch: 733| Step: 0
Training loss: 0.04909191280603409
Validation loss: 1.4321978066557197

Epoch: 6| Step: 1
Training loss: 0.0348302498459816
Validation loss: 1.4334011154790078

Epoch: 6| Step: 2
Training loss: 0.03688867390155792
Validation loss: 1.4008083907506799

Epoch: 6| Step: 3
Training loss: 0.07725435495376587
Validation loss: 1.4061290640984812

Epoch: 6| Step: 4
Training loss: 0.03113534301519394
Validation loss: 1.428663799839635

Epoch: 6| Step: 5
Training loss: 0.07394597679376602
Validation loss: 1.409104367738129

Epoch: 6| Step: 6
Training loss: 0.040726736187934875
Validation loss: 1.4170448664695985

Epoch: 6| Step: 7
Training loss: 0.07088277488946915
Validation loss: 1.3889091924954486

Epoch: 6| Step: 8
Training loss: 0.056037068367004395
Validation loss: 1.3910875596025938

Epoch: 6| Step: 9
Training loss: 0.036019109189510345
Validation loss: 1.4058436514228903

Epoch: 6| Step: 10
Training loss: 0.07485237717628479
Validation loss: 1.389246250993462

Epoch: 6| Step: 11
Training loss: 0.03728589415550232
Validation loss: 1.3922129356732933

Epoch: 6| Step: 12
Training loss: 0.05187160521745682
Validation loss: 1.3970585247521758

Epoch: 6| Step: 13
Training loss: 0.025167755782604218
Validation loss: 1.3953112716315894

Epoch: 734| Step: 0
Training loss: 0.051366761326789856
Validation loss: 1.433648802900827

Epoch: 6| Step: 1
Training loss: 0.05916619300842285
Validation loss: 1.414257009824117

Epoch: 6| Step: 2
Training loss: 0.061900850385427475
Validation loss: 1.4167707299673429

Epoch: 6| Step: 3
Training loss: 0.0261661559343338
Validation loss: 1.4189388284119226

Epoch: 6| Step: 4
Training loss: 0.07144622504711151
Validation loss: 1.420911333894217

Epoch: 6| Step: 5
Training loss: 0.06084319204092026
Validation loss: 1.4311068654060364

Epoch: 6| Step: 6
Training loss: 0.03640761226415634
Validation loss: 1.4201837214090491

Epoch: 6| Step: 7
Training loss: 0.023482052609324455
Validation loss: 1.4302310341147966

Epoch: 6| Step: 8
Training loss: 0.04525180906057358
Validation loss: 1.4125362724386237

Epoch: 6| Step: 9
Training loss: 0.05705959349870682
Validation loss: 1.40845997230981

Epoch: 6| Step: 10
Training loss: 0.05707157403230667
Validation loss: 1.4184451218574279

Epoch: 6| Step: 11
Training loss: 0.06992921978235245
Validation loss: 1.4277308275622707

Epoch: 6| Step: 12
Training loss: 0.09656953811645508
Validation loss: 1.4475232990839149

Epoch: 6| Step: 13
Training loss: 0.038481876254081726
Validation loss: 1.434584920124341

Epoch: 735| Step: 0
Training loss: 0.0753917321562767
Validation loss: 1.4574890713537894

Epoch: 6| Step: 1
Training loss: 0.03375028073787689
Validation loss: 1.4538520702751734

Epoch: 6| Step: 2
Training loss: 0.06469939649105072
Validation loss: 1.45059895899988

Epoch: 6| Step: 3
Training loss: 0.05218460410833359
Validation loss: 1.4568341329533567

Epoch: 6| Step: 4
Training loss: 0.055587559938430786
Validation loss: 1.4467980041298816

Epoch: 6| Step: 5
Training loss: 0.057717062532901764
Validation loss: 1.4395613362712245

Epoch: 6| Step: 6
Training loss: 0.017950180917978287
Validation loss: 1.4016238495867739

Epoch: 6| Step: 7
Training loss: 0.06073392555117607
Validation loss: 1.4337407196721723

Epoch: 6| Step: 8
Training loss: 0.06052761524915695
Validation loss: 1.4160638611803773

Epoch: 6| Step: 9
Training loss: 0.04557529091835022
Validation loss: 1.409954914482691

Epoch: 6| Step: 10
Training loss: 0.05944584310054779
Validation loss: 1.421090409319888

Epoch: 6| Step: 11
Training loss: 0.0560406856238842
Validation loss: 1.3965946730747019

Epoch: 6| Step: 12
Training loss: 0.0347750186920166
Validation loss: 1.391999178035285

Epoch: 6| Step: 13
Training loss: 0.032684240490198135
Validation loss: 1.3800256790653351

Epoch: 736| Step: 0
Training loss: 0.03922554850578308
Validation loss: 1.3799955934606574

Epoch: 6| Step: 1
Training loss: 0.04024089127779007
Validation loss: 1.378670766789426

Epoch: 6| Step: 2
Training loss: 0.03169236332178116
Validation loss: 1.3936755657196045

Epoch: 6| Step: 3
Training loss: 0.04315371811389923
Validation loss: 1.4327713968933269

Epoch: 6| Step: 4
Training loss: 0.036520786583423615
Validation loss: 1.4356616658549155

Epoch: 6| Step: 5
Training loss: 0.08462277799844742
Validation loss: 1.412570373986357

Epoch: 6| Step: 6
Training loss: 0.03669612109661102
Validation loss: 1.4164188818265033

Epoch: 6| Step: 7
Training loss: 0.04276224970817566
Validation loss: 1.4160786239049767

Epoch: 6| Step: 8
Training loss: 0.07257495820522308
Validation loss: 1.4290392950016966

Epoch: 6| Step: 9
Training loss: 0.060537952929735184
Validation loss: 1.447421117495465

Epoch: 6| Step: 10
Training loss: 0.020654048770666122
Validation loss: 1.448981418404528

Epoch: 6| Step: 11
Training loss: 0.04691565781831741
Validation loss: 1.4359050553332093

Epoch: 6| Step: 12
Training loss: 0.04136437177658081
Validation loss: 1.4616795380910237

Epoch: 6| Step: 13
Training loss: 0.10661841928958893
Validation loss: 1.4409454381594093

Epoch: 737| Step: 0
Training loss: 0.06800385564565659
Validation loss: 1.4322823683420818

Epoch: 6| Step: 1
Training loss: 0.0512392520904541
Validation loss: 1.4129678908214773

Epoch: 6| Step: 2
Training loss: 0.032232921570539474
Validation loss: 1.3935900465134652

Epoch: 6| Step: 3
Training loss: 0.05213003605604172
Validation loss: 1.3914065655841623

Epoch: 6| Step: 4
Training loss: 0.03926670178771019
Validation loss: 1.3985591921755063

Epoch: 6| Step: 5
Training loss: 0.032245784997940063
Validation loss: 1.399411537313974

Epoch: 6| Step: 6
Training loss: 0.04940325766801834
Validation loss: 1.388583880598827

Epoch: 6| Step: 7
Training loss: 0.05619586259126663
Validation loss: 1.4161612167153308

Epoch: 6| Step: 8
Training loss: 0.04626762121915817
Validation loss: 1.4305610310646795

Epoch: 6| Step: 9
Training loss: 0.12398184835910797
Validation loss: 1.4116614236626575

Epoch: 6| Step: 10
Training loss: 0.08367900550365448
Validation loss: 1.4269021364950365

Epoch: 6| Step: 11
Training loss: 0.05864396318793297
Validation loss: 1.3882310896791437

Epoch: 6| Step: 12
Training loss: 0.08407892286777496
Validation loss: 1.441563674198684

Epoch: 6| Step: 13
Training loss: 0.07760512828826904
Validation loss: 1.4318514985422934

Epoch: 738| Step: 0
Training loss: 0.06356603652238846
Validation loss: 1.4173861934292702

Epoch: 6| Step: 1
Training loss: 0.06518472731113434
Validation loss: 1.4387721746198592

Epoch: 6| Step: 2
Training loss: 0.034053605049848557
Validation loss: 1.441595547942705

Epoch: 6| Step: 3
Training loss: 0.07071855664253235
Validation loss: 1.4517844659025951

Epoch: 6| Step: 4
Training loss: 0.044537708163261414
Validation loss: 1.4581611028281591

Epoch: 6| Step: 5
Training loss: 0.04290236905217171
Validation loss: 1.4525964529283586

Epoch: 6| Step: 6
Training loss: 0.08273778855800629
Validation loss: 1.4463027036318215

Epoch: 6| Step: 7
Training loss: 0.057428136467933655
Validation loss: 1.4535767339891004

Epoch: 6| Step: 8
Training loss: 0.03970407694578171
Validation loss: 1.4266768065831994

Epoch: 6| Step: 9
Training loss: 0.062183476984500885
Validation loss: 1.4506755605820687

Epoch: 6| Step: 10
Training loss: 0.06451620161533356
Validation loss: 1.439980237714706

Epoch: 6| Step: 11
Training loss: 0.08034031838178635
Validation loss: 1.4396668429015784

Epoch: 6| Step: 12
Training loss: 0.03817228227853775
Validation loss: 1.444293124060477

Epoch: 6| Step: 13
Training loss: 0.03044036775827408
Validation loss: 1.443552186412196

Epoch: 739| Step: 0
Training loss: 0.06816764175891876
Validation loss: 1.4459888832543486

Epoch: 6| Step: 1
Training loss: 0.07386825978755951
Validation loss: 1.4588741615254393

Epoch: 6| Step: 2
Training loss: 0.05374522507190704
Validation loss: 1.4332809461060392

Epoch: 6| Step: 3
Training loss: 0.06917707622051239
Validation loss: 1.439323038824143

Epoch: 6| Step: 4
Training loss: 0.04094100743532181
Validation loss: 1.431250637577426

Epoch: 6| Step: 5
Training loss: 0.05635727941989899
Validation loss: 1.4429813508064515

Epoch: 6| Step: 6
Training loss: 0.049829624593257904
Validation loss: 1.4487297150396532

Epoch: 6| Step: 7
Training loss: 0.05119268596172333
Validation loss: 1.4621527617977512

Epoch: 6| Step: 8
Training loss: 0.04783819243311882
Validation loss: 1.4473231454049387

Epoch: 6| Step: 9
Training loss: 0.04699977487325668
Validation loss: 1.4657085095682452

Epoch: 6| Step: 10
Training loss: 0.07215102016925812
Validation loss: 1.4465939690989833

Epoch: 6| Step: 11
Training loss: 0.07392766326665878
Validation loss: 1.4655036644269062

Epoch: 6| Step: 12
Training loss: 0.04843183606863022
Validation loss: 1.4321717716032458

Epoch: 6| Step: 13
Training loss: 0.04548385366797447
Validation loss: 1.4419446414516819

Epoch: 740| Step: 0
Training loss: 0.04787961393594742
Validation loss: 1.4174478989775463

Epoch: 6| Step: 1
Training loss: 0.04098743200302124
Validation loss: 1.4076122474926773

Epoch: 6| Step: 2
Training loss: 0.05863846465945244
Validation loss: 1.4395770462610389

Epoch: 6| Step: 3
Training loss: 0.03348645567893982
Validation loss: 1.4423890229194396

Epoch: 6| Step: 4
Training loss: 0.0566699244081974
Validation loss: 1.4275456525946175

Epoch: 6| Step: 5
Training loss: 0.06372785568237305
Validation loss: 1.4500227615397463

Epoch: 6| Step: 6
Training loss: 0.041746169328689575
Validation loss: 1.4588987852937432

Epoch: 6| Step: 7
Training loss: 0.05322670936584473
Validation loss: 1.4246383200409591

Epoch: 6| Step: 8
Training loss: 0.07021842896938324
Validation loss: 1.444283543735422

Epoch: 6| Step: 9
Training loss: 0.04948369786143303
Validation loss: 1.4453191475201679

Epoch: 6| Step: 10
Training loss: 0.031015239655971527
Validation loss: 1.4282533943012197

Epoch: 6| Step: 11
Training loss: 0.05060262605547905
Validation loss: 1.433603939830616

Epoch: 6| Step: 12
Training loss: 0.03360868990421295
Validation loss: 1.4380021684913225

Epoch: 6| Step: 13
Training loss: 0.03936217725276947
Validation loss: 1.4308926161899362

Epoch: 741| Step: 0
Training loss: 0.04529770836234093
Validation loss: 1.4361185027707009

Epoch: 6| Step: 1
Training loss: 0.034956544637680054
Validation loss: 1.3933085920990154

Epoch: 6| Step: 2
Training loss: 0.08922920376062393
Validation loss: 1.4078293795226722

Epoch: 6| Step: 3
Training loss: 0.03423670679330826
Validation loss: 1.4254409113237936

Epoch: 6| Step: 4
Training loss: 0.056692302227020264
Validation loss: 1.4176246184174732

Epoch: 6| Step: 5
Training loss: 0.056392863392829895
Validation loss: 1.3988844758720809

Epoch: 6| Step: 6
Training loss: 0.05346459522843361
Validation loss: 1.4174634013124692

Epoch: 6| Step: 7
Training loss: 0.0357707142829895
Validation loss: 1.4126968460698281

Epoch: 6| Step: 8
Training loss: 0.039531875401735306
Validation loss: 1.4246810123484621

Epoch: 6| Step: 9
Training loss: 0.03951779007911682
Validation loss: 1.4349076927349131

Epoch: 6| Step: 10
Training loss: 0.03934486210346222
Validation loss: 1.4218733272244852

Epoch: 6| Step: 11
Training loss: 0.05481107160449028
Validation loss: 1.4160166453289729

Epoch: 6| Step: 12
Training loss: 0.03392723947763443
Validation loss: 1.4093295989498016

Epoch: 6| Step: 13
Training loss: 0.0409998744726181
Validation loss: 1.440836493686963

Epoch: 742| Step: 0
Training loss: 0.091971755027771
Validation loss: 1.4316935385427167

Epoch: 6| Step: 1
Training loss: 0.05365043133497238
Validation loss: 1.4107597617692844

Epoch: 6| Step: 2
Training loss: 0.036749377846717834
Validation loss: 1.4136281769762757

Epoch: 6| Step: 3
Training loss: 0.04869372770190239
Validation loss: 1.4011580200605496

Epoch: 6| Step: 4
Training loss: 0.04396001249551773
Validation loss: 1.3903496662775676

Epoch: 6| Step: 5
Training loss: 0.045918554067611694
Validation loss: 1.4157162686829925

Epoch: 6| Step: 6
Training loss: 0.052675798535346985
Validation loss: 1.4367216440939135

Epoch: 6| Step: 7
Training loss: 0.035618849098682404
Validation loss: 1.4258486083758775

Epoch: 6| Step: 8
Training loss: 0.05237533152103424
Validation loss: 1.4173981810128817

Epoch: 6| Step: 9
Training loss: 0.05724731832742691
Validation loss: 1.4230601787567139

Epoch: 6| Step: 10
Training loss: 0.04480975121259689
Validation loss: 1.4397550423940022

Epoch: 6| Step: 11
Training loss: 0.04429849237203598
Validation loss: 1.4454649007448586

Epoch: 6| Step: 12
Training loss: 0.029328666627407074
Validation loss: 1.420213327612928

Epoch: 6| Step: 13
Training loss: 0.03739092871546745
Validation loss: 1.442805282531246

Epoch: 743| Step: 0
Training loss: 0.040033869445323944
Validation loss: 1.4339757048955528

Epoch: 6| Step: 1
Training loss: 0.039141688495874405
Validation loss: 1.4300074743968185

Epoch: 6| Step: 2
Training loss: 0.05071498453617096
Validation loss: 1.439536984248828

Epoch: 6| Step: 3
Training loss: 0.041609928011894226
Validation loss: 1.44006605814862

Epoch: 6| Step: 4
Training loss: 0.017939845100045204
Validation loss: 1.4330688407344203

Epoch: 6| Step: 5
Training loss: 0.03591977059841156
Validation loss: 1.451738493416899

Epoch: 6| Step: 6
Training loss: 0.06538805365562439
Validation loss: 1.4337985028502762

Epoch: 6| Step: 7
Training loss: 0.05824046581983566
Validation loss: 1.4181501352658836

Epoch: 6| Step: 8
Training loss: 0.03861403465270996
Validation loss: 1.436265754443343

Epoch: 6| Step: 9
Training loss: 0.03593333810567856
Validation loss: 1.3865838986571117

Epoch: 6| Step: 10
Training loss: 0.06235301122069359
Validation loss: 1.4053302195764357

Epoch: 6| Step: 11
Training loss: 0.06792005896568298
Validation loss: 1.4032675284211353

Epoch: 6| Step: 12
Training loss: 0.07394649088382721
Validation loss: 1.4212071370053034

Epoch: 6| Step: 13
Training loss: 0.04104083031415939
Validation loss: 1.4067457465715305

Epoch: 744| Step: 0
Training loss: 0.05320757254958153
Validation loss: 1.419380485370595

Epoch: 6| Step: 1
Training loss: 0.04887718707323074
Validation loss: 1.4157004683248458

Epoch: 6| Step: 2
Training loss: 0.03522582724690437
Validation loss: 1.3955834116987003

Epoch: 6| Step: 3
Training loss: 0.04440636187791824
Validation loss: 1.3943295017365487

Epoch: 6| Step: 4
Training loss: 0.07964777946472168
Validation loss: 1.4135371952928522

Epoch: 6| Step: 5
Training loss: 0.0460960678756237
Validation loss: 1.4132563734567294

Epoch: 6| Step: 6
Training loss: 0.024350930005311966
Validation loss: 1.4363299069866058

Epoch: 6| Step: 7
Training loss: 0.06759953498840332
Validation loss: 1.4269413960877286

Epoch: 6| Step: 8
Training loss: 0.06172376871109009
Validation loss: 1.4336042852811917

Epoch: 6| Step: 9
Training loss: 0.06155183166265488
Validation loss: 1.4382462892481076

Epoch: 6| Step: 10
Training loss: 0.06105692684650421
Validation loss: 1.448405828527225

Epoch: 6| Step: 11
Training loss: 0.04782070964574814
Validation loss: 1.4462345851364957

Epoch: 6| Step: 12
Training loss: 0.04667258635163307
Validation loss: 1.432734356772515

Epoch: 6| Step: 13
Training loss: 0.0465008020401001
Validation loss: 1.4399188500578686

Epoch: 745| Step: 0
Training loss: 0.03051585704088211
Validation loss: 1.4209723229049354

Epoch: 6| Step: 1
Training loss: 0.052778348326683044
Validation loss: 1.4264921629300682

Epoch: 6| Step: 2
Training loss: 0.03563876450061798
Validation loss: 1.4026845168041926

Epoch: 6| Step: 3
Training loss: 0.034539587795734406
Validation loss: 1.380954554004054

Epoch: 6| Step: 4
Training loss: 0.03074638918042183
Validation loss: 1.380383426143277

Epoch: 6| Step: 5
Training loss: 0.07199043780565262
Validation loss: 1.3721999122250466

Epoch: 6| Step: 6
Training loss: 0.04523646458983421
Validation loss: 1.383544606547202

Epoch: 6| Step: 7
Training loss: 0.06396538019180298
Validation loss: 1.4175797893155007

Epoch: 6| Step: 8
Training loss: 0.03089097887277603
Validation loss: 1.3752467414384246

Epoch: 6| Step: 9
Training loss: 0.05558566004037857
Validation loss: 1.401593872295913

Epoch: 6| Step: 10
Training loss: 0.04778764396905899
Validation loss: 1.4115110071756507

Epoch: 6| Step: 11
Training loss: 0.04580969363451004
Validation loss: 1.400291564644024

Epoch: 6| Step: 12
Training loss: 0.04159064590930939
Validation loss: 1.3821762313124955

Epoch: 6| Step: 13
Training loss: 0.05261943116784096
Validation loss: 1.4076461817628594

Epoch: 746| Step: 0
Training loss: 0.05269478261470795
Validation loss: 1.410773261900871

Epoch: 6| Step: 1
Training loss: 0.05333339422941208
Validation loss: 1.4126657401361773

Epoch: 6| Step: 2
Training loss: 0.038064949214458466
Validation loss: 1.4343574405998312

Epoch: 6| Step: 3
Training loss: 0.054704416543245316
Validation loss: 1.4355186980257753

Epoch: 6| Step: 4
Training loss: 0.04009035974740982
Validation loss: 1.416053246426326

Epoch: 6| Step: 5
Training loss: 0.05387629568576813
Validation loss: 1.4485327915478778

Epoch: 6| Step: 6
Training loss: 0.06467927992343903
Validation loss: 1.409520774118362

Epoch: 6| Step: 7
Training loss: 0.05528207868337631
Validation loss: 1.4295928914059874

Epoch: 6| Step: 8
Training loss: 0.029518550261855125
Validation loss: 1.4161004308731324

Epoch: 6| Step: 9
Training loss: 0.033161185681819916
Validation loss: 1.4367982982307352

Epoch: 6| Step: 10
Training loss: 0.062089692801237106
Validation loss: 1.4152535264210035

Epoch: 6| Step: 11
Training loss: 0.03583621606230736
Validation loss: 1.4131087795380624

Epoch: 6| Step: 12
Training loss: 0.017107345163822174
Validation loss: 1.3850621907941756

Epoch: 6| Step: 13
Training loss: 0.055309925228357315
Validation loss: 1.3975855047984789

Epoch: 747| Step: 0
Training loss: 0.04752971976995468
Validation loss: 1.4134579166289298

Epoch: 6| Step: 1
Training loss: 0.07003030925989151
Validation loss: 1.410126127222533

Epoch: 6| Step: 2
Training loss: 0.029599573463201523
Validation loss: 1.4155152510571223

Epoch: 6| Step: 3
Training loss: 0.05508626997470856
Validation loss: 1.4260227026477936

Epoch: 6| Step: 4
Training loss: 0.05932329595088959
Validation loss: 1.4310045883219729

Epoch: 6| Step: 5
Training loss: 0.03520175814628601
Validation loss: 1.4186817728063112

Epoch: 6| Step: 6
Training loss: 0.03208031505346298
Validation loss: 1.4174112068709506

Epoch: 6| Step: 7
Training loss: 0.025662045925855637
Validation loss: 1.409416062857515

Epoch: 6| Step: 8
Training loss: 0.028752369806170464
Validation loss: 1.4029380929085515

Epoch: 6| Step: 9
Training loss: 0.040520429611206055
Validation loss: 1.403176846042756

Epoch: 6| Step: 10
Training loss: 0.037329599261283875
Validation loss: 1.4025997564356814

Epoch: 6| Step: 11
Training loss: 0.06346716731786728
Validation loss: 1.4085280690141904

Epoch: 6| Step: 12
Training loss: 0.02959238924086094
Validation loss: 1.3980290043738581

Epoch: 6| Step: 13
Training loss: 0.0495033822953701
Validation loss: 1.4230443892940399

Epoch: 748| Step: 0
Training loss: 0.03695307672023773
Validation loss: 1.4110962319117721

Epoch: 6| Step: 1
Training loss: 0.051439911127090454
Validation loss: 1.4096983626324644

Epoch: 6| Step: 2
Training loss: 0.06076056510210037
Validation loss: 1.4257269264549337

Epoch: 6| Step: 3
Training loss: 0.036929287016391754
Validation loss: 1.408807530198046

Epoch: 6| Step: 4
Training loss: 0.05730930715799332
Validation loss: 1.4004951548832718

Epoch: 6| Step: 5
Training loss: 0.0425359383225441
Validation loss: 1.3954608055853075

Epoch: 6| Step: 6
Training loss: 0.07226511836051941
Validation loss: 1.4055509221169256

Epoch: 6| Step: 7
Training loss: 0.05544176325201988
Validation loss: 1.4308932237727667

Epoch: 6| Step: 8
Training loss: 0.033687394112348557
Validation loss: 1.3977378863160328

Epoch: 6| Step: 9
Training loss: 0.047861337661743164
Validation loss: 1.4405533306060299

Epoch: 6| Step: 10
Training loss: 0.05500398948788643
Validation loss: 1.4329132879934003

Epoch: 6| Step: 11
Training loss: 0.0297411996871233
Validation loss: 1.4194532241872562

Epoch: 6| Step: 12
Training loss: 0.032265353947877884
Validation loss: 1.4451838924038796

Epoch: 6| Step: 13
Training loss: 0.022517750039696693
Validation loss: 1.4378860599251204

Epoch: 749| Step: 0
Training loss: 0.019519556313753128
Validation loss: 1.4046568024543025

Epoch: 6| Step: 1
Training loss: 0.04044346511363983
Validation loss: 1.4368664231351627

Epoch: 6| Step: 2
Training loss: 0.07925167679786682
Validation loss: 1.4077209067601029

Epoch: 6| Step: 3
Training loss: 0.03307779133319855
Validation loss: 1.4376896222432454

Epoch: 6| Step: 4
Training loss: 0.02719172090291977
Validation loss: 1.451522873293969

Epoch: 6| Step: 5
Training loss: 0.0276859849691391
Validation loss: 1.4611551056626022

Epoch: 6| Step: 6
Training loss: 0.05590010806918144
Validation loss: 1.4263040083710865

Epoch: 6| Step: 7
Training loss: 0.0642431452870369
Validation loss: 1.4442464587508992

Epoch: 6| Step: 8
Training loss: 0.04841955006122589
Validation loss: 1.4360560473575388

Epoch: 6| Step: 9
Training loss: 0.04391147568821907
Validation loss: 1.4429356923667334

Epoch: 6| Step: 10
Training loss: 0.03319637104868889
Validation loss: 1.4334614084612938

Epoch: 6| Step: 11
Training loss: 0.03752675652503967
Validation loss: 1.444173098892294

Epoch: 6| Step: 12
Training loss: 0.042779646813869476
Validation loss: 1.4270952901532572

Epoch: 6| Step: 13
Training loss: 0.03498876094818115
Validation loss: 1.422122363121279

Epoch: 750| Step: 0
Training loss: 0.06942089647054672
Validation loss: 1.4258013053606915

Epoch: 6| Step: 1
Training loss: 0.039232946932315826
Validation loss: 1.4335918067603983

Epoch: 6| Step: 2
Training loss: 0.028620965778827667
Validation loss: 1.4073405035080448

Epoch: 6| Step: 3
Training loss: 0.03606480360031128
Validation loss: 1.4279283823505524

Epoch: 6| Step: 4
Training loss: 0.06493136286735535
Validation loss: 1.4151267582370388

Epoch: 6| Step: 5
Training loss: 0.03176189586520195
Validation loss: 1.4116675558910574

Epoch: 6| Step: 6
Training loss: 0.04523845762014389
Validation loss: 1.4251512952389256

Epoch: 6| Step: 7
Training loss: 0.059937212616205215
Validation loss: 1.395451367542308

Epoch: 6| Step: 8
Training loss: 0.050557106733322144
Validation loss: 1.45223464504365

Epoch: 6| Step: 9
Training loss: 0.033660732209682465
Validation loss: 1.4182775840964368

Epoch: 6| Step: 10
Training loss: 0.045656971633434296
Validation loss: 1.4195384774156796

Epoch: 6| Step: 11
Training loss: 0.06592604517936707
Validation loss: 1.3943955347102175

Epoch: 6| Step: 12
Training loss: 0.03823729604482651
Validation loss: 1.431408662949839

Epoch: 6| Step: 13
Training loss: 0.039154842495918274
Validation loss: 1.4194846576259983

Epoch: 751| Step: 0
Training loss: 0.02518465556204319
Validation loss: 1.410143671497222

Epoch: 6| Step: 1
Training loss: 0.03181315213441849
Validation loss: 1.4304761514868787

Epoch: 6| Step: 2
Training loss: 0.045025117695331573
Validation loss: 1.3837016179997434

Epoch: 6| Step: 3
Training loss: 0.04630183428525925
Validation loss: 1.4060360962344753

Epoch: 6| Step: 4
Training loss: 0.03582791984081268
Validation loss: 1.3985670997250466

Epoch: 6| Step: 5
Training loss: 0.07385812699794769
Validation loss: 1.3895165010165142

Epoch: 6| Step: 6
Training loss: 0.04483621567487717
Validation loss: 1.4024538417016306

Epoch: 6| Step: 7
Training loss: 0.05300811678171158
Validation loss: 1.3988873907314834

Epoch: 6| Step: 8
Training loss: 0.04180090129375458
Validation loss: 1.410366310868212

Epoch: 6| Step: 9
Training loss: 0.0718483105301857
Validation loss: 1.4135534994063839

Epoch: 6| Step: 10
Training loss: 0.0378202386200428
Validation loss: 1.4194532645645963

Epoch: 6| Step: 11
Training loss: 0.027032986283302307
Validation loss: 1.426634286039619

Epoch: 6| Step: 12
Training loss: 0.05609399080276489
Validation loss: 1.413230965855301

Epoch: 6| Step: 13
Training loss: 0.03307119384407997
Validation loss: 1.4221913481271395

Epoch: 752| Step: 0
Training loss: 0.04727920517325401
Validation loss: 1.4435988574899652

Epoch: 6| Step: 1
Training loss: 0.06362197548151016
Validation loss: 1.4169383190011466

Epoch: 6| Step: 2
Training loss: 0.039461225271224976
Validation loss: 1.4053605846179429

Epoch: 6| Step: 3
Training loss: 0.04471202939748764
Validation loss: 1.3986759108881797

Epoch: 6| Step: 4
Training loss: 0.07201257348060608
Validation loss: 1.4264743142230536

Epoch: 6| Step: 5
Training loss: 0.03893710672855377
Validation loss: 1.4162182397739862

Epoch: 6| Step: 6
Training loss: 0.04297719895839691
Validation loss: 1.395160811562692

Epoch: 6| Step: 7
Training loss: 0.06914334744215012
Validation loss: 1.4202950539127472

Epoch: 6| Step: 8
Training loss: 0.03340402990579605
Validation loss: 1.401951671928488

Epoch: 6| Step: 9
Training loss: 0.05024774372577667
Validation loss: 1.4297041937869082

Epoch: 6| Step: 10
Training loss: 0.03409257531166077
Validation loss: 1.389115592484833

Epoch: 6| Step: 11
Training loss: 0.03672882169485092
Validation loss: 1.3970870523042576

Epoch: 6| Step: 12
Training loss: 0.04782514274120331
Validation loss: 1.3619431167520502

Epoch: 6| Step: 13
Training loss: 0.020992808043956757
Validation loss: 1.3745185405977312

Epoch: 753| Step: 0
Training loss: 0.03847624734044075
Validation loss: 1.374725382174215

Epoch: 6| Step: 1
Training loss: 0.02748102694749832
Validation loss: 1.3667780955632527

Epoch: 6| Step: 2
Training loss: 0.045300498604774475
Validation loss: 1.386421613795783

Epoch: 6| Step: 3
Training loss: 0.04360758513212204
Validation loss: 1.3815273520767049

Epoch: 6| Step: 4
Training loss: 0.07835981994867325
Validation loss: 1.3714421391487122

Epoch: 6| Step: 5
Training loss: 0.08380475640296936
Validation loss: 1.392418485815807

Epoch: 6| Step: 6
Training loss: 0.046084195375442505
Validation loss: 1.3779408278003815

Epoch: 6| Step: 7
Training loss: 0.0709569901227951
Validation loss: 1.4054136096790273

Epoch: 6| Step: 8
Training loss: 0.04960724711418152
Validation loss: 1.4103794546537503

Epoch: 6| Step: 9
Training loss: 0.06666094064712524
Validation loss: 1.4239281146757063

Epoch: 6| Step: 10
Training loss: 0.05898851156234741
Validation loss: 1.4192701693504088

Epoch: 6| Step: 11
Training loss: 0.037859492003917694
Validation loss: 1.4418309657804427

Epoch: 6| Step: 12
Training loss: 0.06445105373859406
Validation loss: 1.3965008246001376

Epoch: 6| Step: 13
Training loss: 0.06433812528848648
Validation loss: 1.430630906935661

Epoch: 754| Step: 0
Training loss: 0.03719925880432129
Validation loss: 1.425642506409717

Epoch: 6| Step: 1
Training loss: 0.03710901364684105
Validation loss: 1.417854550064251

Epoch: 6| Step: 2
Training loss: 0.04090849310159683
Validation loss: 1.4245961225160988

Epoch: 6| Step: 3
Training loss: 0.06014592573046684
Validation loss: 1.4647740202565347

Epoch: 6| Step: 4
Training loss: 0.041898734867572784
Validation loss: 1.4407590589215677

Epoch: 6| Step: 5
Training loss: 0.060736238956451416
Validation loss: 1.447487312619404

Epoch: 6| Step: 6
Training loss: 0.050996437668800354
Validation loss: 1.419722278912862

Epoch: 6| Step: 7
Training loss: 0.05607996881008148
Validation loss: 1.4379231096595846

Epoch: 6| Step: 8
Training loss: 0.0335223525762558
Validation loss: 1.4213543591960784

Epoch: 6| Step: 9
Training loss: 0.03469105437397957
Validation loss: 1.4255058688502158

Epoch: 6| Step: 10
Training loss: 0.02566421963274479
Validation loss: 1.4267793842541274

Epoch: 6| Step: 11
Training loss: 0.03429463505744934
Validation loss: 1.4241348530656548

Epoch: 6| Step: 12
Training loss: 0.10070487856864929
Validation loss: 1.446993185627845

Epoch: 6| Step: 13
Training loss: 0.05911688134074211
Validation loss: 1.4266079728321364

Epoch: 755| Step: 0
Training loss: 0.02857646718621254
Validation loss: 1.4140795712829919

Epoch: 6| Step: 1
Training loss: 0.04236256331205368
Validation loss: 1.4544415858484083

Epoch: 6| Step: 2
Training loss: 0.06713713705539703
Validation loss: 1.42072646592253

Epoch: 6| Step: 3
Training loss: 0.0604415126144886
Validation loss: 1.432079219049023

Epoch: 6| Step: 4
Training loss: 0.0661221370100975
Validation loss: 1.4113377114777923

Epoch: 6| Step: 5
Training loss: 0.03198716789484024
Validation loss: 1.4278087398057342

Epoch: 6| Step: 6
Training loss: 0.04011255502700806
Validation loss: 1.4232073650565198

Epoch: 6| Step: 7
Training loss: 0.04922966659069061
Validation loss: 1.4187770370514161

Epoch: 6| Step: 8
Training loss: 0.03161649405956268
Validation loss: 1.3999294709133845

Epoch: 6| Step: 9
Training loss: 0.05844072625041008
Validation loss: 1.4097654627215477

Epoch: 6| Step: 10
Training loss: 0.05039113759994507
Validation loss: 1.4113568458505856

Epoch: 6| Step: 11
Training loss: 0.07101847231388092
Validation loss: 1.403132515568887

Epoch: 6| Step: 12
Training loss: 0.05638223886489868
Validation loss: 1.4085031158180648

Epoch: 6| Step: 13
Training loss: 0.058951668441295624
Validation loss: 1.3831407716197353

Epoch: 756| Step: 0
Training loss: 0.040465883910655975
Validation loss: 1.3914959815240675

Epoch: 6| Step: 1
Training loss: 0.025231968611478806
Validation loss: 1.3984100434087938

Epoch: 6| Step: 2
Training loss: 0.059471845626831055
Validation loss: 1.3892427823876823

Epoch: 6| Step: 3
Training loss: 0.0407000370323658
Validation loss: 1.4000312935921453

Epoch: 6| Step: 4
Training loss: 0.05228593945503235
Validation loss: 1.3956116245638939

Epoch: 6| Step: 5
Training loss: 0.0755852684378624
Validation loss: 1.3873919069126088

Epoch: 6| Step: 6
Training loss: 0.06178494170308113
Validation loss: 1.376366198703807

Epoch: 6| Step: 7
Training loss: 0.0745086595416069
Validation loss: 1.4246692016560545

Epoch: 6| Step: 8
Training loss: 0.06882277131080627
Validation loss: 1.3844778999205558

Epoch: 6| Step: 9
Training loss: 0.0381438210606575
Validation loss: 1.3781574528704408

Epoch: 6| Step: 10
Training loss: 0.05621125549077988
Validation loss: 1.383555232837636

Epoch: 6| Step: 11
Training loss: 0.04224316030740738
Validation loss: 1.4150346402199037

Epoch: 6| Step: 12
Training loss: 0.05305399000644684
Validation loss: 1.4352625185443508

Epoch: 6| Step: 13
Training loss: 0.05281010642647743
Validation loss: 1.438521392883793

Epoch: 757| Step: 0
Training loss: 0.038847193121910095
Validation loss: 1.432013907740193

Epoch: 6| Step: 1
Training loss: 0.04401847720146179
Validation loss: 1.4336397032583914

Epoch: 6| Step: 2
Training loss: 0.044865455478429794
Validation loss: 1.4411984784628755

Epoch: 6| Step: 3
Training loss: 0.03241405636072159
Validation loss: 1.4144814052889425

Epoch: 6| Step: 4
Training loss: 0.027773704379796982
Validation loss: 1.4385566788335

Epoch: 6| Step: 5
Training loss: 0.058973025530576706
Validation loss: 1.447775037057938

Epoch: 6| Step: 6
Training loss: 0.06727825105190277
Validation loss: 1.4423171909906531

Epoch: 6| Step: 7
Training loss: 0.042878057807683945
Validation loss: 1.46506880944775

Epoch: 6| Step: 8
Training loss: 0.0559215322136879
Validation loss: 1.4471488947509437

Epoch: 6| Step: 9
Training loss: 0.04696105420589447
Validation loss: 1.4541962992760442

Epoch: 6| Step: 10
Training loss: 0.04844192415475845
Validation loss: 1.4400169503304265

Epoch: 6| Step: 11
Training loss: 0.024752410128712654
Validation loss: 1.425248033256941

Epoch: 6| Step: 12
Training loss: 0.06548041105270386
Validation loss: 1.4439421674256683

Epoch: 6| Step: 13
Training loss: 0.05456435680389404
Validation loss: 1.4315946473870227

Epoch: 758| Step: 0
Training loss: 0.04642852395772934
Validation loss: 1.4468225881617556

Epoch: 6| Step: 1
Training loss: 0.07327324151992798
Validation loss: 1.4513129713714763

Epoch: 6| Step: 2
Training loss: 0.04486763849854469
Validation loss: 1.4654674978666409

Epoch: 6| Step: 3
Training loss: 0.04665222764015198
Validation loss: 1.4386381385146931

Epoch: 6| Step: 4
Training loss: 0.04405463486909866
Validation loss: 1.4389453370084044

Epoch: 6| Step: 5
Training loss: 0.030065389350056648
Validation loss: 1.450721686886203

Epoch: 6| Step: 6
Training loss: 0.055733002722263336
Validation loss: 1.4828954794073617

Epoch: 6| Step: 7
Training loss: 0.06472253799438477
Validation loss: 1.4105493471186648

Epoch: 6| Step: 8
Training loss: 0.04832465201616287
Validation loss: 1.458663248246716

Epoch: 6| Step: 9
Training loss: 0.038418807089328766
Validation loss: 1.4350419685404787

Epoch: 6| Step: 10
Training loss: 0.03004235401749611
Validation loss: 1.4551118086743098

Epoch: 6| Step: 11
Training loss: 0.044518861919641495
Validation loss: 1.4433315816105052

Epoch: 6| Step: 12
Training loss: 0.050954222679138184
Validation loss: 1.4628146207460793

Epoch: 6| Step: 13
Training loss: 0.0670405924320221
Validation loss: 1.4511284700004004

Epoch: 759| Step: 0
Training loss: 0.040205277502536774
Validation loss: 1.466900643482003

Epoch: 6| Step: 1
Training loss: 0.026348643004894257
Validation loss: 1.4587014086784855

Epoch: 6| Step: 2
Training loss: 0.05314077064394951
Validation loss: 1.4661156349284674

Epoch: 6| Step: 3
Training loss: 0.027905205264687538
Validation loss: 1.4472831872201735

Epoch: 6| Step: 4
Training loss: 0.02309253066778183
Validation loss: 1.4644387716888099

Epoch: 6| Step: 5
Training loss: 0.06559602916240692
Validation loss: 1.4341002292530511

Epoch: 6| Step: 6
Training loss: 0.07604486495256424
Validation loss: 1.4512356519699097

Epoch: 6| Step: 7
Training loss: 0.04057642072439194
Validation loss: 1.4340020213075864

Epoch: 6| Step: 8
Training loss: 0.0467546209692955
Validation loss: 1.4528348522801553

Epoch: 6| Step: 9
Training loss: 0.03437676653265953
Validation loss: 1.4336879689206359

Epoch: 6| Step: 10
Training loss: 0.05083911120891571
Validation loss: 1.4578840553119619

Epoch: 6| Step: 11
Training loss: 0.04386588931083679
Validation loss: 1.4322527839291481

Epoch: 6| Step: 12
Training loss: 0.044259555637836456
Validation loss: 1.4504910707473755

Epoch: 6| Step: 13
Training loss: 0.05246648192405701
Validation loss: 1.4228311610478226

Epoch: 760| Step: 0
Training loss: 0.038192518055438995
Validation loss: 1.4425848030274915

Epoch: 6| Step: 1
Training loss: 0.06834433972835541
Validation loss: 1.4496182228929253

Epoch: 6| Step: 2
Training loss: 0.06386525928974152
Validation loss: 1.4355052696761263

Epoch: 6| Step: 3
Training loss: 0.06672094017267227
Validation loss: 1.4417934609997658

Epoch: 6| Step: 4
Training loss: 0.04294600710272789
Validation loss: 1.4240661282693186

Epoch: 6| Step: 5
Training loss: 0.041231393814086914
Validation loss: 1.411879442071402

Epoch: 6| Step: 6
Training loss: 0.03864380717277527
Validation loss: 1.41721305154985

Epoch: 6| Step: 7
Training loss: 0.03723495453596115
Validation loss: 1.406098190174308

Epoch: 6| Step: 8
Training loss: 0.05538109317421913
Validation loss: 1.401836754814271

Epoch: 6| Step: 9
Training loss: 0.04868914186954498
Validation loss: 1.4148662590211438

Epoch: 6| Step: 10
Training loss: 0.031947340816259384
Validation loss: 1.4128482809630774

Epoch: 6| Step: 11
Training loss: 0.04769381135702133
Validation loss: 1.4233735261424896

Epoch: 6| Step: 12
Training loss: 0.04374317824840546
Validation loss: 1.4250108811163134

Epoch: 6| Step: 13
Training loss: 0.05464388057589531
Validation loss: 1.448234554900918

Epoch: 761| Step: 0
Training loss: 0.07171504199504852
Validation loss: 1.424915526502876

Epoch: 6| Step: 1
Training loss: 0.07283836603164673
Validation loss: 1.4116721678805608

Epoch: 6| Step: 2
Training loss: 0.02505015954375267
Validation loss: 1.4409491906883896

Epoch: 6| Step: 3
Training loss: 0.0423317551612854
Validation loss: 1.4282878637313843

Epoch: 6| Step: 4
Training loss: 0.019463587552309036
Validation loss: 1.4692604336687314

Epoch: 6| Step: 5
Training loss: 0.030171707272529602
Validation loss: 1.4171149423045497

Epoch: 6| Step: 6
Training loss: 0.04427428916096687
Validation loss: 1.4128791657827233

Epoch: 6| Step: 7
Training loss: 0.0535268560051918
Validation loss: 1.4426851452037852

Epoch: 6| Step: 8
Training loss: 0.03108450397849083
Validation loss: 1.4177566869284517

Epoch: 6| Step: 9
Training loss: 0.03967463970184326
Validation loss: 1.4565166824607438

Epoch: 6| Step: 10
Training loss: 0.03349887579679489
Validation loss: 1.4466733970949728

Epoch: 6| Step: 11
Training loss: 0.024558542296290398
Validation loss: 1.4441072364007272

Epoch: 6| Step: 12
Training loss: 0.0639263167977333
Validation loss: 1.4347645121236001

Epoch: 6| Step: 13
Training loss: 0.02301718108355999
Validation loss: 1.441045029188997

Epoch: 762| Step: 0
Training loss: 0.05422171577811241
Validation loss: 1.42342504250106

Epoch: 6| Step: 1
Training loss: 0.02949659153819084
Validation loss: 1.4261138400723856

Epoch: 6| Step: 2
Training loss: 0.03819239139556885
Validation loss: 1.4213867764319144

Epoch: 6| Step: 3
Training loss: 0.032171718776226044
Validation loss: 1.4299894609758932

Epoch: 6| Step: 4
Training loss: 0.034141577780246735
Validation loss: 1.4166035664978849

Epoch: 6| Step: 5
Training loss: 0.07882829010486603
Validation loss: 1.433147777793228

Epoch: 6| Step: 6
Training loss: 0.04615318030118942
Validation loss: 1.43866378261197

Epoch: 6| Step: 7
Training loss: 0.054178692400455475
Validation loss: 1.4333235909861903

Epoch: 6| Step: 8
Training loss: 0.04815027490258217
Validation loss: 1.4544272140790058

Epoch: 6| Step: 9
Training loss: 0.03344990313053131
Validation loss: 1.4422861465843775

Epoch: 6| Step: 10
Training loss: 0.04507996886968613
Validation loss: 1.4543482295928463

Epoch: 6| Step: 11
Training loss: 0.04072234034538269
Validation loss: 1.4326822219356414

Epoch: 6| Step: 12
Training loss: 0.0444377139210701
Validation loss: 1.429150116059088

Epoch: 6| Step: 13
Training loss: 0.07389398664236069
Validation loss: 1.4651689978056057

Epoch: 763| Step: 0
Training loss: 0.03209592401981354
Validation loss: 1.427218569222317

Epoch: 6| Step: 1
Training loss: 0.059328604489564896
Validation loss: 1.486381781998501

Epoch: 6| Step: 2
Training loss: 0.03166615217924118
Validation loss: 1.46886714876339

Epoch: 6| Step: 3
Training loss: 0.03041692264378071
Validation loss: 1.4553841942100114

Epoch: 6| Step: 4
Training loss: 0.03863490745425224
Validation loss: 1.4369829175292805

Epoch: 6| Step: 5
Training loss: 0.06060176342725754
Validation loss: 1.409637648572204

Epoch: 6| Step: 6
Training loss: 0.05964076519012451
Validation loss: 1.414433979219006

Epoch: 6| Step: 7
Training loss: 0.030382227152585983
Validation loss: 1.4207961924614445

Epoch: 6| Step: 8
Training loss: 0.048551175743341446
Validation loss: 1.4096960867604902

Epoch: 6| Step: 9
Training loss: 0.03408234566450119
Validation loss: 1.3875969250996907

Epoch: 6| Step: 10
Training loss: 0.03736109659075737
Validation loss: 1.3892376781791769

Epoch: 6| Step: 11
Training loss: 0.06390763074159622
Validation loss: 1.4017428044349916

Epoch: 6| Step: 12
Training loss: 0.07413690537214279
Validation loss: 1.4213299982009395

Epoch: 6| Step: 13
Training loss: 0.04987921938300133
Validation loss: 1.3805659471019622

Epoch: 764| Step: 0
Training loss: 0.03722889721393585
Validation loss: 1.3729294461588706

Epoch: 6| Step: 1
Training loss: 0.06016180291771889
Validation loss: 1.396878779575389

Epoch: 6| Step: 2
Training loss: 0.04891781508922577
Validation loss: 1.3971853179316367

Epoch: 6| Step: 3
Training loss: 0.028971800580620766
Validation loss: 1.4036424685549993

Epoch: 6| Step: 4
Training loss: 0.027098583057522774
Validation loss: 1.394056736782033

Epoch: 6| Step: 5
Training loss: 0.05169200524687767
Validation loss: 1.405393054408412

Epoch: 6| Step: 6
Training loss: 0.04466807469725609
Validation loss: 1.4030092121452413

Epoch: 6| Step: 7
Training loss: 0.032316483557224274
Validation loss: 1.4196282663652975

Epoch: 6| Step: 8
Training loss: 0.03619736433029175
Validation loss: 1.4154890096315773

Epoch: 6| Step: 9
Training loss: 0.022796036675572395
Validation loss: 1.4028690015116045

Epoch: 6| Step: 10
Training loss: 0.046492625027894974
Validation loss: 1.4247001922258766

Epoch: 6| Step: 11
Training loss: 0.05545370280742645
Validation loss: 1.4100430614204817

Epoch: 6| Step: 12
Training loss: 0.06805659085512161
Validation loss: 1.4307677771455498

Epoch: 6| Step: 13
Training loss: 0.0515882782638073
Validation loss: 1.4556584973489084

Epoch: 765| Step: 0
Training loss: 0.04051324725151062
Validation loss: 1.4210233380717616

Epoch: 6| Step: 1
Training loss: 0.0285786259919405
Validation loss: 1.422644869614673

Epoch: 6| Step: 2
Training loss: 0.05500563979148865
Validation loss: 1.396917365571504

Epoch: 6| Step: 3
Training loss: 0.030843138694763184
Validation loss: 1.4135163496899348

Epoch: 6| Step: 4
Training loss: 0.023515788838267326
Validation loss: 1.4168151181231263

Epoch: 6| Step: 5
Training loss: 0.04102848842740059
Validation loss: 1.414734072582696

Epoch: 6| Step: 6
Training loss: 0.054937466979026794
Validation loss: 1.4233502329036753

Epoch: 6| Step: 7
Training loss: 0.058961421251297
Validation loss: 1.4295400778452556

Epoch: 6| Step: 8
Training loss: 0.05140057951211929
Validation loss: 1.4191462801348778

Epoch: 6| Step: 9
Training loss: 0.05756770819425583
Validation loss: 1.4184337892839987

Epoch: 6| Step: 10
Training loss: 0.046574681997299194
Validation loss: 1.4103483359018962

Epoch: 6| Step: 11
Training loss: 0.03167589753866196
Validation loss: 1.4103105420707374

Epoch: 6| Step: 12
Training loss: 0.057606153190135956
Validation loss: 1.422274721566067

Epoch: 6| Step: 13
Training loss: 0.07581944018602371
Validation loss: 1.417946675772308

Epoch: 766| Step: 0
Training loss: 0.053749676793813705
Validation loss: 1.4289305895887396

Epoch: 6| Step: 1
Training loss: 0.051744572818279266
Validation loss: 1.4209530276636924

Epoch: 6| Step: 2
Training loss: 0.04894908517599106
Validation loss: 1.409943692145809

Epoch: 6| Step: 3
Training loss: 0.039819493889808655
Validation loss: 1.4243618083256546

Epoch: 6| Step: 4
Training loss: 0.038183994591236115
Validation loss: 1.465367260799613

Epoch: 6| Step: 5
Training loss: 0.045135997235774994
Validation loss: 1.4674177221072617

Epoch: 6| Step: 6
Training loss: 0.07510484755039215
Validation loss: 1.4344256808680873

Epoch: 6| Step: 7
Training loss: 0.04996098577976227
Validation loss: 1.444688840578961

Epoch: 6| Step: 8
Training loss: 0.02178410440683365
Validation loss: 1.4241036650955037

Epoch: 6| Step: 9
Training loss: 0.031518496572971344
Validation loss: 1.4413393056520851

Epoch: 6| Step: 10
Training loss: 0.042388323694467545
Validation loss: 1.436628572402462

Epoch: 6| Step: 11
Training loss: 0.029186338186264038
Validation loss: 1.4130535177005235

Epoch: 6| Step: 12
Training loss: 0.022247960790991783
Validation loss: 1.4132202979057067

Epoch: 6| Step: 13
Training loss: 0.040497951209545135
Validation loss: 1.4055280852061447

Epoch: 767| Step: 0
Training loss: 0.021291308104991913
Validation loss: 1.4260418914979505

Epoch: 6| Step: 1
Training loss: 0.04705626145005226
Validation loss: 1.4441801245494554

Epoch: 6| Step: 2
Training loss: 0.05510301887989044
Validation loss: 1.4311095847878406

Epoch: 6| Step: 3
Training loss: 0.02769293263554573
Validation loss: 1.3973272423590384

Epoch: 6| Step: 4
Training loss: 0.05264413356781006
Validation loss: 1.4066316889178367

Epoch: 6| Step: 5
Training loss: 0.04587181657552719
Validation loss: 1.4196709073999876

Epoch: 6| Step: 6
Training loss: 0.05934847891330719
Validation loss: 1.392133875559735

Epoch: 6| Step: 7
Training loss: 0.038848672062158585
Validation loss: 1.4081722151848577

Epoch: 6| Step: 8
Training loss: 0.03683888167142868
Validation loss: 1.4309457207238803

Epoch: 6| Step: 9
Training loss: 0.03206798806786537
Validation loss: 1.4007832478451472

Epoch: 6| Step: 10
Training loss: 0.03881169110536575
Validation loss: 1.4142238017051452

Epoch: 6| Step: 11
Training loss: 0.04174398258328438
Validation loss: 1.3998446092810681

Epoch: 6| Step: 12
Training loss: 0.03561324626207352
Validation loss: 1.4263548774103965

Epoch: 6| Step: 13
Training loss: 0.03231624886393547
Validation loss: 1.4014532886525637

Epoch: 768| Step: 0
Training loss: 0.05708402767777443
Validation loss: 1.3933020099516837

Epoch: 6| Step: 1
Training loss: 0.0365021750330925
Validation loss: 1.3885204990704854

Epoch: 6| Step: 2
Training loss: 0.05641138553619385
Validation loss: 1.4084060051107918

Epoch: 6| Step: 3
Training loss: 0.026422947645187378
Validation loss: 1.4056012169007333

Epoch: 6| Step: 4
Training loss: 0.03932736814022064
Validation loss: 1.4260049109817834

Epoch: 6| Step: 5
Training loss: 0.03932216763496399
Validation loss: 1.4341247543211906

Epoch: 6| Step: 6
Training loss: 0.04852043837308884
Validation loss: 1.4115060696037867

Epoch: 6| Step: 7
Training loss: 0.05241122841835022
Validation loss: 1.4152621421762692

Epoch: 6| Step: 8
Training loss: 0.04125635325908661
Validation loss: 1.4141009738368373

Epoch: 6| Step: 9
Training loss: 0.029658200219273567
Validation loss: 1.3795420463367174

Epoch: 6| Step: 10
Training loss: 0.04015108942985535
Validation loss: 1.4049697819576468

Epoch: 6| Step: 11
Training loss: 0.026916516944766045
Validation loss: 1.3701783867292507

Epoch: 6| Step: 12
Training loss: 0.03845682740211487
Validation loss: 1.3849935429070586

Epoch: 6| Step: 13
Training loss: 0.04269138351082802
Validation loss: 1.3921175432461563

Epoch: 769| Step: 0
Training loss: 0.0316055491566658
Validation loss: 1.3648632328997377

Epoch: 6| Step: 1
Training loss: 0.054882340133190155
Validation loss: 1.3715209781482656

Epoch: 6| Step: 2
Training loss: 0.02860035002231598
Validation loss: 1.3829956464870001

Epoch: 6| Step: 3
Training loss: 0.0330081582069397
Validation loss: 1.3748655498668712

Epoch: 6| Step: 4
Training loss: 0.03308127820491791
Validation loss: 1.383282430710331

Epoch: 6| Step: 5
Training loss: 0.07181645929813385
Validation loss: 1.3777449182284776

Epoch: 6| Step: 6
Training loss: 0.04792855307459831
Validation loss: 1.3880327158076788

Epoch: 6| Step: 7
Training loss: 0.0507022999227047
Validation loss: 1.3928485006414435

Epoch: 6| Step: 8
Training loss: 0.058605365455150604
Validation loss: 1.392315500526018

Epoch: 6| Step: 9
Training loss: 0.039590541273355484
Validation loss: 1.4132079296214606

Epoch: 6| Step: 10
Training loss: 0.03330325335264206
Validation loss: 1.4075257444894442

Epoch: 6| Step: 11
Training loss: 0.02609655261039734
Validation loss: 1.409578542555532

Epoch: 6| Step: 12
Training loss: 0.05869859829545021
Validation loss: 1.4131626377823532

Epoch: 6| Step: 13
Training loss: 0.04300610348582268
Validation loss: 1.4468314955311437

Epoch: 770| Step: 0
Training loss: 0.07375472038984299
Validation loss: 1.4489706254774524

Epoch: 6| Step: 1
Training loss: 0.03392386808991432
Validation loss: 1.4474611051620976

Epoch: 6| Step: 2
Training loss: 0.0511135533452034
Validation loss: 1.4516799142283778

Epoch: 6| Step: 3
Training loss: 0.04242074489593506
Validation loss: 1.4464018197469815

Epoch: 6| Step: 4
Training loss: 0.0374051108956337
Validation loss: 1.4386552097976848

Epoch: 6| Step: 5
Training loss: 0.02691570669412613
Validation loss: 1.400893078055433

Epoch: 6| Step: 6
Training loss: 0.03181607276201248
Validation loss: 1.3902467316196812

Epoch: 6| Step: 7
Training loss: 0.0334773063659668
Validation loss: 1.4028285908442673

Epoch: 6| Step: 8
Training loss: 0.06517669558525085
Validation loss: 1.3932838747578282

Epoch: 6| Step: 9
Training loss: 0.03724249452352524
Validation loss: 1.409914869134144

Epoch: 6| Step: 10
Training loss: 0.03743694722652435
Validation loss: 1.3966782990322317

Epoch: 6| Step: 11
Training loss: 0.05907812714576721
Validation loss: 1.3736981294488395

Epoch: 6| Step: 12
Training loss: 0.050261225551366806
Validation loss: 1.4003530945829166

Epoch: 6| Step: 13
Training loss: 0.03525429219007492
Validation loss: 1.4004442666166572

Epoch: 771| Step: 0
Training loss: 0.020643552765250206
Validation loss: 1.4095069541726062

Epoch: 6| Step: 1
Training loss: 0.026529693976044655
Validation loss: 1.3861618503447501

Epoch: 6| Step: 2
Training loss: 0.027997484430670738
Validation loss: 1.401390749921081

Epoch: 6| Step: 3
Training loss: 0.0440051294863224
Validation loss: 1.4190030854235414

Epoch: 6| Step: 4
Training loss: 0.05189065635204315
Validation loss: 1.4212833553232171

Epoch: 6| Step: 5
Training loss: 0.058757733553647995
Validation loss: 1.40467970601974

Epoch: 6| Step: 6
Training loss: 0.02594960667192936
Validation loss: 1.4183463717019686

Epoch: 6| Step: 7
Training loss: 0.04183065891265869
Validation loss: 1.4241019102834886

Epoch: 6| Step: 8
Training loss: 0.04656219482421875
Validation loss: 1.4322117259425502

Epoch: 6| Step: 9
Training loss: 0.043608468025922775
Validation loss: 1.4357984040373115

Epoch: 6| Step: 10
Training loss: 0.05392098426818848
Validation loss: 1.4287899655680503

Epoch: 6| Step: 11
Training loss: 0.045931655913591385
Validation loss: 1.4209371330917522

Epoch: 6| Step: 12
Training loss: 0.05495522543787956
Validation loss: 1.4379107118934713

Epoch: 6| Step: 13
Training loss: 0.03537779301404953
Validation loss: 1.43350100645455

Epoch: 772| Step: 0
Training loss: 0.03367853909730911
Validation loss: 1.431033879198054

Epoch: 6| Step: 1
Training loss: 0.03369516134262085
Validation loss: 1.4581187886576499

Epoch: 6| Step: 2
Training loss: 0.07927200943231583
Validation loss: 1.4257250960155199

Epoch: 6| Step: 3
Training loss: 0.04267960786819458
Validation loss: 1.4166563236585228

Epoch: 6| Step: 4
Training loss: 0.035532306879758835
Validation loss: 1.4308093504239154

Epoch: 6| Step: 5
Training loss: 0.05181114375591278
Validation loss: 1.4463445640379382

Epoch: 6| Step: 6
Training loss: 0.042060479521751404
Validation loss: 1.4513331702960435

Epoch: 6| Step: 7
Training loss: 0.04327875375747681
Validation loss: 1.420854349290171

Epoch: 6| Step: 8
Training loss: 0.03873014450073242
Validation loss: 1.446884270637266

Epoch: 6| Step: 9
Training loss: 0.05385497957468033
Validation loss: 1.4356046043416506

Epoch: 6| Step: 10
Training loss: 0.043512456119060516
Validation loss: 1.4326978139979865

Epoch: 6| Step: 11
Training loss: 0.03717448189854622
Validation loss: 1.416301578603765

Epoch: 6| Step: 12
Training loss: 0.044209614396095276
Validation loss: 1.4398136497825704

Epoch: 6| Step: 13
Training loss: 0.02141249179840088
Validation loss: 1.4143740682191746

Epoch: 773| Step: 0
Training loss: 0.04079129546880722
Validation loss: 1.4258756688846055

Epoch: 6| Step: 1
Training loss: 0.06937038898468018
Validation loss: 1.4362107092334377

Epoch: 6| Step: 2
Training loss: 0.06333154439926147
Validation loss: 1.4206916914191297

Epoch: 6| Step: 3
Training loss: 0.0649288222193718
Validation loss: 1.3832242988771009

Epoch: 6| Step: 4
Training loss: 0.037368014454841614
Validation loss: 1.4064964248288063

Epoch: 6| Step: 5
Training loss: 0.031441621482372284
Validation loss: 1.3954450315044773

Epoch: 6| Step: 6
Training loss: 0.03419291973114014
Validation loss: 1.402420268263868

Epoch: 6| Step: 7
Training loss: 0.03471990302205086
Validation loss: 1.392201283926605

Epoch: 6| Step: 8
Training loss: 0.06733939051628113
Validation loss: 1.3965502900461997

Epoch: 6| Step: 9
Training loss: 0.033614806830883026
Validation loss: 1.3898901221572713

Epoch: 6| Step: 10
Training loss: 0.04043206572532654
Validation loss: 1.400535519405078

Epoch: 6| Step: 11
Training loss: 0.04002346843481064
Validation loss: 1.418954599288202

Epoch: 6| Step: 12
Training loss: 0.027735654264688492
Validation loss: 1.3663923419931883

Epoch: 6| Step: 13
Training loss: 0.023222830146551132
Validation loss: 1.3646675816146276

Epoch: 774| Step: 0
Training loss: 0.02652015909552574
Validation loss: 1.3952725497625207

Epoch: 6| Step: 1
Training loss: 0.039393454790115356
Validation loss: 1.3754443237858434

Epoch: 6| Step: 2
Training loss: 0.029680371284484863
Validation loss: 1.3802623992325158

Epoch: 6| Step: 3
Training loss: 0.02902265079319477
Validation loss: 1.3879550823601343

Epoch: 6| Step: 4
Training loss: 0.02888072095811367
Validation loss: 1.4042622068876862

Epoch: 6| Step: 5
Training loss: 0.058085113763809204
Validation loss: 1.3805887981127667

Epoch: 6| Step: 6
Training loss: 0.0683833509683609
Validation loss: 1.3734894696102347

Epoch: 6| Step: 7
Training loss: 0.05944112688302994
Validation loss: 1.3993061934748003

Epoch: 6| Step: 8
Training loss: 0.030295908451080322
Validation loss: 1.397512997350385

Epoch: 6| Step: 9
Training loss: 0.0445142537355423
Validation loss: 1.4045037505447224

Epoch: 6| Step: 10
Training loss: 0.029441993683576584
Validation loss: 1.3981444515207762

Epoch: 6| Step: 11
Training loss: 0.07921531051397324
Validation loss: 1.3781719374400314

Epoch: 6| Step: 12
Training loss: 0.04024690389633179
Validation loss: 1.3863437316750968

Epoch: 6| Step: 13
Training loss: 0.031632740050554276
Validation loss: 1.4021641080097487

Epoch: 775| Step: 0
Training loss: 0.04258428514003754
Validation loss: 1.4142901077065417

Epoch: 6| Step: 1
Training loss: 0.03417316824197769
Validation loss: 1.4367643722923853

Epoch: 6| Step: 2
Training loss: 0.05354591831564903
Validation loss: 1.406374433989166

Epoch: 6| Step: 3
Training loss: 0.03461313247680664
Validation loss: 1.4221247787116675

Epoch: 6| Step: 4
Training loss: 0.05761338770389557
Validation loss: 1.4036036499084965

Epoch: 6| Step: 5
Training loss: 0.03497861698269844
Validation loss: 1.4058569400541243

Epoch: 6| Step: 6
Training loss: 0.03508400171995163
Validation loss: 1.3838955548501783

Epoch: 6| Step: 7
Training loss: 0.054722726345062256
Validation loss: 1.3852314513216737

Epoch: 6| Step: 8
Training loss: 0.07234174013137817
Validation loss: 1.3725135018748622

Epoch: 6| Step: 9
Training loss: 0.05306347459554672
Validation loss: 1.3796169181023874

Epoch: 6| Step: 10
Training loss: 0.10911799967288971
Validation loss: 1.399108584209155

Epoch: 6| Step: 11
Training loss: 0.032623179256916046
Validation loss: 1.3757317053374423

Epoch: 6| Step: 12
Training loss: 0.04277333617210388
Validation loss: 1.3703635642605443

Epoch: 6| Step: 13
Training loss: 0.031369999051094055
Validation loss: 1.3855925683052308

Epoch: 776| Step: 0
Training loss: 0.03395042195916176
Validation loss: 1.389031857572576

Epoch: 6| Step: 1
Training loss: 0.022005844861268997
Validation loss: 1.3785826941972137

Epoch: 6| Step: 2
Training loss: 0.0583430677652359
Validation loss: 1.4222978084318099

Epoch: 6| Step: 3
Training loss: 0.05521433800458908
Validation loss: 1.4141539873615387

Epoch: 6| Step: 4
Training loss: 0.059832848608493805
Validation loss: 1.4069681193238945

Epoch: 6| Step: 5
Training loss: 0.06746624410152435
Validation loss: 1.4423185330565258

Epoch: 6| Step: 6
Training loss: 0.0701642632484436
Validation loss: 1.4350809153690134

Epoch: 6| Step: 7
Training loss: 0.041588664054870605
Validation loss: 1.4156686131672194

Epoch: 6| Step: 8
Training loss: 0.035209979861974716
Validation loss: 1.392224314392254

Epoch: 6| Step: 9
Training loss: 0.03392292931675911
Validation loss: 1.4174450841001285

Epoch: 6| Step: 10
Training loss: 0.046187371015548706
Validation loss: 1.4165502440544866

Epoch: 6| Step: 11
Training loss: 0.04564867541193962
Validation loss: 1.3991161174671625

Epoch: 6| Step: 12
Training loss: 0.040694139897823334
Validation loss: 1.406778238152945

Epoch: 6| Step: 13
Training loss: 0.096978560090065
Validation loss: 1.3841157254352365

Epoch: 777| Step: 0
Training loss: 0.04581023380160332
Validation loss: 1.3945824471853112

Epoch: 6| Step: 1
Training loss: 0.05361366644501686
Validation loss: 1.4040986850697508

Epoch: 6| Step: 2
Training loss: 0.06745991110801697
Validation loss: 1.403163968875844

Epoch: 6| Step: 3
Training loss: 0.03696835786104202
Validation loss: 1.40361625020222

Epoch: 6| Step: 4
Training loss: 0.045643389225006104
Validation loss: 1.4051539039099088

Epoch: 6| Step: 5
Training loss: 0.04435103386640549
Validation loss: 1.418932532751432

Epoch: 6| Step: 6
Training loss: 0.041331179440021515
Validation loss: 1.4225090504974447

Epoch: 6| Step: 7
Training loss: 0.04901668801903725
Validation loss: 1.3958450799347253

Epoch: 6| Step: 8
Training loss: 0.030678443610668182
Validation loss: 1.421988106543018

Epoch: 6| Step: 9
Training loss: 0.05948271602392197
Validation loss: 1.42151806687796

Epoch: 6| Step: 10
Training loss: 0.04444816708564758
Validation loss: 1.415862214180731

Epoch: 6| Step: 11
Training loss: 0.03485888987779617
Validation loss: 1.4296097973341584

Epoch: 6| Step: 12
Training loss: 0.05318807065486908
Validation loss: 1.3957589749367005

Epoch: 6| Step: 13
Training loss: 0.036453843116760254
Validation loss: 1.4245652806374334

Epoch: 778| Step: 0
Training loss: 0.04841563105583191
Validation loss: 1.4126783397889906

Epoch: 6| Step: 1
Training loss: 0.049821026623249054
Validation loss: 1.397019863128662

Epoch: 6| Step: 2
Training loss: 0.046828947961330414
Validation loss: 1.3850923981717838

Epoch: 6| Step: 3
Training loss: 0.03984467312693596
Validation loss: 1.38182625591114

Epoch: 6| Step: 4
Training loss: 0.05820779874920845
Validation loss: 1.378840970736678

Epoch: 6| Step: 5
Training loss: 0.03592810034751892
Validation loss: 1.3860003973848076

Epoch: 6| Step: 6
Training loss: 0.04700469970703125
Validation loss: 1.3701065407004407

Epoch: 6| Step: 7
Training loss: 0.048027101904153824
Validation loss: 1.379982538120721

Epoch: 6| Step: 8
Training loss: 0.0367867574095726
Validation loss: 1.3618991945379524

Epoch: 6| Step: 9
Training loss: 0.027492281049489975
Validation loss: 1.3702145379076722

Epoch: 6| Step: 10
Training loss: 0.022524220868945122
Validation loss: 1.3804956123393068

Epoch: 6| Step: 11
Training loss: 0.04161249101161957
Validation loss: 1.3435511159640487

Epoch: 6| Step: 12
Training loss: 0.03368031233549118
Validation loss: 1.3558706609151696

Epoch: 6| Step: 13
Training loss: 0.06708689779043198
Validation loss: 1.3597790163050416

Epoch: 779| Step: 0
Training loss: 0.06746620684862137
Validation loss: 1.3605994409130466

Epoch: 6| Step: 1
Training loss: 0.04603208974003792
Validation loss: 1.3930301409895702

Epoch: 6| Step: 2
Training loss: 0.03662020340561867
Validation loss: 1.3984748573713406

Epoch: 6| Step: 3
Training loss: 0.03640890121459961
Validation loss: 1.3852001306831196

Epoch: 6| Step: 4
Training loss: 0.05689051002264023
Validation loss: 1.3905810797086327

Epoch: 6| Step: 5
Training loss: 0.056704454123973846
Validation loss: 1.3841669405660322

Epoch: 6| Step: 6
Training loss: 0.03985209763050079
Validation loss: 1.3954078753789265

Epoch: 6| Step: 7
Training loss: 0.03680873662233353
Validation loss: 1.4051785174236502

Epoch: 6| Step: 8
Training loss: 0.02549872174859047
Validation loss: 1.393717687617066

Epoch: 6| Step: 9
Training loss: 0.02775687724351883
Validation loss: 1.3964697302028697

Epoch: 6| Step: 10
Training loss: 0.049081940203905106
Validation loss: 1.3924332831495552

Epoch: 6| Step: 11
Training loss: 0.03728991374373436
Validation loss: 1.37945972206772

Epoch: 6| Step: 12
Training loss: 0.03186503052711487
Validation loss: 1.3758953912283785

Epoch: 6| Step: 13
Training loss: 0.07611996680498123
Validation loss: 1.3781188636697748

Epoch: 780| Step: 0
Training loss: 0.0401117317378521
Validation loss: 1.3940313887852493

Epoch: 6| Step: 1
Training loss: 0.050310149788856506
Validation loss: 1.3928972841590963

Epoch: 6| Step: 2
Training loss: 0.0342218279838562
Validation loss: 1.4079042352655882

Epoch: 6| Step: 3
Training loss: 0.055105458945035934
Validation loss: 1.4213072651176042

Epoch: 6| Step: 4
Training loss: 0.046139370650053024
Validation loss: 1.4236452118042977

Epoch: 6| Step: 5
Training loss: 0.03008885309100151
Validation loss: 1.4209142654172835

Epoch: 6| Step: 6
Training loss: 0.03195082023739815
Validation loss: 1.4119249941200338

Epoch: 6| Step: 7
Training loss: 0.045771241188049316
Validation loss: 1.4191581844001688

Epoch: 6| Step: 8
Training loss: 0.04699748009443283
Validation loss: 1.4083337681267851

Epoch: 6| Step: 9
Training loss: 0.07670529931783676
Validation loss: 1.3806560244611514

Epoch: 6| Step: 10
Training loss: 0.051593609154224396
Validation loss: 1.3950496232637795

Epoch: 6| Step: 11
Training loss: 0.04722175747156143
Validation loss: 1.3975182643500708

Epoch: 6| Step: 12
Training loss: 0.05259149521589279
Validation loss: 1.4221834771094783

Epoch: 6| Step: 13
Training loss: 0.02136624976992607
Validation loss: 1.380122814127194

Epoch: 781| Step: 0
Training loss: 0.04331329092383385
Validation loss: 1.3800474187379241

Epoch: 6| Step: 1
Training loss: 0.0492975227534771
Validation loss: 1.404629882304899

Epoch: 6| Step: 2
Training loss: 0.058288317173719406
Validation loss: 1.4428535840844596

Epoch: 6| Step: 3
Training loss: 0.03660532087087631
Validation loss: 1.4199997314842798

Epoch: 6| Step: 4
Training loss: 0.03368381783366203
Validation loss: 1.4229189945805458

Epoch: 6| Step: 5
Training loss: 0.07103195786476135
Validation loss: 1.3981020328819111

Epoch: 6| Step: 6
Training loss: 0.026840776205062866
Validation loss: 1.403542096255928

Epoch: 6| Step: 7
Training loss: 0.04609452560544014
Validation loss: 1.3907919724782307

Epoch: 6| Step: 8
Training loss: 0.02881818637251854
Validation loss: 1.406238446953476

Epoch: 6| Step: 9
Training loss: 0.06936422735452652
Validation loss: 1.377874690999267

Epoch: 6| Step: 10
Training loss: 0.044011808931827545
Validation loss: 1.3858286155167447

Epoch: 6| Step: 11
Training loss: 0.06311611831188202
Validation loss: 1.3824415835001136

Epoch: 6| Step: 12
Training loss: 0.053316399455070496
Validation loss: 1.407109647668818

Epoch: 6| Step: 13
Training loss: 0.050112348049879074
Validation loss: 1.4052920008218417

Epoch: 782| Step: 0
Training loss: 0.02105514332652092
Validation loss: 1.3754323464567944

Epoch: 6| Step: 1
Training loss: 0.05114901810884476
Validation loss: 1.405646094711878

Epoch: 6| Step: 2
Training loss: 0.056681904941797256
Validation loss: 1.4053001929354925

Epoch: 6| Step: 3
Training loss: 0.049277640879154205
Validation loss: 1.4040182623811948

Epoch: 6| Step: 4
Training loss: 0.04062506556510925
Validation loss: 1.3995071700824204

Epoch: 6| Step: 5
Training loss: 0.06247217208147049
Validation loss: 1.3842743314722532

Epoch: 6| Step: 6
Training loss: 0.03323101997375488
Validation loss: 1.385236737548664

Epoch: 6| Step: 7
Training loss: 0.029797784984111786
Validation loss: 1.3721540525395384

Epoch: 6| Step: 8
Training loss: 0.03262954205274582
Validation loss: 1.3982101409666

Epoch: 6| Step: 9
Training loss: 0.04825422912836075
Validation loss: 1.3696225817485521

Epoch: 6| Step: 10
Training loss: 0.037660349160432816
Validation loss: 1.3995947043100994

Epoch: 6| Step: 11
Training loss: 0.03017309308052063
Validation loss: 1.3895535135781893

Epoch: 6| Step: 12
Training loss: 0.050042033195495605
Validation loss: 1.3941830537652458

Epoch: 6| Step: 13
Training loss: 0.018081853166222572
Validation loss: 1.3703767843143915

Epoch: 783| Step: 0
Training loss: 0.030218306928873062
Validation loss: 1.3837911275125319

Epoch: 6| Step: 1
Training loss: 0.042897988110780716
Validation loss: 1.4016160324055662

Epoch: 6| Step: 2
Training loss: 0.041945382952690125
Validation loss: 1.3914513728951896

Epoch: 6| Step: 3
Training loss: 0.02447350323200226
Validation loss: 1.3892465445303148

Epoch: 6| Step: 4
Training loss: 0.0744285136461258
Validation loss: 1.401590742090697

Epoch: 6| Step: 5
Training loss: 0.01712457463145256
Validation loss: 1.4149780145255468

Epoch: 6| Step: 6
Training loss: 0.03444485366344452
Validation loss: 1.3989560552822646

Epoch: 6| Step: 7
Training loss: 0.046162039041519165
Validation loss: 1.4149034792377102

Epoch: 6| Step: 8
Training loss: 0.03099801391363144
Validation loss: 1.4335430924610426

Epoch: 6| Step: 9
Training loss: 0.038069091737270355
Validation loss: 1.4192540344371591

Epoch: 6| Step: 10
Training loss: 0.03290318697690964
Validation loss: 1.4030334334219656

Epoch: 6| Step: 11
Training loss: 0.06076733022928238
Validation loss: 1.4254630175969933

Epoch: 6| Step: 12
Training loss: 0.0329856276512146
Validation loss: 1.413120376166477

Epoch: 6| Step: 13
Training loss: 0.05765090882778168
Validation loss: 1.4331175537519558

Epoch: 784| Step: 0
Training loss: 0.03534354269504547
Validation loss: 1.3839220321306618

Epoch: 6| Step: 1
Training loss: 0.05552419647574425
Validation loss: 1.4237581670925181

Epoch: 6| Step: 2
Training loss: 0.03336889296770096
Validation loss: 1.4507254836379841

Epoch: 6| Step: 3
Training loss: 0.05609705299139023
Validation loss: 1.4264896838895735

Epoch: 6| Step: 4
Training loss: 0.02681085094809532
Validation loss: 1.4269574483235676

Epoch: 6| Step: 5
Training loss: 0.028064697980880737
Validation loss: 1.4328385706870788

Epoch: 6| Step: 6
Training loss: 0.02114308625459671
Validation loss: 1.4516193892366143

Epoch: 6| Step: 7
Training loss: 0.03682155907154083
Validation loss: 1.4437431616167868

Epoch: 6| Step: 8
Training loss: 0.06024319678544998
Validation loss: 1.431539366322179

Epoch: 6| Step: 9
Training loss: 0.05620070546865463
Validation loss: 1.443687258228179

Epoch: 6| Step: 10
Training loss: 0.031405504792928696
Validation loss: 1.4238914315418532

Epoch: 6| Step: 11
Training loss: 0.02584163472056389
Validation loss: 1.412761304968147

Epoch: 6| Step: 12
Training loss: 0.037210650742053986
Validation loss: 1.4023790410769883

Epoch: 6| Step: 13
Training loss: 0.03067774325609207
Validation loss: 1.4290555292560208

Epoch: 785| Step: 0
Training loss: 0.02914530225098133
Validation loss: 1.434419793467368

Epoch: 6| Step: 1
Training loss: 0.03169717639684677
Validation loss: 1.4013974230776551

Epoch: 6| Step: 2
Training loss: 0.04140634089708328
Validation loss: 1.4203146080816946

Epoch: 6| Step: 3
Training loss: 0.035967953503131866
Validation loss: 1.4119694643123175

Epoch: 6| Step: 4
Training loss: 0.04352480173110962
Validation loss: 1.4256294914471206

Epoch: 6| Step: 5
Training loss: 0.028561782091856003
Validation loss: 1.4151806036631267

Epoch: 6| Step: 6
Training loss: 0.02666621282696724
Validation loss: 1.4126658465272637

Epoch: 6| Step: 7
Training loss: 0.043370116502046585
Validation loss: 1.3991543336581158

Epoch: 6| Step: 8
Training loss: 0.048293717205524445
Validation loss: 1.3816655925525132

Epoch: 6| Step: 9
Training loss: 0.0692753717303276
Validation loss: 1.4320122977738738

Epoch: 6| Step: 10
Training loss: 0.04302824288606644
Validation loss: 1.4243255892107565

Epoch: 6| Step: 11
Training loss: 0.0527440570294857
Validation loss: 1.4020129954943092

Epoch: 6| Step: 12
Training loss: 0.06445878744125366
Validation loss: 1.4410709142684937

Epoch: 6| Step: 13
Training loss: 0.03729657456278801
Validation loss: 1.4208891032844462

Epoch: 786| Step: 0
Training loss: 0.03887984901666641
Validation loss: 1.415874610665024

Epoch: 6| Step: 1
Training loss: 0.03738570213317871
Validation loss: 1.4319509306261617

Epoch: 6| Step: 2
Training loss: 0.034752942621707916
Validation loss: 1.4162013902459094

Epoch: 6| Step: 3
Training loss: 0.02173212543129921
Validation loss: 1.4334153347117926

Epoch: 6| Step: 4
Training loss: 0.04991047456860542
Validation loss: 1.4210382693557329

Epoch: 6| Step: 5
Training loss: 0.06869244575500488
Validation loss: 1.4005542314180763

Epoch: 6| Step: 6
Training loss: 0.04064987599849701
Validation loss: 1.374349852403005

Epoch: 6| Step: 7
Training loss: 0.051252514123916626
Validation loss: 1.4110659091703353

Epoch: 6| Step: 8
Training loss: 0.03742177039384842
Validation loss: 1.3886840189656904

Epoch: 6| Step: 9
Training loss: 0.030113816261291504
Validation loss: 1.3959134829941617

Epoch: 6| Step: 10
Training loss: 0.07757410407066345
Validation loss: 1.4082201732102262

Epoch: 6| Step: 11
Training loss: 0.06973730772733688
Validation loss: 1.4039341954774753

Epoch: 6| Step: 12
Training loss: 0.06490200012922287
Validation loss: 1.385304880398576

Epoch: 6| Step: 13
Training loss: 0.06397923827171326
Validation loss: 1.3905188614322292

Epoch: 787| Step: 0
Training loss: 0.06158174201846123
Validation loss: 1.3859548991726292

Epoch: 6| Step: 1
Training loss: 0.039335936307907104
Validation loss: 1.3859698394293427

Epoch: 6| Step: 2
Training loss: 0.07913791388273239
Validation loss: 1.3949755212312103

Epoch: 6| Step: 3
Training loss: 0.041932668536901474
Validation loss: 1.3825100288596204

Epoch: 6| Step: 4
Training loss: 0.03970496356487274
Validation loss: 1.3827059691952122

Epoch: 6| Step: 5
Training loss: 0.03014507330954075
Validation loss: 1.3688738551191104

Epoch: 6| Step: 6
Training loss: 0.02724798396229744
Validation loss: 1.395555147560694

Epoch: 6| Step: 7
Training loss: 0.058829165995121
Validation loss: 1.377764609552199

Epoch: 6| Step: 8
Training loss: 0.03646460920572281
Validation loss: 1.3615354440545524

Epoch: 6| Step: 9
Training loss: 0.0593661367893219
Validation loss: 1.3600405390544603

Epoch: 6| Step: 10
Training loss: 0.04562566801905632
Validation loss: 1.3818073208614061

Epoch: 6| Step: 11
Training loss: 0.028710462152957916
Validation loss: 1.3372558791150329

Epoch: 6| Step: 12
Training loss: 0.041630979627370834
Validation loss: 1.366660355239786

Epoch: 6| Step: 13
Training loss: 0.04844282194972038
Validation loss: 1.3635540700727893

Epoch: 788| Step: 0
Training loss: 0.037163954228162766
Validation loss: 1.3785839644811486

Epoch: 6| Step: 1
Training loss: 0.04787774384021759
Validation loss: 1.4120443572280228

Epoch: 6| Step: 2
Training loss: 0.049398086965084076
Validation loss: 1.3730834934019274

Epoch: 6| Step: 3
Training loss: 0.04694671928882599
Validation loss: 1.3890613791763142

Epoch: 6| Step: 4
Training loss: 0.03733521327376366
Validation loss: 1.3858044314128097

Epoch: 6| Step: 5
Training loss: 0.03767835721373558
Validation loss: 1.3649436517428326

Epoch: 6| Step: 6
Training loss: 0.02620353177189827
Validation loss: 1.3774409794038343

Epoch: 6| Step: 7
Training loss: 0.029199443757534027
Validation loss: 1.3844662776557348

Epoch: 6| Step: 8
Training loss: 0.02981201559305191
Validation loss: 1.3944086413229666

Epoch: 6| Step: 9
Training loss: 0.04307468235492706
Validation loss: 1.380246494406013

Epoch: 6| Step: 10
Training loss: 0.031393252313137054
Validation loss: 1.3607691654594996

Epoch: 6| Step: 11
Training loss: 0.03896408528089523
Validation loss: 1.390084433299239

Epoch: 6| Step: 12
Training loss: 0.04293828085064888
Validation loss: 1.4065656290259412

Epoch: 6| Step: 13
Training loss: 0.08475605398416519
Validation loss: 1.3862013688651464

Epoch: 789| Step: 0
Training loss: 0.05383685231208801
Validation loss: 1.414028820171151

Epoch: 6| Step: 1
Training loss: 0.07818526774644852
Validation loss: 1.4177061678260885

Epoch: 6| Step: 2
Training loss: 0.05035550147294998
Validation loss: 1.429927441381639

Epoch: 6| Step: 3
Training loss: 0.055852048099040985
Validation loss: 1.4319834773258497

Epoch: 6| Step: 4
Training loss: 0.046597033739089966
Validation loss: 1.4292311860669045

Epoch: 6| Step: 5
Training loss: 0.030198359861969948
Validation loss: 1.4042174585403935

Epoch: 6| Step: 6
Training loss: 0.05070797726511955
Validation loss: 1.4154236573044972

Epoch: 6| Step: 7
Training loss: 0.030206795781850815
Validation loss: 1.4316390842519782

Epoch: 6| Step: 8
Training loss: 0.0571027472615242
Validation loss: 1.443622571806754

Epoch: 6| Step: 9
Training loss: 0.04734203219413757
Validation loss: 1.419178193615329

Epoch: 6| Step: 10
Training loss: 0.026265740394592285
Validation loss: 1.396165814450992

Epoch: 6| Step: 11
Training loss: 0.05531627684831619
Validation loss: 1.3978739823064497

Epoch: 6| Step: 12
Training loss: 0.04834683984518051
Validation loss: 1.4044319839887722

Epoch: 6| Step: 13
Training loss: 0.06558725237846375
Validation loss: 1.3994085173453055

Epoch: 790| Step: 0
Training loss: 0.034216247498989105
Validation loss: 1.4258907225824171

Epoch: 6| Step: 1
Training loss: 0.0548982098698616
Validation loss: 1.41962904314841

Epoch: 6| Step: 2
Training loss: 0.033447474241256714
Validation loss: 1.4046481822126655

Epoch: 6| Step: 3
Training loss: 0.05728006362915039
Validation loss: 1.407466524390764

Epoch: 6| Step: 4
Training loss: 0.0377223826944828
Validation loss: 1.4004063760080645

Epoch: 6| Step: 5
Training loss: 0.04379379376769066
Validation loss: 1.3888350891810592

Epoch: 6| Step: 6
Training loss: 0.043178267776966095
Validation loss: 1.4098791435200682

Epoch: 6| Step: 7
Training loss: 0.04388030618429184
Validation loss: 1.3881276858750211

Epoch: 6| Step: 8
Training loss: 0.04623829573392868
Validation loss: 1.4006491156034573

Epoch: 6| Step: 9
Training loss: 0.026182107627391815
Validation loss: 1.4021841659340808

Epoch: 6| Step: 10
Training loss: 0.0545973926782608
Validation loss: 1.4019978943691458

Epoch: 6| Step: 11
Training loss: 0.03829521685838699
Validation loss: 1.3984641541716873

Epoch: 6| Step: 12
Training loss: 0.057504259049892426
Validation loss: 1.4078133542050597

Epoch: 6| Step: 13
Training loss: 0.021137263625860214
Validation loss: 1.4101519110382243

Epoch: 791| Step: 0
Training loss: 0.052865445613861084
Validation loss: 1.4288709528984562

Epoch: 6| Step: 1
Training loss: 0.02178364060819149
Validation loss: 1.4354468173878168

Epoch: 6| Step: 2
Training loss: 0.03290800750255585
Validation loss: 1.4440612382786249

Epoch: 6| Step: 3
Training loss: 0.03341121971607208
Validation loss: 1.442938276516494

Epoch: 6| Step: 4
Training loss: 0.06478851288557053
Validation loss: 1.4299075462484871

Epoch: 6| Step: 5
Training loss: 0.046434178948402405
Validation loss: 1.4157316941086964

Epoch: 6| Step: 6
Training loss: 0.07439121603965759
Validation loss: 1.4299859077699724

Epoch: 6| Step: 7
Training loss: 0.055137962102890015
Validation loss: 1.4202921608442902

Epoch: 6| Step: 8
Training loss: 0.04374242201447487
Validation loss: 1.4067464682363695

Epoch: 6| Step: 9
Training loss: 0.03377941995859146
Validation loss: 1.4191732637343868

Epoch: 6| Step: 10
Training loss: 0.0631326287984848
Validation loss: 1.4393858589151853

Epoch: 6| Step: 11
Training loss: 0.03168606758117676
Validation loss: 1.4378789624860209

Epoch: 6| Step: 12
Training loss: 0.036781441420316696
Validation loss: 1.4362310747946463

Epoch: 6| Step: 13
Training loss: 0.044281378388404846
Validation loss: 1.450407515289963

Epoch: 792| Step: 0
Training loss: 0.06360407918691635
Validation loss: 1.4660054047902424

Epoch: 6| Step: 1
Training loss: 0.0543968603014946
Validation loss: 1.4290334409283054

Epoch: 6| Step: 2
Training loss: 0.07725853472948074
Validation loss: 1.441181662262127

Epoch: 6| Step: 3
Training loss: 0.06959477066993713
Validation loss: 1.4275554341654624

Epoch: 6| Step: 4
Training loss: 0.03897470608353615
Validation loss: 1.4259193533210344

Epoch: 6| Step: 5
Training loss: 0.047976303845644
Validation loss: 1.4039618725417762

Epoch: 6| Step: 6
Training loss: 0.03812309354543686
Validation loss: 1.4398342934987878

Epoch: 6| Step: 7
Training loss: 0.031897373497486115
Validation loss: 1.3909014668515933

Epoch: 6| Step: 8
Training loss: 0.03353194147348404
Validation loss: 1.400995526262509

Epoch: 6| Step: 9
Training loss: 0.04667162522673607
Validation loss: 1.4109383718941801

Epoch: 6| Step: 10
Training loss: 0.04690445587038994
Validation loss: 1.4310382091870872

Epoch: 6| Step: 11
Training loss: 0.0531214140355587
Validation loss: 1.422838689819459

Epoch: 6| Step: 12
Training loss: 0.04911614581942558
Validation loss: 1.4075039496985815

Epoch: 6| Step: 13
Training loss: 0.03798201307654381
Validation loss: 1.402121643866262

Epoch: 793| Step: 0
Training loss: 0.05798256769776344
Validation loss: 1.4298270876689623

Epoch: 6| Step: 1
Training loss: 0.050739239901304245
Validation loss: 1.3932203964520526

Epoch: 6| Step: 2
Training loss: 0.03313180059194565
Validation loss: 1.4048485294465096

Epoch: 6| Step: 3
Training loss: 0.027888478711247444
Validation loss: 1.4094910942098147

Epoch: 6| Step: 4
Training loss: 0.047382622957229614
Validation loss: 1.4121546847845918

Epoch: 6| Step: 5
Training loss: 0.062361858785152435
Validation loss: 1.422861071043117

Epoch: 6| Step: 6
Training loss: 0.060626715421676636
Validation loss: 1.3997405639258764

Epoch: 6| Step: 7
Training loss: 0.03448092192411423
Validation loss: 1.4115597048113424

Epoch: 6| Step: 8
Training loss: 0.04295200854539871
Validation loss: 1.4079253737644484

Epoch: 6| Step: 9
Training loss: 0.03446672484278679
Validation loss: 1.3917412706600722

Epoch: 6| Step: 10
Training loss: 0.06256187707185745
Validation loss: 1.3963675806599278

Epoch: 6| Step: 11
Training loss: 0.037230320274829865
Validation loss: 1.3811411383331462

Epoch: 6| Step: 12
Training loss: 0.03884502127766609
Validation loss: 1.4071233528916554

Epoch: 6| Step: 13
Training loss: 0.027739308774471283
Validation loss: 1.4419968564023253

Epoch: 794| Step: 0
Training loss: 0.02535570040345192
Validation loss: 1.4246994474882722

Epoch: 6| Step: 1
Training loss: 0.06516756117343903
Validation loss: 1.438081540087218

Epoch: 6| Step: 2
Training loss: 0.06656957417726517
Validation loss: 1.4285353614437966

Epoch: 6| Step: 3
Training loss: 0.04767485707998276
Validation loss: 1.4254522400517617

Epoch: 6| Step: 4
Training loss: 0.05606237053871155
Validation loss: 1.4287694628520677

Epoch: 6| Step: 5
Training loss: 0.04355791211128235
Validation loss: 1.403656239791583

Epoch: 6| Step: 6
Training loss: 0.06135288253426552
Validation loss: 1.4010103543599446

Epoch: 6| Step: 7
Training loss: 0.03867834806442261
Validation loss: 1.4045980297109133

Epoch: 6| Step: 8
Training loss: 0.0755288377404213
Validation loss: 1.408680482577252

Epoch: 6| Step: 9
Training loss: 0.031180739402770996
Validation loss: 1.4054736296335857

Epoch: 6| Step: 10
Training loss: 0.04099252447485924
Validation loss: 1.382476229821482

Epoch: 6| Step: 11
Training loss: 0.05437922850251198
Validation loss: 1.3774826270277782

Epoch: 6| Step: 12
Training loss: 0.03504807502031326
Validation loss: 1.396380974400428

Epoch: 6| Step: 13
Training loss: 0.07635536789894104
Validation loss: 1.3906208295975961

Epoch: 795| Step: 0
Training loss: 0.02994459494948387
Validation loss: 1.4062775027367376

Epoch: 6| Step: 1
Training loss: 0.10459578782320023
Validation loss: 1.4247490206072408

Epoch: 6| Step: 2
Training loss: 0.03672846034169197
Validation loss: 1.4077135337296354

Epoch: 6| Step: 3
Training loss: 0.08528432250022888
Validation loss: 1.4273688754727762

Epoch: 6| Step: 4
Training loss: 0.037550512701272964
Validation loss: 1.393567503139537

Epoch: 6| Step: 5
Training loss: 0.022619910538196564
Validation loss: 1.3707933605358165

Epoch: 6| Step: 6
Training loss: 0.04241175204515457
Validation loss: 1.3565710142094602

Epoch: 6| Step: 7
Training loss: 0.033426813781261444
Validation loss: 1.3581896930612543

Epoch: 6| Step: 8
Training loss: 0.03320525959134102
Validation loss: 1.4017620125124532

Epoch: 6| Step: 9
Training loss: 0.0436675101518631
Validation loss: 1.3676578921656455

Epoch: 6| Step: 10
Training loss: 0.07334169745445251
Validation loss: 1.403980186549566

Epoch: 6| Step: 11
Training loss: 0.04841296002268791
Validation loss: 1.4077328366618003

Epoch: 6| Step: 12
Training loss: 0.0880509614944458
Validation loss: 1.3993386837743944

Epoch: 6| Step: 13
Training loss: 0.029959287494421005
Validation loss: 1.3772008861264875

Epoch: 796| Step: 0
Training loss: 0.032407764345407486
Validation loss: 1.4051588786545621

Epoch: 6| Step: 1
Training loss: 0.027864307165145874
Validation loss: 1.417370791076332

Epoch: 6| Step: 2
Training loss: 0.0717986673116684
Validation loss: 1.4194392042775308

Epoch: 6| Step: 3
Training loss: 0.05045774579048157
Validation loss: 1.4379657820988727

Epoch: 6| Step: 4
Training loss: 0.038930997252464294
Validation loss: 1.4073318076390091

Epoch: 6| Step: 5
Training loss: 0.07982014119625092
Validation loss: 1.4369276390280774

Epoch: 6| Step: 6
Training loss: 0.03624007850885391
Validation loss: 1.4294630301895963

Epoch: 6| Step: 7
Training loss: 0.03650788962841034
Validation loss: 1.3945892933876283

Epoch: 6| Step: 8
Training loss: 0.06271210312843323
Validation loss: 1.4133074693782355

Epoch: 6| Step: 9
Training loss: 0.04138042777776718
Validation loss: 1.4212502542362417

Epoch: 6| Step: 10
Training loss: 0.0609777569770813
Validation loss: 1.4337069026885494

Epoch: 6| Step: 11
Training loss: 0.044236935675144196
Validation loss: 1.4273981150760446

Epoch: 6| Step: 12
Training loss: 0.05426037684082985
Validation loss: 1.416765256594586

Epoch: 6| Step: 13
Training loss: 0.06513360142707825
Validation loss: 1.431342988885859

Epoch: 797| Step: 0
Training loss: 0.04622073099017143
Validation loss: 1.4329025976119503

Epoch: 6| Step: 1
Training loss: 0.058104563504457474
Validation loss: 1.4464950920433126

Epoch: 6| Step: 2
Training loss: 0.05252791941165924
Validation loss: 1.4443182547887166

Epoch: 6| Step: 3
Training loss: 0.04761550948023796
Validation loss: 1.4515784966048373

Epoch: 6| Step: 4
Training loss: 0.047373995184898376
Validation loss: 1.4474743617478238

Epoch: 6| Step: 5
Training loss: 0.03380383178591728
Validation loss: 1.4576551593760008

Epoch: 6| Step: 6
Training loss: 0.015131860971450806
Validation loss: 1.468732842835047

Epoch: 6| Step: 7
Training loss: 0.015801243484020233
Validation loss: 1.4513038512199157

Epoch: 6| Step: 8
Training loss: 0.054565440863370895
Validation loss: 1.4667173508674867

Epoch: 6| Step: 9
Training loss: 0.07086624205112457
Validation loss: 1.4459016220543974

Epoch: 6| Step: 10
Training loss: 0.05205287039279938
Validation loss: 1.459244804997598

Epoch: 6| Step: 11
Training loss: 0.05623319000005722
Validation loss: 1.4150179880921558

Epoch: 6| Step: 12
Training loss: 0.050269681960344315
Validation loss: 1.4527926009188417

Epoch: 6| Step: 13
Training loss: 0.07192206382751465
Validation loss: 1.441155529791309

Epoch: 798| Step: 0
Training loss: 0.04553551226854324
Validation loss: 1.444876028004513

Epoch: 6| Step: 1
Training loss: 0.0421123206615448
Validation loss: 1.4177989344443045

Epoch: 6| Step: 2
Training loss: 0.07352301478385925
Validation loss: 1.42867693080697

Epoch: 6| Step: 3
Training loss: 0.03278319537639618
Validation loss: 1.4271153839685584

Epoch: 6| Step: 4
Training loss: 0.038206178694963455
Validation loss: 1.3969924206374793

Epoch: 6| Step: 5
Training loss: 0.05547264590859413
Validation loss: 1.4033449644683509

Epoch: 6| Step: 6
Training loss: 0.04717761278152466
Validation loss: 1.4055686381555372

Epoch: 6| Step: 7
Training loss: 0.046651676297187805
Validation loss: 1.4028193860925653

Epoch: 6| Step: 8
Training loss: 0.06757461279630661
Validation loss: 1.3778565122235207

Epoch: 6| Step: 9
Training loss: 0.05573989450931549
Validation loss: 1.3714091662437684

Epoch: 6| Step: 10
Training loss: 0.04570259153842926
Validation loss: 1.37784061636976

Epoch: 6| Step: 11
Training loss: 0.060314953327178955
Validation loss: 1.3527572834363548

Epoch: 6| Step: 12
Training loss: 0.030261829495429993
Validation loss: 1.3714782140588249

Epoch: 6| Step: 13
Training loss: 0.04880772903561592
Validation loss: 1.369740132362612

Epoch: 799| Step: 0
Training loss: 0.0501885786652565
Validation loss: 1.3850770451689278

Epoch: 6| Step: 1
Training loss: 0.04541473463177681
Validation loss: 1.3972208922909153

Epoch: 6| Step: 2
Training loss: 0.04484323784708977
Validation loss: 1.386703949461701

Epoch: 6| Step: 3
Training loss: 0.03515520691871643
Validation loss: 1.4019494389974942

Epoch: 6| Step: 4
Training loss: 0.04670911282300949
Validation loss: 1.3968632464767785

Epoch: 6| Step: 5
Training loss: 0.04401952028274536
Validation loss: 1.3820214502273067

Epoch: 6| Step: 6
Training loss: 0.04693363234400749
Validation loss: 1.4188467417993853

Epoch: 6| Step: 7
Training loss: 0.03413300961256027
Validation loss: 1.4012311209914505

Epoch: 6| Step: 8
Training loss: 0.03986097872257233
Validation loss: 1.3804260556415846

Epoch: 6| Step: 9
Training loss: 0.03757135570049286
Validation loss: 1.427192998188798

Epoch: 6| Step: 10
Training loss: 0.05876017361879349
Validation loss: 1.3938026428222656

Epoch: 6| Step: 11
Training loss: 0.05218895152211189
Validation loss: 1.435940049027884

Epoch: 6| Step: 12
Training loss: 0.031414516270160675
Validation loss: 1.4244382336575498

Epoch: 6| Step: 13
Training loss: 0.029341021552681923
Validation loss: 1.4179982164854645

Epoch: 800| Step: 0
Training loss: 0.036991484463214874
Validation loss: 1.4356386097528602

Epoch: 6| Step: 1
Training loss: 0.041602399200201035
Validation loss: 1.4415658468841224

Epoch: 6| Step: 2
Training loss: 0.02954799309372902
Validation loss: 1.4316702863221527

Epoch: 6| Step: 3
Training loss: 0.05187080800533295
Validation loss: 1.4326682590669202

Epoch: 6| Step: 4
Training loss: 0.046011783182621
Validation loss: 1.4251749784715715

Epoch: 6| Step: 5
Training loss: 0.05503834784030914
Validation loss: 1.425265169912769

Epoch: 6| Step: 6
Training loss: 0.05057484656572342
Validation loss: 1.4316408499594657

Epoch: 6| Step: 7
Training loss: 0.05625111609697342
Validation loss: 1.43488295168005

Epoch: 6| Step: 8
Training loss: 0.058427438139915466
Validation loss: 1.426598891135185

Epoch: 6| Step: 9
Training loss: 0.03779006749391556
Validation loss: 1.4053298504121843

Epoch: 6| Step: 10
Training loss: 0.04733841121196747
Validation loss: 1.4372124441208378

Epoch: 6| Step: 11
Training loss: 0.04387020319700241
Validation loss: 1.4179423175832278

Epoch: 6| Step: 12
Training loss: 0.03200529143214226
Validation loss: 1.4019848915838427

Epoch: 6| Step: 13
Training loss: 0.02127084508538246
Validation loss: 1.3986065035225244

Testing loss: 2.214957665072547
