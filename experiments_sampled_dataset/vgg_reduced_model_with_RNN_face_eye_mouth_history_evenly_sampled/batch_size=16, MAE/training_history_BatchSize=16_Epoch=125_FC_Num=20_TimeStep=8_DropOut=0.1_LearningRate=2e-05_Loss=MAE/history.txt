Epoch: 1| Step: 0
Training loss: 3.4602200984954834
Validation loss: 5.153575517797983

Epoch: 6| Step: 1
Training loss: 4.787571907043457
Validation loss: 5.133419436793173

Epoch: 6| Step: 2
Training loss: 6.308172225952148
Validation loss: 5.114746150150094

Epoch: 6| Step: 3
Training loss: 4.001534461975098
Validation loss: 5.096555402201991

Epoch: 6| Step: 4
Training loss: 4.459512710571289
Validation loss: 5.075988784913094

Epoch: 6| Step: 5
Training loss: 4.4824018478393555
Validation loss: 5.053511368331089

Epoch: 6| Step: 6
Training loss: 4.9400410652160645
Validation loss: 5.02762117180773

Epoch: 6| Step: 7
Training loss: 5.63068962097168
Validation loss: 4.998202775114326

Epoch: 6| Step: 8
Training loss: 5.429239273071289
Validation loss: 4.965452814614901

Epoch: 6| Step: 9
Training loss: 4.406557559967041
Validation loss: 4.92959810585104

Epoch: 6| Step: 10
Training loss: 4.587733268737793
Validation loss: 4.889279991067866

Epoch: 6| Step: 11
Training loss: 5.251239776611328
Validation loss: 4.846483092154226

Epoch: 6| Step: 12
Training loss: 3.3117690086364746
Validation loss: 4.79851980106805

Epoch: 6| Step: 13
Training loss: 6.8945770263671875
Validation loss: 4.747551789847753

Epoch: 2| Step: 0
Training loss: 6.045520782470703
Validation loss: 4.695875875411495

Epoch: 6| Step: 1
Training loss: 4.249499320983887
Validation loss: 4.641818800280171

Epoch: 6| Step: 2
Training loss: 3.8548364639282227
Validation loss: 4.587622504080495

Epoch: 6| Step: 3
Training loss: 3.7294836044311523
Validation loss: 4.5339902703480055

Epoch: 6| Step: 4
Training loss: 4.108905792236328
Validation loss: 4.482125279723957

Epoch: 6| Step: 5
Training loss: 2.8591432571411133
Validation loss: 4.432022858691472

Epoch: 6| Step: 6
Training loss: 5.422801971435547
Validation loss: 4.383500263255129

Epoch: 6| Step: 7
Training loss: 4.395163536071777
Validation loss: 4.335915544981598

Epoch: 6| Step: 8
Training loss: 4.265933990478516
Validation loss: 4.287153987474339

Epoch: 6| Step: 9
Training loss: 3.3892056941986084
Validation loss: 4.250203368484333

Epoch: 6| Step: 10
Training loss: 4.46464729309082
Validation loss: 4.216920575787944

Epoch: 6| Step: 11
Training loss: 4.247979640960693
Validation loss: 4.180619696135162

Epoch: 6| Step: 12
Training loss: 3.7846240997314453
Validation loss: 4.1397557514970025

Epoch: 6| Step: 13
Training loss: 3.2142906188964844
Validation loss: 4.095130269245435

Epoch: 3| Step: 0
Training loss: 3.864184617996216
Validation loss: 4.045549790064494

Epoch: 6| Step: 1
Training loss: 3.6247944831848145
Validation loss: 4.000900350591188

Epoch: 6| Step: 2
Training loss: 3.1648380756378174
Validation loss: 3.9609482262724187

Epoch: 6| Step: 3
Training loss: 3.9192545413970947
Validation loss: 3.932075362051687

Epoch: 6| Step: 4
Training loss: 4.496868133544922
Validation loss: 3.9018857145822174

Epoch: 6| Step: 5
Training loss: 2.997490406036377
Validation loss: 3.8723627828782603

Epoch: 6| Step: 6
Training loss: 3.5299792289733887
Validation loss: 3.844558015946419

Epoch: 6| Step: 7
Training loss: 4.051972389221191
Validation loss: 3.819718478828348

Epoch: 6| Step: 8
Training loss: 2.97067928314209
Validation loss: 3.7950086644900742

Epoch: 6| Step: 9
Training loss: 3.55940580368042
Validation loss: 3.7715273954535045

Epoch: 6| Step: 10
Training loss: 3.8089394569396973
Validation loss: 3.747164833930231

Epoch: 6| Step: 11
Training loss: 4.4608917236328125
Validation loss: 3.7213463603809314

Epoch: 6| Step: 12
Training loss: 4.006150245666504
Validation loss: 3.694729866520051

Epoch: 6| Step: 13
Training loss: 3.440410852432251
Validation loss: 3.671961269071025

Epoch: 4| Step: 0
Training loss: 2.3300890922546387
Validation loss: 3.652400691022155

Epoch: 6| Step: 1
Training loss: 2.686234474182129
Validation loss: 3.639499915543423

Epoch: 6| Step: 2
Training loss: 3.1839306354522705
Validation loss: 3.623405453979328

Epoch: 6| Step: 3
Training loss: 3.066967487335205
Validation loss: 3.6089609643464446

Epoch: 6| Step: 4
Training loss: 3.559598922729492
Validation loss: 3.597769965407669

Epoch: 6| Step: 5
Training loss: 3.4820923805236816
Validation loss: 3.586374282836914

Epoch: 6| Step: 6
Training loss: 4.013383865356445
Validation loss: 3.577810836094682

Epoch: 6| Step: 7
Training loss: 4.051041603088379
Validation loss: 3.568080448335217

Epoch: 6| Step: 8
Training loss: 4.07838249206543
Validation loss: 3.550846187017297

Epoch: 6| Step: 9
Training loss: 3.330340623855591
Validation loss: 3.532824780351372

Epoch: 6| Step: 10
Training loss: 3.587918758392334
Validation loss: 3.5209191050580753

Epoch: 6| Step: 11
Training loss: 3.890145778656006
Validation loss: 3.5058858163895144

Epoch: 6| Step: 12
Training loss: 3.4409565925598145
Validation loss: 3.4875251221400436

Epoch: 6| Step: 13
Training loss: 4.636373996734619
Validation loss: 3.4738342223628873

Epoch: 5| Step: 0
Training loss: 3.36940598487854
Validation loss: 3.4609551634839786

Epoch: 6| Step: 1
Training loss: 2.8755531311035156
Validation loss: 3.4365249859389437

Epoch: 6| Step: 2
Training loss: 4.620662212371826
Validation loss: 3.4354066848754883

Epoch: 6| Step: 3
Training loss: 3.4494130611419678
Validation loss: 3.4311569070303314

Epoch: 6| Step: 4
Training loss: 3.1245996952056885
Validation loss: 3.4260852311247136

Epoch: 6| Step: 5
Training loss: 3.775306224822998
Validation loss: 3.410874464178598

Epoch: 6| Step: 6
Training loss: 3.036747932434082
Validation loss: 3.396198862342424

Epoch: 6| Step: 7
Training loss: 2.9529800415039062
Validation loss: 3.3866310504175003

Epoch: 6| Step: 8
Training loss: 3.247288465499878
Validation loss: 3.387034995581514

Epoch: 6| Step: 9
Training loss: 3.389055013656616
Validation loss: 3.3787552900211786

Epoch: 6| Step: 10
Training loss: 3.0416507720947266
Validation loss: 3.3641326760733

Epoch: 6| Step: 11
Training loss: 4.271025657653809
Validation loss: 3.349460676152219

Epoch: 6| Step: 12
Training loss: 2.9201629161834717
Validation loss: 3.343108259221559

Epoch: 6| Step: 13
Training loss: 2.440624237060547
Validation loss: 3.3362172906116774

Epoch: 6| Step: 0
Training loss: 3.983445167541504
Validation loss: 3.3369070406882995

Epoch: 6| Step: 1
Training loss: 3.255537748336792
Validation loss: 3.3280131739954792

Epoch: 6| Step: 2
Training loss: 2.6185803413391113
Validation loss: 3.320602232410062

Epoch: 6| Step: 3
Training loss: 2.3398656845092773
Validation loss: 3.311364525107927

Epoch: 6| Step: 4
Training loss: 2.725970506668091
Validation loss: 3.3143099815614763

Epoch: 6| Step: 5
Training loss: 4.0145463943481445
Validation loss: 3.307251643109065

Epoch: 6| Step: 6
Training loss: 3.1712148189544678
Validation loss: 3.302074060645155

Epoch: 6| Step: 7
Training loss: 3.8342628479003906
Validation loss: 3.292694842943581

Epoch: 6| Step: 8
Training loss: 2.8550901412963867
Validation loss: 3.2863461509827645

Epoch: 6| Step: 9
Training loss: 2.5387320518493652
Validation loss: 3.281991389489943

Epoch: 6| Step: 10
Training loss: 3.8532421588897705
Validation loss: 3.2838672104702202

Epoch: 6| Step: 11
Training loss: 3.889505386352539
Validation loss: 3.278705148286717

Epoch: 6| Step: 12
Training loss: 3.7639968395233154
Validation loss: 3.27436230515921

Epoch: 6| Step: 13
Training loss: 2.6866228580474854
Validation loss: 3.267745300005841

Epoch: 7| Step: 0
Training loss: 3.5490355491638184
Validation loss: 3.2634188616147606

Epoch: 6| Step: 1
Training loss: 2.8852219581604004
Validation loss: 3.2602647273771224

Epoch: 6| Step: 2
Training loss: 3.414306163787842
Validation loss: 3.2611942368168987

Epoch: 6| Step: 3
Training loss: 3.0443062782287598
Validation loss: 3.257297482541812

Epoch: 6| Step: 4
Training loss: 2.8613364696502686
Validation loss: 3.2849051695997997

Epoch: 6| Step: 5
Training loss: 3.003696918487549
Validation loss: 3.249977796308456

Epoch: 6| Step: 6
Training loss: 3.609254837036133
Validation loss: 3.240447716046405

Epoch: 6| Step: 7
Training loss: 3.637777805328369
Validation loss: 3.2408995602720525

Epoch: 6| Step: 8
Training loss: 3.750246524810791
Validation loss: 3.2393190988930325

Epoch: 6| Step: 9
Training loss: 3.614304304122925
Validation loss: 3.23350344422043

Epoch: 6| Step: 10
Training loss: 2.2898271083831787
Validation loss: 3.229212171287947

Epoch: 6| Step: 11
Training loss: 3.3994741439819336
Validation loss: 3.230414605909778

Epoch: 6| Step: 12
Training loss: 3.0207417011260986
Validation loss: 3.2256378742956344

Epoch: 6| Step: 13
Training loss: 3.0825889110565186
Validation loss: 3.225661749480873

Epoch: 8| Step: 0
Training loss: 2.592937469482422
Validation loss: 3.223509229639525

Epoch: 6| Step: 1
Training loss: 3.5275630950927734
Validation loss: 3.2170693130903345

Epoch: 6| Step: 2
Training loss: 3.578299045562744
Validation loss: 3.2132947342370146

Epoch: 6| Step: 3
Training loss: 2.848444938659668
Validation loss: 3.207004416373468

Epoch: 6| Step: 4
Training loss: 3.3346948623657227
Validation loss: 3.2017647604788504

Epoch: 6| Step: 5
Training loss: 3.5555810928344727
Validation loss: 3.1963517024952877

Epoch: 6| Step: 6
Training loss: 3.6398749351501465
Validation loss: 3.1925034164100565

Epoch: 6| Step: 7
Training loss: 3.3093819618225098
Validation loss: 3.1896269629078526

Epoch: 6| Step: 8
Training loss: 3.7891411781311035
Validation loss: 3.1818139245433192

Epoch: 6| Step: 9
Training loss: 3.209536552429199
Validation loss: 3.176495147007768

Epoch: 6| Step: 10
Training loss: 2.3784899711608887
Validation loss: 3.1771835075911654

Epoch: 6| Step: 11
Training loss: 3.1350016593933105
Validation loss: 3.1991324552925686

Epoch: 6| Step: 12
Training loss: 3.0251476764678955
Validation loss: 3.1662243002204487

Epoch: 6| Step: 13
Training loss: 2.4792561531066895
Validation loss: 3.1689905197389665

Epoch: 9| Step: 0
Training loss: 3.243511438369751
Validation loss: 3.175670003378263

Epoch: 6| Step: 1
Training loss: 2.9044766426086426
Validation loss: 3.182700839093936

Epoch: 6| Step: 2
Training loss: 4.14141321182251
Validation loss: 3.19095270095333

Epoch: 6| Step: 3
Training loss: 3.164191246032715
Validation loss: 3.1636448009039766

Epoch: 6| Step: 4
Training loss: 3.4610393047332764
Validation loss: 3.1601895081099642

Epoch: 6| Step: 5
Training loss: 2.582014799118042
Validation loss: 3.157386790039719

Epoch: 6| Step: 6
Training loss: 2.5017011165618896
Validation loss: 3.1555736193092923

Epoch: 6| Step: 7
Training loss: 3.619861125946045
Validation loss: 3.1549644957306566

Epoch: 6| Step: 8
Training loss: 2.8031060695648193
Validation loss: 3.150211752101939

Epoch: 6| Step: 9
Training loss: 2.890315055847168
Validation loss: 3.153675699746737

Epoch: 6| Step: 10
Training loss: 3.54998779296875
Validation loss: 3.148532711049562

Epoch: 6| Step: 11
Training loss: 2.998201370239258
Validation loss: 3.1456794610587497

Epoch: 6| Step: 12
Training loss: 2.966484785079956
Validation loss: 3.141519328599335

Epoch: 6| Step: 13
Training loss: 3.853133201599121
Validation loss: 3.1417925819273917

Epoch: 10| Step: 0
Training loss: 2.325845241546631
Validation loss: 3.1413835966458885

Epoch: 6| Step: 1
Training loss: 3.4735915660858154
Validation loss: 3.137527665784282

Epoch: 6| Step: 2
Training loss: 2.8888463973999023
Validation loss: 3.141299757906186

Epoch: 6| Step: 3
Training loss: 4.710690498352051
Validation loss: 3.131203205354752

Epoch: 6| Step: 4
Training loss: 3.1592047214508057
Validation loss: 3.129422982533773

Epoch: 6| Step: 5
Training loss: 3.554661273956299
Validation loss: 3.1354654168569915

Epoch: 6| Step: 6
Training loss: 2.6630938053131104
Validation loss: 3.135771307893979

Epoch: 6| Step: 7
Training loss: 2.8489227294921875
Validation loss: 3.1420145624427387

Epoch: 6| Step: 8
Training loss: 3.0054569244384766
Validation loss: 3.1340660664343063

Epoch: 6| Step: 9
Training loss: 2.958491325378418
Validation loss: 3.127985110846899

Epoch: 6| Step: 10
Training loss: 3.327354669570923
Validation loss: 3.1238769715832126

Epoch: 6| Step: 11
Training loss: 3.1906745433807373
Validation loss: 3.1193700144367833

Epoch: 6| Step: 12
Training loss: 3.255399227142334
Validation loss: 3.118982832918885

Epoch: 6| Step: 13
Training loss: 2.4239954948425293
Validation loss: 3.1169475047819075

Epoch: 11| Step: 0
Training loss: 3.349987506866455
Validation loss: 3.1139987463592202

Epoch: 6| Step: 1
Training loss: 2.525437355041504
Validation loss: 3.113978344907043

Epoch: 6| Step: 2
Training loss: 3.8216664791107178
Validation loss: 3.11386082249303

Epoch: 6| Step: 3
Training loss: 3.4027750492095947
Validation loss: 3.1142593147934123

Epoch: 6| Step: 4
Training loss: 3.6022462844848633
Validation loss: 3.1122616875556206

Epoch: 6| Step: 5
Training loss: 2.0038905143737793
Validation loss: 3.1094555854797363

Epoch: 6| Step: 6
Training loss: 2.8214638233184814
Validation loss: 3.1036257846381075

Epoch: 6| Step: 7
Training loss: 3.1620917320251465
Validation loss: 3.100609969067317

Epoch: 6| Step: 8
Training loss: 3.0182626247406006
Validation loss: 3.1006464471099195

Epoch: 6| Step: 9
Training loss: 2.8603639602661133
Validation loss: 3.099107801273305

Epoch: 6| Step: 10
Training loss: 3.014875888824463
Validation loss: 3.098264576286398

Epoch: 6| Step: 11
Training loss: 2.8908801078796387
Validation loss: 3.0958007509990404

Epoch: 6| Step: 12
Training loss: 4.138349533081055
Validation loss: 3.0947988033294678

Epoch: 6| Step: 13
Training loss: 3.3653721809387207
Validation loss: 3.0911773071494153

Epoch: 12| Step: 0
Training loss: 4.106561183929443
Validation loss: 3.086247008333924

Epoch: 6| Step: 1
Training loss: 4.078133583068848
Validation loss: 3.0852660466265935

Epoch: 6| Step: 2
Training loss: 2.5529685020446777
Validation loss: 3.0817381207660963

Epoch: 6| Step: 3
Training loss: 2.924238920211792
Validation loss: 3.0780903652150142

Epoch: 6| Step: 4
Training loss: 2.5774264335632324
Validation loss: 3.074314319959251

Epoch: 6| Step: 5
Training loss: 3.2898192405700684
Validation loss: 3.0720034696722545

Epoch: 6| Step: 6
Training loss: 1.980812668800354
Validation loss: 3.0715980555421565

Epoch: 6| Step: 7
Training loss: 2.536832332611084
Validation loss: 3.0701130692676832

Epoch: 6| Step: 8
Training loss: 3.572327136993408
Validation loss: 3.0687879054777083

Epoch: 6| Step: 9
Training loss: 3.4752097129821777
Validation loss: 3.068051915014944

Epoch: 6| Step: 10
Training loss: 2.5679163932800293
Validation loss: 3.064608981532435

Epoch: 6| Step: 11
Training loss: 2.6135950088500977
Validation loss: 3.0637923286807154

Epoch: 6| Step: 12
Training loss: 3.3848819732666016
Validation loss: 3.0636753984676894

Epoch: 6| Step: 13
Training loss: 4.591828346252441
Validation loss: 3.0610008496110157

Epoch: 13| Step: 0
Training loss: 2.894552230834961
Validation loss: 3.0604876805377264

Epoch: 6| Step: 1
Training loss: 2.637908935546875
Validation loss: 3.059808426005866

Epoch: 6| Step: 2
Training loss: 2.406804084777832
Validation loss: 3.0577166054838445

Epoch: 6| Step: 3
Training loss: 3.5240161418914795
Validation loss: 3.057723222240325

Epoch: 6| Step: 4
Training loss: 2.798525810241699
Validation loss: 3.056511740530691

Epoch: 6| Step: 5
Training loss: 3.428453207015991
Validation loss: 3.0541813296656453

Epoch: 6| Step: 6
Training loss: 2.0476856231689453
Validation loss: 3.0532252660361667

Epoch: 6| Step: 7
Training loss: 3.4700632095336914
Validation loss: 3.051959219799247

Epoch: 6| Step: 8
Training loss: 3.0391592979431152
Validation loss: 3.048878159574283

Epoch: 6| Step: 9
Training loss: 3.4255990982055664
Validation loss: 3.0486750833449827

Epoch: 6| Step: 10
Training loss: 3.8079113960266113
Validation loss: 3.0474704106648765

Epoch: 6| Step: 11
Training loss: 3.6469662189483643
Validation loss: 3.0463830629984536

Epoch: 6| Step: 12
Training loss: 2.4174485206604004
Validation loss: 3.0455576630048853

Epoch: 6| Step: 13
Training loss: 4.495619297027588
Validation loss: 3.0440143180149857

Epoch: 14| Step: 0
Training loss: 2.8007285594940186
Validation loss: 3.044627797219061

Epoch: 6| Step: 1
Training loss: 3.3780155181884766
Validation loss: 3.0424100763054303

Epoch: 6| Step: 2
Training loss: 3.1143999099731445
Validation loss: 3.0411378106763287

Epoch: 6| Step: 3
Training loss: 2.708047389984131
Validation loss: 3.0430886847998506

Epoch: 6| Step: 4
Training loss: 2.931319236755371
Validation loss: 3.0395675525870374

Epoch: 6| Step: 5
Training loss: 3.7983741760253906
Validation loss: 3.039063856165896

Epoch: 6| Step: 6
Training loss: 3.0939221382141113
Validation loss: 3.0368701540013796

Epoch: 6| Step: 7
Training loss: 3.0099875926971436
Validation loss: 3.038236874406056

Epoch: 6| Step: 8
Training loss: 3.3509538173675537
Validation loss: 3.03451879050142

Epoch: 6| Step: 9
Training loss: 3.1326234340667725
Validation loss: 3.032616217931112

Epoch: 6| Step: 10
Training loss: 3.0128183364868164
Validation loss: 3.0321813578246744

Epoch: 6| Step: 11
Training loss: 2.9347753524780273
Validation loss: 3.0311610109062603

Epoch: 6| Step: 12
Training loss: 3.137259006500244
Validation loss: 3.0273132631855626

Epoch: 6| Step: 13
Training loss: 2.719660758972168
Validation loss: 3.0290478198759017

Epoch: 15| Step: 0
Training loss: 2.8176069259643555
Validation loss: 3.0246884489572174

Epoch: 6| Step: 1
Training loss: 2.4214367866516113
Validation loss: 3.024277279453893

Epoch: 6| Step: 2
Training loss: 2.7826409339904785
Validation loss: 3.0250793759540846

Epoch: 6| Step: 3
Training loss: 2.6693241596221924
Validation loss: 3.0207039104994906

Epoch: 6| Step: 4
Training loss: 4.205956935882568
Validation loss: 3.0197918363796767

Epoch: 6| Step: 5
Training loss: 3.3499038219451904
Validation loss: 3.0167811480901574

Epoch: 6| Step: 6
Training loss: 3.349681854248047
Validation loss: 3.013492140718686

Epoch: 6| Step: 7
Training loss: 4.161608695983887
Validation loss: 3.0113530287178616

Epoch: 6| Step: 8
Training loss: 3.0918867588043213
Validation loss: 3.008657201643913

Epoch: 6| Step: 9
Training loss: 2.800454616546631
Validation loss: 3.008635336352933

Epoch: 6| Step: 10
Training loss: 2.7262754440307617
Validation loss: 3.009945120862735

Epoch: 6| Step: 11
Training loss: 2.689176559448242
Validation loss: 3.007369331134263

Epoch: 6| Step: 12
Training loss: 2.7758755683898926
Validation loss: 3.006986077113818

Epoch: 6| Step: 13
Training loss: 3.3641245365142822
Validation loss: 3.006741787797661

Epoch: 16| Step: 0
Training loss: 3.5278995037078857
Validation loss: 3.0041529235019477

Epoch: 6| Step: 1
Training loss: 2.4921319484710693
Validation loss: 3.005266345957274

Epoch: 6| Step: 2
Training loss: 3.3964967727661133
Validation loss: 3.0072790884202525

Epoch: 6| Step: 3
Training loss: 2.493274211883545
Validation loss: 3.0104431285653064

Epoch: 6| Step: 4
Training loss: 2.9199676513671875
Validation loss: 3.013886959322037

Epoch: 6| Step: 5
Training loss: 2.4992172718048096
Validation loss: 3.00109835081203

Epoch: 6| Step: 6
Training loss: 3.588501453399658
Validation loss: 2.9972098155688216

Epoch: 6| Step: 7
Training loss: 3.4653689861297607
Validation loss: 2.9940339339676725

Epoch: 6| Step: 8
Training loss: 2.7355055809020996
Validation loss: 2.9960804600869455

Epoch: 6| Step: 9
Training loss: 2.805689573287964
Validation loss: 2.996092393834104

Epoch: 6| Step: 10
Training loss: 3.0377790927886963
Validation loss: 2.9905866781870523

Epoch: 6| Step: 11
Training loss: 3.584282636642456
Validation loss: 2.990107431206652

Epoch: 6| Step: 12
Training loss: 3.409329414367676
Validation loss: 2.9779702027638755

Epoch: 6| Step: 13
Training loss: 2.836503505706787
Validation loss: 2.9738724282992783

Epoch: 17| Step: 0
Training loss: 3.7374348640441895
Validation loss: 2.9773602280565488

Epoch: 6| Step: 1
Training loss: 2.6790175437927246
Validation loss: 2.9762771360335813

Epoch: 6| Step: 2
Training loss: 3.6699752807617188
Validation loss: 2.9760179904199417

Epoch: 6| Step: 3
Training loss: 3.2886691093444824
Validation loss: 2.974928048349196

Epoch: 6| Step: 4
Training loss: 2.376502275466919
Validation loss: 2.9703320226361676

Epoch: 6| Step: 5
Training loss: 3.1364104747772217
Validation loss: 2.961804469426473

Epoch: 6| Step: 6
Training loss: 3.1409857273101807
Validation loss: 2.960573222047539

Epoch: 6| Step: 7
Training loss: 3.121063709259033
Validation loss: 2.9600366905171382

Epoch: 6| Step: 8
Training loss: 3.590637683868408
Validation loss: 2.956010046825614

Epoch: 6| Step: 9
Training loss: 2.6508145332336426
Validation loss: 2.952344386808334

Epoch: 6| Step: 10
Training loss: 2.5388174057006836
Validation loss: 2.954995391189411

Epoch: 6| Step: 11
Training loss: 2.8138012886047363
Validation loss: 2.9526333039806736

Epoch: 6| Step: 12
Training loss: 3.497568368911743
Validation loss: 2.951844128229285

Epoch: 6| Step: 13
Training loss: 1.7754862308502197
Validation loss: 2.9525816645673526

Epoch: 18| Step: 0
Training loss: 3.0793704986572266
Validation loss: 2.9544788355468423

Epoch: 6| Step: 1
Training loss: 3.671543598175049
Validation loss: 2.949497494646298

Epoch: 6| Step: 2
Training loss: 2.683865547180176
Validation loss: 2.9474458027911443

Epoch: 6| Step: 3
Training loss: 3.252514600753784
Validation loss: 2.9464546224122405

Epoch: 6| Step: 4
Training loss: 2.857883930206299
Validation loss: 2.9465611929534585

Epoch: 6| Step: 5
Training loss: 3.513233184814453
Validation loss: 2.9424208107814995

Epoch: 6| Step: 6
Training loss: 3.14876127243042
Validation loss: 2.942330196339597

Epoch: 6| Step: 7
Training loss: 3.1476120948791504
Validation loss: 2.9419747988382974

Epoch: 6| Step: 8
Training loss: 2.5002293586730957
Validation loss: 2.940964639827769

Epoch: 6| Step: 9
Training loss: 2.436645030975342
Validation loss: 2.9425671331344114

Epoch: 6| Step: 10
Training loss: 3.085562229156494
Validation loss: 2.940339811386601

Epoch: 6| Step: 11
Training loss: 2.6933064460754395
Validation loss: 2.939306233518867

Epoch: 6| Step: 12
Training loss: 3.470315933227539
Validation loss: 2.9369169127556587

Epoch: 6| Step: 13
Training loss: 2.740502119064331
Validation loss: 2.9345328269466275

Epoch: 19| Step: 0
Training loss: 1.8652539253234863
Validation loss: 2.9356070333911526

Epoch: 6| Step: 1
Training loss: 2.757472038269043
Validation loss: 2.9370896636798816

Epoch: 6| Step: 2
Training loss: 3.755760908126831
Validation loss: 2.945140156694638

Epoch: 6| Step: 3
Training loss: 2.7948131561279297
Validation loss: 2.935653732668969

Epoch: 6| Step: 4
Training loss: 3.4542441368103027
Validation loss: 2.922810487849738

Epoch: 6| Step: 5
Training loss: 2.5360472202301025
Validation loss: 2.923361252712947

Epoch: 6| Step: 6
Training loss: 2.2806568145751953
Validation loss: 2.9243698889209377

Epoch: 6| Step: 7
Training loss: 3.7664954662323
Validation loss: 2.922589850682084

Epoch: 6| Step: 8
Training loss: 3.0144927501678467
Validation loss: 2.91745065873669

Epoch: 6| Step: 9
Training loss: 2.9838645458221436
Validation loss: 2.9076324739763812

Epoch: 6| Step: 10
Training loss: 2.2753705978393555
Validation loss: 2.906415257402646

Epoch: 6| Step: 11
Training loss: 4.189099311828613
Validation loss: 2.8998619843554754

Epoch: 6| Step: 12
Training loss: 3.449897527694702
Validation loss: 2.9002586949256157

Epoch: 6| Step: 13
Training loss: 3.095198392868042
Validation loss: 2.8988968223653813

Epoch: 20| Step: 0
Training loss: 3.5108184814453125
Validation loss: 2.902122054048764

Epoch: 6| Step: 1
Training loss: 2.8819286823272705
Validation loss: 2.9096843286227156

Epoch: 6| Step: 2
Training loss: 3.3050429821014404
Validation loss: 2.9523392954180316

Epoch: 6| Step: 3
Training loss: 2.8357291221618652
Validation loss: 2.915982659145068

Epoch: 6| Step: 4
Training loss: 1.8899515867233276
Validation loss: 2.8981108793648342

Epoch: 6| Step: 5
Training loss: 3.5698437690734863
Validation loss: 2.9006281514321604

Epoch: 6| Step: 6
Training loss: 3.0468287467956543
Validation loss: 2.911185097950761

Epoch: 6| Step: 7
Training loss: 3.416271686553955
Validation loss: 2.919355164292038

Epoch: 6| Step: 8
Training loss: 2.501728057861328
Validation loss: 2.9220824856911936

Epoch: 6| Step: 9
Training loss: 4.141820907592773
Validation loss: 2.924747085058561

Epoch: 6| Step: 10
Training loss: 3.3504583835601807
Validation loss: 2.9264834542428293

Epoch: 6| Step: 11
Training loss: 3.2210230827331543
Validation loss: 2.92393950493105

Epoch: 6| Step: 12
Training loss: 2.116725444793701
Validation loss: 2.923503619368358

Epoch: 6| Step: 13
Training loss: 1.7956682443618774
Validation loss: 2.9225955137642483

Epoch: 21| Step: 0
Training loss: 3.066192150115967
Validation loss: 2.918565647576445

Epoch: 6| Step: 1
Training loss: 3.1564459800720215
Validation loss: 2.922285579865979

Epoch: 6| Step: 2
Training loss: 2.389021396636963
Validation loss: 2.918442641535113

Epoch: 6| Step: 3
Training loss: 3.905803918838501
Validation loss: 2.9021594524383545

Epoch: 6| Step: 4
Training loss: 1.7197697162628174
Validation loss: 2.888688523282287

Epoch: 6| Step: 5
Training loss: 3.6041059494018555
Validation loss: 2.887492836162608

Epoch: 6| Step: 6
Training loss: 3.586381196975708
Validation loss: 2.8821305459545505

Epoch: 6| Step: 7
Training loss: 3.7265419960021973
Validation loss: 2.88062947539873

Epoch: 6| Step: 8
Training loss: 1.8700896501541138
Validation loss: 2.8814145108704925

Epoch: 6| Step: 9
Training loss: 3.0152509212493896
Validation loss: 2.8790806237087456

Epoch: 6| Step: 10
Training loss: 2.9529948234558105
Validation loss: 2.8769678146608415

Epoch: 6| Step: 11
Training loss: 2.6230382919311523
Validation loss: 2.878748711719308

Epoch: 6| Step: 12
Training loss: 3.5003271102905273
Validation loss: 2.8769862933825423

Epoch: 6| Step: 13
Training loss: 2.582401990890503
Validation loss: 2.8727329546405422

Epoch: 22| Step: 0
Training loss: 3.485110282897949
Validation loss: 2.8720551024201098

Epoch: 6| Step: 1
Training loss: 2.620769500732422
Validation loss: 2.8679811211042505

Epoch: 6| Step: 2
Training loss: 2.5543227195739746
Validation loss: 2.867156772203343

Epoch: 6| Step: 3
Training loss: 3.2963781356811523
Validation loss: 2.8647433096362698

Epoch: 6| Step: 4
Training loss: 2.754277229309082
Validation loss: 2.8644172453111216

Epoch: 6| Step: 5
Training loss: 2.1462111473083496
Validation loss: 2.8620633643160582

Epoch: 6| Step: 6
Training loss: 2.863358974456787
Validation loss: 2.863020655929401

Epoch: 6| Step: 7
Training loss: 3.1460695266723633
Validation loss: 2.860886614809754

Epoch: 6| Step: 8
Training loss: 2.8557825088500977
Validation loss: 2.8595485584710234

Epoch: 6| Step: 9
Training loss: 2.804535388946533
Validation loss: 2.8592039026239866

Epoch: 6| Step: 10
Training loss: 3.3899893760681152
Validation loss: 2.857358391566943

Epoch: 6| Step: 11
Training loss: 3.3942487239837646
Validation loss: 2.8573469808024745

Epoch: 6| Step: 12
Training loss: 3.195795774459839
Validation loss: 2.8564777553722425

Epoch: 6| Step: 13
Training loss: 3.2853057384490967
Validation loss: 2.8542866758120957

Epoch: 23| Step: 0
Training loss: 3.1362576484680176
Validation loss: 2.852172120924919

Epoch: 6| Step: 1
Training loss: 2.5028271675109863
Validation loss: 2.852092448101249

Epoch: 6| Step: 2
Training loss: 4.284710884094238
Validation loss: 2.8493721741502003

Epoch: 6| Step: 3
Training loss: 1.9451584815979004
Validation loss: 2.849248093943442

Epoch: 6| Step: 4
Training loss: 2.6563210487365723
Validation loss: 2.8471607008287982

Epoch: 6| Step: 5
Training loss: 2.7056710720062256
Validation loss: 2.845853523541522

Epoch: 6| Step: 6
Training loss: 2.4154882431030273
Validation loss: 2.846988785651422

Epoch: 6| Step: 7
Training loss: 3.7829861640930176
Validation loss: 2.8456559924669165

Epoch: 6| Step: 8
Training loss: 3.074906349182129
Validation loss: 2.843743493480067

Epoch: 6| Step: 9
Training loss: 3.9380548000335693
Validation loss: 2.8424460836636123

Epoch: 6| Step: 10
Training loss: 2.78659725189209
Validation loss: 2.8435326596742034

Epoch: 6| Step: 11
Training loss: 2.3886427879333496
Validation loss: 2.8407588722885295

Epoch: 6| Step: 12
Training loss: 2.7507424354553223
Validation loss: 2.84016909650577

Epoch: 6| Step: 13
Training loss: 3.294506072998047
Validation loss: 2.837988663745183

Epoch: 24| Step: 0
Training loss: 2.450653076171875
Validation loss: 2.838564283104353

Epoch: 6| Step: 1
Training loss: 3.8328959941864014
Validation loss: 2.838223380427207

Epoch: 6| Step: 2
Training loss: 3.446364402770996
Validation loss: 2.838911417991884

Epoch: 6| Step: 3
Training loss: 2.9939725399017334
Validation loss: 2.8363741546548824

Epoch: 6| Step: 4
Training loss: 2.473621368408203
Validation loss: 2.8374534371078655

Epoch: 6| Step: 5
Training loss: 3.929952621459961
Validation loss: 2.8404322439624416

Epoch: 6| Step: 6
Training loss: 2.6609630584716797
Validation loss: 2.8426135945063766

Epoch: 6| Step: 7
Training loss: 2.778698682785034
Validation loss: 2.8422679849850234

Epoch: 6| Step: 8
Training loss: 2.839568853378296
Validation loss: 2.8449125110462146

Epoch: 6| Step: 9
Training loss: 2.6295700073242188
Validation loss: 2.8415841415364254

Epoch: 6| Step: 10
Training loss: 2.143400192260742
Validation loss: 2.8390859224463023

Epoch: 6| Step: 11
Training loss: 2.4846560955047607
Validation loss: 2.843747954214773

Epoch: 6| Step: 12
Training loss: 3.0410404205322266
Validation loss: 2.836875625835952

Epoch: 6| Step: 13
Training loss: 4.224449157714844
Validation loss: 2.8340948115112963

Epoch: 25| Step: 0
Training loss: 1.7584471702575684
Validation loss: 2.8313813106988066

Epoch: 6| Step: 1
Training loss: 2.7338523864746094
Validation loss: 2.8297966423855034

Epoch: 6| Step: 2
Training loss: 2.623128890991211
Validation loss: 2.8275526441553587

Epoch: 6| Step: 3
Training loss: 3.6836533546447754
Validation loss: 2.8287677559801327

Epoch: 6| Step: 4
Training loss: 2.408475637435913
Validation loss: 2.8277692410253708

Epoch: 6| Step: 5
Training loss: 3.259686231613159
Validation loss: 2.826049030468028

Epoch: 6| Step: 6
Training loss: 2.8935861587524414
Validation loss: 2.8257027902910785

Epoch: 6| Step: 7
Training loss: 3.470597267150879
Validation loss: 2.8251877753965315

Epoch: 6| Step: 8
Training loss: 3.4162228107452393
Validation loss: 2.8274549181743334

Epoch: 6| Step: 9
Training loss: 2.960636615753174
Validation loss: 2.8262991238665838

Epoch: 6| Step: 10
Training loss: 2.8928561210632324
Validation loss: 2.8278801466829036

Epoch: 6| Step: 11
Training loss: 3.006837844848633
Validation loss: 2.827266964861142

Epoch: 6| Step: 12
Training loss: 2.979641914367676
Validation loss: 2.827291332265382

Epoch: 6| Step: 13
Training loss: 3.3999147415161133
Validation loss: 2.8274650932640157

Epoch: 26| Step: 0
Training loss: 2.3721113204956055
Validation loss: 2.8254826427787862

Epoch: 6| Step: 1
Training loss: 3.7795331478118896
Validation loss: 2.8236258465756654

Epoch: 6| Step: 2
Training loss: 3.6916701793670654
Validation loss: 2.8252126734743834

Epoch: 6| Step: 3
Training loss: 2.896394968032837
Validation loss: 2.8244377413103656

Epoch: 6| Step: 4
Training loss: 3.1682472229003906
Validation loss: 2.8216521278504403

Epoch: 6| Step: 5
Training loss: 3.1670284271240234
Validation loss: 2.8217260683736494

Epoch: 6| Step: 6
Training loss: 3.265406608581543
Validation loss: 2.823225875054636

Epoch: 6| Step: 7
Training loss: 3.1822805404663086
Validation loss: 2.8232485196923696

Epoch: 6| Step: 8
Training loss: 2.7255749702453613
Validation loss: 2.8255763387167327

Epoch: 6| Step: 9
Training loss: 2.2026078701019287
Validation loss: 2.823922775124991

Epoch: 6| Step: 10
Training loss: 3.005763053894043
Validation loss: 2.822942159509146

Epoch: 6| Step: 11
Training loss: 2.4893388748168945
Validation loss: 2.8165748683355187

Epoch: 6| Step: 12
Training loss: 2.488243579864502
Validation loss: 2.8201783703219507

Epoch: 6| Step: 13
Training loss: 2.5216875076293945
Validation loss: 2.824570394331409

Epoch: 27| Step: 0
Training loss: 3.098335027694702
Validation loss: 2.829918017951391

Epoch: 6| Step: 1
Training loss: 3.3018131256103516
Validation loss: 2.8301723311024327

Epoch: 6| Step: 2
Training loss: 2.3757529258728027
Validation loss: 2.8253998397499003

Epoch: 6| Step: 3
Training loss: 2.72951078414917
Validation loss: 2.815830220458328

Epoch: 6| Step: 4
Training loss: 2.5546481609344482
Validation loss: 2.812876952591763

Epoch: 6| Step: 5
Training loss: 2.920044422149658
Validation loss: 2.812681741611932

Epoch: 6| Step: 6
Training loss: 2.6552157402038574
Validation loss: 2.8248520333279847

Epoch: 6| Step: 7
Training loss: 3.049741268157959
Validation loss: 2.807118167159378

Epoch: 6| Step: 8
Training loss: 2.6179749965667725
Validation loss: 2.8068992989037627

Epoch: 6| Step: 9
Training loss: 3.4427330493927
Validation loss: 2.8072145062108196

Epoch: 6| Step: 10
Training loss: 3.7924695014953613
Validation loss: 2.805373255924512

Epoch: 6| Step: 11
Training loss: 2.835286855697632
Validation loss: 2.8086580666162635

Epoch: 6| Step: 12
Training loss: 2.8222060203552246
Validation loss: 2.8111735582351685

Epoch: 6| Step: 13
Training loss: 2.8703739643096924
Validation loss: 2.8102901007539485

Epoch: 28| Step: 0
Training loss: 3.196385622024536
Validation loss: 2.815053355309271

Epoch: 6| Step: 1
Training loss: 2.473545551300049
Validation loss: 2.816627069186139

Epoch: 6| Step: 2
Training loss: 2.0175347328186035
Validation loss: 2.8209193111747823

Epoch: 6| Step: 3
Training loss: 2.9757909774780273
Validation loss: 2.8338206865454234

Epoch: 6| Step: 4
Training loss: 3.1047444343566895
Validation loss: 2.835292677725515

Epoch: 6| Step: 5
Training loss: 3.120717763900757
Validation loss: 2.8239723482439594

Epoch: 6| Step: 6
Training loss: 2.4799697399139404
Validation loss: 2.8062675178691907

Epoch: 6| Step: 7
Training loss: 2.6675591468811035
Validation loss: 2.7966163671144875

Epoch: 6| Step: 8
Training loss: 3.107332706451416
Validation loss: 2.7919946434677287

Epoch: 6| Step: 9
Training loss: 2.4883055686950684
Validation loss: 2.796798147181029

Epoch: 6| Step: 10
Training loss: 3.4171037673950195
Validation loss: 2.801440082570558

Epoch: 6| Step: 11
Training loss: 2.6482582092285156
Validation loss: 2.8048255366663777

Epoch: 6| Step: 12
Training loss: 4.116888046264648
Validation loss: 2.7956235229328112

Epoch: 6| Step: 13
Training loss: 3.0641891956329346
Validation loss: 2.791114681510515

Epoch: 29| Step: 0
Training loss: 3.304168224334717
Validation loss: 2.7922773771388556

Epoch: 6| Step: 1
Training loss: 2.4293065071105957
Validation loss: 2.7901883150941584

Epoch: 6| Step: 2
Training loss: 4.255766868591309
Validation loss: 2.7918897905657367

Epoch: 6| Step: 3
Training loss: 2.758953094482422
Validation loss: 2.7954506950993694

Epoch: 6| Step: 4
Training loss: 2.546067476272583
Validation loss: 2.7924014676001763

Epoch: 6| Step: 5
Training loss: 2.6225433349609375
Validation loss: 2.791581710179647

Epoch: 6| Step: 6
Training loss: 2.6723904609680176
Validation loss: 2.7872564587541806

Epoch: 6| Step: 7
Training loss: 2.296171188354492
Validation loss: 2.788568037812428

Epoch: 6| Step: 8
Training loss: 2.8052899837493896
Validation loss: 2.7837147430707048

Epoch: 6| Step: 9
Training loss: 2.4910998344421387
Validation loss: 2.7846145758064846

Epoch: 6| Step: 10
Training loss: 2.2638707160949707
Validation loss: 2.7846149039524857

Epoch: 6| Step: 11
Training loss: 3.6848485469818115
Validation loss: 2.7873766960636264

Epoch: 6| Step: 12
Training loss: 3.377039670944214
Validation loss: 2.7859147338457007

Epoch: 6| Step: 13
Training loss: 3.4250566959381104
Validation loss: 2.785692035510976

Epoch: 30| Step: 0
Training loss: 2.4511375427246094
Validation loss: 2.779541369407408

Epoch: 6| Step: 1
Training loss: 3.409304618835449
Validation loss: 2.781261351800734

Epoch: 6| Step: 2
Training loss: 3.4010233879089355
Validation loss: 2.784082422974289

Epoch: 6| Step: 3
Training loss: 3.3003597259521484
Validation loss: 2.7822200047072543

Epoch: 6| Step: 4
Training loss: 2.5730090141296387
Validation loss: 2.783270030893305

Epoch: 6| Step: 5
Training loss: 3.073593854904175
Validation loss: 2.7834533414533063

Epoch: 6| Step: 6
Training loss: 2.686044692993164
Validation loss: 2.7854264090138097

Epoch: 6| Step: 7
Training loss: 2.970327854156494
Validation loss: 2.789222927503688

Epoch: 6| Step: 8
Training loss: 3.300520658493042
Validation loss: 2.7771911672366563

Epoch: 6| Step: 9
Training loss: 3.49493670463562
Validation loss: 2.7706602081175773

Epoch: 6| Step: 10
Training loss: 2.835134983062744
Validation loss: 2.768153449540497

Epoch: 6| Step: 11
Training loss: 3.058056116104126
Validation loss: 2.765950233705582

Epoch: 6| Step: 12
Training loss: 1.994920253753662
Validation loss: 2.764906391020744

Epoch: 6| Step: 13
Training loss: 1.7196295261383057
Validation loss: 2.76170745459936

Epoch: 31| Step: 0
Training loss: 2.411320447921753
Validation loss: 2.7636198894951933

Epoch: 6| Step: 1
Training loss: 2.6770596504211426
Validation loss: 2.759009430485387

Epoch: 6| Step: 2
Training loss: 3.651697874069214
Validation loss: 2.758541440451017

Epoch: 6| Step: 3
Training loss: 3.5017805099487305
Validation loss: 2.756777499311714

Epoch: 6| Step: 4
Training loss: 2.7299904823303223
Validation loss: 2.7556397479067565

Epoch: 6| Step: 5
Training loss: 3.0170109272003174
Validation loss: 2.7553452163614254

Epoch: 6| Step: 6
Training loss: 3.4307961463928223
Validation loss: 2.7539107184256277

Epoch: 6| Step: 7
Training loss: 3.0235824584960938
Validation loss: 2.7515115891733477

Epoch: 6| Step: 8
Training loss: 2.469845771789551
Validation loss: 2.754719739319176

Epoch: 6| Step: 9
Training loss: 2.8740429878234863
Validation loss: 2.75992234804297

Epoch: 6| Step: 10
Training loss: 2.570164442062378
Validation loss: 2.7642067042730187

Epoch: 6| Step: 11
Training loss: 2.807438850402832
Validation loss: 2.760683398092947

Epoch: 6| Step: 12
Training loss: 2.6436731815338135
Validation loss: 2.7512510002300306

Epoch: 6| Step: 13
Training loss: 2.521941900253296
Validation loss: 2.7474303732636156

Epoch: 32| Step: 0
Training loss: 2.4080426692962646
Validation loss: 2.744674390362155

Epoch: 6| Step: 1
Training loss: 3.4538488388061523
Validation loss: 2.741958866837204

Epoch: 6| Step: 2
Training loss: 2.537870407104492
Validation loss: 2.750157399844098

Epoch: 6| Step: 3
Training loss: 3.327281951904297
Validation loss: 2.7540560935133245

Epoch: 6| Step: 4
Training loss: 2.7279584407806396
Validation loss: 2.7533628863673054

Epoch: 6| Step: 5
Training loss: 2.7293477058410645
Validation loss: 2.7539962363499466

Epoch: 6| Step: 6
Training loss: 2.8089513778686523
Validation loss: 2.7587169447252826

Epoch: 6| Step: 7
Training loss: 2.9233644008636475
Validation loss: 2.7562854315644953

Epoch: 6| Step: 8
Training loss: 2.6791234016418457
Validation loss: 2.745209765690629

Epoch: 6| Step: 9
Training loss: 2.8367695808410645
Validation loss: 2.743235480400824

Epoch: 6| Step: 10
Training loss: 3.204294204711914
Validation loss: 2.7404972917290142

Epoch: 6| Step: 11
Training loss: 2.8674840927124023
Validation loss: 2.7417269419598322

Epoch: 6| Step: 12
Training loss: 2.4067037105560303
Validation loss: 2.736207736435757

Epoch: 6| Step: 13
Training loss: 3.6782734394073486
Validation loss: 2.7382532063350884

Epoch: 33| Step: 0
Training loss: 3.163828134536743
Validation loss: 2.73686315936427

Epoch: 6| Step: 1
Training loss: 2.6243038177490234
Validation loss: 2.7398250461906515

Epoch: 6| Step: 2
Training loss: 1.4158105850219727
Validation loss: 2.735399361579649

Epoch: 6| Step: 3
Training loss: 2.6008121967315674
Validation loss: 2.7348987184545046

Epoch: 6| Step: 4
Training loss: 2.8432438373565674
Validation loss: 2.7401716555318525

Epoch: 6| Step: 5
Training loss: 2.6726326942443848
Validation loss: 2.736890169882005

Epoch: 6| Step: 6
Training loss: 2.87735652923584
Validation loss: 2.7253011811164116

Epoch: 6| Step: 7
Training loss: 3.373737335205078
Validation loss: 2.7255311524996193

Epoch: 6| Step: 8
Training loss: 2.5340962409973145
Validation loss: 2.7262519046824467

Epoch: 6| Step: 9
Training loss: 3.404010534286499
Validation loss: 2.7256946204811014

Epoch: 6| Step: 10
Training loss: 3.2106378078460693
Validation loss: 2.729971880553871

Epoch: 6| Step: 11
Training loss: 3.046426296234131
Validation loss: 2.733634541111608

Epoch: 6| Step: 12
Training loss: 2.816480875015259
Validation loss: 2.747982276383267

Epoch: 6| Step: 13
Training loss: 3.961568593978882
Validation loss: 2.751331131945374

Epoch: 34| Step: 0
Training loss: 2.198410987854004
Validation loss: 2.756944646117508

Epoch: 6| Step: 1
Training loss: 2.9881515502929688
Validation loss: 2.7593932074885212

Epoch: 6| Step: 2
Training loss: 2.450721263885498
Validation loss: 2.73826245082322

Epoch: 6| Step: 3
Training loss: 2.85861873626709
Validation loss: 2.7217984276433147

Epoch: 6| Step: 4
Training loss: 3.2865967750549316
Validation loss: 2.7183316189755677

Epoch: 6| Step: 5
Training loss: 3.150665283203125
Validation loss: 2.7409576574961343

Epoch: 6| Step: 6
Training loss: 3.361870050430298
Validation loss: 2.7515181264569684

Epoch: 6| Step: 7
Training loss: 2.727837085723877
Validation loss: 2.726436056116576

Epoch: 6| Step: 8
Training loss: 2.674116611480713
Validation loss: 2.7178624753029115

Epoch: 6| Step: 9
Training loss: 3.790308952331543
Validation loss: 2.71362312762968

Epoch: 6| Step: 10
Training loss: 2.686077117919922
Validation loss: 2.711456537246704

Epoch: 6| Step: 11
Training loss: 3.0626044273376465
Validation loss: 2.713999127828947

Epoch: 6| Step: 12
Training loss: 2.4204862117767334
Validation loss: 2.730621548109157

Epoch: 6| Step: 13
Training loss: 2.156386375427246
Validation loss: 2.751377351822392

Epoch: 35| Step: 0
Training loss: 2.1925418376922607
Validation loss: 2.7425961391900175

Epoch: 6| Step: 1
Training loss: 3.1335458755493164
Validation loss: 2.7203182635768766

Epoch: 6| Step: 2
Training loss: 3.3298323154449463
Validation loss: 2.707993607367239

Epoch: 6| Step: 3
Training loss: 2.772350311279297
Validation loss: 2.708147966733543

Epoch: 6| Step: 4
Training loss: 3.1535797119140625
Validation loss: 2.710956455558859

Epoch: 6| Step: 5
Training loss: 3.228330373764038
Validation loss: 2.7136000510184997

Epoch: 6| Step: 6
Training loss: 2.29300594329834
Validation loss: 2.712973008873642

Epoch: 6| Step: 7
Training loss: 3.7809009552001953
Validation loss: 2.7146042418736283

Epoch: 6| Step: 8
Training loss: 2.3933489322662354
Validation loss: 2.7153445059253323

Epoch: 6| Step: 9
Training loss: 3.0553627014160156
Validation loss: 2.7150918796498287

Epoch: 6| Step: 10
Training loss: 3.2115559577941895
Validation loss: 2.7161474663724183

Epoch: 6| Step: 11
Training loss: 1.9473129510879517
Validation loss: 2.71397146871013

Epoch: 6| Step: 12
Training loss: 2.8056089878082275
Validation loss: 2.710727548086515

Epoch: 6| Step: 13
Training loss: 2.845855236053467
Validation loss: 2.7116906309640534

Epoch: 36| Step: 0
Training loss: 2.8894777297973633
Validation loss: 2.714564872044389

Epoch: 6| Step: 1
Training loss: 2.6368398666381836
Validation loss: 2.7145244485588482

Epoch: 6| Step: 2
Training loss: 2.49428129196167
Validation loss: 2.7034098384200886

Epoch: 6| Step: 3
Training loss: 3.2984776496887207
Validation loss: 2.7076413016165457

Epoch: 6| Step: 4
Training loss: 3.027646064758301
Validation loss: 2.711280733026484

Epoch: 6| Step: 5
Training loss: 2.9354419708251953
Validation loss: 2.7125381526126655

Epoch: 6| Step: 6
Training loss: 2.237596273422241
Validation loss: 2.709244538378972

Epoch: 6| Step: 7
Training loss: 2.79219126701355
Validation loss: 2.701474435867802

Epoch: 6| Step: 8
Training loss: 1.9454772472381592
Validation loss: 2.696114699045817

Epoch: 6| Step: 9
Training loss: 3.173692226409912
Validation loss: 2.694361607233683

Epoch: 6| Step: 10
Training loss: 3.211681604385376
Validation loss: 2.6949017586246615

Epoch: 6| Step: 11
Training loss: 2.629274606704712
Validation loss: 2.693919853497577

Epoch: 6| Step: 12
Training loss: 3.456266403198242
Validation loss: 2.694443092551283

Epoch: 6| Step: 13
Training loss: 3.379357099533081
Validation loss: 2.6906535702366985

Epoch: 37| Step: 0
Training loss: 3.7366719245910645
Validation loss: 2.6922214518311205

Epoch: 6| Step: 1
Training loss: 2.536100387573242
Validation loss: 2.691424697958013

Epoch: 6| Step: 2
Training loss: 2.712085485458374
Validation loss: 2.686502041355256

Epoch: 6| Step: 3
Training loss: 3.480433464050293
Validation loss: 2.6930820967561457

Epoch: 6| Step: 4
Training loss: 3.156571626663208
Validation loss: 2.693128401233304

Epoch: 6| Step: 5
Training loss: 2.8689217567443848
Validation loss: 2.6976670193415817

Epoch: 6| Step: 6
Training loss: 2.4425551891326904
Validation loss: 2.6965178622994372

Epoch: 6| Step: 7
Training loss: 2.513380289077759
Validation loss: 2.711654573358515

Epoch: 6| Step: 8
Training loss: 2.7555694580078125
Validation loss: 2.7022413310184272

Epoch: 6| Step: 9
Training loss: 3.1807026863098145
Validation loss: 2.6934746824285036

Epoch: 6| Step: 10
Training loss: 2.3216896057128906
Validation loss: 2.695552267054076

Epoch: 6| Step: 11
Training loss: 3.0202975273132324
Validation loss: 2.691370905086558

Epoch: 6| Step: 12
Training loss: 2.111942768096924
Validation loss: 2.689865904469644

Epoch: 6| Step: 13
Training loss: 2.9368679523468018
Validation loss: 2.6850272558068715

Epoch: 38| Step: 0
Training loss: 3.3065671920776367
Validation loss: 2.679562076445549

Epoch: 6| Step: 1
Training loss: 2.038701057434082
Validation loss: 2.680036275617538

Epoch: 6| Step: 2
Training loss: 2.797621726989746
Validation loss: 2.6806581430537726

Epoch: 6| Step: 3
Training loss: 3.5153889656066895
Validation loss: 2.682678040637765

Epoch: 6| Step: 4
Training loss: 2.539328098297119
Validation loss: 2.679735255497758

Epoch: 6| Step: 5
Training loss: 3.460770606994629
Validation loss: 2.6774692843037267

Epoch: 6| Step: 6
Training loss: 2.925027370452881
Validation loss: 2.674804061971685

Epoch: 6| Step: 7
Training loss: 3.4341702461242676
Validation loss: 2.6762771298808437

Epoch: 6| Step: 8
Training loss: 1.9235963821411133
Validation loss: 2.675919045684158

Epoch: 6| Step: 9
Training loss: 3.0445523262023926
Validation loss: 2.6764285743877454

Epoch: 6| Step: 10
Training loss: 2.3134143352508545
Validation loss: 2.67643045097269

Epoch: 6| Step: 11
Training loss: 3.206056594848633
Validation loss: 2.6734230723432315

Epoch: 6| Step: 12
Training loss: 2.1228573322296143
Validation loss: 2.673124469736571

Epoch: 6| Step: 13
Training loss: 2.8990166187286377
Validation loss: 2.671439875838577

Epoch: 39| Step: 0
Training loss: 3.5214462280273438
Validation loss: 2.6700310296909784

Epoch: 6| Step: 1
Training loss: 3.1700127124786377
Validation loss: 2.668840010960897

Epoch: 6| Step: 2
Training loss: 2.0591373443603516
Validation loss: 2.66810542280956

Epoch: 6| Step: 3
Training loss: 3.2497129440307617
Validation loss: 2.6695486960872525

Epoch: 6| Step: 4
Training loss: 3.44935941696167
Validation loss: 2.6670482312479327

Epoch: 6| Step: 5
Training loss: 2.400641441345215
Validation loss: 2.6658893323713735

Epoch: 6| Step: 6
Training loss: 2.6553516387939453
Validation loss: 2.6653081883666334

Epoch: 6| Step: 7
Training loss: 1.672654151916504
Validation loss: 2.668107707013366

Epoch: 6| Step: 8
Training loss: 2.494880437850952
Validation loss: 2.663587144626084

Epoch: 6| Step: 9
Training loss: 2.866088390350342
Validation loss: 2.6637489154774654

Epoch: 6| Step: 10
Training loss: 2.997495412826538
Validation loss: 2.673854902226438

Epoch: 6| Step: 11
Training loss: 2.7794270515441895
Validation loss: 2.6893155600434993

Epoch: 6| Step: 12
Training loss: 3.0790631771087646
Validation loss: 2.7031949489347395

Epoch: 6| Step: 13
Training loss: 3.1381747722625732
Validation loss: 2.7128712156767487

Epoch: 40| Step: 0
Training loss: 2.3612735271453857
Validation loss: 2.697045200614519

Epoch: 6| Step: 1
Training loss: 3.400026321411133
Validation loss: 2.708796006377025

Epoch: 6| Step: 2
Training loss: 2.341529130935669
Validation loss: 2.690930861298756

Epoch: 6| Step: 3
Training loss: 2.7290313243865967
Validation loss: 2.6901232401529946

Epoch: 6| Step: 4
Training loss: 2.810582399368286
Validation loss: 2.6890290885843258

Epoch: 6| Step: 5
Training loss: 2.5793604850769043
Validation loss: 2.6778352042680145

Epoch: 6| Step: 6
Training loss: 2.8396332263946533
Validation loss: 2.663405195359261

Epoch: 6| Step: 7
Training loss: 3.957859516143799
Validation loss: 2.658582179777084

Epoch: 6| Step: 8
Training loss: 2.8018970489501953
Validation loss: 2.6570446850151144

Epoch: 6| Step: 9
Training loss: 2.2746729850769043
Validation loss: 2.6655449892884944

Epoch: 6| Step: 10
Training loss: 2.786123275756836
Validation loss: 2.673638853975522

Epoch: 6| Step: 11
Training loss: 2.0450499057769775
Validation loss: 2.6717730286300823

Epoch: 6| Step: 12
Training loss: 3.4734110832214355
Validation loss: 2.6592638159310944

Epoch: 6| Step: 13
Training loss: 3.2427141666412354
Validation loss: 2.6578475095892466

Epoch: 41| Step: 0
Training loss: 1.6530969142913818
Validation loss: 2.6637392044067383

Epoch: 6| Step: 1
Training loss: 3.5009374618530273
Validation loss: 2.6800573154162337

Epoch: 6| Step: 2
Training loss: 3.2576255798339844
Validation loss: 2.717375491255073

Epoch: 6| Step: 3
Training loss: 2.2652313709259033
Validation loss: 2.727432502213345

Epoch: 6| Step: 4
Training loss: 2.0822064876556396
Validation loss: 2.694120740377775

Epoch: 6| Step: 5
Training loss: 2.9751901626586914
Validation loss: 2.6885706070930726

Epoch: 6| Step: 6
Training loss: 3.266244411468506
Validation loss: 2.668832637930429

Epoch: 6| Step: 7
Training loss: 3.169072151184082
Validation loss: 2.64597846359335

Epoch: 6| Step: 8
Training loss: 2.9564390182495117
Validation loss: 2.648188526912402

Epoch: 6| Step: 9
Training loss: 2.0014395713806152
Validation loss: 2.678785934243151

Epoch: 6| Step: 10
Training loss: 2.8434066772460938
Validation loss: 2.6962672433545514

Epoch: 6| Step: 11
Training loss: 3.6957054138183594
Validation loss: 2.71267928102965

Epoch: 6| Step: 12
Training loss: 3.216634750366211
Validation loss: 2.713722975023331

Epoch: 6| Step: 13
Training loss: 2.6179275512695312
Validation loss: 2.6860609182747464

Epoch: 42| Step: 0
Training loss: 2.617007255554199
Validation loss: 2.6592919929053194

Epoch: 6| Step: 1
Training loss: 2.620960235595703
Validation loss: 2.653788774244247

Epoch: 6| Step: 2
Training loss: 2.210794448852539
Validation loss: 2.6518438682761243

Epoch: 6| Step: 3
Training loss: 3.881993293762207
Validation loss: 2.6500627994537354

Epoch: 6| Step: 4
Training loss: 2.5331735610961914
Validation loss: 2.6624409639707176

Epoch: 6| Step: 5
Training loss: 2.6673583984375
Validation loss: 2.6733207625727498

Epoch: 6| Step: 6
Training loss: 2.358574390411377
Validation loss: 2.6890550992822133

Epoch: 6| Step: 7
Training loss: 3.465813159942627
Validation loss: 2.6817982478808333

Epoch: 6| Step: 8
Training loss: 2.9600791931152344
Validation loss: 2.6522945639907674

Epoch: 6| Step: 9
Training loss: 3.2133378982543945
Validation loss: 2.6350169720188266

Epoch: 6| Step: 10
Training loss: 2.9424331188201904
Validation loss: 2.6270756131859234

Epoch: 6| Step: 11
Training loss: 2.1822867393493652
Validation loss: 2.626102332145937

Epoch: 6| Step: 12
Training loss: 2.417233943939209
Validation loss: 2.6273943275533695

Epoch: 6| Step: 13
Training loss: 3.388622760772705
Validation loss: 2.6449864577221613

Epoch: 43| Step: 0
Training loss: 2.8585147857666016
Validation loss: 2.663607330732448

Epoch: 6| Step: 1
Training loss: 2.4210450649261475
Validation loss: 2.6823088276770806

Epoch: 6| Step: 2
Training loss: 2.541275978088379
Validation loss: 2.696818067181495

Epoch: 6| Step: 3
Training loss: 3.2065212726593018
Validation loss: 2.701714538758801

Epoch: 6| Step: 4
Training loss: 2.462378978729248
Validation loss: 2.690544246345438

Epoch: 6| Step: 5
Training loss: 2.5199568271636963
Validation loss: 2.6663622856140137

Epoch: 6| Step: 6
Training loss: 2.819148540496826
Validation loss: 2.656095894434119

Epoch: 6| Step: 7
Training loss: 2.9262943267822266
Validation loss: 2.6624513851699008

Epoch: 6| Step: 8
Training loss: 2.3902242183685303
Validation loss: 2.6658498292328208

Epoch: 6| Step: 9
Training loss: 2.940762519836426
Validation loss: 2.6832572285847

Epoch: 6| Step: 10
Training loss: 3.36826753616333
Validation loss: 2.6924402765048447

Epoch: 6| Step: 11
Training loss: 2.373600721359253
Validation loss: 2.7081282549006964

Epoch: 6| Step: 12
Training loss: 3.4390389919281006
Validation loss: 2.727616922829741

Epoch: 6| Step: 13
Training loss: 3.6621038913726807
Validation loss: 2.710914614380047

Epoch: 44| Step: 0
Training loss: 2.437803268432617
Validation loss: 2.694564786008609

Epoch: 6| Step: 1
Training loss: 2.786101818084717
Validation loss: 2.664344823488625

Epoch: 6| Step: 2
Training loss: 2.939995050430298
Validation loss: 2.653684336652038

Epoch: 6| Step: 3
Training loss: 3.9243576526641846
Validation loss: 2.642056767658521

Epoch: 6| Step: 4
Training loss: 3.0209622383117676
Validation loss: 2.6461076095540035

Epoch: 6| Step: 5
Training loss: 3.322993278503418
Validation loss: 2.6517351878586637

Epoch: 6| Step: 6
Training loss: 2.9876766204833984
Validation loss: 2.668410942118655

Epoch: 6| Step: 7
Training loss: 3.0473883152008057
Validation loss: 2.6763417079884517

Epoch: 6| Step: 8
Training loss: 2.632951498031616
Validation loss: 2.7355144587896203

Epoch: 6| Step: 9
Training loss: 3.157554864883423
Validation loss: 2.777470706611551

Epoch: 6| Step: 10
Training loss: 2.217866897583008
Validation loss: 2.7453924455950336

Epoch: 6| Step: 11
Training loss: 2.206835985183716
Validation loss: 2.7064910678453344

Epoch: 6| Step: 12
Training loss: 2.650129556655884
Validation loss: 2.648429896241875

Epoch: 6| Step: 13
Training loss: 1.692746639251709
Validation loss: 2.638701764486169

Epoch: 45| Step: 0
Training loss: 3.4295308589935303
Validation loss: 2.6409379025941253

Epoch: 6| Step: 1
Training loss: 2.753777503967285
Validation loss: 2.6529590750253327

Epoch: 6| Step: 2
Training loss: 2.9831337928771973
Validation loss: 2.669321693399901

Epoch: 6| Step: 3
Training loss: 2.5002598762512207
Validation loss: 2.684410213142313

Epoch: 6| Step: 4
Training loss: 1.7825634479522705
Validation loss: 2.7206593226361018

Epoch: 6| Step: 5
Training loss: 2.8553237915039062
Validation loss: 2.768522472791774

Epoch: 6| Step: 6
Training loss: 2.8138601779937744
Validation loss: 2.767102341498098

Epoch: 6| Step: 7
Training loss: 3.2483110427856445
Validation loss: 2.7322465219805316

Epoch: 6| Step: 8
Training loss: 2.7230374813079834
Validation loss: 2.656654022073233

Epoch: 6| Step: 9
Training loss: 3.465449810028076
Validation loss: 2.6344872418270318

Epoch: 6| Step: 10
Training loss: 2.1197705268859863
Validation loss: 2.6327058986950944

Epoch: 6| Step: 11
Training loss: 3.581754684448242
Validation loss: 2.641603413448539

Epoch: 6| Step: 12
Training loss: 2.9117064476013184
Validation loss: 2.659003068042058

Epoch: 6| Step: 13
Training loss: 2.0010056495666504
Validation loss: 2.6694511546883533

Epoch: 46| Step: 0
Training loss: 3.3615314960479736
Validation loss: 2.662801460553241

Epoch: 6| Step: 1
Training loss: 3.0524446964263916
Validation loss: 2.6573372220480316

Epoch: 6| Step: 2
Training loss: 1.8146069049835205
Validation loss: 2.650292545236567

Epoch: 6| Step: 3
Training loss: 2.749584197998047
Validation loss: 2.6474571638209845

Epoch: 6| Step: 4
Training loss: 3.1418447494506836
Validation loss: 2.644207795461019

Epoch: 6| Step: 5
Training loss: 3.2258682250976562
Validation loss: 2.636134050225699

Epoch: 6| Step: 6
Training loss: 2.4042813777923584
Validation loss: 2.627953601139848

Epoch: 6| Step: 7
Training loss: 2.822476863861084
Validation loss: 2.6304545787072953

Epoch: 6| Step: 8
Training loss: 4.035470962524414
Validation loss: 2.629503555195306

Epoch: 6| Step: 9
Training loss: 1.4720239639282227
Validation loss: 2.629043181737264

Epoch: 6| Step: 10
Training loss: 2.3226771354675293
Validation loss: 2.6306890236434115

Epoch: 6| Step: 11
Training loss: 3.3876547813415527
Validation loss: 2.6302138682334655

Epoch: 6| Step: 12
Training loss: 3.0919041633605957
Validation loss: 2.6398831439274613

Epoch: 6| Step: 13
Training loss: 1.8509243726730347
Validation loss: 2.6480277558808685

Epoch: 47| Step: 0
Training loss: 3.9186666011810303
Validation loss: 2.6529594364986626

Epoch: 6| Step: 1
Training loss: 2.8347768783569336
Validation loss: 2.65445714868525

Epoch: 6| Step: 2
Training loss: 2.8672714233398438
Validation loss: 2.644274780827184

Epoch: 6| Step: 3
Training loss: 2.069760799407959
Validation loss: 2.6304582126678957

Epoch: 6| Step: 4
Training loss: 2.1191039085388184
Validation loss: 2.624195352677376

Epoch: 6| Step: 5
Training loss: 2.1274356842041016
Validation loss: 2.6197251940286286

Epoch: 6| Step: 6
Training loss: 2.8079674243927
Validation loss: 2.617732583835561

Epoch: 6| Step: 7
Training loss: 2.3296852111816406
Validation loss: 2.6187363055444535

Epoch: 6| Step: 8
Training loss: 3.3450422286987305
Validation loss: 2.616434253672118

Epoch: 6| Step: 9
Training loss: 3.5879616737365723
Validation loss: 2.6160765258214806

Epoch: 6| Step: 10
Training loss: 3.2271156311035156
Validation loss: 2.6183941902652865

Epoch: 6| Step: 11
Training loss: 3.016793727874756
Validation loss: 2.6378681172606764

Epoch: 6| Step: 12
Training loss: 2.093111991882324
Validation loss: 2.6161000241515455

Epoch: 6| Step: 13
Training loss: 2.2595033645629883
Validation loss: 2.6123988166932137

Epoch: 48| Step: 0
Training loss: 3.2898685932159424
Validation loss: 2.6138301690419516

Epoch: 6| Step: 1
Training loss: 2.3738245964050293
Validation loss: 2.615039092238231

Epoch: 6| Step: 2
Training loss: 2.6473870277404785
Validation loss: 2.6144498266199583

Epoch: 6| Step: 3
Training loss: 2.3903656005859375
Validation loss: 2.614275896421043

Epoch: 6| Step: 4
Training loss: 3.020308494567871
Validation loss: 2.6113160169252785

Epoch: 6| Step: 5
Training loss: 2.3611180782318115
Validation loss: 2.6146035860943537

Epoch: 6| Step: 6
Training loss: 2.2033214569091797
Validation loss: 2.6111268612646286

Epoch: 6| Step: 7
Training loss: 2.742882251739502
Validation loss: 2.608768614389563

Epoch: 6| Step: 8
Training loss: 2.5816988945007324
Validation loss: 2.6071854176059848

Epoch: 6| Step: 9
Training loss: 2.457697629928589
Validation loss: 2.6084789588887203

Epoch: 6| Step: 10
Training loss: 3.2787389755249023
Validation loss: 2.609305912448514

Epoch: 6| Step: 11
Training loss: 2.9938101768493652
Validation loss: 2.6080654615996988

Epoch: 6| Step: 12
Training loss: 3.3359951972961426
Validation loss: 2.605798277803647

Epoch: 6| Step: 13
Training loss: 3.3476145267486572
Validation loss: 2.6021843853817193

Epoch: 49| Step: 0
Training loss: 2.8985788822174072
Validation loss: 2.6021804271205777

Epoch: 6| Step: 1
Training loss: 2.906543493270874
Validation loss: 2.599249775691699

Epoch: 6| Step: 2
Training loss: 2.1351864337921143
Validation loss: 2.6039899702995055

Epoch: 6| Step: 3
Training loss: 3.3158349990844727
Validation loss: 2.6018073328079714

Epoch: 6| Step: 4
Training loss: 2.5385804176330566
Validation loss: 2.5985734565283662

Epoch: 6| Step: 5
Training loss: 3.1633834838867188
Validation loss: 2.6015338820795857

Epoch: 6| Step: 6
Training loss: 3.076582908630371
Validation loss: 2.5961052294700377

Epoch: 6| Step: 7
Training loss: 3.1793198585510254
Validation loss: 2.5980865186260593

Epoch: 6| Step: 8
Training loss: 3.451676845550537
Validation loss: 2.5952198146491923

Epoch: 6| Step: 9
Training loss: 2.171267032623291
Validation loss: 2.5947086298337547

Epoch: 6| Step: 10
Training loss: 2.2850403785705566
Validation loss: 2.5935769568207445

Epoch: 6| Step: 11
Training loss: 3.16896390914917
Validation loss: 2.5948901535362325

Epoch: 6| Step: 12
Training loss: 2.3983869552612305
Validation loss: 2.596968020162275

Epoch: 6| Step: 13
Training loss: 1.3129377365112305
Validation loss: 2.5963755653750513

Epoch: 50| Step: 0
Training loss: 2.7773423194885254
Validation loss: 2.595506824472899

Epoch: 6| Step: 1
Training loss: 2.8168139457702637
Validation loss: 2.591415156600296

Epoch: 6| Step: 2
Training loss: 2.3025901317596436
Validation loss: 2.589356573679114

Epoch: 6| Step: 3
Training loss: 2.8006365299224854
Validation loss: 2.588405675785516

Epoch: 6| Step: 4
Training loss: 2.5300064086914062
Validation loss: 2.5866905796912407

Epoch: 6| Step: 5
Training loss: 2.633519172668457
Validation loss: 2.587218648643904

Epoch: 6| Step: 6
Training loss: 4.099427223205566
Validation loss: 2.5860264814028175

Epoch: 6| Step: 7
Training loss: 2.9486327171325684
Validation loss: 2.5861973326693297

Epoch: 6| Step: 8
Training loss: 2.364485263824463
Validation loss: 2.5841765429383967

Epoch: 6| Step: 9
Training loss: 2.0321507453918457
Validation loss: 2.582166284643194

Epoch: 6| Step: 10
Training loss: 2.491598129272461
Validation loss: 2.5830438829237417

Epoch: 6| Step: 11
Training loss: 2.443387508392334
Validation loss: 2.580518094442224

Epoch: 6| Step: 12
Training loss: 3.3040924072265625
Validation loss: 2.5800705827692503

Epoch: 6| Step: 13
Training loss: 3.100094795227051
Validation loss: 2.580129159394131

Epoch: 51| Step: 0
Training loss: 3.2515475749969482
Validation loss: 2.581390001440561

Epoch: 6| Step: 1
Training loss: 1.6442816257476807
Validation loss: 2.580495644641179

Epoch: 6| Step: 2
Training loss: 2.8676064014434814
Validation loss: 2.5811283203863327

Epoch: 6| Step: 3
Training loss: 2.527114152908325
Validation loss: 2.5883068038571264

Epoch: 6| Step: 4
Training loss: 1.9232996702194214
Validation loss: 2.585950937322391

Epoch: 6| Step: 5
Training loss: 3.735219955444336
Validation loss: 2.582822112626927

Epoch: 6| Step: 6
Training loss: 3.174002170562744
Validation loss: 2.57834457325679

Epoch: 6| Step: 7
Training loss: 2.8211913108825684
Validation loss: 2.5783128558948474

Epoch: 6| Step: 8
Training loss: 2.8262059688568115
Validation loss: 2.5746443912547123

Epoch: 6| Step: 9
Training loss: 2.8695006370544434
Validation loss: 2.5769261339659333

Epoch: 6| Step: 10
Training loss: 3.7890801429748535
Validation loss: 2.5765683368969987

Epoch: 6| Step: 11
Training loss: 2.2362313270568848
Validation loss: 2.5747821843752297

Epoch: 6| Step: 12
Training loss: 2.5101475715637207
Validation loss: 2.5817194728441137

Epoch: 6| Step: 13
Training loss: 1.779976487159729
Validation loss: 2.5863369331564954

Epoch: 52| Step: 0
Training loss: 2.793980836868286
Validation loss: 2.5877357887965378

Epoch: 6| Step: 1
Training loss: 1.7907392978668213
Validation loss: 2.585754430422219

Epoch: 6| Step: 2
Training loss: 1.8336647748947144
Validation loss: 2.5869426009475545

Epoch: 6| Step: 3
Training loss: 2.586411952972412
Validation loss: 2.5792036210336993

Epoch: 6| Step: 4
Training loss: 3.128159523010254
Validation loss: 2.576810767573695

Epoch: 6| Step: 5
Training loss: 2.6946988105773926
Validation loss: 2.573486643452798

Epoch: 6| Step: 6
Training loss: 3.6438426971435547
Validation loss: 2.574786893783077

Epoch: 6| Step: 7
Training loss: 2.881314754486084
Validation loss: 2.57200188021506

Epoch: 6| Step: 8
Training loss: 2.505337715148926
Validation loss: 2.576588338421237

Epoch: 6| Step: 9
Training loss: 2.69240403175354
Validation loss: 2.5770345990375807

Epoch: 6| Step: 10
Training loss: 3.1604881286621094
Validation loss: 2.574692754335301

Epoch: 6| Step: 11
Training loss: 2.270413398742676
Validation loss: 2.574441361170943

Epoch: 6| Step: 12
Training loss: 3.682518482208252
Validation loss: 2.5699744814185688

Epoch: 6| Step: 13
Training loss: 2.661511182785034
Validation loss: 2.5674683842607724

Epoch: 53| Step: 0
Training loss: 1.897905945777893
Validation loss: 2.5664677748116116

Epoch: 6| Step: 1
Training loss: 3.1952638626098633
Validation loss: 2.5632900499528453

Epoch: 6| Step: 2
Training loss: 2.5539913177490234
Validation loss: 2.5653004774483303

Epoch: 6| Step: 3
Training loss: 3.2863693237304688
Validation loss: 2.565022219893753

Epoch: 6| Step: 4
Training loss: 2.7461018562316895
Validation loss: 2.5636117689071165

Epoch: 6| Step: 5
Training loss: 2.8551459312438965
Validation loss: 2.5613946376308316

Epoch: 6| Step: 6
Training loss: 2.4062957763671875
Validation loss: 2.5609054078337965

Epoch: 6| Step: 7
Training loss: 2.2337260246276855
Validation loss: 2.559786378696401

Epoch: 6| Step: 8
Training loss: 3.2440388202667236
Validation loss: 2.55971912799343

Epoch: 6| Step: 9
Training loss: 2.7005696296691895
Validation loss: 2.5609178286726757

Epoch: 6| Step: 10
Training loss: 3.690988063812256
Validation loss: 2.5569348335266113

Epoch: 6| Step: 11
Training loss: 2.815026044845581
Validation loss: 2.5559406203608357

Epoch: 6| Step: 12
Training loss: 2.098778486251831
Validation loss: 2.5544797758902273

Epoch: 6| Step: 13
Training loss: 2.354060411453247
Validation loss: 2.5543747050787813

Epoch: 54| Step: 0
Training loss: 3.294034957885742
Validation loss: 2.5562715709850354

Epoch: 6| Step: 1
Training loss: 1.967392921447754
Validation loss: 2.5564667922194286

Epoch: 6| Step: 2
Training loss: 2.1426784992218018
Validation loss: 2.5593418382829234

Epoch: 6| Step: 3
Training loss: 2.843858480453491
Validation loss: 2.5667804107871106

Epoch: 6| Step: 4
Training loss: 2.9584860801696777
Validation loss: 2.5706060278800225

Epoch: 6| Step: 5
Training loss: 3.1658835411071777
Validation loss: 2.5811055116755988

Epoch: 6| Step: 6
Training loss: 2.963261127471924
Validation loss: 2.5878067298602034

Epoch: 6| Step: 7
Training loss: 2.5376317501068115
Validation loss: 2.5991774118074806

Epoch: 6| Step: 8
Training loss: 2.590672731399536
Validation loss: 2.581544973516977

Epoch: 6| Step: 9
Training loss: 3.4636073112487793
Validation loss: 2.5766555724605436

Epoch: 6| Step: 10
Training loss: 2.7563841342926025
Validation loss: 2.5621178611632316

Epoch: 6| Step: 11
Training loss: 2.341400623321533
Validation loss: 2.5542865542955298

Epoch: 6| Step: 12
Training loss: 2.3729705810546875
Validation loss: 2.5480145767170894

Epoch: 6| Step: 13
Training loss: 2.9905996322631836
Validation loss: 2.5476860564242125

Epoch: 55| Step: 0
Training loss: 2.792335033416748
Validation loss: 2.5464753643158944

Epoch: 6| Step: 1
Training loss: 2.9655723571777344
Validation loss: 2.5667442737087125

Epoch: 6| Step: 2
Training loss: 2.4200053215026855
Validation loss: 2.603002912254744

Epoch: 6| Step: 3
Training loss: 3.3183321952819824
Validation loss: 2.554668803368845

Epoch: 6| Step: 4
Training loss: 2.550999402999878
Validation loss: 2.5425481924446682

Epoch: 6| Step: 5
Training loss: 2.502072334289551
Validation loss: 2.541020477971723

Epoch: 6| Step: 6
Training loss: 3.5450925827026367
Validation loss: 2.5460582728027017

Epoch: 6| Step: 7
Training loss: 2.7155232429504395
Validation loss: 2.552789044636552

Epoch: 6| Step: 8
Training loss: 2.6754727363586426
Validation loss: 2.571386191152757

Epoch: 6| Step: 9
Training loss: 2.133329391479492
Validation loss: 2.592626189672819

Epoch: 6| Step: 10
Training loss: 2.715880870819092
Validation loss: 2.596341074153941

Epoch: 6| Step: 11
Training loss: 1.808497428894043
Validation loss: 2.58151053613232

Epoch: 6| Step: 12
Training loss: 3.631383180618286
Validation loss: 2.563820041635985

Epoch: 6| Step: 13
Training loss: 2.398049831390381
Validation loss: 2.546201362404772

Epoch: 56| Step: 0
Training loss: 2.736523151397705
Validation loss: 2.539119687131656

Epoch: 6| Step: 1
Training loss: 3.9420218467712402
Validation loss: 2.5361525371510494

Epoch: 6| Step: 2
Training loss: 2.7723793983459473
Validation loss: 2.5364254520785425

Epoch: 6| Step: 3
Training loss: 2.864962100982666
Validation loss: 2.5355505199842554

Epoch: 6| Step: 4
Training loss: 2.4294919967651367
Validation loss: 2.5443011176201606

Epoch: 6| Step: 5
Training loss: 3.6733767986297607
Validation loss: 2.5433445233170704

Epoch: 6| Step: 6
Training loss: 2.1840615272521973
Validation loss: 2.544582912998815

Epoch: 6| Step: 7
Training loss: 2.405643939971924
Validation loss: 2.544650198310934

Epoch: 6| Step: 8
Training loss: 2.6502935886383057
Validation loss: 2.549690915692237

Epoch: 6| Step: 9
Training loss: 2.1660385131835938
Validation loss: 2.5518212626057286

Epoch: 6| Step: 10
Training loss: 3.0337319374084473
Validation loss: 2.550890753346105

Epoch: 6| Step: 11
Training loss: 2.749147415161133
Validation loss: 2.5471939297132593

Epoch: 6| Step: 12
Training loss: 2.17600154876709
Validation loss: 2.5416397202399468

Epoch: 6| Step: 13
Training loss: 2.254950523376465
Validation loss: 2.5354613924539215

Epoch: 57| Step: 0
Training loss: 2.2307446002960205
Validation loss: 2.528464736477021

Epoch: 6| Step: 1
Training loss: 2.228466033935547
Validation loss: 2.5256738406355663

Epoch: 6| Step: 2
Training loss: 2.651477813720703
Validation loss: 2.5249404881590154

Epoch: 6| Step: 3
Training loss: 2.7036373615264893
Validation loss: 2.5277229611591627

Epoch: 6| Step: 4
Training loss: 2.8293650150299072
Validation loss: 2.529040677573091

Epoch: 6| Step: 5
Training loss: 2.312906503677368
Validation loss: 2.5313545811560845

Epoch: 6| Step: 6
Training loss: 3.560431718826294
Validation loss: 2.537318665494201

Epoch: 6| Step: 7
Training loss: 3.098327398300171
Validation loss: 2.537867925500357

Epoch: 6| Step: 8
Training loss: 2.2542319297790527
Validation loss: 2.534820765577337

Epoch: 6| Step: 9
Training loss: 3.3447165489196777
Validation loss: 2.5283977652108796

Epoch: 6| Step: 10
Training loss: 2.530038356781006
Validation loss: 2.522126461869927

Epoch: 6| Step: 11
Training loss: 2.9503753185272217
Validation loss: 2.52159942606444

Epoch: 6| Step: 12
Training loss: 2.9560821056365967
Validation loss: 2.5190431276957193

Epoch: 6| Step: 13
Training loss: 2.097743272781372
Validation loss: 2.5221393159640733

Epoch: 58| Step: 0
Training loss: 3.177675247192383
Validation loss: 2.5198619083691667

Epoch: 6| Step: 1
Training loss: 2.4856009483337402
Validation loss: 2.5212373759156916

Epoch: 6| Step: 2
Training loss: 2.3376030921936035
Validation loss: 2.5224816183890066

Epoch: 6| Step: 3
Training loss: 3.048006296157837
Validation loss: 2.5239030955940165

Epoch: 6| Step: 4
Training loss: 2.8215999603271484
Validation loss: 2.5278650560686664

Epoch: 6| Step: 5
Training loss: 2.163503646850586
Validation loss: 2.526910376805131

Epoch: 6| Step: 6
Training loss: 1.6807429790496826
Validation loss: 2.5235456189801617

Epoch: 6| Step: 7
Training loss: 3.001824378967285
Validation loss: 2.523882101940852

Epoch: 6| Step: 8
Training loss: 2.685189723968506
Validation loss: 2.525884202731553

Epoch: 6| Step: 9
Training loss: 3.073180913925171
Validation loss: 2.5230452758009716

Epoch: 6| Step: 10
Training loss: 3.0388450622558594
Validation loss: 2.5218633349223802

Epoch: 6| Step: 11
Training loss: 2.846283435821533
Validation loss: 2.518502973741101

Epoch: 6| Step: 12
Training loss: 2.6674742698669434
Validation loss: 2.520339322346513

Epoch: 6| Step: 13
Training loss: 3.0165343284606934
Validation loss: 2.5169436495791198

Epoch: 59| Step: 0
Training loss: 2.9844019412994385
Validation loss: 2.5154231466272825

Epoch: 6| Step: 1
Training loss: 3.0859580039978027
Validation loss: 2.5190022504457863

Epoch: 6| Step: 2
Training loss: 2.1056947708129883
Validation loss: 2.519241230462187

Epoch: 6| Step: 3
Training loss: 2.4909472465515137
Validation loss: 2.519340579227735

Epoch: 6| Step: 4
Training loss: 2.1204257011413574
Validation loss: 2.5225767730384745

Epoch: 6| Step: 5
Training loss: 2.67216157913208
Validation loss: 2.525112610991283

Epoch: 6| Step: 6
Training loss: 2.8807437419891357
Validation loss: 2.5261159045721895

Epoch: 6| Step: 7
Training loss: 2.0100526809692383
Validation loss: 2.529930991511191

Epoch: 6| Step: 8
Training loss: 2.6060585975646973
Validation loss: 2.5292505500137166

Epoch: 6| Step: 9
Training loss: 2.530552387237549
Validation loss: 2.534044176019648

Epoch: 6| Step: 10
Training loss: 3.314584732055664
Validation loss: 2.527247569894278

Epoch: 6| Step: 11
Training loss: 3.2105822563171387
Validation loss: 2.5308695557296916

Epoch: 6| Step: 12
Training loss: 2.504542589187622
Validation loss: 2.5338064111689085

Epoch: 6| Step: 13
Training loss: 3.840200662612915
Validation loss: 2.52762350984799

Epoch: 60| Step: 0
Training loss: 3.1917505264282227
Validation loss: 2.519630503910844

Epoch: 6| Step: 1
Training loss: 3.2352476119995117
Validation loss: 2.51064787116102

Epoch: 6| Step: 2
Training loss: 2.395496368408203
Validation loss: 2.510196675536453

Epoch: 6| Step: 3
Training loss: 2.5337488651275635
Validation loss: 2.5026401832539547

Epoch: 6| Step: 4
Training loss: 2.2752623558044434
Validation loss: 2.5045655106985443

Epoch: 6| Step: 5
Training loss: 2.808967113494873
Validation loss: 2.505351745954124

Epoch: 6| Step: 6
Training loss: 2.1180834770202637
Validation loss: 2.5046958923339844

Epoch: 6| Step: 7
Training loss: 2.552955389022827
Validation loss: 2.5061230428757204

Epoch: 6| Step: 8
Training loss: 2.957709550857544
Validation loss: 2.5041428894125004

Epoch: 6| Step: 9
Training loss: 2.7285118103027344
Validation loss: 2.504762468799468

Epoch: 6| Step: 10
Training loss: 3.124049663543701
Validation loss: 2.505661900325488

Epoch: 6| Step: 11
Training loss: 2.5708158016204834
Validation loss: 2.512153366560577

Epoch: 6| Step: 12
Training loss: 2.8137402534484863
Validation loss: 2.512318939291021

Epoch: 6| Step: 13
Training loss: 2.3961613178253174
Validation loss: 2.5183444279496388

Epoch: 61| Step: 0
Training loss: 3.01359224319458
Validation loss: 2.519189009102442

Epoch: 6| Step: 1
Training loss: 3.4217491149902344
Validation loss: 2.5200630182861

Epoch: 6| Step: 2
Training loss: 2.0208451747894287
Validation loss: 2.5159985480769986

Epoch: 6| Step: 3
Training loss: 3.2164969444274902
Validation loss: 2.5152918574630574

Epoch: 6| Step: 4
Training loss: 2.6733243465423584
Validation loss: 2.5149874174466698

Epoch: 6| Step: 5
Training loss: 1.8509271144866943
Validation loss: 2.5154532360774216

Epoch: 6| Step: 6
Training loss: 3.052109956741333
Validation loss: 2.503000032517218

Epoch: 6| Step: 7
Training loss: 2.7039332389831543
Validation loss: 2.500096318542316

Epoch: 6| Step: 8
Training loss: 2.9130773544311523
Validation loss: 2.497457229962913

Epoch: 6| Step: 9
Training loss: 2.606069564819336
Validation loss: 2.4981616491912515

Epoch: 6| Step: 10
Training loss: 1.99468195438385
Validation loss: 2.5034869563195015

Epoch: 6| Step: 11
Training loss: 2.453796625137329
Validation loss: 2.5098188718159995

Epoch: 6| Step: 12
Training loss: 3.1288795471191406
Validation loss: 2.5241412014089604

Epoch: 6| Step: 13
Training loss: 2.9624478816986084
Validation loss: 2.526273917126399

Epoch: 62| Step: 0
Training loss: 3.0862088203430176
Validation loss: 2.510802281800137

Epoch: 6| Step: 1
Training loss: 2.1252434253692627
Validation loss: 2.5002818799787954

Epoch: 6| Step: 2
Training loss: 2.42798113822937
Validation loss: 2.4953042358480473

Epoch: 6| Step: 3
Training loss: 2.097322940826416
Validation loss: 2.495504517709055

Epoch: 6| Step: 4
Training loss: 3.11160945892334
Validation loss: 2.492817355740455

Epoch: 6| Step: 5
Training loss: 2.788088321685791
Validation loss: 2.5029462101638957

Epoch: 6| Step: 6
Training loss: 2.3499257564544678
Validation loss: 2.516261064878074

Epoch: 6| Step: 7
Training loss: 2.9014689922332764
Validation loss: 2.5337214572455293

Epoch: 6| Step: 8
Training loss: 2.997556447982788
Validation loss: 2.555142915377053

Epoch: 6| Step: 9
Training loss: 2.710627555847168
Validation loss: 2.546829646633517

Epoch: 6| Step: 10
Training loss: 2.873647689819336
Validation loss: 2.527686167788762

Epoch: 6| Step: 11
Training loss: 2.701188564300537
Validation loss: 2.5169629871204333

Epoch: 6| Step: 12
Training loss: 3.1799814701080322
Validation loss: 2.506500454359157

Epoch: 6| Step: 13
Training loss: 2.381122589111328
Validation loss: 2.4968606220778597

Epoch: 63| Step: 0
Training loss: 2.8531148433685303
Validation loss: 2.496487327801284

Epoch: 6| Step: 1
Training loss: 2.659724235534668
Validation loss: 2.4935900113915883

Epoch: 6| Step: 2
Training loss: 2.090601921081543
Validation loss: 2.488505167345847

Epoch: 6| Step: 3
Training loss: 2.5803332328796387
Validation loss: 2.4884061454444804

Epoch: 6| Step: 4
Training loss: 2.5382752418518066
Validation loss: 2.489458273815852

Epoch: 6| Step: 5
Training loss: 2.8213162422180176
Validation loss: 2.4882427389903734

Epoch: 6| Step: 6
Training loss: 3.065688371658325
Validation loss: 2.4872860805962675

Epoch: 6| Step: 7
Training loss: 2.950444221496582
Validation loss: 2.4860180731742614

Epoch: 6| Step: 8
Training loss: 2.799941062927246
Validation loss: 2.485340513208861

Epoch: 6| Step: 9
Training loss: 3.1336395740509033
Validation loss: 2.4894177695756317

Epoch: 6| Step: 10
Training loss: 3.069390058517456
Validation loss: 2.502717548801053

Epoch: 6| Step: 11
Training loss: 2.013826370239258
Validation loss: 2.5134978320008967

Epoch: 6| Step: 12
Training loss: 2.836545705795288
Validation loss: 2.506241411291143

Epoch: 6| Step: 13
Training loss: 2.02730393409729
Validation loss: 2.494824263357347

Epoch: 64| Step: 0
Training loss: 3.101484775543213
Validation loss: 2.487181196930588

Epoch: 6| Step: 1
Training loss: 2.0891764163970947
Validation loss: 2.481267656049421

Epoch: 6| Step: 2
Training loss: 2.0036072731018066
Validation loss: 2.4807037384279313

Epoch: 6| Step: 3
Training loss: 2.4864273071289062
Validation loss: 2.4800710037190425

Epoch: 6| Step: 4
Training loss: 2.4646849632263184
Validation loss: 2.479530139635968

Epoch: 6| Step: 5
Training loss: 2.4225785732269287
Validation loss: 2.4807324460757676

Epoch: 6| Step: 6
Training loss: 2.5765557289123535
Validation loss: 2.4790224529081777

Epoch: 6| Step: 7
Training loss: 3.1620736122131348
Validation loss: 2.4778512242019817

Epoch: 6| Step: 8
Training loss: 3.2061569690704346
Validation loss: 2.4731105989025486

Epoch: 6| Step: 9
Training loss: 2.5272879600524902
Validation loss: 2.4749520696619505

Epoch: 6| Step: 10
Training loss: 3.3480191230773926
Validation loss: 2.4732359327295774

Epoch: 6| Step: 11
Training loss: 2.968982219696045
Validation loss: 2.4697466511880197

Epoch: 6| Step: 12
Training loss: 2.6557705402374268
Validation loss: 2.473161828133368

Epoch: 6| Step: 13
Training loss: 2.4841771125793457
Validation loss: 2.4729518403289137

Epoch: 65| Step: 0
Training loss: 2.3929009437561035
Validation loss: 2.4714879835805585

Epoch: 6| Step: 1
Training loss: 2.468688488006592
Validation loss: 2.4961475787624234

Epoch: 6| Step: 2
Training loss: 2.3427557945251465
Validation loss: 2.5298827873763217

Epoch: 6| Step: 3
Training loss: 2.9489665031433105
Validation loss: 2.5554409744918987

Epoch: 6| Step: 4
Training loss: 2.4598515033721924
Validation loss: 2.555855586964597

Epoch: 6| Step: 5
Training loss: 2.0750813484191895
Validation loss: 2.5507133955596597

Epoch: 6| Step: 6
Training loss: 3.443326473236084
Validation loss: 2.550742974845312

Epoch: 6| Step: 7
Training loss: 3.0988144874572754
Validation loss: 2.548937115617978

Epoch: 6| Step: 8
Training loss: 1.6712170839309692
Validation loss: 2.5402156178669264

Epoch: 6| Step: 9
Training loss: 2.9529566764831543
Validation loss: 2.5346277990648822

Epoch: 6| Step: 10
Training loss: 2.9521636962890625
Validation loss: 2.5305710146504063

Epoch: 6| Step: 11
Training loss: 3.5592846870422363
Validation loss: 2.5337064522568897

Epoch: 6| Step: 12
Training loss: 2.805474042892456
Validation loss: 2.5318269473250195

Epoch: 6| Step: 13
Training loss: 2.650517463684082
Validation loss: 2.5333121515089467

Epoch: 66| Step: 0
Training loss: 2.494563102722168
Validation loss: 2.536596741727603

Epoch: 6| Step: 1
Training loss: 1.999342441558838
Validation loss: 2.5312591111788185

Epoch: 6| Step: 2
Training loss: 3.517749786376953
Validation loss: 2.529849530548178

Epoch: 6| Step: 3
Training loss: 2.8556926250457764
Validation loss: 2.5276702116894465

Epoch: 6| Step: 4
Training loss: 3.789719581604004
Validation loss: 2.527888833835561

Epoch: 6| Step: 5
Training loss: 2.1809401512145996
Validation loss: 2.526587652903731

Epoch: 6| Step: 6
Training loss: 2.519739866256714
Validation loss: 2.527616931546119

Epoch: 6| Step: 7
Training loss: 3.2886602878570557
Validation loss: 2.526427702237201

Epoch: 6| Step: 8
Training loss: 2.1491339206695557
Validation loss: 2.5281058844699653

Epoch: 6| Step: 9
Training loss: 3.373626232147217
Validation loss: 2.530735223524032

Epoch: 6| Step: 10
Training loss: 2.7336678504943848
Validation loss: 2.531736837920322

Epoch: 6| Step: 11
Training loss: 2.5319314002990723
Validation loss: 2.539967331835019

Epoch: 6| Step: 12
Training loss: 1.7959935665130615
Validation loss: 2.5461242980854486

Epoch: 6| Step: 13
Training loss: 2.8631670475006104
Validation loss: 2.546242675473613

Epoch: 67| Step: 0
Training loss: 2.5272371768951416
Validation loss: 2.544224282746674

Epoch: 6| Step: 1
Training loss: 2.1190266609191895
Validation loss: 2.5396820960506314

Epoch: 6| Step: 2
Training loss: 2.436969518661499
Validation loss: 2.531758600665677

Epoch: 6| Step: 3
Training loss: 2.918508768081665
Validation loss: 2.5317238710259877

Epoch: 6| Step: 4
Training loss: 1.7364656925201416
Validation loss: 2.5305770943241734

Epoch: 6| Step: 5
Training loss: 3.8554251194000244
Validation loss: 2.524141978192073

Epoch: 6| Step: 6
Training loss: 3.2362091541290283
Validation loss: 2.5266130726824523

Epoch: 6| Step: 7
Training loss: 2.8952574729919434
Validation loss: 2.5224595428794943

Epoch: 6| Step: 8
Training loss: 2.896557331085205
Validation loss: 2.520162154269475

Epoch: 6| Step: 9
Training loss: 2.6280202865600586
Validation loss: 2.51867917788926

Epoch: 6| Step: 10
Training loss: 2.5271053314208984
Validation loss: 2.5164123350574124

Epoch: 6| Step: 11
Training loss: 2.657503604888916
Validation loss: 2.516453778871926

Epoch: 6| Step: 12
Training loss: 2.992072820663452
Validation loss: 2.516680561086183

Epoch: 6| Step: 13
Training loss: 2.162215232849121
Validation loss: 2.5137451002674718

Epoch: 68| Step: 0
Training loss: 2.295637369155884
Validation loss: 2.5143787758324736

Epoch: 6| Step: 1
Training loss: 2.3013968467712402
Validation loss: 2.517713797989712

Epoch: 6| Step: 2
Training loss: 3.057403326034546
Validation loss: 2.5200751007244153

Epoch: 6| Step: 3
Training loss: 1.967254638671875
Validation loss: 2.5166228971173688

Epoch: 6| Step: 4
Training loss: 3.159008502960205
Validation loss: 2.5192050344200543

Epoch: 6| Step: 5
Training loss: 1.6663857698440552
Validation loss: 2.5216719847853466

Epoch: 6| Step: 6
Training loss: 2.750577449798584
Validation loss: 2.513060123689713

Epoch: 6| Step: 7
Training loss: 3.617159366607666
Validation loss: 2.5122114714755805

Epoch: 6| Step: 8
Training loss: 2.9785804748535156
Validation loss: 2.505776115643081

Epoch: 6| Step: 9
Training loss: 2.241164207458496
Validation loss: 2.484029572497132

Epoch: 6| Step: 10
Training loss: 2.9344642162323
Validation loss: 2.4433513302956857

Epoch: 6| Step: 11
Training loss: 2.9384586811065674
Validation loss: 2.44104496125252

Epoch: 6| Step: 12
Training loss: 3.314742088317871
Validation loss: 2.442917787900535

Epoch: 6| Step: 13
Training loss: 2.193403720855713
Validation loss: 2.4395966786210255

Epoch: 69| Step: 0
Training loss: 2.583047866821289
Validation loss: 2.4389458215364845

Epoch: 6| Step: 1
Training loss: 2.853698253631592
Validation loss: 2.4383571122282293

Epoch: 6| Step: 2
Training loss: 2.796109199523926
Validation loss: 2.438667466563563

Epoch: 6| Step: 3
Training loss: 2.4473724365234375
Validation loss: 2.436843228596513

Epoch: 6| Step: 4
Training loss: 2.4898531436920166
Validation loss: 2.4428193620456162

Epoch: 6| Step: 5
Training loss: 2.7397236824035645
Validation loss: 2.446939545293008

Epoch: 6| Step: 6
Training loss: 3.2838218212127686
Validation loss: 2.457307400241975

Epoch: 6| Step: 7
Training loss: 1.8284919261932373
Validation loss: 2.471090908973448

Epoch: 6| Step: 8
Training loss: 2.8664608001708984
Validation loss: 2.4925985746486212

Epoch: 6| Step: 9
Training loss: 2.265981912612915
Validation loss: 2.4891479758806128

Epoch: 6| Step: 10
Training loss: 3.384565591812134
Validation loss: 2.5074118644960466

Epoch: 6| Step: 11
Training loss: 2.366877555847168
Validation loss: 2.494043691183931

Epoch: 6| Step: 12
Training loss: 2.4526443481445312
Validation loss: 2.496954607707198

Epoch: 6| Step: 13
Training loss: 3.3313798904418945
Validation loss: 2.4893730225101596

Epoch: 70| Step: 0
Training loss: 2.805548667907715
Validation loss: 2.4733204739068144

Epoch: 6| Step: 1
Training loss: 2.699368953704834
Validation loss: 2.4587725208651636

Epoch: 6| Step: 2
Training loss: 2.410590171813965
Validation loss: 2.4559422154580393

Epoch: 6| Step: 3
Training loss: 3.1125099658966064
Validation loss: 2.449091467806088

Epoch: 6| Step: 4
Training loss: 2.303042411804199
Validation loss: 2.4372424643526793

Epoch: 6| Step: 5
Training loss: 2.5419788360595703
Validation loss: 2.4363084275235414

Epoch: 6| Step: 6
Training loss: 2.7234549522399902
Validation loss: 2.4378491037635395

Epoch: 6| Step: 7
Training loss: 2.6914749145507812
Validation loss: 2.438346057809809

Epoch: 6| Step: 8
Training loss: 3.2046992778778076
Validation loss: 2.4380503059715353

Epoch: 6| Step: 9
Training loss: 2.546156406402588
Validation loss: 2.4393821121543966

Epoch: 6| Step: 10
Training loss: 2.0298333168029785
Validation loss: 2.4480917171765397

Epoch: 6| Step: 11
Training loss: 3.177900791168213
Validation loss: 2.4566207675523657

Epoch: 6| Step: 12
Training loss: 2.599130153656006
Validation loss: 2.453849500225436

Epoch: 6| Step: 13
Training loss: 2.4030542373657227
Validation loss: 2.459600974154729

Epoch: 71| Step: 0
Training loss: 2.5124337673187256
Validation loss: 2.439316911082114

Epoch: 6| Step: 1
Training loss: 2.542717695236206
Validation loss: 2.430058451109035

Epoch: 6| Step: 2
Training loss: 3.661062240600586
Validation loss: 2.4232506854559785

Epoch: 6| Step: 3
Training loss: 2.1003799438476562
Validation loss: 2.422873112463182

Epoch: 6| Step: 4
Training loss: 3.0799410343170166
Validation loss: 2.4224537752007924

Epoch: 6| Step: 5
Training loss: 2.402400016784668
Validation loss: 2.422299144088581

Epoch: 6| Step: 6
Training loss: 2.3584532737731934
Validation loss: 2.422501766553489

Epoch: 6| Step: 7
Training loss: 2.1225476264953613
Validation loss: 2.4198313015763477

Epoch: 6| Step: 8
Training loss: 2.7421135902404785
Validation loss: 2.4217050229349444

Epoch: 6| Step: 9
Training loss: 2.27376651763916
Validation loss: 2.422086742616469

Epoch: 6| Step: 10
Training loss: 2.875913619995117
Validation loss: 2.4205046956257155

Epoch: 6| Step: 11
Training loss: 3.0436060428619385
Validation loss: 2.418015113440893

Epoch: 6| Step: 12
Training loss: 2.7767281532287598
Validation loss: 2.418350150508265

Epoch: 6| Step: 13
Training loss: 2.776973009109497
Validation loss: 2.4190495949919506

Epoch: 72| Step: 0
Training loss: 2.882366180419922
Validation loss: 2.4224069631227882

Epoch: 6| Step: 1
Training loss: 2.57637882232666
Validation loss: 2.4196844562407462

Epoch: 6| Step: 2
Training loss: 2.7641990184783936
Validation loss: 2.4194879506223943

Epoch: 6| Step: 3
Training loss: 2.0818686485290527
Validation loss: 2.4237008530606508

Epoch: 6| Step: 4
Training loss: 2.709465265274048
Validation loss: 2.42601938145135

Epoch: 6| Step: 5
Training loss: 2.74699068069458
Validation loss: 2.4253389860994075

Epoch: 6| Step: 6
Training loss: 2.5885791778564453
Validation loss: 2.4250515891659643

Epoch: 6| Step: 7
Training loss: 2.4829745292663574
Validation loss: 2.4240850671645133

Epoch: 6| Step: 8
Training loss: 2.5997047424316406
Validation loss: 2.4260567285681285

Epoch: 6| Step: 9
Training loss: 2.520533561706543
Validation loss: 2.424709394413938

Epoch: 6| Step: 10
Training loss: 2.204273223876953
Validation loss: 2.4334958496914116

Epoch: 6| Step: 11
Training loss: 2.946549415588379
Validation loss: 2.4416325502498175

Epoch: 6| Step: 12
Training loss: 2.7090330123901367
Validation loss: 2.4549443657680223

Epoch: 6| Step: 13
Training loss: 3.74629807472229
Validation loss: 2.447122807143837

Epoch: 73| Step: 0
Training loss: 1.95379638671875
Validation loss: 2.4301490758054998

Epoch: 6| Step: 1
Training loss: 2.9614930152893066
Validation loss: 2.419452885145782

Epoch: 6| Step: 2
Training loss: 2.5196361541748047
Validation loss: 2.417029978126608

Epoch: 6| Step: 3
Training loss: 2.8287055492401123
Validation loss: 2.4114607713555776

Epoch: 6| Step: 4
Training loss: 3.11751127243042
Validation loss: 2.408335813912012

Epoch: 6| Step: 5
Training loss: 1.7032227516174316
Validation loss: 2.4087829333479687

Epoch: 6| Step: 6
Training loss: 2.390451669692993
Validation loss: 2.4109917840650006

Epoch: 6| Step: 7
Training loss: 2.256509780883789
Validation loss: 2.4094783452249344

Epoch: 6| Step: 8
Training loss: 3.313563823699951
Validation loss: 2.410145495527534

Epoch: 6| Step: 9
Training loss: 3.1436357498168945
Validation loss: 2.40902836989331

Epoch: 6| Step: 10
Training loss: 3.052502155303955
Validation loss: 2.405776108464887

Epoch: 6| Step: 11
Training loss: 2.65445613861084
Validation loss: 2.404173010139055

Epoch: 6| Step: 12
Training loss: 2.1968319416046143
Validation loss: 2.4036726156870523

Epoch: 6| Step: 13
Training loss: 3.0305869579315186
Validation loss: 2.4032402166756253

Epoch: 74| Step: 0
Training loss: 3.121950149536133
Validation loss: 2.4033799222720567

Epoch: 6| Step: 1
Training loss: 2.849808692932129
Validation loss: 2.408825392364174

Epoch: 6| Step: 2
Training loss: 3.435312271118164
Validation loss: 2.406518059392129

Epoch: 6| Step: 3
Training loss: 3.0758118629455566
Validation loss: 2.4100801457640944

Epoch: 6| Step: 4
Training loss: 2.232085704803467
Validation loss: 2.407956520716349

Epoch: 6| Step: 5
Training loss: 3.4338200092315674
Validation loss: 2.4117629297317995

Epoch: 6| Step: 6
Training loss: 2.5632481575012207
Validation loss: 2.407681195966659

Epoch: 6| Step: 7
Training loss: 1.9674932956695557
Validation loss: 2.4059738959035566

Epoch: 6| Step: 8
Training loss: 2.7274718284606934
Validation loss: 2.4050804184329126

Epoch: 6| Step: 9
Training loss: 1.7059576511383057
Validation loss: 2.404148901662519

Epoch: 6| Step: 10
Training loss: 2.2509307861328125
Validation loss: 2.404630635374336

Epoch: 6| Step: 11
Training loss: 3.2046632766723633
Validation loss: 2.406012988859607

Epoch: 6| Step: 12
Training loss: 2.0887210369110107
Validation loss: 2.403792676105294

Epoch: 6| Step: 13
Training loss: 2.090794324874878
Validation loss: 2.4037717209067395

Epoch: 75| Step: 0
Training loss: 2.4755897521972656
Validation loss: 2.4063203488626788

Epoch: 6| Step: 1
Training loss: 2.389035701751709
Validation loss: 2.4085607579959336

Epoch: 6| Step: 2
Training loss: 2.443559169769287
Validation loss: 2.405313430293914

Epoch: 6| Step: 3
Training loss: 2.2601475715637207
Validation loss: 2.408273540517335

Epoch: 6| Step: 4
Training loss: 2.7251744270324707
Validation loss: 2.4145518169608167

Epoch: 6| Step: 5
Training loss: 3.535226821899414
Validation loss: 2.4202700917438795

Epoch: 6| Step: 6
Training loss: 2.5716774463653564
Validation loss: 2.4105752975709978

Epoch: 6| Step: 7
Training loss: 1.833770751953125
Validation loss: 2.4062363921955066

Epoch: 6| Step: 8
Training loss: 2.9551548957824707
Validation loss: 2.3958408704368015

Epoch: 6| Step: 9
Training loss: 2.8827788829803467
Validation loss: 2.390635895472701

Epoch: 6| Step: 10
Training loss: 2.044076442718506
Validation loss: 2.3888049638399513

Epoch: 6| Step: 11
Training loss: 3.210144519805908
Validation loss: 2.3866602746389245

Epoch: 6| Step: 12
Training loss: 2.5833940505981445
Validation loss: 2.38471044007168

Epoch: 6| Step: 13
Training loss: 3.278999090194702
Validation loss: 2.384933912625877

Epoch: 76| Step: 0
Training loss: 2.9800333976745605
Validation loss: 2.3854057224847938

Epoch: 6| Step: 1
Training loss: 2.8138527870178223
Validation loss: 2.3890448898397465

Epoch: 6| Step: 2
Training loss: 2.9933409690856934
Validation loss: 2.3863253183262323

Epoch: 6| Step: 3
Training loss: 2.5753273963928223
Validation loss: 2.388033884827809

Epoch: 6| Step: 4
Training loss: 2.554635524749756
Validation loss: 2.3922528374579644

Epoch: 6| Step: 5
Training loss: 2.479520797729492
Validation loss: 2.3965157808796054

Epoch: 6| Step: 6
Training loss: 2.6250741481781006
Validation loss: 2.403537191370482

Epoch: 6| Step: 7
Training loss: 2.693830966949463
Validation loss: 2.3965061608181206

Epoch: 6| Step: 8
Training loss: 1.6904783248901367
Validation loss: 2.3971258953053463

Epoch: 6| Step: 9
Training loss: 3.054723024368286
Validation loss: 2.3975679297601022

Epoch: 6| Step: 10
Training loss: 2.676358699798584
Validation loss: 2.3930493913671023

Epoch: 6| Step: 11
Training loss: 2.2750163078308105
Validation loss: 2.3918244966896633

Epoch: 6| Step: 12
Training loss: 2.8384337425231934
Validation loss: 2.383672216887115

Epoch: 6| Step: 13
Training loss: 2.511003255844116
Validation loss: 2.385134925124466

Epoch: 77| Step: 0
Training loss: 2.0411980152130127
Validation loss: 2.3874462573759017

Epoch: 6| Step: 1
Training loss: 2.638655185699463
Validation loss: 2.387239525395055

Epoch: 6| Step: 2
Training loss: 2.4190425872802734
Validation loss: 2.391161903258293

Epoch: 6| Step: 3
Training loss: 3.495196580886841
Validation loss: 2.3959837395657777

Epoch: 6| Step: 4
Training loss: 2.620608329772949
Validation loss: 2.3963331740389586

Epoch: 6| Step: 5
Training loss: 2.5994510650634766
Validation loss: 2.396787904923962

Epoch: 6| Step: 6
Training loss: 2.584012508392334
Validation loss: 2.3860182505781933

Epoch: 6| Step: 7
Training loss: 3.334616184234619
Validation loss: 2.381567603798323

Epoch: 6| Step: 8
Training loss: 2.4330761432647705
Validation loss: 2.379807791402263

Epoch: 6| Step: 9
Training loss: 1.988391637802124
Validation loss: 2.3816997876731296

Epoch: 6| Step: 10
Training loss: 3.0332512855529785
Validation loss: 2.38908976124179

Epoch: 6| Step: 11
Training loss: 2.295687675476074
Validation loss: 2.4061585728840162

Epoch: 6| Step: 12
Training loss: 2.5876760482788086
Validation loss: 2.4071760536521993

Epoch: 6| Step: 13
Training loss: 2.8017385005950928
Validation loss: 2.406971111092516

Epoch: 78| Step: 0
Training loss: 3.3365468978881836
Validation loss: 2.3733879366228656

Epoch: 6| Step: 1
Training loss: 2.291046380996704
Validation loss: 2.3721897704626924

Epoch: 6| Step: 2
Training loss: 2.5273585319519043
Validation loss: 2.386436859766642

Epoch: 6| Step: 3
Training loss: 2.338904857635498
Validation loss: 2.404429940767186

Epoch: 6| Step: 4
Training loss: 2.43937611579895
Validation loss: 2.410135546038228

Epoch: 6| Step: 5
Training loss: 3.177852153778076
Validation loss: 2.408966951472785

Epoch: 6| Step: 6
Training loss: 2.1158955097198486
Validation loss: 2.4033910356542116

Epoch: 6| Step: 7
Training loss: 1.9851984977722168
Validation loss: 2.3955815094773487

Epoch: 6| Step: 8
Training loss: 2.250904083251953
Validation loss: 2.3904892321555846

Epoch: 6| Step: 9
Training loss: 2.939152240753174
Validation loss: 2.377731361696797

Epoch: 6| Step: 10
Training loss: 2.9847235679626465
Validation loss: 2.3719031759487685

Epoch: 6| Step: 11
Training loss: 2.6851000785827637
Validation loss: 2.3664326283239547

Epoch: 6| Step: 12
Training loss: 2.936479091644287
Validation loss: 2.3666306490539224

Epoch: 6| Step: 13
Training loss: 2.7899980545043945
Validation loss: 2.367100715637207

Epoch: 79| Step: 0
Training loss: 2.6389272212982178
Validation loss: 2.379022782848727

Epoch: 6| Step: 1
Training loss: 3.4451379776000977
Validation loss: 2.379836477259154

Epoch: 6| Step: 2
Training loss: 2.121319532394409
Validation loss: 2.3710893392562866

Epoch: 6| Step: 3
Training loss: 2.312889575958252
Validation loss: 2.36838137590757

Epoch: 6| Step: 4
Training loss: 2.4746932983398438
Validation loss: 2.368790271461651

Epoch: 6| Step: 5
Training loss: 2.4491147994995117
Validation loss: 2.371814453473655

Epoch: 6| Step: 6
Training loss: 2.750441074371338
Validation loss: 2.3713448714184504

Epoch: 6| Step: 7
Training loss: 3.08528208732605
Validation loss: 2.383309354064285

Epoch: 6| Step: 8
Training loss: 2.195737838745117
Validation loss: 2.381679291366249

Epoch: 6| Step: 9
Training loss: 2.638930320739746
Validation loss: 2.379143555959066

Epoch: 6| Step: 10
Training loss: 2.9506592750549316
Validation loss: 2.3753858176610803

Epoch: 6| Step: 11
Training loss: 2.9751105308532715
Validation loss: 2.3729987939198813

Epoch: 6| Step: 12
Training loss: 2.343295097351074
Validation loss: 2.3724014656518095

Epoch: 6| Step: 13
Training loss: 2.371490716934204
Validation loss: 2.381786787381736

Epoch: 80| Step: 0
Training loss: 2.1193416118621826
Validation loss: 2.3915952995259273

Epoch: 6| Step: 1
Training loss: 2.533912181854248
Validation loss: 2.40680351308597

Epoch: 6| Step: 2
Training loss: 2.8365535736083984
Validation loss: 2.4119494884244856

Epoch: 6| Step: 3
Training loss: 2.46826171875
Validation loss: 2.3999706827184206

Epoch: 6| Step: 4
Training loss: 3.3074612617492676
Validation loss: 2.384366589207803

Epoch: 6| Step: 5
Training loss: 2.3052115440368652
Validation loss: 2.3785929038960445

Epoch: 6| Step: 6
Training loss: 1.671376347541809
Validation loss: 2.3674505718292727

Epoch: 6| Step: 7
Training loss: 2.7569265365600586
Validation loss: 2.3646355803294847

Epoch: 6| Step: 8
Training loss: 2.415421724319458
Validation loss: 2.3634184868104997

Epoch: 6| Step: 9
Training loss: 3.517240524291992
Validation loss: 2.362182386459843

Epoch: 6| Step: 10
Training loss: 2.8179452419281006
Validation loss: 2.364404914199665

Epoch: 6| Step: 11
Training loss: 2.199451446533203
Validation loss: 2.3693708988928024

Epoch: 6| Step: 12
Training loss: 3.3498289585113525
Validation loss: 2.370015267402895

Epoch: 6| Step: 13
Training loss: 2.5894742012023926
Validation loss: 2.364301368754397

Epoch: 81| Step: 0
Training loss: 2.5328660011291504
Validation loss: 2.357572296614288

Epoch: 6| Step: 1
Training loss: 2.848707437515259
Validation loss: 2.351118920951761

Epoch: 6| Step: 2
Training loss: 2.1994616985321045
Validation loss: 2.3502556534223658

Epoch: 6| Step: 3
Training loss: 2.6384923458099365
Validation loss: 2.3515654994595434

Epoch: 6| Step: 4
Training loss: 2.4557905197143555
Validation loss: 2.349526943699006

Epoch: 6| Step: 5
Training loss: 3.2012503147125244
Validation loss: 2.352675825036982

Epoch: 6| Step: 6
Training loss: 2.923757791519165
Validation loss: 2.359420432839342

Epoch: 6| Step: 7
Training loss: 2.921236991882324
Validation loss: 2.3650662873380925

Epoch: 6| Step: 8
Training loss: 2.445026397705078
Validation loss: 2.368707195405037

Epoch: 6| Step: 9
Training loss: 2.5711774826049805
Validation loss: 2.369724124990484

Epoch: 6| Step: 10
Training loss: 2.5592284202575684
Validation loss: 2.3699495946207354

Epoch: 6| Step: 11
Training loss: 2.3338727951049805
Validation loss: 2.368511579369986

Epoch: 6| Step: 12
Training loss: 2.7600584030151367
Validation loss: 2.3624168852324128

Epoch: 6| Step: 13
Training loss: 2.02740216255188
Validation loss: 2.3624297367629183

Epoch: 82| Step: 0
Training loss: 2.818756580352783
Validation loss: 2.3584131040880756

Epoch: 6| Step: 1
Training loss: 2.6372852325439453
Validation loss: 2.344939831764467

Epoch: 6| Step: 2
Training loss: 2.736984968185425
Validation loss: 2.3432508412227837

Epoch: 6| Step: 3
Training loss: 2.9483892917633057
Validation loss: 2.3500257230574086

Epoch: 6| Step: 4
Training loss: 2.120635509490967
Validation loss: 2.352137214394026

Epoch: 6| Step: 5
Training loss: 2.3535003662109375
Validation loss: 2.3569011021685857

Epoch: 6| Step: 6
Training loss: 3.274984359741211
Validation loss: 2.3592564828934206

Epoch: 6| Step: 7
Training loss: 2.50130295753479
Validation loss: 2.3560593974205757

Epoch: 6| Step: 8
Training loss: 3.4097392559051514
Validation loss: 2.3516589685152938

Epoch: 6| Step: 9
Training loss: 1.9283066987991333
Validation loss: 2.3497589583038003

Epoch: 6| Step: 10
Training loss: 1.9777156114578247
Validation loss: 2.3585814352958434

Epoch: 6| Step: 11
Training loss: 2.6481270790100098
Validation loss: 2.3597046482947563

Epoch: 6| Step: 12
Training loss: 2.6633594036102295
Validation loss: 2.3560002901220836

Epoch: 6| Step: 13
Training loss: 2.5736770629882812
Validation loss: 2.35659961546621

Epoch: 83| Step: 0
Training loss: 2.6510748863220215
Validation loss: 2.354957954857939

Epoch: 6| Step: 1
Training loss: 2.8117318153381348
Validation loss: 2.350644237251692

Epoch: 6| Step: 2
Training loss: 2.59492564201355
Validation loss: 2.348360638464651

Epoch: 6| Step: 3
Training loss: 2.441744565963745
Validation loss: 2.348928928375244

Epoch: 6| Step: 4
Training loss: 2.346508502960205
Validation loss: 2.3499831281682497

Epoch: 6| Step: 5
Training loss: 2.708414316177368
Validation loss: 2.3531886685279106

Epoch: 6| Step: 6
Training loss: 2.1693363189697266
Validation loss: 2.3543422632319952

Epoch: 6| Step: 7
Training loss: 2.5818209648132324
Validation loss: 2.3580906724417083

Epoch: 6| Step: 8
Training loss: 2.2629761695861816
Validation loss: 2.3554082134718537

Epoch: 6| Step: 9
Training loss: 2.152768850326538
Validation loss: 2.3553083942782496

Epoch: 6| Step: 10
Training loss: 3.0419058799743652
Validation loss: 2.361263936565768

Epoch: 6| Step: 11
Training loss: 2.9214625358581543
Validation loss: 2.3832092387701875

Epoch: 6| Step: 12
Training loss: 2.4717538356781006
Validation loss: 2.385500643842964

Epoch: 6| Step: 13
Training loss: 3.8468501567840576
Validation loss: 2.3934821210881716

Epoch: 84| Step: 0
Training loss: 1.959019660949707
Validation loss: 2.3936739557532856

Epoch: 6| Step: 1
Training loss: 2.2110633850097656
Validation loss: 2.390620041919011

Epoch: 6| Step: 2
Training loss: 3.1028685569763184
Validation loss: 2.4001649387421145

Epoch: 6| Step: 3
Training loss: 2.4449169635772705
Validation loss: 2.409110814012507

Epoch: 6| Step: 4
Training loss: 2.940455913543701
Validation loss: 2.4073796092822985

Epoch: 6| Step: 5
Training loss: 2.2754364013671875
Validation loss: 2.3872360029528217

Epoch: 6| Step: 6
Training loss: 2.841341257095337
Validation loss: 2.368497330655334

Epoch: 6| Step: 7
Training loss: 2.5267510414123535
Validation loss: 2.3670943757539153

Epoch: 6| Step: 8
Training loss: 3.276662826538086
Validation loss: 2.3631548484166465

Epoch: 6| Step: 9
Training loss: 2.377167224884033
Validation loss: 2.3663078456796627

Epoch: 6| Step: 10
Training loss: 2.5436644554138184
Validation loss: 2.3745394419598322

Epoch: 6| Step: 11
Training loss: 2.713508367538452
Validation loss: 2.372945708613242

Epoch: 6| Step: 12
Training loss: 3.023815155029297
Validation loss: 2.373272931703957

Epoch: 6| Step: 13
Training loss: 2.2566847801208496
Validation loss: 2.3670675626365085

Epoch: 85| Step: 0
Training loss: 2.8900935649871826
Validation loss: 2.363180355359149

Epoch: 6| Step: 1
Training loss: 2.6353695392608643
Validation loss: 2.3629022798230572

Epoch: 6| Step: 2
Training loss: 3.6026835441589355
Validation loss: 2.3696011292037142

Epoch: 6| Step: 3
Training loss: 2.183000087738037
Validation loss: 2.371155059465798

Epoch: 6| Step: 4
Training loss: 2.116236925125122
Validation loss: 2.379757423554697

Epoch: 6| Step: 5
Training loss: 2.8589329719543457
Validation loss: 2.3842830888686644

Epoch: 6| Step: 6
Training loss: 2.507533550262451
Validation loss: 2.3844104787354827

Epoch: 6| Step: 7
Training loss: 2.081328868865967
Validation loss: 2.380289093140633

Epoch: 6| Step: 8
Training loss: 2.5560948848724365
Validation loss: 2.379162960155036

Epoch: 6| Step: 9
Training loss: 2.241727113723755
Validation loss: 2.3756560920387186

Epoch: 6| Step: 10
Training loss: 2.4097580909729004
Validation loss: 2.37089785709176

Epoch: 6| Step: 11
Training loss: 2.4327664375305176
Validation loss: 2.3727988889140468

Epoch: 6| Step: 12
Training loss: 3.079024314880371
Validation loss: 2.3747815752542145

Epoch: 6| Step: 13
Training loss: 3.1364734172821045
Validation loss: 2.3797865734305432

Epoch: 86| Step: 0
Training loss: 3.3213295936584473
Validation loss: 2.3717928932559107

Epoch: 6| Step: 1
Training loss: 2.04194974899292
Validation loss: 2.364550618715184

Epoch: 6| Step: 2
Training loss: 2.4782824516296387
Validation loss: 2.3586324440535678

Epoch: 6| Step: 3
Training loss: 3.0269358158111572
Validation loss: 2.3421792676371913

Epoch: 6| Step: 4
Training loss: 2.2000818252563477
Validation loss: 2.337286977357762

Epoch: 6| Step: 5
Training loss: 2.8972089290618896
Validation loss: 2.333511811430736

Epoch: 6| Step: 6
Training loss: 2.5633583068847656
Validation loss: 2.329304600274691

Epoch: 6| Step: 7
Training loss: 3.036835193634033
Validation loss: 2.3301611074837307

Epoch: 6| Step: 8
Training loss: 2.273819923400879
Validation loss: 2.3289082127232708

Epoch: 6| Step: 9
Training loss: 2.0510292053222656
Validation loss: 2.3313620116121028

Epoch: 6| Step: 10
Training loss: 2.4819071292877197
Validation loss: 2.332184483928065

Epoch: 6| Step: 11
Training loss: 2.8646979331970215
Validation loss: 2.336426934888286

Epoch: 6| Step: 12
Training loss: 2.617713451385498
Validation loss: 2.3428365286960395

Epoch: 6| Step: 13
Training loss: 2.374933958053589
Validation loss: 2.3506123788895144

Epoch: 87| Step: 0
Training loss: 2.2776360511779785
Validation loss: 2.36190551839849

Epoch: 6| Step: 1
Training loss: 2.350454330444336
Validation loss: 2.377478370102503

Epoch: 6| Step: 2
Training loss: 2.4693198204040527
Validation loss: 2.3893158192275674

Epoch: 6| Step: 3
Training loss: 3.1085402965545654
Validation loss: 2.364323522454949

Epoch: 6| Step: 4
Training loss: 2.68017578125
Validation loss: 2.3515044361032467

Epoch: 6| Step: 5
Training loss: 2.3492062091827393
Validation loss: 2.3406378710141746

Epoch: 6| Step: 6
Training loss: 2.6418652534484863
Validation loss: 2.3357502670698267

Epoch: 6| Step: 7
Training loss: 2.925503730773926
Validation loss: 2.340678773900514

Epoch: 6| Step: 8
Training loss: 2.5035643577575684
Validation loss: 2.3455813751425794

Epoch: 6| Step: 9
Training loss: 2.596633195877075
Validation loss: 2.365448505647721

Epoch: 6| Step: 10
Training loss: 2.7215161323547363
Validation loss: 2.3853406085762927

Epoch: 6| Step: 11
Training loss: 2.9286270141601562
Validation loss: 2.3802592164726666

Epoch: 6| Step: 12
Training loss: 2.352116107940674
Validation loss: 2.373518369531119

Epoch: 6| Step: 13
Training loss: 2.5909111499786377
Validation loss: 2.353232934910764

Epoch: 88| Step: 0
Training loss: 2.686339855194092
Validation loss: 2.342871648009105

Epoch: 6| Step: 1
Training loss: 2.6412534713745117
Validation loss: 2.341093732464698

Epoch: 6| Step: 2
Training loss: 2.19931697845459
Validation loss: 2.3424933930878997

Epoch: 6| Step: 3
Training loss: 2.4124069213867188
Validation loss: 2.355020180825264

Epoch: 6| Step: 4
Training loss: 3.1047489643096924
Validation loss: 2.3581958329805763

Epoch: 6| Step: 5
Training loss: 2.6849236488342285
Validation loss: 2.3586470901325183

Epoch: 6| Step: 6
Training loss: 2.5984976291656494
Validation loss: 2.361256253334784

Epoch: 6| Step: 7
Training loss: 2.9174134731292725
Validation loss: 2.364363647276355

Epoch: 6| Step: 8
Training loss: 3.1141912937164307
Validation loss: 2.375285117856918

Epoch: 6| Step: 9
Training loss: 2.2947840690612793
Validation loss: 2.3798255664046093

Epoch: 6| Step: 10
Training loss: 3.0383193492889404
Validation loss: 2.3838505206569547

Epoch: 6| Step: 11
Training loss: 1.7803449630737305
Validation loss: 2.3685993917526735

Epoch: 6| Step: 12
Training loss: 2.162644386291504
Validation loss: 2.3521425775302354

Epoch: 6| Step: 13
Training loss: 2.670452356338501
Validation loss: 2.3384203475008727

Epoch: 89| Step: 0
Training loss: 2.4882402420043945
Validation loss: 2.333369880594233

Epoch: 6| Step: 1
Training loss: 2.3827571868896484
Validation loss: 2.332305336511263

Epoch: 6| Step: 2
Training loss: 2.347442626953125
Validation loss: 2.331117642823086

Epoch: 6| Step: 3
Training loss: 3.0259993076324463
Validation loss: 2.3304164255819013

Epoch: 6| Step: 4
Training loss: 3.1287779808044434
Validation loss: 2.329460931080644

Epoch: 6| Step: 5
Training loss: 2.0790271759033203
Validation loss: 2.336816574937554

Epoch: 6| Step: 6
Training loss: 2.8640973567962646
Validation loss: 2.340041801493655

Epoch: 6| Step: 7
Training loss: 2.3060171604156494
Validation loss: 2.348572895091067

Epoch: 6| Step: 8
Training loss: 2.4102954864501953
Validation loss: 2.3441134665601995

Epoch: 6| Step: 9
Training loss: 2.758301258087158
Validation loss: 2.345446022607947

Epoch: 6| Step: 10
Training loss: 2.4556708335876465
Validation loss: 2.3413672190840527

Epoch: 6| Step: 11
Training loss: 2.0396857261657715
Validation loss: 2.3466066698874197

Epoch: 6| Step: 12
Training loss: 2.895291328430176
Validation loss: 2.350863064489057

Epoch: 6| Step: 13
Training loss: 3.0337729454040527
Validation loss: 2.3452748995955273

Epoch: 90| Step: 0
Training loss: 2.9433813095092773
Validation loss: 2.343232193300801

Epoch: 6| Step: 1
Training loss: 2.400116443634033
Validation loss: 2.3414138568344938

Epoch: 6| Step: 2
Training loss: 1.789242148399353
Validation loss: 2.3354750756294496

Epoch: 6| Step: 3
Training loss: 2.1057729721069336
Validation loss: 2.3421635755928616

Epoch: 6| Step: 4
Training loss: 1.9877042770385742
Validation loss: 2.3621547760501986

Epoch: 6| Step: 5
Training loss: 2.9592864513397217
Validation loss: 2.374504869984042

Epoch: 6| Step: 6
Training loss: 2.966212749481201
Validation loss: 2.3855411775650515

Epoch: 6| Step: 7
Training loss: 2.0495166778564453
Validation loss: 2.379499186751663

Epoch: 6| Step: 8
Training loss: 2.8521463871002197
Validation loss: 2.343049362141599

Epoch: 6| Step: 9
Training loss: 2.321425676345825
Validation loss: 2.321147962283063

Epoch: 6| Step: 10
Training loss: 2.822967529296875
Validation loss: 2.313020087057544

Epoch: 6| Step: 11
Training loss: 2.7358837127685547
Validation loss: 2.30794253400577

Epoch: 6| Step: 12
Training loss: 3.5896427631378174
Validation loss: 2.308066171984519

Epoch: 6| Step: 13
Training loss: 2.6113667488098145
Validation loss: 2.302580992380778

Epoch: 91| Step: 0
Training loss: 2.4144058227539062
Validation loss: 2.3000388863266155

Epoch: 6| Step: 1
Training loss: 2.6770966053009033
Validation loss: 2.304568931620608

Epoch: 6| Step: 2
Training loss: 3.5084681510925293
Validation loss: 2.3065416120713755

Epoch: 6| Step: 3
Training loss: 2.604281187057495
Validation loss: 2.30557724993716

Epoch: 6| Step: 4
Training loss: 2.1964612007141113
Validation loss: 2.3124160330782653

Epoch: 6| Step: 5
Training loss: 2.8960189819335938
Validation loss: 2.317045701447354

Epoch: 6| Step: 6
Training loss: 2.541370391845703
Validation loss: 2.3341227449396604

Epoch: 6| Step: 7
Training loss: 2.42051100730896
Validation loss: 2.3448814961218063

Epoch: 6| Step: 8
Training loss: 2.3249003887176514
Validation loss: 2.3264950475385113

Epoch: 6| Step: 9
Training loss: 2.4650490283966064
Validation loss: 2.3129025069616174

Epoch: 6| Step: 10
Training loss: 2.420764207839966
Validation loss: 2.3073857112597396

Epoch: 6| Step: 11
Training loss: 2.2784175872802734
Validation loss: 2.3110488460909937

Epoch: 6| Step: 12
Training loss: 3.0714282989501953
Validation loss: 2.3102336314416703

Epoch: 6| Step: 13
Training loss: 2.1007630825042725
Validation loss: 2.3121015512815086

Epoch: 92| Step: 0
Training loss: 2.8864188194274902
Validation loss: 2.311722219631236

Epoch: 6| Step: 1
Training loss: 3.152496814727783
Validation loss: 2.315263784059914

Epoch: 6| Step: 2
Training loss: 2.2363359928131104
Validation loss: 2.3230119136071976

Epoch: 6| Step: 3
Training loss: 2.228325843811035
Validation loss: 2.3210214901995916

Epoch: 6| Step: 4
Training loss: 1.9079415798187256
Validation loss: 2.3056032503804853

Epoch: 6| Step: 5
Training loss: 3.173788547515869
Validation loss: 2.3059417663082

Epoch: 6| Step: 6
Training loss: 2.986477851867676
Validation loss: 2.2988461550845893

Epoch: 6| Step: 7
Training loss: 2.4226739406585693
Validation loss: 2.3023232542058474

Epoch: 6| Step: 8
Training loss: 2.682281017303467
Validation loss: 2.2978008972701205

Epoch: 6| Step: 9
Training loss: 2.0311670303344727
Validation loss: 2.303529570179601

Epoch: 6| Step: 10
Training loss: 2.0561466217041016
Validation loss: 2.3043519989136727

Epoch: 6| Step: 11
Training loss: 2.3609619140625
Validation loss: 2.3026837046428392

Epoch: 6| Step: 12
Training loss: 2.8765745162963867
Validation loss: 2.3014006537775837

Epoch: 6| Step: 13
Training loss: 3.4371979236602783
Validation loss: 2.302951115433888

Epoch: 93| Step: 0
Training loss: 2.7411022186279297
Validation loss: 2.307555288396856

Epoch: 6| Step: 1
Training loss: 2.8390953540802
Validation loss: 2.315748958177464

Epoch: 6| Step: 2
Training loss: 3.126434803009033
Validation loss: 2.3270418285041727

Epoch: 6| Step: 3
Training loss: 3.0337188243865967
Validation loss: 2.323262007005753

Epoch: 6| Step: 4
Training loss: 2.5705373287200928
Validation loss: 2.3215369332221245

Epoch: 6| Step: 5
Training loss: 2.759974956512451
Validation loss: 2.316866151748165

Epoch: 6| Step: 6
Training loss: 2.1460013389587402
Validation loss: 2.3103926233066026

Epoch: 6| Step: 7
Training loss: 2.521745204925537
Validation loss: 2.318213285938386

Epoch: 6| Step: 8
Training loss: 2.497349500656128
Validation loss: 2.321315780762703

Epoch: 6| Step: 9
Training loss: 3.141136646270752
Validation loss: 2.3460452120791198

Epoch: 6| Step: 10
Training loss: 2.075620174407959
Validation loss: 2.402188807405451

Epoch: 6| Step: 11
Training loss: 2.4209988117218018
Validation loss: 2.479282881623955

Epoch: 6| Step: 12
Training loss: 2.069904327392578
Validation loss: 2.5429830448601836

Epoch: 6| Step: 13
Training loss: 2.38668155670166
Validation loss: 2.5239969145867134

Epoch: 94| Step: 0
Training loss: 2.9411392211914062
Validation loss: 2.5054041108777447

Epoch: 6| Step: 1
Training loss: 3.5961174964904785
Validation loss: 2.512389729099889

Epoch: 6| Step: 2
Training loss: 1.9585208892822266
Validation loss: 2.463760778468142

Epoch: 6| Step: 3
Training loss: 2.644963264465332
Validation loss: 2.452851544144333

Epoch: 6| Step: 4
Training loss: 2.7185330390930176
Validation loss: 2.4420703534157044

Epoch: 6| Step: 5
Training loss: 2.8494210243225098
Validation loss: 2.4313381615505425

Epoch: 6| Step: 6
Training loss: 2.3997879028320312
Validation loss: 2.41318932912683

Epoch: 6| Step: 7
Training loss: 1.9759711027145386
Validation loss: 2.4131802717844644

Epoch: 6| Step: 8
Training loss: 2.2001914978027344
Validation loss: 2.4040263058036886

Epoch: 6| Step: 9
Training loss: 3.3119101524353027
Validation loss: 2.4050565329931115

Epoch: 6| Step: 10
Training loss: 2.4563333988189697
Validation loss: 2.398490813470656

Epoch: 6| Step: 11
Training loss: 2.721959352493286
Validation loss: 2.3989679351929696

Epoch: 6| Step: 12
Training loss: 2.2218177318573
Validation loss: 2.4092796002664874

Epoch: 6| Step: 13
Training loss: 2.9481115341186523
Validation loss: 2.436644756665794

Epoch: 95| Step: 0
Training loss: 2.643782615661621
Validation loss: 2.464773242191602

Epoch: 6| Step: 1
Training loss: 3.6268482208251953
Validation loss: 2.4557953855042816

Epoch: 6| Step: 2
Training loss: 3.0074825286865234
Validation loss: 2.457959618619693

Epoch: 6| Step: 3
Training loss: 3.05454158782959
Validation loss: 2.442851845936109

Epoch: 6| Step: 4
Training loss: 3.42744779586792
Validation loss: 2.4282003500128306

Epoch: 6| Step: 5
Training loss: 2.3009743690490723
Validation loss: 2.412176988458121

Epoch: 6| Step: 6
Training loss: 2.4182329177856445
Validation loss: 2.4134701067401516

Epoch: 6| Step: 7
Training loss: 2.7732911109924316
Validation loss: 2.4187676675858034

Epoch: 6| Step: 8
Training loss: 2.3428962230682373
Validation loss: 2.420202819249963

Epoch: 6| Step: 9
Training loss: 2.4412612915039062
Validation loss: 2.430544258445822

Epoch: 6| Step: 10
Training loss: 2.312628746032715
Validation loss: 2.4218194612892727

Epoch: 6| Step: 11
Training loss: 2.3597517013549805
Validation loss: 2.412462147333289

Epoch: 6| Step: 12
Training loss: 2.545292377471924
Validation loss: 2.4144535064697266

Epoch: 6| Step: 13
Training loss: 1.5138897895812988
Validation loss: 2.451125811505061

Epoch: 96| Step: 0
Training loss: 2.747971534729004
Validation loss: 2.455517679132441

Epoch: 6| Step: 1
Training loss: 2.636470317840576
Validation loss: 2.424373419054093

Epoch: 6| Step: 2
Training loss: 2.357264995574951
Validation loss: 2.3916828196535826

Epoch: 6| Step: 3
Training loss: 3.251041889190674
Validation loss: 2.360710577298236

Epoch: 6| Step: 4
Training loss: 2.9267172813415527
Validation loss: 2.3471510999946186

Epoch: 6| Step: 5
Training loss: 2.616520404815674
Validation loss: 2.343719546512891

Epoch: 6| Step: 6
Training loss: 2.2185211181640625
Validation loss: 2.342802104129586

Epoch: 6| Step: 7
Training loss: 3.0966036319732666
Validation loss: 2.34088981792491

Epoch: 6| Step: 8
Training loss: 2.527378559112549
Validation loss: 2.341581283077117

Epoch: 6| Step: 9
Training loss: 2.389641523361206
Validation loss: 2.3451705517307406

Epoch: 6| Step: 10
Training loss: 2.568110942840576
Validation loss: 2.34691801891532

Epoch: 6| Step: 11
Training loss: 2.7645905017852783
Validation loss: 2.342094559823313

Epoch: 6| Step: 12
Training loss: 2.5566463470458984
Validation loss: 2.3381786910436486

Epoch: 6| Step: 13
Training loss: 1.4655413627624512
Validation loss: 2.3347037658896497

Epoch: 97| Step: 0
Training loss: 2.2095346450805664
Validation loss: 2.340758116014542

Epoch: 6| Step: 1
Training loss: 3.9778270721435547
Validation loss: 2.3770736520008375

Epoch: 6| Step: 2
Training loss: 1.8962091207504272
Validation loss: 2.4161157146576913

Epoch: 6| Step: 3
Training loss: 3.271251678466797
Validation loss: 2.3974330040716354

Epoch: 6| Step: 4
Training loss: 2.331313133239746
Validation loss: 2.3324982504690848

Epoch: 6| Step: 5
Training loss: 2.089043378829956
Validation loss: 2.3224779380265104

Epoch: 6| Step: 6
Training loss: 2.3330140113830566
Validation loss: 2.3177073001861572

Epoch: 6| Step: 7
Training loss: 3.1153011322021484
Validation loss: 2.3257477104022937

Epoch: 6| Step: 8
Training loss: 2.810882568359375
Validation loss: 2.329862792004821

Epoch: 6| Step: 9
Training loss: 2.2585277557373047
Validation loss: 2.3313798981328167

Epoch: 6| Step: 10
Training loss: 2.728299617767334
Validation loss: 2.338945552866946

Epoch: 6| Step: 11
Training loss: 3.168365001678467
Validation loss: 2.3284870219487015

Epoch: 6| Step: 12
Training loss: 2.0644149780273438
Validation loss: 2.321978456230574

Epoch: 6| Step: 13
Training loss: 1.6488467454910278
Validation loss: 2.3166110848867767

Epoch: 98| Step: 0
Training loss: 3.1085071563720703
Validation loss: 2.309017212160172

Epoch: 6| Step: 1
Training loss: 2.860978603363037
Validation loss: 2.3111808402563936

Epoch: 6| Step: 2
Training loss: 2.3344686031341553
Validation loss: 2.3210116304377073

Epoch: 6| Step: 3
Training loss: 2.704904079437256
Validation loss: 2.3277228647662747

Epoch: 6| Step: 4
Training loss: 2.9191579818725586
Validation loss: 2.3628429392332673

Epoch: 6| Step: 5
Training loss: 2.725912570953369
Validation loss: 2.3643868994969193

Epoch: 6| Step: 6
Training loss: 2.350956439971924
Validation loss: 2.322652752681445

Epoch: 6| Step: 7
Training loss: 2.181220293045044
Validation loss: 2.290269631211476

Epoch: 6| Step: 8
Training loss: 1.9572679996490479
Validation loss: 2.281944521011845

Epoch: 6| Step: 9
Training loss: 3.157839775085449
Validation loss: 2.269909917667348

Epoch: 6| Step: 10
Training loss: 3.2063050270080566
Validation loss: 2.2649347730862197

Epoch: 6| Step: 11
Training loss: 2.0834312438964844
Validation loss: 2.26607802350034

Epoch: 6| Step: 12
Training loss: 2.013418436050415
Validation loss: 2.277511191624467

Epoch: 6| Step: 13
Training loss: 1.85280179977417
Validation loss: 2.2970354364764307

Epoch: 99| Step: 0
Training loss: 2.303511381149292
Validation loss: 2.3179970582326255

Epoch: 6| Step: 1
Training loss: 1.8270299434661865
Validation loss: 2.3609061241149902

Epoch: 6| Step: 2
Training loss: 2.4840445518493652
Validation loss: 2.3721361852461293

Epoch: 6| Step: 3
Training loss: 2.698756217956543
Validation loss: 2.355012465548772

Epoch: 6| Step: 4
Training loss: 2.831244707107544
Validation loss: 2.3247197494711926

Epoch: 6| Step: 5
Training loss: 3.0545897483825684
Validation loss: 2.327932491097399

Epoch: 6| Step: 6
Training loss: 2.58192777633667
Validation loss: 2.331406585631832

Epoch: 6| Step: 7
Training loss: 2.1578621864318848
Validation loss: 2.3350242132781656

Epoch: 6| Step: 8
Training loss: 2.6459383964538574
Validation loss: 2.337253471856476

Epoch: 6| Step: 9
Training loss: 2.1771085262298584
Validation loss: 2.3509512742360434

Epoch: 6| Step: 10
Training loss: 3.610105037689209
Validation loss: 2.3401133257855653

Epoch: 6| Step: 11
Training loss: 2.2858924865722656
Validation loss: 2.338851313437185

Epoch: 6| Step: 12
Training loss: 3.039533853530884
Validation loss: 2.3486854235331216

Epoch: 6| Step: 13
Training loss: 2.4778051376342773
Validation loss: 2.346884239104486

Epoch: 100| Step: 0
Training loss: 2.9893078804016113
Validation loss: 2.3505786362514702

Epoch: 6| Step: 1
Training loss: 2.8645384311676025
Validation loss: 2.3470714925437846

Epoch: 6| Step: 2
Training loss: 3.068927049636841
Validation loss: 2.3382878970074397

Epoch: 6| Step: 3
Training loss: 2.7621331214904785
Validation loss: 2.3440423857781196

Epoch: 6| Step: 4
Training loss: 2.4290595054626465
Validation loss: 2.3346221241899716

Epoch: 6| Step: 5
Training loss: 2.2536704540252686
Validation loss: 2.338957622487058

Epoch: 6| Step: 6
Training loss: 2.6981921195983887
Validation loss: 2.3425221020175564

Epoch: 6| Step: 7
Training loss: 2.383340835571289
Validation loss: 2.3458504266636346

Epoch: 6| Step: 8
Training loss: 2.284719705581665
Validation loss: 2.350697471249488

Epoch: 6| Step: 9
Training loss: 2.7337229251861572
Validation loss: 2.3636499681780414

Epoch: 6| Step: 10
Training loss: 1.9059112071990967
Validation loss: 2.356247648116081

Epoch: 6| Step: 11
Training loss: 2.2874419689178467
Validation loss: 2.3541819741649013

Epoch: 6| Step: 12
Training loss: 2.9343414306640625
Validation loss: 2.3407128959573726

Epoch: 6| Step: 13
Training loss: 2.0317635536193848
Validation loss: 2.33835684099505

Epoch: 101| Step: 0
Training loss: 2.5854361057281494
Validation loss: 2.3252353924576954

Epoch: 6| Step: 1
Training loss: 2.375974178314209
Validation loss: 2.3206921572326333

Epoch: 6| Step: 2
Training loss: 2.400496482849121
Validation loss: 2.3114473409550165

Epoch: 6| Step: 3
Training loss: 2.9977893829345703
Validation loss: 2.3106109737068095

Epoch: 6| Step: 4
Training loss: 2.4803993701934814
Validation loss: 2.2897093065323366

Epoch: 6| Step: 5
Training loss: 2.258014678955078
Validation loss: 2.2751192046749975

Epoch: 6| Step: 6
Training loss: 2.2444677352905273
Validation loss: 2.2690996175171225

Epoch: 6| Step: 7
Training loss: 2.587442398071289
Validation loss: 2.26498350533106

Epoch: 6| Step: 8
Training loss: 2.517455577850342
Validation loss: 2.2628878444753666

Epoch: 6| Step: 9
Training loss: 2.6757287979125977
Validation loss: 2.262904523521341

Epoch: 6| Step: 10
Training loss: 2.7283883094787598
Validation loss: 2.261148674513704

Epoch: 6| Step: 11
Training loss: 2.4814648628234863
Validation loss: 2.259551187997223

Epoch: 6| Step: 12
Training loss: 2.5882129669189453
Validation loss: 2.267265801788658

Epoch: 6| Step: 13
Training loss: 2.3448879718780518
Validation loss: 2.2916445757753108

Epoch: 102| Step: 0
Training loss: 2.8588953018188477
Validation loss: 2.320505606230869

Epoch: 6| Step: 1
Training loss: 1.8353917598724365
Validation loss: 2.3398213796718146

Epoch: 6| Step: 2
Training loss: 2.9117817878723145
Validation loss: 2.3634863540690434

Epoch: 6| Step: 3
Training loss: 2.6657605171203613
Validation loss: 2.369676502802039

Epoch: 6| Step: 4
Training loss: 2.3952126502990723
Validation loss: 2.352914000070223

Epoch: 6| Step: 5
Training loss: 2.3756494522094727
Validation loss: 2.3477528069608953

Epoch: 6| Step: 6
Training loss: 1.8793853521347046
Validation loss: 2.344005443716562

Epoch: 6| Step: 7
Training loss: 3.1579151153564453
Validation loss: 2.3483633995056152

Epoch: 6| Step: 8
Training loss: 2.3243942260742188
Validation loss: 2.344597570357784

Epoch: 6| Step: 9
Training loss: 3.08263897895813
Validation loss: 2.355185857383154

Epoch: 6| Step: 10
Training loss: 2.484774112701416
Validation loss: 2.370957971901022

Epoch: 6| Step: 11
Training loss: 2.502877712249756
Validation loss: 2.3549003293437343

Epoch: 6| Step: 12
Training loss: 2.8830037117004395
Validation loss: 2.339990528680945

Epoch: 6| Step: 13
Training loss: 2.101590394973755
Validation loss: 2.341254393259684

Epoch: 103| Step: 0
Training loss: 2.3554720878601074
Validation loss: 2.346575713926746

Epoch: 6| Step: 1
Training loss: 1.712632656097412
Validation loss: 2.3582040545760945

Epoch: 6| Step: 2
Training loss: 1.8887335062026978
Validation loss: 2.373360264685846

Epoch: 6| Step: 3
Training loss: 3.766479730606079
Validation loss: 2.39392715115701

Epoch: 6| Step: 4
Training loss: 2.5338902473449707
Validation loss: 2.3721596246124594

Epoch: 6| Step: 5
Training loss: 2.7229957580566406
Validation loss: 2.3272147588832404

Epoch: 6| Step: 6
Training loss: 2.990044593811035
Validation loss: 2.3150925559382283

Epoch: 6| Step: 7
Training loss: 2.893307685852051
Validation loss: 2.3205885835873183

Epoch: 6| Step: 8
Training loss: 1.9806864261627197
Validation loss: 2.326990765909995

Epoch: 6| Step: 9
Training loss: 2.2921061515808105
Validation loss: 2.3629263754813903

Epoch: 6| Step: 10
Training loss: 2.426016330718994
Validation loss: 2.373353209546817

Epoch: 6| Step: 11
Training loss: 2.6006417274475098
Validation loss: 2.350487096335298

Epoch: 6| Step: 12
Training loss: 2.745965003967285
Validation loss: 2.335305175473613

Epoch: 6| Step: 13
Training loss: 3.1277079582214355
Validation loss: 2.3193123238061064

Epoch: 104| Step: 0
Training loss: 2.6788644790649414
Validation loss: 2.3082697083873134

Epoch: 6| Step: 1
Training loss: 2.7397689819335938
Validation loss: 2.2927754771324897

Epoch: 6| Step: 2
Training loss: 2.8701038360595703
Validation loss: 2.2706218778446154

Epoch: 6| Step: 3
Training loss: 2.4713921546936035
Validation loss: 2.2541749067203973

Epoch: 6| Step: 4
Training loss: 1.6182336807250977
Validation loss: 2.246432068527386

Epoch: 6| Step: 5
Training loss: 2.1963839530944824
Validation loss: 2.2261424077454435

Epoch: 6| Step: 6
Training loss: 2.7789721488952637
Validation loss: 2.222149283655228

Epoch: 6| Step: 7
Training loss: 1.8652024269104004
Validation loss: 2.2264913410268803

Epoch: 6| Step: 8
Training loss: 2.585340738296509
Validation loss: 2.2308189510017313

Epoch: 6| Step: 9
Training loss: 2.726174831390381
Validation loss: 2.2331813971201577

Epoch: 6| Step: 10
Training loss: 3.2498157024383545
Validation loss: 2.2467887657944874

Epoch: 6| Step: 11
Training loss: 2.197650909423828
Validation loss: 2.258154866515949

Epoch: 6| Step: 12
Training loss: 3.016871452331543
Validation loss: 2.2680294770066456

Epoch: 6| Step: 13
Training loss: 2.0727813243865967
Validation loss: 2.2985649890797113

Epoch: 105| Step: 0
Training loss: 2.7277672290802
Validation loss: 2.3084974032576366

Epoch: 6| Step: 1
Training loss: 2.6523308753967285
Validation loss: 2.34393508203568

Epoch: 6| Step: 2
Training loss: 2.455155372619629
Validation loss: 2.4249603799594346

Epoch: 6| Step: 3
Training loss: 2.607229471206665
Validation loss: 2.4650849885838007

Epoch: 6| Step: 4
Training loss: 2.705859661102295
Validation loss: 2.491114088284072

Epoch: 6| Step: 5
Training loss: 2.204150676727295
Validation loss: 2.4438585542863414

Epoch: 6| Step: 6
Training loss: 2.5114893913269043
Validation loss: 2.391189629031766

Epoch: 6| Step: 7
Training loss: 2.5560057163238525
Validation loss: 2.3236271847960768

Epoch: 6| Step: 8
Training loss: 2.3855059146881104
Validation loss: 2.263146654252083

Epoch: 6| Step: 9
Training loss: 3.415337324142456
Validation loss: 2.2299622412650817

Epoch: 6| Step: 10
Training loss: 1.8750381469726562
Validation loss: 2.2054928887274956

Epoch: 6| Step: 11
Training loss: 2.2824623584747314
Validation loss: 2.1981127185206257

Epoch: 6| Step: 12
Training loss: 2.284609079360962
Validation loss: 2.196257424610917

Epoch: 6| Step: 13
Training loss: 2.8935649394989014
Validation loss: 2.201875314917616

Epoch: 106| Step: 0
Training loss: 2.9218616485595703
Validation loss: 2.2055104240294425

Epoch: 6| Step: 1
Training loss: 2.6279468536376953
Validation loss: 2.200968162987822

Epoch: 6| Step: 2
Training loss: 2.4039411544799805
Validation loss: 2.1970396990417154

Epoch: 6| Step: 3
Training loss: 2.2608766555786133
Validation loss: 2.198025534229894

Epoch: 6| Step: 4
Training loss: 2.0384700298309326
Validation loss: 2.200869852496732

Epoch: 6| Step: 5
Training loss: 2.2659778594970703
Validation loss: 2.2114014343548845

Epoch: 6| Step: 6
Training loss: 2.203094482421875
Validation loss: 2.2189103275217037

Epoch: 6| Step: 7
Training loss: 2.42130970954895
Validation loss: 2.2312283080111266

Epoch: 6| Step: 8
Training loss: 2.3432421684265137
Validation loss: 2.2765950566978863

Epoch: 6| Step: 9
Training loss: 2.3696603775024414
Validation loss: 2.2991755111243135

Epoch: 6| Step: 10
Training loss: 3.1126394271850586
Validation loss: 2.2942795984206663

Epoch: 6| Step: 11
Training loss: 2.9801225662231445
Validation loss: 2.2709995110829673

Epoch: 6| Step: 12
Training loss: 2.804530382156372
Validation loss: 2.226768934598533

Epoch: 6| Step: 13
Training loss: 2.8667449951171875
Validation loss: 2.185881471121183

Epoch: 107| Step: 0
Training loss: 2.280988931655884
Validation loss: 2.182299860062138

Epoch: 6| Step: 1
Training loss: 2.815542697906494
Validation loss: 2.2046956759627148

Epoch: 6| Step: 2
Training loss: 3.2522974014282227
Validation loss: 2.2277496066144717

Epoch: 6| Step: 3
Training loss: 2.181558609008789
Validation loss: 2.2573449483481784

Epoch: 6| Step: 4
Training loss: 2.2109127044677734
Validation loss: 2.2605964855481218

Epoch: 6| Step: 5
Training loss: 2.172996759414673
Validation loss: 2.2601433902658443

Epoch: 6| Step: 6
Training loss: 2.7384719848632812
Validation loss: 2.2363439247172368

Epoch: 6| Step: 7
Training loss: 2.2930245399475098
Validation loss: 2.2198645812208935

Epoch: 6| Step: 8
Training loss: 2.400449752807617
Validation loss: 2.2133259773254395

Epoch: 6| Step: 9
Training loss: 3.042051315307617
Validation loss: 2.221592221208798

Epoch: 6| Step: 10
Training loss: 2.7803611755371094
Validation loss: 2.220104927657753

Epoch: 6| Step: 11
Training loss: 2.435649871826172
Validation loss: 2.242404091742731

Epoch: 6| Step: 12
Training loss: 2.0226993560791016
Validation loss: 2.2984879965423257

Epoch: 6| Step: 13
Training loss: 3.4512879848480225
Validation loss: 2.3140311446241153

Epoch: 108| Step: 0
Training loss: 2.7703561782836914
Validation loss: 2.3032465237443165

Epoch: 6| Step: 1
Training loss: 1.8532724380493164
Validation loss: 2.2504471143086753

Epoch: 6| Step: 2
Training loss: 2.9900546073913574
Validation loss: 2.2242684992410804

Epoch: 6| Step: 3
Training loss: 1.8954211473464966
Validation loss: 2.220382490465718

Epoch: 6| Step: 4
Training loss: 2.6515867710113525
Validation loss: 2.198556823115195

Epoch: 6| Step: 5
Training loss: 1.7425086498260498
Validation loss: 2.2097718331121627

Epoch: 6| Step: 6
Training loss: 2.616431951522827
Validation loss: 2.2406068284024476

Epoch: 6| Step: 7
Training loss: 3.0512237548828125
Validation loss: 2.248106389917353

Epoch: 6| Step: 8
Training loss: 2.6304171085357666
Validation loss: 2.2727991739908853

Epoch: 6| Step: 9
Training loss: 2.4397165775299072
Validation loss: 2.261138918579266

Epoch: 6| Step: 10
Training loss: 2.473890781402588
Validation loss: 2.2347343147441907

Epoch: 6| Step: 11
Training loss: 2.5890822410583496
Validation loss: 2.225378849173105

Epoch: 6| Step: 12
Training loss: 2.791464328765869
Validation loss: 2.2076043287913003

Epoch: 6| Step: 13
Training loss: 2.7161736488342285
Validation loss: 2.210462902181892

Epoch: 109| Step: 0
Training loss: 2.695005416870117
Validation loss: 2.198344122978949

Epoch: 6| Step: 1
Training loss: 2.5130178928375244
Validation loss: 2.2017773761544177

Epoch: 6| Step: 2
Training loss: 2.4075536727905273
Validation loss: 2.1931178146792996

Epoch: 6| Step: 3
Training loss: 2.871457576751709
Validation loss: 2.1885050086564917

Epoch: 6| Step: 4
Training loss: 2.780460834503174
Validation loss: 2.1874741815751597

Epoch: 6| Step: 5
Training loss: 2.0710971355438232
Validation loss: 2.194121089032901

Epoch: 6| Step: 6
Training loss: 2.598606586456299
Validation loss: 2.191983945908085

Epoch: 6| Step: 7
Training loss: 2.1788339614868164
Validation loss: 2.1942384768557806

Epoch: 6| Step: 8
Training loss: 3.007996082305908
Validation loss: 2.206452590163036

Epoch: 6| Step: 9
Training loss: 2.4740519523620605
Validation loss: 2.260337837280766

Epoch: 6| Step: 10
Training loss: 2.5955920219421387
Validation loss: 2.269288174567684

Epoch: 6| Step: 11
Training loss: 1.7891578674316406
Validation loss: 2.2698846914434947

Epoch: 6| Step: 12
Training loss: 2.5088605880737305
Validation loss: 2.246435530724064

Epoch: 6| Step: 13
Training loss: 2.488162040710449
Validation loss: 2.234646107560845

Epoch: 110| Step: 0
Training loss: 2.779573440551758
Validation loss: 2.235386440830846

Epoch: 6| Step: 1
Training loss: 2.226320266723633
Validation loss: 2.2106072992406864

Epoch: 6| Step: 2
Training loss: 3.051811695098877
Validation loss: 2.189931672106507

Epoch: 6| Step: 3
Training loss: 3.2700133323669434
Validation loss: 2.1789432648689515

Epoch: 6| Step: 4
Training loss: 2.122560501098633
Validation loss: 2.1718207482368714

Epoch: 6| Step: 5
Training loss: 2.058602809906006
Validation loss: 2.1641781342926847

Epoch: 6| Step: 6
Training loss: 2.812286376953125
Validation loss: 2.158886214738251

Epoch: 6| Step: 7
Training loss: 2.8208236694335938
Validation loss: 2.157261607467487

Epoch: 6| Step: 8
Training loss: 2.2699661254882812
Validation loss: 2.1550801159233175

Epoch: 6| Step: 9
Training loss: 2.3944308757781982
Validation loss: 2.163400588497039

Epoch: 6| Step: 10
Training loss: 2.6899681091308594
Validation loss: 2.1668541098153717

Epoch: 6| Step: 11
Training loss: 2.2154903411865234
Validation loss: 2.169325708061136

Epoch: 6| Step: 12
Training loss: 1.9490175247192383
Validation loss: 2.175615072250366

Epoch: 6| Step: 13
Training loss: 1.6775579452514648
Validation loss: 2.1842581354161745

Epoch: 111| Step: 0
Training loss: 2.377645969390869
Validation loss: 2.182162456614997

Epoch: 6| Step: 1
Training loss: 2.423074245452881
Validation loss: 2.18102805460653

Epoch: 6| Step: 2
Training loss: 2.9929592609405518
Validation loss: 2.171159928844821

Epoch: 6| Step: 3
Training loss: 2.664691686630249
Validation loss: 2.1677071279095066

Epoch: 6| Step: 4
Training loss: 2.0604474544525146
Validation loss: 2.1620260284792994

Epoch: 6| Step: 5
Training loss: 2.327023506164551
Validation loss: 2.1710372868404595

Epoch: 6| Step: 6
Training loss: 3.305305004119873
Validation loss: 2.2021060900021623

Epoch: 6| Step: 7
Training loss: 2.5656790733337402
Validation loss: 2.217804278096845

Epoch: 6| Step: 8
Training loss: 3.0351738929748535
Validation loss: 2.2295085307090514

Epoch: 6| Step: 9
Training loss: 2.7335498332977295
Validation loss: 2.2361672898774505

Epoch: 6| Step: 10
Training loss: 2.3612568378448486
Validation loss: 2.2132696464497554

Epoch: 6| Step: 11
Training loss: 1.318339467048645
Validation loss: 2.190711000914215

Epoch: 6| Step: 12
Training loss: 1.9584438800811768
Validation loss: 2.1698475576216176

Epoch: 6| Step: 13
Training loss: 2.3325066566467285
Validation loss: 2.1618167713124263

Epoch: 112| Step: 0
Training loss: 2.6543850898742676
Validation loss: 2.155677239100138

Epoch: 6| Step: 1
Training loss: 2.3455967903137207
Validation loss: 2.1491395645244147

Epoch: 6| Step: 2
Training loss: 2.629814624786377
Validation loss: 2.1459494457449964

Epoch: 6| Step: 3
Training loss: 2.3077311515808105
Validation loss: 2.14868607828694

Epoch: 6| Step: 4
Training loss: 2.989420175552368
Validation loss: 2.146872739638052

Epoch: 6| Step: 5
Training loss: 2.3698782920837402
Validation loss: 2.141345049745293

Epoch: 6| Step: 6
Training loss: 1.959795355796814
Validation loss: 2.1423436851911646

Epoch: 6| Step: 7
Training loss: 2.187723159790039
Validation loss: 2.1463860901453162

Epoch: 6| Step: 8
Training loss: 3.0981664657592773
Validation loss: 2.155825006064548

Epoch: 6| Step: 9
Training loss: 2.4484684467315674
Validation loss: 2.1782011575596307

Epoch: 6| Step: 10
Training loss: 2.5456929206848145
Validation loss: 2.1652313176021782

Epoch: 6| Step: 11
Training loss: 2.197089672088623
Validation loss: 2.1684609049110004

Epoch: 6| Step: 12
Training loss: 2.5851621627807617
Validation loss: 2.156343972811135

Epoch: 6| Step: 13
Training loss: 2.009251594543457
Validation loss: 2.166222405690019

Epoch: 113| Step: 0
Training loss: 2.213744878768921
Validation loss: 2.1828992007881083

Epoch: 6| Step: 1
Training loss: 1.9052252769470215
Validation loss: 2.2246621834334506

Epoch: 6| Step: 2
Training loss: 2.5154519081115723
Validation loss: 2.2921551940261677

Epoch: 6| Step: 3
Training loss: 2.6572961807250977
Validation loss: 2.3154170436243855

Epoch: 6| Step: 4
Training loss: 2.4579336643218994
Validation loss: 2.3275165147678827

Epoch: 6| Step: 5
Training loss: 2.229581117630005
Validation loss: 2.277238756097773

Epoch: 6| Step: 6
Training loss: 2.4130477905273438
Validation loss: 2.2287506595734627

Epoch: 6| Step: 7
Training loss: 1.5136789083480835
Validation loss: 2.1826280137544036

Epoch: 6| Step: 8
Training loss: 2.4821529388427734
Validation loss: 2.1588586043286067

Epoch: 6| Step: 9
Training loss: 2.6699416637420654
Validation loss: 2.142819607129661

Epoch: 6| Step: 10
Training loss: 2.8218181133270264
Validation loss: 2.1358327045235583

Epoch: 6| Step: 11
Training loss: 3.185366153717041
Validation loss: 2.1286183736657582

Epoch: 6| Step: 12
Training loss: 2.9809184074401855
Validation loss: 2.1316755253781556

Epoch: 6| Step: 13
Training loss: 2.8614325523376465
Validation loss: 2.1279184510630946

Epoch: 114| Step: 0
Training loss: 3.0146360397338867
Validation loss: 2.1310473718950824

Epoch: 6| Step: 1
Training loss: 2.771298408508301
Validation loss: 2.1261501055891796

Epoch: 6| Step: 2
Training loss: 2.9345405101776123
Validation loss: 2.1281123520225607

Epoch: 6| Step: 3
Training loss: 2.4169464111328125
Validation loss: 2.132154351921492

Epoch: 6| Step: 4
Training loss: 2.5642051696777344
Validation loss: 2.1448495388031006

Epoch: 6| Step: 5
Training loss: 2.245260000228882
Validation loss: 2.1371583348961285

Epoch: 6| Step: 6
Training loss: 1.7759196758270264
Validation loss: 2.148885473128288

Epoch: 6| Step: 7
Training loss: 2.669985294342041
Validation loss: 2.164657210790983

Epoch: 6| Step: 8
Training loss: 2.472637891769409
Validation loss: 2.175493901775729

Epoch: 6| Step: 9
Training loss: 2.663332939147949
Validation loss: 2.199983476310648

Epoch: 6| Step: 10
Training loss: 2.6235744953155518
Validation loss: 2.1888458459608016

Epoch: 6| Step: 11
Training loss: 1.7375434637069702
Validation loss: 2.1783416271209717

Epoch: 6| Step: 12
Training loss: 2.025758743286133
Validation loss: 2.17094559566949

Epoch: 6| Step: 13
Training loss: 2.1120288372039795
Validation loss: 2.1536942066684848

Epoch: 115| Step: 0
Training loss: 2.419135093688965
Validation loss: 2.156848112742106

Epoch: 6| Step: 1
Training loss: 2.2290425300598145
Validation loss: 2.1506253250183596

Epoch: 6| Step: 2
Training loss: 1.947591781616211
Validation loss: 2.151877357113746

Epoch: 6| Step: 3
Training loss: 2.375976085662842
Validation loss: 2.1593253099790184

Epoch: 6| Step: 4
Training loss: 2.782811164855957
Validation loss: 2.165440715769286

Epoch: 6| Step: 5
Training loss: 2.542300224304199
Validation loss: 2.1874635014482724

Epoch: 6| Step: 6
Training loss: 2.0232930183410645
Validation loss: 2.208882103684128

Epoch: 6| Step: 7
Training loss: 2.071613311767578
Validation loss: 2.226686954498291

Epoch: 6| Step: 8
Training loss: 3.584071159362793
Validation loss: 2.247478190288749

Epoch: 6| Step: 9
Training loss: 3.030979871749878
Validation loss: 2.2634875056564168

Epoch: 6| Step: 10
Training loss: 2.716355562210083
Validation loss: 2.2626763184865317

Epoch: 6| Step: 11
Training loss: 1.7699450254440308
Validation loss: 2.2316111057035384

Epoch: 6| Step: 12
Training loss: 2.1866660118103027
Validation loss: 2.2071723989261094

Epoch: 6| Step: 13
Training loss: 2.220770835876465
Validation loss: 2.1544329786813385

Epoch: 116| Step: 0
Training loss: 3.1974542140960693
Validation loss: 2.133527030227005

Epoch: 6| Step: 1
Training loss: 2.254091501235962
Validation loss: 2.132083882567703

Epoch: 6| Step: 2
Training loss: 2.5296716690063477
Validation loss: 2.1441944491478706

Epoch: 6| Step: 3
Training loss: 1.8306255340576172
Validation loss: 2.1410575848753735

Epoch: 6| Step: 4
Training loss: 2.6685824394226074
Validation loss: 2.1293451734768447

Epoch: 6| Step: 5
Training loss: 1.9804308414459229
Validation loss: 2.125305493672689

Epoch: 6| Step: 6
Training loss: 2.5467474460601807
Validation loss: 2.1170054686966764

Epoch: 6| Step: 7
Training loss: 3.0694706439971924
Validation loss: 2.111124692424651

Epoch: 6| Step: 8
Training loss: 2.562304973602295
Validation loss: 2.1183389771369194

Epoch: 6| Step: 9
Training loss: 2.119128704071045
Validation loss: 2.128602594457647

Epoch: 6| Step: 10
Training loss: 2.4305548667907715
Validation loss: 2.138850153133433

Epoch: 6| Step: 11
Training loss: 2.435124397277832
Validation loss: 2.1455098967398367

Epoch: 6| Step: 12
Training loss: 2.5068414211273193
Validation loss: 2.1681583363522767

Epoch: 6| Step: 13
Training loss: 2.1487374305725098
Validation loss: 2.2001648000491563

Epoch: 117| Step: 0
Training loss: 2.3949167728424072
Validation loss: 2.214880689497917

Epoch: 6| Step: 1
Training loss: 2.7584190368652344
Validation loss: 2.1966363101877193

Epoch: 6| Step: 2
Training loss: 2.9133987426757812
Validation loss: 2.176107257925054

Epoch: 6| Step: 3
Training loss: 2.5367372035980225
Validation loss: 2.1473495601325907

Epoch: 6| Step: 4
Training loss: 2.8524603843688965
Validation loss: 2.1398055220162995

Epoch: 6| Step: 5
Training loss: 2.3989615440368652
Validation loss: 2.138047433668567

Epoch: 6| Step: 6
Training loss: 2.448864698410034
Validation loss: 2.132293644771781

Epoch: 6| Step: 7
Training loss: 1.9680187702178955
Validation loss: 2.135111685722105

Epoch: 6| Step: 8
Training loss: 1.8910223245620728
Validation loss: 2.130230934389176

Epoch: 6| Step: 9
Training loss: 2.5211403369903564
Validation loss: 2.13698217432986

Epoch: 6| Step: 10
Training loss: 2.3000974655151367
Validation loss: 2.142420297027916

Epoch: 6| Step: 11
Training loss: 1.647296667098999
Validation loss: 2.1498882821811143

Epoch: 6| Step: 12
Training loss: 2.454120635986328
Validation loss: 2.164213518942556

Epoch: 6| Step: 13
Training loss: 3.236738920211792
Validation loss: 2.1723342467379827

Epoch: 118| Step: 0
Training loss: 2.61539888381958
Validation loss: 2.20090651512146

Epoch: 6| Step: 1
Training loss: 2.497638702392578
Validation loss: 2.239794779849309

Epoch: 6| Step: 2
Training loss: 2.941725730895996
Validation loss: 2.253402053668935

Epoch: 6| Step: 3
Training loss: 2.4332900047302246
Validation loss: 2.274357108659642

Epoch: 6| Step: 4
Training loss: 2.326399087905884
Validation loss: 2.2748974318145425

Epoch: 6| Step: 5
Training loss: 2.6083984375
Validation loss: 2.2721107313709874

Epoch: 6| Step: 6
Training loss: 2.1097397804260254
Validation loss: 2.2842806616137104

Epoch: 6| Step: 7
Training loss: 2.280569314956665
Validation loss: 2.2694386615548083

Epoch: 6| Step: 8
Training loss: 1.799300193786621
Validation loss: 2.2645842900840183

Epoch: 6| Step: 9
Training loss: 2.1996779441833496
Validation loss: 2.2626444370515886

Epoch: 6| Step: 10
Training loss: 2.799868583679199
Validation loss: 2.2380290954343733

Epoch: 6| Step: 11
Training loss: 2.8560523986816406
Validation loss: 2.2169058348542903

Epoch: 6| Step: 12
Training loss: 2.680502414703369
Validation loss: 2.1828951886905137

Epoch: 6| Step: 13
Training loss: 1.367595911026001
Validation loss: 2.1607726594453216

Epoch: 119| Step: 0
Training loss: 2.574276924133301
Validation loss: 2.155312661201723

Epoch: 6| Step: 1
Training loss: 2.042774200439453
Validation loss: 2.14152447126245

Epoch: 6| Step: 2
Training loss: 2.850853204727173
Validation loss: 2.1381593583732523

Epoch: 6| Step: 3
Training loss: 2.2613487243652344
Validation loss: 2.137712554265094

Epoch: 6| Step: 4
Training loss: 2.3583972454071045
Validation loss: 2.125202222536969

Epoch: 6| Step: 5
Training loss: 2.7141225337982178
Validation loss: 2.119488089315353

Epoch: 6| Step: 6
Training loss: 2.4698171615600586
Validation loss: 2.1113083542034192

Epoch: 6| Step: 7
Training loss: 1.4412827491760254
Validation loss: 2.1123959056792723

Epoch: 6| Step: 8
Training loss: 1.9101736545562744
Validation loss: 2.111335708249

Epoch: 6| Step: 9
Training loss: 3.3748111724853516
Validation loss: 2.1078647682743687

Epoch: 6| Step: 10
Training loss: 2.583615303039551
Validation loss: 2.108899724098944

Epoch: 6| Step: 11
Training loss: 2.3611645698547363
Validation loss: 2.107565426057385

Epoch: 6| Step: 12
Training loss: 2.2964537143707275
Validation loss: 2.112211524799306

Epoch: 6| Step: 13
Training loss: 2.0879361629486084
Validation loss: 2.125046246795244

Epoch: 120| Step: 0
Training loss: 3.033315896987915
Validation loss: 2.1223141647154287

Epoch: 6| Step: 1
Training loss: 2.634232521057129
Validation loss: 2.132601717466949

Epoch: 6| Step: 2
Training loss: 2.0687248706817627
Validation loss: 2.144032327077722

Epoch: 6| Step: 3
Training loss: 2.047891616821289
Validation loss: 2.136250809956622

Epoch: 6| Step: 4
Training loss: 2.3952810764312744
Validation loss: 2.113116566852857

Epoch: 6| Step: 5
Training loss: 2.787632942199707
Validation loss: 2.106514528233518

Epoch: 6| Step: 6
Training loss: 2.11554217338562
Validation loss: 2.104916439261488

Epoch: 6| Step: 7
Training loss: 2.0444858074188232
Validation loss: 2.104902978866331

Epoch: 6| Step: 8
Training loss: 2.464378595352173
Validation loss: 2.1162193949504564

Epoch: 6| Step: 9
Training loss: 2.290621757507324
Validation loss: 2.118079564904654

Epoch: 6| Step: 10
Training loss: 2.7090792655944824
Validation loss: 2.124710754681659

Epoch: 6| Step: 11
Training loss: 2.674539089202881
Validation loss: 2.124792762981948

Epoch: 6| Step: 12
Training loss: 1.9521431922912598
Validation loss: 2.1205080042603197

Epoch: 6| Step: 13
Training loss: 1.8326045274734497
Validation loss: 2.1141758913634927

Epoch: 121| Step: 0
Training loss: 2.519124746322632
Validation loss: 2.1146039244949177

Epoch: 6| Step: 1
Training loss: 2.295154571533203
Validation loss: 2.1164066560806765

Epoch: 6| Step: 2
Training loss: 2.2325797080993652
Validation loss: 2.107961013752927

Epoch: 6| Step: 3
Training loss: 1.9951350688934326
Validation loss: 2.1178782832237983

Epoch: 6| Step: 4
Training loss: 2.1211347579956055
Validation loss: 2.1248919822836436

Epoch: 6| Step: 5
Training loss: 2.7441558837890625
Validation loss: 2.1444506670839045

Epoch: 6| Step: 6
Training loss: 2.2571170330047607
Validation loss: 2.156258935569435

Epoch: 6| Step: 7
Training loss: 1.8563108444213867
Validation loss: 2.1627430531286422

Epoch: 6| Step: 8
Training loss: 2.3464951515197754
Validation loss: 2.1538102742164367

Epoch: 6| Step: 9
Training loss: 2.694812297821045
Validation loss: 2.127118565702951

Epoch: 6| Step: 10
Training loss: 2.1829988956451416
Validation loss: 2.111273870673231

Epoch: 6| Step: 11
Training loss: 2.1348824501037598
Validation loss: 2.1038079107961347

Epoch: 6| Step: 12
Training loss: 3.2111010551452637
Validation loss: 2.102810437961291

Epoch: 6| Step: 13
Training loss: 2.758774757385254
Validation loss: 2.1127564189254597

Epoch: 122| Step: 0
Training loss: 2.2774155139923096
Validation loss: 2.1083199183146157

Epoch: 6| Step: 1
Training loss: 2.4236812591552734
Validation loss: 2.1122953353389615

Epoch: 6| Step: 2
Training loss: 2.4382400512695312
Validation loss: 2.108795004506265

Epoch: 6| Step: 3
Training loss: 2.3896517753601074
Validation loss: 2.1134151989413845

Epoch: 6| Step: 4
Training loss: 2.5546703338623047
Validation loss: 2.128297544294788

Epoch: 6| Step: 5
Training loss: 2.049039602279663
Validation loss: 2.1249772528166413

Epoch: 6| Step: 6
Training loss: 2.751495838165283
Validation loss: 2.125647116732854

Epoch: 6| Step: 7
Training loss: 2.3792943954467773
Validation loss: 2.1207784824473883

Epoch: 6| Step: 8
Training loss: 2.410979986190796
Validation loss: 2.10797950272919

Epoch: 6| Step: 9
Training loss: 1.9857369661331177
Validation loss: 2.1029546632561633

Epoch: 6| Step: 10
Training loss: 2.8195276260375977
Validation loss: 2.0972957867448048

Epoch: 6| Step: 11
Training loss: 2.0423905849456787
Validation loss: 2.0969807794017177

Epoch: 6| Step: 12
Training loss: 2.246427536010742
Validation loss: 2.099153777604462

Epoch: 6| Step: 13
Training loss: 2.377567768096924
Validation loss: 2.104676213315738

Epoch: 123| Step: 0
Training loss: 2.593621015548706
Validation loss: 2.112040532532559

Epoch: 6| Step: 1
Training loss: 2.217374801635742
Validation loss: 2.1225452384641095

Epoch: 6| Step: 2
Training loss: 2.3762269020080566
Validation loss: 2.126117810126274

Epoch: 6| Step: 3
Training loss: 1.7233893871307373
Validation loss: 2.1176773322525846

Epoch: 6| Step: 4
Training loss: 1.9928067922592163
Validation loss: 2.1180659981184107

Epoch: 6| Step: 5
Training loss: 2.7874693870544434
Validation loss: 2.127970172512916

Epoch: 6| Step: 6
Training loss: 3.039515256881714
Validation loss: 2.124498946692354

Epoch: 6| Step: 7
Training loss: 2.002981662750244
Validation loss: 2.127101707202132

Epoch: 6| Step: 8
Training loss: 2.41105318069458
Validation loss: 2.129061006730603

Epoch: 6| Step: 9
Training loss: 2.63285231590271
Validation loss: 2.1162553961559007

Epoch: 6| Step: 10
Training loss: 2.6877307891845703
Validation loss: 2.1172421645092707

Epoch: 6| Step: 11
Training loss: 2.7595021724700928
Validation loss: 2.1126490434010825

Epoch: 6| Step: 12
Training loss: 1.9008907079696655
Validation loss: 2.1007594690527966

Epoch: 6| Step: 13
Training loss: 1.3070942163467407
Validation loss: 2.1041775531666254

Epoch: 124| Step: 0
Training loss: 2.443578004837036
Validation loss: 2.1047179365670807

Epoch: 6| Step: 1
Training loss: 2.135993003845215
Validation loss: 2.1150342918211416

Epoch: 6| Step: 2
Training loss: 2.240851402282715
Validation loss: 2.1223240411409767

Epoch: 6| Step: 3
Training loss: 2.4786617755889893
Validation loss: 2.1269027058796217

Epoch: 6| Step: 4
Training loss: 2.1256704330444336
Validation loss: 2.127997858549959

Epoch: 6| Step: 5
Training loss: 2.7147252559661865
Validation loss: 2.1267623773185154

Epoch: 6| Step: 6
Training loss: 1.4854986667633057
Validation loss: 2.1183015249108754

Epoch: 6| Step: 7
Training loss: 2.6929094791412354
Validation loss: 2.114349083233905

Epoch: 6| Step: 8
Training loss: 2.769296884536743
Validation loss: 2.1220037680800243

Epoch: 6| Step: 9
Training loss: 2.595601797103882
Validation loss: 2.1229353873960433

Epoch: 6| Step: 10
Training loss: 2.586237668991089
Validation loss: 2.1276318668037333

Epoch: 6| Step: 11
Training loss: 1.7531511783599854
Validation loss: 2.1252150458674275

Epoch: 6| Step: 12
Training loss: 2.166646957397461
Validation loss: 2.123484229528776

Epoch: 6| Step: 13
Training loss: 2.825211763381958
Validation loss: 2.13377603279647

Epoch: 125| Step: 0
Training loss: 2.6746058464050293
Validation loss: 2.1583653547430552

Epoch: 6| Step: 1
Training loss: 2.37393856048584
Validation loss: 2.1558562901712235

Epoch: 6| Step: 2
Training loss: 1.9421744346618652
Validation loss: 2.178299198868454

Epoch: 6| Step: 3
Training loss: 3.57789945602417
Validation loss: 2.188615106767224

Epoch: 6| Step: 4
Training loss: 2.485722541809082
Validation loss: 2.179042452125139

Epoch: 6| Step: 5
Training loss: 2.4452524185180664
Validation loss: 2.156123540734732

Epoch: 6| Step: 6
Training loss: 2.326706647872925
Validation loss: 2.128280467884515

Epoch: 6| Step: 7
Training loss: 2.308289051055908
Validation loss: 2.123555915330046

Epoch: 6| Step: 8
Training loss: 2.096156120300293
Validation loss: 2.1283875665357037

Epoch: 6| Step: 9
Training loss: 2.2958638668060303
Validation loss: 2.118559149003798

Epoch: 6| Step: 10
Training loss: 1.3987975120544434
Validation loss: 2.11468864897246

Epoch: 6| Step: 11
Training loss: 2.216850757598877
Validation loss: 2.1141590687536422

Epoch: 6| Step: 12
Training loss: 2.7309422492980957
Validation loss: 2.1076515515645347

Epoch: 6| Step: 13
Training loss: 1.972679615020752
Validation loss: 2.120824545942327

Testing loss: 2.352274364895291
