Epoch: 1| Step: 0
Training loss: 4.409863471984863
Validation loss: 5.2347359913651665

Epoch: 6| Step: 1
Training loss: 5.324506759643555
Validation loss: 5.21900725108321

Epoch: 6| Step: 2
Training loss: 6.0748491287231445
Validation loss: 5.203327824992519

Epoch: 6| Step: 3
Training loss: 5.592936038970947
Validation loss: 5.184503960353072

Epoch: 6| Step: 4
Training loss: 4.097113609313965
Validation loss: 5.1619799008933445

Epoch: 6| Step: 5
Training loss: 4.737245559692383
Validation loss: 5.136158445829986

Epoch: 6| Step: 6
Training loss: 4.724963188171387
Validation loss: 5.107283499933058

Epoch: 6| Step: 7
Training loss: 4.879179000854492
Validation loss: 5.0738498369852705

Epoch: 6| Step: 8
Training loss: 5.539677619934082
Validation loss: 5.036523757442351

Epoch: 6| Step: 9
Training loss: 3.9454240798950195
Validation loss: 4.996516125176543

Epoch: 6| Step: 10
Training loss: 4.676126956939697
Validation loss: 4.950926288481681

Epoch: 6| Step: 11
Training loss: 5.398820877075195
Validation loss: 4.901327046014929

Epoch: 6| Step: 12
Training loss: 4.295374870300293
Validation loss: 4.8463264383295535

Epoch: 6| Step: 13
Training loss: 3.8297576904296875
Validation loss: 4.7897674909202

Epoch: 2| Step: 0
Training loss: 3.2870912551879883
Validation loss: 4.728882564011441

Epoch: 6| Step: 1
Training loss: 4.635467529296875
Validation loss: 4.666502578284151

Epoch: 6| Step: 2
Training loss: 4.560086727142334
Validation loss: 4.603131827487741

Epoch: 6| Step: 3
Training loss: 4.951801300048828
Validation loss: 4.5389423011451635

Epoch: 6| Step: 4
Training loss: 4.3233819007873535
Validation loss: 4.472429065294163

Epoch: 6| Step: 5
Training loss: 4.304929733276367
Validation loss: 4.4037112984606015

Epoch: 6| Step: 6
Training loss: 3.9550607204437256
Validation loss: 4.334164096463111

Epoch: 6| Step: 7
Training loss: 4.148419380187988
Validation loss: 4.2665903722086265

Epoch: 6| Step: 8
Training loss: 3.4432146549224854
Validation loss: 4.1988167608937905

Epoch: 6| Step: 9
Training loss: 4.212364196777344
Validation loss: 4.128273804982503

Epoch: 6| Step: 10
Training loss: 4.9233551025390625
Validation loss: 4.055092119401501

Epoch: 6| Step: 11
Training loss: 2.7872812747955322
Validation loss: 3.9787034937130508

Epoch: 6| Step: 12
Training loss: 4.313348293304443
Validation loss: 3.9189637578943723

Epoch: 6| Step: 13
Training loss: 3.7106568813323975
Validation loss: 3.8655985478431947

Epoch: 3| Step: 0
Training loss: 2.892751693725586
Validation loss: 3.8160511985901864

Epoch: 6| Step: 1
Training loss: 3.286656141281128
Validation loss: 3.7703315134971374

Epoch: 6| Step: 2
Training loss: 3.6656484603881836
Validation loss: 3.7237104139020367

Epoch: 6| Step: 3
Training loss: 3.1052942276000977
Validation loss: 3.6784181851212696

Epoch: 6| Step: 4
Training loss: 4.430907249450684
Validation loss: 3.6359124388746036

Epoch: 6| Step: 5
Training loss: 3.058469295501709
Validation loss: 3.604090375284995

Epoch: 6| Step: 6
Training loss: 4.404858589172363
Validation loss: 3.573221932175339

Epoch: 6| Step: 7
Training loss: 3.568277597427368
Validation loss: 3.539646997246691

Epoch: 6| Step: 8
Training loss: 3.320342540740967
Validation loss: 3.5132995907978346

Epoch: 6| Step: 9
Training loss: 2.754861831665039
Validation loss: 3.4917662118070867

Epoch: 6| Step: 10
Training loss: 3.1801137924194336
Validation loss: 3.4785082801695792

Epoch: 6| Step: 11
Training loss: 3.7133123874664307
Validation loss: 3.45900143859207

Epoch: 6| Step: 12
Training loss: 4.039007663726807
Validation loss: 3.430546009412376

Epoch: 6| Step: 13
Training loss: 3.4696972370147705
Validation loss: 3.40144323020853

Epoch: 4| Step: 0
Training loss: 3.8177168369293213
Validation loss: 3.3785640475570515

Epoch: 6| Step: 1
Training loss: 3.611476421356201
Validation loss: 3.3538041422444005

Epoch: 6| Step: 2
Training loss: 2.5950424671173096
Validation loss: 3.336273854778659

Epoch: 6| Step: 3
Training loss: 2.783883571624756
Validation loss: 3.315002223496796

Epoch: 6| Step: 4
Training loss: 2.9912986755371094
Validation loss: 3.2997792510576147

Epoch: 6| Step: 5
Training loss: 4.0810441970825195
Validation loss: 3.3114750744194112

Epoch: 6| Step: 6
Training loss: 3.8346152305603027
Validation loss: 3.303119562005484

Epoch: 6| Step: 7
Training loss: 4.2098541259765625
Validation loss: 3.255070988849927

Epoch: 6| Step: 8
Training loss: 2.4711179733276367
Validation loss: 3.2445298958850164

Epoch: 6| Step: 9
Training loss: 2.9147119522094727
Validation loss: 3.2391947777040544

Epoch: 6| Step: 10
Training loss: 3.0642995834350586
Validation loss: 3.2203572104054112

Epoch: 6| Step: 11
Training loss: 2.5865516662597656
Validation loss: 3.194924621171849

Epoch: 6| Step: 12
Training loss: 3.9692039489746094
Validation loss: 3.182726331936416

Epoch: 6| Step: 13
Training loss: 1.9945969581604004
Validation loss: 3.1682350789347002

Epoch: 5| Step: 0
Training loss: 3.2367992401123047
Validation loss: 3.1577331045622468

Epoch: 6| Step: 1
Training loss: 2.274705648422241
Validation loss: 3.1714194846409622

Epoch: 6| Step: 2
Training loss: 2.587996006011963
Validation loss: 3.1488441651867283

Epoch: 6| Step: 3
Training loss: 2.997976779937744
Validation loss: 3.1095554367188485

Epoch: 6| Step: 4
Training loss: 2.4082233905792236
Validation loss: 3.0993215448112896

Epoch: 6| Step: 5
Training loss: 3.511748790740967
Validation loss: 3.1336519307987665

Epoch: 6| Step: 6
Training loss: 3.048722267150879
Validation loss: 3.0906917946313017

Epoch: 6| Step: 7
Training loss: 3.952848434448242
Validation loss: 3.0738585764361965

Epoch: 6| Step: 8
Training loss: 3.80041241645813
Validation loss: 3.0872363813461794

Epoch: 6| Step: 9
Training loss: 3.706191301345825
Validation loss: 3.121908418593868

Epoch: 6| Step: 10
Training loss: 3.3172879219055176
Validation loss: 3.0927599886412263

Epoch: 6| Step: 11
Training loss: 3.0708212852478027
Validation loss: 3.049302339553833

Epoch: 6| Step: 12
Training loss: 2.9999375343322754
Validation loss: 3.064201593399048

Epoch: 6| Step: 13
Training loss: 2.88450288772583
Validation loss: 3.062247089160386

Epoch: 6| Step: 0
Training loss: 3.750857353210449
Validation loss: 3.101642729133688

Epoch: 6| Step: 1
Training loss: 2.3326821327209473
Validation loss: 3.105038822338145

Epoch: 6| Step: 2
Training loss: 3.7400221824645996
Validation loss: 3.078142814738776

Epoch: 6| Step: 3
Training loss: 2.4043736457824707
Validation loss: 3.0319754205724245

Epoch: 6| Step: 4
Training loss: 3.618293285369873
Validation loss: 3.031795673472907

Epoch: 6| Step: 5
Training loss: 2.6528072357177734
Validation loss: 3.036210116519723

Epoch: 6| Step: 6
Training loss: 3.291374444961548
Validation loss: 3.0448707662602907

Epoch: 6| Step: 7
Training loss: 3.0786960124969482
Validation loss: 3.0515520367571103

Epoch: 6| Step: 8
Training loss: 2.99088716506958
Validation loss: 3.05526896702346

Epoch: 6| Step: 9
Training loss: 3.8994264602661133
Validation loss: 3.048324946434267

Epoch: 6| Step: 10
Training loss: 2.2140848636627197
Validation loss: 3.0279476488790205

Epoch: 6| Step: 11
Training loss: 3.1183221340179443
Validation loss: 3.016770814054756

Epoch: 6| Step: 12
Training loss: 3.6756625175476074
Validation loss: 2.9893525133850756

Epoch: 6| Step: 13
Training loss: 2.255547523498535
Validation loss: 2.9628965829008367

Epoch: 7| Step: 0
Training loss: 3.9911935329437256
Validation loss: 2.945256274233582

Epoch: 6| Step: 1
Training loss: 2.6979727745056152
Validation loss: 2.9346188447808705

Epoch: 6| Step: 2
Training loss: 3.696403980255127
Validation loss: 2.939002747176796

Epoch: 6| Step: 3
Training loss: 2.8493714332580566
Validation loss: 2.934626874103341

Epoch: 6| Step: 4
Training loss: 3.0258727073669434
Validation loss: 2.924023700016801

Epoch: 6| Step: 5
Training loss: 2.99167537689209
Validation loss: 2.9091516617805726

Epoch: 6| Step: 6
Training loss: 2.2711009979248047
Validation loss: 2.9005332172557874

Epoch: 6| Step: 7
Training loss: 2.2758655548095703
Validation loss: 2.890226061626147

Epoch: 6| Step: 8
Training loss: 3.5314111709594727
Validation loss: 2.8899664391753492

Epoch: 6| Step: 9
Training loss: 3.0383949279785156
Validation loss: 2.9041305536864908

Epoch: 6| Step: 10
Training loss: 3.628091812133789
Validation loss: 2.8903340267878708

Epoch: 6| Step: 11
Training loss: 3.5747437477111816
Validation loss: 2.8709771889512257

Epoch: 6| Step: 12
Training loss: 1.9935240745544434
Validation loss: 2.861482274147772

Epoch: 6| Step: 13
Training loss: 2.1948320865631104
Validation loss: 2.8582560452081824

Epoch: 8| Step: 0
Training loss: 2.3948214054107666
Validation loss: 2.8565186377494567

Epoch: 6| Step: 1
Training loss: 2.680715560913086
Validation loss: 2.859434817426948

Epoch: 6| Step: 2
Training loss: 3.2720189094543457
Validation loss: 2.856332132893224

Epoch: 6| Step: 3
Training loss: 3.3425607681274414
Validation loss: 2.850625535493256

Epoch: 6| Step: 4
Training loss: 3.001255512237549
Validation loss: 2.8439040107111775

Epoch: 6| Step: 5
Training loss: 2.8108088970184326
Validation loss: 2.8331715189000612

Epoch: 6| Step: 6
Training loss: 3.7932868003845215
Validation loss: 2.826403087185275

Epoch: 6| Step: 7
Training loss: 2.4077789783477783
Validation loss: 2.8251326930138374

Epoch: 6| Step: 8
Training loss: 3.152869462966919
Validation loss: 2.8230231038985716

Epoch: 6| Step: 9
Training loss: 3.270341157913208
Validation loss: 2.816744166035806

Epoch: 6| Step: 10
Training loss: 2.8772225379943848
Validation loss: 2.812630594417613

Epoch: 6| Step: 11
Training loss: 2.7974298000335693
Validation loss: 2.8020434328304824

Epoch: 6| Step: 12
Training loss: 2.462690591812134
Validation loss: 2.804304607452885

Epoch: 6| Step: 13
Training loss: 3.124561309814453
Validation loss: 2.795957954980994

Epoch: 9| Step: 0
Training loss: 3.193466901779175
Validation loss: 2.7886617158048894

Epoch: 6| Step: 1
Training loss: 2.848827362060547
Validation loss: 2.787787111856604

Epoch: 6| Step: 2
Training loss: 1.8704084157943726
Validation loss: 2.779901776262509

Epoch: 6| Step: 3
Training loss: 2.5714306831359863
Validation loss: 2.77705241018726

Epoch: 6| Step: 4
Training loss: 3.2782020568847656
Validation loss: 2.775204327798659

Epoch: 6| Step: 5
Training loss: 2.693023681640625
Validation loss: 2.7716189840788483

Epoch: 6| Step: 6
Training loss: 3.808487892150879
Validation loss: 2.764954766919536

Epoch: 6| Step: 7
Training loss: 1.864744782447815
Validation loss: 2.7612738737496

Epoch: 6| Step: 8
Training loss: 3.466402769088745
Validation loss: 2.7580219045762093

Epoch: 6| Step: 9
Training loss: 3.3976550102233887
Validation loss: 2.7542824181177283

Epoch: 6| Step: 10
Training loss: 2.942840814590454
Validation loss: 2.752433720455375

Epoch: 6| Step: 11
Training loss: 3.0749640464782715
Validation loss: 2.751360195939259

Epoch: 6| Step: 12
Training loss: 2.89776349067688
Validation loss: 2.7384359990396807

Epoch: 6| Step: 13
Training loss: 2.7360589504241943
Validation loss: 2.7349314946000294

Epoch: 10| Step: 0
Training loss: 2.866161346435547
Validation loss: 2.7371325800495763

Epoch: 6| Step: 1
Training loss: 3.50252103805542
Validation loss: 2.733713811443698

Epoch: 6| Step: 2
Training loss: 2.5795421600341797
Validation loss: 2.735684423036473

Epoch: 6| Step: 3
Training loss: 3.0081992149353027
Validation loss: 2.7298128758707354

Epoch: 6| Step: 4
Training loss: 3.073923349380493
Validation loss: 2.725104944680327

Epoch: 6| Step: 5
Training loss: 3.1375184059143066
Validation loss: 2.7194625844237623

Epoch: 6| Step: 6
Training loss: 2.8674392700195312
Validation loss: 2.7140979997573362

Epoch: 6| Step: 7
Training loss: 2.319220542907715
Validation loss: 2.7073232845593522

Epoch: 6| Step: 8
Training loss: 2.619847536087036
Validation loss: 2.70591055193255

Epoch: 6| Step: 9
Training loss: 3.319490432739258
Validation loss: 2.7024955877693753

Epoch: 6| Step: 10
Training loss: 2.4037792682647705
Validation loss: 2.701011544914656

Epoch: 6| Step: 11
Training loss: 3.101712703704834
Validation loss: 2.699598079086632

Epoch: 6| Step: 12
Training loss: 2.5265822410583496
Validation loss: 2.694226793063584

Epoch: 6| Step: 13
Training loss: 3.0004191398620605
Validation loss: 2.6881734504494617

Epoch: 11| Step: 0
Training loss: 2.5256147384643555
Validation loss: 2.685522743450698

Epoch: 6| Step: 1
Training loss: 2.8533389568328857
Validation loss: 2.683288053799701

Epoch: 6| Step: 2
Training loss: 3.402543067932129
Validation loss: 2.6789132266916256

Epoch: 6| Step: 3
Training loss: 3.2419114112854004
Validation loss: 2.6785683913897445

Epoch: 6| Step: 4
Training loss: 3.072120189666748
Validation loss: 2.6708251942870436

Epoch: 6| Step: 5
Training loss: 2.326885223388672
Validation loss: 2.676550308863322

Epoch: 6| Step: 6
Training loss: 2.4713168144226074
Validation loss: 2.6719664835160777

Epoch: 6| Step: 7
Training loss: 3.0590579509735107
Validation loss: 2.6822326824229252

Epoch: 6| Step: 8
Training loss: 2.6565866470336914
Validation loss: 2.668479847651656

Epoch: 6| Step: 9
Training loss: 3.5462148189544678
Validation loss: 2.648167471731863

Epoch: 6| Step: 10
Training loss: 2.4427247047424316
Validation loss: 2.6563629104245092

Epoch: 6| Step: 11
Training loss: 2.834487199783325
Validation loss: 2.653011273312312

Epoch: 6| Step: 12
Training loss: 2.852006196975708
Validation loss: 2.6473613836432017

Epoch: 6| Step: 13
Training loss: 2.4783518314361572
Validation loss: 2.646138806496897

Epoch: 12| Step: 0
Training loss: 1.971086025238037
Validation loss: 2.6526740674049623

Epoch: 6| Step: 1
Training loss: 3.3493611812591553
Validation loss: 2.650971184494675

Epoch: 6| Step: 2
Training loss: 3.0308737754821777
Validation loss: 2.6387208225906535

Epoch: 6| Step: 3
Training loss: 3.2679896354675293
Validation loss: 2.634430995551489

Epoch: 6| Step: 4
Training loss: 2.887627601623535
Validation loss: 2.642470908421342

Epoch: 6| Step: 5
Training loss: 2.991367816925049
Validation loss: 2.6407916033139793

Epoch: 6| Step: 6
Training loss: 2.851663112640381
Validation loss: 2.6442326755933863

Epoch: 6| Step: 7
Training loss: 2.6935746669769287
Validation loss: 2.645779378952519

Epoch: 6| Step: 8
Training loss: 2.298593759536743
Validation loss: 2.6412165754584858

Epoch: 6| Step: 9
Training loss: 2.571197271347046
Validation loss: 2.6229583499252156

Epoch: 6| Step: 10
Training loss: 3.336641788482666
Validation loss: 2.6138247264328824

Epoch: 6| Step: 11
Training loss: 2.8108880519866943
Validation loss: 2.614749936647313

Epoch: 6| Step: 12
Training loss: 3.078155517578125
Validation loss: 2.616967098687285

Epoch: 6| Step: 13
Training loss: 1.9977937936782837
Validation loss: 2.6096553571762575

Epoch: 13| Step: 0
Training loss: 2.7660326957702637
Validation loss: 2.6073057420792116

Epoch: 6| Step: 1
Training loss: 2.225750684738159
Validation loss: 2.604802498253443

Epoch: 6| Step: 2
Training loss: 3.1197543144226074
Validation loss: 2.593818977314939

Epoch: 6| Step: 3
Training loss: 2.929271697998047
Validation loss: 2.5909947990089335

Epoch: 6| Step: 4
Training loss: 3.1604807376861572
Validation loss: 2.5937340310824815

Epoch: 6| Step: 5
Training loss: 2.1150050163269043
Validation loss: 2.5900126093177387

Epoch: 6| Step: 6
Training loss: 2.7710206508636475
Validation loss: 2.6311911767528904

Epoch: 6| Step: 7
Training loss: 3.020981788635254
Validation loss: 2.664767954939155

Epoch: 6| Step: 8
Training loss: 3.0767431259155273
Validation loss: 2.6586559767364175

Epoch: 6| Step: 9
Training loss: 2.5910091400146484
Validation loss: 2.598837503822901

Epoch: 6| Step: 10
Training loss: 2.196333885192871
Validation loss: 2.5918703720133793

Epoch: 6| Step: 11
Training loss: 3.1219022274017334
Validation loss: 2.6603336846956642

Epoch: 6| Step: 12
Training loss: 3.4347472190856934
Validation loss: 2.6903061789851033

Epoch: 6| Step: 13
Training loss: 2.840980052947998
Validation loss: 2.7010971500027563

Epoch: 14| Step: 0
Training loss: 2.9442250728607178
Validation loss: 2.6824268064191266

Epoch: 6| Step: 1
Training loss: 2.626307964324951
Validation loss: 2.660722230070381

Epoch: 6| Step: 2
Training loss: 3.3431601524353027
Validation loss: 2.647731514387233

Epoch: 6| Step: 3
Training loss: 2.610121488571167
Validation loss: 2.6378571320605535

Epoch: 6| Step: 4
Training loss: 2.450150966644287
Validation loss: 2.617421260444067

Epoch: 6| Step: 5
Training loss: 3.0186197757720947
Validation loss: 2.6642039155447357

Epoch: 6| Step: 6
Training loss: 2.899043083190918
Validation loss: 2.6614448511472313

Epoch: 6| Step: 7
Training loss: 3.012288808822632
Validation loss: 2.6819438216506795

Epoch: 6| Step: 8
Training loss: 2.365405559539795
Validation loss: 2.6219086775215725

Epoch: 6| Step: 9
Training loss: 2.2430872917175293
Validation loss: 2.5780444863022014

Epoch: 6| Step: 10
Training loss: 3.1519789695739746
Validation loss: 2.563081408059725

Epoch: 6| Step: 11
Training loss: 2.6421561241149902
Validation loss: 2.5649364379144486

Epoch: 6| Step: 12
Training loss: 3.1165900230407715
Validation loss: 2.565607783614948

Epoch: 6| Step: 13
Training loss: 2.7342491149902344
Validation loss: 2.568724816845309

Epoch: 15| Step: 0
Training loss: 2.637019634246826
Validation loss: 2.5595939415757374

Epoch: 6| Step: 1
Training loss: 3.080911636352539
Validation loss: 2.5654049278587423

Epoch: 6| Step: 2
Training loss: 2.680558681488037
Validation loss: 2.5571489693016134

Epoch: 6| Step: 3
Training loss: 3.04319167137146
Validation loss: 2.5525760445543515

Epoch: 6| Step: 4
Training loss: 2.3127031326293945
Validation loss: 2.5504111320741716

Epoch: 6| Step: 5
Training loss: 3.0331966876983643
Validation loss: 2.5622328173729683

Epoch: 6| Step: 6
Training loss: 2.9710755348205566
Validation loss: 2.54974445989055

Epoch: 6| Step: 7
Training loss: 2.4424874782562256
Validation loss: 2.5293988130425893

Epoch: 6| Step: 8
Training loss: 2.482856273651123
Validation loss: 2.5278785151820027

Epoch: 6| Step: 9
Training loss: 2.843761920928955
Validation loss: 2.525885226905987

Epoch: 6| Step: 10
Training loss: 2.599039077758789
Validation loss: 2.5211507248622116

Epoch: 6| Step: 11
Training loss: 2.905900239944458
Validation loss: 2.518451193327545

Epoch: 6| Step: 12
Training loss: 2.890315532684326
Validation loss: 2.5196500439797678

Epoch: 6| Step: 13
Training loss: 2.6017560958862305
Validation loss: 2.5150591160661433

Epoch: 16| Step: 0
Training loss: 3.4013397693634033
Validation loss: 2.539076412877729

Epoch: 6| Step: 1
Training loss: 3.602029800415039
Validation loss: 2.5772999537888395

Epoch: 6| Step: 2
Training loss: 2.135110855102539
Validation loss: 2.5735219268388647

Epoch: 6| Step: 3
Training loss: 2.182227611541748
Validation loss: 2.5462740057258197

Epoch: 6| Step: 4
Training loss: 3.2209930419921875
Validation loss: 2.505804382344728

Epoch: 6| Step: 5
Training loss: 2.8231897354125977
Validation loss: 2.5157672269369966

Epoch: 6| Step: 6
Training loss: 2.576228141784668
Validation loss: 2.5422927307826217

Epoch: 6| Step: 7
Training loss: 3.206733465194702
Validation loss: 2.560806712796611

Epoch: 6| Step: 8
Training loss: 2.1440303325653076
Validation loss: 2.5558939313375824

Epoch: 6| Step: 9
Training loss: 2.4054489135742188
Validation loss: 2.5574327412471978

Epoch: 6| Step: 10
Training loss: 3.1041998863220215
Validation loss: 2.558331148598784

Epoch: 6| Step: 11
Training loss: 2.754209280014038
Validation loss: 2.5521826026260213

Epoch: 6| Step: 12
Training loss: 2.8341150283813477
Validation loss: 2.534106801914912

Epoch: 6| Step: 13
Training loss: 2.1303932666778564
Validation loss: 2.506924908648255

Epoch: 17| Step: 0
Training loss: 2.4516592025756836
Validation loss: 2.4957571183481524

Epoch: 6| Step: 1
Training loss: 3.3526010513305664
Validation loss: 2.4918012901019027

Epoch: 6| Step: 2
Training loss: 2.4249725341796875
Validation loss: 2.483359116379933

Epoch: 6| Step: 3
Training loss: 2.4890339374542236
Validation loss: 2.4819140613719983

Epoch: 6| Step: 4
Training loss: 2.9614076614379883
Validation loss: 2.4872946405923493

Epoch: 6| Step: 5
Training loss: 1.7082452774047852
Validation loss: 2.486501398906913

Epoch: 6| Step: 6
Training loss: 3.1960091590881348
Validation loss: 2.4854015586196736

Epoch: 6| Step: 7
Training loss: 3.069664239883423
Validation loss: 2.476910601380051

Epoch: 6| Step: 8
Training loss: 3.130014419555664
Validation loss: 2.469049051243772

Epoch: 6| Step: 9
Training loss: 1.9568395614624023
Validation loss: 2.4694606719478482

Epoch: 6| Step: 10
Training loss: 2.7779111862182617
Validation loss: 2.4676537385550876

Epoch: 6| Step: 11
Training loss: 1.9091302156448364
Validation loss: 2.4706653395006732

Epoch: 6| Step: 12
Training loss: 3.0917510986328125
Validation loss: 2.473698495536722

Epoch: 6| Step: 13
Training loss: 4.170088768005371
Validation loss: 2.47579268229905

Epoch: 18| Step: 0
Training loss: 2.990007162094116
Validation loss: 2.473106051004061

Epoch: 6| Step: 1
Training loss: 2.8078200817108154
Validation loss: 2.4705988719899166

Epoch: 6| Step: 2
Training loss: 2.803109645843506
Validation loss: 2.4728775357687347

Epoch: 6| Step: 3
Training loss: 3.4569756984710693
Validation loss: 2.4680569094996296

Epoch: 6| Step: 4
Training loss: 1.7641041278839111
Validation loss: 2.467104519567182

Epoch: 6| Step: 5
Training loss: 2.816819190979004
Validation loss: 2.5005884208986835

Epoch: 6| Step: 6
Training loss: 2.6124954223632812
Validation loss: 2.5264844843136367

Epoch: 6| Step: 7
Training loss: 2.247260093688965
Validation loss: 2.532024586072532

Epoch: 6| Step: 8
Training loss: 2.4076666831970215
Validation loss: 2.54479706159202

Epoch: 6| Step: 9
Training loss: 2.5768814086914062
Validation loss: 2.5565874576568604

Epoch: 6| Step: 10
Training loss: 2.784106492996216
Validation loss: 2.5625615376298145

Epoch: 6| Step: 11
Training loss: 2.7571139335632324
Validation loss: 2.5452365157424763

Epoch: 6| Step: 12
Training loss: 3.2169382572174072
Validation loss: 2.5253468739089144

Epoch: 6| Step: 13
Training loss: 2.94172739982605
Validation loss: 2.518475846577716

Epoch: 19| Step: 0
Training loss: 2.6586806774139404
Validation loss: 2.517624283349642

Epoch: 6| Step: 1
Training loss: 3.226989269256592
Validation loss: 2.5209463796307965

Epoch: 6| Step: 2
Training loss: 2.474884510040283
Validation loss: 2.521224537203389

Epoch: 6| Step: 3
Training loss: 2.74226450920105
Validation loss: 2.5089252712906047

Epoch: 6| Step: 4
Training loss: 2.4259679317474365
Validation loss: 2.5098322668383197

Epoch: 6| Step: 5
Training loss: 3.0220561027526855
Validation loss: 2.5058080432235554

Epoch: 6| Step: 6
Training loss: 3.808720588684082
Validation loss: 2.499617435598886

Epoch: 6| Step: 7
Training loss: 2.1172597408294678
Validation loss: 2.492424370140158

Epoch: 6| Step: 8
Training loss: 2.5232157707214355
Validation loss: 2.475556391541676

Epoch: 6| Step: 9
Training loss: 3.1694116592407227
Validation loss: 2.4873445495482414

Epoch: 6| Step: 10
Training loss: 2.6272215843200684
Validation loss: 2.485206937277189

Epoch: 6| Step: 11
Training loss: 1.9690556526184082
Validation loss: 2.4638915190132717

Epoch: 6| Step: 12
Training loss: 2.3517513275146484
Validation loss: 2.45764482918606

Epoch: 6| Step: 13
Training loss: 3.118852376937866
Validation loss: 2.4832798998842955

Epoch: 20| Step: 0
Training loss: 2.173126459121704
Validation loss: 2.4705009357903593

Epoch: 6| Step: 1
Training loss: 2.744978427886963
Validation loss: 2.452517094150666

Epoch: 6| Step: 2
Training loss: 2.8828177452087402
Validation loss: 2.4617355792753157

Epoch: 6| Step: 3
Training loss: 2.952785015106201
Validation loss: 2.456758124853975

Epoch: 6| Step: 4
Training loss: 2.4268970489501953
Validation loss: 2.46810636725477

Epoch: 6| Step: 5
Training loss: 2.5277061462402344
Validation loss: 2.468221031209474

Epoch: 6| Step: 6
Training loss: 3.1723737716674805
Validation loss: 2.4562309865028626

Epoch: 6| Step: 7
Training loss: 2.678729772567749
Validation loss: 2.4475553804828274

Epoch: 6| Step: 8
Training loss: 2.6201815605163574
Validation loss: 2.4376416936997445

Epoch: 6| Step: 9
Training loss: 2.742021322250366
Validation loss: 2.429029723649384

Epoch: 6| Step: 10
Training loss: 2.904608726501465
Validation loss: 2.421226111791467

Epoch: 6| Step: 11
Training loss: 2.7814207077026367
Validation loss: 2.4203341186687513

Epoch: 6| Step: 12
Training loss: 2.6720056533813477
Validation loss: 2.42559475539833

Epoch: 6| Step: 13
Training loss: 1.9282582998275757
Validation loss: 2.417467983820105

Epoch: 21| Step: 0
Training loss: 2.6668577194213867
Validation loss: 2.417504825899678

Epoch: 6| Step: 1
Training loss: 2.5343847274780273
Validation loss: 2.4213526300204697

Epoch: 6| Step: 2
Training loss: 2.410698413848877
Validation loss: 2.4220135878491145

Epoch: 6| Step: 3
Training loss: 2.9473373889923096
Validation loss: 2.432570319021902

Epoch: 6| Step: 4
Training loss: 2.991746187210083
Validation loss: 2.42750060173773

Epoch: 6| Step: 5
Training loss: 2.7125446796417236
Validation loss: 2.4264645884113927

Epoch: 6| Step: 6
Training loss: 2.451261043548584
Validation loss: 2.423108623873803

Epoch: 6| Step: 7
Training loss: 2.101053237915039
Validation loss: 2.4231697743938816

Epoch: 6| Step: 8
Training loss: 2.8323328495025635
Validation loss: 2.429414259490146

Epoch: 6| Step: 9
Training loss: 2.9931201934814453
Validation loss: 2.428793373928275

Epoch: 6| Step: 10
Training loss: 2.579648733139038
Validation loss: 2.4399718905007965

Epoch: 6| Step: 11
Training loss: 2.1939711570739746
Validation loss: 2.4528744630916144

Epoch: 6| Step: 12
Training loss: 3.24495267868042
Validation loss: 2.456905636736142

Epoch: 6| Step: 13
Training loss: 2.825451135635376
Validation loss: 2.4463290424757105

Epoch: 22| Step: 0
Training loss: 2.051889181137085
Validation loss: 2.4342367367077897

Epoch: 6| Step: 1
Training loss: 2.972524404525757
Validation loss: 2.4244726498921714

Epoch: 6| Step: 2
Training loss: 3.045173168182373
Validation loss: 2.412808641310661

Epoch: 6| Step: 3
Training loss: 2.5235910415649414
Validation loss: 2.402769930901066

Epoch: 6| Step: 4
Training loss: 2.859560012817383
Validation loss: 2.3982099589481147

Epoch: 6| Step: 5
Training loss: 2.6873977184295654
Validation loss: 2.3949412658650386

Epoch: 6| Step: 6
Training loss: 3.1772470474243164
Validation loss: 2.3921568342434463

Epoch: 6| Step: 7
Training loss: 2.450061798095703
Validation loss: 2.390598279173656

Epoch: 6| Step: 8
Training loss: 2.895566940307617
Validation loss: 2.386976436902118

Epoch: 6| Step: 9
Training loss: 2.494131088256836
Validation loss: 2.388455903658303

Epoch: 6| Step: 10
Training loss: 1.7006103992462158
Validation loss: 2.388807794099213

Epoch: 6| Step: 11
Training loss: 2.6217288970947266
Validation loss: 2.3883041489508843

Epoch: 6| Step: 12
Training loss: 2.6083950996398926
Validation loss: 2.3982565992621967

Epoch: 6| Step: 13
Training loss: 3.3562958240509033
Validation loss: 2.407579227160382

Epoch: 23| Step: 0
Training loss: 3.035271406173706
Validation loss: 2.3931611225169194

Epoch: 6| Step: 1
Training loss: 3.0979726314544678
Validation loss: 2.409283653382332

Epoch: 6| Step: 2
Training loss: 2.1137852668762207
Validation loss: 2.400699600096672

Epoch: 6| Step: 3
Training loss: 2.786181926727295
Validation loss: 2.3932005359280493

Epoch: 6| Step: 4
Training loss: 2.6348862648010254
Validation loss: 2.3837338339897896

Epoch: 6| Step: 5
Training loss: 3.0255959033966064
Validation loss: 2.3774341383287982

Epoch: 6| Step: 6
Training loss: 2.7051949501037598
Validation loss: 2.379151000771471

Epoch: 6| Step: 7
Training loss: 2.2516891956329346
Validation loss: 2.3804800536042903

Epoch: 6| Step: 8
Training loss: 2.8866350650787354
Validation loss: 2.3881786792509017

Epoch: 6| Step: 9
Training loss: 3.09131121635437
Validation loss: 2.37765412176809

Epoch: 6| Step: 10
Training loss: 1.9001991748809814
Validation loss: 2.363067965353689

Epoch: 6| Step: 11
Training loss: 2.829545021057129
Validation loss: 2.369805292416644

Epoch: 6| Step: 12
Training loss: 2.1826608180999756
Validation loss: 2.366959451347269

Epoch: 6| Step: 13
Training loss: 2.327558755874634
Validation loss: 2.370261853741061

Epoch: 24| Step: 0
Training loss: 2.5138649940490723
Validation loss: 2.392396616679366

Epoch: 6| Step: 1
Training loss: 2.946629762649536
Validation loss: 2.4204292143544843

Epoch: 6| Step: 2
Training loss: 2.3831117153167725
Validation loss: 2.5277341309414116

Epoch: 6| Step: 3
Training loss: 2.85797381401062
Validation loss: 2.640013469162808

Epoch: 6| Step: 4
Training loss: 3.1970574855804443
Validation loss: 2.633901026941115

Epoch: 6| Step: 5
Training loss: 2.7197375297546387
Validation loss: 2.547909264923424

Epoch: 6| Step: 6
Training loss: 2.774731159210205
Validation loss: 2.4798977759576615

Epoch: 6| Step: 7
Training loss: 2.3092174530029297
Validation loss: 2.3903906601731495

Epoch: 6| Step: 8
Training loss: 2.1582112312316895
Validation loss: 2.358037902462867

Epoch: 6| Step: 9
Training loss: 2.373075485229492
Validation loss: 2.360619919274443

Epoch: 6| Step: 10
Training loss: 2.8101000785827637
Validation loss: 2.401987250133227

Epoch: 6| Step: 11
Training loss: 2.4470558166503906
Validation loss: 2.4459154477683445

Epoch: 6| Step: 12
Training loss: 3.4705142974853516
Validation loss: 2.454495499210973

Epoch: 6| Step: 13
Training loss: 2.8612897396087646
Validation loss: 2.3979413586278118

Epoch: 25| Step: 0
Training loss: 1.6707862615585327
Validation loss: 2.3835569812405493

Epoch: 6| Step: 1
Training loss: 3.08066725730896
Validation loss: 2.397702322211317

Epoch: 6| Step: 2
Training loss: 2.6821937561035156
Validation loss: 2.4220769456637803

Epoch: 6| Step: 3
Training loss: 2.3869552612304688
Validation loss: 2.4193834694482947

Epoch: 6| Step: 4
Training loss: 2.7771925926208496
Validation loss: 2.4037751279851443

Epoch: 6| Step: 5
Training loss: 2.5964059829711914
Validation loss: 2.4190000411002868

Epoch: 6| Step: 6
Training loss: 2.730365753173828
Validation loss: 2.425599350724169

Epoch: 6| Step: 7
Training loss: 2.4353578090667725
Validation loss: 2.430358914918797

Epoch: 6| Step: 8
Training loss: 3.6015472412109375
Validation loss: 2.427015645529634

Epoch: 6| Step: 9
Training loss: 2.405395030975342
Validation loss: 2.4199637956516717

Epoch: 6| Step: 10
Training loss: 2.9359688758850098
Validation loss: 2.4074402111832813

Epoch: 6| Step: 11
Training loss: 1.969055414199829
Validation loss: 2.4014346958488546

Epoch: 6| Step: 12
Training loss: 3.2204360961914062
Validation loss: 2.395853832203855

Epoch: 6| Step: 13
Training loss: 2.440439462661743
Validation loss: 2.4050552742455595

Epoch: 26| Step: 0
Training loss: 3.3228049278259277
Validation loss: 2.3969774797398555

Epoch: 6| Step: 1
Training loss: 2.5004639625549316
Validation loss: 2.3953161290896836

Epoch: 6| Step: 2
Training loss: 2.6473922729492188
Validation loss: 2.384043255159932

Epoch: 6| Step: 3
Training loss: 2.629342555999756
Validation loss: 2.3841493296366867

Epoch: 6| Step: 4
Training loss: 3.1334149837493896
Validation loss: 2.3787661419119885

Epoch: 6| Step: 5
Training loss: 2.7030019760131836
Validation loss: 2.37085614409498

Epoch: 6| Step: 6
Training loss: 2.5163187980651855
Validation loss: 2.3674252033233643

Epoch: 6| Step: 7
Training loss: 2.487736225128174
Validation loss: 2.3607834487833004

Epoch: 6| Step: 8
Training loss: 2.798964738845825
Validation loss: 2.363535968206262

Epoch: 6| Step: 9
Training loss: 1.5901718139648438
Validation loss: 2.3700326629864272

Epoch: 6| Step: 10
Training loss: 2.289696455001831
Validation loss: 2.3715142242370115

Epoch: 6| Step: 11
Training loss: 2.864403009414673
Validation loss: 2.363555057074434

Epoch: 6| Step: 12
Training loss: 2.001410722732544
Validation loss: 2.3763573810618412

Epoch: 6| Step: 13
Training loss: 3.6270244121551514
Validation loss: 2.3806401632165395

Epoch: 27| Step: 0
Training loss: 2.4594974517822266
Validation loss: 2.391447235179204

Epoch: 6| Step: 1
Training loss: 3.0698204040527344
Validation loss: 2.387726770934238

Epoch: 6| Step: 2
Training loss: 2.6596903800964355
Validation loss: 2.387974654474566

Epoch: 6| Step: 3
Training loss: 2.173679828643799
Validation loss: 2.378103256225586

Epoch: 6| Step: 4
Training loss: 2.5591273307800293
Validation loss: 2.36889212874956

Epoch: 6| Step: 5
Training loss: 2.6674699783325195
Validation loss: 2.355333197501398

Epoch: 6| Step: 6
Training loss: 3.3973865509033203
Validation loss: 2.356193352771062

Epoch: 6| Step: 7
Training loss: 2.4944658279418945
Validation loss: 2.3594870644231

Epoch: 6| Step: 8
Training loss: 2.0357747077941895
Validation loss: 2.3439672018892024

Epoch: 6| Step: 9
Training loss: 3.41520357131958
Validation loss: 2.332639848032305

Epoch: 6| Step: 10
Training loss: 2.5228424072265625
Validation loss: 2.3284148939194216

Epoch: 6| Step: 11
Training loss: 2.139402389526367
Validation loss: 2.330990542647659

Epoch: 6| Step: 12
Training loss: 2.6232845783233643
Validation loss: 2.3285483070599136

Epoch: 6| Step: 13
Training loss: 2.176800489425659
Validation loss: 2.3303879178980345

Epoch: 28| Step: 0
Training loss: 3.1954026222229004
Validation loss: 2.331030309841197

Epoch: 6| Step: 1
Training loss: 2.5166776180267334
Validation loss: 2.331620298406129

Epoch: 6| Step: 2
Training loss: 2.7760097980499268
Validation loss: 2.333506735422278

Epoch: 6| Step: 3
Training loss: 2.5819079875946045
Validation loss: 2.335001959595629

Epoch: 6| Step: 4
Training loss: 2.349870204925537
Validation loss: 2.336949945777975

Epoch: 6| Step: 5
Training loss: 2.896865129470825
Validation loss: 2.3349443404905257

Epoch: 6| Step: 6
Training loss: 2.6703624725341797
Validation loss: 2.3352273894894506

Epoch: 6| Step: 7
Training loss: 2.202329635620117
Validation loss: 2.34434929714408

Epoch: 6| Step: 8
Training loss: 2.846082925796509
Validation loss: 2.3643979410971365

Epoch: 6| Step: 9
Training loss: 2.313962459564209
Validation loss: 2.3718243952720397

Epoch: 6| Step: 10
Training loss: 2.5428731441497803
Validation loss: 2.3734693834858556

Epoch: 6| Step: 11
Training loss: 2.420109748840332
Validation loss: 2.376351207815191

Epoch: 6| Step: 12
Training loss: 2.7943291664123535
Validation loss: 2.3961957193190053

Epoch: 6| Step: 13
Training loss: 2.5371530055999756
Validation loss: 2.394642283839564

Epoch: 29| Step: 0
Training loss: 2.8394775390625
Validation loss: 2.37778288830993

Epoch: 6| Step: 1
Training loss: 2.4354562759399414
Validation loss: 2.362968885770408

Epoch: 6| Step: 2
Training loss: 2.909494400024414
Validation loss: 2.350544309103361

Epoch: 6| Step: 3
Training loss: 2.7236714363098145
Validation loss: 2.3477218279274563

Epoch: 6| Step: 4
Training loss: 2.5222690105438232
Validation loss: 2.336422630535659

Epoch: 6| Step: 5
Training loss: 2.4196906089782715
Validation loss: 2.3344169432117092

Epoch: 6| Step: 6
Training loss: 2.4863481521606445
Validation loss: 2.3434949741568616

Epoch: 6| Step: 7
Training loss: 2.313042640686035
Validation loss: 2.3479791841199322

Epoch: 6| Step: 8
Training loss: 2.5356664657592773
Validation loss: 2.352992921747187

Epoch: 6| Step: 9
Training loss: 3.1510086059570312
Validation loss: 2.344030072612147

Epoch: 6| Step: 10
Training loss: 2.338933229446411
Validation loss: 2.327724572150938

Epoch: 6| Step: 11
Training loss: 2.444554328918457
Validation loss: 2.3197314457226823

Epoch: 6| Step: 12
Training loss: 3.1193506717681885
Validation loss: 2.3092272820011264

Epoch: 6| Step: 13
Training loss: 1.6015172004699707
Validation loss: 2.304599162070982

Epoch: 30| Step: 0
Training loss: 1.9761680364608765
Validation loss: 2.302589585704188

Epoch: 6| Step: 1
Training loss: 2.644334316253662
Validation loss: 2.3077996084767003

Epoch: 6| Step: 2
Training loss: 2.342958688735962
Validation loss: 2.309094023960893

Epoch: 6| Step: 3
Training loss: 1.7182519435882568
Validation loss: 2.308682582711661

Epoch: 6| Step: 4
Training loss: 2.607940196990967
Validation loss: 2.303841160189721

Epoch: 6| Step: 5
Training loss: 3.214165449142456
Validation loss: 2.298773782227629

Epoch: 6| Step: 6
Training loss: 2.977003574371338
Validation loss: 2.3068312239903275

Epoch: 6| Step: 7
Training loss: 2.762185573577881
Validation loss: 2.307910152660903

Epoch: 6| Step: 8
Training loss: 3.0156140327453613
Validation loss: 2.3165157289915186

Epoch: 6| Step: 9
Training loss: 2.5952868461608887
Validation loss: 2.31933379942371

Epoch: 6| Step: 10
Training loss: 3.124805450439453
Validation loss: 2.3243888629380094

Epoch: 6| Step: 11
Training loss: 2.950657606124878
Validation loss: 2.324563528901787

Epoch: 6| Step: 12
Training loss: 1.9734116792678833
Validation loss: 2.323264139954762

Epoch: 6| Step: 13
Training loss: 2.195112705230713
Validation loss: 2.348908201340706

Epoch: 31| Step: 0
Training loss: 3.0717709064483643
Validation loss: 2.3502644338915424

Epoch: 6| Step: 1
Training loss: 2.5075254440307617
Validation loss: 2.3410599282992783

Epoch: 6| Step: 2
Training loss: 3.4177794456481934
Validation loss: 2.3256637768078874

Epoch: 6| Step: 3
Training loss: 2.615220069885254
Validation loss: 2.306846639161469

Epoch: 6| Step: 4
Training loss: 2.2890923023223877
Validation loss: 2.30132108606318

Epoch: 6| Step: 5
Training loss: 2.817802906036377
Validation loss: 2.3026134352530203

Epoch: 6| Step: 6
Training loss: 2.8708877563476562
Validation loss: 2.30056098968752

Epoch: 6| Step: 7
Training loss: 1.9903067350387573
Validation loss: 2.303253642974361

Epoch: 6| Step: 8
Training loss: 2.256552219390869
Validation loss: 2.3067079000575568

Epoch: 6| Step: 9
Training loss: 2.7747559547424316
Validation loss: 2.324918936657649

Epoch: 6| Step: 10
Training loss: 2.245260715484619
Validation loss: 2.3372422623377975

Epoch: 6| Step: 11
Training loss: 2.5362141132354736
Validation loss: 2.352303812580724

Epoch: 6| Step: 12
Training loss: 1.913857340812683
Validation loss: 2.339645783106486

Epoch: 6| Step: 13
Training loss: 2.8495683670043945
Validation loss: 2.336590031141876

Epoch: 32| Step: 0
Training loss: 2.745558023452759
Validation loss: 2.3437498897634526

Epoch: 6| Step: 1
Training loss: 2.0766334533691406
Validation loss: 2.33950368050606

Epoch: 6| Step: 2
Training loss: 2.297374725341797
Validation loss: 2.340291130927301

Epoch: 6| Step: 3
Training loss: 2.164736747741699
Validation loss: 2.3431412558401785

Epoch: 6| Step: 4
Training loss: 2.719163417816162
Validation loss: 2.346975931557276

Epoch: 6| Step: 5
Training loss: 2.8641841411590576
Validation loss: 2.3457982181220927

Epoch: 6| Step: 6
Training loss: 3.214930772781372
Validation loss: 2.338870597142045

Epoch: 6| Step: 7
Training loss: 2.729909896850586
Validation loss: 2.331459945248019

Epoch: 6| Step: 8
Training loss: 2.964906692504883
Validation loss: 2.319091640492921

Epoch: 6| Step: 9
Training loss: 3.275846004486084
Validation loss: 2.3112077354103007

Epoch: 6| Step: 10
Training loss: 2.130505084991455
Validation loss: 2.3143901107131795

Epoch: 6| Step: 11
Training loss: 2.4562885761260986
Validation loss: 2.314061851911647

Epoch: 6| Step: 12
Training loss: 2.0955259799957275
Validation loss: 2.3288376074965282

Epoch: 6| Step: 13
Training loss: 2.246035575866699
Validation loss: 2.339661334150581

Epoch: 33| Step: 0
Training loss: 2.663053512573242
Validation loss: 2.3619220128623386

Epoch: 6| Step: 1
Training loss: 2.498131275177002
Validation loss: 2.3482559291265344

Epoch: 6| Step: 2
Training loss: 2.9983115196228027
Validation loss: 2.3123401711064

Epoch: 6| Step: 3
Training loss: 1.8637516498565674
Validation loss: 2.3057513057544665

Epoch: 6| Step: 4
Training loss: 2.6404809951782227
Validation loss: 2.298594638865481

Epoch: 6| Step: 5
Training loss: 3.1208395957946777
Validation loss: 2.307343211225284

Epoch: 6| Step: 6
Training loss: 2.61844801902771
Validation loss: 2.3136306193567093

Epoch: 6| Step: 7
Training loss: 1.9756603240966797
Validation loss: 2.3142194363378708

Epoch: 6| Step: 8
Training loss: 3.019188404083252
Validation loss: 2.314261926117764

Epoch: 6| Step: 9
Training loss: 2.427009105682373
Validation loss: 2.3015749633953138

Epoch: 6| Step: 10
Training loss: 2.773453712463379
Validation loss: 2.2907068729400635

Epoch: 6| Step: 11
Training loss: 2.7108192443847656
Validation loss: 2.2780325002567743

Epoch: 6| Step: 12
Training loss: 1.7450032234191895
Validation loss: 2.2725415050342517

Epoch: 6| Step: 13
Training loss: 3.1118812561035156
Validation loss: 2.27437085746437

Epoch: 34| Step: 0
Training loss: 3.0036182403564453
Validation loss: 2.275574143214892

Epoch: 6| Step: 1
Training loss: 2.464409112930298
Validation loss: 2.2722235956499652

Epoch: 6| Step: 2
Training loss: 2.764307975769043
Validation loss: 2.2783431519744215

Epoch: 6| Step: 3
Training loss: 2.539973735809326
Validation loss: 2.281149579632667

Epoch: 6| Step: 4
Training loss: 2.1526503562927246
Validation loss: 2.290673868630522

Epoch: 6| Step: 5
Training loss: 2.060858726501465
Validation loss: 2.296519366643762

Epoch: 6| Step: 6
Training loss: 3.7408652305603027
Validation loss: 2.306584260796988

Epoch: 6| Step: 7
Training loss: 2.215075731277466
Validation loss: 2.3062212313375166

Epoch: 6| Step: 8
Training loss: 3.0511891841888428
Validation loss: 2.305697651319606

Epoch: 6| Step: 9
Training loss: 2.6478559970855713
Validation loss: 2.2937747304157545

Epoch: 6| Step: 10
Training loss: 2.9438648223876953
Validation loss: 2.28126956570533

Epoch: 6| Step: 11
Training loss: 2.1620564460754395
Validation loss: 2.271350440158639

Epoch: 6| Step: 12
Training loss: 1.9275275468826294
Validation loss: 2.2755956777962307

Epoch: 6| Step: 13
Training loss: 2.1465883255004883
Validation loss: 2.278889209993424

Epoch: 35| Step: 0
Training loss: 2.3787896633148193
Validation loss: 2.284053556380733

Epoch: 6| Step: 1
Training loss: 2.455185651779175
Validation loss: 2.3121739484930552

Epoch: 6| Step: 2
Training loss: 2.390502452850342
Validation loss: 2.3352400564378306

Epoch: 6| Step: 3
Training loss: 2.2428677082061768
Validation loss: 2.3780023180028445

Epoch: 6| Step: 4
Training loss: 3.4498162269592285
Validation loss: 2.383101612009028

Epoch: 6| Step: 5
Training loss: 2.8399648666381836
Validation loss: 2.35300955464763

Epoch: 6| Step: 6
Training loss: 2.6893653869628906
Validation loss: 2.3103912261224564

Epoch: 6| Step: 7
Training loss: 2.000934600830078
Validation loss: 2.296786126270089

Epoch: 6| Step: 8
Training loss: 3.081486701965332
Validation loss: 2.2899966022019744

Epoch: 6| Step: 9
Training loss: 2.2455270290374756
Validation loss: 2.293380493758827

Epoch: 6| Step: 10
Training loss: 2.7138123512268066
Validation loss: 2.302059240238641

Epoch: 6| Step: 11
Training loss: 3.0055251121520996
Validation loss: 2.3123809958017

Epoch: 6| Step: 12
Training loss: 1.9567807912826538
Validation loss: 2.309479836494692

Epoch: 6| Step: 13
Training loss: 2.5748183727264404
Validation loss: 2.322071757367862

Epoch: 36| Step: 0
Training loss: 2.6073808670043945
Validation loss: 2.328857652602657

Epoch: 6| Step: 1
Training loss: 2.3544793128967285
Validation loss: 2.3390099592106317

Epoch: 6| Step: 2
Training loss: 2.708895206451416
Validation loss: 2.3418089420564714

Epoch: 6| Step: 3
Training loss: 1.7964956760406494
Validation loss: 2.3654308242182576

Epoch: 6| Step: 4
Training loss: 2.9152445793151855
Validation loss: 2.389569390204645

Epoch: 6| Step: 5
Training loss: 3.338108539581299
Validation loss: 2.358899067806941

Epoch: 6| Step: 6
Training loss: 2.6034443378448486
Validation loss: 2.3317920828378327

Epoch: 6| Step: 7
Training loss: 2.981238603591919
Validation loss: 2.301645871131651

Epoch: 6| Step: 8
Training loss: 2.4285027980804443
Validation loss: 2.291307977450791

Epoch: 6| Step: 9
Training loss: 2.988706111907959
Validation loss: 2.2867315840977493

Epoch: 6| Step: 10
Training loss: 2.546119213104248
Validation loss: 2.2910794904155116

Epoch: 6| Step: 11
Training loss: 1.9915517568588257
Validation loss: 2.307134005331224

Epoch: 6| Step: 12
Training loss: 2.225503444671631
Validation loss: 2.3056867507196244

Epoch: 6| Step: 13
Training loss: 1.9925929307937622
Validation loss: 2.318983906058855

Epoch: 37| Step: 0
Training loss: 2.712916374206543
Validation loss: 2.358540270918159

Epoch: 6| Step: 1
Training loss: 3.754427909851074
Validation loss: 2.3832902972416212

Epoch: 6| Step: 2
Training loss: 2.233736991882324
Validation loss: 2.3632083862058577

Epoch: 6| Step: 3
Training loss: 3.0717358589172363
Validation loss: 2.3160734074090117

Epoch: 6| Step: 4
Training loss: 2.491840362548828
Validation loss: 2.2676926107816797

Epoch: 6| Step: 5
Training loss: 2.7101869583129883
Validation loss: 2.243501583735148

Epoch: 6| Step: 6
Training loss: 2.522465229034424
Validation loss: 2.2454217608257006

Epoch: 6| Step: 7
Training loss: 2.797170400619507
Validation loss: 2.2583791004714144

Epoch: 6| Step: 8
Training loss: 1.9958605766296387
Validation loss: 2.2664562092032483

Epoch: 6| Step: 9
Training loss: 2.800846576690674
Validation loss: 2.2704843782609507

Epoch: 6| Step: 10
Training loss: 2.53897762298584
Validation loss: 2.268623662251298

Epoch: 6| Step: 11
Training loss: 2.2451252937316895
Validation loss: 2.261686255854945

Epoch: 6| Step: 12
Training loss: 2.294863700866699
Validation loss: 2.2601916738735732

Epoch: 6| Step: 13
Training loss: 2.020314931869507
Validation loss: 2.2498004615947766

Epoch: 38| Step: 0
Training loss: 2.6327643394470215
Validation loss: 2.239504578293011

Epoch: 6| Step: 1
Training loss: 2.3819234371185303
Validation loss: 2.24072556085484

Epoch: 6| Step: 2
Training loss: 2.377466917037964
Validation loss: 2.2432682129644577

Epoch: 6| Step: 3
Training loss: 3.290800094604492
Validation loss: 2.261689478351224

Epoch: 6| Step: 4
Training loss: 2.5301215648651123
Validation loss: 2.2929987240863103

Epoch: 6| Step: 5
Training loss: 2.7877964973449707
Validation loss: 2.352927069510183

Epoch: 6| Step: 6
Training loss: 3.1252365112304688
Validation loss: 2.459503722447221

Epoch: 6| Step: 7
Training loss: 2.692161798477173
Validation loss: 2.5032159897588913

Epoch: 6| Step: 8
Training loss: 2.7954611778259277
Validation loss: 2.4598567511445735

Epoch: 6| Step: 9
Training loss: 1.9361319541931152
Validation loss: 2.3781466253342165

Epoch: 6| Step: 10
Training loss: 2.989663600921631
Validation loss: 2.295450328498758

Epoch: 6| Step: 11
Training loss: 1.9446182250976562
Validation loss: 2.259573677534698

Epoch: 6| Step: 12
Training loss: 2.262216806411743
Validation loss: 2.233471437167096

Epoch: 6| Step: 13
Training loss: 2.416139841079712
Validation loss: 2.2311723257905696

Epoch: 39| Step: 0
Training loss: 2.7439427375793457
Validation loss: 2.23161228241459

Epoch: 6| Step: 1
Training loss: 3.0295841693878174
Validation loss: 2.23314606758856

Epoch: 6| Step: 2
Training loss: 1.9332482814788818
Validation loss: 2.241713385428152

Epoch: 6| Step: 3
Training loss: 3.005690097808838
Validation loss: 2.249201254178119

Epoch: 6| Step: 4
Training loss: 2.685299873352051
Validation loss: 2.2549376180095058

Epoch: 6| Step: 5
Training loss: 2.94822359085083
Validation loss: 2.251875482579713

Epoch: 6| Step: 6
Training loss: 2.7205471992492676
Validation loss: 2.2417838881092687

Epoch: 6| Step: 7
Training loss: 2.6329355239868164
Validation loss: 2.235777267845728

Epoch: 6| Step: 8
Training loss: 2.5929481983184814
Validation loss: 2.2399429403325564

Epoch: 6| Step: 9
Training loss: 2.7764410972595215
Validation loss: 2.245727159643686

Epoch: 6| Step: 10
Training loss: 1.8423497676849365
Validation loss: 2.248851619740968

Epoch: 6| Step: 11
Training loss: 2.5739192962646484
Validation loss: 2.265611784432524

Epoch: 6| Step: 12
Training loss: 1.7142791748046875
Validation loss: 2.2963498330885366

Epoch: 6| Step: 13
Training loss: 2.6547045707702637
Validation loss: 2.3555838882282214

Epoch: 40| Step: 0
Training loss: 1.8257057666778564
Validation loss: 2.374288402577882

Epoch: 6| Step: 1
Training loss: 2.6506094932556152
Validation loss: 2.373048041456489

Epoch: 6| Step: 2
Training loss: 2.3713998794555664
Validation loss: 2.3529842463872765

Epoch: 6| Step: 3
Training loss: 2.0164875984191895
Validation loss: 2.3352780034465175

Epoch: 6| Step: 4
Training loss: 2.8600685596466064
Validation loss: 2.31914016508287

Epoch: 6| Step: 5
Training loss: 2.611351490020752
Validation loss: 2.3070820070082143

Epoch: 6| Step: 6
Training loss: 3.1027586460113525
Validation loss: 2.279150393701369

Epoch: 6| Step: 7
Training loss: 2.8896422386169434
Validation loss: 2.2569367936862412

Epoch: 6| Step: 8
Training loss: 2.8940911293029785
Validation loss: 2.2528181998960433

Epoch: 6| Step: 9
Training loss: 2.5304481983184814
Validation loss: 2.2621611484917263

Epoch: 6| Step: 10
Training loss: 2.314819812774658
Validation loss: 2.2850988705952964

Epoch: 6| Step: 11
Training loss: 2.836775302886963
Validation loss: 2.340072670290547

Epoch: 6| Step: 12
Training loss: 2.5980682373046875
Validation loss: 2.43111773203778

Epoch: 6| Step: 13
Training loss: 2.7725601196289062
Validation loss: 2.387535677161268

Epoch: 41| Step: 0
Training loss: 1.7411946058273315
Validation loss: 2.3519233247285247

Epoch: 6| Step: 1
Training loss: 2.7057576179504395
Validation loss: 2.350537079636769

Epoch: 6| Step: 2
Training loss: 2.6497280597686768
Validation loss: 2.3101892778950353

Epoch: 6| Step: 3
Training loss: 2.951294422149658
Validation loss: 2.258628081249934

Epoch: 6| Step: 4
Training loss: 2.221548557281494
Validation loss: 2.2478861578049196

Epoch: 6| Step: 5
Training loss: 3.345090389251709
Validation loss: 2.2392537965569446

Epoch: 6| Step: 6
Training loss: 2.9951119422912598
Validation loss: 2.2369867909339165

Epoch: 6| Step: 7
Training loss: 2.867727041244507
Validation loss: 2.2334948688425045

Epoch: 6| Step: 8
Training loss: 2.4314210414886475
Validation loss: 2.2442226230457263

Epoch: 6| Step: 9
Training loss: 1.8393808603286743
Validation loss: 2.2626743188468357

Epoch: 6| Step: 10
Training loss: 2.761963367462158
Validation loss: 2.2700515972670687

Epoch: 6| Step: 11
Training loss: 2.3605315685272217
Validation loss: 2.2731149273533977

Epoch: 6| Step: 12
Training loss: 2.08085560798645
Validation loss: 2.2581666438810286

Epoch: 6| Step: 13
Training loss: 3.2711267471313477
Validation loss: 2.2510545945936635

Epoch: 42| Step: 0
Training loss: 2.528853178024292
Validation loss: 2.240471948859512

Epoch: 6| Step: 1
Training loss: 2.844043254852295
Validation loss: 2.2446288601044686

Epoch: 6| Step: 2
Training loss: 2.4963555335998535
Validation loss: 2.2472298247839815

Epoch: 6| Step: 3
Training loss: 2.579465389251709
Validation loss: 2.2502540747324624

Epoch: 6| Step: 4
Training loss: 2.458761692047119
Validation loss: 2.2657249537847375

Epoch: 6| Step: 5
Training loss: 2.6680989265441895
Validation loss: 2.266864509992702

Epoch: 6| Step: 6
Training loss: 2.633664608001709
Validation loss: 2.2999661763509116

Epoch: 6| Step: 7
Training loss: 2.0404410362243652
Validation loss: 2.323065960279075

Epoch: 6| Step: 8
Training loss: 2.7032337188720703
Validation loss: 2.3301462204225603

Epoch: 6| Step: 9
Training loss: 2.115086317062378
Validation loss: 2.319599587430236

Epoch: 6| Step: 10
Training loss: 2.2096052169799805
Validation loss: 2.296333997480331

Epoch: 6| Step: 11
Training loss: 2.9297094345092773
Validation loss: 2.2845630415024294

Epoch: 6| Step: 12
Training loss: 2.366807699203491
Validation loss: 2.2709031720315256

Epoch: 6| Step: 13
Training loss: 3.0631492137908936
Validation loss: 2.264946383814658

Epoch: 43| Step: 0
Training loss: 3.312920093536377
Validation loss: 2.2543049858462427

Epoch: 6| Step: 1
Training loss: 2.4953131675720215
Validation loss: 2.259254645275813

Epoch: 6| Step: 2
Training loss: 2.3894762992858887
Validation loss: 2.27256057852058

Epoch: 6| Step: 3
Training loss: 2.8320157527923584
Validation loss: 2.2901925476648475

Epoch: 6| Step: 4
Training loss: 3.002605438232422
Validation loss: 2.3208659566858763

Epoch: 6| Step: 5
Training loss: 2.4962339401245117
Validation loss: 2.340868539707635

Epoch: 6| Step: 6
Training loss: 1.8230808973312378
Validation loss: 2.3507111200722317

Epoch: 6| Step: 7
Training loss: 3.093341827392578
Validation loss: 2.3324662998158443

Epoch: 6| Step: 8
Training loss: 2.3202600479125977
Validation loss: 2.329493973844795

Epoch: 6| Step: 9
Training loss: 2.5869617462158203
Validation loss: 2.2889556090037027

Epoch: 6| Step: 10
Training loss: 2.1994595527648926
Validation loss: 2.2498419207911335

Epoch: 6| Step: 11
Training loss: 1.929823398590088
Validation loss: 2.230955159792336

Epoch: 6| Step: 12
Training loss: 2.4090323448181152
Validation loss: 2.2137624448345554

Epoch: 6| Step: 13
Training loss: 2.322449207305908
Validation loss: 2.2038398442729825

Epoch: 44| Step: 0
Training loss: 2.6685738563537598
Validation loss: 2.195843732485207

Epoch: 6| Step: 1
Training loss: 1.9785126447677612
Validation loss: 2.1926906647220736

Epoch: 6| Step: 2
Training loss: 2.591447353363037
Validation loss: 2.193558824959622

Epoch: 6| Step: 3
Training loss: 2.946430206298828
Validation loss: 2.1921430351913616

Epoch: 6| Step: 4
Training loss: 2.7790887355804443
Validation loss: 2.1889037778300624

Epoch: 6| Step: 5
Training loss: 1.9087551832199097
Validation loss: 2.1908919272884244

Epoch: 6| Step: 6
Training loss: 2.9504401683807373
Validation loss: 2.1954183629764024

Epoch: 6| Step: 7
Training loss: 2.87209415435791
Validation loss: 2.213560060788226

Epoch: 6| Step: 8
Training loss: 2.692821502685547
Validation loss: 2.221519368951039

Epoch: 6| Step: 9
Training loss: 2.288921594619751
Validation loss: 2.217462352527085

Epoch: 6| Step: 10
Training loss: 2.493739366531372
Validation loss: 2.2256602676965858

Epoch: 6| Step: 11
Training loss: 2.0107150077819824
Validation loss: 2.215621430386779

Epoch: 6| Step: 12
Training loss: 2.2054390907287598
Validation loss: 2.2416838189607025

Epoch: 6| Step: 13
Training loss: 3.2740063667297363
Validation loss: 2.2327922800535798

Epoch: 45| Step: 0
Training loss: 1.962038516998291
Validation loss: 2.2143505773236676

Epoch: 6| Step: 1
Training loss: 2.2819886207580566
Validation loss: 2.211334122124539

Epoch: 6| Step: 2
Training loss: 3.3133363723754883
Validation loss: 2.205854614575704

Epoch: 6| Step: 3
Training loss: 2.1034533977508545
Validation loss: 2.2018767838836997

Epoch: 6| Step: 4
Training loss: 2.2000749111175537
Validation loss: 2.2020967711684523

Epoch: 6| Step: 5
Training loss: 2.8587095737457275
Validation loss: 2.196585221957135

Epoch: 6| Step: 6
Training loss: 2.785256862640381
Validation loss: 2.1972706420447237

Epoch: 6| Step: 7
Training loss: 2.5638318061828613
Validation loss: 2.196838043069327

Epoch: 6| Step: 8
Training loss: 2.498032808303833
Validation loss: 2.201891770926855

Epoch: 6| Step: 9
Training loss: 3.060497283935547
Validation loss: 2.211394145924558

Epoch: 6| Step: 10
Training loss: 2.892855644226074
Validation loss: 2.202238380268056

Epoch: 6| Step: 11
Training loss: 1.877485990524292
Validation loss: 2.1947497808805077

Epoch: 6| Step: 12
Training loss: 1.926522970199585
Validation loss: 2.205435922068934

Epoch: 6| Step: 13
Training loss: 2.7825734615325928
Validation loss: 2.214407577309557

Epoch: 46| Step: 0
Training loss: 1.8225561380386353
Validation loss: 2.226616049325594

Epoch: 6| Step: 1
Training loss: 2.313119649887085
Validation loss: 2.241999803050872

Epoch: 6| Step: 2
Training loss: 3.033633232116699
Validation loss: 2.2513877832761375

Epoch: 6| Step: 3
Training loss: 2.4017157554626465
Validation loss: 2.248829536540534

Epoch: 6| Step: 4
Training loss: 3.212649345397949
Validation loss: 2.237300544656733

Epoch: 6| Step: 5
Training loss: 2.2765188217163086
Validation loss: 2.235853461809056

Epoch: 6| Step: 6
Training loss: 3.01701021194458
Validation loss: 2.235642707476052

Epoch: 6| Step: 7
Training loss: 2.040339708328247
Validation loss: 2.2317412207203526

Epoch: 6| Step: 8
Training loss: 2.8431901931762695
Validation loss: 2.228345447970975

Epoch: 6| Step: 9
Training loss: 2.428985118865967
Validation loss: 2.222373970093266

Epoch: 6| Step: 10
Training loss: 1.9996167421340942
Validation loss: 2.229746672414964

Epoch: 6| Step: 11
Training loss: 2.485743999481201
Validation loss: 2.223996662324475

Epoch: 6| Step: 12
Training loss: 2.3113019466400146
Validation loss: 2.2013152389116186

Epoch: 6| Step: 13
Training loss: 3.0538852214813232
Validation loss: 2.1913569486269386

Epoch: 47| Step: 0
Training loss: 2.532649040222168
Validation loss: 2.188808333489203

Epoch: 6| Step: 1
Training loss: 2.32958984375
Validation loss: 2.1899997316380984

Epoch: 6| Step: 2
Training loss: 3.174612522125244
Validation loss: 2.1836143949980378

Epoch: 6| Step: 3
Training loss: 2.527808904647827
Validation loss: 2.176433790114618

Epoch: 6| Step: 4
Training loss: 2.131770610809326
Validation loss: 2.1807426919219313

Epoch: 6| Step: 5
Training loss: 2.348266363143921
Validation loss: 2.174544544630153

Epoch: 6| Step: 6
Training loss: 2.678236961364746
Validation loss: 2.1780471571030153

Epoch: 6| Step: 7
Training loss: 2.564225196838379
Validation loss: 2.170678448933427

Epoch: 6| Step: 8
Training loss: 2.6687588691711426
Validation loss: 2.177292272608767

Epoch: 6| Step: 9
Training loss: 2.7355570793151855
Validation loss: 2.1879266077472317

Epoch: 6| Step: 10
Training loss: 2.202815294265747
Validation loss: 2.2035998170093825

Epoch: 6| Step: 11
Training loss: 2.3146755695343018
Validation loss: 2.2340972013370965

Epoch: 6| Step: 12
Training loss: 2.170078992843628
Validation loss: 2.2772017730179654

Epoch: 6| Step: 13
Training loss: 2.2415342330932617
Validation loss: 2.3190367170559463

Epoch: 48| Step: 0
Training loss: 2.0712239742279053
Validation loss: 2.3527901044455906

Epoch: 6| Step: 1
Training loss: 2.3198819160461426
Validation loss: 2.359102515764134

Epoch: 6| Step: 2
Training loss: 2.4896719455718994
Validation loss: 2.3424041989029094

Epoch: 6| Step: 3
Training loss: 2.8185458183288574
Validation loss: 2.3192041996986634

Epoch: 6| Step: 4
Training loss: 2.8073058128356934
Validation loss: 2.291144242850683

Epoch: 6| Step: 5
Training loss: 2.2383716106414795
Validation loss: 2.235622000950639

Epoch: 6| Step: 6
Training loss: 2.5783262252807617
Validation loss: 2.206014770333485

Epoch: 6| Step: 7
Training loss: 2.566318988800049
Validation loss: 2.1674105736517135

Epoch: 6| Step: 8
Training loss: 2.817512035369873
Validation loss: 2.159916462436799

Epoch: 6| Step: 9
Training loss: 3.0768234729766846
Validation loss: 2.156901978677319

Epoch: 6| Step: 10
Training loss: 2.236448287963867
Validation loss: 2.1751130063046693

Epoch: 6| Step: 11
Training loss: 2.931034564971924
Validation loss: 2.1942203147436983

Epoch: 6| Step: 12
Training loss: 2.02793288230896
Validation loss: 2.194736985750096

Epoch: 6| Step: 13
Training loss: 2.440572738647461
Validation loss: 2.2101231903158207

Epoch: 49| Step: 0
Training loss: 1.6317870616912842
Validation loss: 2.2122332331954793

Epoch: 6| Step: 1
Training loss: 2.05806827545166
Validation loss: 2.213033369792405

Epoch: 6| Step: 2
Training loss: 2.668597936630249
Validation loss: 2.2180158579221336

Epoch: 6| Step: 3
Training loss: 1.8461010456085205
Validation loss: 2.231221673309162

Epoch: 6| Step: 4
Training loss: 2.5855653285980225
Validation loss: 2.306343306777298

Epoch: 6| Step: 5
Training loss: 3.100800037384033
Validation loss: 2.333258531426871

Epoch: 6| Step: 6
Training loss: 3.1449174880981445
Validation loss: 2.303059967615271

Epoch: 6| Step: 7
Training loss: 2.4674739837646484
Validation loss: 2.230967742140575

Epoch: 6| Step: 8
Training loss: 2.1421456336975098
Validation loss: 2.1977752767583376

Epoch: 6| Step: 9
Training loss: 2.6375060081481934
Validation loss: 2.1558620083716606

Epoch: 6| Step: 10
Training loss: 2.211632490158081
Validation loss: 2.1501815216515654

Epoch: 6| Step: 11
Training loss: 2.7624988555908203
Validation loss: 2.147827999566191

Epoch: 6| Step: 12
Training loss: 3.381946563720703
Validation loss: 2.153149092069236

Epoch: 6| Step: 13
Training loss: 2.1331570148468018
Validation loss: 2.1612237217605754

Epoch: 50| Step: 0
Training loss: 2.29563307762146
Validation loss: 2.1555527820382068

Epoch: 6| Step: 1
Training loss: 2.872992992401123
Validation loss: 2.153125996230751

Epoch: 6| Step: 2
Training loss: 3.0862507820129395
Validation loss: 2.157381724285823

Epoch: 6| Step: 3
Training loss: 2.541100263595581
Validation loss: 2.154049413178557

Epoch: 6| Step: 4
Training loss: 2.2843427658081055
Validation loss: 2.1573234693978423

Epoch: 6| Step: 5
Training loss: 1.9002121686935425
Validation loss: 2.152503646830077

Epoch: 6| Step: 6
Training loss: 2.605555772781372
Validation loss: 2.154854484783706

Epoch: 6| Step: 7
Training loss: 1.713944911956787
Validation loss: 2.1590207648533646

Epoch: 6| Step: 8
Training loss: 2.4452974796295166
Validation loss: 2.1683514066921767

Epoch: 6| Step: 9
Training loss: 2.7401938438415527
Validation loss: 2.1730492986658567

Epoch: 6| Step: 10
Training loss: 2.5011656284332275
Validation loss: 2.1858716216138614

Epoch: 6| Step: 11
Training loss: 2.4170989990234375
Validation loss: 2.207001592523308

Epoch: 6| Step: 12
Training loss: 2.477646827697754
Validation loss: 2.216840810673211

Epoch: 6| Step: 13
Training loss: 3.003654718399048
Validation loss: 2.225001505626145

Epoch: 51| Step: 0
Training loss: 2.6373674869537354
Validation loss: 2.222570350093226

Epoch: 6| Step: 1
Training loss: 2.52368426322937
Validation loss: 2.2123930390163133

Epoch: 6| Step: 2
Training loss: 2.902977466583252
Validation loss: 2.2078851243501068

Epoch: 6| Step: 3
Training loss: 2.6358346939086914
Validation loss: 2.204112636145725

Epoch: 6| Step: 4
Training loss: 2.2391252517700195
Validation loss: 2.1994682986249208

Epoch: 6| Step: 5
Training loss: 2.6122474670410156
Validation loss: 2.202196660862174

Epoch: 6| Step: 6
Training loss: 2.5748205184936523
Validation loss: 2.2079288318593013

Epoch: 6| Step: 7
Training loss: 2.5275423526763916
Validation loss: 2.200071357911633

Epoch: 6| Step: 8
Training loss: 2.9887728691101074
Validation loss: 2.184951633535406

Epoch: 6| Step: 9
Training loss: 2.264253616333008
Validation loss: 2.1638924306438816

Epoch: 6| Step: 10
Training loss: 2.1205105781555176
Validation loss: 2.1649314767570904

Epoch: 6| Step: 11
Training loss: 2.927184581756592
Validation loss: 2.1521802435639086

Epoch: 6| Step: 12
Training loss: 1.6204807758331299
Validation loss: 2.1479030091275453

Epoch: 6| Step: 13
Training loss: 1.436310887336731
Validation loss: 2.1527894671245287

Epoch: 52| Step: 0
Training loss: 2.2667198181152344
Validation loss: 2.165721226763982

Epoch: 6| Step: 1
Training loss: 1.9876810312271118
Validation loss: 2.187599060355976

Epoch: 6| Step: 2
Training loss: 2.5217385292053223
Validation loss: 2.234911113656977

Epoch: 6| Step: 3
Training loss: 2.4159581661224365
Validation loss: 2.2360351547118156

Epoch: 6| Step: 4
Training loss: 2.502023696899414
Validation loss: 2.208368045027538

Epoch: 6| Step: 5
Training loss: 2.695537567138672
Validation loss: 2.178432818382017

Epoch: 6| Step: 6
Training loss: 2.6218695640563965
Validation loss: 2.1728206065393265

Epoch: 6| Step: 7
Training loss: 1.9121590852737427
Validation loss: 2.1550595016889673

Epoch: 6| Step: 8
Training loss: 2.627751588821411
Validation loss: 2.1590429877722137

Epoch: 6| Step: 9
Training loss: 2.383798360824585
Validation loss: 2.1495352765565277

Epoch: 6| Step: 10
Training loss: 2.3072924613952637
Validation loss: 2.1479822512595885

Epoch: 6| Step: 11
Training loss: 2.5364928245544434
Validation loss: 2.146857435985278

Epoch: 6| Step: 12
Training loss: 3.283249616622925
Validation loss: 2.160910068019744

Epoch: 6| Step: 13
Training loss: 2.582247257232666
Validation loss: 2.175071936781688

Epoch: 53| Step: 0
Training loss: 2.6040515899658203
Validation loss: 2.2095981695318736

Epoch: 6| Step: 1
Training loss: 2.711625576019287
Validation loss: 2.214628041431468

Epoch: 6| Step: 2
Training loss: 2.6484549045562744
Validation loss: 2.2276806241722515

Epoch: 6| Step: 3
Training loss: 1.6766717433929443
Validation loss: 2.2485281139291744

Epoch: 6| Step: 4
Training loss: 1.9249446392059326
Validation loss: 2.2555354192692745

Epoch: 6| Step: 5
Training loss: 2.8991708755493164
Validation loss: 2.2562669451518724

Epoch: 6| Step: 6
Training loss: 1.9631565809249878
Validation loss: 2.2284195320580595

Epoch: 6| Step: 7
Training loss: 2.7923474311828613
Validation loss: 2.2185738214882473

Epoch: 6| Step: 8
Training loss: 2.719142436981201
Validation loss: 2.207544772855697

Epoch: 6| Step: 9
Training loss: 2.3356008529663086
Validation loss: 2.1807484575497207

Epoch: 6| Step: 10
Training loss: 2.625422477722168
Validation loss: 2.1547830412464757

Epoch: 6| Step: 11
Training loss: 3.135092258453369
Validation loss: 2.1434000153695383

Epoch: 6| Step: 12
Training loss: 1.8432878255844116
Validation loss: 2.1275831268679712

Epoch: 6| Step: 13
Training loss: 2.551011085510254
Validation loss: 2.127732082079816

Epoch: 54| Step: 0
Training loss: 2.4312527179718018
Validation loss: 2.1302403519230504

Epoch: 6| Step: 1
Training loss: 2.275313377380371
Validation loss: 2.1367123062892626

Epoch: 6| Step: 2
Training loss: 2.7833099365234375
Validation loss: 2.134494637930265

Epoch: 6| Step: 3
Training loss: 2.0397753715515137
Validation loss: 2.1487579550794376

Epoch: 6| Step: 4
Training loss: 2.3385140895843506
Validation loss: 2.171875156382079

Epoch: 6| Step: 5
Training loss: 1.9834214448928833
Validation loss: 2.1822013752434843

Epoch: 6| Step: 6
Training loss: 2.366347312927246
Validation loss: 2.1891446113586426

Epoch: 6| Step: 7
Training loss: 2.896979808807373
Validation loss: 2.1829307476679483

Epoch: 6| Step: 8
Training loss: 2.497711181640625
Validation loss: 2.163314107925661

Epoch: 6| Step: 9
Training loss: 2.4711179733276367
Validation loss: 2.172649037453436

Epoch: 6| Step: 10
Training loss: 2.711148738861084
Validation loss: 2.1763107276731923

Epoch: 6| Step: 11
Training loss: 2.176872730255127
Validation loss: 2.1831710876957064

Epoch: 6| Step: 12
Training loss: 2.5776548385620117
Validation loss: 2.1756904407214095

Epoch: 6| Step: 13
Training loss: 2.7932653427124023
Validation loss: 2.1904468882468437

Epoch: 55| Step: 0
Training loss: 3.182811737060547
Validation loss: 2.1832643965239167

Epoch: 6| Step: 1
Training loss: 2.772512912750244
Validation loss: 2.2009258603536956

Epoch: 6| Step: 2
Training loss: 2.2113213539123535
Validation loss: 2.2009733159054994

Epoch: 6| Step: 3
Training loss: 2.2801878452301025
Validation loss: 2.2065125614084224

Epoch: 6| Step: 4
Training loss: 2.0232465267181396
Validation loss: 2.1898037618206394

Epoch: 6| Step: 5
Training loss: 1.984748363494873
Validation loss: 2.170743521823678

Epoch: 6| Step: 6
Training loss: 2.2864186763763428
Validation loss: 2.1450953816854827

Epoch: 6| Step: 7
Training loss: 2.3907341957092285
Validation loss: 2.1424702482838787

Epoch: 6| Step: 8
Training loss: 2.142010450363159
Validation loss: 2.1451226549763835

Epoch: 6| Step: 9
Training loss: 2.6449460983276367
Validation loss: 2.142018151539628

Epoch: 6| Step: 10
Training loss: 2.3561019897460938
Validation loss: 2.1378129592505832

Epoch: 6| Step: 11
Training loss: 2.761478900909424
Validation loss: 2.1392551109354985

Epoch: 6| Step: 12
Training loss: 2.4063844680786133
Validation loss: 2.148418785423361

Epoch: 6| Step: 13
Training loss: 2.659855842590332
Validation loss: 2.1429431438446045

Epoch: 56| Step: 0
Training loss: 2.138996124267578
Validation loss: 2.1488858910017115

Epoch: 6| Step: 1
Training loss: 2.2136359214782715
Validation loss: 2.157702548529512

Epoch: 6| Step: 2
Training loss: 2.515678644180298
Validation loss: 2.160532328390306

Epoch: 6| Step: 3
Training loss: 2.4750802516937256
Validation loss: 2.169873849038155

Epoch: 6| Step: 4
Training loss: 2.5832996368408203
Validation loss: 2.1676874288948635

Epoch: 6| Step: 5
Training loss: 2.3401756286621094
Validation loss: 2.164554665165563

Epoch: 6| Step: 6
Training loss: 2.1646125316619873
Validation loss: 2.152559221431773

Epoch: 6| Step: 7
Training loss: 1.9858981370925903
Validation loss: 2.183494649907594

Epoch: 6| Step: 8
Training loss: 1.9832379817962646
Validation loss: 2.1977768508336877

Epoch: 6| Step: 9
Training loss: 2.3813350200653076
Validation loss: 2.2356186271995626

Epoch: 6| Step: 10
Training loss: 3.176248550415039
Validation loss: 2.2278115159721783

Epoch: 6| Step: 11
Training loss: 2.378096580505371
Validation loss: 2.2164514090425227

Epoch: 6| Step: 12
Training loss: 3.00250506401062
Validation loss: 2.1927737574423514

Epoch: 6| Step: 13
Training loss: 2.9460043907165527
Validation loss: 2.152780591800649

Epoch: 57| Step: 0
Training loss: 1.815629243850708
Validation loss: 2.1227338621693272

Epoch: 6| Step: 1
Training loss: 2.801370859146118
Validation loss: 2.1122218690892702

Epoch: 6| Step: 2
Training loss: 2.436525344848633
Validation loss: 2.1206240525809665

Epoch: 6| Step: 3
Training loss: 2.4886770248413086
Validation loss: 2.128294085943571

Epoch: 6| Step: 4
Training loss: 2.0949349403381348
Validation loss: 2.137134236674155

Epoch: 6| Step: 5
Training loss: 2.1110918521881104
Validation loss: 2.1518372848469722

Epoch: 6| Step: 6
Training loss: 2.199310779571533
Validation loss: 2.1615148462275022

Epoch: 6| Step: 7
Training loss: 2.662031650543213
Validation loss: 2.166247747277701

Epoch: 6| Step: 8
Training loss: 2.7229409217834473
Validation loss: 2.165920115286304

Epoch: 6| Step: 9
Training loss: 2.294269323348999
Validation loss: 2.1644267292432886

Epoch: 6| Step: 10
Training loss: 2.6148340702056885
Validation loss: 2.154757063875916

Epoch: 6| Step: 11
Training loss: 2.667001724243164
Validation loss: 2.1460750743906987

Epoch: 6| Step: 12
Training loss: 3.012481689453125
Validation loss: 2.1505354604413434

Epoch: 6| Step: 13
Training loss: 3.036566734313965
Validation loss: 2.1552686588738554

Epoch: 58| Step: 0
Training loss: 2.241156816482544
Validation loss: 2.171961348543885

Epoch: 6| Step: 1
Training loss: 2.2976555824279785
Validation loss: 2.1907375884312454

Epoch: 6| Step: 2
Training loss: 2.7976324558258057
Validation loss: 2.2192664736060688

Epoch: 6| Step: 3
Training loss: 2.0585341453552246
Validation loss: 2.2441373666127524

Epoch: 6| Step: 4
Training loss: 2.40008807182312
Validation loss: 2.2553107020675496

Epoch: 6| Step: 5
Training loss: 2.8129215240478516
Validation loss: 2.2688162890813683

Epoch: 6| Step: 6
Training loss: 2.6983940601348877
Validation loss: 2.3049838030210106

Epoch: 6| Step: 7
Training loss: 3.2822813987731934
Validation loss: 2.348213429092079

Epoch: 6| Step: 8
Training loss: 2.7464330196380615
Validation loss: 2.3947531741152526

Epoch: 6| Step: 9
Training loss: 2.260300636291504
Validation loss: 2.409746136716617

Epoch: 6| Step: 10
Training loss: 2.5570058822631836
Validation loss: 2.3856587025427047

Epoch: 6| Step: 11
Training loss: 2.168935775756836
Validation loss: 2.361369622650967

Epoch: 6| Step: 12
Training loss: 2.3182148933410645
Validation loss: 2.299633792651597

Epoch: 6| Step: 13
Training loss: 2.6124255657196045
Validation loss: 2.236459691037414

Epoch: 59| Step: 0
Training loss: 2.256575584411621
Validation loss: 2.173466441451862

Epoch: 6| Step: 1
Training loss: 1.9919008016586304
Validation loss: 2.138759510491484

Epoch: 6| Step: 2
Training loss: 2.415477752685547
Validation loss: 2.1250491731910297

Epoch: 6| Step: 3
Training loss: 2.3274126052856445
Validation loss: 2.118571965925155

Epoch: 6| Step: 4
Training loss: 2.270566701889038
Validation loss: 2.116619510035361

Epoch: 6| Step: 5
Training loss: 2.1547610759735107
Validation loss: 2.1176670417990735

Epoch: 6| Step: 6
Training loss: 2.288179874420166
Validation loss: 2.12027431303455

Epoch: 6| Step: 7
Training loss: 2.783250331878662
Validation loss: 2.1354234705689135

Epoch: 6| Step: 8
Training loss: 2.18863582611084
Validation loss: 2.1376257583659184

Epoch: 6| Step: 9
Training loss: 2.8358049392700195
Validation loss: 2.1512107926030315

Epoch: 6| Step: 10
Training loss: 2.128836154937744
Validation loss: 2.155260509060275

Epoch: 6| Step: 11
Training loss: 2.9206736087799072
Validation loss: 2.16108303172614

Epoch: 6| Step: 12
Training loss: 2.6973202228546143
Validation loss: 2.150558679334579

Epoch: 6| Step: 13
Training loss: 3.04758358001709
Validation loss: 2.1570471217555385

Epoch: 60| Step: 0
Training loss: 2.2100868225097656
Validation loss: 2.160058811146726

Epoch: 6| Step: 1
Training loss: 2.700976610183716
Validation loss: 2.152813547401018

Epoch: 6| Step: 2
Training loss: 3.203834295272827
Validation loss: 2.1418596980392293

Epoch: 6| Step: 3
Training loss: 2.3213233947753906
Validation loss: 2.1303911568016134

Epoch: 6| Step: 4
Training loss: 2.1356325149536133
Validation loss: 2.1494004572591474

Epoch: 6| Step: 5
Training loss: 2.784053325653076
Validation loss: 2.144235163606623

Epoch: 6| Step: 6
Training loss: 2.7092981338500977
Validation loss: 2.1620369213883595

Epoch: 6| Step: 7
Training loss: 1.705808162689209
Validation loss: 2.1747000832711496

Epoch: 6| Step: 8
Training loss: 2.423985481262207
Validation loss: 2.167989892344321

Epoch: 6| Step: 9
Training loss: 2.565363883972168
Validation loss: 2.146645156286096

Epoch: 6| Step: 10
Training loss: 2.3764524459838867
Validation loss: 2.105384701041765

Epoch: 6| Step: 11
Training loss: 2.33651065826416
Validation loss: 2.099409641758088

Epoch: 6| Step: 12
Training loss: 2.1556804180145264
Validation loss: 2.097371703834944

Epoch: 6| Step: 13
Training loss: 2.193441390991211
Validation loss: 2.0931458537296583

Epoch: 61| Step: 0
Training loss: 2.2285706996917725
Validation loss: 2.089188737253989

Epoch: 6| Step: 1
Training loss: 2.270960569381714
Validation loss: 2.0919891083112327

Epoch: 6| Step: 2
Training loss: 2.6712751388549805
Validation loss: 2.0956566461952786

Epoch: 6| Step: 3
Training loss: 1.821916937828064
Validation loss: 2.1032580739708355

Epoch: 6| Step: 4
Training loss: 3.2905282974243164
Validation loss: 2.101557634210074

Epoch: 6| Step: 5
Training loss: 2.161240577697754
Validation loss: 2.107609236112205

Epoch: 6| Step: 6
Training loss: 2.683030843734741
Validation loss: 2.116874506396632

Epoch: 6| Step: 7
Training loss: 2.411163806915283
Validation loss: 2.1115631672643844

Epoch: 6| Step: 8
Training loss: 1.9803261756896973
Validation loss: 2.105055255274619

Epoch: 6| Step: 9
Training loss: 1.9562854766845703
Validation loss: 2.107756012229509

Epoch: 6| Step: 10
Training loss: 2.6080217361450195
Validation loss: 2.1273262218762468

Epoch: 6| Step: 11
Training loss: 2.694141149520874
Validation loss: 2.1509041324738534

Epoch: 6| Step: 12
Training loss: 2.717733383178711
Validation loss: 2.2134800290548675

Epoch: 6| Step: 13
Training loss: 1.9482485055923462
Validation loss: 2.2574464531355005

Epoch: 62| Step: 0
Training loss: 2.0683813095092773
Validation loss: 2.2921666586270897

Epoch: 6| Step: 1
Training loss: 2.9884579181671143
Validation loss: 2.269682699634183

Epoch: 6| Step: 2
Training loss: 1.920637607574463
Validation loss: 2.2277575257003948

Epoch: 6| Step: 3
Training loss: 2.2121334075927734
Validation loss: 2.15901961634236

Epoch: 6| Step: 4
Training loss: 2.550297737121582
Validation loss: 2.1459754487519622

Epoch: 6| Step: 5
Training loss: 2.3430440425872803
Validation loss: 2.108314275741577

Epoch: 6| Step: 6
Training loss: 2.767129421234131
Validation loss: 2.107052710748488

Epoch: 6| Step: 7
Training loss: 2.201132297515869
Validation loss: 2.1130160900854293

Epoch: 6| Step: 8
Training loss: 2.1921839714050293
Validation loss: 2.123464003685982

Epoch: 6| Step: 9
Training loss: 2.804391622543335
Validation loss: 2.111773772906232

Epoch: 6| Step: 10
Training loss: 2.188481569290161
Validation loss: 2.115248305823213

Epoch: 6| Step: 11
Training loss: 3.0314722061157227
Validation loss: 2.1167397396538847

Epoch: 6| Step: 12
Training loss: 1.9278147220611572
Validation loss: 2.109742133848129

Epoch: 6| Step: 13
Training loss: 2.92615008354187
Validation loss: 2.1228736472386185

Epoch: 63| Step: 0
Training loss: 2.1856346130371094
Validation loss: 2.1277678628121652

Epoch: 6| Step: 1
Training loss: 2.2968292236328125
Validation loss: 2.1608666348200973

Epoch: 6| Step: 2
Training loss: 1.8039865493774414
Validation loss: 2.1689511319642425

Epoch: 6| Step: 3
Training loss: 2.9054970741271973
Validation loss: 2.173622133911297

Epoch: 6| Step: 4
Training loss: 1.9144514799118042
Validation loss: 2.170784224746048

Epoch: 6| Step: 5
Training loss: 2.1179347038269043
Validation loss: 2.1396483426452964

Epoch: 6| Step: 6
Training loss: 2.7860612869262695
Validation loss: 2.1301423503506567

Epoch: 6| Step: 7
Training loss: 1.7405034303665161
Validation loss: 2.1218050692671087

Epoch: 6| Step: 8
Training loss: 2.57140851020813
Validation loss: 2.0983894781399797

Epoch: 6| Step: 9
Training loss: 2.486060857772827
Validation loss: 2.086574066069818

Epoch: 6| Step: 10
Training loss: 2.7672853469848633
Validation loss: 2.0831913845513457

Epoch: 6| Step: 11
Training loss: 2.6821494102478027
Validation loss: 2.08071247864795

Epoch: 6| Step: 12
Training loss: 3.0005531311035156
Validation loss: 2.0835662106032014

Epoch: 6| Step: 13
Training loss: 2.4350976943969727
Validation loss: 2.080342190240019

Epoch: 64| Step: 0
Training loss: 2.702443838119507
Validation loss: 2.081226025858233

Epoch: 6| Step: 1
Training loss: 1.9188687801361084
Validation loss: 2.0832017596049974

Epoch: 6| Step: 2
Training loss: 2.222588539123535
Validation loss: 2.0881925680304088

Epoch: 6| Step: 3
Training loss: 2.9102983474731445
Validation loss: 2.0939138922640073

Epoch: 6| Step: 4
Training loss: 2.2974438667297363
Validation loss: 2.1128946555558072

Epoch: 6| Step: 5
Training loss: 2.3550028800964355
Validation loss: 2.1396641936353458

Epoch: 6| Step: 6
Training loss: 2.2720108032226562
Validation loss: 2.127423942729991

Epoch: 6| Step: 7
Training loss: 2.5694761276245117
Validation loss: 2.115962178476395

Epoch: 6| Step: 8
Training loss: 2.8043527603149414
Validation loss: 2.095709039318946

Epoch: 6| Step: 9
Training loss: 2.1556873321533203
Validation loss: 2.091149009684081

Epoch: 6| Step: 10
Training loss: 2.2352051734924316
Validation loss: 2.089096601291369

Epoch: 6| Step: 11
Training loss: 1.9753752946853638
Validation loss: 2.0913729283117477

Epoch: 6| Step: 12
Training loss: 2.966212034225464
Validation loss: 2.0851023863720637

Epoch: 6| Step: 13
Training loss: 1.6855534315109253
Validation loss: 2.0877133979592273

Epoch: 65| Step: 0
Training loss: 2.3018240928649902
Validation loss: 2.1063555927686792

Epoch: 6| Step: 1
Training loss: 2.5894277095794678
Validation loss: 2.1164185975187566

Epoch: 6| Step: 2
Training loss: 2.7259349822998047
Validation loss: 2.1297942617888093

Epoch: 6| Step: 3
Training loss: 2.544675827026367
Validation loss: 2.1296200444621425

Epoch: 6| Step: 4
Training loss: 2.288369655609131
Validation loss: 2.127874325680476

Epoch: 6| Step: 5
Training loss: 1.7825108766555786
Validation loss: 2.132344303592559

Epoch: 6| Step: 6
Training loss: 2.130145788192749
Validation loss: 2.1079087424021896

Epoch: 6| Step: 7
Training loss: 2.213237762451172
Validation loss: 2.1046396634911977

Epoch: 6| Step: 8
Training loss: 2.4358551502227783
Validation loss: 2.1180832834653955

Epoch: 6| Step: 9
Training loss: 2.696932792663574
Validation loss: 2.1232870727457027

Epoch: 6| Step: 10
Training loss: 2.0091471672058105
Validation loss: 2.11407401997556

Epoch: 6| Step: 11
Training loss: 2.7139129638671875
Validation loss: 2.1034926163252963

Epoch: 6| Step: 12
Training loss: 2.6349096298217773
Validation loss: 2.08427942440074

Epoch: 6| Step: 13
Training loss: 2.40903377532959
Validation loss: 2.077103086697158

Epoch: 66| Step: 0
Training loss: 2.0445847511291504
Validation loss: 2.090996362829721

Epoch: 6| Step: 1
Training loss: 2.093062400817871
Validation loss: 2.1069081906349427

Epoch: 6| Step: 2
Training loss: 2.5104141235351562
Validation loss: 2.1220506647581696

Epoch: 6| Step: 3
Training loss: 2.186958074569702
Validation loss: 2.1170460844552643

Epoch: 6| Step: 4
Training loss: 2.188352584838867
Validation loss: 2.110611346460158

Epoch: 6| Step: 5
Training loss: 2.5633065700531006
Validation loss: 2.0952656192164265

Epoch: 6| Step: 6
Training loss: 2.9981632232666016
Validation loss: 2.0866515841535342

Epoch: 6| Step: 7
Training loss: 2.6135945320129395
Validation loss: 2.087654144533219

Epoch: 6| Step: 8
Training loss: 2.5793514251708984
Validation loss: 2.0829920371373496

Epoch: 6| Step: 9
Training loss: 2.320125102996826
Validation loss: 2.090973598982698

Epoch: 6| Step: 10
Training loss: 2.2186472415924072
Validation loss: 2.081566115861298

Epoch: 6| Step: 11
Training loss: 2.0941877365112305
Validation loss: 2.082244275718607

Epoch: 6| Step: 12
Training loss: 2.1336214542388916
Validation loss: 2.093766289372598

Epoch: 6| Step: 13
Training loss: 2.9046881198883057
Validation loss: 2.1122765669258694

Epoch: 67| Step: 0
Training loss: 2.52010440826416
Validation loss: 2.1264475391757105

Epoch: 6| Step: 1
Training loss: 2.5509955883026123
Validation loss: 2.1565251158129786

Epoch: 6| Step: 2
Training loss: 2.7565417289733887
Validation loss: 2.153072149522843

Epoch: 6| Step: 3
Training loss: 2.359673261642456
Validation loss: 2.16402837153404

Epoch: 6| Step: 4
Training loss: 2.653306722640991
Validation loss: 2.1360823159576743

Epoch: 6| Step: 5
Training loss: 2.691431999206543
Validation loss: 2.119983464158991

Epoch: 6| Step: 6
Training loss: 2.6452207565307617
Validation loss: 2.0971091331974154

Epoch: 6| Step: 7
Training loss: 2.4760727882385254
Validation loss: 2.0806627094104724

Epoch: 6| Step: 8
Training loss: 1.9524078369140625
Validation loss: 2.075639291476178

Epoch: 6| Step: 9
Training loss: 1.4667608737945557
Validation loss: 2.0834980728805705

Epoch: 6| Step: 10
Training loss: 2.4115853309631348
Validation loss: 2.076206386730235

Epoch: 6| Step: 11
Training loss: 1.9090607166290283
Validation loss: 2.084862001480595

Epoch: 6| Step: 12
Training loss: 1.7648283243179321
Validation loss: 2.0802098371649302

Epoch: 6| Step: 13
Training loss: 3.3542590141296387
Validation loss: 2.0765337726121307

Epoch: 68| Step: 0
Training loss: 2.4543704986572266
Validation loss: 2.0793752388287614

Epoch: 6| Step: 1
Training loss: 2.1779122352600098
Validation loss: 2.075713793436686

Epoch: 6| Step: 2
Training loss: 2.345531940460205
Validation loss: 2.072944147612459

Epoch: 6| Step: 3
Training loss: 2.710639476776123
Validation loss: 2.0714703349656958

Epoch: 6| Step: 4
Training loss: 2.513166904449463
Validation loss: 2.0778635727461947

Epoch: 6| Step: 5
Training loss: 2.2444076538085938
Validation loss: 2.0764738372577134

Epoch: 6| Step: 6
Training loss: 1.9740996360778809
Validation loss: 2.083403787305278

Epoch: 6| Step: 7
Training loss: 2.0936951637268066
Validation loss: 2.0920492013295493

Epoch: 6| Step: 8
Training loss: 2.34633207321167
Validation loss: 2.096264898136098

Epoch: 6| Step: 9
Training loss: 2.3965365886688232
Validation loss: 2.1021364145381476

Epoch: 6| Step: 10
Training loss: 1.9915860891342163
Validation loss: 2.115041980179407

Epoch: 6| Step: 11
Training loss: 2.1145358085632324
Validation loss: 2.1348435519843973

Epoch: 6| Step: 12
Training loss: 3.162778615951538
Validation loss: 2.154722805946104

Epoch: 6| Step: 13
Training loss: 2.624556303024292
Validation loss: 2.1737438401868268

Epoch: 69| Step: 0
Training loss: 1.8577115535736084
Validation loss: 2.169116352194099

Epoch: 6| Step: 1
Training loss: 2.5553698539733887
Validation loss: 2.1764659112499607

Epoch: 6| Step: 2
Training loss: 2.722464084625244
Validation loss: 2.153550861984171

Epoch: 6| Step: 3
Training loss: 2.3921799659729004
Validation loss: 2.140011954051192

Epoch: 6| Step: 4
Training loss: 2.649055004119873
Validation loss: 2.1176452828991796

Epoch: 6| Step: 5
Training loss: 2.860403299331665
Validation loss: 2.1137167971621276

Epoch: 6| Step: 6
Training loss: 2.051980972290039
Validation loss: 2.0968015142666396

Epoch: 6| Step: 7
Training loss: 2.332797050476074
Validation loss: 2.0958352101746427

Epoch: 6| Step: 8
Training loss: 2.1726632118225098
Validation loss: 2.0863133143353205

Epoch: 6| Step: 9
Training loss: 1.6003527641296387
Validation loss: 2.0846249723947174

Epoch: 6| Step: 10
Training loss: 2.78442645072937
Validation loss: 2.0798408997956144

Epoch: 6| Step: 11
Training loss: 1.8148069381713867
Validation loss: 2.065661125285651

Epoch: 6| Step: 12
Training loss: 2.632446527481079
Validation loss: 2.0662222472570275

Epoch: 6| Step: 13
Training loss: 2.923609972000122
Validation loss: 2.054797072564402

Epoch: 70| Step: 0
Training loss: 2.773334503173828
Validation loss: 2.0701147958796513

Epoch: 6| Step: 1
Training loss: 2.940659999847412
Validation loss: 2.065288353991765

Epoch: 6| Step: 2
Training loss: 1.8749957084655762
Validation loss: 2.064731705573297

Epoch: 6| Step: 3
Training loss: 2.981618881225586
Validation loss: 2.0755827170546337

Epoch: 6| Step: 4
Training loss: 2.308500289916992
Validation loss: 2.068404331002184

Epoch: 6| Step: 5
Training loss: 2.104689359664917
Validation loss: 2.0601439476013184

Epoch: 6| Step: 6
Training loss: 2.698561191558838
Validation loss: 2.0621590075954312

Epoch: 6| Step: 7
Training loss: 1.9143186807632446
Validation loss: 2.074958316741451

Epoch: 6| Step: 8
Training loss: 1.7521964311599731
Validation loss: 2.1036734401538806

Epoch: 6| Step: 9
Training loss: 2.246588706970215
Validation loss: 2.1414365332613707

Epoch: 6| Step: 10
Training loss: 3.0143938064575195
Validation loss: 2.177174041348119

Epoch: 6| Step: 11
Training loss: 2.5650062561035156
Validation loss: 2.1927831583125617

Epoch: 6| Step: 12
Training loss: 2.4152579307556152
Validation loss: 2.181605444159559

Epoch: 6| Step: 13
Training loss: 1.44895601272583
Validation loss: 2.1834518140362156

Epoch: 71| Step: 0
Training loss: 2.7501840591430664
Validation loss: 2.1560898583422423

Epoch: 6| Step: 1
Training loss: 1.2211861610412598
Validation loss: 2.1383872749984905

Epoch: 6| Step: 2
Training loss: 3.0550241470336914
Validation loss: 2.1200213714312484

Epoch: 6| Step: 3
Training loss: 2.160857677459717
Validation loss: 2.0971131837496193

Epoch: 6| Step: 4
Training loss: 2.6957387924194336
Validation loss: 2.0766884947335846

Epoch: 6| Step: 5
Training loss: 2.321784734725952
Validation loss: 2.0766732282536005

Epoch: 6| Step: 6
Training loss: 1.9922502040863037
Validation loss: 2.0824368102576143

Epoch: 6| Step: 7
Training loss: 2.7031283378601074
Validation loss: 2.081541786911667

Epoch: 6| Step: 8
Training loss: 2.8810713291168213
Validation loss: 2.079941657281691

Epoch: 6| Step: 9
Training loss: 2.421412229537964
Validation loss: 2.079094890625246

Epoch: 6| Step: 10
Training loss: 1.9560585021972656
Validation loss: 2.079476797452537

Epoch: 6| Step: 11
Training loss: 1.89484441280365
Validation loss: 2.0749940961919804

Epoch: 6| Step: 12
Training loss: 2.640371322631836
Validation loss: 2.0879860693408596

Epoch: 6| Step: 13
Training loss: 1.7876218557357788
Validation loss: 2.0849706588252896

Epoch: 72| Step: 0
Training loss: 2.264317035675049
Validation loss: 2.0870851188577633

Epoch: 6| Step: 1
Training loss: 2.2364654541015625
Validation loss: 2.0875446796417236

Epoch: 6| Step: 2
Training loss: 2.899151563644409
Validation loss: 2.0777010148571384

Epoch: 6| Step: 3
Training loss: 2.000352382659912
Validation loss: 2.07856108039938

Epoch: 6| Step: 4
Training loss: 2.281975269317627
Validation loss: 2.0803413057839997

Epoch: 6| Step: 5
Training loss: 2.8369436264038086
Validation loss: 2.074080144205401

Epoch: 6| Step: 6
Training loss: 2.6598119735717773
Validation loss: 2.0783119381115003

Epoch: 6| Step: 7
Training loss: 1.8872298002243042
Validation loss: 2.0625931511643114

Epoch: 6| Step: 8
Training loss: 2.407437562942505
Validation loss: 2.068852674576544

Epoch: 6| Step: 9
Training loss: 2.0786080360412598
Validation loss: 2.0581775019245763

Epoch: 6| Step: 10
Training loss: 1.7255055904388428
Validation loss: 2.055833037181567

Epoch: 6| Step: 11
Training loss: 2.4091873168945312
Validation loss: 2.072899441565237

Epoch: 6| Step: 12
Training loss: 2.4735770225524902
Validation loss: 2.0666398681620115

Epoch: 6| Step: 13
Training loss: 2.187652587890625
Validation loss: 2.062221465572234

Epoch: 73| Step: 0
Training loss: 1.8269586563110352
Validation loss: 2.059189813111418

Epoch: 6| Step: 1
Training loss: 2.38369083404541
Validation loss: 2.06407533666139

Epoch: 6| Step: 2
Training loss: 2.1838302612304688
Validation loss: 2.063583074077483

Epoch: 6| Step: 3
Training loss: 2.686270236968994
Validation loss: 2.0644405285517373

Epoch: 6| Step: 4
Training loss: 2.0501222610473633
Validation loss: 2.0588499217905025

Epoch: 6| Step: 5
Training loss: 2.3660013675689697
Validation loss: 2.068063884653071

Epoch: 6| Step: 6
Training loss: 2.320451021194458
Validation loss: 2.0618318562866538

Epoch: 6| Step: 7
Training loss: 2.6452620029449463
Validation loss: 2.0531630400688416

Epoch: 6| Step: 8
Training loss: 1.7164990901947021
Validation loss: 2.0531746777155067

Epoch: 6| Step: 9
Training loss: 2.3843181133270264
Validation loss: 2.058959968628422

Epoch: 6| Step: 10
Training loss: 2.7699222564697266
Validation loss: 2.058388488267058

Epoch: 6| Step: 11
Training loss: 2.038299083709717
Validation loss: 2.06183034886596

Epoch: 6| Step: 12
Training loss: 2.338061809539795
Validation loss: 2.072915804001593

Epoch: 6| Step: 13
Training loss: 2.961280345916748
Validation loss: 2.0817569609611266

Epoch: 74| Step: 0
Training loss: 2.7883191108703613
Validation loss: 2.0746479547151955

Epoch: 6| Step: 1
Training loss: 2.2342212200164795
Validation loss: 2.094087134125412

Epoch: 6| Step: 2
Training loss: 1.9692838191986084
Validation loss: 2.1020428519095145

Epoch: 6| Step: 3
Training loss: 2.604867935180664
Validation loss: 2.088174086745067

Epoch: 6| Step: 4
Training loss: 2.5463480949401855
Validation loss: 2.0998165222906295

Epoch: 6| Step: 5
Training loss: 2.51104736328125
Validation loss: 2.09962438255228

Epoch: 6| Step: 6
Training loss: 1.701359510421753
Validation loss: 2.0945880400237216

Epoch: 6| Step: 7
Training loss: 1.955924153327942
Validation loss: 2.1216221817078127

Epoch: 6| Step: 8
Training loss: 1.9260854721069336
Validation loss: 2.1182055152872556

Epoch: 6| Step: 9
Training loss: 2.7881596088409424
Validation loss: 2.106319437744797

Epoch: 6| Step: 10
Training loss: 2.636834144592285
Validation loss: 2.093396061210222

Epoch: 6| Step: 11
Training loss: 2.0172998905181885
Validation loss: 2.0854781314890873

Epoch: 6| Step: 12
Training loss: 2.1821842193603516
Validation loss: 2.0708958179719987

Epoch: 6| Step: 13
Training loss: 2.799323081970215
Validation loss: 2.0603089037761895

Epoch: 75| Step: 0
Training loss: 2.396841526031494
Validation loss: 2.049010640831404

Epoch: 6| Step: 1
Training loss: 1.923682689666748
Validation loss: 2.060994892991999

Epoch: 6| Step: 2
Training loss: 1.9860538244247437
Validation loss: 2.046568916689965

Epoch: 6| Step: 3
Training loss: 2.056894063949585
Validation loss: 2.053314019274968

Epoch: 6| Step: 4
Training loss: 2.814629554748535
Validation loss: 2.046300144605739

Epoch: 6| Step: 5
Training loss: 2.520660161972046
Validation loss: 2.060570401530112

Epoch: 6| Step: 6
Training loss: 2.0192999839782715
Validation loss: 2.047054624044767

Epoch: 6| Step: 7
Training loss: 2.752340793609619
Validation loss: 2.048244176372405

Epoch: 6| Step: 8
Training loss: 2.399991035461426
Validation loss: 2.0472230116526284

Epoch: 6| Step: 9
Training loss: 2.1364145278930664
Validation loss: 2.054572618135842

Epoch: 6| Step: 10
Training loss: 2.248145341873169
Validation loss: 2.05731120417195

Epoch: 6| Step: 11
Training loss: 2.2618370056152344
Validation loss: 2.066115648515763

Epoch: 6| Step: 12
Training loss: 1.8180029392242432
Validation loss: 2.0731670151474657

Epoch: 6| Step: 13
Training loss: 3.125349998474121
Validation loss: 2.0797002418066866

Epoch: 76| Step: 0
Training loss: 2.6447925567626953
Validation loss: 2.0716749775794243

Epoch: 6| Step: 1
Training loss: 1.7955752611160278
Validation loss: 2.050966232053695

Epoch: 6| Step: 2
Training loss: 2.1508984565734863
Validation loss: 2.054427739112608

Epoch: 6| Step: 3
Training loss: 1.8449417352676392
Validation loss: 2.045502032003095

Epoch: 6| Step: 4
Training loss: 2.126159191131592
Validation loss: 2.0463213612956386

Epoch: 6| Step: 5
Training loss: 2.6213197708129883
Validation loss: 2.060942501150152

Epoch: 6| Step: 6
Training loss: 1.5229225158691406
Validation loss: 2.0649566406844766

Epoch: 6| Step: 7
Training loss: 2.7790441513061523
Validation loss: 2.0626660752040085

Epoch: 6| Step: 8
Training loss: 2.9494824409484863
Validation loss: 2.0620917325378745

Epoch: 6| Step: 9
Training loss: 2.468381404876709
Validation loss: 2.0579080325300976

Epoch: 6| Step: 10
Training loss: 2.5320608615875244
Validation loss: 2.0778125332247828

Epoch: 6| Step: 11
Training loss: 1.5708720684051514
Validation loss: 2.0915540879772556

Epoch: 6| Step: 12
Training loss: 2.7852118015289307
Validation loss: 2.1288448943886706

Epoch: 6| Step: 13
Training loss: 2.4796361923217773
Validation loss: 2.1463334432212253

Epoch: 77| Step: 0
Training loss: 2.1979246139526367
Validation loss: 2.18788492807778

Epoch: 6| Step: 1
Training loss: 2.4793782234191895
Validation loss: 2.281448983377026

Epoch: 6| Step: 2
Training loss: 1.9653798341751099
Validation loss: 2.31034255027771

Epoch: 6| Step: 3
Training loss: 3.3272061347961426
Validation loss: 2.341135307024884

Epoch: 6| Step: 4
Training loss: 1.9070402383804321
Validation loss: 2.3044533729553223

Epoch: 6| Step: 5
Training loss: 1.9132750034332275
Validation loss: 2.2231458976704586

Epoch: 6| Step: 6
Training loss: 2.767225742340088
Validation loss: 2.1687486146086004

Epoch: 6| Step: 7
Training loss: 2.802077054977417
Validation loss: 2.131307300700936

Epoch: 6| Step: 8
Training loss: 1.4654481410980225
Validation loss: 2.1066069115874586

Epoch: 6| Step: 9
Training loss: 2.4632575511932373
Validation loss: 2.1076321601867676

Epoch: 6| Step: 10
Training loss: 2.963435649871826
Validation loss: 2.1573901919908423

Epoch: 6| Step: 11
Training loss: 2.897477626800537
Validation loss: 2.1984646025524346

Epoch: 6| Step: 12
Training loss: 2.499210834503174
Validation loss: 2.202546699072725

Epoch: 6| Step: 13
Training loss: 1.725830078125
Validation loss: 2.2012400473317792

Epoch: 78| Step: 0
Training loss: 2.672328472137451
Validation loss: 2.210932209927549

Epoch: 6| Step: 1
Training loss: 2.8588333129882812
Validation loss: 2.1794047765834357

Epoch: 6| Step: 2
Training loss: 1.8130773305892944
Validation loss: 2.1325616605820192

Epoch: 6| Step: 3
Training loss: 2.325078010559082
Validation loss: 2.092168782346992

Epoch: 6| Step: 4
Training loss: 2.1190757751464844
Validation loss: 2.057851734981742

Epoch: 6| Step: 5
Training loss: 2.5839128494262695
Validation loss: 2.0217580949106524

Epoch: 6| Step: 6
Training loss: 1.9599967002868652
Validation loss: 2.0180299846074914

Epoch: 6| Step: 7
Training loss: 2.330198049545288
Validation loss: 2.057684963749301

Epoch: 6| Step: 8
Training loss: 2.4799418449401855
Validation loss: 2.1352879770340456

Epoch: 6| Step: 9
Training loss: 2.386024236679077
Validation loss: 2.2383478328745854

Epoch: 6| Step: 10
Training loss: 2.648026466369629
Validation loss: 2.3388441711343746

Epoch: 6| Step: 11
Training loss: 2.4574360847473145
Validation loss: 2.3730478338015977

Epoch: 6| Step: 12
Training loss: 2.7716779708862305
Validation loss: 2.353578882832681

Epoch: 6| Step: 13
Training loss: 2.117539167404175
Validation loss: 2.2711203636661654

Epoch: 79| Step: 0
Training loss: 2.2246837615966797
Validation loss: 2.1934099492206367

Epoch: 6| Step: 1
Training loss: 2.3755040168762207
Validation loss: 2.10124558530828

Epoch: 6| Step: 2
Training loss: 2.901662826538086
Validation loss: 2.038866573764432

Epoch: 6| Step: 3
Training loss: 2.236049175262451
Validation loss: 2.0180151334372898

Epoch: 6| Step: 4
Training loss: 2.368844985961914
Validation loss: 2.016301493490896

Epoch: 6| Step: 5
Training loss: 1.9197747707366943
Validation loss: 2.0253910428734234

Epoch: 6| Step: 6
Training loss: 2.3669681549072266
Validation loss: 2.0351096250677623

Epoch: 6| Step: 7
Training loss: 2.3457159996032715
Validation loss: 2.0530782950821744

Epoch: 6| Step: 8
Training loss: 2.471822738647461
Validation loss: 2.0531222717736357

Epoch: 6| Step: 9
Training loss: 2.040506362915039
Validation loss: 2.060456222103488

Epoch: 6| Step: 10
Training loss: 2.5288238525390625
Validation loss: 2.066746409221362

Epoch: 6| Step: 11
Training loss: 2.4139816761016846
Validation loss: 2.0697265491690686

Epoch: 6| Step: 12
Training loss: 2.0959312915802
Validation loss: 2.0844920219913607

Epoch: 6| Step: 13
Training loss: 1.697738528251648
Validation loss: 2.0879105662786834

Epoch: 80| Step: 0
Training loss: 2.22965145111084
Validation loss: 2.08852901253649

Epoch: 6| Step: 1
Training loss: 2.7632510662078857
Validation loss: 2.1012439663692186

Epoch: 6| Step: 2
Training loss: 2.366866111755371
Validation loss: 2.1579117236598844

Epoch: 6| Step: 3
Training loss: 2.660176992416382
Validation loss: 2.2424268466170116

Epoch: 6| Step: 4
Training loss: 2.9931774139404297
Validation loss: 2.346049469004395

Epoch: 6| Step: 5
Training loss: 2.2370781898498535
Validation loss: 2.427792715769942

Epoch: 6| Step: 6
Training loss: 2.9036216735839844
Validation loss: 2.455606347771101

Epoch: 6| Step: 7
Training loss: 2.498784065246582
Validation loss: 2.4718550405194684

Epoch: 6| Step: 8
Training loss: 2.6268067359924316
Validation loss: 2.3965360169769614

Epoch: 6| Step: 9
Training loss: 2.4586586952209473
Validation loss: 2.319773151028541

Epoch: 6| Step: 10
Training loss: 1.332719087600708
Validation loss: 2.215375349085818

Epoch: 6| Step: 11
Training loss: 1.5673075914382935
Validation loss: 2.1626942465382237

Epoch: 6| Step: 12
Training loss: 2.6395320892333984
Validation loss: 2.1076900728287233

Epoch: 6| Step: 13
Training loss: 3.097325086593628
Validation loss: 2.08774628690494

Epoch: 81| Step: 0
Training loss: 2.267906665802002
Validation loss: 2.1005075618784916

Epoch: 6| Step: 1
Training loss: 2.415133476257324
Validation loss: 2.0986478174886396

Epoch: 6| Step: 2
Training loss: 2.0676846504211426
Validation loss: 2.095456369461552

Epoch: 6| Step: 3
Training loss: 2.1224164962768555
Validation loss: 2.099672932778635

Epoch: 6| Step: 4
Training loss: 2.629082441329956
Validation loss: 2.0828492487630537

Epoch: 6| Step: 5
Training loss: 1.7824764251708984
Validation loss: 2.0833152827396186

Epoch: 6| Step: 6
Training loss: 2.750293254852295
Validation loss: 2.097497247880505

Epoch: 6| Step: 7
Training loss: 2.5051684379577637
Validation loss: 2.1056624433045745

Epoch: 6| Step: 8
Training loss: 2.4447171688079834
Validation loss: 2.088612752576028

Epoch: 6| Step: 9
Training loss: 1.9668318033218384
Validation loss: 2.1055610384992374

Epoch: 6| Step: 10
Training loss: 2.450389862060547
Validation loss: 2.1192667394556026

Epoch: 6| Step: 11
Training loss: 2.8242075443267822
Validation loss: 2.0983176257020686

Epoch: 6| Step: 12
Training loss: 2.4711830615997314
Validation loss: 2.0790673353338756

Epoch: 6| Step: 13
Training loss: 2.181368350982666
Validation loss: 2.08917070973304

Epoch: 82| Step: 0
Training loss: 2.4260149002075195
Validation loss: 2.072595266885655

Epoch: 6| Step: 1
Training loss: 1.649121642112732
Validation loss: 2.081428909814486

Epoch: 6| Step: 2
Training loss: 2.5712244510650635
Validation loss: 2.0989994823291735

Epoch: 6| Step: 3
Training loss: 2.7461819648742676
Validation loss: 2.094980614159697

Epoch: 6| Step: 4
Training loss: 2.4608800411224365
Validation loss: 2.124721498899562

Epoch: 6| Step: 5
Training loss: 2.482532024383545
Validation loss: 2.154533217030187

Epoch: 6| Step: 6
Training loss: 3.3050546646118164
Validation loss: 2.177540389440393

Epoch: 6| Step: 7
Training loss: 3.009965181350708
Validation loss: 2.1468826160636

Epoch: 6| Step: 8
Training loss: 1.9551016092300415
Validation loss: 2.1351956244437926

Epoch: 6| Step: 9
Training loss: 2.024660587310791
Validation loss: 2.0848408822090394

Epoch: 6| Step: 10
Training loss: 2.0339863300323486
Validation loss: 2.039901625725531

Epoch: 6| Step: 11
Training loss: 2.4187161922454834
Validation loss: 2.0183441485128095

Epoch: 6| Step: 12
Training loss: 2.1702239513397217
Validation loss: 2.0046033359343007

Epoch: 6| Step: 13
Training loss: 1.121732473373413
Validation loss: 2.0161482390537055

Epoch: 83| Step: 0
Training loss: 2.6254639625549316
Validation loss: 2.0225988562389086

Epoch: 6| Step: 1
Training loss: 2.668793201446533
Validation loss: 2.028437131194658

Epoch: 6| Step: 2
Training loss: 2.639472007751465
Validation loss: 2.0294239931209113

Epoch: 6| Step: 3
Training loss: 2.3060479164123535
Validation loss: 2.026832401111562

Epoch: 6| Step: 4
Training loss: 2.432180166244507
Validation loss: 2.0083740667630265

Epoch: 6| Step: 5
Training loss: 1.6398228406906128
Validation loss: 2.0173494610735165

Epoch: 6| Step: 6
Training loss: 2.191518783569336
Validation loss: 2.01599391301473

Epoch: 6| Step: 7
Training loss: 1.89848792552948
Validation loss: 2.0066468433667253

Epoch: 6| Step: 8
Training loss: 2.2374987602233887
Validation loss: 2.0065857005375687

Epoch: 6| Step: 9
Training loss: 2.826270580291748
Validation loss: 2.0114349780544156

Epoch: 6| Step: 10
Training loss: 2.813234329223633
Validation loss: 2.0126609327972576

Epoch: 6| Step: 11
Training loss: 1.685654878616333
Validation loss: 2.015957801572738

Epoch: 6| Step: 12
Training loss: 1.9754104614257812
Validation loss: 2.0243918857266827

Epoch: 6| Step: 13
Training loss: 2.0030884742736816
Validation loss: 2.029047995485285

Epoch: 84| Step: 0
Training loss: 2.4568865299224854
Validation loss: 2.034601064138515

Epoch: 6| Step: 1
Training loss: 1.676674485206604
Validation loss: 2.0622392944110337

Epoch: 6| Step: 2
Training loss: 2.5548229217529297
Validation loss: 2.061884795465777

Epoch: 6| Step: 3
Training loss: 2.3000121116638184
Validation loss: 2.072961243250037

Epoch: 6| Step: 4
Training loss: 1.8279324769973755
Validation loss: 2.0769547416317846

Epoch: 6| Step: 5
Training loss: 2.841362476348877
Validation loss: 2.0949882050996185

Epoch: 6| Step: 6
Training loss: 2.145618438720703
Validation loss: 2.0957108748856412

Epoch: 6| Step: 7
Training loss: 2.924896240234375
Validation loss: 2.1194575166189544

Epoch: 6| Step: 8
Training loss: 2.2615537643432617
Validation loss: 2.1243905867299726

Epoch: 6| Step: 9
Training loss: 1.9139883518218994
Validation loss: 2.123667368324854

Epoch: 6| Step: 10
Training loss: 1.8934439420700073
Validation loss: 2.104081130796863

Epoch: 6| Step: 11
Training loss: 2.35310697555542
Validation loss: 2.0862009743208527

Epoch: 6| Step: 12
Training loss: 2.58524751663208
Validation loss: 2.048345829850884

Epoch: 6| Step: 13
Training loss: 2.3387115001678467
Validation loss: 2.0309793128762195

Epoch: 85| Step: 0
Training loss: 2.2419214248657227
Validation loss: 2.0069302205116517

Epoch: 6| Step: 1
Training loss: 2.955367088317871
Validation loss: 1.9910838065608856

Epoch: 6| Step: 2
Training loss: 2.2525641918182373
Validation loss: 1.9875091352770407

Epoch: 6| Step: 3
Training loss: 2.1150903701782227
Validation loss: 1.9787776265093076

Epoch: 6| Step: 4
Training loss: 2.2646989822387695
Validation loss: 1.979926691260389

Epoch: 6| Step: 5
Training loss: 2.3036112785339355
Validation loss: 1.9750116640521633

Epoch: 6| Step: 6
Training loss: 2.27148175239563
Validation loss: 1.969024489002843

Epoch: 6| Step: 7
Training loss: 1.634335994720459
Validation loss: 1.9681068261464436

Epoch: 6| Step: 8
Training loss: 2.8694100379943848
Validation loss: 1.9691667428580664

Epoch: 6| Step: 9
Training loss: 2.291264533996582
Validation loss: 1.972415408780498

Epoch: 6| Step: 10
Training loss: 2.458423137664795
Validation loss: 1.9737738614441247

Epoch: 6| Step: 11
Training loss: 2.462144374847412
Validation loss: 1.96971389555162

Epoch: 6| Step: 12
Training loss: 1.7421810626983643
Validation loss: 1.97549254919893

Epoch: 6| Step: 13
Training loss: 1.082075595855713
Validation loss: 1.9796232561911307

Epoch: 86| Step: 0
Training loss: 2.7014760971069336
Validation loss: 1.9689517636452951

Epoch: 6| Step: 1
Training loss: 1.7597248554229736
Validation loss: 1.9624242231410036

Epoch: 6| Step: 2
Training loss: 2.4277901649475098
Validation loss: 1.9587807168242752

Epoch: 6| Step: 3
Training loss: 2.3469858169555664
Validation loss: 1.9722187108890985

Epoch: 6| Step: 4
Training loss: 1.6433677673339844
Validation loss: 1.9750306862656788

Epoch: 6| Step: 5
Training loss: 2.8391151428222656
Validation loss: 1.975768255931075

Epoch: 6| Step: 6
Training loss: 1.946838617324829
Validation loss: 1.9681367361417381

Epoch: 6| Step: 7
Training loss: 1.678206205368042
Validation loss: 1.9725749351645028

Epoch: 6| Step: 8
Training loss: 2.1132469177246094
Validation loss: 1.967643310946803

Epoch: 6| Step: 9
Training loss: 2.307600736618042
Validation loss: 1.9684504898645545

Epoch: 6| Step: 10
Training loss: 2.472428321838379
Validation loss: 1.975025515402517

Epoch: 6| Step: 11
Training loss: 1.4486515522003174
Validation loss: 1.9751740758137037

Epoch: 6| Step: 12
Training loss: 3.0486326217651367
Validation loss: 1.989689580855831

Epoch: 6| Step: 13
Training loss: 2.9303033351898193
Validation loss: 1.9861319962368216

Epoch: 87| Step: 0
Training loss: 2.2197678089141846
Validation loss: 1.9841119576525945

Epoch: 6| Step: 1
Training loss: 2.3513858318328857
Validation loss: 1.9916441748219151

Epoch: 6| Step: 2
Training loss: 2.075680732727051
Validation loss: 1.9876695614989086

Epoch: 6| Step: 3
Training loss: 1.5778435468673706
Validation loss: 1.9918361158781155

Epoch: 6| Step: 4
Training loss: 2.134903907775879
Validation loss: 1.9813840850707023

Epoch: 6| Step: 5
Training loss: 2.637216806411743
Validation loss: 1.9918792478499874

Epoch: 6| Step: 6
Training loss: 1.9770948886871338
Validation loss: 1.9930378595987956

Epoch: 6| Step: 7
Training loss: 2.741049289703369
Validation loss: 1.9966034145765408

Epoch: 6| Step: 8
Training loss: 2.1030707359313965
Validation loss: 2.0050430105578516

Epoch: 6| Step: 9
Training loss: 2.253119707107544
Validation loss: 2.026521195647537

Epoch: 6| Step: 10
Training loss: 2.6338982582092285
Validation loss: 2.0328529393801125

Epoch: 6| Step: 11
Training loss: 2.1193344593048096
Validation loss: 2.040007975793654

Epoch: 6| Step: 12
Training loss: 2.252749443054199
Validation loss: 2.0283237118874826

Epoch: 6| Step: 13
Training loss: 2.3020482063293457
Validation loss: 2.0223368726750857

Epoch: 88| Step: 0
Training loss: 1.9199328422546387
Validation loss: 2.003308009075862

Epoch: 6| Step: 1
Training loss: 2.1967649459838867
Validation loss: 1.9988446248474943

Epoch: 6| Step: 2
Training loss: 1.9753174781799316
Validation loss: 1.9955945758409397

Epoch: 6| Step: 3
Training loss: 2.5625696182250977
Validation loss: 2.001818380048198

Epoch: 6| Step: 4
Training loss: 2.694599151611328
Validation loss: 2.0044032232735747

Epoch: 6| Step: 5
Training loss: 2.299088478088379
Validation loss: 2.0070235037034556

Epoch: 6| Step: 6
Training loss: 2.495771884918213
Validation loss: 2.00699173250506

Epoch: 6| Step: 7
Training loss: 2.5679779052734375
Validation loss: 2.0116990381671536

Epoch: 6| Step: 8
Training loss: 2.5348575115203857
Validation loss: 2.016632064696281

Epoch: 6| Step: 9
Training loss: 2.3673715591430664
Validation loss: 2.020642316469582

Epoch: 6| Step: 10
Training loss: 1.7907553911209106
Validation loss: 2.0137323923008417

Epoch: 6| Step: 11
Training loss: 2.4354782104492188
Validation loss: 2.0076395862845966

Epoch: 6| Step: 12
Training loss: 1.62410569190979
Validation loss: 1.9842941466198172

Epoch: 6| Step: 13
Training loss: 2.191361427307129
Validation loss: 1.9813032009268319

Epoch: 89| Step: 0
Training loss: 2.341165065765381
Validation loss: 2.0238551632050545

Epoch: 6| Step: 1
Training loss: 0.9263992309570312
Validation loss: 2.0743387963182185

Epoch: 6| Step: 2
Training loss: 2.320314407348633
Validation loss: 2.103012705361971

Epoch: 6| Step: 3
Training loss: 2.456892967224121
Validation loss: 2.1358957572649886

Epoch: 6| Step: 4
Training loss: 2.9017558097839355
Validation loss: 2.1647666808097594

Epoch: 6| Step: 5
Training loss: 2.837165355682373
Validation loss: 2.138200875251524

Epoch: 6| Step: 6
Training loss: 2.310915946960449
Validation loss: 2.1103776129343177

Epoch: 6| Step: 7
Training loss: 2.7328310012817383
Validation loss: 2.057173257232994

Epoch: 6| Step: 8
Training loss: 1.9922173023223877
Validation loss: 2.023703703316309

Epoch: 6| Step: 9
Training loss: 2.979363441467285
Validation loss: 2.0109748173785467

Epoch: 6| Step: 10
Training loss: 2.236487627029419
Validation loss: 2.013267191507483

Epoch: 6| Step: 11
Training loss: 1.2850871086120605
Validation loss: 2.036271309339872

Epoch: 6| Step: 12
Training loss: 2.182659864425659
Validation loss: 2.0473391881553074

Epoch: 6| Step: 13
Training loss: 2.7863683700561523
Validation loss: 2.0521745527944257

Epoch: 90| Step: 0
Training loss: 2.034616708755493
Validation loss: 2.034858565176687

Epoch: 6| Step: 1
Training loss: 1.645753026008606
Validation loss: 2.041617557566653

Epoch: 6| Step: 2
Training loss: 2.2891671657562256
Validation loss: 2.035720799558906

Epoch: 6| Step: 3
Training loss: 2.6147501468658447
Validation loss: 2.0448698587315057

Epoch: 6| Step: 4
Training loss: 1.7401397228240967
Validation loss: 2.0667961105223625

Epoch: 6| Step: 5
Training loss: 2.723438262939453
Validation loss: 2.0818623214639644

Epoch: 6| Step: 6
Training loss: 2.3690898418426514
Validation loss: 2.074741686544111

Epoch: 6| Step: 7
Training loss: 2.582737445831299
Validation loss: 2.074544442597256

Epoch: 6| Step: 8
Training loss: 2.447810173034668
Validation loss: 2.0829513906150736

Epoch: 6| Step: 9
Training loss: 1.2198365926742554
Validation loss: 2.079011881223289

Epoch: 6| Step: 10
Training loss: 2.8992807865142822
Validation loss: 2.0654710262052474

Epoch: 6| Step: 11
Training loss: 2.284512758255005
Validation loss: 2.0473666626919984

Epoch: 6| Step: 12
Training loss: 2.0020861625671387
Validation loss: 2.0213958012160433

Epoch: 6| Step: 13
Training loss: 2.520822763442993
Validation loss: 2.0200397532473326

Epoch: 91| Step: 0
Training loss: 2.358492612838745
Validation loss: 1.9861833203223445

Epoch: 6| Step: 1
Training loss: 2.2966115474700928
Validation loss: 1.9747415640020882

Epoch: 6| Step: 2
Training loss: 3.0680527687072754
Validation loss: 1.962121844291687

Epoch: 6| Step: 3
Training loss: 1.8784000873565674
Validation loss: 1.9642712711006083

Epoch: 6| Step: 4
Training loss: 1.6162989139556885
Validation loss: 1.9765947172718663

Epoch: 6| Step: 5
Training loss: 2.7745730876922607
Validation loss: 1.9827219055544945

Epoch: 6| Step: 6
Training loss: 2.4403843879699707
Validation loss: 1.9772211454247917

Epoch: 6| Step: 7
Training loss: 2.5230207443237305
Validation loss: 1.9728261616922194

Epoch: 6| Step: 8
Training loss: 1.6935782432556152
Validation loss: 1.9652463543799616

Epoch: 6| Step: 9
Training loss: 2.4505105018615723
Validation loss: 1.972280776628884

Epoch: 6| Step: 10
Training loss: 1.727057695388794
Validation loss: 1.972844252022364

Epoch: 6| Step: 11
Training loss: 1.9363136291503906
Validation loss: 1.985908621100969

Epoch: 6| Step: 12
Training loss: 2.2250542640686035
Validation loss: 1.9947012547523744

Epoch: 6| Step: 13
Training loss: 1.944054126739502
Validation loss: 2.0017684851923296

Epoch: 92| Step: 0
Training loss: 2.178957462310791
Validation loss: 2.022156391092526

Epoch: 6| Step: 1
Training loss: 2.1036322116851807
Validation loss: 2.040551888045444

Epoch: 6| Step: 2
Training loss: 2.326810598373413
Validation loss: 2.07645926167888

Epoch: 6| Step: 3
Training loss: 2.2760353088378906
Validation loss: 2.1116915056782384

Epoch: 6| Step: 4
Training loss: 2.2614221572875977
Validation loss: 2.1480988481993317

Epoch: 6| Step: 5
Training loss: 2.5434226989746094
Validation loss: 2.1669851426155335

Epoch: 6| Step: 6
Training loss: 1.8241289854049683
Validation loss: 2.175091071795392

Epoch: 6| Step: 7
Training loss: 1.8767460584640503
Validation loss: 2.186226765314738

Epoch: 6| Step: 8
Training loss: 2.134087324142456
Validation loss: 2.184396643792429

Epoch: 6| Step: 9
Training loss: 2.520512104034424
Validation loss: 2.1857422474891908

Epoch: 6| Step: 10
Training loss: 2.8734042644500732
Validation loss: 2.1446755906587005

Epoch: 6| Step: 11
Training loss: 2.5372226238250732
Validation loss: 2.126876906682086

Epoch: 6| Step: 12
Training loss: 2.051729917526245
Validation loss: 2.0982601770790676

Epoch: 6| Step: 13
Training loss: 1.66450834274292
Validation loss: 2.0525933798923286

Epoch: 93| Step: 0
Training loss: 2.1288318634033203
Validation loss: 2.0302165503142984

Epoch: 6| Step: 1
Training loss: 2.103602886199951
Validation loss: 2.0175801041305705

Epoch: 6| Step: 2
Training loss: 2.6623611450195312
Validation loss: 2.005144429463212

Epoch: 6| Step: 3
Training loss: 1.8111716508865356
Validation loss: 2.001607725697179

Epoch: 6| Step: 4
Training loss: 2.910183906555176
Validation loss: 2.017679158077445

Epoch: 6| Step: 5
Training loss: 1.5797076225280762
Validation loss: 2.038235547722027

Epoch: 6| Step: 6
Training loss: 1.8047239780426025
Validation loss: 2.0693281645415933

Epoch: 6| Step: 7
Training loss: 2.5758132934570312
Validation loss: 2.0950748151348484

Epoch: 6| Step: 8
Training loss: 1.6399366855621338
Validation loss: 2.0815836178359164

Epoch: 6| Step: 9
Training loss: 1.69404935836792
Validation loss: 2.0511044020293863

Epoch: 6| Step: 10
Training loss: 2.0746166706085205
Validation loss: 2.022154438880182

Epoch: 6| Step: 11
Training loss: 2.8810081481933594
Validation loss: 1.9920298066190494

Epoch: 6| Step: 12
Training loss: 2.6358513832092285
Validation loss: 1.9815633912240305

Epoch: 6| Step: 13
Training loss: 2.1877355575561523
Validation loss: 1.976111945285592

Epoch: 94| Step: 0
Training loss: 1.9187085628509521
Validation loss: 1.9781351679114885

Epoch: 6| Step: 1
Training loss: 2.043107271194458
Validation loss: 1.9862574838822888

Epoch: 6| Step: 2
Training loss: 1.9431045055389404
Validation loss: 1.9955939580035467

Epoch: 6| Step: 3
Training loss: 1.912731647491455
Validation loss: 1.983163643908757

Epoch: 6| Step: 4
Training loss: 2.1654598712921143
Validation loss: 1.9878244605115665

Epoch: 6| Step: 5
Training loss: 2.646695852279663
Validation loss: 1.9911116861527967

Epoch: 6| Step: 6
Training loss: 2.6574153900146484
Validation loss: 2.0012921697349957

Epoch: 6| Step: 7
Training loss: 2.609510898590088
Validation loss: 2.009043311560026

Epoch: 6| Step: 8
Training loss: 1.8289837837219238
Validation loss: 2.0148734264476325

Epoch: 6| Step: 9
Training loss: 1.8408753871917725
Validation loss: 2.0106079270762782

Epoch: 6| Step: 10
Training loss: 2.9472522735595703
Validation loss: 2.007837806978533

Epoch: 6| Step: 11
Training loss: 2.211890697479248
Validation loss: 2.0073721126843522

Epoch: 6| Step: 12
Training loss: 1.5418074131011963
Validation loss: 2.0201526072717484

Epoch: 6| Step: 13
Training loss: 2.0782318115234375
Validation loss: 2.0142940526367514

Epoch: 95| Step: 0
Training loss: 2.1123809814453125
Validation loss: 2.019617392170814

Epoch: 6| Step: 1
Training loss: 2.6238112449645996
Validation loss: 2.012846503206479

Epoch: 6| Step: 2
Training loss: 2.6310582160949707
Validation loss: 1.9956246999002272

Epoch: 6| Step: 3
Training loss: 2.0924153327941895
Validation loss: 2.000720952146797

Epoch: 6| Step: 4
Training loss: 2.2177982330322266
Validation loss: 2.0002602569518553

Epoch: 6| Step: 5
Training loss: 2.462024688720703
Validation loss: 2.0119902754342682

Epoch: 6| Step: 6
Training loss: 1.6784358024597168
Validation loss: 2.0179362373967327

Epoch: 6| Step: 7
Training loss: 2.4323699474334717
Validation loss: 2.0680463749875306

Epoch: 6| Step: 8
Training loss: 2.1280713081359863
Validation loss: 2.1162181285119828

Epoch: 6| Step: 9
Training loss: 2.006476879119873
Validation loss: 2.1542774515767253

Epoch: 6| Step: 10
Training loss: 1.6296796798706055
Validation loss: 2.1411684572055774

Epoch: 6| Step: 11
Training loss: 2.826244831085205
Validation loss: 2.1345087635901665

Epoch: 6| Step: 12
Training loss: 1.953026533126831
Validation loss: 2.0801212428718485

Epoch: 6| Step: 13
Training loss: 1.836732268333435
Validation loss: 2.030851576917915

Epoch: 96| Step: 0
Training loss: 2.2515008449554443
Validation loss: 2.022535789397455

Epoch: 6| Step: 1
Training loss: 2.5216376781463623
Validation loss: 2.004012620577248

Epoch: 6| Step: 2
Training loss: 1.8719104528427124
Validation loss: 1.993760431966474

Epoch: 6| Step: 3
Training loss: 2.692732334136963
Validation loss: 1.9968439148318382

Epoch: 6| Step: 4
Training loss: 2.170325517654419
Validation loss: 2.015433092271128

Epoch: 6| Step: 5
Training loss: 2.813382625579834
Validation loss: 2.009761982066657

Epoch: 6| Step: 6
Training loss: 2.037193775177002
Validation loss: 2.020726480791646

Epoch: 6| Step: 7
Training loss: 1.4392144680023193
Validation loss: 2.0254984658251525

Epoch: 6| Step: 8
Training loss: 1.951660394668579
Validation loss: 2.017671582519367

Epoch: 6| Step: 9
Training loss: 1.957109808921814
Validation loss: 2.013721268664124

Epoch: 6| Step: 10
Training loss: 2.270482301712036
Validation loss: 2.0121444040729153

Epoch: 6| Step: 11
Training loss: 2.1448750495910645
Validation loss: 2.0118375055251585

Epoch: 6| Step: 12
Training loss: 2.682941198348999
Validation loss: 2.015672819588774

Epoch: 6| Step: 13
Training loss: 1.1718641519546509
Validation loss: 2.0029769123241468

Epoch: 97| Step: 0
Training loss: 2.0902230739593506
Validation loss: 2.0105124276171447

Epoch: 6| Step: 1
Training loss: 1.3703038692474365
Validation loss: 2.0037634987984934

Epoch: 6| Step: 2
Training loss: 3.005836009979248
Validation loss: 2.011040405560565

Epoch: 6| Step: 3
Training loss: 1.9554026126861572
Validation loss: 2.0328183507406585

Epoch: 6| Step: 4
Training loss: 1.9954500198364258
Validation loss: 2.029997080884954

Epoch: 6| Step: 5
Training loss: 2.2156968116760254
Validation loss: 2.0322288979766188

Epoch: 6| Step: 6
Training loss: 1.8486599922180176
Validation loss: 2.0188338205378544

Epoch: 6| Step: 7
Training loss: 2.5097832679748535
Validation loss: 2.0112868996076685

Epoch: 6| Step: 8
Training loss: 2.0970206260681152
Validation loss: 2.0116419048719507

Epoch: 6| Step: 9
Training loss: 1.9658477306365967
Validation loss: 2.0014415453839045

Epoch: 6| Step: 10
Training loss: 2.4360132217407227
Validation loss: 1.9919952423341813

Epoch: 6| Step: 11
Training loss: 1.9613988399505615
Validation loss: 1.9950717726061422

Epoch: 6| Step: 12
Training loss: 2.235731601715088
Validation loss: 1.9754264995615969

Epoch: 6| Step: 13
Training loss: 2.7077255249023438
Validation loss: 1.9669587701879523

Epoch: 98| Step: 0
Training loss: 1.7928608655929565
Validation loss: 1.97633146983321

Epoch: 6| Step: 1
Training loss: 2.446859121322632
Validation loss: 1.9889912066921112

Epoch: 6| Step: 2
Training loss: 2.5442678928375244
Validation loss: 1.9885929412739252

Epoch: 6| Step: 3
Training loss: 1.8699698448181152
Validation loss: 1.9841179309352752

Epoch: 6| Step: 4
Training loss: 1.7645764350891113
Validation loss: 1.9910580163360925

Epoch: 6| Step: 5
Training loss: 2.1710598468780518
Validation loss: 2.000408785317534

Epoch: 6| Step: 6
Training loss: 2.6190168857574463
Validation loss: 2.013574456655851

Epoch: 6| Step: 7
Training loss: 2.014939069747925
Validation loss: 2.0055683646150815

Epoch: 6| Step: 8
Training loss: 1.240959882736206
Validation loss: 2.0252949512133034

Epoch: 6| Step: 9
Training loss: 1.61496102809906
Validation loss: 2.037367788694238

Epoch: 6| Step: 10
Training loss: 2.8777732849121094
Validation loss: 2.0271350978523173

Epoch: 6| Step: 11
Training loss: 2.150791645050049
Validation loss: 2.0367878226823706

Epoch: 6| Step: 12
Training loss: 2.4623870849609375
Validation loss: 2.0179085628960722

Epoch: 6| Step: 13
Training loss: 1.9384645223617554
Validation loss: 2.0201241893153035

Epoch: 99| Step: 0
Training loss: 2.595207452774048
Validation loss: 2.0145761223249536

Epoch: 6| Step: 1
Training loss: 1.9521374702453613
Validation loss: 2.014472947325758

Epoch: 6| Step: 2
Training loss: 2.6549458503723145
Validation loss: 2.013809948839167

Epoch: 6| Step: 3
Training loss: 2.0636157989501953
Validation loss: 2.0127563963654223

Epoch: 6| Step: 4
Training loss: 2.068570375442505
Validation loss: 1.9977562709521222

Epoch: 6| Step: 5
Training loss: 2.222188711166382
Validation loss: 2.006964493823308

Epoch: 6| Step: 6
Training loss: 1.6474404335021973
Validation loss: 1.9991182229852165

Epoch: 6| Step: 7
Training loss: 1.7460678815841675
Validation loss: 2.019616637178647

Epoch: 6| Step: 8
Training loss: 1.784023404121399
Validation loss: 2.0328146719163462

Epoch: 6| Step: 9
Training loss: 2.1558399200439453
Validation loss: 2.017119953709264

Epoch: 6| Step: 10
Training loss: 1.8227314949035645
Validation loss: 2.0197997375201155

Epoch: 6| Step: 11
Training loss: 1.8791279792785645
Validation loss: 2.005011558532715

Epoch: 6| Step: 12
Training loss: 1.991956353187561
Validation loss: 2.0155091439524004

Epoch: 6| Step: 13
Training loss: 3.297699213027954
Validation loss: 2.0379814332531345

Epoch: 100| Step: 0
Training loss: 2.0799648761749268
Validation loss: 2.054710275383406

Epoch: 6| Step: 1
Training loss: 1.7898911237716675
Validation loss: 2.058546725139823

Epoch: 6| Step: 2
Training loss: 2.319187641143799
Validation loss: 2.0729862284916702

Epoch: 6| Step: 3
Training loss: 1.5154011249542236
Validation loss: 2.0766406443811234

Epoch: 6| Step: 4
Training loss: 2.0218610763549805
Validation loss: 2.0846168994903564

Epoch: 6| Step: 5
Training loss: 1.9536051750183105
Validation loss: 2.078856416927871

Epoch: 6| Step: 6
Training loss: 2.408841609954834
Validation loss: 2.05676455138832

Epoch: 6| Step: 7
Training loss: 1.4521052837371826
Validation loss: 2.056132024334323

Epoch: 6| Step: 8
Training loss: 1.9660487174987793
Validation loss: 2.060272455215454

Epoch: 6| Step: 9
Training loss: 2.093397617340088
Validation loss: 2.0694113854439027

Epoch: 6| Step: 10
Training loss: 2.2383859157562256
Validation loss: 2.0596850302911576

Epoch: 6| Step: 11
Training loss: 2.83569073677063
Validation loss: 2.0248167489164617

Epoch: 6| Step: 12
Training loss: 2.5635743141174316
Validation loss: 2.0161548993920766

Epoch: 6| Step: 13
Training loss: 1.8429747819900513
Validation loss: 1.993232004104122

Epoch: 101| Step: 0
Training loss: 2.3841898441314697
Validation loss: 1.9830674420120895

Epoch: 6| Step: 1
Training loss: 1.8168219327926636
Validation loss: 1.9627651245363298

Epoch: 6| Step: 2
Training loss: 2.0473999977111816
Validation loss: 1.9648762377359534

Epoch: 6| Step: 3
Training loss: 2.2995147705078125
Validation loss: 1.952180515694362

Epoch: 6| Step: 4
Training loss: 1.8538219928741455
Validation loss: 1.963626584699077

Epoch: 6| Step: 5
Training loss: 2.2851476669311523
Validation loss: 1.9526491421525196

Epoch: 6| Step: 6
Training loss: 2.119994640350342
Validation loss: 1.9631069283331595

Epoch: 6| Step: 7
Training loss: 1.9372353553771973
Validation loss: 1.9654544720085718

Epoch: 6| Step: 8
Training loss: 1.6375733613967896
Validation loss: 1.9805160978788972

Epoch: 6| Step: 9
Training loss: 2.641537666320801
Validation loss: 1.994449362959913

Epoch: 6| Step: 10
Training loss: 2.3420944213867188
Validation loss: 1.9844768406242452

Epoch: 6| Step: 11
Training loss: 1.926093578338623
Validation loss: 1.9832347169999154

Epoch: 6| Step: 12
Training loss: 2.1029117107391357
Validation loss: 1.9865195956281436

Epoch: 6| Step: 13
Training loss: 1.6283259391784668
Validation loss: 1.9837845051160423

Epoch: 102| Step: 0
Training loss: 1.974258303642273
Validation loss: 1.990604390380203

Epoch: 6| Step: 1
Training loss: 2.0651698112487793
Validation loss: 1.995866637076101

Epoch: 6| Step: 2
Training loss: 2.6087610721588135
Validation loss: 2.011110428840883

Epoch: 6| Step: 3
Training loss: 2.495482921600342
Validation loss: 2.0328254827889065

Epoch: 6| Step: 4
Training loss: 2.65736985206604
Validation loss: 2.040431478972076

Epoch: 6| Step: 5
Training loss: 1.9960540533065796
Validation loss: 2.0468893025511052

Epoch: 6| Step: 6
Training loss: 1.9923261404037476
Validation loss: 2.0547658986942743

Epoch: 6| Step: 7
Training loss: 2.520371437072754
Validation loss: 2.0650412446709088

Epoch: 6| Step: 8
Training loss: 1.6371713876724243
Validation loss: 2.0717557950686385

Epoch: 6| Step: 9
Training loss: 1.5626564025878906
Validation loss: 2.067813737418062

Epoch: 6| Step: 10
Training loss: 2.0629403591156006
Validation loss: 2.0529178496330016

Epoch: 6| Step: 11
Training loss: 1.5153744220733643
Validation loss: 2.0419316099536036

Epoch: 6| Step: 12
Training loss: 1.987419605255127
Validation loss: 2.044979421041345

Epoch: 6| Step: 13
Training loss: 1.6358399391174316
Validation loss: 2.0123493902144896

Epoch: 103| Step: 0
Training loss: 2.925734281539917
Validation loss: 2.008168076956144

Epoch: 6| Step: 1
Training loss: 1.968971848487854
Validation loss: 2.0056312750744563

Epoch: 6| Step: 2
Training loss: 2.429004669189453
Validation loss: 2.0200104815985567

Epoch: 6| Step: 3
Training loss: 2.374691963195801
Validation loss: 2.0087975353323

Epoch: 6| Step: 4
Training loss: 1.9322689771652222
Validation loss: 2.015822059364729

Epoch: 6| Step: 5
Training loss: 1.979495882987976
Validation loss: 1.9995637760367444

Epoch: 6| Step: 6
Training loss: 1.9641273021697998
Validation loss: 2.0125812766372517

Epoch: 6| Step: 7
Training loss: 1.757738471031189
Validation loss: 2.001226696916806

Epoch: 6| Step: 8
Training loss: 1.7248046398162842
Validation loss: 1.9981144858944802

Epoch: 6| Step: 9
Training loss: 1.9473156929016113
Validation loss: 2.012296650999336

Epoch: 6| Step: 10
Training loss: 1.7779927253723145
Validation loss: 2.018395995581022

Epoch: 6| Step: 11
Training loss: 1.9541618824005127
Validation loss: 2.0120887589711014

Epoch: 6| Step: 12
Training loss: 1.4694349765777588
Validation loss: 1.996240754281321

Epoch: 6| Step: 13
Training loss: 2.471280574798584
Validation loss: 2.001457927047565

Epoch: 104| Step: 0
Training loss: 2.2222297191619873
Validation loss: 2.0111851692199707

Epoch: 6| Step: 1
Training loss: 1.4796022176742554
Validation loss: 2.0214464972096104

Epoch: 6| Step: 2
Training loss: 1.8069982528686523
Validation loss: 2.018825456660281

Epoch: 6| Step: 3
Training loss: 2.878732681274414
Validation loss: 2.0264058343825804

Epoch: 6| Step: 4
Training loss: 2.4039840698242188
Validation loss: 2.025624785372006

Epoch: 6| Step: 5
Training loss: 1.5971086025238037
Validation loss: 2.0249677691408383

Epoch: 6| Step: 6
Training loss: 1.4232745170593262
Validation loss: 2.0323165437226653

Epoch: 6| Step: 7
Training loss: 2.2533628940582275
Validation loss: 2.0475796448287142

Epoch: 6| Step: 8
Training loss: 2.2422385215759277
Validation loss: 2.053976558869885

Epoch: 6| Step: 9
Training loss: 2.363668441772461
Validation loss: 2.0390532324391026

Epoch: 6| Step: 10
Training loss: 2.3138175010681152
Validation loss: 2.021929963942497

Epoch: 6| Step: 11
Training loss: 2.178044319152832
Validation loss: 2.001933108093918

Epoch: 6| Step: 12
Training loss: 1.144351601600647
Validation loss: 2.014678478240967

Epoch: 6| Step: 13
Training loss: 1.6178135871887207
Validation loss: 2.02709928507446

Epoch: 105| Step: 0
Training loss: 2.3245978355407715
Validation loss: 2.0470935836915047

Epoch: 6| Step: 1
Training loss: 2.2800209522247314
Validation loss: 2.060322376989549

Epoch: 6| Step: 2
Training loss: 1.6038435697555542
Validation loss: 2.0825191492675454

Epoch: 6| Step: 3
Training loss: 2.546976089477539
Validation loss: 2.08802407146782

Epoch: 6| Step: 4
Training loss: 1.4820727109909058
Validation loss: 2.1232807943897862

Epoch: 6| Step: 5
Training loss: 1.6767985820770264
Validation loss: 2.127327234514298

Epoch: 6| Step: 6
Training loss: 2.150407314300537
Validation loss: 2.095965962256155

Epoch: 6| Step: 7
Training loss: 1.7996755838394165
Validation loss: 2.0774610388663506

Epoch: 6| Step: 8
Training loss: 2.0832269191741943
Validation loss: 2.0705915420286116

Epoch: 6| Step: 9
Training loss: 1.7894864082336426
Validation loss: 2.0720820529486543

Epoch: 6| Step: 10
Training loss: 2.69254207611084
Validation loss: 2.055593095799928

Epoch: 6| Step: 11
Training loss: 2.119877815246582
Validation loss: 2.0469163797234975

Epoch: 6| Step: 12
Training loss: 1.8057489395141602
Validation loss: 2.03941261640159

Epoch: 6| Step: 13
Training loss: 2.4096078872680664
Validation loss: 2.0495073231317664

Epoch: 106| Step: 0
Training loss: 2.020082950592041
Validation loss: 2.0735001461480254

Epoch: 6| Step: 1
Training loss: 2.3452515602111816
Validation loss: 2.095189203498184

Epoch: 6| Step: 2
Training loss: 1.684013843536377
Validation loss: 2.1214620554318993

Epoch: 6| Step: 3
Training loss: 2.434481143951416
Validation loss: 2.150984125752603

Epoch: 6| Step: 4
Training loss: 2.246446132659912
Validation loss: 2.1018001725596767

Epoch: 6| Step: 5
Training loss: 2.586134433746338
Validation loss: 2.0781136776811335

Epoch: 6| Step: 6
Training loss: 2.3939104080200195
Validation loss: 2.039473969449279

Epoch: 6| Step: 7
Training loss: 2.342869281768799
Validation loss: 2.0066720759996803

Epoch: 6| Step: 8
Training loss: 1.6432750225067139
Validation loss: 2.00311065361064

Epoch: 6| Step: 9
Training loss: 1.412611961364746
Validation loss: 1.9857610246186614

Epoch: 6| Step: 10
Training loss: 2.0008645057678223
Validation loss: 2.0288011130466255

Epoch: 6| Step: 11
Training loss: 1.7979254722595215
Validation loss: 2.0527845659563617

Epoch: 6| Step: 12
Training loss: 2.139007568359375
Validation loss: 2.0813140305139686

Epoch: 6| Step: 13
Training loss: 1.8980985879898071
Validation loss: 2.0842804754934003

Epoch: 107| Step: 0
Training loss: 2.307097911834717
Validation loss: 2.0902334041492914

Epoch: 6| Step: 1
Training loss: 1.928725004196167
Validation loss: 2.1396601328285794

Epoch: 6| Step: 2
Training loss: 2.3369126319885254
Validation loss: 2.1732420844416462

Epoch: 6| Step: 3
Training loss: 2.584207773208618
Validation loss: 2.1586635087126043

Epoch: 6| Step: 4
Training loss: 1.8761234283447266
Validation loss: 2.106913633244012

Epoch: 6| Step: 5
Training loss: 2.118267059326172
Validation loss: 2.0532160715390275

Epoch: 6| Step: 6
Training loss: 1.5886240005493164
Validation loss: 2.0522405255225395

Epoch: 6| Step: 7
Training loss: 1.2493799924850464
Validation loss: 2.0593564215526787

Epoch: 6| Step: 8
Training loss: 2.422935724258423
Validation loss: 2.0432390807777323

Epoch: 6| Step: 9
Training loss: 2.399106740951538
Validation loss: 2.0281350510094756

Epoch: 6| Step: 10
Training loss: 1.8165972232818604
Validation loss: 2.034532070159912

Epoch: 6| Step: 11
Training loss: 2.5654966831207275
Validation loss: 2.055474591511552

Epoch: 6| Step: 12
Training loss: 2.16382098197937
Validation loss: 2.0223270616223736

Epoch: 6| Step: 13
Training loss: 1.6635146141052246
Validation loss: 2.019478731257941

Epoch: 108| Step: 0
Training loss: 0.9632797837257385
Validation loss: 1.9961454073588054

Epoch: 6| Step: 1
Training loss: 2.607631206512451
Validation loss: 1.9892661007501746

Epoch: 6| Step: 2
Training loss: 2.512634754180908
Validation loss: 1.9876031593609882

Epoch: 6| Step: 3
Training loss: 1.66379976272583
Validation loss: 1.9870686223430019

Epoch: 6| Step: 4
Training loss: 1.933393955230713
Validation loss: 1.9891530070253598

Epoch: 6| Step: 5
Training loss: 2.674391269683838
Validation loss: 2.0131022776326826

Epoch: 6| Step: 6
Training loss: 2.407930374145508
Validation loss: 2.00719432164264

Epoch: 6| Step: 7
Training loss: 2.1825244426727295
Validation loss: 2.0055598802463983

Epoch: 6| Step: 8
Training loss: 2.250053882598877
Validation loss: 2.0100218736997215

Epoch: 6| Step: 9
Training loss: 1.8666349649429321
Validation loss: 2.0185149459428686

Epoch: 6| Step: 10
Training loss: 1.6579868793487549
Validation loss: 2.013107074204312

Epoch: 6| Step: 11
Training loss: 2.0299172401428223
Validation loss: 2.024504433396042

Epoch: 6| Step: 12
Training loss: 1.7948400974273682
Validation loss: 2.074432055155436

Epoch: 6| Step: 13
Training loss: 1.1782383918762207
Validation loss: 2.100191543179174

Epoch: 109| Step: 0
Training loss: 2.390169858932495
Validation loss: 2.096653876766082

Epoch: 6| Step: 1
Training loss: 1.6166105270385742
Validation loss: 2.0729433234019945

Epoch: 6| Step: 2
Training loss: 2.69050931930542
Validation loss: 2.024089128740372

Epoch: 6| Step: 3
Training loss: 1.4938499927520752
Validation loss: 1.9951638483232068

Epoch: 6| Step: 4
Training loss: 1.4373531341552734
Validation loss: 1.9851313816603793

Epoch: 6| Step: 5
Training loss: 2.055790424346924
Validation loss: 1.9853230971162037

Epoch: 6| Step: 6
Training loss: 2.1472415924072266
Validation loss: 2.006940439183225

Epoch: 6| Step: 7
Training loss: 2.607776641845703
Validation loss: 2.051195442035634

Epoch: 6| Step: 8
Training loss: 2.186716079711914
Validation loss: 2.0715976017777638

Epoch: 6| Step: 9
Training loss: 1.7629799842834473
Validation loss: 2.0693631095270955

Epoch: 6| Step: 10
Training loss: 1.5461466312408447
Validation loss: 2.047361071391772

Epoch: 6| Step: 11
Training loss: 2.3228445053100586
Validation loss: 2.052797343141289

Epoch: 6| Step: 12
Training loss: 2.186823844909668
Validation loss: 2.103840540814143

Epoch: 6| Step: 13
Training loss: 2.7080094814300537
Validation loss: 2.1479557150153705

Epoch: 110| Step: 0
Training loss: 2.2166237831115723
Validation loss: 2.174591017025773

Epoch: 6| Step: 1
Training loss: 1.6652499437332153
Validation loss: 2.1532397193293416

Epoch: 6| Step: 2
Training loss: 1.719376802444458
Validation loss: 2.135830681811097

Epoch: 6| Step: 3
Training loss: 2.718909978866577
Validation loss: 2.1096643760640132

Epoch: 6| Step: 4
Training loss: 2.1042380332946777
Validation loss: 2.0881224806590746

Epoch: 6| Step: 5
Training loss: 2.142271041870117
Validation loss: 2.046100740791649

Epoch: 6| Step: 6
Training loss: 2.1859993934631348
Validation loss: 2.0337829846207813

Epoch: 6| Step: 7
Training loss: 2.047337055206299
Validation loss: 2.0293774425342517

Epoch: 6| Step: 8
Training loss: 1.6548033952713013
Validation loss: 2.0458817071812128

Epoch: 6| Step: 9
Training loss: 1.8621588945388794
Validation loss: 2.064969979306703

Epoch: 6| Step: 10
Training loss: 2.517089366912842
Validation loss: 2.0822691840510212

Epoch: 6| Step: 11
Training loss: 1.6110458374023438
Validation loss: 2.0808365524456067

Epoch: 6| Step: 12
Training loss: 1.8744313716888428
Validation loss: 2.098851598719115

Epoch: 6| Step: 13
Training loss: 1.9048715829849243
Validation loss: 2.1085212358864407

Epoch: 111| Step: 0
Training loss: 2.0593740940093994
Validation loss: 2.1082773644437074

Epoch: 6| Step: 1
Training loss: 2.262467622756958
Validation loss: 2.072374363099375

Epoch: 6| Step: 2
Training loss: 1.9536739587783813
Validation loss: 2.0419977031728274

Epoch: 6| Step: 3
Training loss: 2.119640827178955
Validation loss: 2.0329394250787716

Epoch: 6| Step: 4
Training loss: 1.8280096054077148
Validation loss: 2.027775074846001

Epoch: 6| Step: 5
Training loss: 1.8214176893234253
Validation loss: 2.0219321814916467

Epoch: 6| Step: 6
Training loss: 1.9237802028656006
Validation loss: 2.0093982053059403

Epoch: 6| Step: 7
Training loss: 1.8532887697219849
Validation loss: 2.0091577858053227

Epoch: 6| Step: 8
Training loss: 1.7297855615615845
Validation loss: 2.0133009213273243

Epoch: 6| Step: 9
Training loss: 2.0879464149475098
Validation loss: 2.001687293411583

Epoch: 6| Step: 10
Training loss: 2.041165351867676
Validation loss: 2.0066568877107356

Epoch: 6| Step: 11
Training loss: 1.9823589324951172
Validation loss: 2.001970676965611

Epoch: 6| Step: 12
Training loss: 2.1924245357513428
Validation loss: 2.01189447218372

Epoch: 6| Step: 13
Training loss: 1.4784317016601562
Validation loss: 2.011538444026824

Epoch: 112| Step: 0
Training loss: 2.3381824493408203
Validation loss: 2.0122542458195842

Epoch: 6| Step: 1
Training loss: 1.9562385082244873
Validation loss: 2.039780501396425

Epoch: 6| Step: 2
Training loss: 2.681046962738037
Validation loss: 2.0368669058686946

Epoch: 6| Step: 3
Training loss: 1.855787992477417
Validation loss: 2.039936110537539

Epoch: 6| Step: 4
Training loss: 1.7950260639190674
Validation loss: 2.0562227233763664

Epoch: 6| Step: 5
Training loss: 1.90380859375
Validation loss: 2.0557721917347243

Epoch: 6| Step: 6
Training loss: 1.8224799633026123
Validation loss: 2.0573928125442995

Epoch: 6| Step: 7
Training loss: 1.6797361373901367
Validation loss: 2.0773828362905853

Epoch: 6| Step: 8
Training loss: 1.5818862915039062
Validation loss: 2.0651740874013593

Epoch: 6| Step: 9
Training loss: 2.1716926097869873
Validation loss: 2.0741701651644964

Epoch: 6| Step: 10
Training loss: 2.1571273803710938
Validation loss: 2.07615412435224

Epoch: 6| Step: 11
Training loss: 1.6346060037612915
Validation loss: 2.083105851245183

Epoch: 6| Step: 12
Training loss: 1.3955378532409668
Validation loss: 2.0842243753453737

Epoch: 6| Step: 13
Training loss: 2.103020429611206
Validation loss: 2.1100112289510746

Epoch: 113| Step: 0
Training loss: 1.49623441696167
Validation loss: 2.0987580668541694

Epoch: 6| Step: 1
Training loss: 1.9278779029846191
Validation loss: 2.1086089918690343

Epoch: 6| Step: 2
Training loss: 1.1877615451812744
Validation loss: 2.067949115589101

Epoch: 6| Step: 3
Training loss: 1.8681844472885132
Validation loss: 2.052469907268401

Epoch: 6| Step: 4
Training loss: 2.1644678115844727
Validation loss: 2.038172719299152

Epoch: 6| Step: 5
Training loss: 1.5724828243255615
Validation loss: 2.0502920189211444

Epoch: 6| Step: 6
Training loss: 2.126908779144287
Validation loss: 2.0563225310335875

Epoch: 6| Step: 7
Training loss: 2.5160152912139893
Validation loss: 2.0641480184370473

Epoch: 6| Step: 8
Training loss: 2.5542614459991455
Validation loss: 2.052022464813725

Epoch: 6| Step: 9
Training loss: 2.261467456817627
Validation loss: 2.037652184886317

Epoch: 6| Step: 10
Training loss: 1.2609909772872925
Validation loss: 2.0299595491860503

Epoch: 6| Step: 11
Training loss: 2.2336678504943848
Validation loss: 2.012605683777922

Epoch: 6| Step: 12
Training loss: 1.8820364475250244
Validation loss: 2.017528441644484

Epoch: 6| Step: 13
Training loss: 2.338132858276367
Validation loss: 2.0531892135579097

Epoch: 114| Step: 0
Training loss: 1.89739990234375
Validation loss: 2.0638563145873365

Epoch: 6| Step: 1
Training loss: 2.3122363090515137
Validation loss: 2.0777122166848954

Epoch: 6| Step: 2
Training loss: 1.5594878196716309
Validation loss: 2.0778040706470446

Epoch: 6| Step: 3
Training loss: 2.4150049686431885
Validation loss: 2.062934101268809

Epoch: 6| Step: 4
Training loss: 1.482671856880188
Validation loss: 2.0473685790133733

Epoch: 6| Step: 5
Training loss: 2.0613038539886475
Validation loss: 2.0479811058249524

Epoch: 6| Step: 6
Training loss: 1.7967784404754639
Validation loss: 2.05634057265456

Epoch: 6| Step: 7
Training loss: 1.936732530593872
Validation loss: 2.0557309260932346

Epoch: 6| Step: 8
Training loss: 1.729229211807251
Validation loss: 2.069774289284983

Epoch: 6| Step: 9
Training loss: 1.7642836570739746
Validation loss: 2.0555098748976186

Epoch: 6| Step: 10
Training loss: 2.004103183746338
Validation loss: 2.0414531000198854

Epoch: 6| Step: 11
Training loss: 2.1736083030700684
Validation loss: 2.0306506746558735

Epoch: 6| Step: 12
Training loss: 1.9268944263458252
Validation loss: 2.0173994956477994

Epoch: 6| Step: 13
Training loss: 1.4101592302322388
Validation loss: 2.029430015112764

Epoch: 115| Step: 0
Training loss: 1.5421617031097412
Validation loss: 2.0459642666642384

Epoch: 6| Step: 1
Training loss: 2.5599212646484375
Validation loss: 2.050630524594297

Epoch: 6| Step: 2
Training loss: 1.8768928050994873
Validation loss: 2.037756049504844

Epoch: 6| Step: 3
Training loss: 0.9259483814239502
Validation loss: 2.0199786770728325

Epoch: 6| Step: 4
Training loss: 1.985713243484497
Validation loss: 2.012993020396079

Epoch: 6| Step: 5
Training loss: 2.3013181686401367
Validation loss: 2.0137846598061184

Epoch: 6| Step: 6
Training loss: 2.0702695846557617
Validation loss: 2.0063259601593018

Epoch: 6| Step: 7
Training loss: 1.7278673648834229
Validation loss: 1.9945612184463009

Epoch: 6| Step: 8
Training loss: 2.40118408203125
Validation loss: 1.9801065844874228

Epoch: 6| Step: 9
Training loss: 1.827237606048584
Validation loss: 1.9777668240249797

Epoch: 6| Step: 10
Training loss: 1.341033935546875
Validation loss: 1.9856969310391335

Epoch: 6| Step: 11
Training loss: 2.1380128860473633
Validation loss: 2.0025238567782986

Epoch: 6| Step: 12
Training loss: 1.8016406297683716
Validation loss: 2.0219250161160707

Epoch: 6| Step: 13
Training loss: 1.975710153579712
Validation loss: 2.0542150415400022

Epoch: 116| Step: 0
Training loss: 2.20487117767334
Validation loss: 2.0903154252677836

Epoch: 6| Step: 1
Training loss: 1.3553128242492676
Validation loss: 2.1167229478077223

Epoch: 6| Step: 2
Training loss: 1.5599372386932373
Validation loss: 2.0989876613822034

Epoch: 6| Step: 3
Training loss: 0.972093939781189
Validation loss: 2.1018470384741343

Epoch: 6| Step: 4
Training loss: 3.140125036239624
Validation loss: 2.1234599800520044

Epoch: 6| Step: 5
Training loss: 1.9499917030334473
Validation loss: 2.1015709497595347

Epoch: 6| Step: 6
Training loss: 2.3239810466766357
Validation loss: 2.0691872450613205

Epoch: 6| Step: 7
Training loss: 1.0441409349441528
Validation loss: 2.0343606779652257

Epoch: 6| Step: 8
Training loss: 1.7859289646148682
Validation loss: 2.0052458714413386

Epoch: 6| Step: 9
Training loss: 2.3800265789031982
Validation loss: 2.0044883963882283

Epoch: 6| Step: 10
Training loss: 2.244598388671875
Validation loss: 2.008084694544474

Epoch: 6| Step: 11
Training loss: 2.1006312370300293
Validation loss: 2.019911486615417

Epoch: 6| Step: 12
Training loss: 1.6996809244155884
Validation loss: 2.0327689468219714

Epoch: 6| Step: 13
Training loss: 1.5814437866210938
Validation loss: 2.0400724026464645

Epoch: 117| Step: 0
Training loss: 1.6683895587921143
Validation loss: 2.041461366479115

Epoch: 6| Step: 1
Training loss: 1.6666815280914307
Validation loss: 2.064635761322514

Epoch: 6| Step: 2
Training loss: 1.2363181114196777
Validation loss: 2.0622607379831295

Epoch: 6| Step: 3
Training loss: 1.9310004711151123
Validation loss: 2.094142702318007

Epoch: 6| Step: 4
Training loss: 2.7167015075683594
Validation loss: 2.093774926277899

Epoch: 6| Step: 5
Training loss: 2.1834726333618164
Validation loss: 2.0938941637674966

Epoch: 6| Step: 6
Training loss: 2.1036877632141113
Validation loss: 2.0969397649970105

Epoch: 6| Step: 7
Training loss: 2.0266945362091064
Validation loss: 2.0769459175807174

Epoch: 6| Step: 8
Training loss: 2.2777323722839355
Validation loss: 2.0743806413424912

Epoch: 6| Step: 9
Training loss: 2.435154438018799
Validation loss: 2.0698216858730523

Epoch: 6| Step: 10
Training loss: 1.197495698928833
Validation loss: 2.062735431937761

Epoch: 6| Step: 11
Training loss: 0.720948338508606
Validation loss: 2.0540372248618834

Epoch: 6| Step: 12
Training loss: 2.131659507751465
Validation loss: 2.049356834862822

Epoch: 6| Step: 13
Training loss: 2.0511393547058105
Validation loss: 2.051349614256172

Epoch: 118| Step: 0
Training loss: 2.0151636600494385
Validation loss: 2.051474686591856

Epoch: 6| Step: 1
Training loss: 1.330501675605774
Validation loss: 2.044639184910764

Epoch: 6| Step: 2
Training loss: 1.5332764387130737
Validation loss: 2.047628405273602

Epoch: 6| Step: 3
Training loss: 1.5930747985839844
Validation loss: 2.0313369330539497

Epoch: 6| Step: 4
Training loss: 1.363227128982544
Validation loss: 2.0159426760929886

Epoch: 6| Step: 5
Training loss: 2.239128351211548
Validation loss: 2.0140564005862

Epoch: 6| Step: 6
Training loss: 2.340634822845459
Validation loss: 2.008053502728862

Epoch: 6| Step: 7
Training loss: 2.4091882705688477
Validation loss: 2.009779321250095

Epoch: 6| Step: 8
Training loss: 1.7111183404922485
Validation loss: 2.01100980594594

Epoch: 6| Step: 9
Training loss: 1.9147206544876099
Validation loss: 2.0007391539953088

Epoch: 6| Step: 10
Training loss: 2.1877284049987793
Validation loss: 2.0021948301663963

Epoch: 6| Step: 11
Training loss: 1.7114144563674927
Validation loss: 2.0008692715757634

Epoch: 6| Step: 12
Training loss: 1.7922234535217285
Validation loss: 2.0067783094221547

Epoch: 6| Step: 13
Training loss: 1.6741385459899902
Validation loss: 2.007173679208243

Epoch: 119| Step: 0
Training loss: 1.863511085510254
Validation loss: 2.032770813152354

Epoch: 6| Step: 1
Training loss: 2.3679044246673584
Validation loss: 2.0549071194023214

Epoch: 6| Step: 2
Training loss: 1.794490098953247
Validation loss: 2.0676354515937065

Epoch: 6| Step: 3
Training loss: 1.9629950523376465
Validation loss: 2.068795975818429

Epoch: 6| Step: 4
Training loss: 1.9799379110336304
Validation loss: 2.0868772127295054

Epoch: 6| Step: 5
Training loss: 2.1614809036254883
Validation loss: 2.064813426745835

Epoch: 6| Step: 6
Training loss: 1.5684713125228882
Validation loss: 2.059023262352072

Epoch: 6| Step: 7
Training loss: 1.6622228622436523
Validation loss: 2.070034086063344

Epoch: 6| Step: 8
Training loss: 1.6504522562026978
Validation loss: 2.072342723928472

Epoch: 6| Step: 9
Training loss: 1.4854923486709595
Validation loss: 2.065909606154247

Epoch: 6| Step: 10
Training loss: 2.1479129791259766
Validation loss: 2.073709485351398

Epoch: 6| Step: 11
Training loss: 1.5987476110458374
Validation loss: 2.069018310116183

Epoch: 6| Step: 12
Training loss: 1.5881109237670898
Validation loss: 2.0712708862878944

Epoch: 6| Step: 13
Training loss: 2.391632556915283
Validation loss: 2.0618896138283516

Epoch: 120| Step: 0
Training loss: 2.223897933959961
Validation loss: 2.0641411171164563

Epoch: 6| Step: 1
Training loss: 1.718665361404419
Validation loss: 2.03447393191758

Epoch: 6| Step: 2
Training loss: 1.4038007259368896
Validation loss: 1.998264665244728

Epoch: 6| Step: 3
Training loss: 1.1263165473937988
Validation loss: 1.9652279653856832

Epoch: 6| Step: 4
Training loss: 2.085031270980835
Validation loss: 1.9798411758997108

Epoch: 6| Step: 5
Training loss: 1.878866195678711
Validation loss: 1.9721816060363606

Epoch: 6| Step: 6
Training loss: 1.8652153015136719
Validation loss: 1.993690682995704

Epoch: 6| Step: 7
Training loss: 1.6225780248641968
Validation loss: 2.001458097529668

Epoch: 6| Step: 8
Training loss: 1.9894754886627197
Validation loss: 1.9988057126281082

Epoch: 6| Step: 9
Training loss: 2.1906487941741943
Validation loss: 2.0157790568567093

Epoch: 6| Step: 10
Training loss: 1.49257230758667
Validation loss: 1.9978791616296256

Epoch: 6| Step: 11
Training loss: 2.1671299934387207
Validation loss: 2.016153843172135

Epoch: 6| Step: 12
Training loss: 2.57814621925354
Validation loss: 2.0362374423652567

Epoch: 6| Step: 13
Training loss: 1.6978108882904053
Validation loss: 2.0497749467049875

Epoch: 121| Step: 0
Training loss: 2.4074478149414062
Validation loss: 2.058856374473982

Epoch: 6| Step: 1
Training loss: 2.151742935180664
Validation loss: 2.0708429877476027

Epoch: 6| Step: 2
Training loss: 2.223060131072998
Validation loss: 2.0938451572131087

Epoch: 6| Step: 3
Training loss: 1.7969770431518555
Validation loss: 2.0947031795337634

Epoch: 6| Step: 4
Training loss: 1.4617271423339844
Validation loss: 2.093838373819987

Epoch: 6| Step: 5
Training loss: 2.1280198097229004
Validation loss: 2.072569070323821

Epoch: 6| Step: 6
Training loss: 1.8589727878570557
Validation loss: 2.0432569519166024

Epoch: 6| Step: 7
Training loss: 1.6010009050369263
Validation loss: 2.0058754797904723

Epoch: 6| Step: 8
Training loss: 1.9381256103515625
Validation loss: 1.9998697798739198

Epoch: 6| Step: 9
Training loss: 1.8234748840332031
Validation loss: 1.9979070258396927

Epoch: 6| Step: 10
Training loss: 1.4790068864822388
Validation loss: 2.0116339524586997

Epoch: 6| Step: 11
Training loss: 2.3086469173431396
Validation loss: 2.0105493414786553

Epoch: 6| Step: 12
Training loss: 1.3111604452133179
Validation loss: 1.990586269286371

Epoch: 6| Step: 13
Training loss: 1.712433099746704
Validation loss: 1.963401957224774

Epoch: 122| Step: 0
Training loss: 2.0569889545440674
Validation loss: 1.9628111803403465

Epoch: 6| Step: 1
Training loss: 2.2647337913513184
Validation loss: 2.010464265782346

Epoch: 6| Step: 2
Training loss: 1.8348329067230225
Validation loss: 2.054259587359685

Epoch: 6| Step: 3
Training loss: 1.8227709531784058
Validation loss: 2.081340583421851

Epoch: 6| Step: 4
Training loss: 1.8480395078659058
Validation loss: 2.090420062823962

Epoch: 6| Step: 5
Training loss: 2.0131301879882812
Validation loss: 2.0885206448134555

Epoch: 6| Step: 6
Training loss: 1.8586807250976562
Validation loss: 2.0646570805580384

Epoch: 6| Step: 7
Training loss: 2.1797170639038086
Validation loss: 2.0273958713777605

Epoch: 6| Step: 8
Training loss: 1.8725253343582153
Validation loss: 1.9965910091195056

Epoch: 6| Step: 9
Training loss: 1.2053663730621338
Validation loss: 1.9828239589609125

Epoch: 6| Step: 10
Training loss: 1.1509838104248047
Validation loss: 1.985625966902702

Epoch: 6| Step: 11
Training loss: 2.186561107635498
Validation loss: 1.9847492402599705

Epoch: 6| Step: 12
Training loss: 2.034491539001465
Validation loss: 1.9872590713603522

Epoch: 6| Step: 13
Training loss: 1.9359190464019775
Validation loss: 2.0152320938725627

Epoch: 123| Step: 0
Training loss: 2.1186070442199707
Validation loss: 2.011722792861282

Epoch: 6| Step: 1
Training loss: 2.1886301040649414
Validation loss: 2.0200863166521956

Epoch: 6| Step: 2
Training loss: 1.4629472494125366
Validation loss: 2.042656247333814

Epoch: 6| Step: 3
Training loss: 2.1068410873413086
Validation loss: 2.0774614939125637

Epoch: 6| Step: 4
Training loss: 1.7510228157043457
Validation loss: 2.1144476090708086

Epoch: 6| Step: 5
Training loss: 2.1403236389160156
Validation loss: 2.133565766837007

Epoch: 6| Step: 6
Training loss: 2.1510820388793945
Validation loss: 2.1326650419542865

Epoch: 6| Step: 7
Training loss: 1.9860122203826904
Validation loss: 2.08500773163252

Epoch: 6| Step: 8
Training loss: 2.1231045722961426
Validation loss: 2.0374397206050094

Epoch: 6| Step: 9
Training loss: 1.5919156074523926
Validation loss: 2.0300690179230063

Epoch: 6| Step: 10
Training loss: 1.6925885677337646
Validation loss: 2.04289686423476

Epoch: 6| Step: 11
Training loss: 1.0610709190368652
Validation loss: 2.045159868014756

Epoch: 6| Step: 12
Training loss: 0.8783353567123413
Validation loss: 2.056020047075005

Epoch: 6| Step: 13
Training loss: 2.5198049545288086
Validation loss: 2.061964475980369

Epoch: 124| Step: 0
Training loss: 2.145533323287964
Validation loss: 2.057667293856221

Epoch: 6| Step: 1
Training loss: 1.7976257801055908
Validation loss: 2.065557138894194

Epoch: 6| Step: 2
Training loss: 1.497813105583191
Validation loss: 2.0725225402462866

Epoch: 6| Step: 3
Training loss: 1.6760331392288208
Validation loss: 2.091378076102144

Epoch: 6| Step: 4
Training loss: 1.6909570693969727
Validation loss: 2.100115683770949

Epoch: 6| Step: 5
Training loss: 1.5987321138381958
Validation loss: 2.089471617052632

Epoch: 6| Step: 6
Training loss: 1.6883094310760498
Validation loss: 2.0892040293703795

Epoch: 6| Step: 7
Training loss: 1.8761978149414062
Validation loss: 2.0698640167072253

Epoch: 6| Step: 8
Training loss: 1.5384982824325562
Validation loss: 2.068098501492572

Epoch: 6| Step: 9
Training loss: 2.093428134918213
Validation loss: 2.0526344109607

Epoch: 6| Step: 10
Training loss: 1.2287112474441528
Validation loss: 2.041231691196401

Epoch: 6| Step: 11
Training loss: 2.5753722190856934
Validation loss: 2.0611502098780807

Epoch: 6| Step: 12
Training loss: 1.8888239860534668
Validation loss: 2.065220694388113

Epoch: 6| Step: 13
Training loss: 2.271050453186035
Validation loss: 2.0953507372128066

Epoch: 125| Step: 0
Training loss: 1.9375410079956055
Validation loss: 2.112003413579797

Epoch: 6| Step: 1
Training loss: 2.302661895751953
Validation loss: 2.0976404579736854

Epoch: 6| Step: 2
Training loss: 2.076894521713257
Validation loss: 2.058809108631585

Epoch: 6| Step: 3
Training loss: 1.7981969118118286
Validation loss: 2.032637498712027

Epoch: 6| Step: 4
Training loss: 1.8967015743255615
Validation loss: 2.009875951274749

Epoch: 6| Step: 5
Training loss: 1.5530129671096802
Validation loss: 1.9873648587093558

Epoch: 6| Step: 6
Training loss: 1.7058486938476562
Validation loss: 1.9783842127810243

Epoch: 6| Step: 7
Training loss: 1.9778703451156616
Validation loss: 1.9770528013988207

Epoch: 6| Step: 8
Training loss: 2.006012439727783
Validation loss: 1.9806968806892313

Epoch: 6| Step: 9
Training loss: 1.299084186553955
Validation loss: 1.9919675409152944

Epoch: 6| Step: 10
Training loss: 1.4688694477081299
Validation loss: 2.007931569571136

Epoch: 6| Step: 11
Training loss: 1.9891406297683716
Validation loss: 2.0245207496868667

Epoch: 6| Step: 12
Training loss: 1.7161908149719238
Validation loss: 2.0279500099920456

Epoch: 6| Step: 13
Training loss: 0.91498863697052
Validation loss: 2.054032310362785

Epoch: 126| Step: 0
Training loss: 1.7336153984069824
Validation loss: 2.0640778272382674

Epoch: 6| Step: 1
Training loss: 1.410282850265503
Validation loss: 2.0368149793276222

Epoch: 6| Step: 2
Training loss: 2.2023868560791016
Validation loss: 2.0278955813377135

Epoch: 6| Step: 3
Training loss: 2.042670726776123
Validation loss: 2.0289306268897107

Epoch: 6| Step: 4
Training loss: 1.7358503341674805
Validation loss: 2.03987023907323

Epoch: 6| Step: 5
Training loss: 1.209388017654419
Validation loss: 2.0174665976596136

Epoch: 6| Step: 6
Training loss: 2.4020659923553467
Validation loss: 2.012737612570486

Epoch: 6| Step: 7
Training loss: 1.9003876447677612
Validation loss: 2.0009731797761816

Epoch: 6| Step: 8
Training loss: 1.6666033267974854
Validation loss: 2.000326710362588

Epoch: 6| Step: 9
Training loss: 1.5643107891082764
Validation loss: 1.9994499196288407

Epoch: 6| Step: 10
Training loss: 1.5652177333831787
Validation loss: 2.0086991735683974

Epoch: 6| Step: 11
Training loss: 1.7144675254821777
Validation loss: 2.0081380336515364

Epoch: 6| Step: 12
Training loss: 1.5532920360565186
Validation loss: 2.0147699643206853

Epoch: 6| Step: 13
Training loss: 1.803011178970337
Validation loss: 2.0200228460373415

Epoch: 127| Step: 0
Training loss: 1.6321446895599365
Validation loss: 2.0029268777498634

Epoch: 6| Step: 1
Training loss: 1.8812854290008545
Validation loss: 1.9646333289402786

Epoch: 6| Step: 2
Training loss: 1.4115839004516602
Validation loss: 1.9815634450604838

Epoch: 6| Step: 3
Training loss: 1.8464391231536865
Validation loss: 1.9711679066381147

Epoch: 6| Step: 4
Training loss: 1.779217004776001
Validation loss: 1.9755869629562541

Epoch: 6| Step: 5
Training loss: 1.747157096862793
Validation loss: 1.9672117746004494

Epoch: 6| Step: 6
Training loss: 1.4558744430541992
Validation loss: 1.9841614141259143

Epoch: 6| Step: 7
Training loss: 2.4813449382781982
Validation loss: 1.9975808102597472

Epoch: 6| Step: 8
Training loss: 1.679997205734253
Validation loss: 2.0214875795507945

Epoch: 6| Step: 9
Training loss: 1.4492355585098267
Validation loss: 2.062139948209127

Epoch: 6| Step: 10
Training loss: 2.236598014831543
Validation loss: 2.095094765386274

Epoch: 6| Step: 11
Training loss: 1.6680588722229004
Validation loss: 2.1137123146364765

Epoch: 6| Step: 12
Training loss: 1.5742945671081543
Validation loss: 2.121869320510536

Epoch: 6| Step: 13
Training loss: 1.6474876403808594
Validation loss: 2.0855925365160872

Epoch: 128| Step: 0
Training loss: 1.7409961223602295
Validation loss: 2.0785301821206206

Epoch: 6| Step: 1
Training loss: 1.6529247760772705
Validation loss: 2.0816171451281478

Epoch: 6| Step: 2
Training loss: 1.0526070594787598
Validation loss: 2.0876181715278217

Epoch: 6| Step: 3
Training loss: 1.5070116519927979
Validation loss: 2.079764496895575

Epoch: 6| Step: 4
Training loss: 1.9173094034194946
Validation loss: 2.0809166200699343

Epoch: 6| Step: 5
Training loss: 1.6682311296463013
Validation loss: 2.078439676633445

Epoch: 6| Step: 6
Training loss: 1.5848619937896729
Validation loss: 2.051234404246012

Epoch: 6| Step: 7
Training loss: 1.7176460027694702
Validation loss: 2.0125063785942654

Epoch: 6| Step: 8
Training loss: 2.0258212089538574
Validation loss: 1.9909671660392516

Epoch: 6| Step: 9
Training loss: 1.80727219581604
Validation loss: 1.9719346928340133

Epoch: 6| Step: 10
Training loss: 1.212632417678833
Validation loss: 1.943429918699367

Epoch: 6| Step: 11
Training loss: 2.323624849319458
Validation loss: 1.9486128296903384

Epoch: 6| Step: 12
Training loss: 1.7388666868209839
Validation loss: 1.9386461601462415

Epoch: 6| Step: 13
Training loss: 2.337501049041748
Validation loss: 1.951540167613696

Epoch: 129| Step: 0
Training loss: 1.6207906007766724
Validation loss: 1.979180028361659

Epoch: 6| Step: 1
Training loss: 2.5591049194335938
Validation loss: 1.9955095103991929

Epoch: 6| Step: 2
Training loss: 1.4591872692108154
Validation loss: 2.0199024087639263

Epoch: 6| Step: 3
Training loss: 1.829869270324707
Validation loss: 2.0388673992567163

Epoch: 6| Step: 4
Training loss: 1.7526049613952637
Validation loss: 2.042918430861606

Epoch: 6| Step: 5
Training loss: 1.657454252243042
Validation loss: 2.059402815757259

Epoch: 6| Step: 6
Training loss: 1.264655590057373
Validation loss: 2.088803074693167

Epoch: 6| Step: 7
Training loss: 1.2472487688064575
Validation loss: 2.0880688576288122

Epoch: 6| Step: 8
Training loss: 2.8980937004089355
Validation loss: 2.104543473130913

Epoch: 6| Step: 9
Training loss: 1.2157158851623535
Validation loss: 2.116602243915681

Epoch: 6| Step: 10
Training loss: 1.6789271831512451
Validation loss: 2.1324761926486926

Epoch: 6| Step: 11
Training loss: 1.5754411220550537
Validation loss: 2.1401674850012666

Epoch: 6| Step: 12
Training loss: 1.5226223468780518
Validation loss: 2.1250221639551143

Epoch: 6| Step: 13
Training loss: 2.2278621196746826
Validation loss: 2.107827148129863

Epoch: 130| Step: 0
Training loss: 1.0941873788833618
Validation loss: 2.0540309567605295

Epoch: 6| Step: 1
Training loss: 1.2053155899047852
Validation loss: 2.0226976897126887

Epoch: 6| Step: 2
Training loss: 2.1275370121002197
Validation loss: 2.0099460207005984

Epoch: 6| Step: 3
Training loss: 1.6806135177612305
Validation loss: 1.9923353143917617

Epoch: 6| Step: 4
Training loss: 1.4154144525527954
Validation loss: 1.953829139791509

Epoch: 6| Step: 5
Training loss: 0.9384555816650391
Validation loss: 1.939456897397195

Epoch: 6| Step: 6
Training loss: 2.0839853286743164
Validation loss: 1.9408085730768019

Epoch: 6| Step: 7
Training loss: 2.1090943813323975
Validation loss: 1.9393242905216832

Epoch: 6| Step: 8
Training loss: 2.265961170196533
Validation loss: 1.9459906931846374

Epoch: 6| Step: 9
Training loss: 1.7355308532714844
Validation loss: 1.9632819262883996

Epoch: 6| Step: 10
Training loss: 1.2843925952911377
Validation loss: 1.98240065574646

Epoch: 6| Step: 11
Training loss: 1.8090943098068237
Validation loss: 1.9907512036702966

Epoch: 6| Step: 12
Training loss: 1.9384818077087402
Validation loss: 2.02740821530742

Epoch: 6| Step: 13
Training loss: 2.3378515243530273
Validation loss: 2.0407637088529524

Epoch: 131| Step: 0
Training loss: 1.9392952919006348
Validation loss: 2.040198197928808

Epoch: 6| Step: 1
Training loss: 1.7713596820831299
Validation loss: 2.0237580730069067

Epoch: 6| Step: 2
Training loss: 1.5871790647506714
Validation loss: 2.0063789454839562

Epoch: 6| Step: 3
Training loss: 1.152648687362671
Validation loss: 1.9986434187940372

Epoch: 6| Step: 4
Training loss: 1.5924768447875977
Validation loss: 2.017200844262236

Epoch: 6| Step: 5
Training loss: 1.8129932880401611
Validation loss: 2.0203720972102177

Epoch: 6| Step: 6
Training loss: 1.7564332485198975
Validation loss: 2.0184695284853698

Epoch: 6| Step: 7
Training loss: 1.4971733093261719
Validation loss: 2.0125858745267315

Epoch: 6| Step: 8
Training loss: 1.5428001880645752
Validation loss: 2.057691586914883

Epoch: 6| Step: 9
Training loss: 2.0350561141967773
Validation loss: 2.0832680912428003

Epoch: 6| Step: 10
Training loss: 1.5488379001617432
Validation loss: 2.098740645634231

Epoch: 6| Step: 11
Training loss: 1.786684513092041
Validation loss: 2.105653980726837

Epoch: 6| Step: 12
Training loss: 1.4593284130096436
Validation loss: 2.1022806039420505

Epoch: 6| Step: 13
Training loss: 2.016468048095703
Validation loss: 2.110711564299881

Epoch: 132| Step: 0
Training loss: 1.2940380573272705
Validation loss: 2.0755785613931637

Epoch: 6| Step: 1
Training loss: 2.148266315460205
Validation loss: 2.0343802385432745

Epoch: 6| Step: 2
Training loss: 1.3768315315246582
Validation loss: 2.0303671308743056

Epoch: 6| Step: 3
Training loss: 1.5625706911087036
Validation loss: 2.0336059498530563

Epoch: 6| Step: 4
Training loss: 1.9357364177703857
Validation loss: 2.029496423659786

Epoch: 6| Step: 5
Training loss: 1.9052306413650513
Validation loss: 2.0196959408380653

Epoch: 6| Step: 6
Training loss: 1.8585991859436035
Validation loss: 2.0218531752145417

Epoch: 6| Step: 7
Training loss: 2.001065492630005
Validation loss: 2.024848820060812

Epoch: 6| Step: 8
Training loss: 1.332608699798584
Validation loss: 2.0359384026578677

Epoch: 6| Step: 9
Training loss: 1.864640712738037
Validation loss: 2.065505776354062

Epoch: 6| Step: 10
Training loss: 1.9337985515594482
Validation loss: 2.0791493846524145

Epoch: 6| Step: 11
Training loss: 1.436375379562378
Validation loss: 2.0766536753664733

Epoch: 6| Step: 12
Training loss: 1.2147715091705322
Validation loss: 2.061483093487319

Epoch: 6| Step: 13
Training loss: 1.2104506492614746
Validation loss: 2.0658652731167373

Epoch: 133| Step: 0
Training loss: 1.5178569555282593
Validation loss: 2.0755786088205155

Epoch: 6| Step: 1
Training loss: 1.7007358074188232
Validation loss: 2.0824309331114574

Epoch: 6| Step: 2
Training loss: 1.1356889009475708
Validation loss: 2.085381841146818

Epoch: 6| Step: 3
Training loss: 1.7747881412506104
Validation loss: 2.060832909358445

Epoch: 6| Step: 4
Training loss: 1.1118379831314087
Validation loss: 2.038370649019877

Epoch: 6| Step: 5
Training loss: 1.3938466310501099
Validation loss: 2.0147298189901535

Epoch: 6| Step: 6
Training loss: 1.8091537952423096
Validation loss: 1.9974460627443047

Epoch: 6| Step: 7
Training loss: 2.578857183456421
Validation loss: 2.0036516843303556

Epoch: 6| Step: 8
Training loss: 1.481763243675232
Validation loss: 1.9783350139535882

Epoch: 6| Step: 9
Training loss: 1.829925775527954
Validation loss: 1.9944031443647159

Epoch: 6| Step: 10
Training loss: 1.9548282623291016
Validation loss: 2.0023379146411853

Epoch: 6| Step: 11
Training loss: 1.716533899307251
Validation loss: 2.0198533945186163

Epoch: 6| Step: 12
Training loss: 1.478217601776123
Validation loss: 2.0212181793746127

Epoch: 6| Step: 13
Training loss: 1.176616907119751
Validation loss: 2.017745764024796

Epoch: 134| Step: 0
Training loss: 0.7904120683670044
Validation loss: 2.0043833794132357

Epoch: 6| Step: 1
Training loss: 2.263392448425293
Validation loss: 2.0062922226485385

Epoch: 6| Step: 2
Training loss: 1.6209969520568848
Validation loss: 2.0222827939577

Epoch: 6| Step: 3
Training loss: 1.7477548122406006
Validation loss: 2.019778928449077

Epoch: 6| Step: 4
Training loss: 1.5847678184509277
Validation loss: 2.0349190491502003

Epoch: 6| Step: 5
Training loss: 1.5615640878677368
Validation loss: 2.058704883821549

Epoch: 6| Step: 6
Training loss: 1.2809287309646606
Validation loss: 2.058817503272846

Epoch: 6| Step: 7
Training loss: 1.8255454301834106
Validation loss: 2.060625542876541

Epoch: 6| Step: 8
Training loss: 1.8949298858642578
Validation loss: 2.057003510895596

Epoch: 6| Step: 9
Training loss: 1.436485767364502
Validation loss: 2.026866812859812

Epoch: 6| Step: 10
Training loss: 1.9577199220657349
Validation loss: 2.0001747979912707

Epoch: 6| Step: 11
Training loss: 1.3784557580947876
Validation loss: 1.974794949254682

Epoch: 6| Step: 12
Training loss: 1.2691251039505005
Validation loss: 1.9771479099027571

Epoch: 6| Step: 13
Training loss: 2.2048392295837402
Validation loss: 1.9806012594571678

Epoch: 135| Step: 0
Training loss: 1.492128849029541
Validation loss: 1.973319193368317

Epoch: 6| Step: 1
Training loss: 1.312003254890442
Validation loss: 1.975194340111107

Epoch: 6| Step: 2
Training loss: 1.784040093421936
Validation loss: 1.9700590000357678

Epoch: 6| Step: 3
Training loss: 1.3056408166885376
Validation loss: 1.9651656676364202

Epoch: 6| Step: 4
Training loss: 1.0503334999084473
Validation loss: 1.9628546673764464

Epoch: 6| Step: 5
Training loss: 1.0595848560333252
Validation loss: 1.9860811438611758

Epoch: 6| Step: 6
Training loss: 1.6208763122558594
Validation loss: 1.984296138568591

Epoch: 6| Step: 7
Training loss: 1.88931143283844
Validation loss: 1.9912814222356325

Epoch: 6| Step: 8
Training loss: 1.6502094268798828
Validation loss: 1.9633502793568436

Epoch: 6| Step: 9
Training loss: 2.0952529907226562
Validation loss: 1.9551033435329315

Epoch: 6| Step: 10
Training loss: 1.946489930152893
Validation loss: 1.9671267719678982

Epoch: 6| Step: 11
Training loss: 1.4359701871871948
Validation loss: 2.0069027229021956

Epoch: 6| Step: 12
Training loss: 1.8110393285751343
Validation loss: 2.03624822503777

Epoch: 6| Step: 13
Training loss: 2.0732696056365967
Validation loss: 2.0672322037399455

Epoch: 136| Step: 0
Training loss: 1.39213228225708
Validation loss: 2.0879430745237615

Epoch: 6| Step: 1
Training loss: 1.3484536409378052
Validation loss: 2.0920929601115565

Epoch: 6| Step: 2
Training loss: 1.3159191608428955
Validation loss: 2.1093816462383477

Epoch: 6| Step: 3
Training loss: 1.008610725402832
Validation loss: 2.133598191763765

Epoch: 6| Step: 4
Training loss: 1.5937137603759766
Validation loss: 2.151469953598515

Epoch: 6| Step: 5
Training loss: 1.7707613706588745
Validation loss: 2.167323935416437

Epoch: 6| Step: 6
Training loss: 1.9480746984481812
Validation loss: 2.1512660877678984

Epoch: 6| Step: 7
Training loss: 1.448637843132019
Validation loss: 2.1346937328256588

Epoch: 6| Step: 8
Training loss: 1.6689611673355103
Validation loss: 2.099734237117152

Epoch: 6| Step: 9
Training loss: 1.9459619522094727
Validation loss: 2.0437073246125252

Epoch: 6| Step: 10
Training loss: 1.5085110664367676
Validation loss: 2.0283813963654223

Epoch: 6| Step: 11
Training loss: 1.6835999488830566
Validation loss: 1.980365837773969

Epoch: 6| Step: 12
Training loss: 1.5501823425292969
Validation loss: 1.9703971955084032

Epoch: 6| Step: 13
Training loss: 1.827989101409912
Validation loss: 1.9563763885087864

Epoch: 137| Step: 0
Training loss: 2.080608367919922
Validation loss: 1.926512877146403

Epoch: 6| Step: 1
Training loss: 1.8217370510101318
Validation loss: 1.9255757408757364

Epoch: 6| Step: 2
Training loss: 1.251879334449768
Validation loss: 1.941627694714454

Epoch: 6| Step: 3
Training loss: 1.8121293783187866
Validation loss: 1.9294958960625432

Epoch: 6| Step: 4
Training loss: 1.522722601890564
Validation loss: 1.944527954183599

Epoch: 6| Step: 5
Training loss: 1.41898512840271
Validation loss: 1.9530043999354045

Epoch: 6| Step: 6
Training loss: 1.0320627689361572
Validation loss: 1.9858054678927186

Epoch: 6| Step: 7
Training loss: 1.6643011569976807
Validation loss: 1.9816714307313323

Epoch: 6| Step: 8
Training loss: 1.5074493885040283
Validation loss: 1.9813917683016868

Epoch: 6| Step: 9
Training loss: 1.191068172454834
Validation loss: 2.003149749130331

Epoch: 6| Step: 10
Training loss: 1.578593373298645
Validation loss: 1.9922283439226047

Epoch: 6| Step: 11
Training loss: 1.427756667137146
Validation loss: 2.006303709040406

Epoch: 6| Step: 12
Training loss: 1.9532759189605713
Validation loss: 2.027246523928899

Epoch: 6| Step: 13
Training loss: 1.6427810192108154
Validation loss: 2.049542254017245

Epoch: 138| Step: 0
Training loss: 2.095069408416748
Validation loss: 2.080167229457568

Epoch: 6| Step: 1
Training loss: 1.4571335315704346
Validation loss: 2.0893332112220024

Epoch: 6| Step: 2
Training loss: 1.511022686958313
Validation loss: 2.1154130248613257

Epoch: 6| Step: 3
Training loss: 1.964233636856079
Validation loss: 2.1573167693230415

Epoch: 6| Step: 4
Training loss: 0.9760852456092834
Validation loss: 2.186090269396382

Epoch: 6| Step: 5
Training loss: 1.492706298828125
Validation loss: 2.1770891476702947

Epoch: 6| Step: 6
Training loss: 0.5621196031570435
Validation loss: 2.1062851836604457

Epoch: 6| Step: 7
Training loss: 1.710953712463379
Validation loss: 2.067540822490569

Epoch: 6| Step: 8
Training loss: 1.5967152118682861
Validation loss: 2.027610255825904

Epoch: 6| Step: 9
Training loss: 2.169295072555542
Validation loss: 1.9895139432722522

Epoch: 6| Step: 10
Training loss: 1.8630547523498535
Validation loss: 1.980709243846196

Epoch: 6| Step: 11
Training loss: 1.2316372394561768
Validation loss: 2.0029035947656118

Epoch: 6| Step: 12
Training loss: 1.7441656589508057
Validation loss: 1.9711002072980326

Epoch: 6| Step: 13
Training loss: 1.347851276397705
Validation loss: 1.968166107772499

Epoch: 139| Step: 0
Training loss: 1.2752068042755127
Validation loss: 1.995595783315679

Epoch: 6| Step: 1
Training loss: 0.7525773048400879
Validation loss: 2.0166364639036116

Epoch: 6| Step: 2
Training loss: 1.6899430751800537
Validation loss: 2.04043568975182

Epoch: 6| Step: 3
Training loss: 1.3664838075637817
Validation loss: 2.059423295400476

Epoch: 6| Step: 4
Training loss: 1.588281512260437
Validation loss: 2.0647598492201937

Epoch: 6| Step: 5
Training loss: 1.4866305589675903
Validation loss: 2.051489004524805

Epoch: 6| Step: 6
Training loss: 2.0970377922058105
Validation loss: 2.031077531076247

Epoch: 6| Step: 7
Training loss: 1.7537779808044434
Validation loss: 1.9972661823354743

Epoch: 6| Step: 8
Training loss: 1.0112961530685425
Validation loss: 1.9837633102170882

Epoch: 6| Step: 9
Training loss: 1.4382891654968262
Validation loss: 1.9679793362976403

Epoch: 6| Step: 10
Training loss: 1.6310608386993408
Validation loss: 1.9601897193539528

Epoch: 6| Step: 11
Training loss: 1.7733434438705444
Validation loss: 1.9657925790356052

Epoch: 6| Step: 12
Training loss: 1.8743653297424316
Validation loss: 1.991260617010055

Epoch: 6| Step: 13
Training loss: 1.7924611568450928
Validation loss: 2.0421674161828975

Epoch: 140| Step: 0
Training loss: 1.9504010677337646
Validation loss: 2.067728486112369

Epoch: 6| Step: 1
Training loss: 1.5267506837844849
Validation loss: 2.0894760880419003

Epoch: 6| Step: 2
Training loss: 2.11430025100708
Validation loss: 2.0777215175731207

Epoch: 6| Step: 3
Training loss: 1.323887825012207
Validation loss: 2.0615208020774265

Epoch: 6| Step: 4
Training loss: 1.3062584400177002
Validation loss: 2.0185956980592463

Epoch: 6| Step: 5
Training loss: 2.017498016357422
Validation loss: 2.0152200268160914

Epoch: 6| Step: 6
Training loss: 1.3576927185058594
Validation loss: 2.005118182910386

Epoch: 6| Step: 7
Training loss: 1.0827035903930664
Validation loss: 2.00337472269612

Epoch: 6| Step: 8
Training loss: 0.8175992369651794
Validation loss: 1.995664563230289

Epoch: 6| Step: 9
Training loss: 1.8895965814590454
Validation loss: 1.9914080635193856

Epoch: 6| Step: 10
Training loss: 1.8208181858062744
Validation loss: 2.004050213803527

Epoch: 6| Step: 11
Training loss: 1.1880357265472412
Validation loss: 2.0138372016209427

Epoch: 6| Step: 12
Training loss: 1.5462450981140137
Validation loss: 2.026243912276401

Epoch: 6| Step: 13
Training loss: 0.8397723436355591
Validation loss: 2.019881517656388

Epoch: 141| Step: 0
Training loss: 1.4303030967712402
Validation loss: 2.0234666639758694

Epoch: 6| Step: 1
Training loss: 1.2067759037017822
Validation loss: 2.033187717519781

Epoch: 6| Step: 2
Training loss: 1.5731897354125977
Validation loss: 2.0166249646935412

Epoch: 6| Step: 3
Training loss: 1.0009292364120483
Validation loss: 2.0236752584416378

Epoch: 6| Step: 4
Training loss: 1.8669785261154175
Validation loss: 2.024853035967837

Epoch: 6| Step: 5
Training loss: 0.9184608459472656
Validation loss: 2.0197879627186763

Epoch: 6| Step: 6
Training loss: 1.6234806776046753
Validation loss: 2.010418641951776

Epoch: 6| Step: 7
Training loss: 1.710240364074707
Validation loss: 2.0110964262357323

Epoch: 6| Step: 8
Training loss: 1.3729562759399414
Validation loss: 1.9936495673271917

Epoch: 6| Step: 9
Training loss: 1.0662622451782227
Validation loss: 2.0020675043905936

Epoch: 6| Step: 10
Training loss: 2.1627116203308105
Validation loss: 1.9964660982931814

Epoch: 6| Step: 11
Training loss: 2.127946376800537
Validation loss: 1.9723565629733506

Epoch: 6| Step: 12
Training loss: 1.0985043048858643
Validation loss: 1.9750002327785696

Epoch: 6| Step: 13
Training loss: 0.8949324488639832
Validation loss: 1.9711267691786571

Epoch: 142| Step: 0
Training loss: 1.960255742073059
Validation loss: 1.9444401725645988

Epoch: 6| Step: 1
Training loss: 1.3746417760849
Validation loss: 1.9442215747730707

Epoch: 6| Step: 2
Training loss: 1.3743950128555298
Validation loss: 1.9419684820277716

Epoch: 6| Step: 3
Training loss: 1.1645488739013672
Validation loss: 1.9449644242563555

Epoch: 6| Step: 4
Training loss: 1.6852132081985474
Validation loss: 1.96704319343772

Epoch: 6| Step: 5
Training loss: 1.0604255199432373
Validation loss: 1.9903296116859681

Epoch: 6| Step: 6
Training loss: 1.9140706062316895
Validation loss: 2.035358703264626

Epoch: 6| Step: 7
Training loss: 1.489389181137085
Validation loss: 2.0452874475909817

Epoch: 6| Step: 8
Training loss: 1.4147521257400513
Validation loss: 2.0552663572372927

Epoch: 6| Step: 9
Training loss: 1.2965843677520752
Validation loss: 2.0672395408794446

Epoch: 6| Step: 10
Training loss: 0.9949153661727905
Validation loss: 2.0681619823619886

Epoch: 6| Step: 11
Training loss: 1.5507521629333496
Validation loss: 2.0434852479606547

Epoch: 6| Step: 12
Training loss: 1.800832986831665
Validation loss: 2.03919320209052

Epoch: 6| Step: 13
Training loss: 1.3781542778015137
Validation loss: 2.0323865541847805

Epoch: 143| Step: 0
Training loss: 1.4076189994812012
Validation loss: 2.012202751251959

Epoch: 6| Step: 1
Training loss: 1.7855608463287354
Validation loss: 2.0154892680465535

Epoch: 6| Step: 2
Training loss: 1.8637418746948242
Validation loss: 1.9951142444405505

Epoch: 6| Step: 3
Training loss: 1.2543891668319702
Validation loss: 2.0001163687757266

Epoch: 6| Step: 4
Training loss: 1.3693925142288208
Validation loss: 1.9900242103043424

Epoch: 6| Step: 5
Training loss: 1.009149432182312
Validation loss: 1.9647032932568622

Epoch: 6| Step: 6
Training loss: 1.651115894317627
Validation loss: 1.9793918542964484

Epoch: 6| Step: 7
Training loss: 1.2756099700927734
Validation loss: 2.0019066667044036

Epoch: 6| Step: 8
Training loss: 1.44990873336792
Validation loss: 2.0368731137244933

Epoch: 6| Step: 9
Training loss: 1.7672119140625
Validation loss: 2.069623613870272

Epoch: 6| Step: 10
Training loss: 0.9978213310241699
Validation loss: 2.069561637857909

Epoch: 6| Step: 11
Training loss: 1.2451833486557007
Validation loss: 2.0516928139553277

Epoch: 6| Step: 12
Training loss: 1.7749546766281128
Validation loss: 2.029537472673642

Epoch: 6| Step: 13
Training loss: 1.418178677558899
Validation loss: 1.9775364014410204

Epoch: 144| Step: 0
Training loss: 1.0125341415405273
Validation loss: 1.9870161164191462

Epoch: 6| Step: 1
Training loss: 0.9047331213951111
Validation loss: 2.0123986223692536

Epoch: 6| Step: 2
Training loss: 1.1175686120986938
Validation loss: 2.0419915799171693

Epoch: 6| Step: 3
Training loss: 1.067089319229126
Validation loss: 2.040518856817676

Epoch: 6| Step: 4
Training loss: 1.8174976110458374
Validation loss: 1.9992284044142692

Epoch: 6| Step: 5
Training loss: 1.390801191329956
Validation loss: 1.984230322222556

Epoch: 6| Step: 6
Training loss: 1.1936062574386597
Validation loss: 2.0106099292796147

Epoch: 6| Step: 7
Training loss: 1.6440598964691162
Validation loss: 2.0501969193899505

Epoch: 6| Step: 8
Training loss: 2.469082832336426
Validation loss: 2.0673346109287714

Epoch: 6| Step: 9
Training loss: 2.173208236694336
Validation loss: 2.082210601017039

Epoch: 6| Step: 10
Training loss: 2.0012807846069336
Validation loss: 2.0307730526052494

Epoch: 6| Step: 11
Training loss: 2.076406478881836
Validation loss: 1.9941740920466762

Epoch: 6| Step: 12
Training loss: 1.032335638999939
Validation loss: 1.9734985443853563

Epoch: 6| Step: 13
Training loss: 1.5125417709350586
Validation loss: 1.9549225850771832

Epoch: 145| Step: 0
Training loss: 1.4410288333892822
Validation loss: 1.947839824102258

Epoch: 6| Step: 1
Training loss: 1.3628346920013428
Validation loss: 1.9484784987664991

Epoch: 6| Step: 2
Training loss: 1.3074995279312134
Validation loss: 1.9615735289871052

Epoch: 6| Step: 3
Training loss: 1.5644164085388184
Validation loss: 1.979317888136833

Epoch: 6| Step: 4
Training loss: 2.0461959838867188
Validation loss: 1.9899885257085164

Epoch: 6| Step: 5
Training loss: 1.4603605270385742
Validation loss: 1.9994442821830831

Epoch: 6| Step: 6
Training loss: 1.580641746520996
Validation loss: 2.0360071748815556

Epoch: 6| Step: 7
Training loss: 1.5043456554412842
Validation loss: 2.056656627244847

Epoch: 6| Step: 8
Training loss: 1.1961151361465454
Validation loss: 2.110699351115893

Epoch: 6| Step: 9
Training loss: 1.5412673950195312
Validation loss: 2.105144218731952

Epoch: 6| Step: 10
Training loss: 1.178562879562378
Validation loss: 2.0941053693012526

Epoch: 6| Step: 11
Training loss: 1.19167160987854
Validation loss: 2.09732376375506

Epoch: 6| Step: 12
Training loss: 1.4461007118225098
Validation loss: 2.073997718031688

Epoch: 6| Step: 13
Training loss: 0.8581100106239319
Validation loss: 2.030364910761515

Epoch: 146| Step: 0
Training loss: 1.0493595600128174
Validation loss: 2.0218316637059695

Epoch: 6| Step: 1
Training loss: 1.5053668022155762
Validation loss: 2.0408531388928814

Epoch: 6| Step: 2
Training loss: 2.041626214981079
Validation loss: 2.0440709360184206

Epoch: 6| Step: 3
Training loss: 1.6914091110229492
Validation loss: 2.0423162239854054

Epoch: 6| Step: 4
Training loss: 0.7646802067756653
Validation loss: 2.0273276964823403

Epoch: 6| Step: 5
Training loss: 1.7882288694381714
Validation loss: 2.0305684330642864

Epoch: 6| Step: 6
Training loss: 1.515197515487671
Validation loss: 2.065034279259302

Epoch: 6| Step: 7
Training loss: 1.1363575458526611
Validation loss: 2.1394916106295843

Epoch: 6| Step: 8
Training loss: 1.4568029642105103
Validation loss: 2.1838054592891405

Epoch: 6| Step: 9
Training loss: 1.5732182264328003
Validation loss: 2.214440535473567

Epoch: 6| Step: 10
Training loss: 2.025296449661255
Validation loss: 2.2360593477884927

Epoch: 6| Step: 11
Training loss: 1.1106551885604858
Validation loss: 2.2358295994420208

Epoch: 6| Step: 12
Training loss: 1.7441155910491943
Validation loss: 2.2175014506104174

Epoch: 6| Step: 13
Training loss: 0.691936731338501
Validation loss: 2.1344730879670832

Epoch: 147| Step: 0
Training loss: 0.8427738547325134
Validation loss: 2.089840289085142

Epoch: 6| Step: 1
Training loss: 1.5627689361572266
Validation loss: 2.0349959352964997

Epoch: 6| Step: 2
Training loss: 1.7742784023284912
Validation loss: 2.02106640672171

Epoch: 6| Step: 3
Training loss: 1.7739105224609375
Validation loss: 2.0308383651959

Epoch: 6| Step: 4
Training loss: 1.2507963180541992
Validation loss: 2.069918619689121

Epoch: 6| Step: 5
Training loss: 1.4492098093032837
Validation loss: 2.0578935300150225

Epoch: 6| Step: 6
Training loss: 1.4427074193954468
Validation loss: 2.058729692171979

Epoch: 6| Step: 7
Training loss: 1.5728278160095215
Validation loss: 2.0355475269338137

Epoch: 6| Step: 8
Training loss: 2.0019707679748535
Validation loss: 2.0400704927341913

Epoch: 6| Step: 9
Training loss: 1.0894241333007812
Validation loss: 2.0218632272494736

Epoch: 6| Step: 10
Training loss: 0.8599228858947754
Validation loss: 2.0784049521210375

Epoch: 6| Step: 11
Training loss: 1.408232569694519
Validation loss: 2.0880407953775055

Epoch: 6| Step: 12
Training loss: 1.6251981258392334
Validation loss: 2.1087066486317623

Epoch: 6| Step: 13
Training loss: 1.156121850013733
Validation loss: 2.1005439091754217

Epoch: 148| Step: 0
Training loss: 1.6157240867614746
Validation loss: 2.0606957609935472

Epoch: 6| Step: 1
Training loss: 1.3721343278884888
Validation loss: 2.0212947194294264

Epoch: 6| Step: 2
Training loss: 1.4419682025909424
Validation loss: 1.9736386127369379

Epoch: 6| Step: 3
Training loss: 1.2651257514953613
Validation loss: 1.9597897170692362

Epoch: 6| Step: 4
Training loss: 0.964977502822876
Validation loss: 1.950367994205926

Epoch: 6| Step: 5
Training loss: 1.2691075801849365
Validation loss: 1.95195020398786

Epoch: 6| Step: 6
Training loss: 1.958784818649292
Validation loss: 1.945511999950614

Epoch: 6| Step: 7
Training loss: 1.799992322921753
Validation loss: 1.9457774175110685

Epoch: 6| Step: 8
Training loss: 0.8680608868598938
Validation loss: 1.954947406245816

Epoch: 6| Step: 9
Training loss: 0.966679036617279
Validation loss: 1.9701003105409685

Epoch: 6| Step: 10
Training loss: 1.4318432807922363
Validation loss: 2.019532811257147

Epoch: 6| Step: 11
Training loss: 1.3083908557891846
Validation loss: 2.029524169942384

Epoch: 6| Step: 12
Training loss: 2.009148120880127
Validation loss: 2.0664755657155025

Epoch: 6| Step: 13
Training loss: 1.1209454536437988
Validation loss: 2.107098533261207

Epoch: 149| Step: 0
Training loss: 1.427616834640503
Validation loss: 2.1312591645025436

Epoch: 6| Step: 1
Training loss: 0.9073807001113892
Validation loss: 2.1321106649214223

Epoch: 6| Step: 2
Training loss: 0.7713683247566223
Validation loss: 2.0692531626711608

Epoch: 6| Step: 3
Training loss: 0.597010612487793
Validation loss: 2.0306160462799894

Epoch: 6| Step: 4
Training loss: 1.2970620393753052
Validation loss: 2.00460547272877

Epoch: 6| Step: 5
Training loss: 2.0620126724243164
Validation loss: 1.9828234744328324

Epoch: 6| Step: 6
Training loss: 1.0697442293167114
Validation loss: 1.961539130057058

Epoch: 6| Step: 7
Training loss: 1.2075111865997314
Validation loss: 1.9494583042719031

Epoch: 6| Step: 8
Training loss: 2.0186729431152344
Validation loss: 1.9611946126466155

Epoch: 6| Step: 9
Training loss: 1.541628122329712
Validation loss: 1.9702943166097004

Epoch: 6| Step: 10
Training loss: 1.5692265033721924
Validation loss: 2.006971251580023

Epoch: 6| Step: 11
Training loss: 1.5710458755493164
Validation loss: 2.00763778532705

Epoch: 6| Step: 12
Training loss: 1.7891098260879517
Validation loss: 2.002361015606952

Epoch: 6| Step: 13
Training loss: 1.898366093635559
Validation loss: 1.9860362314408826

Epoch: 150| Step: 0
Training loss: 1.2282979488372803
Validation loss: 1.9860380093256633

Epoch: 6| Step: 1
Training loss: 1.463932752609253
Validation loss: 2.0016215385929232

Epoch: 6| Step: 2
Training loss: 1.1782081127166748
Validation loss: 1.998587526300902

Epoch: 6| Step: 3
Training loss: 1.6092286109924316
Validation loss: 1.9775353734211256

Epoch: 6| Step: 4
Training loss: 0.9487783908843994
Validation loss: 1.9916635123632287

Epoch: 6| Step: 5
Training loss: 1.7032890319824219
Validation loss: 2.0112534902429067

Epoch: 6| Step: 6
Training loss: 1.0756783485412598
Validation loss: 2.0032007168698054

Epoch: 6| Step: 7
Training loss: 1.283858060836792
Validation loss: 2.0108098727400585

Epoch: 6| Step: 8
Training loss: 1.7859152555465698
Validation loss: 2.0385139321768158

Epoch: 6| Step: 9
Training loss: 1.5655484199523926
Validation loss: 2.027877348725514

Epoch: 6| Step: 10
Training loss: 1.4185965061187744
Validation loss: 2.0673618649923675

Epoch: 6| Step: 11
Training loss: 1.0354938507080078
Validation loss: 2.0237494514834498

Epoch: 6| Step: 12
Training loss: 0.9057894945144653
Validation loss: 2.021029546696653

Epoch: 6| Step: 13
Training loss: 1.7446272373199463
Validation loss: 2.0211327537413566

Epoch: 151| Step: 0
Training loss: 1.6960786581039429
Validation loss: 2.0319179924585486

Epoch: 6| Step: 1
Training loss: 1.281130075454712
Validation loss: 2.0127940280463106

Epoch: 6| Step: 2
Training loss: 1.6659719944000244
Validation loss: 2.022905683004728

Epoch: 6| Step: 3
Training loss: 1.330693006515503
Validation loss: 2.025835842214605

Epoch: 6| Step: 4
Training loss: 0.9391429424285889
Validation loss: 2.0015415722324

Epoch: 6| Step: 5
Training loss: 1.8499295711517334
Validation loss: 1.9809112625737344

Epoch: 6| Step: 6
Training loss: 0.5528231263160706
Validation loss: 1.968951912336452

Epoch: 6| Step: 7
Training loss: 1.868849277496338
Validation loss: 1.941868192406111

Epoch: 6| Step: 8
Training loss: 1.2944611310958862
Validation loss: 1.9430945791223997

Epoch: 6| Step: 9
Training loss: 1.2525722980499268
Validation loss: 1.9231198500561457

Epoch: 6| Step: 10
Training loss: 1.3920230865478516
Validation loss: 1.9452700281655917

Epoch: 6| Step: 11
Training loss: 1.2196834087371826
Validation loss: 1.9713876132042176

Epoch: 6| Step: 12
Training loss: 0.9298234581947327
Validation loss: 1.9985505868029851

Epoch: 6| Step: 13
Training loss: 0.9527390599250793
Validation loss: 2.0132331040597733

Epoch: 152| Step: 0
Training loss: 0.6237804889678955
Validation loss: 2.0263658774796354

Epoch: 6| Step: 1
Training loss: 1.388871192932129
Validation loss: 2.0462748363453853

Epoch: 6| Step: 2
Training loss: 1.137014627456665
Validation loss: 2.058474635565153

Epoch: 6| Step: 3
Training loss: 1.3112988471984863
Validation loss: 2.0481608503608295

Epoch: 6| Step: 4
Training loss: 1.9347221851348877
Validation loss: 2.056100655627507

Epoch: 6| Step: 5
Training loss: 1.2498211860656738
Validation loss: 2.03519977677253

Epoch: 6| Step: 6
Training loss: 1.681962490081787
Validation loss: 2.0360253959573726

Epoch: 6| Step: 7
Training loss: 0.9757301807403564
Validation loss: 2.031490969401534

Epoch: 6| Step: 8
Training loss: 1.2958652973175049
Validation loss: 2.02260680865216

Epoch: 6| Step: 9
Training loss: 1.2112464904785156
Validation loss: 1.9816529981551632

Epoch: 6| Step: 10
Training loss: 1.3827816247940063
Validation loss: 1.969486057117421

Epoch: 6| Step: 11
Training loss: 1.521267294883728
Validation loss: 1.9612160805732972

Epoch: 6| Step: 12
Training loss: 1.4683688879013062
Validation loss: 1.9454062933562903

Epoch: 6| Step: 13
Training loss: 1.4653228521347046
Validation loss: 1.9646931412399455

Epoch: 153| Step: 0
Training loss: 1.3462165594100952
Validation loss: 1.9579980450291787

Epoch: 6| Step: 1
Training loss: 1.4915685653686523
Validation loss: 1.9598099621393348

Epoch: 6| Step: 2
Training loss: 1.155116319656372
Validation loss: 1.9421626124330746

Epoch: 6| Step: 3
Training loss: 1.3410375118255615
Validation loss: 1.922921089715855

Epoch: 6| Step: 4
Training loss: 1.3370527029037476
Validation loss: 1.9154173815122215

Epoch: 6| Step: 5
Training loss: 1.219651222229004
Validation loss: 1.9299959444230603

Epoch: 6| Step: 6
Training loss: 1.3970359563827515
Validation loss: 1.9460555943109656

Epoch: 6| Step: 7
Training loss: 1.136317491531372
Validation loss: 1.9505056540171306

Epoch: 6| Step: 8
Training loss: 2.25234317779541
Validation loss: 1.9615719651663175

Epoch: 6| Step: 9
Training loss: 1.4795316457748413
Validation loss: 1.969096124813121

Epoch: 6| Step: 10
Training loss: 0.6515893340110779
Validation loss: 2.0304887602406163

Epoch: 6| Step: 11
Training loss: 1.4798274040222168
Validation loss: 2.0825889033655964

Epoch: 6| Step: 12
Training loss: 1.5644179582595825
Validation loss: 2.1370644774488223

Epoch: 6| Step: 13
Training loss: 1.4793050289154053
Validation loss: 2.1417643075348227

Epoch: 154| Step: 0
Training loss: 1.2442078590393066
Validation loss: 2.101865609486898

Epoch: 6| Step: 1
Training loss: 1.754058837890625
Validation loss: 2.023192544137278

Epoch: 6| Step: 2
Training loss: 1.6183192729949951
Validation loss: 1.9866163217893211

Epoch: 6| Step: 3
Training loss: 1.106940746307373
Validation loss: 1.9715217595459313

Epoch: 6| Step: 4
Training loss: 0.8431782722473145
Validation loss: 1.9862165938141525

Epoch: 6| Step: 5
Training loss: 1.2763772010803223
Validation loss: 2.005633536205497

Epoch: 6| Step: 6
Training loss: 1.005133867263794
Validation loss: 2.002846110251642

Epoch: 6| Step: 7
Training loss: 1.3117265701293945
Validation loss: 1.9771798579923567

Epoch: 6| Step: 8
Training loss: 1.1651488542556763
Validation loss: 1.9669039877512122

Epoch: 6| Step: 9
Training loss: 1.6608483791351318
Validation loss: 1.9696024976750857

Epoch: 6| Step: 10
Training loss: 1.689157247543335
Validation loss: 1.9746016584416872

Epoch: 6| Step: 11
Training loss: 1.0842360258102417
Validation loss: 1.991872323456631

Epoch: 6| Step: 12
Training loss: 1.1996042728424072
Validation loss: 2.010471966958815

Epoch: 6| Step: 13
Training loss: 1.6898354291915894
Validation loss: 2.030575598439863

Epoch: 155| Step: 0
Training loss: 1.4648958444595337
Validation loss: 2.0409019147196124

Epoch: 6| Step: 1
Training loss: 1.6035523414611816
Validation loss: 2.0263535873864287

Epoch: 6| Step: 2
Training loss: 1.1263983249664307
Validation loss: 2.0275518753195323

Epoch: 6| Step: 3
Training loss: 1.0956981182098389
Validation loss: 2.014519981158677

Epoch: 6| Step: 4
Training loss: 1.07671320438385
Validation loss: 1.9910288036510508

Epoch: 6| Step: 5
Training loss: 1.0088016986846924
Validation loss: 1.9917762766602218

Epoch: 6| Step: 6
Training loss: 1.8024022579193115
Validation loss: 1.997052090142363

Epoch: 6| Step: 7
Training loss: 1.5044636726379395
Validation loss: 2.008058562073656

Epoch: 6| Step: 8
Training loss: 1.161942481994629
Validation loss: 1.989110699263952

Epoch: 6| Step: 9
Training loss: 1.1537566184997559
Validation loss: 1.984339616631949

Epoch: 6| Step: 10
Training loss: 0.9480540156364441
Validation loss: 1.9812256290066628

Epoch: 6| Step: 11
Training loss: 1.3623842000961304
Validation loss: 1.973699604311297

Epoch: 6| Step: 12
Training loss: 1.0305113792419434
Validation loss: 1.980695680905414

Epoch: 6| Step: 13
Training loss: 1.1041748523712158
Validation loss: 2.0315072600559523

Epoch: 156| Step: 0
Training loss: 1.5683856010437012
Validation loss: 2.0324592641604844

Epoch: 6| Step: 1
Training loss: 0.8401222229003906
Validation loss: 2.04506060641299

Epoch: 6| Step: 2
Training loss: 1.3359873294830322
Validation loss: 2.0375031578925347

Epoch: 6| Step: 3
Training loss: 1.4178712368011475
Validation loss: 2.013228597179536

Epoch: 6| Step: 4
Training loss: 1.3733654022216797
Validation loss: 2.0027289749473653

Epoch: 6| Step: 5
Training loss: 1.4179868698120117
Validation loss: 2.0115732557030133

Epoch: 6| Step: 6
Training loss: 1.1981120109558105
Validation loss: 2.0057911654954315

Epoch: 6| Step: 7
Training loss: 0.5784009695053101
Validation loss: 2.016339798127451

Epoch: 6| Step: 8
Training loss: 1.230086326599121
Validation loss: 1.9922446768770936

Epoch: 6| Step: 9
Training loss: 0.9055658578872681
Validation loss: 1.9733304208324802

Epoch: 6| Step: 10
Training loss: 1.529547929763794
Validation loss: 1.9794825430839293

Epoch: 6| Step: 11
Training loss: 1.333640456199646
Validation loss: 1.9814384239976124

Epoch: 6| Step: 12
Training loss: 1.3584644794464111
Validation loss: 1.9872057155896259

Epoch: 6| Step: 13
Training loss: 1.735399842262268
Validation loss: 1.9914706727509857

Epoch: 157| Step: 0
Training loss: 1.4884246587753296
Validation loss: 1.9955757407731907

Epoch: 6| Step: 1
Training loss: 1.2524988651275635
Validation loss: 1.9865963510287705

Epoch: 6| Step: 2
Training loss: 1.2477343082427979
Validation loss: 1.978533358984096

Epoch: 6| Step: 3
Training loss: 1.7190577983856201
Validation loss: 1.9608583168316913

Epoch: 6| Step: 4
Training loss: 0.8683418035507202
Validation loss: 1.9910708550483949

Epoch: 6| Step: 5
Training loss: 0.6947304010391235
Validation loss: 1.9711871634247482

Epoch: 6| Step: 6
Training loss: 1.4752362966537476
Validation loss: 1.9793771338719193

Epoch: 6| Step: 7
Training loss: 1.3851152658462524
Validation loss: 1.9696834497554327

Epoch: 6| Step: 8
Training loss: 1.0713918209075928
Validation loss: 1.962360594862251

Epoch: 6| Step: 9
Training loss: 1.2718360424041748
Validation loss: 1.9938915698759017

Epoch: 6| Step: 10
Training loss: 1.2651728391647339
Validation loss: 1.979212248197166

Epoch: 6| Step: 11
Training loss: 1.2374061346054077
Validation loss: 1.9683208721940235

Epoch: 6| Step: 12
Training loss: 1.0129272937774658
Validation loss: 1.955246602335284

Epoch: 6| Step: 13
Training loss: 1.3943430185317993
Validation loss: 1.9615505280033234

Epoch: 158| Step: 0
Training loss: 1.0302071571350098
Validation loss: 1.9717934977623723

Epoch: 6| Step: 1
Training loss: 1.3465548753738403
Validation loss: 1.9913669683599984

Epoch: 6| Step: 2
Training loss: 1.5636277198791504
Validation loss: 1.9770202470082108

Epoch: 6| Step: 3
Training loss: 1.3408722877502441
Validation loss: 1.9794003335378503

Epoch: 6| Step: 4
Training loss: 1.257652997970581
Validation loss: 1.9811094678858274

Epoch: 6| Step: 5
Training loss: 1.2526371479034424
Validation loss: 1.9969498752265848

Epoch: 6| Step: 6
Training loss: 1.433741807937622
Validation loss: 2.0123607471425045

Epoch: 6| Step: 7
Training loss: 1.0604054927825928
Validation loss: 2.027387665164086

Epoch: 6| Step: 8
Training loss: 1.4764312505722046
Validation loss: 2.042328602524214

Epoch: 6| Step: 9
Training loss: 1.5815989971160889
Validation loss: 2.0589812314638527

Epoch: 6| Step: 10
Training loss: 0.7143130302429199
Validation loss: 2.065847501959852

Epoch: 6| Step: 11
Training loss: 1.1677968502044678
Validation loss: 2.0461089841781126

Epoch: 6| Step: 12
Training loss: 0.8486572504043579
Validation loss: 2.025321820730804

Epoch: 6| Step: 13
Training loss: 0.4649207293987274
Validation loss: 1.9924420259332145

Epoch: 159| Step: 0
Training loss: 1.7410215139389038
Validation loss: 1.9662989736885153

Epoch: 6| Step: 1
Training loss: 0.9426464438438416
Validation loss: 1.9184372848080051

Epoch: 6| Step: 2
Training loss: 1.0468745231628418
Validation loss: 1.902291690149615

Epoch: 6| Step: 3
Training loss: 1.4585822820663452
Validation loss: 1.9195584058761597

Epoch: 6| Step: 4
Training loss: 1.379117488861084
Validation loss: 1.9134303498011764

Epoch: 6| Step: 5
Training loss: 1.5527279376983643
Validation loss: 1.9119038761302989

Epoch: 6| Step: 6
Training loss: 1.193998098373413
Validation loss: 1.942924609748266

Epoch: 6| Step: 7
Training loss: 1.1131187677383423
Validation loss: 1.9689390454241025

Epoch: 6| Step: 8
Training loss: 1.132979154586792
Validation loss: 1.992932108140761

Epoch: 6| Step: 9
Training loss: 0.45174098014831543
Validation loss: 2.040311135271544

Epoch: 6| Step: 10
Training loss: 1.5215177536010742
Validation loss: 2.0181831006080873

Epoch: 6| Step: 11
Training loss: 1.1700094938278198
Validation loss: 2.0037362216621317

Epoch: 6| Step: 12
Training loss: 0.9728496074676514
Validation loss: 2.0160491299885575

Epoch: 6| Step: 13
Training loss: 1.005794644355774
Validation loss: 2.013299736925351

Epoch: 160| Step: 0
Training loss: 1.015570044517517
Validation loss: 2.0136022644658245

Epoch: 6| Step: 1
Training loss: 1.1591252088546753
Validation loss: 2.0176829240655385

Epoch: 6| Step: 2
Training loss: 1.5474151372909546
Validation loss: 2.026292465066397

Epoch: 6| Step: 3
Training loss: 1.155900478363037
Validation loss: 1.9971529360740417

Epoch: 6| Step: 4
Training loss: 1.298668384552002
Validation loss: 1.984875314979143

Epoch: 6| Step: 5
Training loss: 1.3296149969100952
Validation loss: 1.9830755418346775

Epoch: 6| Step: 6
Training loss: 1.425464391708374
Validation loss: 2.0025350175878054

Epoch: 6| Step: 7
Training loss: 0.9006775617599487
Validation loss: 1.998086021792504

Epoch: 6| Step: 8
Training loss: 1.1331554651260376
Validation loss: 2.0110257056451615

Epoch: 6| Step: 9
Training loss: 0.8546436429023743
Validation loss: 1.9866960535767257

Epoch: 6| Step: 10
Training loss: 0.7956733107566833
Validation loss: 1.9712617551126788

Epoch: 6| Step: 11
Training loss: 0.8775643110275269
Validation loss: 1.950952688852946

Epoch: 6| Step: 12
Training loss: 1.264185905456543
Validation loss: 1.9353117814628027

Epoch: 6| Step: 13
Training loss: 1.8543570041656494
Validation loss: 1.923880636051137

Epoch: 161| Step: 0
Training loss: 1.1249823570251465
Validation loss: 1.9239105306645876

Epoch: 6| Step: 1
Training loss: 1.3188352584838867
Validation loss: 1.9382553318495392

Epoch: 6| Step: 2
Training loss: 1.1891779899597168
Validation loss: 1.9602200882409209

Epoch: 6| Step: 3
Training loss: 1.0985643863677979
Validation loss: 1.9952192255245742

Epoch: 6| Step: 4
Training loss: 0.9095820188522339
Validation loss: 2.011580292896558

Epoch: 6| Step: 5
Training loss: 1.091713547706604
Validation loss: 2.0115791341309905

Epoch: 6| Step: 6
Training loss: 1.4912936687469482
Validation loss: 2.019321508305047

Epoch: 6| Step: 7
Training loss: 0.957854151725769
Validation loss: 2.001623974051527

Epoch: 6| Step: 8
Training loss: 1.1045124530792236
Validation loss: 1.9602126998286094

Epoch: 6| Step: 9
Training loss: 1.2622874975204468
Validation loss: 1.943399570321524

Epoch: 6| Step: 10
Training loss: 1.3538339138031006
Validation loss: 1.9264314354106944

Epoch: 6| Step: 11
Training loss: 1.136467456817627
Validation loss: 1.9345565290861233

Epoch: 6| Step: 12
Training loss: 0.7965896129608154
Validation loss: 1.9298656012422295

Epoch: 6| Step: 13
Training loss: 1.656571388244629
Validation loss: 1.9391590497827018

Epoch: 162| Step: 0
Training loss: 1.5033245086669922
Validation loss: 1.906420418011245

Epoch: 6| Step: 1
Training loss: 1.2156355381011963
Validation loss: 1.9132141028681109

Epoch: 6| Step: 2
Training loss: 1.0964819192886353
Validation loss: 1.9162480241508895

Epoch: 6| Step: 3
Training loss: 1.4129585027694702
Validation loss: 1.9074125943645355

Epoch: 6| Step: 4
Training loss: 1.4097259044647217
Validation loss: 1.930882377009238

Epoch: 6| Step: 5
Training loss: 0.8344300985336304
Validation loss: 1.9343631831548547

Epoch: 6| Step: 6
Training loss: 1.099879503250122
Validation loss: 1.9431397440612956

Epoch: 6| Step: 7
Training loss: 1.334761142730713
Validation loss: 1.9257535049992223

Epoch: 6| Step: 8
Training loss: 1.1564502716064453
Validation loss: 1.9363352380773073

Epoch: 6| Step: 9
Training loss: 1.0372496843338013
Validation loss: 1.9542430216266262

Epoch: 6| Step: 10
Training loss: 1.2929816246032715
Validation loss: 1.9606153913723525

Epoch: 6| Step: 11
Training loss: 0.6651492118835449
Validation loss: 1.9945595072161766

Epoch: 6| Step: 12
Training loss: 0.7061601877212524
Validation loss: 2.0142528510862783

Epoch: 6| Step: 13
Training loss: 1.4645209312438965
Validation loss: 2.021311221584197

Epoch: 163| Step: 0
Training loss: 0.9967872500419617
Validation loss: 2.031415726548882

Epoch: 6| Step: 1
Training loss: 0.8552956581115723
Validation loss: 2.008437031058855

Epoch: 6| Step: 2
Training loss: 0.6548805236816406
Validation loss: 1.9781988205448273

Epoch: 6| Step: 3
Training loss: 1.0779461860656738
Validation loss: 1.962133833157119

Epoch: 6| Step: 4
Training loss: 1.3710180521011353
Validation loss: 1.9353452446640178

Epoch: 6| Step: 5
Training loss: 0.9068537950515747
Validation loss: 1.9053062649183377

Epoch: 6| Step: 6
Training loss: 1.5777223110198975
Validation loss: 1.9029692988241873

Epoch: 6| Step: 7
Training loss: 1.3607683181762695
Validation loss: 1.9044161688896917

Epoch: 6| Step: 8
Training loss: 1.0603519678115845
Validation loss: 1.9366535089349235

Epoch: 6| Step: 9
Training loss: 1.7012982368469238
Validation loss: 1.9558865754835066

Epoch: 6| Step: 10
Training loss: 0.8181615471839905
Validation loss: 1.9636329476551344

Epoch: 6| Step: 11
Training loss: 0.8021786212921143
Validation loss: 1.9818940675386818

Epoch: 6| Step: 12
Training loss: 1.7025607824325562
Validation loss: 1.9938887101347729

Epoch: 6| Step: 13
Training loss: 1.0250492095947266
Validation loss: 1.9981899902384768

Epoch: 164| Step: 0
Training loss: 1.3487191200256348
Validation loss: 1.9930726526885905

Epoch: 6| Step: 1
Training loss: 1.2713572978973389
Validation loss: 1.9791227617571432

Epoch: 6| Step: 2
Training loss: 0.8286367654800415
Validation loss: 1.9680624341451993

Epoch: 6| Step: 3
Training loss: 0.9348062872886658
Validation loss: 1.9503462981152278

Epoch: 6| Step: 4
Training loss: 0.6881640553474426
Validation loss: 1.9391327737480082

Epoch: 6| Step: 5
Training loss: 1.3470685482025146
Validation loss: 1.9217714648092947

Epoch: 6| Step: 6
Training loss: 1.0840239524841309
Validation loss: 1.915901719882924

Epoch: 6| Step: 7
Training loss: 0.9607810974121094
Validation loss: 1.9080684787483626

Epoch: 6| Step: 8
Training loss: 1.6157945394515991
Validation loss: 1.8954426088640768

Epoch: 6| Step: 9
Training loss: 1.1133596897125244
Validation loss: 1.891719659169515

Epoch: 6| Step: 10
Training loss: 0.9731112122535706
Validation loss: 1.9129597025532876

Epoch: 6| Step: 11
Training loss: 1.0617595911026
Validation loss: 1.9351854785796134

Epoch: 6| Step: 12
Training loss: 1.404617190361023
Validation loss: 1.910724703983594

Epoch: 6| Step: 13
Training loss: 1.177852749824524
Validation loss: 1.9447359269665134

Epoch: 165| Step: 0
Training loss: 1.0187433958053589
Validation loss: 1.9388245562071442

Epoch: 6| Step: 1
Training loss: 0.7008259892463684
Validation loss: 1.974862637058381

Epoch: 6| Step: 2
Training loss: 0.6817654371261597
Validation loss: 2.021163994266141

Epoch: 6| Step: 3
Training loss: 1.1045606136322021
Validation loss: 2.055789916746078

Epoch: 6| Step: 4
Training loss: 1.444678783416748
Validation loss: 2.0666780138528473

Epoch: 6| Step: 5
Training loss: 1.3529353141784668
Validation loss: 2.086240876105524

Epoch: 6| Step: 6
Training loss: 1.0642282962799072
Validation loss: 2.0396149722478722

Epoch: 6| Step: 7
Training loss: 1.2738710641860962
Validation loss: 2.033198636065247

Epoch: 6| Step: 8
Training loss: 1.4033761024475098
Validation loss: 1.9924382919906287

Epoch: 6| Step: 9
Training loss: 0.633379340171814
Validation loss: 1.9950958169916624

Epoch: 6| Step: 10
Training loss: 1.162860631942749
Validation loss: 1.9861149352083924

Epoch: 6| Step: 11
Training loss: 1.1356847286224365
Validation loss: 1.9949071958500852

Epoch: 6| Step: 12
Training loss: 1.428550124168396
Validation loss: 1.990072093984132

Epoch: 6| Step: 13
Training loss: 1.2692326307296753
Validation loss: 1.973922501328171

Epoch: 166| Step: 0
Training loss: 1.2554445266723633
Validation loss: 1.9568665655710364

Epoch: 6| Step: 1
Training loss: 1.309878945350647
Validation loss: 1.91899363968962

Epoch: 6| Step: 2
Training loss: 1.4706134796142578
Validation loss: 1.882096529006958

Epoch: 6| Step: 3
Training loss: 0.8424004316329956
Validation loss: 1.887018580590525

Epoch: 6| Step: 4
Training loss: 1.512089729309082
Validation loss: 1.905491776363824

Epoch: 6| Step: 5
Training loss: 1.0703232288360596
Validation loss: 1.9315748599267775

Epoch: 6| Step: 6
Training loss: 1.1458265781402588
Validation loss: 1.9357191093506352

Epoch: 6| Step: 7
Training loss: 0.734074592590332
Validation loss: 1.9549823114948888

Epoch: 6| Step: 8
Training loss: 1.4196431636810303
Validation loss: 1.9535443218805457

Epoch: 6| Step: 9
Training loss: 1.1162056922912598
Validation loss: 1.9599836872469993

Epoch: 6| Step: 10
Training loss: 1.0670424699783325
Validation loss: 2.017038514537196

Epoch: 6| Step: 11
Training loss: 0.8842020630836487
Validation loss: 2.0739164326780584

Epoch: 6| Step: 12
Training loss: 1.0773632526397705
Validation loss: 2.0825501590646724

Epoch: 6| Step: 13
Training loss: 0.8530307412147522
Validation loss: 2.0645276525969147

Epoch: 167| Step: 0
Training loss: 1.17523992061615
Validation loss: 2.0291691877508677

Epoch: 6| Step: 1
Training loss: 0.9566221833229065
Validation loss: 2.0001857908823157

Epoch: 6| Step: 2
Training loss: 1.3034942150115967
Validation loss: 1.9610698633296515

Epoch: 6| Step: 3
Training loss: 1.3059933185577393
Validation loss: 1.9638715931164321

Epoch: 6| Step: 4
Training loss: 0.9712096452713013
Validation loss: 1.9426473725226618

Epoch: 6| Step: 5
Training loss: 0.9486673474311829
Validation loss: 1.9453373352686565

Epoch: 6| Step: 6
Training loss: 0.9891076683998108
Validation loss: 1.9441629302117132

Epoch: 6| Step: 7
Training loss: 1.6335749626159668
Validation loss: 1.9302530647605978

Epoch: 6| Step: 8
Training loss: 0.9574981927871704
Validation loss: 1.949533659924743

Epoch: 6| Step: 9
Training loss: 1.0426321029663086
Validation loss: 1.9741615326173845

Epoch: 6| Step: 10
Training loss: 1.0877536535263062
Validation loss: 2.0068870539306314

Epoch: 6| Step: 11
Training loss: 0.8595308065414429
Validation loss: 2.0477000667202856

Epoch: 6| Step: 12
Training loss: 0.8904627561569214
Validation loss: 2.0720313056822746

Epoch: 6| Step: 13
Training loss: 1.746638298034668
Validation loss: 2.0646658469271917

Epoch: 168| Step: 0
Training loss: 0.5164743661880493
Validation loss: 2.0021782998115785

Epoch: 6| Step: 1
Training loss: 0.9138389825820923
Validation loss: 1.9840721955863379

Epoch: 6| Step: 2
Training loss: 0.9399338960647583
Validation loss: 1.9640206162647535

Epoch: 6| Step: 3
Training loss: 1.3559755086898804
Validation loss: 1.9675596631983274

Epoch: 6| Step: 4
Training loss: 1.7824468612670898
Validation loss: 1.947332916721221

Epoch: 6| Step: 5
Training loss: 1.5248260498046875
Validation loss: 1.971507929986523

Epoch: 6| Step: 6
Training loss: 1.0903698205947876
Validation loss: 1.9395602108329855

Epoch: 6| Step: 7
Training loss: 1.07294499874115
Validation loss: 1.9566375901622157

Epoch: 6| Step: 8
Training loss: 0.8329905867576599
Validation loss: 1.9405243332668016

Epoch: 6| Step: 9
Training loss: 1.3953533172607422
Validation loss: 1.9340531005654285

Epoch: 6| Step: 10
Training loss: 0.8391442894935608
Validation loss: 1.9957372757696337

Epoch: 6| Step: 11
Training loss: 1.3366191387176514
Validation loss: 2.0623495476220244

Epoch: 6| Step: 12
Training loss: 0.7542204260826111
Validation loss: 2.126258965461485

Epoch: 6| Step: 13
Training loss: 1.854481816291809
Validation loss: 2.1375881471941547

Epoch: 169| Step: 0
Training loss: 1.1661412715911865
Validation loss: 2.144048721559586

Epoch: 6| Step: 1
Training loss: 1.0393621921539307
Validation loss: 2.114981451342183

Epoch: 6| Step: 2
Training loss: 0.96103835105896
Validation loss: 2.0858302436849123

Epoch: 6| Step: 3
Training loss: 1.0662281513214111
Validation loss: 2.0586715231659594

Epoch: 6| Step: 4
Training loss: 1.2798285484313965
Validation loss: 1.9900227157018517

Epoch: 6| Step: 5
Training loss: 0.7969313263893127
Validation loss: 1.9704919989391039

Epoch: 6| Step: 6
Training loss: 1.0770785808563232
Validation loss: 1.9419164772956603

Epoch: 6| Step: 7
Training loss: 1.2025530338287354
Validation loss: 1.9405093385327248

Epoch: 6| Step: 8
Training loss: 1.3884726762771606
Validation loss: 1.9439494866196827

Epoch: 6| Step: 9
Training loss: 0.5028916597366333
Validation loss: 1.906330894398433

Epoch: 6| Step: 10
Training loss: 1.1072087287902832
Validation loss: 1.9104977551326956

Epoch: 6| Step: 11
Training loss: 1.699617624282837
Validation loss: 1.8999340790574268

Epoch: 6| Step: 12
Training loss: 1.003570318222046
Validation loss: 1.9124466347438034

Epoch: 6| Step: 13
Training loss: 1.1045130491256714
Validation loss: 1.9326188269481863

Epoch: 170| Step: 0
Training loss: 0.7910783886909485
Validation loss: 1.9473362507358674

Epoch: 6| Step: 1
Training loss: 1.6348819732666016
Validation loss: 1.985741433276925

Epoch: 6| Step: 2
Training loss: 1.4612966775894165
Validation loss: 2.0047657746140675

Epoch: 6| Step: 3
Training loss: 0.9502474069595337
Validation loss: 2.041209142695191

Epoch: 6| Step: 4
Training loss: 0.48788943886756897
Validation loss: 2.0542459744279102

Epoch: 6| Step: 5
Training loss: 0.9245408177375793
Validation loss: 2.054950609002062

Epoch: 6| Step: 6
Training loss: 1.2009568214416504
Validation loss: 2.0508705813397645

Epoch: 6| Step: 7
Training loss: 1.531904697418213
Validation loss: 2.002746899922689

Epoch: 6| Step: 8
Training loss: 1.0204609632492065
Validation loss: 1.9701591422480922

Epoch: 6| Step: 9
Training loss: 1.1156132221221924
Validation loss: 1.9151847721428

Epoch: 6| Step: 10
Training loss: 0.8832048177719116
Validation loss: 1.9195820311064362

Epoch: 6| Step: 11
Training loss: 0.8600246906280518
Validation loss: 1.899616709319494

Epoch: 6| Step: 12
Training loss: 1.1540331840515137
Validation loss: 1.8912736292808288

Epoch: 6| Step: 13
Training loss: 1.3616856336593628
Validation loss: 1.8738781354760612

Epoch: 171| Step: 0
Training loss: 0.9287071228027344
Validation loss: 1.8724798746006464

Epoch: 6| Step: 1
Training loss: 1.1909637451171875
Validation loss: 1.855578455873715

Epoch: 6| Step: 2
Training loss: 1.291311502456665
Validation loss: 1.8884452107132121

Epoch: 6| Step: 3
Training loss: 0.6214742660522461
Validation loss: 1.8975007482754287

Epoch: 6| Step: 4
Training loss: 0.5500760078430176
Validation loss: 1.914559692464849

Epoch: 6| Step: 5
Training loss: 0.792975127696991
Validation loss: 1.9362960784666

Epoch: 6| Step: 6
Training loss: 1.5047805309295654
Validation loss: 1.9724694785251413

Epoch: 6| Step: 7
Training loss: 1.2523398399353027
Validation loss: 1.9861871068195631

Epoch: 6| Step: 8
Training loss: 0.9878861308097839
Validation loss: 2.022625679610878

Epoch: 6| Step: 9
Training loss: 1.2671860456466675
Validation loss: 2.0483791046245123

Epoch: 6| Step: 10
Training loss: 1.4638617038726807
Validation loss: 2.043472727139791

Epoch: 6| Step: 11
Training loss: 0.8188519477844238
Validation loss: 2.033734793304115

Epoch: 6| Step: 12
Training loss: 1.1795880794525146
Validation loss: 2.044489129897087

Epoch: 6| Step: 13
Training loss: 0.8695241212844849
Validation loss: 2.0273968147975143

Epoch: 172| Step: 0
Training loss: 1.1158727407455444
Validation loss: 2.030129050695768

Epoch: 6| Step: 1
Training loss: 1.0546345710754395
Validation loss: 2.049439034154338

Epoch: 6| Step: 2
Training loss: 0.9899524450302124
Validation loss: 2.0182788372039795

Epoch: 6| Step: 3
Training loss: 1.195896029472351
Validation loss: 2.0250730963163477

Epoch: 6| Step: 4
Training loss: 0.9935829639434814
Validation loss: 1.9742081831860285

Epoch: 6| Step: 5
Training loss: 0.9400631785392761
Validation loss: 1.9589642593937535

Epoch: 6| Step: 6
Training loss: 0.9892927408218384
Validation loss: 1.9945706321347145

Epoch: 6| Step: 7
Training loss: 1.134332537651062
Validation loss: 1.987040917078654

Epoch: 6| Step: 8
Training loss: 0.893194854259491
Validation loss: 1.9971468269184072

Epoch: 6| Step: 9
Training loss: 0.8934834003448486
Validation loss: 2.0089885765506375

Epoch: 6| Step: 10
Training loss: 1.1188699007034302
Validation loss: 1.972222835786881

Epoch: 6| Step: 11
Training loss: 1.893547534942627
Validation loss: 1.944900599859094

Epoch: 6| Step: 12
Training loss: 0.5605461597442627
Validation loss: 1.9323520519400155

Epoch: 6| Step: 13
Training loss: 1.279909372329712
Validation loss: 1.9074258432593396

Epoch: 173| Step: 0
Training loss: 0.9995168447494507
Validation loss: 1.9235621460022465

Epoch: 6| Step: 1
Training loss: 1.1455388069152832
Validation loss: 1.9264497654412382

Epoch: 6| Step: 2
Training loss: 0.8868266344070435
Validation loss: 1.9615692553981658

Epoch: 6| Step: 3
Training loss: 1.0460660457611084
Validation loss: 1.9692984511775355

Epoch: 6| Step: 4
Training loss: 0.8701151013374329
Validation loss: 1.9813261814014886

Epoch: 6| Step: 5
Training loss: 1.0986456871032715
Validation loss: 1.99968502213878

Epoch: 6| Step: 6
Training loss: 1.217221975326538
Validation loss: 2.0376664823101414

Epoch: 6| Step: 7
Training loss: 0.7107256054878235
Validation loss: 2.04538470186213

Epoch: 6| Step: 8
Training loss: 0.5780999660491943
Validation loss: 2.0281422599669425

Epoch: 6| Step: 9
Training loss: 1.397670030593872
Validation loss: 2.037295356873543

Epoch: 6| Step: 10
Training loss: 1.1550977230072021
Validation loss: 2.012858536935622

Epoch: 6| Step: 11
Training loss: 1.0084502696990967
Validation loss: 1.9920681932921052

Epoch: 6| Step: 12
Training loss: 1.2410222291946411
Validation loss: 1.9759098829761628

Epoch: 6| Step: 13
Training loss: 1.3195494413375854
Validation loss: 1.954672658315269

Epoch: 174| Step: 0
Training loss: 1.279296636581421
Validation loss: 1.9325085557917112

Epoch: 6| Step: 1
Training loss: 1.23140287399292
Validation loss: 1.8968563284925235

Epoch: 6| Step: 2
Training loss: 1.334615707397461
Validation loss: 1.8982265777485345

Epoch: 6| Step: 3
Training loss: 0.7710419297218323
Validation loss: 1.8785348438447522

Epoch: 6| Step: 4
Training loss: 0.6561112403869629
Validation loss: 1.8934420154940697

Epoch: 6| Step: 5
Training loss: 0.5632714629173279
Validation loss: 1.900593311555924

Epoch: 6| Step: 6
Training loss: 1.1154530048370361
Validation loss: 1.9105727595667685

Epoch: 6| Step: 7
Training loss: 0.9732919335365295
Validation loss: 1.9482130030150056

Epoch: 6| Step: 8
Training loss: 0.49778616428375244
Validation loss: 2.010997951671641

Epoch: 6| Step: 9
Training loss: 1.0265514850616455
Validation loss: 2.0376827934736848

Epoch: 6| Step: 10
Training loss: 1.412111759185791
Validation loss: 2.0576013390735914

Epoch: 6| Step: 11
Training loss: 0.6083834171295166
Validation loss: 2.0558524618866625

Epoch: 6| Step: 12
Training loss: 1.1625713109970093
Validation loss: 2.025789696683166

Epoch: 6| Step: 13
Training loss: 1.4877296686172485
Validation loss: 2.033380787859681

Epoch: 175| Step: 0
Training loss: 0.8235009908676147
Validation loss: 2.01110101515247

Epoch: 6| Step: 1
Training loss: 0.8897797465324402
Validation loss: 2.0131113503568914

Epoch: 6| Step: 2
Training loss: 1.2259989976882935
Validation loss: 1.9924354860859532

Epoch: 6| Step: 3
Training loss: 1.038306474685669
Validation loss: 1.9606143748888405

Epoch: 6| Step: 4
Training loss: 0.6939099431037903
Validation loss: 1.9470516250979515

Epoch: 6| Step: 5
Training loss: 1.039829969406128
Validation loss: 1.9270735145896993

Epoch: 6| Step: 6
Training loss: 1.0580724477767944
Validation loss: 1.9552576285536571

Epoch: 6| Step: 7
Training loss: 0.949752688407898
Validation loss: 1.967330963380875

Epoch: 6| Step: 8
Training loss: 1.0688412189483643
Validation loss: 1.9759436153596448

Epoch: 6| Step: 9
Training loss: 0.9841841459274292
Validation loss: 1.9405060224635626

Epoch: 6| Step: 10
Training loss: 0.6985144019126892
Validation loss: 1.9301107621962024

Epoch: 6| Step: 11
Training loss: 1.0913680791854858
Validation loss: 1.913513764258354

Epoch: 6| Step: 12
Training loss: 1.5001168251037598
Validation loss: 1.8862529877693421

Epoch: 6| Step: 13
Training loss: 0.7270777225494385
Validation loss: 1.9219450771167714

Epoch: 176| Step: 0
Training loss: 0.9125614166259766
Validation loss: 1.9303780550597816

Epoch: 6| Step: 1
Training loss: 0.7596646547317505
Validation loss: 1.901874275617702

Epoch: 6| Step: 2
Training loss: 0.7197719812393188
Validation loss: 1.89753468062288

Epoch: 6| Step: 3
Training loss: 1.4620578289031982
Validation loss: 1.895253486530755

Epoch: 6| Step: 4
Training loss: 1.1626081466674805
Validation loss: 1.8710016307010446

Epoch: 6| Step: 5
Training loss: 0.8766335248947144
Validation loss: 1.8867247719918527

Epoch: 6| Step: 6
Training loss: 1.2489268779754639
Validation loss: 1.9264089125458912

Epoch: 6| Step: 7
Training loss: 0.668712854385376
Validation loss: 1.9539259390164447

Epoch: 6| Step: 8
Training loss: 1.0677275657653809
Validation loss: 2.002821473665135

Epoch: 6| Step: 9
Training loss: 0.8740193843841553
Validation loss: 2.013780745126868

Epoch: 6| Step: 10
Training loss: 0.9304792881011963
Validation loss: 2.0465928636571413

Epoch: 6| Step: 11
Training loss: 1.320765495300293
Validation loss: 2.0365290295693184

Epoch: 6| Step: 12
Training loss: 1.2756295204162598
Validation loss: 1.9853481528579549

Epoch: 6| Step: 13
Training loss: 0.795562744140625
Validation loss: 1.9578403401118454

Epoch: 177| Step: 0
Training loss: 0.8639706373214722
Validation loss: 1.9384883578105638

Epoch: 6| Step: 1
Training loss: 1.146862506866455
Validation loss: 1.948904865531511

Epoch: 6| Step: 2
Training loss: 0.940633237361908
Validation loss: 1.9485431742924515

Epoch: 6| Step: 3
Training loss: 0.9424962997436523
Validation loss: 1.9606526051798174

Epoch: 6| Step: 4
Training loss: 1.3200416564941406
Validation loss: 1.957527176026375

Epoch: 6| Step: 5
Training loss: 1.0497410297393799
Validation loss: 1.9728714804495535

Epoch: 6| Step: 6
Training loss: 1.0963363647460938
Validation loss: 1.9979779951034053

Epoch: 6| Step: 7
Training loss: 0.8456484079360962
Validation loss: 2.033029240946616

Epoch: 6| Step: 8
Training loss: 0.9450032711029053
Validation loss: 2.0405073755530903

Epoch: 6| Step: 9
Training loss: 1.1662805080413818
Validation loss: 1.9871176583792574

Epoch: 6| Step: 10
Training loss: 0.689899742603302
Validation loss: 1.9592772004424885

Epoch: 6| Step: 11
Training loss: 0.6624895334243774
Validation loss: 1.9227259287270166

Epoch: 6| Step: 12
Training loss: 1.1884738206863403
Validation loss: 1.8722530449590375

Epoch: 6| Step: 13
Training loss: 0.9677579402923584
Validation loss: 1.8820669292121806

Epoch: 178| Step: 0
Training loss: 0.819710373878479
Validation loss: 1.8580675535304572

Epoch: 6| Step: 1
Training loss: 1.2613606452941895
Validation loss: 1.89374465070745

Epoch: 6| Step: 2
Training loss: 0.7345179319381714
Validation loss: 1.8947749637788343

Epoch: 6| Step: 3
Training loss: 1.10990571975708
Validation loss: 1.920256544184941

Epoch: 6| Step: 4
Training loss: 1.0632247924804688
Validation loss: 1.9345583402982323

Epoch: 6| Step: 5
Training loss: 0.9658949375152588
Validation loss: 1.977701848553073

Epoch: 6| Step: 6
Training loss: 0.7128984332084656
Validation loss: 1.9975261380595546

Epoch: 6| Step: 7
Training loss: 0.7813670635223389
Validation loss: 2.0078586301495953

Epoch: 6| Step: 8
Training loss: 0.8757526278495789
Validation loss: 2.041696648443899

Epoch: 6| Step: 9
Training loss: 0.8402154445648193
Validation loss: 2.0098458361882034

Epoch: 6| Step: 10
Training loss: 1.016198992729187
Validation loss: 2.0310535123271327

Epoch: 6| Step: 11
Training loss: 0.6775960922241211
Validation loss: 2.013463456143615

Epoch: 6| Step: 12
Training loss: 1.1235226392745972
Validation loss: 2.035435156155658

Epoch: 6| Step: 13
Training loss: 1.7613855600357056
Validation loss: 2.0355364455971667

Epoch: 179| Step: 0
Training loss: 0.924830436706543
Validation loss: 2.0077799058729604

Epoch: 6| Step: 1
Training loss: 0.9749758243560791
Validation loss: 2.00340288172486

Epoch: 6| Step: 2
Training loss: 0.6811960339546204
Validation loss: 1.9580291560901109

Epoch: 6| Step: 3
Training loss: 0.9893025755882263
Validation loss: 1.9268785676648539

Epoch: 6| Step: 4
Training loss: 0.6401048898696899
Validation loss: 1.9064941278067968

Epoch: 6| Step: 5
Training loss: 0.7542815804481506
Validation loss: 1.894184394549298

Epoch: 6| Step: 6
Training loss: 1.1269745826721191
Validation loss: 1.8765360873232606

Epoch: 6| Step: 7
Training loss: 1.2546156644821167
Validation loss: 1.8671589846252112

Epoch: 6| Step: 8
Training loss: 1.072826623916626
Validation loss: 1.8721432826852287

Epoch: 6| Step: 9
Training loss: 1.2960206270217896
Validation loss: 1.8738356636416527

Epoch: 6| Step: 10
Training loss: 1.3201210498809814
Validation loss: 1.8617510577683807

Epoch: 6| Step: 11
Training loss: 0.9800921678543091
Validation loss: 1.8902483422269103

Epoch: 6| Step: 12
Training loss: 0.5854138135910034
Validation loss: 1.8908476598801152

Epoch: 6| Step: 13
Training loss: 1.0768179893493652
Validation loss: 1.909852453457412

Epoch: 180| Step: 0
Training loss: 1.1636314392089844
Validation loss: 1.9233479051179783

Epoch: 6| Step: 1
Training loss: 0.8384686708450317
Validation loss: 1.9338577229489562

Epoch: 6| Step: 2
Training loss: 1.0075817108154297
Validation loss: 1.9447704515149515

Epoch: 6| Step: 3
Training loss: 0.4682099521160126
Validation loss: 1.9483615198443014

Epoch: 6| Step: 4
Training loss: 0.649109423160553
Validation loss: 1.9470960927265946

Epoch: 6| Step: 5
Training loss: 1.150514841079712
Validation loss: 1.9545279831014655

Epoch: 6| Step: 6
Training loss: 1.1031299829483032
Validation loss: 1.94960408185118

Epoch: 6| Step: 7
Training loss: 1.0302374362945557
Validation loss: 1.9394267451378606

Epoch: 6| Step: 8
Training loss: 0.7458100318908691
Validation loss: 1.9484988028003323

Epoch: 6| Step: 9
Training loss: 0.5102242231369019
Validation loss: 1.9623037204947522

Epoch: 6| Step: 10
Training loss: 0.6525002717971802
Validation loss: 1.9786721698699459

Epoch: 6| Step: 11
Training loss: 1.1040005683898926
Validation loss: 1.9720498387531569

Epoch: 6| Step: 12
Training loss: 1.08565354347229
Validation loss: 1.9625766097858388

Epoch: 6| Step: 13
Training loss: 1.2946022748947144
Validation loss: 1.9647245868559806

Epoch: 181| Step: 0
Training loss: 0.5450384616851807
Validation loss: 1.9529713225621048

Epoch: 6| Step: 1
Training loss: 1.3693269491195679
Validation loss: 1.9488301623252131

Epoch: 6| Step: 2
Training loss: 0.6653463244438171
Validation loss: 1.9368251613391343

Epoch: 6| Step: 3
Training loss: 1.0220515727996826
Validation loss: 1.9271563829914216

Epoch: 6| Step: 4
Training loss: 1.091131329536438
Validation loss: 1.8924819372033561

Epoch: 6| Step: 5
Training loss: 0.830753743648529
Validation loss: 1.9059035534499793

Epoch: 6| Step: 6
Training loss: 0.5359907150268555
Validation loss: 1.9091053111578828

Epoch: 6| Step: 7
Training loss: 0.6646305322647095
Validation loss: 1.9157820260652931

Epoch: 6| Step: 8
Training loss: 1.1253305673599243
Validation loss: 1.917124117574384

Epoch: 6| Step: 9
Training loss: 1.1893441677093506
Validation loss: 1.9321334349211825

Epoch: 6| Step: 10
Training loss: 0.9635090827941895
Validation loss: 1.9184973368080713

Epoch: 6| Step: 11
Training loss: 0.951278030872345
Validation loss: 1.933128112105913

Epoch: 6| Step: 12
Training loss: 0.7658178806304932
Validation loss: 1.915731753072431

Epoch: 6| Step: 13
Training loss: 1.1806479692459106
Validation loss: 1.9177025133563625

Epoch: 182| Step: 0
Training loss: 1.366830587387085
Validation loss: 1.9156854319316086

Epoch: 6| Step: 1
Training loss: 0.8401231169700623
Validation loss: 1.906252412385838

Epoch: 6| Step: 2
Training loss: 0.9474015831947327
Validation loss: 1.919420567891931

Epoch: 6| Step: 3
Training loss: 1.179821491241455
Validation loss: 1.9086698767959431

Epoch: 6| Step: 4
Training loss: 1.0607298612594604
Validation loss: 1.9320659880997033

Epoch: 6| Step: 5
Training loss: 0.6779986023902893
Validation loss: 1.920552933087913

Epoch: 6| Step: 6
Training loss: 0.4799659252166748
Validation loss: 1.9292781352996826

Epoch: 6| Step: 7
Training loss: 0.639856219291687
Validation loss: 1.943816977162515

Epoch: 6| Step: 8
Training loss: 1.1965394020080566
Validation loss: 1.9463595510810934

Epoch: 6| Step: 9
Training loss: 0.8056322932243347
Validation loss: 1.9428861551387335

Epoch: 6| Step: 10
Training loss: 0.7890503406524658
Validation loss: 1.9661130905151367

Epoch: 6| Step: 11
Training loss: 0.6834721565246582
Validation loss: 1.9932139817104544

Epoch: 6| Step: 12
Training loss: 1.0803427696228027
Validation loss: 1.9915698958981423

Epoch: 6| Step: 13
Training loss: 0.6985298991203308
Validation loss: 2.0060326322432487

Epoch: 183| Step: 0
Training loss: 0.6995403170585632
Validation loss: 2.0158721067572154

Epoch: 6| Step: 1
Training loss: 1.1431167125701904
Validation loss: 2.0185429101349204

Epoch: 6| Step: 2
Training loss: 1.0784722566604614
Validation loss: 1.9819957081989577

Epoch: 6| Step: 3
Training loss: 0.9443577527999878
Validation loss: 1.9452649034479612

Epoch: 6| Step: 4
Training loss: 0.7524807453155518
Validation loss: 1.933549770744898

Epoch: 6| Step: 5
Training loss: 0.8831084370613098
Validation loss: 1.903181847705636

Epoch: 6| Step: 6
Training loss: 0.7024565935134888
Validation loss: 1.8917977374087098

Epoch: 6| Step: 7
Training loss: 1.3059632778167725
Validation loss: 1.877275413082492

Epoch: 6| Step: 8
Training loss: 0.46317943930625916
Validation loss: 1.863944253613872

Epoch: 6| Step: 9
Training loss: 0.9131244421005249
Validation loss: 1.8808646304633028

Epoch: 6| Step: 10
Training loss: 1.1110929250717163
Validation loss: 1.8857483017829157

Epoch: 6| Step: 11
Training loss: 1.068932056427002
Validation loss: 1.898820259237802

Epoch: 6| Step: 12
Training loss: 0.37691399455070496
Validation loss: 1.8933094355367845

Epoch: 6| Step: 13
Training loss: 1.163894772529602
Validation loss: 1.9126305195593065

Epoch: 184| Step: 0
Training loss: 0.9948989152908325
Validation loss: 1.9144059252995316

Epoch: 6| Step: 1
Training loss: 0.7326723337173462
Validation loss: 1.946862643764865

Epoch: 6| Step: 2
Training loss: 1.2863560914993286
Validation loss: 1.9240849582097863

Epoch: 6| Step: 3
Training loss: 0.29453766345977783
Validation loss: 1.927567671704036

Epoch: 6| Step: 4
Training loss: 1.2877552509307861
Validation loss: 1.9364527848459059

Epoch: 6| Step: 5
Training loss: 1.1718987226486206
Validation loss: 1.9020489390178392

Epoch: 6| Step: 6
Training loss: 0.4612715244293213
Validation loss: 1.879710675567709

Epoch: 6| Step: 7
Training loss: 1.1925048828125
Validation loss: 1.896258734887646

Epoch: 6| Step: 8
Training loss: 0.8740416765213013
Validation loss: 1.8820503040026593

Epoch: 6| Step: 9
Training loss: 0.6820091605186462
Validation loss: 1.8945227079494025

Epoch: 6| Step: 10
Training loss: 0.8254885673522949
Validation loss: 1.9326545820441297

Epoch: 6| Step: 11
Training loss: 0.8531917929649353
Validation loss: 1.9172631566242506

Epoch: 6| Step: 12
Training loss: 1.08424711227417
Validation loss: 1.9157340065125497

Epoch: 6| Step: 13
Training loss: 0.6486953496932983
Validation loss: 1.9120474515422698

Epoch: 185| Step: 0
Training loss: 0.704745352268219
Validation loss: 1.9356247878843738

Epoch: 6| Step: 1
Training loss: 0.7600448131561279
Validation loss: 1.9485667072316653

Epoch: 6| Step: 2
Training loss: 0.4909168779850006
Validation loss: 1.9558623593340638

Epoch: 6| Step: 3
Training loss: 1.1202895641326904
Validation loss: 1.9660909586055304

Epoch: 6| Step: 4
Training loss: 0.9163297414779663
Validation loss: 1.9736318319074568

Epoch: 6| Step: 5
Training loss: 0.5804978013038635
Validation loss: 1.9945751467058737

Epoch: 6| Step: 6
Training loss: 0.7985371947288513
Validation loss: 1.9785186270231843

Epoch: 6| Step: 7
Training loss: 0.7136861085891724
Validation loss: 2.0010487482111943

Epoch: 6| Step: 8
Training loss: 1.0963491201400757
Validation loss: 1.9435208023235362

Epoch: 6| Step: 9
Training loss: 0.8457414507865906
Validation loss: 1.95416275916561

Epoch: 6| Step: 10
Training loss: 0.9576108455657959
Validation loss: 1.9107045576136599

Epoch: 6| Step: 11
Training loss: 1.0835230350494385
Validation loss: 1.9370316895105506

Epoch: 6| Step: 12
Training loss: 0.9636926054954529
Validation loss: 1.9087324488547541

Epoch: 6| Step: 13
Training loss: 1.100145697593689
Validation loss: 1.8884421471626527

Epoch: 186| Step: 0
Training loss: 0.8072432279586792
Validation loss: 1.8780921889889626

Epoch: 6| Step: 1
Training loss: 0.7047855257987976
Validation loss: 1.8943125599174089

Epoch: 6| Step: 2
Training loss: 0.6715632677078247
Validation loss: 1.9110420621851438

Epoch: 6| Step: 3
Training loss: 0.8020410537719727
Validation loss: 1.9451658520647275

Epoch: 6| Step: 4
Training loss: 1.7210041284561157
Validation loss: 1.9355905453364055

Epoch: 6| Step: 5
Training loss: 0.8379038572311401
Validation loss: 1.9574166574785787

Epoch: 6| Step: 6
Training loss: 0.8778117895126343
Validation loss: 1.9796310881132722

Epoch: 6| Step: 7
Training loss: 0.7824074029922485
Validation loss: 1.9892208294201923

Epoch: 6| Step: 8
Training loss: 0.910297691822052
Validation loss: 1.9941772209700717

Epoch: 6| Step: 9
Training loss: 0.7983137965202332
Validation loss: 1.974497720759402

Epoch: 6| Step: 10
Training loss: 0.9646586179733276
Validation loss: 1.9590378217799689

Epoch: 6| Step: 11
Training loss: 0.6283555626869202
Validation loss: 1.948294929278794

Epoch: 6| Step: 12
Training loss: 0.4990110695362091
Validation loss: 1.946905961600683

Epoch: 6| Step: 13
Training loss: 1.380523443222046
Validation loss: 1.9295976854139758

Epoch: 187| Step: 0
Training loss: 0.6742011904716492
Validation loss: 1.9377828285258303

Epoch: 6| Step: 1
Training loss: 1.1394786834716797
Validation loss: 1.9584370684880081

Epoch: 6| Step: 2
Training loss: 0.7364884614944458
Validation loss: 1.9613102546302221

Epoch: 6| Step: 3
Training loss: 0.783565878868103
Validation loss: 1.9912785740308865

Epoch: 6| Step: 4
Training loss: 0.6647801995277405
Validation loss: 1.9738733025007351

Epoch: 6| Step: 5
Training loss: 0.7208621501922607
Validation loss: 1.9703093318529026

Epoch: 6| Step: 6
Training loss: 0.7405179738998413
Validation loss: 1.9418896449509488

Epoch: 6| Step: 7
Training loss: 0.8241591453552246
Validation loss: 1.9394247019162743

Epoch: 6| Step: 8
Training loss: 1.1424376964569092
Validation loss: 1.9501019190716486

Epoch: 6| Step: 9
Training loss: 1.0521259307861328
Validation loss: 1.9214012469014814

Epoch: 6| Step: 10
Training loss: 1.401522159576416
Validation loss: 1.9135667611193914

Epoch: 6| Step: 11
Training loss: 0.6759506464004517
Validation loss: 1.9229644075516732

Epoch: 6| Step: 12
Training loss: 0.4610838294029236
Validation loss: 1.9096327725277151

Epoch: 6| Step: 13
Training loss: 0.9045864939689636
Validation loss: 1.9452353139077463

Epoch: 188| Step: 0
Training loss: 0.55791175365448
Validation loss: 1.9607741294368621

Epoch: 6| Step: 1
Training loss: 0.8484355211257935
Validation loss: 1.9916853712451073

Epoch: 6| Step: 2
Training loss: 0.7659236788749695
Validation loss: 1.972546100616455

Epoch: 6| Step: 3
Training loss: 0.8121523857116699
Validation loss: 1.9704703195120699

Epoch: 6| Step: 4
Training loss: 1.1088191270828247
Validation loss: 1.9643473650819512

Epoch: 6| Step: 5
Training loss: 1.0121219158172607
Validation loss: 1.9549196650904994

Epoch: 6| Step: 6
Training loss: 0.9816956520080566
Validation loss: 1.9496995095283753

Epoch: 6| Step: 7
Training loss: 1.1427979469299316
Validation loss: 1.9724046799444384

Epoch: 6| Step: 8
Training loss: 0.7315478324890137
Validation loss: 1.9537656948130617

Epoch: 6| Step: 9
Training loss: 0.6818626523017883
Validation loss: 1.9496100743611653

Epoch: 6| Step: 10
Training loss: 0.7764115333557129
Validation loss: 1.9126116806460964

Epoch: 6| Step: 11
Training loss: 0.7752944231033325
Validation loss: 1.9202454243936846

Epoch: 6| Step: 12
Training loss: 0.7488194704055786
Validation loss: 1.9273780981699626

Epoch: 6| Step: 13
Training loss: 0.6314577460289001
Validation loss: 1.9386249485836233

Epoch: 189| Step: 0
Training loss: 0.8564852476119995
Validation loss: 1.9483262826037664

Epoch: 6| Step: 1
Training loss: 1.0105993747711182
Validation loss: 1.9796604007802985

Epoch: 6| Step: 2
Training loss: 0.8454277515411377
Validation loss: 1.9850464661916096

Epoch: 6| Step: 3
Training loss: 0.9172787666320801
Validation loss: 1.9693706291978077

Epoch: 6| Step: 4
Training loss: 0.723179280757904
Validation loss: 1.9518559466126144

Epoch: 6| Step: 5
Training loss: 0.6724414825439453
Validation loss: 1.9437195421547018

Epoch: 6| Step: 6
Training loss: 0.6694220304489136
Validation loss: 1.9678793940492856

Epoch: 6| Step: 7
Training loss: 0.8824782371520996
Validation loss: 1.9474667643988004

Epoch: 6| Step: 8
Training loss: 0.691438615322113
Validation loss: 1.9495508324715398

Epoch: 6| Step: 9
Training loss: 0.6778931021690369
Validation loss: 1.9508175491004862

Epoch: 6| Step: 10
Training loss: 1.378019094467163
Validation loss: 1.9523226522630261

Epoch: 6| Step: 11
Training loss: 0.5751015543937683
Validation loss: 1.9256017374736007

Epoch: 6| Step: 12
Training loss: 0.6726133823394775
Validation loss: 1.9380722763717815

Epoch: 6| Step: 13
Training loss: 0.944640576839447
Validation loss: 1.912109226308843

Epoch: 190| Step: 0
Training loss: 1.0896952152252197
Validation loss: 1.9129684996861283

Epoch: 6| Step: 1
Training loss: 0.5589981079101562
Validation loss: 1.8856431412440475

Epoch: 6| Step: 2
Training loss: 0.8592535853385925
Validation loss: 1.8832237310307

Epoch: 6| Step: 3
Training loss: 0.8937647342681885
Validation loss: 1.887280535954301

Epoch: 6| Step: 4
Training loss: 1.1876407861709595
Validation loss: 1.8777706264167704

Epoch: 6| Step: 5
Training loss: 0.6573712825775146
Validation loss: 1.8743095820949924

Epoch: 6| Step: 6
Training loss: 0.7769841551780701
Validation loss: 1.8715162751495198

Epoch: 6| Step: 7
Training loss: 0.7737938165664673
Validation loss: 1.8785634476651427

Epoch: 6| Step: 8
Training loss: 1.001685380935669
Validation loss: 1.9170937294601111

Epoch: 6| Step: 9
Training loss: 0.4912306070327759
Validation loss: 1.9182814475028747

Epoch: 6| Step: 10
Training loss: 0.7165557146072388
Validation loss: 1.932350504782892

Epoch: 6| Step: 11
Training loss: 0.770249605178833
Validation loss: 1.9421544997922835

Epoch: 6| Step: 12
Training loss: 0.7151973247528076
Validation loss: 1.949490060088455

Epoch: 6| Step: 13
Training loss: 0.8157694935798645
Validation loss: 1.9927106698354085

Epoch: 191| Step: 0
Training loss: 0.6175822019577026
Validation loss: 1.9910429613564604

Epoch: 6| Step: 1
Training loss: 1.1375350952148438
Validation loss: 1.978905548331558

Epoch: 6| Step: 2
Training loss: 0.9004546403884888
Validation loss: 1.9878703753153484

Epoch: 6| Step: 3
Training loss: 0.5304821133613586
Validation loss: 1.9303667160772509

Epoch: 6| Step: 4
Training loss: 0.9169230461120605
Validation loss: 1.9046279115061606

Epoch: 6| Step: 5
Training loss: 0.7224723100662231
Validation loss: 1.8712216449040238

Epoch: 6| Step: 6
Training loss: 0.6261455416679382
Validation loss: 1.8787454430774977

Epoch: 6| Step: 7
Training loss: 1.2948253154754639
Validation loss: 1.8617194621793685

Epoch: 6| Step: 8
Training loss: 0.5695565938949585
Validation loss: 1.8448065147604993

Epoch: 6| Step: 9
Training loss: 1.0683094263076782
Validation loss: 1.8554402371888519

Epoch: 6| Step: 10
Training loss: 0.8278188109397888
Validation loss: 1.8503131122999295

Epoch: 6| Step: 11
Training loss: 0.6864222884178162
Validation loss: 1.8715663571511545

Epoch: 6| Step: 12
Training loss: 0.7300708293914795
Validation loss: 1.909460021603492

Epoch: 6| Step: 13
Training loss: 1.0471382141113281
Validation loss: 1.9227875612115348

Epoch: 192| Step: 0
Training loss: 0.5869903564453125
Validation loss: 1.9621548498830488

Epoch: 6| Step: 1
Training loss: 0.5815538167953491
Validation loss: 1.970145348579653

Epoch: 6| Step: 2
Training loss: 0.8045907020568848
Validation loss: 1.9670229701585666

Epoch: 6| Step: 3
Training loss: 0.8453577756881714
Validation loss: 1.9766439494266306

Epoch: 6| Step: 4
Training loss: 0.7264947891235352
Validation loss: 1.9511742694403535

Epoch: 6| Step: 5
Training loss: 0.5307205319404602
Validation loss: 1.9615178608125257

Epoch: 6| Step: 6
Training loss: 0.8352674245834351
Validation loss: 1.9332635941043976

Epoch: 6| Step: 7
Training loss: 0.8688338994979858
Validation loss: 1.9041104803803146

Epoch: 6| Step: 8
Training loss: 0.9235249757766724
Validation loss: 1.9103829770959833

Epoch: 6| Step: 9
Training loss: 1.009239912033081
Validation loss: 1.9193905925238004

Epoch: 6| Step: 10
Training loss: 0.9255731105804443
Validation loss: 1.9060969224540136

Epoch: 6| Step: 11
Training loss: 0.8732877373695374
Validation loss: 1.9308129664390319

Epoch: 6| Step: 12
Training loss: 0.9873507618904114
Validation loss: 1.9563525235781105

Epoch: 6| Step: 13
Training loss: 0.7686816453933716
Validation loss: 1.9306634831172165

Epoch: 193| Step: 0
Training loss: 0.6603659987449646
Validation loss: 1.9117836260026502

Epoch: 6| Step: 1
Training loss: 0.9461383819580078
Validation loss: 1.902591618158484

Epoch: 6| Step: 2
Training loss: 0.43032121658325195
Validation loss: 1.8960696228088871

Epoch: 6| Step: 3
Training loss: 0.7909661531448364
Validation loss: 1.9040554287613078

Epoch: 6| Step: 4
Training loss: 1.3066668510437012
Validation loss: 1.8890391357483403

Epoch: 6| Step: 5
Training loss: 0.6909178495407104
Validation loss: 1.9056113791722122

Epoch: 6| Step: 6
Training loss: 0.8956983089447021
Validation loss: 1.9184090322063816

Epoch: 6| Step: 7
Training loss: 0.7871345281600952
Validation loss: 1.9377201782759799

Epoch: 6| Step: 8
Training loss: 0.7005071640014648
Validation loss: 1.9087707740004345

Epoch: 6| Step: 9
Training loss: 0.9711899757385254
Validation loss: 1.9264772874052807

Epoch: 6| Step: 10
Training loss: 0.984518826007843
Validation loss: 1.902042354306867

Epoch: 6| Step: 11
Training loss: 0.6489291191101074
Validation loss: 1.92732903393366

Epoch: 6| Step: 12
Training loss: 0.5604007244110107
Validation loss: 1.9457608922835319

Epoch: 6| Step: 13
Training loss: 0.43539243936538696
Validation loss: 1.9413605505420315

Epoch: 194| Step: 0
Training loss: 0.7085262537002563
Validation loss: 1.928759765881364

Epoch: 6| Step: 1
Training loss: 0.5159838199615479
Validation loss: 1.966987745736235

Epoch: 6| Step: 2
Training loss: 0.5388978719711304
Validation loss: 1.9461456485973891

Epoch: 6| Step: 3
Training loss: 0.6679112911224365
Validation loss: 1.925799782558154

Epoch: 6| Step: 4
Training loss: 0.9991425275802612
Validation loss: 1.920003152662708

Epoch: 6| Step: 5
Training loss: 0.936898946762085
Validation loss: 1.9219662168974518

Epoch: 6| Step: 6
Training loss: 0.7926706075668335
Validation loss: 1.9141228109277704

Epoch: 6| Step: 7
Training loss: 0.4594309329986572
Validation loss: 1.9002949871042722

Epoch: 6| Step: 8
Training loss: 1.0797957181930542
Validation loss: 1.8996113602833082

Epoch: 6| Step: 9
Training loss: 1.0713250637054443
Validation loss: 1.8809977090486916

Epoch: 6| Step: 10
Training loss: 0.9168857336044312
Validation loss: 1.8881199667530675

Epoch: 6| Step: 11
Training loss: 0.7654857635498047
Validation loss: 1.881864623356891

Epoch: 6| Step: 12
Training loss: 0.7074287533760071
Validation loss: 1.8810751335595244

Epoch: 6| Step: 13
Training loss: 1.4412038326263428
Validation loss: 1.896772450016391

Epoch: 195| Step: 0
Training loss: 0.512066662311554
Validation loss: 1.9112908481269755

Epoch: 6| Step: 1
Training loss: 0.5738972425460815
Validation loss: 1.9104738966111214

Epoch: 6| Step: 2
Training loss: 1.0139288902282715
Validation loss: 1.9125709918237501

Epoch: 6| Step: 3
Training loss: 0.7983522415161133
Validation loss: 1.9324157468734249

Epoch: 6| Step: 4
Training loss: 1.135911464691162
Validation loss: 1.948612783544807

Epoch: 6| Step: 5
Training loss: 0.8077828288078308
Validation loss: 1.9482471404537078

Epoch: 6| Step: 6
Training loss: 0.7230682969093323
Validation loss: 1.948850303567866

Epoch: 6| Step: 7
Training loss: 0.5485029220581055
Validation loss: 1.9528191986904349

Epoch: 6| Step: 8
Training loss: 0.868254542350769
Validation loss: 1.9361288829516339

Epoch: 6| Step: 9
Training loss: 0.7860434055328369
Validation loss: 1.898005622689442

Epoch: 6| Step: 10
Training loss: 1.3963969945907593
Validation loss: 1.8897815545399983

Epoch: 6| Step: 11
Training loss: 0.6528690457344055
Validation loss: 1.8848903243259718

Epoch: 6| Step: 12
Training loss: 0.6949080228805542
Validation loss: 1.8593389462399226

Epoch: 6| Step: 13
Training loss: 0.4722674787044525
Validation loss: 1.8047181778056647

Epoch: 196| Step: 0
Training loss: 0.9291191697120667
Validation loss: 1.7810262864635837

Epoch: 6| Step: 1
Training loss: 0.7781621217727661
Validation loss: 1.8048706464870001

Epoch: 6| Step: 2
Training loss: 0.693427562713623
Validation loss: 1.7868683030528407

Epoch: 6| Step: 3
Training loss: 0.6370385885238647
Validation loss: 1.7912572058298255

Epoch: 6| Step: 4
Training loss: 0.5118973851203918
Validation loss: 1.8057125306898547

Epoch: 6| Step: 5
Training loss: 0.7203500270843506
Validation loss: 1.829472872518724

Epoch: 6| Step: 6
Training loss: 1.0933607816696167
Validation loss: 1.8343107020983132

Epoch: 6| Step: 7
Training loss: 0.9936891198158264
Validation loss: 1.859013900961927

Epoch: 6| Step: 8
Training loss: 0.7448768615722656
Validation loss: 1.8807330951895764

Epoch: 6| Step: 9
Training loss: 0.7217048406600952
Validation loss: 1.8768664739465202

Epoch: 6| Step: 10
Training loss: 0.549159586429596
Validation loss: 1.8944872527994134

Epoch: 6| Step: 11
Training loss: 1.233008623123169
Validation loss: 1.937477380998673

Epoch: 6| Step: 12
Training loss: 0.7179136276245117
Validation loss: 1.946823989191363

Epoch: 6| Step: 13
Training loss: 1.440522313117981
Validation loss: 1.9508673298743464

Epoch: 197| Step: 0
Training loss: 0.5724076628684998
Validation loss: 1.929900679537045

Epoch: 6| Step: 1
Training loss: 0.677962064743042
Validation loss: 1.9404636044656076

Epoch: 6| Step: 2
Training loss: 0.43967297673225403
Validation loss: 1.921987138768678

Epoch: 6| Step: 3
Training loss: 0.9789585471153259
Validation loss: 1.940079463425503

Epoch: 6| Step: 4
Training loss: 0.7061554193496704
Validation loss: 1.9273487470483268

Epoch: 6| Step: 5
Training loss: 0.7582929134368896
Validation loss: 1.9079841798351658

Epoch: 6| Step: 6
Training loss: 0.703602135181427
Validation loss: 1.8953076972756335

Epoch: 6| Step: 7
Training loss: 0.7693026065826416
Validation loss: 1.8868289788564045

Epoch: 6| Step: 8
Training loss: 0.96100914478302
Validation loss: 1.8744238345853743

Epoch: 6| Step: 9
Training loss: 0.8846540451049805
Validation loss: 1.880621462739924

Epoch: 6| Step: 10
Training loss: 0.7958862781524658
Validation loss: 1.8492245904860958

Epoch: 6| Step: 11
Training loss: 0.6013936996459961
Validation loss: 1.8570447250079083

Epoch: 6| Step: 12
Training loss: 0.9608691930770874
Validation loss: 1.8439332157052972

Epoch: 6| Step: 13
Training loss: 0.8401355147361755
Validation loss: 1.8363681788085608

Epoch: 198| Step: 0
Training loss: 0.7147825956344604
Validation loss: 1.8484364119909142

Epoch: 6| Step: 1
Training loss: 0.4689163863658905
Validation loss: 1.8656996898753668

Epoch: 6| Step: 2
Training loss: 0.6310721039772034
Validation loss: 1.8601365217598536

Epoch: 6| Step: 3
Training loss: 0.8244305849075317
Validation loss: 1.8689609830097487

Epoch: 6| Step: 4
Training loss: 0.934744119644165
Validation loss: 1.8625754746057654

Epoch: 6| Step: 5
Training loss: 0.7251687049865723
Validation loss: 1.8580345312754314

Epoch: 6| Step: 6
Training loss: 0.8361667394638062
Validation loss: 1.8500622408364409

Epoch: 6| Step: 7
Training loss: 0.6260591745376587
Validation loss: 1.8399568014247443

Epoch: 6| Step: 8
Training loss: 0.6300928592681885
Validation loss: 1.8402426268464775

Epoch: 6| Step: 9
Training loss: 0.9466562867164612
Validation loss: 1.82863619507

Epoch: 6| Step: 10
Training loss: 0.5465847253799438
Validation loss: 1.8211592525564215

Epoch: 6| Step: 11
Training loss: 0.7124804854393005
Validation loss: 1.822479099355718

Epoch: 6| Step: 12
Training loss: 0.7321417331695557
Validation loss: 1.8146073074751004

Epoch: 6| Step: 13
Training loss: 0.7815759778022766
Validation loss: 1.8010882254569762

Epoch: 199| Step: 0
Training loss: 0.565871000289917
Validation loss: 1.845498702859366

Epoch: 6| Step: 1
Training loss: 0.8227685689926147
Validation loss: 1.8439631436460762

Epoch: 6| Step: 2
Training loss: 0.7484930753707886
Validation loss: 1.8286010706296532

Epoch: 6| Step: 3
Training loss: 0.6025701761245728
Validation loss: 1.8683303697134859

Epoch: 6| Step: 4
Training loss: 0.8415782451629639
Validation loss: 1.8823408260140368

Epoch: 6| Step: 5
Training loss: 0.4609872102737427
Validation loss: 1.8911883728478545

Epoch: 6| Step: 6
Training loss: 0.6328810453414917
Validation loss: 1.8976712252504082

Epoch: 6| Step: 7
Training loss: 0.8215757012367249
Validation loss: 1.89939159218983

Epoch: 6| Step: 8
Training loss: 0.9255394339561462
Validation loss: 1.8553933866562382

Epoch: 6| Step: 9
Training loss: 0.46724170446395874
Validation loss: 1.8617030036064885

Epoch: 6| Step: 10
Training loss: 0.5852552652359009
Validation loss: 1.8565683813505276

Epoch: 6| Step: 11
Training loss: 0.9243469834327698
Validation loss: 1.837213002225404

Epoch: 6| Step: 12
Training loss: 0.8388645648956299
Validation loss: 1.8597013899075088

Epoch: 6| Step: 13
Training loss: 0.6660544872283936
Validation loss: 1.849701331507775

Epoch: 200| Step: 0
Training loss: 0.2878461480140686
Validation loss: 1.8564576128477692

Epoch: 6| Step: 1
Training loss: 0.7019844055175781
Validation loss: 1.8449584361045592

Epoch: 6| Step: 2
Training loss: 0.8904324769973755
Validation loss: 1.8277418972343527

Epoch: 6| Step: 3
Training loss: 1.0501508712768555
Validation loss: 1.8469299052351265

Epoch: 6| Step: 4
Training loss: 0.5560433864593506
Validation loss: 1.8292684042325584

Epoch: 6| Step: 5
Training loss: 0.9109785556793213
Validation loss: 1.8492753262160926

Epoch: 6| Step: 6
Training loss: 0.7152917385101318
Validation loss: 1.8697953044727285

Epoch: 6| Step: 7
Training loss: 0.6803904175758362
Validation loss: 1.891625844022279

Epoch: 6| Step: 8
Training loss: 0.6881352663040161
Validation loss: 1.8756455990575975

Epoch: 6| Step: 9
Training loss: 0.7095317244529724
Validation loss: 1.885102116933433

Epoch: 6| Step: 10
Training loss: 0.7556168437004089
Validation loss: 1.910707563482305

Epoch: 6| Step: 11
Training loss: 0.5504255294799805
Validation loss: 1.9088670515245008

Epoch: 6| Step: 12
Training loss: 0.8352866172790527
Validation loss: 1.8949291936812862

Epoch: 6| Step: 13
Training loss: 0.358036071062088
Validation loss: 1.8808924998006513

Epoch: 201| Step: 0
Training loss: 0.6266717910766602
Validation loss: 1.885417817741312

Epoch: 6| Step: 1
Training loss: 0.7145993113517761
Validation loss: 1.866472073780593

Epoch: 6| Step: 2
Training loss: 0.5206091403961182
Validation loss: 1.890480476040994

Epoch: 6| Step: 3
Training loss: 0.8947069644927979
Validation loss: 1.9130737448251376

Epoch: 6| Step: 4
Training loss: 0.5592687129974365
Validation loss: 1.8877281117182907

Epoch: 6| Step: 5
Training loss: 1.0982961654663086
Validation loss: 1.8985727589617494

Epoch: 6| Step: 6
Training loss: 0.8698055744171143
Validation loss: 1.8734117361807054

Epoch: 6| Step: 7
Training loss: 1.2189762592315674
Validation loss: 1.8782380883411696

Epoch: 6| Step: 8
Training loss: 0.654606282711029
Validation loss: 1.8474827556199924

Epoch: 6| Step: 9
Training loss: 0.41616564989089966
Validation loss: 1.8591216225777902

Epoch: 6| Step: 10
Training loss: 0.8331066370010376
Validation loss: 1.8499132305063226

Epoch: 6| Step: 11
Training loss: 0.41637709736824036
Validation loss: 1.862726705048674

Epoch: 6| Step: 12
Training loss: 0.578972339630127
Validation loss: 1.8736254335731588

Epoch: 6| Step: 13
Training loss: 0.708568274974823
Validation loss: 1.9101028416746406

Epoch: 202| Step: 0
Training loss: 0.9378114938735962
Validation loss: 1.9317050979983421

Epoch: 6| Step: 1
Training loss: 0.9885897040367126
Validation loss: 1.9535500695628505

Epoch: 6| Step: 2
Training loss: 1.3979535102844238
Validation loss: 1.951053923176181

Epoch: 6| Step: 3
Training loss: 0.8309811949729919
Validation loss: 1.9622858544831634

Epoch: 6| Step: 4
Training loss: 0.4975208342075348
Validation loss: 1.9183682126383628

Epoch: 6| Step: 5
Training loss: 0.7021183967590332
Validation loss: 1.8881703294733518

Epoch: 6| Step: 6
Training loss: 0.5724568367004395
Validation loss: 1.899565726198176

Epoch: 6| Step: 7
Training loss: 0.3834690451622009
Validation loss: 1.8865832385196482

Epoch: 6| Step: 8
Training loss: 0.5949640870094299
Validation loss: 1.8942604718669769

Epoch: 6| Step: 9
Training loss: 0.9767855405807495
Validation loss: 1.8876937281700872

Epoch: 6| Step: 10
Training loss: 0.6059911251068115
Validation loss: 1.8606628987096971

Epoch: 6| Step: 11
Training loss: 0.5011581778526306
Validation loss: 1.8638735560960666

Epoch: 6| Step: 12
Training loss: 0.5321114659309387
Validation loss: 1.8561606650711389

Epoch: 6| Step: 13
Training loss: 0.8191208243370056
Validation loss: 1.8682037425297562

Epoch: 203| Step: 0
Training loss: 0.7573004961013794
Validation loss: 1.8487756649653118

Epoch: 6| Step: 1
Training loss: 0.537412166595459
Validation loss: 1.8650408367956839

Epoch: 6| Step: 2
Training loss: 0.4837779998779297
Validation loss: 1.841211554824665

Epoch: 6| Step: 3
Training loss: 1.1244008541107178
Validation loss: 1.8238379904018935

Epoch: 6| Step: 4
Training loss: 0.7180014848709106
Validation loss: 1.8481382093121927

Epoch: 6| Step: 5
Training loss: 0.8937419652938843
Validation loss: 1.850709553687803

Epoch: 6| Step: 6
Training loss: 0.6589144468307495
Validation loss: 1.8566958660720496

Epoch: 6| Step: 7
Training loss: 0.40406107902526855
Validation loss: 1.8792109720168575

Epoch: 6| Step: 8
Training loss: 0.3550986051559448
Validation loss: 1.8999216569367277

Epoch: 6| Step: 9
Training loss: 0.98126620054245
Validation loss: 1.887003065437399

Epoch: 6| Step: 10
Training loss: 0.6148983240127563
Validation loss: 1.8795130060565086

Epoch: 6| Step: 11
Training loss: 0.5662739872932434
Validation loss: 1.8991466491453108

Epoch: 6| Step: 12
Training loss: 1.0489616394042969
Validation loss: 1.9078938576482958

Epoch: 6| Step: 13
Training loss: 0.9090179800987244
Validation loss: 1.8906431300665743

Epoch: 204| Step: 0
Training loss: 0.27614572644233704
Validation loss: 1.8897776411425682

Epoch: 6| Step: 1
Training loss: 0.6631087064743042
Validation loss: 1.904541577062299

Epoch: 6| Step: 2
Training loss: 0.33529895544052124
Validation loss: 1.8781499516579412

Epoch: 6| Step: 3
Training loss: 0.5988718271255493
Validation loss: 1.8846252246569561

Epoch: 6| Step: 4
Training loss: 0.9602125287055969
Validation loss: 1.8728192083297237

Epoch: 6| Step: 5
Training loss: 0.7634320259094238
Validation loss: 1.8564822289251512

Epoch: 6| Step: 6
Training loss: 0.831114649772644
Validation loss: 1.8592691190781132

Epoch: 6| Step: 7
Training loss: 0.5739086270332336
Validation loss: 1.854158031043186

Epoch: 6| Step: 8
Training loss: 0.828151524066925
Validation loss: 1.8573289276451193

Epoch: 6| Step: 9
Training loss: 0.6965232491493225
Validation loss: 1.852204994488788

Epoch: 6| Step: 10
Training loss: 0.7859134078025818
Validation loss: 1.857181272199077

Epoch: 6| Step: 11
Training loss: 0.6465693712234497
Validation loss: 1.8562982466913038

Epoch: 6| Step: 12
Training loss: 0.8134148716926575
Validation loss: 1.865326658371956

Epoch: 6| Step: 13
Training loss: 0.6609878540039062
Validation loss: 1.8644089570609472

Epoch: 205| Step: 0
Training loss: 0.7760875821113586
Validation loss: 1.8797757561488817

Epoch: 6| Step: 1
Training loss: 0.479910671710968
Validation loss: 1.8522679126390846

Epoch: 6| Step: 2
Training loss: 0.9785302877426147
Validation loss: 1.8568304277235461

Epoch: 6| Step: 3
Training loss: 0.8476225137710571
Validation loss: 1.8372493700314594

Epoch: 6| Step: 4
Training loss: 0.7516297101974487
Validation loss: 1.8245109742687595

Epoch: 6| Step: 5
Training loss: 0.6749343872070312
Validation loss: 1.8337911995508338

Epoch: 6| Step: 6
Training loss: 0.5793881416320801
Validation loss: 1.8233087267926944

Epoch: 6| Step: 7
Training loss: 0.5448369979858398
Validation loss: 1.8265607844116867

Epoch: 6| Step: 8
Training loss: 0.585824191570282
Validation loss: 1.8280097643534343

Epoch: 6| Step: 9
Training loss: 0.39969655871391296
Validation loss: 1.8201324555181688

Epoch: 6| Step: 10
Training loss: 0.6556728482246399
Validation loss: 1.8451068644882531

Epoch: 6| Step: 11
Training loss: 0.6074697971343994
Validation loss: 1.8539924519036406

Epoch: 6| Step: 12
Training loss: 0.5964838862419128
Validation loss: 1.8506118994887157

Epoch: 6| Step: 13
Training loss: 0.5786182880401611
Validation loss: 1.8682262820582236

Epoch: 206| Step: 0
Training loss: 0.6539962887763977
Validation loss: 1.854827978277719

Epoch: 6| Step: 1
Training loss: 0.529936671257019
Validation loss: 1.8523987929026287

Epoch: 6| Step: 2
Training loss: 0.9949953556060791
Validation loss: 1.8777775764465332

Epoch: 6| Step: 3
Training loss: 0.7437136769294739
Validation loss: 1.8600122736346336

Epoch: 6| Step: 4
Training loss: 0.7830618023872375
Validation loss: 1.868798412302489

Epoch: 6| Step: 5
Training loss: 0.5109276175498962
Validation loss: 1.8566870817574121

Epoch: 6| Step: 6
Training loss: 0.5835345983505249
Validation loss: 1.8502734784157044

Epoch: 6| Step: 7
Training loss: 0.5028635263442993
Validation loss: 1.8639972825204172

Epoch: 6| Step: 8
Training loss: 0.6659657955169678
Validation loss: 1.8481456938610281

Epoch: 6| Step: 9
Training loss: 0.4126805067062378
Validation loss: 1.860125054595291

Epoch: 6| Step: 10
Training loss: 0.3382037580013275
Validation loss: 1.8328910668690999

Epoch: 6| Step: 11
Training loss: 0.9052584171295166
Validation loss: 1.8391839765733289

Epoch: 6| Step: 12
Training loss: 0.6625247001647949
Validation loss: 1.836575984954834

Epoch: 6| Step: 13
Training loss: 0.6263114809989929
Validation loss: 1.8278698818657988

Epoch: 207| Step: 0
Training loss: 0.8593200445175171
Validation loss: 1.8206404588555778

Epoch: 6| Step: 1
Training loss: 0.6040324568748474
Validation loss: 1.8476983116519066

Epoch: 6| Step: 2
Training loss: 0.6900249123573303
Validation loss: 1.838308670187509

Epoch: 6| Step: 3
Training loss: 0.43203818798065186
Validation loss: 1.8211673562244703

Epoch: 6| Step: 4
Training loss: 0.668848991394043
Validation loss: 1.7990051623313659

Epoch: 6| Step: 5
Training loss: 0.8245854377746582
Validation loss: 1.8144585868363738

Epoch: 6| Step: 6
Training loss: 0.5411104559898376
Validation loss: 1.7991181394105316

Epoch: 6| Step: 7
Training loss: 0.49152684211730957
Validation loss: 1.7838822077679377

Epoch: 6| Step: 8
Training loss: 0.46735814213752747
Validation loss: 1.779043661650791

Epoch: 6| Step: 9
Training loss: 0.7596204280853271
Validation loss: 1.802610024970065

Epoch: 6| Step: 10
Training loss: 0.8742721080780029
Validation loss: 1.792764336832108

Epoch: 6| Step: 11
Training loss: 0.6273581981658936
Validation loss: 1.8232034675536617

Epoch: 6| Step: 12
Training loss: 0.6420903205871582
Validation loss: 1.845245667683181

Epoch: 6| Step: 13
Training loss: 0.7780724167823792
Validation loss: 1.8731718627355431

Epoch: 208| Step: 0
Training loss: 0.6465001106262207
Validation loss: 1.89398177208439

Epoch: 6| Step: 1
Training loss: 0.5771017670631409
Validation loss: 1.9151759275826075

Epoch: 6| Step: 2
Training loss: 0.8813563585281372
Validation loss: 1.9374353244740476

Epoch: 6| Step: 3
Training loss: 0.8590775728225708
Validation loss: 1.907998026058238

Epoch: 6| Step: 4
Training loss: 0.7512105703353882
Validation loss: 1.9189261390316872

Epoch: 6| Step: 5
Training loss: 0.729036271572113
Validation loss: 1.8467569697287776

Epoch: 6| Step: 6
Training loss: 0.7042896747589111
Validation loss: 1.8416710335721251

Epoch: 6| Step: 7
Training loss: 0.4064432680606842
Validation loss: 1.834009414078087

Epoch: 6| Step: 8
Training loss: 0.6456135511398315
Validation loss: 1.7832969286108529

Epoch: 6| Step: 9
Training loss: 0.500791072845459
Validation loss: 1.81795169332976

Epoch: 6| Step: 10
Training loss: 0.7164821624755859
Validation loss: 1.8015213833060315

Epoch: 6| Step: 11
Training loss: 0.5107020139694214
Validation loss: 1.790576914305328

Epoch: 6| Step: 12
Training loss: 0.6380282044410706
Validation loss: 1.7967503455377394

Epoch: 6| Step: 13
Training loss: 0.7479449510574341
Validation loss: 1.8072505586890764

Epoch: 209| Step: 0
Training loss: 0.38632017374038696
Validation loss: 1.7924425742959464

Epoch: 6| Step: 1
Training loss: 0.6757889986038208
Validation loss: 1.8098422211985434

Epoch: 6| Step: 2
Training loss: 0.889286458492279
Validation loss: 1.8300229926263132

Epoch: 6| Step: 3
Training loss: 1.0556273460388184
Validation loss: 1.8263263369119296

Epoch: 6| Step: 4
Training loss: 0.3272683620452881
Validation loss: 1.8162482477003528

Epoch: 6| Step: 5
Training loss: 0.605698823928833
Validation loss: 1.8145067666166572

Epoch: 6| Step: 6
Training loss: 0.8291245102882385
Validation loss: 1.8291345796277445

Epoch: 6| Step: 7
Training loss: 0.7986646890640259
Validation loss: 1.8373603564436718

Epoch: 6| Step: 8
Training loss: 0.2913345694541931
Validation loss: 1.8421908488837622

Epoch: 6| Step: 9
Training loss: 0.680306077003479
Validation loss: 1.8403156700954642

Epoch: 6| Step: 10
Training loss: 0.5117978453636169
Validation loss: 1.8110938918205999

Epoch: 6| Step: 11
Training loss: 0.3804779052734375
Validation loss: 1.8177650961824643

Epoch: 6| Step: 12
Training loss: 0.3901790380477905
Validation loss: 1.821904702853131

Epoch: 6| Step: 13
Training loss: 0.9758294224739075
Validation loss: 1.8419185530754827

Epoch: 210| Step: 0
Training loss: 0.4489947259426117
Validation loss: 1.8428857890508508

Epoch: 6| Step: 1
Training loss: 0.4662458598613739
Validation loss: 1.8404605773187452

Epoch: 6| Step: 2
Training loss: 0.6267606019973755
Validation loss: 1.8506459497636365

Epoch: 6| Step: 3
Training loss: 0.6390193700790405
Validation loss: 1.8318143711295178

Epoch: 6| Step: 4
Training loss: 0.6286214590072632
Validation loss: 1.8444894757322086

Epoch: 6| Step: 5
Training loss: 0.9645510911941528
Validation loss: 1.856427345224606

Epoch: 6| Step: 6
Training loss: 1.0422534942626953
Validation loss: 1.8544553056839974

Epoch: 6| Step: 7
Training loss: 0.645500123500824
Validation loss: 1.8520387141935286

Epoch: 6| Step: 8
Training loss: 0.38031020760536194
Validation loss: 1.8527572103725967

Epoch: 6| Step: 9
Training loss: 0.6559087038040161
Validation loss: 1.8582452779175134

Epoch: 6| Step: 10
Training loss: 0.5225047469139099
Validation loss: 1.8707527909227597

Epoch: 6| Step: 11
Training loss: 0.48199886083602905
Validation loss: 1.8905232593577395

Epoch: 6| Step: 12
Training loss: 0.4024159908294678
Validation loss: 1.8818671780247842

Epoch: 6| Step: 13
Training loss: 0.3927767276763916
Validation loss: 1.8479492215700046

Epoch: 211| Step: 0
Training loss: 0.417510986328125
Validation loss: 1.8207866684083016

Epoch: 6| Step: 1
Training loss: 0.3872946500778198
Validation loss: 1.8147668236045427

Epoch: 6| Step: 2
Training loss: 0.32248666882514954
Validation loss: 1.8203222008161648

Epoch: 6| Step: 3
Training loss: 0.9359391331672668
Validation loss: 1.8172475407200475

Epoch: 6| Step: 4
Training loss: 0.72458815574646
Validation loss: 1.8247880487031833

Epoch: 6| Step: 5
Training loss: 0.6665976643562317
Validation loss: 1.8399817725663543

Epoch: 6| Step: 6
Training loss: 0.6747034788131714
Validation loss: 1.8251027112366052

Epoch: 6| Step: 7
Training loss: 0.9502606987953186
Validation loss: 1.8578139069259807

Epoch: 6| Step: 8
Training loss: 0.6506239175796509
Validation loss: 1.871722521320466

Epoch: 6| Step: 9
Training loss: 0.4986368715763092
Validation loss: 1.871125154597785

Epoch: 6| Step: 10
Training loss: 0.7317788600921631
Validation loss: 1.876613352888374

Epoch: 6| Step: 11
Training loss: 0.27960824966430664
Validation loss: 1.8605488179832377

Epoch: 6| Step: 12
Training loss: 0.5402406454086304
Validation loss: 1.860415554815723

Epoch: 6| Step: 13
Training loss: 0.4685654044151306
Validation loss: 1.8251920297581663

Epoch: 212| Step: 0
Training loss: 0.6467156410217285
Validation loss: 1.83107388916836

Epoch: 6| Step: 1
Training loss: 0.6676744222640991
Validation loss: 1.8385020186824184

Epoch: 6| Step: 2
Training loss: 0.47742003202438354
Validation loss: 1.851818537199369

Epoch: 6| Step: 3
Training loss: 0.697663426399231
Validation loss: 1.8489625928222493

Epoch: 6| Step: 4
Training loss: 0.6292597651481628
Validation loss: 1.861041251049247

Epoch: 6| Step: 5
Training loss: 0.3978188931941986
Validation loss: 1.8303385690976215

Epoch: 6| Step: 6
Training loss: 0.5596979856491089
Validation loss: 1.8429461204877464

Epoch: 6| Step: 7
Training loss: 0.49986064434051514
Validation loss: 1.8268630940427062

Epoch: 6| Step: 8
Training loss: 0.6676911115646362
Validation loss: 1.8302056289488269

Epoch: 6| Step: 9
Training loss: 0.6145540475845337
Validation loss: 1.8352951759933143

Epoch: 6| Step: 10
Training loss: 0.5656964778900146
Validation loss: 1.8202053731487644

Epoch: 6| Step: 11
Training loss: 0.58318030834198
Validation loss: 1.8235066808680052

Epoch: 6| Step: 12
Training loss: 0.5616077184677124
Validation loss: 1.8254471196923205

Epoch: 6| Step: 13
Training loss: 0.7051750421524048
Validation loss: 1.8122404557402416

Epoch: 213| Step: 0
Training loss: 0.6876042485237122
Validation loss: 1.797833711870255

Epoch: 6| Step: 1
Training loss: 0.6602386832237244
Validation loss: 1.7915568441473029

Epoch: 6| Step: 2
Training loss: 0.27562326192855835
Validation loss: 1.7996066385699856

Epoch: 6| Step: 3
Training loss: 0.793129026889801
Validation loss: 1.7998873033831198

Epoch: 6| Step: 4
Training loss: 0.48964983224868774
Validation loss: 1.7977694221722182

Epoch: 6| Step: 5
Training loss: 0.6525146961212158
Validation loss: 1.7898847377428444

Epoch: 6| Step: 6
Training loss: 0.5985157489776611
Validation loss: 1.7866905709748626

Epoch: 6| Step: 7
Training loss: 0.3363751769065857
Validation loss: 1.806164820988973

Epoch: 6| Step: 8
Training loss: 0.36078330874443054
Validation loss: 1.8008119560057116

Epoch: 6| Step: 9
Training loss: 0.3911081552505493
Validation loss: 1.811041501260573

Epoch: 6| Step: 10
Training loss: 0.4777858853340149
Validation loss: 1.8192961356973136

Epoch: 6| Step: 11
Training loss: 0.799363911151886
Validation loss: 1.8374715774290022

Epoch: 6| Step: 12
Training loss: 0.8085673451423645
Validation loss: 1.8332704677376697

Epoch: 6| Step: 13
Training loss: 0.5790672898292542
Validation loss: 1.8545672521796277

Epoch: 214| Step: 0
Training loss: 0.40906473994255066
Validation loss: 1.8247618931595997

Epoch: 6| Step: 1
Training loss: 0.5423912405967712
Validation loss: 1.8149381094081427

Epoch: 6| Step: 2
Training loss: 0.753253161907196
Validation loss: 1.8023100553020355

Epoch: 6| Step: 3
Training loss: 0.8190390467643738
Validation loss: 1.8000055692529167

Epoch: 6| Step: 4
Training loss: 0.7496052384376526
Validation loss: 1.800171015083149

Epoch: 6| Step: 5
Training loss: 0.3728812336921692
Validation loss: 1.7795991769400976

Epoch: 6| Step: 6
Training loss: 0.2848479151725769
Validation loss: 1.795605062156595

Epoch: 6| Step: 7
Training loss: 0.4827650785446167
Validation loss: 1.8148466284557054

Epoch: 6| Step: 8
Training loss: 0.9104102849960327
Validation loss: 1.8029768774586339

Epoch: 6| Step: 9
Training loss: 0.9086636304855347
Validation loss: 1.8245218376959524

Epoch: 6| Step: 10
Training loss: 0.6294993162155151
Validation loss: 1.7992722757401005

Epoch: 6| Step: 11
Training loss: 0.4199730157852173
Validation loss: 1.8091602991986018

Epoch: 6| Step: 12
Training loss: 0.23142576217651367
Validation loss: 1.8159894917600898

Epoch: 6| Step: 13
Training loss: 0.38554173707962036
Validation loss: 1.8192786003953667

Epoch: 215| Step: 0
Training loss: 0.2855311632156372
Validation loss: 1.8109822452709239

Epoch: 6| Step: 1
Training loss: 0.5480892062187195
Validation loss: 1.8302734026344873

Epoch: 6| Step: 2
Training loss: 0.8287877440452576
Validation loss: 1.8419575281040643

Epoch: 6| Step: 3
Training loss: 0.3477647602558136
Validation loss: 1.814486785601544

Epoch: 6| Step: 4
Training loss: 0.5823778510093689
Validation loss: 1.8108356639903078

Epoch: 6| Step: 5
Training loss: 0.32365915179252625
Validation loss: 1.7528060149121028

Epoch: 6| Step: 6
Training loss: 0.38705992698669434
Validation loss: 1.7796124078894173

Epoch: 6| Step: 7
Training loss: 0.5621400475502014
Validation loss: 1.7736198620129657

Epoch: 6| Step: 8
Training loss: 0.49089130759239197
Validation loss: 1.7682812547170987

Epoch: 6| Step: 9
Training loss: 0.5369276404380798
Validation loss: 1.757112140296608

Epoch: 6| Step: 10
Training loss: 0.5754638910293579
Validation loss: 1.7641668345338555

Epoch: 6| Step: 11
Training loss: 0.7473145723342896
Validation loss: 1.7493631339842273

Epoch: 6| Step: 12
Training loss: 0.46157896518707275
Validation loss: 1.7754732690831667

Epoch: 6| Step: 13
Training loss: 0.9271382093429565
Validation loss: 1.7542342370556248

Epoch: 216| Step: 0
Training loss: 0.39886966347694397
Validation loss: 1.7848226934350946

Epoch: 6| Step: 1
Training loss: 0.4501948058605194
Validation loss: 1.792817707984678

Epoch: 6| Step: 2
Training loss: 0.46102195978164673
Validation loss: 1.8112305364301127

Epoch: 6| Step: 3
Training loss: 0.4214925169944763
Validation loss: 1.7931510991947626

Epoch: 6| Step: 4
Training loss: 0.6733483076095581
Validation loss: 1.8122515357950681

Epoch: 6| Step: 5
Training loss: 0.5795602202415466
Validation loss: 1.803806112658593

Epoch: 6| Step: 6
Training loss: 0.5734187960624695
Validation loss: 1.7825431272547732

Epoch: 6| Step: 7
Training loss: 0.7189844846725464
Validation loss: 1.785942159673219

Epoch: 6| Step: 8
Training loss: 0.6304590702056885
Validation loss: 1.7866475274485927

Epoch: 6| Step: 9
Training loss: 0.8000439405441284
Validation loss: 1.7725392810760006

Epoch: 6| Step: 10
Training loss: 0.6279840469360352
Validation loss: 1.7635366493655789

Epoch: 6| Step: 11
Training loss: 0.44248121976852417
Validation loss: 1.7632871084315802

Epoch: 6| Step: 12
Training loss: 0.500645637512207
Validation loss: 1.7404606560225129

Epoch: 6| Step: 13
Training loss: 0.2813490331172943
Validation loss: 1.8005837650709255

Epoch: 217| Step: 0
Training loss: 0.6022127866744995
Validation loss: 1.7845301820385842

Epoch: 6| Step: 1
Training loss: 0.9315958023071289
Validation loss: 1.8050821827303978

Epoch: 6| Step: 2
Training loss: 0.6850675344467163
Validation loss: 1.8208460807800293

Epoch: 6| Step: 3
Training loss: 0.45638155937194824
Validation loss: 1.8349458350930163

Epoch: 6| Step: 4
Training loss: 0.3904871642589569
Validation loss: 1.824243305831827

Epoch: 6| Step: 5
Training loss: 0.5923022627830505
Validation loss: 1.8209690509303924

Epoch: 6| Step: 6
Training loss: 0.3563186824321747
Validation loss: 1.7980681029699181

Epoch: 6| Step: 7
Training loss: 0.4109325706958771
Validation loss: 1.8200725688729236

Epoch: 6| Step: 8
Training loss: 0.24923409521579742
Validation loss: 1.7965908793992893

Epoch: 6| Step: 9
Training loss: 0.7316806316375732
Validation loss: 1.8099816819672943

Epoch: 6| Step: 10
Training loss: 0.21768805384635925
Validation loss: 1.7867387289642005

Epoch: 6| Step: 11
Training loss: 0.3772592842578888
Validation loss: 1.761079547225788

Epoch: 6| Step: 12
Training loss: 0.5496087074279785
Validation loss: 1.7564903689968971

Epoch: 6| Step: 13
Training loss: 1.0918711423873901
Validation loss: 1.7419810705287482

Epoch: 218| Step: 0
Training loss: 0.5418104529380798
Validation loss: 1.7563349841743388

Epoch: 6| Step: 1
Training loss: 0.29453200101852417
Validation loss: 1.745953466302605

Epoch: 6| Step: 2
Training loss: 0.23719853162765503
Validation loss: 1.7413800339544974

Epoch: 6| Step: 3
Training loss: 0.509917140007019
Validation loss: 1.7670187411769744

Epoch: 6| Step: 4
Training loss: 0.596120297908783
Validation loss: 1.7494917838804183

Epoch: 6| Step: 5
Training loss: 0.43117207288742065
Validation loss: 1.7533915401786886

Epoch: 6| Step: 6
Training loss: 0.6637545824050903
Validation loss: 1.7625849221342353

Epoch: 6| Step: 7
Training loss: 0.5465670824050903
Validation loss: 1.7760437150155344

Epoch: 6| Step: 8
Training loss: 0.40904292464256287
Validation loss: 1.7670290957215011

Epoch: 6| Step: 9
Training loss: 0.6212327480316162
Validation loss: 1.7512296079307474

Epoch: 6| Step: 10
Training loss: 0.5705801248550415
Validation loss: 1.7729645108663907

Epoch: 6| Step: 11
Training loss: 0.4622120261192322
Validation loss: 1.767195624689902

Epoch: 6| Step: 12
Training loss: 0.3802959620952606
Validation loss: 1.768309957237654

Epoch: 6| Step: 13
Training loss: 1.0391379594802856
Validation loss: 1.795775403258621

Epoch: 219| Step: 0
Training loss: 0.4786734879016876
Validation loss: 1.7977482964915614

Epoch: 6| Step: 1
Training loss: 0.32315945625305176
Validation loss: 1.7879792746677194

Epoch: 6| Step: 2
Training loss: 0.6644395589828491
Validation loss: 1.7943543400815738

Epoch: 6| Step: 3
Training loss: 0.3882097601890564
Validation loss: 1.7967779559473838

Epoch: 6| Step: 4
Training loss: 0.4177194833755493
Validation loss: 1.8015254325764154

Epoch: 6| Step: 5
Training loss: 0.42220255732536316
Validation loss: 1.800378539228952

Epoch: 6| Step: 6
Training loss: 0.724011242389679
Validation loss: 1.8065135107245496

Epoch: 6| Step: 7
Training loss: 0.4716988503932953
Validation loss: 1.8069591394034765

Epoch: 6| Step: 8
Training loss: 0.4604964852333069
Validation loss: 1.7936777043086227

Epoch: 6| Step: 9
Training loss: 0.680652379989624
Validation loss: 1.7799004021511282

Epoch: 6| Step: 10
Training loss: 0.45903509855270386
Validation loss: 1.78889040793142

Epoch: 6| Step: 11
Training loss: 0.45080170035362244
Validation loss: 1.7806664461730628

Epoch: 6| Step: 12
Training loss: 0.8421540260314941
Validation loss: 1.7516490438933014

Epoch: 6| Step: 13
Training loss: 0.4734184443950653
Validation loss: 1.7577243953622796

Epoch: 220| Step: 0
Training loss: 0.4145454466342926
Validation loss: 1.7560246452208488

Epoch: 6| Step: 1
Training loss: 0.6109411716461182
Validation loss: 1.7276545634833715

Epoch: 6| Step: 2
Training loss: 0.6455081105232239
Validation loss: 1.7512723604838054

Epoch: 6| Step: 3
Training loss: 0.3725726008415222
Validation loss: 1.766347127576028

Epoch: 6| Step: 4
Training loss: 0.3356541693210602
Validation loss: 1.784052336087791

Epoch: 6| Step: 5
Training loss: 0.5080780982971191
Validation loss: 1.7769524897298505

Epoch: 6| Step: 6
Training loss: 0.48207777738571167
Validation loss: 1.7996351334356493

Epoch: 6| Step: 7
Training loss: 0.6272368431091309
Validation loss: 1.8073857753507552

Epoch: 6| Step: 8
Training loss: 0.6372002363204956
Validation loss: 1.844386241769278

Epoch: 6| Step: 9
Training loss: 0.3743864893913269
Validation loss: 1.8324899160733787

Epoch: 6| Step: 10
Training loss: 0.598875105381012
Validation loss: 1.8173132199113087

Epoch: 6| Step: 11
Training loss: 0.5861799716949463
Validation loss: 1.7988957205126364

Epoch: 6| Step: 12
Training loss: 0.4668799638748169
Validation loss: 1.7521145061780048

Epoch: 6| Step: 13
Training loss: 0.3283528685569763
Validation loss: 1.7631673159137848

Epoch: 221| Step: 0
Training loss: 0.6640315055847168
Validation loss: 1.7547828958880516

Epoch: 6| Step: 1
Training loss: 0.5396533012390137
Validation loss: 1.7570594677361109

Epoch: 6| Step: 2
Training loss: 0.4637356400489807
Validation loss: 1.7505700780499367

Epoch: 6| Step: 3
Training loss: 0.40661442279815674
Validation loss: 1.78555525759215

Epoch: 6| Step: 4
Training loss: 0.34404927492141724
Validation loss: 1.776454907591625

Epoch: 6| Step: 5
Training loss: 0.8949742317199707
Validation loss: 1.7942693387308428

Epoch: 6| Step: 6
Training loss: 0.6137442588806152
Validation loss: 1.8065590948186896

Epoch: 6| Step: 7
Training loss: 0.4471004903316498
Validation loss: 1.8465643185441212

Epoch: 6| Step: 8
Training loss: 0.47665756940841675
Validation loss: 1.8263965152925061

Epoch: 6| Step: 9
Training loss: 0.40093880891799927
Validation loss: 1.8063473316930956

Epoch: 6| Step: 10
Training loss: 0.28508177399635315
Validation loss: 1.8191698943414996

Epoch: 6| Step: 11
Training loss: 0.5512232780456543
Validation loss: 1.8005710289042482

Epoch: 6| Step: 12
Training loss: 0.3425041437149048
Validation loss: 1.8261341151370798

Epoch: 6| Step: 13
Training loss: 0.43629416823387146
Validation loss: 1.816150406355499

Epoch: 222| Step: 0
Training loss: 0.4658351540565491
Validation loss: 1.8452006501536216

Epoch: 6| Step: 1
Training loss: 0.5417542457580566
Validation loss: 1.84212238301513

Epoch: 6| Step: 2
Training loss: 0.27786338329315186
Validation loss: 1.8644551513015584

Epoch: 6| Step: 3
Training loss: 0.46072137355804443
Validation loss: 1.821794581669633

Epoch: 6| Step: 4
Training loss: 0.5570940971374512
Validation loss: 1.8384155099109938

Epoch: 6| Step: 5
Training loss: 0.4587516188621521
Validation loss: 1.8374687497333815

Epoch: 6| Step: 6
Training loss: 0.5320339798927307
Validation loss: 1.8246190035214989

Epoch: 6| Step: 7
Training loss: 0.30501553416252136
Validation loss: 1.8046486223897626

Epoch: 6| Step: 8
Training loss: 0.8126821517944336
Validation loss: 1.8276350216198993

Epoch: 6| Step: 9
Training loss: 0.487947553396225
Validation loss: 1.8179140180669806

Epoch: 6| Step: 10
Training loss: 0.4063689708709717
Validation loss: 1.8103462239747405

Epoch: 6| Step: 11
Training loss: 0.9207414388656616
Validation loss: 1.8016532556985014

Epoch: 6| Step: 12
Training loss: 0.3420022130012512
Validation loss: 1.7895130777871737

Epoch: 6| Step: 13
Training loss: 0.5923588275909424
Validation loss: 1.7609826403279458

Epoch: 223| Step: 0
Training loss: 0.5424813032150269
Validation loss: 1.7685305303142917

Epoch: 6| Step: 1
Training loss: 0.41871026158332825
Validation loss: 1.7818848368942097

Epoch: 6| Step: 2
Training loss: 0.754547119140625
Validation loss: 1.798895953803934

Epoch: 6| Step: 3
Training loss: 0.635348916053772
Validation loss: 1.8075263346395185

Epoch: 6| Step: 4
Training loss: 0.25546544790267944
Validation loss: 1.7994176431368756

Epoch: 6| Step: 5
Training loss: 0.5571954250335693
Validation loss: 1.8073880185363114

Epoch: 6| Step: 6
Training loss: 0.4041035771369934
Validation loss: 1.7881388138699275

Epoch: 6| Step: 7
Training loss: 0.381803959608078
Validation loss: 1.796266842913884

Epoch: 6| Step: 8
Training loss: 0.5730248689651489
Validation loss: 1.7988697944148895

Epoch: 6| Step: 9
Training loss: 0.40651190280914307
Validation loss: 1.795104604895397

Epoch: 6| Step: 10
Training loss: 0.581160843372345
Validation loss: 1.8111738735629666

Epoch: 6| Step: 11
Training loss: 0.594151496887207
Validation loss: 1.808523613919494

Epoch: 6| Step: 12
Training loss: 0.5341591835021973
Validation loss: 1.8099203686560354

Epoch: 6| Step: 13
Training loss: 0.5905081629753113
Validation loss: 1.8189802048026875

Epoch: 224| Step: 0
Training loss: 0.5268293023109436
Validation loss: 1.8202560576059486

Epoch: 6| Step: 1
Training loss: 0.39576849341392517
Validation loss: 1.7969335971340057

Epoch: 6| Step: 2
Training loss: 0.5324055552482605
Validation loss: 1.8045752676584388

Epoch: 6| Step: 3
Training loss: 0.7338044047355652
Validation loss: 1.8095782162040792

Epoch: 6| Step: 4
Training loss: 0.5974712371826172
Validation loss: 1.7960939971349572

Epoch: 6| Step: 5
Training loss: 0.343471884727478
Validation loss: 1.8197945189732376

Epoch: 6| Step: 6
Training loss: 0.41032055020332336
Validation loss: 1.845750948434235

Epoch: 6| Step: 7
Training loss: 0.4600521922111511
Validation loss: 1.8446696881325013

Epoch: 6| Step: 8
Training loss: 0.5935091972351074
Validation loss: 1.838884207510179

Epoch: 6| Step: 9
Training loss: 0.4279833734035492
Validation loss: 1.8132058484579927

Epoch: 6| Step: 10
Training loss: 0.3866886496543884
Validation loss: 1.8025879244650564

Epoch: 6| Step: 11
Training loss: 0.30272984504699707
Validation loss: 1.797719906735164

Epoch: 6| Step: 12
Training loss: 0.5328353047370911
Validation loss: 1.7802103232311945

Epoch: 6| Step: 13
Training loss: 0.731880784034729
Validation loss: 1.7876563508023497

Epoch: 225| Step: 0
Training loss: 0.38441091775894165
Validation loss: 1.7903861614965624

Epoch: 6| Step: 1
Training loss: 0.5478269457817078
Validation loss: 1.7629189606635802

Epoch: 6| Step: 2
Training loss: 0.3906828761100769
Validation loss: 1.7711373003580237

Epoch: 6| Step: 3
Training loss: 0.4404732882976532
Validation loss: 1.7903410439850183

Epoch: 6| Step: 4
Training loss: 0.5382903218269348
Validation loss: 1.793574994610202

Epoch: 6| Step: 5
Training loss: 0.5776573419570923
Validation loss: 1.7659729744798394

Epoch: 6| Step: 6
Training loss: 0.49459972977638245
Validation loss: 1.7913391013299265

Epoch: 6| Step: 7
Training loss: 0.5732417702674866
Validation loss: 1.81299102434548

Epoch: 6| Step: 8
Training loss: 0.3757242262363434
Validation loss: 1.797711246757097

Epoch: 6| Step: 9
Training loss: 0.4233339726924896
Validation loss: 1.800900831017443

Epoch: 6| Step: 10
Training loss: 0.18184268474578857
Validation loss: 1.7745570149472965

Epoch: 6| Step: 11
Training loss: 0.6727081537246704
Validation loss: 1.7686857062001382

Epoch: 6| Step: 12
Training loss: 0.4839606285095215
Validation loss: 1.7860618483635686

Epoch: 6| Step: 13
Training loss: 0.8853580951690674
Validation loss: 1.7765171502226142

Epoch: 226| Step: 0
Training loss: 0.47246065735816956
Validation loss: 1.7746276663195701

Epoch: 6| Step: 1
Training loss: 0.258165568113327
Validation loss: 1.771940521014634

Epoch: 6| Step: 2
Training loss: 0.4470606744289398
Validation loss: 1.7941520239717217

Epoch: 6| Step: 3
Training loss: 0.5206489562988281
Validation loss: 1.8243162029532975

Epoch: 6| Step: 4
Training loss: 0.4513198435306549
Validation loss: 1.8492656792363813

Epoch: 6| Step: 5
Training loss: 0.5822815895080566
Validation loss: 1.8436688377011208

Epoch: 6| Step: 6
Training loss: 0.3540687561035156
Validation loss: 1.8187696562018445

Epoch: 6| Step: 7
Training loss: 0.4323573112487793
Validation loss: 1.8017986230952765

Epoch: 6| Step: 8
Training loss: 0.8133543729782104
Validation loss: 1.7876492136268205

Epoch: 6| Step: 9
Training loss: 0.6813757419586182
Validation loss: 1.7663526765761837

Epoch: 6| Step: 10
Training loss: 0.3709873557090759
Validation loss: 1.7402388254801433

Epoch: 6| Step: 11
Training loss: 0.4880567193031311
Validation loss: 1.7112350079321093

Epoch: 6| Step: 12
Training loss: 0.5643321871757507
Validation loss: 1.7143667333869523

Epoch: 6| Step: 13
Training loss: 0.26889660954475403
Validation loss: 1.71834812882126

Epoch: 227| Step: 0
Training loss: 0.36597740650177
Validation loss: 1.7083209022398917

Epoch: 6| Step: 1
Training loss: 0.5602874159812927
Validation loss: 1.7197378425187961

Epoch: 6| Step: 2
Training loss: 0.7014936804771423
Validation loss: 1.7318990128014677

Epoch: 6| Step: 3
Training loss: 0.3989291191101074
Validation loss: 1.747255052289655

Epoch: 6| Step: 4
Training loss: 0.4527621567249298
Validation loss: 1.780218429462884

Epoch: 6| Step: 5
Training loss: 0.33150041103363037
Validation loss: 1.775173080864773

Epoch: 6| Step: 6
Training loss: 0.3296334147453308
Validation loss: 1.7850656201762538

Epoch: 6| Step: 7
Training loss: 0.4234028458595276
Validation loss: 1.8095382105919622

Epoch: 6| Step: 8
Training loss: 0.38957396149635315
Validation loss: 1.8110082175142022

Epoch: 6| Step: 9
Training loss: 0.4682035446166992
Validation loss: 1.845842344786531

Epoch: 6| Step: 10
Training loss: 0.6489750146865845
Validation loss: 1.8315074302816903

Epoch: 6| Step: 11
Training loss: 0.3738296627998352
Validation loss: 1.8672336404041578

Epoch: 6| Step: 12
Training loss: 0.5309402346611023
Validation loss: 1.8262292159500944

Epoch: 6| Step: 13
Training loss: 0.5089265704154968
Validation loss: 1.8154567749269548

Epoch: 228| Step: 0
Training loss: 0.37510237097740173
Validation loss: 1.786968792638471

Epoch: 6| Step: 1
Training loss: 0.33986616134643555
Validation loss: 1.768937110900879

Epoch: 6| Step: 2
Training loss: 0.5826807022094727
Validation loss: 1.761128653762161

Epoch: 6| Step: 3
Training loss: 0.38615551590919495
Validation loss: 1.729779779270131

Epoch: 6| Step: 4
Training loss: 0.6554211378097534
Validation loss: 1.7241463609921035

Epoch: 6| Step: 5
Training loss: 0.24273917078971863
Validation loss: 1.7423813881412629

Epoch: 6| Step: 6
Training loss: 0.4273112714290619
Validation loss: 1.7149470608721498

Epoch: 6| Step: 7
Training loss: 0.3978153467178345
Validation loss: 1.7173450710952922

Epoch: 6| Step: 8
Training loss: 0.5607611536979675
Validation loss: 1.718065563068595

Epoch: 6| Step: 9
Training loss: 0.7501355409622192
Validation loss: 1.7220052083333333

Epoch: 6| Step: 10
Training loss: 0.2590038776397705
Validation loss: 1.7259562079624464

Epoch: 6| Step: 11
Training loss: 0.47073543071746826
Validation loss: 1.7370691568620744

Epoch: 6| Step: 12
Training loss: 0.44677427411079407
Validation loss: 1.7867229830834173

Epoch: 6| Step: 13
Training loss: 0.4701816737651825
Validation loss: 1.7496734383285686

Epoch: 229| Step: 0
Training loss: 0.19995854794979095
Validation loss: 1.73157746817476

Epoch: 6| Step: 1
Training loss: 0.5614315271377563
Validation loss: 1.7431744554991364

Epoch: 6| Step: 2
Training loss: 0.524207353591919
Validation loss: 1.7623872167320662

Epoch: 6| Step: 3
Training loss: 0.41921114921569824
Validation loss: 1.77130171304108

Epoch: 6| Step: 4
Training loss: 0.5117124915122986
Validation loss: 1.7470204163623113

Epoch: 6| Step: 5
Training loss: 0.4347490072250366
Validation loss: 1.7704429549555625

Epoch: 6| Step: 6
Training loss: 0.5214558839797974
Validation loss: 1.7403194186508015

Epoch: 6| Step: 7
Training loss: 0.24955137073993683
Validation loss: 1.75857283735788

Epoch: 6| Step: 8
Training loss: 0.31513267755508423
Validation loss: 1.7896424519118441

Epoch: 6| Step: 9
Training loss: 0.446339875459671
Validation loss: 1.783034106736542

Epoch: 6| Step: 10
Training loss: 0.49529221653938293
Validation loss: 1.8057070855171449

Epoch: 6| Step: 11
Training loss: 0.49075016379356384
Validation loss: 1.7830803881409347

Epoch: 6| Step: 12
Training loss: 0.42515233159065247
Validation loss: 1.7889135883700462

Epoch: 6| Step: 13
Training loss: 0.2914573848247528
Validation loss: 1.7760697154588596

Epoch: 230| Step: 0
Training loss: 0.377116858959198
Validation loss: 1.7608509140629922

Epoch: 6| Step: 1
Training loss: 0.27422311902046204
Validation loss: 1.783665273779182

Epoch: 6| Step: 2
Training loss: 0.20420369505882263
Validation loss: 1.7699323123501194

Epoch: 6| Step: 3
Training loss: 0.5592292547225952
Validation loss: 1.7727818886439006

Epoch: 6| Step: 4
Training loss: 0.3499605059623718
Validation loss: 1.7644888406158776

Epoch: 6| Step: 5
Training loss: 0.4949455261230469
Validation loss: 1.772540375750552

Epoch: 6| Step: 6
Training loss: 0.4179456830024719
Validation loss: 1.7822551368385233

Epoch: 6| Step: 7
Training loss: 0.3041311502456665
Validation loss: 1.7752434053728658

Epoch: 6| Step: 8
Training loss: 0.6542378664016724
Validation loss: 1.782031427147568

Epoch: 6| Step: 9
Training loss: 0.24246543645858765
Validation loss: 1.7477392919601933

Epoch: 6| Step: 10
Training loss: 0.6593875885009766
Validation loss: 1.761036693408925

Epoch: 6| Step: 11
Training loss: 0.37861454486846924
Validation loss: 1.73452712387167

Epoch: 6| Step: 12
Training loss: 0.5958897471427917
Validation loss: 1.7565134571444603

Epoch: 6| Step: 13
Training loss: 0.43548378348350525
Validation loss: 1.7439221784632692

Epoch: 231| Step: 0
Training loss: 0.4342074394226074
Validation loss: 1.7708977601861442

Epoch: 6| Step: 1
Training loss: 0.2967705726623535
Validation loss: 1.755547591435012

Epoch: 6| Step: 2
Training loss: 0.25056231021881104
Validation loss: 1.7555500948300926

Epoch: 6| Step: 3
Training loss: 0.19746460020542145
Validation loss: 1.7882842415122575

Epoch: 6| Step: 4
Training loss: 0.38956254720687866
Validation loss: 1.7841602845858502

Epoch: 6| Step: 5
Training loss: 0.5994333028793335
Validation loss: 1.7803479215150237

Epoch: 6| Step: 6
Training loss: 0.6039340496063232
Validation loss: 1.8281258126740814

Epoch: 6| Step: 7
Training loss: 0.5373368859291077
Validation loss: 1.841295849892401

Epoch: 6| Step: 8
Training loss: 0.7112616896629333
Validation loss: 1.8325936473825926

Epoch: 6| Step: 9
Training loss: 0.46388480067253113
Validation loss: 1.8480486408356698

Epoch: 6| Step: 10
Training loss: 0.5395891666412354
Validation loss: 1.7976347701523894

Epoch: 6| Step: 11
Training loss: 0.2882407307624817
Validation loss: 1.7688067651564074

Epoch: 6| Step: 12
Training loss: 0.5002768039703369
Validation loss: 1.736024377166584

Epoch: 6| Step: 13
Training loss: 0.8039118647575378
Validation loss: 1.7642118174542663

Epoch: 232| Step: 0
Training loss: 0.639694333076477
Validation loss: 1.746147818462823

Epoch: 6| Step: 1
Training loss: 0.7949314117431641
Validation loss: 1.7506286290384108

Epoch: 6| Step: 2
Training loss: 0.5120315551757812
Validation loss: 1.7414750411946287

Epoch: 6| Step: 3
Training loss: 0.39747363328933716
Validation loss: 1.7529925402774607

Epoch: 6| Step: 4
Training loss: 0.34559980034828186
Validation loss: 1.743117255549277

Epoch: 6| Step: 5
Training loss: 0.5500367283821106
Validation loss: 1.7659133531713997

Epoch: 6| Step: 6
Training loss: 0.5406044125556946
Validation loss: 1.7628131361417874

Epoch: 6| Step: 7
Training loss: 0.4405030608177185
Validation loss: 1.76261943258265

Epoch: 6| Step: 8
Training loss: 0.316057026386261
Validation loss: 1.744592312843569

Epoch: 6| Step: 9
Training loss: 0.32415950298309326
Validation loss: 1.7440816689563055

Epoch: 6| Step: 10
Training loss: 0.3847654461860657
Validation loss: 1.7511091283572617

Epoch: 6| Step: 11
Training loss: 0.23506927490234375
Validation loss: 1.7422044123372724

Epoch: 6| Step: 12
Training loss: 0.40621960163116455
Validation loss: 1.7365490005862327

Epoch: 6| Step: 13
Training loss: 0.29623061418533325
Validation loss: 1.7445545581079298

Epoch: 233| Step: 0
Training loss: 0.42742860317230225
Validation loss: 1.7416261267918411

Epoch: 6| Step: 1
Training loss: 0.3872082829475403
Validation loss: 1.7345231527923255

Epoch: 6| Step: 2
Training loss: 0.5234596729278564
Validation loss: 1.7332877497519217

Epoch: 6| Step: 3
Training loss: 0.5974985361099243
Validation loss: 1.7345609408552929

Epoch: 6| Step: 4
Training loss: 0.33838215470314026
Validation loss: 1.743299134315983

Epoch: 6| Step: 5
Training loss: 0.48467889428138733
Validation loss: 1.7432331564605876

Epoch: 6| Step: 6
Training loss: 0.3876611292362213
Validation loss: 1.7588033765874884

Epoch: 6| Step: 7
Training loss: 0.5831196308135986
Validation loss: 1.7849234509211716

Epoch: 6| Step: 8
Training loss: 0.33054375648498535
Validation loss: 1.774695352841449

Epoch: 6| Step: 9
Training loss: 0.44379475712776184
Validation loss: 1.780335327630402

Epoch: 6| Step: 10
Training loss: 0.5376622676849365
Validation loss: 1.7868427999557988

Epoch: 6| Step: 11
Training loss: 0.3665337860584259
Validation loss: 1.806470840207992

Epoch: 6| Step: 12
Training loss: 0.23293019831180573
Validation loss: 1.7857256794488559

Epoch: 6| Step: 13
Training loss: 0.14661246538162231
Validation loss: 1.8192484532633135

Epoch: 234| Step: 0
Training loss: 0.3090660870075226
Validation loss: 1.8155976367253128

Epoch: 6| Step: 1
Training loss: 0.5845608711242676
Validation loss: 1.8277113636334736

Epoch: 6| Step: 2
Training loss: 0.555419921875
Validation loss: 1.830810123874295

Epoch: 6| Step: 3
Training loss: 0.6036667823791504
Validation loss: 1.7928566266131658

Epoch: 6| Step: 4
Training loss: 0.2771824598312378
Validation loss: 1.7688735813222907

Epoch: 6| Step: 5
Training loss: 0.4998909533023834
Validation loss: 1.7696791054100118

Epoch: 6| Step: 6
Training loss: 0.29936492443084717
Validation loss: 1.7666646844597274

Epoch: 6| Step: 7
Training loss: 0.30856943130493164
Validation loss: 1.7684908143935665

Epoch: 6| Step: 8
Training loss: 0.38395726680755615
Validation loss: 1.7331919234286073

Epoch: 6| Step: 9
Training loss: 0.6835222840309143
Validation loss: 1.7325665822593115

Epoch: 6| Step: 10
Training loss: 0.35314318537712097
Validation loss: 1.7663562746458157

Epoch: 6| Step: 11
Training loss: 0.4292411804199219
Validation loss: 1.7786355992799163

Epoch: 6| Step: 12
Training loss: 0.35101309418678284
Validation loss: 1.7677712453308927

Epoch: 6| Step: 13
Training loss: 0.4806758165359497
Validation loss: 1.7613276102209603

Epoch: 235| Step: 0
Training loss: 0.30724209547042847
Validation loss: 1.7667149189979798

Epoch: 6| Step: 1
Training loss: 0.26931095123291016
Validation loss: 1.7591792357865201

Epoch: 6| Step: 2
Training loss: 0.36469602584838867
Validation loss: 1.77528586054361

Epoch: 6| Step: 3
Training loss: 0.33521828055381775
Validation loss: 1.7634480076451455

Epoch: 6| Step: 4
Training loss: 0.29326027631759644
Validation loss: 1.7658729886495939

Epoch: 6| Step: 5
Training loss: 0.4617423713207245
Validation loss: 1.7723686220825359

Epoch: 6| Step: 6
Training loss: 0.6650129556655884
Validation loss: 1.77062100748862

Epoch: 6| Step: 7
Training loss: 0.49451687932014465
Validation loss: 1.7485820862554735

Epoch: 6| Step: 8
Training loss: 0.49314144253730774
Validation loss: 1.773348698052027

Epoch: 6| Step: 9
Training loss: 0.43895605206489563
Validation loss: 1.7795536646278955

Epoch: 6| Step: 10
Training loss: 0.5693472027778625
Validation loss: 1.7801609782762424

Epoch: 6| Step: 11
Training loss: 0.24271145462989807
Validation loss: 1.783626066741123

Epoch: 6| Step: 12
Training loss: 0.3407825827598572
Validation loss: 1.781952948980434

Epoch: 6| Step: 13
Training loss: 0.23494158685207367
Validation loss: 1.773377844082412

Epoch: 236| Step: 0
Training loss: 0.4255930483341217
Validation loss: 1.773186836191403

Epoch: 6| Step: 1
Training loss: 0.3917098045349121
Validation loss: 1.7795740917164793

Epoch: 6| Step: 2
Training loss: 0.23727388679981232
Validation loss: 1.7726163607771679

Epoch: 6| Step: 3
Training loss: 0.30378931760787964
Validation loss: 1.7903222307082145

Epoch: 6| Step: 4
Training loss: 0.3802526593208313
Validation loss: 1.7985249027129142

Epoch: 6| Step: 5
Training loss: 0.6623187065124512
Validation loss: 1.8180566756956038

Epoch: 6| Step: 6
Training loss: 0.34901005029678345
Validation loss: 1.8462857328435427

Epoch: 6| Step: 7
Training loss: 0.3326755166053772
Validation loss: 1.8378400494975429

Epoch: 6| Step: 8
Training loss: 0.31706586480140686
Validation loss: 1.8134616241660169

Epoch: 6| Step: 9
Training loss: 0.5074473023414612
Validation loss: 1.8007482585086618

Epoch: 6| Step: 10
Training loss: 0.7544376254081726
Validation loss: 1.7935967419737129

Epoch: 6| Step: 11
Training loss: 0.3872428834438324
Validation loss: 1.7728224723569808

Epoch: 6| Step: 12
Training loss: 0.226869136095047
Validation loss: 1.7737955765057636

Epoch: 6| Step: 13
Training loss: 0.31140947341918945
Validation loss: 1.7684297100190194

Epoch: 237| Step: 0
Training loss: 0.2457020878791809
Validation loss: 1.7706273448082708

Epoch: 6| Step: 1
Training loss: 0.5480576157569885
Validation loss: 1.7492613946237872

Epoch: 6| Step: 2
Training loss: 0.2078649252653122
Validation loss: 1.7316129938248666

Epoch: 6| Step: 3
Training loss: 0.17886438965797424
Validation loss: 1.7323034771027104

Epoch: 6| Step: 4
Training loss: 0.5180628299713135
Validation loss: 1.729034431519047

Epoch: 6| Step: 5
Training loss: 0.5514131188392639
Validation loss: 1.7587374333412416

Epoch: 6| Step: 6
Training loss: 0.589713990688324
Validation loss: 1.7386438128768757

Epoch: 6| Step: 7
Training loss: 0.47970667481422424
Validation loss: 1.7644903480365712

Epoch: 6| Step: 8
Training loss: 0.26023221015930176
Validation loss: 1.75106587653519

Epoch: 6| Step: 9
Training loss: 0.4424913227558136
Validation loss: 1.7452504929675852

Epoch: 6| Step: 10
Training loss: 0.4226183295249939
Validation loss: 1.7449377954647105

Epoch: 6| Step: 11
Training loss: 0.5335797667503357
Validation loss: 1.749364004340223

Epoch: 6| Step: 12
Training loss: 0.5365767478942871
Validation loss: 1.7669227917989094

Epoch: 6| Step: 13
Training loss: 0.594306468963623
Validation loss: 1.7496829366171232

Epoch: 238| Step: 0
Training loss: 0.5425381660461426
Validation loss: 1.7782561779022217

Epoch: 6| Step: 1
Training loss: 0.3289111256599426
Validation loss: 1.762073863578099

Epoch: 6| Step: 2
Training loss: 0.4855153560638428
Validation loss: 1.787288317116358

Epoch: 6| Step: 3
Training loss: 0.49584537744522095
Validation loss: 1.7921733138381795

Epoch: 6| Step: 4
Training loss: 0.4418395161628723
Validation loss: 1.7715708722350418

Epoch: 6| Step: 5
Training loss: 0.4168813228607178
Validation loss: 1.7611010946253294

Epoch: 6| Step: 6
Training loss: 0.17235037684440613
Validation loss: 1.758429793901341

Epoch: 6| Step: 7
Training loss: 0.48798099160194397
Validation loss: 1.72456923607857

Epoch: 6| Step: 8
Training loss: 0.42696282267570496
Validation loss: 1.7302629076024538

Epoch: 6| Step: 9
Training loss: 0.34707215428352356
Validation loss: 1.7007061076420609

Epoch: 6| Step: 10
Training loss: 0.6472489237785339
Validation loss: 1.7515404634578253

Epoch: 6| Step: 11
Training loss: 0.580059289932251
Validation loss: 1.7465547259135912

Epoch: 6| Step: 12
Training loss: 0.3386818766593933
Validation loss: 1.7580737298534763

Epoch: 6| Step: 13
Training loss: 0.28915679454803467
Validation loss: 1.7275832776100404

Epoch: 239| Step: 0
Training loss: 0.43971508741378784
Validation loss: 1.7200911262983918

Epoch: 6| Step: 1
Training loss: 0.37840506434440613
Validation loss: 1.711456847447221

Epoch: 6| Step: 2
Training loss: 0.2539026439189911
Validation loss: 1.7175764691445135

Epoch: 6| Step: 3
Training loss: 0.5371915102005005
Validation loss: 1.6961019974882885

Epoch: 6| Step: 4
Training loss: 0.4284355044364929
Validation loss: 1.7218390280200588

Epoch: 6| Step: 5
Training loss: 0.411711186170578
Validation loss: 1.689006108109669

Epoch: 6| Step: 6
Training loss: 0.3711751401424408
Validation loss: 1.7181524102405836

Epoch: 6| Step: 7
Training loss: 0.3665958046913147
Validation loss: 1.711547795162406

Epoch: 6| Step: 8
Training loss: 0.36985355615615845
Validation loss: 1.741542403415967

Epoch: 6| Step: 9
Training loss: 0.533396303653717
Validation loss: 1.7564837201949088

Epoch: 6| Step: 10
Training loss: 0.3969283103942871
Validation loss: 1.7833865201601418

Epoch: 6| Step: 11
Training loss: 0.3788982629776001
Validation loss: 1.7602161412597985

Epoch: 6| Step: 12
Training loss: 0.26076969504356384
Validation loss: 1.7651886914366035

Epoch: 6| Step: 13
Training loss: 0.7557699680328369
Validation loss: 1.743260581006286

Epoch: 240| Step: 0
Training loss: 0.27835357189178467
Validation loss: 1.7365026589362853

Epoch: 6| Step: 1
Training loss: 0.49160218238830566
Validation loss: 1.7357115027725056

Epoch: 6| Step: 2
Training loss: 0.5136871337890625
Validation loss: 1.7087383834264611

Epoch: 6| Step: 3
Training loss: 0.5415697693824768
Validation loss: 1.706156631951691

Epoch: 6| Step: 4
Training loss: 0.280906081199646
Validation loss: 1.7238842620644519

Epoch: 6| Step: 5
Training loss: 0.3517088294029236
Validation loss: 1.724018112305672

Epoch: 6| Step: 6
Training loss: 0.2709429860115051
Validation loss: 1.7142427480348976

Epoch: 6| Step: 7
Training loss: 0.3359168469905853
Validation loss: 1.725223224650147

Epoch: 6| Step: 8
Training loss: 0.443878173828125
Validation loss: 1.7450465053640387

Epoch: 6| Step: 9
Training loss: 0.3847076892852783
Validation loss: 1.7177014248345488

Epoch: 6| Step: 10
Training loss: 0.4195014238357544
Validation loss: 1.704943731266965

Epoch: 6| Step: 11
Training loss: 0.2742781639099121
Validation loss: 1.717694672205115

Epoch: 6| Step: 12
Training loss: 0.32816413044929504
Validation loss: 1.7117050206789406

Epoch: 6| Step: 13
Training loss: 0.4626801908016205
Validation loss: 1.6877700257044967

Epoch: 241| Step: 0
Training loss: 0.4582067131996155
Validation loss: 1.703074985934842

Epoch: 6| Step: 1
Training loss: 0.4249346852302551
Validation loss: 1.7118379403186101

Epoch: 6| Step: 2
Training loss: 0.33552688360214233
Validation loss: 1.7228218534941315

Epoch: 6| Step: 3
Training loss: 0.26402080059051514
Validation loss: 1.7344532794849847

Epoch: 6| Step: 4
Training loss: 0.6390163898468018
Validation loss: 1.737077905285743

Epoch: 6| Step: 5
Training loss: 0.19630217552185059
Validation loss: 1.7437547535024664

Epoch: 6| Step: 6
Training loss: 0.2857074737548828
Validation loss: 1.7173032709347305

Epoch: 6| Step: 7
Training loss: 0.3392757177352905
Validation loss: 1.7354068986831173

Epoch: 6| Step: 8
Training loss: 0.4290813207626343
Validation loss: 1.7271171308332873

Epoch: 6| Step: 9
Training loss: 0.2362418919801712
Validation loss: 1.7221755494353592

Epoch: 6| Step: 10
Training loss: 0.2756742238998413
Validation loss: 1.7137272845032394

Epoch: 6| Step: 11
Training loss: 0.374581515789032
Validation loss: 1.7373922486459055

Epoch: 6| Step: 12
Training loss: 0.6340228915214539
Validation loss: 1.7064004341761272

Epoch: 6| Step: 13
Training loss: 0.4290466904640198
Validation loss: 1.7191580931345622

Epoch: 242| Step: 0
Training loss: 0.533169150352478
Validation loss: 1.734446810137841

Epoch: 6| Step: 1
Training loss: 0.1709722876548767
Validation loss: 1.7526795325740692

Epoch: 6| Step: 2
Training loss: 0.4661135673522949
Validation loss: 1.7491127906307098

Epoch: 6| Step: 3
Training loss: 0.2931922674179077
Validation loss: 1.7392961299547585

Epoch: 6| Step: 4
Training loss: 0.40606820583343506
Validation loss: 1.7609829210465955

Epoch: 6| Step: 5
Training loss: 0.42021265625953674
Validation loss: 1.7813543260738414

Epoch: 6| Step: 6
Training loss: 0.40209487080574036
Validation loss: 1.8048847362559328

Epoch: 6| Step: 7
Training loss: 0.3417513966560364
Validation loss: 1.781457922791922

Epoch: 6| Step: 8
Training loss: 0.46933451294898987
Validation loss: 1.7401559827148274

Epoch: 6| Step: 9
Training loss: 0.4544343054294586
Validation loss: 1.7236204429339337

Epoch: 6| Step: 10
Training loss: 0.33060646057128906
Validation loss: 1.7126215683516635

Epoch: 6| Step: 11
Training loss: 0.5094902515411377
Validation loss: 1.7264619219687678

Epoch: 6| Step: 12
Training loss: 0.39759504795074463
Validation loss: 1.730013915287551

Epoch: 6| Step: 13
Training loss: 0.3388422727584839
Validation loss: 1.7134999504653357

Epoch: 243| Step: 0
Training loss: 0.4308152496814728
Validation loss: 1.723701343741468

Epoch: 6| Step: 1
Training loss: 0.42094236612319946
Validation loss: 1.6962369065130911

Epoch: 6| Step: 2
Training loss: 0.2518121302127838
Validation loss: 1.7106103192093551

Epoch: 6| Step: 3
Training loss: 0.3624500036239624
Validation loss: 1.7275311280322332

Epoch: 6| Step: 4
Training loss: 0.6373915672302246
Validation loss: 1.7274278889420212

Epoch: 6| Step: 5
Training loss: 0.48163819313049316
Validation loss: 1.7295575910998928

Epoch: 6| Step: 6
Training loss: 0.3905390501022339
Validation loss: 1.731579230677697

Epoch: 6| Step: 7
Training loss: 0.20400376617908478
Validation loss: 1.7235596987508959

Epoch: 6| Step: 8
Training loss: 0.296965628862381
Validation loss: 1.7191737672334075

Epoch: 6| Step: 9
Training loss: 0.24717062711715698
Validation loss: 1.7134586252192014

Epoch: 6| Step: 10
Training loss: 0.400036096572876
Validation loss: 1.7340486805926087

Epoch: 6| Step: 11
Training loss: 0.3112891912460327
Validation loss: 1.7212849496513285

Epoch: 6| Step: 12
Training loss: 0.39145737886428833
Validation loss: 1.7229069253449798

Epoch: 6| Step: 13
Training loss: 0.38041171431541443
Validation loss: 1.7005682658123713

Epoch: 244| Step: 0
Training loss: 0.4161083996295929
Validation loss: 1.7218279248924666

Epoch: 6| Step: 1
Training loss: 0.3269460201263428
Validation loss: 1.701466138644885

Epoch: 6| Step: 2
Training loss: 0.7342369556427002
Validation loss: 1.7375430086607575

Epoch: 6| Step: 3
Training loss: 0.39474359154701233
Validation loss: 1.7234669577690862

Epoch: 6| Step: 4
Training loss: 0.2955511808395386
Validation loss: 1.704161859327747

Epoch: 6| Step: 5
Training loss: 0.2260778844356537
Validation loss: 1.7027850074152793

Epoch: 6| Step: 6
Training loss: 0.2734891474246979
Validation loss: 1.709405279928638

Epoch: 6| Step: 7
Training loss: 0.3660331666469574
Validation loss: 1.725244117039506

Epoch: 6| Step: 8
Training loss: 0.40708571672439575
Validation loss: 1.6968780602178266

Epoch: 6| Step: 9
Training loss: 0.20761212706565857
Validation loss: 1.7201880639599216

Epoch: 6| Step: 10
Training loss: 0.32853132486343384
Validation loss: 1.7290268867246565

Epoch: 6| Step: 11
Training loss: 0.4083794951438904
Validation loss: 1.7169534262790476

Epoch: 6| Step: 12
Training loss: 0.4883817136287689
Validation loss: 1.7228971168559084

Epoch: 6| Step: 13
Training loss: 0.1750289350748062
Validation loss: 1.7301217740581882

Epoch: 245| Step: 0
Training loss: 0.25232183933258057
Validation loss: 1.7356766564871675

Epoch: 6| Step: 1
Training loss: 0.5055819153785706
Validation loss: 1.7255882601584158

Epoch: 6| Step: 2
Training loss: 0.31263044476509094
Validation loss: 1.738150353072792

Epoch: 6| Step: 3
Training loss: 0.40485820174217224
Validation loss: 1.7325151838282102

Epoch: 6| Step: 4
Training loss: 0.2912830114364624
Validation loss: 1.7107841865990752

Epoch: 6| Step: 5
Training loss: 0.3855883479118347
Validation loss: 1.735629758527202

Epoch: 6| Step: 6
Training loss: 0.4807608127593994
Validation loss: 1.7043935855229695

Epoch: 6| Step: 7
Training loss: 0.4972986578941345
Validation loss: 1.7316476222007506

Epoch: 6| Step: 8
Training loss: 0.23639991879463196
Validation loss: 1.7247744939660514

Epoch: 6| Step: 9
Training loss: 0.26731210947036743
Validation loss: 1.701232671737671

Epoch: 6| Step: 10
Training loss: 0.2997886538505554
Validation loss: 1.70646160135987

Epoch: 6| Step: 11
Training loss: 0.5066943168640137
Validation loss: 1.7328926786299674

Epoch: 6| Step: 12
Training loss: 0.307104229927063
Validation loss: 1.7257289309655466

Epoch: 6| Step: 13
Training loss: 0.39908480644226074
Validation loss: 1.733918132320527

Epoch: 246| Step: 0
Training loss: 0.4237504303455353
Validation loss: 1.7528034076895764

Epoch: 6| Step: 1
Training loss: 0.377144992351532
Validation loss: 1.7523919869494695

Epoch: 6| Step: 2
Training loss: 0.47866490483283997
Validation loss: 1.7613715856306014

Epoch: 6| Step: 3
Training loss: 0.3550559878349304
Validation loss: 1.7479861436351654

Epoch: 6| Step: 4
Training loss: 0.3097556233406067
Validation loss: 1.7621669948741954

Epoch: 6| Step: 5
Training loss: 0.37957319617271423
Validation loss: 1.7417941862537014

Epoch: 6| Step: 6
Training loss: 0.15093804895877838
Validation loss: 1.7499759235689718

Epoch: 6| Step: 7
Training loss: 0.17042580246925354
Validation loss: 1.7188430255459202

Epoch: 6| Step: 8
Training loss: 0.42152541875839233
Validation loss: 1.7178448810372302

Epoch: 6| Step: 9
Training loss: 0.291321337223053
Validation loss: 1.7102689448223318

Epoch: 6| Step: 10
Training loss: 0.4817463457584381
Validation loss: 1.7175897577757477

Epoch: 6| Step: 11
Training loss: 0.22435249388217926
Validation loss: 1.6890865077254593

Epoch: 6| Step: 12
Training loss: 0.4266936480998993
Validation loss: 1.698397228794713

Epoch: 6| Step: 13
Training loss: 0.33568376302719116
Validation loss: 1.689075851953158

Epoch: 247| Step: 0
Training loss: 0.49971920251846313
Validation loss: 1.704486148331755

Epoch: 6| Step: 1
Training loss: 0.4078923165798187
Validation loss: 1.7108628403755926

Epoch: 6| Step: 2
Training loss: 0.287830114364624
Validation loss: 1.6947951150196854

Epoch: 6| Step: 3
Training loss: 0.3517802655696869
Validation loss: 1.6997535408184092

Epoch: 6| Step: 4
Training loss: 0.3171568512916565
Validation loss: 1.7024663712388726

Epoch: 6| Step: 5
Training loss: 0.4647996425628662
Validation loss: 1.7137301878262592

Epoch: 6| Step: 6
Training loss: 0.36883386969566345
Validation loss: 1.7084739720949562

Epoch: 6| Step: 7
Training loss: 0.28969112038612366
Validation loss: 1.7030841522319342

Epoch: 6| Step: 8
Training loss: 0.4053881764411926
Validation loss: 1.704454493779008

Epoch: 6| Step: 9
Training loss: 0.23872795701026917
Validation loss: 1.6990164941357029

Epoch: 6| Step: 10
Training loss: 0.20900917053222656
Validation loss: 1.7557677556109685

Epoch: 6| Step: 11
Training loss: 0.3192785978317261
Validation loss: 1.7575091751672889

Epoch: 6| Step: 12
Training loss: 0.32075607776641846
Validation loss: 1.7658742025334349

Epoch: 6| Step: 13
Training loss: 0.48533424735069275
Validation loss: 1.7504564715969948

Epoch: 248| Step: 0
Training loss: 0.36009812355041504
Validation loss: 1.7357500689004057

Epoch: 6| Step: 1
Training loss: 0.27219757437705994
Validation loss: 1.7325424866009784

Epoch: 6| Step: 2
Training loss: 0.396854043006897
Validation loss: 1.7353799804564445

Epoch: 6| Step: 3
Training loss: 0.28906911611557007
Validation loss: 1.7070166128937916

Epoch: 6| Step: 4
Training loss: 0.24905449151992798
Validation loss: 1.7049815449663388

Epoch: 6| Step: 5
Training loss: 0.30457794666290283
Validation loss: 1.7006004138659405

Epoch: 6| Step: 6
Training loss: 0.26198309659957886
Validation loss: 1.6930270733371857

Epoch: 6| Step: 7
Training loss: 0.4514450430870056
Validation loss: 1.690633350803006

Epoch: 6| Step: 8
Training loss: 0.2996461093425751
Validation loss: 1.677653899756811

Epoch: 6| Step: 9
Training loss: 0.46458446979522705
Validation loss: 1.690034120313583

Epoch: 6| Step: 10
Training loss: 0.4491841197013855
Validation loss: 1.692210030812089

Epoch: 6| Step: 11
Training loss: 0.32981181144714355
Validation loss: 1.6864963923731158

Epoch: 6| Step: 12
Training loss: 0.12077288329601288
Validation loss: 1.6821970042362009

Epoch: 6| Step: 13
Training loss: 0.3357733488082886
Validation loss: 1.7019322277397237

Epoch: 249| Step: 0
Training loss: 0.32735705375671387
Validation loss: 1.6912326748653124

Epoch: 6| Step: 1
Training loss: 0.24602414667606354
Validation loss: 1.7135611375172932

Epoch: 6| Step: 2
Training loss: 0.4236848056316376
Validation loss: 1.7128348837616623

Epoch: 6| Step: 3
Training loss: 0.41463321447372437
Validation loss: 1.6963243151223788

Epoch: 6| Step: 4
Training loss: 0.19801846146583557
Validation loss: 1.6921127201408468

Epoch: 6| Step: 5
Training loss: 0.33884090185165405
Validation loss: 1.7151898081584642

Epoch: 6| Step: 6
Training loss: 0.3626798689365387
Validation loss: 1.7197570570053593

Epoch: 6| Step: 7
Training loss: 0.31409889459609985
Validation loss: 1.751123002780381

Epoch: 6| Step: 8
Training loss: 0.2452862709760666
Validation loss: 1.7506554306194346

Epoch: 6| Step: 9
Training loss: 0.3543056845664978
Validation loss: 1.7358095568995322

Epoch: 6| Step: 10
Training loss: 0.2782922387123108
Validation loss: 1.725355863571167

Epoch: 6| Step: 11
Training loss: 0.4562667906284332
Validation loss: 1.7132646037686257

Epoch: 6| Step: 12
Training loss: 0.4272470474243164
Validation loss: 1.7068852916840584

Epoch: 6| Step: 13
Training loss: 0.3005658984184265
Validation loss: 1.6825454094076668

Epoch: 250| Step: 0
Training loss: 0.2700909972190857
Validation loss: 1.6797448512046569

Epoch: 6| Step: 1
Training loss: 0.2739490270614624
Validation loss: 1.6739171602392708

Epoch: 6| Step: 2
Training loss: 0.4448241591453552
Validation loss: 1.6744687941766554

Epoch: 6| Step: 3
Training loss: 0.46247920393943787
Validation loss: 1.6859785984921198

Epoch: 6| Step: 4
Training loss: 0.23758108913898468
Validation loss: 1.686400951877717

Epoch: 6| Step: 5
Training loss: 0.25073209404945374
Validation loss: 1.722584734680832

Epoch: 6| Step: 6
Training loss: 0.4380794167518616
Validation loss: 1.7059018381180302

Epoch: 6| Step: 7
Training loss: 0.3343812823295593
Validation loss: 1.732903967621506

Epoch: 6| Step: 8
Training loss: 0.3130861520767212
Validation loss: 1.7689063613132765

Epoch: 6| Step: 9
Training loss: 0.46323949098587036
Validation loss: 1.7409719369744743

Epoch: 6| Step: 10
Training loss: 0.24022924900054932
Validation loss: 1.74097103200933

Epoch: 6| Step: 11
Training loss: 0.53082275390625
Validation loss: 1.7460974839425856

Epoch: 6| Step: 12
Training loss: 0.2823673486709595
Validation loss: 1.7368840863627772

Epoch: 6| Step: 13
Training loss: 0.2306787669658661
Validation loss: 1.7338885209893669

Epoch: 251| Step: 0
Training loss: 0.25920408964157104
Validation loss: 1.724790834611462

Epoch: 6| Step: 1
Training loss: 0.4360288381576538
Validation loss: 1.712478360822124

Epoch: 6| Step: 2
Training loss: 0.3866758644580841
Validation loss: 1.7158593772560038

Epoch: 6| Step: 3
Training loss: 0.35614025592803955
Validation loss: 1.7018696697809363

Epoch: 6| Step: 4
Training loss: 0.385505348443985
Validation loss: 1.694376846795441

Epoch: 6| Step: 5
Training loss: 0.3886784017086029
Validation loss: 1.6990580148594354

Epoch: 6| Step: 6
Training loss: 0.3764117956161499
Validation loss: 1.702700887956927

Epoch: 6| Step: 7
Training loss: 0.379642128944397
Validation loss: 1.6954291757716928

Epoch: 6| Step: 8
Training loss: 0.1746731847524643
Validation loss: 1.7184495015810894

Epoch: 6| Step: 9
Training loss: 0.3733002543449402
Validation loss: 1.7318358036779589

Epoch: 6| Step: 10
Training loss: 0.24287377297878265
Validation loss: 1.727538344680622

Epoch: 6| Step: 11
Training loss: 0.23024925589561462
Validation loss: 1.7475706095336585

Epoch: 6| Step: 12
Training loss: 0.2684076428413391
Validation loss: 1.7425528495542464

Epoch: 6| Step: 13
Training loss: 0.23695336282253265
Validation loss: 1.7396452657638057

Epoch: 252| Step: 0
Training loss: 0.3616754114627838
Validation loss: 1.7570830596390592

Epoch: 6| Step: 1
Training loss: 0.17880529165267944
Validation loss: 1.7541621346627512

Epoch: 6| Step: 2
Training loss: 0.44777587056159973
Validation loss: 1.777353097033757

Epoch: 6| Step: 3
Training loss: 0.23552456498146057
Validation loss: 1.758977759268976

Epoch: 6| Step: 4
Training loss: 0.20904847979545593
Validation loss: 1.7345507632019699

Epoch: 6| Step: 5
Training loss: 0.27683573961257935
Validation loss: 1.737656178012971

Epoch: 6| Step: 6
Training loss: 0.15574532747268677
Validation loss: 1.750274254429725

Epoch: 6| Step: 7
Training loss: 0.461036741733551
Validation loss: 1.69866935283907

Epoch: 6| Step: 8
Training loss: 0.3547522723674774
Validation loss: 1.717559733698445

Epoch: 6| Step: 9
Training loss: 0.305051326751709
Validation loss: 1.7053532933676114

Epoch: 6| Step: 10
Training loss: 0.2732655107975006
Validation loss: 1.7124715812744633

Epoch: 6| Step: 11
Training loss: 0.332633912563324
Validation loss: 1.7142718376651886

Epoch: 6| Step: 12
Training loss: 0.36282220482826233
Validation loss: 1.6996914545694988

Epoch: 6| Step: 13
Training loss: 0.3249959349632263
Validation loss: 1.7048881951198782

Epoch: 253| Step: 0
Training loss: 0.37368011474609375
Validation loss: 1.6989832052620508

Epoch: 6| Step: 1
Training loss: 0.25208356976509094
Validation loss: 1.7271008824789396

Epoch: 6| Step: 2
Training loss: 0.4156093895435333
Validation loss: 1.7392044310928674

Epoch: 6| Step: 3
Training loss: 0.19792839884757996
Validation loss: 1.728134539819533

Epoch: 6| Step: 4
Training loss: 0.35439586639404297
Validation loss: 1.7277306331101285

Epoch: 6| Step: 5
Training loss: 0.1790945678949356
Validation loss: 1.717549313781082

Epoch: 6| Step: 6
Training loss: 0.29225584864616394
Validation loss: 1.69747817836782

Epoch: 6| Step: 7
Training loss: 0.23335547745227814
Validation loss: 1.750800581388576

Epoch: 6| Step: 8
Training loss: 0.2851771116256714
Validation loss: 1.7025103902304044

Epoch: 6| Step: 9
Training loss: 0.41173702478408813
Validation loss: 1.7186521035368725

Epoch: 6| Step: 10
Training loss: 0.3911373019218445
Validation loss: 1.7180366285385624

Epoch: 6| Step: 11
Training loss: 0.4259401261806488
Validation loss: 1.7067805400458715

Epoch: 6| Step: 12
Training loss: 0.30239391326904297
Validation loss: 1.729037054123417

Epoch: 6| Step: 13
Training loss: 0.3276113271713257
Validation loss: 1.7385477660804667

Epoch: 254| Step: 0
Training loss: 0.26344621181488037
Validation loss: 1.7712331638541272

Epoch: 6| Step: 1
Training loss: 0.30578017234802246
Validation loss: 1.8160249270418638

Epoch: 6| Step: 2
Training loss: 0.28296560049057007
Validation loss: 1.8260492022319506

Epoch: 6| Step: 3
Training loss: 0.2459951788187027
Validation loss: 1.7844826739321473

Epoch: 6| Step: 4
Training loss: 0.46016544103622437
Validation loss: 1.7780976474926036

Epoch: 6| Step: 5
Training loss: 0.3624614477157593
Validation loss: 1.7135964849943757

Epoch: 6| Step: 6
Training loss: 0.30119967460632324
Validation loss: 1.7286121486335673

Epoch: 6| Step: 7
Training loss: 0.40261757373809814
Validation loss: 1.696962091230577

Epoch: 6| Step: 8
Training loss: 0.2894185483455658
Validation loss: 1.7042597237453665

Epoch: 6| Step: 9
Training loss: 0.2770887613296509
Validation loss: 1.7053665307260328

Epoch: 6| Step: 10
Training loss: 0.3742859661579132
Validation loss: 1.708945938335952

Epoch: 6| Step: 11
Training loss: 0.2847338318824768
Validation loss: 1.739271794596026

Epoch: 6| Step: 12
Training loss: 0.3477967083454132
Validation loss: 1.7084553869821693

Epoch: 6| Step: 13
Training loss: 0.33216243982315063
Validation loss: 1.7128194455177552

Epoch: 255| Step: 0
Training loss: 0.3608434200286865
Validation loss: 1.717283942366159

Epoch: 6| Step: 1
Training loss: 0.40504348278045654
Validation loss: 1.6841961465856081

Epoch: 6| Step: 2
Training loss: 0.377204030752182
Validation loss: 1.7315762594182005

Epoch: 6| Step: 3
Training loss: 0.23426790535449982
Validation loss: 1.6873795896448114

Epoch: 6| Step: 4
Training loss: 0.3429272174835205
Validation loss: 1.720560085388922

Epoch: 6| Step: 5
Training loss: 0.23123681545257568
Validation loss: 1.6757712569288028

Epoch: 6| Step: 6
Training loss: 0.2031109631061554
Validation loss: 1.6766952045502201

Epoch: 6| Step: 7
Training loss: 0.5210919976234436
Validation loss: 1.7134538068566272

Epoch: 6| Step: 8
Training loss: 0.28135937452316284
Validation loss: 1.6940750524561892

Epoch: 6| Step: 9
Training loss: 0.3577619791030884
Validation loss: 1.7001488298498175

Epoch: 6| Step: 10
Training loss: 0.16580845415592194
Validation loss: 1.6947657523616668

Epoch: 6| Step: 11
Training loss: 0.2962223291397095
Validation loss: 1.6791411984351374

Epoch: 6| Step: 12
Training loss: 0.27413010597229004
Validation loss: 1.6755672911162018

Epoch: 6| Step: 13
Training loss: 0.13906536996364594
Validation loss: 1.6780916977954168

Epoch: 256| Step: 0
Training loss: 0.3111063241958618
Validation loss: 1.7194745848255772

Epoch: 6| Step: 1
Training loss: 0.25937730073928833
Validation loss: 1.719954103551885

Epoch: 6| Step: 2
Training loss: 0.3871755003929138
Validation loss: 1.714097810047929

Epoch: 6| Step: 3
Training loss: 0.3366626501083374
Validation loss: 1.7126930605980657

Epoch: 6| Step: 4
Training loss: 0.27168703079223633
Validation loss: 1.694728353972076

Epoch: 6| Step: 5
Training loss: 0.2887386381626129
Validation loss: 1.6858021161889518

Epoch: 6| Step: 6
Training loss: 0.4443035423755646
Validation loss: 1.70971933872469

Epoch: 6| Step: 7
Training loss: 0.3650039732456207
Validation loss: 1.680327747457771

Epoch: 6| Step: 8
Training loss: 0.2355547994375229
Validation loss: 1.6683857274311844

Epoch: 6| Step: 9
Training loss: 0.10101744532585144
Validation loss: 1.6680036373035882

Epoch: 6| Step: 10
Training loss: 0.4277111887931824
Validation loss: 1.6796567209305302

Epoch: 6| Step: 11
Training loss: 0.29956939816474915
Validation loss: 1.6784174032108758

Epoch: 6| Step: 12
Training loss: 0.43586450815200806
Validation loss: 1.7125309231460735

Epoch: 6| Step: 13
Training loss: 0.41243836283683777
Validation loss: 1.6921825191026092

Epoch: 257| Step: 0
Training loss: 0.45464372634887695
Validation loss: 1.6706565387787358

Epoch: 6| Step: 1
Training loss: 0.13770031929016113
Validation loss: 1.6895464017827024

Epoch: 6| Step: 2
Training loss: 0.46804875135421753
Validation loss: 1.682216211031842

Epoch: 6| Step: 3
Training loss: 0.14946937561035156
Validation loss: 1.6599857935341455

Epoch: 6| Step: 4
Training loss: 0.30475014448165894
Validation loss: 1.6832074849836287

Epoch: 6| Step: 5
Training loss: 0.24158276617527008
Validation loss: 1.714425890676437

Epoch: 6| Step: 6
Training loss: 0.23147641122341156
Validation loss: 1.6880087634568572

Epoch: 6| Step: 7
Training loss: 0.2674171030521393
Validation loss: 1.710436906865848

Epoch: 6| Step: 8
Training loss: 0.4079667329788208
Validation loss: 1.7270784352415351

Epoch: 6| Step: 9
Training loss: 0.41672849655151367
Validation loss: 1.7004378739223684

Epoch: 6| Step: 10
Training loss: 0.32201048731803894
Validation loss: 1.7117897413110221

Epoch: 6| Step: 11
Training loss: 0.3954537510871887
Validation loss: 1.7078259106605285

Epoch: 6| Step: 12
Training loss: 0.37360066175460815
Validation loss: 1.7181857183415403

Epoch: 6| Step: 13
Training loss: 0.2860765755176544
Validation loss: 1.7286124549886233

Epoch: 258| Step: 0
Training loss: 0.5539278388023376
Validation loss: 1.7390910835676296

Epoch: 6| Step: 1
Training loss: 0.3606216311454773
Validation loss: 1.7480138309540287

Epoch: 6| Step: 2
Training loss: 0.3194373846054077
Validation loss: 1.7445052054620558

Epoch: 6| Step: 3
Training loss: 0.2758886516094208
Validation loss: 1.7424824353187316

Epoch: 6| Step: 4
Training loss: 0.3109052777290344
Validation loss: 1.7365834636072959

Epoch: 6| Step: 5
Training loss: 0.3698195815086365
Validation loss: 1.7051309808608024

Epoch: 6| Step: 6
Training loss: 0.3137916624546051
Validation loss: 1.7188236316045125

Epoch: 6| Step: 7
Training loss: 0.30868780612945557
Validation loss: 1.6980604099970993

Epoch: 6| Step: 8
Training loss: 0.16999226808547974
Validation loss: 1.6582391262054443

Epoch: 6| Step: 9
Training loss: 0.31720006465911865
Validation loss: 1.6595188597197175

Epoch: 6| Step: 10
Training loss: 0.37935125827789307
Validation loss: 1.6840977207306893

Epoch: 6| Step: 11
Training loss: 0.24007217586040497
Validation loss: 1.6795638081847981

Epoch: 6| Step: 12
Training loss: 0.3420112729072571
Validation loss: 1.6694455364699006

Epoch: 6| Step: 13
Training loss: 0.1713080108165741
Validation loss: 1.641423439466825

Epoch: 259| Step: 0
Training loss: 0.3599794805049896
Validation loss: 1.6717055536085559

Epoch: 6| Step: 1
Training loss: 0.26850247383117676
Validation loss: 1.6862980281153033

Epoch: 6| Step: 2
Training loss: 0.37875980138778687
Validation loss: 1.7077224818609094

Epoch: 6| Step: 3
Training loss: 0.27430230379104614
Validation loss: 1.7240376472473145

Epoch: 6| Step: 4
Training loss: 0.24654151499271393
Validation loss: 1.7349012487678117

Epoch: 6| Step: 5
Training loss: 0.21276915073394775
Validation loss: 1.7168505332803214

Epoch: 6| Step: 6
Training loss: 0.2248082458972931
Validation loss: 1.7056268030597317

Epoch: 6| Step: 7
Training loss: 0.3737199306488037
Validation loss: 1.6826820411989767

Epoch: 6| Step: 8
Training loss: 0.2889680862426758
Validation loss: 1.6645848289612801

Epoch: 6| Step: 9
Training loss: 0.2393280565738678
Validation loss: 1.6712907539900912

Epoch: 6| Step: 10
Training loss: 0.3084856867790222
Validation loss: 1.6738207045421805

Epoch: 6| Step: 11
Training loss: 0.3032657206058502
Validation loss: 1.641917561972013

Epoch: 6| Step: 12
Training loss: 0.3688015043735504
Validation loss: 1.6932372867420156

Epoch: 6| Step: 13
Training loss: 0.41915571689605713
Validation loss: 1.68849398884722

Epoch: 260| Step: 0
Training loss: 0.33944159746170044
Validation loss: 1.6984087074956586

Epoch: 6| Step: 1
Training loss: 0.3934627175331116
Validation loss: 1.6956247155384352

Epoch: 6| Step: 2
Training loss: 0.38357794284820557
Validation loss: 1.734088800286734

Epoch: 6| Step: 3
Training loss: 0.27814534306526184
Validation loss: 1.739338469761674

Epoch: 6| Step: 4
Training loss: 0.34954220056533813
Validation loss: 1.7493000171517814

Epoch: 6| Step: 5
Training loss: 0.5263077020645142
Validation loss: 1.743580311857244

Epoch: 6| Step: 6
Training loss: 0.40854334831237793
Validation loss: 1.7351536225247126

Epoch: 6| Step: 7
Training loss: 0.5121235847473145
Validation loss: 1.726804091084388

Epoch: 6| Step: 8
Training loss: 0.36383622884750366
Validation loss: 1.7085481241185179

Epoch: 6| Step: 9
Training loss: 0.19632762670516968
Validation loss: 1.7166840209755847

Epoch: 6| Step: 10
Training loss: 0.18995198607444763
Validation loss: 1.7339183720209266

Epoch: 6| Step: 11
Training loss: 0.29032450914382935
Validation loss: 1.7025238467801003

Epoch: 6| Step: 12
Training loss: 0.23776386678218842
Validation loss: 1.7022901247906428

Epoch: 6| Step: 13
Training loss: 0.29696527123451233
Validation loss: 1.7032664501538841

Epoch: 261| Step: 0
Training loss: 0.36404892802238464
Validation loss: 1.6876305751903082

Epoch: 6| Step: 1
Training loss: 0.40199989080429077
Validation loss: 1.6819095124480545

Epoch: 6| Step: 2
Training loss: 0.2335597276687622
Validation loss: 1.6871135081014326

Epoch: 6| Step: 3
Training loss: 0.22371263802051544
Validation loss: 1.696904396498075

Epoch: 6| Step: 4
Training loss: 0.22972726821899414
Validation loss: 1.6775025603591756

Epoch: 6| Step: 5
Training loss: 0.3591906428337097
Validation loss: 1.6873539135020266

Epoch: 6| Step: 6
Training loss: 0.32695186138153076
Validation loss: 1.7169423539151427

Epoch: 6| Step: 7
Training loss: 0.23852044343948364
Validation loss: 1.691082178905446

Epoch: 6| Step: 8
Training loss: 0.24680984020233154
Validation loss: 1.7007238377806961

Epoch: 6| Step: 9
Training loss: 0.21083208918571472
Validation loss: 1.7321858175339238

Epoch: 6| Step: 10
Training loss: 0.3887747526168823
Validation loss: 1.6909910421217642

Epoch: 6| Step: 11
Training loss: 0.327990859746933
Validation loss: 1.6839623592233146

Epoch: 6| Step: 12
Training loss: 0.3392006754875183
Validation loss: 1.7073150347637873

Epoch: 6| Step: 13
Training loss: 0.30458346009254456
Validation loss: 1.6895426755310388

Epoch: 262| Step: 0
Training loss: 0.47419673204421997
Validation loss: 1.695420838171436

Epoch: 6| Step: 1
Training loss: 0.30202680826187134
Validation loss: 1.6885289043508551

Epoch: 6| Step: 2
Training loss: 0.25650036334991455
Validation loss: 1.6829894819567282

Epoch: 6| Step: 3
Training loss: 0.36925655603408813
Validation loss: 1.6488819276132891

Epoch: 6| Step: 4
Training loss: 0.19526441395282745
Validation loss: 1.662397934544471

Epoch: 6| Step: 5
Training loss: 0.3232119679450989
Validation loss: 1.6731688937833231

Epoch: 6| Step: 6
Training loss: 0.2709936499595642
Validation loss: 1.7049011440687283

Epoch: 6| Step: 7
Training loss: 0.22773799300193787
Validation loss: 1.7161858876546223

Epoch: 6| Step: 8
Training loss: 0.32881397008895874
Validation loss: 1.7305356558933054

Epoch: 6| Step: 9
Training loss: 0.4339214563369751
Validation loss: 1.747819536475725

Epoch: 6| Step: 10
Training loss: 0.2755237817764282
Validation loss: 1.7263478873878397

Epoch: 6| Step: 11
Training loss: 0.22411829233169556
Validation loss: 1.6856950201014036

Epoch: 6| Step: 12
Training loss: 0.18143770098686218
Validation loss: 1.6749640459655433

Epoch: 6| Step: 13
Training loss: 0.1989326924085617
Validation loss: 1.6489492654800415

Epoch: 263| Step: 0
Training loss: 0.3236761689186096
Validation loss: 1.6524235356238581

Epoch: 6| Step: 1
Training loss: 0.2570439279079437
Validation loss: 1.654106915638011

Epoch: 6| Step: 2
Training loss: 0.33593273162841797
Validation loss: 1.6428233013358167

Epoch: 6| Step: 3
Training loss: 0.22835077345371246
Validation loss: 1.6613201556667205

Epoch: 6| Step: 4
Training loss: 0.23883385956287384
Validation loss: 1.6495019774283133

Epoch: 6| Step: 5
Training loss: 0.13596877455711365
Validation loss: 1.6676041310833347

Epoch: 6| Step: 6
Training loss: 0.4101050794124603
Validation loss: 1.6628450744895524

Epoch: 6| Step: 7
Training loss: 0.15287429094314575
Validation loss: 1.6765595982151646

Epoch: 6| Step: 8
Training loss: 0.23067019879817963
Validation loss: 1.683351800005923

Epoch: 6| Step: 9
Training loss: 0.27704572677612305
Validation loss: 1.692747785199073

Epoch: 6| Step: 10
Training loss: 0.39995843172073364
Validation loss: 1.7198269085217548

Epoch: 6| Step: 11
Training loss: 0.26000505685806274
Validation loss: 1.725780753679173

Epoch: 6| Step: 12
Training loss: 0.2557157874107361
Validation loss: 1.7360883400004397

Epoch: 6| Step: 13
Training loss: 0.3905344605445862
Validation loss: 1.746623372518888

Epoch: 264| Step: 0
Training loss: 0.4003146290779114
Validation loss: 1.6940985238680275

Epoch: 6| Step: 1
Training loss: 0.24929922819137573
Validation loss: 1.6923013476915256

Epoch: 6| Step: 2
Training loss: 0.20442375540733337
Validation loss: 1.6960521487779514

Epoch: 6| Step: 3
Training loss: 0.2981209456920624
Validation loss: 1.6658845614361506

Epoch: 6| Step: 4
Training loss: 0.3217732310295105
Validation loss: 1.711782436217031

Epoch: 6| Step: 5
Training loss: 0.4825385808944702
Validation loss: 1.7039381464322407

Epoch: 6| Step: 6
Training loss: 0.20770946145057678
Validation loss: 1.6812454064687092

Epoch: 6| Step: 7
Training loss: 0.10297564417123795
Validation loss: 1.6863994739388908

Epoch: 6| Step: 8
Training loss: 0.24000942707061768
Validation loss: 1.6795944526631346

Epoch: 6| Step: 9
Training loss: 0.3601268529891968
Validation loss: 1.704119018329087

Epoch: 6| Step: 10
Training loss: 0.2569739818572998
Validation loss: 1.705516904912969

Epoch: 6| Step: 11
Training loss: 0.3080492317676544
Validation loss: 1.6939233169760755

Epoch: 6| Step: 12
Training loss: 0.24455958604812622
Validation loss: 1.6916952556179417

Epoch: 6| Step: 13
Training loss: 0.1432715803384781
Validation loss: 1.6808247720041583

Epoch: 265| Step: 0
Training loss: 0.3318111300468445
Validation loss: 1.6733375441643499

Epoch: 6| Step: 1
Training loss: 0.40387654304504395
Validation loss: 1.6707537584407355

Epoch: 6| Step: 2
Training loss: 0.29072511196136475
Validation loss: 1.6377075538840344

Epoch: 6| Step: 3
Training loss: 0.21852993965148926
Validation loss: 1.6311366660620576

Epoch: 6| Step: 4
Training loss: 0.43601617217063904
Validation loss: 1.6361097763943415

Epoch: 6| Step: 5
Training loss: 0.33901315927505493
Validation loss: 1.6337249951977884

Epoch: 6| Step: 6
Training loss: 0.33488258719444275
Validation loss: 1.6184843868337653

Epoch: 6| Step: 7
Training loss: 0.24753162264823914
Validation loss: 1.657063603401184

Epoch: 6| Step: 8
Training loss: 0.2016495019197464
Validation loss: 1.6292202588050597

Epoch: 6| Step: 9
Training loss: 0.2790346145629883
Validation loss: 1.6209101112939979

Epoch: 6| Step: 10
Training loss: 0.2550120949745178
Validation loss: 1.6455381019141084

Epoch: 6| Step: 11
Training loss: 0.24886882305145264
Validation loss: 1.6542857193177747

Epoch: 6| Step: 12
Training loss: 0.21344101428985596
Validation loss: 1.6561022496992541

Epoch: 6| Step: 13
Training loss: 0.26766127347946167
Validation loss: 1.6715131472515803

Epoch: 266| Step: 0
Training loss: 0.3460775911808014
Validation loss: 1.7072044367431312

Epoch: 6| Step: 1
Training loss: 0.35450509190559387
Validation loss: 1.6858789754170243

Epoch: 6| Step: 2
Training loss: 0.31920596957206726
Validation loss: 1.6699907074692428

Epoch: 6| Step: 3
Training loss: 0.140511155128479
Validation loss: 1.7040475235190442

Epoch: 6| Step: 4
Training loss: 0.2572880983352661
Validation loss: 1.7071100742586198

Epoch: 6| Step: 5
Training loss: 0.4329530894756317
Validation loss: 1.7222490310668945

Epoch: 6| Step: 6
Training loss: 0.36030152440071106
Validation loss: 1.7102482049695906

Epoch: 6| Step: 7
Training loss: 0.25289738178253174
Validation loss: 1.6695859496311476

Epoch: 6| Step: 8
Training loss: 0.24707892537117004
Validation loss: 1.636173899455737

Epoch: 6| Step: 9
Training loss: 0.18431901931762695
Validation loss: 1.6332127894124677

Epoch: 6| Step: 10
Training loss: 0.30714964866638184
Validation loss: 1.632325280097223

Epoch: 6| Step: 11
Training loss: 0.237569659948349
Validation loss: 1.6162069741115774

Epoch: 6| Step: 12
Training loss: 0.270976185798645
Validation loss: 1.623455297562384

Epoch: 6| Step: 13
Training loss: 0.4278477132320404
Validation loss: 1.5960030735179942

Epoch: 267| Step: 0
Training loss: 0.23985843360424042
Validation loss: 1.629760043595427

Epoch: 6| Step: 1
Training loss: 0.3018725514411926
Validation loss: 1.619566386745822

Epoch: 6| Step: 2
Training loss: 0.4464458227157593
Validation loss: 1.633072530069659

Epoch: 6| Step: 3
Training loss: 0.23514878749847412
Validation loss: 1.6367400923082907

Epoch: 6| Step: 4
Training loss: 0.13339465856552124
Validation loss: 1.6534442017155309

Epoch: 6| Step: 5
Training loss: 0.2276799976825714
Validation loss: 1.6688268735844602

Epoch: 6| Step: 6
Training loss: 0.207931250333786
Validation loss: 1.675511480659567

Epoch: 6| Step: 7
Training loss: 0.26083844900131226
Validation loss: 1.6768827181990429

Epoch: 6| Step: 8
Training loss: 0.22707641124725342
Validation loss: 1.6676352011260165

Epoch: 6| Step: 9
Training loss: 0.23443493247032166
Validation loss: 1.7232329653155418

Epoch: 6| Step: 10
Training loss: 0.26144886016845703
Validation loss: 1.7242480862525202

Epoch: 6| Step: 11
Training loss: 0.3579646944999695
Validation loss: 1.7283320952487249

Epoch: 6| Step: 12
Training loss: 0.1487371027469635
Validation loss: 1.7142986751371814

Epoch: 6| Step: 13
Training loss: 0.21150106191635132
Validation loss: 1.7291938463846843

Epoch: 268| Step: 0
Training loss: 0.2657697796821594
Validation loss: 1.7280052951587144

Epoch: 6| Step: 1
Training loss: 0.23813019692897797
Validation loss: 1.7180079221725464

Epoch: 6| Step: 2
Training loss: 0.226554736495018
Validation loss: 1.7083977332679174

Epoch: 6| Step: 3
Training loss: 0.2429806888103485
Validation loss: 1.7099975411609938

Epoch: 6| Step: 4
Training loss: 0.14871862530708313
Validation loss: 1.6962594498870194

Epoch: 6| Step: 5
Training loss: 0.2822405695915222
Validation loss: 1.6803117259856193

Epoch: 6| Step: 6
Training loss: 0.3434961438179016
Validation loss: 1.6736691664623957

Epoch: 6| Step: 7
Training loss: 0.28920674324035645
Validation loss: 1.6751073637316305

Epoch: 6| Step: 8
Training loss: 0.16554155945777893
Validation loss: 1.648352023093931

Epoch: 6| Step: 9
Training loss: 0.29656070470809937
Validation loss: 1.659796537891511

Epoch: 6| Step: 10
Training loss: 0.41165047883987427
Validation loss: 1.6467883753520187

Epoch: 6| Step: 11
Training loss: 0.22247149050235748
Validation loss: 1.6696003355005735

Epoch: 6| Step: 12
Training loss: 0.1885835975408554
Validation loss: 1.6432138476320493

Epoch: 6| Step: 13
Training loss: 0.1279945969581604
Validation loss: 1.6394180918252597

Epoch: 269| Step: 0
Training loss: 0.24401825666427612
Validation loss: 1.667175441659907

Epoch: 6| Step: 1
Training loss: 0.26862406730651855
Validation loss: 1.6853133619472545

Epoch: 6| Step: 2
Training loss: 0.3436312675476074
Validation loss: 1.6760732204683366

Epoch: 6| Step: 3
Training loss: 0.19487793743610382
Validation loss: 1.6838630219941497

Epoch: 6| Step: 4
Training loss: 0.2252146154642105
Validation loss: 1.6867141621087187

Epoch: 6| Step: 5
Training loss: 0.32147088646888733
Validation loss: 1.6956494046795754

Epoch: 6| Step: 6
Training loss: 0.17231379449367523
Validation loss: 1.6916689667650449

Epoch: 6| Step: 7
Training loss: 0.24481040239334106
Validation loss: 1.7022422116289857

Epoch: 6| Step: 8
Training loss: 0.2182830572128296
Validation loss: 1.6861802993282196

Epoch: 6| Step: 9
Training loss: 0.19389519095420837
Validation loss: 1.6636057746025823

Epoch: 6| Step: 10
Training loss: 0.2936003804206848
Validation loss: 1.6622695884396952

Epoch: 6| Step: 11
Training loss: 0.300309419631958
Validation loss: 1.6646159925768453

Epoch: 6| Step: 12
Training loss: 0.2337712198495865
Validation loss: 1.6554847225066154

Epoch: 6| Step: 13
Training loss: 0.3328380584716797
Validation loss: 1.642313377831572

Epoch: 270| Step: 0
Training loss: 0.20111533999443054
Validation loss: 1.6446792156465593

Epoch: 6| Step: 1
Training loss: 0.15312230587005615
Validation loss: 1.658567866971416

Epoch: 6| Step: 2
Training loss: 0.19231761991977692
Validation loss: 1.6738822152537685

Epoch: 6| Step: 3
Training loss: 0.2606278359889984
Validation loss: 1.682719704925373

Epoch: 6| Step: 4
Training loss: 0.28176453709602356
Validation loss: 1.6771841151739961

Epoch: 6| Step: 5
Training loss: 0.4216289222240448
Validation loss: 1.655661597046801

Epoch: 6| Step: 6
Training loss: 0.23564669489860535
Validation loss: 1.6691158586932766

Epoch: 6| Step: 7
Training loss: 0.2546311020851135
Validation loss: 1.6666337264481412

Epoch: 6| Step: 8
Training loss: 0.23657497763633728
Validation loss: 1.6517964870698991

Epoch: 6| Step: 9
Training loss: 0.1889132559299469
Validation loss: 1.6391822657277506

Epoch: 6| Step: 10
Training loss: 0.2920832633972168
Validation loss: 1.6174822110001759

Epoch: 6| Step: 11
Training loss: 0.35566678643226624
Validation loss: 1.6148815308847735

Epoch: 6| Step: 12
Training loss: 0.22102060914039612
Validation loss: 1.6207317895786737

Epoch: 6| Step: 13
Training loss: 0.3472321629524231
Validation loss: 1.6036908088191864

Epoch: 271| Step: 0
Training loss: 0.1958882212638855
Validation loss: 1.6065596790723904

Epoch: 6| Step: 1
Training loss: 0.14406971633434296
Validation loss: 1.6053391259203675

Epoch: 6| Step: 2
Training loss: 0.18637216091156006
Validation loss: 1.6217465695514475

Epoch: 6| Step: 3
Training loss: 0.286939799785614
Validation loss: 1.625287079042004

Epoch: 6| Step: 4
Training loss: 0.1680838167667389
Validation loss: 1.6391019962167228

Epoch: 6| Step: 5
Training loss: 0.21690241992473602
Validation loss: 1.6464651630770775

Epoch: 6| Step: 6
Training loss: 0.38123229146003723
Validation loss: 1.6349259371398597

Epoch: 6| Step: 7
Training loss: 0.24346564710140228
Validation loss: 1.6737626009089972

Epoch: 6| Step: 8
Training loss: 0.37413057684898376
Validation loss: 1.6613690007117488

Epoch: 6| Step: 9
Training loss: 0.17090481519699097
Validation loss: 1.6397388212142452

Epoch: 6| Step: 10
Training loss: 0.17051821947097778
Validation loss: 1.6461599783230854

Epoch: 6| Step: 11
Training loss: 0.3419724106788635
Validation loss: 1.6575282376299623

Epoch: 6| Step: 12
Training loss: 0.28510910272598267
Validation loss: 1.6440291289360291

Epoch: 6| Step: 13
Training loss: 0.3917410671710968
Validation loss: 1.6323114761742212

Epoch: 272| Step: 0
Training loss: 0.26983779668807983
Validation loss: 1.619759241739909

Epoch: 6| Step: 1
Training loss: 0.1843809187412262
Validation loss: 1.6185588272668983

Epoch: 6| Step: 2
Training loss: 0.18563729524612427
Validation loss: 1.5991099649860012

Epoch: 6| Step: 3
Training loss: 0.18946273624897003
Validation loss: 1.6295693766686223

Epoch: 6| Step: 4
Training loss: 0.20547589659690857
Validation loss: 1.6380920948520783

Epoch: 6| Step: 5
Training loss: 0.28576377034187317
Validation loss: 1.6264687661201722

Epoch: 6| Step: 6
Training loss: 0.2506493926048279
Validation loss: 1.6286642000239382

Epoch: 6| Step: 7
Training loss: 0.16063067317008972
Validation loss: 1.625599063852782

Epoch: 6| Step: 8
Training loss: 0.2808626890182495
Validation loss: 1.607686197885903

Epoch: 6| Step: 9
Training loss: 0.24729406833648682
Validation loss: 1.626494566599528

Epoch: 6| Step: 10
Training loss: 0.3145240545272827
Validation loss: 1.626007532560697

Epoch: 6| Step: 11
Training loss: 0.21713486313819885
Validation loss: 1.6036371011887827

Epoch: 6| Step: 12
Training loss: 0.2359025776386261
Validation loss: 1.641394748482653

Epoch: 6| Step: 13
Training loss: 0.14678698778152466
Validation loss: 1.6101103764708324

Epoch: 273| Step: 0
Training loss: 0.18888351321220398
Validation loss: 1.6211136643604567

Epoch: 6| Step: 1
Training loss: 0.25001075863838196
Validation loss: 1.6395431103244904

Epoch: 6| Step: 2
Training loss: 0.1816747486591339
Validation loss: 1.658569638447095

Epoch: 6| Step: 3
Training loss: 0.13618457317352295
Validation loss: 1.634222097294305

Epoch: 6| Step: 4
Training loss: 0.21356308460235596
Validation loss: 1.6617926679631716

Epoch: 6| Step: 5
Training loss: 0.29687830805778503
Validation loss: 1.6307027596299366

Epoch: 6| Step: 6
Training loss: 0.22508060932159424
Validation loss: 1.6389103012700235

Epoch: 6| Step: 7
Training loss: 0.18910351395606995
Validation loss: 1.6268892262571601

Epoch: 6| Step: 8
Training loss: 0.3320716321468353
Validation loss: 1.6371503222373225

Epoch: 6| Step: 9
Training loss: 0.21600529551506042
Validation loss: 1.6311808786084574

Epoch: 6| Step: 10
Training loss: 0.14831188321113586
Validation loss: 1.6250819262637888

Epoch: 6| Step: 11
Training loss: 0.34005069732666016
Validation loss: 1.5939878853418494

Epoch: 6| Step: 12
Training loss: 0.33400610089302063
Validation loss: 1.6283644117334837

Epoch: 6| Step: 13
Training loss: 0.26135721802711487
Validation loss: 1.671119568168476

Epoch: 274| Step: 0
Training loss: 0.23291316628456116
Validation loss: 1.6457693858813214

Epoch: 6| Step: 1
Training loss: 0.21613949537277222
Validation loss: 1.6821614696133522

Epoch: 6| Step: 2
Training loss: 0.25021660327911377
Validation loss: 1.710735724818322

Epoch: 6| Step: 3
Training loss: 0.35390952229499817
Validation loss: 1.7212413741696266

Epoch: 6| Step: 4
Training loss: 0.27510809898376465
Validation loss: 1.7239619685757546

Epoch: 6| Step: 5
Training loss: 0.16626249253749847
Validation loss: 1.7018495362292054

Epoch: 6| Step: 6
Training loss: 0.4296347498893738
Validation loss: 1.6964776067323581

Epoch: 6| Step: 7
Training loss: 0.30393800139427185
Validation loss: 1.7296672726190219

Epoch: 6| Step: 8
Training loss: 0.22418862581253052
Validation loss: 1.6837827133876022

Epoch: 6| Step: 9
Training loss: 0.28616708517074585
Validation loss: 1.6705929784364597

Epoch: 6| Step: 10
Training loss: 0.23663604259490967
Validation loss: 1.6715667497727178

Epoch: 6| Step: 11
Training loss: 0.14549031853675842
Validation loss: 1.6550771139001335

Epoch: 6| Step: 12
Training loss: 0.22662588953971863
Validation loss: 1.6316291516827

Epoch: 6| Step: 13
Training loss: 0.11744771897792816
Validation loss: 1.6421028003897717

Epoch: 275| Step: 0
Training loss: 0.16356408596038818
Validation loss: 1.6029828812486382

Epoch: 6| Step: 1
Training loss: 0.1681860387325287
Validation loss: 1.601647650041888

Epoch: 6| Step: 2
Training loss: 0.37590527534484863
Validation loss: 1.603429098283091

Epoch: 6| Step: 3
Training loss: 0.3610305190086365
Validation loss: 1.607330902930229

Epoch: 6| Step: 4
Training loss: 0.21200112998485565
Validation loss: 1.5932287041858961

Epoch: 6| Step: 5
Training loss: 0.3811073303222656
Validation loss: 1.6116291528107018

Epoch: 6| Step: 6
Training loss: 0.1376846581697464
Validation loss: 1.5995785574759207

Epoch: 6| Step: 7
Training loss: 0.19493085145950317
Validation loss: 1.628776732311454

Epoch: 6| Step: 8
Training loss: 0.3572896718978882
Validation loss: 1.6389552944449968

Epoch: 6| Step: 9
Training loss: 0.15321388840675354
Validation loss: 1.6457839883783811

Epoch: 6| Step: 10
Training loss: 0.24139238893985748
Validation loss: 1.6535778276381954

Epoch: 6| Step: 11
Training loss: 0.18890883028507233
Validation loss: 1.6709760453111382

Epoch: 6| Step: 12
Training loss: 0.1255989670753479
Validation loss: 1.6800257852000575

Epoch: 6| Step: 13
Training loss: 0.15584582090377808
Validation loss: 1.6548241697331911

Epoch: 276| Step: 0
Training loss: 0.3026760220527649
Validation loss: 1.6837232164157334

Epoch: 6| Step: 1
Training loss: 0.17918431758880615
Validation loss: 1.6561882700971378

Epoch: 6| Step: 2
Training loss: 0.2911629378795624
Validation loss: 1.6571064738817112

Epoch: 6| Step: 3
Training loss: 0.23078405857086182
Validation loss: 1.6420838627763974

Epoch: 6| Step: 4
Training loss: 0.18625235557556152
Validation loss: 1.652583424763013

Epoch: 6| Step: 5
Training loss: 0.2272559404373169
Validation loss: 1.6386547896169847

Epoch: 6| Step: 6
Training loss: 0.2614651024341583
Validation loss: 1.6280620956933627

Epoch: 6| Step: 7
Training loss: 0.2575611174106598
Validation loss: 1.6039215454491236

Epoch: 6| Step: 8
Training loss: 0.18806615471839905
Validation loss: 1.6044057415377708

Epoch: 6| Step: 9
Training loss: 0.32306361198425293
Validation loss: 1.608578089744814

Epoch: 6| Step: 10
Training loss: 0.15818911790847778
Validation loss: 1.6194348514720958

Epoch: 6| Step: 11
Training loss: 0.2526010274887085
Validation loss: 1.6258758370594313

Epoch: 6| Step: 12
Training loss: 0.26672786474227905
Validation loss: 1.6452172904886224

Epoch: 6| Step: 13
Training loss: 0.13111387193202972
Validation loss: 1.6135441500653502

Epoch: 277| Step: 0
Training loss: 0.342441588640213
Validation loss: 1.6472689695255731

Epoch: 6| Step: 1
Training loss: 0.22249475121498108
Validation loss: 1.6394847823727516

Epoch: 6| Step: 2
Training loss: 0.2118617296218872
Validation loss: 1.6275174463948896

Epoch: 6| Step: 3
Training loss: 0.12570708990097046
Validation loss: 1.6417901977416007

Epoch: 6| Step: 4
Training loss: 0.16293826699256897
Validation loss: 1.6469806830088298

Epoch: 6| Step: 5
Training loss: 0.22181010246276855
Validation loss: 1.649084214882184

Epoch: 6| Step: 6
Training loss: 0.20316605269908905
Validation loss: 1.628193489966854

Epoch: 6| Step: 7
Training loss: 0.28923487663269043
Validation loss: 1.618760613984959

Epoch: 6| Step: 8
Training loss: 0.2916796803474426
Validation loss: 1.5735730663422616

Epoch: 6| Step: 9
Training loss: 0.24617190659046173
Validation loss: 1.5733261185307656

Epoch: 6| Step: 10
Training loss: 0.19038119912147522
Validation loss: 1.5895845005589146

Epoch: 6| Step: 11
Training loss: 0.18644888699054718
Validation loss: 1.6029083139152938

Epoch: 6| Step: 12
Training loss: 0.32709619402885437
Validation loss: 1.607274204172114

Epoch: 6| Step: 13
Training loss: 0.18495804071426392
Validation loss: 1.6180828912283785

Epoch: 278| Step: 0
Training loss: 0.20545369386672974
Validation loss: 1.5998744515962497

Epoch: 6| Step: 1
Training loss: 0.33323734998703003
Validation loss: 1.6264928540875834

Epoch: 6| Step: 2
Training loss: 0.349364697933197
Validation loss: 1.6342386789219354

Epoch: 6| Step: 3
Training loss: 0.2746792435646057
Validation loss: 1.6583240634651595

Epoch: 6| Step: 4
Training loss: 0.1599273383617401
Validation loss: 1.6288279500058902

Epoch: 6| Step: 5
Training loss: 0.11935483664274216
Validation loss: 1.6548014853590278

Epoch: 6| Step: 6
Training loss: 0.3912878632545471
Validation loss: 1.6527160175385014

Epoch: 6| Step: 7
Training loss: 0.22457322478294373
Validation loss: 1.6810305426197667

Epoch: 6| Step: 8
Training loss: 0.2347557246685028
Validation loss: 1.6761784886801114

Epoch: 6| Step: 9
Training loss: 0.20313149690628052
Validation loss: 1.6936389964113954

Epoch: 6| Step: 10
Training loss: 0.21678908169269562
Validation loss: 1.6829570467754076

Epoch: 6| Step: 11
Training loss: 0.1584704965353012
Validation loss: 1.6557468868071032

Epoch: 6| Step: 12
Training loss: 0.20649221539497375
Validation loss: 1.63691549019147

Epoch: 6| Step: 13
Training loss: 0.1650310903787613
Validation loss: 1.6137780156186832

Epoch: 279| Step: 0
Training loss: 0.20716488361358643
Validation loss: 1.6380304598039197

Epoch: 6| Step: 1
Training loss: 0.1582939624786377
Validation loss: 1.617812284859278

Epoch: 6| Step: 2
Training loss: 0.31171488761901855
Validation loss: 1.6160360831086353

Epoch: 6| Step: 3
Training loss: 0.24456416070461273
Validation loss: 1.626754513350866

Epoch: 6| Step: 4
Training loss: 0.16501764953136444
Validation loss: 1.6294303876097485

Epoch: 6| Step: 5
Training loss: 0.2611263394355774
Validation loss: 1.6421744926001436

Epoch: 6| Step: 6
Training loss: 0.32679271697998047
Validation loss: 1.6383828988639257

Epoch: 6| Step: 7
Training loss: 0.20678550004959106
Validation loss: 1.659528648981484

Epoch: 6| Step: 8
Training loss: 0.1537255346775055
Validation loss: 1.6501815549788936

Epoch: 6| Step: 9
Training loss: 0.24935439229011536
Validation loss: 1.6342131732612528

Epoch: 6| Step: 10
Training loss: 0.25435447692871094
Validation loss: 1.610386247275978

Epoch: 6| Step: 11
Training loss: 0.22086460888385773
Validation loss: 1.6302694056623726

Epoch: 6| Step: 12
Training loss: 0.14036336541175842
Validation loss: 1.6421493227763841

Epoch: 6| Step: 13
Training loss: 0.3238323926925659
Validation loss: 1.6437908257207563

Epoch: 280| Step: 0
Training loss: 0.19466644525527954
Validation loss: 1.657604496966126

Epoch: 6| Step: 1
Training loss: 0.2540203332901001
Validation loss: 1.6552044486486783

Epoch: 6| Step: 2
Training loss: 0.22894535958766937
Validation loss: 1.674752991686585

Epoch: 6| Step: 3
Training loss: 0.15429513156414032
Validation loss: 1.6744844452027352

Epoch: 6| Step: 4
Training loss: 0.2655176520347595
Validation loss: 1.670636917955132

Epoch: 6| Step: 5
Training loss: 0.15450672805309296
Validation loss: 1.6612111765851256

Epoch: 6| Step: 6
Training loss: 0.2760941982269287
Validation loss: 1.6738102051519579

Epoch: 6| Step: 7
Training loss: 0.2845739722251892
Validation loss: 1.6478593913457726

Epoch: 6| Step: 8
Training loss: 0.23227089643478394
Validation loss: 1.6463364247352845

Epoch: 6| Step: 9
Training loss: 0.23555481433868408
Validation loss: 1.6513568534645984

Epoch: 6| Step: 10
Training loss: 0.16954705119132996
Validation loss: 1.6427976367294148

Epoch: 6| Step: 11
Training loss: 0.2308516800403595
Validation loss: 1.6259214993446105

Epoch: 6| Step: 12
Training loss: 0.28929248452186584
Validation loss: 1.6372264046822824

Epoch: 6| Step: 13
Training loss: 0.37663424015045166
Validation loss: 1.6255367596944172

Epoch: 281| Step: 0
Training loss: 0.21074533462524414
Validation loss: 1.591845275253378

Epoch: 6| Step: 1
Training loss: 0.25773465633392334
Validation loss: 1.6014505765771354

Epoch: 6| Step: 2
Training loss: 0.17037205398082733
Validation loss: 1.594622096707744

Epoch: 6| Step: 3
Training loss: 0.17917057871818542
Validation loss: 1.5927312527933428

Epoch: 6| Step: 4
Training loss: 0.1518162190914154
Validation loss: 1.5796846856353104

Epoch: 6| Step: 5
Training loss: 0.24062703549861908
Validation loss: 1.5709174922717515

Epoch: 6| Step: 6
Training loss: 0.26354414224624634
Validation loss: 1.579387914749884

Epoch: 6| Step: 7
Training loss: 0.27290669083595276
Validation loss: 1.5830485513133388

Epoch: 6| Step: 8
Training loss: 0.2604958117008209
Validation loss: 1.6160101403472245

Epoch: 6| Step: 9
Training loss: 0.21633441746234894
Validation loss: 1.6000246386374197

Epoch: 6| Step: 10
Training loss: 0.13585658371448517
Validation loss: 1.6205741179886686

Epoch: 6| Step: 11
Training loss: 0.31087854504585266
Validation loss: 1.6248124299510833

Epoch: 6| Step: 12
Training loss: 0.19813749194145203
Validation loss: 1.6196486116737447

Epoch: 6| Step: 13
Training loss: 0.13695847988128662
Validation loss: 1.612054713310734

Epoch: 282| Step: 0
Training loss: 0.15879325568675995
Validation loss: 1.621742320317094

Epoch: 6| Step: 1
Training loss: 0.12258325517177582
Validation loss: 1.642960129245635

Epoch: 6| Step: 2
Training loss: 0.24693073332309723
Validation loss: 1.6451986528212024

Epoch: 6| Step: 3
Training loss: 0.32403993606567383
Validation loss: 1.6254459299067014

Epoch: 6| Step: 4
Training loss: 0.25586700439453125
Validation loss: 1.6512216009119505

Epoch: 6| Step: 5
Training loss: 0.1396690458059311
Validation loss: 1.6598332415344894

Epoch: 6| Step: 6
Training loss: 0.24658964574337006
Validation loss: 1.6408697969170027

Epoch: 6| Step: 7
Training loss: 0.1634465456008911
Validation loss: 1.606808534232519

Epoch: 6| Step: 8
Training loss: 0.15375559031963348
Validation loss: 1.6233832515696043

Epoch: 6| Step: 9
Training loss: 0.21064700186252594
Validation loss: 1.6206981776863016

Epoch: 6| Step: 10
Training loss: 0.17489883303642273
Validation loss: 1.6166607949041552

Epoch: 6| Step: 11
Training loss: 0.2772623896598816
Validation loss: 1.630898493592457

Epoch: 6| Step: 12
Training loss: 0.2833217978477478
Validation loss: 1.6141580150973411

Epoch: 6| Step: 13
Training loss: 0.21618209779262543
Validation loss: 1.5962516441140124

Epoch: 283| Step: 0
Training loss: 0.25792229175567627
Validation loss: 1.612847217949488

Epoch: 6| Step: 1
Training loss: 0.22925671935081482
Validation loss: 1.6081044379101004

Epoch: 6| Step: 2
Training loss: 0.3042970597743988
Validation loss: 1.631243166103158

Epoch: 6| Step: 3
Training loss: 0.2455756813287735
Validation loss: 1.6438574329499276

Epoch: 6| Step: 4
Training loss: 0.22549951076507568
Validation loss: 1.6573219055770545

Epoch: 6| Step: 5
Training loss: 0.26601696014404297
Validation loss: 1.6758265995210218

Epoch: 6| Step: 6
Training loss: 0.17894409596920013
Validation loss: 1.6757896574594642

Epoch: 6| Step: 7
Training loss: 0.31343209743499756
Validation loss: 1.644511091452773

Epoch: 6| Step: 8
Training loss: 0.20650169253349304
Validation loss: 1.6733484550188946

Epoch: 6| Step: 9
Training loss: 0.25870129466056824
Validation loss: 1.6329555562747422

Epoch: 6| Step: 10
Training loss: 0.23775620758533478
Validation loss: 1.6319357284935572

Epoch: 6| Step: 11
Training loss: 0.23581662774085999
Validation loss: 1.6322855346946306

Epoch: 6| Step: 12
Training loss: 0.23524582386016846
Validation loss: 1.6427966625459733

Epoch: 6| Step: 13
Training loss: 0.22575408220291138
Validation loss: 1.620932021448689

Epoch: 284| Step: 0
Training loss: 0.26928621530532837
Validation loss: 1.6291590506030666

Epoch: 6| Step: 1
Training loss: 0.25370025634765625
Validation loss: 1.6158610646442702

Epoch: 6| Step: 2
Training loss: 0.3410591185092926
Validation loss: 1.6117688218752544

Epoch: 6| Step: 3
Training loss: 0.15829184651374817
Validation loss: 1.6141289203397688

Epoch: 6| Step: 4
Training loss: 0.19750475883483887
Validation loss: 1.5914610662767965

Epoch: 6| Step: 5
Training loss: 0.41276270151138306
Validation loss: 1.608107268169362

Epoch: 6| Step: 6
Training loss: 0.18475979566574097
Validation loss: 1.6160219292486868

Epoch: 6| Step: 7
Training loss: 0.20512697100639343
Validation loss: 1.6404977395970335

Epoch: 6| Step: 8
Training loss: 0.15902996063232422
Validation loss: 1.679940164730113

Epoch: 6| Step: 9
Training loss: 0.2740035057067871
Validation loss: 1.667884595932499

Epoch: 6| Step: 10
Training loss: 0.26599061489105225
Validation loss: 1.6890350695579284

Epoch: 6| Step: 11
Training loss: 0.23939228057861328
Validation loss: 1.6687739023598291

Epoch: 6| Step: 12
Training loss: 0.20691782236099243
Validation loss: 1.6885448425046858

Epoch: 6| Step: 13
Training loss: 0.25001370906829834
Validation loss: 1.6693595775993921

Epoch: 285| Step: 0
Training loss: 0.1776934564113617
Validation loss: 1.6364348588451263

Epoch: 6| Step: 1
Training loss: 0.1989857703447342
Validation loss: 1.6147156030901018

Epoch: 6| Step: 2
Training loss: 0.2933209240436554
Validation loss: 1.6201648917249454

Epoch: 6| Step: 3
Training loss: 0.17327037453651428
Validation loss: 1.6271836603841474

Epoch: 6| Step: 4
Training loss: 0.2873779535293579
Validation loss: 1.6445110997846049

Epoch: 6| Step: 5
Training loss: 0.33337101340293884
Validation loss: 1.644335190455119

Epoch: 6| Step: 6
Training loss: 0.20111462473869324
Validation loss: 1.6214158996458976

Epoch: 6| Step: 7
Training loss: 0.14862769842147827
Validation loss: 1.617414823142431

Epoch: 6| Step: 8
Training loss: 0.1598905771970749
Validation loss: 1.636390536062179

Epoch: 6| Step: 9
Training loss: 0.14968188107013702
Validation loss: 1.6160592443199568

Epoch: 6| Step: 10
Training loss: 0.14738519489765167
Validation loss: 1.6372037869627758

Epoch: 6| Step: 11
Training loss: 0.2383347451686859
Validation loss: 1.625874685984786

Epoch: 6| Step: 12
Training loss: 0.13834504783153534
Validation loss: 1.6232253659156062

Epoch: 6| Step: 13
Training loss: 0.18236126005649567
Validation loss: 1.629856473656111

Epoch: 286| Step: 0
Training loss: 0.340778648853302
Validation loss: 1.6362817953991633

Epoch: 6| Step: 1
Training loss: 0.23391911387443542
Validation loss: 1.6275115782214749

Epoch: 6| Step: 2
Training loss: 0.29364877939224243
Validation loss: 1.6342606711131271

Epoch: 6| Step: 3
Training loss: 0.15355032682418823
Validation loss: 1.6256287238931144

Epoch: 6| Step: 4
Training loss: 0.2005225270986557
Validation loss: 1.6322977465967978

Epoch: 6| Step: 5
Training loss: 0.15354672074317932
Validation loss: 1.6525042749220324

Epoch: 6| Step: 6
Training loss: 0.22730980813503265
Validation loss: 1.633344006794755

Epoch: 6| Step: 7
Training loss: 0.2794065773487091
Validation loss: 1.6591401420613772

Epoch: 6| Step: 8
Training loss: 0.22060777246952057
Validation loss: 1.6698997225812686

Epoch: 6| Step: 9
Training loss: 0.1679043173789978
Validation loss: 1.656587928854009

Epoch: 6| Step: 10
Training loss: 0.1881655752658844
Validation loss: 1.6848136596782233

Epoch: 6| Step: 11
Training loss: 0.16998526453971863
Validation loss: 1.6742888983859812

Epoch: 6| Step: 12
Training loss: 0.25178325176239014
Validation loss: 1.6342138821078884

Epoch: 6| Step: 13
Training loss: 0.16318157315254211
Validation loss: 1.6145482024838846

Epoch: 287| Step: 0
Training loss: 0.234768345952034
Validation loss: 1.6099367180178243

Epoch: 6| Step: 1
Training loss: 0.1441788375377655
Validation loss: 1.596805085418045

Epoch: 6| Step: 2
Training loss: 0.20949728786945343
Validation loss: 1.6358152217762445

Epoch: 6| Step: 3
Training loss: 0.2913917303085327
Validation loss: 1.6191949408541444

Epoch: 6| Step: 4
Training loss: 0.2206776738166809
Validation loss: 1.647970240603211

Epoch: 6| Step: 5
Training loss: 0.2213532030582428
Validation loss: 1.6046275349073513

Epoch: 6| Step: 6
Training loss: 0.24870651960372925
Validation loss: 1.6305045812360701

Epoch: 6| Step: 7
Training loss: 0.17581568658351898
Validation loss: 1.6213806559962611

Epoch: 6| Step: 8
Training loss: 0.21129822731018066
Validation loss: 1.6190176881769651

Epoch: 6| Step: 9
Training loss: 0.3095812499523163
Validation loss: 1.6160047310654835

Epoch: 6| Step: 10
Training loss: 0.1278449296951294
Validation loss: 1.6027865858488186

Epoch: 6| Step: 11
Training loss: 0.23757727444171906
Validation loss: 1.5975866369021836

Epoch: 6| Step: 12
Training loss: 0.14765658974647522
Validation loss: 1.5932182996503768

Epoch: 6| Step: 13
Training loss: 0.14016148447990417
Validation loss: 1.597960292652089

Epoch: 288| Step: 0
Training loss: 0.2357698231935501
Validation loss: 1.6059267610631964

Epoch: 6| Step: 1
Training loss: 0.25456345081329346
Validation loss: 1.6208068696401452

Epoch: 6| Step: 2
Training loss: 0.16863909363746643
Validation loss: 1.6278942195318078

Epoch: 6| Step: 3
Training loss: 0.2608460485935211
Validation loss: 1.609946749543631

Epoch: 6| Step: 4
Training loss: 0.16758060455322266
Validation loss: 1.6069664878229941

Epoch: 6| Step: 5
Training loss: 0.20384030044078827
Validation loss: 1.5963109577855756

Epoch: 6| Step: 6
Training loss: 0.19186550378799438
Validation loss: 1.5898427873529413

Epoch: 6| Step: 7
Training loss: 0.17504480481147766
Validation loss: 1.5959489525005381

Epoch: 6| Step: 8
Training loss: 0.1489993929862976
Validation loss: 1.6070145240394018

Epoch: 6| Step: 9
Training loss: 0.22972601652145386
Validation loss: 1.5764294708928754

Epoch: 6| Step: 10
Training loss: 0.1813982129096985
Validation loss: 1.6136560337517851

Epoch: 6| Step: 11
Training loss: 0.09583714604377747
Validation loss: 1.6329652276090396

Epoch: 6| Step: 12
Training loss: 0.27972090244293213
Validation loss: 1.681296694663263

Epoch: 6| Step: 13
Training loss: 0.1588091254234314
Validation loss: 1.6650472046226583

Epoch: 289| Step: 0
Training loss: 0.23117023706436157
Validation loss: 1.6770924957849647

Epoch: 6| Step: 1
Training loss: 0.2369295358657837
Validation loss: 1.676285025894001

Epoch: 6| Step: 2
Training loss: 0.20350942015647888
Validation loss: 1.6540850413742887

Epoch: 6| Step: 3
Training loss: 0.08311686664819717
Validation loss: 1.6225063762357157

Epoch: 6| Step: 4
Training loss: 0.12888722121715546
Validation loss: 1.6093807399913829

Epoch: 6| Step: 5
Training loss: 0.2235584259033203
Validation loss: 1.6015517724457609

Epoch: 6| Step: 6
Training loss: 0.2510182857513428
Validation loss: 1.6088518391373337

Epoch: 6| Step: 7
Training loss: 0.17928290367126465
Validation loss: 1.6051264475750666

Epoch: 6| Step: 8
Training loss: 0.21479728817939758
Validation loss: 1.5945657542956773

Epoch: 6| Step: 9
Training loss: 0.20245081186294556
Validation loss: 1.5974465903415476

Epoch: 6| Step: 10
Training loss: 0.2303660362958908
Validation loss: 1.616983829006072

Epoch: 6| Step: 11
Training loss: 0.2663244307041168
Validation loss: 1.6136361642550396

Epoch: 6| Step: 12
Training loss: 0.17119523882865906
Validation loss: 1.6327740671814128

Epoch: 6| Step: 13
Training loss: 0.23874275386333466
Validation loss: 1.6345477142641622

Epoch: 290| Step: 0
Training loss: 0.3772497773170471
Validation loss: 1.6094061892519715

Epoch: 6| Step: 1
Training loss: 0.13247919082641602
Validation loss: 1.6073357507746706

Epoch: 6| Step: 2
Training loss: 0.12021957337856293
Validation loss: 1.612463323018884

Epoch: 6| Step: 3
Training loss: 0.12486378848552704
Validation loss: 1.593751497166131

Epoch: 6| Step: 4
Training loss: 0.28164970874786377
Validation loss: 1.5853336857211204

Epoch: 6| Step: 5
Training loss: 0.19111788272857666
Validation loss: 1.5923014847181176

Epoch: 6| Step: 6
Training loss: 0.11471870541572571
Validation loss: 1.5653729349054315

Epoch: 6| Step: 7
Training loss: 0.24481499195098877
Validation loss: 1.564736061198737

Epoch: 6| Step: 8
Training loss: 0.26108163595199585
Validation loss: 1.5363758289685814

Epoch: 6| Step: 9
Training loss: 0.30188417434692383
Validation loss: 1.5419460881140925

Epoch: 6| Step: 10
Training loss: 0.2340034395456314
Validation loss: 1.546790305004325

Epoch: 6| Step: 11
Training loss: 0.28469300270080566
Validation loss: 1.5686186680229761

Epoch: 6| Step: 12
Training loss: 0.21384499967098236
Validation loss: 1.5446122410476848

Epoch: 6| Step: 13
Training loss: 0.165113165974617
Validation loss: 1.5868744875795098

Epoch: 291| Step: 0
Training loss: 0.20359688997268677
Validation loss: 1.6089608348825926

Epoch: 6| Step: 1
Training loss: 0.27949634194374084
Validation loss: 1.6464133211361465

Epoch: 6| Step: 2
Training loss: 0.31641942262649536
Validation loss: 1.655004789752345

Epoch: 6| Step: 3
Training loss: 0.3281760811805725
Validation loss: 1.6697979460480392

Epoch: 6| Step: 4
Training loss: 0.2529269754886627
Validation loss: 1.6907257290296658

Epoch: 6| Step: 5
Training loss: 0.2025032639503479
Validation loss: 1.6820831068100468

Epoch: 6| Step: 6
Training loss: 0.30784329771995544
Validation loss: 1.659015610653867

Epoch: 6| Step: 7
Training loss: 0.17981022596359253
Validation loss: 1.6447519704859743

Epoch: 6| Step: 8
Training loss: 0.2696470320224762
Validation loss: 1.6449650218409877

Epoch: 6| Step: 9
Training loss: 0.16582328081130981
Validation loss: 1.6348084698441208

Epoch: 6| Step: 10
Training loss: 0.13528016209602356
Validation loss: 1.631998703043948

Epoch: 6| Step: 11
Training loss: 0.0634535625576973
Validation loss: 1.6140565103100193

Epoch: 6| Step: 12
Training loss: 0.22708876430988312
Validation loss: 1.617844964868279

Epoch: 6| Step: 13
Training loss: 0.17997588217258453
Validation loss: 1.6186650747893958

Epoch: 292| Step: 0
Training loss: 0.16193918883800507
Validation loss: 1.6238229326022569

Epoch: 6| Step: 1
Training loss: 0.17416507005691528
Validation loss: 1.607569517627839

Epoch: 6| Step: 2
Training loss: 0.1646450161933899
Validation loss: 1.5967740038389802

Epoch: 6| Step: 3
Training loss: 0.16531416773796082
Validation loss: 1.6164781662725634

Epoch: 6| Step: 4
Training loss: 0.21409247815608978
Validation loss: 1.644017743807967

Epoch: 6| Step: 5
Training loss: 0.3401499092578888
Validation loss: 1.6465830213280135

Epoch: 6| Step: 6
Training loss: 0.2071458250284195
Validation loss: 1.6547044810428415

Epoch: 6| Step: 7
Training loss: 0.29613161087036133
Validation loss: 1.6363684592708465

Epoch: 6| Step: 8
Training loss: 0.18371903896331787
Validation loss: 1.6385389028056976

Epoch: 6| Step: 9
Training loss: 0.22323986887931824
Validation loss: 1.6612680150616554

Epoch: 6| Step: 10
Training loss: 0.2519996166229248
Validation loss: 1.6610602294245074

Epoch: 6| Step: 11
Training loss: 0.24479718506336212
Validation loss: 1.6364673529901812

Epoch: 6| Step: 12
Training loss: 0.24310535192489624
Validation loss: 1.6241925172908331

Epoch: 6| Step: 13
Training loss: 0.1768328845500946
Validation loss: 1.6370327011231454

Epoch: 293| Step: 0
Training loss: 0.27046850323677063
Validation loss: 1.635853304657885

Epoch: 6| Step: 1
Training loss: 0.190538227558136
Validation loss: 1.6794075350607596

Epoch: 6| Step: 2
Training loss: 0.2110407054424286
Validation loss: 1.664044209705886

Epoch: 6| Step: 3
Training loss: 0.2871095836162567
Validation loss: 1.6804697513580322

Epoch: 6| Step: 4
Training loss: 0.19434043765068054
Validation loss: 1.6446293675771324

Epoch: 6| Step: 5
Training loss: 0.24515360593795776
Validation loss: 1.66332733502952

Epoch: 6| Step: 6
Training loss: 0.16046655178070068
Validation loss: 1.653182207256235

Epoch: 6| Step: 7
Training loss: 0.3202664852142334
Validation loss: 1.6638813377708517

Epoch: 6| Step: 8
Training loss: 0.1528220772743225
Validation loss: 1.6412957957995835

Epoch: 6| Step: 9
Training loss: 0.2103196531534195
Validation loss: 1.6475595581916072

Epoch: 6| Step: 10
Training loss: 0.3535972237586975
Validation loss: 1.630233254483951

Epoch: 6| Step: 11
Training loss: 0.20487022399902344
Validation loss: 1.6499045959082983

Epoch: 6| Step: 12
Training loss: 0.10632768273353577
Validation loss: 1.6166486778566915

Epoch: 6| Step: 13
Training loss: 0.11391317844390869
Validation loss: 1.6122362511132353

Epoch: 294| Step: 0
Training loss: 0.16798801720142365
Validation loss: 1.6438874890727382

Epoch: 6| Step: 1
Training loss: 0.2410963773727417
Validation loss: 1.6488495757502895

Epoch: 6| Step: 2
Training loss: 0.1455250382423401
Validation loss: 1.639326799300409

Epoch: 6| Step: 3
Training loss: 0.10174219310283661
Validation loss: 1.6584125744399203

Epoch: 6| Step: 4
Training loss: 0.23646089434623718
Validation loss: 1.6767736724627915

Epoch: 6| Step: 5
Training loss: 0.15128740668296814
Validation loss: 1.6501611291721303

Epoch: 6| Step: 6
Training loss: 0.14638271927833557
Validation loss: 1.6727285628677697

Epoch: 6| Step: 7
Training loss: 0.280859112739563
Validation loss: 1.690092537992744

Epoch: 6| Step: 8
Training loss: 0.21517330408096313
Validation loss: 1.669716037729735

Epoch: 6| Step: 9
Training loss: 0.249800905585289
Validation loss: 1.670298913473724

Epoch: 6| Step: 10
Training loss: 0.17738980054855347
Validation loss: 1.655206859752696

Epoch: 6| Step: 11
Training loss: 0.1237771287560463
Validation loss: 1.6522049698778378

Epoch: 6| Step: 12
Training loss: 0.13803790509700775
Validation loss: 1.6092476101331814

Epoch: 6| Step: 13
Training loss: 0.18821950256824493
Validation loss: 1.6185781404536257

Epoch: 295| Step: 0
Training loss: 0.09465837478637695
Validation loss: 1.6585095864470287

Epoch: 6| Step: 1
Training loss: 0.1418459713459015
Validation loss: 1.6248769119221678

Epoch: 6| Step: 2
Training loss: 0.16215413808822632
Validation loss: 1.6605805453433786

Epoch: 6| Step: 3
Training loss: 0.2518930435180664
Validation loss: 1.6228003886438185

Epoch: 6| Step: 4
Training loss: 0.30902087688446045
Validation loss: 1.6191010866113889

Epoch: 6| Step: 5
Training loss: 0.2842268943786621
Validation loss: 1.6575034228704308

Epoch: 6| Step: 6
Training loss: 0.24812576174736023
Validation loss: 1.6528446879438174

Epoch: 6| Step: 7
Training loss: 0.2832326591014862
Validation loss: 1.6437920447318786

Epoch: 6| Step: 8
Training loss: 0.16800090670585632
Validation loss: 1.6468148551961428

Epoch: 6| Step: 9
Training loss: 0.12522552907466888
Validation loss: 1.6386721550777394

Epoch: 6| Step: 10
Training loss: 0.23547282814979553
Validation loss: 1.6372334200848815

Epoch: 6| Step: 11
Training loss: 0.25553083419799805
Validation loss: 1.6089872173083726

Epoch: 6| Step: 12
Training loss: 0.13950049877166748
Validation loss: 1.606419704293692

Epoch: 6| Step: 13
Training loss: 0.1365378499031067
Validation loss: 1.610325397983674

Epoch: 296| Step: 0
Training loss: 0.18369466066360474
Validation loss: 1.6272859675909883

Epoch: 6| Step: 1
Training loss: 0.24182769656181335
Validation loss: 1.6222204726229432

Epoch: 6| Step: 2
Training loss: 0.16288137435913086
Validation loss: 1.6161755977138397

Epoch: 6| Step: 3
Training loss: 0.1248088926076889
Validation loss: 1.6357144783901911

Epoch: 6| Step: 4
Training loss: 0.2131916582584381
Validation loss: 1.6466328661928895

Epoch: 6| Step: 5
Training loss: 0.20663180947303772
Validation loss: 1.6607214712327527

Epoch: 6| Step: 6
Training loss: 0.17269304394721985
Validation loss: 1.628827807723835

Epoch: 6| Step: 7
Training loss: 0.35327786207199097
Validation loss: 1.6409808051201604

Epoch: 6| Step: 8
Training loss: 0.2189602553844452
Validation loss: 1.6347075482850433

Epoch: 6| Step: 9
Training loss: 0.12335216253995895
Validation loss: 1.6082397917265534

Epoch: 6| Step: 10
Training loss: 0.1221918836236
Validation loss: 1.6154724968376981

Epoch: 6| Step: 11
Training loss: 0.15580430626869202
Validation loss: 1.600689467563424

Epoch: 6| Step: 12
Training loss: 0.197420135140419
Validation loss: 1.609713836382794

Epoch: 6| Step: 13
Training loss: 0.23629000782966614
Validation loss: 1.6173216348053308

Epoch: 297| Step: 0
Training loss: 0.24021536111831665
Validation loss: 1.6081428297104374

Epoch: 6| Step: 1
Training loss: 0.12195423245429993
Validation loss: 1.601635955995129

Epoch: 6| Step: 2
Training loss: 0.13069969415664673
Validation loss: 1.6280216888714862

Epoch: 6| Step: 3
Training loss: 0.13942602276802063
Validation loss: 1.6717482779615669

Epoch: 6| Step: 4
Training loss: 0.1750480830669403
Validation loss: 1.669088690511642

Epoch: 6| Step: 5
Training loss: 0.17781788110733032
Validation loss: 1.6493793905422252

Epoch: 6| Step: 6
Training loss: 0.18212789297103882
Validation loss: 1.6712476066363755

Epoch: 6| Step: 7
Training loss: 0.25567227602005005
Validation loss: 1.649562894657094

Epoch: 6| Step: 8
Training loss: 0.27398258447647095
Validation loss: 1.636933042157081

Epoch: 6| Step: 9
Training loss: 0.21953310072422028
Validation loss: 1.6329072470306067

Epoch: 6| Step: 10
Training loss: 0.26754558086395264
Validation loss: 1.609343349292714

Epoch: 6| Step: 11
Training loss: 0.21660207211971283
Validation loss: 1.6029806803631526

Epoch: 6| Step: 12
Training loss: 0.23413841426372528
Validation loss: 1.5831852638593285

Epoch: 6| Step: 13
Training loss: 0.2648690342903137
Validation loss: 1.563164553334636

Epoch: 298| Step: 0
Training loss: 0.1310233771800995
Validation loss: 1.5708738411626508

Epoch: 6| Step: 1
Training loss: 0.18138398230075836
Validation loss: 1.5955132976655038

Epoch: 6| Step: 2
Training loss: 0.26329749822616577
Validation loss: 1.568138272531571

Epoch: 6| Step: 3
Training loss: 0.22366248071193695
Validation loss: 1.5687504237697971

Epoch: 6| Step: 4
Training loss: 0.20587271451950073
Validation loss: 1.617882941358833

Epoch: 6| Step: 5
Training loss: 0.20342519879341125
Validation loss: 1.6239834267606017

Epoch: 6| Step: 6
Training loss: 0.17615346610546112
Validation loss: 1.6177257209695795

Epoch: 6| Step: 7
Training loss: 0.20660147070884705
Validation loss: 1.6232205924167429

Epoch: 6| Step: 8
Training loss: 0.1795724332332611
Validation loss: 1.617392901451357

Epoch: 6| Step: 9
Training loss: 0.1527569591999054
Validation loss: 1.6053585570345643

Epoch: 6| Step: 10
Training loss: 0.23046502470970154
Validation loss: 1.6294826192240561

Epoch: 6| Step: 11
Training loss: 0.1969555914402008
Validation loss: 1.6084543069203694

Epoch: 6| Step: 12
Training loss: 0.1354520320892334
Validation loss: 1.626073504006991

Epoch: 6| Step: 13
Training loss: 0.2421872317790985
Validation loss: 1.6150716966198337

Epoch: 299| Step: 0
Training loss: 0.15191954374313354
Validation loss: 1.622603431824715

Epoch: 6| Step: 1
Training loss: 0.3097691833972931
Validation loss: 1.6024596319403699

Epoch: 6| Step: 2
Training loss: 0.19258345663547516
Validation loss: 1.6165207060434486

Epoch: 6| Step: 3
Training loss: 0.2760462164878845
Validation loss: 1.6186938708828342

Epoch: 6| Step: 4
Training loss: 0.23118874430656433
Validation loss: 1.5966052803941952

Epoch: 6| Step: 5
Training loss: 0.17384997010231018
Validation loss: 1.6020947861415085

Epoch: 6| Step: 6
Training loss: 0.1276545524597168
Validation loss: 1.56974478883128

Epoch: 6| Step: 7
Training loss: 0.09398263692855835
Validation loss: 1.5797196818936257

Epoch: 6| Step: 8
Training loss: 0.16010136902332306
Validation loss: 1.5774274372285413

Epoch: 6| Step: 9
Training loss: 0.19321858882904053
Validation loss: 1.5603719680540022

Epoch: 6| Step: 10
Training loss: 0.2220383882522583
Validation loss: 1.5378932491425545

Epoch: 6| Step: 11
Training loss: 0.15741948783397675
Validation loss: 1.560391931123631

Epoch: 6| Step: 12
Training loss: 0.2150951325893402
Validation loss: 1.5602641259470293

Epoch: 6| Step: 13
Training loss: 0.11950453370809555
Validation loss: 1.5821728360268377

Epoch: 300| Step: 0
Training loss: 0.11458736658096313
Validation loss: 1.5593839768440492

Epoch: 6| Step: 1
Training loss: 0.11864610016345978
Validation loss: 1.5986959344597274

Epoch: 6| Step: 2
Training loss: 0.25889143347740173
Validation loss: 1.6126827527117986

Epoch: 6| Step: 3
Training loss: 0.2714100182056427
Validation loss: 1.610673830073367

Epoch: 6| Step: 4
Training loss: 0.22245611250400543
Validation loss: 1.6107769025269376

Epoch: 6| Step: 5
Training loss: 0.20301270484924316
Validation loss: 1.5893272892121346

Epoch: 6| Step: 6
Training loss: 0.19852036237716675
Validation loss: 1.6237206164226736

Epoch: 6| Step: 7
Training loss: 0.23460064828395844
Validation loss: 1.5794685130478234

Epoch: 6| Step: 8
Training loss: 0.20081114768981934
Validation loss: 1.5969558582510999

Epoch: 6| Step: 9
Training loss: 0.12293055653572083
Validation loss: 1.5825319738798245

Epoch: 6| Step: 10
Training loss: 0.23914268612861633
Validation loss: 1.5864100058873494

Epoch: 6| Step: 11
Training loss: 0.2039186954498291
Validation loss: 1.5926043166909167

Epoch: 6| Step: 12
Training loss: 0.14567555487155914
Validation loss: 1.5902900926528438

Epoch: 6| Step: 13
Training loss: 0.23380643129348755
Validation loss: 1.5861048544606855

Testing loss: 2.1108042081197103
