Epoch: 1| Step: 0
Training loss: 4.327972412109375
Validation loss: 5.228337857031053

Epoch: 6| Step: 1
Training loss: 6.566108703613281
Validation loss: 5.211243906328755

Epoch: 6| Step: 2
Training loss: 4.130328178405762
Validation loss: 5.196371483546431

Epoch: 6| Step: 3
Training loss: 5.2649030685424805
Validation loss: 5.18093672619071

Epoch: 6| Step: 4
Training loss: 5.257451057434082
Validation loss: 5.163509830351798

Epoch: 6| Step: 5
Training loss: 6.182441711425781
Validation loss: 5.143763988248764

Epoch: 6| Step: 6
Training loss: 3.6558194160461426
Validation loss: 5.121449014191986

Epoch: 6| Step: 7
Training loss: 5.164307594299316
Validation loss: 5.0954969057472805

Epoch: 6| Step: 8
Training loss: 4.433560371398926
Validation loss: 5.065421965814406

Epoch: 6| Step: 9
Training loss: 5.542454719543457
Validation loss: 5.03137485442623

Epoch: 6| Step: 10
Training loss: 5.2618255615234375
Validation loss: 4.994042094035815

Epoch: 6| Step: 11
Training loss: 4.29026985168457
Validation loss: 4.952588306960239

Epoch: 6| Step: 12
Training loss: 3.467142105102539
Validation loss: 4.907409893569126

Epoch: 6| Step: 13
Training loss: 4.771092891693115
Validation loss: 4.857189762976862

Epoch: 2| Step: 0
Training loss: 4.21451997756958
Validation loss: 4.804237847687096

Epoch: 6| Step: 1
Training loss: 4.712612152099609
Validation loss: 4.749407132466634

Epoch: 6| Step: 2
Training loss: 5.809094429016113
Validation loss: 4.690391694345782

Epoch: 6| Step: 3
Training loss: 5.461947917938232
Validation loss: 4.629443199403824

Epoch: 6| Step: 4
Training loss: 5.711041450500488
Validation loss: 4.564913057511853

Epoch: 6| Step: 5
Training loss: 3.5676932334899902
Validation loss: 4.497715816702894

Epoch: 6| Step: 6
Training loss: 4.8921003341674805
Validation loss: 4.431308489973827

Epoch: 6| Step: 7
Training loss: 2.4491748809814453
Validation loss: 4.3679119028070925

Epoch: 6| Step: 8
Training loss: 3.5513267517089844
Validation loss: 4.312429223009335

Epoch: 6| Step: 9
Training loss: 4.027456283569336
Validation loss: 4.257202789347659

Epoch: 6| Step: 10
Training loss: 3.219512939453125
Validation loss: 4.20270235051391

Epoch: 6| Step: 11
Training loss: 4.379152297973633
Validation loss: 4.14330925480012

Epoch: 6| Step: 12
Training loss: 3.273838996887207
Validation loss: 4.079797785769227

Epoch: 6| Step: 13
Training loss: 3.673119068145752
Validation loss: 4.021687066683206

Epoch: 3| Step: 0
Training loss: 2.43471360206604
Validation loss: 3.9757554095278502

Epoch: 6| Step: 1
Training loss: 4.276498794555664
Validation loss: 3.93573518465924

Epoch: 6| Step: 2
Training loss: 3.43088436126709
Validation loss: 3.896036858199745

Epoch: 6| Step: 3
Training loss: 3.1089789867401123
Validation loss: 3.860779287994549

Epoch: 6| Step: 4
Training loss: 4.43195915222168
Validation loss: 3.8273855742587837

Epoch: 6| Step: 5
Training loss: 4.550678253173828
Validation loss: 3.7982419639505367

Epoch: 6| Step: 6
Training loss: 4.489884376525879
Validation loss: 3.770131875109929

Epoch: 6| Step: 7
Training loss: 2.584780693054199
Validation loss: 3.7523705113318657

Epoch: 6| Step: 8
Training loss: 3.145298957824707
Validation loss: 3.749835173288981

Epoch: 6| Step: 9
Training loss: 4.499676704406738
Validation loss: 3.719739601176272

Epoch: 6| Step: 10
Training loss: 4.323969841003418
Validation loss: 3.706570412523003

Epoch: 6| Step: 11
Training loss: 2.612744092941284
Validation loss: 3.699003150386195

Epoch: 6| Step: 12
Training loss: 3.9573006629943848
Validation loss: 3.6938868645698792

Epoch: 6| Step: 13
Training loss: 3.498075246810913
Validation loss: 3.6859204589679675

Epoch: 4| Step: 0
Training loss: 3.1092445850372314
Validation loss: 3.678443072944559

Epoch: 6| Step: 1
Training loss: 3.606111526489258
Validation loss: 3.6660863404632895

Epoch: 6| Step: 2
Training loss: 2.498776912689209
Validation loss: 3.6529782869482554

Epoch: 6| Step: 3
Training loss: 4.139472007751465
Validation loss: 3.6423913381432973

Epoch: 6| Step: 4
Training loss: 4.610634803771973
Validation loss: 3.633640848180299

Epoch: 6| Step: 5
Training loss: 4.130418300628662
Validation loss: 3.628006996647004

Epoch: 6| Step: 6
Training loss: 3.510944128036499
Validation loss: 3.6175353629614717

Epoch: 6| Step: 7
Training loss: 3.5735392570495605
Validation loss: 3.6063883330232356

Epoch: 6| Step: 8
Training loss: 2.685041666030884
Validation loss: 3.5962849252967426

Epoch: 6| Step: 9
Training loss: 3.713726043701172
Validation loss: 3.5848245877091602

Epoch: 6| Step: 10
Training loss: 3.8086366653442383
Validation loss: 3.5785137607205297

Epoch: 6| Step: 11
Training loss: 3.372838020324707
Validation loss: 3.5681196746005805

Epoch: 6| Step: 12
Training loss: 3.412884473800659
Validation loss: 3.5675295373444915

Epoch: 6| Step: 13
Training loss: 3.091608762741089
Validation loss: 3.5660583844748874

Epoch: 5| Step: 0
Training loss: 3.202770471572876
Validation loss: 3.6044698325536584

Epoch: 6| Step: 1
Training loss: 2.3354074954986572
Validation loss: 3.542846777105844

Epoch: 6| Step: 2
Training loss: 3.410835027694702
Validation loss: 3.5343023807771745

Epoch: 6| Step: 3
Training loss: 2.6130025386810303
Validation loss: 3.532722109107561

Epoch: 6| Step: 4
Training loss: 3.0847692489624023
Validation loss: 3.529177091454947

Epoch: 6| Step: 5
Training loss: 4.368836402893066
Validation loss: 3.5240449443940194

Epoch: 6| Step: 6
Training loss: 4.272347450256348
Validation loss: 3.519828704095656

Epoch: 6| Step: 7
Training loss: 3.3910024166107178
Validation loss: 3.5129240379538587

Epoch: 6| Step: 8
Training loss: 3.5453779697418213
Validation loss: 3.5067988057290354

Epoch: 6| Step: 9
Training loss: 4.115935325622559
Validation loss: 3.5012447654560046

Epoch: 6| Step: 10
Training loss: 3.8092539310455322
Validation loss: 3.4944196465194866

Epoch: 6| Step: 11
Training loss: 3.364368438720703
Validation loss: 3.484409298948062

Epoch: 6| Step: 12
Training loss: 3.3640565872192383
Validation loss: 3.4781032172582482

Epoch: 6| Step: 13
Training loss: 3.3409206867218018
Validation loss: 3.4695553830874863

Epoch: 6| Step: 0
Training loss: 3.1245789527893066
Validation loss: 3.4594400467411166

Epoch: 6| Step: 1
Training loss: 2.175534248352051
Validation loss: 3.4432691707405993

Epoch: 6| Step: 2
Training loss: 3.069056510925293
Validation loss: 3.435616836752943

Epoch: 6| Step: 3
Training loss: 4.777074337005615
Validation loss: 3.4286454236635597

Epoch: 6| Step: 4
Training loss: 3.204768180847168
Validation loss: 3.417082966014903

Epoch: 6| Step: 5
Training loss: 2.925992012023926
Validation loss: 3.415666385363507

Epoch: 6| Step: 6
Training loss: 2.827897071838379
Validation loss: 3.4099296523678686

Epoch: 6| Step: 7
Training loss: 3.533928394317627
Validation loss: 3.426962139785931

Epoch: 6| Step: 8
Training loss: 3.581144332885742
Validation loss: 3.410426955069265

Epoch: 6| Step: 9
Training loss: 4.31033182144165
Validation loss: 3.3758965640939693

Epoch: 6| Step: 10
Training loss: 4.066558361053467
Validation loss: 3.366388805450932

Epoch: 6| Step: 11
Training loss: 2.923797607421875
Validation loss: 3.3641061782836914

Epoch: 6| Step: 12
Training loss: 3.1054186820983887
Validation loss: 3.3616169960268083

Epoch: 6| Step: 13
Training loss: 3.3000917434692383
Validation loss: 3.356958676409978

Epoch: 7| Step: 0
Training loss: 2.738816738128662
Validation loss: 3.3515385761055896

Epoch: 6| Step: 1
Training loss: 2.7107574939727783
Validation loss: 3.344474882207891

Epoch: 6| Step: 2
Training loss: 3.2726006507873535
Validation loss: 3.3420439945754183

Epoch: 6| Step: 3
Training loss: 3.15523624420166
Validation loss: 3.331724159179195

Epoch: 6| Step: 4
Training loss: 3.122443675994873
Validation loss: 3.3128051655266875

Epoch: 6| Step: 5
Training loss: 2.9857892990112305
Validation loss: 3.29794676585864

Epoch: 6| Step: 6
Training loss: 3.208977222442627
Validation loss: 3.290326561979068

Epoch: 6| Step: 7
Training loss: 3.817676544189453
Validation loss: 3.289242152244814

Epoch: 6| Step: 8
Training loss: 3.6905441284179688
Validation loss: 3.2767111229640182

Epoch: 6| Step: 9
Training loss: 2.7664122581481934
Validation loss: 3.2675925352240123

Epoch: 6| Step: 10
Training loss: 3.612600803375244
Validation loss: 3.273636720513785

Epoch: 6| Step: 11
Training loss: 2.8872263431549072
Validation loss: 3.258772906436715

Epoch: 6| Step: 12
Training loss: 4.195323944091797
Validation loss: 3.255619446436564

Epoch: 6| Step: 13
Training loss: 3.840607166290283
Validation loss: 3.2470363596434235

Epoch: 8| Step: 0
Training loss: 2.5314090251922607
Validation loss: 3.2393580816125356

Epoch: 6| Step: 1
Training loss: 3.2022180557250977
Validation loss: 3.236024174638974

Epoch: 6| Step: 2
Training loss: 2.413159132003784
Validation loss: 3.2381268009062736

Epoch: 6| Step: 3
Training loss: 3.8398098945617676
Validation loss: 3.2297639231528006

Epoch: 6| Step: 4
Training loss: 3.6038601398468018
Validation loss: 3.226892150858397

Epoch: 6| Step: 5
Training loss: 3.341179370880127
Validation loss: 3.220361235321209

Epoch: 6| Step: 6
Training loss: 3.369896411895752
Validation loss: 3.252034858990741

Epoch: 6| Step: 7
Training loss: 3.1573848724365234
Validation loss: 3.209337406260993

Epoch: 6| Step: 8
Training loss: 3.264281749725342
Validation loss: 3.2094194709613757

Epoch: 6| Step: 9
Training loss: 4.130699157714844
Validation loss: 3.215244985395862

Epoch: 6| Step: 10
Training loss: 2.612171173095703
Validation loss: 3.215459146807271

Epoch: 6| Step: 11
Training loss: 2.7573277950286865
Validation loss: 3.217032863247779

Epoch: 6| Step: 12
Training loss: 3.825432062149048
Validation loss: 3.214189067963631

Epoch: 6| Step: 13
Training loss: 2.745380163192749
Validation loss: 3.2006304238432195

Epoch: 9| Step: 0
Training loss: 2.6272614002227783
Validation loss: 3.1897954633159022

Epoch: 6| Step: 1
Training loss: 2.5543854236602783
Validation loss: 3.1810762882232666

Epoch: 6| Step: 2
Training loss: 2.858656406402588
Validation loss: 3.1797294155243905

Epoch: 6| Step: 3
Training loss: 3.7650585174560547
Validation loss: 3.173953551118092

Epoch: 6| Step: 4
Training loss: 3.064236640930176
Validation loss: 3.1735346266018447

Epoch: 6| Step: 5
Training loss: 3.482719898223877
Validation loss: 3.1732633165133897

Epoch: 6| Step: 6
Training loss: 2.8963332176208496
Validation loss: 3.1728280872427006

Epoch: 6| Step: 7
Training loss: 2.90725040435791
Validation loss: 3.166768261181411

Epoch: 6| Step: 8
Training loss: 3.513728141784668
Validation loss: 3.161207047841882

Epoch: 6| Step: 9
Training loss: 3.1104938983917236
Validation loss: 3.155631883170015

Epoch: 6| Step: 10
Training loss: 2.9922709465026855
Validation loss: 3.1480228336908485

Epoch: 6| Step: 11
Training loss: 3.0485973358154297
Validation loss: 3.1483748805138374

Epoch: 6| Step: 12
Training loss: 4.130858898162842
Validation loss: 3.1454224227577128

Epoch: 6| Step: 13
Training loss: 3.56500506401062
Validation loss: 3.138953875469905

Epoch: 10| Step: 0
Training loss: 3.209125280380249
Validation loss: 3.141246780272453

Epoch: 6| Step: 1
Training loss: 3.624056816101074
Validation loss: 3.14062927615258

Epoch: 6| Step: 2
Training loss: 2.5625901222229004
Validation loss: 3.137138566663188

Epoch: 6| Step: 3
Training loss: 3.2392446994781494
Validation loss: 3.1368009505733365

Epoch: 6| Step: 4
Training loss: 2.7522506713867188
Validation loss: 3.1263155321921072

Epoch: 6| Step: 5
Training loss: 3.040705919265747
Validation loss: 3.151962367437219

Epoch: 6| Step: 6
Training loss: 4.175537109375
Validation loss: 3.117497774862474

Epoch: 6| Step: 7
Training loss: 2.9468789100646973
Validation loss: 3.1162619385668027

Epoch: 6| Step: 8
Training loss: 2.934185266494751
Validation loss: 3.1181411794436875

Epoch: 6| Step: 9
Training loss: 2.9073548316955566
Validation loss: 3.11737734271634

Epoch: 6| Step: 10
Training loss: 3.09255313873291
Validation loss: 3.122186586421023

Epoch: 6| Step: 11
Training loss: 3.6854195594787598
Validation loss: 3.1226208158718642

Epoch: 6| Step: 12
Training loss: 2.6314878463745117
Validation loss: 3.114327125651862

Epoch: 6| Step: 13
Training loss: 3.118098735809326
Validation loss: 3.104211679068945

Epoch: 11| Step: 0
Training loss: 3.0969505310058594
Validation loss: 3.108711652858283

Epoch: 6| Step: 1
Training loss: 3.447312831878662
Validation loss: 3.101884149735974

Epoch: 6| Step: 2
Training loss: 3.540769577026367
Validation loss: 3.1025603766082437

Epoch: 6| Step: 3
Training loss: 3.02010440826416
Validation loss: 3.0972028445172053

Epoch: 6| Step: 4
Training loss: 3.621182918548584
Validation loss: 3.094860084595219

Epoch: 6| Step: 5
Training loss: 3.252957820892334
Validation loss: 3.0890765856671076

Epoch: 6| Step: 6
Training loss: 2.151726007461548
Validation loss: 3.084296393138106

Epoch: 6| Step: 7
Training loss: 3.4155592918395996
Validation loss: 3.0828863369521273

Epoch: 6| Step: 8
Training loss: 2.691422700881958
Validation loss: 3.0813349267487884

Epoch: 6| Step: 9
Training loss: 3.045651435852051
Validation loss: 3.0817144993812806

Epoch: 6| Step: 10
Training loss: 2.9014439582824707
Validation loss: 3.076235194360056

Epoch: 6| Step: 11
Training loss: 3.7320499420166016
Validation loss: 3.073783779657015

Epoch: 6| Step: 12
Training loss: 2.1229019165039062
Validation loss: 3.0745194445374193

Epoch: 6| Step: 13
Training loss: 3.9610989093780518
Validation loss: 3.075400411441762

Epoch: 12| Step: 0
Training loss: 3.2832088470458984
Validation loss: 3.076170536779588

Epoch: 6| Step: 1
Training loss: 3.7389976978302
Validation loss: 3.0719138858138875

Epoch: 6| Step: 2
Training loss: 3.111995220184326
Validation loss: 3.0754618567805134

Epoch: 6| Step: 3
Training loss: 3.434504508972168
Validation loss: 3.079813890559699

Epoch: 6| Step: 4
Training loss: 2.121640682220459
Validation loss: 3.0721786124731905

Epoch: 6| Step: 5
Training loss: 3.152158260345459
Validation loss: 3.064652704423474

Epoch: 6| Step: 6
Training loss: 2.9373321533203125
Validation loss: 3.057234292389244

Epoch: 6| Step: 7
Training loss: 4.4076337814331055
Validation loss: 3.0529012577508086

Epoch: 6| Step: 8
Training loss: 2.6128621101379395
Validation loss: 3.0558367057513167

Epoch: 6| Step: 9
Training loss: 2.6072394847869873
Validation loss: 3.0557815336411998

Epoch: 6| Step: 10
Training loss: 2.567788600921631
Validation loss: 3.0454364438210764

Epoch: 6| Step: 11
Training loss: 3.194803237915039
Validation loss: 3.040582956806306

Epoch: 6| Step: 12
Training loss: 2.782193183898926
Validation loss: 3.034094956613356

Epoch: 6| Step: 13
Training loss: 3.7308545112609863
Validation loss: 3.0349617414577033

Epoch: 13| Step: 0
Training loss: 3.2608768939971924
Validation loss: 3.045242812043877

Epoch: 6| Step: 1
Training loss: 2.8418164253234863
Validation loss: 3.0534520354322208

Epoch: 6| Step: 2
Training loss: 2.930178642272949
Validation loss: 3.0408285099972963

Epoch: 6| Step: 3
Training loss: 1.9138141870498657
Validation loss: 3.0166078741832445

Epoch: 6| Step: 4
Training loss: 3.4818477630615234
Validation loss: 3.0506492968528502

Epoch: 6| Step: 5
Training loss: 2.533416509628296
Validation loss: 3.106874442869617

Epoch: 6| Step: 6
Training loss: 3.759101629257202
Validation loss: 3.237912301094301

Epoch: 6| Step: 7
Training loss: 4.299387454986572
Validation loss: 3.131186544254262

Epoch: 6| Step: 8
Training loss: 2.6699366569519043
Validation loss: 3.005201885777135

Epoch: 6| Step: 9
Training loss: 3.765275001525879
Validation loss: 3.041112628034366

Epoch: 6| Step: 10
Training loss: 2.2920684814453125
Validation loss: 3.116269829452679

Epoch: 6| Step: 11
Training loss: 3.8978641033172607
Validation loss: 3.2343100373462965

Epoch: 6| Step: 12
Training loss: 2.672884464263916
Validation loss: 3.191029869100099

Epoch: 6| Step: 13
Training loss: 3.6290016174316406
Validation loss: 3.1837903607276177

Epoch: 14| Step: 0
Training loss: 3.559074878692627
Validation loss: 3.1723624403758715

Epoch: 6| Step: 1
Training loss: 3.3717703819274902
Validation loss: 3.1471954750758346

Epoch: 6| Step: 2
Training loss: 2.91448974609375
Validation loss: 3.1136950472349763

Epoch: 6| Step: 3
Training loss: 2.549731731414795
Validation loss: 3.0951807011840162

Epoch: 6| Step: 4
Training loss: 3.1652894020080566
Validation loss: 3.0913074785663235

Epoch: 6| Step: 5
Training loss: 2.9501280784606934
Validation loss: 3.0964771521988737

Epoch: 6| Step: 6
Training loss: 2.312880754470825
Validation loss: 3.1032560666402182

Epoch: 6| Step: 7
Training loss: 2.9192380905151367
Validation loss: 3.1316387268804733

Epoch: 6| Step: 8
Training loss: 3.2053046226501465
Validation loss: 3.1418452801242953

Epoch: 6| Step: 9
Training loss: 2.843822956085205
Validation loss: 3.1151076029705744

Epoch: 6| Step: 10
Training loss: 2.8736467361450195
Validation loss: 3.0885881864896385

Epoch: 6| Step: 11
Training loss: 3.799623727798462
Validation loss: 3.0591879019173245

Epoch: 6| Step: 12
Training loss: 3.582918167114258
Validation loss: 3.0351121066718973

Epoch: 6| Step: 13
Training loss: 4.174773216247559
Validation loss: 3.0045607628360873

Epoch: 15| Step: 0
Training loss: 2.7002272605895996
Validation loss: 2.9949548834113666

Epoch: 6| Step: 1
Training loss: 2.506302833557129
Validation loss: 3.015216668446859

Epoch: 6| Step: 2
Training loss: 2.879486560821533
Validation loss: 2.990201388635943

Epoch: 6| Step: 3
Training loss: 2.9307374954223633
Validation loss: 2.9994621430673907

Epoch: 6| Step: 4
Training loss: 2.7438793182373047
Validation loss: 2.9751790928584274

Epoch: 6| Step: 5
Training loss: 3.6228885650634766
Validation loss: 2.959864734321512

Epoch: 6| Step: 6
Training loss: 4.021215438842773
Validation loss: 2.958177463982695

Epoch: 6| Step: 7
Training loss: 3.294801712036133
Validation loss: 2.9598807340027182

Epoch: 6| Step: 8
Training loss: 2.6322498321533203
Validation loss: 2.966361099673856

Epoch: 6| Step: 9
Training loss: 3.77315616607666
Validation loss: 2.9858093723174064

Epoch: 6| Step: 10
Training loss: 2.384695529937744
Validation loss: 2.976561220743323

Epoch: 6| Step: 11
Training loss: 2.712688446044922
Validation loss: 2.96830314974631

Epoch: 6| Step: 12
Training loss: 3.31058931350708
Validation loss: 2.9564073983059136

Epoch: 6| Step: 13
Training loss: 3.0567445755004883
Validation loss: 2.942985729504657

Epoch: 16| Step: 0
Training loss: 3.2056002616882324
Validation loss: 2.937799776754072

Epoch: 6| Step: 1
Training loss: 3.2280445098876953
Validation loss: 2.9359112452435236

Epoch: 6| Step: 2
Training loss: 3.1743931770324707
Validation loss: 2.9345401076860327

Epoch: 6| Step: 3
Training loss: 2.3869946002960205
Validation loss: 2.9370428182745494

Epoch: 6| Step: 4
Training loss: 3.8443145751953125
Validation loss: 2.934485484195012

Epoch: 6| Step: 5
Training loss: 3.255054235458374
Validation loss: 2.934875842063658

Epoch: 6| Step: 6
Training loss: 3.5586323738098145
Validation loss: 2.936171270185901

Epoch: 6| Step: 7
Training loss: 3.4220168590545654
Validation loss: 2.942950612755232

Epoch: 6| Step: 8
Training loss: 2.6165518760681152
Validation loss: 2.92731967536352

Epoch: 6| Step: 9
Training loss: 3.2422423362731934
Validation loss: 2.9279391816867295

Epoch: 6| Step: 10
Training loss: 2.506716012954712
Validation loss: 2.9215931277121268

Epoch: 6| Step: 11
Training loss: 2.2709450721740723
Validation loss: 2.9196495292007283

Epoch: 6| Step: 12
Training loss: 2.229910135269165
Validation loss: 2.9186520473931425

Epoch: 6| Step: 13
Training loss: 3.3824453353881836
Validation loss: 2.9144820628627652

Epoch: 17| Step: 0
Training loss: 2.4323205947875977
Validation loss: 2.917755619172127

Epoch: 6| Step: 1
Training loss: 2.5873379707336426
Validation loss: 2.91480524821948

Epoch: 6| Step: 2
Training loss: 2.531953811645508
Validation loss: 2.91561371280301

Epoch: 6| Step: 3
Training loss: 3.550616502761841
Validation loss: 2.9153220935534407

Epoch: 6| Step: 4
Training loss: 2.728630542755127
Validation loss: 2.9123672311024

Epoch: 6| Step: 5
Training loss: 3.3104610443115234
Validation loss: 2.9130923671107136

Epoch: 6| Step: 6
Training loss: 2.9225525856018066
Validation loss: 2.90859644387358

Epoch: 6| Step: 7
Training loss: 4.359204292297363
Validation loss: 2.9061359205553607

Epoch: 6| Step: 8
Training loss: 3.258014440536499
Validation loss: 2.9014253359968945

Epoch: 6| Step: 9
Training loss: 2.68756103515625
Validation loss: 2.900478309200656

Epoch: 6| Step: 10
Training loss: 2.461232900619507
Validation loss: 2.9019504644537486

Epoch: 6| Step: 11
Training loss: 3.1256582736968994
Validation loss: 2.902153081791375

Epoch: 6| Step: 12
Training loss: 2.8858790397644043
Validation loss: 2.9116186018913024

Epoch: 6| Step: 13
Training loss: 3.3070013523101807
Validation loss: 2.9111298976405973

Epoch: 18| Step: 0
Training loss: 2.707099437713623
Validation loss: 2.9136594239101616

Epoch: 6| Step: 1
Training loss: 2.828951120376587
Validation loss: 2.9161203830472884

Epoch: 6| Step: 2
Training loss: 2.554851770401001
Validation loss: 2.906202498302665

Epoch: 6| Step: 3
Training loss: 2.650533676147461
Validation loss: 2.9057456011413247

Epoch: 6| Step: 4
Training loss: 3.3231945037841797
Validation loss: 2.901115022679811

Epoch: 6| Step: 5
Training loss: 2.855912208557129
Validation loss: 2.896800515472248

Epoch: 6| Step: 6
Training loss: 2.721207857131958
Validation loss: 2.8927419621457338

Epoch: 6| Step: 7
Training loss: 2.7148122787475586
Validation loss: 2.88923490688365

Epoch: 6| Step: 8
Training loss: 2.9593119621276855
Validation loss: 2.8912948998071815

Epoch: 6| Step: 9
Training loss: 3.5197224617004395
Validation loss: 2.891240116088621

Epoch: 6| Step: 10
Training loss: 3.051468849182129
Validation loss: 2.891419477360223

Epoch: 6| Step: 11
Training loss: 2.7373180389404297
Validation loss: 2.8910583603766655

Epoch: 6| Step: 12
Training loss: 4.063273906707764
Validation loss: 2.887031214211577

Epoch: 6| Step: 13
Training loss: 3.1973912715911865
Validation loss: 2.8883408679757068

Epoch: 19| Step: 0
Training loss: 2.555600643157959
Validation loss: 2.887085332665392

Epoch: 6| Step: 1
Training loss: 3.027564287185669
Validation loss: 2.8931989387799333

Epoch: 6| Step: 2
Training loss: 3.3112730979919434
Validation loss: 2.8953554040642193

Epoch: 6| Step: 3
Training loss: 2.2981810569763184
Validation loss: 2.894056697045603

Epoch: 6| Step: 4
Training loss: 3.173243522644043
Validation loss: 2.8915254839005007

Epoch: 6| Step: 5
Training loss: 2.4665708541870117
Validation loss: 2.8992162622431272

Epoch: 6| Step: 6
Training loss: 3.616568088531494
Validation loss: 2.8858560054532942

Epoch: 6| Step: 7
Training loss: 3.0123655796051025
Validation loss: 2.8907165194070465

Epoch: 6| Step: 8
Training loss: 2.7268309593200684
Validation loss: 2.8874469008497012

Epoch: 6| Step: 9
Training loss: 3.4154434204101562
Validation loss: 2.8756214136718423

Epoch: 6| Step: 10
Training loss: 3.373563289642334
Validation loss: 2.8715922883761826

Epoch: 6| Step: 11
Training loss: 2.73252010345459
Validation loss: 2.86687066478114

Epoch: 6| Step: 12
Training loss: 2.702554941177368
Validation loss: 2.8659288421753915

Epoch: 6| Step: 13
Training loss: 3.2391514778137207
Validation loss: 2.863907024424563

Epoch: 20| Step: 0
Training loss: 3.7663121223449707
Validation loss: 2.86991306530532

Epoch: 6| Step: 1
Training loss: 3.860645294189453
Validation loss: 2.8656206900073635

Epoch: 6| Step: 2
Training loss: 2.329317331314087
Validation loss: 2.8588214612776235

Epoch: 6| Step: 3
Training loss: 2.285316228866577
Validation loss: 2.8537851123399633

Epoch: 6| Step: 4
Training loss: 2.4266562461853027
Validation loss: 2.8466621291252876

Epoch: 6| Step: 5
Training loss: 2.111713409423828
Validation loss: 2.8434959047584125

Epoch: 6| Step: 6
Training loss: 4.060650825500488
Validation loss: 2.8582287578172583

Epoch: 6| Step: 7
Training loss: 2.425901412963867
Validation loss: 2.865501001317014

Epoch: 6| Step: 8
Training loss: 3.1488471031188965
Validation loss: 2.8687789106881745

Epoch: 6| Step: 9
Training loss: 2.455185651779175
Validation loss: 2.8553483588721162

Epoch: 6| Step: 10
Training loss: 3.5250654220581055
Validation loss: 2.8457042376200357

Epoch: 6| Step: 11
Training loss: 4.079643249511719
Validation loss: 2.840731236242479

Epoch: 6| Step: 12
Training loss: 2.637749195098877
Validation loss: 2.838932732100128

Epoch: 6| Step: 13
Training loss: 1.59921395778656
Validation loss: 2.847541985973235

Epoch: 21| Step: 0
Training loss: 2.9043047428131104
Validation loss: 2.8715136410087667

Epoch: 6| Step: 1
Training loss: 2.5335898399353027
Validation loss: 2.8809587724747194

Epoch: 6| Step: 2
Training loss: 2.4964756965637207
Validation loss: 2.885478506806076

Epoch: 6| Step: 3
Training loss: 2.9828100204467773
Validation loss: 2.882338193155104

Epoch: 6| Step: 4
Training loss: 2.7397942543029785
Validation loss: 2.865511727589433

Epoch: 6| Step: 5
Training loss: 2.575915813446045
Validation loss: 2.8557160157029347

Epoch: 6| Step: 6
Training loss: 2.9623563289642334
Validation loss: 2.8515050180496706

Epoch: 6| Step: 7
Training loss: 2.9525365829467773
Validation loss: 2.8451912274924656

Epoch: 6| Step: 8
Training loss: 3.5183753967285156
Validation loss: 2.836261467267108

Epoch: 6| Step: 9
Training loss: 3.393653392791748
Validation loss: 2.8372879925594536

Epoch: 6| Step: 10
Training loss: 2.8388772010803223
Validation loss: 2.8485117573891916

Epoch: 6| Step: 11
Training loss: 3.656378746032715
Validation loss: 2.847425406978976

Epoch: 6| Step: 12
Training loss: 2.6633799076080322
Validation loss: 2.83822605686803

Epoch: 6| Step: 13
Training loss: 3.3634419441223145
Validation loss: 2.833955472515475

Epoch: 22| Step: 0
Training loss: 2.9334964752197266
Validation loss: 2.8304433848268244

Epoch: 6| Step: 1
Training loss: 3.091235637664795
Validation loss: 2.8312158353867067

Epoch: 6| Step: 2
Training loss: 3.556813955307007
Validation loss: 2.8239251413652973

Epoch: 6| Step: 3
Training loss: 2.9857304096221924
Validation loss: 2.825874464486235

Epoch: 6| Step: 4
Training loss: 3.0353498458862305
Validation loss: 2.821414421963435

Epoch: 6| Step: 5
Training loss: 3.5272679328918457
Validation loss: 2.8252191799943165

Epoch: 6| Step: 6
Training loss: 3.346254587173462
Validation loss: 2.822874420432634

Epoch: 6| Step: 7
Training loss: 1.9544204473495483
Validation loss: 2.819919147799092

Epoch: 6| Step: 8
Training loss: 2.3786516189575195
Validation loss: 2.822368678226266

Epoch: 6| Step: 9
Training loss: 2.51002836227417
Validation loss: 2.824181082428143

Epoch: 6| Step: 10
Training loss: 3.070089340209961
Validation loss: 2.8157518320186163

Epoch: 6| Step: 11
Training loss: 2.643751621246338
Validation loss: 2.8188303875666794

Epoch: 6| Step: 12
Training loss: 2.8833067417144775
Validation loss: 2.816776242307437

Epoch: 6| Step: 13
Training loss: 3.27107310295105
Validation loss: 2.8099058828046246

Epoch: 23| Step: 0
Training loss: 2.495452880859375
Validation loss: 2.8103933513805432

Epoch: 6| Step: 1
Training loss: 3.092172861099243
Validation loss: 2.805433852698213

Epoch: 6| Step: 2
Training loss: 3.1859474182128906
Validation loss: 2.798983804641231

Epoch: 6| Step: 3
Training loss: 2.726992607116699
Validation loss: 2.802644411722819

Epoch: 6| Step: 4
Training loss: 2.143355369567871
Validation loss: 2.801057305387271

Epoch: 6| Step: 5
Training loss: 3.183485507965088
Validation loss: 2.8021631445935977

Epoch: 6| Step: 6
Training loss: 3.1767992973327637
Validation loss: 2.8044804450004333

Epoch: 6| Step: 7
Training loss: 2.6256163120269775
Validation loss: 2.8124037250395744

Epoch: 6| Step: 8
Training loss: 2.5017566680908203
Validation loss: 2.804182198739821

Epoch: 6| Step: 9
Training loss: 3.4155890941619873
Validation loss: 2.8017941495423675

Epoch: 6| Step: 10
Training loss: 3.7285704612731934
Validation loss: 2.791967220203851

Epoch: 6| Step: 11
Training loss: 3.0219573974609375
Validation loss: 2.7889501894673994

Epoch: 6| Step: 12
Training loss: 2.954122304916382
Validation loss: 2.7862950755703833

Epoch: 6| Step: 13
Training loss: 2.235292673110962
Validation loss: 2.7866704515231553

Epoch: 24| Step: 0
Training loss: 1.9937056303024292
Validation loss: 2.7841756754024054

Epoch: 6| Step: 1
Training loss: 2.7872793674468994
Validation loss: 2.7859002262033443

Epoch: 6| Step: 2
Training loss: 1.9260470867156982
Validation loss: 2.78817141953335

Epoch: 6| Step: 3
Training loss: 2.4655396938323975
Validation loss: 2.7832558719060754

Epoch: 6| Step: 4
Training loss: 3.256046772003174
Validation loss: 2.7878621803816928

Epoch: 6| Step: 5
Training loss: 4.1469268798828125
Validation loss: 2.8067941665649414

Epoch: 6| Step: 6
Training loss: 2.664785146713257
Validation loss: 2.7848844502561834

Epoch: 6| Step: 7
Training loss: 2.2631330490112305
Validation loss: 2.776636867113011

Epoch: 6| Step: 8
Training loss: 3.9937334060668945
Validation loss: 2.7746730671134046

Epoch: 6| Step: 9
Training loss: 3.0818660259246826
Validation loss: 2.778578999221966

Epoch: 6| Step: 10
Training loss: 2.522533893585205
Validation loss: 2.781887556916924

Epoch: 6| Step: 11
Training loss: 2.10744309425354
Validation loss: 2.783477767821281

Epoch: 6| Step: 12
Training loss: 3.918238401412964
Validation loss: 2.793894870306856

Epoch: 6| Step: 13
Training loss: 4.016610145568848
Validation loss: 2.7963369969398744

Epoch: 25| Step: 0
Training loss: 2.9664478302001953
Validation loss: 2.7915792311391523

Epoch: 6| Step: 1
Training loss: 2.718653440475464
Validation loss: 2.787661490901824

Epoch: 6| Step: 2
Training loss: 2.2283029556274414
Validation loss: 2.787722938804216

Epoch: 6| Step: 3
Training loss: 2.8478305339813232
Validation loss: 2.7895962833076395

Epoch: 6| Step: 4
Training loss: 2.8156063556671143
Validation loss: 2.7883084897072083

Epoch: 6| Step: 5
Training loss: 2.7514500617980957
Validation loss: 2.782401489955123

Epoch: 6| Step: 6
Training loss: 2.3685553073883057
Validation loss: 2.779012251925725

Epoch: 6| Step: 7
Training loss: 3.0360515117645264
Validation loss: 2.777278910401047

Epoch: 6| Step: 8
Training loss: 3.3619720935821533
Validation loss: 2.776954153532623

Epoch: 6| Step: 9
Training loss: 3.0185558795928955
Validation loss: 2.7817135216087423

Epoch: 6| Step: 10
Training loss: 2.8766555786132812
Validation loss: 2.7741205820473294

Epoch: 6| Step: 11
Training loss: 3.3838253021240234
Validation loss: 2.7703841065847747

Epoch: 6| Step: 12
Training loss: 2.6041667461395264
Validation loss: 2.7721965389866985

Epoch: 6| Step: 13
Training loss: 4.068438529968262
Validation loss: 2.765602937308691

Epoch: 26| Step: 0
Training loss: 2.388721466064453
Validation loss: 2.767079850678803

Epoch: 6| Step: 1
Training loss: 2.6664741039276123
Validation loss: 2.7624544251349663

Epoch: 6| Step: 2
Training loss: 2.3277204036712646
Validation loss: 2.7614668184711086

Epoch: 6| Step: 3
Training loss: 3.653108596801758
Validation loss: 2.7615922548437632

Epoch: 6| Step: 4
Training loss: 3.6877200603485107
Validation loss: 2.7604107241476736

Epoch: 6| Step: 5
Training loss: 2.6930503845214844
Validation loss: 2.761256597375357

Epoch: 6| Step: 6
Training loss: 3.6409783363342285
Validation loss: 2.760733127593994

Epoch: 6| Step: 7
Training loss: 2.704451084136963
Validation loss: 2.7565962371005805

Epoch: 6| Step: 8
Training loss: 2.4180703163146973
Validation loss: 2.7534524215165006

Epoch: 6| Step: 9
Training loss: 1.7722123861312866
Validation loss: 2.7564736130417034

Epoch: 6| Step: 10
Training loss: 2.7877025604248047
Validation loss: 2.7615393695010932

Epoch: 6| Step: 11
Training loss: 3.388885259628296
Validation loss: 2.7583504005145003

Epoch: 6| Step: 12
Training loss: 2.9037580490112305
Validation loss: 2.759886303255635

Epoch: 6| Step: 13
Training loss: 3.6205825805664062
Validation loss: 2.7631279473663657

Epoch: 27| Step: 0
Training loss: 3.1057393550872803
Validation loss: 2.7617833383621706

Epoch: 6| Step: 1
Training loss: 2.398897171020508
Validation loss: 2.762019839338077

Epoch: 6| Step: 2
Training loss: 3.0051164627075195
Validation loss: 2.7698929771300285

Epoch: 6| Step: 3
Training loss: 2.1805343627929688
Validation loss: 2.7799940493799027

Epoch: 6| Step: 4
Training loss: 2.1713714599609375
Validation loss: 2.77887023392544

Epoch: 6| Step: 5
Training loss: 2.7065024375915527
Validation loss: 2.7960079229006203

Epoch: 6| Step: 6
Training loss: 2.6788408756256104
Validation loss: 2.7746193383329656

Epoch: 6| Step: 7
Training loss: 3.43890118598938
Validation loss: 2.7632603388960644

Epoch: 6| Step: 8
Training loss: 3.1564018726348877
Validation loss: 2.757127523422241

Epoch: 6| Step: 9
Training loss: 2.57603120803833
Validation loss: 2.7486068561512935

Epoch: 6| Step: 10
Training loss: 3.478187322616577
Validation loss: 2.7441375178675496

Epoch: 6| Step: 11
Training loss: 2.981738805770874
Validation loss: 2.7869436305056334

Epoch: 6| Step: 12
Training loss: 3.5776281356811523
Validation loss: 2.828108710627402

Epoch: 6| Step: 13
Training loss: 2.932194232940674
Validation loss: 2.7940912579977386

Epoch: 28| Step: 0
Training loss: 3.8256688117980957
Validation loss: 2.7643729256045435

Epoch: 6| Step: 1
Training loss: 3.599745273590088
Validation loss: 2.7509328472998833

Epoch: 6| Step: 2
Training loss: 2.8014004230499268
Validation loss: 2.7490834830909647

Epoch: 6| Step: 3
Training loss: 2.1039810180664062
Validation loss: 2.763442923945765

Epoch: 6| Step: 4
Training loss: 3.377501964569092
Validation loss: 2.8455941241274596

Epoch: 6| Step: 5
Training loss: 1.8587963581085205
Validation loss: 2.885148499601631

Epoch: 6| Step: 6
Training loss: 3.362086057662964
Validation loss: 2.900361325151177

Epoch: 6| Step: 7
Training loss: 3.308192253112793
Validation loss: 2.8921843754347933

Epoch: 6| Step: 8
Training loss: 2.679248332977295
Validation loss: 2.822214026604929

Epoch: 6| Step: 9
Training loss: 2.511521816253662
Validation loss: 2.776041494902744

Epoch: 6| Step: 10
Training loss: 2.634982109069824
Validation loss: 2.7570925963822233

Epoch: 6| Step: 11
Training loss: 3.1080782413482666
Validation loss: 2.763526032047887

Epoch: 6| Step: 12
Training loss: 2.310845375061035
Validation loss: 2.770589551618022

Epoch: 6| Step: 13
Training loss: 3.8538522720336914
Validation loss: 2.7872126230629544

Epoch: 29| Step: 0
Training loss: 2.535048484802246
Validation loss: 2.7814350281992266

Epoch: 6| Step: 1
Training loss: 3.044750690460205
Validation loss: 2.777142106845815

Epoch: 6| Step: 2
Training loss: 2.330965757369995
Validation loss: 2.78768632488866

Epoch: 6| Step: 3
Training loss: 2.9138236045837402
Validation loss: 2.7821804836232173

Epoch: 6| Step: 4
Training loss: 3.349199056625366
Validation loss: 2.739078244855327

Epoch: 6| Step: 5
Training loss: 3.474039077758789
Validation loss: 2.7294435347280195

Epoch: 6| Step: 6
Training loss: 2.4136571884155273
Validation loss: 2.733062954359157

Epoch: 6| Step: 7
Training loss: 3.209409713745117
Validation loss: 2.731357664190313

Epoch: 6| Step: 8
Training loss: 3.754765272140503
Validation loss: 2.745556318631736

Epoch: 6| Step: 9
Training loss: 2.6827545166015625
Validation loss: 2.7451376581704743

Epoch: 6| Step: 10
Training loss: 1.9944316148757935
Validation loss: 2.7325243052615913

Epoch: 6| Step: 11
Training loss: 2.6615869998931885
Validation loss: 2.726665137916483

Epoch: 6| Step: 12
Training loss: 3.3320536613464355
Validation loss: 2.7251909573872886

Epoch: 6| Step: 13
Training loss: 2.4390268325805664
Validation loss: 2.719567398871145

Epoch: 30| Step: 0
Training loss: 3.2190067768096924
Validation loss: 2.7208420845770065

Epoch: 6| Step: 1
Training loss: 2.6607155799865723
Validation loss: 2.7178076313387964

Epoch: 6| Step: 2
Training loss: 3.5922048091888428
Validation loss: 2.717765856814641

Epoch: 6| Step: 3
Training loss: 3.1595733165740967
Validation loss: 2.7198034665917836

Epoch: 6| Step: 4
Training loss: 2.860473394393921
Validation loss: 2.718023614216876

Epoch: 6| Step: 5
Training loss: 3.1469814777374268
Validation loss: 2.7157977191350793

Epoch: 6| Step: 6
Training loss: 2.392996311187744
Validation loss: 2.7188232483402377

Epoch: 6| Step: 7
Training loss: 2.663102149963379
Validation loss: 2.7188472029983357

Epoch: 6| Step: 8
Training loss: 2.6177563667297363
Validation loss: 2.719226767939906

Epoch: 6| Step: 9
Training loss: 2.8415021896362305
Validation loss: 2.7174541463134108

Epoch: 6| Step: 10
Training loss: 1.914300799369812
Validation loss: 2.716341576268596

Epoch: 6| Step: 11
Training loss: 3.2845888137817383
Validation loss: 2.712754944319366

Epoch: 6| Step: 12
Training loss: 2.811790704727173
Validation loss: 2.7099372315150436

Epoch: 6| Step: 13
Training loss: 2.6690030097961426
Validation loss: 2.7132942009997625

Epoch: 31| Step: 0
Training loss: 2.840456962585449
Validation loss: 2.7188294805506223

Epoch: 6| Step: 1
Training loss: 2.58677339553833
Validation loss: 2.711556755086427

Epoch: 6| Step: 2
Training loss: 2.7152018547058105
Validation loss: 2.7120382606342273

Epoch: 6| Step: 3
Training loss: 3.268376350402832
Validation loss: 2.7129516934835785

Epoch: 6| Step: 4
Training loss: 3.1542134284973145
Validation loss: 2.705214656809325

Epoch: 6| Step: 5
Training loss: 3.1026549339294434
Validation loss: 2.7085467538525982

Epoch: 6| Step: 6
Training loss: 2.6147100925445557
Validation loss: 2.7056581640756256

Epoch: 6| Step: 7
Training loss: 2.9835686683654785
Validation loss: 2.701708503948745

Epoch: 6| Step: 8
Training loss: 2.594825506210327
Validation loss: 2.704590471841956

Epoch: 6| Step: 9
Training loss: 1.9993376731872559
Validation loss: 2.698842079408707

Epoch: 6| Step: 10
Training loss: 2.916149616241455
Validation loss: 2.7040251967727498

Epoch: 6| Step: 11
Training loss: 2.995837926864624
Validation loss: 2.6995235489260767

Epoch: 6| Step: 12
Training loss: 3.0754501819610596
Validation loss: 2.700978584187005

Epoch: 6| Step: 13
Training loss: 2.990830421447754
Validation loss: 2.6973681680617796

Epoch: 32| Step: 0
Training loss: 3.518021583557129
Validation loss: 2.6960940309750137

Epoch: 6| Step: 1
Training loss: 3.2713136672973633
Validation loss: 2.6941821523891982

Epoch: 6| Step: 2
Training loss: 2.420177698135376
Validation loss: 2.7006309032440186

Epoch: 6| Step: 3
Training loss: 2.686323642730713
Validation loss: 2.69859375492219

Epoch: 6| Step: 4
Training loss: 3.812150001525879
Validation loss: 2.6983146564934843

Epoch: 6| Step: 5
Training loss: 2.2418408393859863
Validation loss: 2.6984689389505694

Epoch: 6| Step: 6
Training loss: 3.895401954650879
Validation loss: 2.698350873044742

Epoch: 6| Step: 7
Training loss: 3.3350863456726074
Validation loss: 2.6985214858926754

Epoch: 6| Step: 8
Training loss: 2.0976641178131104
Validation loss: 2.698664708804059

Epoch: 6| Step: 9
Training loss: 2.090541362762451
Validation loss: 2.6950815723788355

Epoch: 6| Step: 10
Training loss: 2.5596208572387695
Validation loss: 2.6935865391967115

Epoch: 6| Step: 11
Training loss: 2.7740373611450195
Validation loss: 2.697805053444319

Epoch: 6| Step: 12
Training loss: 2.5381500720977783
Validation loss: 2.690818384129514

Epoch: 6| Step: 13
Training loss: 2.080521821975708
Validation loss: 2.6881491112452682

Epoch: 33| Step: 0
Training loss: 1.9182713031768799
Validation loss: 2.686715167055848

Epoch: 6| Step: 1
Training loss: 3.0899763107299805
Validation loss: 2.6869000747639644

Epoch: 6| Step: 2
Training loss: 2.7585949897766113
Validation loss: 2.6897053872385333

Epoch: 6| Step: 3
Training loss: 3.5864028930664062
Validation loss: 2.6925976686580206

Epoch: 6| Step: 4
Training loss: 3.0692195892333984
Validation loss: 2.6937585979379635

Epoch: 6| Step: 5
Training loss: 3.0222063064575195
Validation loss: 2.6952919601112284

Epoch: 6| Step: 6
Training loss: 2.578700542449951
Validation loss: 2.696387178154402

Epoch: 6| Step: 7
Training loss: 3.2768092155456543
Validation loss: 2.69831835069964

Epoch: 6| Step: 8
Training loss: 3.002469062805176
Validation loss: 2.694602268998341

Epoch: 6| Step: 9
Training loss: 2.7212769985198975
Validation loss: 2.6925869936584146

Epoch: 6| Step: 10
Training loss: 3.5590925216674805
Validation loss: 2.6833489043738252

Epoch: 6| Step: 11
Training loss: 2.1612164974212646
Validation loss: 2.683716812441426

Epoch: 6| Step: 12
Training loss: 2.3795642852783203
Validation loss: 2.6945324585001957

Epoch: 6| Step: 13
Training loss: 2.37288761138916
Validation loss: 2.7113813161849976

Epoch: 34| Step: 0
Training loss: 2.577206611633301
Validation loss: 2.732785096732519

Epoch: 6| Step: 1
Training loss: 3.5422873497009277
Validation loss: 2.7676624739041893

Epoch: 6| Step: 2
Training loss: 3.2133126258850098
Validation loss: 2.7517380534961657

Epoch: 6| Step: 3
Training loss: 2.8127598762512207
Validation loss: 2.7175952760122155

Epoch: 6| Step: 4
Training loss: 2.0258753299713135
Validation loss: 2.690278989012523

Epoch: 6| Step: 5
Training loss: 2.440275192260742
Validation loss: 2.682074685250559

Epoch: 6| Step: 6
Training loss: 2.049213171005249
Validation loss: 2.6792963781664447

Epoch: 6| Step: 7
Training loss: 3.4618401527404785
Validation loss: 2.675140611587032

Epoch: 6| Step: 8
Training loss: 2.345453977584839
Validation loss: 2.6819768567239084

Epoch: 6| Step: 9
Training loss: 3.698805809020996
Validation loss: 2.6818087741892827

Epoch: 6| Step: 10
Training loss: 3.028628349304199
Validation loss: 2.6858335438595025

Epoch: 6| Step: 11
Training loss: 2.9865293502807617
Validation loss: 2.694885059069562

Epoch: 6| Step: 12
Training loss: 2.6033859252929688
Validation loss: 2.6850620777376237

Epoch: 6| Step: 13
Training loss: 3.007676601409912
Validation loss: 2.6855878906865276

Epoch: 35| Step: 0
Training loss: 4.327692985534668
Validation loss: 2.6760330456559376

Epoch: 6| Step: 1
Training loss: 2.1789889335632324
Validation loss: 2.674984857600222

Epoch: 6| Step: 2
Training loss: 1.6603291034698486
Validation loss: 2.674080169329079

Epoch: 6| Step: 3
Training loss: 2.344249725341797
Validation loss: 2.676606862775741

Epoch: 6| Step: 4
Training loss: 2.748948574066162
Validation loss: 2.6799507397477345

Epoch: 6| Step: 5
Training loss: 2.3959145545959473
Validation loss: 2.6750463337026615

Epoch: 6| Step: 6
Training loss: 2.5037128925323486
Validation loss: 2.6748876264018397

Epoch: 6| Step: 7
Training loss: 2.9076876640319824
Validation loss: 2.6832453435467136

Epoch: 6| Step: 8
Training loss: 2.1749141216278076
Validation loss: 2.687648287383459

Epoch: 6| Step: 9
Training loss: 2.7842905521392822
Validation loss: 2.689058780670166

Epoch: 6| Step: 10
Training loss: 3.205889940261841
Validation loss: 2.7017019179559525

Epoch: 6| Step: 11
Training loss: 3.2729995250701904
Validation loss: 2.7023271411977787

Epoch: 6| Step: 12
Training loss: 3.7987124919891357
Validation loss: 2.710777990279659

Epoch: 6| Step: 13
Training loss: 3.3318591117858887
Validation loss: 2.6931183389438096

Epoch: 36| Step: 0
Training loss: 2.9357144832611084
Validation loss: 2.694095955100111

Epoch: 6| Step: 1
Training loss: 2.9256269931793213
Validation loss: 2.6801477914215415

Epoch: 6| Step: 2
Training loss: 1.3811492919921875
Validation loss: 2.6697448427959154

Epoch: 6| Step: 3
Training loss: 3.0343754291534424
Validation loss: 2.6674118400901876

Epoch: 6| Step: 4
Training loss: 2.764390468597412
Validation loss: 2.6719006261517926

Epoch: 6| Step: 5
Training loss: 2.846947431564331
Validation loss: 2.6728270258954776

Epoch: 6| Step: 6
Training loss: 3.0862090587615967
Validation loss: 2.668582293295091

Epoch: 6| Step: 7
Training loss: 2.4484052658081055
Validation loss: 2.6764351629441783

Epoch: 6| Step: 8
Training loss: 3.5284247398376465
Validation loss: 2.6644065226277998

Epoch: 6| Step: 9
Training loss: 2.6651010513305664
Validation loss: 2.6607526066482707

Epoch: 6| Step: 10
Training loss: 2.512587547302246
Validation loss: 2.6595695531496437

Epoch: 6| Step: 11
Training loss: 2.9391469955444336
Validation loss: 2.658145789177187

Epoch: 6| Step: 12
Training loss: 3.837367534637451
Validation loss: 2.658124117441075

Epoch: 6| Step: 13
Training loss: 2.1371610164642334
Validation loss: 2.660157988148351

Epoch: 37| Step: 0
Training loss: 2.4959232807159424
Validation loss: 2.6677986780802407

Epoch: 6| Step: 1
Training loss: 2.7065186500549316
Validation loss: 2.682111008192903

Epoch: 6| Step: 2
Training loss: 2.3514137268066406
Validation loss: 2.6849097769747496

Epoch: 6| Step: 3
Training loss: 3.153529167175293
Validation loss: 2.6784720472110215

Epoch: 6| Step: 4
Training loss: 1.9345054626464844
Validation loss: 2.666767950980894

Epoch: 6| Step: 5
Training loss: 3.0199310779571533
Validation loss: 2.6578408300235705

Epoch: 6| Step: 6
Training loss: 3.9223222732543945
Validation loss: 2.6517880860195366

Epoch: 6| Step: 7
Training loss: 3.669288158416748
Validation loss: 2.648124505114812

Epoch: 6| Step: 8
Training loss: 2.6940195560455322
Validation loss: 2.6492097121413036

Epoch: 6| Step: 9
Training loss: 3.0447213649749756
Validation loss: 2.6499456154402865

Epoch: 6| Step: 10
Training loss: 3.164048433303833
Validation loss: 2.6581918603630474

Epoch: 6| Step: 11
Training loss: 2.1625990867614746
Validation loss: 2.6611306795509915

Epoch: 6| Step: 12
Training loss: 2.745434522628784
Validation loss: 2.6571492354075112

Epoch: 6| Step: 13
Training loss: 2.054795265197754
Validation loss: 2.6571448182546966

Epoch: 38| Step: 0
Training loss: 2.927003860473633
Validation loss: 2.642614144150929

Epoch: 6| Step: 1
Training loss: 2.277073860168457
Validation loss: 2.6350473896149667

Epoch: 6| Step: 2
Training loss: 1.9420838356018066
Validation loss: 2.6397398620523433

Epoch: 6| Step: 3
Training loss: 2.410229444503784
Validation loss: 2.640087937795988

Epoch: 6| Step: 4
Training loss: 2.6660079956054688
Validation loss: 2.6542508576505925

Epoch: 6| Step: 5
Training loss: 2.697394847869873
Validation loss: 2.6364339577254428

Epoch: 6| Step: 6
Training loss: 2.861330032348633
Validation loss: 2.6341224972919752

Epoch: 6| Step: 7
Training loss: 2.597491979598999
Validation loss: 2.622517596008957

Epoch: 6| Step: 8
Training loss: 3.239098310470581
Validation loss: 2.6219940108637654

Epoch: 6| Step: 9
Training loss: 2.136155128479004
Validation loss: 2.6235258066526024

Epoch: 6| Step: 10
Training loss: 3.1810269355773926
Validation loss: 2.628788650676768

Epoch: 6| Step: 11
Training loss: 3.688281536102295
Validation loss: 2.6354063685222338

Epoch: 6| Step: 12
Training loss: 3.1432371139526367
Validation loss: 2.6380119246821248

Epoch: 6| Step: 13
Training loss: 3.4597482681274414
Validation loss: 2.6371543176712526

Epoch: 39| Step: 0
Training loss: 2.7041215896606445
Validation loss: 2.6424076480250203

Epoch: 6| Step: 1
Training loss: 2.9322876930236816
Validation loss: 2.6452853141292447

Epoch: 6| Step: 2
Training loss: 2.1413514614105225
Validation loss: 2.6288502549612396

Epoch: 6| Step: 3
Training loss: 2.6021459102630615
Validation loss: 2.6171575694955806

Epoch: 6| Step: 4
Training loss: 2.9535677433013916
Validation loss: 2.6106425998031453

Epoch: 6| Step: 5
Training loss: 2.8374814987182617
Validation loss: 2.6097586770211496

Epoch: 6| Step: 6
Training loss: 3.4760003089904785
Validation loss: 2.6176594457318707

Epoch: 6| Step: 7
Training loss: 3.6691291332244873
Validation loss: 2.6320400699492423

Epoch: 6| Step: 8
Training loss: 3.944927453994751
Validation loss: 2.6315929402587233

Epoch: 6| Step: 9
Training loss: 2.3737406730651855
Validation loss: 2.6213502781365507

Epoch: 6| Step: 10
Training loss: 2.297619342803955
Validation loss: 2.6167080710011144

Epoch: 6| Step: 11
Training loss: 2.6715261936187744
Validation loss: 2.611544611633465

Epoch: 6| Step: 12
Training loss: 1.8035228252410889
Validation loss: 2.6118338313153995

Epoch: 6| Step: 13
Training loss: 2.605868339538574
Validation loss: 2.6075905702447377

Epoch: 40| Step: 0
Training loss: 3.532867908477783
Validation loss: 2.6024627685546875

Epoch: 6| Step: 1
Training loss: 3.2446866035461426
Validation loss: 2.596919439172232

Epoch: 6| Step: 2
Training loss: 2.7531089782714844
Validation loss: 2.6042901033996255

Epoch: 6| Step: 3
Training loss: 3.048011302947998
Validation loss: 2.6056121882571968

Epoch: 6| Step: 4
Training loss: 2.3889176845550537
Validation loss: 2.6053651173909507

Epoch: 6| Step: 5
Training loss: 2.665722131729126
Validation loss: 2.6052691449401197

Epoch: 6| Step: 6
Training loss: 2.1948511600494385
Validation loss: 2.5994570716734855

Epoch: 6| Step: 7
Training loss: 1.524848461151123
Validation loss: 2.603888960294826

Epoch: 6| Step: 8
Training loss: 2.9089999198913574
Validation loss: 2.6027466533004597

Epoch: 6| Step: 9
Training loss: 3.2527387142181396
Validation loss: 2.6022506375466623

Epoch: 6| Step: 10
Training loss: 2.8569254875183105
Validation loss: 2.6179136050644742

Epoch: 6| Step: 11
Training loss: 2.8542656898498535
Validation loss: 2.599248996344946

Epoch: 6| Step: 12
Training loss: 3.061258316040039
Validation loss: 2.599143607642061

Epoch: 6| Step: 13
Training loss: 2.1589155197143555
Validation loss: 2.6002276943575953

Epoch: 41| Step: 0
Training loss: 3.424614429473877
Validation loss: 2.599543543272121

Epoch: 6| Step: 1
Training loss: 3.3523597717285156
Validation loss: 2.6000010480162916

Epoch: 6| Step: 2
Training loss: 2.923358917236328
Validation loss: 2.600979435828424

Epoch: 6| Step: 3
Training loss: 2.34476375579834
Validation loss: 2.604903410839778

Epoch: 6| Step: 4
Training loss: 2.5591249465942383
Validation loss: 2.614839082123131

Epoch: 6| Step: 5
Training loss: 2.66593074798584
Validation loss: 2.610676396277643

Epoch: 6| Step: 6
Training loss: 2.76170015335083
Validation loss: 2.609585808169457

Epoch: 6| Step: 7
Training loss: 2.3780038356781006
Validation loss: 2.602040675378615

Epoch: 6| Step: 8
Training loss: 3.2007293701171875
Validation loss: 2.592359527464836

Epoch: 6| Step: 9
Training loss: 2.8543572425842285
Validation loss: 2.5896424375554568

Epoch: 6| Step: 10
Training loss: 2.8544600009918213
Validation loss: 2.5865126527765745

Epoch: 6| Step: 11
Training loss: 2.3812808990478516
Validation loss: 2.590898198466147

Epoch: 6| Step: 12
Training loss: 2.3432836532592773
Validation loss: 2.5901691785422702

Epoch: 6| Step: 13
Training loss: 2.5291502475738525
Validation loss: 2.591159107864544

Epoch: 42| Step: 0
Training loss: 2.771029472351074
Validation loss: 2.5883972157714186

Epoch: 6| Step: 1
Training loss: 2.610527515411377
Validation loss: 2.5896042418736283

Epoch: 6| Step: 2
Training loss: 1.8260458707809448
Validation loss: 2.5873913970044864

Epoch: 6| Step: 3
Training loss: 2.774684429168701
Validation loss: 2.585374201497724

Epoch: 6| Step: 4
Training loss: 2.8329224586486816
Validation loss: 2.5848577278916554

Epoch: 6| Step: 5
Training loss: 3.3091142177581787
Validation loss: 2.580615289749638

Epoch: 6| Step: 6
Training loss: 3.249274730682373
Validation loss: 2.5800979291239092

Epoch: 6| Step: 7
Training loss: 1.9106554985046387
Validation loss: 2.5760840523627495

Epoch: 6| Step: 8
Training loss: 2.701154947280884
Validation loss: 2.582098719894245

Epoch: 6| Step: 9
Training loss: 2.9746227264404297
Validation loss: 2.5814211060923915

Epoch: 6| Step: 10
Training loss: 2.3880703449249268
Validation loss: 2.587869680056008

Epoch: 6| Step: 11
Training loss: 3.6997010707855225
Validation loss: 2.5900805509218605

Epoch: 6| Step: 12
Training loss: 2.936159133911133
Validation loss: 2.5918009306794856

Epoch: 6| Step: 13
Training loss: 2.2103283405303955
Validation loss: 2.5956990154840613

Epoch: 43| Step: 0
Training loss: 2.5443029403686523
Validation loss: 2.6233187106347855

Epoch: 6| Step: 1
Training loss: 2.197497844696045
Validation loss: 2.6590196214696413

Epoch: 6| Step: 2
Training loss: 3.5025088787078857
Validation loss: 2.664851657805904

Epoch: 6| Step: 3
Training loss: 2.797114610671997
Validation loss: 2.6146645238322597

Epoch: 6| Step: 4
Training loss: 2.2819652557373047
Validation loss: 2.6013685682768464

Epoch: 6| Step: 5
Training loss: 3.1848349571228027
Validation loss: 2.5948732514535227

Epoch: 6| Step: 6
Training loss: 1.664542555809021
Validation loss: 2.5881592381385063

Epoch: 6| Step: 7
Training loss: 3.1249327659606934
Validation loss: 2.5786428964266213

Epoch: 6| Step: 8
Training loss: 2.1805193424224854
Validation loss: 2.5698713461558023

Epoch: 6| Step: 9
Training loss: 4.075140476226807
Validation loss: 2.563839417631908

Epoch: 6| Step: 10
Training loss: 3.882262706756592
Validation loss: 2.567963689886114

Epoch: 6| Step: 11
Training loss: 2.5437755584716797
Validation loss: 2.5756647535549697

Epoch: 6| Step: 12
Training loss: 2.41044545173645
Validation loss: 2.575955952367475

Epoch: 6| Step: 13
Training loss: 1.8427881002426147
Validation loss: 2.577083992701705

Epoch: 44| Step: 0
Training loss: 2.6171398162841797
Validation loss: 2.5770057888441187

Epoch: 6| Step: 1
Training loss: 2.7180521488189697
Validation loss: 2.5717362793543006

Epoch: 6| Step: 2
Training loss: 2.3891921043395996
Validation loss: 2.566032112285655

Epoch: 6| Step: 3
Training loss: 3.1634631156921387
Validation loss: 2.560437043507894

Epoch: 6| Step: 4
Training loss: 2.2967474460601807
Validation loss: 2.559800504356302

Epoch: 6| Step: 5
Training loss: 2.6164989471435547
Validation loss: 2.5568547915386897

Epoch: 6| Step: 6
Training loss: 3.241055965423584
Validation loss: 2.5691646786146265

Epoch: 6| Step: 7
Training loss: 2.408524513244629
Validation loss: 2.55910611409013

Epoch: 6| Step: 8
Training loss: 2.5580153465270996
Validation loss: 2.56331907292848

Epoch: 6| Step: 9
Training loss: 3.140498638153076
Validation loss: 2.5625194426505797

Epoch: 6| Step: 10
Training loss: 2.3922786712646484
Validation loss: 2.5652940888558664

Epoch: 6| Step: 11
Training loss: 2.8397130966186523
Validation loss: 2.5592177657670874

Epoch: 6| Step: 12
Training loss: 3.44160532951355
Validation loss: 2.560495489387102

Epoch: 6| Step: 13
Training loss: 2.407418966293335
Validation loss: 2.561338416991695

Epoch: 45| Step: 0
Training loss: 2.0910332202911377
Validation loss: 2.5620750073463685

Epoch: 6| Step: 1
Training loss: 3.4047040939331055
Validation loss: 2.5523413381268902

Epoch: 6| Step: 2
Training loss: 3.332165002822876
Validation loss: 2.561888228180588

Epoch: 6| Step: 3
Training loss: 2.0576171875
Validation loss: 2.5593502649696926

Epoch: 6| Step: 4
Training loss: 2.5446362495422363
Validation loss: 2.5505031770275486

Epoch: 6| Step: 5
Training loss: 2.6446290016174316
Validation loss: 2.550586049274732

Epoch: 6| Step: 6
Training loss: 2.8637330532073975
Validation loss: 2.551111667386947

Epoch: 6| Step: 7
Training loss: 2.937211751937866
Validation loss: 2.547477729858891

Epoch: 6| Step: 8
Training loss: 3.0229601860046387
Validation loss: 2.5493092844563146

Epoch: 6| Step: 9
Training loss: 2.1429262161254883
Validation loss: 2.5485534539786716

Epoch: 6| Step: 10
Training loss: 2.5345840454101562
Validation loss: 2.5495243841601956

Epoch: 6| Step: 11
Training loss: 2.76632022857666
Validation loss: 2.5505642480747674

Epoch: 6| Step: 12
Training loss: 2.746396064758301
Validation loss: 2.551389214813068

Epoch: 6| Step: 13
Training loss: 3.462545156478882
Validation loss: 2.5529768441313054

Epoch: 46| Step: 0
Training loss: 1.6029791831970215
Validation loss: 2.550783788004229

Epoch: 6| Step: 1
Training loss: 3.0810155868530273
Validation loss: 2.5482075137476765

Epoch: 6| Step: 2
Training loss: 2.444044351577759
Validation loss: 2.5557570406185683

Epoch: 6| Step: 3
Training loss: 3.751706600189209
Validation loss: 2.5552117952736477

Epoch: 6| Step: 4
Training loss: 2.785022258758545
Validation loss: 2.5627200142029793

Epoch: 6| Step: 5
Training loss: 2.9138951301574707
Validation loss: 2.5737971105883197

Epoch: 6| Step: 6
Training loss: 3.3537354469299316
Validation loss: 2.5851442019144693

Epoch: 6| Step: 7
Training loss: 2.6885311603546143
Validation loss: 2.611488019266436

Epoch: 6| Step: 8
Training loss: 2.78432035446167
Validation loss: 2.629718780517578

Epoch: 6| Step: 9
Training loss: 2.5798099040985107
Validation loss: 2.6811379873624412

Epoch: 6| Step: 10
Training loss: 2.849485397338867
Validation loss: 2.640691372656053

Epoch: 6| Step: 11
Training loss: 2.5633256435394287
Validation loss: 2.589099807123984

Epoch: 6| Step: 12
Training loss: 2.6437559127807617
Validation loss: 2.556604746849306

Epoch: 6| Step: 13
Training loss: 2.1088342666625977
Validation loss: 2.542763707458332

Epoch: 47| Step: 0
Training loss: 2.0349998474121094
Validation loss: 2.540649799890416

Epoch: 6| Step: 1
Training loss: 2.9789021015167236
Validation loss: 2.540111941675986

Epoch: 6| Step: 2
Training loss: 2.449220657348633
Validation loss: 2.5382197646684546

Epoch: 6| Step: 3
Training loss: 2.7040562629699707
Validation loss: 2.5386634385713966

Epoch: 6| Step: 4
Training loss: 2.6006646156311035
Validation loss: 2.5411296185626777

Epoch: 6| Step: 5
Training loss: 3.201582908630371
Validation loss: 2.5452680382677304

Epoch: 6| Step: 6
Training loss: 2.4520645141601562
Validation loss: 2.5447601733669156

Epoch: 6| Step: 7
Training loss: 2.815537452697754
Validation loss: 2.5392072969867336

Epoch: 6| Step: 8
Training loss: 2.626509189605713
Validation loss: 2.5455400559210006

Epoch: 6| Step: 9
Training loss: 3.762646436691284
Validation loss: 2.53854973085465

Epoch: 6| Step: 10
Training loss: 2.592536687850952
Validation loss: 2.537204770631688

Epoch: 6| Step: 11
Training loss: 2.5805492401123047
Validation loss: 2.541648095653903

Epoch: 6| Step: 12
Training loss: 2.7605059146881104
Validation loss: 2.5452351211219706

Epoch: 6| Step: 13
Training loss: 2.456709861755371
Validation loss: 2.5466904165924236

Epoch: 48| Step: 0
Training loss: 3.268658399581909
Validation loss: 2.5490280992241314

Epoch: 6| Step: 1
Training loss: 2.756972312927246
Validation loss: 2.5582387344811552

Epoch: 6| Step: 2
Training loss: 3.4737415313720703
Validation loss: 2.5646367919060493

Epoch: 6| Step: 3
Training loss: 2.8123104572296143
Validation loss: 2.5653053252927718

Epoch: 6| Step: 4
Training loss: 2.654637336730957
Validation loss: 2.554595624246905

Epoch: 6| Step: 5
Training loss: 3.049973487854004
Validation loss: 2.5469582157750286

Epoch: 6| Step: 6
Training loss: 2.730499267578125
Validation loss: 2.534330047586913

Epoch: 6| Step: 7
Training loss: 3.1213135719299316
Validation loss: 2.5262233236784577

Epoch: 6| Step: 8
Training loss: 2.290828227996826
Validation loss: 2.5265937261683966

Epoch: 6| Step: 9
Training loss: 3.0259201526641846
Validation loss: 2.5279123603656726

Epoch: 6| Step: 10
Training loss: 2.7297606468200684
Validation loss: 2.5243836487493208

Epoch: 6| Step: 11
Training loss: 2.269538164138794
Validation loss: 2.524282193952991

Epoch: 6| Step: 12
Training loss: 1.783299446105957
Validation loss: 2.5240986783017396

Epoch: 6| Step: 13
Training loss: 1.695803165435791
Validation loss: 2.524965973310573

Epoch: 49| Step: 0
Training loss: 4.10849142074585
Validation loss: 2.523516011494462

Epoch: 6| Step: 1
Training loss: 2.425748109817505
Validation loss: 2.5226999046981975

Epoch: 6| Step: 2
Training loss: 2.9864797592163086
Validation loss: 2.5233664538270686

Epoch: 6| Step: 3
Training loss: 2.4489316940307617
Validation loss: 2.523363608185963

Epoch: 6| Step: 4
Training loss: 2.088955879211426
Validation loss: 2.52365207159391

Epoch: 6| Step: 5
Training loss: 2.621776819229126
Validation loss: 2.532869408207555

Epoch: 6| Step: 6
Training loss: 1.9685879945755005
Validation loss: 2.525926900166337

Epoch: 6| Step: 7
Training loss: 2.57612943649292
Validation loss: 2.520616364735429

Epoch: 6| Step: 8
Training loss: 2.697244167327881
Validation loss: 2.5231601012650358

Epoch: 6| Step: 9
Training loss: 2.9896793365478516
Validation loss: 2.5226781163164365

Epoch: 6| Step: 10
Training loss: 2.9562549591064453
Validation loss: 2.5179322329900597

Epoch: 6| Step: 11
Training loss: 2.7312171459198
Validation loss: 2.516577333532354

Epoch: 6| Step: 12
Training loss: 2.8956525325775146
Validation loss: 2.5249128700584493

Epoch: 6| Step: 13
Training loss: 2.33829402923584
Validation loss: 2.523166069420435

Epoch: 50| Step: 0
Training loss: 2.7824440002441406
Validation loss: 2.5223558641249135

Epoch: 6| Step: 1
Training loss: 2.3980743885040283
Validation loss: 2.519608125891737

Epoch: 6| Step: 2
Training loss: 2.873289108276367
Validation loss: 2.516144452556487

Epoch: 6| Step: 3
Training loss: 2.2151050567626953
Validation loss: 2.517309319588446

Epoch: 6| Step: 4
Training loss: 2.8331429958343506
Validation loss: 2.513748538109564

Epoch: 6| Step: 5
Training loss: 2.1018996238708496
Validation loss: 2.5139105960886967

Epoch: 6| Step: 6
Training loss: 2.7222070693969727
Validation loss: 2.512090224091725

Epoch: 6| Step: 7
Training loss: 2.7569217681884766
Validation loss: 2.514471677041823

Epoch: 6| Step: 8
Training loss: 3.409520149230957
Validation loss: 2.516887434067265

Epoch: 6| Step: 9
Training loss: 2.7242026329040527
Validation loss: 2.5151471091854956

Epoch: 6| Step: 10
Training loss: 2.6430861949920654
Validation loss: 2.5142655475165254

Epoch: 6| Step: 11
Training loss: 3.2157063484191895
Validation loss: 2.5152452684217885

Epoch: 6| Step: 12
Training loss: 2.7353055477142334
Validation loss: 2.5212932837906705

Epoch: 6| Step: 13
Training loss: 2.3067641258239746
Validation loss: 2.5349031955965105

Epoch: 51| Step: 0
Training loss: 2.872528553009033
Validation loss: 2.546342034493723

Epoch: 6| Step: 1
Training loss: 2.5686445236206055
Validation loss: 2.5295109236112205

Epoch: 6| Step: 2
Training loss: 2.7066726684570312
Validation loss: 2.5296139537647204

Epoch: 6| Step: 3
Training loss: 3.1217658519744873
Validation loss: 2.514140434162591

Epoch: 6| Step: 4
Training loss: 3.083911418914795
Validation loss: 2.5051090204587547

Epoch: 6| Step: 5
Training loss: 2.6680774688720703
Validation loss: 2.5052127786861953

Epoch: 6| Step: 6
Training loss: 2.5289955139160156
Validation loss: 2.499938113715059

Epoch: 6| Step: 7
Training loss: 2.6563942432403564
Validation loss: 2.5026602642510527

Epoch: 6| Step: 8
Training loss: 2.928114414215088
Validation loss: 2.5029688958198792

Epoch: 6| Step: 9
Training loss: 2.112100124359131
Validation loss: 2.5005145688210764

Epoch: 6| Step: 10
Training loss: 2.8534371852874756
Validation loss: 2.4989267190297446

Epoch: 6| Step: 11
Training loss: 2.0996148586273193
Validation loss: 2.498034918180076

Epoch: 6| Step: 12
Training loss: 3.0581207275390625
Validation loss: 2.4980614262242473

Epoch: 6| Step: 13
Training loss: 2.5694799423217773
Validation loss: 2.496905331970543

Epoch: 52| Step: 0
Training loss: 2.90264630317688
Validation loss: 2.497693528411209

Epoch: 6| Step: 1
Training loss: 2.978358507156372
Validation loss: 2.4956833239524596

Epoch: 6| Step: 2
Training loss: 1.8604156970977783
Validation loss: 2.500272266326412

Epoch: 6| Step: 3
Training loss: 3.271310329437256
Validation loss: 2.500366710847424

Epoch: 6| Step: 4
Training loss: 2.739950656890869
Validation loss: 2.4986352792350193

Epoch: 6| Step: 5
Training loss: 2.6851308345794678
Validation loss: 2.4999797421116985

Epoch: 6| Step: 6
Training loss: 2.7759222984313965
Validation loss: 2.496000164298601

Epoch: 6| Step: 7
Training loss: 2.237450122833252
Validation loss: 2.4963683364211873

Epoch: 6| Step: 8
Training loss: 2.5281331539154053
Validation loss: 2.4944379329681396

Epoch: 6| Step: 9
Training loss: 2.879293441772461
Validation loss: 2.500101747051362

Epoch: 6| Step: 10
Training loss: 1.788171648979187
Validation loss: 2.5081067572357836

Epoch: 6| Step: 11
Training loss: 3.060290813446045
Validation loss: 2.510404391955304

Epoch: 6| Step: 12
Training loss: 2.98423433303833
Validation loss: 2.510523860172559

Epoch: 6| Step: 13
Training loss: 3.3321611881256104
Validation loss: 2.5196068979078725

Epoch: 53| Step: 0
Training loss: 2.5454933643341064
Validation loss: 2.535024883926556

Epoch: 6| Step: 1
Training loss: 2.272524356842041
Validation loss: 2.5392118653943463

Epoch: 6| Step: 2
Training loss: 2.6657421588897705
Validation loss: 2.5408627576725458

Epoch: 6| Step: 3
Training loss: 3.1138100624084473
Validation loss: 2.530579879719724

Epoch: 6| Step: 4
Training loss: 2.7379212379455566
Validation loss: 2.5109302895043486

Epoch: 6| Step: 5
Training loss: 2.6961960792541504
Validation loss: 2.4970954054145404

Epoch: 6| Step: 6
Training loss: 2.9799606800079346
Validation loss: 2.4933934211730957

Epoch: 6| Step: 7
Training loss: 2.60127329826355
Validation loss: 2.511707070053265

Epoch: 6| Step: 8
Training loss: 2.9522385597229004
Validation loss: 2.5367562847752727

Epoch: 6| Step: 9
Training loss: 2.0426998138427734
Validation loss: 2.58510180698928

Epoch: 6| Step: 10
Training loss: 2.7464208602905273
Validation loss: 2.6214740327609483

Epoch: 6| Step: 11
Training loss: 2.9747486114501953
Validation loss: 2.5474387163756997

Epoch: 6| Step: 12
Training loss: 2.922816276550293
Validation loss: 2.523105308573733

Epoch: 6| Step: 13
Training loss: 3.335312604904175
Validation loss: 2.5075142537393877

Epoch: 54| Step: 0
Training loss: 2.8344357013702393
Validation loss: 2.4953057458323817

Epoch: 6| Step: 1
Training loss: 2.5820746421813965
Validation loss: 2.489451580150153

Epoch: 6| Step: 2
Training loss: 2.3267946243286133
Validation loss: 2.502295914516654

Epoch: 6| Step: 3
Training loss: 2.8644089698791504
Validation loss: 2.52930720134448

Epoch: 6| Step: 4
Training loss: 2.5385069847106934
Validation loss: 2.5763200354832474

Epoch: 6| Step: 5
Training loss: 2.6797196865081787
Validation loss: 2.535703420639038

Epoch: 6| Step: 6
Training loss: 2.6420650482177734
Validation loss: 2.5108988925974858

Epoch: 6| Step: 7
Training loss: 2.8580374717712402
Validation loss: 2.4938659539786716

Epoch: 6| Step: 8
Training loss: 2.7652316093444824
Validation loss: 2.489792864809754

Epoch: 6| Step: 9
Training loss: 3.5495052337646484
Validation loss: 2.4907003371946272

Epoch: 6| Step: 10
Training loss: 3.1373372077941895
Validation loss: 2.489363647276355

Epoch: 6| Step: 11
Training loss: 1.964982271194458
Validation loss: 2.492391324812366

Epoch: 6| Step: 12
Training loss: 2.2123374938964844
Validation loss: 2.4915705791083713

Epoch: 6| Step: 13
Training loss: 3.1051480770111084
Validation loss: 2.4923563029176448

Epoch: 55| Step: 0
Training loss: 3.5323452949523926
Validation loss: 2.49102024878225

Epoch: 6| Step: 1
Training loss: 2.014288902282715
Validation loss: 2.5007308221632436

Epoch: 6| Step: 2
Training loss: 2.074415683746338
Validation loss: 2.526987450097197

Epoch: 6| Step: 3
Training loss: 3.5467607975006104
Validation loss: 2.5466877901425926

Epoch: 6| Step: 4
Training loss: 2.6021108627319336
Validation loss: 2.5457687916294223

Epoch: 6| Step: 5
Training loss: 2.850839614868164
Validation loss: 2.5509480302051832

Epoch: 6| Step: 6
Training loss: 2.2963857650756836
Validation loss: 2.553054660879156

Epoch: 6| Step: 7
Training loss: 2.5443363189697266
Validation loss: 2.5472891587083057

Epoch: 6| Step: 8
Training loss: 2.465118885040283
Validation loss: 2.555162050390756

Epoch: 6| Step: 9
Training loss: 2.828070878982544
Validation loss: 2.5677229614667993

Epoch: 6| Step: 10
Training loss: 2.472884178161621
Validation loss: 2.550109855590328

Epoch: 6| Step: 11
Training loss: 2.8510801792144775
Validation loss: 2.531653781091013

Epoch: 6| Step: 12
Training loss: 3.652024507522583
Validation loss: 2.5287043561217604

Epoch: 6| Step: 13
Training loss: 2.2591052055358887
Validation loss: 2.5307389613120788

Epoch: 56| Step: 0
Training loss: 3.190504789352417
Validation loss: 2.531600780384515

Epoch: 6| Step: 1
Training loss: 2.5514817237854004
Validation loss: 2.5306279838726087

Epoch: 6| Step: 2
Training loss: 1.9501285552978516
Validation loss: 2.5271529254092964

Epoch: 6| Step: 3
Training loss: 3.1912872791290283
Validation loss: 2.5239060847989974

Epoch: 6| Step: 4
Training loss: 2.8633437156677246
Validation loss: 2.527361598066104

Epoch: 6| Step: 5
Training loss: 2.336961269378662
Validation loss: 2.5222391877123105

Epoch: 6| Step: 6
Training loss: 2.663816452026367
Validation loss: 2.5303338907098256

Epoch: 6| Step: 7
Training loss: 2.676853656768799
Validation loss: 2.5497163367527786

Epoch: 6| Step: 8
Training loss: 2.6856064796447754
Validation loss: 2.558140634208597

Epoch: 6| Step: 9
Training loss: 2.0433387756347656
Validation loss: 2.5403554106271393

Epoch: 6| Step: 10
Training loss: 2.8389835357666016
Validation loss: 2.5152046500995593

Epoch: 6| Step: 11
Training loss: 3.4258317947387695
Validation loss: 2.4927440638183267

Epoch: 6| Step: 12
Training loss: 2.8544154167175293
Validation loss: 2.4750622626273864

Epoch: 6| Step: 13
Training loss: 2.67283034324646
Validation loss: 2.468418578947744

Epoch: 57| Step: 0
Training loss: 2.4160616397857666
Validation loss: 2.468291780000092

Epoch: 6| Step: 1
Training loss: 2.925281524658203
Validation loss: 2.472809135272939

Epoch: 6| Step: 2
Training loss: 2.45878005027771
Validation loss: 2.4739996464021745

Epoch: 6| Step: 3
Training loss: 2.432574510574341
Validation loss: 2.4756966124298754

Epoch: 6| Step: 4
Training loss: 3.4498260021209717
Validation loss: 2.4734051740297707

Epoch: 6| Step: 5
Training loss: 2.2325150966644287
Validation loss: 2.469916538525653

Epoch: 6| Step: 6
Training loss: 2.3459019660949707
Validation loss: 2.470416315140263

Epoch: 6| Step: 7
Training loss: 2.625943183898926
Validation loss: 2.473480501482564

Epoch: 6| Step: 8
Training loss: 2.5192360877990723
Validation loss: 2.468281412637362

Epoch: 6| Step: 9
Training loss: 2.924776792526245
Validation loss: 2.4704931987229215

Epoch: 6| Step: 10
Training loss: 3.459395408630371
Validation loss: 2.4742892788302515

Epoch: 6| Step: 11
Training loss: 2.3145751953125
Validation loss: 2.474005071065759

Epoch: 6| Step: 12
Training loss: 2.518965721130371
Validation loss: 2.4771012054976596

Epoch: 6| Step: 13
Training loss: 3.3720037937164307
Validation loss: 2.478180044440813

Epoch: 58| Step: 0
Training loss: 2.1604528427124023
Validation loss: 2.4717002145705687

Epoch: 6| Step: 1
Training loss: 3.0609047412872314
Validation loss: 2.469526449839274

Epoch: 6| Step: 2
Training loss: 2.63728404045105
Validation loss: 2.4719189405441284

Epoch: 6| Step: 3
Training loss: 3.1855578422546387
Validation loss: 2.4698664501149166

Epoch: 6| Step: 4
Training loss: 2.748994827270508
Validation loss: 2.468795891731016

Epoch: 6| Step: 5
Training loss: 2.225799560546875
Validation loss: 2.4648171419738443

Epoch: 6| Step: 6
Training loss: 2.432795524597168
Validation loss: 2.4671845961642522

Epoch: 6| Step: 7
Training loss: 2.3530383110046387
Validation loss: 2.466812167116391

Epoch: 6| Step: 8
Training loss: 2.521852970123291
Validation loss: 2.470059517891176

Epoch: 6| Step: 9
Training loss: 3.417111873626709
Validation loss: 2.4667447766950055

Epoch: 6| Step: 10
Training loss: 2.920440673828125
Validation loss: 2.470987102036835

Epoch: 6| Step: 11
Training loss: 2.4036831855773926
Validation loss: 2.466391712106684

Epoch: 6| Step: 12
Training loss: 2.5485458374023438
Validation loss: 2.467633088429769

Epoch: 6| Step: 13
Training loss: 3.0034265518188477
Validation loss: 2.4660638891240603

Epoch: 59| Step: 0
Training loss: 2.465430736541748
Validation loss: 2.464449090342368

Epoch: 6| Step: 1
Training loss: 2.590916633605957
Validation loss: 2.463811182206677

Epoch: 6| Step: 2
Training loss: 2.5418756008148193
Validation loss: 2.4689663969060427

Epoch: 6| Step: 3
Training loss: 1.900816798210144
Validation loss: 2.464257529986802

Epoch: 6| Step: 4
Training loss: 3.2870264053344727
Validation loss: 2.4675480165789203

Epoch: 6| Step: 5
Training loss: 3.6514968872070312
Validation loss: 2.463440648971065

Epoch: 6| Step: 6
Training loss: 3.233109474182129
Validation loss: 2.4665506347533195

Epoch: 6| Step: 7
Training loss: 2.400123119354248
Validation loss: 2.4665672420173563

Epoch: 6| Step: 8
Training loss: 2.7117807865142822
Validation loss: 2.464451088700243

Epoch: 6| Step: 9
Training loss: 2.2620201110839844
Validation loss: 2.465138581491286

Epoch: 6| Step: 10
Training loss: 2.9659581184387207
Validation loss: 2.461954427021806

Epoch: 6| Step: 11
Training loss: 3.2640230655670166
Validation loss: 2.4589977866859845

Epoch: 6| Step: 12
Training loss: 1.9168113470077515
Validation loss: 2.4580566626723095

Epoch: 6| Step: 13
Training loss: 1.965343713760376
Validation loss: 2.4559545773331837

Epoch: 60| Step: 0
Training loss: 2.5022048950195312
Validation loss: 2.4567455527602986

Epoch: 6| Step: 1
Training loss: 3.085625648498535
Validation loss: 2.45135909511197

Epoch: 6| Step: 2
Training loss: 3.1846179962158203
Validation loss: 2.4554420542973343

Epoch: 6| Step: 3
Training loss: 2.5845658779144287
Validation loss: 2.451813349159815

Epoch: 6| Step: 4
Training loss: 2.6877493858337402
Validation loss: 2.452615955824493

Epoch: 6| Step: 5
Training loss: 2.4714832305908203
Validation loss: 2.457505759372506

Epoch: 6| Step: 6
Training loss: 2.7703702449798584
Validation loss: 2.4554406340404222

Epoch: 6| Step: 7
Training loss: 3.215080499649048
Validation loss: 2.455223419333017

Epoch: 6| Step: 8
Training loss: 3.1083078384399414
Validation loss: 2.4520601944256852

Epoch: 6| Step: 9
Training loss: 1.5468690395355225
Validation loss: 2.4492173194885254

Epoch: 6| Step: 10
Training loss: 2.846822738647461
Validation loss: 2.4476083760620444

Epoch: 6| Step: 11
Training loss: 2.4860944747924805
Validation loss: 2.4452654059215257

Epoch: 6| Step: 12
Training loss: 2.231733798980713
Validation loss: 2.4476491353845082

Epoch: 6| Step: 13
Training loss: 2.680894136428833
Validation loss: 2.4493317655337754

Epoch: 61| Step: 0
Training loss: 2.8624954223632812
Validation loss: 2.454683503796977

Epoch: 6| Step: 1
Training loss: 2.385221242904663
Validation loss: 2.4709257989801388

Epoch: 6| Step: 2
Training loss: 2.628067970275879
Validation loss: 2.4544578931664907

Epoch: 6| Step: 3
Training loss: 2.3237991333007812
Validation loss: 2.445064321640999

Epoch: 6| Step: 4
Training loss: 2.1942176818847656
Validation loss: 2.4433011983030584

Epoch: 6| Step: 5
Training loss: 4.00384521484375
Validation loss: 2.4447527162490355

Epoch: 6| Step: 6
Training loss: 2.707400321960449
Validation loss: 2.4538592753871793

Epoch: 6| Step: 7
Training loss: 2.199242353439331
Validation loss: 2.4588080119061213

Epoch: 6| Step: 8
Training loss: 1.9525108337402344
Validation loss: 2.476599657407371

Epoch: 6| Step: 9
Training loss: 3.0009350776672363
Validation loss: 2.4958404623052126

Epoch: 6| Step: 10
Training loss: 2.6712756156921387
Validation loss: 2.4733266984262774

Epoch: 6| Step: 11
Training loss: 2.695399522781372
Validation loss: 2.4556767837975615

Epoch: 6| Step: 12
Training loss: 2.695901870727539
Validation loss: 2.449606187881962

Epoch: 6| Step: 13
Training loss: 3.5856661796569824
Validation loss: 2.442284150790143

Epoch: 62| Step: 0
Training loss: 2.690884590148926
Validation loss: 2.4391621556333316

Epoch: 6| Step: 1
Training loss: 3.245120048522949
Validation loss: 2.436927000681559

Epoch: 6| Step: 2
Training loss: 2.843588352203369
Validation loss: 2.4316692890659457

Epoch: 6| Step: 3
Training loss: 3.503358840942383
Validation loss: 2.4320927871170865

Epoch: 6| Step: 4
Training loss: 2.1915431022644043
Validation loss: 2.431637889595442

Epoch: 6| Step: 5
Training loss: 2.389141321182251
Validation loss: 2.4397616232595136

Epoch: 6| Step: 6
Training loss: 3.000335693359375
Validation loss: 2.4435911716953402

Epoch: 6| Step: 7
Training loss: 1.790259838104248
Validation loss: 2.444369726283576

Epoch: 6| Step: 8
Training loss: 2.447199821472168
Validation loss: 2.4459722349720616

Epoch: 6| Step: 9
Training loss: 3.083442211151123
Validation loss: 2.4484223268365346

Epoch: 6| Step: 10
Training loss: 2.949368953704834
Validation loss: 2.4515758816913893

Epoch: 6| Step: 11
Training loss: 2.64285945892334
Validation loss: 2.450817649082471

Epoch: 6| Step: 12
Training loss: 2.006556749343872
Validation loss: 2.4409312971176638

Epoch: 6| Step: 13
Training loss: 2.6107287406921387
Validation loss: 2.4340569024444907

Epoch: 63| Step: 0
Training loss: 2.9308722019195557
Validation loss: 2.429697157234274

Epoch: 6| Step: 1
Training loss: 2.393829584121704
Validation loss: 2.4295898765646

Epoch: 6| Step: 2
Training loss: 2.252863645553589
Validation loss: 2.4248648740911998

Epoch: 6| Step: 3
Training loss: 2.402902126312256
Validation loss: 2.431154494644493

Epoch: 6| Step: 4
Training loss: 2.5497653484344482
Validation loss: 2.4287008803377867

Epoch: 6| Step: 5
Training loss: 2.817185878753662
Validation loss: 2.430912043458672

Epoch: 6| Step: 6
Training loss: 3.055159091949463
Validation loss: 2.428513947353568

Epoch: 6| Step: 7
Training loss: 2.0560896396636963
Validation loss: 2.4289637047757386

Epoch: 6| Step: 8
Training loss: 2.4238810539245605
Validation loss: 2.4228998281622447

Epoch: 6| Step: 9
Training loss: 3.3439202308654785
Validation loss: 2.418224078352733

Epoch: 6| Step: 10
Training loss: 2.4779610633850098
Validation loss: 2.4227059425846225

Epoch: 6| Step: 11
Training loss: 2.8632044792175293
Validation loss: 2.421580663291357

Epoch: 6| Step: 12
Training loss: 3.5321388244628906
Validation loss: 2.4198785238368536

Epoch: 6| Step: 13
Training loss: 1.697705864906311
Validation loss: 2.420462303264167

Epoch: 64| Step: 0
Training loss: 2.5588297843933105
Validation loss: 2.4225403211450063

Epoch: 6| Step: 1
Training loss: 3.043267250061035
Validation loss: 2.423376129519555

Epoch: 6| Step: 2
Training loss: 2.9957170486450195
Validation loss: 2.4229828567915064

Epoch: 6| Step: 3
Training loss: 2.9672892093658447
Validation loss: 2.4228301637916156

Epoch: 6| Step: 4
Training loss: 2.8130273818969727
Validation loss: 2.4205467777867473

Epoch: 6| Step: 5
Training loss: 2.788425922393799
Validation loss: 2.4263348041042203

Epoch: 6| Step: 6
Training loss: 2.7989814281463623
Validation loss: 2.430545389011342

Epoch: 6| Step: 7
Training loss: 2.2291877269744873
Validation loss: 2.4273267023025022

Epoch: 6| Step: 8
Training loss: 2.464799165725708
Validation loss: 2.479399693909512

Epoch: 6| Step: 9
Training loss: 2.2761826515197754
Validation loss: 2.564319061976607

Epoch: 6| Step: 10
Training loss: 2.310307264328003
Validation loss: 2.5556055012569634

Epoch: 6| Step: 11
Training loss: 2.248077869415283
Validation loss: 2.523680486986714

Epoch: 6| Step: 12
Training loss: 3.2250375747680664
Validation loss: 2.52387241137925

Epoch: 6| Step: 13
Training loss: 2.949185609817505
Validation loss: 2.5213698469182497

Epoch: 65| Step: 0
Training loss: 3.4283080101013184
Validation loss: 2.519429850321944

Epoch: 6| Step: 1
Training loss: 2.327455997467041
Validation loss: 2.5138889538344515

Epoch: 6| Step: 2
Training loss: 2.602114200592041
Validation loss: 2.511869148541522

Epoch: 6| Step: 3
Training loss: 3.2061767578125
Validation loss: 2.5099849188199608

Epoch: 6| Step: 4
Training loss: 2.806676149368286
Validation loss: 2.513288128760553

Epoch: 6| Step: 5
Training loss: 2.9067721366882324
Validation loss: 2.5108391161887877

Epoch: 6| Step: 6
Training loss: 2.808717727661133
Validation loss: 2.5044089312194497

Epoch: 6| Step: 7
Training loss: 2.5927562713623047
Validation loss: 2.4958752073267454

Epoch: 6| Step: 8
Training loss: 2.133512258529663
Validation loss: 2.4935480856126353

Epoch: 6| Step: 9
Training loss: 2.7187252044677734
Validation loss: 2.488711295589324

Epoch: 6| Step: 10
Training loss: 2.7330121994018555
Validation loss: 2.486519070081813

Epoch: 6| Step: 11
Training loss: 2.8919310569763184
Validation loss: 2.4877948017530542

Epoch: 6| Step: 12
Training loss: 2.0316152572631836
Validation loss: 2.492714520423643

Epoch: 6| Step: 13
Training loss: 2.546361207962036
Validation loss: 2.4931808415279595

Epoch: 66| Step: 0
Training loss: 2.9502716064453125
Validation loss: 2.4997278080191663

Epoch: 6| Step: 1
Training loss: 3.0590085983276367
Validation loss: 2.504297210324195

Epoch: 6| Step: 2
Training loss: 2.7162468433380127
Validation loss: 2.512837040808893

Epoch: 6| Step: 3
Training loss: 2.9114506244659424
Validation loss: 2.520124953280213

Epoch: 6| Step: 4
Training loss: 2.2834620475769043
Validation loss: 2.527167691979357

Epoch: 6| Step: 5
Training loss: 3.1756715774536133
Validation loss: 2.5364876639458442

Epoch: 6| Step: 6
Training loss: 2.451948642730713
Validation loss: 2.5395671449681765

Epoch: 6| Step: 7
Training loss: 2.206925392150879
Validation loss: 2.5160569555015972

Epoch: 6| Step: 8
Training loss: 2.9306881427764893
Validation loss: 2.490056648049303

Epoch: 6| Step: 9
Training loss: 2.3716468811035156
Validation loss: 2.483750694541521

Epoch: 6| Step: 10
Training loss: 2.6752147674560547
Validation loss: 2.4777174816336682

Epoch: 6| Step: 11
Training loss: 2.1268649101257324
Validation loss: 2.4830197031779955

Epoch: 6| Step: 12
Training loss: 2.8190722465515137
Validation loss: 2.4878822731715378

Epoch: 6| Step: 13
Training loss: 3.472968101501465
Validation loss: 2.4942944575381536

Epoch: 67| Step: 0
Training loss: 2.376649856567383
Validation loss: 2.495952690801313

Epoch: 6| Step: 1
Training loss: 3.168107509613037
Validation loss: 2.49005546621097

Epoch: 6| Step: 2
Training loss: 2.841984748840332
Validation loss: 2.4866398893376833

Epoch: 6| Step: 3
Training loss: 3.6378962993621826
Validation loss: 2.4771549958054737

Epoch: 6| Step: 4
Training loss: 2.311098098754883
Validation loss: 2.474549203790644

Epoch: 6| Step: 5
Training loss: 3.0584816932678223
Validation loss: 2.4773987313752532

Epoch: 6| Step: 6
Training loss: 2.4698166847229004
Validation loss: 2.4731473128000894

Epoch: 6| Step: 7
Training loss: 3.192931652069092
Validation loss: 2.474517055737075

Epoch: 6| Step: 8
Training loss: 3.094393730163574
Validation loss: 2.4720299910473567

Epoch: 6| Step: 9
Training loss: 2.4787912368774414
Validation loss: 2.47884605520515

Epoch: 6| Step: 10
Training loss: 2.5261332988739014
Validation loss: 2.484572584911059

Epoch: 6| Step: 11
Training loss: 2.9096662998199463
Validation loss: 2.4824298069041264

Epoch: 6| Step: 12
Training loss: 1.3009607791900635
Validation loss: 2.48112569573105

Epoch: 6| Step: 13
Training loss: 1.8361544609069824
Validation loss: 2.4880607820326284

Epoch: 68| Step: 0
Training loss: 2.940668821334839
Validation loss: 2.4798234585792787

Epoch: 6| Step: 1
Training loss: 2.3181772232055664
Validation loss: 2.468454078961444

Epoch: 6| Step: 2
Training loss: 2.0278143882751465
Validation loss: 2.4698978060035297

Epoch: 6| Step: 3
Training loss: 2.69393253326416
Validation loss: 2.4784561485372563

Epoch: 6| Step: 4
Training loss: 2.3856563568115234
Validation loss: 2.471358194146105

Epoch: 6| Step: 5
Training loss: 2.1902809143066406
Validation loss: 2.4687624951844573

Epoch: 6| Step: 6
Training loss: 2.267235279083252
Validation loss: 2.474055810641217

Epoch: 6| Step: 7
Training loss: 2.520874500274658
Validation loss: 2.5123683098823792

Epoch: 6| Step: 8
Training loss: 3.5867068767547607
Validation loss: 2.497196198791586

Epoch: 6| Step: 9
Training loss: 2.7361505031585693
Validation loss: 2.481285746379565

Epoch: 6| Step: 10
Training loss: 2.3731322288513184
Validation loss: 2.4730540860083794

Epoch: 6| Step: 11
Training loss: 3.722417116165161
Validation loss: 2.4756307858292774

Epoch: 6| Step: 12
Training loss: 2.942608118057251
Validation loss: 2.466943940808696

Epoch: 6| Step: 13
Training loss: 2.8246054649353027
Validation loss: 2.468516570265575

Epoch: 69| Step: 0
Training loss: 2.849581718444824
Validation loss: 2.4664738819163334

Epoch: 6| Step: 1
Training loss: 2.419184684753418
Validation loss: 2.4596771655544156

Epoch: 6| Step: 2
Training loss: 2.468670129776001
Validation loss: 2.4608916057053434

Epoch: 6| Step: 3
Training loss: 2.4549660682678223
Validation loss: 2.4581915332425024

Epoch: 6| Step: 4
Training loss: 3.548921823501587
Validation loss: 2.456692977618146

Epoch: 6| Step: 5
Training loss: 2.096229314804077
Validation loss: 2.458043577850506

Epoch: 6| Step: 6
Training loss: 3.384697675704956
Validation loss: 2.4631355706081597

Epoch: 6| Step: 7
Training loss: 2.2564425468444824
Validation loss: 2.465526520564992

Epoch: 6| Step: 8
Training loss: 3.2003281116485596
Validation loss: 2.4633175096204205

Epoch: 6| Step: 9
Training loss: 3.058622360229492
Validation loss: 2.4602653313708562

Epoch: 6| Step: 10
Training loss: 2.5394582748413086
Validation loss: 2.458976780214617

Epoch: 6| Step: 11
Training loss: 2.629505157470703
Validation loss: 2.4546794558084137

Epoch: 6| Step: 12
Training loss: 2.0011730194091797
Validation loss: 2.4531645518477245

Epoch: 6| Step: 13
Training loss: 2.5474889278411865
Validation loss: 2.4497628199156893

Epoch: 70| Step: 0
Training loss: 2.3873448371887207
Validation loss: 2.4485282923585627

Epoch: 6| Step: 1
Training loss: 2.6874961853027344
Validation loss: 2.4514711390259447

Epoch: 6| Step: 2
Training loss: 2.911405563354492
Validation loss: 2.4507781895258094

Epoch: 6| Step: 3
Training loss: 2.40165376663208
Validation loss: 2.454849366218813

Epoch: 6| Step: 4
Training loss: 2.6666219234466553
Validation loss: 2.448687186805151

Epoch: 6| Step: 5
Training loss: 3.273493528366089
Validation loss: 2.449905933872346

Epoch: 6| Step: 6
Training loss: 2.5722994804382324
Validation loss: 2.448885322898947

Epoch: 6| Step: 7
Training loss: 2.578181743621826
Validation loss: 2.4481867244166713

Epoch: 6| Step: 8
Training loss: 3.551917552947998
Validation loss: 2.450860579808553

Epoch: 6| Step: 9
Training loss: 2.3646397590637207
Validation loss: 2.450267340547295

Epoch: 6| Step: 10
Training loss: 2.1612582206726074
Validation loss: 2.4522503550334642

Epoch: 6| Step: 11
Training loss: 2.468891143798828
Validation loss: 2.4584248245403333

Epoch: 6| Step: 12
Training loss: 2.8266375064849854
Validation loss: 2.4640450195599626

Epoch: 6| Step: 13
Training loss: 2.443883180618286
Validation loss: 2.4734402292518207

Epoch: 71| Step: 0
Training loss: 1.4993178844451904
Validation loss: 2.479171040237591

Epoch: 6| Step: 1
Training loss: 2.062720537185669
Validation loss: 2.487147743983935

Epoch: 6| Step: 2
Training loss: 2.5962464809417725
Validation loss: 2.5018116812552176

Epoch: 6| Step: 3
Training loss: 3.8800036907196045
Validation loss: 2.513592517504128

Epoch: 6| Step: 4
Training loss: 3.4479522705078125
Validation loss: 2.519202214415355

Epoch: 6| Step: 5
Training loss: 2.108555555343628
Validation loss: 2.508370171311081

Epoch: 6| Step: 6
Training loss: 2.305532932281494
Validation loss: 2.4845775263283842

Epoch: 6| Step: 7
Training loss: 2.578749179840088
Validation loss: 2.4701026537085093

Epoch: 6| Step: 8
Training loss: 3.403794765472412
Validation loss: 2.4514524116311023

Epoch: 6| Step: 9
Training loss: 2.5817618370056152
Validation loss: 2.4488314992638043

Epoch: 6| Step: 10
Training loss: 3.5259108543395996
Validation loss: 2.4538061593168523

Epoch: 6| Step: 11
Training loss: 2.5922441482543945
Validation loss: 2.464245992322122

Epoch: 6| Step: 12
Training loss: 1.8839882612228394
Validation loss: 2.4676571148698048

Epoch: 6| Step: 13
Training loss: 3.3853602409362793
Validation loss: 2.461418903002175

Epoch: 72| Step: 0
Training loss: 2.9287240505218506
Validation loss: 2.4588487725104056

Epoch: 6| Step: 1
Training loss: 2.5657405853271484
Validation loss: 2.4533036626795286

Epoch: 6| Step: 2
Training loss: 2.3501029014587402
Validation loss: 2.4491746502537883

Epoch: 6| Step: 3
Training loss: 2.9699721336364746
Validation loss: 2.4425127429346882

Epoch: 6| Step: 4
Training loss: 2.7999181747436523
Validation loss: 2.44751617985387

Epoch: 6| Step: 5
Training loss: 2.557121515274048
Validation loss: 2.4478724413020636

Epoch: 6| Step: 6
Training loss: 2.7050700187683105
Validation loss: 2.4492170015970864

Epoch: 6| Step: 7
Training loss: 2.737025737762451
Validation loss: 2.446765991949266

Epoch: 6| Step: 8
Training loss: 2.32163405418396
Validation loss: 2.4337962571010796

Epoch: 6| Step: 9
Training loss: 2.0457472801208496
Validation loss: 2.427408515766103

Epoch: 6| Step: 10
Training loss: 2.8666200637817383
Validation loss: 2.431877336194438

Epoch: 6| Step: 11
Training loss: 2.7754411697387695
Validation loss: 2.44405262700973

Epoch: 6| Step: 12
Training loss: 2.6872572898864746
Validation loss: 2.455911082606162

Epoch: 6| Step: 13
Training loss: 3.3860013484954834
Validation loss: 2.464636368136252

Epoch: 73| Step: 0
Training loss: 2.80955171585083
Validation loss: 2.477267303774434

Epoch: 6| Step: 1
Training loss: 1.676093578338623
Validation loss: 2.457100365751533

Epoch: 6| Step: 2
Training loss: 2.2187280654907227
Validation loss: 2.44451400028762

Epoch: 6| Step: 3
Training loss: 3.049859046936035
Validation loss: 2.4240330085959485

Epoch: 6| Step: 4
Training loss: 2.5548505783081055
Validation loss: 2.4184671294304634

Epoch: 6| Step: 5
Training loss: 2.683075428009033
Validation loss: 2.4134126376080256

Epoch: 6| Step: 6
Training loss: 3.6084940433502197
Validation loss: 2.416115035292923

Epoch: 6| Step: 7
Training loss: 2.7593724727630615
Validation loss: 2.4176772563688216

Epoch: 6| Step: 8
Training loss: 1.900545358657837
Validation loss: 2.4208014165201495

Epoch: 6| Step: 9
Training loss: 3.4772467613220215
Validation loss: 2.4137691092747513

Epoch: 6| Step: 10
Training loss: 2.981675148010254
Validation loss: 2.4175731289771294

Epoch: 6| Step: 11
Training loss: 1.9490264654159546
Validation loss: 2.4218479664094987

Epoch: 6| Step: 12
Training loss: 2.906959295272827
Validation loss: 2.4227034866168933

Epoch: 6| Step: 13
Training loss: 2.7926101684570312
Validation loss: 2.4187674932582404

Epoch: 74| Step: 0
Training loss: 2.2478458881378174
Validation loss: 2.4192730893370924

Epoch: 6| Step: 1
Training loss: 2.9491710662841797
Validation loss: 2.434019757855323

Epoch: 6| Step: 2
Training loss: 2.9672317504882812
Validation loss: 2.448764237024451

Epoch: 6| Step: 3
Training loss: 2.783982276916504
Validation loss: 2.4399181899204048

Epoch: 6| Step: 4
Training loss: 2.867609739303589
Validation loss: 2.4422918917030416

Epoch: 6| Step: 5
Training loss: 1.9458956718444824
Validation loss: 2.442250523515927

Epoch: 6| Step: 6
Training loss: 2.666874647140503
Validation loss: 2.4421295376234156

Epoch: 6| Step: 7
Training loss: 2.5065855979919434
Validation loss: 2.4405975931434223

Epoch: 6| Step: 8
Training loss: 2.107173442840576
Validation loss: 2.4339937958666074

Epoch: 6| Step: 9
Training loss: 3.1854190826416016
Validation loss: 2.4348290248583724

Epoch: 6| Step: 10
Training loss: 2.944474935531616
Validation loss: 2.4234626113727527

Epoch: 6| Step: 11
Training loss: 2.8573598861694336
Validation loss: 2.423666020875336

Epoch: 6| Step: 12
Training loss: 2.397594451904297
Validation loss: 2.4118787191247426

Epoch: 6| Step: 13
Training loss: 2.7163243293762207
Validation loss: 2.410763514939175

Epoch: 75| Step: 0
Training loss: 2.4904589653015137
Validation loss: 2.399188498015045

Epoch: 6| Step: 1
Training loss: 2.59879732131958
Validation loss: 2.349263273259645

Epoch: 6| Step: 2
Training loss: 2.396153450012207
Validation loss: 2.344164735527449

Epoch: 6| Step: 3
Training loss: 2.396003007888794
Validation loss: 2.345924849151283

Epoch: 6| Step: 4
Training loss: 3.5562734603881836
Validation loss: 2.347717046737671

Epoch: 6| Step: 5
Training loss: 3.061051845550537
Validation loss: 2.3377802192523913

Epoch: 6| Step: 6
Training loss: 2.7760956287384033
Validation loss: 2.3548409502993346

Epoch: 6| Step: 7
Training loss: 2.683622360229492
Validation loss: 2.3285364873947634

Epoch: 6| Step: 8
Training loss: 2.4507150650024414
Validation loss: 2.3328577959409325

Epoch: 6| Step: 9
Training loss: 2.3832521438598633
Validation loss: 2.341114218517016

Epoch: 6| Step: 10
Training loss: 2.5966031551361084
Validation loss: 2.3475226074136715

Epoch: 6| Step: 11
Training loss: 1.9832228422164917
Validation loss: 2.3524771185331446

Epoch: 6| Step: 12
Training loss: 2.636174201965332
Validation loss: 2.350266046421502

Epoch: 6| Step: 13
Training loss: 2.62965726852417
Validation loss: 2.3603586637845604

Epoch: 76| Step: 0
Training loss: 3.072136878967285
Validation loss: 2.356409019039523

Epoch: 6| Step: 1
Training loss: 2.992612838745117
Validation loss: 2.355531838632399

Epoch: 6| Step: 2
Training loss: 2.860243797302246
Validation loss: 2.342539095109509

Epoch: 6| Step: 3
Training loss: 2.9150032997131348
Validation loss: 2.346745898646693

Epoch: 6| Step: 4
Training loss: 2.4998397827148438
Validation loss: 2.3430311192748365

Epoch: 6| Step: 5
Training loss: 1.9399898052215576
Validation loss: 2.346204811526883

Epoch: 6| Step: 6
Training loss: 2.307034969329834
Validation loss: 2.342883330519481

Epoch: 6| Step: 7
Training loss: 2.313754081726074
Validation loss: 2.33859186275031

Epoch: 6| Step: 8
Training loss: 2.7560346126556396
Validation loss: 2.331957288967666

Epoch: 6| Step: 9
Training loss: 2.4088711738586426
Validation loss: 2.325145967545048

Epoch: 6| Step: 10
Training loss: 2.661616563796997
Validation loss: 2.329682186085691

Epoch: 6| Step: 11
Training loss: 3.273658275604248
Validation loss: 2.3264808859876407

Epoch: 6| Step: 12
Training loss: 2.0497024059295654
Validation loss: 2.3267330584987516

Epoch: 6| Step: 13
Training loss: 2.403813123703003
Validation loss: 2.3268203299532653

Epoch: 77| Step: 0
Training loss: 2.732573986053467
Validation loss: 2.324985101658811

Epoch: 6| Step: 1
Training loss: 1.9011578559875488
Validation loss: 2.322681082192288

Epoch: 6| Step: 2
Training loss: 2.8785181045532227
Validation loss: 2.31956079442014

Epoch: 6| Step: 3
Training loss: 2.647451877593994
Validation loss: 2.3263664604515157

Epoch: 6| Step: 4
Training loss: 2.507634162902832
Validation loss: 2.3228498299916587

Epoch: 6| Step: 5
Training loss: 2.76473069190979
Validation loss: 2.326205604819841

Epoch: 6| Step: 6
Training loss: 2.3776113986968994
Validation loss: 2.32146615623146

Epoch: 6| Step: 7
Training loss: 2.5265040397644043
Validation loss: 2.3213207362800516

Epoch: 6| Step: 8
Training loss: 2.3322956562042236
Validation loss: 2.3205609424139864

Epoch: 6| Step: 9
Training loss: 2.728398323059082
Validation loss: 2.3234064758464856

Epoch: 6| Step: 10
Training loss: 3.344489097595215
Validation loss: 2.3227936734435377

Epoch: 6| Step: 11
Training loss: 2.911736249923706
Validation loss: 2.3254237174987793

Epoch: 6| Step: 12
Training loss: 2.691187858581543
Validation loss: 2.329715598014093

Epoch: 6| Step: 13
Training loss: 2.08625864982605
Validation loss: 2.328474852346605

Epoch: 78| Step: 0
Training loss: 2.5990371704101562
Validation loss: 2.3278170016504105

Epoch: 6| Step: 1
Training loss: 2.122897148132324
Validation loss: 2.326424426929925

Epoch: 6| Step: 2
Training loss: 2.4719231128692627
Validation loss: 2.332657467934393

Epoch: 6| Step: 3
Training loss: 3.0046181678771973
Validation loss: 2.339568268868231

Epoch: 6| Step: 4
Training loss: 1.9957865476608276
Validation loss: 2.3374564340037685

Epoch: 6| Step: 5
Training loss: 2.850161075592041
Validation loss: 2.3410158208621445

Epoch: 6| Step: 6
Training loss: 1.8697543144226074
Validation loss: 2.333822919476417

Epoch: 6| Step: 7
Training loss: 2.4317197799682617
Validation loss: 2.3319799515508834

Epoch: 6| Step: 8
Training loss: 2.5580244064331055
Validation loss: 2.3232359681078183

Epoch: 6| Step: 9
Training loss: 2.828815460205078
Validation loss: 2.3264546035438456

Epoch: 6| Step: 10
Training loss: 2.972607135772705
Validation loss: 2.3266401060165895

Epoch: 6| Step: 11
Training loss: 2.684018611907959
Validation loss: 2.3246449578192925

Epoch: 6| Step: 12
Training loss: 3.699350357055664
Validation loss: 2.322511916519493

Epoch: 6| Step: 13
Training loss: 2.010037422180176
Validation loss: 2.3185295827927126

Epoch: 79| Step: 0
Training loss: 2.0231544971466064
Validation loss: 2.3197678827470347

Epoch: 6| Step: 1
Training loss: 2.527268886566162
Validation loss: 2.3172121688883793

Epoch: 6| Step: 2
Training loss: 2.218214511871338
Validation loss: 2.318466305732727

Epoch: 6| Step: 3
Training loss: 2.925469160079956
Validation loss: 2.3225315104248705

Epoch: 6| Step: 4
Training loss: 3.035727024078369
Validation loss: 2.3269429411939395

Epoch: 6| Step: 5
Training loss: 3.075427770614624
Validation loss: 2.35252724155303

Epoch: 6| Step: 6
Training loss: 2.4423632621765137
Validation loss: 2.35745563942899

Epoch: 6| Step: 7
Training loss: 2.611060619354248
Validation loss: 2.37145056263093

Epoch: 6| Step: 8
Training loss: 2.0130720138549805
Validation loss: 2.3564482273594027

Epoch: 6| Step: 9
Training loss: 2.808846950531006
Validation loss: 2.337251042806974

Epoch: 6| Step: 10
Training loss: 3.297832489013672
Validation loss: 2.326291876454507

Epoch: 6| Step: 11
Training loss: 2.4725472927093506
Validation loss: 2.318194902071389

Epoch: 6| Step: 12
Training loss: 2.9216930866241455
Validation loss: 2.3143665277829735

Epoch: 6| Step: 13
Training loss: 1.87113356590271
Validation loss: 2.3241368852635866

Epoch: 80| Step: 0
Training loss: 3.0594253540039062
Validation loss: 2.3426930968479445

Epoch: 6| Step: 1
Training loss: 2.174375534057617
Validation loss: 2.3568235379393383

Epoch: 6| Step: 2
Training loss: 2.982741117477417
Validation loss: 2.3606265334672827

Epoch: 6| Step: 3
Training loss: 2.3879358768463135
Validation loss: 2.33573813848598

Epoch: 6| Step: 4
Training loss: 2.4976229667663574
Validation loss: 2.3251803869842202

Epoch: 6| Step: 5
Training loss: 2.5874741077423096
Validation loss: 2.311675912590437

Epoch: 6| Step: 6
Training loss: 2.7576613426208496
Validation loss: 2.3079780122285247

Epoch: 6| Step: 7
Training loss: 2.059523820877075
Validation loss: 2.2993317829665316

Epoch: 6| Step: 8
Training loss: 2.2176108360290527
Validation loss: 2.304291671322238

Epoch: 6| Step: 9
Training loss: 2.5397181510925293
Validation loss: 2.305755333233905

Epoch: 6| Step: 10
Training loss: 2.585998773574829
Validation loss: 2.3053559000774095

Epoch: 6| Step: 11
Training loss: 2.831089973449707
Validation loss: 2.3106253941853843

Epoch: 6| Step: 12
Training loss: 3.115950107574463
Validation loss: 2.3205122076055056

Epoch: 6| Step: 13
Training loss: 2.68275785446167
Validation loss: 2.3559660578286774

Epoch: 81| Step: 0
Training loss: 2.0536532402038574
Validation loss: 2.3338801809536514

Epoch: 6| Step: 1
Training loss: 2.3482770919799805
Validation loss: 2.303294640715404

Epoch: 6| Step: 2
Training loss: 2.433238983154297
Validation loss: 2.300293432768955

Epoch: 6| Step: 3
Training loss: 2.422365188598633
Validation loss: 2.3015907810580347

Epoch: 6| Step: 4
Training loss: 2.218447208404541
Validation loss: 2.299092661949896

Epoch: 6| Step: 5
Training loss: 2.4004440307617188
Validation loss: 2.2985494982811714

Epoch: 6| Step: 6
Training loss: 2.4674625396728516
Validation loss: 2.3004431237456617

Epoch: 6| Step: 7
Training loss: 1.9832520484924316
Validation loss: 2.2995589958724154

Epoch: 6| Step: 8
Training loss: 2.8879311084747314
Validation loss: 2.2969785992817213

Epoch: 6| Step: 9
Training loss: 3.284322500228882
Validation loss: 2.3074741645525862

Epoch: 6| Step: 10
Training loss: 2.4506096839904785
Validation loss: 2.330592604093654

Epoch: 6| Step: 11
Training loss: 3.174975872039795
Validation loss: 2.345360694393035

Epoch: 6| Step: 12
Training loss: 2.9185643196105957
Validation loss: 2.3573718660621235

Epoch: 6| Step: 13
Training loss: 3.78644061088562
Validation loss: 2.379195149226855

Epoch: 82| Step: 0
Training loss: 1.500624418258667
Validation loss: 2.365338312682285

Epoch: 6| Step: 1
Training loss: 2.7348358631134033
Validation loss: 2.3475746365003687

Epoch: 6| Step: 2
Training loss: 2.7084715366363525
Validation loss: 2.3485553854255268

Epoch: 6| Step: 3
Training loss: 2.1324050426483154
Validation loss: 2.328427783904537

Epoch: 6| Step: 4
Training loss: 2.2199480533599854
Validation loss: 2.3155661295819026

Epoch: 6| Step: 5
Training loss: 2.9242730140686035
Validation loss: 2.309710007841869

Epoch: 6| Step: 6
Training loss: 2.529517650604248
Validation loss: 2.2964909922692085

Epoch: 6| Step: 7
Training loss: 2.5764899253845215
Validation loss: 2.2928905153787262

Epoch: 6| Step: 8
Training loss: 3.4868407249450684
Validation loss: 2.2980328913657897

Epoch: 6| Step: 9
Training loss: 2.476815700531006
Validation loss: 2.2876543332171697

Epoch: 6| Step: 10
Training loss: 2.770554542541504
Validation loss: 2.2905235854528283

Epoch: 6| Step: 11
Training loss: 2.947033405303955
Validation loss: 2.292531669780772

Epoch: 6| Step: 12
Training loss: 2.80826997756958
Validation loss: 2.295605746648645

Epoch: 6| Step: 13
Training loss: 2.362993001937866
Validation loss: 2.2985187756117953

Epoch: 83| Step: 0
Training loss: 2.532108783721924
Validation loss: 2.302632285702613

Epoch: 6| Step: 1
Training loss: 2.539015531539917
Validation loss: 2.3022177168118056

Epoch: 6| Step: 2
Training loss: 1.892066478729248
Validation loss: 2.317342153159521

Epoch: 6| Step: 3
Training loss: 2.798779249191284
Validation loss: 2.3225259268155662

Epoch: 6| Step: 4
Training loss: 2.5037548542022705
Validation loss: 2.3194785502649125

Epoch: 6| Step: 5
Training loss: 2.264961004257202
Validation loss: 2.3210634287967475

Epoch: 6| Step: 6
Training loss: 2.5202925205230713
Validation loss: 2.3280265792723625

Epoch: 6| Step: 7
Training loss: 3.061962842941284
Validation loss: 2.3245823562786145

Epoch: 6| Step: 8
Training loss: 3.234060764312744
Validation loss: 2.3121711054155902

Epoch: 6| Step: 9
Training loss: 2.460148334503174
Validation loss: 2.2960030955653035

Epoch: 6| Step: 10
Training loss: 2.573789119720459
Validation loss: 2.287432796211653

Epoch: 6| Step: 11
Training loss: 2.372960090637207
Validation loss: 2.2810497847936486

Epoch: 6| Step: 12
Training loss: 3.088791847229004
Validation loss: 2.287231174848413

Epoch: 6| Step: 13
Training loss: 2.086333751678467
Validation loss: 2.2877745320720058

Epoch: 84| Step: 0
Training loss: 2.0371475219726562
Validation loss: 2.292760246543474

Epoch: 6| Step: 1
Training loss: 2.2474379539489746
Validation loss: 2.290065678217078

Epoch: 6| Step: 2
Training loss: 2.9207448959350586
Validation loss: 2.287856945427515

Epoch: 6| Step: 3
Training loss: 2.755706787109375
Validation loss: 2.2888931971724316

Epoch: 6| Step: 4
Training loss: 3.0694494247436523
Validation loss: 2.2878046497221916

Epoch: 6| Step: 5
Training loss: 2.9750306606292725
Validation loss: 2.288789141562677

Epoch: 6| Step: 6
Training loss: 2.384209156036377
Validation loss: 2.2882494875179824

Epoch: 6| Step: 7
Training loss: 2.324179172515869
Validation loss: 2.2884445292975313

Epoch: 6| Step: 8
Training loss: 1.9814987182617188
Validation loss: 2.28633104601214

Epoch: 6| Step: 9
Training loss: 2.936394214630127
Validation loss: 2.2852174082110004

Epoch: 6| Step: 10
Training loss: 2.753756523132324
Validation loss: 2.281128260397142

Epoch: 6| Step: 11
Training loss: 2.904858350753784
Validation loss: 2.2833420230496313

Epoch: 6| Step: 12
Training loss: 2.57102632522583
Validation loss: 2.2790582820933354

Epoch: 6| Step: 13
Training loss: 2.015057325363159
Validation loss: 2.2942738225383144

Epoch: 85| Step: 0
Training loss: 2.471892833709717
Validation loss: 2.3206285789448726

Epoch: 6| Step: 1
Training loss: 2.0515403747558594
Validation loss: 2.346063583127914

Epoch: 6| Step: 2
Training loss: 2.274674892425537
Validation loss: 2.4174841450106714

Epoch: 6| Step: 3
Training loss: 3.2138795852661133
Validation loss: 2.4012533003284084

Epoch: 6| Step: 4
Training loss: 2.288325786590576
Validation loss: 2.3345103956037954

Epoch: 6| Step: 5
Training loss: 3.3283944129943848
Validation loss: 2.3020151661288355

Epoch: 6| Step: 6
Training loss: 3.398207902908325
Validation loss: 2.2774361384812223

Epoch: 6| Step: 7
Training loss: 2.6844849586486816
Validation loss: 2.276852253944643

Epoch: 6| Step: 8
Training loss: 2.599368095397949
Validation loss: 2.2796470375471216

Epoch: 6| Step: 9
Training loss: 2.603170156478882
Validation loss: 2.2988310731867307

Epoch: 6| Step: 10
Training loss: 2.321298837661743
Validation loss: 2.3129072778968403

Epoch: 6| Step: 11
Training loss: 1.7624213695526123
Validation loss: 2.326975599411995

Epoch: 6| Step: 12
Training loss: 2.775360107421875
Validation loss: 2.37936342916181

Epoch: 6| Step: 13
Training loss: 3.2532193660736084
Validation loss: 2.408362957739061

Epoch: 86| Step: 0
Training loss: 3.235383987426758
Validation loss: 2.3914322314723844

Epoch: 6| Step: 1
Training loss: 2.631141185760498
Validation loss: 2.393603632527013

Epoch: 6| Step: 2
Training loss: 2.832984447479248
Validation loss: 2.3763450666140487

Epoch: 6| Step: 3
Training loss: 2.6258251667022705
Validation loss: 2.3554235581428773

Epoch: 6| Step: 4
Training loss: 2.0814342498779297
Validation loss: 2.3430707634136243

Epoch: 6| Step: 5
Training loss: 2.255767345428467
Validation loss: 2.341900522990893

Epoch: 6| Step: 6
Training loss: 2.2983570098876953
Validation loss: 2.3667133546644643

Epoch: 6| Step: 7
Training loss: 2.579922914505005
Validation loss: 2.3999065250478764

Epoch: 6| Step: 8
Training loss: 3.057168960571289
Validation loss: 2.4127883526586715

Epoch: 6| Step: 9
Training loss: 2.029219150543213
Validation loss: 2.4175134935686664

Epoch: 6| Step: 10
Training loss: 2.441666603088379
Validation loss: 2.4162107898342993

Epoch: 6| Step: 11
Training loss: 2.8256635665893555
Validation loss: 2.424320167110812

Epoch: 6| Step: 12
Training loss: 3.199627637863159
Validation loss: 2.427749031333513

Epoch: 6| Step: 13
Training loss: 2.5610687732696533
Validation loss: 2.411730271513744

Epoch: 87| Step: 0
Training loss: 2.2307937145233154
Validation loss: 2.392966285828621

Epoch: 6| Step: 1
Training loss: 2.4962399005889893
Validation loss: 2.3631248474121094

Epoch: 6| Step: 2
Training loss: 2.650346517562866
Validation loss: 2.3484234527875016

Epoch: 6| Step: 3
Training loss: 2.739414691925049
Validation loss: 2.344418623114145

Epoch: 6| Step: 4
Training loss: 2.489551544189453
Validation loss: 2.3406049128501647

Epoch: 6| Step: 5
Training loss: 2.525991678237915
Validation loss: 2.333570675183368

Epoch: 6| Step: 6
Training loss: 3.000910758972168
Validation loss: 2.3296307543272614

Epoch: 6| Step: 7
Training loss: 2.3800482749938965
Validation loss: 2.3286926041367235

Epoch: 6| Step: 8
Training loss: 2.840669631958008
Validation loss: 2.3651269738392164

Epoch: 6| Step: 9
Training loss: 2.6503100395202637
Validation loss: 2.3899497062929216

Epoch: 6| Step: 10
Training loss: 2.885770559310913
Validation loss: 2.40416790593055

Epoch: 6| Step: 11
Training loss: 2.2808055877685547
Validation loss: 2.4118566602788944

Epoch: 6| Step: 12
Training loss: 2.8176116943359375
Validation loss: 2.412858442593646

Epoch: 6| Step: 13
Training loss: 2.7153286933898926
Validation loss: 2.3968706900073635

Epoch: 88| Step: 0
Training loss: 2.1026406288146973
Validation loss: 2.381856378688607

Epoch: 6| Step: 1
Training loss: 2.8372769355773926
Validation loss: 2.380804702799807

Epoch: 6| Step: 2
Training loss: 1.7279528379440308
Validation loss: 2.381457649251466

Epoch: 6| Step: 3
Training loss: 2.9749906063079834
Validation loss: 2.3842726984331684

Epoch: 6| Step: 4
Training loss: 3.0801453590393066
Validation loss: 2.3908492877919185

Epoch: 6| Step: 5
Training loss: 3.328822374343872
Validation loss: 2.3989314520230858

Epoch: 6| Step: 6
Training loss: 2.82529878616333
Validation loss: 2.3989075409468783

Epoch: 6| Step: 7
Training loss: 1.5884939432144165
Validation loss: 2.4034005595791723

Epoch: 6| Step: 8
Training loss: 2.518596887588501
Validation loss: 2.4149820343140633

Epoch: 6| Step: 9
Training loss: 2.6769986152648926
Validation loss: 2.4229148177690405

Epoch: 6| Step: 10
Training loss: 2.627521514892578
Validation loss: 2.394370227731684

Epoch: 6| Step: 11
Training loss: 3.1268091201782227
Validation loss: 2.390974483182353

Epoch: 6| Step: 12
Training loss: 2.7738890647888184
Validation loss: 2.3637033072851037

Epoch: 6| Step: 13
Training loss: 2.3985257148742676
Validation loss: 2.358670965317757

Epoch: 89| Step: 0
Training loss: 2.811122179031372
Validation loss: 2.358665471435875

Epoch: 6| Step: 1
Training loss: 2.7200300693511963
Validation loss: 2.365128891442412

Epoch: 6| Step: 2
Training loss: 2.953223943710327
Validation loss: 2.3711159280551377

Epoch: 6| Step: 3
Training loss: 2.155163526535034
Validation loss: 2.380200165574269

Epoch: 6| Step: 4
Training loss: 2.942775249481201
Validation loss: 2.387031123202334

Epoch: 6| Step: 5
Training loss: 2.808600425720215
Validation loss: 2.3837373307956162

Epoch: 6| Step: 6
Training loss: 2.6787540912628174
Validation loss: 2.361727770938668

Epoch: 6| Step: 7
Training loss: 1.671992540359497
Validation loss: 2.335101568570701

Epoch: 6| Step: 8
Training loss: 2.8343286514282227
Validation loss: 2.299076659705049

Epoch: 6| Step: 9
Training loss: 1.7000545263290405
Validation loss: 2.289766880773729

Epoch: 6| Step: 10
Training loss: 3.339362144470215
Validation loss: 2.290732693928544

Epoch: 6| Step: 11
Training loss: 2.083545207977295
Validation loss: 2.2960201258300454

Epoch: 6| Step: 12
Training loss: 2.447007417678833
Validation loss: 2.3020800416187575

Epoch: 6| Step: 13
Training loss: 3.225412607192993
Validation loss: 2.2681903172564764

Epoch: 90| Step: 0
Training loss: 2.2901082038879395
Validation loss: 2.260795993189658

Epoch: 6| Step: 1
Training loss: 3.0313720703125
Validation loss: 2.263101754649993

Epoch: 6| Step: 2
Training loss: 2.4431679248809814
Validation loss: 2.259498360336468

Epoch: 6| Step: 3
Training loss: 1.5766899585723877
Validation loss: 2.262168656113327

Epoch: 6| Step: 4
Training loss: 3.19549560546875
Validation loss: 2.256327131743072

Epoch: 6| Step: 5
Training loss: 2.440826416015625
Validation loss: 2.26337085488022

Epoch: 6| Step: 6
Training loss: 2.6270742416381836
Validation loss: 2.2558928356375745

Epoch: 6| Step: 7
Training loss: 2.331974983215332
Validation loss: 2.251081725602509

Epoch: 6| Step: 8
Training loss: 2.1986677646636963
Validation loss: 2.245159669588971

Epoch: 6| Step: 9
Training loss: 2.464792013168335
Validation loss: 2.2421629839046027

Epoch: 6| Step: 10
Training loss: 2.548776626586914
Validation loss: 2.250499230559154

Epoch: 6| Step: 11
Training loss: 2.566061496734619
Validation loss: 2.2737762543462936

Epoch: 6| Step: 12
Training loss: 3.3812713623046875
Validation loss: 2.312146984120851

Epoch: 6| Step: 13
Training loss: 3.142275333404541
Validation loss: 2.404812974314536

Epoch: 91| Step: 0
Training loss: 3.0307319164276123
Validation loss: 2.5300520056037494

Epoch: 6| Step: 1
Training loss: 2.9479894638061523
Validation loss: 2.4512858236989667

Epoch: 6| Step: 2
Training loss: 2.1525866985321045
Validation loss: 2.321465702467067

Epoch: 6| Step: 3
Training loss: 2.1429195404052734
Validation loss: 2.2624871782077256

Epoch: 6| Step: 4
Training loss: 2.327789783477783
Validation loss: 2.2498189172437115

Epoch: 6| Step: 5
Training loss: 2.805492401123047
Validation loss: 2.242422716591948

Epoch: 6| Step: 6
Training loss: 2.546833038330078
Validation loss: 2.237506689563874

Epoch: 6| Step: 7
Training loss: 2.6651337146759033
Validation loss: 2.2444621414266606

Epoch: 6| Step: 8
Training loss: 2.0734856128692627
Validation loss: 2.2382694213621077

Epoch: 6| Step: 9
Training loss: 2.924548625946045
Validation loss: 2.2407091279183664

Epoch: 6| Step: 10
Training loss: 1.9522935152053833
Validation loss: 2.2367860245448288

Epoch: 6| Step: 11
Training loss: 3.3760008811950684
Validation loss: 2.2351747712781354

Epoch: 6| Step: 12
Training loss: 3.1765613555908203
Validation loss: 2.2386050044849353

Epoch: 6| Step: 13
Training loss: 1.9844316244125366
Validation loss: 2.238372197715185

Epoch: 92| Step: 0
Training loss: 2.907891273498535
Validation loss: 2.240819086310684

Epoch: 6| Step: 1
Training loss: 2.1454710960388184
Validation loss: 2.243873575682281

Epoch: 6| Step: 2
Training loss: 3.0761466026306152
Validation loss: 2.246654595098188

Epoch: 6| Step: 3
Training loss: 3.1863510608673096
Validation loss: 2.2487385478070987

Epoch: 6| Step: 4
Training loss: 2.874028205871582
Validation loss: 2.2599508300904305

Epoch: 6| Step: 5
Training loss: 2.224341630935669
Validation loss: 2.294553420876944

Epoch: 6| Step: 6
Training loss: 1.4176441431045532
Validation loss: 2.311565717061361

Epoch: 6| Step: 7
Training loss: 2.8902602195739746
Validation loss: 2.3214033803632184

Epoch: 6| Step: 8
Training loss: 1.9768457412719727
Validation loss: 2.3215832402629237

Epoch: 6| Step: 9
Training loss: 2.6792373657226562
Validation loss: 2.29685890290045

Epoch: 6| Step: 10
Training loss: 2.3650121688842773
Validation loss: 2.291541830185921

Epoch: 6| Step: 11
Training loss: 2.4773755073547363
Validation loss: 2.2785214531806206

Epoch: 6| Step: 12
Training loss: 2.9232406616210938
Validation loss: 2.2487488959425237

Epoch: 6| Step: 13
Training loss: 2.597193717956543
Validation loss: 2.233861336144068

Epoch: 93| Step: 0
Training loss: 2.776719570159912
Validation loss: 2.2429549911970734

Epoch: 6| Step: 1
Training loss: 2.5112571716308594
Validation loss: 2.247680126979787

Epoch: 6| Step: 2
Training loss: 2.960838556289673
Validation loss: 2.2621052829168176

Epoch: 6| Step: 3
Training loss: 2.863508462905884
Validation loss: 2.2668783613430556

Epoch: 6| Step: 4
Training loss: 2.6233272552490234
Validation loss: 2.258082412904309

Epoch: 6| Step: 5
Training loss: 2.390982151031494
Validation loss: 2.25093416501117

Epoch: 6| Step: 6
Training loss: 2.7000977993011475
Validation loss: 2.248064446192916

Epoch: 6| Step: 7
Training loss: 2.533428430557251
Validation loss: 2.251347182899393

Epoch: 6| Step: 8
Training loss: 2.892486333847046
Validation loss: 2.259454743836516

Epoch: 6| Step: 9
Training loss: 2.3287007808685303
Validation loss: 2.26577312971956

Epoch: 6| Step: 10
Training loss: 2.6445398330688477
Validation loss: 2.259222302385556

Epoch: 6| Step: 11
Training loss: 2.2084693908691406
Validation loss: 2.240630872787968

Epoch: 6| Step: 12
Training loss: 2.182736396789551
Validation loss: 2.239989329409856

Epoch: 6| Step: 13
Training loss: 2.10591459274292
Validation loss: 2.2291719913482666

Epoch: 94| Step: 0
Training loss: 2.139693021774292
Validation loss: 2.2283645470937095

Epoch: 6| Step: 1
Training loss: 3.2679688930511475
Validation loss: 2.2275431950887046

Epoch: 6| Step: 2
Training loss: 1.6597126722335815
Validation loss: 2.2307317128745456

Epoch: 6| Step: 3
Training loss: 2.8624401092529297
Validation loss: 2.231313934890173

Epoch: 6| Step: 4
Training loss: 2.4150569438934326
Validation loss: 2.2381903689394713

Epoch: 6| Step: 5
Training loss: 2.732942819595337
Validation loss: 2.2400640262070524

Epoch: 6| Step: 6
Training loss: 2.7959296703338623
Validation loss: 2.2500866407989175

Epoch: 6| Step: 7
Training loss: 2.959014654159546
Validation loss: 2.2582751807346138

Epoch: 6| Step: 8
Training loss: 2.8257808685302734
Validation loss: 2.255049708069012

Epoch: 6| Step: 9
Training loss: 1.8206274509429932
Validation loss: 2.24572548174089

Epoch: 6| Step: 10
Training loss: 2.5513129234313965
Validation loss: 2.233796311962989

Epoch: 6| Step: 11
Training loss: 2.051478624343872
Validation loss: 2.2290451449732624

Epoch: 6| Step: 12
Training loss: 2.9585795402526855
Validation loss: 2.2246610938861804

Epoch: 6| Step: 13
Training loss: 3.124974250793457
Validation loss: 2.225195820613574

Epoch: 95| Step: 0
Training loss: 2.465174436569214
Validation loss: 2.2389072961704706

Epoch: 6| Step: 1
Training loss: 2.828902244567871
Validation loss: 2.25113949724423

Epoch: 6| Step: 2
Training loss: 1.9666856527328491
Validation loss: 2.2547459704901582

Epoch: 6| Step: 3
Training loss: 2.9630050659179688
Validation loss: 2.2600219941908315

Epoch: 6| Step: 4
Training loss: 3.1465492248535156
Validation loss: 2.2570306434426257

Epoch: 6| Step: 5
Training loss: 2.4893696308135986
Validation loss: 2.256330527285094

Epoch: 6| Step: 6
Training loss: 2.783393621444702
Validation loss: 2.2380967550380255

Epoch: 6| Step: 7
Training loss: 2.8899738788604736
Validation loss: 2.2346931708756315

Epoch: 6| Step: 8
Training loss: 2.579875946044922
Validation loss: 2.231750803609048

Epoch: 6| Step: 9
Training loss: 1.8764705657958984
Validation loss: 2.2258487414288264

Epoch: 6| Step: 10
Training loss: 2.7960610389709473
Validation loss: 2.2201023229988675

Epoch: 6| Step: 11
Training loss: 1.6714500188827515
Validation loss: 2.222437882936129

Epoch: 6| Step: 12
Training loss: 2.2333974838256836
Validation loss: 2.2209501343388713

Epoch: 6| Step: 13
Training loss: 3.211132526397705
Validation loss: 2.2246773960769817

Epoch: 96| Step: 0
Training loss: 2.5361580848693848
Validation loss: 2.224823494111338

Epoch: 6| Step: 1
Training loss: 2.3645238876342773
Validation loss: 2.2236984058093

Epoch: 6| Step: 2
Training loss: 2.267641544342041
Validation loss: 2.2279317866089525

Epoch: 6| Step: 3
Training loss: 3.266784906387329
Validation loss: 2.2300535530172367

Epoch: 6| Step: 4
Training loss: 2.155503749847412
Validation loss: 2.233156583642447

Epoch: 6| Step: 5
Training loss: 2.868040084838867
Validation loss: 2.226504102829964

Epoch: 6| Step: 6
Training loss: 3.1268107891082764
Validation loss: 2.22391277615742

Epoch: 6| Step: 7
Training loss: 3.307969331741333
Validation loss: 2.2199912660865375

Epoch: 6| Step: 8
Training loss: 1.7545106410980225
Validation loss: 2.215972979863485

Epoch: 6| Step: 9
Training loss: 2.7774927616119385
Validation loss: 2.2124393986117457

Epoch: 6| Step: 10
Training loss: 2.5473761558532715
Validation loss: 2.2125075017252276

Epoch: 6| Step: 11
Training loss: 2.0223007202148438
Validation loss: 2.2181174832005657

Epoch: 6| Step: 12
Training loss: 2.6072998046875
Validation loss: 2.221239633457635

Epoch: 6| Step: 13
Training loss: 1.787010669708252
Validation loss: 2.2274661756330922

Epoch: 97| Step: 0
Training loss: 2.5807411670684814
Validation loss: 2.2426262568402033

Epoch: 6| Step: 1
Training loss: 1.8594708442687988
Validation loss: 2.2539930087263866

Epoch: 6| Step: 2
Training loss: 2.2733993530273438
Validation loss: 2.246583714280077

Epoch: 6| Step: 3
Training loss: 1.9747345447540283
Validation loss: 2.2194489048373316

Epoch: 6| Step: 4
Training loss: 2.738572597503662
Validation loss: 2.2279007127208095

Epoch: 6| Step: 5
Training loss: 2.050447940826416
Validation loss: 2.2231373607471423

Epoch: 6| Step: 6
Training loss: 2.2849578857421875
Validation loss: 2.2208146049130346

Epoch: 6| Step: 7
Training loss: 3.1930038928985596
Validation loss: 2.227138865378595

Epoch: 6| Step: 8
Training loss: 2.745659112930298
Validation loss: 2.2205518740479664

Epoch: 6| Step: 9
Training loss: 2.2554051876068115
Validation loss: 2.232659685996271

Epoch: 6| Step: 10
Training loss: 2.748368740081787
Validation loss: 2.257416243194252

Epoch: 6| Step: 11
Training loss: 2.672126293182373
Validation loss: 2.2698390176219325

Epoch: 6| Step: 12
Training loss: 3.0041022300720215
Validation loss: 2.302336113427275

Epoch: 6| Step: 13
Training loss: 3.323751449584961
Validation loss: 2.3140543609537105

Epoch: 98| Step: 0
Training loss: 2.2628560066223145
Validation loss: 2.311755326486403

Epoch: 6| Step: 1
Training loss: 2.6757760047912598
Validation loss: 2.333799516001055

Epoch: 6| Step: 2
Training loss: 2.3862955570220947
Validation loss: 2.3168558048945602

Epoch: 6| Step: 3
Training loss: 2.57578182220459
Validation loss: 2.2668396836967877

Epoch: 6| Step: 4
Training loss: 2.8750391006469727
Validation loss: 2.2697317036249305

Epoch: 6| Step: 5
Training loss: 2.5316638946533203
Validation loss: 2.2441173215066232

Epoch: 6| Step: 6
Training loss: 2.7155983448028564
Validation loss: 2.2229276626340804

Epoch: 6| Step: 7
Training loss: 2.019320487976074
Validation loss: 2.2137676080067954

Epoch: 6| Step: 8
Training loss: 2.209120273590088
Validation loss: 2.2054710311274373

Epoch: 6| Step: 9
Training loss: 3.2515242099761963
Validation loss: 2.2087697162423083

Epoch: 6| Step: 10
Training loss: 1.9029037952423096
Validation loss: 2.20860965277559

Epoch: 6| Step: 11
Training loss: 2.4634199142456055
Validation loss: 2.2113816943219913

Epoch: 6| Step: 12
Training loss: 2.6273066997528076
Validation loss: 2.2095378714223064

Epoch: 6| Step: 13
Training loss: 2.883970022201538
Validation loss: 2.203960677628876

Epoch: 99| Step: 0
Training loss: 2.2305591106414795
Validation loss: 2.206287758324736

Epoch: 6| Step: 1
Training loss: 2.5545289516448975
Validation loss: 2.204889605122228

Epoch: 6| Step: 2
Training loss: 2.7847721576690674
Validation loss: 2.2195734336812007

Epoch: 6| Step: 3
Training loss: 2.0443952083587646
Validation loss: 2.238383182915308

Epoch: 6| Step: 4
Training loss: 3.386127233505249
Validation loss: 2.252945589762862

Epoch: 6| Step: 5
Training loss: 2.4831972122192383
Validation loss: 2.2364745140075684

Epoch: 6| Step: 6
Training loss: 2.540386199951172
Validation loss: 2.2159281110250824

Epoch: 6| Step: 7
Training loss: 1.8717994689941406
Validation loss: 2.20561485521255

Epoch: 6| Step: 8
Training loss: 2.5712087154388428
Validation loss: 2.1952674042794014

Epoch: 6| Step: 9
Training loss: 2.8178067207336426
Validation loss: 2.1952840743526334

Epoch: 6| Step: 10
Training loss: 2.2434849739074707
Validation loss: 2.192120945581826

Epoch: 6| Step: 11
Training loss: 2.93503475189209
Validation loss: 2.195142556262273

Epoch: 6| Step: 12
Training loss: 2.6585042476654053
Validation loss: 2.1938052510702484

Epoch: 6| Step: 13
Training loss: 1.8759905099868774
Validation loss: 2.198059974178191

Epoch: 100| Step: 0
Training loss: 2.3164031505584717
Validation loss: 2.1994816744199364

Epoch: 6| Step: 1
Training loss: 2.4671998023986816
Validation loss: 2.1968724727630615

Epoch: 6| Step: 2
Training loss: 2.6262807846069336
Validation loss: 2.229729143522119

Epoch: 6| Step: 3
Training loss: 2.260000228881836
Validation loss: 2.2481848527026433

Epoch: 6| Step: 4
Training loss: 2.44039249420166
Validation loss: 2.259440529731012

Epoch: 6| Step: 5
Training loss: 2.713777542114258
Validation loss: 2.301492794867485

Epoch: 6| Step: 6
Training loss: 3.03464412689209
Validation loss: 2.343040491945

Epoch: 6| Step: 7
Training loss: 2.8659133911132812
Validation loss: 2.307288605679748

Epoch: 6| Step: 8
Training loss: 2.830308437347412
Validation loss: 2.2851288395543254

Epoch: 6| Step: 9
Training loss: 1.9541399478912354
Validation loss: 2.236768605888531

Epoch: 6| Step: 10
Training loss: 2.8515613079071045
Validation loss: 2.227115992576845

Epoch: 6| Step: 11
Training loss: 2.229196548461914
Validation loss: 2.2070273378843903

Epoch: 6| Step: 12
Training loss: 2.136561870574951
Validation loss: 2.203147224200669

Epoch: 6| Step: 13
Training loss: 2.2611188888549805
Validation loss: 2.203413741562956

Epoch: 101| Step: 0
Training loss: 1.7777031660079956
Validation loss: 2.191739384846021

Epoch: 6| Step: 1
Training loss: 2.5058517456054688
Validation loss: 2.184074617201282

Epoch: 6| Step: 2
Training loss: 2.496983289718628
Validation loss: 2.188270048428607

Epoch: 6| Step: 3
Training loss: 2.8736510276794434
Validation loss: 2.1861662377593336

Epoch: 6| Step: 4
Training loss: 3.344869375228882
Validation loss: 2.189731390245499

Epoch: 6| Step: 5
Training loss: 3.2080793380737305
Validation loss: 2.1853355541024158

Epoch: 6| Step: 6
Training loss: 2.500966787338257
Validation loss: 2.1804550206789406

Epoch: 6| Step: 7
Training loss: 2.4087882041931152
Validation loss: 2.1856891903825986

Epoch: 6| Step: 8
Training loss: 2.257674217224121
Validation loss: 2.187241441460066

Epoch: 6| Step: 9
Training loss: 2.3851208686828613
Validation loss: 2.18910506720184

Epoch: 6| Step: 10
Training loss: 2.3247692584991455
Validation loss: 2.201780255122851

Epoch: 6| Step: 11
Training loss: 2.3296704292297363
Validation loss: 2.1958654721577964

Epoch: 6| Step: 12
Training loss: 2.10259747505188
Validation loss: 2.217716124749953

Epoch: 6| Step: 13
Training loss: 2.865544319152832
Validation loss: 2.2335244109553676

Epoch: 102| Step: 0
Training loss: 2.3287880420684814
Validation loss: 2.262377263397299

Epoch: 6| Step: 1
Training loss: 1.881305456161499
Validation loss: 2.2599351457370225

Epoch: 6| Step: 2
Training loss: 2.163227081298828
Validation loss: 2.2543905063342025

Epoch: 6| Step: 3
Training loss: 2.8455581665039062
Validation loss: 2.2478910620494554

Epoch: 6| Step: 4
Training loss: 2.198404312133789
Validation loss: 2.223335204585906

Epoch: 6| Step: 5
Training loss: 3.094818353652954
Validation loss: 2.2353899478912354

Epoch: 6| Step: 6
Training loss: 2.3850083351135254
Validation loss: 2.2010476896839757

Epoch: 6| Step: 7
Training loss: 2.9344587326049805
Validation loss: 2.191654630886611

Epoch: 6| Step: 8
Training loss: 2.5649261474609375
Validation loss: 2.1815579860441145

Epoch: 6| Step: 9
Training loss: 2.901470422744751
Validation loss: 2.181361162534324

Epoch: 6| Step: 10
Training loss: 2.3411154747009277
Validation loss: 2.181917499470454

Epoch: 6| Step: 11
Training loss: 3.140617847442627
Validation loss: 2.197008159852797

Epoch: 6| Step: 12
Training loss: 2.154815196990967
Validation loss: 2.2095461032723867

Epoch: 6| Step: 13
Training loss: 1.775675654411316
Validation loss: 2.207724637882684

Epoch: 103| Step: 0
Training loss: 2.1998214721679688
Validation loss: 2.2067761985204553

Epoch: 6| Step: 1
Training loss: 2.287973403930664
Validation loss: 2.188260301466911

Epoch: 6| Step: 2
Training loss: 2.8562369346618652
Validation loss: 2.18793918753183

Epoch: 6| Step: 3
Training loss: 2.7758841514587402
Validation loss: 2.1852082744721444

Epoch: 6| Step: 4
Training loss: 2.3140411376953125
Validation loss: 2.1878290996756604

Epoch: 6| Step: 5
Training loss: 2.7027626037597656
Validation loss: 2.2014112780171056

Epoch: 6| Step: 6
Training loss: 2.918682813644409
Validation loss: 2.219642593014625

Epoch: 6| Step: 7
Training loss: 2.638528823852539
Validation loss: 2.20974644794259

Epoch: 6| Step: 8
Training loss: 2.362231492996216
Validation loss: 2.227556420910743

Epoch: 6| Step: 9
Training loss: 2.6489009857177734
Validation loss: 2.2188066039034116

Epoch: 6| Step: 10
Training loss: 1.5555272102355957
Validation loss: 2.2209792854965373

Epoch: 6| Step: 11
Training loss: 2.3790106773376465
Validation loss: 2.1955420304370183

Epoch: 6| Step: 12
Training loss: 2.641655683517456
Validation loss: 2.20248564340735

Epoch: 6| Step: 13
Training loss: 2.571732521057129
Validation loss: 2.200133116014542

Epoch: 104| Step: 0
Training loss: 2.5230326652526855
Validation loss: 2.1899925483170377

Epoch: 6| Step: 1
Training loss: 3.159040927886963
Validation loss: 2.185539207150859

Epoch: 6| Step: 2
Training loss: 1.6757802963256836
Validation loss: 2.174876546347013

Epoch: 6| Step: 3
Training loss: 2.73862886428833
Validation loss: 2.177611029276284

Epoch: 6| Step: 4
Training loss: 2.7850723266601562
Validation loss: 2.1782133066526024

Epoch: 6| Step: 5
Training loss: 2.7999401092529297
Validation loss: 2.1726205938605854

Epoch: 6| Step: 6
Training loss: 2.0700361728668213
Validation loss: 2.186663655824559

Epoch: 6| Step: 7
Training loss: 2.2590949535369873
Validation loss: 2.201348638021818

Epoch: 6| Step: 8
Training loss: 3.079852342605591
Validation loss: 2.2079309442991852

Epoch: 6| Step: 9
Training loss: 2.5391392707824707
Validation loss: 2.20702386671497

Epoch: 6| Step: 10
Training loss: 1.5518687963485718
Validation loss: 2.2261375919465096

Epoch: 6| Step: 11
Training loss: 2.776735782623291
Validation loss: 2.2343933813033567

Epoch: 6| Step: 12
Training loss: 2.4958341121673584
Validation loss: 2.224232501881097

Epoch: 6| Step: 13
Training loss: 1.9385285377502441
Validation loss: 2.1991172234217324

Epoch: 105| Step: 0
Training loss: 2.0206761360168457
Validation loss: 2.1805368392698226

Epoch: 6| Step: 1
Training loss: 2.2631523609161377
Validation loss: 2.174602295762749

Epoch: 6| Step: 2
Training loss: 2.651080846786499
Validation loss: 2.1714394528378724

Epoch: 6| Step: 3
Training loss: 2.5886003971099854
Validation loss: 2.168819228808085

Epoch: 6| Step: 4
Training loss: 2.263838291168213
Validation loss: 2.168494564230724

Epoch: 6| Step: 5
Training loss: 2.1423158645629883
Validation loss: 2.171837575974003

Epoch: 6| Step: 6
Training loss: 1.3974547386169434
Validation loss: 2.165635165347848

Epoch: 6| Step: 7
Training loss: 3.2030038833618164
Validation loss: 2.1721883640494397

Epoch: 6| Step: 8
Training loss: 3.2325963973999023
Validation loss: 2.182265107349683

Epoch: 6| Step: 9
Training loss: 2.5698468685150146
Validation loss: 2.1802760170352076

Epoch: 6| Step: 10
Training loss: 2.5198798179626465
Validation loss: 2.1940400472251316

Epoch: 6| Step: 11
Training loss: 2.167778968811035
Validation loss: 2.222474587860928

Epoch: 6| Step: 12
Training loss: 2.963954448699951
Validation loss: 2.232435537922767

Epoch: 6| Step: 13
Training loss: 2.844111680984497
Validation loss: 2.234918595642172

Epoch: 106| Step: 0
Training loss: 2.993715524673462
Validation loss: 2.2086611896432857

Epoch: 6| Step: 1
Training loss: 3.2747349739074707
Validation loss: 2.179207988964614

Epoch: 6| Step: 2
Training loss: 1.7867424488067627
Validation loss: 2.1742274927836593

Epoch: 6| Step: 3
Training loss: 1.9232442378997803
Validation loss: 2.1637383250780005

Epoch: 6| Step: 4
Training loss: 2.627199172973633
Validation loss: 2.1565219984259656

Epoch: 6| Step: 5
Training loss: 2.9584293365478516
Validation loss: 2.1659884978366155

Epoch: 6| Step: 6
Training loss: 2.0967960357666016
Validation loss: 2.159724791844686

Epoch: 6| Step: 7
Training loss: 2.150123119354248
Validation loss: 2.162973375730617

Epoch: 6| Step: 8
Training loss: 2.5452589988708496
Validation loss: 2.1648520064610306

Epoch: 6| Step: 9
Training loss: 1.9617276191711426
Validation loss: 2.1679807811655025

Epoch: 6| Step: 10
Training loss: 2.11663818359375
Validation loss: 2.1862365981583953

Epoch: 6| Step: 11
Training loss: 3.0917232036590576
Validation loss: 2.195792621181857

Epoch: 6| Step: 12
Training loss: 2.723876476287842
Validation loss: 2.208820177662757

Epoch: 6| Step: 13
Training loss: 2.40860652923584
Validation loss: 2.228902760372367

Epoch: 107| Step: 0
Training loss: 1.8346376419067383
Validation loss: 2.270523553253502

Epoch: 6| Step: 1
Training loss: 2.3923206329345703
Validation loss: 2.2266497458181074

Epoch: 6| Step: 2
Training loss: 2.749049663543701
Validation loss: 2.224165229387181

Epoch: 6| Step: 3
Training loss: 2.894578218460083
Validation loss: 2.22233179051389

Epoch: 6| Step: 4
Training loss: 3.1270594596862793
Validation loss: 2.204945982143443

Epoch: 6| Step: 5
Training loss: 1.6619515419006348
Validation loss: 2.1897534208913005

Epoch: 6| Step: 6
Training loss: 3.305739402770996
Validation loss: 2.202922544171733

Epoch: 6| Step: 7
Training loss: 2.4250059127807617
Validation loss: 2.2219568439709243

Epoch: 6| Step: 8
Training loss: 2.792510986328125
Validation loss: 2.2238094627216296

Epoch: 6| Step: 9
Training loss: 2.7988290786743164
Validation loss: 2.222363207929878

Epoch: 6| Step: 10
Training loss: 2.2987794876098633
Validation loss: 2.2141233439086587

Epoch: 6| Step: 11
Training loss: 2.116955280303955
Validation loss: 2.1987665519919446

Epoch: 6| Step: 12
Training loss: 2.5894880294799805
Validation loss: 2.201130300439814

Epoch: 6| Step: 13
Training loss: 1.8729093074798584
Validation loss: 2.2122466435996433

Epoch: 108| Step: 0
Training loss: 2.829342842102051
Validation loss: 2.2140148583278862

Epoch: 6| Step: 1
Training loss: 2.2701363563537598
Validation loss: 2.2236929414092854

Epoch: 6| Step: 2
Training loss: 2.8936593532562256
Validation loss: 2.230309961944498

Epoch: 6| Step: 3
Training loss: 3.130852460861206
Validation loss: 2.2326084157472015

Epoch: 6| Step: 4
Training loss: 2.747619152069092
Validation loss: 2.2455418058620986

Epoch: 6| Step: 5
Training loss: 2.275458335876465
Validation loss: 2.254393018702025

Epoch: 6| Step: 6
Training loss: 2.152316093444824
Validation loss: 2.2821975138879593

Epoch: 6| Step: 7
Training loss: 2.350400924682617
Validation loss: 2.2612825875641196

Epoch: 6| Step: 8
Training loss: 2.4819180965423584
Validation loss: 2.2406481722349763

Epoch: 6| Step: 9
Training loss: 2.853182315826416
Validation loss: 2.2192006623873146

Epoch: 6| Step: 10
Training loss: 2.3995132446289062
Validation loss: 2.204881727054555

Epoch: 6| Step: 11
Training loss: 1.7880887985229492
Validation loss: 2.1860228559022308

Epoch: 6| Step: 12
Training loss: 2.1069045066833496
Validation loss: 2.1759350376744426

Epoch: 6| Step: 13
Training loss: 2.607440233230591
Validation loss: 2.1673992244146203

Epoch: 109| Step: 0
Training loss: 2.8995680809020996
Validation loss: 2.1705862847707604

Epoch: 6| Step: 1
Training loss: 3.074345588684082
Validation loss: 2.1723955267219135

Epoch: 6| Step: 2
Training loss: 2.346713066101074
Validation loss: 2.172106081439603

Epoch: 6| Step: 3
Training loss: 2.693005323410034
Validation loss: 2.1528660071793424

Epoch: 6| Step: 4
Training loss: 2.5297164916992188
Validation loss: 2.1584120899118404

Epoch: 6| Step: 5
Training loss: 3.0401675701141357
Validation loss: 2.163477525916151

Epoch: 6| Step: 6
Training loss: 2.237420082092285
Validation loss: 2.149218995084045

Epoch: 6| Step: 7
Training loss: 2.6090359687805176
Validation loss: 2.1482860888204267

Epoch: 6| Step: 8
Training loss: 2.321908473968506
Validation loss: 2.156735743245771

Epoch: 6| Step: 9
Training loss: 2.3767542839050293
Validation loss: 2.1496598182186

Epoch: 6| Step: 10
Training loss: 2.263538360595703
Validation loss: 2.155272788898919

Epoch: 6| Step: 11
Training loss: 2.279599189758301
Validation loss: 2.1585669184243805

Epoch: 6| Step: 12
Training loss: 1.469409704208374
Validation loss: 2.170001570896436

Epoch: 6| Step: 13
Training loss: 1.9066026210784912
Validation loss: 2.1883250282656763

Epoch: 110| Step: 0
Training loss: 1.9670920372009277
Validation loss: 2.198189050920548

Epoch: 6| Step: 1
Training loss: 2.6469430923461914
Validation loss: 2.20208824834516

Epoch: 6| Step: 2
Training loss: 2.3980369567871094
Validation loss: 2.1727563950323288

Epoch: 6| Step: 3
Training loss: 2.7593202590942383
Validation loss: 2.172262473772931

Epoch: 6| Step: 4
Training loss: 2.451699733734131
Validation loss: 2.145361279928556

Epoch: 6| Step: 5
Training loss: 2.8442955017089844
Validation loss: 2.138780246498764

Epoch: 6| Step: 6
Training loss: 1.9865686893463135
Validation loss: 2.1342195310900287

Epoch: 6| Step: 7
Training loss: 2.4886817932128906
Validation loss: 2.1362230918740712

Epoch: 6| Step: 8
Training loss: 2.573079824447632
Validation loss: 2.1339325597209315

Epoch: 6| Step: 9
Training loss: 2.4042587280273438
Validation loss: 2.134907453290878

Epoch: 6| Step: 10
Training loss: 2.7374472618103027
Validation loss: 2.136286151024603

Epoch: 6| Step: 11
Training loss: 2.3008971214294434
Validation loss: 2.136307421550956

Epoch: 6| Step: 12
Training loss: 2.3143606185913086
Validation loss: 2.1351372836738505

Epoch: 6| Step: 13
Training loss: 2.8213560581207275
Validation loss: 2.1368877105815436

Epoch: 111| Step: 0
Training loss: 2.757096529006958
Validation loss: 2.153823509011217

Epoch: 6| Step: 1
Training loss: 2.7312281131744385
Validation loss: 2.1672625080231698

Epoch: 6| Step: 2
Training loss: 2.919473648071289
Validation loss: 2.1989053116049817

Epoch: 6| Step: 3
Training loss: 2.3639156818389893
Validation loss: 2.199545419344338

Epoch: 6| Step: 4
Training loss: 2.5158421993255615
Validation loss: 2.225522343830396

Epoch: 6| Step: 5
Training loss: 2.122617483139038
Validation loss: 2.247153162956238

Epoch: 6| Step: 6
Training loss: 1.9022274017333984
Validation loss: 2.281293402435959

Epoch: 6| Step: 7
Training loss: 2.6151814460754395
Validation loss: 2.2237927670119912

Epoch: 6| Step: 8
Training loss: 2.3693454265594482
Validation loss: 2.172171861894669

Epoch: 6| Step: 9
Training loss: 2.345379114151001
Validation loss: 2.1592743409577237

Epoch: 6| Step: 10
Training loss: 2.1598293781280518
Validation loss: 2.1395024432930896

Epoch: 6| Step: 11
Training loss: 2.8650221824645996
Validation loss: 2.1374201492596696

Epoch: 6| Step: 12
Training loss: 1.988560438156128
Validation loss: 2.134945830991191

Epoch: 6| Step: 13
Training loss: 2.916025400161743
Validation loss: 2.1278605166301934

Epoch: 112| Step: 0
Training loss: 2.4848923683166504
Validation loss: 2.1297701622850154

Epoch: 6| Step: 1
Training loss: 2.612553834915161
Validation loss: 2.130887882683867

Epoch: 6| Step: 2
Training loss: 2.8232192993164062
Validation loss: 2.1387595771461405

Epoch: 6| Step: 3
Training loss: 2.367292881011963
Validation loss: 2.133218160239599

Epoch: 6| Step: 4
Training loss: 2.4758894443511963
Validation loss: 2.1345959671082033

Epoch: 6| Step: 5
Training loss: 2.0914604663848877
Validation loss: 2.1426108806363997

Epoch: 6| Step: 6
Training loss: 2.5350558757781982
Validation loss: 2.1500803527011665

Epoch: 6| Step: 7
Training loss: 1.6892123222351074
Validation loss: 2.1536075658695673

Epoch: 6| Step: 8
Training loss: 2.441814422607422
Validation loss: 2.1828786814084618

Epoch: 6| Step: 9
Training loss: 3.3923513889312744
Validation loss: 2.2107053290131273

Epoch: 6| Step: 10
Training loss: 2.22232723236084
Validation loss: 2.2380300914087603

Epoch: 6| Step: 11
Training loss: 2.7666797637939453
Validation loss: 2.1935002047528505

Epoch: 6| Step: 12
Training loss: 2.251523017883301
Validation loss: 2.1809325577110372

Epoch: 6| Step: 13
Training loss: 2.510690927505493
Validation loss: 2.1902409522764144

Epoch: 113| Step: 0
Training loss: 2.1602718830108643
Validation loss: 2.182094807265907

Epoch: 6| Step: 1
Training loss: 2.3993420600891113
Validation loss: 2.1771803620041057

Epoch: 6| Step: 2
Training loss: 2.006046772003174
Validation loss: 2.1755563982071413

Epoch: 6| Step: 3
Training loss: 2.348879098892212
Validation loss: 2.179055831765616

Epoch: 6| Step: 4
Training loss: 2.478520393371582
Validation loss: 2.1750156828152236

Epoch: 6| Step: 5
Training loss: 2.221078872680664
Validation loss: 2.1736360903709167

Epoch: 6| Step: 6
Training loss: 2.6209893226623535
Validation loss: 2.175963432558121

Epoch: 6| Step: 7
Training loss: 2.6976542472839355
Validation loss: 2.1865110935703402

Epoch: 6| Step: 8
Training loss: 3.1135432720184326
Validation loss: 2.189556324353782

Epoch: 6| Step: 9
Training loss: 2.2719526290893555
Validation loss: 2.1995000223959646

Epoch: 6| Step: 10
Training loss: 2.181185245513916
Validation loss: 2.180264267870175

Epoch: 6| Step: 11
Training loss: 3.1740431785583496
Validation loss: 2.184331347865443

Epoch: 6| Step: 12
Training loss: 2.072253942489624
Validation loss: 2.1815177830316688

Epoch: 6| Step: 13
Training loss: 2.3145997524261475
Validation loss: 2.1789965937214513

Epoch: 114| Step: 0
Training loss: 2.304225444793701
Validation loss: 2.174725506895332

Epoch: 6| Step: 1
Training loss: 2.2222514152526855
Validation loss: 2.190449394205565

Epoch: 6| Step: 2
Training loss: 2.6665539741516113
Validation loss: 2.221969930074548

Epoch: 6| Step: 3
Training loss: 2.574068069458008
Validation loss: 2.220639351875551

Epoch: 6| Step: 4
Training loss: 2.074556350708008
Validation loss: 2.221564967145202

Epoch: 6| Step: 5
Training loss: 2.7872695922851562
Validation loss: 2.21821395556132

Epoch: 6| Step: 6
Training loss: 3.048495292663574
Validation loss: 2.1798856668574835

Epoch: 6| Step: 7
Training loss: 3.124995470046997
Validation loss: 2.1546660110514653

Epoch: 6| Step: 8
Training loss: 2.447286367416382
Validation loss: 2.1464047931855723

Epoch: 6| Step: 9
Training loss: 2.394122838973999
Validation loss: 2.139002018077399

Epoch: 6| Step: 10
Training loss: 1.5584994554519653
Validation loss: 2.129214254758691

Epoch: 6| Step: 11
Training loss: 2.3654966354370117
Validation loss: 2.1319262391777447

Epoch: 6| Step: 12
Training loss: 2.294088840484619
Validation loss: 2.1289359113221527

Epoch: 6| Step: 13
Training loss: 2.0955190658569336
Validation loss: 2.129999094111945

Epoch: 115| Step: 0
Training loss: 2.1194469928741455
Validation loss: 2.131140887096364

Epoch: 6| Step: 1
Training loss: 2.8673031330108643
Validation loss: 2.131144239056495

Epoch: 6| Step: 2
Training loss: 2.5315003395080566
Validation loss: 2.1280626468760993

Epoch: 6| Step: 3
Training loss: 2.845170497894287
Validation loss: 2.1344789766496226

Epoch: 6| Step: 4
Training loss: 2.4449148178100586
Validation loss: 2.1353145248146466

Epoch: 6| Step: 5
Training loss: 2.8387136459350586
Validation loss: 2.137825071170766

Epoch: 6| Step: 6
Training loss: 2.414632558822632
Validation loss: 2.140349357358871

Epoch: 6| Step: 7
Training loss: 2.986847400665283
Validation loss: 2.1655662649421283

Epoch: 6| Step: 8
Training loss: 1.9648370742797852
Validation loss: 2.1772953515411704

Epoch: 6| Step: 9
Training loss: 2.250765562057495
Validation loss: 2.1674946046644643

Epoch: 6| Step: 10
Training loss: 2.3670544624328613
Validation loss: 2.1560634515618764

Epoch: 6| Step: 11
Training loss: 2.2928924560546875
Validation loss: 2.1291405846995692

Epoch: 6| Step: 12
Training loss: 1.6011582612991333
Validation loss: 2.137595363842544

Epoch: 6| Step: 13
Training loss: 2.218230724334717
Validation loss: 2.134093312806981

Epoch: 116| Step: 0
Training loss: 2.2080459594726562
Validation loss: 2.1276972832218295

Epoch: 6| Step: 1
Training loss: 2.373410940170288
Validation loss: 2.118012500065629

Epoch: 6| Step: 2
Training loss: 2.3486063480377197
Validation loss: 2.1211127158134215

Epoch: 6| Step: 3
Training loss: 1.9106812477111816
Validation loss: 2.1156048697810017

Epoch: 6| Step: 4
Training loss: 1.6245734691619873
Validation loss: 2.1084471505175353

Epoch: 6| Step: 5
Training loss: 2.6802079677581787
Validation loss: 2.1127713649503645

Epoch: 6| Step: 6
Training loss: 3.2182483673095703
Validation loss: 2.1246314433313187

Epoch: 6| Step: 7
Training loss: 1.6467217206954956
Validation loss: 2.137248310991513

Epoch: 6| Step: 8
Training loss: 2.310281753540039
Validation loss: 2.1511684643324984

Epoch: 6| Step: 9
Training loss: 2.2835230827331543
Validation loss: 2.2134949032978346

Epoch: 6| Step: 10
Training loss: 3.5598182678222656
Validation loss: 2.2802681948549006

Epoch: 6| Step: 11
Training loss: 3.15110445022583
Validation loss: 2.26240800785762

Epoch: 6| Step: 12
Training loss: 2.781838893890381
Validation loss: 2.247340538168466

Epoch: 6| Step: 13
Training loss: 2.1828885078430176
Validation loss: 2.239916939889231

Epoch: 117| Step: 0
Training loss: 2.2279272079467773
Validation loss: 2.152794534160245

Epoch: 6| Step: 1
Training loss: 2.4032912254333496
Validation loss: 2.1153073182670017

Epoch: 6| Step: 2
Training loss: 2.356928825378418
Validation loss: 2.1151095590283795

Epoch: 6| Step: 3
Training loss: 2.586933135986328
Validation loss: 2.1062086769329604

Epoch: 6| Step: 4
Training loss: 2.52001953125
Validation loss: 2.103534976641337

Epoch: 6| Step: 5
Training loss: 2.828545093536377
Validation loss: 2.1093958936711794

Epoch: 6| Step: 6
Training loss: 2.872738838195801
Validation loss: 2.1173681520646617

Epoch: 6| Step: 7
Training loss: 1.971004843711853
Validation loss: 2.1031744685224307

Epoch: 6| Step: 8
Training loss: 2.6865482330322266
Validation loss: 2.116029118978849

Epoch: 6| Step: 9
Training loss: 2.1720829010009766
Validation loss: 2.110205174774252

Epoch: 6| Step: 10
Training loss: 2.5034990310668945
Validation loss: 2.115782876168528

Epoch: 6| Step: 11
Training loss: 2.263110637664795
Validation loss: 2.1124174774333997

Epoch: 6| Step: 12
Training loss: 2.670088052749634
Validation loss: 2.1170753420040174

Epoch: 6| Step: 13
Training loss: 1.5736318826675415
Validation loss: 2.115226657159867

Epoch: 118| Step: 0
Training loss: 1.5022859573364258
Validation loss: 2.116045605751776

Epoch: 6| Step: 1
Training loss: 2.7800540924072266
Validation loss: 2.11922699405301

Epoch: 6| Step: 2
Training loss: 2.5403521060943604
Validation loss: 2.1309492190678916

Epoch: 6| Step: 3
Training loss: 2.4506595134735107
Validation loss: 2.144560016611571

Epoch: 6| Step: 4
Training loss: 2.2601163387298584
Validation loss: 2.1378039544628513

Epoch: 6| Step: 5
Training loss: 1.9516621828079224
Validation loss: 2.12946847433685

Epoch: 6| Step: 6
Training loss: 1.893109917640686
Validation loss: 2.1198279203907138

Epoch: 6| Step: 7
Training loss: 2.063528060913086
Validation loss: 2.105135302389822

Epoch: 6| Step: 8
Training loss: 2.8516693115234375
Validation loss: 2.1058228003081454

Epoch: 6| Step: 9
Training loss: 2.8055124282836914
Validation loss: 2.0982525656300206

Epoch: 6| Step: 10
Training loss: 2.4001331329345703
Validation loss: 2.1094102680042224

Epoch: 6| Step: 11
Training loss: 2.636293411254883
Validation loss: 2.098411029384982

Epoch: 6| Step: 12
Training loss: 3.020965814590454
Validation loss: 2.1109813131311888

Epoch: 6| Step: 13
Training loss: 2.4886159896850586
Validation loss: 2.105354696191767

Epoch: 119| Step: 0
Training loss: 2.813324213027954
Validation loss: 2.1019645032062324

Epoch: 6| Step: 1
Training loss: 1.705635905265808
Validation loss: 2.0974071743667766

Epoch: 6| Step: 2
Training loss: 2.3240435123443604
Validation loss: 2.1087313698184107

Epoch: 6| Step: 3
Training loss: 1.7204347848892212
Validation loss: 2.1127254245101765

Epoch: 6| Step: 4
Training loss: 2.072455883026123
Validation loss: 2.1082837953362414

Epoch: 6| Step: 5
Training loss: 2.238807201385498
Validation loss: 2.125498625539964

Epoch: 6| Step: 6
Training loss: 1.9530611038208008
Validation loss: 2.1346068023353495

Epoch: 6| Step: 7
Training loss: 2.583921432495117
Validation loss: 2.1472523635433567

Epoch: 6| Step: 8
Training loss: 2.650846004486084
Validation loss: 2.139542051540908

Epoch: 6| Step: 9
Training loss: 2.782400369644165
Validation loss: 2.1389385654080297

Epoch: 6| Step: 10
Training loss: 2.867032051086426
Validation loss: 2.1358965250753585

Epoch: 6| Step: 11
Training loss: 2.945469379425049
Validation loss: 2.1322143654669485

Epoch: 6| Step: 12
Training loss: 2.415841579437256
Validation loss: 2.120701951365317

Epoch: 6| Step: 13
Training loss: 2.8644587993621826
Validation loss: 2.1209028561909995

Epoch: 120| Step: 0
Training loss: 2.4026148319244385
Validation loss: 2.117784553958524

Epoch: 6| Step: 1
Training loss: 2.366624593734741
Validation loss: 2.108453860846899

Epoch: 6| Step: 2
Training loss: 2.6626687049865723
Validation loss: 2.098835132455313

Epoch: 6| Step: 3
Training loss: 2.2432377338409424
Validation loss: 2.1005459985425396

Epoch: 6| Step: 4
Training loss: 2.9443209171295166
Validation loss: 2.099715740449967

Epoch: 6| Step: 5
Training loss: 2.322964668273926
Validation loss: 2.09498752445303

Epoch: 6| Step: 6
Training loss: 2.473734140396118
Validation loss: 2.1024135017907746

Epoch: 6| Step: 7
Training loss: 2.216136932373047
Validation loss: 2.1089988844369048

Epoch: 6| Step: 8
Training loss: 2.0852808952331543
Validation loss: 2.12936802705129

Epoch: 6| Step: 9
Training loss: 2.3995110988616943
Validation loss: 2.134388877499488

Epoch: 6| Step: 10
Training loss: 2.0882365703582764
Validation loss: 2.144157625013782

Epoch: 6| Step: 11
Training loss: 2.731534004211426
Validation loss: 2.1370179153257802

Epoch: 6| Step: 12
Training loss: 2.667344570159912
Validation loss: 2.117789569721427

Epoch: 6| Step: 13
Training loss: 1.807005524635315
Validation loss: 2.107908876993323

Epoch: 121| Step: 0
Training loss: 2.821521520614624
Validation loss: 2.101053435315368

Epoch: 6| Step: 1
Training loss: 1.8602923154830933
Validation loss: 2.0864761529430265

Epoch: 6| Step: 2
Training loss: 3.138066053390503
Validation loss: 2.098005994673698

Epoch: 6| Step: 3
Training loss: 2.236931324005127
Validation loss: 2.0922896285210886

Epoch: 6| Step: 4
Training loss: 2.15859317779541
Validation loss: 2.091608785813855

Epoch: 6| Step: 5
Training loss: 2.8315482139587402
Validation loss: 2.0935730165050876

Epoch: 6| Step: 6
Training loss: 2.100158452987671
Validation loss: 2.088883751182146

Epoch: 6| Step: 7
Training loss: 1.7425168752670288
Validation loss: 2.088855546007874

Epoch: 6| Step: 8
Training loss: 2.3791537284851074
Validation loss: 2.087164666063042

Epoch: 6| Step: 9
Training loss: 2.6844632625579834
Validation loss: 2.094489343704716

Epoch: 6| Step: 10
Training loss: 2.896912097930908
Validation loss: 2.0872740232816307

Epoch: 6| Step: 11
Training loss: 1.5327110290527344
Validation loss: 2.095882018407186

Epoch: 6| Step: 12
Training loss: 2.4064159393310547
Validation loss: 2.0924761731137513

Epoch: 6| Step: 13
Training loss: 2.5652568340301514
Validation loss: 2.139345217776555

Epoch: 122| Step: 0
Training loss: 2.163238525390625
Validation loss: 2.1796396496475383

Epoch: 6| Step: 1
Training loss: 2.294097423553467
Validation loss: 2.1765663790446457

Epoch: 6| Step: 2
Training loss: 2.924562454223633
Validation loss: 2.1672051875822005

Epoch: 6| Step: 3
Training loss: 2.8943066596984863
Validation loss: 2.134136402478782

Epoch: 6| Step: 4
Training loss: 2.1530747413635254
Validation loss: 2.1211035956618605

Epoch: 6| Step: 5
Training loss: 2.3821325302124023
Validation loss: 2.103373476254043

Epoch: 6| Step: 6
Training loss: 2.314039707183838
Validation loss: 2.100814446326225

Epoch: 6| Step: 7
Training loss: 2.387211322784424
Validation loss: 2.083002018672164

Epoch: 6| Step: 8
Training loss: 2.1064562797546387
Validation loss: 2.088339149311025

Epoch: 6| Step: 9
Training loss: 2.062966823577881
Validation loss: 2.082157491355814

Epoch: 6| Step: 10
Training loss: 3.123317241668701
Validation loss: 2.0912981648598947

Epoch: 6| Step: 11
Training loss: 1.9940088987350464
Validation loss: 2.0895660872100503

Epoch: 6| Step: 12
Training loss: 2.2203011512756348
Validation loss: 2.086839952776509

Epoch: 6| Step: 13
Training loss: 3.0041050910949707
Validation loss: 2.0829695347816712

Epoch: 123| Step: 0
Training loss: 2.1631412506103516
Validation loss: 2.0954737791451077

Epoch: 6| Step: 1
Training loss: 2.0268964767456055
Validation loss: 2.0975013112509124

Epoch: 6| Step: 2
Training loss: 2.5114264488220215
Validation loss: 2.1193435192108154

Epoch: 6| Step: 3
Training loss: 1.4904811382293701
Validation loss: 2.1339355527713733

Epoch: 6| Step: 4
Training loss: 2.466580390930176
Validation loss: 2.1419670479272

Epoch: 6| Step: 5
Training loss: 2.649843215942383
Validation loss: 2.1606132753433718

Epoch: 6| Step: 6
Training loss: 2.6575422286987305
Validation loss: 2.16228481518325

Epoch: 6| Step: 7
Training loss: 2.3057684898376465
Validation loss: 2.1196555937490156

Epoch: 6| Step: 8
Training loss: 2.2604458332061768
Validation loss: 2.095436267955329

Epoch: 6| Step: 9
Training loss: 2.248243570327759
Validation loss: 2.0932145836532756

Epoch: 6| Step: 10
Training loss: 2.6382455825805664
Validation loss: 2.110324549418624

Epoch: 6| Step: 11
Training loss: 2.7698702812194824
Validation loss: 2.1279179101349204

Epoch: 6| Step: 12
Training loss: 2.5585014820098877
Validation loss: 2.1238578686150174

Epoch: 6| Step: 13
Training loss: 2.8326687812805176
Validation loss: 2.1217611092393116

Epoch: 124| Step: 0
Training loss: 2.6716790199279785
Validation loss: 2.151458819707235

Epoch: 6| Step: 1
Training loss: 2.22819185256958
Validation loss: 2.105948942963795

Epoch: 6| Step: 2
Training loss: 1.9375929832458496
Validation loss: 2.096530880979312

Epoch: 6| Step: 3
Training loss: 2.6794593334198
Validation loss: 2.0818946028268464

Epoch: 6| Step: 4
Training loss: 2.2741589546203613
Validation loss: 2.0814719200134277

Epoch: 6| Step: 5
Training loss: 1.9862873554229736
Validation loss: 2.1022185484568277

Epoch: 6| Step: 6
Training loss: 3.1852922439575195
Validation loss: 2.115290064965525

Epoch: 6| Step: 7
Training loss: 1.8376281261444092
Validation loss: 2.146275310106175

Epoch: 6| Step: 8
Training loss: 2.9004898071289062
Validation loss: 2.1975620254393546

Epoch: 6| Step: 9
Training loss: 2.252593755722046
Validation loss: 2.1718584004268853

Epoch: 6| Step: 10
Training loss: 1.772324800491333
Validation loss: 2.145702729942978

Epoch: 6| Step: 11
Training loss: 2.78281831741333
Validation loss: 2.1193230754585675

Epoch: 6| Step: 12
Training loss: 2.3991189002990723
Validation loss: 2.1029478029538224

Epoch: 6| Step: 13
Training loss: 3.4871718883514404
Validation loss: 2.0876765815160607

Epoch: 125| Step: 0
Training loss: 2.6105644702911377
Validation loss: 2.0789942356847946

Epoch: 6| Step: 1
Training loss: 2.4225363731384277
Validation loss: 2.069421583606351

Epoch: 6| Step: 2
Training loss: 2.293300151824951
Validation loss: 2.0789644154169227

Epoch: 6| Step: 3
Training loss: 1.9395875930786133
Validation loss: 2.0768894444229784

Epoch: 6| Step: 4
Training loss: 2.362041473388672
Validation loss: 2.07898126622682

Epoch: 6| Step: 5
Training loss: 1.9911198616027832
Validation loss: 2.0852265498971425

Epoch: 6| Step: 6
Training loss: 2.1978867053985596
Validation loss: 2.086579745815646

Epoch: 6| Step: 7
Training loss: 2.165825843811035
Validation loss: 2.0894150259674236

Epoch: 6| Step: 8
Training loss: 3.044192314147949
Validation loss: 2.0923731045056413

Epoch: 6| Step: 9
Training loss: 2.6174659729003906
Validation loss: 2.092696451371716

Epoch: 6| Step: 10
Training loss: 2.559743642807007
Validation loss: 2.1014695334178146

Epoch: 6| Step: 11
Training loss: 2.3594064712524414
Validation loss: 2.1025669497828328

Epoch: 6| Step: 12
Training loss: 2.5879967212677
Validation loss: 2.10254930937162

Epoch: 6| Step: 13
Training loss: 2.068589448928833
Validation loss: 2.1059459358133297

Epoch: 126| Step: 0
Training loss: 2.2519259452819824
Validation loss: 2.1065352937226653

Epoch: 6| Step: 1
Training loss: 2.6819915771484375
Validation loss: 2.0968158065631823

Epoch: 6| Step: 2
Training loss: 2.9392576217651367
Validation loss: 2.1138337389115365

Epoch: 6| Step: 3
Training loss: 1.8101643323898315
Validation loss: 2.1119779835465136

Epoch: 6| Step: 4
Training loss: 1.7889248132705688
Validation loss: 2.105670799491226

Epoch: 6| Step: 5
Training loss: 2.7810988426208496
Validation loss: 2.106082095894762

Epoch: 6| Step: 6
Training loss: 2.6944844722747803
Validation loss: 2.106260884192682

Epoch: 6| Step: 7
Training loss: 1.5658307075500488
Validation loss: 2.113478950274888

Epoch: 6| Step: 8
Training loss: 2.270642042160034
Validation loss: 2.116682590976838

Epoch: 6| Step: 9
Training loss: 3.4654643535614014
Validation loss: 2.11887881576374

Epoch: 6| Step: 10
Training loss: 1.6869981288909912
Validation loss: 2.121897489793839

Epoch: 6| Step: 11
Training loss: 2.7636897563934326
Validation loss: 2.1271861240427983

Epoch: 6| Step: 12
Training loss: 2.0062673091888428
Validation loss: 2.1288072242531726

Epoch: 6| Step: 13
Training loss: 2.4005801677703857
Validation loss: 2.159679889678955

Epoch: 127| Step: 0
Training loss: 2.7474522590637207
Validation loss: 2.1526507690388668

Epoch: 6| Step: 1
Training loss: 1.5257000923156738
Validation loss: 2.1523799973149456

Epoch: 6| Step: 2
Training loss: 2.1381702423095703
Validation loss: 2.1482904188094603

Epoch: 6| Step: 3
Training loss: 2.429205894470215
Validation loss: 2.132825065684575

Epoch: 6| Step: 4
Training loss: 1.6862378120422363
Validation loss: 2.121623710919452

Epoch: 6| Step: 5
Training loss: 2.6607255935668945
Validation loss: 2.123725703967515

Epoch: 6| Step: 6
Training loss: 2.8401880264282227
Validation loss: 2.1028237317198064

Epoch: 6| Step: 7
Training loss: 3.0861454010009766
Validation loss: 2.0968323856271724

Epoch: 6| Step: 8
Training loss: 2.3493967056274414
Validation loss: 2.08839572885985

Epoch: 6| Step: 9
Training loss: 1.9212446212768555
Validation loss: 2.085802719157229

Epoch: 6| Step: 10
Training loss: 2.614652395248413
Validation loss: 2.0696266851117535

Epoch: 6| Step: 11
Training loss: 2.240628480911255
Validation loss: 2.071869211812173

Epoch: 6| Step: 12
Training loss: 2.7206757068634033
Validation loss: 2.0802782453516477

Epoch: 6| Step: 13
Training loss: 2.2458388805389404
Validation loss: 2.0928750409874866

Epoch: 128| Step: 0
Training loss: 2.096575975418091
Validation loss: 2.0874494198829896

Epoch: 6| Step: 1
Training loss: 2.4601001739501953
Validation loss: 2.0694006130259526

Epoch: 6| Step: 2
Training loss: 2.2882680892944336
Validation loss: 2.0712599062150523

Epoch: 6| Step: 3
Training loss: 2.491196632385254
Validation loss: 2.065759816477376

Epoch: 6| Step: 4
Training loss: 2.5655088424682617
Validation loss: 2.0624527110848376

Epoch: 6| Step: 5
Training loss: 2.0878498554229736
Validation loss: 2.071939783711587

Epoch: 6| Step: 6
Training loss: 2.605189561843872
Validation loss: 2.0605609019597373

Epoch: 6| Step: 7
Training loss: 2.4567742347717285
Validation loss: 2.065899343900783

Epoch: 6| Step: 8
Training loss: 2.6132266521453857
Validation loss: 2.0697126888459727

Epoch: 6| Step: 9
Training loss: 2.6704416275024414
Validation loss: 2.059465915926041

Epoch: 6| Step: 10
Training loss: 2.6174428462982178
Validation loss: 2.057231540321022

Epoch: 6| Step: 11
Training loss: 1.934314250946045
Validation loss: 2.0617411700628137

Epoch: 6| Step: 12
Training loss: 2.2829782962799072
Validation loss: 2.08412104780956

Epoch: 6| Step: 13
Training loss: 1.426047682762146
Validation loss: 2.104919097756827

Epoch: 129| Step: 0
Training loss: 2.1615207195281982
Validation loss: 2.142527759716075

Epoch: 6| Step: 1
Training loss: 2.22214412689209
Validation loss: 2.110621790732107

Epoch: 6| Step: 2
Training loss: 2.2023088932037354
Validation loss: 2.091815848504343

Epoch: 6| Step: 3
Training loss: 2.5586681365966797
Validation loss: 2.0775425331566924

Epoch: 6| Step: 4
Training loss: 2.3056249618530273
Validation loss: 2.070893733732162

Epoch: 6| Step: 5
Training loss: 2.036668062210083
Validation loss: 2.061804748350574

Epoch: 6| Step: 6
Training loss: 2.38991641998291
Validation loss: 2.0715342567813013

Epoch: 6| Step: 7
Training loss: 2.3016490936279297
Validation loss: 2.0813803903518187

Epoch: 6| Step: 8
Training loss: 3.231976270675659
Validation loss: 2.082008961708315

Epoch: 6| Step: 9
Training loss: 2.294426441192627
Validation loss: 2.082407247635626

Epoch: 6| Step: 10
Training loss: 2.363112449645996
Validation loss: 2.082028863250568

Epoch: 6| Step: 11
Training loss: 2.500868558883667
Validation loss: 2.0852621293837026

Epoch: 6| Step: 12
Training loss: 2.4117484092712402
Validation loss: 2.0775498177415583

Epoch: 6| Step: 13
Training loss: 2.003626823425293
Validation loss: 2.0656891151141097

Epoch: 130| Step: 0
Training loss: 2.52766752243042
Validation loss: 2.0783071428216915

Epoch: 6| Step: 1
Training loss: 2.161661148071289
Validation loss: 2.0791076767829155

Epoch: 6| Step: 2
Training loss: 2.120887279510498
Validation loss: 2.0784452781882337

Epoch: 6| Step: 3
Training loss: 2.5526485443115234
Validation loss: 2.082315762837728

Epoch: 6| Step: 4
Training loss: 2.989809274673462
Validation loss: 2.0623635220271286

Epoch: 6| Step: 5
Training loss: 2.138718843460083
Validation loss: 2.055783074389222

Epoch: 6| Step: 6
Training loss: 2.822844982147217
Validation loss: 2.0643646563253095

Epoch: 6| Step: 7
Training loss: 1.9209651947021484
Validation loss: 2.070901575908866

Epoch: 6| Step: 8
Training loss: 1.754509687423706
Validation loss: 2.068322156065254

Epoch: 6| Step: 9
Training loss: 2.9676930904388428
Validation loss: 2.079189274900703

Epoch: 6| Step: 10
Training loss: 1.863344430923462
Validation loss: 2.0810307405328237

Epoch: 6| Step: 11
Training loss: 1.856558084487915
Validation loss: 2.0750797679347377

Epoch: 6| Step: 12
Training loss: 2.3008546829223633
Validation loss: 2.073250171958759

Epoch: 6| Step: 13
Training loss: 2.9982986450195312
Validation loss: 2.07156107758963

Epoch: 131| Step: 0
Training loss: 2.6956520080566406
Validation loss: 2.066537954474008

Epoch: 6| Step: 1
Training loss: 2.760317325592041
Validation loss: 2.0862352066142584

Epoch: 6| Step: 2
Training loss: 1.949049472808838
Validation loss: 2.082100410615244

Epoch: 6| Step: 3
Training loss: 1.4207948446273804
Validation loss: 2.076979644836918

Epoch: 6| Step: 4
Training loss: 1.548439621925354
Validation loss: 2.078029804332282

Epoch: 6| Step: 5
Training loss: 1.8139500617980957
Validation loss: 2.0724033450567596

Epoch: 6| Step: 6
Training loss: 2.804734945297241
Validation loss: 2.0688570981384604

Epoch: 6| Step: 7
Training loss: 2.195848226547241
Validation loss: 2.0693448922967397

Epoch: 6| Step: 8
Training loss: 3.0270562171936035
Validation loss: 2.0626590034013152

Epoch: 6| Step: 9
Training loss: 2.610447406768799
Validation loss: 2.070180518652803

Epoch: 6| Step: 10
Training loss: 2.9939680099487305
Validation loss: 2.067457265751336

Epoch: 6| Step: 11
Training loss: 3.0228841304779053
Validation loss: 2.063991491512586

Epoch: 6| Step: 12
Training loss: 2.041421890258789
Validation loss: 2.0603943947822816

Epoch: 6| Step: 13
Training loss: 1.5029406547546387
Validation loss: 2.075481778831892

Epoch: 132| Step: 0
Training loss: 2.5690486431121826
Validation loss: 2.087582870196271

Epoch: 6| Step: 1
Training loss: 1.9927679300308228
Validation loss: 2.101530203255274

Epoch: 6| Step: 2
Training loss: 1.6470866203308105
Validation loss: 2.1067154279319187

Epoch: 6| Step: 3
Training loss: 2.125749349594116
Validation loss: 2.082839281328263

Epoch: 6| Step: 4
Training loss: 2.5222079753875732
Validation loss: 2.0735747032268073

Epoch: 6| Step: 5
Training loss: 2.3335399627685547
Validation loss: 2.059990447054627

Epoch: 6| Step: 6
Training loss: 2.6587905883789062
Validation loss: 2.072177363980201

Epoch: 6| Step: 7
Training loss: 2.0914762020111084
Validation loss: 2.0649490728173205

Epoch: 6| Step: 8
Training loss: 2.3768227100372314
Validation loss: 2.0696064297870924

Epoch: 6| Step: 9
Training loss: 2.3896219730377197
Validation loss: 2.067320180195634

Epoch: 6| Step: 10
Training loss: 2.2793595790863037
Validation loss: 2.059309264665009

Epoch: 6| Step: 11
Training loss: 2.5356268882751465
Validation loss: 2.063630134828629

Epoch: 6| Step: 12
Training loss: 2.4562408924102783
Validation loss: 2.0657635555472424

Epoch: 6| Step: 13
Training loss: 3.662536144256592
Validation loss: 2.0728617175932853

Epoch: 133| Step: 0
Training loss: 2.109727382659912
Validation loss: 2.084169239126226

Epoch: 6| Step: 1
Training loss: 2.259629726409912
Validation loss: 2.0958734327746975

Epoch: 6| Step: 2
Training loss: 2.2235500812530518
Validation loss: 2.102298168725865

Epoch: 6| Step: 3
Training loss: 2.667935371398926
Validation loss: 2.1280593410615

Epoch: 6| Step: 4
Training loss: 2.6306042671203613
Validation loss: 2.1372959357435986

Epoch: 6| Step: 5
Training loss: 2.491166114807129
Validation loss: 2.1336737473805747

Epoch: 6| Step: 6
Training loss: 2.9986801147460938
Validation loss: 2.111758852517733

Epoch: 6| Step: 7
Training loss: 1.692918300628662
Validation loss: 2.1100911735206522

Epoch: 6| Step: 8
Training loss: 2.0730862617492676
Validation loss: 2.087816624231236

Epoch: 6| Step: 9
Training loss: 2.167731285095215
Validation loss: 2.0810653663450673

Epoch: 6| Step: 10
Training loss: 3.0120716094970703
Validation loss: 2.084406038766266

Epoch: 6| Step: 11
Training loss: 2.0851945877075195
Validation loss: 2.0694383933979976

Epoch: 6| Step: 12
Training loss: 1.861785650253296
Validation loss: 2.072604578028443

Epoch: 6| Step: 13
Training loss: 2.4128029346466064
Validation loss: 2.0755705782162246

Epoch: 134| Step: 0
Training loss: 2.5864996910095215
Validation loss: 2.0717430396746566

Epoch: 6| Step: 1
Training loss: 2.3981871604919434
Validation loss: 2.063218588470131

Epoch: 6| Step: 2
Training loss: 2.6929707527160645
Validation loss: 2.070102216095053

Epoch: 6| Step: 3
Training loss: 2.3425896167755127
Validation loss: 2.06434771450617

Epoch: 6| Step: 4
Training loss: 2.0077028274536133
Validation loss: 2.064917607973981

Epoch: 6| Step: 5
Training loss: 2.0806052684783936
Validation loss: 2.055438931270312

Epoch: 6| Step: 6
Training loss: 2.4353208541870117
Validation loss: 2.0550423975913756

Epoch: 6| Step: 7
Training loss: 2.49450945854187
Validation loss: 2.063120854798184

Epoch: 6| Step: 8
Training loss: 1.6697437763214111
Validation loss: 2.07516082256071

Epoch: 6| Step: 9
Training loss: 2.5257673263549805
Validation loss: 2.0759027824606946

Epoch: 6| Step: 10
Training loss: 1.7732462882995605
Validation loss: 2.060168153496199

Epoch: 6| Step: 11
Training loss: 3.1436142921447754
Validation loss: 2.07848015651908

Epoch: 6| Step: 12
Training loss: 1.8708605766296387
Validation loss: 2.0523503083054737

Epoch: 6| Step: 13
Training loss: 2.8689522743225098
Validation loss: 2.0566057171872867

Epoch: 135| Step: 0
Training loss: 2.5202436447143555
Validation loss: 2.054896032938393

Epoch: 6| Step: 1
Training loss: 2.769237518310547
Validation loss: 2.0521392796629216

Epoch: 6| Step: 2
Training loss: 2.3402862548828125
Validation loss: 2.055190678565733

Epoch: 6| Step: 3
Training loss: 1.8124854564666748
Validation loss: 2.054585185102237

Epoch: 6| Step: 4
Training loss: 2.2679290771484375
Validation loss: 2.070434260111983

Epoch: 6| Step: 5
Training loss: 2.5973739624023438
Validation loss: 2.0856670038674467

Epoch: 6| Step: 6
Training loss: 2.3414182662963867
Validation loss: 2.085450990225679

Epoch: 6| Step: 7
Training loss: 2.3567447662353516
Validation loss: 2.0922863188610283

Epoch: 6| Step: 8
Training loss: 2.1551647186279297
Validation loss: 2.115344944820609

Epoch: 6| Step: 9
Training loss: 2.0225815773010254
Validation loss: 2.1158849449567896

Epoch: 6| Step: 10
Training loss: 2.1505563259124756
Validation loss: 2.1295470614587106

Epoch: 6| Step: 11
Training loss: 2.26425838470459
Validation loss: 2.142519002319664

Epoch: 6| Step: 12
Training loss: 2.4067511558532715
Validation loss: 2.148472205285103

Epoch: 6| Step: 13
Training loss: 2.6972222328186035
Validation loss: 2.1307460159383793

Epoch: 136| Step: 0
Training loss: 2.163741111755371
Validation loss: 2.1189866296706663

Epoch: 6| Step: 1
Training loss: 2.418093204498291
Validation loss: 2.1045466366634575

Epoch: 6| Step: 2
Training loss: 2.51772403717041
Validation loss: 2.101886510848999

Epoch: 6| Step: 3
Training loss: 2.580199718475342
Validation loss: 2.1035001534287647

Epoch: 6| Step: 4
Training loss: 2.213503360748291
Validation loss: 2.0954121197423627

Epoch: 6| Step: 5
Training loss: 2.920175075531006
Validation loss: 2.0889418689153527

Epoch: 6| Step: 6
Training loss: 1.9647488594055176
Validation loss: 2.091796193071591

Epoch: 6| Step: 7
Training loss: 1.767210602760315
Validation loss: 2.0909383117511706

Epoch: 6| Step: 8
Training loss: 1.827031135559082
Validation loss: 2.0803344941908315

Epoch: 6| Step: 9
Training loss: 2.1607720851898193
Validation loss: 2.0872052536215833

Epoch: 6| Step: 10
Training loss: 2.731618642807007
Validation loss: 2.096482143607191

Epoch: 6| Step: 11
Training loss: 2.660433769226074
Validation loss: 2.1370533358666206

Epoch: 6| Step: 12
Training loss: 1.9840877056121826
Validation loss: 2.173117019796884

Epoch: 6| Step: 13
Training loss: 3.1314384937286377
Validation loss: 2.194724481592896

Epoch: 137| Step: 0
Training loss: 2.893850564956665
Validation loss: 2.2125176216966365

Epoch: 6| Step: 1
Training loss: 2.4154839515686035
Validation loss: 2.1449616006625596

Epoch: 6| Step: 2
Training loss: 2.5760459899902344
Validation loss: 2.0931524666406776

Epoch: 6| Step: 3
Training loss: 2.6720144748687744
Validation loss: 2.056354784196423

Epoch: 6| Step: 4
Training loss: 1.815116286277771
Validation loss: 2.036843781830162

Epoch: 6| Step: 5
Training loss: 1.8492164611816406
Validation loss: 2.0250570017804383

Epoch: 6| Step: 6
Training loss: 1.7343937158584595
Validation loss: 2.0267182870577742

Epoch: 6| Step: 7
Training loss: 2.3462610244750977
Validation loss: 2.0391884491007817

Epoch: 6| Step: 8
Training loss: 2.2949280738830566
Validation loss: 2.0273701016620924

Epoch: 6| Step: 9
Training loss: 2.3014144897460938
Validation loss: 2.026804911193027

Epoch: 6| Step: 10
Training loss: 1.9297841787338257
Validation loss: 2.0284812424772527

Epoch: 6| Step: 11
Training loss: 2.0318171977996826
Validation loss: 2.054376802136821

Epoch: 6| Step: 12
Training loss: 3.4710116386413574
Validation loss: 2.0740283766100482

Epoch: 6| Step: 13
Training loss: 2.389218330383301
Validation loss: 2.0611750759104246

Epoch: 138| Step: 0
Training loss: 2.1499574184417725
Validation loss: 2.056457414421984

Epoch: 6| Step: 1
Training loss: 2.519070863723755
Validation loss: 2.0435384127401535

Epoch: 6| Step: 2
Training loss: 2.487250328063965
Validation loss: 2.041488278296686

Epoch: 6| Step: 3
Training loss: 1.2195439338684082
Validation loss: 2.039351333854019

Epoch: 6| Step: 4
Training loss: 2.5119874477386475
Validation loss: 2.0428971628988943

Epoch: 6| Step: 5
Training loss: 2.5787947177886963
Validation loss: 2.0550461212793985

Epoch: 6| Step: 6
Training loss: 3.4880423545837402
Validation loss: 2.0589384135379585

Epoch: 6| Step: 7
Training loss: 2.2640814781188965
Validation loss: 2.0622777733751523

Epoch: 6| Step: 8
Training loss: 2.0023579597473145
Validation loss: 2.0604732190409014

Epoch: 6| Step: 9
Training loss: 1.1753604412078857
Validation loss: 2.0680800586618404

Epoch: 6| Step: 10
Training loss: 2.381251811981201
Validation loss: 2.0718131655006

Epoch: 6| Step: 11
Training loss: 2.7573230266571045
Validation loss: 2.084686961225284

Epoch: 6| Step: 12
Training loss: 2.297022819519043
Validation loss: 2.0879069130907775

Epoch: 6| Step: 13
Training loss: 1.9967710971832275
Validation loss: 2.0834885515192503

Epoch: 139| Step: 0
Training loss: 2.2290782928466797
Validation loss: 2.067686261669282

Epoch: 6| Step: 1
Training loss: 1.5718648433685303
Validation loss: 2.07086355199096

Epoch: 6| Step: 2
Training loss: 2.2466514110565186
Validation loss: 2.0612730621009745

Epoch: 6| Step: 3
Training loss: 2.294668197631836
Validation loss: 2.0384014665439563

Epoch: 6| Step: 4
Training loss: 1.8782191276550293
Validation loss: 2.0336334320806686

Epoch: 6| Step: 5
Training loss: 2.5786876678466797
Validation loss: 2.0380889215776996

Epoch: 6| Step: 6
Training loss: 2.4627652168273926
Validation loss: 2.049968698973297

Epoch: 6| Step: 7
Training loss: 2.9209659099578857
Validation loss: 2.060765140800066

Epoch: 6| Step: 8
Training loss: 2.087935447692871
Validation loss: 2.0755823978813748

Epoch: 6| Step: 9
Training loss: 2.974217414855957
Validation loss: 2.0799923763480237

Epoch: 6| Step: 10
Training loss: 2.1582674980163574
Validation loss: 2.06645506299952

Epoch: 6| Step: 11
Training loss: 2.2793946266174316
Validation loss: 2.051787257194519

Epoch: 6| Step: 12
Training loss: 2.2845516204833984
Validation loss: 2.0489407277876333

Epoch: 6| Step: 13
Training loss: 2.139096975326538
Validation loss: 2.0611682322717484

Epoch: 140| Step: 0
Training loss: 2.156179904937744
Validation loss: 2.0756422883720806

Epoch: 6| Step: 1
Training loss: 2.0228066444396973
Validation loss: 2.0812721124259372

Epoch: 6| Step: 2
Training loss: 2.93338680267334
Validation loss: 2.069256308258221

Epoch: 6| Step: 3
Training loss: 2.2455801963806152
Validation loss: 2.0627540593506186

Epoch: 6| Step: 4
Training loss: 2.50075101852417
Validation loss: 2.049041131491302

Epoch: 6| Step: 5
Training loss: 2.511861562728882
Validation loss: 2.052803022887117

Epoch: 6| Step: 6
Training loss: 1.939361572265625
Validation loss: 2.057070880807856

Epoch: 6| Step: 7
Training loss: 2.4869284629821777
Validation loss: 2.0564388536637828

Epoch: 6| Step: 8
Training loss: 2.460420608520508
Validation loss: 2.0780627727508545

Epoch: 6| Step: 9
Training loss: 2.1660547256469727
Validation loss: 2.0922624180393834

Epoch: 6| Step: 10
Training loss: 2.372117042541504
Validation loss: 2.0812894605821177

Epoch: 6| Step: 11
Training loss: 1.986986517906189
Validation loss: 2.066769410205144

Epoch: 6| Step: 12
Training loss: 1.9679397344589233
Validation loss: 2.05333810980602

Epoch: 6| Step: 13
Training loss: 1.9606187343597412
Validation loss: 2.035239158138152

Epoch: 141| Step: 0
Training loss: 2.6334667205810547
Validation loss: 2.0366604430701143

Epoch: 6| Step: 1
Training loss: 2.0534629821777344
Validation loss: 2.037137254591911

Epoch: 6| Step: 2
Training loss: 2.4430840015411377
Validation loss: 2.033754548718852

Epoch: 6| Step: 3
Training loss: 2.4906389713287354
Validation loss: 2.0453627006981963

Epoch: 6| Step: 4
Training loss: 2.0594539642333984
Validation loss: 2.0435703287842455

Epoch: 6| Step: 5
Training loss: 2.227118968963623
Validation loss: 2.039685323674192

Epoch: 6| Step: 6
Training loss: 1.9945147037506104
Validation loss: 2.0275890032450357

Epoch: 6| Step: 7
Training loss: 2.597491502761841
Validation loss: 2.0175016016088505

Epoch: 6| Step: 8
Training loss: 2.5551068782806396
Validation loss: 2.0196300834737797

Epoch: 6| Step: 9
Training loss: 2.2615675926208496
Validation loss: 2.0214595153767574

Epoch: 6| Step: 10
Training loss: 2.459773540496826
Validation loss: 2.0093527711847776

Epoch: 6| Step: 11
Training loss: 2.2955708503723145
Validation loss: 2.010954523599276

Epoch: 6| Step: 12
Training loss: 1.7565244436264038
Validation loss: 2.0164747814978323

Epoch: 6| Step: 13
Training loss: 1.607062816619873
Validation loss: 2.0021399323658278

Epoch: 142| Step: 0
Training loss: 2.0287671089172363
Validation loss: 2.008861598148141

Epoch: 6| Step: 1
Training loss: 1.7686378955841064
Validation loss: 2.006883382797241

Epoch: 6| Step: 2
Training loss: 2.3248701095581055
Validation loss: 2.0083486354479225

Epoch: 6| Step: 3
Training loss: 2.1903553009033203
Validation loss: 2.027369503052004

Epoch: 6| Step: 4
Training loss: 2.009805679321289
Validation loss: 2.023345752428937

Epoch: 6| Step: 5
Training loss: 1.890984296798706
Validation loss: 2.0144623530808317

Epoch: 6| Step: 6
Training loss: 2.2499794960021973
Validation loss: 2.020319846368605

Epoch: 6| Step: 7
Training loss: 2.452566623687744
Validation loss: 2.0159489236852175

Epoch: 6| Step: 8
Training loss: 2.0581259727478027
Validation loss: 2.0151634139399373

Epoch: 6| Step: 9
Training loss: 2.314563274383545
Validation loss: 2.0135094299111316

Epoch: 6| Step: 10
Training loss: 2.024631977081299
Validation loss: 2.002457872513802

Epoch: 6| Step: 11
Training loss: 2.4725022315979004
Validation loss: 1.9958811895821684

Epoch: 6| Step: 12
Training loss: 3.0849907398223877
Validation loss: 1.9890201271221202

Epoch: 6| Step: 13
Training loss: 3.3638715744018555
Validation loss: 2.0033785732843543

Epoch: 143| Step: 0
Training loss: 2.191585063934326
Validation loss: 2.012174565304992

Epoch: 6| Step: 1
Training loss: 2.4773027896881104
Validation loss: 2.025794966246492

Epoch: 6| Step: 2
Training loss: 2.1194493770599365
Validation loss: 2.061803299893615

Epoch: 6| Step: 3
Training loss: 2.022775411605835
Validation loss: 2.0806164151878765

Epoch: 6| Step: 4
Training loss: 1.8365353345870972
Validation loss: 2.0751857334567654

Epoch: 6| Step: 5
Training loss: 1.9407060146331787
Validation loss: 2.106283251957227

Epoch: 6| Step: 6
Training loss: 2.6893460750579834
Validation loss: 2.106326162174184

Epoch: 6| Step: 7
Training loss: 2.598794460296631
Validation loss: 2.03375405393621

Epoch: 6| Step: 8
Training loss: 2.4967546463012695
Validation loss: 2.0247433121486376

Epoch: 6| Step: 9
Training loss: 2.336925506591797
Validation loss: 2.024940618904688

Epoch: 6| Step: 10
Training loss: 2.2243146896362305
Validation loss: 2.032289133276991

Epoch: 6| Step: 11
Training loss: 2.234501361846924
Validation loss: 2.0297863457792547

Epoch: 6| Step: 12
Training loss: 2.302001953125
Validation loss: 2.0316872122467204

Epoch: 6| Step: 13
Training loss: 2.893960475921631
Validation loss: 2.042228764103305

Epoch: 144| Step: 0
Training loss: 2.429964542388916
Validation loss: 2.0564302231675837

Epoch: 6| Step: 1
Training loss: 2.1378860473632812
Validation loss: 2.0817364672178864

Epoch: 6| Step: 2
Training loss: 1.920276403427124
Validation loss: 2.0862165574104554

Epoch: 6| Step: 3
Training loss: 2.2737958431243896
Validation loss: 2.0870990971083283

Epoch: 6| Step: 4
Training loss: 2.3721041679382324
Validation loss: 2.078154343430714

Epoch: 6| Step: 5
Training loss: 2.20408296585083
Validation loss: 2.0796269191208707

Epoch: 6| Step: 6
Training loss: 2.693802833557129
Validation loss: 2.08454462276992

Epoch: 6| Step: 7
Training loss: 3.0875751972198486
Validation loss: 2.103124613402992

Epoch: 6| Step: 8
Training loss: 2.0386300086975098
Validation loss: 2.0943813477793047

Epoch: 6| Step: 9
Training loss: 1.765559196472168
Validation loss: 2.074507849190825

Epoch: 6| Step: 10
Training loss: 1.8785414695739746
Validation loss: 2.061333658874676

Epoch: 6| Step: 11
Training loss: 2.1698508262634277
Validation loss: 2.035354252784483

Epoch: 6| Step: 12
Training loss: 2.0528757572174072
Validation loss: 2.026937655223313

Epoch: 6| Step: 13
Training loss: 3.154524803161621
Validation loss: 2.0252851196514663

Epoch: 145| Step: 0
Training loss: 1.963132619857788
Validation loss: 2.0293546774054088

Epoch: 6| Step: 1
Training loss: 2.3890647888183594
Validation loss: 2.0605558118512555

Epoch: 6| Step: 2
Training loss: 2.7129788398742676
Validation loss: 2.087189241122174

Epoch: 6| Step: 3
Training loss: 2.1278603076934814
Validation loss: 2.078505587834184

Epoch: 6| Step: 4
Training loss: 1.7437915802001953
Validation loss: 2.099630739099236

Epoch: 6| Step: 5
Training loss: 1.7693901062011719
Validation loss: 2.080545638197212

Epoch: 6| Step: 6
Training loss: 2.8637638092041016
Validation loss: 2.1100487324499313

Epoch: 6| Step: 7
Training loss: 1.9097093343734741
Validation loss: 2.1191193442190848

Epoch: 6| Step: 8
Training loss: 3.3268837928771973
Validation loss: 2.150585828288909

Epoch: 6| Step: 9
Training loss: 2.188055992126465
Validation loss: 2.1702248921958347

Epoch: 6| Step: 10
Training loss: 2.7267041206359863
Validation loss: 2.151632273068992

Epoch: 6| Step: 11
Training loss: 2.0017330646514893
Validation loss: 2.149961274157288

Epoch: 6| Step: 12
Training loss: 2.205117702484131
Validation loss: 2.119652663507769

Epoch: 6| Step: 13
Training loss: 2.5442051887512207
Validation loss: 2.1068650778903755

Epoch: 146| Step: 0
Training loss: 2.1702098846435547
Validation loss: 2.1006907186200543

Epoch: 6| Step: 1
Training loss: 2.4954347610473633
Validation loss: 2.094415000689927

Epoch: 6| Step: 2
Training loss: 1.6714165210723877
Validation loss: 2.082662954125353

Epoch: 6| Step: 3
Training loss: 2.790131092071533
Validation loss: 2.091289525390953

Epoch: 6| Step: 4
Training loss: 2.760972499847412
Validation loss: 2.1038893781682497

Epoch: 6| Step: 5
Training loss: 2.6016669273376465
Validation loss: 2.077143730655793

Epoch: 6| Step: 6
Training loss: 2.7456178665161133
Validation loss: 2.0603208336778867

Epoch: 6| Step: 7
Training loss: 2.3983442783355713
Validation loss: 2.042076454367689

Epoch: 6| Step: 8
Training loss: 1.9164369106292725
Validation loss: 2.0397779480103524

Epoch: 6| Step: 9
Training loss: 1.5145246982574463
Validation loss: 2.0338336190869732

Epoch: 6| Step: 10
Training loss: 2.4612984657287598
Validation loss: 2.026726127952658

Epoch: 6| Step: 11
Training loss: 2.380911350250244
Validation loss: 2.041134084424665

Epoch: 6| Step: 12
Training loss: 1.788360357284546
Validation loss: 2.033110417345519

Epoch: 6| Step: 13
Training loss: 2.07804274559021
Validation loss: 2.0377053137748473

Epoch: 147| Step: 0
Training loss: 2.124279499053955
Validation loss: 2.0407449763308287

Epoch: 6| Step: 1
Training loss: 2.2565112113952637
Validation loss: 2.0405688080736386

Epoch: 6| Step: 2
Training loss: 2.3738951683044434
Validation loss: 2.0458197644961778

Epoch: 6| Step: 3
Training loss: 2.3539838790893555
Validation loss: 2.083595218196992

Epoch: 6| Step: 4
Training loss: 2.575225591659546
Validation loss: 2.0929252127165436

Epoch: 6| Step: 5
Training loss: 1.8123427629470825
Validation loss: 2.190326313818655

Epoch: 6| Step: 6
Training loss: 2.6870083808898926
Validation loss: 2.2520911437208935

Epoch: 6| Step: 7
Training loss: 1.6686031818389893
Validation loss: 2.2305320103963218

Epoch: 6| Step: 8
Training loss: 3.1609065532684326
Validation loss: 2.186360848847256

Epoch: 6| Step: 9
Training loss: 2.723522186279297
Validation loss: 2.1065583972520727

Epoch: 6| Step: 10
Training loss: 1.9845198392868042
Validation loss: 2.0208969423847813

Epoch: 6| Step: 11
Training loss: 1.8160320520401
Validation loss: 2.014542361741425

Epoch: 6| Step: 12
Training loss: 2.408923387527466
Validation loss: 2.0321407164296796

Epoch: 6| Step: 13
Training loss: 1.8784395456314087
Validation loss: 2.0534612158293366

Epoch: 148| Step: 0
Training loss: 2.0980947017669678
Validation loss: 2.016335028474049

Epoch: 6| Step: 1
Training loss: 1.9433236122131348
Validation loss: 2.0172844471470004

Epoch: 6| Step: 2
Training loss: 2.771070957183838
Validation loss: 2.007123419033584

Epoch: 6| Step: 3
Training loss: 2.679483652114868
Validation loss: 2.0017563937812723

Epoch: 6| Step: 4
Training loss: 2.223619222640991
Validation loss: 1.9912366341519099

Epoch: 6| Step: 5
Training loss: 1.6716878414154053
Validation loss: 1.9859253668016004

Epoch: 6| Step: 6
Training loss: 2.09437894821167
Validation loss: 1.97862886100687

Epoch: 6| Step: 7
Training loss: 2.3138959407806396
Validation loss: 1.9757961996140019

Epoch: 6| Step: 8
Training loss: 1.8579767942428589
Validation loss: 1.9852776899132678

Epoch: 6| Step: 9
Training loss: 2.284976005554199
Validation loss: 1.9802287586273686

Epoch: 6| Step: 10
Training loss: 1.9902989864349365
Validation loss: 1.9812035406789472

Epoch: 6| Step: 11
Training loss: 2.490532398223877
Validation loss: 1.9814932141252743

Epoch: 6| Step: 12
Training loss: 2.541666030883789
Validation loss: 1.9831714963400235

Epoch: 6| Step: 13
Training loss: 2.669438362121582
Validation loss: 1.9847150874394242

Epoch: 149| Step: 0
Training loss: 2.2777371406555176
Validation loss: 1.984101858190311

Epoch: 6| Step: 1
Training loss: 2.623091220855713
Validation loss: 1.9900295401132235

Epoch: 6| Step: 2
Training loss: 2.2124381065368652
Validation loss: 1.978396656692669

Epoch: 6| Step: 3
Training loss: 1.7514264583587646
Validation loss: 1.9788856724257111

Epoch: 6| Step: 4
Training loss: 2.534714460372925
Validation loss: 1.9685502218943771

Epoch: 6| Step: 5
Training loss: 2.5094761848449707
Validation loss: 1.983215796050205

Epoch: 6| Step: 6
Training loss: 2.329859733581543
Validation loss: 1.9974636262462986

Epoch: 6| Step: 7
Training loss: 2.5723652839660645
Validation loss: 1.987041199079124

Epoch: 6| Step: 8
Training loss: 2.4999961853027344
Validation loss: 1.9867508052497782

Epoch: 6| Step: 9
Training loss: 1.9190874099731445
Validation loss: 1.9765591018943376

Epoch: 6| Step: 10
Training loss: 2.795858383178711
Validation loss: 1.980545634864479

Epoch: 6| Step: 11
Training loss: 1.7803194522857666
Validation loss: 1.9769532167783348

Epoch: 6| Step: 12
Training loss: 1.5131183862686157
Validation loss: 1.960558291404478

Epoch: 6| Step: 13
Training loss: 2.6181623935699463
Validation loss: 1.977462660881781

Epoch: 150| Step: 0
Training loss: 3.1366629600524902
Validation loss: 1.9762511227720527

Epoch: 6| Step: 1
Training loss: 1.8158905506134033
Validation loss: 1.9767894103962889

Epoch: 6| Step: 2
Training loss: 2.933426856994629
Validation loss: 1.9735013015808598

Epoch: 6| Step: 3
Training loss: 1.8452247381210327
Validation loss: 1.970832178669591

Epoch: 6| Step: 4
Training loss: 1.1223340034484863
Validation loss: 1.9805823987530125

Epoch: 6| Step: 5
Training loss: 2.4531452655792236
Validation loss: 1.977414213201051

Epoch: 6| Step: 6
Training loss: 2.477965831756592
Validation loss: 1.9955246999699583

Epoch: 6| Step: 7
Training loss: 1.8449002504348755
Validation loss: 2.022123445746719

Epoch: 6| Step: 8
Training loss: 2.1970109939575195
Validation loss: 2.0308509949714906

Epoch: 6| Step: 9
Training loss: 1.938460111618042
Validation loss: 2.0461466338044856

Epoch: 6| Step: 10
Training loss: 2.5611510276794434
Validation loss: 2.0345798794941237

Epoch: 6| Step: 11
Training loss: 2.9245100021362305
Validation loss: 2.0223440201051774

Epoch: 6| Step: 12
Training loss: 2.2113471031188965
Validation loss: 2.0150903681273102

Epoch: 6| Step: 13
Training loss: 1.8620866537094116
Validation loss: 2.0137491918379262

Epoch: 151| Step: 0
Training loss: 2.2677130699157715
Validation loss: 2.0030687906408824

Epoch: 6| Step: 1
Training loss: 2.15017032623291
Validation loss: 2.0094209742802445

Epoch: 6| Step: 2
Training loss: 2.388848066329956
Validation loss: 2.0240768066016575

Epoch: 6| Step: 3
Training loss: 2.120162010192871
Validation loss: 2.0285351519943564

Epoch: 6| Step: 4
Training loss: 1.6894755363464355
Validation loss: 2.052040256479735

Epoch: 6| Step: 5
Training loss: 2.2356882095336914
Validation loss: 2.048249465163036

Epoch: 6| Step: 6
Training loss: 2.40783953666687
Validation loss: 2.039414628859489

Epoch: 6| Step: 7
Training loss: 1.5800195932388306
Validation loss: 2.0542735412556636

Epoch: 6| Step: 8
Training loss: 2.464890480041504
Validation loss: 2.0636144517570414

Epoch: 6| Step: 9
Training loss: 1.9369590282440186
Validation loss: 2.078511053516019

Epoch: 6| Step: 10
Training loss: 2.6652591228485107
Validation loss: 2.083703822987054

Epoch: 6| Step: 11
Training loss: 2.537672519683838
Validation loss: 2.0875866618207706

Epoch: 6| Step: 12
Training loss: 2.559967041015625
Validation loss: 2.0936318802577194

Epoch: 6| Step: 13
Training loss: 2.4253523349761963
Validation loss: 2.082525676296603

Epoch: 152| Step: 0
Training loss: 2.5940985679626465
Validation loss: 2.064092997581728

Epoch: 6| Step: 1
Training loss: 3.1593499183654785
Validation loss: 2.040818609217162

Epoch: 6| Step: 2
Training loss: 2.1111106872558594
Validation loss: 2.026675906232608

Epoch: 6| Step: 3
Training loss: 2.4692585468292236
Validation loss: 2.0296215216318765

Epoch: 6| Step: 4
Training loss: 1.641335368156433
Validation loss: 2.0285826447189494

Epoch: 6| Step: 5
Training loss: 2.4016432762145996
Validation loss: 2.0503308901222805

Epoch: 6| Step: 6
Training loss: 2.0850577354431152
Validation loss: 2.082169666085192

Epoch: 6| Step: 7
Training loss: 2.583261013031006
Validation loss: 2.094468911488851

Epoch: 6| Step: 8
Training loss: 1.9829617738723755
Validation loss: 2.0654310000840055

Epoch: 6| Step: 9
Training loss: 1.5410442352294922
Validation loss: 2.042694568634033

Epoch: 6| Step: 10
Training loss: 1.6940906047821045
Validation loss: 2.0164352514410533

Epoch: 6| Step: 11
Training loss: 2.4935269355773926
Validation loss: 2.0156859454288276

Epoch: 6| Step: 12
Training loss: 2.735605001449585
Validation loss: 2.0612071227001887

Epoch: 6| Step: 13
Training loss: 2.5804760456085205
Validation loss: 2.1035808773450952

Epoch: 153| Step: 0
Training loss: 2.2214314937591553
Validation loss: 2.164757746522145

Epoch: 6| Step: 1
Training loss: 2.7859179973602295
Validation loss: 2.2038837453370452

Epoch: 6| Step: 2
Training loss: 2.8600242137908936
Validation loss: 2.2542922573704876

Epoch: 6| Step: 3
Training loss: 2.8797125816345215
Validation loss: 2.266300739780549

Epoch: 6| Step: 4
Training loss: 2.065608501434326
Validation loss: 2.2539014765011367

Epoch: 6| Step: 5
Training loss: 2.0065956115722656
Validation loss: 2.21395206451416

Epoch: 6| Step: 6
Training loss: 2.6080117225646973
Validation loss: 2.1450375895346365

Epoch: 6| Step: 7
Training loss: 2.5825836658477783
Validation loss: 2.079352940282514

Epoch: 6| Step: 8
Training loss: 1.9996764659881592
Validation loss: 2.0785054442703084

Epoch: 6| Step: 9
Training loss: 1.7592928409576416
Validation loss: 2.136701763317149

Epoch: 6| Step: 10
Training loss: 2.474837303161621
Validation loss: 2.201894311494725

Epoch: 6| Step: 11
Training loss: 2.623448133468628
Validation loss: 2.2470752513536842

Epoch: 6| Step: 12
Training loss: 2.7367944717407227
Validation loss: 2.197580414433633

Epoch: 6| Step: 13
Training loss: 1.8901203870773315
Validation loss: 2.130607392198296

Epoch: 154| Step: 0
Training loss: 2.4208521842956543
Validation loss: 2.136058653554609

Epoch: 6| Step: 1
Training loss: 2.5939784049987793
Validation loss: 2.1111334959665933

Epoch: 6| Step: 2
Training loss: 2.0278468132019043
Validation loss: 2.1337906468299126

Epoch: 6| Step: 3
Training loss: 2.2313284873962402
Validation loss: 2.1201649686341644

Epoch: 6| Step: 4
Training loss: 2.388596534729004
Validation loss: 2.099682137530337

Epoch: 6| Step: 5
Training loss: 2.349431037902832
Validation loss: 2.097135713023524

Epoch: 6| Step: 6
Training loss: 2.290515422821045
Validation loss: 2.0710882012562086

Epoch: 6| Step: 7
Training loss: 2.2345564365386963
Validation loss: 2.0589640063624226

Epoch: 6| Step: 8
Training loss: 1.8128294944763184
Validation loss: 2.043310091059695

Epoch: 6| Step: 9
Training loss: 2.0994269847869873
Validation loss: 2.0302177565072173

Epoch: 6| Step: 10
Training loss: 1.8287111520767212
Validation loss: 2.0357845021832373

Epoch: 6| Step: 11
Training loss: 2.5659751892089844
Validation loss: 2.0434798322698122

Epoch: 6| Step: 12
Training loss: 2.0912625789642334
Validation loss: 2.065891924724784

Epoch: 6| Step: 13
Training loss: 2.9000792503356934
Validation loss: 2.0780130970862603

Epoch: 155| Step: 0
Training loss: 2.631653070449829
Validation loss: 2.0667764935442197

Epoch: 6| Step: 1
Training loss: 2.155522584915161
Validation loss: 2.0622152166981853

Epoch: 6| Step: 2
Training loss: 1.608605980873108
Validation loss: 2.0410831769307456

Epoch: 6| Step: 3
Training loss: 3.0436530113220215
Validation loss: 2.0095358023079495

Epoch: 6| Step: 4
Training loss: 2.932662010192871
Validation loss: 1.9889508729339929

Epoch: 6| Step: 5
Training loss: 1.8664923906326294
Validation loss: 1.9669563616475751

Epoch: 6| Step: 6
Training loss: 1.5660884380340576
Validation loss: 1.9702884151089577

Epoch: 6| Step: 7
Training loss: 2.0608749389648438
Validation loss: 1.9784259283414452

Epoch: 6| Step: 8
Training loss: 2.293571949005127
Validation loss: 1.9795471763098111

Epoch: 6| Step: 9
Training loss: 2.5611815452575684
Validation loss: 1.981059428184263

Epoch: 6| Step: 10
Training loss: 1.7208905220031738
Validation loss: 1.9833849706957418

Epoch: 6| Step: 11
Training loss: 2.0753531455993652
Validation loss: 1.9959594459943875

Epoch: 6| Step: 12
Training loss: 2.5447797775268555
Validation loss: 2.013984485339093

Epoch: 6| Step: 13
Training loss: 2.0847179889678955
Validation loss: 1.996893472568963

Epoch: 156| Step: 0
Training loss: 1.6802270412445068
Validation loss: 1.990144674495984

Epoch: 6| Step: 1
Training loss: 2.695162773132324
Validation loss: 1.9831620749606882

Epoch: 6| Step: 2
Training loss: 2.096597194671631
Validation loss: 1.9811539265417284

Epoch: 6| Step: 3
Training loss: 1.625481128692627
Validation loss: 1.9803295263680079

Epoch: 6| Step: 4
Training loss: 1.9828884601593018
Validation loss: 1.9815101726080782

Epoch: 6| Step: 5
Training loss: 2.1558585166931152
Validation loss: 1.9741505397263395

Epoch: 6| Step: 6
Training loss: 2.3901889324188232
Validation loss: 1.9796744033854494

Epoch: 6| Step: 7
Training loss: 2.0337729454040527
Validation loss: 1.9816292921702068

Epoch: 6| Step: 8
Training loss: 1.908000111579895
Validation loss: 1.9790658361168318

Epoch: 6| Step: 9
Training loss: 2.645266056060791
Validation loss: 1.9757669459107101

Epoch: 6| Step: 10
Training loss: 2.1844282150268555
Validation loss: 1.9768420406567153

Epoch: 6| Step: 11
Training loss: 2.629210948944092
Validation loss: 1.9793482621510823

Epoch: 6| Step: 12
Training loss: 1.8906280994415283
Validation loss: 1.9778000552167174

Epoch: 6| Step: 13
Training loss: 3.132606267929077
Validation loss: 1.971170239551093

Epoch: 157| Step: 0
Training loss: 2.017448902130127
Validation loss: 1.9740149795368154

Epoch: 6| Step: 1
Training loss: 1.7823976278305054
Validation loss: 1.9791872386009461

Epoch: 6| Step: 2
Training loss: 2.1489617824554443
Validation loss: 1.9749058946486442

Epoch: 6| Step: 3
Training loss: 2.6885008811950684
Validation loss: 1.9895126358155282

Epoch: 6| Step: 4
Training loss: 2.1584160327911377
Validation loss: 1.9865330880688084

Epoch: 6| Step: 5
Training loss: 2.07633113861084
Validation loss: 1.981197073895444

Epoch: 6| Step: 6
Training loss: 2.483640670776367
Validation loss: 1.9929072844084872

Epoch: 6| Step: 7
Training loss: 2.9852073192596436
Validation loss: 2.0107232447593444

Epoch: 6| Step: 8
Training loss: 2.289611339569092
Validation loss: 2.0192074596240954

Epoch: 6| Step: 9
Training loss: 2.451241970062256
Validation loss: 2.0342658976072907

Epoch: 6| Step: 10
Training loss: 2.4794139862060547
Validation loss: 2.026537561929354

Epoch: 6| Step: 11
Training loss: 1.865095853805542
Validation loss: 2.0137481932998984

Epoch: 6| Step: 12
Training loss: 1.445704460144043
Validation loss: 2.011765456968738

Epoch: 6| Step: 13
Training loss: 1.6179916858673096
Validation loss: 2.004765413140738

Epoch: 158| Step: 0
Training loss: 1.3029587268829346
Validation loss: 2.003844787997584

Epoch: 6| Step: 1
Training loss: 2.6082074642181396
Validation loss: 2.011104004357451

Epoch: 6| Step: 2
Training loss: 2.3083889484405518
Validation loss: 2.042943803212976

Epoch: 6| Step: 3
Training loss: 2.079406499862671
Validation loss: 2.072648379110521

Epoch: 6| Step: 4
Training loss: 1.3073019981384277
Validation loss: 2.09252840985534

Epoch: 6| Step: 5
Training loss: 2.3085553646087646
Validation loss: 2.0552257889060566

Epoch: 6| Step: 6
Training loss: 2.8128247261047363
Validation loss: 2.011300140811551

Epoch: 6| Step: 7
Training loss: 1.5683856010437012
Validation loss: 1.970559339369497

Epoch: 6| Step: 8
Training loss: 1.5739071369171143
Validation loss: 1.9785717110480032

Epoch: 6| Step: 9
Training loss: 2.630915641784668
Validation loss: 1.9685992361396871

Epoch: 6| Step: 10
Training loss: 2.5080296993255615
Validation loss: 1.9733879168828328

Epoch: 6| Step: 11
Training loss: 2.6455237865448
Validation loss: 1.9553989953892206

Epoch: 6| Step: 12
Training loss: 2.4736056327819824
Validation loss: 1.9449807418290006

Epoch: 6| Step: 13
Training loss: 2.693629264831543
Validation loss: 1.942262288062803

Epoch: 159| Step: 0
Training loss: 1.6524078845977783
Validation loss: 1.9303713306303947

Epoch: 6| Step: 1
Training loss: 2.3293466567993164
Validation loss: 1.9321933228482482

Epoch: 6| Step: 2
Training loss: 1.9634366035461426
Validation loss: 1.9402015696289718

Epoch: 6| Step: 3
Training loss: 3.4109930992126465
Validation loss: 1.931618817390934

Epoch: 6| Step: 4
Training loss: 2.6569480895996094
Validation loss: 1.939364972934928

Epoch: 6| Step: 5
Training loss: 2.63456392288208
Validation loss: 1.9318914644179805

Epoch: 6| Step: 6
Training loss: 1.7746994495391846
Validation loss: 1.9388207748372068

Epoch: 6| Step: 7
Training loss: 1.602508306503296
Validation loss: 1.93712721396518

Epoch: 6| Step: 8
Training loss: 1.7486876249313354
Validation loss: 1.9367793465173373

Epoch: 6| Step: 9
Training loss: 1.8779397010803223
Validation loss: 1.952133503011478

Epoch: 6| Step: 10
Training loss: 1.9409945011138916
Validation loss: 1.9664961227806665

Epoch: 6| Step: 11
Training loss: 2.3047518730163574
Validation loss: 1.9835134449825491

Epoch: 6| Step: 12
Training loss: 2.2595267295837402
Validation loss: 2.001940838752254

Epoch: 6| Step: 13
Training loss: 2.3996565341949463
Validation loss: 2.0101900280162854

Epoch: 160| Step: 0
Training loss: 3.141846179962158
Validation loss: 2.0091706616904146

Epoch: 6| Step: 1
Training loss: 2.310059070587158
Validation loss: 1.9807158913663638

Epoch: 6| Step: 2
Training loss: 2.349285364151001
Validation loss: 1.9685700401183097

Epoch: 6| Step: 3
Training loss: 1.818498134613037
Validation loss: 1.9713838254251788

Epoch: 6| Step: 4
Training loss: 1.3476109504699707
Validation loss: 1.9877911383105862

Epoch: 6| Step: 5
Training loss: 2.501333713531494
Validation loss: 2.0056334618599183

Epoch: 6| Step: 6
Training loss: 2.343857765197754
Validation loss: 2.0104735128341185

Epoch: 6| Step: 7
Training loss: 2.2897329330444336
Validation loss: 2.0143995028670116

Epoch: 6| Step: 8
Training loss: 1.9435521364212036
Validation loss: 2.0118928263264317

Epoch: 6| Step: 9
Training loss: 2.397648334503174
Validation loss: 1.985667315862512

Epoch: 6| Step: 10
Training loss: 2.1616368293762207
Validation loss: 1.9846093411086707

Epoch: 6| Step: 11
Training loss: 2.634885549545288
Validation loss: 1.9839331565364715

Epoch: 6| Step: 12
Training loss: 1.6493427753448486
Validation loss: 1.9828639209911387

Epoch: 6| Step: 13
Training loss: 1.1302582025527954
Validation loss: 1.9970282431571715

Epoch: 161| Step: 0
Training loss: 1.8840291500091553
Validation loss: 2.006392122596823

Epoch: 6| Step: 1
Training loss: 1.920735478401184
Validation loss: 2.014961100393726

Epoch: 6| Step: 2
Training loss: 1.8656463623046875
Validation loss: 2.032314331300797

Epoch: 6| Step: 3
Training loss: 2.221536874771118
Validation loss: 2.054617961247762

Epoch: 6| Step: 4
Training loss: 2.0844600200653076
Validation loss: 2.0667166607354277

Epoch: 6| Step: 5
Training loss: 2.062648057937622
Validation loss: 2.0836366299659974

Epoch: 6| Step: 6
Training loss: 1.9835466146469116
Validation loss: 2.0966160323030207

Epoch: 6| Step: 7
Training loss: 2.954906463623047
Validation loss: 2.10244990933326

Epoch: 6| Step: 8
Training loss: 2.3563990592956543
Validation loss: 2.099001028204477

Epoch: 6| Step: 9
Training loss: 2.3394994735717773
Validation loss: 2.0761458745566745

Epoch: 6| Step: 10
Training loss: 1.6319146156311035
Validation loss: 2.0618697802225747

Epoch: 6| Step: 11
Training loss: 2.355741262435913
Validation loss: 2.047552767620292

Epoch: 6| Step: 12
Training loss: 1.954324722290039
Validation loss: 2.043461174093267

Epoch: 6| Step: 13
Training loss: 2.1276280879974365
Validation loss: 2.0559468961531118

Epoch: 162| Step: 0
Training loss: 2.251936435699463
Validation loss: 2.053367821119165

Epoch: 6| Step: 1
Training loss: 1.7292261123657227
Validation loss: 2.0615440209706626

Epoch: 6| Step: 2
Training loss: 2.2855803966522217
Validation loss: 2.067602861312128

Epoch: 6| Step: 3
Training loss: 2.440087080001831
Validation loss: 2.0538249015808105

Epoch: 6| Step: 4
Training loss: 1.9278266429901123
Validation loss: 2.0567891443929365

Epoch: 6| Step: 5
Training loss: 2.7230591773986816
Validation loss: 2.0399122494523243

Epoch: 6| Step: 6
Training loss: 2.0420470237731934
Validation loss: 2.048878405683784

Epoch: 6| Step: 7
Training loss: 1.770371675491333
Validation loss: 2.0459670982053204

Epoch: 6| Step: 8
Training loss: 0.8729361891746521
Validation loss: 2.0373815054534585

Epoch: 6| Step: 9
Training loss: 2.313222646713257
Validation loss: 2.030160750112226

Epoch: 6| Step: 10
Training loss: 1.965131163597107
Validation loss: 2.0497851525583575

Epoch: 6| Step: 11
Training loss: 2.378969192504883
Validation loss: 2.0337985600194624

Epoch: 6| Step: 12
Training loss: 1.9627633094787598
Validation loss: 2.0345566195826374

Epoch: 6| Step: 13
Training loss: 3.58288311958313
Validation loss: 2.0388514200846353

Epoch: 163| Step: 0
Training loss: 1.9753543138504028
Validation loss: 2.0344400546884023

Epoch: 6| Step: 1
Training loss: 1.9899944067001343
Validation loss: 2.032051706826815

Epoch: 6| Step: 2
Training loss: 1.4740827083587646
Validation loss: 2.047530713901725

Epoch: 6| Step: 3
Training loss: 2.1631951332092285
Validation loss: 2.073290523662362

Epoch: 6| Step: 4
Training loss: 2.09670352935791
Validation loss: 2.0904448340016026

Epoch: 6| Step: 5
Training loss: 2.261845350265503
Validation loss: 2.1300680970632904

Epoch: 6| Step: 6
Training loss: 2.2066497802734375
Validation loss: 2.157141852122481

Epoch: 6| Step: 7
Training loss: 2.3298768997192383
Validation loss: 2.1457659480392293

Epoch: 6| Step: 8
Training loss: 2.140390396118164
Validation loss: 2.176791229555684

Epoch: 6| Step: 9
Training loss: 2.0041489601135254
Validation loss: 2.150131258913266

Epoch: 6| Step: 10
Training loss: 2.4540629386901855
Validation loss: 2.091838167559716

Epoch: 6| Step: 11
Training loss: 2.137937068939209
Validation loss: 2.0596261691021662

Epoch: 6| Step: 12
Training loss: 1.8426477909088135
Validation loss: 2.0439611070899555

Epoch: 6| Step: 13
Training loss: 2.2333242893218994
Validation loss: 2.037801588735273

Epoch: 164| Step: 0
Training loss: 2.563875913619995
Validation loss: 2.0306650566798385

Epoch: 6| Step: 1
Training loss: 1.9840917587280273
Validation loss: 2.009892522647817

Epoch: 6| Step: 2
Training loss: 1.308523416519165
Validation loss: 2.0054113480352584

Epoch: 6| Step: 3
Training loss: 1.9505269527435303
Validation loss: 1.9843679230700257

Epoch: 6| Step: 4
Training loss: 1.9522074460983276
Validation loss: 1.9737720540774766

Epoch: 6| Step: 5
Training loss: 2.3487496376037598
Validation loss: 1.9650567654640443

Epoch: 6| Step: 6
Training loss: 1.767642855644226
Validation loss: 1.9683616430528703

Epoch: 6| Step: 7
Training loss: 2.1224708557128906
Validation loss: 1.9945112248902679

Epoch: 6| Step: 8
Training loss: 2.629209518432617
Validation loss: 2.0283274189118417

Epoch: 6| Step: 9
Training loss: 2.3280434608459473
Validation loss: 2.0455868654353644

Epoch: 6| Step: 10
Training loss: 2.551307201385498
Validation loss: 2.047123283468267

Epoch: 6| Step: 11
Training loss: 2.6599087715148926
Validation loss: 2.044530225056474

Epoch: 6| Step: 12
Training loss: 1.6330244541168213
Validation loss: 2.0562564608871297

Epoch: 6| Step: 13
Training loss: 1.8792462348937988
Validation loss: 2.063179067386094

Epoch: 165| Step: 0
Training loss: 1.8557868003845215
Validation loss: 2.077323067572809

Epoch: 6| Step: 1
Training loss: 1.3919018507003784
Validation loss: 2.0911375604650027

Epoch: 6| Step: 2
Training loss: 1.9493026733398438
Validation loss: 2.1082094202759447

Epoch: 6| Step: 3
Training loss: 2.871014356613159
Validation loss: 2.1077442374280704

Epoch: 6| Step: 4
Training loss: 1.6951794624328613
Validation loss: 2.111408381051915

Epoch: 6| Step: 5
Training loss: 1.8819541931152344
Validation loss: 2.1197304494919313

Epoch: 6| Step: 6
Training loss: 2.380844831466675
Validation loss: 2.1291630191187703

Epoch: 6| Step: 7
Training loss: 2.6670398712158203
Validation loss: 2.1255727762817056

Epoch: 6| Step: 8
Training loss: 2.343230724334717
Validation loss: 2.133885186205628

Epoch: 6| Step: 9
Training loss: 2.0715644359588623
Validation loss: 2.125028737129704

Epoch: 6| Step: 10
Training loss: 2.174619197845459
Validation loss: 2.125726261446553

Epoch: 6| Step: 11
Training loss: 1.9133652448654175
Validation loss: 2.116070234647361

Epoch: 6| Step: 12
Training loss: 1.629201889038086
Validation loss: 2.1420338025657077

Epoch: 6| Step: 13
Training loss: 2.738063335418701
Validation loss: 2.2061126001419558

Epoch: 166| Step: 0
Training loss: 2.253321647644043
Validation loss: 2.187170966978996

Epoch: 6| Step: 1
Training loss: 1.977863073348999
Validation loss: 2.160715840196097

Epoch: 6| Step: 2
Training loss: 2.347011089324951
Validation loss: 2.1423540769084806

Epoch: 6| Step: 3
Training loss: 1.7803272008895874
Validation loss: 2.1090070406595864

Epoch: 6| Step: 4
Training loss: 1.9388763904571533
Validation loss: 2.0971972134805497

Epoch: 6| Step: 5
Training loss: 2.24977707862854
Validation loss: 2.08053857023998

Epoch: 6| Step: 6
Training loss: 2.1419413089752197
Validation loss: 2.081431766991974

Epoch: 6| Step: 7
Training loss: 2.0779786109924316
Validation loss: 2.0870785110740253

Epoch: 6| Step: 8
Training loss: 2.5933690071105957
Validation loss: 2.100465420753725

Epoch: 6| Step: 9
Training loss: 1.74367094039917
Validation loss: 2.1087834501779206

Epoch: 6| Step: 10
Training loss: 1.8472694158554077
Validation loss: 2.1041774493391796

Epoch: 6| Step: 11
Training loss: 2.5261454582214355
Validation loss: 2.0982047742412937

Epoch: 6| Step: 12
Training loss: 1.3198002576828003
Validation loss: 2.097562692498648

Epoch: 6| Step: 13
Training loss: 2.348369836807251
Validation loss: 2.1013906437863588

Epoch: 167| Step: 0
Training loss: 2.4735159873962402
Validation loss: 2.0975464646534254

Epoch: 6| Step: 1
Training loss: 1.797720193862915
Validation loss: 2.0777844511052614

Epoch: 6| Step: 2
Training loss: 2.179736852645874
Validation loss: 2.0966297477804203

Epoch: 6| Step: 3
Training loss: 2.5068931579589844
Validation loss: 2.098436668354978

Epoch: 6| Step: 4
Training loss: 2.0227713584899902
Validation loss: 2.088914453342397

Epoch: 6| Step: 5
Training loss: 1.5962047576904297
Validation loss: 2.084510104630583

Epoch: 6| Step: 6
Training loss: 1.6619008779525757
Validation loss: 2.0948314333474762

Epoch: 6| Step: 7
Training loss: 1.9160306453704834
Validation loss: 2.090907394245107

Epoch: 6| Step: 8
Training loss: 1.8271111249923706
Validation loss: 2.097841215390031

Epoch: 6| Step: 9
Training loss: 2.033862829208374
Validation loss: 2.1160183081062893

Epoch: 6| Step: 10
Training loss: 2.5032663345336914
Validation loss: 2.1203990315878265

Epoch: 6| Step: 11
Training loss: 1.8732270002365112
Validation loss: 2.1210103034973145

Epoch: 6| Step: 12
Training loss: 1.7672317028045654
Validation loss: 2.1197813454494683

Epoch: 6| Step: 13
Training loss: 2.0248379707336426
Validation loss: 2.122242460968674

Epoch: 168| Step: 0
Training loss: 2.2639572620391846
Validation loss: 2.0587260748750422

Epoch: 6| Step: 1
Training loss: 2.4560751914978027
Validation loss: 2.0358740821961434

Epoch: 6| Step: 2
Training loss: 2.227480411529541
Validation loss: 2.013176595011065

Epoch: 6| Step: 3
Training loss: 1.8493397235870361
Validation loss: 2.004865975790126

Epoch: 6| Step: 4
Training loss: 2.185894012451172
Validation loss: 1.9931202819270473

Epoch: 6| Step: 5
Training loss: 1.6846110820770264
Validation loss: 1.999691511995049

Epoch: 6| Step: 6
Training loss: 1.6502039432525635
Validation loss: 2.000469091118023

Epoch: 6| Step: 7
Training loss: 2.017671585083008
Validation loss: 2.018240177503196

Epoch: 6| Step: 8
Training loss: 1.6926369667053223
Validation loss: 2.007923810712753

Epoch: 6| Step: 9
Training loss: 2.205528497695923
Validation loss: 2.04288230147413

Epoch: 6| Step: 10
Training loss: 2.6870837211608887
Validation loss: 2.043825916064683

Epoch: 6| Step: 11
Training loss: 1.7113468647003174
Validation loss: 2.0403546787077382

Epoch: 6| Step: 12
Training loss: 1.6471935510635376
Validation loss: 2.014031525581114

Epoch: 6| Step: 13
Training loss: 3.0514261722564697
Validation loss: 2.0418634876128166

Epoch: 169| Step: 0
Training loss: 1.9037485122680664
Validation loss: 2.0837046971885105

Epoch: 6| Step: 1
Training loss: 2.061272144317627
Validation loss: 2.081538397778747

Epoch: 6| Step: 2
Training loss: 2.1251869201660156
Validation loss: 2.0931362695591424

Epoch: 6| Step: 3
Training loss: 1.6734776496887207
Validation loss: 2.0975924256027385

Epoch: 6| Step: 4
Training loss: 2.129777431488037
Validation loss: 2.0793621488796767

Epoch: 6| Step: 5
Training loss: 2.435389995574951
Validation loss: 2.0827058617786696

Epoch: 6| Step: 6
Training loss: 1.8622591495513916
Validation loss: 2.0808806483463576

Epoch: 6| Step: 7
Training loss: 2.6374125480651855
Validation loss: 2.0669095311113583

Epoch: 6| Step: 8
Training loss: 1.219317078590393
Validation loss: 2.0380543637019333

Epoch: 6| Step: 9
Training loss: 2.044316053390503
Validation loss: 2.0468281776674333

Epoch: 6| Step: 10
Training loss: 1.9782781600952148
Validation loss: 2.0677200773710847

Epoch: 6| Step: 11
Training loss: 2.1668574810028076
Validation loss: 2.086305538813273

Epoch: 6| Step: 12
Training loss: 2.2371201515197754
Validation loss: 2.107144950538553

Epoch: 6| Step: 13
Training loss: 1.954893946647644
Validation loss: 2.0958926908431517

Epoch: 170| Step: 0
Training loss: 2.0133659839630127
Validation loss: 2.0740271178624963

Epoch: 6| Step: 1
Training loss: 1.9973453283309937
Validation loss: 2.0524332407982118

Epoch: 6| Step: 2
Training loss: 2.0371224880218506
Validation loss: 2.0659744406259186

Epoch: 6| Step: 3
Training loss: 2.738619804382324
Validation loss: 2.0933082975367063

Epoch: 6| Step: 4
Training loss: 2.5725059509277344
Validation loss: 2.1283174945462133

Epoch: 6| Step: 5
Training loss: 2.402379035949707
Validation loss: 2.1610731642733336

Epoch: 6| Step: 6
Training loss: 1.3983914852142334
Validation loss: 2.175641518767162

Epoch: 6| Step: 7
Training loss: 1.9368896484375
Validation loss: 2.170239997166459

Epoch: 6| Step: 8
Training loss: 1.8584892749786377
Validation loss: 2.1323371702624905

Epoch: 6| Step: 9
Training loss: 1.7495672702789307
Validation loss: 2.1008424374365036

Epoch: 6| Step: 10
Training loss: 1.7678794860839844
Validation loss: 2.102385574771512

Epoch: 6| Step: 11
Training loss: 1.91744065284729
Validation loss: 2.0665786561145576

Epoch: 6| Step: 12
Training loss: 2.2835354804992676
Validation loss: 2.0778248412634737

Epoch: 6| Step: 13
Training loss: 1.2703577280044556
Validation loss: 2.082330947281212

Epoch: 171| Step: 0
Training loss: 2.0475988388061523
Validation loss: 2.1260804489094722

Epoch: 6| Step: 1
Training loss: 1.5665113925933838
Validation loss: 2.150142833750735

Epoch: 6| Step: 2
Training loss: 2.179673671722412
Validation loss: 2.1632552198184434

Epoch: 6| Step: 3
Training loss: 2.0849647521972656
Validation loss: 2.120356802017458

Epoch: 6| Step: 4
Training loss: 1.9091027975082397
Validation loss: 2.093949935769522

Epoch: 6| Step: 5
Training loss: 2.515270709991455
Validation loss: 2.0783873168371056

Epoch: 6| Step: 6
Training loss: 1.564993143081665
Validation loss: 2.074667748584542

Epoch: 6| Step: 7
Training loss: 2.3671600818634033
Validation loss: 2.067508771855344

Epoch: 6| Step: 8
Training loss: 1.9495353698730469
Validation loss: 2.083025783620855

Epoch: 6| Step: 9
Training loss: 2.1200194358825684
Validation loss: 2.103666715724494

Epoch: 6| Step: 10
Training loss: 2.008925676345825
Validation loss: 2.1180508931477866

Epoch: 6| Step: 11
Training loss: 1.581046462059021
Validation loss: 2.1251728842335362

Epoch: 6| Step: 12
Training loss: 2.8050830364227295
Validation loss: 2.1778577989147556

Epoch: 6| Step: 13
Training loss: 1.320164442062378
Validation loss: 2.2123367683861845

Epoch: 172| Step: 0
Training loss: 1.135629415512085
Validation loss: 2.2469228544542865

Epoch: 6| Step: 1
Training loss: 2.636641025543213
Validation loss: 2.2335815570687734

Epoch: 6| Step: 2
Training loss: 1.6672940254211426
Validation loss: 2.213549560116183

Epoch: 6| Step: 3
Training loss: 1.9107692241668701
Validation loss: 2.1970612464412564

Epoch: 6| Step: 4
Training loss: 1.4329395294189453
Validation loss: 2.19126901062586

Epoch: 6| Step: 5
Training loss: 2.569521427154541
Validation loss: 2.121159029263322

Epoch: 6| Step: 6
Training loss: 2.493929862976074
Validation loss: 2.0818613780442106

Epoch: 6| Step: 7
Training loss: 1.9679648876190186
Validation loss: 2.084724545478821

Epoch: 6| Step: 8
Training loss: 1.5068035125732422
Validation loss: 2.0694919119599047

Epoch: 6| Step: 9
Training loss: 1.947890281677246
Validation loss: 2.0650476896634666

Epoch: 6| Step: 10
Training loss: 2.4526703357696533
Validation loss: 2.0771846207239295

Epoch: 6| Step: 11
Training loss: 2.094062328338623
Validation loss: 2.073205381311396

Epoch: 6| Step: 12
Training loss: 1.7224161624908447
Validation loss: 2.1015128345899683

Epoch: 6| Step: 13
Training loss: 2.2744557857513428
Validation loss: 2.1113779596103135

Epoch: 173| Step: 0
Training loss: 1.9100079536437988
Validation loss: 2.116402059473017

Epoch: 6| Step: 1
Training loss: 1.9652334451675415
Validation loss: 2.1303503718427432

Epoch: 6| Step: 2
Training loss: 1.971653938293457
Validation loss: 2.169366978829907

Epoch: 6| Step: 3
Training loss: 1.854581594467163
Validation loss: 2.1684460486135175

Epoch: 6| Step: 4
Training loss: 1.7801376581192017
Validation loss: 2.134890769117622

Epoch: 6| Step: 5
Training loss: 2.0249452590942383
Validation loss: 2.083764878652429

Epoch: 6| Step: 6
Training loss: 2.3130974769592285
Validation loss: 2.033970022714266

Epoch: 6| Step: 7
Training loss: 1.5539236068725586
Validation loss: 2.024047273461537

Epoch: 6| Step: 8
Training loss: 1.9646469354629517
Validation loss: 2.043693515562242

Epoch: 6| Step: 9
Training loss: 2.5727829933166504
Validation loss: 2.0294862383155414

Epoch: 6| Step: 10
Training loss: 1.7618755102157593
Validation loss: 2.0274589574465187

Epoch: 6| Step: 11
Training loss: 1.730223298072815
Validation loss: 2.052315185146947

Epoch: 6| Step: 12
Training loss: 2.0790176391601562
Validation loss: 2.133324228307252

Epoch: 6| Step: 13
Training loss: 2.5533523559570312
Validation loss: 2.1736744449984644

Epoch: 174| Step: 0
Training loss: 1.9326602220535278
Validation loss: 2.2415786635491157

Epoch: 6| Step: 1
Training loss: 2.3229775428771973
Validation loss: 2.2641272673042874

Epoch: 6| Step: 2
Training loss: 1.6546058654785156
Validation loss: 2.2640672140224005

Epoch: 6| Step: 3
Training loss: 1.6838593482971191
Validation loss: 2.2136300481775755

Epoch: 6| Step: 4
Training loss: 2.2143924236297607
Validation loss: 2.1541012487103863

Epoch: 6| Step: 5
Training loss: 1.357588529586792
Validation loss: 2.1280456845478346

Epoch: 6| Step: 6
Training loss: 1.6916627883911133
Validation loss: 2.112806520154399

Epoch: 6| Step: 7
Training loss: 2.112649440765381
Validation loss: 2.100499221073684

Epoch: 6| Step: 8
Training loss: 2.0220017433166504
Validation loss: 2.081064188352195

Epoch: 6| Step: 9
Training loss: 1.8477226495742798
Validation loss: 2.0701146689794396

Epoch: 6| Step: 10
Training loss: 2.4909915924072266
Validation loss: 2.034389688122657

Epoch: 6| Step: 11
Training loss: 2.191253662109375
Validation loss: 2.0175946630457395

Epoch: 6| Step: 12
Training loss: 2.6870174407958984
Validation loss: 2.001937384246498

Epoch: 6| Step: 13
Training loss: 1.310988187789917
Validation loss: 2.012098954569909

Epoch: 175| Step: 0
Training loss: 1.1639362573623657
Validation loss: 2.0203060924365954

Epoch: 6| Step: 1
Training loss: 2.00244402885437
Validation loss: 2.0625240174672936

Epoch: 6| Step: 2
Training loss: 1.4730180501937866
Validation loss: 2.08600341632802

Epoch: 6| Step: 3
Training loss: 2.0320241451263428
Validation loss: 2.131008691685174

Epoch: 6| Step: 4
Training loss: 2.4955596923828125
Validation loss: 2.1427415750359975

Epoch: 6| Step: 5
Training loss: 2.1326568126678467
Validation loss: 2.096814413224497

Epoch: 6| Step: 6
Training loss: 2.4168505668640137
Validation loss: 2.049843426673643

Epoch: 6| Step: 7
Training loss: 2.0754270553588867
Validation loss: 2.050784141786637

Epoch: 6| Step: 8
Training loss: 2.485628128051758
Validation loss: 2.062900432976343

Epoch: 6| Step: 9
Training loss: 1.6928236484527588
Validation loss: 2.060430280623897

Epoch: 6| Step: 10
Training loss: 2.146228790283203
Validation loss: 2.062277611865792

Epoch: 6| Step: 11
Training loss: 2.4773850440979004
Validation loss: 2.0602713272135746

Epoch: 6| Step: 12
Training loss: 1.790356159210205
Validation loss: 2.063306221397974

Epoch: 6| Step: 13
Training loss: 1.2889679670333862
Validation loss: 2.0517133153894895

Epoch: 176| Step: 0
Training loss: 2.491323471069336
Validation loss: 2.0518213805331977

Epoch: 6| Step: 1
Training loss: 1.667932152748108
Validation loss: 2.0465753219460927

Epoch: 6| Step: 2
Training loss: 2.0878489017486572
Validation loss: 2.053765135426675

Epoch: 6| Step: 3
Training loss: 2.2353286743164062
Validation loss: 2.05531765825005

Epoch: 6| Step: 4
Training loss: 1.7313265800476074
Validation loss: 2.0594893476014495

Epoch: 6| Step: 5
Training loss: 2.08192777633667
Validation loss: 2.0718409143468386

Epoch: 6| Step: 6
Training loss: 1.8342585563659668
Validation loss: 2.0802482763926187

Epoch: 6| Step: 7
Training loss: 1.2940138578414917
Validation loss: 2.091141039325345

Epoch: 6| Step: 8
Training loss: 2.2134897708892822
Validation loss: 2.102686528236635

Epoch: 6| Step: 9
Training loss: 2.708320140838623
Validation loss: 2.0934170574270268

Epoch: 6| Step: 10
Training loss: 1.7788660526275635
Validation loss: 2.075922171274821

Epoch: 6| Step: 11
Training loss: 1.6867809295654297
Validation loss: 2.0808866306017806

Epoch: 6| Step: 12
Training loss: 1.8306798934936523
Validation loss: 2.0871595515999743

Epoch: 6| Step: 13
Training loss: 1.3009817600250244
Validation loss: 2.101844528669952

Epoch: 177| Step: 0
Training loss: 1.6211423873901367
Validation loss: 2.122077497102881

Epoch: 6| Step: 1
Training loss: 2.0445573329925537
Validation loss: 2.140328912324803

Epoch: 6| Step: 2
Training loss: 2.1619510650634766
Validation loss: 2.159998938601504

Epoch: 6| Step: 3
Training loss: 1.9684712886810303
Validation loss: 2.164215369891095

Epoch: 6| Step: 4
Training loss: 1.3639940023422241
Validation loss: 2.1366027644885484

Epoch: 6| Step: 5
Training loss: 1.760711431503296
Validation loss: 2.1339776951779603

Epoch: 6| Step: 6
Training loss: 2.0900282859802246
Validation loss: 2.138794525977104

Epoch: 6| Step: 7
Training loss: 2.393782615661621
Validation loss: 2.140003027454499

Epoch: 6| Step: 8
Training loss: 2.079476833343506
Validation loss: 2.1405415701609787

Epoch: 6| Step: 9
Training loss: 1.9028420448303223
Validation loss: 2.17225149626373

Epoch: 6| Step: 10
Training loss: 1.6429786682128906
Validation loss: 2.1679905922182146

Epoch: 6| Step: 11
Training loss: 1.854243278503418
Validation loss: 2.1462623393663796

Epoch: 6| Step: 12
Training loss: 1.400231122970581
Validation loss: 2.106383033978042

Epoch: 6| Step: 13
Training loss: 2.4016811847686768
Validation loss: 2.0908733208974204

Epoch: 178| Step: 0
Training loss: 1.22901451587677
Validation loss: 2.067879392254737

Epoch: 6| Step: 1
Training loss: 1.747580885887146
Validation loss: 2.0680423654535764

Epoch: 6| Step: 2
Training loss: 1.6760672330856323
Validation loss: 2.0775161417581702

Epoch: 6| Step: 3
Training loss: 1.4442611932754517
Validation loss: 2.0648552089609127

Epoch: 6| Step: 4
Training loss: 2.200991630554199
Validation loss: 2.126056178923576

Epoch: 6| Step: 5
Training loss: 2.225646495819092
Validation loss: 2.1114463293424217

Epoch: 6| Step: 6
Training loss: 2.0333704948425293
Validation loss: 2.0892113729189803

Epoch: 6| Step: 7
Training loss: 1.6568454504013062
Validation loss: 2.0795811068627144

Epoch: 6| Step: 8
Training loss: 1.9058825969696045
Validation loss: 2.0710221631552583

Epoch: 6| Step: 9
Training loss: 1.957554817199707
Validation loss: 2.0818964999209166

Epoch: 6| Step: 10
Training loss: 2.384366750717163
Validation loss: 2.0771643897538543

Epoch: 6| Step: 11
Training loss: 2.552945137023926
Validation loss: 2.0903319158861713

Epoch: 6| Step: 12
Training loss: 1.6433100700378418
Validation loss: 2.135609496024347

Epoch: 6| Step: 13
Training loss: 2.0918076038360596
Validation loss: 2.164309086338166

Epoch: 179| Step: 0
Training loss: 1.4950835704803467
Validation loss: 2.2284564305377264

Epoch: 6| Step: 1
Training loss: 2.70355224609375
Validation loss: 2.2321318541803667

Epoch: 6| Step: 2
Training loss: 1.8365461826324463
Validation loss: 2.236961151963921

Epoch: 6| Step: 3
Training loss: 1.6878118515014648
Validation loss: 2.2349793526434127

Epoch: 6| Step: 4
Training loss: 1.4735150337219238
Validation loss: 2.2213305504091325

Epoch: 6| Step: 5
Training loss: 2.16387939453125
Validation loss: 2.202885768746817

Epoch: 6| Step: 6
Training loss: 1.8097208738327026
Validation loss: 2.1929513664655786

Epoch: 6| Step: 7
Training loss: 1.9341975450515747
Validation loss: 2.1485931078592935

Epoch: 6| Step: 8
Training loss: 1.7622919082641602
Validation loss: 2.1384672221317085

Epoch: 6| Step: 9
Training loss: 1.1848313808441162
Validation loss: 2.144804226454868

Epoch: 6| Step: 10
Training loss: 2.4548065662384033
Validation loss: 2.1341105173992854

Epoch: 6| Step: 11
Training loss: 1.456658959388733
Validation loss: 2.130012772416556

Epoch: 6| Step: 12
Training loss: 2.4954118728637695
Validation loss: 2.1584517417415494

Epoch: 6| Step: 13
Training loss: 2.068840265274048
Validation loss: 2.156431516011556

Epoch: 180| Step: 0
Training loss: 1.883907675743103
Validation loss: 2.147318160662087

Epoch: 6| Step: 1
Training loss: 1.6878597736358643
Validation loss: 2.1138698157443794

Epoch: 6| Step: 2
Training loss: 1.4581348896026611
Validation loss: 2.0994344577994397

Epoch: 6| Step: 3
Training loss: 2.046088695526123
Validation loss: 2.0883937702384046

Epoch: 6| Step: 4
Training loss: 1.9729564189910889
Validation loss: 2.0658088140590216

Epoch: 6| Step: 5
Training loss: 2.3002679347991943
Validation loss: 2.062479393456572

Epoch: 6| Step: 6
Training loss: 1.5686662197113037
Validation loss: 2.056823351049936

Epoch: 6| Step: 7
Training loss: 2.1904759407043457
Validation loss: 2.0501144957798783

Epoch: 6| Step: 8
Training loss: 1.4762063026428223
Validation loss: 2.0540846291408745

Epoch: 6| Step: 9
Training loss: 1.7948901653289795
Validation loss: 2.0581105627039427

Epoch: 6| Step: 10
Training loss: 2.2411065101623535
Validation loss: 2.0768362322161273

Epoch: 6| Step: 11
Training loss: 2.120697498321533
Validation loss: 2.128075333051784

Epoch: 6| Step: 12
Training loss: 1.395043134689331
Validation loss: 2.1787345922121437

Epoch: 6| Step: 13
Training loss: 1.902987003326416
Validation loss: 2.1979061506127797

Epoch: 181| Step: 0
Training loss: 2.496978759765625
Validation loss: 2.223540545791708

Epoch: 6| Step: 1
Training loss: 1.6188408136367798
Validation loss: 2.2202512423197427

Epoch: 6| Step: 2
Training loss: 1.874515414237976
Validation loss: 2.1804830540892897

Epoch: 6| Step: 3
Training loss: 1.9094566106796265
Validation loss: 2.1362557154829784

Epoch: 6| Step: 4
Training loss: 1.500731110572815
Validation loss: 2.1286893006294005

Epoch: 6| Step: 5
Training loss: 1.9433820247650146
Validation loss: 2.1293652903649116

Epoch: 6| Step: 6
Training loss: 1.6136088371276855
Validation loss: 2.1163943762420327

Epoch: 6| Step: 7
Training loss: 1.6081249713897705
Validation loss: 2.1117146450986146

Epoch: 6| Step: 8
Training loss: 1.4765843152999878
Validation loss: 2.107374600184861

Epoch: 6| Step: 9
Training loss: 1.8911528587341309
Validation loss: 2.1411223078286774

Epoch: 6| Step: 10
Training loss: 1.7743785381317139
Validation loss: 2.1691746737367366

Epoch: 6| Step: 11
Training loss: 2.1604013442993164
Validation loss: 2.1727692183627876

Epoch: 6| Step: 12
Training loss: 2.060802459716797
Validation loss: 2.1567695704839562

Epoch: 6| Step: 13
Training loss: 2.092054605484009
Validation loss: 2.090456023011156

Epoch: 182| Step: 0
Training loss: 1.8918538093566895
Validation loss: 2.054975349416015

Epoch: 6| Step: 1
Training loss: 2.2650647163391113
Validation loss: 2.04993240551282

Epoch: 6| Step: 2
Training loss: 2.486470937728882
Validation loss: 2.048298707572363

Epoch: 6| Step: 3
Training loss: 2.1954562664031982
Validation loss: 2.0413642814082484

Epoch: 6| Step: 4
Training loss: 1.429609775543213
Validation loss: 2.0331348860135643

Epoch: 6| Step: 5
Training loss: 1.73063325881958
Validation loss: 2.038835246075866

Epoch: 6| Step: 6
Training loss: 1.7262163162231445
Validation loss: 2.0689164797465005

Epoch: 6| Step: 7
Training loss: 1.8217511177062988
Validation loss: 2.0555061589005175

Epoch: 6| Step: 8
Training loss: 1.8249510526657104
Validation loss: 2.046361764272054

Epoch: 6| Step: 9
Training loss: 1.4380271434783936
Validation loss: 2.0555730917120494

Epoch: 6| Step: 10
Training loss: 1.7891544103622437
Validation loss: 2.048679459479547

Epoch: 6| Step: 11
Training loss: 1.9621587991714478
Validation loss: 2.035270324317358

Epoch: 6| Step: 12
Training loss: 1.5280787944793701
Validation loss: 2.024288614590963

Epoch: 6| Step: 13
Training loss: 1.57467782497406
Validation loss: 2.0305217645501576

Epoch: 183| Step: 0
Training loss: 1.541534185409546
Validation loss: 2.0635961550538258

Epoch: 6| Step: 1
Training loss: 2.2103195190429688
Validation loss: 2.0980633151146675

Epoch: 6| Step: 2
Training loss: 1.8036844730377197
Validation loss: 2.1408215543275237

Epoch: 6| Step: 3
Training loss: 1.9094367027282715
Validation loss: 2.157432589479672

Epoch: 6| Step: 4
Training loss: 1.5714532136917114
Validation loss: 2.152737497001566

Epoch: 6| Step: 5
Training loss: 1.3170349597930908
Validation loss: 2.1674809994236117

Epoch: 6| Step: 6
Training loss: 2.4536960124969482
Validation loss: 2.161054088223365

Epoch: 6| Step: 7
Training loss: 1.873523473739624
Validation loss: 2.1313684525028354

Epoch: 6| Step: 8
Training loss: 1.536745309829712
Validation loss: 2.083481929635489

Epoch: 6| Step: 9
Training loss: 2.2687087059020996
Validation loss: 2.0817799055448143

Epoch: 6| Step: 10
Training loss: 2.4236228466033936
Validation loss: 2.0676235332283923

Epoch: 6| Step: 11
Training loss: 1.180755615234375
Validation loss: 2.0671531167081607

Epoch: 6| Step: 12
Training loss: 1.4161601066589355
Validation loss: 2.081158253454393

Epoch: 6| Step: 13
Training loss: 1.9250479936599731
Validation loss: 2.1150617573850896

Epoch: 184| Step: 0
Training loss: 2.0583901405334473
Validation loss: 2.177774117838952

Epoch: 6| Step: 1
Training loss: 1.8569574356079102
Validation loss: 2.195948859696747

Epoch: 6| Step: 2
Training loss: 1.8440933227539062
Validation loss: 2.173896651114187

Epoch: 6| Step: 3
Training loss: 1.981115698814392
Validation loss: 2.166828296517813

Epoch: 6| Step: 4
Training loss: 1.27555513381958
Validation loss: 2.0909099425038984

Epoch: 6| Step: 5
Training loss: 2.124969005584717
Validation loss: 2.057119405397805

Epoch: 6| Step: 6
Training loss: 2.4904422760009766
Validation loss: 2.0316073022862917

Epoch: 6| Step: 7
Training loss: 1.9806647300720215
Validation loss: 2.039731525605725

Epoch: 6| Step: 8
Training loss: 1.866020917892456
Validation loss: 2.029590158052342

Epoch: 6| Step: 9
Training loss: 1.382199764251709
Validation loss: 2.0253936270231843

Epoch: 6| Step: 10
Training loss: 2.129784107208252
Validation loss: 2.0570207436879477

Epoch: 6| Step: 11
Training loss: 1.5642768144607544
Validation loss: 2.0468445849675003

Epoch: 6| Step: 12
Training loss: 1.1141115427017212
Validation loss: 2.0547130825699016

Epoch: 6| Step: 13
Training loss: 2.3689355850219727
Validation loss: 2.0686941582669496

Epoch: 185| Step: 0
Training loss: 1.3621912002563477
Validation loss: 2.0994725816993305

Epoch: 6| Step: 1
Training loss: 1.024843692779541
Validation loss: 2.0951549571047545

Epoch: 6| Step: 2
Training loss: 2.0031232833862305
Validation loss: 2.102277227627334

Epoch: 6| Step: 3
Training loss: 1.8294850587844849
Validation loss: 2.1200706240951375

Epoch: 6| Step: 4
Training loss: 2.1453702449798584
Validation loss: 2.097957008628435

Epoch: 6| Step: 5
Training loss: 1.4269218444824219
Validation loss: 2.0979084378929547

Epoch: 6| Step: 6
Training loss: 2.389801502227783
Validation loss: 2.086626816821355

Epoch: 6| Step: 7
Training loss: 2.031202793121338
Validation loss: 2.048277239645681

Epoch: 6| Step: 8
Training loss: 1.9687880277633667
Validation loss: 2.053550915051532

Epoch: 6| Step: 9
Training loss: 1.8761094808578491
Validation loss: 2.0579522989129506

Epoch: 6| Step: 10
Training loss: 1.3327895402908325
Validation loss: 2.0758312645778862

Epoch: 6| Step: 11
Training loss: 1.5507346391677856
Validation loss: 2.124956338636337

Epoch: 6| Step: 12
Training loss: 2.4783778190612793
Validation loss: 2.1667863809934227

Epoch: 6| Step: 13
Training loss: 1.23898184299469
Validation loss: 2.285624175943354

Epoch: 186| Step: 0
Training loss: 1.9110972881317139
Validation loss: 2.296972954145042

Epoch: 6| Step: 1
Training loss: 1.709564447402954
Validation loss: 2.264742435947541

Epoch: 6| Step: 2
Training loss: 2.1052536964416504
Validation loss: 2.2416595694839314

Epoch: 6| Step: 3
Training loss: 2.1697158813476562
Validation loss: 2.1803209884192354

Epoch: 6| Step: 4
Training loss: 1.879563808441162
Validation loss: 2.1052140253846363

Epoch: 6| Step: 5
Training loss: 1.4537907838821411
Validation loss: 2.1089095377152964

Epoch: 6| Step: 6
Training loss: 1.4910571575164795
Validation loss: 2.110459763516662

Epoch: 6| Step: 7
Training loss: 1.3758525848388672
Validation loss: 2.1054918278930006

Epoch: 6| Step: 8
Training loss: 1.7408782243728638
Validation loss: 2.1037855199588242

Epoch: 6| Step: 9
Training loss: 2.1840755939483643
Validation loss: 2.109587889845653

Epoch: 6| Step: 10
Training loss: 1.701039433479309
Validation loss: 2.123512383430235

Epoch: 6| Step: 11
Training loss: 1.9853543043136597
Validation loss: 2.1474364419137277

Epoch: 6| Step: 12
Training loss: 1.7273532152175903
Validation loss: 2.1997933259574314

Epoch: 6| Step: 13
Training loss: 1.8548589944839478
Validation loss: 2.2442605162179596

Epoch: 187| Step: 0
Training loss: 2.4525623321533203
Validation loss: 2.2150800305028118

Epoch: 6| Step: 1
Training loss: 1.8627421855926514
Validation loss: 2.164832768901702

Epoch: 6| Step: 2
Training loss: 1.351300597190857
Validation loss: 2.1202914996813704

Epoch: 6| Step: 3
Training loss: 1.6546026468276978
Validation loss: 2.084733509248303

Epoch: 6| Step: 4
Training loss: 2.251222610473633
Validation loss: 2.0249394345027145

Epoch: 6| Step: 5
Training loss: 1.2446939945220947
Validation loss: 2.031934089558099

Epoch: 6| Step: 6
Training loss: 2.0269618034362793
Validation loss: 2.0226072662620136

Epoch: 6| Step: 7
Training loss: 2.343702793121338
Validation loss: 2.0328392726118847

Epoch: 6| Step: 8
Training loss: 2.8481640815734863
Validation loss: 2.003404873673634

Epoch: 6| Step: 9
Training loss: 1.3434689044952393
Validation loss: 2.0014697595309188

Epoch: 6| Step: 10
Training loss: 1.7587487697601318
Validation loss: 2.0196396740533973

Epoch: 6| Step: 11
Training loss: 1.1517651081085205
Validation loss: 2.035334507624308

Epoch: 6| Step: 12
Training loss: 2.1495652198791504
Validation loss: 2.085653942118409

Epoch: 6| Step: 13
Training loss: 0.8945562839508057
Validation loss: 2.1103860639756724

Epoch: 188| Step: 0
Training loss: 1.3760229349136353
Validation loss: 2.165967910520492

Epoch: 6| Step: 1
Training loss: 1.9487922191619873
Validation loss: 2.1830832368584088

Epoch: 6| Step: 2
Training loss: 1.8266257047653198
Validation loss: 2.226813184317722

Epoch: 6| Step: 3
Training loss: 2.232044219970703
Validation loss: 2.2403724578119095

Epoch: 6| Step: 4
Training loss: 1.6022093296051025
Validation loss: 2.2178733348846436

Epoch: 6| Step: 5
Training loss: 1.6053760051727295
Validation loss: 2.189564738222348

Epoch: 6| Step: 6
Training loss: 1.7659779787063599
Validation loss: 2.171147423405801

Epoch: 6| Step: 7
Training loss: 2.171389102935791
Validation loss: 2.161187215517926

Epoch: 6| Step: 8
Training loss: 1.7692458629608154
Validation loss: 2.1597999603517595

Epoch: 6| Step: 9
Training loss: 1.9644657373428345
Validation loss: 2.118347398696407

Epoch: 6| Step: 10
Training loss: 1.8385028839111328
Validation loss: 2.1120024778509654

Epoch: 6| Step: 11
Training loss: 2.2443904876708984
Validation loss: 2.119057801461989

Epoch: 6| Step: 12
Training loss: 1.6398849487304688
Validation loss: 2.1297288838253228

Epoch: 6| Step: 13
Training loss: 1.6363062858581543
Validation loss: 2.137473657567014

Epoch: 189| Step: 0
Training loss: 2.094207286834717
Validation loss: 2.1203040217840545

Epoch: 6| Step: 1
Training loss: 1.9446667432785034
Validation loss: 2.074651374611803

Epoch: 6| Step: 2
Training loss: 2.1529645919799805
Validation loss: 2.0426394798422374

Epoch: 6| Step: 3
Training loss: 1.1364781856536865
Validation loss: 2.025581217581226

Epoch: 6| Step: 4
Training loss: 1.1805968284606934
Validation loss: 2.027774090407997

Epoch: 6| Step: 5
Training loss: 1.3502956628799438
Validation loss: 2.036546699462398

Epoch: 6| Step: 6
Training loss: 2.2942161560058594
Validation loss: 2.042050967934311

Epoch: 6| Step: 7
Training loss: 1.6773886680603027
Validation loss: 2.0881460430801555

Epoch: 6| Step: 8
Training loss: 2.1343698501586914
Validation loss: 2.1287172686669136

Epoch: 6| Step: 9
Training loss: 2.1194846630096436
Validation loss: 2.168820486273817

Epoch: 6| Step: 10
Training loss: 1.381669521331787
Validation loss: 2.214641358262749

Epoch: 6| Step: 11
Training loss: 1.6943714618682861
Validation loss: 2.237931207943988

Epoch: 6| Step: 12
Training loss: 1.8541455268859863
Validation loss: 2.2510705096747285

Epoch: 6| Step: 13
Training loss: 2.187886953353882
Validation loss: 2.222463410387757

Epoch: 190| Step: 0
Training loss: 1.5761864185333252
Validation loss: 2.188057279074064

Epoch: 6| Step: 1
Training loss: 1.870898723602295
Validation loss: 2.1798979774598153

Epoch: 6| Step: 2
Training loss: 1.5282671451568604
Validation loss: 2.144365515760196

Epoch: 6| Step: 3
Training loss: 1.63790762424469
Validation loss: 2.132487994368358

Epoch: 6| Step: 4
Training loss: 2.3140363693237305
Validation loss: 2.1298526563952045

Epoch: 6| Step: 5
Training loss: 1.441954255104065
Validation loss: 2.1299568158324047

Epoch: 6| Step: 6
Training loss: 1.29889714717865
Validation loss: 2.1445778851868003

Epoch: 6| Step: 7
Training loss: 2.1640050411224365
Validation loss: 2.1556485442705053

Epoch: 6| Step: 8
Training loss: 1.9731107950210571
Validation loss: 2.1407970382321264

Epoch: 6| Step: 9
Training loss: 1.6942648887634277
Validation loss: 2.1574545855163247

Epoch: 6| Step: 10
Training loss: 1.7573363780975342
Validation loss: 2.197016385293776

Epoch: 6| Step: 11
Training loss: 1.3756688833236694
Validation loss: 2.16766627629598

Epoch: 6| Step: 12
Training loss: 1.8400044441223145
Validation loss: 2.13960357891616

Epoch: 6| Step: 13
Training loss: 1.8753657341003418
Validation loss: 2.110950000824467

Epoch: 191| Step: 0
Training loss: 1.4273141622543335
Validation loss: 2.1173549800790767

Epoch: 6| Step: 1
Training loss: 1.6001569032669067
Validation loss: 2.136692390646986

Epoch: 6| Step: 2
Training loss: 1.9223048686981201
Validation loss: 2.155520933930592

Epoch: 6| Step: 3
Training loss: 1.443472146987915
Validation loss: 2.1455638280478855

Epoch: 6| Step: 4
Training loss: 1.61124849319458
Validation loss: 2.1139957750997236

Epoch: 6| Step: 5
Training loss: 1.8682490587234497
Validation loss: 2.089818810903898

Epoch: 6| Step: 6
Training loss: 0.9374992847442627
Validation loss: 2.0856667282760784

Epoch: 6| Step: 7
Training loss: 1.878523349761963
Validation loss: 2.0701165148006972

Epoch: 6| Step: 8
Training loss: 2.308893918991089
Validation loss: 2.089383171450707

Epoch: 6| Step: 9
Training loss: 1.6361942291259766
Validation loss: 2.0858392651363085

Epoch: 6| Step: 10
Training loss: 1.6739979982376099
Validation loss: 2.1161484538867907

Epoch: 6| Step: 11
Training loss: 1.5325944423675537
Validation loss: 2.112880204313545

Epoch: 6| Step: 12
Training loss: 2.084212303161621
Validation loss: 2.131666574426877

Epoch: 6| Step: 13
Training loss: 2.0543458461761475
Validation loss: 2.143734262835595

Epoch: 192| Step: 0
Training loss: 1.8004660606384277
Validation loss: 2.1363994652225125

Epoch: 6| Step: 1
Training loss: 1.5524805784225464
Validation loss: 2.1653227959909747

Epoch: 6| Step: 2
Training loss: 2.2493913173675537
Validation loss: 2.1873788602890505

Epoch: 6| Step: 3
Training loss: 1.950448751449585
Validation loss: 2.21289381160531

Epoch: 6| Step: 4
Training loss: 1.5254056453704834
Validation loss: 2.1992842407636743

Epoch: 6| Step: 5
Training loss: 1.5585930347442627
Validation loss: 2.1371801694234214

Epoch: 6| Step: 6
Training loss: 1.6908481121063232
Validation loss: 2.108687752036638

Epoch: 6| Step: 7
Training loss: 1.7657041549682617
Validation loss: 2.0839753484213226

Epoch: 6| Step: 8
Training loss: 1.650130271911621
Validation loss: 2.087667711319462

Epoch: 6| Step: 9
Training loss: 2.1500024795532227
Validation loss: 2.1093147980269564

Epoch: 6| Step: 10
Training loss: 1.4548044204711914
Validation loss: 2.1093880361126316

Epoch: 6| Step: 11
Training loss: 1.8309699296951294
Validation loss: 2.103987298985963

Epoch: 6| Step: 12
Training loss: 2.009373188018799
Validation loss: 2.0887338038413756

Epoch: 6| Step: 13
Training loss: 1.1883885860443115
Validation loss: 2.0767646848514514

Epoch: 193| Step: 0
Training loss: 1.3443577289581299
Validation loss: 2.076309706575127

Epoch: 6| Step: 1
Training loss: 1.2796149253845215
Validation loss: 2.110839213094404

Epoch: 6| Step: 2
Training loss: 1.986954689025879
Validation loss: 2.1534562828720256

Epoch: 6| Step: 3
Training loss: 1.4584720134735107
Validation loss: 2.178811998777492

Epoch: 6| Step: 4
Training loss: 1.6822376251220703
Validation loss: 2.1877193732928206

Epoch: 6| Step: 5
Training loss: 1.8053867816925049
Validation loss: 2.185112020020844

Epoch: 6| Step: 6
Training loss: 1.3598883152008057
Validation loss: 2.1681697958259174

Epoch: 6| Step: 7
Training loss: 1.9942941665649414
Validation loss: 2.172705158110588

Epoch: 6| Step: 8
Training loss: 1.1860603094100952
Validation loss: 2.182638088862101

Epoch: 6| Step: 9
Training loss: 1.7722201347351074
Validation loss: 2.1588440274679535

Epoch: 6| Step: 10
Training loss: 2.0944204330444336
Validation loss: 2.1340443447072017

Epoch: 6| Step: 11
Training loss: 1.845524549484253
Validation loss: 2.1173781912813903

Epoch: 6| Step: 12
Training loss: 1.395305871963501
Validation loss: 2.114766401629294

Epoch: 6| Step: 13
Training loss: 2.540670394897461
Validation loss: 2.0905875403393983

Epoch: 194| Step: 0
Training loss: 1.6149280071258545
Validation loss: 2.0727440131607877

Epoch: 6| Step: 1
Training loss: 1.800666093826294
Validation loss: 2.0653038999085784

Epoch: 6| Step: 2
Training loss: 1.4342808723449707
Validation loss: 2.08948363027265

Epoch: 6| Step: 3
Training loss: 1.918562412261963
Validation loss: 2.0788783770735546

Epoch: 6| Step: 4
Training loss: 2.3350634574890137
Validation loss: 2.096745498718754

Epoch: 6| Step: 5
Training loss: 1.4827938079833984
Validation loss: 2.069495777929983

Epoch: 6| Step: 6
Training loss: 1.6958707571029663
Validation loss: 2.03946659129153

Epoch: 6| Step: 7
Training loss: 1.5715463161468506
Validation loss: 2.0401715873390116

Epoch: 6| Step: 8
Training loss: 1.6858080625534058
Validation loss: 2.0176258702431955

Epoch: 6| Step: 9
Training loss: 2.054039716720581
Validation loss: 2.035080494419221

Epoch: 6| Step: 10
Training loss: 1.5892369747161865
Validation loss: 2.047066460373581

Epoch: 6| Step: 11
Training loss: 1.425521731376648
Validation loss: 2.077999731545807

Epoch: 6| Step: 12
Training loss: 1.025496244430542
Validation loss: 2.1387015722131215

Epoch: 6| Step: 13
Training loss: 1.7543514966964722
Validation loss: 2.205296698436942

Epoch: 195| Step: 0
Training loss: 1.8555428981781006
Validation loss: 2.2461386957476215

Epoch: 6| Step: 1
Training loss: 2.5755960941314697
Validation loss: 2.24100927383669

Epoch: 6| Step: 2
Training loss: 1.757641077041626
Validation loss: 2.1988115285032537

Epoch: 6| Step: 3
Training loss: 1.5291273593902588
Validation loss: 2.1361566410269788

Epoch: 6| Step: 4
Training loss: 1.2593541145324707
Validation loss: 2.11167715185432

Epoch: 6| Step: 5
Training loss: 1.2465686798095703
Validation loss: 2.0966552303683375

Epoch: 6| Step: 6
Training loss: 1.5802866220474243
Validation loss: 2.0932956152064826

Epoch: 6| Step: 7
Training loss: 1.852418303489685
Validation loss: 2.0682312237319125

Epoch: 6| Step: 8
Training loss: 1.3670456409454346
Validation loss: 2.07028099542023

Epoch: 6| Step: 9
Training loss: 2.1379199028015137
Validation loss: 2.134941626620549

Epoch: 6| Step: 10
Training loss: 1.8532657623291016
Validation loss: 2.184764354459701

Epoch: 6| Step: 11
Training loss: 1.8744769096374512
Validation loss: 2.1851153501900296

Epoch: 6| Step: 12
Training loss: 1.8486963510513306
Validation loss: 2.159420995302098

Epoch: 6| Step: 13
Training loss: 0.708453893661499
Validation loss: 2.1304789281660512

Epoch: 196| Step: 0
Training loss: 1.6471914052963257
Validation loss: 2.1119856321683494

Epoch: 6| Step: 1
Training loss: 2.0025742053985596
Validation loss: 2.1016254989049767

Epoch: 6| Step: 2
Training loss: 0.9401353597640991
Validation loss: 2.0873020515646985

Epoch: 6| Step: 3
Training loss: 1.5798101425170898
Validation loss: 2.0862525855341265

Epoch: 6| Step: 4
Training loss: 1.5695502758026123
Validation loss: 2.0966470113364597

Epoch: 6| Step: 5
Training loss: 1.1016426086425781
Validation loss: 2.121656555001454

Epoch: 6| Step: 6
Training loss: 1.1251250505447388
Validation loss: 2.118612120228429

Epoch: 6| Step: 7
Training loss: 2.2944564819335938
Validation loss: 2.116959571838379

Epoch: 6| Step: 8
Training loss: 2.4171648025512695
Validation loss: 2.0791443804258942

Epoch: 6| Step: 9
Training loss: 1.841576337814331
Validation loss: 2.0654979982683734

Epoch: 6| Step: 10
Training loss: 1.1289896965026855
Validation loss: 2.0516810904267015

Epoch: 6| Step: 11
Training loss: 1.7744048833847046
Validation loss: 2.048675183326967

Epoch: 6| Step: 12
Training loss: 1.3583416938781738
Validation loss: 2.0550936293858353

Epoch: 6| Step: 13
Training loss: 1.5683636665344238
Validation loss: 2.072956872242753

Epoch: 197| Step: 0
Training loss: 1.1397101879119873
Validation loss: 2.067843747395341

Epoch: 6| Step: 1
Training loss: 1.4931052923202515
Validation loss: 2.088722054676343

Epoch: 6| Step: 2
Training loss: 1.9412784576416016
Validation loss: 2.1297579324373634

Epoch: 6| Step: 3
Training loss: 1.7783910036087036
Validation loss: 2.1328636843671083

Epoch: 6| Step: 4
Training loss: 1.192230224609375
Validation loss: 2.143174616239404

Epoch: 6| Step: 5
Training loss: 1.5027254819869995
Validation loss: 2.1570820808410645

Epoch: 6| Step: 6
Training loss: 1.693588137626648
Validation loss: 2.159446934218048

Epoch: 6| Step: 7
Training loss: 1.5968513488769531
Validation loss: 2.1387302029517388

Epoch: 6| Step: 8
Training loss: 1.6861019134521484
Validation loss: 2.1157178750602146

Epoch: 6| Step: 9
Training loss: 1.6425981521606445
Validation loss: 2.109327793121338

Epoch: 6| Step: 10
Training loss: 2.036925792694092
Validation loss: 2.107620600731142

Epoch: 6| Step: 11
Training loss: 1.2166393995285034
Validation loss: 2.094124940133864

Epoch: 6| Step: 12
Training loss: 2.102450370788574
Validation loss: 2.099135096355151

Epoch: 6| Step: 13
Training loss: 0.9055245518684387
Validation loss: 2.113875433962832

Epoch: 198| Step: 0
Training loss: 1.5389623641967773
Validation loss: 2.1250974157805085

Epoch: 6| Step: 1
Training loss: 2.091818332672119
Validation loss: 2.0970928771521455

Epoch: 6| Step: 2
Training loss: 1.192807912826538
Validation loss: 2.0943129857381186

Epoch: 6| Step: 3
Training loss: 1.3390223979949951
Validation loss: 2.072082919459189

Epoch: 6| Step: 4
Training loss: 1.89335036277771
Validation loss: 2.0941445699302097

Epoch: 6| Step: 5
Training loss: 1.5646495819091797
Validation loss: 2.0954635732917377

Epoch: 6| Step: 6
Training loss: 1.6120491027832031
Validation loss: 2.0920658829391643

Epoch: 6| Step: 7
Training loss: 1.9761501550674438
Validation loss: 2.127846215360908

Epoch: 6| Step: 8
Training loss: 1.6904313564300537
Validation loss: 2.1641255168504614

Epoch: 6| Step: 9
Training loss: 1.709615707397461
Validation loss: 2.2123900049476215

Epoch: 6| Step: 10
Training loss: 1.5123801231384277
Validation loss: 2.260257487655968

Epoch: 6| Step: 11
Training loss: 1.6463830471038818
Validation loss: 2.231881349317489

Epoch: 6| Step: 12
Training loss: 0.7205514907836914
Validation loss: 2.199412630450341

Epoch: 6| Step: 13
Training loss: 1.6308528184890747
Validation loss: 2.137776279962191

Epoch: 199| Step: 0
Training loss: 1.5147119760513306
Validation loss: 2.1174888251930155

Epoch: 6| Step: 1
Training loss: 1.9689075946807861
Validation loss: 2.0868237069858018

Epoch: 6| Step: 2
Training loss: 1.3399717807769775
Validation loss: 2.062950864914925

Epoch: 6| Step: 3
Training loss: 1.550824522972107
Validation loss: 2.0570969658513225

Epoch: 6| Step: 4
Training loss: 1.7134439945220947
Validation loss: 2.0419941486850863

Epoch: 6| Step: 5
Training loss: 1.6158016920089722
Validation loss: 2.0449653594724593

Epoch: 6| Step: 6
Training loss: 1.2284386157989502
Validation loss: 2.048185497201899

Epoch: 6| Step: 7
Training loss: 1.928367018699646
Validation loss: 2.044603083723335

Epoch: 6| Step: 8
Training loss: 1.9966672658920288
Validation loss: 2.0926373338186615

Epoch: 6| Step: 9
Training loss: 1.3502482175827026
Validation loss: 2.1310030209120883

Epoch: 6| Step: 10
Training loss: 1.5693628787994385
Validation loss: 2.1520605318007933

Epoch: 6| Step: 11
Training loss: 1.3163609504699707
Validation loss: 2.1666577272517706

Epoch: 6| Step: 12
Training loss: 1.3636646270751953
Validation loss: 2.129820913396856

Epoch: 6| Step: 13
Training loss: 1.661611795425415
Validation loss: 2.1108635702440814

Epoch: 200| Step: 0
Training loss: 1.0218884944915771
Validation loss: 2.1162519378046833

Epoch: 6| Step: 1
Training loss: 1.889798879623413
Validation loss: 2.125442804828767

Epoch: 6| Step: 2
Training loss: 2.4905455112457275
Validation loss: 2.101834561235161

Epoch: 6| Step: 3
Training loss: 1.7578309774398804
Validation loss: 2.0957467786727415

Epoch: 6| Step: 4
Training loss: 1.6828274726867676
Validation loss: 2.0836466794372885

Epoch: 6| Step: 5
Training loss: 0.8885786533355713
Validation loss: 2.096827478818996

Epoch: 6| Step: 6
Training loss: 1.8410531282424927
Validation loss: 2.1026657704384095

Epoch: 6| Step: 7
Training loss: 1.473961591720581
Validation loss: 2.136806413691531

Epoch: 6| Step: 8
Training loss: 1.1245808601379395
Validation loss: 2.179198565021638

Epoch: 6| Step: 9
Training loss: 1.0399985313415527
Validation loss: 2.151369376849103

Epoch: 6| Step: 10
Training loss: 1.2731834650039673
Validation loss: 2.127125193995814

Epoch: 6| Step: 11
Training loss: 1.424854040145874
Validation loss: 2.110944865852274

Epoch: 6| Step: 12
Training loss: 1.9896957874298096
Validation loss: 2.0773999268008816

Epoch: 6| Step: 13
Training loss: 1.6071349382400513
Validation loss: 2.0620599997940885

Epoch: 201| Step: 0
Training loss: 2.2416787147521973
Validation loss: 2.0793839154704923

Epoch: 6| Step: 1
Training loss: 1.3744759559631348
Validation loss: 2.1027771375512563

Epoch: 6| Step: 2
Training loss: 1.7499432563781738
Validation loss: 2.1014679516515424

Epoch: 6| Step: 3
Training loss: 2.0000627040863037
Validation loss: 2.141418645458837

Epoch: 6| Step: 4
Training loss: 1.8156464099884033
Validation loss: 2.16486410556301

Epoch: 6| Step: 5
Training loss: 1.2360219955444336
Validation loss: 2.195265270048572

Epoch: 6| Step: 6
Training loss: 1.3732328414916992
Validation loss: 2.2358069086587555

Epoch: 6| Step: 7
Training loss: 1.7315938472747803
Validation loss: 2.2146836096240627

Epoch: 6| Step: 8
Training loss: 1.2813234329223633
Validation loss: 2.162417528449848

Epoch: 6| Step: 9
Training loss: 1.837448000907898
Validation loss: 2.107603201302149

Epoch: 6| Step: 10
Training loss: 1.0244767665863037
Validation loss: 2.0432845930899344

Epoch: 6| Step: 11
Training loss: 1.361860752105713
Validation loss: 2.0165658753405333

Epoch: 6| Step: 12
Training loss: 1.2413747310638428
Validation loss: 1.9819811133928196

Epoch: 6| Step: 13
Training loss: 1.362609624862671
Validation loss: 1.9858794289250528

Epoch: 202| Step: 0
Training loss: 1.6325769424438477
Validation loss: 1.9610125390432214

Epoch: 6| Step: 1
Training loss: 1.5445040464401245
Validation loss: 1.9644784606913084

Epoch: 6| Step: 2
Training loss: 0.7548004388809204
Validation loss: 2.037344014772805

Epoch: 6| Step: 3
Training loss: 2.0567870140075684
Validation loss: 2.096557914569814

Epoch: 6| Step: 4
Training loss: 1.3780367374420166
Validation loss: 2.1642227134396954

Epoch: 6| Step: 5
Training loss: 1.3974186182022095
Validation loss: 2.195864369792323

Epoch: 6| Step: 6
Training loss: 1.4021058082580566
Validation loss: 2.1890506898203204

Epoch: 6| Step: 7
Training loss: 1.8029717206954956
Validation loss: 2.1484091115254227

Epoch: 6| Step: 8
Training loss: 1.2235708236694336
Validation loss: 2.132795911963268

Epoch: 6| Step: 9
Training loss: 2.6388096809387207
Validation loss: 2.124282313931373

Epoch: 6| Step: 10
Training loss: 1.8654890060424805
Validation loss: 2.1238306555696713

Epoch: 6| Step: 11
Training loss: 1.9293861389160156
Validation loss: 2.1186457346844416

Epoch: 6| Step: 12
Training loss: 1.4537649154663086
Validation loss: 2.139686128144623

Epoch: 6| Step: 13
Training loss: 1.0779024362564087
Validation loss: 2.164381379722267

Epoch: 203| Step: 0
Training loss: 1.6487789154052734
Validation loss: 2.24341288305098

Epoch: 6| Step: 1
Training loss: 1.7354704141616821
Validation loss: 2.2836281868719284

Epoch: 6| Step: 2
Training loss: 1.7796473503112793
Validation loss: 2.332637758665187

Epoch: 6| Step: 3
Training loss: 1.5798982381820679
Validation loss: 2.3482275496246996

Epoch: 6| Step: 4
Training loss: 1.746307373046875
Validation loss: 2.308629112858926

Epoch: 6| Step: 5
Training loss: 2.1624951362609863
Validation loss: 2.2061719945681992

Epoch: 6| Step: 6
Training loss: 0.9793264865875244
Validation loss: 2.1420825758287982

Epoch: 6| Step: 7
Training loss: 1.4872123003005981
Validation loss: 2.0759716021117343

Epoch: 6| Step: 8
Training loss: 2.188143491744995
Validation loss: 2.0630884208986835

Epoch: 6| Step: 9
Training loss: 1.1845922470092773
Validation loss: 2.072583561302513

Epoch: 6| Step: 10
Training loss: 1.9612653255462646
Validation loss: 2.076670979940763

Epoch: 6| Step: 11
Training loss: 1.4584009647369385
Validation loss: 2.0743716378365793

Epoch: 6| Step: 12
Training loss: 1.5149507522583008
Validation loss: 2.0632979587842057

Epoch: 6| Step: 13
Training loss: 1.8166143894195557
Validation loss: 2.0625373740350046

Epoch: 204| Step: 0
Training loss: 1.1873782873153687
Validation loss: 2.1250898453497116

Epoch: 6| Step: 1
Training loss: 2.5959713459014893
Validation loss: 2.175177293439065

Epoch: 6| Step: 2
Training loss: 1.6839673519134521
Validation loss: 2.2195348265350505

Epoch: 6| Step: 3
Training loss: 1.0342224836349487
Validation loss: 2.2431718303311254

Epoch: 6| Step: 4
Training loss: 2.0849461555480957
Validation loss: 2.2682748276700258

Epoch: 6| Step: 5
Training loss: 1.6155879497528076
Validation loss: 2.202807387998027

Epoch: 6| Step: 6
Training loss: 1.6274654865264893
Validation loss: 2.1425123394176526

Epoch: 6| Step: 7
Training loss: 1.5786161422729492
Validation loss: 2.0263894693825835

Epoch: 6| Step: 8
Training loss: 1.4229207038879395
Validation loss: 2.0010217812753495

Epoch: 6| Step: 9
Training loss: 1.687364101409912
Validation loss: 2.0152213265818935

Epoch: 6| Step: 10
Training loss: 1.4407603740692139
Validation loss: 2.005244339666059

Epoch: 6| Step: 11
Training loss: 1.928220272064209
Validation loss: 1.9879668387033607

Epoch: 6| Step: 12
Training loss: 2.1495563983917236
Validation loss: 2.0150840923350346

Epoch: 6| Step: 13
Training loss: 0.9886395335197449
Validation loss: 2.003289179135394

Epoch: 205| Step: 0
Training loss: 1.7355401515960693
Validation loss: 1.9996236357637631

Epoch: 6| Step: 1
Training loss: 1.1978217363357544
Validation loss: 2.0043903499521236

Epoch: 6| Step: 2
Training loss: 1.1481926441192627
Validation loss: 2.055898492054273

Epoch: 6| Step: 3
Training loss: 1.6628254652023315
Validation loss: 2.123106065616813

Epoch: 6| Step: 4
Training loss: 1.5077755451202393
Validation loss: 2.206077193701139

Epoch: 6| Step: 5
Training loss: 1.9473273754119873
Validation loss: 2.2756535955654678

Epoch: 6| Step: 6
Training loss: 2.2722461223602295
Validation loss: 2.297499087549025

Epoch: 6| Step: 7
Training loss: 1.670018196105957
Validation loss: 2.2620941156982095

Epoch: 6| Step: 8
Training loss: 1.4438698291778564
Validation loss: 2.234016321038687

Epoch: 6| Step: 9
Training loss: 1.7594009637832642
Validation loss: 2.2055665664775397

Epoch: 6| Step: 10
Training loss: 1.4934905767440796
Validation loss: 2.157330507873207

Epoch: 6| Step: 11
Training loss: 1.554137945175171
Validation loss: 2.0879170510076706

Epoch: 6| Step: 12
Training loss: 1.291649341583252
Validation loss: 2.1183392155554985

Epoch: 6| Step: 13
Training loss: 1.4877042770385742
Validation loss: 2.095128687479163

Epoch: 206| Step: 0
Training loss: 2.166295051574707
Validation loss: 2.097091826059485

Epoch: 6| Step: 1
Training loss: 1.3713371753692627
Validation loss: 2.1128081801117107

Epoch: 6| Step: 2
Training loss: 1.1767572164535522
Validation loss: 2.1356317509887037

Epoch: 6| Step: 3
Training loss: 1.5309560298919678
Validation loss: 2.180586520061698

Epoch: 6| Step: 4
Training loss: 1.3630921840667725
Validation loss: 2.238454254724646

Epoch: 6| Step: 5
Training loss: 1.2987005710601807
Validation loss: 2.272496061940347

Epoch: 6| Step: 6
Training loss: 1.818127155303955
Validation loss: 2.305753110557474

Epoch: 6| Step: 7
Training loss: 1.463916301727295
Validation loss: 2.29094761161394

Epoch: 6| Step: 8
Training loss: 1.2251559495925903
Validation loss: 2.2466677850292576

Epoch: 6| Step: 9
Training loss: 2.1358067989349365
Validation loss: 2.1859693629767305

Epoch: 6| Step: 10
Training loss: 1.9696816205978394
Validation loss: 2.153546484567786

Epoch: 6| Step: 11
Training loss: 1.2436983585357666
Validation loss: 2.108657334440498

Epoch: 6| Step: 12
Training loss: 1.5376131534576416
Validation loss: 2.069621632176061

Epoch: 6| Step: 13
Training loss: 1.40109384059906
Validation loss: 2.0828177749469714

Epoch: 207| Step: 0
Training loss: 1.2897226810455322
Validation loss: 2.033225687601233

Epoch: 6| Step: 1
Training loss: 1.5820958614349365
Validation loss: 2.020862840837048

Epoch: 6| Step: 2
Training loss: 1.4942752122879028
Validation loss: 2.0117678065453806

Epoch: 6| Step: 3
Training loss: 0.9292172193527222
Validation loss: 2.0115198973686463

Epoch: 6| Step: 4
Training loss: 1.8875846862792969
Validation loss: 2.0203813993802635

Epoch: 6| Step: 5
Training loss: 0.9740376472473145
Validation loss: 2.0225482525364047

Epoch: 6| Step: 6
Training loss: 1.5712302923202515
Validation loss: 2.0374110193662744

Epoch: 6| Step: 7
Training loss: 1.704352617263794
Validation loss: 2.0350215640119327

Epoch: 6| Step: 8
Training loss: 1.5927611589431763
Validation loss: 2.073969179584134

Epoch: 6| Step: 9
Training loss: 1.4748806953430176
Validation loss: 2.0883411540780017

Epoch: 6| Step: 10
Training loss: 1.4213080406188965
Validation loss: 2.1182570431822088

Epoch: 6| Step: 11
Training loss: 1.6581640243530273
Validation loss: 2.1257854892361547

Epoch: 6| Step: 12
Training loss: 1.5210001468658447
Validation loss: 2.175692125033307

Epoch: 6| Step: 13
Training loss: 1.751481294631958
Validation loss: 2.1292386029356267

Epoch: 208| Step: 0
Training loss: 1.8102803230285645
Validation loss: 2.140715338850534

Epoch: 6| Step: 1
Training loss: 1.5045108795166016
Validation loss: 2.124972451117731

Epoch: 6| Step: 2
Training loss: 1.2138054370880127
Validation loss: 2.1248349528158865

Epoch: 6| Step: 3
Training loss: 1.4277222156524658
Validation loss: 2.111294577198644

Epoch: 6| Step: 4
Training loss: 1.1931686401367188
Validation loss: 2.0786232140756424

Epoch: 6| Step: 5
Training loss: 1.4446072578430176
Validation loss: 2.0662642704543246

Epoch: 6| Step: 6
Training loss: 1.0287177562713623
Validation loss: 2.0588696618233957

Epoch: 6| Step: 7
Training loss: 1.525761365890503
Validation loss: 2.0293161869049072

Epoch: 6| Step: 8
Training loss: 1.5456856489181519
Validation loss: 2.0415309449677825

Epoch: 6| Step: 9
Training loss: 1.2836971282958984
Validation loss: 2.0498502139122254

Epoch: 6| Step: 10
Training loss: 1.7600651979446411
Validation loss: 2.068792957131581

Epoch: 6| Step: 11
Training loss: 1.5165817737579346
Validation loss: 2.0718595725233837

Epoch: 6| Step: 12
Training loss: 1.5982716083526611
Validation loss: 2.126726027457945

Epoch: 6| Step: 13
Training loss: 1.407021164894104
Validation loss: 2.1194338580613494

Epoch: 209| Step: 0
Training loss: 1.6939090490341187
Validation loss: 2.1272751336456626

Epoch: 6| Step: 1
Training loss: 1.2512569427490234
Validation loss: 2.096003468318652

Epoch: 6| Step: 2
Training loss: 1.151038408279419
Validation loss: 2.079478210018527

Epoch: 6| Step: 3
Training loss: 1.5068330764770508
Validation loss: 2.0688077942017586

Epoch: 6| Step: 4
Training loss: 1.1944580078125
Validation loss: 2.0429852342092865

Epoch: 6| Step: 5
Training loss: 1.3961255550384521
Validation loss: 2.063045842673189

Epoch: 6| Step: 6
Training loss: 1.3836123943328857
Validation loss: 2.0605981939582416

Epoch: 6| Step: 7
Training loss: 1.5996010303497314
Validation loss: 2.0879395392633255

Epoch: 6| Step: 8
Training loss: 1.7623424530029297
Validation loss: 2.0831380377533617

Epoch: 6| Step: 9
Training loss: 1.8363938331604004
Validation loss: 2.106186036140688

Epoch: 6| Step: 10
Training loss: 1.2288846969604492
Validation loss: 2.1133137749087427

Epoch: 6| Step: 11
Training loss: 1.1168475151062012
Validation loss: 2.118933446945683

Epoch: 6| Step: 12
Training loss: 1.8422038555145264
Validation loss: 2.120881308791458

Epoch: 6| Step: 13
Training loss: 1.3442115783691406
Validation loss: 2.1248982785850443

Epoch: 210| Step: 0
Training loss: 1.3554506301879883
Validation loss: 2.1020032513526177

Epoch: 6| Step: 1
Training loss: 1.0897306203842163
Validation loss: 2.0706340010448168

Epoch: 6| Step: 2
Training loss: 1.507470965385437
Validation loss: 2.028058067444832

Epoch: 6| Step: 3
Training loss: 2.027526378631592
Validation loss: 1.992620470703289

Epoch: 6| Step: 4
Training loss: 1.4322545528411865
Validation loss: 1.9949516147695563

Epoch: 6| Step: 5
Training loss: 1.097825050354004
Validation loss: 1.9790413405305596

Epoch: 6| Step: 6
Training loss: 1.1527819633483887
Validation loss: 1.9808360466393091

Epoch: 6| Step: 7
Training loss: 0.9799071550369263
Validation loss: 2.012524083096494

Epoch: 6| Step: 8
Training loss: 1.5184321403503418
Validation loss: 2.0252520525327293

Epoch: 6| Step: 9
Training loss: 1.1504077911376953
Validation loss: 2.0597173270358833

Epoch: 6| Step: 10
Training loss: 1.3844037055969238
Validation loss: 2.067318977848176

Epoch: 6| Step: 11
Training loss: 1.7305254936218262
Validation loss: 2.0790072653883245

Epoch: 6| Step: 12
Training loss: 2.039224624633789
Validation loss: 2.072307380296851

Epoch: 6| Step: 13
Training loss: 1.8383405208587646
Validation loss: 2.080890670899422

Epoch: 211| Step: 0
Training loss: 1.118922233581543
Validation loss: 2.0792969183255265

Epoch: 6| Step: 1
Training loss: 1.5893969535827637
Validation loss: 2.054972540947699

Epoch: 6| Step: 2
Training loss: 1.5448768138885498
Validation loss: 2.053542055109496

Epoch: 6| Step: 3
Training loss: 2.100651264190674
Validation loss: 2.0694937834175686

Epoch: 6| Step: 4
Training loss: 1.1788796186447144
Validation loss: 2.096207962241224

Epoch: 6| Step: 5
Training loss: 1.5309118032455444
Validation loss: 2.102292306961552

Epoch: 6| Step: 6
Training loss: 1.6985732316970825
Validation loss: 2.1302590536814865

Epoch: 6| Step: 7
Training loss: 1.2464203834533691
Validation loss: 2.1445626366523003

Epoch: 6| Step: 8
Training loss: 1.5592494010925293
Validation loss: 2.1609734412162536

Epoch: 6| Step: 9
Training loss: 1.1902108192443848
Validation loss: 2.1986355576463925

Epoch: 6| Step: 10
Training loss: 1.8152120113372803
Validation loss: 2.1896674889390186

Epoch: 6| Step: 11
Training loss: 0.9437868595123291
Validation loss: 2.1103499756064465

Epoch: 6| Step: 12
Training loss: 1.114778757095337
Validation loss: 2.0773217780615694

Epoch: 6| Step: 13
Training loss: 1.4929962158203125
Validation loss: 2.042389605634956

Epoch: 212| Step: 0
Training loss: 1.3886712789535522
Validation loss: 2.050452334906465

Epoch: 6| Step: 1
Training loss: 1.1258453130722046
Validation loss: 2.0376977215531054

Epoch: 6| Step: 2
Training loss: 0.6212223172187805
Validation loss: 2.0144045891300326

Epoch: 6| Step: 3
Training loss: 1.977644443511963
Validation loss: 2.034927791164767

Epoch: 6| Step: 4
Training loss: 1.7250750064849854
Validation loss: 2.0421189518385034

Epoch: 6| Step: 5
Training loss: 0.9986340999603271
Validation loss: 2.05769637579559

Epoch: 6| Step: 6
Training loss: 1.3620858192443848
Validation loss: 2.04310562533717

Epoch: 6| Step: 7
Training loss: 1.684844970703125
Validation loss: 2.0763978009582846

Epoch: 6| Step: 8
Training loss: 1.4817794561386108
Validation loss: 2.068123630298081

Epoch: 6| Step: 9
Training loss: 1.1299928426742554
Validation loss: 2.049071491405528

Epoch: 6| Step: 10
Training loss: 1.5523685216903687
Validation loss: 2.05104257470818

Epoch: 6| Step: 11
Training loss: 1.5234302282333374
Validation loss: 2.0340141122059157

Epoch: 6| Step: 12
Training loss: 1.1746677160263062
Validation loss: 2.0121138070219304

Epoch: 6| Step: 13
Training loss: 1.3380036354064941
Validation loss: 1.9956501812063239

Epoch: 213| Step: 0
Training loss: 1.8990025520324707
Validation loss: 2.014289435519967

Epoch: 6| Step: 1
Training loss: 1.6007517576217651
Validation loss: 2.0202168021150815

Epoch: 6| Step: 2
Training loss: 1.6501526832580566
Validation loss: 2.029818175941385

Epoch: 6| Step: 3
Training loss: 1.5636459589004517
Validation loss: 2.0355315310980684

Epoch: 6| Step: 4
Training loss: 1.1217572689056396
Validation loss: 2.0520789072077763

Epoch: 6| Step: 5
Training loss: 2.0519895553588867
Validation loss: 2.0703481089684272

Epoch: 6| Step: 6
Training loss: 1.6880717277526855
Validation loss: 2.120953359911519

Epoch: 6| Step: 7
Training loss: 1.4593050479888916
Validation loss: 2.116287185299781

Epoch: 6| Step: 8
Training loss: 0.8486264944076538
Validation loss: 2.1435359472869546

Epoch: 6| Step: 9
Training loss: 1.3037883043289185
Validation loss: 2.1831956601911977

Epoch: 6| Step: 10
Training loss: 1.751713752746582
Validation loss: 2.1718441260758268

Epoch: 6| Step: 11
Training loss: 1.5732288360595703
Validation loss: 2.1500171179412515

Epoch: 6| Step: 12
Training loss: 1.1664215326309204
Validation loss: 2.1326583572613296

Epoch: 6| Step: 13
Training loss: 0.9978981018066406
Validation loss: 2.0722015673114407

Epoch: 214| Step: 0
Training loss: 1.7635328769683838
Validation loss: 2.0052470237978044

Epoch: 6| Step: 1
Training loss: 1.4420130252838135
Validation loss: 2.023965266443068

Epoch: 6| Step: 2
Training loss: 1.3211270570755005
Validation loss: 2.023975706869556

Epoch: 6| Step: 3
Training loss: 1.3730473518371582
Validation loss: 2.0511530458286242

Epoch: 6| Step: 4
Training loss: 0.9932589530944824
Validation loss: 2.0662178993225098

Epoch: 6| Step: 5
Training loss: 1.5828057527542114
Validation loss: 2.059367543907576

Epoch: 6| Step: 6
Training loss: 1.6951595544815063
Validation loss: 2.052043334130318

Epoch: 6| Step: 7
Training loss: 1.234832763671875
Validation loss: 2.0139311129047024

Epoch: 6| Step: 8
Training loss: 1.2699730396270752
Validation loss: 2.056353384448636

Epoch: 6| Step: 9
Training loss: 1.9272936582565308
Validation loss: 2.1049099429961173

Epoch: 6| Step: 10
Training loss: 1.0460530519485474
Validation loss: 2.1358781258265176

Epoch: 6| Step: 11
Training loss: 1.5039699077606201
Validation loss: 2.1206561019343715

Epoch: 6| Step: 12
Training loss: 1.5938962697982788
Validation loss: 2.1149215877697034

Epoch: 6| Step: 13
Training loss: 1.3251662254333496
Validation loss: 2.068963499479396

Epoch: 215| Step: 0
Training loss: 1.6792807579040527
Validation loss: 2.050556517416431

Epoch: 6| Step: 1
Training loss: 1.450291633605957
Validation loss: 2.0400647770973945

Epoch: 6| Step: 2
Training loss: 1.5719002485275269
Validation loss: 2.026005647515738

Epoch: 6| Step: 3
Training loss: 1.2881343364715576
Validation loss: 2.0136855199772823

Epoch: 6| Step: 4
Training loss: 1.2367500066757202
Validation loss: 2.0192487675656556

Epoch: 6| Step: 5
Training loss: 1.2893567085266113
Validation loss: 2.039012393643779

Epoch: 6| Step: 6
Training loss: 1.3209128379821777
Validation loss: 2.0573280370363625

Epoch: 6| Step: 7
Training loss: 1.2846022844314575
Validation loss: 2.059351610881026

Epoch: 6| Step: 8
Training loss: 1.3454351425170898
Validation loss: 2.067463649216519

Epoch: 6| Step: 9
Training loss: 1.8538570404052734
Validation loss: 2.088024011222265

Epoch: 6| Step: 10
Training loss: 1.2948236465454102
Validation loss: 2.063678797855172

Epoch: 6| Step: 11
Training loss: 1.016852617263794
Validation loss: 2.0734491130357147

Epoch: 6| Step: 12
Training loss: 1.5355539321899414
Validation loss: 2.0753819327200613

Epoch: 6| Step: 13
Training loss: 1.2950119972229004
Validation loss: 2.058303456152639

Epoch: 216| Step: 0
Training loss: 1.3138816356658936
Validation loss: 2.0664316178649984

Epoch: 6| Step: 1
Training loss: 1.2055151462554932
Validation loss: 2.0585826148268995

Epoch: 6| Step: 2
Training loss: 0.7200194001197815
Validation loss: 2.067162198405112

Epoch: 6| Step: 3
Training loss: 0.7048649787902832
Validation loss: 2.0175924672875354

Epoch: 6| Step: 4
Training loss: 1.4765045642852783
Validation loss: 1.9960816906344505

Epoch: 6| Step: 5
Training loss: 1.271134376525879
Validation loss: 1.978066252123925

Epoch: 6| Step: 6
Training loss: 2.0435359477996826
Validation loss: 1.9930208600977415

Epoch: 6| Step: 7
Training loss: 1.5951951742172241
Validation loss: 1.9904208619107482

Epoch: 6| Step: 8
Training loss: 1.7441636323928833
Validation loss: 1.992051907764968

Epoch: 6| Step: 9
Training loss: 1.037842035293579
Validation loss: 1.9895577020542596

Epoch: 6| Step: 10
Training loss: 0.779877245426178
Validation loss: 2.006381065614762

Epoch: 6| Step: 11
Training loss: 1.9840091466903687
Validation loss: 2.012389582972373

Epoch: 6| Step: 12
Training loss: 1.9108811616897583
Validation loss: 2.0292550709939774

Epoch: 6| Step: 13
Training loss: 0.9507132768630981
Validation loss: 1.9963837682559926

Epoch: 217| Step: 0
Training loss: 1.6769665479660034
Validation loss: 2.004357586624802

Epoch: 6| Step: 1
Training loss: 1.064587116241455
Validation loss: 1.9975432247243903

Epoch: 6| Step: 2
Training loss: 1.5478109121322632
Validation loss: 2.015914696519093

Epoch: 6| Step: 3
Training loss: 1.5705314874649048
Validation loss: 2.016876934677042

Epoch: 6| Step: 4
Training loss: 1.0374844074249268
Validation loss: 2.044533775698754

Epoch: 6| Step: 5
Training loss: 1.0845518112182617
Validation loss: 2.0640058953274965

Epoch: 6| Step: 6
Training loss: 1.255509614944458
Validation loss: 2.075166598443062

Epoch: 6| Step: 7
Training loss: 1.2592852115631104
Validation loss: 2.0700878148437827

Epoch: 6| Step: 8
Training loss: 1.2223165035247803
Validation loss: 2.0790278180952995

Epoch: 6| Step: 9
Training loss: 1.0325639247894287
Validation loss: 2.069746946775785

Epoch: 6| Step: 10
Training loss: 1.2303743362426758
Validation loss: 2.0610199461701098

Epoch: 6| Step: 11
Training loss: 1.4340050220489502
Validation loss: 2.087664504205027

Epoch: 6| Step: 12
Training loss: 1.538606882095337
Validation loss: 2.0794556012717624

Epoch: 6| Step: 13
Training loss: 1.2348926067352295
Validation loss: 2.026630619520782

Epoch: 218| Step: 0
Training loss: 1.642148733139038
Validation loss: 1.9776964623440978

Epoch: 6| Step: 1
Training loss: 1.0894535779953003
Validation loss: 1.9783191245089295

Epoch: 6| Step: 2
Training loss: 1.318213939666748
Validation loss: 1.961297228772153

Epoch: 6| Step: 3
Training loss: 1.2136911153793335
Validation loss: 1.9645665345653411

Epoch: 6| Step: 4
Training loss: 0.9651814699172974
Validation loss: 1.9661739846711517

Epoch: 6| Step: 5
Training loss: 1.130260705947876
Validation loss: 1.9691611092577699

Epoch: 6| Step: 6
Training loss: 1.5364418029785156
Validation loss: 1.9906624670951598

Epoch: 6| Step: 7
Training loss: 1.1406058073043823
Validation loss: 2.020105520884196

Epoch: 6| Step: 8
Training loss: 0.933621883392334
Validation loss: 2.0362195430263395

Epoch: 6| Step: 9
Training loss: 1.935872197151184
Validation loss: 2.053294207460137

Epoch: 6| Step: 10
Training loss: 1.1360892057418823
Validation loss: 2.0558367698423323

Epoch: 6| Step: 11
Training loss: 1.087430477142334
Validation loss: 2.066070661749891

Epoch: 6| Step: 12
Training loss: 1.822018027305603
Validation loss: 2.0562102717737996

Epoch: 6| Step: 13
Training loss: 1.062713623046875
Validation loss: 2.072539218010441

Epoch: 219| Step: 0
Training loss: 1.818109393119812
Validation loss: 2.041090314106275

Epoch: 6| Step: 1
Training loss: 0.9544250965118408
Validation loss: 2.023377783836857

Epoch: 6| Step: 2
Training loss: 0.9316534399986267
Validation loss: 2.058492645140617

Epoch: 6| Step: 3
Training loss: 0.9279247522354126
Validation loss: 2.028338301566339

Epoch: 6| Step: 4
Training loss: 1.86875319480896
Validation loss: 2.016181049808379

Epoch: 6| Step: 5
Training loss: 1.2681511640548706
Validation loss: 2.0461268873624903

Epoch: 6| Step: 6
Training loss: 1.3611947298049927
Validation loss: 2.03253004371479

Epoch: 6| Step: 7
Training loss: 0.7995618581771851
Validation loss: 2.005436440949799

Epoch: 6| Step: 8
Training loss: 1.4359431266784668
Validation loss: 1.9762040004935315

Epoch: 6| Step: 9
Training loss: 1.7814445495605469
Validation loss: 1.9617869033608386

Epoch: 6| Step: 10
Training loss: 1.1866178512573242
Validation loss: 1.9616698142020934

Epoch: 6| Step: 11
Training loss: 1.2041316032409668
Validation loss: 1.9727468041963474

Epoch: 6| Step: 12
Training loss: 1.355677604675293
Validation loss: 1.9579057731936056

Epoch: 6| Step: 13
Training loss: 0.7179418206214905
Validation loss: 1.9954827459909583

Epoch: 220| Step: 0
Training loss: 1.774803638458252
Validation loss: 2.0303754562972696

Epoch: 6| Step: 1
Training loss: 0.9563283920288086
Validation loss: 2.035510342608216

Epoch: 6| Step: 2
Training loss: 1.1077711582183838
Validation loss: 2.0640833582929385

Epoch: 6| Step: 3
Training loss: 1.0078766345977783
Validation loss: 2.0898297550857707

Epoch: 6| Step: 4
Training loss: 1.450537919998169
Validation loss: 2.0710785850401847

Epoch: 6| Step: 5
Training loss: 1.5588936805725098
Validation loss: 2.0920676262147966

Epoch: 6| Step: 6
Training loss: 1.3006134033203125
Validation loss: 2.0640759237350954

Epoch: 6| Step: 7
Training loss: 1.2157104015350342
Validation loss: 2.04040063452977

Epoch: 6| Step: 8
Training loss: 1.2185149192810059
Validation loss: 2.0216625749423938

Epoch: 6| Step: 9
Training loss: 1.4236021041870117
Validation loss: 1.9916843778343611

Epoch: 6| Step: 10
Training loss: 1.6698777675628662
Validation loss: 2.001192537687158

Epoch: 6| Step: 11
Training loss: 1.2041257619857788
Validation loss: 2.0109941280016335

Epoch: 6| Step: 12
Training loss: 0.8290610313415527
Validation loss: 1.9818070524482316

Epoch: 6| Step: 13
Training loss: 1.4066346883773804
Validation loss: 1.9878211764879123

Epoch: 221| Step: 0
Training loss: 1.1361346244812012
Validation loss: 1.996163998880694

Epoch: 6| Step: 1
Training loss: 1.696847915649414
Validation loss: 2.063720809516086

Epoch: 6| Step: 2
Training loss: 1.3740079402923584
Validation loss: 2.1182157044769614

Epoch: 6| Step: 3
Training loss: 1.1066330671310425
Validation loss: 2.15448683820745

Epoch: 6| Step: 4
Training loss: 1.4335968494415283
Validation loss: 2.1437883351438787

Epoch: 6| Step: 5
Training loss: 1.7474982738494873
Validation loss: 2.1306367330653693

Epoch: 6| Step: 6
Training loss: 1.334048867225647
Validation loss: 2.0792196681422572

Epoch: 6| Step: 7
Training loss: 1.2122985124588013
Validation loss: 2.0291049377892607

Epoch: 6| Step: 8
Training loss: 1.3768601417541504
Validation loss: 2.028552727032733

Epoch: 6| Step: 9
Training loss: 1.4728413820266724
Validation loss: 2.035870785354286

Epoch: 6| Step: 10
Training loss: 0.7745016813278198
Validation loss: 2.057654070597823

Epoch: 6| Step: 11
Training loss: 1.7356383800506592
Validation loss: 2.0268707762482348

Epoch: 6| Step: 12
Training loss: 0.8601959943771362
Validation loss: 2.0170726430031563

Epoch: 6| Step: 13
Training loss: 0.45091691613197327
Validation loss: 2.0114210497948433

Epoch: 222| Step: 0
Training loss: 0.8733795881271362
Validation loss: 2.0116439942390687

Epoch: 6| Step: 1
Training loss: 0.7912765741348267
Validation loss: 2.0704411998871834

Epoch: 6| Step: 2
Training loss: 0.7770491242408752
Validation loss: 2.125202153318672

Epoch: 6| Step: 3
Training loss: 1.5821596384048462
Validation loss: 2.129371884048626

Epoch: 6| Step: 4
Training loss: 1.671396017074585
Validation loss: 2.1529312415789534

Epoch: 6| Step: 5
Training loss: 1.3803163766860962
Validation loss: 2.1129524643703173

Epoch: 6| Step: 6
Training loss: 1.4334001541137695
Validation loss: 2.0415099231145715

Epoch: 6| Step: 7
Training loss: 1.2793011665344238
Validation loss: 2.013556557316934

Epoch: 6| Step: 8
Training loss: 1.6001102924346924
Validation loss: 2.0064899229234263

Epoch: 6| Step: 9
Training loss: 1.5211565494537354
Validation loss: 1.9906599380636727

Epoch: 6| Step: 10
Training loss: 1.1502652168273926
Validation loss: 2.014933786084575

Epoch: 6| Step: 11
Training loss: 1.1889948844909668
Validation loss: 2.014422378232402

Epoch: 6| Step: 12
Training loss: 1.3863675594329834
Validation loss: 1.9888086421515352

Epoch: 6| Step: 13
Training loss: 1.718123435974121
Validation loss: 2.011220044987176

Epoch: 223| Step: 0
Training loss: 1.1789135932922363
Validation loss: 2.0627378494508806

Epoch: 6| Step: 1
Training loss: 0.7769099473953247
Validation loss: 2.0514694439467562

Epoch: 6| Step: 2
Training loss: 0.9878210425376892
Validation loss: 2.0670942068099976

Epoch: 6| Step: 3
Training loss: 1.0149720907211304
Validation loss: 2.0623713090855587

Epoch: 6| Step: 4
Training loss: 1.8966596126556396
Validation loss: 2.059101184209188

Epoch: 6| Step: 5
Training loss: 0.6772271990776062
Validation loss: 2.0539693447851364

Epoch: 6| Step: 6
Training loss: 2.113816738128662
Validation loss: 2.030263529028944

Epoch: 6| Step: 7
Training loss: 1.517580270767212
Validation loss: 2.023495337014557

Epoch: 6| Step: 8
Training loss: 1.411481499671936
Validation loss: 2.004848499451914

Epoch: 6| Step: 9
Training loss: 1.1050726175308228
Validation loss: 2.007322993329776

Epoch: 6| Step: 10
Training loss: 1.3791115283966064
Validation loss: 1.9964611966122863

Epoch: 6| Step: 11
Training loss: 1.1509976387023926
Validation loss: 2.0029418571020967

Epoch: 6| Step: 12
Training loss: 0.9682902097702026
Validation loss: 2.022151877803187

Epoch: 6| Step: 13
Training loss: 0.9851894378662109
Validation loss: 2.0080621473250853

Epoch: 224| Step: 0
Training loss: 0.9663569331169128
Validation loss: 2.022127289925852

Epoch: 6| Step: 1
Training loss: 1.0027951002120972
Validation loss: 2.0267253921877955

Epoch: 6| Step: 2
Training loss: 1.086159110069275
Validation loss: 2.0275936600982503

Epoch: 6| Step: 3
Training loss: 0.7940628528594971
Validation loss: 2.0390341384436494

Epoch: 6| Step: 4
Training loss: 1.4204726219177246
Validation loss: 2.0300706073802006

Epoch: 6| Step: 5
Training loss: 1.3531570434570312
Validation loss: 2.01896487000168

Epoch: 6| Step: 6
Training loss: 1.1638457775115967
Validation loss: 2.022660647669146

Epoch: 6| Step: 7
Training loss: 0.878876805305481
Validation loss: 2.02822293004682

Epoch: 6| Step: 8
Training loss: 0.8432982563972473
Validation loss: 2.0072107084335817

Epoch: 6| Step: 9
Training loss: 1.6363818645477295
Validation loss: 1.9909703244445145

Epoch: 6| Step: 10
Training loss: 1.3122408390045166
Validation loss: 1.998502149376818

Epoch: 6| Step: 11
Training loss: 1.158074140548706
Validation loss: 1.9987428188323975

Epoch: 6| Step: 12
Training loss: 1.3060669898986816
Validation loss: 2.0356433622298704

Epoch: 6| Step: 13
Training loss: 2.2841367721557617
Validation loss: 2.024152789064633

Epoch: 225| Step: 0
Training loss: 1.8396387100219727
Validation loss: 2.0497964633408414

Epoch: 6| Step: 1
Training loss: 1.2989665269851685
Validation loss: 2.029916778687508

Epoch: 6| Step: 2
Training loss: 1.5060925483703613
Validation loss: 2.0161002733374156

Epoch: 6| Step: 3
Training loss: 1.0314640998840332
Validation loss: 1.9985690039973105

Epoch: 6| Step: 4
Training loss: 0.7446157932281494
Validation loss: 1.9716855120915238

Epoch: 6| Step: 5
Training loss: 0.7139851450920105
Validation loss: 1.968910824867987

Epoch: 6| Step: 6
Training loss: 1.2195041179656982
Validation loss: 1.9898261357379217

Epoch: 6| Step: 7
Training loss: 1.0523099899291992
Validation loss: 2.018901396823186

Epoch: 6| Step: 8
Training loss: 0.8852194547653198
Validation loss: 2.0699865036113287

Epoch: 6| Step: 9
Training loss: 1.1556072235107422
Validation loss: 2.1353376296258744

Epoch: 6| Step: 10
Training loss: 1.2512433528900146
Validation loss: 2.1586787700653076

Epoch: 6| Step: 11
Training loss: 1.6501343250274658
Validation loss: 2.116608019798033

Epoch: 6| Step: 12
Training loss: 1.0712754726409912
Validation loss: 2.0978287266146753

Epoch: 6| Step: 13
Training loss: 1.0393292903900146
Validation loss: 2.0616614036662604

Epoch: 226| Step: 0
Training loss: 0.9019323587417603
Validation loss: 2.0511596510487218

Epoch: 6| Step: 1
Training loss: 1.5056613683700562
Validation loss: 2.0575752232664373

Epoch: 6| Step: 2
Training loss: 0.8693913817405701
Validation loss: 2.054110860311857

Epoch: 6| Step: 3
Training loss: 1.1159858703613281
Validation loss: 2.0363179765721804

Epoch: 6| Step: 4
Training loss: 1.1071808338165283
Validation loss: 2.005553937727405

Epoch: 6| Step: 5
Training loss: 1.5673327445983887
Validation loss: 2.0271442513312063

Epoch: 6| Step: 6
Training loss: 1.6780041456222534
Validation loss: 2.0581537677395727

Epoch: 6| Step: 7
Training loss: 1.947509765625
Validation loss: 2.075774103082636

Epoch: 6| Step: 8
Training loss: 0.9567748308181763
Validation loss: 2.074768222788329

Epoch: 6| Step: 9
Training loss: 1.4619649648666382
Validation loss: 2.021132875514287

Epoch: 6| Step: 10
Training loss: 1.4212064743041992
Validation loss: 2.01952362573275

Epoch: 6| Step: 11
Training loss: 0.7365564107894897
Validation loss: 1.9803600067733436

Epoch: 6| Step: 12
Training loss: 0.6999006867408752
Validation loss: 2.0103568928216093

Epoch: 6| Step: 13
Training loss: 1.2280391454696655
Validation loss: 2.0083441862496

Epoch: 227| Step: 0
Training loss: 1.131894826889038
Validation loss: 2.0138391038422943

Epoch: 6| Step: 1
Training loss: 1.0923296213150024
Validation loss: 2.0449164182909074

Epoch: 6| Step: 2
Training loss: 1.1180965900421143
Validation loss: 2.0468381912477556

Epoch: 6| Step: 3
Training loss: 1.0381088256835938
Validation loss: 2.0775035042916574

Epoch: 6| Step: 4
Training loss: 1.3291923999786377
Validation loss: 2.072312601151005

Epoch: 6| Step: 5
Training loss: 1.2485005855560303
Validation loss: 2.0784096205106346

Epoch: 6| Step: 6
Training loss: 1.1983047723770142
Validation loss: 2.085006739503594

Epoch: 6| Step: 7
Training loss: 1.003570795059204
Validation loss: 2.0557545077416206

Epoch: 6| Step: 8
Training loss: 1.1968517303466797
Validation loss: 2.0407693206623034

Epoch: 6| Step: 9
Training loss: 1.3685863018035889
Validation loss: 2.042105218415619

Epoch: 6| Step: 10
Training loss: 1.572222113609314
Validation loss: 1.99504300086729

Epoch: 6| Step: 11
Training loss: 1.1726216077804565
Validation loss: 2.0478269976954304

Epoch: 6| Step: 12
Training loss: 0.9210309386253357
Validation loss: 2.0423602301587342

Epoch: 6| Step: 13
Training loss: 0.6829437017440796
Validation loss: 2.0074789998351887

Epoch: 228| Step: 0
Training loss: 1.3815176486968994
Validation loss: 1.9825164374484812

Epoch: 6| Step: 1
Training loss: 1.218348741531372
Validation loss: 1.982313427873837

Epoch: 6| Step: 2
Training loss: 0.5136395692825317
Validation loss: 1.9669895223391953

Epoch: 6| Step: 3
Training loss: 1.229377031326294
Validation loss: 1.9677287814437703

Epoch: 6| Step: 4
Training loss: 1.2779655456542969
Validation loss: 1.9880699675570253

Epoch: 6| Step: 5
Training loss: 1.4132168292999268
Validation loss: 1.976212514344082

Epoch: 6| Step: 6
Training loss: 1.0423699617385864
Validation loss: 1.983561595280965

Epoch: 6| Step: 7
Training loss: 0.9628401398658752
Validation loss: 1.9854627963035338

Epoch: 6| Step: 8
Training loss: 1.265903353691101
Validation loss: 1.971080385228639

Epoch: 6| Step: 9
Training loss: 0.8053169250488281
Validation loss: 2.001776049214025

Epoch: 6| Step: 10
Training loss: 0.7244691848754883
Validation loss: 2.0069926707975325

Epoch: 6| Step: 11
Training loss: 1.0666790008544922
Validation loss: 2.024780737456455

Epoch: 6| Step: 12
Training loss: 2.0031049251556396
Validation loss: 2.018421705051135

Epoch: 6| Step: 13
Training loss: 0.7381194233894348
Validation loss: 2.0356819373305126

Epoch: 229| Step: 0
Training loss: 1.0722675323486328
Validation loss: 2.043498028991043

Epoch: 6| Step: 1
Training loss: 1.1126443147659302
Validation loss: 2.093068434346107

Epoch: 6| Step: 2
Training loss: 0.486830472946167
Validation loss: 2.0898335364557084

Epoch: 6| Step: 3
Training loss: 1.1097142696380615
Validation loss: 2.104419746706563

Epoch: 6| Step: 4
Training loss: 1.2045834064483643
Validation loss: 2.1102979349833664

Epoch: 6| Step: 5
Training loss: 1.6418057680130005
Validation loss: 2.0722489074994157

Epoch: 6| Step: 6
Training loss: 1.213793396949768
Validation loss: 2.050131255580533

Epoch: 6| Step: 7
Training loss: 0.8987218141555786
Validation loss: 2.018508921387375

Epoch: 6| Step: 8
Training loss: 1.920541524887085
Validation loss: 2.0103350326579106

Epoch: 6| Step: 9
Training loss: 0.7278974056243896
Validation loss: 1.99352184162345

Epoch: 6| Step: 10
Training loss: 1.003495693206787
Validation loss: 1.991851149066802

Epoch: 6| Step: 11
Training loss: 1.2148785591125488
Validation loss: 1.9828148131729455

Epoch: 6| Step: 12
Training loss: 1.3431729078292847
Validation loss: 1.9736179985025877

Epoch: 6| Step: 13
Training loss: 0.9131760001182556
Validation loss: 1.9487243583125453

Epoch: 230| Step: 0
Training loss: 1.0158121585845947
Validation loss: 1.9478750498064104

Epoch: 6| Step: 1
Training loss: 0.7888379693031311
Validation loss: 1.9532955820842455

Epoch: 6| Step: 2
Training loss: 0.9710826277732849
Validation loss: 1.9391993220134447

Epoch: 6| Step: 3
Training loss: 1.096886396408081
Validation loss: 1.9518914504717755

Epoch: 6| Step: 4
Training loss: 1.1677700281143188
Validation loss: 1.9432768719170683

Epoch: 6| Step: 5
Training loss: 0.5292125344276428
Validation loss: 1.9708956185207571

Epoch: 6| Step: 6
Training loss: 1.2225267887115479
Validation loss: 1.9640964167092436

Epoch: 6| Step: 7
Training loss: 0.7984577417373657
Validation loss: 1.9584267190707627

Epoch: 6| Step: 8
Training loss: 1.0385063886642456
Validation loss: 1.9650517074010705

Epoch: 6| Step: 9
Training loss: 1.4591509103775024
Validation loss: 1.9839834987476308

Epoch: 6| Step: 10
Training loss: 1.0183823108673096
Validation loss: 1.9696497840266074

Epoch: 6| Step: 11
Training loss: 1.4119642972946167
Validation loss: 1.9989276111766856

Epoch: 6| Step: 12
Training loss: 1.4041070938110352
Validation loss: 2.0017217871963338

Epoch: 6| Step: 13
Training loss: 1.627355933189392
Validation loss: 1.9960217860437208

Epoch: 231| Step: 0
Training loss: 0.5133603811264038
Validation loss: 2.0395534653817453

Epoch: 6| Step: 1
Training loss: 1.221954345703125
Validation loss: 2.095007755423105

Epoch: 6| Step: 2
Training loss: 1.1290732622146606
Validation loss: 2.1116075849020355

Epoch: 6| Step: 3
Training loss: 1.453075885772705
Validation loss: 2.078163372573032

Epoch: 6| Step: 4
Training loss: 1.343593955039978
Validation loss: 2.075857377821399

Epoch: 6| Step: 5
Training loss: 1.1436591148376465
Validation loss: 2.0046189190239034

Epoch: 6| Step: 6
Training loss: 1.3575692176818848
Validation loss: 1.996773660823863

Epoch: 6| Step: 7
Training loss: 1.2022104263305664
Validation loss: 1.9934238310783141

Epoch: 6| Step: 8
Training loss: 1.3388590812683105
Validation loss: 2.009749347163785

Epoch: 6| Step: 9
Training loss: 1.5813353061676025
Validation loss: 2.0008327268785044

Epoch: 6| Step: 10
Training loss: 0.6201801300048828
Validation loss: 1.9797282065114667

Epoch: 6| Step: 11
Training loss: 0.9901533126831055
Validation loss: 2.0026218070778796

Epoch: 6| Step: 12
Training loss: 0.9670313596725464
Validation loss: 2.015894769340433

Epoch: 6| Step: 13
Training loss: 1.0769867897033691
Validation loss: 2.032880107561747

Epoch: 232| Step: 0
Training loss: 0.9410779476165771
Validation loss: 2.053728683020479

Epoch: 6| Step: 1
Training loss: 0.9754058122634888
Validation loss: 2.071518889037512

Epoch: 6| Step: 2
Training loss: 0.8836016654968262
Validation loss: 2.023880861138785

Epoch: 6| Step: 3
Training loss: 0.8100624084472656
Validation loss: 1.9760510101113269

Epoch: 6| Step: 4
Training loss: 0.9606891870498657
Validation loss: 1.986491527608646

Epoch: 6| Step: 5
Training loss: 0.9864605665206909
Validation loss: 1.988766526663175

Epoch: 6| Step: 6
Training loss: 1.4595861434936523
Validation loss: 1.971801934703704

Epoch: 6| Step: 7
Training loss: 1.2022696733474731
Validation loss: 2.00328988926385

Epoch: 6| Step: 8
Training loss: 0.7410479187965393
Validation loss: 1.9884718489903275

Epoch: 6| Step: 9
Training loss: 1.286892294883728
Validation loss: 1.9884836481463524

Epoch: 6| Step: 10
Training loss: 1.6970322132110596
Validation loss: 1.9958863399362052

Epoch: 6| Step: 11
Training loss: 0.8011170625686646
Validation loss: 1.9804580544912687

Epoch: 6| Step: 12
Training loss: 1.2789947986602783
Validation loss: 1.9949322772282425

Epoch: 6| Step: 13
Training loss: 1.9030838012695312
Validation loss: 1.9750246309464978

Epoch: 233| Step: 0
Training loss: 1.0098536014556885
Validation loss: 1.9844533166577738

Epoch: 6| Step: 1
Training loss: 1.1456072330474854
Validation loss: 1.9418120332943496

Epoch: 6| Step: 2
Training loss: 1.1826539039611816
Validation loss: 1.9551660809465634

Epoch: 6| Step: 3
Training loss: 1.5733563899993896
Validation loss: 1.9340460774719075

Epoch: 6| Step: 4
Training loss: 0.8628727197647095
Validation loss: 1.9233261987727175

Epoch: 6| Step: 5
Training loss: 1.2848989963531494
Validation loss: 1.9437882336237098

Epoch: 6| Step: 6
Training loss: 1.4122233390808105
Validation loss: 1.9493424251515379

Epoch: 6| Step: 7
Training loss: 1.0357434749603271
Validation loss: 1.9512558547399377

Epoch: 6| Step: 8
Training loss: 1.2146116495132446
Validation loss: 1.9669590791066487

Epoch: 6| Step: 9
Training loss: 0.7355242967605591
Validation loss: 1.9555015051236717

Epoch: 6| Step: 10
Training loss: 1.1295714378356934
Validation loss: 1.9626846903113908

Epoch: 6| Step: 11
Training loss: 0.5869861841201782
Validation loss: 1.9522523803095664

Epoch: 6| Step: 12
Training loss: 1.0539419651031494
Validation loss: 1.9508149649507256

Epoch: 6| Step: 13
Training loss: 0.528310239315033
Validation loss: 1.9496682613126692

Epoch: 234| Step: 0
Training loss: 1.5933271646499634
Validation loss: 1.9674571829457437

Epoch: 6| Step: 1
Training loss: 1.428847074508667
Validation loss: 1.9380945518452635

Epoch: 6| Step: 2
Training loss: 0.8773341178894043
Validation loss: 1.9592784143263293

Epoch: 6| Step: 3
Training loss: 1.1009629964828491
Validation loss: 1.973933869792569

Epoch: 6| Step: 4
Training loss: 1.1306588649749756
Validation loss: 1.9449585073737687

Epoch: 6| Step: 5
Training loss: 0.9723143577575684
Validation loss: 1.9554726013573267

Epoch: 6| Step: 6
Training loss: 1.6587073802947998
Validation loss: 1.9589320126400198

Epoch: 6| Step: 7
Training loss: 0.7500964403152466
Validation loss: 1.9402744821322861

Epoch: 6| Step: 8
Training loss: 0.6602212190628052
Validation loss: 1.960896489440754

Epoch: 6| Step: 9
Training loss: 1.0756198167800903
Validation loss: 1.9695320590849845

Epoch: 6| Step: 10
Training loss: 0.8137898445129395
Validation loss: 2.0236490259888353

Epoch: 6| Step: 11
Training loss: 0.5349703431129456
Validation loss: 2.0512358039937992

Epoch: 6| Step: 12
Training loss: 1.0767936706542969
Validation loss: 2.0650536193642566

Epoch: 6| Step: 13
Training loss: 1.2577874660491943
Validation loss: 2.0489013477038314

Epoch: 235| Step: 0
Training loss: 1.3026480674743652
Validation loss: 1.9931955209342382

Epoch: 6| Step: 1
Training loss: 0.8804948329925537
Validation loss: 1.9907821480945875

Epoch: 6| Step: 2
Training loss: 0.911514401435852
Validation loss: 1.9893055205704064

Epoch: 6| Step: 3
Training loss: 1.5408401489257812
Validation loss: 1.999140562549714

Epoch: 6| Step: 4
Training loss: 1.2072534561157227
Validation loss: 1.9660481483705583

Epoch: 6| Step: 5
Training loss: 0.6583947539329529
Validation loss: 1.951994292197689

Epoch: 6| Step: 6
Training loss: 0.7831742763519287
Validation loss: 1.9928759169834915

Epoch: 6| Step: 7
Training loss: 1.07358717918396
Validation loss: 2.0511959547637613

Epoch: 6| Step: 8
Training loss: 1.1306884288787842
Validation loss: 2.1232436498006186

Epoch: 6| Step: 9
Training loss: 0.9230502843856812
Validation loss: 2.1067463992744364

Epoch: 6| Step: 10
Training loss: 1.05655837059021
Validation loss: 2.120992688722508

Epoch: 6| Step: 11
Training loss: 0.9462761878967285
Validation loss: 2.01961213286205

Epoch: 6| Step: 12
Training loss: 1.6659424304962158
Validation loss: 1.9796663202265257

Epoch: 6| Step: 13
Training loss: 1.234348177909851
Validation loss: 1.9762157778586111

Epoch: 236| Step: 0
Training loss: 1.290026068687439
Validation loss: 1.9280886547539824

Epoch: 6| Step: 1
Training loss: 1.0075042247772217
Validation loss: 1.9617929086890271

Epoch: 6| Step: 2
Training loss: 1.1410601139068604
Validation loss: 1.9250532606596589

Epoch: 6| Step: 3
Training loss: 0.9086568355560303
Validation loss: 1.94017497698466

Epoch: 6| Step: 4
Training loss: 0.7092929482460022
Validation loss: 1.9182491507581485

Epoch: 6| Step: 5
Training loss: 0.9766344428062439
Validation loss: 1.923553378351273

Epoch: 6| Step: 6
Training loss: 1.4714751243591309
Validation loss: 1.957793866434405

Epoch: 6| Step: 7
Training loss: 0.9335812926292419
Validation loss: 2.0038789933727634

Epoch: 6| Step: 8
Training loss: 1.044909954071045
Validation loss: 2.0500502445364512

Epoch: 6| Step: 9
Training loss: 1.2946014404296875
Validation loss: 2.08573313425946

Epoch: 6| Step: 10
Training loss: 1.4423962831497192
Validation loss: 2.054068816605435

Epoch: 6| Step: 11
Training loss: 1.3102145195007324
Validation loss: 2.0168140536995343

Epoch: 6| Step: 12
Training loss: 0.969933807849884
Validation loss: 2.001307531069684

Epoch: 6| Step: 13
Training loss: 0.8466377258300781
Validation loss: 2.0127177623010453

Epoch: 237| Step: 0
Training loss: 1.4735743999481201
Validation loss: 2.0362887267143495

Epoch: 6| Step: 1
Training loss: 1.0413005352020264
Validation loss: 2.04608755470604

Epoch: 6| Step: 2
Training loss: 0.8159674406051636
Validation loss: 2.061311460310413

Epoch: 6| Step: 3
Training loss: 0.9919286370277405
Validation loss: 2.066354295258881

Epoch: 6| Step: 4
Training loss: 0.9242543578147888
Validation loss: 2.0256539570387972

Epoch: 6| Step: 5
Training loss: 1.2064485549926758
Validation loss: 2.0239645511873308

Epoch: 6| Step: 6
Training loss: 0.9327242374420166
Validation loss: 2.001099367295542

Epoch: 6| Step: 7
Training loss: 0.8701833486557007
Validation loss: 2.0106380780537925

Epoch: 6| Step: 8
Training loss: 1.0971567630767822
Validation loss: 2.029726794970933

Epoch: 6| Step: 9
Training loss: 1.515684962272644
Validation loss: 2.0199557350527857

Epoch: 6| Step: 10
Training loss: 0.7681460380554199
Validation loss: 1.9654473937967771

Epoch: 6| Step: 11
Training loss: 0.894372820854187
Validation loss: 1.9650482951953847

Epoch: 6| Step: 12
Training loss: 1.0400651693344116
Validation loss: 1.9677319629217989

Epoch: 6| Step: 13
Training loss: 1.543217420578003
Validation loss: 1.9576284334223757

Epoch: 238| Step: 0
Training loss: 1.0580313205718994
Validation loss: 1.9641312117217689

Epoch: 6| Step: 1
Training loss: 0.9178260564804077
Validation loss: 1.9687165137260192

Epoch: 6| Step: 2
Training loss: 0.9574415683746338
Validation loss: 1.9771715184693694

Epoch: 6| Step: 3
Training loss: 1.1378827095031738
Validation loss: 1.9830541021080428

Epoch: 6| Step: 4
Training loss: 1.1935282945632935
Validation loss: 1.9957108830892911

Epoch: 6| Step: 5
Training loss: 1.4195258617401123
Validation loss: 1.9948102735703992

Epoch: 6| Step: 6
Training loss: 1.3858563899993896
Validation loss: 1.9926671674174647

Epoch: 6| Step: 7
Training loss: 1.2375739812850952
Validation loss: 1.991546159149498

Epoch: 6| Step: 8
Training loss: 0.7959544658660889
Validation loss: 1.963652903033841

Epoch: 6| Step: 9
Training loss: 1.0851659774780273
Validation loss: 1.9669272579172605

Epoch: 6| Step: 10
Training loss: 0.7841642498970032
Validation loss: 1.9445545045278405

Epoch: 6| Step: 11
Training loss: 0.561206042766571
Validation loss: 1.9492611244160643

Epoch: 6| Step: 12
Training loss: 1.0216457843780518
Validation loss: 1.9404974624674807

Epoch: 6| Step: 13
Training loss: 0.8983383178710938
Validation loss: 1.9434804134471442

Epoch: 239| Step: 0
Training loss: 0.8620779514312744
Validation loss: 1.9836428383345246

Epoch: 6| Step: 1
Training loss: 1.7215533256530762
Validation loss: 2.001276666118253

Epoch: 6| Step: 2
Training loss: 1.128821849822998
Validation loss: 2.0314391300242436

Epoch: 6| Step: 3
Training loss: 0.7020636796951294
Validation loss: 1.9999032866570257

Epoch: 6| Step: 4
Training loss: 0.9925144910812378
Validation loss: 2.0114680067185433

Epoch: 6| Step: 5
Training loss: 1.2290918827056885
Validation loss: 1.983259641995994

Epoch: 6| Step: 6
Training loss: 1.151626467704773
Validation loss: 1.9653494896427277

Epoch: 6| Step: 7
Training loss: 0.4387773275375366
Validation loss: 1.996924070260858

Epoch: 6| Step: 8
Training loss: 0.9783614277839661
Validation loss: 1.9772862465150896

Epoch: 6| Step: 9
Training loss: 1.1329410076141357
Validation loss: 1.9574397866443922

Epoch: 6| Step: 10
Training loss: 0.5987992882728577
Validation loss: 2.0202243789549796

Epoch: 6| Step: 11
Training loss: 1.0541470050811768
Validation loss: 2.0606596777516026

Epoch: 6| Step: 12
Training loss: 1.3130927085876465
Validation loss: 2.113485227348984

Epoch: 6| Step: 13
Training loss: 1.1104360818862915
Validation loss: 2.091419909590034

Epoch: 240| Step: 0
Training loss: 1.3475232124328613
Validation loss: 2.1064673111002934

Epoch: 6| Step: 1
Training loss: 0.9271934032440186
Validation loss: 2.0695626005049674

Epoch: 6| Step: 2
Training loss: 0.5618183016777039
Validation loss: 2.031552417303926

Epoch: 6| Step: 3
Training loss: 0.9802564978599548
Validation loss: 1.976648961344073

Epoch: 6| Step: 4
Training loss: 1.0435755252838135
Validation loss: 1.9582320374827231

Epoch: 6| Step: 5
Training loss: 0.9816951751708984
Validation loss: 1.9899708494063346

Epoch: 6| Step: 6
Training loss: 1.2051788568496704
Validation loss: 1.9993662475257792

Epoch: 6| Step: 7
Training loss: 0.9347493648529053
Validation loss: 2.0041986229599162

Epoch: 6| Step: 8
Training loss: 1.0174223184585571
Validation loss: 2.004852156485281

Epoch: 6| Step: 9
Training loss: 1.0530900955200195
Validation loss: 2.019067073381075

Epoch: 6| Step: 10
Training loss: 0.9189179539680481
Validation loss: 1.9928419064450007

Epoch: 6| Step: 11
Training loss: 1.161306381225586
Validation loss: 1.981537385653424

Epoch: 6| Step: 12
Training loss: 1.0373458862304688
Validation loss: 2.0037680543879026

Epoch: 6| Step: 13
Training loss: 1.4014647006988525
Validation loss: 2.0449108423725253

Epoch: 241| Step: 0
Training loss: 0.9122802019119263
Validation loss: 2.0252588154167257

Epoch: 6| Step: 1
Training loss: 0.9981391429901123
Validation loss: 2.019853538082492

Epoch: 6| Step: 2
Training loss: 0.9497590065002441
Validation loss: 1.9672337373097737

Epoch: 6| Step: 3
Training loss: 0.9026793241500854
Validation loss: 1.9514330548624839

Epoch: 6| Step: 4
Training loss: 1.1428422927856445
Validation loss: 1.944279319496565

Epoch: 6| Step: 5
Training loss: 1.1416993141174316
Validation loss: 1.9316345876263035

Epoch: 6| Step: 6
Training loss: 1.2872816324234009
Validation loss: 1.9478695982245988

Epoch: 6| Step: 7
Training loss: 0.884955108165741
Validation loss: 1.9276821536402549

Epoch: 6| Step: 8
Training loss: 0.7528126835823059
Validation loss: 1.9217576403771677

Epoch: 6| Step: 9
Training loss: 1.1516218185424805
Validation loss: 1.9206998245690459

Epoch: 6| Step: 10
Training loss: 0.8101822733879089
Validation loss: 1.923243986662998

Epoch: 6| Step: 11
Training loss: 0.8960248827934265
Validation loss: 1.9108329473003265

Epoch: 6| Step: 12
Training loss: 0.9805097579956055
Validation loss: 1.951774961204939

Epoch: 6| Step: 13
Training loss: 0.9852790832519531
Validation loss: 1.9804637303916357

Epoch: 242| Step: 0
Training loss: 1.1562035083770752
Validation loss: 1.9640336369955411

Epoch: 6| Step: 1
Training loss: 1.1093729734420776
Validation loss: 1.9414084790855326

Epoch: 6| Step: 2
Training loss: 0.6236220598220825
Validation loss: 1.9635943212816793

Epoch: 6| Step: 3
Training loss: 1.0044755935668945
Validation loss: 1.9353781925734652

Epoch: 6| Step: 4
Training loss: 0.9007692933082581
Validation loss: 1.940290822777697

Epoch: 6| Step: 5
Training loss: 1.0193212032318115
Validation loss: 1.9444110701161046

Epoch: 6| Step: 6
Training loss: 1.3361718654632568
Validation loss: 1.9433473784436461

Epoch: 6| Step: 7
Training loss: 1.2680630683898926
Validation loss: 1.9125435095961376

Epoch: 6| Step: 8
Training loss: 0.9377394914627075
Validation loss: 1.9021151629827355

Epoch: 6| Step: 9
Training loss: 0.9452265501022339
Validation loss: 1.9256196432216193

Epoch: 6| Step: 10
Training loss: 0.7204426527023315
Validation loss: 1.9095368795497443

Epoch: 6| Step: 11
Training loss: 0.745231032371521
Validation loss: 1.9306794853620632

Epoch: 6| Step: 12
Training loss: 1.0923874378204346
Validation loss: 1.9233230249856108

Epoch: 6| Step: 13
Training loss: 0.6245076656341553
Validation loss: 1.9280139759022703

Epoch: 243| Step: 0
Training loss: 1.0296485424041748
Validation loss: 1.9183847981114541

Epoch: 6| Step: 1
Training loss: 0.7521691918373108
Validation loss: 1.8826031095238143

Epoch: 6| Step: 2
Training loss: 0.7939146757125854
Validation loss: 1.8893052019098753

Epoch: 6| Step: 3
Training loss: 1.0841081142425537
Validation loss: 1.8930660729767175

Epoch: 6| Step: 4
Training loss: 1.176711082458496
Validation loss: 1.9135637206415976

Epoch: 6| Step: 5
Training loss: 0.9493182897567749
Validation loss: 1.9188589895925214

Epoch: 6| Step: 6
Training loss: 0.5097435116767883
Validation loss: 1.9435069535368232

Epoch: 6| Step: 7
Training loss: 1.0889233350753784
Validation loss: 1.971859473054127

Epoch: 6| Step: 8
Training loss: 1.1516062021255493
Validation loss: 1.9867566849595757

Epoch: 6| Step: 9
Training loss: 1.1433830261230469
Validation loss: 1.9805149006587204

Epoch: 6| Step: 10
Training loss: 1.019995927810669
Validation loss: 1.9670044452913347

Epoch: 6| Step: 11
Training loss: 0.8826071619987488
Validation loss: 1.9954364658683859

Epoch: 6| Step: 12
Training loss: 0.8149387836456299
Validation loss: 2.0020315890671103

Epoch: 6| Step: 13
Training loss: 0.9475759863853455
Validation loss: 1.9656520107740998

Epoch: 244| Step: 0
Training loss: 0.710334300994873
Validation loss: 1.951823393503825

Epoch: 6| Step: 1
Training loss: 0.728583812713623
Validation loss: 1.9261498553778535

Epoch: 6| Step: 2
Training loss: 0.3759921193122864
Validation loss: 1.9977173971873459

Epoch: 6| Step: 3
Training loss: 1.2884020805358887
Validation loss: 2.0078352779470463

Epoch: 6| Step: 4
Training loss: 1.2201967239379883
Validation loss: 2.0082639571159118

Epoch: 6| Step: 5
Training loss: 1.3804144859313965
Validation loss: 1.9879156492089713

Epoch: 6| Step: 6
Training loss: 0.941504716873169
Validation loss: 1.9131930387148293

Epoch: 6| Step: 7
Training loss: 1.082585334777832
Validation loss: 1.8990301573148338

Epoch: 6| Step: 8
Training loss: 1.125569224357605
Validation loss: 1.907560149828593

Epoch: 6| Step: 9
Training loss: 0.7045820951461792
Validation loss: 1.9251505610763386

Epoch: 6| Step: 10
Training loss: 1.3992853164672852
Validation loss: 1.907441198184926

Epoch: 6| Step: 11
Training loss: 1.2458176612854004
Validation loss: 1.917304620947889

Epoch: 6| Step: 12
Training loss: 0.9117730855941772
Validation loss: 1.8976212611762426

Epoch: 6| Step: 13
Training loss: 0.8321825265884399
Validation loss: 1.8767172918524793

Epoch: 245| Step: 0
Training loss: 0.5043472051620483
Validation loss: 1.868164740582948

Epoch: 6| Step: 1
Training loss: 0.8959665298461914
Validation loss: 1.9548211661718224

Epoch: 6| Step: 2
Training loss: 1.1071134805679321
Validation loss: 1.972964785432303

Epoch: 6| Step: 3
Training loss: 0.860553503036499
Validation loss: 1.9792925183491041

Epoch: 6| Step: 4
Training loss: 1.0482741594314575
Validation loss: 2.0085564326214533

Epoch: 6| Step: 5
Training loss: 1.1815162897109985
Validation loss: 1.9770904100069435

Epoch: 6| Step: 6
Training loss: 0.6420716643333435
Validation loss: 1.9412282820670836

Epoch: 6| Step: 7
Training loss: 1.0722829103469849
Validation loss: 1.9272387771196262

Epoch: 6| Step: 8
Training loss: 0.9867363572120667
Validation loss: 1.9628376832572363

Epoch: 6| Step: 9
Training loss: 1.1304826736450195
Validation loss: 1.9587126662654262

Epoch: 6| Step: 10
Training loss: 1.0938258171081543
Validation loss: 1.9570798297082224

Epoch: 6| Step: 11
Training loss: 0.5697945356369019
Validation loss: 1.9642552432193552

Epoch: 6| Step: 12
Training loss: 1.4976632595062256
Validation loss: 1.9573535412870429

Epoch: 6| Step: 13
Training loss: 0.9021390080451965
Validation loss: 1.986838145922589

Epoch: 246| Step: 0
Training loss: 0.9065123200416565
Validation loss: 1.9516046585575226

Epoch: 6| Step: 1
Training loss: 0.6963041424751282
Validation loss: 1.9461009886956984

Epoch: 6| Step: 2
Training loss: 0.905064046382904
Validation loss: 1.9435400065555368

Epoch: 6| Step: 3
Training loss: 0.9258212447166443
Validation loss: 1.960799910688913

Epoch: 6| Step: 4
Training loss: 0.9512044191360474
Validation loss: 1.9432786331381848

Epoch: 6| Step: 5
Training loss: 0.9310462474822998
Validation loss: 1.9334436167952835

Epoch: 6| Step: 6
Training loss: 0.8535559773445129
Validation loss: 1.9192534749225905

Epoch: 6| Step: 7
Training loss: 1.354696273803711
Validation loss: 1.9253757743425266

Epoch: 6| Step: 8
Training loss: 0.635631799697876
Validation loss: 1.9162231901640534

Epoch: 6| Step: 9
Training loss: 1.0717543363571167
Validation loss: 1.9222560262167325

Epoch: 6| Step: 10
Training loss: 1.225874423980713
Validation loss: 1.914365606923257

Epoch: 6| Step: 11
Training loss: 1.182804822921753
Validation loss: 1.9011103465992918

Epoch: 6| Step: 12
Training loss: 0.8635650873184204
Validation loss: 1.9229118580459266

Epoch: 6| Step: 13
Training loss: 0.3267495632171631
Validation loss: 1.9200282507045294

Epoch: 247| Step: 0
Training loss: 0.8019596338272095
Validation loss: 1.9082032698456959

Epoch: 6| Step: 1
Training loss: 0.8500528335571289
Validation loss: 1.9158948467623802

Epoch: 6| Step: 2
Training loss: 0.7918649911880493
Validation loss: 1.9201169231886506

Epoch: 6| Step: 3
Training loss: 0.834241509437561
Validation loss: 1.9160044962360012

Epoch: 6| Step: 4
Training loss: 0.749889612197876
Validation loss: 1.9111175203836093

Epoch: 6| Step: 5
Training loss: 0.3850020170211792
Validation loss: 1.9244329057713991

Epoch: 6| Step: 6
Training loss: 0.915201723575592
Validation loss: 1.9309847495889152

Epoch: 6| Step: 7
Training loss: 1.5327833890914917
Validation loss: 1.9256959038396035

Epoch: 6| Step: 8
Training loss: 1.1853898763656616
Validation loss: 1.9320107326712659

Epoch: 6| Step: 9
Training loss: 0.7277013063430786
Validation loss: 1.9279852297998243

Epoch: 6| Step: 10
Training loss: 1.0718224048614502
Validation loss: 1.9308389899551228

Epoch: 6| Step: 11
Training loss: 1.3632729053497314
Validation loss: 1.9692795302278252

Epoch: 6| Step: 12
Training loss: 0.9480211734771729
Validation loss: 1.9992363401638564

Epoch: 6| Step: 13
Training loss: 0.8735969662666321
Validation loss: 1.9909844424134941

Epoch: 248| Step: 0
Training loss: 0.8189817070960999
Validation loss: 1.9761668277043167

Epoch: 6| Step: 1
Training loss: 0.6742703914642334
Validation loss: 1.9595940036158408

Epoch: 6| Step: 2
Training loss: 0.6296873688697815
Validation loss: 1.9037935733795166

Epoch: 6| Step: 3
Training loss: 0.7359023094177246
Validation loss: 1.9071840804110292

Epoch: 6| Step: 4
Training loss: 0.6249901652336121
Validation loss: 1.9246482438938592

Epoch: 6| Step: 5
Training loss: 0.9731799364089966
Validation loss: 1.8958200241929741

Epoch: 6| Step: 6
Training loss: 1.3382412195205688
Validation loss: 1.9022773478620796

Epoch: 6| Step: 7
Training loss: 1.4552087783813477
Validation loss: 1.8953277654545282

Epoch: 6| Step: 8
Training loss: 0.945968508720398
Validation loss: 1.8834659566161454

Epoch: 6| Step: 9
Training loss: 1.2017457485198975
Validation loss: 1.8962324973075622

Epoch: 6| Step: 10
Training loss: 0.9925276041030884
Validation loss: 1.8585749492850354

Epoch: 6| Step: 11
Training loss: 0.7955946326255798
Validation loss: 1.8867429430766771

Epoch: 6| Step: 12
Training loss: 0.9368143081665039
Validation loss: 1.8963500120306527

Epoch: 6| Step: 13
Training loss: 0.7129742503166199
Validation loss: 1.896524574166985

Epoch: 249| Step: 0
Training loss: 0.6871736645698547
Validation loss: 1.9827561660479474

Epoch: 6| Step: 1
Training loss: 1.2972890138626099
Validation loss: 2.0163999629277054

Epoch: 6| Step: 2
Training loss: 0.9244985580444336
Validation loss: 2.0299915318847983

Epoch: 6| Step: 3
Training loss: 0.857923150062561
Validation loss: 2.021571061944449

Epoch: 6| Step: 4
Training loss: 1.1866322755813599
Validation loss: 2.0294884225373626

Epoch: 6| Step: 5
Training loss: 0.6052568554878235
Validation loss: 1.9662568825547413

Epoch: 6| Step: 6
Training loss: 0.6343133449554443
Validation loss: 1.9229613260556293

Epoch: 6| Step: 7
Training loss: 1.50748610496521
Validation loss: 1.9000948590617026

Epoch: 6| Step: 8
Training loss: 0.9527784585952759
Validation loss: 1.872965007699946

Epoch: 6| Step: 9
Training loss: 0.7376673221588135
Validation loss: 1.8957660070029638

Epoch: 6| Step: 10
Training loss: 0.7462297677993774
Validation loss: 1.864319093765751

Epoch: 6| Step: 11
Training loss: 0.946781575679779
Validation loss: 1.8436768080598565

Epoch: 6| Step: 12
Training loss: 1.274977684020996
Validation loss: 1.8099621329256284

Epoch: 6| Step: 13
Training loss: 1.0565129518508911
Validation loss: 1.8345943932892175

Epoch: 250| Step: 0
Training loss: 0.657578706741333
Validation loss: 1.8829643636621454

Epoch: 6| Step: 1
Training loss: 1.1360089778900146
Validation loss: 1.9424061249661189

Epoch: 6| Step: 2
Training loss: 0.8246934413909912
Validation loss: 1.9512933467024116

Epoch: 6| Step: 3
Training loss: 0.8661378622055054
Validation loss: 1.9745621450485722

Epoch: 6| Step: 4
Training loss: 0.8805434703826904
Validation loss: 1.9307488049230268

Epoch: 6| Step: 5
Training loss: 0.7984216213226318
Validation loss: 1.9157777114581036

Epoch: 6| Step: 6
Training loss: 0.7777213454246521
Validation loss: 1.9246830837700957

Epoch: 6| Step: 7
Training loss: 1.1573443412780762
Validation loss: 1.9612196107064523

Epoch: 6| Step: 8
Training loss: 0.7210668325424194
Validation loss: 1.9542879622469667

Epoch: 6| Step: 9
Training loss: 1.0808336734771729
Validation loss: 1.944582849420527

Epoch: 6| Step: 10
Training loss: 1.2791388034820557
Validation loss: 1.9470206563190748

Epoch: 6| Step: 11
Training loss: 0.9376057386398315
Validation loss: 1.9253779726643716

Epoch: 6| Step: 12
Training loss: 1.1099214553833008
Validation loss: 1.8946148400665612

Epoch: 6| Step: 13
Training loss: 0.8526836633682251
Validation loss: 1.959255072378343

Epoch: 251| Step: 0
Training loss: 1.3229906558990479
Validation loss: 1.9710461529352332

Epoch: 6| Step: 1
Training loss: 1.1431241035461426
Validation loss: 2.0002186580370833

Epoch: 6| Step: 2
Training loss: 0.7643328309059143
Validation loss: 1.9408045776428715

Epoch: 6| Step: 3
Training loss: 0.7653341293334961
Validation loss: 1.917717101753399

Epoch: 6| Step: 4
Training loss: 0.9350826144218445
Validation loss: 1.87449279908211

Epoch: 6| Step: 5
Training loss: 1.0494966506958008
Validation loss: 1.8742173000048565

Epoch: 6| Step: 6
Training loss: 0.833705723285675
Validation loss: 1.896227676381347

Epoch: 6| Step: 7
Training loss: 0.6684086918830872
Validation loss: 1.9216389630430488

Epoch: 6| Step: 8
Training loss: 1.3550472259521484
Validation loss: 1.9971243399445728

Epoch: 6| Step: 9
Training loss: 1.4515585899353027
Validation loss: 1.9874635819465882

Epoch: 6| Step: 10
Training loss: 1.0797278881072998
Validation loss: 1.9614963582766953

Epoch: 6| Step: 11
Training loss: 0.7376037836074829
Validation loss: 1.9649875548578077

Epoch: 6| Step: 12
Training loss: 0.7671231627464294
Validation loss: 1.9712142867426719

Epoch: 6| Step: 13
Training loss: 1.016224980354309
Validation loss: 2.0349995077297254

Epoch: 252| Step: 0
Training loss: 0.8368107080459595
Validation loss: 2.1069853254543838

Epoch: 6| Step: 1
Training loss: 1.3970550298690796
Validation loss: 2.1081903557623587

Epoch: 6| Step: 2
Training loss: 0.854214072227478
Validation loss: 2.0508179536429783

Epoch: 6| Step: 3
Training loss: 1.0320143699645996
Validation loss: 1.9635781344547067

Epoch: 6| Step: 4
Training loss: 1.40871262550354
Validation loss: 1.9186845543564006

Epoch: 6| Step: 5
Training loss: 0.8854203820228577
Validation loss: 1.8801998707555956

Epoch: 6| Step: 6
Training loss: 1.2243685722351074
Validation loss: 1.8972644395725702

Epoch: 6| Step: 7
Training loss: 1.0173431634902954
Validation loss: 1.9154831645309285

Epoch: 6| Step: 8
Training loss: 0.8040856122970581
Validation loss: 1.904000022078073

Epoch: 6| Step: 9
Training loss: 0.7795857191085815
Validation loss: 1.8935083817410212

Epoch: 6| Step: 10
Training loss: 0.6767184734344482
Validation loss: 1.8821217988127021

Epoch: 6| Step: 11
Training loss: 0.725217878818512
Validation loss: 1.8828775421265633

Epoch: 6| Step: 12
Training loss: 1.0132654905319214
Validation loss: 1.9004827596807992

Epoch: 6| Step: 13
Training loss: 1.2069257497787476
Validation loss: 1.900461717318463

Epoch: 253| Step: 0
Training loss: 0.7964785099029541
Validation loss: 1.9185240883981027

Epoch: 6| Step: 1
Training loss: 1.0927256345748901
Validation loss: 1.9265177519090715

Epoch: 6| Step: 2
Training loss: 1.1076712608337402
Validation loss: 1.906921358518703

Epoch: 6| Step: 3
Training loss: 0.7545827627182007
Validation loss: 1.9212883185314875

Epoch: 6| Step: 4
Training loss: 0.5817621946334839
Validation loss: 1.9260751214078677

Epoch: 6| Step: 5
Training loss: 0.8354860544204712
Validation loss: 1.9469216049358409

Epoch: 6| Step: 6
Training loss: 0.6713268756866455
Validation loss: 1.9225415516925115

Epoch: 6| Step: 7
Training loss: 0.9512181282043457
Validation loss: 1.941957781391759

Epoch: 6| Step: 8
Training loss: 0.8171847462654114
Validation loss: 1.9772936938911356

Epoch: 6| Step: 9
Training loss: 1.0878314971923828
Validation loss: 1.977108665691909

Epoch: 6| Step: 10
Training loss: 0.8448833227157593
Validation loss: 1.9648384509548065

Epoch: 6| Step: 11
Training loss: 1.2759395837783813
Validation loss: 1.9805793339206326

Epoch: 6| Step: 12
Training loss: 0.9413645267486572
Validation loss: 1.9888195606970018

Epoch: 6| Step: 13
Training loss: 1.1570578813552856
Validation loss: 1.9610698761478547

Epoch: 254| Step: 0
Training loss: 1.009430170059204
Validation loss: 1.9134530149480349

Epoch: 6| Step: 1
Training loss: 1.0620782375335693
Validation loss: 1.9065999959104805

Epoch: 6| Step: 2
Training loss: 0.9271271228790283
Validation loss: 1.8917145908519786

Epoch: 6| Step: 3
Training loss: 0.8150371313095093
Validation loss: 1.8624191027815624

Epoch: 6| Step: 4
Training loss: 0.6096159219741821
Validation loss: 1.866088008367887

Epoch: 6| Step: 5
Training loss: 0.4628464877605438
Validation loss: 1.8611453733136576

Epoch: 6| Step: 6
Training loss: 1.1501295566558838
Validation loss: 1.8610495392994215

Epoch: 6| Step: 7
Training loss: 0.9255641102790833
Validation loss: 1.867373897183326

Epoch: 6| Step: 8
Training loss: 0.9946924448013306
Validation loss: 1.8616592550790438

Epoch: 6| Step: 9
Training loss: 0.7936439514160156
Validation loss: 1.8772988627033849

Epoch: 6| Step: 10
Training loss: 0.8530672788619995
Validation loss: 1.8948870217928322

Epoch: 6| Step: 11
Training loss: 1.1555349826812744
Validation loss: 1.8859690748235232

Epoch: 6| Step: 12
Training loss: 0.6315332651138306
Validation loss: 1.898326599469749

Epoch: 6| Step: 13
Training loss: 0.9799467921257019
Validation loss: 1.8996302286783855

Epoch: 255| Step: 0
Training loss: 0.6360515356063843
Validation loss: 1.9683969392571399

Epoch: 6| Step: 1
Training loss: 0.6097409725189209
Validation loss: 2.0367543235901864

Epoch: 6| Step: 2
Training loss: 1.2675403356552124
Validation loss: 2.055266211109777

Epoch: 6| Step: 3
Training loss: 1.5859980583190918
Validation loss: 1.9981667687816005

Epoch: 6| Step: 4
Training loss: 0.941826343536377
Validation loss: 1.936427168948676

Epoch: 6| Step: 5
Training loss: 0.8986300826072693
Validation loss: 1.912215022630589

Epoch: 6| Step: 6
Training loss: 0.8222348690032959
Validation loss: 1.9131556005888088

Epoch: 6| Step: 7
Training loss: 1.0967941284179688
Validation loss: 1.9304371495400705

Epoch: 6| Step: 8
Training loss: 1.1630182266235352
Validation loss: 1.9365062175258514

Epoch: 6| Step: 9
Training loss: 0.8249152898788452
Validation loss: 1.9316104086496497

Epoch: 6| Step: 10
Training loss: 0.6324207186698914
Validation loss: 1.881491704653668

Epoch: 6| Step: 11
Training loss: 0.9123838543891907
Validation loss: 1.9030055628027966

Epoch: 6| Step: 12
Training loss: 0.47264134883880615
Validation loss: 1.9405045701611427

Epoch: 6| Step: 13
Training loss: 1.749727725982666
Validation loss: 2.0059765654225505

Epoch: 256| Step: 0
Training loss: 1.2351231575012207
Validation loss: 2.0265565008245487

Epoch: 6| Step: 1
Training loss: 0.7669230699539185
Validation loss: 1.9764848780888382

Epoch: 6| Step: 2
Training loss: 0.8672307133674622
Validation loss: 1.9661221581120645

Epoch: 6| Step: 3
Training loss: 0.7724348306655884
Validation loss: 1.9269597658547022

Epoch: 6| Step: 4
Training loss: 0.8074002861976624
Validation loss: 1.9351454011855587

Epoch: 6| Step: 5
Training loss: 1.1852726936340332
Validation loss: 1.909804913305467

Epoch: 6| Step: 6
Training loss: 0.8938167095184326
Validation loss: 1.9328507325982536

Epoch: 6| Step: 7
Training loss: 0.6598565578460693
Validation loss: 1.9153996680372505

Epoch: 6| Step: 8
Training loss: 0.3456629514694214
Validation loss: 1.8930439872126426

Epoch: 6| Step: 9
Training loss: 0.7289900183677673
Validation loss: 1.8833418648730043

Epoch: 6| Step: 10
Training loss: 0.8879521489143372
Validation loss: 1.899372305921329

Epoch: 6| Step: 11
Training loss: 1.0586519241333008
Validation loss: 1.9380064472075431

Epoch: 6| Step: 12
Training loss: 1.213983178138733
Validation loss: 1.9097136476988434

Epoch: 6| Step: 13
Training loss: 0.5974623560905457
Validation loss: 1.9230628718612015

Epoch: 257| Step: 0
Training loss: 0.39826998114585876
Validation loss: 1.901325015611546

Epoch: 6| Step: 1
Training loss: 0.7131908535957336
Validation loss: 1.9152939960520754

Epoch: 6| Step: 2
Training loss: 1.2715801000595093
Validation loss: 1.9146069929163942

Epoch: 6| Step: 3
Training loss: 1.2674052715301514
Validation loss: 1.8795409702485608

Epoch: 6| Step: 4
Training loss: 1.1779563426971436
Validation loss: 1.9048278536847842

Epoch: 6| Step: 5
Training loss: 0.766257107257843
Validation loss: 1.9042420746177755

Epoch: 6| Step: 6
Training loss: 0.8096244931221008
Validation loss: 1.9065944981831375

Epoch: 6| Step: 7
Training loss: 0.7287800908088684
Validation loss: 1.9050204574420888

Epoch: 6| Step: 8
Training loss: 0.5478786826133728
Validation loss: 1.9138423601786296

Epoch: 6| Step: 9
Training loss: 0.8884115219116211
Validation loss: 1.9437832358062908

Epoch: 6| Step: 10
Training loss: 1.1730144023895264
Validation loss: 1.9540833055332143

Epoch: 6| Step: 11
Training loss: 0.4298681616783142
Validation loss: 1.9433558333304621

Epoch: 6| Step: 12
Training loss: 0.8980528712272644
Validation loss: 1.9532045600234822

Epoch: 6| Step: 13
Training loss: 0.7345077395439148
Validation loss: 1.948684823128485

Epoch: 258| Step: 0
Training loss: 0.822178065776825
Validation loss: 1.9326102182429323

Epoch: 6| Step: 1
Training loss: 1.0166711807250977
Validation loss: 1.924723825147075

Epoch: 6| Step: 2
Training loss: 1.0385524034500122
Validation loss: 1.9319972825306717

Epoch: 6| Step: 3
Training loss: 0.6645378470420837
Validation loss: 1.9266427691264818

Epoch: 6| Step: 4
Training loss: 0.6076953411102295
Validation loss: 1.8928528062758907

Epoch: 6| Step: 5
Training loss: 0.8742451071739197
Validation loss: 1.9344603733349872

Epoch: 6| Step: 6
Training loss: 0.81927490234375
Validation loss: 1.9174111414981145

Epoch: 6| Step: 7
Training loss: 0.6927573680877686
Validation loss: 1.898034022700402

Epoch: 6| Step: 8
Training loss: 0.9182376861572266
Validation loss: 1.8754411525623773

Epoch: 6| Step: 9
Training loss: 0.5654392838478088
Validation loss: 1.8846583494576075

Epoch: 6| Step: 10
Training loss: 1.0428097248077393
Validation loss: 1.8684583287085257

Epoch: 6| Step: 11
Training loss: 1.3176610469818115
Validation loss: 1.8806247147180701

Epoch: 6| Step: 12
Training loss: 0.732964038848877
Validation loss: 1.8932633630691036

Epoch: 6| Step: 13
Training loss: 0.6195788979530334
Validation loss: 1.8925692855670888

Epoch: 259| Step: 0
Training loss: 1.0464584827423096
Validation loss: 1.9299376446713683

Epoch: 6| Step: 1
Training loss: 0.8678187131881714
Validation loss: 1.9129504593469764

Epoch: 6| Step: 2
Training loss: 0.7443490624427795
Validation loss: 1.919821367468885

Epoch: 6| Step: 3
Training loss: 1.648573398590088
Validation loss: 1.8699028133064188

Epoch: 6| Step: 4
Training loss: 0.7054794430732727
Validation loss: 1.9040055467236427

Epoch: 6| Step: 5
Training loss: 0.4687483608722687
Validation loss: 1.8791553551150906

Epoch: 6| Step: 6
Training loss: 0.613162636756897
Validation loss: 1.8895564592012795

Epoch: 6| Step: 7
Training loss: 0.9800407886505127
Validation loss: 1.9059471084225563

Epoch: 6| Step: 8
Training loss: 1.0909202098846436
Validation loss: 1.8771949250210997

Epoch: 6| Step: 9
Training loss: 0.7485916614532471
Validation loss: 1.860543761202084

Epoch: 6| Step: 10
Training loss: 0.7621565461158752
Validation loss: 1.8694580908744567

Epoch: 6| Step: 11
Training loss: 0.6937412023544312
Validation loss: 1.9221124187592538

Epoch: 6| Step: 12
Training loss: 0.9424628019332886
Validation loss: 1.9492800274202902

Epoch: 6| Step: 13
Training loss: 0.6421461701393127
Validation loss: 1.941292465374034

Epoch: 260| Step: 0
Training loss: 0.8954077959060669
Validation loss: 1.9652294843427596

Epoch: 6| Step: 1
Training loss: 0.5673329830169678
Validation loss: 1.938036818658152

Epoch: 6| Step: 2
Training loss: 0.8508038520812988
Validation loss: 1.9086233851730183

Epoch: 6| Step: 3
Training loss: 1.2339166402816772
Validation loss: 1.8712111826865905

Epoch: 6| Step: 4
Training loss: 0.8868439793586731
Validation loss: 1.8733187490893948

Epoch: 6| Step: 5
Training loss: 1.0755558013916016
Validation loss: 1.8635373487267444

Epoch: 6| Step: 6
Training loss: 0.6048367023468018
Validation loss: 1.8725180574642715

Epoch: 6| Step: 7
Training loss: 0.756670355796814
Validation loss: 1.8628165760347921

Epoch: 6| Step: 8
Training loss: 0.8210875988006592
Validation loss: 1.8548943099155222

Epoch: 6| Step: 9
Training loss: 0.6885549426078796
Validation loss: 1.8775811144100722

Epoch: 6| Step: 10
Training loss: 0.7815381288528442
Validation loss: 1.8783820098446262

Epoch: 6| Step: 11
Training loss: 0.5657672882080078
Validation loss: 1.905057499485631

Epoch: 6| Step: 12
Training loss: 1.1537069082260132
Validation loss: 1.9125905934200491

Epoch: 6| Step: 13
Training loss: 0.897528350353241
Validation loss: 1.9246799433103172

Epoch: 261| Step: 0
Training loss: 1.1232149600982666
Validation loss: 1.9270271639670096

Epoch: 6| Step: 1
Training loss: 0.7221176624298096
Validation loss: 1.9369670626937703

Epoch: 6| Step: 2
Training loss: 0.6479641199111938
Validation loss: 1.9555206298828125

Epoch: 6| Step: 3
Training loss: 1.09908127784729
Validation loss: 1.968631326511342

Epoch: 6| Step: 4
Training loss: 0.7261193990707397
Validation loss: 1.9673648521464357

Epoch: 6| Step: 5
Training loss: 0.6892980337142944
Validation loss: 1.9354569437683269

Epoch: 6| Step: 6
Training loss: 1.017348051071167
Validation loss: 1.9314087257590344

Epoch: 6| Step: 7
Training loss: 1.0454410314559937
Validation loss: 1.920500486127792

Epoch: 6| Step: 8
Training loss: 0.49122050404548645
Validation loss: 1.9075301949695875

Epoch: 6| Step: 9
Training loss: 0.60031658411026
Validation loss: 1.8997708648763678

Epoch: 6| Step: 10
Training loss: 0.7205365300178528
Validation loss: 1.8520630405795189

Epoch: 6| Step: 11
Training loss: 0.6429203748703003
Validation loss: 1.8527066297428583

Epoch: 6| Step: 12
Training loss: 0.7087383270263672
Validation loss: 1.8233819315510411

Epoch: 6| Step: 13
Training loss: 1.2888797521591187
Validation loss: 1.8282168654985325

Epoch: 262| Step: 0
Training loss: 0.9144356846809387
Validation loss: 1.8369317003475722

Epoch: 6| Step: 1
Training loss: 0.9110078811645508
Validation loss: 1.8243196382317493

Epoch: 6| Step: 2
Training loss: 0.818855345249176
Validation loss: 1.8527844080360987

Epoch: 6| Step: 3
Training loss: 1.1142457723617554
Validation loss: 1.8535303261972242

Epoch: 6| Step: 4
Training loss: 0.8833798170089722
Validation loss: 1.8523534087724582

Epoch: 6| Step: 5
Training loss: 1.0339055061340332
Validation loss: 1.8436728831260436

Epoch: 6| Step: 6
Training loss: 1.1377956867218018
Validation loss: 1.8567071653181506

Epoch: 6| Step: 7
Training loss: 0.9081408977508545
Validation loss: 1.8266085911822576

Epoch: 6| Step: 8
Training loss: 0.5443087220191956
Validation loss: 1.8646238388553742

Epoch: 6| Step: 9
Training loss: 0.7293100357055664
Validation loss: 1.8805377457731514

Epoch: 6| Step: 10
Training loss: 0.6713086366653442
Validation loss: 1.8597724360804404

Epoch: 6| Step: 11
Training loss: 0.3942473232746124
Validation loss: 1.9097677328253304

Epoch: 6| Step: 12
Training loss: 0.662968635559082
Validation loss: 1.9272004455648444

Epoch: 6| Step: 13
Training loss: 0.9358590245246887
Validation loss: 1.9669246327492498

Epoch: 263| Step: 0
Training loss: 0.922616720199585
Validation loss: 1.974995259315737

Epoch: 6| Step: 1
Training loss: 0.45335978269577026
Validation loss: 1.9957072734832764

Epoch: 6| Step: 2
Training loss: 0.8783833980560303
Validation loss: 2.0019023021062217

Epoch: 6| Step: 3
Training loss: 0.8575409650802612
Validation loss: 1.969730443851922

Epoch: 6| Step: 4
Training loss: 0.8301200866699219
Validation loss: 1.962268461463272

Epoch: 6| Step: 5
Training loss: 0.8198262453079224
Validation loss: 1.9155064705879457

Epoch: 6| Step: 6
Training loss: 0.6296842098236084
Validation loss: 1.9031948017817673

Epoch: 6| Step: 7
Training loss: 0.5331265926361084
Validation loss: 1.8908952641230758

Epoch: 6| Step: 8
Training loss: 0.8893976211547852
Validation loss: 1.8705891050318235

Epoch: 6| Step: 9
Training loss: 0.7637882828712463
Validation loss: 1.8670316024493145

Epoch: 6| Step: 10
Training loss: 0.566304087638855
Validation loss: 1.8484752280737764

Epoch: 6| Step: 11
Training loss: 1.09446382522583
Validation loss: 1.8372955322265625

Epoch: 6| Step: 12
Training loss: 1.0983861684799194
Validation loss: 1.8405595876837288

Epoch: 6| Step: 13
Training loss: 0.7937652468681335
Validation loss: 1.8673683648468347

Epoch: 264| Step: 0
Training loss: 0.820693850517273
Validation loss: 1.8417400544689548

Epoch: 6| Step: 1
Training loss: 1.0242825746536255
Validation loss: 1.8530787729447888

Epoch: 6| Step: 2
Training loss: 0.5550709366798401
Validation loss: 1.8418408952733523

Epoch: 6| Step: 3
Training loss: 0.766746997833252
Validation loss: 1.8441588724813154

Epoch: 6| Step: 4
Training loss: 0.49925458431243896
Validation loss: 1.8553435674277685

Epoch: 6| Step: 5
Training loss: 0.89247065782547
Validation loss: 1.8259494932748939

Epoch: 6| Step: 6
Training loss: 0.7204917669296265
Validation loss: 1.8407500572102045

Epoch: 6| Step: 7
Training loss: 0.8705782890319824
Validation loss: 1.8398241099490915

Epoch: 6| Step: 8
Training loss: 0.7394897937774658
Validation loss: 1.8394507387632966

Epoch: 6| Step: 9
Training loss: 1.0312687158584595
Validation loss: 1.8186367057984876

Epoch: 6| Step: 10
Training loss: 0.7188699245452881
Validation loss: 1.8240833564471173

Epoch: 6| Step: 11
Training loss: 0.6532487869262695
Validation loss: 1.829232737582217

Epoch: 6| Step: 12
Training loss: 0.4447564482688904
Validation loss: 1.808898865535695

Epoch: 6| Step: 13
Training loss: 0.9280164241790771
Validation loss: 1.8478390273227487

Epoch: 265| Step: 0
Training loss: 0.26654714345932007
Validation loss: 1.8564506141088342

Epoch: 6| Step: 1
Training loss: 0.6315003633499146
Validation loss: 1.8618940550793883

Epoch: 6| Step: 2
Training loss: 0.6070069670677185
Validation loss: 1.8779328061688332

Epoch: 6| Step: 3
Training loss: 0.6522724628448486
Validation loss: 1.8666968602006153

Epoch: 6| Step: 4
Training loss: 0.7061824202537537
Validation loss: 1.8474136244866155

Epoch: 6| Step: 5
Training loss: 0.9542803168296814
Validation loss: 1.8418874894419024

Epoch: 6| Step: 6
Training loss: 1.0097076892852783
Validation loss: 1.8281791671629875

Epoch: 6| Step: 7
Training loss: 0.7026808261871338
Validation loss: 1.8203380492425734

Epoch: 6| Step: 8
Training loss: 0.5840927958488464
Validation loss: 1.8311432535930345

Epoch: 6| Step: 9
Training loss: 0.8790623545646667
Validation loss: 1.8124744225573797

Epoch: 6| Step: 10
Training loss: 0.8541365265846252
Validation loss: 1.8416306536684754

Epoch: 6| Step: 11
Training loss: 0.786536693572998
Validation loss: 1.8359344185039561

Epoch: 6| Step: 12
Training loss: 0.950593113899231
Validation loss: 1.8728606239441903

Epoch: 6| Step: 13
Training loss: 0.8308461308479309
Validation loss: 1.8597830700617966

Epoch: 266| Step: 0
Training loss: 0.9392327666282654
Validation loss: 1.874213675016998

Epoch: 6| Step: 1
Training loss: 1.0425242185592651
Validation loss: 1.8590849548257806

Epoch: 6| Step: 2
Training loss: 0.8596656322479248
Validation loss: 1.8259605207750875

Epoch: 6| Step: 3
Training loss: 0.6384059190750122
Validation loss: 1.847695445501676

Epoch: 6| Step: 4
Training loss: 0.6657044887542725
Validation loss: 1.8435530906082482

Epoch: 6| Step: 5
Training loss: 0.8937350511550903
Validation loss: 1.866029329197381

Epoch: 6| Step: 6
Training loss: 0.5538973808288574
Validation loss: 1.8390656055942658

Epoch: 6| Step: 7
Training loss: 0.5384532809257507
Validation loss: 1.853533237211166

Epoch: 6| Step: 8
Training loss: 0.7800251245498657
Validation loss: 1.8437574281487414

Epoch: 6| Step: 9
Training loss: 0.7277757525444031
Validation loss: 1.8721181500342585

Epoch: 6| Step: 10
Training loss: 0.785142183303833
Validation loss: 1.881186512208754

Epoch: 6| Step: 11
Training loss: 0.7083542346954346
Validation loss: 1.902894684063491

Epoch: 6| Step: 12
Training loss: 0.7139178514480591
Validation loss: 1.9443593807117914

Epoch: 6| Step: 13
Training loss: 0.25066080689430237
Validation loss: 1.9386443963614843

Epoch: 267| Step: 0
Training loss: 0.5253188610076904
Validation loss: 1.95771655472376

Epoch: 6| Step: 1
Training loss: 0.6784279346466064
Validation loss: 1.9212732238154258

Epoch: 6| Step: 2
Training loss: 1.0284724235534668
Validation loss: 1.9435544603614396

Epoch: 6| Step: 3
Training loss: 0.6969890594482422
Validation loss: 1.9147493467536023

Epoch: 6| Step: 4
Training loss: 0.43973737955093384
Validation loss: 1.8828975846690517

Epoch: 6| Step: 5
Training loss: 1.3792856931686401
Validation loss: 1.828847764640726

Epoch: 6| Step: 6
Training loss: 0.7164245843887329
Validation loss: 1.823449129699379

Epoch: 6| Step: 7
Training loss: 0.7315251231193542
Validation loss: 1.7943578279146584

Epoch: 6| Step: 8
Training loss: 0.4840841293334961
Validation loss: 1.843078661990422

Epoch: 6| Step: 9
Training loss: 1.493059515953064
Validation loss: 1.8460372519749466

Epoch: 6| Step: 10
Training loss: 0.5940543413162231
Validation loss: 1.8490061977858185

Epoch: 6| Step: 11
Training loss: 0.5794858932495117
Validation loss: 1.8424897424636348

Epoch: 6| Step: 12
Training loss: 0.7829574346542358
Validation loss: 1.8192725566125685

Epoch: 6| Step: 13
Training loss: 0.7440430521965027
Validation loss: 1.820977395580661

Epoch: 268| Step: 0
Training loss: 0.7907841205596924
Validation loss: 1.8461229544813915

Epoch: 6| Step: 1
Training loss: 0.692324161529541
Validation loss: 1.8672708849753104

Epoch: 6| Step: 2
Training loss: 0.8452569842338562
Validation loss: 1.87859768508583

Epoch: 6| Step: 3
Training loss: 0.7862136960029602
Validation loss: 1.881817643360425

Epoch: 6| Step: 4
Training loss: 0.9051215648651123
Validation loss: 1.8752094545672018

Epoch: 6| Step: 5
Training loss: 0.6675336360931396
Validation loss: 1.8574990431467693

Epoch: 6| Step: 6
Training loss: 0.5295584201812744
Validation loss: 1.8499580993447253

Epoch: 6| Step: 7
Training loss: 1.3549659252166748
Validation loss: 1.8792079751209547

Epoch: 6| Step: 8
Training loss: 0.848846435546875
Validation loss: 1.9545499342744068

Epoch: 6| Step: 9
Training loss: 0.7281819581985474
Validation loss: 1.9658209431555964

Epoch: 6| Step: 10
Training loss: 0.9546521902084351
Validation loss: 1.920364164536999

Epoch: 6| Step: 11
Training loss: 0.8203105926513672
Validation loss: 1.8930609790227746

Epoch: 6| Step: 12
Training loss: 0.2551095485687256
Validation loss: 1.8524886561978249

Epoch: 6| Step: 13
Training loss: 1.073549747467041
Validation loss: 1.8628060766445693

Epoch: 269| Step: 0
Training loss: 0.7987757325172424
Validation loss: 1.834815699567077

Epoch: 6| Step: 1
Training loss: 0.7800949811935425
Validation loss: 1.8215646705319803

Epoch: 6| Step: 2
Training loss: 1.0027694702148438
Validation loss: 1.8428714429178545

Epoch: 6| Step: 3
Training loss: 0.5122790932655334
Validation loss: 1.839672830797011

Epoch: 6| Step: 4
Training loss: 0.4596186876296997
Validation loss: 1.8397503129897579

Epoch: 6| Step: 5
Training loss: 0.4832420349121094
Validation loss: 1.8830562432607014

Epoch: 6| Step: 6
Training loss: 1.0797104835510254
Validation loss: 1.8814709378827004

Epoch: 6| Step: 7
Training loss: 0.6582467555999756
Validation loss: 1.903268321867912

Epoch: 6| Step: 8
Training loss: 0.6332294940948486
Validation loss: 1.8663194589717413

Epoch: 6| Step: 9
Training loss: 0.8706204891204834
Validation loss: 1.8958936147792365

Epoch: 6| Step: 10
Training loss: 1.0374574661254883
Validation loss: 1.8226430557107414

Epoch: 6| Step: 11
Training loss: 0.9345815181732178
Validation loss: 1.8083846415242841

Epoch: 6| Step: 12
Training loss: 0.5569719076156616
Validation loss: 1.8018421896042363

Epoch: 6| Step: 13
Training loss: 0.585902750492096
Validation loss: 1.8008003157954062

Epoch: 270| Step: 0
Training loss: 0.5725382566452026
Validation loss: 1.8127078446008826

Epoch: 6| Step: 1
Training loss: 0.709686279296875
Validation loss: 1.785172511172551

Epoch: 6| Step: 2
Training loss: 0.5155284404754639
Validation loss: 1.8061633302319435

Epoch: 6| Step: 3
Training loss: 0.866658091545105
Validation loss: 1.7945281767076062

Epoch: 6| Step: 4
Training loss: 0.41501298546791077
Validation loss: 1.8041660926675285

Epoch: 6| Step: 5
Training loss: 0.4754193425178528
Validation loss: 1.7974928040658273

Epoch: 6| Step: 6
Training loss: 0.6128161549568176
Validation loss: 1.7959626848979662

Epoch: 6| Step: 7
Training loss: 0.6391429901123047
Validation loss: 1.7994778463917394

Epoch: 6| Step: 8
Training loss: 0.7286807894706726
Validation loss: 1.7994573808485461

Epoch: 6| Step: 9
Training loss: 1.1967908143997192
Validation loss: 1.829160871044282

Epoch: 6| Step: 10
Training loss: 0.9606885313987732
Validation loss: 1.836346326335784

Epoch: 6| Step: 11
Training loss: 0.9355324506759644
Validation loss: 1.8467744242760442

Epoch: 6| Step: 12
Training loss: 0.9105393886566162
Validation loss: 1.8343193338763328

Epoch: 6| Step: 13
Training loss: 0.6632687449455261
Validation loss: 1.831020494943024

Epoch: 271| Step: 0
Training loss: 0.49795547127723694
Validation loss: 1.8026183984612907

Epoch: 6| Step: 1
Training loss: 0.7035505771636963
Validation loss: 1.8278348125437254

Epoch: 6| Step: 2
Training loss: 0.5252885818481445
Validation loss: 1.839338799958588

Epoch: 6| Step: 3
Training loss: 0.905857264995575
Validation loss: 1.860557561279625

Epoch: 6| Step: 4
Training loss: 1.0821173191070557
Validation loss: 1.8506102126131776

Epoch: 6| Step: 5
Training loss: 0.8451453447341919
Validation loss: 1.837979990948913

Epoch: 6| Step: 6
Training loss: 0.9066076278686523
Validation loss: 1.8282447566268265

Epoch: 6| Step: 7
Training loss: 0.7284376621246338
Validation loss: 1.8280699047991025

Epoch: 6| Step: 8
Training loss: 0.8256187438964844
Validation loss: 1.8497395515441895

Epoch: 6| Step: 9
Training loss: 0.8345258235931396
Validation loss: 1.835221343143012

Epoch: 6| Step: 10
Training loss: 0.5372785925865173
Validation loss: 1.8092510854044268

Epoch: 6| Step: 11
Training loss: 0.34669750928878784
Validation loss: 1.792321248721051

Epoch: 6| Step: 12
Training loss: 0.45046567916870117
Validation loss: 1.7956932565217376

Epoch: 6| Step: 13
Training loss: 0.22878572344779968
Validation loss: 1.8126427230014597

Epoch: 272| Step: 0
Training loss: 1.0264880657196045
Validation loss: 1.8146996113561815

Epoch: 6| Step: 1
Training loss: 0.5716879367828369
Validation loss: 1.8238455492963073

Epoch: 6| Step: 2
Training loss: 0.3727647364139557
Validation loss: 1.821635159113074

Epoch: 6| Step: 3
Training loss: 0.9830653667449951
Validation loss: 1.8164158969797113

Epoch: 6| Step: 4
Training loss: 0.6629621982574463
Validation loss: 1.8507390150459864

Epoch: 6| Step: 5
Training loss: 0.5761855244636536
Validation loss: 1.8559710556460964

Epoch: 6| Step: 6
Training loss: 0.6110823154449463
Validation loss: 1.9288353407254784

Epoch: 6| Step: 7
Training loss: 0.5453131198883057
Validation loss: 1.905400364629684

Epoch: 6| Step: 8
Training loss: 0.9321529865264893
Validation loss: 1.8631525334491525

Epoch: 6| Step: 9
Training loss: 1.1208510398864746
Validation loss: 1.8184820810953777

Epoch: 6| Step: 10
Training loss: 0.49590420722961426
Validation loss: 1.8081340520612654

Epoch: 6| Step: 11
Training loss: 0.6628179550170898
Validation loss: 1.8139643246127712

Epoch: 6| Step: 12
Training loss: 0.779302716255188
Validation loss: 1.8368279889065733

Epoch: 6| Step: 13
Training loss: 0.6967896223068237
Validation loss: 1.8560481738018733

Epoch: 273| Step: 0
Training loss: 0.7940634489059448
Validation loss: 1.8578253458904963

Epoch: 6| Step: 1
Training loss: 0.8298201560974121
Validation loss: 1.8778751460454797

Epoch: 6| Step: 2
Training loss: 0.7255926132202148
Validation loss: 1.8523300078607374

Epoch: 6| Step: 3
Training loss: 0.721844494342804
Validation loss: 1.840641272965298

Epoch: 6| Step: 4
Training loss: 0.37445712089538574
Validation loss: 1.8555412318116875

Epoch: 6| Step: 5
Training loss: 0.5500780344009399
Validation loss: 1.8658596431055376

Epoch: 6| Step: 6
Training loss: 0.44170624017715454
Validation loss: 1.8780723797377719

Epoch: 6| Step: 7
Training loss: 0.7432000637054443
Validation loss: 1.8909097499744867

Epoch: 6| Step: 8
Training loss: 0.5628302097320557
Validation loss: 1.8813676295741912

Epoch: 6| Step: 9
Training loss: 0.7097511291503906
Validation loss: 1.8562335519380466

Epoch: 6| Step: 10
Training loss: 0.6639831066131592
Validation loss: 1.8637134528929187

Epoch: 6| Step: 11
Training loss: 1.0493559837341309
Validation loss: 1.851216168813808

Epoch: 6| Step: 12
Training loss: 0.867714524269104
Validation loss: 1.8496000997481807

Epoch: 6| Step: 13
Training loss: 0.9604572653770447
Validation loss: 1.8325871549626833

Epoch: 274| Step: 0
Training loss: 0.6329386234283447
Validation loss: 1.8392980585816086

Epoch: 6| Step: 1
Training loss: 1.0107691287994385
Validation loss: 1.8278765691223966

Epoch: 6| Step: 2
Training loss: 1.3404407501220703
Validation loss: 1.8314957631531583

Epoch: 6| Step: 3
Training loss: 0.6339197754859924
Validation loss: 1.8483338176563222

Epoch: 6| Step: 4
Training loss: 0.2321859747171402
Validation loss: 1.855351976169053

Epoch: 6| Step: 5
Training loss: 0.649924635887146
Validation loss: 1.8571329168094102

Epoch: 6| Step: 6
Training loss: 0.6333892345428467
Validation loss: 1.8881120963763165

Epoch: 6| Step: 7
Training loss: 0.9564609527587891
Validation loss: 1.8704502608186455

Epoch: 6| Step: 8
Training loss: 0.43219900131225586
Validation loss: 1.8782461497091478

Epoch: 6| Step: 9
Training loss: 0.6156982183456421
Validation loss: 1.8810266615242086

Epoch: 6| Step: 10
Training loss: 0.5447436571121216
Validation loss: 1.889958276543566

Epoch: 6| Step: 11
Training loss: 0.48498523235321045
Validation loss: 1.8687947950055521

Epoch: 6| Step: 12
Training loss: 0.8937212228775024
Validation loss: 1.8494249979654949

Epoch: 6| Step: 13
Training loss: 0.9521034955978394
Validation loss: 1.8469566299069313

Epoch: 275| Step: 0
Training loss: 0.41531312465667725
Validation loss: 1.8411797887535506

Epoch: 6| Step: 1
Training loss: 0.3353423476219177
Validation loss: 1.8692987888090071

Epoch: 6| Step: 2
Training loss: 0.7948192954063416
Validation loss: 1.9021189674254386

Epoch: 6| Step: 3
Training loss: 1.1615898609161377
Validation loss: 1.855134270524466

Epoch: 6| Step: 4
Training loss: 0.5855838656425476
Validation loss: 1.8923180128938408

Epoch: 6| Step: 5
Training loss: 0.7016180753707886
Validation loss: 1.8512358498829666

Epoch: 6| Step: 6
Training loss: 0.6374679803848267
Validation loss: 1.8454527854919434

Epoch: 6| Step: 7
Training loss: 0.8891944289207458
Validation loss: 1.7911014390248123

Epoch: 6| Step: 8
Training loss: 0.533764123916626
Validation loss: 1.811456726443383

Epoch: 6| Step: 9
Training loss: 0.6542865633964539
Validation loss: 1.8235385443574639

Epoch: 6| Step: 10
Training loss: 0.8081827163696289
Validation loss: 1.814574945357538

Epoch: 6| Step: 11
Training loss: 1.0335297584533691
Validation loss: 1.8291254299943165

Epoch: 6| Step: 12
Training loss: 0.42202693223953247
Validation loss: 1.8129871160753313

Epoch: 6| Step: 13
Training loss: 0.42254626750946045
Validation loss: 1.8216347284214471

Epoch: 276| Step: 0
Training loss: 0.6373649835586548
Validation loss: 1.8377519858780729

Epoch: 6| Step: 1
Training loss: 0.47124266624450684
Validation loss: 1.8665481908347017

Epoch: 6| Step: 2
Training loss: 0.4601309597492218
Validation loss: 1.8745127198516682

Epoch: 6| Step: 3
Training loss: 0.541039764881134
Validation loss: 1.8955647112220846

Epoch: 6| Step: 4
Training loss: 0.652687132358551
Validation loss: 1.8569171582498858

Epoch: 6| Step: 5
Training loss: 0.5468931198120117
Validation loss: 1.829036230682045

Epoch: 6| Step: 6
Training loss: 0.7992808818817139
Validation loss: 1.8372390526597218

Epoch: 6| Step: 7
Training loss: 0.46685391664505005
Validation loss: 1.8242374940585064

Epoch: 6| Step: 8
Training loss: 0.9528559446334839
Validation loss: 1.8121868179690452

Epoch: 6| Step: 9
Training loss: 0.8365620374679565
Validation loss: 1.8127531236217869

Epoch: 6| Step: 10
Training loss: 0.770005464553833
Validation loss: 1.813478760821845

Epoch: 6| Step: 11
Training loss: 0.8647857904434204
Validation loss: 1.806414524714152

Epoch: 6| Step: 12
Training loss: 0.7714647054672241
Validation loss: 1.8122571950317712

Epoch: 6| Step: 13
Training loss: 0.4599394202232361
Validation loss: 1.814503926102833

Epoch: 277| Step: 0
Training loss: 0.3565387725830078
Validation loss: 1.8082063467271867

Epoch: 6| Step: 1
Training loss: 0.8817199468612671
Validation loss: 1.8032273669396677

Epoch: 6| Step: 2
Training loss: 0.5967884063720703
Validation loss: 1.8011410813177786

Epoch: 6| Step: 3
Training loss: 0.641329288482666
Validation loss: 1.7999047361394411

Epoch: 6| Step: 4
Training loss: 0.6759597063064575
Validation loss: 1.7861400368393108

Epoch: 6| Step: 5
Training loss: 0.6686941385269165
Validation loss: 1.781791160183568

Epoch: 6| Step: 6
Training loss: 0.8368455767631531
Validation loss: 1.7659704095573836

Epoch: 6| Step: 7
Training loss: 1.2227602005004883
Validation loss: 1.766410881473172

Epoch: 6| Step: 8
Training loss: 0.5838257670402527
Validation loss: 1.798858937396798

Epoch: 6| Step: 9
Training loss: 0.4810682237148285
Validation loss: 1.775589067448852

Epoch: 6| Step: 10
Training loss: 0.338261216878891
Validation loss: 1.7723052245314403

Epoch: 6| Step: 11
Training loss: 0.7267806529998779
Validation loss: 1.772382019668497

Epoch: 6| Step: 12
Training loss: 0.8167099356651306
Validation loss: 1.8189750871350687

Epoch: 6| Step: 13
Training loss: 0.36373716592788696
Validation loss: 1.832898522576978

Epoch: 278| Step: 0
Training loss: 0.4900743365287781
Validation loss: 1.8538315116718251

Epoch: 6| Step: 1
Training loss: 0.9549928903579712
Validation loss: 1.8958048525676932

Epoch: 6| Step: 2
Training loss: 0.4182547628879547
Validation loss: 1.894345429635817

Epoch: 6| Step: 3
Training loss: 0.6775509715080261
Validation loss: 1.920155514952957

Epoch: 6| Step: 4
Training loss: 0.5759780406951904
Validation loss: 1.91382037696018

Epoch: 6| Step: 5
Training loss: 0.5764076113700867
Validation loss: 1.9109138993806736

Epoch: 6| Step: 6
Training loss: 0.40854185819625854
Validation loss: 1.910237125171128

Epoch: 6| Step: 7
Training loss: 0.5510287880897522
Validation loss: 1.9051649801192745

Epoch: 6| Step: 8
Training loss: 0.5753155946731567
Validation loss: 1.8844300418771722

Epoch: 6| Step: 9
Training loss: 0.6211315393447876
Validation loss: 1.8473164727610927

Epoch: 6| Step: 10
Training loss: 1.0992156267166138
Validation loss: 1.8234294217119935

Epoch: 6| Step: 11
Training loss: 0.7054464817047119
Validation loss: 1.8030094267219625

Epoch: 6| Step: 12
Training loss: 0.4614330232143402
Validation loss: 1.7891437443353797

Epoch: 6| Step: 13
Training loss: 1.0532450675964355
Validation loss: 1.7672253462576097

Epoch: 279| Step: 0
Training loss: 0.4565708041191101
Validation loss: 1.7643662280933832

Epoch: 6| Step: 1
Training loss: 0.6643902063369751
Validation loss: 1.7875823718245312

Epoch: 6| Step: 2
Training loss: 0.7609862089157104
Validation loss: 1.789834403222607

Epoch: 6| Step: 3
Training loss: 0.5731323957443237
Validation loss: 1.8030025254013717

Epoch: 6| Step: 4
Training loss: 0.7117621898651123
Validation loss: 1.8122772709015877

Epoch: 6| Step: 5
Training loss: 0.7060432434082031
Validation loss: 1.82215291325764

Epoch: 6| Step: 6
Training loss: 0.5846704244613647
Validation loss: 1.851226834840672

Epoch: 6| Step: 7
Training loss: 0.7345108389854431
Validation loss: 1.860271523075719

Epoch: 6| Step: 8
Training loss: 0.589730978012085
Validation loss: 1.8547422193711804

Epoch: 6| Step: 9
Training loss: 0.5880635976791382
Validation loss: 1.8263685132867546

Epoch: 6| Step: 10
Training loss: 0.6200456619262695
Validation loss: 1.8406019800452775

Epoch: 6| Step: 11
Training loss: 1.0339059829711914
Validation loss: 1.8262680653602845

Epoch: 6| Step: 12
Training loss: 0.5390397906303406
Validation loss: 1.8448720798697522

Epoch: 6| Step: 13
Training loss: 0.9816865921020508
Validation loss: 1.8270283911817817

Epoch: 280| Step: 0
Training loss: 0.6631590127944946
Validation loss: 1.821357475813999

Epoch: 6| Step: 1
Training loss: 0.9675228595733643
Validation loss: 1.833576576684111

Epoch: 6| Step: 2
Training loss: 0.350019633769989
Validation loss: 1.8333043347122848

Epoch: 6| Step: 3
Training loss: 0.4665701985359192
Validation loss: 1.8244969383362801

Epoch: 6| Step: 4
Training loss: 0.5073839426040649
Validation loss: 1.8418644192398235

Epoch: 6| Step: 5
Training loss: 0.9077621698379517
Validation loss: 1.8299658362583449

Epoch: 6| Step: 6
Training loss: 0.6256323456764221
Validation loss: 1.821092818372993

Epoch: 6| Step: 7
Training loss: 0.42589277029037476
Validation loss: 1.8136707352053734

Epoch: 6| Step: 8
Training loss: 0.6207934617996216
Validation loss: 1.83709583743926

Epoch: 6| Step: 9
Training loss: 0.9648801684379578
Validation loss: 1.8193267776120094

Epoch: 6| Step: 10
Training loss: 0.5930318236351013
Validation loss: 1.8220176184049217

Epoch: 6| Step: 11
Training loss: 0.22680509090423584
Validation loss: 1.8172242186402763

Epoch: 6| Step: 12
Training loss: 0.805949330329895
Validation loss: 1.8242699600035144

Epoch: 6| Step: 13
Training loss: 0.5536861419677734
Validation loss: 1.8286124403758715

Epoch: 281| Step: 0
Training loss: 0.5643651485443115
Validation loss: 1.803580258482246

Epoch: 6| Step: 1
Training loss: 0.4027758836746216
Validation loss: 1.8307654203907135

Epoch: 6| Step: 2
Training loss: 0.6003327369689941
Validation loss: 1.823612597680861

Epoch: 6| Step: 3
Training loss: 0.5683453679084778
Validation loss: 1.8075540193947413

Epoch: 6| Step: 4
Training loss: 0.807992696762085
Validation loss: 1.8274232020942114

Epoch: 6| Step: 5
Training loss: 0.45777371525764465
Validation loss: 1.7913925250371296

Epoch: 6| Step: 6
Training loss: 0.5733156800270081
Validation loss: 1.7547872348498272

Epoch: 6| Step: 7
Training loss: 0.7874565124511719
Validation loss: 1.7467998073947044

Epoch: 6| Step: 8
Training loss: 0.7597644925117493
Validation loss: 1.7577320965387488

Epoch: 6| Step: 9
Training loss: 0.3588404059410095
Validation loss: 1.769304734404369

Epoch: 6| Step: 10
Training loss: 1.1440792083740234
Validation loss: 1.7584063981169014

Epoch: 6| Step: 11
Training loss: 0.712380051612854
Validation loss: 1.769316001604962

Epoch: 6| Step: 12
Training loss: 0.7390296459197998
Validation loss: 1.8166904680190548

Epoch: 6| Step: 13
Training loss: 0.31358131766319275
Validation loss: 1.8394045906682168

Epoch: 282| Step: 0
Training loss: 0.8297236561775208
Validation loss: 1.8579584424213698

Epoch: 6| Step: 1
Training loss: 0.6668241620063782
Validation loss: 1.8732122977574666

Epoch: 6| Step: 2
Training loss: 0.632122814655304
Validation loss: 1.8826582508702432

Epoch: 6| Step: 3
Training loss: 0.7943881750106812
Validation loss: 1.8720085979789816

Epoch: 6| Step: 4
Training loss: 0.6119115352630615
Validation loss: 1.8775890437505578

Epoch: 6| Step: 5
Training loss: 0.7269870638847351
Validation loss: 1.8719078494656471

Epoch: 6| Step: 6
Training loss: 0.528548002243042
Validation loss: 1.8410052625081872

Epoch: 6| Step: 7
Training loss: 0.7904102802276611
Validation loss: 1.8541720881257007

Epoch: 6| Step: 8
Training loss: 0.5053020715713501
Validation loss: 1.8171550394386373

Epoch: 6| Step: 9
Training loss: 0.366963267326355
Validation loss: 1.8144081907887613

Epoch: 6| Step: 10
Training loss: 0.5040230751037598
Validation loss: 1.804326472743865

Epoch: 6| Step: 11
Training loss: 0.5463777184486389
Validation loss: 1.7897492518988989

Epoch: 6| Step: 12
Training loss: 0.6859550476074219
Validation loss: 1.7632958299370223

Epoch: 6| Step: 13
Training loss: 0.19039879739284515
Validation loss: 1.7669881441259896

Epoch: 283| Step: 0
Training loss: 0.6149836182594299
Validation loss: 1.784978405121834

Epoch: 6| Step: 1
Training loss: 0.4545479118824005
Validation loss: 1.8000089660767586

Epoch: 6| Step: 2
Training loss: 0.5951966047286987
Validation loss: 1.8041899037617508

Epoch: 6| Step: 3
Training loss: 0.6254833936691284
Validation loss: 1.8379440794708908

Epoch: 6| Step: 4
Training loss: 0.6364067792892456
Validation loss: 1.8096067623425556

Epoch: 6| Step: 5
Training loss: 0.8411946296691895
Validation loss: 1.8235027982342629

Epoch: 6| Step: 6
Training loss: 0.4230979084968567
Validation loss: 1.7959272951208136

Epoch: 6| Step: 7
Training loss: 0.6241434812545776
Validation loss: 1.7855491010091638

Epoch: 6| Step: 8
Training loss: 0.5431725978851318
Validation loss: 1.8108690400277414

Epoch: 6| Step: 9
Training loss: 0.7016388177871704
Validation loss: 1.795154966333861

Epoch: 6| Step: 10
Training loss: 0.5285055637359619
Validation loss: 1.8037177016658168

Epoch: 6| Step: 11
Training loss: 0.444571852684021
Validation loss: 1.790832822040845

Epoch: 6| Step: 12
Training loss: 0.8089067339897156
Validation loss: 1.7679146233425345

Epoch: 6| Step: 13
Training loss: 1.4342336654663086
Validation loss: 1.8003351175656883

Epoch: 284| Step: 0
Training loss: 0.4971780776977539
Validation loss: 1.7551409659847137

Epoch: 6| Step: 1
Training loss: 0.9266828894615173
Validation loss: 1.7949797376509635

Epoch: 6| Step: 2
Training loss: 0.3667253255844116
Validation loss: 1.7991358759582683

Epoch: 6| Step: 3
Training loss: 0.5599672794342041
Validation loss: 1.857422286464322

Epoch: 6| Step: 4
Training loss: 0.7058146595954895
Validation loss: 1.8525166793536114

Epoch: 6| Step: 5
Training loss: 0.5345732569694519
Validation loss: 1.839567361339446

Epoch: 6| Step: 6
Training loss: 0.3923949599266052
Validation loss: 1.8216421117064774

Epoch: 6| Step: 7
Training loss: 0.9090284705162048
Validation loss: 1.794260626198143

Epoch: 6| Step: 8
Training loss: 0.662543773651123
Validation loss: 1.7670322566904046

Epoch: 6| Step: 9
Training loss: 0.7863613367080688
Validation loss: 1.7803752012150262

Epoch: 6| Step: 10
Training loss: 0.9962387084960938
Validation loss: 1.8221993330986268

Epoch: 6| Step: 11
Training loss: 0.48117509484291077
Validation loss: 1.8059229209858885

Epoch: 6| Step: 12
Training loss: 0.6124200224876404
Validation loss: 1.8084778926705802

Epoch: 6| Step: 13
Training loss: 0.8976245522499084
Validation loss: 1.7959574166164602

Epoch: 285| Step: 0
Training loss: 0.7271074056625366
Validation loss: 1.7560809940420172

Epoch: 6| Step: 1
Training loss: 0.9249672889709473
Validation loss: 1.7651287150639359

Epoch: 6| Step: 2
Training loss: 0.6496583223342896
Validation loss: 1.790714499770954

Epoch: 6| Step: 3
Training loss: 0.6215476989746094
Validation loss: 1.8539845533268426

Epoch: 6| Step: 4
Training loss: 0.5785453915596008
Validation loss: 1.8585399684085642

Epoch: 6| Step: 5
Training loss: 0.6463286876678467
Validation loss: 1.8561935783714376

Epoch: 6| Step: 6
Training loss: 0.37447530031204224
Validation loss: 1.8862652394079393

Epoch: 6| Step: 7
Training loss: 0.3090941905975342
Validation loss: 1.87965359739078

Epoch: 6| Step: 8
Training loss: 0.5622758865356445
Validation loss: 1.830505919712846

Epoch: 6| Step: 9
Training loss: 0.6460904479026794
Validation loss: 1.8364336375267274

Epoch: 6| Step: 10
Training loss: 0.5880360007286072
Validation loss: 1.8121416184210009

Epoch: 6| Step: 11
Training loss: 0.6253938674926758
Validation loss: 1.8436860999753397

Epoch: 6| Step: 12
Training loss: 0.6792262196540833
Validation loss: 1.8404671094750846

Epoch: 6| Step: 13
Training loss: 0.6970141530036926
Validation loss: 1.8129500676226873

Epoch: 286| Step: 0
Training loss: 0.5411974787712097
Validation loss: 1.8239514507273191

Epoch: 6| Step: 1
Training loss: 0.5483995676040649
Validation loss: 1.8162369625542754

Epoch: 6| Step: 2
Training loss: 0.6127180457115173
Validation loss: 1.8099734244808074

Epoch: 6| Step: 3
Training loss: 0.7323201894760132
Validation loss: 1.7991302039033623

Epoch: 6| Step: 4
Training loss: 0.2074139416217804
Validation loss: 1.8019322784998084

Epoch: 6| Step: 5
Training loss: 0.9832375049591064
Validation loss: 1.7922255595525105

Epoch: 6| Step: 6
Training loss: 0.7354602813720703
Validation loss: 1.7827907287946312

Epoch: 6| Step: 7
Training loss: 0.7670836448669434
Validation loss: 1.7758573870505057

Epoch: 6| Step: 8
Training loss: 0.3998897969722748
Validation loss: 1.7645690748768468

Epoch: 6| Step: 9
Training loss: 0.4383474588394165
Validation loss: 1.779173130630165

Epoch: 6| Step: 10
Training loss: 0.44153672456741333
Validation loss: 1.7932288621061592

Epoch: 6| Step: 11
Training loss: 0.8016561269760132
Validation loss: 1.8178951919719737

Epoch: 6| Step: 12
Training loss: 0.6172953844070435
Validation loss: 1.8411452372868855

Epoch: 6| Step: 13
Training loss: 0.49504125118255615
Validation loss: 1.8792735325392855

Epoch: 287| Step: 0
Training loss: 0.4159679114818573
Validation loss: 1.8641326645369172

Epoch: 6| Step: 1
Training loss: 0.7181656956672668
Validation loss: 1.8989920539240683

Epoch: 6| Step: 2
Training loss: 0.678577184677124
Validation loss: 1.8486785337489138

Epoch: 6| Step: 3
Training loss: 0.3627617061138153
Validation loss: 1.8465205392529886

Epoch: 6| Step: 4
Training loss: 0.44029784202575684
Validation loss: 1.8398561477661133

Epoch: 6| Step: 5
Training loss: 0.4434756636619568
Validation loss: 1.817403047315536

Epoch: 6| Step: 6
Training loss: 0.8368661403656006
Validation loss: 1.820850347959867

Epoch: 6| Step: 7
Training loss: 0.7312644124031067
Validation loss: 1.8259294148414367

Epoch: 6| Step: 8
Training loss: 0.4836426377296448
Validation loss: 1.8249686007858605

Epoch: 6| Step: 9
Training loss: 0.5770441293716431
Validation loss: 1.8278640367651497

Epoch: 6| Step: 10
Training loss: 0.44324973225593567
Validation loss: 1.8364536775055753

Epoch: 6| Step: 11
Training loss: 0.6640549898147583
Validation loss: 1.833714642832356

Epoch: 6| Step: 12
Training loss: 0.7464903593063354
Validation loss: 1.8666589516465382

Epoch: 6| Step: 13
Training loss: 0.9067429304122925
Validation loss: 1.8563135131712882

Epoch: 288| Step: 0
Training loss: 0.6339267492294312
Validation loss: 1.8387939801780127

Epoch: 6| Step: 1
Training loss: 0.7496432065963745
Validation loss: 1.8177020652319795

Epoch: 6| Step: 2
Training loss: 0.4297217130661011
Validation loss: 1.8246390435003466

Epoch: 6| Step: 3
Training loss: 0.6602751016616821
Validation loss: 1.8110421447343723

Epoch: 6| Step: 4
Training loss: 0.7915841341018677
Validation loss: 1.8262927698832687

Epoch: 6| Step: 5
Training loss: 0.7819606065750122
Validation loss: 1.8026650400571926

Epoch: 6| Step: 6
Training loss: 0.3769628405570984
Validation loss: 1.7647929550499044

Epoch: 6| Step: 7
Training loss: 0.32187896966934204
Validation loss: 1.7732366054288802

Epoch: 6| Step: 8
Training loss: 0.3695780634880066
Validation loss: 1.7624852311226629

Epoch: 6| Step: 9
Training loss: 0.8260510563850403
Validation loss: 1.7834342064396027

Epoch: 6| Step: 10
Training loss: 0.749784529209137
Validation loss: 1.7917716349324873

Epoch: 6| Step: 11
Training loss: 0.2609931528568268
Validation loss: 1.7939935871349868

Epoch: 6| Step: 12
Training loss: 0.7131779193878174
Validation loss: 1.7678338891716414

Epoch: 6| Step: 13
Training loss: 0.7456949949264526
Validation loss: 1.777255694071452

Epoch: 289| Step: 0
Training loss: 0.6084417700767517
Validation loss: 1.757367814740827

Epoch: 6| Step: 1
Training loss: 0.3845036029815674
Validation loss: 1.7372080831117527

Epoch: 6| Step: 2
Training loss: 0.32012736797332764
Validation loss: 1.7648023277200677

Epoch: 6| Step: 3
Training loss: 1.1458076238632202
Validation loss: 1.7819630804882254

Epoch: 6| Step: 4
Training loss: 0.5667808055877686
Validation loss: 1.783249214131345

Epoch: 6| Step: 5
Training loss: 0.5947416424751282
Validation loss: 1.8077265575367918

Epoch: 6| Step: 6
Training loss: 0.77348792552948
Validation loss: 1.8242087569288028

Epoch: 6| Step: 7
Training loss: 0.4224756956100464
Validation loss: 1.8267594357972503

Epoch: 6| Step: 8
Training loss: 0.6829938888549805
Validation loss: 1.8810943967552596

Epoch: 6| Step: 9
Training loss: 0.700300931930542
Validation loss: 1.895441839771886

Epoch: 6| Step: 10
Training loss: 0.6600182056427002
Validation loss: 1.9359379711971487

Epoch: 6| Step: 11
Training loss: 1.0195796489715576
Validation loss: 1.925676586807415

Epoch: 6| Step: 12
Training loss: 0.516998291015625
Validation loss: 1.894232221828994

Epoch: 6| Step: 13
Training loss: 0.4811946451663971
Validation loss: 1.838148110656328

Epoch: 290| Step: 0
Training loss: 0.30639058351516724
Validation loss: 1.807459121109337

Epoch: 6| Step: 1
Training loss: 0.47145071625709534
Validation loss: 1.7827008437084895

Epoch: 6| Step: 2
Training loss: 0.33402150869369507
Validation loss: 1.7928259180438133

Epoch: 6| Step: 3
Training loss: 0.6714072227478027
Validation loss: 1.813392416123421

Epoch: 6| Step: 4
Training loss: 0.4777759313583374
Validation loss: 1.8267070798463718

Epoch: 6| Step: 5
Training loss: 0.4232175946235657
Validation loss: 1.8212339672991025

Epoch: 6| Step: 6
Training loss: 0.8174475431442261
Validation loss: 1.8208968267645886

Epoch: 6| Step: 7
Training loss: 0.6637566089630127
Validation loss: 1.822147661639798

Epoch: 6| Step: 8
Training loss: 0.645910918712616
Validation loss: 1.8434677598296956

Epoch: 6| Step: 9
Training loss: 0.6276015639305115
Validation loss: 1.8403160713052238

Epoch: 6| Step: 10
Training loss: 0.7389260530471802
Validation loss: 1.8576465127288655

Epoch: 6| Step: 11
Training loss: 0.9931978583335876
Validation loss: 1.8772543322655462

Epoch: 6| Step: 12
Training loss: 0.6372678279876709
Validation loss: 1.8814879335382932

Epoch: 6| Step: 13
Training loss: 0.4061482846736908
Validation loss: 1.8356426813269173

Epoch: 291| Step: 0
Training loss: 0.6299575567245483
Validation loss: 1.8058199715870682

Epoch: 6| Step: 1
Training loss: 0.6692037582397461
Validation loss: 1.7783786660881453

Epoch: 6| Step: 2
Training loss: 0.614959716796875
Validation loss: 1.7924360882851385

Epoch: 6| Step: 3
Training loss: 0.2475491315126419
Validation loss: 1.8087366793745308

Epoch: 6| Step: 4
Training loss: 0.3472733795642853
Validation loss: 1.828236920859224

Epoch: 6| Step: 5
Training loss: 0.4538624882698059
Validation loss: 1.7932727535565693

Epoch: 6| Step: 6
Training loss: 1.0343925952911377
Validation loss: 1.7916531434623144

Epoch: 6| Step: 7
Training loss: 0.3107651472091675
Validation loss: 1.7804616715318413

Epoch: 6| Step: 8
Training loss: 0.6045392155647278
Validation loss: 1.7766095284492738

Epoch: 6| Step: 9
Training loss: 0.9321523904800415
Validation loss: 1.7781505110443279

Epoch: 6| Step: 10
Training loss: 0.6498983502388
Validation loss: 1.796704617879724

Epoch: 6| Step: 11
Training loss: 0.20460650324821472
Validation loss: 1.7821518093027093

Epoch: 6| Step: 12
Training loss: 0.27621325850486755
Validation loss: 1.7715647682066886

Epoch: 6| Step: 13
Training loss: 0.9127228260040283
Validation loss: 1.7741922768213416

Epoch: 292| Step: 0
Training loss: 0.2566532790660858
Validation loss: 1.7964950966578659

Epoch: 6| Step: 1
Training loss: 0.3866725564002991
Validation loss: 1.8047800781906291

Epoch: 6| Step: 2
Training loss: 0.7239387035369873
Validation loss: 1.8272022547260407

Epoch: 6| Step: 3
Training loss: 0.5197367668151855
Validation loss: 1.8169636675106582

Epoch: 6| Step: 4
Training loss: 0.3449993133544922
Validation loss: 1.8208981778032036

Epoch: 6| Step: 5
Training loss: 0.5237206220626831
Validation loss: 1.8048740958654752

Epoch: 6| Step: 6
Training loss: 0.47506704926490784
Validation loss: 1.8059928647933468

Epoch: 6| Step: 7
Training loss: 0.6494464874267578
Validation loss: 1.7822878873476418

Epoch: 6| Step: 8
Training loss: 0.4094504714012146
Validation loss: 1.7999915435749998

Epoch: 6| Step: 9
Training loss: 0.9510573148727417
Validation loss: 1.78936642472462

Epoch: 6| Step: 10
Training loss: 0.47668397426605225
Validation loss: 1.7767816333360569

Epoch: 6| Step: 11
Training loss: 0.8727644681930542
Validation loss: 1.8002298179493155

Epoch: 6| Step: 12
Training loss: 0.6194442510604858
Validation loss: 1.816839692413166

Epoch: 6| Step: 13
Training loss: 0.41625675559043884
Validation loss: 1.827553992630333

Epoch: 293| Step: 0
Training loss: 0.6385539770126343
Validation loss: 1.8483223171644314

Epoch: 6| Step: 1
Training loss: 0.5385414361953735
Validation loss: 1.847878453552082

Epoch: 6| Step: 2
Training loss: 0.36439841985702515
Validation loss: 1.8598008796732912

Epoch: 6| Step: 3
Training loss: 0.5590790510177612
Validation loss: 1.8098863401720602

Epoch: 6| Step: 4
Training loss: 0.8736713528633118
Validation loss: 1.776432842336675

Epoch: 6| Step: 5
Training loss: 0.32388126850128174
Validation loss: 1.7916971675811275

Epoch: 6| Step: 6
Training loss: 0.3859371840953827
Validation loss: 1.7954430144320253

Epoch: 6| Step: 7
Training loss: 0.5554669499397278
Validation loss: 1.7951155452318088

Epoch: 6| Step: 8
Training loss: 0.630425214767456
Validation loss: 1.7873327475722118

Epoch: 6| Step: 9
Training loss: 0.8768833875656128
Validation loss: 1.784956455230713

Epoch: 6| Step: 10
Training loss: 0.5359432697296143
Validation loss: 1.8006256908498786

Epoch: 6| Step: 11
Training loss: 0.5730645656585693
Validation loss: 1.7965525939900389

Epoch: 6| Step: 12
Training loss: 0.45478755235671997
Validation loss: 1.8109161584608016

Epoch: 6| Step: 13
Training loss: 0.5143622159957886
Validation loss: 1.8392376861264628

Epoch: 294| Step: 0
Training loss: 0.41254252195358276
Validation loss: 1.8315210752589728

Epoch: 6| Step: 1
Training loss: 1.0137406587600708
Validation loss: 1.8246079901213288

Epoch: 6| Step: 2
Training loss: 0.5055974721908569
Validation loss: 1.8039790891831922

Epoch: 6| Step: 3
Training loss: 0.32215702533721924
Validation loss: 1.8034883442745413

Epoch: 6| Step: 4
Training loss: 0.6894182562828064
Validation loss: 1.7905270258585613

Epoch: 6| Step: 5
Training loss: 0.7505019307136536
Validation loss: 1.7753730268888577

Epoch: 6| Step: 6
Training loss: 0.49771982431411743
Validation loss: 1.7800303184857933

Epoch: 6| Step: 7
Training loss: 0.37238094210624695
Validation loss: 1.773846726263723

Epoch: 6| Step: 8
Training loss: 0.8061443567276001
Validation loss: 1.771276604744696

Epoch: 6| Step: 9
Training loss: 0.5433701276779175
Validation loss: 1.7866143475296676

Epoch: 6| Step: 10
Training loss: 0.3657589852809906
Validation loss: 1.8004789288325975

Epoch: 6| Step: 11
Training loss: 0.3957696557044983
Validation loss: 1.7980991742944206

Epoch: 6| Step: 12
Training loss: 0.2680555582046509
Validation loss: 1.8255330695900867

Epoch: 6| Step: 13
Training loss: 0.34969282150268555
Validation loss: 1.8212291630365516

Epoch: 295| Step: 0
Training loss: 0.4451618194580078
Validation loss: 1.8185137266753821

Epoch: 6| Step: 1
Training loss: 0.4767836332321167
Validation loss: 1.8132143744858362

Epoch: 6| Step: 2
Training loss: 0.9670894145965576
Validation loss: 1.803319490084084

Epoch: 6| Step: 3
Training loss: 0.7476791739463806
Validation loss: 1.7683433371205484

Epoch: 6| Step: 4
Training loss: 0.1645970195531845
Validation loss: 1.778098798567249

Epoch: 6| Step: 5
Training loss: 0.3398650288581848
Validation loss: 1.7867711103090675

Epoch: 6| Step: 6
Training loss: 0.5326323509216309
Validation loss: 1.790669322013855

Epoch: 6| Step: 7
Training loss: 0.4582575559616089
Validation loss: 1.7914900984815372

Epoch: 6| Step: 8
Training loss: 0.4694409966468811
Validation loss: 1.803179569141839

Epoch: 6| Step: 9
Training loss: 0.45044124126434326
Validation loss: 1.7395060818682435

Epoch: 6| Step: 10
Training loss: 0.49856555461883545
Validation loss: 1.7746511377314085

Epoch: 6| Step: 11
Training loss: 0.7637097835540771
Validation loss: 1.7438762572503859

Epoch: 6| Step: 12
Training loss: 0.491713285446167
Validation loss: 1.7622981814927952

Epoch: 6| Step: 13
Training loss: 0.6382371187210083
Validation loss: 1.7559117681236678

Epoch: 296| Step: 0
Training loss: 0.283765971660614
Validation loss: 1.7896919635034376

Epoch: 6| Step: 1
Training loss: 0.5039311647415161
Validation loss: 1.7792870870200537

Epoch: 6| Step: 2
Training loss: 0.4747748374938965
Validation loss: 1.740800121779083

Epoch: 6| Step: 3
Training loss: 0.5477816462516785
Validation loss: 1.7673463539410663

Epoch: 6| Step: 4
Training loss: 0.4512365460395813
Validation loss: 1.735899201003454

Epoch: 6| Step: 5
Training loss: 0.4456316828727722
Validation loss: 1.742567354632962

Epoch: 6| Step: 6
Training loss: 0.5564000010490417
Validation loss: 1.751719945220537

Epoch: 6| Step: 7
Training loss: 0.4994578957557678
Validation loss: 1.765305902368279

Epoch: 6| Step: 8
Training loss: 0.5069711208343506
Validation loss: 1.7491908983517719

Epoch: 6| Step: 9
Training loss: 0.9588925838470459
Validation loss: 1.7351604546270063

Epoch: 6| Step: 10
Training loss: 0.22621610760688782
Validation loss: 1.7604394792228617

Epoch: 6| Step: 11
Training loss: 0.8206931948661804
Validation loss: 1.7273110407654957

Epoch: 6| Step: 12
Training loss: 0.6153299808502197
Validation loss: 1.7385867795636576

Epoch: 6| Step: 13
Training loss: 0.7653154134750366
Validation loss: 1.728650499415654

Epoch: 297| Step: 0
Training loss: 0.5319859981536865
Validation loss: 1.7320024172465007

Epoch: 6| Step: 1
Training loss: 0.5697157382965088
Validation loss: 1.7355916038636239

Epoch: 6| Step: 2
Training loss: 0.364046573638916
Validation loss: 1.7742551847170758

Epoch: 6| Step: 3
Training loss: 0.36728960275650024
Validation loss: 1.785147282385057

Epoch: 6| Step: 4
Training loss: 0.5161279439926147
Validation loss: 1.796896364099236

Epoch: 6| Step: 5
Training loss: 0.4808618426322937
Validation loss: 1.7769093410943144

Epoch: 6| Step: 6
Training loss: 0.6121854782104492
Validation loss: 1.7850934510589929

Epoch: 6| Step: 7
Training loss: 0.5178520083427429
Validation loss: 1.7852418166334911

Epoch: 6| Step: 8
Training loss: 0.1433543562889099
Validation loss: 1.77897080298393

Epoch: 6| Step: 9
Training loss: 0.8584380149841309
Validation loss: 1.7708891719900153

Epoch: 6| Step: 10
Training loss: 0.4049714505672455
Validation loss: 1.7833368829501572

Epoch: 6| Step: 11
Training loss: 0.8378981351852417
Validation loss: 1.8084944986527967

Epoch: 6| Step: 12
Training loss: 0.40328335762023926
Validation loss: 1.7622649131282684

Epoch: 6| Step: 13
Training loss: 0.7264939546585083
Validation loss: 1.7760355293109853

Epoch: 298| Step: 0
Training loss: 0.756738543510437
Validation loss: 1.7722242186146397

Epoch: 6| Step: 1
Training loss: 0.8336967825889587
Validation loss: 1.7890312197387859

Epoch: 6| Step: 2
Training loss: 0.3928244709968567
Validation loss: 1.788536323014126

Epoch: 6| Step: 3
Training loss: 0.4876835346221924
Validation loss: 1.8094553870539511

Epoch: 6| Step: 4
Training loss: 0.4238879680633545
Validation loss: 1.8018339090449835

Epoch: 6| Step: 5
Training loss: 0.27594155073165894
Validation loss: 1.812754725897184

Epoch: 6| Step: 6
Training loss: 0.673714280128479
Validation loss: 1.7940053183545348

Epoch: 6| Step: 7
Training loss: 0.34259122610092163
Validation loss: 1.7822116357023998

Epoch: 6| Step: 8
Training loss: 0.40722453594207764
Validation loss: 1.7791608841188493

Epoch: 6| Step: 9
Training loss: 0.48004117608070374
Validation loss: 1.8110727366580759

Epoch: 6| Step: 10
Training loss: 0.7370121479034424
Validation loss: 1.7982795341040498

Epoch: 6| Step: 11
Training loss: 0.5539005994796753
Validation loss: 1.8094509647738548

Epoch: 6| Step: 12
Training loss: 0.3919512629508972
Validation loss: 1.833018615681638

Epoch: 6| Step: 13
Training loss: 0.4662746787071228
Validation loss: 1.8198328787280666

Epoch: 299| Step: 0
Training loss: 0.5681716203689575
Validation loss: 1.8703161670315651

Epoch: 6| Step: 1
Training loss: 0.6676439642906189
Validation loss: 1.898409697317308

Epoch: 6| Step: 2
Training loss: 0.6074227094650269
Validation loss: 1.8900531991835563

Epoch: 6| Step: 3
Training loss: 0.7397861480712891
Validation loss: 1.8679768744335379

Epoch: 6| Step: 4
Training loss: 0.5422276854515076
Validation loss: 1.873356355133877

Epoch: 6| Step: 5
Training loss: 0.6321436166763306
Validation loss: 1.815760515069449

Epoch: 6| Step: 6
Training loss: 0.6303545236587524
Validation loss: 1.7672133317557714

Epoch: 6| Step: 7
Training loss: 0.2757195830345154
Validation loss: 1.7388763671280236

Epoch: 6| Step: 8
Training loss: 0.5052164196968079
Validation loss: 1.7489604360313826

Epoch: 6| Step: 9
Training loss: 0.41451165080070496
Validation loss: 1.7449903308704335

Epoch: 6| Step: 10
Training loss: 0.6247057318687439
Validation loss: 1.758250226256668

Epoch: 6| Step: 11
Training loss: 0.8265541791915894
Validation loss: 1.7544976716400476

Epoch: 6| Step: 12
Training loss: 0.352789044380188
Validation loss: 1.7373241263051187

Epoch: 6| Step: 13
Training loss: 0.48513877391815186
Validation loss: 1.7505108848694833

Epoch: 300| Step: 0
Training loss: 0.41295766830444336
Validation loss: 1.7996197791509732

Epoch: 6| Step: 1
Training loss: 0.34013327956199646
Validation loss: 1.7941716819681146

Epoch: 6| Step: 2
Training loss: 0.515139639377594
Validation loss: 1.8279146545676774

Epoch: 6| Step: 3
Training loss: 0.594443678855896
Validation loss: 1.8206741656026533

Epoch: 6| Step: 4
Training loss: 0.3437381088733673
Validation loss: 1.7853160404389905

Epoch: 6| Step: 5
Training loss: 0.6678898334503174
Validation loss: 1.789868317624574

Epoch: 6| Step: 6
Training loss: 0.5067201852798462
Validation loss: 1.758485186484552

Epoch: 6| Step: 7
Training loss: 0.47776302695274353
Validation loss: 1.7809405865207795

Epoch: 6| Step: 8
Training loss: 0.6157305836677551
Validation loss: 1.7391134154412053

Epoch: 6| Step: 9
Training loss: 0.3775923252105713
Validation loss: 1.7514133030368435

Epoch: 6| Step: 10
Training loss: 0.24981731176376343
Validation loss: 1.7571366410101614

Epoch: 6| Step: 11
Training loss: 0.5677924156188965
Validation loss: 1.7316102776476132

Epoch: 6| Step: 12
Training loss: 0.5467956066131592
Validation loss: 1.731285427206306

Epoch: 6| Step: 13
Training loss: 1.2762097120285034
Validation loss: 1.7343517452157953

Epoch: 301| Step: 0
Training loss: 0.6860677599906921
Validation loss: 1.7644452023249801

Epoch: 6| Step: 1
Training loss: 0.3191456198692322
Validation loss: 1.8062267700831096

Epoch: 6| Step: 2
Training loss: 0.3902016282081604
Validation loss: 1.7951641467309767

Epoch: 6| Step: 3
Training loss: 0.8510512113571167
Validation loss: 1.8218533018583893

Epoch: 6| Step: 4
Training loss: 0.3405725061893463
Validation loss: 1.7965064792222873

Epoch: 6| Step: 5
Training loss: 0.29050061106681824
Validation loss: 1.7889886927861038

Epoch: 6| Step: 6
Training loss: 0.5032466053962708
Validation loss: 1.7907207935087142

Epoch: 6| Step: 7
Training loss: 0.6108076572418213
Validation loss: 1.8157512475085515

Epoch: 6| Step: 8
Training loss: 0.5609143972396851
Validation loss: 1.80179807191254

Epoch: 6| Step: 9
Training loss: 0.35450804233551025
Validation loss: 1.786628819281055

Epoch: 6| Step: 10
Training loss: 0.674210786819458
Validation loss: 1.8277627370690788

Epoch: 6| Step: 11
Training loss: 0.517025887966156
Validation loss: 1.786793856210606

Epoch: 6| Step: 12
Training loss: 0.5886334776878357
Validation loss: 1.7690414613293064

Epoch: 6| Step: 13
Training loss: 0.4977102279663086
Validation loss: 1.7701339414042812

Epoch: 302| Step: 0
Training loss: 0.3339230716228485
Validation loss: 1.7798427240822905

Epoch: 6| Step: 1
Training loss: 0.9894042611122131
Validation loss: 1.8143870176807526

Epoch: 6| Step: 2
Training loss: 0.5550780296325684
Validation loss: 1.8062837623780774

Epoch: 6| Step: 3
Training loss: 0.43649399280548096
Validation loss: 1.7743630024694628

Epoch: 6| Step: 4
Training loss: 0.7667401432991028
Validation loss: 1.7816032158431185

Epoch: 6| Step: 5
Training loss: 0.47727203369140625
Validation loss: 1.7469291648557108

Epoch: 6| Step: 6
Training loss: 0.3879615068435669
Validation loss: 1.7425632502443047

Epoch: 6| Step: 7
Training loss: 0.5385888814926147
Validation loss: 1.7816425523450297

Epoch: 6| Step: 8
Training loss: 0.4495987296104431
Validation loss: 1.7741312032104821

Epoch: 6| Step: 9
Training loss: 0.40065282583236694
Validation loss: 1.766783989885802

Epoch: 6| Step: 10
Training loss: 0.5631988048553467
Validation loss: 1.7512531588154454

Epoch: 6| Step: 11
Training loss: 0.48560163378715515
Validation loss: 1.7221745739700973

Epoch: 6| Step: 12
Training loss: 0.4021355211734772
Validation loss: 1.7321453889211018

Epoch: 6| Step: 13
Training loss: 0.3514429032802582
Validation loss: 1.7265559434890747

Epoch: 303| Step: 0
Training loss: 0.6220289468765259
Validation loss: 1.7195983676500217

Epoch: 6| Step: 1
Training loss: 0.5439184904098511
Validation loss: 1.7446919372004848

Epoch: 6| Step: 2
Training loss: 0.3529488742351532
Validation loss: 1.735049122123308

Epoch: 6| Step: 3
Training loss: 0.319683313369751
Validation loss: 1.7268134958000594

Epoch: 6| Step: 4
Training loss: 0.6552963256835938
Validation loss: 1.7239502886290192

Epoch: 6| Step: 5
Training loss: 0.5344887971878052
Validation loss: 1.714437839805439

Epoch: 6| Step: 6
Training loss: 0.5357118844985962
Validation loss: 1.7130128234945319

Epoch: 6| Step: 7
Training loss: 0.4933549165725708
Validation loss: 1.721196456622052

Epoch: 6| Step: 8
Training loss: 0.43004485964775085
Validation loss: 1.7401738153990878

Epoch: 6| Step: 9
Training loss: 0.2782258689403534
Validation loss: 1.7206385879106418

Epoch: 6| Step: 10
Training loss: 0.2588832378387451
Validation loss: 1.7367317702180596

Epoch: 6| Step: 11
Training loss: 0.5321380496025085
Validation loss: 1.7486952684258903

Epoch: 6| Step: 12
Training loss: 0.5446949601173401
Validation loss: 1.752860071838543

Epoch: 6| Step: 13
Training loss: 0.4923977851867676
Validation loss: 1.774745282306466

Epoch: 304| Step: 0
Training loss: 0.4219691753387451
Validation loss: 1.7789297424336916

Epoch: 6| Step: 1
Training loss: 0.3968082368373871
Validation loss: 1.7945658365885417

Epoch: 6| Step: 2
Training loss: 0.6132672429084778
Validation loss: 1.775620815574482

Epoch: 6| Step: 3
Training loss: 0.42357125878334045
Validation loss: 1.7771915876737205

Epoch: 6| Step: 4
Training loss: 0.5087530612945557
Validation loss: 1.7903084626761816

Epoch: 6| Step: 5
Training loss: 0.8232510685920715
Validation loss: 1.7475247370299472

Epoch: 6| Step: 6
Training loss: 0.5305943489074707
Validation loss: 1.7535891122715448

Epoch: 6| Step: 7
Training loss: 0.49505895376205444
Validation loss: 1.754372840286583

Epoch: 6| Step: 8
Training loss: 0.33310022950172424
Validation loss: 1.7514788655824558

Epoch: 6| Step: 9
Training loss: 0.382355272769928
Validation loss: 1.7500879277465164

Epoch: 6| Step: 10
Training loss: 0.34710076451301575
Validation loss: 1.728978177552582

Epoch: 6| Step: 11
Training loss: 0.43518152832984924
Validation loss: 1.730544021052699

Epoch: 6| Step: 12
Training loss: 0.4501408338546753
Validation loss: 1.7346815652744745

Epoch: 6| Step: 13
Training loss: 0.1724257916212082
Validation loss: 1.7301845576173516

Epoch: 305| Step: 0
Training loss: 0.306143194437027
Validation loss: 1.7305143084577335

Epoch: 6| Step: 1
Training loss: 0.5381798148155212
Validation loss: 1.7089271494137344

Epoch: 6| Step: 2
Training loss: 0.2885723114013672
Validation loss: 1.7055132107068134

Epoch: 6| Step: 3
Training loss: 0.6389952301979065
Validation loss: 1.695713247022321

Epoch: 6| Step: 4
Training loss: 0.3674088716506958
Validation loss: 1.7159293877181185

Epoch: 6| Step: 5
Training loss: 0.7270039916038513
Validation loss: 1.7269990815911243

Epoch: 6| Step: 6
Training loss: 0.5336834788322449
Validation loss: 1.717503632268598

Epoch: 6| Step: 7
Training loss: 0.19214123487472534
Validation loss: 1.728601424924789

Epoch: 6| Step: 8
Training loss: 0.4644026756286621
Validation loss: 1.7406179007663523

Epoch: 6| Step: 9
Training loss: 0.49812179803848267
Validation loss: 1.7459630261185348

Epoch: 6| Step: 10
Training loss: 0.5863490700721741
Validation loss: 1.7901491388197868

Epoch: 6| Step: 11
Training loss: 0.47678157687187195
Validation loss: 1.7804212185644335

Epoch: 6| Step: 12
Training loss: 0.3653706908226013
Validation loss: 1.7497197056329379

Epoch: 6| Step: 13
Training loss: 0.31947171688079834
Validation loss: 1.7236498978830153

Epoch: 306| Step: 0
Training loss: 0.6430424451828003
Validation loss: 1.7255329521753455

Epoch: 6| Step: 1
Training loss: 0.5455445647239685
Validation loss: 1.7446931267297396

Epoch: 6| Step: 2
Training loss: 0.5256849527359009
Validation loss: 1.748027342621998

Epoch: 6| Step: 3
Training loss: 0.48490142822265625
Validation loss: 1.7183494811416955

Epoch: 6| Step: 4
Training loss: 0.7039480209350586
Validation loss: 1.7332682212193806

Epoch: 6| Step: 5
Training loss: 0.6190744042396545
Validation loss: 1.7156360200656358

Epoch: 6| Step: 6
Training loss: 0.34004151821136475
Validation loss: 1.738357561890797

Epoch: 6| Step: 7
Training loss: 0.4216305613517761
Validation loss: 1.7767124393934846

Epoch: 6| Step: 8
Training loss: 0.48857414722442627
Validation loss: 1.7672792685929166

Epoch: 6| Step: 9
Training loss: 0.33642616868019104
Validation loss: 1.7625598894652499

Epoch: 6| Step: 10
Training loss: 0.5874312520027161
Validation loss: 1.7331348978063112

Epoch: 6| Step: 11
Training loss: 0.2003370225429535
Validation loss: 1.7257606649911532

Epoch: 6| Step: 12
Training loss: 0.21748000383377075
Validation loss: 1.7363870925800775

Epoch: 6| Step: 13
Training loss: 0.26573446393013
Validation loss: 1.7391340976120324

Epoch: 307| Step: 0
Training loss: 0.3537038564682007
Validation loss: 1.7238736639740646

Epoch: 6| Step: 1
Training loss: 0.39918097853660583
Validation loss: 1.7186250686645508

Epoch: 6| Step: 2
Training loss: 0.5835549831390381
Validation loss: 1.7127955985325638

Epoch: 6| Step: 3
Training loss: 0.4432552456855774
Validation loss: 1.7078899709127282

Epoch: 6| Step: 4
Training loss: 0.7975149750709534
Validation loss: 1.6948898197502218

Epoch: 6| Step: 5
Training loss: 0.24495843052864075
Validation loss: 1.7383979417944466

Epoch: 6| Step: 6
Training loss: 0.3062688410282135
Validation loss: 1.6840619989620742

Epoch: 6| Step: 7
Training loss: 0.3079270124435425
Validation loss: 1.703020344498337

Epoch: 6| Step: 8
Training loss: 0.5155473947525024
Validation loss: 1.7431076367696126

Epoch: 6| Step: 9
Training loss: 0.5936073064804077
Validation loss: 1.7717686122463596

Epoch: 6| Step: 10
Training loss: 0.3046594262123108
Validation loss: 1.7468863046297463

Epoch: 6| Step: 11
Training loss: 0.25090858340263367
Validation loss: 1.7593863087315713

Epoch: 6| Step: 12
Training loss: 0.5569115877151489
Validation loss: 1.770469888564079

Epoch: 6| Step: 13
Training loss: 0.7602850198745728
Validation loss: 1.7783850200714604

Epoch: 308| Step: 0
Training loss: 0.37245357036590576
Validation loss: 1.7486958580632364

Epoch: 6| Step: 1
Training loss: 0.21114782989025116
Validation loss: 1.7485275576191563

Epoch: 6| Step: 2
Training loss: 0.570868730545044
Validation loss: 1.7407128298154442

Epoch: 6| Step: 3
Training loss: 0.29419034719467163
Validation loss: 1.740746248152948

Epoch: 6| Step: 4
Training loss: 0.3634222149848938
Validation loss: 1.734766499970549

Epoch: 6| Step: 5
Training loss: 0.4307900071144104
Validation loss: 1.770332528698829

Epoch: 6| Step: 6
Training loss: 0.3503350019454956
Validation loss: 1.7327832252748552

Epoch: 6| Step: 7
Training loss: 0.6033324003219604
Validation loss: 1.7350187147817304

Epoch: 6| Step: 8
Training loss: 0.33418703079223633
Validation loss: 1.6994538807099866

Epoch: 6| Step: 9
Training loss: 0.22454042732715607
Validation loss: 1.709909660841829

Epoch: 6| Step: 10
Training loss: 0.6604100465774536
Validation loss: 1.7137253848455285

Epoch: 6| Step: 11
Training loss: 0.9184896349906921
Validation loss: 1.7334353526433308

Epoch: 6| Step: 12
Training loss: 0.3159775137901306
Validation loss: 1.7421357131773425

Epoch: 6| Step: 13
Training loss: 0.299702525138855
Validation loss: 1.7203933897838797

Epoch: 309| Step: 0
Training loss: 0.2863999307155609
Validation loss: 1.731201220584172

Epoch: 6| Step: 1
Training loss: 0.4262062907218933
Validation loss: 1.726650789219846

Epoch: 6| Step: 2
Training loss: 0.3443431258201599
Validation loss: 1.738717682259057

Epoch: 6| Step: 3
Training loss: 0.49144160747528076
Validation loss: 1.7529281954611502

Epoch: 6| Step: 4
Training loss: 0.18131449818611145
Validation loss: 1.7660050469060098

Epoch: 6| Step: 5
Training loss: 0.3556399643421173
Validation loss: 1.7134741711360153

Epoch: 6| Step: 6
Training loss: 0.3944959044456482
Validation loss: 1.7468720405332503

Epoch: 6| Step: 7
Training loss: 0.7011296153068542
Validation loss: 1.7521263668614049

Epoch: 6| Step: 8
Training loss: 0.5315846800804138
Validation loss: 1.760979462695378

Epoch: 6| Step: 9
Training loss: 0.29288023710250854
Validation loss: 1.7354671480835124

Epoch: 6| Step: 10
Training loss: 0.8954798579216003
Validation loss: 1.733656329493369

Epoch: 6| Step: 11
Training loss: 0.22113090753555298
Validation loss: 1.7308024078287103

Epoch: 6| Step: 12
Training loss: 0.6463063359260559
Validation loss: 1.6999448396826302

Epoch: 6| Step: 13
Training loss: 0.4245917499065399
Validation loss: 1.7065824359975836

Epoch: 310| Step: 0
Training loss: 0.4937906265258789
Validation loss: 1.707706843653033

Epoch: 6| Step: 1
Training loss: 0.22373443841934204
Validation loss: 1.6954340524570917

Epoch: 6| Step: 2
Training loss: 0.4978783130645752
Validation loss: 1.7066522400866273

Epoch: 6| Step: 3
Training loss: 0.32009458541870117
Validation loss: 1.699180677372922

Epoch: 6| Step: 4
Training loss: 0.27186861634254456
Validation loss: 1.707162541727866

Epoch: 6| Step: 5
Training loss: 0.354155570268631
Validation loss: 1.7105637570863128

Epoch: 6| Step: 6
Training loss: 0.5495689511299133
Validation loss: 1.7208456018919587

Epoch: 6| Step: 7
Training loss: 0.3829053044319153
Validation loss: 1.735843079064482

Epoch: 6| Step: 8
Training loss: 0.3162078857421875
Validation loss: 1.7138740311386764

Epoch: 6| Step: 9
Training loss: 0.5972182750701904
Validation loss: 1.770070871999187

Epoch: 6| Step: 10
Training loss: 0.4552353322505951
Validation loss: 1.7846783232945267

Epoch: 6| Step: 11
Training loss: 0.6876710653305054
Validation loss: 1.838173387512084

Epoch: 6| Step: 12
Training loss: 0.6716052889823914
Validation loss: 1.823143861627066

Epoch: 6| Step: 13
Training loss: 0.4521530866622925
Validation loss: 1.797484117169534

Epoch: 311| Step: 0
Training loss: 0.3080722689628601
Validation loss: 1.7954357708654096

Epoch: 6| Step: 1
Training loss: 0.43991145491600037
Validation loss: 1.7894085338038783

Epoch: 6| Step: 2
Training loss: 0.4341456890106201
Validation loss: 1.7877023591790149

Epoch: 6| Step: 3
Training loss: 0.44764959812164307
Validation loss: 1.7493393972355833

Epoch: 6| Step: 4
Training loss: 0.3879883587360382
Validation loss: 1.7322928187667683

Epoch: 6| Step: 5
Training loss: 0.30719512701034546
Validation loss: 1.6967377278112596

Epoch: 6| Step: 6
Training loss: 0.34349191188812256
Validation loss: 1.6713471835659397

Epoch: 6| Step: 7
Training loss: 0.7504351735115051
Validation loss: 1.6871558363719652

Epoch: 6| Step: 8
Training loss: 0.2630273699760437
Validation loss: 1.6676015815427225

Epoch: 6| Step: 9
Training loss: 0.5418200492858887
Validation loss: 1.6735172066637265

Epoch: 6| Step: 10
Training loss: 0.5155011415481567
Validation loss: 1.6789728467182448

Epoch: 6| Step: 11
Training loss: 0.6883702874183655
Validation loss: 1.6759363348766039

Epoch: 6| Step: 12
Training loss: 0.35600024461746216
Validation loss: 1.7079623104423605

Epoch: 6| Step: 13
Training loss: 0.5314457416534424
Validation loss: 1.720135740054551

Epoch: 312| Step: 0
Training loss: 0.578109860420227
Validation loss: 1.7471778879883468

Epoch: 6| Step: 1
Training loss: 0.2771335542201996
Validation loss: 1.746796541316535

Epoch: 6| Step: 2
Training loss: 0.3866567015647888
Validation loss: 1.7951056521425965

Epoch: 6| Step: 3
Training loss: 0.3553248643875122
Validation loss: 1.8001191513512724

Epoch: 6| Step: 4
Training loss: 0.5914931893348694
Validation loss: 1.7996320801396524

Epoch: 6| Step: 5
Training loss: 0.3402581214904785
Validation loss: 1.7467329027832195

Epoch: 6| Step: 6
Training loss: 0.5303434133529663
Validation loss: 1.7332324289506482

Epoch: 6| Step: 7
Training loss: 0.3380679786205292
Validation loss: 1.7018463175783876

Epoch: 6| Step: 8
Training loss: 0.38737183809280396
Validation loss: 1.702647985950593

Epoch: 6| Step: 9
Training loss: 0.5449240803718567
Validation loss: 1.7017201941500428

Epoch: 6| Step: 10
Training loss: 0.24841396510601044
Validation loss: 1.7007089443104242

Epoch: 6| Step: 11
Training loss: 0.5608658790588379
Validation loss: 1.6892715013155373

Epoch: 6| Step: 12
Training loss: 0.26122263073921204
Validation loss: 1.7128257802737656

Epoch: 6| Step: 13
Training loss: 0.5701553821563721
Validation loss: 1.7070219862845637

Epoch: 313| Step: 0
Training loss: 0.5656288862228394
Validation loss: 1.7227902188095996

Epoch: 6| Step: 1
Training loss: 0.4887292683124542
Validation loss: 1.7154672453480382

Epoch: 6| Step: 2
Training loss: 0.1503695547580719
Validation loss: 1.7461803036351358

Epoch: 6| Step: 3
Training loss: 0.38614556193351746
Validation loss: 1.741634350951

Epoch: 6| Step: 4
Training loss: 0.5739744901657104
Validation loss: 1.7656211365935623

Epoch: 6| Step: 5
Training loss: 0.5368841290473938
Validation loss: 1.7526426584489885

Epoch: 6| Step: 6
Training loss: 0.3908587098121643
Validation loss: 1.7442549146631712

Epoch: 6| Step: 7
Training loss: 0.4998249411582947
Validation loss: 1.7503153931710027

Epoch: 6| Step: 8
Training loss: 0.22394931316375732
Validation loss: 1.7228144714909215

Epoch: 6| Step: 9
Training loss: 0.23000021278858185
Validation loss: 1.7148327827453613

Epoch: 6| Step: 10
Training loss: 0.2904369831085205
Validation loss: 1.719370831725418

Epoch: 6| Step: 11
Training loss: 0.4558243453502655
Validation loss: 1.7234746525364537

Epoch: 6| Step: 12
Training loss: 0.532058596611023
Validation loss: 1.7401010720960555

Epoch: 6| Step: 13
Training loss: 0.44349926710128784
Validation loss: 1.7367870961466143

Epoch: 314| Step: 0
Training loss: 0.4720306396484375
Validation loss: 1.7358303851978754

Epoch: 6| Step: 1
Training loss: 0.3866961598396301
Validation loss: 1.7446368189268215

Epoch: 6| Step: 2
Training loss: 0.6639789342880249
Validation loss: 1.7530835392654582

Epoch: 6| Step: 3
Training loss: 0.614024817943573
Validation loss: 1.767002574859127

Epoch: 6| Step: 4
Training loss: 0.5393729209899902
Validation loss: 1.765103029948409

Epoch: 6| Step: 5
Training loss: 0.18243178725242615
Validation loss: 1.7631634204618392

Epoch: 6| Step: 6
Training loss: 0.35171085596084595
Validation loss: 1.7209762168186966

Epoch: 6| Step: 7
Training loss: 0.6042673587799072
Validation loss: 1.7034822625498618

Epoch: 6| Step: 8
Training loss: 0.3248748779296875
Validation loss: 1.6889010321709417

Epoch: 6| Step: 9
Training loss: 0.41831451654434204
Validation loss: 1.7085032668164981

Epoch: 6| Step: 10
Training loss: 0.4636228084564209
Validation loss: 1.6970023160339684

Epoch: 6| Step: 11
Training loss: 0.2657146751880646
Validation loss: 1.7402388011255572

Epoch: 6| Step: 12
Training loss: 0.34597212076187134
Validation loss: 1.737978764759597

Epoch: 6| Step: 13
Training loss: 0.2287011742591858
Validation loss: 1.7606809087978896

Epoch: 315| Step: 0
Training loss: 0.26552456617355347
Validation loss: 1.7930973005551163

Epoch: 6| Step: 1
Training loss: 0.507701575756073
Validation loss: 1.7971280031306769

Epoch: 6| Step: 2
Training loss: 0.6016888618469238
Validation loss: 1.8555160004605529

Epoch: 6| Step: 3
Training loss: 0.19119399785995483
Validation loss: 1.8200881942625968

Epoch: 6| Step: 4
Training loss: 0.788548469543457
Validation loss: 1.834635607657894

Epoch: 6| Step: 5
Training loss: 0.5550190210342407
Validation loss: 1.760184476452489

Epoch: 6| Step: 6
Training loss: 0.11704818904399872
Validation loss: 1.7282087367068055

Epoch: 6| Step: 7
Training loss: 0.5047458410263062
Validation loss: 1.7222401236975065

Epoch: 6| Step: 8
Training loss: 0.1667691320180893
Validation loss: 1.7204208854706056

Epoch: 6| Step: 9
Training loss: 0.4395328164100647
Validation loss: 1.7144329958064581

Epoch: 6| Step: 10
Training loss: 0.49510854482650757
Validation loss: 1.7187482080151957

Epoch: 6| Step: 11
Training loss: 0.37777602672576904
Validation loss: 1.7274758392764675

Epoch: 6| Step: 12
Training loss: 0.8730369806289673
Validation loss: 1.7582105987815446

Epoch: 6| Step: 13
Training loss: 0.3044857084751129
Validation loss: 1.7615510058659378

Epoch: 316| Step: 0
Training loss: 0.6691175699234009
Validation loss: 1.7444953277546873

Epoch: 6| Step: 1
Training loss: 0.29862505197525024
Validation loss: 1.7442634105682373

Epoch: 6| Step: 2
Training loss: 0.20357424020767212
Validation loss: 1.7159315463035338

Epoch: 6| Step: 3
Training loss: 0.3309890627861023
Validation loss: 1.6979726873418337

Epoch: 6| Step: 4
Training loss: 0.33548399806022644
Validation loss: 1.6986586624576199

Epoch: 6| Step: 5
Training loss: 0.4864894151687622
Validation loss: 1.6973425944646199

Epoch: 6| Step: 6
Training loss: 0.1995384693145752
Validation loss: 1.7238770556706253

Epoch: 6| Step: 7
Training loss: 0.4788912534713745
Validation loss: 1.6962851516662105

Epoch: 6| Step: 8
Training loss: 0.8907382488250732
Validation loss: 1.7207782332615187

Epoch: 6| Step: 9
Training loss: 0.13485832512378693
Validation loss: 1.7223360589755479

Epoch: 6| Step: 10
Training loss: 0.6387406587600708
Validation loss: 1.7258761377744778

Epoch: 6| Step: 11
Training loss: 0.7307997941970825
Validation loss: 1.7643538649364183

Epoch: 6| Step: 12
Training loss: 0.3284183144569397
Validation loss: 1.7524788597578644

Epoch: 6| Step: 13
Training loss: 0.11449539661407471
Validation loss: 1.757268233965802

Epoch: 317| Step: 0
Training loss: 0.5801165103912354
Validation loss: 1.8003955297572638

Epoch: 6| Step: 1
Training loss: 0.3904716670513153
Validation loss: 1.782253767854424

Epoch: 6| Step: 2
Training loss: 0.25126913189888
Validation loss: 1.779697601513196

Epoch: 6| Step: 3
Training loss: 0.47769519686698914
Validation loss: 1.7732916147478166

Epoch: 6| Step: 4
Training loss: 0.3306596875190735
Validation loss: 1.7665006396591023

Epoch: 6| Step: 5
Training loss: 0.09373442083597183
Validation loss: 1.754121599658843

Epoch: 6| Step: 6
Training loss: 0.3267161548137665
Validation loss: 1.7559874416679464

Epoch: 6| Step: 7
Training loss: 0.5486609935760498
Validation loss: 1.7653832345880487

Epoch: 6| Step: 8
Training loss: 0.33905500173568726
Validation loss: 1.7050911534217097

Epoch: 6| Step: 9
Training loss: 0.4772856533527374
Validation loss: 1.7440286297951975

Epoch: 6| Step: 10
Training loss: 0.5592128038406372
Validation loss: 1.698231606073277

Epoch: 6| Step: 11
Training loss: 0.26035910844802856
Validation loss: 1.6964095818099154

Epoch: 6| Step: 12
Training loss: 0.4418429732322693
Validation loss: 1.699803117782839

Epoch: 6| Step: 13
Training loss: 0.3960356116294861
Validation loss: 1.682125162052852

Epoch: 318| Step: 0
Training loss: 0.4731360673904419
Validation loss: 1.7232248578020322

Epoch: 6| Step: 1
Training loss: 0.2998548746109009
Validation loss: 1.6889867718501756

Epoch: 6| Step: 2
Training loss: 0.6530658006668091
Validation loss: 1.7121648557724491

Epoch: 6| Step: 3
Training loss: 0.17193353176116943
Validation loss: 1.7238265134954964

Epoch: 6| Step: 4
Training loss: 0.3574819266796112
Validation loss: 1.7178384283537507

Epoch: 6| Step: 5
Training loss: 0.2358933985233307
Validation loss: 1.7038917823504376

Epoch: 6| Step: 6
Training loss: 0.37918999791145325
Validation loss: 1.7223596906149259

Epoch: 6| Step: 7
Training loss: 0.46626296639442444
Validation loss: 1.7110038431741859

Epoch: 6| Step: 8
Training loss: 0.7307488918304443
Validation loss: 1.7290074556104598

Epoch: 6| Step: 9
Training loss: 0.4292864203453064
Validation loss: 1.7261444586579517

Epoch: 6| Step: 10
Training loss: 0.34980103373527527
Validation loss: 1.7355173428853352

Epoch: 6| Step: 11
Training loss: 0.22555896639823914
Validation loss: 1.727591312059792

Epoch: 6| Step: 12
Training loss: 0.3694272041320801
Validation loss: 1.7364583592261038

Epoch: 6| Step: 13
Training loss: 0.6405871510505676
Validation loss: 1.7435390064793248

Epoch: 319| Step: 0
Training loss: 0.28354668617248535
Validation loss: 1.7558928612739808

Epoch: 6| Step: 1
Training loss: 0.3136756420135498
Validation loss: 1.7428950904518046

Epoch: 6| Step: 2
Training loss: 0.3159438967704773
Validation loss: 1.758458577176576

Epoch: 6| Step: 3
Training loss: 0.3650195002555847
Validation loss: 1.7638996506250033

Epoch: 6| Step: 4
Training loss: 0.5172390937805176
Validation loss: 1.7505521466655116

Epoch: 6| Step: 5
Training loss: 0.4921807646751404
Validation loss: 1.7421396881021478

Epoch: 6| Step: 6
Training loss: 0.27030742168426514
Validation loss: 1.7217356158841042

Epoch: 6| Step: 7
Training loss: 0.4770858883857727
Validation loss: 1.6969190835952759

Epoch: 6| Step: 8
Training loss: 0.20364393293857574
Validation loss: 1.711888671562236

Epoch: 6| Step: 9
Training loss: 0.4898598790168762
Validation loss: 1.7443247174703946

Epoch: 6| Step: 10
Training loss: 0.4938138723373413
Validation loss: 1.7261475196448706

Epoch: 6| Step: 11
Training loss: 0.4562336802482605
Validation loss: 1.7099597748889719

Epoch: 6| Step: 12
Training loss: 0.47291749715805054
Validation loss: 1.7114957224938177

Epoch: 6| Step: 13
Training loss: 0.2826378047466278
Validation loss: 1.7155271332751039

Epoch: 320| Step: 0
Training loss: 0.3535480499267578
Validation loss: 1.6846582235828522

Epoch: 6| Step: 1
Training loss: 0.2573661208152771
Validation loss: 1.7152541773293608

Epoch: 6| Step: 2
Training loss: 0.5725612640380859
Validation loss: 1.726134031049667

Epoch: 6| Step: 3
Training loss: 0.3197283446788788
Validation loss: 1.7370500718393633

Epoch: 6| Step: 4
Training loss: 0.2838609218597412
Validation loss: 1.6945222090649348

Epoch: 6| Step: 5
Training loss: 0.5105494260787964
Validation loss: 1.704463399866576

Epoch: 6| Step: 6
Training loss: 0.6516603231430054
Validation loss: 1.7047289033089914

Epoch: 6| Step: 7
Training loss: 0.28697770833969116
Validation loss: 1.7138893553005752

Epoch: 6| Step: 8
Training loss: 0.6191210746765137
Validation loss: 1.7234116664496801

Epoch: 6| Step: 9
Training loss: 0.41903671622276306
Validation loss: 1.789586204354481

Epoch: 6| Step: 10
Training loss: 0.3938394784927368
Validation loss: 1.7994648641155613

Epoch: 6| Step: 11
Training loss: 0.39149031043052673
Validation loss: 1.795021955684949

Epoch: 6| Step: 12
Training loss: 0.2544228136539459
Validation loss: 1.7780885619501914

Epoch: 6| Step: 13
Training loss: 0.3148193955421448
Validation loss: 1.77089258035024

Epoch: 321| Step: 0
Training loss: 0.4539977014064789
Validation loss: 1.7509791543406825

Epoch: 6| Step: 1
Training loss: 0.4706117808818817
Validation loss: 1.6853075271011682

Epoch: 6| Step: 2
Training loss: 0.2745409607887268
Validation loss: 1.7067370824916388

Epoch: 6| Step: 3
Training loss: 0.27208906412124634
Validation loss: 1.703785769401058

Epoch: 6| Step: 4
Training loss: 0.3718380928039551
Validation loss: 1.7001838581536406

Epoch: 6| Step: 5
Training loss: 0.4952084720134735
Validation loss: 1.690300731248753

Epoch: 6| Step: 6
Training loss: 0.5435887575149536
Validation loss: 1.693722677487199

Epoch: 6| Step: 7
Training loss: 0.40058067440986633
Validation loss: 1.701119279348722

Epoch: 6| Step: 8
Training loss: 0.3523460030555725
Validation loss: 1.6909714629573207

Epoch: 6| Step: 9
Training loss: 0.38767898082733154
Validation loss: 1.677389116697414

Epoch: 6| Step: 10
Training loss: 0.1933710277080536
Validation loss: 1.7234000082938903

Epoch: 6| Step: 11
Training loss: 0.27006810903549194
Validation loss: 1.7318784421490085

Epoch: 6| Step: 12
Training loss: 0.35181260108947754
Validation loss: 1.7359753834303988

Epoch: 6| Step: 13
Training loss: 0.45999056100845337
Validation loss: 1.7343920148828977

Epoch: 322| Step: 0
Training loss: 0.45755237340927124
Validation loss: 1.7267084775432464

Epoch: 6| Step: 1
Training loss: 0.2992810010910034
Validation loss: 1.7223297934378348

Epoch: 6| Step: 2
Training loss: 0.335938036441803
Validation loss: 1.7449704498373053

Epoch: 6| Step: 3
Training loss: 0.4890406131744385
Validation loss: 1.7310080758986934

Epoch: 6| Step: 4
Training loss: 0.557127833366394
Validation loss: 1.7218113291648127

Epoch: 6| Step: 5
Training loss: 0.34594982862472534
Validation loss: 1.7460975198335544

Epoch: 6| Step: 6
Training loss: 0.15034469962120056
Validation loss: 1.7314082768655592

Epoch: 6| Step: 7
Training loss: 0.3842371702194214
Validation loss: 1.7514398867084133

Epoch: 6| Step: 8
Training loss: 0.3304879069328308
Validation loss: 1.804292336586983

Epoch: 6| Step: 9
Training loss: 0.3447569012641907
Validation loss: 1.778400400633453

Epoch: 6| Step: 10
Training loss: 0.47883301973342896
Validation loss: 1.7438222387785554

Epoch: 6| Step: 11
Training loss: 0.2672237455844879
Validation loss: 1.7737956931514125

Epoch: 6| Step: 12
Training loss: 0.26417022943496704
Validation loss: 1.7389781141793856

Epoch: 6| Step: 13
Training loss: 0.4222475290298462
Validation loss: 1.79754590219067

Epoch: 323| Step: 0
Training loss: 0.37721532583236694
Validation loss: 1.7713791157609673

Epoch: 6| Step: 1
Training loss: 0.5531259775161743
Validation loss: 1.8032981490576139

Epoch: 6| Step: 2
Training loss: 0.27023035287857056
Validation loss: 1.8001393336121754

Epoch: 6| Step: 3
Training loss: 0.33440062403678894
Validation loss: 1.8151767920422297

Epoch: 6| Step: 4
Training loss: 0.2371407300233841
Validation loss: 1.7897378116525628

Epoch: 6| Step: 5
Training loss: 0.48731479048728943
Validation loss: 1.8075353560909149

Epoch: 6| Step: 6
Training loss: 0.3702235817909241
Validation loss: 1.7861526384148547

Epoch: 6| Step: 7
Training loss: 0.4845549464225769
Validation loss: 1.7672791275926816

Epoch: 6| Step: 8
Training loss: 0.25993025302886963
Validation loss: 1.770976520353748

Epoch: 6| Step: 9
Training loss: 0.30848148465156555
Validation loss: 1.7708048974314043

Epoch: 6| Step: 10
Training loss: 0.5545517206192017
Validation loss: 1.7340720404860794

Epoch: 6| Step: 11
Training loss: 0.40159404277801514
Validation loss: 1.7326330113154587

Epoch: 6| Step: 12
Training loss: 0.27524906396865845
Validation loss: 1.7301612746330999

Epoch: 6| Step: 13
Training loss: 0.1889438033103943
Validation loss: 1.7205062335537327

Epoch: 324| Step: 0
Training loss: 0.29770201444625854
Validation loss: 1.7592695156733196

Epoch: 6| Step: 1
Training loss: 0.5216479301452637
Validation loss: 1.7779737275133851

Epoch: 6| Step: 2
Training loss: 0.45317769050598145
Validation loss: 1.7908243030630133

Epoch: 6| Step: 3
Training loss: 0.29063063859939575
Validation loss: 1.7752388497834564

Epoch: 6| Step: 4
Training loss: 0.4328898787498474
Validation loss: 1.7272337585367181

Epoch: 6| Step: 5
Training loss: 0.5661318898200989
Validation loss: 1.730504402550318

Epoch: 6| Step: 6
Training loss: 0.5869378447532654
Validation loss: 1.7183400828351256

Epoch: 6| Step: 7
Training loss: 0.37951749563217163
Validation loss: 1.7318131949311943

Epoch: 6| Step: 8
Training loss: 0.3926313519477844
Validation loss: 1.7428871957204675

Epoch: 6| Step: 9
Training loss: 0.2753087878227234
Validation loss: 1.7284130729654783

Epoch: 6| Step: 10
Training loss: 0.3045063018798828
Validation loss: 1.735329210117299

Epoch: 6| Step: 11
Training loss: 0.3420683741569519
Validation loss: 1.7346913404362176

Epoch: 6| Step: 12
Training loss: 0.19637271761894226
Validation loss: 1.7630119375003281

Epoch: 6| Step: 13
Training loss: 0.2261752039194107
Validation loss: 1.7571822789407545

Epoch: 325| Step: 0
Training loss: 0.3400021493434906
Validation loss: 1.7739931505213502

Epoch: 6| Step: 1
Training loss: 0.30682799220085144
Validation loss: 1.7756739829176216

Epoch: 6| Step: 2
Training loss: 0.4391475319862366
Validation loss: 1.7594646394893687

Epoch: 6| Step: 3
Training loss: 0.5410898327827454
Validation loss: 1.751917915959512

Epoch: 6| Step: 4
Training loss: 0.09816814959049225
Validation loss: 1.770054401889924

Epoch: 6| Step: 5
Training loss: 0.4504780173301697
Validation loss: 1.7690307017295592

Epoch: 6| Step: 6
Training loss: 0.40565225481987
Validation loss: 1.7738240277895363

Epoch: 6| Step: 7
Training loss: 0.1723259687423706
Validation loss: 1.7727372633513583

Epoch: 6| Step: 8
Training loss: 0.19502736628055573
Validation loss: 1.7595798738541142

Epoch: 6| Step: 9
Training loss: 0.2635897994041443
Validation loss: 1.75111771398975

Epoch: 6| Step: 10
Training loss: 0.49984490871429443
Validation loss: 1.7143566044428016

Epoch: 6| Step: 11
Training loss: 0.5562063455581665
Validation loss: 1.747458666883489

Epoch: 6| Step: 12
Training loss: 0.4555945098400116
Validation loss: 1.723225829421833

Epoch: 6| Step: 13
Training loss: 0.23855572938919067
Validation loss: 1.7604800642177623

Epoch: 326| Step: 0
Training loss: 0.29735416173934937
Validation loss: 1.7725237825865388

Epoch: 6| Step: 1
Training loss: 0.46296900510787964
Validation loss: 1.7895912406265095

Epoch: 6| Step: 2
Training loss: 0.3027839660644531
Validation loss: 1.779029655200179

Epoch: 6| Step: 3
Training loss: 0.2510411739349365
Validation loss: 1.7804661348301878

Epoch: 6| Step: 4
Training loss: 0.31542158126831055
Validation loss: 1.7640231091489074

Epoch: 6| Step: 5
Training loss: 0.41809165477752686
Validation loss: 1.7549345390771025

Epoch: 6| Step: 6
Training loss: 0.32218217849731445
Validation loss: 1.7431356035253054

Epoch: 6| Step: 7
Training loss: 0.2888326644897461
Validation loss: 1.7789978891290643

Epoch: 6| Step: 8
Training loss: 0.4321672022342682
Validation loss: 1.798456161252914

Epoch: 6| Step: 9
Training loss: 0.4570237994194031
Validation loss: 1.7909138125758017

Epoch: 6| Step: 10
Training loss: 0.5531759858131409
Validation loss: 1.7672112654614192

Epoch: 6| Step: 11
Training loss: 0.4087478220462799
Validation loss: 1.769840572469978

Epoch: 6| Step: 12
Training loss: 0.517192542552948
Validation loss: 1.7711286429435975

Epoch: 6| Step: 13
Training loss: 0.0943458154797554
Validation loss: 1.7448984628082604

Epoch: 327| Step: 0
Training loss: 0.2889462113380432
Validation loss: 1.7274633005101194

Epoch: 6| Step: 1
Training loss: 0.3032735586166382
Validation loss: 1.723739743232727

Epoch: 6| Step: 2
Training loss: 0.514275074005127
Validation loss: 1.7011405229568481

Epoch: 6| Step: 3
Training loss: 0.5051102638244629
Validation loss: 1.7005446521184777

Epoch: 6| Step: 4
Training loss: 0.2759758234024048
Validation loss: 1.7311939859902987

Epoch: 6| Step: 5
Training loss: 0.2753463387489319
Validation loss: 1.7007143151375554

Epoch: 6| Step: 6
Training loss: 0.3477526009082794
Validation loss: 1.7037867961391326

Epoch: 6| Step: 7
Training loss: 0.2411295473575592
Validation loss: 1.7256038791389876

Epoch: 6| Step: 8
Training loss: 0.3789322078227997
Validation loss: 1.7359390181879844

Epoch: 6| Step: 9
Training loss: 0.3190300166606903
Validation loss: 1.767360520619218

Epoch: 6| Step: 10
Training loss: 0.6273554563522339
Validation loss: 1.7693614511079685

Epoch: 6| Step: 11
Training loss: 0.47602200508117676
Validation loss: 1.7592602532397035

Epoch: 6| Step: 12
Training loss: 0.20337703824043274
Validation loss: 1.7870025865493282

Epoch: 6| Step: 13
Training loss: 0.16857711970806122
Validation loss: 1.8004766010469007

Epoch: 328| Step: 0
Training loss: 0.5153724551200867
Validation loss: 1.7596050795688425

Epoch: 6| Step: 1
Training loss: 0.6688352823257446
Validation loss: 1.7533824341271513

Epoch: 6| Step: 2
Training loss: 0.12171284109354019
Validation loss: 1.744341799007949

Epoch: 6| Step: 3
Training loss: 0.10133665055036545
Validation loss: 1.727619896652878

Epoch: 6| Step: 4
Training loss: 0.13527870178222656
Validation loss: 1.7222658331676195

Epoch: 6| Step: 5
Training loss: 0.17832127213478088
Validation loss: 1.7089754022577757

Epoch: 6| Step: 6
Training loss: 0.49570488929748535
Validation loss: 1.6785304571992608

Epoch: 6| Step: 7
Training loss: 0.36824119091033936
Validation loss: 1.6801768490063247

Epoch: 6| Step: 8
Training loss: 0.3517458736896515
Validation loss: 1.684206244125161

Epoch: 6| Step: 9
Training loss: 0.6087027788162231
Validation loss: 1.693324004450152

Epoch: 6| Step: 10
Training loss: 0.238745778799057
Validation loss: 1.6973262871465375

Epoch: 6| Step: 11
Training loss: 0.329833060503006
Validation loss: 1.6950119131354875

Epoch: 6| Step: 12
Training loss: 0.2973232865333557
Validation loss: 1.714158546540045

Epoch: 6| Step: 13
Training loss: 0.43438097834587097
Validation loss: 1.692301946301614

Epoch: 329| Step: 0
Training loss: 0.40451881289482117
Validation loss: 1.6749873013906582

Epoch: 6| Step: 1
Training loss: 0.5570145845413208
Validation loss: 1.7015072145769674

Epoch: 6| Step: 2
Training loss: 0.27691650390625
Validation loss: 1.7053186406371414

Epoch: 6| Step: 3
Training loss: 0.2765772342681885
Validation loss: 1.706167192869289

Epoch: 6| Step: 4
Training loss: 0.21237042546272278
Validation loss: 1.6846331550228981

Epoch: 6| Step: 5
Training loss: 0.33628565073013306
Validation loss: 1.7042534351348877

Epoch: 6| Step: 6
Training loss: 0.4503743648529053
Validation loss: 1.741499564980948

Epoch: 6| Step: 7
Training loss: 0.4266859292984009
Validation loss: 1.717248853816781

Epoch: 6| Step: 8
Training loss: 0.4251469373703003
Validation loss: 1.7142563635303127

Epoch: 6| Step: 9
Training loss: 0.18429350852966309
Validation loss: 1.703714055399741

Epoch: 6| Step: 10
Training loss: 0.41134345531463623
Validation loss: 1.6916370007299608

Epoch: 6| Step: 11
Training loss: 0.30749770998954773
Validation loss: 1.707520713088333

Epoch: 6| Step: 12
Training loss: 0.42849624156951904
Validation loss: 1.6798034214204358

Epoch: 6| Step: 13
Training loss: 0.10772588849067688
Validation loss: 1.6944193058116461

Epoch: 330| Step: 0
Training loss: 0.23345497250556946
Validation loss: 1.707208179658459

Epoch: 6| Step: 1
Training loss: 0.42388156056404114
Validation loss: 1.6853341646091913

Epoch: 6| Step: 2
Training loss: 0.2920634150505066
Validation loss: 1.7161699661644556

Epoch: 6| Step: 3
Training loss: 0.49480023980140686
Validation loss: 1.6924624109780917

Epoch: 6| Step: 4
Training loss: 0.2527835965156555
Validation loss: 1.6811243039305492

Epoch: 6| Step: 5
Training loss: 0.3432941436767578
Validation loss: 1.727481621567921

Epoch: 6| Step: 6
Training loss: 0.26249539852142334
Validation loss: 1.7219370411288353

Epoch: 6| Step: 7
Training loss: 0.2672179937362671
Validation loss: 1.7112180135583366

Epoch: 6| Step: 8
Training loss: 0.27215778827667236
Validation loss: 1.7288972754632272

Epoch: 6| Step: 9
Training loss: 0.3672615587711334
Validation loss: 1.7291748023802234

Epoch: 6| Step: 10
Training loss: 0.5912781357765198
Validation loss: 1.720124493363083

Epoch: 6| Step: 11
Training loss: 0.554635763168335
Validation loss: 1.703864679541639

Epoch: 6| Step: 12
Training loss: 0.23430046439170837
Validation loss: 1.7051122662841633

Epoch: 6| Step: 13
Training loss: 0.41091129183769226
Validation loss: 1.7241067219805974

Epoch: 331| Step: 0
Training loss: 0.25220417976379395
Validation loss: 1.7032730502467002

Epoch: 6| Step: 1
Training loss: 0.29636916518211365
Validation loss: 1.7095802093064913

Epoch: 6| Step: 2
Training loss: 0.4360273480415344
Validation loss: 1.7109637760346936

Epoch: 6| Step: 3
Training loss: 0.3044459819793701
Validation loss: 1.7072304576955817

Epoch: 6| Step: 4
Training loss: 0.22318333387374878
Validation loss: 1.7187205412054574

Epoch: 6| Step: 5
Training loss: 0.24516142904758453
Validation loss: 1.7122335164777693

Epoch: 6| Step: 6
Training loss: 0.3921898603439331
Validation loss: 1.7033617778490948

Epoch: 6| Step: 7
Training loss: 0.26905691623687744
Validation loss: 1.696764430692119

Epoch: 6| Step: 8
Training loss: 0.7784701585769653
Validation loss: 1.7211266384329846

Epoch: 6| Step: 9
Training loss: 0.3274030387401581
Validation loss: 1.7011853136042112

Epoch: 6| Step: 10
Training loss: 0.2583051025867462
Validation loss: 1.673083588641177

Epoch: 6| Step: 11
Training loss: 0.3280237913131714
Validation loss: 1.6992675649222506

Epoch: 6| Step: 12
Training loss: 0.4425702691078186
Validation loss: 1.7005829298368065

Epoch: 6| Step: 13
Training loss: 0.2740951478481293
Validation loss: 1.7167777015316872

Epoch: 332| Step: 0
Training loss: 0.36345231533050537
Validation loss: 1.7342304375863844

Epoch: 6| Step: 1
Training loss: 0.10547433793544769
Validation loss: 1.7346972265551168

Epoch: 6| Step: 2
Training loss: 0.44978195428848267
Validation loss: 1.7076345553962133

Epoch: 6| Step: 3
Training loss: 0.38994109630584717
Validation loss: 1.6796170767917429

Epoch: 6| Step: 4
Training loss: 0.08849434554576874
Validation loss: 1.6765567077103483

Epoch: 6| Step: 5
Training loss: 0.46292775869369507
Validation loss: 1.6899357649587816

Epoch: 6| Step: 6
Training loss: 0.4567946195602417
Validation loss: 1.7001711578779324

Epoch: 6| Step: 7
Training loss: 0.5420969724655151
Validation loss: 1.708316138995591

Epoch: 6| Step: 8
Training loss: 0.5644394159317017
Validation loss: 1.666373925824319

Epoch: 6| Step: 9
Training loss: 0.327290803194046
Validation loss: 1.6407015644093996

Epoch: 6| Step: 10
Training loss: 0.4189794659614563
Validation loss: 1.6607960270297142

Epoch: 6| Step: 11
Training loss: 0.33778589963912964
Validation loss: 1.667597968091247

Epoch: 6| Step: 12
Training loss: 0.19360285997390747
Validation loss: 1.6669397033670896

Epoch: 6| Step: 13
Training loss: 0.2716093957424164
Validation loss: 1.672832671032157

Epoch: 333| Step: 0
Training loss: 0.2532476484775543
Validation loss: 1.6529896836127005

Epoch: 6| Step: 1
Training loss: 0.4762120842933655
Validation loss: 1.6693088111057077

Epoch: 6| Step: 2
Training loss: 0.08063627779483795
Validation loss: 1.6362041286242905

Epoch: 6| Step: 3
Training loss: 0.2940373420715332
Validation loss: 1.698897025918448

Epoch: 6| Step: 4
Training loss: 0.4412904381752014
Validation loss: 1.6966343823299612

Epoch: 6| Step: 5
Training loss: 0.44807422161102295
Validation loss: 1.6940055906131704

Epoch: 6| Step: 6
Training loss: 0.16734878718852997
Validation loss: 1.7361222890115553

Epoch: 6| Step: 7
Training loss: 0.3291155695915222
Validation loss: 1.692588536970077

Epoch: 6| Step: 8
Training loss: 0.3725312352180481
Validation loss: 1.69518958240427

Epoch: 6| Step: 9
Training loss: 0.4742659330368042
Validation loss: 1.7155954376343758

Epoch: 6| Step: 10
Training loss: 0.2957398295402527
Validation loss: 1.7083152724850563

Epoch: 6| Step: 11
Training loss: 0.3157341182231903
Validation loss: 1.7078647857071252

Epoch: 6| Step: 12
Training loss: 0.44038015604019165
Validation loss: 1.6966227703197028

Epoch: 6| Step: 13
Training loss: 0.3694727122783661
Validation loss: 1.718244033475076

Epoch: 334| Step: 0
Training loss: 0.32362812757492065
Validation loss: 1.7137430252567414

Epoch: 6| Step: 1
Training loss: 0.435193806886673
Validation loss: 1.6929284231637114

Epoch: 6| Step: 2
Training loss: 0.304675817489624
Validation loss: 1.6632663126914733

Epoch: 6| Step: 3
Training loss: 0.3791700303554535
Validation loss: 1.6814251689500705

Epoch: 6| Step: 4
Training loss: 0.32074153423309326
Validation loss: 1.6490145088523946

Epoch: 6| Step: 5
Training loss: 0.2702590525150299
Validation loss: 1.6917799518954368

Epoch: 6| Step: 6
Training loss: 0.37697723507881165
Validation loss: 1.7154746850331624

Epoch: 6| Step: 7
Training loss: 0.368022084236145
Validation loss: 1.7134276384948401

Epoch: 6| Step: 8
Training loss: 0.2866538465023041
Validation loss: 1.6777652220059467

Epoch: 6| Step: 9
Training loss: 0.47401151061058044
Validation loss: 1.7047852316210348

Epoch: 6| Step: 10
Training loss: 0.2869027853012085
Validation loss: 1.695665003151022

Epoch: 6| Step: 11
Training loss: 0.2576020359992981
Validation loss: 1.6407371874778502

Epoch: 6| Step: 12
Training loss: 0.23327241837978363
Validation loss: 1.6581701604268884

Epoch: 6| Step: 13
Training loss: 0.3100638687610626
Validation loss: 1.6524743841540428

Epoch: 335| Step: 0
Training loss: 0.08863463997840881
Validation loss: 1.678122393546566

Epoch: 6| Step: 1
Training loss: 0.3749772310256958
Validation loss: 1.6720154516158565

Epoch: 6| Step: 2
Training loss: 0.4354264736175537
Validation loss: 1.6768719829538816

Epoch: 6| Step: 3
Training loss: 0.2352185696363449
Validation loss: 1.6758405957170712

Epoch: 6| Step: 4
Training loss: 0.35159415006637573
Validation loss: 1.686012125784351

Epoch: 6| Step: 5
Training loss: 0.6587460041046143
Validation loss: 1.6620930664000972

Epoch: 6| Step: 6
Training loss: 0.16740472614765167
Validation loss: 1.6631877069832177

Epoch: 6| Step: 7
Training loss: 0.30211031436920166
Validation loss: 1.664403179640411

Epoch: 6| Step: 8
Training loss: 0.14004923403263092
Validation loss: 1.638296890002425

Epoch: 6| Step: 9
Training loss: 0.5574141144752502
Validation loss: 1.628712643859207

Epoch: 6| Step: 10
Training loss: 0.5367063283920288
Validation loss: 1.6484971892449163

Epoch: 6| Step: 11
Training loss: 0.36675405502319336
Validation loss: 1.640266401793367

Epoch: 6| Step: 12
Training loss: 0.132766991853714
Validation loss: 1.6431557106715378

Epoch: 6| Step: 13
Training loss: 0.34038230776786804
Validation loss: 1.677250418611752

Epoch: 336| Step: 0
Training loss: 0.238772913813591
Validation loss: 1.684903609496291

Epoch: 6| Step: 1
Training loss: 0.2854174077510834
Validation loss: 1.7121384868057825

Epoch: 6| Step: 2
Training loss: 0.25737637281417847
Validation loss: 1.7169495705635316

Epoch: 6| Step: 3
Training loss: 0.24726873636245728
Validation loss: 1.7029620678194108

Epoch: 6| Step: 4
Training loss: 0.23655074834823608
Validation loss: 1.7200917377266833

Epoch: 6| Step: 5
Training loss: 0.3600267469882965
Validation loss: 1.7360365685596262

Epoch: 6| Step: 6
Training loss: 0.7317606210708618
Validation loss: 1.7450317887849705

Epoch: 6| Step: 7
Training loss: 0.4971628785133362
Validation loss: 1.7535598483136905

Epoch: 6| Step: 8
Training loss: 0.31894803047180176
Validation loss: 1.7798534875274987

Epoch: 6| Step: 9
Training loss: 0.4086601138114929
Validation loss: 1.748220471925633

Epoch: 6| Step: 10
Training loss: 0.33611875772476196
Validation loss: 1.7358929546930457

Epoch: 6| Step: 11
Training loss: 0.1373252123594284
Validation loss: 1.7340057114119172

Epoch: 6| Step: 12
Training loss: 0.2411935031414032
Validation loss: 1.7277498258057462

Epoch: 6| Step: 13
Training loss: 0.4846102297306061
Validation loss: 1.7276002694201726

Epoch: 337| Step: 0
Training loss: 0.2255198061466217
Validation loss: 1.6952352241803241

Epoch: 6| Step: 1
Training loss: 0.2771851420402527
Validation loss: 1.6905848723585888

Epoch: 6| Step: 2
Training loss: 0.2427617609500885
Validation loss: 1.6888499362494356

Epoch: 6| Step: 3
Training loss: 0.48615166544914246
Validation loss: 1.7190530479595225

Epoch: 6| Step: 4
Training loss: 0.1896919161081314
Validation loss: 1.7054518140772337

Epoch: 6| Step: 5
Training loss: 0.4301973581314087
Validation loss: 1.6849619162979947

Epoch: 6| Step: 6
Training loss: 0.23395514488220215
Validation loss: 1.6634767414421163

Epoch: 6| Step: 7
Training loss: 0.34367817640304565
Validation loss: 1.692296197337489

Epoch: 6| Step: 8
Training loss: 0.2674191892147064
Validation loss: 1.6950773577536307

Epoch: 6| Step: 9
Training loss: 0.3007035553455353
Validation loss: 1.6957875195369925

Epoch: 6| Step: 10
Training loss: 0.21460460126399994
Validation loss: 1.7011195741673952

Epoch: 6| Step: 11
Training loss: 0.6778656244277954
Validation loss: 1.7458162064193397

Epoch: 6| Step: 12
Training loss: 0.22550489008426666
Validation loss: 1.751559284425551

Epoch: 6| Step: 13
Training loss: 0.3566478192806244
Validation loss: 1.7209354036597795

Epoch: 338| Step: 0
Training loss: 0.29938575625419617
Validation loss: 1.7272475316960325

Epoch: 6| Step: 1
Training loss: 0.4091509282588959
Validation loss: 1.7090282517094766

Epoch: 6| Step: 2
Training loss: 0.3833059072494507
Validation loss: 1.676212849155549

Epoch: 6| Step: 3
Training loss: 0.3044874668121338
Validation loss: 1.6737977227857035

Epoch: 6| Step: 4
Training loss: 0.4198527932167053
Validation loss: 1.6841672261555989

Epoch: 6| Step: 5
Training loss: 0.3773241341114044
Validation loss: 1.6895089905749086

Epoch: 6| Step: 6
Training loss: 0.3079458177089691
Validation loss: 1.6676252003638976

Epoch: 6| Step: 7
Training loss: 0.2628401219844818
Validation loss: 1.6620887915293376

Epoch: 6| Step: 8
Training loss: 0.2282390296459198
Validation loss: 1.6847425532597367

Epoch: 6| Step: 9
Training loss: 0.22495388984680176
Validation loss: 1.7068504466805408

Epoch: 6| Step: 10
Training loss: 0.31197065114974976
Validation loss: 1.7131711257401334

Epoch: 6| Step: 11
Training loss: 0.2539556324481964
Validation loss: 1.726970091942818

Epoch: 6| Step: 12
Training loss: 0.28095272183418274
Validation loss: 1.7705680144730436

Epoch: 6| Step: 13
Training loss: 0.6541797518730164
Validation loss: 1.7379196395156205

Epoch: 339| Step: 0
Training loss: 0.3396851122379303
Validation loss: 1.7209530677846683

Epoch: 6| Step: 1
Training loss: 0.36462998390197754
Validation loss: 1.7262190785459293

Epoch: 6| Step: 2
Training loss: 0.42282435297966003
Validation loss: 1.7292809870935255

Epoch: 6| Step: 3
Training loss: 0.25816610455513
Validation loss: 1.687160099706342

Epoch: 6| Step: 4
Training loss: 0.25588032603263855
Validation loss: 1.6853588896413003

Epoch: 6| Step: 5
Training loss: 0.1948627233505249
Validation loss: 1.6684747113976428

Epoch: 6| Step: 6
Training loss: 0.3170992136001587
Validation loss: 1.6712574510164158

Epoch: 6| Step: 7
Training loss: 0.4834401309490204
Validation loss: 1.6652637591926

Epoch: 6| Step: 8
Training loss: 0.37659358978271484
Validation loss: 1.6986230252891459

Epoch: 6| Step: 9
Training loss: 0.194865882396698
Validation loss: 1.7125871873671008

Epoch: 6| Step: 10
Training loss: 0.34429875016212463
Validation loss: 1.7333739694728647

Epoch: 6| Step: 11
Training loss: 0.5237188339233398
Validation loss: 1.7295855245282572

Epoch: 6| Step: 12
Training loss: 0.17273440957069397
Validation loss: 1.7306550965514234

Epoch: 6| Step: 13
Training loss: 0.11911047995090485
Validation loss: 1.753932119697653

Epoch: 340| Step: 0
Training loss: 0.2702072262763977
Validation loss: 1.7235455705273537

Epoch: 6| Step: 1
Training loss: 0.19668295979499817
Validation loss: 1.742673498328014

Epoch: 6| Step: 2
Training loss: 0.39314931631088257
Validation loss: 1.7383885255423925

Epoch: 6| Step: 3
Training loss: 0.21021392941474915
Validation loss: 1.7160925487036347

Epoch: 6| Step: 4
Training loss: 0.363275408744812
Validation loss: 1.7063222546731271

Epoch: 6| Step: 5
Training loss: 0.3041353225708008
Validation loss: 1.6814173152369838

Epoch: 6| Step: 6
Training loss: 0.2587507963180542
Validation loss: 1.6961006823406424

Epoch: 6| Step: 7
Training loss: 0.4354861378669739
Validation loss: 1.6722432246772192

Epoch: 6| Step: 8
Training loss: 0.23534652590751648
Validation loss: 1.6929007627630746

Epoch: 6| Step: 9
Training loss: 0.2715223431587219
Validation loss: 1.674260631684334

Epoch: 6| Step: 10
Training loss: 0.3588009774684906
Validation loss: 1.685263882401169

Epoch: 6| Step: 11
Training loss: 0.37993839383125305
Validation loss: 1.6772537205808906

Epoch: 6| Step: 12
Training loss: 0.40931612253189087
Validation loss: 1.6634053337958552

Epoch: 6| Step: 13
Training loss: 0.25694847106933594
Validation loss: 1.6535163476902952

Epoch: 341| Step: 0
Training loss: 0.14532296359539032
Validation loss: 1.653729422118074

Epoch: 6| Step: 1
Training loss: 0.1484336256980896
Validation loss: 1.6440094696578158

Epoch: 6| Step: 2
Training loss: 0.36209797859191895
Validation loss: 1.6631000708508235

Epoch: 6| Step: 3
Training loss: 0.3839297294616699
Validation loss: 1.6957850456237793

Epoch: 6| Step: 4
Training loss: 0.4118560552597046
Validation loss: 1.6965291666728195

Epoch: 6| Step: 5
Training loss: 0.3473953306674957
Validation loss: 1.7227441892828992

Epoch: 6| Step: 6
Training loss: 0.6471585631370544
Validation loss: 1.7023398799280967

Epoch: 6| Step: 7
Training loss: 0.3904750645160675
Validation loss: 1.7356435380956179

Epoch: 6| Step: 8
Training loss: 0.38241299986839294
Validation loss: 1.739091436068217

Epoch: 6| Step: 9
Training loss: 0.16499751806259155
Validation loss: 1.7077859909303728

Epoch: 6| Step: 10
Training loss: 0.37194377183914185
Validation loss: 1.720351303777387

Epoch: 6| Step: 11
Training loss: 0.1639239341020584
Validation loss: 1.7108632806808717

Epoch: 6| Step: 12
Training loss: 0.17121940851211548
Validation loss: 1.685681704551943

Epoch: 6| Step: 13
Training loss: 0.08771897852420807
Validation loss: 1.7059956378834222

Epoch: 342| Step: 0
Training loss: 0.3183586299419403
Validation loss: 1.703170568712296

Epoch: 6| Step: 1
Training loss: 0.21386557817459106
Validation loss: 1.7035228372901998

Epoch: 6| Step: 2
Training loss: 0.20926500856876373
Validation loss: 1.718545243304263

Epoch: 6| Step: 3
Training loss: 0.192746102809906
Validation loss: 1.6964276054854035

Epoch: 6| Step: 4
Training loss: 0.39250504970550537
Validation loss: 1.6850181574462562

Epoch: 6| Step: 5
Training loss: 0.3958962559700012
Validation loss: 1.6960098974166378

Epoch: 6| Step: 6
Training loss: 0.3125731647014618
Validation loss: 1.6755739899091824

Epoch: 6| Step: 7
Training loss: 0.25262022018432617
Validation loss: 1.6844135381842171

Epoch: 6| Step: 8
Training loss: 0.20721961557865143
Validation loss: 1.6868537087594309

Epoch: 6| Step: 9
Training loss: 0.2671111822128296
Validation loss: 1.6934411512908114

Epoch: 6| Step: 10
Training loss: 0.29714369773864746
Validation loss: 1.6953208754139562

Epoch: 6| Step: 11
Training loss: 0.6773245334625244
Validation loss: 1.710610774255568

Epoch: 6| Step: 12
Training loss: 0.07243429869413376
Validation loss: 1.7004651113223004

Epoch: 6| Step: 13
Training loss: 0.18784670531749725
Validation loss: 1.7183380524317424

Epoch: 343| Step: 0
Training loss: 0.3879050016403198
Validation loss: 1.7051640569522817

Epoch: 6| Step: 1
Training loss: 0.2331399768590927
Validation loss: 1.7579193076779764

Epoch: 6| Step: 2
Training loss: 0.33551347255706787
Validation loss: 1.7391001280917917

Epoch: 6| Step: 3
Training loss: 0.46289604902267456
Validation loss: 1.7218183355946695

Epoch: 6| Step: 4
Training loss: 0.23592549562454224
Validation loss: 1.707264277242845

Epoch: 6| Step: 5
Training loss: 0.3241039216518402
Validation loss: 1.6741928772259784

Epoch: 6| Step: 6
Training loss: 0.18872450292110443
Validation loss: 1.708952812738316

Epoch: 6| Step: 7
Training loss: 0.24127696454524994
Validation loss: 1.6778741921147993

Epoch: 6| Step: 8
Training loss: 0.18149912357330322
Validation loss: 1.681120208514634

Epoch: 6| Step: 9
Training loss: 0.5179536938667297
Validation loss: 1.6817909761141705

Epoch: 6| Step: 10
Training loss: 0.40641269087791443
Validation loss: 1.7154304827413251

Epoch: 6| Step: 11
Training loss: 0.21768856048583984
Validation loss: 1.6788217636846727

Epoch: 6| Step: 12
Training loss: 0.30122897028923035
Validation loss: 1.6666773038525735

Epoch: 6| Step: 13
Training loss: 0.2189110815525055
Validation loss: 1.6722296476364136

Epoch: 344| Step: 0
Training loss: 0.1761011928319931
Validation loss: 1.6886327035965458

Epoch: 6| Step: 1
Training loss: 0.2752847671508789
Validation loss: 1.6888505604959303

Epoch: 6| Step: 2
Training loss: 0.38517770171165466
Validation loss: 1.7176897679605792

Epoch: 6| Step: 3
Training loss: 0.458197683095932
Validation loss: 1.710264991688472

Epoch: 6| Step: 4
Training loss: 0.41183578968048096
Validation loss: 1.7562591337388562

Epoch: 6| Step: 5
Training loss: 0.1300538331270218
Validation loss: 1.7278624760207308

Epoch: 6| Step: 6
Training loss: 0.6362875699996948
Validation loss: 1.7176118807126117

Epoch: 6| Step: 7
Training loss: 0.08689165115356445
Validation loss: 1.6827848239611554

Epoch: 6| Step: 8
Training loss: 0.28186342120170593
Validation loss: 1.6714675631574405

Epoch: 6| Step: 9
Training loss: 0.27613934874534607
Validation loss: 1.639150591306789

Epoch: 6| Step: 10
Training loss: 0.40695446729660034
Validation loss: 1.6283117584002915

Epoch: 6| Step: 11
Training loss: 0.17728948593139648
Validation loss: 1.6332324897089312

Epoch: 6| Step: 12
Training loss: 0.2693140208721161
Validation loss: 1.6081797871538388

Epoch: 6| Step: 13
Training loss: 0.2211281657218933
Validation loss: 1.6438012507654005

Epoch: 345| Step: 0
Training loss: 0.43385931849479675
Validation loss: 1.6595640810587073

Epoch: 6| Step: 1
Training loss: 0.2620347738265991
Validation loss: 1.6589571660564792

Epoch: 6| Step: 2
Training loss: 0.3316188454627991
Validation loss: 1.650193847635741

Epoch: 6| Step: 3
Training loss: 0.22641459107398987
Validation loss: 1.6718931589075314

Epoch: 6| Step: 4
Training loss: 0.4445313811302185
Validation loss: 1.6864176552782777

Epoch: 6| Step: 5
Training loss: 0.2901957333087921
Validation loss: 1.6859229559539466

Epoch: 6| Step: 6
Training loss: 0.44835078716278076
Validation loss: 1.6862736517383206

Epoch: 6| Step: 7
Training loss: 0.29998332262039185
Validation loss: 1.710067618277765

Epoch: 6| Step: 8
Training loss: 0.23639148473739624
Validation loss: 1.7168159689954532

Epoch: 6| Step: 9
Training loss: 0.24787220358848572
Validation loss: 1.7399556713719522

Epoch: 6| Step: 10
Training loss: 0.37512755393981934
Validation loss: 1.710465669631958

Epoch: 6| Step: 11
Training loss: 0.24525713920593262
Validation loss: 1.7216757420570619

Epoch: 6| Step: 12
Training loss: 0.2964765131473541
Validation loss: 1.7244609376435638

Epoch: 6| Step: 13
Training loss: 0.2591433525085449
Validation loss: 1.7462442946690384

Epoch: 346| Step: 0
Training loss: 0.23682363331317902
Validation loss: 1.7304814707848333

Epoch: 6| Step: 1
Training loss: 0.27708199620246887
Validation loss: 1.7194263191633328

Epoch: 6| Step: 2
Training loss: 0.24525265395641327
Validation loss: 1.7396602220432733

Epoch: 6| Step: 3
Training loss: 0.4525281488895416
Validation loss: 1.7818024619933097

Epoch: 6| Step: 4
Training loss: 0.2021777480840683
Validation loss: 1.7420000260876072

Epoch: 6| Step: 5
Training loss: 0.34772756695747375
Validation loss: 1.742819502789487

Epoch: 6| Step: 6
Training loss: 0.2774852216243744
Validation loss: 1.7355805468815628

Epoch: 6| Step: 7
Training loss: 0.26943260431289673
Validation loss: 1.7359004302691388

Epoch: 6| Step: 8
Training loss: 0.23424132168293
Validation loss: 1.6652271568134267

Epoch: 6| Step: 9
Training loss: 0.6442826986312866
Validation loss: 1.6773612114690966

Epoch: 6| Step: 10
Training loss: 0.4131268858909607
Validation loss: 1.6653849181308542

Epoch: 6| Step: 11
Training loss: 0.3975486159324646
Validation loss: 1.6520981839908067

Epoch: 6| Step: 12
Training loss: 0.3289274573326111
Validation loss: 1.690610921511086

Epoch: 6| Step: 13
Training loss: 0.35485073924064636
Validation loss: 1.6715014275684152

Epoch: 347| Step: 0
Training loss: 0.34275251626968384
Validation loss: 1.7030159081182172

Epoch: 6| Step: 1
Training loss: 0.17565393447875977
Validation loss: 1.6860792252325243

Epoch: 6| Step: 2
Training loss: 0.3403201103210449
Validation loss: 1.6917944838923793

Epoch: 6| Step: 3
Training loss: 0.2685443162918091
Validation loss: 1.664263133079775

Epoch: 6| Step: 4
Training loss: 0.2064828872680664
Validation loss: 1.6778348094673567

Epoch: 6| Step: 5
Training loss: 0.14235714077949524
Validation loss: 1.649396106760989

Epoch: 6| Step: 6
Training loss: 0.3580999970436096
Validation loss: 1.6813069876804148

Epoch: 6| Step: 7
Training loss: 0.14842131733894348
Validation loss: 1.6717355584585538

Epoch: 6| Step: 8
Training loss: 0.4469354748725891
Validation loss: 1.7006061577027844

Epoch: 6| Step: 9
Training loss: 0.27885279059410095
Validation loss: 1.6914977078796716

Epoch: 6| Step: 10
Training loss: 0.3248254656791687
Validation loss: 1.6773242604347967

Epoch: 6| Step: 11
Training loss: 0.35918864607810974
Validation loss: 1.68652517180289

Epoch: 6| Step: 12
Training loss: 0.3251302242279053
Validation loss: 1.6662341881823797

Epoch: 6| Step: 13
Training loss: 0.6153474450111389
Validation loss: 1.6780525279301468

Epoch: 348| Step: 0
Training loss: 0.29131361842155457
Validation loss: 1.6804906245200866

Epoch: 6| Step: 1
Training loss: 0.4404793679714203
Validation loss: 1.686574246293755

Epoch: 6| Step: 2
Training loss: 0.17243945598602295
Validation loss: 1.6919917445028982

Epoch: 6| Step: 3
Training loss: 0.3930598497390747
Validation loss: 1.7216704583937121

Epoch: 6| Step: 4
Training loss: 0.3236618638038635
Validation loss: 1.7118541707274735

Epoch: 6| Step: 5
Training loss: 0.22880758345127106
Validation loss: 1.6617339067561652

Epoch: 6| Step: 6
Training loss: 0.1870773583650589
Validation loss: 1.6929316392508886

Epoch: 6| Step: 7
Training loss: 0.23699703812599182
Validation loss: 1.7083731402633011

Epoch: 6| Step: 8
Training loss: 0.22792109847068787
Validation loss: 1.6681049459724016

Epoch: 6| Step: 9
Training loss: 0.28365325927734375
Validation loss: 1.662617318091854

Epoch: 6| Step: 10
Training loss: 0.36586809158325195
Validation loss: 1.6418858151282034

Epoch: 6| Step: 11
Training loss: 0.23397377133369446
Validation loss: 1.6575960882248417

Epoch: 6| Step: 12
Training loss: 0.19972756505012512
Validation loss: 1.6561695798750846

Epoch: 6| Step: 13
Training loss: 0.4916580617427826
Validation loss: 1.624067941019612

Epoch: 349| Step: 0
Training loss: 0.23014019429683685
Validation loss: 1.6429262366346133

Epoch: 6| Step: 1
Training loss: 0.19335943460464478
Validation loss: 1.6434252326206495

Epoch: 6| Step: 2
Training loss: 0.26797717809677124
Validation loss: 1.6710226074341805

Epoch: 6| Step: 3
Training loss: 0.2573130130767822
Validation loss: 1.6864137649536133

Epoch: 6| Step: 4
Training loss: 0.3759269714355469
Validation loss: 1.70849883684548

Epoch: 6| Step: 5
Training loss: 0.3663432002067566
Validation loss: 1.7162769276608703

Epoch: 6| Step: 6
Training loss: 0.4259905219078064
Validation loss: 1.711658259873749

Epoch: 6| Step: 7
Training loss: 0.3147261142730713
Validation loss: 1.7273563249136812

Epoch: 6| Step: 8
Training loss: 0.16826820373535156
Validation loss: 1.713213089973696

Epoch: 6| Step: 9
Training loss: 0.24342861771583557
Validation loss: 1.67012390013664

Epoch: 6| Step: 10
Training loss: 0.33408409357070923
Validation loss: 1.6603810582109677

Epoch: 6| Step: 11
Training loss: 0.17759011685848236
Validation loss: 1.6647152849422988

Epoch: 6| Step: 12
Training loss: 0.4212660789489746
Validation loss: 1.6613919472181669

Epoch: 6| Step: 13
Training loss: 0.270357221364975
Validation loss: 1.676530981576571

Epoch: 350| Step: 0
Training loss: 0.33006322383880615
Validation loss: 1.6369906189621135

Epoch: 6| Step: 1
Training loss: 0.2765125632286072
Validation loss: 1.665984538293654

Epoch: 6| Step: 2
Training loss: 0.26407963037490845
Validation loss: 1.65304357646614

Epoch: 6| Step: 3
Training loss: 0.18811339139938354
Validation loss: 1.6605944556574668

Epoch: 6| Step: 4
Training loss: 0.20305736362934113
Validation loss: 1.651675110222191

Epoch: 6| Step: 5
Training loss: 0.37781068682670593
Validation loss: 1.652406055440185

Epoch: 6| Step: 6
Training loss: 0.3492204546928406
Validation loss: 1.6737645313303957

Epoch: 6| Step: 7
Training loss: 0.1353074610233307
Validation loss: 1.6831107806133967

Epoch: 6| Step: 8
Training loss: 0.2525472640991211
Validation loss: 1.6480381463163642

Epoch: 6| Step: 9
Training loss: 0.18800382316112518
Validation loss: 1.6815629261796192

Epoch: 6| Step: 10
Training loss: 0.19559313356876373
Validation loss: 1.6820484451068345

Epoch: 6| Step: 11
Training loss: 0.35326170921325684
Validation loss: 1.6893323044623099

Epoch: 6| Step: 12
Training loss: 0.4043838381767273
Validation loss: 1.6850187996382355

Epoch: 6| Step: 13
Training loss: 0.47825539112091064
Validation loss: 1.6903067006859729

Epoch: 351| Step: 0
Training loss: 0.4664100706577301
Validation loss: 1.6919450529160038

Epoch: 6| Step: 1
Training loss: 0.2862074375152588
Validation loss: 1.6922666975246963

Epoch: 6| Step: 2
Training loss: 0.16709750890731812
Validation loss: 1.6999261994515695

Epoch: 6| Step: 3
Training loss: 0.3909800052642822
Validation loss: 1.7099696923327703

Epoch: 6| Step: 4
Training loss: 0.41830864548683167
Validation loss: 1.7333083768044748

Epoch: 6| Step: 5
Training loss: 0.216309055685997
Validation loss: 1.7516815380383564

Epoch: 6| Step: 6
Training loss: 0.26643240451812744
Validation loss: 1.776378922565009

Epoch: 6| Step: 7
Training loss: 0.47013139724731445
Validation loss: 1.770461005549277

Epoch: 6| Step: 8
Training loss: 0.26977601647377014
Validation loss: 1.75298797956077

Epoch: 6| Step: 9
Training loss: 0.3648664355278015
Validation loss: 1.711402129101497

Epoch: 6| Step: 10
Training loss: 0.12290298938751221
Validation loss: 1.7154565434302054

Epoch: 6| Step: 11
Training loss: 0.320069819688797
Validation loss: 1.672175709919263

Epoch: 6| Step: 12
Training loss: 0.2715103328227997
Validation loss: 1.7112023715049989

Epoch: 6| Step: 13
Training loss: 0.19659431278705597
Validation loss: 1.651470233035344

Epoch: 352| Step: 0
Training loss: 0.5794311761856079
Validation loss: 1.653613922416523

Epoch: 6| Step: 1
Training loss: 0.3919474482536316
Validation loss: 1.6453471029958417

Epoch: 6| Step: 2
Training loss: 0.2655913829803467
Validation loss: 1.650167929228916

Epoch: 6| Step: 3
Training loss: 0.2510286867618561
Validation loss: 1.6387883206849456

Epoch: 6| Step: 4
Training loss: 0.20011702179908752
Validation loss: 1.6197410629641624

Epoch: 6| Step: 5
Training loss: 0.3798830509185791
Validation loss: 1.6364634690746185

Epoch: 6| Step: 6
Training loss: 0.33468902111053467
Validation loss: 1.636677780459004

Epoch: 6| Step: 7
Training loss: 0.32705771923065186
Validation loss: 1.6421982780579598

Epoch: 6| Step: 8
Training loss: 0.30993619561195374
Validation loss: 1.6324932562407626

Epoch: 6| Step: 9
Training loss: 0.32296717166900635
Validation loss: 1.6415800471459665

Epoch: 6| Step: 10
Training loss: 0.15774305164813995
Validation loss: 1.6285379343135382

Epoch: 6| Step: 11
Training loss: 0.28767627477645874
Validation loss: 1.639606975740002

Epoch: 6| Step: 12
Training loss: 0.1840318739414215
Validation loss: 1.6583395183727305

Epoch: 6| Step: 13
Training loss: 0.13905301690101624
Validation loss: 1.6686379794151551

Epoch: 353| Step: 0
Training loss: 0.28552281856536865
Validation loss: 1.6739760970556608

Epoch: 6| Step: 1
Training loss: 0.20847465097904205
Validation loss: 1.6760080014505694

Epoch: 6| Step: 2
Training loss: 0.38549745082855225
Validation loss: 1.705374038347634

Epoch: 6| Step: 3
Training loss: 0.35764503479003906
Validation loss: 1.69592410261913

Epoch: 6| Step: 4
Training loss: 0.22698040306568146
Validation loss: 1.693502349238242

Epoch: 6| Step: 5
Training loss: 0.24942269921302795
Validation loss: 1.664573400251327

Epoch: 6| Step: 6
Training loss: 0.23068594932556152
Validation loss: 1.630278161776963

Epoch: 6| Step: 7
Training loss: 0.30282139778137207
Validation loss: 1.6575279069203201

Epoch: 6| Step: 8
Training loss: 0.34421804547309875
Validation loss: 1.6723948896572154

Epoch: 6| Step: 9
Training loss: 0.279546856880188
Validation loss: 1.640649882696008

Epoch: 6| Step: 10
Training loss: 0.3241058886051178
Validation loss: 1.6602419627610074

Epoch: 6| Step: 11
Training loss: 0.21895453333854675
Validation loss: 1.6378626836243497

Epoch: 6| Step: 12
Training loss: 0.29878973960876465
Validation loss: 1.660890019068154

Epoch: 6| Step: 13
Training loss: 0.17668285965919495
Validation loss: 1.6728874368052329

Epoch: 354| Step: 0
Training loss: 0.3086433410644531
Validation loss: 1.6705023755309403

Epoch: 6| Step: 1
Training loss: 0.1913008987903595
Validation loss: 1.692322184962611

Epoch: 6| Step: 2
Training loss: 0.23412111401557922
Validation loss: 1.6783735341923212

Epoch: 6| Step: 3
Training loss: 0.3902047872543335
Validation loss: 1.6996878315043706

Epoch: 6| Step: 4
Training loss: 0.1505899578332901
Validation loss: 1.6918053998742053

Epoch: 6| Step: 5
Training loss: 0.2985454201698303
Validation loss: 1.6556292580020042

Epoch: 6| Step: 6
Training loss: 0.22662866115570068
Validation loss: 1.6717087017592562

Epoch: 6| Step: 7
Training loss: 0.30808722972869873
Validation loss: 1.646025711490262

Epoch: 6| Step: 8
Training loss: 0.47645115852355957
Validation loss: 1.662750215940578

Epoch: 6| Step: 9
Training loss: 0.4199225604534149
Validation loss: 1.6546752965578468

Epoch: 6| Step: 10
Training loss: 0.4700436592102051
Validation loss: 1.639100182440973

Epoch: 6| Step: 11
Training loss: 0.14395254850387573
Validation loss: 1.6331700112230034

Epoch: 6| Step: 12
Training loss: 0.13793319463729858
Validation loss: 1.6637139474191973

Epoch: 6| Step: 13
Training loss: 0.320992112159729
Validation loss: 1.6786722624173729

Epoch: 355| Step: 0
Training loss: 0.16081783175468445
Validation loss: 1.6801901581466838

Epoch: 6| Step: 1
Training loss: 0.17856498062610626
Validation loss: 1.6815120186856998

Epoch: 6| Step: 2
Training loss: 0.3126492500305176
Validation loss: 1.6777431746964813

Epoch: 6| Step: 3
Training loss: 0.20247341692447662
Validation loss: 1.6576329533771803

Epoch: 6| Step: 4
Training loss: 0.2694314420223236
Validation loss: 1.6537350711002146

Epoch: 6| Step: 5
Training loss: 0.19783088564872742
Validation loss: 1.6637673172899472

Epoch: 6| Step: 6
Training loss: 0.45590829849243164
Validation loss: 1.6327207024379442

Epoch: 6| Step: 7
Training loss: 0.23509810864925385
Validation loss: 1.6342862806012552

Epoch: 6| Step: 8
Training loss: 0.2086544781923294
Validation loss: 1.635308793796006

Epoch: 6| Step: 9
Training loss: 0.24821019172668457
Validation loss: 1.6528698654584988

Epoch: 6| Step: 10
Training loss: 0.33726269006729126
Validation loss: 1.6482853017827517

Epoch: 6| Step: 11
Training loss: 0.5740629434585571
Validation loss: 1.655923508828686

Epoch: 6| Step: 12
Training loss: 0.31580355763435364
Validation loss: 1.6962052583694458

Epoch: 6| Step: 13
Training loss: 0.41055309772491455
Validation loss: 1.683233271362961

Epoch: 356| Step: 0
Training loss: 0.2713812291622162
Validation loss: 1.6489554887176843

Epoch: 6| Step: 1
Training loss: 0.18800529837608337
Validation loss: 1.670138434697223

Epoch: 6| Step: 2
Training loss: 0.23076510429382324
Validation loss: 1.652947974461381

Epoch: 6| Step: 3
Training loss: 0.24791009724140167
Validation loss: 1.639592820598233

Epoch: 6| Step: 4
Training loss: 0.46668267250061035
Validation loss: 1.6559379767346125

Epoch: 6| Step: 5
Training loss: 0.34715673327445984
Validation loss: 1.6537818267781248

Epoch: 6| Step: 6
Training loss: 0.23751303553581238
Validation loss: 1.6666645644813456

Epoch: 6| Step: 7
Training loss: 0.3118417263031006
Validation loss: 1.6633498835307297

Epoch: 6| Step: 8
Training loss: 0.303975373506546
Validation loss: 1.701990214727258

Epoch: 6| Step: 9
Training loss: 0.2513132095336914
Validation loss: 1.6852443077230965

Epoch: 6| Step: 10
Training loss: 0.3789769113063812
Validation loss: 1.6662930570622927

Epoch: 6| Step: 11
Training loss: 0.14896520972251892
Validation loss: 1.6195599289350613

Epoch: 6| Step: 12
Training loss: 0.4008205831050873
Validation loss: 1.6639784151507961

Epoch: 6| Step: 13
Training loss: 0.12710046768188477
Validation loss: 1.6281834520319456

Epoch: 357| Step: 0
Training loss: 0.2912837266921997
Validation loss: 1.6416788280651133

Epoch: 6| Step: 1
Training loss: 0.18027211725711823
Validation loss: 1.6264183918635051

Epoch: 6| Step: 2
Training loss: 0.22604307532310486
Validation loss: 1.6453576510952366

Epoch: 6| Step: 3
Training loss: 0.18366627395153046
Validation loss: 1.622604250907898

Epoch: 6| Step: 4
Training loss: 0.2079978585243225
Validation loss: 1.653782965034567

Epoch: 6| Step: 5
Training loss: 0.13596147298812866
Validation loss: 1.639023519331409

Epoch: 6| Step: 6
Training loss: 0.42774346470832825
Validation loss: 1.6396985464198615

Epoch: 6| Step: 7
Training loss: 0.2875187397003174
Validation loss: 1.6545745884218523

Epoch: 6| Step: 8
Training loss: 0.2068568766117096
Validation loss: 1.6570516376085178

Epoch: 6| Step: 9
Training loss: 0.20613515377044678
Validation loss: 1.6597431769935034

Epoch: 6| Step: 10
Training loss: 0.27366214990615845
Validation loss: 1.6845774573664511

Epoch: 6| Step: 11
Training loss: 0.4564440846443176
Validation loss: 1.660406389544087

Epoch: 6| Step: 12
Training loss: 0.32813531160354614
Validation loss: 1.6409490198217414

Epoch: 6| Step: 13
Training loss: 0.5171200633049011
Validation loss: 1.636500230399511

Epoch: 358| Step: 0
Training loss: 0.1682981550693512
Validation loss: 1.6648561211042507

Epoch: 6| Step: 1
Training loss: 0.20247511565685272
Validation loss: 1.6324061245046637

Epoch: 6| Step: 2
Training loss: 0.37767595052719116
Validation loss: 1.6494423868835613

Epoch: 6| Step: 3
Training loss: 0.3853644132614136
Validation loss: 1.6329154929807108

Epoch: 6| Step: 4
Training loss: 0.18029570579528809
Validation loss: 1.6766276987650062

Epoch: 6| Step: 5
Training loss: 0.4771342873573303
Validation loss: 1.663646395488452

Epoch: 6| Step: 6
Training loss: 0.2191215455532074
Validation loss: 1.6819608993427728

Epoch: 6| Step: 7
Training loss: 0.2223358452320099
Validation loss: 1.7105149915141444

Epoch: 6| Step: 8
Training loss: 0.14395156502723694
Validation loss: 1.648882882569426

Epoch: 6| Step: 9
Training loss: 0.2849034070968628
Validation loss: 1.6622187834914013

Epoch: 6| Step: 10
Training loss: 0.13700231909751892
Validation loss: 1.6437229264167048

Epoch: 6| Step: 11
Training loss: 0.1596854031085968
Validation loss: 1.6450594214982883

Epoch: 6| Step: 12
Training loss: 0.25164899230003357
Validation loss: 1.6537591500948834

Epoch: 6| Step: 13
Training loss: 0.5034239888191223
Validation loss: 1.6451708168111823

Epoch: 359| Step: 0
Training loss: 0.23858118057250977
Validation loss: 1.602542600324077

Epoch: 6| Step: 1
Training loss: 0.20152729749679565
Validation loss: 1.633616417966863

Epoch: 6| Step: 2
Training loss: 0.39778077602386475
Validation loss: 1.6224991865055536

Epoch: 6| Step: 3
Training loss: 0.38904327154159546
Validation loss: 1.6464487250133226

Epoch: 6| Step: 4
Training loss: 0.21537601947784424
Validation loss: 1.65934463982941

Epoch: 6| Step: 5
Training loss: 0.24907463788986206
Validation loss: 1.710425776820029

Epoch: 6| Step: 6
Training loss: 0.2253209501504898
Validation loss: 1.6920868760796004

Epoch: 6| Step: 7
Training loss: 0.2916223108768463
Validation loss: 1.7024952801324988

Epoch: 6| Step: 8
Training loss: 0.24368104338645935
Validation loss: 1.6918359187341505

Epoch: 6| Step: 9
Training loss: 0.24041631817817688
Validation loss: 1.6710201796664987

Epoch: 6| Step: 10
Training loss: 0.23912733793258667
Validation loss: 1.6757419288799327

Epoch: 6| Step: 11
Training loss: 0.15865099430084229
Validation loss: 1.7074273401691067

Epoch: 6| Step: 12
Training loss: 0.24213093519210815
Validation loss: 1.6869279171830864

Epoch: 6| Step: 13
Training loss: 0.2812804579734802
Validation loss: 1.688303832084902

Epoch: 360| Step: 0
Training loss: 0.2086828649044037
Validation loss: 1.6779948819068171

Epoch: 6| Step: 1
Training loss: 0.2608422040939331
Validation loss: 1.709641634777028

Epoch: 6| Step: 2
Training loss: 0.19951079785823822
Validation loss: 1.7098332848600162

Epoch: 6| Step: 3
Training loss: 0.2730982303619385
Validation loss: 1.6747093444229455

Epoch: 6| Step: 4
Training loss: 0.3300004005432129
Validation loss: 1.67093228268367

Epoch: 6| Step: 5
Training loss: 0.18262946605682373
Validation loss: 1.6631628262099398

Epoch: 6| Step: 6
Training loss: 0.08199939876794815
Validation loss: 1.6537766507876817

Epoch: 6| Step: 7
Training loss: 0.3152937591075897
Validation loss: 1.6672674943042058

Epoch: 6| Step: 8
Training loss: 0.23844566941261292
Validation loss: 1.6297686394824777

Epoch: 6| Step: 9
Training loss: 0.3876822590827942
Validation loss: 1.6331295108282438

Epoch: 6| Step: 10
Training loss: 0.2021036148071289
Validation loss: 1.6264845966010966

Epoch: 6| Step: 11
Training loss: 0.2685740888118744
Validation loss: 1.6216139229395057

Epoch: 6| Step: 12
Training loss: 0.2808106541633606
Validation loss: 1.6403304235909575

Epoch: 6| Step: 13
Training loss: 0.24240578711032867
Validation loss: 1.65354956734565

Epoch: 361| Step: 0
Training loss: 0.2388448566198349
Validation loss: 1.657354970132151

Epoch: 6| Step: 1
Training loss: 0.34088197350502014
Validation loss: 1.6844051089338077

Epoch: 6| Step: 2
Training loss: 0.1788102686405182
Validation loss: 1.6817163254625054

Epoch: 6| Step: 3
Training loss: 0.21047860383987427
Validation loss: 1.6406484547481741

Epoch: 6| Step: 4
Training loss: 0.21036119759082794
Validation loss: 1.6425438491247033

Epoch: 6| Step: 5
Training loss: 0.1813141107559204
Validation loss: 1.6272201961086643

Epoch: 6| Step: 6
Training loss: 0.13995636999607086
Validation loss: 1.642176551203574

Epoch: 6| Step: 7
Training loss: 0.4628823697566986
Validation loss: 1.62201141542004

Epoch: 6| Step: 8
Training loss: 0.2661874294281006
Validation loss: 1.6476559421067596

Epoch: 6| Step: 9
Training loss: 0.30815446376800537
Validation loss: 1.6504418183398504

Epoch: 6| Step: 10
Training loss: 0.22487041354179382
Validation loss: 1.68797396075341

Epoch: 6| Step: 11
Training loss: 0.2387159764766693
Validation loss: 1.6815099241913005

Epoch: 6| Step: 12
Training loss: 0.32249438762664795
Validation loss: 1.6724278593576083

Epoch: 6| Step: 13
Training loss: 0.310001939535141
Validation loss: 1.652420199045571

Epoch: 362| Step: 0
Training loss: 0.17316797375679016
Validation loss: 1.6734161864044845

Epoch: 6| Step: 1
Training loss: 0.09652356803417206
Validation loss: 1.6540196570017005

Epoch: 6| Step: 2
Training loss: 0.22583043575286865
Validation loss: 1.6970828194772043

Epoch: 6| Step: 3
Training loss: 0.16667571663856506
Validation loss: 1.6508353512774232

Epoch: 6| Step: 4
Training loss: 0.28100189566612244
Validation loss: 1.6682414739362654

Epoch: 6| Step: 5
Training loss: 0.34437161684036255
Validation loss: 1.64132377793712

Epoch: 6| Step: 6
Training loss: 0.3817710876464844
Validation loss: 1.652311932656073

Epoch: 6| Step: 7
Training loss: 0.1647196114063263
Validation loss: 1.652105510875743

Epoch: 6| Step: 8
Training loss: 0.312484472990036
Validation loss: 1.6567857444927256

Epoch: 6| Step: 9
Training loss: 0.3873608708381653
Validation loss: 1.6294095464932021

Epoch: 6| Step: 10
Training loss: 0.17009036242961884
Validation loss: 1.630405564461985

Epoch: 6| Step: 11
Training loss: 0.17533284425735474
Validation loss: 1.6512256591550765

Epoch: 6| Step: 12
Training loss: 0.28155452013015747
Validation loss: 1.6470991219243696

Epoch: 6| Step: 13
Training loss: 0.43311765789985657
Validation loss: 1.6575923222367481

Epoch: 363| Step: 0
Training loss: 0.23852550983428955
Validation loss: 1.6866239399038336

Epoch: 6| Step: 1
Training loss: 0.4246363043785095
Validation loss: 1.6953575598296298

Epoch: 6| Step: 2
Training loss: 0.3159923553466797
Validation loss: 1.6885468626535067

Epoch: 6| Step: 3
Training loss: 0.20729652047157288
Validation loss: 1.7083345010716429

Epoch: 6| Step: 4
Training loss: 0.4420105516910553
Validation loss: 1.7295650564214236

Epoch: 6| Step: 5
Training loss: 0.2098035216331482
Validation loss: 1.701756864465693

Epoch: 6| Step: 6
Training loss: 0.2806229591369629
Validation loss: 1.6906183945235385

Epoch: 6| Step: 7
Training loss: 0.27203235030174255
Validation loss: 1.6774940259995

Epoch: 6| Step: 8
Training loss: 0.23096266388893127
Validation loss: 1.6805904783228391

Epoch: 6| Step: 9
Training loss: 0.24140317738056183
Validation loss: 1.6682585388101556

Epoch: 6| Step: 10
Training loss: 0.2153397798538208
Validation loss: 1.654261758250575

Epoch: 6| Step: 11
Training loss: 0.2512769103050232
Validation loss: 1.6612675792427474

Epoch: 6| Step: 12
Training loss: 0.14957474172115326
Validation loss: 1.6885482572740125

Epoch: 6| Step: 13
Training loss: 0.29641443490982056
Validation loss: 1.6976942734051776

Epoch: 364| Step: 0
Training loss: 0.15983930230140686
Validation loss: 1.6791185525155836

Epoch: 6| Step: 1
Training loss: 0.2618626058101654
Validation loss: 1.6653026444937593

Epoch: 6| Step: 2
Training loss: 0.19376076757907867
Validation loss: 1.660804469098327

Epoch: 6| Step: 3
Training loss: 0.26200971007347107
Validation loss: 1.6454051707380561

Epoch: 6| Step: 4
Training loss: 0.14354485273361206
Validation loss: 1.6287304534707019

Epoch: 6| Step: 5
Training loss: 0.2638813555240631
Validation loss: 1.6154657512582757

Epoch: 6| Step: 6
Training loss: 0.37312471866607666
Validation loss: 1.6212154678119126

Epoch: 6| Step: 7
Training loss: 0.4460328221321106
Validation loss: 1.613013252135246

Epoch: 6| Step: 8
Training loss: 0.22576940059661865
Validation loss: 1.6057229606054162

Epoch: 6| Step: 9
Training loss: 0.2661381661891937
Validation loss: 1.6344933612372285

Epoch: 6| Step: 10
Training loss: 0.3165777027606964
Validation loss: 1.6079987902795114

Epoch: 6| Step: 11
Training loss: 0.2646560072898865
Validation loss: 1.6269129476239603

Epoch: 6| Step: 12
Training loss: 0.22354179620742798
Validation loss: 1.6324989846957627

Epoch: 6| Step: 13
Training loss: 0.13521091639995575
Validation loss: 1.6465064658913562

Epoch: 365| Step: 0
Training loss: 0.39958345890045166
Validation loss: 1.6319676945286412

Epoch: 6| Step: 1
Training loss: 0.3489472270011902
Validation loss: 1.6259106205355736

Epoch: 6| Step: 2
Training loss: 0.21628817915916443
Validation loss: 1.6177479477338894

Epoch: 6| Step: 3
Training loss: 0.15374207496643066
Validation loss: 1.6182023607274538

Epoch: 6| Step: 4
Training loss: 0.1112837940454483
Validation loss: 1.6460185973874983

Epoch: 6| Step: 5
Training loss: 0.21308977901935577
Validation loss: 1.6140223228803245

Epoch: 6| Step: 6
Training loss: 0.25232869386672974
Validation loss: 1.6289048246158067

Epoch: 6| Step: 7
Training loss: 0.23329594731330872
Validation loss: 1.6448711900300876

Epoch: 6| Step: 8
Training loss: 0.3899887800216675
Validation loss: 1.622678820804883

Epoch: 6| Step: 9
Training loss: 0.22985172271728516
Validation loss: 1.6397109159859278

Epoch: 6| Step: 10
Training loss: 0.22280806303024292
Validation loss: 1.6515819552124187

Epoch: 6| Step: 11
Training loss: 0.23158584535121918
Validation loss: 1.6617783782302693

Epoch: 6| Step: 12
Training loss: 0.18653835356235504
Validation loss: 1.6301093909048265

Epoch: 6| Step: 13
Training loss: 0.33659422397613525
Validation loss: 1.6643350842178508

Epoch: 366| Step: 0
Training loss: 0.36451563239097595
Validation loss: 1.6827284456581197

Epoch: 6| Step: 1
Training loss: 0.3386589586734772
Validation loss: 1.6558540123765186

Epoch: 6| Step: 2
Training loss: 0.24714623391628265
Validation loss: 1.6459846272263476

Epoch: 6| Step: 3
Training loss: 0.2974224388599396
Validation loss: 1.6466159487283358

Epoch: 6| Step: 4
Training loss: 0.16230705380439758
Validation loss: 1.6384442403752317

Epoch: 6| Step: 5
Training loss: 0.10385400801897049
Validation loss: 1.641532125011567

Epoch: 6| Step: 6
Training loss: 0.15092453360557556
Validation loss: 1.6415526982276671

Epoch: 6| Step: 7
Training loss: 0.17894943058490753
Validation loss: 1.6345366431820778

Epoch: 6| Step: 8
Training loss: 0.18443778157234192
Validation loss: 1.619794084179786

Epoch: 6| Step: 9
Training loss: 0.10487695038318634
Validation loss: 1.6447140657773582

Epoch: 6| Step: 10
Training loss: 0.18231800198554993
Validation loss: 1.6626505621017948

Epoch: 6| Step: 11
Training loss: 0.11892935633659363
Validation loss: 1.7060173198740969

Epoch: 6| Step: 12
Training loss: 0.4677570164203644
Validation loss: 1.7249714289942095

Epoch: 6| Step: 13
Training loss: 0.28883838653564453
Validation loss: 1.7452116012573242

Epoch: 367| Step: 0
Training loss: 0.2305930107831955
Validation loss: 1.747522695090181

Epoch: 6| Step: 1
Training loss: 0.266878604888916
Validation loss: 1.7419208044646888

Epoch: 6| Step: 2
Training loss: 0.22014307975769043
Validation loss: 1.689626327124975

Epoch: 6| Step: 3
Training loss: 0.15853610634803772
Validation loss: 1.6919270356496174

Epoch: 6| Step: 4
Training loss: 0.2658421993255615
Validation loss: 1.6222830177635275

Epoch: 6| Step: 5
Training loss: 0.1780029982328415
Validation loss: 1.628255287806193

Epoch: 6| Step: 6
Training loss: 0.20702573657035828
Validation loss: 1.6082058298972346

Epoch: 6| Step: 7
Training loss: 0.18635612726211548
Validation loss: 1.6148836253791727

Epoch: 6| Step: 8
Training loss: 0.30360227823257446
Validation loss: 1.6150961101696055

Epoch: 6| Step: 9
Training loss: 0.2965210974216461
Validation loss: 1.6349946683452976

Epoch: 6| Step: 10
Training loss: 0.13949134945869446
Validation loss: 1.6238933699105376

Epoch: 6| Step: 11
Training loss: 0.18803414702415466
Validation loss: 1.6226524076154154

Epoch: 6| Step: 12
Training loss: 0.3809741139411926
Validation loss: 1.6281953511699554

Epoch: 6| Step: 13
Training loss: 0.19629383087158203
Validation loss: 1.634566589068341

Epoch: 368| Step: 0
Training loss: 0.23491308093070984
Validation loss: 1.6394292539165867

Epoch: 6| Step: 1
Training loss: 0.1402636468410492
Validation loss: 1.6430945024695447

Epoch: 6| Step: 2
Training loss: 0.1675567775964737
Validation loss: 1.646496739438785

Epoch: 6| Step: 3
Training loss: 0.191260427236557
Validation loss: 1.6197781870442052

Epoch: 6| Step: 4
Training loss: 0.17237743735313416
Validation loss: 1.6235505983393679

Epoch: 6| Step: 5
Training loss: 0.3553752899169922
Validation loss: 1.6045090126734909

Epoch: 6| Step: 6
Training loss: 0.2512080669403076
Validation loss: 1.611270930177422

Epoch: 6| Step: 7
Training loss: 0.2693735361099243
Validation loss: 1.5995307712144748

Epoch: 6| Step: 8
Training loss: 0.21219302713871002
Validation loss: 1.5925022229071586

Epoch: 6| Step: 9
Training loss: 0.42449039220809937
Validation loss: 1.6138140898878857

Epoch: 6| Step: 10
Training loss: 0.17173169553279877
Validation loss: 1.5778741900638869

Epoch: 6| Step: 11
Training loss: 0.23277616500854492
Validation loss: 1.5920950520423152

Epoch: 6| Step: 12
Training loss: 0.15537434816360474
Validation loss: 1.5769481838390391

Epoch: 6| Step: 13
Training loss: 0.2579927146434784
Validation loss: 1.596236296879348

Epoch: 369| Step: 0
Training loss: 0.21511106193065643
Validation loss: 1.6109349727630615

Epoch: 6| Step: 1
Training loss: 0.1876659244298935
Validation loss: 1.599596567051385

Epoch: 6| Step: 2
Training loss: 0.26373255252838135
Validation loss: 1.6272013533499934

Epoch: 6| Step: 3
Training loss: 0.15235979855060577
Validation loss: 1.653047061735584

Epoch: 6| Step: 4
Training loss: 0.21340233087539673
Validation loss: 1.6556828034821378

Epoch: 6| Step: 5
Training loss: 0.210627019405365
Validation loss: 1.6398663418267363

Epoch: 6| Step: 6
Training loss: 0.3480689525604248
Validation loss: 1.6377232818193332

Epoch: 6| Step: 7
Training loss: 0.24116754531860352
Validation loss: 1.6251788241888887

Epoch: 6| Step: 8
Training loss: 0.13333582878112793
Validation loss: 1.5993134962615145

Epoch: 6| Step: 9
Training loss: 0.21773743629455566
Validation loss: 1.583715167096866

Epoch: 6| Step: 10
Training loss: 0.36360660195350647
Validation loss: 1.5888280022528865

Epoch: 6| Step: 11
Training loss: 0.20524390041828156
Validation loss: 1.5801866996672846

Epoch: 6| Step: 12
Training loss: 0.17292740941047668
Validation loss: 1.600369825158068

Epoch: 6| Step: 13
Training loss: 0.3631388545036316
Validation loss: 1.6064629029202204

Epoch: 370| Step: 0
Training loss: 0.27175742387771606
Validation loss: 1.6209020486441992

Epoch: 6| Step: 1
Training loss: 0.0979245975613594
Validation loss: 1.610082305887694

Epoch: 6| Step: 2
Training loss: 0.22061964869499207
Validation loss: 1.60316050693553

Epoch: 6| Step: 3
Training loss: 0.2058519423007965
Validation loss: 1.6317487109091975

Epoch: 6| Step: 4
Training loss: 0.43094462156295776
Validation loss: 1.645419773235116

Epoch: 6| Step: 5
Training loss: 0.23993733525276184
Validation loss: 1.645527425632682

Epoch: 6| Step: 6
Training loss: 0.4602838456630707
Validation loss: 1.6344806404523953

Epoch: 6| Step: 7
Training loss: 0.14568735659122467
Validation loss: 1.594785173734029

Epoch: 6| Step: 8
Training loss: 0.19270530343055725
Validation loss: 1.616674623181743

Epoch: 6| Step: 9
Training loss: 0.16274967789649963
Validation loss: 1.6086185170758156

Epoch: 6| Step: 10
Training loss: 0.26458442211151123
Validation loss: 1.6307949289198844

Epoch: 6| Step: 11
Training loss: 0.1816573292016983
Validation loss: 1.598865056550631

Epoch: 6| Step: 12
Training loss: 0.21872101724147797
Validation loss: 1.632408186953555

Epoch: 6| Step: 13
Training loss: 0.15614554286003113
Validation loss: 1.6329867275812293

Epoch: 371| Step: 0
Training loss: 0.3825002908706665
Validation loss: 1.6512706664300734

Epoch: 6| Step: 1
Training loss: 0.310818612575531
Validation loss: 1.6440032079655638

Epoch: 6| Step: 2
Training loss: 0.24264708161354065
Validation loss: 1.6668595985699726

Epoch: 6| Step: 3
Training loss: 0.13299712538719177
Validation loss: 1.6788093095184655

Epoch: 6| Step: 4
Training loss: 0.23435693979263306
Validation loss: 1.667790529548481

Epoch: 6| Step: 5
Training loss: 0.21277868747711182
Validation loss: 1.6908031432859358

Epoch: 6| Step: 6
Training loss: 0.11683878302574158
Validation loss: 1.6689543134422713

Epoch: 6| Step: 7
Training loss: 0.4233781695365906
Validation loss: 1.681816542020408

Epoch: 6| Step: 8
Training loss: 0.2939019203186035
Validation loss: 1.6581956840330554

Epoch: 6| Step: 9
Training loss: 0.1212722435593605
Validation loss: 1.6528840372639317

Epoch: 6| Step: 10
Training loss: 0.12528802454471588
Validation loss: 1.6450234113201019

Epoch: 6| Step: 11
Training loss: 0.26039034128189087
Validation loss: 1.657748935043171

Epoch: 6| Step: 12
Training loss: 0.11478962004184723
Validation loss: 1.6382083457003358

Epoch: 6| Step: 13
Training loss: 0.21630631387233734
Validation loss: 1.6256367096336939

Epoch: 372| Step: 0
Training loss: 0.20898211002349854
Validation loss: 1.6369583093991844

Epoch: 6| Step: 1
Training loss: 0.30940544605255127
Validation loss: 1.662618742194227

Epoch: 6| Step: 2
Training loss: 0.2854198217391968
Validation loss: 1.636960744857788

Epoch: 6| Step: 3
Training loss: 0.2341323345899582
Validation loss: 1.6878843461313555

Epoch: 6| Step: 4
Training loss: 0.19291067123413086
Validation loss: 1.6856698233594176

Epoch: 6| Step: 5
Training loss: 0.2190472036600113
Validation loss: 1.696216904988853

Epoch: 6| Step: 6
Training loss: 0.3312581479549408
Validation loss: 1.7063104516716414

Epoch: 6| Step: 7
Training loss: 0.29582810401916504
Validation loss: 1.6695984255883

Epoch: 6| Step: 8
Training loss: 0.23425590991973877
Validation loss: 1.6906952037606189

Epoch: 6| Step: 9
Training loss: 0.2234087735414505
Validation loss: 1.6897364553584848

Epoch: 6| Step: 10
Training loss: 0.28133052587509155
Validation loss: 1.6781087562602053

Epoch: 6| Step: 11
Training loss: 0.3677278757095337
Validation loss: 1.7182705838193175

Epoch: 6| Step: 12
Training loss: 0.2377839982509613
Validation loss: 1.7319605799131497

Epoch: 6| Step: 13
Training loss: 0.2984079122543335
Validation loss: 1.7625711874295307

Epoch: 373| Step: 0
Training loss: 0.2906280755996704
Validation loss: 1.7608101124404578

Epoch: 6| Step: 1
Training loss: 0.3438924252986908
Validation loss: 1.7102452196100706

Epoch: 6| Step: 2
Training loss: 0.14447049796581268
Validation loss: 1.7085155722915486

Epoch: 6| Step: 3
Training loss: 0.18758681416511536
Validation loss: 1.6619617144266765

Epoch: 6| Step: 4
Training loss: 0.2368360310792923
Validation loss: 1.6399390684661044

Epoch: 6| Step: 5
Training loss: 0.26869386434555054
Validation loss: 1.6447440924183014

Epoch: 6| Step: 6
Training loss: 0.2918580174446106
Validation loss: 1.6549525581380373

Epoch: 6| Step: 7
Training loss: 0.4730207324028015
Validation loss: 1.6562924974708146

Epoch: 6| Step: 8
Training loss: 0.5192356109619141
Validation loss: 1.6740320779943978

Epoch: 6| Step: 9
Training loss: 0.2463897317647934
Validation loss: 1.6780689647120814

Epoch: 6| Step: 10
Training loss: 0.40366610884666443
Validation loss: 1.6510191194472774

Epoch: 6| Step: 11
Training loss: 0.12503337860107422
Validation loss: 1.6653611519003426

Epoch: 6| Step: 12
Training loss: 0.35642510652542114
Validation loss: 1.6778719335473993

Epoch: 6| Step: 13
Training loss: 0.3422650098800659
Validation loss: 1.6825194717735372

Epoch: 374| Step: 0
Training loss: 0.22779437899589539
Validation loss: 1.6841898759206135

Epoch: 6| Step: 1
Training loss: 0.17918604612350464
Validation loss: 1.6440735094008907

Epoch: 6| Step: 2
Training loss: 0.21447977423667908
Validation loss: 1.6518153670013591

Epoch: 6| Step: 3
Training loss: 0.24751180410385132
Validation loss: 1.644357256991889

Epoch: 6| Step: 4
Training loss: 0.3409974277019501
Validation loss: 1.6145884965055732

Epoch: 6| Step: 5
Training loss: 0.3111846446990967
Validation loss: 1.6754814091549124

Epoch: 6| Step: 6
Training loss: 0.2846246361732483
Validation loss: 1.6587535155716764

Epoch: 6| Step: 7
Training loss: 0.13528776168823242
Validation loss: 1.7155660211399038

Epoch: 6| Step: 8
Training loss: 0.25839149951934814
Validation loss: 1.7183408173181678

Epoch: 6| Step: 9
Training loss: 0.2343975156545639
Validation loss: 1.7416027515165267

Epoch: 6| Step: 10
Training loss: 0.1679304838180542
Validation loss: 1.7312948319219774

Epoch: 6| Step: 11
Training loss: 0.3036938011646271
Validation loss: 1.6996638236507293

Epoch: 6| Step: 12
Training loss: 0.3234124183654785
Validation loss: 1.724058033317648

Epoch: 6| Step: 13
Training loss: 0.5138499736785889
Validation loss: 1.7040977708755

Epoch: 375| Step: 0
Training loss: 0.24982407689094543
Validation loss: 1.694946878699846

Epoch: 6| Step: 1
Training loss: 0.23288016021251678
Validation loss: 1.6506336555686048

Epoch: 6| Step: 2
Training loss: 0.3155362904071808
Validation loss: 1.6225747357132614

Epoch: 6| Step: 3
Training loss: 0.16690513491630554
Validation loss: 1.650370055629361

Epoch: 6| Step: 4
Training loss: 0.22502979636192322
Validation loss: 1.6634352091820008

Epoch: 6| Step: 5
Training loss: 0.36557847261428833
Validation loss: 1.662493566031097

Epoch: 6| Step: 6
Training loss: 0.14866633713245392
Validation loss: 1.6540628056372366

Epoch: 6| Step: 7
Training loss: 0.290185809135437
Validation loss: 1.6647231989009406

Epoch: 6| Step: 8
Training loss: 0.18321600556373596
Validation loss: 1.6667654001584618

Epoch: 6| Step: 9
Training loss: 0.21621282398700714
Validation loss: 1.6775957179325882

Epoch: 6| Step: 10
Training loss: 0.20085343718528748
Validation loss: 1.6846966256377518

Epoch: 6| Step: 11
Training loss: 0.1528838872909546
Validation loss: 1.6926327713074223

Epoch: 6| Step: 12
Training loss: 0.22324074804782867
Validation loss: 1.6882845714528074

Epoch: 6| Step: 13
Training loss: 0.10868612676858902
Validation loss: 1.6679579724547684

Epoch: 376| Step: 0
Training loss: 0.2670263946056366
Validation loss: 1.6822233289800665

Epoch: 6| Step: 1
Training loss: 0.12206350266933441
Validation loss: 1.6691027789987543

Epoch: 6| Step: 2
Training loss: 0.21863926947116852
Validation loss: 1.6532621088848318

Epoch: 6| Step: 3
Training loss: 0.15232181549072266
Validation loss: 1.6615163908209851

Epoch: 6| Step: 4
Training loss: 0.23532435297966003
Validation loss: 1.614600246952426

Epoch: 6| Step: 5
Training loss: 0.09847994148731232
Validation loss: 1.6519668115082609

Epoch: 6| Step: 6
Training loss: 0.2007109820842743
Validation loss: 1.6413709130338443

Epoch: 6| Step: 7
Training loss: 0.22635003924369812
Validation loss: 1.6395159857247465

Epoch: 6| Step: 8
Training loss: 0.2867845892906189
Validation loss: 1.6659497625084334

Epoch: 6| Step: 9
Training loss: 0.22431857883930206
Validation loss: 1.6747815173159364

Epoch: 6| Step: 10
Training loss: 0.2910268306732178
Validation loss: 1.6771063061170681

Epoch: 6| Step: 11
Training loss: 0.11924050748348236
Validation loss: 1.692610263824463

Epoch: 6| Step: 12
Training loss: 0.19786855578422546
Validation loss: 1.6595126557093796

Epoch: 6| Step: 13
Training loss: 0.5052875280380249
Validation loss: 1.6583019251464515

Epoch: 377| Step: 0
Training loss: 0.21461379528045654
Validation loss: 1.6336445552046581

Epoch: 6| Step: 1
Training loss: 0.1782703995704651
Validation loss: 1.6470920667853406

Epoch: 6| Step: 2
Training loss: 0.1252702921628952
Validation loss: 1.6112756049761208

Epoch: 6| Step: 3
Training loss: 0.18602868914604187
Validation loss: 1.5846106826618154

Epoch: 6| Step: 4
Training loss: 0.14776018261909485
Validation loss: 1.6012088752562

Epoch: 6| Step: 5
Training loss: 0.43662145733833313
Validation loss: 1.5983606115464242

Epoch: 6| Step: 6
Training loss: 0.3711443543434143
Validation loss: 1.5838028923157723

Epoch: 6| Step: 7
Training loss: 0.32726889848709106
Validation loss: 1.6151630788721063

Epoch: 6| Step: 8
Training loss: 0.16765999794006348
Validation loss: 1.610539077430643

Epoch: 6| Step: 9
Training loss: 0.18146803975105286
Validation loss: 1.6505938371022542

Epoch: 6| Step: 10
Training loss: 0.1863548755645752
Validation loss: 1.635195243743158

Epoch: 6| Step: 11
Training loss: 0.1929771602153778
Validation loss: 1.628390348085793

Epoch: 6| Step: 12
Training loss: 0.07856053858995438
Validation loss: 1.6532091632966073

Epoch: 6| Step: 13
Training loss: 0.2856225073337555
Validation loss: 1.6272933842033468

Epoch: 378| Step: 0
Training loss: 0.1333068162202835
Validation loss: 1.6487274362194924

Epoch: 6| Step: 1
Training loss: 0.20801934599876404
Validation loss: 1.6564278205235798

Epoch: 6| Step: 2
Training loss: 0.21111798286437988
Validation loss: 1.657241036815028

Epoch: 6| Step: 3
Training loss: 0.24448883533477783
Validation loss: 1.662550235307345

Epoch: 6| Step: 4
Training loss: 0.2509974241256714
Validation loss: 1.6615860231461064

Epoch: 6| Step: 5
Training loss: 0.20983266830444336
Validation loss: 1.6543375087040726

Epoch: 6| Step: 6
Training loss: 0.18713825941085815
Validation loss: 1.6377661458907589

Epoch: 6| Step: 7
Training loss: 0.21345829963684082
Validation loss: 1.6186362748504968

Epoch: 6| Step: 8
Training loss: 0.1743186116218567
Validation loss: 1.6165677962764617

Epoch: 6| Step: 9
Training loss: 0.3302183151245117
Validation loss: 1.6012513086359987

Epoch: 6| Step: 10
Training loss: 0.34345436096191406
Validation loss: 1.5897455317999727

Epoch: 6| Step: 11
Training loss: 0.245853990316391
Validation loss: 1.6151155733293103

Epoch: 6| Step: 12
Training loss: 0.14534255862236023
Validation loss: 1.6058783210733885

Epoch: 6| Step: 13
Training loss: 0.399896502494812
Validation loss: 1.6241772341471847

Epoch: 379| Step: 0
Training loss: 0.21338702738285065
Validation loss: 1.6853340684726674

Epoch: 6| Step: 1
Training loss: 0.2091614454984665
Validation loss: 1.7317920641232563

Epoch: 6| Step: 2
Training loss: 0.2937690317630768
Validation loss: 1.7273107267195178

Epoch: 6| Step: 3
Training loss: 0.14958640933036804
Validation loss: 1.700724281290526

Epoch: 6| Step: 4
Training loss: 0.3297509551048279
Validation loss: 1.7109614572217386

Epoch: 6| Step: 5
Training loss: 0.14466986060142517
Validation loss: 1.6599193080779044

Epoch: 6| Step: 6
Training loss: 0.2040884792804718
Validation loss: 1.595048414763584

Epoch: 6| Step: 7
Training loss: 0.2891080975532532
Validation loss: 1.5945080595631753

Epoch: 6| Step: 8
Training loss: 0.3282243609428406
Validation loss: 1.5928961756408855

Epoch: 6| Step: 9
Training loss: 0.14532862603664398
Validation loss: 1.5895889843663862

Epoch: 6| Step: 10
Training loss: 0.25433996319770813
Validation loss: 1.6105721073765908

Epoch: 6| Step: 11
Training loss: 0.20091673731803894
Validation loss: 1.6031788882388864

Epoch: 6| Step: 12
Training loss: 0.4962228238582611
Validation loss: 1.584651582984514

Epoch: 6| Step: 13
Training loss: 0.21576093137264252
Validation loss: 1.5755625309482697

Epoch: 380| Step: 0
Training loss: 0.12240780889987946
Validation loss: 1.6175116774856404

Epoch: 6| Step: 1
Training loss: 0.2593410015106201
Validation loss: 1.6208378422644831

Epoch: 6| Step: 2
Training loss: 0.2887152433395386
Validation loss: 1.6171581322147

Epoch: 6| Step: 3
Training loss: 0.20946809649467468
Validation loss: 1.6063644386106921

Epoch: 6| Step: 4
Training loss: 0.09422904253005981
Validation loss: 1.6196616439409153

Epoch: 6| Step: 5
Training loss: 0.3655453026294708
Validation loss: 1.601642188846424

Epoch: 6| Step: 6
Training loss: 0.30524158477783203
Validation loss: 1.5804080117133357

Epoch: 6| Step: 7
Training loss: 0.2232402116060257
Validation loss: 1.5903152881130096

Epoch: 6| Step: 8
Training loss: 0.27593082189559937
Validation loss: 1.5683819888740458

Epoch: 6| Step: 9
Training loss: 0.15801431238651276
Validation loss: 1.5618795412842945

Epoch: 6| Step: 10
Training loss: 0.09810315817594528
Validation loss: 1.5522228799840456

Epoch: 6| Step: 11
Training loss: 0.18602778017520905
Validation loss: 1.5509123007456462

Epoch: 6| Step: 12
Training loss: 0.257484495639801
Validation loss: 1.544872687708947

Epoch: 6| Step: 13
Training loss: 0.2232433408498764
Validation loss: 1.5680790370510471

Epoch: 381| Step: 0
Training loss: 0.14667847752571106
Validation loss: 1.5721155546044792

Epoch: 6| Step: 1
Training loss: 0.14146175980567932
Validation loss: 1.6110520529490646

Epoch: 6| Step: 2
Training loss: 0.1736452281475067
Validation loss: 1.6050327849644486

Epoch: 6| Step: 3
Training loss: 0.1922919750213623
Validation loss: 1.6190837865234704

Epoch: 6| Step: 4
Training loss: 0.2565162181854248
Validation loss: 1.6193399365230272

Epoch: 6| Step: 5
Training loss: 0.1095363050699234
Validation loss: 1.595218736638305

Epoch: 6| Step: 6
Training loss: 0.12411915510892868
Validation loss: 1.5834196229134836

Epoch: 6| Step: 7
Training loss: 0.3355533182621002
Validation loss: 1.571410108638066

Epoch: 6| Step: 8
Training loss: 0.24244911968708038
Validation loss: 1.5733806728034891

Epoch: 6| Step: 9
Training loss: 0.11748521775007248
Validation loss: 1.5814884798501128

Epoch: 6| Step: 10
Training loss: 0.17802926898002625
Validation loss: 1.5711908250726678

Epoch: 6| Step: 11
Training loss: 0.3260255455970764
Validation loss: 1.566403067240151

Epoch: 6| Step: 12
Training loss: 0.2810654640197754
Validation loss: 1.5732047019466278

Epoch: 6| Step: 13
Training loss: 0.5044429302215576
Validation loss: 1.5583543059646443

Epoch: 382| Step: 0
Training loss: 0.17715725302696228
Validation loss: 1.611490531634259

Epoch: 6| Step: 1
Training loss: 0.10827845335006714
Validation loss: 1.6152430144689416

Epoch: 6| Step: 2
Training loss: 0.20997561514377594
Validation loss: 1.6242232502147715

Epoch: 6| Step: 3
Training loss: 0.21934117376804352
Validation loss: 1.6284298178970174

Epoch: 6| Step: 4
Training loss: 0.23149190843105316
Validation loss: 1.6315928838586296

Epoch: 6| Step: 5
Training loss: 0.23047232627868652
Validation loss: 1.5938476747082126

Epoch: 6| Step: 6
Training loss: 0.18291249871253967
Validation loss: 1.60302173706793

Epoch: 6| Step: 7
Training loss: 0.20464152097702026
Validation loss: 1.5877007207562845

Epoch: 6| Step: 8
Training loss: 0.10596942901611328
Validation loss: 1.6036256744015602

Epoch: 6| Step: 9
Training loss: 0.11312419921159744
Validation loss: 1.6121134745177401

Epoch: 6| Step: 10
Training loss: 0.3513846695423126
Validation loss: 1.5951621519621981

Epoch: 6| Step: 11
Training loss: 0.3523072600364685
Validation loss: 1.599583456593175

Epoch: 6| Step: 12
Training loss: 0.22087545692920685
Validation loss: 1.6079831905262445

Epoch: 6| Step: 13
Training loss: 0.16835714876651764
Validation loss: 1.6167415124113842

Epoch: 383| Step: 0
Training loss: 0.18750381469726562
Validation loss: 1.6217770730295489

Epoch: 6| Step: 1
Training loss: 0.4656640589237213
Validation loss: 1.6386608103270173

Epoch: 6| Step: 2
Training loss: 0.05649721994996071
Validation loss: 1.6344558397928874

Epoch: 6| Step: 3
Training loss: 0.21163047850131989
Validation loss: 1.6108128088776783

Epoch: 6| Step: 4
Training loss: 0.1923362910747528
Validation loss: 1.6023312627628286

Epoch: 6| Step: 5
Training loss: 0.059727735817432404
Validation loss: 1.5897027010558753

Epoch: 6| Step: 6
Training loss: 0.14795303344726562
Validation loss: 1.6094337413387914

Epoch: 6| Step: 7
Training loss: 0.12170907109975815
Validation loss: 1.5871623203318606

Epoch: 6| Step: 8
Training loss: 0.19670531153678894
Validation loss: 1.5791039646312754

Epoch: 6| Step: 9
Training loss: 0.271677702665329
Validation loss: 1.5897635618845622

Epoch: 6| Step: 10
Training loss: 0.21683752536773682
Validation loss: 1.6257666093046947

Epoch: 6| Step: 11
Training loss: 0.23916825652122498
Validation loss: 1.6023013771221202

Epoch: 6| Step: 12
Training loss: 0.07673139870166779
Validation loss: 1.6303803677199988

Epoch: 6| Step: 13
Training loss: 0.2957410514354706
Validation loss: 1.6465132518481183

Epoch: 384| Step: 0
Training loss: 0.23557642102241516
Validation loss: 1.675831171774095

Epoch: 6| Step: 1
Training loss: 0.24596059322357178
Validation loss: 1.6447501746557092

Epoch: 6| Step: 2
Training loss: 0.23953726887702942
Validation loss: 1.6630308743446105

Epoch: 6| Step: 3
Training loss: 0.1997247040271759
Validation loss: 1.6526037313604867

Epoch: 6| Step: 4
Training loss: 0.1287125200033188
Validation loss: 1.6582352794626707

Epoch: 6| Step: 5
Training loss: 0.2832646071910858
Validation loss: 1.629215484024376

Epoch: 6| Step: 6
Training loss: 0.1958935409784317
Validation loss: 1.6432434487086471

Epoch: 6| Step: 7
Training loss: 0.3442886769771576
Validation loss: 1.6181869929836643

Epoch: 6| Step: 8
Training loss: 0.10424679517745972
Validation loss: 1.6131549137894825

Epoch: 6| Step: 9
Training loss: 0.09585361182689667
Validation loss: 1.6369803643995715

Epoch: 6| Step: 10
Training loss: 0.1998308300971985
Validation loss: 1.6201905037767144

Epoch: 6| Step: 11
Training loss: 0.14376962184906006
Validation loss: 1.6100435564594884

Epoch: 6| Step: 12
Training loss: 0.2791242003440857
Validation loss: 1.6426964754699378

Epoch: 6| Step: 13
Training loss: 0.1617971807718277
Validation loss: 1.610667278689723

Epoch: 385| Step: 0
Training loss: 0.20784404873847961
Validation loss: 1.5942204575384817

Epoch: 6| Step: 1
Training loss: 0.19564223289489746
Validation loss: 1.6046219769344534

Epoch: 6| Step: 2
Training loss: 0.22856488823890686
Validation loss: 1.611950493627979

Epoch: 6| Step: 3
Training loss: 0.17486920952796936
Validation loss: 1.610858876218078

Epoch: 6| Step: 4
Training loss: 0.19720911979675293
Validation loss: 1.6150611216022122

Epoch: 6| Step: 5
Training loss: 0.1759270578622818
Validation loss: 1.6103134578274143

Epoch: 6| Step: 6
Training loss: 0.13564498722553253
Validation loss: 1.599916765766759

Epoch: 6| Step: 7
Training loss: 0.3469637334346771
Validation loss: 1.5983785621581539

Epoch: 6| Step: 8
Training loss: 0.1329231858253479
Validation loss: 1.6203512581445838

Epoch: 6| Step: 9
Training loss: 0.12757346034049988
Validation loss: 1.6093820218117005

Epoch: 6| Step: 10
Training loss: 0.11374673992395401
Validation loss: 1.6348158710746354

Epoch: 6| Step: 11
Training loss: 0.3811875581741333
Validation loss: 1.6210256725229242

Epoch: 6| Step: 12
Training loss: 0.19316944479942322
Validation loss: 1.629677257230205

Epoch: 6| Step: 13
Training loss: 0.17606636881828308
Validation loss: 1.6566529709805724

Epoch: 386| Step: 0
Training loss: 0.0837181881070137
Validation loss: 1.6408028576963691

Epoch: 6| Step: 1
Training loss: 0.2507065236568451
Validation loss: 1.6077418622150217

Epoch: 6| Step: 2
Training loss: 0.1769440919160843
Validation loss: 1.6134916326051116

Epoch: 6| Step: 3
Training loss: 0.2668720483779907
Validation loss: 1.5909464231101416

Epoch: 6| Step: 4
Training loss: 0.2584744691848755
Validation loss: 1.5909298876280427

Epoch: 6| Step: 5
Training loss: 0.17275729775428772
Validation loss: 1.6090292597329745

Epoch: 6| Step: 6
Training loss: 0.2364611178636551
Validation loss: 1.6347618064572733

Epoch: 6| Step: 7
Training loss: 0.20837095379829407
Validation loss: 1.6282519332824215

Epoch: 6| Step: 8
Training loss: 0.17624083161354065
Validation loss: 1.6503542892394527

Epoch: 6| Step: 9
Training loss: 0.29658037424087524
Validation loss: 1.6125191873119724

Epoch: 6| Step: 10
Training loss: 0.13158109784126282
Validation loss: 1.6495654647068312

Epoch: 6| Step: 11
Training loss: 0.2122289389371872
Validation loss: 1.6813445116883965

Epoch: 6| Step: 12
Training loss: 0.3275986909866333
Validation loss: 1.661928907517464

Epoch: 6| Step: 13
Training loss: 0.15837809443473816
Validation loss: 1.6466967931357763

Epoch: 387| Step: 0
Training loss: 0.17484314739704132
Validation loss: 1.6463957371250275

Epoch: 6| Step: 1
Training loss: 0.3035130500793457
Validation loss: 1.61093847597799

Epoch: 6| Step: 2
Training loss: 0.2899126708507538
Validation loss: 1.6754884078938475

Epoch: 6| Step: 3
Training loss: 0.21908605098724365
Validation loss: 1.7021560181853592

Epoch: 6| Step: 4
Training loss: 0.27516672015190125
Validation loss: 1.6393261314720236

Epoch: 6| Step: 5
Training loss: 0.2607560157775879
Validation loss: 1.6463397805408766

Epoch: 6| Step: 6
Training loss: 0.08995935320854187
Validation loss: 1.6507870933061004

Epoch: 6| Step: 7
Training loss: 0.18687322735786438
Validation loss: 1.681518977688205

Epoch: 6| Step: 8
Training loss: 0.32917332649230957
Validation loss: 1.7290847711665656

Epoch: 6| Step: 9
Training loss: 0.18050330877304077
Validation loss: 1.6657598813374836

Epoch: 6| Step: 10
Training loss: 0.35284045338630676
Validation loss: 1.6380919948700936

Epoch: 6| Step: 11
Training loss: 0.17335323989391327
Validation loss: 1.6193808637639528

Epoch: 6| Step: 12
Training loss: 0.2579539120197296
Validation loss: 1.5857992479878087

Epoch: 6| Step: 13
Training loss: 0.1654108613729477
Validation loss: 1.5945466051819503

Epoch: 388| Step: 0
Training loss: 0.22571983933448792
Validation loss: 1.5881047338567755

Epoch: 6| Step: 1
Training loss: 0.27677464485168457
Validation loss: 1.5877118136293145

Epoch: 6| Step: 2
Training loss: 0.32656794786453247
Validation loss: 1.6010067821830831

Epoch: 6| Step: 3
Training loss: 0.13978616893291473
Validation loss: 1.5859011757758357

Epoch: 6| Step: 4
Training loss: 0.19821494817733765
Validation loss: 1.5983715236827891

Epoch: 6| Step: 5
Training loss: 0.25446468591690063
Validation loss: 1.6126594799821095

Epoch: 6| Step: 6
Training loss: 0.2574731707572937
Validation loss: 1.619000204147831

Epoch: 6| Step: 7
Training loss: 0.1492488533258438
Validation loss: 1.592773929719002

Epoch: 6| Step: 8
Training loss: 0.23636841773986816
Validation loss: 1.5771975273727088

Epoch: 6| Step: 9
Training loss: 0.21186582744121552
Validation loss: 1.5922547309629378

Epoch: 6| Step: 10
Training loss: 0.16152162849903107
Validation loss: 1.5963791249900736

Epoch: 6| Step: 11
Training loss: 0.148110494017601
Validation loss: 1.5718475849397722

Epoch: 6| Step: 12
Training loss: 0.14296524226665497
Validation loss: 1.5782058918347923

Epoch: 6| Step: 13
Training loss: 0.22621461749076843
Validation loss: 1.5609079035379554

Epoch: 389| Step: 0
Training loss: 0.25207269191741943
Validation loss: 1.5691761278337049

Epoch: 6| Step: 1
Training loss: 0.25275370478630066
Validation loss: 1.553545626260901

Epoch: 6| Step: 2
Training loss: 0.3358743488788605
Validation loss: 1.5823259353637695

Epoch: 6| Step: 3
Training loss: 0.09390297532081604
Validation loss: 1.5708264189381753

Epoch: 6| Step: 4
Training loss: 0.140732541680336
Validation loss: 1.5851735376542615

Epoch: 6| Step: 5
Training loss: 0.13378937542438507
Validation loss: 1.5602858822832826

Epoch: 6| Step: 6
Training loss: 0.2563045620918274
Validation loss: 1.5944894385594193

Epoch: 6| Step: 7
Training loss: 0.2283717691898346
Validation loss: 1.636571050972067

Epoch: 6| Step: 8
Training loss: 0.32724952697753906
Validation loss: 1.6352505953081193

Epoch: 6| Step: 9
Training loss: 0.0677853673696518
Validation loss: 1.6247774042109007

Epoch: 6| Step: 10
Training loss: 0.15639963746070862
Validation loss: 1.6198439059718963

Epoch: 6| Step: 11
Training loss: 0.15065142512321472
Validation loss: 1.6070350395735873

Epoch: 6| Step: 12
Training loss: 0.24442949891090393
Validation loss: 1.623538109564012

Epoch: 6| Step: 13
Training loss: 0.06791402399539948
Validation loss: 1.6134858169863302

Epoch: 390| Step: 0
Training loss: 0.29459860920906067
Validation loss: 1.6224109267675748

Epoch: 6| Step: 1
Training loss: 0.24651920795440674
Validation loss: 1.6079589102857856

Epoch: 6| Step: 2
Training loss: 0.1325157880783081
Validation loss: 1.6147986970922

Epoch: 6| Step: 3
Training loss: 0.2782217860221863
Validation loss: 1.6069052680846183

Epoch: 6| Step: 4
Training loss: 0.23945128917694092
Validation loss: 1.6126727173405309

Epoch: 6| Step: 5
Training loss: 0.20868657529354095
Validation loss: 1.6163011212502756

Epoch: 6| Step: 6
Training loss: 0.17746421694755554
Validation loss: 1.6128300043844408

Epoch: 6| Step: 7
Training loss: 0.12387902289628983
Validation loss: 1.5993586381276448

Epoch: 6| Step: 8
Training loss: 0.14683829247951508
Validation loss: 1.6089111463997954

Epoch: 6| Step: 9
Training loss: 0.1391448825597763
Validation loss: 1.572184080718666

Epoch: 6| Step: 10
Training loss: 0.14233720302581787
Validation loss: 1.580852391899273

Epoch: 6| Step: 11
Training loss: 0.18326523900032043
Validation loss: 1.5809950303005915

Epoch: 6| Step: 12
Training loss: 0.21329021453857422
Validation loss: 1.5741326783293037

Epoch: 6| Step: 13
Training loss: 0.10525234043598175
Validation loss: 1.5615377733784337

Epoch: 391| Step: 0
Training loss: 0.2099369466304779
Validation loss: 1.5810425460979503

Epoch: 6| Step: 1
Training loss: 0.26833540201187134
Validation loss: 1.5867644612507155

Epoch: 6| Step: 2
Training loss: 0.18092209100723267
Validation loss: 1.5892502505292174

Epoch: 6| Step: 3
Training loss: 0.16485357284545898
Validation loss: 1.620450904292445

Epoch: 6| Step: 4
Training loss: 0.11570854485034943
Validation loss: 1.6038500660209245

Epoch: 6| Step: 5
Training loss: 0.08468742668628693
Validation loss: 1.5965718710294334

Epoch: 6| Step: 6
Training loss: 0.10904529690742493
Validation loss: 1.6046465776299919

Epoch: 6| Step: 7
Training loss: 0.2149590253829956
Validation loss: 1.6401693115952194

Epoch: 6| Step: 8
Training loss: 0.15469270944595337
Validation loss: 1.643826989717381

Epoch: 6| Step: 9
Training loss: 0.3655264377593994
Validation loss: 1.6345278447674167

Epoch: 6| Step: 10
Training loss: 0.20164340734481812
Validation loss: 1.6304851501218733

Epoch: 6| Step: 11
Training loss: 0.23182353377342224
Validation loss: 1.6194677968179025

Epoch: 6| Step: 12
Training loss: 0.26675599813461304
Validation loss: 1.6044359501971994

Epoch: 6| Step: 13
Training loss: 0.14975789189338684
Validation loss: 1.587724047322427

Epoch: 392| Step: 0
Training loss: 0.2436874657869339
Validation loss: 1.606876293818156

Epoch: 6| Step: 1
Training loss: 0.13129180669784546
Validation loss: 1.6038015202809406

Epoch: 6| Step: 2
Training loss: 0.11960490047931671
Validation loss: 1.5882429974053496

Epoch: 6| Step: 3
Training loss: 0.20760558545589447
Validation loss: 1.5771620837591027

Epoch: 6| Step: 4
Training loss: 0.143883615732193
Validation loss: 1.5613356572325512

Epoch: 6| Step: 5
Training loss: 0.1887587010860443
Validation loss: 1.5693011527420373

Epoch: 6| Step: 6
Training loss: 0.3542141020298004
Validation loss: 1.574966166609077

Epoch: 6| Step: 7
Training loss: 0.204668328166008
Validation loss: 1.5796667478417838

Epoch: 6| Step: 8
Training loss: 0.25207939743995667
Validation loss: 1.5937546299349876

Epoch: 6| Step: 9
Training loss: 0.20315435528755188
Validation loss: 1.577673823602738

Epoch: 6| Step: 10
Training loss: 0.2228613644838333
Validation loss: 1.621863184436675

Epoch: 6| Step: 11
Training loss: 0.21734362840652466
Validation loss: 1.6305839425774031

Epoch: 6| Step: 12
Training loss: 0.27946940064430237
Validation loss: 1.6616038891576952

Epoch: 6| Step: 13
Training loss: 0.05975878983736038
Validation loss: 1.635900068026717

Epoch: 393| Step: 0
Training loss: 0.26300472021102905
Validation loss: 1.6251071665876655

Epoch: 6| Step: 1
Training loss: 0.14859038591384888
Validation loss: 1.5985805385856218

Epoch: 6| Step: 2
Training loss: 0.19956821203231812
Validation loss: 1.5908135746114997

Epoch: 6| Step: 3
Training loss: 0.2665979266166687
Validation loss: 1.57960077639549

Epoch: 6| Step: 4
Training loss: 0.34015581011772156
Validation loss: 1.574998632554085

Epoch: 6| Step: 5
Training loss: 0.18827539682388306
Validation loss: 1.5804314215977986

Epoch: 6| Step: 6
Training loss: 0.10839015990495682
Validation loss: 1.5618428504595192

Epoch: 6| Step: 7
Training loss: 0.09045836329460144
Validation loss: 1.577928150853803

Epoch: 6| Step: 8
Training loss: 0.1331951916217804
Validation loss: 1.5716284962110623

Epoch: 6| Step: 9
Training loss: 0.22529500722885132
Validation loss: 1.6362208307430308

Epoch: 6| Step: 10
Training loss: 0.21653473377227783
Validation loss: 1.5969379460939797

Epoch: 6| Step: 11
Training loss: 0.13801677525043488
Validation loss: 1.605277584445092

Epoch: 6| Step: 12
Training loss: 0.21465252339839935
Validation loss: 1.5707132611223447

Epoch: 6| Step: 13
Training loss: 0.1826101541519165
Validation loss: 1.5670818128893453

Epoch: 394| Step: 0
Training loss: 0.15136991441249847
Validation loss: 1.5829547118115168

Epoch: 6| Step: 1
Training loss: 0.17959222197532654
Validation loss: 1.59979332775198

Epoch: 6| Step: 2
Training loss: 0.207918182015419
Validation loss: 1.6188036459748463

Epoch: 6| Step: 3
Training loss: 0.18991681933403015
Validation loss: 1.5693853273186633

Epoch: 6| Step: 4
Training loss: 0.10498165339231491
Validation loss: 1.5847900535470696

Epoch: 6| Step: 5
Training loss: 0.2729650139808655
Validation loss: 1.5844088292890979

Epoch: 6| Step: 6
Training loss: 0.06431984901428223
Validation loss: 1.5891044806408625

Epoch: 6| Step: 7
Training loss: 0.2565380036830902
Validation loss: 1.5947200816164735

Epoch: 6| Step: 8
Training loss: 0.2275243103504181
Validation loss: 1.6181432124107116

Epoch: 6| Step: 9
Training loss: 0.1602049469947815
Validation loss: 1.556089803736697

Epoch: 6| Step: 10
Training loss: 0.136280357837677
Validation loss: 1.5856720965395692

Epoch: 6| Step: 11
Training loss: 0.22070574760437012
Validation loss: 1.551544463762673

Epoch: 6| Step: 12
Training loss: 0.24271945655345917
Validation loss: 1.6151195674814203

Epoch: 6| Step: 13
Training loss: 0.3504106104373932
Validation loss: 1.5646258605423795

Epoch: 395| Step: 0
Training loss: 0.31731536984443665
Validation loss: 1.5849827181908391

Epoch: 6| Step: 1
Training loss: 0.2800583243370056
Validation loss: 1.6039465550453431

Epoch: 6| Step: 2
Training loss: 0.1320870816707611
Validation loss: 1.5990746610908098

Epoch: 6| Step: 3
Training loss: 0.08211119472980499
Validation loss: 1.6061850247844573

Epoch: 6| Step: 4
Training loss: 0.26650822162628174
Validation loss: 1.5905466169439337

Epoch: 6| Step: 5
Training loss: 0.18440775573253632
Validation loss: 1.6173882010162517

Epoch: 6| Step: 6
Training loss: 0.15797899663448334
Validation loss: 1.6432758210807719

Epoch: 6| Step: 7
Training loss: 0.1986340582370758
Validation loss: 1.6238190999595068

Epoch: 6| Step: 8
Training loss: 0.1292630434036255
Validation loss: 1.6190491261020783

Epoch: 6| Step: 9
Training loss: 0.12821455299854279
Validation loss: 1.6255518877378075

Epoch: 6| Step: 10
Training loss: 0.29642897844314575
Validation loss: 1.6126452287038167

Epoch: 6| Step: 11
Training loss: 0.27401259541511536
Validation loss: 1.5918712808239845

Epoch: 6| Step: 12
Training loss: 0.15993061661720276
Validation loss: 1.5964394897542975

Epoch: 6| Step: 13
Training loss: 0.27341631054878235
Validation loss: 1.5861779361642816

Epoch: 396| Step: 0
Training loss: 0.17393705248832703
Validation loss: 1.5947668680580713

Epoch: 6| Step: 1
Training loss: 0.16875062882900238
Validation loss: 1.599272963821247

Epoch: 6| Step: 2
Training loss: 0.22405344247817993
Validation loss: 1.585012516667766

Epoch: 6| Step: 3
Training loss: 0.12805326282978058
Validation loss: 1.5751320059581468

Epoch: 6| Step: 4
Training loss: 0.3044812083244324
Validation loss: 1.5875410187628962

Epoch: 6| Step: 5
Training loss: 0.11663457751274109
Validation loss: 1.6101218884991062

Epoch: 6| Step: 6
Training loss: 0.256446897983551
Validation loss: 1.5849782407924693

Epoch: 6| Step: 7
Training loss: 0.3403036594390869
Validation loss: 1.5981861455466158

Epoch: 6| Step: 8
Training loss: 0.12462301552295685
Validation loss: 1.6172295014063518

Epoch: 6| Step: 9
Training loss: 0.16949838399887085
Validation loss: 1.5984768995674707

Epoch: 6| Step: 10
Training loss: 0.22365014255046844
Validation loss: 1.6123084214425856

Epoch: 6| Step: 11
Training loss: 0.23918750882148743
Validation loss: 1.6040215799885411

Epoch: 6| Step: 12
Training loss: 0.09859173744916916
Validation loss: 1.607341508711538

Epoch: 6| Step: 13
Training loss: 0.21007926762104034
Validation loss: 1.5966117484595186

Epoch: 397| Step: 0
Training loss: 0.12061962485313416
Validation loss: 1.5946281609996673

Epoch: 6| Step: 1
Training loss: 0.19682270288467407
Validation loss: 1.5751993976613528

Epoch: 6| Step: 2
Training loss: 0.11022529006004333
Validation loss: 1.6233270655396164

Epoch: 6| Step: 3
Training loss: 0.355879545211792
Validation loss: 1.590960071932885

Epoch: 6| Step: 4
Training loss: 0.18611615896224976
Validation loss: 1.604447498116442

Epoch: 6| Step: 5
Training loss: 0.35685428977012634
Validation loss: 1.5803449051354521

Epoch: 6| Step: 6
Training loss: 0.15025509893894196
Validation loss: 1.5687016953704178

Epoch: 6| Step: 7
Training loss: 0.2833530306816101
Validation loss: 1.5813507392842283

Epoch: 6| Step: 8
Training loss: 0.16088588535785675
Validation loss: 1.5835234836865497

Epoch: 6| Step: 9
Training loss: 0.15487180650234222
Validation loss: 1.580695048455269

Epoch: 6| Step: 10
Training loss: 0.1857689619064331
Validation loss: 1.5951870795219176

Epoch: 6| Step: 11
Training loss: 0.2169102430343628
Validation loss: 1.5883777551753546

Epoch: 6| Step: 12
Training loss: 0.15081211924552917
Validation loss: 1.5719507125116163

Epoch: 6| Step: 13
Training loss: 0.3047805428504944
Validation loss: 1.5610826835837415

Epoch: 398| Step: 0
Training loss: 0.18496359884738922
Validation loss: 1.544244526534952

Epoch: 6| Step: 1
Training loss: 0.14098404347896576
Validation loss: 1.553770888236261

Epoch: 6| Step: 2
Training loss: 0.13831886649131775
Validation loss: 1.5857876603321364

Epoch: 6| Step: 3
Training loss: 0.47266221046447754
Validation loss: 1.5792918641080138

Epoch: 6| Step: 4
Training loss: 0.16640646755695343
Validation loss: 1.550889233107208

Epoch: 6| Step: 5
Training loss: 0.19595259428024292
Validation loss: 1.5850749425990607

Epoch: 6| Step: 6
Training loss: 0.20111629366874695
Validation loss: 1.6292680860847555

Epoch: 6| Step: 7
Training loss: 0.22697892785072327
Validation loss: 1.6250898427860712

Epoch: 6| Step: 8
Training loss: 0.16557028889656067
Validation loss: 1.6734936480881066

Epoch: 6| Step: 9
Training loss: 0.2634112238883972
Validation loss: 1.6857088150516633

Epoch: 6| Step: 10
Training loss: 0.1567806601524353
Validation loss: 1.6517689035784813

Epoch: 6| Step: 11
Training loss: 0.2764667868614197
Validation loss: 1.6015395925891014

Epoch: 6| Step: 12
Training loss: 0.18889373540878296
Validation loss: 1.6296309476257653

Epoch: 6| Step: 13
Training loss: 0.21534806489944458
Validation loss: 1.6060620264340473

Epoch: 399| Step: 0
Training loss: 0.2523019313812256
Validation loss: 1.6217415102066532

Epoch: 6| Step: 1
Training loss: 0.3357648253440857
Validation loss: 1.6381044105816913

Epoch: 6| Step: 2
Training loss: 0.15436938405036926
Validation loss: 1.6370727150670943

Epoch: 6| Step: 3
Training loss: 0.25018587708473206
Validation loss: 1.6148065469598258

Epoch: 6| Step: 4
Training loss: 0.20743075013160706
Validation loss: 1.6208519076788297

Epoch: 6| Step: 5
Training loss: 0.13145606219768524
Validation loss: 1.6255096684220016

Epoch: 6| Step: 6
Training loss: 0.10940468311309814
Validation loss: 1.6349232414717316

Epoch: 6| Step: 7
Training loss: 0.21749329566955566
Validation loss: 1.6214366856441702

Epoch: 6| Step: 8
Training loss: 0.15372151136398315
Validation loss: 1.616503188686986

Epoch: 6| Step: 9
Training loss: 0.17738588154315948
Validation loss: 1.6127804338291127

Epoch: 6| Step: 10
Training loss: 0.26530539989471436
Validation loss: 1.6277321769345192

Epoch: 6| Step: 11
Training loss: 0.211690753698349
Validation loss: 1.6207920421836197

Epoch: 6| Step: 12
Training loss: 0.11698183417320251
Validation loss: 1.6408022770317652

Epoch: 6| Step: 13
Training loss: 0.065270334482193
Validation loss: 1.6523044391344952

Epoch: 400| Step: 0
Training loss: 0.18847112357616425
Validation loss: 1.6539864091462986

Epoch: 6| Step: 1
Training loss: 0.23649486899375916
Validation loss: 1.6470842040995115

Epoch: 6| Step: 2
Training loss: 0.14837655425071716
Validation loss: 1.625294457199753

Epoch: 6| Step: 3
Training loss: 0.0831802487373352
Validation loss: 1.604990182384368

Epoch: 6| Step: 4
Training loss: 0.1547604352235794
Validation loss: 1.6159768207098848

Epoch: 6| Step: 5
Training loss: 0.2541164755821228
Validation loss: 1.5867298777385423

Epoch: 6| Step: 6
Training loss: 0.20178209245204926
Validation loss: 1.5865233149579776

Epoch: 6| Step: 7
Training loss: 0.1663772165775299
Validation loss: 1.5773405362200994

Epoch: 6| Step: 8
Training loss: 0.1605272889137268
Validation loss: 1.599892129180252

Epoch: 6| Step: 9
Training loss: 0.2176152467727661
Validation loss: 1.5763038384017123

Epoch: 6| Step: 10
Training loss: 0.20377308130264282
Validation loss: 1.619485370574459

Epoch: 6| Step: 11
Training loss: 0.17299285531044006
Validation loss: 1.620828293984936

Epoch: 6| Step: 12
Training loss: 0.23823493719100952
Validation loss: 1.6642738670431159

Epoch: 6| Step: 13
Training loss: 0.39422300457954407
Validation loss: 1.6816165934326828

Epoch: 401| Step: 0
Training loss: 0.20531028509140015
Validation loss: 1.6860578329332414

Epoch: 6| Step: 1
Training loss: 0.2384912669658661
Validation loss: 1.695271211926655

Epoch: 6| Step: 2
Training loss: 0.13982516527175903
Validation loss: 1.6430448934596071

Epoch: 6| Step: 3
Training loss: 0.19037629663944244
Validation loss: 1.617152076895519

Epoch: 6| Step: 4
Training loss: 0.16203820705413818
Validation loss: 1.623690717963762

Epoch: 6| Step: 5
Training loss: 0.15177588164806366
Validation loss: 1.601379079203452

Epoch: 6| Step: 6
Training loss: 0.1939888894557953
Validation loss: 1.6143005791530813

Epoch: 6| Step: 7
Training loss: 0.14122651517391205
Validation loss: 1.598877069770649

Epoch: 6| Step: 8
Training loss: 0.1861775666475296
Validation loss: 1.5956659035016132

Epoch: 6| Step: 9
Training loss: 0.16549396514892578
Validation loss: 1.6102478260635047

Epoch: 6| Step: 10
Training loss: 0.20666538178920746
Validation loss: 1.611180748990787

Epoch: 6| Step: 11
Training loss: 0.14421260356903076
Validation loss: 1.6188221464874923

Epoch: 6| Step: 12
Training loss: 0.322934091091156
Validation loss: 1.6010286910559541

Epoch: 6| Step: 13
Training loss: 0.19874711334705353
Validation loss: 1.602440091871446

Epoch: 402| Step: 0
Training loss: 0.17319118976593018
Validation loss: 1.58441972988908

Epoch: 6| Step: 1
Training loss: 0.15072724223136902
Validation loss: 1.5939321953763244

Epoch: 6| Step: 2
Training loss: 0.09531188011169434
Validation loss: 1.5794553820804884

Epoch: 6| Step: 3
Training loss: 0.1565806269645691
Validation loss: 1.5856795362246934

Epoch: 6| Step: 4
Training loss: 0.13911297917366028
Validation loss: 1.5776605465078866

Epoch: 6| Step: 5
Training loss: 0.2657729387283325
Validation loss: 1.6118065285426315

Epoch: 6| Step: 6
Training loss: 0.12114524841308594
Validation loss: 1.6008660088303268

Epoch: 6| Step: 7
Training loss: 0.21770256757736206
Validation loss: 1.609559848103472

Epoch: 6| Step: 8
Training loss: 0.2581467628479004
Validation loss: 1.6073771958710046

Epoch: 6| Step: 9
Training loss: 0.24916419386863708
Validation loss: 1.6260347161241757

Epoch: 6| Step: 10
Training loss: 0.13525906205177307
Validation loss: 1.6085485553228727

Epoch: 6| Step: 11
Training loss: 0.26277589797973633
Validation loss: 1.5835583235627861

Epoch: 6| Step: 12
Training loss: 0.13772299885749817
Validation loss: 1.584715820127918

Epoch: 6| Step: 13
Training loss: 0.15944348275661469
Validation loss: 1.6010067283466298

Epoch: 403| Step: 0
Training loss: 0.12132921814918518
Validation loss: 1.6003085567105202

Epoch: 6| Step: 1
Training loss: 0.1318059265613556
Validation loss: 1.5831548603632117

Epoch: 6| Step: 2
Training loss: 0.09855765849351883
Validation loss: 1.6005957536799933

Epoch: 6| Step: 3
Training loss: 0.3091401159763336
Validation loss: 1.6079045188042425

Epoch: 6| Step: 4
Training loss: 0.13444800674915314
Validation loss: 1.6319456164554884

Epoch: 6| Step: 5
Training loss: 0.08522740006446838
Validation loss: 1.5991623709278722

Epoch: 6| Step: 6
Training loss: 0.14395061135292053
Validation loss: 1.596928555478332

Epoch: 6| Step: 7
Training loss: 0.21719810366630554
Validation loss: 1.5915306627109487

Epoch: 6| Step: 8
Training loss: 0.20832395553588867
Validation loss: 1.5929163784109137

Epoch: 6| Step: 9
Training loss: 0.26659923791885376
Validation loss: 1.618009110932709

Epoch: 6| Step: 10
Training loss: 0.14530138671398163
Validation loss: 1.6206146337652718

Epoch: 6| Step: 11
Training loss: 0.2948528528213501
Validation loss: 1.704803269396546

Epoch: 6| Step: 12
Training loss: 0.22403821349143982
Validation loss: 1.714199617344846

Epoch: 6| Step: 13
Training loss: 0.4318552613258362
Validation loss: 1.7146189904982043

Epoch: 404| Step: 0
Training loss: 0.16511356830596924
Validation loss: 1.6690023919587493

Epoch: 6| Step: 1
Training loss: 0.19232666492462158
Validation loss: 1.6348274010483936

Epoch: 6| Step: 2
Training loss: 0.2435666173696518
Validation loss: 1.6199265167277346

Epoch: 6| Step: 3
Training loss: 0.17239373922348022
Validation loss: 1.62137560946967

Epoch: 6| Step: 4
Training loss: 0.31363996863365173
Validation loss: 1.6245235461060719

Epoch: 6| Step: 5
Training loss: 0.18288490176200867
Validation loss: 1.6334182946912703

Epoch: 6| Step: 6
Training loss: 0.24318374693393707
Validation loss: 1.6546345064716954

Epoch: 6| Step: 7
Training loss: 0.11969742923974991
Validation loss: 1.6175697042096047

Epoch: 6| Step: 8
Training loss: 0.189711332321167
Validation loss: 1.6264306217111566

Epoch: 6| Step: 9
Training loss: 0.3191608786582947
Validation loss: 1.6259609806922175

Epoch: 6| Step: 10
Training loss: 0.21866723895072937
Validation loss: 1.6264289796993296

Epoch: 6| Step: 11
Training loss: 0.19277746975421906
Validation loss: 1.6283781060608484

Epoch: 6| Step: 12
Training loss: 0.1884797215461731
Validation loss: 1.614678467473676

Epoch: 6| Step: 13
Training loss: 0.15024590492248535
Validation loss: 1.611564406784632

Epoch: 405| Step: 0
Training loss: 0.12348873168230057
Validation loss: 1.6080546981544905

Epoch: 6| Step: 1
Training loss: 0.1739691197872162
Validation loss: 1.5827426006717067

Epoch: 6| Step: 2
Training loss: 0.17799721658229828
Validation loss: 1.603640917808779

Epoch: 6| Step: 3
Training loss: 0.10388606041669846
Validation loss: 1.6367415535834529

Epoch: 6| Step: 4
Training loss: 0.20942679047584534
Validation loss: 1.6060737358626498

Epoch: 6| Step: 5
Training loss: 0.23884284496307373
Validation loss: 1.629069269344371

Epoch: 6| Step: 6
Training loss: 0.5488315224647522
Validation loss: 1.644389662691342

Epoch: 6| Step: 7
Training loss: 0.16913360357284546
Validation loss: 1.6843095543564006

Epoch: 6| Step: 8
Training loss: 0.11652892827987671
Validation loss: 1.6410647540964105

Epoch: 6| Step: 9
Training loss: 0.14306297898292542
Validation loss: 1.6710424577036211

Epoch: 6| Step: 10
Training loss: 0.2700827121734619
Validation loss: 1.6694977360387002

Epoch: 6| Step: 11
Training loss: 0.1740686595439911
Validation loss: 1.593792994817098

Epoch: 6| Step: 12
Training loss: 0.0992218405008316
Validation loss: 1.5985885409898655

Epoch: 6| Step: 13
Training loss: 0.10517501831054688
Validation loss: 1.5861473647497033

Epoch: 406| Step: 0
Training loss: 0.1545131951570511
Validation loss: 1.5855291812650618

Epoch: 6| Step: 1
Training loss: 0.12753623723983765
Validation loss: 1.59614957276211

Epoch: 6| Step: 2
Training loss: 0.2459947168827057
Validation loss: 1.5779819655162033

Epoch: 6| Step: 3
Training loss: 0.23736946284770966
Validation loss: 1.6031996934644637

Epoch: 6| Step: 4
Training loss: 0.2931897044181824
Validation loss: 1.6193307074167396

Epoch: 6| Step: 5
Training loss: 0.21447524428367615
Validation loss: 1.6013509535020398

Epoch: 6| Step: 6
Training loss: 0.21323972940444946
Validation loss: 1.6279428940947338

Epoch: 6| Step: 7
Training loss: 0.20962835848331451
Validation loss: 1.6254547231940812

Epoch: 6| Step: 8
Training loss: 0.21556787192821503
Validation loss: 1.6488097239566106

Epoch: 6| Step: 9
Training loss: 0.21377348899841309
Validation loss: 1.6597891763974262

Epoch: 6| Step: 10
Training loss: 0.16048270463943481
Validation loss: 1.6360734778065835

Epoch: 6| Step: 11
Training loss: 0.1371665596961975
Validation loss: 1.6343427845226821

Epoch: 6| Step: 12
Training loss: 0.23464804887771606
Validation loss: 1.6647155566882061

Epoch: 6| Step: 13
Training loss: 0.12566547095775604
Validation loss: 1.6295106167434363

Epoch: 407| Step: 0
Training loss: 0.23690636456012726
Validation loss: 1.6209474917381042

Epoch: 6| Step: 1
Training loss: 0.12792465090751648
Validation loss: 1.639760527559506

Epoch: 6| Step: 2
Training loss: 0.3381178379058838
Validation loss: 1.6343378200325915

Epoch: 6| Step: 3
Training loss: 0.08494646847248077
Validation loss: 1.6462637262959634

Epoch: 6| Step: 4
Training loss: 0.135687917470932
Validation loss: 1.62020404108109

Epoch: 6| Step: 5
Training loss: 0.0999663844704628
Validation loss: 1.633739435544578

Epoch: 6| Step: 6
Training loss: 0.15605489909648895
Validation loss: 1.6417347308128112

Epoch: 6| Step: 7
Training loss: 0.2125326544046402
Validation loss: 1.5932405712783977

Epoch: 6| Step: 8
Training loss: 0.17428608238697052
Validation loss: 1.6248736163621307

Epoch: 6| Step: 9
Training loss: 0.21926480531692505
Validation loss: 1.6389169769902383

Epoch: 6| Step: 10
Training loss: 0.19546613097190857
Validation loss: 1.6589214391605829

Epoch: 6| Step: 11
Training loss: 0.1801038682460785
Validation loss: 1.63300504479357

Epoch: 6| Step: 12
Training loss: 0.2248821258544922
Validation loss: 1.658101156193723

Epoch: 6| Step: 13
Training loss: 0.12938810884952545
Validation loss: 1.6233421448738343

Epoch: 408| Step: 0
Training loss: 0.2858112156391144
Validation loss: 1.6441987573459584

Epoch: 6| Step: 1
Training loss: 0.18877393007278442
Validation loss: 1.6268623285396124

Epoch: 6| Step: 2
Training loss: 0.17124153673648834
Validation loss: 1.6045665279511483

Epoch: 6| Step: 3
Training loss: 0.17112517356872559
Validation loss: 1.6065705591632473

Epoch: 6| Step: 4
Training loss: 0.19427987933158875
Validation loss: 1.6210214354658639

Epoch: 6| Step: 5
Training loss: 0.22591787576675415
Validation loss: 1.6241383744824318

Epoch: 6| Step: 6
Training loss: 0.2353944480419159
Validation loss: 1.629726852140119

Epoch: 6| Step: 7
Training loss: 0.13848352432250977
Validation loss: 1.6160014752418763

Epoch: 6| Step: 8
Training loss: 0.21730372309684753
Validation loss: 1.6165783943668488

Epoch: 6| Step: 9
Training loss: 0.2355620265007019
Validation loss: 1.591052665505358

Epoch: 6| Step: 10
Training loss: 0.13342875242233276
Validation loss: 1.602070677664972

Epoch: 6| Step: 11
Training loss: 0.08906444907188416
Validation loss: 1.6014600441020022

Epoch: 6| Step: 12
Training loss: 0.25678128004074097
Validation loss: 1.6430296256978025

Epoch: 6| Step: 13
Training loss: 0.10531718283891678
Validation loss: 1.6468929161307633

Epoch: 409| Step: 0
Training loss: 0.3626875877380371
Validation loss: 1.67602676217274

Epoch: 6| Step: 1
Training loss: 0.1812276393175125
Validation loss: 1.671706840556155

Epoch: 6| Step: 2
Training loss: 0.22647686302661896
Validation loss: 1.678099178498791

Epoch: 6| Step: 3
Training loss: 0.10402463376522064
Validation loss: 1.680098484921199

Epoch: 6| Step: 4
Training loss: 0.20520970225334167
Validation loss: 1.6527224753492622

Epoch: 6| Step: 5
Training loss: 0.23271676898002625
Validation loss: 1.6413470134940198

Epoch: 6| Step: 6
Training loss: 0.16244372725486755
Validation loss: 1.6265267479804255

Epoch: 6| Step: 7
Training loss: 0.1751987636089325
Validation loss: 1.6207808371513122

Epoch: 6| Step: 8
Training loss: 0.10341142117977142
Validation loss: 1.614866018295288

Epoch: 6| Step: 9
Training loss: 0.12698587775230408
Validation loss: 1.609015695510372

Epoch: 6| Step: 10
Training loss: 0.19735753536224365
Validation loss: 1.6079073259907384

Epoch: 6| Step: 11
Training loss: 0.2585168480873108
Validation loss: 1.6071516634315572

Epoch: 6| Step: 12
Training loss: 0.18879956007003784
Validation loss: 1.617987835279075

Epoch: 6| Step: 13
Training loss: 0.11573126912117004
Validation loss: 1.613723740782789

Epoch: 410| Step: 0
Training loss: 0.13168984651565552
Validation loss: 1.6242328100307013

Epoch: 6| Step: 1
Training loss: 0.26696768403053284
Validation loss: 1.6301207760328889

Epoch: 6| Step: 2
Training loss: 0.19687184691429138
Validation loss: 1.6501513117103166

Epoch: 6| Step: 3
Training loss: 0.19930784404277802
Validation loss: 1.6423599976365284

Epoch: 6| Step: 4
Training loss: 0.18941381573677063
Validation loss: 1.634034502890802

Epoch: 6| Step: 5
Training loss: 0.11579664051532745
Validation loss: 1.6149266201962706

Epoch: 6| Step: 6
Training loss: 0.15802541375160217
Validation loss: 1.6180991485554685

Epoch: 6| Step: 7
Training loss: 0.35052257776260376
Validation loss: 1.6319453177913543

Epoch: 6| Step: 8
Training loss: 0.13313522934913635
Validation loss: 1.6126017134676698

Epoch: 6| Step: 9
Training loss: 0.14604386687278748
Validation loss: 1.605455767723822

Epoch: 6| Step: 10
Training loss: 0.11304759234189987
Validation loss: 1.5907954144221481

Epoch: 6| Step: 11
Training loss: 0.19091787934303284
Validation loss: 1.5856347135318223

Epoch: 6| Step: 12
Training loss: 0.11105520278215408
Validation loss: 1.6141999979172983

Epoch: 6| Step: 13
Training loss: 0.13124246895313263
Validation loss: 1.6153098293530044

Epoch: 411| Step: 0
Training loss: 0.26141366362571716
Validation loss: 1.6170788170188986

Epoch: 6| Step: 1
Training loss: 0.21448242664337158
Validation loss: 1.6104736969035158

Epoch: 6| Step: 2
Training loss: 0.20103682577610016
Validation loss: 1.6225474560132591

Epoch: 6| Step: 3
Training loss: 0.14524739980697632
Validation loss: 1.6350965230695662

Epoch: 6| Step: 4
Training loss: 0.17573946714401245
Validation loss: 1.590615080248925

Epoch: 6| Step: 5
Training loss: 0.17148825526237488
Validation loss: 1.5978944365696242

Epoch: 6| Step: 6
Training loss: 0.1289566308259964
Validation loss: 1.6165257166790705

Epoch: 6| Step: 7
Training loss: 0.1980057954788208
Validation loss: 1.5871275753103278

Epoch: 6| Step: 8
Training loss: 0.1611729860305786
Validation loss: 1.575586417669891

Epoch: 6| Step: 9
Training loss: 0.2951609194278717
Validation loss: 1.5914419504903978

Epoch: 6| Step: 10
Training loss: 0.21795892715454102
Validation loss: 1.6144049564997356

Epoch: 6| Step: 11
Training loss: 0.14694534242153168
Validation loss: 1.5839824599604453

Epoch: 6| Step: 12
Training loss: 0.0993928462266922
Validation loss: 1.628068938050219

Epoch: 6| Step: 13
Training loss: 0.12924712896347046
Validation loss: 1.6362836027658114

Epoch: 412| Step: 0
Training loss: 0.12984296679496765
Validation loss: 1.6140763028975456

Epoch: 6| Step: 1
Training loss: 0.09187335520982742
Validation loss: 1.6690168790919806

Epoch: 6| Step: 2
Training loss: 0.07924844324588776
Validation loss: 1.6157650588661112

Epoch: 6| Step: 3
Training loss: 0.16211044788360596
Validation loss: 1.60786392611842

Epoch: 6| Step: 4
Training loss: 0.15045768022537231
Validation loss: 1.610994521007743

Epoch: 6| Step: 5
Training loss: 0.10398347675800323
Validation loss: 1.6223310591072164

Epoch: 6| Step: 6
Training loss: 0.25911563634872437
Validation loss: 1.602811526226741

Epoch: 6| Step: 7
Training loss: 0.07559800893068314
Validation loss: 1.605210534987911

Epoch: 6| Step: 8
Training loss: 0.17223826050758362
Validation loss: 1.6019547241990284

Epoch: 6| Step: 9
Training loss: 0.1822395920753479
Validation loss: 1.6190077335603776

Epoch: 6| Step: 10
Training loss: 0.14321866631507874
Validation loss: 1.6091918483857186

Epoch: 6| Step: 11
Training loss: 0.270724892616272
Validation loss: 1.6083758031168292

Epoch: 6| Step: 12
Training loss: 0.3573746681213379
Validation loss: 1.6118314663569133

Epoch: 6| Step: 13
Training loss: 0.17359690368175507
Validation loss: 1.6381492230199999

Epoch: 413| Step: 0
Training loss: 0.14095661044120789
Validation loss: 1.6239631175994873

Epoch: 6| Step: 1
Training loss: 0.2847945988178253
Validation loss: 1.6378902773703299

Epoch: 6| Step: 2
Training loss: 0.21848079562187195
Validation loss: 1.6373596088860625

Epoch: 6| Step: 3
Training loss: 0.17087861895561218
Validation loss: 1.6364782061628116

Epoch: 6| Step: 4
Training loss: 0.14228515326976776
Validation loss: 1.626212291820075

Epoch: 6| Step: 5
Training loss: 0.19727131724357605
Validation loss: 1.6440424175672634

Epoch: 6| Step: 6
Training loss: 0.19439518451690674
Validation loss: 1.666448426503007

Epoch: 6| Step: 7
Training loss: 0.15472297370433807
Validation loss: 1.660997534310946

Epoch: 6| Step: 8
Training loss: 0.27546459436416626
Validation loss: 1.6546617451534475

Epoch: 6| Step: 9
Training loss: 0.14506205916404724
Validation loss: 1.6112007966605566

Epoch: 6| Step: 10
Training loss: 0.09419821202754974
Validation loss: 1.6402181835584744

Epoch: 6| Step: 11
Training loss: 0.10002358257770538
Validation loss: 1.6266266421605182

Epoch: 6| Step: 12
Training loss: 0.1644507348537445
Validation loss: 1.6206481187574324

Epoch: 6| Step: 13
Training loss: 0.1694713979959488
Validation loss: 1.594959787143174

Epoch: 414| Step: 0
Training loss: 0.1603490710258484
Validation loss: 1.6172346607331307

Epoch: 6| Step: 1
Training loss: 0.2976909279823303
Validation loss: 1.6314305669517928

Epoch: 6| Step: 2
Training loss: 0.1417492926120758
Validation loss: 1.6433822877945439

Epoch: 6| Step: 3
Training loss: 0.17714199423789978
Validation loss: 1.6485323700853574

Epoch: 6| Step: 4
Training loss: 0.21141576766967773
Validation loss: 1.637417483073409

Epoch: 6| Step: 5
Training loss: 0.08416557312011719
Validation loss: 1.6854405518501037

Epoch: 6| Step: 6
Training loss: 0.16051088273525238
Validation loss: 1.6444109268085931

Epoch: 6| Step: 7
Training loss: 0.12335850298404694
Validation loss: 1.6591828266779582

Epoch: 6| Step: 8
Training loss: 0.1688949316740036
Validation loss: 1.6590184280949254

Epoch: 6| Step: 9
Training loss: 0.26664894819259644
Validation loss: 1.660193879117248

Epoch: 6| Step: 10
Training loss: 0.145868718624115
Validation loss: 1.658316917316888

Epoch: 6| Step: 11
Training loss: 0.1265694499015808
Validation loss: 1.644018607754861

Epoch: 6| Step: 12
Training loss: 0.20681363344192505
Validation loss: 1.6482369239612291

Epoch: 6| Step: 13
Training loss: 0.09918160736560822
Validation loss: 1.6293878786025509

Epoch: 415| Step: 0
Training loss: 0.18525750935077667
Validation loss: 1.610455725782661

Epoch: 6| Step: 1
Training loss: 0.06987544894218445
Validation loss: 1.5803348428459578

Epoch: 6| Step: 2
Training loss: 0.25087159872055054
Validation loss: 1.618042533115674

Epoch: 6| Step: 3
Training loss: 0.21046182513237
Validation loss: 1.6055392642174997

Epoch: 6| Step: 4
Training loss: 0.1613956242799759
Validation loss: 1.5674728539682203

Epoch: 6| Step: 5
Training loss: 0.3654274046421051
Validation loss: 1.5665651213738225

Epoch: 6| Step: 6
Training loss: 0.282656729221344
Validation loss: 1.5626535755331799

Epoch: 6| Step: 7
Training loss: 0.24804002046585083
Validation loss: 1.5825903736135012

Epoch: 6| Step: 8
Training loss: 0.1988401710987091
Validation loss: 1.5499608003964989

Epoch: 6| Step: 9
Training loss: 0.14742407202720642
Validation loss: 1.5295204795816892

Epoch: 6| Step: 10
Training loss: 0.13047483563423157
Validation loss: 1.5263456324095368

Epoch: 6| Step: 11
Training loss: 0.14142510294914246
Validation loss: 1.5412810835787045

Epoch: 6| Step: 12
Training loss: 0.12644878029823303
Validation loss: 1.5644403837060417

Epoch: 6| Step: 13
Training loss: 0.06201702356338501
Validation loss: 1.5928087760043401

Epoch: 416| Step: 0
Training loss: 0.15536780655384064
Validation loss: 1.5751748072203768

Epoch: 6| Step: 1
Training loss: 0.15122883021831512
Validation loss: 1.6067978823056785

Epoch: 6| Step: 2
Training loss: 0.15766936540603638
Validation loss: 1.6143166993253975

Epoch: 6| Step: 3
Training loss: 0.19864864647388458
Validation loss: 1.6512995548145746

Epoch: 6| Step: 4
Training loss: 0.1472179889678955
Validation loss: 1.6371983597355504

Epoch: 6| Step: 5
Training loss: 0.22911810874938965
Validation loss: 1.6830303899703487

Epoch: 6| Step: 6
Training loss: 0.1828058362007141
Validation loss: 1.6681495610103811

Epoch: 6| Step: 7
Training loss: 0.09727808833122253
Validation loss: 1.6561167522143292

Epoch: 6| Step: 8
Training loss: 0.16895201802253723
Validation loss: 1.6840678299626997

Epoch: 6| Step: 9
Training loss: 0.33100223541259766
Validation loss: 1.6726485759981218

Epoch: 6| Step: 10
Training loss: 0.10742895305156708
Validation loss: 1.6795138082196635

Epoch: 6| Step: 11
Training loss: 0.23775069415569305
Validation loss: 1.655080755551656

Epoch: 6| Step: 12
Training loss: 0.08561189472675323
Validation loss: 1.6276427315127464

Epoch: 6| Step: 13
Training loss: 0.10877881944179535
Validation loss: 1.636666517103872

Epoch: 417| Step: 0
Training loss: 0.13520154356956482
Validation loss: 1.646495811400875

Epoch: 6| Step: 1
Training loss: 0.20600438117980957
Validation loss: 1.630374332909943

Epoch: 6| Step: 2
Training loss: 0.0986679345369339
Validation loss: 1.6249499103074432

Epoch: 6| Step: 3
Training loss: 0.21879562735557556
Validation loss: 1.6387527219710811

Epoch: 6| Step: 4
Training loss: 0.24120283126831055
Validation loss: 1.6466739369976906

Epoch: 6| Step: 5
Training loss: 0.2782386541366577
Validation loss: 1.6284084537977814

Epoch: 6| Step: 6
Training loss: 0.3159577548503876
Validation loss: 1.6335676882856636

Epoch: 6| Step: 7
Training loss: 0.22779342532157898
Validation loss: 1.6607023003280803

Epoch: 6| Step: 8
Training loss: 0.11616834253072739
Validation loss: 1.6846730145074988

Epoch: 6| Step: 9
Training loss: 0.2860180139541626
Validation loss: 1.751838126490193

Epoch: 6| Step: 10
Training loss: 0.16496966779232025
Validation loss: 1.74469938073107

Epoch: 6| Step: 11
Training loss: 0.1685754656791687
Validation loss: 1.740073512959224

Epoch: 6| Step: 12
Training loss: 0.1972588300704956
Validation loss: 1.7153923050049813

Epoch: 6| Step: 13
Training loss: 0.21751287579536438
Validation loss: 1.660205730827906

Epoch: 418| Step: 0
Training loss: 0.163117453455925
Validation loss: 1.6666808833358109

Epoch: 6| Step: 1
Training loss: 0.2389489859342575
Validation loss: 1.6244245921411822

Epoch: 6| Step: 2
Training loss: 0.12392908334732056
Validation loss: 1.610767811857244

Epoch: 6| Step: 3
Training loss: 0.19387313723564148
Validation loss: 1.606828635738742

Epoch: 6| Step: 4
Training loss: 0.13355737924575806
Validation loss: 1.6332142263330438

Epoch: 6| Step: 5
Training loss: 0.16799865663051605
Validation loss: 1.6292768601448304

Epoch: 6| Step: 6
Training loss: 0.3167276978492737
Validation loss: 1.6381211844823693

Epoch: 6| Step: 7
Training loss: 0.11304733157157898
Validation loss: 1.6483097140507033

Epoch: 6| Step: 8
Training loss: 0.17363178730010986
Validation loss: 1.6085221318788425

Epoch: 6| Step: 9
Training loss: 0.10782060027122498
Validation loss: 1.6070106490965812

Epoch: 6| Step: 10
Training loss: 0.16048115491867065
Validation loss: 1.5916809394795408

Epoch: 6| Step: 11
Training loss: 0.27584734559059143
Validation loss: 1.6086564615208616

Epoch: 6| Step: 12
Training loss: 0.15220698714256287
Validation loss: 1.581914096750239

Epoch: 6| Step: 13
Training loss: 0.06878060102462769
Validation loss: 1.5842115007421023

Epoch: 419| Step: 0
Training loss: 0.33124345541000366
Validation loss: 1.5815443114567829

Epoch: 6| Step: 1
Training loss: 0.10751985013484955
Validation loss: 1.6008165626115696

Epoch: 6| Step: 2
Training loss: 0.17622092366218567
Validation loss: 1.6094657708239812

Epoch: 6| Step: 3
Training loss: 0.079268679022789
Validation loss: 1.6128951862294187

Epoch: 6| Step: 4
Training loss: 0.1355482041835785
Validation loss: 1.6706067221139067

Epoch: 6| Step: 5
Training loss: 0.18030473589897156
Validation loss: 1.640396132264086

Epoch: 6| Step: 6
Training loss: 0.18107931315898895
Validation loss: 1.657398840432526

Epoch: 6| Step: 7
Training loss: 0.15640223026275635
Validation loss: 1.6335131276038386

Epoch: 6| Step: 8
Training loss: 0.17408078908920288
Validation loss: 1.6413188672834826

Epoch: 6| Step: 9
Training loss: 0.18693354725837708
Validation loss: 1.6161659840614564

Epoch: 6| Step: 10
Training loss: 0.22409602999687195
Validation loss: 1.6317854901795745

Epoch: 6| Step: 11
Training loss: 0.2583859860897064
Validation loss: 1.5936951175812752

Epoch: 6| Step: 12
Training loss: 0.15724046528339386
Validation loss: 1.6002902843618905

Epoch: 6| Step: 13
Training loss: 0.09756244719028473
Validation loss: 1.6200161980044456

Epoch: 420| Step: 0
Training loss: 0.1175021082162857
Validation loss: 1.611752192179362

Epoch: 6| Step: 1
Training loss: 0.12565849721431732
Validation loss: 1.6093661003215338

Epoch: 6| Step: 2
Training loss: 0.19500043988227844
Validation loss: 1.6283699850882254

Epoch: 6| Step: 3
Training loss: 0.31750252842903137
Validation loss: 1.6278146441264818

Epoch: 6| Step: 4
Training loss: 0.15597717463970184
Validation loss: 1.630390695346299

Epoch: 6| Step: 5
Training loss: 0.14632773399353027
Validation loss: 1.638218855345121

Epoch: 6| Step: 6
Training loss: 0.09007514268159866
Validation loss: 1.6332281417744134

Epoch: 6| Step: 7
Training loss: 0.20452740788459778
Validation loss: 1.6380653791530158

Epoch: 6| Step: 8
Training loss: 0.10215581208467484
Validation loss: 1.6523027381589335

Epoch: 6| Step: 9
Training loss: 0.13216455280780792
Validation loss: 1.6543583780206659

Epoch: 6| Step: 10
Training loss: 0.07965106517076492
Validation loss: 1.6673017394158147

Epoch: 6| Step: 11
Training loss: 0.11892477422952652
Validation loss: 1.6544860037424232

Epoch: 6| Step: 12
Training loss: 0.22794900834560394
Validation loss: 1.6586296866017003

Epoch: 6| Step: 13
Training loss: 0.062477853149175644
Validation loss: 1.6646146876837618

Epoch: 421| Step: 0
Training loss: 0.14059992134571075
Validation loss: 1.6456336693097187

Epoch: 6| Step: 1
Training loss: 0.1276218295097351
Validation loss: 1.6913828131973103

Epoch: 6| Step: 2
Training loss: 0.202204167842865
Validation loss: 1.6993726632928337

Epoch: 6| Step: 3
Training loss: 0.24634405970573425
Validation loss: 1.6820136398397467

Epoch: 6| Step: 4
Training loss: 0.13478216528892517
Validation loss: 1.6783179429269606

Epoch: 6| Step: 5
Training loss: 0.17288735508918762
Validation loss: 1.6886954435738184

Epoch: 6| Step: 6
Training loss: 0.13531625270843506
Validation loss: 1.6400042233928558

Epoch: 6| Step: 7
Training loss: 0.1107097864151001
Validation loss: 1.6408613644620424

Epoch: 6| Step: 8
Training loss: 0.11961938440799713
Validation loss: 1.6194366831933298

Epoch: 6| Step: 9
Training loss: 0.39120858907699585
Validation loss: 1.635554769987701

Epoch: 6| Step: 10
Training loss: 0.1011245846748352
Validation loss: 1.6362391107825822

Epoch: 6| Step: 11
Training loss: 0.14785847067832947
Validation loss: 1.6173745816753757

Epoch: 6| Step: 12
Training loss: 0.10241162031888962
Validation loss: 1.653344702977006

Epoch: 6| Step: 13
Training loss: 0.2664700448513031
Validation loss: 1.6154547327308244

Epoch: 422| Step: 0
Training loss: 0.2349383383989334
Validation loss: 1.6567037285015147

Epoch: 6| Step: 1
Training loss: 0.15913423895835876
Validation loss: 1.621686694442585

Epoch: 6| Step: 2
Training loss: 0.18863540887832642
Validation loss: 1.625649675246208

Epoch: 6| Step: 3
Training loss: 0.15769265592098236
Validation loss: 1.6308350127230409

Epoch: 6| Step: 4
Training loss: 0.22583816945552826
Validation loss: 1.5939298496451428

Epoch: 6| Step: 5
Training loss: 0.08582131564617157
Validation loss: 1.6015004534875192

Epoch: 6| Step: 6
Training loss: 0.09726288914680481
Validation loss: 1.6163610091773413

Epoch: 6| Step: 7
Training loss: 0.26942336559295654
Validation loss: 1.5861885393819501

Epoch: 6| Step: 8
Training loss: 0.17096981406211853
Validation loss: 1.5997576341834119

Epoch: 6| Step: 9
Training loss: 0.15963126718997955
Validation loss: 1.6082168497065061

Epoch: 6| Step: 10
Training loss: 0.0909029096364975
Validation loss: 1.5930055790050055

Epoch: 6| Step: 11
Training loss: 0.16085284948349
Validation loss: 1.627522869776654

Epoch: 6| Step: 12
Training loss: 0.10079532116651535
Validation loss: 1.6269581099992156

Epoch: 6| Step: 13
Training loss: 0.0908380076289177
Validation loss: 1.6294277509053547

Epoch: 423| Step: 0
Training loss: 0.22507375478744507
Validation loss: 1.6374797667226484

Epoch: 6| Step: 1
Training loss: 0.13676846027374268
Validation loss: 1.6463636864898026

Epoch: 6| Step: 2
Training loss: 0.28674596548080444
Validation loss: 1.6283144899593887

Epoch: 6| Step: 3
Training loss: 0.10806261003017426
Validation loss: 1.6154791872988465

Epoch: 6| Step: 4
Training loss: 0.20031508803367615
Validation loss: 1.6163099273558585

Epoch: 6| Step: 5
Training loss: 0.09214232116937637
Validation loss: 1.585345927105155

Epoch: 6| Step: 6
Training loss: 0.0664946585893631
Validation loss: 1.6064390367077244

Epoch: 6| Step: 7
Training loss: 0.11580716073513031
Validation loss: 1.603383485347994

Epoch: 6| Step: 8
Training loss: 0.14954710006713867
Validation loss: 1.581354594999744

Epoch: 6| Step: 9
Training loss: 0.23548004031181335
Validation loss: 1.5902861151643979

Epoch: 6| Step: 10
Training loss: 0.1596977263689041
Validation loss: 1.6079703864230905

Epoch: 6| Step: 11
Training loss: 0.12759317457675934
Validation loss: 1.5864395018546813

Epoch: 6| Step: 12
Training loss: 0.15536832809448242
Validation loss: 1.5881264568657003

Epoch: 6| Step: 13
Training loss: 0.1453397274017334
Validation loss: 1.602890735031456

Epoch: 424| Step: 0
Training loss: 0.18693140149116516
Validation loss: 1.6378747417080788

Epoch: 6| Step: 1
Training loss: 0.1810852587223053
Validation loss: 1.674436979396369

Epoch: 6| Step: 2
Training loss: 0.17281728982925415
Validation loss: 1.679257849211334

Epoch: 6| Step: 3
Training loss: 0.15594518184661865
Validation loss: 1.6768926971702165

Epoch: 6| Step: 4
Training loss: 0.15039867162704468
Validation loss: 1.6443811129498225

Epoch: 6| Step: 5
Training loss: 0.1029224842786789
Validation loss: 1.5971201241657298

Epoch: 6| Step: 6
Training loss: 0.07709395885467529
Validation loss: 1.6037322885246688

Epoch: 6| Step: 7
Training loss: 0.31905895471572876
Validation loss: 1.6222161016156595

Epoch: 6| Step: 8
Training loss: 0.1625540852546692
Validation loss: 1.607436353160489

Epoch: 6| Step: 9
Training loss: 0.27141639590263367
Validation loss: 1.6127362738373459

Epoch: 6| Step: 10
Training loss: 0.13921131193637848
Validation loss: 1.61122561911101

Epoch: 6| Step: 11
Training loss: 0.13885070383548737
Validation loss: 1.5916917324066162

Epoch: 6| Step: 12
Training loss: 0.17691616714000702
Validation loss: 1.6048002217405586

Epoch: 6| Step: 13
Training loss: 0.1699470728635788
Validation loss: 1.6119783322016399

Epoch: 425| Step: 0
Training loss: 0.26717084646224976
Validation loss: 1.6345423460006714

Epoch: 6| Step: 1
Training loss: 0.1149984747171402
Validation loss: 1.6431437897425827

Epoch: 6| Step: 2
Training loss: 0.1790754199028015
Validation loss: 1.6438752220522972

Epoch: 6| Step: 3
Training loss: 0.18733276426792145
Validation loss: 1.653540131866291

Epoch: 6| Step: 4
Training loss: 0.3112003803253174
Validation loss: 1.6230302856814476

Epoch: 6| Step: 5
Training loss: 0.11231890320777893
Validation loss: 1.647850513458252

Epoch: 6| Step: 6
Training loss: 0.09419361501932144
Validation loss: 1.6223674910042876

Epoch: 6| Step: 7
Training loss: 0.16048003733158112
Validation loss: 1.6322900428566882

Epoch: 6| Step: 8
Training loss: 0.15783041715621948
Validation loss: 1.6349425238947715

Epoch: 6| Step: 9
Training loss: 0.21876829862594604
Validation loss: 1.6137153897234189

Epoch: 6| Step: 10
Training loss: 0.19340960681438446
Validation loss: 1.6368688229591615

Epoch: 6| Step: 11
Training loss: 0.15302829444408417
Validation loss: 1.6088594992955525

Epoch: 6| Step: 12
Training loss: 0.16979628801345825
Validation loss: 1.6389211172698646

Epoch: 6| Step: 13
Training loss: 0.10562018305063248
Validation loss: 1.6651736677333873

Epoch: 426| Step: 0
Training loss: 0.3093961775302887
Validation loss: 1.706730547771659

Epoch: 6| Step: 1
Training loss: 0.2115837186574936
Validation loss: 1.7202807652053012

Epoch: 6| Step: 2
Training loss: 0.164189875125885
Validation loss: 1.7431541014743108

Epoch: 6| Step: 3
Training loss: 0.1783619523048401
Validation loss: 1.7018244484419465

Epoch: 6| Step: 4
Training loss: 0.17218053340911865
Validation loss: 1.6502887728393718

Epoch: 6| Step: 5
Training loss: 0.18598634004592896
Validation loss: 1.6049381456067484

Epoch: 6| Step: 6
Training loss: 0.1614663153886795
Validation loss: 1.6115220990232242

Epoch: 6| Step: 7
Training loss: 0.09534594416618347
Validation loss: 1.6188695994756555

Epoch: 6| Step: 8
Training loss: 0.26128220558166504
Validation loss: 1.619669101571524

Epoch: 6| Step: 9
Training loss: 0.05772387981414795
Validation loss: 1.6039075274621286

Epoch: 6| Step: 10
Training loss: 0.30634111166000366
Validation loss: 1.608770696065759

Epoch: 6| Step: 11
Training loss: 0.14217275381088257
Validation loss: 1.6281395522497033

Epoch: 6| Step: 12
Training loss: 0.1311657428741455
Validation loss: 1.6414743790062525

Epoch: 6| Step: 13
Training loss: 0.1750255823135376
Validation loss: 1.66100864384764

Epoch: 427| Step: 0
Training loss: 0.16359657049179077
Validation loss: 1.7202984261256393

Epoch: 6| Step: 1
Training loss: 0.17022645473480225
Validation loss: 1.6944716130533526

Epoch: 6| Step: 2
Training loss: 0.26193225383758545
Validation loss: 1.6956061496529529

Epoch: 6| Step: 3
Training loss: 0.05838634446263313
Validation loss: 1.681144484909632

Epoch: 6| Step: 4
Training loss: 0.14310485124588013
Validation loss: 1.6403072034159014

Epoch: 6| Step: 5
Training loss: 0.09398350119590759
Validation loss: 1.6299587500992643

Epoch: 6| Step: 6
Training loss: 0.24832133948802948
Validation loss: 1.6053220213100474

Epoch: 6| Step: 7
Training loss: 0.160798579454422
Validation loss: 1.6256952631858088

Epoch: 6| Step: 8
Training loss: 0.1670176237821579
Validation loss: 1.602912619549741

Epoch: 6| Step: 9
Training loss: 0.1456926316022873
Validation loss: 1.607312774145475

Epoch: 6| Step: 10
Training loss: 0.1894787847995758
Validation loss: 1.5965471536882463

Epoch: 6| Step: 11
Training loss: 0.07307134568691254
Validation loss: 1.5930084131097282

Epoch: 6| Step: 12
Training loss: 0.1991955041885376
Validation loss: 1.6298970381418865

Epoch: 6| Step: 13
Training loss: 0.12255094945430756
Validation loss: 1.6501639491768294

Epoch: 428| Step: 0
Training loss: 0.11371840536594391
Validation loss: 1.6486832480276785

Epoch: 6| Step: 1
Training loss: 0.21636757254600525
Validation loss: 1.7097618297864032

Epoch: 6| Step: 2
Training loss: 0.14710432291030884
Validation loss: 1.6647599256166847

Epoch: 6| Step: 3
Training loss: 0.3433377742767334
Validation loss: 1.7059662944527083

Epoch: 6| Step: 4
Training loss: 0.1132851243019104
Validation loss: 1.6509505010420276

Epoch: 6| Step: 5
Training loss: 0.13090229034423828
Validation loss: 1.629939603549178

Epoch: 6| Step: 6
Training loss: 0.19251057505607605
Validation loss: 1.631017606745484

Epoch: 6| Step: 7
Training loss: 0.10677403211593628
Validation loss: 1.6137220487799695

Epoch: 6| Step: 8
Training loss: 0.13702799379825592
Validation loss: 1.635516143614246

Epoch: 6| Step: 9
Training loss: 0.19004520773887634
Validation loss: 1.639414853947137

Epoch: 6| Step: 10
Training loss: 0.15921957790851593
Validation loss: 1.630855667975641

Epoch: 6| Step: 11
Training loss: 0.13452336192131042
Validation loss: 1.629231136332276

Epoch: 6| Step: 12
Training loss: 0.15806329250335693
Validation loss: 1.6768661763078423

Epoch: 6| Step: 13
Training loss: 0.19914668798446655
Validation loss: 1.6831459294083297

Epoch: 429| Step: 0
Training loss: 0.1895691603422165
Validation loss: 1.6743955022545272

Epoch: 6| Step: 1
Training loss: 0.18176668882369995
Validation loss: 1.6854371518217108

Epoch: 6| Step: 2
Training loss: 0.09378708153963089
Validation loss: 1.696854809279083

Epoch: 6| Step: 3
Training loss: 0.1675126850605011
Validation loss: 1.655616380835092

Epoch: 6| Step: 4
Training loss: 0.15472164750099182
Validation loss: 1.64671488090228

Epoch: 6| Step: 5
Training loss: 0.07234956324100494
Validation loss: 1.6560878574207265

Epoch: 6| Step: 6
Training loss: 0.14992450177669525
Validation loss: 1.6691548106490925

Epoch: 6| Step: 7
Training loss: 0.17170977592468262
Validation loss: 1.6878887632841706

Epoch: 6| Step: 8
Training loss: 0.1940162032842636
Validation loss: 1.696073575686383

Epoch: 6| Step: 9
Training loss: 0.17052924633026123
Validation loss: 1.6885533935280257

Epoch: 6| Step: 10
Training loss: 0.14357227087020874
Validation loss: 1.7086768297738926

Epoch: 6| Step: 11
Training loss: 0.2604230046272278
Validation loss: 1.7052392959594727

Epoch: 6| Step: 12
Training loss: 0.15179869532585144
Validation loss: 1.6844168234896917

Epoch: 6| Step: 13
Training loss: 0.2696586549282074
Validation loss: 1.6733973872277044

Epoch: 430| Step: 0
Training loss: 0.1301126778125763
Validation loss: 1.6318731282346992

Epoch: 6| Step: 1
Training loss: 0.19737881422042847
Validation loss: 1.6441693203423613

Epoch: 6| Step: 2
Training loss: 0.14000889658927917
Validation loss: 1.6170700288588

Epoch: 6| Step: 3
Training loss: 0.08359581232070923
Validation loss: 1.5922950416482904

Epoch: 6| Step: 4
Training loss: 0.3112165331840515
Validation loss: 1.5816571302311395

Epoch: 6| Step: 5
Training loss: 0.1919858753681183
Validation loss: 1.5662157471461962

Epoch: 6| Step: 6
Training loss: 0.1327090710401535
Validation loss: 1.5963966756738641

Epoch: 6| Step: 7
Training loss: 0.1988372951745987
Validation loss: 1.6015716842425767

Epoch: 6| Step: 8
Training loss: 0.18304681777954102
Validation loss: 1.5889821180733301

Epoch: 6| Step: 9
Training loss: 0.11752188205718994
Validation loss: 1.588159195838436

Epoch: 6| Step: 10
Training loss: 0.18555551767349243
Validation loss: 1.6057626457624539

Epoch: 6| Step: 11
Training loss: 0.18112966418266296
Validation loss: 1.6236391182868712

Epoch: 6| Step: 12
Training loss: 0.11178910732269287
Validation loss: 1.615972775284962

Epoch: 6| Step: 13
Training loss: 0.11688312143087387
Validation loss: 1.6209885766429286

Epoch: 431| Step: 0
Training loss: 0.17341741919517517
Validation loss: 1.6161715292161511

Epoch: 6| Step: 1
Training loss: 0.34347930550575256
Validation loss: 1.640271653411209

Epoch: 6| Step: 2
Training loss: 0.30076736211776733
Validation loss: 1.6475412768702353

Epoch: 6| Step: 3
Training loss: 0.16500303149223328
Validation loss: 1.6044804972987021

Epoch: 6| Step: 4
Training loss: 0.17372696101665497
Validation loss: 1.5870414510849984

Epoch: 6| Step: 5
Training loss: 0.2523859739303589
Validation loss: 1.579684385689356

Epoch: 6| Step: 6
Training loss: 0.0786810964345932
Validation loss: 1.5850946390500633

Epoch: 6| Step: 7
Training loss: 0.16444720327854156
Validation loss: 1.5882299382199523

Epoch: 6| Step: 8
Training loss: 0.1814606636762619
Validation loss: 1.564949909845988

Epoch: 6| Step: 9
Training loss: 0.15665888786315918
Validation loss: 1.5642251455655662

Epoch: 6| Step: 10
Training loss: 0.18598672747612
Validation loss: 1.5745347674174974

Epoch: 6| Step: 11
Training loss: 0.10358412563800812
Validation loss: 1.5763451027613815

Epoch: 6| Step: 12
Training loss: 0.08886425197124481
Validation loss: 1.5513976581635014

Epoch: 6| Step: 13
Training loss: 0.20731060206890106
Validation loss: 1.5842757007127166

Epoch: 432| Step: 0
Training loss: 0.24358178675174713
Validation loss: 1.5749207786334458

Epoch: 6| Step: 1
Training loss: 0.14161188900470734
Validation loss: 1.5986603075458157

Epoch: 6| Step: 2
Training loss: 0.0820564404129982
Validation loss: 1.606383046796245

Epoch: 6| Step: 3
Training loss: 0.363176554441452
Validation loss: 1.5914526690718949

Epoch: 6| Step: 4
Training loss: 0.08898252248764038
Validation loss: 1.6195265144430182

Epoch: 6| Step: 5
Training loss: 0.11966975033283234
Validation loss: 1.6299828790849256

Epoch: 6| Step: 6
Training loss: 0.1345963031053543
Validation loss: 1.6788384837488974

Epoch: 6| Step: 7
Training loss: 0.1450500786304474
Validation loss: 1.6620695501245477

Epoch: 6| Step: 8
Training loss: 0.049168363213539124
Validation loss: 1.6616231523534304

Epoch: 6| Step: 9
Training loss: 0.07523688673973083
Validation loss: 1.6955168516405168

Epoch: 6| Step: 10
Training loss: 0.14621508121490479
Validation loss: 1.653662299597135

Epoch: 6| Step: 11
Training loss: 0.2008761167526245
Validation loss: 1.639272120691115

Epoch: 6| Step: 12
Training loss: 0.15504372119903564
Validation loss: 1.6272349588332637

Epoch: 6| Step: 13
Training loss: 0.17680703103542328
Validation loss: 1.6377573654215822

Epoch: 433| Step: 0
Training loss: 0.21130721271038055
Validation loss: 1.599314720399918

Epoch: 6| Step: 1
Training loss: 0.08809564262628555
Validation loss: 1.573056165890027

Epoch: 6| Step: 2
Training loss: 0.14557313919067383
Validation loss: 1.5774785985228836

Epoch: 6| Step: 3
Training loss: 0.14780084788799286
Validation loss: 1.5649740811317199

Epoch: 6| Step: 4
Training loss: 0.1401897817850113
Validation loss: 1.5729167910032376

Epoch: 6| Step: 5
Training loss: 0.15524686872959137
Validation loss: 1.5826849988711778

Epoch: 6| Step: 6
Training loss: 0.13125240802764893
Validation loss: 1.605157732963562

Epoch: 6| Step: 7
Training loss: 0.13604459166526794
Validation loss: 1.611054806299107

Epoch: 6| Step: 8
Training loss: 0.11530405282974243
Validation loss: 1.615415609011086

Epoch: 6| Step: 9
Training loss: 0.18636824190616608
Validation loss: 1.5965321871542162

Epoch: 6| Step: 10
Training loss: 0.22761419415473938
Validation loss: 1.5884317271811987

Epoch: 6| Step: 11
Training loss: 0.16634732484817505
Validation loss: 1.614275376001994

Epoch: 6| Step: 12
Training loss: 0.16814468801021576
Validation loss: 1.6025232884191698

Epoch: 6| Step: 13
Training loss: 0.19354036450386047
Validation loss: 1.592932834420153

Epoch: 434| Step: 0
Training loss: 0.0750996544957161
Validation loss: 1.6214406169870847

Epoch: 6| Step: 1
Training loss: 0.14834906160831451
Validation loss: 1.6044707452097247

Epoch: 6| Step: 2
Training loss: 0.13718698918819427
Validation loss: 1.6131598000885339

Epoch: 6| Step: 3
Training loss: 0.17392224073410034
Validation loss: 1.6272070510413057

Epoch: 6| Step: 4
Training loss: 0.11368291079998016
Validation loss: 1.6222514721655077

Epoch: 6| Step: 5
Training loss: 0.2025468796491623
Validation loss: 1.6176728304996286

Epoch: 6| Step: 6
Training loss: 0.1669573187828064
Validation loss: 1.6349262473403767

Epoch: 6| Step: 7
Training loss: 0.09315410256385803
Validation loss: 1.6196756478278869

Epoch: 6| Step: 8
Training loss: 0.1385655403137207
Validation loss: 1.6377220025626562

Epoch: 6| Step: 9
Training loss: 0.07373064011335373
Validation loss: 1.6125118552997548

Epoch: 6| Step: 10
Training loss: 0.2182147204875946
Validation loss: 1.6198255733777118

Epoch: 6| Step: 11
Training loss: 0.2892289161682129
Validation loss: 1.609524279512385

Epoch: 6| Step: 12
Training loss: 0.182074636220932
Validation loss: 1.6256310080969205

Epoch: 6| Step: 13
Training loss: 0.16669878363609314
Validation loss: 1.5997359291199715

Epoch: 435| Step: 0
Training loss: 0.08741739392280579
Validation loss: 1.5742219314780286

Epoch: 6| Step: 1
Training loss: 0.22458404302597046
Validation loss: 1.5692798745247625

Epoch: 6| Step: 2
Training loss: 0.28459158539772034
Validation loss: 1.6012778692348029

Epoch: 6| Step: 3
Training loss: 0.15985088050365448
Validation loss: 1.5999035989084551

Epoch: 6| Step: 4
Training loss: 0.15690584480762482
Validation loss: 1.5931715606361307

Epoch: 6| Step: 5
Training loss: 0.11670073866844177
Validation loss: 1.6046268132425123

Epoch: 6| Step: 6
Training loss: 0.08299590647220612
Validation loss: 1.6256224622008622

Epoch: 6| Step: 7
Training loss: 0.10863819718360901
Validation loss: 1.6238794467782462

Epoch: 6| Step: 8
Training loss: 0.20540928840637207
Validation loss: 1.6748253273707565

Epoch: 6| Step: 9
Training loss: 0.12237590551376343
Validation loss: 1.6818436653383317

Epoch: 6| Step: 10
Training loss: 0.20389775931835175
Validation loss: 1.7061980180842902

Epoch: 6| Step: 11
Training loss: 0.37594014406204224
Validation loss: 1.6837954021269275

Epoch: 6| Step: 12
Training loss: 0.16544261574745178
Validation loss: 1.6725356348099247

Epoch: 6| Step: 13
Training loss: 0.25333496928215027
Validation loss: 1.6418137947718303

Epoch: 436| Step: 0
Training loss: 0.20575398206710815
Validation loss: 1.6240292133823517

Epoch: 6| Step: 1
Training loss: 0.2323053777217865
Validation loss: 1.5813152687523955

Epoch: 6| Step: 2
Training loss: 0.26603958010673523
Validation loss: 1.5970425631410332

Epoch: 6| Step: 3
Training loss: 0.12591329216957092
Validation loss: 1.6047341958169015

Epoch: 6| Step: 4
Training loss: 0.23003610968589783
Validation loss: 1.5843296256116641

Epoch: 6| Step: 5
Training loss: 0.25332045555114746
Validation loss: 1.5638209709557154

Epoch: 6| Step: 6
Training loss: 0.14104941487312317
Validation loss: 1.5641944113598074

Epoch: 6| Step: 7
Training loss: 0.1460258960723877
Validation loss: 1.5928848296083429

Epoch: 6| Step: 8
Training loss: 0.11103038489818573
Validation loss: 1.5878851644454464

Epoch: 6| Step: 9
Training loss: 0.16989296674728394
Validation loss: 1.5998160095625027

Epoch: 6| Step: 10
Training loss: 0.24419617652893066
Validation loss: 1.595127881214183

Epoch: 6| Step: 11
Training loss: 0.12573792040348053
Validation loss: 1.6045798870824999

Epoch: 6| Step: 12
Training loss: 0.12281729280948639
Validation loss: 1.6236551512954056

Epoch: 6| Step: 13
Training loss: 0.06415346264839172
Validation loss: 1.6000701740223875

Epoch: 437| Step: 0
Training loss: 0.2511586546897888
Validation loss: 1.5892930979369788

Epoch: 6| Step: 1
Training loss: 0.1039038747549057
Validation loss: 1.603399790743346

Epoch: 6| Step: 2
Training loss: 0.11963531374931335
Validation loss: 1.5717475023320926

Epoch: 6| Step: 3
Training loss: 0.1752614974975586
Validation loss: 1.5697456893100534

Epoch: 6| Step: 4
Training loss: 0.13990601897239685
Validation loss: 1.5887047295929284

Epoch: 6| Step: 5
Training loss: 0.17817053198814392
Validation loss: 1.580066434157792

Epoch: 6| Step: 6
Training loss: 0.16905955970287323
Validation loss: 1.600446706177086

Epoch: 6| Step: 7
Training loss: 0.17927870154380798
Validation loss: 1.5758922843522922

Epoch: 6| Step: 8
Training loss: 0.11144944280385971
Validation loss: 1.5866091879465247

Epoch: 6| Step: 9
Training loss: 0.12663325667381287
Validation loss: 1.5746396972287087

Epoch: 6| Step: 10
Training loss: 0.1539793610572815
Validation loss: 1.5864848616302654

Epoch: 6| Step: 11
Training loss: 0.10332617163658142
Validation loss: 1.589053710301717

Epoch: 6| Step: 12
Training loss: 0.27714967727661133
Validation loss: 1.5816161042900496

Epoch: 6| Step: 13
Training loss: 0.07504421472549438
Validation loss: 1.588111175003872

Epoch: 438| Step: 0
Training loss: 0.16132190823554993
Validation loss: 1.5718898645011328

Epoch: 6| Step: 1
Training loss: 0.11622050404548645
Validation loss: 1.5589463428784442

Epoch: 6| Step: 2
Training loss: 0.1090618371963501
Validation loss: 1.5762105705917522

Epoch: 6| Step: 3
Training loss: 0.16259536147117615
Validation loss: 1.5865668891578593

Epoch: 6| Step: 4
Training loss: 0.16170662641525269
Validation loss: 1.591968794022837

Epoch: 6| Step: 5
Training loss: 0.13364920020103455
Validation loss: 1.5906856047209872

Epoch: 6| Step: 6
Training loss: 0.10433168709278107
Validation loss: 1.6167492020514704

Epoch: 6| Step: 7
Training loss: 0.20777423679828644
Validation loss: 1.5888673272184146

Epoch: 6| Step: 8
Training loss: 0.10247979313135147
Validation loss: 1.597318664673836

Epoch: 6| Step: 9
Training loss: 0.3377574682235718
Validation loss: 1.5791428371142315

Epoch: 6| Step: 10
Training loss: 0.1928953230381012
Validation loss: 1.577211926060338

Epoch: 6| Step: 11
Training loss: 0.11297155171632767
Validation loss: 1.5756338796307963

Epoch: 6| Step: 12
Training loss: 0.12154719978570938
Validation loss: 1.578801655000256

Epoch: 6| Step: 13
Training loss: 0.09258650988340378
Validation loss: 1.6159827593834168

Epoch: 439| Step: 0
Training loss: 0.17406833171844482
Validation loss: 1.625346331186192

Epoch: 6| Step: 1
Training loss: 0.1941225826740265
Validation loss: 1.6217222777746056

Epoch: 6| Step: 2
Training loss: 0.12518534064292908
Validation loss: 1.6153210677126402

Epoch: 6| Step: 3
Training loss: 0.3119230568408966
Validation loss: 1.5985123803538661

Epoch: 6| Step: 4
Training loss: 0.13096065819263458
Validation loss: 1.6049354230203936

Epoch: 6| Step: 5
Training loss: 0.0883595198392868
Validation loss: 1.5867770051443448

Epoch: 6| Step: 6
Training loss: 0.09532710909843445
Validation loss: 1.5942994638155865

Epoch: 6| Step: 7
Training loss: 0.16799139976501465
Validation loss: 1.597502287357084

Epoch: 6| Step: 8
Training loss: 0.17545518279075623
Validation loss: 1.5914057288118588

Epoch: 6| Step: 9
Training loss: 0.15755301713943481
Validation loss: 1.5699949777254494

Epoch: 6| Step: 10
Training loss: 0.09995068609714508
Validation loss: 1.5552458173485213

Epoch: 6| Step: 11
Training loss: 0.12657395005226135
Validation loss: 1.5842787706723778

Epoch: 6| Step: 12
Training loss: 0.08061006665229797
Validation loss: 1.5924849830647951

Epoch: 6| Step: 13
Training loss: 0.15522366762161255
Validation loss: 1.583155523064316

Epoch: 440| Step: 0
Training loss: 0.10941006243228912
Validation loss: 1.609655354612617

Epoch: 6| Step: 1
Training loss: 0.09840626269578934
Validation loss: 1.6128551793354813

Epoch: 6| Step: 2
Training loss: 0.08810272812843323
Validation loss: 1.6216350883565924

Epoch: 6| Step: 3
Training loss: 0.1952473223209381
Validation loss: 1.599097587729013

Epoch: 6| Step: 4
Training loss: 0.12163250148296356
Validation loss: 1.6016651738074519

Epoch: 6| Step: 5
Training loss: 0.28008997440338135
Validation loss: 1.5848577522462415

Epoch: 6| Step: 6
Training loss: 0.07792694866657257
Validation loss: 1.5971137451869186

Epoch: 6| Step: 7
Training loss: 0.15697446465492249
Validation loss: 1.6087965683270526

Epoch: 6| Step: 8
Training loss: 0.10148018598556519
Validation loss: 1.599732497686981

Epoch: 6| Step: 9
Training loss: 0.20094230771064758
Validation loss: 1.5945715199234665

Epoch: 6| Step: 10
Training loss: 0.1991511881351471
Validation loss: 1.5937434639981998

Epoch: 6| Step: 11
Training loss: 0.15674152970314026
Validation loss: 1.5871658312377108

Epoch: 6| Step: 12
Training loss: 0.16184577345848083
Validation loss: 1.5877910711432015

Epoch: 6| Step: 13
Training loss: 0.20041987299919128
Validation loss: 1.6103454930807954

Epoch: 441| Step: 0
Training loss: 0.13838031888008118
Validation loss: 1.6092435916264851

Epoch: 6| Step: 1
Training loss: 0.09273696690797806
Validation loss: 1.620947181537587

Epoch: 6| Step: 2
Training loss: 0.17447340488433838
Validation loss: 1.6482160040127334

Epoch: 6| Step: 3
Training loss: 0.12674547731876373
Validation loss: 1.6109771805424844

Epoch: 6| Step: 4
Training loss: 0.1306685358285904
Validation loss: 1.611177703385712

Epoch: 6| Step: 5
Training loss: 0.15627825260162354
Validation loss: 1.611090849804622

Epoch: 6| Step: 6
Training loss: 0.3172493577003479
Validation loss: 1.5881326608760382

Epoch: 6| Step: 7
Training loss: 0.1747910976409912
Validation loss: 1.5865995730123212

Epoch: 6| Step: 8
Training loss: 0.07878993451595306
Validation loss: 1.5848752990845711

Epoch: 6| Step: 9
Training loss: 0.09292884916067123
Validation loss: 1.5836845149276078

Epoch: 6| Step: 10
Training loss: 0.12630152702331543
Validation loss: 1.530063970114595

Epoch: 6| Step: 11
Training loss: 0.14798572659492493
Validation loss: 1.5543476086790844

Epoch: 6| Step: 12
Training loss: 0.15401607751846313
Validation loss: 1.5266076339188444

Epoch: 6| Step: 13
Training loss: 0.22786106169223785
Validation loss: 1.5513542493184407

Epoch: 442| Step: 0
Training loss: 0.08963780105113983
Validation loss: 1.570567015678652

Epoch: 6| Step: 1
Training loss: 0.13260769844055176
Validation loss: 1.5507259317623672

Epoch: 6| Step: 2
Training loss: 0.14462901651859283
Validation loss: 1.558393002838217

Epoch: 6| Step: 3
Training loss: 0.12976376712322235
Validation loss: 1.5812823144338464

Epoch: 6| Step: 4
Training loss: 0.15389031171798706
Validation loss: 1.6088639318302114

Epoch: 6| Step: 5
Training loss: 0.12587326765060425
Validation loss: 1.5853554096914106

Epoch: 6| Step: 6
Training loss: 0.12639489769935608
Validation loss: 1.5843715539542578

Epoch: 6| Step: 7
Training loss: 0.16304564476013184
Validation loss: 1.5865359524244904

Epoch: 6| Step: 8
Training loss: 0.09354951977729797
Validation loss: 1.565331369317988

Epoch: 6| Step: 9
Training loss: 0.1778075397014618
Validation loss: 1.5593780830342283

Epoch: 6| Step: 10
Training loss: 0.14290592074394226
Validation loss: 1.5759044795907953

Epoch: 6| Step: 11
Training loss: 0.12100600451231003
Validation loss: 1.5863503691970662

Epoch: 6| Step: 12
Training loss: 0.24166539311408997
Validation loss: 1.5629055730758175

Epoch: 6| Step: 13
Training loss: 0.12293966859579086
Validation loss: 1.5751640335206063

Epoch: 443| Step: 0
Training loss: 0.17378376424312592
Validation loss: 1.5985710402970672

Epoch: 6| Step: 1
Training loss: 0.12780041992664337
Validation loss: 1.6106539131492696

Epoch: 6| Step: 2
Training loss: 0.2233809381723404
Validation loss: 1.6012076754723825

Epoch: 6| Step: 3
Training loss: 0.15709209442138672
Validation loss: 1.5845564808896793

Epoch: 6| Step: 4
Training loss: 0.04649476334452629
Validation loss: 1.5797679373013076

Epoch: 6| Step: 5
Training loss: 0.12344634532928467
Validation loss: 1.6087297085792787

Epoch: 6| Step: 6
Training loss: 0.23834915459156036
Validation loss: 1.6127966475743118

Epoch: 6| Step: 7
Training loss: 0.180842787027359
Validation loss: 1.6376433808316466

Epoch: 6| Step: 8
Training loss: 0.07858875393867493
Validation loss: 1.6282803691843504

Epoch: 6| Step: 9
Training loss: 0.0666135624051094
Validation loss: 1.6237809036367683

Epoch: 6| Step: 10
Training loss: 0.15308254957199097
Validation loss: 1.6228137400842482

Epoch: 6| Step: 11
Training loss: 0.0888097733259201
Validation loss: 1.6404294057558941

Epoch: 6| Step: 12
Training loss: 0.08181129395961761
Validation loss: 1.6085296395004436

Epoch: 6| Step: 13
Training loss: 0.1579650491476059
Validation loss: 1.6260675896880448

Epoch: 444| Step: 0
Training loss: 0.06915229558944702
Validation loss: 1.638678648138559

Epoch: 6| Step: 1
Training loss: 0.13699406385421753
Validation loss: 1.6151664795414094

Epoch: 6| Step: 2
Training loss: 0.1058419942855835
Validation loss: 1.6201136035303916

Epoch: 6| Step: 3
Training loss: 0.25008511543273926
Validation loss: 1.5993952084613103

Epoch: 6| Step: 4
Training loss: 0.0955851823091507
Validation loss: 1.6053030183238368

Epoch: 6| Step: 5
Training loss: 0.17969265580177307
Validation loss: 1.5843945549380394

Epoch: 6| Step: 6
Training loss: 0.1661418378353119
Validation loss: 1.590854419815925

Epoch: 6| Step: 7
Training loss: 0.07077927887439728
Validation loss: 1.5728894638758835

Epoch: 6| Step: 8
Training loss: 0.17128390073776245
Validation loss: 1.572231682397986

Epoch: 6| Step: 9
Training loss: 0.1380942016839981
Validation loss: 1.5561349302209833

Epoch: 6| Step: 10
Training loss: 0.10335256904363632
Validation loss: 1.5754877777509793

Epoch: 6| Step: 11
Training loss: 0.09382826089859009
Validation loss: 1.560061106117823

Epoch: 6| Step: 12
Training loss: 0.08620733767747879
Validation loss: 1.5554756131223453

Epoch: 6| Step: 13
Training loss: 0.1147744357585907
Validation loss: 1.5475399878717238

Epoch: 445| Step: 0
Training loss: 0.09738288819789886
Validation loss: 1.5393542846043904

Epoch: 6| Step: 1
Training loss: 0.12831875681877136
Validation loss: 1.556875108390726

Epoch: 6| Step: 2
Training loss: 0.17125985026359558
Validation loss: 1.5487992763519287

Epoch: 6| Step: 3
Training loss: 0.149485781788826
Validation loss: 1.5624662342891897

Epoch: 6| Step: 4
Training loss: 0.13215650618076324
Validation loss: 1.5845135623408901

Epoch: 6| Step: 5
Training loss: 0.18554235994815826
Validation loss: 1.5738247825253395

Epoch: 6| Step: 6
Training loss: 0.07471570372581482
Validation loss: 1.5495647653456657

Epoch: 6| Step: 7
Training loss: 0.08405250310897827
Validation loss: 1.5848310967927337

Epoch: 6| Step: 8
Training loss: 0.14669808745384216
Validation loss: 1.5964145519400155

Epoch: 6| Step: 9
Training loss: 0.10652559995651245
Validation loss: 1.5662221344568397

Epoch: 6| Step: 10
Training loss: 0.12062741070985794
Validation loss: 1.547023093828591

Epoch: 6| Step: 11
Training loss: 0.2550342381000519
Validation loss: 1.560616716261833

Epoch: 6| Step: 12
Training loss: 0.05296853184700012
Validation loss: 1.5681572402677229

Epoch: 6| Step: 13
Training loss: 0.09253314137458801
Validation loss: 1.5520860559196883

Epoch: 446| Step: 0
Training loss: 0.14786508679389954
Validation loss: 1.5378542882139965

Epoch: 6| Step: 1
Training loss: 0.1456368863582611
Validation loss: 1.5655449936466832

Epoch: 6| Step: 2
Training loss: 0.11799605190753937
Validation loss: 1.546824788534513

Epoch: 6| Step: 3
Training loss: 0.22245395183563232
Validation loss: 1.5619134159498318

Epoch: 6| Step: 4
Training loss: 0.13350099325180054
Validation loss: 1.5417300962632703

Epoch: 6| Step: 5
Training loss: 0.1335269808769226
Validation loss: 1.5660780475985618

Epoch: 6| Step: 6
Training loss: 0.1284123957157135
Validation loss: 1.5778226249961442

Epoch: 6| Step: 7
Training loss: 0.1670786440372467
Validation loss: 1.569149125006891

Epoch: 6| Step: 8
Training loss: 0.10590171813964844
Validation loss: 1.5828107262170443

Epoch: 6| Step: 9
Training loss: 0.12890322506427765
Validation loss: 1.5792432305633382

Epoch: 6| Step: 10
Training loss: 0.11275972425937653
Validation loss: 1.604444775530087

Epoch: 6| Step: 11
Training loss: 0.10310407727956772
Validation loss: 1.5839530844842233

Epoch: 6| Step: 12
Training loss: 0.1155906617641449
Validation loss: 1.6003460294456893

Epoch: 6| Step: 13
Training loss: 0.07295344769954681
Validation loss: 1.640877616020941

Epoch: 447| Step: 0
Training loss: 0.30573412775993347
Validation loss: 1.660199188417004

Epoch: 6| Step: 1
Training loss: 0.06587204337120056
Validation loss: 1.6423510582216325

Epoch: 6| Step: 2
Training loss: 0.13026219606399536
Validation loss: 1.665406503985005

Epoch: 6| Step: 3
Training loss: 0.134329691529274
Validation loss: 1.636860029671782

Epoch: 6| Step: 4
Training loss: 0.1007126197218895
Validation loss: 1.657467039682532

Epoch: 6| Step: 5
Training loss: 0.0766914039850235
Validation loss: 1.6256065137924687

Epoch: 6| Step: 6
Training loss: 0.06814438104629517
Validation loss: 1.6179110850057294

Epoch: 6| Step: 7
Training loss: 0.13419969379901886
Validation loss: 1.6018720333294203

Epoch: 6| Step: 8
Training loss: 0.11092586815357208
Validation loss: 1.6050905591698104

Epoch: 6| Step: 9
Training loss: 0.1610332727432251
Validation loss: 1.5981013339052919

Epoch: 6| Step: 10
Training loss: 0.135474294424057
Validation loss: 1.5861529227226012

Epoch: 6| Step: 11
Training loss: 0.17714256048202515
Validation loss: 1.5949891985103648

Epoch: 6| Step: 12
Training loss: 0.11209090799093246
Validation loss: 1.5513257826528242

Epoch: 6| Step: 13
Training loss: 0.1444249153137207
Validation loss: 1.5773674711104362

Epoch: 448| Step: 0
Training loss: 0.10535693168640137
Validation loss: 1.5831894002934939

Epoch: 6| Step: 1
Training loss: 0.13566049933433533
Validation loss: 1.5660244322592212

Epoch: 6| Step: 2
Training loss: 0.1051664799451828
Validation loss: 1.576107910884324

Epoch: 6| Step: 3
Training loss: 0.14522621035575867
Validation loss: 1.5984830984505274

Epoch: 6| Step: 4
Training loss: 0.15337234735488892
Validation loss: 1.5911413290167367

Epoch: 6| Step: 5
Training loss: 0.16184447705745697
Validation loss: 1.5964571481109948

Epoch: 6| Step: 6
Training loss: 0.13983504474163055
Validation loss: 1.6267710090965353

Epoch: 6| Step: 7
Training loss: 0.10455240309238434
Validation loss: 1.6249989283982145

Epoch: 6| Step: 8
Training loss: 0.15739333629608154
Validation loss: 1.605767584616138

Epoch: 6| Step: 9
Training loss: 0.13179725408554077
Validation loss: 1.5787396379696426

Epoch: 6| Step: 10
Training loss: 0.14752650260925293
Validation loss: 1.581363231905045

Epoch: 6| Step: 11
Training loss: 0.10890233516693115
Validation loss: 1.550435689187819

Epoch: 6| Step: 12
Training loss: 0.21516942977905273
Validation loss: 1.5487112396506852

Epoch: 6| Step: 13
Training loss: 0.15617772936820984
Validation loss: 1.544210640333032

Epoch: 449| Step: 0
Training loss: 0.09341250360012054
Validation loss: 1.5762477818355765

Epoch: 6| Step: 1
Training loss: 0.07614493370056152
Validation loss: 1.5831524864319833

Epoch: 6| Step: 2
Training loss: 0.19546058773994446
Validation loss: 1.6176191363283383

Epoch: 6| Step: 3
Training loss: 0.14555399119853973
Validation loss: 1.6153562415030696

Epoch: 6| Step: 4
Training loss: 0.060787517577409744
Validation loss: 1.6230563002247964

Epoch: 6| Step: 5
Training loss: 0.12220364063978195
Validation loss: 1.6217677234321513

Epoch: 6| Step: 6
Training loss: 0.1412452906370163
Validation loss: 1.5721474744940316

Epoch: 6| Step: 7
Training loss: 0.26217320561408997
Validation loss: 1.562847073360156

Epoch: 6| Step: 8
Training loss: 0.21248933672904968
Validation loss: 1.561235676529587

Epoch: 6| Step: 9
Training loss: 0.21653267741203308
Validation loss: 1.55930495262146

Epoch: 6| Step: 10
Training loss: 0.12903465330600739
Validation loss: 1.5512986401075959

Epoch: 6| Step: 11
Training loss: 0.1576860547065735
Validation loss: 1.5773273424435688

Epoch: 6| Step: 12
Training loss: 0.06144719570875168
Validation loss: 1.5308846427548317

Epoch: 6| Step: 13
Training loss: 0.07219824194908142
Validation loss: 1.5339886616635066

Epoch: 450| Step: 0
Training loss: 0.1347004473209381
Validation loss: 1.5613832243027226

Epoch: 6| Step: 1
Training loss: 0.09704612195491791
Validation loss: 1.5577159158645137

Epoch: 6| Step: 2
Training loss: 0.2002135068178177
Validation loss: 1.5697676212556901

Epoch: 6| Step: 3
Training loss: 0.0967833623290062
Validation loss: 1.571250605326827

Epoch: 6| Step: 4
Training loss: 0.18247665464878082
Validation loss: 1.5814188846977808

Epoch: 6| Step: 5
Training loss: 0.06212078779935837
Validation loss: 1.5845804381114181

Epoch: 6| Step: 6
Training loss: 0.12009839713573456
Validation loss: 1.5876482712325228

Epoch: 6| Step: 7
Training loss: 0.1137695461511612
Validation loss: 1.5811502548956102

Epoch: 6| Step: 8
Training loss: 0.06686894595623016
Validation loss: 1.5766946859257196

Epoch: 6| Step: 9
Training loss: 0.18349331617355347
Validation loss: 1.578558709031792

Epoch: 6| Step: 10
Training loss: 0.07529395818710327
Validation loss: 1.5937734496208928

Epoch: 6| Step: 11
Training loss: 0.10593172907829285
Validation loss: 1.558471957842509

Epoch: 6| Step: 12
Training loss: 0.11592231690883636
Validation loss: 1.590266304631387

Epoch: 6| Step: 13
Training loss: 0.21902437508106232
Validation loss: 1.5776968335592618

Epoch: 451| Step: 0
Training loss: 0.1150195300579071
Validation loss: 1.577802554253609

Epoch: 6| Step: 1
Training loss: 0.13598589599132538
Validation loss: 1.5676779849554903

Epoch: 6| Step: 2
Training loss: 0.1280553936958313
Validation loss: 1.6009099150216708

Epoch: 6| Step: 3
Training loss: 0.09729905426502228
Validation loss: 1.6065034609968945

Epoch: 6| Step: 4
Training loss: 0.12064139544963837
Validation loss: 1.602454513631841

Epoch: 6| Step: 5
Training loss: 0.117306649684906
Validation loss: 1.5706572814654278

Epoch: 6| Step: 6
Training loss: 0.11576743423938751
Validation loss: 1.6040093770591162

Epoch: 6| Step: 7
Training loss: 0.2997959852218628
Validation loss: 1.590111779910262

Epoch: 6| Step: 8
Training loss: 0.08691886067390442
Validation loss: 1.568339720849068

Epoch: 6| Step: 9
Training loss: 0.11803688853979111
Validation loss: 1.612161467152257

Epoch: 6| Step: 10
Training loss: 0.1459525227546692
Validation loss: 1.5974944817122592

Epoch: 6| Step: 11
Training loss: 0.06849512457847595
Validation loss: 1.570963967231012

Epoch: 6| Step: 12
Training loss: 0.11271187663078308
Validation loss: 1.5877373808173723

Epoch: 6| Step: 13
Training loss: 0.04165584594011307
Validation loss: 1.5596046614390549

Epoch: 452| Step: 0
Training loss: 0.15226149559020996
Validation loss: 1.5607693554252706

Epoch: 6| Step: 1
Training loss: 0.14874032139778137
Validation loss: 1.5590883096059163

Epoch: 6| Step: 2
Training loss: 0.13622339069843292
Validation loss: 1.5633574044832619

Epoch: 6| Step: 3
Training loss: 0.07629276067018509
Validation loss: 1.5849344435558523

Epoch: 6| Step: 4
Training loss: 0.10372849553823471
Validation loss: 1.592980961645803

Epoch: 6| Step: 5
Training loss: 0.14179714024066925
Validation loss: 1.6096319421645133

Epoch: 6| Step: 6
Training loss: 0.1413724273443222
Validation loss: 1.6134533933413926

Epoch: 6| Step: 7
Training loss: 0.16537974774837494
Validation loss: 1.625759119628578

Epoch: 6| Step: 8
Training loss: 0.11765242367982864
Validation loss: 1.6303905030732513

Epoch: 6| Step: 9
Training loss: 0.12150293588638306
Validation loss: 1.6140199386945335

Epoch: 6| Step: 10
Training loss: 0.1019136905670166
Validation loss: 1.6106754413215063

Epoch: 6| Step: 11
Training loss: 0.1822376400232315
Validation loss: 1.6078882576316915

Epoch: 6| Step: 12
Training loss: 0.08713175356388092
Validation loss: 1.6054739759814354

Epoch: 6| Step: 13
Training loss: 0.07759825140237808
Validation loss: 1.580645143344838

Epoch: 453| Step: 0
Training loss: 0.22257927060127258
Validation loss: 1.5749890573563115

Epoch: 6| Step: 1
Training loss: 0.14493994414806366
Validation loss: 1.5912718003795994

Epoch: 6| Step: 2
Training loss: 0.14018766582012177
Validation loss: 1.5938087009614514

Epoch: 6| Step: 3
Training loss: 0.10584715008735657
Validation loss: 1.5707021592765726

Epoch: 6| Step: 4
Training loss: 0.10467874258756638
Validation loss: 1.5886765282641175

Epoch: 6| Step: 5
Training loss: 0.22415712475776672
Validation loss: 1.580813709125724

Epoch: 6| Step: 6
Training loss: 0.12961256504058838
Validation loss: 1.5808658125579997

Epoch: 6| Step: 7
Training loss: 0.05373087152838707
Validation loss: 1.6187049240194342

Epoch: 6| Step: 8
Training loss: 0.06618473678827286
Validation loss: 1.5922933342636272

Epoch: 6| Step: 9
Training loss: 0.10563254356384277
Validation loss: 1.5909905036290486

Epoch: 6| Step: 10
Training loss: 0.17690066993236542
Validation loss: 1.6175469608717068

Epoch: 6| Step: 11
Training loss: 0.10378294438123703
Validation loss: 1.567291594320728

Epoch: 6| Step: 12
Training loss: 0.05529133230447769
Validation loss: 1.5721408936285204

Epoch: 6| Step: 13
Training loss: 0.07649635523557663
Validation loss: 1.5564439347995225

Epoch: 454| Step: 0
Training loss: 0.060666341334581375
Validation loss: 1.5449860967615598

Epoch: 6| Step: 1
Training loss: 0.05445060878992081
Validation loss: 1.5235090178828086

Epoch: 6| Step: 2
Training loss: 0.12462843209505081
Validation loss: 1.538278204138561

Epoch: 6| Step: 3
Training loss: 0.07605323195457458
Validation loss: 1.5360075825004167

Epoch: 6| Step: 4
Training loss: 0.2384868562221527
Validation loss: 1.5150330810136692

Epoch: 6| Step: 5
Training loss: 0.1009155809879303
Validation loss: 1.546513033169572

Epoch: 6| Step: 6
Training loss: 0.15378405153751373
Validation loss: 1.5387902926373225

Epoch: 6| Step: 7
Training loss: 0.10125774145126343
Validation loss: 1.529552709671759

Epoch: 6| Step: 8
Training loss: 0.0817226767539978
Validation loss: 1.5465845266977947

Epoch: 6| Step: 9
Training loss: 0.075027234852314
Validation loss: 1.5424924729972758

Epoch: 6| Step: 10
Training loss: 0.20259463787078857
Validation loss: 1.555800389218074

Epoch: 6| Step: 11
Training loss: 0.15823078155517578
Validation loss: 1.562896736206547

Epoch: 6| Step: 12
Training loss: 0.13801740109920502
Validation loss: 1.5768469706658395

Epoch: 6| Step: 13
Training loss: 0.06160369887948036
Validation loss: 1.597522856086813

Epoch: 455| Step: 0
Training loss: 0.18444925546646118
Validation loss: 1.5905188232339837

Epoch: 6| Step: 1
Training loss: 0.08742471039295197
Validation loss: 1.6137111071617372

Epoch: 6| Step: 2
Training loss: 0.10058712959289551
Validation loss: 1.6051918614295222

Epoch: 6| Step: 3
Training loss: 0.07821156829595566
Validation loss: 1.6182399001172794

Epoch: 6| Step: 4
Training loss: 0.12852440774440765
Validation loss: 1.603564445049532

Epoch: 6| Step: 5
Training loss: 0.19232381880283356
Validation loss: 1.6101609635096725

Epoch: 6| Step: 6
Training loss: 0.17288705706596375
Validation loss: 1.6168082708953528

Epoch: 6| Step: 7
Training loss: 0.0957065224647522
Validation loss: 1.6249408798833047

Epoch: 6| Step: 8
Training loss: 0.08039340376853943
Validation loss: 1.6183330000087779

Epoch: 6| Step: 9
Training loss: 0.20881304144859314
Validation loss: 1.615759075328868

Epoch: 6| Step: 10
Training loss: 0.1206834465265274
Validation loss: 1.6192063836641208

Epoch: 6| Step: 11
Training loss: 0.13928255438804626
Validation loss: 1.6196812506644958

Epoch: 6| Step: 12
Training loss: 0.07814659923315048
Validation loss: 1.6317252330882575

Epoch: 6| Step: 13
Training loss: 0.1344866007566452
Validation loss: 1.6107310825778591

Epoch: 456| Step: 0
Training loss: 0.10822027921676636
Validation loss: 1.6027689890194965

Epoch: 6| Step: 1
Training loss: 0.11027604341506958
Validation loss: 1.6106984833235383

Epoch: 6| Step: 2
Training loss: 0.07593569904565811
Validation loss: 1.620145381137889

Epoch: 6| Step: 3
Training loss: 0.12700703740119934
Validation loss: 1.6229024971685102

Epoch: 6| Step: 4
Training loss: 0.07768598198890686
Validation loss: 1.6200799454924881

Epoch: 6| Step: 5
Training loss: 0.1414019763469696
Validation loss: 1.6007735690762919

Epoch: 6| Step: 6
Training loss: 0.09833171963691711
Validation loss: 1.5952876652440717

Epoch: 6| Step: 7
Training loss: 0.14776098728179932
Validation loss: 1.6051243171896985

Epoch: 6| Step: 8
Training loss: 0.10211671888828278
Validation loss: 1.6026534290723904

Epoch: 6| Step: 9
Training loss: 0.0944719985127449
Validation loss: 1.6251275706034836

Epoch: 6| Step: 10
Training loss: 0.17544136941432953
Validation loss: 1.6058061065212372

Epoch: 6| Step: 11
Training loss: 0.22264641523361206
Validation loss: 1.6156568437494256

Epoch: 6| Step: 12
Training loss: 0.16527517139911652
Validation loss: 1.5987407898390165

Epoch: 6| Step: 13
Training loss: 0.06348388642072678
Validation loss: 1.6035981729466429

Epoch: 457| Step: 0
Training loss: 0.11689699441194534
Validation loss: 1.5793460120436966

Epoch: 6| Step: 1
Training loss: 0.1819949597120285
Validation loss: 1.582731916058448

Epoch: 6| Step: 2
Training loss: 0.07750944793224335
Validation loss: 1.573284528588736

Epoch: 6| Step: 3
Training loss: 0.12614744901657104
Validation loss: 1.5718363933665778

Epoch: 6| Step: 4
Training loss: 0.06579748541116714
Validation loss: 1.5749572118123372

Epoch: 6| Step: 5
Training loss: 0.11785382032394409
Validation loss: 1.5429431033390824

Epoch: 6| Step: 6
Training loss: 0.12461750954389572
Validation loss: 1.5549156563256377

Epoch: 6| Step: 7
Training loss: 0.07541542500257492
Validation loss: 1.5491814844069942

Epoch: 6| Step: 8
Training loss: 0.1166628897190094
Validation loss: 1.535558396770108

Epoch: 6| Step: 9
Training loss: 0.16292625665664673
Validation loss: 1.5388289177289574

Epoch: 6| Step: 10
Training loss: 0.13747787475585938
Validation loss: 1.5267081875954904

Epoch: 6| Step: 11
Training loss: 0.09982210397720337
Validation loss: 1.5325890882040865

Epoch: 6| Step: 12
Training loss: 0.07656240463256836
Validation loss: 1.5116508506959485

Epoch: 6| Step: 13
Training loss: 0.0747213065624237
Validation loss: 1.5221543747891662

Epoch: 458| Step: 0
Training loss: 0.05469321087002754
Validation loss: 1.5333466952846897

Epoch: 6| Step: 1
Training loss: 0.13912832736968994
Validation loss: 1.5218871895984938

Epoch: 6| Step: 2
Training loss: 0.1954783797264099
Validation loss: 1.5273836030754993

Epoch: 6| Step: 3
Training loss: 0.08787712454795837
Validation loss: 1.5485224134178572

Epoch: 6| Step: 4
Training loss: 0.07697182893753052
Validation loss: 1.567234936580863

Epoch: 6| Step: 5
Training loss: 0.06007920205593109
Validation loss: 1.5873650555969567

Epoch: 6| Step: 6
Training loss: 0.2024737447500229
Validation loss: 1.581798053556873

Epoch: 6| Step: 7
Training loss: 0.206655353307724
Validation loss: 1.5920912245268464

Epoch: 6| Step: 8
Training loss: 0.07789593935012817
Validation loss: 1.5770845900299728

Epoch: 6| Step: 9
Training loss: 0.0849205031991005
Validation loss: 1.5524042960136168

Epoch: 6| Step: 10
Training loss: 0.12672367691993713
Validation loss: 1.579001808038322

Epoch: 6| Step: 11
Training loss: 0.15542913973331451
Validation loss: 1.5724902999016546

Epoch: 6| Step: 12
Training loss: 0.1378900706768036
Validation loss: 1.5595369415898477

Epoch: 6| Step: 13
Training loss: 0.05476093292236328
Validation loss: 1.5416474688437678

Epoch: 459| Step: 0
Training loss: 0.18503797054290771
Validation loss: 1.5409880453540432

Epoch: 6| Step: 1
Training loss: 0.2198735773563385
Validation loss: 1.5458395981019544

Epoch: 6| Step: 2
Training loss: 0.09161671996116638
Validation loss: 1.5285789953765048

Epoch: 6| Step: 3
Training loss: 0.14353331923484802
Validation loss: 1.5342456243371452

Epoch: 6| Step: 4
Training loss: 0.12733644247055054
Validation loss: 1.5453072209512033

Epoch: 6| Step: 5
Training loss: 0.14303043484687805
Validation loss: 1.5655498684093516

Epoch: 6| Step: 6
Training loss: 0.1453981101512909
Validation loss: 1.604122632934201

Epoch: 6| Step: 7
Training loss: 0.1092907190322876
Validation loss: 1.594885185200681

Epoch: 6| Step: 8
Training loss: 0.10190100967884064
Validation loss: 1.6242007158135856

Epoch: 6| Step: 9
Training loss: 0.07510615140199661
Validation loss: 1.6005320190101542

Epoch: 6| Step: 10
Training loss: 0.0960584431886673
Validation loss: 1.5738980001018894

Epoch: 6| Step: 11
Training loss: 0.07173638045787811
Validation loss: 1.5724211636409964

Epoch: 6| Step: 12
Training loss: 0.07710526138544083
Validation loss: 1.605794212510509

Epoch: 6| Step: 13
Training loss: 0.06290778517723083
Validation loss: 1.593739450618785

Epoch: 460| Step: 0
Training loss: 0.07918764650821686
Validation loss: 1.5844633079344226

Epoch: 6| Step: 1
Training loss: 0.12474501132965088
Validation loss: 1.5847339425035702

Epoch: 6| Step: 2
Training loss: 0.122386135160923
Validation loss: 1.5891677141189575

Epoch: 6| Step: 3
Training loss: 0.07159500569105148
Validation loss: 1.6056595720270628

Epoch: 6| Step: 4
Training loss: 0.11731141060590744
Validation loss: 1.5733558042075044

Epoch: 6| Step: 5
Training loss: 0.0950964167714119
Validation loss: 1.5811208601920836

Epoch: 6| Step: 6
Training loss: 0.09410077333450317
Validation loss: 1.5339420636494954

Epoch: 6| Step: 7
Training loss: 0.10931895673274994
Validation loss: 1.5597075364922965

Epoch: 6| Step: 8
Training loss: 0.1472100466489792
Validation loss: 1.5480844782244774

Epoch: 6| Step: 9
Training loss: 0.04624902456998825
Validation loss: 1.571902241758121

Epoch: 6| Step: 10
Training loss: 0.08281853795051575
Validation loss: 1.575237677943322

Epoch: 6| Step: 11
Training loss: 0.19289883971214294
Validation loss: 1.542399328242066

Epoch: 6| Step: 12
Training loss: 0.11290578544139862
Validation loss: 1.5589655022467337

Epoch: 6| Step: 13
Training loss: 0.08717986941337585
Validation loss: 1.5743646942159182

Epoch: 461| Step: 0
Training loss: 0.13927213847637177
Validation loss: 1.5617395600964945

Epoch: 6| Step: 1
Training loss: 0.0715944692492485
Validation loss: 1.5601441783289756

Epoch: 6| Step: 2
Training loss: 0.08115322887897491
Validation loss: 1.5818526526933074

Epoch: 6| Step: 3
Training loss: 0.11305554211139679
Validation loss: 1.621762115468261

Epoch: 6| Step: 4
Training loss: 0.1374034881591797
Validation loss: 1.604067539656034

Epoch: 6| Step: 5
Training loss: 0.11087502539157867
Validation loss: 1.5597072493645452

Epoch: 6| Step: 6
Training loss: 0.13816606998443604
Validation loss: 1.6039128688073927

Epoch: 6| Step: 7
Training loss: 0.07898399233818054
Validation loss: 1.608076516018119

Epoch: 6| Step: 8
Training loss: 0.08168677985668182
Validation loss: 1.591993652364259

Epoch: 6| Step: 9
Training loss: 0.1353289783000946
Validation loss: 1.6025051993708457

Epoch: 6| Step: 10
Training loss: 0.09785224497318268
Validation loss: 1.5887906871816164

Epoch: 6| Step: 11
Training loss: 0.1518155187368393
Validation loss: 1.5764709570074593

Epoch: 6| Step: 12
Training loss: 0.13945138454437256
Validation loss: 1.5767442487901258

Epoch: 6| Step: 13
Training loss: 0.24308210611343384
Validation loss: 1.5838957319977462

Epoch: 462| Step: 0
Training loss: 0.07047463208436966
Validation loss: 1.5766026691723896

Epoch: 6| Step: 1
Training loss: 0.09107086062431335
Validation loss: 1.557598767742034

Epoch: 6| Step: 2
Training loss: 0.11712964624166489
Validation loss: 1.5842831237341768

Epoch: 6| Step: 3
Training loss: 0.08505824208259583
Validation loss: 1.5599606460140598

Epoch: 6| Step: 4
Training loss: 0.1722480058670044
Validation loss: 1.5546855644513202

Epoch: 6| Step: 5
Training loss: 0.11225732415914536
Validation loss: 1.5505029898817821

Epoch: 6| Step: 6
Training loss: 0.12120320647954941
Validation loss: 1.5492500323121265

Epoch: 6| Step: 7
Training loss: 0.19029489159584045
Validation loss: 1.5545021628820768

Epoch: 6| Step: 8
Training loss: 0.11117410659790039
Validation loss: 1.5574278959663965

Epoch: 6| Step: 9
Training loss: 0.07850505411624908
Validation loss: 1.5412091644861365

Epoch: 6| Step: 10
Training loss: 0.11446229368448257
Validation loss: 1.544938357927466

Epoch: 6| Step: 11
Training loss: 0.09467334300279617
Validation loss: 1.5616628200777116

Epoch: 6| Step: 12
Training loss: 0.09977834671735764
Validation loss: 1.5539644918134135

Epoch: 6| Step: 13
Training loss: 0.0731789618730545
Validation loss: 1.535789269272999

Epoch: 463| Step: 0
Training loss: 0.06126317009329796
Validation loss: 1.5530860500950967

Epoch: 6| Step: 1
Training loss: 0.12159819155931473
Validation loss: 1.5332531518833612

Epoch: 6| Step: 2
Training loss: 0.10977619886398315
Validation loss: 1.5271276312489663

Epoch: 6| Step: 3
Training loss: 0.09369023144245148
Validation loss: 1.551467894225992

Epoch: 6| Step: 4
Training loss: 0.12133382260799408
Validation loss: 1.5355784341853151

Epoch: 6| Step: 5
Training loss: 0.05009375140070915
Validation loss: 1.5407842654053883

Epoch: 6| Step: 6
Training loss: 0.11799164116382599
Validation loss: 1.5568227024488552

Epoch: 6| Step: 7
Training loss: 0.06779439747333527
Validation loss: 1.567758039761615

Epoch: 6| Step: 8
Training loss: 0.1356450617313385
Validation loss: 1.5482729865658669

Epoch: 6| Step: 9
Training loss: 0.11719924956560135
Validation loss: 1.5645103262316795

Epoch: 6| Step: 10
Training loss: 0.20392313599586487
Validation loss: 1.550539623024643

Epoch: 6| Step: 11
Training loss: 0.1673460602760315
Validation loss: 1.606368052062168

Epoch: 6| Step: 12
Training loss: 0.0925016775727272
Validation loss: 1.567459599946135

Epoch: 6| Step: 13
Training loss: 0.08896751701831818
Validation loss: 1.571356164511814

Epoch: 464| Step: 0
Training loss: 0.08381699025630951
Validation loss: 1.581485980300493

Epoch: 6| Step: 1
Training loss: 0.12942683696746826
Validation loss: 1.5844591689366165

Epoch: 6| Step: 2
Training loss: 0.10183776915073395
Validation loss: 1.563836943718695

Epoch: 6| Step: 3
Training loss: 0.1188601702451706
Validation loss: 1.570512483837784

Epoch: 6| Step: 4
Training loss: 0.11744654178619385
Validation loss: 1.5644044517188944

Epoch: 6| Step: 5
Training loss: 0.22156985104084015
Validation loss: 1.5743222172542284

Epoch: 6| Step: 6
Training loss: 0.13679835200309753
Validation loss: 1.5688773944813719

Epoch: 6| Step: 7
Training loss: 0.09558285772800446
Validation loss: 1.5685686924124276

Epoch: 6| Step: 8
Training loss: 0.08636350184679031
Validation loss: 1.5516826632202312

Epoch: 6| Step: 9
Training loss: 0.08648618310689926
Validation loss: 1.5380460094380122

Epoch: 6| Step: 10
Training loss: 0.05790375545620918
Validation loss: 1.5689365043435046

Epoch: 6| Step: 11
Training loss: 0.0790444165468216
Validation loss: 1.572725055038288

Epoch: 6| Step: 12
Training loss: 0.10384891927242279
Validation loss: 1.5793223842497794

Epoch: 6| Step: 13
Training loss: 0.07585505396127701
Validation loss: 1.5841342146678636

Epoch: 465| Step: 0
Training loss: 0.06777828186750412
Validation loss: 1.5870215508245653

Epoch: 6| Step: 1
Training loss: 0.06864640861749649
Validation loss: 1.5533826056347098

Epoch: 6| Step: 2
Training loss: 0.10794525593519211
Validation loss: 1.5501410820150887

Epoch: 6| Step: 3
Training loss: 0.08076518028974533
Validation loss: 1.554002272185459

Epoch: 6| Step: 4
Training loss: 0.05478851869702339
Validation loss: 1.5657110086051367

Epoch: 6| Step: 5
Training loss: 0.18773683905601501
Validation loss: 1.561716559112713

Epoch: 6| Step: 6
Training loss: 0.12699384987354279
Validation loss: 1.5696710232765443

Epoch: 6| Step: 7
Training loss: 0.12143906950950623
Validation loss: 1.5714665830776255

Epoch: 6| Step: 8
Training loss: 0.07495628297328949
Validation loss: 1.5749142285316222

Epoch: 6| Step: 9
Training loss: 0.12393965572118759
Validation loss: 1.5721592159681423

Epoch: 6| Step: 10
Training loss: 0.1404387354850769
Validation loss: 1.5804497279146665

Epoch: 6| Step: 11
Training loss: 0.1762397587299347
Validation loss: 1.5782147863859772

Epoch: 6| Step: 12
Training loss: 0.11992426216602325
Validation loss: 1.5808531238186745

Epoch: 6| Step: 13
Training loss: 0.1182064488530159
Validation loss: 1.5739703909043343

Epoch: 466| Step: 0
Training loss: 0.06422432512044907
Validation loss: 1.6124650022035003

Epoch: 6| Step: 1
Training loss: 0.08318701386451721
Validation loss: 1.640609364355764

Epoch: 6| Step: 2
Training loss: 0.19192244112491608
Validation loss: 1.6064582524761077

Epoch: 6| Step: 3
Training loss: 0.07296925783157349
Validation loss: 1.6643389066060383

Epoch: 6| Step: 4
Training loss: 0.10645630955696106
Validation loss: 1.6431338364078152

Epoch: 6| Step: 5
Training loss: 0.1410406231880188
Validation loss: 1.6393994708215036

Epoch: 6| Step: 6
Training loss: 0.12066951394081116
Validation loss: 1.6353672755661832

Epoch: 6| Step: 7
Training loss: 0.05285942554473877
Validation loss: 1.6144783868584582

Epoch: 6| Step: 8
Training loss: 0.15573976933956146
Validation loss: 1.5959613220666045

Epoch: 6| Step: 9
Training loss: 0.09179741889238358
Validation loss: 1.5921721471253263

Epoch: 6| Step: 10
Training loss: 0.052063874900341034
Validation loss: 1.575091145371878

Epoch: 6| Step: 11
Training loss: 0.22515541315078735
Validation loss: 1.579829805640764

Epoch: 6| Step: 12
Training loss: 0.1168922483921051
Validation loss: 1.5629875967579503

Epoch: 6| Step: 13
Training loss: 0.15046949684619904
Validation loss: 1.5651868184407551

Epoch: 467| Step: 0
Training loss: 0.09010747075080872
Validation loss: 1.554393756774164

Epoch: 6| Step: 1
Training loss: 0.09469911456108093
Validation loss: 1.5511987747684601

Epoch: 6| Step: 2
Training loss: 0.19627262651920319
Validation loss: 1.5526135506168488

Epoch: 6| Step: 3
Training loss: 0.059781793504953384
Validation loss: 1.5889385900189799

Epoch: 6| Step: 4
Training loss: 0.11599763482809067
Validation loss: 1.5814215701113465

Epoch: 6| Step: 5
Training loss: 0.0664820671081543
Validation loss: 1.5552302598953247

Epoch: 6| Step: 6
Training loss: 0.26408952474594116
Validation loss: 1.567238078963372

Epoch: 6| Step: 7
Training loss: 0.11191591620445251
Validation loss: 1.5765031242883334

Epoch: 6| Step: 8
Training loss: 0.0817459300160408
Validation loss: 1.5632099079829391

Epoch: 6| Step: 9
Training loss: 0.1235140711069107
Validation loss: 1.555719846038408

Epoch: 6| Step: 10
Training loss: 0.1259136199951172
Validation loss: 1.5776299661205662

Epoch: 6| Step: 11
Training loss: 0.1197274923324585
Validation loss: 1.5620616046331262

Epoch: 6| Step: 12
Training loss: 0.1025802344083786
Validation loss: 1.5919337272644043

Epoch: 6| Step: 13
Training loss: 0.1391167938709259
Validation loss: 1.600908492201118

Epoch: 468| Step: 0
Training loss: 0.11505613476037979
Validation loss: 1.5880772381700494

Epoch: 6| Step: 1
Training loss: 0.04974052309989929
Validation loss: 1.6044688968248264

Epoch: 6| Step: 2
Training loss: 0.17537522315979004
Validation loss: 1.5883694848706644

Epoch: 6| Step: 3
Training loss: 0.09757734835147858
Validation loss: 1.560268900727713

Epoch: 6| Step: 4
Training loss: 0.062407538294792175
Validation loss: 1.5875348070616364

Epoch: 6| Step: 5
Training loss: 0.1242426335811615
Validation loss: 1.565251294002738

Epoch: 6| Step: 6
Training loss: 0.0868014246225357
Validation loss: 1.5708386141766784

Epoch: 6| Step: 7
Training loss: 0.10698574036359787
Validation loss: 1.5883549580010035

Epoch: 6| Step: 8
Training loss: 0.10871078819036484
Validation loss: 1.5643961891051261

Epoch: 6| Step: 9
Training loss: 0.10985815525054932
Validation loss: 1.5656840929421045

Epoch: 6| Step: 10
Training loss: 0.24132464826107025
Validation loss: 1.5696169048227289

Epoch: 6| Step: 11
Training loss: 0.07109677046537399
Validation loss: 1.5769438397499822

Epoch: 6| Step: 12
Training loss: 0.10197959840297699
Validation loss: 1.5470309308780137

Epoch: 6| Step: 13
Training loss: 0.06284824758768082
Validation loss: 1.5787622806846455

Epoch: 469| Step: 0
Training loss: 0.16307379305362701
Validation loss: 1.5806269479054276

Epoch: 6| Step: 1
Training loss: 0.10511547327041626
Validation loss: 1.6135293091497114

Epoch: 6| Step: 2
Training loss: 0.16902217268943787
Validation loss: 1.589932152020034

Epoch: 6| Step: 3
Training loss: 0.11731226742267609
Validation loss: 1.6041446475572483

Epoch: 6| Step: 4
Training loss: 0.06279844790697098
Validation loss: 1.5789918950808945

Epoch: 6| Step: 5
Training loss: 0.1346014142036438
Validation loss: 1.5835804247087049

Epoch: 6| Step: 6
Training loss: 0.09585490077733994
Validation loss: 1.5611878524544418

Epoch: 6| Step: 7
Training loss: 0.10993926972150803
Validation loss: 1.5958164609888548

Epoch: 6| Step: 8
Training loss: 0.09278026223182678
Validation loss: 1.57745700241417

Epoch: 6| Step: 9
Training loss: 0.17687207460403442
Validation loss: 1.576613828700076

Epoch: 6| Step: 10
Training loss: 0.08168371766805649
Validation loss: 1.5417884549786967

Epoch: 6| Step: 11
Training loss: 0.08603853732347488
Validation loss: 1.588795328652987

Epoch: 6| Step: 12
Training loss: 0.12235015630722046
Validation loss: 1.5927806131301387

Epoch: 6| Step: 13
Training loss: 0.13317357003688812
Validation loss: 1.6246472276667112

Epoch: 470| Step: 0
Training loss: 0.11185303330421448
Validation loss: 1.6142135461171467

Epoch: 6| Step: 1
Training loss: 0.08331792056560516
Validation loss: 1.604764303853435

Epoch: 6| Step: 2
Training loss: 0.14066815376281738
Validation loss: 1.6032402874321066

Epoch: 6| Step: 3
Training loss: 0.12209802120923996
Validation loss: 1.59372030919598

Epoch: 6| Step: 4
Training loss: 0.18253971636295319
Validation loss: 1.5927339362841781

Epoch: 6| Step: 5
Training loss: 0.10493022203445435
Validation loss: 1.59460061980832

Epoch: 6| Step: 6
Training loss: 0.16962608695030212
Validation loss: 1.5743963333868212

Epoch: 6| Step: 7
Training loss: 0.1242469996213913
Validation loss: 1.5637545995814826

Epoch: 6| Step: 8
Training loss: 0.12427914142608643
Validation loss: 1.5642667957531509

Epoch: 6| Step: 9
Training loss: 0.0909811332821846
Validation loss: 1.548557250730453

Epoch: 6| Step: 10
Training loss: 0.11903066188097
Validation loss: 1.5546107471630137

Epoch: 6| Step: 11
Training loss: 0.12943054735660553
Validation loss: 1.5326489940766366

Epoch: 6| Step: 12
Training loss: 0.07850711047649384
Validation loss: 1.5696444306322324

Epoch: 6| Step: 13
Training loss: 0.1127677783370018
Validation loss: 1.5740828744826778

Epoch: 471| Step: 0
Training loss: 0.08697782456874847
Validation loss: 1.5933403673992361

Epoch: 6| Step: 1
Training loss: 0.05932817608118057
Validation loss: 1.5741171349761307

Epoch: 6| Step: 2
Training loss: 0.11676336824893951
Validation loss: 1.5893835470240603

Epoch: 6| Step: 3
Training loss: 0.14514635503292084
Validation loss: 1.5760814182219967

Epoch: 6| Step: 4
Training loss: 0.1482800394296646
Validation loss: 1.5980079379132999

Epoch: 6| Step: 5
Training loss: 0.1511121243238449
Validation loss: 1.57847664817687

Epoch: 6| Step: 6
Training loss: 0.19074299931526184
Validation loss: 1.5638277364033524

Epoch: 6| Step: 7
Training loss: 0.07177963107824326
Validation loss: 1.5862186454957532

Epoch: 6| Step: 8
Training loss: 0.07326047122478485
Validation loss: 1.572157169542005

Epoch: 6| Step: 9
Training loss: 0.11252273619174957
Validation loss: 1.5822668203743555

Epoch: 6| Step: 10
Training loss: 0.11967336386442184
Validation loss: 1.542971852005169

Epoch: 6| Step: 11
Training loss: 0.2280747890472412
Validation loss: 1.5592093935576818

Epoch: 6| Step: 12
Training loss: 0.07597589492797852
Validation loss: 1.5571071806774344

Epoch: 6| Step: 13
Training loss: 0.1554427295923233
Validation loss: 1.558456652907915

Epoch: 472| Step: 0
Training loss: 0.05838949233293533
Validation loss: 1.5707035961971487

Epoch: 6| Step: 1
Training loss: 0.06966081261634827
Validation loss: 1.5878847933584643

Epoch: 6| Step: 2
Training loss: 0.15609019994735718
Validation loss: 1.5853869504826044

Epoch: 6| Step: 3
Training loss: 0.18390196561813354
Validation loss: 1.592002437960717

Epoch: 6| Step: 4
Training loss: 0.1299554854631424
Validation loss: 1.5980571367407357

Epoch: 6| Step: 5
Training loss: 0.13942858576774597
Validation loss: 1.6127879606780184

Epoch: 6| Step: 6
Training loss: 0.04851337894797325
Validation loss: 1.5531746424654478

Epoch: 6| Step: 7
Training loss: 0.09698891639709473
Validation loss: 1.5463365201027162

Epoch: 6| Step: 8
Training loss: 0.1887592077255249
Validation loss: 1.5710988320330137

Epoch: 6| Step: 9
Training loss: 0.06536383181810379
Validation loss: 1.5797023850102578

Epoch: 6| Step: 10
Training loss: 0.06924613565206528
Validation loss: 1.569929443379884

Epoch: 6| Step: 11
Training loss: 0.08936896920204163
Validation loss: 1.5699966312736593

Epoch: 6| Step: 12
Training loss: 0.13064919412136078
Validation loss: 1.5844144923712618

Epoch: 6| Step: 13
Training loss: 0.09611332416534424
Validation loss: 1.5707394615296395

Epoch: 473| Step: 0
Training loss: 0.12098690867424011
Validation loss: 1.5865317692038834

Epoch: 6| Step: 1
Training loss: 0.07889194786548615
Validation loss: 1.5901396402748682

Epoch: 6| Step: 2
Training loss: 0.104983851313591
Validation loss: 1.5707944067575599

Epoch: 6| Step: 3
Training loss: 0.05223441869020462
Validation loss: 1.562385300154327

Epoch: 6| Step: 4
Training loss: 0.15599989891052246
Validation loss: 1.569531927826584

Epoch: 6| Step: 5
Training loss: 0.14121538400650024
Validation loss: 1.5549459944489181

Epoch: 6| Step: 6
Training loss: 0.11791585385799408
Validation loss: 1.538773064972252

Epoch: 6| Step: 7
Training loss: 0.16400034725666046
Validation loss: 1.5322513118866952

Epoch: 6| Step: 8
Training loss: 0.20184960961341858
Validation loss: 1.5289115284078865

Epoch: 6| Step: 9
Training loss: 0.09277328103780746
Validation loss: 1.5348722152812506

Epoch: 6| Step: 10
Training loss: 0.08321629464626312
Validation loss: 1.5567685468222505

Epoch: 6| Step: 11
Training loss: 0.10359437763690948
Validation loss: 1.550519867609906

Epoch: 6| Step: 12
Training loss: 0.22895196080207825
Validation loss: 1.5833201222522284

Epoch: 6| Step: 13
Training loss: 0.0732228085398674
Validation loss: 1.6044411338785642

Epoch: 474| Step: 0
Training loss: 0.12752781808376312
Validation loss: 1.6198977372979606

Epoch: 6| Step: 1
Training loss: 0.092690110206604
Validation loss: 1.6211571385783534

Epoch: 6| Step: 2
Training loss: 0.12986774742603302
Validation loss: 1.613432825252574

Epoch: 6| Step: 3
Training loss: 0.09277474880218506
Validation loss: 1.5831211510524954

Epoch: 6| Step: 4
Training loss: 0.05310793220996857
Validation loss: 1.6067388032072334

Epoch: 6| Step: 5
Training loss: 0.2185686230659485
Validation loss: 1.584770384655204

Epoch: 6| Step: 6
Training loss: 0.11005599051713943
Validation loss: 1.5813568522853236

Epoch: 6| Step: 7
Training loss: 0.1575603485107422
Validation loss: 1.5911918301736154

Epoch: 6| Step: 8
Training loss: 0.20967711508274078
Validation loss: 1.5913286734652776

Epoch: 6| Step: 9
Training loss: 0.12885057926177979
Validation loss: 1.5823589396733109

Epoch: 6| Step: 10
Training loss: 0.16138295829296112
Validation loss: 1.6014657981934086

Epoch: 6| Step: 11
Training loss: 0.1064857468008995
Validation loss: 1.6002124701776812

Epoch: 6| Step: 12
Training loss: 0.07948897778987885
Validation loss: 1.6009695260755477

Epoch: 6| Step: 13
Training loss: 0.09860753268003464
Validation loss: 1.6051227123506608

Epoch: 475| Step: 0
Training loss: 0.15529271960258484
Validation loss: 1.6328993997266215

Epoch: 6| Step: 1
Training loss: 0.11660975962877274
Validation loss: 1.628651991967232

Epoch: 6| Step: 2
Training loss: 0.08213236182928085
Validation loss: 1.6282017128441924

Epoch: 6| Step: 3
Training loss: 0.08020059764385223
Validation loss: 1.6315463114810247

Epoch: 6| Step: 4
Training loss: 0.10121677815914154
Validation loss: 1.5921177248800955

Epoch: 6| Step: 5
Training loss: 0.0906505286693573
Validation loss: 1.5798033591239684

Epoch: 6| Step: 6
Training loss: 0.09794364869594574
Validation loss: 1.593091207806782

Epoch: 6| Step: 7
Training loss: 0.06668788194656372
Validation loss: 1.575000092547427

Epoch: 6| Step: 8
Training loss: 0.1044427677989006
Validation loss: 1.5935994848128288

Epoch: 6| Step: 9
Training loss: 0.16049672663211823
Validation loss: 1.57975249649376

Epoch: 6| Step: 10
Training loss: 0.16444335877895355
Validation loss: 1.5667903743764406

Epoch: 6| Step: 11
Training loss: 0.15822328627109528
Validation loss: 1.5882302561113912

Epoch: 6| Step: 12
Training loss: 0.10878953337669373
Validation loss: 1.5968656629644415

Epoch: 6| Step: 13
Training loss: 0.07997698336839676
Validation loss: 1.5870965821768648

Epoch: 476| Step: 0
Training loss: 0.08936819434165955
Validation loss: 1.5877155206536735

Epoch: 6| Step: 1
Training loss: 0.09629985690116882
Validation loss: 1.5927461885636853

Epoch: 6| Step: 2
Training loss: 0.12451867014169693
Validation loss: 1.5793375789478261

Epoch: 6| Step: 3
Training loss: 0.10703490674495697
Validation loss: 1.594858996329769

Epoch: 6| Step: 4
Training loss: 0.17406165599822998
Validation loss: 1.5797846765928372

Epoch: 6| Step: 5
Training loss: 0.04345518350601196
Validation loss: 1.601760551493655

Epoch: 6| Step: 6
Training loss: 0.19748732447624207
Validation loss: 1.5901627553406583

Epoch: 6| Step: 7
Training loss: 0.15409280359745026
Validation loss: 1.597882532304333

Epoch: 6| Step: 8
Training loss: 0.07454612851142883
Validation loss: 1.5936890020165393

Epoch: 6| Step: 9
Training loss: 0.09552617371082306
Validation loss: 1.5855283121908865

Epoch: 6| Step: 10
Training loss: 0.07564658671617508
Validation loss: 1.5591615092369817

Epoch: 6| Step: 11
Training loss: 0.15402752161026
Validation loss: 1.5887157019748483

Epoch: 6| Step: 12
Training loss: 0.11713704466819763
Validation loss: 1.606151335341956

Epoch: 6| Step: 13
Training loss: 0.09952419251203537
Validation loss: 1.6033053167404667

Epoch: 477| Step: 0
Training loss: 0.0768766775727272
Validation loss: 1.581740672870349

Epoch: 6| Step: 1
Training loss: 0.08653870224952698
Validation loss: 1.5686530874621483

Epoch: 6| Step: 2
Training loss: 0.1735754907131195
Validation loss: 1.582516513844972

Epoch: 6| Step: 3
Training loss: 0.10765521228313446
Validation loss: 1.5721389632071219

Epoch: 6| Step: 4
Training loss: 0.07854724675416946
Validation loss: 1.564668204194756

Epoch: 6| Step: 5
Training loss: 0.09401753544807434
Validation loss: 1.5831024416031376

Epoch: 6| Step: 6
Training loss: 0.10513909161090851
Validation loss: 1.5453124917963499

Epoch: 6| Step: 7
Training loss: 0.06360289454460144
Validation loss: 1.5497675531653947

Epoch: 6| Step: 8
Training loss: 0.11120337247848511
Validation loss: 1.5620438078398347

Epoch: 6| Step: 9
Training loss: 0.065727099776268
Validation loss: 1.56711289446841

Epoch: 6| Step: 10
Training loss: 0.11371993273496628
Validation loss: 1.548623533659084

Epoch: 6| Step: 11
Training loss: 0.11890541017055511
Validation loss: 1.5660774656521377

Epoch: 6| Step: 12
Training loss: 0.1682150661945343
Validation loss: 1.5663399696350098

Epoch: 6| Step: 13
Training loss: 0.11518391966819763
Validation loss: 1.5824114199607604

Epoch: 478| Step: 0
Training loss: 0.23922038078308105
Validation loss: 1.594533638287616

Epoch: 6| Step: 1
Training loss: 0.1357458531856537
Validation loss: 1.6182929546602312

Epoch: 6| Step: 2
Training loss: 0.15943220257759094
Validation loss: 1.6373423235390776

Epoch: 6| Step: 3
Training loss: 0.12623342871665955
Validation loss: 1.6119200465499715

Epoch: 6| Step: 4
Training loss: 0.10196938365697861
Validation loss: 1.5650370582457511

Epoch: 6| Step: 5
Training loss: 0.09531217813491821
Validation loss: 1.555299138510099

Epoch: 6| Step: 6
Training loss: 0.0968586653470993
Validation loss: 1.5953718372570571

Epoch: 6| Step: 7
Training loss: 0.1529705822467804
Validation loss: 1.5577865992822955

Epoch: 6| Step: 8
Training loss: 0.05921538919210434
Validation loss: 1.5881759351299656

Epoch: 6| Step: 9
Training loss: 0.10719946026802063
Validation loss: 1.581115484237671

Epoch: 6| Step: 10
Training loss: 0.11964627355337143
Validation loss: 1.5701022622405842

Epoch: 6| Step: 11
Training loss: 0.17905855178833008
Validation loss: 1.561726644474973

Epoch: 6| Step: 12
Training loss: 0.10647065937519073
Validation loss: 1.5768531298124662

Epoch: 6| Step: 13
Training loss: 0.05321023240685463
Validation loss: 1.5817543024657874

Epoch: 479| Step: 0
Training loss: 0.13495652377605438
Validation loss: 1.5895239448034635

Epoch: 6| Step: 1
Training loss: 0.19324558973312378
Validation loss: 1.5789924507500024

Epoch: 6| Step: 2
Training loss: 0.09019261598587036
Validation loss: 1.6054116936140164

Epoch: 6| Step: 3
Training loss: 0.06853339076042175
Validation loss: 1.6088427510312808

Epoch: 6| Step: 4
Training loss: 0.1151713877916336
Validation loss: 1.6253608952286422

Epoch: 6| Step: 5
Training loss: 0.18860025703907013
Validation loss: 1.6476313798658309

Epoch: 6| Step: 6
Training loss: 0.16048704087734222
Validation loss: 1.6614136003678845

Epoch: 6| Step: 7
Training loss: 0.14581447839736938
Validation loss: 1.6259015055112942

Epoch: 6| Step: 8
Training loss: 0.062082439661026
Validation loss: 1.5904596620990383

Epoch: 6| Step: 9
Training loss: 0.09520609676837921
Validation loss: 1.5809468146293395

Epoch: 6| Step: 10
Training loss: 0.0843002051115036
Validation loss: 1.556327856997008

Epoch: 6| Step: 11
Training loss: 0.12228083610534668
Validation loss: 1.5571652663651334

Epoch: 6| Step: 12
Training loss: 0.11106621474027634
Validation loss: 1.5574297033330446

Epoch: 6| Step: 13
Training loss: 0.3393102288246155
Validation loss: 1.5675150066293695

Epoch: 480| Step: 0
Training loss: 0.11806274950504303
Validation loss: 1.5839474624203098

Epoch: 6| Step: 1
Training loss: 0.11334578692913055
Validation loss: 1.5582175844459123

Epoch: 6| Step: 2
Training loss: 0.18842078745365143
Validation loss: 1.5641861243914532

Epoch: 6| Step: 3
Training loss: 0.0927419513463974
Validation loss: 1.5799119113593973

Epoch: 6| Step: 4
Training loss: 0.0788598358631134
Validation loss: 1.5754003249188906

Epoch: 6| Step: 5
Training loss: 0.08621804416179657
Validation loss: 1.6104972785519016

Epoch: 6| Step: 6
Training loss: 0.07470610737800598
Validation loss: 1.615021313390424

Epoch: 6| Step: 7
Training loss: 0.054475292563438416
Validation loss: 1.6039714338958904

Epoch: 6| Step: 8
Training loss: 0.1085994690656662
Validation loss: 1.6146310196127942

Epoch: 6| Step: 9
Training loss: 0.2309962809085846
Validation loss: 1.6286485169523506

Epoch: 6| Step: 10
Training loss: 0.05288250371813774
Validation loss: 1.5954516985083138

Epoch: 6| Step: 11
Training loss: 0.06743353605270386
Validation loss: 1.6014967503086213

Epoch: 6| Step: 12
Training loss: 0.1254880577325821
Validation loss: 1.5912607241702337

Epoch: 6| Step: 13
Training loss: 0.10463748127222061
Validation loss: 1.5719782690848074

Epoch: 481| Step: 0
Training loss: 0.20049455761909485
Validation loss: 1.542846651487453

Epoch: 6| Step: 1
Training loss: 0.12969964742660522
Validation loss: 1.5687933737231838

Epoch: 6| Step: 2
Training loss: 0.08576301485300064
Validation loss: 1.5751751328027377

Epoch: 6| Step: 3
Training loss: 0.09876272082328796
Validation loss: 1.6105071703592937

Epoch: 6| Step: 4
Training loss: 0.07010498642921448
Validation loss: 1.5690014618699268

Epoch: 6| Step: 5
Training loss: 0.11324357986450195
Validation loss: 1.579587192945583

Epoch: 6| Step: 6
Training loss: 0.08152741193771362
Validation loss: 1.5678127017072452

Epoch: 6| Step: 7
Training loss: 0.1826235055923462
Validation loss: 1.5788096638136013

Epoch: 6| Step: 8
Training loss: 0.10832993686199188
Validation loss: 1.5903604299791398

Epoch: 6| Step: 9
Training loss: 0.09195029735565186
Validation loss: 1.5885814851330173

Epoch: 6| Step: 10
Training loss: 0.07093103975057602
Validation loss: 1.557614500804614

Epoch: 6| Step: 11
Training loss: 0.06934241950511932
Validation loss: 1.5565362591897287

Epoch: 6| Step: 12
Training loss: 0.15005528926849365
Validation loss: 1.548943946438451

Epoch: 6| Step: 13
Training loss: 0.07130013406276703
Validation loss: 1.5461576164409678

Epoch: 482| Step: 0
Training loss: 0.13109982013702393
Validation loss: 1.5522416894153883

Epoch: 6| Step: 1
Training loss: 0.09432986378669739
Validation loss: 1.5083386334039832

Epoch: 6| Step: 2
Training loss: 0.05440644174814224
Validation loss: 1.5157263868598527

Epoch: 6| Step: 3
Training loss: 0.12398427724838257
Validation loss: 1.5190963924572032

Epoch: 6| Step: 4
Training loss: 0.15173745155334473
Validation loss: 1.5211491918051114

Epoch: 6| Step: 5
Training loss: 0.16173706948757172
Validation loss: 1.5365947722106852

Epoch: 6| Step: 6
Training loss: 0.1943783164024353
Validation loss: 1.5433953000653176

Epoch: 6| Step: 7
Training loss: 0.11146700382232666
Validation loss: 1.5499679209083639

Epoch: 6| Step: 8
Training loss: 0.0837411880493164
Validation loss: 1.5397136390850108

Epoch: 6| Step: 9
Training loss: 0.05006891489028931
Validation loss: 1.555924830898162

Epoch: 6| Step: 10
Training loss: 0.08396787941455841
Validation loss: 1.5640512756122056

Epoch: 6| Step: 11
Training loss: 0.08586126565933228
Validation loss: 1.5793452262878418

Epoch: 6| Step: 12
Training loss: 0.1335163414478302
Validation loss: 1.5884461800257366

Epoch: 6| Step: 13
Training loss: 0.041902802884578705
Validation loss: 1.5965272175368441

Epoch: 483| Step: 0
Training loss: 0.147892564535141
Validation loss: 1.5746808923700804

Epoch: 6| Step: 1
Training loss: 0.11585354059934616
Validation loss: 1.5970021909283054

Epoch: 6| Step: 2
Training loss: 0.1460760086774826
Validation loss: 1.589501396302254

Epoch: 6| Step: 3
Training loss: 0.09658686816692352
Validation loss: 1.5764178153007262

Epoch: 6| Step: 4
Training loss: 0.13068649172782898
Validation loss: 1.5649202421147337

Epoch: 6| Step: 5
Training loss: 0.17331603169441223
Validation loss: 1.5611566702524822

Epoch: 6| Step: 6
Training loss: 0.09505628794431686
Validation loss: 1.5589568576505106

Epoch: 6| Step: 7
Training loss: 0.09260573983192444
Validation loss: 1.5155351059411162

Epoch: 6| Step: 8
Training loss: 0.19524817168712616
Validation loss: 1.5377752627095869

Epoch: 6| Step: 9
Training loss: 0.09179098904132843
Validation loss: 1.554871460442902

Epoch: 6| Step: 10
Training loss: 0.09739355742931366
Validation loss: 1.5261875608915925

Epoch: 6| Step: 11
Training loss: 0.13751721382141113
Validation loss: 1.5481425690394577

Epoch: 6| Step: 12
Training loss: 0.07135673612356186
Validation loss: 1.5504325089916107

Epoch: 6| Step: 13
Training loss: 0.07789341360330582
Validation loss: 1.5360083964563185

Epoch: 484| Step: 0
Training loss: 0.17127510905265808
Validation loss: 1.566773900421717

Epoch: 6| Step: 1
Training loss: 0.18422433733940125
Validation loss: 1.5642217846326931

Epoch: 6| Step: 2
Training loss: 0.17281395196914673
Validation loss: 1.5599284261785529

Epoch: 6| Step: 3
Training loss: 0.11561264097690582
Validation loss: 1.5585730396291262

Epoch: 6| Step: 4
Training loss: 0.07836379110813141
Validation loss: 1.554651862831526

Epoch: 6| Step: 5
Training loss: 0.09432520717382431
Validation loss: 1.568436981529318

Epoch: 6| Step: 6
Training loss: 0.09990531206130981
Validation loss: 1.5454118277436943

Epoch: 6| Step: 7
Training loss: 0.1557333767414093
Validation loss: 1.5506174179815477

Epoch: 6| Step: 8
Training loss: 0.055962011218070984
Validation loss: 1.5768144207616006

Epoch: 6| Step: 9
Training loss: 0.11076874285936356
Validation loss: 1.5623449356325212

Epoch: 6| Step: 10
Training loss: 0.05870572477579117
Validation loss: 1.5494909376226447

Epoch: 6| Step: 11
Training loss: 0.11451700329780579
Validation loss: 1.5238962090143593

Epoch: 6| Step: 12
Training loss: 0.08148084580898285
Validation loss: 1.5401638066896828

Epoch: 6| Step: 13
Training loss: 0.10834821313619614
Validation loss: 1.5499460581810243

Epoch: 485| Step: 0
Training loss: 0.09535104036331177
Validation loss: 1.5690993185966247

Epoch: 6| Step: 1
Training loss: 0.15304557979106903
Validation loss: 1.5524422891678349

Epoch: 6| Step: 2
Training loss: 0.09725207835435867
Validation loss: 1.5713898276769986

Epoch: 6| Step: 3
Training loss: 0.1312381774187088
Validation loss: 1.5603392918904622

Epoch: 6| Step: 4
Training loss: 0.09984558075666428
Validation loss: 1.560430952297744

Epoch: 6| Step: 5
Training loss: 0.0892951488494873
Validation loss: 1.5643716396824006

Epoch: 6| Step: 6
Training loss: 0.09545285999774933
Validation loss: 1.5954455291071246

Epoch: 6| Step: 7
Training loss: 0.22926539182662964
Validation loss: 1.590911183305966

Epoch: 6| Step: 8
Training loss: 0.05414891988039017
Validation loss: 1.600870555446994

Epoch: 6| Step: 9
Training loss: 0.0942760482430458
Validation loss: 1.5993918411193355

Epoch: 6| Step: 10
Training loss: 0.061543162912130356
Validation loss: 1.5804789066314697

Epoch: 6| Step: 11
Training loss: 0.08259963244199753
Validation loss: 1.554773320433914

Epoch: 6| Step: 12
Training loss: 0.10541301965713501
Validation loss: 1.5584461894086612

Epoch: 6| Step: 13
Training loss: 0.0559283085167408
Validation loss: 1.5831488575986636

Epoch: 486| Step: 0
Training loss: 0.12374071031808853
Validation loss: 1.5480106748560423

Epoch: 6| Step: 1
Training loss: 0.08489872515201569
Validation loss: 1.551737194420189

Epoch: 6| Step: 2
Training loss: 0.17747345566749573
Validation loss: 1.5707075929128995

Epoch: 6| Step: 3
Training loss: 0.10339175164699554
Validation loss: 1.524543236660701

Epoch: 6| Step: 4
Training loss: 0.08331646770238876
Validation loss: 1.5492675804322766

Epoch: 6| Step: 5
Training loss: 0.16445320844650269
Validation loss: 1.5476330723813785

Epoch: 6| Step: 6
Training loss: 0.19794665277004242
Validation loss: 1.5491394176278064

Epoch: 6| Step: 7
Training loss: 0.0817699059844017
Validation loss: 1.5463380954598869

Epoch: 6| Step: 8
Training loss: 0.12233185768127441
Validation loss: 1.5469069788532872

Epoch: 6| Step: 9
Training loss: 0.09260585159063339
Validation loss: 1.5441179557513165

Epoch: 6| Step: 10
Training loss: 0.14080286026000977
Validation loss: 1.5329985836500764

Epoch: 6| Step: 11
Training loss: 0.09439397603273392
Validation loss: 1.5538393066775413

Epoch: 6| Step: 12
Training loss: 0.10365168750286102
Validation loss: 1.5952267364789081

Epoch: 6| Step: 13
Training loss: 0.05668957531452179
Validation loss: 1.5651674655175978

Epoch: 487| Step: 0
Training loss: 0.14425212144851685
Validation loss: 1.6014308519260858

Epoch: 6| Step: 1
Training loss: 0.09561887383460999
Validation loss: 1.6317651041092411

Epoch: 6| Step: 2
Training loss: 0.16096100211143494
Validation loss: 1.6323421296253

Epoch: 6| Step: 3
Training loss: 0.09649425745010376
Validation loss: 1.6221694382288123

Epoch: 6| Step: 4
Training loss: 0.07779617607593536
Validation loss: 1.6156292551307267

Epoch: 6| Step: 5
Training loss: 0.09478394687175751
Validation loss: 1.6121711500229374

Epoch: 6| Step: 6
Training loss: 0.08481226116418839
Validation loss: 1.598416656576177

Epoch: 6| Step: 7
Training loss: 0.1034746766090393
Validation loss: 1.5706586953132384

Epoch: 6| Step: 8
Training loss: 0.10506998002529144
Validation loss: 1.5673234667829288

Epoch: 6| Step: 9
Training loss: 0.10593727231025696
Validation loss: 1.5550685903077484

Epoch: 6| Step: 10
Training loss: 0.057909440249204636
Validation loss: 1.5527982365700506

Epoch: 6| Step: 11
Training loss: 0.07120601832866669
Validation loss: 1.5680625669417843

Epoch: 6| Step: 12
Training loss: 0.20892973244190216
Validation loss: 1.5514265965389948

Epoch: 6| Step: 13
Training loss: 0.0929722785949707
Validation loss: 1.5566739087463708

Epoch: 488| Step: 0
Training loss: 0.11887642741203308
Validation loss: 1.543966422798813

Epoch: 6| Step: 1
Training loss: 0.08151296526193619
Validation loss: 1.541655428947941

Epoch: 6| Step: 2
Training loss: 0.08762010931968689
Validation loss: 1.5528159615814046

Epoch: 6| Step: 3
Training loss: 0.058214277029037476
Validation loss: 1.5401998527588383

Epoch: 6| Step: 4
Training loss: 0.1343567669391632
Validation loss: 1.5321762548979891

Epoch: 6| Step: 5
Training loss: 0.11043912917375565
Validation loss: 1.583291019162824

Epoch: 6| Step: 6
Training loss: 0.11585815995931625
Validation loss: 1.5726235348691222

Epoch: 6| Step: 7
Training loss: 0.13601617515087128
Validation loss: 1.581166285340504

Epoch: 6| Step: 8
Training loss: 0.13667187094688416
Validation loss: 1.5636736757011824

Epoch: 6| Step: 9
Training loss: 0.14746691286563873
Validation loss: 1.565915644809764

Epoch: 6| Step: 10
Training loss: 0.12607023119926453
Validation loss: 1.5694871384610412

Epoch: 6| Step: 11
Training loss: 0.2163855880498886
Validation loss: 1.5956849410969725

Epoch: 6| Step: 12
Training loss: 0.0743638202548027
Validation loss: 1.5560440183967672

Epoch: 6| Step: 13
Training loss: 0.04625023901462555
Validation loss: 1.5571858100993659

Epoch: 489| Step: 0
Training loss: 0.0883616954088211
Validation loss: 1.5920743621805662

Epoch: 6| Step: 1
Training loss: 0.26274481415748596
Validation loss: 1.6105202936357068

Epoch: 6| Step: 2
Training loss: 0.23027372360229492
Validation loss: 1.6051840166891775

Epoch: 6| Step: 3
Training loss: 0.19547820091247559
Validation loss: 1.5981627036166448

Epoch: 6| Step: 4
Training loss: 0.16889382898807526
Validation loss: 1.5765440271746727

Epoch: 6| Step: 5
Training loss: 0.05401138588786125
Validation loss: 1.540065521834999

Epoch: 6| Step: 6
Training loss: 0.14773395657539368
Validation loss: 1.5375103283953924

Epoch: 6| Step: 7
Training loss: 0.12202335894107819
Validation loss: 1.5334213805455033

Epoch: 6| Step: 8
Training loss: 0.11595895886421204
Validation loss: 1.5497005601083078

Epoch: 6| Step: 9
Training loss: 0.1483156681060791
Validation loss: 1.5872277264953942

Epoch: 6| Step: 10
Training loss: 0.28253182768821716
Validation loss: 1.5991440883246801

Epoch: 6| Step: 11
Training loss: 0.12130910903215408
Validation loss: 1.5753814892102314

Epoch: 6| Step: 12
Training loss: 0.09455251693725586
Validation loss: 1.5538252938178279

Epoch: 6| Step: 13
Training loss: 0.12233980745077133
Validation loss: 1.5755300829487462

Epoch: 490| Step: 0
Training loss: 0.14463196694850922
Validation loss: 1.5626455135242914

Epoch: 6| Step: 1
Training loss: 0.16767574846744537
Validation loss: 1.5693273916039416

Epoch: 6| Step: 2
Training loss: 0.09947508573532104
Validation loss: 1.557457027896758

Epoch: 6| Step: 3
Training loss: 0.1995619684457779
Validation loss: 1.571224626674447

Epoch: 6| Step: 4
Training loss: 0.10857684910297394
Validation loss: 1.5612163825701642

Epoch: 6| Step: 5
Training loss: 0.09374313801527023
Validation loss: 1.561950416975124

Epoch: 6| Step: 6
Training loss: 0.08894118666648865
Validation loss: 1.551415293447433

Epoch: 6| Step: 7
Training loss: 0.1003551334142685
Validation loss: 1.551153213747086

Epoch: 6| Step: 8
Training loss: 0.08153442293405533
Validation loss: 1.5411235017161216

Epoch: 6| Step: 9
Training loss: 0.09218741953372955
Validation loss: 1.529217496995003

Epoch: 6| Step: 10
Training loss: 0.05009927600622177
Validation loss: 1.5774830233666204

Epoch: 6| Step: 11
Training loss: 0.1818545162677765
Validation loss: 1.5479123464194677

Epoch: 6| Step: 12
Training loss: 0.04771693795919418
Validation loss: 1.5480551597892598

Epoch: 6| Step: 13
Training loss: 0.07750575989484787
Validation loss: 1.532444146371657

Epoch: 491| Step: 0
Training loss: 0.12933212518692017
Validation loss: 1.5429807132290256

Epoch: 6| Step: 1
Training loss: 0.06343355774879456
Validation loss: 1.5593865340755833

Epoch: 6| Step: 2
Training loss: 0.08263304084539413
Validation loss: 1.5508452525702856

Epoch: 6| Step: 3
Training loss: 0.05269679054617882
Validation loss: 1.5383827455582157

Epoch: 6| Step: 4
Training loss: 0.17742818593978882
Validation loss: 1.5744477202815395

Epoch: 6| Step: 5
Training loss: 0.09754902124404907
Validation loss: 1.5552038851604666

Epoch: 6| Step: 6
Training loss: 0.07170010358095169
Validation loss: 1.596735905575496

Epoch: 6| Step: 7
Training loss: 0.17154255509376526
Validation loss: 1.5692436515644033

Epoch: 6| Step: 8
Training loss: 0.07310625910758972
Validation loss: 1.5722926637177825

Epoch: 6| Step: 9
Training loss: 0.15489299595355988
Validation loss: 1.5542768714248494

Epoch: 6| Step: 10
Training loss: 0.10717851668596268
Validation loss: 1.5402620735988821

Epoch: 6| Step: 11
Training loss: 0.12647494673728943
Validation loss: 1.5543657259274555

Epoch: 6| Step: 12
Training loss: 0.10749660432338715
Validation loss: 1.5458008922556394

Epoch: 6| Step: 13
Training loss: 0.10480312258005142
Validation loss: 1.5373899423947899

Epoch: 492| Step: 0
Training loss: 0.20677992701530457
Validation loss: 1.510674435605285

Epoch: 6| Step: 1
Training loss: 0.08402879536151886
Validation loss: 1.5252575566691737

Epoch: 6| Step: 2
Training loss: 0.19811633229255676
Validation loss: 1.5166447521537862

Epoch: 6| Step: 3
Training loss: 0.08153241127729416
Validation loss: 1.514690658097626

Epoch: 6| Step: 4
Training loss: 0.11338667571544647
Validation loss: 1.516845408306327

Epoch: 6| Step: 5
Training loss: 0.15955492854118347
Validation loss: 1.5043456785140499

Epoch: 6| Step: 6
Training loss: 0.10427854210138321
Validation loss: 1.5123641689618428

Epoch: 6| Step: 7
Training loss: 0.07642096281051636
Validation loss: 1.5353506938103707

Epoch: 6| Step: 8
Training loss: 0.11514244973659515
Validation loss: 1.5154572904750865

Epoch: 6| Step: 9
Training loss: 0.056244924664497375
Validation loss: 1.5378509285629436

Epoch: 6| Step: 10
Training loss: 0.09121263027191162
Validation loss: 1.5710693328611312

Epoch: 6| Step: 11
Training loss: 0.13928236067295074
Validation loss: 1.570079666312023

Epoch: 6| Step: 12
Training loss: 0.07215110957622528
Validation loss: 1.5566179047348678

Epoch: 6| Step: 13
Training loss: 0.1216362714767456
Validation loss: 1.545411604706959

Epoch: 493| Step: 0
Training loss: 0.12968575954437256
Validation loss: 1.5675743626010032

Epoch: 6| Step: 1
Training loss: 0.13439980149269104
Validation loss: 1.564176982448947

Epoch: 6| Step: 2
Training loss: 0.07860918343067169
Validation loss: 1.5320396859158751

Epoch: 6| Step: 3
Training loss: 0.1891767978668213
Validation loss: 1.550290858873757

Epoch: 6| Step: 4
Training loss: 0.07446413487195969
Validation loss: 1.51791464513348

Epoch: 6| Step: 5
Training loss: 0.06675822287797928
Validation loss: 1.5275777257898802

Epoch: 6| Step: 6
Training loss: 0.10265984386205673
Validation loss: 1.523177098202449

Epoch: 6| Step: 7
Training loss: 0.06547200679779053
Validation loss: 1.5360162514512257

Epoch: 6| Step: 8
Training loss: 0.07703018933534622
Validation loss: 1.5277452917509182

Epoch: 6| Step: 9
Training loss: 0.04592439532279968
Validation loss: 1.5482578822361526

Epoch: 6| Step: 10
Training loss: 0.09058183431625366
Validation loss: 1.5402279335965392

Epoch: 6| Step: 11
Training loss: 0.2179553359746933
Validation loss: 1.5374188500065957

Epoch: 6| Step: 12
Training loss: 0.08175433427095413
Validation loss: 1.5364328430544945

Epoch: 6| Step: 13
Training loss: 0.13420231640338898
Validation loss: 1.5519616398760068

Epoch: 494| Step: 0
Training loss: 0.14522096514701843
Validation loss: 1.5405478118568339

Epoch: 6| Step: 1
Training loss: 0.13762177526950836
Validation loss: 1.567338837090359

Epoch: 6| Step: 2
Training loss: 0.06906922906637192
Validation loss: 1.5677613404489332

Epoch: 6| Step: 3
Training loss: 0.06546039879322052
Validation loss: 1.5729395151138306

Epoch: 6| Step: 4
Training loss: 0.09954915195703506
Validation loss: 1.553046190610496

Epoch: 6| Step: 5
Training loss: 0.10004934668540955
Validation loss: 1.5451987866432435

Epoch: 6| Step: 6
Training loss: 0.095230832695961
Validation loss: 1.553410195535229

Epoch: 6| Step: 7
Training loss: 0.04401310533285141
Validation loss: 1.5405507920890726

Epoch: 6| Step: 8
Training loss: 0.1676330268383026
Validation loss: 1.5369019508361816

Epoch: 6| Step: 9
Training loss: 0.1069955825805664
Validation loss: 1.5727390653343611

Epoch: 6| Step: 10
Training loss: 0.10309430956840515
Validation loss: 1.5602492645222654

Epoch: 6| Step: 11
Training loss: 0.08140042424201965
Validation loss: 1.5607649357088151

Epoch: 6| Step: 12
Training loss: 0.15527518093585968
Validation loss: 1.5536150868220995

Epoch: 6| Step: 13
Training loss: 0.08389881253242493
Validation loss: 1.5427074060645154

Epoch: 495| Step: 0
Training loss: 0.07680249959230423
Validation loss: 1.55606766926345

Epoch: 6| Step: 1
Training loss: 0.08248616755008698
Validation loss: 1.544877972654117

Epoch: 6| Step: 2
Training loss: 0.047997038811445236
Validation loss: 1.551303428988303

Epoch: 6| Step: 3
Training loss: 0.1450328677892685
Validation loss: 1.5598647389360654

Epoch: 6| Step: 4
Training loss: 0.09513871371746063
Validation loss: 1.5345437122929482

Epoch: 6| Step: 5
Training loss: 0.2826763391494751
Validation loss: 1.5526096128648328

Epoch: 6| Step: 6
Training loss: 0.061991360038518906
Validation loss: 1.5594208484054894

Epoch: 6| Step: 7
Training loss: 0.07086440920829773
Validation loss: 1.5427688244850404

Epoch: 6| Step: 8
Training loss: 0.08914651721715927
Validation loss: 1.544188053377213

Epoch: 6| Step: 9
Training loss: 0.05603419244289398
Validation loss: 1.528170601014168

Epoch: 6| Step: 10
Training loss: 0.0991656556725502
Validation loss: 1.5313897504601428

Epoch: 6| Step: 11
Training loss: 0.09424401819705963
Validation loss: 1.5474784322964248

Epoch: 6| Step: 12
Training loss: 0.10068405419588089
Validation loss: 1.5496449855066114

Epoch: 6| Step: 13
Training loss: 0.16353905200958252
Validation loss: 1.516468382650806

Epoch: 496| Step: 0
Training loss: 0.12208577990531921
Validation loss: 1.5008758870504235

Epoch: 6| Step: 1
Training loss: 0.07910194247961044
Validation loss: 1.5037070666590044

Epoch: 6| Step: 2
Training loss: 0.10198496282100677
Validation loss: 1.5188331642458517

Epoch: 6| Step: 3
Training loss: 0.06539148092269897
Validation loss: 1.4922679034612512

Epoch: 6| Step: 4
Training loss: 0.08362976461648941
Validation loss: 1.5152784521861742

Epoch: 6| Step: 5
Training loss: 0.10457999259233475
Validation loss: 1.5236862923509331

Epoch: 6| Step: 6
Training loss: 0.09098993986845016
Validation loss: 1.498590156596194

Epoch: 6| Step: 7
Training loss: 0.09102185815572739
Validation loss: 1.5231688176431963

Epoch: 6| Step: 8
Training loss: 0.09928593784570694
Validation loss: 1.5613773458747453

Epoch: 6| Step: 9
Training loss: 0.1254487782716751
Validation loss: 1.5588895813111336

Epoch: 6| Step: 10
Training loss: 0.22705423831939697
Validation loss: 1.5685788059747348

Epoch: 6| Step: 11
Training loss: 0.0746467113494873
Validation loss: 1.5434908898927833

Epoch: 6| Step: 12
Training loss: 0.09373564273118973
Validation loss: 1.5881040442374446

Epoch: 6| Step: 13
Training loss: 0.039668381214141846
Validation loss: 1.5736133129365983

Epoch: 497| Step: 0
Training loss: 0.2076990306377411
Validation loss: 1.540490787516358

Epoch: 6| Step: 1
Training loss: 0.08271980285644531
Validation loss: 1.5482076444933492

Epoch: 6| Step: 2
Training loss: 0.10083113610744476
Validation loss: 1.533062050419469

Epoch: 6| Step: 3
Training loss: 0.12660706043243408
Validation loss: 1.5279637459785707

Epoch: 6| Step: 4
Training loss: 0.06643389910459518
Validation loss: 1.5249357249147149

Epoch: 6| Step: 5
Training loss: 0.10395549237728119
Validation loss: 1.562411101274593

Epoch: 6| Step: 6
Training loss: 0.08410249650478363
Validation loss: 1.5564857804647056

Epoch: 6| Step: 7
Training loss: 0.09992976486682892
Validation loss: 1.5620324291208738

Epoch: 6| Step: 8
Training loss: 0.07961628586053848
Validation loss: 1.5648378313228648

Epoch: 6| Step: 9
Training loss: 0.10397610068321228
Validation loss: 1.5672478842478927

Epoch: 6| Step: 10
Training loss: 0.12903845310211182
Validation loss: 1.557392748453284

Epoch: 6| Step: 11
Training loss: 0.09609892219305038
Validation loss: 1.5561940567467802

Epoch: 6| Step: 12
Training loss: 0.05307586491107941
Validation loss: 1.5530883445534656

Epoch: 6| Step: 13
Training loss: 0.11868873983621597
Validation loss: 1.5305919852308048

Epoch: 498| Step: 0
Training loss: 0.0833602175116539
Validation loss: 1.5443108350999895

Epoch: 6| Step: 1
Training loss: 0.08407506346702576
Validation loss: 1.554375486989175

Epoch: 6| Step: 2
Training loss: 0.09162483364343643
Validation loss: 1.5489861401178504

Epoch: 6| Step: 3
Training loss: 0.09958017617464066
Validation loss: 1.5387745313746954

Epoch: 6| Step: 4
Training loss: 0.05321035906672478
Validation loss: 1.5253587153650099

Epoch: 6| Step: 5
Training loss: 0.07410653680562973
Validation loss: 1.561469611301217

Epoch: 6| Step: 6
Training loss: 0.0759580135345459
Validation loss: 1.5887010264140304

Epoch: 6| Step: 7
Training loss: 0.07837913185358047
Validation loss: 1.5649065612464823

Epoch: 6| Step: 8
Training loss: 0.15432654321193695
Validation loss: 1.5489132365872782

Epoch: 6| Step: 9
Training loss: 0.10451605916023254
Validation loss: 1.5646867034255818

Epoch: 6| Step: 10
Training loss: 0.10766750574111938
Validation loss: 1.5546637863241217

Epoch: 6| Step: 11
Training loss: 0.10083994269371033
Validation loss: 1.5366709732240247

Epoch: 6| Step: 12
Training loss: 0.07253047823905945
Validation loss: 1.5588385751170497

Epoch: 6| Step: 13
Training loss: 0.17867064476013184
Validation loss: 1.5288520295132872

Epoch: 499| Step: 0
Training loss: 0.0714079886674881
Validation loss: 1.5250497184773928

Epoch: 6| Step: 1
Training loss: 0.06318578124046326
Validation loss: 1.5414469742005872

Epoch: 6| Step: 2
Training loss: 0.1314876228570938
Validation loss: 1.521696570099041

Epoch: 6| Step: 3
Training loss: 0.04055343568325043
Validation loss: 1.5432436132943759

Epoch: 6| Step: 4
Training loss: 0.18396171927452087
Validation loss: 1.5144823699869134

Epoch: 6| Step: 5
Training loss: 0.13445137441158295
Validation loss: 1.5070467136239494

Epoch: 6| Step: 6
Training loss: 0.09508135914802551
Validation loss: 1.5183192529985983

Epoch: 6| Step: 7
Training loss: 0.10493998229503632
Validation loss: 1.5254764364611717

Epoch: 6| Step: 8
Training loss: 0.0714593231678009
Validation loss: 1.5124500067003313

Epoch: 6| Step: 9
Training loss: 0.0923481434583664
Validation loss: 1.5033899686669792

Epoch: 6| Step: 10
Training loss: 0.11580745875835419
Validation loss: 1.515696528137371

Epoch: 6| Step: 11
Training loss: 0.18393026292324066
Validation loss: 1.4925976363561486

Epoch: 6| Step: 12
Training loss: 0.10292613506317139
Validation loss: 1.4987443929077477

Epoch: 6| Step: 13
Training loss: 0.08699429780244827
Validation loss: 1.5083314430329107

Epoch: 500| Step: 0
Training loss: 0.10020202398300171
Validation loss: 1.5184877918612572

Epoch: 6| Step: 1
Training loss: 0.21412459015846252
Validation loss: 1.5290401494631203

Epoch: 6| Step: 2
Training loss: 0.06522410362958908
Validation loss: 1.531040660796627

Epoch: 6| Step: 3
Training loss: 0.14244727790355682
Validation loss: 1.5484817092136671

Epoch: 6| Step: 4
Training loss: 0.10875342041254044
Validation loss: 1.5446002047549012

Epoch: 6| Step: 5
Training loss: 0.10692399740219116
Validation loss: 1.5394606103179276

Epoch: 6| Step: 6
Training loss: 0.06628741323947906
Validation loss: 1.5582864438333819

Epoch: 6| Step: 7
Training loss: 0.07447564601898193
Validation loss: 1.562920969019654

Epoch: 6| Step: 8
Training loss: 0.04667489230632782
Validation loss: 1.5404793447063816

Epoch: 6| Step: 9
Training loss: 0.10435550659894943
Validation loss: 1.56451254634447

Epoch: 6| Step: 10
Training loss: 0.041467227041721344
Validation loss: 1.5501857508895218

Epoch: 6| Step: 11
Training loss: 0.10587452352046967
Validation loss: 1.5605347053979033

Epoch: 6| Step: 12
Training loss: 0.04769493266940117
Validation loss: 1.5707864389624646

Epoch: 6| Step: 13
Training loss: 0.07050604373216629
Validation loss: 1.5637759688079997

Epoch: 501| Step: 0
Training loss: 0.08000607788562775
Validation loss: 1.5810360280416345

Epoch: 6| Step: 1
Training loss: 0.08945366740226746
Validation loss: 1.5575805864026468

Epoch: 6| Step: 2
Training loss: 0.08724644035100937
Validation loss: 1.5549025048491776

Epoch: 6| Step: 3
Training loss: 0.0599626749753952
Validation loss: 1.5688721979818037

Epoch: 6| Step: 4
Training loss: 0.08662939071655273
Validation loss: 1.549267545823128

Epoch: 6| Step: 5
Training loss: 0.06464337557554245
Validation loss: 1.5424426242869387

Epoch: 6| Step: 6
Training loss: 0.06943979859352112
Validation loss: 1.5554449186530164

Epoch: 6| Step: 7
Training loss: 0.11603564023971558
Validation loss: 1.5400869090070006

Epoch: 6| Step: 8
Training loss: 0.08356733620166779
Validation loss: 1.5552212294711862

Epoch: 6| Step: 9
Training loss: 0.15353715419769287
Validation loss: 1.5375291006539458

Epoch: 6| Step: 10
Training loss: 0.16805848479270935
Validation loss: 1.5597958257121425

Epoch: 6| Step: 11
Training loss: 0.1103515625
Validation loss: 1.5498610863121607

Epoch: 6| Step: 12
Training loss: 0.11881614476442337
Validation loss: 1.573454224935142

Epoch: 6| Step: 13
Training loss: 0.06037642061710358
Validation loss: 1.5532954367258216

Epoch: 502| Step: 0
Training loss: 0.17132344841957092
Validation loss: 1.557149419220545

Epoch: 6| Step: 1
Training loss: 0.056714147329330444
Validation loss: 1.5613575866145473

Epoch: 6| Step: 2
Training loss: 0.11141443252563477
Validation loss: 1.5718681389285671

Epoch: 6| Step: 3
Training loss: 0.08669092506170273
Validation loss: 1.5622868448175409

Epoch: 6| Step: 4
Training loss: 0.050594039261341095
Validation loss: 1.5307175267127253

Epoch: 6| Step: 5
Training loss: 0.08137790858745575
Validation loss: 1.5397073530381726

Epoch: 6| Step: 6
Training loss: 0.08958399295806885
Validation loss: 1.5292625004245388

Epoch: 6| Step: 7
Training loss: 0.06509172916412354
Validation loss: 1.5135616371708531

Epoch: 6| Step: 8
Training loss: 0.04709664732217789
Validation loss: 1.5249325447185065

Epoch: 6| Step: 9
Training loss: 0.15759162604808807
Validation loss: 1.5218189820166557

Epoch: 6| Step: 10
Training loss: 0.14890219271183014
Validation loss: 1.53832487393451

Epoch: 6| Step: 11
Training loss: 0.07613971084356308
Validation loss: 1.5368099789465628

Epoch: 6| Step: 12
Training loss: 0.09075365960597992
Validation loss: 1.5284172014523578

Epoch: 6| Step: 13
Training loss: 0.27233123779296875
Validation loss: 1.5364009154740201

Epoch: 503| Step: 0
Training loss: 0.07139146327972412
Validation loss: 1.5368935805495068

Epoch: 6| Step: 1
Training loss: 0.07943633198738098
Validation loss: 1.5858581566041516

Epoch: 6| Step: 2
Training loss: 0.09217612445354462
Validation loss: 1.561055278265348

Epoch: 6| Step: 3
Training loss: 0.18470454216003418
Validation loss: 1.56324169969046

Epoch: 6| Step: 4
Training loss: 0.0728558897972107
Validation loss: 1.5450510901789511

Epoch: 6| Step: 5
Training loss: 0.05869244784116745
Validation loss: 1.5307418697623796

Epoch: 6| Step: 6
Training loss: 0.14572535455226898
Validation loss: 1.5384011883889475

Epoch: 6| Step: 7
Training loss: 0.09973106533288956
Validation loss: 1.5358307002693095

Epoch: 6| Step: 8
Training loss: 0.20853227376937866
Validation loss: 1.538775251757714

Epoch: 6| Step: 9
Training loss: 0.08842737972736359
Validation loss: 1.535895666768474

Epoch: 6| Step: 10
Training loss: 0.06206526234745979
Validation loss: 1.5512084063663278

Epoch: 6| Step: 11
Training loss: 0.13923515379428864
Validation loss: 1.529142641252087

Epoch: 6| Step: 12
Training loss: 0.07684463262557983
Validation loss: 1.5648613399074924

Epoch: 6| Step: 13
Training loss: 0.08368068188428879
Validation loss: 1.5443164264002154

Epoch: 504| Step: 0
Training loss: 0.1146453246474266
Validation loss: 1.555354740030022

Epoch: 6| Step: 1
Training loss: 0.09421193599700928
Validation loss: 1.5800010581170358

Epoch: 6| Step: 2
Training loss: 0.08298605680465698
Validation loss: 1.5839009695155646

Epoch: 6| Step: 3
Training loss: 0.09648790210485458
Validation loss: 1.5883487347633607

Epoch: 6| Step: 4
Training loss: 0.17125892639160156
Validation loss: 1.6071242055585306

Epoch: 6| Step: 5
Training loss: 0.10933854430913925
Validation loss: 1.5579152235420801

Epoch: 6| Step: 6
Training loss: 0.1094379723072052
Validation loss: 1.5305296938906434

Epoch: 6| Step: 7
Training loss: 0.09847616404294968
Validation loss: 1.5541308887543217

Epoch: 6| Step: 8
Training loss: 0.076343834400177
Validation loss: 1.5453352953798027

Epoch: 6| Step: 9
Training loss: 0.09586555510759354
Validation loss: 1.5329820494497977

Epoch: 6| Step: 10
Training loss: 0.11790606379508972
Validation loss: 1.5341071992792108

Epoch: 6| Step: 11
Training loss: 0.06212587654590607
Validation loss: 1.5571753440364715

Epoch: 6| Step: 12
Training loss: 0.058917850255966187
Validation loss: 1.5566397892531527

Epoch: 6| Step: 13
Training loss: 0.1470697522163391
Validation loss: 1.5556587057728921

Epoch: 505| Step: 0
Training loss: 0.09650306403636932
Validation loss: 1.5444286939918355

Epoch: 6| Step: 1
Training loss: 0.1568537950515747
Validation loss: 1.5484986830783147

Epoch: 6| Step: 2
Training loss: 0.0677160918712616
Validation loss: 1.5670240181748585

Epoch: 6| Step: 3
Training loss: 0.08664091676473618
Validation loss: 1.5856025885510188

Epoch: 6| Step: 4
Training loss: 0.15673181414604187
Validation loss: 1.5775256112057676

Epoch: 6| Step: 5
Training loss: 0.09653480350971222
Validation loss: 1.5889670477118543

Epoch: 6| Step: 6
Training loss: 0.09944386780261993
Validation loss: 1.561982234319051

Epoch: 6| Step: 7
Training loss: 0.08563496917486191
Validation loss: 1.5922189720215336

Epoch: 6| Step: 8
Training loss: 0.09873615205287933
Validation loss: 1.5973542262149114

Epoch: 6| Step: 9
Training loss: 0.09216179698705673
Validation loss: 1.5857532050019951

Epoch: 6| Step: 10
Training loss: 0.07664772868156433
Validation loss: 1.5673250382946384

Epoch: 6| Step: 11
Training loss: 0.0841018408536911
Validation loss: 1.5624644974226594

Epoch: 6| Step: 12
Training loss: 0.06789270043373108
Validation loss: 1.5602022422257291

Epoch: 6| Step: 13
Training loss: 0.0777747631072998
Validation loss: 1.570369614067898

Epoch: 506| Step: 0
Training loss: 0.07811024785041809
Validation loss: 1.5495090567937462

Epoch: 6| Step: 1
Training loss: 0.09505011141300201
Validation loss: 1.5749809857337707

Epoch: 6| Step: 2
Training loss: 0.1337762326002121
Validation loss: 1.5535831528325235

Epoch: 6| Step: 3
Training loss: 0.12383536994457245
Validation loss: 1.5521700894960793

Epoch: 6| Step: 4
Training loss: 0.06918501108884811
Validation loss: 1.5709474432852961

Epoch: 6| Step: 5
Training loss: 0.11076846718788147
Validation loss: 1.5636082477467035

Epoch: 6| Step: 6
Training loss: 0.12272185832262039
Validation loss: 1.5798860141026076

Epoch: 6| Step: 7
Training loss: 0.08186693489551544
Validation loss: 1.5895320971806843

Epoch: 6| Step: 8
Training loss: 0.09700474143028259
Validation loss: 1.6170801590847712

Epoch: 6| Step: 9
Training loss: 0.08413668721914291
Validation loss: 1.6317855183796217

Epoch: 6| Step: 10
Training loss: 0.06187528744339943
Validation loss: 1.5787621851890319

Epoch: 6| Step: 11
Training loss: 0.06189188361167908
Validation loss: 1.5899254391270299

Epoch: 6| Step: 12
Training loss: 0.12769263982772827
Validation loss: 1.5714900647440264

Epoch: 6| Step: 13
Training loss: 0.26154789328575134
Validation loss: 1.5657357605554725

Epoch: 507| Step: 0
Training loss: 0.07229282706975937
Validation loss: 1.5618677011100195

Epoch: 6| Step: 1
Training loss: 0.09570454061031342
Validation loss: 1.5688848598029024

Epoch: 6| Step: 2
Training loss: 0.0640438050031662
Validation loss: 1.5536262899316766

Epoch: 6| Step: 3
Training loss: 0.08076122403144836
Validation loss: 1.5433875386432936

Epoch: 6| Step: 4
Training loss: 0.10025107115507126
Validation loss: 1.5964448644268898

Epoch: 6| Step: 5
Training loss: 0.06321702897548676
Validation loss: 1.5627511201366302

Epoch: 6| Step: 6
Training loss: 0.10677690804004669
Validation loss: 1.5756282755123672

Epoch: 6| Step: 7
Training loss: 0.08005636930465698
Validation loss: 1.5820869720110329

Epoch: 6| Step: 8
Training loss: 0.08349594473838806
Validation loss: 1.6006974353585193

Epoch: 6| Step: 9
Training loss: 0.13301293551921844
Validation loss: 1.5797696139222832

Epoch: 6| Step: 10
Training loss: 0.09803756326436996
Validation loss: 1.5887728711610198

Epoch: 6| Step: 11
Training loss: 0.07785128057003021
Validation loss: 1.6023657873112669

Epoch: 6| Step: 12
Training loss: 0.061702243983745575
Validation loss: 1.5829944892596173

Epoch: 6| Step: 13
Training loss: 0.20749031007289886
Validation loss: 1.5905600593936058

Epoch: 508| Step: 0
Training loss: 0.06886778771877289
Validation loss: 1.5717996910054197

Epoch: 6| Step: 1
Training loss: 0.054064445197582245
Validation loss: 1.5687851867368143

Epoch: 6| Step: 2
Training loss: 0.10977263748645782
Validation loss: 1.5608323543302474

Epoch: 6| Step: 3
Training loss: 0.08698256313800812
Validation loss: 1.5679786500110422

Epoch: 6| Step: 4
Training loss: 0.18389160931110382
Validation loss: 1.563282407740111

Epoch: 6| Step: 5
Training loss: 0.05075579881668091
Validation loss: 1.576841546643165

Epoch: 6| Step: 6
Training loss: 0.060685738921165466
Validation loss: 1.5456429226424104

Epoch: 6| Step: 7
Training loss: 0.08968649059534073
Validation loss: 1.5983550349871318

Epoch: 6| Step: 8
Training loss: 0.1045336127281189
Validation loss: 1.6055917816777383

Epoch: 6| Step: 9
Training loss: 0.12035471200942993
Validation loss: 1.584362801685128

Epoch: 6| Step: 10
Training loss: 0.11043105274438858
Validation loss: 1.603010570490232

Epoch: 6| Step: 11
Training loss: 0.1626790165901184
Validation loss: 1.5861617698464343

Epoch: 6| Step: 12
Training loss: 0.09704062342643738
Validation loss: 1.599892097134744

Epoch: 6| Step: 13
Training loss: 0.07692454755306244
Validation loss: 1.5852784969473397

Epoch: 509| Step: 0
Training loss: 0.03901182487607002
Validation loss: 1.5619909404426493

Epoch: 6| Step: 1
Training loss: 0.0697392076253891
Validation loss: 1.5683570561870452

Epoch: 6| Step: 2
Training loss: 0.08655963838100433
Validation loss: 1.5965468037512995

Epoch: 6| Step: 3
Training loss: 0.08531008660793304
Validation loss: 1.568857200684086

Epoch: 6| Step: 4
Training loss: 0.07099896669387817
Validation loss: 1.5656288477682299

Epoch: 6| Step: 5
Training loss: 0.09107240289449692
Validation loss: 1.5890764081349937

Epoch: 6| Step: 6
Training loss: 0.11273267865180969
Validation loss: 1.5921373905674103

Epoch: 6| Step: 7
Training loss: 0.08922562003135681
Validation loss: 1.5916585409513084

Epoch: 6| Step: 8
Training loss: 0.06503729522228241
Validation loss: 1.597563523118214

Epoch: 6| Step: 9
Training loss: 0.06526012718677521
Validation loss: 1.6102908080623997

Epoch: 6| Step: 10
Training loss: 0.11501780897378922
Validation loss: 1.563176942128007

Epoch: 6| Step: 11
Training loss: 0.15162210166454315
Validation loss: 1.5833135792004165

Epoch: 6| Step: 12
Training loss: 0.15859158337116241
Validation loss: 1.5790964288096274

Epoch: 6| Step: 13
Training loss: 0.0586041621863842
Validation loss: 1.5796296763163742

Epoch: 510| Step: 0
Training loss: 0.08915019035339355
Validation loss: 1.573200656521705

Epoch: 6| Step: 1
Training loss: 0.1383514106273651
Validation loss: 1.5537105068083732

Epoch: 6| Step: 2
Training loss: 0.09316721558570862
Validation loss: 1.5722412447775564

Epoch: 6| Step: 3
Training loss: 0.10573913156986237
Validation loss: 1.5967242474197059

Epoch: 6| Step: 4
Training loss: 0.13646657764911652
Validation loss: 1.5870327193249938

Epoch: 6| Step: 5
Training loss: 0.1339227557182312
Validation loss: 1.6008475877905404

Epoch: 6| Step: 6
Training loss: 0.11576391756534576
Validation loss: 1.5980209586440877

Epoch: 6| Step: 7
Training loss: 0.05739628151059151
Validation loss: 1.5540699779346425

Epoch: 6| Step: 8
Training loss: 0.0757230818271637
Validation loss: 1.5430077609195505

Epoch: 6| Step: 9
Training loss: 0.08658875524997711
Validation loss: 1.550087680098831

Epoch: 6| Step: 10
Training loss: 0.08186379075050354
Validation loss: 1.5327955176753383

Epoch: 6| Step: 11
Training loss: 0.11004292964935303
Validation loss: 1.5552139000226093

Epoch: 6| Step: 12
Training loss: 0.09961235523223877
Validation loss: 1.5419792616239159

Epoch: 6| Step: 13
Training loss: 0.057136137038469315
Validation loss: 1.5700622989285378

Epoch: 511| Step: 0
Training loss: 0.07446233928203583
Validation loss: 1.5493820508321126

Epoch: 6| Step: 1
Training loss: 0.07949770987033844
Validation loss: 1.5806197222842966

Epoch: 6| Step: 2
Training loss: 0.05156547948718071
Validation loss: 1.5939194656187488

Epoch: 6| Step: 3
Training loss: 0.08982153236865997
Validation loss: 1.577101005020962

Epoch: 6| Step: 4
Training loss: 0.06942039728164673
Validation loss: 1.5807051312538885

Epoch: 6| Step: 5
Training loss: 0.13375894725322723
Validation loss: 1.590829856934086

Epoch: 6| Step: 6
Training loss: 0.09941166639328003
Validation loss: 1.5987677266520839

Epoch: 6| Step: 7
Training loss: 0.05962888151407242
Validation loss: 1.5839234718712427

Epoch: 6| Step: 8
Training loss: 0.16483598947525024
Validation loss: 1.5695649590543521

Epoch: 6| Step: 9
Training loss: 0.08439747989177704
Validation loss: 1.5665998176861835

Epoch: 6| Step: 10
Training loss: 0.07516337931156158
Validation loss: 1.5582099050603888

Epoch: 6| Step: 11
Training loss: 0.07061365246772766
Validation loss: 1.5490752420117777

Epoch: 6| Step: 12
Training loss: 0.14558447897434235
Validation loss: 1.5573343820469354

Epoch: 6| Step: 13
Training loss: 0.08574718981981277
Validation loss: 1.5525293068219257

Epoch: 512| Step: 0
Training loss: 0.07650256901979446
Validation loss: 1.5776286971184514

Epoch: 6| Step: 1
Training loss: 0.11878063529729843
Validation loss: 1.565223079855724

Epoch: 6| Step: 2
Training loss: 0.08497736603021622
Validation loss: 1.5539639585761613

Epoch: 6| Step: 3
Training loss: 0.1079544872045517
Validation loss: 1.5609492076340543

Epoch: 6| Step: 4
Training loss: 0.12444344162940979
Validation loss: 1.5516112889012983

Epoch: 6| Step: 5
Training loss: 0.07922469079494476
Validation loss: 1.565056195823095

Epoch: 6| Step: 6
Training loss: 0.1438712179660797
Validation loss: 1.5786629158963439

Epoch: 6| Step: 7
Training loss: 0.06148790568113327
Validation loss: 1.6020004685207079

Epoch: 6| Step: 8
Training loss: 0.06496979296207428
Validation loss: 1.62808326367409

Epoch: 6| Step: 9
Training loss: 0.13185450434684753
Validation loss: 1.5998994573470084

Epoch: 6| Step: 10
Training loss: 0.05146799609065056
Validation loss: 1.6055482151687785

Epoch: 6| Step: 11
Training loss: 0.09724581241607666
Validation loss: 1.5715232331265685

Epoch: 6| Step: 12
Training loss: 0.050603363662958145
Validation loss: 1.5926103322736678

Epoch: 6| Step: 13
Training loss: 0.1040268987417221
Validation loss: 1.6005822150937972

Epoch: 513| Step: 0
Training loss: 0.1096860021352768
Validation loss: 1.5671113268021615

Epoch: 6| Step: 1
Training loss: 0.062357328832149506
Validation loss: 1.5902483937560872

Epoch: 6| Step: 2
Training loss: 0.08616092056035995
Validation loss: 1.5511236934251682

Epoch: 6| Step: 3
Training loss: 0.2039344757795334
Validation loss: 1.5553184145240373

Epoch: 6| Step: 4
Training loss: 0.14639610052108765
Validation loss: 1.5557774087434173

Epoch: 6| Step: 5
Training loss: 0.07077848166227341
Validation loss: 1.5749493298992034

Epoch: 6| Step: 6
Training loss: 0.06540991365909576
Validation loss: 1.5798017863304383

Epoch: 6| Step: 7
Training loss: 0.12795332074165344
Validation loss: 1.5944134945510535

Epoch: 6| Step: 8
Training loss: 0.12204645574092865
Validation loss: 1.6257186320520216

Epoch: 6| Step: 9
Training loss: 0.1621115505695343
Validation loss: 1.634671688079834

Epoch: 6| Step: 10
Training loss: 0.20129457116127014
Validation loss: 1.620444093981097

Epoch: 6| Step: 11
Training loss: 0.07091894745826721
Validation loss: 1.5901324620810888

Epoch: 6| Step: 12
Training loss: 0.08009753376245499
Validation loss: 1.5678999629071964

Epoch: 6| Step: 13
Training loss: 0.10749086737632751
Validation loss: 1.584876956478242

Epoch: 514| Step: 0
Training loss: 0.06369995325803757
Validation loss: 1.582002555170367

Epoch: 6| Step: 1
Training loss: 0.11213415861129761
Validation loss: 1.584389950639458

Epoch: 6| Step: 2
Training loss: 0.18253400921821594
Validation loss: 1.596693834950847

Epoch: 6| Step: 3
Training loss: 0.07991041243076324
Validation loss: 1.5815397526628228

Epoch: 6| Step: 4
Training loss: 0.05490519478917122
Validation loss: 1.5797838677642166

Epoch: 6| Step: 5
Training loss: 0.11007741093635559
Validation loss: 1.6363854920992287

Epoch: 6| Step: 6
Training loss: 0.12352108955383301
Validation loss: 1.6238818245549356

Epoch: 6| Step: 7
Training loss: 0.1005425751209259
Validation loss: 1.6563427614909347

Epoch: 6| Step: 8
Training loss: 0.11010648310184479
Validation loss: 1.6261606575340353

Epoch: 6| Step: 9
Training loss: 0.10411770641803741
Validation loss: 1.611091342023624

Epoch: 6| Step: 10
Training loss: 0.05635785311460495
Validation loss: 1.594101599467698

Epoch: 6| Step: 11
Training loss: 0.07634589076042175
Validation loss: 1.5973648999326973

Epoch: 6| Step: 12
Training loss: 0.09932740777730942
Validation loss: 1.5843810599337342

Epoch: 6| Step: 13
Training loss: 0.13391314446926117
Validation loss: 1.5931244652758363

Epoch: 515| Step: 0
Training loss: 0.13769906759262085
Validation loss: 1.58536014761976

Epoch: 6| Step: 1
Training loss: 0.06140304356813431
Validation loss: 1.5779978908518308

Epoch: 6| Step: 2
Training loss: 0.09266664832830429
Validation loss: 1.5832157006827734

Epoch: 6| Step: 3
Training loss: 0.12811163067817688
Validation loss: 1.5585180456920336

Epoch: 6| Step: 4
Training loss: 0.12733855843544006
Validation loss: 1.5656733205241542

Epoch: 6| Step: 5
Training loss: 0.11045582592487335
Validation loss: 1.5607532711439236

Epoch: 6| Step: 6
Training loss: 0.12185944616794586
Validation loss: 1.5600271994067776

Epoch: 6| Step: 7
Training loss: 0.07745848596096039
Validation loss: 1.5870308132581814

Epoch: 6| Step: 8
Training loss: 0.04657868295907974
Validation loss: 1.5704272741912513

Epoch: 6| Step: 9
Training loss: 0.07429851591587067
Validation loss: 1.579195886529902

Epoch: 6| Step: 10
Training loss: 0.19499975442886353
Validation loss: 1.5887856560368692

Epoch: 6| Step: 11
Training loss: 0.07712670415639877
Validation loss: 1.5635614523323633

Epoch: 6| Step: 12
Training loss: 0.12474782764911652
Validation loss: 1.5593608604964388

Epoch: 6| Step: 13
Training loss: 0.10690448433160782
Validation loss: 1.553171561610314

Epoch: 516| Step: 0
Training loss: 0.07810650765895844
Validation loss: 1.5376765074268464

Epoch: 6| Step: 1
Training loss: 0.09160207211971283
Validation loss: 1.5453412135442097

Epoch: 6| Step: 2
Training loss: 0.1083817332983017
Validation loss: 1.548453410466512

Epoch: 6| Step: 3
Training loss: 0.1252097487449646
Validation loss: 1.538891427619483

Epoch: 6| Step: 4
Training loss: 0.11142571270465851
Validation loss: 1.539386216030326

Epoch: 6| Step: 5
Training loss: 0.08197272568941116
Validation loss: 1.5397566851749216

Epoch: 6| Step: 6
Training loss: 0.0966002568602562
Validation loss: 1.5280972603828675

Epoch: 6| Step: 7
Training loss: 0.1338905692100525
Validation loss: 1.5456831493685323

Epoch: 6| Step: 8
Training loss: 0.13626858592033386
Validation loss: 1.5414787274534985

Epoch: 6| Step: 9
Training loss: 0.07342760264873505
Validation loss: 1.523070030314948

Epoch: 6| Step: 10
Training loss: 0.05783884972333908
Validation loss: 1.5644893402694373

Epoch: 6| Step: 11
Training loss: 0.0607830211520195
Validation loss: 1.5734974107434672

Epoch: 6| Step: 12
Training loss: 0.08900301158428192
Validation loss: 1.5816174989105554

Epoch: 6| Step: 13
Training loss: 0.10864374041557312
Validation loss: 1.6155825955893404

Epoch: 517| Step: 0
Training loss: 0.13727642595767975
Validation loss: 1.6008919298007924

Epoch: 6| Step: 1
Training loss: 0.14027467370033264
Validation loss: 1.5753961327255412

Epoch: 6| Step: 2
Training loss: 0.09628625214099884
Validation loss: 1.554165877321715

Epoch: 6| Step: 3
Training loss: 0.07915382087230682
Validation loss: 1.5395082152017983

Epoch: 6| Step: 4
Training loss: 0.08923429250717163
Validation loss: 1.54125847483194

Epoch: 6| Step: 5
Training loss: 0.1545240879058838
Validation loss: 1.5430709841430827

Epoch: 6| Step: 6
Training loss: 0.14904174208641052
Validation loss: 1.5371471451174827

Epoch: 6| Step: 7
Training loss: 0.08069206774234772
Validation loss: 1.5592809364359865

Epoch: 6| Step: 8
Training loss: 0.08565697073936462
Validation loss: 1.5553387518851989

Epoch: 6| Step: 9
Training loss: 0.10355999320745468
Validation loss: 1.5580100628637499

Epoch: 6| Step: 10
Training loss: 0.14088240265846252
Validation loss: 1.5726972215919084

Epoch: 6| Step: 11
Training loss: 0.14025726914405823
Validation loss: 1.5728666115832586

Epoch: 6| Step: 12
Training loss: 0.07710467278957367
Validation loss: 1.583548204873198

Epoch: 6| Step: 13
Training loss: 0.16245204210281372
Validation loss: 1.5540156338804512

Epoch: 518| Step: 0
Training loss: 0.1010236069560051
Validation loss: 1.5833650019861036

Epoch: 6| Step: 1
Training loss: 0.09363476932048798
Validation loss: 1.5803411545292023

Epoch: 6| Step: 2
Training loss: 0.1089048683643341
Validation loss: 1.555537744234967

Epoch: 6| Step: 3
Training loss: 0.12274213135242462
Validation loss: 1.564681500516912

Epoch: 6| Step: 4
Training loss: 0.12164650857448578
Validation loss: 1.5426876750043643

Epoch: 6| Step: 5
Training loss: 0.07743801921606064
Validation loss: 1.5724526810389694

Epoch: 6| Step: 6
Training loss: 0.09654980897903442
Validation loss: 1.5749078476300804

Epoch: 6| Step: 7
Training loss: 0.12851835787296295
Validation loss: 1.5854782545438377

Epoch: 6| Step: 8
Training loss: 0.12553183734416962
Validation loss: 1.6305828466210315

Epoch: 6| Step: 9
Training loss: 0.14880436658859253
Validation loss: 1.607007936764789

Epoch: 6| Step: 10
Training loss: 0.11631082743406296
Validation loss: 1.6173212002682429

Epoch: 6| Step: 11
Training loss: 0.0767638087272644
Validation loss: 1.6041270020187541

Epoch: 6| Step: 12
Training loss: 0.10205039381980896
Validation loss: 1.628198730048313

Epoch: 6| Step: 13
Training loss: 0.10992380976676941
Validation loss: 1.6169764341846589

Epoch: 519| Step: 0
Training loss: 0.1181780993938446
Validation loss: 1.5930739852689928

Epoch: 6| Step: 1
Training loss: 0.14802604913711548
Validation loss: 1.5834244912670505

Epoch: 6| Step: 2
Training loss: 0.06529652327299118
Validation loss: 1.587714534933849

Epoch: 6| Step: 3
Training loss: 0.08212583512067795
Validation loss: 1.5627944097724011

Epoch: 6| Step: 4
Training loss: 0.10106337070465088
Validation loss: 1.577463101315242

Epoch: 6| Step: 5
Training loss: 0.10254902392625809
Validation loss: 1.5591556013271373

Epoch: 6| Step: 6
Training loss: 0.11121991276741028
Validation loss: 1.5822148284604471

Epoch: 6| Step: 7
Training loss: 0.1089547798037529
Validation loss: 1.5751123300162695

Epoch: 6| Step: 8
Training loss: 0.12546595931053162
Validation loss: 1.6080614789839713

Epoch: 6| Step: 9
Training loss: 0.10730184614658356
Validation loss: 1.5812402925183695

Epoch: 6| Step: 10
Training loss: 0.08452288806438446
Validation loss: 1.5900366434486963

Epoch: 6| Step: 11
Training loss: 0.059906162321567535
Validation loss: 1.6019997955650411

Epoch: 6| Step: 12
Training loss: 0.10114528983831406
Validation loss: 1.5932101652186403

Epoch: 6| Step: 13
Training loss: 0.06173592060804367
Validation loss: 1.6057538178659254

Epoch: 520| Step: 0
Training loss: 0.1040138304233551
Validation loss: 1.5779151173048123

Epoch: 6| Step: 1
Training loss: 0.060111045837402344
Validation loss: 1.6129002366014706

Epoch: 6| Step: 2
Training loss: 0.09127043187618256
Validation loss: 1.6076377463597122

Epoch: 6| Step: 3
Training loss: 0.12040236592292786
Validation loss: 1.5793918140472905

Epoch: 6| Step: 4
Training loss: 0.10581018775701523
Validation loss: 1.624923752200219

Epoch: 6| Step: 5
Training loss: 0.15898756682872772
Validation loss: 1.6050870508276007

Epoch: 6| Step: 6
Training loss: 0.12594787776470184
Validation loss: 1.6160666622141355

Epoch: 6| Step: 7
Training loss: 0.15700441598892212
Validation loss: 1.616579630041635

Epoch: 6| Step: 8
Training loss: 0.06294012069702148
Validation loss: 1.6117774876215125

Epoch: 6| Step: 9
Training loss: 0.1057967096567154
Validation loss: 1.636808471013141

Epoch: 6| Step: 10
Training loss: 0.11832422018051147
Validation loss: 1.6536590412098875

Epoch: 6| Step: 11
Training loss: 0.12429424375295639
Validation loss: 1.6410253535034836

Epoch: 6| Step: 12
Training loss: 0.05976776033639908
Validation loss: 1.6119133144296625

Epoch: 6| Step: 13
Training loss: 0.16891221702098846
Validation loss: 1.581185588272669

Epoch: 521| Step: 0
Training loss: 0.15711569786071777
Validation loss: 1.563252006807635

Epoch: 6| Step: 1
Training loss: 0.09638917446136475
Validation loss: 1.568409751820308

Epoch: 6| Step: 2
Training loss: 0.11023871600627899
Validation loss: 1.5827806252305225

Epoch: 6| Step: 3
Training loss: 0.1678382009267807
Validation loss: 1.5923617309139622

Epoch: 6| Step: 4
Training loss: 0.11267396807670593
Validation loss: 1.5680505960218367

Epoch: 6| Step: 5
Training loss: 0.09696812927722931
Validation loss: 1.543684769702214

Epoch: 6| Step: 6
Training loss: 0.11413352191448212
Validation loss: 1.5811205217915196

Epoch: 6| Step: 7
Training loss: 0.09334589540958405
Validation loss: 1.5602755469660605

Epoch: 6| Step: 8
Training loss: 0.08904337882995605
Validation loss: 1.56983265056405

Epoch: 6| Step: 9
Training loss: 0.10659274458885193
Validation loss: 1.5724195254746305

Epoch: 6| Step: 10
Training loss: 0.13307906687259674
Validation loss: 1.6097076349360968

Epoch: 6| Step: 11
Training loss: 0.10632587969303131
Validation loss: 1.6328696153497184

Epoch: 6| Step: 12
Training loss: 0.11844850331544876
Validation loss: 1.6257619191241521

Epoch: 6| Step: 13
Training loss: 0.16243231296539307
Validation loss: 1.6473309993743896

Epoch: 522| Step: 0
Training loss: 0.12423501908779144
Validation loss: 1.6231971043412403

Epoch: 6| Step: 1
Training loss: 0.09617957472801208
Validation loss: 1.5906745144115981

Epoch: 6| Step: 2
Training loss: 0.11830255389213562
Validation loss: 1.584250480897965

Epoch: 6| Step: 3
Training loss: 0.04430144280195236
Validation loss: 1.554402583388872

Epoch: 6| Step: 4
Training loss: 0.10339038074016571
Validation loss: 1.5648255335387362

Epoch: 6| Step: 5
Training loss: 0.19433698058128357
Validation loss: 1.5739438799760674

Epoch: 6| Step: 6
Training loss: 0.1010403111577034
Validation loss: 1.568199675570252

Epoch: 6| Step: 7
Training loss: 0.09729327261447906
Validation loss: 1.5593065023422241

Epoch: 6| Step: 8
Training loss: 0.06940704584121704
Validation loss: 1.5805226474679925

Epoch: 6| Step: 9
Training loss: 0.07986863702535629
Validation loss: 1.5617554950457748

Epoch: 6| Step: 10
Training loss: 0.06596525758504868
Validation loss: 1.521790409600863

Epoch: 6| Step: 11
Training loss: 0.0973878800868988
Validation loss: 1.5727381603692168

Epoch: 6| Step: 12
Training loss: 0.07216881215572357
Validation loss: 1.5571997281043761

Epoch: 6| Step: 13
Training loss: 0.16244016587734222
Validation loss: 1.5706122549631263

Epoch: 523| Step: 0
Training loss: 0.17170806229114532
Validation loss: 1.5674942398584017

Epoch: 6| Step: 1
Training loss: 0.06926701962947845
Validation loss: 1.5898474480516167

Epoch: 6| Step: 2
Training loss: 0.054023876786231995
Validation loss: 1.5966058815679243

Epoch: 6| Step: 3
Training loss: 0.08195766806602478
Validation loss: 1.5919694951785508

Epoch: 6| Step: 4
Training loss: 0.09141498804092407
Validation loss: 1.558114133855348

Epoch: 6| Step: 5
Training loss: 0.0815056711435318
Validation loss: 1.5560716454700758

Epoch: 6| Step: 6
Training loss: 0.06194889917969704
Validation loss: 1.5761222262536325

Epoch: 6| Step: 7
Training loss: 0.07194909453392029
Validation loss: 1.5528737421958678

Epoch: 6| Step: 8
Training loss: 0.1373281478881836
Validation loss: 1.549425591704666

Epoch: 6| Step: 9
Training loss: 0.12208109349012375
Validation loss: 1.5779529733042563

Epoch: 6| Step: 10
Training loss: 0.07460431754589081
Validation loss: 1.5731347119936379

Epoch: 6| Step: 11
Training loss: 0.09961491823196411
Validation loss: 1.5931734449119979

Epoch: 6| Step: 12
Training loss: 0.09580191969871521
Validation loss: 1.5833066676252632

Epoch: 6| Step: 13
Training loss: 0.06294091790914536
Validation loss: 1.586343252530662

Epoch: 524| Step: 0
Training loss: 0.08687938749790192
Validation loss: 1.576784779948573

Epoch: 6| Step: 1
Training loss: 0.14186453819274902
Validation loss: 1.6213993064818844

Epoch: 6| Step: 2
Training loss: 0.1062631905078888
Validation loss: 1.6013080830215125

Epoch: 6| Step: 3
Training loss: 0.10561994463205338
Validation loss: 1.5918143487745715

Epoch: 6| Step: 4
Training loss: 0.12858960032463074
Validation loss: 1.6038760100641558

Epoch: 6| Step: 5
Training loss: 0.08635757863521576
Validation loss: 1.5642179007171302

Epoch: 6| Step: 6
Training loss: 0.10999414324760437
Validation loss: 1.5478177442345569

Epoch: 6| Step: 7
Training loss: 0.06938005983829498
Validation loss: 1.5363070695630965

Epoch: 6| Step: 8
Training loss: 0.13752833008766174
Validation loss: 1.5332376136574695

Epoch: 6| Step: 9
Training loss: 0.11053667217493057
Validation loss: 1.54637655263306

Epoch: 6| Step: 10
Training loss: 0.14590300619602203
Validation loss: 1.509922879998402

Epoch: 6| Step: 11
Training loss: 0.10975117236375809
Validation loss: 1.5267507709482664

Epoch: 6| Step: 12
Training loss: 0.07570385187864304
Validation loss: 1.5313088329889442

Epoch: 6| Step: 13
Training loss: 0.0691639706492424
Validation loss: 1.5427493510707733

Epoch: 525| Step: 0
Training loss: 0.1170811802148819
Validation loss: 1.600408466913367

Epoch: 6| Step: 1
Training loss: 0.10180580615997314
Validation loss: 1.635639895675003

Epoch: 6| Step: 2
Training loss: 0.105657197535038
Validation loss: 1.6424868427297121

Epoch: 6| Step: 3
Training loss: 0.12844404578208923
Validation loss: 1.6281296078876784

Epoch: 6| Step: 4
Training loss: 0.10329706966876984
Validation loss: 1.6000485407408847

Epoch: 6| Step: 5
Training loss: 0.09554224461317062
Validation loss: 1.5885357311976853

Epoch: 6| Step: 6
Training loss: 0.13500705361366272
Validation loss: 1.57503104658537

Epoch: 6| Step: 7
Training loss: 0.08999098092317581
Validation loss: 1.5845320609308058

Epoch: 6| Step: 8
Training loss: 0.17820173501968384
Validation loss: 1.5924163454322404

Epoch: 6| Step: 9
Training loss: 0.09489748626947403
Validation loss: 1.5635670474780503

Epoch: 6| Step: 10
Training loss: 0.06348152458667755
Validation loss: 1.582703874957177

Epoch: 6| Step: 11
Training loss: 0.09151399880647659
Validation loss: 1.5836860620847313

Epoch: 6| Step: 12
Training loss: 0.0840727686882019
Validation loss: 1.583600478787576

Epoch: 6| Step: 13
Training loss: 0.09866932034492493
Validation loss: 1.5955252416672245

Epoch: 526| Step: 0
Training loss: 0.11876294016838074
Validation loss: 1.59581958863043

Epoch: 6| Step: 1
Training loss: 0.17097283899784088
Validation loss: 1.6084946470875894

Epoch: 6| Step: 2
Training loss: 0.18589383363723755
Validation loss: 1.625107680597613

Epoch: 6| Step: 3
Training loss: 0.07072442024946213
Validation loss: 1.5991678096914803

Epoch: 6| Step: 4
Training loss: 0.07380589842796326
Validation loss: 1.5804961240419777

Epoch: 6| Step: 5
Training loss: 0.08324175328016281
Validation loss: 1.5966724849516345

Epoch: 6| Step: 6
Training loss: 0.11096649616956711
Validation loss: 1.5969942192877493

Epoch: 6| Step: 7
Training loss: 0.06898975372314453
Validation loss: 1.615846892838837

Epoch: 6| Step: 8
Training loss: 0.07826095819473267
Validation loss: 1.5860320368120748

Epoch: 6| Step: 9
Training loss: 0.1320568025112152
Validation loss: 1.5818032064745504

Epoch: 6| Step: 10
Training loss: 0.08040894567966461
Validation loss: 1.6077067659747215

Epoch: 6| Step: 11
Training loss: 0.11268765479326248
Validation loss: 1.5934814919707596

Epoch: 6| Step: 12
Training loss: 0.08108922839164734
Validation loss: 1.5849921780247842

Epoch: 6| Step: 13
Training loss: 0.1287728101015091
Validation loss: 1.5822621135301487

Epoch: 527| Step: 0
Training loss: 0.09001678228378296
Validation loss: 1.5896286528597596

Epoch: 6| Step: 1
Training loss: 0.11117619276046753
Validation loss: 1.6011618952597342

Epoch: 6| Step: 2
Training loss: 0.1274089515209198
Validation loss: 1.6029998756224109

Epoch: 6| Step: 3
Training loss: 0.08478105813264847
Validation loss: 1.6015898450728385

Epoch: 6| Step: 4
Training loss: 0.09473954886198044
Validation loss: 1.5971998642849665

Epoch: 6| Step: 5
Training loss: 0.17507648468017578
Validation loss: 1.6607350572463004

Epoch: 6| Step: 6
Training loss: 0.11418347805738449
Validation loss: 1.651262729398666

Epoch: 6| Step: 7
Training loss: 0.13053779304027557
Validation loss: 1.5965093963889665

Epoch: 6| Step: 8
Training loss: 0.13117313385009766
Validation loss: 1.579471307416116

Epoch: 6| Step: 9
Training loss: 0.1381102204322815
Validation loss: 1.5457257250303864

Epoch: 6| Step: 10
Training loss: 0.09110984951257706
Validation loss: 1.5313742109524306

Epoch: 6| Step: 11
Training loss: 0.08866408467292786
Validation loss: 1.5152563010492632

Epoch: 6| Step: 12
Training loss: 0.07630519568920135
Validation loss: 1.5216313818449616

Epoch: 6| Step: 13
Training loss: 0.08761653304100037
Validation loss: 1.5302135495729343

Epoch: 528| Step: 0
Training loss: 0.10320059955120087
Validation loss: 1.5303947191725495

Epoch: 6| Step: 1
Training loss: 0.08619621396064758
Validation loss: 1.537272334098816

Epoch: 6| Step: 2
Training loss: 0.06759218871593475
Validation loss: 1.5225003060474191

Epoch: 6| Step: 3
Training loss: 0.07563403248786926
Validation loss: 1.528590158108742

Epoch: 6| Step: 4
Training loss: 0.13383933901786804
Validation loss: 1.5795771050196823

Epoch: 6| Step: 5
Training loss: 0.1083713099360466
Validation loss: 1.5493737638637584

Epoch: 6| Step: 6
Training loss: 0.10212402045726776
Validation loss: 1.5817151761824084

Epoch: 6| Step: 7
Training loss: 0.18642038106918335
Validation loss: 1.5592672651813877

Epoch: 6| Step: 8
Training loss: 0.062035251408815384
Validation loss: 1.5241881173144105

Epoch: 6| Step: 9
Training loss: 0.0646497905254364
Validation loss: 1.5382909332552264

Epoch: 6| Step: 10
Training loss: 0.04067061468958855
Validation loss: 1.5151445134993522

Epoch: 6| Step: 11
Training loss: 0.061837974935770035
Validation loss: 1.5028791068702616

Epoch: 6| Step: 12
Training loss: 0.05801526457071304
Validation loss: 1.5404353231512091

Epoch: 6| Step: 13
Training loss: 0.06205136328935623
Validation loss: 1.5320706393129082

Epoch: 529| Step: 0
Training loss: 0.10282449424266815
Validation loss: 1.5160108714975336

Epoch: 6| Step: 1
Training loss: 0.09452258050441742
Validation loss: 1.5224869962661498

Epoch: 6| Step: 2
Training loss: 0.046725086867809296
Validation loss: 1.527447456954628

Epoch: 6| Step: 3
Training loss: 0.0664539784193039
Validation loss: 1.5338875119404127

Epoch: 6| Step: 4
Training loss: 0.09843122959136963
Validation loss: 1.545387650048861

Epoch: 6| Step: 5
Training loss: 0.0627233237028122
Validation loss: 1.5635475035636657

Epoch: 6| Step: 6
Training loss: 0.09059151262044907
Validation loss: 1.5682780294008152

Epoch: 6| Step: 7
Training loss: 0.08989705890417099
Validation loss: 1.6165306363054501

Epoch: 6| Step: 8
Training loss: 0.07141147553920746
Validation loss: 1.5842399007530623

Epoch: 6| Step: 9
Training loss: 0.11303222179412842
Validation loss: 1.5899590446103005

Epoch: 6| Step: 10
Training loss: 0.05728514865040779
Validation loss: 1.6100883509523125

Epoch: 6| Step: 11
Training loss: 0.1410578191280365
Validation loss: 1.5955617812372023

Epoch: 6| Step: 12
Training loss: 0.14906686544418335
Validation loss: 1.5885428126140306

Epoch: 6| Step: 13
Training loss: 0.07514974474906921
Validation loss: 1.572814388941693

Epoch: 530| Step: 0
Training loss: 0.08689136803150177
Validation loss: 1.5804917517528738

Epoch: 6| Step: 1
Training loss: 0.12020039558410645
Validation loss: 1.577934862464987

Epoch: 6| Step: 2
Training loss: 0.0794011726975441
Validation loss: 1.5721661147250925

Epoch: 6| Step: 3
Training loss: 0.12698839604854584
Validation loss: 1.5518136588476037

Epoch: 6| Step: 4
Training loss: 0.08100737631320953
Validation loss: 1.5501695461170648

Epoch: 6| Step: 5
Training loss: 0.08736273646354675
Validation loss: 1.5639324765051565

Epoch: 6| Step: 6
Training loss: 0.07601328194141388
Validation loss: 1.5704474167157245

Epoch: 6| Step: 7
Training loss: 0.05640164017677307
Validation loss: 1.590821366156301

Epoch: 6| Step: 8
Training loss: 0.13106180727481842
Validation loss: 1.6013417807958459

Epoch: 6| Step: 9
Training loss: 0.11380264908075333
Validation loss: 1.6350507595205819

Epoch: 6| Step: 10
Training loss: 0.15962567925453186
Validation loss: 1.6204769406267392

Epoch: 6| Step: 11
Training loss: 0.08884420990943909
Validation loss: 1.592984555869974

Epoch: 6| Step: 12
Training loss: 0.10899808257818222
Validation loss: 1.584884556390906

Epoch: 6| Step: 13
Training loss: 0.033514607697725296
Validation loss: 1.5419343645854662

Epoch: 531| Step: 0
Training loss: 0.1024288684129715
Validation loss: 1.5540587363704559

Epoch: 6| Step: 1
Training loss: 0.09425261616706848
Validation loss: 1.5556982294205697

Epoch: 6| Step: 2
Training loss: 0.08018004894256592
Validation loss: 1.568814855749889

Epoch: 6| Step: 3
Training loss: 0.10220859944820404
Validation loss: 1.5556220777573124

Epoch: 6| Step: 4
Training loss: 0.10561318695545197
Validation loss: 1.5811698936646985

Epoch: 6| Step: 5
Training loss: 0.06858526170253754
Validation loss: 1.5544878308491041

Epoch: 6| Step: 6
Training loss: 0.06416936218738556
Validation loss: 1.5533931518113742

Epoch: 6| Step: 7
Training loss: 0.11865546554327011
Validation loss: 1.5421791864979653

Epoch: 6| Step: 8
Training loss: 0.0758548229932785
Validation loss: 1.5283716186400382

Epoch: 6| Step: 9
Training loss: 0.09937840700149536
Validation loss: 1.5472278377061248

Epoch: 6| Step: 10
Training loss: 0.11286681145429611
Validation loss: 1.5488619842836935

Epoch: 6| Step: 11
Training loss: 0.09868168830871582
Validation loss: 1.5708674538520075

Epoch: 6| Step: 12
Training loss: 0.12010635435581207
Validation loss: 1.5642521432650986

Epoch: 6| Step: 13
Training loss: 0.05436266213655472
Validation loss: 1.5899527995817122

Epoch: 532| Step: 0
Training loss: 0.13185542821884155
Validation loss: 1.572354805084967

Epoch: 6| Step: 1
Training loss: 0.12228532135486603
Validation loss: 1.6140029007388699

Epoch: 6| Step: 2
Training loss: 0.07860946655273438
Validation loss: 1.5638761161476054

Epoch: 6| Step: 3
Training loss: 0.12287034094333649
Validation loss: 1.5517679452896118

Epoch: 6| Step: 4
Training loss: 0.12029508501291275
Validation loss: 1.5622799806697394

Epoch: 6| Step: 5
Training loss: 0.06479169428348541
Validation loss: 1.5508444245143602

Epoch: 6| Step: 6
Training loss: 0.05734674260020256
Validation loss: 1.5420667625242663

Epoch: 6| Step: 7
Training loss: 0.11887937039136887
Validation loss: 1.5248529116312664

Epoch: 6| Step: 8
Training loss: 0.09061156958341599
Validation loss: 1.5596682204995105

Epoch: 6| Step: 9
Training loss: 0.06535382568836212
Validation loss: 1.5378645107310305

Epoch: 6| Step: 10
Training loss: 0.10481175035238266
Validation loss: 1.5193932992155834

Epoch: 6| Step: 11
Training loss: 0.09249849617481232
Validation loss: 1.564471355048559

Epoch: 6| Step: 12
Training loss: 0.07696561515331268
Validation loss: 1.5350960916088474

Epoch: 6| Step: 13
Training loss: 0.059688370674848557
Validation loss: 1.5293236137718282

Epoch: 533| Step: 0
Training loss: 0.138201504945755
Validation loss: 1.5272407762465938

Epoch: 6| Step: 1
Training loss: 0.0722200870513916
Validation loss: 1.5364892880121868

Epoch: 6| Step: 2
Training loss: 0.09241858124732971
Validation loss: 1.5680134527144893

Epoch: 6| Step: 3
Training loss: 0.08820933103561401
Validation loss: 1.542936191763929

Epoch: 6| Step: 4
Training loss: 0.12033195793628693
Validation loss: 1.5764648696427703

Epoch: 6| Step: 5
Training loss: 0.07869701087474823
Validation loss: 1.5635954667163152

Epoch: 6| Step: 6
Training loss: 0.10120073705911636
Validation loss: 1.5553399285962504

Epoch: 6| Step: 7
Training loss: 0.08166447281837463
Validation loss: 1.5769239176986038

Epoch: 6| Step: 8
Training loss: 0.12408707290887833
Validation loss: 1.5556055345842916

Epoch: 6| Step: 9
Training loss: 0.08660510927438736
Validation loss: 1.5348515523377286

Epoch: 6| Step: 10
Training loss: 0.08271345496177673
Validation loss: 1.548742178947695

Epoch: 6| Step: 11
Training loss: 0.12229013442993164
Validation loss: 1.556221555638057

Epoch: 6| Step: 12
Training loss: 0.08416705578565598
Validation loss: 1.5461437625269736

Epoch: 6| Step: 13
Training loss: 0.0636012926697731
Validation loss: 1.5604423066621185

Epoch: 534| Step: 0
Training loss: 0.06399621069431305
Validation loss: 1.5754153484939246

Epoch: 6| Step: 1
Training loss: 0.08840270340442657
Validation loss: 1.5676956151121406

Epoch: 6| Step: 2
Training loss: 0.10262742638587952
Validation loss: 1.5749291604565037

Epoch: 6| Step: 3
Training loss: 0.10807293653488159
Validation loss: 1.5762541768371419

Epoch: 6| Step: 4
Training loss: 0.1237194687128067
Validation loss: 1.5783481828628048

Epoch: 6| Step: 5
Training loss: 0.07525764405727386
Validation loss: 1.551462173461914

Epoch: 6| Step: 6
Training loss: 0.09798736870288849
Validation loss: 1.579117400671846

Epoch: 6| Step: 7
Training loss: 0.0802471786737442
Validation loss: 1.5603057107617777

Epoch: 6| Step: 8
Training loss: 0.05540471896529198
Validation loss: 1.5622205067706365

Epoch: 6| Step: 9
Training loss: 0.09023844450712204
Validation loss: 1.567117876903985

Epoch: 6| Step: 10
Training loss: 0.07746084034442902
Validation loss: 1.5585938448547034

Epoch: 6| Step: 11
Training loss: 0.07824580371379852
Validation loss: 1.5725806425976496

Epoch: 6| Step: 12
Training loss: 0.06574218720197678
Validation loss: 1.5687239503347745

Epoch: 6| Step: 13
Training loss: 0.053053438663482666
Validation loss: 1.5632294589473354

Epoch: 535| Step: 0
Training loss: 0.05141647905111313
Validation loss: 1.5766361003280969

Epoch: 6| Step: 1
Training loss: 0.045739926397800446
Validation loss: 1.5730152899219143

Epoch: 6| Step: 2
Training loss: 0.09501729160547256
Validation loss: 1.5734389520460559

Epoch: 6| Step: 3
Training loss: 0.12801413238048553
Validation loss: 1.584428124530341

Epoch: 6| Step: 4
Training loss: 0.10962174832820892
Validation loss: 1.5929288607771679

Epoch: 6| Step: 5
Training loss: 0.0820489153265953
Validation loss: 1.6022802681051276

Epoch: 6| Step: 6
Training loss: 0.09344419836997986
Validation loss: 1.5804008117286108

Epoch: 6| Step: 7
Training loss: 0.08384297788143158
Validation loss: 1.5815674245998423

Epoch: 6| Step: 8
Training loss: 0.08138985186815262
Validation loss: 1.5677758416821879

Epoch: 6| Step: 9
Training loss: 0.17650431394577026
Validation loss: 1.5726059482943626

Epoch: 6| Step: 10
Training loss: 0.09944052249193192
Validation loss: 1.5641445165039392

Epoch: 6| Step: 11
Training loss: 0.0762166976928711
Validation loss: 1.5602047084480204

Epoch: 6| Step: 12
Training loss: 0.08351640403270721
Validation loss: 1.5142048161516908

Epoch: 6| Step: 13
Training loss: 0.10114285349845886
Validation loss: 1.5324454384465371

Epoch: 536| Step: 0
Training loss: 0.048325128853321075
Validation loss: 1.5127618671745382

Epoch: 6| Step: 1
Training loss: 0.1729193776845932
Validation loss: 1.5131718958577802

Epoch: 6| Step: 2
Training loss: 0.10256094485521317
Validation loss: 1.523377534522805

Epoch: 6| Step: 3
Training loss: 0.1277616024017334
Validation loss: 1.5268501081774313

Epoch: 6| Step: 4
Training loss: 0.06806088238954544
Validation loss: 1.525436153334956

Epoch: 6| Step: 5
Training loss: 0.06154929846525192
Validation loss: 1.5408540361671037

Epoch: 6| Step: 6
Training loss: 0.13113029301166534
Validation loss: 1.5308442525966193

Epoch: 6| Step: 7
Training loss: 0.06956900656223297
Validation loss: 1.522133461890682

Epoch: 6| Step: 8
Training loss: 0.06758235394954681
Validation loss: 1.5380528191084504

Epoch: 6| Step: 9
Training loss: 0.07954635471105576
Validation loss: 1.530749983684991

Epoch: 6| Step: 10
Training loss: 0.1504102498292923
Validation loss: 1.5276472209602274

Epoch: 6| Step: 11
Training loss: 0.09423913806676865
Validation loss: 1.5139443720540693

Epoch: 6| Step: 12
Training loss: 0.11565672606229782
Validation loss: 1.5221590675333494

Epoch: 6| Step: 13
Training loss: 0.08147689700126648
Validation loss: 1.508354870221948

Epoch: 537| Step: 0
Training loss: 0.1172519326210022
Validation loss: 1.5064648274452455

Epoch: 6| Step: 1
Training loss: 0.08875644207000732
Validation loss: 1.5077149534738192

Epoch: 6| Step: 2
Training loss: 0.10936132818460464
Validation loss: 1.5301742463983514

Epoch: 6| Step: 3
Training loss: 0.051398374140262604
Validation loss: 1.5334054513644146

Epoch: 6| Step: 4
Training loss: 0.11551696062088013
Validation loss: 1.5425097544987996

Epoch: 6| Step: 5
Training loss: 0.11433741450309753
Validation loss: 1.557281591558969

Epoch: 6| Step: 6
Training loss: 0.06763036549091339
Validation loss: 1.5688056689436718

Epoch: 6| Step: 7
Training loss: 0.10406967997550964
Validation loss: 1.567973707311897

Epoch: 6| Step: 8
Training loss: 0.0984843373298645
Validation loss: 1.5745103666859288

Epoch: 6| Step: 9
Training loss: 0.08926606923341751
Validation loss: 1.6013515700576126

Epoch: 6| Step: 10
Training loss: 0.07809184491634369
Validation loss: 1.6068641511342858

Epoch: 6| Step: 11
Training loss: 0.06739028543233871
Validation loss: 1.5703623410194152

Epoch: 6| Step: 12
Training loss: 0.0743633434176445
Validation loss: 1.5840395932556481

Epoch: 6| Step: 13
Training loss: 0.06659621745347977
Validation loss: 1.587979055220081

Epoch: 538| Step: 0
Training loss: 0.07088321447372437
Validation loss: 1.5773740019849551

Epoch: 6| Step: 1
Training loss: 0.04566194862127304
Validation loss: 1.5800966191035446

Epoch: 6| Step: 2
Training loss: 0.12426531314849854
Validation loss: 1.5859740831518685

Epoch: 6| Step: 3
Training loss: 0.0746086984872818
Validation loss: 1.5815526926389305

Epoch: 6| Step: 4
Training loss: 0.09368424862623215
Validation loss: 1.5477686069344962

Epoch: 6| Step: 5
Training loss: 0.10533875226974487
Validation loss: 1.5373502790286977

Epoch: 6| Step: 6
Training loss: 0.062168896198272705
Validation loss: 1.5472139594375447

Epoch: 6| Step: 7
Training loss: 0.07330624759197235
Validation loss: 1.548447387192839

Epoch: 6| Step: 8
Training loss: 0.0521831214427948
Validation loss: 1.5496533045204737

Epoch: 6| Step: 9
Training loss: 0.07729068398475647
Validation loss: 1.5406673544196672

Epoch: 6| Step: 10
Training loss: 0.08436989784240723
Validation loss: 1.536347823758279

Epoch: 6| Step: 11
Training loss: 0.12854799628257751
Validation loss: 1.5470483597888742

Epoch: 6| Step: 12
Training loss: 0.07930796593427658
Validation loss: 1.5494722999552244

Epoch: 6| Step: 13
Training loss: 0.14037808775901794
Validation loss: 1.5454411391289002

Epoch: 539| Step: 0
Training loss: 0.07303080707788467
Validation loss: 1.4985635806155462

Epoch: 6| Step: 1
Training loss: 0.10723008215427399
Validation loss: 1.5183525316176876

Epoch: 6| Step: 2
Training loss: 0.06689964979887009
Validation loss: 1.5369668493988693

Epoch: 6| Step: 3
Training loss: 0.1052321344614029
Validation loss: 1.5217035957562026

Epoch: 6| Step: 4
Training loss: 0.05881563574075699
Validation loss: 1.5393442748695292

Epoch: 6| Step: 5
Training loss: 0.0805245041847229
Validation loss: 1.5314417231467463

Epoch: 6| Step: 6
Training loss: 0.06669303774833679
Validation loss: 1.5307859143903177

Epoch: 6| Step: 7
Training loss: 0.04846572130918503
Validation loss: 1.522798453607867

Epoch: 6| Step: 8
Training loss: 0.10547173023223877
Validation loss: 1.5520111655676236

Epoch: 6| Step: 9
Training loss: 0.11274142563343048
Validation loss: 1.534876957375516

Epoch: 6| Step: 10
Training loss: 0.12740004062652588
Validation loss: 1.5422473543433732

Epoch: 6| Step: 11
Training loss: 0.10160958766937256
Validation loss: 1.5196727578357985

Epoch: 6| Step: 12
Training loss: 0.06826212257146835
Validation loss: 1.5382036444961384

Epoch: 6| Step: 13
Training loss: 0.09014640748500824
Validation loss: 1.5349351154860629

Epoch: 540| Step: 0
Training loss: 0.10751424729824066
Validation loss: 1.5186310929636802

Epoch: 6| Step: 1
Training loss: 0.09125503897666931
Validation loss: 1.5327365013860887

Epoch: 6| Step: 2
Training loss: 0.06617886573076248
Validation loss: 1.53698480385606

Epoch: 6| Step: 3
Training loss: 0.07471513748168945
Validation loss: 1.5242549680894422

Epoch: 6| Step: 4
Training loss: 0.10748368501663208
Validation loss: 1.5586246034150482

Epoch: 6| Step: 5
Training loss: 0.06599197536706924
Validation loss: 1.5600064121266848

Epoch: 6| Step: 6
Training loss: 0.09499472379684448
Validation loss: 1.552498173970048

Epoch: 6| Step: 7
Training loss: 0.053452469408512115
Validation loss: 1.5508890267341369

Epoch: 6| Step: 8
Training loss: 0.06517931818962097
Validation loss: 1.5890268497569586

Epoch: 6| Step: 9
Training loss: 0.0770825520157814
Validation loss: 1.5949498812357585

Epoch: 6| Step: 10
Training loss: 0.06940608471632004
Validation loss: 1.6156606802376368

Epoch: 6| Step: 11
Training loss: 0.07269789278507233
Validation loss: 1.6060902392992409

Epoch: 6| Step: 12
Training loss: 0.08339230716228485
Validation loss: 1.5996567164697955

Epoch: 6| Step: 13
Training loss: 0.0895981639623642
Validation loss: 1.5867630871393348

Epoch: 541| Step: 0
Training loss: 0.07047619670629501
Validation loss: 1.589575650871441

Epoch: 6| Step: 1
Training loss: 0.06182310730218887
Validation loss: 1.5543173513104838

Epoch: 6| Step: 2
Training loss: 0.079763263463974
Validation loss: 1.5515849474937684

Epoch: 6| Step: 3
Training loss: 0.0609150230884552
Validation loss: 1.5220670418072773

Epoch: 6| Step: 4
Training loss: 0.08204531669616699
Validation loss: 1.5466338613981843

Epoch: 6| Step: 5
Training loss: 0.11435654014348984
Validation loss: 1.5160415377668155

Epoch: 6| Step: 6
Training loss: 0.09664645791053772
Validation loss: 1.5329453342704362

Epoch: 6| Step: 7
Training loss: 0.0397377647459507
Validation loss: 1.5372171017431444

Epoch: 6| Step: 8
Training loss: 0.11766485869884491
Validation loss: 1.5296826542064708

Epoch: 6| Step: 9
Training loss: 0.08145361393690109
Validation loss: 1.5159237384796143

Epoch: 6| Step: 10
Training loss: 0.047221921384334564
Validation loss: 1.5263542449602516

Epoch: 6| Step: 11
Training loss: 0.09824493527412415
Validation loss: 1.5074316558017526

Epoch: 6| Step: 12
Training loss: 0.11221691966056824
Validation loss: 1.5144855501831218

Epoch: 6| Step: 13
Training loss: 0.15547087788581848
Validation loss: 1.513847686911142

Epoch: 542| Step: 0
Training loss: 0.06875785440206528
Validation loss: 1.5180397546419533

Epoch: 6| Step: 1
Training loss: 0.057137779891490936
Validation loss: 1.519815061682014

Epoch: 6| Step: 2
Training loss: 0.061875224113464355
Validation loss: 1.5222179607678485

Epoch: 6| Step: 3
Training loss: 0.07626550644636154
Validation loss: 1.5294678441939815

Epoch: 6| Step: 4
Training loss: 0.10464151948690414
Validation loss: 1.5193597373142038

Epoch: 6| Step: 5
Training loss: 0.08562412858009338
Validation loss: 1.5247752281927294

Epoch: 6| Step: 6
Training loss: 0.045446548610925674
Validation loss: 1.5429300441536853

Epoch: 6| Step: 7
Training loss: 0.12786710262298584
Validation loss: 1.5091346540758688

Epoch: 6| Step: 8
Training loss: 0.10358293354511261
Validation loss: 1.5245446069266206

Epoch: 6| Step: 9
Training loss: 0.07770657539367676
Validation loss: 1.53634730333923

Epoch: 6| Step: 10
Training loss: 0.06444858014583588
Validation loss: 1.549502609878458

Epoch: 6| Step: 11
Training loss: 0.060745999217033386
Validation loss: 1.5459550901125836

Epoch: 6| Step: 12
Training loss: 0.06752462685108185
Validation loss: 1.5159538804843862

Epoch: 6| Step: 13
Training loss: 0.10368764400482178
Validation loss: 1.5248694483951857

Epoch: 543| Step: 0
Training loss: 0.06717394292354584
Validation loss: 1.508742772122865

Epoch: 6| Step: 1
Training loss: 0.10239424556493759
Validation loss: 1.5181641911947599

Epoch: 6| Step: 2
Training loss: 0.07626733183860779
Validation loss: 1.5288007451641945

Epoch: 6| Step: 3
Training loss: 0.07196095585823059
Validation loss: 1.5332310251010361

Epoch: 6| Step: 4
Training loss: 0.05081930756568909
Validation loss: 1.536759025307112

Epoch: 6| Step: 5
Training loss: 0.047599852085113525
Validation loss: 1.5185835214071377

Epoch: 6| Step: 6
Training loss: 0.07912452518939972
Validation loss: 1.5520773344142462

Epoch: 6| Step: 7
Training loss: 0.0790536180138588
Validation loss: 1.5277287139687488

Epoch: 6| Step: 8
Training loss: 0.10912249237298965
Validation loss: 1.5372450582442745

Epoch: 6| Step: 9
Training loss: 0.13620120286941528
Validation loss: 1.5115763718082058

Epoch: 6| Step: 10
Training loss: 0.0817885547876358
Validation loss: 1.5131252119618077

Epoch: 6| Step: 11
Training loss: 0.06539937108755112
Validation loss: 1.5023766858603365

Epoch: 6| Step: 12
Training loss: 0.1291693150997162
Validation loss: 1.5412107654797134

Epoch: 6| Step: 13
Training loss: 0.05811715126037598
Validation loss: 1.5280675811152304

Epoch: 544| Step: 0
Training loss: 0.17310810089111328
Validation loss: 1.590529804588646

Epoch: 6| Step: 1
Training loss: 0.0828166976571083
Validation loss: 1.5765521218699794

Epoch: 6| Step: 2
Training loss: 0.11765404045581818
Validation loss: 1.5858587872597478

Epoch: 6| Step: 3
Training loss: 0.07397457957267761
Validation loss: 1.5788016114183652

Epoch: 6| Step: 4
Training loss: 0.12381970137357712
Validation loss: 1.5524090592579176

Epoch: 6| Step: 5
Training loss: 0.09474828839302063
Validation loss: 1.5300936365640292

Epoch: 6| Step: 6
Training loss: 0.0599532276391983
Validation loss: 1.5141798488555416

Epoch: 6| Step: 7
Training loss: 0.13640867173671722
Validation loss: 1.4951133394754061

Epoch: 6| Step: 8
Training loss: 0.07274903357028961
Validation loss: 1.518546668432092

Epoch: 6| Step: 9
Training loss: 0.06673867255449295
Validation loss: 1.4825472665089432

Epoch: 6| Step: 10
Training loss: 0.08078163862228394
Validation loss: 1.5103432106715378

Epoch: 6| Step: 11
Training loss: 0.09073309600353241
Validation loss: 1.5161735306503952

Epoch: 6| Step: 12
Training loss: 0.09621410816907883
Validation loss: 1.5071907222911876

Epoch: 6| Step: 13
Training loss: 0.08802840113639832
Validation loss: 1.5312673161106725

Epoch: 545| Step: 0
Training loss: 0.08571378886699677
Validation loss: 1.5510525626520957

Epoch: 6| Step: 1
Training loss: 0.08850690722465515
Validation loss: 1.549870196209159

Epoch: 6| Step: 2
Training loss: 0.14473281800746918
Validation loss: 1.5892205597251974

Epoch: 6| Step: 3
Training loss: 0.10849317163228989
Validation loss: 1.5646326746991885

Epoch: 6| Step: 4
Training loss: 0.11125846207141876
Validation loss: 1.5580844340785858

Epoch: 6| Step: 5
Training loss: 0.07235151529312134
Validation loss: 1.5344876358585973

Epoch: 6| Step: 6
Training loss: 0.07196099311113358
Validation loss: 1.541803785549697

Epoch: 6| Step: 7
Training loss: 0.05389801412820816
Validation loss: 1.5621821136884793

Epoch: 6| Step: 8
Training loss: 0.129713773727417
Validation loss: 1.5457686801110544

Epoch: 6| Step: 9
Training loss: 0.1034192219376564
Validation loss: 1.5474006898941532

Epoch: 6| Step: 10
Training loss: 0.09429913759231567
Validation loss: 1.5490951153539843

Epoch: 6| Step: 11
Training loss: 0.15181735157966614
Validation loss: 1.5596858224561136

Epoch: 6| Step: 12
Training loss: 0.13682720065116882
Validation loss: 1.5793174838507047

Epoch: 6| Step: 13
Training loss: 0.08266044408082962
Validation loss: 1.5843640040325861

Epoch: 546| Step: 0
Training loss: 0.13259004056453705
Validation loss: 1.6153261059073991

Epoch: 6| Step: 1
Training loss: 0.15782035887241364
Validation loss: 1.6374149155873123

Epoch: 6| Step: 2
Training loss: 0.21461759507656097
Validation loss: 1.622641424978933

Epoch: 6| Step: 3
Training loss: 0.16125638782978058
Validation loss: 1.599814623914739

Epoch: 6| Step: 4
Training loss: 0.07952415198087692
Validation loss: 1.592617755295128

Epoch: 6| Step: 5
Training loss: 0.1263134479522705
Validation loss: 1.5868003432468702

Epoch: 6| Step: 6
Training loss: 0.0883556604385376
Validation loss: 1.5655106293257846

Epoch: 6| Step: 7
Training loss: 0.07505127787590027
Validation loss: 1.5500144208631208

Epoch: 6| Step: 8
Training loss: 0.13314928114414215
Validation loss: 1.546850146785859

Epoch: 6| Step: 9
Training loss: 0.13091255724430084
Validation loss: 1.5708516054255988

Epoch: 6| Step: 10
Training loss: 0.07749524712562561
Validation loss: 1.5751758121675061

Epoch: 6| Step: 11
Training loss: 0.058641497045755386
Validation loss: 1.5532964083456224

Epoch: 6| Step: 12
Training loss: 0.03665703162550926
Validation loss: 1.533175944000162

Epoch: 6| Step: 13
Training loss: 0.06284037977457047
Validation loss: 1.5717424077372397

Epoch: 547| Step: 0
Training loss: 0.11273983120918274
Validation loss: 1.6262238038483487

Epoch: 6| Step: 1
Training loss: 0.15107303857803345
Validation loss: 1.5945845983361686

Epoch: 6| Step: 2
Training loss: 0.05442960560321808
Validation loss: 1.616315366119467

Epoch: 6| Step: 3
Training loss: 0.10152778029441833
Validation loss: 1.6013300008671258

Epoch: 6| Step: 4
Training loss: 0.09770821034908295
Validation loss: 1.6281566209690546

Epoch: 6| Step: 5
Training loss: 0.07839468866586685
Validation loss: 1.6136998579066286

Epoch: 6| Step: 6
Training loss: 0.08707135915756226
Validation loss: 1.621493963785069

Epoch: 6| Step: 7
Training loss: 0.10671811550855637
Validation loss: 1.5979551435798727

Epoch: 6| Step: 8
Training loss: 0.07996033132076263
Validation loss: 1.5791481105230187

Epoch: 6| Step: 9
Training loss: 0.06886765360832214
Validation loss: 1.5739851151743243

Epoch: 6| Step: 10
Training loss: 0.08016248047351837
Validation loss: 1.588718400206617

Epoch: 6| Step: 11
Training loss: 0.16975152492523193
Validation loss: 1.6021893972991614

Epoch: 6| Step: 12
Training loss: 0.1115727573633194
Validation loss: 1.590300856098052

Epoch: 6| Step: 13
Training loss: 0.09866258502006531
Validation loss: 1.572073052006383

Epoch: 548| Step: 0
Training loss: 0.13018512725830078
Validation loss: 1.5453839250790176

Epoch: 6| Step: 1
Training loss: 0.11339767277240753
Validation loss: 1.5579593335428545

Epoch: 6| Step: 2
Training loss: 0.1477247178554535
Validation loss: 1.5696807023017638

Epoch: 6| Step: 3
Training loss: 0.10655088722705841
Validation loss: 1.575704433584726

Epoch: 6| Step: 4
Training loss: 0.10688947141170502
Validation loss: 1.5814275850531876

Epoch: 6| Step: 5
Training loss: 0.0909431055188179
Validation loss: 1.5371414813944089

Epoch: 6| Step: 6
Training loss: 0.10251741856336594
Validation loss: 1.5499366380835091

Epoch: 6| Step: 7
Training loss: 0.07342130690813065
Validation loss: 1.5027047793070476

Epoch: 6| Step: 8
Training loss: 0.10603190213441849
Validation loss: 1.515532898646529

Epoch: 6| Step: 9
Training loss: 0.1321379840373993
Validation loss: 1.5184528750758017

Epoch: 6| Step: 10
Training loss: 0.19181382656097412
Validation loss: 1.5073303125237907

Epoch: 6| Step: 11
Training loss: 0.11732180416584015
Validation loss: 1.5142360066854825

Epoch: 6| Step: 12
Training loss: 0.08168970048427582
Validation loss: 1.5183375445745324

Epoch: 6| Step: 13
Training loss: 0.08484860509634018
Validation loss: 1.5412624830840735

Epoch: 549| Step: 0
Training loss: 0.12397269904613495
Validation loss: 1.5263157352324455

Epoch: 6| Step: 1
Training loss: 0.08877375721931458
Validation loss: 1.5094259951704292

Epoch: 6| Step: 2
Training loss: 0.09795353561639786
Validation loss: 1.5769448690516974

Epoch: 6| Step: 3
Training loss: 0.10123754292726517
Validation loss: 1.5976679966013918

Epoch: 6| Step: 4
Training loss: 0.1975145936012268
Validation loss: 1.6044914914715676

Epoch: 6| Step: 5
Training loss: 0.08252984285354614
Validation loss: 1.5926939889948855

Epoch: 6| Step: 6
Training loss: 0.06096809357404709
Validation loss: 1.5710409027273937

Epoch: 6| Step: 7
Training loss: 0.05289798229932785
Validation loss: 1.5719175364381524

Epoch: 6| Step: 8
Training loss: 0.04547639563679695
Validation loss: 1.5718134603192728

Epoch: 6| Step: 9
Training loss: 0.06780639290809631
Validation loss: 1.5685437622890677

Epoch: 6| Step: 10
Training loss: 0.0965360477566719
Validation loss: 1.572594464466136

Epoch: 6| Step: 11
Training loss: 0.09374986588954926
Validation loss: 1.5621215425511843

Epoch: 6| Step: 12
Training loss: 0.05083852261304855
Validation loss: 1.534191289255696

Epoch: 6| Step: 13
Training loss: 0.081307053565979
Validation loss: 1.5598759446092831

Epoch: 550| Step: 0
Training loss: 0.07558811455965042
Validation loss: 1.5496920475395777

Epoch: 6| Step: 1
Training loss: 0.07029065489768982
Validation loss: 1.5724341177171277

Epoch: 6| Step: 2
Training loss: 0.13818512856960297
Validation loss: 1.5661422385964343

Epoch: 6| Step: 3
Training loss: 0.10513746738433838
Validation loss: 1.5764804860597015

Epoch: 6| Step: 4
Training loss: 0.08273223042488098
Validation loss: 1.5865587572897635

Epoch: 6| Step: 5
Training loss: 0.11062218248844147
Validation loss: 1.610188086827596

Epoch: 6| Step: 6
Training loss: 0.12901726365089417
Validation loss: 1.6067997537633425

Epoch: 6| Step: 7
Training loss: 0.11961542069911957
Validation loss: 1.5756344942636387

Epoch: 6| Step: 8
Training loss: 0.07026715576648712
Validation loss: 1.5494090818589734

Epoch: 6| Step: 9
Training loss: 0.06498365104198456
Validation loss: 1.5443360030010183

Epoch: 6| Step: 10
Training loss: 0.06722083687782288
Validation loss: 1.545498606979206

Epoch: 6| Step: 11
Training loss: 0.08059629797935486
Validation loss: 1.5566959214466873

Epoch: 6| Step: 12
Training loss: 0.07407142221927643
Validation loss: 1.56808949670484

Epoch: 6| Step: 13
Training loss: 0.07686510682106018
Validation loss: 1.5758761487981325

Epoch: 551| Step: 0
Training loss: 0.0920121893286705
Validation loss: 1.5718647280047018

Epoch: 6| Step: 1
Training loss: 0.11001364886760712
Validation loss: 1.5817649851563156

Epoch: 6| Step: 2
Training loss: 0.06050106883049011
Validation loss: 1.574035870131626

Epoch: 6| Step: 3
Training loss: 0.11368975043296814
Validation loss: 1.560468678833336

Epoch: 6| Step: 4
Training loss: 0.08985649049282074
Validation loss: 1.5539910447212957

Epoch: 6| Step: 5
Training loss: 0.053107209503650665
Validation loss: 1.5436958189933532

Epoch: 6| Step: 6
Training loss: 0.071149542927742
Validation loss: 1.5304428659459597

Epoch: 6| Step: 7
Training loss: 0.07912541925907135
Validation loss: 1.503532830105033

Epoch: 6| Step: 8
Training loss: 0.061482176184654236
Validation loss: 1.5262145355183592

Epoch: 6| Step: 9
Training loss: 0.07083450257778168
Validation loss: 1.533630363402828

Epoch: 6| Step: 10
Training loss: 0.09508415311574936
Validation loss: 1.5110768836031678

Epoch: 6| Step: 11
Training loss: 0.05273311212658882
Validation loss: 1.5129612171521751

Epoch: 6| Step: 12
Training loss: 0.10220523923635483
Validation loss: 1.5049395048490135

Epoch: 6| Step: 13
Training loss: 0.0331188440322876
Validation loss: 1.5068773031234741

Epoch: 552| Step: 0
Training loss: 0.10379891097545624
Validation loss: 1.5389197077802432

Epoch: 6| Step: 1
Training loss: 0.07102756202220917
Validation loss: 1.5048567985975614

Epoch: 6| Step: 2
Training loss: 0.10556843876838684
Validation loss: 1.5376144263052172

Epoch: 6| Step: 3
Training loss: 0.07365886867046356
Validation loss: 1.5318345318558395

Epoch: 6| Step: 4
Training loss: 0.09273077547550201
Validation loss: 1.5183026341981785

Epoch: 6| Step: 5
Training loss: 0.07444623112678528
Validation loss: 1.5119718966945526

Epoch: 6| Step: 6
Training loss: 0.16003406047821045
Validation loss: 1.5485717968274189

Epoch: 6| Step: 7
Training loss: 0.07802791893482208
Validation loss: 1.5252918184444468

Epoch: 6| Step: 8
Training loss: 0.06873652338981628
Validation loss: 1.5393442915331932

Epoch: 6| Step: 9
Training loss: 0.11283380538225174
Validation loss: 1.5371638497998636

Epoch: 6| Step: 10
Training loss: 0.06832461059093475
Validation loss: 1.5329562553795435

Epoch: 6| Step: 11
Training loss: 0.07600768655538559
Validation loss: 1.5223116220966462

Epoch: 6| Step: 12
Training loss: 0.05528545752167702
Validation loss: 1.5483842331876037

Epoch: 6| Step: 13
Training loss: 0.08921395242214203
Validation loss: 1.5451157618594427

Epoch: 553| Step: 0
Training loss: 0.09687169641256332
Validation loss: 1.5241073600707515

Epoch: 6| Step: 1
Training loss: 0.13380634784698486
Validation loss: 1.5209258961421188

Epoch: 6| Step: 2
Training loss: 0.10286444425582886
Validation loss: 1.5021322670803274

Epoch: 6| Step: 3
Training loss: 0.08636019378900528
Validation loss: 1.5087227218894548

Epoch: 6| Step: 4
Training loss: 0.10071684420108795
Validation loss: 1.5466415510382703

Epoch: 6| Step: 5
Training loss: 0.10328246653079987
Validation loss: 1.54983683939903

Epoch: 6| Step: 6
Training loss: 0.05474149435758591
Validation loss: 1.5416426914994434

Epoch: 6| Step: 7
Training loss: 0.052968092262744904
Validation loss: 1.5556246529343307

Epoch: 6| Step: 8
Training loss: 0.1054515689611435
Validation loss: 1.5890832870237288

Epoch: 6| Step: 9
Training loss: 0.1331993043422699
Validation loss: 1.6106539131492696

Epoch: 6| Step: 10
Training loss: 0.11263208091259003
Validation loss: 1.5968438963736258

Epoch: 6| Step: 11
Training loss: 0.10517311096191406
Validation loss: 1.6063139297628914

Epoch: 6| Step: 12
Training loss: 0.09222789108753204
Validation loss: 1.5538983691123225

Epoch: 6| Step: 13
Training loss: 0.08664795756340027
Validation loss: 1.55697121543269

Epoch: 554| Step: 0
Training loss: 0.15170614421367645
Validation loss: 1.5500479872508715

Epoch: 6| Step: 1
Training loss: 0.1379154920578003
Validation loss: 1.5317905795189641

Epoch: 6| Step: 2
Training loss: 0.08270693570375443
Validation loss: 1.5164635091699579

Epoch: 6| Step: 3
Training loss: 0.0712381899356842
Validation loss: 1.5216738754703152

Epoch: 6| Step: 4
Training loss: 0.09873658418655396
Validation loss: 1.5295877636119883

Epoch: 6| Step: 5
Training loss: 0.1373491734266281
Validation loss: 1.5433769584983907

Epoch: 6| Step: 6
Training loss: 0.09383141994476318
Validation loss: 1.525019561090777

Epoch: 6| Step: 7
Training loss: 0.1143571138381958
Validation loss: 1.561772269587363

Epoch: 6| Step: 8
Training loss: 0.14442254602909088
Validation loss: 1.5511302845452422

Epoch: 6| Step: 9
Training loss: 0.1023978590965271
Validation loss: 1.5818636648116573

Epoch: 6| Step: 10
Training loss: 0.08545053005218506
Validation loss: 1.566856357359117

Epoch: 6| Step: 11
Training loss: 0.0806329995393753
Validation loss: 1.5972000386125298

Epoch: 6| Step: 12
Training loss: 0.0628729909658432
Validation loss: 1.6022937977185814

Epoch: 6| Step: 13
Training loss: 0.17163917422294617
Validation loss: 1.5976296394102034

Epoch: 555| Step: 0
Training loss: 0.11356950551271439
Validation loss: 1.5967746780764671

Epoch: 6| Step: 1
Training loss: 0.08947151899337769
Validation loss: 1.627463286922824

Epoch: 6| Step: 2
Training loss: 0.09436316043138504
Validation loss: 1.6099544443109983

Epoch: 6| Step: 3
Training loss: 0.09792225062847137
Validation loss: 1.5851645008210213

Epoch: 6| Step: 4
Training loss: 0.0695713609457016
Validation loss: 1.5709247307110858

Epoch: 6| Step: 5
Training loss: 0.15179389715194702
Validation loss: 1.600947295465777

Epoch: 6| Step: 6
Training loss: 0.06893475353717804
Validation loss: 1.5964786762832313

Epoch: 6| Step: 7
Training loss: 0.06420920044183731
Validation loss: 1.562320706664875

Epoch: 6| Step: 8
Training loss: 0.11139459908008575
Validation loss: 1.5708681665441042

Epoch: 6| Step: 9
Training loss: 0.10871616005897522
Validation loss: 1.574941469777015

Epoch: 6| Step: 10
Training loss: 0.10598049312829971
Validation loss: 1.5644213409834011

Epoch: 6| Step: 11
Training loss: 0.1161971464753151
Validation loss: 1.5700434177152571

Epoch: 6| Step: 12
Training loss: 0.07004429399967194
Validation loss: 1.588131341242021

Epoch: 6| Step: 13
Training loss: 0.12102463841438293
Validation loss: 1.5885133217739802

Epoch: 556| Step: 0
Training loss: 0.07727652788162231
Validation loss: 1.60661143513136

Epoch: 6| Step: 1
Training loss: 0.11954843997955322
Validation loss: 1.5885516212832542

Epoch: 6| Step: 2
Training loss: 0.07882790267467499
Validation loss: 1.6271688271594305

Epoch: 6| Step: 3
Training loss: 0.07034572213888168
Validation loss: 1.6062459509859803

Epoch: 6| Step: 4
Training loss: 0.07868480682373047
Validation loss: 1.5841881139304048

Epoch: 6| Step: 5
Training loss: 0.1410176157951355
Validation loss: 1.5993560155232747

Epoch: 6| Step: 6
Training loss: 0.05669764429330826
Validation loss: 1.5781507991975354

Epoch: 6| Step: 7
Training loss: 0.12904195487499237
Validation loss: 1.552897157207612

Epoch: 6| Step: 8
Training loss: 0.07266958802938461
Validation loss: 1.5554635396567724

Epoch: 6| Step: 9
Training loss: 0.07142031192779541
Validation loss: 1.5343533151893205

Epoch: 6| Step: 10
Training loss: 0.09495101869106293
Validation loss: 1.5380937668585009

Epoch: 6| Step: 11
Training loss: 0.12838579714298248
Validation loss: 1.5306465702672158

Epoch: 6| Step: 12
Training loss: 0.07868921756744385
Validation loss: 1.5414702853848856

Epoch: 6| Step: 13
Training loss: 0.04873863235116005
Validation loss: 1.5357200253394343

Epoch: 557| Step: 0
Training loss: 0.1094348356127739
Validation loss: 1.5551619375905683

Epoch: 6| Step: 1
Training loss: 0.14332862198352814
Validation loss: 1.5577968858903455

Epoch: 6| Step: 2
Training loss: 0.1259649395942688
Validation loss: 1.5578224261601765

Epoch: 6| Step: 3
Training loss: 0.09733913093805313
Validation loss: 1.566659544103889

Epoch: 6| Step: 4
Training loss: 0.09486061334609985
Validation loss: 1.5472249959104805

Epoch: 6| Step: 5
Training loss: 0.0976051390171051
Validation loss: 1.5442457327278711

Epoch: 6| Step: 6
Training loss: 0.07132735848426819
Validation loss: 1.5716592131122467

Epoch: 6| Step: 7
Training loss: 0.11739522963762283
Validation loss: 1.516072505263872

Epoch: 6| Step: 8
Training loss: 0.0790780559182167
Validation loss: 1.540228110487743

Epoch: 6| Step: 9
Training loss: 0.11671847850084305
Validation loss: 1.5107498899582894

Epoch: 6| Step: 10
Training loss: 0.16045653820037842
Validation loss: 1.5161865500993625

Epoch: 6| Step: 11
Training loss: 0.08786679804325104
Validation loss: 1.5070382766826178

Epoch: 6| Step: 12
Training loss: 0.1035938411951065
Validation loss: 1.5208960861288092

Epoch: 6| Step: 13
Training loss: 0.07795557379722595
Validation loss: 1.513181327491678

Epoch: 558| Step: 0
Training loss: 0.051055580377578735
Validation loss: 1.4969423791413665

Epoch: 6| Step: 1
Training loss: 0.08360320329666138
Validation loss: 1.535168384992948

Epoch: 6| Step: 2
Training loss: 0.10255741328001022
Validation loss: 1.5605066078965382

Epoch: 6| Step: 3
Training loss: 0.05837303400039673
Validation loss: 1.550653749896634

Epoch: 6| Step: 4
Training loss: 0.13102346658706665
Validation loss: 1.5780118344932474

Epoch: 6| Step: 5
Training loss: 0.05703568458557129
Validation loss: 1.5795588570256387

Epoch: 6| Step: 6
Training loss: 0.08829402178525925
Validation loss: 1.595644691938995

Epoch: 6| Step: 7
Training loss: 0.09322207421064377
Validation loss: 1.58056890708144

Epoch: 6| Step: 8
Training loss: 0.1053239032626152
Validation loss: 1.5400811023609613

Epoch: 6| Step: 9
Training loss: 0.07263565063476562
Validation loss: 1.5544571415070565

Epoch: 6| Step: 10
Training loss: 0.038753241300582886
Validation loss: 1.5281520992197015

Epoch: 6| Step: 11
Training loss: 0.09274399280548096
Validation loss: 1.519125033450383

Epoch: 6| Step: 12
Training loss: 0.06791478395462036
Validation loss: 1.5313262542088826

Epoch: 6| Step: 13
Training loss: 0.05396231636404991
Validation loss: 1.5145947920378817

Epoch: 559| Step: 0
Training loss: 0.1177447959780693
Validation loss: 1.5231564032134188

Epoch: 6| Step: 1
Training loss: 0.06871267408132553
Validation loss: 1.5108749302484656

Epoch: 6| Step: 2
Training loss: 0.0981416404247284
Validation loss: 1.5497247916395946

Epoch: 6| Step: 3
Training loss: 0.04747358709573746
Validation loss: 1.5333926857158702

Epoch: 6| Step: 4
Training loss: 0.1160738468170166
Validation loss: 1.5654687945560744

Epoch: 6| Step: 5
Training loss: 0.05431019142270088
Validation loss: 1.5601333136199622

Epoch: 6| Step: 6
Training loss: 0.12423385679721832
Validation loss: 1.5045343182420219

Epoch: 6| Step: 7
Training loss: 0.07316680252552032
Validation loss: 1.5472701877676032

Epoch: 6| Step: 8
Training loss: 0.0807412639260292
Validation loss: 1.5148559680549047

Epoch: 6| Step: 9
Training loss: 0.08568350970745087
Validation loss: 1.4981056477433892

Epoch: 6| Step: 10
Training loss: 0.08837035298347473
Validation loss: 1.5103420775423768

Epoch: 6| Step: 11
Training loss: 0.08530406653881073
Validation loss: 1.5088379331814346

Epoch: 6| Step: 12
Training loss: 0.06989789009094238
Validation loss: 1.4969257744409705

Epoch: 6| Step: 13
Training loss: 0.04373936355113983
Validation loss: 1.529136057822935

Epoch: 560| Step: 0
Training loss: 0.08530738949775696
Validation loss: 1.5238943369157854

Epoch: 6| Step: 1
Training loss: 0.07715125381946564
Validation loss: 1.5001024328252321

Epoch: 6| Step: 2
Training loss: 0.06468375027179718
Validation loss: 1.5418801512769473

Epoch: 6| Step: 3
Training loss: 0.08435505628585815
Validation loss: 1.5409923343248264

Epoch: 6| Step: 4
Training loss: 0.0586165152490139
Validation loss: 1.5674586142263105

Epoch: 6| Step: 5
Training loss: 0.07922716438770294
Validation loss: 1.5254422836406256

Epoch: 6| Step: 6
Training loss: 0.050230465829372406
Validation loss: 1.5504594272182834

Epoch: 6| Step: 7
Training loss: 0.08822016417980194
Validation loss: 1.5438347234520862

Epoch: 6| Step: 8
Training loss: 0.06041565537452698
Validation loss: 1.5385779116743354

Epoch: 6| Step: 9
Training loss: 0.08705569803714752
Validation loss: 1.5318975628063243

Epoch: 6| Step: 10
Training loss: 0.06681469827890396
Validation loss: 1.5462427011100195

Epoch: 6| Step: 11
Training loss: 0.0931864008307457
Validation loss: 1.5338130804800219

Epoch: 6| Step: 12
Training loss: 0.051920779049396515
Validation loss: 1.5419949844319334

Epoch: 6| Step: 13
Training loss: 0.08258987963199615
Validation loss: 1.5473899572126326

Epoch: 561| Step: 0
Training loss: 0.06251639127731323
Validation loss: 1.5428170568199568

Epoch: 6| Step: 1
Training loss: 0.0641237199306488
Validation loss: 1.5336185245103733

Epoch: 6| Step: 2
Training loss: 0.04202045500278473
Validation loss: 1.5484297736998527

Epoch: 6| Step: 3
Training loss: 0.09830518811941147
Validation loss: 1.5284085427561114

Epoch: 6| Step: 4
Training loss: 0.07505273818969727
Validation loss: 1.528525016000194

Epoch: 6| Step: 5
Training loss: 0.0919625535607338
Validation loss: 1.5328870742551741

Epoch: 6| Step: 6
Training loss: 0.0495312474668026
Validation loss: 1.5338672079065794

Epoch: 6| Step: 7
Training loss: 0.05720615014433861
Validation loss: 1.5261996394844466

Epoch: 6| Step: 8
Training loss: 0.06161525845527649
Validation loss: 1.5340892512311217

Epoch: 6| Step: 9
Training loss: 0.10788736492395401
Validation loss: 1.5435854311912292

Epoch: 6| Step: 10
Training loss: 0.07983154058456421
Validation loss: 1.5653484649555658

Epoch: 6| Step: 11
Training loss: 0.08886519074440002
Validation loss: 1.5474210913463304

Epoch: 6| Step: 12
Training loss: 0.06424300372600555
Validation loss: 1.520942000932591

Epoch: 6| Step: 13
Training loss: 0.04411223158240318
Validation loss: 1.5484813285130326

Epoch: 562| Step: 0
Training loss: 0.07308676838874817
Validation loss: 1.5535107043481642

Epoch: 6| Step: 1
Training loss: 0.060128483921289444
Validation loss: 1.5722000445089033

Epoch: 6| Step: 2
Training loss: 0.05678139999508858
Validation loss: 1.5288599409082884

Epoch: 6| Step: 3
Training loss: 0.0422816276550293
Validation loss: 1.5333142883034163

Epoch: 6| Step: 4
Training loss: 0.02974884770810604
Validation loss: 1.5451485008321784

Epoch: 6| Step: 5
Training loss: 0.04326248914003372
Validation loss: 1.534542880391562

Epoch: 6| Step: 6
Training loss: 0.08001543581485748
Validation loss: 1.5242325798157723

Epoch: 6| Step: 7
Training loss: 0.10782134532928467
Validation loss: 1.523829762653638

Epoch: 6| Step: 8
Training loss: 0.043792638927698135
Validation loss: 1.5312192606669601

Epoch: 6| Step: 9
Training loss: 0.08077505975961685
Validation loss: 1.528040236042392

Epoch: 6| Step: 10
Training loss: 0.07854722440242767
Validation loss: 1.5257961788485128

Epoch: 6| Step: 11
Training loss: 0.10591962933540344
Validation loss: 1.5251857567858953

Epoch: 6| Step: 12
Training loss: 0.062094397842884064
Validation loss: 1.513762394587199

Epoch: 6| Step: 13
Training loss: 0.12497573345899582
Validation loss: 1.5284849559107134

Epoch: 563| Step: 0
Training loss: 0.06985843926668167
Validation loss: 1.5234638478166314

Epoch: 6| Step: 1
Training loss: 0.04531358554959297
Validation loss: 1.5394510581929197

Epoch: 6| Step: 2
Training loss: 0.06677375733852386
Validation loss: 1.5426662301504483

Epoch: 6| Step: 3
Training loss: 0.049886494874954224
Validation loss: 1.5375750680123605

Epoch: 6| Step: 4
Training loss: 0.07545025646686554
Validation loss: 1.5403533956056

Epoch: 6| Step: 5
Training loss: 0.04951728880405426
Validation loss: 1.5486505557132024

Epoch: 6| Step: 6
Training loss: 0.08827430754899979
Validation loss: 1.558147629102071

Epoch: 6| Step: 7
Training loss: 0.07684234529733658
Validation loss: 1.5377417437491878

Epoch: 6| Step: 8
Training loss: 0.0601692721247673
Validation loss: 1.5582243152844009

Epoch: 6| Step: 9
Training loss: 0.0626765787601471
Validation loss: 1.5457929693242556

Epoch: 6| Step: 10
Training loss: 0.11735142767429352
Validation loss: 1.5412532924323954

Epoch: 6| Step: 11
Training loss: 0.05130141228437424
Validation loss: 1.5403219704986901

Epoch: 6| Step: 12
Training loss: 0.07042494416236877
Validation loss: 1.5524323826195092

Epoch: 6| Step: 13
Training loss: 0.11919137835502625
Validation loss: 1.5626855434909943

Epoch: 564| Step: 0
Training loss: 0.05422147363424301
Validation loss: 1.56461420495023

Epoch: 6| Step: 1
Training loss: 0.08536916971206665
Validation loss: 1.541494962989643

Epoch: 6| Step: 2
Training loss: 0.1009393036365509
Validation loss: 1.5541615845054708

Epoch: 6| Step: 3
Training loss: 0.12154008448123932
Validation loss: 1.5426228456599738

Epoch: 6| Step: 4
Training loss: 0.06263626366853714
Validation loss: 1.5614858865737915

Epoch: 6| Step: 5
Training loss: 0.07196509838104248
Validation loss: 1.5534319108532322

Epoch: 6| Step: 6
Training loss: 0.10517041385173798
Validation loss: 1.5745998736350768

Epoch: 6| Step: 7
Training loss: 0.08187787234783173
Validation loss: 1.592170573049976

Epoch: 6| Step: 8
Training loss: 0.07343263924121857
Validation loss: 1.571535316846704

Epoch: 6| Step: 9
Training loss: 0.045271143317222595
Validation loss: 1.5767035356131933

Epoch: 6| Step: 10
Training loss: 0.11742053925991058
Validation loss: 1.5861024125929801

Epoch: 6| Step: 11
Training loss: 0.09512235224246979
Validation loss: 1.5587518920180619

Epoch: 6| Step: 12
Training loss: 0.05700937658548355
Validation loss: 1.5621374012321554

Epoch: 6| Step: 13
Training loss: 0.04625808447599411
Validation loss: 1.544965503036335

Epoch: 565| Step: 0
Training loss: 0.08159718662500381
Validation loss: 1.5563391421430854

Epoch: 6| Step: 1
Training loss: 0.08748216181993484
Validation loss: 1.561719597026866

Epoch: 6| Step: 2
Training loss: 0.05988558381795883
Validation loss: 1.5595955880739356

Epoch: 6| Step: 3
Training loss: 0.07657070457935333
Validation loss: 1.5319226787936302

Epoch: 6| Step: 4
Training loss: 0.0699562132358551
Validation loss: 1.5299805325846518

Epoch: 6| Step: 5
Training loss: 0.08267504721879959
Validation loss: 1.549452018994157

Epoch: 6| Step: 6
Training loss: 0.10344743728637695
Validation loss: 1.5407313121262418

Epoch: 6| Step: 7
Training loss: 0.08220543712377548
Validation loss: 1.5338348073344077

Epoch: 6| Step: 8
Training loss: 0.07857389748096466
Validation loss: 1.5353571522620417

Epoch: 6| Step: 9
Training loss: 0.053079161792993546
Validation loss: 1.5645347141450452

Epoch: 6| Step: 10
Training loss: 0.06897445768117905
Validation loss: 1.546639883390037

Epoch: 6| Step: 11
Training loss: 0.07812201976776123
Validation loss: 1.5571498601667342

Epoch: 6| Step: 12
Training loss: 0.05653730034828186
Validation loss: 1.556700341163143

Epoch: 6| Step: 13
Training loss: 0.13051244616508484
Validation loss: 1.5561101667342647

Epoch: 566| Step: 0
Training loss: 0.09286752343177795
Validation loss: 1.518116258805798

Epoch: 6| Step: 1
Training loss: 0.07484693825244904
Validation loss: 1.5340113332194667

Epoch: 6| Step: 2
Training loss: 0.11280681192874908
Validation loss: 1.5476602367175523

Epoch: 6| Step: 3
Training loss: 0.07858344912528992
Validation loss: 1.5322770194340778

Epoch: 6| Step: 4
Training loss: 0.05603288859128952
Validation loss: 1.5339953771201513

Epoch: 6| Step: 5
Training loss: 0.10398080199956894
Validation loss: 1.5107950818154119

Epoch: 6| Step: 6
Training loss: 0.06075126305222511
Validation loss: 1.52852197488149

Epoch: 6| Step: 7
Training loss: 0.09160421043634415
Validation loss: 1.5598287287578787

Epoch: 6| Step: 8
Training loss: 0.07579696178436279
Validation loss: 1.565431676244223

Epoch: 6| Step: 9
Training loss: 0.11329343914985657
Validation loss: 1.5826079640337216

Epoch: 6| Step: 10
Training loss: 0.07259772717952728
Validation loss: 1.5452686919960925

Epoch: 6| Step: 11
Training loss: 0.059249717742204666
Validation loss: 1.539873529505986

Epoch: 6| Step: 12
Training loss: 0.0671406239271164
Validation loss: 1.5698990591110722

Epoch: 6| Step: 13
Training loss: 0.08035938441753387
Validation loss: 1.5433211236871698

Epoch: 567| Step: 0
Training loss: 0.04331859201192856
Validation loss: 1.529937365362721

Epoch: 6| Step: 1
Training loss: 0.07581782341003418
Validation loss: 1.5568824295074708

Epoch: 6| Step: 2
Training loss: 0.07596638798713684
Validation loss: 1.5461433741354174

Epoch: 6| Step: 3
Training loss: 0.04084115847945213
Validation loss: 1.525925733709848

Epoch: 6| Step: 4
Training loss: 0.08890733867883682
Validation loss: 1.5538610745501775

Epoch: 6| Step: 5
Training loss: 0.05008509010076523
Validation loss: 1.5429876376223821

Epoch: 6| Step: 6
Training loss: 0.061758480966091156
Validation loss: 1.5245661004897086

Epoch: 6| Step: 7
Training loss: 0.047069113701581955
Validation loss: 1.532806763084986

Epoch: 6| Step: 8
Training loss: 0.13047939538955688
Validation loss: 1.5449932864917222

Epoch: 6| Step: 9
Training loss: 0.08214527368545532
Validation loss: 1.5511522793000745

Epoch: 6| Step: 10
Training loss: 0.09450098872184753
Validation loss: 1.552001763415593

Epoch: 6| Step: 11
Training loss: 0.07739554345607758
Validation loss: 1.5358201688335789

Epoch: 6| Step: 12
Training loss: 0.06169305741786957
Validation loss: 1.5519365341432634

Epoch: 6| Step: 13
Training loss: 0.06924699991941452
Validation loss: 1.5730768506244948

Epoch: 568| Step: 0
Training loss: 0.03832002356648445
Validation loss: 1.5787888034697501

Epoch: 6| Step: 1
Training loss: 0.05644950643181801
Validation loss: 1.5775234019884499

Epoch: 6| Step: 2
Training loss: 0.10180233418941498
Validation loss: 1.558357891216073

Epoch: 6| Step: 3
Training loss: 0.07905413955450058
Validation loss: 1.5551821621515418

Epoch: 6| Step: 4
Training loss: 0.06952302157878876
Validation loss: 1.5642893929635324

Epoch: 6| Step: 5
Training loss: 0.08614388108253479
Validation loss: 1.5460785870910974

Epoch: 6| Step: 6
Training loss: 0.09895534813404083
Validation loss: 1.5493786065809187

Epoch: 6| Step: 7
Training loss: 0.05175776407122612
Validation loss: 1.5576410883216447

Epoch: 6| Step: 8
Training loss: 0.05994853377342224
Validation loss: 1.5387181569171209

Epoch: 6| Step: 9
Training loss: 0.08187904953956604
Validation loss: 1.537713046996824

Epoch: 6| Step: 10
Training loss: 0.08766832202672958
Validation loss: 1.56379404247448

Epoch: 6| Step: 11
Training loss: 0.10124380141496658
Validation loss: 1.5537844780952699

Epoch: 6| Step: 12
Training loss: 0.09734877943992615
Validation loss: 1.549532599346612

Epoch: 6| Step: 13
Training loss: 0.05638990178704262
Validation loss: 1.5698139411146923

Epoch: 569| Step: 0
Training loss: 0.11509360373020172
Validation loss: 1.6112211904218119

Epoch: 6| Step: 1
Training loss: 0.07438796758651733
Validation loss: 1.5928077543935468

Epoch: 6| Step: 2
Training loss: 0.10341686010360718
Validation loss: 1.5975489872758106

Epoch: 6| Step: 3
Training loss: 0.10609252005815506
Validation loss: 1.5889705727177281

Epoch: 6| Step: 4
Training loss: 0.11540883779525757
Validation loss: 1.6045724217609694

Epoch: 6| Step: 5
Training loss: 0.07140059024095535
Validation loss: 1.582431649649015

Epoch: 6| Step: 6
Training loss: 0.06561294198036194
Validation loss: 1.5373088403414654

Epoch: 6| Step: 7
Training loss: 0.11361917108297348
Validation loss: 1.5458820737818235

Epoch: 6| Step: 8
Training loss: 0.08076872676610947
Validation loss: 1.527994437884259

Epoch: 6| Step: 9
Training loss: 0.10242541879415512
Validation loss: 1.5015182072116482

Epoch: 6| Step: 10
Training loss: 0.07576750218868256
Validation loss: 1.5019846744434808

Epoch: 6| Step: 11
Training loss: 0.05297252535820007
Validation loss: 1.4867154552090553

Epoch: 6| Step: 12
Training loss: 0.06961719691753387
Validation loss: 1.5224394618823964

Epoch: 6| Step: 13
Training loss: 0.053127579391002655
Validation loss: 1.519986621795162

Epoch: 570| Step: 0
Training loss: 0.06629480421543121
Validation loss: 1.5287037344389065

Epoch: 6| Step: 1
Training loss: 0.05086681991815567
Validation loss: 1.517619308604989

Epoch: 6| Step: 2
Training loss: 0.06419078260660172
Validation loss: 1.5312421834597023

Epoch: 6| Step: 3
Training loss: 0.10825888067483902
Validation loss: 1.5459189677751193

Epoch: 6| Step: 4
Training loss: 0.049565188586711884
Validation loss: 1.5448810964502313

Epoch: 6| Step: 5
Training loss: 0.07624892890453339
Validation loss: 1.5498383686106691

Epoch: 6| Step: 6
Training loss: 0.11725088208913803
Validation loss: 1.5555105055532148

Epoch: 6| Step: 7
Training loss: 0.05826994404196739
Validation loss: 1.5283363326903312

Epoch: 6| Step: 8
Training loss: 0.05069485306739807
Validation loss: 1.5460870073687645

Epoch: 6| Step: 9
Training loss: 0.04233821481466293
Validation loss: 1.5845173187153314

Epoch: 6| Step: 10
Training loss: 0.09313477575778961
Validation loss: 1.5622976544082805

Epoch: 6| Step: 11
Training loss: 0.08623252809047699
Validation loss: 1.586429149873795

Epoch: 6| Step: 12
Training loss: 0.052043311297893524
Validation loss: 1.5696502757328812

Epoch: 6| Step: 13
Training loss: 0.07615985721349716
Validation loss: 1.579811660192346

Epoch: 571| Step: 0
Training loss: 0.07376478612422943
Validation loss: 1.5462016777325702

Epoch: 6| Step: 1
Training loss: 0.04680154100060463
Validation loss: 1.5217783957399347

Epoch: 6| Step: 2
Training loss: 0.11948056519031525
Validation loss: 1.5409876954170965

Epoch: 6| Step: 3
Training loss: 0.05487038195133209
Validation loss: 1.5374673694692633

Epoch: 6| Step: 4
Training loss: 0.0644860714673996
Validation loss: 1.5417612227060462

Epoch: 6| Step: 5
Training loss: 0.06854530423879623
Validation loss: 1.5529817406849196

Epoch: 6| Step: 6
Training loss: 0.06964340806007385
Validation loss: 1.562122726953158

Epoch: 6| Step: 7
Training loss: 0.043168842792510986
Validation loss: 1.5456351041793823

Epoch: 6| Step: 8
Training loss: 0.052724700421094894
Validation loss: 1.5472825996337398

Epoch: 6| Step: 9
Training loss: 0.06048575043678284
Validation loss: 1.5644339899862967

Epoch: 6| Step: 10
Training loss: 0.11785537004470825
Validation loss: 1.5393284956614177

Epoch: 6| Step: 11
Training loss: 0.11027952283620834
Validation loss: 1.542791235831476

Epoch: 6| Step: 12
Training loss: 0.060977380722761154
Validation loss: 1.538670419364847

Epoch: 6| Step: 13
Training loss: 0.0805078074336052
Validation loss: 1.562979434126167

Epoch: 572| Step: 0
Training loss: 0.05399774760007858
Validation loss: 1.5699630232267483

Epoch: 6| Step: 1
Training loss: 0.09522537887096405
Validation loss: 1.5312570410390054

Epoch: 6| Step: 2
Training loss: 0.04465340077877045
Validation loss: 1.5561453424474245

Epoch: 6| Step: 3
Training loss: 0.11212541162967682
Validation loss: 1.5574948339052097

Epoch: 6| Step: 4
Training loss: 0.08081002533435822
Validation loss: 1.5703933213346748

Epoch: 6| Step: 5
Training loss: 0.11026431620121002
Validation loss: 1.5779695331409413

Epoch: 6| Step: 6
Training loss: 0.11556793004274368
Validation loss: 1.5944377248005202

Epoch: 6| Step: 7
Training loss: 0.0707874447107315
Validation loss: 1.5843391790184924

Epoch: 6| Step: 8
Training loss: 0.09883718192577362
Validation loss: 1.580486714199025

Epoch: 6| Step: 9
Training loss: 0.06568902730941772
Validation loss: 1.5522520080689461

Epoch: 6| Step: 10
Training loss: 0.0515243336558342
Validation loss: 1.5280258463275047

Epoch: 6| Step: 11
Training loss: 0.05454418808221817
Validation loss: 1.548873915467211

Epoch: 6| Step: 12
Training loss: 0.07887838780879974
Validation loss: 1.538374279135017

Epoch: 6| Step: 13
Training loss: 0.08597155660390854
Validation loss: 1.5337311593435143

Epoch: 573| Step: 0
Training loss: 0.10802879929542542
Validation loss: 1.5276962364873579

Epoch: 6| Step: 1
Training loss: 0.05750798434019089
Validation loss: 1.554508202819414

Epoch: 6| Step: 2
Training loss: 0.06238303333520889
Validation loss: 1.534593496271359

Epoch: 6| Step: 3
Training loss: 0.06301429122686386
Validation loss: 1.5612850355845627

Epoch: 6| Step: 4
Training loss: 0.09590405970811844
Validation loss: 1.5458799754419634

Epoch: 6| Step: 5
Training loss: 0.08510158956050873
Validation loss: 1.5590625475811701

Epoch: 6| Step: 6
Training loss: 0.06327229738235474
Validation loss: 1.548566479836741

Epoch: 6| Step: 7
Training loss: 0.08475172519683838
Validation loss: 1.5543909752240745

Epoch: 6| Step: 8
Training loss: 0.056140121072530746
Validation loss: 1.572333360231051

Epoch: 6| Step: 9
Training loss: 0.06703507155179977
Validation loss: 1.5762014030128397

Epoch: 6| Step: 10
Training loss: 0.09322908520698547
Validation loss: 1.5371523313624884

Epoch: 6| Step: 11
Training loss: 0.059777528047561646
Validation loss: 1.538468026345776

Epoch: 6| Step: 12
Training loss: 0.09412122517824173
Validation loss: 1.5704342908756708

Epoch: 6| Step: 13
Training loss: 0.05206716060638428
Validation loss: 1.5536232673993675

Epoch: 574| Step: 0
Training loss: 0.07055433839559555
Validation loss: 1.545928994814555

Epoch: 6| Step: 1
Training loss: 0.04199383780360222
Validation loss: 1.5411110808772426

Epoch: 6| Step: 2
Training loss: 0.05497126653790474
Validation loss: 1.5314205141477688

Epoch: 6| Step: 3
Training loss: 0.06992821395397186
Validation loss: 1.5320983548318186

Epoch: 6| Step: 4
Training loss: 0.060157403349876404
Validation loss: 1.5422397557125296

Epoch: 6| Step: 5
Training loss: 0.10010884702205658
Validation loss: 1.5405630027094195

Epoch: 6| Step: 6
Training loss: 0.10188477486371994
Validation loss: 1.565022180157323

Epoch: 6| Step: 7
Training loss: 0.05173202604055405
Validation loss: 1.561657062140844

Epoch: 6| Step: 8
Training loss: 0.05558173358440399
Validation loss: 1.5447776394505655

Epoch: 6| Step: 9
Training loss: 0.0902116447687149
Validation loss: 1.5454843198099444

Epoch: 6| Step: 10
Training loss: 0.06135633587837219
Validation loss: 1.539508194051763

Epoch: 6| Step: 11
Training loss: 0.10305988043546677
Validation loss: 1.5588939125819872

Epoch: 6| Step: 12
Training loss: 0.0650116503238678
Validation loss: 1.5734151665882399

Epoch: 6| Step: 13
Training loss: 0.06133691966533661
Validation loss: 1.5385852859866234

Epoch: 575| Step: 0
Training loss: 0.06561700254678726
Validation loss: 1.5494245662484118

Epoch: 6| Step: 1
Training loss: 0.08619292080402374
Validation loss: 1.5446910806881484

Epoch: 6| Step: 2
Training loss: 0.05471218377351761
Validation loss: 1.5790142423363143

Epoch: 6| Step: 3
Training loss: 0.13676221668720245
Validation loss: 1.5424514919198968

Epoch: 6| Step: 4
Training loss: 0.05790819227695465
Validation loss: 1.5359874848396546

Epoch: 6| Step: 5
Training loss: 0.0856977179646492
Validation loss: 1.5383813496558898

Epoch: 6| Step: 6
Training loss: 0.11160863935947418
Validation loss: 1.5585458099201162

Epoch: 6| Step: 7
Training loss: 0.0701017826795578
Validation loss: 1.5478207244667956

Epoch: 6| Step: 8
Training loss: 0.05295245349407196
Validation loss: 1.5577428456275695

Epoch: 6| Step: 9
Training loss: 0.06397845596075058
Validation loss: 1.5569208591215071

Epoch: 6| Step: 10
Training loss: 0.06390100717544556
Validation loss: 1.5161140939240814

Epoch: 6| Step: 11
Training loss: 0.09609521180391312
Validation loss: 1.5109949458029963

Epoch: 6| Step: 12
Training loss: 0.06563052535057068
Validation loss: 1.5309111200353152

Epoch: 6| Step: 13
Training loss: 0.036222219467163086
Validation loss: 1.516932552219719

Epoch: 576| Step: 0
Training loss: 0.06561899185180664
Validation loss: 1.5188881389556392

Epoch: 6| Step: 1
Training loss: 0.06515838205814362
Validation loss: 1.5331464006054787

Epoch: 6| Step: 2
Training loss: 0.10815036296844482
Validation loss: 1.5209726120835991

Epoch: 6| Step: 3
Training loss: 0.08297929912805557
Validation loss: 1.526984671110748

Epoch: 6| Step: 4
Training loss: 0.07001654803752899
Validation loss: 1.5171248489810574

Epoch: 6| Step: 5
Training loss: 0.12433140724897385
Validation loss: 1.5081273599337506

Epoch: 6| Step: 6
Training loss: 0.03662392497062683
Validation loss: 1.547787485584136

Epoch: 6| Step: 7
Training loss: 0.11051428318023682
Validation loss: 1.5340595629907423

Epoch: 6| Step: 8
Training loss: 0.10880511999130249
Validation loss: 1.5095865149651804

Epoch: 6| Step: 9
Training loss: 0.08185484260320663
Validation loss: 1.5389812595100814

Epoch: 6| Step: 10
Training loss: 0.05830691009759903
Validation loss: 1.514121304276169

Epoch: 6| Step: 11
Training loss: 0.07333129644393921
Validation loss: 1.5219580268347135

Epoch: 6| Step: 12
Training loss: 0.06412050127983093
Validation loss: 1.5155298427868915

Epoch: 6| Step: 13
Training loss: 0.062391187995672226
Validation loss: 1.5053194966367496

Epoch: 577| Step: 0
Training loss: 0.06387396901845932
Validation loss: 1.5379988198639245

Epoch: 6| Step: 1
Training loss: 0.04722572863101959
Validation loss: 1.5549828301193893

Epoch: 6| Step: 2
Training loss: 0.06648924946784973
Validation loss: 1.5247453515247633

Epoch: 6| Step: 3
Training loss: 0.08162027597427368
Validation loss: 1.5122910058626564

Epoch: 6| Step: 4
Training loss: 0.08336220681667328
Validation loss: 1.5239857896681754

Epoch: 6| Step: 5
Training loss: 0.0667693093419075
Validation loss: 1.5162883035598262

Epoch: 6| Step: 6
Training loss: 0.0577818937599659
Validation loss: 1.5177763662030619

Epoch: 6| Step: 7
Training loss: 0.08155327290296555
Validation loss: 1.5296929485054427

Epoch: 6| Step: 8
Training loss: 0.05724726617336273
Validation loss: 1.5301193575705252

Epoch: 6| Step: 9
Training loss: 0.08195070177316666
Validation loss: 1.5323268713489655

Epoch: 6| Step: 10
Training loss: 0.06896428763866425
Validation loss: 1.5365451561507357

Epoch: 6| Step: 11
Training loss: 0.11062970012426376
Validation loss: 1.5532061951134795

Epoch: 6| Step: 12
Training loss: 0.07676826417446136
Validation loss: 1.5395539383734427

Epoch: 6| Step: 13
Training loss: 0.09980800747871399
Validation loss: 1.5270525575965963

Epoch: 578| Step: 0
Training loss: 0.05175041779875755
Validation loss: 1.5302487804043678

Epoch: 6| Step: 1
Training loss: 0.13180585205554962
Validation loss: 1.5411926059312717

Epoch: 6| Step: 2
Training loss: 0.135339617729187
Validation loss: 1.5292345029051586

Epoch: 6| Step: 3
Training loss: 0.11941483616828918
Validation loss: 1.536054035668732

Epoch: 6| Step: 4
Training loss: 0.05675944685935974
Validation loss: 1.5354139317748368

Epoch: 6| Step: 5
Training loss: 0.06753144413232803
Validation loss: 1.518090118644058

Epoch: 6| Step: 6
Training loss: 0.03974812105298042
Validation loss: 1.5496983169227518

Epoch: 6| Step: 7
Training loss: 0.07526237517595291
Validation loss: 1.5307459421055292

Epoch: 6| Step: 8
Training loss: 0.05396076291799545
Validation loss: 1.5537811030623734

Epoch: 6| Step: 9
Training loss: 0.08615250140428543
Validation loss: 1.5358376272263066

Epoch: 6| Step: 10
Training loss: 0.1089915931224823
Validation loss: 1.5550621324969875

Epoch: 6| Step: 11
Training loss: 0.14163090288639069
Validation loss: 1.524739816624631

Epoch: 6| Step: 12
Training loss: 0.09771063178777695
Validation loss: 1.5181915324221376

Epoch: 6| Step: 13
Training loss: 0.07227803021669388
Validation loss: 1.5246525297882736

Epoch: 579| Step: 0
Training loss: 0.0805220678448677
Validation loss: 1.5235565272710656

Epoch: 6| Step: 1
Training loss: 0.07151603698730469
Validation loss: 1.5152465207602388

Epoch: 6| Step: 2
Training loss: 0.1165686771273613
Validation loss: 1.5464130627211703

Epoch: 6| Step: 3
Training loss: 0.03556098788976669
Validation loss: 1.5374460906110785

Epoch: 6| Step: 4
Training loss: 0.06698701530694962
Validation loss: 1.5611664813051942

Epoch: 6| Step: 5
Training loss: 0.03950171172618866
Validation loss: 1.5448687614933136

Epoch: 6| Step: 6
Training loss: 0.06910094618797302
Validation loss: 1.5425134948504868

Epoch: 6| Step: 7
Training loss: 0.05407445877790451
Validation loss: 1.564229743455046

Epoch: 6| Step: 8
Training loss: 0.06148297339677811
Validation loss: 1.560718205026401

Epoch: 6| Step: 9
Training loss: 0.07261474430561066
Validation loss: 1.5377236386781097

Epoch: 6| Step: 10
Training loss: 0.09542711079120636
Validation loss: 1.5168978680846512

Epoch: 6| Step: 11
Training loss: 0.11379396915435791
Validation loss: 1.5508208338932326

Epoch: 6| Step: 12
Training loss: 0.06825084984302521
Validation loss: 1.5322061290023148

Epoch: 6| Step: 13
Training loss: 0.045062437653541565
Validation loss: 1.520452291734757

Epoch: 580| Step: 0
Training loss: 0.05596894770860672
Validation loss: 1.4961762377010879

Epoch: 6| Step: 1
Training loss: 0.05710587650537491
Validation loss: 1.5085659898737425

Epoch: 6| Step: 2
Training loss: 0.05592629313468933
Validation loss: 1.4798077280803392

Epoch: 6| Step: 3
Training loss: 0.03456221893429756
Validation loss: 1.4938117688702

Epoch: 6| Step: 4
Training loss: 0.0732218474149704
Validation loss: 1.5303218428806593

Epoch: 6| Step: 5
Training loss: 0.09162316471338272
Validation loss: 1.4965064512786044

Epoch: 6| Step: 6
Training loss: 0.0999525636434555
Validation loss: 1.5043533335449875

Epoch: 6| Step: 7
Training loss: 0.07456208020448685
Validation loss: 1.4985382480006064

Epoch: 6| Step: 8
Training loss: 0.04822571203112602
Validation loss: 1.5035296140178558

Epoch: 6| Step: 9
Training loss: 0.095880426466465
Validation loss: 1.50520953055351

Epoch: 6| Step: 10
Training loss: 0.09734617173671722
Validation loss: 1.508181341232792

Epoch: 6| Step: 11
Training loss: 0.06550075858831406
Validation loss: 1.5027271034897014

Epoch: 6| Step: 12
Training loss: 0.101671501994133
Validation loss: 1.51438021403487

Epoch: 6| Step: 13
Training loss: 0.1281658560037613
Validation loss: 1.4898016452789307

Epoch: 581| Step: 0
Training loss: 0.0615321546792984
Validation loss: 1.5233202967592465

Epoch: 6| Step: 1
Training loss: 0.08161047101020813
Validation loss: 1.5147872714586155

Epoch: 6| Step: 2
Training loss: 0.06418093293905258
Validation loss: 1.5461637499511882

Epoch: 6| Step: 3
Training loss: 0.06837289035320282
Validation loss: 1.5145171316721107

Epoch: 6| Step: 4
Training loss: 0.0815013200044632
Validation loss: 1.531529306083597

Epoch: 6| Step: 5
Training loss: 0.06844867020845413
Validation loss: 1.5173934813468688

Epoch: 6| Step: 6
Training loss: 0.06014357879757881
Validation loss: 1.4845733668214531

Epoch: 6| Step: 7
Training loss: 0.0505961999297142
Validation loss: 1.5154568841380458

Epoch: 6| Step: 8
Training loss: 0.07309651374816895
Validation loss: 1.5377634340716946

Epoch: 6| Step: 9
Training loss: 0.05381812900304794
Validation loss: 1.5022558666044665

Epoch: 6| Step: 10
Training loss: 0.06480341404676437
Validation loss: 1.5319919445181405

Epoch: 6| Step: 11
Training loss: 0.05836857482790947
Validation loss: 1.5468307630990141

Epoch: 6| Step: 12
Training loss: 0.06012798100709915
Validation loss: 1.5225191321424258

Epoch: 6| Step: 13
Training loss: 0.19886460900306702
Validation loss: 1.5520734376804803

Epoch: 582| Step: 0
Training loss: 0.12814241647720337
Validation loss: 1.568133625932919

Epoch: 6| Step: 1
Training loss: 0.12391658127307892
Validation loss: 1.5787396930879163

Epoch: 6| Step: 2
Training loss: 0.059077225625514984
Validation loss: 1.5693211068389237

Epoch: 6| Step: 3
Training loss: 0.059978414326906204
Validation loss: 1.5527928580519974

Epoch: 6| Step: 4
Training loss: 0.053468309342861176
Validation loss: 1.533248415557287

Epoch: 6| Step: 5
Training loss: 0.07029171288013458
Validation loss: 1.5377952655156453

Epoch: 6| Step: 6
Training loss: 0.09335113316774368
Validation loss: 1.5466009570706276

Epoch: 6| Step: 7
Training loss: 0.08249421417713165
Validation loss: 1.5164744905246201

Epoch: 6| Step: 8
Training loss: 0.08320111036300659
Validation loss: 1.5230062623177805

Epoch: 6| Step: 9
Training loss: 0.09189066290855408
Validation loss: 1.5079340806571386

Epoch: 6| Step: 10
Training loss: 0.05854091793298721
Validation loss: 1.5170227994201004

Epoch: 6| Step: 11
Training loss: 0.047669585794210434
Validation loss: 1.5130550656267392

Epoch: 6| Step: 12
Training loss: 0.06998462229967117
Validation loss: 1.537021275489561

Epoch: 6| Step: 13
Training loss: 0.057856008410453796
Validation loss: 1.5366097637402114

Epoch: 583| Step: 0
Training loss: 0.13042104244232178
Validation loss: 1.5447918420196862

Epoch: 6| Step: 1
Training loss: 0.07371746003627777
Validation loss: 1.5435239384251256

Epoch: 6| Step: 2
Training loss: 0.05394509807229042
Validation loss: 1.545883918321261

Epoch: 6| Step: 3
Training loss: 0.13501569628715515
Validation loss: 1.5464809607434016

Epoch: 6| Step: 4
Training loss: 0.10948015749454498
Validation loss: 1.5617809962200861

Epoch: 6| Step: 5
Training loss: 0.076052226126194
Validation loss: 1.5475308074746081

Epoch: 6| Step: 6
Training loss: 0.12986773252487183
Validation loss: 1.532226558654539

Epoch: 6| Step: 7
Training loss: 0.13113060593605042
Validation loss: 1.5483189218787736

Epoch: 6| Step: 8
Training loss: 0.07014402747154236
Validation loss: 1.5254953715109056

Epoch: 6| Step: 9
Training loss: 0.03521077334880829
Validation loss: 1.5157671372095745

Epoch: 6| Step: 10
Training loss: 0.07276181131601334
Validation loss: 1.515391545910989

Epoch: 6| Step: 11
Training loss: 0.05642770975828171
Validation loss: 1.4940722091223604

Epoch: 6| Step: 12
Training loss: 0.048589564859867096
Validation loss: 1.4834931768396848

Epoch: 6| Step: 13
Training loss: 0.055704422295093536
Validation loss: 1.4857789893304147

Epoch: 584| Step: 0
Training loss: 0.056348927319049835
Validation loss: 1.5022168979849866

Epoch: 6| Step: 1
Training loss: 0.06373380869626999
Validation loss: 1.4794626838417464

Epoch: 6| Step: 2
Training loss: 0.12636126577854156
Validation loss: 1.4838038362482542

Epoch: 6| Step: 3
Training loss: 0.08006707578897476
Validation loss: 1.4900094578343053

Epoch: 6| Step: 4
Training loss: 0.0675479918718338
Validation loss: 1.5121259663694648

Epoch: 6| Step: 5
Training loss: 0.0642826035618782
Validation loss: 1.4918029744138

Epoch: 6| Step: 6
Training loss: 0.09474261850118637
Validation loss: 1.4828825086675665

Epoch: 6| Step: 7
Training loss: 0.12103104591369629
Validation loss: 1.4769620869749336

Epoch: 6| Step: 8
Training loss: 0.07598719745874405
Validation loss: 1.4746487358564973

Epoch: 6| Step: 9
Training loss: 0.052444614470005035
Validation loss: 1.5017060772065194

Epoch: 6| Step: 10
Training loss: 0.04833104461431503
Validation loss: 1.483289400736491

Epoch: 6| Step: 11
Training loss: 0.08932650834321976
Validation loss: 1.4899747333218973

Epoch: 6| Step: 12
Training loss: 0.101836197078228
Validation loss: 1.518548418757736

Epoch: 6| Step: 13
Training loss: 0.06622384488582611
Validation loss: 1.5321613691186393

Epoch: 585| Step: 0
Training loss: 0.04169772192835808
Validation loss: 1.5667128024562713

Epoch: 6| Step: 1
Training loss: 0.06923340260982513
Validation loss: 1.5508334482869794

Epoch: 6| Step: 2
Training loss: 0.07584036886692047
Validation loss: 1.5715340439991285

Epoch: 6| Step: 3
Training loss: 0.09100894629955292
Validation loss: 1.5776387927352742

Epoch: 6| Step: 4
Training loss: 0.09385910630226135
Validation loss: 1.5887873672669934

Epoch: 6| Step: 5
Training loss: 0.0881713479757309
Validation loss: 1.5766435092495334

Epoch: 6| Step: 6
Training loss: 0.07419479638338089
Validation loss: 1.5514408003899358

Epoch: 6| Step: 7
Training loss: 0.03171634301543236
Validation loss: 1.5419831993759319

Epoch: 6| Step: 8
Training loss: 0.06425055861473083
Validation loss: 1.5261451262299732

Epoch: 6| Step: 9
Training loss: 0.08913923054933548
Validation loss: 1.5473210670614754

Epoch: 6| Step: 10
Training loss: 0.06583293527364731
Validation loss: 1.5400283016184324

Epoch: 6| Step: 11
Training loss: 0.03871914744377136
Validation loss: 1.5380844864794003

Epoch: 6| Step: 12
Training loss: 0.10151723772287369
Validation loss: 1.5523372696292015

Epoch: 6| Step: 13
Training loss: 0.12576694786548615
Validation loss: 1.5509311210724614

Epoch: 586| Step: 0
Training loss: 0.06580772995948792
Validation loss: 1.5669201932927614

Epoch: 6| Step: 1
Training loss: 0.14031849801540375
Validation loss: 1.5741066855769004

Epoch: 6| Step: 2
Training loss: 0.1173572763800621
Validation loss: 1.5856094180896718

Epoch: 6| Step: 3
Training loss: 0.10075260698795319
Validation loss: 1.553596797809806

Epoch: 6| Step: 4
Training loss: 0.07323072850704193
Validation loss: 1.5302194805555447

Epoch: 6| Step: 5
Training loss: 0.06856991350650787
Validation loss: 1.514227956853887

Epoch: 6| Step: 6
Training loss: 0.08601605147123337
Validation loss: 1.5344065748235232

Epoch: 6| Step: 7
Training loss: 0.09490885585546494
Validation loss: 1.5120669782802623

Epoch: 6| Step: 8
Training loss: 0.09903248399496078
Validation loss: 1.5188664287649176

Epoch: 6| Step: 9
Training loss: 0.09583228081464767
Validation loss: 1.5066185574377737

Epoch: 6| Step: 10
Training loss: 0.06997939944267273
Validation loss: 1.5018160163715322

Epoch: 6| Step: 11
Training loss: 0.08213280141353607
Validation loss: 1.5132596390221709

Epoch: 6| Step: 12
Training loss: 0.11140084266662598
Validation loss: 1.5387411579009025

Epoch: 6| Step: 13
Training loss: 0.047141995280981064
Validation loss: 1.542170536133551

Epoch: 587| Step: 0
Training loss: 0.056604236364364624
Validation loss: 1.5537783971396826

Epoch: 6| Step: 1
Training loss: 0.10989075154066086
Validation loss: 1.54628840825891

Epoch: 6| Step: 2
Training loss: 0.10796281695365906
Validation loss: 1.5495944100041543

Epoch: 6| Step: 3
Training loss: 0.06298321485519409
Validation loss: 1.5652976253981232

Epoch: 6| Step: 4
Training loss: 0.159085214138031
Validation loss: 1.5777342575852589

Epoch: 6| Step: 5
Training loss: 0.1009734719991684
Validation loss: 1.5744525950442079

Epoch: 6| Step: 6
Training loss: 0.1455889344215393
Validation loss: 1.5152490856826946

Epoch: 6| Step: 7
Training loss: 0.0861603170633316
Validation loss: 1.5179514103038336

Epoch: 6| Step: 8
Training loss: 0.0678538829088211
Validation loss: 1.521593806564167

Epoch: 6| Step: 9
Training loss: 0.11016875505447388
Validation loss: 1.5427223790076472

Epoch: 6| Step: 10
Training loss: 0.15191127359867096
Validation loss: 1.5285881302689994

Epoch: 6| Step: 11
Training loss: 0.1428271234035492
Validation loss: 1.5257377393784062

Epoch: 6| Step: 12
Training loss: 0.08312726020812988
Validation loss: 1.5284560752171341

Epoch: 6| Step: 13
Training loss: 0.06254497915506363
Validation loss: 1.5325676343774284

Epoch: 588| Step: 0
Training loss: 0.08838490396738052
Validation loss: 1.5276469504961403

Epoch: 6| Step: 1
Training loss: 0.1254282295703888
Validation loss: 1.542672744361303

Epoch: 6| Step: 2
Training loss: 0.12509237229824066
Validation loss: 1.5376811514618576

Epoch: 6| Step: 3
Training loss: 0.07245151698589325
Validation loss: 1.5669216699497674

Epoch: 6| Step: 4
Training loss: 0.08166471123695374
Validation loss: 1.5474454228596022

Epoch: 6| Step: 5
Training loss: 0.10211315006017685
Validation loss: 1.5463645304402998

Epoch: 6| Step: 6
Training loss: 0.05211031436920166
Validation loss: 1.5309573424759733

Epoch: 6| Step: 7
Training loss: 0.10360969603061676
Validation loss: 1.5103965305512952

Epoch: 6| Step: 8
Training loss: 0.07349660992622375
Validation loss: 1.4929796720063815

Epoch: 6| Step: 9
Training loss: 0.11172064393758774
Validation loss: 1.5149488064550585

Epoch: 6| Step: 10
Training loss: 0.06839942187070847
Validation loss: 1.482530047816615

Epoch: 6| Step: 11
Training loss: 0.06414632499217987
Validation loss: 1.5111864151493195

Epoch: 6| Step: 12
Training loss: 0.05085379257798195
Validation loss: 1.5295828798765778

Epoch: 6| Step: 13
Training loss: 0.060132019221782684
Validation loss: 1.503790904757797

Epoch: 589| Step: 0
Training loss: 0.06494862586259842
Validation loss: 1.5392352150332542

Epoch: 6| Step: 1
Training loss: 0.08442186564207077
Validation loss: 1.5482060691361785

Epoch: 6| Step: 2
Training loss: 0.059415608644485474
Validation loss: 1.5506838726741012

Epoch: 6| Step: 3
Training loss: 0.07425304502248764
Validation loss: 1.562344604922879

Epoch: 6| Step: 4
Training loss: 0.0643317848443985
Validation loss: 1.580171746592368

Epoch: 6| Step: 5
Training loss: 0.08422990143299103
Validation loss: 1.5624659176795714

Epoch: 6| Step: 6
Training loss: 0.06801743805408478
Validation loss: 1.566604346357366

Epoch: 6| Step: 7
Training loss: 0.12532228231430054
Validation loss: 1.5547596075201546

Epoch: 6| Step: 8
Training loss: 0.05646922439336777
Validation loss: 1.5479954493943082

Epoch: 6| Step: 9
Training loss: 0.0473913848400116
Validation loss: 1.531695794033748

Epoch: 6| Step: 10
Training loss: 0.058902084827423096
Validation loss: 1.5307589128453245

Epoch: 6| Step: 11
Training loss: 0.08979865163564682
Validation loss: 1.5090254122211086

Epoch: 6| Step: 12
Training loss: 0.07162486016750336
Validation loss: 1.5037629065975067

Epoch: 6| Step: 13
Training loss: 0.0577201321721077
Validation loss: 1.5288297476307038

Epoch: 590| Step: 0
Training loss: 0.05820338800549507
Validation loss: 1.527298019778344

Epoch: 6| Step: 1
Training loss: 0.07841167598962784
Validation loss: 1.5079282137655443

Epoch: 6| Step: 2
Training loss: 0.07481168955564499
Validation loss: 1.4914361251297819

Epoch: 6| Step: 3
Training loss: 0.09000140428543091
Validation loss: 1.5173162619272869

Epoch: 6| Step: 4
Training loss: 0.07352370023727417
Validation loss: 1.5253418504550893

Epoch: 6| Step: 5
Training loss: 0.07804122567176819
Validation loss: 1.53690726910868

Epoch: 6| Step: 6
Training loss: 0.04964129626750946
Validation loss: 1.5442412027748682

Epoch: 6| Step: 7
Training loss: 0.0935090184211731
Validation loss: 1.559192370342952

Epoch: 6| Step: 8
Training loss: 0.07115218043327332
Validation loss: 1.5441172968956731

Epoch: 6| Step: 9
Training loss: 0.07138321548700333
Validation loss: 1.5518494306072113

Epoch: 6| Step: 10
Training loss: 0.05814012140035629
Validation loss: 1.5359055931850145

Epoch: 6| Step: 11
Training loss: 0.09650576114654541
Validation loss: 1.5242882390176096

Epoch: 6| Step: 12
Training loss: 0.05903128534555435
Validation loss: 1.5271134658526349

Epoch: 6| Step: 13
Training loss: 0.10122786462306976
Validation loss: 1.5338729754570992

Epoch: 591| Step: 0
Training loss: 0.08206164836883545
Validation loss: 1.5225195666795135

Epoch: 6| Step: 1
Training loss: 0.09113781899213791
Validation loss: 1.515643765849452

Epoch: 6| Step: 2
Training loss: 0.0731140673160553
Validation loss: 1.5255099932352703

Epoch: 6| Step: 3
Training loss: 0.051899589598178864
Validation loss: 1.5224758694248814

Epoch: 6| Step: 4
Training loss: 0.07006362080574036
Validation loss: 1.5302668034389455

Epoch: 6| Step: 5
Training loss: 0.08983711898326874
Validation loss: 1.528709287284523

Epoch: 6| Step: 6
Training loss: 0.06738444417715073
Validation loss: 1.5312688658314366

Epoch: 6| Step: 7
Training loss: 0.054035793989896774
Validation loss: 1.519977428579843

Epoch: 6| Step: 8
Training loss: 0.058422744274139404
Validation loss: 1.5059084687181699

Epoch: 6| Step: 9
Training loss: 0.0904662013053894
Validation loss: 1.5518946622007637

Epoch: 6| Step: 10
Training loss: 0.06510123610496521
Validation loss: 1.5227771125813967

Epoch: 6| Step: 11
Training loss: 0.09094586223363876
Validation loss: 1.5323661745235484

Epoch: 6| Step: 12
Training loss: 0.07369291037321091
Validation loss: 1.5217252380104476

Epoch: 6| Step: 13
Training loss: 0.0559641569852829
Validation loss: 1.5044911933201615

Epoch: 592| Step: 0
Training loss: 0.03384228050708771
Validation loss: 1.514920037920757

Epoch: 6| Step: 1
Training loss: 0.10996752977371216
Validation loss: 1.5192478613186908

Epoch: 6| Step: 2
Training loss: 0.07231754809617996
Validation loss: 1.5264921072990663

Epoch: 6| Step: 3
Training loss: 0.07441937923431396
Validation loss: 1.5027555342643493

Epoch: 6| Step: 4
Training loss: 0.08574318885803223
Validation loss: 1.5245763973523212

Epoch: 6| Step: 5
Training loss: 0.07811998575925827
Validation loss: 1.51865098040591

Epoch: 6| Step: 6
Training loss: 0.05394536256790161
Validation loss: 1.5302377323950491

Epoch: 6| Step: 7
Training loss: 0.0747692659497261
Validation loss: 1.5183897890070432

Epoch: 6| Step: 8
Training loss: 0.07223466783761978
Validation loss: 1.534632541800058

Epoch: 6| Step: 9
Training loss: 0.06151914224028587
Validation loss: 1.532051738872323

Epoch: 6| Step: 10
Training loss: 0.0816466361284256
Validation loss: 1.548302440233128

Epoch: 6| Step: 11
Training loss: 0.02736036852002144
Validation loss: 1.5335430560573455

Epoch: 6| Step: 12
Training loss: 0.10093770921230316
Validation loss: 1.5422343541217107

Epoch: 6| Step: 13
Training loss: 0.14226120710372925
Validation loss: 1.5178781350453694

Epoch: 593| Step: 0
Training loss: 0.10293053090572357
Validation loss: 1.5356333473677277

Epoch: 6| Step: 1
Training loss: 0.07512220740318298
Validation loss: 1.507385088551429

Epoch: 6| Step: 2
Training loss: 0.04187792167067528
Validation loss: 1.5077125128879343

Epoch: 6| Step: 3
Training loss: 0.05743660032749176
Validation loss: 1.4729209792229436

Epoch: 6| Step: 4
Training loss: 0.06452454626560211
Validation loss: 1.4734935606679609

Epoch: 6| Step: 5
Training loss: 0.05989145487546921
Validation loss: 1.4938875218873382

Epoch: 6| Step: 6
Training loss: 0.05110098421573639
Validation loss: 1.4525018943253385

Epoch: 6| Step: 7
Training loss: 0.07490263134241104
Validation loss: 1.4599802699140323

Epoch: 6| Step: 8
Training loss: 0.03954613208770752
Validation loss: 1.4678656670355028

Epoch: 6| Step: 9
Training loss: 0.07515670359134674
Validation loss: 1.463048593972319

Epoch: 6| Step: 10
Training loss: 0.10099557042121887
Validation loss: 1.4629166574888333

Epoch: 6| Step: 11
Training loss: 0.0710376724600792
Validation loss: 1.4710601036266615

Epoch: 6| Step: 12
Training loss: 0.09998902678489685
Validation loss: 1.4880311809560305

Epoch: 6| Step: 13
Training loss: 0.10871652513742447
Validation loss: 1.4776811670231562

Epoch: 594| Step: 0
Training loss: 0.06315499544143677
Validation loss: 1.510780498545657

Epoch: 6| Step: 1
Training loss: 0.09779610484838486
Validation loss: 1.5176788683860534

Epoch: 6| Step: 2
Training loss: 0.09213957190513611
Validation loss: 1.4977818548038442

Epoch: 6| Step: 3
Training loss: 0.0748295933008194
Validation loss: 1.5056549861866941

Epoch: 6| Step: 4
Training loss: 0.08914250880479813
Validation loss: 1.5066262528460512

Epoch: 6| Step: 5
Training loss: 0.09239712357521057
Validation loss: 1.5165781782519432

Epoch: 6| Step: 6
Training loss: 0.05977524816989899
Validation loss: 1.5100922199987596

Epoch: 6| Step: 7
Training loss: 0.050440624356269836
Validation loss: 1.5330212039332236

Epoch: 6| Step: 8
Training loss: 0.048108454793691635
Validation loss: 1.5084589713363237

Epoch: 6| Step: 9
Training loss: 0.05060647428035736
Validation loss: 1.5231423941991662

Epoch: 6| Step: 10
Training loss: 0.08853555470705032
Validation loss: 1.5212153491153513

Epoch: 6| Step: 11
Training loss: 0.06509555876255035
Validation loss: 1.5432523091634114

Epoch: 6| Step: 12
Training loss: 0.08958487212657928
Validation loss: 1.5307590756365048

Epoch: 6| Step: 13
Training loss: 0.07307647168636322
Validation loss: 1.5197851773231261

Epoch: 595| Step: 0
Training loss: 0.05968362092971802
Validation loss: 1.522288881322389

Epoch: 6| Step: 1
Training loss: 0.04439567029476166
Validation loss: 1.5070894123405538

Epoch: 6| Step: 2
Training loss: 0.09309148788452148
Validation loss: 1.5072589612776233

Epoch: 6| Step: 3
Training loss: 0.0853651836514473
Validation loss: 1.5288690854144353

Epoch: 6| Step: 4
Training loss: 0.04034697636961937
Validation loss: 1.5104409751071726

Epoch: 6| Step: 5
Training loss: 0.11622877418994904
Validation loss: 1.522649271513826

Epoch: 6| Step: 6
Training loss: 0.07031074166297913
Validation loss: 1.5244381030400593

Epoch: 6| Step: 7
Training loss: 0.05417859926819801
Validation loss: 1.51543410875464

Epoch: 6| Step: 8
Training loss: 0.1093117892742157
Validation loss: 1.513345085164552

Epoch: 6| Step: 9
Training loss: 0.08097594976425171
Validation loss: 1.5181514037552701

Epoch: 6| Step: 10
Training loss: 0.06488578766584396
Validation loss: 1.5160977532786708

Epoch: 6| Step: 11
Training loss: 0.10406675189733505
Validation loss: 1.5026364313658847

Epoch: 6| Step: 12
Training loss: 0.08503475785255432
Validation loss: 1.49910690194817

Epoch: 6| Step: 13
Training loss: 0.08314026892185211
Validation loss: 1.5006326808724353

Epoch: 596| Step: 0
Training loss: 0.050814803689718246
Validation loss: 1.5365465828167495

Epoch: 6| Step: 1
Training loss: 0.060413941740989685
Validation loss: 1.513077365454807

Epoch: 6| Step: 2
Training loss: 0.05240010842680931
Validation loss: 1.4993704365145775

Epoch: 6| Step: 3
Training loss: 0.07292667031288147
Validation loss: 1.5366633886932044

Epoch: 6| Step: 4
Training loss: 0.06144748628139496
Validation loss: 1.5306049700706237

Epoch: 6| Step: 5
Training loss: 0.04393966495990753
Validation loss: 1.5042665620003977

Epoch: 6| Step: 6
Training loss: 0.08439817279577255
Validation loss: 1.4954749204779183

Epoch: 6| Step: 7
Training loss: 0.10189491510391235
Validation loss: 1.5008172751754842

Epoch: 6| Step: 8
Training loss: 0.046853046864271164
Validation loss: 1.509496065878099

Epoch: 6| Step: 9
Training loss: 0.04249956086277962
Validation loss: 1.522240802805911

Epoch: 6| Step: 10
Training loss: 0.056064948439598083
Validation loss: 1.5200727210249951

Epoch: 6| Step: 11
Training loss: 0.05588768422603607
Validation loss: 1.5121139422539742

Epoch: 6| Step: 12
Training loss: 0.0872548446059227
Validation loss: 1.5180182226242558

Epoch: 6| Step: 13
Training loss: 0.07893060147762299
Validation loss: 1.5268796643903177

Epoch: 597| Step: 0
Training loss: 0.05763683468103409
Validation loss: 1.5430063259217046

Epoch: 6| Step: 1
Training loss: 0.046851564198732376
Validation loss: 1.5409443378448486

Epoch: 6| Step: 2
Training loss: 0.038360901176929474
Validation loss: 1.5626914578099405

Epoch: 6| Step: 3
Training loss: 0.06428574025630951
Validation loss: 1.5911990314401605

Epoch: 6| Step: 4
Training loss: 0.05529022961854935
Validation loss: 1.540245367634681

Epoch: 6| Step: 5
Training loss: 0.1146569550037384
Validation loss: 1.5462815415474676

Epoch: 6| Step: 6
Training loss: 0.07868318259716034
Validation loss: 1.565344646412839

Epoch: 6| Step: 7
Training loss: 0.03252905607223511
Validation loss: 1.5524250371481783

Epoch: 6| Step: 8
Training loss: 0.08394137769937515
Validation loss: 1.524330388474208

Epoch: 6| Step: 9
Training loss: 0.0674811601638794
Validation loss: 1.545057253171039

Epoch: 6| Step: 10
Training loss: 0.05247028172016144
Validation loss: 1.5489319985912693

Epoch: 6| Step: 11
Training loss: 0.05576440691947937
Validation loss: 1.52786724798141

Epoch: 6| Step: 12
Training loss: 0.10271459817886353
Validation loss: 1.5369474464847195

Epoch: 6| Step: 13
Training loss: 0.05641339719295502
Validation loss: 1.53533544207132

Epoch: 598| Step: 0
Training loss: 0.08455592393875122
Validation loss: 1.5429751001378542

Epoch: 6| Step: 1
Training loss: 0.05647003650665283
Validation loss: 1.4981450829454648

Epoch: 6| Step: 2
Training loss: 0.04799029603600502
Validation loss: 1.5345222450071765

Epoch: 6| Step: 3
Training loss: 0.04277051240205765
Validation loss: 1.542520720471618

Epoch: 6| Step: 4
Training loss: 0.05724605172872543
Validation loss: 1.5182235420391124

Epoch: 6| Step: 5
Training loss: 0.09448084980249405
Validation loss: 1.5056180005432458

Epoch: 6| Step: 6
Training loss: 0.07853783667087555
Validation loss: 1.5378924903049265

Epoch: 6| Step: 7
Training loss: 0.06350909173488617
Validation loss: 1.5198270454201648

Epoch: 6| Step: 8
Training loss: 0.05956504866480827
Validation loss: 1.5253531086829402

Epoch: 6| Step: 9
Training loss: 0.056147269904613495
Validation loss: 1.4735539292776456

Epoch: 6| Step: 10
Training loss: 0.05320819467306137
Validation loss: 1.5071674008523264

Epoch: 6| Step: 11
Training loss: 0.051503829658031464
Validation loss: 1.522345309616417

Epoch: 6| Step: 12
Training loss: 0.069928377866745
Validation loss: 1.512925653047459

Epoch: 6| Step: 13
Training loss: 0.02470821887254715
Validation loss: 1.517811280424877

Epoch: 599| Step: 0
Training loss: 0.03557366505265236
Validation loss: 1.5285195394228863

Epoch: 6| Step: 1
Training loss: 0.07167761027812958
Validation loss: 1.536203997109526

Epoch: 6| Step: 2
Training loss: 0.06748388707637787
Validation loss: 1.5312651139433666

Epoch: 6| Step: 3
Training loss: 0.053485430777072906
Validation loss: 1.541917722712281

Epoch: 6| Step: 4
Training loss: 0.0778496116399765
Validation loss: 1.526921574787427

Epoch: 6| Step: 5
Training loss: 0.061460696160793304
Validation loss: 1.5241116958279763

Epoch: 6| Step: 6
Training loss: 0.06303492188453674
Validation loss: 1.525760736516727

Epoch: 6| Step: 7
Training loss: 0.04783123731613159
Validation loss: 1.5306761175073602

Epoch: 6| Step: 8
Training loss: 0.04466668516397476
Validation loss: 1.5200889713020735

Epoch: 6| Step: 9
Training loss: 0.04816920682787895
Validation loss: 1.534458661592135

Epoch: 6| Step: 10
Training loss: 0.03995460271835327
Validation loss: 1.5287894766817811

Epoch: 6| Step: 11
Training loss: 0.08110711723566055
Validation loss: 1.4933812259345927

Epoch: 6| Step: 12
Training loss: 0.11297919601202011
Validation loss: 1.4739214515173307

Epoch: 6| Step: 13
Training loss: 0.10010503232479095
Validation loss: 1.5100177488019388

Epoch: 600| Step: 0
Training loss: 0.05827302485704422
Validation loss: 1.497207191682631

Epoch: 6| Step: 1
Training loss: 0.04908570647239685
Validation loss: 1.4910102813474593

Epoch: 6| Step: 2
Training loss: 0.07102829962968826
Validation loss: 1.5003535689846161

Epoch: 6| Step: 3
Training loss: 0.07222221791744232
Validation loss: 1.4823628881926179

Epoch: 6| Step: 4
Training loss: 0.07116030156612396
Validation loss: 1.5076613349299277

Epoch: 6| Step: 5
Training loss: 0.059710461646318436
Validation loss: 1.4676477601451259

Epoch: 6| Step: 6
Training loss: 0.07160790264606476
Validation loss: 1.5073424103439494

Epoch: 6| Step: 7
Training loss: 0.07088268548250198
Validation loss: 1.495518801032856

Epoch: 6| Step: 8
Training loss: 0.044846199452877045
Validation loss: 1.4916690716179468

Epoch: 6| Step: 9
Training loss: 0.03805767744779587
Validation loss: 1.480295737584432

Epoch: 6| Step: 10
Training loss: 0.05316796153783798
Validation loss: 1.4928260105912403

Epoch: 6| Step: 11
Training loss: 0.07716608047485352
Validation loss: 1.485394077916299

Epoch: 6| Step: 12
Training loss: 0.040204890072345734
Validation loss: 1.5130776128461283

Epoch: 6| Step: 13
Training loss: 0.08823657035827637
Validation loss: 1.5299985101146083

Epoch: 601| Step: 0
Training loss: 0.05412884056568146
Validation loss: 1.5130445841820008

Epoch: 6| Step: 1
Training loss: 0.07352077215909958
Validation loss: 1.5167225099379016

Epoch: 6| Step: 2
Training loss: 0.05287285894155502
Validation loss: 1.5189798384584405

Epoch: 6| Step: 3
Training loss: 0.05330755561590195
Validation loss: 1.480666486806767

Epoch: 6| Step: 4
Training loss: 0.05023317411541939
Validation loss: 1.4856354472457722

Epoch: 6| Step: 5
Training loss: 0.0832618772983551
Validation loss: 1.5416496633201517

Epoch: 6| Step: 6
Training loss: 0.04401145875453949
Validation loss: 1.4893795059573265

Epoch: 6| Step: 7
Training loss: 0.046487368643283844
Validation loss: 1.5059338705514067

Epoch: 6| Step: 8
Training loss: 0.07042969763278961
Validation loss: 1.4969889348553074

Epoch: 6| Step: 9
Training loss: 0.04322698712348938
Validation loss: 1.4893921318874563

Epoch: 6| Step: 10
Training loss: 0.09671202301979065
Validation loss: 1.4887663709220065

Epoch: 6| Step: 11
Training loss: 0.050818219780921936
Validation loss: 1.4991607396833357

Epoch: 6| Step: 12
Training loss: 0.04846639931201935
Validation loss: 1.5182516638950636

Epoch: 6| Step: 13
Training loss: 0.03999659791588783
Validation loss: 1.5054110532165856

Epoch: 602| Step: 0
Training loss: 0.06098288297653198
Validation loss: 1.503123825596225

Epoch: 6| Step: 1
Training loss: 0.05399530380964279
Validation loss: 1.5069227154536913

Epoch: 6| Step: 2
Training loss: 0.07151702046394348
Validation loss: 1.5332870380852812

Epoch: 6| Step: 3
Training loss: 0.06387439370155334
Validation loss: 1.5135854098104662

Epoch: 6| Step: 4
Training loss: 0.0703214704990387
Validation loss: 1.5028487661833405

Epoch: 6| Step: 5
Training loss: 0.07354910671710968
Validation loss: 1.5005772126618253

Epoch: 6| Step: 6
Training loss: 0.07880349457263947
Validation loss: 1.5318982857529835

Epoch: 6| Step: 7
Training loss: 0.127553328871727
Validation loss: 1.512086997749985

Epoch: 6| Step: 8
Training loss: 0.08024752140045166
Validation loss: 1.5422587215259511

Epoch: 6| Step: 9
Training loss: 0.08747728914022446
Validation loss: 1.5351039978765673

Epoch: 6| Step: 10
Training loss: 0.0840834230184555
Validation loss: 1.5289544264475505

Epoch: 6| Step: 11
Training loss: 0.0928257554769516
Validation loss: 1.5397614663647068

Epoch: 6| Step: 12
Training loss: 0.09298740327358246
Validation loss: 1.5093743083297566

Epoch: 6| Step: 13
Training loss: 0.06923825293779373
Validation loss: 1.510422779667762

Epoch: 603| Step: 0
Training loss: 0.1082734689116478
Validation loss: 1.5007497956675868

Epoch: 6| Step: 1
Training loss: 0.067049540579319
Validation loss: 1.5253351503802883

Epoch: 6| Step: 2
Training loss: 0.06535740196704865
Validation loss: 1.5063577877577914

Epoch: 6| Step: 3
Training loss: 0.10535374283790588
Validation loss: 1.5020665737890428

Epoch: 6| Step: 4
Training loss: 0.09483496844768524
Validation loss: 1.5133026646029564

Epoch: 6| Step: 5
Training loss: 0.06386848539113998
Validation loss: 1.5078635728487404

Epoch: 6| Step: 6
Training loss: 0.08367541432380676
Validation loss: 1.5420579551368632

Epoch: 6| Step: 7
Training loss: 0.10952141135931015
Validation loss: 1.528122933962012

Epoch: 6| Step: 8
Training loss: 0.03138015419244766
Validation loss: 1.5387451264166063

Epoch: 6| Step: 9
Training loss: 0.07005760073661804
Validation loss: 1.5257984412613737

Epoch: 6| Step: 10
Training loss: 0.1165504902601242
Validation loss: 1.5287649990409933

Epoch: 6| Step: 11
Training loss: 0.0556487999856472
Validation loss: 1.5317616795980802

Epoch: 6| Step: 12
Training loss: 0.0471930131316185
Validation loss: 1.4984784959464945

Epoch: 6| Step: 13
Training loss: 0.0969877615571022
Validation loss: 1.5090677174188758

Epoch: 604| Step: 0
Training loss: 0.11935244500637054
Validation loss: 1.5197637215737374

Epoch: 6| Step: 1
Training loss: 0.09999507665634155
Validation loss: 1.5074505485514158

Epoch: 6| Step: 2
Training loss: 0.08661477267742157
Validation loss: 1.4999102482231714

Epoch: 6| Step: 3
Training loss: 0.061224110424518585
Validation loss: 1.4789205353747132

Epoch: 6| Step: 4
Training loss: 0.07579585909843445
Validation loss: 1.5196018359994377

Epoch: 6| Step: 5
Training loss: 0.09697742760181427
Validation loss: 1.5062624792898855

Epoch: 6| Step: 6
Training loss: 0.09482301771640778
Validation loss: 1.5083697611285793

Epoch: 6| Step: 7
Training loss: 0.09394282102584839
Validation loss: 1.5078705369785268

Epoch: 6| Step: 8
Training loss: 0.061250798404216766
Validation loss: 1.4665610021160496

Epoch: 6| Step: 9
Training loss: 0.10312652587890625
Validation loss: 1.4691506803676646

Epoch: 6| Step: 10
Training loss: 0.06073840335011482
Validation loss: 1.4824671117208337

Epoch: 6| Step: 11
Training loss: 0.0931503102183342
Validation loss: 1.4888933832927416

Epoch: 6| Step: 12
Training loss: 0.07218966633081436
Validation loss: 1.486713392760164

Epoch: 6| Step: 13
Training loss: 0.07824749499559402
Validation loss: 1.506124625923813

Epoch: 605| Step: 0
Training loss: 0.07113786041736603
Validation loss: 1.5107861654732817

Epoch: 6| Step: 1
Training loss: 0.07760877907276154
Validation loss: 1.5126066182249336

Epoch: 6| Step: 2
Training loss: 0.06689530611038208
Validation loss: 1.5165382777490923

Epoch: 6| Step: 3
Training loss: 0.08918656408786774
Validation loss: 1.547849146268701

Epoch: 6| Step: 4
Training loss: 0.037773214280605316
Validation loss: 1.515970386484618

Epoch: 6| Step: 5
Training loss: 0.06396056711673737
Validation loss: 1.5172243887378323

Epoch: 6| Step: 6
Training loss: 0.05698655918240547
Validation loss: 1.5219947868777859

Epoch: 6| Step: 7
Training loss: 0.10082724690437317
Validation loss: 1.538325095689425

Epoch: 6| Step: 8
Training loss: 0.07137459516525269
Validation loss: 1.5138861774116434

Epoch: 6| Step: 9
Training loss: 0.05975020304322243
Validation loss: 1.5217130107264365

Epoch: 6| Step: 10
Training loss: 0.06481322646141052
Validation loss: 1.502154879672553

Epoch: 6| Step: 11
Training loss: 0.164857879281044
Validation loss: 1.4946864292185793

Epoch: 6| Step: 12
Training loss: 0.0599711611866951
Validation loss: 1.4890123387818694

Epoch: 6| Step: 13
Training loss: 0.07637029141187668
Validation loss: 1.5038706564134168

Epoch: 606| Step: 0
Training loss: 0.060973282903432846
Validation loss: 1.4746769653853549

Epoch: 6| Step: 1
Training loss: 0.058754272758960724
Validation loss: 1.4956304322006881

Epoch: 6| Step: 2
Training loss: 0.06585866212844849
Validation loss: 1.48768525995234

Epoch: 6| Step: 3
Training loss: 0.06872503459453583
Validation loss: 1.5102343713083575

Epoch: 6| Step: 4
Training loss: 0.07470791786909103
Validation loss: 1.489739017460936

Epoch: 6| Step: 5
Training loss: 0.05424943566322327
Validation loss: 1.5254949940148221

Epoch: 6| Step: 6
Training loss: 0.08904001861810684
Validation loss: 1.511019508043925

Epoch: 6| Step: 7
Training loss: 0.06662191450595856
Validation loss: 1.525440054555093

Epoch: 6| Step: 8
Training loss: 0.08728994429111481
Validation loss: 1.5250290888611988

Epoch: 6| Step: 9
Training loss: 0.05309111252427101
Validation loss: 1.528482824243525

Epoch: 6| Step: 10
Training loss: 0.0645437091588974
Validation loss: 1.5423691413735832

Epoch: 6| Step: 11
Training loss: 0.06425915658473969
Validation loss: 1.5303205584967008

Epoch: 6| Step: 12
Training loss: 0.08281662315130234
Validation loss: 1.5198423535593095

Epoch: 6| Step: 13
Training loss: 0.05802373215556145
Validation loss: 1.5337703740724953

Epoch: 607| Step: 0
Training loss: 0.06845363974571228
Validation loss: 1.540469237553176

Epoch: 6| Step: 1
Training loss: 0.05818285793066025
Validation loss: 1.508867230466617

Epoch: 6| Step: 2
Training loss: 0.07430143654346466
Validation loss: 1.5142699890239264

Epoch: 6| Step: 3
Training loss: 0.04849795997142792
Validation loss: 1.4947565178717337

Epoch: 6| Step: 4
Training loss: 0.04357177019119263
Validation loss: 1.5076300713323778

Epoch: 6| Step: 5
Training loss: 0.06716223061084747
Validation loss: 1.4889955982085197

Epoch: 6| Step: 6
Training loss: 0.08089198172092438
Validation loss: 1.475453064005862

Epoch: 6| Step: 7
Training loss: 0.05577687919139862
Validation loss: 1.4727803801977506

Epoch: 6| Step: 8
Training loss: 0.07795045524835587
Validation loss: 1.5018846052949146

Epoch: 6| Step: 9
Training loss: 0.07022834569215775
Validation loss: 1.4771185844175276

Epoch: 6| Step: 10
Training loss: 0.07049864530563354
Validation loss: 1.4741213212731064

Epoch: 6| Step: 11
Training loss: 0.06719963252544403
Validation loss: 1.504612281758298

Epoch: 6| Step: 12
Training loss: 0.05709518492221832
Validation loss: 1.491404878195896

Epoch: 6| Step: 13
Training loss: 0.06894980370998383
Validation loss: 1.5005176605716828

Epoch: 608| Step: 0
Training loss: 0.04599964991211891
Validation loss: 1.5141099896482242

Epoch: 6| Step: 1
Training loss: 0.05818473547697067
Validation loss: 1.5225227661030267

Epoch: 6| Step: 2
Training loss: 0.06476148962974548
Validation loss: 1.5091787512584398

Epoch: 6| Step: 3
Training loss: 0.049111876636743546
Validation loss: 1.525792118041746

Epoch: 6| Step: 4
Training loss: 0.04132317006587982
Validation loss: 1.5355185039581791

Epoch: 6| Step: 5
Training loss: 0.0620088092982769
Validation loss: 1.5299499400200383

Epoch: 6| Step: 6
Training loss: 0.05349338427186012
Validation loss: 1.5507549188470329

Epoch: 6| Step: 7
Training loss: 0.05725891888141632
Validation loss: 1.5419644988993162

Epoch: 6| Step: 8
Training loss: 0.04804341495037079
Validation loss: 1.5660645282396706

Epoch: 6| Step: 9
Training loss: 0.12650994956493378
Validation loss: 1.5438553517864597

Epoch: 6| Step: 10
Training loss: 0.0808546170592308
Validation loss: 1.5526417711729645

Epoch: 6| Step: 11
Training loss: 0.05996048077940941
Validation loss: 1.565098314516006

Epoch: 6| Step: 12
Training loss: 0.04678230732679367
Validation loss: 1.566638272295716

Epoch: 6| Step: 13
Training loss: 0.0553925558924675
Validation loss: 1.54763206999789

Epoch: 609| Step: 0
Training loss: 0.04241998493671417
Validation loss: 1.552402191264655

Epoch: 6| Step: 1
Training loss: 0.05813855305314064
Validation loss: 1.5384975171858264

Epoch: 6| Step: 2
Training loss: 0.08894573152065277
Validation loss: 1.542874752834279

Epoch: 6| Step: 3
Training loss: 0.05443111062049866
Validation loss: 1.5529740574539348

Epoch: 6| Step: 4
Training loss: 0.04945661872625351
Validation loss: 1.5479799047593148

Epoch: 6| Step: 5
Training loss: 0.05991438776254654
Validation loss: 1.537847529175461

Epoch: 6| Step: 6
Training loss: 0.05065719783306122
Validation loss: 1.5534568832766624

Epoch: 6| Step: 7
Training loss: 0.06517317146062851
Validation loss: 1.5419669638397873

Epoch: 6| Step: 8
Training loss: 0.04539934918284416
Validation loss: 1.5241463415084346

Epoch: 6| Step: 9
Training loss: 0.08514711260795593
Validation loss: 1.543587988422763

Epoch: 6| Step: 10
Training loss: 0.10667017102241516
Validation loss: 1.5220512613173454

Epoch: 6| Step: 11
Training loss: 0.04105616360902786
Validation loss: 1.5549005039276615

Epoch: 6| Step: 12
Training loss: 0.0678618922829628
Validation loss: 1.5532261607467488

Epoch: 6| Step: 13
Training loss: 0.06744919717311859
Validation loss: 1.5421820840527933

Epoch: 610| Step: 0
Training loss: 0.0752725675702095
Validation loss: 1.5205707165502733

Epoch: 6| Step: 1
Training loss: 0.04701308161020279
Validation loss: 1.5273625171312721

Epoch: 6| Step: 2
Training loss: 0.055324990302324295
Validation loss: 1.5482553564092165

Epoch: 6| Step: 3
Training loss: 0.06279994547367096
Validation loss: 1.5380699365369734

Epoch: 6| Step: 4
Training loss: 0.07644828408956528
Validation loss: 1.5348357705659763

Epoch: 6| Step: 5
Training loss: 0.09602370113134384
Validation loss: 1.5543200367240495

Epoch: 6| Step: 6
Training loss: 0.048974424600601196
Validation loss: 1.549832163318511

Epoch: 6| Step: 7
Training loss: 0.05354512855410576
Validation loss: 1.5819221658091391

Epoch: 6| Step: 8
Training loss: 0.0627327486872673
Validation loss: 1.5559009877584313

Epoch: 6| Step: 9
Training loss: 0.07771085202693939
Validation loss: 1.547481736829204

Epoch: 6| Step: 10
Training loss: 0.08061596006155014
Validation loss: 1.5478597943500807

Epoch: 6| Step: 11
Training loss: 0.05129086598753929
Validation loss: 1.5623039801915486

Epoch: 6| Step: 12
Training loss: 0.036339275538921356
Validation loss: 1.5452467382595103

Epoch: 6| Step: 13
Training loss: 0.042987968772649765
Validation loss: 1.5280653904843073

Epoch: 611| Step: 0
Training loss: 0.0671742856502533
Validation loss: 1.5259301124080535

Epoch: 6| Step: 1
Training loss: 0.05403490364551544
Validation loss: 1.543131225852556

Epoch: 6| Step: 2
Training loss: 0.049429625272750854
Validation loss: 1.5515619336917836

Epoch: 6| Step: 3
Training loss: 0.04702942073345184
Validation loss: 1.5455264263255621

Epoch: 6| Step: 4
Training loss: 0.1010860800743103
Validation loss: 1.5238745597101027

Epoch: 6| Step: 5
Training loss: 0.11145040392875671
Validation loss: 1.5267768636826546

Epoch: 6| Step: 6
Training loss: 0.10457389801740646
Validation loss: 1.530210671886321

Epoch: 6| Step: 7
Training loss: 0.07032746076583862
Validation loss: 1.5343107587547713

Epoch: 6| Step: 8
Training loss: 0.07420191168785095
Validation loss: 1.5519460888319119

Epoch: 6| Step: 9
Training loss: 0.06815415620803833
Validation loss: 1.5643637718692902

Epoch: 6| Step: 10
Training loss: 0.04821929335594177
Validation loss: 1.5872075916618429

Epoch: 6| Step: 11
Training loss: 0.08339275419712067
Validation loss: 1.6128587556141678

Epoch: 6| Step: 12
Training loss: 0.11418163776397705
Validation loss: 1.608002233248885

Epoch: 6| Step: 13
Training loss: 0.08887945115566254
Validation loss: 1.5859477686625656

Epoch: 612| Step: 0
Training loss: 0.06443235278129578
Validation loss: 1.5626932523583854

Epoch: 6| Step: 1
Training loss: 0.06660981476306915
Validation loss: 1.517221300832687

Epoch: 6| Step: 2
Training loss: 0.0767754390835762
Validation loss: 1.5336442993533226

Epoch: 6| Step: 3
Training loss: 0.06165195256471634
Validation loss: 1.5306296220389746

Epoch: 6| Step: 4
Training loss: 0.09108486026525497
Validation loss: 1.515211679602182

Epoch: 6| Step: 5
Training loss: 0.13121816515922546
Validation loss: 1.49851785039389

Epoch: 6| Step: 6
Training loss: 0.1375787854194641
Validation loss: 1.493486294182398

Epoch: 6| Step: 7
Training loss: 0.07552354782819748
Validation loss: 1.5044580531376663

Epoch: 6| Step: 8
Training loss: 0.07754427194595337
Validation loss: 1.4993037087942964

Epoch: 6| Step: 9
Training loss: 0.08607389032840729
Validation loss: 1.513760958948443

Epoch: 6| Step: 10
Training loss: 0.06740587204694748
Validation loss: 1.5135936685787734

Epoch: 6| Step: 11
Training loss: 0.06454503536224365
Validation loss: 1.5379310327191507

Epoch: 6| Step: 12
Training loss: 0.07225871086120605
Validation loss: 1.5278305084474626

Epoch: 6| Step: 13
Training loss: 0.09663617610931396
Validation loss: 1.5430098964321999

Epoch: 613| Step: 0
Training loss: 0.0526246577501297
Validation loss: 1.5430167862164077

Epoch: 6| Step: 1
Training loss: 0.033811286091804504
Validation loss: 1.535945620588077

Epoch: 6| Step: 2
Training loss: 0.04172143340110779
Validation loss: 1.5493851336099769

Epoch: 6| Step: 3
Training loss: 0.03514089435338974
Validation loss: 1.5186458838883268

Epoch: 6| Step: 4
Training loss: 0.04805554449558258
Validation loss: 1.5183734393888904

Epoch: 6| Step: 5
Training loss: 0.06123385578393936
Validation loss: 1.5233064800180414

Epoch: 6| Step: 6
Training loss: 0.05162186920642853
Validation loss: 1.5371542713975395

Epoch: 6| Step: 7
Training loss: 0.13396476209163666
Validation loss: 1.5275092253120996

Epoch: 6| Step: 8
Training loss: 0.061841174960136414
Validation loss: 1.515259035172001

Epoch: 6| Step: 9
Training loss: 0.05124934762716293
Validation loss: 1.491119582165954

Epoch: 6| Step: 10
Training loss: 0.08453693985939026
Validation loss: 1.5072834645548174

Epoch: 6| Step: 11
Training loss: 0.07623690366744995
Validation loss: 1.4967917037266556

Epoch: 6| Step: 12
Training loss: 0.08093708753585815
Validation loss: 1.5336354791477163

Epoch: 6| Step: 13
Training loss: 0.06357359886169434
Validation loss: 1.509477323101413

Epoch: 614| Step: 0
Training loss: 0.11629277467727661
Validation loss: 1.476463072402503

Epoch: 6| Step: 1
Training loss: 0.07842876017093658
Validation loss: 1.504805059843166

Epoch: 6| Step: 2
Training loss: 0.039792485535144806
Validation loss: 1.494689351768904

Epoch: 6| Step: 3
Training loss: 0.08889712393283844
Validation loss: 1.4977188520534064

Epoch: 6| Step: 4
Training loss: 0.06530773639678955
Validation loss: 1.5149157931727748

Epoch: 6| Step: 5
Training loss: 0.054407160729169846
Validation loss: 1.52974235498777

Epoch: 6| Step: 6
Training loss: 0.07606425881385803
Validation loss: 1.5217107470317552

Epoch: 6| Step: 7
Training loss: 0.10244424641132355
Validation loss: 1.516510207165954

Epoch: 6| Step: 8
Training loss: 0.07543382048606873
Validation loss: 1.5160314088226647

Epoch: 6| Step: 9
Training loss: 0.04623784124851227
Validation loss: 1.4943966224629393

Epoch: 6| Step: 10
Training loss: 0.056337468326091766
Validation loss: 1.5090494450702463

Epoch: 6| Step: 11
Training loss: 0.06446918100118637
Validation loss: 1.4652291049239456

Epoch: 6| Step: 12
Training loss: 0.05208226665854454
Validation loss: 1.4841744617749286

Epoch: 6| Step: 13
Training loss: 0.10421843081712723
Validation loss: 1.4864373168637675

Epoch: 615| Step: 0
Training loss: 0.07867315411567688
Validation loss: 1.4920599909238919

Epoch: 6| Step: 1
Training loss: 0.05208639055490494
Validation loss: 1.4860903633538114

Epoch: 6| Step: 2
Training loss: 0.05981699377298355
Validation loss: 1.4943543711016256

Epoch: 6| Step: 3
Training loss: 0.06440974026918411
Validation loss: 1.517803906753499

Epoch: 6| Step: 4
Training loss: 0.1176043301820755
Validation loss: 1.5304744410258468

Epoch: 6| Step: 5
Training loss: 0.03708165884017944
Validation loss: 1.5319400859135452

Epoch: 6| Step: 6
Training loss: 0.06950391829013824
Validation loss: 1.5192419111087758

Epoch: 6| Step: 7
Training loss: 0.09135956317186356
Validation loss: 1.5000973850168207

Epoch: 6| Step: 8
Training loss: 0.05128324404358864
Validation loss: 1.5099136598648564

Epoch: 6| Step: 9
Training loss: 0.047956354916095734
Validation loss: 1.4938916506305817

Epoch: 6| Step: 10
Training loss: 0.04360242560505867
Validation loss: 1.5032465124642977

Epoch: 6| Step: 11
Training loss: 0.06638284027576447
Validation loss: 1.4913525183995564

Epoch: 6| Step: 12
Training loss: 0.046468354761600494
Validation loss: 1.4955348019958825

Epoch: 6| Step: 13
Training loss: 0.052509479224681854
Validation loss: 1.4753564673085366

Epoch: 616| Step: 0
Training loss: 0.13574421405792236
Validation loss: 1.482750468356635

Epoch: 6| Step: 1
Training loss: 0.05114617198705673
Validation loss: 1.5062665003602222

Epoch: 6| Step: 2
Training loss: 0.06741321086883545
Validation loss: 1.5293141706015474

Epoch: 6| Step: 3
Training loss: 0.060959912836551666
Validation loss: 1.52680754405196

Epoch: 6| Step: 4
Training loss: 0.07010521739721298
Validation loss: 1.5314991051150906

Epoch: 6| Step: 5
Training loss: 0.07756217569112778
Validation loss: 1.5456605290853849

Epoch: 6| Step: 6
Training loss: 0.05291726440191269
Validation loss: 1.5432705097301032

Epoch: 6| Step: 7
Training loss: 0.09930320829153061
Validation loss: 1.5465669657594414

Epoch: 6| Step: 8
Training loss: 0.049638595432043076
Validation loss: 1.5389931458298878

Epoch: 6| Step: 9
Training loss: 0.046528976410627365
Validation loss: 1.5404842233145108

Epoch: 6| Step: 10
Training loss: 0.054373010993003845
Validation loss: 1.4901538792476858

Epoch: 6| Step: 11
Training loss: 0.046888649463653564
Validation loss: 1.5175259023584344

Epoch: 6| Step: 12
Training loss: 0.05604507029056549
Validation loss: 1.5047606088781869

Epoch: 6| Step: 13
Training loss: 0.04934742674231529
Validation loss: 1.4854062052183254

Epoch: 617| Step: 0
Training loss: 0.055914923548698425
Validation loss: 1.490403752814057

Epoch: 6| Step: 1
Training loss: 0.06175439804792404
Validation loss: 1.4840494150756507

Epoch: 6| Step: 2
Training loss: 0.06364583969116211
Validation loss: 1.5002186875189505

Epoch: 6| Step: 3
Training loss: 0.06897865235805511
Validation loss: 1.5209117935549827

Epoch: 6| Step: 4
Training loss: 0.08331616222858429
Validation loss: 1.5098019748605707

Epoch: 6| Step: 5
Training loss: 0.05911470204591751
Validation loss: 1.5111594597498577

Epoch: 6| Step: 6
Training loss: 0.08479756116867065
Validation loss: 1.5130056027443177

Epoch: 6| Step: 7
Training loss: 0.05450841039419174
Validation loss: 1.5133330719445341

Epoch: 6| Step: 8
Training loss: 0.06443415582180023
Validation loss: 1.5040493037111016

Epoch: 6| Step: 9
Training loss: 0.05991625040769577
Validation loss: 1.507935639991555

Epoch: 6| Step: 10
Training loss: 0.04409382492303848
Validation loss: 1.5393845265911472

Epoch: 6| Step: 11
Training loss: 0.0447973869740963
Validation loss: 1.510682903310304

Epoch: 6| Step: 12
Training loss: 0.054458796977996826
Validation loss: 1.4868854861105643

Epoch: 6| Step: 13
Training loss: 0.10960552096366882
Validation loss: 1.5134130831687682

Epoch: 618| Step: 0
Training loss: 0.0818772092461586
Validation loss: 1.5149875328104982

Epoch: 6| Step: 1
Training loss: 0.04947119951248169
Validation loss: 1.4769653133166734

Epoch: 6| Step: 2
Training loss: 0.06415875256061554
Validation loss: 1.5110681723522883

Epoch: 6| Step: 3
Training loss: 0.04685971140861511
Validation loss: 1.505444082521623

Epoch: 6| Step: 4
Training loss: 0.06024140864610672
Validation loss: 1.5040146022714593

Epoch: 6| Step: 5
Training loss: 0.07904833555221558
Validation loss: 1.5026060406879713

Epoch: 6| Step: 6
Training loss: 0.05089551955461502
Validation loss: 1.5122495402571976

Epoch: 6| Step: 7
Training loss: 0.051476769149303436
Validation loss: 1.4974107806400587

Epoch: 6| Step: 8
Training loss: 0.053896427154541016
Validation loss: 1.4984683272659138

Epoch: 6| Step: 9
Training loss: 0.0535106360912323
Validation loss: 1.4918515938584522

Epoch: 6| Step: 10
Training loss: 0.08995389193296432
Validation loss: 1.5025071764505038

Epoch: 6| Step: 11
Training loss: 0.026933584362268448
Validation loss: 1.480195132634973

Epoch: 6| Step: 12
Training loss: 0.07484498620033264
Validation loss: 1.4829834712448942

Epoch: 6| Step: 13
Training loss: 0.07376465946435928
Validation loss: 1.475402150102841

Epoch: 619| Step: 0
Training loss: 0.055045999586582184
Validation loss: 1.4881089156673801

Epoch: 6| Step: 1
Training loss: 0.06543395668268204
Validation loss: 1.5165516189349595

Epoch: 6| Step: 2
Training loss: 0.054646335542201996
Validation loss: 1.483647532360528

Epoch: 6| Step: 3
Training loss: 0.039343610405921936
Validation loss: 1.4792904591047635

Epoch: 6| Step: 4
Training loss: 0.06491285562515259
Validation loss: 1.4758222795301867

Epoch: 6| Step: 5
Training loss: 0.06076505407691002
Validation loss: 1.4902226912078036

Epoch: 6| Step: 6
Training loss: 0.07544319331645966
Validation loss: 1.4856338898340862

Epoch: 6| Step: 7
Training loss: 0.10082545876502991
Validation loss: 1.4849708875020344

Epoch: 6| Step: 8
Training loss: 0.05092702433466911
Validation loss: 1.4911507688542849

Epoch: 6| Step: 9
Training loss: 0.04170582816004753
Validation loss: 1.4801935201050134

Epoch: 6| Step: 10
Training loss: 0.06951899081468582
Validation loss: 1.4765938353794876

Epoch: 6| Step: 11
Training loss: 0.11002806574106216
Validation loss: 1.4797108096461142

Epoch: 6| Step: 12
Training loss: 0.054387398064136505
Validation loss: 1.4897282905476068

Epoch: 6| Step: 13
Training loss: 0.054602328687906265
Validation loss: 1.4809749575071438

Epoch: 620| Step: 0
Training loss: 0.06191394850611687
Validation loss: 1.4955143120981031

Epoch: 6| Step: 1
Training loss: 0.08892519026994705
Validation loss: 1.4699279287809968

Epoch: 6| Step: 2
Training loss: 0.03249097242951393
Validation loss: 1.4720632337754773

Epoch: 6| Step: 3
Training loss: 0.04038137197494507
Validation loss: 1.4758546608750538

Epoch: 6| Step: 4
Training loss: 0.05671209096908569
Validation loss: 1.4908677506190475

Epoch: 6| Step: 5
Training loss: 0.10743199288845062
Validation loss: 1.4965377789671703

Epoch: 6| Step: 6
Training loss: 0.0345727913081646
Validation loss: 1.4758164446841004

Epoch: 6| Step: 7
Training loss: 0.05053245648741722
Validation loss: 1.4691355753970403

Epoch: 6| Step: 8
Training loss: 0.04530683532357216
Validation loss: 1.4854774257188201

Epoch: 6| Step: 9
Training loss: 0.10161572694778442
Validation loss: 1.4781178261644097

Epoch: 6| Step: 10
Training loss: 0.07091343402862549
Validation loss: 1.4583659479694981

Epoch: 6| Step: 11
Training loss: 0.04034527391195297
Validation loss: 1.4715683857599895

Epoch: 6| Step: 12
Training loss: 0.04073332995176315
Validation loss: 1.4690831476642239

Epoch: 6| Step: 13
Training loss: 0.04834742844104767
Validation loss: 1.4755580694444719

Epoch: 621| Step: 0
Training loss: 0.06153310835361481
Validation loss: 1.4500103374963165

Epoch: 6| Step: 1
Training loss: 0.04391292482614517
Validation loss: 1.4782385915838263

Epoch: 6| Step: 2
Training loss: 0.05942966789007187
Validation loss: 1.4641090259757092

Epoch: 6| Step: 3
Training loss: 0.06660141050815582
Validation loss: 1.461702371156344

Epoch: 6| Step: 4
Training loss: 0.044088058173656464
Validation loss: 1.4673870250742922

Epoch: 6| Step: 5
Training loss: 0.08185087144374847
Validation loss: 1.4806866389448925

Epoch: 6| Step: 6
Training loss: 0.05400652065873146
Validation loss: 1.4830527497876076

Epoch: 6| Step: 7
Training loss: 0.052689533680677414
Validation loss: 1.4701678996445031

Epoch: 6| Step: 8
Training loss: 0.03994603455066681
Validation loss: 1.4705276437985

Epoch: 6| Step: 9
Training loss: 0.03308450058102608
Validation loss: 1.466988242441608

Epoch: 6| Step: 10
Training loss: 0.06731667369604111
Validation loss: 1.4905576013749646

Epoch: 6| Step: 11
Training loss: 0.04106907546520233
Validation loss: 1.458264567518747

Epoch: 6| Step: 12
Training loss: 0.07122749090194702
Validation loss: 1.4659131714092788

Epoch: 6| Step: 13
Training loss: 0.030252285301685333
Validation loss: 1.4897318937445199

Epoch: 622| Step: 0
Training loss: 0.048858266323804855
Validation loss: 1.4871645960756528

Epoch: 6| Step: 1
Training loss: 0.03897371143102646
Validation loss: 1.4947933804604314

Epoch: 6| Step: 2
Training loss: 0.04003293067216873
Validation loss: 1.4953728798897035

Epoch: 6| Step: 3
Training loss: 0.05366230010986328
Validation loss: 1.497868150793096

Epoch: 6| Step: 4
Training loss: 0.05703078955411911
Validation loss: 1.4974746960465626

Epoch: 6| Step: 5
Training loss: 0.04974738135933876
Validation loss: 1.4673148444903794

Epoch: 6| Step: 6
Training loss: 0.06316421180963516
Validation loss: 1.495883801931976

Epoch: 6| Step: 7
Training loss: 0.060619790107011795
Validation loss: 1.4924364269420665

Epoch: 6| Step: 8
Training loss: 0.079011932015419
Validation loss: 1.4878005942990702

Epoch: 6| Step: 9
Training loss: 0.06175459921360016
Validation loss: 1.484109846494531

Epoch: 6| Step: 10
Training loss: 0.07723090797662735
Validation loss: 1.4716652285668157

Epoch: 6| Step: 11
Training loss: 0.042416784912347794
Validation loss: 1.4821677797584123

Epoch: 6| Step: 12
Training loss: 0.03714394569396973
Validation loss: 1.4623136058930428

Epoch: 6| Step: 13
Training loss: 0.07391314953565598
Validation loss: 1.4839485845258158

Epoch: 623| Step: 0
Training loss: 0.045390430837869644
Validation loss: 1.4751565238480926

Epoch: 6| Step: 1
Training loss: 0.07613439857959747
Validation loss: 1.4822544654210408

Epoch: 6| Step: 2
Training loss: 0.05192602425813675
Validation loss: 1.451208047969367

Epoch: 6| Step: 3
Training loss: 0.0554618202149868
Validation loss: 1.4690462914846276

Epoch: 6| Step: 4
Training loss: 0.0751277282834053
Validation loss: 1.4857736146578224

Epoch: 6| Step: 5
Training loss: 0.06475228816270828
Validation loss: 1.501383977551614

Epoch: 6| Step: 6
Training loss: 0.05030173808336258
Validation loss: 1.4775013064825406

Epoch: 6| Step: 7
Training loss: 0.05784815549850464
Validation loss: 1.4876378864370368

Epoch: 6| Step: 8
Training loss: 0.08116651326417923
Validation loss: 1.4824555868743567

Epoch: 6| Step: 9
Training loss: 0.0561584010720253
Validation loss: 1.459415974155549

Epoch: 6| Step: 10
Training loss: 0.0490480437874794
Validation loss: 1.4854238738295853

Epoch: 6| Step: 11
Training loss: 0.03375915437936783
Validation loss: 1.4996936449440577

Epoch: 6| Step: 12
Training loss: 0.06274190545082092
Validation loss: 1.4819901912443099

Epoch: 6| Step: 13
Training loss: 0.020895639434456825
Validation loss: 1.4944204284298805

Epoch: 624| Step: 0
Training loss: 0.06051821634173393
Validation loss: 1.5174885949780863

Epoch: 6| Step: 1
Training loss: 0.09252111613750458
Validation loss: 1.5190452414174234

Epoch: 6| Step: 2
Training loss: 0.07409483194351196
Validation loss: 1.5420790154446837

Epoch: 6| Step: 3
Training loss: 0.05852118134498596
Validation loss: 1.5221745814046552

Epoch: 6| Step: 4
Training loss: 0.06119266152381897
Validation loss: 1.5338199125823153

Epoch: 6| Step: 5
Training loss: 0.051334090530872345
Validation loss: 1.4990118626625306

Epoch: 6| Step: 6
Training loss: 0.0693565160036087
Validation loss: 1.4905929168065388

Epoch: 6| Step: 7
Training loss: 0.07610846310853958
Validation loss: 1.5010591963286042

Epoch: 6| Step: 8
Training loss: 0.0523332878947258
Validation loss: 1.5041515416996454

Epoch: 6| Step: 9
Training loss: 0.05916588380932808
Validation loss: 1.4997323815540602

Epoch: 6| Step: 10
Training loss: 0.05260405316948891
Validation loss: 1.504302692669694

Epoch: 6| Step: 11
Training loss: 0.052613500505685806
Validation loss: 1.5088080590771091

Epoch: 6| Step: 12
Training loss: 0.059312157332897186
Validation loss: 1.5148763759161836

Epoch: 6| Step: 13
Training loss: 0.03582565486431122
Validation loss: 1.523435111968748

Epoch: 625| Step: 0
Training loss: 0.03943043202161789
Validation loss: 1.5201954918522989

Epoch: 6| Step: 1
Training loss: 0.04112626984715462
Validation loss: 1.5013758469653387

Epoch: 6| Step: 2
Training loss: 0.04491787403821945
Validation loss: 1.5127250468859108

Epoch: 6| Step: 3
Training loss: 0.07728033512830734
Validation loss: 1.513727209901297

Epoch: 6| Step: 4
Training loss: 0.07199347764253616
Validation loss: 1.534166182241132

Epoch: 6| Step: 5
Training loss: 0.04088312387466431
Validation loss: 1.5321402549743652

Epoch: 6| Step: 6
Training loss: 0.07505907118320465
Validation loss: 1.5450572121527888

Epoch: 6| Step: 7
Training loss: 0.06764723360538483
Validation loss: 1.530477625067516

Epoch: 6| Step: 8
Training loss: 0.07643106579780579
Validation loss: 1.50979249259477

Epoch: 6| Step: 9
Training loss: 0.1052122712135315
Validation loss: 1.4982613107209564

Epoch: 6| Step: 10
Training loss: 0.0437530092895031
Validation loss: 1.491983272696054

Epoch: 6| Step: 11
Training loss: 0.04333522170782089
Validation loss: 1.4575910978419806

Epoch: 6| Step: 12
Training loss: 0.05669069662690163
Validation loss: 1.4969168016987462

Epoch: 6| Step: 13
Training loss: 0.04753205552697182
Validation loss: 1.4991236373942385

Epoch: 626| Step: 0
Training loss: 0.06119496375322342
Validation loss: 1.4875704498701199

Epoch: 6| Step: 1
Training loss: 0.03750843554735184
Validation loss: 1.4946076395691081

Epoch: 6| Step: 2
Training loss: 0.05409795790910721
Validation loss: 1.475423127092341

Epoch: 6| Step: 3
Training loss: 0.04456484690308571
Validation loss: 1.4844903202467068

Epoch: 6| Step: 4
Training loss: 0.02282584086060524
Validation loss: 1.499245729497684

Epoch: 6| Step: 5
Training loss: 0.0590391606092453
Validation loss: 1.4800459723318777

Epoch: 6| Step: 6
Training loss: 0.05010157823562622
Validation loss: 1.5034721570630227

Epoch: 6| Step: 7
Training loss: 0.057878829538822174
Validation loss: 1.4921326432176816

Epoch: 6| Step: 8
Training loss: 0.0699416920542717
Validation loss: 1.4989201035550845

Epoch: 6| Step: 9
Training loss: 0.06937148422002792
Validation loss: 1.5122408315699587

Epoch: 6| Step: 10
Training loss: 0.08536523580551147
Validation loss: 1.5122545098745694

Epoch: 6| Step: 11
Training loss: 0.05069449543952942
Validation loss: 1.4894129806949246

Epoch: 6| Step: 12
Training loss: 0.04330340027809143
Validation loss: 1.4700563466677101

Epoch: 6| Step: 13
Training loss: 0.08563277125358582
Validation loss: 1.4850746559840378

Epoch: 627| Step: 0
Training loss: 0.050476014614105225
Validation loss: 1.4720307396304222

Epoch: 6| Step: 1
Training loss: 0.05401352792978287
Validation loss: 1.4920924966053297

Epoch: 6| Step: 2
Training loss: 0.057389404624700546
Validation loss: 1.4939954562853741

Epoch: 6| Step: 3
Training loss: 0.07788881659507751
Validation loss: 1.4782788753509521

Epoch: 6| Step: 4
Training loss: 0.051314033567905426
Validation loss: 1.4690866803610196

Epoch: 6| Step: 5
Training loss: 0.06264787167310715
Validation loss: 1.467804261433181

Epoch: 6| Step: 6
Training loss: 0.07178403437137604
Validation loss: 1.4484279745368547

Epoch: 6| Step: 7
Training loss: 0.0764801949262619
Validation loss: 1.459914468949841

Epoch: 6| Step: 8
Training loss: 0.06716331839561462
Validation loss: 1.4648794922777402

Epoch: 6| Step: 9
Training loss: 0.08285868912935257
Validation loss: 1.4548475178339149

Epoch: 6| Step: 10
Training loss: 0.07821714133024216
Validation loss: 1.461723034099866

Epoch: 6| Step: 11
Training loss: 0.07165397703647614
Validation loss: 1.4873455045043782

Epoch: 6| Step: 12
Training loss: 0.06915352493524551
Validation loss: 1.4761560117044756

Epoch: 6| Step: 13
Training loss: 0.13607649505138397
Validation loss: 1.472408554887259

Epoch: 628| Step: 0
Training loss: 0.0645967647433281
Validation loss: 1.5063292595647997

Epoch: 6| Step: 1
Training loss: 0.05368998646736145
Validation loss: 1.4824504570294452

Epoch: 6| Step: 2
Training loss: 0.04599051922559738
Validation loss: 1.5026853674201555

Epoch: 6| Step: 3
Training loss: 0.046899713575839996
Validation loss: 1.5034093741447694

Epoch: 6| Step: 4
Training loss: 0.07078419625759125
Validation loss: 1.4936396434742918

Epoch: 6| Step: 5
Training loss: 0.051249343901872635
Validation loss: 1.4905660511344991

Epoch: 6| Step: 6
Training loss: 0.05862390995025635
Validation loss: 1.500956485348363

Epoch: 6| Step: 7
Training loss: 0.06676997244358063
Validation loss: 1.4847495581514092

Epoch: 6| Step: 8
Training loss: 0.05549434944987297
Validation loss: 1.4791115791566911

Epoch: 6| Step: 9
Training loss: 0.034071147441864014
Validation loss: 1.476028867947158

Epoch: 6| Step: 10
Training loss: 0.07588443905115128
Validation loss: 1.485564080617761

Epoch: 6| Step: 11
Training loss: 0.06649697571992874
Validation loss: 1.476269498948128

Epoch: 6| Step: 12
Training loss: 0.07642798125743866
Validation loss: 1.4745411360135643

Epoch: 6| Step: 13
Training loss: 0.08409661799669266
Validation loss: 1.4633591828807708

Epoch: 629| Step: 0
Training loss: 0.07146403938531876
Validation loss: 1.4937875437480148

Epoch: 6| Step: 1
Training loss: 0.08246055990457535
Validation loss: 1.5125691711261708

Epoch: 6| Step: 2
Training loss: 0.06984378397464752
Validation loss: 1.4916827627407607

Epoch: 6| Step: 3
Training loss: 0.05535995960235596
Validation loss: 1.516803067217591

Epoch: 6| Step: 4
Training loss: 0.04795679450035095
Validation loss: 1.4855061702189907

Epoch: 6| Step: 5
Training loss: 0.08041902631521225
Validation loss: 1.4833515818401048

Epoch: 6| Step: 6
Training loss: 0.04572867974638939
Validation loss: 1.4603909382256128

Epoch: 6| Step: 7
Training loss: 0.07958337664604187
Validation loss: 1.4611888470188263

Epoch: 6| Step: 8
Training loss: 0.042143628001213074
Validation loss: 1.4875850395489765

Epoch: 6| Step: 9
Training loss: 0.0451810285449028
Validation loss: 1.4981593188419138

Epoch: 6| Step: 10
Training loss: 0.06368554383516312
Validation loss: 1.4729846472381263

Epoch: 6| Step: 11
Training loss: 0.06872247159481049
Validation loss: 1.4847884344798263

Epoch: 6| Step: 12
Training loss: 0.05691084265708923
Validation loss: 1.5118651518257715

Epoch: 6| Step: 13
Training loss: 0.06612624228000641
Validation loss: 1.484617442213079

Epoch: 630| Step: 0
Training loss: 0.04186432063579559
Validation loss: 1.4771582029199088

Epoch: 6| Step: 1
Training loss: 0.04906586557626724
Validation loss: 1.4885949357863395

Epoch: 6| Step: 2
Training loss: 0.044406674802303314
Validation loss: 1.483489562747299

Epoch: 6| Step: 3
Training loss: 0.09530588239431381
Validation loss: 1.4844290825628466

Epoch: 6| Step: 4
Training loss: 0.07017287611961365
Validation loss: 1.512988785261749

Epoch: 6| Step: 5
Training loss: 0.0594492070376873
Validation loss: 1.5022860047637776

Epoch: 6| Step: 6
Training loss: 0.06633380800485611
Validation loss: 1.5047619047985281

Epoch: 6| Step: 7
Training loss: 0.04783986508846283
Validation loss: 1.5372535528675202

Epoch: 6| Step: 8
Training loss: 0.04235578700900078
Validation loss: 1.5264172054106189

Epoch: 6| Step: 9
Training loss: 0.08913235366344452
Validation loss: 1.5335921754119217

Epoch: 6| Step: 10
Training loss: 0.06114809960126877
Validation loss: 1.5424552271443028

Epoch: 6| Step: 11
Training loss: 0.03708811104297638
Validation loss: 1.5521769228801932

Epoch: 6| Step: 12
Training loss: 0.07819774001836777
Validation loss: 1.510906074636726

Epoch: 6| Step: 13
Training loss: 0.06993130594491959
Validation loss: 1.5197317049067507

Epoch: 631| Step: 0
Training loss: 0.08819225430488586
Validation loss: 1.5070471379064745

Epoch: 6| Step: 1
Training loss: 0.06383536010980606
Validation loss: 1.504852956341159

Epoch: 6| Step: 2
Training loss: 0.0675809234380722
Validation loss: 1.495888392130534

Epoch: 6| Step: 3
Training loss: 0.04735998064279556
Validation loss: 1.490833487561954

Epoch: 6| Step: 4
Training loss: 0.0644419863820076
Validation loss: 1.5159478187561035

Epoch: 6| Step: 5
Training loss: 0.049848612397909164
Validation loss: 1.5093737443288167

Epoch: 6| Step: 6
Training loss: 0.0678662657737732
Validation loss: 1.5000841732948058

Epoch: 6| Step: 7
Training loss: 0.0518350824713707
Validation loss: 1.50289128352237

Epoch: 6| Step: 8
Training loss: 0.08987738937139511
Validation loss: 1.5335290534521944

Epoch: 6| Step: 9
Training loss: 0.09909050166606903
Validation loss: 1.5381734025093816

Epoch: 6| Step: 10
Training loss: 0.054321832954883575
Validation loss: 1.51238166516827

Epoch: 6| Step: 11
Training loss: 0.07388812303543091
Validation loss: 1.5108306305382841

Epoch: 6| Step: 12
Training loss: 0.1075175330042839
Validation loss: 1.5205533786486554

Epoch: 6| Step: 13
Training loss: 0.09824873507022858
Validation loss: 1.5101988648855558

Epoch: 632| Step: 0
Training loss: 0.07204149663448334
Validation loss: 1.5009242821765203

Epoch: 6| Step: 1
Training loss: 0.03824113681912422
Validation loss: 1.5378475253300001

Epoch: 6| Step: 2
Training loss: 0.0727689266204834
Validation loss: 1.544878250809126

Epoch: 6| Step: 3
Training loss: 0.07897542417049408
Validation loss: 1.5556107246747581

Epoch: 6| Step: 4
Training loss: 0.1433461606502533
Validation loss: 1.5581539548853391

Epoch: 6| Step: 5
Training loss: 0.07734730839729309
Validation loss: 1.5702537067474858

Epoch: 6| Step: 6
Training loss: 0.0892740935087204
Validation loss: 1.5758789495755268

Epoch: 6| Step: 7
Training loss: 0.07978561520576477
Validation loss: 1.5723460810158842

Epoch: 6| Step: 8
Training loss: 0.04611331224441528
Validation loss: 1.5424297432745657

Epoch: 6| Step: 9
Training loss: 0.04910485818982124
Validation loss: 1.5310303344521472

Epoch: 6| Step: 10
Training loss: 0.05657046288251877
Validation loss: 1.5295515342425274

Epoch: 6| Step: 11
Training loss: 0.13422074913978577
Validation loss: 1.5072869575151833

Epoch: 6| Step: 12
Training loss: 0.050537534058094025
Validation loss: 1.5071570834805887

Epoch: 6| Step: 13
Training loss: 0.11850503087043762
Validation loss: 1.5194324729263142

Epoch: 633| Step: 0
Training loss: 0.06240997463464737
Validation loss: 1.536362373700706

Epoch: 6| Step: 1
Training loss: 0.055430442094802856
Validation loss: 1.5162625261532363

Epoch: 6| Step: 2
Training loss: 0.06185761094093323
Validation loss: 1.5540401345940047

Epoch: 6| Step: 3
Training loss: 0.0781915932893753
Validation loss: 1.5835769355937999

Epoch: 6| Step: 4
Training loss: 0.05934622883796692
Validation loss: 1.560677396353855

Epoch: 6| Step: 5
Training loss: 0.08143915235996246
Validation loss: 1.5462037696633288

Epoch: 6| Step: 6
Training loss: 0.051230303943157196
Validation loss: 1.5141399893709409

Epoch: 6| Step: 7
Training loss: 0.05968480557203293
Validation loss: 1.5029090194291965

Epoch: 6| Step: 8
Training loss: 0.053881943225860596
Validation loss: 1.50699056220311

Epoch: 6| Step: 9
Training loss: 0.08725504577159882
Validation loss: 1.4876556428529883

Epoch: 6| Step: 10
Training loss: 0.05959731340408325
Validation loss: 1.4949173440215409

Epoch: 6| Step: 11
Training loss: 0.07274319231510162
Validation loss: 1.5035385367690877

Epoch: 6| Step: 12
Training loss: 0.043497033417224884
Validation loss: 1.5005903923383324

Epoch: 6| Step: 13
Training loss: 0.03994029015302658
Validation loss: 1.4962007717419696

Epoch: 634| Step: 0
Training loss: 0.038376420736312866
Validation loss: 1.4763621514843357

Epoch: 6| Step: 1
Training loss: 0.063124880194664
Validation loss: 1.5296730046631188

Epoch: 6| Step: 2
Training loss: 0.05683384835720062
Validation loss: 1.5205866188131354

Epoch: 6| Step: 3
Training loss: 0.09803251922130585
Validation loss: 1.5457101060498146

Epoch: 6| Step: 4
Training loss: 0.15786422789096832
Validation loss: 1.5550148820364347

Epoch: 6| Step: 5
Training loss: 0.09028425812721252
Validation loss: 1.5311347355124771

Epoch: 6| Step: 6
Training loss: 0.07931114733219147
Validation loss: 1.529139511046871

Epoch: 6| Step: 7
Training loss: 0.0459904670715332
Validation loss: 1.5006877119823168

Epoch: 6| Step: 8
Training loss: 0.07565639913082123
Validation loss: 1.4925555529132966

Epoch: 6| Step: 9
Training loss: 0.055707089602947235
Validation loss: 1.4818886185205111

Epoch: 6| Step: 10
Training loss: 0.04557611793279648
Validation loss: 1.4789251999188495

Epoch: 6| Step: 11
Training loss: 0.05467813089489937
Validation loss: 1.4712266563087382

Epoch: 6| Step: 12
Training loss: 0.06414289772510529
Validation loss: 1.481551392104036

Epoch: 6| Step: 13
Training loss: 0.09948709607124329
Validation loss: 1.492074114661063

Epoch: 635| Step: 0
Training loss: 0.041241809725761414
Validation loss: 1.5099158107593496

Epoch: 6| Step: 1
Training loss: 0.0640430673956871
Validation loss: 1.4894769166105537

Epoch: 6| Step: 2
Training loss: 0.034438759088516235
Validation loss: 1.490108589972219

Epoch: 6| Step: 3
Training loss: 0.03904922306537628
Validation loss: 1.5122447629128732

Epoch: 6| Step: 4
Training loss: 0.04752149432897568
Validation loss: 1.4988748488887664

Epoch: 6| Step: 5
Training loss: 0.08012046664953232
Validation loss: 1.5142920837607434

Epoch: 6| Step: 6
Training loss: 0.08578966557979584
Validation loss: 1.4946357011795044

Epoch: 6| Step: 7
Training loss: 0.024547602981328964
Validation loss: 1.460156702226208

Epoch: 6| Step: 8
Training loss: 0.06457268446683884
Validation loss: 1.5019812481377715

Epoch: 6| Step: 9
Training loss: 0.07111264765262604
Validation loss: 1.4703125633219236

Epoch: 6| Step: 10
Training loss: 0.05718221515417099
Validation loss: 1.4713795108179892

Epoch: 6| Step: 11
Training loss: 0.04876265674829483
Validation loss: 1.4766145175503147

Epoch: 6| Step: 12
Training loss: 0.0867975726723671
Validation loss: 1.4909065154290968

Epoch: 6| Step: 13
Training loss: 0.04089069738984108
Validation loss: 1.4883884909332439

Epoch: 636| Step: 0
Training loss: 0.10234150290489197
Validation loss: 1.5001195258991693

Epoch: 6| Step: 1
Training loss: 0.0582704171538353
Validation loss: 1.4910976092020671

Epoch: 6| Step: 2
Training loss: 0.050642311573028564
Validation loss: 1.4805622741740236

Epoch: 6| Step: 3
Training loss: 0.06299646943807602
Validation loss: 1.49350191444479

Epoch: 6| Step: 4
Training loss: 0.06439736485481262
Validation loss: 1.5062976409030218

Epoch: 6| Step: 5
Training loss: 0.060167063027620316
Validation loss: 1.5006674822940622

Epoch: 6| Step: 6
Training loss: 0.06612631678581238
Validation loss: 1.5426985973952918

Epoch: 6| Step: 7
Training loss: 0.041920192539691925
Validation loss: 1.552278063630545

Epoch: 6| Step: 8
Training loss: 0.08097224682569504
Validation loss: 1.5598930697287283

Epoch: 6| Step: 9
Training loss: 0.09320475161075592
Validation loss: 1.521384016160042

Epoch: 6| Step: 10
Training loss: 0.05870354175567627
Validation loss: 1.5376837029252002

Epoch: 6| Step: 11
Training loss: 0.031495288014411926
Validation loss: 1.4985189989048948

Epoch: 6| Step: 12
Training loss: 0.045114628970623016
Validation loss: 1.4968698793841946

Epoch: 6| Step: 13
Training loss: 0.030900053679943085
Validation loss: 1.5020738314556819

Epoch: 637| Step: 0
Training loss: 0.06437478959560394
Validation loss: 1.5105219297511603

Epoch: 6| Step: 1
Training loss: 0.0631699487566948
Validation loss: 1.507884778002257

Epoch: 6| Step: 2
Training loss: 0.03517311066389084
Validation loss: 1.5163675815828386

Epoch: 6| Step: 3
Training loss: 0.05271861329674721
Validation loss: 1.502254319447343

Epoch: 6| Step: 4
Training loss: 0.08681241422891617
Validation loss: 1.495711721399779

Epoch: 6| Step: 5
Training loss: 0.050308916717767715
Validation loss: 1.544017214928904

Epoch: 6| Step: 6
Training loss: 0.06310436129570007
Validation loss: 1.5198060633033834

Epoch: 6| Step: 7
Training loss: 0.07217450439929962
Validation loss: 1.544104628665473

Epoch: 6| Step: 8
Training loss: 0.0870223194360733
Validation loss: 1.5244417741734495

Epoch: 6| Step: 9
Training loss: 0.07692767679691315
Validation loss: 1.5174117319045528

Epoch: 6| Step: 10
Training loss: 0.09232188761234283
Validation loss: 1.5275865088226974

Epoch: 6| Step: 11
Training loss: 0.06107405200600624
Validation loss: 1.518668092707152

Epoch: 6| Step: 12
Training loss: 0.07157430052757263
Validation loss: 1.5198804601546256

Epoch: 6| Step: 13
Training loss: 0.061638157814741135
Validation loss: 1.5255662882199852

Epoch: 638| Step: 0
Training loss: 0.0754520446062088
Validation loss: 1.526280508246473

Epoch: 6| Step: 1
Training loss: 0.04258522391319275
Validation loss: 1.5156838804162958

Epoch: 6| Step: 2
Training loss: 0.060781482607126236
Validation loss: 1.505916883868556

Epoch: 6| Step: 3
Training loss: 0.04692825302481651
Validation loss: 1.536691991872685

Epoch: 6| Step: 4
Training loss: 0.042926810681819916
Validation loss: 1.519441980187611

Epoch: 6| Step: 5
Training loss: 0.04302157834172249
Validation loss: 1.525220210834216

Epoch: 6| Step: 6
Training loss: 0.04586204141378403
Validation loss: 1.5223793752731816

Epoch: 6| Step: 7
Training loss: 0.044595375657081604
Validation loss: 1.515896535688831

Epoch: 6| Step: 8
Training loss: 0.048737410455942154
Validation loss: 1.5028190638429375

Epoch: 6| Step: 9
Training loss: 0.08232928067445755
Validation loss: 1.5105701223496468

Epoch: 6| Step: 10
Training loss: 0.08203902095556259
Validation loss: 1.526983102162679

Epoch: 6| Step: 11
Training loss: 0.0964459553360939
Validation loss: 1.5352668082842262

Epoch: 6| Step: 12
Training loss: 0.047302234917879105
Validation loss: 1.5285187049578595

Epoch: 6| Step: 13
Training loss: 0.037669818848371506
Validation loss: 1.5101820589393697

Epoch: 639| Step: 0
Training loss: 0.06149296462535858
Validation loss: 1.5018483579799693

Epoch: 6| Step: 1
Training loss: 0.04568205773830414
Validation loss: 1.497342501917193

Epoch: 6| Step: 2
Training loss: 0.03495185077190399
Validation loss: 1.492029031117757

Epoch: 6| Step: 3
Training loss: 0.04121847450733185
Validation loss: 1.4916592797925394

Epoch: 6| Step: 4
Training loss: 0.026390809565782547
Validation loss: 1.5046179179222352

Epoch: 6| Step: 5
Training loss: 0.06593848019838333
Validation loss: 1.4880008441145702

Epoch: 6| Step: 6
Training loss: 0.0782284364104271
Validation loss: 1.4777039725293395

Epoch: 6| Step: 7
Training loss: 0.03843910992145538
Validation loss: 1.491992360802107

Epoch: 6| Step: 8
Training loss: 0.0556970089673996
Validation loss: 1.488298987829557

Epoch: 6| Step: 9
Training loss: 0.0526704341173172
Validation loss: 1.5009571634313112

Epoch: 6| Step: 10
Training loss: 0.059507399797439575
Validation loss: 1.4762778942302992

Epoch: 6| Step: 11
Training loss: 0.03523772954940796
Validation loss: 1.465727508708995

Epoch: 6| Step: 12
Training loss: 0.06236255168914795
Validation loss: 1.4861164926200785

Epoch: 6| Step: 13
Training loss: 0.06324818730354309
Validation loss: 1.4810254086730301

Epoch: 640| Step: 0
Training loss: 0.04642556607723236
Validation loss: 1.4971252410642562

Epoch: 6| Step: 1
Training loss: 0.05667964741587639
Validation loss: 1.4859301890096357

Epoch: 6| Step: 2
Training loss: 0.07500073313713074
Validation loss: 1.475596550972231

Epoch: 6| Step: 3
Training loss: 0.06379295885562897
Validation loss: 1.477498713360038

Epoch: 6| Step: 4
Training loss: 0.06143226847052574
Validation loss: 1.4827572120133268

Epoch: 6| Step: 5
Training loss: 0.04967263340950012
Validation loss: 1.489310811924678

Epoch: 6| Step: 6
Training loss: 0.05164892226457596
Validation loss: 1.4824168271915887

Epoch: 6| Step: 7
Training loss: 0.05258990079164505
Validation loss: 1.501671919258692

Epoch: 6| Step: 8
Training loss: 0.05308549106121063
Validation loss: 1.505554776037893

Epoch: 6| Step: 9
Training loss: 0.057715773582458496
Validation loss: 1.5229588298387424

Epoch: 6| Step: 10
Training loss: 0.09209589660167694
Validation loss: 1.5118309579869753

Epoch: 6| Step: 11
Training loss: 0.029733285307884216
Validation loss: 1.5317776267246535

Epoch: 6| Step: 12
Training loss: 0.050883278250694275
Validation loss: 1.535323053277949

Epoch: 6| Step: 13
Training loss: 0.030731849372386932
Validation loss: 1.5309205023191308

Epoch: 641| Step: 0
Training loss: 0.043371982872486115
Validation loss: 1.542841629315448

Epoch: 6| Step: 1
Training loss: 0.07906771451234818
Validation loss: 1.542201006284324

Epoch: 6| Step: 2
Training loss: 0.06067630276083946
Validation loss: 1.541639547194204

Epoch: 6| Step: 3
Training loss: 0.058398548513650894
Validation loss: 1.5464767166363296

Epoch: 6| Step: 4
Training loss: 0.05031808465719223
Validation loss: 1.5344622327435402

Epoch: 6| Step: 5
Training loss: 0.040105585008859634
Validation loss: 1.5496420885926934

Epoch: 6| Step: 6
Training loss: 0.045594945549964905
Validation loss: 1.567850023187617

Epoch: 6| Step: 7
Training loss: 0.05085868760943413
Validation loss: 1.544663054968721

Epoch: 6| Step: 8
Training loss: 0.03511979803442955
Validation loss: 1.5437642528164772

Epoch: 6| Step: 9
Training loss: 0.03246670961380005
Validation loss: 1.5535208999469716

Epoch: 6| Step: 10
Training loss: 0.06838349997997284
Validation loss: 1.5557565817268946

Epoch: 6| Step: 11
Training loss: 0.04610031843185425
Validation loss: 1.5488229310640724

Epoch: 6| Step: 12
Training loss: 0.09500430524349213
Validation loss: 1.5554211165315361

Epoch: 6| Step: 13
Training loss: 0.10036835074424744
Validation loss: 1.5200059131909442

Epoch: 642| Step: 0
Training loss: 0.08751698583364487
Validation loss: 1.513242877939696

Epoch: 6| Step: 1
Training loss: 0.04959258437156677
Validation loss: 1.5307951306784024

Epoch: 6| Step: 2
Training loss: 0.08858878910541534
Validation loss: 1.508742655477216

Epoch: 6| Step: 3
Training loss: 0.05146832391619682
Validation loss: 1.4981451739547074

Epoch: 6| Step: 4
Training loss: 0.04931744560599327
Validation loss: 1.4910886582507883

Epoch: 6| Step: 5
Training loss: 0.04719164967536926
Validation loss: 1.4956989442148516

Epoch: 6| Step: 6
Training loss: 0.06158004701137543
Validation loss: 1.488357783645712

Epoch: 6| Step: 7
Training loss: 0.09447748214006424
Validation loss: 1.4792351927808536

Epoch: 6| Step: 8
Training loss: 0.04333748295903206
Validation loss: 1.4903097203982774

Epoch: 6| Step: 9
Training loss: 0.11533617228269577
Validation loss: 1.5060881363448275

Epoch: 6| Step: 10
Training loss: 0.05198086053133011
Validation loss: 1.4893635101215814

Epoch: 6| Step: 11
Training loss: 0.05649230256676674
Validation loss: 1.5031327137383081

Epoch: 6| Step: 12
Training loss: 0.04433050751686096
Validation loss: 1.5101818307753532

Epoch: 6| Step: 13
Training loss: 0.10099051892757416
Validation loss: 1.5200033969776605

Epoch: 643| Step: 0
Training loss: 0.04592573642730713
Validation loss: 1.5122736705246793

Epoch: 6| Step: 1
Training loss: 0.05874871090054512
Validation loss: 1.4998402582701815

Epoch: 6| Step: 2
Training loss: 0.06641994416713715
Validation loss: 1.51896757207891

Epoch: 6| Step: 3
Training loss: 0.07632631063461304
Validation loss: 1.5066402605784837

Epoch: 6| Step: 4
Training loss: 0.06323517113924026
Validation loss: 1.5117249834922053

Epoch: 6| Step: 5
Training loss: 0.06385472416877747
Validation loss: 1.486958138404354

Epoch: 6| Step: 6
Training loss: 0.06863083690404892
Validation loss: 1.5198213477288522

Epoch: 6| Step: 7
Training loss: 0.07933379709720612
Validation loss: 1.4990655029973676

Epoch: 6| Step: 8
Training loss: 0.08305957168340683
Validation loss: 1.4968793725454679

Epoch: 6| Step: 9
Training loss: 0.04473751783370972
Validation loss: 1.5047635891104256

Epoch: 6| Step: 10
Training loss: 0.05434197559952736
Validation loss: 1.4972733477110505

Epoch: 6| Step: 11
Training loss: 0.035726398229599
Validation loss: 1.503071290190502

Epoch: 6| Step: 12
Training loss: 0.02627040073275566
Validation loss: 1.4972476497773202

Epoch: 6| Step: 13
Training loss: 0.08294650912284851
Validation loss: 1.4994908609697897

Epoch: 644| Step: 0
Training loss: 0.07513013482093811
Validation loss: 1.533916683607204

Epoch: 6| Step: 1
Training loss: 0.08045491576194763
Validation loss: 1.524100362613637

Epoch: 6| Step: 2
Training loss: 0.05355684459209442
Validation loss: 1.5128113383887916

Epoch: 6| Step: 3
Training loss: 0.052320051938295364
Validation loss: 1.541482420377834

Epoch: 6| Step: 4
Training loss: 0.030715977773070335
Validation loss: 1.5170414909239738

Epoch: 6| Step: 5
Training loss: 0.11742933839559555
Validation loss: 1.5265841093114627

Epoch: 6| Step: 6
Training loss: 0.04588330537080765
Validation loss: 1.5113670723412627

Epoch: 6| Step: 7
Training loss: 0.04573189839720726
Validation loss: 1.5422665496026315

Epoch: 6| Step: 8
Training loss: 0.034235693514347076
Validation loss: 1.4881106576611918

Epoch: 6| Step: 9
Training loss: 0.10248817503452301
Validation loss: 1.4805755551143358

Epoch: 6| Step: 10
Training loss: 0.04787013679742813
Validation loss: 1.491006826841703

Epoch: 6| Step: 11
Training loss: 0.07190115004777908
Validation loss: 1.519303862766553

Epoch: 6| Step: 12
Training loss: 0.04367726296186447
Validation loss: 1.485208026824459

Epoch: 6| Step: 13
Training loss: 0.033884115517139435
Validation loss: 1.4801353382807907

Epoch: 645| Step: 0
Training loss: 0.047695472836494446
Validation loss: 1.4818190720773512

Epoch: 6| Step: 1
Training loss: 0.07286874949932098
Validation loss: 1.4950309261198966

Epoch: 6| Step: 2
Training loss: 0.033931929618120193
Validation loss: 1.4940749611905826

Epoch: 6| Step: 3
Training loss: 0.06290315091609955
Validation loss: 1.500145403287744

Epoch: 6| Step: 4
Training loss: 0.04624504595994949
Validation loss: 1.521644087247951

Epoch: 6| Step: 5
Training loss: 0.04877438396215439
Validation loss: 1.5041097569209274

Epoch: 6| Step: 6
Training loss: 0.042609795928001404
Validation loss: 1.5121796092679423

Epoch: 6| Step: 7
Training loss: 0.04332137480378151
Validation loss: 1.499698046715029

Epoch: 6| Step: 8
Training loss: 0.04255633428692818
Validation loss: 1.499473653172934

Epoch: 6| Step: 9
Training loss: 0.1006421148777008
Validation loss: 1.5218703990341516

Epoch: 6| Step: 10
Training loss: 0.05362458527088165
Validation loss: 1.5186043606009534

Epoch: 6| Step: 11
Training loss: 0.039504602551460266
Validation loss: 1.5235134645174908

Epoch: 6| Step: 12
Training loss: 0.04980728402733803
Validation loss: 1.5211841290996921

Epoch: 6| Step: 13
Training loss: 0.02192961424589157
Validation loss: 1.5388086611224758

Epoch: 646| Step: 0
Training loss: 0.04635438323020935
Validation loss: 1.5254564791597345

Epoch: 6| Step: 1
Training loss: 0.0725594013929367
Validation loss: 1.50198814048562

Epoch: 6| Step: 2
Training loss: 0.023866690695285797
Validation loss: 1.5060570047747703

Epoch: 6| Step: 3
Training loss: 0.04339104890823364
Validation loss: 1.5225702613912604

Epoch: 6| Step: 4
Training loss: 0.06067271530628204
Validation loss: 1.5144988093324887

Epoch: 6| Step: 5
Training loss: 0.03334573656320572
Validation loss: 1.506948196759788

Epoch: 6| Step: 6
Training loss: 0.06421677768230438
Validation loss: 1.5170076239493586

Epoch: 6| Step: 7
Training loss: 0.06583002954721451
Validation loss: 1.520067811012268

Epoch: 6| Step: 8
Training loss: 0.025632735341787338
Validation loss: 1.5267659464190084

Epoch: 6| Step: 9
Training loss: 0.03834196925163269
Validation loss: 1.5141160372764833

Epoch: 6| Step: 10
Training loss: 0.06834831833839417
Validation loss: 1.5123481186487342

Epoch: 6| Step: 11
Training loss: 0.04338609427213669
Validation loss: 1.5366305766567108

Epoch: 6| Step: 12
Training loss: 0.055105362087488174
Validation loss: 1.5321194894852177

Epoch: 6| Step: 13
Training loss: 0.06513288617134094
Validation loss: 1.510506191561299

Epoch: 647| Step: 0
Training loss: 0.02725677564740181
Validation loss: 1.5314750697023125

Epoch: 6| Step: 1
Training loss: 0.05255874618887901
Validation loss: 1.5083397319239955

Epoch: 6| Step: 2
Training loss: 0.04747266694903374
Validation loss: 1.5339867645694363

Epoch: 6| Step: 3
Training loss: 0.03382767736911774
Validation loss: 1.5205219894327142

Epoch: 6| Step: 4
Training loss: 0.03648418188095093
Validation loss: 1.5256943587333924

Epoch: 6| Step: 5
Training loss: 0.054507169872522354
Validation loss: 1.4924694325334282

Epoch: 6| Step: 6
Training loss: 0.10078743100166321
Validation loss: 1.5167771154834377

Epoch: 6| Step: 7
Training loss: 0.050619401037693024
Validation loss: 1.5185623732946252

Epoch: 6| Step: 8
Training loss: 0.09467390924692154
Validation loss: 1.477793014177712

Epoch: 6| Step: 9
Training loss: 0.055772073566913605
Validation loss: 1.5195062365583194

Epoch: 6| Step: 10
Training loss: 0.06457558274269104
Validation loss: 1.4988239196039015

Epoch: 6| Step: 11
Training loss: 0.044172972440719604
Validation loss: 1.5174729106246785

Epoch: 6| Step: 12
Training loss: 0.06853869557380676
Validation loss: 1.5085266123535812

Epoch: 6| Step: 13
Training loss: 0.03835828974843025
Validation loss: 1.5032981723867438

Epoch: 648| Step: 0
Training loss: 0.05478552728891373
Validation loss: 1.5307793078884002

Epoch: 6| Step: 1
Training loss: 0.039852872490882874
Validation loss: 1.507466225213902

Epoch: 6| Step: 2
Training loss: 0.09680716693401337
Validation loss: 1.5276741558505642

Epoch: 6| Step: 3
Training loss: 0.05691375583410263
Validation loss: 1.5042749399779944

Epoch: 6| Step: 4
Training loss: 0.062412410974502563
Validation loss: 1.4796069501548685

Epoch: 6| Step: 5
Training loss: 0.05471517890691757
Validation loss: 1.4948879896953542

Epoch: 6| Step: 6
Training loss: 0.06723615527153015
Validation loss: 1.4913870775571434

Epoch: 6| Step: 7
Training loss: 0.07521210610866547
Validation loss: 1.4918824876508405

Epoch: 6| Step: 8
Training loss: 0.05583842098712921
Validation loss: 1.498971152049239

Epoch: 6| Step: 9
Training loss: 0.07357849180698395
Validation loss: 1.493529535108997

Epoch: 6| Step: 10
Training loss: 0.022169126197695732
Validation loss: 1.4670316442366569

Epoch: 6| Step: 11
Training loss: 0.0686025470495224
Validation loss: 1.4985119995250498

Epoch: 6| Step: 12
Training loss: 0.04145544767379761
Validation loss: 1.4872947251924904

Epoch: 6| Step: 13
Training loss: 0.03273702412843704
Validation loss: 1.4932414588107858

Epoch: 649| Step: 0
Training loss: 0.024720873683691025
Validation loss: 1.455179310614063

Epoch: 6| Step: 1
Training loss: 0.032170794904232025
Validation loss: 1.4880483855483353

Epoch: 6| Step: 2
Training loss: 0.0920453816652298
Validation loss: 1.4882896971958939

Epoch: 6| Step: 3
Training loss: 0.036757491528987885
Validation loss: 1.4764972233003186

Epoch: 6| Step: 4
Training loss: 0.04642818495631218
Validation loss: 1.466786866546959

Epoch: 6| Step: 5
Training loss: 0.06010047346353531
Validation loss: 1.476888777107321

Epoch: 6| Step: 6
Training loss: 0.0875149667263031
Validation loss: 1.4798812212482575

Epoch: 6| Step: 7
Training loss: 0.05970537289977074
Validation loss: 1.4771128482716058

Epoch: 6| Step: 8
Training loss: 0.06498722732067108
Validation loss: 1.4860818514259913

Epoch: 6| Step: 9
Training loss: 0.056392040103673935
Validation loss: 1.4728278633086913

Epoch: 6| Step: 10
Training loss: 0.10592643916606903
Validation loss: 1.4664176715317594

Epoch: 6| Step: 11
Training loss: 0.0682571679353714
Validation loss: 1.4750779956899664

Epoch: 6| Step: 12
Training loss: 0.04549524933099747
Validation loss: 1.489638239465734

Epoch: 6| Step: 13
Training loss: 0.10555240511894226
Validation loss: 1.4945504588465537

Epoch: 650| Step: 0
Training loss: 0.06992340087890625
Validation loss: 1.5145832684732252

Epoch: 6| Step: 1
Training loss: 0.06811051070690155
Validation loss: 1.507362469550102

Epoch: 6| Step: 2
Training loss: 0.06986485421657562
Validation loss: 1.4917422750944733

Epoch: 6| Step: 3
Training loss: 0.04100529104471207
Validation loss: 1.4993431081054032

Epoch: 6| Step: 4
Training loss: 0.08649216592311859
Validation loss: 1.5293225806246522

Epoch: 6| Step: 5
Training loss: 0.06729969382286072
Validation loss: 1.4762832862074657

Epoch: 6| Step: 6
Training loss: 0.03990770876407623
Validation loss: 1.4847718464430941

Epoch: 6| Step: 7
Training loss: 0.05852700024843216
Validation loss: 1.495190942159263

Epoch: 6| Step: 8
Training loss: 0.09225408732891083
Validation loss: 1.4951899705394622

Epoch: 6| Step: 9
Training loss: 0.06440860778093338
Validation loss: 1.4682053237833002

Epoch: 6| Step: 10
Training loss: 0.04251094162464142
Validation loss: 1.4693116154721988

Epoch: 6| Step: 11
Training loss: 0.04231046140193939
Validation loss: 1.4767482703731907

Epoch: 6| Step: 12
Training loss: 0.027686994522809982
Validation loss: 1.468407400192753

Epoch: 6| Step: 13
Training loss: 0.052678994834423065
Validation loss: 1.464896341805817

Epoch: 651| Step: 0
Training loss: 0.04062110185623169
Validation loss: 1.4862081338000555

Epoch: 6| Step: 1
Training loss: 0.05299846827983856
Validation loss: 1.4727668326388124

Epoch: 6| Step: 2
Training loss: 0.04182570055127144
Validation loss: 1.4854854922140799

Epoch: 6| Step: 3
Training loss: 0.07669292390346527
Validation loss: 1.4978967302589006

Epoch: 6| Step: 4
Training loss: 0.06306113302707672
Validation loss: 1.4921343400273273

Epoch: 6| Step: 5
Training loss: 0.04998065531253815
Validation loss: 1.4839237031116281

Epoch: 6| Step: 6
Training loss: 0.03622423857450485
Validation loss: 1.4922621224516182

Epoch: 6| Step: 7
Training loss: 0.04943844676017761
Validation loss: 1.5100386245276338

Epoch: 6| Step: 8
Training loss: 0.07200134545564651
Validation loss: 1.4842720582921018

Epoch: 6| Step: 9
Training loss: 0.04257526248693466
Validation loss: 1.4851544098828429

Epoch: 6| Step: 10
Training loss: 0.042015787214040756
Validation loss: 1.4762559116527598

Epoch: 6| Step: 11
Training loss: 0.051950205117464066
Validation loss: 1.5035617979623939

Epoch: 6| Step: 12
Training loss: 0.04249740391969681
Validation loss: 1.4831063946088154

Epoch: 6| Step: 13
Training loss: 0.03348150849342346
Validation loss: 1.5151156302421325

Epoch: 652| Step: 0
Training loss: 0.05715256556868553
Validation loss: 1.5224047219881447

Epoch: 6| Step: 1
Training loss: 0.04364284873008728
Validation loss: 1.521107925522712

Epoch: 6| Step: 2
Training loss: 0.06287388503551483
Validation loss: 1.5317339358791229

Epoch: 6| Step: 3
Training loss: 0.07112521678209305
Validation loss: 1.5285146787602415

Epoch: 6| Step: 4
Training loss: 0.05771151930093765
Validation loss: 1.5260205281678068

Epoch: 6| Step: 5
Training loss: 0.07964393496513367
Validation loss: 1.5165325704441275

Epoch: 6| Step: 6
Training loss: 0.05000099539756775
Validation loss: 1.492083913536482

Epoch: 6| Step: 7
Training loss: 0.040324866771698
Validation loss: 1.5033065490825201

Epoch: 6| Step: 8
Training loss: 0.07035287469625473
Validation loss: 1.5160151861047233

Epoch: 6| Step: 9
Training loss: 0.06924079358577728
Validation loss: 1.5174239937977125

Epoch: 6| Step: 10
Training loss: 0.067808598279953
Validation loss: 1.4983014739969724

Epoch: 6| Step: 11
Training loss: 0.038171231746673584
Validation loss: 1.491037122664913

Epoch: 6| Step: 12
Training loss: 0.06845241785049438
Validation loss: 1.50874714825743

Epoch: 6| Step: 13
Training loss: 0.035964734852313995
Validation loss: 1.51980879229884

Epoch: 653| Step: 0
Training loss: 0.05455467849969864
Validation loss: 1.5044612294884139

Epoch: 6| Step: 1
Training loss: 0.06271132081747055
Validation loss: 1.5281231249532392

Epoch: 6| Step: 2
Training loss: 0.06955946981906891
Validation loss: 1.5273034162418817

Epoch: 6| Step: 3
Training loss: 0.039848070591688156
Validation loss: 1.5237398826947777

Epoch: 6| Step: 4
Training loss: 0.04488974064588547
Validation loss: 1.5176969542298266

Epoch: 6| Step: 5
Training loss: 0.06066662818193436
Validation loss: 1.526962850683479

Epoch: 6| Step: 6
Training loss: 0.04474233090877533
Validation loss: 1.5334957120239094

Epoch: 6| Step: 7
Training loss: 0.05665111914277077
Validation loss: 1.551158430114869

Epoch: 6| Step: 8
Training loss: 0.047517288476228714
Validation loss: 1.5333869047062372

Epoch: 6| Step: 9
Training loss: 0.055676884949207306
Validation loss: 1.5127105379617343

Epoch: 6| Step: 10
Training loss: 0.05821232125163078
Validation loss: 1.5009543767539404

Epoch: 6| Step: 11
Training loss: 0.06308126449584961
Validation loss: 1.534175080637778

Epoch: 6| Step: 12
Training loss: 0.06414857506752014
Validation loss: 1.5362781363148843

Epoch: 6| Step: 13
Training loss: 0.10826896876096725
Validation loss: 1.5324679472113167

Epoch: 654| Step: 0
Training loss: 0.04625631868839264
Validation loss: 1.5190059984883955

Epoch: 6| Step: 1
Training loss: 0.05481210723519325
Validation loss: 1.5421752878414687

Epoch: 6| Step: 2
Training loss: 0.05723457783460617
Validation loss: 1.5355109386546637

Epoch: 6| Step: 3
Training loss: 0.0983823612332344
Validation loss: 1.517076821737392

Epoch: 6| Step: 4
Training loss: 0.1031474620103836
Validation loss: 1.5079295994133077

Epoch: 6| Step: 5
Training loss: 0.0706288069486618
Validation loss: 1.4977964887055017

Epoch: 6| Step: 6
Training loss: 0.05985250696539879
Validation loss: 1.4909820313094764

Epoch: 6| Step: 7
Training loss: 0.04184336960315704
Validation loss: 1.4863982110895135

Epoch: 6| Step: 8
Training loss: 0.0707697868347168
Validation loss: 1.497891963169139

Epoch: 6| Step: 9
Training loss: 0.10117005556821823
Validation loss: 1.49549852648089

Epoch: 6| Step: 10
Training loss: 0.07657724618911743
Validation loss: 1.5044315502207766

Epoch: 6| Step: 11
Training loss: 0.06624498963356018
Validation loss: 1.4871320160486365

Epoch: 6| Step: 12
Training loss: 0.06768740713596344
Validation loss: 1.50035995821799

Epoch: 6| Step: 13
Training loss: 0.03570691868662834
Validation loss: 1.4947193796916673

Epoch: 655| Step: 0
Training loss: 0.07365228235721588
Validation loss: 1.4947212126947218

Epoch: 6| Step: 1
Training loss: 0.07273729890584946
Validation loss: 1.5141704236307452

Epoch: 6| Step: 2
Training loss: 0.053420454263687134
Validation loss: 1.5119178897591048

Epoch: 6| Step: 3
Training loss: 0.10299228876829147
Validation loss: 1.5117336447520922

Epoch: 6| Step: 4
Training loss: 0.04728991538286209
Validation loss: 1.48115328819521

Epoch: 6| Step: 5
Training loss: 0.06353159248828888
Validation loss: 1.4491466155616186

Epoch: 6| Step: 6
Training loss: 0.054002076387405396
Validation loss: 1.464293743974419

Epoch: 6| Step: 7
Training loss: 0.04611369967460632
Validation loss: 1.475808246161348

Epoch: 6| Step: 8
Training loss: 0.05784110724925995
Validation loss: 1.464174432139243

Epoch: 6| Step: 9
Training loss: 0.08964315056800842
Validation loss: 1.4604180564162552

Epoch: 6| Step: 10
Training loss: 0.09650526940822601
Validation loss: 1.4565639322803867

Epoch: 6| Step: 11
Training loss: 0.0716671496629715
Validation loss: 1.4724545607002832

Epoch: 6| Step: 12
Training loss: 0.04099850356578827
Validation loss: 1.4743192285619757

Epoch: 6| Step: 13
Training loss: 0.08199519664049149
Validation loss: 1.482935998388516

Epoch: 656| Step: 0
Training loss: 0.07504105567932129
Validation loss: 1.4495106512500393

Epoch: 6| Step: 1
Training loss: 0.05861780792474747
Validation loss: 1.482232375811505

Epoch: 6| Step: 2
Training loss: 0.0788143128156662
Validation loss: 1.512329432272142

Epoch: 6| Step: 3
Training loss: 0.06298828125
Validation loss: 1.4844588977034374

Epoch: 6| Step: 4
Training loss: 0.07350368052721024
Validation loss: 1.4929686720653246

Epoch: 6| Step: 5
Training loss: 0.055924445390701294
Validation loss: 1.486817588088333

Epoch: 6| Step: 6
Training loss: 0.058415479958057404
Validation loss: 1.4844516015821887

Epoch: 6| Step: 7
Training loss: 0.06865859776735306
Validation loss: 1.4901923133480934

Epoch: 6| Step: 8
Training loss: 0.10276274383068085
Validation loss: 1.493995274266889

Epoch: 6| Step: 9
Training loss: 0.06875379383563995
Validation loss: 1.4924287052564724

Epoch: 6| Step: 10
Training loss: 0.1086561530828476
Validation loss: 1.4900298605683029

Epoch: 6| Step: 11
Training loss: 0.10849342495203018
Validation loss: 1.5020866163315312

Epoch: 6| Step: 12
Training loss: 0.07601584494113922
Validation loss: 1.5182892853213894

Epoch: 6| Step: 13
Training loss: 0.07533008605241776
Validation loss: 1.5432293953434113

Epoch: 657| Step: 0
Training loss: 0.11935194581747055
Validation loss: 1.5720420063182872

Epoch: 6| Step: 1
Training loss: 0.08357119560241699
Validation loss: 1.5346068272026636

Epoch: 6| Step: 2
Training loss: 0.06716500222682953
Validation loss: 1.547518745545418

Epoch: 6| Step: 3
Training loss: 0.05651810020208359
Validation loss: 1.5089151641373992

Epoch: 6| Step: 4
Training loss: 0.05873939022421837
Validation loss: 1.5476527995960687

Epoch: 6| Step: 5
Training loss: 0.02700110152363777
Validation loss: 1.5461172980646933

Epoch: 6| Step: 6
Training loss: 0.10613211244344711
Validation loss: 1.5146304458700202

Epoch: 6| Step: 7
Training loss: 0.1015818640589714
Validation loss: 1.5242086918123308

Epoch: 6| Step: 8
Training loss: 0.14060810208320618
Validation loss: 1.4888900826054234

Epoch: 6| Step: 9
Training loss: 0.073751300573349
Validation loss: 1.494479933092671

Epoch: 6| Step: 10
Training loss: 0.20861473679542542
Validation loss: 1.4775175727823728

Epoch: 6| Step: 11
Training loss: 0.07325772196054459
Validation loss: 1.481150015707939

Epoch: 6| Step: 12
Training loss: 0.08013062179088593
Validation loss: 1.4828663410678986

Epoch: 6| Step: 13
Training loss: 0.05965906381607056
Validation loss: 1.4757696249151742

Epoch: 658| Step: 0
Training loss: 0.049726296216249466
Validation loss: 1.5132995792614516

Epoch: 6| Step: 1
Training loss: 0.06263154745101929
Validation loss: 1.52317508574455

Epoch: 6| Step: 2
Training loss: 0.0936969518661499
Validation loss: 1.5555628268949446

Epoch: 6| Step: 3
Training loss: 0.099193274974823
Validation loss: 1.5293329261964368

Epoch: 6| Step: 4
Training loss: 0.07593782991170883
Validation loss: 1.5672375232942644

Epoch: 6| Step: 5
Training loss: 0.120022714138031
Validation loss: 1.5299213086405108

Epoch: 6| Step: 6
Training loss: 0.057062048465013504
Validation loss: 1.4997704080356065

Epoch: 6| Step: 7
Training loss: 0.057040534913539886
Validation loss: 1.5073486438361547

Epoch: 6| Step: 8
Training loss: 0.03428834676742554
Validation loss: 1.498220266834382

Epoch: 6| Step: 9
Training loss: 0.06120307743549347
Validation loss: 1.5244997662882651

Epoch: 6| Step: 10
Training loss: 0.055300503969192505
Validation loss: 1.5013657865985748

Epoch: 6| Step: 11
Training loss: 0.03592689335346222
Validation loss: 1.4900057751645324

Epoch: 6| Step: 12
Training loss: 0.08600842207670212
Validation loss: 1.4998543416300127

Epoch: 6| Step: 13
Training loss: 0.05697333812713623
Validation loss: 1.504061124658072

Epoch: 659| Step: 0
Training loss: 0.05452624708414078
Validation loss: 1.513923463001046

Epoch: 6| Step: 1
Training loss: 0.04085247591137886
Validation loss: 1.5208068252891622

Epoch: 6| Step: 2
Training loss: 0.04716219753026962
Validation loss: 1.4995132005342873

Epoch: 6| Step: 3
Training loss: 0.0862169861793518
Validation loss: 1.5148949443653066

Epoch: 6| Step: 4
Training loss: 0.06938618421554565
Validation loss: 1.517891537758612

Epoch: 6| Step: 5
Training loss: 0.039033472537994385
Validation loss: 1.5134065587033507

Epoch: 6| Step: 6
Training loss: 0.03862346336245537
Validation loss: 1.5184895761551396

Epoch: 6| Step: 7
Training loss: 0.041906025260686874
Validation loss: 1.504597435715378

Epoch: 6| Step: 8
Training loss: 0.05027388781309128
Validation loss: 1.5231889486312866

Epoch: 6| Step: 9
Training loss: 0.07482761144638062
Validation loss: 1.4887561593004452

Epoch: 6| Step: 10
Training loss: 0.1249559223651886
Validation loss: 1.5350195618085964

Epoch: 6| Step: 11
Training loss: 0.09034685790538788
Validation loss: 1.5370935445190759

Epoch: 6| Step: 12
Training loss: 0.01954997330904007
Validation loss: 1.5267366132428568

Epoch: 6| Step: 13
Training loss: 0.12637057900428772
Validation loss: 1.5221026994848763

Epoch: 660| Step: 0
Training loss: 0.039462096989154816
Validation loss: 1.540930405739815

Epoch: 6| Step: 1
Training loss: 0.09046822786331177
Validation loss: 1.5378112049512966

Epoch: 6| Step: 2
Training loss: 0.07463851571083069
Validation loss: 1.5398671780863116

Epoch: 6| Step: 3
Training loss: 0.06176745519042015
Validation loss: 1.5161540803088938

Epoch: 6| Step: 4
Training loss: 0.06609290093183517
Validation loss: 1.531478105052825

Epoch: 6| Step: 5
Training loss: 0.05203235149383545
Validation loss: 1.5223433099767214

Epoch: 6| Step: 6
Training loss: 0.06922202557325363
Validation loss: 1.5463100505131546

Epoch: 6| Step: 7
Training loss: 0.035033151507377625
Validation loss: 1.5460482995997193

Epoch: 6| Step: 8
Training loss: 0.048733171075582504
Validation loss: 1.5408254208103302

Epoch: 6| Step: 9
Training loss: 0.05801163613796234
Validation loss: 1.5291908838415658

Epoch: 6| Step: 10
Training loss: 0.06619670987129211
Validation loss: 1.519103648842022

Epoch: 6| Step: 11
Training loss: 0.10693198442459106
Validation loss: 1.5267459987312235

Epoch: 6| Step: 12
Training loss: 0.04526345431804657
Validation loss: 1.5350614927148307

Epoch: 6| Step: 13
Training loss: 0.05774933844804764
Validation loss: 1.5152631126424319

Epoch: 661| Step: 0
Training loss: 0.04804281145334244
Validation loss: 1.527994123838281

Epoch: 6| Step: 1
Training loss: 0.04457825794816017
Validation loss: 1.5237530008439095

Epoch: 6| Step: 2
Training loss: 0.05912425369024277
Validation loss: 1.543662509610576

Epoch: 6| Step: 3
Training loss: 0.05399612709879875
Validation loss: 1.5431695522800568

Epoch: 6| Step: 4
Training loss: 0.0287109836935997
Validation loss: 1.5368380238932948

Epoch: 6| Step: 5
Training loss: 0.07445827126502991
Validation loss: 1.5281993650620984

Epoch: 6| Step: 6
Training loss: 0.04532688111066818
Validation loss: 1.527558103684456

Epoch: 6| Step: 7
Training loss: 0.04431220516562462
Validation loss: 1.4963303663397347

Epoch: 6| Step: 8
Training loss: 0.0840543881058693
Validation loss: 1.5079149027024545

Epoch: 6| Step: 9
Training loss: 0.031620416790246964
Validation loss: 1.5190605982657401

Epoch: 6| Step: 10
Training loss: 0.0716799646615982
Validation loss: 1.5013973789830362

Epoch: 6| Step: 11
Training loss: 0.045164380222558975
Validation loss: 1.5102785838547574

Epoch: 6| Step: 12
Training loss: 0.050854966044425964
Validation loss: 1.4972404703017204

Epoch: 6| Step: 13
Training loss: 0.04862703010439873
Validation loss: 1.5265484208701758

Epoch: 662| Step: 0
Training loss: 0.05186902731657028
Validation loss: 1.5253041008467316

Epoch: 6| Step: 1
Training loss: 0.060228198766708374
Validation loss: 1.5414775545879076

Epoch: 6| Step: 2
Training loss: 0.05535559728741646
Validation loss: 1.5327474365952194

Epoch: 6| Step: 3
Training loss: 0.053322359919548035
Validation loss: 1.5344429733932659

Epoch: 6| Step: 4
Training loss: 0.07195042818784714
Validation loss: 1.5122290503594182

Epoch: 6| Step: 5
Training loss: 0.07383304834365845
Validation loss: 1.5572322850586267

Epoch: 6| Step: 6
Training loss: 0.038795992732048035
Validation loss: 1.528504096051698

Epoch: 6| Step: 7
Training loss: 0.04221612587571144
Validation loss: 1.5223955877365605

Epoch: 6| Step: 8
Training loss: 0.0476883128285408
Validation loss: 1.5154762908976565

Epoch: 6| Step: 9
Training loss: 0.052600134164094925
Validation loss: 1.517522632434804

Epoch: 6| Step: 10
Training loss: 0.0521102100610733
Validation loss: 1.4782041529173493

Epoch: 6| Step: 11
Training loss: 0.06288363039493561
Validation loss: 1.5162634131728963

Epoch: 6| Step: 12
Training loss: 0.03793460130691528
Validation loss: 1.5061930853833434

Epoch: 6| Step: 13
Training loss: 0.0727030411362648
Validation loss: 1.5284642884808202

Epoch: 663| Step: 0
Training loss: 0.0656484067440033
Validation loss: 1.5199543840141707

Epoch: 6| Step: 1
Training loss: 0.04143430292606354
Validation loss: 1.5379811909890944

Epoch: 6| Step: 2
Training loss: 0.042990513145923615
Validation loss: 1.5258180018394225

Epoch: 6| Step: 3
Training loss: 0.04296204075217247
Validation loss: 1.5392371916001844

Epoch: 6| Step: 4
Training loss: 0.05374939367175102
Validation loss: 1.5460259478579286

Epoch: 6| Step: 5
Training loss: 0.06939950585365295
Validation loss: 1.5234065658302718

Epoch: 6| Step: 6
Training loss: 0.03401128575205803
Validation loss: 1.5172113962070917

Epoch: 6| Step: 7
Training loss: 0.07450412213802338
Validation loss: 1.5403565386290192

Epoch: 6| Step: 8
Training loss: 0.05083170905709267
Validation loss: 1.512893074302263

Epoch: 6| Step: 9
Training loss: 0.05796927958726883
Validation loss: 1.5174437351124261

Epoch: 6| Step: 10
Training loss: 0.0312575101852417
Validation loss: 1.5263217738879624

Epoch: 6| Step: 11
Training loss: 0.04531972110271454
Validation loss: 1.546003624957095

Epoch: 6| Step: 12
Training loss: 0.07426994293928146
Validation loss: 1.5077871263668101

Epoch: 6| Step: 13
Training loss: 0.030159341171383858
Validation loss: 1.5041701909034484

Epoch: 664| Step: 0
Training loss: 0.03596026450395584
Validation loss: 1.517376616436948

Epoch: 6| Step: 1
Training loss: 0.057334788143634796
Validation loss: 1.5371264001374603

Epoch: 6| Step: 2
Training loss: 0.03979027643799782
Validation loss: 1.5247211840844923

Epoch: 6| Step: 3
Training loss: 0.049214255064725876
Validation loss: 1.543729115557927

Epoch: 6| Step: 4
Training loss: 0.05372726917266846
Validation loss: 1.4988333461105183

Epoch: 6| Step: 5
Training loss: 0.06011269614100456
Validation loss: 1.5266973933865946

Epoch: 6| Step: 6
Training loss: 0.05671286582946777
Validation loss: 1.5164168701376965

Epoch: 6| Step: 7
Training loss: 0.05546700209379196
Validation loss: 1.533851412034804

Epoch: 6| Step: 8
Training loss: 0.04400160163640976
Validation loss: 1.532199868591883

Epoch: 6| Step: 9
Training loss: 0.07428370416164398
Validation loss: 1.5205746132840392

Epoch: 6| Step: 10
Training loss: 0.09310227632522583
Validation loss: 1.518951771079853

Epoch: 6| Step: 11
Training loss: 0.03907446190714836
Validation loss: 1.5386478849636611

Epoch: 6| Step: 12
Training loss: 0.08014814555644989
Validation loss: 1.5306133429209392

Epoch: 6| Step: 13
Training loss: 0.06674341857433319
Validation loss: 1.5418672228372226

Epoch: 665| Step: 0
Training loss: 0.06078769639134407
Validation loss: 1.5265764908124042

Epoch: 6| Step: 1
Training loss: 0.03848859667778015
Validation loss: 1.5317326079132736

Epoch: 6| Step: 2
Training loss: 0.06422735750675201
Validation loss: 1.5278063525435746

Epoch: 6| Step: 3
Training loss: 0.07295794039964676
Validation loss: 1.5459406689930988

Epoch: 6| Step: 4
Training loss: 0.05244073271751404
Validation loss: 1.5588833478189283

Epoch: 6| Step: 5
Training loss: 0.04284428060054779
Validation loss: 1.499484380086263

Epoch: 6| Step: 6
Training loss: 0.05815485119819641
Validation loss: 1.5522055292642245

Epoch: 6| Step: 7
Training loss: 0.05036653205752373
Validation loss: 1.5430280841806883

Epoch: 6| Step: 8
Training loss: 0.08763791620731354
Validation loss: 1.5087362386847054

Epoch: 6| Step: 9
Training loss: 0.0686236172914505
Validation loss: 1.5262103183295137

Epoch: 6| Step: 10
Training loss: 0.07447444647550583
Validation loss: 1.524916357891534

Epoch: 6| Step: 11
Training loss: 0.08647854626178741
Validation loss: 1.5270913454794115

Epoch: 6| Step: 12
Training loss: 0.0506584495306015
Validation loss: 1.522562458950986

Epoch: 6| Step: 13
Training loss: 0.06933948397636414
Validation loss: 1.4990654248063282

Epoch: 666| Step: 0
Training loss: 0.06441055238246918
Validation loss: 1.5048288555555447

Epoch: 6| Step: 1
Training loss: 0.04004494100809097
Validation loss: 1.5186517430889992

Epoch: 6| Step: 2
Training loss: 0.03794293850660324
Validation loss: 1.509045430409011

Epoch: 6| Step: 3
Training loss: 0.05602936074137688
Validation loss: 1.4957499580998574

Epoch: 6| Step: 4
Training loss: 0.05352006107568741
Validation loss: 1.4986648674934142

Epoch: 6| Step: 5
Training loss: 0.03932958096265793
Validation loss: 1.498633228322511

Epoch: 6| Step: 6
Training loss: 0.05579385161399841
Validation loss: 1.512984828282428

Epoch: 6| Step: 7
Training loss: 0.0527307465672493
Validation loss: 1.506829676128203

Epoch: 6| Step: 8
Training loss: 0.05409082770347595
Validation loss: 1.5167911437249952

Epoch: 6| Step: 9
Training loss: 0.08107677847146988
Validation loss: 1.507743937994844

Epoch: 6| Step: 10
Training loss: 0.047768451273441315
Validation loss: 1.5203748076192793

Epoch: 6| Step: 11
Training loss: 0.04596909135580063
Validation loss: 1.528257127731077

Epoch: 6| Step: 12
Training loss: 0.08664791285991669
Validation loss: 1.5495874817653368

Epoch: 6| Step: 13
Training loss: 0.038903672248125076
Validation loss: 1.5301014813043738

Epoch: 667| Step: 0
Training loss: 0.05039103329181671
Validation loss: 1.5361624392130042

Epoch: 6| Step: 1
Training loss: 0.02463700622320175
Validation loss: 1.5216261109998148

Epoch: 6| Step: 2
Training loss: 0.08223449438810349
Validation loss: 1.5243765167010728

Epoch: 6| Step: 3
Training loss: 0.11026818305253983
Validation loss: 1.5174708020302556

Epoch: 6| Step: 4
Training loss: 0.04786817729473114
Validation loss: 1.5214725207257014

Epoch: 6| Step: 5
Training loss: 0.04872678220272064
Validation loss: 1.5295097981729815

Epoch: 6| Step: 6
Training loss: 0.07405411452054977
Validation loss: 1.5590492397226312

Epoch: 6| Step: 7
Training loss: 0.04745690897107124
Validation loss: 1.5597182396919496

Epoch: 6| Step: 8
Training loss: 0.05345655977725983
Validation loss: 1.5449782571484965

Epoch: 6| Step: 9
Training loss: 0.04216662794351578
Validation loss: 1.5323716184144378

Epoch: 6| Step: 10
Training loss: 0.039364442229270935
Validation loss: 1.5381461599821686

Epoch: 6| Step: 11
Training loss: 0.07069803029298782
Validation loss: 1.5514453367520404

Epoch: 6| Step: 12
Training loss: 0.08200448006391525
Validation loss: 1.543029131427888

Epoch: 6| Step: 13
Training loss: 0.028864661231637
Validation loss: 1.5627763989151164

Epoch: 668| Step: 0
Training loss: 0.056549716740846634
Validation loss: 1.550944298826238

Epoch: 6| Step: 1
Training loss: 0.042276911437511444
Validation loss: 1.580107254366721

Epoch: 6| Step: 2
Training loss: 0.12470892816781998
Validation loss: 1.577012385091474

Epoch: 6| Step: 3
Training loss: 0.08064506202936172
Validation loss: 1.5657174856432023

Epoch: 6| Step: 4
Training loss: 0.06290322542190552
Validation loss: 1.5700314788408176

Epoch: 6| Step: 5
Training loss: 0.09258957207202911
Validation loss: 1.5503144187311972

Epoch: 6| Step: 6
Training loss: 0.04984510689973831
Validation loss: 1.5666267692401845

Epoch: 6| Step: 7
Training loss: 0.04725655913352966
Validation loss: 1.5357087645479428

Epoch: 6| Step: 8
Training loss: 0.04430174455046654
Validation loss: 1.5255052043545632

Epoch: 6| Step: 9
Training loss: 0.06547389924526215
Validation loss: 1.536180370597429

Epoch: 6| Step: 10
Training loss: 0.04920714348554611
Validation loss: 1.5186138294076408

Epoch: 6| Step: 11
Training loss: 0.05941963940858841
Validation loss: 1.535055733496143

Epoch: 6| Step: 12
Training loss: 0.09127198159694672
Validation loss: 1.5548967366577477

Epoch: 6| Step: 13
Training loss: 0.045635685324668884
Validation loss: 1.512583419840823

Epoch: 669| Step: 0
Training loss: 0.046136945486068726
Validation loss: 1.521116546405259

Epoch: 6| Step: 1
Training loss: 0.04271867498755455
Validation loss: 1.5354352497285413

Epoch: 6| Step: 2
Training loss: 0.07356651872396469
Validation loss: 1.5347899954806092

Epoch: 6| Step: 3
Training loss: 0.08679750561714172
Validation loss: 1.5665204319902646

Epoch: 6| Step: 4
Training loss: 0.05386887490749359
Validation loss: 1.5382366827739182

Epoch: 6| Step: 5
Training loss: 0.11412259936332703
Validation loss: 1.5451355595742502

Epoch: 6| Step: 6
Training loss: 0.0720328688621521
Validation loss: 1.5199503443574394

Epoch: 6| Step: 7
Training loss: 0.06003119423985481
Validation loss: 1.5374151096549085

Epoch: 6| Step: 8
Training loss: 0.07564380019903183
Validation loss: 1.536691979695392

Epoch: 6| Step: 9
Training loss: 0.048892367631196976
Validation loss: 1.5221418744774275

Epoch: 6| Step: 10
Training loss: 0.04662299156188965
Validation loss: 1.5051941820370254

Epoch: 6| Step: 11
Training loss: 0.08935051411390305
Validation loss: 1.5131619745685208

Epoch: 6| Step: 12
Training loss: 0.10461293160915375
Validation loss: 1.4993582079487462

Epoch: 6| Step: 13
Training loss: 0.052301984280347824
Validation loss: 1.5140541920097925

Epoch: 670| Step: 0
Training loss: 0.05247511714696884
Validation loss: 1.4915618896484375

Epoch: 6| Step: 1
Training loss: 0.04077868163585663
Validation loss: 1.5245701984692646

Epoch: 6| Step: 2
Training loss: 0.05541437119245529
Validation loss: 1.5239884032998035

Epoch: 6| Step: 3
Training loss: 0.07204707711935043
Validation loss: 1.5210184307508572

Epoch: 6| Step: 4
Training loss: 0.06187634915113449
Validation loss: 1.5343857247342345

Epoch: 6| Step: 5
Training loss: 0.08210089802742004
Validation loss: 1.563314296865976

Epoch: 6| Step: 6
Training loss: 0.03120497614145279
Validation loss: 1.5621782233638148

Epoch: 6| Step: 7
Training loss: 0.0589381605386734
Validation loss: 1.5533153767226844

Epoch: 6| Step: 8
Training loss: 0.05256584286689758
Validation loss: 1.5708736463259625

Epoch: 6| Step: 9
Training loss: 0.046800389885902405
Validation loss: 1.5431363710793116

Epoch: 6| Step: 10
Training loss: 0.05361589789390564
Validation loss: 1.5452775788563553

Epoch: 6| Step: 11
Training loss: 0.029588274657726288
Validation loss: 1.5272424221038818

Epoch: 6| Step: 12
Training loss: 0.05880386382341385
Validation loss: 1.5276509741301179

Epoch: 6| Step: 13
Training loss: 0.03326879441738129
Validation loss: 1.5298952056515602

Epoch: 671| Step: 0
Training loss: 0.06894461810588837
Validation loss: 1.5377690253719207

Epoch: 6| Step: 1
Training loss: 0.07942360639572144
Validation loss: 1.5357968884129678

Epoch: 6| Step: 2
Training loss: 0.04089580848813057
Validation loss: 1.5159803975012995

Epoch: 6| Step: 3
Training loss: 0.06859168410301208
Validation loss: 1.5345230358903126

Epoch: 6| Step: 4
Training loss: 0.05092529579997063
Validation loss: 1.533300539498688

Epoch: 6| Step: 5
Training loss: 0.05186840891838074
Validation loss: 1.5234581757617254

Epoch: 6| Step: 6
Training loss: 0.04966716095805168
Validation loss: 1.543672861591462

Epoch: 6| Step: 7
Training loss: 0.08220058679580688
Validation loss: 1.546701181319452

Epoch: 6| Step: 8
Training loss: 0.02591126225888729
Validation loss: 1.5430017953277917

Epoch: 6| Step: 9
Training loss: 0.058169782161712646
Validation loss: 1.5296564422627932

Epoch: 6| Step: 10
Training loss: 0.04921746999025345
Validation loss: 1.5450177500324864

Epoch: 6| Step: 11
Training loss: 0.05824168771505356
Validation loss: 1.5118072571293

Epoch: 6| Step: 12
Training loss: 0.05344019830226898
Validation loss: 1.5178470034753122

Epoch: 6| Step: 13
Training loss: 0.0665983259677887
Validation loss: 1.5065122445424397

Epoch: 672| Step: 0
Training loss: 0.0879799872636795
Validation loss: 1.5453988429038756

Epoch: 6| Step: 1
Training loss: 0.030866282060742378
Validation loss: 1.562047125190817

Epoch: 6| Step: 2
Training loss: 0.04669633507728577
Validation loss: 1.5231228669484456

Epoch: 6| Step: 3
Training loss: 0.0654139444231987
Validation loss: 1.5569333914787538

Epoch: 6| Step: 4
Training loss: 0.046371012926101685
Validation loss: 1.5138222863597255

Epoch: 6| Step: 5
Training loss: 0.06889429688453674
Validation loss: 1.5290247112192132

Epoch: 6| Step: 6
Training loss: 0.05807747319340706
Validation loss: 1.5279048860714

Epoch: 6| Step: 7
Training loss: 0.07122381031513214
Validation loss: 1.5491240973113685

Epoch: 6| Step: 8
Training loss: 0.05363406240940094
Validation loss: 1.5230292222833122

Epoch: 6| Step: 9
Training loss: 0.06771532446146011
Validation loss: 1.5211354724822506

Epoch: 6| Step: 10
Training loss: 0.04023226350545883
Validation loss: 1.5111695438302972

Epoch: 6| Step: 11
Training loss: 0.0484246201813221
Validation loss: 1.5313686927159627

Epoch: 6| Step: 12
Training loss: 0.029424455016851425
Validation loss: 1.5440603148552678

Epoch: 6| Step: 13
Training loss: 0.10840455442667007
Validation loss: 1.5428678822773758

Epoch: 673| Step: 0
Training loss: 0.0592159628868103
Validation loss: 1.5364157512623777

Epoch: 6| Step: 1
Training loss: 0.03551224246621132
Validation loss: 1.5478230573797738

Epoch: 6| Step: 2
Training loss: 0.034372638911008835
Validation loss: 1.5392494637479064

Epoch: 6| Step: 3
Training loss: 0.07193569839000702
Validation loss: 1.5353854535728373

Epoch: 6| Step: 4
Training loss: 0.049699243158102036
Validation loss: 1.549324167672024

Epoch: 6| Step: 5
Training loss: 0.04696290194988251
Validation loss: 1.5281717392706102

Epoch: 6| Step: 6
Training loss: 0.054527029395103455
Validation loss: 1.5311905286645378

Epoch: 6| Step: 7
Training loss: 0.04184698686003685
Validation loss: 1.5376131367939774

Epoch: 6| Step: 8
Training loss: 0.06837933510541916
Validation loss: 1.5505737816133807

Epoch: 6| Step: 9
Training loss: 0.054990820586681366
Validation loss: 1.5385428192794963

Epoch: 6| Step: 10
Training loss: 0.03861983120441437
Validation loss: 1.542492990852684

Epoch: 6| Step: 11
Training loss: 0.04370522499084473
Validation loss: 1.5266043498951902

Epoch: 6| Step: 12
Training loss: 0.08770269900560379
Validation loss: 1.5216452793408466

Epoch: 6| Step: 13
Training loss: 0.022936644032597542
Validation loss: 1.5124183111293341

Epoch: 674| Step: 0
Training loss: 0.033869676291942596
Validation loss: 1.503205878760225

Epoch: 6| Step: 1
Training loss: 0.054311759769916534
Validation loss: 1.4884843787839335

Epoch: 6| Step: 2
Training loss: 0.0942377895116806
Validation loss: 1.5205490396868797

Epoch: 6| Step: 3
Training loss: 0.06702836602926254
Validation loss: 1.5231204878899358

Epoch: 6| Step: 4
Training loss: 0.045410800725221634
Validation loss: 1.5003628897410568

Epoch: 6| Step: 5
Training loss: 0.08944007754325867
Validation loss: 1.5303397858014671

Epoch: 6| Step: 6
Training loss: 0.0636640340089798
Validation loss: 1.5077903629631124

Epoch: 6| Step: 7
Training loss: 0.056547243148088455
Validation loss: 1.5290380075413694

Epoch: 6| Step: 8
Training loss: 0.04971296340227127
Validation loss: 1.531959658027977

Epoch: 6| Step: 9
Training loss: 0.04823242500424385
Validation loss: 1.5258934036377938

Epoch: 6| Step: 10
Training loss: 0.035029783844947815
Validation loss: 1.5332195771637784

Epoch: 6| Step: 11
Training loss: 0.04314826801419258
Validation loss: 1.5722533259340512

Epoch: 6| Step: 12
Training loss: 0.059934698045253754
Validation loss: 1.5663204205933439

Epoch: 6| Step: 13
Training loss: 0.0723719596862793
Validation loss: 1.5648841216999998

Epoch: 675| Step: 0
Training loss: 0.03368361294269562
Validation loss: 1.5299055794233918

Epoch: 6| Step: 1
Training loss: 0.0504244789481163
Validation loss: 1.5409109925711026

Epoch: 6| Step: 2
Training loss: 0.06604422628879547
Validation loss: 1.51913498550333

Epoch: 6| Step: 3
Training loss: 0.05902525410056114
Validation loss: 1.547917354491449

Epoch: 6| Step: 4
Training loss: 0.0778643935918808
Validation loss: 1.505919744250595

Epoch: 6| Step: 5
Training loss: 0.07243585586547852
Validation loss: 1.5008040961398874

Epoch: 6| Step: 6
Training loss: 0.03521645814180374
Validation loss: 1.5151417422038254

Epoch: 6| Step: 7
Training loss: 0.05925801768898964
Validation loss: 1.507270973215821

Epoch: 6| Step: 8
Training loss: 0.07178299129009247
Validation loss: 1.5263895860282324

Epoch: 6| Step: 9
Training loss: 0.05913599953055382
Validation loss: 1.521562276347991

Epoch: 6| Step: 10
Training loss: 0.05220016464591026
Validation loss: 1.5161414787333498

Epoch: 6| Step: 11
Training loss: 0.04734994098544121
Validation loss: 1.5355340716659382

Epoch: 6| Step: 12
Training loss: 0.08463086187839508
Validation loss: 1.5384665766069967

Epoch: 6| Step: 13
Training loss: 0.04673237353563309
Validation loss: 1.5510799654068486

Epoch: 676| Step: 0
Training loss: 0.07568737864494324
Validation loss: 1.5577562393680695

Epoch: 6| Step: 1
Training loss: 0.0692269429564476
Validation loss: 1.5279848376909893

Epoch: 6| Step: 2
Training loss: 0.06491014361381531
Validation loss: 1.537087566109114

Epoch: 6| Step: 3
Training loss: 0.05188249796628952
Validation loss: 1.5302325910137546

Epoch: 6| Step: 4
Training loss: 0.04275728017091751
Validation loss: 1.5186622822156517

Epoch: 6| Step: 5
Training loss: 0.062043823301792145
Validation loss: 1.5226713880415885

Epoch: 6| Step: 6
Training loss: 0.09893359243869781
Validation loss: 1.5096894361639535

Epoch: 6| Step: 7
Training loss: 0.04780451953411102
Validation loss: 1.4961601995652722

Epoch: 6| Step: 8
Training loss: 0.0964464545249939
Validation loss: 1.5135567534354426

Epoch: 6| Step: 9
Training loss: 0.056342992931604385
Validation loss: 1.5111518316371466

Epoch: 6| Step: 10
Training loss: 0.06470198929309845
Validation loss: 1.5060582084040488

Epoch: 6| Step: 11
Training loss: 0.06545835733413696
Validation loss: 1.529870129400684

Epoch: 6| Step: 12
Training loss: 0.06455458700656891
Validation loss: 1.5367672148571219

Epoch: 6| Step: 13
Training loss: 0.057605452835559845
Validation loss: 1.526031208294694

Epoch: 677| Step: 0
Training loss: 0.04092485457658768
Validation loss: 1.550784746805827

Epoch: 6| Step: 1
Training loss: 0.06213386356830597
Validation loss: 1.5424647805511311

Epoch: 6| Step: 2
Training loss: 0.03906264156103134
Validation loss: 1.5487574697822653

Epoch: 6| Step: 3
Training loss: 0.04060330241918564
Validation loss: 1.5545055186876686

Epoch: 6| Step: 4
Training loss: 0.02614397555589676
Validation loss: 1.5418308691311908

Epoch: 6| Step: 5
Training loss: 0.02521384134888649
Validation loss: 1.5460979528324579

Epoch: 6| Step: 6
Training loss: 0.02673780918121338
Validation loss: 1.546988401361691

Epoch: 6| Step: 7
Training loss: 0.05188252031803131
Validation loss: 1.5671021464050456

Epoch: 6| Step: 8
Training loss: 0.06452864408493042
Validation loss: 1.5675480929754113

Epoch: 6| Step: 9
Training loss: 0.07571928203105927
Validation loss: 1.5543728092665314

Epoch: 6| Step: 10
Training loss: 0.06945326924324036
Validation loss: 1.56121499435876

Epoch: 6| Step: 11
Training loss: 0.05020404979586601
Validation loss: 1.5559492829025432

Epoch: 6| Step: 12
Training loss: 0.06677190959453583
Validation loss: 1.5627332861705492

Epoch: 6| Step: 13
Training loss: 0.030414793640375137
Validation loss: 1.5440278425011584

Epoch: 678| Step: 0
Training loss: 0.05380399525165558
Validation loss: 1.5612398270637757

Epoch: 6| Step: 1
Training loss: 0.07151972502470016
Validation loss: 1.5867417307310208

Epoch: 6| Step: 2
Training loss: 0.06933382898569107
Validation loss: 1.560529572348441

Epoch: 6| Step: 3
Training loss: 0.05355875939130783
Validation loss: 1.5499166621956775

Epoch: 6| Step: 4
Training loss: 0.067501500248909
Validation loss: 1.5724387771339827

Epoch: 6| Step: 5
Training loss: 0.05843842029571533
Validation loss: 1.5593712470864738

Epoch: 6| Step: 6
Training loss: 0.06733161211013794
Validation loss: 1.5564727898566955

Epoch: 6| Step: 7
Training loss: 0.03865077346563339
Validation loss: 1.5652330857451244

Epoch: 6| Step: 8
Training loss: 0.037036243826150894
Validation loss: 1.5445096864495227

Epoch: 6| Step: 9
Training loss: 0.041546016931533813
Validation loss: 1.5118916021880282

Epoch: 6| Step: 10
Training loss: 0.04420716315507889
Validation loss: 1.5308596895587059

Epoch: 6| Step: 11
Training loss: 0.04156019166111946
Validation loss: 1.5265663823773783

Epoch: 6| Step: 12
Training loss: 0.04435034096240997
Validation loss: 1.5248040153134255

Epoch: 6| Step: 13
Training loss: 0.043852899223566055
Validation loss: 1.533873587526301

Epoch: 679| Step: 0
Training loss: 0.03141862526535988
Validation loss: 1.5370271590448195

Epoch: 6| Step: 1
Training loss: 0.061064571142196655
Validation loss: 1.5475134939275763

Epoch: 6| Step: 2
Training loss: 0.046104393899440765
Validation loss: 1.5423983579040856

Epoch: 6| Step: 3
Training loss: 0.05073554813861847
Validation loss: 1.5368921026106803

Epoch: 6| Step: 4
Training loss: 0.055497173219919205
Validation loss: 1.5434801886158604

Epoch: 6| Step: 5
Training loss: 0.06982120126485825
Validation loss: 1.544538003142162

Epoch: 6| Step: 6
Training loss: 0.04129347577691078
Validation loss: 1.538345354859547

Epoch: 6| Step: 7
Training loss: 0.06687648594379425
Validation loss: 1.5425258157073811

Epoch: 6| Step: 8
Training loss: 0.03399798274040222
Validation loss: 1.538423579226258

Epoch: 6| Step: 9
Training loss: 0.055260069668293
Validation loss: 1.5372080636280838

Epoch: 6| Step: 10
Training loss: 0.03848574310541153
Validation loss: 1.5462175723045104

Epoch: 6| Step: 11
Training loss: 0.07629343122243881
Validation loss: 1.5287073706426928

Epoch: 6| Step: 12
Training loss: 0.04781971126794815
Validation loss: 1.5319758717731764

Epoch: 6| Step: 13
Training loss: 0.045035772025585175
Validation loss: 1.50360744742937

Epoch: 680| Step: 0
Training loss: 0.06549403071403503
Validation loss: 1.5012583476240917

Epoch: 6| Step: 1
Training loss: 0.0615915022790432
Validation loss: 1.513366727418797

Epoch: 6| Step: 2
Training loss: 0.0658625066280365
Validation loss: 1.5054708655162523

Epoch: 6| Step: 3
Training loss: 0.037870392203330994
Validation loss: 1.5259932856405936

Epoch: 6| Step: 4
Training loss: 0.0673440620303154
Validation loss: 1.4981825236351258

Epoch: 6| Step: 5
Training loss: 0.07609768211841583
Validation loss: 1.528746924733603

Epoch: 6| Step: 6
Training loss: 0.04232923686504364
Validation loss: 1.5346169292285878

Epoch: 6| Step: 7
Training loss: 0.04162078723311424
Validation loss: 1.5272530253215502

Epoch: 6| Step: 8
Training loss: 0.05088344216346741
Validation loss: 1.5293850693651425

Epoch: 6| Step: 9
Training loss: 0.04528919607400894
Validation loss: 1.5211788633818268

Epoch: 6| Step: 10
Training loss: 0.02904815971851349
Validation loss: 1.5131425729361914

Epoch: 6| Step: 11
Training loss: 0.04628029465675354
Validation loss: 1.5171621960978354

Epoch: 6| Step: 12
Training loss: 0.04242580756545067
Validation loss: 1.5134825001480758

Epoch: 6| Step: 13
Training loss: 0.0248726774007082
Validation loss: 1.528279883887178

Epoch: 681| Step: 0
Training loss: 0.021732410416007042
Validation loss: 1.5336712098890735

Epoch: 6| Step: 1
Training loss: 0.049119673669338226
Validation loss: 1.5253207850199875

Epoch: 6| Step: 2
Training loss: 0.05983497202396393
Validation loss: 1.5187879185522757

Epoch: 6| Step: 3
Training loss: 0.04372943192720413
Validation loss: 1.4990689075121315

Epoch: 6| Step: 4
Training loss: 0.06445488333702087
Validation loss: 1.5343781658398208

Epoch: 6| Step: 5
Training loss: 0.048482608050107956
Validation loss: 1.5343973739172823

Epoch: 6| Step: 6
Training loss: 0.03941158577799797
Validation loss: 1.528915543710032

Epoch: 6| Step: 7
Training loss: 0.02105337753891945
Validation loss: 1.5179200492879397

Epoch: 6| Step: 8
Training loss: 0.03195668011903763
Validation loss: 1.5215067671191307

Epoch: 6| Step: 9
Training loss: 0.043296560645103455
Validation loss: 1.5299319304445738

Epoch: 6| Step: 10
Training loss: 0.06242838129401207
Validation loss: 1.5286478701458182

Epoch: 6| Step: 11
Training loss: 0.056978315114974976
Validation loss: 1.530716009037469

Epoch: 6| Step: 12
Training loss: 0.08545832335948944
Validation loss: 1.5234374743635937

Epoch: 6| Step: 13
Training loss: 0.04270990565419197
Validation loss: 1.5170756206717542

Epoch: 682| Step: 0
Training loss: 0.04069123789668083
Validation loss: 1.5104078836338495

Epoch: 6| Step: 1
Training loss: 0.03314518928527832
Validation loss: 1.5220143718104209

Epoch: 6| Step: 2
Training loss: 0.06446654349565506
Validation loss: 1.5295935638489262

Epoch: 6| Step: 3
Training loss: 0.0555291622877121
Validation loss: 1.5302808195032098

Epoch: 6| Step: 4
Training loss: 0.048493847250938416
Validation loss: 1.5132947416715725

Epoch: 6| Step: 5
Training loss: 0.09167101234197617
Validation loss: 1.5143989978298065

Epoch: 6| Step: 6
Training loss: 0.050979554653167725
Validation loss: 1.5179943910209082

Epoch: 6| Step: 7
Training loss: 0.06167559698224068
Validation loss: 1.514655855394179

Epoch: 6| Step: 8
Training loss: 0.04785209149122238
Validation loss: 1.5124739446947653

Epoch: 6| Step: 9
Training loss: 0.032564692199230194
Validation loss: 1.4980793255631641

Epoch: 6| Step: 10
Training loss: 0.055207569152116776
Validation loss: 1.5242440469803349

Epoch: 6| Step: 11
Training loss: 0.06227954477071762
Validation loss: 1.4994761232406861

Epoch: 6| Step: 12
Training loss: 0.039801113307476044
Validation loss: 1.5102725522492522

Epoch: 6| Step: 13
Training loss: 0.035636622458696365
Validation loss: 1.51132030640879

Epoch: 683| Step: 0
Training loss: 0.036120764911174774
Validation loss: 1.5088658473824943

Epoch: 6| Step: 1
Training loss: 0.053645189851522446
Validation loss: 1.5270447602836035

Epoch: 6| Step: 2
Training loss: 0.029794909060001373
Validation loss: 1.5022412756437897

Epoch: 6| Step: 3
Training loss: 0.026039503514766693
Validation loss: 1.4847164730871878

Epoch: 6| Step: 4
Training loss: 0.057882461696863174
Validation loss: 1.4847498619428245

Epoch: 6| Step: 5
Training loss: 0.03700859844684601
Validation loss: 1.4768431596858527

Epoch: 6| Step: 6
Training loss: 0.05606193467974663
Validation loss: 1.4981653331428446

Epoch: 6| Step: 7
Training loss: 0.03675344958901405
Validation loss: 1.487045193231234

Epoch: 6| Step: 8
Training loss: 0.04089520871639252
Validation loss: 1.519917175333987

Epoch: 6| Step: 9
Training loss: 0.0976530909538269
Validation loss: 1.4979508820400442

Epoch: 6| Step: 10
Training loss: 0.030121635645627975
Validation loss: 1.4917696983583513

Epoch: 6| Step: 11
Training loss: 0.023256823420524597
Validation loss: 1.5110996371956282

Epoch: 6| Step: 12
Training loss: 0.04136273264884949
Validation loss: 1.5088030266505417

Epoch: 6| Step: 13
Training loss: 0.04128442704677582
Validation loss: 1.492417029155198

Epoch: 684| Step: 0
Training loss: 0.034809041768312454
Validation loss: 1.51280560288378

Epoch: 6| Step: 1
Training loss: 0.05245531350374222
Validation loss: 1.5324957934758996

Epoch: 6| Step: 2
Training loss: 0.05061538517475128
Validation loss: 1.516676559243151

Epoch: 6| Step: 3
Training loss: 0.03319427743554115
Validation loss: 1.5237817918100665

Epoch: 6| Step: 4
Training loss: 0.05723357945680618
Validation loss: 1.528389197523876

Epoch: 6| Step: 5
Training loss: 0.06958803534507751
Validation loss: 1.5294834439472487

Epoch: 6| Step: 6
Training loss: 0.06605304777622223
Validation loss: 1.5154163452886766

Epoch: 6| Step: 7
Training loss: 0.08447200059890747
Validation loss: 1.536906752535092

Epoch: 6| Step: 8
Training loss: 0.047123514115810394
Validation loss: 1.5150261989203833

Epoch: 6| Step: 9
Training loss: 0.07646910846233368
Validation loss: 1.5479374829158987

Epoch: 6| Step: 10
Training loss: 0.08703894913196564
Validation loss: 1.5377381488841066

Epoch: 6| Step: 11
Training loss: 0.055571310222148895
Validation loss: 1.5373202434150122

Epoch: 6| Step: 12
Training loss: 0.03438349813222885
Validation loss: 1.5419151218988563

Epoch: 6| Step: 13
Training loss: 0.04854361340403557
Validation loss: 1.531439959361989

Epoch: 685| Step: 0
Training loss: 0.05675522983074188
Validation loss: 1.510361329201729

Epoch: 6| Step: 1
Training loss: 0.037069566547870636
Validation loss: 1.5119799080715384

Epoch: 6| Step: 2
Training loss: 0.03554113581776619
Validation loss: 1.5169478199815238

Epoch: 6| Step: 3
Training loss: 0.06779518723487854
Validation loss: 1.5231947411773026

Epoch: 6| Step: 4
Training loss: 0.1069716364145279
Validation loss: 1.497891450441012

Epoch: 6| Step: 5
Training loss: 0.03847430646419525
Validation loss: 1.513396764314303

Epoch: 6| Step: 6
Training loss: 0.05320121347904205
Validation loss: 1.5120067596435547

Epoch: 6| Step: 7
Training loss: 0.03610975295305252
Validation loss: 1.5286712800302813

Epoch: 6| Step: 8
Training loss: 0.05394347012042999
Validation loss: 1.5373719097465597

Epoch: 6| Step: 9
Training loss: 0.07088231295347214
Validation loss: 1.5235739279818792

Epoch: 6| Step: 10
Training loss: 0.04193706065416336
Validation loss: 1.5569853962108653

Epoch: 6| Step: 11
Training loss: 0.04494293034076691
Validation loss: 1.5319104066459082

Epoch: 6| Step: 12
Training loss: 0.03567253053188324
Validation loss: 1.5536094173308341

Epoch: 6| Step: 13
Training loss: 0.036800041794776917
Validation loss: 1.530129635205833

Epoch: 686| Step: 0
Training loss: 0.044219721108675
Validation loss: 1.5293213769953737

Epoch: 6| Step: 1
Training loss: 0.03875948488712311
Validation loss: 1.5319118833029142

Epoch: 6| Step: 2
Training loss: 0.048249952495098114
Validation loss: 1.5502720596969768

Epoch: 6| Step: 3
Training loss: 0.04956229031085968
Validation loss: 1.5313738622973043

Epoch: 6| Step: 4
Training loss: 0.08947235345840454
Validation loss: 1.5360574478744178

Epoch: 6| Step: 5
Training loss: 0.049946852028369904
Validation loss: 1.54943859705361

Epoch: 6| Step: 6
Training loss: 0.0756700187921524
Validation loss: 1.5328286296577864

Epoch: 6| Step: 7
Training loss: 0.04829946905374527
Validation loss: 1.5314695476203837

Epoch: 6| Step: 8
Training loss: 0.0739041417837143
Validation loss: 1.5454017064904655

Epoch: 6| Step: 9
Training loss: 0.0431218184530735
Validation loss: 1.5427026389747538

Epoch: 6| Step: 10
Training loss: 0.049418121576309204
Validation loss: 1.5337616474397722

Epoch: 6| Step: 11
Training loss: 0.04941105842590332
Validation loss: 1.5441152857195946

Epoch: 6| Step: 12
Training loss: 0.05982634425163269
Validation loss: 1.5561842033939977

Epoch: 6| Step: 13
Training loss: 0.019281115382909775
Validation loss: 1.555767083680758

Epoch: 687| Step: 0
Training loss: 0.0645725280046463
Validation loss: 1.5793582342004264

Epoch: 6| Step: 1
Training loss: 0.052224334329366684
Validation loss: 1.5720703012199813

Epoch: 6| Step: 2
Training loss: 0.054264530539512634
Validation loss: 1.5878732922256633

Epoch: 6| Step: 3
Training loss: 0.09061715006828308
Validation loss: 1.5783153836445143

Epoch: 6| Step: 4
Training loss: 0.022379666566848755
Validation loss: 1.5510821752650763

Epoch: 6| Step: 5
Training loss: 0.023088932037353516
Validation loss: 1.5334317197081864

Epoch: 6| Step: 6
Training loss: 0.05508560687303543
Validation loss: 1.5258847385324457

Epoch: 6| Step: 7
Training loss: 0.04208650439977646
Validation loss: 1.5231733411870978

Epoch: 6| Step: 8
Training loss: 0.02031686156988144
Validation loss: 1.5073529879252117

Epoch: 6| Step: 9
Training loss: 0.07105618715286255
Validation loss: 1.5198488812292776

Epoch: 6| Step: 10
Training loss: 0.041708916425704956
Validation loss: 1.5241124399246708

Epoch: 6| Step: 11
Training loss: 0.04349926859140396
Validation loss: 1.53042346431363

Epoch: 6| Step: 12
Training loss: 0.05256384611129761
Validation loss: 1.5231919045089393

Epoch: 6| Step: 13
Training loss: 0.05249819532036781
Validation loss: 1.541329724814302

Epoch: 688| Step: 0
Training loss: 0.04632100090384483
Validation loss: 1.5421467186302267

Epoch: 6| Step: 1
Training loss: 0.07129145413637161
Validation loss: 1.5438278951952535

Epoch: 6| Step: 2
Training loss: 0.04663514345884323
Validation loss: 1.553740006621166

Epoch: 6| Step: 3
Training loss: 0.05783466994762421
Validation loss: 1.5578706764405774

Epoch: 6| Step: 4
Training loss: 0.043099187314510345
Validation loss: 1.5438848157082834

Epoch: 6| Step: 5
Training loss: 0.06492476165294647
Validation loss: 1.5448020658185404

Epoch: 6| Step: 6
Training loss: 0.03799092769622803
Validation loss: 1.5521853239305559

Epoch: 6| Step: 7
Training loss: 0.047579310834407806
Validation loss: 1.5263311991127588

Epoch: 6| Step: 8
Training loss: 0.051195837557315826
Validation loss: 1.5174524296996414

Epoch: 6| Step: 9
Training loss: 0.06692317873239517
Validation loss: 1.5186732340884466

Epoch: 6| Step: 10
Training loss: 0.042016323655843735
Validation loss: 1.5359322986295145

Epoch: 6| Step: 11
Training loss: 0.07755519449710846
Validation loss: 1.501345649842293

Epoch: 6| Step: 12
Training loss: 0.06300368905067444
Validation loss: 1.5181051133781351

Epoch: 6| Step: 13
Training loss: 0.01876066066324711
Validation loss: 1.5005194346110027

Epoch: 689| Step: 0
Training loss: 0.04805757850408554
Validation loss: 1.5297710946811143

Epoch: 6| Step: 1
Training loss: 0.045948244631290436
Validation loss: 1.5027691632188775

Epoch: 6| Step: 2
Training loss: 0.025809280574321747
Validation loss: 1.5040189284150318

Epoch: 6| Step: 3
Training loss: 0.05612330883741379
Validation loss: 1.511509322351025

Epoch: 6| Step: 4
Training loss: 0.049559734761714935
Validation loss: 1.525916822494999

Epoch: 6| Step: 5
Training loss: 0.03272680938243866
Validation loss: 1.5256367601374143

Epoch: 6| Step: 6
Training loss: 0.05477692186832428
Validation loss: 1.4991752524529733

Epoch: 6| Step: 7
Training loss: 0.03957566246390343
Validation loss: 1.504243420016381

Epoch: 6| Step: 8
Training loss: 0.07512155175209045
Validation loss: 1.5153519171540455

Epoch: 6| Step: 9
Training loss: 0.0399320125579834
Validation loss: 1.5260405027738182

Epoch: 6| Step: 10
Training loss: 0.05604684352874756
Validation loss: 1.5461008676918604

Epoch: 6| Step: 11
Training loss: 0.05892692878842354
Validation loss: 1.5116059241756317

Epoch: 6| Step: 12
Training loss: 0.06178469955921173
Validation loss: 1.4991578530239802

Epoch: 6| Step: 13
Training loss: 0.03821039944887161
Validation loss: 1.520914343095595

Epoch: 690| Step: 0
Training loss: 0.04220794141292572
Validation loss: 1.510920819415841

Epoch: 6| Step: 1
Training loss: 0.03653218597173691
Validation loss: 1.500214308820745

Epoch: 6| Step: 2
Training loss: 0.07324568927288055
Validation loss: 1.5027873387900732

Epoch: 6| Step: 3
Training loss: 0.050259530544281006
Validation loss: 1.5058803532713203

Epoch: 6| Step: 4
Training loss: 0.03851396590471268
Validation loss: 1.4977898956626974

Epoch: 6| Step: 5
Training loss: 0.03819052502512932
Validation loss: 1.5165272348670549

Epoch: 6| Step: 6
Training loss: 0.04242550581693649
Validation loss: 1.4871580921193606

Epoch: 6| Step: 7
Training loss: 0.04077177122235298
Validation loss: 1.515233644234237

Epoch: 6| Step: 8
Training loss: 0.06409283727407455
Validation loss: 1.4994927170456096

Epoch: 6| Step: 9
Training loss: 0.06673116236925125
Validation loss: 1.5100423392429148

Epoch: 6| Step: 10
Training loss: 0.06645561754703522
Validation loss: 1.525615951066376

Epoch: 6| Step: 11
Training loss: 0.061157017946243286
Validation loss: 1.516168189305131

Epoch: 6| Step: 12
Training loss: 0.0799790471792221
Validation loss: 1.5003805865523636

Epoch: 6| Step: 13
Training loss: 0.08835572749376297
Validation loss: 1.5065952667626001

Epoch: 691| Step: 0
Training loss: 0.04838377237319946
Validation loss: 1.4889452444609774

Epoch: 6| Step: 1
Training loss: 0.06382245570421219
Validation loss: 1.4898018721611268

Epoch: 6| Step: 2
Training loss: 0.0542474091053009
Validation loss: 1.4936046215795702

Epoch: 6| Step: 3
Training loss: 0.0535971000790596
Validation loss: 1.4979839773588284

Epoch: 6| Step: 4
Training loss: 0.06303662061691284
Validation loss: 1.4880170565779491

Epoch: 6| Step: 5
Training loss: 0.06303198635578156
Validation loss: 1.4911497305798274

Epoch: 6| Step: 6
Training loss: 0.06380614638328552
Validation loss: 1.4873281883937057

Epoch: 6| Step: 7
Training loss: 0.030523933470249176
Validation loss: 1.4894062383200533

Epoch: 6| Step: 8
Training loss: 0.051512427628040314
Validation loss: 1.4632142596347357

Epoch: 6| Step: 9
Training loss: 0.07346606254577637
Validation loss: 1.4783783522985314

Epoch: 6| Step: 10
Training loss: 0.0538543164730072
Validation loss: 1.465688874644618

Epoch: 6| Step: 11
Training loss: 0.04506325721740723
Validation loss: 1.4483349861637238

Epoch: 6| Step: 12
Training loss: 0.09287644922733307
Validation loss: 1.4807901010718396

Epoch: 6| Step: 13
Training loss: 0.04315885901451111
Validation loss: 1.4839380671901088

Epoch: 692| Step: 0
Training loss: 0.049180768430233
Validation loss: 1.4785068945218158

Epoch: 6| Step: 1
Training loss: 0.04087309166789055
Validation loss: 1.501283117519912

Epoch: 6| Step: 2
Training loss: 0.03946617245674133
Validation loss: 1.5139189945754183

Epoch: 6| Step: 3
Training loss: 0.07487992197275162
Validation loss: 1.495403092394593

Epoch: 6| Step: 4
Training loss: 0.07674120366573334
Validation loss: 1.5022415807170253

Epoch: 6| Step: 5
Training loss: 0.0656910389661789
Validation loss: 1.5038684093823997

Epoch: 6| Step: 6
Training loss: 0.051766134798526764
Validation loss: 1.5040032748253114

Epoch: 6| Step: 7
Training loss: 0.07978960126638412
Validation loss: 1.508143719806466

Epoch: 6| Step: 8
Training loss: 0.05047370120882988
Validation loss: 1.5114486999409174

Epoch: 6| Step: 9
Training loss: 0.048688966780900955
Validation loss: 1.5249181139853694

Epoch: 6| Step: 10
Training loss: 0.05842144787311554
Validation loss: 1.511952889862881

Epoch: 6| Step: 11
Training loss: 0.07884052395820618
Validation loss: 1.505008061726888

Epoch: 6| Step: 12
Training loss: 0.04949963837862015
Validation loss: 1.526062652628909

Epoch: 6| Step: 13
Training loss: 0.09140346944332123
Validation loss: 1.5299343255258375

Epoch: 693| Step: 0
Training loss: 0.03996473550796509
Validation loss: 1.5160557467450377

Epoch: 6| Step: 1
Training loss: 0.05246585234999657
Validation loss: 1.4910568870523924

Epoch: 6| Step: 2
Training loss: 0.03712444007396698
Validation loss: 1.5037274347838534

Epoch: 6| Step: 3
Training loss: 0.03038325533270836
Validation loss: 1.4949017186318674

Epoch: 6| Step: 4
Training loss: 0.04799525439739227
Validation loss: 1.511647657681537

Epoch: 6| Step: 5
Training loss: 0.05261566862463951
Validation loss: 1.517415859365976

Epoch: 6| Step: 6
Training loss: 0.04926952347159386
Validation loss: 1.5234678740142493

Epoch: 6| Step: 7
Training loss: 0.03899837285280228
Validation loss: 1.5421935999265282

Epoch: 6| Step: 8
Training loss: 0.03175672888755798
Validation loss: 1.5378467382923249

Epoch: 6| Step: 9
Training loss: 0.10055883228778839
Validation loss: 1.5431437812825686

Epoch: 6| Step: 10
Training loss: 0.0871187299489975
Validation loss: 1.5501998034856652

Epoch: 6| Step: 11
Training loss: 0.05159299820661545
Validation loss: 1.536706893674789

Epoch: 6| Step: 12
Training loss: 0.049765244126319885
Validation loss: 1.5580850455068773

Epoch: 6| Step: 13
Training loss: 0.0701754242181778
Validation loss: 1.545786642259167

Epoch: 694| Step: 0
Training loss: 0.059600699692964554
Validation loss: 1.5416264585269395

Epoch: 6| Step: 1
Training loss: 0.112784743309021
Validation loss: 1.5642611108800417

Epoch: 6| Step: 2
Training loss: 0.05210883542895317
Validation loss: 1.5389582726263231

Epoch: 6| Step: 3
Training loss: 0.08057869225740433
Validation loss: 1.5498760028551983

Epoch: 6| Step: 4
Training loss: 0.0760241150856018
Validation loss: 1.5299971795851184

Epoch: 6| Step: 5
Training loss: 0.05218936875462532
Validation loss: 1.5342065108719694

Epoch: 6| Step: 6
Training loss: 0.04163965955376625
Validation loss: 1.5415320383605136

Epoch: 6| Step: 7
Training loss: 0.07569998502731323
Validation loss: 1.5417277210502214

Epoch: 6| Step: 8
Training loss: 0.05842778459191322
Validation loss: 1.5288349249029671

Epoch: 6| Step: 9
Training loss: 0.02470373921096325
Validation loss: 1.524714610909903

Epoch: 6| Step: 10
Training loss: 0.04564101994037628
Validation loss: 1.539326734440301

Epoch: 6| Step: 11
Training loss: 0.056811653077602386
Validation loss: 1.5398098704635457

Epoch: 6| Step: 12
Training loss: 0.054516199976205826
Validation loss: 1.5597203290590675

Epoch: 6| Step: 13
Training loss: 0.07294254750013351
Validation loss: 1.559786460732901

Epoch: 695| Step: 0
Training loss: 0.057533081620931625
Validation loss: 1.5516553130201114

Epoch: 6| Step: 1
Training loss: 0.03907332569360733
Validation loss: 1.5383028471341698

Epoch: 6| Step: 2
Training loss: 0.06954757124185562
Validation loss: 1.55271263148195

Epoch: 6| Step: 3
Training loss: 0.04495556280016899
Validation loss: 1.530592180067493

Epoch: 6| Step: 4
Training loss: 0.07187077403068542
Validation loss: 1.5399602869505524

Epoch: 6| Step: 5
Training loss: 0.0439196452498436
Validation loss: 1.5454886933808685

Epoch: 6| Step: 6
Training loss: 0.05777478963136673
Validation loss: 1.5162137823720132

Epoch: 6| Step: 7
Training loss: 0.04583407938480377
Validation loss: 1.5164915233530023

Epoch: 6| Step: 8
Training loss: 0.025782756507396698
Validation loss: 1.5127308740410754

Epoch: 6| Step: 9
Training loss: 0.08897003531455994
Validation loss: 1.509983721599784

Epoch: 6| Step: 10
Training loss: 0.029059994965791702
Validation loss: 1.504139974553098

Epoch: 6| Step: 11
Training loss: 0.05866512283682823
Validation loss: 1.5118582197414931

Epoch: 6| Step: 12
Training loss: 0.03574611246585846
Validation loss: 1.5200227716917634

Epoch: 6| Step: 13
Training loss: 0.07785268127918243
Validation loss: 1.5579897024298226

Epoch: 696| Step: 0
Training loss: 0.06105104833841324
Validation loss: 1.558488453588178

Epoch: 6| Step: 1
Training loss: 0.0909067690372467
Validation loss: 1.5502502713152158

Epoch: 6| Step: 2
Training loss: 0.04923916608095169
Validation loss: 1.5236449036546933

Epoch: 6| Step: 3
Training loss: 0.10368283092975616
Validation loss: 1.5069405494197723

Epoch: 6| Step: 4
Training loss: 0.07871000468730927
Validation loss: 1.5100488906265588

Epoch: 6| Step: 5
Training loss: 0.05423811078071594
Validation loss: 1.5190580788479056

Epoch: 6| Step: 6
Training loss: 0.04950804263353348
Validation loss: 1.51827553138938

Epoch: 6| Step: 7
Training loss: 0.06051009148359299
Validation loss: 1.5067070184215423

Epoch: 6| Step: 8
Training loss: 0.057022638618946075
Validation loss: 1.520837103166888

Epoch: 6| Step: 9
Training loss: 0.04360492527484894
Validation loss: 1.5048138710760302

Epoch: 6| Step: 10
Training loss: 0.03933533653616905
Validation loss: 1.5048259304415794

Epoch: 6| Step: 11
Training loss: 0.047406405210494995
Validation loss: 1.516942290849583

Epoch: 6| Step: 12
Training loss: 0.07196779549121857
Validation loss: 1.5211633789923884

Epoch: 6| Step: 13
Training loss: 0.04596686363220215
Validation loss: 1.5181411120199388

Epoch: 697| Step: 0
Training loss: 0.05473313480615616
Validation loss: 1.5078969386316114

Epoch: 6| Step: 1
Training loss: 0.06732378900051117
Validation loss: 1.4956156694760887

Epoch: 6| Step: 2
Training loss: 0.037538476288318634
Validation loss: 1.4964568768778155

Epoch: 6| Step: 3
Training loss: 0.04864134639501572
Validation loss: 1.5088765441730458

Epoch: 6| Step: 4
Training loss: 0.038478292524814606
Validation loss: 1.5008647646955264

Epoch: 6| Step: 5
Training loss: 0.057098791003227234
Validation loss: 1.5012786567852061

Epoch: 6| Step: 6
Training loss: 0.07190601527690887
Validation loss: 1.4954006710360128

Epoch: 6| Step: 7
Training loss: 0.06472982466220856
Validation loss: 1.52779261912069

Epoch: 6| Step: 8
Training loss: 0.0574507936835289
Validation loss: 1.5239727811146808

Epoch: 6| Step: 9
Training loss: 0.03526681661605835
Validation loss: 1.501880556024531

Epoch: 6| Step: 10
Training loss: 0.06099623441696167
Validation loss: 1.524830146502423

Epoch: 6| Step: 11
Training loss: 0.044270679354667664
Validation loss: 1.5237779040490427

Epoch: 6| Step: 12
Training loss: 0.04853560030460358
Validation loss: 1.5392591837913758

Epoch: 6| Step: 13
Training loss: 0.04993969947099686
Validation loss: 1.5643765580269597

Epoch: 698| Step: 0
Training loss: 0.07626877725124359
Validation loss: 1.5596306042004657

Epoch: 6| Step: 1
Training loss: 0.07706523686647415
Validation loss: 1.516333613344418

Epoch: 6| Step: 2
Training loss: 0.09045366942882538
Validation loss: 1.5266917802954232

Epoch: 6| Step: 3
Training loss: 0.08199772238731384
Validation loss: 1.530133762667256

Epoch: 6| Step: 4
Training loss: 0.047713980078697205
Validation loss: 1.5279503637744534

Epoch: 6| Step: 5
Training loss: 0.03604264557361603
Validation loss: 1.5075858203313683

Epoch: 6| Step: 6
Training loss: 0.05222298204898834
Validation loss: 1.5208132779726418

Epoch: 6| Step: 7
Training loss: 0.05859173834323883
Validation loss: 1.5128147294444423

Epoch: 6| Step: 8
Training loss: 0.037447214126586914
Validation loss: 1.52717625710272

Epoch: 6| Step: 9
Training loss: 0.04078490287065506
Validation loss: 1.5096796968931794

Epoch: 6| Step: 10
Training loss: 0.027915872633457184
Validation loss: 1.4920597230234454

Epoch: 6| Step: 11
Training loss: 0.06536077708005905
Validation loss: 1.492870448738016

Epoch: 6| Step: 12
Training loss: 0.07689201831817627
Validation loss: 1.5141573234270977

Epoch: 6| Step: 13
Training loss: 0.03968353942036629
Validation loss: 1.4953776713340514

Epoch: 699| Step: 0
Training loss: 0.033584654331207275
Validation loss: 1.5218983286170549

Epoch: 6| Step: 1
Training loss: 0.06783325225114822
Validation loss: 1.5152039873984553

Epoch: 6| Step: 2
Training loss: 0.05459939315915108
Validation loss: 1.5211141417103429

Epoch: 6| Step: 3
Training loss: 0.059734150767326355
Validation loss: 1.496956544537698

Epoch: 6| Step: 4
Training loss: 0.06174035370349884
Validation loss: 1.5250100922840897

Epoch: 6| Step: 5
Training loss: 0.03239927068352699
Validation loss: 1.5062443312778269

Epoch: 6| Step: 6
Training loss: 0.06221572682261467
Validation loss: 1.5159666743329776

Epoch: 6| Step: 7
Training loss: 0.06339963525533676
Validation loss: 1.4998607840589298

Epoch: 6| Step: 8
Training loss: 0.06595805287361145
Validation loss: 1.4970992380572903

Epoch: 6| Step: 9
Training loss: 0.026941796764731407
Validation loss: 1.5033168126178045

Epoch: 6| Step: 10
Training loss: 0.06110134348273277
Validation loss: 1.5126133977725942

Epoch: 6| Step: 11
Training loss: 0.041298311203718185
Validation loss: 1.5153004661683114

Epoch: 6| Step: 12
Training loss: 0.06729451566934586
Validation loss: 1.5070985171102709

Epoch: 6| Step: 13
Training loss: 0.06213716045022011
Validation loss: 1.5177088475996448

Epoch: 700| Step: 0
Training loss: 0.05581921711564064
Validation loss: 1.5271945281695294

Epoch: 6| Step: 1
Training loss: 0.061245664954185486
Validation loss: 1.5091786570446466

Epoch: 6| Step: 2
Training loss: 0.05844179913401604
Validation loss: 1.518847498842465

Epoch: 6| Step: 3
Training loss: 0.037044405937194824
Validation loss: 1.5199603778059765

Epoch: 6| Step: 4
Training loss: 0.04708171635866165
Validation loss: 1.5294984245813021

Epoch: 6| Step: 5
Training loss: 0.04041173309087753
Validation loss: 1.5362604728309057

Epoch: 6| Step: 6
Training loss: 0.06593212485313416
Validation loss: 1.5326049507305186

Epoch: 6| Step: 7
Training loss: 0.05467823147773743
Validation loss: 1.5518673068733626

Epoch: 6| Step: 8
Training loss: 0.08203910291194916
Validation loss: 1.546914892811929

Epoch: 6| Step: 9
Training loss: 0.036063823848962784
Validation loss: 1.5221776821280038

Epoch: 6| Step: 10
Training loss: 0.040886640548706055
Validation loss: 1.5349811674446188

Epoch: 6| Step: 11
Training loss: 0.08482561260461807
Validation loss: 1.521115312653203

Epoch: 6| Step: 12
Training loss: 0.038001082837581635
Validation loss: 1.505210268882013

Epoch: 6| Step: 13
Training loss: 0.07995165139436722
Validation loss: 1.5154778265183972

Epoch: 701| Step: 0
Training loss: 0.046389803290367126
Validation loss: 1.5234947358408282

Epoch: 6| Step: 1
Training loss: 0.08837825059890747
Validation loss: 1.521251356729897

Epoch: 6| Step: 2
Training loss: 0.0767626091837883
Validation loss: 1.5165411618448073

Epoch: 6| Step: 3
Training loss: 0.047716181725263596
Validation loss: 1.5248731746468493

Epoch: 6| Step: 4
Training loss: 0.04465639591217041
Validation loss: 1.5214044253031414

Epoch: 6| Step: 5
Training loss: 0.03320259600877762
Validation loss: 1.5264395667660622

Epoch: 6| Step: 6
Training loss: 0.05780865252017975
Validation loss: 1.5226961438373854

Epoch: 6| Step: 7
Training loss: 0.019996413961052895
Validation loss: 1.517822975753456

Epoch: 6| Step: 8
Training loss: 0.06253771483898163
Validation loss: 1.5169469771846649

Epoch: 6| Step: 9
Training loss: 0.036256082355976105
Validation loss: 1.49947371790486

Epoch: 6| Step: 10
Training loss: 0.06975759565830231
Validation loss: 1.5245086428939656

Epoch: 6| Step: 11
Training loss: 0.05619607865810394
Validation loss: 1.506777637748308

Epoch: 6| Step: 12
Training loss: 0.05754317343235016
Validation loss: 1.5165634642365158

Epoch: 6| Step: 13
Training loss: 0.08142605423927307
Validation loss: 1.489936110152993

Epoch: 702| Step: 0
Training loss: 0.05828242003917694
Validation loss: 1.4905263275228522

Epoch: 6| Step: 1
Training loss: 0.04823383688926697
Validation loss: 1.4894883799296554

Epoch: 6| Step: 2
Training loss: 0.11364266276359558
Validation loss: 1.4922193904076853

Epoch: 6| Step: 3
Training loss: 0.03971204161643982
Validation loss: 1.499184626404957

Epoch: 6| Step: 4
Training loss: 0.024791095405817032
Validation loss: 1.5169923049147411

Epoch: 6| Step: 5
Training loss: 0.038443394005298615
Validation loss: 1.5242758950879496

Epoch: 6| Step: 6
Training loss: 0.07508502900600433
Validation loss: 1.5317697563479025

Epoch: 6| Step: 7
Training loss: 0.041807226836681366
Validation loss: 1.5591029197938981

Epoch: 6| Step: 8
Training loss: 0.05690948665142059
Validation loss: 1.5455827411784921

Epoch: 6| Step: 9
Training loss: 0.033637434244155884
Validation loss: 1.5400613123370754

Epoch: 6| Step: 10
Training loss: 0.03329068794846535
Validation loss: 1.5020861933308263

Epoch: 6| Step: 11
Training loss: 0.05978405848145485
Validation loss: 1.5108026830098962

Epoch: 6| Step: 12
Training loss: 0.06602823734283447
Validation loss: 1.513099205109381

Epoch: 6| Step: 13
Training loss: 0.029051555320620537
Validation loss: 1.525220545389319

Epoch: 703| Step: 0
Training loss: 0.05281343311071396
Validation loss: 1.5246189871141989

Epoch: 6| Step: 1
Training loss: 0.038876235485076904
Validation loss: 1.5157131507832518

Epoch: 6| Step: 2
Training loss: 0.04629957675933838
Validation loss: 1.5196121418347923

Epoch: 6| Step: 3
Training loss: 0.0915803611278534
Validation loss: 1.5329711296225106

Epoch: 6| Step: 4
Training loss: 0.0766654908657074
Validation loss: 1.5442070320088377

Epoch: 6| Step: 5
Training loss: 0.04669826850295067
Validation loss: 1.5247632226636332

Epoch: 6| Step: 6
Training loss: 0.05332644656300545
Validation loss: 1.5183436024573542

Epoch: 6| Step: 7
Training loss: 0.042814742773771286
Validation loss: 1.5105028806194183

Epoch: 6| Step: 8
Training loss: 0.052608683705329895
Validation loss: 1.5194550329639065

Epoch: 6| Step: 9
Training loss: 0.05867914855480194
Validation loss: 1.5058058493880815

Epoch: 6| Step: 10
Training loss: 0.04193364456295967
Validation loss: 1.5080154839382376

Epoch: 6| Step: 11
Training loss: 0.059211596846580505
Validation loss: 1.495607477362438

Epoch: 6| Step: 12
Training loss: 0.04027494043111801
Validation loss: 1.521742691275894

Epoch: 6| Step: 13
Training loss: 0.0549197643995285
Validation loss: 1.5261325541362967

Epoch: 704| Step: 0
Training loss: 0.04270128160715103
Validation loss: 1.5181697145585091

Epoch: 6| Step: 1
Training loss: 0.04706986993551254
Validation loss: 1.5171460695164178

Epoch: 6| Step: 2
Training loss: 0.04139184206724167
Validation loss: 1.5040896451601418

Epoch: 6| Step: 3
Training loss: 0.06146861985325813
Validation loss: 1.5001188580707838

Epoch: 6| Step: 4
Training loss: 0.038834135979413986
Validation loss: 1.5241854870191185

Epoch: 6| Step: 5
Training loss: 0.06172362342476845
Validation loss: 1.5436137850566576

Epoch: 6| Step: 6
Training loss: 0.039653073996305466
Validation loss: 1.5520837371067335

Epoch: 6| Step: 7
Training loss: 0.04791886359453201
Validation loss: 1.5370729456665695

Epoch: 6| Step: 8
Training loss: 0.04958430677652359
Validation loss: 1.5363856797577233

Epoch: 6| Step: 9
Training loss: 0.04402439296245575
Validation loss: 1.5208679258182485

Epoch: 6| Step: 10
Training loss: 0.0913238674402237
Validation loss: 1.5290692493479738

Epoch: 6| Step: 11
Training loss: 0.060397133231163025
Validation loss: 1.5158592193357405

Epoch: 6| Step: 12
Training loss: 0.05026997625827789
Validation loss: 1.5052397507493214

Epoch: 6| Step: 13
Training loss: 0.027750663459300995
Validation loss: 1.5098275003894683

Epoch: 705| Step: 0
Training loss: 0.06763140857219696
Validation loss: 1.4916808592375888

Epoch: 6| Step: 1
Training loss: 0.12479809671640396
Validation loss: 1.5194466171726104

Epoch: 6| Step: 2
Training loss: 0.07682180404663086
Validation loss: 1.514773638017716

Epoch: 6| Step: 3
Training loss: 0.03376367688179016
Validation loss: 1.4923198018022763

Epoch: 6| Step: 4
Training loss: 0.05010052025318146
Validation loss: 1.509892878993865

Epoch: 6| Step: 5
Training loss: 0.08538114279508591
Validation loss: 1.5137918367180774

Epoch: 6| Step: 6
Training loss: 0.06742985546588898
Validation loss: 1.5290834339716102

Epoch: 6| Step: 7
Training loss: 0.04257965832948685
Validation loss: 1.5305343289529123

Epoch: 6| Step: 8
Training loss: 0.08403588831424713
Validation loss: 1.546124058385049

Epoch: 6| Step: 9
Training loss: 0.09231126308441162
Validation loss: 1.5664572702941073

Epoch: 6| Step: 10
Training loss: 0.037299077957868576
Validation loss: 1.5422619235131048

Epoch: 6| Step: 11
Training loss: 0.03826066851615906
Validation loss: 1.5288179741110852

Epoch: 6| Step: 12
Training loss: 0.038482729345560074
Validation loss: 1.5294876842088596

Epoch: 6| Step: 13
Training loss: 0.040755920112133026
Validation loss: 1.5388175172190512

Epoch: 706| Step: 0
Training loss: 0.06844581663608551
Validation loss: 1.522005985500992

Epoch: 6| Step: 1
Training loss: 0.06764481961727142
Validation loss: 1.4940920279872032

Epoch: 6| Step: 2
Training loss: 0.09185267984867096
Validation loss: 1.5337320630268385

Epoch: 6| Step: 3
Training loss: 0.045512691140174866
Validation loss: 1.5521475845767605

Epoch: 6| Step: 4
Training loss: 0.07399863004684448
Validation loss: 1.5780954636553282

Epoch: 6| Step: 5
Training loss: 0.12878093123435974
Validation loss: 1.5625681684863182

Epoch: 6| Step: 6
Training loss: 0.06300777941942215
Validation loss: 1.5712438501337522

Epoch: 6| Step: 7
Training loss: 0.06564638763666153
Validation loss: 1.532684273617242

Epoch: 6| Step: 8
Training loss: 0.048184383660554886
Validation loss: 1.5238092432739914

Epoch: 6| Step: 9
Training loss: 0.054290540516376495
Validation loss: 1.5094955954500424

Epoch: 6| Step: 10
Training loss: 0.054784275591373444
Validation loss: 1.5039441816268428

Epoch: 6| Step: 11
Training loss: 0.043483003973960876
Validation loss: 1.510456621005971

Epoch: 6| Step: 12
Training loss: 0.0886235311627388
Validation loss: 1.5109784744119132

Epoch: 6| Step: 13
Training loss: 0.04744308441877365
Validation loss: 1.508721770778779

Epoch: 707| Step: 0
Training loss: 0.10680623352527618
Validation loss: 1.5034126139456225

Epoch: 6| Step: 1
Training loss: 0.04805921018123627
Validation loss: 1.5279742248596684

Epoch: 6| Step: 2
Training loss: 0.035526737570762634
Validation loss: 1.508721536205661

Epoch: 6| Step: 3
Training loss: 0.07123953104019165
Validation loss: 1.484734531371824

Epoch: 6| Step: 4
Training loss: 0.05086848884820938
Validation loss: 1.5193663566343245

Epoch: 6| Step: 5
Training loss: 0.06224323809146881
Validation loss: 1.488316100130799

Epoch: 6| Step: 6
Training loss: 0.0806487426161766
Validation loss: 1.4959590319664247

Epoch: 6| Step: 7
Training loss: 0.06158297881484032
Validation loss: 1.4972734541021369

Epoch: 6| Step: 8
Training loss: 0.09345728158950806
Validation loss: 1.4885997208215858

Epoch: 6| Step: 9
Training loss: 0.08239840716123581
Validation loss: 1.4937797887350923

Epoch: 6| Step: 10
Training loss: 0.06390109658241272
Validation loss: 1.4868187596721034

Epoch: 6| Step: 11
Training loss: 0.0820685550570488
Validation loss: 1.4964341361035582

Epoch: 6| Step: 12
Training loss: 0.08012319356203079
Validation loss: 1.4750427558857908

Epoch: 6| Step: 13
Training loss: 0.06222330033779144
Validation loss: 1.4737238922426779

Epoch: 708| Step: 0
Training loss: 0.05707821995019913
Validation loss: 1.4866159167341007

Epoch: 6| Step: 1
Training loss: 0.0367116741836071
Validation loss: 1.4831232037595523

Epoch: 6| Step: 2
Training loss: 0.060964733362197876
Validation loss: 1.4848026344853062

Epoch: 6| Step: 3
Training loss: 0.06468797475099564
Validation loss: 1.512142543510724

Epoch: 6| Step: 4
Training loss: 0.07145315408706665
Validation loss: 1.5293154690855293

Epoch: 6| Step: 5
Training loss: 0.07651598751544952
Validation loss: 1.5444966247004848

Epoch: 6| Step: 6
Training loss: 0.06625483930110931
Validation loss: 1.5381983698055308

Epoch: 6| Step: 7
Training loss: 0.10002540051937103
Validation loss: 1.5405502998700706

Epoch: 6| Step: 8
Training loss: 0.08244125545024872
Validation loss: 1.538124002436156

Epoch: 6| Step: 9
Training loss: 0.08153365552425385
Validation loss: 1.53293195655269

Epoch: 6| Step: 10
Training loss: 0.09855347871780396
Validation loss: 1.5194030474590998

Epoch: 6| Step: 11
Training loss: 0.040068842470645905
Validation loss: 1.4998689646361976

Epoch: 6| Step: 12
Training loss: 0.09928250312805176
Validation loss: 1.5211318180125246

Epoch: 6| Step: 13
Training loss: 0.035089150071144104
Validation loss: 1.5179682989274301

Epoch: 709| Step: 0
Training loss: 0.05259445682168007
Validation loss: 1.5426629922723258

Epoch: 6| Step: 1
Training loss: 0.05989029258489609
Validation loss: 1.5380026243066276

Epoch: 6| Step: 2
Training loss: 0.03480754792690277
Validation loss: 1.5328419939164193

Epoch: 6| Step: 3
Training loss: 0.05282953754067421
Validation loss: 1.5207831218678465

Epoch: 6| Step: 4
Training loss: 0.03889740630984306
Validation loss: 1.5518546001885527

Epoch: 6| Step: 5
Training loss: 0.06989356130361557
Validation loss: 1.5490238397352156

Epoch: 6| Step: 6
Training loss: 0.05699894204735756
Validation loss: 1.587331429604561

Epoch: 6| Step: 7
Training loss: 0.11849196255207062
Validation loss: 1.5902832361959642

Epoch: 6| Step: 8
Training loss: 0.04429524391889572
Validation loss: 1.5684564228980773

Epoch: 6| Step: 9
Training loss: 0.05709420144557953
Validation loss: 1.580095637229181

Epoch: 6| Step: 10
Training loss: 0.044798023998737335
Validation loss: 1.5750481197910924

Epoch: 6| Step: 11
Training loss: 0.04112766683101654
Validation loss: 1.5666021928992322

Epoch: 6| Step: 12
Training loss: 0.07704218477010727
Validation loss: 1.5483922407191286

Epoch: 6| Step: 13
Training loss: 0.07721108943223953
Validation loss: 1.533290788691531

Epoch: 710| Step: 0
Training loss: 0.05734628438949585
Validation loss: 1.5313162611376854

Epoch: 6| Step: 1
Training loss: 0.0604778528213501
Validation loss: 1.5613647366082797

Epoch: 6| Step: 2
Training loss: 0.06573310494422913
Validation loss: 1.5360847942290767

Epoch: 6| Step: 3
Training loss: 0.09414660930633545
Validation loss: 1.5394228760914137

Epoch: 6| Step: 4
Training loss: 0.03849536553025246
Validation loss: 1.5415479470324773

Epoch: 6| Step: 5
Training loss: 0.05747951194643974
Validation loss: 1.5421018010826522

Epoch: 6| Step: 6
Training loss: 0.05214131250977516
Validation loss: 1.5286944373961417

Epoch: 6| Step: 7
Training loss: 0.07307606935501099
Validation loss: 1.535765205660174

Epoch: 6| Step: 8
Training loss: 0.044877778738737106
Validation loss: 1.5502911357469455

Epoch: 6| Step: 9
Training loss: 0.0688033327460289
Validation loss: 1.5669246924820768

Epoch: 6| Step: 10
Training loss: 0.07933381199836731
Validation loss: 1.534433783382498

Epoch: 6| Step: 11
Training loss: 0.058742374181747437
Validation loss: 1.5184954154875971

Epoch: 6| Step: 12
Training loss: 0.0595971941947937
Validation loss: 1.5487783455079602

Epoch: 6| Step: 13
Training loss: 0.07018569111824036
Validation loss: 1.5309083795034757

Epoch: 711| Step: 0
Training loss: 0.09262467175722122
Validation loss: 1.5330904645304526

Epoch: 6| Step: 1
Training loss: 0.07461593300104141
Validation loss: 1.520274277656309

Epoch: 6| Step: 2
Training loss: 0.06643062084913254
Validation loss: 1.5139173179544427

Epoch: 6| Step: 3
Training loss: 0.029615625739097595
Validation loss: 1.5192421187636673

Epoch: 6| Step: 4
Training loss: 0.04158497601747513
Validation loss: 1.5175342431632421

Epoch: 6| Step: 5
Training loss: 0.06967360526323318
Validation loss: 1.5238637270465973

Epoch: 6| Step: 6
Training loss: 0.07694927603006363
Validation loss: 1.5243918357356903

Epoch: 6| Step: 7
Training loss: 0.05104978382587433
Validation loss: 1.4800386980015745

Epoch: 6| Step: 8
Training loss: 0.04075809568166733
Validation loss: 1.491518093693641

Epoch: 6| Step: 9
Training loss: 0.048567481338977814
Validation loss: 1.504916166746488

Epoch: 6| Step: 10
Training loss: 0.04239121824502945
Validation loss: 1.489732075763005

Epoch: 6| Step: 11
Training loss: 0.06833168864250183
Validation loss: 1.5027424314970612

Epoch: 6| Step: 12
Training loss: 0.088828444480896
Validation loss: 1.5004081553028477

Epoch: 6| Step: 13
Training loss: 0.07381696254014969
Validation loss: 1.5336580750762776

Epoch: 712| Step: 0
Training loss: 0.06485304981470108
Validation loss: 1.5134304056885421

Epoch: 6| Step: 1
Training loss: 0.04866606369614601
Validation loss: 1.54542379097272

Epoch: 6| Step: 2
Training loss: 0.054659295827150345
Validation loss: 1.5381929105327976

Epoch: 6| Step: 3
Training loss: 0.05865645408630371
Validation loss: 1.5343155630173222

Epoch: 6| Step: 4
Training loss: 0.0659249871969223
Validation loss: 1.5506721568363968

Epoch: 6| Step: 5
Training loss: 0.060973286628723145
Validation loss: 1.571374588115241

Epoch: 6| Step: 6
Training loss: 0.09994370490312576
Validation loss: 1.5862527572980492

Epoch: 6| Step: 7
Training loss: 0.07916035503149033
Validation loss: 1.557627147243869

Epoch: 6| Step: 8
Training loss: 0.07129344344139099
Validation loss: 1.5391796776043472

Epoch: 6| Step: 9
Training loss: 0.05732617899775505
Validation loss: 1.5383486286286385

Epoch: 6| Step: 10
Training loss: 0.05928830802440643
Validation loss: 1.5422541351728543

Epoch: 6| Step: 11
Training loss: 0.06572005897760391
Validation loss: 1.544635998305454

Epoch: 6| Step: 12
Training loss: 0.04449988901615143
Validation loss: 1.5190791007011168

Epoch: 6| Step: 13
Training loss: 0.1046452596783638
Validation loss: 1.5266512196551087

Epoch: 713| Step: 0
Training loss: 0.04294540733098984
Validation loss: 1.5177787318024585

Epoch: 6| Step: 1
Training loss: 0.08711271733045578
Validation loss: 1.528644492549281

Epoch: 6| Step: 2
Training loss: 0.046021636575460434
Validation loss: 1.5326947396801365

Epoch: 6| Step: 3
Training loss: 0.03142194449901581
Validation loss: 1.5301899307517595

Epoch: 6| Step: 4
Training loss: 0.03028164617717266
Validation loss: 1.5192111986939625

Epoch: 6| Step: 5
Training loss: 0.09017077088356018
Validation loss: 1.5573848524401266

Epoch: 6| Step: 6
Training loss: 0.05547131597995758
Validation loss: 1.5752887341283983

Epoch: 6| Step: 7
Training loss: 0.05178075656294823
Validation loss: 1.5491094486687773

Epoch: 6| Step: 8
Training loss: 0.03592608869075775
Validation loss: 1.571786799738484

Epoch: 6| Step: 9
Training loss: 0.05342062562704086
Validation loss: 1.5854765727955809

Epoch: 6| Step: 10
Training loss: 0.03622446954250336
Validation loss: 1.5786184457040602

Epoch: 6| Step: 11
Training loss: 0.045984357595443726
Validation loss: 1.552869341706717

Epoch: 6| Step: 12
Training loss: 0.03249719738960266
Validation loss: 1.5586907222706785

Epoch: 6| Step: 13
Training loss: 0.0524299293756485
Validation loss: 1.5396563776077763

Epoch: 714| Step: 0
Training loss: 0.036413051187992096
Validation loss: 1.51673347591072

Epoch: 6| Step: 1
Training loss: 0.03383389860391617
Validation loss: 1.5205574625281877

Epoch: 6| Step: 2
Training loss: 0.04180915653705597
Validation loss: 1.516327267052025

Epoch: 6| Step: 3
Training loss: 0.051031023263931274
Validation loss: 1.515142383113984

Epoch: 6| Step: 4
Training loss: 0.07868123054504395
Validation loss: 1.5106554377463557

Epoch: 6| Step: 5
Training loss: 0.04199103266000748
Validation loss: 1.5459339964774348

Epoch: 6| Step: 6
Training loss: 0.07179310917854309
Validation loss: 1.508024133661742

Epoch: 6| Step: 7
Training loss: 0.051307037472724915
Validation loss: 1.5271554839226507

Epoch: 6| Step: 8
Training loss: 0.06501898169517517
Validation loss: 1.5292941818955124

Epoch: 6| Step: 9
Training loss: 0.06260484457015991
Validation loss: 1.5216940551675775

Epoch: 6| Step: 10
Training loss: 0.08878269791603088
Validation loss: 1.535777662390022

Epoch: 6| Step: 11
Training loss: 0.06750012189149857
Validation loss: 1.5431587247438328

Epoch: 6| Step: 12
Training loss: 0.10442361235618591
Validation loss: 1.5795483460990332

Epoch: 6| Step: 13
Training loss: 0.05283217877149582
Validation loss: 1.5710800206789406

Epoch: 715| Step: 0
Training loss: 0.06651744991540909
Validation loss: 1.5537688809056436

Epoch: 6| Step: 1
Training loss: 0.053875405341386795
Validation loss: 1.5605008922597414

Epoch: 6| Step: 2
Training loss: 0.05227108299732208
Validation loss: 1.5586335107844362

Epoch: 6| Step: 3
Training loss: 0.033644743263721466
Validation loss: 1.5662823415571643

Epoch: 6| Step: 4
Training loss: 0.05281754583120346
Validation loss: 1.5490887998252787

Epoch: 6| Step: 5
Training loss: 0.12398283928632736
Validation loss: 1.5216513705509964

Epoch: 6| Step: 6
Training loss: 0.055545780807733536
Validation loss: 1.5329152922476492

Epoch: 6| Step: 7
Training loss: 0.054982639849185944
Validation loss: 1.5205020622540546

Epoch: 6| Step: 8
Training loss: 0.049634769558906555
Validation loss: 1.541826617333197

Epoch: 6| Step: 9
Training loss: 0.04228511080145836
Validation loss: 1.5308764724321262

Epoch: 6| Step: 10
Training loss: 0.04403696954250336
Validation loss: 1.5275469101885313

Epoch: 6| Step: 11
Training loss: 0.045713555067777634
Validation loss: 1.5138817115496563

Epoch: 6| Step: 12
Training loss: 0.04798421263694763
Validation loss: 1.53404450672929

Epoch: 6| Step: 13
Training loss: 0.04909634590148926
Validation loss: 1.5307262969273392

Epoch: 716| Step: 0
Training loss: 0.04626493901014328
Validation loss: 1.5169791380564372

Epoch: 6| Step: 1
Training loss: 0.04583064094185829
Validation loss: 1.5161701966357488

Epoch: 6| Step: 2
Training loss: 0.022240187972784042
Validation loss: 1.4950974577216691

Epoch: 6| Step: 3
Training loss: 0.04955955594778061
Validation loss: 1.522836987690259

Epoch: 6| Step: 4
Training loss: 0.07830525189638138
Validation loss: 1.509753752780217

Epoch: 6| Step: 5
Training loss: 0.05393517017364502
Validation loss: 1.5223563486529934

Epoch: 6| Step: 6
Training loss: 0.07390770316123962
Validation loss: 1.5156172398597962

Epoch: 6| Step: 7
Training loss: 0.05016447603702545
Validation loss: 1.4962249199549358

Epoch: 6| Step: 8
Training loss: 0.06703190505504608
Validation loss: 1.5046976548369213

Epoch: 6| Step: 9
Training loss: 0.06307990849018097
Validation loss: 1.5250262419382732

Epoch: 6| Step: 10
Training loss: 0.04933607950806618
Validation loss: 1.5209288815016389

Epoch: 6| Step: 11
Training loss: 0.079598568379879
Validation loss: 1.5416922582093107

Epoch: 6| Step: 12
Training loss: 0.059345610439777374
Validation loss: 1.5382569195121847

Epoch: 6| Step: 13
Training loss: 0.059974413365125656
Validation loss: 1.5183836695968465

Epoch: 717| Step: 0
Training loss: 0.0584271177649498
Validation loss: 1.5352541708177136

Epoch: 6| Step: 1
Training loss: 0.043008364737033844
Validation loss: 1.5165659304588073

Epoch: 6| Step: 2
Training loss: 0.04669225215911865
Validation loss: 1.4904517178894372

Epoch: 6| Step: 3
Training loss: 0.05783829092979431
Validation loss: 1.5120194368464972

Epoch: 6| Step: 4
Training loss: 0.044638991355895996
Validation loss: 1.523227431440866

Epoch: 6| Step: 5
Training loss: 0.10182608664035797
Validation loss: 1.5315459518022434

Epoch: 6| Step: 6
Training loss: 0.0471932590007782
Validation loss: 1.5342446065718127

Epoch: 6| Step: 7
Training loss: 0.08768005669116974
Validation loss: 1.5307791604790637

Epoch: 6| Step: 8
Training loss: 0.04985569417476654
Validation loss: 1.5244947729572174

Epoch: 6| Step: 9
Training loss: 0.039812635630369186
Validation loss: 1.5552580612961964

Epoch: 6| Step: 10
Training loss: 0.05255350470542908
Validation loss: 1.5488804091689408

Epoch: 6| Step: 11
Training loss: 0.05283742770552635
Validation loss: 1.5624697657041653

Epoch: 6| Step: 12
Training loss: 0.05029468238353729
Validation loss: 1.5690047805027296

Epoch: 6| Step: 13
Training loss: 0.0474630706012249
Validation loss: 1.5705392629869523

Epoch: 718| Step: 0
Training loss: 0.042822472751140594
Validation loss: 1.565969172344413

Epoch: 6| Step: 1
Training loss: 0.06737793982028961
Validation loss: 1.5737464088265614

Epoch: 6| Step: 2
Training loss: 0.058219876140356064
Validation loss: 1.556229091459705

Epoch: 6| Step: 3
Training loss: 0.04499705135822296
Validation loss: 1.5406871277798888

Epoch: 6| Step: 4
Training loss: 0.07055973261594772
Validation loss: 1.5393318450579079

Epoch: 6| Step: 5
Training loss: 0.03973441570997238
Validation loss: 1.512458300077787

Epoch: 6| Step: 6
Training loss: 0.07510842382907867
Validation loss: 1.5104695161183674

Epoch: 6| Step: 7
Training loss: 0.05865826457738876
Validation loss: 1.5168139614084715

Epoch: 6| Step: 8
Training loss: 0.0643545463681221
Validation loss: 1.5194250159366156

Epoch: 6| Step: 9
Training loss: 0.08081990480422974
Validation loss: 1.5232857042743313

Epoch: 6| Step: 10
Training loss: 0.06423451006412506
Validation loss: 1.5056526020009031

Epoch: 6| Step: 11
Training loss: 0.03720436245203018
Validation loss: 1.5350317442288963

Epoch: 6| Step: 12
Training loss: 0.06734540313482285
Validation loss: 1.5539369467766053

Epoch: 6| Step: 13
Training loss: 0.038577206432819366
Validation loss: 1.5626262593012985

Epoch: 719| Step: 0
Training loss: 0.06785517930984497
Validation loss: 1.6094171013883365

Epoch: 6| Step: 1
Training loss: 0.09312404692173004
Validation loss: 1.5973150973678918

Epoch: 6| Step: 2
Training loss: 0.06110928952693939
Validation loss: 1.5725642455521451

Epoch: 6| Step: 3
Training loss: 0.058968279510736465
Validation loss: 1.5535044644468574

Epoch: 6| Step: 4
Training loss: 0.024550799280405045
Validation loss: 1.5299339063705937

Epoch: 6| Step: 5
Training loss: 0.034713249653577805
Validation loss: 1.5440334517468688

Epoch: 6| Step: 6
Training loss: 0.0560181625187397
Validation loss: 1.5125574924612557

Epoch: 6| Step: 7
Training loss: 0.05110767483711243
Validation loss: 1.516152980507061

Epoch: 6| Step: 8
Training loss: 0.09809380024671555
Validation loss: 1.5022983320297734

Epoch: 6| Step: 9
Training loss: 0.04577214643359184
Validation loss: 1.485258702308901

Epoch: 6| Step: 10
Training loss: 0.04143699258565903
Validation loss: 1.4977623384485963

Epoch: 6| Step: 11
Training loss: 0.07083781808614731
Validation loss: 1.5132375109580256

Epoch: 6| Step: 12
Training loss: 0.04415864497423172
Validation loss: 1.5006502994927027

Epoch: 6| Step: 13
Training loss: 0.07353278249502182
Validation loss: 1.48864669440895

Epoch: 720| Step: 0
Training loss: 0.053174033761024475
Validation loss: 1.489995087346723

Epoch: 6| Step: 1
Training loss: 0.04139342159032822
Validation loss: 1.505273001168364

Epoch: 6| Step: 2
Training loss: 0.039013784378767014
Validation loss: 1.5410667183578655

Epoch: 6| Step: 3
Training loss: 0.04906736686825752
Validation loss: 1.552511795874565

Epoch: 6| Step: 4
Training loss: 0.08033072203397751
Validation loss: 1.5324760354975218

Epoch: 6| Step: 5
Training loss: 0.060327813029289246
Validation loss: 1.5466816758596769

Epoch: 6| Step: 6
Training loss: 0.0340438112616539
Validation loss: 1.529988701625537

Epoch: 6| Step: 7
Training loss: 0.06904709339141846
Validation loss: 1.509722303318721

Epoch: 6| Step: 8
Training loss: 0.06480260193347931
Validation loss: 1.5133089993589668

Epoch: 6| Step: 9
Training loss: 0.04410248249769211
Validation loss: 1.5323040639200518

Epoch: 6| Step: 10
Training loss: 0.06329656392335892
Validation loss: 1.5426272781946326

Epoch: 6| Step: 11
Training loss: 0.05390296131372452
Validation loss: 1.5200204003241755

Epoch: 6| Step: 12
Training loss: 0.03348949924111366
Validation loss: 1.5351082637745848

Epoch: 6| Step: 13
Training loss: 0.034615982323884964
Validation loss: 1.5217208657213437

Epoch: 721| Step: 0
Training loss: 0.0475759394466877
Validation loss: 1.5175443028890958

Epoch: 6| Step: 1
Training loss: 0.036964185535907745
Validation loss: 1.5242944071369786

Epoch: 6| Step: 2
Training loss: 0.04208306968212128
Validation loss: 1.517954070080993

Epoch: 6| Step: 3
Training loss: 0.039853841066360474
Validation loss: 1.5449496879372546

Epoch: 6| Step: 4
Training loss: 0.045690011233091354
Validation loss: 1.5581508951802407

Epoch: 6| Step: 5
Training loss: 0.07594075798988342
Validation loss: 1.566810486137226

Epoch: 6| Step: 6
Training loss: 0.03904125094413757
Validation loss: 1.5513024458321192

Epoch: 6| Step: 7
Training loss: 0.08159681409597397
Validation loss: 1.5425139537421606

Epoch: 6| Step: 8
Training loss: 0.04546729475259781
Validation loss: 1.5349779308483165

Epoch: 6| Step: 9
Training loss: 0.09089016169309616
Validation loss: 1.5158972317172634

Epoch: 6| Step: 10
Training loss: 0.0626956894993782
Validation loss: 1.493972134846513

Epoch: 6| Step: 11
Training loss: 0.0767732560634613
Validation loss: 1.5026480408125027

Epoch: 6| Step: 12
Training loss: 0.0445222407579422
Validation loss: 1.5088368526069067

Epoch: 6| Step: 13
Training loss: 0.08292242884635925
Validation loss: 1.4957744639406922

Epoch: 722| Step: 0
Training loss: 0.054257526993751526
Validation loss: 1.5167973003079813

Epoch: 6| Step: 1
Training loss: 0.06511528044939041
Validation loss: 1.5161726782398839

Epoch: 6| Step: 2
Training loss: 0.06389565020799637
Validation loss: 1.5321946708104943

Epoch: 6| Step: 3
Training loss: 0.045079201459884644
Validation loss: 1.5235562657797208

Epoch: 6| Step: 4
Training loss: 0.07424023002386093
Validation loss: 1.530323628456362

Epoch: 6| Step: 5
Training loss: 0.09846574068069458
Validation loss: 1.5510059479744203

Epoch: 6| Step: 6
Training loss: 0.056769631803035736
Validation loss: 1.5396681460001136

Epoch: 6| Step: 7
Training loss: 0.0360175259411335
Validation loss: 1.5031295489239436

Epoch: 6| Step: 8
Training loss: 0.044635653495788574
Validation loss: 1.5291083730677122

Epoch: 6| Step: 9
Training loss: 0.030002310872077942
Validation loss: 1.5004105901205411

Epoch: 6| Step: 10
Training loss: 0.04691917821764946
Validation loss: 1.5063759524335143

Epoch: 6| Step: 11
Training loss: 0.04433122277259827
Validation loss: 1.497642127416467

Epoch: 6| Step: 12
Training loss: 0.07064492255449295
Validation loss: 1.5043230736127464

Epoch: 6| Step: 13
Training loss: 0.02527061477303505
Validation loss: 1.506429683777594

Epoch: 723| Step: 0
Training loss: 0.025127530097961426
Validation loss: 1.5148232598458566

Epoch: 6| Step: 1
Training loss: 0.036448389291763306
Validation loss: 1.5244422548560685

Epoch: 6| Step: 2
Training loss: 0.04276178032159805
Validation loss: 1.5397832534646476

Epoch: 6| Step: 3
Training loss: 0.06124125421047211
Validation loss: 1.5178737589108047

Epoch: 6| Step: 4
Training loss: 0.05445696786046028
Validation loss: 1.5145067989185292

Epoch: 6| Step: 5
Training loss: 0.09575863927602768
Validation loss: 1.5388869406074606

Epoch: 6| Step: 6
Training loss: 0.05014047771692276
Validation loss: 1.547966093145391

Epoch: 6| Step: 7
Training loss: 0.07164081931114197
Validation loss: 1.5452856517607165

Epoch: 6| Step: 8
Training loss: 0.0716283842921257
Validation loss: 1.5345843812470794

Epoch: 6| Step: 9
Training loss: 0.0582021102309227
Validation loss: 1.5403430231155888

Epoch: 6| Step: 10
Training loss: 0.05407099425792694
Validation loss: 1.5553907309809039

Epoch: 6| Step: 11
Training loss: 0.036178652197122574
Validation loss: 1.5358787390493578

Epoch: 6| Step: 12
Training loss: 0.03925522416830063
Validation loss: 1.5261560101662912

Epoch: 6| Step: 13
Training loss: 0.06724406033754349
Validation loss: 1.5426830155875093

Epoch: 724| Step: 0
Training loss: 0.07057897746562958
Validation loss: 1.53872601960295

Epoch: 6| Step: 1
Training loss: 0.04770396649837494
Validation loss: 1.5282915356338664

Epoch: 6| Step: 2
Training loss: 0.06264684349298477
Validation loss: 1.5638323689019809

Epoch: 6| Step: 3
Training loss: 0.04372471570968628
Validation loss: 1.5812511431273593

Epoch: 6| Step: 4
Training loss: 0.10290245711803436
Validation loss: 1.5853004186384139

Epoch: 6| Step: 5
Training loss: 0.04247250780463219
Validation loss: 1.572373217152011

Epoch: 6| Step: 6
Training loss: 0.06922806799411774
Validation loss: 1.5676325354524838

Epoch: 6| Step: 7
Training loss: 0.07064346969127655
Validation loss: 1.5549504398017802

Epoch: 6| Step: 8
Training loss: 0.05874815955758095
Validation loss: 1.5305432446541325

Epoch: 6| Step: 9
Training loss: 0.08246546238660812
Validation loss: 1.5402797652829079

Epoch: 6| Step: 10
Training loss: 0.06854221224784851
Validation loss: 1.5135669003250778

Epoch: 6| Step: 11
Training loss: 0.05394569784402847
Validation loss: 1.5364222673959629

Epoch: 6| Step: 12
Training loss: 0.06375037133693695
Validation loss: 1.55915855720479

Epoch: 6| Step: 13
Training loss: 0.02652672864496708
Validation loss: 1.548058968718334

Epoch: 725| Step: 0
Training loss: 0.05672532320022583
Validation loss: 1.5374090991994387

Epoch: 6| Step: 1
Training loss: 0.0706397294998169
Validation loss: 1.5233368822323379

Epoch: 6| Step: 2
Training loss: 0.0628894791007042
Validation loss: 1.5535414180447977

Epoch: 6| Step: 3
Training loss: 0.09067171066999435
Validation loss: 1.558064902341494

Epoch: 6| Step: 4
Training loss: 0.04935762658715248
Validation loss: 1.5751025099908151

Epoch: 6| Step: 5
Training loss: 0.060652956366539
Validation loss: 1.5500906295673822

Epoch: 6| Step: 6
Training loss: 0.061669543385505676
Validation loss: 1.5455937154831425

Epoch: 6| Step: 7
Training loss: 0.04168994724750519
Validation loss: 1.5273495758733442

Epoch: 6| Step: 8
Training loss: 0.045860517770051956
Validation loss: 1.5333885761999315

Epoch: 6| Step: 9
Training loss: 0.057234302163124084
Validation loss: 1.5284131457728725

Epoch: 6| Step: 10
Training loss: 0.08180530369281769
Validation loss: 1.5325552109749085

Epoch: 6| Step: 11
Training loss: 0.07439729571342468
Validation loss: 1.5235325636402253

Epoch: 6| Step: 12
Training loss: 0.06127725914120674
Validation loss: 1.5260905258117183

Epoch: 6| Step: 13
Training loss: 0.06431044638156891
Validation loss: 1.546792495635248

Epoch: 726| Step: 0
Training loss: 0.06716477870941162
Validation loss: 1.5651682179461244

Epoch: 6| Step: 1
Training loss: 0.05390516668558121
Validation loss: 1.5361357388957855

Epoch: 6| Step: 2
Training loss: 0.02540482208132744
Validation loss: 1.5865796817246305

Epoch: 6| Step: 3
Training loss: 0.0331326425075531
Validation loss: 1.561369723530226

Epoch: 6| Step: 4
Training loss: 0.03366728872060776
Validation loss: 1.566925379537767

Epoch: 6| Step: 5
Training loss: 0.05687370151281357
Validation loss: 1.5837350327481505

Epoch: 6| Step: 6
Training loss: 0.05338465794920921
Validation loss: 1.5891150646312262

Epoch: 6| Step: 7
Training loss: 0.046208154410123825
Validation loss: 1.5698196388060046

Epoch: 6| Step: 8
Training loss: 0.051301732659339905
Validation loss: 1.5587437986045756

Epoch: 6| Step: 9
Training loss: 0.04952516779303551
Validation loss: 1.5630778061446322

Epoch: 6| Step: 10
Training loss: 0.04453139752149582
Validation loss: 1.5379855594327372

Epoch: 6| Step: 11
Training loss: 0.06296706199645996
Validation loss: 1.5409692436136224

Epoch: 6| Step: 12
Training loss: 0.06397286057472229
Validation loss: 1.5385252070683304

Epoch: 6| Step: 13
Training loss: 0.026300469413399696
Validation loss: 1.52839599053065

Epoch: 727| Step: 0
Training loss: 0.04414229094982147
Validation loss: 1.5397387268722698

Epoch: 6| Step: 1
Training loss: 0.05489671230316162
Validation loss: 1.5434724502666022

Epoch: 6| Step: 2
Training loss: 0.0536670908331871
Validation loss: 1.5298709407929452

Epoch: 6| Step: 3
Training loss: 0.05333520472049713
Validation loss: 1.5480338501673874

Epoch: 6| Step: 4
Training loss: 0.07684055715799332
Validation loss: 1.5395538537733016

Epoch: 6| Step: 5
Training loss: 0.04104388877749443
Validation loss: 1.5375200035751506

Epoch: 6| Step: 6
Training loss: 0.06301459670066833
Validation loss: 1.5381615789987708

Epoch: 6| Step: 7
Training loss: 0.04151099920272827
Validation loss: 1.5249934196472168

Epoch: 6| Step: 8
Training loss: 0.060406360775232315
Validation loss: 1.549572088385141

Epoch: 6| Step: 9
Training loss: 0.04229468107223511
Validation loss: 1.54833520484227

Epoch: 6| Step: 10
Training loss: 0.041750699281692505
Validation loss: 1.5376527463236163

Epoch: 6| Step: 11
Training loss: 0.0294911228120327
Validation loss: 1.5357502122079172

Epoch: 6| Step: 12
Training loss: 0.05364272743463516
Validation loss: 1.5516741942333918

Epoch: 6| Step: 13
Training loss: 0.019384728744626045
Validation loss: 1.5499477213428867

Epoch: 728| Step: 0
Training loss: 0.046063441783189774
Validation loss: 1.5568864025095457

Epoch: 6| Step: 1
Training loss: 0.04211423546075821
Validation loss: 1.552843552763744

Epoch: 6| Step: 2
Training loss: 0.051810652017593384
Validation loss: 1.5825095971425374

Epoch: 6| Step: 3
Training loss: 0.044783174991607666
Validation loss: 1.572305820321524

Epoch: 6| Step: 4
Training loss: 0.055441081523895264
Validation loss: 1.5731193416862077

Epoch: 6| Step: 5
Training loss: 0.06080913916230202
Validation loss: 1.5616462910047142

Epoch: 6| Step: 6
Training loss: 0.07310223579406738
Validation loss: 1.5590608837783977

Epoch: 6| Step: 7
Training loss: 0.08606105297803879
Validation loss: 1.556449923464047

Epoch: 6| Step: 8
Training loss: 0.03570907562971115
Validation loss: 1.54377648779141

Epoch: 6| Step: 9
Training loss: 0.04714954271912575
Validation loss: 1.5376712083816528

Epoch: 6| Step: 10
Training loss: 0.06650690734386444
Validation loss: 1.5075270559198113

Epoch: 6| Step: 11
Training loss: 0.08295375108718872
Validation loss: 1.5281688410748717

Epoch: 6| Step: 12
Training loss: 0.053799062967300415
Validation loss: 1.5130261733967771

Epoch: 6| Step: 13
Training loss: 0.03765881806612015
Validation loss: 1.532020168278807

Epoch: 729| Step: 0
Training loss: 0.04100682586431503
Validation loss: 1.534248544323829

Epoch: 6| Step: 1
Training loss: 0.07552527636289597
Validation loss: 1.5304490340653287

Epoch: 6| Step: 2
Training loss: 0.0623263344168663
Validation loss: 1.4987873825975644

Epoch: 6| Step: 3
Training loss: 0.04717522859573364
Validation loss: 1.4977963534734582

Epoch: 6| Step: 4
Training loss: 0.0529315359890461
Validation loss: 1.5544402035333778

Epoch: 6| Step: 5
Training loss: 0.04986955597996712
Validation loss: 1.530315194078671

Epoch: 6| Step: 6
Training loss: 0.03163183480501175
Validation loss: 1.5160403892558107

Epoch: 6| Step: 7
Training loss: 0.05332983285188675
Validation loss: 1.5107007802173655

Epoch: 6| Step: 8
Training loss: 0.05065927654504776
Validation loss: 1.5104709568844046

Epoch: 6| Step: 9
Training loss: 0.05240653455257416
Validation loss: 1.4962070148478273

Epoch: 6| Step: 10
Training loss: 0.07627475261688232
Validation loss: 1.4995293207066034

Epoch: 6| Step: 11
Training loss: 0.04194433242082596
Validation loss: 1.500835343073773

Epoch: 6| Step: 12
Training loss: 0.046655409038066864
Validation loss: 1.5059625435900945

Epoch: 6| Step: 13
Training loss: 0.07186673581600189
Validation loss: 1.5267683844412527

Epoch: 730| Step: 0
Training loss: 0.05107630044221878
Validation loss: 1.5203291113658617

Epoch: 6| Step: 1
Training loss: 0.06386379152536392
Validation loss: 1.5007092645091396

Epoch: 6| Step: 2
Training loss: 0.041689224541187286
Validation loss: 1.5455038015560438

Epoch: 6| Step: 3
Training loss: 0.043730758130550385
Validation loss: 1.49888954752235

Epoch: 6| Step: 4
Training loss: 0.058642297983169556
Validation loss: 1.517173449839315

Epoch: 6| Step: 5
Training loss: 0.07293543219566345
Validation loss: 1.5118052139077136

Epoch: 6| Step: 6
Training loss: 0.028010910376906395
Validation loss: 1.5014633222292828

Epoch: 6| Step: 7
Training loss: 0.034406859427690506
Validation loss: 1.5256484593114545

Epoch: 6| Step: 8
Training loss: 0.03630967065691948
Validation loss: 1.5252858195253598

Epoch: 6| Step: 9
Training loss: 0.04004807025194168
Validation loss: 1.5222552566118137

Epoch: 6| Step: 10
Training loss: 0.0423845574259758
Validation loss: 1.549077259596958

Epoch: 6| Step: 11
Training loss: 0.0861402302980423
Validation loss: 1.5783502478753366

Epoch: 6| Step: 12
Training loss: 0.08226725459098816
Validation loss: 1.5364132824764456

Epoch: 6| Step: 13
Training loss: 0.10436404496431351
Validation loss: 1.5497501255363546

Epoch: 731| Step: 0
Training loss: 0.032920632511377335
Validation loss: 1.5367124272931008

Epoch: 6| Step: 1
Training loss: 0.04101132974028587
Validation loss: 1.5328531636986682

Epoch: 6| Step: 2
Training loss: 0.03996613249182701
Validation loss: 1.5113547271297825

Epoch: 6| Step: 3
Training loss: 0.04616212844848633
Validation loss: 1.514400403986695

Epoch: 6| Step: 4
Training loss: 0.09421021491289139
Validation loss: 1.493903411331997

Epoch: 6| Step: 5
Training loss: 0.05757628008723259
Validation loss: 1.5175153805363564

Epoch: 6| Step: 6
Training loss: 0.05630754306912422
Validation loss: 1.4972347982468144

Epoch: 6| Step: 7
Training loss: 0.05927393212914467
Validation loss: 1.4935024246092765

Epoch: 6| Step: 8
Training loss: 0.046621814370155334
Validation loss: 1.5046690869074997

Epoch: 6| Step: 9
Training loss: 0.08653467893600464
Validation loss: 1.5082235887486448

Epoch: 6| Step: 10
Training loss: 0.07165858149528503
Validation loss: 1.5302157216174628

Epoch: 6| Step: 11
Training loss: 0.0717342346906662
Validation loss: 1.5064743616247689

Epoch: 6| Step: 12
Training loss: 0.030385129153728485
Validation loss: 1.4942802729145173

Epoch: 6| Step: 13
Training loss: 0.04603172838687897
Validation loss: 1.4964308661799277

Epoch: 732| Step: 0
Training loss: 0.06457875669002533
Validation loss: 1.4944802779023365

Epoch: 6| Step: 1
Training loss: 0.05753704905509949
Validation loss: 1.4820695948857132

Epoch: 6| Step: 2
Training loss: 0.12416218966245651
Validation loss: 1.4976343160034509

Epoch: 6| Step: 3
Training loss: 0.04635043814778328
Validation loss: 1.4918239706306047

Epoch: 6| Step: 4
Training loss: 0.03383314236998558
Validation loss: 1.4763684913676272

Epoch: 6| Step: 5
Training loss: 0.07069873064756393
Validation loss: 1.505582748561777

Epoch: 6| Step: 6
Training loss: 0.03773865848779678
Validation loss: 1.4808368631588515

Epoch: 6| Step: 7
Training loss: 0.03574981912970543
Validation loss: 1.5590409963361678

Epoch: 6| Step: 8
Training loss: 0.0944562554359436
Validation loss: 1.568784838081688

Epoch: 6| Step: 9
Training loss: 0.1042325496673584
Validation loss: 1.5642309637479885

Epoch: 6| Step: 10
Training loss: 0.11510930955410004
Validation loss: 1.5741878145484514

Epoch: 6| Step: 11
Training loss: 0.05740448459982872
Validation loss: 1.5275712615700179

Epoch: 6| Step: 12
Training loss: 0.07783214747905731
Validation loss: 1.49923357143197

Epoch: 6| Step: 13
Training loss: 0.082204669713974
Validation loss: 1.5147376291213497

Epoch: 733| Step: 0
Training loss: 0.2000894844532013
Validation loss: 1.5285369542337233

Epoch: 6| Step: 1
Training loss: 0.10410907119512558
Validation loss: 1.5089087627267326

Epoch: 6| Step: 2
Training loss: 0.09582251310348511
Validation loss: 1.500464609874192

Epoch: 6| Step: 3
Training loss: 0.05037155747413635
Validation loss: 1.4943605674210416

Epoch: 6| Step: 4
Training loss: 0.09539151191711426
Validation loss: 1.5290994304482655

Epoch: 6| Step: 5
Training loss: 0.08214219659566879
Validation loss: 1.5448380939422115

Epoch: 6| Step: 6
Training loss: 0.16312316060066223
Validation loss: 1.5547871192296345

Epoch: 6| Step: 7
Training loss: 0.11555251479148865
Validation loss: 1.5384514780454739

Epoch: 6| Step: 8
Training loss: 0.06365514546632767
Validation loss: 1.5421272580341627

Epoch: 6| Step: 9
Training loss: 0.0691860020160675
Validation loss: 1.496923122354733

Epoch: 6| Step: 10
Training loss: 0.08977866172790527
Validation loss: 1.5113987345849313

Epoch: 6| Step: 11
Training loss: 0.0798090398311615
Validation loss: 1.5296117118609849

Epoch: 6| Step: 12
Training loss: 0.13164395093917847
Validation loss: 1.545264934980741

Epoch: 6| Step: 13
Training loss: 0.07609843462705612
Validation loss: 1.5366004692610873

Epoch: 734| Step: 0
Training loss: 0.04685170575976372
Validation loss: 1.5218558164053066

Epoch: 6| Step: 1
Training loss: 0.07381996512413025
Validation loss: 1.5715015383176907

Epoch: 6| Step: 2
Training loss: 0.06879788637161255
Validation loss: 1.5566991247156614

Epoch: 6| Step: 3
Training loss: 0.07540091872215271
Validation loss: 1.583003367147138

Epoch: 6| Step: 4
Training loss: 0.06515777111053467
Validation loss: 1.590110832645047

Epoch: 6| Step: 5
Training loss: 0.059434521943330765
Validation loss: 1.5510815394821988

Epoch: 6| Step: 6
Training loss: 0.04538857191801071
Validation loss: 1.5461076241667553

Epoch: 6| Step: 7
Training loss: 0.06800629198551178
Validation loss: 1.5444714318039596

Epoch: 6| Step: 8
Training loss: 0.0507064163684845
Validation loss: 1.5326021909713745

Epoch: 6| Step: 9
Training loss: 0.08778432011604309
Validation loss: 1.5436651376626824

Epoch: 6| Step: 10
Training loss: 0.0438733771443367
Validation loss: 1.524423776134368

Epoch: 6| Step: 11
Training loss: 0.10768657177686691
Validation loss: 1.503168039424445

Epoch: 6| Step: 12
Training loss: 0.04562278091907501
Validation loss: 1.4993637172124719

Epoch: 6| Step: 13
Training loss: 0.07235470414161682
Validation loss: 1.5183987412401425

Epoch: 735| Step: 0
Training loss: 0.12077831476926804
Validation loss: 1.5131837321865944

Epoch: 6| Step: 1
Training loss: 0.11240602284669876
Validation loss: 1.5167229893387004

Epoch: 6| Step: 2
Training loss: 0.08994569629430771
Validation loss: 1.5000413963871617

Epoch: 6| Step: 3
Training loss: 0.05836629867553711
Validation loss: 1.5224445455817766

Epoch: 6| Step: 4
Training loss: 0.04461881145834923
Validation loss: 1.5298605670211136

Epoch: 6| Step: 5
Training loss: 0.04170311242341995
Validation loss: 1.5330631976486535

Epoch: 6| Step: 6
Training loss: 0.08630827069282532
Validation loss: 1.5776772281175018

Epoch: 6| Step: 7
Training loss: 0.14962399005889893
Validation loss: 1.595566120198978

Epoch: 6| Step: 8
Training loss: 0.13512933254241943
Validation loss: 1.571079663051072

Epoch: 6| Step: 9
Training loss: 0.06467098742723465
Validation loss: 1.5237596355458742

Epoch: 6| Step: 10
Training loss: 0.05198846757411957
Validation loss: 1.4912944570664437

Epoch: 6| Step: 11
Training loss: 0.11750216782093048
Validation loss: 1.516338280452195

Epoch: 6| Step: 12
Training loss: 0.06607067584991455
Validation loss: 1.4989465705810054

Epoch: 6| Step: 13
Training loss: 0.10146898776292801
Validation loss: 1.4761361165713238

Epoch: 736| Step: 0
Training loss: 0.07809994369745255
Validation loss: 1.4697005646203154

Epoch: 6| Step: 1
Training loss: 0.05340862274169922
Validation loss: 1.4957575580125213

Epoch: 6| Step: 2
Training loss: 0.05591551959514618
Validation loss: 1.4930726546113209

Epoch: 6| Step: 3
Training loss: 0.07906152307987213
Validation loss: 1.5011445271071566

Epoch: 6| Step: 4
Training loss: 0.055272944271564484
Validation loss: 1.4877154160571355

Epoch: 6| Step: 5
Training loss: 0.049727972596883774
Validation loss: 1.518532645317816

Epoch: 6| Step: 6
Training loss: 0.03854694962501526
Validation loss: 1.521896844269127

Epoch: 6| Step: 7
Training loss: 0.045147087424993515
Validation loss: 1.5186629154348885

Epoch: 6| Step: 8
Training loss: 0.10425186902284622
Validation loss: 1.5531475992612942

Epoch: 6| Step: 9
Training loss: 0.07193166017532349
Validation loss: 1.5074244186442385

Epoch: 6| Step: 10
Training loss: 0.0968560203909874
Validation loss: 1.5276442926417115

Epoch: 6| Step: 11
Training loss: 0.0480140745639801
Validation loss: 1.5287231527349001

Epoch: 6| Step: 12
Training loss: 0.05461440235376358
Validation loss: 1.5179232128204838

Epoch: 6| Step: 13
Training loss: 0.05424867570400238
Validation loss: 1.503629442184202

Epoch: 737| Step: 0
Training loss: 0.05575577914714813
Validation loss: 1.5149445508116035

Epoch: 6| Step: 1
Training loss: 0.053645048290491104
Validation loss: 1.5030654027897825

Epoch: 6| Step: 2
Training loss: 0.07162488996982574
Validation loss: 1.5002638601487683

Epoch: 6| Step: 3
Training loss: 0.043111156672239304
Validation loss: 1.4969116513447096

Epoch: 6| Step: 4
Training loss: 0.03496258705854416
Validation loss: 1.5042481614697365

Epoch: 6| Step: 5
Training loss: 0.0448511466383934
Validation loss: 1.5072750160771031

Epoch: 6| Step: 6
Training loss: 0.035701870918273926
Validation loss: 1.5122966509993359

Epoch: 6| Step: 7
Training loss: 0.03284182772040367
Validation loss: 1.5155673270584435

Epoch: 6| Step: 8
Training loss: 0.05563206970691681
Validation loss: 1.5005568650461012

Epoch: 6| Step: 9
Training loss: 0.09036583453416824
Validation loss: 1.5109434819990588

Epoch: 6| Step: 10
Training loss: 0.042660292237997055
Validation loss: 1.54217263062795

Epoch: 6| Step: 11
Training loss: 0.03661298006772995
Validation loss: 1.5122040792178082

Epoch: 6| Step: 12
Training loss: 0.04075000435113907
Validation loss: 1.522550658513141

Epoch: 6| Step: 13
Training loss: 0.10610491037368774
Validation loss: 1.5157939657088249

Epoch: 738| Step: 0
Training loss: 0.04031120240688324
Validation loss: 1.530131665609216

Epoch: 6| Step: 1
Training loss: 0.04605209827423096
Validation loss: 1.5182373869803645

Epoch: 6| Step: 2
Training loss: 0.040078647434711456
Validation loss: 1.5179471251785115

Epoch: 6| Step: 3
Training loss: 0.044179610908031464
Validation loss: 1.5205076535542805

Epoch: 6| Step: 4
Training loss: 0.04859090596437454
Validation loss: 1.5318030259942497

Epoch: 6| Step: 5
Training loss: 0.05354587733745575
Validation loss: 1.5287843314550256

Epoch: 6| Step: 6
Training loss: 0.028829913586378098
Validation loss: 1.5561456782843477

Epoch: 6| Step: 7
Training loss: 0.09737029671669006
Validation loss: 1.5223524217964501

Epoch: 6| Step: 8
Training loss: 0.06895266473293304
Validation loss: 1.5283528732997116

Epoch: 6| Step: 9
Training loss: 0.06557387858629227
Validation loss: 1.5449827883833198

Epoch: 6| Step: 10
Training loss: 0.04325047880411148
Validation loss: 1.5512766748346307

Epoch: 6| Step: 11
Training loss: 0.06344478577375412
Validation loss: 1.5195417570811447

Epoch: 6| Step: 12
Training loss: 0.052083294838666916
Validation loss: 1.5310114365752026

Epoch: 6| Step: 13
Training loss: 0.03600947558879852
Validation loss: 1.5142150143141389

Epoch: 739| Step: 0
Training loss: 0.07011613249778748
Validation loss: 1.505523330421858

Epoch: 6| Step: 1
Training loss: 0.06455454230308533
Validation loss: 1.500788962969216

Epoch: 6| Step: 2
Training loss: 0.06330311298370361
Validation loss: 1.509330685420703

Epoch: 6| Step: 3
Training loss: 0.04667878523468971
Validation loss: 1.5153706599307317

Epoch: 6| Step: 4
Training loss: 0.04067474603652954
Validation loss: 1.4994735320409138

Epoch: 6| Step: 5
Training loss: 0.062314800918102264
Validation loss: 1.5101250884353474

Epoch: 6| Step: 6
Training loss: 0.05395695939660072
Validation loss: 1.540443544746727

Epoch: 6| Step: 7
Training loss: 0.08643390238285065
Validation loss: 1.5243772422113726

Epoch: 6| Step: 8
Training loss: 0.07107152789831161
Validation loss: 1.516747873316529

Epoch: 6| Step: 9
Training loss: 0.030456140637397766
Validation loss: 1.5254214899514311

Epoch: 6| Step: 10
Training loss: 0.06362923979759216
Validation loss: 1.5172111218975437

Epoch: 6| Step: 11
Training loss: 0.06143023073673248
Validation loss: 1.5311952848588266

Epoch: 6| Step: 12
Training loss: 0.05381172522902489
Validation loss: 1.547530270391895

Epoch: 6| Step: 13
Training loss: 0.02534017711877823
Validation loss: 1.5413164554103729

Epoch: 740| Step: 0
Training loss: 0.07406356930732727
Validation loss: 1.5080612410781205

Epoch: 6| Step: 1
Training loss: 0.037873052060604095
Validation loss: 1.5161026844414331

Epoch: 6| Step: 2
Training loss: 0.04544398561120033
Validation loss: 1.5303881104274462

Epoch: 6| Step: 3
Training loss: 0.08078920841217041
Validation loss: 1.4741349592003772

Epoch: 6| Step: 4
Training loss: 0.07348162680864334
Validation loss: 1.491951573279596

Epoch: 6| Step: 5
Training loss: 0.07518899440765381
Validation loss: 1.5164494354237792

Epoch: 6| Step: 6
Training loss: 0.07435764372348785
Validation loss: 1.495714533713556

Epoch: 6| Step: 7
Training loss: 0.03406575694680214
Validation loss: 1.5129524110465922

Epoch: 6| Step: 8
Training loss: 0.04379548504948616
Validation loss: 1.5353883081866848

Epoch: 6| Step: 9
Training loss: 0.04866022616624832
Validation loss: 1.5341635134912306

Epoch: 6| Step: 10
Training loss: 0.04551531374454498
Validation loss: 1.5143750162534817

Epoch: 6| Step: 11
Training loss: 0.027858205139636993
Validation loss: 1.5209810554340322

Epoch: 6| Step: 12
Training loss: 0.028376884758472443
Validation loss: 1.5528721937569239

Epoch: 6| Step: 13
Training loss: 0.0899505615234375
Validation loss: 1.513109480181048

Epoch: 741| Step: 0
Training loss: 0.038580041378736496
Validation loss: 1.5095588302099576

Epoch: 6| Step: 1
Training loss: 0.049221429973840714
Validation loss: 1.4971112448682067

Epoch: 6| Step: 2
Training loss: 0.04736611992120743
Validation loss: 1.4981404914650867

Epoch: 6| Step: 3
Training loss: 0.04091491550207138
Validation loss: 1.5095175184229368

Epoch: 6| Step: 4
Training loss: 0.04167044162750244
Validation loss: 1.51131546561436

Epoch: 6| Step: 5
Training loss: 0.047786910086870193
Validation loss: 1.495157653285611

Epoch: 6| Step: 6
Training loss: 0.042181555181741714
Validation loss: 1.5179787579403128

Epoch: 6| Step: 7
Training loss: 0.0641356110572815
Validation loss: 1.5530635400484967

Epoch: 6| Step: 8
Training loss: 0.06096497178077698
Validation loss: 1.510695977877545

Epoch: 6| Step: 9
Training loss: 0.07989680767059326
Validation loss: 1.5326572592540453

Epoch: 6| Step: 10
Training loss: 0.040404289960861206
Validation loss: 1.5487577133281256

Epoch: 6| Step: 11
Training loss: 0.03390877693891525
Validation loss: 1.5490258534749348

Epoch: 6| Step: 12
Training loss: 0.0707004964351654
Validation loss: 1.5566047519765875

Epoch: 6| Step: 13
Training loss: 0.022721542045474052
Validation loss: 1.5337519504690682

Epoch: 742| Step: 0
Training loss: 0.05707108974456787
Validation loss: 1.540719069460387

Epoch: 6| Step: 1
Training loss: 0.021264106035232544
Validation loss: 1.5559912266269806

Epoch: 6| Step: 2
Training loss: 0.06415609270334244
Validation loss: 1.54996701722504

Epoch: 6| Step: 3
Training loss: 0.074637271463871
Validation loss: 1.5335982307311027

Epoch: 6| Step: 4
Training loss: 0.04552912712097168
Validation loss: 1.5419913530349731

Epoch: 6| Step: 5
Training loss: 0.03574874997138977
Validation loss: 1.5257996461724723

Epoch: 6| Step: 6
Training loss: 0.030708912760019302
Validation loss: 1.5544248537350727

Epoch: 6| Step: 7
Training loss: 0.043120574206113815
Validation loss: 1.5447640393369941

Epoch: 6| Step: 8
Training loss: 0.05985042452812195
Validation loss: 1.54145957193067

Epoch: 6| Step: 9
Training loss: 0.04217919707298279
Validation loss: 1.5520107925579112

Epoch: 6| Step: 10
Training loss: 0.04450102150440216
Validation loss: 1.5640509795117121

Epoch: 6| Step: 11
Training loss: 0.06387586891651154
Validation loss: 1.539186195660663

Epoch: 6| Step: 12
Training loss: 0.0593172051012516
Validation loss: 1.5543269418901013

Epoch: 6| Step: 13
Training loss: 0.01733253337442875
Validation loss: 1.5408578918826195

Epoch: 743| Step: 0
Training loss: 0.05985692888498306
Validation loss: 1.5459138225483637

Epoch: 6| Step: 1
Training loss: 0.03683743253350258
Validation loss: 1.5421683647299325

Epoch: 6| Step: 2
Training loss: 0.06078962981700897
Validation loss: 1.5583074823502572

Epoch: 6| Step: 3
Training loss: 0.04682515934109688
Validation loss: 1.5754428871216313

Epoch: 6| Step: 4
Training loss: 0.053402163088321686
Validation loss: 1.5485708918622745

Epoch: 6| Step: 5
Training loss: 0.04837701469659805
Validation loss: 1.5408734736904022

Epoch: 6| Step: 6
Training loss: 0.036254629492759705
Validation loss: 1.5539232684719948

Epoch: 6| Step: 7
Training loss: 0.03449513390660286
Validation loss: 1.5474900404612224

Epoch: 6| Step: 8
Training loss: 0.10402078926563263
Validation loss: 1.5206260117151404

Epoch: 6| Step: 9
Training loss: 0.04110275208950043
Validation loss: 1.4945019970658004

Epoch: 6| Step: 10
Training loss: 0.047559887170791626
Validation loss: 1.4971278995595954

Epoch: 6| Step: 11
Training loss: 0.10810726135969162
Validation loss: 1.5096218739786456

Epoch: 6| Step: 12
Training loss: 0.04974844679236412
Validation loss: 1.4896192691659416

Epoch: 6| Step: 13
Training loss: 0.07220148295164108
Validation loss: 1.4889422744833014

Epoch: 744| Step: 0
Training loss: 0.04816205054521561
Validation loss: 1.484736748920974

Epoch: 6| Step: 1
Training loss: 0.05840755254030228
Validation loss: 1.5066712825529036

Epoch: 6| Step: 2
Training loss: 0.04640350118279457
Validation loss: 1.4894532029346754

Epoch: 6| Step: 3
Training loss: 0.02517688274383545
Validation loss: 1.4812250957694104

Epoch: 6| Step: 4
Training loss: 0.037976521998643875
Validation loss: 1.4648882676196355

Epoch: 6| Step: 5
Training loss: 0.0580093152821064
Validation loss: 1.4896176322813957

Epoch: 6| Step: 6
Training loss: 0.05771195888519287
Validation loss: 1.4712898987595753

Epoch: 6| Step: 7
Training loss: 0.0837784856557846
Validation loss: 1.4622734259533625

Epoch: 6| Step: 8
Training loss: 0.041473180055618286
Validation loss: 1.4904136016804685

Epoch: 6| Step: 9
Training loss: 0.072843536734581
Validation loss: 1.4835227984254078

Epoch: 6| Step: 10
Training loss: 0.044501181691884995
Validation loss: 1.5005597029962847

Epoch: 6| Step: 11
Training loss: 0.04811690002679825
Validation loss: 1.4875280152085006

Epoch: 6| Step: 12
Training loss: 0.04711002856492996
Validation loss: 1.4740604008397749

Epoch: 6| Step: 13
Training loss: 0.04166211187839508
Validation loss: 1.497218986993195

Epoch: 745| Step: 0
Training loss: 0.05452990531921387
Validation loss: 1.4807491225581015

Epoch: 6| Step: 1
Training loss: 0.038593269884586334
Validation loss: 1.4952116897029262

Epoch: 6| Step: 2
Training loss: 0.06257148832082748
Validation loss: 1.4795779938338904

Epoch: 6| Step: 3
Training loss: 0.08509905636310577
Validation loss: 1.4935067562005853

Epoch: 6| Step: 4
Training loss: 0.057736147195100784
Validation loss: 1.4798556829011569

Epoch: 6| Step: 5
Training loss: 0.06520475447177887
Validation loss: 1.5163218975067139

Epoch: 6| Step: 6
Training loss: 0.053144555538892746
Validation loss: 1.4985598941003122

Epoch: 6| Step: 7
Training loss: 0.11479547619819641
Validation loss: 1.5148263336509786

Epoch: 6| Step: 8
Training loss: 0.17494824528694153
Validation loss: 1.5214783658263504

Epoch: 6| Step: 9
Training loss: 0.11101566255092621
Validation loss: 1.4690190617756178

Epoch: 6| Step: 10
Training loss: 0.05679486691951752
Validation loss: 1.4730734902043496

Epoch: 6| Step: 11
Training loss: 0.08493570238351822
Validation loss: 1.46452703655407

Epoch: 6| Step: 12
Training loss: 0.09265848994255066
Validation loss: 1.474689147805655

Epoch: 6| Step: 13
Training loss: 0.051328256726264954
Validation loss: 1.4761947233189818

Epoch: 746| Step: 0
Training loss: 0.1719427853822708
Validation loss: 1.4707146485646565

Epoch: 6| Step: 1
Training loss: 0.055964432656764984
Validation loss: 1.4979256506889098

Epoch: 6| Step: 2
Training loss: 0.09612254798412323
Validation loss: 1.539709089904703

Epoch: 6| Step: 3
Training loss: 0.08991018682718277
Validation loss: 1.564353540379514

Epoch: 6| Step: 4
Training loss: 0.150020569562912
Validation loss: 1.5663649587221042

Epoch: 6| Step: 5
Training loss: 0.12836122512817383
Validation loss: 1.5645604530970256

Epoch: 6| Step: 6
Training loss: 0.13086490333080292
Validation loss: 1.5525306168422903

Epoch: 6| Step: 7
Training loss: 0.06431765109300613
Validation loss: 1.5100978112989856

Epoch: 6| Step: 8
Training loss: 0.050391994416713715
Validation loss: 1.4918717979103007

Epoch: 6| Step: 9
Training loss: 0.06463196873664856
Validation loss: 1.5105528023935133

Epoch: 6| Step: 10
Training loss: 0.07991631329059601
Validation loss: 1.5120443772244196

Epoch: 6| Step: 11
Training loss: 0.09949877858161926
Validation loss: 1.506748345590407

Epoch: 6| Step: 12
Training loss: 0.07053335011005402
Validation loss: 1.4957304449491604

Epoch: 6| Step: 13
Training loss: 0.08843956887722015
Validation loss: 1.4947170519059705

Epoch: 747| Step: 0
Training loss: 0.0385318323969841
Validation loss: 1.499652374175287

Epoch: 6| Step: 1
Training loss: 0.10495642572641373
Validation loss: 1.5068467099179503

Epoch: 6| Step: 2
Training loss: 0.06402000039815903
Validation loss: 1.509717002991707

Epoch: 6| Step: 3
Training loss: 0.09723132848739624
Validation loss: 1.534675161043803

Epoch: 6| Step: 4
Training loss: 0.0915943831205368
Validation loss: 1.5308867449401526

Epoch: 6| Step: 5
Training loss: 0.08413532376289368
Validation loss: 1.499790406996204

Epoch: 6| Step: 6
Training loss: 0.08717122673988342
Validation loss: 1.506616266824866

Epoch: 6| Step: 7
Training loss: 0.07303972542285919
Validation loss: 1.4886889906339749

Epoch: 6| Step: 8
Training loss: 0.07665678858757019
Validation loss: 1.5107071450961533

Epoch: 6| Step: 9
Training loss: 0.135931596159935
Validation loss: 1.5419416786521993

Epoch: 6| Step: 10
Training loss: 0.09037956595420837
Validation loss: 1.5224784228109545

Epoch: 6| Step: 11
Training loss: 0.08315084874629974
Validation loss: 1.4826668731627926

Epoch: 6| Step: 12
Training loss: 0.05661746859550476
Validation loss: 1.4704219513041998

Epoch: 6| Step: 13
Training loss: 0.0374131053686142
Validation loss: 1.4884175318543629

Epoch: 748| Step: 0
Training loss: 0.08659657090902328
Validation loss: 1.512875081390463

Epoch: 6| Step: 1
Training loss: 0.09050445258617401
Validation loss: 1.54602946389106

Epoch: 6| Step: 2
Training loss: 0.16621917486190796
Validation loss: 1.5367514523126746

Epoch: 6| Step: 3
Training loss: 0.0796806588768959
Validation loss: 1.503765324110626

Epoch: 6| Step: 4
Training loss: 0.07970835268497467
Validation loss: 1.5040097787816038

Epoch: 6| Step: 5
Training loss: 0.07545238733291626
Validation loss: 1.4839567407484977

Epoch: 6| Step: 6
Training loss: 0.08133925497531891
Validation loss: 1.4838008739614998

Epoch: 6| Step: 7
Training loss: 0.1046253964304924
Validation loss: 1.505374067573137

Epoch: 6| Step: 8
Training loss: 0.04515719413757324
Validation loss: 1.4887940063271472

Epoch: 6| Step: 9
Training loss: 0.062070123851299286
Validation loss: 1.4872535185147358

Epoch: 6| Step: 10
Training loss: 0.07406548410654068
Validation loss: 1.4866529408321585

Epoch: 6| Step: 11
Training loss: 0.045756831765174866
Validation loss: 1.512097434331012

Epoch: 6| Step: 12
Training loss: 0.05220622569322586
Validation loss: 1.4986707638668757

Epoch: 6| Step: 13
Training loss: 0.029644230380654335
Validation loss: 1.532282458197686

Epoch: 749| Step: 0
Training loss: 0.04909074679017067
Validation loss: 1.5295349218512093

Epoch: 6| Step: 1
Training loss: 0.03609118610620499
Validation loss: 1.5400446403411128

Epoch: 6| Step: 2
Training loss: 0.1331918090581894
Validation loss: 1.5442213640418103

Epoch: 6| Step: 3
Training loss: 0.07638914883136749
Validation loss: 1.5569543351409256

Epoch: 6| Step: 4
Training loss: 0.08370603621006012
Validation loss: 1.5423484028026622

Epoch: 6| Step: 5
Training loss: 0.05016130208969116
Validation loss: 1.5307210773550055

Epoch: 6| Step: 6
Training loss: 0.055066585540771484
Validation loss: 1.5200948651118944

Epoch: 6| Step: 7
Training loss: 0.04926922917366028
Validation loss: 1.5422259453804261

Epoch: 6| Step: 8
Training loss: 0.05800095200538635
Validation loss: 1.5433007594077819

Epoch: 6| Step: 9
Training loss: 0.08945246785879135
Validation loss: 1.5323351339627338

Epoch: 6| Step: 10
Training loss: 0.10109737515449524
Validation loss: 1.5466283521344584

Epoch: 6| Step: 11
Training loss: 0.04409521818161011
Validation loss: 1.5497735213207942

Epoch: 6| Step: 12
Training loss: 0.06710325181484222
Validation loss: 1.5440358628508866

Epoch: 6| Step: 13
Training loss: 0.040075819939374924
Validation loss: 1.5283797069262433

Epoch: 750| Step: 0
Training loss: 0.05357395112514496
Validation loss: 1.54453222597799

Epoch: 6| Step: 1
Training loss: 0.09646360576152802
Validation loss: 1.526114192060245

Epoch: 6| Step: 2
Training loss: 0.05636944994330406
Validation loss: 1.5345167741980603

Epoch: 6| Step: 3
Training loss: 0.06786146759986877
Validation loss: 1.5339655760795838

Epoch: 6| Step: 4
Training loss: 0.08215421438217163
Validation loss: 1.5452904508959862

Epoch: 6| Step: 5
Training loss: 0.0739590972661972
Validation loss: 1.5436381556654488

Epoch: 6| Step: 6
Training loss: 0.06395398080348969
Validation loss: 1.5441973863109466

Epoch: 6| Step: 7
Training loss: 0.05865957587957382
Validation loss: 1.5361951217856458

Epoch: 6| Step: 8
Training loss: 0.051481664180755615
Validation loss: 1.5502288379976827

Epoch: 6| Step: 9
Training loss: 0.04508762061595917
Validation loss: 1.5332394088468244

Epoch: 6| Step: 10
Training loss: 0.04929588735103607
Validation loss: 1.5322706917280793

Epoch: 6| Step: 11
Training loss: 0.055258557200431824
Validation loss: 1.5330781680281445

Epoch: 6| Step: 12
Training loss: 0.05718938633799553
Validation loss: 1.547410456083154

Epoch: 6| Step: 13
Training loss: 0.06908173114061356
Validation loss: 1.5434692982704408

Testing loss: 2.1195222748650444
