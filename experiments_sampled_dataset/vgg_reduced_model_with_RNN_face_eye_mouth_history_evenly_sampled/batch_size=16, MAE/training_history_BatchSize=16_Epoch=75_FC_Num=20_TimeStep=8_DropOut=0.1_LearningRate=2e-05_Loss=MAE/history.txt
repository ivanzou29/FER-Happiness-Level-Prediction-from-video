Epoch: 1| Step: 0
Training loss: 4.512151718139648
Validation loss: 5.19339527622346

Epoch: 6| Step: 1
Training loss: 4.784266471862793
Validation loss: 5.171626162785356

Epoch: 6| Step: 2
Training loss: 5.021580219268799
Validation loss: 5.1492799482037945

Epoch: 6| Step: 3
Training loss: 3.9516396522521973
Validation loss: 5.1254019019424275

Epoch: 6| Step: 4
Training loss: 4.49962043762207
Validation loss: 5.097555852705432

Epoch: 6| Step: 5
Training loss: 4.208768367767334
Validation loss: 5.06651242574056

Epoch: 6| Step: 6
Training loss: 6.303295135498047
Validation loss: 5.031735948337022

Epoch: 6| Step: 7
Training loss: 4.514421463012695
Validation loss: 4.991391966419835

Epoch: 6| Step: 8
Training loss: 4.053979396820068
Validation loss: 4.945556225315217

Epoch: 6| Step: 9
Training loss: 4.029798984527588
Validation loss: 4.893908490416824

Epoch: 6| Step: 10
Training loss: 5.9471540451049805
Validation loss: 4.8376665986994265

Epoch: 6| Step: 11
Training loss: 5.51961612701416
Validation loss: 4.772009008674211

Epoch: 6| Step: 12
Training loss: 5.019733428955078
Validation loss: 4.699259393958635

Epoch: 6| Step: 13
Training loss: 4.171648979187012
Validation loss: 4.620478696720575

Epoch: 2| Step: 0
Training loss: 4.6392412185668945
Validation loss: 4.533891993184244

Epoch: 6| Step: 1
Training loss: 2.6694912910461426
Validation loss: 4.441838382392802

Epoch: 6| Step: 2
Training loss: 5.022663116455078
Validation loss: 4.34719709170762

Epoch: 6| Step: 3
Training loss: 4.237797260284424
Validation loss: 4.251453781640658

Epoch: 6| Step: 4
Training loss: 5.310134410858154
Validation loss: 4.161587617730581

Epoch: 6| Step: 5
Training loss: 3.829930543899536
Validation loss: 4.070696020639071

Epoch: 6| Step: 6
Training loss: 3.2751429080963135
Validation loss: 3.9823761268328597

Epoch: 6| Step: 7
Training loss: 2.5019705295562744
Validation loss: 3.8978827948211343

Epoch: 6| Step: 8
Training loss: 4.064262390136719
Validation loss: 3.831647124341739

Epoch: 6| Step: 9
Training loss: 2.818232297897339
Validation loss: 3.7689588531371085

Epoch: 6| Step: 10
Training loss: 3.800724744796753
Validation loss: 3.7081747926691526

Epoch: 6| Step: 11
Training loss: 3.9800803661346436
Validation loss: 3.644332952396844

Epoch: 6| Step: 12
Training loss: 3.69358229637146
Validation loss: 3.590140914404264

Epoch: 6| Step: 13
Training loss: 3.833585023880005
Validation loss: 3.5335186091802453

Epoch: 3| Step: 0
Training loss: 3.3661396503448486
Validation loss: 3.4928672698236283

Epoch: 6| Step: 1
Training loss: 4.236752510070801
Validation loss: 3.456900312054542

Epoch: 6| Step: 2
Training loss: 3.403369903564453
Validation loss: 3.4250154674694104

Epoch: 6| Step: 3
Training loss: 4.147850036621094
Validation loss: 3.3974593018972747

Epoch: 6| Step: 4
Training loss: 3.18572998046875
Validation loss: 3.3729010858843402

Epoch: 6| Step: 5
Training loss: 3.073735237121582
Validation loss: 3.3459517673779557

Epoch: 6| Step: 6
Training loss: 3.296985387802124
Validation loss: 3.3237303174952024

Epoch: 6| Step: 7
Training loss: 3.869828939437866
Validation loss: 3.3024202059674006

Epoch: 6| Step: 8
Training loss: 2.8879151344299316
Validation loss: 3.2808990555424846

Epoch: 6| Step: 9
Training loss: 2.011606216430664
Validation loss: 3.257319914397373

Epoch: 6| Step: 10
Training loss: 3.2506909370422363
Validation loss: 3.239415191834973

Epoch: 6| Step: 11
Training loss: 2.7188124656677246
Validation loss: 3.224997064118744

Epoch: 6| Step: 12
Training loss: 3.5675151348114014
Validation loss: 3.2001288321710404

Epoch: 6| Step: 13
Training loss: 3.140925407409668
Validation loss: 3.1778909134608444

Epoch: 4| Step: 0
Training loss: 3.204228639602661
Validation loss: 3.1650120442913425

Epoch: 6| Step: 1
Training loss: 2.7544596195220947
Validation loss: 3.156959395254812

Epoch: 6| Step: 2
Training loss: 3.266082763671875
Validation loss: 3.149225637476931

Epoch: 6| Step: 3
Training loss: 3.894822120666504
Validation loss: 3.1119078872024373

Epoch: 6| Step: 4
Training loss: 3.2299296855926514
Validation loss: 3.0970783464370237

Epoch: 6| Step: 5
Training loss: 4.172569274902344
Validation loss: 3.077887817095685

Epoch: 6| Step: 6
Training loss: 3.459660530090332
Validation loss: 3.0625216422542447

Epoch: 6| Step: 7
Training loss: 2.4127368927001953
Validation loss: 3.046653639885687

Epoch: 6| Step: 8
Training loss: 2.7827179431915283
Validation loss: 3.0376942003926923

Epoch: 6| Step: 9
Training loss: 2.119485378265381
Validation loss: 3.017442482773976

Epoch: 6| Step: 10
Training loss: 2.785560131072998
Validation loss: 3.0025106066016742

Epoch: 6| Step: 11
Training loss: 3.0919904708862305
Validation loss: 2.989103635152181

Epoch: 6| Step: 12
Training loss: 3.609220027923584
Validation loss: 2.9775670318193335

Epoch: 6| Step: 13
Training loss: 2.555053234100342
Validation loss: 2.9659285186439432

Epoch: 5| Step: 0
Training loss: 1.9238522052764893
Validation loss: 2.96061614764634

Epoch: 6| Step: 1
Training loss: 4.088747024536133
Validation loss: 2.951850857785953

Epoch: 6| Step: 2
Training loss: 3.102383852005005
Validation loss: 2.9428692351105394

Epoch: 6| Step: 3
Training loss: 3.309823751449585
Validation loss: 2.930944385067109

Epoch: 6| Step: 4
Training loss: 3.5313282012939453
Validation loss: 2.9215208971372215

Epoch: 6| Step: 5
Training loss: 3.106639862060547
Validation loss: 2.9125559868351107

Epoch: 6| Step: 6
Training loss: 3.5205259323120117
Validation loss: 2.9087143687791723

Epoch: 6| Step: 7
Training loss: 2.4737441539764404
Validation loss: 2.8973415359374015

Epoch: 6| Step: 8
Training loss: 2.628781318664551
Validation loss: 2.892316828491867

Epoch: 6| Step: 9
Training loss: 3.6403236389160156
Validation loss: 2.8905934236382924

Epoch: 6| Step: 10
Training loss: 2.683088779449463
Validation loss: 2.8710437615712485

Epoch: 6| Step: 11
Training loss: 1.7715840339660645
Validation loss: 2.8740762408061693

Epoch: 6| Step: 12
Training loss: 3.453728199005127
Validation loss: 2.902884478210121

Epoch: 6| Step: 13
Training loss: 2.6677184104919434
Validation loss: 2.8672146028087986

Epoch: 6| Step: 0
Training loss: 2.920083522796631
Validation loss: 2.850698294178132

Epoch: 6| Step: 1
Training loss: 2.9653079509735107
Validation loss: 2.8451624762627388

Epoch: 6| Step: 2
Training loss: 2.805839776992798
Validation loss: 2.847284117052632

Epoch: 6| Step: 3
Training loss: 2.265869140625
Validation loss: 2.8469757572297127

Epoch: 6| Step: 4
Training loss: 2.582550525665283
Validation loss: 2.8309968953491538

Epoch: 6| Step: 5
Training loss: 2.4786782264709473
Validation loss: 2.8192920325904764

Epoch: 6| Step: 6
Training loss: 3.240516185760498
Validation loss: 2.8111004085950952

Epoch: 6| Step: 7
Training loss: 2.136791467666626
Validation loss: 2.802944797341542

Epoch: 6| Step: 8
Training loss: 3.2315244674682617
Validation loss: 2.803028788617862

Epoch: 6| Step: 9
Training loss: 4.01699161529541
Validation loss: 2.8111849369541293

Epoch: 6| Step: 10
Training loss: 3.401679515838623
Validation loss: 2.7836725224730787

Epoch: 6| Step: 11
Training loss: 2.1360678672790527
Validation loss: 2.791532793352681

Epoch: 6| Step: 12
Training loss: 3.218522071838379
Validation loss: 2.8189085324605307

Epoch: 6| Step: 13
Training loss: 4.434077262878418
Validation loss: 2.7839662157079226

Epoch: 7| Step: 0
Training loss: 2.286318302154541
Validation loss: 2.7737752365809616

Epoch: 6| Step: 1
Training loss: 2.7681219577789307
Validation loss: 2.7823341687520347

Epoch: 6| Step: 2
Training loss: 2.7197275161743164
Validation loss: 2.7898144516893613

Epoch: 6| Step: 3
Training loss: 3.6540019512176514
Validation loss: 2.763399565091697

Epoch: 6| Step: 4
Training loss: 2.5030083656311035
Validation loss: 2.74947359741375

Epoch: 6| Step: 5
Training loss: 2.994873285293579
Validation loss: 2.743654228025867

Epoch: 6| Step: 6
Training loss: 3.5051825046539307
Validation loss: 2.7406263095076366

Epoch: 6| Step: 7
Training loss: 2.5900354385375977
Validation loss: 2.7383825394415084

Epoch: 6| Step: 8
Training loss: 2.5234780311584473
Validation loss: 2.735185182222756

Epoch: 6| Step: 9
Training loss: 2.736563205718994
Validation loss: 2.732915348904107

Epoch: 6| Step: 10
Training loss: 3.419459104537964
Validation loss: 2.7323978895782144

Epoch: 6| Step: 11
Training loss: 3.6510629653930664
Validation loss: 2.7240030073350474

Epoch: 6| Step: 12
Training loss: 2.6192336082458496
Validation loss: 2.718970050093948

Epoch: 6| Step: 13
Training loss: 2.5639467239379883
Validation loss: 2.709198446683986

Epoch: 8| Step: 0
Training loss: 2.975431203842163
Validation loss: 2.6989612630618516

Epoch: 6| Step: 1
Training loss: 2.3940625190734863
Validation loss: 2.690639329212968

Epoch: 6| Step: 2
Training loss: 2.7928194999694824
Validation loss: 2.7106826587389876

Epoch: 6| Step: 3
Training loss: 3.20525860786438
Validation loss: 2.7249078237882225

Epoch: 6| Step: 4
Training loss: 2.561877489089966
Validation loss: 2.721560450010402

Epoch: 6| Step: 5
Training loss: 2.8143372535705566
Validation loss: 2.679768834062802

Epoch: 6| Step: 6
Training loss: 3.6509933471679688
Validation loss: 2.6737077107993503

Epoch: 6| Step: 7
Training loss: 2.9016456604003906
Validation loss: 2.670997324810233

Epoch: 6| Step: 8
Training loss: 3.147348403930664
Validation loss: 2.676644366274598

Epoch: 6| Step: 9
Training loss: 2.589723587036133
Validation loss: 2.6737382950321322

Epoch: 6| Step: 10
Training loss: 2.3759026527404785
Validation loss: 2.6686864540141118

Epoch: 6| Step: 11
Training loss: 2.4578864574432373
Validation loss: 2.6631567785816808

Epoch: 6| Step: 12
Training loss: 3.278615951538086
Validation loss: 2.6573090450738066

Epoch: 6| Step: 13
Training loss: 2.865353584289551
Validation loss: 2.6500954474172285

Epoch: 9| Step: 0
Training loss: 2.7991111278533936
Validation loss: 2.644421313398628

Epoch: 6| Step: 1
Training loss: 2.759974479675293
Validation loss: 2.6359893916755595

Epoch: 6| Step: 2
Training loss: 3.0749216079711914
Validation loss: 2.628933496372674

Epoch: 6| Step: 3
Training loss: 2.2927680015563965
Validation loss: 2.6302124274674283

Epoch: 6| Step: 4
Training loss: 2.907747268676758
Validation loss: 2.6293020812414025

Epoch: 6| Step: 5
Training loss: 2.6641058921813965
Validation loss: 2.6213890480738815

Epoch: 6| Step: 6
Training loss: 2.702670097351074
Validation loss: 2.6094547958784204

Epoch: 6| Step: 7
Training loss: 3.3259716033935547
Validation loss: 2.592737328621649

Epoch: 6| Step: 8
Training loss: 2.8565094470977783
Validation loss: 2.5845170918331353

Epoch: 6| Step: 9
Training loss: 3.379678726196289
Validation loss: 2.5784593397571194

Epoch: 6| Step: 10
Training loss: 2.4160311222076416
Validation loss: 2.5733142937383344

Epoch: 6| Step: 11
Training loss: 2.573225259780884
Validation loss: 2.5685568342926683

Epoch: 6| Step: 12
Training loss: 2.6787121295928955
Validation loss: 2.5588919860060497

Epoch: 6| Step: 13
Training loss: 2.7636425495147705
Validation loss: 2.5570670917469966

Epoch: 10| Step: 0
Training loss: 2.5982346534729004
Validation loss: 2.551366444556944

Epoch: 6| Step: 1
Training loss: 3.822479724884033
Validation loss: 2.5666007893059843

Epoch: 6| Step: 2
Training loss: 3.3405685424804688
Validation loss: 2.601259021348851

Epoch: 6| Step: 3
Training loss: 2.462161064147949
Validation loss: 2.5659095651359967

Epoch: 6| Step: 4
Training loss: 2.6321680545806885
Validation loss: 2.539267375905027

Epoch: 6| Step: 5
Training loss: 2.290342092514038
Validation loss: 2.5377769752215316

Epoch: 6| Step: 6
Training loss: 1.8762290477752686
Validation loss: 2.548143148422241

Epoch: 6| Step: 7
Training loss: 2.680243492126465
Validation loss: 2.5740059832090973

Epoch: 6| Step: 8
Training loss: 3.2315726280212402
Validation loss: 2.5961699947234123

Epoch: 6| Step: 9
Training loss: 2.824646234512329
Validation loss: 2.598860307406354

Epoch: 6| Step: 10
Training loss: 2.4268198013305664
Validation loss: 2.5758257591596214

Epoch: 6| Step: 11
Training loss: 2.5262036323547363
Validation loss: 2.550334297200685

Epoch: 6| Step: 12
Training loss: 3.066957950592041
Validation loss: 2.528833420045914

Epoch: 6| Step: 13
Training loss: 3.0932579040527344
Validation loss: 2.5284599822054625

Epoch: 11| Step: 0
Training loss: 2.5930917263031006
Validation loss: 2.52802215596681

Epoch: 6| Step: 1
Training loss: 1.783581256866455
Validation loss: 2.5349416450787614

Epoch: 6| Step: 2
Training loss: 2.0629162788391113
Validation loss: 2.533801991452453

Epoch: 6| Step: 3
Training loss: 3.8067920207977295
Validation loss: 2.5489709120924755

Epoch: 6| Step: 4
Training loss: 2.203089714050293
Validation loss: 2.528315803056122

Epoch: 6| Step: 5
Training loss: 2.6825923919677734
Validation loss: 2.5146150537716445

Epoch: 6| Step: 6
Training loss: 2.8142380714416504
Validation loss: 2.5049793412608485

Epoch: 6| Step: 7
Training loss: 2.829322338104248
Validation loss: 2.492078140217771

Epoch: 6| Step: 8
Training loss: 2.7727198600769043
Validation loss: 2.490457542480961

Epoch: 6| Step: 9
Training loss: 2.566710948944092
Validation loss: 2.4991620279127553

Epoch: 6| Step: 10
Training loss: 3.0641651153564453
Validation loss: 2.4869143911587295

Epoch: 6| Step: 11
Training loss: 2.887361526489258
Validation loss: 2.48497631472926

Epoch: 6| Step: 12
Training loss: 3.251713275909424
Validation loss: 2.498591089761385

Epoch: 6| Step: 13
Training loss: 3.155487060546875
Validation loss: 2.500908059458579

Epoch: 12| Step: 0
Training loss: 2.731343984603882
Validation loss: 2.481506339965328

Epoch: 6| Step: 1
Training loss: 2.718902111053467
Validation loss: 2.5019967940545853

Epoch: 6| Step: 2
Training loss: 2.1797380447387695
Validation loss: 2.502653460348806

Epoch: 6| Step: 3
Training loss: 2.328843355178833
Validation loss: 2.477674938017322

Epoch: 6| Step: 4
Training loss: 3.1604557037353516
Validation loss: 2.466113431479341

Epoch: 6| Step: 5
Training loss: 3.63617205619812
Validation loss: 2.4717654156428512

Epoch: 6| Step: 6
Training loss: 2.5241029262542725
Validation loss: 2.483019044322352

Epoch: 6| Step: 7
Training loss: 2.9491114616394043
Validation loss: 2.4714894986921743

Epoch: 6| Step: 8
Training loss: 2.400650978088379
Validation loss: 2.460591600787255

Epoch: 6| Step: 9
Training loss: 3.131281852722168
Validation loss: 2.4581735339216007

Epoch: 6| Step: 10
Training loss: 3.6263794898986816
Validation loss: 2.453607879659181

Epoch: 6| Step: 11
Training loss: 2.5458264350891113
Validation loss: 2.4492099695308234

Epoch: 6| Step: 12
Training loss: 1.927342414855957
Validation loss: 2.439345100874542

Epoch: 6| Step: 13
Training loss: 1.5967234373092651
Validation loss: 2.4449661547137844

Epoch: 13| Step: 0
Training loss: 3.144538164138794
Validation loss: 2.4373675571974887

Epoch: 6| Step: 1
Training loss: 2.956538438796997
Validation loss: 2.441822800585019

Epoch: 6| Step: 2
Training loss: 2.3048460483551025
Validation loss: 2.454829321112684

Epoch: 6| Step: 3
Training loss: 2.0975260734558105
Validation loss: 2.472482878674743

Epoch: 6| Step: 4
Training loss: 2.3327198028564453
Validation loss: 2.474999012485627

Epoch: 6| Step: 5
Training loss: 2.5263845920562744
Validation loss: 2.490521979588334

Epoch: 6| Step: 6
Training loss: 3.2004573345184326
Validation loss: 2.4835642025034916

Epoch: 6| Step: 7
Training loss: 2.9110922813415527
Validation loss: 2.4366938426930416

Epoch: 6| Step: 8
Training loss: 2.0609898567199707
Validation loss: 2.407246440969488

Epoch: 6| Step: 9
Training loss: 3.415123462677002
Validation loss: 2.401071684334868

Epoch: 6| Step: 10
Training loss: 1.6639330387115479
Validation loss: 2.40624935396256

Epoch: 6| Step: 11
Training loss: 2.6869847774505615
Validation loss: 2.4160254616891184

Epoch: 6| Step: 12
Training loss: 3.0694689750671387
Validation loss: 2.4117317686798754

Epoch: 6| Step: 13
Training loss: 3.4199154376983643
Validation loss: 2.404683728371897

Epoch: 14| Step: 0
Training loss: 2.7669076919555664
Validation loss: 2.4066266449548865

Epoch: 6| Step: 1
Training loss: 2.920994520187378
Validation loss: 2.4229924217347176

Epoch: 6| Step: 2
Training loss: 2.204341173171997
Validation loss: 2.4800556577661985

Epoch: 6| Step: 3
Training loss: 2.2590324878692627
Validation loss: 2.4984147574311946

Epoch: 6| Step: 4
Training loss: 2.699387550354004
Validation loss: 2.4824196933418192

Epoch: 6| Step: 5
Training loss: 2.8729610443115234
Validation loss: 2.458677658470728

Epoch: 6| Step: 6
Training loss: 2.4780983924865723
Validation loss: 2.4550026027105187

Epoch: 6| Step: 7
Training loss: 2.5053746700286865
Validation loss: 2.4584024824121946

Epoch: 6| Step: 8
Training loss: 3.7545676231384277
Validation loss: 2.4713960360455256

Epoch: 6| Step: 9
Training loss: 2.5134224891662598
Validation loss: 2.471625074263542

Epoch: 6| Step: 10
Training loss: 2.5129048824310303
Validation loss: 2.4721665305476033

Epoch: 6| Step: 11
Training loss: 2.867401599884033
Validation loss: 2.471877021174277

Epoch: 6| Step: 12
Training loss: 2.531186580657959
Validation loss: 2.4602716456177416

Epoch: 6| Step: 13
Training loss: 2.9782168865203857
Validation loss: 2.453468225335562

Epoch: 15| Step: 0
Training loss: 2.3099374771118164
Validation loss: 2.4632259889315535

Epoch: 6| Step: 1
Training loss: 1.9602617025375366
Validation loss: 2.4755465240888697

Epoch: 6| Step: 2
Training loss: 2.4762208461761475
Validation loss: 2.4751919777162614

Epoch: 6| Step: 3
Training loss: 3.047295570373535
Validation loss: 2.4500589037454255

Epoch: 6| Step: 4
Training loss: 2.7105908393859863
Validation loss: 2.4263232549031577

Epoch: 6| Step: 5
Training loss: 2.362950325012207
Validation loss: 2.4139970605091383

Epoch: 6| Step: 6
Training loss: 2.2319202423095703
Validation loss: 2.415379725476747

Epoch: 6| Step: 7
Training loss: 2.9982528686523438
Validation loss: 2.4222414352560557

Epoch: 6| Step: 8
Training loss: 2.4458274841308594
Validation loss: 2.4187132645678777

Epoch: 6| Step: 9
Training loss: 3.3185083866119385
Validation loss: 2.41593502413842

Epoch: 6| Step: 10
Training loss: 2.8956494331359863
Validation loss: 2.412949033962783

Epoch: 6| Step: 11
Training loss: 3.3536763191223145
Validation loss: 2.397915445348268

Epoch: 6| Step: 12
Training loss: 2.3057897090911865
Validation loss: 2.3863995203407864

Epoch: 6| Step: 13
Training loss: 3.2673215866088867
Validation loss: 2.374559074319819

Epoch: 16| Step: 0
Training loss: 3.0067553520202637
Validation loss: 2.3671726898480485

Epoch: 6| Step: 1
Training loss: 3.238959550857544
Validation loss: 2.375732183456421

Epoch: 6| Step: 2
Training loss: 2.6926732063293457
Validation loss: 2.381353014258928

Epoch: 6| Step: 3
Training loss: 2.632766008377075
Validation loss: 2.3666229171137654

Epoch: 6| Step: 4
Training loss: 2.362447500228882
Validation loss: 2.3572648263746694

Epoch: 6| Step: 5
Training loss: 2.4695475101470947
Validation loss: 2.3455712461984284

Epoch: 6| Step: 6
Training loss: 2.7297921180725098
Validation loss: 2.3413386973001624

Epoch: 6| Step: 7
Training loss: 2.7038753032684326
Validation loss: 2.3387919138836604

Epoch: 6| Step: 8
Training loss: 1.934496521949768
Validation loss: 2.346238572110412

Epoch: 6| Step: 9
Training loss: 2.935025215148926
Validation loss: 2.3511576575617634

Epoch: 6| Step: 10
Training loss: 2.6375834941864014
Validation loss: 2.3477605645374586

Epoch: 6| Step: 11
Training loss: 2.125518560409546
Validation loss: 2.3512749082298687

Epoch: 6| Step: 12
Training loss: 2.9677605628967285
Validation loss: 2.367457841032295

Epoch: 6| Step: 13
Training loss: 2.0870420932769775
Validation loss: 2.363253463980972

Epoch: 17| Step: 0
Training loss: 2.805539131164551
Validation loss: 2.34194355369896

Epoch: 6| Step: 1
Training loss: 3.2951459884643555
Validation loss: 2.319688297087146

Epoch: 6| Step: 2
Training loss: 2.5747902393341064
Validation loss: 2.3156819061566423

Epoch: 6| Step: 3
Training loss: 2.4598171710968018
Validation loss: 2.308182308750768

Epoch: 6| Step: 4
Training loss: 2.1943087577819824
Validation loss: 2.3109000587976105

Epoch: 6| Step: 5
Training loss: 3.426520347595215
Validation loss: 2.30959516186868

Epoch: 6| Step: 6
Training loss: 2.511167049407959
Validation loss: 2.305471889434322

Epoch: 6| Step: 7
Training loss: 2.4469168186187744
Validation loss: 2.3056497753307386

Epoch: 6| Step: 8
Training loss: 1.8238862752914429
Validation loss: 2.3012416619126514

Epoch: 6| Step: 9
Training loss: 2.7144975662231445
Validation loss: 2.30126929026778

Epoch: 6| Step: 10
Training loss: 2.8015143871307373
Validation loss: 2.3164780460378176

Epoch: 6| Step: 11
Training loss: 2.385920524597168
Validation loss: 2.3196470711820867

Epoch: 6| Step: 12
Training loss: 2.6382689476013184
Validation loss: 2.3428794260947936

Epoch: 6| Step: 13
Training loss: 2.415224552154541
Validation loss: 2.4008456071217856

Epoch: 18| Step: 0
Training loss: 3.1086959838867188
Validation loss: 2.4181483432810795

Epoch: 6| Step: 1
Training loss: 3.2555394172668457
Validation loss: 2.39927230599106

Epoch: 6| Step: 2
Training loss: 2.5711071491241455
Validation loss: 2.369641052779331

Epoch: 6| Step: 3
Training loss: 2.6682076454162598
Validation loss: 2.3631846802209013

Epoch: 6| Step: 4
Training loss: 3.123847723007202
Validation loss: 2.3695740904859317

Epoch: 6| Step: 5
Training loss: 2.352597713470459
Validation loss: 2.354117601148544

Epoch: 6| Step: 6
Training loss: 2.854449510574341
Validation loss: 2.34884399496099

Epoch: 6| Step: 7
Training loss: 1.6878719329833984
Validation loss: 2.3478722085234938

Epoch: 6| Step: 8
Training loss: 2.023752212524414
Validation loss: 2.3463818847492175

Epoch: 6| Step: 9
Training loss: 2.35396671295166
Validation loss: 2.333925585592947

Epoch: 6| Step: 10
Training loss: 2.576537609100342
Validation loss: 2.3276135742023425

Epoch: 6| Step: 11
Training loss: 2.4639017581939697
Validation loss: 2.2988275020353255

Epoch: 6| Step: 12
Training loss: 3.299865484237671
Validation loss: 2.3007802194164646

Epoch: 6| Step: 13
Training loss: 1.9274020195007324
Validation loss: 2.286992762678413

Epoch: 19| Step: 0
Training loss: 1.8823390007019043
Validation loss: 2.275755266989431

Epoch: 6| Step: 1
Training loss: 2.367736339569092
Validation loss: 2.267879637338782

Epoch: 6| Step: 2
Training loss: 2.6837167739868164
Validation loss: 2.275996997792234

Epoch: 6| Step: 3
Training loss: 2.6229355335235596
Validation loss: 2.3106251044939925

Epoch: 6| Step: 4
Training loss: 2.922396183013916
Validation loss: 2.3629267164455947

Epoch: 6| Step: 5
Training loss: 2.417903423309326
Validation loss: 2.409693428265151

Epoch: 6| Step: 6
Training loss: 2.053283214569092
Validation loss: 2.4437640354197514

Epoch: 6| Step: 7
Training loss: 2.55159068107605
Validation loss: 2.414995321663477

Epoch: 6| Step: 8
Training loss: 2.660068988800049
Validation loss: 2.3091663775905484

Epoch: 6| Step: 9
Training loss: 3.0716633796691895
Validation loss: 2.2785452899112495

Epoch: 6| Step: 10
Training loss: 2.8108339309692383
Validation loss: 2.2810296627783004

Epoch: 6| Step: 11
Training loss: 2.5933332443237305
Validation loss: 2.2709177386376167

Epoch: 6| Step: 12
Training loss: 3.302051067352295
Validation loss: 2.2635669028887184

Epoch: 6| Step: 13
Training loss: 2.5821948051452637
Validation loss: 2.2649353165780344

Epoch: 20| Step: 0
Training loss: 2.4504892826080322
Validation loss: 2.261375913055994

Epoch: 6| Step: 1
Training loss: 2.0221235752105713
Validation loss: 2.2764657056459816

Epoch: 6| Step: 2
Training loss: 2.950528383255005
Validation loss: 2.293631366504136

Epoch: 6| Step: 3
Training loss: 2.7961957454681396
Validation loss: 2.307428139512257

Epoch: 6| Step: 4
Training loss: 2.216447353363037
Validation loss: 2.300059897925264

Epoch: 6| Step: 5
Training loss: 2.8212122917175293
Validation loss: 2.2983397155679683

Epoch: 6| Step: 6
Training loss: 2.8327651023864746
Validation loss: 2.269110228425713

Epoch: 6| Step: 7
Training loss: 2.610884189605713
Validation loss: 2.2573317558534685

Epoch: 6| Step: 8
Training loss: 2.472512722015381
Validation loss: 2.2498329813762377

Epoch: 6| Step: 9
Training loss: 2.5810914039611816
Validation loss: 2.2533319227157103

Epoch: 6| Step: 10
Training loss: 1.7149021625518799
Validation loss: 2.2573447791478967

Epoch: 6| Step: 11
Training loss: 3.045356273651123
Validation loss: 2.2640592180272585

Epoch: 6| Step: 12
Training loss: 2.213479995727539
Validation loss: 2.2692141686716387

Epoch: 6| Step: 13
Training loss: 3.7507734298706055
Validation loss: 2.302569943089639

Epoch: 21| Step: 0
Training loss: 2.435513973236084
Validation loss: 2.354931201986087

Epoch: 6| Step: 1
Training loss: 2.4534716606140137
Validation loss: 2.3595616766201553

Epoch: 6| Step: 2
Training loss: 2.74851393699646
Validation loss: 2.3671300693224837

Epoch: 6| Step: 3
Training loss: 3.093864917755127
Validation loss: 2.38030078077829

Epoch: 6| Step: 4
Training loss: 2.8177826404571533
Validation loss: 2.3857793551619335

Epoch: 6| Step: 5
Training loss: 2.243122100830078
Validation loss: 2.3786744968865507

Epoch: 6| Step: 6
Training loss: 2.693479061126709
Validation loss: 2.3664583954759824

Epoch: 6| Step: 7
Training loss: 2.907308340072632
Validation loss: 2.3672194993624123

Epoch: 6| Step: 8
Training loss: 2.4638383388519287
Validation loss: 2.3776406729093162

Epoch: 6| Step: 9
Training loss: 3.036430835723877
Validation loss: 2.3723491161100325

Epoch: 6| Step: 10
Training loss: 2.810750961303711
Validation loss: 2.337643333660659

Epoch: 6| Step: 11
Training loss: 2.0618152618408203
Validation loss: 2.3335684627614994

Epoch: 6| Step: 12
Training loss: 2.493288516998291
Validation loss: 2.3310632936416136

Epoch: 6| Step: 13
Training loss: 1.9755927324295044
Validation loss: 2.336610391575803

Epoch: 22| Step: 0
Training loss: 2.4334986209869385
Validation loss: 2.359774153719666

Epoch: 6| Step: 1
Training loss: 1.9032336473464966
Validation loss: 2.3697393683977026

Epoch: 6| Step: 2
Training loss: 2.482456922531128
Validation loss: 2.329546054204305

Epoch: 6| Step: 3
Training loss: 2.778141498565674
Validation loss: 2.280779074597102

Epoch: 6| Step: 4
Training loss: 2.2155539989471436
Validation loss: 2.28677196656504

Epoch: 6| Step: 5
Training loss: 2.673511505126953
Validation loss: 2.3027725501727034

Epoch: 6| Step: 6
Training loss: 2.4808363914489746
Validation loss: 2.2626025266544794

Epoch: 6| Step: 7
Training loss: 3.509377956390381
Validation loss: 2.259548048819265

Epoch: 6| Step: 8
Training loss: 2.7139923572540283
Validation loss: 2.2445098905153174

Epoch: 6| Step: 9
Training loss: 2.9166455268859863
Validation loss: 2.2583821332582863

Epoch: 6| Step: 10
Training loss: 2.8471648693084717
Validation loss: 2.282128462227442

Epoch: 6| Step: 11
Training loss: 2.528181552886963
Validation loss: 2.302616814131378

Epoch: 6| Step: 12
Training loss: 1.9697434902191162
Validation loss: 2.328899065653483

Epoch: 6| Step: 13
Training loss: 2.6210081577301025
Validation loss: 2.3430791452366817

Epoch: 23| Step: 0
Training loss: 2.632993459701538
Validation loss: 2.3721158350667646

Epoch: 6| Step: 1
Training loss: 2.7786593437194824
Validation loss: 2.34077779452006

Epoch: 6| Step: 2
Training loss: 2.5075531005859375
Validation loss: 2.2846631875602146

Epoch: 6| Step: 3
Training loss: 2.76069712638855
Validation loss: 2.2396155454779185

Epoch: 6| Step: 4
Training loss: 2.6808650493621826
Validation loss: 2.224120283639559

Epoch: 6| Step: 5
Training loss: 3.0063657760620117
Validation loss: 2.2231779970148557

Epoch: 6| Step: 6
Training loss: 2.3351426124572754
Validation loss: 2.2483222689679874

Epoch: 6| Step: 7
Training loss: 2.45939564704895
Validation loss: 2.2539700743972615

Epoch: 6| Step: 8
Training loss: 3.171975612640381
Validation loss: 2.224984895798468

Epoch: 6| Step: 9
Training loss: 1.949439287185669
Validation loss: 2.2077784230632167

Epoch: 6| Step: 10
Training loss: 2.9112117290496826
Validation loss: 2.227206350654684

Epoch: 6| Step: 11
Training loss: 2.4838833808898926
Validation loss: 2.2669182298003987

Epoch: 6| Step: 12
Training loss: 2.1968913078308105
Validation loss: 2.331282356733917

Epoch: 6| Step: 13
Training loss: 1.8437097072601318
Validation loss: 2.4158690180829776

Epoch: 24| Step: 0
Training loss: 2.734752893447876
Validation loss: 2.3832347751945577

Epoch: 6| Step: 1
Training loss: 3.022935628890991
Validation loss: 2.3257572727818645

Epoch: 6| Step: 2
Training loss: 3.1706576347351074
Validation loss: 2.291026753763999

Epoch: 6| Step: 3
Training loss: 2.3398516178131104
Validation loss: 2.2247476321394726

Epoch: 6| Step: 4
Training loss: 2.925037384033203
Validation loss: 2.1947224063258015

Epoch: 6| Step: 5
Training loss: 2.698883056640625
Validation loss: 2.1864597707666378

Epoch: 6| Step: 6
Training loss: 1.9946279525756836
Validation loss: 2.1926484210516817

Epoch: 6| Step: 7
Training loss: 2.1330409049987793
Validation loss: 2.1967602545215237

Epoch: 6| Step: 8
Training loss: 2.803847312927246
Validation loss: 2.1992139149737615

Epoch: 6| Step: 9
Training loss: 2.0587639808654785
Validation loss: 2.198893388112386

Epoch: 6| Step: 10
Training loss: 2.161177158355713
Validation loss: 2.1905971214335453

Epoch: 6| Step: 11
Training loss: 2.334402561187744
Validation loss: 2.1875188017404206

Epoch: 6| Step: 12
Training loss: 2.384896755218506
Validation loss: 2.1877258516127065

Epoch: 6| Step: 13
Training loss: 3.326571464538574
Validation loss: 2.1826441646904073

Epoch: 25| Step: 0
Training loss: 2.631242275238037
Validation loss: 2.190913777197561

Epoch: 6| Step: 1
Training loss: 2.321951389312744
Validation loss: 2.1994016760139057

Epoch: 6| Step: 2
Training loss: 2.835501194000244
Validation loss: 2.2241293025273148

Epoch: 6| Step: 3
Training loss: 1.7844915390014648
Validation loss: 2.2307014426877423

Epoch: 6| Step: 4
Training loss: 2.5535683631896973
Validation loss: 2.2400105512270363

Epoch: 6| Step: 5
Training loss: 1.7524702548980713
Validation loss: 2.236667920184392

Epoch: 6| Step: 6
Training loss: 2.2015295028686523
Validation loss: 2.2198242782264628

Epoch: 6| Step: 7
Training loss: 2.3074631690979004
Validation loss: 2.2168395621802217

Epoch: 6| Step: 8
Training loss: 2.632697582244873
Validation loss: 2.205712382511426

Epoch: 6| Step: 9
Training loss: 2.9632034301757812
Validation loss: 2.206773696407195

Epoch: 6| Step: 10
Training loss: 2.913618564605713
Validation loss: 2.207790974647768

Epoch: 6| Step: 11
Training loss: 3.408229351043701
Validation loss: 2.2102996508280435

Epoch: 6| Step: 12
Training loss: 2.5635318756103516
Validation loss: 2.2117560704549155

Epoch: 6| Step: 13
Training loss: 2.2265114784240723
Validation loss: 2.239374142821117

Epoch: 26| Step: 0
Training loss: 2.787013530731201
Validation loss: 2.2481809559688775

Epoch: 6| Step: 1
Training loss: 3.204777717590332
Validation loss: 2.2087361248590613

Epoch: 6| Step: 2
Training loss: 2.4924330711364746
Validation loss: 2.1757084400423112

Epoch: 6| Step: 3
Training loss: 2.308981418609619
Validation loss: 2.1650813497522825

Epoch: 6| Step: 4
Training loss: 2.8403232097625732
Validation loss: 2.1630998785777757

Epoch: 6| Step: 5
Training loss: 1.726454257965088
Validation loss: 2.165672722683158

Epoch: 6| Step: 6
Training loss: 1.9654436111450195
Validation loss: 2.1704495901702554

Epoch: 6| Step: 7
Training loss: 1.9807555675506592
Validation loss: 2.1844061856628745

Epoch: 6| Step: 8
Training loss: 1.9745899438858032
Validation loss: 2.1975530847426383

Epoch: 6| Step: 9
Training loss: 3.1826844215393066
Validation loss: 2.219868347208987

Epoch: 6| Step: 10
Training loss: 2.401097536087036
Validation loss: 2.227394779523214

Epoch: 6| Step: 11
Training loss: 2.8780903816223145
Validation loss: 2.215168422268283

Epoch: 6| Step: 12
Training loss: 2.660684823989868
Validation loss: 2.189469475899973

Epoch: 6| Step: 13
Training loss: 3.1328089237213135
Validation loss: 2.173529786448325

Epoch: 27| Step: 0
Training loss: 1.3613409996032715
Validation loss: 2.16762206374958

Epoch: 6| Step: 1
Training loss: 3.0723559856414795
Validation loss: 2.1617441472186836

Epoch: 6| Step: 2
Training loss: 2.9740281105041504
Validation loss: 2.153689786952029

Epoch: 6| Step: 3
Training loss: 2.1791396141052246
Validation loss: 2.155214264828672

Epoch: 6| Step: 4
Training loss: 1.758630633354187
Validation loss: 2.1572134776781966

Epoch: 6| Step: 5
Training loss: 2.83453106880188
Validation loss: 2.157901156333185

Epoch: 6| Step: 6
Training loss: 2.5706310272216797
Validation loss: 2.157670077457223

Epoch: 6| Step: 7
Training loss: 2.602869987487793
Validation loss: 2.1577341838549544

Epoch: 6| Step: 8
Training loss: 1.8825165033340454
Validation loss: 2.157535319687218

Epoch: 6| Step: 9
Training loss: 2.1529760360717773
Validation loss: 2.1540261917216803

Epoch: 6| Step: 10
Training loss: 2.9214301109313965
Validation loss: 2.154611861833962

Epoch: 6| Step: 11
Training loss: 2.97446346282959
Validation loss: 2.1570216019948325

Epoch: 6| Step: 12
Training loss: 2.794041156768799
Validation loss: 2.1489886340274604

Epoch: 6| Step: 13
Training loss: 2.821019411087036
Validation loss: 2.1526143550872803

Epoch: 28| Step: 0
Training loss: 2.952768325805664
Validation loss: 2.160593476346744

Epoch: 6| Step: 1
Training loss: 2.486621379852295
Validation loss: 2.1762059478349585

Epoch: 6| Step: 2
Training loss: 2.652090549468994
Validation loss: 2.1800843028612036

Epoch: 6| Step: 3
Training loss: 2.8153536319732666
Validation loss: 2.1781663625471053

Epoch: 6| Step: 4
Training loss: 1.7667090892791748
Validation loss: 2.1804383467602473

Epoch: 6| Step: 5
Training loss: 2.402151584625244
Validation loss: 2.1792851583932036

Epoch: 6| Step: 6
Training loss: 1.5316283702850342
Validation loss: 2.190134947017957

Epoch: 6| Step: 7
Training loss: 2.7053627967834473
Validation loss: 2.182782667939381

Epoch: 6| Step: 8
Training loss: 2.3061671257019043
Validation loss: 2.1602551462829753

Epoch: 6| Step: 9
Training loss: 2.1438968181610107
Validation loss: 2.1393636221526773

Epoch: 6| Step: 10
Training loss: 2.8819117546081543
Validation loss: 2.139247276449716

Epoch: 6| Step: 11
Training loss: 2.5179624557495117
Validation loss: 2.138490346170241

Epoch: 6| Step: 12
Training loss: 2.7103543281555176
Validation loss: 2.1426765585458405

Epoch: 6| Step: 13
Training loss: 3.22074031829834
Validation loss: 2.145157060315532

Epoch: 29| Step: 0
Training loss: 2.654982089996338
Validation loss: 2.1321756544933526

Epoch: 6| Step: 1
Training loss: 2.5001349449157715
Validation loss: 2.1320539520632837

Epoch: 6| Step: 2
Training loss: 3.153907537460327
Validation loss: 2.1432486554627777

Epoch: 6| Step: 3
Training loss: 2.2876577377319336
Validation loss: 2.162535148282205

Epoch: 6| Step: 4
Training loss: 2.5494165420532227
Validation loss: 2.18265397702494

Epoch: 6| Step: 5
Training loss: 2.450411558151245
Validation loss: 2.1706163062844226

Epoch: 6| Step: 6
Training loss: 2.2182395458221436
Validation loss: 2.1818108033108454

Epoch: 6| Step: 7
Training loss: 2.0219764709472656
Validation loss: 2.1758318562661447

Epoch: 6| Step: 8
Training loss: 2.248279094696045
Validation loss: 2.1906827829217397

Epoch: 6| Step: 9
Training loss: 2.55958890914917
Validation loss: 2.2408539146505375

Epoch: 6| Step: 10
Training loss: 2.5407052040100098
Validation loss: 2.2308557392448507

Epoch: 6| Step: 11
Training loss: 2.1079795360565186
Validation loss: 2.217894564392746

Epoch: 6| Step: 12
Training loss: 2.816004753112793
Validation loss: 2.1673552643868232

Epoch: 6| Step: 13
Training loss: 2.825611114501953
Validation loss: 2.135707691151609

Epoch: 30| Step: 0
Training loss: 2.9066269397735596
Validation loss: 2.1355254009205806

Epoch: 6| Step: 1
Training loss: 2.281703472137451
Validation loss: 2.1651746611441336

Epoch: 6| Step: 2
Training loss: 3.078803539276123
Validation loss: 2.2211879632806264

Epoch: 6| Step: 3
Training loss: 2.602175235748291
Validation loss: 2.3140914337609404

Epoch: 6| Step: 4
Training loss: 3.130561113357544
Validation loss: 2.4187672445850987

Epoch: 6| Step: 5
Training loss: 2.637239456176758
Validation loss: 2.24534636159097

Epoch: 6| Step: 6
Training loss: 1.9797227382659912
Validation loss: 2.159378238903579

Epoch: 6| Step: 7
Training loss: 2.8449926376342773
Validation loss: 2.1265026728312173

Epoch: 6| Step: 8
Training loss: 3.1158018112182617
Validation loss: 2.1227281426870697

Epoch: 6| Step: 9
Training loss: 1.9327008724212646
Validation loss: 2.1628607421792965

Epoch: 6| Step: 10
Training loss: 2.4248671531677246
Validation loss: 2.2018321175729074

Epoch: 6| Step: 11
Training loss: 2.520538330078125
Validation loss: 2.262009829603216

Epoch: 6| Step: 12
Training loss: 2.2221577167510986
Validation loss: 2.2638142185826458

Epoch: 6| Step: 13
Training loss: 2.6589860916137695
Validation loss: 2.218166992228518

Epoch: 31| Step: 0
Training loss: 3.069370985031128
Validation loss: 2.1530597876476985

Epoch: 6| Step: 1
Training loss: 2.2648658752441406
Validation loss: 2.1317070837943786

Epoch: 6| Step: 2
Training loss: 2.7009077072143555
Validation loss: 2.123778079145698

Epoch: 6| Step: 3
Training loss: 2.694828987121582
Validation loss: 2.1148460270256124

Epoch: 6| Step: 4
Training loss: 2.8033571243286133
Validation loss: 2.1229714270560973

Epoch: 6| Step: 5
Training loss: 2.1086463928222656
Validation loss: 2.127360678488208

Epoch: 6| Step: 6
Training loss: 2.73075795173645
Validation loss: 2.1280950679573962

Epoch: 6| Step: 7
Training loss: 2.050084114074707
Validation loss: 2.1540963803568194

Epoch: 6| Step: 8
Training loss: 2.3961434364318848
Validation loss: 2.1601166802067913

Epoch: 6| Step: 9
Training loss: 2.7478575706481934
Validation loss: 2.1881847971229145

Epoch: 6| Step: 10
Training loss: 1.7492921352386475
Validation loss: 2.178137735653949

Epoch: 6| Step: 11
Training loss: 2.7416601181030273
Validation loss: 2.1660176451488207

Epoch: 6| Step: 12
Training loss: 2.1248552799224854
Validation loss: 2.139700292259134

Epoch: 6| Step: 13
Training loss: 2.688479423522949
Validation loss: 2.1166682986802954

Epoch: 32| Step: 0
Training loss: 1.899327278137207
Validation loss: 2.106262622341033

Epoch: 6| Step: 1
Training loss: 2.0836877822875977
Validation loss: 2.108703536372031

Epoch: 6| Step: 2
Training loss: 2.334275722503662
Validation loss: 2.1085800919481503

Epoch: 6| Step: 3
Training loss: 2.508363723754883
Validation loss: 2.1060714555043045

Epoch: 6| Step: 4
Training loss: 3.1652021408081055
Validation loss: 2.1073605834796862

Epoch: 6| Step: 5
Training loss: 2.4486191272735596
Validation loss: 2.1058758202419487

Epoch: 6| Step: 6
Training loss: 2.971365451812744
Validation loss: 2.1028359051673644

Epoch: 6| Step: 7
Training loss: 2.229257345199585
Validation loss: 2.1063962533909786

Epoch: 6| Step: 8
Training loss: 2.332693099975586
Validation loss: 2.1069537593472387

Epoch: 6| Step: 9
Training loss: 2.7570581436157227
Validation loss: 2.1122984732350996

Epoch: 6| Step: 10
Training loss: 1.9344357252120972
Validation loss: 2.1275435378474574

Epoch: 6| Step: 11
Training loss: 3.314854860305786
Validation loss: 2.1459932763089418

Epoch: 6| Step: 12
Training loss: 2.1034531593322754
Validation loss: 2.16827832242494

Epoch: 6| Step: 13
Training loss: 2.770500898361206
Validation loss: 2.1894428922284033

Epoch: 33| Step: 0
Training loss: 2.585942506790161
Validation loss: 2.200724970909857

Epoch: 6| Step: 1
Training loss: 2.649489402770996
Validation loss: 2.2142166873460174

Epoch: 6| Step: 2
Training loss: 2.08778977394104
Validation loss: 2.2302997061001357

Epoch: 6| Step: 3
Training loss: 1.4149504899978638
Validation loss: 2.2480286987878944

Epoch: 6| Step: 4
Training loss: 2.7266604900360107
Validation loss: 2.2110686609821935

Epoch: 6| Step: 5
Training loss: 3.119208335876465
Validation loss: 2.2056925809511574

Epoch: 6| Step: 6
Training loss: 3.0439109802246094
Validation loss: 2.1668646489420245

Epoch: 6| Step: 7
Training loss: 1.9743674993515015
Validation loss: 2.139669677262665

Epoch: 6| Step: 8
Training loss: 2.977632999420166
Validation loss: 2.118901132255472

Epoch: 6| Step: 9
Training loss: 1.9965217113494873
Validation loss: 2.111608218121272

Epoch: 6| Step: 10
Training loss: 2.338144302368164
Validation loss: 2.1110559650646743

Epoch: 6| Step: 11
Training loss: 2.9383132457733154
Validation loss: 2.1133071453340593

Epoch: 6| Step: 12
Training loss: 2.5497024059295654
Validation loss: 2.1066504165690434

Epoch: 6| Step: 13
Training loss: 2.5232505798339844
Validation loss: 2.115650705111924

Epoch: 34| Step: 0
Training loss: 3.027470588684082
Validation loss: 2.1137615583276235

Epoch: 6| Step: 1
Training loss: 2.799485445022583
Validation loss: 2.100532680429438

Epoch: 6| Step: 2
Training loss: 1.7982828617095947
Validation loss: 2.0971494977192213

Epoch: 6| Step: 3
Training loss: 2.45045804977417
Validation loss: 2.1053447543933825

Epoch: 6| Step: 4
Training loss: 2.7383460998535156
Validation loss: 2.1204506235737957

Epoch: 6| Step: 5
Training loss: 2.0228848457336426
Validation loss: 2.1489941971276396

Epoch: 6| Step: 6
Training loss: 2.2774367332458496
Validation loss: 2.1499699879718084

Epoch: 6| Step: 7
Training loss: 2.155323028564453
Validation loss: 2.144943698760002

Epoch: 6| Step: 8
Training loss: 2.0884153842926025
Validation loss: 2.1345173671681392

Epoch: 6| Step: 9
Training loss: 2.1779751777648926
Validation loss: 2.1173842389096498

Epoch: 6| Step: 10
Training loss: 2.837350845336914
Validation loss: 2.1005258149998163

Epoch: 6| Step: 11
Training loss: 2.8435497283935547
Validation loss: 2.095275285423443

Epoch: 6| Step: 12
Training loss: 2.3334555625915527
Validation loss: 2.0903150548217115

Epoch: 6| Step: 13
Training loss: 3.320128917694092
Validation loss: 2.1012364267021097

Epoch: 35| Step: 0
Training loss: 2.77774715423584
Validation loss: 2.1049236994917675

Epoch: 6| Step: 1
Training loss: 2.148225784301758
Validation loss: 2.1180361368322886

Epoch: 6| Step: 2
Training loss: 2.1630005836486816
Validation loss: 2.1401680618204098

Epoch: 6| Step: 3
Training loss: 2.28436017036438
Validation loss: 2.1498669424364643

Epoch: 6| Step: 4
Training loss: 3.206728458404541
Validation loss: 2.15628307865512

Epoch: 6| Step: 5
Training loss: 3.0057661533355713
Validation loss: 2.1487966481075493

Epoch: 6| Step: 6
Training loss: 2.082488536834717
Validation loss: 2.1397907093007076

Epoch: 6| Step: 7
Training loss: 2.562981367111206
Validation loss: 2.1337768723887782

Epoch: 6| Step: 8
Training loss: 2.166562557220459
Validation loss: 2.122015960754887

Epoch: 6| Step: 9
Training loss: 1.6684224605560303
Validation loss: 2.1106513520722747

Epoch: 6| Step: 10
Training loss: 2.62430477142334
Validation loss: 2.103998855877948

Epoch: 6| Step: 11
Training loss: 2.638692855834961
Validation loss: 2.0982974524139077

Epoch: 6| Step: 12
Training loss: 2.3815066814422607
Validation loss: 2.0926502366219797

Epoch: 6| Step: 13
Training loss: 2.4906821250915527
Validation loss: 2.0865733777323077

Epoch: 36| Step: 0
Training loss: 2.0763678550720215
Validation loss: 2.10040392157852

Epoch: 6| Step: 1
Training loss: 2.4571917057037354
Validation loss: 2.111461656067961

Epoch: 6| Step: 2
Training loss: 2.4970221519470215
Validation loss: 2.112764855866791

Epoch: 6| Step: 3
Training loss: 2.7775206565856934
Validation loss: 2.115632462245162

Epoch: 6| Step: 4
Training loss: 2.236891269683838
Validation loss: 2.1255389516071608

Epoch: 6| Step: 5
Training loss: 2.9893336296081543
Validation loss: 2.1234241480468423

Epoch: 6| Step: 6
Training loss: 2.504528284072876
Validation loss: 2.121373648284584

Epoch: 6| Step: 7
Training loss: 2.139570951461792
Validation loss: 2.1100448152070403

Epoch: 6| Step: 8
Training loss: 2.438156843185425
Validation loss: 2.1041526384251092

Epoch: 6| Step: 9
Training loss: 2.3549232482910156
Validation loss: 2.109578533839154

Epoch: 6| Step: 10
Training loss: 2.426665782928467
Validation loss: 2.115450527078362

Epoch: 6| Step: 11
Training loss: 2.671412229537964
Validation loss: 2.108654217053485

Epoch: 6| Step: 12
Training loss: 2.125805139541626
Validation loss: 2.1185203598391626

Epoch: 6| Step: 13
Training loss: 2.3646156787872314
Validation loss: 2.132966938839164

Epoch: 37| Step: 0
Training loss: 2.6725473403930664
Validation loss: 2.135626727534879

Epoch: 6| Step: 1
Training loss: 2.6604115962982178
Validation loss: 2.112449881851032

Epoch: 6| Step: 2
Training loss: 2.666818141937256
Validation loss: 2.0909796273836525

Epoch: 6| Step: 3
Training loss: 3.3357961177825928
Validation loss: 2.0903793099106

Epoch: 6| Step: 4
Training loss: 1.7458851337432861
Validation loss: 2.0950367783987396

Epoch: 6| Step: 5
Training loss: 2.9040517807006836
Validation loss: 2.129293651990993

Epoch: 6| Step: 6
Training loss: 1.9464755058288574
Validation loss: 2.128148627537553

Epoch: 6| Step: 7
Training loss: 2.854123592376709
Validation loss: 2.112307010158416

Epoch: 6| Step: 8
Training loss: 2.7622463703155518
Validation loss: 2.0961969334592103

Epoch: 6| Step: 9
Training loss: 2.6665406227111816
Validation loss: 2.0785643823685183

Epoch: 6| Step: 10
Training loss: 2.94411563873291
Validation loss: 2.064630527650156

Epoch: 6| Step: 11
Training loss: 1.0592386722564697
Validation loss: 2.0608636999642975

Epoch: 6| Step: 12
Training loss: 1.5931041240692139
Validation loss: 2.060110353654431

Epoch: 6| Step: 13
Training loss: 2.3363587856292725
Validation loss: 2.0571483283914547

Epoch: 38| Step: 0
Training loss: 1.9145071506500244
Validation loss: 2.0646730212755102

Epoch: 6| Step: 1
Training loss: 3.243363618850708
Validation loss: 2.061721691521265

Epoch: 6| Step: 2
Training loss: 2.9267964363098145
Validation loss: 2.0673842583933184

Epoch: 6| Step: 3
Training loss: 2.399240493774414
Validation loss: 2.0724781854178316

Epoch: 6| Step: 4
Training loss: 3.3134102821350098
Validation loss: 2.0650776663134174

Epoch: 6| Step: 5
Training loss: 2.3490095138549805
Validation loss: 2.066312866826211

Epoch: 6| Step: 6
Training loss: 1.9509681463241577
Validation loss: 2.0658790142305437

Epoch: 6| Step: 7
Training loss: 2.866969108581543
Validation loss: 2.0723103887291363

Epoch: 6| Step: 8
Training loss: 2.9026894569396973
Validation loss: 2.0884141973269883

Epoch: 6| Step: 9
Training loss: 1.903208613395691
Validation loss: 2.085330673443374

Epoch: 6| Step: 10
Training loss: 2.351451873779297
Validation loss: 2.092308659707346

Epoch: 6| Step: 11
Training loss: 1.9674338102340698
Validation loss: 2.0952145720040924

Epoch: 6| Step: 12
Training loss: 1.8474643230438232
Validation loss: 2.0833935096699703

Epoch: 6| Step: 13
Training loss: 1.2967230081558228
Validation loss: 2.088370297544746

Epoch: 39| Step: 0
Training loss: 2.384244441986084
Validation loss: 2.1123652637645765

Epoch: 6| Step: 1
Training loss: 2.0581893920898438
Validation loss: 2.1375628696974887

Epoch: 6| Step: 2
Training loss: 3.0475168228149414
Validation loss: 2.1262675767303794

Epoch: 6| Step: 3
Training loss: 2.546062707901001
Validation loss: 2.1311486613365913

Epoch: 6| Step: 4
Training loss: 2.660740375518799
Validation loss: 2.103745183637065

Epoch: 6| Step: 5
Training loss: 2.4891371726989746
Validation loss: 2.0884650394480717

Epoch: 6| Step: 6
Training loss: 2.1504921913146973
Validation loss: 2.0726578722717943

Epoch: 6| Step: 7
Training loss: 2.408750295639038
Validation loss: 2.060538620077154

Epoch: 6| Step: 8
Training loss: 2.3673033714294434
Validation loss: 2.051188706069864

Epoch: 6| Step: 9
Training loss: 2.280059814453125
Validation loss: 2.053823258287163

Epoch: 6| Step: 10
Training loss: 2.1184937953948975
Validation loss: 2.0593960310823176

Epoch: 6| Step: 11
Training loss: 2.4312586784362793
Validation loss: 2.056472636038257

Epoch: 6| Step: 12
Training loss: 2.3070194721221924
Validation loss: 2.0666263475213

Epoch: 6| Step: 13
Training loss: 2.86590576171875
Validation loss: 2.077262258016935

Epoch: 40| Step: 0
Training loss: 1.342307448387146
Validation loss: 2.1075055753031084

Epoch: 6| Step: 1
Training loss: 2.121551990509033
Validation loss: 2.123161023662936

Epoch: 6| Step: 2
Training loss: 2.261434555053711
Validation loss: 2.103189124855944

Epoch: 6| Step: 3
Training loss: 2.226283311843872
Validation loss: 2.093469791514899

Epoch: 6| Step: 4
Training loss: 2.4847562313079834
Validation loss: 2.1171100037072295

Epoch: 6| Step: 5
Training loss: 2.4449591636657715
Validation loss: 2.1638930356630715

Epoch: 6| Step: 6
Training loss: 3.2456350326538086
Validation loss: 2.202890516609274

Epoch: 6| Step: 7
Training loss: 2.5404865741729736
Validation loss: 2.1698695959583407

Epoch: 6| Step: 8
Training loss: 2.6357498168945312
Validation loss: 2.10475081013095

Epoch: 6| Step: 9
Training loss: 2.1016573905944824
Validation loss: 2.068063320652131

Epoch: 6| Step: 10
Training loss: 2.3918771743774414
Validation loss: 2.04494910342719

Epoch: 6| Step: 11
Training loss: 2.4747748374938965
Validation loss: 2.043609203830842

Epoch: 6| Step: 12
Training loss: 3.1594579219818115
Validation loss: 2.041928034956737

Epoch: 6| Step: 13
Training loss: 2.537529945373535
Validation loss: 2.044390497669097

Epoch: 41| Step: 0
Training loss: 2.146716833114624
Validation loss: 2.050545145106572

Epoch: 6| Step: 1
Training loss: 2.881540536880493
Validation loss: 2.0519875095736597

Epoch: 6| Step: 2
Training loss: 2.4146342277526855
Validation loss: 2.050155883194298

Epoch: 6| Step: 3
Training loss: 2.279665231704712
Validation loss: 2.046121274271319

Epoch: 6| Step: 4
Training loss: 2.4835047721862793
Validation loss: 2.0408143343464022

Epoch: 6| Step: 5
Training loss: 2.852391004562378
Validation loss: 2.0412176321911555

Epoch: 6| Step: 6
Training loss: 2.6221909523010254
Validation loss: 2.047289481727026

Epoch: 6| Step: 7
Training loss: 2.1599135398864746
Validation loss: 2.0651561726805983

Epoch: 6| Step: 8
Training loss: 2.6518101692199707
Validation loss: 2.0905692038997525

Epoch: 6| Step: 9
Training loss: 2.350370407104492
Validation loss: 2.1211634758980042

Epoch: 6| Step: 10
Training loss: 2.462773084640503
Validation loss: 2.1259352032856276

Epoch: 6| Step: 11
Training loss: 2.134714126586914
Validation loss: 2.126129279854477

Epoch: 6| Step: 12
Training loss: 1.9982115030288696
Validation loss: 2.1028441485538276

Epoch: 6| Step: 13
Training loss: 2.885129451751709
Validation loss: 2.0712265173594155

Epoch: 42| Step: 0
Training loss: 2.057495594024658
Validation loss: 2.036289871379893

Epoch: 6| Step: 1
Training loss: 2.81457781791687
Validation loss: 2.0520866199206282

Epoch: 6| Step: 2
Training loss: 2.6412510871887207
Validation loss: 2.083202585097282

Epoch: 6| Step: 3
Training loss: 1.9364973306655884
Validation loss: 2.112964448108468

Epoch: 6| Step: 4
Training loss: 2.9238500595092773
Validation loss: 2.098661791893744

Epoch: 6| Step: 5
Training loss: 2.668405055999756
Validation loss: 2.0753757774188952

Epoch: 6| Step: 6
Training loss: 1.7972007989883423
Validation loss: 2.0652084863314064

Epoch: 6| Step: 7
Training loss: 2.687189817428589
Validation loss: 2.041396088497613

Epoch: 6| Step: 8
Training loss: 2.5540316104888916
Validation loss: 2.048029967533645

Epoch: 6| Step: 9
Training loss: 2.0125818252563477
Validation loss: 2.0497155061332126

Epoch: 6| Step: 10
Training loss: 2.7562613487243652
Validation loss: 2.0590763732951176

Epoch: 6| Step: 11
Training loss: 2.47983980178833
Validation loss: 2.0886161942635812

Epoch: 6| Step: 12
Training loss: 2.7813353538513184
Validation loss: 2.1068058783008206

Epoch: 6| Step: 13
Training loss: 1.9040913581848145
Validation loss: 2.122344773302796

Epoch: 43| Step: 0
Training loss: 2.5107812881469727
Validation loss: 2.1150628366777973

Epoch: 6| Step: 1
Training loss: 2.923556327819824
Validation loss: 2.101667745139009

Epoch: 6| Step: 2
Training loss: 3.240536689758301
Validation loss: 2.0882465839385986

Epoch: 6| Step: 3
Training loss: 2.1819071769714355
Validation loss: 2.0873715339168424

Epoch: 6| Step: 4
Training loss: 1.421297550201416
Validation loss: 2.063951464109523

Epoch: 6| Step: 5
Training loss: 2.244431257247925
Validation loss: 2.052406228998656

Epoch: 6| Step: 6
Training loss: 1.8613215684890747
Validation loss: 2.0458343259749876

Epoch: 6| Step: 7
Training loss: 2.717461109161377
Validation loss: 2.042608902018557

Epoch: 6| Step: 8
Training loss: 2.922088384628296
Validation loss: 2.0424059744804137

Epoch: 6| Step: 9
Training loss: 2.514047145843506
Validation loss: 2.0430548191070557

Epoch: 6| Step: 10
Training loss: 2.2283272743225098
Validation loss: 2.0463171492340746

Epoch: 6| Step: 11
Training loss: 2.1929736137390137
Validation loss: 2.0445670414996404

Epoch: 6| Step: 12
Training loss: 2.6439027786254883
Validation loss: 2.0528175228385517

Epoch: 6| Step: 13
Training loss: 1.8657506704330444
Validation loss: 2.07421653116903

Epoch: 44| Step: 0
Training loss: 2.3756518363952637
Validation loss: 2.102226254760578

Epoch: 6| Step: 1
Training loss: 2.4065752029418945
Validation loss: 2.1379386353236374

Epoch: 6| Step: 2
Training loss: 2.274841070175171
Validation loss: 2.1787074868397047

Epoch: 6| Step: 3
Training loss: 2.678466320037842
Validation loss: 2.2180194726554294

Epoch: 6| Step: 4
Training loss: 2.7050399780273438
Validation loss: 2.2303641611529934

Epoch: 6| Step: 5
Training loss: 2.3944668769836426
Validation loss: 2.208347858921174

Epoch: 6| Step: 6
Training loss: 2.939636707305908
Validation loss: 2.16902014388833

Epoch: 6| Step: 7
Training loss: 2.921248197555542
Validation loss: 2.1335372668440624

Epoch: 6| Step: 8
Training loss: 1.9980220794677734
Validation loss: 2.09524856844256

Epoch: 6| Step: 9
Training loss: 2.363396167755127
Validation loss: 2.077036806332168

Epoch: 6| Step: 10
Training loss: 1.9890128374099731
Validation loss: 2.090704720507386

Epoch: 6| Step: 11
Training loss: 2.2035272121429443
Validation loss: 2.078980830407912

Epoch: 6| Step: 12
Training loss: 2.4261136054992676
Validation loss: 2.0761289147920508

Epoch: 6| Step: 13
Training loss: 2.7575130462646484
Validation loss: 2.0708859812828804

Epoch: 45| Step: 0
Training loss: 2.780970811843872
Validation loss: 2.067327832662931

Epoch: 6| Step: 1
Training loss: 2.328850030899048
Validation loss: 2.0673014169098227

Epoch: 6| Step: 2
Training loss: 2.1532034873962402
Validation loss: 2.068018187758743

Epoch: 6| Step: 3
Training loss: 2.7150115966796875
Validation loss: 2.0699128566249723

Epoch: 6| Step: 4
Training loss: 2.486630439758301
Validation loss: 2.0782995864909184

Epoch: 6| Step: 5
Training loss: 1.918055534362793
Validation loss: 2.085123933771605

Epoch: 6| Step: 6
Training loss: 2.9635677337646484
Validation loss: 2.0895850555871123

Epoch: 6| Step: 7
Training loss: 1.8844753503799438
Validation loss: 2.094225432283135

Epoch: 6| Step: 8
Training loss: 1.750802755355835
Validation loss: 2.1143978359878703

Epoch: 6| Step: 9
Training loss: 2.039513111114502
Validation loss: 2.1430989055223364

Epoch: 6| Step: 10
Training loss: 2.766159772872925
Validation loss: 2.2032720042813208

Epoch: 6| Step: 11
Training loss: 2.9599733352661133
Validation loss: 2.1986417744749334

Epoch: 6| Step: 12
Training loss: 2.732417583465576
Validation loss: 2.1789344536360873

Epoch: 6| Step: 13
Training loss: 2.014207601547241
Validation loss: 2.136687760711998

Epoch: 46| Step: 0
Training loss: 2.298527717590332
Validation loss: 2.1064336197350615

Epoch: 6| Step: 1
Training loss: 2.4746780395507812
Validation loss: 2.069269983999191

Epoch: 6| Step: 2
Training loss: 2.0981693267822266
Validation loss: 2.050510892304041

Epoch: 6| Step: 3
Training loss: 2.534057378768921
Validation loss: 2.042282050655734

Epoch: 6| Step: 4
Training loss: 2.906675338745117
Validation loss: 2.0485310477595173

Epoch: 6| Step: 5
Training loss: 2.171529769897461
Validation loss: 2.037486227609778

Epoch: 6| Step: 6
Training loss: 2.3097105026245117
Validation loss: 2.032439793309858

Epoch: 6| Step: 7
Training loss: 2.5287160873413086
Validation loss: 2.031693617502848

Epoch: 6| Step: 8
Training loss: 1.8951023817062378
Validation loss: 2.0306491813352032

Epoch: 6| Step: 9
Training loss: 2.428147792816162
Validation loss: 2.0363661525070027

Epoch: 6| Step: 10
Training loss: 2.882507801055908
Validation loss: 2.0438417080909974

Epoch: 6| Step: 11
Training loss: 2.048436403274536
Validation loss: 2.053056275972756

Epoch: 6| Step: 12
Training loss: 1.8997396230697632
Validation loss: 2.0700688644122054

Epoch: 6| Step: 13
Training loss: 3.282860279083252
Validation loss: 2.0825541455258607

Epoch: 47| Step: 0
Training loss: 1.8857107162475586
Validation loss: 2.114833302395318

Epoch: 6| Step: 1
Training loss: 2.8719711303710938
Validation loss: 2.153079055970715

Epoch: 6| Step: 2
Training loss: 2.583106279373169
Validation loss: 2.1512658390947568

Epoch: 6| Step: 3
Training loss: 2.799625873565674
Validation loss: 2.2029111526345693

Epoch: 6| Step: 4
Training loss: 2.75270938873291
Validation loss: 2.231020878720027

Epoch: 6| Step: 5
Training loss: 2.324089527130127
Validation loss: 2.233795735143846

Epoch: 6| Step: 6
Training loss: 2.9159908294677734
Validation loss: 2.158793335319847

Epoch: 6| Step: 7
Training loss: 1.5715045928955078
Validation loss: 2.09666544647627

Epoch: 6| Step: 8
Training loss: 2.9891796112060547
Validation loss: 2.077909761859525

Epoch: 6| Step: 9
Training loss: 1.8397364616394043
Validation loss: 2.046153094178887

Epoch: 6| Step: 10
Training loss: 2.0075037479400635
Validation loss: 2.030261124334028

Epoch: 6| Step: 11
Training loss: 1.8852633237838745
Validation loss: 2.028882797046374

Epoch: 6| Step: 12
Training loss: 3.1288909912109375
Validation loss: 2.0278999113267466

Epoch: 6| Step: 13
Training loss: 2.364812135696411
Validation loss: 2.037604780607326

Epoch: 48| Step: 0
Training loss: 2.7771964073181152
Validation loss: 2.041225689713673

Epoch: 6| Step: 1
Training loss: 2.52874493598938
Validation loss: 2.0371596287655573

Epoch: 6| Step: 2
Training loss: 2.6051716804504395
Validation loss: 2.032875153326219

Epoch: 6| Step: 3
Training loss: 2.6430187225341797
Validation loss: 2.0351472721304944

Epoch: 6| Step: 4
Training loss: 2.6235339641571045
Validation loss: 2.0312398608012865

Epoch: 6| Step: 5
Training loss: 2.5489470958709717
Validation loss: 2.02354722766466

Epoch: 6| Step: 6
Training loss: 2.1415648460388184
Validation loss: 2.019564417100722

Epoch: 6| Step: 7
Training loss: 2.201563835144043
Validation loss: 2.0386992141764653

Epoch: 6| Step: 8
Training loss: 2.3430442810058594
Validation loss: 2.05786645027899

Epoch: 6| Step: 9
Training loss: 1.6948344707489014
Validation loss: 2.0827994038981776

Epoch: 6| Step: 10
Training loss: 2.182098388671875
Validation loss: 2.118780189944852

Epoch: 6| Step: 11
Training loss: 2.5007550716400146
Validation loss: 2.1448769697579007

Epoch: 6| Step: 12
Training loss: 2.7009825706481934
Validation loss: 2.166956599040698

Epoch: 6| Step: 13
Training loss: 1.553568959236145
Validation loss: 2.1490974118632655

Epoch: 49| Step: 0
Training loss: 2.206692934036255
Validation loss: 2.168775584108086

Epoch: 6| Step: 1
Training loss: 2.282423973083496
Validation loss: 2.140161201518069

Epoch: 6| Step: 2
Training loss: 1.8596787452697754
Validation loss: 2.1476603451595513

Epoch: 6| Step: 3
Training loss: 2.394756317138672
Validation loss: 2.1469013229493172

Epoch: 6| Step: 4
Training loss: 2.1571478843688965
Validation loss: 2.11153349825131

Epoch: 6| Step: 5
Training loss: 2.539788246154785
Validation loss: 2.072444390225154

Epoch: 6| Step: 6
Training loss: 2.581826686859131
Validation loss: 2.054345933339929

Epoch: 6| Step: 7
Training loss: 2.597050905227661
Validation loss: 2.050919419975691

Epoch: 6| Step: 8
Training loss: 1.8428332805633545
Validation loss: 2.036769108105731

Epoch: 6| Step: 9
Training loss: 2.972459316253662
Validation loss: 2.0362468945082797

Epoch: 6| Step: 10
Training loss: 2.540217638015747
Validation loss: 2.0409808851057485

Epoch: 6| Step: 11
Training loss: 2.2491464614868164
Validation loss: 2.054801280780505

Epoch: 6| Step: 12
Training loss: 2.7836861610412598
Validation loss: 2.043143477491153

Epoch: 6| Step: 13
Training loss: 2.2940244674682617
Validation loss: 2.0274721909594793

Epoch: 50| Step: 0
Training loss: 2.4893312454223633
Validation loss: 2.0136404332294258

Epoch: 6| Step: 1
Training loss: 2.50997257232666
Validation loss: 2.009448435998732

Epoch: 6| Step: 2
Training loss: 1.9468135833740234
Validation loss: 2.0053593292031238

Epoch: 6| Step: 3
Training loss: 2.2216296195983887
Validation loss: 2.0105259444123957

Epoch: 6| Step: 4
Training loss: 2.455599784851074
Validation loss: 2.014289638047577

Epoch: 6| Step: 5
Training loss: 2.3998942375183105
Validation loss: 2.0199318162856565

Epoch: 6| Step: 6
Training loss: 2.5461599826812744
Validation loss: 2.0245610411449144

Epoch: 6| Step: 7
Training loss: 2.6131935119628906
Validation loss: 2.0499479257932274

Epoch: 6| Step: 8
Training loss: 2.923412561416626
Validation loss: 2.064510496713782

Epoch: 6| Step: 9
Training loss: 2.6041550636291504
Validation loss: 2.0679956918121665

Epoch: 6| Step: 10
Training loss: 3.1549060344696045
Validation loss: 2.062470605296473

Epoch: 6| Step: 11
Training loss: 1.7520463466644287
Validation loss: 2.063809057717682

Epoch: 6| Step: 12
Training loss: 1.572439193725586
Validation loss: 2.0447477243279897

Epoch: 6| Step: 13
Training loss: 1.832979440689087
Validation loss: 2.0431705802999516

Epoch: 51| Step: 0
Training loss: 2.453563690185547
Validation loss: 2.0393855007745887

Epoch: 6| Step: 1
Training loss: 1.79874587059021
Validation loss: 2.032987750986571

Epoch: 6| Step: 2
Training loss: 3.010939359664917
Validation loss: 2.0283273138025755

Epoch: 6| Step: 3
Training loss: 2.366114616394043
Validation loss: 2.025319416035888

Epoch: 6| Step: 4
Training loss: 2.332784414291382
Validation loss: 2.016394640809746

Epoch: 6| Step: 5
Training loss: 2.162736415863037
Validation loss: 2.018842065206138

Epoch: 6| Step: 6
Training loss: 3.4267964363098145
Validation loss: 2.0156678512532222

Epoch: 6| Step: 7
Training loss: 2.0754315853118896
Validation loss: 2.0093911552941925

Epoch: 6| Step: 8
Training loss: 2.522336721420288
Validation loss: 2.0005258885763024

Epoch: 6| Step: 9
Training loss: 2.4898102283477783
Validation loss: 2.005890341215236

Epoch: 6| Step: 10
Training loss: 1.5199679136276245
Validation loss: 2.0303182858292774

Epoch: 6| Step: 11
Training loss: 2.1364378929138184
Validation loss: 2.055835859749907

Epoch: 6| Step: 12
Training loss: 2.156294345855713
Validation loss: 2.071362950468576

Epoch: 6| Step: 13
Training loss: 2.7499825954437256
Validation loss: 2.1165937710833806

Epoch: 52| Step: 0
Training loss: 2.0277652740478516
Validation loss: 2.14207616929085

Epoch: 6| Step: 1
Training loss: 2.5244669914245605
Validation loss: 2.170775326349402

Epoch: 6| Step: 2
Training loss: 2.645979404449463
Validation loss: 2.1628369669760428

Epoch: 6| Step: 3
Training loss: 1.6543965339660645
Validation loss: 2.111281159103558

Epoch: 6| Step: 4
Training loss: 2.831409215927124
Validation loss: 2.0769180302978842

Epoch: 6| Step: 5
Training loss: 2.621725082397461
Validation loss: 2.046111891346593

Epoch: 6| Step: 6
Training loss: 2.7166178226470947
Validation loss: 2.0258919744081396

Epoch: 6| Step: 7
Training loss: 1.9730119705200195
Validation loss: 2.0146779219309487

Epoch: 6| Step: 8
Training loss: 2.3654379844665527
Validation loss: 2.0120716787153676

Epoch: 6| Step: 9
Training loss: 2.230154514312744
Validation loss: 2.0271946537879204

Epoch: 6| Step: 10
Training loss: 2.383100986480713
Validation loss: 2.0487828241881503

Epoch: 6| Step: 11
Training loss: 2.093510150909424
Validation loss: 2.0639195429381503

Epoch: 6| Step: 12
Training loss: 2.6544034481048584
Validation loss: 2.0822917902341453

Epoch: 6| Step: 13
Training loss: 2.874342918395996
Validation loss: 2.077928973782447

Epoch: 53| Step: 0
Training loss: 2.38995623588562
Validation loss: 2.017360597528437

Epoch: 6| Step: 1
Training loss: 2.5225679874420166
Validation loss: 2.0110437152206257

Epoch: 6| Step: 2
Training loss: 2.0252609252929688
Validation loss: 2.036927946152226

Epoch: 6| Step: 3
Training loss: 1.9116240739822388
Validation loss: 2.0853249565247567

Epoch: 6| Step: 4
Training loss: 2.058093309402466
Validation loss: 2.1154482031381256

Epoch: 6| Step: 5
Training loss: 2.2172675132751465
Validation loss: 2.21994145583081

Epoch: 6| Step: 6
Training loss: 3.362431526184082
Validation loss: 2.294136595982377

Epoch: 6| Step: 7
Training loss: 2.4185049533843994
Validation loss: 2.39815104135903

Epoch: 6| Step: 8
Training loss: 2.717940330505371
Validation loss: 2.444573030676893

Epoch: 6| Step: 9
Training loss: 2.857616424560547
Validation loss: 2.473403360254021

Epoch: 6| Step: 10
Training loss: 3.6700596809387207
Validation loss: 2.462588282041652

Epoch: 6| Step: 11
Training loss: 2.624980926513672
Validation loss: 2.336218718559511

Epoch: 6| Step: 12
Training loss: 1.9968280792236328
Validation loss: 2.1570354097632953

Epoch: 6| Step: 13
Training loss: 0.9033340811729431
Validation loss: 2.071254654597211

Epoch: 54| Step: 0
Training loss: 2.432379722595215
Validation loss: 2.0131051284010693

Epoch: 6| Step: 1
Training loss: 2.1035726070404053
Validation loss: 2.0019767540757374

Epoch: 6| Step: 2
Training loss: 2.401538848876953
Validation loss: 2.019599435149982

Epoch: 6| Step: 3
Training loss: 2.0911779403686523
Validation loss: 2.028301695341705

Epoch: 6| Step: 4
Training loss: 2.9796557426452637
Validation loss: 2.061343494281974

Epoch: 6| Step: 5
Training loss: 2.8659067153930664
Validation loss: 2.0813088711871894

Epoch: 6| Step: 6
Training loss: 3.0404131412506104
Validation loss: 2.122079699270187

Epoch: 6| Step: 7
Training loss: 2.745647430419922
Validation loss: 2.1076052163236882

Epoch: 6| Step: 8
Training loss: 2.332674980163574
Validation loss: 2.1132682549056185

Epoch: 6| Step: 9
Training loss: 2.123800277709961
Validation loss: 2.0999064214767946

Epoch: 6| Step: 10
Training loss: 2.4062650203704834
Validation loss: 2.033459872327825

Epoch: 6| Step: 11
Training loss: 2.1659975051879883
Validation loss: 2.0131012188491

Epoch: 6| Step: 12
Training loss: 1.4341192245483398
Validation loss: 2.0072253647670952

Epoch: 6| Step: 13
Training loss: 3.1081345081329346
Validation loss: 2.0103150131881877

Epoch: 55| Step: 0
Training loss: 2.2253503799438477
Validation loss: 2.046600834015877

Epoch: 6| Step: 1
Training loss: 2.2370004653930664
Validation loss: 2.081456028005128

Epoch: 6| Step: 2
Training loss: 2.539029598236084
Validation loss: 2.113041167618126

Epoch: 6| Step: 3
Training loss: 2.2487525939941406
Validation loss: 2.126389773943091

Epoch: 6| Step: 4
Training loss: 2.4136369228363037
Validation loss: 2.11980882511344

Epoch: 6| Step: 5
Training loss: 2.673768997192383
Validation loss: 2.1140277872803392

Epoch: 6| Step: 6
Training loss: 2.0883777141571045
Validation loss: 2.0899814944113455

Epoch: 6| Step: 7
Training loss: 2.631377696990967
Validation loss: 2.091431530573035

Epoch: 6| Step: 8
Training loss: 2.134357452392578
Validation loss: 2.073511090329898

Epoch: 6| Step: 9
Training loss: 3.122446060180664
Validation loss: 2.0767736960482854

Epoch: 6| Step: 10
Training loss: 2.564948081970215
Validation loss: 2.0583688828252975

Epoch: 6| Step: 11
Training loss: 2.1461782455444336
Validation loss: 2.0512624709836897

Epoch: 6| Step: 12
Training loss: 1.8904107809066772
Validation loss: 2.02551071874557

Epoch: 6| Step: 13
Training loss: 1.9044842720031738
Validation loss: 2.0226400795803277

Epoch: 56| Step: 0
Training loss: 2.06197190284729
Validation loss: 2.0000001102365474

Epoch: 6| Step: 1
Training loss: 2.345689296722412
Validation loss: 1.986429447768837

Epoch: 6| Step: 2
Training loss: 1.9210059642791748
Validation loss: 1.9874894798442881

Epoch: 6| Step: 3
Training loss: 2.1498122215270996
Validation loss: 1.9841230248892179

Epoch: 6| Step: 4
Training loss: 2.4950790405273438
Validation loss: 1.9860508493197861

Epoch: 6| Step: 5
Training loss: 3.0021755695343018
Validation loss: 1.9818778345661778

Epoch: 6| Step: 6
Training loss: 2.785114288330078
Validation loss: 1.978876716347151

Epoch: 6| Step: 7
Training loss: 2.461787223815918
Validation loss: 1.9855235327956497

Epoch: 6| Step: 8
Training loss: 2.2518131732940674
Validation loss: 1.9868017435073853

Epoch: 6| Step: 9
Training loss: 2.476543426513672
Validation loss: 2.0031057121933147

Epoch: 6| Step: 10
Training loss: 1.4268999099731445
Validation loss: 2.0255866499357325

Epoch: 6| Step: 11
Training loss: 2.5748233795166016
Validation loss: 2.0489158438098047

Epoch: 6| Step: 12
Training loss: 2.0794882774353027
Validation loss: 2.0516677171953264

Epoch: 6| Step: 13
Training loss: 3.2660138607025146
Validation loss: 2.0506975932787825

Epoch: 57| Step: 0
Training loss: 2.478123664855957
Validation loss: 2.069998597586027

Epoch: 6| Step: 1
Training loss: 2.505499839782715
Validation loss: 2.0871891860039002

Epoch: 6| Step: 2
Training loss: 2.2953336238861084
Validation loss: 2.0971183110308904

Epoch: 6| Step: 3
Training loss: 2.686488628387451
Validation loss: 2.114434608849146

Epoch: 6| Step: 4
Training loss: 2.307499647140503
Validation loss: 2.0796067330145065

Epoch: 6| Step: 5
Training loss: 2.612165927886963
Validation loss: 2.056173175893804

Epoch: 6| Step: 6
Training loss: 2.011143445968628
Validation loss: 2.0284437876875683

Epoch: 6| Step: 7
Training loss: 2.7819294929504395
Validation loss: 2.002366301833942

Epoch: 6| Step: 8
Training loss: 1.9156036376953125
Validation loss: 2.002374146574287

Epoch: 6| Step: 9
Training loss: 1.9772017002105713
Validation loss: 2.003079718159091

Epoch: 6| Step: 10
Training loss: 1.972351312637329
Validation loss: 2.0115887067651235

Epoch: 6| Step: 11
Training loss: 2.541355848312378
Validation loss: 2.0070204657893025

Epoch: 6| Step: 12
Training loss: 2.6367077827453613
Validation loss: 2.0088765826276553

Epoch: 6| Step: 13
Training loss: 1.7587647438049316
Validation loss: 2.028654281811048

Epoch: 58| Step: 0
Training loss: 2.2846081256866455
Validation loss: 2.034840815810747

Epoch: 6| Step: 1
Training loss: 2.594308853149414
Validation loss: 2.0447300710985736

Epoch: 6| Step: 2
Training loss: 1.8411198854446411
Validation loss: 2.049852642961728

Epoch: 6| Step: 3
Training loss: 2.3475844860076904
Validation loss: 2.0285900215948782

Epoch: 6| Step: 4
Training loss: 1.605684518814087
Validation loss: 2.0287712325331984

Epoch: 6| Step: 5
Training loss: 2.883380889892578
Validation loss: 2.027535641065208

Epoch: 6| Step: 6
Training loss: 2.3128855228424072
Validation loss: 2.0161246074143278

Epoch: 6| Step: 7
Training loss: 2.0752694606781006
Validation loss: 2.0003265411623063

Epoch: 6| Step: 8
Training loss: 2.444654703140259
Validation loss: 1.9996628043472127

Epoch: 6| Step: 9
Training loss: 2.8242738246917725
Validation loss: 2.006510211575416

Epoch: 6| Step: 10
Training loss: 2.6204674243927
Validation loss: 2.0027750961242186

Epoch: 6| Step: 11
Training loss: 2.8236958980560303
Validation loss: 2.014206820918668

Epoch: 6| Step: 12
Training loss: 2.1536705493927
Validation loss: 2.0059496420685963

Epoch: 6| Step: 13
Training loss: 1.4820866584777832
Validation loss: 2.0057953403842066

Epoch: 59| Step: 0
Training loss: 2.1064209938049316
Validation loss: 1.9897401537946475

Epoch: 6| Step: 1
Training loss: 1.4826982021331787
Validation loss: 1.9933452913838048

Epoch: 6| Step: 2
Training loss: 2.481171131134033
Validation loss: 1.9924129645029705

Epoch: 6| Step: 3
Training loss: 2.9977829456329346
Validation loss: 1.9938284325343307

Epoch: 6| Step: 4
Training loss: 2.204768657684326
Validation loss: 1.990974836452033

Epoch: 6| Step: 5
Training loss: 2.880131721496582
Validation loss: 1.9939767827269852

Epoch: 6| Step: 6
Training loss: 2.0886669158935547
Validation loss: 1.9913500252590384

Epoch: 6| Step: 7
Training loss: 2.4502675533294678
Validation loss: 1.9850728075991395

Epoch: 6| Step: 8
Training loss: 2.2349226474761963
Validation loss: 1.9932962002292756

Epoch: 6| Step: 9
Training loss: 2.7290356159210205
Validation loss: 1.9929898836279427

Epoch: 6| Step: 10
Training loss: 2.0636954307556152
Validation loss: 1.9946270553014611

Epoch: 6| Step: 11
Training loss: 2.3760597705841064
Validation loss: 1.998170724479101

Epoch: 6| Step: 12
Training loss: 1.938336968421936
Validation loss: 2.005931559429374

Epoch: 6| Step: 13
Training loss: 2.228504180908203
Validation loss: 2.0062473794465423

Epoch: 60| Step: 0
Training loss: 1.6991766691207886
Validation loss: 2.009420966589323

Epoch: 6| Step: 1
Training loss: 1.6753095388412476
Validation loss: 2.0232185061259935

Epoch: 6| Step: 2
Training loss: 2.4362926483154297
Validation loss: 2.025240793023058

Epoch: 6| Step: 3
Training loss: 2.5404722690582275
Validation loss: 2.033167246849306

Epoch: 6| Step: 4
Training loss: 2.426119804382324
Validation loss: 2.031374937744551

Epoch: 6| Step: 5
Training loss: 2.3683929443359375
Validation loss: 2.034030191359981

Epoch: 6| Step: 6
Training loss: 2.5783135890960693
Validation loss: 2.0329364602283766

Epoch: 6| Step: 7
Training loss: 2.8186240196228027
Validation loss: 2.04723544274607

Epoch: 6| Step: 8
Training loss: 2.2880749702453613
Validation loss: 2.054219111319511

Epoch: 6| Step: 9
Training loss: 2.2818703651428223
Validation loss: 2.0749033343407417

Epoch: 6| Step: 10
Training loss: 2.0381665229797363
Validation loss: 2.0785844120928036

Epoch: 6| Step: 11
Training loss: 2.4206557273864746
Validation loss: 2.08942396666414

Epoch: 6| Step: 12
Training loss: 2.025691032409668
Validation loss: 2.0989530701791086

Epoch: 6| Step: 13
Training loss: 2.86346173286438
Validation loss: 2.095378029731012

Epoch: 61| Step: 0
Training loss: 1.6374619007110596
Validation loss: 2.082099114694903

Epoch: 6| Step: 1
Training loss: 2.5377306938171387
Validation loss: 2.0947104397640435

Epoch: 6| Step: 2
Training loss: 2.243926525115967
Validation loss: 2.102698641438638

Epoch: 6| Step: 3
Training loss: 2.069772481918335
Validation loss: 2.0970901699476343

Epoch: 6| Step: 4
Training loss: 2.5375776290893555
Validation loss: 2.102330889753116

Epoch: 6| Step: 5
Training loss: 2.3504130840301514
Validation loss: 2.0983937325016147

Epoch: 6| Step: 6
Training loss: 2.4637348651885986
Validation loss: 2.1007772517460648

Epoch: 6| Step: 7
Training loss: 2.3741025924682617
Validation loss: 2.0774066704575733

Epoch: 6| Step: 8
Training loss: 2.8148088455200195
Validation loss: 2.061244148080067

Epoch: 6| Step: 9
Training loss: 1.8134992122650146
Validation loss: 2.049720911569493

Epoch: 6| Step: 10
Training loss: 1.840818166732788
Validation loss: 2.048670362400752

Epoch: 6| Step: 11
Training loss: 2.5911593437194824
Validation loss: 2.0391126935200026

Epoch: 6| Step: 12
Training loss: 2.1502513885498047
Validation loss: 2.0520735402261057

Epoch: 6| Step: 13
Training loss: 2.4411227703094482
Validation loss: 2.0323066121788433

Epoch: 62| Step: 0
Training loss: 2.3436837196350098
Validation loss: 2.009720661306894

Epoch: 6| Step: 1
Training loss: 2.323908805847168
Validation loss: 2.0002968067763955

Epoch: 6| Step: 2
Training loss: 2.2824559211730957
Validation loss: 1.9876223059110745

Epoch: 6| Step: 3
Training loss: 2.327890396118164
Validation loss: 1.9862054394137474

Epoch: 6| Step: 4
Training loss: 3.017568588256836
Validation loss: 1.9958115867389146

Epoch: 6| Step: 5
Training loss: 2.320610284805298
Validation loss: 1.986118567887173

Epoch: 6| Step: 6
Training loss: 2.0585827827453613
Validation loss: 1.985729899457706

Epoch: 6| Step: 7
Training loss: 2.575410842895508
Validation loss: 1.9949522044069024

Epoch: 6| Step: 8
Training loss: 2.2757248878479004
Validation loss: 1.988722921699606

Epoch: 6| Step: 9
Training loss: 2.203749418258667
Validation loss: 1.9899074326279342

Epoch: 6| Step: 10
Training loss: 1.6267362833023071
Validation loss: 1.9970795557063112

Epoch: 6| Step: 11
Training loss: 1.7099876403808594
Validation loss: 1.9936421032874816

Epoch: 6| Step: 12
Training loss: 2.5229387283325195
Validation loss: 2.0085811768808672

Epoch: 6| Step: 13
Training loss: 2.829887628555298
Validation loss: 2.0262432470116565

Epoch: 63| Step: 0
Training loss: 2.5510611534118652
Validation loss: 2.04287616924573

Epoch: 6| Step: 1
Training loss: 2.4052610397338867
Validation loss: 2.0448126075088338

Epoch: 6| Step: 2
Training loss: 2.6095428466796875
Validation loss: 2.0436012155266217

Epoch: 6| Step: 3
Training loss: 2.639047622680664
Validation loss: 2.0289758713014665

Epoch: 6| Step: 4
Training loss: 1.4260966777801514
Validation loss: 2.0123628595823884

Epoch: 6| Step: 5
Training loss: 2.0557126998901367
Validation loss: 2.0063940837819088

Epoch: 6| Step: 6
Training loss: 2.3958654403686523
Validation loss: 1.9963314123051141

Epoch: 6| Step: 7
Training loss: 2.6613364219665527
Validation loss: 1.9715851891425349

Epoch: 6| Step: 8
Training loss: 2.122716188430786
Validation loss: 1.966814588474971

Epoch: 6| Step: 9
Training loss: 2.1717329025268555
Validation loss: 1.9765862623850505

Epoch: 6| Step: 10
Training loss: 2.5514235496520996
Validation loss: 1.9836192746316232

Epoch: 6| Step: 11
Training loss: 2.3280253410339355
Validation loss: 2.001845476447895

Epoch: 6| Step: 12
Training loss: 2.227581024169922
Validation loss: 2.01508956058051

Epoch: 6| Step: 13
Training loss: 2.0488898754119873
Validation loss: 2.029704079833082

Epoch: 64| Step: 0
Training loss: 2.478461742401123
Validation loss: 2.029642721658112

Epoch: 6| Step: 1
Training loss: 2.4233736991882324
Validation loss: 2.047899902507823

Epoch: 6| Step: 2
Training loss: 2.625398874282837
Validation loss: 2.058024598706153

Epoch: 6| Step: 3
Training loss: 2.21684193611145
Validation loss: 2.0464081892403225

Epoch: 6| Step: 4
Training loss: 2.5271294116973877
Validation loss: 2.040244251169184

Epoch: 6| Step: 5
Training loss: 2.583174228668213
Validation loss: 2.034383435403147

Epoch: 6| Step: 6
Training loss: 2.3873941898345947
Validation loss: 2.0327896456564627

Epoch: 6| Step: 7
Training loss: 2.3544840812683105
Validation loss: 2.0123321702403407

Epoch: 6| Step: 8
Training loss: 1.8138916492462158
Validation loss: 2.024868961303465

Epoch: 6| Step: 9
Training loss: 2.5589218139648438
Validation loss: 2.033053860869459

Epoch: 6| Step: 10
Training loss: 1.6886279582977295
Validation loss: 2.0260639062491794

Epoch: 6| Step: 11
Training loss: 2.551722288131714
Validation loss: 2.02719848386703

Epoch: 6| Step: 12
Training loss: 1.7758688926696777
Validation loss: 2.02812558861189

Epoch: 6| Step: 13
Training loss: 2.1059179306030273
Validation loss: 2.036587292148221

Epoch: 65| Step: 0
Training loss: 2.263822555541992
Validation loss: 2.0526407521258117

Epoch: 6| Step: 1
Training loss: 2.617077350616455
Validation loss: 2.061972442493644

Epoch: 6| Step: 2
Training loss: 2.1178338527679443
Validation loss: 2.049700011489212

Epoch: 6| Step: 3
Training loss: 2.326327323913574
Validation loss: 2.0456455522967922

Epoch: 6| Step: 4
Training loss: 2.4094512462615967
Validation loss: 2.0380154643007504

Epoch: 6| Step: 5
Training loss: 1.9804061651229858
Validation loss: 2.0321375041879635

Epoch: 6| Step: 6
Training loss: 2.466153621673584
Validation loss: 2.026161821939612

Epoch: 6| Step: 7
Training loss: 2.481088161468506
Validation loss: 2.0235759186488327

Epoch: 6| Step: 8
Training loss: 2.709077835083008
Validation loss: 2.0128281962487007

Epoch: 6| Step: 9
Training loss: 1.8480756282806396
Validation loss: 2.01119597752889

Epoch: 6| Step: 10
Training loss: 1.9110569953918457
Validation loss: 2.0037668725495696

Epoch: 6| Step: 11
Training loss: 2.580052137374878
Validation loss: 2.0036968287601264

Epoch: 6| Step: 12
Training loss: 1.964357614517212
Validation loss: 2.004393559630199

Epoch: 6| Step: 13
Training loss: 1.9784592390060425
Validation loss: 2.014899771700623

Epoch: 66| Step: 0
Training loss: 2.1953840255737305
Validation loss: 2.020641698632189

Epoch: 6| Step: 1
Training loss: 2.3950376510620117
Validation loss: 2.0242601568980882

Epoch: 6| Step: 2
Training loss: 2.096057415008545
Validation loss: 2.0306183984202724

Epoch: 6| Step: 3
Training loss: 1.677857756614685
Validation loss: 2.0371229033316336

Epoch: 6| Step: 4
Training loss: 3.0652709007263184
Validation loss: 2.057568996183334

Epoch: 6| Step: 5
Training loss: 2.466808557510376
Validation loss: 2.0460974195952057

Epoch: 6| Step: 6
Training loss: 2.49556303024292
Validation loss: 2.043008828675875

Epoch: 6| Step: 7
Training loss: 2.8062262535095215
Validation loss: 2.014010214036511

Epoch: 6| Step: 8
Training loss: 2.5757787227630615
Validation loss: 2.006551642571726

Epoch: 6| Step: 9
Training loss: 2.0050454139709473
Validation loss: 2.0131400656956497

Epoch: 6| Step: 10
Training loss: 1.9713330268859863
Validation loss: 2.019890659598894

Epoch: 6| Step: 11
Training loss: 1.8013544082641602
Validation loss: 2.0125613225403653

Epoch: 6| Step: 12
Training loss: 1.7193596363067627
Validation loss: 2.01938929224527

Epoch: 6| Step: 13
Training loss: 2.3460397720336914
Validation loss: 2.0137525220071115

Epoch: 67| Step: 0
Training loss: 2.488271474838257
Validation loss: 2.0282827859283774

Epoch: 6| Step: 1
Training loss: 2.3483633995056152
Validation loss: 2.019800223330016

Epoch: 6| Step: 2
Training loss: 2.17936372756958
Validation loss: 2.018798412815217

Epoch: 6| Step: 3
Training loss: 1.685817837715149
Validation loss: 2.0182736253225677

Epoch: 6| Step: 4
Training loss: 2.3974409103393555
Validation loss: 1.9909328055638138

Epoch: 6| Step: 5
Training loss: 1.824207067489624
Validation loss: 2.00326253650009

Epoch: 6| Step: 6
Training loss: 2.088223934173584
Validation loss: 2.0078486960421325

Epoch: 6| Step: 7
Training loss: 2.57015323638916
Validation loss: 2.00906789687372

Epoch: 6| Step: 8
Training loss: 2.443986654281616
Validation loss: 2.010435576079994

Epoch: 6| Step: 9
Training loss: 1.9756433963775635
Validation loss: 1.9967863264904226

Epoch: 6| Step: 10
Training loss: 2.2796356678009033
Validation loss: 1.9892572536263415

Epoch: 6| Step: 11
Training loss: 2.4727392196655273
Validation loss: 1.993424650161497

Epoch: 6| Step: 12
Training loss: 2.5648303031921387
Validation loss: 1.994926801291845

Epoch: 6| Step: 13
Training loss: 2.0075390338897705
Validation loss: 2.0119779725228586

Epoch: 68| Step: 0
Training loss: 1.8999114036560059
Validation loss: 2.00100996417384

Epoch: 6| Step: 1
Training loss: 1.9705508947372437
Validation loss: 2.027713248806615

Epoch: 6| Step: 2
Training loss: 2.683126449584961
Validation loss: 2.025313268425644

Epoch: 6| Step: 3
Training loss: 2.2740681171417236
Validation loss: 2.0379757727346113

Epoch: 6| Step: 4
Training loss: 2.333163261413574
Validation loss: 2.0235412338728547

Epoch: 6| Step: 5
Training loss: 3.204408645629883
Validation loss: 2.020588201861228

Epoch: 6| Step: 6
Training loss: 1.6670830249786377
Validation loss: 2.016050277217742

Epoch: 6| Step: 7
Training loss: 2.500814199447632
Validation loss: 2.0280186540337017

Epoch: 6| Step: 8
Training loss: 2.0980236530303955
Validation loss: 2.0536491358152

Epoch: 6| Step: 9
Training loss: 1.6845407485961914
Validation loss: 2.0668290276681223

Epoch: 6| Step: 10
Training loss: 2.2088470458984375
Validation loss: 2.065608086124543

Epoch: 6| Step: 11
Training loss: 2.447755813598633
Validation loss: 2.050747045906641

Epoch: 6| Step: 12
Training loss: 2.859820604324341
Validation loss: 2.0425682503690004

Epoch: 6| Step: 13
Training loss: 1.1610175371170044
Validation loss: 2.060923751964364

Epoch: 69| Step: 0
Training loss: 2.068483591079712
Validation loss: 2.1101559951741207

Epoch: 6| Step: 1
Training loss: 2.1334710121154785
Validation loss: 2.157247348498273

Epoch: 6| Step: 2
Training loss: 2.2926254272460938
Validation loss: 2.125018594085529

Epoch: 6| Step: 3
Training loss: 2.5936026573181152
Validation loss: 2.0930263944851455

Epoch: 6| Step: 4
Training loss: 2.5299177169799805
Validation loss: 2.0639006360884635

Epoch: 6| Step: 5
Training loss: 1.731722116470337
Validation loss: 2.011248130952158

Epoch: 6| Step: 6
Training loss: 1.669008731842041
Validation loss: 1.9912021006307294

Epoch: 6| Step: 7
Training loss: 1.5990946292877197
Validation loss: 1.9846386396756737

Epoch: 6| Step: 8
Training loss: 2.617666721343994
Validation loss: 1.988105531661741

Epoch: 6| Step: 9
Training loss: 2.590097665786743
Validation loss: 1.9918114087914909

Epoch: 6| Step: 10
Training loss: 2.3395047187805176
Validation loss: 2.0123749420207035

Epoch: 6| Step: 11
Training loss: 2.4175562858581543
Validation loss: 2.0485832563010593

Epoch: 6| Step: 12
Training loss: 2.7164249420166016
Validation loss: 2.065428380043276

Epoch: 6| Step: 13
Training loss: 3.335747003555298
Validation loss: 2.05223943597527

Epoch: 70| Step: 0
Training loss: 2.725445508956909
Validation loss: 2.066614435565087

Epoch: 6| Step: 1
Training loss: 2.232729434967041
Validation loss: 2.0547914953641992

Epoch: 6| Step: 2
Training loss: 1.9043121337890625
Validation loss: 2.0502814567217262

Epoch: 6| Step: 3
Training loss: 1.701401710510254
Validation loss: 2.034945482848793

Epoch: 6| Step: 4
Training loss: 1.6003532409667969
Validation loss: 2.028341826572213

Epoch: 6| Step: 5
Training loss: 1.9876437187194824
Validation loss: 2.0349144217788533

Epoch: 6| Step: 6
Training loss: 2.71236515045166
Validation loss: 2.04889363755462

Epoch: 6| Step: 7
Training loss: 2.6547956466674805
Validation loss: 2.0477817032926824

Epoch: 6| Step: 8
Training loss: 3.309338092803955
Validation loss: 2.03829703920631

Epoch: 6| Step: 9
Training loss: 1.7034484148025513
Validation loss: 2.0128926487379175

Epoch: 6| Step: 10
Training loss: 1.9171971082687378
Validation loss: 2.015489078337146

Epoch: 6| Step: 11
Training loss: 1.8967500925064087
Validation loss: 2.014375872509454

Epoch: 6| Step: 12
Training loss: 2.719637632369995
Validation loss: 2.0275437485787178

Epoch: 6| Step: 13
Training loss: 2.1178054809570312
Validation loss: 2.0284359788381927

Epoch: 71| Step: 0
Training loss: 1.8332297801971436
Validation loss: 2.0453312832822084

Epoch: 6| Step: 1
Training loss: 1.968375325202942
Validation loss: 2.0406626757755073

Epoch: 6| Step: 2
Training loss: 2.582000732421875
Validation loss: 2.0479348731297318

Epoch: 6| Step: 3
Training loss: 2.775275230407715
Validation loss: 2.0493744188739407

Epoch: 6| Step: 4
Training loss: 1.9087412357330322
Validation loss: 2.042864150898431

Epoch: 6| Step: 5
Training loss: 3.078569173812866
Validation loss: 2.0271128377606793

Epoch: 6| Step: 6
Training loss: 2.0807952880859375
Validation loss: 2.0247026617809007

Epoch: 6| Step: 7
Training loss: 1.7464392185211182
Validation loss: 2.019770855544716

Epoch: 6| Step: 8
Training loss: 2.101623773574829
Validation loss: 2.0264491291456324

Epoch: 6| Step: 9
Training loss: 1.5313687324523926
Validation loss: 2.0263769882981495

Epoch: 6| Step: 10
Training loss: 1.9166808128356934
Validation loss: 2.026887127148208

Epoch: 6| Step: 11
Training loss: 2.5549018383026123
Validation loss: 2.025728225708008

Epoch: 6| Step: 12
Training loss: 2.476398468017578
Validation loss: 2.0361886626930645

Epoch: 6| Step: 13
Training loss: 2.5628557205200195
Validation loss: 2.0280363892996185

Epoch: 72| Step: 0
Training loss: 2.2409298419952393
Validation loss: 2.01294227697516

Epoch: 6| Step: 1
Training loss: 2.6988744735717773
Validation loss: 2.0044716442784956

Epoch: 6| Step: 2
Training loss: 2.04988956451416
Validation loss: 2.000889896064676

Epoch: 6| Step: 3
Training loss: 1.5155994892120361
Validation loss: 2.0021419371328046

Epoch: 6| Step: 4
Training loss: 1.5811764001846313
Validation loss: 2.006061787246376

Epoch: 6| Step: 5
Training loss: 2.338231086730957
Validation loss: 1.9988513582496232

Epoch: 6| Step: 6
Training loss: 1.9115703105926514
Validation loss: 1.9974655502585954

Epoch: 6| Step: 7
Training loss: 2.2241601943969727
Validation loss: 1.9935781109717585

Epoch: 6| Step: 8
Training loss: 2.6888070106506348
Validation loss: 2.0029612113070745

Epoch: 6| Step: 9
Training loss: 2.214564085006714
Validation loss: 2.0048061737450222

Epoch: 6| Step: 10
Training loss: 2.244593620300293
Validation loss: 2.0126978223041823

Epoch: 6| Step: 11
Training loss: 2.610154151916504
Validation loss: 2.0491056288442304

Epoch: 6| Step: 12
Training loss: 1.985692024230957
Validation loss: 2.0643529251057613

Epoch: 6| Step: 13
Training loss: 1.9433403015136719
Validation loss: 2.080610795687604

Epoch: 73| Step: 0
Training loss: 2.729987621307373
Validation loss: 2.0914546905025357

Epoch: 6| Step: 1
Training loss: 2.202317237854004
Validation loss: 2.0840919530519875

Epoch: 6| Step: 2
Training loss: 2.773233652114868
Validation loss: 2.069974576273272

Epoch: 6| Step: 3
Training loss: 2.529357433319092
Validation loss: 2.071693258900796

Epoch: 6| Step: 4
Training loss: 2.297198534011841
Validation loss: 2.0568235663957495

Epoch: 6| Step: 5
Training loss: 2.338386058807373
Validation loss: 2.0630599324421217

Epoch: 6| Step: 6
Training loss: 2.000079870223999
Validation loss: 2.0390415653105705

Epoch: 6| Step: 7
Training loss: 1.689277172088623
Validation loss: 2.0553937624859553

Epoch: 6| Step: 8
Training loss: 3.15297269821167
Validation loss: 2.0642813533864994

Epoch: 6| Step: 9
Training loss: 2.1818413734436035
Validation loss: 2.081290514238419

Epoch: 6| Step: 10
Training loss: 1.4993151426315308
Validation loss: 2.085249449617119

Epoch: 6| Step: 11
Training loss: 2.0787389278411865
Validation loss: 2.0639024549914944

Epoch: 6| Step: 12
Training loss: 1.3257925510406494
Validation loss: 2.041222098053143

Epoch: 6| Step: 13
Training loss: 1.198438048362732
Validation loss: 2.039727380198817

Epoch: 74| Step: 0
Training loss: 2.4066691398620605
Validation loss: 2.0337910767524474

Epoch: 6| Step: 1
Training loss: 2.250255823135376
Validation loss: 2.0160899546838578

Epoch: 6| Step: 2
Training loss: 2.1046245098114014
Validation loss: 2.0187037221847044

Epoch: 6| Step: 3
Training loss: 1.9082921743392944
Validation loss: 2.0296409745370187

Epoch: 6| Step: 4
Training loss: 1.8184025287628174
Validation loss: 2.0294390006731917

Epoch: 6| Step: 5
Training loss: 2.298301935195923
Validation loss: 2.022703093867148

Epoch: 6| Step: 6
Training loss: 1.589691400527954
Validation loss: 2.053406469283565

Epoch: 6| Step: 7
Training loss: 2.5279030799865723
Validation loss: 2.063250635259895

Epoch: 6| Step: 8
Training loss: 3.4541895389556885
Validation loss: 2.0838037254989787

Epoch: 6| Step: 9
Training loss: 1.7123435735702515
Validation loss: 2.0816837844028266

Epoch: 6| Step: 10
Training loss: 2.224551200866699
Validation loss: 2.091476619884532

Epoch: 6| Step: 11
Training loss: 2.299128770828247
Validation loss: 2.0889745681516585

Epoch: 6| Step: 12
Training loss: 1.7810485363006592
Validation loss: 2.0835146621991227

Epoch: 6| Step: 13
Training loss: 1.4465352296829224
Validation loss: 2.0589236956770702

Epoch: 75| Step: 0
Training loss: 2.3710989952087402
Validation loss: 2.0477125144773916

Epoch: 6| Step: 1
Training loss: 2.634261131286621
Validation loss: 2.045488547253352

Epoch: 6| Step: 2
Training loss: 1.4406498670578003
Validation loss: 2.0522815271090438

Epoch: 6| Step: 3
Training loss: 2.3462893962860107
Validation loss: 2.025858175370001

Epoch: 6| Step: 4
Training loss: 2.3893485069274902
Validation loss: 2.037970527525871

Epoch: 6| Step: 5
Training loss: 2.135011672973633
Validation loss: 2.056544044966339

Epoch: 6| Step: 6
Training loss: 1.7617290019989014
Validation loss: 2.0538771895952124

Epoch: 6| Step: 7
Training loss: 1.8837201595306396
Validation loss: 2.0658338351916243

Epoch: 6| Step: 8
Training loss: 2.4645209312438965
Validation loss: 2.096729040145874

Epoch: 6| Step: 9
Training loss: 2.5355398654937744
Validation loss: 2.107304831986786

Epoch: 6| Step: 10
Training loss: 1.6537294387817383
Validation loss: 2.0827267810862553

Epoch: 6| Step: 11
Training loss: 2.2751455307006836
Validation loss: 2.04314895086391

Epoch: 6| Step: 12
Training loss: 2.020387887954712
Validation loss: 2.0334559127848637

Epoch: 6| Step: 13
Training loss: 1.665465235710144
Validation loss: 2.0133935610453286

Testing loss: 2.2575722058614094
