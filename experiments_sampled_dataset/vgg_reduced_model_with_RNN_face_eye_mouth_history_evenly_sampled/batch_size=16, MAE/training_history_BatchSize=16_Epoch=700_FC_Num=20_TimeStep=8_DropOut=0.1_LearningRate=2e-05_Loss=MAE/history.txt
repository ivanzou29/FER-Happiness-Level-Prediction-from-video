Epoch: 1| Step: 0
Training loss: 4.563109397888184
Validation loss: 5.2306171489018265

Epoch: 6| Step: 1
Training loss: 5.009814739227295
Validation loss: 5.211253827618014

Epoch: 6| Step: 2
Training loss: 4.8862175941467285
Validation loss: 5.192376100888816

Epoch: 6| Step: 3
Training loss: 5.262200355529785
Validation loss: 5.173965679701938

Epoch: 6| Step: 4
Training loss: 4.985633850097656
Validation loss: 5.1540646450493925

Epoch: 6| Step: 5
Training loss: 2.971336841583252
Validation loss: 5.131066778654693

Epoch: 6| Step: 6
Training loss: 5.774384498596191
Validation loss: 5.10527918928413

Epoch: 6| Step: 7
Training loss: 4.687915802001953
Validation loss: 5.075911568057153

Epoch: 6| Step: 8
Training loss: 5.294857025146484
Validation loss: 5.041638384583176

Epoch: 6| Step: 9
Training loss: 4.518870830535889
Validation loss: 5.003422162866079

Epoch: 6| Step: 10
Training loss: 4.625517845153809
Validation loss: 4.9600040886991765

Epoch: 6| Step: 11
Training loss: 5.874953269958496
Validation loss: 4.912234629354169

Epoch: 6| Step: 12
Training loss: 5.103527069091797
Validation loss: 4.860680364793347

Epoch: 6| Step: 13
Training loss: 4.267573356628418
Validation loss: 4.804685874651837

Epoch: 2| Step: 0
Training loss: 4.18359375
Validation loss: 4.744747192628922

Epoch: 6| Step: 1
Training loss: 5.346250534057617
Validation loss: 4.684376547413487

Epoch: 6| Step: 2
Training loss: 4.351100921630859
Validation loss: 4.622854084096929

Epoch: 6| Step: 3
Training loss: 2.852935791015625
Validation loss: 4.562676434875817

Epoch: 6| Step: 4
Training loss: 3.9768178462982178
Validation loss: 4.506112324294223

Epoch: 6| Step: 5
Training loss: 4.273905277252197
Validation loss: 4.449617365355133

Epoch: 6| Step: 6
Training loss: 4.019935607910156
Validation loss: 4.390212787094937

Epoch: 6| Step: 7
Training loss: 4.4369964599609375
Validation loss: 4.326649276159143

Epoch: 6| Step: 8
Training loss: 3.667454719543457
Validation loss: 4.258385924882786

Epoch: 6| Step: 9
Training loss: 4.285895347595215
Validation loss: 4.190832279061758

Epoch: 6| Step: 10
Training loss: 3.7050678730010986
Validation loss: 4.135601464138236

Epoch: 6| Step: 11
Training loss: 5.155848503112793
Validation loss: 4.088694757030856

Epoch: 6| Step: 12
Training loss: 4.502314567565918
Validation loss: 4.050878765762493

Epoch: 6| Step: 13
Training loss: 3.3970370292663574
Validation loss: 4.005631041783158

Epoch: 3| Step: 0
Training loss: 4.768146514892578
Validation loss: 3.9627298283320602

Epoch: 6| Step: 1
Training loss: 5.286899566650391
Validation loss: 3.927309907892699

Epoch: 6| Step: 2
Training loss: 2.543903350830078
Validation loss: 3.897421262597525

Epoch: 6| Step: 3
Training loss: 3.6464903354644775
Validation loss: 3.872722436023015

Epoch: 6| Step: 4
Training loss: 4.642210006713867
Validation loss: 3.844569816384264

Epoch: 6| Step: 5
Training loss: 2.2257866859436035
Validation loss: 3.811520622622582

Epoch: 6| Step: 6
Training loss: 3.815150260925293
Validation loss: 3.7747514837531635

Epoch: 6| Step: 7
Training loss: 3.793302059173584
Validation loss: 3.7403427041986936

Epoch: 6| Step: 8
Training loss: 4.031689643859863
Validation loss: 3.705667439327445

Epoch: 6| Step: 9
Training loss: 2.9808554649353027
Validation loss: 3.6735081903396116

Epoch: 6| Step: 10
Training loss: 3.667245864868164
Validation loss: 3.6401329296891407

Epoch: 6| Step: 11
Training loss: 4.208573341369629
Validation loss: 3.6072729120972338

Epoch: 6| Step: 12
Training loss: 2.069155693054199
Validation loss: 3.5703760705968386

Epoch: 6| Step: 13
Training loss: 3.5399110317230225
Validation loss: 3.5331310713162987

Epoch: 4| Step: 0
Training loss: 2.873823404312134
Validation loss: 3.5020112350422847

Epoch: 6| Step: 1
Training loss: 3.228679656982422
Validation loss: 3.479114688852782

Epoch: 6| Step: 2
Training loss: 3.1913299560546875
Validation loss: 3.463944696610974

Epoch: 6| Step: 3
Training loss: 4.8567023277282715
Validation loss: 3.4521601738468295

Epoch: 6| Step: 4
Training loss: 2.9437756538391113
Validation loss: 3.4177282343628588

Epoch: 6| Step: 5
Training loss: 2.8856048583984375
Validation loss: 3.3911792309053483

Epoch: 6| Step: 6
Training loss: 3.642364025115967
Validation loss: 3.3657637488457466

Epoch: 6| Step: 7
Training loss: 3.4219765663146973
Validation loss: 3.3486788042130007

Epoch: 6| Step: 8
Training loss: 3.400778293609619
Validation loss: 3.339587906355499

Epoch: 6| Step: 9
Training loss: 2.8337807655334473
Validation loss: 3.3175997734069824

Epoch: 6| Step: 10
Training loss: 3.868267059326172
Validation loss: 3.3073191822216077

Epoch: 6| Step: 11
Training loss: 3.704590082168579
Validation loss: 3.2889744312532487

Epoch: 6| Step: 12
Training loss: 2.841073751449585
Validation loss: 3.2709674553204606

Epoch: 6| Step: 13
Training loss: 2.5177173614501953
Validation loss: 3.2573261004622265

Epoch: 5| Step: 0
Training loss: 4.291323661804199
Validation loss: 3.2542454222197175

Epoch: 6| Step: 1
Training loss: 4.392621994018555
Validation loss: 3.242741479668566

Epoch: 6| Step: 2
Training loss: 3.780052661895752
Validation loss: 3.2320846280744

Epoch: 6| Step: 3
Training loss: 2.511103868484497
Validation loss: 3.224248129834411

Epoch: 6| Step: 4
Training loss: 3.005474090576172
Validation loss: 3.2140875939399964

Epoch: 6| Step: 5
Training loss: 3.000067710876465
Validation loss: 3.199696812578427

Epoch: 6| Step: 6
Training loss: 3.016963481903076
Validation loss: 3.184066305878342

Epoch: 6| Step: 7
Training loss: 2.144125461578369
Validation loss: 3.1769502419297413

Epoch: 6| Step: 8
Training loss: 2.3538050651550293
Validation loss: 3.1745393430033038

Epoch: 6| Step: 9
Training loss: 2.840999126434326
Validation loss: 3.1639992831855692

Epoch: 6| Step: 10
Training loss: 2.8222217559814453
Validation loss: 3.1490445316478772

Epoch: 6| Step: 11
Training loss: 3.515122413635254
Validation loss: 3.133435738983975

Epoch: 6| Step: 12
Training loss: 3.1033835411071777
Validation loss: 3.1203615203980477

Epoch: 6| Step: 13
Training loss: 4.397663593292236
Validation loss: 3.1196283601945445

Epoch: 6| Step: 0
Training loss: 2.9484329223632812
Validation loss: 3.119445147052888

Epoch: 6| Step: 1
Training loss: 2.935298204421997
Validation loss: 3.1259254486330095

Epoch: 6| Step: 2
Training loss: 2.9405946731567383
Validation loss: 3.1009950407089724

Epoch: 6| Step: 3
Training loss: 3.121629238128662
Validation loss: 3.079767645046275

Epoch: 6| Step: 4
Training loss: 3.5177536010742188
Validation loss: 3.0685352945840485

Epoch: 6| Step: 5
Training loss: 3.044952630996704
Validation loss: 3.0639713733426985

Epoch: 6| Step: 6
Training loss: 2.9298629760742188
Validation loss: 3.0658097933697444

Epoch: 6| Step: 7
Training loss: 4.051002025604248
Validation loss: 3.0660148077113654

Epoch: 6| Step: 8
Training loss: 2.643444538116455
Validation loss: 3.075463864111131

Epoch: 6| Step: 9
Training loss: 3.6407370567321777
Validation loss: 3.082180138557188

Epoch: 6| Step: 10
Training loss: 2.893673896789551
Validation loss: 3.0721194333927606

Epoch: 6| Step: 11
Training loss: 3.4146478176116943
Validation loss: 3.061935458132016

Epoch: 6| Step: 12
Training loss: 2.644946575164795
Validation loss: 3.0507928838012037

Epoch: 6| Step: 13
Training loss: 2.6472394466400146
Validation loss: 3.03127718997258

Epoch: 7| Step: 0
Training loss: 2.591557741165161
Validation loss: 3.0252857669707267

Epoch: 6| Step: 1
Training loss: 2.8822855949401855
Validation loss: 3.0148841283654653

Epoch: 6| Step: 2
Training loss: 2.098008632659912
Validation loss: 3.001288075600901

Epoch: 6| Step: 3
Training loss: 3.73115873336792
Validation loss: 2.995757577239826

Epoch: 6| Step: 4
Training loss: 2.9445385932922363
Validation loss: 2.9927608659190517

Epoch: 6| Step: 5
Training loss: 2.5129239559173584
Validation loss: 2.9829673331270934

Epoch: 6| Step: 6
Training loss: 3.7917609214782715
Validation loss: 2.976611529627154

Epoch: 6| Step: 7
Training loss: 2.654142379760742
Validation loss: 2.9657057357090775

Epoch: 6| Step: 8
Training loss: 3.3954923152923584
Validation loss: 2.9555053044390935

Epoch: 6| Step: 9
Training loss: 3.221958637237549
Validation loss: 2.95394830806281

Epoch: 6| Step: 10
Training loss: 3.640660285949707
Validation loss: 2.948755859046854

Epoch: 6| Step: 11
Training loss: 2.804236888885498
Validation loss: 2.9416610399881997

Epoch: 6| Step: 12
Training loss: 3.238375186920166
Validation loss: 2.9431416424371863

Epoch: 6| Step: 13
Training loss: 3.208793878555298
Validation loss: 2.943275461914719

Epoch: 8| Step: 0
Training loss: 3.209897994995117
Validation loss: 2.9779489424920853

Epoch: 6| Step: 1
Training loss: 2.6019604206085205
Validation loss: 2.98391374721322

Epoch: 6| Step: 2
Training loss: 3.0642166137695312
Validation loss: 2.956374737524217

Epoch: 6| Step: 3
Training loss: 2.9483370780944824
Validation loss: 2.924824022477673

Epoch: 6| Step: 4
Training loss: 2.674219846725464
Validation loss: 2.9558281462679625

Epoch: 6| Step: 5
Training loss: 2.840816020965576
Validation loss: 3.035917087267804

Epoch: 6| Step: 6
Training loss: 4.112231731414795
Validation loss: 3.0263271793242423

Epoch: 6| Step: 7
Training loss: 3.304471969604492
Validation loss: 2.93918703961116

Epoch: 6| Step: 8
Training loss: 2.6380841732025146
Validation loss: 2.9141242273392214

Epoch: 6| Step: 9
Training loss: 2.2801880836486816
Validation loss: 2.916122551887266

Epoch: 6| Step: 10
Training loss: 3.98356294631958
Validation loss: 2.941799625273674

Epoch: 6| Step: 11
Training loss: 3.1339168548583984
Validation loss: 2.92506645828165

Epoch: 6| Step: 12
Training loss: 2.4688096046447754
Validation loss: 2.9326614590101343

Epoch: 6| Step: 13
Training loss: 3.1681246757507324
Validation loss: 2.942827276004258

Epoch: 9| Step: 0
Training loss: 2.6687917709350586
Validation loss: 2.9497095743815103

Epoch: 6| Step: 1
Training loss: 3.1734766960144043
Validation loss: 2.9500340261766986

Epoch: 6| Step: 2
Training loss: 2.926590919494629
Validation loss: 2.9361604234223724

Epoch: 6| Step: 3
Training loss: 3.3330798149108887
Validation loss: 2.9496505081012683

Epoch: 6| Step: 4
Training loss: 3.0585572719573975
Validation loss: 2.9150603355899936

Epoch: 6| Step: 5
Training loss: 2.650264263153076
Validation loss: 2.900545189457555

Epoch: 6| Step: 6
Training loss: 2.751450300216675
Validation loss: 2.8921917330834175

Epoch: 6| Step: 7
Training loss: 2.7829551696777344
Validation loss: 2.892316505473147

Epoch: 6| Step: 8
Training loss: 1.9571045637130737
Validation loss: 2.896166862980012

Epoch: 6| Step: 9
Training loss: 2.6843652725219727
Validation loss: 2.897584786979101

Epoch: 6| Step: 10
Training loss: 4.085088729858398
Validation loss: 2.9055539177310084

Epoch: 6| Step: 11
Training loss: 2.2954764366149902
Validation loss: 2.90380629416435

Epoch: 6| Step: 12
Training loss: 3.7714223861694336
Validation loss: 2.8775393552677606

Epoch: 6| Step: 13
Training loss: 4.604543209075928
Validation loss: 2.8654224718770673

Epoch: 10| Step: 0
Training loss: 2.7516233921051025
Validation loss: 2.860447019659063

Epoch: 6| Step: 1
Training loss: 2.9415853023529053
Validation loss: 2.855843751661239

Epoch: 6| Step: 2
Training loss: 2.791853904724121
Validation loss: 2.8516914511239655

Epoch: 6| Step: 3
Training loss: 3.4747066497802734
Validation loss: 2.8743151669861167

Epoch: 6| Step: 4
Training loss: 3.5925791263580322
Validation loss: 2.8528921014519146

Epoch: 6| Step: 5
Training loss: 2.794640064239502
Validation loss: 2.8390410561715402

Epoch: 6| Step: 6
Training loss: 3.309565782546997
Validation loss: 2.8355342829099266

Epoch: 6| Step: 7
Training loss: 2.155979871749878
Validation loss: 2.8370880337171656

Epoch: 6| Step: 8
Training loss: 3.004117012023926
Validation loss: 2.8462924649638515

Epoch: 6| Step: 9
Training loss: 2.6621692180633545
Validation loss: 2.8603971619759836

Epoch: 6| Step: 10
Training loss: 3.529334783554077
Validation loss: 2.8674820597453783

Epoch: 6| Step: 11
Training loss: 2.9799060821533203
Validation loss: 2.8749075089731524

Epoch: 6| Step: 12
Training loss: 2.7533950805664062
Validation loss: 2.850368087009717

Epoch: 6| Step: 13
Training loss: 2.4100279808044434
Validation loss: 2.82947217008119

Epoch: 11| Step: 0
Training loss: 2.9272422790527344
Validation loss: 2.8221851600113737

Epoch: 6| Step: 1
Training loss: 2.8811511993408203
Validation loss: 2.8232181456781205

Epoch: 6| Step: 2
Training loss: 2.7817838191986084
Validation loss: 2.809190421976069

Epoch: 6| Step: 3
Training loss: 3.2579145431518555
Validation loss: 2.8039181360634426

Epoch: 6| Step: 4
Training loss: 3.3077733516693115
Validation loss: 2.8046721348198513

Epoch: 6| Step: 5
Training loss: 2.7085869312286377
Validation loss: 2.8527831928704375

Epoch: 6| Step: 6
Training loss: 2.3449110984802246
Validation loss: 2.877069357902773

Epoch: 6| Step: 7
Training loss: 3.1278786659240723
Validation loss: 2.8627311696288404

Epoch: 6| Step: 8
Training loss: 2.213142156600952
Validation loss: 2.797508419200938

Epoch: 6| Step: 9
Training loss: 3.6870510578155518
Validation loss: 2.786985251211351

Epoch: 6| Step: 10
Training loss: 2.544933795928955
Validation loss: 2.7974114418029785

Epoch: 6| Step: 11
Training loss: 2.7263596057891846
Validation loss: 2.837105715146629

Epoch: 6| Step: 12
Training loss: 2.963771343231201
Validation loss: 2.9013275202884468

Epoch: 6| Step: 13
Training loss: 4.339590072631836
Validation loss: 2.9363145776974258

Epoch: 12| Step: 0
Training loss: 2.302825927734375
Validation loss: 2.9211304751775597

Epoch: 6| Step: 1
Training loss: 3.2521238327026367
Validation loss: 2.8934195733839467

Epoch: 6| Step: 2
Training loss: 3.0216212272644043
Validation loss: 2.8483074916306363

Epoch: 6| Step: 3
Training loss: 2.449094295501709
Validation loss: 2.8046868026897473

Epoch: 6| Step: 4
Training loss: 3.0416507720947266
Validation loss: 2.7874699690008677

Epoch: 6| Step: 5
Training loss: 2.4378039836883545
Validation loss: 2.785672559533068

Epoch: 6| Step: 6
Training loss: 3.192248821258545
Validation loss: 2.7778308417207453

Epoch: 6| Step: 7
Training loss: 2.7663841247558594
Validation loss: 2.7734083103877243

Epoch: 6| Step: 8
Training loss: 2.857632875442505
Validation loss: 2.788605264438096

Epoch: 6| Step: 9
Training loss: 3.4813232421875
Validation loss: 2.8047342249142226

Epoch: 6| Step: 10
Training loss: 3.2019729614257812
Validation loss: 2.7786061943218274

Epoch: 6| Step: 11
Training loss: 3.417847156524658
Validation loss: 2.7662834634063063

Epoch: 6| Step: 12
Training loss: 2.795377731323242
Validation loss: 2.7620435171229865

Epoch: 6| Step: 13
Training loss: 2.6061182022094727
Validation loss: 2.7577212754116265

Epoch: 13| Step: 0
Training loss: 2.749340534210205
Validation loss: 2.762799588582849

Epoch: 6| Step: 1
Training loss: 3.1043457984924316
Validation loss: 2.766497378708214

Epoch: 6| Step: 2
Training loss: 3.3535547256469727
Validation loss: 2.768484720619776

Epoch: 6| Step: 3
Training loss: 2.8533623218536377
Validation loss: 2.768800030472458

Epoch: 6| Step: 4
Training loss: 2.2143561840057373
Validation loss: 2.767194104451005

Epoch: 6| Step: 5
Training loss: 2.8301942348480225
Validation loss: 2.7604610048314577

Epoch: 6| Step: 6
Training loss: 3.53096866607666
Validation loss: 2.758786960314679

Epoch: 6| Step: 7
Training loss: 2.535212278366089
Validation loss: 2.7596377147141324

Epoch: 6| Step: 8
Training loss: 3.0509276390075684
Validation loss: 2.7587713374886462

Epoch: 6| Step: 9
Training loss: 2.586705446243286
Validation loss: 2.7535872100501932

Epoch: 6| Step: 10
Training loss: 2.5477852821350098
Validation loss: 2.7494613278296685

Epoch: 6| Step: 11
Training loss: 2.8742189407348633
Validation loss: 2.7442687929317517

Epoch: 6| Step: 12
Training loss: 2.8705697059631348
Validation loss: 2.739904708759759

Epoch: 6| Step: 13
Training loss: 3.6932132244110107
Validation loss: 2.7381468460124028

Epoch: 14| Step: 0
Training loss: 2.819718360900879
Validation loss: 2.7395360880000617

Epoch: 6| Step: 1
Training loss: 3.0573034286499023
Validation loss: 2.7505625499192106

Epoch: 6| Step: 2
Training loss: 3.0228421688079834
Validation loss: 2.7352182147323445

Epoch: 6| Step: 3
Training loss: 2.937012195587158
Validation loss: 2.7297734034958707

Epoch: 6| Step: 4
Training loss: 3.7070152759552
Validation loss: 2.7244764784330964

Epoch: 6| Step: 5
Training loss: 2.627619504928589
Validation loss: 2.7199963651677614

Epoch: 6| Step: 6
Training loss: 2.3866829872131348
Validation loss: 2.7165075758452057

Epoch: 6| Step: 7
Training loss: 2.844468355178833
Validation loss: 2.7157103451349403

Epoch: 6| Step: 8
Training loss: 2.559408664703369
Validation loss: 2.711939037487071

Epoch: 6| Step: 9
Training loss: 2.9702088832855225
Validation loss: 2.7133864228443434

Epoch: 6| Step: 10
Training loss: 2.6211071014404297
Validation loss: 2.7109518179329495

Epoch: 6| Step: 11
Training loss: 2.9324164390563965
Validation loss: 2.710158630083966

Epoch: 6| Step: 12
Training loss: 2.8077259063720703
Validation loss: 2.708004761767644

Epoch: 6| Step: 13
Training loss: 2.8855137825012207
Validation loss: 2.705859863629905

Epoch: 15| Step: 0
Training loss: 2.1902084350585938
Validation loss: 2.711698526977211

Epoch: 6| Step: 1
Training loss: 3.0886006355285645
Validation loss: 2.7220608265169206

Epoch: 6| Step: 2
Training loss: 2.812776565551758
Validation loss: 2.728627497150052

Epoch: 6| Step: 3
Training loss: 2.3601951599121094
Validation loss: 2.7210515801624586

Epoch: 6| Step: 4
Training loss: 2.70186185836792
Validation loss: 2.7062281100980696

Epoch: 6| Step: 5
Training loss: 2.6608426570892334
Validation loss: 2.703608823078935

Epoch: 6| Step: 6
Training loss: 4.162847518920898
Validation loss: 2.708712808547481

Epoch: 6| Step: 7
Training loss: 2.2095768451690674
Validation loss: 2.710036757171795

Epoch: 6| Step: 8
Training loss: 2.715066909790039
Validation loss: 2.700557959977017

Epoch: 6| Step: 9
Training loss: 3.310647487640381
Validation loss: 2.6996000069443897

Epoch: 6| Step: 10
Training loss: 3.01118803024292
Validation loss: 2.6976065046043805

Epoch: 6| Step: 11
Training loss: 3.3385210037231445
Validation loss: 2.695453833508235

Epoch: 6| Step: 12
Training loss: 2.468690872192383
Validation loss: 2.6960234975302093

Epoch: 6| Step: 13
Training loss: 2.9481027126312256
Validation loss: 2.6942882332750546

Epoch: 16| Step: 0
Training loss: 3.2107114791870117
Validation loss: 2.699490593325707

Epoch: 6| Step: 1
Training loss: 2.0994791984558105
Validation loss: 2.7038081410110637

Epoch: 6| Step: 2
Training loss: 2.464128017425537
Validation loss: 2.702640002773654

Epoch: 6| Step: 3
Training loss: 2.8223061561584473
Validation loss: 2.7036401020583285

Epoch: 6| Step: 4
Training loss: 2.5744471549987793
Validation loss: 2.6927041840809647

Epoch: 6| Step: 5
Training loss: 2.281942844390869
Validation loss: 2.686974876670427

Epoch: 6| Step: 6
Training loss: 3.4037373065948486
Validation loss: 2.6847054189251316

Epoch: 6| Step: 7
Training loss: 2.463514804840088
Validation loss: 2.681212240649808

Epoch: 6| Step: 8
Training loss: 3.8536601066589355
Validation loss: 2.6814991607460925

Epoch: 6| Step: 9
Training loss: 3.1460814476013184
Validation loss: 2.679058172369516

Epoch: 6| Step: 10
Training loss: 3.2814364433288574
Validation loss: 2.6795165666969876

Epoch: 6| Step: 11
Training loss: 2.6414034366607666
Validation loss: 2.68108840398891

Epoch: 6| Step: 12
Training loss: 2.793060302734375
Validation loss: 2.6832654091619674

Epoch: 6| Step: 13
Training loss: 2.68457293510437
Validation loss: 2.6898964451205347

Epoch: 17| Step: 0
Training loss: 2.730179786682129
Validation loss: 2.6953477756951445

Epoch: 6| Step: 1
Training loss: 3.851858615875244
Validation loss: 2.6913565717717653

Epoch: 6| Step: 2
Training loss: 2.277132034301758
Validation loss: 2.683731699502596

Epoch: 6| Step: 3
Training loss: 2.777989149093628
Validation loss: 2.690757841192266

Epoch: 6| Step: 4
Training loss: 1.8136537075042725
Validation loss: 2.6906306717985418

Epoch: 6| Step: 5
Training loss: 3.339914321899414
Validation loss: 2.6804536798948884

Epoch: 6| Step: 6
Training loss: 2.3287062644958496
Validation loss: 2.6695177067992506

Epoch: 6| Step: 7
Training loss: 3.2676568031311035
Validation loss: 2.65950531600624

Epoch: 6| Step: 8
Training loss: 3.2171788215637207
Validation loss: 2.6515334242133686

Epoch: 6| Step: 9
Training loss: 2.048643112182617
Validation loss: 2.6490571960326164

Epoch: 6| Step: 10
Training loss: 3.3544158935546875
Validation loss: 2.6444550380911878

Epoch: 6| Step: 11
Training loss: 2.615926742553711
Validation loss: 2.641208702518094

Epoch: 6| Step: 12
Training loss: 2.8060784339904785
Validation loss: 2.639611851784491

Epoch: 6| Step: 13
Training loss: 3.0440356731414795
Validation loss: 2.650241110914497

Epoch: 18| Step: 0
Training loss: 2.956923484802246
Validation loss: 2.657162412520378

Epoch: 6| Step: 1
Training loss: 2.690143346786499
Validation loss: 2.6662676949654855

Epoch: 6| Step: 2
Training loss: 2.846193552017212
Validation loss: 2.7039517638503865

Epoch: 6| Step: 3
Training loss: 2.8097715377807617
Validation loss: 2.6800187095519035

Epoch: 6| Step: 4
Training loss: 2.6648242473602295
Validation loss: 2.655451238796275

Epoch: 6| Step: 5
Training loss: 3.7586510181427
Validation loss: 2.6366141662802747

Epoch: 6| Step: 6
Training loss: 3.2927327156066895
Validation loss: 2.6273218457416823

Epoch: 6| Step: 7
Training loss: 2.0289838314056396
Validation loss: 2.628023806438651

Epoch: 6| Step: 8
Training loss: 2.740318536758423
Validation loss: 2.6324715563046035

Epoch: 6| Step: 9
Training loss: 2.87831974029541
Validation loss: 2.630511058274136

Epoch: 6| Step: 10
Training loss: 2.783071994781494
Validation loss: 2.6225671998916136

Epoch: 6| Step: 11
Training loss: 2.3398375511169434
Validation loss: 2.617919783438406

Epoch: 6| Step: 12
Training loss: 2.2382941246032715
Validation loss: 2.6139125311246483

Epoch: 6| Step: 13
Training loss: 3.2778468132019043
Validation loss: 2.6189837789022796

Epoch: 19| Step: 0
Training loss: 2.4371447563171387
Validation loss: 2.620926123793407

Epoch: 6| Step: 1
Training loss: 1.8429901599884033
Validation loss: 2.620801179639755

Epoch: 6| Step: 2
Training loss: 2.7607827186584473
Validation loss: 2.624929110209147

Epoch: 6| Step: 3
Training loss: 3.3606860637664795
Validation loss: 2.623790059038388

Epoch: 6| Step: 4
Training loss: 3.102808952331543
Validation loss: 2.6153250663511214

Epoch: 6| Step: 5
Training loss: 3.0062384605407715
Validation loss: 2.6060133031619492

Epoch: 6| Step: 6
Training loss: 2.7488389015197754
Validation loss: 2.6131374502694733

Epoch: 6| Step: 7
Training loss: 2.1771960258483887
Validation loss: 2.6537920941588697

Epoch: 6| Step: 8
Training loss: 2.7690627574920654
Validation loss: 2.7566018360917286

Epoch: 6| Step: 9
Training loss: 2.693774700164795
Validation loss: 2.6885909547087965

Epoch: 6| Step: 10
Training loss: 2.8995513916015625
Validation loss: 2.5960593018480527

Epoch: 6| Step: 11
Training loss: 2.980710983276367
Validation loss: 2.6050625001230547

Epoch: 6| Step: 12
Training loss: 2.806344747543335
Validation loss: 2.6240060611437728

Epoch: 6| Step: 13
Training loss: 3.91715145111084
Validation loss: 2.6510161379332184

Epoch: 20| Step: 0
Training loss: 3.2731246948242188
Validation loss: 2.6427661475314888

Epoch: 6| Step: 1
Training loss: 3.3685173988342285
Validation loss: 2.631199718803488

Epoch: 6| Step: 2
Training loss: 2.1190924644470215
Validation loss: 2.61565262527876

Epoch: 6| Step: 3
Training loss: 2.6402037143707275
Validation loss: 2.6023442001752954

Epoch: 6| Step: 4
Training loss: 3.0414085388183594
Validation loss: 2.5905275319212224

Epoch: 6| Step: 5
Training loss: 2.5240790843963623
Validation loss: 2.583311742351901

Epoch: 6| Step: 6
Training loss: 2.6356935501098633
Validation loss: 2.576375235793411

Epoch: 6| Step: 7
Training loss: 3.3018734455108643
Validation loss: 2.576718491892661

Epoch: 6| Step: 8
Training loss: 2.1810386180877686
Validation loss: 2.5801007337467645

Epoch: 6| Step: 9
Training loss: 2.118558645248413
Validation loss: 2.595374604707123

Epoch: 6| Step: 10
Training loss: 2.4694056510925293
Validation loss: 2.611133275493499

Epoch: 6| Step: 11
Training loss: 2.8607447147369385
Validation loss: 2.58998288390457

Epoch: 6| Step: 12
Training loss: 2.8434624671936035
Validation loss: 2.5845387315237396

Epoch: 6| Step: 13
Training loss: 3.620615243911743
Validation loss: 2.570662301073792

Epoch: 21| Step: 0
Training loss: 3.120682716369629
Validation loss: 2.5712785720825195

Epoch: 6| Step: 1
Training loss: 2.9726688861846924
Validation loss: 2.574685296704692

Epoch: 6| Step: 2
Training loss: 1.9639906883239746
Validation loss: 2.57704359228893

Epoch: 6| Step: 3
Training loss: 3.308957099914551
Validation loss: 2.573377358016147

Epoch: 6| Step: 4
Training loss: 3.3536553382873535
Validation loss: 2.5778139893726637

Epoch: 6| Step: 5
Training loss: 2.1437933444976807
Validation loss: 2.568977448248094

Epoch: 6| Step: 6
Training loss: 2.827643871307373
Validation loss: 2.5700993999358146

Epoch: 6| Step: 7
Training loss: 2.8778913021087646
Validation loss: 2.5735457276785247

Epoch: 6| Step: 8
Training loss: 2.9082531929016113
Validation loss: 2.5729239217696653

Epoch: 6| Step: 9
Training loss: 2.6958999633789062
Validation loss: 2.57440020192054

Epoch: 6| Step: 10
Training loss: 2.207009792327881
Validation loss: 2.5679178135369414

Epoch: 6| Step: 11
Training loss: 3.419316291809082
Validation loss: 2.560740840050482

Epoch: 6| Step: 12
Training loss: 2.4492270946502686
Validation loss: 2.5551793549650457

Epoch: 6| Step: 13
Training loss: 1.7717472314834595
Validation loss: 2.556923617598831

Epoch: 22| Step: 0
Training loss: 2.037853479385376
Validation loss: 2.55272553941255

Epoch: 6| Step: 1
Training loss: 2.3533220291137695
Validation loss: 2.5570440471813245

Epoch: 6| Step: 2
Training loss: 3.565903425216675
Validation loss: 2.55434295182587

Epoch: 6| Step: 3
Training loss: 2.4067702293395996
Validation loss: 2.5466068226804017

Epoch: 6| Step: 4
Training loss: 3.0733883380889893
Validation loss: 2.545889569867042

Epoch: 6| Step: 5
Training loss: 2.5605735778808594
Validation loss: 2.5428564010127896

Epoch: 6| Step: 6
Training loss: 2.063624143600464
Validation loss: 2.542029155197964

Epoch: 6| Step: 7
Training loss: 2.42630672454834
Validation loss: 2.5390668453708773

Epoch: 6| Step: 8
Training loss: 3.4567809104919434
Validation loss: 2.5383658101481776

Epoch: 6| Step: 9
Training loss: 2.7619857788085938
Validation loss: 2.541227940590151

Epoch: 6| Step: 10
Training loss: 3.006145715713501
Validation loss: 2.542635322898947

Epoch: 6| Step: 11
Training loss: 3.127859592437744
Validation loss: 2.537719449689311

Epoch: 6| Step: 12
Training loss: 2.642956256866455
Validation loss: 2.535793119861234

Epoch: 6| Step: 13
Training loss: 2.7558469772338867
Validation loss: 2.5382140400589153

Epoch: 23| Step: 0
Training loss: 2.778360366821289
Validation loss: 2.534671098955216

Epoch: 6| Step: 1
Training loss: 3.385173797607422
Validation loss: 2.534076762455766

Epoch: 6| Step: 2
Training loss: 2.676945686340332
Validation loss: 2.53162524777074

Epoch: 6| Step: 3
Training loss: 3.3131885528564453
Validation loss: 2.527029824513261

Epoch: 6| Step: 4
Training loss: 2.433460235595703
Validation loss: 2.5315556051910564

Epoch: 6| Step: 5
Training loss: 2.5120599269866943
Validation loss: 2.534746100825648

Epoch: 6| Step: 6
Training loss: 2.0962576866149902
Validation loss: 2.5464254117781118

Epoch: 6| Step: 7
Training loss: 2.136012554168701
Validation loss: 2.5350326927759315

Epoch: 6| Step: 8
Training loss: 2.212895393371582
Validation loss: 2.5354329552701724

Epoch: 6| Step: 9
Training loss: 3.4921703338623047
Validation loss: 2.532542849099764

Epoch: 6| Step: 10
Training loss: 2.6817402839660645
Validation loss: 2.5239695861775386

Epoch: 6| Step: 11
Training loss: 2.8314902782440186
Validation loss: 2.5253015820698073

Epoch: 6| Step: 12
Training loss: 2.43315052986145
Validation loss: 2.5233098486418366

Epoch: 6| Step: 13
Training loss: 3.229551076889038
Validation loss: 2.522595872161209

Epoch: 24| Step: 0
Training loss: 2.224825382232666
Validation loss: 2.524332256727321

Epoch: 6| Step: 1
Training loss: 3.037043571472168
Validation loss: 2.53367865982876

Epoch: 6| Step: 2
Training loss: 3.601017475128174
Validation loss: 2.5238196644731747

Epoch: 6| Step: 3
Training loss: 3.162853479385376
Validation loss: 2.5207898078426236

Epoch: 6| Step: 4
Training loss: 2.730546474456787
Validation loss: 2.520689795094152

Epoch: 6| Step: 5
Training loss: 3.289567470550537
Validation loss: 2.5216514320783716

Epoch: 6| Step: 6
Training loss: 3.133554697036743
Validation loss: 2.525531299652592

Epoch: 6| Step: 7
Training loss: 1.9553903341293335
Validation loss: 2.524936406843124

Epoch: 6| Step: 8
Training loss: 3.202206611633301
Validation loss: 2.550002722329991

Epoch: 6| Step: 9
Training loss: 1.3855104446411133
Validation loss: 2.534332352299844

Epoch: 6| Step: 10
Training loss: 2.933110237121582
Validation loss: 2.5211051561499156

Epoch: 6| Step: 11
Training loss: 1.8783197402954102
Validation loss: 2.512880863681916

Epoch: 6| Step: 12
Training loss: 2.6918535232543945
Validation loss: 2.517561399808494

Epoch: 6| Step: 13
Training loss: 2.760378837585449
Validation loss: 2.5158569556410595

Epoch: 25| Step: 0
Training loss: 2.846606969833374
Validation loss: 2.5217404852631273

Epoch: 6| Step: 1
Training loss: 3.2734975814819336
Validation loss: 2.519644614188902

Epoch: 6| Step: 2
Training loss: 2.927717685699463
Validation loss: 2.5135523555099324

Epoch: 6| Step: 3
Training loss: 2.935692310333252
Validation loss: 2.517938426745835

Epoch: 6| Step: 4
Training loss: 2.537818431854248
Validation loss: 2.5126104893222934

Epoch: 6| Step: 5
Training loss: 2.1965909004211426
Validation loss: 2.5212336663276917

Epoch: 6| Step: 6
Training loss: 2.299128532409668
Validation loss: 2.517289505209974

Epoch: 6| Step: 7
Training loss: 2.974485158920288
Validation loss: 2.5246409395689606

Epoch: 6| Step: 8
Training loss: 3.416274309158325
Validation loss: 2.534072204302716

Epoch: 6| Step: 9
Training loss: 2.900237560272217
Validation loss: 2.5350863984836045

Epoch: 6| Step: 10
Training loss: 2.677093982696533
Validation loss: 2.5245394142725135

Epoch: 6| Step: 11
Training loss: 2.6081011295318604
Validation loss: 2.5051527484770744

Epoch: 6| Step: 12
Training loss: 2.5170979499816895
Validation loss: 2.4965771808419177

Epoch: 6| Step: 13
Training loss: 1.3105599880218506
Validation loss: 2.4988012160024335

Epoch: 26| Step: 0
Training loss: 2.4050984382629395
Validation loss: 2.5016546967209026

Epoch: 6| Step: 1
Training loss: 2.0734469890594482
Validation loss: 2.504422208314301

Epoch: 6| Step: 2
Training loss: 3.8418655395507812
Validation loss: 2.506975140622867

Epoch: 6| Step: 3
Training loss: 2.416440963745117
Validation loss: 2.503105689120549

Epoch: 6| Step: 4
Training loss: 1.6805576086044312
Validation loss: 2.4950651020132084

Epoch: 6| Step: 5
Training loss: 3.340695858001709
Validation loss: 2.494463136119227

Epoch: 6| Step: 6
Training loss: 3.1555941104888916
Validation loss: 2.4996998361361924

Epoch: 6| Step: 7
Training loss: 3.2778167724609375
Validation loss: 2.511135665319299

Epoch: 6| Step: 8
Training loss: 2.982722282409668
Validation loss: 2.5330721178362445

Epoch: 6| Step: 9
Training loss: 3.052293539047241
Validation loss: 2.5335818183037544

Epoch: 6| Step: 10
Training loss: 2.0445303916931152
Validation loss: 2.5179664729743876

Epoch: 6| Step: 11
Training loss: 2.5239083766937256
Validation loss: 2.51258740117473

Epoch: 6| Step: 12
Training loss: 2.7141761779785156
Validation loss: 2.508871493800994

Epoch: 6| Step: 13
Training loss: 2.0481536388397217
Validation loss: 2.5050954587997927

Epoch: 27| Step: 0
Training loss: 2.8751869201660156
Validation loss: 2.495736506677443

Epoch: 6| Step: 1
Training loss: 2.5245749950408936
Validation loss: 2.4875190950209096

Epoch: 6| Step: 2
Training loss: 3.9730517864227295
Validation loss: 2.484339310276893

Epoch: 6| Step: 3
Training loss: 2.7388486862182617
Validation loss: 2.4932206343579035

Epoch: 6| Step: 4
Training loss: 2.9477920532226562
Validation loss: 2.4899326703881703

Epoch: 6| Step: 5
Training loss: 2.661160469055176
Validation loss: 2.4860062188999628

Epoch: 6| Step: 6
Training loss: 2.57415509223938
Validation loss: 2.481459138213947

Epoch: 6| Step: 7
Training loss: 2.4963581562042236
Validation loss: 2.485721908589845

Epoch: 6| Step: 8
Training loss: 2.6547508239746094
Validation loss: 2.486991907960625

Epoch: 6| Step: 9
Training loss: 2.856745719909668
Validation loss: 2.4852136232519664

Epoch: 6| Step: 10
Training loss: 2.1539714336395264
Validation loss: 2.4798165470041256

Epoch: 6| Step: 11
Training loss: 1.7162230014801025
Validation loss: 2.484613759543306

Epoch: 6| Step: 12
Training loss: 2.600429058074951
Validation loss: 2.4920079861917803

Epoch: 6| Step: 13
Training loss: 3.02528977394104
Validation loss: 2.53123487195661

Epoch: 28| Step: 0
Training loss: 3.0574257373809814
Validation loss: 2.5668526029074066

Epoch: 6| Step: 1
Training loss: 2.528684616088867
Validation loss: 2.592325015734601

Epoch: 6| Step: 2
Training loss: 2.3399369716644287
Validation loss: 2.5641664920314664

Epoch: 6| Step: 3
Training loss: 2.4010205268859863
Validation loss: 2.5409660057354997

Epoch: 6| Step: 4
Training loss: 3.1817712783813477
Validation loss: 2.5162350516165457

Epoch: 6| Step: 5
Training loss: 3.4465246200561523
Validation loss: 2.4853079524091495

Epoch: 6| Step: 6
Training loss: 2.450843334197998
Validation loss: 2.475375352367278

Epoch: 6| Step: 7
Training loss: 2.2267966270446777
Validation loss: 2.479723738085839

Epoch: 6| Step: 8
Training loss: 2.5874080657958984
Validation loss: 2.4877470154916086

Epoch: 6| Step: 9
Training loss: 2.8497843742370605
Validation loss: 2.496498707802065

Epoch: 6| Step: 10
Training loss: 2.545663356781006
Validation loss: 2.505789408119776

Epoch: 6| Step: 11
Training loss: 2.8087964057922363
Validation loss: 2.505382276350452

Epoch: 6| Step: 12
Training loss: 2.1629080772399902
Validation loss: 2.5014160935596754

Epoch: 6| Step: 13
Training loss: 3.6859991550445557
Validation loss: 2.498912203696466

Epoch: 29| Step: 0
Training loss: 3.6687140464782715
Validation loss: 2.4951359712949364

Epoch: 6| Step: 1
Training loss: 2.2330799102783203
Validation loss: 2.490280830731956

Epoch: 6| Step: 2
Training loss: 2.3527350425720215
Validation loss: 2.4898924417393182

Epoch: 6| Step: 3
Training loss: 2.7817115783691406
Validation loss: 2.4767778073587725

Epoch: 6| Step: 4
Training loss: 2.7965714931488037
Validation loss: 2.4726259580222507

Epoch: 6| Step: 5
Training loss: 2.4149563312530518
Validation loss: 2.471188452935988

Epoch: 6| Step: 6
Training loss: 2.1979570388793945
Validation loss: 2.4735797451388453

Epoch: 6| Step: 7
Training loss: 2.5140864849090576
Validation loss: 2.4709801084251812

Epoch: 6| Step: 8
Training loss: 2.384430170059204
Validation loss: 2.4737651348114014

Epoch: 6| Step: 9
Training loss: 3.068364143371582
Validation loss: 2.4667282207037813

Epoch: 6| Step: 10
Training loss: 2.743107318878174
Validation loss: 2.467069137480951

Epoch: 6| Step: 11
Training loss: 2.848402500152588
Validation loss: 2.4704290666887836

Epoch: 6| Step: 12
Training loss: 2.797999858856201
Validation loss: 2.4696230606366227

Epoch: 6| Step: 13
Training loss: 3.017336368560791
Validation loss: 2.4733310155971076

Epoch: 30| Step: 0
Training loss: 2.3744537830352783
Validation loss: 2.47928628870236

Epoch: 6| Step: 1
Training loss: 1.7949211597442627
Validation loss: 2.4849417183988836

Epoch: 6| Step: 2
Training loss: 2.2967617511749268
Validation loss: 2.4964541824915076

Epoch: 6| Step: 3
Training loss: 2.668785333633423
Validation loss: 2.50092061104313

Epoch: 6| Step: 4
Training loss: 2.777198314666748
Validation loss: 2.50682040696503

Epoch: 6| Step: 5
Training loss: 3.110703945159912
Validation loss: 2.5030741935135215

Epoch: 6| Step: 6
Training loss: 2.572755813598633
Validation loss: 2.496549165377053

Epoch: 6| Step: 7
Training loss: 2.9791674613952637
Validation loss: 2.4809714953104653

Epoch: 6| Step: 8
Training loss: 3.5151193141937256
Validation loss: 2.4611811509696384

Epoch: 6| Step: 9
Training loss: 2.9384379386901855
Validation loss: 2.458956677426574

Epoch: 6| Step: 10
Training loss: 2.0545973777770996
Validation loss: 2.4615995576304774

Epoch: 6| Step: 11
Training loss: 2.903552770614624
Validation loss: 2.4660010389102403

Epoch: 6| Step: 12
Training loss: 2.504119396209717
Validation loss: 2.461270252863566

Epoch: 6| Step: 13
Training loss: 3.59077787399292
Validation loss: 2.4537546762856106

Epoch: 31| Step: 0
Training loss: 2.929858684539795
Validation loss: 2.454779271156557

Epoch: 6| Step: 1
Training loss: 2.8438186645507812
Validation loss: 2.453047421670729

Epoch: 6| Step: 2
Training loss: 2.9667506217956543
Validation loss: 2.45410797672887

Epoch: 6| Step: 3
Training loss: 2.5514001846313477
Validation loss: 2.4531991917599916

Epoch: 6| Step: 4
Training loss: 2.345602512359619
Validation loss: 2.455382590652794

Epoch: 6| Step: 5
Training loss: 2.8713345527648926
Validation loss: 2.462476981583462

Epoch: 6| Step: 6
Training loss: 2.963731288909912
Validation loss: 2.463358258688322

Epoch: 6| Step: 7
Training loss: 2.8027496337890625
Validation loss: 2.4623017182914158

Epoch: 6| Step: 8
Training loss: 1.6141760349273682
Validation loss: 2.4642418481970347

Epoch: 6| Step: 9
Training loss: 3.13295841217041
Validation loss: 2.458705189407513

Epoch: 6| Step: 10
Training loss: 2.4665277004241943
Validation loss: 2.456613532958492

Epoch: 6| Step: 11
Training loss: 2.3420236110687256
Validation loss: 2.4585126343593804

Epoch: 6| Step: 12
Training loss: 3.0002505779266357
Validation loss: 2.4520141373398485

Epoch: 6| Step: 13
Training loss: 2.4543213844299316
Validation loss: 2.4508415652859594

Epoch: 32| Step: 0
Training loss: 2.4095373153686523
Validation loss: 2.4468452430540517

Epoch: 6| Step: 1
Training loss: 3.2569382190704346
Validation loss: 2.44559576947202

Epoch: 6| Step: 2
Training loss: 2.926535129547119
Validation loss: 2.446813398791898

Epoch: 6| Step: 3
Training loss: 3.3482794761657715
Validation loss: 2.4411625939030803

Epoch: 6| Step: 4
Training loss: 2.3580732345581055
Validation loss: 2.4408516037848687

Epoch: 6| Step: 5
Training loss: 2.7490313053131104
Validation loss: 2.444776045378818

Epoch: 6| Step: 6
Training loss: 2.1642932891845703
Validation loss: 2.4418463783879436

Epoch: 6| Step: 7
Training loss: 3.096156358718872
Validation loss: 2.4398966937936764

Epoch: 6| Step: 8
Training loss: 2.0362436771392822
Validation loss: 2.444636503855387

Epoch: 6| Step: 9
Training loss: 2.5020017623901367
Validation loss: 2.4468205257128646

Epoch: 6| Step: 10
Training loss: 3.1464710235595703
Validation loss: 2.445315417423043

Epoch: 6| Step: 11
Training loss: 2.567488670349121
Validation loss: 2.4475882694285405

Epoch: 6| Step: 12
Training loss: 2.2345938682556152
Validation loss: 2.443642070216517

Epoch: 6| Step: 13
Training loss: 2.3861775398254395
Validation loss: 2.4426778901007866

Epoch: 33| Step: 0
Training loss: 2.1746678352355957
Validation loss: 2.442424258878154

Epoch: 6| Step: 1
Training loss: 2.6044583320617676
Validation loss: 2.442013317538846

Epoch: 6| Step: 2
Training loss: 2.539463996887207
Validation loss: 2.4411656446354364

Epoch: 6| Step: 3
Training loss: 2.2923383712768555
Validation loss: 2.438363705911944

Epoch: 6| Step: 4
Training loss: 3.0692667961120605
Validation loss: 2.4438344996462584

Epoch: 6| Step: 5
Training loss: 2.6428728103637695
Validation loss: 2.444082139640726

Epoch: 6| Step: 6
Training loss: 3.2890689373016357
Validation loss: 2.4493612781647713

Epoch: 6| Step: 7
Training loss: 3.1047072410583496
Validation loss: 2.4501150013298116

Epoch: 6| Step: 8
Training loss: 2.565786361694336
Validation loss: 2.4499804589056198

Epoch: 6| Step: 9
Training loss: 2.3476200103759766
Validation loss: 2.450915572463825

Epoch: 6| Step: 10
Training loss: 2.4008257389068604
Validation loss: 2.4430320468000186

Epoch: 6| Step: 11
Training loss: 3.130770683288574
Validation loss: 2.431839886532035

Epoch: 6| Step: 12
Training loss: 2.359675884246826
Validation loss: 2.4307015608715754

Epoch: 6| Step: 13
Training loss: 2.7713606357574463
Validation loss: 2.429267109081309

Epoch: 34| Step: 0
Training loss: 2.973194122314453
Validation loss: 2.4300662907220985

Epoch: 6| Step: 1
Training loss: 2.3202853202819824
Validation loss: 2.4276063852412726

Epoch: 6| Step: 2
Training loss: 2.364718198776245
Validation loss: 2.4299243445037515

Epoch: 6| Step: 3
Training loss: 2.3267812728881836
Validation loss: 2.4252475256560952

Epoch: 6| Step: 4
Training loss: 3.125863790512085
Validation loss: 2.426410936540173

Epoch: 6| Step: 5
Training loss: 2.7201390266418457
Validation loss: 2.4249107273676063

Epoch: 6| Step: 6
Training loss: 2.9030556678771973
Validation loss: 2.4235657286900345

Epoch: 6| Step: 7
Training loss: 2.635467052459717
Validation loss: 2.439324717367849

Epoch: 6| Step: 8
Training loss: 2.791539192199707
Validation loss: 2.4541082510384182

Epoch: 6| Step: 9
Training loss: 2.0817065238952637
Validation loss: 2.476904643479214

Epoch: 6| Step: 10
Training loss: 2.7878994941711426
Validation loss: 2.507023180684736

Epoch: 6| Step: 11
Training loss: 2.4122867584228516
Validation loss: 2.5331945855130433

Epoch: 6| Step: 12
Training loss: 2.8573503494262695
Validation loss: 2.5498238789137972

Epoch: 6| Step: 13
Training loss: 3.2886781692504883
Validation loss: 2.505725012030653

Epoch: 35| Step: 0
Training loss: 3.25994873046875
Validation loss: 2.4638842049465386

Epoch: 6| Step: 1
Training loss: 1.7727553844451904
Validation loss: 2.4350281838447816

Epoch: 6| Step: 2
Training loss: 3.0584604740142822
Validation loss: 2.421497362916188

Epoch: 6| Step: 3
Training loss: 2.4565677642822266
Validation loss: 2.417011450695735

Epoch: 6| Step: 4
Training loss: 2.7446506023406982
Validation loss: 2.417531592871553

Epoch: 6| Step: 5
Training loss: 2.6933507919311523
Validation loss: 2.4194547412216023

Epoch: 6| Step: 6
Training loss: 2.507969379425049
Validation loss: 2.4241514641751527

Epoch: 6| Step: 7
Training loss: 2.849114418029785
Validation loss: 2.423262555112121

Epoch: 6| Step: 8
Training loss: 2.5468590259552
Validation loss: 2.4167977404850784

Epoch: 6| Step: 9
Training loss: 2.560889720916748
Validation loss: 2.421583139768211

Epoch: 6| Step: 10
Training loss: 2.3498573303222656
Validation loss: 2.427231765562488

Epoch: 6| Step: 11
Training loss: 2.604931354522705
Validation loss: 2.424778728074925

Epoch: 6| Step: 12
Training loss: 2.897712469100952
Validation loss: 2.4304369021487493

Epoch: 6| Step: 13
Training loss: 3.244839668273926
Validation loss: 2.4362528888128137

Epoch: 36| Step: 0
Training loss: 2.138082981109619
Validation loss: 2.435262490344304

Epoch: 6| Step: 1
Training loss: 2.782179832458496
Validation loss: 2.4477836649904967

Epoch: 6| Step: 2
Training loss: 2.8896052837371826
Validation loss: 2.443168922137189

Epoch: 6| Step: 3
Training loss: 2.0971052646636963
Validation loss: 2.433647224980016

Epoch: 6| Step: 4
Training loss: 2.667482852935791
Validation loss: 2.4281904107780865

Epoch: 6| Step: 5
Training loss: 2.4842448234558105
Validation loss: 2.4203179882418726

Epoch: 6| Step: 6
Training loss: 3.2678234577178955
Validation loss: 2.4247962274859027

Epoch: 6| Step: 7
Training loss: 2.6473894119262695
Validation loss: 2.426358897198913

Epoch: 6| Step: 8
Training loss: 2.994028329849243
Validation loss: 2.4055090770926526

Epoch: 6| Step: 9
Training loss: 2.7161221504211426
Validation loss: 2.400591558025729

Epoch: 6| Step: 10
Training loss: 2.8493432998657227
Validation loss: 2.4040608431703303

Epoch: 6| Step: 11
Training loss: 3.1763336658477783
Validation loss: 2.407113262402114

Epoch: 6| Step: 12
Training loss: 2.0791330337524414
Validation loss: 2.417384445026357

Epoch: 6| Step: 13
Training loss: 2.2264719009399414
Validation loss: 2.4309308913446244

Epoch: 37| Step: 0
Training loss: 2.4339303970336914
Validation loss: 2.431250456840761

Epoch: 6| Step: 1
Training loss: 2.342888116836548
Validation loss: 2.427354706230984

Epoch: 6| Step: 2
Training loss: 2.997875690460205
Validation loss: 2.437164846286979

Epoch: 6| Step: 3
Training loss: 2.8810200691223145
Validation loss: 2.4369124340754684

Epoch: 6| Step: 4
Training loss: 3.0821940898895264
Validation loss: 2.4350916877869637

Epoch: 6| Step: 5
Training loss: 2.726369857788086
Validation loss: 2.4424854478528424

Epoch: 6| Step: 6
Training loss: 2.933151960372925
Validation loss: 2.448790027249244

Epoch: 6| Step: 7
Training loss: 2.542389392852783
Validation loss: 2.4346115025140906

Epoch: 6| Step: 8
Training loss: 2.7434983253479004
Validation loss: 2.4246256941108295

Epoch: 6| Step: 9
Training loss: 2.110820770263672
Validation loss: 2.4146192817277807

Epoch: 6| Step: 10
Training loss: 2.859909772872925
Validation loss: 2.4268094980588524

Epoch: 6| Step: 11
Training loss: 2.6018147468566895
Validation loss: 2.460615409317837

Epoch: 6| Step: 12
Training loss: 2.6777143478393555
Validation loss: 2.4331183023350214

Epoch: 6| Step: 13
Training loss: 1.869184970855713
Validation loss: 2.42052286671054

Epoch: 38| Step: 0
Training loss: 2.0943500995635986
Validation loss: 2.423746934501074

Epoch: 6| Step: 1
Training loss: 3.0470266342163086
Validation loss: 2.4342764821103824

Epoch: 6| Step: 2
Training loss: 2.4925074577331543
Validation loss: 2.428641373111356

Epoch: 6| Step: 3
Training loss: 2.4509198665618896
Validation loss: 2.422554741623581

Epoch: 6| Step: 4
Training loss: 2.5425477027893066
Validation loss: 2.417191502868488

Epoch: 6| Step: 5
Training loss: 2.496840715408325
Validation loss: 2.4218121062042894

Epoch: 6| Step: 6
Training loss: 2.630497932434082
Validation loss: 2.420979981781334

Epoch: 6| Step: 7
Training loss: 2.9575610160827637
Validation loss: 2.409685127196773

Epoch: 6| Step: 8
Training loss: 3.29697585105896
Validation loss: 2.4070777816157185

Epoch: 6| Step: 9
Training loss: 2.814755439758301
Validation loss: 2.3980265740425355

Epoch: 6| Step: 10
Training loss: 2.729065179824829
Validation loss: 2.4008831875298613

Epoch: 6| Step: 11
Training loss: 2.927391767501831
Validation loss: 2.4002527549702632

Epoch: 6| Step: 12
Training loss: 1.7076411247253418
Validation loss: 2.405842581102925

Epoch: 6| Step: 13
Training loss: 2.872143030166626
Validation loss: 2.402710788993425

Epoch: 39| Step: 0
Training loss: 2.6017184257507324
Validation loss: 2.4169491837101598

Epoch: 6| Step: 1
Training loss: 2.9546303749084473
Validation loss: 2.421715449261409

Epoch: 6| Step: 2
Training loss: 3.036973237991333
Validation loss: 2.4299657831909838

Epoch: 6| Step: 3
Training loss: 2.893453598022461
Validation loss: 2.4328244578453804

Epoch: 6| Step: 4
Training loss: 2.8750834465026855
Validation loss: 2.4398591236401628

Epoch: 6| Step: 5
Training loss: 2.6071276664733887
Validation loss: 2.4378286894931587

Epoch: 6| Step: 6
Training loss: 2.5828943252563477
Validation loss: 2.4351402482678814

Epoch: 6| Step: 7
Training loss: 1.9420535564422607
Validation loss: 2.4318328570294123

Epoch: 6| Step: 8
Training loss: 3.3513782024383545
Validation loss: 2.418960694343813

Epoch: 6| Step: 9
Training loss: 2.389767646789551
Validation loss: 2.406838191452847

Epoch: 6| Step: 10
Training loss: 2.838949203491211
Validation loss: 2.3990277859472458

Epoch: 6| Step: 11
Training loss: 2.4905176162719727
Validation loss: 2.393924549061765

Epoch: 6| Step: 12
Training loss: 2.5487780570983887
Validation loss: 2.391564466620004

Epoch: 6| Step: 13
Training loss: 1.4527575969696045
Validation loss: 2.392879737320767

Epoch: 40| Step: 0
Training loss: 2.8645362854003906
Validation loss: 2.387468781522525

Epoch: 6| Step: 1
Training loss: 2.8271687030792236
Validation loss: 2.4043147922844015

Epoch: 6| Step: 2
Training loss: 1.803128957748413
Validation loss: 2.4245267311731973

Epoch: 6| Step: 3
Training loss: 2.543837070465088
Validation loss: 2.417689279843402

Epoch: 6| Step: 4
Training loss: 2.3604624271392822
Validation loss: 2.413596642914639

Epoch: 6| Step: 5
Training loss: 2.856905460357666
Validation loss: 2.4220705083621445

Epoch: 6| Step: 6
Training loss: 2.7024450302124023
Validation loss: 2.4275775058295137

Epoch: 6| Step: 7
Training loss: 3.146684408187866
Validation loss: 2.4266975002904094

Epoch: 6| Step: 8
Training loss: 2.7275753021240234
Validation loss: 2.4187791116776003

Epoch: 6| Step: 9
Training loss: 2.0763626098632812
Validation loss: 2.4075331764836467

Epoch: 6| Step: 10
Training loss: 3.0923118591308594
Validation loss: 2.409783299251269

Epoch: 6| Step: 11
Training loss: 2.8662548065185547
Validation loss: 2.4109065122501825

Epoch: 6| Step: 12
Training loss: 2.293818950653076
Validation loss: 2.4160283175847863

Epoch: 6| Step: 13
Training loss: 2.9240074157714844
Validation loss: 2.4189711809158325

Epoch: 41| Step: 0
Training loss: 2.7761106491088867
Validation loss: 2.4103613950872935

Epoch: 6| Step: 1
Training loss: 2.151475667953491
Validation loss: 2.4229986411268993

Epoch: 6| Step: 2
Training loss: 2.7218775749206543
Validation loss: 2.429473319361287

Epoch: 6| Step: 3
Training loss: 2.701911449432373
Validation loss: 2.435602488056306

Epoch: 6| Step: 4
Training loss: 2.08302640914917
Validation loss: 2.412677864874563

Epoch: 6| Step: 5
Training loss: 2.0437779426574707
Validation loss: 2.4021397700873752

Epoch: 6| Step: 6
Training loss: 2.6233572959899902
Validation loss: 2.401501092859494

Epoch: 6| Step: 7
Training loss: 2.4801483154296875
Validation loss: 2.4010932496798936

Epoch: 6| Step: 8
Training loss: 3.2562386989593506
Validation loss: 2.3970160843223653

Epoch: 6| Step: 9
Training loss: 3.4434447288513184
Validation loss: 2.3986656563256377

Epoch: 6| Step: 10
Training loss: 2.56205415725708
Validation loss: 2.3922563355456115

Epoch: 6| Step: 11
Training loss: 2.2967305183410645
Validation loss: 2.388457517470083

Epoch: 6| Step: 12
Training loss: 2.740900993347168
Validation loss: 2.386604803864674

Epoch: 6| Step: 13
Training loss: 3.304926872253418
Validation loss: 2.3870764778506373

Epoch: 42| Step: 0
Training loss: 3.1055479049682617
Validation loss: 2.3862808135248

Epoch: 6| Step: 1
Training loss: 2.5343852043151855
Validation loss: 2.386799758480441

Epoch: 6| Step: 2
Training loss: 3.367525339126587
Validation loss: 2.3888771328874814

Epoch: 6| Step: 3
Training loss: 2.3671343326568604
Validation loss: 2.381970428651379

Epoch: 6| Step: 4
Training loss: 2.433481454849243
Validation loss: 2.3877232613102084

Epoch: 6| Step: 5
Training loss: 3.1281871795654297
Validation loss: 2.398941857840425

Epoch: 6| Step: 6
Training loss: 1.8399429321289062
Validation loss: 2.3960569443241244

Epoch: 6| Step: 7
Training loss: 2.709739923477173
Validation loss: 2.3969739611430834

Epoch: 6| Step: 8
Training loss: 1.7497879266738892
Validation loss: 2.392989097102996

Epoch: 6| Step: 9
Training loss: 2.408689498901367
Validation loss: 2.40505402575257

Epoch: 6| Step: 10
Training loss: 2.475987195968628
Validation loss: 2.4345452606037097

Epoch: 6| Step: 11
Training loss: 3.0425069332122803
Validation loss: 2.4249159007944088

Epoch: 6| Step: 12
Training loss: 3.211374282836914
Validation loss: 2.4159415614220405

Epoch: 6| Step: 13
Training loss: 2.182671070098877
Validation loss: 2.4022575655291156

Epoch: 43| Step: 0
Training loss: 2.805933952331543
Validation loss: 2.3808268834185857

Epoch: 6| Step: 1
Training loss: 2.030688524246216
Validation loss: 2.378472456368067

Epoch: 6| Step: 2
Training loss: 2.6180758476257324
Validation loss: 2.398831090619487

Epoch: 6| Step: 3
Training loss: 3.0827295780181885
Validation loss: 2.421612226834861

Epoch: 6| Step: 4
Training loss: 2.688206195831299
Validation loss: 2.4035874002723285

Epoch: 6| Step: 5
Training loss: 1.8434514999389648
Validation loss: 2.415382949254846

Epoch: 6| Step: 6
Training loss: 2.689136028289795
Validation loss: 2.435772285666517

Epoch: 6| Step: 7
Training loss: 2.497964382171631
Validation loss: 2.403367434778521

Epoch: 6| Step: 8
Training loss: 3.5946152210235596
Validation loss: 2.4018660155675744

Epoch: 6| Step: 9
Training loss: 2.4584784507751465
Validation loss: 2.3852019617634435

Epoch: 6| Step: 10
Training loss: 2.432732343673706
Validation loss: 2.388012683519753

Epoch: 6| Step: 11
Training loss: 2.6179726123809814
Validation loss: 2.3958085096010597

Epoch: 6| Step: 12
Training loss: 2.5988502502441406
Validation loss: 2.40327537187966

Epoch: 6| Step: 13
Training loss: 3.51304292678833
Validation loss: 2.4107135726559545

Epoch: 44| Step: 0
Training loss: 2.4642157554626465
Validation loss: 2.4000328971493627

Epoch: 6| Step: 1
Training loss: 2.6954121589660645
Validation loss: 2.380755450135918

Epoch: 6| Step: 2
Training loss: 2.399109125137329
Validation loss: 2.3780084476676038

Epoch: 6| Step: 3
Training loss: 2.7284815311431885
Validation loss: 2.3873056775780133

Epoch: 6| Step: 4
Training loss: 2.4106433391571045
Validation loss: 2.385017328364875

Epoch: 6| Step: 5
Training loss: 2.339787483215332
Validation loss: 2.392568924093759

Epoch: 6| Step: 6
Training loss: 2.499129056930542
Validation loss: 2.4116540262776036

Epoch: 6| Step: 7
Training loss: 2.6734790802001953
Validation loss: 2.409514155439151

Epoch: 6| Step: 8
Training loss: 3.0335841178894043
Validation loss: 2.3863364906721216

Epoch: 6| Step: 9
Training loss: 2.520620584487915
Validation loss: 2.379432314185686

Epoch: 6| Step: 10
Training loss: 2.2775821685791016
Validation loss: 2.376458937121976

Epoch: 6| Step: 11
Training loss: 2.9437808990478516
Validation loss: 2.391204152055966

Epoch: 6| Step: 12
Training loss: 2.9814932346343994
Validation loss: 2.402463697618054

Epoch: 6| Step: 13
Training loss: 2.926560878753662
Validation loss: 2.3951184621421238

Epoch: 45| Step: 0
Training loss: 2.6776809692382812
Validation loss: 2.3989124990278676

Epoch: 6| Step: 1
Training loss: 2.589893341064453
Validation loss: 2.3942710430391374

Epoch: 6| Step: 2
Training loss: 3.0085439682006836
Validation loss: 2.405195325933477

Epoch: 6| Step: 3
Training loss: 3.1957173347473145
Validation loss: 2.4074666346273115

Epoch: 6| Step: 4
Training loss: 1.9758857488632202
Validation loss: 2.411109109078684

Epoch: 6| Step: 5
Training loss: 2.4280314445495605
Validation loss: 2.4149094089385

Epoch: 6| Step: 6
Training loss: 2.510955333709717
Validation loss: 2.4229963620503745

Epoch: 6| Step: 7
Training loss: 1.7349340915679932
Validation loss: 2.4210643947765393

Epoch: 6| Step: 8
Training loss: 2.1928858757019043
Validation loss: 2.4349262227294264

Epoch: 6| Step: 9
Training loss: 3.0023374557495117
Validation loss: 2.4354774746843564

Epoch: 6| Step: 10
Training loss: 2.7503814697265625
Validation loss: 2.428635658756379

Epoch: 6| Step: 11
Training loss: 3.2731475830078125
Validation loss: 2.4192995807175994

Epoch: 6| Step: 12
Training loss: 2.550485134124756
Validation loss: 2.410787343978882

Epoch: 6| Step: 13
Training loss: 3.2293012142181396
Validation loss: 2.4047935662731046

Epoch: 46| Step: 0
Training loss: 2.9168920516967773
Validation loss: 2.404609928848923

Epoch: 6| Step: 1
Training loss: 2.348271369934082
Validation loss: 2.396506417182184

Epoch: 6| Step: 2
Training loss: 2.6211600303649902
Validation loss: 2.3861120593163276

Epoch: 6| Step: 3
Training loss: 2.4609079360961914
Validation loss: 2.385078994176721

Epoch: 6| Step: 4
Training loss: 2.294351577758789
Validation loss: 2.3841317597255913

Epoch: 6| Step: 5
Training loss: 3.241896629333496
Validation loss: 2.385462660943308

Epoch: 6| Step: 6
Training loss: 2.4471848011016846
Validation loss: 2.3892382985802105

Epoch: 6| Step: 7
Training loss: 3.073878288269043
Validation loss: 2.3820233037394862

Epoch: 6| Step: 8
Training loss: 2.74672532081604
Validation loss: 2.377813352051602

Epoch: 6| Step: 9
Training loss: 3.006962299346924
Validation loss: 2.384082950571532

Epoch: 6| Step: 10
Training loss: 1.819091558456421
Validation loss: 2.4059460086207234

Epoch: 6| Step: 11
Training loss: 2.4786369800567627
Validation loss: 2.449009521033174

Epoch: 6| Step: 12
Training loss: 2.7185802459716797
Validation loss: 2.4441768200166765

Epoch: 6| Step: 13
Training loss: 2.8131208419799805
Validation loss: 2.42417642378038

Epoch: 47| Step: 0
Training loss: 2.225332736968994
Validation loss: 2.411527459339429

Epoch: 6| Step: 1
Training loss: 2.5669665336608887
Validation loss: 2.3845298674798783

Epoch: 6| Step: 2
Training loss: 3.046520709991455
Validation loss: 2.3760679896159838

Epoch: 6| Step: 3
Training loss: 2.7037391662597656
Validation loss: 2.3761020527091077

Epoch: 6| Step: 4
Training loss: 2.9747090339660645
Validation loss: 2.388425334807365

Epoch: 6| Step: 5
Training loss: 2.603743076324463
Validation loss: 2.432210486422303

Epoch: 6| Step: 6
Training loss: 2.709977149963379
Validation loss: 2.415423280449324

Epoch: 6| Step: 7
Training loss: 1.7658400535583496
Validation loss: 2.380326940167335

Epoch: 6| Step: 8
Training loss: 2.9515838623046875
Validation loss: 2.3812773099509617

Epoch: 6| Step: 9
Training loss: 2.6167995929718018
Validation loss: 2.4023758544716785

Epoch: 6| Step: 10
Training loss: 2.687286853790283
Validation loss: 2.427525830525224

Epoch: 6| Step: 11
Training loss: 2.472601890563965
Validation loss: 2.445487799183015

Epoch: 6| Step: 12
Training loss: 3.1540746688842773
Validation loss: 2.4818969131797872

Epoch: 6| Step: 13
Training loss: 2.4867727756500244
Validation loss: 2.4842552395277124

Epoch: 48| Step: 0
Training loss: 2.278043746948242
Validation loss: 2.4693718494907504

Epoch: 6| Step: 1
Training loss: 2.3548994064331055
Validation loss: 2.451149156016688

Epoch: 6| Step: 2
Training loss: 3.084745168685913
Validation loss: 2.4656526016932663

Epoch: 6| Step: 3
Training loss: 2.996692657470703
Validation loss: 2.4540389558320403

Epoch: 6| Step: 4
Training loss: 3.0591588020324707
Validation loss: 2.435082754781169

Epoch: 6| Step: 5
Training loss: 2.9367592334747314
Validation loss: 2.4078503398485083

Epoch: 6| Step: 6
Training loss: 2.52028489112854
Validation loss: 2.3756413536687053

Epoch: 6| Step: 7
Training loss: 2.370593786239624
Validation loss: 2.35754229176429

Epoch: 6| Step: 8
Training loss: 2.451472759246826
Validation loss: 2.347473698277627

Epoch: 6| Step: 9
Training loss: 2.184939384460449
Validation loss: 2.3474539633720153

Epoch: 6| Step: 10
Training loss: 3.131765365600586
Validation loss: 2.3428490264441377

Epoch: 6| Step: 11
Training loss: 2.205026149749756
Validation loss: 2.3382812879418813

Epoch: 6| Step: 12
Training loss: 2.64548921585083
Validation loss: 2.343146106248261

Epoch: 6| Step: 13
Training loss: 2.004340648651123
Validation loss: 2.3366229841786046

Epoch: 49| Step: 0
Training loss: 2.792973756790161
Validation loss: 2.3293703602206324

Epoch: 6| Step: 1
Training loss: 2.925158977508545
Validation loss: 2.324288063151862

Epoch: 6| Step: 2
Training loss: 2.7278106212615967
Validation loss: 2.321675863317264

Epoch: 6| Step: 3
Training loss: 2.8084535598754883
Validation loss: 2.3246832611740276

Epoch: 6| Step: 4
Training loss: 2.5953187942504883
Validation loss: 2.3245313577754523

Epoch: 6| Step: 5
Training loss: 2.5016326904296875
Validation loss: 2.3249435424804688

Epoch: 6| Step: 6
Training loss: 2.888434886932373
Validation loss: 2.33073599620532

Epoch: 6| Step: 7
Training loss: 2.4857420921325684
Validation loss: 2.333858618172266

Epoch: 6| Step: 8
Training loss: 2.978940963745117
Validation loss: 2.335503239785471

Epoch: 6| Step: 9
Training loss: 2.7293014526367188
Validation loss: 2.3308167483216975

Epoch: 6| Step: 10
Training loss: 1.633253574371338
Validation loss: 2.3408120293771066

Epoch: 6| Step: 11
Training loss: 2.5542335510253906
Validation loss: 2.3487763866301505

Epoch: 6| Step: 12
Training loss: 2.120605230331421
Validation loss: 2.3593923814835085

Epoch: 6| Step: 13
Training loss: 2.5845484733581543
Validation loss: 2.3495915051429503

Epoch: 50| Step: 0
Training loss: 3.303694248199463
Validation loss: 2.344868726627801

Epoch: 6| Step: 1
Training loss: 2.1841320991516113
Validation loss: 2.335025010570403

Epoch: 6| Step: 2
Training loss: 2.4153153896331787
Validation loss: 2.3261777739371023

Epoch: 6| Step: 3
Training loss: 2.5026028156280518
Validation loss: 2.319162425174508

Epoch: 6| Step: 4
Training loss: 2.7021431922912598
Validation loss: 2.315397504837282

Epoch: 6| Step: 5
Training loss: 2.7019083499908447
Validation loss: 2.3146998728475263

Epoch: 6| Step: 6
Training loss: 2.7185020446777344
Validation loss: 2.313968050864435

Epoch: 6| Step: 7
Training loss: 2.8016552925109863
Validation loss: 2.312584501440807

Epoch: 6| Step: 8
Training loss: 2.6061959266662598
Validation loss: 2.30981247655807

Epoch: 6| Step: 9
Training loss: 2.6899514198303223
Validation loss: 2.3117770456498667

Epoch: 6| Step: 10
Training loss: 3.1308979988098145
Validation loss: 2.311700746577273

Epoch: 6| Step: 11
Training loss: 2.366156578063965
Validation loss: 2.313591052127141

Epoch: 6| Step: 12
Training loss: 2.3282525539398193
Validation loss: 2.310614429494386

Epoch: 6| Step: 13
Training loss: 1.6039146184921265
Validation loss: 2.3087991283785914

Epoch: 51| Step: 0
Training loss: 2.9087717533111572
Validation loss: 2.3043662194282777

Epoch: 6| Step: 1
Training loss: 2.360422372817993
Validation loss: 2.3204071009030907

Epoch: 6| Step: 2
Training loss: 2.6775784492492676
Validation loss: 2.3466432914938977

Epoch: 6| Step: 3
Training loss: 2.4452176094055176
Validation loss: 2.3600487888500257

Epoch: 6| Step: 4
Training loss: 2.5005850791931152
Validation loss: 2.4011869404905584

Epoch: 6| Step: 5
Training loss: 3.127033233642578
Validation loss: 2.4012176400871685

Epoch: 6| Step: 6
Training loss: 2.667109251022339
Validation loss: 2.4076714284958376

Epoch: 6| Step: 7
Training loss: 2.607908248901367
Validation loss: 2.4055530153295046

Epoch: 6| Step: 8
Training loss: 2.1707239151000977
Validation loss: 2.3823465249871694

Epoch: 6| Step: 9
Training loss: 2.839634418487549
Validation loss: 2.3439552501965593

Epoch: 6| Step: 10
Training loss: 2.2099428176879883
Validation loss: 2.324348639416438

Epoch: 6| Step: 11
Training loss: 2.5902023315429688
Validation loss: 2.3195019652766566

Epoch: 6| Step: 12
Training loss: 2.5705084800720215
Validation loss: 2.320725405088035

Epoch: 6| Step: 13
Training loss: 2.721339225769043
Validation loss: 2.31593914698529

Epoch: 52| Step: 0
Training loss: 2.4838485717773438
Validation loss: 2.3046849107229583

Epoch: 6| Step: 1
Training loss: 2.229614496231079
Validation loss: 2.307522735288066

Epoch: 6| Step: 2
Training loss: 2.7213454246520996
Validation loss: 2.3034839066126014

Epoch: 6| Step: 3
Training loss: 2.8911709785461426
Validation loss: 2.3003478486050843

Epoch: 6| Step: 4
Training loss: 3.0094709396362305
Validation loss: 2.294467162060481

Epoch: 6| Step: 5
Training loss: 2.347195625305176
Validation loss: 2.2973215682532198

Epoch: 6| Step: 6
Training loss: 2.455249786376953
Validation loss: 2.2937312485069357

Epoch: 6| Step: 7
Training loss: 2.8247506618499756
Validation loss: 2.2861321715898413

Epoch: 6| Step: 8
Training loss: 3.1401026248931885
Validation loss: 2.285103590257706

Epoch: 6| Step: 9
Training loss: 2.1856915950775146
Validation loss: 2.2894922815343386

Epoch: 6| Step: 10
Training loss: 2.5419259071350098
Validation loss: 2.288341542725922

Epoch: 6| Step: 11
Training loss: 2.0496411323547363
Validation loss: 2.3020720020417245

Epoch: 6| Step: 12
Training loss: 2.5695176124572754
Validation loss: 2.3097943106005268

Epoch: 6| Step: 13
Training loss: 2.8030319213867188
Validation loss: 2.343739245527534

Epoch: 53| Step: 0
Training loss: 2.9864795207977295
Validation loss: 2.375471374040009

Epoch: 6| Step: 1
Training loss: 3.065096855163574
Validation loss: 2.388681427125008

Epoch: 6| Step: 2
Training loss: 2.5496792793273926
Validation loss: 2.4100928844944125

Epoch: 6| Step: 3
Training loss: 3.1684558391571045
Validation loss: 2.4270725993699926

Epoch: 6| Step: 4
Training loss: 3.3395400047302246
Validation loss: 2.3676345502176592

Epoch: 6| Step: 5
Training loss: 2.9625535011291504
Validation loss: 2.3117310231731785

Epoch: 6| Step: 6
Training loss: 2.734915256500244
Validation loss: 2.293343925988802

Epoch: 6| Step: 7
Training loss: 2.1013858318328857
Validation loss: 2.2868117452949606

Epoch: 6| Step: 8
Training loss: 2.452678680419922
Validation loss: 2.280277990525769

Epoch: 6| Step: 9
Training loss: 1.94352388381958
Validation loss: 2.281727288358955

Epoch: 6| Step: 10
Training loss: 2.13590145111084
Validation loss: 2.360222360139252

Epoch: 6| Step: 11
Training loss: 2.5429561138153076
Validation loss: 2.3668293594032206

Epoch: 6| Step: 12
Training loss: 2.2878665924072266
Validation loss: 2.3749979362692883

Epoch: 6| Step: 13
Training loss: 2.316739797592163
Validation loss: 2.399163015427128

Epoch: 54| Step: 0
Training loss: 1.922654151916504
Validation loss: 2.4653751773218953

Epoch: 6| Step: 1
Training loss: 2.959073781967163
Validation loss: 2.5519573380870204

Epoch: 6| Step: 2
Training loss: 2.728691339492798
Validation loss: 2.491351790325616

Epoch: 6| Step: 3
Training loss: 3.3372654914855957
Validation loss: 2.477433507160474

Epoch: 6| Step: 4
Training loss: 2.5658183097839355
Validation loss: 2.476386026669574

Epoch: 6| Step: 5
Training loss: 3.1907920837402344
Validation loss: 2.450920504908408

Epoch: 6| Step: 6
Training loss: 2.921937942504883
Validation loss: 2.4327101861276934

Epoch: 6| Step: 7
Training loss: 2.886246681213379
Validation loss: 2.469884159744427

Epoch: 6| Step: 8
Training loss: 2.65559720993042
Validation loss: 2.4586963909928516

Epoch: 6| Step: 9
Training loss: 2.58455753326416
Validation loss: 2.445340984611101

Epoch: 6| Step: 10
Training loss: 2.263470411300659
Validation loss: 2.427111027061298

Epoch: 6| Step: 11
Training loss: 2.811444044113159
Validation loss: 2.41500194867452

Epoch: 6| Step: 12
Training loss: 1.9051835536956787
Validation loss: 2.3970986258599067

Epoch: 6| Step: 13
Training loss: 2.102870225906372
Validation loss: 2.3591778329623643

Epoch: 55| Step: 0
Training loss: 1.769963026046753
Validation loss: 2.341161932996524

Epoch: 6| Step: 1
Training loss: 2.4926538467407227
Validation loss: 2.3258497586814304

Epoch: 6| Step: 2
Training loss: 2.244967460632324
Validation loss: 2.327189419859199

Epoch: 6| Step: 3
Training loss: 2.269794225692749
Validation loss: 2.3157046712854856

Epoch: 6| Step: 4
Training loss: 3.16219162940979
Validation loss: 2.307287880169448

Epoch: 6| Step: 5
Training loss: 2.506009817123413
Validation loss: 2.2978454533443657

Epoch: 6| Step: 6
Training loss: 2.483241081237793
Validation loss: 2.2950995173505557

Epoch: 6| Step: 7
Training loss: 3.045253038406372
Validation loss: 2.296080876422185

Epoch: 6| Step: 8
Training loss: 2.7169289588928223
Validation loss: 2.3134545818451913

Epoch: 6| Step: 9
Training loss: 2.862459659576416
Validation loss: 2.3179981118889263

Epoch: 6| Step: 10
Training loss: 2.245357036590576
Validation loss: 2.317925694168255

Epoch: 6| Step: 11
Training loss: 2.3370823860168457
Validation loss: 2.308648435018396

Epoch: 6| Step: 12
Training loss: 2.8601088523864746
Validation loss: 2.302126246113931

Epoch: 6| Step: 13
Training loss: 3.621777057647705
Validation loss: 2.2937806575529036

Epoch: 56| Step: 0
Training loss: 1.9559593200683594
Validation loss: 2.28074465515793

Epoch: 6| Step: 1
Training loss: 3.265481472015381
Validation loss: 2.2801108898655063

Epoch: 6| Step: 2
Training loss: 2.5078258514404297
Validation loss: 2.282975548057146

Epoch: 6| Step: 3
Training loss: 2.1205477714538574
Validation loss: 2.2803445323821037

Epoch: 6| Step: 4
Training loss: 3.1763949394226074
Validation loss: 2.2823690060646302

Epoch: 6| Step: 5
Training loss: 2.0137505531311035
Validation loss: 2.292787064788162

Epoch: 6| Step: 6
Training loss: 2.6735475063323975
Validation loss: 2.3066928886598155

Epoch: 6| Step: 7
Training loss: 2.403907299041748
Validation loss: 2.3352527387680544

Epoch: 6| Step: 8
Training loss: 2.2328286170959473
Validation loss: 2.329908276116976

Epoch: 6| Step: 9
Training loss: 2.9365310668945312
Validation loss: 2.3188503070544173

Epoch: 6| Step: 10
Training loss: 2.971954345703125
Validation loss: 2.2972322971590105

Epoch: 6| Step: 11
Training loss: 2.8152146339416504
Validation loss: 2.2733417582768265

Epoch: 6| Step: 12
Training loss: 2.6055831909179688
Validation loss: 2.268177975890457

Epoch: 6| Step: 13
Training loss: 2.160548210144043
Validation loss: 2.260164112173101

Epoch: 57| Step: 0
Training loss: 2.304591178894043
Validation loss: 2.2557577304942633

Epoch: 6| Step: 1
Training loss: 3.0555872917175293
Validation loss: 2.255681176339426

Epoch: 6| Step: 2
Training loss: 2.3414828777313232
Validation loss: 2.2729884809063328

Epoch: 6| Step: 3
Training loss: 3.000497579574585
Validation loss: 2.2866651319688365

Epoch: 6| Step: 4
Training loss: 1.8233139514923096
Validation loss: 2.290095034465995

Epoch: 6| Step: 5
Training loss: 2.0957531929016113
Validation loss: 2.2855389220740205

Epoch: 6| Step: 6
Training loss: 2.0751585960388184
Validation loss: 2.279400522990893

Epoch: 6| Step: 7
Training loss: 2.4836745262145996
Validation loss: 2.290620614123601

Epoch: 6| Step: 8
Training loss: 2.1691718101501465
Validation loss: 2.309652651509931

Epoch: 6| Step: 9
Training loss: 2.691040277481079
Validation loss: 2.338745114623859

Epoch: 6| Step: 10
Training loss: 3.3260140419006348
Validation loss: 2.3586523737958682

Epoch: 6| Step: 11
Training loss: 3.651224136352539
Validation loss: 2.375759234992407

Epoch: 6| Step: 12
Training loss: 2.4207394123077393
Validation loss: 2.3638587536350375

Epoch: 6| Step: 13
Training loss: 2.7878518104553223
Validation loss: 2.3419216627715738

Epoch: 58| Step: 0
Training loss: 2.8529207706451416
Validation loss: 2.299122264308314

Epoch: 6| Step: 1
Training loss: 2.3483355045318604
Validation loss: 2.270917702746648

Epoch: 6| Step: 2
Training loss: 3.00880765914917
Validation loss: 2.251308843653689

Epoch: 6| Step: 3
Training loss: 3.134089946746826
Validation loss: 2.2600896050853114

Epoch: 6| Step: 4
Training loss: 1.6242384910583496
Validation loss: 2.30416036933981

Epoch: 6| Step: 5
Training loss: 2.8252673149108887
Validation loss: 2.317640822420838

Epoch: 6| Step: 6
Training loss: 2.907475471496582
Validation loss: 2.340674869475826

Epoch: 6| Step: 7
Training loss: 2.713474988937378
Validation loss: 2.3981943386857227

Epoch: 6| Step: 8
Training loss: 2.710742712020874
Validation loss: 2.355854744552284

Epoch: 6| Step: 9
Training loss: 3.107923746109009
Validation loss: 2.3180189235236055

Epoch: 6| Step: 10
Training loss: 1.9245579242706299
Validation loss: 2.3045222707974014

Epoch: 6| Step: 11
Training loss: 2.3888015747070312
Validation loss: 2.258007900689238

Epoch: 6| Step: 12
Training loss: 2.4205799102783203
Validation loss: 2.247676759637812

Epoch: 6| Step: 13
Training loss: 2.506985902786255
Validation loss: 2.2491734181680987

Epoch: 59| Step: 0
Training loss: 2.874500274658203
Validation loss: 2.24727447571293

Epoch: 6| Step: 1
Training loss: 2.5441699028015137
Validation loss: 2.257912915240052

Epoch: 6| Step: 2
Training loss: 2.453298807144165
Validation loss: 2.26922018553621

Epoch: 6| Step: 3
Training loss: 2.043196439743042
Validation loss: 2.284062836759834

Epoch: 6| Step: 4
Training loss: 2.672022819519043
Validation loss: 2.301241672167214

Epoch: 6| Step: 5
Training loss: 1.7606942653656006
Validation loss: 2.313662403373308

Epoch: 6| Step: 6
Training loss: 3.2940447330474854
Validation loss: 2.335464039156514

Epoch: 6| Step: 7
Training loss: 2.5476808547973633
Validation loss: 2.3355920032788346

Epoch: 6| Step: 8
Training loss: 2.8586950302124023
Validation loss: 2.3100677049288185

Epoch: 6| Step: 9
Training loss: 1.5967711210250854
Validation loss: 2.298855559800261

Epoch: 6| Step: 10
Training loss: 1.7113208770751953
Validation loss: 2.284120349473851

Epoch: 6| Step: 11
Training loss: 2.8155317306518555
Validation loss: 2.2858408830499135

Epoch: 6| Step: 12
Training loss: 3.623914957046509
Validation loss: 2.2861334149555494

Epoch: 6| Step: 13
Training loss: 3.183562994003296
Validation loss: 2.2836051320516937

Epoch: 60| Step: 0
Training loss: 2.9139299392700195
Validation loss: 2.2823046151027886

Epoch: 6| Step: 1
Training loss: 2.9086861610412598
Validation loss: 2.286699484753352

Epoch: 6| Step: 2
Training loss: 2.8604629039764404
Validation loss: 2.292686059910764

Epoch: 6| Step: 3
Training loss: 2.603829860687256
Validation loss: 2.310965872580005

Epoch: 6| Step: 4
Training loss: 2.296132802963257
Validation loss: 2.27200484788546

Epoch: 6| Step: 5
Training loss: 2.4790592193603516
Validation loss: 2.265416696507444

Epoch: 6| Step: 6
Training loss: 2.169820785522461
Validation loss: 2.266717936403008

Epoch: 6| Step: 7
Training loss: 2.696187734603882
Validation loss: 2.2732345442618094

Epoch: 6| Step: 8
Training loss: 2.252519130706787
Validation loss: 2.2678659962069605

Epoch: 6| Step: 9
Training loss: 1.5239334106445312
Validation loss: 2.2647374958120365

Epoch: 6| Step: 10
Training loss: 3.0488829612731934
Validation loss: 2.258441548193655

Epoch: 6| Step: 11
Training loss: 3.079604148864746
Validation loss: 2.256370746961204

Epoch: 6| Step: 12
Training loss: 2.7707791328430176
Validation loss: 2.261316245602023

Epoch: 6| Step: 13
Training loss: 1.4816985130310059
Validation loss: 2.258055204986244

Epoch: 61| Step: 0
Training loss: 2.3066818714141846
Validation loss: 2.2586749484462123

Epoch: 6| Step: 1
Training loss: 2.2339377403259277
Validation loss: 2.2527709468718498

Epoch: 6| Step: 2
Training loss: 2.6946916580200195
Validation loss: 2.2490405087829917

Epoch: 6| Step: 3
Training loss: 2.4223084449768066
Validation loss: 2.249977619417252

Epoch: 6| Step: 4
Training loss: 2.9829864501953125
Validation loss: 2.2630530634234027

Epoch: 6| Step: 5
Training loss: 2.50101375579834
Validation loss: 2.271292136561486

Epoch: 6| Step: 6
Training loss: 2.333170175552368
Validation loss: 2.2758793471961893

Epoch: 6| Step: 7
Training loss: 2.1069371700286865
Validation loss: 2.2733802564682497

Epoch: 6| Step: 8
Training loss: 3.375690460205078
Validation loss: 2.290906360072474

Epoch: 6| Step: 9
Training loss: 2.5573301315307617
Validation loss: 2.2824840212381012

Epoch: 6| Step: 10
Training loss: 2.992840051651001
Validation loss: 2.265285640634516

Epoch: 6| Step: 11
Training loss: 1.89373779296875
Validation loss: 2.2464477349353094

Epoch: 6| Step: 12
Training loss: 2.6506612300872803
Validation loss: 2.242901502117034

Epoch: 6| Step: 13
Training loss: 2.359865665435791
Validation loss: 2.2283186117808023

Epoch: 62| Step: 0
Training loss: 2.6724693775177
Validation loss: 2.2255868501560663

Epoch: 6| Step: 1
Training loss: 2.133540153503418
Validation loss: 2.221047862883537

Epoch: 6| Step: 2
Training loss: 2.4608070850372314
Validation loss: 2.222328487262931

Epoch: 6| Step: 3
Training loss: 2.594137191772461
Validation loss: 2.2245552155279342

Epoch: 6| Step: 4
Training loss: 3.038849353790283
Validation loss: 2.22034365131009

Epoch: 6| Step: 5
Training loss: 2.1414594650268555
Validation loss: 2.221722302898284

Epoch: 6| Step: 6
Training loss: 2.4575421810150146
Validation loss: 2.2184041059145363

Epoch: 6| Step: 7
Training loss: 2.7538270950317383
Validation loss: 2.217428389415946

Epoch: 6| Step: 8
Training loss: 3.231461763381958
Validation loss: 2.219353242587018

Epoch: 6| Step: 9
Training loss: 1.9655065536499023
Validation loss: 2.214918674961213

Epoch: 6| Step: 10
Training loss: 2.6928911209106445
Validation loss: 2.220525195521693

Epoch: 6| Step: 11
Training loss: 2.776486873626709
Validation loss: 2.2264774384037143

Epoch: 6| Step: 12
Training loss: 2.0386404991149902
Validation loss: 2.232935354273806

Epoch: 6| Step: 13
Training loss: 2.513566017150879
Validation loss: 2.256287013330767

Epoch: 63| Step: 0
Training loss: 2.3127286434173584
Validation loss: 2.2748103731422016

Epoch: 6| Step: 1
Training loss: 3.0353951454162598
Validation loss: 2.2843318549535607

Epoch: 6| Step: 2
Training loss: 2.4101181030273438
Validation loss: 2.296421484280658

Epoch: 6| Step: 3
Training loss: 2.897429943084717
Validation loss: 2.312751664910265

Epoch: 6| Step: 4
Training loss: 2.6947474479675293
Validation loss: 2.309043215167138

Epoch: 6| Step: 5
Training loss: 2.5648066997528076
Validation loss: 2.296086762541084

Epoch: 6| Step: 6
Training loss: 1.2023346424102783
Validation loss: 2.255853751654266

Epoch: 6| Step: 7
Training loss: 2.887436866760254
Validation loss: 2.2484146189946

Epoch: 6| Step: 8
Training loss: 2.1025872230529785
Validation loss: 2.241667967970653

Epoch: 6| Step: 9
Training loss: 2.404864549636841
Validation loss: 2.2328460088340183

Epoch: 6| Step: 10
Training loss: 2.824704170227051
Validation loss: 2.2695674947513047

Epoch: 6| Step: 11
Training loss: 2.983752727508545
Validation loss: 2.249627233833395

Epoch: 6| Step: 12
Training loss: 2.7896997928619385
Validation loss: 2.2353491885687715

Epoch: 6| Step: 13
Training loss: 2.0849108695983887
Validation loss: 2.2250760729594896

Epoch: 64| Step: 0
Training loss: 1.8747960329055786
Validation loss: 2.227207447892876

Epoch: 6| Step: 1
Training loss: 2.9399328231811523
Validation loss: 2.2220550865255375

Epoch: 6| Step: 2
Training loss: 2.128101348876953
Validation loss: 2.2176728863869943

Epoch: 6| Step: 3
Training loss: 2.929678440093994
Validation loss: 2.2291508848949144

Epoch: 6| Step: 4
Training loss: 2.5565900802612305
Validation loss: 2.232776482899984

Epoch: 6| Step: 5
Training loss: 2.2628884315490723
Validation loss: 2.2269631675494614

Epoch: 6| Step: 6
Training loss: 2.5221710205078125
Validation loss: 2.235877772813202

Epoch: 6| Step: 7
Training loss: 2.159986734390259
Validation loss: 2.2381811705968713

Epoch: 6| Step: 8
Training loss: 2.345149040222168
Validation loss: 2.2604949987062843

Epoch: 6| Step: 9
Training loss: 2.6883583068847656
Validation loss: 2.2698010129313313

Epoch: 6| Step: 10
Training loss: 2.2709779739379883
Validation loss: 2.2708874389689457

Epoch: 6| Step: 11
Training loss: 2.7772529125213623
Validation loss: 2.2703164277538175

Epoch: 6| Step: 12
Training loss: 3.3176450729370117
Validation loss: 2.2633104221795195

Epoch: 6| Step: 13
Training loss: 2.635298728942871
Validation loss: 2.24415688104527

Epoch: 65| Step: 0
Training loss: 2.404158115386963
Validation loss: 2.2455605076205347

Epoch: 6| Step: 1
Training loss: 3.1289305686950684
Validation loss: 2.2245029262317124

Epoch: 6| Step: 2
Training loss: 1.934546709060669
Validation loss: 2.218795358493764

Epoch: 6| Step: 3
Training loss: 3.2893645763397217
Validation loss: 2.2362041127297188

Epoch: 6| Step: 4
Training loss: 3.029839277267456
Validation loss: 2.244083153304233

Epoch: 6| Step: 5
Training loss: 2.125915050506592
Validation loss: 2.2391360318788918

Epoch: 6| Step: 6
Training loss: 2.2196052074432373
Validation loss: 2.2445874778173303

Epoch: 6| Step: 7
Training loss: 2.3413991928100586
Validation loss: 2.2365727437439786

Epoch: 6| Step: 8
Training loss: 2.7144265174865723
Validation loss: 2.2326953911012217

Epoch: 6| Step: 9
Training loss: 2.3449978828430176
Validation loss: 2.2394669363575597

Epoch: 6| Step: 10
Training loss: 2.162931203842163
Validation loss: 2.2473894293590257

Epoch: 6| Step: 11
Training loss: 2.6488664150238037
Validation loss: 2.236180095262425

Epoch: 6| Step: 12
Training loss: 2.287425994873047
Validation loss: 2.241492671351279

Epoch: 6| Step: 13
Training loss: 2.501648187637329
Validation loss: 2.2390966902496996

Epoch: 66| Step: 0
Training loss: 2.5672447681427
Validation loss: 2.2619254460898777

Epoch: 6| Step: 1
Training loss: 2.079847812652588
Validation loss: 2.2687626859193206

Epoch: 6| Step: 2
Training loss: 2.4412083625793457
Validation loss: 2.2657639185587564

Epoch: 6| Step: 3
Training loss: 2.4018638134002686
Validation loss: 2.264541825940532

Epoch: 6| Step: 4
Training loss: 2.9410088062286377
Validation loss: 2.2561677681502474

Epoch: 6| Step: 5
Training loss: 2.9264943599700928
Validation loss: 2.237582774572475

Epoch: 6| Step: 6
Training loss: 1.8558833599090576
Validation loss: 2.2269173411912817

Epoch: 6| Step: 7
Training loss: 1.827024221420288
Validation loss: 2.2034172857961347

Epoch: 6| Step: 8
Training loss: 2.856823444366455
Validation loss: 2.199415801673807

Epoch: 6| Step: 9
Training loss: 2.924579620361328
Validation loss: 2.2087195201586654

Epoch: 6| Step: 10
Training loss: 2.4809975624084473
Validation loss: 2.198500161529869

Epoch: 6| Step: 11
Training loss: 2.77523136138916
Validation loss: 2.2068751678671887

Epoch: 6| Step: 12
Training loss: 2.842784881591797
Validation loss: 2.2029766703164704

Epoch: 6| Step: 13
Training loss: 1.8063416481018066
Validation loss: 2.2015257804624495

Epoch: 67| Step: 0
Training loss: 2.4503695964813232
Validation loss: 2.20470441028636

Epoch: 6| Step: 1
Training loss: 2.5376229286193848
Validation loss: 2.2180759009494575

Epoch: 6| Step: 2
Training loss: 3.419559955596924
Validation loss: 2.244659931428971

Epoch: 6| Step: 3
Training loss: 2.5650830268859863
Validation loss: 2.2417718261800785

Epoch: 6| Step: 4
Training loss: 2.552802562713623
Validation loss: 2.2218654860732374

Epoch: 6| Step: 5
Training loss: 2.794954776763916
Validation loss: 2.2055308357361825

Epoch: 6| Step: 6
Training loss: 1.8545291423797607
Validation loss: 2.194056390434183

Epoch: 6| Step: 7
Training loss: 2.9593265056610107
Validation loss: 2.1928579217644146

Epoch: 6| Step: 8
Training loss: 1.984107255935669
Validation loss: 2.191254923420568

Epoch: 6| Step: 9
Training loss: 2.962099552154541
Validation loss: 2.1950301149839997

Epoch: 6| Step: 10
Training loss: 1.7647440433502197
Validation loss: 2.1890511820393224

Epoch: 6| Step: 11
Training loss: 2.8963539600372314
Validation loss: 2.195152585224439

Epoch: 6| Step: 12
Training loss: 2.184537887573242
Validation loss: 2.2028171067596762

Epoch: 6| Step: 13
Training loss: 2.0801124572753906
Validation loss: 2.221580546389344

Epoch: 68| Step: 0
Training loss: 3.540165424346924
Validation loss: 2.225728757919804

Epoch: 6| Step: 1
Training loss: 2.38362193107605
Validation loss: 2.23308737303621

Epoch: 6| Step: 2
Training loss: 2.6587257385253906
Validation loss: 2.2260903363586753

Epoch: 6| Step: 3
Training loss: 1.7122554779052734
Validation loss: 2.231035740144791

Epoch: 6| Step: 4
Training loss: 1.8924741744995117
Validation loss: 2.246630735294793

Epoch: 6| Step: 5
Training loss: 2.9445414543151855
Validation loss: 2.2504718175498386

Epoch: 6| Step: 6
Training loss: 2.306227684020996
Validation loss: 2.2621312090145644

Epoch: 6| Step: 7
Training loss: 2.619332790374756
Validation loss: 2.2573445638020835

Epoch: 6| Step: 8
Training loss: 3.4704155921936035
Validation loss: 2.2464316250175558

Epoch: 6| Step: 9
Training loss: 2.6979317665100098
Validation loss: 2.254561067909323

Epoch: 6| Step: 10
Training loss: 1.8253288269042969
Validation loss: 2.2597171696283485

Epoch: 6| Step: 11
Training loss: 2.139726161956787
Validation loss: 2.265902198770995

Epoch: 6| Step: 12
Training loss: 2.085787773132324
Validation loss: 2.2668556654325096

Epoch: 6| Step: 13
Training loss: 2.780916213989258
Validation loss: 2.2231089171542915

Epoch: 69| Step: 0
Training loss: 3.091315269470215
Validation loss: 2.1910843156999156

Epoch: 6| Step: 1
Training loss: 2.6381783485412598
Validation loss: 2.1800718961223478

Epoch: 6| Step: 2
Training loss: 2.619065761566162
Validation loss: 2.176954047654265

Epoch: 6| Step: 3
Training loss: 2.507354736328125
Validation loss: 2.1882690447632984

Epoch: 6| Step: 4
Training loss: 2.572286605834961
Validation loss: 2.1989206960124354

Epoch: 6| Step: 5
Training loss: 2.435953140258789
Validation loss: 2.195490265405306

Epoch: 6| Step: 6
Training loss: 2.6541380882263184
Validation loss: 2.224048335065124

Epoch: 6| Step: 7
Training loss: 2.250973701477051
Validation loss: 2.230268806539556

Epoch: 6| Step: 8
Training loss: 2.3353781700134277
Validation loss: 2.2620540998315297

Epoch: 6| Step: 9
Training loss: 2.908064842224121
Validation loss: 2.216677091454947

Epoch: 6| Step: 10
Training loss: 2.7446513175964355
Validation loss: 2.215845592560307

Epoch: 6| Step: 11
Training loss: 2.0372509956359863
Validation loss: 2.2075700849615116

Epoch: 6| Step: 12
Training loss: 2.041921854019165
Validation loss: 2.197584174012625

Epoch: 6| Step: 13
Training loss: 3.3142645359039307
Validation loss: 2.1972061741736626

Epoch: 70| Step: 0
Training loss: 2.134098529815674
Validation loss: 2.188235359807168

Epoch: 6| Step: 1
Training loss: 2.330996513366699
Validation loss: 2.1864376350115706

Epoch: 6| Step: 2
Training loss: 3.217386484146118
Validation loss: 2.1889360489383822

Epoch: 6| Step: 3
Training loss: 2.1888086795806885
Validation loss: 2.1900117140944286

Epoch: 6| Step: 4
Training loss: 2.4620299339294434
Validation loss: 2.193110018648127

Epoch: 6| Step: 5
Training loss: 2.467923164367676
Validation loss: 2.2094688979528283

Epoch: 6| Step: 6
Training loss: 2.9588394165039062
Validation loss: 2.2632505393797353

Epoch: 6| Step: 7
Training loss: 3.0105929374694824
Validation loss: 2.2733361016037645

Epoch: 6| Step: 8
Training loss: 2.3573310375213623
Validation loss: 2.2830048863605787

Epoch: 6| Step: 9
Training loss: 2.786999225616455
Validation loss: 2.290675526024193

Epoch: 6| Step: 10
Training loss: 2.2477455139160156
Validation loss: 2.2742870981975267

Epoch: 6| Step: 11
Training loss: 1.5505616664886475
Validation loss: 2.2371421167927403

Epoch: 6| Step: 12
Training loss: 2.7202744483947754
Validation loss: 2.2098109799046672

Epoch: 6| Step: 13
Training loss: 2.5113956928253174
Validation loss: 2.186944735947476

Epoch: 71| Step: 0
Training loss: 2.8833069801330566
Validation loss: 2.1785411219443045

Epoch: 6| Step: 1
Training loss: 2.610039234161377
Validation loss: 2.173570393234171

Epoch: 6| Step: 2
Training loss: 1.9360482692718506
Validation loss: 2.1728984886600125

Epoch: 6| Step: 3
Training loss: 2.2083423137664795
Validation loss: 2.1732940878919376

Epoch: 6| Step: 4
Training loss: 3.082104444503784
Validation loss: 2.165398043970908

Epoch: 6| Step: 5
Training loss: 2.375515937805176
Validation loss: 2.169669851180046

Epoch: 6| Step: 6
Training loss: 1.9349608421325684
Validation loss: 2.1707043135037987

Epoch: 6| Step: 7
Training loss: 2.71893048286438
Validation loss: 2.1687895046767367

Epoch: 6| Step: 8
Training loss: 2.5112597942352295
Validation loss: 2.165096172722437

Epoch: 6| Step: 9
Training loss: 2.817742347717285
Validation loss: 2.1664476330562303

Epoch: 6| Step: 10
Training loss: 2.26935076713562
Validation loss: 2.1712290189599477

Epoch: 6| Step: 11
Training loss: 2.2310800552368164
Validation loss: 2.18448293593622

Epoch: 6| Step: 12
Training loss: 2.7106471061706543
Validation loss: 2.201686651475968

Epoch: 6| Step: 13
Training loss: 2.8947031497955322
Validation loss: 2.235029676909088

Epoch: 72| Step: 0
Training loss: 2.5965614318847656
Validation loss: 2.2709969525696128

Epoch: 6| Step: 1
Training loss: 2.018207550048828
Validation loss: 2.2814026135270313

Epoch: 6| Step: 2
Training loss: 2.898804187774658
Validation loss: 2.281636607262396

Epoch: 6| Step: 3
Training loss: 1.7662044763565063
Validation loss: 2.2461193274426203

Epoch: 6| Step: 4
Training loss: 2.2556381225585938
Validation loss: 2.2098187220993863

Epoch: 6| Step: 5
Training loss: 1.936084270477295
Validation loss: 2.1901574596281974

Epoch: 6| Step: 6
Training loss: 2.288562774658203
Validation loss: 2.1710587445125786

Epoch: 6| Step: 7
Training loss: 2.6952567100524902
Validation loss: 2.1538909148144465

Epoch: 6| Step: 8
Training loss: 2.8412299156188965
Validation loss: 2.153720002020559

Epoch: 6| Step: 9
Training loss: 2.670807361602783
Validation loss: 2.162356376647949

Epoch: 6| Step: 10
Training loss: 2.1298418045043945
Validation loss: 2.1669940102484917

Epoch: 6| Step: 11
Training loss: 2.9343152046203613
Validation loss: 2.2090323817345405

Epoch: 6| Step: 12
Training loss: 3.06268310546875
Validation loss: 2.179807860364196

Epoch: 6| Step: 13
Training loss: 3.283812999725342
Validation loss: 2.164681537176973

Epoch: 73| Step: 0
Training loss: 2.2559220790863037
Validation loss: 2.158688788772911

Epoch: 6| Step: 1
Training loss: 2.527880907058716
Validation loss: 2.158220601338212

Epoch: 6| Step: 2
Training loss: 3.096877098083496
Validation loss: 2.156645090349259

Epoch: 6| Step: 3
Training loss: 1.7531427145004272
Validation loss: 2.157290925261795

Epoch: 6| Step: 4
Training loss: 2.666475296020508
Validation loss: 2.164886728409798

Epoch: 6| Step: 5
Training loss: 2.668306827545166
Validation loss: 2.169738472148936

Epoch: 6| Step: 6
Training loss: 2.447430372238159
Validation loss: 2.182736009679815

Epoch: 6| Step: 7
Training loss: 2.5976333618164062
Validation loss: 2.2023271411977787

Epoch: 6| Step: 8
Training loss: 2.289321184158325
Validation loss: 2.2242036711785103

Epoch: 6| Step: 9
Training loss: 2.1734185218811035
Validation loss: 2.233240560818744

Epoch: 6| Step: 10
Training loss: 3.023603916168213
Validation loss: 2.241004587501608

Epoch: 6| Step: 11
Training loss: 2.4314041137695312
Validation loss: 2.2505963669028333

Epoch: 6| Step: 12
Training loss: 2.4231207370758057
Validation loss: 2.251450971890521

Epoch: 6| Step: 13
Training loss: 2.4519364833831787
Validation loss: 2.258393731168521

Epoch: 74| Step: 0
Training loss: 2.6390438079833984
Validation loss: 2.216973820040303

Epoch: 6| Step: 1
Training loss: 1.8715194463729858
Validation loss: 2.2283275717048237

Epoch: 6| Step: 2
Training loss: 2.662578582763672
Validation loss: 2.2363883782458562

Epoch: 6| Step: 3
Training loss: 2.5818400382995605
Validation loss: 2.219864040292719

Epoch: 6| Step: 4
Training loss: 3.2317967414855957
Validation loss: 2.2144352800102642

Epoch: 6| Step: 5
Training loss: 2.917811870574951
Validation loss: 2.2135729982006933

Epoch: 6| Step: 6
Training loss: 2.9621315002441406
Validation loss: 2.212236265982351

Epoch: 6| Step: 7
Training loss: 2.26839280128479
Validation loss: 2.2088337752126876

Epoch: 6| Step: 8
Training loss: 2.1083569526672363
Validation loss: 2.2068073903360674

Epoch: 6| Step: 9
Training loss: 3.0855929851531982
Validation loss: 2.207248244234311

Epoch: 6| Step: 10
Training loss: 2.3455772399902344
Validation loss: 2.2123551086712907

Epoch: 6| Step: 11
Training loss: 1.690826177597046
Validation loss: 2.2012184986504177

Epoch: 6| Step: 12
Training loss: 2.2267541885375977
Validation loss: 2.210589098673995

Epoch: 6| Step: 13
Training loss: 2.2603728771209717
Validation loss: 2.2070865400375856

Epoch: 75| Step: 0
Training loss: 2.341946601867676
Validation loss: 2.2078772296187696

Epoch: 6| Step: 1
Training loss: 2.1622583866119385
Validation loss: 2.2163952755671676

Epoch: 6| Step: 2
Training loss: 2.9602808952331543
Validation loss: 2.2253363760568763

Epoch: 6| Step: 3
Training loss: 2.5951766967773438
Validation loss: 2.2163491223448064

Epoch: 6| Step: 4
Training loss: 2.799182891845703
Validation loss: 2.228034432216357

Epoch: 6| Step: 5
Training loss: 2.2496745586395264
Validation loss: 2.2356613271979877

Epoch: 6| Step: 6
Training loss: 2.538625478744507
Validation loss: 2.248686482829432

Epoch: 6| Step: 7
Training loss: 1.9431488513946533
Validation loss: 2.25831187412303

Epoch: 6| Step: 8
Training loss: 2.79244327545166
Validation loss: 2.2629404760176137

Epoch: 6| Step: 9
Training loss: 2.4588727951049805
Validation loss: 2.235837023745301

Epoch: 6| Step: 10
Training loss: 2.7934939861297607
Validation loss: 2.210000603429733

Epoch: 6| Step: 11
Training loss: 2.66690731048584
Validation loss: 2.195644050516108

Epoch: 6| Step: 12
Training loss: 2.275900363922119
Validation loss: 2.163280079441686

Epoch: 6| Step: 13
Training loss: 1.9462653398513794
Validation loss: 2.153991191617904

Epoch: 76| Step: 0
Training loss: 2.838265895843506
Validation loss: 2.1480375823154243

Epoch: 6| Step: 1
Training loss: 2.5117764472961426
Validation loss: 2.156328405103376

Epoch: 6| Step: 2
Training loss: 2.8269174098968506
Validation loss: 2.156198024749756

Epoch: 6| Step: 3
Training loss: 2.7967677116394043
Validation loss: 2.16107484345795

Epoch: 6| Step: 4
Training loss: 2.293839931488037
Validation loss: 2.17270581183895

Epoch: 6| Step: 5
Training loss: 2.236025810241699
Validation loss: 2.1850114624987365

Epoch: 6| Step: 6
Training loss: 3.006533622741699
Validation loss: 2.203660540683295

Epoch: 6| Step: 7
Training loss: 2.440640926361084
Validation loss: 2.2293505027729976

Epoch: 6| Step: 8
Training loss: 2.52494740486145
Validation loss: 2.2237638055637317

Epoch: 6| Step: 9
Training loss: 1.8761608600616455
Validation loss: 2.209956976675218

Epoch: 6| Step: 10
Training loss: 3.0204663276672363
Validation loss: 2.19856979385499

Epoch: 6| Step: 11
Training loss: 2.0027542114257812
Validation loss: 2.179077330455985

Epoch: 6| Step: 12
Training loss: 1.7637312412261963
Validation loss: 2.1576530497561217

Epoch: 6| Step: 13
Training loss: 2.343287467956543
Validation loss: 2.137437753779914

Epoch: 77| Step: 0
Training loss: 1.533851146697998
Validation loss: 2.1406597680942987

Epoch: 6| Step: 1
Training loss: 1.8158862590789795
Validation loss: 2.1418835168243735

Epoch: 6| Step: 2
Training loss: 2.598503589630127
Validation loss: 2.134237914957026

Epoch: 6| Step: 3
Training loss: 2.551957607269287
Validation loss: 2.1319896495470436

Epoch: 6| Step: 4
Training loss: 2.6381587982177734
Validation loss: 2.143938961849418

Epoch: 6| Step: 5
Training loss: 3.1932425498962402
Validation loss: 2.1601956249565206

Epoch: 6| Step: 6
Training loss: 1.7964215278625488
Validation loss: 2.1736142507163425

Epoch: 6| Step: 7
Training loss: 2.957519292831421
Validation loss: 2.207743352459323

Epoch: 6| Step: 8
Training loss: 2.4433677196502686
Validation loss: 2.2007008444878364

Epoch: 6| Step: 9
Training loss: 2.606433868408203
Validation loss: 2.213635654859645

Epoch: 6| Step: 10
Training loss: 2.249988317489624
Validation loss: 2.2213755294840825

Epoch: 6| Step: 11
Training loss: 3.135340690612793
Validation loss: 2.2036073900038198

Epoch: 6| Step: 12
Training loss: 2.397616386413574
Validation loss: 2.1736259973177345

Epoch: 6| Step: 13
Training loss: 2.701418161392212
Validation loss: 2.1424458462704896

Epoch: 78| Step: 0
Training loss: 3.1491737365722656
Validation loss: 2.1279644427760953

Epoch: 6| Step: 1
Training loss: 2.29457426071167
Validation loss: 2.1311177822851364

Epoch: 6| Step: 2
Training loss: 2.565232992172241
Validation loss: 2.1271773089644728

Epoch: 6| Step: 3
Training loss: 2.8324222564697266
Validation loss: 2.1239215507302234

Epoch: 6| Step: 4
Training loss: 2.3987207412719727
Validation loss: 2.1281009028034825

Epoch: 6| Step: 5
Training loss: 2.7574028968811035
Validation loss: 2.131562699553787

Epoch: 6| Step: 6
Training loss: 2.7065486907958984
Validation loss: 2.1388695214384343

Epoch: 6| Step: 7
Training loss: 1.79325532913208
Validation loss: 2.1590938209205546

Epoch: 6| Step: 8
Training loss: 2.7401046752929688
Validation loss: 2.184773573311426

Epoch: 6| Step: 9
Training loss: 2.0746893882751465
Validation loss: 2.196998066799615

Epoch: 6| Step: 10
Training loss: 1.8956754207611084
Validation loss: 2.194364563111336

Epoch: 6| Step: 11
Training loss: 2.984117031097412
Validation loss: 2.172486553909958

Epoch: 6| Step: 12
Training loss: 1.7362077236175537
Validation loss: 2.1586918471961893

Epoch: 6| Step: 13
Training loss: 2.48709774017334
Validation loss: 2.149702746381042

Epoch: 79| Step: 0
Training loss: 2.1667261123657227
Validation loss: 2.130871211328814

Epoch: 6| Step: 1
Training loss: 2.4699454307556152
Validation loss: 2.1223076466591126

Epoch: 6| Step: 2
Training loss: 2.0512242317199707
Validation loss: 2.1185018400992117

Epoch: 6| Step: 3
Training loss: 2.9531145095825195
Validation loss: 2.1213432178702405

Epoch: 6| Step: 4
Training loss: 1.6085271835327148
Validation loss: 2.121264676893911

Epoch: 6| Step: 5
Training loss: 2.6546783447265625
Validation loss: 2.129838441007881

Epoch: 6| Step: 6
Training loss: 2.5578079223632812
Validation loss: 2.1301933539811

Epoch: 6| Step: 7
Training loss: 2.3629002571105957
Validation loss: 2.1275531040724887

Epoch: 6| Step: 8
Training loss: 3.4406068325042725
Validation loss: 2.128794276586143

Epoch: 6| Step: 9
Training loss: 2.263598680496216
Validation loss: 2.1192665869189846

Epoch: 6| Step: 10
Training loss: 1.9638862609863281
Validation loss: 2.132913451040945

Epoch: 6| Step: 11
Training loss: 3.0357043743133545
Validation loss: 2.1543243674821753

Epoch: 6| Step: 12
Training loss: 2.2275476455688477
Validation loss: 2.1787863187892462

Epoch: 6| Step: 13
Training loss: 2.364696741104126
Validation loss: 2.1938422405591576

Epoch: 80| Step: 0
Training loss: 3.0989880561828613
Validation loss: 2.193435130580779

Epoch: 6| Step: 1
Training loss: 1.9915591478347778
Validation loss: 2.2047766049702964

Epoch: 6| Step: 2
Training loss: 2.2887091636657715
Validation loss: 2.200357178206085

Epoch: 6| Step: 3
Training loss: 2.168239116668701
Validation loss: 2.2144820946519093

Epoch: 6| Step: 4
Training loss: 2.497480869293213
Validation loss: 2.1834105214764996

Epoch: 6| Step: 5
Training loss: 2.167985439300537
Validation loss: 2.1596561836939987

Epoch: 6| Step: 6
Training loss: 2.363856315612793
Validation loss: 2.1352635583569928

Epoch: 6| Step: 7
Training loss: 2.2290303707122803
Validation loss: 2.116791304721627

Epoch: 6| Step: 8
Training loss: 2.8908092975616455
Validation loss: 2.119786577840005

Epoch: 6| Step: 9
Training loss: 2.516005277633667
Validation loss: 2.132902950368902

Epoch: 6| Step: 10
Training loss: 2.466187000274658
Validation loss: 2.1183927341174056

Epoch: 6| Step: 11
Training loss: 2.7495546340942383
Validation loss: 2.12327144991967

Epoch: 6| Step: 12
Training loss: 2.525454044342041
Validation loss: 2.126143575996481

Epoch: 6| Step: 13
Training loss: 1.728095531463623
Validation loss: 2.1192648590251966

Epoch: 81| Step: 0
Training loss: 2.2118661403656006
Validation loss: 2.1306190682995703

Epoch: 6| Step: 1
Training loss: 2.5140585899353027
Validation loss: 2.132912772957997

Epoch: 6| Step: 2
Training loss: 2.458420753479004
Validation loss: 2.125219868075463

Epoch: 6| Step: 3
Training loss: 2.45224666595459
Validation loss: 2.1369881091579312

Epoch: 6| Step: 4
Training loss: 1.734357237815857
Validation loss: 2.1546891248354347

Epoch: 6| Step: 5
Training loss: 2.5184988975524902
Validation loss: 2.1597917259380384

Epoch: 6| Step: 6
Training loss: 2.1125988960266113
Validation loss: 2.150719868239536

Epoch: 6| Step: 7
Training loss: 2.3560073375701904
Validation loss: 2.1486705221155638

Epoch: 6| Step: 8
Training loss: 2.591770648956299
Validation loss: 2.120259073472792

Epoch: 6| Step: 9
Training loss: 2.857095956802368
Validation loss: 2.1193339645221667

Epoch: 6| Step: 10
Training loss: 2.713867425918579
Validation loss: 2.1167129521728842

Epoch: 6| Step: 11
Training loss: 2.3067784309387207
Validation loss: 2.1256975794351227

Epoch: 6| Step: 12
Training loss: 2.612647771835327
Validation loss: 2.1449714296607563

Epoch: 6| Step: 13
Training loss: 2.670322895050049
Validation loss: 2.1603531734917754

Epoch: 82| Step: 0
Training loss: 2.3396241664886475
Validation loss: 2.1704547148878857

Epoch: 6| Step: 1
Training loss: 2.5072264671325684
Validation loss: 2.162895942247042

Epoch: 6| Step: 2
Training loss: 2.5019774436950684
Validation loss: 2.132496174945626

Epoch: 6| Step: 3
Training loss: 2.739180088043213
Validation loss: 2.120150609682965

Epoch: 6| Step: 4
Training loss: 2.562671184539795
Validation loss: 2.1060514424436834

Epoch: 6| Step: 5
Training loss: 2.5802698135375977
Validation loss: 2.103966853951895

Epoch: 6| Step: 6
Training loss: 2.2321066856384277
Validation loss: 2.102755411978691

Epoch: 6| Step: 7
Training loss: 2.5103585720062256
Validation loss: 2.1007834096108713

Epoch: 6| Step: 8
Training loss: 2.8910560607910156
Validation loss: 2.107344429980042

Epoch: 6| Step: 9
Training loss: 2.205120325088501
Validation loss: 2.103292603646555

Epoch: 6| Step: 10
Training loss: 1.5685696601867676
Validation loss: 2.1236303531995384

Epoch: 6| Step: 11
Training loss: 1.9640178680419922
Validation loss: 2.140003950365128

Epoch: 6| Step: 12
Training loss: 3.027693271636963
Validation loss: 2.147522064947313

Epoch: 6| Step: 13
Training loss: 2.0967485904693604
Validation loss: 2.140414527667466

Epoch: 83| Step: 0
Training loss: 1.786754846572876
Validation loss: 2.1106740659283054

Epoch: 6| Step: 1
Training loss: 2.6785802841186523
Validation loss: 2.1031453660739365

Epoch: 6| Step: 2
Training loss: 2.2027645111083984
Validation loss: 2.1055993469812537

Epoch: 6| Step: 3
Training loss: 2.3096609115600586
Validation loss: 2.1015283946068055

Epoch: 6| Step: 4
Training loss: 2.562835931777954
Validation loss: 2.0920838591873006

Epoch: 6| Step: 5
Training loss: 2.4046645164489746
Validation loss: 2.0921175915707826

Epoch: 6| Step: 6
Training loss: 2.1280901432037354
Validation loss: 2.0858719451453096

Epoch: 6| Step: 7
Training loss: 2.249298572540283
Validation loss: 2.085053878445779

Epoch: 6| Step: 8
Training loss: 2.7692453861236572
Validation loss: 2.0897746560394124

Epoch: 6| Step: 9
Training loss: 2.106801986694336
Validation loss: 2.09314529613782

Epoch: 6| Step: 10
Training loss: 2.461909294128418
Validation loss: 2.0973683095747426

Epoch: 6| Step: 11
Training loss: 2.686267137527466
Validation loss: 2.1226930502922303

Epoch: 6| Step: 12
Training loss: 2.861504077911377
Validation loss: 2.1609807681011897

Epoch: 6| Step: 13
Training loss: 2.5387368202209473
Validation loss: 2.193609017197804

Epoch: 84| Step: 0
Training loss: 2.662517786026001
Validation loss: 2.2516104482835337

Epoch: 6| Step: 1
Training loss: 2.1623058319091797
Validation loss: 2.2286601425499044

Epoch: 6| Step: 2
Training loss: 2.3300437927246094
Validation loss: 2.1680543832881476

Epoch: 6| Step: 3
Training loss: 3.1417441368103027
Validation loss: 2.1474459235386183

Epoch: 6| Step: 4
Training loss: 2.2419471740722656
Validation loss: 2.097422763865481

Epoch: 6| Step: 5
Training loss: 2.3182005882263184
Validation loss: 2.092450564907443

Epoch: 6| Step: 6
Training loss: 2.76802134513855
Validation loss: 2.0807745200331493

Epoch: 6| Step: 7
Training loss: 2.296971559524536
Validation loss: 2.07935849056449

Epoch: 6| Step: 8
Training loss: 2.8190712928771973
Validation loss: 2.0792776077024397

Epoch: 6| Step: 9
Training loss: 1.8819409608840942
Validation loss: 2.085275032187021

Epoch: 6| Step: 10
Training loss: 3.0863704681396484
Validation loss: 2.084458710044943

Epoch: 6| Step: 11
Training loss: 1.5579935312271118
Validation loss: 2.0895811024532525

Epoch: 6| Step: 12
Training loss: 2.1232495307922363
Validation loss: 2.082018934270387

Epoch: 6| Step: 13
Training loss: 2.8228259086608887
Validation loss: 2.0910529551967496

Epoch: 85| Step: 0
Training loss: 2.3613572120666504
Validation loss: 2.098505032959805

Epoch: 6| Step: 1
Training loss: 2.650693893432617
Validation loss: 2.11552692485112

Epoch: 6| Step: 2
Training loss: 1.872243881225586
Validation loss: 2.140241035851099

Epoch: 6| Step: 3
Training loss: 2.587151288986206
Validation loss: 2.1675084585784585

Epoch: 6| Step: 4
Training loss: 2.8698232173919678
Validation loss: 2.177203678315686

Epoch: 6| Step: 5
Training loss: 2.409191131591797
Validation loss: 2.2112032059700257

Epoch: 6| Step: 6
Training loss: 2.9300711154937744
Validation loss: 2.2042086419238838

Epoch: 6| Step: 7
Training loss: 2.512080669403076
Validation loss: 2.1837883585242817

Epoch: 6| Step: 8
Training loss: 2.3689606189727783
Validation loss: 2.149427039648897

Epoch: 6| Step: 9
Training loss: 2.725797176361084
Validation loss: 2.141611106934086

Epoch: 6| Step: 10
Training loss: 2.0852437019348145
Validation loss: 2.1355371013764413

Epoch: 6| Step: 11
Training loss: 2.1105031967163086
Validation loss: 2.1449450433895154

Epoch: 6| Step: 12
Training loss: 1.7266488075256348
Validation loss: 2.148636520549815

Epoch: 6| Step: 13
Training loss: 2.6246135234832764
Validation loss: 2.1526428678984284

Epoch: 86| Step: 0
Training loss: 2.250437021255493
Validation loss: 2.142919396841398

Epoch: 6| Step: 1
Training loss: 2.212319850921631
Validation loss: 2.137527870875533

Epoch: 6| Step: 2
Training loss: 2.5481247901916504
Validation loss: 2.127681529650124

Epoch: 6| Step: 3
Training loss: 2.7403101921081543
Validation loss: 2.130353519993444

Epoch: 6| Step: 4
Training loss: 2.2425718307495117
Validation loss: 2.1207540855612805

Epoch: 6| Step: 5
Training loss: 1.9799606800079346
Validation loss: 2.1066997346057685

Epoch: 6| Step: 6
Training loss: 2.238605499267578
Validation loss: 2.119222056481146

Epoch: 6| Step: 7
Training loss: 2.471322774887085
Validation loss: 2.1107769678997736

Epoch: 6| Step: 8
Training loss: 2.369532585144043
Validation loss: 2.0946694984230945

Epoch: 6| Step: 9
Training loss: 2.0833840370178223
Validation loss: 2.08690397713774

Epoch: 6| Step: 10
Training loss: 3.011990547180176
Validation loss: 2.08452667215819

Epoch: 6| Step: 11
Training loss: 2.8574416637420654
Validation loss: 2.0873277674439135

Epoch: 6| Step: 12
Training loss: 2.2768728733062744
Validation loss: 2.081077365465062

Epoch: 6| Step: 13
Training loss: 2.524474620819092
Validation loss: 2.0767449384094565

Epoch: 87| Step: 0
Training loss: 2.213381767272949
Validation loss: 2.0814543911205825

Epoch: 6| Step: 1
Training loss: 1.9253966808319092
Validation loss: 2.1132053764917518

Epoch: 6| Step: 2
Training loss: 2.658419609069824
Validation loss: 2.1820046722248034

Epoch: 6| Step: 3
Training loss: 2.630345344543457
Validation loss: 2.2101864276393766

Epoch: 6| Step: 4
Training loss: 2.439511299133301
Validation loss: 2.1958042037102485

Epoch: 6| Step: 5
Training loss: 2.1304612159729004
Validation loss: 2.1497217121944634

Epoch: 6| Step: 6
Training loss: 2.791811227798462
Validation loss: 2.129822228544502

Epoch: 6| Step: 7
Training loss: 2.6009204387664795
Validation loss: 2.1153724296118623

Epoch: 6| Step: 8
Training loss: 2.0331506729125977
Validation loss: 2.1083003115910355

Epoch: 6| Step: 9
Training loss: 2.56794810295105
Validation loss: 2.1143447276084655

Epoch: 6| Step: 10
Training loss: 2.707711696624756
Validation loss: 2.09231908347017

Epoch: 6| Step: 11
Training loss: 1.9295103549957275
Validation loss: 2.082155477616095

Epoch: 6| Step: 12
Training loss: 2.0522401332855225
Validation loss: 2.0671397460404264

Epoch: 6| Step: 13
Training loss: 3.106348991394043
Validation loss: 2.0753520304156887

Epoch: 88| Step: 0
Training loss: 2.5485939979553223
Validation loss: 2.064068020031016

Epoch: 6| Step: 1
Training loss: 2.421603202819824
Validation loss: 2.072161600153933

Epoch: 6| Step: 2
Training loss: 2.410754919052124
Validation loss: 2.071712972015463

Epoch: 6| Step: 3
Training loss: 2.3423447608947754
Validation loss: 2.070188095492701

Epoch: 6| Step: 4
Training loss: 2.217658281326294
Validation loss: 2.064799262631324

Epoch: 6| Step: 5
Training loss: 2.670996904373169
Validation loss: 2.066671350950836

Epoch: 6| Step: 6
Training loss: 2.4294981956481934
Validation loss: 2.0669114794782413

Epoch: 6| Step: 7
Training loss: 2.9866127967834473
Validation loss: 2.0648607643701697

Epoch: 6| Step: 8
Training loss: 2.0920660495758057
Validation loss: 2.067822556341848

Epoch: 6| Step: 9
Training loss: 2.2398626804351807
Validation loss: 2.0623319636109056

Epoch: 6| Step: 10
Training loss: 2.7631449699401855
Validation loss: 2.0590512496168896

Epoch: 6| Step: 11
Training loss: 1.7101335525512695
Validation loss: 2.0581137288001274

Epoch: 6| Step: 12
Training loss: 2.465069532394409
Validation loss: 2.0584353016268824

Epoch: 6| Step: 13
Training loss: 2.1204476356506348
Validation loss: 2.067336105531262

Epoch: 89| Step: 0
Training loss: 2.2595365047454834
Validation loss: 2.060103629225044

Epoch: 6| Step: 1
Training loss: 2.634474277496338
Validation loss: 2.0537306339510026

Epoch: 6| Step: 2
Training loss: 2.398707866668701
Validation loss: 2.062819691114528

Epoch: 6| Step: 3
Training loss: 2.336846351623535
Validation loss: 2.084598623296266

Epoch: 6| Step: 4
Training loss: 2.089970588684082
Validation loss: 2.0971159114632556

Epoch: 6| Step: 5
Training loss: 2.845038414001465
Validation loss: 2.119283245455834

Epoch: 6| Step: 6
Training loss: 2.476348638534546
Validation loss: 2.1443741501018567

Epoch: 6| Step: 7
Training loss: 2.9247567653656006
Validation loss: 2.142524775638375

Epoch: 6| Step: 8
Training loss: 2.8440213203430176
Validation loss: 2.129392123991443

Epoch: 6| Step: 9
Training loss: 1.819129467010498
Validation loss: 2.080352396093389

Epoch: 6| Step: 10
Training loss: 1.9796018600463867
Validation loss: 2.0583876794384373

Epoch: 6| Step: 11
Training loss: 1.757369041442871
Validation loss: 2.050972188672712

Epoch: 6| Step: 12
Training loss: 2.152639389038086
Validation loss: 2.0527517718653523

Epoch: 6| Step: 13
Training loss: 2.7198092937469482
Validation loss: 2.045390481589943

Epoch: 90| Step: 0
Training loss: 2.5864648818969727
Validation loss: 2.047139826641288

Epoch: 6| Step: 1
Training loss: 3.5039308071136475
Validation loss: 2.0434256933068715

Epoch: 6| Step: 2
Training loss: 2.9788365364074707
Validation loss: 2.049663095064061

Epoch: 6| Step: 3
Training loss: 1.89851713180542
Validation loss: 2.051390201814713

Epoch: 6| Step: 4
Training loss: 2.5061373710632324
Validation loss: 2.0480455865142164

Epoch: 6| Step: 5
Training loss: 2.2181789875030518
Validation loss: 2.052072182778389

Epoch: 6| Step: 6
Training loss: 2.1688613891601562
Validation loss: 2.0446068330477645

Epoch: 6| Step: 7
Training loss: 2.513625144958496
Validation loss: 2.0463056589967463

Epoch: 6| Step: 8
Training loss: 2.098849296569824
Validation loss: 2.054401756614767

Epoch: 6| Step: 9
Training loss: 2.3552346229553223
Validation loss: 2.057076879726943

Epoch: 6| Step: 10
Training loss: 2.5061402320861816
Validation loss: 2.076704776415261

Epoch: 6| Step: 11
Training loss: 2.362920045852661
Validation loss: 2.095204842987881

Epoch: 6| Step: 12
Training loss: 1.0472259521484375
Validation loss: 2.124098777770996

Epoch: 6| Step: 13
Training loss: 2.470668315887451
Validation loss: 2.1500808910657

Epoch: 91| Step: 0
Training loss: 2.2675182819366455
Validation loss: 2.143372384450769

Epoch: 6| Step: 1
Training loss: 1.9645514488220215
Validation loss: 2.1197548797053676

Epoch: 6| Step: 2
Training loss: 2.230886459350586
Validation loss: 2.1368203483602053

Epoch: 6| Step: 3
Training loss: 2.6185359954833984
Validation loss: 2.1520565555941675

Epoch: 6| Step: 4
Training loss: 2.5313148498535156
Validation loss: 2.1331370851045013

Epoch: 6| Step: 5
Training loss: 1.7365221977233887
Validation loss: 2.1055246604386197

Epoch: 6| Step: 6
Training loss: 2.8474206924438477
Validation loss: 2.0699740661087858

Epoch: 6| Step: 7
Training loss: 2.649930953979492
Validation loss: 2.0597848417938396

Epoch: 6| Step: 8
Training loss: 1.4743990898132324
Validation loss: 2.050310698888635

Epoch: 6| Step: 9
Training loss: 2.6031107902526855
Validation loss: 2.0510944525400796

Epoch: 6| Step: 10
Training loss: 2.3001279830932617
Validation loss: 2.049779385648748

Epoch: 6| Step: 11
Training loss: 3.011054754257202
Validation loss: 2.049191017304697

Epoch: 6| Step: 12
Training loss: 2.418687582015991
Validation loss: 2.0457118608618297

Epoch: 6| Step: 13
Training loss: 2.666180372238159
Validation loss: 2.047371087535735

Epoch: 92| Step: 0
Training loss: 2.0016558170318604
Validation loss: 2.0501546795650194

Epoch: 6| Step: 1
Training loss: 2.9863321781158447
Validation loss: 2.0374806209277083

Epoch: 6| Step: 2
Training loss: 3.3033080101013184
Validation loss: 2.0387042978758454

Epoch: 6| Step: 3
Training loss: 1.9277820587158203
Validation loss: 2.0492013167309504

Epoch: 6| Step: 4
Training loss: 2.2356302738189697
Validation loss: 2.043972408899697

Epoch: 6| Step: 5
Training loss: 2.9964652061462402
Validation loss: 2.060912242499731

Epoch: 6| Step: 6
Training loss: 1.7854164838790894
Validation loss: 2.070295573562704

Epoch: 6| Step: 7
Training loss: 2.547305107116699
Validation loss: 2.0754402337535733

Epoch: 6| Step: 8
Training loss: 2.1967294216156006
Validation loss: 2.1088511123452136

Epoch: 6| Step: 9
Training loss: 2.44545578956604
Validation loss: 2.1185283917252735

Epoch: 6| Step: 10
Training loss: 3.0824925899505615
Validation loss: 2.1122757363063034

Epoch: 6| Step: 11
Training loss: 1.849833607673645
Validation loss: 2.106934881979419

Epoch: 6| Step: 12
Training loss: 2.0901927947998047
Validation loss: 2.1040455602830455

Epoch: 6| Step: 13
Training loss: 1.43352210521698
Validation loss: 2.0691153695506435

Epoch: 93| Step: 0
Training loss: 2.3913965225219727
Validation loss: 2.0430071264184932

Epoch: 6| Step: 1
Training loss: 2.031477689743042
Validation loss: 2.0410697793447845

Epoch: 6| Step: 2
Training loss: 2.180239200592041
Validation loss: 2.031622520057104

Epoch: 6| Step: 3
Training loss: 2.7139720916748047
Validation loss: 2.023857924246019

Epoch: 6| Step: 4
Training loss: 2.7781901359558105
Validation loss: 2.0326569567444506

Epoch: 6| Step: 5
Training loss: 2.262293815612793
Validation loss: 2.034815688287058

Epoch: 6| Step: 6
Training loss: 2.6354668140411377
Validation loss: 2.034964862690177

Epoch: 6| Step: 7
Training loss: 2.297722339630127
Validation loss: 2.0392808004092147

Epoch: 6| Step: 8
Training loss: 2.094674587249756
Validation loss: 2.034391244252523

Epoch: 6| Step: 9
Training loss: 1.999107003211975
Validation loss: 2.042786649478379

Epoch: 6| Step: 10
Training loss: 2.4705352783203125
Validation loss: 2.025036214500345

Epoch: 6| Step: 11
Training loss: 1.929521918296814
Validation loss: 2.0231200007982153

Epoch: 6| Step: 12
Training loss: 2.6990303993225098
Validation loss: 2.0347644564925984

Epoch: 6| Step: 13
Training loss: 2.9110898971557617
Validation loss: 2.0226281535240913

Epoch: 94| Step: 0
Training loss: 2.205137252807617
Validation loss: 2.0367760119899625

Epoch: 6| Step: 1
Training loss: 2.2029337882995605
Validation loss: 2.0215654219350507

Epoch: 6| Step: 2
Training loss: 2.582106590270996
Validation loss: 2.0222543003738567

Epoch: 6| Step: 3
Training loss: 2.5880794525146484
Validation loss: 2.0321222594989243

Epoch: 6| Step: 4
Training loss: 2.7803115844726562
Validation loss: 2.042727179424737

Epoch: 6| Step: 5
Training loss: 1.9685945510864258
Validation loss: 2.051917153020059

Epoch: 6| Step: 6
Training loss: 2.8327980041503906
Validation loss: 2.0404144051254436

Epoch: 6| Step: 7
Training loss: 2.488537311553955
Validation loss: 2.054930761296262

Epoch: 6| Step: 8
Training loss: 1.3227862119674683
Validation loss: 2.060421753955144

Epoch: 6| Step: 9
Training loss: 2.3556652069091797
Validation loss: 2.0516182889220533

Epoch: 6| Step: 10
Training loss: 2.4976749420166016
Validation loss: 2.046216731430382

Epoch: 6| Step: 11
Training loss: 2.5124621391296387
Validation loss: 2.036066839771886

Epoch: 6| Step: 12
Training loss: 1.9537596702575684
Validation loss: 2.0311112429506037

Epoch: 6| Step: 13
Training loss: 2.4706525802612305
Validation loss: 2.0353533324374946

Epoch: 95| Step: 0
Training loss: 2.3690011501312256
Validation loss: 2.0380859631364063

Epoch: 6| Step: 1
Training loss: 3.1380112171173096
Validation loss: 2.0640216078809512

Epoch: 6| Step: 2
Training loss: 2.6284923553466797
Validation loss: 2.0725057535274054

Epoch: 6| Step: 3
Training loss: 1.8520114421844482
Validation loss: 2.0891164092607397

Epoch: 6| Step: 4
Training loss: 1.8447585105895996
Validation loss: 2.090835476434359

Epoch: 6| Step: 5
Training loss: 1.5253031253814697
Validation loss: 2.106403395693789

Epoch: 6| Step: 6
Training loss: 2.105494976043701
Validation loss: 2.0540584287335797

Epoch: 6| Step: 7
Training loss: 2.68708872795105
Validation loss: 2.037560616770098

Epoch: 6| Step: 8
Training loss: 2.176056385040283
Validation loss: 2.026638302751767

Epoch: 6| Step: 9
Training loss: 2.3987419605255127
Validation loss: 2.0257837618550947

Epoch: 6| Step: 10
Training loss: 2.908949851989746
Validation loss: 2.014094777004693

Epoch: 6| Step: 11
Training loss: 2.4894156455993652
Validation loss: 2.0129271835409184

Epoch: 6| Step: 12
Training loss: 1.9472929239273071
Validation loss: 2.0171642534194456

Epoch: 6| Step: 13
Training loss: 2.956312417984009
Validation loss: 2.0129016522438294

Epoch: 96| Step: 0
Training loss: 2.5184895992279053
Validation loss: 2.0026282136158278

Epoch: 6| Step: 1
Training loss: 2.1477279663085938
Validation loss: 2.0045634418405514

Epoch: 6| Step: 2
Training loss: 2.2057900428771973
Validation loss: 2.0039603569174327

Epoch: 6| Step: 3
Training loss: 2.283750057220459
Validation loss: 2.0075974028597594

Epoch: 6| Step: 4
Training loss: 2.753692626953125
Validation loss: 1.9999356321109238

Epoch: 6| Step: 5
Training loss: 2.33614182472229
Validation loss: 2.0082923391813874

Epoch: 6| Step: 6
Training loss: 2.8382325172424316
Validation loss: 2.004083838514102

Epoch: 6| Step: 7
Training loss: 2.406977415084839
Validation loss: 2.0127451266011884

Epoch: 6| Step: 8
Training loss: 1.9355320930480957
Validation loss: 2.0307375538733696

Epoch: 6| Step: 9
Training loss: 2.669342041015625
Validation loss: 2.0535851165812504

Epoch: 6| Step: 10
Training loss: 1.6220155954360962
Validation loss: 2.0556839832695584

Epoch: 6| Step: 11
Training loss: 2.696946382522583
Validation loss: 2.060148375008696

Epoch: 6| Step: 12
Training loss: 2.0261950492858887
Validation loss: 2.0320106706311627

Epoch: 6| Step: 13
Training loss: 2.116705894470215
Validation loss: 2.037911912446381

Epoch: 97| Step: 0
Training loss: 1.6629633903503418
Validation loss: 2.009440622022075

Epoch: 6| Step: 1
Training loss: 2.47125244140625
Validation loss: 1.9923763146964453

Epoch: 6| Step: 2
Training loss: 2.611079454421997
Validation loss: 1.9928976771652058

Epoch: 6| Step: 3
Training loss: 2.1397998332977295
Validation loss: 1.9894665979569959

Epoch: 6| Step: 4
Training loss: 2.0809736251831055
Validation loss: 1.9921858041517195

Epoch: 6| Step: 5
Training loss: 1.7769849300384521
Validation loss: 1.9962731894626413

Epoch: 6| Step: 6
Training loss: 2.302335262298584
Validation loss: 2.012041691810854

Epoch: 6| Step: 7
Training loss: 2.2327396869659424
Validation loss: 2.022482249044603

Epoch: 6| Step: 8
Training loss: 2.4575304985046387
Validation loss: 2.0268570082162016

Epoch: 6| Step: 9
Training loss: 3.147071599960327
Validation loss: 2.0323908880192745

Epoch: 6| Step: 10
Training loss: 1.7972474098205566
Validation loss: 2.0214252189923356

Epoch: 6| Step: 11
Training loss: 3.0059432983398438
Validation loss: 2.017996629079183

Epoch: 6| Step: 12
Training loss: 2.210045337677002
Validation loss: 2.012742961606672

Epoch: 6| Step: 13
Training loss: 2.5796151161193848
Validation loss: 2.0041983448049074

Epoch: 98| Step: 0
Training loss: 2.3375961780548096
Validation loss: 2.004003826008048

Epoch: 6| Step: 1
Training loss: 2.208862781524658
Validation loss: 1.9941621429176741

Epoch: 6| Step: 2
Training loss: 2.5968432426452637
Validation loss: 1.98504348211391

Epoch: 6| Step: 3
Training loss: 2.406667947769165
Validation loss: 1.9843245757523404

Epoch: 6| Step: 4
Training loss: 1.6524803638458252
Validation loss: 1.9839550705366238

Epoch: 6| Step: 5
Training loss: 2.9215545654296875
Validation loss: 1.9883428440299085

Epoch: 6| Step: 6
Training loss: 2.313702344894409
Validation loss: 1.989928066089589

Epoch: 6| Step: 7
Training loss: 2.6300125122070312
Validation loss: 1.998167722455917

Epoch: 6| Step: 8
Training loss: 2.1577320098876953
Validation loss: 2.004086367545589

Epoch: 6| Step: 9
Training loss: 1.7353447675704956
Validation loss: 2.014110795913204

Epoch: 6| Step: 10
Training loss: 2.392590045928955
Validation loss: 2.0405468504915953

Epoch: 6| Step: 11
Training loss: 2.711045265197754
Validation loss: 2.070027255242871

Epoch: 6| Step: 12
Training loss: 2.051316738128662
Validation loss: 2.0802990492954048

Epoch: 6| Step: 13
Training loss: 2.3369271755218506
Validation loss: 2.0755549053991995

Epoch: 99| Step: 0
Training loss: 2.6419079303741455
Validation loss: 2.0459921667652745

Epoch: 6| Step: 1
Training loss: 2.1386494636535645
Validation loss: 2.057471259947746

Epoch: 6| Step: 2
Training loss: 2.4596681594848633
Validation loss: 2.0525805155436196

Epoch: 6| Step: 3
Training loss: 2.0339441299438477
Validation loss: 2.0345217412517917

Epoch: 6| Step: 4
Training loss: 2.9300107955932617
Validation loss: 2.0385231574376426

Epoch: 6| Step: 5
Training loss: 2.174743175506592
Validation loss: 2.02961980142901

Epoch: 6| Step: 6
Training loss: 1.8346881866455078
Validation loss: 2.042213821923861

Epoch: 6| Step: 7
Training loss: 2.554107189178467
Validation loss: 2.0599200738373624

Epoch: 6| Step: 8
Training loss: 2.589585542678833
Validation loss: 2.1045925924854894

Epoch: 6| Step: 9
Training loss: 2.6226539611816406
Validation loss: 2.1069044272104898

Epoch: 6| Step: 10
Training loss: 2.2818994522094727
Validation loss: 2.0846570948118806

Epoch: 6| Step: 11
Training loss: 2.4585955142974854
Validation loss: 2.0277417500813804

Epoch: 6| Step: 12
Training loss: 1.9974509477615356
Validation loss: 2.0111863818219913

Epoch: 6| Step: 13
Training loss: 1.3878965377807617
Validation loss: 2.003299387552405

Epoch: 100| Step: 0
Training loss: 2.5287742614746094
Validation loss: 2.004907518304804

Epoch: 6| Step: 1
Training loss: 1.952711582183838
Validation loss: 1.9894204139709473

Epoch: 6| Step: 2
Training loss: 2.578341007232666
Validation loss: 1.9802378134060932

Epoch: 6| Step: 3
Training loss: 2.5933003425598145
Validation loss: 1.9757558094557894

Epoch: 6| Step: 4
Training loss: 1.9345639944076538
Validation loss: 1.9749796416169854

Epoch: 6| Step: 5
Training loss: 1.842909812927246
Validation loss: 1.9838652444142166

Epoch: 6| Step: 6
Training loss: 2.2881243228912354
Validation loss: 1.9943295653148363

Epoch: 6| Step: 7
Training loss: 2.398254156112671
Validation loss: 2.0233968380958802

Epoch: 6| Step: 8
Training loss: 2.248028039932251
Validation loss: 2.036457279677032

Epoch: 6| Step: 9
Training loss: 2.114138126373291
Validation loss: 2.0384439012055755

Epoch: 6| Step: 10
Training loss: 2.568039655685425
Validation loss: 2.0052552941024944

Epoch: 6| Step: 11
Training loss: 2.251943826675415
Validation loss: 1.994922645630375

Epoch: 6| Step: 12
Training loss: 2.856729745864868
Validation loss: 1.9879027540965746

Epoch: 6| Step: 13
Training loss: 2.13248872756958
Validation loss: 1.9956000645955403

Epoch: 101| Step: 0
Training loss: 1.9684005975723267
Validation loss: 1.992201018077071

Epoch: 6| Step: 1
Training loss: 2.3176941871643066
Validation loss: 1.981406009325417

Epoch: 6| Step: 2
Training loss: 2.3187096118927
Validation loss: 1.9892178620061567

Epoch: 6| Step: 3
Training loss: 1.1552081108093262
Validation loss: 2.0114506162622923

Epoch: 6| Step: 4
Training loss: 2.2071549892425537
Validation loss: 2.0324070966371925

Epoch: 6| Step: 5
Training loss: 2.368846893310547
Validation loss: 2.0374278458215858

Epoch: 6| Step: 6
Training loss: 2.238166570663452
Validation loss: 2.028456949418591

Epoch: 6| Step: 7
Training loss: 2.9368886947631836
Validation loss: 2.026041888421582

Epoch: 6| Step: 8
Training loss: 2.247819423675537
Validation loss: 1.989654185951397

Epoch: 6| Step: 9
Training loss: 1.9071145057678223
Validation loss: 1.981173921656865

Epoch: 6| Step: 10
Training loss: 2.7621190547943115
Validation loss: 1.9794938718118975

Epoch: 6| Step: 11
Training loss: 2.527914047241211
Validation loss: 1.965950696699081

Epoch: 6| Step: 12
Training loss: 2.3424072265625
Validation loss: 1.9630258903708508

Epoch: 6| Step: 13
Training loss: 2.6250789165496826
Validation loss: 1.9718120713387766

Epoch: 102| Step: 0
Training loss: 2.1860342025756836
Validation loss: 1.9808545497155958

Epoch: 6| Step: 1
Training loss: 1.861313819885254
Validation loss: 1.987269345150199

Epoch: 6| Step: 2
Training loss: 2.5482451915740967
Validation loss: 1.9920054763875983

Epoch: 6| Step: 3
Training loss: 1.7756798267364502
Validation loss: 2.013086598406556

Epoch: 6| Step: 4
Training loss: 2.476935386657715
Validation loss: 2.0444910769821494

Epoch: 6| Step: 5
Training loss: 2.7119839191436768
Validation loss: 2.0383584358358897

Epoch: 6| Step: 6
Training loss: 2.8023948669433594
Validation loss: 2.0229858736838064

Epoch: 6| Step: 7
Training loss: 1.6915327310562134
Validation loss: 1.9992226682683474

Epoch: 6| Step: 8
Training loss: 2.2574596405029297
Validation loss: 1.9640066418596493

Epoch: 6| Step: 9
Training loss: 2.4450764656066895
Validation loss: 1.959902371129682

Epoch: 6| Step: 10
Training loss: 1.7133487462997437
Validation loss: 1.9637144637364212

Epoch: 6| Step: 11
Training loss: 1.751167893409729
Validation loss: 2.001122648997973

Epoch: 6| Step: 12
Training loss: 3.0238776206970215
Validation loss: 2.0109684787770754

Epoch: 6| Step: 13
Training loss: 2.6960911750793457
Validation loss: 1.995241149779289

Epoch: 103| Step: 0
Training loss: 1.8417659997940063
Validation loss: 1.9805359712211035

Epoch: 6| Step: 1
Training loss: 2.351222515106201
Validation loss: 1.9698685266638314

Epoch: 6| Step: 2
Training loss: 2.538787603378296
Validation loss: 1.9663974174889185

Epoch: 6| Step: 3
Training loss: 2.48496150970459
Validation loss: 1.958478432829662

Epoch: 6| Step: 4
Training loss: 2.4356021881103516
Validation loss: 1.9544881377168881

Epoch: 6| Step: 5
Training loss: 2.3359732627868652
Validation loss: 1.9565535130039338

Epoch: 6| Step: 6
Training loss: 2.3612422943115234
Validation loss: 1.9608891958831458

Epoch: 6| Step: 7
Training loss: 2.31355619430542
Validation loss: 1.9677799670926985

Epoch: 6| Step: 8
Training loss: 1.6785809993743896
Validation loss: 1.990589080318328

Epoch: 6| Step: 9
Training loss: 2.399866819381714
Validation loss: 2.0341397613607426

Epoch: 6| Step: 10
Training loss: 2.1963272094726562
Validation loss: 2.0564496747909056

Epoch: 6| Step: 11
Training loss: 2.142618179321289
Validation loss: 2.06513822719615

Epoch: 6| Step: 12
Training loss: 2.2729530334472656
Validation loss: 2.0378793977922007

Epoch: 6| Step: 13
Training loss: 2.585268259048462
Validation loss: 1.9787827742997037

Epoch: 104| Step: 0
Training loss: 1.5667567253112793
Validation loss: 1.9445781400126796

Epoch: 6| Step: 1
Training loss: 2.051222324371338
Validation loss: 1.9455753193106702

Epoch: 6| Step: 2
Training loss: 2.065880537033081
Validation loss: 1.9437081480538974

Epoch: 6| Step: 3
Training loss: 2.387024164199829
Validation loss: 1.945774870534097

Epoch: 6| Step: 4
Training loss: 2.3706085681915283
Validation loss: 1.948279934544717

Epoch: 6| Step: 5
Training loss: 2.3007750511169434
Validation loss: 1.9626708556247014

Epoch: 6| Step: 6
Training loss: 2.223708391189575
Validation loss: 1.9707875379952051

Epoch: 6| Step: 7
Training loss: 1.938291311264038
Validation loss: 1.9862262459211453

Epoch: 6| Step: 8
Training loss: 2.7650980949401855
Validation loss: 2.0148263695419475

Epoch: 6| Step: 9
Training loss: 2.536219596862793
Validation loss: 2.052660160167243

Epoch: 6| Step: 10
Training loss: 1.793758749961853
Validation loss: 2.074961504628581

Epoch: 6| Step: 11
Training loss: 2.9726834297180176
Validation loss: 2.0821479494853685

Epoch: 6| Step: 12
Training loss: 2.215872287750244
Validation loss: 2.0530374665414133

Epoch: 6| Step: 13
Training loss: 3.656398296356201
Validation loss: 2.0741445223490396

Epoch: 105| Step: 0
Training loss: 2.4085328578948975
Validation loss: 2.0586407287146455

Epoch: 6| Step: 1
Training loss: 2.366506576538086
Validation loss: 2.048168423355267

Epoch: 6| Step: 2
Training loss: 2.5731093883514404
Validation loss: 2.048239520801011

Epoch: 6| Step: 3
Training loss: 2.5619914531707764
Validation loss: 2.044897538359447

Epoch: 6| Step: 4
Training loss: 2.1283297538757324
Validation loss: 2.024660671910932

Epoch: 6| Step: 5
Training loss: 1.9144995212554932
Validation loss: 1.9983935163867088

Epoch: 6| Step: 6
Training loss: 2.46386456489563
Validation loss: 1.9851579025227537

Epoch: 6| Step: 7
Training loss: 2.8788087368011475
Validation loss: 1.9965089995373961

Epoch: 6| Step: 8
Training loss: 2.115272283554077
Validation loss: 2.011614981517997

Epoch: 6| Step: 9
Training loss: 2.49822735786438
Validation loss: 2.0558669656835575

Epoch: 6| Step: 10
Training loss: 2.2598037719726562
Validation loss: 2.0853649339368268

Epoch: 6| Step: 11
Training loss: 2.0923233032226562
Validation loss: 2.1185340624983593

Epoch: 6| Step: 12
Training loss: 1.6555376052856445
Validation loss: 2.1102899095063568

Epoch: 6| Step: 13
Training loss: 1.4798622131347656
Validation loss: 2.035795873211276

Epoch: 106| Step: 0
Training loss: 1.8191152811050415
Validation loss: 1.9976855836888796

Epoch: 6| Step: 1
Training loss: 1.889147162437439
Validation loss: 1.982651800237676

Epoch: 6| Step: 2
Training loss: 2.676222801208496
Validation loss: 1.9910650817296838

Epoch: 6| Step: 3
Training loss: 2.320544958114624
Validation loss: 2.0076343910668486

Epoch: 6| Step: 4
Training loss: 1.831212043762207
Validation loss: 2.0341201546371623

Epoch: 6| Step: 5
Training loss: 2.345963478088379
Validation loss: 2.074865807769119

Epoch: 6| Step: 6
Training loss: 2.0991086959838867
Validation loss: 2.104748679745582

Epoch: 6| Step: 7
Training loss: 2.4429008960723877
Validation loss: 2.0948375566031343

Epoch: 6| Step: 8
Training loss: 2.753051996231079
Validation loss: 2.0779054369977725

Epoch: 6| Step: 9
Training loss: 1.6038429737091064
Validation loss: 2.0634865222438687

Epoch: 6| Step: 10
Training loss: 2.3774867057800293
Validation loss: 2.033793108437651

Epoch: 6| Step: 11
Training loss: 2.628274917602539
Validation loss: 2.0126134592999696

Epoch: 6| Step: 12
Training loss: 2.0106358528137207
Validation loss: 1.9900129751492572

Epoch: 6| Step: 13
Training loss: 2.780689001083374
Validation loss: 1.9783031286731843

Epoch: 107| Step: 0
Training loss: 1.9552329778671265
Validation loss: 1.9692895284263037

Epoch: 6| Step: 1
Training loss: 2.91791033744812
Validation loss: 1.9598005151235929

Epoch: 6| Step: 2
Training loss: 1.4826734066009521
Validation loss: 1.97368069617979

Epoch: 6| Step: 3
Training loss: 2.187715530395508
Validation loss: 2.0029145620202504

Epoch: 6| Step: 4
Training loss: 2.653012275695801
Validation loss: 2.0816432327352543

Epoch: 6| Step: 5
Training loss: 2.5320143699645996
Validation loss: 2.218476803072037

Epoch: 6| Step: 6
Training loss: 2.159454822540283
Validation loss: 2.160760344997529

Epoch: 6| Step: 7
Training loss: 1.8437838554382324
Validation loss: 2.049927757632348

Epoch: 6| Step: 8
Training loss: 2.074982166290283
Validation loss: 1.9823536142226188

Epoch: 6| Step: 9
Training loss: 2.4350168704986572
Validation loss: 1.943737119756719

Epoch: 6| Step: 10
Training loss: 2.6300292015075684
Validation loss: 1.9488997690139278

Epoch: 6| Step: 11
Training loss: 2.1601390838623047
Validation loss: 1.962226310083943

Epoch: 6| Step: 12
Training loss: 2.2903871536254883
Validation loss: 1.9917031847020632

Epoch: 6| Step: 13
Training loss: 2.4787347316741943
Validation loss: 2.014413841309086

Epoch: 108| Step: 0
Training loss: 1.5496907234191895
Validation loss: 2.0331721203301543

Epoch: 6| Step: 1
Training loss: 2.3753769397735596
Validation loss: 2.059362070534819

Epoch: 6| Step: 2
Training loss: 3.2024898529052734
Validation loss: 2.0545879474250217

Epoch: 6| Step: 3
Training loss: 1.576279878616333
Validation loss: 2.0353527428001486

Epoch: 6| Step: 4
Training loss: 1.9275208711624146
Validation loss: 2.018917099122078

Epoch: 6| Step: 5
Training loss: 2.748513698577881
Validation loss: 2.000890894602704

Epoch: 6| Step: 6
Training loss: 2.5233702659606934
Validation loss: 2.0052091921529462

Epoch: 6| Step: 7
Training loss: 2.487604856491089
Validation loss: 2.004216076225363

Epoch: 6| Step: 8
Training loss: 2.1196651458740234
Validation loss: 1.9984576509844871

Epoch: 6| Step: 9
Training loss: 1.8936312198638916
Validation loss: 1.9777602175230622

Epoch: 6| Step: 10
Training loss: 1.379483938217163
Validation loss: 1.9850467225556732

Epoch: 6| Step: 11
Training loss: 2.1362462043762207
Validation loss: 1.9877892027619064

Epoch: 6| Step: 12
Training loss: 2.8340485095977783
Validation loss: 1.9914886554082234

Epoch: 6| Step: 13
Training loss: 2.4940874576568604
Validation loss: 1.9958076246323124

Epoch: 109| Step: 0
Training loss: 1.7297097444534302
Validation loss: 2.022397751449257

Epoch: 6| Step: 1
Training loss: 1.9994008541107178
Validation loss: 2.0503856930681454

Epoch: 6| Step: 2
Training loss: 2.033081531524658
Validation loss: 2.0633581274299213

Epoch: 6| Step: 3
Training loss: 2.4014041423797607
Validation loss: 2.1188315396667807

Epoch: 6| Step: 4
Training loss: 2.114964485168457
Validation loss: 2.135488812641431

Epoch: 6| Step: 5
Training loss: 1.8091871738433838
Validation loss: 2.115720700192195

Epoch: 6| Step: 6
Training loss: 2.6542298793792725
Validation loss: 2.1236139164176038

Epoch: 6| Step: 7
Training loss: 2.3270745277404785
Validation loss: 2.0747858426904164

Epoch: 6| Step: 8
Training loss: 2.1552085876464844
Validation loss: 2.0220742430738223

Epoch: 6| Step: 9
Training loss: 2.3049516677856445
Validation loss: 1.997765605167676

Epoch: 6| Step: 10
Training loss: 2.2187700271606445
Validation loss: 1.9837397170323197

Epoch: 6| Step: 11
Training loss: 1.9677172899246216
Validation loss: 1.987258449677498

Epoch: 6| Step: 12
Training loss: 2.489419937133789
Validation loss: 1.9821683335047897

Epoch: 6| Step: 13
Training loss: 2.8719944953918457
Validation loss: 1.99811969008497

Epoch: 110| Step: 0
Training loss: 2.0073907375335693
Validation loss: 1.9746957491802912

Epoch: 6| Step: 1
Training loss: 2.0360047817230225
Validation loss: 1.9717860209044589

Epoch: 6| Step: 2
Training loss: 2.5034408569335938
Validation loss: 2.0176182485395864

Epoch: 6| Step: 3
Training loss: 2.289252281188965
Validation loss: 2.058605142818984

Epoch: 6| Step: 4
Training loss: 2.31602144241333
Validation loss: 2.0547453254781742

Epoch: 6| Step: 5
Training loss: 1.407646656036377
Validation loss: 2.0564127224747852

Epoch: 6| Step: 6
Training loss: 3.249891996383667
Validation loss: 2.0528681867866108

Epoch: 6| Step: 7
Training loss: 2.3765370845794678
Validation loss: 2.0268005312130017

Epoch: 6| Step: 8
Training loss: 2.0752739906311035
Validation loss: 2.0061814118457097

Epoch: 6| Step: 9
Training loss: 1.8430243730545044
Validation loss: 1.9549737976443382

Epoch: 6| Step: 10
Training loss: 2.1032164096832275
Validation loss: 1.936621791572981

Epoch: 6| Step: 11
Training loss: 2.301882266998291
Validation loss: 1.9360226277382142

Epoch: 6| Step: 12
Training loss: 1.976583480834961
Validation loss: 1.9438033129579277

Epoch: 6| Step: 13
Training loss: 3.0081260204315186
Validation loss: 1.9348755036630938

Epoch: 111| Step: 0
Training loss: 2.607726812362671
Validation loss: 1.941178321838379

Epoch: 6| Step: 1
Training loss: 2.5268447399139404
Validation loss: 1.9392091766480477

Epoch: 6| Step: 2
Training loss: 2.3207781314849854
Validation loss: 1.940027444593368

Epoch: 6| Step: 3
Training loss: 1.7874023914337158
Validation loss: 1.9480214259957755

Epoch: 6| Step: 4
Training loss: 1.9642739295959473
Validation loss: 1.955947970831266

Epoch: 6| Step: 5
Training loss: 1.6439753770828247
Validation loss: 1.9683156449307677

Epoch: 6| Step: 6
Training loss: 2.493680238723755
Validation loss: 1.9679497211210188

Epoch: 6| Step: 7
Training loss: 2.2322964668273926
Validation loss: 1.9977125185792164

Epoch: 6| Step: 8
Training loss: 2.1910839080810547
Validation loss: 2.0546009232920985

Epoch: 6| Step: 9
Training loss: 2.2033026218414307
Validation loss: 2.1193009730308288

Epoch: 6| Step: 10
Training loss: 1.8850719928741455
Validation loss: 2.167937894021311

Epoch: 6| Step: 11
Training loss: 2.602297067642212
Validation loss: 2.1878389876375914

Epoch: 6| Step: 12
Training loss: 1.963726282119751
Validation loss: 2.219943695170905

Epoch: 6| Step: 13
Training loss: 2.246553659439087
Validation loss: 2.1700343572965233

Epoch: 112| Step: 0
Training loss: 2.6004538536071777
Validation loss: 2.0878037688552693

Epoch: 6| Step: 1
Training loss: 1.6886138916015625
Validation loss: 2.046184362903718

Epoch: 6| Step: 2
Training loss: 2.293766975402832
Validation loss: 2.0073323019089235

Epoch: 6| Step: 3
Training loss: 2.050666093826294
Validation loss: 1.9638573226108347

Epoch: 6| Step: 4
Training loss: 2.1523289680480957
Validation loss: 1.9576126760052097

Epoch: 6| Step: 5
Training loss: 2.633028030395508
Validation loss: 1.9609663127571024

Epoch: 6| Step: 6
Training loss: 2.3072824478149414
Validation loss: 1.9579059539302703

Epoch: 6| Step: 7
Training loss: 2.4261486530303955
Validation loss: 1.974964919910636

Epoch: 6| Step: 8
Training loss: 1.7407232522964478
Validation loss: 1.9777666240610101

Epoch: 6| Step: 9
Training loss: 2.1603715419769287
Validation loss: 1.9844781878173992

Epoch: 6| Step: 10
Training loss: 1.572527289390564
Validation loss: 1.9987821373888242

Epoch: 6| Step: 11
Training loss: 2.859229803085327
Validation loss: 2.0207285368314354

Epoch: 6| Step: 12
Training loss: 2.247366428375244
Validation loss: 2.0496322262671685

Epoch: 6| Step: 13
Training loss: 1.4297850131988525
Validation loss: 2.0685617129007974

Epoch: 113| Step: 0
Training loss: 1.616307258605957
Validation loss: 2.087619061111122

Epoch: 6| Step: 1
Training loss: 2.371591091156006
Validation loss: 2.1033179554887997

Epoch: 6| Step: 2
Training loss: 2.7451701164245605
Validation loss: 2.149642216261997

Epoch: 6| Step: 3
Training loss: 1.9144476652145386
Validation loss: 2.1734137304367556

Epoch: 6| Step: 4
Training loss: 2.136162042617798
Validation loss: 2.1780347439550583

Epoch: 6| Step: 5
Training loss: 1.4567277431488037
Validation loss: 2.1695389773256037

Epoch: 6| Step: 6
Training loss: 1.9828194379806519
Validation loss: 2.124563842691401

Epoch: 6| Step: 7
Training loss: 2.563626766204834
Validation loss: 2.07894314489057

Epoch: 6| Step: 8
Training loss: 2.4282565116882324
Validation loss: 2.0525473984338904

Epoch: 6| Step: 9
Training loss: 2.1401915550231934
Validation loss: 2.059123549410092

Epoch: 6| Step: 10
Training loss: 1.947069525718689
Validation loss: 2.0702255848915345

Epoch: 6| Step: 11
Training loss: 2.5455050468444824
Validation loss: 2.053055391516737

Epoch: 6| Step: 12
Training loss: 2.4753689765930176
Validation loss: 2.0557233748897428

Epoch: 6| Step: 13
Training loss: 2.3056745529174805
Validation loss: 2.0348997141725276

Epoch: 114| Step: 0
Training loss: 2.976827383041382
Validation loss: 1.996193314111361

Epoch: 6| Step: 1
Training loss: 2.3179469108581543
Validation loss: 1.9868741586644163

Epoch: 6| Step: 2
Training loss: 1.665137767791748
Validation loss: 1.9879342202217347

Epoch: 6| Step: 3
Training loss: 1.7468799352645874
Validation loss: 1.9800142652244979

Epoch: 6| Step: 4
Training loss: 1.4766782522201538
Validation loss: 2.005934833198465

Epoch: 6| Step: 5
Training loss: 2.6396281719207764
Validation loss: 2.0230327011436544

Epoch: 6| Step: 6
Training loss: 1.6024914979934692
Validation loss: 2.065941543989284

Epoch: 6| Step: 7
Training loss: 1.979628324508667
Validation loss: 2.0655438053992485

Epoch: 6| Step: 8
Training loss: 2.5416646003723145
Validation loss: 2.0643326390174126

Epoch: 6| Step: 9
Training loss: 1.81016206741333
Validation loss: 2.051244557544749

Epoch: 6| Step: 10
Training loss: 1.8748745918273926
Validation loss: 2.0372301493921587

Epoch: 6| Step: 11
Training loss: 1.737480878829956
Validation loss: 1.9918229336379676

Epoch: 6| Step: 12
Training loss: 2.536520004272461
Validation loss: 1.9609581526889597

Epoch: 6| Step: 13
Training loss: 3.153322458267212
Validation loss: 1.9330755651638072

Epoch: 115| Step: 0
Training loss: 2.2278170585632324
Validation loss: 1.9247411656123337

Epoch: 6| Step: 1
Training loss: 2.3609800338745117
Validation loss: 1.932568839801255

Epoch: 6| Step: 2
Training loss: 2.2551560401916504
Validation loss: 1.9542639909252044

Epoch: 6| Step: 3
Training loss: 2.9253392219543457
Validation loss: 1.9629980505153697

Epoch: 6| Step: 4
Training loss: 2.0149359703063965
Validation loss: 1.9736141415052517

Epoch: 6| Step: 5
Training loss: 2.3703935146331787
Validation loss: 1.9740997681053736

Epoch: 6| Step: 6
Training loss: 1.7283560037612915
Validation loss: 1.9790568556836856

Epoch: 6| Step: 7
Training loss: 2.178189754486084
Validation loss: 1.9791713965836393

Epoch: 6| Step: 8
Training loss: 2.0628366470336914
Validation loss: 1.981329184706493

Epoch: 6| Step: 9
Training loss: 2.351215362548828
Validation loss: 1.9993858029765468

Epoch: 6| Step: 10
Training loss: 2.5461902618408203
Validation loss: 2.0102890204357844

Epoch: 6| Step: 11
Training loss: 1.8583686351776123
Validation loss: 2.023397937897713

Epoch: 6| Step: 12
Training loss: 1.5857386589050293
Validation loss: 2.0221859870418424

Epoch: 6| Step: 13
Training loss: 1.8664368391036987
Validation loss: 2.0183906491084764

Epoch: 116| Step: 0
Training loss: 1.9183590412139893
Validation loss: 2.02790726512991

Epoch: 6| Step: 1
Training loss: 2.1598730087280273
Validation loss: 2.0188634998054913

Epoch: 6| Step: 2
Training loss: 2.0852038860321045
Validation loss: 2.016994058444936

Epoch: 6| Step: 3
Training loss: 1.995131015777588
Validation loss: 2.0079071855032318

Epoch: 6| Step: 4
Training loss: 2.084798574447632
Validation loss: 1.991023330278294

Epoch: 6| Step: 5
Training loss: 2.356968879699707
Validation loss: 1.9922451050050798

Epoch: 6| Step: 6
Training loss: 2.1319522857666016
Validation loss: 1.991801033737839

Epoch: 6| Step: 7
Training loss: 2.1880619525909424
Validation loss: 1.9985456812766291

Epoch: 6| Step: 8
Training loss: 1.8481814861297607
Validation loss: 2.010586407876784

Epoch: 6| Step: 9
Training loss: 1.8701575994491577
Validation loss: 2.0188627653224493

Epoch: 6| Step: 10
Training loss: 2.228397846221924
Validation loss: 2.0362395394232964

Epoch: 6| Step: 11
Training loss: 1.8393127918243408
Validation loss: 2.064945051746984

Epoch: 6| Step: 12
Training loss: 2.041095495223999
Validation loss: 2.075017508640084

Epoch: 6| Step: 13
Training loss: 2.8169167041778564
Validation loss: 2.082180970458574

Epoch: 117| Step: 0
Training loss: 2.077979564666748
Validation loss: 2.12896462409727

Epoch: 6| Step: 1
Training loss: 1.9162449836730957
Validation loss: 2.1630233359593216

Epoch: 6| Step: 2
Training loss: 1.3867089748382568
Validation loss: 2.1664869528944775

Epoch: 6| Step: 3
Training loss: 2.006141185760498
Validation loss: 2.1153083847415064

Epoch: 6| Step: 4
Training loss: 2.209033250808716
Validation loss: 2.0484173400427705

Epoch: 6| Step: 5
Training loss: 2.0938057899475098
Validation loss: 1.995776666107998

Epoch: 6| Step: 6
Training loss: 1.609928846359253
Validation loss: 1.9832895648094915

Epoch: 6| Step: 7
Training loss: 2.0413358211517334
Validation loss: 1.9943271977927095

Epoch: 6| Step: 8
Training loss: 2.7644150257110596
Validation loss: 2.0067096371804514

Epoch: 6| Step: 9
Training loss: 2.109727144241333
Validation loss: 1.992735993477606

Epoch: 6| Step: 10
Training loss: 2.482659101486206
Validation loss: 1.9722661946409492

Epoch: 6| Step: 11
Training loss: 2.017130136489868
Validation loss: 1.9788959897974485

Epoch: 6| Step: 12
Training loss: 3.042149066925049
Validation loss: 1.9798434652307981

Epoch: 6| Step: 13
Training loss: 1.9359196424484253
Validation loss: 1.9812998399939588

Epoch: 118| Step: 0
Training loss: 1.6387507915496826
Validation loss: 1.9914795019293343

Epoch: 6| Step: 1
Training loss: 1.9740946292877197
Validation loss: 1.9959338506062825

Epoch: 6| Step: 2
Training loss: 2.016860246658325
Validation loss: 1.9979101022084553

Epoch: 6| Step: 3
Training loss: 1.7289735078811646
Validation loss: 2.011310628665391

Epoch: 6| Step: 4
Training loss: 2.175415277481079
Validation loss: 1.9987597093787244

Epoch: 6| Step: 5
Training loss: 1.763599157333374
Validation loss: 1.9981184133919336

Epoch: 6| Step: 6
Training loss: 2.2447619438171387
Validation loss: 2.004257586694533

Epoch: 6| Step: 7
Training loss: 1.9425089359283447
Validation loss: 2.0010159374565206

Epoch: 6| Step: 8
Training loss: 3.005385637283325
Validation loss: 1.9964135039237239

Epoch: 6| Step: 9
Training loss: 2.239485502243042
Validation loss: 1.979034827601525

Epoch: 6| Step: 10
Training loss: 1.1619887351989746
Validation loss: 1.9853114081967262

Epoch: 6| Step: 11
Training loss: 1.9786272048950195
Validation loss: 1.975759203715991

Epoch: 6| Step: 12
Training loss: 2.9147233963012695
Validation loss: 1.9817925268603909

Epoch: 6| Step: 13
Training loss: 1.874899983406067
Validation loss: 1.9958593742821806

Epoch: 119| Step: 0
Training loss: 2.0324087142944336
Validation loss: 1.993757963180542

Epoch: 6| Step: 1
Training loss: 2.326582908630371
Validation loss: 1.9958465663335656

Epoch: 6| Step: 2
Training loss: 2.00765061378479
Validation loss: 2.02889359125527

Epoch: 6| Step: 3
Training loss: 2.525063991546631
Validation loss: 2.037119152725384

Epoch: 6| Step: 4
Training loss: 2.4002771377563477
Validation loss: 2.04713225236503

Epoch: 6| Step: 5
Training loss: 2.013061761856079
Validation loss: 2.0691360927397207

Epoch: 6| Step: 6
Training loss: 1.3918483257293701
Validation loss: 2.089331196200463

Epoch: 6| Step: 7
Training loss: 1.313093662261963
Validation loss: 2.1131145056857856

Epoch: 6| Step: 8
Training loss: 2.7474794387817383
Validation loss: 2.1181196653714744

Epoch: 6| Step: 9
Training loss: 2.0102176666259766
Validation loss: 2.1241834035483738

Epoch: 6| Step: 10
Training loss: 2.2556910514831543
Validation loss: 2.1165989086192143

Epoch: 6| Step: 11
Training loss: 1.9616838693618774
Validation loss: 2.0973268913966354

Epoch: 6| Step: 12
Training loss: 2.0326900482177734
Validation loss: 2.0492466470246673

Epoch: 6| Step: 13
Training loss: 1.6725512742996216
Validation loss: 2.0190025529553814

Epoch: 120| Step: 0
Training loss: 2.0757815837860107
Validation loss: 2.008599473584083

Epoch: 6| Step: 1
Training loss: 2.5815601348876953
Validation loss: 2.0182342298569216

Epoch: 6| Step: 2
Training loss: 2.5384974479675293
Validation loss: 2.0178855157667592

Epoch: 6| Step: 3
Training loss: 1.6469166278839111
Validation loss: 2.0188650854172243

Epoch: 6| Step: 4
Training loss: 1.7588074207305908
Validation loss: 2.0055150780626523

Epoch: 6| Step: 5
Training loss: 1.717233657836914
Validation loss: 2.026666861708446

Epoch: 6| Step: 6
Training loss: 2.1691246032714844
Validation loss: 2.020063046486147

Epoch: 6| Step: 7
Training loss: 1.6142735481262207
Validation loss: 2.0275874253242248

Epoch: 6| Step: 8
Training loss: 1.6851563453674316
Validation loss: 2.028353932083294

Epoch: 6| Step: 9
Training loss: 2.6774230003356934
Validation loss: 2.051768897682108

Epoch: 6| Step: 10
Training loss: 2.0185842514038086
Validation loss: 2.060855229695638

Epoch: 6| Step: 11
Training loss: 1.7711204290390015
Validation loss: 2.0453973047194944

Epoch: 6| Step: 12
Training loss: 1.3140922784805298
Validation loss: 2.011515248206354

Epoch: 6| Step: 13
Training loss: 2.964923143386841
Validation loss: 2.002011514479114

Epoch: 121| Step: 0
Training loss: 2.567314624786377
Validation loss: 2.0164102136447863

Epoch: 6| Step: 1
Training loss: 1.876326084136963
Validation loss: 1.9983006856774772

Epoch: 6| Step: 2
Training loss: 2.1630501747131348
Validation loss: 1.976218549154138

Epoch: 6| Step: 3
Training loss: 2.3907783031463623
Validation loss: 1.9624813410543627

Epoch: 6| Step: 4
Training loss: 1.6986358165740967
Validation loss: 1.9701862155750234

Epoch: 6| Step: 5
Training loss: 2.901952028274536
Validation loss: 1.9773449192764938

Epoch: 6| Step: 6
Training loss: 1.628807783126831
Validation loss: 1.9905250995389876

Epoch: 6| Step: 7
Training loss: 1.6102724075317383
Validation loss: 2.027661656820646

Epoch: 6| Step: 8
Training loss: 2.019315004348755
Validation loss: 2.0372155558678413

Epoch: 6| Step: 9
Training loss: 1.674477219581604
Validation loss: 2.0502539321940434

Epoch: 6| Step: 10
Training loss: 1.8834153413772583
Validation loss: 2.0556132139698153

Epoch: 6| Step: 11
Training loss: 1.9020051956176758
Validation loss: 2.0411852752008746

Epoch: 6| Step: 12
Training loss: 2.2084708213806152
Validation loss: 2.023506640106119

Epoch: 6| Step: 13
Training loss: 2.3497567176818848
Validation loss: 2.03087947189167

Epoch: 122| Step: 0
Training loss: 1.4608888626098633
Validation loss: 2.040526182420792

Epoch: 6| Step: 1
Training loss: 1.2717832326889038
Validation loss: 2.075777487088275

Epoch: 6| Step: 2
Training loss: 1.8242905139923096
Validation loss: 2.1245118648775163

Epoch: 6| Step: 3
Training loss: 2.367502450942993
Validation loss: 2.144083607581354

Epoch: 6| Step: 4
Training loss: 1.6869666576385498
Validation loss: 2.133880720343641

Epoch: 6| Step: 5
Training loss: 2.0344555377960205
Validation loss: 2.1028238047835646

Epoch: 6| Step: 6
Training loss: 2.4789624214172363
Validation loss: 2.0886184477036998

Epoch: 6| Step: 7
Training loss: 2.1431632041931152
Validation loss: 2.047388025509414

Epoch: 6| Step: 8
Training loss: 2.52852201461792
Validation loss: 2.0180698530648344

Epoch: 6| Step: 9
Training loss: 2.1691293716430664
Validation loss: 1.9963057989715247

Epoch: 6| Step: 10
Training loss: 2.229526996612549
Validation loss: 2.0025743617806384

Epoch: 6| Step: 11
Training loss: 2.2283456325531006
Validation loss: 2.0287270674141507

Epoch: 6| Step: 12
Training loss: 2.544473171234131
Validation loss: 2.071413396507181

Epoch: 6| Step: 13
Training loss: 1.6540777683258057
Validation loss: 2.080245089787309

Epoch: 123| Step: 0
Training loss: 2.3609702587127686
Validation loss: 2.1001597630080355

Epoch: 6| Step: 1
Training loss: 1.1515958309173584
Validation loss: 2.10195650592927

Epoch: 6| Step: 2
Training loss: 2.0447826385498047
Validation loss: 2.0952915376232517

Epoch: 6| Step: 3
Training loss: 2.0075318813323975
Validation loss: 2.067389941984607

Epoch: 6| Step: 4
Training loss: 2.2338054180145264
Validation loss: 2.034754317293885

Epoch: 6| Step: 5
Training loss: 2.2283637523651123
Validation loss: 2.00707301914051

Epoch: 6| Step: 6
Training loss: 2.0310189723968506
Validation loss: 1.9741302536379906

Epoch: 6| Step: 7
Training loss: 1.6559853553771973
Validation loss: 2.005247018670523

Epoch: 6| Step: 8
Training loss: 2.3136212825775146
Validation loss: 2.00662975670189

Epoch: 6| Step: 9
Training loss: 2.3446803092956543
Validation loss: 2.0053432244126514

Epoch: 6| Step: 10
Training loss: 1.3493061065673828
Validation loss: 1.9904544866213234

Epoch: 6| Step: 11
Training loss: 2.3200926780700684
Validation loss: 2.003496895554245

Epoch: 6| Step: 12
Training loss: 2.2218735218048096
Validation loss: 1.9881129854468889

Epoch: 6| Step: 13
Training loss: 2.201676368713379
Validation loss: 2.0045250051765033

Epoch: 124| Step: 0
Training loss: 1.7192082405090332
Validation loss: 2.0071347964707242

Epoch: 6| Step: 1
Training loss: 2.751101016998291
Validation loss: 2.0036796395496657

Epoch: 6| Step: 2
Training loss: 2.116786241531372
Validation loss: 2.0222244390877346

Epoch: 6| Step: 3
Training loss: 2.44948410987854
Validation loss: 2.032848873446065

Epoch: 6| Step: 4
Training loss: 1.6778159141540527
Validation loss: 2.0508124315610496

Epoch: 6| Step: 5
Training loss: 2.1053690910339355
Validation loss: 2.059209164752755

Epoch: 6| Step: 6
Training loss: 1.8505122661590576
Validation loss: 2.0591582764861402

Epoch: 6| Step: 7
Training loss: 1.575451135635376
Validation loss: 2.046671408478932

Epoch: 6| Step: 8
Training loss: 2.2936148643493652
Validation loss: 2.0274820455940823

Epoch: 6| Step: 9
Training loss: 1.2766273021697998
Validation loss: 2.0152647443996963

Epoch: 6| Step: 10
Training loss: 1.452748417854309
Validation loss: 2.0109831645924556

Epoch: 6| Step: 11
Training loss: 1.9074127674102783
Validation loss: 2.0227685282307286

Epoch: 6| Step: 12
Training loss: 2.867452621459961
Validation loss: 1.994611096638505

Epoch: 6| Step: 13
Training loss: 2.024517059326172
Validation loss: 1.995268488443026

Epoch: 125| Step: 0
Training loss: 1.677598237991333
Validation loss: 2.0060362662038496

Epoch: 6| Step: 1
Training loss: 2.060347318649292
Validation loss: 2.026236396963878

Epoch: 6| Step: 2
Training loss: 1.9223123788833618
Validation loss: 2.055540753949073

Epoch: 6| Step: 3
Training loss: 1.6972343921661377
Validation loss: 2.063741401959491

Epoch: 6| Step: 4
Training loss: 1.5883532762527466
Validation loss: 2.0890131573523245

Epoch: 6| Step: 5
Training loss: 2.131523609161377
Validation loss: 2.14783880787511

Epoch: 6| Step: 6
Training loss: 3.155888319015503
Validation loss: 2.1619764592057917

Epoch: 6| Step: 7
Training loss: 2.0770416259765625
Validation loss: 2.147582084901871

Epoch: 6| Step: 8
Training loss: 1.6264762878417969
Validation loss: 2.108757580480268

Epoch: 6| Step: 9
Training loss: 1.7004355192184448
Validation loss: 2.0848753170300554

Epoch: 6| Step: 10
Training loss: 2.3715925216674805
Validation loss: 2.03752887633539

Epoch: 6| Step: 11
Training loss: 2.268752098083496
Validation loss: 2.0188445737285

Epoch: 6| Step: 12
Training loss: 1.534092664718628
Validation loss: 2.0088384202731553

Epoch: 6| Step: 13
Training loss: 1.8937187194824219
Validation loss: 1.9864689996165614

Epoch: 126| Step: 0
Training loss: 2.867755651473999
Validation loss: 1.9730377248538438

Epoch: 6| Step: 1
Training loss: 1.9594309329986572
Validation loss: 1.9850500732339837

Epoch: 6| Step: 2
Training loss: 1.9253239631652832
Validation loss: 1.9962300459543865

Epoch: 6| Step: 3
Training loss: 2.0754947662353516
Validation loss: 2.0167122630662817

Epoch: 6| Step: 4
Training loss: 2.085085868835449
Validation loss: 2.020619494940645

Epoch: 6| Step: 5
Training loss: 1.9826444387435913
Validation loss: 2.0247360993457097

Epoch: 6| Step: 6
Training loss: 1.4134249687194824
Validation loss: 2.039428340491428

Epoch: 6| Step: 7
Training loss: 1.7871524095535278
Validation loss: 2.022280498217511

Epoch: 6| Step: 8
Training loss: 2.092958927154541
Validation loss: 2.021104456276022

Epoch: 6| Step: 9
Training loss: 2.34592342376709
Validation loss: 2.0154612269452823

Epoch: 6| Step: 10
Training loss: 2.1122748851776123
Validation loss: 2.0073687722606044

Epoch: 6| Step: 11
Training loss: 1.099310040473938
Validation loss: 1.982778351794007

Epoch: 6| Step: 12
Training loss: 1.3145983219146729
Validation loss: 1.9796933461261053

Epoch: 6| Step: 13
Training loss: 3.2384371757507324
Validation loss: 1.9688374355275144

Epoch: 127| Step: 0
Training loss: 2.4292619228363037
Validation loss: 2.0104775633863223

Epoch: 6| Step: 1
Training loss: 2.0065131187438965
Validation loss: 2.0094086226596626

Epoch: 6| Step: 2
Training loss: 2.0695652961730957
Validation loss: 2.0330801484405354

Epoch: 6| Step: 3
Training loss: 1.6217180490493774
Validation loss: 2.056345001343758

Epoch: 6| Step: 4
Training loss: 2.0903916358947754
Validation loss: 2.063007447027391

Epoch: 6| Step: 5
Training loss: 1.6686413288116455
Validation loss: 2.0512016563005346

Epoch: 6| Step: 6
Training loss: 1.4514451026916504
Validation loss: 2.0439411465839674

Epoch: 6| Step: 7
Training loss: 1.9811511039733887
Validation loss: 2.016902772329187

Epoch: 6| Step: 8
Training loss: 1.5430035591125488
Validation loss: 2.010890651774663

Epoch: 6| Step: 9
Training loss: 2.721764326095581
Validation loss: 2.0188989998191915

Epoch: 6| Step: 10
Training loss: 2.16580867767334
Validation loss: 1.9916308028723604

Epoch: 6| Step: 11
Training loss: 1.5095901489257812
Validation loss: 1.9906926411454395

Epoch: 6| Step: 12
Training loss: 1.82664954662323
Validation loss: 1.9849921734102312

Epoch: 6| Step: 13
Training loss: 2.1795103549957275
Validation loss: 1.9890478400773899

Epoch: 128| Step: 0
Training loss: 2.4127585887908936
Validation loss: 1.9734411906170588

Epoch: 6| Step: 1
Training loss: 1.5394229888916016
Validation loss: 1.9895559382695023

Epoch: 6| Step: 2
Training loss: 2.777392864227295
Validation loss: 1.976116467547673

Epoch: 6| Step: 3
Training loss: 1.690194010734558
Validation loss: 1.9804340626603814

Epoch: 6| Step: 4
Training loss: 2.290954113006592
Validation loss: 1.968160072962443

Epoch: 6| Step: 5
Training loss: 2.176563024520874
Validation loss: 1.9789472664556196

Epoch: 6| Step: 6
Training loss: 1.2226113080978394
Validation loss: 2.0075820799796813

Epoch: 6| Step: 7
Training loss: 1.7756068706512451
Validation loss: 2.0457178033808225

Epoch: 6| Step: 8
Training loss: 1.5650300979614258
Validation loss: 2.092090888689923

Epoch: 6| Step: 9
Training loss: 2.5991134643554688
Validation loss: 2.124217494841545

Epoch: 6| Step: 10
Training loss: 2.0070130825042725
Validation loss: 2.12509564686847

Epoch: 6| Step: 11
Training loss: 1.661312460899353
Validation loss: 2.1093607743581138

Epoch: 6| Step: 12
Training loss: 1.660872220993042
Validation loss: 2.1070676157551427

Epoch: 6| Step: 13
Training loss: 2.0379316806793213
Validation loss: 2.1008162344655683

Epoch: 129| Step: 0
Training loss: 1.828606367111206
Validation loss: 2.09465374741503

Epoch: 6| Step: 1
Training loss: 1.7744181156158447
Validation loss: 2.0772537903119157

Epoch: 6| Step: 2
Training loss: 1.3499400615692139
Validation loss: 2.068733428114204

Epoch: 6| Step: 3
Training loss: 1.7962942123413086
Validation loss: 2.0316294623959448

Epoch: 6| Step: 4
Training loss: 2.7656755447387695
Validation loss: 2.0268829791776595

Epoch: 6| Step: 5
Training loss: 1.9244608879089355
Validation loss: 2.0247318026840047

Epoch: 6| Step: 6
Training loss: 2.38106632232666
Validation loss: 2.02836464681933

Epoch: 6| Step: 7
Training loss: 1.9506458044052124
Validation loss: 2.046052489229428

Epoch: 6| Step: 8
Training loss: 1.738781452178955
Validation loss: 2.0253160051120225

Epoch: 6| Step: 9
Training loss: 1.8051111698150635
Validation loss: 2.005750221590842

Epoch: 6| Step: 10
Training loss: 2.14821195602417
Validation loss: 1.9898049780117568

Epoch: 6| Step: 11
Training loss: 2.371375560760498
Validation loss: 1.9653070639538508

Epoch: 6| Step: 12
Training loss: 1.3057992458343506
Validation loss: 1.9468653150784072

Epoch: 6| Step: 13
Training loss: 1.9283779859542847
Validation loss: 1.9325091736291045

Epoch: 130| Step: 0
Training loss: 1.702027678489685
Validation loss: 1.940816657517546

Epoch: 6| Step: 1
Training loss: 2.0562777519226074
Validation loss: 1.9485060450851277

Epoch: 6| Step: 2
Training loss: 2.354491949081421
Validation loss: 1.9531822781408987

Epoch: 6| Step: 3
Training loss: 1.5105938911437988
Validation loss: 1.9637969360556653

Epoch: 6| Step: 4
Training loss: 2.683919906616211
Validation loss: 1.963433733550451

Epoch: 6| Step: 5
Training loss: 2.0546183586120605
Validation loss: 1.9789039575925438

Epoch: 6| Step: 6
Training loss: 1.5995240211486816
Validation loss: 1.9946733161967287

Epoch: 6| Step: 7
Training loss: 1.043050765991211
Validation loss: 2.002584634288665

Epoch: 6| Step: 8
Training loss: 2.0366296768188477
Validation loss: 2.037439941078104

Epoch: 6| Step: 9
Training loss: 2.1088497638702393
Validation loss: 2.0493638489836004

Epoch: 6| Step: 10
Training loss: 1.7677350044250488
Validation loss: 2.0743967256238385

Epoch: 6| Step: 11
Training loss: 2.1847550868988037
Validation loss: 2.0851080443269465

Epoch: 6| Step: 12
Training loss: 2.0494015216827393
Validation loss: 2.0895202698246127

Epoch: 6| Step: 13
Training loss: 2.1074345111846924
Validation loss: 2.081225105511245

Epoch: 131| Step: 0
Training loss: 1.9210960865020752
Validation loss: 2.074902449884722

Epoch: 6| Step: 1
Training loss: 1.6960707902908325
Validation loss: 2.0736962262020318

Epoch: 6| Step: 2
Training loss: 2.3403635025024414
Validation loss: 2.0668401436139177

Epoch: 6| Step: 3
Training loss: 2.595541000366211
Validation loss: 2.105131418474259

Epoch: 6| Step: 4
Training loss: 2.15142560005188
Validation loss: 2.107384779120004

Epoch: 6| Step: 5
Training loss: 1.8017005920410156
Validation loss: 2.060667094363961

Epoch: 6| Step: 6
Training loss: 1.467604160308838
Validation loss: 2.0390862636668707

Epoch: 6| Step: 7
Training loss: 2.3273239135742188
Validation loss: 1.9903320330445484

Epoch: 6| Step: 8
Training loss: 1.9774887561798096
Validation loss: 1.963984481749996

Epoch: 6| Step: 9
Training loss: 1.6985676288604736
Validation loss: 1.942213414817728

Epoch: 6| Step: 10
Training loss: 1.9723191261291504
Validation loss: 1.9622311310101581

Epoch: 6| Step: 11
Training loss: 1.5106284618377686
Validation loss: 1.940846158612159

Epoch: 6| Step: 12
Training loss: 1.499436616897583
Validation loss: 1.9232075175931376

Epoch: 6| Step: 13
Training loss: 2.14621639251709
Validation loss: 1.9036098910916237

Epoch: 132| Step: 0
Training loss: 2.0020740032196045
Validation loss: 1.9239683099972305

Epoch: 6| Step: 1
Training loss: 2.0059266090393066
Validation loss: 1.9381965821789158

Epoch: 6| Step: 2
Training loss: 1.9342750310897827
Validation loss: 1.9684741702131046

Epoch: 6| Step: 3
Training loss: 2.3541760444641113
Validation loss: 1.984643954102711

Epoch: 6| Step: 4
Training loss: 1.9521938562393188
Validation loss: 1.9852010306491648

Epoch: 6| Step: 5
Training loss: 1.886042833328247
Validation loss: 1.9933469116046865

Epoch: 6| Step: 6
Training loss: 1.6829780340194702
Validation loss: 1.9828780440873996

Epoch: 6| Step: 7
Training loss: 2.002581834793091
Validation loss: 2.01507128695006

Epoch: 6| Step: 8
Training loss: 1.9717940092086792
Validation loss: 2.057757318660777

Epoch: 6| Step: 9
Training loss: 1.8049921989440918
Validation loss: 2.094437917073568

Epoch: 6| Step: 10
Training loss: 1.6769062280654907
Validation loss: 2.077781877210063

Epoch: 6| Step: 11
Training loss: 2.2295775413513184
Validation loss: 2.0514424077926146

Epoch: 6| Step: 12
Training loss: 1.706286907196045
Validation loss: 2.0284246142192552

Epoch: 6| Step: 13
Training loss: 0.9528728127479553
Validation loss: 2.006216392722181

Epoch: 133| Step: 0
Training loss: 1.6647725105285645
Validation loss: 1.9878643328143704

Epoch: 6| Step: 1
Training loss: 1.0082480907440186
Validation loss: 1.9802579238850584

Epoch: 6| Step: 2
Training loss: 1.958470344543457
Validation loss: 1.9911010367895967

Epoch: 6| Step: 3
Training loss: 2.0510239601135254
Validation loss: 1.9838913486849876

Epoch: 6| Step: 4
Training loss: 1.6878869533538818
Validation loss: 1.9988740080146379

Epoch: 6| Step: 5
Training loss: 2.057250499725342
Validation loss: 2.0511420631921418

Epoch: 6| Step: 6
Training loss: 2.5338096618652344
Validation loss: 2.0858141529944634

Epoch: 6| Step: 7
Training loss: 1.7768592834472656
Validation loss: 2.0994489269871868

Epoch: 6| Step: 8
Training loss: 1.8652405738830566
Validation loss: 2.0902008548859627

Epoch: 6| Step: 9
Training loss: 2.0990946292877197
Validation loss: 2.027024956159694

Epoch: 6| Step: 10
Training loss: 2.298801898956299
Validation loss: 2.0296681747641614

Epoch: 6| Step: 11
Training loss: 1.5415736436843872
Validation loss: 1.989205301448863

Epoch: 6| Step: 12
Training loss: 1.8866236209869385
Validation loss: 1.9965355011724657

Epoch: 6| Step: 13
Training loss: 1.430706262588501
Validation loss: 1.9768471435834003

Epoch: 134| Step: 0
Training loss: 1.4706079959869385
Validation loss: 1.9911993934262184

Epoch: 6| Step: 1
Training loss: 2.4995853900909424
Validation loss: 1.971686622147919

Epoch: 6| Step: 2
Training loss: 1.9874156713485718
Validation loss: 1.979271601605159

Epoch: 6| Step: 3
Training loss: 1.8775969743728638
Validation loss: 1.9881143364855038

Epoch: 6| Step: 4
Training loss: 1.5122179985046387
Validation loss: 1.987277905146281

Epoch: 6| Step: 5
Training loss: 1.7935068607330322
Validation loss: 1.9776427784273702

Epoch: 6| Step: 6
Training loss: 1.4688012599945068
Validation loss: 1.9906328442276164

Epoch: 6| Step: 7
Training loss: 1.458923101425171
Validation loss: 1.9848189969216623

Epoch: 6| Step: 8
Training loss: 2.5753793716430664
Validation loss: 2.0099544602055706

Epoch: 6| Step: 9
Training loss: 2.0961596965789795
Validation loss: 2.013839352515436

Epoch: 6| Step: 10
Training loss: 1.8545267581939697
Validation loss: 2.0043100772365445

Epoch: 6| Step: 11
Training loss: 1.81492280960083
Validation loss: 2.038067235741564

Epoch: 6| Step: 12
Training loss: 2.0883965492248535
Validation loss: 2.0540763665271062

Epoch: 6| Step: 13
Training loss: 2.0042378902435303
Validation loss: 2.081383894848567

Epoch: 135| Step: 0
Training loss: 1.7134544849395752
Validation loss: 2.0618717016712313

Epoch: 6| Step: 1
Training loss: 1.7271212339401245
Validation loss: 2.0696641873287898

Epoch: 6| Step: 2
Training loss: 1.9896175861358643
Validation loss: 2.025529871704758

Epoch: 6| Step: 3
Training loss: 2.092193126678467
Validation loss: 1.9881467498758787

Epoch: 6| Step: 4
Training loss: 1.467519998550415
Validation loss: 1.9881524398762693

Epoch: 6| Step: 5
Training loss: 2.2180888652801514
Validation loss: 2.014313054341142

Epoch: 6| Step: 6
Training loss: 1.4119027853012085
Validation loss: 2.020312883520639

Epoch: 6| Step: 7
Training loss: 1.580833077430725
Validation loss: 2.0107709412933676

Epoch: 6| Step: 8
Training loss: 2.1002185344696045
Validation loss: 1.9779653395375898

Epoch: 6| Step: 9
Training loss: 2.015397548675537
Validation loss: 1.9570552815673172

Epoch: 6| Step: 10
Training loss: 2.5984444618225098
Validation loss: 1.9614697476868987

Epoch: 6| Step: 11
Training loss: 1.2701460123062134
Validation loss: 1.979724375150537

Epoch: 6| Step: 12
Training loss: 2.512051582336426
Validation loss: 2.021307610696362

Epoch: 6| Step: 13
Training loss: 1.4084372520446777
Validation loss: 2.041580800087221

Epoch: 136| Step: 0
Training loss: 2.1148228645324707
Validation loss: 2.043271844105054

Epoch: 6| Step: 1
Training loss: 2.285210132598877
Validation loss: 2.0212373656611287

Epoch: 6| Step: 2
Training loss: 1.1969037055969238
Validation loss: 1.9655224507854832

Epoch: 6| Step: 3
Training loss: 2.5237932205200195
Validation loss: 1.9429008576177782

Epoch: 6| Step: 4
Training loss: 2.0627965927124023
Validation loss: 1.9834118094495548

Epoch: 6| Step: 5
Training loss: 1.6544396877288818
Validation loss: 1.9901916160378406

Epoch: 6| Step: 6
Training loss: 2.249802589416504
Validation loss: 2.0267189818043865

Epoch: 6| Step: 7
Training loss: 1.3964474201202393
Validation loss: 2.0480933779029438

Epoch: 6| Step: 8
Training loss: 1.4733597040176392
Validation loss: 2.0178665704624628

Epoch: 6| Step: 9
Training loss: 2.328150749206543
Validation loss: 1.9950771665060392

Epoch: 6| Step: 10
Training loss: 0.9762754440307617
Validation loss: 1.9593107520893056

Epoch: 6| Step: 11
Training loss: 2.0553226470947266
Validation loss: 1.9539990348200644

Epoch: 6| Step: 12
Training loss: 2.1240177154541016
Validation loss: 1.9878406165748514

Epoch: 6| Step: 13
Training loss: 1.8909732103347778
Validation loss: 1.995787617980793

Epoch: 137| Step: 0
Training loss: 2.220831871032715
Validation loss: 2.0429718161142

Epoch: 6| Step: 1
Training loss: 1.9364235401153564
Validation loss: 2.052443527406262

Epoch: 6| Step: 2
Training loss: 1.6534168720245361
Validation loss: 2.0864023136836227

Epoch: 6| Step: 3
Training loss: 2.1017534732818604
Validation loss: 2.0791934151803293

Epoch: 6| Step: 4
Training loss: 2.029256582260132
Validation loss: 2.057217087796939

Epoch: 6| Step: 5
Training loss: 1.4351356029510498
Validation loss: 2.0448308567846976

Epoch: 6| Step: 6
Training loss: 2.15377140045166
Validation loss: 2.0015737830951648

Epoch: 6| Step: 7
Training loss: 1.5101449489593506
Validation loss: 1.9940717130578973

Epoch: 6| Step: 8
Training loss: 1.1875717639923096
Validation loss: 1.998775565496055

Epoch: 6| Step: 9
Training loss: 2.2362608909606934
Validation loss: 1.9619281317598076

Epoch: 6| Step: 10
Training loss: 1.8061509132385254
Validation loss: 1.9645462292496876

Epoch: 6| Step: 11
Training loss: 2.3901586532592773
Validation loss: 1.9444361643124652

Epoch: 6| Step: 12
Training loss: 1.8076568841934204
Validation loss: 1.9245730394958167

Epoch: 6| Step: 13
Training loss: 1.2754435539245605
Validation loss: 1.9270261321016537

Epoch: 138| Step: 0
Training loss: 1.441734790802002
Validation loss: 1.9236468499706638

Epoch: 6| Step: 1
Training loss: 1.0424728393554688
Validation loss: 1.9369138427959975

Epoch: 6| Step: 2
Training loss: 2.3180980682373047
Validation loss: 1.9332372796150945

Epoch: 6| Step: 3
Training loss: 1.6229760646820068
Validation loss: 1.9387680253674906

Epoch: 6| Step: 4
Training loss: 1.6018314361572266
Validation loss: 1.9535741421484178

Epoch: 6| Step: 5
Training loss: 2.223174810409546
Validation loss: 1.9673784266236007

Epoch: 6| Step: 6
Training loss: 1.9921669960021973
Validation loss: 2.0035233677074475

Epoch: 6| Step: 7
Training loss: 1.5430994033813477
Validation loss: 2.0409995240549885

Epoch: 6| Step: 8
Training loss: 2.2941882610321045
Validation loss: 2.083790058730751

Epoch: 6| Step: 9
Training loss: 2.0487608909606934
Validation loss: 2.097396159684786

Epoch: 6| Step: 10
Training loss: 1.5853667259216309
Validation loss: 2.0966610729053454

Epoch: 6| Step: 11
Training loss: 2.02877140045166
Validation loss: 2.058080655272289

Epoch: 6| Step: 12
Training loss: 1.6952438354492188
Validation loss: 2.0380581809628393

Epoch: 6| Step: 13
Training loss: 2.0250916481018066
Validation loss: 2.010888925162695

Epoch: 139| Step: 0
Training loss: 1.3664588928222656
Validation loss: 1.9944586753845215

Epoch: 6| Step: 1
Training loss: 1.583367109298706
Validation loss: 2.0009338894198017

Epoch: 6| Step: 2
Training loss: 1.6833298206329346
Validation loss: 2.005378900035735

Epoch: 6| Step: 3
Training loss: 1.3888096809387207
Validation loss: 1.9792466804545412

Epoch: 6| Step: 4
Training loss: 2.5186610221862793
Validation loss: 1.953664792481289

Epoch: 6| Step: 5
Training loss: 1.9237940311431885
Validation loss: 1.9442698570989794

Epoch: 6| Step: 6
Training loss: 1.6952331066131592
Validation loss: 1.9175648702088224

Epoch: 6| Step: 7
Training loss: 1.7970632314682007
Validation loss: 1.9256712851985809

Epoch: 6| Step: 8
Training loss: 2.1992673873901367
Validation loss: 1.9184458396768058

Epoch: 6| Step: 9
Training loss: 2.0791401863098145
Validation loss: 1.944069072764407

Epoch: 6| Step: 10
Training loss: 1.7650446891784668
Validation loss: 1.9898223133497341

Epoch: 6| Step: 11
Training loss: 1.4896854162216187
Validation loss: 2.0264509467668432

Epoch: 6| Step: 12
Training loss: 1.9920926094055176
Validation loss: 2.065997290354903

Epoch: 6| Step: 13
Training loss: 2.135192394256592
Validation loss: 2.0964535897777927

Epoch: 140| Step: 0
Training loss: 2.007519483566284
Validation loss: 2.091424777943601

Epoch: 6| Step: 1
Training loss: 2.1706151962280273
Validation loss: 2.0376280251369683

Epoch: 6| Step: 2
Training loss: 1.4913420677185059
Validation loss: 1.9634117362319783

Epoch: 6| Step: 3
Training loss: 1.2360121011734009
Validation loss: 1.939212711908484

Epoch: 6| Step: 4
Training loss: 2.36806058883667
Validation loss: 1.9345221647652246

Epoch: 6| Step: 5
Training loss: 2.3575215339660645
Validation loss: 1.9497414122345627

Epoch: 6| Step: 6
Training loss: 2.665450096130371
Validation loss: 1.9555288207146428

Epoch: 6| Step: 7
Training loss: 1.501988410949707
Validation loss: 1.9952203560900945

Epoch: 6| Step: 8
Training loss: 1.4002522230148315
Validation loss: 2.017305912510041

Epoch: 6| Step: 9
Training loss: 1.652867317199707
Validation loss: 2.006490251069428

Epoch: 6| Step: 10
Training loss: 1.5608408451080322
Validation loss: 2.017784913380941

Epoch: 6| Step: 11
Training loss: 1.5353460311889648
Validation loss: 2.010527164705338

Epoch: 6| Step: 12
Training loss: 1.929366111755371
Validation loss: 2.0361873719000045

Epoch: 6| Step: 13
Training loss: 1.559752345085144
Validation loss: 2.030715484772959

Epoch: 141| Step: 0
Training loss: 2.061282157897949
Validation loss: 2.035501801839439

Epoch: 6| Step: 1
Training loss: 1.9978820085525513
Validation loss: 2.0498442111476773

Epoch: 6| Step: 2
Training loss: 2.048828363418579
Validation loss: 2.06862090351761

Epoch: 6| Step: 3
Training loss: 1.5698091983795166
Validation loss: 2.0534494923007105

Epoch: 6| Step: 4
Training loss: 1.6209661960601807
Validation loss: 2.01543604430332

Epoch: 6| Step: 5
Training loss: 1.537156343460083
Validation loss: 2.016421982037124

Epoch: 6| Step: 6
Training loss: 1.4078199863433838
Validation loss: 2.0163325096971247

Epoch: 6| Step: 7
Training loss: 1.666332483291626
Validation loss: 1.9995531010371383

Epoch: 6| Step: 8
Training loss: 2.045945167541504
Validation loss: 1.968723238155406

Epoch: 6| Step: 9
Training loss: 1.5005571842193604
Validation loss: 1.921276774457706

Epoch: 6| Step: 10
Training loss: 1.4917265176773071
Validation loss: 1.9299903582501154

Epoch: 6| Step: 11
Training loss: 2.3521456718444824
Validation loss: 1.946244025743136

Epoch: 6| Step: 12
Training loss: 2.0061473846435547
Validation loss: 1.9590471765046478

Epoch: 6| Step: 13
Training loss: 1.5823163986206055
Validation loss: 1.9985269936182166

Epoch: 142| Step: 0
Training loss: 2.171480894088745
Validation loss: 2.0413325217462357

Epoch: 6| Step: 1
Training loss: 1.8374395370483398
Validation loss: 2.0101300798436648

Epoch: 6| Step: 2
Training loss: 1.7048661708831787
Validation loss: 1.9669876521633518

Epoch: 6| Step: 3
Training loss: 1.7339555025100708
Validation loss: 1.919264498577323

Epoch: 6| Step: 4
Training loss: 2.2377519607543945
Validation loss: 1.9363378337634507

Epoch: 6| Step: 5
Training loss: 1.3637323379516602
Validation loss: 1.9847903354193575

Epoch: 6| Step: 6
Training loss: 1.3945058584213257
Validation loss: 2.0140528883985294

Epoch: 6| Step: 7
Training loss: 1.5625286102294922
Validation loss: 2.0514952059715026

Epoch: 6| Step: 8
Training loss: 1.6367542743682861
Validation loss: 2.0769619454619703

Epoch: 6| Step: 9
Training loss: 2.287715435028076
Validation loss: 2.0898675328941754

Epoch: 6| Step: 10
Training loss: 1.5320184230804443
Validation loss: 2.092218199083882

Epoch: 6| Step: 11
Training loss: 1.8693755865097046
Validation loss: 2.059630617018669

Epoch: 6| Step: 12
Training loss: 1.445594072341919
Validation loss: 2.0793946186701455

Epoch: 6| Step: 13
Training loss: 1.7917035818099976
Validation loss: 2.059662834290535

Epoch: 143| Step: 0
Training loss: 1.3545706272125244
Validation loss: 2.0593030991092807

Epoch: 6| Step: 1
Training loss: 1.747442364692688
Validation loss: 2.1255383286424863

Epoch: 6| Step: 2
Training loss: 1.5794075727462769
Validation loss: 2.1499280762928787

Epoch: 6| Step: 3
Training loss: 1.8904364109039307
Validation loss: 2.1338742830420054

Epoch: 6| Step: 4
Training loss: 1.8694252967834473
Validation loss: 2.1168068378202376

Epoch: 6| Step: 5
Training loss: 2.1177921295166016
Validation loss: 2.0725130919487245

Epoch: 6| Step: 6
Training loss: 1.9150718450546265
Validation loss: 2.0154996328456427

Epoch: 6| Step: 7
Training loss: 1.5178825855255127
Validation loss: 1.9515047227182696

Epoch: 6| Step: 8
Training loss: 1.5021201372146606
Validation loss: 1.9141274857264694

Epoch: 6| Step: 9
Training loss: 1.797532320022583
Validation loss: 1.8821004436862083

Epoch: 6| Step: 10
Training loss: 2.0134243965148926
Validation loss: 1.887364977149553

Epoch: 6| Step: 11
Training loss: 2.0066347122192383
Validation loss: 1.8660869034387733

Epoch: 6| Step: 12
Training loss: 1.9025897979736328
Validation loss: 1.8680538054435485

Epoch: 6| Step: 13
Training loss: 1.3590238094329834
Validation loss: 1.8889653131526003

Epoch: 144| Step: 0
Training loss: 1.6341667175292969
Validation loss: 1.909613727241434

Epoch: 6| Step: 1
Training loss: 1.3724530935287476
Validation loss: 1.9270635266457834

Epoch: 6| Step: 2
Training loss: 1.8399920463562012
Validation loss: 1.975028279007122

Epoch: 6| Step: 3
Training loss: 1.7660844326019287
Validation loss: 1.9814381496880644

Epoch: 6| Step: 4
Training loss: 1.4802544116973877
Validation loss: 2.029694196998432

Epoch: 6| Step: 5
Training loss: 1.185502290725708
Validation loss: 2.04070621408442

Epoch: 6| Step: 6
Training loss: 1.7747304439544678
Validation loss: 2.0661869407981954

Epoch: 6| Step: 7
Training loss: 1.8556797504425049
Validation loss: 2.0817916662462297

Epoch: 6| Step: 8
Training loss: 1.8449901342391968
Validation loss: 2.0925395104192916

Epoch: 6| Step: 9
Training loss: 1.6073825359344482
Validation loss: 2.0706110295429023

Epoch: 6| Step: 10
Training loss: 1.8644756078720093
Validation loss: 2.001222728401102

Epoch: 6| Step: 11
Training loss: 1.6462363004684448
Validation loss: 1.9771790068636659

Epoch: 6| Step: 12
Training loss: 2.2704367637634277
Validation loss: 1.8991596121941843

Epoch: 6| Step: 13
Training loss: 2.1590054035186768
Validation loss: 1.908872728706688

Epoch: 145| Step: 0
Training loss: 2.038612127304077
Validation loss: 1.902348958035951

Epoch: 6| Step: 1
Training loss: 1.0821621417999268
Validation loss: 1.9201528692758212

Epoch: 6| Step: 2
Training loss: 1.9985747337341309
Validation loss: 1.8982187240354476

Epoch: 6| Step: 3
Training loss: 1.8740392923355103
Validation loss: 1.9150834314284786

Epoch: 6| Step: 4
Training loss: 1.816929578781128
Validation loss: 1.96164918714954

Epoch: 6| Step: 5
Training loss: 1.997543454170227
Validation loss: 1.9813365039005075

Epoch: 6| Step: 6
Training loss: 1.4523195028305054
Validation loss: 2.0558348663391603

Epoch: 6| Step: 7
Training loss: 1.5537161827087402
Validation loss: 2.109143152031847

Epoch: 6| Step: 8
Training loss: 1.3268425464630127
Validation loss: 2.0805145732818113

Epoch: 6| Step: 9
Training loss: 2.054506301879883
Validation loss: 2.088861685927196

Epoch: 6| Step: 10
Training loss: 1.720351219177246
Validation loss: 2.0451973740772535

Epoch: 6| Step: 11
Training loss: 1.17201566696167
Validation loss: 2.036983402826453

Epoch: 6| Step: 12
Training loss: 2.6173312664031982
Validation loss: 2.0231563942406767

Epoch: 6| Step: 13
Training loss: 1.3887380361557007
Validation loss: 2.012833433766519

Epoch: 146| Step: 0
Training loss: 1.7055881023406982
Validation loss: 1.9639049396719983

Epoch: 6| Step: 1
Training loss: 2.224097728729248
Validation loss: 1.9741814521051222

Epoch: 6| Step: 2
Training loss: 2.50502872467041
Validation loss: 1.9741809521951983

Epoch: 6| Step: 3
Training loss: 1.8036283254623413
Validation loss: 1.9616192002450266

Epoch: 6| Step: 4
Training loss: 1.7718385457992554
Validation loss: 1.9567558098864812

Epoch: 6| Step: 5
Training loss: 1.4950482845306396
Validation loss: 1.9802051436516546

Epoch: 6| Step: 6
Training loss: 1.2789888381958008
Validation loss: 1.9939770480637908

Epoch: 6| Step: 7
Training loss: 1.581999659538269
Validation loss: 2.0151680695113314

Epoch: 6| Step: 8
Training loss: 1.9940980672836304
Validation loss: 1.9746442584581272

Epoch: 6| Step: 9
Training loss: 1.4600733518600464
Validation loss: 1.9650109057785363

Epoch: 6| Step: 10
Training loss: 1.5651623010635376
Validation loss: 1.9640317488742132

Epoch: 6| Step: 11
Training loss: 0.9267351627349854
Validation loss: 1.9658972999101043

Epoch: 6| Step: 12
Training loss: 2.0046839714050293
Validation loss: 1.9911878173069288

Epoch: 6| Step: 13
Training loss: 1.98663330078125
Validation loss: 1.999853196964469

Epoch: 147| Step: 0
Training loss: 2.036609649658203
Validation loss: 2.0338936915961643

Epoch: 6| Step: 1
Training loss: 2.320131778717041
Validation loss: 2.0515964108128704

Epoch: 6| Step: 2
Training loss: 1.219578504562378
Validation loss: 2.0615437146156066

Epoch: 6| Step: 3
Training loss: 1.400797724723816
Validation loss: 2.048233296281548

Epoch: 6| Step: 4
Training loss: 1.6453059911727905
Validation loss: 2.034816611197687

Epoch: 6| Step: 5
Training loss: 1.5831589698791504
Validation loss: 1.9994101601262246

Epoch: 6| Step: 6
Training loss: 1.640547275543213
Validation loss: 1.9794675842408211

Epoch: 6| Step: 7
Training loss: 1.1180437803268433
Validation loss: 1.956073118794349

Epoch: 6| Step: 8
Training loss: 2.2511258125305176
Validation loss: 1.9544233814362557

Epoch: 6| Step: 9
Training loss: 1.5715633630752563
Validation loss: 1.9751598886264268

Epoch: 6| Step: 10
Training loss: 1.9878034591674805
Validation loss: 1.967756445689868

Epoch: 6| Step: 11
Training loss: 1.6257243156433105
Validation loss: 2.001256855585242

Epoch: 6| Step: 12
Training loss: 1.2483153343200684
Validation loss: 2.0300344677381617

Epoch: 6| Step: 13
Training loss: 2.908510446548462
Validation loss: 2.0846329171170472

Epoch: 148| Step: 0
Training loss: 1.342879056930542
Validation loss: 2.0924694653480285

Epoch: 6| Step: 1
Training loss: 1.2695083618164062
Validation loss: 2.0685777843639417

Epoch: 6| Step: 2
Training loss: 1.9956425428390503
Validation loss: 2.0902122964141188

Epoch: 6| Step: 3
Training loss: 1.7719467878341675
Validation loss: 2.0749748650417534

Epoch: 6| Step: 4
Training loss: 1.6378636360168457
Validation loss: 2.0569073333535144

Epoch: 6| Step: 5
Training loss: 1.8121267557144165
Validation loss: 2.093268841825506

Epoch: 6| Step: 6
Training loss: 1.531428575515747
Validation loss: 2.1215114285868983

Epoch: 6| Step: 7
Training loss: 2.0348072052001953
Validation loss: 2.115924266076857

Epoch: 6| Step: 8
Training loss: 2.0045924186706543
Validation loss: 2.021005286965319

Epoch: 6| Step: 9
Training loss: 1.1239407062530518
Validation loss: 1.9706042453806887

Epoch: 6| Step: 10
Training loss: 1.7588483095169067
Validation loss: 1.9406117226487847

Epoch: 6| Step: 11
Training loss: 1.5226575136184692
Validation loss: 1.926459127856839

Epoch: 6| Step: 12
Training loss: 2.095419406890869
Validation loss: 1.920423089817006

Epoch: 6| Step: 13
Training loss: 1.836535930633545
Validation loss: 1.9246474619834655

Epoch: 149| Step: 0
Training loss: 1.749504566192627
Validation loss: 1.9487786485302834

Epoch: 6| Step: 1
Training loss: 2.479078531265259
Validation loss: 1.990711340340235

Epoch: 6| Step: 2
Training loss: 1.3445899486541748
Validation loss: 2.0031109907293834

Epoch: 6| Step: 3
Training loss: 1.1868653297424316
Validation loss: 2.060815393283803

Epoch: 6| Step: 4
Training loss: 1.6392488479614258
Validation loss: 2.0963970230471705

Epoch: 6| Step: 5
Training loss: 0.9745415449142456
Validation loss: 2.080699925781578

Epoch: 6| Step: 6
Training loss: 1.7219741344451904
Validation loss: 2.058087933448053

Epoch: 6| Step: 7
Training loss: 1.8811988830566406
Validation loss: 2.010111226830431

Epoch: 6| Step: 8
Training loss: 1.7633905410766602
Validation loss: 2.036901923917955

Epoch: 6| Step: 9
Training loss: 2.3759894371032715
Validation loss: 2.0645244365097373

Epoch: 6| Step: 10
Training loss: 1.8741414546966553
Validation loss: 2.090761611538549

Epoch: 6| Step: 11
Training loss: 1.8072624206542969
Validation loss: 2.0980996265206286

Epoch: 6| Step: 12
Training loss: 1.6263158321380615
Validation loss: 2.0664001690444125

Epoch: 6| Step: 13
Training loss: 1.5384597778320312
Validation loss: 2.0124817919987503

Epoch: 150| Step: 0
Training loss: 1.442603349685669
Validation loss: 1.952749639429072

Epoch: 6| Step: 1
Training loss: 1.7307432889938354
Validation loss: 1.8972377507917342

Epoch: 6| Step: 2
Training loss: 1.7008419036865234
Validation loss: 1.9190912426158946

Epoch: 6| Step: 3
Training loss: 2.4513602256774902
Validation loss: 1.948946004272789

Epoch: 6| Step: 4
Training loss: 1.4104993343353271
Validation loss: 1.9489087879016835

Epoch: 6| Step: 5
Training loss: 1.411503553390503
Validation loss: 1.9313648875041673

Epoch: 6| Step: 6
Training loss: 1.5794323682785034
Validation loss: 1.920583576284429

Epoch: 6| Step: 7
Training loss: 2.254173994064331
Validation loss: 1.914192529134853

Epoch: 6| Step: 8
Training loss: 1.7263957262039185
Validation loss: 1.9628018948339647

Epoch: 6| Step: 9
Training loss: 1.862329363822937
Validation loss: 1.992822672731133

Epoch: 6| Step: 10
Training loss: 2.2674622535705566
Validation loss: 2.055782828279721

Epoch: 6| Step: 11
Training loss: 1.8141698837280273
Validation loss: 2.072958679609401

Epoch: 6| Step: 12
Training loss: 1.1424620151519775
Validation loss: 2.1055916252956597

Epoch: 6| Step: 13
Training loss: 1.2602558135986328
Validation loss: 2.1083460174581057

Epoch: 151| Step: 0
Training loss: 1.843385934829712
Validation loss: 2.1024235897166754

Epoch: 6| Step: 1
Training loss: 1.684946894645691
Validation loss: 2.1208549366202405

Epoch: 6| Step: 2
Training loss: 1.890333890914917
Validation loss: 2.1019549215993574

Epoch: 6| Step: 3
Training loss: 1.9516098499298096
Validation loss: 2.092976003564814

Epoch: 6| Step: 4
Training loss: 1.1354516744613647
Validation loss: 2.1344410962955926

Epoch: 6| Step: 5
Training loss: 2.059091567993164
Validation loss: 2.113979411381547

Epoch: 6| Step: 6
Training loss: 1.7089983224868774
Validation loss: 2.0788896724741948

Epoch: 6| Step: 7
Training loss: 1.7608954906463623
Validation loss: 2.037039460674409

Epoch: 6| Step: 8
Training loss: 1.5969091653823853
Validation loss: 1.9640301542897378

Epoch: 6| Step: 9
Training loss: 1.4143439531326294
Validation loss: 1.9371228679533927

Epoch: 6| Step: 10
Training loss: 1.1658821105957031
Validation loss: 1.9275939246659637

Epoch: 6| Step: 11
Training loss: 1.8331124782562256
Validation loss: 1.8988955110631964

Epoch: 6| Step: 12
Training loss: 1.8323169946670532
Validation loss: 1.8882988524693314

Epoch: 6| Step: 13
Training loss: 1.57430100440979
Validation loss: 1.8708876050928587

Epoch: 152| Step: 0
Training loss: 1.8649035692214966
Validation loss: 1.8770193976740683

Epoch: 6| Step: 1
Training loss: 1.4616762399673462
Validation loss: 1.8988606852869834

Epoch: 6| Step: 2
Training loss: 1.5157290697097778
Validation loss: 1.9487922550529562

Epoch: 6| Step: 3
Training loss: 1.670846700668335
Validation loss: 1.9665508962446643

Epoch: 6| Step: 4
Training loss: 1.456268310546875
Validation loss: 1.9556712360792263

Epoch: 6| Step: 5
Training loss: 0.9371662139892578
Validation loss: 1.960604577936152

Epoch: 6| Step: 6
Training loss: 1.9093424081802368
Validation loss: 1.9859201446656258

Epoch: 6| Step: 7
Training loss: 2.3287806510925293
Validation loss: 1.9664626224066621

Epoch: 6| Step: 8
Training loss: 2.003108263015747
Validation loss: 1.9846331342574088

Epoch: 6| Step: 9
Training loss: 1.3477487564086914
Validation loss: 2.0008191395831365

Epoch: 6| Step: 10
Training loss: 1.7783520221710205
Validation loss: 1.9901212274387319

Epoch: 6| Step: 11
Training loss: 1.3432024717330933
Validation loss: 1.9462564324819913

Epoch: 6| Step: 12
Training loss: 1.7360420227050781
Validation loss: 1.9565789827736475

Epoch: 6| Step: 13
Training loss: 2.258578300476074
Validation loss: 1.9474582031208982

Epoch: 153| Step: 0
Training loss: 1.1709328889846802
Validation loss: 1.9362344844366914

Epoch: 6| Step: 1
Training loss: 2.026764154434204
Validation loss: 1.9411662329909622

Epoch: 6| Step: 2
Training loss: 1.3470866680145264
Validation loss: 1.95044667361885

Epoch: 6| Step: 3
Training loss: 2.0371859073638916
Validation loss: 1.977287495008079

Epoch: 6| Step: 4
Training loss: 1.2786333560943604
Validation loss: 1.9786099644117459

Epoch: 6| Step: 5
Training loss: 1.9770047664642334
Validation loss: 2.0202873624781126

Epoch: 6| Step: 6
Training loss: 1.5891368389129639
Validation loss: 2.0431944324124243

Epoch: 6| Step: 7
Training loss: 1.04390549659729
Validation loss: 2.086262636287238

Epoch: 6| Step: 8
Training loss: 1.6196749210357666
Validation loss: 2.1095026872491323

Epoch: 6| Step: 9
Training loss: 1.7362669706344604
Validation loss: 2.1040758304698493

Epoch: 6| Step: 10
Training loss: 1.624464750289917
Validation loss: 2.0711119456957747

Epoch: 6| Step: 11
Training loss: 2.1168606281280518
Validation loss: 2.0334088238336707

Epoch: 6| Step: 12
Training loss: 1.809993028640747
Validation loss: 2.0147076550350396

Epoch: 6| Step: 13
Training loss: 0.925762414932251
Validation loss: 1.964066687450614

Epoch: 154| Step: 0
Training loss: 1.4136030673980713
Validation loss: 1.9500360001799881

Epoch: 6| Step: 1
Training loss: 1.9772145748138428
Validation loss: 1.9089175526813795

Epoch: 6| Step: 2
Training loss: 1.1052358150482178
Validation loss: 1.914094969790469

Epoch: 6| Step: 3
Training loss: 1.6236491203308105
Validation loss: 1.926451849681075

Epoch: 6| Step: 4
Training loss: 1.4715521335601807
Validation loss: 1.9573161166201356

Epoch: 6| Step: 5
Training loss: 1.3359322547912598
Validation loss: 2.01975546216452

Epoch: 6| Step: 6
Training loss: 1.8746625185012817
Validation loss: 2.0772358499547487

Epoch: 6| Step: 7
Training loss: 1.8261637687683105
Validation loss: 2.1223980560097644

Epoch: 6| Step: 8
Training loss: 1.1946558952331543
Validation loss: 2.1765761119063183

Epoch: 6| Step: 9
Training loss: 1.925543189048767
Validation loss: 2.141825135036181

Epoch: 6| Step: 10
Training loss: 1.6537063121795654
Validation loss: 2.047220233948

Epoch: 6| Step: 11
Training loss: 1.8172966241836548
Validation loss: 1.9781598288525817

Epoch: 6| Step: 12
Training loss: 1.8177201747894287
Validation loss: 1.9138687336316673

Epoch: 6| Step: 13
Training loss: 1.671863079071045
Validation loss: 1.8887057791474045

Epoch: 155| Step: 0
Training loss: 1.523508071899414
Validation loss: 1.8827525082454886

Epoch: 6| Step: 1
Training loss: 1.2661473751068115
Validation loss: 1.8926756048715243

Epoch: 6| Step: 2
Training loss: 2.15911602973938
Validation loss: 1.8819767710983113

Epoch: 6| Step: 3
Training loss: 1.795621633529663
Validation loss: 1.8941044486979002

Epoch: 6| Step: 4
Training loss: 2.4060778617858887
Validation loss: 1.896447516256763

Epoch: 6| Step: 5
Training loss: 1.6026332378387451
Validation loss: 1.9070423187748078

Epoch: 6| Step: 6
Training loss: 1.7047250270843506
Validation loss: 1.9160485729094474

Epoch: 6| Step: 7
Training loss: 2.0940685272216797
Validation loss: 1.9543869918392551

Epoch: 6| Step: 8
Training loss: 2.336848258972168
Validation loss: 2.0161347684039863

Epoch: 6| Step: 9
Training loss: 1.146361231803894
Validation loss: 2.06128813118063

Epoch: 6| Step: 10
Training loss: 1.0200804471969604
Validation loss: 2.1409338084600305

Epoch: 6| Step: 11
Training loss: 1.5789992809295654
Validation loss: 2.151631639849755

Epoch: 6| Step: 12
Training loss: 1.0800050497055054
Validation loss: 2.1549417536745787

Epoch: 6| Step: 13
Training loss: 1.5444921255111694
Validation loss: 2.134703431078183

Epoch: 156| Step: 0
Training loss: 1.1324079036712646
Validation loss: 2.079426730832746

Epoch: 6| Step: 1
Training loss: 1.956423282623291
Validation loss: 2.0261411025959957

Epoch: 6| Step: 2
Training loss: 1.2106852531433105
Validation loss: 1.9394735110703336

Epoch: 6| Step: 3
Training loss: 0.9523730874061584
Validation loss: 1.9085057576497395

Epoch: 6| Step: 4
Training loss: 1.6576945781707764
Validation loss: 1.8842068756780317

Epoch: 6| Step: 5
Training loss: 1.637412428855896
Validation loss: 1.8886352944117721

Epoch: 6| Step: 6
Training loss: 1.7728136777877808
Validation loss: 1.8765005187321735

Epoch: 6| Step: 7
Training loss: 1.5226010084152222
Validation loss: 1.907541992843792

Epoch: 6| Step: 8
Training loss: 1.3712923526763916
Validation loss: 1.93009215529247

Epoch: 6| Step: 9
Training loss: 1.7750322818756104
Validation loss: 1.9211362100416614

Epoch: 6| Step: 10
Training loss: 2.32661771774292
Validation loss: 1.9636145202062463

Epoch: 6| Step: 11
Training loss: 1.9554698467254639
Validation loss: 1.9686996731706845

Epoch: 6| Step: 12
Training loss: 2.0088727474212646
Validation loss: 2.0446560831480127

Epoch: 6| Step: 13
Training loss: 1.546828269958496
Validation loss: 2.101514349701584

Epoch: 157| Step: 0
Training loss: 1.5619488954544067
Validation loss: 2.1690003436098815

Epoch: 6| Step: 1
Training loss: 1.4593244791030884
Validation loss: 2.181714665505194

Epoch: 6| Step: 2
Training loss: 1.7809827327728271
Validation loss: 2.17690848535107

Epoch: 6| Step: 3
Training loss: 1.3214555978775024
Validation loss: 2.089206700683922

Epoch: 6| Step: 4
Training loss: 1.5772569179534912
Validation loss: 2.025050570887904

Epoch: 6| Step: 5
Training loss: 1.3901822566986084
Validation loss: 1.9987480025137625

Epoch: 6| Step: 6
Training loss: 1.8852577209472656
Validation loss: 1.9418629497610114

Epoch: 6| Step: 7
Training loss: 1.0936083793640137
Validation loss: 1.9150140362401162

Epoch: 6| Step: 8
Training loss: 1.9477661848068237
Validation loss: 1.8790629333065403

Epoch: 6| Step: 9
Training loss: 1.439237117767334
Validation loss: 1.9189674085186375

Epoch: 6| Step: 10
Training loss: 1.664076805114746
Validation loss: 1.9493783161204348

Epoch: 6| Step: 11
Training loss: 2.5198988914489746
Validation loss: 1.964156214908887

Epoch: 6| Step: 12
Training loss: 1.678640604019165
Validation loss: 2.022934913635254

Epoch: 6| Step: 13
Training loss: 1.5501809120178223
Validation loss: 2.0830857394843973

Epoch: 158| Step: 0
Training loss: 1.1986608505249023
Validation loss: 2.1526182825847338

Epoch: 6| Step: 1
Training loss: 1.7084463834762573
Validation loss: 2.228537436454527

Epoch: 6| Step: 2
Training loss: 1.687238335609436
Validation loss: 2.23440029287851

Epoch: 6| Step: 3
Training loss: 1.9433163404464722
Validation loss: 2.234261243574081

Epoch: 6| Step: 4
Training loss: 1.9621481895446777
Validation loss: 2.161330512774888

Epoch: 6| Step: 5
Training loss: 1.4368808269500732
Validation loss: 2.1160065999595066

Epoch: 6| Step: 6
Training loss: 1.790104866027832
Validation loss: 2.0574240863964124

Epoch: 6| Step: 7
Training loss: 1.5918928384780884
Validation loss: 2.0293820801601616

Epoch: 6| Step: 8
Training loss: 1.686584711074829
Validation loss: 1.9919835175237348

Epoch: 6| Step: 9
Training loss: 1.498220443725586
Validation loss: 1.9312462396519159

Epoch: 6| Step: 10
Training loss: 2.115657329559326
Validation loss: 1.9121178657777849

Epoch: 6| Step: 11
Training loss: 1.5579135417938232
Validation loss: 1.8964831457343152

Epoch: 6| Step: 12
Training loss: 1.0215357542037964
Validation loss: 1.8849810579771638

Epoch: 6| Step: 13
Training loss: 2.195526599884033
Validation loss: 1.8920242350588563

Epoch: 159| Step: 0
Training loss: 1.032710313796997
Validation loss: 1.9231245363912275

Epoch: 6| Step: 1
Training loss: 1.5416886806488037
Validation loss: 1.9344545102888537

Epoch: 6| Step: 2
Training loss: 2.102667808532715
Validation loss: 1.9543538183294318

Epoch: 6| Step: 3
Training loss: 2.2250072956085205
Validation loss: 2.0200378407714186

Epoch: 6| Step: 4
Training loss: 2.1239821910858154
Validation loss: 2.0853183884774484

Epoch: 6| Step: 5
Training loss: 1.6561203002929688
Validation loss: 2.135826394122134

Epoch: 6| Step: 6
Training loss: 1.3748319149017334
Validation loss: 2.181156386611282

Epoch: 6| Step: 7
Training loss: 0.9815108776092529
Validation loss: 2.1989194911013366

Epoch: 6| Step: 8
Training loss: 1.6668462753295898
Validation loss: 2.174521211654909

Epoch: 6| Step: 9
Training loss: 1.0253163576126099
Validation loss: 2.159737358811081

Epoch: 6| Step: 10
Training loss: 1.3936209678649902
Validation loss: 2.107821818320982

Epoch: 6| Step: 11
Training loss: 1.3674921989440918
Validation loss: 2.115436069426998

Epoch: 6| Step: 12
Training loss: 2.1874990463256836
Validation loss: 2.1069653828938804

Epoch: 6| Step: 13
Training loss: 1.6373995542526245
Validation loss: 2.0890484638111566

Epoch: 160| Step: 0
Training loss: 1.0111958980560303
Validation loss: 2.114583706343046

Epoch: 6| Step: 1
Training loss: 2.426971435546875
Validation loss: 2.1242886486873833

Epoch: 6| Step: 2
Training loss: 1.3824107646942139
Validation loss: 2.0875664090597503

Epoch: 6| Step: 3
Training loss: 1.6143944263458252
Validation loss: 2.0708922391296714

Epoch: 6| Step: 4
Training loss: 1.4169350862503052
Validation loss: 2.0509047777422014

Epoch: 6| Step: 5
Training loss: 1.9552273750305176
Validation loss: 2.071403335499507

Epoch: 6| Step: 6
Training loss: 1.4424917697906494
Validation loss: 2.1161896362099597

Epoch: 6| Step: 7
Training loss: 1.8821126222610474
Validation loss: 2.0665718060667797

Epoch: 6| Step: 8
Training loss: 1.1584573984146118
Validation loss: 2.0653542575015815

Epoch: 6| Step: 9
Training loss: 1.717278242111206
Validation loss: 2.064905312753493

Epoch: 6| Step: 10
Training loss: 2.090332508087158
Validation loss: 2.053746954087288

Epoch: 6| Step: 11
Training loss: 1.217175006866455
Validation loss: 2.044929289048718

Epoch: 6| Step: 12
Training loss: 1.689932942390442
Validation loss: 2.0411482088027464

Epoch: 6| Step: 13
Training loss: 0.8042585849761963
Validation loss: 2.0142205197324037

Epoch: 161| Step: 0
Training loss: 1.0457642078399658
Validation loss: 2.024651155676893

Epoch: 6| Step: 1
Training loss: 1.4238661527633667
Validation loss: 2.059225538725494

Epoch: 6| Step: 2
Training loss: 1.4492554664611816
Validation loss: 2.0594206907415904

Epoch: 6| Step: 3
Training loss: 1.338756799697876
Validation loss: 2.050084034601847

Epoch: 6| Step: 4
Training loss: 1.322230577468872
Validation loss: 2.047925818351007

Epoch: 6| Step: 5
Training loss: 1.5462719202041626
Validation loss: 2.0599579913641817

Epoch: 6| Step: 6
Training loss: 1.501133680343628
Validation loss: 2.040864529148225

Epoch: 6| Step: 7
Training loss: 1.5837866067886353
Validation loss: 2.02645525111947

Epoch: 6| Step: 8
Training loss: 1.8887577056884766
Validation loss: 2.0655535754337104

Epoch: 6| Step: 9
Training loss: 1.9605740308761597
Validation loss: 2.046685626429896

Epoch: 6| Step: 10
Training loss: 1.0210217237472534
Validation loss: 2.0129814750404766

Epoch: 6| Step: 11
Training loss: 1.5644419193267822
Validation loss: 2.0030599486443306

Epoch: 6| Step: 12
Training loss: 1.8549221754074097
Validation loss: 1.9884466484028807

Epoch: 6| Step: 13
Training loss: 1.9321836233139038
Validation loss: 1.9661292260692966

Epoch: 162| Step: 0
Training loss: 1.1921241283416748
Validation loss: 1.989621639251709

Epoch: 6| Step: 1
Training loss: 1.3569329977035522
Validation loss: 1.9945544965805546

Epoch: 6| Step: 2
Training loss: 1.7152180671691895
Validation loss: 2.0885274987066946

Epoch: 6| Step: 3
Training loss: 1.715577244758606
Validation loss: 2.02546166604565

Epoch: 6| Step: 4
Training loss: 1.1312000751495361
Validation loss: 2.0075148228676087

Epoch: 6| Step: 5
Training loss: 1.7514793872833252
Validation loss: 1.988108624694168

Epoch: 6| Step: 6
Training loss: 1.314056158065796
Validation loss: 1.9906739804052538

Epoch: 6| Step: 7
Training loss: 1.8824682235717773
Validation loss: 1.9642264304622528

Epoch: 6| Step: 8
Training loss: 1.5235382318496704
Validation loss: 1.9756378845501972

Epoch: 6| Step: 9
Training loss: 1.173872709274292
Validation loss: 1.9669644127609909

Epoch: 6| Step: 10
Training loss: 1.814744472503662
Validation loss: 2.0202924436138523

Epoch: 6| Step: 11
Training loss: 1.5429047346115112
Validation loss: 2.0479160008891935

Epoch: 6| Step: 12
Training loss: 1.4884800910949707
Validation loss: 2.0880646577445408

Epoch: 6| Step: 13
Training loss: 0.8532324433326721
Validation loss: 2.0964730939557477

Epoch: 163| Step: 0
Training loss: 1.4963388442993164
Validation loss: 2.1573569697718464

Epoch: 6| Step: 1
Training loss: 1.4358479976654053
Validation loss: 2.189138602184993

Epoch: 6| Step: 2
Training loss: 1.6714568138122559
Validation loss: 2.1997053828290714

Epoch: 6| Step: 3
Training loss: 1.4806435108184814
Validation loss: 2.169315750880908

Epoch: 6| Step: 4
Training loss: 1.7205430269241333
Validation loss: 2.1071397566026255

Epoch: 6| Step: 5
Training loss: 1.18340003490448
Validation loss: 2.0140506862312235

Epoch: 6| Step: 6
Training loss: 1.4443039894104004
Validation loss: 1.9841030951469176

Epoch: 6| Step: 7
Training loss: 1.4805305004119873
Validation loss: 1.9992116215408489

Epoch: 6| Step: 8
Training loss: 2.151045560836792
Validation loss: 1.9729017108999274

Epoch: 6| Step: 9
Training loss: 1.459041714668274
Validation loss: 1.97182451012314

Epoch: 6| Step: 10
Training loss: 2.4035229682922363
Validation loss: 1.954698593385758

Epoch: 6| Step: 11
Training loss: 1.2547416687011719
Validation loss: 1.9212944853690364

Epoch: 6| Step: 12
Training loss: 1.1122689247131348
Validation loss: 1.8868584171418221

Epoch: 6| Step: 13
Training loss: 0.97688889503479
Validation loss: 1.9097790615532988

Epoch: 164| Step: 0
Training loss: 1.593139410018921
Validation loss: 1.9314612650102185

Epoch: 6| Step: 1
Training loss: 1.6797043085098267
Validation loss: 1.9639805978344334

Epoch: 6| Step: 2
Training loss: 1.8702754974365234
Validation loss: 2.0511264211388043

Epoch: 6| Step: 3
Training loss: 1.3534724712371826
Validation loss: 2.055388812095888

Epoch: 6| Step: 4
Training loss: 1.9465854167938232
Validation loss: 2.1047003358922978

Epoch: 6| Step: 5
Training loss: 1.514761209487915
Validation loss: 2.129742519829863

Epoch: 6| Step: 6
Training loss: 1.4596869945526123
Validation loss: 2.0667452094375447

Epoch: 6| Step: 7
Training loss: 1.428544521331787
Validation loss: 1.944781268796613

Epoch: 6| Step: 8
Training loss: 1.3589057922363281
Validation loss: 1.8997088247729885

Epoch: 6| Step: 9
Training loss: 1.7568670511245728
Validation loss: 1.89827928491818

Epoch: 6| Step: 10
Training loss: 1.2272121906280518
Validation loss: 1.9054960422618414

Epoch: 6| Step: 11
Training loss: 1.0517953634262085
Validation loss: 1.9317392482552478

Epoch: 6| Step: 12
Training loss: 1.6673036813735962
Validation loss: 1.9418237234956475

Epoch: 6| Step: 13
Training loss: 1.707737684249878
Validation loss: 1.9625615355789021

Epoch: 165| Step: 0
Training loss: 1.2749946117401123
Validation loss: 1.9882677216683664

Epoch: 6| Step: 1
Training loss: 1.8645015954971313
Validation loss: 2.0077843178984938

Epoch: 6| Step: 2
Training loss: 1.968374490737915
Validation loss: 2.0335240953712055

Epoch: 6| Step: 3
Training loss: 1.9247453212738037
Validation loss: 2.055951097960113

Epoch: 6| Step: 4
Training loss: 1.1480380296707153
Validation loss: 2.0215705210162747

Epoch: 6| Step: 5
Training loss: 0.9311118721961975
Validation loss: 2.0499594634579075

Epoch: 6| Step: 6
Training loss: 1.3920338153839111
Validation loss: 2.06791760588205

Epoch: 6| Step: 7
Training loss: 1.683950424194336
Validation loss: 2.1280874603538105

Epoch: 6| Step: 8
Training loss: 1.8549728393554688
Validation loss: 2.1253876173368065

Epoch: 6| Step: 9
Training loss: 1.203005075454712
Validation loss: 2.1504247034749677

Epoch: 6| Step: 10
Training loss: 1.7021863460540771
Validation loss: 2.114778698131602

Epoch: 6| Step: 11
Training loss: 1.0255482196807861
Validation loss: 2.0695453100307013

Epoch: 6| Step: 12
Training loss: 1.8529528379440308
Validation loss: 2.0397708159621044

Epoch: 6| Step: 13
Training loss: 1.6107537746429443
Validation loss: 2.011772055779734

Epoch: 166| Step: 0
Training loss: 1.6134464740753174
Validation loss: 1.9467913079005417

Epoch: 6| Step: 1
Training loss: 2.0589141845703125
Validation loss: 1.9199548985368462

Epoch: 6| Step: 2
Training loss: 1.8221811056137085
Validation loss: 1.8879914488843692

Epoch: 6| Step: 3
Training loss: 1.635561227798462
Validation loss: 1.893945150477912

Epoch: 6| Step: 4
Training loss: 1.4175976514816284
Validation loss: 1.9266018829038065

Epoch: 6| Step: 5
Training loss: 1.536834716796875
Validation loss: 1.955960000714948

Epoch: 6| Step: 6
Training loss: 1.353860855102539
Validation loss: 1.9888917412809146

Epoch: 6| Step: 7
Training loss: 1.5671533346176147
Validation loss: 1.9921404084851664

Epoch: 6| Step: 8
Training loss: 1.1463388204574585
Validation loss: 2.0353998317513415

Epoch: 6| Step: 9
Training loss: 1.2703522443771362
Validation loss: 2.0530849438841625

Epoch: 6| Step: 10
Training loss: 1.6159882545471191
Validation loss: 2.0635273841119584

Epoch: 6| Step: 11
Training loss: 1.7069170475006104
Validation loss: 2.042436320294616

Epoch: 6| Step: 12
Training loss: 0.8175667524337769
Validation loss: 2.033207657516644

Epoch: 6| Step: 13
Training loss: 0.7273536920547485
Validation loss: 2.0487823691419376

Epoch: 167| Step: 0
Training loss: 0.8355653285980225
Validation loss: 2.034483322533228

Epoch: 6| Step: 1
Training loss: 1.292970895767212
Validation loss: 2.024199939543201

Epoch: 6| Step: 2
Training loss: 1.520592212677002
Validation loss: 1.967569015359366

Epoch: 6| Step: 3
Training loss: 1.1672205924987793
Validation loss: 1.9313220349691247

Epoch: 6| Step: 4
Training loss: 1.989367961883545
Validation loss: 1.901210819521258

Epoch: 6| Step: 5
Training loss: 1.4917926788330078
Validation loss: 1.8791217188681326

Epoch: 6| Step: 6
Training loss: 1.654468297958374
Validation loss: 1.854558374292107

Epoch: 6| Step: 7
Training loss: 1.05806303024292
Validation loss: 1.9048235980413293

Epoch: 6| Step: 8
Training loss: 1.4870103597640991
Validation loss: 1.9103236800880843

Epoch: 6| Step: 9
Training loss: 1.5694704055786133
Validation loss: 1.938630065610332

Epoch: 6| Step: 10
Training loss: 1.7561450004577637
Validation loss: 1.9723395929541638

Epoch: 6| Step: 11
Training loss: 1.4587211608886719
Validation loss: 2.029024024163523

Epoch: 6| Step: 12
Training loss: 1.3915596008300781
Validation loss: 2.0599802335103354

Epoch: 6| Step: 13
Training loss: 1.3777670860290527
Validation loss: 2.090069527267128

Epoch: 168| Step: 0
Training loss: 1.5714795589447021
Validation loss: 2.085464805685064

Epoch: 6| Step: 1
Training loss: 1.4621831178665161
Validation loss: 2.030855078851023

Epoch: 6| Step: 2
Training loss: 1.4292933940887451
Validation loss: 1.9804953695625387

Epoch: 6| Step: 3
Training loss: 1.6931062936782837
Validation loss: 1.940946429006515

Epoch: 6| Step: 4
Training loss: 1.0619820356369019
Validation loss: 1.9238879629360732

Epoch: 6| Step: 5
Training loss: 1.9177072048187256
Validation loss: 1.8883523620584959

Epoch: 6| Step: 6
Training loss: 1.639763593673706
Validation loss: 1.887340945582236

Epoch: 6| Step: 7
Training loss: 1.4934685230255127
Validation loss: 1.8883496561358053

Epoch: 6| Step: 8
Training loss: 1.1256587505340576
Validation loss: 1.9318740572980655

Epoch: 6| Step: 9
Training loss: 1.5581400394439697
Validation loss: 2.0063463872478855

Epoch: 6| Step: 10
Training loss: 1.7605360746383667
Validation loss: 2.0755269501798894

Epoch: 6| Step: 11
Training loss: 1.6329917907714844
Validation loss: 2.102827259289321

Epoch: 6| Step: 12
Training loss: 0.6771864295005798
Validation loss: 2.1123347513137327

Epoch: 6| Step: 13
Training loss: 1.1952521800994873
Validation loss: 2.142665506691061

Epoch: 169| Step: 0
Training loss: 1.6305310726165771
Validation loss: 2.1424270855483187

Epoch: 6| Step: 1
Training loss: 1.326352834701538
Validation loss: 2.136344181594028

Epoch: 6| Step: 2
Training loss: 1.8447794914245605
Validation loss: 2.080897101791956

Epoch: 6| Step: 3
Training loss: 0.8228510618209839
Validation loss: 2.046007151244789

Epoch: 6| Step: 4
Training loss: 1.3098403215408325
Validation loss: 2.0520753757928007

Epoch: 6| Step: 5
Training loss: 1.6984901428222656
Validation loss: 2.021019393397916

Epoch: 6| Step: 6
Training loss: 1.6656972169876099
Validation loss: 2.033878278988664

Epoch: 6| Step: 7
Training loss: 1.3340243101119995
Validation loss: 1.95816885143198

Epoch: 6| Step: 8
Training loss: 1.3156540393829346
Validation loss: 1.9255773905784852

Epoch: 6| Step: 9
Training loss: 1.5815130472183228
Validation loss: 1.8936187785158876

Epoch: 6| Step: 10
Training loss: 1.544434905052185
Validation loss: 1.872479292654222

Epoch: 6| Step: 11
Training loss: 1.1741527318954468
Validation loss: 1.9002680893867248

Epoch: 6| Step: 12
Training loss: 1.0611495971679688
Validation loss: 1.9310329062964326

Epoch: 6| Step: 13
Training loss: 1.7607672214508057
Validation loss: 1.9820512033277942

Epoch: 170| Step: 0
Training loss: 1.300295352935791
Validation loss: 1.9807877002223846

Epoch: 6| Step: 1
Training loss: 1.044191598892212
Validation loss: 1.987650796931277

Epoch: 6| Step: 2
Training loss: 1.602670431137085
Validation loss: 2.0005395104808192

Epoch: 6| Step: 3
Training loss: 1.826000452041626
Validation loss: 2.030148962492584

Epoch: 6| Step: 4
Training loss: 1.6568350791931152
Validation loss: 2.060457915388128

Epoch: 6| Step: 5
Training loss: 0.998194694519043
Validation loss: 2.0443306789603284

Epoch: 6| Step: 6
Training loss: 1.3935277462005615
Validation loss: 2.031168624918948

Epoch: 6| Step: 7
Training loss: 1.1796488761901855
Validation loss: 1.9650536878134615

Epoch: 6| Step: 8
Training loss: 1.6856825351715088
Validation loss: 1.8834170256891558

Epoch: 6| Step: 9
Training loss: 1.2057323455810547
Validation loss: 1.8689226924732167

Epoch: 6| Step: 10
Training loss: 1.0920238494873047
Validation loss: 1.846169884486865

Epoch: 6| Step: 11
Training loss: 1.4373068809509277
Validation loss: 1.8391485534688479

Epoch: 6| Step: 12
Training loss: 2.0268237590789795
Validation loss: 1.8536775189061319

Epoch: 6| Step: 13
Training loss: 1.0444718599319458
Validation loss: 1.870451101692774

Epoch: 171| Step: 0
Training loss: 1.1576250791549683
Validation loss: 1.8825454237640544

Epoch: 6| Step: 1
Training loss: 1.0556867122650146
Validation loss: 1.932504721867141

Epoch: 6| Step: 2
Training loss: 1.1205393075942993
Validation loss: 1.998468045265444

Epoch: 6| Step: 3
Training loss: 1.848800539970398
Validation loss: 2.055153533976565

Epoch: 6| Step: 4
Training loss: 1.8946154117584229
Validation loss: 2.064417305813041

Epoch: 6| Step: 5
Training loss: 0.9330448508262634
Validation loss: 2.0240716139475503

Epoch: 6| Step: 6
Training loss: 1.4023535251617432
Validation loss: 1.9661747153087328

Epoch: 6| Step: 7
Training loss: 1.572446346282959
Validation loss: 1.9604480356298468

Epoch: 6| Step: 8
Training loss: 1.08561372756958
Validation loss: 1.979495943233531

Epoch: 6| Step: 9
Training loss: 1.2794052362442017
Validation loss: 1.970274422758369

Epoch: 6| Step: 10
Training loss: 1.8190150260925293
Validation loss: 1.9748170375823975

Epoch: 6| Step: 11
Training loss: 1.7428607940673828
Validation loss: 1.960236144322221

Epoch: 6| Step: 12
Training loss: 0.9936599135398865
Validation loss: 1.9381092453515658

Epoch: 6| Step: 13
Training loss: 1.2998937368392944
Validation loss: 1.9445240984680832

Epoch: 172| Step: 0
Training loss: 1.1377882957458496
Validation loss: 1.9690586982234832

Epoch: 6| Step: 1
Training loss: 1.3849079608917236
Validation loss: 1.9644077503553001

Epoch: 6| Step: 2
Training loss: 1.1528260707855225
Validation loss: 1.977081193718859

Epoch: 6| Step: 3
Training loss: 1.6206409931182861
Validation loss: 1.977147138246926

Epoch: 6| Step: 4
Training loss: 0.9732630848884583
Validation loss: 1.9640183602609942

Epoch: 6| Step: 5
Training loss: 0.9161739945411682
Validation loss: 2.0050169062870804

Epoch: 6| Step: 6
Training loss: 1.2904772758483887
Validation loss: 1.9549080069347093

Epoch: 6| Step: 7
Training loss: 1.525357961654663
Validation loss: 1.966070080316195

Epoch: 6| Step: 8
Training loss: 1.7200292348861694
Validation loss: 1.959058343723256

Epoch: 6| Step: 9
Training loss: 1.5839074850082397
Validation loss: 1.9411695913601947

Epoch: 6| Step: 10
Training loss: 1.445739507675171
Validation loss: 1.9551370515618274

Epoch: 6| Step: 11
Training loss: 1.4317681789398193
Validation loss: 1.9279298295256913

Epoch: 6| Step: 12
Training loss: 1.2077192068099976
Validation loss: 1.960329237804618

Epoch: 6| Step: 13
Training loss: 1.554463267326355
Validation loss: 1.942039466673328

Epoch: 173| Step: 0
Training loss: 1.027003288269043
Validation loss: 1.9518639515804987

Epoch: 6| Step: 1
Training loss: 1.6456736326217651
Validation loss: 1.9782823093475834

Epoch: 6| Step: 2
Training loss: 1.2258052825927734
Validation loss: 2.004120103774532

Epoch: 6| Step: 3
Training loss: 1.3600718975067139
Validation loss: 1.9755567248149584

Epoch: 6| Step: 4
Training loss: 1.2966110706329346
Validation loss: 1.9809893382492887

Epoch: 6| Step: 5
Training loss: 1.9058189392089844
Validation loss: 2.011080729064121

Epoch: 6| Step: 6
Training loss: 1.060974359512329
Validation loss: 2.003589407090218

Epoch: 6| Step: 7
Training loss: 1.4183626174926758
Validation loss: 2.0525587681801087

Epoch: 6| Step: 8
Training loss: 1.0342191457748413
Validation loss: 2.0536841782190467

Epoch: 6| Step: 9
Training loss: 1.1514699459075928
Validation loss: 2.0572789022999425

Epoch: 6| Step: 10
Training loss: 1.3542349338531494
Validation loss: 2.0579197714405675

Epoch: 6| Step: 11
Training loss: 1.9421181678771973
Validation loss: 2.01301472930498

Epoch: 6| Step: 12
Training loss: 1.0118215084075928
Validation loss: 1.9554981082998297

Epoch: 6| Step: 13
Training loss: 1.1963961124420166
Validation loss: 1.9118328709756174

Epoch: 174| Step: 0
Training loss: 1.6234861612319946
Validation loss: 1.9075333610657723

Epoch: 6| Step: 1
Training loss: 1.2513611316680908
Validation loss: 1.9234833063617829

Epoch: 6| Step: 2
Training loss: 1.6592915058135986
Validation loss: 1.9398371993854482

Epoch: 6| Step: 3
Training loss: 1.7032501697540283
Validation loss: 1.9794932052653322

Epoch: 6| Step: 4
Training loss: 1.0589278936386108
Validation loss: 1.9900306963151502

Epoch: 6| Step: 5
Training loss: 0.7223252058029175
Validation loss: 2.031149055368157

Epoch: 6| Step: 6
Training loss: 1.2216650247573853
Validation loss: 2.0417570734536774

Epoch: 6| Step: 7
Training loss: 0.6880803108215332
Validation loss: 2.048368407833961

Epoch: 6| Step: 8
Training loss: 1.5600733757019043
Validation loss: 2.024292460051916

Epoch: 6| Step: 9
Training loss: 1.3026959896087646
Validation loss: 1.9616946776707966

Epoch: 6| Step: 10
Training loss: 1.414705753326416
Validation loss: 1.945616287569846

Epoch: 6| Step: 11
Training loss: 1.614699125289917
Validation loss: 1.923412916480854

Epoch: 6| Step: 12
Training loss: 1.5157462358474731
Validation loss: 1.927603534472886

Epoch: 6| Step: 13
Training loss: 0.9818273186683655
Validation loss: 1.9249409565361597

Epoch: 175| Step: 0
Training loss: 1.397442102432251
Validation loss: 1.9198721531898744

Epoch: 6| Step: 1
Training loss: 1.5643093585968018
Validation loss: 1.9230478630271008

Epoch: 6| Step: 2
Training loss: 1.4697282314300537
Validation loss: 1.9462070849633986

Epoch: 6| Step: 3
Training loss: 1.2568867206573486
Validation loss: 1.9242433706919353

Epoch: 6| Step: 4
Training loss: 0.9944789409637451
Validation loss: 1.9218466922801027

Epoch: 6| Step: 5
Training loss: 1.3676016330718994
Validation loss: 1.9361808146199873

Epoch: 6| Step: 6
Training loss: 0.9394605159759521
Validation loss: 1.9415491819381714

Epoch: 6| Step: 7
Training loss: 1.234675645828247
Validation loss: 1.9501546070139895

Epoch: 6| Step: 8
Training loss: 1.976086139678955
Validation loss: 1.9892843538714993

Epoch: 6| Step: 9
Training loss: 1.1141157150268555
Validation loss: 2.0402419567108154

Epoch: 6| Step: 10
Training loss: 1.4937682151794434
Validation loss: 2.046180978898079

Epoch: 6| Step: 11
Training loss: 0.9909418821334839
Validation loss: 2.0464126986842

Epoch: 6| Step: 12
Training loss: 1.0541445016860962
Validation loss: 2.090515817365339

Epoch: 6| Step: 13
Training loss: 0.9879395961761475
Validation loss: 2.074165895421018

Epoch: 176| Step: 0
Training loss: 1.203158974647522
Validation loss: 2.046372082925612

Epoch: 6| Step: 1
Training loss: 1.0161093473434448
Validation loss: 1.9840109732843214

Epoch: 6| Step: 2
Training loss: 1.5513617992401123
Validation loss: 1.9596037774957635

Epoch: 6| Step: 3
Training loss: 1.2467827796936035
Validation loss: 1.9221884025040494

Epoch: 6| Step: 4
Training loss: 1.4687271118164062
Validation loss: 1.9245370818722634

Epoch: 6| Step: 5
Training loss: 1.6736626625061035
Validation loss: 1.9249763347769295

Epoch: 6| Step: 6
Training loss: 1.0467581748962402
Validation loss: 1.9208162420539445

Epoch: 6| Step: 7
Training loss: 1.0759074687957764
Validation loss: 1.9221458640149844

Epoch: 6| Step: 8
Training loss: 1.292323112487793
Validation loss: 1.942862569644887

Epoch: 6| Step: 9
Training loss: 1.3667035102844238
Validation loss: 1.9208112147546583

Epoch: 6| Step: 10
Training loss: 1.673112154006958
Validation loss: 1.9405233321651336

Epoch: 6| Step: 11
Training loss: 1.6403874158859253
Validation loss: 1.9972087208942702

Epoch: 6| Step: 12
Training loss: 1.014669418334961
Validation loss: 2.085650490176293

Epoch: 6| Step: 13
Training loss: 0.6108199954032898
Validation loss: 2.0896467290898806

Epoch: 177| Step: 0
Training loss: 1.0843186378479004
Validation loss: 2.0937716525088073

Epoch: 6| Step: 1
Training loss: 1.049617052078247
Validation loss: 2.03499279099126

Epoch: 6| Step: 2
Training loss: 1.8278779983520508
Validation loss: 1.9809125905395837

Epoch: 6| Step: 3
Training loss: 1.1686455011367798
Validation loss: 1.902969338560617

Epoch: 6| Step: 4
Training loss: 1.552436113357544
Validation loss: 1.8325940357741488

Epoch: 6| Step: 5
Training loss: 1.495102882385254
Validation loss: 1.8272110851862098

Epoch: 6| Step: 6
Training loss: 1.0634641647338867
Validation loss: 1.8334413741224556

Epoch: 6| Step: 7
Training loss: 1.134728193283081
Validation loss: 1.8830103284569197

Epoch: 6| Step: 8
Training loss: 2.240704298019409
Validation loss: 1.8931669868448728

Epoch: 6| Step: 9
Training loss: 1.4717230796813965
Validation loss: 1.8996158158907326

Epoch: 6| Step: 10
Training loss: 1.1980345249176025
Validation loss: 1.9155039479655604

Epoch: 6| Step: 11
Training loss: 0.5470435619354248
Validation loss: 1.9417537822518298

Epoch: 6| Step: 12
Training loss: 1.6980178356170654
Validation loss: 1.9815893352672618

Epoch: 6| Step: 13
Training loss: 1.1256296634674072
Validation loss: 2.017966357610559

Epoch: 178| Step: 0
Training loss: 1.0500109195709229
Validation loss: 2.091336668178599

Epoch: 6| Step: 1
Training loss: 1.086495280265808
Validation loss: 2.127514498208159

Epoch: 6| Step: 2
Training loss: 1.2931888103485107
Validation loss: 2.166135012462575

Epoch: 6| Step: 3
Training loss: 1.6032558679580688
Validation loss: 2.142754864949052

Epoch: 6| Step: 4
Training loss: 1.6581038236618042
Validation loss: 2.04511627715121

Epoch: 6| Step: 5
Training loss: 1.459487795829773
Validation loss: 1.9796846297479445

Epoch: 6| Step: 6
Training loss: 1.363760232925415
Validation loss: 1.9437276906864618

Epoch: 6| Step: 7
Training loss: 1.1344414949417114
Validation loss: 1.8988761594218593

Epoch: 6| Step: 8
Training loss: 1.8027279376983643
Validation loss: 1.8895381753162672

Epoch: 6| Step: 9
Training loss: 1.5325486660003662
Validation loss: 1.8735938892569592

Epoch: 6| Step: 10
Training loss: 0.8761588335037231
Validation loss: 1.8482437928517659

Epoch: 6| Step: 11
Training loss: 1.1813559532165527
Validation loss: 1.8456043556172361

Epoch: 6| Step: 12
Training loss: 0.9220143556594849
Validation loss: 1.8486630096230456

Epoch: 6| Step: 13
Training loss: 0.985271155834198
Validation loss: 1.8465466422419394

Epoch: 179| Step: 0
Training loss: 0.5860309600830078
Validation loss: 1.8672076502153951

Epoch: 6| Step: 1
Training loss: 1.194227933883667
Validation loss: 1.8817421543982722

Epoch: 6| Step: 2
Training loss: 1.3708362579345703
Validation loss: 1.9366484072900587

Epoch: 6| Step: 3
Training loss: 1.4827756881713867
Validation loss: 1.9568778007261214

Epoch: 6| Step: 4
Training loss: 1.3688304424285889
Validation loss: 1.9791827791480607

Epoch: 6| Step: 5
Training loss: 1.3133759498596191
Validation loss: 1.9864436272651917

Epoch: 6| Step: 6
Training loss: 1.2261874675750732
Validation loss: 1.9845010260100007

Epoch: 6| Step: 7
Training loss: 1.6424020528793335
Validation loss: 1.9928078792428459

Epoch: 6| Step: 8
Training loss: 1.5929346084594727
Validation loss: 1.984720265993508

Epoch: 6| Step: 9
Training loss: 1.4431287050247192
Validation loss: 1.9800829182388962

Epoch: 6| Step: 10
Training loss: 0.7944564819335938
Validation loss: 1.988736480794927

Epoch: 6| Step: 11
Training loss: 0.8314751386642456
Validation loss: 1.954339232496036

Epoch: 6| Step: 12
Training loss: 1.2172930240631104
Validation loss: 1.9278721963205645

Epoch: 6| Step: 13
Training loss: 1.2260234355926514
Validation loss: 1.9047511187932824

Epoch: 180| Step: 0
Training loss: 1.1668890714645386
Validation loss: 1.9170599009401055

Epoch: 6| Step: 1
Training loss: 1.2684593200683594
Validation loss: 1.9674111425235707

Epoch: 6| Step: 2
Training loss: 1.4487384557724
Validation loss: 1.996212492706955

Epoch: 6| Step: 3
Training loss: 0.625461220741272
Validation loss: 2.012917894189076

Epoch: 6| Step: 4
Training loss: 0.972169041633606
Validation loss: 1.9990745026578185

Epoch: 6| Step: 5
Training loss: 1.0393171310424805
Validation loss: 2.057411548911884

Epoch: 6| Step: 6
Training loss: 1.6815520524978638
Validation loss: 2.0996816465931554

Epoch: 6| Step: 7
Training loss: 1.686916708946228
Validation loss: 2.0909843342278593

Epoch: 6| Step: 8
Training loss: 0.8589857816696167
Validation loss: 2.0215711849991993

Epoch: 6| Step: 9
Training loss: 1.2329174280166626
Validation loss: 2.019941550429149

Epoch: 6| Step: 10
Training loss: 1.2976570129394531
Validation loss: 1.9716158913027855

Epoch: 6| Step: 11
Training loss: 1.4237569570541382
Validation loss: 1.9327313015537877

Epoch: 6| Step: 12
Training loss: 1.6462875604629517
Validation loss: 1.9381321873716129

Epoch: 6| Step: 13
Training loss: 1.0349940061569214
Validation loss: 1.8830404127797773

Epoch: 181| Step: 0
Training loss: 0.9018698930740356
Validation loss: 1.9080737918935797

Epoch: 6| Step: 1
Training loss: 1.0544474124908447
Validation loss: 1.9019597115055207

Epoch: 6| Step: 2
Training loss: 0.7772977948188782
Validation loss: 1.8682279689337618

Epoch: 6| Step: 3
Training loss: 1.2093188762664795
Validation loss: 1.908016639371072

Epoch: 6| Step: 4
Training loss: 1.7922465801239014
Validation loss: 1.8816715325078657

Epoch: 6| Step: 5
Training loss: 1.2313899993896484
Validation loss: 1.9250590762784403

Epoch: 6| Step: 6
Training loss: 1.2518742084503174
Validation loss: 1.9495685536374328

Epoch: 6| Step: 7
Training loss: 1.2262139320373535
Validation loss: 2.001826787507662

Epoch: 6| Step: 8
Training loss: 1.0792384147644043
Validation loss: 2.03129804518915

Epoch: 6| Step: 9
Training loss: 1.2233942747116089
Validation loss: 2.0685667581455682

Epoch: 6| Step: 10
Training loss: 1.2380869388580322
Validation loss: 2.116524765568395

Epoch: 6| Step: 11
Training loss: 1.6966506242752075
Validation loss: 2.1288821158870572

Epoch: 6| Step: 12
Training loss: 1.0595088005065918
Validation loss: 2.0699875111220987

Epoch: 6| Step: 13
Training loss: 1.4356681108474731
Validation loss: 2.0405424666661087

Epoch: 182| Step: 0
Training loss: 0.8651938438415527
Validation loss: 1.9911759822599349

Epoch: 6| Step: 1
Training loss: 1.3561851978302002
Validation loss: 1.9226047249250515

Epoch: 6| Step: 2
Training loss: 1.378159761428833
Validation loss: 1.870522161965729

Epoch: 6| Step: 3
Training loss: 1.1167845726013184
Validation loss: 1.8385002138794109

Epoch: 6| Step: 4
Training loss: 1.4234435558319092
Validation loss: 1.8273141114942488

Epoch: 6| Step: 5
Training loss: 1.3999632596969604
Validation loss: 1.8254736008182648

Epoch: 6| Step: 6
Training loss: 1.1880474090576172
Validation loss: 1.7936097909045476

Epoch: 6| Step: 7
Training loss: 1.2247517108917236
Validation loss: 1.8283629750692716

Epoch: 6| Step: 8
Training loss: 0.9679845571517944
Validation loss: 1.8568568434766544

Epoch: 6| Step: 9
Training loss: 1.4307538270950317
Validation loss: 1.8628351432020946

Epoch: 6| Step: 10
Training loss: 0.8502289652824402
Validation loss: 1.8742929940582604

Epoch: 6| Step: 11
Training loss: 1.6159300804138184
Validation loss: 1.8655813458145305

Epoch: 6| Step: 12
Training loss: 1.2310898303985596
Validation loss: 1.9033263652555403

Epoch: 6| Step: 13
Training loss: 1.2486740350723267
Validation loss: 1.9092243704744565

Epoch: 183| Step: 0
Training loss: 1.2736742496490479
Validation loss: 1.911816127838627

Epoch: 6| Step: 1
Training loss: 1.3952713012695312
Validation loss: 1.9194717484135781

Epoch: 6| Step: 2
Training loss: 1.5729533433914185
Validation loss: 1.9667062708126601

Epoch: 6| Step: 3
Training loss: 1.502199411392212
Validation loss: 1.9846023103242278

Epoch: 6| Step: 4
Training loss: 1.1378960609436035
Validation loss: 2.0580663886121524

Epoch: 6| Step: 5
Training loss: 0.966522216796875
Validation loss: 2.038335286160951

Epoch: 6| Step: 6
Training loss: 1.4557303190231323
Validation loss: 1.9798142269093504

Epoch: 6| Step: 7
Training loss: 1.745646595954895
Validation loss: 1.9367686638268091

Epoch: 6| Step: 8
Training loss: 0.5392838716506958
Validation loss: 1.8960279572394587

Epoch: 6| Step: 9
Training loss: 0.8814905881881714
Validation loss: 1.846386468538674

Epoch: 6| Step: 10
Training loss: 0.9705774784088135
Validation loss: 1.8386461529680478

Epoch: 6| Step: 11
Training loss: 1.5221730470657349
Validation loss: 1.8477713920736825

Epoch: 6| Step: 12
Training loss: 1.2081871032714844
Validation loss: 1.8658835195725965

Epoch: 6| Step: 13
Training loss: 0.8118851184844971
Validation loss: 1.9243233460252003

Epoch: 184| Step: 0
Training loss: 1.1418981552124023
Validation loss: 1.9489851536289338

Epoch: 6| Step: 1
Training loss: 0.9193747043609619
Validation loss: 1.976762971570415

Epoch: 6| Step: 2
Training loss: 1.3860342502593994
Validation loss: 1.9632406375741447

Epoch: 6| Step: 3
Training loss: 1.4591161012649536
Validation loss: 1.9993718721533333

Epoch: 6| Step: 4
Training loss: 1.4962329864501953
Validation loss: 1.9391212796652189

Epoch: 6| Step: 5
Training loss: 0.8234032392501831
Validation loss: 1.9246226728603404

Epoch: 6| Step: 6
Training loss: 1.1198574304580688
Validation loss: 1.9071076172654347

Epoch: 6| Step: 7
Training loss: 1.0626050233840942
Validation loss: 1.9124320924922984

Epoch: 6| Step: 8
Training loss: 0.8203945159912109
Validation loss: 1.8860573563524472

Epoch: 6| Step: 9
Training loss: 1.4745426177978516
Validation loss: 1.913523986775388

Epoch: 6| Step: 10
Training loss: 1.3576847314834595
Validation loss: 1.9555006668131838

Epoch: 6| Step: 11
Training loss: 1.2653473615646362
Validation loss: 1.942248555921739

Epoch: 6| Step: 12
Training loss: 1.310808777809143
Validation loss: 1.9815276566372122

Epoch: 6| Step: 13
Training loss: 1.0575909614562988
Validation loss: 1.9463811741080335

Epoch: 185| Step: 0
Training loss: 1.1705474853515625
Validation loss: 1.9694612487669914

Epoch: 6| Step: 1
Training loss: 0.8928103446960449
Validation loss: 1.960128088151255

Epoch: 6| Step: 2
Training loss: 1.1936008930206299
Validation loss: 1.9291170258675852

Epoch: 6| Step: 3
Training loss: 1.1438753604888916
Validation loss: 1.866686414646846

Epoch: 6| Step: 4
Training loss: 1.170987844467163
Validation loss: 1.8413273185812018

Epoch: 6| Step: 5
Training loss: 0.8029475212097168
Validation loss: 1.773874153373062

Epoch: 6| Step: 6
Training loss: 1.5221813917160034
Validation loss: 1.7540196923799412

Epoch: 6| Step: 7
Training loss: 1.2504318952560425
Validation loss: 1.7217266290418562

Epoch: 6| Step: 8
Training loss: 1.329075574874878
Validation loss: 1.71705828174468

Epoch: 6| Step: 9
Training loss: 1.3324685096740723
Validation loss: 1.7556701039755216

Epoch: 6| Step: 10
Training loss: 1.2224689722061157
Validation loss: 1.8023736476898193

Epoch: 6| Step: 11
Training loss: 1.5517363548278809
Validation loss: 1.8575127919514973

Epoch: 6| Step: 12
Training loss: 1.1685874462127686
Validation loss: 1.8930722257142425

Epoch: 6| Step: 13
Training loss: 1.769623041152954
Validation loss: 1.9030918818648144

Epoch: 186| Step: 0
Training loss: 1.2485785484313965
Validation loss: 1.9254938126892172

Epoch: 6| Step: 1
Training loss: 1.7168442010879517
Validation loss: 1.95288255394146

Epoch: 6| Step: 2
Training loss: 1.512778639793396
Validation loss: 1.919237849532917

Epoch: 6| Step: 3
Training loss: 1.2908821105957031
Validation loss: 1.890707290300759

Epoch: 6| Step: 4
Training loss: 0.5701994895935059
Validation loss: 1.8903162043581727

Epoch: 6| Step: 5
Training loss: 1.2176371812820435
Validation loss: 1.8592774624465613

Epoch: 6| Step: 6
Training loss: 1.0722837448120117
Validation loss: 1.8288097330318984

Epoch: 6| Step: 7
Training loss: 0.7027343511581421
Validation loss: 1.8234226844644035

Epoch: 6| Step: 8
Training loss: 1.039406657218933
Validation loss: 1.819369141773511

Epoch: 6| Step: 9
Training loss: 1.3391481637954712
Validation loss: 1.8271266080999886

Epoch: 6| Step: 10
Training loss: 1.3778742551803589
Validation loss: 1.8934683722834433

Epoch: 6| Step: 11
Training loss: 1.0058236122131348
Validation loss: 1.9404515771455662

Epoch: 6| Step: 12
Training loss: 1.1017742156982422
Validation loss: 1.9528777624971123

Epoch: 6| Step: 13
Training loss: 1.1919149160385132
Validation loss: 2.0163330147343297

Epoch: 187| Step: 0
Training loss: 0.9355482459068298
Validation loss: 2.026845259051169

Epoch: 6| Step: 1
Training loss: 1.2317304611206055
Validation loss: 2.0565726423776276

Epoch: 6| Step: 2
Training loss: 1.1144005060195923
Validation loss: 2.0357936569439468

Epoch: 6| Step: 3
Training loss: 0.7707990407943726
Validation loss: 2.0477982464657036

Epoch: 6| Step: 4
Training loss: 1.6530261039733887
Validation loss: 2.025347722473965

Epoch: 6| Step: 5
Training loss: 1.0749276876449585
Validation loss: 1.9738814997416672

Epoch: 6| Step: 6
Training loss: 1.3130559921264648
Validation loss: 1.9637789418620448

Epoch: 6| Step: 7
Training loss: 0.6990019083023071
Validation loss: 1.9279753200469478

Epoch: 6| Step: 8
Training loss: 1.3878412246704102
Validation loss: 1.8698226687728718

Epoch: 6| Step: 9
Training loss: 1.132528305053711
Validation loss: 1.8260053191133725

Epoch: 6| Step: 10
Training loss: 1.1532163619995117
Validation loss: 1.7950219018484956

Epoch: 6| Step: 11
Training loss: 1.4153493642807007
Validation loss: 1.8064631621042888

Epoch: 6| Step: 12
Training loss: 0.7864934206008911
Validation loss: 1.7908911474289433

Epoch: 6| Step: 13
Training loss: 1.564808964729309
Validation loss: 1.7853531094007595

Epoch: 188| Step: 0
Training loss: 1.4284937381744385
Validation loss: 1.8207516170317126

Epoch: 6| Step: 1
Training loss: 0.8517732620239258
Validation loss: 1.8622621349109116

Epoch: 6| Step: 2
Training loss: 1.3244044780731201
Validation loss: 1.8387259257737028

Epoch: 6| Step: 3
Training loss: 0.9529538154602051
Validation loss: 1.8691611392523653

Epoch: 6| Step: 4
Training loss: 0.7683500647544861
Validation loss: 1.8611271150650517

Epoch: 6| Step: 5
Training loss: 0.43108657002449036
Validation loss: 1.9642702161624868

Epoch: 6| Step: 6
Training loss: 1.0248743295669556
Validation loss: 1.97479235997764

Epoch: 6| Step: 7
Training loss: 1.1948542594909668
Validation loss: 2.004914119679441

Epoch: 6| Step: 8
Training loss: 1.5466375350952148
Validation loss: 2.009033738925893

Epoch: 6| Step: 9
Training loss: 0.9664041996002197
Validation loss: 2.0558433353259997

Epoch: 6| Step: 10
Training loss: 0.9092991352081299
Validation loss: 2.0105782170449533

Epoch: 6| Step: 11
Training loss: 1.755176067352295
Validation loss: 1.9847531985211115

Epoch: 6| Step: 12
Training loss: 1.2839572429656982
Validation loss: 1.930176188868861

Epoch: 6| Step: 13
Training loss: 1.3309780359268188
Validation loss: 1.8948435885931856

Epoch: 189| Step: 0
Training loss: 1.2213711738586426
Validation loss: 1.848313029094409

Epoch: 6| Step: 1
Training loss: 1.4733777046203613
Validation loss: 1.8259122640855852

Epoch: 6| Step: 2
Training loss: 1.1141315698623657
Validation loss: 1.853074578828709

Epoch: 6| Step: 3
Training loss: 0.7562286853790283
Validation loss: 1.857979073319384

Epoch: 6| Step: 4
Training loss: 0.9208238124847412
Validation loss: 1.8812768343956239

Epoch: 6| Step: 5
Training loss: 1.1242231130599976
Validation loss: 1.8793014249493998

Epoch: 6| Step: 6
Training loss: 1.2242798805236816
Validation loss: 1.9551422083249657

Epoch: 6| Step: 7
Training loss: 1.3933136463165283
Validation loss: 1.9897394962208246

Epoch: 6| Step: 8
Training loss: 1.166137933731079
Validation loss: 2.00039812057249

Epoch: 6| Step: 9
Training loss: 1.2998234033584595
Validation loss: 1.9961048403093893

Epoch: 6| Step: 10
Training loss: 0.6253175139427185
Validation loss: 1.9733045690803117

Epoch: 6| Step: 11
Training loss: 1.326935887336731
Validation loss: 1.930100356378863

Epoch: 6| Step: 12
Training loss: 1.303610920906067
Validation loss: 1.9034298658370972

Epoch: 6| Step: 13
Training loss: 0.35023272037506104
Validation loss: 1.904305729814755

Epoch: 190| Step: 0
Training loss: 0.7166728973388672
Validation loss: 1.8496878557307745

Epoch: 6| Step: 1
Training loss: 0.958219051361084
Validation loss: 1.8710231960460704

Epoch: 6| Step: 2
Training loss: 1.4954231977462769
Validation loss: 1.8440915153872581

Epoch: 6| Step: 3
Training loss: 0.7634066343307495
Validation loss: 1.8367466913756503

Epoch: 6| Step: 4
Training loss: 1.111518144607544
Validation loss: 1.8447245244056947

Epoch: 6| Step: 5
Training loss: 0.9274073839187622
Validation loss: 1.8537114051080519

Epoch: 6| Step: 6
Training loss: 0.8540452718734741
Validation loss: 1.855875410059447

Epoch: 6| Step: 7
Training loss: 0.8282812237739563
Validation loss: 1.8883438892261957

Epoch: 6| Step: 8
Training loss: 1.2701970338821411
Validation loss: 1.9213130743272844

Epoch: 6| Step: 9
Training loss: 1.4548423290252686
Validation loss: 1.9376169199584632

Epoch: 6| Step: 10
Training loss: 1.5818257331848145
Validation loss: 1.9393268426259358

Epoch: 6| Step: 11
Training loss: 0.9842195510864258
Validation loss: 1.901946461328896

Epoch: 6| Step: 12
Training loss: 0.8965138792991638
Validation loss: 1.8728290014369513

Epoch: 6| Step: 13
Training loss: 1.1412007808685303
Validation loss: 1.8034649036263908

Epoch: 191| Step: 0
Training loss: 0.8610419034957886
Validation loss: 1.7714695571571268

Epoch: 6| Step: 1
Training loss: 1.1470867395401
Validation loss: 1.8252121325462096

Epoch: 6| Step: 2
Training loss: 1.9407258033752441
Validation loss: 1.8238125270412815

Epoch: 6| Step: 3
Training loss: 1.3534088134765625
Validation loss: 1.8532158828550769

Epoch: 6| Step: 4
Training loss: 0.926833987236023
Validation loss: 1.8552895412650159

Epoch: 6| Step: 5
Training loss: 1.1148169040679932
Validation loss: 1.8576261458858367

Epoch: 6| Step: 6
Training loss: 0.92876136302948
Validation loss: 1.8843874239152478

Epoch: 6| Step: 7
Training loss: 1.0868470668792725
Validation loss: 1.9204494337881766

Epoch: 6| Step: 8
Training loss: 0.5759785175323486
Validation loss: 1.8874506642741542

Epoch: 6| Step: 9
Training loss: 0.9192390441894531
Validation loss: 1.9252554267965338

Epoch: 6| Step: 10
Training loss: 1.0904016494750977
Validation loss: 1.9136735072699926

Epoch: 6| Step: 11
Training loss: 0.6938738822937012
Validation loss: 1.924761071000048

Epoch: 6| Step: 12
Training loss: 1.3146977424621582
Validation loss: 1.8845677606521114

Epoch: 6| Step: 13
Training loss: 1.1271626949310303
Validation loss: 1.8514432240557928

Epoch: 192| Step: 0
Training loss: 0.7109174728393555
Validation loss: 1.8443026875936857

Epoch: 6| Step: 1
Training loss: 0.7988698482513428
Validation loss: 1.854823999507453

Epoch: 6| Step: 2
Training loss: 1.1991865634918213
Validation loss: 1.8476626052651355

Epoch: 6| Step: 3
Training loss: 0.9356582164764404
Validation loss: 1.8171809155453917

Epoch: 6| Step: 4
Training loss: 1.5077183246612549
Validation loss: 1.8226521527895363

Epoch: 6| Step: 5
Training loss: 1.2037084102630615
Validation loss: 1.8314574008346887

Epoch: 6| Step: 6
Training loss: 1.3032865524291992
Validation loss: 1.8229387165397726

Epoch: 6| Step: 7
Training loss: 0.9399381279945374
Validation loss: 1.8507057518087409

Epoch: 6| Step: 8
Training loss: 1.401914358139038
Validation loss: 1.8828474501127839

Epoch: 6| Step: 9
Training loss: 1.0457334518432617
Validation loss: 1.8818476456467823

Epoch: 6| Step: 10
Training loss: 0.9290702939033508
Validation loss: 1.9258883871057981

Epoch: 6| Step: 11
Training loss: 0.8662809133529663
Validation loss: 1.9218630944528887

Epoch: 6| Step: 12
Training loss: 0.8484980463981628
Validation loss: 1.8951081563067693

Epoch: 6| Step: 13
Training loss: 1.0725739002227783
Validation loss: 1.9181866517630957

Epoch: 193| Step: 0
Training loss: 1.3862594366073608
Validation loss: 1.9261866820755826

Epoch: 6| Step: 1
Training loss: 0.857445240020752
Validation loss: 1.932652355522238

Epoch: 6| Step: 2
Training loss: 1.3507931232452393
Validation loss: 1.9053475331234675

Epoch: 6| Step: 3
Training loss: 1.1307406425476074
Validation loss: 1.8893742971522833

Epoch: 6| Step: 4
Training loss: 0.6978629231452942
Validation loss: 1.8929345261666082

Epoch: 6| Step: 5
Training loss: 1.5648667812347412
Validation loss: 1.9102104581812376

Epoch: 6| Step: 6
Training loss: 0.7739720344543457
Validation loss: 1.887160808809342

Epoch: 6| Step: 7
Training loss: 0.6665812134742737
Validation loss: 1.8859753019066268

Epoch: 6| Step: 8
Training loss: 0.9701114892959595
Validation loss: 1.8134675025939941

Epoch: 6| Step: 9
Training loss: 1.0282151699066162
Validation loss: 1.8035433625662198

Epoch: 6| Step: 10
Training loss: 1.3992490768432617
Validation loss: 1.7949286789022467

Epoch: 6| Step: 11
Training loss: 0.714028537273407
Validation loss: 1.7496935039438226

Epoch: 6| Step: 12
Training loss: 1.1558212041854858
Validation loss: 1.7441287373983732

Epoch: 6| Step: 13
Training loss: 0.6706851124763489
Validation loss: 1.7483144152549006

Epoch: 194| Step: 0
Training loss: 1.0178192853927612
Validation loss: 1.7607103240105413

Epoch: 6| Step: 1
Training loss: 1.3061842918395996
Validation loss: 1.780066095372682

Epoch: 6| Step: 2
Training loss: 0.8235843181610107
Validation loss: 1.7923767707681144

Epoch: 6| Step: 3
Training loss: 0.939909040927887
Validation loss: 1.8330937995705554

Epoch: 6| Step: 4
Training loss: 0.970108151435852
Validation loss: 1.8622209307967976

Epoch: 6| Step: 5
Training loss: 1.0597805976867676
Validation loss: 1.9366736463321153

Epoch: 6| Step: 6
Training loss: 1.4830701351165771
Validation loss: 1.9590736704487954

Epoch: 6| Step: 7
Training loss: 1.079979419708252
Validation loss: 1.9398198743020334

Epoch: 6| Step: 8
Training loss: 1.1521800756454468
Validation loss: 1.910379417480961

Epoch: 6| Step: 9
Training loss: 0.8031840324401855
Validation loss: 1.8750242199949039

Epoch: 6| Step: 10
Training loss: 1.084747076034546
Validation loss: 1.8325642078153548

Epoch: 6| Step: 11
Training loss: 0.6216346025466919
Validation loss: 1.8275712843864196

Epoch: 6| Step: 12
Training loss: 1.249547004699707
Validation loss: 1.7922862986082673

Epoch: 6| Step: 13
Training loss: 0.6961753368377686
Validation loss: 1.7903862396876018

Epoch: 195| Step: 0
Training loss: 1.045142650604248
Validation loss: 1.8087347656167962

Epoch: 6| Step: 1
Training loss: 0.9238216876983643
Validation loss: 1.7970509234295096

Epoch: 6| Step: 2
Training loss: 0.8896256685256958
Validation loss: 1.8340371590788647

Epoch: 6| Step: 3
Training loss: 1.228393316268921
Validation loss: 1.893381246956446

Epoch: 6| Step: 4
Training loss: 1.145485281944275
Validation loss: 1.9000150131922897

Epoch: 6| Step: 5
Training loss: 1.4284802675247192
Validation loss: 1.8756686461869108

Epoch: 6| Step: 6
Training loss: 1.0243380069732666
Validation loss: 1.876358752609581

Epoch: 6| Step: 7
Training loss: 1.1145979166030884
Validation loss: 1.8596580342579914

Epoch: 6| Step: 8
Training loss: 0.6921591758728027
Validation loss: 1.8841780244663198

Epoch: 6| Step: 9
Training loss: 0.6264028549194336
Validation loss: 1.8107413168876403

Epoch: 6| Step: 10
Training loss: 1.298017978668213
Validation loss: 1.823889172205361

Epoch: 6| Step: 11
Training loss: 0.8564865589141846
Validation loss: 1.7808723821434924

Epoch: 6| Step: 12
Training loss: 1.0456606149673462
Validation loss: 1.7394270602092947

Epoch: 6| Step: 13
Training loss: 0.6887317895889282
Validation loss: 1.7696430196044266

Epoch: 196| Step: 0
Training loss: 1.048295021057129
Validation loss: 1.772538520956552

Epoch: 6| Step: 1
Training loss: 0.9096540808677673
Validation loss: 1.8159075860054261

Epoch: 6| Step: 2
Training loss: 0.6428596377372742
Validation loss: 1.843379424464318

Epoch: 6| Step: 3
Training loss: 1.4959073066711426
Validation loss: 1.8766400942238428

Epoch: 6| Step: 4
Training loss: 0.9846312999725342
Validation loss: 1.8987450740670646

Epoch: 6| Step: 5
Training loss: 0.6418893337249756
Validation loss: 1.936553926878078

Epoch: 6| Step: 6
Training loss: 1.5089999437332153
Validation loss: 1.9176857215102001

Epoch: 6| Step: 7
Training loss: 0.6613510847091675
Validation loss: 1.9303874328572264

Epoch: 6| Step: 8
Training loss: 0.5360034108161926
Validation loss: 1.9221440438301332

Epoch: 6| Step: 9
Training loss: 1.1780507564544678
Validation loss: 1.9128730156088387

Epoch: 6| Step: 10
Training loss: 0.7055048942565918
Validation loss: 1.8889123188552035

Epoch: 6| Step: 11
Training loss: 1.342521071434021
Validation loss: 1.8874026524123324

Epoch: 6| Step: 12
Training loss: 1.2322535514831543
Validation loss: 1.866236711061129

Epoch: 6| Step: 13
Training loss: 1.0826380252838135
Validation loss: 1.8181403452350247

Epoch: 197| Step: 0
Training loss: 1.055780053138733
Validation loss: 1.8389367172794957

Epoch: 6| Step: 1
Training loss: 0.6702873110771179
Validation loss: 1.8620828249121224

Epoch: 6| Step: 2
Training loss: 1.1617388725280762
Validation loss: 1.8578083463894424

Epoch: 6| Step: 3
Training loss: 0.972623348236084
Validation loss: 1.8813977600425802

Epoch: 6| Step: 4
Training loss: 1.0260899066925049
Validation loss: 1.8956625051395868

Epoch: 6| Step: 5
Training loss: 1.3413350582122803
Validation loss: 1.8751156458290674

Epoch: 6| Step: 6
Training loss: 0.4164023995399475
Validation loss: 1.8221177503626833

Epoch: 6| Step: 7
Training loss: 0.8205404281616211
Validation loss: 1.827803946310474

Epoch: 6| Step: 8
Training loss: 0.6809144020080566
Validation loss: 1.824413744352197

Epoch: 6| Step: 9
Training loss: 1.1135069131851196
Validation loss: 1.8204791815050188

Epoch: 6| Step: 10
Training loss: 0.9484364986419678
Validation loss: 1.8227768021245156

Epoch: 6| Step: 11
Training loss: 1.2864453792572021
Validation loss: 1.8396595267839329

Epoch: 6| Step: 12
Training loss: 1.1838933229446411
Validation loss: 1.8356919775726974

Epoch: 6| Step: 13
Training loss: 0.7462272644042969
Validation loss: 1.8280526675203794

Epoch: 198| Step: 0
Training loss: 0.8282272815704346
Validation loss: 1.7828834915673861

Epoch: 6| Step: 1
Training loss: 0.5761392712593079
Validation loss: 1.788384986180131

Epoch: 6| Step: 2
Training loss: 0.990609884262085
Validation loss: 1.787723925805861

Epoch: 6| Step: 3
Training loss: 1.022779941558838
Validation loss: 1.8108575062085224

Epoch: 6| Step: 4
Training loss: 0.8448603749275208
Validation loss: 1.8308042198099115

Epoch: 6| Step: 5
Training loss: 0.919736385345459
Validation loss: 1.870425957505421

Epoch: 6| Step: 6
Training loss: 1.2605576515197754
Validation loss: 1.8975431239733132

Epoch: 6| Step: 7
Training loss: 1.1382733583450317
Validation loss: 1.9432849576396327

Epoch: 6| Step: 8
Training loss: 1.0001542568206787
Validation loss: 1.8822797882941462

Epoch: 6| Step: 9
Training loss: 0.9865726828575134
Validation loss: 1.8867075340722197

Epoch: 6| Step: 10
Training loss: 1.0118193626403809
Validation loss: 1.8530756786305418

Epoch: 6| Step: 11
Training loss: 0.7446084022521973
Validation loss: 1.8373138263661375

Epoch: 6| Step: 12
Training loss: 0.9546827077865601
Validation loss: 1.8062545881476453

Epoch: 6| Step: 13
Training loss: 1.0327399969100952
Validation loss: 1.7974775324585617

Epoch: 199| Step: 0
Training loss: 0.9429999589920044
Validation loss: 1.7849778821391444

Epoch: 6| Step: 1
Training loss: 0.788253664970398
Validation loss: 1.7795413540255638

Epoch: 6| Step: 2
Training loss: 1.100226879119873
Validation loss: 1.8051210552133539

Epoch: 6| Step: 3
Training loss: 1.167039394378662
Validation loss: 1.8552737248841153

Epoch: 6| Step: 4
Training loss: 0.47878497838974
Validation loss: 1.8768075537937943

Epoch: 6| Step: 5
Training loss: 0.6203262805938721
Validation loss: 1.907894031975859

Epoch: 6| Step: 6
Training loss: 1.1824535131454468
Validation loss: 1.8823318840355001

Epoch: 6| Step: 7
Training loss: 0.9718159437179565
Validation loss: 1.8849239528820079

Epoch: 6| Step: 8
Training loss: 0.8207813501358032
Validation loss: 1.8328261785609747

Epoch: 6| Step: 9
Training loss: 0.9041014909744263
Validation loss: 1.8129755476469636

Epoch: 6| Step: 10
Training loss: 1.2110440731048584
Validation loss: 1.8556877938649987

Epoch: 6| Step: 11
Training loss: 1.087134838104248
Validation loss: 1.8018409026566373

Epoch: 6| Step: 12
Training loss: 0.9823635816574097
Validation loss: 1.7773577103050806

Epoch: 6| Step: 13
Training loss: 0.5693284869194031
Validation loss: 1.734930843435308

Epoch: 200| Step: 0
Training loss: 0.88506019115448
Validation loss: 1.7369982452802761

Epoch: 6| Step: 1
Training loss: 1.199083924293518
Validation loss: 1.7487618564277567

Epoch: 6| Step: 2
Training loss: 1.02519953250885
Validation loss: 1.7519841014697988

Epoch: 6| Step: 3
Training loss: 0.8215108513832092
Validation loss: 1.7785988533368675

Epoch: 6| Step: 4
Training loss: 0.8502436876296997
Validation loss: 1.8331576547315043

Epoch: 6| Step: 5
Training loss: 0.9107203483581543
Validation loss: 1.9021275915125364

Epoch: 6| Step: 6
Training loss: 1.305501937866211
Validation loss: 1.9423040292596305

Epoch: 6| Step: 7
Training loss: 0.9420174360275269
Validation loss: 1.9359470772486862

Epoch: 6| Step: 8
Training loss: 0.7406408190727234
Validation loss: 1.9421178717767038

Epoch: 6| Step: 9
Training loss: 0.9340863227844238
Validation loss: 1.921645358044614

Epoch: 6| Step: 10
Training loss: 1.3246541023254395
Validation loss: 1.868070678044391

Epoch: 6| Step: 11
Training loss: 1.0110722780227661
Validation loss: 1.8364802457953011

Epoch: 6| Step: 12
Training loss: 0.5969018936157227
Validation loss: 1.7969031398014357

Epoch: 6| Step: 13
Training loss: 1.1942307949066162
Validation loss: 1.7762597414755052

Epoch: 201| Step: 0
Training loss: 1.0585243701934814
Validation loss: 1.7722343962679628

Epoch: 6| Step: 1
Training loss: 1.1019765138626099
Validation loss: 1.7524213252529022

Epoch: 6| Step: 2
Training loss: 0.9451956748962402
Validation loss: 1.7440460087150655

Epoch: 6| Step: 3
Training loss: 0.8124287724494934
Validation loss: 1.7701781718961653

Epoch: 6| Step: 4
Training loss: 0.47633492946624756
Validation loss: 1.8141867473561277

Epoch: 6| Step: 5
Training loss: 1.3790745735168457
Validation loss: 1.7986140815160607

Epoch: 6| Step: 6
Training loss: 0.6974502801895142
Validation loss: 1.874821339884112

Epoch: 6| Step: 7
Training loss: 0.8762654066085815
Validation loss: 1.8863565639782978

Epoch: 6| Step: 8
Training loss: 0.9678930640220642
Validation loss: 1.8949284886801114

Epoch: 6| Step: 9
Training loss: 0.8897775411605835
Validation loss: 1.8661365021941483

Epoch: 6| Step: 10
Training loss: 1.2194898128509521
Validation loss: 1.8520825447574738

Epoch: 6| Step: 11
Training loss: 0.6606251001358032
Validation loss: 1.8355764291619743

Epoch: 6| Step: 12
Training loss: 1.0655395984649658
Validation loss: 1.8011470994641703

Epoch: 6| Step: 13
Training loss: 1.1612679958343506
Validation loss: 1.8030427758411696

Epoch: 202| Step: 0
Training loss: 0.8920474648475647
Validation loss: 1.7864347939850183

Epoch: 6| Step: 1
Training loss: 0.7835659980773926
Validation loss: 1.7756961020090247

Epoch: 6| Step: 2
Training loss: 0.6863385438919067
Validation loss: 1.7796405649954272

Epoch: 6| Step: 3
Training loss: 1.164857029914856
Validation loss: 1.76948122824392

Epoch: 6| Step: 4
Training loss: 1.0301220417022705
Validation loss: 1.816413814021695

Epoch: 6| Step: 5
Training loss: 0.8234572410583496
Validation loss: 1.7956150372823079

Epoch: 6| Step: 6
Training loss: 0.9589307904243469
Validation loss: 1.8586944251932123

Epoch: 6| Step: 7
Training loss: 0.7208738923072815
Validation loss: 1.8661879416434997

Epoch: 6| Step: 8
Training loss: 0.881720781326294
Validation loss: 1.9875376737245949

Epoch: 6| Step: 9
Training loss: 1.2657805681228638
Validation loss: 2.0157030359391244

Epoch: 6| Step: 10
Training loss: 1.1461925506591797
Validation loss: 1.9685521343702912

Epoch: 6| Step: 11
Training loss: 1.1876659393310547
Validation loss: 1.9200118972409157

Epoch: 6| Step: 12
Training loss: 1.0235763788223267
Validation loss: 1.8507428182068693

Epoch: 6| Step: 13
Training loss: 0.8311619162559509
Validation loss: 1.7957727998815558

Epoch: 203| Step: 0
Training loss: 0.6999375820159912
Validation loss: 1.7842022065193421

Epoch: 6| Step: 1
Training loss: 1.2724542617797852
Validation loss: 1.7815358715672647

Epoch: 6| Step: 2
Training loss: 1.6303889751434326
Validation loss: 1.800378543074413

Epoch: 6| Step: 3
Training loss: 1.0000802278518677
Validation loss: 1.7901090204074819

Epoch: 6| Step: 4
Training loss: 0.4488697052001953
Validation loss: 1.8188116012081024

Epoch: 6| Step: 5
Training loss: 0.9672331809997559
Validation loss: 1.8271741456882928

Epoch: 6| Step: 6
Training loss: 0.9057295322418213
Validation loss: 1.8592183102843582

Epoch: 6| Step: 7
Training loss: 1.048156976699829
Validation loss: 1.905718711114699

Epoch: 6| Step: 8
Training loss: 0.5004708170890808
Validation loss: 1.919279675329885

Epoch: 6| Step: 9
Training loss: 1.1446226835250854
Validation loss: 1.9053554586184922

Epoch: 6| Step: 10
Training loss: 0.9774126410484314
Validation loss: 1.933560190662261

Epoch: 6| Step: 11
Training loss: 0.4493974447250366
Validation loss: 1.9333441962477982

Epoch: 6| Step: 12
Training loss: 1.2869236469268799
Validation loss: 1.9212588687096872

Epoch: 6| Step: 13
Training loss: 0.9498366117477417
Validation loss: 1.8639779962519163

Epoch: 204| Step: 0
Training loss: 0.6193550229072571
Validation loss: 1.8289357257145706

Epoch: 6| Step: 1
Training loss: 1.2319034337997437
Validation loss: 1.817547825074965

Epoch: 6| Step: 2
Training loss: 1.0203907489776611
Validation loss: 1.8007630173878004

Epoch: 6| Step: 3
Training loss: 0.6460581421852112
Validation loss: 1.812943507266301

Epoch: 6| Step: 4
Training loss: 0.7280094623565674
Validation loss: 1.7994597631116067

Epoch: 6| Step: 5
Training loss: 0.8243282437324524
Validation loss: 1.7948959232658468

Epoch: 6| Step: 6
Training loss: 0.6106975078582764
Validation loss: 1.8390469269085956

Epoch: 6| Step: 7
Training loss: 1.0572326183319092
Validation loss: 1.8215152217495827

Epoch: 6| Step: 8
Training loss: 0.805762529373169
Validation loss: 1.8124630912657707

Epoch: 6| Step: 9
Training loss: 1.0309232473373413
Validation loss: 1.8360195941822504

Epoch: 6| Step: 10
Training loss: 0.9715530872344971
Validation loss: 1.8271068193579232

Epoch: 6| Step: 11
Training loss: 1.2153449058532715
Validation loss: 1.8811940300849177

Epoch: 6| Step: 12
Training loss: 1.0341224670410156
Validation loss: 1.926312990086053

Epoch: 6| Step: 13
Training loss: 1.241027593612671
Validation loss: 1.9880164874497281

Epoch: 205| Step: 0
Training loss: 1.0649058818817139
Validation loss: 1.9779545722469207

Epoch: 6| Step: 1
Training loss: 1.1747103929519653
Validation loss: 1.940400456869474

Epoch: 6| Step: 2
Training loss: 0.49720701575279236
Validation loss: 1.8512147658614702

Epoch: 6| Step: 3
Training loss: 0.9832940101623535
Validation loss: 1.7865616800964519

Epoch: 6| Step: 4
Training loss: 0.6922426819801331
Validation loss: 1.7657212211239723

Epoch: 6| Step: 5
Training loss: 1.0985766649246216
Validation loss: 1.7434190332248647

Epoch: 6| Step: 6
Training loss: 0.5904301404953003
Validation loss: 1.7628095957540697

Epoch: 6| Step: 7
Training loss: 1.382685661315918
Validation loss: 1.7322589992195048

Epoch: 6| Step: 8
Training loss: 0.8380948901176453
Validation loss: 1.7640598192009875

Epoch: 6| Step: 9
Training loss: 0.9325945377349854
Validation loss: 1.8035803969188402

Epoch: 6| Step: 10
Training loss: 1.2064874172210693
Validation loss: 1.848704263728152

Epoch: 6| Step: 11
Training loss: 1.0325148105621338
Validation loss: 1.8526286437947264

Epoch: 6| Step: 12
Training loss: 0.8296471834182739
Validation loss: 1.9074549649351387

Epoch: 6| Step: 13
Training loss: 0.853408694267273
Validation loss: 1.8705288671678113

Epoch: 206| Step: 0
Training loss: 0.8676406741142273
Validation loss: 1.8382794369933426

Epoch: 6| Step: 1
Training loss: 1.1649937629699707
Validation loss: 1.818577988173372

Epoch: 6| Step: 2
Training loss: 0.975469708442688
Validation loss: 1.8115536705140145

Epoch: 6| Step: 3
Training loss: 0.5857642889022827
Validation loss: 1.7889207691274664

Epoch: 6| Step: 4
Training loss: 0.5708061456680298
Validation loss: 1.7669666454356203

Epoch: 6| Step: 5
Training loss: 0.582146167755127
Validation loss: 1.7177855814656904

Epoch: 6| Step: 6
Training loss: 0.9266262054443359
Validation loss: 1.744436369147352

Epoch: 6| Step: 7
Training loss: 1.5675773620605469
Validation loss: 1.7665779385515439

Epoch: 6| Step: 8
Training loss: 0.8231281042098999
Validation loss: 1.7914303477092455

Epoch: 6| Step: 9
Training loss: 0.858711302280426
Validation loss: 1.81669536969995

Epoch: 6| Step: 10
Training loss: 1.243279218673706
Validation loss: 1.8254872983501804

Epoch: 6| Step: 11
Training loss: 1.1336621046066284
Validation loss: 1.8565932396919496

Epoch: 6| Step: 12
Training loss: 0.7387224435806274
Validation loss: 1.8169609205697173

Epoch: 6| Step: 13
Training loss: 0.8837370276451111
Validation loss: 1.790360245653378

Epoch: 207| Step: 0
Training loss: 0.8753076195716858
Validation loss: 1.7904750698356218

Epoch: 6| Step: 1
Training loss: 1.1527807712554932
Validation loss: 1.8227236155540711

Epoch: 6| Step: 2
Training loss: 0.9695525169372559
Validation loss: 1.7829413849820372

Epoch: 6| Step: 3
Training loss: 0.7443963885307312
Validation loss: 1.8373097206956597

Epoch: 6| Step: 4
Training loss: 1.013173222541809
Validation loss: 1.8045876205608409

Epoch: 6| Step: 5
Training loss: 0.8334853649139404
Validation loss: 1.8135267970382527

Epoch: 6| Step: 6
Training loss: 0.8920468091964722
Validation loss: 1.799245548504655

Epoch: 6| Step: 7
Training loss: 0.9790139198303223
Validation loss: 1.8235951777427428

Epoch: 6| Step: 8
Training loss: 1.0934237241744995
Validation loss: 1.8197264671325684

Epoch: 6| Step: 9
Training loss: 0.8599604964256287
Validation loss: 1.820640960047322

Epoch: 6| Step: 10
Training loss: 1.0657563209533691
Validation loss: 1.8754803390913113

Epoch: 6| Step: 11
Training loss: 0.7296589612960815
Validation loss: 1.8644180592670236

Epoch: 6| Step: 12
Training loss: 0.7670198678970337
Validation loss: 1.808899720509847

Epoch: 6| Step: 13
Training loss: 1.047202467918396
Validation loss: 1.78586075639212

Epoch: 208| Step: 0
Training loss: 0.969874382019043
Validation loss: 1.808243195215861

Epoch: 6| Step: 1
Training loss: 1.0510426759719849
Validation loss: 1.8199084112721104

Epoch: 6| Step: 2
Training loss: 0.7327265739440918
Validation loss: 1.798789498626545

Epoch: 6| Step: 3
Training loss: 1.0115643739700317
Validation loss: 1.847011343125374

Epoch: 6| Step: 4
Training loss: 0.9172866940498352
Validation loss: 1.8537114153626144

Epoch: 6| Step: 5
Training loss: 0.7418390512466431
Validation loss: 1.8629253692524408

Epoch: 6| Step: 6
Training loss: 0.6258065700531006
Validation loss: 1.8729086998970277

Epoch: 6| Step: 7
Training loss: 1.1701337099075317
Validation loss: 1.8437724344192012

Epoch: 6| Step: 8
Training loss: 1.194786787033081
Validation loss: 1.848488087295204

Epoch: 6| Step: 9
Training loss: 0.7620357275009155
Validation loss: 1.8263852903919835

Epoch: 6| Step: 10
Training loss: 0.7301030158996582
Validation loss: 1.8194640580043997

Epoch: 6| Step: 11
Training loss: 0.8729532957077026
Validation loss: 1.8295749977070799

Epoch: 6| Step: 12
Training loss: 0.8432618379592896
Validation loss: 1.8001541988824004

Epoch: 6| Step: 13
Training loss: 1.0932475328445435
Validation loss: 1.7771474840820476

Epoch: 209| Step: 0
Training loss: 1.1524593830108643
Validation loss: 1.7801036873171407

Epoch: 6| Step: 1
Training loss: 0.9937875866889954
Validation loss: 1.7785628867405716

Epoch: 6| Step: 2
Training loss: 0.7090074419975281
Validation loss: 1.7889020032780145

Epoch: 6| Step: 3
Training loss: 1.0073695182800293
Validation loss: 1.7758532826618483

Epoch: 6| Step: 4
Training loss: 0.7128750681877136
Validation loss: 1.8022946183399489

Epoch: 6| Step: 5
Training loss: 0.9404115676879883
Validation loss: 1.8270626016842422

Epoch: 6| Step: 6
Training loss: 0.5367021560668945
Validation loss: 1.8554193601813367

Epoch: 6| Step: 7
Training loss: 1.054553508758545
Validation loss: 1.9377740378020911

Epoch: 6| Step: 8
Training loss: 0.6515291929244995
Validation loss: 1.9653149317669611

Epoch: 6| Step: 9
Training loss: 1.1115096807479858
Validation loss: 1.9690201743956535

Epoch: 6| Step: 10
Training loss: 0.8542828559875488
Validation loss: 1.9268081726566437

Epoch: 6| Step: 11
Training loss: 0.5233158469200134
Validation loss: 1.9027769706582511

Epoch: 6| Step: 12
Training loss: 1.3031269311904907
Validation loss: 1.8890675780593709

Epoch: 6| Step: 13
Training loss: 0.7668605446815491
Validation loss: 1.8343366064051145

Epoch: 210| Step: 0
Training loss: 0.7725883722305298
Validation loss: 1.8231429592255624

Epoch: 6| Step: 1
Training loss: 0.6797304749488831
Validation loss: 1.7788819792450115

Epoch: 6| Step: 2
Training loss: 1.1940710544586182
Validation loss: 1.7148962072146836

Epoch: 6| Step: 3
Training loss: 0.7107036113739014
Validation loss: 1.731629624161669

Epoch: 6| Step: 4
Training loss: 0.9345763325691223
Validation loss: 1.7366227975455664

Epoch: 6| Step: 5
Training loss: 0.8620051145553589
Validation loss: 1.7702500127976941

Epoch: 6| Step: 6
Training loss: 0.9470070600509644
Validation loss: 1.7855330154459963

Epoch: 6| Step: 7
Training loss: 1.3080263137817383
Validation loss: 1.8196251635910363

Epoch: 6| Step: 8
Training loss: 0.4593190848827362
Validation loss: 1.850736826978704

Epoch: 6| Step: 9
Training loss: 0.5956971645355225
Validation loss: 1.8401830811654367

Epoch: 6| Step: 10
Training loss: 0.9629008769989014
Validation loss: 1.8287393969874228

Epoch: 6| Step: 11
Training loss: 0.7509223222732544
Validation loss: 1.8211324112389677

Epoch: 6| Step: 12
Training loss: 1.0796327590942383
Validation loss: 1.813170676590294

Epoch: 6| Step: 13
Training loss: 0.793117105960846
Validation loss: 1.7529161745502102

Epoch: 211| Step: 0
Training loss: 0.9218246340751648
Validation loss: 1.7378338049816828

Epoch: 6| Step: 1
Training loss: 0.8080226182937622
Validation loss: 1.7396959162527514

Epoch: 6| Step: 2
Training loss: 0.9368420243263245
Validation loss: 1.7387266876876994

Epoch: 6| Step: 3
Training loss: 1.1507912874221802
Validation loss: 1.730390012905162

Epoch: 6| Step: 4
Training loss: 0.8183685541152954
Validation loss: 1.7365570093995781

Epoch: 6| Step: 5
Training loss: 0.7044464349746704
Validation loss: 1.7452376452825402

Epoch: 6| Step: 6
Training loss: 0.8757717609405518
Validation loss: 1.7641489198130946

Epoch: 6| Step: 7
Training loss: 0.9223102331161499
Validation loss: 1.7786512554332774

Epoch: 6| Step: 8
Training loss: 0.5322149991989136
Validation loss: 1.8407135368675314

Epoch: 6| Step: 9
Training loss: 1.1480568647384644
Validation loss: 1.827932830779783

Epoch: 6| Step: 10
Training loss: 0.3275411128997803
Validation loss: 1.869301426795221

Epoch: 6| Step: 11
Training loss: 1.0376534461975098
Validation loss: 1.8734200334036222

Epoch: 6| Step: 12
Training loss: 0.9648316502571106
Validation loss: 1.840682650125155

Epoch: 6| Step: 13
Training loss: 0.7070130109786987
Validation loss: 1.8331041810333089

Epoch: 212| Step: 0
Training loss: 0.5227787494659424
Validation loss: 1.8091105645702732

Epoch: 6| Step: 1
Training loss: 1.08804452419281
Validation loss: 1.787527818833628

Epoch: 6| Step: 2
Training loss: 0.9939567446708679
Validation loss: 1.814076897918537

Epoch: 6| Step: 3
Training loss: 0.80144202709198
Validation loss: 1.774179498354594

Epoch: 6| Step: 4
Training loss: 0.49093738198280334
Validation loss: 1.8090030339456373

Epoch: 6| Step: 5
Training loss: 0.7307621240615845
Validation loss: 1.787442716860002

Epoch: 6| Step: 6
Training loss: 0.7893734574317932
Validation loss: 1.8299661708134476

Epoch: 6| Step: 7
Training loss: 1.1427372694015503
Validation loss: 1.839316834685623

Epoch: 6| Step: 8
Training loss: 0.8929665088653564
Validation loss: 1.830334323708729

Epoch: 6| Step: 9
Training loss: 0.790608286857605
Validation loss: 1.824396865342253

Epoch: 6| Step: 10
Training loss: 1.0467655658721924
Validation loss: 1.8020431136572233

Epoch: 6| Step: 11
Training loss: 1.138608694076538
Validation loss: 1.7728397256584578

Epoch: 6| Step: 12
Training loss: 0.555170476436615
Validation loss: 1.8229866771287815

Epoch: 6| Step: 13
Training loss: 0.2854119539260864
Validation loss: 1.8082032331856348

Epoch: 213| Step: 0
Training loss: 0.6999011039733887
Validation loss: 1.8203552576803392

Epoch: 6| Step: 1
Training loss: 0.7546815276145935
Validation loss: 1.8356965549530522

Epoch: 6| Step: 2
Training loss: 1.2679872512817383
Validation loss: 1.8017359087544103

Epoch: 6| Step: 3
Training loss: 0.7719072103500366
Validation loss: 1.8077302145701584

Epoch: 6| Step: 4
Training loss: 0.8709331750869751
Validation loss: 1.8068419656445902

Epoch: 6| Step: 5
Training loss: 0.7088234424591064
Validation loss: 1.8330504855801981

Epoch: 6| Step: 6
Training loss: 0.7623097896575928
Validation loss: 1.8117626508076985

Epoch: 6| Step: 7
Training loss: 1.0021474361419678
Validation loss: 1.8355303246487853

Epoch: 6| Step: 8
Training loss: 0.7117072343826294
Validation loss: 1.869098876112251

Epoch: 6| Step: 9
Training loss: 0.6665109992027283
Validation loss: 1.8759028706499326

Epoch: 6| Step: 10
Training loss: 0.8347318172454834
Validation loss: 1.8444795403429257

Epoch: 6| Step: 11
Training loss: 0.7741487622261047
Validation loss: 1.7728940838126725

Epoch: 6| Step: 12
Training loss: 0.9797147512435913
Validation loss: 1.7954897303735056

Epoch: 6| Step: 13
Training loss: 0.6604565382003784
Validation loss: 1.7422149322366203

Epoch: 214| Step: 0
Training loss: 1.0449891090393066
Validation loss: 1.7283528338196457

Epoch: 6| Step: 1
Training loss: 0.8062101602554321
Validation loss: 1.737376360483067

Epoch: 6| Step: 2
Training loss: 0.8061819076538086
Validation loss: 1.7726689231011175

Epoch: 6| Step: 3
Training loss: 1.0262970924377441
Validation loss: 1.7971050636742705

Epoch: 6| Step: 4
Training loss: 0.6835120320320129
Validation loss: 1.810650110244751

Epoch: 6| Step: 5
Training loss: 0.48240891098976135
Validation loss: 1.8378023255255915

Epoch: 6| Step: 6
Training loss: 0.6273369789123535
Validation loss: 1.8415747073388868

Epoch: 6| Step: 7
Training loss: 1.0449185371398926
Validation loss: 1.8589525889324885

Epoch: 6| Step: 8
Training loss: 0.535026490688324
Validation loss: 1.8490982645301408

Epoch: 6| Step: 9
Training loss: 0.8957303762435913
Validation loss: 1.8338493365113453

Epoch: 6| Step: 10
Training loss: 0.9114047884941101
Validation loss: 1.7798544322290728

Epoch: 6| Step: 11
Training loss: 0.965610146522522
Validation loss: 1.782515993682287

Epoch: 6| Step: 12
Training loss: 0.8557719588279724
Validation loss: 1.7679536842530774

Epoch: 6| Step: 13
Training loss: 0.35241737961769104
Validation loss: 1.7448795905677221

Epoch: 215| Step: 0
Training loss: 0.5096969604492188
Validation loss: 1.7748839778284873

Epoch: 6| Step: 1
Training loss: 0.8544936776161194
Validation loss: 1.7676455231123074

Epoch: 6| Step: 2
Training loss: 0.9035140872001648
Validation loss: 1.7891471078318935

Epoch: 6| Step: 3
Training loss: 0.9573957920074463
Validation loss: 1.778839397174056

Epoch: 6| Step: 4
Training loss: 1.002859354019165
Validation loss: 1.766050087508335

Epoch: 6| Step: 5
Training loss: 0.861006498336792
Validation loss: 1.8047066811592347

Epoch: 6| Step: 6
Training loss: 0.5843356847763062
Validation loss: 1.7726533323205926

Epoch: 6| Step: 7
Training loss: 0.9396147727966309
Validation loss: 1.7814581535195793

Epoch: 6| Step: 8
Training loss: 0.7388899326324463
Validation loss: 1.7994125966102845

Epoch: 6| Step: 9
Training loss: 0.6720539331436157
Validation loss: 1.8071190016244048

Epoch: 6| Step: 10
Training loss: 1.0177891254425049
Validation loss: 1.8397274799244379

Epoch: 6| Step: 11
Training loss: 0.8804633617401123
Validation loss: 1.870695721718573

Epoch: 6| Step: 12
Training loss: 0.6202461123466492
Validation loss: 1.876053233300486

Epoch: 6| Step: 13
Training loss: 0.6680406928062439
Validation loss: 1.8972586329265306

Epoch: 216| Step: 0
Training loss: 0.8693967461585999
Validation loss: 1.8419875252631404

Epoch: 6| Step: 1
Training loss: 0.5849463939666748
Validation loss: 1.7755879612379177

Epoch: 6| Step: 2
Training loss: 0.9845767021179199
Validation loss: 1.7234142531630814

Epoch: 6| Step: 3
Training loss: 0.8853222131729126
Validation loss: 1.6742451114039267

Epoch: 6| Step: 4
Training loss: 1.0745203495025635
Validation loss: 1.7083787341271677

Epoch: 6| Step: 5
Training loss: 1.2341010570526123
Validation loss: 1.6686495247707571

Epoch: 6| Step: 6
Training loss: 0.8571570515632629
Validation loss: 1.702442862654245

Epoch: 6| Step: 7
Training loss: 0.6528007984161377
Validation loss: 1.6744850553492063

Epoch: 6| Step: 8
Training loss: 0.7030448317527771
Validation loss: 1.7466499959268877

Epoch: 6| Step: 9
Training loss: 0.5088472962379456
Validation loss: 1.7561406640596287

Epoch: 6| Step: 10
Training loss: 0.5196036100387573
Validation loss: 1.8149288187744796

Epoch: 6| Step: 11
Training loss: 0.4136805534362793
Validation loss: 1.8176146143226213

Epoch: 6| Step: 12
Training loss: 0.8879640102386475
Validation loss: 1.8307061464555803

Epoch: 6| Step: 13
Training loss: 1.7197602987289429
Validation loss: 1.8387773921412807

Epoch: 217| Step: 0
Training loss: 1.4190341234207153
Validation loss: 1.8294521647114907

Epoch: 6| Step: 1
Training loss: 0.4537123441696167
Validation loss: 1.8288510999371927

Epoch: 6| Step: 2
Training loss: 0.8614208698272705
Validation loss: 1.8338734001241705

Epoch: 6| Step: 3
Training loss: 0.45650702714920044
Validation loss: 1.839838186899821

Epoch: 6| Step: 4
Training loss: 0.6617266535758972
Validation loss: 1.8520003980205906

Epoch: 6| Step: 5
Training loss: 0.5877315998077393
Validation loss: 1.8085034637040989

Epoch: 6| Step: 6
Training loss: 0.6241495013237
Validation loss: 1.8037291560121762

Epoch: 6| Step: 7
Training loss: 0.5753358006477356
Validation loss: 1.743673841158549

Epoch: 6| Step: 8
Training loss: 0.9316980838775635
Validation loss: 1.7251002115588034

Epoch: 6| Step: 9
Training loss: 0.6308914422988892
Validation loss: 1.7448076983933807

Epoch: 6| Step: 10
Training loss: 0.8330706357955933
Validation loss: 1.7868463416253366

Epoch: 6| Step: 11
Training loss: 0.8216466903686523
Validation loss: 1.7403838557581748

Epoch: 6| Step: 12
Training loss: 1.0550882816314697
Validation loss: 1.7222683788627706

Epoch: 6| Step: 13
Training loss: 0.7765814661979675
Validation loss: 1.750223071344437

Epoch: 218| Step: 0
Training loss: 0.9205149412155151
Validation loss: 1.746749170364872

Epoch: 6| Step: 1
Training loss: 0.7212326526641846
Validation loss: 1.7567148041981522

Epoch: 6| Step: 2
Training loss: 1.0776941776275635
Validation loss: 1.8040435980725031

Epoch: 6| Step: 3
Training loss: 0.6589394807815552
Validation loss: 1.8596909558901222

Epoch: 6| Step: 4
Training loss: 0.5216841101646423
Validation loss: 1.8454194402181974

Epoch: 6| Step: 5
Training loss: 0.8625437021255493
Validation loss: 1.8780304744679441

Epoch: 6| Step: 6
Training loss: 0.4707469940185547
Validation loss: 1.8573754577226536

Epoch: 6| Step: 7
Training loss: 0.9660811424255371
Validation loss: 1.8034495179371168

Epoch: 6| Step: 8
Training loss: 0.6087779998779297
Validation loss: 1.8564689902849094

Epoch: 6| Step: 9
Training loss: 0.9126707911491394
Validation loss: 1.7899053712044992

Epoch: 6| Step: 10
Training loss: 0.824150562286377
Validation loss: 1.7883340812498523

Epoch: 6| Step: 11
Training loss: 0.8402823209762573
Validation loss: 1.7763331961888138

Epoch: 6| Step: 12
Training loss: 0.6956722736358643
Validation loss: 1.7886067321223598

Epoch: 6| Step: 13
Training loss: 0.7270902991294861
Validation loss: 1.795028717287125

Epoch: 219| Step: 0
Training loss: 1.1343833208084106
Validation loss: 1.7633213176522204

Epoch: 6| Step: 1
Training loss: 0.9049865007400513
Validation loss: 1.776033857817291

Epoch: 6| Step: 2
Training loss: 0.9318246841430664
Validation loss: 1.7701308099172448

Epoch: 6| Step: 3
Training loss: 0.612975001335144
Validation loss: 1.8307221192185597

Epoch: 6| Step: 4
Training loss: 0.6237782835960388
Validation loss: 1.8253566424051921

Epoch: 6| Step: 5
Training loss: 0.8116054534912109
Validation loss: 1.867135981077789

Epoch: 6| Step: 6
Training loss: 1.043062686920166
Validation loss: 1.821183366160239

Epoch: 6| Step: 7
Training loss: 0.8506161570549011
Validation loss: 1.7996688094190372

Epoch: 6| Step: 8
Training loss: 0.5286310315132141
Validation loss: 1.7587885574627948

Epoch: 6| Step: 9
Training loss: 0.6249501705169678
Validation loss: 1.7431205357274702

Epoch: 6| Step: 10
Training loss: 0.6702857613563538
Validation loss: 1.750197002964635

Epoch: 6| Step: 11
Training loss: 0.3845686912536621
Validation loss: 1.7459467341822963

Epoch: 6| Step: 12
Training loss: 0.7586408257484436
Validation loss: 1.7839939491723174

Epoch: 6| Step: 13
Training loss: 0.35571739077568054
Validation loss: 1.80025178129955

Epoch: 220| Step: 0
Training loss: 0.7663361430168152
Validation loss: 1.8129459093975764

Epoch: 6| Step: 1
Training loss: 0.8102535605430603
Validation loss: 1.8364336926450011

Epoch: 6| Step: 2
Training loss: 0.9172805547714233
Validation loss: 1.839420077621296

Epoch: 6| Step: 3
Training loss: 0.5785939693450928
Validation loss: 1.7915573479026876

Epoch: 6| Step: 4
Training loss: 1.095956563949585
Validation loss: 1.8070093585598854

Epoch: 6| Step: 5
Training loss: 0.9559410214424133
Validation loss: 1.7912124844007595

Epoch: 6| Step: 6
Training loss: 0.7762198448181152
Validation loss: 1.7395654762944868

Epoch: 6| Step: 7
Training loss: 0.3815554678440094
Validation loss: 1.7452324000738

Epoch: 6| Step: 8
Training loss: 0.6264758706092834
Validation loss: 1.7271623278176913

Epoch: 6| Step: 9
Training loss: 0.5515750646591187
Validation loss: 1.7383282133328017

Epoch: 6| Step: 10
Training loss: 0.9352962970733643
Validation loss: 1.7324860031886766

Epoch: 6| Step: 11
Training loss: 1.0004017353057861
Validation loss: 1.7239999437844882

Epoch: 6| Step: 12
Training loss: 0.5578538179397583
Validation loss: 1.7291967163803756

Epoch: 6| Step: 13
Training loss: 0.44611427187919617
Validation loss: 1.7464382956104894

Epoch: 221| Step: 0
Training loss: 0.9255395531654358
Validation loss: 1.7374093583835069

Epoch: 6| Step: 1
Training loss: 0.6152454614639282
Validation loss: 1.7351592304886028

Epoch: 6| Step: 2
Training loss: 0.6699653267860413
Validation loss: 1.7711186050086893

Epoch: 6| Step: 3
Training loss: 0.5323470830917358
Validation loss: 1.8413211607163953

Epoch: 6| Step: 4
Training loss: 0.5456211566925049
Validation loss: 1.79104285470901

Epoch: 6| Step: 5
Training loss: 0.678145170211792
Validation loss: 1.7851700718684862

Epoch: 6| Step: 6
Training loss: 0.8174280524253845
Validation loss: 1.7962763565842823

Epoch: 6| Step: 7
Training loss: 0.6501615047454834
Validation loss: 1.7932489841215071

Epoch: 6| Step: 8
Training loss: 0.5335667133331299
Validation loss: 1.7865246598438551

Epoch: 6| Step: 9
Training loss: 0.8334003686904907
Validation loss: 1.7732422069836689

Epoch: 6| Step: 10
Training loss: 0.7706676721572876
Validation loss: 1.747935393805145

Epoch: 6| Step: 11
Training loss: 0.6074405908584595
Validation loss: 1.7338615066261702

Epoch: 6| Step: 12
Training loss: 0.8082574605941772
Validation loss: 1.741799675008302

Epoch: 6| Step: 13
Training loss: 1.000643253326416
Validation loss: 1.723782245830823

Epoch: 222| Step: 0
Training loss: 0.5335749387741089
Validation loss: 1.7652149674712971

Epoch: 6| Step: 1
Training loss: 0.5302146077156067
Validation loss: 1.8051495667426818

Epoch: 6| Step: 2
Training loss: 0.7535360455513
Validation loss: 1.8328264913251322

Epoch: 6| Step: 3
Training loss: 0.6450098752975464
Validation loss: 1.8362216411098358

Epoch: 6| Step: 4
Training loss: 0.9578595161437988
Validation loss: 1.8459177350485196

Epoch: 6| Step: 5
Training loss: 0.6041061878204346
Validation loss: 1.8299028514533915

Epoch: 6| Step: 6
Training loss: 0.637182891368866
Validation loss: 1.8112091364399079

Epoch: 6| Step: 7
Training loss: 0.7162302136421204
Validation loss: 1.7896752024209628

Epoch: 6| Step: 8
Training loss: 0.7499202489852905
Validation loss: 1.779483219628693

Epoch: 6| Step: 9
Training loss: 0.8379813432693481
Validation loss: 1.7625321162644254

Epoch: 6| Step: 10
Training loss: 0.5533797740936279
Validation loss: 1.7787318716767013

Epoch: 6| Step: 11
Training loss: 0.5883986949920654
Validation loss: 1.7269590682880853

Epoch: 6| Step: 12
Training loss: 1.0194792747497559
Validation loss: 1.724408204837512

Epoch: 6| Step: 13
Training loss: 0.623602032661438
Validation loss: 1.7098197501192811

Epoch: 223| Step: 0
Training loss: 1.350150465965271
Validation loss: 1.7032663642719228

Epoch: 6| Step: 1
Training loss: 0.7209905385971069
Validation loss: 1.7380943503431094

Epoch: 6| Step: 2
Training loss: 0.46914780139923096
Validation loss: 1.7718544429348362

Epoch: 6| Step: 3
Training loss: 0.7942754030227661
Validation loss: 1.831371598346259

Epoch: 6| Step: 4
Training loss: 0.51353520154953
Validation loss: 1.8161859563601914

Epoch: 6| Step: 5
Training loss: 0.5654958486557007
Validation loss: 1.840019488847384

Epoch: 6| Step: 6
Training loss: 0.6122094988822937
Validation loss: 1.8009460344109485

Epoch: 6| Step: 7
Training loss: 0.5635960102081299
Validation loss: 1.7854513314462477

Epoch: 6| Step: 8
Training loss: 1.0517692565917969
Validation loss: 1.8014767310952629

Epoch: 6| Step: 9
Training loss: 1.0565733909606934
Validation loss: 1.7723819081501295

Epoch: 6| Step: 10
Training loss: 0.5891081690788269
Validation loss: 1.7740227201933503

Epoch: 6| Step: 11
Training loss: 0.7567338347434998
Validation loss: 1.765165421270555

Epoch: 6| Step: 12
Training loss: 0.7074213027954102
Validation loss: 1.7727120473820677

Epoch: 6| Step: 13
Training loss: 0.6387699842453003
Validation loss: 1.785977267449902

Epoch: 224| Step: 0
Training loss: 0.6026833057403564
Validation loss: 1.8308754608195315

Epoch: 6| Step: 1
Training loss: 0.8235070109367371
Validation loss: 1.8480577109962382

Epoch: 6| Step: 2
Training loss: 0.699427604675293
Validation loss: 1.849235164221897

Epoch: 6| Step: 3
Training loss: 0.6036925315856934
Validation loss: 1.8923431506720922

Epoch: 6| Step: 4
Training loss: 0.998376190662384
Validation loss: 1.8904003033074

Epoch: 6| Step: 5
Training loss: 0.49971720576286316
Validation loss: 1.8002163492223269

Epoch: 6| Step: 6
Training loss: 0.6344321370124817
Validation loss: 1.7245837168026996

Epoch: 6| Step: 7
Training loss: 0.6589611172676086
Validation loss: 1.7206387122472127

Epoch: 6| Step: 8
Training loss: 0.7390169501304626
Validation loss: 1.714236943952499

Epoch: 6| Step: 9
Training loss: 0.8110743165016174
Validation loss: 1.6878843692041212

Epoch: 6| Step: 10
Training loss: 1.0270299911499023
Validation loss: 1.691751822348564

Epoch: 6| Step: 11
Training loss: 0.7834348082542419
Validation loss: 1.7268128113080097

Epoch: 6| Step: 12
Training loss: 1.1504348516464233
Validation loss: 1.7596278267522012

Epoch: 6| Step: 13
Training loss: 0.22577248513698578
Validation loss: 1.7611872765325731

Epoch: 225| Step: 0
Training loss: 0.8050582408905029
Validation loss: 1.79873671326586

Epoch: 6| Step: 1
Training loss: 0.7615412473678589
Validation loss: 1.8143951687761533

Epoch: 6| Step: 2
Training loss: 1.3494338989257812
Validation loss: 1.8466794247268348

Epoch: 6| Step: 3
Training loss: 0.6814350485801697
Validation loss: 1.8071036261896933

Epoch: 6| Step: 4
Training loss: 0.6022619009017944
Validation loss: 1.7680868333385837

Epoch: 6| Step: 5
Training loss: 1.0085055828094482
Validation loss: 1.7188649267278693

Epoch: 6| Step: 6
Training loss: 0.38143229484558105
Validation loss: 1.7045366892250635

Epoch: 6| Step: 7
Training loss: 0.5061793327331543
Validation loss: 1.691836921117639

Epoch: 6| Step: 8
Training loss: 0.7060327529907227
Validation loss: 1.7082639637813772

Epoch: 6| Step: 9
Training loss: 0.6410897970199585
Validation loss: 1.689566780162114

Epoch: 6| Step: 10
Training loss: 0.8270322680473328
Validation loss: 1.725684763282858

Epoch: 6| Step: 11
Training loss: 0.7196893692016602
Validation loss: 1.7219287221149733

Epoch: 6| Step: 12
Training loss: 0.6563130617141724
Validation loss: 1.7662204363012826

Epoch: 6| Step: 13
Training loss: 0.8646536469459534
Validation loss: 1.7818182130013742

Epoch: 226| Step: 0
Training loss: 0.8092764616012573
Validation loss: 1.834206578552082

Epoch: 6| Step: 1
Training loss: 0.9120694398880005
Validation loss: 1.8063053225958219

Epoch: 6| Step: 2
Training loss: 0.660219669342041
Validation loss: 1.7552832429127028

Epoch: 6| Step: 3
Training loss: 0.6643623113632202
Validation loss: 1.7591682287954515

Epoch: 6| Step: 4
Training loss: 0.5378499031066895
Validation loss: 1.7362926826682141

Epoch: 6| Step: 5
Training loss: 0.6499729156494141
Validation loss: 1.7157979549900177

Epoch: 6| Step: 6
Training loss: 1.0321027040481567
Validation loss: 1.7287666208000594

Epoch: 6| Step: 7
Training loss: 0.5230082273483276
Validation loss: 1.778867620293812

Epoch: 6| Step: 8
Training loss: 0.7735863327980042
Validation loss: 1.764507588519845

Epoch: 6| Step: 9
Training loss: 0.6003973484039307
Validation loss: 1.8203332603618663

Epoch: 6| Step: 10
Training loss: 0.8467055559158325
Validation loss: 1.827583828280049

Epoch: 6| Step: 11
Training loss: 0.644058883190155
Validation loss: 1.8035301969897362

Epoch: 6| Step: 12
Training loss: 0.6404770612716675
Validation loss: 1.8156012617131716

Epoch: 6| Step: 13
Training loss: 0.4186517000198364
Validation loss: 1.7898142671072355

Epoch: 227| Step: 0
Training loss: 0.4165773093700409
Validation loss: 1.81307731264381

Epoch: 6| Step: 1
Training loss: 0.862920880317688
Validation loss: 1.7921067937727897

Epoch: 6| Step: 2
Training loss: 0.6224542856216431
Validation loss: 1.8229737448435959

Epoch: 6| Step: 3
Training loss: 0.7450168132781982
Validation loss: 1.823444107527374

Epoch: 6| Step: 4
Training loss: 0.4811532497406006
Validation loss: 1.7629006472967004

Epoch: 6| Step: 5
Training loss: 0.9180541038513184
Validation loss: 1.7901674624412292

Epoch: 6| Step: 6
Training loss: 0.335534930229187
Validation loss: 1.8082751663782264

Epoch: 6| Step: 7
Training loss: 0.7639665603637695
Validation loss: 1.808254050952132

Epoch: 6| Step: 8
Training loss: 0.5979492664337158
Validation loss: 1.8265652964192052

Epoch: 6| Step: 9
Training loss: 0.8230544924736023
Validation loss: 1.8720884502574962

Epoch: 6| Step: 10
Training loss: 0.606322705745697
Validation loss: 1.8597071016988447

Epoch: 6| Step: 11
Training loss: 0.8357441425323486
Validation loss: 1.8407354418949415

Epoch: 6| Step: 12
Training loss: 1.0171173810958862
Validation loss: 1.8108446623689385

Epoch: 6| Step: 13
Training loss: 0.6790531873703003
Validation loss: 1.7892143239257157

Epoch: 228| Step: 0
Training loss: 0.6057361364364624
Validation loss: 1.7841222696406867

Epoch: 6| Step: 1
Training loss: 0.7181476354598999
Validation loss: 1.7406575974597727

Epoch: 6| Step: 2
Training loss: 0.6672816276550293
Validation loss: 1.7864872665815457

Epoch: 6| Step: 3
Training loss: 0.6554347276687622
Validation loss: 1.7807399765137704

Epoch: 6| Step: 4
Training loss: 0.6309077143669128
Validation loss: 1.8035379032934866

Epoch: 6| Step: 5
Training loss: 0.6445053815841675
Validation loss: 1.818171867760279

Epoch: 6| Step: 6
Training loss: 0.6141108274459839
Validation loss: 1.8120235948152439

Epoch: 6| Step: 7
Training loss: 0.7505890130996704
Validation loss: 1.8091186438837359

Epoch: 6| Step: 8
Training loss: 0.8967423439025879
Validation loss: 1.7456978251857143

Epoch: 6| Step: 9
Training loss: 0.6400071978569031
Validation loss: 1.72835333501139

Epoch: 6| Step: 10
Training loss: 0.44656383991241455
Validation loss: 1.7413064254227506

Epoch: 6| Step: 11
Training loss: 0.6135278940200806
Validation loss: 1.7385106791732132

Epoch: 6| Step: 12
Training loss: 1.1204068660736084
Validation loss: 1.7475177946911062

Epoch: 6| Step: 13
Training loss: 0.6308631896972656
Validation loss: 1.7397003776283675

Epoch: 229| Step: 0
Training loss: 0.7670516967773438
Validation loss: 1.7754843247834073

Epoch: 6| Step: 1
Training loss: 0.4155116081237793
Validation loss: 1.7890349639359342

Epoch: 6| Step: 2
Training loss: 0.9631027579307556
Validation loss: 1.8019559062937254

Epoch: 6| Step: 3
Training loss: 0.7798604965209961
Validation loss: 1.8552092403493903

Epoch: 6| Step: 4
Training loss: 0.8467987775802612
Validation loss: 1.8517951683331562

Epoch: 6| Step: 5
Training loss: 0.9371023774147034
Validation loss: 1.7797076650845107

Epoch: 6| Step: 6
Training loss: 0.5995988249778748
Validation loss: 1.736852410019085

Epoch: 6| Step: 7
Training loss: 0.6997697949409485
Validation loss: 1.7259767017056864

Epoch: 6| Step: 8
Training loss: 0.48560938239097595
Validation loss: 1.7633917895696496

Epoch: 6| Step: 9
Training loss: 0.5973148941993713
Validation loss: 1.7313306100906865

Epoch: 6| Step: 10
Training loss: 0.7732841372489929
Validation loss: 1.7653538488572644

Epoch: 6| Step: 11
Training loss: 0.5633887052536011
Validation loss: 1.72709136368126

Epoch: 6| Step: 12
Training loss: 0.7531373500823975
Validation loss: 1.7426173430617138

Epoch: 6| Step: 13
Training loss: 0.5685049891471863
Validation loss: 1.7650443943597938

Epoch: 230| Step: 0
Training loss: 1.2010524272918701
Validation loss: 1.801202461283694

Epoch: 6| Step: 1
Training loss: 0.5151272416114807
Validation loss: 1.8023803131554716

Epoch: 6| Step: 2
Training loss: 0.7955421805381775
Validation loss: 1.8715375136303645

Epoch: 6| Step: 3
Training loss: 0.5319581031799316
Validation loss: 1.8738435647820915

Epoch: 6| Step: 4
Training loss: 0.6609678268432617
Validation loss: 1.8738990765745922

Epoch: 6| Step: 5
Training loss: 0.8049755692481995
Validation loss: 1.822455293388777

Epoch: 6| Step: 6
Training loss: 0.5733706951141357
Validation loss: 1.7997568089474913

Epoch: 6| Step: 7
Training loss: 0.8974382877349854
Validation loss: 1.8029476724645144

Epoch: 6| Step: 8
Training loss: 0.7314781546592712
Validation loss: 1.7759407540803314

Epoch: 6| Step: 9
Training loss: 0.7576446533203125
Validation loss: 1.7411421832217966

Epoch: 6| Step: 10
Training loss: 0.45714807510375977
Validation loss: 1.7186636706834197

Epoch: 6| Step: 11
Training loss: 0.713415265083313
Validation loss: 1.7493864541412683

Epoch: 6| Step: 12
Training loss: 0.6163402795791626
Validation loss: 1.740272751418493

Epoch: 6| Step: 13
Training loss: 0.7638588547706604
Validation loss: 1.7728467115791895

Epoch: 231| Step: 0
Training loss: 0.5547550916671753
Validation loss: 1.790062778739519

Epoch: 6| Step: 1
Training loss: 0.5181316137313843
Validation loss: 1.800870871031156

Epoch: 6| Step: 2
Training loss: 0.595369815826416
Validation loss: 1.8562963162699053

Epoch: 6| Step: 3
Training loss: 0.4780406057834625
Validation loss: 1.8980701687515422

Epoch: 6| Step: 4
Training loss: 0.42996811866760254
Validation loss: 1.876920743655133

Epoch: 6| Step: 5
Training loss: 0.8333446979522705
Validation loss: 1.8762476110971102

Epoch: 6| Step: 6
Training loss: 1.023381233215332
Validation loss: 1.834892854895643

Epoch: 6| Step: 7
Training loss: 0.6398443579673767
Validation loss: 1.7856887104690715

Epoch: 6| Step: 8
Training loss: 0.6512966752052307
Validation loss: 1.7623041381118119

Epoch: 6| Step: 9
Training loss: 0.7139387726783752
Validation loss: 1.7571698234927269

Epoch: 6| Step: 10
Training loss: 0.5684643387794495
Validation loss: 1.7699789885551698

Epoch: 6| Step: 11
Training loss: 0.8612937927246094
Validation loss: 1.7368314702023742

Epoch: 6| Step: 12
Training loss: 0.5376124978065491
Validation loss: 1.7472313078500892

Epoch: 6| Step: 13
Training loss: 0.7829231023788452
Validation loss: 1.783189215967732

Epoch: 232| Step: 0
Training loss: 0.632813572883606
Validation loss: 1.7949445247650146

Epoch: 6| Step: 1
Training loss: 0.7480940222740173
Validation loss: 1.8733972490474742

Epoch: 6| Step: 2
Training loss: 0.47839856147766113
Validation loss: 1.8669400625331427

Epoch: 6| Step: 3
Training loss: 0.8332952260971069
Validation loss: 1.857840145787885

Epoch: 6| Step: 4
Training loss: 0.7685233354568481
Validation loss: 1.7946645341893679

Epoch: 6| Step: 5
Training loss: 1.037559151649475
Validation loss: 1.801604563190091

Epoch: 6| Step: 6
Training loss: 0.3110552728176117
Validation loss: 1.7986035910985803

Epoch: 6| Step: 7
Training loss: 0.6130199432373047
Validation loss: 1.7816479693176925

Epoch: 6| Step: 8
Training loss: 0.4944758117198944
Validation loss: 1.7869257798758886

Epoch: 6| Step: 9
Training loss: 0.5350393056869507
Validation loss: 1.7467371827812606

Epoch: 6| Step: 10
Training loss: 0.4733733832836151
Validation loss: 1.7496256507853025

Epoch: 6| Step: 11
Training loss: 0.6734075546264648
Validation loss: 1.74185743383182

Epoch: 6| Step: 12
Training loss: 0.6397678256034851
Validation loss: 1.747924191977388

Epoch: 6| Step: 13
Training loss: 0.6086004376411438
Validation loss: 1.7710481023275724

Epoch: 233| Step: 0
Training loss: 0.6524937748908997
Validation loss: 1.7768330445853613

Epoch: 6| Step: 1
Training loss: 0.635486900806427
Validation loss: 1.7958869421353905

Epoch: 6| Step: 2
Training loss: 0.5994691848754883
Validation loss: 1.8005675397893435

Epoch: 6| Step: 3
Training loss: 0.5006444454193115
Validation loss: 1.8308883200409591

Epoch: 6| Step: 4
Training loss: 0.8441205024719238
Validation loss: 1.8130888438993884

Epoch: 6| Step: 5
Training loss: 0.643841028213501
Validation loss: 1.8129394041594638

Epoch: 6| Step: 6
Training loss: 0.519688606262207
Validation loss: 1.78604079574667

Epoch: 6| Step: 7
Training loss: 0.8142329454421997
Validation loss: 1.7758058168554818

Epoch: 6| Step: 8
Training loss: 0.4812151789665222
Validation loss: 1.7564892179222518

Epoch: 6| Step: 9
Training loss: 0.6715006828308105
Validation loss: 1.7326314500583115

Epoch: 6| Step: 10
Training loss: 0.6877544522285461
Validation loss: 1.7462312777837117

Epoch: 6| Step: 11
Training loss: 0.5382950901985168
Validation loss: 1.7336868829624628

Epoch: 6| Step: 12
Training loss: 0.6486931443214417
Validation loss: 1.7290752972325971

Epoch: 6| Step: 13
Training loss: 0.8387104272842407
Validation loss: 1.748610975921795

Epoch: 234| Step: 0
Training loss: 0.44800305366516113
Validation loss: 1.7425602110483314

Epoch: 6| Step: 1
Training loss: 0.5539723634719849
Validation loss: 1.7305942466182094

Epoch: 6| Step: 2
Training loss: 0.908517599105835
Validation loss: 1.7924847397752988

Epoch: 6| Step: 3
Training loss: 0.6183346509933472
Validation loss: 1.817597412293957

Epoch: 6| Step: 4
Training loss: 0.7924701571464539
Validation loss: 1.8339317742214407

Epoch: 6| Step: 5
Training loss: 0.5407169461250305
Validation loss: 1.8419097649153842

Epoch: 6| Step: 6
Training loss: 0.7081324458122253
Validation loss: 1.8413762559172928

Epoch: 6| Step: 7
Training loss: 0.5682162046432495
Validation loss: 1.8381177225420553

Epoch: 6| Step: 8
Training loss: 0.6766871213912964
Validation loss: 1.837639558699823

Epoch: 6| Step: 9
Training loss: 0.6563994884490967
Validation loss: 1.867503563563029

Epoch: 6| Step: 10
Training loss: 0.8475688099861145
Validation loss: 1.8700906563830633

Epoch: 6| Step: 11
Training loss: 0.6198121905326843
Validation loss: 1.8646745630489883

Epoch: 6| Step: 12
Training loss: 0.6304511427879333
Validation loss: 1.8182068794004378

Epoch: 6| Step: 13
Training loss: 0.8197005391120911
Validation loss: 1.7490204213767924

Epoch: 235| Step: 0
Training loss: 0.5719000697135925
Validation loss: 1.7551382536529212

Epoch: 6| Step: 1
Training loss: 0.7052122354507446
Validation loss: 1.7285298416691441

Epoch: 6| Step: 2
Training loss: 0.9184403419494629
Validation loss: 1.7437592129553519

Epoch: 6| Step: 3
Training loss: 0.5732147693634033
Validation loss: 1.7357360829589188

Epoch: 6| Step: 4
Training loss: 0.6376141309738159
Validation loss: 1.7745895693379063

Epoch: 6| Step: 5
Training loss: 1.0036522150039673
Validation loss: 1.7875729350633518

Epoch: 6| Step: 6
Training loss: 0.4094257354736328
Validation loss: 1.825043455246956

Epoch: 6| Step: 7
Training loss: 0.7472593784332275
Validation loss: 1.8395603382459251

Epoch: 6| Step: 8
Training loss: 0.5575072765350342
Validation loss: 1.8544092562890822

Epoch: 6| Step: 9
Training loss: 0.5168783664703369
Validation loss: 1.83173325497617

Epoch: 6| Step: 10
Training loss: 0.731385350227356
Validation loss: 1.861885775801956

Epoch: 6| Step: 11
Training loss: 0.44879627227783203
Validation loss: 1.8214866371564968

Epoch: 6| Step: 12
Training loss: 0.7200983762741089
Validation loss: 1.8329986692756735

Epoch: 6| Step: 13
Training loss: 0.3578552007675171
Validation loss: 1.8071214011920396

Epoch: 236| Step: 0
Training loss: 1.0245604515075684
Validation loss: 1.7711737309732745

Epoch: 6| Step: 1
Training loss: 0.4426723122596741
Validation loss: 1.809408922349253

Epoch: 6| Step: 2
Training loss: 0.5999356508255005
Validation loss: 1.780287483687042

Epoch: 6| Step: 3
Training loss: 0.5800472497940063
Validation loss: 1.8133864043861307

Epoch: 6| Step: 4
Training loss: 0.4942213296890259
Validation loss: 1.7726927918772544

Epoch: 6| Step: 5
Training loss: 0.4721642732620239
Validation loss: 1.793518530425205

Epoch: 6| Step: 6
Training loss: 0.6440932750701904
Validation loss: 1.7760877468252694

Epoch: 6| Step: 7
Training loss: 0.480477899312973
Validation loss: 1.7753199992641326

Epoch: 6| Step: 8
Training loss: 0.5471722483634949
Validation loss: 1.778871492672992

Epoch: 6| Step: 9
Training loss: 0.5118494033813477
Validation loss: 1.762598508147783

Epoch: 6| Step: 10
Training loss: 0.6381124258041382
Validation loss: 1.7789011642497072

Epoch: 6| Step: 11
Training loss: 0.8263285160064697
Validation loss: 1.8004359506791638

Epoch: 6| Step: 12
Training loss: 0.5994712710380554
Validation loss: 1.8363603315045756

Epoch: 6| Step: 13
Training loss: 0.3417420983314514
Validation loss: 1.810926604014571

Epoch: 237| Step: 0
Training loss: 0.9440433979034424
Validation loss: 1.8054367585848736

Epoch: 6| Step: 1
Training loss: 0.6702612638473511
Validation loss: 1.7758479015801543

Epoch: 6| Step: 2
Training loss: 0.5401482582092285
Validation loss: 1.8017226252504575

Epoch: 6| Step: 3
Training loss: 0.6883101463317871
Validation loss: 1.7781536707314112

Epoch: 6| Step: 4
Training loss: 0.5841171145439148
Validation loss: 1.7838213059210009

Epoch: 6| Step: 5
Training loss: 0.44351962208747864
Validation loss: 1.7656920981663529

Epoch: 6| Step: 6
Training loss: 0.6083319187164307
Validation loss: 1.7622616226955126

Epoch: 6| Step: 7
Training loss: 0.6925034523010254
Validation loss: 1.8105061208048174

Epoch: 6| Step: 8
Training loss: 0.4099419414997101
Validation loss: 1.7827257751136698

Epoch: 6| Step: 9
Training loss: 0.5272821187973022
Validation loss: 1.7848027188290831

Epoch: 6| Step: 10
Training loss: 0.5882972478866577
Validation loss: 1.7653120486967024

Epoch: 6| Step: 11
Training loss: 0.5511248707771301
Validation loss: 1.771147430583995

Epoch: 6| Step: 12
Training loss: 0.6579480171203613
Validation loss: 1.8046198262963244

Epoch: 6| Step: 13
Training loss: 0.5728715658187866
Validation loss: 1.7651799776220833

Epoch: 238| Step: 0
Training loss: 0.4089841842651367
Validation loss: 1.7709895897937078

Epoch: 6| Step: 1
Training loss: 0.5474810600280762
Validation loss: 1.7666377457239295

Epoch: 6| Step: 2
Training loss: 0.56629478931427
Validation loss: 1.7800713136631956

Epoch: 6| Step: 3
Training loss: 0.5289559960365295
Validation loss: 1.7787686189015706

Epoch: 6| Step: 4
Training loss: 0.7989482879638672
Validation loss: 1.8071970196180447

Epoch: 6| Step: 5
Training loss: 0.5939900875091553
Validation loss: 1.7842411328387517

Epoch: 6| Step: 6
Training loss: 0.49071794748306274
Validation loss: 1.7728033206796134

Epoch: 6| Step: 7
Training loss: 0.6617991924285889
Validation loss: 1.7791816329443326

Epoch: 6| Step: 8
Training loss: 0.5711203217506409
Validation loss: 1.7747298261170745

Epoch: 6| Step: 9
Training loss: 0.6353830099105835
Validation loss: 1.7344067904257006

Epoch: 6| Step: 10
Training loss: 0.5054663419723511
Validation loss: 1.748875666690129

Epoch: 6| Step: 11
Training loss: 0.4664340615272522
Validation loss: 1.788080056508382

Epoch: 6| Step: 12
Training loss: 0.9785695672035217
Validation loss: 1.7812949816385906

Epoch: 6| Step: 13
Training loss: 0.530455470085144
Validation loss: 1.8176061927631337

Epoch: 239| Step: 0
Training loss: 0.41123276948928833
Validation loss: 1.8568651189086258

Epoch: 6| Step: 1
Training loss: 0.5803281664848328
Validation loss: 1.8559339213114914

Epoch: 6| Step: 2
Training loss: 0.8248447179794312
Validation loss: 1.8634802423497683

Epoch: 6| Step: 3
Training loss: 0.5143128037452698
Validation loss: 1.8446321641245196

Epoch: 6| Step: 4
Training loss: 0.4502928853034973
Validation loss: 1.7835388516867032

Epoch: 6| Step: 5
Training loss: 0.6953984498977661
Validation loss: 1.7311681393654115

Epoch: 6| Step: 6
Training loss: 0.6409324407577515
Validation loss: 1.7618307772503103

Epoch: 6| Step: 7
Training loss: 0.6079570055007935
Validation loss: 1.7068122266441264

Epoch: 6| Step: 8
Training loss: 0.7920355796813965
Validation loss: 1.7287726915010841

Epoch: 6| Step: 9
Training loss: 0.47508057951927185
Validation loss: 1.6880074060091408

Epoch: 6| Step: 10
Training loss: 0.7004467844963074
Validation loss: 1.7006321222551408

Epoch: 6| Step: 11
Training loss: 0.7554988861083984
Validation loss: 1.7243706891613622

Epoch: 6| Step: 12
Training loss: 0.4676699638366699
Validation loss: 1.7484067152905207

Epoch: 6| Step: 13
Training loss: 0.6835596561431885
Validation loss: 1.7074940050801923

Epoch: 240| Step: 0
Training loss: 0.5921649932861328
Validation loss: 1.7890970322393602

Epoch: 6| Step: 1
Training loss: 0.6632421016693115
Validation loss: 1.8375571197079075

Epoch: 6| Step: 2
Training loss: 0.7844560742378235
Validation loss: 1.8349241018295288

Epoch: 6| Step: 3
Training loss: 0.6706818342208862
Validation loss: 1.8429677640238116

Epoch: 6| Step: 4
Training loss: 0.6142221093177795
Validation loss: 1.8058568431485085

Epoch: 6| Step: 5
Training loss: 0.4361008405685425
Validation loss: 1.7821252499857256

Epoch: 6| Step: 6
Training loss: 0.4362905025482178
Validation loss: 1.7688855099421676

Epoch: 6| Step: 7
Training loss: 0.8843526840209961
Validation loss: 1.714649046621015

Epoch: 6| Step: 8
Training loss: 0.6991675496101379
Validation loss: 1.7095527892471643

Epoch: 6| Step: 9
Training loss: 0.6585785150527954
Validation loss: 1.7323819924426336

Epoch: 6| Step: 10
Training loss: 0.500777006149292
Validation loss: 1.7081387594182005

Epoch: 6| Step: 11
Training loss: 0.4190337657928467
Validation loss: 1.7195824641053394

Epoch: 6| Step: 12
Training loss: 0.531594455242157
Validation loss: 1.761263423068549

Epoch: 6| Step: 13
Training loss: 0.5848352313041687
Validation loss: 1.7674383373670681

Epoch: 241| Step: 0
Training loss: 0.8292551636695862
Validation loss: 1.735764830343185

Epoch: 6| Step: 1
Training loss: 0.5288649201393127
Validation loss: 1.7952898497222571

Epoch: 6| Step: 2
Training loss: 0.43381792306900024
Validation loss: 1.8122089780786985

Epoch: 6| Step: 3
Training loss: 0.449768602848053
Validation loss: 1.8223609065496793

Epoch: 6| Step: 4
Training loss: 0.46951785683631897
Validation loss: 1.8530847411001883

Epoch: 6| Step: 5
Training loss: 0.690152108669281
Validation loss: 1.8343064772185458

Epoch: 6| Step: 6
Training loss: 0.6396170258522034
Validation loss: 1.8091825105810677

Epoch: 6| Step: 7
Training loss: 0.271356999874115
Validation loss: 1.828235528802359

Epoch: 6| Step: 8
Training loss: 0.6200576424598694
Validation loss: 1.8062319601735761

Epoch: 6| Step: 9
Training loss: 0.7523753643035889
Validation loss: 1.802256445730886

Epoch: 6| Step: 10
Training loss: 0.6086407899856567
Validation loss: 1.7954513052458405

Epoch: 6| Step: 11
Training loss: 0.543278694152832
Validation loss: 1.8052900837313743

Epoch: 6| Step: 12
Training loss: 0.7583709359169006
Validation loss: 1.761653213090794

Epoch: 6| Step: 13
Training loss: 0.35086700320243835
Validation loss: 1.7755964135610929

Epoch: 242| Step: 0
Training loss: 0.4138084948062897
Validation loss: 1.7553535328116467

Epoch: 6| Step: 1
Training loss: 0.4649299681186676
Validation loss: 1.783399688300266

Epoch: 6| Step: 2
Training loss: 0.6441145539283752
Validation loss: 1.7630311519868913

Epoch: 6| Step: 3
Training loss: 0.9227157831192017
Validation loss: 1.7367507847406531

Epoch: 6| Step: 4
Training loss: 0.344791442155838
Validation loss: 1.732031104385212

Epoch: 6| Step: 5
Training loss: 0.5531140565872192
Validation loss: 1.7511684151105984

Epoch: 6| Step: 6
Training loss: 0.6140439510345459
Validation loss: 1.732529660706879

Epoch: 6| Step: 7
Training loss: 0.6613665223121643
Validation loss: 1.730034944831684

Epoch: 6| Step: 8
Training loss: 0.35060393810272217
Validation loss: 1.7777047670015724

Epoch: 6| Step: 9
Training loss: 0.49005022644996643
Validation loss: 1.7924282012447235

Epoch: 6| Step: 10
Training loss: 0.685028612613678
Validation loss: 1.798298966500067

Epoch: 6| Step: 11
Training loss: 0.504692018032074
Validation loss: 1.8341631081796461

Epoch: 6| Step: 12
Training loss: 0.4987283945083618
Validation loss: 1.8141027189070178

Epoch: 6| Step: 13
Training loss: 0.5154085159301758
Validation loss: 1.8427568110086585

Epoch: 243| Step: 0
Training loss: 0.5594965219497681
Validation loss: 1.795172845163653

Epoch: 6| Step: 1
Training loss: 0.5518373847007751
Validation loss: 1.7770891561303088

Epoch: 6| Step: 2
Training loss: 0.16887019574642181
Validation loss: 1.7709991547369188

Epoch: 6| Step: 3
Training loss: 0.6005265712738037
Validation loss: 1.7241669252354612

Epoch: 6| Step: 4
Training loss: 0.9241219758987427
Validation loss: 1.7156085160470778

Epoch: 6| Step: 5
Training loss: 0.5833694338798523
Validation loss: 1.780105777966079

Epoch: 6| Step: 6
Training loss: 0.43727368116378784
Validation loss: 1.7673895512857745

Epoch: 6| Step: 7
Training loss: 0.7554868459701538
Validation loss: 1.7614716688791912

Epoch: 6| Step: 8
Training loss: 0.6897829174995422
Validation loss: 1.765312030751218

Epoch: 6| Step: 9
Training loss: 0.5331405401229858
Validation loss: 1.7581527540760655

Epoch: 6| Step: 10
Training loss: 0.41941583156585693
Validation loss: 1.8164181811835176

Epoch: 6| Step: 11
Training loss: 0.3556700050830841
Validation loss: 1.7756039301554363

Epoch: 6| Step: 12
Training loss: 0.6648945808410645
Validation loss: 1.7881949896453528

Epoch: 6| Step: 13
Training loss: 0.679436445236206
Validation loss: 1.7532705145497476

Epoch: 244| Step: 0
Training loss: 0.8794592022895813
Validation loss: 1.7788700493433143

Epoch: 6| Step: 1
Training loss: 0.2305910587310791
Validation loss: 1.798962608460457

Epoch: 6| Step: 2
Training loss: 0.503326416015625
Validation loss: 1.7718972134333786

Epoch: 6| Step: 3
Training loss: 0.42975836992263794
Validation loss: 1.78056122667046

Epoch: 6| Step: 4
Training loss: 0.4282277524471283
Validation loss: 1.7950148415821854

Epoch: 6| Step: 5
Training loss: 0.27030542492866516
Validation loss: 1.8048439782152894

Epoch: 6| Step: 6
Training loss: 0.6749398708343506
Validation loss: 1.7670702177991149

Epoch: 6| Step: 7
Training loss: 1.0647516250610352
Validation loss: 1.777859123804236

Epoch: 6| Step: 8
Training loss: 0.325086772441864
Validation loss: 1.7857704085688437

Epoch: 6| Step: 9
Training loss: 0.42678120732307434
Validation loss: 1.7924073588463567

Epoch: 6| Step: 10
Training loss: 0.45737379789352417
Validation loss: 1.7985025644302368

Epoch: 6| Step: 11
Training loss: 0.8553863763809204
Validation loss: 1.8195967917801232

Epoch: 6| Step: 12
Training loss: 0.5252877473831177
Validation loss: 1.839307258206029

Epoch: 6| Step: 13
Training loss: 0.6617577075958252
Validation loss: 1.7758672416851085

Epoch: 245| Step: 0
Training loss: 0.5712345242500305
Validation loss: 1.76829558034097

Epoch: 6| Step: 1
Training loss: 0.5105494856834412
Validation loss: 1.830105076554001

Epoch: 6| Step: 2
Training loss: 0.4002450108528137
Validation loss: 1.7840181576308383

Epoch: 6| Step: 3
Training loss: 0.5979679822921753
Validation loss: 1.8045311102303125

Epoch: 6| Step: 4
Training loss: 0.6635196208953857
Validation loss: 1.831685341814513

Epoch: 6| Step: 5
Training loss: 0.5514107346534729
Validation loss: 1.8088894044199297

Epoch: 6| Step: 6
Training loss: 0.44972559809684753
Validation loss: 1.8390131176158946

Epoch: 6| Step: 7
Training loss: 0.6556394100189209
Validation loss: 1.8148079085093674

Epoch: 6| Step: 8
Training loss: 0.555509090423584
Validation loss: 1.8455635886038504

Epoch: 6| Step: 9
Training loss: 0.4168984591960907
Validation loss: 1.8603453225986932

Epoch: 6| Step: 10
Training loss: 0.7949773073196411
Validation loss: 1.8641970619078605

Epoch: 6| Step: 11
Training loss: 0.6260305047035217
Validation loss: 1.8335064508581673

Epoch: 6| Step: 12
Training loss: 0.4117460548877716
Validation loss: 1.822928410704418

Epoch: 6| Step: 13
Training loss: 0.987410306930542
Validation loss: 1.7869516136825725

Epoch: 246| Step: 0
Training loss: 0.617849588394165
Validation loss: 1.756560428168184

Epoch: 6| Step: 1
Training loss: 0.6092809438705444
Validation loss: 1.7801990073214295

Epoch: 6| Step: 2
Training loss: 0.19943079352378845
Validation loss: 1.78009170357899

Epoch: 6| Step: 3
Training loss: 0.580864429473877
Validation loss: 1.8044457743244786

Epoch: 6| Step: 4
Training loss: 0.49393898248672485
Validation loss: 1.7623386229238203

Epoch: 6| Step: 5
Training loss: 0.33822107315063477
Validation loss: 1.79329264292153

Epoch: 6| Step: 6
Training loss: 0.37395891547203064
Validation loss: 1.7656200009007608

Epoch: 6| Step: 7
Training loss: 0.6202787160873413
Validation loss: 1.7380260408565562

Epoch: 6| Step: 8
Training loss: 1.051173448562622
Validation loss: 1.7513540380744523

Epoch: 6| Step: 9
Training loss: 0.4254319965839386
Validation loss: 1.7232461193556428

Epoch: 6| Step: 10
Training loss: 0.568641185760498
Validation loss: 1.7156253284023655

Epoch: 6| Step: 11
Training loss: 0.5018782615661621
Validation loss: 1.7231696574918685

Epoch: 6| Step: 12
Training loss: 0.6651175022125244
Validation loss: 1.7185219410927064

Epoch: 6| Step: 13
Training loss: 0.6023839712142944
Validation loss: 1.7467421126622025

Epoch: 247| Step: 0
Training loss: 0.3427009880542755
Validation loss: 1.756765209218507

Epoch: 6| Step: 1
Training loss: 0.45525264739990234
Validation loss: 1.7367780054769208

Epoch: 6| Step: 2
Training loss: 0.34876322746276855
Validation loss: 1.7723973784395444

Epoch: 6| Step: 3
Training loss: 1.1064388751983643
Validation loss: 1.7512228796558995

Epoch: 6| Step: 4
Training loss: 0.6475721001625061
Validation loss: 1.7364952589875908

Epoch: 6| Step: 5
Training loss: 0.7974240183830261
Validation loss: 1.7378576494032336

Epoch: 6| Step: 6
Training loss: 0.3410000801086426
Validation loss: 1.7654121806544643

Epoch: 6| Step: 7
Training loss: 0.6071207523345947
Validation loss: 1.7289928954134706

Epoch: 6| Step: 8
Training loss: 0.46510905027389526
Validation loss: 1.7636083172213646

Epoch: 6| Step: 9
Training loss: 0.3519075810909271
Validation loss: 1.7384594935242847

Epoch: 6| Step: 10
Training loss: 0.6389907598495483
Validation loss: 1.7776879905372538

Epoch: 6| Step: 11
Training loss: 0.2644229829311371
Validation loss: 1.801159167802462

Epoch: 6| Step: 12
Training loss: 0.6804108023643494
Validation loss: 1.7983890297592326

Epoch: 6| Step: 13
Training loss: 0.4826292395591736
Validation loss: 1.8042130765094553

Epoch: 248| Step: 0
Training loss: 0.43154996633529663
Validation loss: 1.8054838206178399

Epoch: 6| Step: 1
Training loss: 0.3767337203025818
Validation loss: 1.7654743989308674

Epoch: 6| Step: 2
Training loss: 0.40519440174102783
Validation loss: 1.7641816626312912

Epoch: 6| Step: 3
Training loss: 0.6414486169815063
Validation loss: 1.7914242975173458

Epoch: 6| Step: 4
Training loss: 0.36073607206344604
Validation loss: 1.752580560663695

Epoch: 6| Step: 5
Training loss: 0.34223487973213196
Validation loss: 1.7328598435207079

Epoch: 6| Step: 6
Training loss: 0.6491369605064392
Validation loss: 1.7299860690229683

Epoch: 6| Step: 7
Training loss: 0.870311975479126
Validation loss: 1.7262125489532307

Epoch: 6| Step: 8
Training loss: 0.6989045739173889
Validation loss: 1.7134509535245999

Epoch: 6| Step: 9
Training loss: 0.5330538749694824
Validation loss: 1.716417335694836

Epoch: 6| Step: 10
Training loss: 0.6595481038093567
Validation loss: 1.7512838430302118

Epoch: 6| Step: 11
Training loss: 0.485530823469162
Validation loss: 1.7927975423874394

Epoch: 6| Step: 12
Training loss: 0.19169792532920837
Validation loss: 1.7745923893426054

Epoch: 6| Step: 13
Training loss: 1.0585248470306396
Validation loss: 1.8194442705441547

Epoch: 249| Step: 0
Training loss: 0.35602909326553345
Validation loss: 1.8216708603725638

Epoch: 6| Step: 1
Training loss: 0.6313378810882568
Validation loss: 1.7675512862461868

Epoch: 6| Step: 2
Training loss: 0.487259179353714
Validation loss: 1.7322865916836647

Epoch: 6| Step: 3
Training loss: 0.6116418838500977
Validation loss: 1.725514716999505

Epoch: 6| Step: 4
Training loss: 0.49432462453842163
Validation loss: 1.691397355448815

Epoch: 6| Step: 5
Training loss: 0.6555116176605225
Validation loss: 1.7066568764307166

Epoch: 6| Step: 6
Training loss: 0.5712888836860657
Validation loss: 1.7370270952101676

Epoch: 6| Step: 7
Training loss: 0.699618935585022
Validation loss: 1.7807897175512006

Epoch: 6| Step: 8
Training loss: 0.5003306865692139
Validation loss: 1.7659617854702858

Epoch: 6| Step: 9
Training loss: 0.7451696991920471
Validation loss: 1.7807641811268304

Epoch: 6| Step: 10
Training loss: 0.35767728090286255
Validation loss: 1.7769250972296602

Epoch: 6| Step: 11
Training loss: 0.338493674993515
Validation loss: 1.7939177136267386

Epoch: 6| Step: 12
Training loss: 0.6078964471817017
Validation loss: 1.7725299353240638

Epoch: 6| Step: 13
Training loss: 0.4307120144367218
Validation loss: 1.7433510159933439

Epoch: 250| Step: 0
Training loss: 0.5880192518234253
Validation loss: 1.7334250045079056

Epoch: 6| Step: 1
Training loss: 0.3809329569339752
Validation loss: 1.7446067845949562

Epoch: 6| Step: 2
Training loss: 0.39123284816741943
Validation loss: 1.7482148421707975

Epoch: 6| Step: 3
Training loss: 0.3966452181339264
Validation loss: 1.7387163203249696

Epoch: 6| Step: 4
Training loss: 0.7413466572761536
Validation loss: 1.7471632880549277

Epoch: 6| Step: 5
Training loss: 0.49553579092025757
Validation loss: 1.748763781721874

Epoch: 6| Step: 6
Training loss: 0.46566176414489746
Validation loss: 1.7640704313913982

Epoch: 6| Step: 7
Training loss: 0.7142898440361023
Validation loss: 1.7437542984562535

Epoch: 6| Step: 8
Training loss: 0.5151698589324951
Validation loss: 1.7198363632284186

Epoch: 6| Step: 9
Training loss: 0.2069503664970398
Validation loss: 1.7541990805697698

Epoch: 6| Step: 10
Training loss: 0.7241730690002441
Validation loss: 1.7316263952562887

Epoch: 6| Step: 11
Training loss: 0.30743351578712463
Validation loss: 1.7579347574582664

Epoch: 6| Step: 12
Training loss: 0.8062978982925415
Validation loss: 1.7606017012749948

Epoch: 6| Step: 13
Training loss: 0.2553597390651703
Validation loss: 1.7986428712003975

Epoch: 251| Step: 0
Training loss: 0.44831541180610657
Validation loss: 1.786980377730503

Epoch: 6| Step: 1
Training loss: 0.4567166566848755
Validation loss: 1.7844490325579079

Epoch: 6| Step: 2
Training loss: 0.7262235879898071
Validation loss: 1.7716612495401853

Epoch: 6| Step: 3
Training loss: 0.5354574918746948
Validation loss: 1.7417015849903066

Epoch: 6| Step: 4
Training loss: 0.6093360185623169
Validation loss: 1.7347971380397837

Epoch: 6| Step: 5
Training loss: 0.728807806968689
Validation loss: 1.7581823987345542

Epoch: 6| Step: 6
Training loss: 0.46140652894973755
Validation loss: 1.72929201843918

Epoch: 6| Step: 7
Training loss: 0.25152695178985596
Validation loss: 1.7602677858004006

Epoch: 6| Step: 8
Training loss: 0.4850035309791565
Validation loss: 1.7701323275925012

Epoch: 6| Step: 9
Training loss: 0.6611919403076172
Validation loss: 1.783021298787927

Epoch: 6| Step: 10
Training loss: 0.26589977741241455
Validation loss: 1.7666538556416829

Epoch: 6| Step: 11
Training loss: 0.5772242546081543
Validation loss: 1.7594835578754384

Epoch: 6| Step: 12
Training loss: 0.2984452247619629
Validation loss: 1.7722432831282258

Epoch: 6| Step: 13
Training loss: 0.45022571086883545
Validation loss: 1.75023821092421

Epoch: 252| Step: 0
Training loss: 0.3532748818397522
Validation loss: 1.7711335625699771

Epoch: 6| Step: 1
Training loss: 0.47917696833610535
Validation loss: 1.782018102625365

Epoch: 6| Step: 2
Training loss: 0.5517888069152832
Validation loss: 1.7970674883934759

Epoch: 6| Step: 3
Training loss: 0.6870269775390625
Validation loss: 1.7999887620249102

Epoch: 6| Step: 4
Training loss: 0.4889116883277893
Validation loss: 1.7897679882664834

Epoch: 6| Step: 5
Training loss: 0.4609569311141968
Validation loss: 1.8285428477871803

Epoch: 6| Step: 6
Training loss: 0.6189448833465576
Validation loss: 1.8182370047415457

Epoch: 6| Step: 7
Training loss: 0.4375046491622925
Validation loss: 1.8168831115127893

Epoch: 6| Step: 8
Training loss: 0.737173855304718
Validation loss: 1.7630779717558174

Epoch: 6| Step: 9
Training loss: 0.3651879131793976
Validation loss: 1.7443043314000612

Epoch: 6| Step: 10
Training loss: 0.3761855959892273
Validation loss: 1.7227423985799153

Epoch: 6| Step: 11
Training loss: 0.5099244713783264
Validation loss: 1.7213482561931814

Epoch: 6| Step: 12
Training loss: 0.3587479591369629
Validation loss: 1.7422443615492953

Epoch: 6| Step: 13
Training loss: 1.2308927774429321
Validation loss: 1.7391904528423021

Epoch: 253| Step: 0
Training loss: 0.44741275906562805
Validation loss: 1.7459490068497197

Epoch: 6| Step: 1
Training loss: 0.4777146875858307
Validation loss: 1.7408304188841133

Epoch: 6| Step: 2
Training loss: 0.3038269579410553
Validation loss: 1.76996478983151

Epoch: 6| Step: 3
Training loss: 0.5671995878219604
Validation loss: 1.7661046187082927

Epoch: 6| Step: 4
Training loss: 0.5892168879508972
Validation loss: 1.7729620523350214

Epoch: 6| Step: 5
Training loss: 0.48916202783584595
Validation loss: 1.797424413824594

Epoch: 6| Step: 6
Training loss: 0.4907078146934509
Validation loss: 1.8316396115928568

Epoch: 6| Step: 7
Training loss: 0.5452128648757935
Validation loss: 1.7931145134792532

Epoch: 6| Step: 8
Training loss: 0.8290814161300659
Validation loss: 1.8082562159466486

Epoch: 6| Step: 9
Training loss: 0.3877260088920593
Validation loss: 1.7556005972687916

Epoch: 6| Step: 10
Training loss: 0.7054876089096069
Validation loss: 1.7375991754634406

Epoch: 6| Step: 11
Training loss: 0.516086220741272
Validation loss: 1.7084133727576143

Epoch: 6| Step: 12
Training loss: 0.555016040802002
Validation loss: 1.6898346985540083

Epoch: 6| Step: 13
Training loss: 0.2773570418357849
Validation loss: 1.711253563563029

Epoch: 254| Step: 0
Training loss: 0.3912200331687927
Validation loss: 1.7254884717284993

Epoch: 6| Step: 1
Training loss: 0.4706563353538513
Validation loss: 1.73089212371457

Epoch: 6| Step: 2
Training loss: 0.8255046606063843
Validation loss: 1.774319028341642

Epoch: 6| Step: 3
Training loss: 0.7868243455886841
Validation loss: 1.826088027287555

Epoch: 6| Step: 4
Training loss: 0.36810198426246643
Validation loss: 1.807414408653013

Epoch: 6| Step: 5
Training loss: 0.395303875207901
Validation loss: 1.8853352505673644

Epoch: 6| Step: 6
Training loss: 0.4333638548851013
Validation loss: 1.8384568973254132

Epoch: 6| Step: 7
Training loss: 0.4567524194717407
Validation loss: 1.8350225828027213

Epoch: 6| Step: 8
Training loss: 0.4179120659828186
Validation loss: 1.8196739227541032

Epoch: 6| Step: 9
Training loss: 0.3573538661003113
Validation loss: 1.8125787101766115

Epoch: 6| Step: 10
Training loss: 0.7151700258255005
Validation loss: 1.8162407759697206

Epoch: 6| Step: 11
Training loss: 0.5559093952178955
Validation loss: 1.804244210643153

Epoch: 6| Step: 12
Training loss: 0.5490012168884277
Validation loss: 1.7690701561589395

Epoch: 6| Step: 13
Training loss: 0.46336254477500916
Validation loss: 1.789089443863079

Epoch: 255| Step: 0
Training loss: 0.5190715789794922
Validation loss: 1.7609305022865214

Epoch: 6| Step: 1
Training loss: 0.7602814435958862
Validation loss: 1.757667645331352

Epoch: 6| Step: 2
Training loss: 0.7015637159347534
Validation loss: 1.7488184846857542

Epoch: 6| Step: 3
Training loss: 0.3672183156013489
Validation loss: 1.7673930968007734

Epoch: 6| Step: 4
Training loss: 0.29418134689331055
Validation loss: 1.7589557619505032

Epoch: 6| Step: 5
Training loss: 0.3592554032802582
Validation loss: 1.7639809744332426

Epoch: 6| Step: 6
Training loss: 0.8566069602966309
Validation loss: 1.7718224397269629

Epoch: 6| Step: 7
Training loss: 0.45450833439826965
Validation loss: 1.7558098916084535

Epoch: 6| Step: 8
Training loss: 0.4869324564933777
Validation loss: 1.799450949956012

Epoch: 6| Step: 9
Training loss: 0.24740466475486755
Validation loss: 1.8372929903768724

Epoch: 6| Step: 10
Training loss: 0.4804224371910095
Validation loss: 1.790595454554404

Epoch: 6| Step: 11
Training loss: 0.4351077079772949
Validation loss: 1.7722950455962971

Epoch: 6| Step: 12
Training loss: 0.6470573544502258
Validation loss: 1.7590113352703791

Epoch: 6| Step: 13
Training loss: 0.20405980944633484
Validation loss: 1.7502938547442037

Epoch: 256| Step: 0
Training loss: 0.285550594329834
Validation loss: 1.743870419840659

Epoch: 6| Step: 1
Training loss: 0.7477982640266418
Validation loss: 1.695510862975992

Epoch: 6| Step: 2
Training loss: 0.6081745028495789
Validation loss: 1.7258436564476258

Epoch: 6| Step: 3
Training loss: 0.5612598657608032
Validation loss: 1.7416030976080126

Epoch: 6| Step: 4
Training loss: 0.532770574092865
Validation loss: 1.7461977210096133

Epoch: 6| Step: 5
Training loss: 0.5678733587265015
Validation loss: 1.7577769935771983

Epoch: 6| Step: 6
Training loss: 0.529276967048645
Validation loss: 1.763480551781193

Epoch: 6| Step: 7
Training loss: 0.6997122764587402
Validation loss: 1.7664624144954066

Epoch: 6| Step: 8
Training loss: 0.4642372727394104
Validation loss: 1.7376937507301249

Epoch: 6| Step: 9
Training loss: 0.3363376557826996
Validation loss: 1.8061459910485052

Epoch: 6| Step: 10
Training loss: 0.20971620082855225
Validation loss: 1.7667802636341383

Epoch: 6| Step: 11
Training loss: 0.40517640113830566
Validation loss: 1.7871210869922434

Epoch: 6| Step: 12
Training loss: 0.5166635513305664
Validation loss: 1.7608675443997948

Epoch: 6| Step: 13
Training loss: 0.2876986563205719
Validation loss: 1.732508756781137

Epoch: 257| Step: 0
Training loss: 0.23209303617477417
Validation loss: 1.7414241708734983

Epoch: 6| Step: 1
Training loss: 0.23119452595710754
Validation loss: 1.7757480323955577

Epoch: 6| Step: 2
Training loss: 0.43242403864860535
Validation loss: 1.7800809221882974

Epoch: 6| Step: 3
Training loss: 0.5145043134689331
Validation loss: 1.7493213248509232

Epoch: 6| Step: 4
Training loss: 0.35547077655792236
Validation loss: 1.7446414514254498

Epoch: 6| Step: 5
Training loss: 0.5824612975120544
Validation loss: 1.7755309125428558

Epoch: 6| Step: 6
Training loss: 0.7750443816184998
Validation loss: 1.7713144158804288

Epoch: 6| Step: 7
Training loss: 0.32078397274017334
Validation loss: 1.7971922633468465

Epoch: 6| Step: 8
Training loss: 0.4349345862865448
Validation loss: 1.8025723657300394

Epoch: 6| Step: 9
Training loss: 0.754540205001831
Validation loss: 1.8009714849533573

Epoch: 6| Step: 10
Training loss: 0.510147213935852
Validation loss: 1.802098379340223

Epoch: 6| Step: 11
Training loss: 0.5276259183883667
Validation loss: 1.8140012961561962

Epoch: 6| Step: 12
Training loss: 0.7928040027618408
Validation loss: 1.8304203761521207

Epoch: 6| Step: 13
Training loss: 0.36991018056869507
Validation loss: 1.8042217557148268

Epoch: 258| Step: 0
Training loss: 0.25542593002319336
Validation loss: 1.825482895297389

Epoch: 6| Step: 1
Training loss: 0.20173101127147675
Validation loss: 1.8136759752868323

Epoch: 6| Step: 2
Training loss: 0.6084417104721069
Validation loss: 1.7818481127421062

Epoch: 6| Step: 3
Training loss: 0.4666514992713928
Validation loss: 1.7617754590126775

Epoch: 6| Step: 4
Training loss: 0.5614930987358093
Validation loss: 1.7379361839704617

Epoch: 6| Step: 5
Training loss: 0.46070343255996704
Validation loss: 1.710728181305752

Epoch: 6| Step: 6
Training loss: 0.35772478580474854
Validation loss: 1.7129848900661673

Epoch: 6| Step: 7
Training loss: 0.5379137992858887
Validation loss: 1.7056176739354287

Epoch: 6| Step: 8
Training loss: 0.8325688242912292
Validation loss: 1.709461219849125

Epoch: 6| Step: 9
Training loss: 0.4300101697444916
Validation loss: 1.7066855379330215

Epoch: 6| Step: 10
Training loss: 0.37515658140182495
Validation loss: 1.7146766275487921

Epoch: 6| Step: 11
Training loss: 0.7268598079681396
Validation loss: 1.7299688785306868

Epoch: 6| Step: 12
Training loss: 0.45938122272491455
Validation loss: 1.7358618064593243

Epoch: 6| Step: 13
Training loss: 0.43931901454925537
Validation loss: 1.722363583503231

Epoch: 259| Step: 0
Training loss: 0.2515043318271637
Validation loss: 1.725675932822689

Epoch: 6| Step: 1
Training loss: 0.3926771879196167
Validation loss: 1.7510265496469313

Epoch: 6| Step: 2
Training loss: 0.4058074951171875
Validation loss: 1.7479073116856236

Epoch: 6| Step: 3
Training loss: 0.30728858709335327
Validation loss: 1.747946948133489

Epoch: 6| Step: 4
Training loss: 0.4325892925262451
Validation loss: 1.7395745490186958

Epoch: 6| Step: 5
Training loss: 0.3805217146873474
Validation loss: 1.7368397687071113

Epoch: 6| Step: 6
Training loss: 0.6143980026245117
Validation loss: 1.7178336702367312

Epoch: 6| Step: 7
Training loss: 0.845260500907898
Validation loss: 1.7736770773446688

Epoch: 6| Step: 8
Training loss: 0.45403653383255005
Validation loss: 1.7924754722144014

Epoch: 6| Step: 9
Training loss: 0.41218000650405884
Validation loss: 1.7736264723603443

Epoch: 6| Step: 10
Training loss: 0.3706061840057373
Validation loss: 1.7752601087734263

Epoch: 6| Step: 11
Training loss: 0.60402512550354
Validation loss: 1.7075056183722712

Epoch: 6| Step: 12
Training loss: 0.5566062927246094
Validation loss: 1.7286888117431312

Epoch: 6| Step: 13
Training loss: 0.5517123341560364
Validation loss: 1.7247276459970782

Epoch: 260| Step: 0
Training loss: 0.5456036925315857
Validation loss: 1.7539010278640255

Epoch: 6| Step: 1
Training loss: 0.47694092988967896
Validation loss: 1.7595223021763626

Epoch: 6| Step: 2
Training loss: 0.5443496704101562
Validation loss: 1.7580927277124057

Epoch: 6| Step: 3
Training loss: 0.3716191053390503
Validation loss: 1.7728282302938483

Epoch: 6| Step: 4
Training loss: 0.48432326316833496
Validation loss: 1.8091298982661257

Epoch: 6| Step: 5
Training loss: 0.3443591594696045
Validation loss: 1.8174710645470569

Epoch: 6| Step: 6
Training loss: 0.37888872623443604
Validation loss: 1.8249109047715382

Epoch: 6| Step: 7
Training loss: 0.4556512236595154
Validation loss: 1.8801722449641074

Epoch: 6| Step: 8
Training loss: 0.615412712097168
Validation loss: 1.875430481408232

Epoch: 6| Step: 9
Training loss: 0.5737019777297974
Validation loss: 1.9171666893907773

Epoch: 6| Step: 10
Training loss: 0.4099445939064026
Validation loss: 1.895996634678174

Epoch: 6| Step: 11
Training loss: 0.8964367508888245
Validation loss: 1.9094646592294016

Epoch: 6| Step: 12
Training loss: 0.6027718782424927
Validation loss: 1.8566291627063547

Epoch: 6| Step: 13
Training loss: 0.45475757122039795
Validation loss: 1.7745408845204178

Epoch: 261| Step: 0
Training loss: 0.7420324683189392
Validation loss: 1.8135671666873399

Epoch: 6| Step: 1
Training loss: 0.6333714723587036
Validation loss: 1.757987832510343

Epoch: 6| Step: 2
Training loss: 0.36221545934677124
Validation loss: 1.7587577707024031

Epoch: 6| Step: 3
Training loss: 0.6587451696395874
Validation loss: 1.7374108991315287

Epoch: 6| Step: 4
Training loss: 0.2716142535209656
Validation loss: 1.7317046580776092

Epoch: 6| Step: 5
Training loss: 0.49310117959976196
Validation loss: 1.7600885693744948

Epoch: 6| Step: 6
Training loss: 0.7029731869697571
Validation loss: 1.7607613186682425

Epoch: 6| Step: 7
Training loss: 0.39464083313941956
Validation loss: 1.7484421819768927

Epoch: 6| Step: 8
Training loss: 0.1625456064939499
Validation loss: 1.7542612552642822

Epoch: 6| Step: 9
Training loss: 0.5044318437576294
Validation loss: 1.7894092170141076

Epoch: 6| Step: 10
Training loss: 0.38162529468536377
Validation loss: 1.7679208965711697

Epoch: 6| Step: 11
Training loss: 0.3356549143791199
Validation loss: 1.7800845561488983

Epoch: 6| Step: 12
Training loss: 0.3704915940761566
Validation loss: 1.7417213916778564

Epoch: 6| Step: 13
Training loss: 0.6667220592498779
Validation loss: 1.7590654383423507

Epoch: 262| Step: 0
Training loss: 0.7511237263679504
Validation loss: 1.710457887700809

Epoch: 6| Step: 1
Training loss: 0.9927207231521606
Validation loss: 1.7173748464994534

Epoch: 6| Step: 2
Training loss: 0.2440015971660614
Validation loss: 1.7132581408305834

Epoch: 6| Step: 3
Training loss: 0.44203561544418335
Validation loss: 1.739057062774576

Epoch: 6| Step: 4
Training loss: 0.3009898066520691
Validation loss: 1.703454972595297

Epoch: 6| Step: 5
Training loss: 0.34003761410713196
Validation loss: 1.7268107898773686

Epoch: 6| Step: 6
Training loss: 0.4601062834262848
Validation loss: 1.7215999518671343

Epoch: 6| Step: 7
Training loss: 0.5275635719299316
Validation loss: 1.7532015718439573

Epoch: 6| Step: 8
Training loss: 0.4862569272518158
Validation loss: 1.7630473388138639

Epoch: 6| Step: 9
Training loss: 0.38999801874160767
Validation loss: 1.6977022245366087

Epoch: 6| Step: 10
Training loss: 0.3798426389694214
Validation loss: 1.6703978430840276

Epoch: 6| Step: 11
Training loss: 0.5926953554153442
Validation loss: 1.6579622401986072

Epoch: 6| Step: 12
Training loss: 0.6292062997817993
Validation loss: 1.664186728897915

Epoch: 6| Step: 13
Training loss: 0.21467511355876923
Validation loss: 1.6418647894295313

Epoch: 263| Step: 0
Training loss: 0.4172130227088928
Validation loss: 1.7086253621244942

Epoch: 6| Step: 1
Training loss: 0.5057006478309631
Validation loss: 1.7062230187077676

Epoch: 6| Step: 2
Training loss: 0.6664659976959229
Validation loss: 1.7010997828616892

Epoch: 6| Step: 3
Training loss: 0.531694769859314
Validation loss: 1.7089259880845264

Epoch: 6| Step: 4
Training loss: 0.42039602994918823
Validation loss: 1.7111628722119074

Epoch: 6| Step: 5
Training loss: 0.464508593082428
Validation loss: 1.6982444563219625

Epoch: 6| Step: 6
Training loss: 0.5405908823013306
Validation loss: 1.7081380428806427

Epoch: 6| Step: 7
Training loss: 0.37911295890808105
Validation loss: 1.7557639793683124

Epoch: 6| Step: 8
Training loss: 0.5088976621627808
Validation loss: 1.7412510661668674

Epoch: 6| Step: 9
Training loss: 0.3138435184955597
Validation loss: 1.7373771731571486

Epoch: 6| Step: 10
Training loss: 0.309662401676178
Validation loss: 1.7214927481066795

Epoch: 6| Step: 11
Training loss: 0.6687296628952026
Validation loss: 1.7467928573649416

Epoch: 6| Step: 12
Training loss: 0.6148948073387146
Validation loss: 1.71640351510817

Epoch: 6| Step: 13
Training loss: 0.3544532060623169
Validation loss: 1.6806006611034434

Epoch: 264| Step: 0
Training loss: 0.6726084351539612
Validation loss: 1.673451881895783

Epoch: 6| Step: 1
Training loss: 0.5836277604103088
Validation loss: 1.656843291815891

Epoch: 6| Step: 2
Training loss: 0.434106707572937
Validation loss: 1.683922302338385

Epoch: 6| Step: 3
Training loss: 0.38391947746276855
Validation loss: 1.701674581855856

Epoch: 6| Step: 4
Training loss: 0.6353346109390259
Validation loss: 1.6974947516636183

Epoch: 6| Step: 5
Training loss: 0.4862057566642761
Validation loss: 1.6882408882981987

Epoch: 6| Step: 6
Training loss: 0.5444859266281128
Validation loss: 1.6687515217770812

Epoch: 6| Step: 7
Training loss: 0.2291432023048401
Validation loss: 1.66300719335515

Epoch: 6| Step: 8
Training loss: 0.3543165624141693
Validation loss: 1.7240459611338954

Epoch: 6| Step: 9
Training loss: 0.600797712802887
Validation loss: 1.8697580675924979

Epoch: 6| Step: 10
Training loss: 0.5502574443817139
Validation loss: 1.9013178194722822

Epoch: 6| Step: 11
Training loss: 0.6559152603149414
Validation loss: 1.8659196951056038

Epoch: 6| Step: 12
Training loss: 0.43464502692222595
Validation loss: 1.8793000508380193

Epoch: 6| Step: 13
Training loss: 0.7652763724327087
Validation loss: 1.8388065343262048

Epoch: 265| Step: 0
Training loss: 0.4191618859767914
Validation loss: 1.8251763466865785

Epoch: 6| Step: 1
Training loss: 0.4456567168235779
Validation loss: 1.7421481250434794

Epoch: 6| Step: 2
Training loss: 0.5476112365722656
Validation loss: 1.761526346206665

Epoch: 6| Step: 3
Training loss: 0.58590167760849
Validation loss: 1.7371443125509447

Epoch: 6| Step: 4
Training loss: 0.6274338960647583
Validation loss: 1.7395456426887101

Epoch: 6| Step: 5
Training loss: 0.7729010581970215
Validation loss: 1.745181010615441

Epoch: 6| Step: 6
Training loss: 0.9167808890342712
Validation loss: 1.7579103426266742

Epoch: 6| Step: 7
Training loss: 0.6328485608100891
Validation loss: 1.7370858538535334

Epoch: 6| Step: 8
Training loss: 0.5193648338317871
Validation loss: 1.7392317210474322

Epoch: 6| Step: 9
Training loss: 0.452623575925827
Validation loss: 1.7324834639026272

Epoch: 6| Step: 10
Training loss: 0.40202733874320984
Validation loss: 1.8225095656610304

Epoch: 6| Step: 11
Training loss: 0.5962190628051758
Validation loss: 1.8350739825156428

Epoch: 6| Step: 12
Training loss: 0.34063318371772766
Validation loss: 1.830644679325883

Epoch: 6| Step: 13
Training loss: 0.289745032787323
Validation loss: 1.787298817788401

Epoch: 266| Step: 0
Training loss: 0.5085930824279785
Validation loss: 1.7716073630958475

Epoch: 6| Step: 1
Training loss: 0.6042166948318481
Validation loss: 1.7605034151384908

Epoch: 6| Step: 2
Training loss: 0.5154715776443481
Validation loss: 1.7591542428539646

Epoch: 6| Step: 3
Training loss: 0.6838713884353638
Validation loss: 1.7833705448335218

Epoch: 6| Step: 4
Training loss: 0.7931023836135864
Validation loss: 1.7758770360741565

Epoch: 6| Step: 5
Training loss: 0.6840226650238037
Validation loss: 1.7824928888710596

Epoch: 6| Step: 6
Training loss: 0.29911646246910095
Validation loss: 1.7499607224618234

Epoch: 6| Step: 7
Training loss: 0.34706008434295654
Validation loss: 1.7333643718432354

Epoch: 6| Step: 8
Training loss: 0.4367803633213043
Validation loss: 1.7330179278568556

Epoch: 6| Step: 9
Training loss: 0.26456525921821594
Validation loss: 1.7415970371615501

Epoch: 6| Step: 10
Training loss: 0.30846452713012695
Validation loss: 1.71579376856486

Epoch: 6| Step: 11
Training loss: 0.3117620348930359
Validation loss: 1.7379856686438284

Epoch: 6| Step: 12
Training loss: 0.4481579065322876
Validation loss: 1.744476048536198

Epoch: 6| Step: 13
Training loss: 0.6499934792518616
Validation loss: 1.70645603569605

Epoch: 267| Step: 0
Training loss: 0.7113591432571411
Validation loss: 1.6845311759620585

Epoch: 6| Step: 1
Training loss: 0.3872266709804535
Validation loss: 1.7069828036010906

Epoch: 6| Step: 2
Training loss: 0.43137794733047485
Validation loss: 1.645985734078192

Epoch: 6| Step: 3
Training loss: 0.4767362177371979
Validation loss: 1.694323355151761

Epoch: 6| Step: 4
Training loss: 0.49791115522384644
Validation loss: 1.680087116456801

Epoch: 6| Step: 5
Training loss: 0.40491852164268494
Validation loss: 1.6863846689142206

Epoch: 6| Step: 6
Training loss: 0.3641350269317627
Validation loss: 1.7529501902159823

Epoch: 6| Step: 7
Training loss: 0.500342607498169
Validation loss: 1.7219187892893308

Epoch: 6| Step: 8
Training loss: 0.2844887673854828
Validation loss: 1.7454027463031072

Epoch: 6| Step: 9
Training loss: 0.3608741760253906
Validation loss: 1.7542966783687632

Epoch: 6| Step: 10
Training loss: 0.3462742567062378
Validation loss: 1.7600734464583858

Epoch: 6| Step: 11
Training loss: 0.5054552555084229
Validation loss: 1.7424802921151603

Epoch: 6| Step: 12
Training loss: 0.3631709814071655
Validation loss: 1.7484137281294791

Epoch: 6| Step: 13
Training loss: 0.40377944707870483
Validation loss: 1.7310017257608392

Epoch: 268| Step: 0
Training loss: 0.427295446395874
Validation loss: 1.7404065324414162

Epoch: 6| Step: 1
Training loss: 0.36314475536346436
Validation loss: 1.7351704669255081

Epoch: 6| Step: 2
Training loss: 0.5496603846549988
Validation loss: 1.741001041986609

Epoch: 6| Step: 3
Training loss: 0.3462996780872345
Validation loss: 1.7497427027712587

Epoch: 6| Step: 4
Training loss: 0.34802737832069397
Validation loss: 1.7710370889274023

Epoch: 6| Step: 5
Training loss: 0.43322694301605225
Validation loss: 1.8131077481854347

Epoch: 6| Step: 6
Training loss: 0.6169538497924805
Validation loss: 1.7925348486951602

Epoch: 6| Step: 7
Training loss: 0.420138418674469
Validation loss: 1.753785487144224

Epoch: 6| Step: 8
Training loss: 0.5605606436729431
Validation loss: 1.72241981439693

Epoch: 6| Step: 9
Training loss: 0.6726682186126709
Validation loss: 1.6953887888180312

Epoch: 6| Step: 10
Training loss: 0.30242425203323364
Validation loss: 1.6766610158387052

Epoch: 6| Step: 11
Training loss: 0.4259025454521179
Validation loss: 1.6827288468678792

Epoch: 6| Step: 12
Training loss: 0.3369100093841553
Validation loss: 1.6914591507245136

Epoch: 6| Step: 13
Training loss: 0.5003429055213928
Validation loss: 1.7203353271689465

Epoch: 269| Step: 0
Training loss: 0.4824633300304413
Validation loss: 1.6948761286274079

Epoch: 6| Step: 1
Training loss: 0.35657361149787903
Validation loss: 1.7053541239871775

Epoch: 6| Step: 2
Training loss: 0.41243335604667664
Validation loss: 1.7029975691149313

Epoch: 6| Step: 3
Training loss: 0.3920471668243408
Validation loss: 1.714125274330057

Epoch: 6| Step: 4
Training loss: 0.41634687781333923
Validation loss: 1.6806540912197483

Epoch: 6| Step: 5
Training loss: 0.5072464942932129
Validation loss: 1.7117008880902362

Epoch: 6| Step: 6
Training loss: 0.46394234895706177
Validation loss: 1.7207787293259815

Epoch: 6| Step: 7
Training loss: 0.8338082432746887
Validation loss: 1.7340062433673489

Epoch: 6| Step: 8
Training loss: 0.5692739486694336
Validation loss: 1.7670719956838956

Epoch: 6| Step: 9
Training loss: 0.4179806113243103
Validation loss: 1.793320430222378

Epoch: 6| Step: 10
Training loss: 0.3992847502231598
Validation loss: 1.7625782387230986

Epoch: 6| Step: 11
Training loss: 0.5537475347518921
Validation loss: 1.7745250860850017

Epoch: 6| Step: 12
Training loss: 0.20591163635253906
Validation loss: 1.748812936967419

Epoch: 6| Step: 13
Training loss: 0.2143901288509369
Validation loss: 1.7370303112973449

Epoch: 270| Step: 0
Training loss: 0.38081252574920654
Validation loss: 1.7586779479057557

Epoch: 6| Step: 1
Training loss: 0.33753013610839844
Validation loss: 1.7546597565374067

Epoch: 6| Step: 2
Training loss: 0.5599865913391113
Validation loss: 1.7371915771115212

Epoch: 6| Step: 3
Training loss: 0.39909642934799194
Validation loss: 1.739084134819687

Epoch: 6| Step: 4
Training loss: 0.22090698778629303
Validation loss: 1.727780358765715

Epoch: 6| Step: 5
Training loss: 0.3472754955291748
Validation loss: 1.7416303144988192

Epoch: 6| Step: 6
Training loss: 0.34957414865493774
Validation loss: 1.7150501980576465

Epoch: 6| Step: 7
Training loss: 0.5651088356971741
Validation loss: 1.7272102140611219

Epoch: 6| Step: 8
Training loss: 0.43719348311424255
Validation loss: 1.73291431191147

Epoch: 6| Step: 9
Training loss: 0.48930659890174866
Validation loss: 1.7344490558870378

Epoch: 6| Step: 10
Training loss: 0.5262078642845154
Validation loss: 1.715128993475309

Epoch: 6| Step: 11
Training loss: 0.5884696841239929
Validation loss: 1.6962614059448242

Epoch: 6| Step: 12
Training loss: 0.7568210363388062
Validation loss: 1.730047523334462

Epoch: 6| Step: 13
Training loss: 0.40749070048332214
Validation loss: 1.6975309579603133

Epoch: 271| Step: 0
Training loss: 0.4137323498725891
Validation loss: 1.7537551208208966

Epoch: 6| Step: 1
Training loss: 0.5241655111312866
Validation loss: 1.7523168120332944

Epoch: 6| Step: 2
Training loss: 0.5733978152275085
Validation loss: 1.8280000097008162

Epoch: 6| Step: 3
Training loss: 0.6260160803794861
Validation loss: 1.7692364595269645

Epoch: 6| Step: 4
Training loss: 0.22078338265419006
Validation loss: 1.7866243175280991

Epoch: 6| Step: 5
Training loss: 0.3908872604370117
Validation loss: 1.7483202654828307

Epoch: 6| Step: 6
Training loss: 0.3721853196620941
Validation loss: 1.767892651660468

Epoch: 6| Step: 7
Training loss: 0.5554017424583435
Validation loss: 1.7127912429071241

Epoch: 6| Step: 8
Training loss: 0.3149780333042145
Validation loss: 1.6909851284437283

Epoch: 6| Step: 9
Training loss: 0.3850741982460022
Validation loss: 1.6793222670914025

Epoch: 6| Step: 10
Training loss: 0.4746587872505188
Validation loss: 1.6915230892037834

Epoch: 6| Step: 11
Training loss: 0.7467539310455322
Validation loss: 1.710694077194378

Epoch: 6| Step: 12
Training loss: 0.3005867004394531
Validation loss: 1.6904025206001856

Epoch: 6| Step: 13
Training loss: 0.3622758686542511
Validation loss: 1.7114254633585613

Epoch: 272| Step: 0
Training loss: 0.3884040117263794
Validation loss: 1.72924772385628

Epoch: 6| Step: 1
Training loss: 0.4186380207538605
Validation loss: 1.7474659617229173

Epoch: 6| Step: 2
Training loss: 0.5381377339363098
Validation loss: 1.7366589205239409

Epoch: 6| Step: 3
Training loss: 0.2649086117744446
Validation loss: 1.7362027193910332

Epoch: 6| Step: 4
Training loss: 0.368583619594574
Validation loss: 1.749673488319561

Epoch: 6| Step: 5
Training loss: 0.7069908380508423
Validation loss: 1.7243844591161257

Epoch: 6| Step: 6
Training loss: 0.6134738922119141
Validation loss: 1.7389526187732656

Epoch: 6| Step: 7
Training loss: 0.30323779582977295
Validation loss: 1.7174782394081034

Epoch: 6| Step: 8
Training loss: 0.49030977487564087
Validation loss: 1.7276584320170905

Epoch: 6| Step: 9
Training loss: 0.7981377840042114
Validation loss: 1.7369088088312457

Epoch: 6| Step: 10
Training loss: 0.5198585987091064
Validation loss: 1.7510131635973532

Epoch: 6| Step: 11
Training loss: 0.27870169281959534
Validation loss: 1.7643431578913042

Epoch: 6| Step: 12
Training loss: 0.34236249327659607
Validation loss: 1.7692752909916702

Epoch: 6| Step: 13
Training loss: 0.5688121318817139
Validation loss: 1.764461777543509

Epoch: 273| Step: 0
Training loss: 0.44361627101898193
Validation loss: 1.7436875822723552

Epoch: 6| Step: 1
Training loss: 0.3796563744544983
Validation loss: 1.7880605010576145

Epoch: 6| Step: 2
Training loss: 0.4363940358161926
Validation loss: 1.7521801481964767

Epoch: 6| Step: 3
Training loss: 0.4408115744590759
Validation loss: 1.737970490609446

Epoch: 6| Step: 4
Training loss: 0.41589421033859253
Validation loss: 1.766698411715928

Epoch: 6| Step: 5
Training loss: 0.5698354244232178
Validation loss: 1.7452690678258096

Epoch: 6| Step: 6
Training loss: 0.1928691864013672
Validation loss: 1.7556491295496623

Epoch: 6| Step: 7
Training loss: 0.5377275347709656
Validation loss: 1.7539985359355967

Epoch: 6| Step: 8
Training loss: 0.740740954875946
Validation loss: 1.7705504099527996

Epoch: 6| Step: 9
Training loss: 0.35130786895751953
Validation loss: 1.7282912103078698

Epoch: 6| Step: 10
Training loss: 0.4327879846096039
Validation loss: 1.7569149142952376

Epoch: 6| Step: 11
Training loss: 0.4565260112285614
Validation loss: 1.784131114200879

Epoch: 6| Step: 12
Training loss: 0.15717105567455292
Validation loss: 1.7391083971146615

Epoch: 6| Step: 13
Training loss: 0.3789011240005493
Validation loss: 1.7375937495180356

Epoch: 274| Step: 0
Training loss: 0.4989127516746521
Validation loss: 1.7417133956827142

Epoch: 6| Step: 1
Training loss: 0.41763123869895935
Validation loss: 1.7299139397118681

Epoch: 6| Step: 2
Training loss: 0.1937532126903534
Validation loss: 1.7328485570928103

Epoch: 6| Step: 3
Training loss: 0.4356938600540161
Validation loss: 1.7767511375488774

Epoch: 6| Step: 4
Training loss: 0.5430790185928345
Validation loss: 1.7611918218674198

Epoch: 6| Step: 5
Training loss: 0.37122663855552673
Validation loss: 1.780995407412129

Epoch: 6| Step: 6
Training loss: 0.5691989064216614
Validation loss: 1.7479607828201786

Epoch: 6| Step: 7
Training loss: 0.5610839128494263
Validation loss: 1.7726741606189358

Epoch: 6| Step: 8
Training loss: 0.5384551882743835
Validation loss: 1.7500902606594948

Epoch: 6| Step: 9
Training loss: 0.21857242286205292
Validation loss: 1.7154266244621688

Epoch: 6| Step: 10
Training loss: 0.23139342665672302
Validation loss: 1.7292522935457126

Epoch: 6| Step: 11
Training loss: 0.5600922703742981
Validation loss: 1.7362860197662024

Epoch: 6| Step: 12
Training loss: 0.5414974689483643
Validation loss: 1.6912329991658528

Epoch: 6| Step: 13
Training loss: 0.2215721160173416
Validation loss: 1.658159170099484

Epoch: 275| Step: 0
Training loss: 0.5267480611801147
Validation loss: 1.6999359617951095

Epoch: 6| Step: 1
Training loss: 0.21811141073703766
Validation loss: 1.769290171643739

Epoch: 6| Step: 2
Training loss: 0.6156867742538452
Validation loss: 1.7733118380269697

Epoch: 6| Step: 3
Training loss: 0.410778671503067
Validation loss: 1.7812537480426092

Epoch: 6| Step: 4
Training loss: 0.488864928483963
Validation loss: 1.8155945180564799

Epoch: 6| Step: 5
Training loss: 0.24435283243656158
Validation loss: 1.7960257017484276

Epoch: 6| Step: 6
Training loss: 0.5937218070030212
Validation loss: 1.8292378353816208

Epoch: 6| Step: 7
Training loss: 0.45476436614990234
Validation loss: 1.7577603222221456

Epoch: 6| Step: 8
Training loss: 0.5009560585021973
Validation loss: 1.734531428224297

Epoch: 6| Step: 9
Training loss: 0.4548349380493164
Validation loss: 1.6820262247516262

Epoch: 6| Step: 10
Training loss: 0.40706124901771545
Validation loss: 1.6690626644319104

Epoch: 6| Step: 11
Training loss: 0.30007779598236084
Validation loss: 1.676868151592952

Epoch: 6| Step: 12
Training loss: 0.4774526357650757
Validation loss: 1.6811423314514982

Epoch: 6| Step: 13
Training loss: 0.5980011224746704
Validation loss: 1.6941482097871843

Epoch: 276| Step: 0
Training loss: 0.27234068512916565
Validation loss: 1.719195213369144

Epoch: 6| Step: 1
Training loss: 0.6372674703598022
Validation loss: 1.743661557474444

Epoch: 6| Step: 2
Training loss: 0.3920760154724121
Validation loss: 1.7185793897157073

Epoch: 6| Step: 3
Training loss: 0.462313175201416
Validation loss: 1.7390622400468396

Epoch: 6| Step: 4
Training loss: 0.5740580558776855
Validation loss: 1.7346937079583444

Epoch: 6| Step: 5
Training loss: 0.3141038417816162
Validation loss: 1.7627504423100462

Epoch: 6| Step: 6
Training loss: 0.5922452211380005
Validation loss: 1.7403468137146325

Epoch: 6| Step: 7
Training loss: 0.6307088732719421
Validation loss: 1.7476874346374183

Epoch: 6| Step: 8
Training loss: 0.23502574861049652
Validation loss: 1.7279488630192255

Epoch: 6| Step: 9
Training loss: 0.292733758687973
Validation loss: 1.771505650653634

Epoch: 6| Step: 10
Training loss: 0.35230836272239685
Validation loss: 1.8006325011612268

Epoch: 6| Step: 11
Training loss: 0.5278021097183228
Validation loss: 1.7851256375671716

Epoch: 6| Step: 12
Training loss: 0.2818659842014313
Validation loss: 1.7859536986197195

Epoch: 6| Step: 13
Training loss: 0.42662596702575684
Validation loss: 1.7677266713111632

Epoch: 277| Step: 0
Training loss: 0.3553532660007477
Validation loss: 1.7539794374537725

Epoch: 6| Step: 1
Training loss: 0.4412820339202881
Validation loss: 1.7527653837716708

Epoch: 6| Step: 2
Training loss: 0.401107519865036
Validation loss: 1.725269898291557

Epoch: 6| Step: 3
Training loss: 0.3401558995246887
Validation loss: 1.7498443344587922

Epoch: 6| Step: 4
Training loss: 0.3195153772830963
Validation loss: 1.7467813158548007

Epoch: 6| Step: 5
Training loss: 0.3643496036529541
Validation loss: 1.766575151874173

Epoch: 6| Step: 6
Training loss: 0.46778494119644165
Validation loss: 1.7889087879529564

Epoch: 6| Step: 7
Training loss: 0.5560086965560913
Validation loss: 1.815986567927945

Epoch: 6| Step: 8
Training loss: 0.5150318741798401
Validation loss: 1.815896289322966

Epoch: 6| Step: 9
Training loss: 0.6141935586929321
Validation loss: 1.7890332719331146

Epoch: 6| Step: 10
Training loss: 0.3565112352371216
Validation loss: 1.7235562186087332

Epoch: 6| Step: 11
Training loss: 0.3050973415374756
Validation loss: 1.7380807463840773

Epoch: 6| Step: 12
Training loss: 0.31274062395095825
Validation loss: 1.7575946738643031

Epoch: 6| Step: 13
Training loss: 0.4330293834209442
Validation loss: 1.715102396985536

Epoch: 278| Step: 0
Training loss: 0.6095836162567139
Validation loss: 1.7335721908077117

Epoch: 6| Step: 1
Training loss: 0.3824676275253296
Validation loss: 1.7056267671687628

Epoch: 6| Step: 2
Training loss: 0.4619562029838562
Validation loss: 1.694992406393892

Epoch: 6| Step: 3
Training loss: 0.2911739647388458
Validation loss: 1.6899866096435054

Epoch: 6| Step: 4
Training loss: 0.56861811876297
Validation loss: 1.6889721834531395

Epoch: 6| Step: 5
Training loss: 0.33572760224342346
Validation loss: 1.6844061523355462

Epoch: 6| Step: 6
Training loss: 0.4547829031944275
Validation loss: 1.6609096347644765

Epoch: 6| Step: 7
Training loss: 0.40517744421958923
Validation loss: 1.6665886166275188

Epoch: 6| Step: 8
Training loss: 0.3249036967754364
Validation loss: 1.6653527534136208

Epoch: 6| Step: 9
Training loss: 0.40254446864128113
Validation loss: 1.663886477870326

Epoch: 6| Step: 10
Training loss: 0.20100057125091553
Validation loss: 1.6749648291577575

Epoch: 6| Step: 11
Training loss: 0.3715952932834625
Validation loss: 1.6598425385772542

Epoch: 6| Step: 12
Training loss: 0.32056307792663574
Validation loss: 1.6725519523825696

Epoch: 6| Step: 13
Training loss: 0.5273335576057434
Validation loss: 1.6815406827516453

Epoch: 279| Step: 0
Training loss: 0.7340233325958252
Validation loss: 1.683222907845692

Epoch: 6| Step: 1
Training loss: 0.5262719392776489
Validation loss: 1.6975371504342684

Epoch: 6| Step: 2
Training loss: 0.3938904106616974
Validation loss: 1.7079989999853156

Epoch: 6| Step: 3
Training loss: 0.21142525970935822
Validation loss: 1.7587866911324121

Epoch: 6| Step: 4
Training loss: 0.33233970403671265
Validation loss: 1.7311558261994393

Epoch: 6| Step: 5
Training loss: 0.44663524627685547
Validation loss: 1.7359044205757879

Epoch: 6| Step: 6
Training loss: 0.42143338918685913
Validation loss: 1.7181764610352055

Epoch: 6| Step: 7
Training loss: 0.5137596130371094
Validation loss: 1.6988906719351327

Epoch: 6| Step: 8
Training loss: 0.2865244448184967
Validation loss: 1.7249511082967122

Epoch: 6| Step: 9
Training loss: 0.3601629137992859
Validation loss: 1.723732889339488

Epoch: 6| Step: 10
Training loss: 0.3037692606449127
Validation loss: 1.7108370257962136

Epoch: 6| Step: 11
Training loss: 0.41910332441329956
Validation loss: 1.711083968480428

Epoch: 6| Step: 12
Training loss: 0.46561199426651
Validation loss: 1.7294460650413268

Epoch: 6| Step: 13
Training loss: 0.21903438866138458
Validation loss: 1.7076744815354705

Epoch: 280| Step: 0
Training loss: 0.14851030707359314
Validation loss: 1.7239933360007502

Epoch: 6| Step: 1
Training loss: 0.2298126071691513
Validation loss: 1.6990134280215028

Epoch: 6| Step: 2
Training loss: 0.6772489547729492
Validation loss: 1.6703916929101432

Epoch: 6| Step: 3
Training loss: 0.38968363404273987
Validation loss: 1.6743765197774416

Epoch: 6| Step: 4
Training loss: 0.5428518056869507
Validation loss: 1.6924262995361

Epoch: 6| Step: 5
Training loss: 0.4000573456287384
Validation loss: 1.707245958107774

Epoch: 6| Step: 6
Training loss: 0.41584986448287964
Validation loss: 1.7298854448462044

Epoch: 6| Step: 7
Training loss: 0.3865985870361328
Validation loss: 1.7205693510270887

Epoch: 6| Step: 8
Training loss: 0.3470762073993683
Validation loss: 1.7174498778517528

Epoch: 6| Step: 9
Training loss: 0.45306381583213806
Validation loss: 1.7275525062314925

Epoch: 6| Step: 10
Training loss: 0.3371003270149231
Validation loss: 1.7253675230087773

Epoch: 6| Step: 11
Training loss: 0.3640798330307007
Validation loss: 1.7006908488529984

Epoch: 6| Step: 12
Training loss: 0.35922038555145264
Validation loss: 1.7576736147685716

Epoch: 6| Step: 13
Training loss: 0.20920750498771667
Validation loss: 1.7521878314274613

Epoch: 281| Step: 0
Training loss: 0.26749831438064575
Validation loss: 1.7527685165405273

Epoch: 6| Step: 1
Training loss: 0.5781478881835938
Validation loss: 1.7570153872172039

Epoch: 6| Step: 2
Training loss: 0.42892986536026
Validation loss: 1.7407091394547494

Epoch: 6| Step: 3
Training loss: 0.36839592456817627
Validation loss: 1.7383547803407073

Epoch: 6| Step: 4
Training loss: 0.3485220670700073
Validation loss: 1.7346549649392404

Epoch: 6| Step: 5
Training loss: 0.3827793002128601
Validation loss: 1.73367142164579

Epoch: 6| Step: 6
Training loss: 0.22346937656402588
Validation loss: 1.7005231406099053

Epoch: 6| Step: 7
Training loss: 0.33755993843078613
Validation loss: 1.6806584429997269

Epoch: 6| Step: 8
Training loss: 0.8313846588134766
Validation loss: 1.6592711851161013

Epoch: 6| Step: 9
Training loss: 0.425972580909729
Validation loss: 1.6708294037849671

Epoch: 6| Step: 10
Training loss: 0.3878014087677002
Validation loss: 1.6500089745367728

Epoch: 6| Step: 11
Training loss: 0.32676082849502563
Validation loss: 1.6887971713978758

Epoch: 6| Step: 12
Training loss: 0.2853735685348511
Validation loss: 1.6497811130298081

Epoch: 6| Step: 13
Training loss: 0.34670260548591614
Validation loss: 1.666408327318007

Epoch: 282| Step: 0
Training loss: 0.29246023297309875
Validation loss: 1.6748908835072671

Epoch: 6| Step: 1
Training loss: 0.333057165145874
Validation loss: 1.674239307321528

Epoch: 6| Step: 2
Training loss: 0.295967161655426
Validation loss: 1.6459340305738552

Epoch: 6| Step: 3
Training loss: 0.42858612537384033
Validation loss: 1.666674147370041

Epoch: 6| Step: 4
Training loss: 0.2261502742767334
Validation loss: 1.6566756393319817

Epoch: 6| Step: 5
Training loss: 0.39820629358291626
Validation loss: 1.6124828015604327

Epoch: 6| Step: 6
Training loss: 0.38594257831573486
Validation loss: 1.6507801112308298

Epoch: 6| Step: 7
Training loss: 0.40395092964172363
Validation loss: 1.619374736662834

Epoch: 6| Step: 8
Training loss: 0.2099539339542389
Validation loss: 1.6580615748641312

Epoch: 6| Step: 9
Training loss: 0.5319575071334839
Validation loss: 1.6394415004279024

Epoch: 6| Step: 10
Training loss: 0.3358076810836792
Validation loss: 1.663800283144879

Epoch: 6| Step: 11
Training loss: 0.4931231141090393
Validation loss: 1.6505375395538986

Epoch: 6| Step: 12
Training loss: 0.4592755436897278
Validation loss: 1.6707859987853675

Epoch: 6| Step: 13
Training loss: 0.32787036895751953
Validation loss: 1.6665169295444284

Epoch: 283| Step: 0
Training loss: 0.29898422956466675
Validation loss: 1.7392035107458792

Epoch: 6| Step: 1
Training loss: 0.3373039960861206
Validation loss: 1.7256896354818856

Epoch: 6| Step: 2
Training loss: 0.45915335416793823
Validation loss: 1.7545956360396517

Epoch: 6| Step: 3
Training loss: 0.40679803490638733
Validation loss: 1.7227464106775099

Epoch: 6| Step: 4
Training loss: 0.23083174228668213
Validation loss: 1.6849836380250993

Epoch: 6| Step: 5
Training loss: 0.3933698236942291
Validation loss: 1.6706944819419616

Epoch: 6| Step: 6
Training loss: 0.2970368266105652
Validation loss: 1.6439876966578986

Epoch: 6| Step: 7
Training loss: 0.38461068272590637
Validation loss: 1.6816829494250718

Epoch: 6| Step: 8
Training loss: 0.33875325322151184
Validation loss: 1.6648652040830223

Epoch: 6| Step: 9
Training loss: 0.5360485315322876
Validation loss: 1.6597679353529406

Epoch: 6| Step: 10
Training loss: 0.6329275369644165
Validation loss: 1.6679133176803589

Epoch: 6| Step: 11
Training loss: 0.48849284648895264
Validation loss: 1.6724219629841466

Epoch: 6| Step: 12
Training loss: 0.40692195296287537
Validation loss: 1.6772927058640348

Epoch: 6| Step: 13
Training loss: 0.4304211735725403
Validation loss: 1.6869195635600756

Epoch: 284| Step: 0
Training loss: 0.424956351518631
Validation loss: 1.6943903507724885

Epoch: 6| Step: 1
Training loss: 0.4569462537765503
Validation loss: 1.7285314785536898

Epoch: 6| Step: 2
Training loss: 0.2595944404602051
Validation loss: 1.737702618363083

Epoch: 6| Step: 3
Training loss: 0.4358666241168976
Validation loss: 1.742575176300541

Epoch: 6| Step: 4
Training loss: 0.3252224624156952
Validation loss: 1.7330232256202287

Epoch: 6| Step: 5
Training loss: 0.40079641342163086
Validation loss: 1.7324021708580755

Epoch: 6| Step: 6
Training loss: 0.28301024436950684
Validation loss: 1.7418996851931337

Epoch: 6| Step: 7
Training loss: 0.3254331350326538
Validation loss: 1.7166557286375312

Epoch: 6| Step: 8
Training loss: 0.39448612928390503
Validation loss: 1.6620093237969182

Epoch: 6| Step: 9
Training loss: 0.5690453052520752
Validation loss: 1.6918388592299594

Epoch: 6| Step: 10
Training loss: 0.3339470326900482
Validation loss: 1.6899929623450003

Epoch: 6| Step: 11
Training loss: 0.3968430757522583
Validation loss: 1.7304950657711233

Epoch: 6| Step: 12
Training loss: 0.33230286836624146
Validation loss: 1.7389070808246572

Epoch: 6| Step: 13
Training loss: 0.5109117031097412
Validation loss: 1.7356906142286075

Epoch: 285| Step: 0
Training loss: 0.5449353456497192
Validation loss: 1.7037186635437833

Epoch: 6| Step: 1
Training loss: 0.3427067995071411
Validation loss: 1.7100009649030623

Epoch: 6| Step: 2
Training loss: 0.4211520552635193
Validation loss: 1.723795106334071

Epoch: 6| Step: 3
Training loss: 0.4467684030532837
Validation loss: 1.6841564127193984

Epoch: 6| Step: 4
Training loss: 0.5506832599639893
Validation loss: 1.6986294574635004

Epoch: 6| Step: 5
Training loss: 0.26221734285354614
Validation loss: 1.6887114996551185

Epoch: 6| Step: 6
Training loss: 0.1827094554901123
Validation loss: 1.6507614761270502

Epoch: 6| Step: 7
Training loss: 0.38789623975753784
Validation loss: 1.6631877819697063

Epoch: 6| Step: 8
Training loss: 0.4626426696777344
Validation loss: 1.6583324786155456

Epoch: 6| Step: 9
Training loss: 0.2611483931541443
Validation loss: 1.648122948984946

Epoch: 6| Step: 10
Training loss: 0.17474615573883057
Validation loss: 1.69979150449076

Epoch: 6| Step: 11
Training loss: 0.40057820081710815
Validation loss: 1.724169296603049

Epoch: 6| Step: 12
Training loss: 0.4021605849266052
Validation loss: 1.7071190572554065

Epoch: 6| Step: 13
Training loss: 0.3310745060443878
Validation loss: 1.6884851955598401

Epoch: 286| Step: 0
Training loss: 0.3550093472003937
Validation loss: 1.7156310901846936

Epoch: 6| Step: 1
Training loss: 0.305806964635849
Validation loss: 1.7138043783044303

Epoch: 6| Step: 2
Training loss: 0.588472843170166
Validation loss: 1.6616027765376593

Epoch: 6| Step: 3
Training loss: 0.4586491584777832
Validation loss: 1.6454343488139491

Epoch: 6| Step: 4
Training loss: 0.28207138180732727
Validation loss: 1.6932106812795003

Epoch: 6| Step: 5
Training loss: 0.45493805408477783
Validation loss: 1.6534353443371352

Epoch: 6| Step: 6
Training loss: 0.35871267318725586
Validation loss: 1.6448605906578802

Epoch: 6| Step: 7
Training loss: 0.27699777483940125
Validation loss: 1.6275106194198772

Epoch: 6| Step: 8
Training loss: 0.27785906195640564
Validation loss: 1.634321415296165

Epoch: 6| Step: 9
Training loss: 0.38543057441711426
Validation loss: 1.631953231749996

Epoch: 6| Step: 10
Training loss: 0.5211282968521118
Validation loss: 1.663113711982645

Epoch: 6| Step: 11
Training loss: 0.3026227653026581
Validation loss: 1.7102429584790302

Epoch: 6| Step: 12
Training loss: 0.3376198410987854
Validation loss: 1.7267794929524904

Epoch: 6| Step: 13
Training loss: 0.5294784903526306
Validation loss: 1.7214673424279818

Epoch: 287| Step: 0
Training loss: 0.4966765344142914
Validation loss: 1.717958551581188

Epoch: 6| Step: 1
Training loss: 0.4028312861919403
Validation loss: 1.746284983491385

Epoch: 6| Step: 2
Training loss: 0.31105268001556396
Validation loss: 1.757508421456942

Epoch: 6| Step: 3
Training loss: 0.43798238039016724
Validation loss: 1.7509240129942536

Epoch: 6| Step: 4
Training loss: 0.3410363793373108
Validation loss: 1.7658101115175473

Epoch: 6| Step: 5
Training loss: 0.4374220669269562
Validation loss: 1.768653678637679

Epoch: 6| Step: 6
Training loss: 0.6910984516143799
Validation loss: 1.749347908522493

Epoch: 6| Step: 7
Training loss: 0.339504599571228
Validation loss: 1.7152507266690653

Epoch: 6| Step: 8
Training loss: 0.3205260932445526
Validation loss: 1.6298823587356075

Epoch: 6| Step: 9
Training loss: 0.33334800601005554
Validation loss: 1.6251065897685226

Epoch: 6| Step: 10
Training loss: 0.3597622811794281
Validation loss: 1.6366875517752864

Epoch: 6| Step: 11
Training loss: 0.25262194871902466
Validation loss: 1.6336145439455587

Epoch: 6| Step: 12
Training loss: 0.3741869628429413
Validation loss: 1.6536566506149948

Epoch: 6| Step: 13
Training loss: 0.33752360939979553
Validation loss: 1.6388352545358802

Epoch: 288| Step: 0
Training loss: 0.375526487827301
Validation loss: 1.6469698182998165

Epoch: 6| Step: 1
Training loss: 0.34720510244369507
Validation loss: 1.6269846846980434

Epoch: 6| Step: 2
Training loss: 0.34172481298446655
Validation loss: 1.5994158996048795

Epoch: 6| Step: 3
Training loss: 0.33280742168426514
Validation loss: 1.6421817464213218

Epoch: 6| Step: 4
Training loss: 0.2696813642978668
Validation loss: 1.651392581642315

Epoch: 6| Step: 5
Training loss: 0.32767555117607117
Validation loss: 1.6302707156827372

Epoch: 6| Step: 6
Training loss: 0.26055461168289185
Validation loss: 1.6777691610397831

Epoch: 6| Step: 7
Training loss: 0.3037876486778259
Validation loss: 1.659502443446908

Epoch: 6| Step: 8
Training loss: 0.3501232862472534
Validation loss: 1.6569705458097561

Epoch: 6| Step: 9
Training loss: 0.5119551420211792
Validation loss: 1.6596064785475373

Epoch: 6| Step: 10
Training loss: 0.6415137052536011
Validation loss: 1.6872092869973951

Epoch: 6| Step: 11
Training loss: 0.24764186143875122
Validation loss: 1.6503136773263254

Epoch: 6| Step: 12
Training loss: 0.31640946865081787
Validation loss: 1.6576041944565312

Epoch: 6| Step: 13
Training loss: 0.3650575578212738
Validation loss: 1.6619398798993839

Epoch: 289| Step: 0
Training loss: 0.3126336932182312
Validation loss: 1.6829166079080233

Epoch: 6| Step: 1
Training loss: 0.4524082541465759
Validation loss: 1.7076097714003695

Epoch: 6| Step: 2
Training loss: 0.47885414958000183
Validation loss: 1.6827351136874127

Epoch: 6| Step: 3
Training loss: 0.39351117610931396
Validation loss: 1.6944214220969909

Epoch: 6| Step: 4
Training loss: 0.31088170409202576
Validation loss: 1.660986597819995

Epoch: 6| Step: 5
Training loss: 0.3197457492351532
Validation loss: 1.6577354169660998

Epoch: 6| Step: 6
Training loss: 0.22283481061458588
Validation loss: 1.6230889751065163

Epoch: 6| Step: 7
Training loss: 0.2908886671066284
Validation loss: 1.6440399410904094

Epoch: 6| Step: 8
Training loss: 0.37487274408340454
Validation loss: 1.6367356866918585

Epoch: 6| Step: 9
Training loss: 0.32064077258110046
Validation loss: 1.65885119540717

Epoch: 6| Step: 10
Training loss: 0.5500733852386475
Validation loss: 1.6540020204359485

Epoch: 6| Step: 11
Training loss: 0.3778734505176544
Validation loss: 1.6410648463874735

Epoch: 6| Step: 12
Training loss: 0.26379913091659546
Validation loss: 1.65440204194797

Epoch: 6| Step: 13
Training loss: 0.39931321144104004
Validation loss: 1.6566787483871623

Epoch: 290| Step: 0
Training loss: 0.22636373341083527
Validation loss: 1.6899568483393679

Epoch: 6| Step: 1
Training loss: 0.4944344758987427
Validation loss: 1.6817374229431152

Epoch: 6| Step: 2
Training loss: 0.38247230648994446
Validation loss: 1.7325818589938584

Epoch: 6| Step: 3
Training loss: 0.4996951222419739
Validation loss: 1.7052499812136415

Epoch: 6| Step: 4
Training loss: 0.5919093489646912
Validation loss: 1.712611900862827

Epoch: 6| Step: 5
Training loss: 0.32989567518234253
Validation loss: 1.6852088615458498

Epoch: 6| Step: 6
Training loss: 0.33699649572372437
Validation loss: 1.6334324421421174

Epoch: 6| Step: 7
Training loss: 0.4903450310230255
Validation loss: 1.5980453093846638

Epoch: 6| Step: 8
Training loss: 0.28962332010269165
Validation loss: 1.6343438010061941

Epoch: 6| Step: 9
Training loss: 0.35644444823265076
Validation loss: 1.63996716724929

Epoch: 6| Step: 10
Training loss: 0.4190673232078552
Validation loss: 1.6725514922090756

Epoch: 6| Step: 11
Training loss: 0.411058634519577
Validation loss: 1.6758088950187928

Epoch: 6| Step: 12
Training loss: 0.2395198494195938
Validation loss: 1.6749619796711912

Epoch: 6| Step: 13
Training loss: 0.1610191911458969
Validation loss: 1.6685421684736848

Epoch: 291| Step: 0
Training loss: 0.3126872479915619
Validation loss: 1.651100822674331

Epoch: 6| Step: 1
Training loss: 0.3419596552848816
Validation loss: 1.6856573358658822

Epoch: 6| Step: 2
Training loss: 0.37122035026550293
Validation loss: 1.686355685675016

Epoch: 6| Step: 3
Training loss: 0.1727668046951294
Validation loss: 1.6885543568159944

Epoch: 6| Step: 4
Training loss: 0.23243530094623566
Validation loss: 1.7180541458950247

Epoch: 6| Step: 5
Training loss: 0.43696072697639465
Validation loss: 1.7060819851454867

Epoch: 6| Step: 6
Training loss: 0.28135091066360474
Validation loss: 1.6938287058184225

Epoch: 6| Step: 7
Training loss: 0.34473946690559387
Validation loss: 1.6910217756866126

Epoch: 6| Step: 8
Training loss: 0.43610286712646484
Validation loss: 1.6906122135859665

Epoch: 6| Step: 9
Training loss: 0.24053195118904114
Validation loss: 1.6678036092430033

Epoch: 6| Step: 10
Training loss: 0.15366952121257782
Validation loss: 1.6688910235640824

Epoch: 6| Step: 11
Training loss: 0.5518021583557129
Validation loss: 1.6756456000830537

Epoch: 6| Step: 12
Training loss: 0.3979634642601013
Validation loss: 1.6741187777570499

Epoch: 6| Step: 13
Training loss: 0.40458452701568604
Validation loss: 1.6529795508230887

Epoch: 292| Step: 0
Training loss: 0.34038397669792175
Validation loss: 1.6630904418165966

Epoch: 6| Step: 1
Training loss: 0.4291403293609619
Validation loss: 1.6644359968041862

Epoch: 6| Step: 2
Training loss: 0.35497477650642395
Validation loss: 1.6282655936415478

Epoch: 6| Step: 3
Training loss: 0.32838499546051025
Validation loss: 1.6423345137667913

Epoch: 6| Step: 4
Training loss: 0.27864009141921997
Validation loss: 1.678966651680649

Epoch: 6| Step: 5
Training loss: 0.4078226685523987
Validation loss: 1.6607404062824864

Epoch: 6| Step: 6
Training loss: 0.392625093460083
Validation loss: 1.6368744411776144

Epoch: 6| Step: 7
Training loss: 0.32435253262519836
Validation loss: 1.6704473982575119

Epoch: 6| Step: 8
Training loss: 0.4000738859176636
Validation loss: 1.6677212920240176

Epoch: 6| Step: 9
Training loss: 0.30205681920051575
Validation loss: 1.6379492898141184

Epoch: 6| Step: 10
Training loss: 0.22548440098762512
Validation loss: 1.6697809183469383

Epoch: 6| Step: 11
Training loss: 0.3044748902320862
Validation loss: 1.6771404717558174

Epoch: 6| Step: 12
Training loss: 0.2925138771533966
Validation loss: 1.6341721998747958

Epoch: 6| Step: 13
Training loss: 0.2959344685077667
Validation loss: 1.6653511985655753

Epoch: 293| Step: 0
Training loss: 0.3263464570045471
Validation loss: 1.6230964904190393

Epoch: 6| Step: 1
Training loss: 0.25383031368255615
Validation loss: 1.671764298151898

Epoch: 6| Step: 2
Training loss: 0.33996859192848206
Validation loss: 1.6484560428127166

Epoch: 6| Step: 3
Training loss: 0.5612626075744629
Validation loss: 1.6675422896621048

Epoch: 6| Step: 4
Training loss: 0.26541373133659363
Validation loss: 1.66640136062458

Epoch: 6| Step: 5
Training loss: 0.3596828579902649
Validation loss: 1.685132671427983

Epoch: 6| Step: 6
Training loss: 0.27377888560295105
Validation loss: 1.6492525787763699

Epoch: 6| Step: 7
Training loss: 0.21579591929912567
Validation loss: 1.6581749582803378

Epoch: 6| Step: 8
Training loss: 0.2278474122285843
Validation loss: 1.6582168558592438

Epoch: 6| Step: 9
Training loss: 0.32834574580192566
Validation loss: 1.6789209329953758

Epoch: 6| Step: 10
Training loss: 0.2993074059486389
Validation loss: 1.6626698791339833

Epoch: 6| Step: 11
Training loss: 0.4314969778060913
Validation loss: 1.650257384905251

Epoch: 6| Step: 12
Training loss: 0.39007991552352905
Validation loss: 1.6585350472440001

Epoch: 6| Step: 13
Training loss: 0.4476638436317444
Validation loss: 1.669227542415742

Epoch: 294| Step: 0
Training loss: 0.3433833420276642
Validation loss: 1.6989294252087992

Epoch: 6| Step: 1
Training loss: 0.22265338897705078
Validation loss: 1.6944334827443606

Epoch: 6| Step: 2
Training loss: 0.2968432903289795
Validation loss: 1.7153339411622734

Epoch: 6| Step: 3
Training loss: 0.3903803825378418
Validation loss: 1.680625033634965

Epoch: 6| Step: 4
Training loss: 0.2821494936943054
Validation loss: 1.6297277378779587

Epoch: 6| Step: 5
Training loss: 0.21507291495800018
Validation loss: 1.6199669132950485

Epoch: 6| Step: 6
Training loss: 0.35526522994041443
Validation loss: 1.639781484039881

Epoch: 6| Step: 7
Training loss: 0.329877108335495
Validation loss: 1.653017661904776

Epoch: 6| Step: 8
Training loss: 0.4712856411933899
Validation loss: 1.6949891249338787

Epoch: 6| Step: 9
Training loss: 0.3258097469806671
Validation loss: 1.665722556011651

Epoch: 6| Step: 10
Training loss: 0.2383374571800232
Validation loss: 1.6211506807675926

Epoch: 6| Step: 11
Training loss: 0.3439687490463257
Validation loss: 1.6447186969941663

Epoch: 6| Step: 12
Training loss: 0.35754823684692383
Validation loss: 1.6552427943034838

Epoch: 6| Step: 13
Training loss: 0.742595911026001
Validation loss: 1.6384483652730142

Epoch: 295| Step: 0
Training loss: 0.31556063890457153
Validation loss: 1.6431622056550876

Epoch: 6| Step: 1
Training loss: 0.2047024965286255
Validation loss: 1.680338446811963

Epoch: 6| Step: 2
Training loss: 0.33438971638679504
Validation loss: 1.6677554281808997

Epoch: 6| Step: 3
Training loss: 0.264384925365448
Validation loss: 1.7114122529183664

Epoch: 6| Step: 4
Training loss: 0.5456711649894714
Validation loss: 1.7400016118121404

Epoch: 6| Step: 5
Training loss: 0.3689660429954529
Validation loss: 1.6933436880829513

Epoch: 6| Step: 6
Training loss: 0.2888951301574707
Validation loss: 1.6743537661849812

Epoch: 6| Step: 7
Training loss: 0.24757835268974304
Validation loss: 1.7197997903311124

Epoch: 6| Step: 8
Training loss: 0.32298415899276733
Validation loss: 1.650818770290703

Epoch: 6| Step: 9
Training loss: 0.30995792150497437
Validation loss: 1.6452683383418667

Epoch: 6| Step: 10
Training loss: 0.3768305778503418
Validation loss: 1.6673932671546936

Epoch: 6| Step: 11
Training loss: 0.6871849298477173
Validation loss: 1.6539910647176927

Epoch: 6| Step: 12
Training loss: 0.300412118434906
Validation loss: 1.6608793427867274

Epoch: 6| Step: 13
Training loss: 0.3628138601779938
Validation loss: 1.6840409655724802

Epoch: 296| Step: 0
Training loss: 0.302901953458786
Validation loss: 1.688190524296094

Epoch: 6| Step: 1
Training loss: 0.32244598865509033
Validation loss: 1.6825745323652863

Epoch: 6| Step: 2
Training loss: 0.3797829747200012
Validation loss: 1.6866941067480272

Epoch: 6| Step: 3
Training loss: 0.36956554651260376
Validation loss: 1.7122556894056258

Epoch: 6| Step: 4
Training loss: 0.44330334663391113
Validation loss: 1.6611226502285208

Epoch: 6| Step: 5
Training loss: 0.2664196491241455
Validation loss: 1.6339693761640979

Epoch: 6| Step: 6
Training loss: 0.4487767815589905
Validation loss: 1.6159721843657955

Epoch: 6| Step: 7
Training loss: 0.4764081835746765
Validation loss: 1.6237257219129992

Epoch: 6| Step: 8
Training loss: 0.21095632016658783
Validation loss: 1.642849826043652

Epoch: 6| Step: 9
Training loss: 0.3497685194015503
Validation loss: 1.6271850601319344

Epoch: 6| Step: 10
Training loss: 0.1531815528869629
Validation loss: 1.6308444276932748

Epoch: 6| Step: 11
Training loss: 0.2246137261390686
Validation loss: 1.6880528567939677

Epoch: 6| Step: 12
Training loss: 0.4192246198654175
Validation loss: 1.6804328733874905

Epoch: 6| Step: 13
Training loss: 0.14134646952152252
Validation loss: 1.6798665920893352

Epoch: 297| Step: 0
Training loss: 0.3408948481082916
Validation loss: 1.647504379672389

Epoch: 6| Step: 1
Training loss: 0.3057340979576111
Validation loss: 1.6711117913646083

Epoch: 6| Step: 2
Training loss: 0.19271418452262878
Validation loss: 1.6376556081156577

Epoch: 6| Step: 3
Training loss: 0.2640957832336426
Validation loss: 1.6225639479134673

Epoch: 6| Step: 4
Training loss: 0.25425004959106445
Validation loss: 1.6250726625483523

Epoch: 6| Step: 5
Training loss: 0.2644835114479065
Validation loss: 1.6209803024927776

Epoch: 6| Step: 6
Training loss: 0.3078753650188446
Validation loss: 1.6432155896258611

Epoch: 6| Step: 7
Training loss: 0.6529606580734253
Validation loss: 1.6452355577099709

Epoch: 6| Step: 8
Training loss: 0.2897408604621887
Validation loss: 1.6329329193279307

Epoch: 6| Step: 9
Training loss: 0.2932342290878296
Validation loss: 1.6453774808555521

Epoch: 6| Step: 10
Training loss: 0.3192130923271179
Validation loss: 1.6077733873039164

Epoch: 6| Step: 11
Training loss: 0.32152825593948364
Validation loss: 1.626051074715071

Epoch: 6| Step: 12
Training loss: 0.4157455563545227
Validation loss: 1.6129097643718924

Epoch: 6| Step: 13
Training loss: 0.2115667313337326
Validation loss: 1.6375865949097501

Epoch: 298| Step: 0
Training loss: 0.24624159932136536
Validation loss: 1.6482026743632492

Epoch: 6| Step: 1
Training loss: 0.23783591389656067
Validation loss: 1.6629382576993716

Epoch: 6| Step: 2
Training loss: 0.2724352777004242
Validation loss: 1.6321287424333635

Epoch: 6| Step: 3
Training loss: 0.3209197223186493
Validation loss: 1.600812885069078

Epoch: 6| Step: 4
Training loss: 0.3092532753944397
Validation loss: 1.6131777417275213

Epoch: 6| Step: 5
Training loss: 0.29240164160728455
Validation loss: 1.6336405918162356

Epoch: 6| Step: 6
Training loss: 0.48496097326278687
Validation loss: 1.6480674782106954

Epoch: 6| Step: 7
Training loss: 0.358207106590271
Validation loss: 1.6527404400610155

Epoch: 6| Step: 8
Training loss: 0.21805870532989502
Validation loss: 1.6480365696773733

Epoch: 6| Step: 9
Training loss: 0.36548006534576416
Validation loss: 1.6619192092649397

Epoch: 6| Step: 10
Training loss: 0.3239906430244446
Validation loss: 1.6450565361207532

Epoch: 6| Step: 11
Training loss: 0.4557798504829407
Validation loss: 1.6367689909473542

Epoch: 6| Step: 12
Training loss: 0.39337196946144104
Validation loss: 1.6266642565368323

Epoch: 6| Step: 13
Training loss: 0.21252138912677765
Validation loss: 1.624746512341243

Epoch: 299| Step: 0
Training loss: 0.23218399286270142
Validation loss: 1.5840351338027625

Epoch: 6| Step: 1
Training loss: 0.5410659313201904
Validation loss: 1.6071340550658524

Epoch: 6| Step: 2
Training loss: 0.28355056047439575
Validation loss: 1.6142164532856276

Epoch: 6| Step: 3
Training loss: 0.258012592792511
Validation loss: 1.6292571867665937

Epoch: 6| Step: 4
Training loss: 0.3037547767162323
Validation loss: 1.6622326925236692

Epoch: 6| Step: 5
Training loss: 0.23636633157730103
Validation loss: 1.6592948090645574

Epoch: 6| Step: 6
Training loss: 0.2099006175994873
Validation loss: 1.6605319963988436

Epoch: 6| Step: 7
Training loss: 0.4737218916416168
Validation loss: 1.7074050429046794

Epoch: 6| Step: 8
Training loss: 0.4368724524974823
Validation loss: 1.7313374550111833

Epoch: 6| Step: 9
Training loss: 0.2277384102344513
Validation loss: 1.6893597674626175

Epoch: 6| Step: 10
Training loss: 0.28450092673301697
Validation loss: 1.7004550682601107

Epoch: 6| Step: 11
Training loss: 0.32455411553382874
Validation loss: 1.6805804262879074

Epoch: 6| Step: 12
Training loss: 0.34707874059677124
Validation loss: 1.7065672342495253

Epoch: 6| Step: 13
Training loss: 0.3467845618724823
Validation loss: 1.659412380187742

Epoch: 300| Step: 0
Training loss: 0.4139552116394043
Validation loss: 1.6981296808488908

Epoch: 6| Step: 1
Training loss: 0.2521522045135498
Validation loss: 1.6932216741705453

Epoch: 6| Step: 2
Training loss: 0.43677541613578796
Validation loss: 1.668352734658026

Epoch: 6| Step: 3
Training loss: 0.26469939947128296
Validation loss: 1.6541600368356193

Epoch: 6| Step: 4
Training loss: 0.3569399416446686
Validation loss: 1.6165917022253877

Epoch: 6| Step: 5
Training loss: 0.3754469156265259
Validation loss: 1.6002610825723218

Epoch: 6| Step: 6
Training loss: 0.19041165709495544
Validation loss: 1.602562919739754

Epoch: 6| Step: 7
Training loss: 0.3801653981208801
Validation loss: 1.57189223330508

Epoch: 6| Step: 8
Training loss: 0.42299026250839233
Validation loss: 1.636694851741996

Epoch: 6| Step: 9
Training loss: 0.22902704775333405
Validation loss: 1.6966703553353586

Epoch: 6| Step: 10
Training loss: 0.2994532585144043
Validation loss: 1.682397957771055

Epoch: 6| Step: 11
Training loss: 0.39756476879119873
Validation loss: 1.6475992382213633

Epoch: 6| Step: 12
Training loss: 0.40319985151290894
Validation loss: 1.6360268990198772

Epoch: 6| Step: 13
Training loss: 0.31301820278167725
Validation loss: 1.6341726908119776

Epoch: 301| Step: 0
Training loss: 0.31734323501586914
Validation loss: 1.6130845290358349

Epoch: 6| Step: 1
Training loss: 0.36850035190582275
Validation loss: 1.6396321122364332

Epoch: 6| Step: 2
Training loss: 0.38246020674705505
Validation loss: 1.6550923752528366

Epoch: 6| Step: 3
Training loss: 0.32296621799468994
Validation loss: 1.6376846028912453

Epoch: 6| Step: 4
Training loss: 0.33425766229629517
Validation loss: 1.6339277798129666

Epoch: 6| Step: 5
Training loss: 0.38909927010536194
Validation loss: 1.6818379535469958

Epoch: 6| Step: 6
Training loss: 0.26772913336753845
Validation loss: 1.6841300918209938

Epoch: 6| Step: 7
Training loss: 0.23712773621082306
Validation loss: 1.70019329491482

Epoch: 6| Step: 8
Training loss: 0.5582131147384644
Validation loss: 1.664714365877131

Epoch: 6| Step: 9
Training loss: 0.3485621213912964
Validation loss: 1.6401702191240044

Epoch: 6| Step: 10
Training loss: 0.426041841506958
Validation loss: 1.6450544364990727

Epoch: 6| Step: 11
Training loss: 0.19056573510169983
Validation loss: 1.628957986831665

Epoch: 6| Step: 12
Training loss: 0.3180277943611145
Validation loss: 1.614760329646449

Epoch: 6| Step: 13
Training loss: 0.24036508798599243
Validation loss: 1.6467247855278753

Epoch: 302| Step: 0
Training loss: 0.4674304127693176
Validation loss: 1.6542272811294885

Epoch: 6| Step: 1
Training loss: 0.31102845072746277
Validation loss: 1.655675902161547

Epoch: 6| Step: 2
Training loss: 0.31676051020622253
Validation loss: 1.763046306948508

Epoch: 6| Step: 3
Training loss: 0.17033416032791138
Validation loss: 1.6843294930714432

Epoch: 6| Step: 4
Training loss: 0.39109206199645996
Validation loss: 1.6735666977461947

Epoch: 6| Step: 5
Training loss: 0.5409654378890991
Validation loss: 1.689912780638664

Epoch: 6| Step: 6
Training loss: 0.21135157346725464
Validation loss: 1.6998982544868224

Epoch: 6| Step: 7
Training loss: 0.2814270555973053
Validation loss: 1.6722768763060212

Epoch: 6| Step: 8
Training loss: 0.4050954580307007
Validation loss: 1.7098199013740785

Epoch: 6| Step: 9
Training loss: 0.1926221251487732
Validation loss: 1.678717113310291

Epoch: 6| Step: 10
Training loss: 0.2918643355369568
Validation loss: 1.6573911520742601

Epoch: 6| Step: 11
Training loss: 0.32579654455184937
Validation loss: 1.6595759532784904

Epoch: 6| Step: 12
Training loss: 0.20539771020412445
Validation loss: 1.5876734500290246

Epoch: 6| Step: 13
Training loss: 0.3559163212776184
Validation loss: 1.6335762046998548

Epoch: 303| Step: 0
Training loss: 0.25544285774230957
Validation loss: 1.6297472830741637

Epoch: 6| Step: 1
Training loss: 0.4429837465286255
Validation loss: 1.6609896177886634

Epoch: 6| Step: 2
Training loss: 0.24176642298698425
Validation loss: 1.64972302990575

Epoch: 6| Step: 3
Training loss: 0.19526167213916779
Validation loss: 1.643786439331629

Epoch: 6| Step: 4
Training loss: 0.19156783819198608
Validation loss: 1.6800141078169628

Epoch: 6| Step: 5
Training loss: 0.46036237478256226
Validation loss: 1.6680594221238167

Epoch: 6| Step: 6
Training loss: 0.4501587152481079
Validation loss: 1.7019960008641726

Epoch: 6| Step: 7
Training loss: 0.23887622356414795
Validation loss: 1.6879953492072322

Epoch: 6| Step: 8
Training loss: 0.5429497957229614
Validation loss: 1.6684919249626897

Epoch: 6| Step: 9
Training loss: 0.31707072257995605
Validation loss: 1.6471096213145922

Epoch: 6| Step: 10
Training loss: 0.15037035942077637
Validation loss: 1.664678927390806

Epoch: 6| Step: 11
Training loss: 0.40922775864601135
Validation loss: 1.6195617382244398

Epoch: 6| Step: 12
Training loss: 0.19786784052848816
Validation loss: 1.6287285307402253

Epoch: 6| Step: 13
Training loss: 0.14865480363368988
Validation loss: 1.6040109152434974

Epoch: 304| Step: 0
Training loss: 0.18943753838539124
Validation loss: 1.6012960300650647

Epoch: 6| Step: 1
Training loss: 0.31314900517463684
Validation loss: 1.6005814024197158

Epoch: 6| Step: 2
Training loss: 0.3080294132232666
Validation loss: 1.6481708762466267

Epoch: 6| Step: 3
Training loss: 0.3922139108181
Validation loss: 1.6881813323625954

Epoch: 6| Step: 4
Training loss: 0.4004177451133728
Validation loss: 1.6730282383580362

Epoch: 6| Step: 5
Training loss: 0.3531765341758728
Validation loss: 1.6646107781317927

Epoch: 6| Step: 6
Training loss: 0.3281518220901489
Validation loss: 1.6345122398868683

Epoch: 6| Step: 7
Training loss: 0.36722707748413086
Validation loss: 1.5839535984941708

Epoch: 6| Step: 8
Training loss: 0.4284095764160156
Validation loss: 1.6228935064808014

Epoch: 6| Step: 9
Training loss: 0.3207339346408844
Validation loss: 1.6078319818742814

Epoch: 6| Step: 10
Training loss: 0.31942710280418396
Validation loss: 1.6238388079468922

Epoch: 6| Step: 11
Training loss: 0.22043022513389587
Validation loss: 1.6681285929936234

Epoch: 6| Step: 12
Training loss: 0.36726945638656616
Validation loss: 1.6530083007709955

Epoch: 6| Step: 13
Training loss: 0.7152524590492249
Validation loss: 1.629944086074829

Epoch: 305| Step: 0
Training loss: 0.24348187446594238
Validation loss: 1.6624960809625604

Epoch: 6| Step: 1
Training loss: 0.34548014402389526
Validation loss: 1.684895191141354

Epoch: 6| Step: 2
Training loss: 0.39968377351760864
Validation loss: 1.6903248320343673

Epoch: 6| Step: 3
Training loss: 0.3211972117424011
Validation loss: 1.672369962097496

Epoch: 6| Step: 4
Training loss: 0.19065536558628082
Validation loss: 1.6718968409363941

Epoch: 6| Step: 5
Training loss: 0.2645946145057678
Validation loss: 1.659274137148293

Epoch: 6| Step: 6
Training loss: 0.6386061310768127
Validation loss: 1.6522245971105431

Epoch: 6| Step: 7
Training loss: 0.4282527565956116
Validation loss: 1.696231601058796

Epoch: 6| Step: 8
Training loss: 0.2626206874847412
Validation loss: 1.6533210136557137

Epoch: 6| Step: 9
Training loss: 0.36838072538375854
Validation loss: 1.678121615481633

Epoch: 6| Step: 10
Training loss: 0.21077004075050354
Validation loss: 1.6700476715641637

Epoch: 6| Step: 11
Training loss: 0.3317498564720154
Validation loss: 1.6607908395028883

Epoch: 6| Step: 12
Training loss: 0.3082831799983978
Validation loss: 1.6300399290618075

Epoch: 6| Step: 13
Training loss: 0.23769325017929077
Validation loss: 1.5994505754081152

Epoch: 306| Step: 0
Training loss: 0.553700864315033
Validation loss: 1.5965595604271017

Epoch: 6| Step: 1
Training loss: 0.26343199610710144
Validation loss: 1.5901542325173654

Epoch: 6| Step: 2
Training loss: 0.3083428144454956
Validation loss: 1.606978001133088

Epoch: 6| Step: 3
Training loss: 0.2813751995563507
Validation loss: 1.5998246016040925

Epoch: 6| Step: 4
Training loss: 0.4453100264072418
Validation loss: 1.580484023658178

Epoch: 6| Step: 5
Training loss: 0.324027955532074
Validation loss: 1.566919372927758

Epoch: 6| Step: 6
Training loss: 0.21888239681720734
Validation loss: 1.6057576581995974

Epoch: 6| Step: 7
Training loss: 0.40470874309539795
Validation loss: 1.650055375150455

Epoch: 6| Step: 8
Training loss: 0.5721167922019958
Validation loss: 1.7004145165925384

Epoch: 6| Step: 9
Training loss: 0.23849189281463623
Validation loss: 1.686567598773587

Epoch: 6| Step: 10
Training loss: 0.2897619307041168
Validation loss: 1.6969324350357056

Epoch: 6| Step: 11
Training loss: 0.28409716486930847
Validation loss: 1.6365160044803415

Epoch: 6| Step: 12
Training loss: 0.20026502013206482
Validation loss: 1.6853084218117498

Epoch: 6| Step: 13
Training loss: 0.18437182903289795
Validation loss: 1.6365033682956491

Epoch: 307| Step: 0
Training loss: 0.3077983260154724
Validation loss: 1.646024965470837

Epoch: 6| Step: 1
Training loss: 0.2075219303369522
Validation loss: 1.6323830158479753

Epoch: 6| Step: 2
Training loss: 0.382854163646698
Validation loss: 1.612196445465088

Epoch: 6| Step: 3
Training loss: 0.27750614285469055
Validation loss: 1.6360820634390718

Epoch: 6| Step: 4
Training loss: 0.6681712865829468
Validation loss: 1.6413630157388666

Epoch: 6| Step: 5
Training loss: 0.42758411169052124
Validation loss: 1.6717671553293865

Epoch: 6| Step: 6
Training loss: 0.4133249521255493
Validation loss: 1.6747670955555414

Epoch: 6| Step: 7
Training loss: 0.2655623257160187
Validation loss: 1.6173708695237354

Epoch: 6| Step: 8
Training loss: 0.29405081272125244
Validation loss: 1.6826090440955213

Epoch: 6| Step: 9
Training loss: 0.33332449197769165
Validation loss: 1.7199676241925967

Epoch: 6| Step: 10
Training loss: 0.3596385717391968
Validation loss: 1.6981969789792133

Epoch: 6| Step: 11
Training loss: 0.2678292989730835
Validation loss: 1.6712842692611038

Epoch: 6| Step: 12
Training loss: 0.2965710461139679
Validation loss: 1.7078882391734789

Epoch: 6| Step: 13
Training loss: 0.18136495351791382
Validation loss: 1.6726236574111446

Epoch: 308| Step: 0
Training loss: 0.33913707733154297
Validation loss: 1.6623187244579356

Epoch: 6| Step: 1
Training loss: 0.23737438023090363
Validation loss: 1.664900443887198

Epoch: 6| Step: 2
Training loss: 0.4792221784591675
Validation loss: 1.6765183479555192

Epoch: 6| Step: 3
Training loss: 0.35010090470314026
Validation loss: 1.6701044215950915

Epoch: 6| Step: 4
Training loss: 0.3025463819503784
Validation loss: 1.7213754423203007

Epoch: 6| Step: 5
Training loss: 0.3736392855644226
Validation loss: 1.690638546020754

Epoch: 6| Step: 6
Training loss: 0.19157302379608154
Validation loss: 1.6872242214859172

Epoch: 6| Step: 7
Training loss: 0.27885836362838745
Validation loss: 1.7064692589544481

Epoch: 6| Step: 8
Training loss: 0.4663289189338684
Validation loss: 1.6999681277941632

Epoch: 6| Step: 9
Training loss: 0.35209783911705017
Validation loss: 1.7357430637523692

Epoch: 6| Step: 10
Training loss: 0.21061751246452332
Validation loss: 1.6915055218563284

Epoch: 6| Step: 11
Training loss: 0.393024742603302
Validation loss: 1.6651671842862201

Epoch: 6| Step: 12
Training loss: 0.5068739652633667
Validation loss: 1.6970460953251008

Epoch: 6| Step: 13
Training loss: 0.32388317584991455
Validation loss: 1.6667861015565935

Epoch: 309| Step: 0
Training loss: 0.3779151439666748
Validation loss: 1.7048437813276887

Epoch: 6| Step: 1
Training loss: 0.40848734974861145
Validation loss: 1.6837707578494985

Epoch: 6| Step: 2
Training loss: 0.3249683976173401
Validation loss: 1.6646421429931477

Epoch: 6| Step: 3
Training loss: 0.3387547731399536
Validation loss: 1.67711772969974

Epoch: 6| Step: 4
Training loss: 0.2702521085739136
Validation loss: 1.6759718451448666

Epoch: 6| Step: 5
Training loss: 0.5179953575134277
Validation loss: 1.6884646043982556

Epoch: 6| Step: 6
Training loss: 0.3831373155117035
Validation loss: 1.7064161031476912

Epoch: 6| Step: 7
Training loss: 0.32851967215538025
Validation loss: 1.7371613287156629

Epoch: 6| Step: 8
Training loss: 0.3852238953113556
Validation loss: 1.6987073101023191

Epoch: 6| Step: 9
Training loss: 0.47472819685935974
Validation loss: 1.721081700376285

Epoch: 6| Step: 10
Training loss: 0.343725323677063
Validation loss: 1.6968217690785725

Epoch: 6| Step: 11
Training loss: 0.3044477701187134
Validation loss: 1.6355972052902303

Epoch: 6| Step: 12
Training loss: 0.3904663920402527
Validation loss: 1.6187663616672638

Epoch: 6| Step: 13
Training loss: 0.22175340354442596
Validation loss: 1.5928813654889342

Epoch: 310| Step: 0
Training loss: 0.44111865758895874
Validation loss: 1.6323064546431265

Epoch: 6| Step: 1
Training loss: 0.2890111207962036
Validation loss: 1.6374137773308703

Epoch: 6| Step: 2
Training loss: 0.3873439431190491
Validation loss: 1.671700651927661

Epoch: 6| Step: 3
Training loss: 0.5562546253204346
Validation loss: 1.6451699644006708

Epoch: 6| Step: 4
Training loss: 0.35314786434173584
Validation loss: 1.667054319894442

Epoch: 6| Step: 5
Training loss: 0.3344130516052246
Validation loss: 1.648996494149649

Epoch: 6| Step: 6
Training loss: 0.26792967319488525
Validation loss: 1.6634819584508096

Epoch: 6| Step: 7
Training loss: 0.31645143032073975
Validation loss: 1.6566596159370996

Epoch: 6| Step: 8
Training loss: 0.25889867544174194
Validation loss: 1.6785258016278666

Epoch: 6| Step: 9
Training loss: 0.24209243059158325
Validation loss: 1.6950747351492605

Epoch: 6| Step: 10
Training loss: 0.19860072433948517
Validation loss: 1.708117409418988

Epoch: 6| Step: 11
Training loss: 0.19740603864192963
Validation loss: 1.7220736639474028

Epoch: 6| Step: 12
Training loss: 0.4133761525154114
Validation loss: 1.7507911266819123

Epoch: 6| Step: 13
Training loss: 0.640347421169281
Validation loss: 1.7185830147035661

Epoch: 311| Step: 0
Training loss: 0.3477185368537903
Validation loss: 1.6740262982665852

Epoch: 6| Step: 1
Training loss: 0.2607627213001251
Validation loss: 1.6425672064545334

Epoch: 6| Step: 2
Training loss: 0.3242669701576233
Validation loss: 1.6386257243412796

Epoch: 6| Step: 3
Training loss: 0.19095991551876068
Validation loss: 1.604785079597145

Epoch: 6| Step: 4
Training loss: 0.5303654074668884
Validation loss: 1.642398480446108

Epoch: 6| Step: 5
Training loss: 0.2818971276283264
Validation loss: 1.638209698020771

Epoch: 6| Step: 6
Training loss: 0.3735086917877197
Validation loss: 1.6873337555957097

Epoch: 6| Step: 7
Training loss: 0.277576744556427
Validation loss: 1.7099264270515853

Epoch: 6| Step: 8
Training loss: 0.4027697443962097
Validation loss: 1.723579942539174

Epoch: 6| Step: 9
Training loss: 0.24199278652668
Validation loss: 1.7146640593005764

Epoch: 6| Step: 10
Training loss: 0.2098308801651001
Validation loss: 1.6978548367818196

Epoch: 6| Step: 11
Training loss: 0.4289363622665405
Validation loss: 1.714632152229227

Epoch: 6| Step: 12
Training loss: 0.41473013162612915
Validation loss: 1.7062123001262706

Epoch: 6| Step: 13
Training loss: 0.29403987526893616
Validation loss: 1.7082464848795245

Epoch: 312| Step: 0
Training loss: 0.2985004782676697
Validation loss: 1.689346900550268

Epoch: 6| Step: 1
Training loss: 0.30593788623809814
Validation loss: 1.692899800116016

Epoch: 6| Step: 2
Training loss: 0.6227679252624512
Validation loss: 1.6680163747520858

Epoch: 6| Step: 3
Training loss: 0.312671035528183
Validation loss: 1.6440209419496599

Epoch: 6| Step: 4
Training loss: 0.34390971064567566
Validation loss: 1.6564117221422092

Epoch: 6| Step: 5
Training loss: 0.13485078513622284
Validation loss: 1.6521140401081373

Epoch: 6| Step: 6
Training loss: 0.20813068747520447
Validation loss: 1.6652701221486574

Epoch: 6| Step: 7
Training loss: 0.2296573370695114
Validation loss: 1.6379965454019525

Epoch: 6| Step: 8
Training loss: 0.33276626467704773
Validation loss: 1.665779899525386

Epoch: 6| Step: 9
Training loss: 0.41782546043395996
Validation loss: 1.6377195722313338

Epoch: 6| Step: 10
Training loss: 0.21840190887451172
Validation loss: 1.63193440821863

Epoch: 6| Step: 11
Training loss: 0.3280586004257202
Validation loss: 1.6386026849028885

Epoch: 6| Step: 12
Training loss: 0.31844455003738403
Validation loss: 1.6286448124916322

Epoch: 6| Step: 13
Training loss: 0.20558257400989532
Validation loss: 1.634612524381248

Epoch: 313| Step: 0
Training loss: 0.28804636001586914
Validation loss: 1.6404081390750023

Epoch: 6| Step: 1
Training loss: 0.28026431798934937
Validation loss: 1.6557460766966625

Epoch: 6| Step: 2
Training loss: 0.34715646505355835
Validation loss: 1.6675959889606764

Epoch: 6| Step: 3
Training loss: 0.4044337570667267
Validation loss: 1.6408414802243632

Epoch: 6| Step: 4
Training loss: 0.2085520327091217
Validation loss: 1.6261261137582923

Epoch: 6| Step: 5
Training loss: 0.2366447150707245
Validation loss: 1.6116479776238883

Epoch: 6| Step: 6
Training loss: 0.5052717328071594
Validation loss: 1.6219229775090371

Epoch: 6| Step: 7
Training loss: 0.25853270292282104
Validation loss: 1.6169810423287012

Epoch: 6| Step: 8
Training loss: 0.3175761103630066
Validation loss: 1.628461101362782

Epoch: 6| Step: 9
Training loss: 0.2827177345752716
Validation loss: 1.6421156993476294

Epoch: 6| Step: 10
Training loss: 0.25849318504333496
Validation loss: 1.646840964594195

Epoch: 6| Step: 11
Training loss: 0.4580112397670746
Validation loss: 1.6210640758596442

Epoch: 6| Step: 12
Training loss: 0.3574354946613312
Validation loss: 1.6386416381405247

Epoch: 6| Step: 13
Training loss: 0.317841500043869
Validation loss: 1.6607050408599198

Epoch: 314| Step: 0
Training loss: 0.21654489636421204
Validation loss: 1.6266442268125472

Epoch: 6| Step: 1
Training loss: 0.20336496829986572
Validation loss: 1.6534009351525256

Epoch: 6| Step: 2
Training loss: 0.5353838801383972
Validation loss: 1.6340024009827645

Epoch: 6| Step: 3
Training loss: 0.3447111248970032
Validation loss: 1.6424789672256799

Epoch: 6| Step: 4
Training loss: 0.272560179233551
Validation loss: 1.6493459363137521

Epoch: 6| Step: 5
Training loss: 0.20534354448318481
Validation loss: 1.6605103656809816

Epoch: 6| Step: 6
Training loss: 0.40326106548309326
Validation loss: 1.6779888073603313

Epoch: 6| Step: 7
Training loss: 0.30181607604026794
Validation loss: 1.7141649428234305

Epoch: 6| Step: 8
Training loss: 0.15217703580856323
Validation loss: 1.7160049984532018

Epoch: 6| Step: 9
Training loss: 0.37383395433425903
Validation loss: 1.6966897159494378

Epoch: 6| Step: 10
Training loss: 0.2171342968940735
Validation loss: 1.6662226723086448

Epoch: 6| Step: 11
Training loss: 0.31887802481651306
Validation loss: 1.6495255975313083

Epoch: 6| Step: 12
Training loss: 0.2986553907394409
Validation loss: 1.6405374414177352

Epoch: 6| Step: 13
Training loss: 0.4295006990432739
Validation loss: 1.652414555190712

Epoch: 315| Step: 0
Training loss: 0.31817466020584106
Validation loss: 1.6641102490886566

Epoch: 6| Step: 1
Training loss: 0.19692352414131165
Validation loss: 1.6510857151400657

Epoch: 6| Step: 2
Training loss: 0.40198034048080444
Validation loss: 1.6592195136572725

Epoch: 6| Step: 3
Training loss: 0.44968485832214355
Validation loss: 1.6667494402136853

Epoch: 6| Step: 4
Training loss: 0.2935572564601898
Validation loss: 1.6614790924133793

Epoch: 6| Step: 5
Training loss: 0.3327913284301758
Validation loss: 1.6955022222252303

Epoch: 6| Step: 6
Training loss: 0.16912809014320374
Validation loss: 1.6792588387766192

Epoch: 6| Step: 7
Training loss: 0.45852532982826233
Validation loss: 1.6956244425107074

Epoch: 6| Step: 8
Training loss: 0.20968776941299438
Validation loss: 1.6876893376791349

Epoch: 6| Step: 9
Training loss: 0.4304661452770233
Validation loss: 1.6658339500427246

Epoch: 6| Step: 10
Training loss: 0.35193735361099243
Validation loss: 1.7031223145864343

Epoch: 6| Step: 11
Training loss: 0.49885788559913635
Validation loss: 1.6595817817154752

Epoch: 6| Step: 12
Training loss: 0.2982614040374756
Validation loss: 1.653813995340819

Epoch: 6| Step: 13
Training loss: 0.1993861198425293
Validation loss: 1.625292685724074

Epoch: 316| Step: 0
Training loss: 0.27902936935424805
Validation loss: 1.5980532605160949

Epoch: 6| Step: 1
Training loss: 0.2769346833229065
Validation loss: 1.589634282614595

Epoch: 6| Step: 2
Training loss: 0.48168668150901794
Validation loss: 1.5782233976548719

Epoch: 6| Step: 3
Training loss: 0.35820722579956055
Validation loss: 1.6338788578587193

Epoch: 6| Step: 4
Training loss: 0.3796471357345581
Validation loss: 1.6336907494452693

Epoch: 6| Step: 5
Training loss: 0.3250929117202759
Validation loss: 1.6137871216702204

Epoch: 6| Step: 6
Training loss: 0.3073440492153168
Validation loss: 1.6358510717268913

Epoch: 6| Step: 7
Training loss: 0.2579219341278076
Validation loss: 1.627048998109756

Epoch: 6| Step: 8
Training loss: 0.2942729592323303
Validation loss: 1.6460258909451064

Epoch: 6| Step: 9
Training loss: 0.36771249771118164
Validation loss: 1.6430831045232794

Epoch: 6| Step: 10
Training loss: 0.4365033805370331
Validation loss: 1.619896299095564

Epoch: 6| Step: 11
Training loss: 0.1905546933412552
Validation loss: 1.6170027871285715

Epoch: 6| Step: 12
Training loss: 0.25200819969177246
Validation loss: 1.6184729068509993

Epoch: 6| Step: 13
Training loss: 0.26496216654777527
Validation loss: 1.6556925619802167

Epoch: 317| Step: 0
Training loss: 0.3499888479709625
Validation loss: 1.6912735751880112

Epoch: 6| Step: 1
Training loss: 0.16084611415863037
Validation loss: 1.6792806886857556

Epoch: 6| Step: 2
Training loss: 0.28898510336875916
Validation loss: 1.7119255488918674

Epoch: 6| Step: 3
Training loss: 0.27485954761505127
Validation loss: 1.7212391271386096

Epoch: 6| Step: 4
Training loss: 0.23284105956554413
Validation loss: 1.659559679287736

Epoch: 6| Step: 5
Training loss: 0.3573804497718811
Validation loss: 1.6649978763313704

Epoch: 6| Step: 6
Training loss: 0.2875559329986572
Validation loss: 1.6564585085838073

Epoch: 6| Step: 7
Training loss: 0.4826735854148865
Validation loss: 1.6692615606451546

Epoch: 6| Step: 8
Training loss: 0.3521754741668701
Validation loss: 1.6659064664635608

Epoch: 6| Step: 9
Training loss: 0.25177910923957825
Validation loss: 1.657636090632408

Epoch: 6| Step: 10
Training loss: 0.3552111089229584
Validation loss: 1.627521272628538

Epoch: 6| Step: 11
Training loss: 0.31248319149017334
Validation loss: 1.6405508556673605

Epoch: 6| Step: 12
Training loss: 0.17283979058265686
Validation loss: 1.6334322319235852

Epoch: 6| Step: 13
Training loss: 0.30768734216690063
Validation loss: 1.6440691383936072

Epoch: 318| Step: 0
Training loss: 0.25702276825904846
Validation loss: 1.6568672849285988

Epoch: 6| Step: 1
Training loss: 0.2473461925983429
Validation loss: 1.660307377897283

Epoch: 6| Step: 2
Training loss: 0.2508357763290405
Validation loss: 1.696004238179935

Epoch: 6| Step: 3
Training loss: 0.20927469432353973
Validation loss: 1.673385598326242

Epoch: 6| Step: 4
Training loss: 0.3146706521511078
Validation loss: 1.6761066144512546

Epoch: 6| Step: 5
Training loss: 0.18364699184894562
Validation loss: 1.6563993256579164

Epoch: 6| Step: 6
Training loss: 0.20068073272705078
Validation loss: 1.6347842408764748

Epoch: 6| Step: 7
Training loss: 0.15577423572540283
Validation loss: 1.6315028641813545

Epoch: 6| Step: 8
Training loss: 0.4056665301322937
Validation loss: 1.6090939403862081

Epoch: 6| Step: 9
Training loss: 0.30335676670074463
Validation loss: 1.6038096976536576

Epoch: 6| Step: 10
Training loss: 0.29657626152038574
Validation loss: 1.621972377582263

Epoch: 6| Step: 11
Training loss: 0.4742715358734131
Validation loss: 1.6073362532482351

Epoch: 6| Step: 12
Training loss: 0.35439735651016235
Validation loss: 1.6251332093310613

Epoch: 6| Step: 13
Training loss: 0.18562163412570953
Validation loss: 1.6078667063866892

Epoch: 319| Step: 0
Training loss: 0.19149276614189148
Validation loss: 1.6187599538474955

Epoch: 6| Step: 1
Training loss: 0.3113299012184143
Validation loss: 1.6337969969677668

Epoch: 6| Step: 2
Training loss: 0.24578800797462463
Validation loss: 1.6578354527873378

Epoch: 6| Step: 3
Training loss: 0.34817346930503845
Validation loss: 1.649848932861

Epoch: 6| Step: 4
Training loss: 0.1426950991153717
Validation loss: 1.6365197358592865

Epoch: 6| Step: 5
Training loss: 0.25211846828460693
Validation loss: 1.6377573974670903

Epoch: 6| Step: 6
Training loss: 0.4828612804412842
Validation loss: 1.6344730238760672

Epoch: 6| Step: 7
Training loss: 0.20931975543498993
Validation loss: 1.6055443222804735

Epoch: 6| Step: 8
Training loss: 0.2925264239311218
Validation loss: 1.604927275770454

Epoch: 6| Step: 9
Training loss: 0.1875023990869522
Validation loss: 1.5915358976651264

Epoch: 6| Step: 10
Training loss: 0.17960616946220398
Validation loss: 1.5821841455275012

Epoch: 6| Step: 11
Training loss: 0.19969621300697327
Validation loss: 1.5945888514159827

Epoch: 6| Step: 12
Training loss: 0.30510908365249634
Validation loss: 1.5998816913174045

Epoch: 6| Step: 13
Training loss: 0.17391657829284668
Validation loss: 1.5636836251904886

Epoch: 320| Step: 0
Training loss: 0.734077513217926
Validation loss: 1.5955473120494554

Epoch: 6| Step: 1
Training loss: 0.13718470931053162
Validation loss: 1.5917176123588317

Epoch: 6| Step: 2
Training loss: 0.3223986029624939
Validation loss: 1.5904492626908004

Epoch: 6| Step: 3
Training loss: 0.22663915157318115
Validation loss: 1.6229165984738259

Epoch: 6| Step: 4
Training loss: 0.23530268669128418
Validation loss: 1.614057062774576

Epoch: 6| Step: 5
Training loss: 0.10033108294010162
Validation loss: 1.5950287003670969

Epoch: 6| Step: 6
Training loss: 0.1301785409450531
Validation loss: 1.6050629359419628

Epoch: 6| Step: 7
Training loss: 0.15385887026786804
Validation loss: 1.6397211256847586

Epoch: 6| Step: 8
Training loss: 0.20183822512626648
Validation loss: 1.6291326117771927

Epoch: 6| Step: 9
Training loss: 0.32266736030578613
Validation loss: 1.6351325678569015

Epoch: 6| Step: 10
Training loss: 0.3805600702762604
Validation loss: 1.6600382763852355

Epoch: 6| Step: 11
Training loss: 0.2584492862224579
Validation loss: 1.6290700172865262

Epoch: 6| Step: 12
Training loss: 0.1880030632019043
Validation loss: 1.5924593633221042

Epoch: 6| Step: 13
Training loss: 0.20454761385917664
Validation loss: 1.595754865677126

Epoch: 321| Step: 0
Training loss: 0.22056017816066742
Validation loss: 1.5692878653926234

Epoch: 6| Step: 1
Training loss: 0.2650924026966095
Validation loss: 1.5742745745566584

Epoch: 6| Step: 2
Training loss: 0.21112874150276184
Validation loss: 1.5714531060188048

Epoch: 6| Step: 3
Training loss: 0.3052366375923157
Validation loss: 1.5697438838661357

Epoch: 6| Step: 4
Training loss: 0.3854053020477295
Validation loss: 1.597607567746152

Epoch: 6| Step: 5
Training loss: 0.17334440350532532
Validation loss: 1.614662745947479

Epoch: 6| Step: 6
Training loss: 0.23732389509677887
Validation loss: 1.63047702850834

Epoch: 6| Step: 7
Training loss: 0.1964464783668518
Validation loss: 1.6366517133610223

Epoch: 6| Step: 8
Training loss: 0.32648783922195435
Validation loss: 1.6247500001743276

Epoch: 6| Step: 9
Training loss: 0.36723560094833374
Validation loss: 1.5926508531775525

Epoch: 6| Step: 10
Training loss: 0.3157443106174469
Validation loss: 1.620058557038666

Epoch: 6| Step: 11
Training loss: 0.14502006769180298
Validation loss: 1.638698342025921

Epoch: 6| Step: 12
Training loss: 0.2575185298919678
Validation loss: 1.6386228915183776

Epoch: 6| Step: 13
Training loss: 0.36277878284454346
Validation loss: 1.650118093336782

Epoch: 322| Step: 0
Training loss: 0.17212754487991333
Validation loss: 1.6383068369280906

Epoch: 6| Step: 1
Training loss: 0.16945227980613708
Validation loss: 1.6141156329903552

Epoch: 6| Step: 2
Training loss: 0.1803247481584549
Validation loss: 1.5976217562152493

Epoch: 6| Step: 3
Training loss: 0.27980291843414307
Validation loss: 1.6056387321923369

Epoch: 6| Step: 4
Training loss: 0.25343313813209534
Validation loss: 1.5808309355089742

Epoch: 6| Step: 5
Training loss: 0.47761231660842896
Validation loss: 1.574401795223195

Epoch: 6| Step: 6
Training loss: 0.20960968732833862
Validation loss: 1.5787257597010622

Epoch: 6| Step: 7
Training loss: 0.29564493894577026
Validation loss: 1.5957363972099878

Epoch: 6| Step: 8
Training loss: 0.23909810185432434
Validation loss: 1.5748661166878157

Epoch: 6| Step: 9
Training loss: 0.2670733332633972
Validation loss: 1.611169921454563

Epoch: 6| Step: 10
Training loss: 0.14456483721733093
Validation loss: 1.5685114681079824

Epoch: 6| Step: 11
Training loss: 0.30617308616638184
Validation loss: 1.5572722432433919

Epoch: 6| Step: 12
Training loss: 0.1956644058227539
Validation loss: 1.5900699361678092

Epoch: 6| Step: 13
Training loss: 0.10097360610961914
Validation loss: 1.5481081329366213

Epoch: 323| Step: 0
Training loss: 0.18297794461250305
Validation loss: 1.5726385424214024

Epoch: 6| Step: 1
Training loss: 0.1962958574295044
Validation loss: 1.5442316147588915

Epoch: 6| Step: 2
Training loss: 0.3404989242553711
Validation loss: 1.581180000817904

Epoch: 6| Step: 3
Training loss: 0.22404587268829346
Validation loss: 1.5897800473756687

Epoch: 6| Step: 4
Training loss: 0.3679138422012329
Validation loss: 1.5818674589997979

Epoch: 6| Step: 5
Training loss: 0.36161428689956665
Validation loss: 1.5653378476378739

Epoch: 6| Step: 6
Training loss: 0.16283921897411346
Validation loss: 1.5984720081411383

Epoch: 6| Step: 7
Training loss: 0.17111413180828094
Validation loss: 1.5964053497519544

Epoch: 6| Step: 8
Training loss: 0.26651811599731445
Validation loss: 1.6020938952763875

Epoch: 6| Step: 9
Training loss: 0.15682557225227356
Validation loss: 1.6097917197853007

Epoch: 6| Step: 10
Training loss: 0.42506054043769836
Validation loss: 1.5779184372194353

Epoch: 6| Step: 11
Training loss: 0.12322749197483063
Validation loss: 1.587176787596877

Epoch: 6| Step: 12
Training loss: 0.26207399368286133
Validation loss: 1.5867051578337146

Epoch: 6| Step: 13
Training loss: 0.28218165040016174
Validation loss: 1.598686582298689

Epoch: 324| Step: 0
Training loss: 0.19495627284049988
Validation loss: 1.5643298549036826

Epoch: 6| Step: 1
Training loss: 0.2885688543319702
Validation loss: 1.5491411814125635

Epoch: 6| Step: 2
Training loss: 0.19744183123111725
Validation loss: 1.5797472512850197

Epoch: 6| Step: 3
Training loss: 0.31352707743644714
Validation loss: 1.5815263576405023

Epoch: 6| Step: 4
Training loss: 0.27393674850463867
Validation loss: 1.5925834243015577

Epoch: 6| Step: 5
Training loss: 0.2533639073371887
Validation loss: 1.5823372307644095

Epoch: 6| Step: 6
Training loss: 0.18964022397994995
Validation loss: 1.6054332794681672

Epoch: 6| Step: 7
Training loss: 0.24216651916503906
Validation loss: 1.5919459180165363

Epoch: 6| Step: 8
Training loss: 0.2347736805677414
Validation loss: 1.5918310714024368

Epoch: 6| Step: 9
Training loss: 0.18117737770080566
Validation loss: 1.6299449474580827

Epoch: 6| Step: 10
Training loss: 0.25208449363708496
Validation loss: 1.6416153677048222

Epoch: 6| Step: 11
Training loss: 0.30215883255004883
Validation loss: 1.6724012872224212

Epoch: 6| Step: 12
Training loss: 0.3670409321784973
Validation loss: 1.656395955752301

Epoch: 6| Step: 13
Training loss: 0.21432055532932281
Validation loss: 1.6749398298161005

Epoch: 325| Step: 0
Training loss: 0.22981353104114532
Validation loss: 1.6160193168988792

Epoch: 6| Step: 1
Training loss: 0.17044903337955475
Validation loss: 1.5992647242802445

Epoch: 6| Step: 2
Training loss: 0.21747364103794098
Validation loss: 1.5937024252389067

Epoch: 6| Step: 3
Training loss: 0.5123981237411499
Validation loss: 1.5533945355364072

Epoch: 6| Step: 4
Training loss: 0.2908162474632263
Validation loss: 1.5636090053025113

Epoch: 6| Step: 5
Training loss: 0.2431306540966034
Validation loss: 1.5499915346022575

Epoch: 6| Step: 6
Training loss: 0.24957619607448578
Validation loss: 1.5645928152145878

Epoch: 6| Step: 7
Training loss: 0.27168798446655273
Validation loss: 1.5733275708331858

Epoch: 6| Step: 8
Training loss: 0.2350579798221588
Validation loss: 1.5780694587256319

Epoch: 6| Step: 9
Training loss: 0.2593654990196228
Validation loss: 1.5780602360284457

Epoch: 6| Step: 10
Training loss: 0.2659800946712494
Validation loss: 1.6125153803056287

Epoch: 6| Step: 11
Training loss: 0.2291274070739746
Validation loss: 1.6421799134182673

Epoch: 6| Step: 12
Training loss: 0.32302215695381165
Validation loss: 1.5946059432080997

Epoch: 6| Step: 13
Training loss: 0.11701349169015884
Validation loss: 1.603633939578969

Epoch: 326| Step: 0
Training loss: 0.15321026742458344
Validation loss: 1.5833947716220733

Epoch: 6| Step: 1
Training loss: 0.2151341438293457
Validation loss: 1.5818802541302097

Epoch: 6| Step: 2
Training loss: 0.17625883221626282
Validation loss: 1.5859661973932737

Epoch: 6| Step: 3
Training loss: 0.6423821449279785
Validation loss: 1.612595800430544

Epoch: 6| Step: 4
Training loss: 0.2856234610080719
Validation loss: 1.5800492763519287

Epoch: 6| Step: 5
Training loss: 0.1916140615940094
Validation loss: 1.5769976621033044

Epoch: 6| Step: 6
Training loss: 0.26814234256744385
Validation loss: 1.59126575275134

Epoch: 6| Step: 7
Training loss: 0.19762232899665833
Validation loss: 1.6041555032935193

Epoch: 6| Step: 8
Training loss: 0.2747235894203186
Validation loss: 1.597866226268071

Epoch: 6| Step: 9
Training loss: 0.25290173292160034
Validation loss: 1.6483879832811252

Epoch: 6| Step: 10
Training loss: 0.42174726724624634
Validation loss: 1.6483935316403706

Epoch: 6| Step: 11
Training loss: 0.23993366956710815
Validation loss: 1.645694363501764

Epoch: 6| Step: 12
Training loss: 0.2527799606323242
Validation loss: 1.6171909865512644

Epoch: 6| Step: 13
Training loss: 0.10220012068748474
Validation loss: 1.6118955048181678

Epoch: 327| Step: 0
Training loss: 0.20551416277885437
Validation loss: 1.5868250554607761

Epoch: 6| Step: 1
Training loss: 0.2054375559091568
Validation loss: 1.6122083535758398

Epoch: 6| Step: 2
Training loss: 0.21904990077018738
Validation loss: 1.6107256143323836

Epoch: 6| Step: 3
Training loss: 0.23861856758594513
Validation loss: 1.5882911271946405

Epoch: 6| Step: 4
Training loss: 0.34736448526382446
Validation loss: 1.5734404415212653

Epoch: 6| Step: 5
Training loss: 0.17496338486671448
Validation loss: 1.5845086209235653

Epoch: 6| Step: 6
Training loss: 0.16541989147663116
Validation loss: 1.589957465407669

Epoch: 6| Step: 7
Training loss: 0.24333755671977997
Validation loss: 1.6297132917629775

Epoch: 6| Step: 8
Training loss: 0.23687979578971863
Validation loss: 1.6703261444645543

Epoch: 6| Step: 9
Training loss: 0.3381139636039734
Validation loss: 1.6352763739965295

Epoch: 6| Step: 10
Training loss: 0.18081879615783691
Validation loss: 1.6592156733236005

Epoch: 6| Step: 11
Training loss: 0.16270899772644043
Validation loss: 1.676893429089618

Epoch: 6| Step: 12
Training loss: 0.3840559124946594
Validation loss: 1.652934676857405

Epoch: 6| Step: 13
Training loss: 0.1699073314666748
Validation loss: 1.6360617555597776

Epoch: 328| Step: 0
Training loss: 0.24258919060230255
Validation loss: 1.6294216943043534

Epoch: 6| Step: 1
Training loss: 0.23489442467689514
Validation loss: 1.6021517553637106

Epoch: 6| Step: 2
Training loss: 0.24732078611850739
Validation loss: 1.5794350190829205

Epoch: 6| Step: 3
Training loss: 0.26902562379837036
Validation loss: 1.6050906565881544

Epoch: 6| Step: 4
Training loss: 0.16837908327579498
Validation loss: 1.5679783282741424

Epoch: 6| Step: 5
Training loss: 0.1996695101261139
Validation loss: 1.5433094821950442

Epoch: 6| Step: 6
Training loss: 0.21777072548866272
Validation loss: 1.5764386756445772

Epoch: 6| Step: 7
Training loss: 0.4594065546989441
Validation loss: 1.5653519399704472

Epoch: 6| Step: 8
Training loss: 0.14749294519424438
Validation loss: 1.5947929633561002

Epoch: 6| Step: 9
Training loss: 0.1498066633939743
Validation loss: 1.59493500186551

Epoch: 6| Step: 10
Training loss: 0.2579258680343628
Validation loss: 1.5835869735287083

Epoch: 6| Step: 11
Training loss: 0.26545313000679016
Validation loss: 1.6026931334567327

Epoch: 6| Step: 12
Training loss: 0.19108125567436218
Validation loss: 1.6273892707722162

Epoch: 6| Step: 13
Training loss: 0.18579228222370148
Validation loss: 1.6341262799437328

Epoch: 329| Step: 0
Training loss: 0.27217957377433777
Validation loss: 1.6783468133659774

Epoch: 6| Step: 1
Training loss: 0.20941956341266632
Validation loss: 1.6333580709272815

Epoch: 6| Step: 2
Training loss: 0.26556989550590515
Validation loss: 1.66145533515561

Epoch: 6| Step: 3
Training loss: 0.43169209361076355
Validation loss: 1.626932453724646

Epoch: 6| Step: 4
Training loss: 0.15268851816654205
Validation loss: 1.6004703205118898

Epoch: 6| Step: 5
Training loss: 0.2832586169242859
Validation loss: 1.6211484465547787

Epoch: 6| Step: 6
Training loss: 0.25515085458755493
Validation loss: 1.623502649286742

Epoch: 6| Step: 7
Training loss: 0.3742308020591736
Validation loss: 1.6408150542166926

Epoch: 6| Step: 8
Training loss: 0.09848907589912415
Validation loss: 1.6299636338346748

Epoch: 6| Step: 9
Training loss: 0.2914468050003052
Validation loss: 1.59921311050333

Epoch: 6| Step: 10
Training loss: 0.183245450258255
Validation loss: 1.613803118787786

Epoch: 6| Step: 11
Training loss: 0.23705214262008667
Validation loss: 1.6285780937440935

Epoch: 6| Step: 12
Training loss: 0.23549962043762207
Validation loss: 1.5909133239458966

Epoch: 6| Step: 13
Training loss: 0.10469823330640793
Validation loss: 1.5937230228095927

Epoch: 330| Step: 0
Training loss: 0.2608943581581116
Validation loss: 1.6072342216327626

Epoch: 6| Step: 1
Training loss: 0.1812840700149536
Validation loss: 1.6092835703203756

Epoch: 6| Step: 2
Training loss: 0.24943798780441284
Validation loss: 1.593359015321219

Epoch: 6| Step: 3
Training loss: 0.2017078399658203
Validation loss: 1.5928729759749545

Epoch: 6| Step: 4
Training loss: 0.236410453915596
Validation loss: 1.6130123881883518

Epoch: 6| Step: 5
Training loss: 0.2907651662826538
Validation loss: 1.60945338203061

Epoch: 6| Step: 6
Training loss: 0.33291494846343994
Validation loss: 1.6109605476420412

Epoch: 6| Step: 7
Training loss: 0.26935726404190063
Validation loss: 1.6440918599405596

Epoch: 6| Step: 8
Training loss: 0.15539401769638062
Validation loss: 1.6349821398335118

Epoch: 6| Step: 9
Training loss: 0.19833555817604065
Validation loss: 1.6296916815542406

Epoch: 6| Step: 10
Training loss: 0.4838372766971588
Validation loss: 1.6137751033229213

Epoch: 6| Step: 11
Training loss: 0.2116144597530365
Validation loss: 1.6217301955787085

Epoch: 6| Step: 12
Training loss: 0.2121247947216034
Validation loss: 1.6125174337817776

Epoch: 6| Step: 13
Training loss: 0.3169378638267517
Validation loss: 1.6376383522505402

Epoch: 331| Step: 0
Training loss: 0.14821410179138184
Validation loss: 1.5993226766586304

Epoch: 6| Step: 1
Training loss: 0.16421712934970856
Validation loss: 1.568431895266297

Epoch: 6| Step: 2
Training loss: 0.4048417806625366
Validation loss: 1.594102587751163

Epoch: 6| Step: 3
Training loss: 0.2108580768108368
Validation loss: 1.5895015796025593

Epoch: 6| Step: 4
Training loss: 0.23941929638385773
Validation loss: 1.5955625323839084

Epoch: 6| Step: 5
Training loss: 0.21442076563835144
Validation loss: 1.5627460146463046

Epoch: 6| Step: 6
Training loss: 0.2724202871322632
Validation loss: 1.618974603632445

Epoch: 6| Step: 7
Training loss: 0.3025137186050415
Validation loss: 1.6038837291861092

Epoch: 6| Step: 8
Training loss: 0.28631308674812317
Validation loss: 1.6520615905843756

Epoch: 6| Step: 9
Training loss: 0.3587287962436676
Validation loss: 1.6685348736342562

Epoch: 6| Step: 10
Training loss: 0.28864648938179016
Validation loss: 1.5915579808655607

Epoch: 6| Step: 11
Training loss: 0.30375027656555176
Validation loss: 1.5830201384841756

Epoch: 6| Step: 12
Training loss: 0.19400686025619507
Validation loss: 1.6002660694942679

Epoch: 6| Step: 13
Training loss: 0.3092295527458191
Validation loss: 1.6255701049681632

Epoch: 332| Step: 0
Training loss: 0.2071349322795868
Validation loss: 1.6257511531153033

Epoch: 6| Step: 1
Training loss: 0.2930382490158081
Validation loss: 1.6045992887148293

Epoch: 6| Step: 2
Training loss: 0.23470771312713623
Validation loss: 1.6139617081611388

Epoch: 6| Step: 3
Training loss: 0.31291812658309937
Validation loss: 1.6255740645111247

Epoch: 6| Step: 4
Training loss: 0.20128917694091797
Validation loss: 1.6325886634088331

Epoch: 6| Step: 5
Training loss: 0.18433716893196106
Validation loss: 1.6519122354445919

Epoch: 6| Step: 6
Training loss: 0.18307027220726013
Validation loss: 1.654294515168795

Epoch: 6| Step: 7
Training loss: 0.3214716911315918
Validation loss: 1.6487236279313282

Epoch: 6| Step: 8
Training loss: 0.18896228075027466
Validation loss: 1.6303137143452961

Epoch: 6| Step: 9
Training loss: 0.20543181896209717
Validation loss: 1.6074846072863507

Epoch: 6| Step: 10
Training loss: 0.4613761305809021
Validation loss: 1.608882910461836

Epoch: 6| Step: 11
Training loss: 0.2665143311023712
Validation loss: 1.6190607490078095

Epoch: 6| Step: 12
Training loss: 0.1940668374300003
Validation loss: 1.6372735423426474

Epoch: 6| Step: 13
Training loss: 0.31068769097328186
Validation loss: 1.62466287420642

Epoch: 333| Step: 0
Training loss: 0.18797600269317627
Validation loss: 1.6347522427958827

Epoch: 6| Step: 1
Training loss: 0.22809168696403503
Validation loss: 1.5674919812910018

Epoch: 6| Step: 2
Training loss: 0.14688974618911743
Validation loss: 1.5982922802689254

Epoch: 6| Step: 3
Training loss: 0.26136285066604614
Validation loss: 1.5894767879157938

Epoch: 6| Step: 4
Training loss: 0.15239383280277252
Validation loss: 1.5742479716577837

Epoch: 6| Step: 5
Training loss: 0.15069898962974548
Validation loss: 1.5843268017615042

Epoch: 6| Step: 6
Training loss: 0.30490219593048096
Validation loss: 1.6032470797979703

Epoch: 6| Step: 7
Training loss: 0.46790117025375366
Validation loss: 1.6164059728704474

Epoch: 6| Step: 8
Training loss: 0.22376438975334167
Validation loss: 1.6086449917926584

Epoch: 6| Step: 9
Training loss: 0.2568305730819702
Validation loss: 1.5995258144153062

Epoch: 6| Step: 10
Training loss: 0.3020000457763672
Validation loss: 1.5658298897486862

Epoch: 6| Step: 11
Training loss: 0.20052050054073334
Validation loss: 1.5879604598527313

Epoch: 6| Step: 12
Training loss: 0.2946121096611023
Validation loss: 1.576444004171638

Epoch: 6| Step: 13
Training loss: 0.2538694739341736
Validation loss: 1.6025170151905348

Epoch: 334| Step: 0
Training loss: 0.17847661674022675
Validation loss: 1.6343158022049935

Epoch: 6| Step: 1
Training loss: 0.28766363859176636
Validation loss: 1.6182029247283936

Epoch: 6| Step: 2
Training loss: 0.2742546498775482
Validation loss: 1.610091786230764

Epoch: 6| Step: 3
Training loss: 0.35246512293815613
Validation loss: 1.6303817866950907

Epoch: 6| Step: 4
Training loss: 0.19819384813308716
Validation loss: 1.6008878472030803

Epoch: 6| Step: 5
Training loss: 0.3027866780757904
Validation loss: 1.6073464321833786

Epoch: 6| Step: 6
Training loss: 0.191390722990036
Validation loss: 1.6121089279010732

Epoch: 6| Step: 7
Training loss: 0.4275533854961395
Validation loss: 1.5904543540811027

Epoch: 6| Step: 8
Training loss: 0.226514995098114
Validation loss: 1.5915140983878926

Epoch: 6| Step: 9
Training loss: 0.29265767335891724
Validation loss: 1.5901129066303212

Epoch: 6| Step: 10
Training loss: 0.1664566993713379
Validation loss: 1.6405859813895276

Epoch: 6| Step: 11
Training loss: 0.27854934334754944
Validation loss: 1.6717254833508564

Epoch: 6| Step: 12
Training loss: 0.2493487000465393
Validation loss: 1.6610045522771857

Epoch: 6| Step: 13
Training loss: 0.19146329164505005
Validation loss: 1.6782278591586697

Epoch: 335| Step: 0
Training loss: 0.34362009167671204
Validation loss: 1.6751562497949088

Epoch: 6| Step: 1
Training loss: 0.17004260420799255
Validation loss: 1.6055124562273744

Epoch: 6| Step: 2
Training loss: 0.15806426107883453
Validation loss: 1.6080089358873264

Epoch: 6| Step: 3
Training loss: 0.2771926522254944
Validation loss: 1.5999459528153943

Epoch: 6| Step: 4
Training loss: 0.2455245852470398
Validation loss: 1.5892474465472723

Epoch: 6| Step: 5
Training loss: 0.1614621877670288
Validation loss: 1.5840386280449488

Epoch: 6| Step: 6
Training loss: 0.41468366980552673
Validation loss: 1.5684291419162546

Epoch: 6| Step: 7
Training loss: 0.17555248737335205
Validation loss: 1.5937037685865998

Epoch: 6| Step: 8
Training loss: 0.25707194209098816
Validation loss: 1.5755659277721117

Epoch: 6| Step: 9
Training loss: 0.2654196321964264
Validation loss: 1.6064332031434583

Epoch: 6| Step: 10
Training loss: 0.22185981273651123
Validation loss: 1.6115979353586833

Epoch: 6| Step: 11
Training loss: 0.12088191509246826
Validation loss: 1.6539369039638068

Epoch: 6| Step: 12
Training loss: 0.253228098154068
Validation loss: 1.6805724725928357

Epoch: 6| Step: 13
Training loss: 0.32884204387664795
Validation loss: 1.6570380938950406

Epoch: 336| Step: 0
Training loss: 0.20317018032073975
Validation loss: 1.6166641148187781

Epoch: 6| Step: 1
Training loss: 0.15644773840904236
Validation loss: 1.5816998174113612

Epoch: 6| Step: 2
Training loss: 0.19912761449813843
Validation loss: 1.5301083339157926

Epoch: 6| Step: 3
Training loss: 0.2484624683856964
Validation loss: 1.549255621048712

Epoch: 6| Step: 4
Training loss: 0.19570036232471466
Validation loss: 1.555332149228742

Epoch: 6| Step: 5
Training loss: 0.1614701896905899
Validation loss: 1.566896028416131

Epoch: 6| Step: 6
Training loss: 0.25576072931289673
Validation loss: 1.5375029643376668

Epoch: 6| Step: 7
Training loss: 0.21695134043693542
Validation loss: 1.560458888289749

Epoch: 6| Step: 8
Training loss: 0.1717820167541504
Validation loss: 1.5729764379480833

Epoch: 6| Step: 9
Training loss: 0.4662149250507355
Validation loss: 1.5700214703877766

Epoch: 6| Step: 10
Training loss: 0.21398621797561646
Validation loss: 1.5996124231687157

Epoch: 6| Step: 11
Training loss: 0.2870810031890869
Validation loss: 1.568090526006555

Epoch: 6| Step: 12
Training loss: 0.3507462739944458
Validation loss: 1.584116917784496

Epoch: 6| Step: 13
Training loss: 0.1334351897239685
Validation loss: 1.6120708450194328

Epoch: 337| Step: 0
Training loss: 0.3062443435192108
Validation loss: 1.615881726305972

Epoch: 6| Step: 1
Training loss: 0.12968523800373077
Validation loss: 1.6136079167806974

Epoch: 6| Step: 2
Training loss: 0.24908514320850372
Validation loss: 1.629039833622594

Epoch: 6| Step: 3
Training loss: 0.2907468378543854
Validation loss: 1.6428437002243534

Epoch: 6| Step: 4
Training loss: 0.3049376606941223
Validation loss: 1.6734967167659471

Epoch: 6| Step: 5
Training loss: 0.2442578226327896
Validation loss: 1.6898389016428301

Epoch: 6| Step: 6
Training loss: 0.22755473852157593
Validation loss: 1.6574218580799718

Epoch: 6| Step: 7
Training loss: 0.4337630271911621
Validation loss: 1.620923731275784

Epoch: 6| Step: 8
Training loss: 0.2423219531774521
Validation loss: 1.6316149785954466

Epoch: 6| Step: 9
Training loss: 0.133215069770813
Validation loss: 1.589163177756853

Epoch: 6| Step: 10
Training loss: 0.20664650201797485
Validation loss: 1.5956940548394316

Epoch: 6| Step: 11
Training loss: 0.19140589237213135
Validation loss: 1.5652526463231733

Epoch: 6| Step: 12
Training loss: 0.19061574339866638
Validation loss: 1.5483937366034395

Epoch: 6| Step: 13
Training loss: 0.18444912135601044
Validation loss: 1.5372504316350466

Epoch: 338| Step: 0
Training loss: 0.213410884141922
Validation loss: 1.5693057019223449

Epoch: 6| Step: 1
Training loss: 0.37417346239089966
Validation loss: 1.5582667287959848

Epoch: 6| Step: 2
Training loss: 0.26387014985084534
Validation loss: 1.6006814459318757

Epoch: 6| Step: 3
Training loss: 0.4027368426322937
Validation loss: 1.6210564580014957

Epoch: 6| Step: 4
Training loss: 0.2552257776260376
Validation loss: 1.620930580682652

Epoch: 6| Step: 5
Training loss: 0.26098477840423584
Validation loss: 1.6297282095878356

Epoch: 6| Step: 6
Training loss: 0.22947469353675842
Validation loss: 1.6256090159057288

Epoch: 6| Step: 7
Training loss: 0.2909287214279175
Validation loss: 1.6153745369244648

Epoch: 6| Step: 8
Training loss: 0.19384577870368958
Validation loss: 1.5875788350259104

Epoch: 6| Step: 9
Training loss: 0.14024418592453003
Validation loss: 1.6082924136551477

Epoch: 6| Step: 10
Training loss: 0.18100637197494507
Validation loss: 1.6606037001455984

Epoch: 6| Step: 11
Training loss: 0.4130776524543762
Validation loss: 1.6615020344334264

Epoch: 6| Step: 12
Training loss: 0.23512353003025055
Validation loss: 1.6405678179956251

Epoch: 6| Step: 13
Training loss: 0.25824370980262756
Validation loss: 1.6469896570328744

Epoch: 339| Step: 0
Training loss: 0.3060978055000305
Validation loss: 1.651306067743609

Epoch: 6| Step: 1
Training loss: 0.19489556550979614
Validation loss: 1.647237426491194

Epoch: 6| Step: 2
Training loss: 0.2808126211166382
Validation loss: 1.6583508663280035

Epoch: 6| Step: 3
Training loss: 0.31882089376449585
Validation loss: 1.6456943647835844

Epoch: 6| Step: 4
Training loss: 0.16609561443328857
Validation loss: 1.6853075476102932

Epoch: 6| Step: 5
Training loss: 0.30057185888290405
Validation loss: 1.6954794250508791

Epoch: 6| Step: 6
Training loss: 0.26928627490997314
Validation loss: 1.7244812186046312

Epoch: 6| Step: 7
Training loss: 0.24569456279277802
Validation loss: 1.7247139266742173

Epoch: 6| Step: 8
Training loss: 0.17653566598892212
Validation loss: 1.6806097171639884

Epoch: 6| Step: 9
Training loss: 0.20568422973155975
Validation loss: 1.633475572832169

Epoch: 6| Step: 10
Training loss: 0.23658908903598785
Validation loss: 1.5984049343293714

Epoch: 6| Step: 11
Training loss: 0.1379673182964325
Validation loss: 1.5920207231275496

Epoch: 6| Step: 12
Training loss: 0.21255430579185486
Validation loss: 1.6072293494337349

Epoch: 6| Step: 13
Training loss: 0.16759036481380463
Validation loss: 1.590117754474763

Epoch: 340| Step: 0
Training loss: 0.21729251742362976
Validation loss: 1.6328253053849744

Epoch: 6| Step: 1
Training loss: 0.3857499659061432
Validation loss: 1.6485316317568544

Epoch: 6| Step: 2
Training loss: 0.32359349727630615
Validation loss: 1.6318172575325094

Epoch: 6| Step: 3
Training loss: 0.18940936028957367
Validation loss: 1.655886475757886

Epoch: 6| Step: 4
Training loss: 0.1862170696258545
Validation loss: 1.665073758812361

Epoch: 6| Step: 5
Training loss: 0.26284319162368774
Validation loss: 1.7032192048206125

Epoch: 6| Step: 6
Training loss: 0.277072548866272
Validation loss: 1.6651805382902904

Epoch: 6| Step: 7
Training loss: 0.26339787244796753
Validation loss: 1.6738651875526673

Epoch: 6| Step: 8
Training loss: 0.28195720911026
Validation loss: 1.6371270943713445

Epoch: 6| Step: 9
Training loss: 0.2374480664730072
Validation loss: 1.6193062515668972

Epoch: 6| Step: 10
Training loss: 0.19555819034576416
Validation loss: 1.5959536785720496

Epoch: 6| Step: 11
Training loss: 0.1766912043094635
Validation loss: 1.558635619378859

Epoch: 6| Step: 12
Training loss: 0.2234055995941162
Validation loss: 1.5407515597599808

Epoch: 6| Step: 13
Training loss: 0.2031102478504181
Validation loss: 1.5475548595510504

Epoch: 341| Step: 0
Training loss: 0.19220858812332153
Validation loss: 1.5434268956543298

Epoch: 6| Step: 1
Training loss: 0.22142693400382996
Validation loss: 1.5454810332226496

Epoch: 6| Step: 2
Training loss: 0.5123578310012817
Validation loss: 1.5309726499742078

Epoch: 6| Step: 3
Training loss: 0.20348981022834778
Validation loss: 1.5739857330117175

Epoch: 6| Step: 4
Training loss: 0.2138417363166809
Validation loss: 1.5811664558226062

Epoch: 6| Step: 5
Training loss: 0.1683969497680664
Validation loss: 1.5939673082802885

Epoch: 6| Step: 6
Training loss: 0.2497764527797699
Validation loss: 1.5435200891187113

Epoch: 6| Step: 7
Training loss: 0.1999896764755249
Validation loss: 1.5253050070936962

Epoch: 6| Step: 8
Training loss: 0.2317143827676773
Validation loss: 1.558375200917644

Epoch: 6| Step: 9
Training loss: 0.1965773105621338
Validation loss: 1.5927215981227096

Epoch: 6| Step: 10
Training loss: 0.20702464878559113
Validation loss: 1.5644020912467793

Epoch: 6| Step: 11
Training loss: 0.2178405374288559
Validation loss: 1.5830401726948318

Epoch: 6| Step: 12
Training loss: 0.23661234974861145
Validation loss: 1.593776616998898

Epoch: 6| Step: 13
Training loss: 0.13203035295009613
Validation loss: 1.611974726441086

Epoch: 342| Step: 0
Training loss: 0.20262080430984497
Validation loss: 1.5969997259878344

Epoch: 6| Step: 1
Training loss: 0.24112455546855927
Validation loss: 1.586670991554055

Epoch: 6| Step: 2
Training loss: 0.2027110755443573
Validation loss: 1.6122952815025084

Epoch: 6| Step: 3
Training loss: 0.18592995405197144
Validation loss: 1.615208036156111

Epoch: 6| Step: 4
Training loss: 0.2473524808883667
Validation loss: 1.6403391450963996

Epoch: 6| Step: 5
Training loss: 0.28345686197280884
Validation loss: 1.6503040406011766

Epoch: 6| Step: 6
Training loss: 0.17665037512779236
Validation loss: 1.630670819231259

Epoch: 6| Step: 7
Training loss: 0.19284234941005707
Validation loss: 1.6146722775633617

Epoch: 6| Step: 8
Training loss: 0.2888891100883484
Validation loss: 1.618709005335326

Epoch: 6| Step: 9
Training loss: 0.45600900053977966
Validation loss: 1.5633772021980696

Epoch: 6| Step: 10
Training loss: 0.2002718448638916
Validation loss: 1.5760392219789567

Epoch: 6| Step: 11
Training loss: 0.22064821422100067
Validation loss: 1.5842989644696635

Epoch: 6| Step: 12
Training loss: 0.22361481189727783
Validation loss: 1.5810822979096444

Epoch: 6| Step: 13
Training loss: 0.25984540581703186
Validation loss: 1.562966650532138

Epoch: 343| Step: 0
Training loss: 0.20217987895011902
Validation loss: 1.5975337541231545

Epoch: 6| Step: 1
Training loss: 0.2134459912776947
Validation loss: 1.6061182611732072

Epoch: 6| Step: 2
Training loss: 0.2201746106147766
Validation loss: 1.5513321814998504

Epoch: 6| Step: 3
Training loss: 0.13767686486244202
Validation loss: 1.5645386621516237

Epoch: 6| Step: 4
Training loss: 0.2924545407295227
Validation loss: 1.5673375616791427

Epoch: 6| Step: 5
Training loss: 0.30893588066101074
Validation loss: 1.5787958880906463

Epoch: 6| Step: 6
Training loss: 0.1510636806488037
Validation loss: 1.5916951343577395

Epoch: 6| Step: 7
Training loss: 0.35181379318237305
Validation loss: 1.6069150893918929

Epoch: 6| Step: 8
Training loss: 0.1659582257270813
Validation loss: 1.6145936096868208

Epoch: 6| Step: 9
Training loss: 0.18077905476093292
Validation loss: 1.598110697602713

Epoch: 6| Step: 10
Training loss: 0.10255176573991776
Validation loss: 1.6258635520935059

Epoch: 6| Step: 11
Training loss: 0.12906838953495026
Validation loss: 1.621051816530125

Epoch: 6| Step: 12
Training loss: 0.2694879174232483
Validation loss: 1.6166711238122755

Epoch: 6| Step: 13
Training loss: 0.3063106834888458
Validation loss: 1.6159425179163616

Epoch: 344| Step: 0
Training loss: 0.1432427167892456
Validation loss: 1.6268479054973972

Epoch: 6| Step: 1
Training loss: 0.13273368775844574
Validation loss: 1.6375595337601119

Epoch: 6| Step: 2
Training loss: 0.19324594736099243
Validation loss: 1.6359903850863058

Epoch: 6| Step: 3
Training loss: 0.12416091561317444
Validation loss: 1.654232972411699

Epoch: 6| Step: 4
Training loss: 0.24269038438796997
Validation loss: 1.6034301865485407

Epoch: 6| Step: 5
Training loss: 0.291364848613739
Validation loss: 1.5756579086344729

Epoch: 6| Step: 6
Training loss: 0.1577778458595276
Validation loss: 1.57842815819607

Epoch: 6| Step: 7
Training loss: 0.22872331738471985
Validation loss: 1.5942824553417903

Epoch: 6| Step: 8
Training loss: 0.34507501125335693
Validation loss: 1.6074733952040314

Epoch: 6| Step: 9
Training loss: 0.2506604790687561
Validation loss: 1.6786991216803109

Epoch: 6| Step: 10
Training loss: 0.2791668772697449
Validation loss: 1.6521186469703593

Epoch: 6| Step: 11
Training loss: 0.16939544677734375
Validation loss: 1.6510681631744548

Epoch: 6| Step: 12
Training loss: 0.38320082426071167
Validation loss: 1.6184473358174807

Epoch: 6| Step: 13
Training loss: 0.27621281147003174
Validation loss: 1.5925190679488643

Epoch: 345| Step: 0
Training loss: 0.2676471173763275
Validation loss: 1.569644046086137

Epoch: 6| Step: 1
Training loss: 0.16525503993034363
Validation loss: 1.5856563750133719

Epoch: 6| Step: 2
Training loss: 0.09999740868806839
Validation loss: 1.5814840742336806

Epoch: 6| Step: 3
Training loss: 0.20524011552333832
Validation loss: 1.6091286995077645

Epoch: 6| Step: 4
Training loss: 0.16341161727905273
Validation loss: 1.6391972341845114

Epoch: 6| Step: 5
Training loss: 0.4492044746875763
Validation loss: 1.657508696279218

Epoch: 6| Step: 6
Training loss: 0.19762948155403137
Validation loss: 1.640592639164258

Epoch: 6| Step: 7
Training loss: 0.2649412155151367
Validation loss: 1.654112655629394

Epoch: 6| Step: 8
Training loss: 0.15085752308368683
Validation loss: 1.6224758766030754

Epoch: 6| Step: 9
Training loss: 0.2087598741054535
Validation loss: 1.5989704048761757

Epoch: 6| Step: 10
Training loss: 0.162221759557724
Validation loss: 1.5847537299638152

Epoch: 6| Step: 11
Training loss: 0.11667501926422119
Validation loss: 1.601447984736453

Epoch: 6| Step: 12
Training loss: 0.1748196929693222
Validation loss: 1.6270770257519138

Epoch: 6| Step: 13
Training loss: 0.2020055651664734
Validation loss: 1.6154310818641417

Epoch: 346| Step: 0
Training loss: 0.14473281800746918
Validation loss: 1.635935527022167

Epoch: 6| Step: 1
Training loss: 0.17473988234996796
Validation loss: 1.6254435944300827

Epoch: 6| Step: 2
Training loss: 0.15855887532234192
Validation loss: 1.603340043175605

Epoch: 6| Step: 3
Training loss: 0.08645039051771164
Validation loss: 1.6076761548237135

Epoch: 6| Step: 4
Training loss: 0.26555636525154114
Validation loss: 1.5954806061201199

Epoch: 6| Step: 5
Training loss: 0.2706371247768402
Validation loss: 1.5898979248539094

Epoch: 6| Step: 6
Training loss: 0.2509059011936188
Validation loss: 1.5928120324688573

Epoch: 6| Step: 7
Training loss: 0.15926828980445862
Validation loss: 1.605781852558095

Epoch: 6| Step: 8
Training loss: 0.27607226371765137
Validation loss: 1.5987907955723424

Epoch: 6| Step: 9
Training loss: 0.1976604461669922
Validation loss: 1.6173857873485935

Epoch: 6| Step: 10
Training loss: 0.11446458101272583
Validation loss: 1.583153627252066

Epoch: 6| Step: 11
Training loss: 0.20886212587356567
Validation loss: 1.607579456862583

Epoch: 6| Step: 12
Training loss: 0.37638673186302185
Validation loss: 1.5977671915485012

Epoch: 6| Step: 13
Training loss: 0.1367914080619812
Validation loss: 1.594612221564016

Epoch: 347| Step: 0
Training loss: 0.06670034676790237
Validation loss: 1.5999720737498293

Epoch: 6| Step: 1
Training loss: 0.24213534593582153
Validation loss: 1.6388247730911418

Epoch: 6| Step: 2
Training loss: 0.16996848583221436
Validation loss: 1.6643870492135324

Epoch: 6| Step: 3
Training loss: 0.22267118096351624
Validation loss: 1.6412550236589165

Epoch: 6| Step: 4
Training loss: 0.15864959359169006
Validation loss: 1.6152463946291196

Epoch: 6| Step: 5
Training loss: 0.2292817384004593
Validation loss: 1.5905659769171028

Epoch: 6| Step: 6
Training loss: 0.2239110767841339
Validation loss: 1.6090303403075024

Epoch: 6| Step: 7
Training loss: 0.26552388072013855
Validation loss: 1.6294715391692294

Epoch: 6| Step: 8
Training loss: 0.19274653494358063
Validation loss: 1.564810291413338

Epoch: 6| Step: 9
Training loss: 0.22495141625404358
Validation loss: 1.598172644133209

Epoch: 6| Step: 10
Training loss: 0.20214788615703583
Validation loss: 1.6053068048210555

Epoch: 6| Step: 11
Training loss: 0.20539996027946472
Validation loss: 1.6106244463433501

Epoch: 6| Step: 12
Training loss: 0.2950924038887024
Validation loss: 1.6153957138779342

Epoch: 6| Step: 13
Training loss: 0.40792185068130493
Validation loss: 1.6268173981738347

Epoch: 348| Step: 0
Training loss: 0.19405901432037354
Validation loss: 1.6096837366780927

Epoch: 6| Step: 1
Training loss: 0.13665205240249634
Validation loss: 1.6198636575411725

Epoch: 6| Step: 2
Training loss: 0.16157445311546326
Validation loss: 1.5948157336122246

Epoch: 6| Step: 3
Training loss: 0.14718091487884521
Validation loss: 1.5670558521824498

Epoch: 6| Step: 4
Training loss: 0.20772938430309296
Validation loss: 1.545379029807224

Epoch: 6| Step: 5
Training loss: 0.2463274747133255
Validation loss: 1.5590808391571045

Epoch: 6| Step: 6
Training loss: 0.12244483083486557
Validation loss: 1.5627168365704116

Epoch: 6| Step: 7
Training loss: 0.14423227310180664
Validation loss: 1.5816402768576017

Epoch: 6| Step: 8
Training loss: 0.20095743238925934
Validation loss: 1.5525085323600358

Epoch: 6| Step: 9
Training loss: 0.1860046535730362
Validation loss: 1.5904646073618243

Epoch: 6| Step: 10
Training loss: 0.1618211269378662
Validation loss: 1.5923055064293645

Epoch: 6| Step: 11
Training loss: 0.28289881348609924
Validation loss: 1.6020980611924203

Epoch: 6| Step: 12
Training loss: 0.18729117512702942
Validation loss: 1.600117359110104

Epoch: 6| Step: 13
Training loss: 0.4966675937175751
Validation loss: 1.6425970587679135

Epoch: 349| Step: 0
Training loss: 0.1786678433418274
Validation loss: 1.6388638173380206

Epoch: 6| Step: 1
Training loss: 0.20520466566085815
Validation loss: 1.6729493218083535

Epoch: 6| Step: 2
Training loss: 0.16516846418380737
Validation loss: 1.6248256570549422

Epoch: 6| Step: 3
Training loss: 0.44089096784591675
Validation loss: 1.6129493854379142

Epoch: 6| Step: 4
Training loss: 0.13279622793197632
Validation loss: 1.613230469406292

Epoch: 6| Step: 5
Training loss: 0.1347585916519165
Validation loss: 1.6014507598774408

Epoch: 6| Step: 6
Training loss: 0.21081042289733887
Validation loss: 1.5894099538044264

Epoch: 6| Step: 7
Training loss: 0.1433963179588318
Validation loss: 1.6122419282954226

Epoch: 6| Step: 8
Training loss: 0.18889650702476501
Validation loss: 1.6132440631107619

Epoch: 6| Step: 9
Training loss: 0.17131978273391724
Validation loss: 1.61463511695144

Epoch: 6| Step: 10
Training loss: 0.18296530842781067
Validation loss: 1.610940364099318

Epoch: 6| Step: 11
Training loss: 0.19670987129211426
Validation loss: 1.5910249089681974

Epoch: 6| Step: 12
Training loss: 0.23836246132850647
Validation loss: 1.5644721959226875

Epoch: 6| Step: 13
Training loss: 0.414080411195755
Validation loss: 1.587149090664361

Epoch: 350| Step: 0
Training loss: 0.3495853543281555
Validation loss: 1.563292698193622

Epoch: 6| Step: 1
Training loss: 0.2022293508052826
Validation loss: 1.5598898036505586

Epoch: 6| Step: 2
Training loss: 0.1427774429321289
Validation loss: 1.5592034298886535

Epoch: 6| Step: 3
Training loss: 0.24065731465816498
Validation loss: 1.5861069271641393

Epoch: 6| Step: 4
Training loss: 0.1853126883506775
Validation loss: 1.5815921009227794

Epoch: 6| Step: 5
Training loss: 0.1707548350095749
Validation loss: 1.6090862180597039

Epoch: 6| Step: 6
Training loss: 0.16851411759853363
Validation loss: 1.6290154892911193

Epoch: 6| Step: 7
Training loss: 0.1758669912815094
Validation loss: 1.6491045477569743

Epoch: 6| Step: 8
Training loss: 0.20877352356910706
Validation loss: 1.6916624192268617

Epoch: 6| Step: 9
Training loss: 0.1650601327419281
Validation loss: 1.6992199472201768

Epoch: 6| Step: 10
Training loss: 0.36081016063690186
Validation loss: 1.7057594753080798

Epoch: 6| Step: 11
Training loss: 0.2035006880760193
Validation loss: 1.72082382376476

Epoch: 6| Step: 12
Training loss: 0.24137656390666962
Validation loss: 1.7022951546535696

Epoch: 6| Step: 13
Training loss: 0.1697644144296646
Validation loss: 1.6513757667233866

Epoch: 351| Step: 0
Training loss: 0.14406785368919373
Validation loss: 1.6558688532921575

Epoch: 6| Step: 1
Training loss: 0.3571487367153168
Validation loss: 1.6286061386908255

Epoch: 6| Step: 2
Training loss: 0.16037866473197937
Validation loss: 1.6023016642498713

Epoch: 6| Step: 3
Training loss: 0.30691471695899963
Validation loss: 1.6099233665773947

Epoch: 6| Step: 4
Training loss: 0.15228958427906036
Validation loss: 1.5611902821448542

Epoch: 6| Step: 5
Training loss: 0.242241770029068
Validation loss: 1.5924571983275875

Epoch: 6| Step: 6
Training loss: 0.27516859769821167
Validation loss: 1.5800834983907721

Epoch: 6| Step: 7
Training loss: 0.17605435848236084
Validation loss: 1.5550106276748001

Epoch: 6| Step: 8
Training loss: 0.305601567029953
Validation loss: 1.5807968224248579

Epoch: 6| Step: 9
Training loss: 0.2105381339788437
Validation loss: 1.5514344899885115

Epoch: 6| Step: 10
Training loss: 0.16290387511253357
Validation loss: 1.5674256483713787

Epoch: 6| Step: 11
Training loss: 0.12769508361816406
Validation loss: 1.5693150374197191

Epoch: 6| Step: 12
Training loss: 0.26745516061782837
Validation loss: 1.5713212874627882

Epoch: 6| Step: 13
Training loss: 0.2625911235809326
Validation loss: 1.610837390345912

Epoch: 352| Step: 0
Training loss: 0.3989042341709137
Validation loss: 1.6394716514054166

Epoch: 6| Step: 1
Training loss: 0.18129628896713257
Validation loss: 1.6775023719315887

Epoch: 6| Step: 2
Training loss: 0.19628146290779114
Validation loss: 1.6826915946058048

Epoch: 6| Step: 3
Training loss: 0.2671262323856354
Validation loss: 1.6440639034394295

Epoch: 6| Step: 4
Training loss: 0.10636381059885025
Validation loss: 1.6156338722475114

Epoch: 6| Step: 5
Training loss: 0.36772090196609497
Validation loss: 1.609234554793245

Epoch: 6| Step: 6
Training loss: 0.17526784539222717
Validation loss: 1.5805205683554373

Epoch: 6| Step: 7
Training loss: 0.17901799082756042
Validation loss: 1.5759524529980076

Epoch: 6| Step: 8
Training loss: 0.1442403644323349
Validation loss: 1.5838728027959024

Epoch: 6| Step: 9
Training loss: 0.09977631270885468
Validation loss: 1.554804152058017

Epoch: 6| Step: 10
Training loss: 0.17745926976203918
Validation loss: 1.586206187484085

Epoch: 6| Step: 11
Training loss: 0.1516970992088318
Validation loss: 1.5923654340928601

Epoch: 6| Step: 12
Training loss: 0.16027694940567017
Validation loss: 1.6085047580862557

Epoch: 6| Step: 13
Training loss: 0.15344613790512085
Validation loss: 1.6505739035144928

Epoch: 353| Step: 0
Training loss: 0.1835024505853653
Validation loss: 1.6574382230799685

Epoch: 6| Step: 1
Training loss: 0.29093116521835327
Validation loss: 1.6413046877871278

Epoch: 6| Step: 2
Training loss: 0.17974761128425598
Validation loss: 1.6254241312703779

Epoch: 6| Step: 3
Training loss: 0.17949147522449493
Validation loss: 1.5883780179485198

Epoch: 6| Step: 4
Training loss: 0.12732796370983124
Validation loss: 1.5698592073173934

Epoch: 6| Step: 5
Training loss: 0.12644463777542114
Validation loss: 1.5681043273659163

Epoch: 6| Step: 6
Training loss: 0.253633975982666
Validation loss: 1.5481640010751703

Epoch: 6| Step: 7
Training loss: 0.14162784814834595
Validation loss: 1.5662132629784205

Epoch: 6| Step: 8
Training loss: 0.3370042145252228
Validation loss: 1.564192020764915

Epoch: 6| Step: 9
Training loss: 0.1514788717031479
Validation loss: 1.6148577492724183

Epoch: 6| Step: 10
Training loss: 0.21822798252105713
Validation loss: 1.5872633598184074

Epoch: 6| Step: 11
Training loss: 0.23658499121665955
Validation loss: 1.603055683515405

Epoch: 6| Step: 12
Training loss: 0.19885540008544922
Validation loss: 1.5811124488871584

Epoch: 6| Step: 13
Training loss: 0.17337888479232788
Validation loss: 1.5619911198974938

Epoch: 354| Step: 0
Training loss: 0.207194983959198
Validation loss: 1.6065780962667158

Epoch: 6| Step: 1
Training loss: 0.15673871338367462
Validation loss: 1.5659202016809934

Epoch: 6| Step: 2
Training loss: 0.16429370641708374
Validation loss: 1.6148707687213857

Epoch: 6| Step: 3
Training loss: 0.2046433687210083
Validation loss: 1.624828113022671

Epoch: 6| Step: 4
Training loss: 0.2433372586965561
Validation loss: 1.6336580040634319

Epoch: 6| Step: 5
Training loss: 0.12240645289421082
Validation loss: 1.6538735538400628

Epoch: 6| Step: 6
Training loss: 0.16198214888572693
Validation loss: 1.6853794923392675

Epoch: 6| Step: 7
Training loss: 0.43744635581970215
Validation loss: 1.7046395065963909

Epoch: 6| Step: 8
Training loss: 0.15334179997444153
Validation loss: 1.6659120052091536

Epoch: 6| Step: 9
Training loss: 0.2242184579372406
Validation loss: 1.677685417154784

Epoch: 6| Step: 10
Training loss: 0.2437991499900818
Validation loss: 1.7282327849377868

Epoch: 6| Step: 11
Training loss: 0.2531525194644928
Validation loss: 1.6686427195866902

Epoch: 6| Step: 12
Training loss: 0.14979305863380432
Validation loss: 1.6894690951993387

Epoch: 6| Step: 13
Training loss: 0.14507624506950378
Validation loss: 1.6322792358295892

Epoch: 355| Step: 0
Training loss: 0.1980484127998352
Validation loss: 1.6272215702200448

Epoch: 6| Step: 1
Training loss: 0.20913103222846985
Validation loss: 1.6448067093408236

Epoch: 6| Step: 2
Training loss: 0.15947435796260834
Validation loss: 1.6231000179885535

Epoch: 6| Step: 3
Training loss: 0.1486094892024994
Validation loss: 1.6344381814361901

Epoch: 6| Step: 4
Training loss: 0.09740661084651947
Validation loss: 1.6025825162087717

Epoch: 6| Step: 5
Training loss: 0.10428508371114731
Validation loss: 1.6263092743453158

Epoch: 6| Step: 6
Training loss: 0.2869345247745514
Validation loss: 1.616467814291677

Epoch: 6| Step: 7
Training loss: 0.1719626635313034
Validation loss: 1.6155844766606566

Epoch: 6| Step: 8
Training loss: 0.19156521558761597
Validation loss: 1.635058113323745

Epoch: 6| Step: 9
Training loss: 0.3215755820274353
Validation loss: 1.628938558922019

Epoch: 6| Step: 10
Training loss: 0.3218030631542206
Validation loss: 1.6430696966827556

Epoch: 6| Step: 11
Training loss: 0.46684134006500244
Validation loss: 1.656687145592064

Epoch: 6| Step: 12
Training loss: 0.150880366563797
Validation loss: 1.6504422298041723

Epoch: 6| Step: 13
Training loss: 0.07727889716625214
Validation loss: 1.6554988468846967

Epoch: 356| Step: 0
Training loss: 0.3136340379714966
Validation loss: 1.6563691913440663

Epoch: 6| Step: 1
Training loss: 0.29276204109191895
Validation loss: 1.6417343129393875

Epoch: 6| Step: 2
Training loss: 0.24511229991912842
Validation loss: 1.632340185103878

Epoch: 6| Step: 3
Training loss: 0.20942693948745728
Validation loss: 1.5957812416938044

Epoch: 6| Step: 4
Training loss: 0.24109981954097748
Validation loss: 1.5647018007052842

Epoch: 6| Step: 5
Training loss: 0.17288833856582642
Validation loss: 1.5638970046915033

Epoch: 6| Step: 6
Training loss: 0.2843695282936096
Validation loss: 1.5538188513889108

Epoch: 6| Step: 7
Training loss: 0.4475265443325043
Validation loss: 1.5956723023486394

Epoch: 6| Step: 8
Training loss: 0.3445233106613159
Validation loss: 1.5898243842586395

Epoch: 6| Step: 9
Training loss: 0.3856959342956543
Validation loss: 1.5672402099896503

Epoch: 6| Step: 10
Training loss: 0.17232775688171387
Validation loss: 1.580529288579059

Epoch: 6| Step: 11
Training loss: 0.1220935732126236
Validation loss: 1.6376275952144335

Epoch: 6| Step: 12
Training loss: 0.22245027124881744
Validation loss: 1.6272417870900964

Epoch: 6| Step: 13
Training loss: 0.34445807337760925
Validation loss: 1.6554874848294001

Epoch: 357| Step: 0
Training loss: 0.12604960799217224
Validation loss: 1.6850753240687872

Epoch: 6| Step: 1
Training loss: 0.22998468577861786
Validation loss: 1.6750363431951052

Epoch: 6| Step: 2
Training loss: 0.19171325862407684
Validation loss: 1.6376291987716511

Epoch: 6| Step: 3
Training loss: 0.2290680706501007
Validation loss: 1.6011076960512387

Epoch: 6| Step: 4
Training loss: 0.16650612652301788
Validation loss: 1.541106007432425

Epoch: 6| Step: 5
Training loss: 0.3550850749015808
Validation loss: 1.5642362281840334

Epoch: 6| Step: 6
Training loss: 0.14415574073791504
Validation loss: 1.565742681103368

Epoch: 6| Step: 7
Training loss: 0.19466255605220795
Validation loss: 1.5509599998433103

Epoch: 6| Step: 8
Training loss: 0.23333974182605743
Validation loss: 1.537441502335251

Epoch: 6| Step: 9
Training loss: 0.2842884659767151
Validation loss: 1.5408698410116217

Epoch: 6| Step: 10
Training loss: 0.1858159899711609
Validation loss: 1.5746243961395756

Epoch: 6| Step: 11
Training loss: 0.20207273960113525
Validation loss: 1.5852858571596042

Epoch: 6| Step: 12
Training loss: 0.24595674872398376
Validation loss: 1.6328371711956557

Epoch: 6| Step: 13
Training loss: 0.2084541618824005
Validation loss: 1.6528230969623854

Epoch: 358| Step: 0
Training loss: 0.24469676613807678
Validation loss: 1.6763332723289408

Epoch: 6| Step: 1
Training loss: 0.2626899778842926
Validation loss: 1.6696101491169264

Epoch: 6| Step: 2
Training loss: 0.1372794210910797
Validation loss: 1.6544288550653765

Epoch: 6| Step: 3
Training loss: 0.13024300336837769
Validation loss: 1.6370070211348995

Epoch: 6| Step: 4
Training loss: 0.20852750539779663
Validation loss: 1.6035864199361494

Epoch: 6| Step: 5
Training loss: 0.19769620895385742
Validation loss: 1.5978579815997873

Epoch: 6| Step: 6
Training loss: 0.14573049545288086
Validation loss: 1.5903756618499756

Epoch: 6| Step: 7
Training loss: 0.18115873634815216
Validation loss: 1.5991863537860174

Epoch: 6| Step: 8
Training loss: 0.21250973641872406
Validation loss: 1.5830996087802354

Epoch: 6| Step: 9
Training loss: 0.4031836986541748
Validation loss: 1.605662897068967

Epoch: 6| Step: 10
Training loss: 0.15014901757240295
Validation loss: 1.6245454575425835

Epoch: 6| Step: 11
Training loss: 0.272516131401062
Validation loss: 1.615847345321409

Epoch: 6| Step: 12
Training loss: 0.12967416644096375
Validation loss: 1.6298904034399218

Epoch: 6| Step: 13
Training loss: 0.23205778002738953
Validation loss: 1.638716112541896

Epoch: 359| Step: 0
Training loss: 0.13607756793498993
Validation loss: 1.6374797257043983

Epoch: 6| Step: 1
Training loss: 0.16832436621189117
Validation loss: 1.5915044879400602

Epoch: 6| Step: 2
Training loss: 0.13092440366744995
Validation loss: 1.6155277811070925

Epoch: 6| Step: 3
Training loss: 0.12730920314788818
Validation loss: 1.5977737057593562

Epoch: 6| Step: 4
Training loss: 0.14150191843509674
Validation loss: 1.6032407758056477

Epoch: 6| Step: 5
Training loss: 0.1635943353176117
Validation loss: 1.5645080215187483

Epoch: 6| Step: 6
Training loss: 0.17644977569580078
Validation loss: 1.5790212353070576

Epoch: 6| Step: 7
Training loss: 0.38519787788391113
Validation loss: 1.584281011294293

Epoch: 6| Step: 8
Training loss: 0.1746031492948532
Validation loss: 1.5882945483730686

Epoch: 6| Step: 9
Training loss: 0.16465458273887634
Validation loss: 1.5732484991832445

Epoch: 6| Step: 10
Training loss: 0.12769369781017303
Validation loss: 1.561337201826034

Epoch: 6| Step: 11
Training loss: 0.21471761167049408
Validation loss: 1.580769233806159

Epoch: 6| Step: 12
Training loss: 0.24170927703380585
Validation loss: 1.6123937176119896

Epoch: 6| Step: 13
Training loss: 0.20917142927646637
Validation loss: 1.594381343933844

Epoch: 360| Step: 0
Training loss: 0.10410530865192413
Validation loss: 1.5877692981432843

Epoch: 6| Step: 1
Training loss: 0.22992607951164246
Validation loss: 1.5538653263481714

Epoch: 6| Step: 2
Training loss: 0.14467473328113556
Validation loss: 1.5454110676242458

Epoch: 6| Step: 3
Training loss: 0.22498109936714172
Validation loss: 1.533975374314093

Epoch: 6| Step: 4
Training loss: 0.17237231135368347
Validation loss: 1.5859729115680983

Epoch: 6| Step: 5
Training loss: 0.16404864192008972
Validation loss: 1.5839832469981203

Epoch: 6| Step: 6
Training loss: 0.11255114525556564
Validation loss: 1.5906670760082942

Epoch: 6| Step: 7
Training loss: 0.1410098820924759
Validation loss: 1.598287061978412

Epoch: 6| Step: 8
Training loss: 0.22817516326904297
Validation loss: 1.632993455856077

Epoch: 6| Step: 9
Training loss: 0.19175590574741364
Validation loss: 1.6469110827292166

Epoch: 6| Step: 10
Training loss: 0.20784996449947357
Validation loss: 1.6705368026610343

Epoch: 6| Step: 11
Training loss: 0.22088785469532013
Validation loss: 1.6635289217836113

Epoch: 6| Step: 12
Training loss: 0.3322388529777527
Validation loss: 1.672345333201911

Epoch: 6| Step: 13
Training loss: 0.26041465997695923
Validation loss: 1.6583145997857536

Epoch: 361| Step: 0
Training loss: 0.1330713927745819
Validation loss: 1.6594943320879372

Epoch: 6| Step: 1
Training loss: 0.28324559330940247
Validation loss: 1.6385761050767795

Epoch: 6| Step: 2
Training loss: 0.15344886481761932
Validation loss: 1.6178596827291674

Epoch: 6| Step: 3
Training loss: 0.07364580780267715
Validation loss: 1.6118797948283534

Epoch: 6| Step: 4
Training loss: 0.10252653062343597
Validation loss: 1.5636716196613927

Epoch: 6| Step: 5
Training loss: 0.12753161787986755
Validation loss: 1.5685977038516794

Epoch: 6| Step: 6
Training loss: 0.1214083656668663
Validation loss: 1.5687406011807021

Epoch: 6| Step: 7
Training loss: 0.26265209913253784
Validation loss: 1.5771217500009844

Epoch: 6| Step: 8
Training loss: 0.270149827003479
Validation loss: 1.604220691547599

Epoch: 6| Step: 9
Training loss: 0.3743334710597992
Validation loss: 1.6216850793489845

Epoch: 6| Step: 10
Training loss: 0.1769886314868927
Validation loss: 1.5992935908738004

Epoch: 6| Step: 11
Training loss: 0.25716161727905273
Validation loss: 1.6054096055287186

Epoch: 6| Step: 12
Training loss: 0.22685164213180542
Validation loss: 1.58543259866776

Epoch: 6| Step: 13
Training loss: 0.1459183245897293
Validation loss: 1.573145422884213

Epoch: 362| Step: 0
Training loss: 0.14243534207344055
Validation loss: 1.5732899288977347

Epoch: 6| Step: 1
Training loss: 0.2922215163707733
Validation loss: 1.5723543231205275

Epoch: 6| Step: 2
Training loss: 0.28009772300720215
Validation loss: 1.598338039972449

Epoch: 6| Step: 3
Training loss: 0.1309436857700348
Validation loss: 1.6122334926359114

Epoch: 6| Step: 4
Training loss: 0.1841387003660202
Validation loss: 1.6523904915778869

Epoch: 6| Step: 5
Training loss: 0.22069835662841797
Validation loss: 1.6530302032347648

Epoch: 6| Step: 6
Training loss: 0.1928432583808899
Validation loss: 1.6682125932426863

Epoch: 6| Step: 7
Training loss: 0.17801490426063538
Validation loss: 1.6735505275828864

Epoch: 6| Step: 8
Training loss: 0.14497599005699158
Validation loss: 1.6487299191054476

Epoch: 6| Step: 9
Training loss: 0.22520767152309418
Validation loss: 1.6541938192100936

Epoch: 6| Step: 10
Training loss: 0.11868280172348022
Validation loss: 1.615466821578241

Epoch: 6| Step: 11
Training loss: 0.38820016384124756
Validation loss: 1.6032356728789627

Epoch: 6| Step: 12
Training loss: 0.2516489028930664
Validation loss: 1.5805808408285982

Epoch: 6| Step: 13
Training loss: 0.13669750094413757
Validation loss: 1.5864792344390706

Epoch: 363| Step: 0
Training loss: 0.20640407502651215
Validation loss: 1.5938177685583792

Epoch: 6| Step: 1
Training loss: 0.20711170136928558
Validation loss: 1.6098619468750492

Epoch: 6| Step: 2
Training loss: 0.13346964120864868
Validation loss: 1.5862293333135626

Epoch: 6| Step: 3
Training loss: 0.14451226592063904
Validation loss: 1.6168046177074473

Epoch: 6| Step: 4
Training loss: 0.17661656439304352
Validation loss: 1.601644113499631

Epoch: 6| Step: 5
Training loss: 0.16683658957481384
Validation loss: 1.5832544936928699

Epoch: 6| Step: 6
Training loss: 0.1579146832227707
Validation loss: 1.6024773556699035

Epoch: 6| Step: 7
Training loss: 0.3214058578014374
Validation loss: 1.6245777055781374

Epoch: 6| Step: 8
Training loss: 0.1076212152838707
Validation loss: 1.6281682983521493

Epoch: 6| Step: 9
Training loss: 0.345219224691391
Validation loss: 1.6443350443276026

Epoch: 6| Step: 10
Training loss: 0.2487865388393402
Validation loss: 1.640382867987438

Epoch: 6| Step: 11
Training loss: 0.18177881836891174
Validation loss: 1.6374967867328274

Epoch: 6| Step: 12
Training loss: 0.1520175039768219
Validation loss: 1.6612612073139479

Epoch: 6| Step: 13
Training loss: 0.24203835427761078
Validation loss: 1.6186371746883597

Epoch: 364| Step: 0
Training loss: 0.13044479489326477
Validation loss: 1.646708812764896

Epoch: 6| Step: 1
Training loss: 0.11428969353437424
Validation loss: 1.6242708525350016

Epoch: 6| Step: 2
Training loss: 0.19251570105552673
Validation loss: 1.6123754337269773

Epoch: 6| Step: 3
Training loss: 0.1877165585756302
Validation loss: 1.5872884091510568

Epoch: 6| Step: 4
Training loss: 0.4328030049800873
Validation loss: 1.6029834260222733

Epoch: 6| Step: 5
Training loss: 0.14979320764541626
Validation loss: 1.6226683226964806

Epoch: 6| Step: 6
Training loss: 0.2668004333972931
Validation loss: 1.6629694123421945

Epoch: 6| Step: 7
Training loss: 0.27540841698646545
Validation loss: 1.673874544840987

Epoch: 6| Step: 8
Training loss: 0.15282323956489563
Validation loss: 1.6959898612832511

Epoch: 6| Step: 9
Training loss: 0.324147492647171
Validation loss: 1.728751765784397

Epoch: 6| Step: 10
Training loss: 0.18755625188350677
Validation loss: 1.6797502348499913

Epoch: 6| Step: 11
Training loss: 0.2245783507823944
Validation loss: 1.6616588305401545

Epoch: 6| Step: 12
Training loss: 0.1702142357826233
Validation loss: 1.649812215117998

Epoch: 6| Step: 13
Training loss: 0.04244294390082359
Validation loss: 1.6004655482948467

Epoch: 365| Step: 0
Training loss: 0.25889116525650024
Validation loss: 1.594989408728897

Epoch: 6| Step: 1
Training loss: 0.21680033206939697
Validation loss: 1.6013576279404342

Epoch: 6| Step: 2
Training loss: 0.15487712621688843
Validation loss: 1.5849077996387277

Epoch: 6| Step: 3
Training loss: 0.2030656337738037
Validation loss: 1.5722267589261454

Epoch: 6| Step: 4
Training loss: 0.34108424186706543
Validation loss: 1.5898433193083732

Epoch: 6| Step: 5
Training loss: 0.18171674013137817
Validation loss: 1.5752661696044348

Epoch: 6| Step: 6
Training loss: 0.10457471013069153
Validation loss: 1.5994915231581657

Epoch: 6| Step: 7
Training loss: 0.14271195232868195
Validation loss: 1.621711439983819

Epoch: 6| Step: 8
Training loss: 0.19556330144405365
Validation loss: 1.5707786698495187

Epoch: 6| Step: 9
Training loss: 0.1208215206861496
Validation loss: 1.5564950166210052

Epoch: 6| Step: 10
Training loss: 0.18030616641044617
Validation loss: 1.5991491015239427

Epoch: 6| Step: 11
Training loss: 0.14554861187934875
Validation loss: 1.5761944068375455

Epoch: 6| Step: 12
Training loss: 0.19000543653964996
Validation loss: 1.5876442437530847

Epoch: 6| Step: 13
Training loss: 0.09587685018777847
Validation loss: 1.57969803707574

Epoch: 366| Step: 0
Training loss: 0.3216308355331421
Validation loss: 1.5802556763413131

Epoch: 6| Step: 1
Training loss: 0.0678362101316452
Validation loss: 1.5578356225003478

Epoch: 6| Step: 2
Training loss: 0.1764650046825409
Validation loss: 1.5801762701362692

Epoch: 6| Step: 3
Training loss: 0.19214512407779694
Validation loss: 1.5543807373251965

Epoch: 6| Step: 4
Training loss: 0.23423168063163757
Validation loss: 1.5273855847697104

Epoch: 6| Step: 5
Training loss: 0.2528780698776245
Validation loss: 1.5639956433285949

Epoch: 6| Step: 6
Training loss: 0.1830277144908905
Validation loss: 1.5394021939205866

Epoch: 6| Step: 7
Training loss: 0.1895596981048584
Validation loss: 1.5309220206352971

Epoch: 6| Step: 8
Training loss: 0.14492365717887878
Validation loss: 1.5470376553074006

Epoch: 6| Step: 9
Training loss: 0.2036857157945633
Validation loss: 1.5586018639226114

Epoch: 6| Step: 10
Training loss: 0.11481756716966629
Validation loss: 1.5440918642987487

Epoch: 6| Step: 11
Training loss: 0.16766628623008728
Validation loss: 1.5546222027911936

Epoch: 6| Step: 12
Training loss: 0.20157906413078308
Validation loss: 1.5453449397958734

Epoch: 6| Step: 13
Training loss: 0.21026897430419922
Validation loss: 1.5509976110150736

Epoch: 367| Step: 0
Training loss: 0.17149072885513306
Validation loss: 1.5412077724292714

Epoch: 6| Step: 1
Training loss: 0.34345194697380066
Validation loss: 1.5696978274212088

Epoch: 6| Step: 2
Training loss: 0.22116494178771973
Validation loss: 1.5753147653354111

Epoch: 6| Step: 3
Training loss: 0.2057761549949646
Validation loss: 1.585707769599012

Epoch: 6| Step: 4
Training loss: 0.1255321502685547
Validation loss: 1.5589570550508396

Epoch: 6| Step: 5
Training loss: 0.1837468147277832
Validation loss: 1.5596869132852043

Epoch: 6| Step: 6
Training loss: 0.1135772243142128
Validation loss: 1.5820487096745481

Epoch: 6| Step: 7
Training loss: 0.19189776480197906
Validation loss: 1.5586040622444564

Epoch: 6| Step: 8
Training loss: 0.15995526313781738
Validation loss: 1.5644877905486732

Epoch: 6| Step: 9
Training loss: 0.10099688917398453
Validation loss: 1.6035716020932762

Epoch: 6| Step: 10
Training loss: 0.1515493094921112
Validation loss: 1.580938764797744

Epoch: 6| Step: 11
Training loss: 0.12515902519226074
Validation loss: 1.5442447982808596

Epoch: 6| Step: 12
Training loss: 0.1456146389245987
Validation loss: 1.58469702992388

Epoch: 6| Step: 13
Training loss: 0.11642339825630188
Validation loss: 1.556258524617841

Epoch: 368| Step: 0
Training loss: 0.13475507497787476
Validation loss: 1.6086148369696833

Epoch: 6| Step: 1
Training loss: 0.3490939140319824
Validation loss: 1.6024905456009733

Epoch: 6| Step: 2
Training loss: 0.18567097187042236
Validation loss: 1.6083662612463838

Epoch: 6| Step: 3
Training loss: 0.12202933430671692
Validation loss: 1.571893709962086

Epoch: 6| Step: 4
Training loss: 0.12873147428035736
Validation loss: 1.588644617347307

Epoch: 6| Step: 5
Training loss: 0.10707497596740723
Validation loss: 1.620011825715342

Epoch: 6| Step: 6
Training loss: 0.208951935172081
Validation loss: 1.5770495860807356

Epoch: 6| Step: 7
Training loss: 0.13426756858825684
Validation loss: 1.5831091916689308

Epoch: 6| Step: 8
Training loss: 0.06600835919380188
Validation loss: 1.6206385832960888

Epoch: 6| Step: 9
Training loss: 0.1811661720275879
Validation loss: 1.5648068984349568

Epoch: 6| Step: 10
Training loss: 0.11845742166042328
Validation loss: 1.6021654759683917

Epoch: 6| Step: 11
Training loss: 0.1638028919696808
Validation loss: 1.5606547196706135

Epoch: 6| Step: 12
Training loss: 0.18313945829868317
Validation loss: 1.5887375057384532

Epoch: 6| Step: 13
Training loss: 0.15578405559062958
Validation loss: 1.5876760123878397

Epoch: 369| Step: 0
Training loss: 0.13900339603424072
Validation loss: 1.5975276539402623

Epoch: 6| Step: 1
Training loss: 0.15864558517932892
Validation loss: 1.577330086820869

Epoch: 6| Step: 2
Training loss: 0.18375352025032043
Validation loss: 1.5985601935335385

Epoch: 6| Step: 3
Training loss: 0.1515246331691742
Validation loss: 1.6238775202023086

Epoch: 6| Step: 4
Training loss: 0.09778998792171478
Validation loss: 1.6210725615101476

Epoch: 6| Step: 5
Training loss: 0.219467431306839
Validation loss: 1.6038953552963913

Epoch: 6| Step: 6
Training loss: 0.37653663754463196
Validation loss: 1.6113358172037269

Epoch: 6| Step: 7
Training loss: 0.2115936279296875
Validation loss: 1.5785620513782705

Epoch: 6| Step: 8
Training loss: 0.17349760234355927
Validation loss: 1.5522750116163684

Epoch: 6| Step: 9
Training loss: 0.0909881666302681
Validation loss: 1.555588218473619

Epoch: 6| Step: 10
Training loss: 0.12670432031154633
Validation loss: 1.5663752209755681

Epoch: 6| Step: 11
Training loss: 0.1266155242919922
Validation loss: 1.5752285847099878

Epoch: 6| Step: 12
Training loss: 0.23286107182502747
Validation loss: 1.5972235330971338

Epoch: 6| Step: 13
Training loss: 0.12787474691867828
Validation loss: 1.637664428321264

Epoch: 370| Step: 0
Training loss: 0.1358165293931961
Validation loss: 1.5917672059869254

Epoch: 6| Step: 1
Training loss: 0.21226444840431213
Validation loss: 1.6107771204363914

Epoch: 6| Step: 2
Training loss: 0.14490818977355957
Validation loss: 1.6095445950826008

Epoch: 6| Step: 3
Training loss: 0.19000184535980225
Validation loss: 1.6001765535723778

Epoch: 6| Step: 4
Training loss: 0.16749566793441772
Validation loss: 1.5812767846609956

Epoch: 6| Step: 5
Training loss: 0.1672009378671646
Validation loss: 1.5911859453365367

Epoch: 6| Step: 6
Training loss: 0.12514576315879822
Validation loss: 1.5785760161697224

Epoch: 6| Step: 7
Training loss: 0.38510996103286743
Validation loss: 1.5859861168810117

Epoch: 6| Step: 8
Training loss: 0.13309402763843536
Validation loss: 1.5850821195110198

Epoch: 6| Step: 9
Training loss: 0.17827674746513367
Validation loss: 1.6056108910550353

Epoch: 6| Step: 10
Training loss: 0.3072831928730011
Validation loss: 1.5821433067321777

Epoch: 6| Step: 11
Training loss: 0.1884305477142334
Validation loss: 1.581636687760712

Epoch: 6| Step: 12
Training loss: 0.15419073402881622
Validation loss: 1.5538102144836097

Epoch: 6| Step: 13
Training loss: 0.08394958078861237
Validation loss: 1.5399074785171016

Epoch: 371| Step: 0
Training loss: 0.15693695843219757
Validation loss: 1.5442450713085871

Epoch: 6| Step: 1
Training loss: 0.38652825355529785
Validation loss: 1.540871863724083

Epoch: 6| Step: 2
Training loss: 0.16598883271217346
Validation loss: 1.5395030270340622

Epoch: 6| Step: 3
Training loss: 0.183985635638237
Validation loss: 1.548894859770293

Epoch: 6| Step: 4
Training loss: 0.10697660595178604
Validation loss: 1.5483362302985242

Epoch: 6| Step: 5
Training loss: 0.12309784442186356
Validation loss: 1.5487187152267785

Epoch: 6| Step: 6
Training loss: 0.2178022563457489
Validation loss: 1.5587385264776086

Epoch: 6| Step: 7
Training loss: 0.22070035338401794
Validation loss: 1.554704741765094

Epoch: 6| Step: 8
Training loss: 0.11070124059915543
Validation loss: 1.5662285400334226

Epoch: 6| Step: 9
Training loss: 0.1409328132867813
Validation loss: 1.5509895176015875

Epoch: 6| Step: 10
Training loss: 0.1031235083937645
Validation loss: 1.5763390397512784

Epoch: 6| Step: 11
Training loss: 0.10759472846984863
Validation loss: 1.602605576156288

Epoch: 6| Step: 12
Training loss: 0.17561450600624084
Validation loss: 1.6047057772195468

Epoch: 6| Step: 13
Training loss: 0.16862496733665466
Validation loss: 1.6190103946193573

Epoch: 372| Step: 0
Training loss: 0.2116636335849762
Validation loss: 1.610173483048716

Epoch: 6| Step: 1
Training loss: 0.16762980818748474
Validation loss: 1.6139904683636082

Epoch: 6| Step: 2
Training loss: 0.18566283583641052
Validation loss: 1.6049769334895636

Epoch: 6| Step: 3
Training loss: 0.1769416332244873
Validation loss: 1.5924542052771455

Epoch: 6| Step: 4
Training loss: 0.18388822674751282
Validation loss: 1.5703495548617454

Epoch: 6| Step: 5
Training loss: 0.12496142089366913
Validation loss: 1.5925693755508752

Epoch: 6| Step: 6
Training loss: 0.14133578538894653
Validation loss: 1.6018530925114949

Epoch: 6| Step: 7
Training loss: 0.17464205622673035
Validation loss: 1.5879227461353425

Epoch: 6| Step: 8
Training loss: 0.3099510073661804
Validation loss: 1.613203603093342

Epoch: 6| Step: 9
Training loss: 0.11113058030605316
Validation loss: 1.6060507951244232

Epoch: 6| Step: 10
Training loss: 0.1477273404598236
Validation loss: 1.6636889198774933

Epoch: 6| Step: 11
Training loss: 0.1968524008989334
Validation loss: 1.631584003407468

Epoch: 6| Step: 12
Training loss: 0.15002860128879547
Validation loss: 1.6156469801420807

Epoch: 6| Step: 13
Training loss: 0.25264814496040344
Validation loss: 1.60001693489731

Epoch: 373| Step: 0
Training loss: 0.14294761419296265
Validation loss: 1.5834675136432852

Epoch: 6| Step: 1
Training loss: 0.11996638774871826
Validation loss: 1.5819036806783369

Epoch: 6| Step: 2
Training loss: 0.19426369667053223
Validation loss: 1.578946469932474

Epoch: 6| Step: 3
Training loss: 0.11685694009065628
Validation loss: 1.5799913649917932

Epoch: 6| Step: 4
Training loss: 0.17087531089782715
Validation loss: 1.580007186499975

Epoch: 6| Step: 5
Training loss: 0.13759639859199524
Validation loss: 1.5684546757769842

Epoch: 6| Step: 6
Training loss: 0.13816726207733154
Validation loss: 1.5669359955736386

Epoch: 6| Step: 7
Training loss: 0.17992261052131653
Validation loss: 1.5508141363820722

Epoch: 6| Step: 8
Training loss: 0.19497770071029663
Validation loss: 1.5546217515904417

Epoch: 6| Step: 9
Training loss: 0.1380511075258255
Validation loss: 1.5578672309075632

Epoch: 6| Step: 10
Training loss: 0.14119695127010345
Validation loss: 1.5392537847641976

Epoch: 6| Step: 11
Training loss: 0.28161734342575073
Validation loss: 1.565146735919419

Epoch: 6| Step: 12
Training loss: 0.13729026913642883
Validation loss: 1.5865485719455186

Epoch: 6| Step: 13
Training loss: 0.15648740530014038
Validation loss: 1.6052788624199488

Epoch: 374| Step: 0
Training loss: 0.15549223124980927
Validation loss: 1.5984352057979954

Epoch: 6| Step: 1
Training loss: 0.16385696828365326
Validation loss: 1.6207879538177161

Epoch: 6| Step: 2
Training loss: 0.1467771977186203
Validation loss: 1.5886577252418763

Epoch: 6| Step: 3
Training loss: 0.1318545788526535
Validation loss: 1.6083443658326262

Epoch: 6| Step: 4
Training loss: 0.10012929141521454
Validation loss: 1.5826935588672597

Epoch: 6| Step: 5
Training loss: 0.10924894362688065
Validation loss: 1.5927767240872948

Epoch: 6| Step: 6
Training loss: 0.1424092948436737
Validation loss: 1.6146508416821879

Epoch: 6| Step: 7
Training loss: 0.1847514510154724
Validation loss: 1.5719748056063088

Epoch: 6| Step: 8
Training loss: 0.18692979216575623
Validation loss: 1.5742029874555525

Epoch: 6| Step: 9
Training loss: 0.18269659578800201
Validation loss: 1.564932459144182

Epoch: 6| Step: 10
Training loss: 0.3924408555030823
Validation loss: 1.5850643413041228

Epoch: 6| Step: 11
Training loss: 0.08892063796520233
Validation loss: 1.5907300326132006

Epoch: 6| Step: 12
Training loss: 0.18284839391708374
Validation loss: 1.6133506785156906

Epoch: 6| Step: 13
Training loss: 0.10710695385932922
Validation loss: 1.5939688887647403

Epoch: 375| Step: 0
Training loss: 0.15405616164207458
Validation loss: 1.5614841471436203

Epoch: 6| Step: 1
Training loss: 0.16089549660682678
Validation loss: 1.6106092135111492

Epoch: 6| Step: 2
Training loss: 0.14067760109901428
Validation loss: 1.6011752697729296

Epoch: 6| Step: 3
Training loss: 0.1593804955482483
Validation loss: 1.603068038981448

Epoch: 6| Step: 4
Training loss: 0.16765941679477692
Validation loss: 1.5935210899640155

Epoch: 6| Step: 5
Training loss: 0.15673083066940308
Validation loss: 1.5871598720550537

Epoch: 6| Step: 6
Training loss: 0.08971674740314484
Validation loss: 1.5696542993668587

Epoch: 6| Step: 7
Training loss: 0.1398448646068573
Validation loss: 1.5965062443928053

Epoch: 6| Step: 8
Training loss: 0.14535216987133026
Validation loss: 1.5734654536811254

Epoch: 6| Step: 9
Training loss: 0.25444602966308594
Validation loss: 1.5989960226961362

Epoch: 6| Step: 10
Training loss: 0.3992510437965393
Validation loss: 1.6020403164689259

Epoch: 6| Step: 11
Training loss: 0.1462719738483429
Validation loss: 1.5797432673874723

Epoch: 6| Step: 12
Training loss: 0.18546898663043976
Validation loss: 1.6162344409573464

Epoch: 6| Step: 13
Training loss: 0.1699143797159195
Validation loss: 1.5971573488686674

Epoch: 376| Step: 0
Training loss: 0.14232005178928375
Validation loss: 1.6049806200047976

Epoch: 6| Step: 1
Training loss: 0.07517014443874359
Validation loss: 1.5997946851996965

Epoch: 6| Step: 2
Training loss: 0.2995086908340454
Validation loss: 1.5827535096035208

Epoch: 6| Step: 3
Training loss: 0.20784276723861694
Validation loss: 1.6044701850542458

Epoch: 6| Step: 4
Training loss: 0.13109508156776428
Validation loss: 1.5810036441331268

Epoch: 6| Step: 5
Training loss: 0.19059796631336212
Validation loss: 1.5956522431424869

Epoch: 6| Step: 6
Training loss: 0.20184674859046936
Validation loss: 1.584766730185478

Epoch: 6| Step: 7
Training loss: 0.2195816934108734
Validation loss: 1.621671083152935

Epoch: 6| Step: 8
Training loss: 0.1671617329120636
Validation loss: 1.6259102898259317

Epoch: 6| Step: 9
Training loss: 0.22375570237636566
Validation loss: 1.68309005870614

Epoch: 6| Step: 10
Training loss: 0.12594559788703918
Validation loss: 1.6753276842896656

Epoch: 6| Step: 11
Training loss: 0.26481762528419495
Validation loss: 1.6871171100165254

Epoch: 6| Step: 12
Training loss: 0.11220206320285797
Validation loss: 1.6654574351926004

Epoch: 6| Step: 13
Training loss: 0.1252341866493225
Validation loss: 1.6303248328547324

Epoch: 377| Step: 0
Training loss: 0.15344718098640442
Validation loss: 1.6171723065837738

Epoch: 6| Step: 1
Training loss: 0.15985573828220367
Validation loss: 1.618651440066676

Epoch: 6| Step: 2
Training loss: 0.16521500051021576
Validation loss: 1.6156394148385653

Epoch: 6| Step: 3
Training loss: 0.15234161913394928
Validation loss: 1.6012585009298017

Epoch: 6| Step: 4
Training loss: 0.1146569550037384
Validation loss: 1.6160952480890418

Epoch: 6| Step: 5
Training loss: 0.121038518846035
Validation loss: 1.6262796848051009

Epoch: 6| Step: 6
Training loss: 0.10683578252792358
Validation loss: 1.671040859273685

Epoch: 6| Step: 7
Training loss: 0.1833343356847763
Validation loss: 1.63540990250085

Epoch: 6| Step: 8
Training loss: 0.20043638348579407
Validation loss: 1.6443835496902466

Epoch: 6| Step: 9
Training loss: 0.12003529071807861
Validation loss: 1.6500209762204079

Epoch: 6| Step: 10
Training loss: 0.08516813069581985
Validation loss: 1.624489870122684

Epoch: 6| Step: 11
Training loss: 0.31384336948394775
Validation loss: 1.6170277185337518

Epoch: 6| Step: 12
Training loss: 0.15698891878128052
Validation loss: 1.6542085550164665

Epoch: 6| Step: 13
Training loss: 0.06926710158586502
Validation loss: 1.6674992307539909

Epoch: 378| Step: 0
Training loss: 0.17053759098052979
Validation loss: 1.6494415075548234

Epoch: 6| Step: 1
Training loss: 0.1541937291622162
Validation loss: 1.6445177139774445

Epoch: 6| Step: 2
Training loss: 0.40458932518959045
Validation loss: 1.6491519840814735

Epoch: 6| Step: 3
Training loss: 0.14650177955627441
Validation loss: 1.6285046890217771

Epoch: 6| Step: 4
Training loss: 0.14314968883991241
Validation loss: 1.5757227187515588

Epoch: 6| Step: 5
Training loss: 0.11410323530435562
Validation loss: 1.5543557790017897

Epoch: 6| Step: 6
Training loss: 0.09766130149364471
Validation loss: 1.5840951120981606

Epoch: 6| Step: 7
Training loss: 0.13683632016181946
Validation loss: 1.5833653737139959

Epoch: 6| Step: 8
Training loss: 0.1398535817861557
Validation loss: 1.5352863086167203

Epoch: 6| Step: 9
Training loss: 0.12018171697854996
Validation loss: 1.5393093016839796

Epoch: 6| Step: 10
Training loss: 0.15512540936470032
Validation loss: 1.5403984785079956

Epoch: 6| Step: 11
Training loss: 0.13714133203029633
Validation loss: 1.5525107883637952

Epoch: 6| Step: 12
Training loss: 0.19210295379161835
Validation loss: 1.5924940493799025

Epoch: 6| Step: 13
Training loss: 0.17986151576042175
Validation loss: 1.6465834443287184

Epoch: 379| Step: 0
Training loss: 0.15585188567638397
Validation loss: 1.6688831211418234

Epoch: 6| Step: 1
Training loss: 0.1061641126871109
Validation loss: 1.6592556994448426

Epoch: 6| Step: 2
Training loss: 0.320241242647171
Validation loss: 1.6431775028987596

Epoch: 6| Step: 3
Training loss: 0.19484102725982666
Validation loss: 1.657227244428409

Epoch: 6| Step: 4
Training loss: 0.13926324248313904
Validation loss: 1.6297745076558923

Epoch: 6| Step: 5
Training loss: 0.19866973161697388
Validation loss: 1.5980781291120796

Epoch: 6| Step: 6
Training loss: 0.11109127104282379
Validation loss: 1.5749982069897395

Epoch: 6| Step: 7
Training loss: 0.16472738981246948
Validation loss: 1.5737647112979685

Epoch: 6| Step: 8
Training loss: 0.25023823976516724
Validation loss: 1.578480380196725

Epoch: 6| Step: 9
Training loss: 0.2917710542678833
Validation loss: 1.5102427351859309

Epoch: 6| Step: 10
Training loss: 0.17597399652004242
Validation loss: 1.5112417577415385

Epoch: 6| Step: 11
Training loss: 0.1390780657529831
Validation loss: 1.5106830955833517

Epoch: 6| Step: 12
Training loss: 0.16069889068603516
Validation loss: 1.5310343952589138

Epoch: 6| Step: 13
Training loss: 0.17380128800868988
Validation loss: 1.5472191585007535

Epoch: 380| Step: 0
Training loss: 0.14741089940071106
Validation loss: 1.5586197888979347

Epoch: 6| Step: 1
Training loss: 0.38375231623649597
Validation loss: 1.6157173443866033

Epoch: 6| Step: 2
Training loss: 0.25275370478630066
Validation loss: 1.5963534655109528

Epoch: 6| Step: 3
Training loss: 0.1716955304145813
Validation loss: 1.589107991546713

Epoch: 6| Step: 4
Training loss: 0.1847994178533554
Validation loss: 1.6229099355718142

Epoch: 6| Step: 5
Training loss: 0.10917234420776367
Validation loss: 1.6186773879553682

Epoch: 6| Step: 6
Training loss: 0.1063094288110733
Validation loss: 1.579304523365472

Epoch: 6| Step: 7
Training loss: 0.12348118424415588
Validation loss: 1.5717321429201352

Epoch: 6| Step: 8
Training loss: 0.16242432594299316
Validation loss: 1.5416938598437975

Epoch: 6| Step: 9
Training loss: 0.15379679203033447
Validation loss: 1.5378273379418157

Epoch: 6| Step: 10
Training loss: 0.10529748350381851
Validation loss: 1.5322864094088156

Epoch: 6| Step: 11
Training loss: 0.13176843523979187
Validation loss: 1.546585036862281

Epoch: 6| Step: 12
Training loss: 0.09629368782043457
Validation loss: 1.572322739067898

Epoch: 6| Step: 13
Training loss: 0.17884010076522827
Validation loss: 1.5349670584483812

Epoch: 381| Step: 0
Training loss: 0.13993969559669495
Validation loss: 1.5712315036404518

Epoch: 6| Step: 1
Training loss: 0.09082340449094772
Validation loss: 1.5889238593398884

Epoch: 6| Step: 2
Training loss: 0.17518776655197144
Validation loss: 1.5989637451787149

Epoch: 6| Step: 3
Training loss: 0.16407857835292816
Validation loss: 1.589395667916985

Epoch: 6| Step: 4
Training loss: 0.13917747139930725
Validation loss: 1.5870751373229488

Epoch: 6| Step: 5
Training loss: 0.13837212324142456
Validation loss: 1.595733029868013

Epoch: 6| Step: 6
Training loss: 0.10087156295776367
Validation loss: 1.5489640985765765

Epoch: 6| Step: 7
Training loss: 0.16598081588745117
Validation loss: 1.5756792714518886

Epoch: 6| Step: 8
Training loss: 0.14970313012599945
Validation loss: 1.5397316845514442

Epoch: 6| Step: 9
Training loss: 0.3361743092536926
Validation loss: 1.5864052939158615

Epoch: 6| Step: 10
Training loss: 0.23197855055332184
Validation loss: 1.5403128862380981

Epoch: 6| Step: 11
Training loss: 0.17482498288154602
Validation loss: 1.5519080290230371

Epoch: 6| Step: 12
Training loss: 0.13737207651138306
Validation loss: 1.5555519365495252

Epoch: 6| Step: 13
Training loss: 0.11811651289463043
Validation loss: 1.563068978248104

Epoch: 382| Step: 0
Training loss: 0.05242542177438736
Validation loss: 1.5653742026257258

Epoch: 6| Step: 1
Training loss: 0.11442043632268906
Validation loss: 1.5690222440227386

Epoch: 6| Step: 2
Training loss: 0.1686772108078003
Validation loss: 1.565153306530368

Epoch: 6| Step: 3
Training loss: 0.15825960040092468
Validation loss: 1.5434659527194114

Epoch: 6| Step: 4
Training loss: 0.12326216697692871
Validation loss: 1.553923358199417

Epoch: 6| Step: 5
Training loss: 0.15905983746051788
Validation loss: 1.5832420395266624

Epoch: 6| Step: 6
Training loss: 0.13052788376808167
Validation loss: 1.5706202906946982

Epoch: 6| Step: 7
Training loss: 0.28552237153053284
Validation loss: 1.5594543282703688

Epoch: 6| Step: 8
Training loss: 0.11075657606124878
Validation loss: 1.5660010255793089

Epoch: 6| Step: 9
Training loss: 0.09161341935396194
Validation loss: 1.5651023208454091

Epoch: 6| Step: 10
Training loss: 0.13740511238574982
Validation loss: 1.565665634729529

Epoch: 6| Step: 11
Training loss: 0.2161867916584015
Validation loss: 1.593704902997581

Epoch: 6| Step: 12
Training loss: 0.21495723724365234
Validation loss: 1.5882852692757883

Epoch: 6| Step: 13
Training loss: 0.0592382475733757
Validation loss: 1.589344120794727

Epoch: 383| Step: 0
Training loss: 0.20081499218940735
Validation loss: 1.5668485831188899

Epoch: 6| Step: 1
Training loss: 0.10880538821220398
Validation loss: 1.5633605757067282

Epoch: 6| Step: 2
Training loss: 0.1532478928565979
Validation loss: 1.5497968184050692

Epoch: 6| Step: 3
Training loss: 0.11200223118066788
Validation loss: 1.5836569404089322

Epoch: 6| Step: 4
Training loss: 0.15379799902439117
Validation loss: 1.5744089695715136

Epoch: 6| Step: 5
Training loss: 0.16566191613674164
Validation loss: 1.5871179449942805

Epoch: 6| Step: 6
Training loss: 0.25561586022377014
Validation loss: 1.5520979601849791

Epoch: 6| Step: 7
Training loss: 0.27775606513023376
Validation loss: 1.5713382433819514

Epoch: 6| Step: 8
Training loss: 0.08000952750444412
Validation loss: 1.6049791869296823

Epoch: 6| Step: 9
Training loss: 0.111506886780262
Validation loss: 1.601175614582595

Epoch: 6| Step: 10
Training loss: 0.12378804385662079
Validation loss: 1.6159402721671647

Epoch: 6| Step: 11
Training loss: 0.14801494777202606
Validation loss: 1.6429123160659627

Epoch: 6| Step: 12
Training loss: 0.21847625076770782
Validation loss: 1.6496815271275018

Epoch: 6| Step: 13
Training loss: 0.19572481513023376
Validation loss: 1.64046234725624

Epoch: 384| Step: 0
Training loss: 0.11302608251571655
Validation loss: 1.6112347597716956

Epoch: 6| Step: 1
Training loss: 0.08149480819702148
Validation loss: 1.548934708359421

Epoch: 6| Step: 2
Training loss: 0.11758649349212646
Validation loss: 1.5564614521559847

Epoch: 6| Step: 3
Training loss: 0.1414240002632141
Validation loss: 1.556165741335961

Epoch: 6| Step: 4
Training loss: 0.18375568091869354
Validation loss: 1.5619141709419988

Epoch: 6| Step: 5
Training loss: 0.12529203295707703
Validation loss: 1.556782546863761

Epoch: 6| Step: 6
Training loss: 0.16238825023174286
Validation loss: 1.5135774843154415

Epoch: 6| Step: 7
Training loss: 0.1365576982498169
Validation loss: 1.5319400833499046

Epoch: 6| Step: 8
Training loss: 0.13567239046096802
Validation loss: 1.5966575299539874

Epoch: 6| Step: 9
Training loss: 0.13331803679466248
Validation loss: 1.5716020086760163

Epoch: 6| Step: 10
Training loss: 0.31279146671295166
Validation loss: 1.5872220300859021

Epoch: 6| Step: 11
Training loss: 0.24716995656490326
Validation loss: 1.6050653547369025

Epoch: 6| Step: 12
Training loss: 0.11546210944652557
Validation loss: 1.6116047700246174

Epoch: 6| Step: 13
Training loss: 0.19221274554729462
Validation loss: 1.5560998455170663

Epoch: 385| Step: 0
Training loss: 0.10387613624334335
Validation loss: 1.564189681442835

Epoch: 6| Step: 1
Training loss: 0.15467816591262817
Validation loss: 1.5531669919208815

Epoch: 6| Step: 2
Training loss: 0.10984863340854645
Validation loss: 1.5735884456224338

Epoch: 6| Step: 3
Training loss: 0.19545654952526093
Validation loss: 1.5415143735947148

Epoch: 6| Step: 4
Training loss: 0.3455572724342346
Validation loss: 1.547862672036694

Epoch: 6| Step: 5
Training loss: 0.1629037708044052
Validation loss: 1.5473334840548936

Epoch: 6| Step: 6
Training loss: 0.14687353372573853
Validation loss: 1.5363601766606814

Epoch: 6| Step: 7
Training loss: 0.1516895294189453
Validation loss: 1.5521541154512795

Epoch: 6| Step: 8
Training loss: 0.11297677457332611
Validation loss: 1.5368088419719408

Epoch: 6| Step: 9
Training loss: 0.09865215420722961
Validation loss: 1.5685860674868348

Epoch: 6| Step: 10
Training loss: 0.12296892702579498
Validation loss: 1.572286025170357

Epoch: 6| Step: 11
Training loss: 0.11407406628131866
Validation loss: 1.5678433167037142

Epoch: 6| Step: 12
Training loss: 0.052596163004636765
Validation loss: 1.5792180504850162

Epoch: 6| Step: 13
Training loss: 0.11338570713996887
Validation loss: 1.5771881841844129

Epoch: 386| Step: 0
Training loss: 0.18971148133277893
Validation loss: 1.545656011950585

Epoch: 6| Step: 1
Training loss: 0.10820821672677994
Validation loss: 1.5879995297360163

Epoch: 6| Step: 2
Training loss: 0.13242477178573608
Validation loss: 1.59819281870319

Epoch: 6| Step: 3
Training loss: 0.12513814866542816
Validation loss: 1.5517996344515073

Epoch: 6| Step: 4
Training loss: 0.09978269040584564
Validation loss: 1.566652944011073

Epoch: 6| Step: 5
Training loss: 0.10843198001384735
Validation loss: 1.592439596370984

Epoch: 6| Step: 6
Training loss: 0.164346382021904
Validation loss: 1.58180538300545

Epoch: 6| Step: 7
Training loss: 0.35247495770454407
Validation loss: 1.5913168422637447

Epoch: 6| Step: 8
Training loss: 0.14441797137260437
Validation loss: 1.587257872345627

Epoch: 6| Step: 9
Training loss: 0.17841774225234985
Validation loss: 1.5766940655246857

Epoch: 6| Step: 10
Training loss: 0.12005367130041122
Validation loss: 1.5846501306820941

Epoch: 6| Step: 11
Training loss: 0.06560155004262924
Validation loss: 1.5914105689653786

Epoch: 6| Step: 12
Training loss: 0.1892079859972
Validation loss: 1.5814383023528642

Epoch: 6| Step: 13
Training loss: 0.12721000611782074
Validation loss: 1.5757594646946076

Epoch: 387| Step: 0
Training loss: 0.1107281967997551
Validation loss: 1.5587936806422409

Epoch: 6| Step: 1
Training loss: 0.07900553941726685
Validation loss: 1.5386562212820976

Epoch: 6| Step: 2
Training loss: 0.13392503559589386
Validation loss: 1.5445275857884397

Epoch: 6| Step: 3
Training loss: 0.08683546632528305
Validation loss: 1.5260639677765548

Epoch: 6| Step: 4
Training loss: 0.11788944154977798
Validation loss: 1.5147109377768733

Epoch: 6| Step: 5
Training loss: 0.39673081040382385
Validation loss: 1.4919075863335722

Epoch: 6| Step: 6
Training loss: 0.14913628995418549
Validation loss: 1.5034336210579

Epoch: 6| Step: 7
Training loss: 0.1357235312461853
Validation loss: 1.5082060931831278

Epoch: 6| Step: 8
Training loss: 0.12318029254674911
Validation loss: 1.5094351947948497

Epoch: 6| Step: 9
Training loss: 0.19883963465690613
Validation loss: 1.563675557413409

Epoch: 6| Step: 10
Training loss: 0.15051835775375366
Validation loss: 1.5323812461668445

Epoch: 6| Step: 11
Training loss: 0.200858473777771
Validation loss: 1.573631005902444

Epoch: 6| Step: 12
Training loss: 0.12405795603990555
Validation loss: 1.5848153560392317

Epoch: 6| Step: 13
Training loss: 0.1546810418367386
Validation loss: 1.5597144076901097

Epoch: 388| Step: 0
Training loss: 0.12008678913116455
Validation loss: 1.5766058339867541

Epoch: 6| Step: 1
Training loss: 0.115735724568367
Validation loss: 1.5872746770099928

Epoch: 6| Step: 2
Training loss: 0.1949373334646225
Validation loss: 1.5914055333342603

Epoch: 6| Step: 3
Training loss: 0.08688142895698547
Validation loss: 1.5769696351020568

Epoch: 6| Step: 4
Training loss: 0.1104852557182312
Validation loss: 1.551638137909674

Epoch: 6| Step: 5
Training loss: 0.130923330783844
Validation loss: 1.5699596007664998

Epoch: 6| Step: 6
Training loss: 0.30910131335258484
Validation loss: 1.5671325345193186

Epoch: 6| Step: 7
Training loss: 0.09182451665401459
Validation loss: 1.5740250246499174

Epoch: 6| Step: 8
Training loss: 0.11187282204627991
Validation loss: 1.575334757886907

Epoch: 6| Step: 9
Training loss: 0.17452159523963928
Validation loss: 1.577841289581791

Epoch: 6| Step: 10
Training loss: 0.15061500668525696
Validation loss: 1.5918714179787585

Epoch: 6| Step: 11
Training loss: 0.13022461533546448
Validation loss: 1.5981938903049757

Epoch: 6| Step: 12
Training loss: 0.10368097573518753
Validation loss: 1.6025904173492103

Epoch: 6| Step: 13
Training loss: 0.08815722167491913
Validation loss: 1.594222217477778

Epoch: 389| Step: 0
Training loss: 0.1464395523071289
Validation loss: 1.604315180932322

Epoch: 6| Step: 1
Training loss: 0.1120348796248436
Validation loss: 1.6068331067280104

Epoch: 6| Step: 2
Training loss: 0.37119174003601074
Validation loss: 1.5538295571522047

Epoch: 6| Step: 3
Training loss: 0.11413843929767609
Validation loss: 1.5200259002947039

Epoch: 6| Step: 4
Training loss: 0.15519870817661285
Validation loss: 1.5589266413001603

Epoch: 6| Step: 5
Training loss: 0.13090036809444427
Validation loss: 1.5764826638724214

Epoch: 6| Step: 6
Training loss: 0.08553624153137207
Validation loss: 1.5449407164768507

Epoch: 6| Step: 7
Training loss: 0.10643906891345978
Validation loss: 1.5769037251831384

Epoch: 6| Step: 8
Training loss: 0.09924707561731339
Validation loss: 1.5443193848415087

Epoch: 6| Step: 9
Training loss: 0.14636215567588806
Validation loss: 1.5511215040760655

Epoch: 6| Step: 10
Training loss: 0.17905700206756592
Validation loss: 1.5856675813274999

Epoch: 6| Step: 11
Training loss: 0.08162970840930939
Validation loss: 1.576922365414199

Epoch: 6| Step: 12
Training loss: 0.12966476380825043
Validation loss: 1.5661357775811227

Epoch: 6| Step: 13
Training loss: 0.08189098536968231
Validation loss: 1.574972979484066

Epoch: 390| Step: 0
Training loss: 0.22482550144195557
Validation loss: 1.5926123870316373

Epoch: 6| Step: 1
Training loss: 0.21487529575824738
Validation loss: 1.555048986788719

Epoch: 6| Step: 2
Training loss: 0.07009454071521759
Validation loss: 1.5401197530890023

Epoch: 6| Step: 3
Training loss: 0.15285006165504456
Validation loss: 1.583271300920876

Epoch: 6| Step: 4
Training loss: 0.10076635330915451
Validation loss: 1.6030310020651868

Epoch: 6| Step: 5
Training loss: 0.11550968885421753
Validation loss: 1.6007763672900457

Epoch: 6| Step: 6
Training loss: 0.10268820822238922
Validation loss: 1.6224110421314035

Epoch: 6| Step: 7
Training loss: 0.12970033288002014
Validation loss: 1.633154987007059

Epoch: 6| Step: 8
Training loss: 0.11373333632946014
Validation loss: 1.5980324052995252

Epoch: 6| Step: 9
Training loss: 0.13324806094169617
Validation loss: 1.6052902654934955

Epoch: 6| Step: 10
Training loss: 0.1254272758960724
Validation loss: 1.5701798546698786

Epoch: 6| Step: 11
Training loss: 0.15917657315731049
Validation loss: 1.5911007670946018

Epoch: 6| Step: 12
Training loss: 0.33651337027549744
Validation loss: 1.5624106596874934

Epoch: 6| Step: 13
Training loss: 0.19224947690963745
Validation loss: 1.5348221717342254

Epoch: 391| Step: 0
Training loss: 0.18563544750213623
Validation loss: 1.5621603906795543

Epoch: 6| Step: 1
Training loss: 0.1879883110523224
Validation loss: 1.5563316319578437

Epoch: 6| Step: 2
Training loss: 0.16941703855991364
Validation loss: 1.5554490730326662

Epoch: 6| Step: 3
Training loss: 0.14544948935508728
Validation loss: 1.5671555675486082

Epoch: 6| Step: 4
Training loss: 0.10573895275592804
Validation loss: 1.5827165444691975

Epoch: 6| Step: 5
Training loss: 0.10861051827669144
Validation loss: 1.5952734229385213

Epoch: 6| Step: 6
Training loss: 0.18871602416038513
Validation loss: 1.6160343359875422

Epoch: 6| Step: 7
Training loss: 0.20397044718265533
Validation loss: 1.5928062046727827

Epoch: 6| Step: 8
Training loss: 0.1644589751958847
Validation loss: 1.6051123834425403

Epoch: 6| Step: 9
Training loss: 0.12468579411506653
Validation loss: 1.567843069312393

Epoch: 6| Step: 10
Training loss: 0.100765161216259
Validation loss: 1.5917237779145599

Epoch: 6| Step: 11
Training loss: 0.3135901093482971
Validation loss: 1.5528641375162269

Epoch: 6| Step: 12
Training loss: 0.12838312983512878
Validation loss: 1.5684661070505779

Epoch: 6| Step: 13
Training loss: 0.23222610354423523
Validation loss: 1.582605964394026

Epoch: 392| Step: 0
Training loss: 0.15482166409492493
Validation loss: 1.5465310007654212

Epoch: 6| Step: 1
Training loss: 0.16045594215393066
Validation loss: 1.5294246083946639

Epoch: 6| Step: 2
Training loss: 0.10025721788406372
Validation loss: 1.4887976454150291

Epoch: 6| Step: 3
Training loss: 0.13526776432991028
Validation loss: 1.5094085931777954

Epoch: 6| Step: 4
Training loss: 0.2774272859096527
Validation loss: 1.5106468309638321

Epoch: 6| Step: 5
Training loss: 0.14010179042816162
Validation loss: 1.5477763529746764

Epoch: 6| Step: 6
Training loss: 0.17231965065002441
Validation loss: 1.5337964334795553

Epoch: 6| Step: 7
Training loss: 0.109178826212883
Validation loss: 1.552609941010834

Epoch: 6| Step: 8
Training loss: 0.12898366153240204
Validation loss: 1.558254635141742

Epoch: 6| Step: 9
Training loss: 0.08980154991149902
Validation loss: 1.6075707212571175

Epoch: 6| Step: 10
Training loss: 0.17635858058929443
Validation loss: 1.5952952536203528

Epoch: 6| Step: 11
Training loss: 0.19822075963020325
Validation loss: 1.583164757297885

Epoch: 6| Step: 12
Training loss: 0.15997213125228882
Validation loss: 1.5463675593817106

Epoch: 6| Step: 13
Training loss: 0.20064295828342438
Validation loss: 1.5441194157446585

Epoch: 393| Step: 0
Training loss: 0.10582804679870605
Validation loss: 1.5232666192516204

Epoch: 6| Step: 1
Training loss: 0.13737133145332336
Validation loss: 1.5330578434851863

Epoch: 6| Step: 2
Training loss: 0.15854346752166748
Validation loss: 1.5027879220183178

Epoch: 6| Step: 3
Training loss: 0.29380083084106445
Validation loss: 1.5401474122078187

Epoch: 6| Step: 4
Training loss: 0.10043793171644211
Validation loss: 1.5256954995534753

Epoch: 6| Step: 5
Training loss: 0.13305380940437317
Validation loss: 1.548262789685239

Epoch: 6| Step: 6
Training loss: 0.13572433590888977
Validation loss: 1.5703664223353069

Epoch: 6| Step: 7
Training loss: 0.11738590896129608
Validation loss: 1.5536496434160458

Epoch: 6| Step: 8
Training loss: 0.16219857335090637
Validation loss: 1.566891037648724

Epoch: 6| Step: 9
Training loss: 0.16816507279872894
Validation loss: 1.568327893492996

Epoch: 6| Step: 10
Training loss: 0.17922541499137878
Validation loss: 1.5340332901605995

Epoch: 6| Step: 11
Training loss: 0.1507817506790161
Validation loss: 1.536071433815905

Epoch: 6| Step: 12
Training loss: 0.13793633878231049
Validation loss: 1.5208567162995696

Epoch: 6| Step: 13
Training loss: 0.11425647139549255
Validation loss: 1.5192634649174188

Epoch: 394| Step: 0
Training loss: 0.17190313339233398
Validation loss: 1.5303923212071902

Epoch: 6| Step: 1
Training loss: 0.11239543557167053
Validation loss: 1.5290280804839185

Epoch: 6| Step: 2
Training loss: 0.18543106317520142
Validation loss: 1.572616377184468

Epoch: 6| Step: 3
Training loss: 0.214717298746109
Validation loss: 1.5298473322263328

Epoch: 6| Step: 4
Training loss: 0.2850046157836914
Validation loss: 1.519819510880337

Epoch: 6| Step: 5
Training loss: 0.08483048528432846
Validation loss: 1.5291442537820468

Epoch: 6| Step: 6
Training loss: 0.1806516945362091
Validation loss: 1.58830346984248

Epoch: 6| Step: 7
Training loss: 0.21602486073970795
Validation loss: 1.5986835674573017

Epoch: 6| Step: 8
Training loss: 0.14697478711605072
Validation loss: 1.5554166327240646

Epoch: 6| Step: 9
Training loss: 0.16435866057872772
Validation loss: 1.5300975102250294

Epoch: 6| Step: 10
Training loss: 0.11284098029136658
Validation loss: 1.502239199094875

Epoch: 6| Step: 11
Training loss: 0.14692452549934387
Validation loss: 1.5115851330500778

Epoch: 6| Step: 12
Training loss: 0.1803678274154663
Validation loss: 1.5371198282446912

Epoch: 6| Step: 13
Training loss: 0.1877317577600479
Validation loss: 1.5426551090773715

Epoch: 395| Step: 0
Training loss: 0.34694159030914307
Validation loss: 1.5499190271541636

Epoch: 6| Step: 1
Training loss: 0.19637587666511536
Validation loss: 1.5370872366812922

Epoch: 6| Step: 2
Training loss: 0.13839612901210785
Validation loss: 1.5508779697520758

Epoch: 6| Step: 3
Training loss: 0.14616821706295013
Validation loss: 1.5809831003988943

Epoch: 6| Step: 4
Training loss: 0.103404700756073
Validation loss: 1.6206005042599094

Epoch: 6| Step: 5
Training loss: 0.16585025191307068
Validation loss: 1.600140881794755

Epoch: 6| Step: 6
Training loss: 0.1449226438999176
Validation loss: 1.5921130180358887

Epoch: 6| Step: 7
Training loss: 0.15235665440559387
Validation loss: 1.599260748073619

Epoch: 6| Step: 8
Training loss: 0.13650965690612793
Validation loss: 1.5809601763243317

Epoch: 6| Step: 9
Training loss: 0.10162371397018433
Validation loss: 1.5838011618583434

Epoch: 6| Step: 10
Training loss: 0.13665461540222168
Validation loss: 1.543579278453704

Epoch: 6| Step: 11
Training loss: 0.13487184047698975
Validation loss: 1.5546840378033218

Epoch: 6| Step: 12
Training loss: 0.15355345606803894
Validation loss: 1.5154893417512216

Epoch: 6| Step: 13
Training loss: 0.17995794117450714
Validation loss: 1.5294169405455231

Epoch: 396| Step: 0
Training loss: 0.14158795773983002
Validation loss: 1.5515542120061896

Epoch: 6| Step: 1
Training loss: 0.226458340883255
Validation loss: 1.5339860364954958

Epoch: 6| Step: 2
Training loss: 0.1371418833732605
Validation loss: 1.5234804294442619

Epoch: 6| Step: 3
Training loss: 0.14448413252830505
Validation loss: 1.5491898726391535

Epoch: 6| Step: 4
Training loss: 0.08731620758771896
Validation loss: 1.5736288319351852

Epoch: 6| Step: 5
Training loss: 0.30732691287994385
Validation loss: 1.6005926228338672

Epoch: 6| Step: 6
Training loss: 0.17129477858543396
Validation loss: 1.5945011313243578

Epoch: 6| Step: 7
Training loss: 0.12911739945411682
Validation loss: 1.57369432398068

Epoch: 6| Step: 8
Training loss: 0.16440774500370026
Validation loss: 1.5768748508986605

Epoch: 6| Step: 9
Training loss: 0.12923318147659302
Validation loss: 1.5622853796969178

Epoch: 6| Step: 10
Training loss: 0.17739680409431458
Validation loss: 1.5265484304838284

Epoch: 6| Step: 11
Training loss: 0.12090219557285309
Validation loss: 1.521732985332448

Epoch: 6| Step: 12
Training loss: 0.13950279355049133
Validation loss: 1.5509671216369958

Epoch: 6| Step: 13
Training loss: 0.13977862894535065
Validation loss: 1.5450480535466184

Epoch: 397| Step: 0
Training loss: 0.12141229212284088
Validation loss: 1.5679668239367905

Epoch: 6| Step: 1
Training loss: 0.19179585576057434
Validation loss: 1.5847848282065442

Epoch: 6| Step: 2
Training loss: 0.17231854796409607
Validation loss: 1.6150147158612487

Epoch: 6| Step: 3
Training loss: 0.21202711760997772
Validation loss: 1.6087270180384319

Epoch: 6| Step: 4
Training loss: 0.22555425763130188
Validation loss: 1.610917692543358

Epoch: 6| Step: 5
Training loss: 0.11025021225214005
Validation loss: 1.6463987250481882

Epoch: 6| Step: 6
Training loss: 0.05255356431007385
Validation loss: 1.6253274768911383

Epoch: 6| Step: 7
Training loss: 0.1488979160785675
Validation loss: 1.6431492669608003

Epoch: 6| Step: 8
Training loss: 0.14719060063362122
Validation loss: 1.6477991996272918

Epoch: 6| Step: 9
Training loss: 0.2336389124393463
Validation loss: 1.6415984694675734

Epoch: 6| Step: 10
Training loss: 0.1903523951768875
Validation loss: 1.6140040095134447

Epoch: 6| Step: 11
Training loss: 0.15711750090122223
Validation loss: 1.5619341686207762

Epoch: 6| Step: 12
Training loss: 0.1766003966331482
Validation loss: 1.563132878272764

Epoch: 6| Step: 13
Training loss: 0.3869312107563019
Validation loss: 1.5115421420784407

Epoch: 398| Step: 0
Training loss: 0.3052661120891571
Validation loss: 1.5168217228304954

Epoch: 6| Step: 1
Training loss: 0.18103010952472687
Validation loss: 1.51860450801029

Epoch: 6| Step: 2
Training loss: 0.1495024561882019
Validation loss: 1.5619593256263322

Epoch: 6| Step: 3
Training loss: 0.15890255570411682
Validation loss: 1.5623850271265993

Epoch: 6| Step: 4
Training loss: 0.14888864755630493
Validation loss: 1.6091733196730256

Epoch: 6| Step: 5
Training loss: 0.206880122423172
Validation loss: 1.606413556683448

Epoch: 6| Step: 6
Training loss: 0.1927500069141388
Validation loss: 1.600152023376957

Epoch: 6| Step: 7
Training loss: 0.22590437531471252
Validation loss: 1.6541648475072717

Epoch: 6| Step: 8
Training loss: 0.12904900312423706
Validation loss: 1.598078473921745

Epoch: 6| Step: 9
Training loss: 0.11906842142343521
Validation loss: 1.603171471626528

Epoch: 6| Step: 10
Training loss: 0.08287199586629868
Validation loss: 1.5892457680035663

Epoch: 6| Step: 11
Training loss: 0.11651147156953812
Validation loss: 1.5892304592235114

Epoch: 6| Step: 12
Training loss: 0.1111043393611908
Validation loss: 1.5850128576319704

Epoch: 6| Step: 13
Training loss: 0.1004830151796341
Validation loss: 1.5741684962344427

Epoch: 399| Step: 0
Training loss: 0.12268664687871933
Validation loss: 1.547961292728301

Epoch: 6| Step: 1
Training loss: 0.14385320246219635
Validation loss: 1.5373851445413405

Epoch: 6| Step: 2
Training loss: 0.0856231078505516
Validation loss: 1.550522235132033

Epoch: 6| Step: 3
Training loss: 0.0895746722817421
Validation loss: 1.5595423265170025

Epoch: 6| Step: 4
Training loss: 0.17597703635692596
Validation loss: 1.5636839700001541

Epoch: 6| Step: 5
Training loss: 0.11834131181240082
Validation loss: 1.5807097265797276

Epoch: 6| Step: 6
Training loss: 0.19032081961631775
Validation loss: 1.5722761705357542

Epoch: 6| Step: 7
Training loss: 0.13431531190872192
Validation loss: 1.562872613629987

Epoch: 6| Step: 8
Training loss: 0.15961076319217682
Validation loss: 1.5334667659574939

Epoch: 6| Step: 9
Training loss: 0.3406873941421509
Validation loss: 1.572323283841533

Epoch: 6| Step: 10
Training loss: 0.1200694590806961
Validation loss: 1.554421027501424

Epoch: 6| Step: 11
Training loss: 0.09554290771484375
Validation loss: 1.5987657244487474

Epoch: 6| Step: 12
Training loss: 0.10000103712081909
Validation loss: 1.5438344273515927

Epoch: 6| Step: 13
Training loss: 0.1807297319173813
Validation loss: 1.5800021284370012

Epoch: 400| Step: 0
Training loss: 0.1583680808544159
Validation loss: 1.5878595780300837

Epoch: 6| Step: 1
Training loss: 0.1190306544303894
Validation loss: 1.5719668237111901

Epoch: 6| Step: 2
Training loss: 0.09548550844192505
Validation loss: 1.529041374242434

Epoch: 6| Step: 3
Training loss: 0.16704697906970978
Validation loss: 1.5737651304532123

Epoch: 6| Step: 4
Training loss: 0.11209934949874878
Validation loss: 1.5040334129846225

Epoch: 6| Step: 5
Training loss: 0.21295465528964996
Validation loss: 1.5142170075447328

Epoch: 6| Step: 6
Training loss: 0.19578668475151062
Validation loss: 1.4951138643808262

Epoch: 6| Step: 7
Training loss: 0.17937488853931427
Validation loss: 1.5175406996921827

Epoch: 6| Step: 8
Training loss: 0.15520304441452026
Validation loss: 1.5074537120839602

Epoch: 6| Step: 9
Training loss: 0.111507847905159
Validation loss: 1.5199160639957716

Epoch: 6| Step: 10
Training loss: 0.2162391096353531
Validation loss: 1.5233967252956924

Epoch: 6| Step: 11
Training loss: 0.5418691635131836
Validation loss: 1.521423191152593

Epoch: 6| Step: 12
Training loss: 0.10860896110534668
Validation loss: 1.5467840445938932

Epoch: 6| Step: 13
Training loss: 0.12876269221305847
Validation loss: 1.53853658066001

Epoch: 401| Step: 0
Training loss: 0.11279932409524918
Validation loss: 1.5882494167615009

Epoch: 6| Step: 1
Training loss: 0.3060241937637329
Validation loss: 1.5872963237506088

Epoch: 6| Step: 2
Training loss: 0.11409690231084824
Validation loss: 1.6137394405180407

Epoch: 6| Step: 3
Training loss: 0.2324250191450119
Validation loss: 1.63856969212973

Epoch: 6| Step: 4
Training loss: 0.20660486817359924
Validation loss: 1.6275594567739835

Epoch: 6| Step: 5
Training loss: 0.13243705034255981
Validation loss: 1.6172120942864368

Epoch: 6| Step: 6
Training loss: 0.14548180997371674
Validation loss: 1.5658156660295302

Epoch: 6| Step: 7
Training loss: 0.10164757072925568
Validation loss: 1.550038452430438

Epoch: 6| Step: 8
Training loss: 0.14855782687664032
Validation loss: 1.5563871411867038

Epoch: 6| Step: 9
Training loss: 0.21013858914375305
Validation loss: 1.538118561108907

Epoch: 6| Step: 10
Training loss: 0.17287196218967438
Validation loss: 1.505571719138853

Epoch: 6| Step: 11
Training loss: 0.17691873013973236
Validation loss: 1.4807825216683008

Epoch: 6| Step: 12
Training loss: 0.10572262108325958
Validation loss: 1.5244333077502508

Epoch: 6| Step: 13
Training loss: 0.1112033948302269
Validation loss: 1.5040710574837142

Epoch: 402| Step: 0
Training loss: 0.11791479587554932
Validation loss: 1.5332549169499388

Epoch: 6| Step: 1
Training loss: 0.12696053087711334
Validation loss: 1.5600498748081986

Epoch: 6| Step: 2
Training loss: 0.17704343795776367
Validation loss: 1.540788661408168

Epoch: 6| Step: 3
Training loss: 0.1394633650779724
Validation loss: 1.5432657913495136

Epoch: 6| Step: 4
Training loss: 0.090672567486763
Validation loss: 1.5641483145375406

Epoch: 6| Step: 5
Training loss: 0.13744644820690155
Validation loss: 1.5587164227680494

Epoch: 6| Step: 6
Training loss: 0.1828620731830597
Validation loss: 1.5927181641260784

Epoch: 6| Step: 7
Training loss: 0.12510964274406433
Validation loss: 1.600302396282073

Epoch: 6| Step: 8
Training loss: 0.17471641302108765
Validation loss: 1.5837320884068806

Epoch: 6| Step: 9
Training loss: 0.1995437741279602
Validation loss: 1.5765621264775593

Epoch: 6| Step: 10
Training loss: 0.18746766448020935
Validation loss: 1.6013850473588513

Epoch: 6| Step: 11
Training loss: 0.25975310802459717
Validation loss: 1.6113158118340276

Epoch: 6| Step: 12
Training loss: 0.22341501712799072
Validation loss: 1.6194890673442552

Epoch: 6| Step: 13
Training loss: 0.16294622421264648
Validation loss: 1.6179185836545882

Epoch: 403| Step: 0
Training loss: 0.2287181317806244
Validation loss: 1.6311142290792158

Epoch: 6| Step: 1
Training loss: 0.1100674644112587
Validation loss: 1.644008631347328

Epoch: 6| Step: 2
Training loss: 0.14368274807929993
Validation loss: 1.635542679858464

Epoch: 6| Step: 3
Training loss: 0.205382838845253
Validation loss: 1.6249257646581179

Epoch: 6| Step: 4
Training loss: 0.3084867000579834
Validation loss: 1.5677677444232407

Epoch: 6| Step: 5
Training loss: 0.13624131679534912
Validation loss: 1.589334318714757

Epoch: 6| Step: 6
Training loss: 0.20050275325775146
Validation loss: 1.5383235946778329

Epoch: 6| Step: 7
Training loss: 0.1071862205862999
Validation loss: 1.5398611509671776

Epoch: 6| Step: 8
Training loss: 0.08184538036584854
Validation loss: 1.5313403132141277

Epoch: 6| Step: 9
Training loss: 0.1781039834022522
Validation loss: 1.5114339564436226

Epoch: 6| Step: 10
Training loss: 0.24475447833538055
Validation loss: 1.5280194282531738

Epoch: 6| Step: 11
Training loss: 0.11820998787879944
Validation loss: 1.5477364165808565

Epoch: 6| Step: 12
Training loss: 0.13514462113380432
Validation loss: 1.5571333105846117

Epoch: 6| Step: 13
Training loss: 0.11799350380897522
Validation loss: 1.5429962758095033

Epoch: 404| Step: 0
Training loss: 0.11053194105625153
Validation loss: 1.5581133583540558

Epoch: 6| Step: 1
Training loss: 0.11770136654376984
Validation loss: 1.5476873625991165

Epoch: 6| Step: 2
Training loss: 0.1349104344844818
Validation loss: 1.5432938157871205

Epoch: 6| Step: 3
Training loss: 0.2818562388420105
Validation loss: 1.538360588012203

Epoch: 6| Step: 4
Training loss: 0.0814594030380249
Validation loss: 1.567350874664963

Epoch: 6| Step: 5
Training loss: 0.08414242416620255
Validation loss: 1.531940229477421

Epoch: 6| Step: 6
Training loss: 0.186759814620018
Validation loss: 1.5648357643876025

Epoch: 6| Step: 7
Training loss: 0.13851675391197205
Validation loss: 1.5673705236886137

Epoch: 6| Step: 8
Training loss: 0.22446756064891815
Validation loss: 1.5661827107911468

Epoch: 6| Step: 9
Training loss: 0.13881225883960724
Validation loss: 1.5565941949044504

Epoch: 6| Step: 10
Training loss: 0.10511874407529831
Validation loss: 1.5723426624010968

Epoch: 6| Step: 11
Training loss: 0.17449666559696198
Validation loss: 1.5416381820555656

Epoch: 6| Step: 12
Training loss: 0.10926151275634766
Validation loss: 1.5343967381344046

Epoch: 6| Step: 13
Training loss: 0.09546003490686417
Validation loss: 1.5404519060606598

Epoch: 405| Step: 0
Training loss: 0.1483045518398285
Validation loss: 1.564750370158944

Epoch: 6| Step: 1
Training loss: 0.12512651085853577
Validation loss: 1.5607017740126579

Epoch: 6| Step: 2
Training loss: 0.16451308131217957
Validation loss: 1.5243119860208163

Epoch: 6| Step: 3
Training loss: 0.11011980473995209
Validation loss: 1.5572340232069775

Epoch: 6| Step: 4
Training loss: 0.11066059023141861
Validation loss: 1.5383312432996687

Epoch: 6| Step: 5
Training loss: 0.2643396854400635
Validation loss: 1.5341441913317608

Epoch: 6| Step: 6
Training loss: 0.1290675401687622
Validation loss: 1.5606327095339376

Epoch: 6| Step: 7
Training loss: 0.16644877195358276
Validation loss: 1.5250368105467929

Epoch: 6| Step: 8
Training loss: 0.08635968714952469
Validation loss: 1.5330767913531231

Epoch: 6| Step: 9
Training loss: 0.1676236093044281
Validation loss: 1.526931320467303

Epoch: 6| Step: 10
Training loss: 0.14823023974895477
Validation loss: 1.560018233073655

Epoch: 6| Step: 11
Training loss: 0.21615958213806152
Validation loss: 1.5558579506412629

Epoch: 6| Step: 12
Training loss: 0.12012738734483719
Validation loss: 1.567614419485933

Epoch: 6| Step: 13
Training loss: 0.21359889209270477
Validation loss: 1.6043065196724349

Epoch: 406| Step: 0
Training loss: 0.23175212740898132
Validation loss: 1.5885369277769519

Epoch: 6| Step: 1
Training loss: 0.08732850104570389
Validation loss: 1.564382492855031

Epoch: 6| Step: 2
Training loss: 0.19114243984222412
Validation loss: 1.591166380913027

Epoch: 6| Step: 3
Training loss: 0.1213112622499466
Validation loss: 1.5745086093102731

Epoch: 6| Step: 4
Training loss: 0.12620699405670166
Validation loss: 1.5866609491327757

Epoch: 6| Step: 5
Training loss: 0.09861595183610916
Validation loss: 1.5714056607215636

Epoch: 6| Step: 6
Training loss: 0.1505577266216278
Validation loss: 1.5761405524387155

Epoch: 6| Step: 7
Training loss: 0.3482031524181366
Validation loss: 1.5994653060872068

Epoch: 6| Step: 8
Training loss: 0.19991548359394073
Validation loss: 1.5764939669639833

Epoch: 6| Step: 9
Training loss: 0.1244734525680542
Validation loss: 1.5994922845594344

Epoch: 6| Step: 10
Training loss: 0.23740079998970032
Validation loss: 1.6040419558043122

Epoch: 6| Step: 11
Training loss: 0.17140725255012512
Validation loss: 1.574162511415379

Epoch: 6| Step: 12
Training loss: 0.10027673095464706
Validation loss: 1.5833685923648138

Epoch: 6| Step: 13
Training loss: 0.15385222434997559
Validation loss: 1.5821862374582598

Epoch: 407| Step: 0
Training loss: 0.13522692024707794
Validation loss: 1.5820434298566592

Epoch: 6| Step: 1
Training loss: 0.16129985451698303
Validation loss: 1.602722825542573

Epoch: 6| Step: 2
Training loss: 0.11601623892784119
Validation loss: 1.6111756435004614

Epoch: 6| Step: 3
Training loss: 0.10095196217298508
Validation loss: 1.58338624623514

Epoch: 6| Step: 4
Training loss: 0.09526601433753967
Validation loss: 1.5616990648290163

Epoch: 6| Step: 5
Training loss: 0.22095322608947754
Validation loss: 1.5726464448436615

Epoch: 6| Step: 6
Training loss: 0.10767514258623123
Validation loss: 1.5850474026895338

Epoch: 6| Step: 7
Training loss: 0.17033538222312927
Validation loss: 1.61218124563976

Epoch: 6| Step: 8
Training loss: 0.1797555685043335
Validation loss: 1.6098110022083405

Epoch: 6| Step: 9
Training loss: 0.21207940578460693
Validation loss: 1.5970842697287118

Epoch: 6| Step: 10
Training loss: 0.24709492921829224
Validation loss: 1.591694026864985

Epoch: 6| Step: 11
Training loss: 0.16856956481933594
Validation loss: 1.6136399353704145

Epoch: 6| Step: 12
Training loss: 0.14199323952198029
Validation loss: 1.623858489016051

Epoch: 6| Step: 13
Training loss: 0.2608422636985779
Validation loss: 1.6123920281728108

Epoch: 408| Step: 0
Training loss: 0.20723441243171692
Validation loss: 1.6014037414263653

Epoch: 6| Step: 1
Training loss: 0.09790267050266266
Validation loss: 1.5612523286573348

Epoch: 6| Step: 2
Training loss: 0.13000431656837463
Validation loss: 1.5230493789078088

Epoch: 6| Step: 3
Training loss: 0.1354449987411499
Validation loss: 1.5442482950866863

Epoch: 6| Step: 4
Training loss: 0.18327046930789948
Validation loss: 1.5406279012721071

Epoch: 6| Step: 5
Training loss: 0.0987856313586235
Validation loss: 1.501802316275976

Epoch: 6| Step: 6
Training loss: 0.1405329406261444
Validation loss: 1.5275810098135343

Epoch: 6| Step: 7
Training loss: 0.15866005420684814
Validation loss: 1.526231800356219

Epoch: 6| Step: 8
Training loss: 0.2657262682914734
Validation loss: 1.5349217012364378

Epoch: 6| Step: 9
Training loss: 0.08280102163553238
Validation loss: 1.523866412460163

Epoch: 6| Step: 10
Training loss: 0.23681369423866272
Validation loss: 1.5569050504315285

Epoch: 6| Step: 11
Training loss: 0.09962163865566254
Validation loss: 1.5565513000693372

Epoch: 6| Step: 12
Training loss: 0.12657369673252106
Validation loss: 1.5389398118501068

Epoch: 6| Step: 13
Training loss: 0.18378646671772003
Validation loss: 1.5508427184115174

Epoch: 409| Step: 0
Training loss: 0.26775798201560974
Validation loss: 1.5563065582706082

Epoch: 6| Step: 1
Training loss: 0.11332664638757706
Validation loss: 1.5618679933650519

Epoch: 6| Step: 2
Training loss: 0.08217085152864456
Validation loss: 1.5516605249015234

Epoch: 6| Step: 3
Training loss: 0.10449597239494324
Validation loss: 1.5250848608632241

Epoch: 6| Step: 4
Training loss: 0.08065444231033325
Validation loss: 1.5356617755787347

Epoch: 6| Step: 5
Training loss: 0.09899839758872986
Validation loss: 1.5324534626417263

Epoch: 6| Step: 6
Training loss: 0.09521119296550751
Validation loss: 1.5223116541421542

Epoch: 6| Step: 7
Training loss: 0.1083020269870758
Validation loss: 1.5138420866381737

Epoch: 6| Step: 8
Training loss: 0.14820590615272522
Validation loss: 1.5707950463858984

Epoch: 6| Step: 9
Training loss: 0.10117300599813461
Validation loss: 1.5181400070908249

Epoch: 6| Step: 10
Training loss: 0.10329295694828033
Validation loss: 1.543499287738595

Epoch: 6| Step: 11
Training loss: 0.15929818153381348
Validation loss: 1.5888985510795348

Epoch: 6| Step: 12
Training loss: 0.1461847573518753
Validation loss: 1.5565982044384044

Epoch: 6| Step: 13
Training loss: 0.09892082214355469
Validation loss: 1.5645074280359412

Epoch: 410| Step: 0
Training loss: 0.12143091857433319
Validation loss: 1.5574551500299925

Epoch: 6| Step: 1
Training loss: 0.09273234754800797
Validation loss: 1.5538399680968253

Epoch: 6| Step: 2
Training loss: 0.10138402879238129
Validation loss: 1.5385555080188218

Epoch: 6| Step: 3
Training loss: 0.36323779821395874
Validation loss: 1.5242322452606694

Epoch: 6| Step: 4
Training loss: 0.19159755110740662
Validation loss: 1.5232069594885713

Epoch: 6| Step: 5
Training loss: 0.12156039476394653
Validation loss: 1.544288880081587

Epoch: 6| Step: 6
Training loss: 0.06359052658081055
Validation loss: 1.5550083101436656

Epoch: 6| Step: 7
Training loss: 0.11808834224939346
Validation loss: 1.547225126656153

Epoch: 6| Step: 8
Training loss: 0.07189880311489105
Validation loss: 1.5169006957802722

Epoch: 6| Step: 9
Training loss: 0.10930030047893524
Validation loss: 1.5222050425826863

Epoch: 6| Step: 10
Training loss: 0.06521548330783844
Validation loss: 1.5598001492920743

Epoch: 6| Step: 11
Training loss: 0.07162536680698395
Validation loss: 1.522326405330371

Epoch: 6| Step: 12
Training loss: 0.09773172438144684
Validation loss: 1.5213128982051727

Epoch: 6| Step: 13
Training loss: 0.06939186900854111
Validation loss: 1.5333396145092544

Epoch: 411| Step: 0
Training loss: 0.09649083018302917
Validation loss: 1.5525862939896122

Epoch: 6| Step: 1
Training loss: 0.07731279730796814
Validation loss: 1.5474796730984923

Epoch: 6| Step: 2
Training loss: 0.09002017974853516
Validation loss: 1.5340341688484274

Epoch: 6| Step: 3
Training loss: 0.19631318747997284
Validation loss: 1.527720638500747

Epoch: 6| Step: 4
Training loss: 0.12876443564891815
Validation loss: 1.502698653487749

Epoch: 6| Step: 5
Training loss: 0.15040536224842072
Validation loss: 1.5517160713031728

Epoch: 6| Step: 6
Training loss: 0.13436651229858398
Validation loss: 1.5112012611922396

Epoch: 6| Step: 7
Training loss: 0.10200289636850357
Validation loss: 1.5433418250853015

Epoch: 6| Step: 8
Training loss: 0.11630673706531525
Validation loss: 1.5597552240535777

Epoch: 6| Step: 9
Training loss: 0.13338471949100494
Validation loss: 1.5695145783885833

Epoch: 6| Step: 10
Training loss: 0.13354900479316711
Validation loss: 1.5770080115205498

Epoch: 6| Step: 11
Training loss: 0.1113208457827568
Validation loss: 1.5801005273736932

Epoch: 6| Step: 12
Training loss: 0.2792895436286926
Validation loss: 1.5803461318374963

Epoch: 6| Step: 13
Training loss: 0.16295205056667328
Validation loss: 1.5695237331492926

Epoch: 412| Step: 0
Training loss: 0.1572001427412033
Validation loss: 1.58107590675354

Epoch: 6| Step: 1
Training loss: 0.14217333495616913
Validation loss: 1.569436925713734

Epoch: 6| Step: 2
Training loss: 0.13254894316196442
Validation loss: 1.5717382315666444

Epoch: 6| Step: 3
Training loss: 0.1552284061908722
Validation loss: 1.5669161004404868

Epoch: 6| Step: 4
Training loss: 0.19707685708999634
Validation loss: 1.5470288004926456

Epoch: 6| Step: 5
Training loss: 0.12542863190174103
Validation loss: 1.5526932131859563

Epoch: 6| Step: 6
Training loss: 0.2399064004421234
Validation loss: 1.558702822654478

Epoch: 6| Step: 7
Training loss: 0.139510840177536
Validation loss: 1.5866464645631853

Epoch: 6| Step: 8
Training loss: 0.11802772432565689
Validation loss: 1.5569919495172397

Epoch: 6| Step: 9
Training loss: 0.13203033804893494
Validation loss: 1.5774667250212802

Epoch: 6| Step: 10
Training loss: 0.10958822071552277
Validation loss: 1.5622147385792067

Epoch: 6| Step: 11
Training loss: 0.11600430309772491
Validation loss: 1.5464321387711393

Epoch: 6| Step: 12
Training loss: 0.1548699289560318
Validation loss: 1.5701503599843671

Epoch: 6| Step: 13
Training loss: 0.11792466044425964
Validation loss: 1.591937190742903

Epoch: 413| Step: 0
Training loss: 0.17197167873382568
Validation loss: 1.578215499078074

Epoch: 6| Step: 1
Training loss: 0.13396495580673218
Validation loss: 1.5538030644898773

Epoch: 6| Step: 2
Training loss: 0.12206588685512543
Validation loss: 1.5509191315661195

Epoch: 6| Step: 3
Training loss: 0.25922003388404846
Validation loss: 1.5611620872251448

Epoch: 6| Step: 4
Training loss: 0.09722024947404861
Validation loss: 1.547347963497203

Epoch: 6| Step: 5
Training loss: 0.126890629529953
Validation loss: 1.5329884181740463

Epoch: 6| Step: 6
Training loss: 0.22121722996234894
Validation loss: 1.5494430218973467

Epoch: 6| Step: 7
Training loss: 0.12848471105098724
Validation loss: 1.5414391768875944

Epoch: 6| Step: 8
Training loss: 0.13995391130447388
Validation loss: 1.5763180717345207

Epoch: 6| Step: 9
Training loss: 0.1289052665233612
Validation loss: 1.5694919196508264

Epoch: 6| Step: 10
Training loss: 0.13402336835861206
Validation loss: 1.5367952815947994

Epoch: 6| Step: 11
Training loss: 0.09414122253656387
Validation loss: 1.5481694206114738

Epoch: 6| Step: 12
Training loss: 0.1819751262664795
Validation loss: 1.521699211930716

Epoch: 6| Step: 13
Training loss: 0.10821739584207535
Validation loss: 1.4980356308721727

Epoch: 414| Step: 0
Training loss: 0.09639868140220642
Validation loss: 1.5236349451926448

Epoch: 6| Step: 1
Training loss: 0.13227719068527222
Validation loss: 1.533859282411555

Epoch: 6| Step: 2
Training loss: 0.12179360538721085
Validation loss: 1.5194530704970002

Epoch: 6| Step: 3
Training loss: 0.08633147180080414
Validation loss: 1.5355807632528327

Epoch: 6| Step: 4
Training loss: 0.17640084028244019
Validation loss: 1.5310315342359646

Epoch: 6| Step: 5
Training loss: 0.08624926954507828
Validation loss: 1.5138668655067362

Epoch: 6| Step: 6
Training loss: 0.11807337403297424
Validation loss: 1.5024806248244418

Epoch: 6| Step: 7
Training loss: 0.12322172522544861
Validation loss: 1.5172949132098947

Epoch: 6| Step: 8
Training loss: 0.21538206934928894
Validation loss: 1.522615675003298

Epoch: 6| Step: 9
Training loss: 0.17282910645008087
Validation loss: 1.5236817688070319

Epoch: 6| Step: 10
Training loss: 0.11904135346412659
Validation loss: 1.5143218130193732

Epoch: 6| Step: 11
Training loss: 0.27501314878463745
Validation loss: 1.5565215246651762

Epoch: 6| Step: 12
Training loss: 0.09217879921197891
Validation loss: 1.5724350662641629

Epoch: 6| Step: 13
Training loss: 0.07375870645046234
Validation loss: 1.5657478494028891

Epoch: 415| Step: 0
Training loss: 0.14062809944152832
Validation loss: 1.57908675747533

Epoch: 6| Step: 1
Training loss: 0.0989680141210556
Validation loss: 1.5567941319557927

Epoch: 6| Step: 2
Training loss: 0.14184822142124176
Validation loss: 1.565690202097739

Epoch: 6| Step: 3
Training loss: 0.1335992068052292
Validation loss: 1.564347832433639

Epoch: 6| Step: 4
Training loss: 0.12262940406799316
Validation loss: 1.5615031578207528

Epoch: 6| Step: 5
Training loss: 0.2624049782752991
Validation loss: 1.5554544874416885

Epoch: 6| Step: 6
Training loss: 0.11267849802970886
Validation loss: 1.5517369470288676

Epoch: 6| Step: 7
Training loss: 0.1904277801513672
Validation loss: 1.5489783466503184

Epoch: 6| Step: 8
Training loss: 0.12520043551921844
Validation loss: 1.5663290780077699

Epoch: 6| Step: 9
Training loss: 0.07307608425617218
Validation loss: 1.594903678022405

Epoch: 6| Step: 10
Training loss: 0.12929299473762512
Validation loss: 1.5821891036084903

Epoch: 6| Step: 11
Training loss: 0.22708216309547424
Validation loss: 1.5606337862630044

Epoch: 6| Step: 12
Training loss: 0.1021755263209343
Validation loss: 1.5839059557966007

Epoch: 6| Step: 13
Training loss: 0.15778309106826782
Validation loss: 1.6079438553061536

Epoch: 416| Step: 0
Training loss: 0.0982871949672699
Validation loss: 1.6040678396019885

Epoch: 6| Step: 1
Training loss: 0.12612946331501007
Validation loss: 1.5700948007645146

Epoch: 6| Step: 2
Training loss: 0.07800553739070892
Validation loss: 1.537635591722304

Epoch: 6| Step: 3
Training loss: 0.09629649668931961
Validation loss: 1.541314724952944

Epoch: 6| Step: 4
Training loss: 0.09888716787099838
Validation loss: 1.5229024822993944

Epoch: 6| Step: 5
Training loss: 0.17198070883750916
Validation loss: 1.5210740861072336

Epoch: 6| Step: 6
Training loss: 0.1255590319633484
Validation loss: 1.535124356387764

Epoch: 6| Step: 7
Training loss: 0.2449890822172165
Validation loss: 1.5521997187727241

Epoch: 6| Step: 8
Training loss: 0.14721351861953735
Validation loss: 1.5529730037976337

Epoch: 6| Step: 9
Training loss: 0.16188620030879974
Validation loss: 1.604843480612642

Epoch: 6| Step: 10
Training loss: 0.16902270913124084
Validation loss: 1.5967720849539644

Epoch: 6| Step: 11
Training loss: 0.16861990094184875
Validation loss: 1.6035263525542391

Epoch: 6| Step: 12
Training loss: 0.11742796003818512
Validation loss: 1.5690888204882223

Epoch: 6| Step: 13
Training loss: 0.12647254765033722
Validation loss: 1.5947002499334273

Epoch: 417| Step: 0
Training loss: 0.124238982796669
Validation loss: 1.5684166723682034

Epoch: 6| Step: 1
Training loss: 0.12220484763383865
Validation loss: 1.5610760873363865

Epoch: 6| Step: 2
Training loss: 0.11367582529783249
Validation loss: 1.5592763955875109

Epoch: 6| Step: 3
Training loss: 0.2648751139640808
Validation loss: 1.576558812972038

Epoch: 6| Step: 4
Training loss: 0.19782069325447083
Validation loss: 1.542128155308385

Epoch: 6| Step: 5
Training loss: 0.16948117315769196
Validation loss: 1.5804144054330804

Epoch: 6| Step: 6
Training loss: 0.22032243013381958
Validation loss: 1.5432112268222276

Epoch: 6| Step: 7
Training loss: 0.09184971451759338
Validation loss: 1.5577395936494232

Epoch: 6| Step: 8
Training loss: 0.14032545685768127
Validation loss: 1.528532729353956

Epoch: 6| Step: 9
Training loss: 0.059061579406261444
Validation loss: 1.55800215659603

Epoch: 6| Step: 10
Training loss: 0.07585275918245316
Validation loss: 1.575645128885905

Epoch: 6| Step: 11
Training loss: 0.11592762172222137
Validation loss: 1.596411540944089

Epoch: 6| Step: 12
Training loss: 0.1141689121723175
Validation loss: 1.5961618461916525

Epoch: 6| Step: 13
Training loss: 0.10737114399671555
Validation loss: 1.6105770154665875

Epoch: 418| Step: 0
Training loss: 0.3279445469379425
Validation loss: 1.6369424000863106

Epoch: 6| Step: 1
Training loss: 0.22715747356414795
Validation loss: 1.608873886446799

Epoch: 6| Step: 2
Training loss: 0.15237823128700256
Validation loss: 1.5780507582490162

Epoch: 6| Step: 3
Training loss: 0.13830050826072693
Validation loss: 1.579438881207538

Epoch: 6| Step: 4
Training loss: 0.1311766356229782
Validation loss: 1.562136148893705

Epoch: 6| Step: 5
Training loss: 0.09882307052612305
Validation loss: 1.5684199371645529

Epoch: 6| Step: 6
Training loss: 0.12126941233873367
Validation loss: 1.540603861693413

Epoch: 6| Step: 7
Training loss: 0.09675872325897217
Validation loss: 1.5318066432911863

Epoch: 6| Step: 8
Training loss: 0.13892990350723267
Validation loss: 1.5647534990823397

Epoch: 6| Step: 9
Training loss: 0.09094339609146118
Validation loss: 1.5424079907837736

Epoch: 6| Step: 10
Training loss: 0.10417614132165909
Validation loss: 1.5229860403204476

Epoch: 6| Step: 11
Training loss: 0.12496273219585419
Validation loss: 1.5354429432140884

Epoch: 6| Step: 12
Training loss: 0.12652939558029175
Validation loss: 1.5181418875212311

Epoch: 6| Step: 13
Training loss: 0.09220009297132492
Validation loss: 1.5428456888403943

Epoch: 419| Step: 0
Training loss: 0.10120229423046112
Validation loss: 1.5214772685881583

Epoch: 6| Step: 1
Training loss: 0.13179408013820648
Validation loss: 1.570043662542938

Epoch: 6| Step: 2
Training loss: 0.1473056524991989
Validation loss: 1.5818668898715769

Epoch: 6| Step: 3
Training loss: 0.16319355368614197
Validation loss: 1.582593043645223

Epoch: 6| Step: 4
Training loss: 0.16331395506858826
Validation loss: 1.608589522300228

Epoch: 6| Step: 5
Training loss: 0.10888384282588959
Validation loss: 1.605142189610389

Epoch: 6| Step: 6
Training loss: 0.2603498697280884
Validation loss: 1.5822041560244817

Epoch: 6| Step: 7
Training loss: 0.16709494590759277
Validation loss: 1.5951520499362741

Epoch: 6| Step: 8
Training loss: 0.1059943288564682
Validation loss: 1.5717667418141519

Epoch: 6| Step: 9
Training loss: 0.0849699079990387
Validation loss: 1.5544856209908762

Epoch: 6| Step: 10
Training loss: 0.06959368288516998
Validation loss: 1.5385925487805439

Epoch: 6| Step: 11
Training loss: 0.14422792196273804
Validation loss: 1.5116431584922216

Epoch: 6| Step: 12
Training loss: 0.11315785348415375
Validation loss: 1.5092456622790265

Epoch: 6| Step: 13
Training loss: 0.19712680578231812
Validation loss: 1.5312446753184001

Epoch: 420| Step: 0
Training loss: 0.17508094012737274
Validation loss: 1.5255994155842771

Epoch: 6| Step: 1
Training loss: 0.13124415278434753
Validation loss: 1.529689988782329

Epoch: 6| Step: 2
Training loss: 0.14531506597995758
Validation loss: 1.5126193851552985

Epoch: 6| Step: 3
Training loss: 0.2553289532661438
Validation loss: 1.5065389499869397

Epoch: 6| Step: 4
Training loss: 0.14756610989570618
Validation loss: 1.537496861591134

Epoch: 6| Step: 5
Training loss: 0.12577809393405914
Validation loss: 1.5589084791880783

Epoch: 6| Step: 6
Training loss: 0.12118078023195267
Validation loss: 1.5740478871971049

Epoch: 6| Step: 7
Training loss: 0.08322640508413315
Validation loss: 1.5956861690808368

Epoch: 6| Step: 8
Training loss: 0.14226257801055908
Validation loss: 1.5855664066089097

Epoch: 6| Step: 9
Training loss: 0.12843981385231018
Validation loss: 1.5885983077428674

Epoch: 6| Step: 10
Training loss: 0.14293432235717773
Validation loss: 1.5986577041687504

Epoch: 6| Step: 11
Training loss: 0.18863719701766968
Validation loss: 1.584422182011348

Epoch: 6| Step: 12
Training loss: 0.0749330073595047
Validation loss: 1.566892699528766

Epoch: 6| Step: 13
Training loss: 0.06185854971408844
Validation loss: 1.576693110568549

Epoch: 421| Step: 0
Training loss: 0.13845370709896088
Validation loss: 1.586825119551792

Epoch: 6| Step: 1
Training loss: 0.15797844529151917
Validation loss: 1.576955069777786

Epoch: 6| Step: 2
Training loss: 0.10576551407575607
Validation loss: 1.5562909444173176

Epoch: 6| Step: 3
Training loss: 0.10245566815137863
Validation loss: 1.562486429368296

Epoch: 6| Step: 4
Training loss: 0.1596049815416336
Validation loss: 1.5410246541423183

Epoch: 6| Step: 5
Training loss: 0.15054288506507874
Validation loss: 1.5537443750648088

Epoch: 6| Step: 6
Training loss: 0.09349150210618973
Validation loss: 1.5476519266764324

Epoch: 6| Step: 7
Training loss: 0.13307660818099976
Validation loss: 1.539883376449667

Epoch: 6| Step: 8
Training loss: 0.12305481731891632
Validation loss: 1.5556305134168236

Epoch: 6| Step: 9
Training loss: 0.14530402421951294
Validation loss: 1.541734057088052

Epoch: 6| Step: 10
Training loss: 0.10426768660545349
Validation loss: 1.5850770204297957

Epoch: 6| Step: 11
Training loss: 0.11642158031463623
Validation loss: 1.576899500303371

Epoch: 6| Step: 12
Training loss: 0.1338597685098648
Validation loss: 1.583027345518912

Epoch: 6| Step: 13
Training loss: 0.32864129543304443
Validation loss: 1.5861553094720329

Epoch: 422| Step: 0
Training loss: 0.16463017463684082
Validation loss: 1.5910478638064476

Epoch: 6| Step: 1
Training loss: 0.11314907670021057
Validation loss: 1.578407500379829

Epoch: 6| Step: 2
Training loss: 0.19614079594612122
Validation loss: 1.5626980566209363

Epoch: 6| Step: 3
Training loss: 0.1973772644996643
Validation loss: 1.5686277240835211

Epoch: 6| Step: 4
Training loss: 0.06637070327997208
Validation loss: 1.5596499660963654

Epoch: 6| Step: 5
Training loss: 0.16406530141830444
Validation loss: 1.5360160527690765

Epoch: 6| Step: 6
Training loss: 0.07616031169891357
Validation loss: 1.5591492857984317

Epoch: 6| Step: 7
Training loss: 0.15759992599487305
Validation loss: 1.5219601655519137

Epoch: 6| Step: 8
Training loss: 0.152701735496521
Validation loss: 1.5635579644992788

Epoch: 6| Step: 9
Training loss: 0.09400369226932526
Validation loss: 1.5456714809581797

Epoch: 6| Step: 10
Training loss: 0.11212682723999023
Validation loss: 1.5336437821388245

Epoch: 6| Step: 11
Training loss: 0.10273110866546631
Validation loss: 1.5122702634462746

Epoch: 6| Step: 12
Training loss: 0.32115408778190613
Validation loss: 1.5090531328673005

Epoch: 6| Step: 13
Training loss: 0.0981636568903923
Validation loss: 1.4974120342603294

Epoch: 423| Step: 0
Training loss: 0.1288001984357834
Validation loss: 1.5244814785577918

Epoch: 6| Step: 1
Training loss: 0.11281844973564148
Validation loss: 1.5310407479604085

Epoch: 6| Step: 2
Training loss: 0.08553140610456467
Validation loss: 1.5290370166942637

Epoch: 6| Step: 3
Training loss: 0.10718169063329697
Validation loss: 1.5436057826524139

Epoch: 6| Step: 4
Training loss: 0.08716540038585663
Validation loss: 1.560471850056802

Epoch: 6| Step: 5
Training loss: 0.14644673466682434
Validation loss: 1.580070468687242

Epoch: 6| Step: 6
Training loss: 0.15790650248527527
Validation loss: 1.55974071128394

Epoch: 6| Step: 7
Training loss: 0.3260405361652374
Validation loss: 1.6038579351158553

Epoch: 6| Step: 8
Training loss: 0.10717912018299103
Validation loss: 1.5773444508993497

Epoch: 6| Step: 9
Training loss: 0.20132482051849365
Validation loss: 1.5405684196820824

Epoch: 6| Step: 10
Training loss: 0.0868094339966774
Validation loss: 1.510686767998562

Epoch: 6| Step: 11
Training loss: 0.1556241810321808
Validation loss: 1.5291452292473084

Epoch: 6| Step: 12
Training loss: 0.19346173107624054
Validation loss: 1.4988316964077693

Epoch: 6| Step: 13
Training loss: 0.12269815057516098
Validation loss: 1.4896710409272103

Epoch: 424| Step: 0
Training loss: 0.1876487135887146
Validation loss: 1.471858419397826

Epoch: 6| Step: 1
Training loss: 0.1310638189315796
Validation loss: 1.4829904443474227

Epoch: 6| Step: 2
Training loss: 0.1201375350356102
Validation loss: 1.4974202558558474

Epoch: 6| Step: 3
Training loss: 0.15648537874221802
Validation loss: 1.5099578826658187

Epoch: 6| Step: 4
Training loss: 0.17688550055027008
Validation loss: 1.5156263587295369

Epoch: 6| Step: 5
Training loss: 0.2549244463443756
Validation loss: 1.537586219849125

Epoch: 6| Step: 6
Training loss: 0.0820358395576477
Validation loss: 1.5669634675466886

Epoch: 6| Step: 7
Training loss: 0.16144752502441406
Validation loss: 1.5949691854497439

Epoch: 6| Step: 8
Training loss: 0.2117561399936676
Validation loss: 1.5961918843689786

Epoch: 6| Step: 9
Training loss: 0.25683310627937317
Validation loss: 1.606697178656055

Epoch: 6| Step: 10
Training loss: 0.10994639992713928
Validation loss: 1.6053662300109863

Epoch: 6| Step: 11
Training loss: 0.22597572207450867
Validation loss: 1.5526328471399122

Epoch: 6| Step: 12
Training loss: 0.183282732963562
Validation loss: 1.5581947885533816

Epoch: 6| Step: 13
Training loss: 0.1281285583972931
Validation loss: 1.5211446900521555

Epoch: 425| Step: 0
Training loss: 0.18637090921401978
Validation loss: 1.476921155888547

Epoch: 6| Step: 1
Training loss: 0.36029309034347534
Validation loss: 1.5039056347262474

Epoch: 6| Step: 2
Training loss: 0.09556236118078232
Validation loss: 1.519630438538008

Epoch: 6| Step: 3
Training loss: 0.16450276970863342
Validation loss: 1.5307966419445571

Epoch: 6| Step: 4
Training loss: 0.230972021818161
Validation loss: 1.5714596394569642

Epoch: 6| Step: 5
Training loss: 0.34084776043891907
Validation loss: 1.5893765059850549

Epoch: 6| Step: 6
Training loss: 0.36876121163368225
Validation loss: 1.6061734973743398

Epoch: 6| Step: 7
Training loss: 0.3316946029663086
Validation loss: 1.6133049918759255

Epoch: 6| Step: 8
Training loss: 0.13958847522735596
Validation loss: 1.5839419134201542

Epoch: 6| Step: 9
Training loss: 0.16507205367088318
Validation loss: 1.5583004361839705

Epoch: 6| Step: 10
Training loss: 0.11802633106708527
Validation loss: 1.566390005491113

Epoch: 6| Step: 11
Training loss: 0.1422961950302124
Validation loss: 1.609600454248408

Epoch: 6| Step: 12
Training loss: 0.2366371750831604
Validation loss: 1.677251196676685

Epoch: 6| Step: 13
Training loss: 0.22069069743156433
Validation loss: 1.6497614114515242

Epoch: 426| Step: 0
Training loss: 0.2675268054008484
Validation loss: 1.6658576098821496

Epoch: 6| Step: 1
Training loss: 0.29368776082992554
Validation loss: 1.6742574707154305

Epoch: 6| Step: 2
Training loss: 0.17739328742027283
Validation loss: 1.6238388810106503

Epoch: 6| Step: 3
Training loss: 0.16804546117782593
Validation loss: 1.6331267267145135

Epoch: 6| Step: 4
Training loss: 0.1516273319721222
Validation loss: 1.580902579651084

Epoch: 6| Step: 5
Training loss: 0.16374734044075012
Validation loss: 1.5805189494163758

Epoch: 6| Step: 6
Training loss: 0.21651922166347504
Validation loss: 1.5618256727854412

Epoch: 6| Step: 7
Training loss: 0.2708515226840973
Validation loss: 1.5731578975595453

Epoch: 6| Step: 8
Training loss: 0.19608396291732788
Validation loss: 1.554690643023419

Epoch: 6| Step: 9
Training loss: 0.1169380396604538
Validation loss: 1.534940158167193

Epoch: 6| Step: 10
Training loss: 0.16215917468070984
Validation loss: 1.5332061007458677

Epoch: 6| Step: 11
Training loss: 0.15786167979240417
Validation loss: 1.5352351255314325

Epoch: 6| Step: 12
Training loss: 0.26055392622947693
Validation loss: 1.5066869835699759

Epoch: 6| Step: 13
Training loss: 0.21469146013259888
Validation loss: 1.509101725393726

Epoch: 427| Step: 0
Training loss: 0.13659074902534485
Validation loss: 1.4866184162837204

Epoch: 6| Step: 1
Training loss: 0.3187052011489868
Validation loss: 1.483948499925675

Epoch: 6| Step: 2
Training loss: 0.10047318041324615
Validation loss: 1.5214433605952928

Epoch: 6| Step: 3
Training loss: 0.23494547605514526
Validation loss: 1.5917718487401162

Epoch: 6| Step: 4
Training loss: 0.13975735008716583
Validation loss: 1.578733108376944

Epoch: 6| Step: 5
Training loss: 0.23102304339408875
Validation loss: 1.6107908935957058

Epoch: 6| Step: 6
Training loss: 0.15222837030887604
Validation loss: 1.599898761318576

Epoch: 6| Step: 7
Training loss: 0.19429311156272888
Validation loss: 1.595029087476833

Epoch: 6| Step: 8
Training loss: 0.14829260110855103
Validation loss: 1.5699033083454255

Epoch: 6| Step: 9
Training loss: 0.12433722615242004
Validation loss: 1.553805100020542

Epoch: 6| Step: 10
Training loss: 0.19776812195777893
Validation loss: 1.5414285531608007

Epoch: 6| Step: 11
Training loss: 0.17498335242271423
Validation loss: 1.4965643767387635

Epoch: 6| Step: 12
Training loss: 0.13986444473266602
Validation loss: 1.4836167532910582

Epoch: 6| Step: 13
Training loss: 0.32926204800605774
Validation loss: 1.4535783375463178

Epoch: 428| Step: 0
Training loss: 0.1774720698595047
Validation loss: 1.4637881126455081

Epoch: 6| Step: 1
Training loss: 0.15928775072097778
Validation loss: 1.4691824002932476

Epoch: 6| Step: 2
Training loss: 0.14602628350257874
Validation loss: 1.5013031664715017

Epoch: 6| Step: 3
Training loss: 0.11681323498487473
Validation loss: 1.4767818489382345

Epoch: 6| Step: 4
Training loss: 0.1689024716615677
Validation loss: 1.4979360988063197

Epoch: 6| Step: 5
Training loss: 0.15076640248298645
Validation loss: 1.5068271826672297

Epoch: 6| Step: 6
Training loss: 0.1693461537361145
Validation loss: 1.5136299312755626

Epoch: 6| Step: 7
Training loss: 0.13984951376914978
Validation loss: 1.507758390518927

Epoch: 6| Step: 8
Training loss: 0.2759847342967987
Validation loss: 1.5093395620264032

Epoch: 6| Step: 9
Training loss: 0.17134536802768707
Validation loss: 1.5317119500970329

Epoch: 6| Step: 10
Training loss: 0.10932812094688416
Validation loss: 1.5269867117686937

Epoch: 6| Step: 11
Training loss: 0.14058269560337067
Validation loss: 1.5291624351214337

Epoch: 6| Step: 12
Training loss: 0.12502743303775787
Validation loss: 1.5365876895125195

Epoch: 6| Step: 13
Training loss: 0.09541390836238861
Validation loss: 1.5190502443621237

Epoch: 429| Step: 0
Training loss: 0.09264999628067017
Validation loss: 1.5115048539253972

Epoch: 6| Step: 1
Training loss: 0.22449424862861633
Validation loss: 1.5556617603507092

Epoch: 6| Step: 2
Training loss: 0.15219531953334808
Validation loss: 1.5524981867882512

Epoch: 6| Step: 3
Training loss: 0.09517337381839752
Validation loss: 1.5256585728737615

Epoch: 6| Step: 4
Training loss: 0.0899713933467865
Validation loss: 1.5143237306225685

Epoch: 6| Step: 5
Training loss: 0.16049206256866455
Validation loss: 1.5271421824732134

Epoch: 6| Step: 6
Training loss: 0.10349185764789581
Validation loss: 1.5310886649675266

Epoch: 6| Step: 7
Training loss: 0.14088426530361176
Validation loss: 1.526823273269079

Epoch: 6| Step: 8
Training loss: 0.17713794112205505
Validation loss: 1.5423380354399323

Epoch: 6| Step: 9
Training loss: 0.22545155882835388
Validation loss: 1.5428572335550863

Epoch: 6| Step: 10
Training loss: 0.1250424087047577
Validation loss: 1.531165740823233

Epoch: 6| Step: 11
Training loss: 0.08880689740180969
Validation loss: 1.5459729920151413

Epoch: 6| Step: 12
Training loss: 0.2722708582878113
Validation loss: 1.5495385636565506

Epoch: 6| Step: 13
Training loss: 0.1843123435974121
Validation loss: 1.5515854294582079

Epoch: 430| Step: 0
Training loss: 0.14415791630744934
Validation loss: 1.5256238765614007

Epoch: 6| Step: 1
Training loss: 0.12744739651679993
Validation loss: 1.5594099131963586

Epoch: 6| Step: 2
Training loss: 0.13847379386425018
Validation loss: 1.5804296590948617

Epoch: 6| Step: 3
Training loss: 0.2210613638162613
Validation loss: 1.563398918797893

Epoch: 6| Step: 4
Training loss: 0.14029370248317719
Validation loss: 1.5639032702292166

Epoch: 6| Step: 5
Training loss: 0.12611329555511475
Validation loss: 1.5963052344578568

Epoch: 6| Step: 6
Training loss: 0.14517833292484283
Validation loss: 1.6202913048446819

Epoch: 6| Step: 7
Training loss: 0.1367093324661255
Validation loss: 1.6008702939556492

Epoch: 6| Step: 8
Training loss: 0.1551627218723297
Validation loss: 1.5907324808900074

Epoch: 6| Step: 9
Training loss: 0.09392799437046051
Validation loss: 1.5645149395030031

Epoch: 6| Step: 10
Training loss: 0.16882804036140442
Validation loss: 1.5759741388341433

Epoch: 6| Step: 11
Training loss: 0.16934451460838318
Validation loss: 1.5638033702809324

Epoch: 6| Step: 12
Training loss: 0.1328955888748169
Validation loss: 1.563699476180538

Epoch: 6| Step: 13
Training loss: 0.16342292726039886
Validation loss: 1.5521956015658636

Epoch: 431| Step: 0
Training loss: 0.11545663326978683
Validation loss: 1.5692729667950702

Epoch: 6| Step: 1
Training loss: 0.16260254383087158
Validation loss: 1.5412149134502615

Epoch: 6| Step: 2
Training loss: 0.07071381062269211
Validation loss: 1.5721950505369453

Epoch: 6| Step: 3
Training loss: 0.12297162413597107
Validation loss: 1.540085397740846

Epoch: 6| Step: 4
Training loss: 0.18323586881160736
Validation loss: 1.573519237579838

Epoch: 6| Step: 5
Training loss: 0.10623831301927567
Validation loss: 1.5751763210501721

Epoch: 6| Step: 6
Training loss: 0.15193676948547363
Validation loss: 1.579852229805403

Epoch: 6| Step: 7
Training loss: 0.27928802371025085
Validation loss: 1.5969061825865059

Epoch: 6| Step: 8
Training loss: 0.09331710636615753
Validation loss: 1.576523365512971

Epoch: 6| Step: 9
Training loss: 0.09950611740350723
Validation loss: 1.5909905356745566

Epoch: 6| Step: 10
Training loss: 0.16166846454143524
Validation loss: 1.5786687353605866

Epoch: 6| Step: 11
Training loss: 0.1715894192457199
Validation loss: 1.5689503813302645

Epoch: 6| Step: 12
Training loss: 0.10377750545740128
Validation loss: 1.5226056357865692

Epoch: 6| Step: 13
Training loss: 0.12711651623249054
Validation loss: 1.509336539494094

Epoch: 432| Step: 0
Training loss: 0.16866713762283325
Validation loss: 1.52874739708439

Epoch: 6| Step: 1
Training loss: 0.14222365617752075
Validation loss: 1.5258006152286325

Epoch: 6| Step: 2
Training loss: 0.11902718991041183
Validation loss: 1.512824757124788

Epoch: 6| Step: 3
Training loss: 0.11926939338445663
Validation loss: 1.5280763756844304

Epoch: 6| Step: 4
Training loss: 0.15698078274726868
Validation loss: 1.528203138741114

Epoch: 6| Step: 5
Training loss: 0.0977213978767395
Validation loss: 1.5253920670478576

Epoch: 6| Step: 6
Training loss: 0.10736851394176483
Validation loss: 1.5087036214849001

Epoch: 6| Step: 7
Training loss: 0.09768548607826233
Validation loss: 1.5252064902295348

Epoch: 6| Step: 8
Training loss: 0.11508316546678543
Validation loss: 1.541626226517462

Epoch: 6| Step: 9
Training loss: 0.12486356496810913
Validation loss: 1.5145282822270547

Epoch: 6| Step: 10
Training loss: 0.127173513174057
Validation loss: 1.5096830552624119

Epoch: 6| Step: 11
Training loss: 0.27477213740348816
Validation loss: 1.5157566275647891

Epoch: 6| Step: 12
Training loss: 0.11329369992017746
Validation loss: 1.5276151395613147

Epoch: 6| Step: 13
Training loss: 0.17772060632705688
Validation loss: 1.5347143398818148

Epoch: 433| Step: 0
Training loss: 0.06499261409044266
Validation loss: 1.5292493399753366

Epoch: 6| Step: 1
Training loss: 0.1660068780183792
Validation loss: 1.5449530116973385

Epoch: 6| Step: 2
Training loss: 0.13509759306907654
Validation loss: 1.5408026774724324

Epoch: 6| Step: 3
Training loss: 0.22204941511154175
Validation loss: 1.5163555363173127

Epoch: 6| Step: 4
Training loss: 0.16694779694080353
Validation loss: 1.5377765509390062

Epoch: 6| Step: 5
Training loss: 0.11674753576517105
Validation loss: 1.527687875173425

Epoch: 6| Step: 6
Training loss: 0.18725931644439697
Validation loss: 1.5285358608409922

Epoch: 6| Step: 7
Training loss: 0.11133374273777008
Validation loss: 1.517754784194372

Epoch: 6| Step: 8
Training loss: 0.20582136511802673
Validation loss: 1.5360613510172854

Epoch: 6| Step: 9
Training loss: 0.1215772032737732
Validation loss: 1.5152526222249514

Epoch: 6| Step: 10
Training loss: 0.07810777425765991
Validation loss: 1.4792611791241554

Epoch: 6| Step: 11
Training loss: 0.08266599476337433
Validation loss: 1.4902056147975307

Epoch: 6| Step: 12
Training loss: 0.1495201289653778
Validation loss: 1.498406376889957

Epoch: 6| Step: 13
Training loss: 0.15822158753871918
Validation loss: 1.5030191534308976

Epoch: 434| Step: 0
Training loss: 0.24145600199699402
Validation loss: 1.4827436170270365

Epoch: 6| Step: 1
Training loss: 0.17109471559524536
Validation loss: 1.5288408597310383

Epoch: 6| Step: 2
Training loss: 0.07968595623970032
Validation loss: 1.5084000966882194

Epoch: 6| Step: 3
Training loss: 0.1365906298160553
Validation loss: 1.507065026990829

Epoch: 6| Step: 4
Training loss: 0.14355812966823578
Validation loss: 1.5245724563957543

Epoch: 6| Step: 5
Training loss: 0.14817176759243011
Validation loss: 1.5184582946121052

Epoch: 6| Step: 6
Training loss: 0.11500129103660583
Validation loss: 1.5048449308641496

Epoch: 6| Step: 7
Training loss: 0.07846896350383759
Validation loss: 1.4881359249032953

Epoch: 6| Step: 8
Training loss: 0.08087150007486343
Validation loss: 1.5223204051294634

Epoch: 6| Step: 9
Training loss: 0.18387176096439362
Validation loss: 1.4792988287505282

Epoch: 6| Step: 10
Training loss: 0.13711562752723694
Validation loss: 1.4661253729174215

Epoch: 6| Step: 11
Training loss: 0.11302259564399719
Validation loss: 1.4642570634042062

Epoch: 6| Step: 12
Training loss: 0.10070616006851196
Validation loss: 1.493196552799594

Epoch: 6| Step: 13
Training loss: 0.08648781478404999
Validation loss: 1.4938373668219453

Epoch: 435| Step: 0
Training loss: 0.12961170077323914
Validation loss: 1.554210623105367

Epoch: 6| Step: 1
Training loss: 0.10763974487781525
Validation loss: 1.5636324126233336

Epoch: 6| Step: 2
Training loss: 0.11995207518339157
Validation loss: 1.5640503821834442

Epoch: 6| Step: 3
Training loss: 0.2997913360595703
Validation loss: 1.5449363877696376

Epoch: 6| Step: 4
Training loss: 0.16081276535987854
Validation loss: 1.5120785543995519

Epoch: 6| Step: 5
Training loss: 0.09313696622848511
Validation loss: 1.5278568267822266

Epoch: 6| Step: 6
Training loss: 0.11396583914756775
Validation loss: 1.4923303088834208

Epoch: 6| Step: 7
Training loss: 0.06285443902015686
Validation loss: 1.4927225459006526

Epoch: 6| Step: 8
Training loss: 0.12286445498466492
Validation loss: 1.5002438355517644

Epoch: 6| Step: 9
Training loss: 0.105171337723732
Validation loss: 1.4785957503062424

Epoch: 6| Step: 10
Training loss: 0.12799295783042908
Validation loss: 1.4948964029230096

Epoch: 6| Step: 11
Training loss: 0.21070049703121185
Validation loss: 1.4917998583086076

Epoch: 6| Step: 12
Training loss: 0.15870606899261475
Validation loss: 1.5041421741567633

Epoch: 6| Step: 13
Training loss: 0.1258525252342224
Validation loss: 1.5033156871795654

Epoch: 436| Step: 0
Training loss: 0.1443120688199997
Validation loss: 1.5354935046165221

Epoch: 6| Step: 1
Training loss: 0.11807423084974289
Validation loss: 1.5567308433594242

Epoch: 6| Step: 2
Training loss: 0.1068582683801651
Validation loss: 1.5322067801670363

Epoch: 6| Step: 3
Training loss: 0.15044835209846497
Validation loss: 1.5657475725297005

Epoch: 6| Step: 4
Training loss: 0.11285503208637238
Validation loss: 1.5723173361952587

Epoch: 6| Step: 5
Training loss: 0.12904486060142517
Validation loss: 1.5801644427801973

Epoch: 6| Step: 6
Training loss: 0.15286104381084442
Validation loss: 1.5863201438739736

Epoch: 6| Step: 7
Training loss: 0.15907622873783112
Validation loss: 1.556456140292588

Epoch: 6| Step: 8
Training loss: 0.11708127707242966
Validation loss: 1.5323287825430594

Epoch: 6| Step: 9
Training loss: 0.11679074913263321
Validation loss: 1.5076930817737375

Epoch: 6| Step: 10
Training loss: 0.08512617647647858
Validation loss: 1.4941269633590535

Epoch: 6| Step: 11
Training loss: 0.15529030561447144
Validation loss: 1.4814660523527412

Epoch: 6| Step: 12
Training loss: 0.12811672687530518
Validation loss: 1.5048430581246652

Epoch: 6| Step: 13
Training loss: 0.3995254337787628
Validation loss: 1.5150605952867897

Epoch: 437| Step: 0
Training loss: 0.19944007694721222
Validation loss: 1.5141368207111154

Epoch: 6| Step: 1
Training loss: 0.13587793707847595
Validation loss: 1.5238348207166117

Epoch: 6| Step: 2
Training loss: 0.14166903495788574
Validation loss: 1.5417627173085366

Epoch: 6| Step: 3
Training loss: 0.25368738174438477
Validation loss: 1.5728681074675692

Epoch: 6| Step: 4
Training loss: 0.08578762412071228
Validation loss: 1.5793244684896162

Epoch: 6| Step: 5
Training loss: 0.1026930958032608
Validation loss: 1.6129649710911576

Epoch: 6| Step: 6
Training loss: 0.18564896285533905
Validation loss: 1.6109616525711552

Epoch: 6| Step: 7
Training loss: 0.1886730194091797
Validation loss: 1.5791262824048278

Epoch: 6| Step: 8
Training loss: 0.10658024251461029
Validation loss: 1.5412071622828

Epoch: 6| Step: 9
Training loss: 0.1184723973274231
Validation loss: 1.5389616797047276

Epoch: 6| Step: 10
Training loss: 0.12452176213264465
Validation loss: 1.5340953911504438

Epoch: 6| Step: 11
Training loss: 0.15354517102241516
Validation loss: 1.52703575036859

Epoch: 6| Step: 12
Training loss: 0.11631591618061066
Validation loss: 1.481997379692652

Epoch: 6| Step: 13
Training loss: 0.08883783221244812
Validation loss: 1.5163277079982143

Epoch: 438| Step: 0
Training loss: 0.09661297500133514
Validation loss: 1.5288563454022972

Epoch: 6| Step: 1
Training loss: 0.12632045149803162
Validation loss: 1.4908239251823836

Epoch: 6| Step: 2
Training loss: 0.3364432454109192
Validation loss: 1.512853491690851

Epoch: 6| Step: 3
Training loss: 0.12098110467195511
Validation loss: 1.488342067246796

Epoch: 6| Step: 4
Training loss: 0.1090359091758728
Validation loss: 1.5206652379805041

Epoch: 6| Step: 5
Training loss: 0.10933586955070496
Validation loss: 1.5586004628930041

Epoch: 6| Step: 6
Training loss: 0.10887500643730164
Validation loss: 1.592979875943994

Epoch: 6| Step: 7
Training loss: 0.17342105507850647
Validation loss: 1.5915173176796205

Epoch: 6| Step: 8
Training loss: 0.1631055772304535
Validation loss: 1.6178979950566446

Epoch: 6| Step: 9
Training loss: 0.260135293006897
Validation loss: 1.635805171023133

Epoch: 6| Step: 10
Training loss: 0.22831541299819946
Validation loss: 1.6041830803758355

Epoch: 6| Step: 11
Training loss: 0.17319177091121674
Validation loss: 1.579418736119424

Epoch: 6| Step: 12
Training loss: 0.14503347873687744
Validation loss: 1.5624443638709284

Epoch: 6| Step: 13
Training loss: 0.24145767092704773
Validation loss: 1.5490210607487669

Epoch: 439| Step: 0
Training loss: 0.20408380031585693
Validation loss: 1.5442865394776868

Epoch: 6| Step: 1
Training loss: 0.12463483214378357
Validation loss: 1.5521322040147678

Epoch: 6| Step: 2
Training loss: 0.11379137635231018
Validation loss: 1.525483036553988

Epoch: 6| Step: 3
Training loss: 0.11532289534807205
Validation loss: 1.5154827410174954

Epoch: 6| Step: 4
Training loss: 0.12211862951517105
Validation loss: 1.5194276443091772

Epoch: 6| Step: 5
Training loss: 0.11390827596187592
Validation loss: 1.5406796278492096

Epoch: 6| Step: 6
Training loss: 0.10198074579238892
Validation loss: 1.5297249824770036

Epoch: 6| Step: 7
Training loss: 0.15710708498954773
Validation loss: 1.5616295952950754

Epoch: 6| Step: 8
Training loss: 0.21774032711982727
Validation loss: 1.5340538281266407

Epoch: 6| Step: 9
Training loss: 0.08403898030519485
Validation loss: 1.5171900756897465

Epoch: 6| Step: 10
Training loss: 0.12407619506120682
Validation loss: 1.4937070197956537

Epoch: 6| Step: 11
Training loss: 0.10717914253473282
Validation loss: 1.5436533830499137

Epoch: 6| Step: 12
Training loss: 0.11478941142559052
Validation loss: 1.5103750305791055

Epoch: 6| Step: 13
Training loss: 0.05360465869307518
Validation loss: 1.5627928946607856

Epoch: 440| Step: 0
Training loss: 0.1760435402393341
Validation loss: 1.5684832052517963

Epoch: 6| Step: 1
Training loss: 0.19098125398159027
Validation loss: 1.5296690899838683

Epoch: 6| Step: 2
Training loss: 0.0764027014374733
Validation loss: 1.52455993365216

Epoch: 6| Step: 3
Training loss: 0.09633666276931763
Validation loss: 1.5259174403323923

Epoch: 6| Step: 4
Training loss: 0.0943620577454567
Validation loss: 1.5469399780355475

Epoch: 6| Step: 5
Training loss: 0.1160450354218483
Validation loss: 1.5266047895595591

Epoch: 6| Step: 6
Training loss: 0.09010766446590424
Validation loss: 1.54900509888126

Epoch: 6| Step: 7
Training loss: 0.13312408328056335
Validation loss: 1.5523516554986276

Epoch: 6| Step: 8
Training loss: 0.04994707182049751
Validation loss: 1.5279243492311048

Epoch: 6| Step: 9
Training loss: 0.15126869082450867
Validation loss: 1.5464147765149352

Epoch: 6| Step: 10
Training loss: 0.16880999505519867
Validation loss: 1.538863948596421

Epoch: 6| Step: 11
Training loss: 0.1131402999162674
Validation loss: 1.506572901561696

Epoch: 6| Step: 12
Training loss: 0.12812986969947815
Validation loss: 1.543574648518716

Epoch: 6| Step: 13
Training loss: 0.08744236081838608
Validation loss: 1.5105228424072266

Epoch: 441| Step: 0
Training loss: 0.1235395297408104
Validation loss: 1.5268431581476682

Epoch: 6| Step: 1
Training loss: 0.15932996571063995
Validation loss: 1.5001764528213009

Epoch: 6| Step: 2
Training loss: 0.1609443724155426
Validation loss: 1.5125633490982877

Epoch: 6| Step: 3
Training loss: 0.13977089524269104
Validation loss: 1.5092417604179793

Epoch: 6| Step: 4
Training loss: 0.07817213237285614
Validation loss: 1.5266255255668395

Epoch: 6| Step: 5
Training loss: 0.13907285034656525
Validation loss: 1.497974459842969

Epoch: 6| Step: 6
Training loss: 0.14777788519859314
Validation loss: 1.504070903665276

Epoch: 6| Step: 7
Training loss: 0.10757745802402496
Validation loss: 1.5322617215494956

Epoch: 6| Step: 8
Training loss: 0.14102846384048462
Validation loss: 1.5077349716617214

Epoch: 6| Step: 9
Training loss: 0.2470748871564865
Validation loss: 1.5880085627237956

Epoch: 6| Step: 10
Training loss: 0.17375987768173218
Validation loss: 1.5968760072544057

Epoch: 6| Step: 11
Training loss: 0.06479386240243912
Validation loss: 1.5335776902014209

Epoch: 6| Step: 12
Training loss: 0.09819944947957993
Validation loss: 1.542086426929761

Epoch: 6| Step: 13
Training loss: 0.12168644368648529
Validation loss: 1.5415648414242653

Epoch: 442| Step: 0
Training loss: 0.1316966414451599
Validation loss: 1.5604508294854114

Epoch: 6| Step: 1
Training loss: 0.1339540034532547
Validation loss: 1.5319417292071926

Epoch: 6| Step: 2
Training loss: 0.1460806131362915
Validation loss: 1.5133793405307236

Epoch: 6| Step: 3
Training loss: 0.15508611500263214
Validation loss: 1.5204996537136775

Epoch: 6| Step: 4
Training loss: 0.10752250999212265
Validation loss: 1.5206387671091224

Epoch: 6| Step: 5
Training loss: 0.2854836583137512
Validation loss: 1.5479595302253641

Epoch: 6| Step: 6
Training loss: 0.13872823119163513
Validation loss: 1.5311380535043695

Epoch: 6| Step: 7
Training loss: 0.15580670535564423
Validation loss: 1.5204924998744842

Epoch: 6| Step: 8
Training loss: 0.1844654679298401
Validation loss: 1.5362981416845833

Epoch: 6| Step: 9
Training loss: 0.16137351095676422
Validation loss: 1.5610788355591476

Epoch: 6| Step: 10
Training loss: 0.22775253653526306
Validation loss: 1.5833976512314172

Epoch: 6| Step: 11
Training loss: 0.12088761478662491
Validation loss: 1.5312439498081003

Epoch: 6| Step: 12
Training loss: 0.09103021025657654
Validation loss: 1.5108523458562872

Epoch: 6| Step: 13
Training loss: 0.08844473212957382
Validation loss: 1.4620156403510802

Epoch: 443| Step: 0
Training loss: 0.1151333749294281
Validation loss: 1.4559941086717831

Epoch: 6| Step: 1
Training loss: 0.14384609460830688
Validation loss: 1.48152107192624

Epoch: 6| Step: 2
Training loss: 0.15345361828804016
Validation loss: 1.4920306333931543

Epoch: 6| Step: 3
Training loss: 0.18955668807029724
Validation loss: 1.4764669044043428

Epoch: 6| Step: 4
Training loss: 0.2116551399230957
Validation loss: 1.4754054809129367

Epoch: 6| Step: 5
Training loss: 0.22557099163532257
Validation loss: 1.5043176233127553

Epoch: 6| Step: 6
Training loss: 0.14661981165409088
Validation loss: 1.479244710296713

Epoch: 6| Step: 7
Training loss: 0.20775264501571655
Validation loss: 1.4774272903319328

Epoch: 6| Step: 8
Training loss: 0.12281443178653717
Validation loss: 1.5018672673932967

Epoch: 6| Step: 9
Training loss: 0.10677044093608856
Validation loss: 1.5426282100780035

Epoch: 6| Step: 10
Training loss: 0.1772814393043518
Validation loss: 1.555914782708691

Epoch: 6| Step: 11
Training loss: 0.2478857934474945
Validation loss: 1.600016822097122

Epoch: 6| Step: 12
Training loss: 0.10305608063936234
Validation loss: 1.599788636289617

Epoch: 6| Step: 13
Training loss: 0.15179003775119781
Validation loss: 1.5856823293111657

Epoch: 444| Step: 0
Training loss: 0.2239503413438797
Validation loss: 1.5777491369555074

Epoch: 6| Step: 1
Training loss: 0.24239897727966309
Validation loss: 1.5577826589666388

Epoch: 6| Step: 2
Training loss: 0.0972667708992958
Validation loss: 1.4958246049060617

Epoch: 6| Step: 3
Training loss: 0.18698152899742126
Validation loss: 1.4936387038999988

Epoch: 6| Step: 4
Training loss: 0.22172990441322327
Validation loss: 1.5039324786073418

Epoch: 6| Step: 5
Training loss: 0.243498757481575
Validation loss: 1.5199324546321746

Epoch: 6| Step: 6
Training loss: 0.2771090269088745
Validation loss: 1.504461569170798

Epoch: 6| Step: 7
Training loss: 0.22277012467384338
Validation loss: 1.5141251292279971

Epoch: 6| Step: 8
Training loss: 0.12134091556072235
Validation loss: 1.4962793383547055

Epoch: 6| Step: 9
Training loss: 0.06071252003312111
Validation loss: 1.5030437156718264

Epoch: 6| Step: 10
Training loss: 0.14563652873039246
Validation loss: 1.5566711874418362

Epoch: 6| Step: 11
Training loss: 0.20333713293075562
Validation loss: 1.6048434344671105

Epoch: 6| Step: 12
Training loss: 0.10771816223859787
Validation loss: 1.6162543732632872

Epoch: 6| Step: 13
Training loss: 0.16671103239059448
Validation loss: 1.6026429642913163

Epoch: 445| Step: 0
Training loss: 0.09638801962137222
Validation loss: 1.582109312857351

Epoch: 6| Step: 1
Training loss: 0.2209562063217163
Validation loss: 1.6122278013537008

Epoch: 6| Step: 2
Training loss: 0.15494650602340698
Validation loss: 1.596276270445957

Epoch: 6| Step: 3
Training loss: 0.07006458938121796
Validation loss: 1.5719130680125246

Epoch: 6| Step: 4
Training loss: 0.1402466595172882
Validation loss: 1.5624592432411768

Epoch: 6| Step: 5
Training loss: 0.13878171145915985
Validation loss: 1.5492687148432578

Epoch: 6| Step: 6
Training loss: 0.11693968623876572
Validation loss: 1.4865527768288889

Epoch: 6| Step: 7
Training loss: 0.10519924014806747
Validation loss: 1.5005651468871741

Epoch: 6| Step: 8
Training loss: 0.291898250579834
Validation loss: 1.4948884889643679

Epoch: 6| Step: 9
Training loss: 0.15661552548408508
Validation loss: 1.4732771893983245

Epoch: 6| Step: 10
Training loss: 0.1480253040790558
Validation loss: 1.467463352346933

Epoch: 6| Step: 11
Training loss: 0.19166265428066254
Validation loss: 1.4863081497530783

Epoch: 6| Step: 12
Training loss: 0.10922569036483765
Validation loss: 1.49844939221618

Epoch: 6| Step: 13
Training loss: 0.09719742834568024
Validation loss: 1.5298333898667367

Epoch: 446| Step: 0
Training loss: 0.09905751049518585
Validation loss: 1.5671549509930354

Epoch: 6| Step: 1
Training loss: 0.21345233917236328
Validation loss: 1.575298547744751

Epoch: 6| Step: 2
Training loss: 0.20848208665847778
Validation loss: 1.5767540508700955

Epoch: 6| Step: 3
Training loss: 0.1592281460762024
Validation loss: 1.5752244816031507

Epoch: 6| Step: 4
Training loss: 0.135158509016037
Validation loss: 1.5212682498398649

Epoch: 6| Step: 5
Training loss: 0.2458157241344452
Validation loss: 1.4952386092114192

Epoch: 6| Step: 6
Training loss: 0.11290118843317032
Validation loss: 1.4911229354079052

Epoch: 6| Step: 7
Training loss: 0.1324637234210968
Validation loss: 1.4839814106623332

Epoch: 6| Step: 8
Training loss: 0.14062368869781494
Validation loss: 1.4905101445413405

Epoch: 6| Step: 9
Training loss: 0.1884823739528656
Validation loss: 1.5027005749364053

Epoch: 6| Step: 10
Training loss: 0.15601038932800293
Validation loss: 1.5289168139939666

Epoch: 6| Step: 11
Training loss: 0.19436928629875183
Validation loss: 1.528425407666032

Epoch: 6| Step: 12
Training loss: 0.11006464064121246
Validation loss: 1.5324457422379525

Epoch: 6| Step: 13
Training loss: 0.2636216878890991
Validation loss: 1.5219563796956053

Epoch: 447| Step: 0
Training loss: 0.1356060802936554
Validation loss: 1.5375683269193094

Epoch: 6| Step: 1
Training loss: 0.10478594899177551
Validation loss: 1.5554766257603962

Epoch: 6| Step: 2
Training loss: 0.22277724742889404
Validation loss: 1.5580736142332836

Epoch: 6| Step: 3
Training loss: 0.1563829779624939
Validation loss: 1.5725881912375008

Epoch: 6| Step: 4
Training loss: 0.08641308546066284
Validation loss: 1.5441687773632746

Epoch: 6| Step: 5
Training loss: 0.11450126767158508
Validation loss: 1.540709633981028

Epoch: 6| Step: 6
Training loss: 0.10561063140630722
Validation loss: 1.5328254045978669

Epoch: 6| Step: 7
Training loss: 0.11840203404426575
Validation loss: 1.5094419108924044

Epoch: 6| Step: 8
Training loss: 0.12242390215396881
Validation loss: 1.4914989022798435

Epoch: 6| Step: 9
Training loss: 0.1293688416481018
Validation loss: 1.4785575482153124

Epoch: 6| Step: 10
Training loss: 0.10626909881830215
Validation loss: 1.481578721795031

Epoch: 6| Step: 11
Training loss: 0.31442368030548096
Validation loss: 1.4916750641279324

Epoch: 6| Step: 12
Training loss: 0.15713462233543396
Validation loss: 1.4776112084747643

Epoch: 6| Step: 13
Training loss: 0.13700121641159058
Validation loss: 1.47931892512947

Epoch: 448| Step: 0
Training loss: 0.08491751551628113
Validation loss: 1.490257792575385

Epoch: 6| Step: 1
Training loss: 0.11800608038902283
Validation loss: 1.4880118985329904

Epoch: 6| Step: 2
Training loss: 0.12308323383331299
Validation loss: 1.5107030906984884

Epoch: 6| Step: 3
Training loss: 0.13069221377372742
Validation loss: 1.5436705863603981

Epoch: 6| Step: 4
Training loss: 0.14480294287204742
Validation loss: 1.5474225769760788

Epoch: 6| Step: 5
Training loss: 0.07578586041927338
Validation loss: 1.5473952139577558

Epoch: 6| Step: 6
Training loss: 0.1882687509059906
Validation loss: 1.5277315403825493

Epoch: 6| Step: 7
Training loss: 0.13869625329971313
Validation loss: 1.5514577845091462

Epoch: 6| Step: 8
Training loss: 0.09726150333881378
Validation loss: 1.5177086719902613

Epoch: 6| Step: 9
Training loss: 0.11257675290107727
Validation loss: 1.5072978203014662

Epoch: 6| Step: 10
Training loss: 0.06387690454721451
Validation loss: 1.5172581864941506

Epoch: 6| Step: 11
Training loss: 0.19009867310523987
Validation loss: 1.556451056593208

Epoch: 6| Step: 12
Training loss: 0.09791146218776703
Validation loss: 1.5585086935309953

Epoch: 6| Step: 13
Training loss: 0.1507563292980194
Validation loss: 1.5262443429680281

Epoch: 449| Step: 0
Training loss: 0.06161866337060928
Validation loss: 1.5609857484858523

Epoch: 6| Step: 1
Training loss: 0.17595084011554718
Validation loss: 1.5473758353981921

Epoch: 6| Step: 2
Training loss: 0.054684996604919434
Validation loss: 1.5216978711466635

Epoch: 6| Step: 3
Training loss: 0.08831892907619476
Validation loss: 1.508778945092232

Epoch: 6| Step: 4
Training loss: 0.11097581684589386
Validation loss: 1.5203062847096434

Epoch: 6| Step: 5
Training loss: 0.11404907703399658
Validation loss: 1.531002265150829

Epoch: 6| Step: 6
Training loss: 0.0735398381948471
Validation loss: 1.513881903822704

Epoch: 6| Step: 7
Training loss: 0.1326265037059784
Validation loss: 1.492762973231654

Epoch: 6| Step: 8
Training loss: 0.08429304510354996
Validation loss: 1.5409777036277197

Epoch: 6| Step: 9
Training loss: 0.1421748846769333
Validation loss: 1.5149191605147494

Epoch: 6| Step: 10
Training loss: 0.13548396527767181
Validation loss: 1.4983728983068978

Epoch: 6| Step: 11
Training loss: 0.09055370092391968
Validation loss: 1.5129991936427292

Epoch: 6| Step: 12
Training loss: 0.1604059636592865
Validation loss: 1.5366327621603524

Epoch: 6| Step: 13
Training loss: 0.2785145044326782
Validation loss: 1.4988986183238286

Epoch: 450| Step: 0
Training loss: 0.12073283642530441
Validation loss: 1.545558605142819

Epoch: 6| Step: 1
Training loss: 0.19343554973602295
Validation loss: 1.5430060778894732

Epoch: 6| Step: 2
Training loss: 0.15327441692352295
Validation loss: 1.5585230999095465

Epoch: 6| Step: 3
Training loss: 0.0989857092499733
Validation loss: 1.5380633518260012

Epoch: 6| Step: 4
Training loss: 0.0727769285440445
Validation loss: 1.5180606842041016

Epoch: 6| Step: 5
Training loss: 0.10568492114543915
Validation loss: 1.5180734626708492

Epoch: 6| Step: 6
Training loss: 0.10057425498962402
Validation loss: 1.4946129719416301

Epoch: 6| Step: 7
Training loss: 0.10189446061849594
Validation loss: 1.47951187369644

Epoch: 6| Step: 8
Training loss: 0.17606687545776367
Validation loss: 1.4802286573635635

Epoch: 6| Step: 9
Training loss: 0.1784665882587433
Validation loss: 1.4777035815741426

Epoch: 6| Step: 10
Training loss: 0.1401139199733734
Validation loss: 1.5009829626288465

Epoch: 6| Step: 11
Training loss: 0.14464041590690613
Validation loss: 1.4801600710038216

Epoch: 6| Step: 12
Training loss: 0.148187518119812
Validation loss: 1.4811325316788049

Epoch: 6| Step: 13
Training loss: 0.1690617948770523
Validation loss: 1.4962824365144134

Epoch: 451| Step: 0
Training loss: 0.1258840262889862
Validation loss: 1.5247227030415689

Epoch: 6| Step: 1
Training loss: 0.11977440118789673
Validation loss: 1.5155465840011515

Epoch: 6| Step: 2
Training loss: 0.2294975221157074
Validation loss: 1.5628849332050612

Epoch: 6| Step: 3
Training loss: 0.06581085920333862
Validation loss: 1.5219246802791473

Epoch: 6| Step: 4
Training loss: 0.09667059779167175
Validation loss: 1.5130192272124752

Epoch: 6| Step: 5
Training loss: 0.17082566022872925
Validation loss: 1.4987922560784124

Epoch: 6| Step: 6
Training loss: 0.10116305202245712
Validation loss: 1.5130160213798605

Epoch: 6| Step: 7
Training loss: 0.11836275458335876
Validation loss: 1.5414459871989425

Epoch: 6| Step: 8
Training loss: 0.14106027781963348
Validation loss: 1.5454570426735827

Epoch: 6| Step: 9
Training loss: 0.09816939383745193
Validation loss: 1.556772594810814

Epoch: 6| Step: 10
Training loss: 0.0959153100848198
Validation loss: 1.5708963191637428

Epoch: 6| Step: 11
Training loss: 0.1800367534160614
Validation loss: 1.5437856028156896

Epoch: 6| Step: 12
Training loss: 0.10822965204715729
Validation loss: 1.5502983357316704

Epoch: 6| Step: 13
Training loss: 0.09987251460552216
Validation loss: 1.5372907961568525

Epoch: 452| Step: 0
Training loss: 0.12570850551128387
Validation loss: 1.5139784095107869

Epoch: 6| Step: 1
Training loss: 0.08774514496326447
Validation loss: 1.4865423428115023

Epoch: 6| Step: 2
Training loss: 0.2127680480480194
Validation loss: 1.4990033270210348

Epoch: 6| Step: 3
Training loss: 0.10687808692455292
Validation loss: 1.4843119100857807

Epoch: 6| Step: 4
Training loss: 0.06956838816404343
Validation loss: 1.4792991479237874

Epoch: 6| Step: 5
Training loss: 0.08761550486087799
Validation loss: 1.4835122576964799

Epoch: 6| Step: 6
Training loss: 0.14302054047584534
Validation loss: 1.5142697211234801

Epoch: 6| Step: 7
Training loss: 0.1467561572790146
Validation loss: 1.4656517531282158

Epoch: 6| Step: 8
Training loss: 0.21227364242076874
Validation loss: 1.4922191455800047

Epoch: 6| Step: 9
Training loss: 0.10624434053897858
Validation loss: 1.5030516219395462

Epoch: 6| Step: 10
Training loss: 0.13455143570899963
Validation loss: 1.513940457374819

Epoch: 6| Step: 11
Training loss: 0.11921332776546478
Validation loss: 1.4869815021432855

Epoch: 6| Step: 12
Training loss: 0.11169489473104477
Validation loss: 1.501968232534265

Epoch: 6| Step: 13
Training loss: 0.10216199606657028
Validation loss: 1.4891043465624574

Epoch: 453| Step: 0
Training loss: 0.075070321559906
Validation loss: 1.5040418717168993

Epoch: 6| Step: 1
Training loss: 0.13816198706626892
Validation loss: 1.5223884210791638

Epoch: 6| Step: 2
Training loss: 0.14178334176540375
Validation loss: 1.5387632270013132

Epoch: 6| Step: 3
Training loss: 0.1651645302772522
Validation loss: 1.545042173836821

Epoch: 6| Step: 4
Training loss: 0.15609176456928253
Validation loss: 1.5325060916203324

Epoch: 6| Step: 5
Training loss: 0.19461575150489807
Validation loss: 1.5166281000260384

Epoch: 6| Step: 6
Training loss: 0.11489351093769073
Validation loss: 1.5033083295309415

Epoch: 6| Step: 7
Training loss: 0.12654051184654236
Validation loss: 1.4839513994032336

Epoch: 6| Step: 8
Training loss: 0.18428021669387817
Validation loss: 1.4824257896792503

Epoch: 6| Step: 9
Training loss: 0.11896749585866928
Validation loss: 1.5057683721665414

Epoch: 6| Step: 10
Training loss: 0.11733940988779068
Validation loss: 1.4628882587596934

Epoch: 6| Step: 11
Training loss: 0.07040640711784363
Validation loss: 1.4862969344662083

Epoch: 6| Step: 12
Training loss: 0.12016230076551437
Validation loss: 1.452999512354533

Epoch: 6| Step: 13
Training loss: 0.13506849110126495
Validation loss: 1.4823969961494528

Epoch: 454| Step: 0
Training loss: 0.2588839530944824
Validation loss: 1.4673285509950371

Epoch: 6| Step: 1
Training loss: 0.1417536586523056
Validation loss: 1.4914028952198644

Epoch: 6| Step: 2
Training loss: 0.16403445601463318
Validation loss: 1.4785612956170113

Epoch: 6| Step: 3
Training loss: 0.13567040860652924
Validation loss: 1.4927605211093862

Epoch: 6| Step: 4
Training loss: 0.13627539575099945
Validation loss: 1.5100688652325702

Epoch: 6| Step: 5
Training loss: 0.1308918595314026
Validation loss: 1.4749495162758777

Epoch: 6| Step: 6
Training loss: 0.11128757148981094
Validation loss: 1.4600884273488035

Epoch: 6| Step: 7
Training loss: 0.08288334310054779
Validation loss: 1.4729498547892417

Epoch: 6| Step: 8
Training loss: 0.06803242117166519
Validation loss: 1.4364207726652904

Epoch: 6| Step: 9
Training loss: 0.22068051993846893
Validation loss: 1.4749102272013181

Epoch: 6| Step: 10
Training loss: 0.10708755999803543
Validation loss: 1.446516288224087

Epoch: 6| Step: 11
Training loss: 0.07459201663732529
Validation loss: 1.4617061614990234

Epoch: 6| Step: 12
Training loss: 0.15134713053703308
Validation loss: 1.4782226393299718

Epoch: 6| Step: 13
Training loss: 0.08866915106773376
Validation loss: 1.4890710756342898

Epoch: 455| Step: 0
Training loss: 0.1351717859506607
Validation loss: 1.4884454896373134

Epoch: 6| Step: 1
Training loss: 0.12411706149578094
Validation loss: 1.4931850933259534

Epoch: 6| Step: 2
Training loss: 0.07528873533010483
Validation loss: 1.4963354679845995

Epoch: 6| Step: 3
Training loss: 0.14736807346343994
Validation loss: 1.518088266413699

Epoch: 6| Step: 4
Training loss: 0.04805224388837814
Validation loss: 1.493945119201496

Epoch: 6| Step: 5
Training loss: 0.14926332235336304
Validation loss: 1.5329502654331986

Epoch: 6| Step: 6
Training loss: 0.08802822977304459
Validation loss: 1.5074240379436041

Epoch: 6| Step: 7
Training loss: 0.1210709884762764
Validation loss: 1.492750274237766

Epoch: 6| Step: 8
Training loss: 0.11894626915454865
Validation loss: 1.5181596266326083

Epoch: 6| Step: 9
Training loss: 0.21678966283798218
Validation loss: 1.5298417409261067

Epoch: 6| Step: 10
Training loss: 0.1356460452079773
Validation loss: 1.5487562405165805

Epoch: 6| Step: 11
Training loss: 0.12808921933174133
Validation loss: 1.514983227176051

Epoch: 6| Step: 12
Training loss: 0.10384467244148254
Validation loss: 1.5101033449172974

Epoch: 6| Step: 13
Training loss: 0.11875417828559875
Validation loss: 1.4987984575251097

Epoch: 456| Step: 0
Training loss: 0.09736058115959167
Validation loss: 1.4946289293227657

Epoch: 6| Step: 1
Training loss: 0.10243172943592072
Validation loss: 1.4757476904058968

Epoch: 6| Step: 2
Training loss: 0.1684018075466156
Validation loss: 1.4530987713926582

Epoch: 6| Step: 3
Training loss: 0.18714526295661926
Validation loss: 1.4535309999219832

Epoch: 6| Step: 4
Training loss: 0.2192659080028534
Validation loss: 1.45523162041941

Epoch: 6| Step: 5
Training loss: 0.11924169957637787
Validation loss: 1.457967217891447

Epoch: 6| Step: 6
Training loss: 0.1298099160194397
Validation loss: 1.454047422255239

Epoch: 6| Step: 7
Training loss: 0.14495675265789032
Validation loss: 1.4515418352619294

Epoch: 6| Step: 8
Training loss: 0.10989204794168472
Validation loss: 1.4762385365783528

Epoch: 6| Step: 9
Training loss: 0.05892827361822128
Validation loss: 1.479014604322372

Epoch: 6| Step: 10
Training loss: 0.1272437870502472
Validation loss: 1.524081027635964

Epoch: 6| Step: 11
Training loss: 0.12197211384773254
Validation loss: 1.5115503508557555

Epoch: 6| Step: 12
Training loss: 0.07843518257141113
Validation loss: 1.556046684583028

Epoch: 6| Step: 13
Training loss: 0.29359424114227295
Validation loss: 1.558323117994493

Epoch: 457| Step: 0
Training loss: 0.1549498736858368
Validation loss: 1.5645841731820056

Epoch: 6| Step: 1
Training loss: 0.20995326340198517
Validation loss: 1.5717146717092043

Epoch: 6| Step: 2
Training loss: 0.18068887293338776
Validation loss: 1.5904805224428895

Epoch: 6| Step: 3
Training loss: 0.10519838333129883
Validation loss: 1.535186363804725

Epoch: 6| Step: 4
Training loss: 0.07203444093465805
Validation loss: 1.538334895205754

Epoch: 6| Step: 5
Training loss: 0.16181915998458862
Validation loss: 1.4996865833959272

Epoch: 6| Step: 6
Training loss: 0.12131600826978683
Validation loss: 1.441195757158341

Epoch: 6| Step: 7
Training loss: 0.06842152029275894
Validation loss: 1.4598033120555263

Epoch: 6| Step: 8
Training loss: 0.11741569638252258
Validation loss: 1.45021951711306

Epoch: 6| Step: 9
Training loss: 0.12948472797870636
Validation loss: 1.448348622168264

Epoch: 6| Step: 10
Training loss: 0.0766652449965477
Validation loss: 1.4316835249623945

Epoch: 6| Step: 11
Training loss: 0.20089782774448395
Validation loss: 1.4723154870412682

Epoch: 6| Step: 12
Training loss: 0.15928402543067932
Validation loss: 1.4717995543633737

Epoch: 6| Step: 13
Training loss: 0.1432897448539734
Validation loss: 1.4773156412186161

Epoch: 458| Step: 0
Training loss: 0.06256966292858124
Validation loss: 1.476319214349152

Epoch: 6| Step: 1
Training loss: 0.07205063104629517
Validation loss: 1.498662325643724

Epoch: 6| Step: 2
Training loss: 0.09312577545642853
Validation loss: 1.5389815376650902

Epoch: 6| Step: 3
Training loss: 0.23466067016124725
Validation loss: 1.5189067522684734

Epoch: 6| Step: 4
Training loss: 0.07199415564537048
Validation loss: 1.5376896050668531

Epoch: 6| Step: 5
Training loss: 0.1321081817150116
Validation loss: 1.4993713709615892

Epoch: 6| Step: 6
Training loss: 0.15101659297943115
Validation loss: 1.5133823656266736

Epoch: 6| Step: 7
Training loss: 0.15240731835365295
Validation loss: 1.4996167190613285

Epoch: 6| Step: 8
Training loss: 0.10492904484272003
Validation loss: 1.4909968453068887

Epoch: 6| Step: 9
Training loss: 0.14733228087425232
Validation loss: 1.4904124634240263

Epoch: 6| Step: 10
Training loss: 0.11383208632469177
Validation loss: 1.4834005627580868

Epoch: 6| Step: 11
Training loss: 0.11339594423770905
Validation loss: 1.4352493081041562

Epoch: 6| Step: 12
Training loss: 0.10168243944644928
Validation loss: 1.4506343487770326

Epoch: 6| Step: 13
Training loss: 0.1912449449300766
Validation loss: 1.4811637952763548

Epoch: 459| Step: 0
Training loss: 0.21061129868030548
Validation loss: 1.4822459041431386

Epoch: 6| Step: 1
Training loss: 0.10871390998363495
Validation loss: 1.469532052675883

Epoch: 6| Step: 2
Training loss: 0.07721079140901566
Validation loss: 1.4683830481703564

Epoch: 6| Step: 3
Training loss: 0.08835801482200623
Validation loss: 1.4808332894438057

Epoch: 6| Step: 4
Training loss: 0.10590322315692902
Validation loss: 1.4680739525825746

Epoch: 6| Step: 5
Training loss: 0.14536051452159882
Validation loss: 1.4724234509211716

Epoch: 6| Step: 6
Training loss: 0.11956018954515457
Validation loss: 1.4810377987482215

Epoch: 6| Step: 7
Training loss: 0.31453055143356323
Validation loss: 1.4949263462456324

Epoch: 6| Step: 8
Training loss: 0.1263466775417328
Validation loss: 1.5025371172094857

Epoch: 6| Step: 9
Training loss: 0.1786574423313141
Validation loss: 1.5183355192984305

Epoch: 6| Step: 10
Training loss: 0.10729934275150299
Validation loss: 1.5588773181361537

Epoch: 6| Step: 11
Training loss: 0.1362360417842865
Validation loss: 1.5418185726288827

Epoch: 6| Step: 12
Training loss: 0.06240123137831688
Validation loss: 1.559637423484556

Epoch: 6| Step: 13
Training loss: 0.14219261705875397
Validation loss: 1.537402227360715

Epoch: 460| Step: 0
Training loss: 0.14739659428596497
Validation loss: 1.5344275659130466

Epoch: 6| Step: 1
Training loss: 0.11775660514831543
Validation loss: 1.5228693142373075

Epoch: 6| Step: 2
Training loss: 0.1485590636730194
Validation loss: 1.5154317066233645

Epoch: 6| Step: 3
Training loss: 0.1445493847131729
Validation loss: 1.5055681633692917

Epoch: 6| Step: 4
Training loss: 0.1453382670879364
Validation loss: 1.488853234116749

Epoch: 6| Step: 5
Training loss: 0.1584792137145996
Validation loss: 1.5099502007166545

Epoch: 6| Step: 6
Training loss: 0.10127735137939453
Validation loss: 1.471333908778365

Epoch: 6| Step: 7
Training loss: 0.07818964868783951
Validation loss: 1.4779914091992121

Epoch: 6| Step: 8
Training loss: 0.15087559819221497
Validation loss: 1.4332672011467718

Epoch: 6| Step: 9
Training loss: 0.11785874515771866
Validation loss: 1.4878030835941274

Epoch: 6| Step: 10
Training loss: 0.07224635779857635
Validation loss: 1.4947571139181814

Epoch: 6| Step: 11
Training loss: 0.12211166322231293
Validation loss: 1.505109021740575

Epoch: 6| Step: 12
Training loss: 0.08654278516769409
Validation loss: 1.4928187285700152

Epoch: 6| Step: 13
Training loss: 0.0791393592953682
Validation loss: 1.5130651061252882

Epoch: 461| Step: 0
Training loss: 0.06741965562105179
Validation loss: 1.5223757887399325

Epoch: 6| Step: 1
Training loss: 0.05437517166137695
Validation loss: 1.5198147130268875

Epoch: 6| Step: 2
Training loss: 0.1003139540553093
Validation loss: 1.5113355293068835

Epoch: 6| Step: 3
Training loss: 0.1277996301651001
Validation loss: 1.517883163626476

Epoch: 6| Step: 4
Training loss: 0.08419463038444519
Validation loss: 1.5283933378035022

Epoch: 6| Step: 5
Training loss: 0.23377206921577454
Validation loss: 1.5154462886112992

Epoch: 6| Step: 6
Training loss: 0.0983949601650238
Validation loss: 1.5238909330419315

Epoch: 6| Step: 7
Training loss: 0.13166318833827972
Validation loss: 1.4755233244229389

Epoch: 6| Step: 8
Training loss: 0.10389381647109985
Validation loss: 1.5203630411496727

Epoch: 6| Step: 9
Training loss: 0.09987612068653107
Validation loss: 1.5133021621293918

Epoch: 6| Step: 10
Training loss: 0.05639674887061119
Validation loss: 1.4684995438462944

Epoch: 6| Step: 11
Training loss: 0.11219586431980133
Validation loss: 1.4908328645972795

Epoch: 6| Step: 12
Training loss: 0.06989482045173645
Validation loss: 1.4943593202098724

Epoch: 6| Step: 13
Training loss: 0.0558524988591671
Validation loss: 1.467178830536463

Epoch: 462| Step: 0
Training loss: 0.0943756029009819
Validation loss: 1.496981773325192

Epoch: 6| Step: 1
Training loss: 0.12794429063796997
Validation loss: 1.4971936787328413

Epoch: 6| Step: 2
Training loss: 0.16904661059379578
Validation loss: 1.4896028336658274

Epoch: 6| Step: 3
Training loss: 0.11772268265485764
Validation loss: 1.4965367945291663

Epoch: 6| Step: 4
Training loss: 0.08792059123516083
Validation loss: 1.5057388031354515

Epoch: 6| Step: 5
Training loss: 0.13254714012145996
Validation loss: 1.4947402349082373

Epoch: 6| Step: 6
Training loss: 0.11499987542629242
Validation loss: 1.496159444573105

Epoch: 6| Step: 7
Training loss: 0.06669410318136215
Validation loss: 1.495338047063479

Epoch: 6| Step: 8
Training loss: 0.11859773099422455
Validation loss: 1.4871972619846303

Epoch: 6| Step: 9
Training loss: 0.11105072498321533
Validation loss: 1.5034773362580167

Epoch: 6| Step: 10
Training loss: 0.10990330576896667
Validation loss: 1.5457228306801087

Epoch: 6| Step: 11
Training loss: 0.20816561579704285
Validation loss: 1.5168571331167733

Epoch: 6| Step: 12
Training loss: 0.08453387767076492
Validation loss: 1.5361473765424503

Epoch: 6| Step: 13
Training loss: 0.05239783227443695
Validation loss: 1.547395976640845

Epoch: 463| Step: 0
Training loss: 0.12153512984514236
Validation loss: 1.5519327502096854

Epoch: 6| Step: 1
Training loss: 0.1124514639377594
Validation loss: 1.5361356991593555

Epoch: 6| Step: 2
Training loss: 0.10272770375013351
Validation loss: 1.5314907732830252

Epoch: 6| Step: 3
Training loss: 0.11551259458065033
Validation loss: 1.495898695402248

Epoch: 6| Step: 4
Training loss: 0.17399895191192627
Validation loss: 1.5052343132675334

Epoch: 6| Step: 5
Training loss: 0.11889246106147766
Validation loss: 1.4907523085994105

Epoch: 6| Step: 6
Training loss: 0.10671551525592804
Validation loss: 1.5064822409742622

Epoch: 6| Step: 7
Training loss: 0.19269438087940216
Validation loss: 1.4993484225324405

Epoch: 6| Step: 8
Training loss: 0.07709518074989319
Validation loss: 1.4368320472778813

Epoch: 6| Step: 9
Training loss: 0.1526682823896408
Validation loss: 1.4215157647286691

Epoch: 6| Step: 10
Training loss: 0.11914540827274323
Validation loss: 1.4611395315457416

Epoch: 6| Step: 11
Training loss: 0.10387749969959259
Validation loss: 1.45716461571314

Epoch: 6| Step: 12
Training loss: 0.08333743363618851
Validation loss: 1.4713338677601149

Epoch: 6| Step: 13
Training loss: 0.08292380720376968
Validation loss: 1.4645484599374956

Epoch: 464| Step: 0
Training loss: 0.0931604653596878
Validation loss: 1.4590374397975143

Epoch: 6| Step: 1
Training loss: 0.12556485831737518
Validation loss: 1.4681562031469038

Epoch: 6| Step: 2
Training loss: 0.08138111978769302
Validation loss: 1.4845202802329935

Epoch: 6| Step: 3
Training loss: 0.08747254312038422
Validation loss: 1.5354307825847338

Epoch: 6| Step: 4
Training loss: 0.21045318245887756
Validation loss: 1.5441851731269591

Epoch: 6| Step: 5
Training loss: 0.07818245887756348
Validation loss: 1.5323532217292375

Epoch: 6| Step: 6
Training loss: 0.1860477775335312
Validation loss: 1.5115919536159885

Epoch: 6| Step: 7
Training loss: 0.16131693124771118
Validation loss: 1.4856296585452171

Epoch: 6| Step: 8
Training loss: 0.06010619178414345
Validation loss: 1.4957858529142154

Epoch: 6| Step: 9
Training loss: 0.18752780556678772
Validation loss: 1.4676018184231174

Epoch: 6| Step: 10
Training loss: 0.08929338306188583
Validation loss: 1.4533552931201073

Epoch: 6| Step: 11
Training loss: 0.15255388617515564
Validation loss: 1.4320475298871276

Epoch: 6| Step: 12
Training loss: 0.10158533602952957
Validation loss: 1.4558038570547616

Epoch: 6| Step: 13
Training loss: 0.09425665438175201
Validation loss: 1.4508893694928897

Epoch: 465| Step: 0
Training loss: 0.15418528020381927
Validation loss: 1.4537352554259761

Epoch: 6| Step: 1
Training loss: 0.11451587080955505
Validation loss: 1.4663984288451493

Epoch: 6| Step: 2
Training loss: 0.23299100995063782
Validation loss: 1.460954728946891

Epoch: 6| Step: 3
Training loss: 0.11267182976007462
Validation loss: 1.4656254578662176

Epoch: 6| Step: 4
Training loss: 0.07788354158401489
Validation loss: 1.46119059670356

Epoch: 6| Step: 5
Training loss: 0.13395988941192627
Validation loss: 1.4613306567233095

Epoch: 6| Step: 6
Training loss: 0.16152158379554749
Validation loss: 1.463065920337554

Epoch: 6| Step: 7
Training loss: 0.0962321013212204
Validation loss: 1.4532458654014013

Epoch: 6| Step: 8
Training loss: 0.09399638324975967
Validation loss: 1.4899084952569777

Epoch: 6| Step: 9
Training loss: 0.14542943239212036
Validation loss: 1.457325117562407

Epoch: 6| Step: 10
Training loss: 0.13936282694339752
Validation loss: 1.4365369786498368

Epoch: 6| Step: 11
Training loss: 0.1104544848203659
Validation loss: 1.4305693949422529

Epoch: 6| Step: 12
Training loss: 0.13073289394378662
Validation loss: 1.4443583283373105

Epoch: 6| Step: 13
Training loss: 0.12164810299873352
Validation loss: 1.467298407708445

Epoch: 466| Step: 0
Training loss: 0.13443171977996826
Validation loss: 1.4738499015890143

Epoch: 6| Step: 1
Training loss: 0.22939082980155945
Validation loss: 1.4978743137851838

Epoch: 6| Step: 2
Training loss: 0.11945226788520813
Validation loss: 1.4883744857644523

Epoch: 6| Step: 3
Training loss: 0.1474117934703827
Validation loss: 1.4985528895931859

Epoch: 6| Step: 4
Training loss: 0.10503152757883072
Validation loss: 1.5107211028375933

Epoch: 6| Step: 5
Training loss: 0.07523702085018158
Validation loss: 1.5122067210494832

Epoch: 6| Step: 6
Training loss: 0.07444511353969574
Validation loss: 1.5054883713363318

Epoch: 6| Step: 7
Training loss: 0.12348999083042145
Validation loss: 1.4955020412322013

Epoch: 6| Step: 8
Training loss: 0.11948996782302856
Validation loss: 1.4714846662295762

Epoch: 6| Step: 9
Training loss: 0.16292539238929749
Validation loss: 1.441248473941639

Epoch: 6| Step: 10
Training loss: 0.062328703701496124
Validation loss: 1.4643097962102583

Epoch: 6| Step: 11
Training loss: 0.13018134236335754
Validation loss: 1.4476313078275291

Epoch: 6| Step: 12
Training loss: 0.10205258429050446
Validation loss: 1.4536383254553682

Epoch: 6| Step: 13
Training loss: 0.07835012674331665
Validation loss: 1.4405984186357068

Epoch: 467| Step: 0
Training loss: 0.1603986620903015
Validation loss: 1.4696501403726556

Epoch: 6| Step: 1
Training loss: 0.1045810878276825
Validation loss: 1.4694898102873115

Epoch: 6| Step: 2
Training loss: 0.07228679209947586
Validation loss: 1.4628666831601052

Epoch: 6| Step: 3
Training loss: 0.09512782841920853
Validation loss: 1.476662092311408

Epoch: 6| Step: 4
Training loss: 0.11890795826911926
Validation loss: 1.4865888318707865

Epoch: 6| Step: 5
Training loss: 0.07161363214254379
Validation loss: 1.4895075348115736

Epoch: 6| Step: 6
Training loss: 0.10664045810699463
Validation loss: 1.485422368972532

Epoch: 6| Step: 7
Training loss: 0.16979393362998962
Validation loss: 1.493107912360981

Epoch: 6| Step: 8
Training loss: 0.10724861174821854
Validation loss: 1.4782391478938441

Epoch: 6| Step: 9
Training loss: 0.10278823226690292
Validation loss: 1.5003870084721556

Epoch: 6| Step: 10
Training loss: 0.09118157625198364
Validation loss: 1.515166558245177

Epoch: 6| Step: 11
Training loss: 0.13636016845703125
Validation loss: 1.4983060001045145

Epoch: 6| Step: 12
Training loss: 0.11587071418762207
Validation loss: 1.5140261432175994

Epoch: 6| Step: 13
Training loss: 0.15721704065799713
Validation loss: 1.505807371549709

Epoch: 468| Step: 0
Training loss: 0.07721948623657227
Validation loss: 1.4998380022664224

Epoch: 6| Step: 1
Training loss: 0.1032177284359932
Validation loss: 1.524413808699577

Epoch: 6| Step: 2
Training loss: 0.03227035701274872
Validation loss: 1.4913827546181218

Epoch: 6| Step: 3
Training loss: 0.06856121122837067
Validation loss: 1.539882811166907

Epoch: 6| Step: 4
Training loss: 0.097420834004879
Validation loss: 1.492129736049201

Epoch: 6| Step: 5
Training loss: 0.1994244009256363
Validation loss: 1.5024987625819382

Epoch: 6| Step: 6
Training loss: 0.11046946048736572
Validation loss: 1.5158087848335184

Epoch: 6| Step: 7
Training loss: 0.15758180618286133
Validation loss: 1.464961782578499

Epoch: 6| Step: 8
Training loss: 0.08318763971328735
Validation loss: 1.4933823898274412

Epoch: 6| Step: 9
Training loss: 0.07921146601438522
Validation loss: 1.48191903098937

Epoch: 6| Step: 10
Training loss: 0.12372589856386185
Validation loss: 1.474721889342031

Epoch: 6| Step: 11
Training loss: 0.12210133671760559
Validation loss: 1.4867142826639197

Epoch: 6| Step: 12
Training loss: 0.1581398844718933
Validation loss: 1.464512360993252

Epoch: 6| Step: 13
Training loss: 0.12835000455379486
Validation loss: 1.4539648025266585

Epoch: 469| Step: 0
Training loss: 0.1424710899591446
Validation loss: 1.4462053557877899

Epoch: 6| Step: 1
Training loss: 0.09275007247924805
Validation loss: 1.4815414836329799

Epoch: 6| Step: 2
Training loss: 0.1612989902496338
Validation loss: 1.4621033937700334

Epoch: 6| Step: 3
Training loss: 0.17843171954154968
Validation loss: 1.4750271907416723

Epoch: 6| Step: 4
Training loss: 0.06852898746728897
Validation loss: 1.4581976782891057

Epoch: 6| Step: 5
Training loss: 0.06313814967870712
Validation loss: 1.488934543824965

Epoch: 6| Step: 6
Training loss: 0.08811751008033752
Validation loss: 1.5329420822922901

Epoch: 6| Step: 7
Training loss: 0.13672392070293427
Validation loss: 1.538903078725261

Epoch: 6| Step: 8
Training loss: 0.11044178158044815
Validation loss: 1.5422368818713772

Epoch: 6| Step: 9
Training loss: 0.14329952001571655
Validation loss: 1.5307838468141453

Epoch: 6| Step: 10
Training loss: 0.10281717032194138
Validation loss: 1.5314566999353387

Epoch: 6| Step: 11
Training loss: 0.08556342124938965
Validation loss: 1.5256502423235165

Epoch: 6| Step: 12
Training loss: 0.10406310111284256
Validation loss: 1.4960641989143946

Epoch: 6| Step: 13
Training loss: 0.0525771901011467
Validation loss: 1.4725175096142677

Epoch: 470| Step: 0
Training loss: 0.10401825606822968
Validation loss: 1.4711547756707797

Epoch: 6| Step: 1
Training loss: 0.12358589470386505
Validation loss: 1.458304291130394

Epoch: 6| Step: 2
Training loss: 0.11918220669031143
Validation loss: 1.454284865369079

Epoch: 6| Step: 3
Training loss: 0.10272833704948425
Validation loss: 1.4713854501324315

Epoch: 6| Step: 4
Training loss: 0.16102610528469086
Validation loss: 1.4535062184897802

Epoch: 6| Step: 5
Training loss: 0.05772599205374718
Validation loss: 1.4890516701564993

Epoch: 6| Step: 6
Training loss: 0.03950224816799164
Validation loss: 1.4843512722240981

Epoch: 6| Step: 7
Training loss: 0.1503676474094391
Validation loss: 1.4911096288311867

Epoch: 6| Step: 8
Training loss: 0.0978739857673645
Validation loss: 1.468584515074248

Epoch: 6| Step: 9
Training loss: 0.09083002060651779
Validation loss: 1.5139656810350315

Epoch: 6| Step: 10
Training loss: 0.06240161508321762
Validation loss: 1.5013529600635651

Epoch: 6| Step: 11
Training loss: 0.12441910803318024
Validation loss: 1.5119365761356969

Epoch: 6| Step: 12
Training loss: 0.10759130120277405
Validation loss: 1.4897040538890387

Epoch: 6| Step: 13
Training loss: 0.1275295615196228
Validation loss: 1.4669981271989885

Epoch: 471| Step: 0
Training loss: 0.09505699574947357
Validation loss: 1.4614321044696275

Epoch: 6| Step: 1
Training loss: 0.13507992029190063
Validation loss: 1.457547841533538

Epoch: 6| Step: 2
Training loss: 0.09656240791082382
Validation loss: 1.4397002138117307

Epoch: 6| Step: 3
Training loss: 0.0715244859457016
Validation loss: 1.4623559085271691

Epoch: 6| Step: 4
Training loss: 0.11653487384319305
Validation loss: 1.4428241547717844

Epoch: 6| Step: 5
Training loss: 0.09237316250801086
Validation loss: 1.4634942752058788

Epoch: 6| Step: 6
Training loss: 0.10915158689022064
Validation loss: 1.4446685993543236

Epoch: 6| Step: 7
Training loss: 0.08103011548519135
Validation loss: 1.470592406488234

Epoch: 6| Step: 8
Training loss: 0.19319362938404083
Validation loss: 1.4698547047953452

Epoch: 6| Step: 9
Training loss: 0.05593567341566086
Validation loss: 1.4736579695055563

Epoch: 6| Step: 10
Training loss: 0.10904102027416229
Validation loss: 1.4892293740344305

Epoch: 6| Step: 11
Training loss: 0.1399882435798645
Validation loss: 1.4673214650923205

Epoch: 6| Step: 12
Training loss: 0.05508706718683243
Validation loss: 1.4794995771941317

Epoch: 6| Step: 13
Training loss: 0.09108611941337585
Validation loss: 1.4908960173206944

Epoch: 472| Step: 0
Training loss: 0.09101679176092148
Validation loss: 1.5036082113942792

Epoch: 6| Step: 1
Training loss: 0.08581571280956268
Validation loss: 1.5257559341769065

Epoch: 6| Step: 2
Training loss: 0.10641200840473175
Validation loss: 1.5192376349561958

Epoch: 6| Step: 3
Training loss: 0.13626721501350403
Validation loss: 1.52733092154226

Epoch: 6| Step: 4
Training loss: 0.09613823890686035
Validation loss: 1.508972575587611

Epoch: 6| Step: 5
Training loss: 0.06144457310438156
Validation loss: 1.512800080801851

Epoch: 6| Step: 6
Training loss: 0.12814129889011383
Validation loss: 1.5020028968011179

Epoch: 6| Step: 7
Training loss: 0.19919376075267792
Validation loss: 1.4510338652518489

Epoch: 6| Step: 8
Training loss: 0.097776398062706
Validation loss: 1.4544653347743455

Epoch: 6| Step: 9
Training loss: 0.1279039978981018
Validation loss: 1.4904451408693868

Epoch: 6| Step: 10
Training loss: 0.12313710153102875
Validation loss: 1.4815528264609716

Epoch: 6| Step: 11
Training loss: 0.10106520354747772
Validation loss: 1.483470380306244

Epoch: 6| Step: 12
Training loss: 0.03984537720680237
Validation loss: 1.4907339375506166

Epoch: 6| Step: 13
Training loss: 0.13224384188652039
Validation loss: 1.4839318708706928

Epoch: 473| Step: 0
Training loss: 0.12336871773004532
Validation loss: 1.5105656846877067

Epoch: 6| Step: 1
Training loss: 0.08798873424530029
Validation loss: 1.5367155446801135

Epoch: 6| Step: 2
Training loss: 0.06393134593963623
Validation loss: 1.5012254971329884

Epoch: 6| Step: 3
Training loss: 0.1546737104654312
Validation loss: 1.5331942765943465

Epoch: 6| Step: 4
Training loss: 0.12623895704746246
Validation loss: 1.5506649837698987

Epoch: 6| Step: 5
Training loss: 0.09916076064109802
Validation loss: 1.5434913032798356

Epoch: 6| Step: 6
Training loss: 0.20813098549842834
Validation loss: 1.5288760098077918

Epoch: 6| Step: 7
Training loss: 0.13308972120285034
Validation loss: 1.530484910934202

Epoch: 6| Step: 8
Training loss: 0.17880912125110626
Validation loss: 1.5418504197751322

Epoch: 6| Step: 9
Training loss: 0.09334302693605423
Validation loss: 1.480543989007191

Epoch: 6| Step: 10
Training loss: 0.08997362852096558
Validation loss: 1.4795749982198079

Epoch: 6| Step: 11
Training loss: 0.17329862713813782
Validation loss: 1.4630422028162147

Epoch: 6| Step: 12
Training loss: 0.08048857748508453
Validation loss: 1.4536849606421687

Epoch: 6| Step: 13
Training loss: 0.05241311341524124
Validation loss: 1.4707171160687682

Epoch: 474| Step: 0
Training loss: 0.11239156126976013
Validation loss: 1.474019504362537

Epoch: 6| Step: 1
Training loss: 0.06981374323368073
Validation loss: 1.4940912556904618

Epoch: 6| Step: 2
Training loss: 0.11817890405654907
Validation loss: 1.5122991313216507

Epoch: 6| Step: 3
Training loss: 0.10285208374261856
Validation loss: 1.503790840025871

Epoch: 6| Step: 4
Training loss: 0.13049033284187317
Validation loss: 1.516463727079412

Epoch: 6| Step: 5
Training loss: 0.14505146443843842
Validation loss: 1.4856933265603998

Epoch: 6| Step: 6
Training loss: 0.09963071346282959
Validation loss: 1.522533860898787

Epoch: 6| Step: 7
Training loss: 0.08649522811174393
Validation loss: 1.5225375993277437

Epoch: 6| Step: 8
Training loss: 0.1204322874546051
Validation loss: 1.5277023635884768

Epoch: 6| Step: 9
Training loss: 0.09244741499423981
Validation loss: 1.5076090981883388

Epoch: 6| Step: 10
Training loss: 0.08421820402145386
Validation loss: 1.514899432018239

Epoch: 6| Step: 11
Training loss: 0.06098397448658943
Validation loss: 1.5023758629316926

Epoch: 6| Step: 12
Training loss: 0.09067254513502121
Validation loss: 1.4784013045731412

Epoch: 6| Step: 13
Training loss: 0.07066624611616135
Validation loss: 1.480724012979897

Epoch: 475| Step: 0
Training loss: 0.09138640761375427
Validation loss: 1.4652415424264886

Epoch: 6| Step: 1
Training loss: 0.11638756096363068
Validation loss: 1.4927115119913572

Epoch: 6| Step: 2
Training loss: 0.10727271437644958
Validation loss: 1.4900508208941388

Epoch: 6| Step: 3
Training loss: 0.12673600018024445
Validation loss: 1.4926597713142313

Epoch: 6| Step: 4
Training loss: 0.10575208812952042
Validation loss: 1.46752163287132

Epoch: 6| Step: 5
Training loss: 0.08055269718170166
Validation loss: 1.4626837315097931

Epoch: 6| Step: 6
Training loss: 0.10206073522567749
Validation loss: 1.4991436132820704

Epoch: 6| Step: 7
Training loss: 0.09891625493764877
Validation loss: 1.4595330235778645

Epoch: 6| Step: 8
Training loss: 0.13067960739135742
Validation loss: 1.4987082494202482

Epoch: 6| Step: 9
Training loss: 0.09931318461894989
Validation loss: 1.4794255405343988

Epoch: 6| Step: 10
Training loss: 0.12583106756210327
Validation loss: 1.483655748828765

Epoch: 6| Step: 11
Training loss: 0.10580556094646454
Validation loss: 1.5012138505135812

Epoch: 6| Step: 12
Training loss: 0.1462934911251068
Validation loss: 1.4710111874406055

Epoch: 6| Step: 13
Training loss: 0.13811801373958588
Validation loss: 1.5386310559447094

Epoch: 476| Step: 0
Training loss: 0.08139148354530334
Validation loss: 1.5630276363383058

Epoch: 6| Step: 1
Training loss: 0.11482506990432739
Validation loss: 1.5327042251504877

Epoch: 6| Step: 2
Training loss: 0.0943356603384018
Validation loss: 1.4971160645126014

Epoch: 6| Step: 3
Training loss: 0.1317748874425888
Validation loss: 1.4945230535281602

Epoch: 6| Step: 4
Training loss: 0.1253509223461151
Validation loss: 1.4840701574920325

Epoch: 6| Step: 5
Training loss: 0.12184242904186249
Validation loss: 1.4466334799284577

Epoch: 6| Step: 6
Training loss: 0.15996748208999634
Validation loss: 1.4486769578790153

Epoch: 6| Step: 7
Training loss: 0.09890450537204742
Validation loss: 1.4392817122961885

Epoch: 6| Step: 8
Training loss: 0.1304156631231308
Validation loss: 1.457241669777901

Epoch: 6| Step: 9
Training loss: 0.09648844599723816
Validation loss: 1.4675264339293204

Epoch: 6| Step: 10
Training loss: 0.11402898281812668
Validation loss: 1.4457869824542795

Epoch: 6| Step: 11
Training loss: 0.08152525126934052
Validation loss: 1.4718669511938607

Epoch: 6| Step: 12
Training loss: 0.1334013044834137
Validation loss: 1.4547160338330012

Epoch: 6| Step: 13
Training loss: 0.10753453522920609
Validation loss: 1.4748213585986887

Epoch: 477| Step: 0
Training loss: 0.05938390642404556
Validation loss: 1.4878067431911346

Epoch: 6| Step: 1
Training loss: 0.07488228380680084
Validation loss: 1.517868592534014

Epoch: 6| Step: 2
Training loss: 0.09170520305633545
Validation loss: 1.5440706450452086

Epoch: 6| Step: 3
Training loss: 0.07632937282323837
Validation loss: 1.5460489321780462

Epoch: 6| Step: 4
Training loss: 0.140428364276886
Validation loss: 1.5630953658011653

Epoch: 6| Step: 5
Training loss: 0.12444603443145752
Validation loss: 1.541663528770529

Epoch: 6| Step: 6
Training loss: 0.10966991633176804
Validation loss: 1.5166312802222468

Epoch: 6| Step: 7
Training loss: 0.11532387882471085
Validation loss: 1.502189476002929

Epoch: 6| Step: 8
Training loss: 0.14276356995105743
Validation loss: 1.4821480820255895

Epoch: 6| Step: 9
Training loss: 0.06452197581529617
Validation loss: 1.4892547245948546

Epoch: 6| Step: 10
Training loss: 0.11911767721176147
Validation loss: 1.4778702797428254

Epoch: 6| Step: 11
Training loss: 0.08036794513463974
Validation loss: 1.4730196101691133

Epoch: 6| Step: 12
Training loss: 0.23209768533706665
Validation loss: 1.4716514823257283

Epoch: 6| Step: 13
Training loss: 0.07852978259325027
Validation loss: 1.4589198891834547

Epoch: 478| Step: 0
Training loss: 0.06483964622020721
Validation loss: 1.44519623889718

Epoch: 6| Step: 1
Training loss: 0.10112089663743973
Validation loss: 1.4713927866310201

Epoch: 6| Step: 2
Training loss: 0.07038664072751999
Validation loss: 1.5006464937681794

Epoch: 6| Step: 3
Training loss: 0.08722089976072311
Validation loss: 1.5297558435829737

Epoch: 6| Step: 4
Training loss: 0.10074421763420105
Validation loss: 1.506408159450818

Epoch: 6| Step: 5
Training loss: 0.13659381866455078
Validation loss: 1.5182641526704193

Epoch: 6| Step: 6
Training loss: 0.10508617013692856
Validation loss: 1.4861896396965109

Epoch: 6| Step: 7
Training loss: 0.21727365255355835
Validation loss: 1.4637420869642688

Epoch: 6| Step: 8
Training loss: 0.149635910987854
Validation loss: 1.4479898432249665

Epoch: 6| Step: 9
Training loss: 0.11173136532306671
Validation loss: 1.4295138761561403

Epoch: 6| Step: 10
Training loss: 0.06134326756000519
Validation loss: 1.4598422665749826

Epoch: 6| Step: 11
Training loss: 0.11757199466228485
Validation loss: 1.4574433129320863

Epoch: 6| Step: 12
Training loss: 0.09607987105846405
Validation loss: 1.4545369519982287

Epoch: 6| Step: 13
Training loss: 0.10256605595350266
Validation loss: 1.444995217425849

Epoch: 479| Step: 0
Training loss: 0.10255338996648788
Validation loss: 1.4473058639034149

Epoch: 6| Step: 1
Training loss: 0.12188984453678131
Validation loss: 1.485496073640803

Epoch: 6| Step: 2
Training loss: 0.15398557484149933
Validation loss: 1.4730867134627474

Epoch: 6| Step: 3
Training loss: 0.166446715593338
Validation loss: 1.479037578387927

Epoch: 6| Step: 4
Training loss: 0.09796347469091415
Validation loss: 1.4946461698060394

Epoch: 6| Step: 5
Training loss: 0.20677635073661804
Validation loss: 1.4766910922142766

Epoch: 6| Step: 6
Training loss: 0.08703397959470749
Validation loss: 1.468971296023297

Epoch: 6| Step: 7
Training loss: 0.0682978481054306
Validation loss: 1.4963078242476269

Epoch: 6| Step: 8
Training loss: 0.11369342356920242
Validation loss: 1.5184658560701596

Epoch: 6| Step: 9
Training loss: 0.11324715614318848
Validation loss: 1.5122834533773444

Epoch: 6| Step: 10
Training loss: 0.12333787977695465
Validation loss: 1.5216133376603485

Epoch: 6| Step: 11
Training loss: 0.10010873526334763
Validation loss: 1.5104480430644045

Epoch: 6| Step: 12
Training loss: 0.15322625637054443
Validation loss: 1.5108879464928822

Epoch: 6| Step: 13
Training loss: 0.08278857171535492
Validation loss: 1.5194847519679735

Epoch: 480| Step: 0
Training loss: 0.11690976470708847
Validation loss: 1.505541729670699

Epoch: 6| Step: 1
Training loss: 0.069907546043396
Validation loss: 1.518501611166103

Epoch: 6| Step: 2
Training loss: 0.06563408672809601
Validation loss: 1.4911777748856494

Epoch: 6| Step: 3
Training loss: 0.1535331904888153
Validation loss: 1.4916668912415862

Epoch: 6| Step: 4
Training loss: 0.2045128345489502
Validation loss: 1.4938467305193666

Epoch: 6| Step: 5
Training loss: 0.0964447483420372
Validation loss: 1.5099548351380132

Epoch: 6| Step: 6
Training loss: 0.1258317083120346
Validation loss: 1.4835122580169349

Epoch: 6| Step: 7
Training loss: 0.13815656304359436
Validation loss: 1.4472637561059767

Epoch: 6| Step: 8
Training loss: 0.08730457723140717
Validation loss: 1.4422165373320222

Epoch: 6| Step: 9
Training loss: 0.08833224326372147
Validation loss: 1.4629257648221907

Epoch: 6| Step: 10
Training loss: 0.10651467740535736
Validation loss: 1.4706497884565783

Epoch: 6| Step: 11
Training loss: 0.06761473417282104
Validation loss: 1.4312400176960935

Epoch: 6| Step: 12
Training loss: 0.13825847208499908
Validation loss: 1.4487637601872927

Epoch: 6| Step: 13
Training loss: 0.2201891541481018
Validation loss: 1.447520443188247

Epoch: 481| Step: 0
Training loss: 0.07611669600009918
Validation loss: 1.482437176089133

Epoch: 6| Step: 1
Training loss: 0.0992501825094223
Validation loss: 1.4881950527109125

Epoch: 6| Step: 2
Training loss: 0.13446271419525146
Validation loss: 1.509581260783698

Epoch: 6| Step: 3
Training loss: 0.07797517627477646
Validation loss: 1.532262312468662

Epoch: 6| Step: 4
Training loss: 0.07731518894433975
Validation loss: 1.5464337788602358

Epoch: 6| Step: 5
Training loss: 0.07849571108818054
Validation loss: 1.4981185774649344

Epoch: 6| Step: 6
Training loss: 0.11437030881643295
Validation loss: 1.504201210955138

Epoch: 6| Step: 7
Training loss: 0.15103039145469666
Validation loss: 1.5102147261301677

Epoch: 6| Step: 8
Training loss: 0.08706207573413849
Validation loss: 1.513839921643657

Epoch: 6| Step: 9
Training loss: 0.0901164561510086
Validation loss: 1.4797654049370879

Epoch: 6| Step: 10
Training loss: 0.04938493296504021
Validation loss: 1.4964171404479651

Epoch: 6| Step: 11
Training loss: 0.19831734895706177
Validation loss: 1.497204424232565

Epoch: 6| Step: 12
Training loss: 0.10425670444965363
Validation loss: 1.5047458320535638

Epoch: 6| Step: 13
Training loss: 0.11925053596496582
Validation loss: 1.5199309459296606

Epoch: 482| Step: 0
Training loss: 0.07189016044139862
Validation loss: 1.498611496340844

Epoch: 6| Step: 1
Training loss: 0.12351696193218231
Validation loss: 1.5102103717865483

Epoch: 6| Step: 2
Training loss: 0.07770369201898575
Validation loss: 1.4930556730557514

Epoch: 6| Step: 3
Training loss: 0.13552966713905334
Validation loss: 1.5053813726671281

Epoch: 6| Step: 4
Training loss: 0.1574144959449768
Validation loss: 1.5096010123529742

Epoch: 6| Step: 5
Training loss: 0.06386713683605194
Validation loss: 1.4961319956728207

Epoch: 6| Step: 6
Training loss: 0.1743900179862976
Validation loss: 1.484773305154616

Epoch: 6| Step: 7
Training loss: 0.1360987275838852
Validation loss: 1.483697227252427

Epoch: 6| Step: 8
Training loss: 0.11443984508514404
Validation loss: 1.5076032402694866

Epoch: 6| Step: 9
Training loss: 0.05004598945379257
Validation loss: 1.4934175950224682

Epoch: 6| Step: 10
Training loss: 0.12005172669887543
Validation loss: 1.4997844490953671

Epoch: 6| Step: 11
Training loss: 0.15844056010246277
Validation loss: 1.521655345475802

Epoch: 6| Step: 12
Training loss: 0.09202855080366135
Validation loss: 1.5189883503862607

Epoch: 6| Step: 13
Training loss: 0.15001316368579865
Validation loss: 1.5278369598491217

Epoch: 483| Step: 0
Training loss: 0.04255814850330353
Validation loss: 1.5264059753828152

Epoch: 6| Step: 1
Training loss: 0.09708867967128754
Validation loss: 1.4967316286538237

Epoch: 6| Step: 2
Training loss: 0.08184798061847687
Validation loss: 1.4940241254786009

Epoch: 6| Step: 3
Training loss: 0.11569303274154663
Validation loss: 1.4655836615511166

Epoch: 6| Step: 4
Training loss: 0.2219269573688507
Validation loss: 1.4866671741649669

Epoch: 6| Step: 5
Training loss: 0.10349184274673462
Validation loss: 1.4700014911672121

Epoch: 6| Step: 6
Training loss: 0.0926719456911087
Validation loss: 1.472752627506051

Epoch: 6| Step: 7
Training loss: 0.07939186692237854
Validation loss: 1.4589993530704128

Epoch: 6| Step: 8
Training loss: 0.10272330045700073
Validation loss: 1.468484955449258

Epoch: 6| Step: 9
Training loss: 0.12933458387851715
Validation loss: 1.4413466850916545

Epoch: 6| Step: 10
Training loss: 0.07580026239156723
Validation loss: 1.4768035591289561

Epoch: 6| Step: 11
Training loss: 0.09701649844646454
Validation loss: 1.480642282834617

Epoch: 6| Step: 12
Training loss: 0.059095725417137146
Validation loss: 1.4673164134384484

Epoch: 6| Step: 13
Training loss: 0.07853236794471741
Validation loss: 1.4999281161574907

Epoch: 484| Step: 0
Training loss: 0.11410897970199585
Validation loss: 1.4947992819611744

Epoch: 6| Step: 1
Training loss: 0.12091322243213654
Validation loss: 1.5321123048823366

Epoch: 6| Step: 2
Training loss: 0.11185543239116669
Validation loss: 1.4950296622450634

Epoch: 6| Step: 3
Training loss: 0.08943860232830048
Validation loss: 1.4975057180209825

Epoch: 6| Step: 4
Training loss: 0.20208032429218292
Validation loss: 1.491905273929719

Epoch: 6| Step: 5
Training loss: 0.11216700077056885
Validation loss: 1.4913169145584106

Epoch: 6| Step: 6
Training loss: 0.08213875442743301
Validation loss: 1.483517712162387

Epoch: 6| Step: 7
Training loss: 0.10452412813901901
Validation loss: 1.4526098517961399

Epoch: 6| Step: 8
Training loss: 0.06453222036361694
Validation loss: 1.4751477561971194

Epoch: 6| Step: 9
Training loss: 0.11766871809959412
Validation loss: 1.4698451661294507

Epoch: 6| Step: 10
Training loss: 0.09603045880794525
Validation loss: 1.4550130867188977

Epoch: 6| Step: 11
Training loss: 0.14283522963523865
Validation loss: 1.4464772638454233

Epoch: 6| Step: 12
Training loss: 0.0928158238530159
Validation loss: 1.4625654694854573

Epoch: 6| Step: 13
Training loss: 0.1318373680114746
Validation loss: 1.4854874585264473

Epoch: 485| Step: 0
Training loss: 0.11654313653707504
Validation loss: 1.481423306208785

Epoch: 6| Step: 1
Training loss: 0.07160148024559021
Validation loss: 1.4707010869056947

Epoch: 6| Step: 2
Training loss: 0.09597201645374298
Validation loss: 1.4879964731072868

Epoch: 6| Step: 3
Training loss: 0.07266317307949066
Validation loss: 1.4755903636255572

Epoch: 6| Step: 4
Training loss: 0.05398865416646004
Validation loss: 1.5192884898954822

Epoch: 6| Step: 5
Training loss: 0.114521324634552
Validation loss: 1.488763879704219

Epoch: 6| Step: 6
Training loss: 0.09948232769966125
Validation loss: 1.4986513186526556

Epoch: 6| Step: 7
Training loss: 0.08910618722438812
Validation loss: 1.4736021846853278

Epoch: 6| Step: 8
Training loss: 0.09686543792486191
Validation loss: 1.4696828639635475

Epoch: 6| Step: 9
Training loss: 0.12694254517555237
Validation loss: 1.4877742817324977

Epoch: 6| Step: 10
Training loss: 0.08896113932132721
Validation loss: 1.4658892898149387

Epoch: 6| Step: 11
Training loss: 0.07390011101961136
Validation loss: 1.4530151659442532

Epoch: 6| Step: 12
Training loss: 0.20432011783123016
Validation loss: 1.4626415660304408

Epoch: 6| Step: 13
Training loss: 0.097349613904953
Validation loss: 1.4552500042864072

Epoch: 486| Step: 0
Training loss: 0.17693310976028442
Validation loss: 1.4355943408063663

Epoch: 6| Step: 1
Training loss: 0.08305750042200089
Validation loss: 1.4847761597684634

Epoch: 6| Step: 2
Training loss: 0.06467375159263611
Validation loss: 1.4378115874464794

Epoch: 6| Step: 3
Training loss: 0.09264318645000458
Validation loss: 1.455582849441036

Epoch: 6| Step: 4
Training loss: 0.08375737816095352
Validation loss: 1.4782212703458724

Epoch: 6| Step: 5
Training loss: 0.07366403192281723
Validation loss: 1.4534303757452196

Epoch: 6| Step: 6
Training loss: 0.07217802852392197
Validation loss: 1.4418531387082991

Epoch: 6| Step: 7
Training loss: 0.07611840218305588
Validation loss: 1.4947135986820344

Epoch: 6| Step: 8
Training loss: 0.07428238540887833
Validation loss: 1.4757752008335565

Epoch: 6| Step: 9
Training loss: 0.05776485055685043
Validation loss: 1.4650324057507258

Epoch: 6| Step: 10
Training loss: 0.09210363775491714
Validation loss: 1.4571053161416003

Epoch: 6| Step: 11
Training loss: 0.15829116106033325
Validation loss: 1.452774174751774

Epoch: 6| Step: 12
Training loss: 0.11059323698282242
Validation loss: 1.4646765814032605

Epoch: 6| Step: 13
Training loss: 0.05313603952527046
Validation loss: 1.4312673973780807

Epoch: 487| Step: 0
Training loss: 0.11096145212650299
Validation loss: 1.4572383716542234

Epoch: 6| Step: 1
Training loss: 0.06418055295944214
Validation loss: 1.4651717094964878

Epoch: 6| Step: 2
Training loss: 0.05820688605308533
Validation loss: 1.4174901041933285

Epoch: 6| Step: 3
Training loss: 0.08736544847488403
Validation loss: 1.4729931559613956

Epoch: 6| Step: 4
Training loss: 0.15551021695137024
Validation loss: 1.442380888487703

Epoch: 6| Step: 5
Training loss: 0.09272123873233795
Validation loss: 1.4377492262471108

Epoch: 6| Step: 6
Training loss: 0.08337395638227463
Validation loss: 1.4488581899673707

Epoch: 6| Step: 7
Training loss: 0.1509847640991211
Validation loss: 1.4781356370577248

Epoch: 6| Step: 8
Training loss: 0.07858479022979736
Validation loss: 1.4429980054978402

Epoch: 6| Step: 9
Training loss: 0.07155357301235199
Validation loss: 1.4550723773176952

Epoch: 6| Step: 10
Training loss: 0.09935972094535828
Validation loss: 1.48842615337782

Epoch: 6| Step: 11
Training loss: 0.1491071581840515
Validation loss: 1.48994235069521

Epoch: 6| Step: 12
Training loss: 0.08442316204309464
Validation loss: 1.5110623631426083

Epoch: 6| Step: 13
Training loss: 0.1450137346982956
Validation loss: 1.5064277700198594

Epoch: 488| Step: 0
Training loss: 0.08015943318605423
Validation loss: 1.4699288491279847

Epoch: 6| Step: 1
Training loss: 0.08992956578731537
Validation loss: 1.474441982084705

Epoch: 6| Step: 2
Training loss: 0.09678488969802856
Validation loss: 1.481373660026058

Epoch: 6| Step: 3
Training loss: 0.0812302827835083
Validation loss: 1.4613623426806541

Epoch: 6| Step: 4
Training loss: 0.08001463860273361
Validation loss: 1.4752920020011164

Epoch: 6| Step: 5
Training loss: 0.09925681352615356
Validation loss: 1.4645074202168373

Epoch: 6| Step: 6
Training loss: 0.1451481580734253
Validation loss: 1.4573212285195627

Epoch: 6| Step: 7
Training loss: 0.0805816501379013
Validation loss: 1.4704070757794123

Epoch: 6| Step: 8
Training loss: 0.11322005838155746
Validation loss: 1.4664936860402424

Epoch: 6| Step: 9
Training loss: 0.09460403770208359
Validation loss: 1.4690453493466942

Epoch: 6| Step: 10
Training loss: 0.08513757586479187
Validation loss: 1.4881844302659393

Epoch: 6| Step: 11
Training loss: 0.12857641279697418
Validation loss: 1.493067656793902

Epoch: 6| Step: 12
Training loss: 0.08872541785240173
Validation loss: 1.4971987047503073

Epoch: 6| Step: 13
Training loss: 0.04141750931739807
Validation loss: 1.464502517895032

Epoch: 489| Step: 0
Training loss: 0.05625896155834198
Validation loss: 1.5150664403874388

Epoch: 6| Step: 1
Training loss: 0.12618613243103027
Validation loss: 1.4996140118568175

Epoch: 6| Step: 2
Training loss: 0.05604230612516403
Validation loss: 1.516828307541468

Epoch: 6| Step: 3
Training loss: 0.12808343768119812
Validation loss: 1.5273052992359284

Epoch: 6| Step: 4
Training loss: 0.10976526141166687
Validation loss: 1.4892611426691855

Epoch: 6| Step: 5
Training loss: 0.12373171001672745
Validation loss: 1.4689351756085631

Epoch: 6| Step: 6
Training loss: 0.07353383302688599
Validation loss: 1.453070290627018

Epoch: 6| Step: 7
Training loss: 0.11357060819864273
Validation loss: 1.4625899214898386

Epoch: 6| Step: 8
Training loss: 0.13356217741966248
Validation loss: 1.4544834077999156

Epoch: 6| Step: 9
Training loss: 0.14870165288448334
Validation loss: 1.4461293925521195

Epoch: 6| Step: 10
Training loss: 0.08999499678611755
Validation loss: 1.4507616553255307

Epoch: 6| Step: 11
Training loss: 0.06841421127319336
Validation loss: 1.4527415549883278

Epoch: 6| Step: 12
Training loss: 0.1480761170387268
Validation loss: 1.485759453106952

Epoch: 6| Step: 13
Training loss: 0.08617164194583893
Validation loss: 1.4750107847234255

Epoch: 490| Step: 0
Training loss: 0.0634281113743782
Validation loss: 1.5211126150623444

Epoch: 6| Step: 1
Training loss: 0.11851532012224197
Validation loss: 1.542409207231255

Epoch: 6| Step: 2
Training loss: 0.15172702074050903
Validation loss: 1.522939823007071

Epoch: 6| Step: 3
Training loss: 0.08059611916542053
Validation loss: 1.5261968810071227

Epoch: 6| Step: 4
Training loss: 0.09925485402345657
Validation loss: 1.512535552824697

Epoch: 6| Step: 5
Training loss: 0.10587897151708603
Validation loss: 1.466337973712593

Epoch: 6| Step: 6
Training loss: 0.15581415593624115
Validation loss: 1.46134384985893

Epoch: 6| Step: 7
Training loss: 0.0766853615641594
Validation loss: 1.4589493428507159

Epoch: 6| Step: 8
Training loss: 0.09924392402172089
Validation loss: 1.4557755544621458

Epoch: 6| Step: 9
Training loss: 0.09328502416610718
Validation loss: 1.4526478731504051

Epoch: 6| Step: 10
Training loss: 0.20016010105609894
Validation loss: 1.4509472462438768

Epoch: 6| Step: 11
Training loss: 0.1699228584766388
Validation loss: 1.4444692596312492

Epoch: 6| Step: 12
Training loss: 0.08721963316202164
Validation loss: 1.4385126816329135

Epoch: 6| Step: 13
Training loss: 0.05868203938007355
Validation loss: 1.4489536093127342

Epoch: 491| Step: 0
Training loss: 0.06595931947231293
Validation loss: 1.4574706374957997

Epoch: 6| Step: 1
Training loss: 0.12259477376937866
Validation loss: 1.4754195110772246

Epoch: 6| Step: 2
Training loss: 0.11086752265691757
Validation loss: 1.484508349049476

Epoch: 6| Step: 3
Training loss: 0.10705893486738205
Validation loss: 1.5143271466737152

Epoch: 6| Step: 4
Training loss: 0.11509688198566437
Validation loss: 1.4818058167734454

Epoch: 6| Step: 5
Training loss: 0.16097405552864075
Validation loss: 1.5110773437766618

Epoch: 6| Step: 6
Training loss: 0.1143963634967804
Validation loss: 1.4677740207282446

Epoch: 6| Step: 7
Training loss: 0.11216287314891815
Validation loss: 1.4661288184504355

Epoch: 6| Step: 8
Training loss: 0.0945829451084137
Validation loss: 1.4719029613720473

Epoch: 6| Step: 9
Training loss: 0.05395214632153511
Validation loss: 1.4440502415421188

Epoch: 6| Step: 10
Training loss: 0.06361401826143265
Validation loss: 1.444416760116495

Epoch: 6| Step: 11
Training loss: 0.11510903388261795
Validation loss: 1.4395521174194992

Epoch: 6| Step: 12
Training loss: 0.11479295045137405
Validation loss: 1.4555838056789931

Epoch: 6| Step: 13
Training loss: 0.07339984178543091
Validation loss: 1.4268129109054484

Epoch: 492| Step: 0
Training loss: 0.09616191685199738
Validation loss: 1.4211159995807114

Epoch: 6| Step: 1
Training loss: 0.08918328583240509
Validation loss: 1.4223925631533387

Epoch: 6| Step: 2
Training loss: 0.11715561896562576
Validation loss: 1.4505675890112435

Epoch: 6| Step: 3
Training loss: 0.1417189985513687
Validation loss: 1.4595522149916618

Epoch: 6| Step: 4
Training loss: 0.10041924566030502
Validation loss: 1.4504929678414458

Epoch: 6| Step: 5
Training loss: 0.06501787900924683
Validation loss: 1.4851057696086105

Epoch: 6| Step: 6
Training loss: 0.09696792811155319
Validation loss: 1.4747247952286915

Epoch: 6| Step: 7
Training loss: 0.08821626752614975
Validation loss: 1.4825909073634813

Epoch: 6| Step: 8
Training loss: 0.10156184434890747
Validation loss: 1.4855838103960919

Epoch: 6| Step: 9
Training loss: 0.12228021025657654
Validation loss: 1.4311332266817811

Epoch: 6| Step: 10
Training loss: 0.11882153153419495
Validation loss: 1.4775652936709824

Epoch: 6| Step: 11
Training loss: 0.1049630418419838
Validation loss: 1.4797245840872488

Epoch: 6| Step: 12
Training loss: 0.08040190488100052
Validation loss: 1.4709754913083968

Epoch: 6| Step: 13
Training loss: 0.05125672370195389
Validation loss: 1.4830986222913187

Epoch: 493| Step: 0
Training loss: 0.10709930956363678
Validation loss: 1.4327645173636816

Epoch: 6| Step: 1
Training loss: 0.15340670943260193
Validation loss: 1.4544947083278368

Epoch: 6| Step: 2
Training loss: 0.09244750440120697
Validation loss: 1.4358582894007366

Epoch: 6| Step: 3
Training loss: 0.0671619102358818
Validation loss: 1.443816734898475

Epoch: 6| Step: 4
Training loss: 0.06484095752239227
Validation loss: 1.4486577382651709

Epoch: 6| Step: 5
Training loss: 0.1687566488981247
Validation loss: 1.4587980829259402

Epoch: 6| Step: 6
Training loss: 0.06764256954193115
Validation loss: 1.4392762728916701

Epoch: 6| Step: 7
Training loss: 0.0814470425248146
Validation loss: 1.4710078059986074

Epoch: 6| Step: 8
Training loss: 0.1207050010561943
Validation loss: 1.4876526606980192

Epoch: 6| Step: 9
Training loss: 0.10397450625896454
Validation loss: 1.4680842186814995

Epoch: 6| Step: 10
Training loss: 0.06920218467712402
Validation loss: 1.527170604275119

Epoch: 6| Step: 11
Training loss: 0.14233165979385376
Validation loss: 1.508614533690996

Epoch: 6| Step: 12
Training loss: 0.11122193932533264
Validation loss: 1.4973749165893884

Epoch: 6| Step: 13
Training loss: 0.10333172976970673
Validation loss: 1.4965595173579391

Epoch: 494| Step: 0
Training loss: 0.07174824923276901
Validation loss: 1.5064086785880468

Epoch: 6| Step: 1
Training loss: 0.1080908551812172
Validation loss: 1.4755946365735864

Epoch: 6| Step: 2
Training loss: 0.08840294182300568
Validation loss: 1.4774049674310992

Epoch: 6| Step: 3
Training loss: 0.07684345543384552
Validation loss: 1.4539055221824235

Epoch: 6| Step: 4
Training loss: 0.10828626900911331
Validation loss: 1.4959839608079644

Epoch: 6| Step: 5
Training loss: 0.11164318025112152
Validation loss: 1.4862451707163165

Epoch: 6| Step: 6
Training loss: 0.1389787197113037
Validation loss: 1.4571469086472706

Epoch: 6| Step: 7
Training loss: 0.1006595566868782
Validation loss: 1.456968863805135

Epoch: 6| Step: 8
Training loss: 0.10022669285535812
Validation loss: 1.4763062859094271

Epoch: 6| Step: 9
Training loss: 0.066022127866745
Validation loss: 1.5074794061722294

Epoch: 6| Step: 10
Training loss: 0.05065552890300751
Validation loss: 1.526934104581033

Epoch: 6| Step: 11
Training loss: 0.10116002708673477
Validation loss: 1.5126800511472969

Epoch: 6| Step: 12
Training loss: 0.09488803893327713
Validation loss: 1.5664985846447688

Epoch: 6| Step: 13
Training loss: 0.1194961741566658
Validation loss: 1.5483336243578183

Epoch: 495| Step: 0
Training loss: 0.10152366757392883
Validation loss: 1.539997330275915

Epoch: 6| Step: 1
Training loss: 0.0643409788608551
Validation loss: 1.5409130178472048

Epoch: 6| Step: 2
Training loss: 0.09820803999900818
Validation loss: 1.5002966709034418

Epoch: 6| Step: 3
Training loss: 0.11606447398662567
Validation loss: 1.4562639767123806

Epoch: 6| Step: 4
Training loss: 0.06706732511520386
Validation loss: 1.461503996643969

Epoch: 6| Step: 5
Training loss: 0.11237455904483795
Validation loss: 1.468441741440886

Epoch: 6| Step: 6
Training loss: 0.11982175707817078
Validation loss: 1.4779216855443933

Epoch: 6| Step: 7
Training loss: 0.09767170995473862
Validation loss: 1.4544105939967658

Epoch: 6| Step: 8
Training loss: 0.04411705583333969
Validation loss: 1.4812365270430041

Epoch: 6| Step: 9
Training loss: 0.06762322038412094
Validation loss: 1.483532654341831

Epoch: 6| Step: 10
Training loss: 0.054535575211048126
Validation loss: 1.4715626226958407

Epoch: 6| Step: 11
Training loss: 0.1127312183380127
Validation loss: 1.4727190700910424

Epoch: 6| Step: 12
Training loss: 0.07994653284549713
Validation loss: 1.5274742303356048

Epoch: 6| Step: 13
Training loss: 0.11752597242593765
Validation loss: 1.5342961357485863

Epoch: 496| Step: 0
Training loss: 0.14321979880332947
Validation loss: 1.5102454282904183

Epoch: 6| Step: 1
Training loss: 0.08147436380386353
Validation loss: 1.534040613840985

Epoch: 6| Step: 2
Training loss: 0.09691337496042252
Validation loss: 1.4957825983724287

Epoch: 6| Step: 3
Training loss: 0.08084804564714432
Validation loss: 1.4775556518185524

Epoch: 6| Step: 4
Training loss: 0.05810108035802841
Validation loss: 1.4637569355708298

Epoch: 6| Step: 5
Training loss: 0.06860653311014175
Validation loss: 1.4453858278130973

Epoch: 6| Step: 6
Training loss: 0.11307154595851898
Validation loss: 1.4464576475081905

Epoch: 6| Step: 7
Training loss: 0.05422244220972061
Validation loss: 1.4778734304571663

Epoch: 6| Step: 8
Training loss: 0.0577022060751915
Validation loss: 1.4647906493115168

Epoch: 6| Step: 9
Training loss: 0.1203703060746193
Validation loss: 1.4430015522946593

Epoch: 6| Step: 10
Training loss: 0.10575680434703827
Validation loss: 1.484616498793325

Epoch: 6| Step: 11
Training loss: 0.07130992412567139
Validation loss: 1.4938767712603334

Epoch: 6| Step: 12
Training loss: 0.08316672593355179
Validation loss: 1.472548492493168

Epoch: 6| Step: 13
Training loss: 0.06966463476419449
Validation loss: 1.4754175447648572

Epoch: 497| Step: 0
Training loss: 0.07438190281391144
Validation loss: 1.461517188497769

Epoch: 6| Step: 1
Training loss: 0.12973234057426453
Validation loss: 1.4326723673010384

Epoch: 6| Step: 2
Training loss: 0.16954582929611206
Validation loss: 1.4310662797702256

Epoch: 6| Step: 3
Training loss: 0.08118025958538055
Validation loss: 1.4501977761586506

Epoch: 6| Step: 4
Training loss: 0.11609570682048798
Validation loss: 1.4320471171409852

Epoch: 6| Step: 5
Training loss: 0.0866246372461319
Validation loss: 1.4412715640119327

Epoch: 6| Step: 6
Training loss: 0.10753265023231506
Validation loss: 1.4556520215926632

Epoch: 6| Step: 7
Training loss: 0.09969371557235718
Validation loss: 1.4736437259181854

Epoch: 6| Step: 8
Training loss: 0.08405561745166779
Validation loss: 1.4985249683421145

Epoch: 6| Step: 9
Training loss: 0.1384461522102356
Validation loss: 1.478923237451943

Epoch: 6| Step: 10
Training loss: 0.04287710413336754
Validation loss: 1.5006435250723233

Epoch: 6| Step: 11
Training loss: 0.07384289056062698
Validation loss: 1.4853166123872161

Epoch: 6| Step: 12
Training loss: 0.0740695521235466
Validation loss: 1.491300529049289

Epoch: 6| Step: 13
Training loss: 0.09838870912790298
Validation loss: 1.4773758662644254

Epoch: 498| Step: 0
Training loss: 0.07844962924718857
Validation loss: 1.4692128935167867

Epoch: 6| Step: 1
Training loss: 0.10266115516424179
Validation loss: 1.5304602012839368

Epoch: 6| Step: 2
Training loss: 0.08800552785396576
Validation loss: 1.5002007830527522

Epoch: 6| Step: 3
Training loss: 0.1240779384970665
Validation loss: 1.4640144571181266

Epoch: 6| Step: 4
Training loss: 0.12391789257526398
Validation loss: 1.4937738878752596

Epoch: 6| Step: 5
Training loss: 0.08142877370119095
Validation loss: 1.4715593143176007

Epoch: 6| Step: 6
Training loss: 0.07869716733694077
Validation loss: 1.4680047958127913

Epoch: 6| Step: 7
Training loss: 0.08198447525501251
Validation loss: 1.4702803627137215

Epoch: 6| Step: 8
Training loss: 0.1558249294757843
Validation loss: 1.4591359617889568

Epoch: 6| Step: 9
Training loss: 0.18194425106048584
Validation loss: 1.4612160767278364

Epoch: 6| Step: 10
Training loss: 0.1347278207540512
Validation loss: 1.467695870707112

Epoch: 6| Step: 11
Training loss: 0.09353464841842651
Validation loss: 1.471551170913122

Epoch: 6| Step: 12
Training loss: 0.14957885444164276
Validation loss: 1.4682861553725375

Epoch: 6| Step: 13
Training loss: 0.061478838324546814
Validation loss: 1.4309943081230245

Epoch: 499| Step: 0
Training loss: 0.10288640856742859
Validation loss: 1.4412537262003908

Epoch: 6| Step: 1
Training loss: 0.06797417998313904
Validation loss: 1.4584281739368234

Epoch: 6| Step: 2
Training loss: 0.065848708152771
Validation loss: 1.433379518088474

Epoch: 6| Step: 3
Training loss: 0.2150733470916748
Validation loss: 1.4957159398704447

Epoch: 6| Step: 4
Training loss: 0.08415588736534119
Validation loss: 1.4666695825515255

Epoch: 6| Step: 5
Training loss: 0.08317685127258301
Validation loss: 1.4739722808202107

Epoch: 6| Step: 6
Training loss: 0.07417990267276764
Validation loss: 1.4881704135607647

Epoch: 6| Step: 7
Training loss: 0.15546703338623047
Validation loss: 1.4920324253779587

Epoch: 6| Step: 8
Training loss: 0.07448941469192505
Validation loss: 1.5072024932471655

Epoch: 6| Step: 9
Training loss: 0.07886792719364166
Validation loss: 1.495759681988788

Epoch: 6| Step: 10
Training loss: 0.06471017748117447
Validation loss: 1.4920380884601223

Epoch: 6| Step: 11
Training loss: 0.13280782103538513
Validation loss: 1.5079710739915089

Epoch: 6| Step: 12
Training loss: 0.06949324905872345
Validation loss: 1.482404323034389

Epoch: 6| Step: 13
Training loss: 0.04537217319011688
Validation loss: 1.471488360435732

Epoch: 500| Step: 0
Training loss: 0.13007330894470215
Validation loss: 1.4620327590614237

Epoch: 6| Step: 1
Training loss: 0.09995846450328827
Validation loss: 1.4615502408755723

Epoch: 6| Step: 2
Training loss: 0.08238032460212708
Validation loss: 1.4855081906882666

Epoch: 6| Step: 3
Training loss: 0.09187014400959015
Validation loss: 1.461978623943944

Epoch: 6| Step: 4
Training loss: 0.09323026984930038
Validation loss: 1.4734235437967445

Epoch: 6| Step: 5
Training loss: 0.1217530146241188
Validation loss: 1.4784929265258133

Epoch: 6| Step: 6
Training loss: 0.14835616946220398
Validation loss: 1.5034798601622223

Epoch: 6| Step: 7
Training loss: 0.08642712235450745
Validation loss: 1.4869040404596636

Epoch: 6| Step: 8
Training loss: 0.09957611560821533
Validation loss: 1.4900169295649375

Epoch: 6| Step: 9
Training loss: 0.13666996359825134
Validation loss: 1.5053295858444706

Epoch: 6| Step: 10
Training loss: 0.12509119510650635
Validation loss: 1.4861176193401378

Epoch: 6| Step: 11
Training loss: 0.10325559228658676
Validation loss: 1.487182222386842

Epoch: 6| Step: 12
Training loss: 0.07345552742481232
Validation loss: 1.471907816907411

Epoch: 6| Step: 13
Training loss: 0.07918259501457214
Validation loss: 1.4879344445402904

Epoch: 501| Step: 0
Training loss: 0.09428142011165619
Validation loss: 1.5003462414587698

Epoch: 6| Step: 1
Training loss: 0.13109774887561798
Validation loss: 1.5134763948379024

Epoch: 6| Step: 2
Training loss: 0.11148466169834137
Validation loss: 1.5306583668596

Epoch: 6| Step: 3
Training loss: 0.058858659118413925
Validation loss: 1.5027377419574286

Epoch: 6| Step: 4
Training loss: 0.10429473221302032
Validation loss: 1.5249744948520456

Epoch: 6| Step: 5
Training loss: 0.12644191086292267
Validation loss: 1.5034790974791332

Epoch: 6| Step: 6
Training loss: 0.1000097393989563
Validation loss: 1.517228748208733

Epoch: 6| Step: 7
Training loss: 0.09076351672410965
Validation loss: 1.5078626005880293

Epoch: 6| Step: 8
Training loss: 0.16744081676006317
Validation loss: 1.5206774973100232

Epoch: 6| Step: 9
Training loss: 0.0649992823600769
Validation loss: 1.4771179114618609

Epoch: 6| Step: 10
Training loss: 0.10210084915161133
Validation loss: 1.4816590624470865

Epoch: 6| Step: 11
Training loss: 0.0989258885383606
Validation loss: 1.4847865002129668

Epoch: 6| Step: 12
Training loss: 0.07418875396251678
Validation loss: 1.4794212233635686

Epoch: 6| Step: 13
Training loss: 0.17366743087768555
Validation loss: 1.507950662284769

Epoch: 502| Step: 0
Training loss: 0.07226726412773132
Validation loss: 1.4776615494041032

Epoch: 6| Step: 1
Training loss: 0.07090243697166443
Validation loss: 1.4663416595869168

Epoch: 6| Step: 2
Training loss: 0.09426897764205933
Validation loss: 1.4877781368071032

Epoch: 6| Step: 3
Training loss: 0.09042595326900482
Validation loss: 1.497715179638196

Epoch: 6| Step: 4
Training loss: 0.0538519024848938
Validation loss: 1.4629195377390871

Epoch: 6| Step: 5
Training loss: 0.08801209926605225
Validation loss: 1.4838362413067971

Epoch: 6| Step: 6
Training loss: 0.10388657450675964
Validation loss: 1.4889592797525468

Epoch: 6| Step: 7
Training loss: 0.09836070984601974
Validation loss: 1.475601965381253

Epoch: 6| Step: 8
Training loss: 0.1387411206960678
Validation loss: 1.470252840749679

Epoch: 6| Step: 9
Training loss: 0.07236842066049576
Validation loss: 1.5019284717498287

Epoch: 6| Step: 10
Training loss: 0.08571438491344452
Validation loss: 1.5107305972806868

Epoch: 6| Step: 11
Training loss: 0.05158960819244385
Validation loss: 1.522239367167155

Epoch: 6| Step: 12
Training loss: 0.055219195783138275
Validation loss: 1.5164008986565374

Epoch: 6| Step: 13
Training loss: 0.05925193056464195
Validation loss: 1.4948196180405156

Epoch: 503| Step: 0
Training loss: 0.12108997255563736
Validation loss: 1.4921152245613836

Epoch: 6| Step: 1
Training loss: 0.09526485204696655
Validation loss: 1.4624205532894339

Epoch: 6| Step: 2
Training loss: 0.09150245785713196
Validation loss: 1.4784040451049805

Epoch: 6| Step: 3
Training loss: 0.11846461892127991
Validation loss: 1.4559082702923847

Epoch: 6| Step: 4
Training loss: 0.1453157663345337
Validation loss: 1.4746625179885535

Epoch: 6| Step: 5
Training loss: 0.06500040739774704
Validation loss: 1.4543074971886092

Epoch: 6| Step: 6
Training loss: 0.12548059225082397
Validation loss: 1.4431105557308401

Epoch: 6| Step: 7
Training loss: 0.06833784282207489
Validation loss: 1.4422106178857947

Epoch: 6| Step: 8
Training loss: 0.052747055888175964
Validation loss: 1.4577564244629235

Epoch: 6| Step: 9
Training loss: 0.08224248886108398
Validation loss: 1.46122186030111

Epoch: 6| Step: 10
Training loss: 0.08081623911857605
Validation loss: 1.470805424515919

Epoch: 6| Step: 11
Training loss: 0.1082066148519516
Validation loss: 1.4496551540590101

Epoch: 6| Step: 12
Training loss: 0.08019125461578369
Validation loss: 1.4644477149491668

Epoch: 6| Step: 13
Training loss: 0.0894518792629242
Validation loss: 1.471173612020349

Epoch: 504| Step: 0
Training loss: 0.1126522570848465
Validation loss: 1.47160094271424

Epoch: 6| Step: 1
Training loss: 0.06505580246448517
Validation loss: 1.4951691114774315

Epoch: 6| Step: 2
Training loss: 0.07896645367145538
Validation loss: 1.4732990079028632

Epoch: 6| Step: 3
Training loss: 0.09374784678220749
Validation loss: 1.4665524145608306

Epoch: 6| Step: 4
Training loss: 0.05180899798870087
Validation loss: 1.4439769701291156

Epoch: 6| Step: 5
Training loss: 0.10360822826623917
Validation loss: 1.4620077263924383

Epoch: 6| Step: 6
Training loss: 0.1511807143688202
Validation loss: 1.4831705465111682

Epoch: 6| Step: 7
Training loss: 0.10261283069849014
Validation loss: 1.4723036801943215

Epoch: 6| Step: 8
Training loss: 0.12015201151371002
Validation loss: 1.4633895735586844

Epoch: 6| Step: 9
Training loss: 0.13594123721122742
Validation loss: 1.4559140871929865

Epoch: 6| Step: 10
Training loss: 0.12763096392154694
Validation loss: 1.4896909895763601

Epoch: 6| Step: 11
Training loss: 0.06012474372982979
Validation loss: 1.484819446840594

Epoch: 6| Step: 12
Training loss: 0.07353714853525162
Validation loss: 1.5140424825811898

Epoch: 6| Step: 13
Training loss: 0.2100576013326645
Validation loss: 1.5092515996707383

Epoch: 505| Step: 0
Training loss: 0.1398652344942093
Validation loss: 1.5109283616465907

Epoch: 6| Step: 1
Training loss: 0.09059420228004456
Validation loss: 1.4673973116823422

Epoch: 6| Step: 2
Training loss: 0.08326739072799683
Validation loss: 1.4635263873684792

Epoch: 6| Step: 3
Training loss: 0.10589363425970078
Validation loss: 1.4770354814426874

Epoch: 6| Step: 4
Training loss: 0.0594407320022583
Validation loss: 1.4751796876230547

Epoch: 6| Step: 5
Training loss: 0.11419399082660675
Validation loss: 1.4647577565203431

Epoch: 6| Step: 6
Training loss: 0.08863969892263412
Validation loss: 1.4646786451339722

Epoch: 6| Step: 7
Training loss: 0.10842327028512955
Validation loss: 1.4611971506508448

Epoch: 6| Step: 8
Training loss: 0.09758901596069336
Validation loss: 1.4751030129771079

Epoch: 6| Step: 9
Training loss: 0.12155550718307495
Validation loss: 1.494842767715454

Epoch: 6| Step: 10
Training loss: 0.10063515603542328
Validation loss: 1.52018399905133

Epoch: 6| Step: 11
Training loss: 0.08835764229297638
Validation loss: 1.5187804596398466

Epoch: 6| Step: 12
Training loss: 0.0732712522149086
Validation loss: 1.5311262248664774

Epoch: 6| Step: 13
Training loss: 0.09258366376161575
Validation loss: 1.5585271222617036

Epoch: 506| Step: 0
Training loss: 0.09134814143180847
Validation loss: 1.515010028757075

Epoch: 6| Step: 1
Training loss: 0.08582330495119095
Validation loss: 1.4980260018379457

Epoch: 6| Step: 2
Training loss: 0.05460073798894882
Validation loss: 1.5030144940140426

Epoch: 6| Step: 3
Training loss: 0.09677082300186157
Validation loss: 1.4862113537326935

Epoch: 6| Step: 4
Training loss: 0.10399442911148071
Validation loss: 1.481467059863511

Epoch: 6| Step: 5
Training loss: 0.09735368937253952
Validation loss: 1.4882457563954015

Epoch: 6| Step: 6
Training loss: 0.08800458908081055
Validation loss: 1.4714479100319646

Epoch: 6| Step: 7
Training loss: 0.1113961935043335
Validation loss: 1.4771962742651663

Epoch: 6| Step: 8
Training loss: 0.049097903072834015
Validation loss: 1.4446616134335917

Epoch: 6| Step: 9
Training loss: 0.12346532940864563
Validation loss: 1.4671515425046284

Epoch: 6| Step: 10
Training loss: 0.09367601573467255
Validation loss: 1.472832381084401

Epoch: 6| Step: 11
Training loss: 0.14079508185386658
Validation loss: 1.4758884932405205

Epoch: 6| Step: 12
Training loss: 0.07889692485332489
Validation loss: 1.4646743856450564

Epoch: 6| Step: 13
Training loss: 0.06550103425979614
Validation loss: 1.4894122487755233

Epoch: 507| Step: 0
Training loss: 0.1212998479604721
Validation loss: 1.476032933881206

Epoch: 6| Step: 1
Training loss: 0.057077303528785706
Validation loss: 1.4843372709007674

Epoch: 6| Step: 2
Training loss: 0.14335530996322632
Validation loss: 1.4998358629083122

Epoch: 6| Step: 3
Training loss: 0.08864299952983856
Validation loss: 1.4985803442616616

Epoch: 6| Step: 4
Training loss: 0.0888291597366333
Validation loss: 1.4870387418295747

Epoch: 6| Step: 5
Training loss: 0.09781847894191742
Validation loss: 1.505475862051851

Epoch: 6| Step: 6
Training loss: 0.10408802330493927
Validation loss: 1.4800381532279394

Epoch: 6| Step: 7
Training loss: 0.12000687420368195
Validation loss: 1.4754210889980357

Epoch: 6| Step: 8
Training loss: 0.1377524435520172
Validation loss: 1.4864069633586432

Epoch: 6| Step: 9
Training loss: 0.1354639232158661
Validation loss: 1.491444271097901

Epoch: 6| Step: 10
Training loss: 0.07726038992404938
Validation loss: 1.4808272366882653

Epoch: 6| Step: 11
Training loss: 0.13511942327022552
Validation loss: 1.46895460672276

Epoch: 6| Step: 12
Training loss: 0.09576672315597534
Validation loss: 1.4735877052430184

Epoch: 6| Step: 13
Training loss: 0.09573699533939362
Validation loss: 1.4731979190662343

Epoch: 508| Step: 0
Training loss: 0.06990377604961395
Validation loss: 1.4966688386855587

Epoch: 6| Step: 1
Training loss: 0.1181328296661377
Validation loss: 1.495174402831703

Epoch: 6| Step: 2
Training loss: 0.08420965075492859
Validation loss: 1.4533028307781424

Epoch: 6| Step: 3
Training loss: 0.0905495434999466
Validation loss: 1.4970424623899563

Epoch: 6| Step: 4
Training loss: 0.14793258905410767
Validation loss: 1.4860984074172152

Epoch: 6| Step: 5
Training loss: 0.10858574509620667
Validation loss: 1.5065256408465806

Epoch: 6| Step: 6
Training loss: 0.1019502505660057
Validation loss: 1.5132235519347652

Epoch: 6| Step: 7
Training loss: 0.09317021071910858
Validation loss: 1.4730383247457526

Epoch: 6| Step: 8
Training loss: 0.0787259042263031
Validation loss: 1.5009836637845604

Epoch: 6| Step: 9
Training loss: 0.1300211250782013
Validation loss: 1.4786345958709717

Epoch: 6| Step: 10
Training loss: 0.07453591376543045
Validation loss: 1.473841323647448

Epoch: 6| Step: 11
Training loss: 0.07903531938791275
Validation loss: 1.4643794721172703

Epoch: 6| Step: 12
Training loss: 0.054039839655160904
Validation loss: 1.4514533005734926

Epoch: 6| Step: 13
Training loss: 0.06830022484064102
Validation loss: 1.4703937589481313

Epoch: 509| Step: 0
Training loss: 0.11076731979846954
Validation loss: 1.4632033673665856

Epoch: 6| Step: 1
Training loss: 0.05460268631577492
Validation loss: 1.4753469895291071

Epoch: 6| Step: 2
Training loss: 0.0666978657245636
Validation loss: 1.4566307721599456

Epoch: 6| Step: 3
Training loss: 0.10161501169204712
Validation loss: 1.4634706461301414

Epoch: 6| Step: 4
Training loss: 0.0598302036523819
Validation loss: 1.4524236545767835

Epoch: 6| Step: 5
Training loss: 0.09865665435791016
Validation loss: 1.4675244323668941

Epoch: 6| Step: 6
Training loss: 0.0631866380572319
Validation loss: 1.4635788606059166

Epoch: 6| Step: 7
Training loss: 0.06700340658426285
Validation loss: 1.4573960150441816

Epoch: 6| Step: 8
Training loss: 0.08384809643030167
Validation loss: 1.4310048690406225

Epoch: 6| Step: 9
Training loss: 0.1667727530002594
Validation loss: 1.4632154472412602

Epoch: 6| Step: 10
Training loss: 0.07016363739967346
Validation loss: 1.4332947897654709

Epoch: 6| Step: 11
Training loss: 0.1229420155286789
Validation loss: 1.4501473615246434

Epoch: 6| Step: 12
Training loss: 0.1251264214515686
Validation loss: 1.4568506838172994

Epoch: 6| Step: 13
Training loss: 0.07998193800449371
Validation loss: 1.4722544147122292

Epoch: 510| Step: 0
Training loss: 0.06507130712270737
Validation loss: 1.45345139503479

Epoch: 6| Step: 1
Training loss: 0.060004301369190216
Validation loss: 1.4741059464793052

Epoch: 6| Step: 2
Training loss: 0.09180688112974167
Validation loss: 1.4852850039800007

Epoch: 6| Step: 3
Training loss: 0.0504041463136673
Validation loss: 1.4999130361823625

Epoch: 6| Step: 4
Training loss: 0.07630505412817001
Validation loss: 1.5094380660723614

Epoch: 6| Step: 5
Training loss: 0.06931839883327484
Validation loss: 1.4928821697030017

Epoch: 6| Step: 6
Training loss: 0.08390301465988159
Validation loss: 1.4758203734633744

Epoch: 6| Step: 7
Training loss: 0.1527141034603119
Validation loss: 1.448064975841071

Epoch: 6| Step: 8
Training loss: 0.04681922122836113
Validation loss: 1.4599702332609443

Epoch: 6| Step: 9
Training loss: 0.1021975502371788
Validation loss: 1.4618846344691452

Epoch: 6| Step: 10
Training loss: 0.07580249011516571
Validation loss: 1.4392353514189362

Epoch: 6| Step: 11
Training loss: 0.07048412412405014
Validation loss: 1.4294785338063394

Epoch: 6| Step: 12
Training loss: 0.055296964943408966
Validation loss: 1.4366764496731501

Epoch: 6| Step: 13
Training loss: 0.1271411031484604
Validation loss: 1.4635606786256194

Epoch: 511| Step: 0
Training loss: 0.08394814282655716
Validation loss: 1.4379303878353489

Epoch: 6| Step: 1
Training loss: 0.07094519585371017
Validation loss: 1.4248618477134294

Epoch: 6| Step: 2
Training loss: 0.0653897374868393
Validation loss: 1.451545657650117

Epoch: 6| Step: 3
Training loss: 0.15318839251995087
Validation loss: 1.463714430409093

Epoch: 6| Step: 4
Training loss: 0.06374073773622513
Validation loss: 1.4772059609813075

Epoch: 6| Step: 5
Training loss: 0.05926457792520523
Validation loss: 1.466064537725141

Epoch: 6| Step: 6
Training loss: 0.15975727140903473
Validation loss: 1.5240647587724911

Epoch: 6| Step: 7
Training loss: 0.16288581490516663
Validation loss: 1.526860652431365

Epoch: 6| Step: 8
Training loss: 0.13123902678489685
Validation loss: 1.5095963055087673

Epoch: 6| Step: 9
Training loss: 0.09000115096569061
Validation loss: 1.5220313790023967

Epoch: 6| Step: 10
Training loss: 0.09476777166128159
Validation loss: 1.5091599636180426

Epoch: 6| Step: 11
Training loss: 0.0669078454375267
Validation loss: 1.5004899283891082

Epoch: 6| Step: 12
Training loss: 0.0889355018734932
Validation loss: 1.496191470853744

Epoch: 6| Step: 13
Training loss: 0.07481375336647034
Validation loss: 1.4967995907670708

Epoch: 512| Step: 0
Training loss: 0.1245318353176117
Validation loss: 1.4910725393602926

Epoch: 6| Step: 1
Training loss: 0.12312143296003342
Validation loss: 1.4568442144701559

Epoch: 6| Step: 2
Training loss: 0.10937686264514923
Validation loss: 1.4610335878146592

Epoch: 6| Step: 3
Training loss: 0.09572765231132507
Validation loss: 1.445832815221561

Epoch: 6| Step: 4
Training loss: 0.10353286564350128
Validation loss: 1.4439919635813723

Epoch: 6| Step: 5
Training loss: 0.11589313298463821
Validation loss: 1.450371039811001

Epoch: 6| Step: 6
Training loss: 0.07521024346351624
Validation loss: 1.4509306280843672

Epoch: 6| Step: 7
Training loss: 0.11749628186225891
Validation loss: 1.4483291231175905

Epoch: 6| Step: 8
Training loss: 0.09547358751296997
Validation loss: 1.4259814613608903

Epoch: 6| Step: 9
Training loss: 0.09533821791410446
Validation loss: 1.4705878823034224

Epoch: 6| Step: 10
Training loss: 0.05217479541897774
Validation loss: 1.4634435587031867

Epoch: 6| Step: 11
Training loss: 0.06839404255151749
Validation loss: 1.4728527940729612

Epoch: 6| Step: 12
Training loss: 0.13538169860839844
Validation loss: 1.4666589306246849

Epoch: 6| Step: 13
Training loss: 0.04963719844818115
Validation loss: 1.5063281443811232

Epoch: 513| Step: 0
Training loss: 0.07879739999771118
Validation loss: 1.4621045076718895

Epoch: 6| Step: 1
Training loss: 0.08900287002325058
Validation loss: 1.4828708710209015

Epoch: 6| Step: 2
Training loss: 0.09932305663824081
Validation loss: 1.4660541959988174

Epoch: 6| Step: 3
Training loss: 0.10033322870731354
Validation loss: 1.4556955573379353

Epoch: 6| Step: 4
Training loss: 0.05106058716773987
Validation loss: 1.4629334967623475

Epoch: 6| Step: 5
Training loss: 0.08362089097499847
Validation loss: 1.4674647610674623

Epoch: 6| Step: 6
Training loss: 0.13852372765541077
Validation loss: 1.4568346085086945

Epoch: 6| Step: 7
Training loss: 0.09782896190881729
Validation loss: 1.4801856958737938

Epoch: 6| Step: 8
Training loss: 0.0696701779961586
Validation loss: 1.4522075704348985

Epoch: 6| Step: 9
Training loss: 0.08395865559577942
Validation loss: 1.4831117353131693

Epoch: 6| Step: 10
Training loss: 0.07235570251941681
Validation loss: 1.457849770463923

Epoch: 6| Step: 11
Training loss: 0.07507878541946411
Validation loss: 1.4640301337806128

Epoch: 6| Step: 12
Training loss: 0.07178867608308792
Validation loss: 1.4561790381708453

Epoch: 6| Step: 13
Training loss: 0.08495133370161057
Validation loss: 1.4541749262040662

Epoch: 514| Step: 0
Training loss: 0.11400224268436432
Validation loss: 1.4225540186769219

Epoch: 6| Step: 1
Training loss: 0.07482641935348511
Validation loss: 1.4486062680521319

Epoch: 6| Step: 2
Training loss: 0.0894189178943634
Validation loss: 1.4576792550343338

Epoch: 6| Step: 3
Training loss: 0.09736106544733047
Validation loss: 1.4501599522047146

Epoch: 6| Step: 4
Training loss: 0.06753195822238922
Validation loss: 1.4627385844466507

Epoch: 6| Step: 5
Training loss: 0.09258110076189041
Validation loss: 1.4677962718471405

Epoch: 6| Step: 6
Training loss: 0.09811906516551971
Validation loss: 1.4674558472889725

Epoch: 6| Step: 7
Training loss: 0.09006236493587494
Validation loss: 1.4678139404584003

Epoch: 6| Step: 8
Training loss: 0.10966303944587708
Validation loss: 1.4737351991797005

Epoch: 6| Step: 9
Training loss: 0.04877970367670059
Validation loss: 1.474123263871798

Epoch: 6| Step: 10
Training loss: 0.14452382922172546
Validation loss: 1.4599559986463158

Epoch: 6| Step: 11
Training loss: 0.050766319036483765
Validation loss: 1.4807009850778887

Epoch: 6| Step: 12
Training loss: 0.08040434122085571
Validation loss: 1.4767292161141672

Epoch: 6| Step: 13
Training loss: 0.09129101783037186
Validation loss: 1.4814721679174772

Epoch: 515| Step: 0
Training loss: 0.06581298261880875
Validation loss: 1.4948851626406434

Epoch: 6| Step: 1
Training loss: 0.07709497213363647
Validation loss: 1.5450362069632417

Epoch: 6| Step: 2
Training loss: 0.08421535789966583
Validation loss: 1.5230077312838646

Epoch: 6| Step: 3
Training loss: 0.14739836752414703
Validation loss: 1.5260497331619263

Epoch: 6| Step: 4
Training loss: 0.10943436622619629
Validation loss: 1.5138906689100369

Epoch: 6| Step: 5
Training loss: 0.0791943371295929
Validation loss: 1.4858884247400428

Epoch: 6| Step: 6
Training loss: 0.13489896059036255
Validation loss: 1.457592369407736

Epoch: 6| Step: 7
Training loss: 0.08258056640625
Validation loss: 1.4362499098623953

Epoch: 6| Step: 8
Training loss: 0.08292555809020996
Validation loss: 1.4296187059853667

Epoch: 6| Step: 9
Training loss: 0.11278845369815826
Validation loss: 1.4454887067117999

Epoch: 6| Step: 10
Training loss: 0.14046525955200195
Validation loss: 1.454438340279364

Epoch: 6| Step: 11
Training loss: 0.0971386656165123
Validation loss: 1.4426874204348492

Epoch: 6| Step: 12
Training loss: 0.12948483228683472
Validation loss: 1.4252497124415573

Epoch: 6| Step: 13
Training loss: 0.12475400418043137
Validation loss: 1.433165083649338

Epoch: 516| Step: 0
Training loss: 0.09204860031604767
Validation loss: 1.4775439705899966

Epoch: 6| Step: 1
Training loss: 0.11618800461292267
Validation loss: 1.4912035888241184

Epoch: 6| Step: 2
Training loss: 0.11916953325271606
Validation loss: 1.4983164636037682

Epoch: 6| Step: 3
Training loss: 0.12264389544725418
Validation loss: 1.543321151887217

Epoch: 6| Step: 4
Training loss: 0.1557374745607376
Validation loss: 1.5271748714549567

Epoch: 6| Step: 5
Training loss: 0.15066352486610413
Validation loss: 1.5327164075707878

Epoch: 6| Step: 6
Training loss: 0.12734603881835938
Validation loss: 1.501760224501292

Epoch: 6| Step: 7
Training loss: 0.1123940721154213
Validation loss: 1.4663205967154553

Epoch: 6| Step: 8
Training loss: 0.097979336977005
Validation loss: 1.5023798705429159

Epoch: 6| Step: 9
Training loss: 0.16756147146224976
Validation loss: 1.4805975050054572

Epoch: 6| Step: 10
Training loss: 0.10398638993501663
Validation loss: 1.4702741894670712

Epoch: 6| Step: 11
Training loss: 0.1023435890674591
Validation loss: 1.474119451738173

Epoch: 6| Step: 12
Training loss: 0.07380667328834534
Validation loss: 1.4518206452810636

Epoch: 6| Step: 13
Training loss: 0.10834047198295593
Validation loss: 1.4646606035129999

Epoch: 517| Step: 0
Training loss: 0.1010650098323822
Validation loss: 1.4657757692439581

Epoch: 6| Step: 1
Training loss: 0.1253347545862198
Validation loss: 1.4792197173641575

Epoch: 6| Step: 2
Training loss: 0.10300429165363312
Validation loss: 1.4646733460887786

Epoch: 6| Step: 3
Training loss: 0.08742488920688629
Validation loss: 1.4479070965961744

Epoch: 6| Step: 4
Training loss: 0.060860972851514816
Validation loss: 1.4659806720672115

Epoch: 6| Step: 5
Training loss: 0.10973557829856873
Validation loss: 1.4524293958499868

Epoch: 6| Step: 6
Training loss: 0.08239959180355072
Validation loss: 1.4626163116065405

Epoch: 6| Step: 7
Training loss: 0.10292357206344604
Validation loss: 1.4809248255145164

Epoch: 6| Step: 8
Training loss: 0.12477777153253555
Validation loss: 1.4598605312326902

Epoch: 6| Step: 9
Training loss: 0.0927303284406662
Validation loss: 1.4522143051188479

Epoch: 6| Step: 10
Training loss: 0.08146810531616211
Validation loss: 1.4339720767031434

Epoch: 6| Step: 11
Training loss: 0.08585655689239502
Validation loss: 1.4400840440104086

Epoch: 6| Step: 12
Training loss: 0.05417121946811676
Validation loss: 1.4497538779371528

Epoch: 6| Step: 13
Training loss: 0.10145652294158936
Validation loss: 1.4406406392333329

Epoch: 518| Step: 0
Training loss: 0.06106218323111534
Validation loss: 1.455693265443207

Epoch: 6| Step: 1
Training loss: 0.05894322693347931
Validation loss: 1.4667977735560427

Epoch: 6| Step: 2
Training loss: 0.09683257341384888
Validation loss: 1.4734224132312241

Epoch: 6| Step: 3
Training loss: 0.060207728296518326
Validation loss: 1.4742046915074831

Epoch: 6| Step: 4
Training loss: 0.13942202925682068
Validation loss: 1.4519093177651847

Epoch: 6| Step: 5
Training loss: 0.11693589389324188
Validation loss: 1.456420248554599

Epoch: 6| Step: 6
Training loss: 0.07587125897407532
Validation loss: 1.4400869031106271

Epoch: 6| Step: 7
Training loss: 0.0710785984992981
Validation loss: 1.4505244852394186

Epoch: 6| Step: 8
Training loss: 0.05126543343067169
Validation loss: 1.4531920629162942

Epoch: 6| Step: 9
Training loss: 0.08552753925323486
Validation loss: 1.4231101492399811

Epoch: 6| Step: 10
Training loss: 0.09201490879058838
Validation loss: 1.435697978542697

Epoch: 6| Step: 11
Training loss: 0.06851641088724136
Validation loss: 1.4269148431798464

Epoch: 6| Step: 12
Training loss: 0.09414464980363846
Validation loss: 1.4602337819273754

Epoch: 6| Step: 13
Training loss: 0.1710393726825714
Validation loss: 1.4024810534651562

Epoch: 519| Step: 0
Training loss: 0.07785066962242126
Validation loss: 1.4287572022407287

Epoch: 6| Step: 1
Training loss: 0.07561609148979187
Validation loss: 1.45451880398617

Epoch: 6| Step: 2
Training loss: 0.06512247771024704
Validation loss: 1.4442508861582766

Epoch: 6| Step: 3
Training loss: 0.09256015717983246
Validation loss: 1.4372117160468973

Epoch: 6| Step: 4
Training loss: 0.09176476299762726
Validation loss: 1.444179186256983

Epoch: 6| Step: 5
Training loss: 0.08265423774719238
Validation loss: 1.4303725201596496

Epoch: 6| Step: 6
Training loss: 0.14906953275203705
Validation loss: 1.4761669366590437

Epoch: 6| Step: 7
Training loss: 0.13034610450267792
Validation loss: 1.4864992172487321

Epoch: 6| Step: 8
Training loss: 0.0798010379076004
Validation loss: 1.5019546567752797

Epoch: 6| Step: 9
Training loss: 0.07901902496814728
Validation loss: 1.4957786439567484

Epoch: 6| Step: 10
Training loss: 0.05722964555025101
Validation loss: 1.5023014308303915

Epoch: 6| Step: 11
Training loss: 0.0900171622633934
Validation loss: 1.511134542444701

Epoch: 6| Step: 12
Training loss: 0.08314645290374756
Validation loss: 1.5168192245626961

Epoch: 6| Step: 13
Training loss: 0.12798775732517242
Validation loss: 1.5418133492110877

Epoch: 520| Step: 0
Training loss: 0.0894894078373909
Validation loss: 1.5426710036493116

Epoch: 6| Step: 1
Training loss: 0.07686294615268707
Validation loss: 1.535098022030246

Epoch: 6| Step: 2
Training loss: 0.08494756370782852
Validation loss: 1.495211757639403

Epoch: 6| Step: 3
Training loss: 0.07780805975198746
Validation loss: 1.4875186380519663

Epoch: 6| Step: 4
Training loss: 0.15515148639678955
Validation loss: 1.4651448239562332

Epoch: 6| Step: 5
Training loss: 0.09439690411090851
Validation loss: 1.471921968203719

Epoch: 6| Step: 6
Training loss: 0.05307313799858093
Validation loss: 1.4661572947297046

Epoch: 6| Step: 7
Training loss: 0.10318406671285629
Validation loss: 1.4625327984491985

Epoch: 6| Step: 8
Training loss: 0.09914009273052216
Validation loss: 1.4559903055109003

Epoch: 6| Step: 9
Training loss: 0.11561387032270432
Validation loss: 1.4540948637070195

Epoch: 6| Step: 10
Training loss: 0.09627243131399155
Validation loss: 1.4456941825087353

Epoch: 6| Step: 11
Training loss: 0.12137952446937561
Validation loss: 1.4574647936769711

Epoch: 6| Step: 12
Training loss: 0.13938428461551666
Validation loss: 1.446399131769775

Epoch: 6| Step: 13
Training loss: 0.1007387638092041
Validation loss: 1.4292063777164747

Epoch: 521| Step: 0
Training loss: 0.1269848793745041
Validation loss: 1.4309224300487067

Epoch: 6| Step: 1
Training loss: 0.07633315026760101
Validation loss: 1.4357531378346104

Epoch: 6| Step: 2
Training loss: 0.10733345150947571
Validation loss: 1.43276269589701

Epoch: 6| Step: 3
Training loss: 0.10385486483573914
Validation loss: 1.4301039121484245

Epoch: 6| Step: 4
Training loss: 0.09471136331558228
Validation loss: 1.457314105444057

Epoch: 6| Step: 5
Training loss: 0.12226502597332001
Validation loss: 1.482294169805383

Epoch: 6| Step: 6
Training loss: 0.07784517109394073
Validation loss: 1.4778281591271842

Epoch: 6| Step: 7
Training loss: 0.10261838138103485
Validation loss: 1.4595415348647742

Epoch: 6| Step: 8
Training loss: 0.0783623456954956
Validation loss: 1.4580589494397562

Epoch: 6| Step: 9
Training loss: 0.08485391736030579
Validation loss: 1.4540276206949705

Epoch: 6| Step: 10
Training loss: 0.06420305371284485
Validation loss: 1.4637745759820426

Epoch: 6| Step: 11
Training loss: 0.0881439745426178
Validation loss: 1.4563821746457009

Epoch: 6| Step: 12
Training loss: 0.04409996420145035
Validation loss: 1.4395929151965725

Epoch: 6| Step: 13
Training loss: 0.037225142121315
Validation loss: 1.459545305980149

Epoch: 522| Step: 0
Training loss: 0.10981491953134537
Validation loss: 1.449038290849296

Epoch: 6| Step: 1
Training loss: 0.06834639608860016
Validation loss: 1.4585977100556897

Epoch: 6| Step: 2
Training loss: 0.09912413358688354
Validation loss: 1.4604570801540087

Epoch: 6| Step: 3
Training loss: 0.08823546022176743
Validation loss: 1.4778738252578243

Epoch: 6| Step: 4
Training loss: 0.07155738770961761
Validation loss: 1.4802245055475542

Epoch: 6| Step: 5
Training loss: 0.07619421184062958
Validation loss: 1.456533153851827

Epoch: 6| Step: 6
Training loss: 0.07157494872808456
Validation loss: 1.4630833646302581

Epoch: 6| Step: 7
Training loss: 0.11709689348936081
Validation loss: 1.4577749749665618

Epoch: 6| Step: 8
Training loss: 0.06686370074748993
Validation loss: 1.49043067168164

Epoch: 6| Step: 9
Training loss: 0.08038278669118881
Validation loss: 1.455919437510993

Epoch: 6| Step: 10
Training loss: 0.1559530347585678
Validation loss: 1.4450766258342291

Epoch: 6| Step: 11
Training loss: 0.04690159857273102
Validation loss: 1.4503472646077473

Epoch: 6| Step: 12
Training loss: 0.07567068934440613
Validation loss: 1.4692646021484046

Epoch: 6| Step: 13
Training loss: 0.0630190521478653
Validation loss: 1.4860948760022399

Epoch: 523| Step: 0
Training loss: 0.15436121821403503
Validation loss: 1.504280646001139

Epoch: 6| Step: 1
Training loss: 0.0754927322268486
Validation loss: 1.5127927308441491

Epoch: 6| Step: 2
Training loss: 0.1240774616599083
Validation loss: 1.5143583295165852

Epoch: 6| Step: 3
Training loss: 0.11531953513622284
Validation loss: 1.4676909267261464

Epoch: 6| Step: 4
Training loss: 0.10379805415868759
Validation loss: 1.485786534124805

Epoch: 6| Step: 5
Training loss: 0.08957460522651672
Validation loss: 1.4590753457879508

Epoch: 6| Step: 6
Training loss: 0.08871403336524963
Validation loss: 1.4260516820415374

Epoch: 6| Step: 7
Training loss: 0.07982185482978821
Validation loss: 1.4280975070050967

Epoch: 6| Step: 8
Training loss: 0.09914759546518326
Validation loss: 1.4158059666233678

Epoch: 6| Step: 9
Training loss: 0.07488906383514404
Validation loss: 1.4126749115605508

Epoch: 6| Step: 10
Training loss: 0.0916113555431366
Validation loss: 1.4221669179137035

Epoch: 6| Step: 11
Training loss: 0.09587398171424866
Validation loss: 1.4205326546904862

Epoch: 6| Step: 12
Training loss: 0.09389211982488632
Validation loss: 1.4497218132019043

Epoch: 6| Step: 13
Training loss: 0.05135694891214371
Validation loss: 1.4500363642169583

Epoch: 524| Step: 0
Training loss: 0.07682724297046661
Validation loss: 1.4967997753491966

Epoch: 6| Step: 1
Training loss: 0.0767853781580925
Validation loss: 1.4629310561764626

Epoch: 6| Step: 2
Training loss: 0.09270352125167847
Validation loss: 1.491437712023335

Epoch: 6| Step: 3
Training loss: 0.08243224024772644
Validation loss: 1.494394597186837

Epoch: 6| Step: 4
Training loss: 0.07413344085216522
Validation loss: 1.469400680193337

Epoch: 6| Step: 5
Training loss: 0.03511227294802666
Validation loss: 1.4844220107601536

Epoch: 6| Step: 6
Training loss: 0.10490820556879044
Validation loss: 1.4447862076502975

Epoch: 6| Step: 7
Training loss: 0.10574275255203247
Validation loss: 1.4567918905647852

Epoch: 6| Step: 8
Training loss: 0.08137469738721848
Validation loss: 1.4480100306131507

Epoch: 6| Step: 9
Training loss: 0.04067573696374893
Validation loss: 1.4544595262055755

Epoch: 6| Step: 10
Training loss: 0.10505884140729904
Validation loss: 1.4468899003921016

Epoch: 6| Step: 11
Training loss: 0.1593686044216156
Validation loss: 1.4442499222293976

Epoch: 6| Step: 12
Training loss: 0.07654164731502533
Validation loss: 1.4618878300471971

Epoch: 6| Step: 13
Training loss: 0.060808733105659485
Validation loss: 1.456083119556468

Epoch: 525| Step: 0
Training loss: 0.056347303092479706
Validation loss: 1.4723588728135633

Epoch: 6| Step: 1
Training loss: 0.06297165155410767
Validation loss: 1.4953030860552223

Epoch: 6| Step: 2
Training loss: 0.07275404781103134
Validation loss: 1.4916621305609261

Epoch: 6| Step: 3
Training loss: 0.09094762802124023
Validation loss: 1.487515652051536

Epoch: 6| Step: 4
Training loss: 0.125566765666008
Validation loss: 1.4913508443422214

Epoch: 6| Step: 5
Training loss: 0.09473693370819092
Validation loss: 1.500510900251327

Epoch: 6| Step: 6
Training loss: 0.06977995485067368
Validation loss: 1.4898407830986926

Epoch: 6| Step: 7
Training loss: 0.07870703935623169
Validation loss: 1.4834300420617546

Epoch: 6| Step: 8
Training loss: 0.08761049807071686
Validation loss: 1.4794953202688566

Epoch: 6| Step: 9
Training loss: 0.07378721982240677
Validation loss: 1.4659045293766966

Epoch: 6| Step: 10
Training loss: 0.08414703607559204
Validation loss: 1.4603936390210224

Epoch: 6| Step: 11
Training loss: 0.14378608763217926
Validation loss: 1.448014513779712

Epoch: 6| Step: 12
Training loss: 0.06414195895195007
Validation loss: 1.4315446756219352

Epoch: 6| Step: 13
Training loss: 0.08830845355987549
Validation loss: 1.4664372539007535

Epoch: 526| Step: 0
Training loss: 0.08075712621212006
Validation loss: 1.4242320483730686

Epoch: 6| Step: 1
Training loss: 0.050515204668045044
Validation loss: 1.4318449330586258

Epoch: 6| Step: 2
Training loss: 0.04583360254764557
Validation loss: 1.4174691464311333

Epoch: 6| Step: 3
Training loss: 0.09093435853719711
Validation loss: 1.4192995884085213

Epoch: 6| Step: 4
Training loss: 0.1208864152431488
Validation loss: 1.415608177902878

Epoch: 6| Step: 5
Training loss: 0.08120470494031906
Validation loss: 1.4204283593803324

Epoch: 6| Step: 6
Training loss: 0.061329033225774765
Validation loss: 1.4571001773239465

Epoch: 6| Step: 7
Training loss: 0.06928209215402603
Validation loss: 1.4345905985883487

Epoch: 6| Step: 8
Training loss: 0.08516480028629303
Validation loss: 1.507611043991581

Epoch: 6| Step: 9
Training loss: 0.07334049046039581
Validation loss: 1.4950080148635372

Epoch: 6| Step: 10
Training loss: 0.1730436235666275
Validation loss: 1.5007303786534134

Epoch: 6| Step: 11
Training loss: 0.07345547527074814
Validation loss: 1.4965300995816466

Epoch: 6| Step: 12
Training loss: 0.1038663312792778
Validation loss: 1.4827915237795921

Epoch: 6| Step: 13
Training loss: 0.07508691400289536
Validation loss: 1.464230236186776

Epoch: 527| Step: 0
Training loss: 0.049502283334732056
Validation loss: 1.476169837418423

Epoch: 6| Step: 1
Training loss: 0.06224586442112923
Validation loss: 1.450007220750214

Epoch: 6| Step: 2
Training loss: 0.0971941351890564
Validation loss: 1.4217594554347377

Epoch: 6| Step: 3
Training loss: 0.088896244764328
Validation loss: 1.4085017916976765

Epoch: 6| Step: 4
Training loss: 0.09762617945671082
Validation loss: 1.395895911801246

Epoch: 6| Step: 5
Training loss: 0.11830626428127289
Validation loss: 1.4015177167871946

Epoch: 6| Step: 6
Training loss: 0.09614250808954239
Validation loss: 1.4042901403160506

Epoch: 6| Step: 7
Training loss: 0.11035234481096268
Validation loss: 1.4304512367453626

Epoch: 6| Step: 8
Training loss: 0.16062557697296143
Validation loss: 1.4030355202254428

Epoch: 6| Step: 9
Training loss: 0.08294744789600372
Validation loss: 1.4417789995029409

Epoch: 6| Step: 10
Training loss: 0.053270235657691956
Validation loss: 1.4470268846839986

Epoch: 6| Step: 11
Training loss: 0.05677591264247894
Validation loss: 1.4485098277368853

Epoch: 6| Step: 12
Training loss: 0.07804689556360245
Validation loss: 1.512391617221217

Epoch: 6| Step: 13
Training loss: 0.13057154417037964
Validation loss: 1.5109889109929402

Epoch: 528| Step: 0
Training loss: 0.0802844688296318
Validation loss: 1.5009617882390176

Epoch: 6| Step: 1
Training loss: 0.0384698286652565
Validation loss: 1.507268068610981

Epoch: 6| Step: 2
Training loss: 0.09345695376396179
Validation loss: 1.4862358185552782

Epoch: 6| Step: 3
Training loss: 0.13826698064804077
Validation loss: 1.4497230488766906

Epoch: 6| Step: 4
Training loss: 0.07767868041992188
Validation loss: 1.4465273516152495

Epoch: 6| Step: 5
Training loss: 0.0823930948972702
Validation loss: 1.4490827809097946

Epoch: 6| Step: 6
Training loss: 0.06299865245819092
Validation loss: 1.4234593940037552

Epoch: 6| Step: 7
Training loss: 0.10818043351173401
Validation loss: 1.4068854265315558

Epoch: 6| Step: 8
Training loss: 0.12412165850400925
Validation loss: 1.4160310337620396

Epoch: 6| Step: 9
Training loss: 0.11634984612464905
Validation loss: 1.3952107839686896

Epoch: 6| Step: 10
Training loss: 0.10027165710926056
Validation loss: 1.4142227454852032

Epoch: 6| Step: 11
Training loss: 0.05947543680667877
Validation loss: 1.4162993546455138

Epoch: 6| Step: 12
Training loss: 0.10415691137313843
Validation loss: 1.4275266380720242

Epoch: 6| Step: 13
Training loss: 0.055291835218667984
Validation loss: 1.4147003414810344

Epoch: 529| Step: 0
Training loss: 0.10574060678482056
Validation loss: 1.4135937870189708

Epoch: 6| Step: 1
Training loss: 0.08094339072704315
Validation loss: 1.4614049619243992

Epoch: 6| Step: 2
Training loss: 0.04342680424451828
Validation loss: 1.4583449491890528

Epoch: 6| Step: 3
Training loss: 0.06209918111562729
Validation loss: 1.4646985838490147

Epoch: 6| Step: 4
Training loss: 0.10168372839689255
Validation loss: 1.4817189670378161

Epoch: 6| Step: 5
Training loss: 0.13022667169570923
Validation loss: 1.4629967610041301

Epoch: 6| Step: 6
Training loss: 0.06749018281698227
Validation loss: 1.4513928262136315

Epoch: 6| Step: 7
Training loss: 0.0758257582783699
Validation loss: 1.4415399618046258

Epoch: 6| Step: 8
Training loss: 0.03888976573944092
Validation loss: 1.45897005450341

Epoch: 6| Step: 9
Training loss: 0.10630714148283005
Validation loss: 1.4673326823019213

Epoch: 6| Step: 10
Training loss: 0.08240575343370438
Validation loss: 1.4775683277396745

Epoch: 6| Step: 11
Training loss: 0.05149286985397339
Validation loss: 1.4516918024709147

Epoch: 6| Step: 12
Training loss: 0.07953797280788422
Validation loss: 1.4777151794843777

Epoch: 6| Step: 13
Training loss: 0.13526128232479095
Validation loss: 1.4802783894282516

Epoch: 530| Step: 0
Training loss: 0.06932485103607178
Validation loss: 1.4669474799145934

Epoch: 6| Step: 1
Training loss: 0.09138599038124084
Validation loss: 1.4609784400591286

Epoch: 6| Step: 2
Training loss: 0.06932144612073898
Validation loss: 1.4439907868703206

Epoch: 6| Step: 3
Training loss: 0.1030031070113182
Validation loss: 1.4706628989147883

Epoch: 6| Step: 4
Training loss: 0.13184702396392822
Validation loss: 1.435463874570785

Epoch: 6| Step: 5
Training loss: 0.09045208990573883
Validation loss: 1.4483681981281569

Epoch: 6| Step: 6
Training loss: 0.08528940379619598
Validation loss: 1.4558039249912385

Epoch: 6| Step: 7
Training loss: 0.05340993031859398
Validation loss: 1.4678137712581183

Epoch: 6| Step: 8
Training loss: 0.0505724772810936
Validation loss: 1.477530523013043

Epoch: 6| Step: 9
Training loss: 0.11458847671747208
Validation loss: 1.4765039118387366

Epoch: 6| Step: 10
Training loss: 0.07249301671981812
Validation loss: 1.5116620249645685

Epoch: 6| Step: 11
Training loss: 0.07774677127599716
Validation loss: 1.5134230313762542

Epoch: 6| Step: 12
Training loss: 0.13400912284851074
Validation loss: 1.4941000797415291

Epoch: 6| Step: 13
Training loss: 0.09287922829389572
Validation loss: 1.4847425427488101

Epoch: 531| Step: 0
Training loss: 0.05704120546579361
Validation loss: 1.4840049820561563

Epoch: 6| Step: 1
Training loss: 0.09336227923631668
Validation loss: 1.4764986499663322

Epoch: 6| Step: 2
Training loss: 0.12101687490940094
Validation loss: 1.4701890278888006

Epoch: 6| Step: 3
Training loss: 0.04976406693458557
Validation loss: 1.4475735425949097

Epoch: 6| Step: 4
Training loss: 0.0993681252002716
Validation loss: 1.4628113264678626

Epoch: 6| Step: 5
Training loss: 0.07741717994213104
Validation loss: 1.4738611617395956

Epoch: 6| Step: 6
Training loss: 0.10080187022686005
Validation loss: 1.4666870614533782

Epoch: 6| Step: 7
Training loss: 0.10643037408590317
Validation loss: 1.471264135453009

Epoch: 6| Step: 8
Training loss: 0.06014031171798706
Validation loss: 1.4641436748607184

Epoch: 6| Step: 9
Training loss: 0.06797584891319275
Validation loss: 1.4335547916350826

Epoch: 6| Step: 10
Training loss: 0.09345494210720062
Validation loss: 1.4477889076355965

Epoch: 6| Step: 11
Training loss: 0.1146702840924263
Validation loss: 1.4299094561607606

Epoch: 6| Step: 12
Training loss: 0.04577808827161789
Validation loss: 1.4289656582699026

Epoch: 6| Step: 13
Training loss: 0.19306987524032593
Validation loss: 1.4615760689140649

Epoch: 532| Step: 0
Training loss: 0.11112841963768005
Validation loss: 1.4718845390504407

Epoch: 6| Step: 1
Training loss: 0.10424721240997314
Validation loss: 1.4880904587366248

Epoch: 6| Step: 2
Training loss: 0.11491012573242188
Validation loss: 1.4879216096734489

Epoch: 6| Step: 3
Training loss: 0.08642184734344482
Validation loss: 1.5188736415678454

Epoch: 6| Step: 4
Training loss: 0.13750439882278442
Validation loss: 1.5147961672916208

Epoch: 6| Step: 5
Training loss: 0.07268718630075455
Validation loss: 1.4899459897830922

Epoch: 6| Step: 6
Training loss: 0.06855190545320511
Validation loss: 1.5293087459379626

Epoch: 6| Step: 7
Training loss: 0.07269153743982315
Validation loss: 1.5141264200210571

Epoch: 6| Step: 8
Training loss: 0.13104207813739777
Validation loss: 1.534246915130205

Epoch: 6| Step: 9
Training loss: 0.2014182060956955
Validation loss: 1.5382249560407413

Epoch: 6| Step: 10
Training loss: 0.1467500627040863
Validation loss: 1.5235532176110052

Epoch: 6| Step: 11
Training loss: 0.09727973490953445
Validation loss: 1.5044253962014311

Epoch: 6| Step: 12
Training loss: 0.09528913348913193
Validation loss: 1.4694503135578607

Epoch: 6| Step: 13
Training loss: 0.06462052464485168
Validation loss: 1.4392515267095258

Epoch: 533| Step: 0
Training loss: 0.08113596588373184
Validation loss: 1.4503445176668064

Epoch: 6| Step: 1
Training loss: 0.07219642400741577
Validation loss: 1.3899388793976075

Epoch: 6| Step: 2
Training loss: 0.0995759665966034
Validation loss: 1.4176159033211329

Epoch: 6| Step: 3
Training loss: 0.17855645716190338
Validation loss: 1.424377167096702

Epoch: 6| Step: 4
Training loss: 0.22904419898986816
Validation loss: 1.4710012360285687

Epoch: 6| Step: 5
Training loss: 0.2625701129436493
Validation loss: 1.4404765572599185

Epoch: 6| Step: 6
Training loss: 0.17764708399772644
Validation loss: 1.43726485518999

Epoch: 6| Step: 7
Training loss: 0.055793605744838715
Validation loss: 1.4135306291682745

Epoch: 6| Step: 8
Training loss: 0.1044565886259079
Validation loss: 1.457966519940284

Epoch: 6| Step: 9
Training loss: 0.09097734838724136
Validation loss: 1.4747153277038245

Epoch: 6| Step: 10
Training loss: 0.2008320838212967
Validation loss: 1.5095583969546902

Epoch: 6| Step: 11
Training loss: 0.21505625545978546
Validation loss: 1.5506835676008655

Epoch: 6| Step: 12
Training loss: 0.06984719634056091
Validation loss: 1.5389600210292365

Epoch: 6| Step: 13
Training loss: 0.09510302543640137
Validation loss: 1.5739220393601285

Epoch: 534| Step: 0
Training loss: 0.13613423705101013
Validation loss: 1.553968761556892

Epoch: 6| Step: 1
Training loss: 0.0808212161064148
Validation loss: 1.519726078997376

Epoch: 6| Step: 2
Training loss: 0.11862406134605408
Validation loss: 1.4958302641427645

Epoch: 6| Step: 3
Training loss: 0.12735258042812347
Validation loss: 1.5304748909447783

Epoch: 6| Step: 4
Training loss: 0.10102616250514984
Validation loss: 1.507996791793454

Epoch: 6| Step: 5
Training loss: 0.09081189334392548
Validation loss: 1.512361362416257

Epoch: 6| Step: 6
Training loss: 0.10228228569030762
Validation loss: 1.4901472496730026

Epoch: 6| Step: 7
Training loss: 0.05947260558605194
Validation loss: 1.5035841900815246

Epoch: 6| Step: 8
Training loss: 0.09455250203609467
Validation loss: 1.4800567626953125

Epoch: 6| Step: 9
Training loss: 0.0696934312582016
Validation loss: 1.46084181211328

Epoch: 6| Step: 10
Training loss: 0.13498026132583618
Validation loss: 1.457782865211528

Epoch: 6| Step: 11
Training loss: 0.06960462033748627
Validation loss: 1.4835008716070524

Epoch: 6| Step: 12
Training loss: 0.13491223752498627
Validation loss: 1.4619476731105516

Epoch: 6| Step: 13
Training loss: 0.10526371002197266
Validation loss: 1.4561781498693651

Epoch: 535| Step: 0
Training loss: 0.07217016071081161
Validation loss: 1.4757819252629434

Epoch: 6| Step: 1
Training loss: 0.09217499196529388
Validation loss: 1.526969253375966

Epoch: 6| Step: 2
Training loss: 0.12589557468891144
Validation loss: 1.5554789753370388

Epoch: 6| Step: 3
Training loss: 0.12912940979003906
Validation loss: 1.559198773035439

Epoch: 6| Step: 4
Training loss: 0.11410748213529587
Validation loss: 1.5993543863296509

Epoch: 6| Step: 5
Training loss: 0.11241500079631805
Validation loss: 1.6255560639084026

Epoch: 6| Step: 6
Training loss: 0.09632990509271622
Validation loss: 1.601222788133929

Epoch: 6| Step: 7
Training loss: 0.0996452122926712
Validation loss: 1.5744393628130677

Epoch: 6| Step: 8
Training loss: 0.0815238505601883
Validation loss: 1.578268486966369

Epoch: 6| Step: 9
Training loss: 0.11602292209863663
Validation loss: 1.5054112480532738

Epoch: 6| Step: 10
Training loss: 0.15618260204792023
Validation loss: 1.4987052153515559

Epoch: 6| Step: 11
Training loss: 0.10485909134149551
Validation loss: 1.4806564046490578

Epoch: 6| Step: 12
Training loss: 0.11253030598163605
Validation loss: 1.4570803052635604

Epoch: 6| Step: 13
Training loss: 0.08136433362960815
Validation loss: 1.4500692230398937

Epoch: 536| Step: 0
Training loss: 0.0852339118719101
Validation loss: 1.4362792430385467

Epoch: 6| Step: 1
Training loss: 0.07239528745412827
Validation loss: 1.434126736015402

Epoch: 6| Step: 2
Training loss: 0.047105081379413605
Validation loss: 1.414857563152108

Epoch: 6| Step: 3
Training loss: 0.10390828549861908
Validation loss: 1.419017901984594

Epoch: 6| Step: 4
Training loss: 0.12671701610088348
Validation loss: 1.4245948945322344

Epoch: 6| Step: 5
Training loss: 0.08700843155384064
Validation loss: 1.4203409084709742

Epoch: 6| Step: 6
Training loss: 0.11847171932458878
Validation loss: 1.4190395583388626

Epoch: 6| Step: 7
Training loss: 0.0570809468626976
Validation loss: 1.4215290110598329

Epoch: 6| Step: 8
Training loss: 0.06565523147583008
Validation loss: 1.4335605162446217

Epoch: 6| Step: 9
Training loss: 0.05888352915644646
Validation loss: 1.4564658646942468

Epoch: 6| Step: 10
Training loss: 0.11073586344718933
Validation loss: 1.4826338816714544

Epoch: 6| Step: 11
Training loss: 0.13221599161624908
Validation loss: 1.4645197135145946

Epoch: 6| Step: 12
Training loss: 0.11284703016281128
Validation loss: 1.4799714267894786

Epoch: 6| Step: 13
Training loss: 0.07198800146579742
Validation loss: 1.5034538725371003

Epoch: 537| Step: 0
Training loss: 0.10898847877979279
Validation loss: 1.4516201352560392

Epoch: 6| Step: 1
Training loss: 0.07295393943786621
Validation loss: 1.4599369495145735

Epoch: 6| Step: 2
Training loss: 0.07333922386169434
Validation loss: 1.475118952412759

Epoch: 6| Step: 3
Training loss: 0.09225092828273773
Validation loss: 1.4538999962550339

Epoch: 6| Step: 4
Training loss: 0.06413913518190384
Validation loss: 1.4358471042366439

Epoch: 6| Step: 5
Training loss: 0.07428541034460068
Validation loss: 1.4285360766995339

Epoch: 6| Step: 6
Training loss: 0.10317173600196838
Validation loss: 1.4502696939693984

Epoch: 6| Step: 7
Training loss: 0.08866208791732788
Validation loss: 1.4608718438815045

Epoch: 6| Step: 8
Training loss: 0.12968119978904724
Validation loss: 1.460180139669808

Epoch: 6| Step: 9
Training loss: 0.060038723051548004
Validation loss: 1.4473253949995963

Epoch: 6| Step: 10
Training loss: 0.13631699979305267
Validation loss: 1.4864603607885298

Epoch: 6| Step: 11
Training loss: 0.061943791806697845
Validation loss: 1.4249227912195268

Epoch: 6| Step: 12
Training loss: 0.09162532538175583
Validation loss: 1.4013620948278775

Epoch: 6| Step: 13
Training loss: 0.07630626112222672
Validation loss: 1.4262773016447663

Epoch: 538| Step: 0
Training loss: 0.11990643292665482
Validation loss: 1.4130203441907

Epoch: 6| Step: 1
Training loss: 0.09577314555644989
Validation loss: 1.403463985330315

Epoch: 6| Step: 2
Training loss: 0.053319476544857025
Validation loss: 1.4495501531067716

Epoch: 6| Step: 3
Training loss: 0.12393058836460114
Validation loss: 1.4499657166901456

Epoch: 6| Step: 4
Training loss: 0.09490908682346344
Validation loss: 1.513358062313449

Epoch: 6| Step: 5
Training loss: 0.07552486658096313
Validation loss: 1.4893689437579083

Epoch: 6| Step: 6
Training loss: 0.09199570119380951
Validation loss: 1.4941314189664778

Epoch: 6| Step: 7
Training loss: 0.05995872616767883
Validation loss: 1.4997476211158178

Epoch: 6| Step: 8
Training loss: 0.09939543157815933
Validation loss: 1.5147757248211933

Epoch: 6| Step: 9
Training loss: 0.09821325540542603
Validation loss: 1.5012266084712038

Epoch: 6| Step: 10
Training loss: 0.12180442363023758
Validation loss: 1.487600762356994

Epoch: 6| Step: 11
Training loss: 0.041595786809921265
Validation loss: 1.4798629296723234

Epoch: 6| Step: 12
Training loss: 0.08746443688869476
Validation loss: 1.4741001065059374

Epoch: 6| Step: 13
Training loss: 0.06753647327423096
Validation loss: 1.4574606444246025

Epoch: 539| Step: 0
Training loss: 0.07966014742851257
Validation loss: 1.4385405112338323

Epoch: 6| Step: 1
Training loss: 0.09050086885690689
Validation loss: 1.4315474405083606

Epoch: 6| Step: 2
Training loss: 0.05106976628303528
Validation loss: 1.430737304431136

Epoch: 6| Step: 3
Training loss: 0.15748602151870728
Validation loss: 1.3952156561677174

Epoch: 6| Step: 4
Training loss: 0.07072460651397705
Validation loss: 1.4243153243936517

Epoch: 6| Step: 5
Training loss: 0.04660876840353012
Validation loss: 1.4279390970865886

Epoch: 6| Step: 6
Training loss: 0.11342457681894302
Validation loss: 1.4378960081326064

Epoch: 6| Step: 7
Training loss: 0.0704442709684372
Validation loss: 1.451251176095778

Epoch: 6| Step: 8
Training loss: 0.09163712710142136
Validation loss: 1.4806186934953094

Epoch: 6| Step: 9
Training loss: 0.0982062965631485
Validation loss: 1.5070742304607103

Epoch: 6| Step: 10
Training loss: 0.05867835879325867
Validation loss: 1.501116560351464

Epoch: 6| Step: 11
Training loss: 0.07492752373218536
Validation loss: 1.5204470298623527

Epoch: 6| Step: 12
Training loss: 0.14644619822502136
Validation loss: 1.5165976606389528

Epoch: 6| Step: 13
Training loss: 0.12421809136867523
Validation loss: 1.5083761727938088

Epoch: 540| Step: 0
Training loss: 0.08531999588012695
Validation loss: 1.4795746803283691

Epoch: 6| Step: 1
Training loss: 0.0679333359003067
Validation loss: 1.487243648498289

Epoch: 6| Step: 2
Training loss: 0.07501110434532166
Validation loss: 1.4763905886680848

Epoch: 6| Step: 3
Training loss: 0.05423369258642197
Validation loss: 1.4639518113546475

Epoch: 6| Step: 4
Training loss: 0.10337886214256287
Validation loss: 1.4736785286216325

Epoch: 6| Step: 5
Training loss: 0.07434097677469254
Validation loss: 1.4736519731501097

Epoch: 6| Step: 6
Training loss: 0.06883486360311508
Validation loss: 1.4729388234435872

Epoch: 6| Step: 7
Training loss: 0.14006289839744568
Validation loss: 1.4314134813124133

Epoch: 6| Step: 8
Training loss: 0.1449626386165619
Validation loss: 1.4475658991003548

Epoch: 6| Step: 9
Training loss: 0.041498929262161255
Validation loss: 1.4439246193055184

Epoch: 6| Step: 10
Training loss: 0.10107715427875519
Validation loss: 1.43167882709093

Epoch: 6| Step: 11
Training loss: 0.12125139683485031
Validation loss: 1.42409134680225

Epoch: 6| Step: 12
Training loss: 0.11767091602087021
Validation loss: 1.4408679405848186

Epoch: 6| Step: 13
Training loss: 0.06119076535105705
Validation loss: 1.4302155381889754

Epoch: 541| Step: 0
Training loss: 0.06957920640707016
Validation loss: 1.451299645567453

Epoch: 6| Step: 1
Training loss: 0.07853517681360245
Validation loss: 1.4716732835256925

Epoch: 6| Step: 2
Training loss: 0.040414318442344666
Validation loss: 1.4447505217726513

Epoch: 6| Step: 3
Training loss: 0.09222334623336792
Validation loss: 1.4480908070841143

Epoch: 6| Step: 4
Training loss: 0.06882067024707794
Validation loss: 1.4407715310332596

Epoch: 6| Step: 5
Training loss: 0.08348682522773743
Validation loss: 1.4651827120011853

Epoch: 6| Step: 6
Training loss: 0.07482577115297318
Validation loss: 1.4708449699545418

Epoch: 6| Step: 7
Training loss: 0.10153758525848389
Validation loss: 1.454721761647091

Epoch: 6| Step: 8
Training loss: 0.10219407081604004
Validation loss: 1.467302405706016

Epoch: 6| Step: 9
Training loss: 0.058673445135354996
Validation loss: 1.4844913046847108

Epoch: 6| Step: 10
Training loss: 0.05523790419101715
Validation loss: 1.497277049608128

Epoch: 6| Step: 11
Training loss: 0.08490921556949615
Validation loss: 1.4595514446176507

Epoch: 6| Step: 12
Training loss: 0.11373303085565567
Validation loss: 1.510402084678732

Epoch: 6| Step: 13
Training loss: 0.13848209381103516
Validation loss: 1.4456776483084566

Epoch: 542| Step: 0
Training loss: 0.12107433378696442
Validation loss: 1.4705167303803146

Epoch: 6| Step: 1
Training loss: 0.054295994341373444
Validation loss: 1.4476343957326745

Epoch: 6| Step: 2
Training loss: 0.1003444567322731
Validation loss: 1.4703158268364527

Epoch: 6| Step: 3
Training loss: 0.05213393270969391
Validation loss: 1.4190493078641995

Epoch: 6| Step: 4
Training loss: 0.06276576966047287
Validation loss: 1.4316259802028697

Epoch: 6| Step: 5
Training loss: 0.08702784776687622
Validation loss: 1.4266872277823828

Epoch: 6| Step: 6
Training loss: 0.10456555336713791
Validation loss: 1.4318348092417563

Epoch: 6| Step: 7
Training loss: 0.05851747468113899
Validation loss: 1.4342944788676437

Epoch: 6| Step: 8
Training loss: 0.09400027245283127
Validation loss: 1.4377607709618025

Epoch: 6| Step: 9
Training loss: 0.05573178082704544
Validation loss: 1.4583729601675464

Epoch: 6| Step: 10
Training loss: 0.09206061065196991
Validation loss: 1.4665802499299407

Epoch: 6| Step: 11
Training loss: 0.0977679044008255
Validation loss: 1.4866574380987434

Epoch: 6| Step: 12
Training loss: 0.0875575989484787
Validation loss: 1.4528289507794123

Epoch: 6| Step: 13
Training loss: 0.05662515386939049
Validation loss: 1.4602655864530993

Epoch: 543| Step: 0
Training loss: 0.06803572177886963
Validation loss: 1.4642103372081634

Epoch: 6| Step: 1
Training loss: 0.11374230682849884
Validation loss: 1.4565160761597336

Epoch: 6| Step: 2
Training loss: 0.07158471643924713
Validation loss: 1.4689754170756186

Epoch: 6| Step: 3
Training loss: 0.1021498441696167
Validation loss: 1.4461172114136398

Epoch: 6| Step: 4
Training loss: 0.03942856192588806
Validation loss: 1.4319258466843636

Epoch: 6| Step: 5
Training loss: 0.09435002505779266
Validation loss: 1.4251228096664592

Epoch: 6| Step: 6
Training loss: 0.06139074265956879
Validation loss: 1.4166720669756654

Epoch: 6| Step: 7
Training loss: 0.06603087484836578
Validation loss: 1.4418979216647405

Epoch: 6| Step: 8
Training loss: 0.09838179498910904
Validation loss: 1.4217060067320382

Epoch: 6| Step: 9
Training loss: 0.048092130571603775
Validation loss: 1.4104671529544297

Epoch: 6| Step: 10
Training loss: 0.06929364800453186
Validation loss: 1.4009833105148808

Epoch: 6| Step: 11
Training loss: 0.06787781417369843
Validation loss: 1.416058414725847

Epoch: 6| Step: 12
Training loss: 0.06214671581983566
Validation loss: 1.4029718740012056

Epoch: 6| Step: 13
Training loss: 0.1519865244626999
Validation loss: 1.4037427761221444

Epoch: 544| Step: 0
Training loss: 0.09427137672901154
Validation loss: 1.4408800114867508

Epoch: 6| Step: 1
Training loss: 0.05104842036962509
Validation loss: 1.4411555208185667

Epoch: 6| Step: 2
Training loss: 0.07400550693273544
Validation loss: 1.4359206973865468

Epoch: 6| Step: 3
Training loss: 0.06130427494645119
Validation loss: 1.4224100459006526

Epoch: 6| Step: 4
Training loss: 0.08761559426784515
Validation loss: 1.4250014699915403

Epoch: 6| Step: 5
Training loss: 0.08814944326877594
Validation loss: 1.4640296389979701

Epoch: 6| Step: 6
Training loss: 0.07705804705619812
Validation loss: 1.4411997218285837

Epoch: 6| Step: 7
Training loss: 0.059707485139369965
Validation loss: 1.439783852587464

Epoch: 6| Step: 8
Training loss: 0.07268211245536804
Validation loss: 1.4429091740679998

Epoch: 6| Step: 9
Training loss: 0.08391153812408447
Validation loss: 1.4742273066633491

Epoch: 6| Step: 10
Training loss: 0.10709282755851746
Validation loss: 1.463565985361735

Epoch: 6| Step: 11
Training loss: 0.07883115857839584
Validation loss: 1.4613359666639758

Epoch: 6| Step: 12
Training loss: 0.08607232570648193
Validation loss: 1.4562675183819187

Epoch: 6| Step: 13
Training loss: 0.05571083351969719
Validation loss: 1.4705414092668923

Epoch: 545| Step: 0
Training loss: 0.0706653743982315
Validation loss: 1.4573721494725955

Epoch: 6| Step: 1
Training loss: 0.10517353564500809
Validation loss: 1.4429765414166194

Epoch: 6| Step: 2
Training loss: 0.045941174030303955
Validation loss: 1.4459828574170348

Epoch: 6| Step: 3
Training loss: 0.07017254829406738
Validation loss: 1.43838607880377

Epoch: 6| Step: 4
Training loss: 0.057426583021879196
Validation loss: 1.4475713673458304

Epoch: 6| Step: 5
Training loss: 0.14569991827011108
Validation loss: 1.4383605077702513

Epoch: 6| Step: 6
Training loss: 0.053465619683265686
Validation loss: 1.4608735756207538

Epoch: 6| Step: 7
Training loss: 0.05359784886240959
Validation loss: 1.4492073597446564

Epoch: 6| Step: 8
Training loss: 0.07825562357902527
Validation loss: 1.4738699928406747

Epoch: 6| Step: 9
Training loss: 0.10108321905136108
Validation loss: 1.4385897023703462

Epoch: 6| Step: 10
Training loss: 0.06859296560287476
Validation loss: 1.445812306096477

Epoch: 6| Step: 11
Training loss: 0.09175282716751099
Validation loss: 1.461563015496859

Epoch: 6| Step: 12
Training loss: 0.06549225002527237
Validation loss: 1.4339379495190037

Epoch: 6| Step: 13
Training loss: 0.10293825715780258
Validation loss: 1.4588179024316932

Epoch: 546| Step: 0
Training loss: 0.05381537973880768
Validation loss: 1.4573764583115936

Epoch: 6| Step: 1
Training loss: 0.10568772256374359
Validation loss: 1.4345372280766886

Epoch: 6| Step: 2
Training loss: 0.12391532957553864
Validation loss: 1.4803668991211922

Epoch: 6| Step: 3
Training loss: 0.1457076072692871
Validation loss: 1.498879232714253

Epoch: 6| Step: 4
Training loss: 0.09441229701042175
Validation loss: 1.474045871406473

Epoch: 6| Step: 5
Training loss: 0.08880108594894409
Validation loss: 1.4858440558115642

Epoch: 6| Step: 6
Training loss: 0.1039372906088829
Validation loss: 1.463097362108128

Epoch: 6| Step: 7
Training loss: 0.09483394026756287
Validation loss: 1.4483740739924933

Epoch: 6| Step: 8
Training loss: 0.059297673404216766
Validation loss: 1.43388121615174

Epoch: 6| Step: 9
Training loss: 0.0854954794049263
Validation loss: 1.454769815168073

Epoch: 6| Step: 10
Training loss: 0.09410277009010315
Validation loss: 1.4702755712693738

Epoch: 6| Step: 11
Training loss: 0.1284572035074234
Validation loss: 1.4340758541578889

Epoch: 6| Step: 12
Training loss: 0.07890170812606812
Validation loss: 1.4342644355630363

Epoch: 6| Step: 13
Training loss: 0.16073177754878998
Validation loss: 1.4279008488501272

Epoch: 547| Step: 0
Training loss: 0.07265792787075043
Validation loss: 1.446224944565886

Epoch: 6| Step: 1
Training loss: 0.07761867344379425
Validation loss: 1.4607648900760117

Epoch: 6| Step: 2
Training loss: 0.0832652598619461
Validation loss: 1.436872293872218

Epoch: 6| Step: 3
Training loss: 0.06882147490978241
Validation loss: 1.4476508998101758

Epoch: 6| Step: 4
Training loss: 0.08007420599460602
Validation loss: 1.4457154978987992

Epoch: 6| Step: 5
Training loss: 0.11563858389854431
Validation loss: 1.4716693098827074

Epoch: 6| Step: 6
Training loss: 0.16445298492908478
Validation loss: 1.4493834600653699

Epoch: 6| Step: 7
Training loss: 0.0649157389998436
Validation loss: 1.4704326032310404

Epoch: 6| Step: 8
Training loss: 0.11362394690513611
Validation loss: 1.4885702927907307

Epoch: 6| Step: 9
Training loss: 0.08344128727912903
Validation loss: 1.4901986109313143

Epoch: 6| Step: 10
Training loss: 0.1565784513950348
Validation loss: 1.5239471107400873

Epoch: 6| Step: 11
Training loss: 0.09957879781723022
Validation loss: 1.5142648835336008

Epoch: 6| Step: 12
Training loss: 0.15171855688095093
Validation loss: 1.4913853265905892

Epoch: 6| Step: 13
Training loss: 0.10473766922950745
Validation loss: 1.4840239690196129

Epoch: 548| Step: 0
Training loss: 0.08220215141773224
Validation loss: 1.438217919359925

Epoch: 6| Step: 1
Training loss: 0.10362368822097778
Validation loss: 1.4189072744820708

Epoch: 6| Step: 2
Training loss: 0.12728017568588257
Validation loss: 1.4413622374175696

Epoch: 6| Step: 3
Training loss: 0.10268660634756088
Validation loss: 1.4521482900906635

Epoch: 6| Step: 4
Training loss: 0.23891900479793549
Validation loss: 1.4622900306537587

Epoch: 6| Step: 5
Training loss: 0.22985656559467316
Validation loss: 1.455800469203662

Epoch: 6| Step: 6
Training loss: 0.17840400338172913
Validation loss: 1.4310784942360335

Epoch: 6| Step: 7
Training loss: 0.08418796211481094
Validation loss: 1.4167771224052674

Epoch: 6| Step: 8
Training loss: 0.0578274242579937
Validation loss: 1.4418073085046583

Epoch: 6| Step: 9
Training loss: 0.0954313725233078
Validation loss: 1.4321164232428356

Epoch: 6| Step: 10
Training loss: 0.05340244621038437
Validation loss: 1.4949729359278114

Epoch: 6| Step: 11
Training loss: 0.08237123489379883
Validation loss: 1.5187538349500267

Epoch: 6| Step: 12
Training loss: 0.19146597385406494
Validation loss: 1.5134879043025355

Epoch: 6| Step: 13
Training loss: 0.07030774652957916
Validation loss: 1.5465488139019217

Epoch: 549| Step: 0
Training loss: 0.12315335869789124
Validation loss: 1.5068699493203113

Epoch: 6| Step: 1
Training loss: 0.1125403344631195
Validation loss: 1.5486303298704085

Epoch: 6| Step: 2
Training loss: 0.07497161626815796
Validation loss: 1.4947074920900407

Epoch: 6| Step: 3
Training loss: 0.082246333360672
Validation loss: 1.4857226289728636

Epoch: 6| Step: 4
Training loss: 0.12159021198749542
Validation loss: 1.4920640478851974

Epoch: 6| Step: 5
Training loss: 0.08898517489433289
Validation loss: 1.4654663724284018

Epoch: 6| Step: 6
Training loss: 0.10663829743862152
Validation loss: 1.449681366643598

Epoch: 6| Step: 7
Training loss: 0.0837380662560463
Validation loss: 1.4404422544663953

Epoch: 6| Step: 8
Training loss: 0.07522644102573395
Validation loss: 1.4052057150871522

Epoch: 6| Step: 9
Training loss: 0.045573025941848755
Validation loss: 1.4366848045779812

Epoch: 6| Step: 10
Training loss: 0.0908110961318016
Validation loss: 1.4186447974174254

Epoch: 6| Step: 11
Training loss: 0.10917924344539642
Validation loss: 1.3894425335750784

Epoch: 6| Step: 12
Training loss: 0.07225530594587326
Validation loss: 1.4007723433997041

Epoch: 6| Step: 13
Training loss: 0.06135041266679764
Validation loss: 1.4011652854181105

Epoch: 550| Step: 0
Training loss: 0.1688070446252823
Validation loss: 1.4188126716562497

Epoch: 6| Step: 1
Training loss: 0.1375865638256073
Validation loss: 1.3902176259666361

Epoch: 6| Step: 2
Training loss: 0.0997907817363739
Validation loss: 1.3839834236329602

Epoch: 6| Step: 3
Training loss: 0.06471079587936401
Validation loss: 1.4096722384934783

Epoch: 6| Step: 4
Training loss: 0.06816283613443375
Validation loss: 1.4124381183296122

Epoch: 6| Step: 5
Training loss: 0.13819670677185059
Validation loss: 1.4639827615471297

Epoch: 6| Step: 6
Training loss: 0.10023083537817001
Validation loss: 1.4711208984416018

Epoch: 6| Step: 7
Training loss: 0.15489457547664642
Validation loss: 1.5121429953523862

Epoch: 6| Step: 8
Training loss: 0.1567218154668808
Validation loss: 1.490751039597296

Epoch: 6| Step: 9
Training loss: 0.09860499948263168
Validation loss: 1.4423818716438868

Epoch: 6| Step: 10
Training loss: 0.07905557751655579
Validation loss: 1.4613548658227409

Epoch: 6| Step: 11
Training loss: 0.08337551355361938
Validation loss: 1.4381800390058948

Epoch: 6| Step: 12
Training loss: 0.15015128254890442
Validation loss: 1.4648640489065519

Epoch: 6| Step: 13
Training loss: 0.1315392255783081
Validation loss: 1.4328145070742535

Epoch: 551| Step: 0
Training loss: 0.10171826183795929
Validation loss: 1.4490105387985066

Epoch: 6| Step: 1
Training loss: 0.0592028982937336
Validation loss: 1.4035242206306868

Epoch: 6| Step: 2
Training loss: 0.08016933500766754
Validation loss: 1.4176695654469151

Epoch: 6| Step: 3
Training loss: 0.05168183520436287
Validation loss: 1.4462173433714016

Epoch: 6| Step: 4
Training loss: 0.1379210203886032
Validation loss: 1.4383799260662449

Epoch: 6| Step: 5
Training loss: 0.2595134973526001
Validation loss: 1.4320561873015536

Epoch: 6| Step: 6
Training loss: 0.12706096470355988
Validation loss: 1.4447168060528335

Epoch: 6| Step: 7
Training loss: 0.14944106340408325
Validation loss: 1.4528127947161276

Epoch: 6| Step: 8
Training loss: 0.11368665099143982
Validation loss: 1.4114072668936946

Epoch: 6| Step: 9
Training loss: 0.0795968770980835
Validation loss: 1.429508315619602

Epoch: 6| Step: 10
Training loss: 0.10977689921855927
Validation loss: 1.4137815224227084

Epoch: 6| Step: 11
Training loss: 0.11322546005249023
Validation loss: 1.4432433676976029

Epoch: 6| Step: 12
Training loss: 0.14782549440860748
Validation loss: 1.4804020466343049

Epoch: 6| Step: 13
Training loss: 0.061358604580163956
Validation loss: 1.4506472272257651

Epoch: 552| Step: 0
Training loss: 0.12759573757648468
Validation loss: 1.439461745241637

Epoch: 6| Step: 1
Training loss: 0.1252197027206421
Validation loss: 1.4732959629386984

Epoch: 6| Step: 2
Training loss: 0.08739778399467468
Validation loss: 1.4414312647235008

Epoch: 6| Step: 3
Training loss: 0.09781216084957123
Validation loss: 1.4480864758132606

Epoch: 6| Step: 4
Training loss: 0.08721167594194412
Validation loss: 1.4492951054726877

Epoch: 6| Step: 5
Training loss: 0.06538103520870209
Validation loss: 1.4248864560998895

Epoch: 6| Step: 6
Training loss: 0.09350335597991943
Validation loss: 1.4299428603982414

Epoch: 6| Step: 7
Training loss: 0.08287382125854492
Validation loss: 1.4442668031620722

Epoch: 6| Step: 8
Training loss: 0.09222442656755447
Validation loss: 1.430586350861416

Epoch: 6| Step: 9
Training loss: 0.05466661602258682
Validation loss: 1.4039896547153432

Epoch: 6| Step: 10
Training loss: 0.11435815691947937
Validation loss: 1.42621704839891

Epoch: 6| Step: 11
Training loss: 0.108763188123703
Validation loss: 1.4455637085822322

Epoch: 6| Step: 12
Training loss: 0.08948138356208801
Validation loss: 1.4366425006620345

Epoch: 6| Step: 13
Training loss: 0.08437151461839676
Validation loss: 1.4318150833088865

Epoch: 553| Step: 0
Training loss: 0.07449833303689957
Validation loss: 1.4756267339952531

Epoch: 6| Step: 1
Training loss: 0.10156551748514175
Validation loss: 1.4844023764774363

Epoch: 6| Step: 2
Training loss: 0.07551334798336029
Validation loss: 1.480725230709199

Epoch: 6| Step: 3
Training loss: 0.1436384916305542
Validation loss: 1.5010939400683168

Epoch: 6| Step: 4
Training loss: 0.07794919610023499
Validation loss: 1.5149355421784103

Epoch: 6| Step: 5
Training loss: 0.06034903973340988
Validation loss: 1.4954815731253674

Epoch: 6| Step: 6
Training loss: 0.11816325038671494
Validation loss: 1.4854149119828337

Epoch: 6| Step: 7
Training loss: 0.10188060253858566
Validation loss: 1.4972999095916748

Epoch: 6| Step: 8
Training loss: 0.08902084082365036
Validation loss: 1.4742906196143037

Epoch: 6| Step: 9
Training loss: 0.08398065716028214
Validation loss: 1.4440863286295245

Epoch: 6| Step: 10
Training loss: 0.08037612587213516
Validation loss: 1.4581263347338604

Epoch: 6| Step: 11
Training loss: 0.08552052080631256
Validation loss: 1.4416963438833914

Epoch: 6| Step: 12
Training loss: 0.10550414025783539
Validation loss: 1.4460955242956839

Epoch: 6| Step: 13
Training loss: 0.04722055792808533
Validation loss: 1.4428894404442079

Epoch: 554| Step: 0
Training loss: 0.07453538477420807
Validation loss: 1.4571627737373434

Epoch: 6| Step: 1
Training loss: 0.11936627328395844
Validation loss: 1.4352740267271638

Epoch: 6| Step: 2
Training loss: 0.04687218740582466
Validation loss: 1.434639762806636

Epoch: 6| Step: 3
Training loss: 0.054613687098026276
Validation loss: 1.434829327367967

Epoch: 6| Step: 4
Training loss: 0.08353486657142639
Validation loss: 1.4461353837802846

Epoch: 6| Step: 5
Training loss: 0.11576889455318451
Validation loss: 1.4498715003331502

Epoch: 6| Step: 6
Training loss: 0.04394540935754776
Validation loss: 1.4530812155815862

Epoch: 6| Step: 7
Training loss: 0.09852263331413269
Validation loss: 1.465450474651911

Epoch: 6| Step: 8
Training loss: 0.09854401648044586
Validation loss: 1.485668300300516

Epoch: 6| Step: 9
Training loss: 0.11512591689825058
Validation loss: 1.462389406337533

Epoch: 6| Step: 10
Training loss: 0.07263273745775223
Validation loss: 1.4956920903216127

Epoch: 6| Step: 11
Training loss: 0.11506207287311554
Validation loss: 1.501576037817104

Epoch: 6| Step: 12
Training loss: 0.06069134175777435
Validation loss: 1.498816805501138

Epoch: 6| Step: 13
Training loss: 0.07061921805143356
Validation loss: 1.5052569963598763

Epoch: 555| Step: 0
Training loss: 0.06175585836172104
Validation loss: 1.5225077623962073

Epoch: 6| Step: 1
Training loss: 0.08731065690517426
Validation loss: 1.5188953107403171

Epoch: 6| Step: 2
Training loss: 0.08333763480186462
Validation loss: 1.4933322180983841

Epoch: 6| Step: 3
Training loss: 0.09409622102975845
Validation loss: 1.482231782328698

Epoch: 6| Step: 4
Training loss: 0.08478855341672897
Validation loss: 1.4993224041436308

Epoch: 6| Step: 5
Training loss: 0.07983288168907166
Validation loss: 1.4801324426486928

Epoch: 6| Step: 6
Training loss: 0.0923176109790802
Validation loss: 1.4959001207864413

Epoch: 6| Step: 7
Training loss: 0.06950728595256805
Validation loss: 1.4733797837329168

Epoch: 6| Step: 8
Training loss: 0.11863069981336594
Validation loss: 1.4745689797145065

Epoch: 6| Step: 9
Training loss: 0.07246905565261841
Validation loss: 1.5124999143744027

Epoch: 6| Step: 10
Training loss: 0.09918679296970367
Validation loss: 1.525320928583863

Epoch: 6| Step: 11
Training loss: 0.0954388976097107
Validation loss: 1.538654560683876

Epoch: 6| Step: 12
Training loss: 0.0884765088558197
Validation loss: 1.5202810969403995

Epoch: 6| Step: 13
Training loss: 0.07220784574747086
Validation loss: 1.4940240434421006

Epoch: 556| Step: 0
Training loss: 0.0811668410897255
Validation loss: 1.49647186135733

Epoch: 6| Step: 1
Training loss: 0.09064114093780518
Validation loss: 1.4493035411321988

Epoch: 6| Step: 2
Training loss: 0.06876280903816223
Validation loss: 1.4580724008621708

Epoch: 6| Step: 3
Training loss: 0.09752297401428223
Validation loss: 1.4448403389223161

Epoch: 6| Step: 4
Training loss: 0.061498526483774185
Validation loss: 1.4583829038886613

Epoch: 6| Step: 5
Training loss: 0.05385039001703262
Validation loss: 1.4671947981721611

Epoch: 6| Step: 6
Training loss: 0.16328027844429016
Validation loss: 1.476491871700492

Epoch: 6| Step: 7
Training loss: 0.16164210438728333
Validation loss: 1.4389118491321482

Epoch: 6| Step: 8
Training loss: 0.13358968496322632
Validation loss: 1.4888846002599245

Epoch: 6| Step: 9
Training loss: 0.048088885843753815
Validation loss: 1.4697527462436306

Epoch: 6| Step: 10
Training loss: 0.10407590121030807
Validation loss: 1.502140942440238

Epoch: 6| Step: 11
Training loss: 0.10601207613945007
Validation loss: 1.4746431676290368

Epoch: 6| Step: 12
Training loss: 0.06590577960014343
Validation loss: 1.513036157495232

Epoch: 6| Step: 13
Training loss: 0.12823425233364105
Validation loss: 1.463562201428157

Epoch: 557| Step: 0
Training loss: 0.09046167880296707
Validation loss: 1.504415237775413

Epoch: 6| Step: 1
Training loss: 0.12482212483882904
Validation loss: 1.500365957137077

Epoch: 6| Step: 2
Training loss: 0.07112223654985428
Validation loss: 1.5042343126830233

Epoch: 6| Step: 3
Training loss: 0.06960786879062653
Validation loss: 1.5119753447912072

Epoch: 6| Step: 4
Training loss: 0.08600036799907684
Validation loss: 1.4751415637231642

Epoch: 6| Step: 5
Training loss: 0.11555293202400208
Validation loss: 1.5065228823692567

Epoch: 6| Step: 6
Training loss: 0.11194157600402832
Validation loss: 1.4501825224968694

Epoch: 6| Step: 7
Training loss: 0.040443580597639084
Validation loss: 1.4690348627746745

Epoch: 6| Step: 8
Training loss: 0.07446970045566559
Validation loss: 1.4847696737576557

Epoch: 6| Step: 9
Training loss: 0.1307567059993744
Validation loss: 1.4593893558748308

Epoch: 6| Step: 10
Training loss: 0.09696108102798462
Validation loss: 1.4494652780153419

Epoch: 6| Step: 11
Training loss: 0.09499280154705048
Validation loss: 1.451722797527108

Epoch: 6| Step: 12
Training loss: 0.06672357022762299
Validation loss: 1.44669157971618

Epoch: 6| Step: 13
Training loss: 0.14725251495838165
Validation loss: 1.4613511126528504

Epoch: 558| Step: 0
Training loss: 0.0425824299454689
Validation loss: 1.454868165395593

Epoch: 6| Step: 1
Training loss: 0.07665396481752396
Validation loss: 1.466639462337699

Epoch: 6| Step: 2
Training loss: 0.05950869247317314
Validation loss: 1.4872788742024412

Epoch: 6| Step: 3
Training loss: 0.10163907706737518
Validation loss: 1.492982061960364

Epoch: 6| Step: 4
Training loss: 0.10491423308849335
Validation loss: 1.48555100540961

Epoch: 6| Step: 5
Training loss: 0.07631916552782059
Validation loss: 1.455228033886161

Epoch: 6| Step: 6
Training loss: 0.06104031950235367
Validation loss: 1.4646445999863327

Epoch: 6| Step: 7
Training loss: 0.10364343225955963
Validation loss: 1.4666911543056529

Epoch: 6| Step: 8
Training loss: 0.06703208386898041
Validation loss: 1.44375910938427

Epoch: 6| Step: 9
Training loss: 0.057450465857982635
Validation loss: 1.4421215159918672

Epoch: 6| Step: 10
Training loss: 0.09325279295444489
Validation loss: 1.454909973247077

Epoch: 6| Step: 11
Training loss: 0.08807657659053802
Validation loss: 1.4233823617299397

Epoch: 6| Step: 12
Training loss: 0.11063355952501297
Validation loss: 1.4548836408122894

Epoch: 6| Step: 13
Training loss: 0.10623429715633392
Validation loss: 1.4601925419222923

Epoch: 559| Step: 0
Training loss: 0.06831046938896179
Validation loss: 1.4572065427739134

Epoch: 6| Step: 1
Training loss: 0.08183073997497559
Validation loss: 1.4334546327590942

Epoch: 6| Step: 2
Training loss: 0.1526966094970703
Validation loss: 1.4759636579021331

Epoch: 6| Step: 3
Training loss: 0.07316834479570389
Validation loss: 1.4383062316525368

Epoch: 6| Step: 4
Training loss: 0.08419903367757797
Validation loss: 1.4655507149234894

Epoch: 6| Step: 5
Training loss: 0.045572131872177124
Validation loss: 1.4494446926219489

Epoch: 6| Step: 6
Training loss: 0.05637776106595993
Validation loss: 1.4534045624476608

Epoch: 6| Step: 7
Training loss: 0.06741182506084442
Validation loss: 1.443893668472126

Epoch: 6| Step: 8
Training loss: 0.08942477405071259
Validation loss: 1.4532988212441886

Epoch: 6| Step: 9
Training loss: 0.13134559988975525
Validation loss: 1.4492825500426754

Epoch: 6| Step: 10
Training loss: 0.12730450928211212
Validation loss: 1.4382441659127512

Epoch: 6| Step: 11
Training loss: 0.08564041554927826
Validation loss: 1.4483196222653953

Epoch: 6| Step: 12
Training loss: 0.10028857737779617
Validation loss: 1.4280841356964522

Epoch: 6| Step: 13
Training loss: 0.0708177387714386
Validation loss: 1.4440731297257126

Epoch: 560| Step: 0
Training loss: 0.053563736379146576
Validation loss: 1.449976360926064

Epoch: 6| Step: 1
Training loss: 0.10497981309890747
Validation loss: 1.456451242328972

Epoch: 6| Step: 2
Training loss: 0.06498847901821136
Validation loss: 1.4325795276190645

Epoch: 6| Step: 3
Training loss: 0.10892929881811142
Validation loss: 1.470420361847006

Epoch: 6| Step: 4
Training loss: 0.06466366350650787
Validation loss: 1.4438816988339989

Epoch: 6| Step: 5
Training loss: 0.06948278844356537
Validation loss: 1.4253848169439582

Epoch: 6| Step: 6
Training loss: 0.06421523541212082
Validation loss: 1.45853102848094

Epoch: 6| Step: 7
Training loss: 0.07159078866243362
Validation loss: 1.475074960339454

Epoch: 6| Step: 8
Training loss: 0.08169178664684296
Validation loss: 1.460549492989817

Epoch: 6| Step: 9
Training loss: 0.07890403270721436
Validation loss: 1.4729877146341468

Epoch: 6| Step: 10
Training loss: 0.03477104380726814
Validation loss: 1.4711219162069342

Epoch: 6| Step: 11
Training loss: 0.0507168211042881
Validation loss: 1.4462630697475967

Epoch: 6| Step: 12
Training loss: 0.09050765633583069
Validation loss: 1.4637404244433168

Epoch: 6| Step: 13
Training loss: 0.11326927691698074
Validation loss: 1.4511172322816746

Epoch: 561| Step: 0
Training loss: 0.09112681448459625
Validation loss: 1.4581425946245912

Epoch: 6| Step: 1
Training loss: 0.0648854523897171
Validation loss: 1.4692281253876225

Epoch: 6| Step: 2
Training loss: 0.05220331251621246
Validation loss: 1.4403558315769318

Epoch: 6| Step: 3
Training loss: 0.07764940708875656
Validation loss: 1.4493219685810868

Epoch: 6| Step: 4
Training loss: 0.11352077126502991
Validation loss: 1.488036891465546

Epoch: 6| Step: 5
Training loss: 0.0800522044301033
Validation loss: 1.4481476224878782

Epoch: 6| Step: 6
Training loss: 0.11400002241134644
Validation loss: 1.4526810325602049

Epoch: 6| Step: 7
Training loss: 0.08717066794633865
Validation loss: 1.4198179103994881

Epoch: 6| Step: 8
Training loss: 0.10219795256853104
Validation loss: 1.4619925304125714

Epoch: 6| Step: 9
Training loss: 0.09185421466827393
Validation loss: 1.4434639343651392

Epoch: 6| Step: 10
Training loss: 0.08043096959590912
Validation loss: 1.4306077931516914

Epoch: 6| Step: 11
Training loss: 0.1198389008641243
Validation loss: 1.4398118475432038

Epoch: 6| Step: 12
Training loss: 0.059485748410224915
Validation loss: 1.4336566437957108

Epoch: 6| Step: 13
Training loss: 0.05931757390499115
Validation loss: 1.4134857910935597

Epoch: 562| Step: 0
Training loss: 0.05167143791913986
Validation loss: 1.460862159729004

Epoch: 6| Step: 1
Training loss: 0.07971718907356262
Validation loss: 1.4683805076024865

Epoch: 6| Step: 2
Training loss: 0.06525354087352753
Validation loss: 1.4622758870483727

Epoch: 6| Step: 3
Training loss: 0.08303575217723846
Validation loss: 1.4637641727283437

Epoch: 6| Step: 4
Training loss: 0.062119562178850174
Validation loss: 1.4850309100202335

Epoch: 6| Step: 5
Training loss: 0.04487869143486023
Validation loss: 1.4899508081456667

Epoch: 6| Step: 6
Training loss: 0.08044371008872986
Validation loss: 1.5140689957526423

Epoch: 6| Step: 7
Training loss: 0.07981471717357635
Validation loss: 1.509031782868088

Epoch: 6| Step: 8
Training loss: 0.1394190639257431
Validation loss: 1.532456894074717

Epoch: 6| Step: 9
Training loss: 0.09061728417873383
Validation loss: 1.5515681466748636

Epoch: 6| Step: 10
Training loss: 0.08964727818965912
Validation loss: 1.5513989669020458

Epoch: 6| Step: 11
Training loss: 0.07034359872341156
Validation loss: 1.557585003555462

Epoch: 6| Step: 12
Training loss: 0.07743299007415771
Validation loss: 1.5426137306356942

Epoch: 6| Step: 13
Training loss: 0.054324790835380554
Validation loss: 1.5433106524969942

Epoch: 563| Step: 0
Training loss: 0.11671952903270721
Validation loss: 1.5090484856277384

Epoch: 6| Step: 1
Training loss: 0.06050708144903183
Validation loss: 1.5067653957233633

Epoch: 6| Step: 2
Training loss: 0.06702449917793274
Validation loss: 1.4824563585301882

Epoch: 6| Step: 3
Training loss: 0.10590557754039764
Validation loss: 1.464550927121152

Epoch: 6| Step: 4
Training loss: 0.1118522360920906
Validation loss: 1.455862550325291

Epoch: 6| Step: 5
Training loss: 0.057422202080488205
Validation loss: 1.4487617374748312

Epoch: 6| Step: 6
Training loss: 0.08082142472267151
Validation loss: 1.4386242525551909

Epoch: 6| Step: 7
Training loss: 0.07364886999130249
Validation loss: 1.4281069847845262

Epoch: 6| Step: 8
Training loss: 0.08643447607755661
Validation loss: 1.4642253595013772

Epoch: 6| Step: 9
Training loss: 0.09332268685102463
Validation loss: 1.452860821959793

Epoch: 6| Step: 10
Training loss: 0.04460179805755615
Validation loss: 1.4340986692777244

Epoch: 6| Step: 11
Training loss: 0.11322840303182602
Validation loss: 1.447557210281331

Epoch: 6| Step: 12
Training loss: 0.06465870887041092
Validation loss: 1.4323396631466445

Epoch: 6| Step: 13
Training loss: 0.05742408707737923
Validation loss: 1.4358594302208192

Epoch: 564| Step: 0
Training loss: 0.06766508519649506
Validation loss: 1.4384243398584344

Epoch: 6| Step: 1
Training loss: 0.11831052601337433
Validation loss: 1.4473090146177559

Epoch: 6| Step: 2
Training loss: 0.059670913964509964
Validation loss: 1.465394751999968

Epoch: 6| Step: 3
Training loss: 0.07461683452129364
Validation loss: 1.4831518998710058

Epoch: 6| Step: 4
Training loss: 0.09611281752586365
Validation loss: 1.476639514328331

Epoch: 6| Step: 5
Training loss: 0.12591825425624847
Validation loss: 1.4694293468229231

Epoch: 6| Step: 6
Training loss: 0.06615564227104187
Validation loss: 1.467634198486164

Epoch: 6| Step: 7
Training loss: 0.05227751284837723
Validation loss: 1.4621241579773605

Epoch: 6| Step: 8
Training loss: 0.0783301442861557
Validation loss: 1.4536274556190736

Epoch: 6| Step: 9
Training loss: 0.07080164551734924
Validation loss: 1.4691041541355911

Epoch: 6| Step: 10
Training loss: 0.07939700782299042
Validation loss: 1.4547294442371657

Epoch: 6| Step: 11
Training loss: 0.11055997014045715
Validation loss: 1.4910063685909394

Epoch: 6| Step: 12
Training loss: 0.09613543748855591
Validation loss: 1.4872483181697067

Epoch: 6| Step: 13
Training loss: 0.11590538918972015
Validation loss: 1.4942683250673356

Epoch: 565| Step: 0
Training loss: 0.07073989510536194
Validation loss: 1.4807194727723316

Epoch: 6| Step: 1
Training loss: 0.09766452759504318
Validation loss: 1.4872961454494025

Epoch: 6| Step: 2
Training loss: 0.08581365644931793
Validation loss: 1.4803430559814617

Epoch: 6| Step: 3
Training loss: 0.0377945750951767
Validation loss: 1.4837255657360118

Epoch: 6| Step: 4
Training loss: 0.13678079843521118
Validation loss: 1.4728926740666872

Epoch: 6| Step: 5
Training loss: 0.06183788180351257
Validation loss: 1.4494001685932119

Epoch: 6| Step: 6
Training loss: 0.0781281590461731
Validation loss: 1.4384109140724264

Epoch: 6| Step: 7
Training loss: 0.06312774121761322
Validation loss: 1.4553876564066897

Epoch: 6| Step: 8
Training loss: 0.05048801004886627
Validation loss: 1.4514623188203382

Epoch: 6| Step: 9
Training loss: 0.07253843545913696
Validation loss: 1.4626945398187126

Epoch: 6| Step: 10
Training loss: 0.08553792536258698
Validation loss: 1.4960652045024339

Epoch: 6| Step: 11
Training loss: 0.08771274238824844
Validation loss: 1.4962172418512323

Epoch: 6| Step: 12
Training loss: 0.06913009285926819
Validation loss: 1.5097714995825162

Epoch: 6| Step: 13
Training loss: 0.14239655435085297
Validation loss: 1.5112020943754463

Epoch: 566| Step: 0
Training loss: 0.109278105199337
Validation loss: 1.495964369466228

Epoch: 6| Step: 1
Training loss: 0.09580099582672119
Validation loss: 1.5168442918408302

Epoch: 6| Step: 2
Training loss: 0.0526207759976387
Validation loss: 1.4856252836924728

Epoch: 6| Step: 3
Training loss: 0.05200912803411484
Validation loss: 1.4910767193763488

Epoch: 6| Step: 4
Training loss: 0.07406172156333923
Validation loss: 1.4775217181892806

Epoch: 6| Step: 5
Training loss: 0.14106228947639465
Validation loss: 1.5010062635585826

Epoch: 6| Step: 6
Training loss: 0.07384401559829712
Validation loss: 1.4575292384752663

Epoch: 6| Step: 7
Training loss: 0.0723225548863411
Validation loss: 1.4647986645339637

Epoch: 6| Step: 8
Training loss: 0.03987451642751694
Validation loss: 1.4563826245646323

Epoch: 6| Step: 9
Training loss: 0.09241601824760437
Validation loss: 1.4334265237213464

Epoch: 6| Step: 10
Training loss: 0.06501275300979614
Validation loss: 1.4393592380708264

Epoch: 6| Step: 11
Training loss: 0.10171852260828018
Validation loss: 1.4363541314678807

Epoch: 6| Step: 12
Training loss: 0.08211103081703186
Validation loss: 1.471727600661657

Epoch: 6| Step: 13
Training loss: 0.05028403922915459
Validation loss: 1.4809948346948112

Epoch: 567| Step: 0
Training loss: 0.06195307523012161
Validation loss: 1.5153832204880253

Epoch: 6| Step: 1
Training loss: 0.08682826906442642
Validation loss: 1.501198600697261

Epoch: 6| Step: 2
Training loss: 0.11469077318906784
Validation loss: 1.5138246218363445

Epoch: 6| Step: 3
Training loss: 0.11324415355920792
Validation loss: 1.5121365900962584

Epoch: 6| Step: 4
Training loss: 0.06921014934778214
Validation loss: 1.5077391824414652

Epoch: 6| Step: 5
Training loss: 0.06424637138843536
Validation loss: 1.5004770448130946

Epoch: 6| Step: 6
Training loss: 0.08059345185756683
Validation loss: 1.4910475771914247

Epoch: 6| Step: 7
Training loss: 0.058788079768419266
Validation loss: 1.4535475777041527

Epoch: 6| Step: 8
Training loss: 0.07597377896308899
Validation loss: 1.4427791205785607

Epoch: 6| Step: 9
Training loss: 0.08216989040374756
Validation loss: 1.4853720408613964

Epoch: 6| Step: 10
Training loss: 0.0711614340543747
Validation loss: 1.479733105628721

Epoch: 6| Step: 11
Training loss: 0.05810333788394928
Validation loss: 1.485387816224047

Epoch: 6| Step: 12
Training loss: 0.08867212384939194
Validation loss: 1.4723632502299484

Epoch: 6| Step: 13
Training loss: 0.06116320565342903
Validation loss: 1.4522704719215311

Epoch: 568| Step: 0
Training loss: 0.07720650732517242
Validation loss: 1.442335521662107

Epoch: 6| Step: 1
Training loss: 0.08418402075767517
Validation loss: 1.4445130055950535

Epoch: 6| Step: 2
Training loss: 0.05931168794631958
Validation loss: 1.427952125508298

Epoch: 6| Step: 3
Training loss: 0.07214945554733276
Validation loss: 1.4391156063284924

Epoch: 6| Step: 4
Training loss: 0.05755279213190079
Validation loss: 1.4424920569184005

Epoch: 6| Step: 5
Training loss: 0.05021438002586365
Validation loss: 1.4359682586885267

Epoch: 6| Step: 6
Training loss: 0.08379331231117249
Validation loss: 1.4222390356884207

Epoch: 6| Step: 7
Training loss: 0.11898918449878693
Validation loss: 1.4192528711852206

Epoch: 6| Step: 8
Training loss: 0.07179690152406693
Validation loss: 1.4216142405745804

Epoch: 6| Step: 9
Training loss: 0.06096287816762924
Validation loss: 1.42672800120487

Epoch: 6| Step: 10
Training loss: 0.06389918923377991
Validation loss: 1.4215666850407918

Epoch: 6| Step: 11
Training loss: 0.08880075812339783
Validation loss: 1.432177576967465

Epoch: 6| Step: 12
Training loss: 0.062911756336689
Validation loss: 1.444752582298812

Epoch: 6| Step: 13
Training loss: 0.04837565869092941
Validation loss: 1.432586746831094

Epoch: 569| Step: 0
Training loss: 0.09773865342140198
Validation loss: 1.432828305869974

Epoch: 6| Step: 1
Training loss: 0.04935348033905029
Validation loss: 1.4387412942865843

Epoch: 6| Step: 2
Training loss: 0.12124823778867722
Validation loss: 1.4369203159886021

Epoch: 6| Step: 3
Training loss: 0.08401386439800262
Validation loss: 1.412063293559577

Epoch: 6| Step: 4
Training loss: 0.07067703455686569
Validation loss: 1.4045757503919705

Epoch: 6| Step: 5
Training loss: 0.05771069973707199
Validation loss: 1.444372707797635

Epoch: 6| Step: 6
Training loss: 0.09426063299179077
Validation loss: 1.4261465892996839

Epoch: 6| Step: 7
Training loss: 0.1187637448310852
Validation loss: 1.4299712245182326

Epoch: 6| Step: 8
Training loss: 0.06689527630805969
Validation loss: 1.427898669755587

Epoch: 6| Step: 9
Training loss: 0.0579497292637825
Validation loss: 1.4435816029066681

Epoch: 6| Step: 10
Training loss: 0.11194432526826859
Validation loss: 1.445270105715721

Epoch: 6| Step: 11
Training loss: 0.04814864695072174
Validation loss: 1.4522874534771006

Epoch: 6| Step: 12
Training loss: 0.0642058402299881
Validation loss: 1.4355865434933734

Epoch: 6| Step: 13
Training loss: 0.07750949263572693
Validation loss: 1.447373262015722

Epoch: 570| Step: 0
Training loss: 0.07568006217479706
Validation loss: 1.4565752667765464

Epoch: 6| Step: 1
Training loss: 0.07372346520423889
Validation loss: 1.4749400513146513

Epoch: 6| Step: 2
Training loss: 0.09708353877067566
Validation loss: 1.4764540285192511

Epoch: 6| Step: 3
Training loss: 0.059927038848400116
Validation loss: 1.4565272023600917

Epoch: 6| Step: 4
Training loss: 0.07251427322626114
Validation loss: 1.495297690873505

Epoch: 6| Step: 5
Training loss: 0.10230842232704163
Validation loss: 1.4332685355217225

Epoch: 6| Step: 6
Training loss: 0.05055874586105347
Validation loss: 1.468812887386609

Epoch: 6| Step: 7
Training loss: 0.09078290313482285
Validation loss: 1.4850158883679299

Epoch: 6| Step: 8
Training loss: 0.05867432802915573
Validation loss: 1.458237830028739

Epoch: 6| Step: 9
Training loss: 0.058995842933654785
Validation loss: 1.4890380174882951

Epoch: 6| Step: 10
Training loss: 0.09738962352275848
Validation loss: 1.4805811887146325

Epoch: 6| Step: 11
Training loss: 0.11874853819608688
Validation loss: 1.482879554071734

Epoch: 6| Step: 12
Training loss: 0.07170180231332779
Validation loss: 1.486037774752545

Epoch: 6| Step: 13
Training loss: 0.04985034465789795
Validation loss: 1.483514283293037

Epoch: 571| Step: 0
Training loss: 0.10523959249258041
Validation loss: 1.4779443202480194

Epoch: 6| Step: 1
Training loss: 0.07385851442813873
Validation loss: 1.4430119722120223

Epoch: 6| Step: 2
Training loss: 0.06954750418663025
Validation loss: 1.4479661167308848

Epoch: 6| Step: 3
Training loss: 0.07531004399061203
Validation loss: 1.4480203601621813

Epoch: 6| Step: 4
Training loss: 0.040318939834833145
Validation loss: 1.466543201477297

Epoch: 6| Step: 5
Training loss: 0.06288868188858032
Validation loss: 1.440337093927527

Epoch: 6| Step: 6
Training loss: 0.06435054540634155
Validation loss: 1.4323581072591967

Epoch: 6| Step: 7
Training loss: 0.09777478873729706
Validation loss: 1.4501070860893495

Epoch: 6| Step: 8
Training loss: 0.06669590622186661
Validation loss: 1.424189971339318

Epoch: 6| Step: 9
Training loss: 0.09404364228248596
Validation loss: 1.419893023788288

Epoch: 6| Step: 10
Training loss: 0.04961807280778885
Validation loss: 1.4319713692511282

Epoch: 6| Step: 11
Training loss: 0.07584160566329956
Validation loss: 1.4297711515939364

Epoch: 6| Step: 12
Training loss: 0.07273081690073013
Validation loss: 1.4276719618869085

Epoch: 6| Step: 13
Training loss: 0.0993412435054779
Validation loss: 1.455873752153048

Epoch: 572| Step: 0
Training loss: 0.077244333922863
Validation loss: 1.4740317944557435

Epoch: 6| Step: 1
Training loss: 0.04803413525223732
Validation loss: 1.475674642029629

Epoch: 6| Step: 2
Training loss: 0.09631025791168213
Validation loss: 1.4806340189390286

Epoch: 6| Step: 3
Training loss: 0.11443894356489182
Validation loss: 1.5243125243853497

Epoch: 6| Step: 4
Training loss: 0.09927745163440704
Validation loss: 1.5127177328191779

Epoch: 6| Step: 5
Training loss: 0.06694654375314713
Validation loss: 1.5063104808971446

Epoch: 6| Step: 6
Training loss: 0.055965445935726166
Validation loss: 1.519261642168927

Epoch: 6| Step: 7
Training loss: 0.04576488584280014
Validation loss: 1.4835337464527418

Epoch: 6| Step: 8
Training loss: 0.05906260758638382
Validation loss: 1.4896171990261282

Epoch: 6| Step: 9
Training loss: 0.06986439228057861
Validation loss: 1.4847291143991614

Epoch: 6| Step: 10
Training loss: 0.051598113030195236
Validation loss: 1.4630904915512248

Epoch: 6| Step: 11
Training loss: 0.04736856371164322
Validation loss: 1.4591701158913233

Epoch: 6| Step: 12
Training loss: 0.08010283857584
Validation loss: 1.459943163779474

Epoch: 6| Step: 13
Training loss: 0.08808556199073792
Validation loss: 1.4520488439067718

Epoch: 573| Step: 0
Training loss: 0.07117054611444473
Validation loss: 1.4332027102029452

Epoch: 6| Step: 1
Training loss: 0.08212754875421524
Validation loss: 1.4419540551400953

Epoch: 6| Step: 2
Training loss: 0.049796029925346375
Validation loss: 1.4677696433118594

Epoch: 6| Step: 3
Training loss: 0.07647787034511566
Validation loss: 1.473740695625223

Epoch: 6| Step: 4
Training loss: 0.0676717460155487
Validation loss: 1.4794545404372677

Epoch: 6| Step: 5
Training loss: 0.09192470461130142
Validation loss: 1.4725183594611384

Epoch: 6| Step: 6
Training loss: 0.06612147390842438
Validation loss: 1.4979083166327527

Epoch: 6| Step: 7
Training loss: 0.05588666349649429
Validation loss: 1.4974507542066677

Epoch: 6| Step: 8
Training loss: 0.07365639507770538
Validation loss: 1.4800324222092986

Epoch: 6| Step: 9
Training loss: 0.06286729127168655
Validation loss: 1.4588577901163409

Epoch: 6| Step: 10
Training loss: 0.081366628408432
Validation loss: 1.451236637689734

Epoch: 6| Step: 11
Training loss: 0.08257754147052765
Validation loss: 1.4713273586765412

Epoch: 6| Step: 12
Training loss: 0.0673416405916214
Validation loss: 1.4651497179462063

Epoch: 6| Step: 13
Training loss: 0.08808723092079163
Validation loss: 1.4733334946376022

Epoch: 574| Step: 0
Training loss: 0.08025050163269043
Validation loss: 1.493824061527047

Epoch: 6| Step: 1
Training loss: 0.036635130643844604
Validation loss: 1.472729108666861

Epoch: 6| Step: 2
Training loss: 0.051418934017419815
Validation loss: 1.4954980124709427

Epoch: 6| Step: 3
Training loss: 0.04373016208410263
Validation loss: 1.4609901866605204

Epoch: 6| Step: 4
Training loss: 0.055553629994392395
Validation loss: 1.4567246731891428

Epoch: 6| Step: 5
Training loss: 0.1313258707523346
Validation loss: 1.4571825099247757

Epoch: 6| Step: 6
Training loss: 0.07516804337501526
Validation loss: 1.4699545073252853

Epoch: 6| Step: 7
Training loss: 0.07123757153749466
Validation loss: 1.45790772796959

Epoch: 6| Step: 8
Training loss: 0.08241886645555496
Validation loss: 1.4772769174268168

Epoch: 6| Step: 9
Training loss: 0.05826331675052643
Validation loss: 1.451377220051263

Epoch: 6| Step: 10
Training loss: 0.06270456314086914
Validation loss: 1.45094689630693

Epoch: 6| Step: 11
Training loss: 0.11150282621383667
Validation loss: 1.436209398572163

Epoch: 6| Step: 12
Training loss: 0.07766105234622955
Validation loss: 1.446455475463662

Epoch: 6| Step: 13
Training loss: 0.06706985831260681
Validation loss: 1.443165293303869

Epoch: 575| Step: 0
Training loss: 0.09382063150405884
Validation loss: 1.4329437068713609

Epoch: 6| Step: 1
Training loss: 0.046235255897045135
Validation loss: 1.462754016281456

Epoch: 6| Step: 2
Training loss: 0.08237770199775696
Validation loss: 1.4617212972333353

Epoch: 6| Step: 3
Training loss: 0.055336568504571915
Validation loss: 1.4347925621976134

Epoch: 6| Step: 4
Training loss: 0.06445495784282684
Validation loss: 1.4663452653474705

Epoch: 6| Step: 5
Training loss: 0.1267969310283661
Validation loss: 1.4410932679330148

Epoch: 6| Step: 6
Training loss: 0.0579727441072464
Validation loss: 1.4657050037896762

Epoch: 6| Step: 7
Training loss: 0.04707936942577362
Validation loss: 1.4702254335085552

Epoch: 6| Step: 8
Training loss: 0.09070238471031189
Validation loss: 1.4567584414635935

Epoch: 6| Step: 9
Training loss: 0.08218961954116821
Validation loss: 1.452974550185665

Epoch: 6| Step: 10
Training loss: 0.06727654486894608
Validation loss: 1.438876631439373

Epoch: 6| Step: 11
Training loss: 0.08471118658781052
Validation loss: 1.4402534064426218

Epoch: 6| Step: 12
Training loss: 0.08223129063844681
Validation loss: 1.4529383938799623

Epoch: 6| Step: 13
Training loss: 0.08543547987937927
Validation loss: 1.4558281058906226

Epoch: 576| Step: 0
Training loss: 0.05507220700383186
Validation loss: 1.4406358913708759

Epoch: 6| Step: 1
Training loss: 0.03545565903186798
Validation loss: 1.4455827666867165

Epoch: 6| Step: 2
Training loss: 0.06745342910289764
Validation loss: 1.454520958726124

Epoch: 6| Step: 3
Training loss: 0.031897448003292084
Validation loss: 1.4451833399393226

Epoch: 6| Step: 4
Training loss: 0.0777418464422226
Validation loss: 1.4281216347089378

Epoch: 6| Step: 5
Training loss: 0.0886518806219101
Validation loss: 1.4273831523874754

Epoch: 6| Step: 6
Training loss: 0.10101291537284851
Validation loss: 1.4341413282578992

Epoch: 6| Step: 7
Training loss: 0.06364057958126068
Validation loss: 1.419907154575471

Epoch: 6| Step: 8
Training loss: 0.058030158281326294
Validation loss: 1.4256456000830537

Epoch: 6| Step: 9
Training loss: 0.06149965152144432
Validation loss: 1.4273497596863778

Epoch: 6| Step: 10
Training loss: 0.0900433138012886
Validation loss: 1.4874654149496427

Epoch: 6| Step: 11
Training loss: 0.07702161371707916
Validation loss: 1.4318622440420172

Epoch: 6| Step: 12
Training loss: 0.06566012650728226
Validation loss: 1.426339167420582

Epoch: 6| Step: 13
Training loss: 0.04227125644683838
Validation loss: 1.4574938269071682

Epoch: 577| Step: 0
Training loss: 0.05118472874164581
Validation loss: 1.44803060126561

Epoch: 6| Step: 1
Training loss: 0.04861871898174286
Validation loss: 1.4531781147885066

Epoch: 6| Step: 2
Training loss: 0.09942483901977539
Validation loss: 1.446557947384414

Epoch: 6| Step: 3
Training loss: 0.08606431633234024
Validation loss: 1.4482242612428562

Epoch: 6| Step: 4
Training loss: 0.07370804995298386
Validation loss: 1.4594615454314857

Epoch: 6| Step: 5
Training loss: 0.06739523261785507
Validation loss: 1.4715476785936663

Epoch: 6| Step: 6
Training loss: 0.06219520419836044
Validation loss: 1.463953915462699

Epoch: 6| Step: 7
Training loss: 0.056385308504104614
Validation loss: 1.4837168916579215

Epoch: 6| Step: 8
Training loss: 0.07307329773902893
Validation loss: 1.4780300919727614

Epoch: 6| Step: 9
Training loss: 0.13211354613304138
Validation loss: 1.4724531917161838

Epoch: 6| Step: 10
Training loss: 0.07855679839849472
Validation loss: 1.4789274546407885

Epoch: 6| Step: 11
Training loss: 0.05332145839929581
Validation loss: 1.489121389645402

Epoch: 6| Step: 12
Training loss: 0.06940881907939911
Validation loss: 1.493461835768915

Epoch: 6| Step: 13
Training loss: 0.09442678838968277
Validation loss: 1.4640525938362203

Epoch: 578| Step: 0
Training loss: 0.04601798951625824
Validation loss: 1.4859692537656395

Epoch: 6| Step: 1
Training loss: 0.09368433058261871
Validation loss: 1.5013663935404953

Epoch: 6| Step: 2
Training loss: 0.09879645705223083
Validation loss: 1.5133336949092087

Epoch: 6| Step: 3
Training loss: 0.10421035438776016
Validation loss: 1.4968873095768753

Epoch: 6| Step: 4
Training loss: 0.06456823647022247
Validation loss: 1.4744722881624777

Epoch: 6| Step: 5
Training loss: 0.09382770210504532
Validation loss: 1.4754576516407791

Epoch: 6| Step: 6
Training loss: 0.0631285160779953
Validation loss: 1.482970885051194

Epoch: 6| Step: 7
Training loss: 0.09397149085998535
Validation loss: 1.4887313381318124

Epoch: 6| Step: 8
Training loss: 0.04015946388244629
Validation loss: 1.4685044057907597

Epoch: 6| Step: 9
Training loss: 0.08115563541650772
Validation loss: 1.460620887817875

Epoch: 6| Step: 10
Training loss: 0.07772001624107361
Validation loss: 1.432456640787022

Epoch: 6| Step: 11
Training loss: 0.051365017890930176
Validation loss: 1.4158083975956004

Epoch: 6| Step: 12
Training loss: 0.06319920718669891
Validation loss: 1.4511989688360563

Epoch: 6| Step: 13
Training loss: 0.0660986602306366
Validation loss: 1.4557271926633772

Epoch: 579| Step: 0
Training loss: 0.0396968275308609
Validation loss: 1.4550919519957675

Epoch: 6| Step: 1
Training loss: 0.05979268252849579
Validation loss: 1.4622864088704508

Epoch: 6| Step: 2
Training loss: 0.06666001677513123
Validation loss: 1.4621231376483876

Epoch: 6| Step: 3
Training loss: 0.07810141891241074
Validation loss: 1.4672641933605235

Epoch: 6| Step: 4
Training loss: 0.05348237603902817
Validation loss: 1.4686721717157671

Epoch: 6| Step: 5
Training loss: 0.05566895008087158
Validation loss: 1.4938982238051712

Epoch: 6| Step: 6
Training loss: 0.08515521138906479
Validation loss: 1.4895842664985246

Epoch: 6| Step: 7
Training loss: 0.038679338991642
Validation loss: 1.4905168305161178

Epoch: 6| Step: 8
Training loss: 0.07903962582349777
Validation loss: 1.5031900085428709

Epoch: 6| Step: 9
Training loss: 0.0574369803071022
Validation loss: 1.5078366289856613

Epoch: 6| Step: 10
Training loss: 0.05521441996097565
Validation loss: 1.4868337223606725

Epoch: 6| Step: 11
Training loss: 0.06341171264648438
Validation loss: 1.4776805049629622

Epoch: 6| Step: 12
Training loss: 0.05331798642873764
Validation loss: 1.4849618134960052

Epoch: 6| Step: 13
Training loss: 0.14145247638225555
Validation loss: 1.4656946351451259

Epoch: 580| Step: 0
Training loss: 0.06839069724082947
Validation loss: 1.444579178287137

Epoch: 6| Step: 1
Training loss: 0.0730670616030693
Validation loss: 1.4394590918735792

Epoch: 6| Step: 2
Training loss: 0.06964372098445892
Validation loss: 1.4153894852566462

Epoch: 6| Step: 3
Training loss: 0.09282366931438446
Validation loss: 1.474375904247325

Epoch: 6| Step: 4
Training loss: 0.09054785966873169
Validation loss: 1.4663198994052025

Epoch: 6| Step: 5
Training loss: 0.07707798480987549
Validation loss: 1.4344500681405425

Epoch: 6| Step: 6
Training loss: 0.04792208969593048
Validation loss: 1.452106709121376

Epoch: 6| Step: 7
Training loss: 0.03113807737827301
Validation loss: 1.4776931616567797

Epoch: 6| Step: 8
Training loss: 0.0898270383477211
Validation loss: 1.4940095486179474

Epoch: 6| Step: 9
Training loss: 0.06525767594575882
Validation loss: 1.5048833008735412

Epoch: 6| Step: 10
Training loss: 0.11184632778167725
Validation loss: 1.518761052880236

Epoch: 6| Step: 11
Training loss: 0.08805609494447708
Validation loss: 1.5195847294663871

Epoch: 6| Step: 12
Training loss: 0.07709668576717377
Validation loss: 1.5116280330124723

Epoch: 6| Step: 13
Training loss: 0.052494969218969345
Validation loss: 1.4953416150103334

Epoch: 581| Step: 0
Training loss: 0.0676320493221283
Validation loss: 1.5045780545921736

Epoch: 6| Step: 1
Training loss: 0.09303589910268784
Validation loss: 1.469907106891755

Epoch: 6| Step: 2
Training loss: 0.13232704997062683
Validation loss: 1.4784562203191942

Epoch: 6| Step: 3
Training loss: 0.22434164583683014
Validation loss: 1.4917932377066663

Epoch: 6| Step: 4
Training loss: 0.10149652510881424
Validation loss: 1.4518687058520574

Epoch: 6| Step: 5
Training loss: 0.0785825103521347
Validation loss: 1.4302326274174515

Epoch: 6| Step: 6
Training loss: 0.11535566300153732
Validation loss: 1.427406758390447

Epoch: 6| Step: 7
Training loss: 0.06992968171834946
Validation loss: 1.421334542253966

Epoch: 6| Step: 8
Training loss: 0.10694678872823715
Validation loss: 1.438083666627125

Epoch: 6| Step: 9
Training loss: 0.09191233664751053
Validation loss: 1.4573381959751088

Epoch: 6| Step: 10
Training loss: 0.15453551709651947
Validation loss: 1.457191873622197

Epoch: 6| Step: 11
Training loss: 0.07115501165390015
Validation loss: 1.4208527406056721

Epoch: 6| Step: 12
Training loss: 0.09430581331253052
Validation loss: 1.426817872190988

Epoch: 6| Step: 13
Training loss: 0.09813262522220612
Validation loss: 1.4190615915483045

Epoch: 582| Step: 0
Training loss: 0.0881081372499466
Validation loss: 1.4397485717650382

Epoch: 6| Step: 1
Training loss: 0.05764010176062584
Validation loss: 1.4426254380133845

Epoch: 6| Step: 2
Training loss: 0.07812874764204025
Validation loss: 1.4614779231368855

Epoch: 6| Step: 3
Training loss: 0.07893567532300949
Validation loss: 1.4761443727759904

Epoch: 6| Step: 4
Training loss: 0.047485023736953735
Validation loss: 1.4878113167260283

Epoch: 6| Step: 5
Training loss: 0.11559347808361053
Validation loss: 1.5073672007488947

Epoch: 6| Step: 6
Training loss: 0.06190304458141327
Validation loss: 1.5230965152863534

Epoch: 6| Step: 7
Training loss: 0.10237366706132889
Validation loss: 1.5002567563005673

Epoch: 6| Step: 8
Training loss: 0.09049885720014572
Validation loss: 1.5180144092088104

Epoch: 6| Step: 9
Training loss: 0.07696712017059326
Validation loss: 1.5431022208224061

Epoch: 6| Step: 10
Training loss: 0.08771941065788269
Validation loss: 1.503725577426213

Epoch: 6| Step: 11
Training loss: 0.10842437297105789
Validation loss: 1.5069868776106066

Epoch: 6| Step: 12
Training loss: 0.15491624176502228
Validation loss: 1.5025325000927012

Epoch: 6| Step: 13
Training loss: 0.038876719772815704
Validation loss: 1.4752878514669274

Epoch: 583| Step: 0
Training loss: 0.058066774159669876
Validation loss: 1.4519165895318473

Epoch: 6| Step: 1
Training loss: 0.08647681772708893
Validation loss: 1.4456525489848147

Epoch: 6| Step: 2
Training loss: 0.07737983763217926
Validation loss: 1.4335373063241281

Epoch: 6| Step: 3
Training loss: 0.0576724037528038
Validation loss: 1.4447664201900523

Epoch: 6| Step: 4
Training loss: 0.06510275602340698
Validation loss: 1.4512948656594882

Epoch: 6| Step: 5
Training loss: 0.05877448618412018
Validation loss: 1.459052985714328

Epoch: 6| Step: 6
Training loss: 0.11736936867237091
Validation loss: 1.4783310198014783

Epoch: 6| Step: 7
Training loss: 0.10571856051683426
Validation loss: 1.449250864726241

Epoch: 6| Step: 8
Training loss: 0.08882579207420349
Validation loss: 1.4457290121304092

Epoch: 6| Step: 9
Training loss: 0.12742173671722412
Validation loss: 1.44934505544683

Epoch: 6| Step: 10
Training loss: 0.06240549683570862
Validation loss: 1.4535139196662492

Epoch: 6| Step: 11
Training loss: 0.06769800186157227
Validation loss: 1.477809823328449

Epoch: 6| Step: 12
Training loss: 0.04782240837812424
Validation loss: 1.4674174683068388

Epoch: 6| Step: 13
Training loss: 0.09744700789451599
Validation loss: 1.4687280539543397

Epoch: 584| Step: 0
Training loss: 0.07803697884082794
Validation loss: 1.4746261155733498

Epoch: 6| Step: 1
Training loss: 0.06133450195193291
Validation loss: 1.4965954493450861

Epoch: 6| Step: 2
Training loss: 0.08506694436073303
Validation loss: 1.4931481422916535

Epoch: 6| Step: 3
Training loss: 0.041618458926677704
Validation loss: 1.491078758111564

Epoch: 6| Step: 4
Training loss: 0.10434611141681671
Validation loss: 1.5064903113149828

Epoch: 6| Step: 5
Training loss: 0.0552409328520298
Validation loss: 1.5307450435494865

Epoch: 6| Step: 6
Training loss: 0.1349973976612091
Validation loss: 1.516484728423498

Epoch: 6| Step: 7
Training loss: 0.07579972594976425
Validation loss: 1.5267767854916152

Epoch: 6| Step: 8
Training loss: 0.07596397399902344
Validation loss: 1.515279418678694

Epoch: 6| Step: 9
Training loss: 0.09606635570526123
Validation loss: 1.4696214327248194

Epoch: 6| Step: 10
Training loss: 0.059998538345098495
Validation loss: 1.4756152655488701

Epoch: 6| Step: 11
Training loss: 0.0662519782781601
Validation loss: 1.4550016823635306

Epoch: 6| Step: 12
Training loss: 0.06547902524471283
Validation loss: 1.481477838690563

Epoch: 6| Step: 13
Training loss: 0.10304927825927734
Validation loss: 1.4566000084723196

Epoch: 585| Step: 0
Training loss: 0.0910368338227272
Validation loss: 1.4726471106211345

Epoch: 6| Step: 1
Training loss: 0.06850194185972214
Validation loss: 1.4877003738957066

Epoch: 6| Step: 2
Training loss: 0.06918849050998688
Validation loss: 1.5165914258649271

Epoch: 6| Step: 3
Training loss: 0.09985558688640594
Validation loss: 1.521340315059949

Epoch: 6| Step: 4
Training loss: 0.11652110517024994
Validation loss: 1.5455236101663241

Epoch: 6| Step: 5
Training loss: 0.08932220935821533
Validation loss: 1.5139897408023957

Epoch: 6| Step: 6
Training loss: 0.05005122348666191
Validation loss: 1.5133581635772542

Epoch: 6| Step: 7
Training loss: 0.08135378360748291
Validation loss: 1.4973789312506234

Epoch: 6| Step: 8
Training loss: 0.04237484559416771
Validation loss: 1.510042618679744

Epoch: 6| Step: 9
Training loss: 0.06423188745975494
Validation loss: 1.4740402608789422

Epoch: 6| Step: 10
Training loss: 0.07861500978469849
Validation loss: 1.4984226239624845

Epoch: 6| Step: 11
Training loss: 0.040385596454143524
Validation loss: 1.4640452528512606

Epoch: 6| Step: 12
Training loss: 0.07810056209564209
Validation loss: 1.4517913697868265

Epoch: 6| Step: 13
Training loss: 0.06662622094154358
Validation loss: 1.4460237115942023

Epoch: 586| Step: 0
Training loss: 0.0734119564294815
Validation loss: 1.462942228522352

Epoch: 6| Step: 1
Training loss: 0.05400320515036583
Validation loss: 1.4546386221403718

Epoch: 6| Step: 2
Training loss: 0.09479693323373795
Validation loss: 1.4594966333399537

Epoch: 6| Step: 3
Training loss: 0.060513731092214584
Validation loss: 1.4575160293168918

Epoch: 6| Step: 4
Training loss: 0.07546599954366684
Validation loss: 1.4780779025887931

Epoch: 6| Step: 5
Training loss: 0.11176866292953491
Validation loss: 1.485724574776106

Epoch: 6| Step: 6
Training loss: 0.1256079226732254
Validation loss: 1.5017942779807634

Epoch: 6| Step: 7
Training loss: 0.10035591572523117
Validation loss: 1.4735149439945017

Epoch: 6| Step: 8
Training loss: 0.05259263515472412
Validation loss: 1.4866751432418823

Epoch: 6| Step: 9
Training loss: 0.07932873070240021
Validation loss: 1.480915900199644

Epoch: 6| Step: 10
Training loss: 0.07729855179786682
Validation loss: 1.482426784371817

Epoch: 6| Step: 11
Training loss: 0.07295498996973038
Validation loss: 1.4852854949171825

Epoch: 6| Step: 12
Training loss: 0.08170221000909805
Validation loss: 1.4541515791287987

Epoch: 6| Step: 13
Training loss: 0.09763365238904953
Validation loss: 1.4894386478649673

Epoch: 587| Step: 0
Training loss: 0.1275925636291504
Validation loss: 1.4782897169871996

Epoch: 6| Step: 1
Training loss: 0.0636419802904129
Validation loss: 1.5056342155702653

Epoch: 6| Step: 2
Training loss: 0.06093868613243103
Validation loss: 1.501990342652926

Epoch: 6| Step: 3
Training loss: 0.05745720863342285
Validation loss: 1.4923832922853448

Epoch: 6| Step: 4
Training loss: 0.10640338063240051
Validation loss: 1.4718718515929354

Epoch: 6| Step: 5
Training loss: 0.060664914548397064
Validation loss: 1.4496515092029367

Epoch: 6| Step: 6
Training loss: 0.06272748857736588
Validation loss: 1.4448962211608887

Epoch: 6| Step: 7
Training loss: 0.09503616392612457
Validation loss: 1.4525654719721885

Epoch: 6| Step: 8
Training loss: 0.06691854447126389
Validation loss: 1.4404332906969133

Epoch: 6| Step: 9
Training loss: 0.07778384536504745
Validation loss: 1.4353606854715655

Epoch: 6| Step: 10
Training loss: 0.06367097795009613
Validation loss: 1.4168501630906136

Epoch: 6| Step: 11
Training loss: 0.060414351522922516
Validation loss: 1.4295446077982585

Epoch: 6| Step: 12
Training loss: 0.07021377980709076
Validation loss: 1.4419512876900293

Epoch: 6| Step: 13
Training loss: 0.08806496858596802
Validation loss: 1.4379703280746297

Epoch: 588| Step: 0
Training loss: 0.08251629024744034
Validation loss: 1.436686029998205

Epoch: 6| Step: 1
Training loss: 0.11593153327703476
Validation loss: 1.478409158286228

Epoch: 6| Step: 2
Training loss: 0.12666046619415283
Validation loss: 1.4681856196413758

Epoch: 6| Step: 3
Training loss: 0.07865804433822632
Validation loss: 1.461251607505224

Epoch: 6| Step: 4
Training loss: 0.10070395469665527
Validation loss: 1.4304150791578396

Epoch: 6| Step: 5
Training loss: 0.06724175810813904
Validation loss: 1.4504699873667892

Epoch: 6| Step: 6
Training loss: 0.11664224416017532
Validation loss: 1.4408785732843543

Epoch: 6| Step: 7
Training loss: 0.07425262033939362
Validation loss: 1.4553663730621338

Epoch: 6| Step: 8
Training loss: 0.10538356006145477
Validation loss: 1.425891605756616

Epoch: 6| Step: 9
Training loss: 0.12455140799283981
Validation loss: 1.4428289398070304

Epoch: 6| Step: 10
Training loss: 0.06116313487291336
Validation loss: 1.4288211240563342

Epoch: 6| Step: 11
Training loss: 0.07971425354480743
Validation loss: 1.4144591939064763

Epoch: 6| Step: 12
Training loss: 0.06171661987900734
Validation loss: 1.4182521117630826

Epoch: 6| Step: 13
Training loss: 0.03264216333627701
Validation loss: 1.4385882180224183

Epoch: 589| Step: 0
Training loss: 0.06835546344518661
Validation loss: 1.4247124182280673

Epoch: 6| Step: 1
Training loss: 0.057191163301467896
Validation loss: 1.4420833459464453

Epoch: 6| Step: 2
Training loss: 0.06682328879833221
Validation loss: 1.4557885303292224

Epoch: 6| Step: 3
Training loss: 0.13231991231441498
Validation loss: 1.4400801120265838

Epoch: 6| Step: 4
Training loss: 0.05579942837357521
Validation loss: 1.4569369131518948

Epoch: 6| Step: 5
Training loss: 0.09804517775774002
Validation loss: 1.4440032718002156

Epoch: 6| Step: 6
Training loss: 0.07277283072471619
Validation loss: 1.470824295474637

Epoch: 6| Step: 7
Training loss: 0.10560329258441925
Validation loss: 1.4740057478668869

Epoch: 6| Step: 8
Training loss: 0.10176458209753036
Validation loss: 1.4606717786481302

Epoch: 6| Step: 9
Training loss: 0.10721740126609802
Validation loss: 1.462444051619499

Epoch: 6| Step: 10
Training loss: 0.06516033411026001
Validation loss: 1.4783464336907992

Epoch: 6| Step: 11
Training loss: 0.07546235620975494
Validation loss: 1.4961341683582594

Epoch: 6| Step: 12
Training loss: 0.060835111886262894
Validation loss: 1.4939560210832985

Epoch: 6| Step: 13
Training loss: 0.0776946172118187
Validation loss: 1.4973858582076205

Epoch: 590| Step: 0
Training loss: 0.08628670126199722
Validation loss: 1.4848061287274925

Epoch: 6| Step: 1
Training loss: 0.0659300908446312
Validation loss: 1.477643257828169

Epoch: 6| Step: 2
Training loss: 0.05902577564120293
Validation loss: 1.4984330566980506

Epoch: 6| Step: 3
Training loss: 0.06007061153650284
Validation loss: 1.4556459188461304

Epoch: 6| Step: 4
Training loss: 0.09516077488660812
Validation loss: 1.446767835206883

Epoch: 6| Step: 5
Training loss: 0.05939090624451637
Validation loss: 1.4347820320437032

Epoch: 6| Step: 6
Training loss: 0.09215301275253296
Validation loss: 1.4383311771577405

Epoch: 6| Step: 7
Training loss: 0.07190366089344025
Validation loss: 1.4240131602492383

Epoch: 6| Step: 8
Training loss: 0.05444701015949249
Validation loss: 1.4155891351802374

Epoch: 6| Step: 9
Training loss: 0.054737359285354614
Validation loss: 1.4488943135866554

Epoch: 6| Step: 10
Training loss: 0.06045021116733551
Validation loss: 1.4257260580216684

Epoch: 6| Step: 11
Training loss: 0.055026814341545105
Validation loss: 1.448687075286783

Epoch: 6| Step: 12
Training loss: 0.06454505771398544
Validation loss: 1.4351803961620535

Epoch: 6| Step: 13
Training loss: 0.050789497792720795
Validation loss: 1.4622642711926532

Epoch: 591| Step: 0
Training loss: 0.04971487820148468
Validation loss: 1.475094695245066

Epoch: 6| Step: 1
Training loss: 0.12245430052280426
Validation loss: 1.4805133445288545

Epoch: 6| Step: 2
Training loss: 0.08880271762609482
Validation loss: 1.4688469850888817

Epoch: 6| Step: 3
Training loss: 0.052577316761016846
Validation loss: 1.4641201598669893

Epoch: 6| Step: 4
Training loss: 0.092006616294384
Validation loss: 1.4680371848485803

Epoch: 6| Step: 5
Training loss: 0.08117344975471497
Validation loss: 1.4827473766060286

Epoch: 6| Step: 6
Training loss: 0.04255488142371178
Validation loss: 1.457317615068087

Epoch: 6| Step: 7
Training loss: 0.08681489527225494
Validation loss: 1.471542466071344

Epoch: 6| Step: 8
Training loss: 0.1251237392425537
Validation loss: 1.4452145086821688

Epoch: 6| Step: 9
Training loss: 0.10809159278869629
Validation loss: 1.4391077654336089

Epoch: 6| Step: 10
Training loss: 0.07548234611749649
Validation loss: 1.4285775538413756

Epoch: 6| Step: 11
Training loss: 0.07514455169439316
Validation loss: 1.4536509488218574

Epoch: 6| Step: 12
Training loss: 0.056085921823978424
Validation loss: 1.4663998068019908

Epoch: 6| Step: 13
Training loss: 0.05600399523973465
Validation loss: 1.4273844649714809

Epoch: 592| Step: 0
Training loss: 0.05502324178814888
Validation loss: 1.447926103427846

Epoch: 6| Step: 1
Training loss: 0.08096184581518173
Validation loss: 1.4535428157416723

Epoch: 6| Step: 2
Training loss: 0.09150118380784988
Validation loss: 1.454279968815465

Epoch: 6| Step: 3
Training loss: 0.04757920652627945
Validation loss: 1.4368529114671933

Epoch: 6| Step: 4
Training loss: 0.05794760212302208
Validation loss: 1.4514447040455316

Epoch: 6| Step: 5
Training loss: 0.08344618231058121
Validation loss: 1.4779286230764082

Epoch: 6| Step: 6
Training loss: 0.1008119285106659
Validation loss: 1.4613881700782365

Epoch: 6| Step: 7
Training loss: 0.07204630970954895
Validation loss: 1.4603063944847352

Epoch: 6| Step: 8
Training loss: 0.09049877524375916
Validation loss: 1.4873258554807274

Epoch: 6| Step: 9
Training loss: 0.08969014137983322
Validation loss: 1.4825763856211016

Epoch: 6| Step: 10
Training loss: 0.09749126434326172
Validation loss: 1.4889686671636437

Epoch: 6| Step: 11
Training loss: 0.0689086765050888
Validation loss: 1.4657797531415058

Epoch: 6| Step: 12
Training loss: 0.06384433805942535
Validation loss: 1.452116027955086

Epoch: 6| Step: 13
Training loss: 0.11885550618171692
Validation loss: 1.4427956675970426

Epoch: 593| Step: 0
Training loss: 0.04298337548971176
Validation loss: 1.4467326556482623

Epoch: 6| Step: 1
Training loss: 0.04617420211434364
Validation loss: 1.4594505486949798

Epoch: 6| Step: 2
Training loss: 0.09098631143569946
Validation loss: 1.4569746819875573

Epoch: 6| Step: 3
Training loss: 0.07926610112190247
Validation loss: 1.4437916201929892

Epoch: 6| Step: 4
Training loss: 0.04724746569991112
Validation loss: 1.4645770134464386

Epoch: 6| Step: 5
Training loss: 0.04066929966211319
Validation loss: 1.4499997849105506

Epoch: 6| Step: 6
Training loss: 0.12943722307682037
Validation loss: 1.4380811901502712

Epoch: 6| Step: 7
Training loss: 0.0912851020693779
Validation loss: 1.4419925084678076

Epoch: 6| Step: 8
Training loss: 0.09794656932353973
Validation loss: 1.47266556883371

Epoch: 6| Step: 9
Training loss: 0.06158365309238434
Validation loss: 1.431733723609678

Epoch: 6| Step: 10
Training loss: 0.05445272475481033
Validation loss: 1.4748516877492268

Epoch: 6| Step: 11
Training loss: 0.045716650784015656
Validation loss: 1.4791062531932708

Epoch: 6| Step: 12
Training loss: 0.08950234949588776
Validation loss: 1.5012731513669413

Epoch: 6| Step: 13
Training loss: 0.11031867563724518
Validation loss: 1.4854322261707757

Epoch: 594| Step: 0
Training loss: 0.07488586008548737
Validation loss: 1.4918211826714136

Epoch: 6| Step: 1
Training loss: 0.11593616008758545
Validation loss: 1.4796144180400397

Epoch: 6| Step: 2
Training loss: 0.06330613791942596
Validation loss: 1.459692866571488

Epoch: 6| Step: 3
Training loss: 0.06661242991685867
Validation loss: 1.4512100270999375

Epoch: 6| Step: 4
Training loss: 0.057591043412685394
Validation loss: 1.4355606782820918

Epoch: 6| Step: 5
Training loss: 0.062261223793029785
Validation loss: 1.4778602559079406

Epoch: 6| Step: 6
Training loss: 0.09268862754106522
Validation loss: 1.4639891309122885

Epoch: 6| Step: 7
Training loss: 0.0790160521864891
Validation loss: 1.4371543251058108

Epoch: 6| Step: 8
Training loss: 0.07538384944200516
Validation loss: 1.4775149335143387

Epoch: 6| Step: 9
Training loss: 0.04461178928613663
Validation loss: 1.4751279918096398

Epoch: 6| Step: 10
Training loss: 0.08266876637935638
Validation loss: 1.477216201443826

Epoch: 6| Step: 11
Training loss: 0.11698517203330994
Validation loss: 1.4974189445536623

Epoch: 6| Step: 12
Training loss: 0.07655109465122223
Validation loss: 1.4621757332996657

Epoch: 6| Step: 13
Training loss: 0.08377926051616669
Validation loss: 1.4608155053148988

Epoch: 595| Step: 0
Training loss: 0.04842381551861763
Validation loss: 1.466974111013515

Epoch: 6| Step: 1
Training loss: 0.044543445110321045
Validation loss: 1.452765804465099

Epoch: 6| Step: 2
Training loss: 0.05617150291800499
Validation loss: 1.4618014340759606

Epoch: 6| Step: 3
Training loss: 0.0892171561717987
Validation loss: 1.4296726545979899

Epoch: 6| Step: 4
Training loss: 0.06393422186374664
Validation loss: 1.4408854848595076

Epoch: 6| Step: 5
Training loss: 0.07894866168498993
Validation loss: 1.4486138102828816

Epoch: 6| Step: 6
Training loss: 0.05579951032996178
Validation loss: 1.4430172366480674

Epoch: 6| Step: 7
Training loss: 0.05533457547426224
Validation loss: 1.4347399716736169

Epoch: 6| Step: 8
Training loss: 0.06561961770057678
Validation loss: 1.4497354722792102

Epoch: 6| Step: 9
Training loss: 0.08937731385231018
Validation loss: 1.4303295125243485

Epoch: 6| Step: 10
Training loss: 0.07237902283668518
Validation loss: 1.4883381269311393

Epoch: 6| Step: 11
Training loss: 0.05199474096298218
Validation loss: 1.450147130156076

Epoch: 6| Step: 12
Training loss: 0.08884511888027191
Validation loss: 1.431221108282766

Epoch: 6| Step: 13
Training loss: 0.0649547427892685
Validation loss: 1.4437953349082702

Epoch: 596| Step: 0
Training loss: 0.05409723520278931
Validation loss: 1.4576176552362339

Epoch: 6| Step: 1
Training loss: 0.040319375693798065
Validation loss: 1.437504711971488

Epoch: 6| Step: 2
Training loss: 0.07300761342048645
Validation loss: 1.444906129631945

Epoch: 6| Step: 3
Training loss: 0.04274112731218338
Validation loss: 1.4457724607118996

Epoch: 6| Step: 4
Training loss: 0.0501377210021019
Validation loss: 1.4452282997869677

Epoch: 6| Step: 5
Training loss: 0.07766696810722351
Validation loss: 1.4442952038139425

Epoch: 6| Step: 6
Training loss: 0.0713004395365715
Validation loss: 1.4682039406991774

Epoch: 6| Step: 7
Training loss: 0.06455190479755402
Validation loss: 1.4502433397436654

Epoch: 6| Step: 8
Training loss: 0.06788861751556396
Validation loss: 1.4572358169863302

Epoch: 6| Step: 9
Training loss: 0.06764061748981476
Validation loss: 1.4789726631615752

Epoch: 6| Step: 10
Training loss: 0.04284749925136566
Validation loss: 1.4862424763300086

Epoch: 6| Step: 11
Training loss: 0.08956161141395569
Validation loss: 1.4940982044384044

Epoch: 6| Step: 12
Training loss: 0.04957444220781326
Validation loss: 1.4822774471775177

Epoch: 6| Step: 13
Training loss: 0.05508069694042206
Validation loss: 1.485473717412641

Epoch: 597| Step: 0
Training loss: 0.03658812865614891
Validation loss: 1.4560592225802842

Epoch: 6| Step: 1
Training loss: 0.09331296384334564
Validation loss: 1.4579312083541707

Epoch: 6| Step: 2
Training loss: 0.07758589088916779
Validation loss: 1.4490823309908631

Epoch: 6| Step: 3
Training loss: 0.06985063850879669
Validation loss: 1.4611166613076323

Epoch: 6| Step: 4
Training loss: 0.0740869790315628
Validation loss: 1.4813721923417942

Epoch: 6| Step: 5
Training loss: 0.049976885318756104
Validation loss: 1.454259076426106

Epoch: 6| Step: 6
Training loss: 0.06454919278621674
Validation loss: 1.494654420883425

Epoch: 6| Step: 7
Training loss: 0.05961332470178604
Validation loss: 1.4637002483490975

Epoch: 6| Step: 8
Training loss: 0.051341764628887177
Validation loss: 1.4779702194275395

Epoch: 6| Step: 9
Training loss: 0.09143058955669403
Validation loss: 1.4932807594217279

Epoch: 6| Step: 10
Training loss: 0.06115585193037987
Validation loss: 1.4607863169844433

Epoch: 6| Step: 11
Training loss: 0.03563426434993744
Validation loss: 1.4754544124808362

Epoch: 6| Step: 12
Training loss: 0.04707438498735428
Validation loss: 1.444409878023209

Epoch: 6| Step: 13
Training loss: 0.06711557507514954
Validation loss: 1.4552845544712518

Epoch: 598| Step: 0
Training loss: 0.07512903958559036
Validation loss: 1.4400764050022248

Epoch: 6| Step: 1
Training loss: 0.08410720527172089
Validation loss: 1.4536038085978518

Epoch: 6| Step: 2
Training loss: 0.08031514286994934
Validation loss: 1.4643387743221816

Epoch: 6| Step: 3
Training loss: 0.10260901600122452
Validation loss: 1.4552464472350253

Epoch: 6| Step: 4
Training loss: 0.07009726017713547
Validation loss: 1.4714328845342

Epoch: 6| Step: 5
Training loss: 0.04833880811929703
Validation loss: 1.4754523282409997

Epoch: 6| Step: 6
Training loss: 0.08674078434705734
Validation loss: 1.5025193832253898

Epoch: 6| Step: 7
Training loss: 0.07475019991397858
Validation loss: 1.5088734357587752

Epoch: 6| Step: 8
Training loss: 0.08213526010513306
Validation loss: 1.5112025199397918

Epoch: 6| Step: 9
Training loss: 0.05060279369354248
Validation loss: 1.4758613936362728

Epoch: 6| Step: 10
Training loss: 0.07928772270679474
Validation loss: 1.4762089201199111

Epoch: 6| Step: 11
Training loss: 0.08297324180603027
Validation loss: 1.4619062856961322

Epoch: 6| Step: 12
Training loss: 0.03977055847644806
Validation loss: 1.4420899178392144

Epoch: 6| Step: 13
Training loss: 0.04037509858608246
Validation loss: 1.463317330165576

Epoch: 599| Step: 0
Training loss: 0.04577076435089111
Validation loss: 1.4245569141962195

Epoch: 6| Step: 1
Training loss: 0.07494650781154633
Validation loss: 1.436930771796934

Epoch: 6| Step: 2
Training loss: 0.05236800014972687
Validation loss: 1.4471401309454313

Epoch: 6| Step: 3
Training loss: 0.06607311964035034
Validation loss: 1.4579892568690802

Epoch: 6| Step: 4
Training loss: 0.038494449108839035
Validation loss: 1.4241017513377692

Epoch: 6| Step: 5
Training loss: 0.06007573753595352
Validation loss: 1.450184763118785

Epoch: 6| Step: 6
Training loss: 0.06596129387617111
Validation loss: 1.445116005918031

Epoch: 6| Step: 7
Training loss: 0.05162568762898445
Validation loss: 1.4351091615615352

Epoch: 6| Step: 8
Training loss: 0.08634950965642929
Validation loss: 1.43113955631051

Epoch: 6| Step: 9
Training loss: 0.07117443531751633
Validation loss: 1.4518026844147713

Epoch: 6| Step: 10
Training loss: 0.0748906061053276
Validation loss: 1.4503885225583149

Epoch: 6| Step: 11
Training loss: 0.07823237776756287
Validation loss: 1.4335181713104248

Epoch: 6| Step: 12
Training loss: 0.03510526567697525
Validation loss: 1.4434492600861417

Epoch: 6| Step: 13
Training loss: 0.07102635502815247
Validation loss: 1.4267458979801466

Epoch: 600| Step: 0
Training loss: 0.0450916662812233
Validation loss: 1.4467970671192292

Epoch: 6| Step: 1
Training loss: 0.04833780601620674
Validation loss: 1.4397046553191317

Epoch: 6| Step: 2
Training loss: 0.09311813116073608
Validation loss: 1.4358554091504825

Epoch: 6| Step: 3
Training loss: 0.06819304823875427
Validation loss: 1.433945704531926

Epoch: 6| Step: 4
Training loss: 0.050092753022909164
Validation loss: 1.44651702655259

Epoch: 6| Step: 5
Training loss: 0.08174143731594086
Validation loss: 1.4661652465020456

Epoch: 6| Step: 6
Training loss: 0.04877336323261261
Validation loss: 1.4649132990068006

Epoch: 6| Step: 7
Training loss: 0.09214648604393005
Validation loss: 1.4315363412262292

Epoch: 6| Step: 8
Training loss: 0.05801229923963547
Validation loss: 1.452353290332261

Epoch: 6| Step: 9
Training loss: 0.0677369087934494
Validation loss: 1.4612636995571915

Epoch: 6| Step: 10
Training loss: 0.039776548743247986
Validation loss: 1.4621089837884391

Epoch: 6| Step: 11
Training loss: 0.0431695431470871
Validation loss: 1.4359509996188584

Epoch: 6| Step: 12
Training loss: 0.053569890558719635
Validation loss: 1.4388189815705823

Epoch: 6| Step: 13
Training loss: 0.11649221926927567
Validation loss: 1.4320730009386617

Epoch: 601| Step: 0
Training loss: 0.06347323954105377
Validation loss: 1.440798048050173

Epoch: 6| Step: 1
Training loss: 0.05575396865606308
Validation loss: 1.4189192620656823

Epoch: 6| Step: 2
Training loss: 0.06859811395406723
Validation loss: 1.4418541795463973

Epoch: 6| Step: 3
Training loss: 0.07564754784107208
Validation loss: 1.408645599119125

Epoch: 6| Step: 4
Training loss: 0.05039603263139725
Validation loss: 1.426193591087095

Epoch: 6| Step: 5
Training loss: 0.08757312595844269
Validation loss: 1.4173968492015716

Epoch: 6| Step: 6
Training loss: 0.09446662664413452
Validation loss: 1.4150209683243946

Epoch: 6| Step: 7
Training loss: 0.06021764129400253
Validation loss: 1.4184341456300469

Epoch: 6| Step: 8
Training loss: 0.04952432960271835
Validation loss: 1.4322157252219416

Epoch: 6| Step: 9
Training loss: 0.06282297521829605
Validation loss: 1.4288557101321477

Epoch: 6| Step: 10
Training loss: 0.07990746200084686
Validation loss: 1.4137636346201743

Epoch: 6| Step: 11
Training loss: 0.047999411821365356
Validation loss: 1.4204273243104257

Epoch: 6| Step: 12
Training loss: 0.07226307690143585
Validation loss: 1.4435152776779667

Epoch: 6| Step: 13
Training loss: 0.027386903762817383
Validation loss: 1.4441403676104803

Epoch: 602| Step: 0
Training loss: 0.06334862858057022
Validation loss: 1.4534366355147412

Epoch: 6| Step: 1
Training loss: 0.05762618035078049
Validation loss: 1.4568187267549577

Epoch: 6| Step: 2
Training loss: 0.08650332689285278
Validation loss: 1.4740972102329295

Epoch: 6| Step: 3
Training loss: 0.042776644229888916
Validation loss: 1.4774992735155168

Epoch: 6| Step: 4
Training loss: 0.027394335716962814
Validation loss: 1.453677378674989

Epoch: 6| Step: 5
Training loss: 0.06036034971475601
Validation loss: 1.4741023663551576

Epoch: 6| Step: 6
Training loss: 0.050707921385765076
Validation loss: 1.4782454031769947

Epoch: 6| Step: 7
Training loss: 0.053942035883665085
Validation loss: 1.446231783077281

Epoch: 6| Step: 8
Training loss: 0.07109560072422028
Validation loss: 1.4584975088796308

Epoch: 6| Step: 9
Training loss: 0.0885457843542099
Validation loss: 1.4359895337012507

Epoch: 6| Step: 10
Training loss: 0.04679295793175697
Validation loss: 1.4241517718120287

Epoch: 6| Step: 11
Training loss: 0.0739235132932663
Validation loss: 1.399459885012719

Epoch: 6| Step: 12
Training loss: 0.0667070746421814
Validation loss: 1.4037018860540083

Epoch: 6| Step: 13
Training loss: 0.06728263944387436
Validation loss: 1.394990599283608

Epoch: 603| Step: 0
Training loss: 0.10223154723644257
Validation loss: 1.3985908281418584

Epoch: 6| Step: 1
Training loss: 0.060496941208839417
Validation loss: 1.401852983941314

Epoch: 6| Step: 2
Training loss: 0.09144597500562668
Validation loss: 1.4268554359353998

Epoch: 6| Step: 3
Training loss: 0.053474076092243195
Validation loss: 1.424939150451332

Epoch: 6| Step: 4
Training loss: 0.06900233030319214
Validation loss: 1.4490709612446446

Epoch: 6| Step: 5
Training loss: 0.0882793515920639
Validation loss: 1.4880484816848591

Epoch: 6| Step: 6
Training loss: 0.05435298755764961
Validation loss: 1.4884121494908487

Epoch: 6| Step: 7
Training loss: 0.09927839785814285
Validation loss: 1.4942016127288982

Epoch: 6| Step: 8
Training loss: 0.05684448033571243
Validation loss: 1.517732133147537

Epoch: 6| Step: 9
Training loss: 0.07636724412441254
Validation loss: 1.4919211890107842

Epoch: 6| Step: 10
Training loss: 0.04443596303462982
Validation loss: 1.4937522436982842

Epoch: 6| Step: 11
Training loss: 0.04980463534593582
Validation loss: 1.4595149242749779

Epoch: 6| Step: 12
Training loss: 0.0727166086435318
Validation loss: 1.447196997622008

Epoch: 6| Step: 13
Training loss: 0.06390762329101562
Validation loss: 1.4348844879417009

Epoch: 604| Step: 0
Training loss: 0.0595967099070549
Validation loss: 1.4566942209838538

Epoch: 6| Step: 1
Training loss: 0.09471803903579712
Validation loss: 1.4216947978542698

Epoch: 6| Step: 2
Training loss: 0.0834362655878067
Validation loss: 1.4424163282558482

Epoch: 6| Step: 3
Training loss: 0.0515303760766983
Validation loss: 1.416364663390703

Epoch: 6| Step: 4
Training loss: 0.06397086381912231
Validation loss: 1.4455037860460178

Epoch: 6| Step: 5
Training loss: 0.05369258671998978
Validation loss: 1.4803184822041502

Epoch: 6| Step: 6
Training loss: 0.079049251973629
Validation loss: 1.4766845978716368

Epoch: 6| Step: 7
Training loss: 0.08389542251825333
Validation loss: 1.4780045164528715

Epoch: 6| Step: 8
Training loss: 0.08769649267196655
Validation loss: 1.4693389733632405

Epoch: 6| Step: 9
Training loss: 0.0776444748044014
Validation loss: 1.4833037853240967

Epoch: 6| Step: 10
Training loss: 0.10182221233844757
Validation loss: 1.4690969374872023

Epoch: 6| Step: 11
Training loss: 0.08791597187519073
Validation loss: 1.4294722772413684

Epoch: 6| Step: 12
Training loss: 0.10710951685905457
Validation loss: 1.4548478023980254

Epoch: 6| Step: 13
Training loss: 0.05711544305086136
Validation loss: 1.458541827817117

Epoch: 605| Step: 0
Training loss: 0.03230641037225723
Validation loss: 1.4207865948318152

Epoch: 6| Step: 1
Training loss: 0.03676697611808777
Validation loss: 1.4176627403946334

Epoch: 6| Step: 2
Training loss: 0.07368917018175125
Validation loss: 1.3980933440628873

Epoch: 6| Step: 3
Training loss: 0.07153181731700897
Validation loss: 1.3961358672829085

Epoch: 6| Step: 4
Training loss: 0.07445727288722992
Validation loss: 1.4148599351606062

Epoch: 6| Step: 5
Training loss: 0.04863486811518669
Validation loss: 1.415806435769604

Epoch: 6| Step: 6
Training loss: 0.06477285921573639
Validation loss: 1.4265126900006366

Epoch: 6| Step: 7
Training loss: 0.14305934309959412
Validation loss: 1.4590928451989287

Epoch: 6| Step: 8
Training loss: 0.06298139691352844
Validation loss: 1.445426384607951

Epoch: 6| Step: 9
Training loss: 0.06725595146417618
Validation loss: 1.4501738868733889

Epoch: 6| Step: 10
Training loss: 0.049981728196144104
Validation loss: 1.4958881357664704

Epoch: 6| Step: 11
Training loss: 0.058850474655628204
Validation loss: 1.4519525317735569

Epoch: 6| Step: 12
Training loss: 0.06440664827823639
Validation loss: 1.4818294471310032

Epoch: 6| Step: 13
Training loss: 0.10813936591148376
Validation loss: 1.512479261044533

Epoch: 606| Step: 0
Training loss: 0.05038360506296158
Validation loss: 1.5139889127464705

Epoch: 6| Step: 1
Training loss: 0.06021782383322716
Validation loss: 1.4880045562662103

Epoch: 6| Step: 2
Training loss: 0.07698967307806015
Validation loss: 1.472463414233218

Epoch: 6| Step: 3
Training loss: 0.09959518909454346
Validation loss: 1.4698823241777317

Epoch: 6| Step: 4
Training loss: 0.07941018044948578
Validation loss: 1.4750101181768602

Epoch: 6| Step: 5
Training loss: 0.035871900618076324
Validation loss: 1.4861671206771687

Epoch: 6| Step: 6
Training loss: 0.1130049005150795
Validation loss: 1.4884541823017983

Epoch: 6| Step: 7
Training loss: 0.10700810700654984
Validation loss: 1.4553464048652238

Epoch: 6| Step: 8
Training loss: 0.09068794548511505
Validation loss: 1.4290899615133963

Epoch: 6| Step: 9
Training loss: 0.07452932000160217
Validation loss: 1.4293171282737487

Epoch: 6| Step: 10
Training loss: 0.09027419984340668
Validation loss: 1.4436422445440804

Epoch: 6| Step: 11
Training loss: 0.04641415923833847
Validation loss: 1.4441535190869403

Epoch: 6| Step: 12
Training loss: 0.07898323982954025
Validation loss: 1.439917814347052

Epoch: 6| Step: 13
Training loss: 0.06542151421308517
Validation loss: 1.4454726249940935

Epoch: 607| Step: 0
Training loss: 0.07466039061546326
Validation loss: 1.4418460707510672

Epoch: 6| Step: 1
Training loss: 0.034333474934101105
Validation loss: 1.4114058979095951

Epoch: 6| Step: 2
Training loss: 0.050728630274534225
Validation loss: 1.425279644227797

Epoch: 6| Step: 3
Training loss: 0.042097631841897964
Validation loss: 1.4112444295678088

Epoch: 6| Step: 4
Training loss: 0.08208756148815155
Validation loss: 1.4273545306216004

Epoch: 6| Step: 5
Training loss: 0.08610408008098602
Validation loss: 1.4345738567331785

Epoch: 6| Step: 6
Training loss: 0.10871042311191559
Validation loss: 1.426965493027882

Epoch: 6| Step: 7
Training loss: 0.07164833694696426
Validation loss: 1.4622081800173687

Epoch: 6| Step: 8
Training loss: 0.05658118426799774
Validation loss: 1.432167213450196

Epoch: 6| Step: 9
Training loss: 0.05735166370868683
Validation loss: 1.4590921260977303

Epoch: 6| Step: 10
Training loss: 0.12564674019813538
Validation loss: 1.425837439875449

Epoch: 6| Step: 11
Training loss: 0.09992915391921997
Validation loss: 1.4407738024188625

Epoch: 6| Step: 12
Training loss: 0.07470735907554626
Validation loss: 1.467104184371169

Epoch: 6| Step: 13
Training loss: 0.16548001766204834
Validation loss: 1.4458364876367713

Epoch: 608| Step: 0
Training loss: 0.07038787007331848
Validation loss: 1.4213530914757841

Epoch: 6| Step: 1
Training loss: 0.0766439288854599
Validation loss: 1.4120388710370628

Epoch: 6| Step: 2
Training loss: 0.0482894703745842
Validation loss: 1.4701473161738405

Epoch: 6| Step: 3
Training loss: 0.08222570270299911
Validation loss: 1.4545171696652648

Epoch: 6| Step: 4
Training loss: 0.06798694282770157
Validation loss: 1.4852933614484725

Epoch: 6| Step: 5
Training loss: 0.1081274002790451
Validation loss: 1.4822923932024228

Epoch: 6| Step: 6
Training loss: 0.08042066544294357
Validation loss: 1.5350330734765658

Epoch: 6| Step: 7
Training loss: 0.05445171892642975
Validation loss: 1.54000166667405

Epoch: 6| Step: 8
Training loss: 0.07471615076065063
Validation loss: 1.5473192122674757

Epoch: 6| Step: 9
Training loss: 0.09393041580915451
Validation loss: 1.5473435271170832

Epoch: 6| Step: 10
Training loss: 0.06192531809210777
Validation loss: 1.5554896093183948

Epoch: 6| Step: 11
Training loss: 0.07533836364746094
Validation loss: 1.5166869522422872

Epoch: 6| Step: 12
Training loss: 0.12920859456062317
Validation loss: 1.5265658414492043

Epoch: 6| Step: 13
Training loss: 0.08803308010101318
Validation loss: 1.4881771251719484

Epoch: 609| Step: 0
Training loss: 0.10589928925037384
Validation loss: 1.4802190206384147

Epoch: 6| Step: 1
Training loss: 0.04688692092895508
Validation loss: 1.4765009085337322

Epoch: 6| Step: 2
Training loss: 0.08336687088012695
Validation loss: 1.4734222171127156

Epoch: 6| Step: 3
Training loss: 0.10073969513177872
Validation loss: 1.4620820501799225

Epoch: 6| Step: 4
Training loss: 0.09077094495296478
Validation loss: 1.444852166278388

Epoch: 6| Step: 5
Training loss: 0.05831361189484596
Validation loss: 1.4476635391994188

Epoch: 6| Step: 6
Training loss: 0.06794571876525879
Validation loss: 1.417632415730466

Epoch: 6| Step: 7
Training loss: 0.12529604136943817
Validation loss: 1.4411225049726424

Epoch: 6| Step: 8
Training loss: 0.07714439183473587
Validation loss: 1.4472456798758557

Epoch: 6| Step: 9
Training loss: 0.060725729912519455
Validation loss: 1.4244713616627518

Epoch: 6| Step: 10
Training loss: 0.07992221415042877
Validation loss: 1.4199122075111634

Epoch: 6| Step: 11
Training loss: 0.09758803248405457
Validation loss: 1.485319068354945

Epoch: 6| Step: 12
Training loss: 0.07042360305786133
Validation loss: 1.4792187649716613

Epoch: 6| Step: 13
Training loss: 0.06607364863157272
Validation loss: 1.489793449319819

Epoch: 610| Step: 0
Training loss: 0.1043689176440239
Validation loss: 1.5075106748970606

Epoch: 6| Step: 1
Training loss: 0.10939238965511322
Validation loss: 1.5598630648787304

Epoch: 6| Step: 2
Training loss: 0.0720159113407135
Validation loss: 1.576917604733539

Epoch: 6| Step: 3
Training loss: 0.1707567572593689
Validation loss: 1.6076010824531637

Epoch: 6| Step: 4
Training loss: 0.07021856307983398
Validation loss: 1.5632858071275937

Epoch: 6| Step: 5
Training loss: 0.07087390124797821
Validation loss: 1.5365754891467351

Epoch: 6| Step: 6
Training loss: 0.05262627452611923
Validation loss: 1.4558880918769426

Epoch: 6| Step: 7
Training loss: 0.11771626770496368
Validation loss: 1.4792310730103524

Epoch: 6| Step: 8
Training loss: 0.05099661648273468
Validation loss: 1.453236344040081

Epoch: 6| Step: 9
Training loss: 0.0701584592461586
Validation loss: 1.4569058008091424

Epoch: 6| Step: 10
Training loss: 0.09864668548107147
Validation loss: 1.4212708216841503

Epoch: 6| Step: 11
Training loss: 0.1000867635011673
Validation loss: 1.4483806471670828

Epoch: 6| Step: 12
Training loss: 0.07886963337659836
Validation loss: 1.4434617193796302

Epoch: 6| Step: 13
Training loss: 0.0965072512626648
Validation loss: 1.4301917014583465

Epoch: 611| Step: 0
Training loss: 0.10499134659767151
Validation loss: 1.414244544121527

Epoch: 6| Step: 1
Training loss: 0.08020564913749695
Validation loss: 1.4277177369722756

Epoch: 6| Step: 2
Training loss: 0.04870123043656349
Validation loss: 1.4358499383413663

Epoch: 6| Step: 3
Training loss: 0.09358859807252884
Validation loss: 1.4699364964680006

Epoch: 6| Step: 4
Training loss: 0.11529999226331711
Validation loss: 1.4998534866558608

Epoch: 6| Step: 5
Training loss: 0.0716550350189209
Validation loss: 1.4796138527572795

Epoch: 6| Step: 6
Training loss: 0.12320711463689804
Validation loss: 1.4966600223254132

Epoch: 6| Step: 7
Training loss: 0.10455702245235443
Validation loss: 1.4874915031976597

Epoch: 6| Step: 8
Training loss: 0.057174284011125565
Validation loss: 1.5014171779796641

Epoch: 6| Step: 9
Training loss: 0.0987694188952446
Validation loss: 1.4793196570488714

Epoch: 6| Step: 10
Training loss: 0.07443566620349884
Validation loss: 1.4788718851663734

Epoch: 6| Step: 11
Training loss: 0.06325969845056534
Validation loss: 1.4786252078189646

Epoch: 6| Step: 12
Training loss: 0.06941118836402893
Validation loss: 1.4721324495089951

Epoch: 6| Step: 13
Training loss: 0.07923373579978943
Validation loss: 1.5026153518307594

Epoch: 612| Step: 0
Training loss: 0.07943155616521835
Validation loss: 1.4495198777926865

Epoch: 6| Step: 1
Training loss: 0.053272344172000885
Validation loss: 1.446223533281716

Epoch: 6| Step: 2
Training loss: 0.09883078932762146
Validation loss: 1.4614240802744383

Epoch: 6| Step: 3
Training loss: 0.09986557811498642
Validation loss: 1.4778488502707532

Epoch: 6| Step: 4
Training loss: 0.14542295038700104
Validation loss: 1.469109058380127

Epoch: 6| Step: 5
Training loss: 0.12135055661201477
Validation loss: 1.4833118287465905

Epoch: 6| Step: 6
Training loss: 0.08595621585845947
Validation loss: 1.5038320543945476

Epoch: 6| Step: 7
Training loss: 0.1530463695526123
Validation loss: 1.516695144355938

Epoch: 6| Step: 8
Training loss: 0.15226700901985168
Validation loss: 1.4887348451922018

Epoch: 6| Step: 9
Training loss: 0.0821705237030983
Validation loss: 1.4911830630353702

Epoch: 6| Step: 10
Training loss: 0.039082519710063934
Validation loss: 1.4851711873085267

Epoch: 6| Step: 11
Training loss: 0.10254412889480591
Validation loss: 1.4587297683121057

Epoch: 6| Step: 12
Training loss: 0.07603016495704651
Validation loss: 1.449618854830342

Epoch: 6| Step: 13
Training loss: 0.05152313411235809
Validation loss: 1.4813768581677509

Epoch: 613| Step: 0
Training loss: 0.09906406700611115
Validation loss: 1.483364451316095

Epoch: 6| Step: 1
Training loss: 0.08900056779384613
Validation loss: 1.4717761028197505

Epoch: 6| Step: 2
Training loss: 0.07835115492343903
Validation loss: 1.4980403857846414

Epoch: 6| Step: 3
Training loss: 0.06753866374492645
Validation loss: 1.498760639980275

Epoch: 6| Step: 4
Training loss: 0.10653026401996613
Validation loss: 1.4910920448200677

Epoch: 6| Step: 5
Training loss: 0.07684417068958282
Validation loss: 1.5008777982445174

Epoch: 6| Step: 6
Training loss: 0.13386449217796326
Validation loss: 1.470969698762381

Epoch: 6| Step: 7
Training loss: 0.12039358168840408
Validation loss: 1.5112604627045252

Epoch: 6| Step: 8
Training loss: 0.07853837311267853
Validation loss: 1.4520705720429778

Epoch: 6| Step: 9
Training loss: 0.1085909754037857
Validation loss: 1.4534113496862433

Epoch: 6| Step: 10
Training loss: 0.06725071370601654
Validation loss: 1.4453092262309084

Epoch: 6| Step: 11
Training loss: 0.05197816342115402
Validation loss: 1.4391183096875426

Epoch: 6| Step: 12
Training loss: 0.04749997705221176
Validation loss: 1.4626036959309732

Epoch: 6| Step: 13
Training loss: 0.043272510170936584
Validation loss: 1.4415264257820704

Epoch: 614| Step: 0
Training loss: 0.05004967004060745
Validation loss: 1.4694733940145022

Epoch: 6| Step: 1
Training loss: 0.06306752562522888
Validation loss: 1.4665114315607215

Epoch: 6| Step: 2
Training loss: 0.07892389595508575
Validation loss: 1.4517268596156951

Epoch: 6| Step: 3
Training loss: 0.13429071009159088
Validation loss: 1.4499082590944024

Epoch: 6| Step: 4
Training loss: 0.11209600418806076
Validation loss: 1.4470045419149502

Epoch: 6| Step: 5
Training loss: 0.07949177920818329
Validation loss: 1.4423769263811008

Epoch: 6| Step: 6
Training loss: 0.09821811318397522
Validation loss: 1.4477504222623763

Epoch: 6| Step: 7
Training loss: 0.09306672215461731
Validation loss: 1.4624578247788131

Epoch: 6| Step: 8
Training loss: 0.10181328654289246
Validation loss: 1.4653587815582112

Epoch: 6| Step: 9
Training loss: 0.07500401139259338
Validation loss: 1.4656558703350764

Epoch: 6| Step: 10
Training loss: 0.06180240213871002
Validation loss: 1.4724770810014458

Epoch: 6| Step: 11
Training loss: 0.13306021690368652
Validation loss: 1.4533792067599554

Epoch: 6| Step: 12
Training loss: 0.0375688299536705
Validation loss: 1.4706852718066143

Epoch: 6| Step: 13
Training loss: 0.04672282189130783
Validation loss: 1.4654887837748374

Epoch: 615| Step: 0
Training loss: 0.05940307676792145
Validation loss: 1.4698059597323019

Epoch: 6| Step: 1
Training loss: 0.0307236909866333
Validation loss: 1.4811793745204966

Epoch: 6| Step: 2
Training loss: 0.0976421982049942
Validation loss: 1.4542372316442511

Epoch: 6| Step: 3
Training loss: 0.07946913689374924
Validation loss: 1.4886169882230862

Epoch: 6| Step: 4
Training loss: 0.06542335450649261
Validation loss: 1.4840568752699002

Epoch: 6| Step: 5
Training loss: 0.04391973093152046
Validation loss: 1.445340903856421

Epoch: 6| Step: 6
Training loss: 0.06921519339084625
Validation loss: 1.4456258884040258

Epoch: 6| Step: 7
Training loss: 0.0636204183101654
Validation loss: 1.4354052460321816

Epoch: 6| Step: 8
Training loss: 0.055434130132198334
Validation loss: 1.4064170314419655

Epoch: 6| Step: 9
Training loss: 0.07261791825294495
Validation loss: 1.4100760324026949

Epoch: 6| Step: 10
Training loss: 0.06358867883682251
Validation loss: 1.399256811347059

Epoch: 6| Step: 11
Training loss: 0.08416928350925446
Validation loss: 1.4059303281127766

Epoch: 6| Step: 12
Training loss: 0.08296503871679306
Validation loss: 1.391070596633419

Epoch: 6| Step: 13
Training loss: 0.11848919838666916
Validation loss: 1.3711003590655584

Epoch: 616| Step: 0
Training loss: 0.09145727753639221
Validation loss: 1.4178936853203723

Epoch: 6| Step: 1
Training loss: 0.07685829699039459
Validation loss: 1.3960910932992094

Epoch: 6| Step: 2
Training loss: 0.058391738682985306
Validation loss: 1.4493185256117134

Epoch: 6| Step: 3
Training loss: 0.08756302297115326
Validation loss: 1.4343886195972402

Epoch: 6| Step: 4
Training loss: 0.09351139515638351
Validation loss: 1.4931518172705045

Epoch: 6| Step: 5
Training loss: 0.1184701919555664
Validation loss: 1.4632000692429081

Epoch: 6| Step: 6
Training loss: 0.08422935009002686
Validation loss: 1.4710450403151973

Epoch: 6| Step: 7
Training loss: 0.05923141539096832
Validation loss: 1.4649330903125066

Epoch: 6| Step: 8
Training loss: 0.07216113805770874
Validation loss: 1.4629605611165364

Epoch: 6| Step: 9
Training loss: 0.07510840147733688
Validation loss: 1.4540500820323985

Epoch: 6| Step: 10
Training loss: 0.08812213689088821
Validation loss: 1.4524255862800024

Epoch: 6| Step: 11
Training loss: 0.0671844631433487
Validation loss: 1.4674267486859394

Epoch: 6| Step: 12
Training loss: 0.04641692340373993
Validation loss: 1.435653075095146

Epoch: 6| Step: 13
Training loss: 0.11985751986503601
Validation loss: 1.4289392104712866

Epoch: 617| Step: 0
Training loss: 0.06562571972608566
Validation loss: 1.4061662150967507

Epoch: 6| Step: 1
Training loss: 0.05443749949336052
Validation loss: 1.3993480282445108

Epoch: 6| Step: 2
Training loss: 0.05300475284457207
Validation loss: 1.410537806890344

Epoch: 6| Step: 3
Training loss: 0.10026487708091736
Validation loss: 1.440234706606916

Epoch: 6| Step: 4
Training loss: 0.054433681070804596
Validation loss: 1.4422335547785605

Epoch: 6| Step: 5
Training loss: 0.045200467109680176
Validation loss: 1.4313654027959353

Epoch: 6| Step: 6
Training loss: 0.08274364471435547
Validation loss: 1.4570273173752653

Epoch: 6| Step: 7
Training loss: 0.09357442706823349
Validation loss: 1.4502549889267131

Epoch: 6| Step: 8
Training loss: 0.05891446769237518
Validation loss: 1.4705603366257043

Epoch: 6| Step: 9
Training loss: 0.10537263751029968
Validation loss: 1.4621042522691912

Epoch: 6| Step: 10
Training loss: 0.09165820479393005
Validation loss: 1.4937222785847162

Epoch: 6| Step: 11
Training loss: 0.07163126021623611
Validation loss: 1.497745067842545

Epoch: 6| Step: 12
Training loss: 0.10005338490009308
Validation loss: 1.4734265035198582

Epoch: 6| Step: 13
Training loss: 0.11192478239536285
Validation loss: 1.4623553701626357

Epoch: 618| Step: 0
Training loss: 0.07615256309509277
Validation loss: 1.4819784177246915

Epoch: 6| Step: 1
Training loss: 0.059409916400909424
Validation loss: 1.4694183667500813

Epoch: 6| Step: 2
Training loss: 0.05459948629140854
Validation loss: 1.4837580047627932

Epoch: 6| Step: 3
Training loss: 0.06707847863435745
Validation loss: 1.4936759702620968

Epoch: 6| Step: 4
Training loss: 0.06826485693454742
Validation loss: 1.490371440046577

Epoch: 6| Step: 5
Training loss: 0.14469978213310242
Validation loss: 1.5045748808050667

Epoch: 6| Step: 6
Training loss: 0.07521773874759674
Validation loss: 1.4673040066995928

Epoch: 6| Step: 7
Training loss: 0.07069767266511917
Validation loss: 1.4444279093896188

Epoch: 6| Step: 8
Training loss: 0.07448515295982361
Validation loss: 1.4427551748932048

Epoch: 6| Step: 9
Training loss: 0.061556048691272736
Validation loss: 1.4184303873328752

Epoch: 6| Step: 10
Training loss: 0.12046825885772705
Validation loss: 1.4016954245105866

Epoch: 6| Step: 11
Training loss: 0.10261484235525131
Validation loss: 1.4257508067674534

Epoch: 6| Step: 12
Training loss: 0.10358712822198868
Validation loss: 1.4332759585431827

Epoch: 6| Step: 13
Training loss: 0.10267043113708496
Validation loss: 1.4441447578450686

Epoch: 619| Step: 0
Training loss: 0.06009451672434807
Validation loss: 1.4637033061314655

Epoch: 6| Step: 1
Training loss: 0.07240837812423706
Validation loss: 1.4739898276585404

Epoch: 6| Step: 2
Training loss: 0.06438795477151871
Validation loss: 1.5071593023115588

Epoch: 6| Step: 3
Training loss: 0.0800534039735794
Validation loss: 1.509139883902765

Epoch: 6| Step: 4
Training loss: 0.10160166025161743
Validation loss: 1.52740994832849

Epoch: 6| Step: 5
Training loss: 0.10852302610874176
Validation loss: 1.5194606204186716

Epoch: 6| Step: 6
Training loss: 0.08617992699146271
Validation loss: 1.516970392196409

Epoch: 6| Step: 7
Training loss: 0.08756938576698303
Validation loss: 1.5135873799682946

Epoch: 6| Step: 8
Training loss: 0.05893467739224434
Validation loss: 1.4610450101155106

Epoch: 6| Step: 9
Training loss: 0.09541617333889008
Validation loss: 1.4630163331185617

Epoch: 6| Step: 10
Training loss: 0.07275771349668503
Validation loss: 1.4610238985348774

Epoch: 6| Step: 11
Training loss: 0.06902186572551727
Validation loss: 1.4493246052854805

Epoch: 6| Step: 12
Training loss: 0.0852002277970314
Validation loss: 1.4131154321855115

Epoch: 6| Step: 13
Training loss: 0.09407404065132141
Validation loss: 1.4055868957632331

Epoch: 620| Step: 0
Training loss: 0.06032377481460571
Validation loss: 1.4364484099931614

Epoch: 6| Step: 1
Training loss: 0.07788842916488647
Validation loss: 1.422506666952564

Epoch: 6| Step: 2
Training loss: 0.12617284059524536
Validation loss: 1.4565903884108349

Epoch: 6| Step: 3
Training loss: 0.10925783216953278
Validation loss: 1.4576046723191456

Epoch: 6| Step: 4
Training loss: 0.13262265920639038
Validation loss: 1.5060101606512581

Epoch: 6| Step: 5
Training loss: 0.09282674640417099
Validation loss: 1.4889161061215144

Epoch: 6| Step: 6
Training loss: 0.11334767937660217
Validation loss: 1.4954395268553047

Epoch: 6| Step: 7
Training loss: 0.08498947322368622
Validation loss: 1.4775481006150604

Epoch: 6| Step: 8
Training loss: 0.14394724369049072
Validation loss: 1.515372057114878

Epoch: 6| Step: 9
Training loss: 0.08224433660507202
Validation loss: 1.492697331213182

Epoch: 6| Step: 10
Training loss: 0.10702790319919586
Validation loss: 1.4878838728832942

Epoch: 6| Step: 11
Training loss: 0.10887767374515533
Validation loss: 1.4842839638392131

Epoch: 6| Step: 12
Training loss: 0.09670460224151611
Validation loss: 1.462699544045233

Epoch: 6| Step: 13
Training loss: 0.08228042721748352
Validation loss: 1.4700106017051204

Epoch: 621| Step: 0
Training loss: 0.12653452157974243
Validation loss: 1.4663766673816148

Epoch: 6| Step: 1
Training loss: 0.058316152542829514
Validation loss: 1.455765256317713

Epoch: 6| Step: 2
Training loss: 0.06458161771297455
Validation loss: 1.45739278101152

Epoch: 6| Step: 3
Training loss: 0.0634436383843422
Validation loss: 1.4429992078452982

Epoch: 6| Step: 4
Training loss: 0.05930778756737709
Validation loss: 1.4509378466554868

Epoch: 6| Step: 5
Training loss: 0.05117778480052948
Validation loss: 1.442386733588352

Epoch: 6| Step: 6
Training loss: 0.08802258223295212
Validation loss: 1.4455124658922995

Epoch: 6| Step: 7
Training loss: 0.10746148973703384
Validation loss: 1.4588691290988718

Epoch: 6| Step: 8
Training loss: 0.06819634884595871
Validation loss: 1.440569478978393

Epoch: 6| Step: 9
Training loss: 0.06907318532466888
Validation loss: 1.4419561022071428

Epoch: 6| Step: 10
Training loss: 0.07679963111877441
Validation loss: 1.430125149347449

Epoch: 6| Step: 11
Training loss: 0.06716573238372803
Validation loss: 1.47894448490553

Epoch: 6| Step: 12
Training loss: 0.05488931015133858
Validation loss: 1.4642645928167528

Epoch: 6| Step: 13
Training loss: 0.08396680653095245
Validation loss: 1.4581220342266945

Epoch: 622| Step: 0
Training loss: 0.05689232051372528
Validation loss: 1.4996775760445544

Epoch: 6| Step: 1
Training loss: 0.0975736603140831
Validation loss: 1.50252781632126

Epoch: 6| Step: 2
Training loss: 0.0675063207745552
Validation loss: 1.5058970976901311

Epoch: 6| Step: 3
Training loss: 0.07535193115472794
Validation loss: 1.5067280351474721

Epoch: 6| Step: 4
Training loss: 0.07811720669269562
Validation loss: 1.5383568784242034

Epoch: 6| Step: 5
Training loss: 0.07299010455608368
Validation loss: 1.5476091273369328

Epoch: 6| Step: 6
Training loss: 0.11628082394599915
Validation loss: 1.5408588711933424

Epoch: 6| Step: 7
Training loss: 0.11998666077852249
Validation loss: 1.4989522669904976

Epoch: 6| Step: 8
Training loss: 0.06146486848592758
Validation loss: 1.5175850948979777

Epoch: 6| Step: 9
Training loss: 0.06149446964263916
Validation loss: 1.4628386484679354

Epoch: 6| Step: 10
Training loss: 0.04550246149301529
Validation loss: 1.449269736325869

Epoch: 6| Step: 11
Training loss: 0.09888026118278503
Validation loss: 1.443964860772574

Epoch: 6| Step: 12
Training loss: 0.047637730836868286
Validation loss: 1.4308590863340644

Epoch: 6| Step: 13
Training loss: 0.12343713641166687
Validation loss: 1.4237367171113209

Epoch: 623| Step: 0
Training loss: 0.06401428580284119
Validation loss: 1.4276316447924542

Epoch: 6| Step: 1
Training loss: 0.07742185890674591
Validation loss: 1.4245036801984232

Epoch: 6| Step: 2
Training loss: 0.06513132154941559
Validation loss: 1.423783972699155

Epoch: 6| Step: 3
Training loss: 0.07575373351573944
Validation loss: 1.451745266555458

Epoch: 6| Step: 4
Training loss: 0.13587507605552673
Validation loss: 1.4564305210626254

Epoch: 6| Step: 5
Training loss: 0.07591815292835236
Validation loss: 1.472361768445661

Epoch: 6| Step: 6
Training loss: 0.05327415466308594
Validation loss: 1.49738791296559

Epoch: 6| Step: 7
Training loss: 0.08537262678146362
Validation loss: 1.4925943959143855

Epoch: 6| Step: 8
Training loss: 0.058546245098114014
Validation loss: 1.5419858963258806

Epoch: 6| Step: 9
Training loss: 0.06965633481740952
Validation loss: 1.5027943324017268

Epoch: 6| Step: 10
Training loss: 0.0841156467795372
Validation loss: 1.5120750922028736

Epoch: 6| Step: 11
Training loss: 0.05836921185255051
Validation loss: 1.5190622857821885

Epoch: 6| Step: 12
Training loss: 0.04408020153641701
Validation loss: 1.5150660571231638

Epoch: 6| Step: 13
Training loss: 0.04644621163606644
Validation loss: 1.4710310389918666

Epoch: 624| Step: 0
Training loss: 0.062053434550762177
Validation loss: 1.4650331850974792

Epoch: 6| Step: 1
Training loss: 0.06214180588722229
Validation loss: 1.4641498820756071

Epoch: 6| Step: 2
Training loss: 0.0495576411485672
Validation loss: 1.462969644095308

Epoch: 6| Step: 3
Training loss: 0.05749645456671715
Validation loss: 1.429828856581001

Epoch: 6| Step: 4
Training loss: 0.057278361171483994
Validation loss: 1.4434469822914369

Epoch: 6| Step: 5
Training loss: 0.07859795540571213
Validation loss: 1.4182657464858024

Epoch: 6| Step: 6
Training loss: 0.11028289794921875
Validation loss: 1.439541487283604

Epoch: 6| Step: 7
Training loss: 0.11042545735836029
Validation loss: 1.4125502596619308

Epoch: 6| Step: 8
Training loss: 0.08717016130685806
Validation loss: 1.4068572931392218

Epoch: 6| Step: 9
Training loss: 0.07847422361373901
Validation loss: 1.4361618026610343

Epoch: 6| Step: 10
Training loss: 0.1128637045621872
Validation loss: 1.4556037879759265

Epoch: 6| Step: 11
Training loss: 0.06895725429058075
Validation loss: 1.4310868414499427

Epoch: 6| Step: 12
Training loss: 0.08463728427886963
Validation loss: 1.4707611491603236

Epoch: 6| Step: 13
Training loss: 0.034106478095054626
Validation loss: 1.4837880493492208

Epoch: 625| Step: 0
Training loss: 0.05861087888479233
Validation loss: 1.486374685841222

Epoch: 6| Step: 1
Training loss: 0.08672350645065308
Validation loss: 1.5141522115276707

Epoch: 6| Step: 2
Training loss: 0.10882436484098434
Validation loss: 1.5659485965646722

Epoch: 6| Step: 3
Training loss: 0.041659072041511536
Validation loss: 1.5523745911095732

Epoch: 6| Step: 4
Training loss: 0.0492093525826931
Validation loss: 1.5253044892382879

Epoch: 6| Step: 5
Training loss: 0.1054568737745285
Validation loss: 1.5115167960043876

Epoch: 6| Step: 6
Training loss: 0.08469986915588379
Validation loss: 1.4922079411886071

Epoch: 6| Step: 7
Training loss: 0.08069978654384613
Validation loss: 1.4679349135327082

Epoch: 6| Step: 8
Training loss: 0.07486829906702042
Validation loss: 1.4607982045860701

Epoch: 6| Step: 9
Training loss: 0.08818447589874268
Validation loss: 1.4424052161555136

Epoch: 6| Step: 10
Training loss: 0.06890448182821274
Validation loss: 1.4484777264697577

Epoch: 6| Step: 11
Training loss: 0.09342803806066513
Validation loss: 1.441665178986006

Epoch: 6| Step: 12
Training loss: 0.0880609080195427
Validation loss: 1.414248461364418

Epoch: 6| Step: 13
Training loss: 0.06760039925575256
Validation loss: 1.4294574593984952

Epoch: 626| Step: 0
Training loss: 0.08419053256511688
Validation loss: 1.464148941219494

Epoch: 6| Step: 1
Training loss: 0.10450007766485214
Validation loss: 1.459266399824491

Epoch: 6| Step: 2
Training loss: 0.058193646371364594
Validation loss: 1.5027580806004104

Epoch: 6| Step: 3
Training loss: 0.1353049874305725
Validation loss: 1.4841623190910584

Epoch: 6| Step: 4
Training loss: 0.08275732398033142
Validation loss: 1.4900461845500494

Epoch: 6| Step: 5
Training loss: 0.07849441468715668
Validation loss: 1.4865819356774772

Epoch: 6| Step: 6
Training loss: 0.06809650361537933
Validation loss: 1.4912817208997664

Epoch: 6| Step: 7
Training loss: 0.11380009353160858
Validation loss: 1.469312810128735

Epoch: 6| Step: 8
Training loss: 0.09867335110902786
Validation loss: 1.4754353678354653

Epoch: 6| Step: 9
Training loss: 0.10198348015546799
Validation loss: 1.47953281094951

Epoch: 6| Step: 10
Training loss: 0.10494796931743622
Validation loss: 1.4909460236949306

Epoch: 6| Step: 11
Training loss: 0.05410773307085037
Validation loss: 1.4750631631061595

Epoch: 6| Step: 12
Training loss: 0.07255975902080536
Validation loss: 1.4820466823475336

Epoch: 6| Step: 13
Training loss: 0.09014410525560379
Validation loss: 1.5258531314070507

Epoch: 627| Step: 0
Training loss: 0.11888168752193451
Validation loss: 1.5425518212779876

Epoch: 6| Step: 1
Training loss: 0.07681961357593536
Validation loss: 1.5173028553685834

Epoch: 6| Step: 2
Training loss: 0.09728412330150604
Validation loss: 1.4799551092168337

Epoch: 6| Step: 3
Training loss: 0.058246925473213196
Validation loss: 1.4801904796272196

Epoch: 6| Step: 4
Training loss: 0.06924903392791748
Validation loss: 1.4864660591207526

Epoch: 6| Step: 5
Training loss: 0.06994839012622833
Validation loss: 1.4540317712291595

Epoch: 6| Step: 6
Training loss: 0.07455598562955856
Validation loss: 1.418998909252946

Epoch: 6| Step: 7
Training loss: 0.05150063708424568
Validation loss: 1.435241449263788

Epoch: 6| Step: 8
Training loss: 0.09098438918590546
Validation loss: 1.4507635722878158

Epoch: 6| Step: 9
Training loss: 0.050180546939373016
Validation loss: 1.4509505802585232

Epoch: 6| Step: 10
Training loss: 0.07807383686304092
Validation loss: 1.4084235391309183

Epoch: 6| Step: 11
Training loss: 0.12028959393501282
Validation loss: 1.4126173924374323

Epoch: 6| Step: 12
Training loss: 0.13618908822536469
Validation loss: 1.4091767726405975

Epoch: 6| Step: 13
Training loss: 0.053820908069610596
Validation loss: 1.4387638773969424

Epoch: 628| Step: 0
Training loss: 0.04705849289894104
Validation loss: 1.472289159733762

Epoch: 6| Step: 1
Training loss: 0.10170713067054749
Validation loss: 1.4497889754592732

Epoch: 6| Step: 2
Training loss: 0.05962325260043144
Validation loss: 1.4630771965108893

Epoch: 6| Step: 3
Training loss: 0.09367789328098297
Validation loss: 1.4735735872740388

Epoch: 6| Step: 4
Training loss: 0.06610433757305145
Validation loss: 1.4607486141625272

Epoch: 6| Step: 5
Training loss: 0.12144874036312103
Validation loss: 1.4529502455906202

Epoch: 6| Step: 6
Training loss: 0.06992292404174805
Validation loss: 1.4526412217847762

Epoch: 6| Step: 7
Training loss: 0.05804126709699631
Validation loss: 1.4277194187205324

Epoch: 6| Step: 8
Training loss: 0.07999679446220398
Validation loss: 1.4079802702831965

Epoch: 6| Step: 9
Training loss: 0.06992191821336746
Validation loss: 1.3957158852648992

Epoch: 6| Step: 10
Training loss: 0.045823559165000916
Validation loss: 1.406700712378307

Epoch: 6| Step: 11
Training loss: 0.07390660792589188
Validation loss: 1.4456991213624195

Epoch: 6| Step: 12
Training loss: 0.04547792300581932
Validation loss: 1.4223981095898537

Epoch: 6| Step: 13
Training loss: 0.07783610373735428
Validation loss: 1.4026446047649588

Epoch: 629| Step: 0
Training loss: 0.0673879012465477
Validation loss: 1.4689823248053109

Epoch: 6| Step: 1
Training loss: 0.05698109045624733
Validation loss: 1.4410458431448987

Epoch: 6| Step: 2
Training loss: 0.05955879017710686
Validation loss: 1.466726472300868

Epoch: 6| Step: 3
Training loss: 0.04686446860432625
Validation loss: 1.4778748814777662

Epoch: 6| Step: 4
Training loss: 0.09808768332004547
Validation loss: 1.4962582293377127

Epoch: 6| Step: 5
Training loss: 0.14216914772987366
Validation loss: 1.499847953037549

Epoch: 6| Step: 6
Training loss: 0.11766703426837921
Validation loss: 1.5003267949627292

Epoch: 6| Step: 7
Training loss: 0.0613374188542366
Validation loss: 1.4495681819095407

Epoch: 6| Step: 8
Training loss: 0.07429597526788712
Validation loss: 1.4236023618328957

Epoch: 6| Step: 9
Training loss: 0.08447644859552383
Validation loss: 1.4472770626826952

Epoch: 6| Step: 10
Training loss: 0.0593697652220726
Validation loss: 1.3899501895391813

Epoch: 6| Step: 11
Training loss: 0.06713268160820007
Validation loss: 1.3774105412985689

Epoch: 6| Step: 12
Training loss: 0.07123635709285736
Validation loss: 1.3618702619306502

Epoch: 6| Step: 13
Training loss: 0.12726345658302307
Validation loss: 1.3737870134333128

Epoch: 630| Step: 0
Training loss: 0.0779663547873497
Validation loss: 1.3989090791312597

Epoch: 6| Step: 1
Training loss: 0.10496371239423752
Validation loss: 1.4097362884911158

Epoch: 6| Step: 2
Training loss: 0.05154692381620407
Validation loss: 1.3968837485518506

Epoch: 6| Step: 3
Training loss: 0.07718918472528458
Validation loss: 1.40524766009341

Epoch: 6| Step: 4
Training loss: 0.0575297474861145
Validation loss: 1.426205813243825

Epoch: 6| Step: 5
Training loss: 0.08123070001602173
Validation loss: 1.4562160981598722

Epoch: 6| Step: 6
Training loss: 0.07369820773601532
Validation loss: 1.4555892059879918

Epoch: 6| Step: 7
Training loss: 0.09017135202884674
Validation loss: 1.4828794944670893

Epoch: 6| Step: 8
Training loss: 0.1484844833612442
Validation loss: 1.5103187432853125

Epoch: 6| Step: 9
Training loss: 0.07983659207820892
Validation loss: 1.5060704984972555

Epoch: 6| Step: 10
Training loss: 0.07556940615177155
Validation loss: 1.5039763360895135

Epoch: 6| Step: 11
Training loss: 0.0863480344414711
Validation loss: 1.498144954763433

Epoch: 6| Step: 12
Training loss: 0.06047160178422928
Validation loss: 1.4673472130170433

Epoch: 6| Step: 13
Training loss: 0.06880271434783936
Validation loss: 1.449794114276927

Epoch: 631| Step: 0
Training loss: 0.06676216423511505
Validation loss: 1.4487686759682112

Epoch: 6| Step: 1
Training loss: 0.07399249076843262
Validation loss: 1.4134331973650123

Epoch: 6| Step: 2
Training loss: 0.0740601122379303
Validation loss: 1.4140964092746857

Epoch: 6| Step: 3
Training loss: 0.08048100769519806
Validation loss: 1.4045010676947973

Epoch: 6| Step: 4
Training loss: 0.08450789749622345
Validation loss: 1.4005256737432172

Epoch: 6| Step: 5
Training loss: 0.05200641229748726
Validation loss: 1.4261127056614045

Epoch: 6| Step: 6
Training loss: 0.06480973213911057
Validation loss: 1.4145887039041007

Epoch: 6| Step: 7
Training loss: 0.07924334704875946
Validation loss: 1.437707939455586

Epoch: 6| Step: 8
Training loss: 0.06600404530763626
Validation loss: 1.4510419073925223

Epoch: 6| Step: 9
Training loss: 0.055960193276405334
Validation loss: 1.4700667717123543

Epoch: 6| Step: 10
Training loss: 0.051835447549819946
Validation loss: 1.4555210016107047

Epoch: 6| Step: 11
Training loss: 0.07337893545627594
Validation loss: 1.4706381418371712

Epoch: 6| Step: 12
Training loss: 0.051042281091213226
Validation loss: 1.4513721914701565

Epoch: 6| Step: 13
Training loss: 0.06334900110960007
Validation loss: 1.4615375111179967

Epoch: 632| Step: 0
Training loss: 0.0611531063914299
Validation loss: 1.442284148226502

Epoch: 6| Step: 1
Training loss: 0.07117389142513275
Validation loss: 1.4371992080442366

Epoch: 6| Step: 2
Training loss: 0.06921180337667465
Validation loss: 1.4598854613560501

Epoch: 6| Step: 3
Training loss: 0.0627509132027626
Validation loss: 1.4297089717721427

Epoch: 6| Step: 4
Training loss: 0.12885519862174988
Validation loss: 1.4489956581464378

Epoch: 6| Step: 5
Training loss: 0.08418810367584229
Validation loss: 1.4525825156960437

Epoch: 6| Step: 6
Training loss: 0.08465898782014847
Validation loss: 1.4460869489177581

Epoch: 6| Step: 7
Training loss: 0.04423242807388306
Validation loss: 1.4307220469238937

Epoch: 6| Step: 8
Training loss: 0.07800662517547607
Validation loss: 1.4416238684808054

Epoch: 6| Step: 9
Training loss: 0.06559598445892334
Validation loss: 1.4325770793422576

Epoch: 6| Step: 10
Training loss: 0.04281139373779297
Validation loss: 1.4060804151719617

Epoch: 6| Step: 11
Training loss: 0.10287703573703766
Validation loss: 1.4237286365160378

Epoch: 6| Step: 12
Training loss: 0.06298324465751648
Validation loss: 1.4023854476149364

Epoch: 6| Step: 13
Training loss: 0.08631840348243713
Validation loss: 1.4070447132151613

Epoch: 633| Step: 0
Training loss: 0.05814389884471893
Validation loss: 1.3956094121420255

Epoch: 6| Step: 1
Training loss: 0.06811587512493134
Validation loss: 1.417222544070213

Epoch: 6| Step: 2
Training loss: 0.11793410032987595
Validation loss: 1.3965837365837508

Epoch: 6| Step: 3
Training loss: 0.08589024841785431
Validation loss: 1.4192356383928688

Epoch: 6| Step: 4
Training loss: 0.11903630197048187
Validation loss: 1.4217071494748514

Epoch: 6| Step: 5
Training loss: 0.0779714435338974
Validation loss: 1.4365515580741308

Epoch: 6| Step: 6
Training loss: 0.08116523921489716
Validation loss: 1.487670902282961

Epoch: 6| Step: 7
Training loss: 0.06637843698263168
Validation loss: 1.490258087394058

Epoch: 6| Step: 8
Training loss: 0.1164063811302185
Validation loss: 1.5169393080537037

Epoch: 6| Step: 9
Training loss: 0.10330981761217117
Validation loss: 1.499851836953112

Epoch: 6| Step: 10
Training loss: 0.09722766280174255
Validation loss: 1.515448679847102

Epoch: 6| Step: 11
Training loss: 0.10534150898456573
Validation loss: 1.4934935146762478

Epoch: 6| Step: 12
Training loss: 0.12516838312149048
Validation loss: 1.4979672944673927

Epoch: 6| Step: 13
Training loss: 0.05244433879852295
Validation loss: 1.4935377220953665

Epoch: 634| Step: 0
Training loss: 0.07864060252904892
Validation loss: 1.4820516917013353

Epoch: 6| Step: 1
Training loss: 0.10989628732204437
Validation loss: 1.4808296772741503

Epoch: 6| Step: 2
Training loss: 0.06922367215156555
Validation loss: 1.4610440115774832

Epoch: 6| Step: 3
Training loss: 0.04744663089513779
Validation loss: 1.4895643726471932

Epoch: 6| Step: 4
Training loss: 0.04447246715426445
Validation loss: 1.4620167145165064

Epoch: 6| Step: 5
Training loss: 0.04790063202381134
Validation loss: 1.4684737984852125

Epoch: 6| Step: 6
Training loss: 0.07942494750022888
Validation loss: 1.4588411969523276

Epoch: 6| Step: 7
Training loss: 0.09744232892990112
Validation loss: 1.4655049577836068

Epoch: 6| Step: 8
Training loss: 0.06909968703985214
Validation loss: 1.4311923301348122

Epoch: 6| Step: 9
Training loss: 0.10089604556560516
Validation loss: 1.4492604642786004

Epoch: 6| Step: 10
Training loss: 0.052432261407375336
Validation loss: 1.4460283774201588

Epoch: 6| Step: 11
Training loss: 0.05176512151956558
Validation loss: 1.4458755998201267

Epoch: 6| Step: 12
Training loss: 0.09537658840417862
Validation loss: 1.4629538648871965

Epoch: 6| Step: 13
Training loss: 0.11248721182346344
Validation loss: 1.4648098817435644

Epoch: 635| Step: 0
Training loss: 0.14325284957885742
Validation loss: 1.4738955997651624

Epoch: 6| Step: 1
Training loss: 0.04718476161360741
Validation loss: 1.4467069102871803

Epoch: 6| Step: 2
Training loss: 0.0533570870757103
Validation loss: 1.4580875276237406

Epoch: 6| Step: 3
Training loss: 0.1017865464091301
Validation loss: 1.4517933168718893

Epoch: 6| Step: 4
Training loss: 0.0854707807302475
Validation loss: 1.4476681114524923

Epoch: 6| Step: 5
Training loss: 0.14341023564338684
Validation loss: 1.4556219244516024

Epoch: 6| Step: 6
Training loss: 0.07940603792667389
Validation loss: 1.4475493790000997

Epoch: 6| Step: 7
Training loss: 0.04496050626039505
Validation loss: 1.4508808735878236

Epoch: 6| Step: 8
Training loss: 0.044492628425359726
Validation loss: 1.4398944890627297

Epoch: 6| Step: 9
Training loss: 0.05293930321931839
Validation loss: 1.4329193279307375

Epoch: 6| Step: 10
Training loss: 0.05785616487264633
Validation loss: 1.4569965177966702

Epoch: 6| Step: 11
Training loss: 0.046942755579948425
Validation loss: 1.4495513516087686

Epoch: 6| Step: 12
Training loss: 0.10770703852176666
Validation loss: 1.434597530672627

Epoch: 6| Step: 13
Training loss: 0.06889978796243668
Validation loss: 1.4452529479098577

Epoch: 636| Step: 0
Training loss: 0.09007740020751953
Validation loss: 1.4564229506318287

Epoch: 6| Step: 1
Training loss: 0.046104565262794495
Validation loss: 1.4490015199107509

Epoch: 6| Step: 2
Training loss: 0.04865209385752678
Validation loss: 1.4280867307416854

Epoch: 6| Step: 3
Training loss: 0.07320116460323334
Validation loss: 1.4438050786654155

Epoch: 6| Step: 4
Training loss: 0.050199370831251144
Validation loss: 1.423918604850769

Epoch: 6| Step: 5
Training loss: 0.028742585331201553
Validation loss: 1.4025115351523123

Epoch: 6| Step: 6
Training loss: 0.05636634677648544
Validation loss: 1.4614459385154068

Epoch: 6| Step: 7
Training loss: 0.12231175601482391
Validation loss: 1.438416209272159

Epoch: 6| Step: 8
Training loss: 0.051321327686309814
Validation loss: 1.474955383167472

Epoch: 6| Step: 9
Training loss: 0.08269349485635757
Validation loss: 1.5010862850373792

Epoch: 6| Step: 10
Training loss: 0.11470396816730499
Validation loss: 1.494236485932463

Epoch: 6| Step: 11
Training loss: 0.05706620216369629
Validation loss: 1.519800756567268

Epoch: 6| Step: 12
Training loss: 0.12337245792150497
Validation loss: 1.5063755409691924

Epoch: 6| Step: 13
Training loss: 0.043406229466199875
Validation loss: 1.5044052447042158

Epoch: 637| Step: 0
Training loss: 0.07528872042894363
Validation loss: 1.5028540735603662

Epoch: 6| Step: 1
Training loss: 0.07442350685596466
Validation loss: 1.4800155316629717

Epoch: 6| Step: 2
Training loss: 0.08659869432449341
Validation loss: 1.4256322742790304

Epoch: 6| Step: 3
Training loss: 0.08173011243343353
Validation loss: 1.4556378344053864

Epoch: 6| Step: 4
Training loss: 0.07203835994005203
Validation loss: 1.4205373147482514

Epoch: 6| Step: 5
Training loss: 0.05094881355762482
Validation loss: 1.4110804809037076

Epoch: 6| Step: 6
Training loss: 0.08935695141553879
Validation loss: 1.4090086426786197

Epoch: 6| Step: 7
Training loss: 0.08179972320795059
Validation loss: 1.4410864371125416

Epoch: 6| Step: 8
Training loss: 0.0767531469464302
Validation loss: 1.4047483282704507

Epoch: 6| Step: 9
Training loss: 0.05914302170276642
Validation loss: 1.4531289339065552

Epoch: 6| Step: 10
Training loss: 0.05940614640712738
Validation loss: 1.4348573735965195

Epoch: 6| Step: 11
Training loss: 0.10082130134105682
Validation loss: 1.4725722484691168

Epoch: 6| Step: 12
Training loss: 0.12638723850250244
Validation loss: 1.4761172481762466

Epoch: 6| Step: 13
Training loss: 0.081491619348526
Validation loss: 1.506052024902836

Epoch: 638| Step: 0
Training loss: 0.05973956733942032
Validation loss: 1.5300248246039114

Epoch: 6| Step: 1
Training loss: 0.08579880744218826
Validation loss: 1.5164234189577

Epoch: 6| Step: 2
Training loss: 0.08975465595722198
Validation loss: 1.4936537819523965

Epoch: 6| Step: 3
Training loss: 0.06388115882873535
Validation loss: 1.4941672471261793

Epoch: 6| Step: 4
Training loss: 0.1008450984954834
Validation loss: 1.5087173638805267

Epoch: 6| Step: 5
Training loss: 0.07490783929824829
Validation loss: 1.4856024172998243

Epoch: 6| Step: 6
Training loss: 0.10098180919885635
Validation loss: 1.4899654760155627

Epoch: 6| Step: 7
Training loss: 0.0864998996257782
Validation loss: 1.4679931184296966

Epoch: 6| Step: 8
Training loss: 0.10300278663635254
Validation loss: 1.4644799411937754

Epoch: 6| Step: 9
Training loss: 0.06771528720855713
Validation loss: 1.4587395191192627

Epoch: 6| Step: 10
Training loss: 0.06265082955360413
Validation loss: 1.4605860902417092

Epoch: 6| Step: 11
Training loss: 0.05454043298959732
Validation loss: 1.4503172597577494

Epoch: 6| Step: 12
Training loss: 0.0856110081076622
Validation loss: 1.4421818153832549

Epoch: 6| Step: 13
Training loss: 0.058220572769641876
Validation loss: 1.4585020311417118

Epoch: 639| Step: 0
Training loss: 0.10567604005336761
Validation loss: 1.486042780260886

Epoch: 6| Step: 1
Training loss: 0.0730464905500412
Validation loss: 1.4718290349488616

Epoch: 6| Step: 2
Training loss: 0.12114347517490387
Validation loss: 1.4706681389962473

Epoch: 6| Step: 3
Training loss: 0.089694082736969
Validation loss: 1.4612859666988414

Epoch: 6| Step: 4
Training loss: 0.057345859706401825
Validation loss: 1.445192665182134

Epoch: 6| Step: 5
Training loss: 0.08328672498464584
Validation loss: 1.4302016573567544

Epoch: 6| Step: 6
Training loss: 0.07521942257881165
Validation loss: 1.4369020468445235

Epoch: 6| Step: 7
Training loss: 0.07498158514499664
Validation loss: 1.431561056644686

Epoch: 6| Step: 8
Training loss: 0.07863765954971313
Validation loss: 1.4176018507249895

Epoch: 6| Step: 9
Training loss: 0.17522186040878296
Validation loss: 1.4473330577214558

Epoch: 6| Step: 10
Training loss: 0.1153014749288559
Validation loss: 1.4424028832425353

Epoch: 6| Step: 11
Training loss: 0.08113916963338852
Validation loss: 1.4569617176568637

Epoch: 6| Step: 12
Training loss: 0.044944871217012405
Validation loss: 1.4663390113461403

Epoch: 6| Step: 13
Training loss: 0.13366484642028809
Validation loss: 1.4944634399106425

Epoch: 640| Step: 0
Training loss: 0.15028132498264313
Validation loss: 1.531448059184577

Epoch: 6| Step: 1
Training loss: 0.08189426362514496
Validation loss: 1.5328589434264808

Epoch: 6| Step: 2
Training loss: 0.11047946661710739
Validation loss: 1.5193225696522703

Epoch: 6| Step: 3
Training loss: 0.12448696047067642
Validation loss: 1.5168518891898535

Epoch: 6| Step: 4
Training loss: 0.06918641179800034
Validation loss: 1.5059746260284095

Epoch: 6| Step: 5
Training loss: 0.051419977098703384
Validation loss: 1.4712986869196738

Epoch: 6| Step: 6
Training loss: 0.05145382136106491
Validation loss: 1.474704352758264

Epoch: 6| Step: 7
Training loss: 0.09354303777217865
Validation loss: 1.4447696208953857

Epoch: 6| Step: 8
Training loss: 0.11183378845453262
Validation loss: 1.4528117064506776

Epoch: 6| Step: 9
Training loss: 0.07879244536161423
Validation loss: 1.4757049647710656

Epoch: 6| Step: 10
Training loss: 0.07349231094121933
Validation loss: 1.4356611909404877

Epoch: 6| Step: 11
Training loss: 0.06660590320825577
Validation loss: 1.4478605408822336

Epoch: 6| Step: 12
Training loss: 0.06370793282985687
Validation loss: 1.4550857569581719

Epoch: 6| Step: 13
Training loss: 0.08046162873506546
Validation loss: 1.4633968286616827

Epoch: 641| Step: 0
Training loss: 0.1359332799911499
Validation loss: 1.456390050149733

Epoch: 6| Step: 1
Training loss: 0.055599913001060486
Validation loss: 1.4581498446003083

Epoch: 6| Step: 2
Training loss: 0.08341843634843826
Validation loss: 1.4559683312651932

Epoch: 6| Step: 3
Training loss: 0.09557110071182251
Validation loss: 1.4598867098490398

Epoch: 6| Step: 4
Training loss: 0.06350946426391602
Validation loss: 1.4765562280531852

Epoch: 6| Step: 5
Training loss: 0.06008168309926987
Validation loss: 1.4433927177101054

Epoch: 6| Step: 6
Training loss: 0.08392897248268127
Validation loss: 1.4743435395661222

Epoch: 6| Step: 7
Training loss: 0.05940888822078705
Validation loss: 1.4487677812576294

Epoch: 6| Step: 8
Training loss: 0.08604635298252106
Validation loss: 1.4640047357928367

Epoch: 6| Step: 9
Training loss: 0.0532415509223938
Validation loss: 1.4670468863620554

Epoch: 6| Step: 10
Training loss: 0.10143285244703293
Validation loss: 1.4669265772706719

Epoch: 6| Step: 11
Training loss: 0.030452396720647812
Validation loss: 1.4561604863853865

Epoch: 6| Step: 12
Training loss: 0.05065155774354935
Validation loss: 1.4771113498236543

Epoch: 6| Step: 13
Training loss: 0.08935591578483582
Validation loss: 1.4678363633412186

Epoch: 642| Step: 0
Training loss: 0.07576140761375427
Validation loss: 1.4468424243311728

Epoch: 6| Step: 1
Training loss: 0.06977670639753342
Validation loss: 1.4644559814083962

Epoch: 6| Step: 2
Training loss: 0.047936927527189255
Validation loss: 1.4709998330762308

Epoch: 6| Step: 3
Training loss: 0.08610991388559341
Validation loss: 1.4506512905961724

Epoch: 6| Step: 4
Training loss: 0.04947473853826523
Validation loss: 1.4551955961412

Epoch: 6| Step: 5
Training loss: 0.055694662034511566
Validation loss: 1.4576514433788996

Epoch: 6| Step: 6
Training loss: 0.03832044079899788
Validation loss: 1.4459904842479254

Epoch: 6| Step: 7
Training loss: 0.09873148798942566
Validation loss: 1.4672337232097503

Epoch: 6| Step: 8
Training loss: 0.06909170746803284
Validation loss: 1.4536851259969896

Epoch: 6| Step: 9
Training loss: 0.04333881288766861
Validation loss: 1.4698697610567975

Epoch: 6| Step: 10
Training loss: 0.06105680391192436
Validation loss: 1.4436702984635548

Epoch: 6| Step: 11
Training loss: 0.05576535314321518
Validation loss: 1.4442671780945153

Epoch: 6| Step: 12
Training loss: 0.10176535695791245
Validation loss: 1.4359132166831725

Epoch: 6| Step: 13
Training loss: 0.07012476027011871
Validation loss: 1.413204518697595

Epoch: 643| Step: 0
Training loss: 0.07396844029426575
Validation loss: 1.4250058640715897

Epoch: 6| Step: 1
Training loss: 0.06193319708108902
Validation loss: 1.3936442303401169

Epoch: 6| Step: 2
Training loss: 0.06134913116693497
Validation loss: 1.40744871734291

Epoch: 6| Step: 3
Training loss: 0.11123392730951309
Validation loss: 1.4172023778320642

Epoch: 6| Step: 4
Training loss: 0.06685571372509003
Validation loss: 1.4001248472480363

Epoch: 6| Step: 5
Training loss: 0.041568294167518616
Validation loss: 1.422288829280484

Epoch: 6| Step: 6
Training loss: 0.10041029751300812
Validation loss: 1.3958906345469977

Epoch: 6| Step: 7
Training loss: 0.06132030487060547
Validation loss: 1.4343307108007453

Epoch: 6| Step: 8
Training loss: 0.04481629282236099
Validation loss: 1.4227478824635988

Epoch: 6| Step: 9
Training loss: 0.07718230783939362
Validation loss: 1.391603292957429

Epoch: 6| Step: 10
Training loss: 0.05211177468299866
Validation loss: 1.4357467428330453

Epoch: 6| Step: 11
Training loss: 0.05026981234550476
Validation loss: 1.4105230839021745

Epoch: 6| Step: 12
Training loss: 0.10988799482584
Validation loss: 1.4480865847679876

Epoch: 6| Step: 13
Training loss: 0.06307198852300644
Validation loss: 1.4658077852700346

Epoch: 644| Step: 0
Training loss: 0.07995649427175522
Validation loss: 1.4297137702665021

Epoch: 6| Step: 1
Training loss: 0.06113950163125992
Validation loss: 1.4461908442999727

Epoch: 6| Step: 2
Training loss: 0.07737616449594498
Validation loss: 1.4147762329347673

Epoch: 6| Step: 3
Training loss: 0.06697831302881241
Validation loss: 1.420191253385236

Epoch: 6| Step: 4
Training loss: 0.05833480507135391
Validation loss: 1.4312816909564439

Epoch: 6| Step: 5
Training loss: 0.10903918743133545
Validation loss: 1.435980486613448

Epoch: 6| Step: 6
Training loss: 0.04336358979344368
Validation loss: 1.4229517700851604

Epoch: 6| Step: 7
Training loss: 0.06835399568080902
Validation loss: 1.4240615316616592

Epoch: 6| Step: 8
Training loss: 0.09194251894950867
Validation loss: 1.4409173060488958

Epoch: 6| Step: 9
Training loss: 0.07622979581356049
Validation loss: 1.4345441569564163

Epoch: 6| Step: 10
Training loss: 0.041838422417640686
Validation loss: 1.415374784059422

Epoch: 6| Step: 11
Training loss: 0.08257687836885452
Validation loss: 1.4493957296494515

Epoch: 6| Step: 12
Training loss: 0.04650139808654785
Validation loss: 1.436984767195999

Epoch: 6| Step: 13
Training loss: 0.053121812641620636
Validation loss: 1.4408275952903173

Epoch: 645| Step: 0
Training loss: 0.03759048134088516
Validation loss: 1.4106751026645783

Epoch: 6| Step: 1
Training loss: 0.08173470199108124
Validation loss: 1.4101802905400593

Epoch: 6| Step: 2
Training loss: 0.08907166123390198
Validation loss: 1.4184615483847998

Epoch: 6| Step: 3
Training loss: 0.06729938089847565
Validation loss: 1.4140139766918716

Epoch: 6| Step: 4
Training loss: 0.06760773062705994
Validation loss: 1.395395177666859

Epoch: 6| Step: 5
Training loss: 0.03954436257481575
Validation loss: 1.4210287063352522

Epoch: 6| Step: 6
Training loss: 0.05821637064218521
Validation loss: 1.4539896044679868

Epoch: 6| Step: 7
Training loss: 0.03696466237306595
Validation loss: 1.4367696316011491

Epoch: 6| Step: 8
Training loss: 0.06270027905702591
Validation loss: 1.4293225772919194

Epoch: 6| Step: 9
Training loss: 0.10274109244346619
Validation loss: 1.4493691805870301

Epoch: 6| Step: 10
Training loss: 0.0878184512257576
Validation loss: 1.4534019295887282

Epoch: 6| Step: 11
Training loss: 0.058071237057447433
Validation loss: 1.4288932770811102

Epoch: 6| Step: 12
Training loss: 0.055588189512491226
Validation loss: 1.4424628057787496

Epoch: 6| Step: 13
Training loss: 0.07489185780286789
Validation loss: 1.4433800674253894

Epoch: 646| Step: 0
Training loss: 0.0751955583691597
Validation loss: 1.4503149281265915

Epoch: 6| Step: 1
Training loss: 0.04243083298206329
Validation loss: 1.4293224965372393

Epoch: 6| Step: 2
Training loss: 0.06606198847293854
Validation loss: 1.4459246807200934

Epoch: 6| Step: 3
Training loss: 0.07589186728000641
Validation loss: 1.461219408178842

Epoch: 6| Step: 4
Training loss: 0.08789607137441635
Validation loss: 1.415122369284271

Epoch: 6| Step: 5
Training loss: 0.07018120586872101
Validation loss: 1.4257404611956688

Epoch: 6| Step: 6
Training loss: 0.04482677951455116
Validation loss: 1.4440950206530991

Epoch: 6| Step: 7
Training loss: 0.06997600197792053
Validation loss: 1.4197178335600003

Epoch: 6| Step: 8
Training loss: 0.060510143637657166
Validation loss: 1.4268478244863532

Epoch: 6| Step: 9
Training loss: 0.03672267869114876
Validation loss: 1.4259962830492245

Epoch: 6| Step: 10
Training loss: 0.08064686506986618
Validation loss: 1.4392906273564985

Epoch: 6| Step: 11
Training loss: 0.06043335422873497
Validation loss: 1.403370670093003

Epoch: 6| Step: 12
Training loss: 0.06435234844684601
Validation loss: 1.4242880241845244

Epoch: 6| Step: 13
Training loss: 0.02895244024693966
Validation loss: 1.4228543684046755

Epoch: 647| Step: 0
Training loss: 0.0465635247528553
Validation loss: 1.4431552861326484

Epoch: 6| Step: 1
Training loss: 0.07305489480495453
Validation loss: 1.4123133613217262

Epoch: 6| Step: 2
Training loss: 0.08424139022827148
Validation loss: 1.4333051391827163

Epoch: 6| Step: 3
Training loss: 0.0496019683778286
Validation loss: 1.4445495291422772

Epoch: 6| Step: 4
Training loss: 0.05017608031630516
Validation loss: 1.4240744665104856

Epoch: 6| Step: 5
Training loss: 0.038808438926935196
Validation loss: 1.4345884476938555

Epoch: 6| Step: 6
Training loss: 0.07558096945285797
Validation loss: 1.4442532293258175

Epoch: 6| Step: 7
Training loss: 0.07907013595104218
Validation loss: 1.4477789966008996

Epoch: 6| Step: 8
Training loss: 0.09040974825620651
Validation loss: 1.4567529155362038

Epoch: 6| Step: 9
Training loss: 0.061601422727108
Validation loss: 1.4412979349013297

Epoch: 6| Step: 10
Training loss: 0.046613313257694244
Validation loss: 1.438359183649863

Epoch: 6| Step: 11
Training loss: 0.054938703775405884
Validation loss: 1.437551857322775

Epoch: 6| Step: 12
Training loss: 0.06638278067111969
Validation loss: 1.4281703887447235

Epoch: 6| Step: 13
Training loss: 0.03809507563710213
Validation loss: 1.4193395671024118

Epoch: 648| Step: 0
Training loss: 0.07914265245199203
Validation loss: 1.4313315665850075

Epoch: 6| Step: 1
Training loss: 0.06847208738327026
Validation loss: 1.43902426509447

Epoch: 6| Step: 2
Training loss: 0.061607878655195236
Validation loss: 1.4319138847371584

Epoch: 6| Step: 3
Training loss: 0.057408347725868225
Validation loss: 1.4213867123408983

Epoch: 6| Step: 4
Training loss: 0.08895570039749146
Validation loss: 1.4235315912513322

Epoch: 6| Step: 5
Training loss: 0.07727043330669403
Validation loss: 1.4060156165912587

Epoch: 6| Step: 6
Training loss: 0.038633305579423904
Validation loss: 1.4015560111691874

Epoch: 6| Step: 7
Training loss: 0.04172590747475624
Validation loss: 1.4203722733323292

Epoch: 6| Step: 8
Training loss: 0.07149028778076172
Validation loss: 1.4147045099607078

Epoch: 6| Step: 9
Training loss: 0.06647499650716782
Validation loss: 1.4096867422903738

Epoch: 6| Step: 10
Training loss: 0.043928034603595734
Validation loss: 1.401679072328793

Epoch: 6| Step: 11
Training loss: 0.09324623644351959
Validation loss: 1.4483702900589153

Epoch: 6| Step: 12
Training loss: 0.06633089482784271
Validation loss: 1.4085494267043246

Epoch: 6| Step: 13
Training loss: 0.06218786910176277
Validation loss: 1.4071750576778124

Epoch: 649| Step: 0
Training loss: 0.03010023571550846
Validation loss: 1.4236274457746936

Epoch: 6| Step: 1
Training loss: 0.06320622563362122
Validation loss: 1.441623923599079

Epoch: 6| Step: 2
Training loss: 0.05692525953054428
Validation loss: 1.423048496246338

Epoch: 6| Step: 3
Training loss: 0.04971889406442642
Validation loss: 1.4355006346138575

Epoch: 6| Step: 4
Training loss: 0.1041325032711029
Validation loss: 1.4253394834456905

Epoch: 6| Step: 5
Training loss: 0.06414419412612915
Validation loss: 1.3972778307494296

Epoch: 6| Step: 6
Training loss: 0.046162307262420654
Validation loss: 1.3986363000767206

Epoch: 6| Step: 7
Training loss: 0.06536466628313065
Validation loss: 1.4198776188717093

Epoch: 6| Step: 8
Training loss: 0.08599157631397247
Validation loss: 1.3968036110683153

Epoch: 6| Step: 9
Training loss: 0.06461840122938156
Validation loss: 1.387347266238223

Epoch: 6| Step: 10
Training loss: 0.080472931265831
Validation loss: 1.376992775547889

Epoch: 6| Step: 11
Training loss: 0.06473498046398163
Validation loss: 1.3769720331315072

Epoch: 6| Step: 12
Training loss: 0.11979114264249802
Validation loss: 1.389739090396512

Epoch: 6| Step: 13
Training loss: 0.05576234310865402
Validation loss: 1.3737998226637482

Epoch: 650| Step: 0
Training loss: 0.052655477076768875
Validation loss: 1.4121045207464566

Epoch: 6| Step: 1
Training loss: 0.0374956876039505
Validation loss: 1.3961714839422574

Epoch: 6| Step: 2
Training loss: 0.10274660587310791
Validation loss: 1.3967416530014367

Epoch: 6| Step: 3
Training loss: 0.07585176080465317
Validation loss: 1.4142730069416825

Epoch: 6| Step: 4
Training loss: 0.09006457775831223
Validation loss: 1.4368534498317267

Epoch: 6| Step: 5
Training loss: 0.04119990020990372
Validation loss: 1.4385239411425847

Epoch: 6| Step: 6
Training loss: 0.07814541459083557
Validation loss: 1.421772651774909

Epoch: 6| Step: 7
Training loss: 0.038167037069797516
Validation loss: 1.4592257904750046

Epoch: 6| Step: 8
Training loss: 0.047404807060956955
Validation loss: 1.438038836243332

Epoch: 6| Step: 9
Training loss: 0.09199637174606323
Validation loss: 1.440547590614647

Epoch: 6| Step: 10
Training loss: 0.0814979076385498
Validation loss: 1.4621721544573385

Epoch: 6| Step: 11
Training loss: 0.06869753450155258
Validation loss: 1.4656961579476633

Epoch: 6| Step: 12
Training loss: 0.09976470470428467
Validation loss: 1.4587522540041196

Epoch: 6| Step: 13
Training loss: 0.056531891226768494
Validation loss: 1.473202722046965

Epoch: 651| Step: 0
Training loss: 0.08032585680484772
Validation loss: 1.4864041779630928

Epoch: 6| Step: 1
Training loss: 0.061430424451828
Validation loss: 1.4917714903431554

Epoch: 6| Step: 2
Training loss: 0.06943678855895996
Validation loss: 1.502381641377685

Epoch: 6| Step: 3
Training loss: 0.08863591402769089
Validation loss: 1.4734569057341544

Epoch: 6| Step: 4
Training loss: 0.049018025398254395
Validation loss: 1.44881486123608

Epoch: 6| Step: 5
Training loss: 0.03969614952802658
Validation loss: 1.456795225861252

Epoch: 6| Step: 6
Training loss: 0.06974992156028748
Validation loss: 1.4490500829553092

Epoch: 6| Step: 7
Training loss: 0.04210565611720085
Validation loss: 1.4426261481418405

Epoch: 6| Step: 8
Training loss: 0.05885380506515503
Validation loss: 1.4307424509397118

Epoch: 6| Step: 9
Training loss: 0.08080728352069855
Validation loss: 1.4101715318618282

Epoch: 6| Step: 10
Training loss: 0.09968536347150803
Validation loss: 1.4401861224123227

Epoch: 6| Step: 11
Training loss: 0.11416766047477722
Validation loss: 1.42615637599781

Epoch: 6| Step: 12
Training loss: 0.05982402339577675
Validation loss: 1.4376624527797903

Epoch: 6| Step: 13
Training loss: 0.09257089346647263
Validation loss: 1.4223248292041082

Epoch: 652| Step: 0
Training loss: 0.06985234469175339
Validation loss: 1.4264430692118983

Epoch: 6| Step: 1
Training loss: 0.05897077918052673
Validation loss: 1.4249754939028012

Epoch: 6| Step: 2
Training loss: 0.09345623105764389
Validation loss: 1.443424460708454

Epoch: 6| Step: 3
Training loss: 0.06160940229892731
Validation loss: 1.450313639897172

Epoch: 6| Step: 4
Training loss: 0.05730075389146805
Validation loss: 1.4671232264528993

Epoch: 6| Step: 5
Training loss: 0.0766594409942627
Validation loss: 1.463511650921196

Epoch: 6| Step: 6
Training loss: 0.08241692930459976
Validation loss: 1.470332298868446

Epoch: 6| Step: 7
Training loss: 0.10326778888702393
Validation loss: 1.4416555230335524

Epoch: 6| Step: 8
Training loss: 0.06185918673872948
Validation loss: 1.4484173264554752

Epoch: 6| Step: 9
Training loss: 0.061355218291282654
Validation loss: 1.4532973176689559

Epoch: 6| Step: 10
Training loss: 0.09187256544828415
Validation loss: 1.4312922505922214

Epoch: 6| Step: 11
Training loss: 0.04969928413629532
Validation loss: 1.3973858087293562

Epoch: 6| Step: 12
Training loss: 0.06462796032428741
Validation loss: 1.4079462302628385

Epoch: 6| Step: 13
Training loss: 0.06734351068735123
Validation loss: 1.4033400576601747

Epoch: 653| Step: 0
Training loss: 0.036513060331344604
Validation loss: 1.3909821612860567

Epoch: 6| Step: 1
Training loss: 0.06828101724386215
Validation loss: 1.4014509634305072

Epoch: 6| Step: 2
Training loss: 0.08779403567314148
Validation loss: 1.4222770025653224

Epoch: 6| Step: 3
Training loss: 0.04843475669622421
Validation loss: 1.42595624667342

Epoch: 6| Step: 4
Training loss: 0.034928254783153534
Validation loss: 1.428978822564566

Epoch: 6| Step: 5
Training loss: 0.06694647669792175
Validation loss: 1.4492328064416045

Epoch: 6| Step: 6
Training loss: 0.05117643624544144
Validation loss: 1.4303140140348864

Epoch: 6| Step: 7
Training loss: 0.1115337610244751
Validation loss: 1.4471384094607445

Epoch: 6| Step: 8
Training loss: 0.0857902467250824
Validation loss: 1.4478259849291977

Epoch: 6| Step: 9
Training loss: 0.06492868810892105
Validation loss: 1.4456503737357356

Epoch: 6| Step: 10
Training loss: 0.053466301411390305
Validation loss: 1.4399812490709367

Epoch: 6| Step: 11
Training loss: 0.05526132136583328
Validation loss: 1.4284694643430813

Epoch: 6| Step: 12
Training loss: 0.04929710552096367
Validation loss: 1.4095266249872023

Epoch: 6| Step: 13
Training loss: 0.06539236754179001
Validation loss: 1.4286994703354374

Epoch: 654| Step: 0
Training loss: 0.06803522258996964
Validation loss: 1.4296886023654733

Epoch: 6| Step: 1
Training loss: 0.0423101969063282
Validation loss: 1.381290538336641

Epoch: 6| Step: 2
Training loss: 0.05878514051437378
Validation loss: 1.4087575430511146

Epoch: 6| Step: 3
Training loss: 0.09908342361450195
Validation loss: 1.4093120508296515

Epoch: 6| Step: 4
Training loss: 0.06504589319229126
Validation loss: 1.3994832872062601

Epoch: 6| Step: 5
Training loss: 0.061882663518190384
Validation loss: 1.407891756744795

Epoch: 6| Step: 6
Training loss: 0.0687742829322815
Validation loss: 1.3980049913929355

Epoch: 6| Step: 7
Training loss: 0.057605840265750885
Validation loss: 1.3664759846143826

Epoch: 6| Step: 8
Training loss: 0.03252468630671501
Validation loss: 1.3980351628795746

Epoch: 6| Step: 9
Training loss: 0.057167571038007736
Validation loss: 1.3727369987836449

Epoch: 6| Step: 10
Training loss: 0.053403329104185104
Validation loss: 1.3704458385385492

Epoch: 6| Step: 11
Training loss: 0.054580703377723694
Validation loss: 1.3882465747094923

Epoch: 6| Step: 12
Training loss: 0.054174043238162994
Validation loss: 1.416542963315082

Epoch: 6| Step: 13
Training loss: 0.09778356552124023
Validation loss: 1.4128109152599047

Epoch: 655| Step: 0
Training loss: 0.04537251591682434
Validation loss: 1.41383913511871

Epoch: 6| Step: 1
Training loss: 0.03274064511060715
Validation loss: 1.4323022429661085

Epoch: 6| Step: 2
Training loss: 0.11512140929698944
Validation loss: 1.4077253469856836

Epoch: 6| Step: 3
Training loss: 0.04935155436396599
Validation loss: 1.4106442274585846

Epoch: 6| Step: 4
Training loss: 0.07112080603837967
Validation loss: 1.4252768319140199

Epoch: 6| Step: 5
Training loss: 0.05277198925614357
Validation loss: 1.399166669896854

Epoch: 6| Step: 6
Training loss: 0.09876265376806259
Validation loss: 1.393800405404901

Epoch: 6| Step: 7
Training loss: 0.06354282796382904
Validation loss: 1.3875238228869695

Epoch: 6| Step: 8
Training loss: 0.04940461367368698
Validation loss: 1.4120595314169442

Epoch: 6| Step: 9
Training loss: 0.07889020442962646
Validation loss: 1.395752937563004

Epoch: 6| Step: 10
Training loss: 0.039029017090797424
Validation loss: 1.4125323103320213

Epoch: 6| Step: 11
Training loss: 0.03972739726305008
Validation loss: 1.4067975590305943

Epoch: 6| Step: 12
Training loss: 0.08705917000770569
Validation loss: 1.4051898000060872

Epoch: 6| Step: 13
Training loss: 0.02802024595439434
Validation loss: 1.3688988249789003

Epoch: 656| Step: 0
Training loss: 0.0658915787935257
Validation loss: 1.4134339004434564

Epoch: 6| Step: 1
Training loss: 0.08598184585571289
Validation loss: 1.3612231163568393

Epoch: 6| Step: 2
Training loss: 0.06689988821744919
Validation loss: 1.3682289601013224

Epoch: 6| Step: 3
Training loss: 0.05437985062599182
Validation loss: 1.39029344179297

Epoch: 6| Step: 4
Training loss: 0.055095504969358444
Validation loss: 1.411679804966014

Epoch: 6| Step: 5
Training loss: 0.04488067701458931
Validation loss: 1.383981772648391

Epoch: 6| Step: 6
Training loss: 0.04999781399965286
Validation loss: 1.3934038416031869

Epoch: 6| Step: 7
Training loss: 0.1085660457611084
Validation loss: 1.4112714259855208

Epoch: 6| Step: 8
Training loss: 0.04067354276776314
Validation loss: 1.4258703595848494

Epoch: 6| Step: 9
Training loss: 0.04950764775276184
Validation loss: 1.4267796162636048

Epoch: 6| Step: 10
Training loss: 0.09514648467302322
Validation loss: 1.4147463716486448

Epoch: 6| Step: 11
Training loss: 0.06366416811943054
Validation loss: 1.4254581620616298

Epoch: 6| Step: 12
Training loss: 0.08566965162754059
Validation loss: 1.4542391377110635

Epoch: 6| Step: 13
Training loss: 0.07640808820724487
Validation loss: 1.4263752327170423

Epoch: 657| Step: 0
Training loss: 0.07960651069879532
Validation loss: 1.412223764645156

Epoch: 6| Step: 1
Training loss: 0.04903418570756912
Validation loss: 1.4054220446976282

Epoch: 6| Step: 2
Training loss: 0.05500493943691254
Validation loss: 1.3968107302983601

Epoch: 6| Step: 3
Training loss: 0.08571029454469681
Validation loss: 1.4015113704948015

Epoch: 6| Step: 4
Training loss: 0.08563349395990372
Validation loss: 1.4015622831160022

Epoch: 6| Step: 5
Training loss: 0.07314234226942062
Validation loss: 1.4152006128782868

Epoch: 6| Step: 6
Training loss: 0.05487919971346855
Validation loss: 1.4128694290755897

Epoch: 6| Step: 7
Training loss: 0.054245345294475555
Validation loss: 1.410700055860704

Epoch: 6| Step: 8
Training loss: 0.04416731745004654
Validation loss: 1.4293562545571277

Epoch: 6| Step: 9
Training loss: 0.09035521745681763
Validation loss: 1.45671114870297

Epoch: 6| Step: 10
Training loss: 0.049947306513786316
Validation loss: 1.4542098852895922

Epoch: 6| Step: 11
Training loss: 0.12498828023672104
Validation loss: 1.4628017775474056

Epoch: 6| Step: 12
Training loss: 0.07391716539859772
Validation loss: 1.4594819404745614

Epoch: 6| Step: 13
Training loss: 0.04969652369618416
Validation loss: 1.4774198416740663

Epoch: 658| Step: 0
Training loss: 0.054991647601127625
Validation loss: 1.448345955982003

Epoch: 6| Step: 1
Training loss: 0.0787862241268158
Validation loss: 1.4417162364529026

Epoch: 6| Step: 2
Training loss: 0.09436172246932983
Validation loss: 1.4349214364123601

Epoch: 6| Step: 3
Training loss: 0.06762285530567169
Validation loss: 1.4425729833623415

Epoch: 6| Step: 4
Training loss: 0.07315981388092041
Validation loss: 1.4279472340819657

Epoch: 6| Step: 5
Training loss: 0.068878173828125
Validation loss: 1.4064739634913783

Epoch: 6| Step: 6
Training loss: 0.0470871664583683
Validation loss: 1.4194754169833275

Epoch: 6| Step: 7
Training loss: 0.04557953029870987
Validation loss: 1.4204266455865675

Epoch: 6| Step: 8
Training loss: 0.08679000288248062
Validation loss: 1.4129511989572996

Epoch: 6| Step: 9
Training loss: 0.04184950515627861
Validation loss: 1.4066426683497686

Epoch: 6| Step: 10
Training loss: 0.07991725206375122
Validation loss: 1.390455577963142

Epoch: 6| Step: 11
Training loss: 0.079527348279953
Validation loss: 1.4192809558683825

Epoch: 6| Step: 12
Training loss: 0.05657520890235901
Validation loss: 1.4050327834262644

Epoch: 6| Step: 13
Training loss: 0.061048004776239395
Validation loss: 1.398065040188451

Epoch: 659| Step: 0
Training loss: 0.05511391535401344
Validation loss: 1.419127886013318

Epoch: 6| Step: 1
Training loss: 0.08623611181974411
Validation loss: 1.444853800599293

Epoch: 6| Step: 2
Training loss: 0.07108786702156067
Validation loss: 1.4510675053442679

Epoch: 6| Step: 3
Training loss: 0.03942468389868736
Validation loss: 1.462888063923005

Epoch: 6| Step: 4
Training loss: 0.08995983004570007
Validation loss: 1.4696242270931121

Epoch: 6| Step: 5
Training loss: 0.09268742054700851
Validation loss: 1.4550926185423327

Epoch: 6| Step: 6
Training loss: 0.07941503077745438
Validation loss: 1.4489156642267782

Epoch: 6| Step: 7
Training loss: 0.06211268901824951
Validation loss: 1.4415525774801932

Epoch: 6| Step: 8
Training loss: 0.05100394785404205
Validation loss: 1.4306422561727545

Epoch: 6| Step: 9
Training loss: 0.038952380418777466
Validation loss: 1.391794817422026

Epoch: 6| Step: 10
Training loss: 0.11057977378368378
Validation loss: 1.4115420669637702

Epoch: 6| Step: 11
Training loss: 0.0668877437710762
Validation loss: 1.4151340940947175

Epoch: 6| Step: 12
Training loss: 0.07511626929044724
Validation loss: 1.3957235608049618

Epoch: 6| Step: 13
Training loss: 0.06930187344551086
Validation loss: 1.4101862619000096

Epoch: 660| Step: 0
Training loss: 0.05983399599790573
Validation loss: 1.3759426186161656

Epoch: 6| Step: 1
Training loss: 0.06864769756793976
Validation loss: 1.3909128506978352

Epoch: 6| Step: 2
Training loss: 0.09284388273954391
Validation loss: 1.361635870830987

Epoch: 6| Step: 3
Training loss: 0.06560514122247696
Validation loss: 1.365698404209588

Epoch: 6| Step: 4
Training loss: 0.035703908652067184
Validation loss: 1.353262537269182

Epoch: 6| Step: 5
Training loss: 0.049742940813302994
Validation loss: 1.388205414177269

Epoch: 6| Step: 6
Training loss: 0.0961233451962471
Validation loss: 1.3658607723892375

Epoch: 6| Step: 7
Training loss: 0.07886503636837006
Validation loss: 1.3917317915988225

Epoch: 6| Step: 8
Training loss: 0.03581898659467697
Validation loss: 1.4123132792852258

Epoch: 6| Step: 9
Training loss: 0.08004507422447205
Validation loss: 1.388476191028472

Epoch: 6| Step: 10
Training loss: 0.043572332710027695
Validation loss: 1.4163368735262143

Epoch: 6| Step: 11
Training loss: 0.08523526787757874
Validation loss: 1.4246664841969807

Epoch: 6| Step: 12
Training loss: 0.08539219200611115
Validation loss: 1.4637423048737228

Epoch: 6| Step: 13
Training loss: 0.10775443911552429
Validation loss: 1.4444837467644804

Epoch: 661| Step: 0
Training loss: 0.09312573075294495
Validation loss: 1.4545387837194628

Epoch: 6| Step: 1
Training loss: 0.09522685408592224
Validation loss: 1.469200825178495

Epoch: 6| Step: 2
Training loss: 0.07138962298631668
Validation loss: 1.4654742569051764

Epoch: 6| Step: 3
Training loss: 0.08991555124521255
Validation loss: 1.4423913865961053

Epoch: 6| Step: 4
Training loss: 0.035747066140174866
Validation loss: 1.4103078560162616

Epoch: 6| Step: 5
Training loss: 0.05754941329360008
Validation loss: 1.4100932895496328

Epoch: 6| Step: 6
Training loss: 0.05989697575569153
Validation loss: 1.4199775034381497

Epoch: 6| Step: 7
Training loss: 0.07074712216854095
Validation loss: 1.402846137682597

Epoch: 6| Step: 8
Training loss: 0.03685411065816879
Validation loss: 1.394018215517844

Epoch: 6| Step: 9
Training loss: 0.08171829581260681
Validation loss: 1.4303727688327912

Epoch: 6| Step: 10
Training loss: 0.06150200217962265
Validation loss: 1.4116751429855183

Epoch: 6| Step: 11
Training loss: 0.04344198852777481
Validation loss: 1.4221537023462274

Epoch: 6| Step: 12
Training loss: 0.08069431781768799
Validation loss: 1.4415336514032016

Epoch: 6| Step: 13
Training loss: 0.0731125921010971
Validation loss: 1.4577558758438274

Epoch: 662| Step: 0
Training loss: 0.11131562292575836
Validation loss: 1.4489201557251714

Epoch: 6| Step: 1
Training loss: 0.07165688276290894
Validation loss: 1.4344152859462205

Epoch: 6| Step: 2
Training loss: 0.051881976425647736
Validation loss: 1.405154465347208

Epoch: 6| Step: 3
Training loss: 0.05655411630868912
Validation loss: 1.3865022633665351

Epoch: 6| Step: 4
Training loss: 0.03675118461251259
Validation loss: 1.394099275271098

Epoch: 6| Step: 5
Training loss: 0.05578818917274475
Validation loss: 1.3862495268544843

Epoch: 6| Step: 6
Training loss: 0.07503893226385117
Validation loss: 1.3667322704868932

Epoch: 6| Step: 7
Training loss: 0.0883776918053627
Validation loss: 1.4165445502086351

Epoch: 6| Step: 8
Training loss: 0.10489164292812347
Validation loss: 1.4133186506968674

Epoch: 6| Step: 9
Training loss: 0.057006560266017914
Validation loss: 1.4383024784826464

Epoch: 6| Step: 10
Training loss: 0.06783946603536606
Validation loss: 1.4580858497209446

Epoch: 6| Step: 11
Training loss: 0.11022678017616272
Validation loss: 1.46096323767016

Epoch: 6| Step: 12
Training loss: 0.07412209361791611
Validation loss: 1.456538341378653

Epoch: 6| Step: 13
Training loss: 0.08567260205745697
Validation loss: 1.5021597698170652

Epoch: 663| Step: 0
Training loss: 0.08685418963432312
Validation loss: 1.5182042339796662

Epoch: 6| Step: 1
Training loss: 0.10384809225797653
Validation loss: 1.494439318615903

Epoch: 6| Step: 2
Training loss: 0.06654369831085205
Validation loss: 1.4906029573050879

Epoch: 6| Step: 3
Training loss: 0.06470872461795807
Validation loss: 1.4721640386889059

Epoch: 6| Step: 4
Training loss: 0.06920091807842255
Validation loss: 1.4779219114652244

Epoch: 6| Step: 5
Training loss: 0.08835197240114212
Validation loss: 1.448596086553348

Epoch: 6| Step: 6
Training loss: 0.07386793941259384
Validation loss: 1.4655549077577488

Epoch: 6| Step: 7
Training loss: 0.048225656151771545
Validation loss: 1.4461424376374932

Epoch: 6| Step: 8
Training loss: 0.06880144774913788
Validation loss: 1.4512336478438428

Epoch: 6| Step: 9
Training loss: 0.054100338369607925
Validation loss: 1.4439213372045947

Epoch: 6| Step: 10
Training loss: 0.06286647915840149
Validation loss: 1.447890220149871

Epoch: 6| Step: 11
Training loss: 0.0823693722486496
Validation loss: 1.4452054051942722

Epoch: 6| Step: 12
Training loss: 0.05078441649675369
Validation loss: 1.447485504611846

Epoch: 6| Step: 13
Training loss: 0.05896759778261185
Validation loss: 1.4812484248991935

Epoch: 664| Step: 0
Training loss: 0.08854597806930542
Validation loss: 1.4502619697201637

Epoch: 6| Step: 1
Training loss: 0.09661475569009781
Validation loss: 1.4468523725386588

Epoch: 6| Step: 2
Training loss: 0.03594498336315155
Validation loss: 1.4839719251919818

Epoch: 6| Step: 3
Training loss: 0.046904195100069046
Validation loss: 1.4602179655464746

Epoch: 6| Step: 4
Training loss: 0.05101921781897545
Validation loss: 1.4696241642839165

Epoch: 6| Step: 5
Training loss: 0.043685056269168854
Validation loss: 1.4814354668381393

Epoch: 6| Step: 6
Training loss: 0.11287801712751389
Validation loss: 1.4907060861587524

Epoch: 6| Step: 7
Training loss: 0.05415160953998566
Validation loss: 1.465177421928734

Epoch: 6| Step: 8
Training loss: 0.05950728431344032
Validation loss: 1.4866594486339118

Epoch: 6| Step: 9
Training loss: 0.05479416251182556
Validation loss: 1.4733503172474522

Epoch: 6| Step: 10
Training loss: 0.08687210828065872
Validation loss: 1.4582939288949455

Epoch: 6| Step: 11
Training loss: 0.04629899561405182
Validation loss: 1.4449709000126008

Epoch: 6| Step: 12
Training loss: 0.034563541412353516
Validation loss: 1.4401512543360393

Epoch: 6| Step: 13
Training loss: 0.043670766055583954
Validation loss: 1.4359369175408476

Epoch: 665| Step: 0
Training loss: 0.07413165271282196
Validation loss: 1.438024099796049

Epoch: 6| Step: 1
Training loss: 0.06292659789323807
Validation loss: 1.4405335226366598

Epoch: 6| Step: 2
Training loss: 0.07587680965662003
Validation loss: 1.4521910349527996

Epoch: 6| Step: 3
Training loss: 0.09622859209775925
Validation loss: 1.45960102030026

Epoch: 6| Step: 4
Training loss: 0.08549129217863083
Validation loss: 1.4799118554720314

Epoch: 6| Step: 5
Training loss: 0.07544668763875961
Validation loss: 1.484746599710116

Epoch: 6| Step: 6
Training loss: 0.09842301905155182
Validation loss: 1.4744975804000773

Epoch: 6| Step: 7
Training loss: 0.07029823213815689
Validation loss: 1.493889598436253

Epoch: 6| Step: 8
Training loss: 0.10870455950498581
Validation loss: 1.4638531073447196

Epoch: 6| Step: 9
Training loss: 0.059287626296281815
Validation loss: 1.4568133866915138

Epoch: 6| Step: 10
Training loss: 0.06788311898708344
Validation loss: 1.4276585079008532

Epoch: 6| Step: 11
Training loss: 0.059082042425870895
Validation loss: 1.4550165566064979

Epoch: 6| Step: 12
Training loss: 0.1056731715798378
Validation loss: 1.4524275474650885

Epoch: 6| Step: 13
Training loss: 0.04345875605940819
Validation loss: 1.467623689482289

Epoch: 666| Step: 0
Training loss: 0.07162521779537201
Validation loss: 1.4701887689610964

Epoch: 6| Step: 1
Training loss: 0.05052834004163742
Validation loss: 1.491577556056361

Epoch: 6| Step: 2
Training loss: 0.06463313102722168
Validation loss: 1.45829826401126

Epoch: 6| Step: 3
Training loss: 0.04384341835975647
Validation loss: 1.4810390010956795

Epoch: 6| Step: 4
Training loss: 0.038198281079530716
Validation loss: 1.4876077226413194

Epoch: 6| Step: 5
Training loss: 0.09379608929157257
Validation loss: 1.4928766053210023

Epoch: 6| Step: 6
Training loss: 0.06035652384161949
Validation loss: 1.4673329181568597

Epoch: 6| Step: 7
Training loss: 0.05994962155818939
Validation loss: 1.4517975302152737

Epoch: 6| Step: 8
Training loss: 0.08120854198932648
Validation loss: 1.4763041939786685

Epoch: 6| Step: 9
Training loss: 0.052075836807489395
Validation loss: 1.4401929314418505

Epoch: 6| Step: 10
Training loss: 0.094277024269104
Validation loss: 1.4207156563317904

Epoch: 6| Step: 11
Training loss: 0.053947821259498596
Validation loss: 1.4181298517411756

Epoch: 6| Step: 12
Training loss: 0.03948882594704628
Validation loss: 1.4123031695683796

Epoch: 6| Step: 13
Training loss: 0.07364105433225632
Validation loss: 1.411686901123293

Epoch: 667| Step: 0
Training loss: 0.03190000355243683
Validation loss: 1.438638162869279

Epoch: 6| Step: 1
Training loss: 0.061901114881038666
Validation loss: 1.4515846775424095

Epoch: 6| Step: 2
Training loss: 0.044498510658741
Validation loss: 1.4046851191469418

Epoch: 6| Step: 3
Training loss: 0.06678218394517899
Validation loss: 1.4315795526709607

Epoch: 6| Step: 4
Training loss: 0.0616053007543087
Validation loss: 1.4225716795972598

Epoch: 6| Step: 5
Training loss: 0.06679051369428635
Validation loss: 1.4692776997884114

Epoch: 6| Step: 6
Training loss: 0.07305452972650528
Validation loss: 1.4742982054269442

Epoch: 6| Step: 7
Training loss: 0.05425731837749481
Validation loss: 1.4468499595119106

Epoch: 6| Step: 8
Training loss: 0.047022052109241486
Validation loss: 1.4607100089391072

Epoch: 6| Step: 9
Training loss: 0.07614593207836151
Validation loss: 1.4566354751586914

Epoch: 6| Step: 10
Training loss: 0.04655842483043671
Validation loss: 1.4541969081406951

Epoch: 6| Step: 11
Training loss: 0.10580924898386002
Validation loss: 1.4686325275769798

Epoch: 6| Step: 12
Training loss: 0.05438080430030823
Validation loss: 1.4413012791705389

Epoch: 6| Step: 13
Training loss: 0.05723055079579353
Validation loss: 1.4669168123634913

Epoch: 668| Step: 0
Training loss: 0.05384310707449913
Validation loss: 1.4749739458484035

Epoch: 6| Step: 1
Training loss: 0.056397538632154465
Validation loss: 1.4738164742787678

Epoch: 6| Step: 2
Training loss: 0.0406942144036293
Validation loss: 1.460386537736462

Epoch: 6| Step: 3
Training loss: 0.05323256552219391
Validation loss: 1.446399281101842

Epoch: 6| Step: 4
Training loss: 0.07402106374502182
Validation loss: 1.464532584272405

Epoch: 6| Step: 5
Training loss: 0.06539737433195114
Validation loss: 1.451502251368697

Epoch: 6| Step: 6
Training loss: 0.09836799651384354
Validation loss: 1.424403840495694

Epoch: 6| Step: 7
Training loss: 0.04949282482266426
Validation loss: 1.4336826955118487

Epoch: 6| Step: 8
Training loss: 0.050805967301130295
Validation loss: 1.403644766858829

Epoch: 6| Step: 9
Training loss: 0.04249092563986778
Validation loss: 1.4387217003812072

Epoch: 6| Step: 10
Training loss: 0.061692483723163605
Validation loss: 1.4338251211309945

Epoch: 6| Step: 11
Training loss: 0.03214380145072937
Validation loss: 1.4013719058805896

Epoch: 6| Step: 12
Training loss: 0.04020807892084122
Validation loss: 1.4213045374039681

Epoch: 6| Step: 13
Training loss: 0.05077936872839928
Validation loss: 1.4126950694668678

Epoch: 669| Step: 0
Training loss: 0.06644836068153381
Validation loss: 1.4095097273908637

Epoch: 6| Step: 1
Training loss: 0.06890733540058136
Validation loss: 1.3756931686914096

Epoch: 6| Step: 2
Training loss: 0.04924451559782028
Validation loss: 1.407537648754735

Epoch: 6| Step: 3
Training loss: 0.09904500842094421
Validation loss: 1.388953428114614

Epoch: 6| Step: 4
Training loss: 0.05186872184276581
Validation loss: 1.3998649556149718

Epoch: 6| Step: 5
Training loss: 0.05782224237918854
Validation loss: 1.4289702138593119

Epoch: 6| Step: 6
Training loss: 0.09528516232967377
Validation loss: 1.4089130419556812

Epoch: 6| Step: 7
Training loss: 0.07935036718845367
Validation loss: 1.43207977151358

Epoch: 6| Step: 8
Training loss: 0.054234445095062256
Validation loss: 1.4262974252623897

Epoch: 6| Step: 9
Training loss: 0.05198463052511215
Validation loss: 1.4333684957155617

Epoch: 6| Step: 10
Training loss: 0.046279579401016235
Validation loss: 1.4484318956252067

Epoch: 6| Step: 11
Training loss: 0.043896645307540894
Validation loss: 1.44340391056512

Epoch: 6| Step: 12
Training loss: 0.04169231280684471
Validation loss: 1.4279862219287502

Epoch: 6| Step: 13
Training loss: 0.07279299199581146
Validation loss: 1.450205538862495

Epoch: 670| Step: 0
Training loss: 0.09564262628555298
Validation loss: 1.4171509947828067

Epoch: 6| Step: 1
Training loss: 0.0519518181681633
Validation loss: 1.420142767249897

Epoch: 6| Step: 2
Training loss: 0.11085880547761917
Validation loss: 1.4201205674038138

Epoch: 6| Step: 3
Training loss: 0.06643106788396835
Validation loss: 1.4158213151398527

Epoch: 6| Step: 4
Training loss: 0.10356318205595016
Validation loss: 1.4118728496695077

Epoch: 6| Step: 5
Training loss: 0.06956895440816879
Validation loss: 1.410454914134036

Epoch: 6| Step: 6
Training loss: 0.03939272463321686
Validation loss: 1.4238046138517317

Epoch: 6| Step: 7
Training loss: 0.06537001579999924
Validation loss: 1.408772555730676

Epoch: 6| Step: 8
Training loss: 0.05887439474463463
Validation loss: 1.4268967361860379

Epoch: 6| Step: 9
Training loss: 0.053632110357284546
Validation loss: 1.4274848558569466

Epoch: 6| Step: 10
Training loss: 0.05500173568725586
Validation loss: 1.443299598591302

Epoch: 6| Step: 11
Training loss: 0.06529748439788818
Validation loss: 1.420609635691489

Epoch: 6| Step: 12
Training loss: 0.06973166763782501
Validation loss: 1.4136713127936087

Epoch: 6| Step: 13
Training loss: 0.07339426875114441
Validation loss: 1.422553180366434

Epoch: 671| Step: 0
Training loss: 0.07429336756467819
Validation loss: 1.415663069294345

Epoch: 6| Step: 1
Training loss: 0.048141177743673325
Validation loss: 1.3958930039918551

Epoch: 6| Step: 2
Training loss: 0.06975194811820984
Validation loss: 1.4012700697427154

Epoch: 6| Step: 3
Training loss: 0.0732751190662384
Validation loss: 1.4168606137716642

Epoch: 6| Step: 4
Training loss: 0.09320574998855591
Validation loss: 1.418708816651375

Epoch: 6| Step: 5
Training loss: 0.09030188620090485
Validation loss: 1.4404850275285783

Epoch: 6| Step: 6
Training loss: 0.09295278787612915
Validation loss: 1.444229115722

Epoch: 6| Step: 7
Training loss: 0.039522215723991394
Validation loss: 1.4399850124953895

Epoch: 6| Step: 8
Training loss: 0.09384509921073914
Validation loss: 1.429690432804887

Epoch: 6| Step: 9
Training loss: 0.07336428016424179
Validation loss: 1.420325183099316

Epoch: 6| Step: 10
Training loss: 0.09128227829933167
Validation loss: 1.4382399192420385

Epoch: 6| Step: 11
Training loss: 0.04412836581468582
Validation loss: 1.454801522275453

Epoch: 6| Step: 12
Training loss: 0.10731854289770126
Validation loss: 1.464915612692474

Epoch: 6| Step: 13
Training loss: 0.06809689104557037
Validation loss: 1.4758059600348115

Epoch: 672| Step: 0
Training loss: 0.1474657952785492
Validation loss: 1.4715449290890847

Epoch: 6| Step: 1
Training loss: 0.08152597397565842
Validation loss: 1.4734073351788264

Epoch: 6| Step: 2
Training loss: 0.07830886542797089
Validation loss: 1.4188741586541618

Epoch: 6| Step: 3
Training loss: 0.08135545253753662
Validation loss: 1.4217865197889266

Epoch: 6| Step: 4
Training loss: 0.09507922828197479
Validation loss: 1.4752547523026824

Epoch: 6| Step: 5
Training loss: 0.08029747009277344
Validation loss: 1.4683230743613294

Epoch: 6| Step: 6
Training loss: 0.05278434604406357
Validation loss: 1.4306527876084851

Epoch: 6| Step: 7
Training loss: 0.1266239583492279
Validation loss: 1.4286398272360525

Epoch: 6| Step: 8
Training loss: 0.047930337488651276
Validation loss: 1.4320893287658691

Epoch: 6| Step: 9
Training loss: 0.07576465606689453
Validation loss: 1.4224600727840135

Epoch: 6| Step: 10
Training loss: 0.07376692444086075
Validation loss: 1.449724692170338

Epoch: 6| Step: 11
Training loss: 0.054218269884586334
Validation loss: 1.3990254318842323

Epoch: 6| Step: 12
Training loss: 0.04741393029689789
Validation loss: 1.4066791303696171

Epoch: 6| Step: 13
Training loss: 0.10898637771606445
Validation loss: 1.4189528431943668

Epoch: 673| Step: 0
Training loss: 0.07371857762336731
Validation loss: 1.3994238376617432

Epoch: 6| Step: 1
Training loss: 0.06317667663097382
Validation loss: 1.4028723098898446

Epoch: 6| Step: 2
Training loss: 0.04163431003689766
Validation loss: 1.4024837709242297

Epoch: 6| Step: 3
Training loss: 0.05831816792488098
Validation loss: 1.4126737668950071

Epoch: 6| Step: 4
Training loss: 0.08881008625030518
Validation loss: 1.4102635191332908

Epoch: 6| Step: 5
Training loss: 0.06417284905910492
Validation loss: 1.4238828023274739

Epoch: 6| Step: 6
Training loss: 0.08988992869853973
Validation loss: 1.4004224705439743

Epoch: 6| Step: 7
Training loss: 0.08477210998535156
Validation loss: 1.4247815109068347

Epoch: 6| Step: 8
Training loss: 0.06638304144144058
Validation loss: 1.4526766692438433

Epoch: 6| Step: 9
Training loss: 0.05521933361887932
Validation loss: 1.4318889879411267

Epoch: 6| Step: 10
Training loss: 0.04140754044055939
Validation loss: 1.445737854126961

Epoch: 6| Step: 11
Training loss: 0.08145761489868164
Validation loss: 1.4654377493807065

Epoch: 6| Step: 12
Training loss: 0.06345587968826294
Validation loss: 1.4602266434700257

Epoch: 6| Step: 13
Training loss: 0.04178249090909958
Validation loss: 1.4398595850954774

Epoch: 674| Step: 0
Training loss: 0.026889298111200333
Validation loss: 1.4552984186398086

Epoch: 6| Step: 1
Training loss: 0.051308631896972656
Validation loss: 1.4678364851141488

Epoch: 6| Step: 2
Training loss: 0.0418568029999733
Validation loss: 1.4427206311174618

Epoch: 6| Step: 3
Training loss: 0.08372130990028381
Validation loss: 1.4552499126362544

Epoch: 6| Step: 4
Training loss: 0.053232934325933456
Validation loss: 1.459890446355266

Epoch: 6| Step: 5
Training loss: 0.0874970555305481
Validation loss: 1.4480822381152902

Epoch: 6| Step: 6
Training loss: 0.0384855717420578
Validation loss: 1.4296835212297336

Epoch: 6| Step: 7
Training loss: 0.04636222869157791
Validation loss: 1.4224075604510564

Epoch: 6| Step: 8
Training loss: 0.057366807013750076
Validation loss: 1.4411052196256575

Epoch: 6| Step: 9
Training loss: 0.028216522186994553
Validation loss: 1.4626191482749036

Epoch: 6| Step: 10
Training loss: 0.09438303112983704
Validation loss: 1.414219610152706

Epoch: 6| Step: 11
Training loss: 0.0752420425415039
Validation loss: 1.4245183967774915

Epoch: 6| Step: 12
Training loss: 0.06165779381990433
Validation loss: 1.421502540188451

Epoch: 6| Step: 13
Training loss: 0.06461319327354431
Validation loss: 1.4301219050602247

Epoch: 675| Step: 0
Training loss: 0.07162506878376007
Validation loss: 1.4216358847515558

Epoch: 6| Step: 1
Training loss: 0.08632989227771759
Validation loss: 1.4296841147125408

Epoch: 6| Step: 2
Training loss: 0.07450797408819199
Validation loss: 1.408713815032795

Epoch: 6| Step: 3
Training loss: 0.045276857912540436
Validation loss: 1.4082584816922423

Epoch: 6| Step: 4
Training loss: 0.07640564441680908
Validation loss: 1.4041039213057487

Epoch: 6| Step: 5
Training loss: 0.03784008324146271
Validation loss: 1.434836459416215

Epoch: 6| Step: 6
Training loss: 0.03590948507189751
Validation loss: 1.437949626676498

Epoch: 6| Step: 7
Training loss: 0.04730885103344917
Validation loss: 1.4318408402063514

Epoch: 6| Step: 8
Training loss: 0.06365377455949783
Validation loss: 1.4353074591646913

Epoch: 6| Step: 9
Training loss: 0.07203089445829391
Validation loss: 1.4494735060199615

Epoch: 6| Step: 10
Training loss: 0.061662957072257996
Validation loss: 1.433907190958659

Epoch: 6| Step: 11
Training loss: 0.04540140926837921
Validation loss: 1.430625512394854

Epoch: 6| Step: 12
Training loss: 0.029663074761629105
Validation loss: 1.4349505478335964

Epoch: 6| Step: 13
Training loss: 0.09027164429426193
Validation loss: 1.4158092967925533

Epoch: 676| Step: 0
Training loss: 0.03611353784799576
Validation loss: 1.4086521697300736

Epoch: 6| Step: 1
Training loss: 0.04365648329257965
Validation loss: 1.4131620391722648

Epoch: 6| Step: 2
Training loss: 0.09369170665740967
Validation loss: 1.3969445741304787

Epoch: 6| Step: 3
Training loss: 0.07458171993494034
Validation loss: 1.4207924706961519

Epoch: 6| Step: 4
Training loss: 0.06823288649320602
Validation loss: 1.4186479327499226

Epoch: 6| Step: 5
Training loss: 0.05904959887266159
Validation loss: 1.4127993455497168

Epoch: 6| Step: 6
Training loss: 0.049041517078876495
Validation loss: 1.4323087308996467

Epoch: 6| Step: 7
Training loss: 0.06834772229194641
Validation loss: 1.4031724070989957

Epoch: 6| Step: 8
Training loss: 0.09054949134588242
Validation loss: 1.4217004596546132

Epoch: 6| Step: 9
Training loss: 0.09954442083835602
Validation loss: 1.444359826785262

Epoch: 6| Step: 10
Training loss: 0.044680919498205185
Validation loss: 1.426670329545134

Epoch: 6| Step: 11
Training loss: 0.07879196852445602
Validation loss: 1.4114689826965332

Epoch: 6| Step: 12
Training loss: 0.07188312709331512
Validation loss: 1.436759776966546

Epoch: 6| Step: 13
Training loss: 0.10636512190103531
Validation loss: 1.4107931262703353

Epoch: 677| Step: 0
Training loss: 0.025519007816910744
Validation loss: 1.4120264694254885

Epoch: 6| Step: 1
Training loss: 0.10812193900346756
Validation loss: 1.40437090012335

Epoch: 6| Step: 2
Training loss: 0.05253958702087402
Validation loss: 1.408107014112575

Epoch: 6| Step: 3
Training loss: 0.08828069269657135
Validation loss: 1.3831170944757358

Epoch: 6| Step: 4
Training loss: 0.04675517976284027
Validation loss: 1.4025844630374704

Epoch: 6| Step: 5
Training loss: 0.0598975233733654
Validation loss: 1.3995784636466735

Epoch: 6| Step: 6
Training loss: 0.08354542404413223
Validation loss: 1.415865300804056

Epoch: 6| Step: 7
Training loss: 0.055068790912628174
Validation loss: 1.4401259204392791

Epoch: 6| Step: 8
Training loss: 0.05710624158382416
Validation loss: 1.436907495221784

Epoch: 6| Step: 9
Training loss: 0.11238444596529007
Validation loss: 1.4798238943981867

Epoch: 6| Step: 10
Training loss: 0.03893037140369415
Validation loss: 1.4258949827122431

Epoch: 6| Step: 11
Training loss: 0.07963616400957108
Validation loss: 1.451140264029144

Epoch: 6| Step: 12
Training loss: 0.05494806170463562
Validation loss: 1.41581589944901

Epoch: 6| Step: 13
Training loss: 0.08666105568408966
Validation loss: 1.4205296026763095

Epoch: 678| Step: 0
Training loss: 0.05184026062488556
Validation loss: 1.4267918986658896

Epoch: 6| Step: 1
Training loss: 0.07873444259166718
Validation loss: 1.4181080505412111

Epoch: 6| Step: 2
Training loss: 0.06488997489213943
Validation loss: 1.4203577349262853

Epoch: 6| Step: 3
Training loss: 0.06073863431811333
Validation loss: 1.4203058327397993

Epoch: 6| Step: 4
Training loss: 0.05256607383489609
Validation loss: 1.4403263215095765

Epoch: 6| Step: 5
Training loss: 0.06919624656438828
Validation loss: 1.427553419143923

Epoch: 6| Step: 6
Training loss: 0.06976334005594254
Validation loss: 1.471194161522773

Epoch: 6| Step: 7
Training loss: 0.11060786992311478
Validation loss: 1.4255634764189362

Epoch: 6| Step: 8
Training loss: 0.0582955963909626
Validation loss: 1.449381107925087

Epoch: 6| Step: 9
Training loss: 0.041422583162784576
Validation loss: 1.429136400581688

Epoch: 6| Step: 10
Training loss: 0.050471484661102295
Validation loss: 1.449296130928942

Epoch: 6| Step: 11
Training loss: 0.03195006027817726
Validation loss: 1.3937951377643052

Epoch: 6| Step: 12
Training loss: 0.04471784085035324
Validation loss: 1.4281419925792243

Epoch: 6| Step: 13
Training loss: 0.06009916588664055
Validation loss: 1.4087502520571473

Epoch: 679| Step: 0
Training loss: 0.0405363067984581
Validation loss: 1.4331304655280164

Epoch: 6| Step: 1
Training loss: 0.07145391404628754
Validation loss: 1.4267407553170317

Epoch: 6| Step: 2
Training loss: 0.07349743694067001
Validation loss: 1.4025394288442468

Epoch: 6| Step: 3
Training loss: 0.058964166790246964
Validation loss: 1.3943396588807464

Epoch: 6| Step: 4
Training loss: 0.04760891944169998
Validation loss: 1.4305258284332931

Epoch: 6| Step: 5
Training loss: 0.07598093897104263
Validation loss: 1.4228609915702575

Epoch: 6| Step: 6
Training loss: 0.047092728316783905
Validation loss: 1.4250384575577193

Epoch: 6| Step: 7
Training loss: 0.034591808915138245
Validation loss: 1.4271642674681961

Epoch: 6| Step: 8
Training loss: 0.04976474121212959
Validation loss: 1.4452464695899718

Epoch: 6| Step: 9
Training loss: 0.06937666982412338
Validation loss: 1.433755059396067

Epoch: 6| Step: 10
Training loss: 0.0700402781367302
Validation loss: 1.4539904517512168

Epoch: 6| Step: 11
Training loss: 0.06574386358261108
Validation loss: 1.4543285190418203

Epoch: 6| Step: 12
Training loss: 0.08059114217758179
Validation loss: 1.4181591297990532

Epoch: 6| Step: 13
Training loss: 0.08040007948875427
Validation loss: 1.3921971551833614

Epoch: 680| Step: 0
Training loss: 0.036053240299224854
Validation loss: 1.3905779892398464

Epoch: 6| Step: 1
Training loss: 0.09556812047958374
Validation loss: 1.3919004547980525

Epoch: 6| Step: 2
Training loss: 0.058515459299087524
Validation loss: 1.3860386892031598

Epoch: 6| Step: 3
Training loss: 0.07569162547588348
Validation loss: 1.3648101937386297

Epoch: 6| Step: 4
Training loss: 0.06250445544719696
Validation loss: 1.3490954406799809

Epoch: 6| Step: 5
Training loss: 0.06233959272503853
Validation loss: 1.3669680574888825

Epoch: 6| Step: 6
Training loss: 0.051811542361974716
Validation loss: 1.3738171426198815

Epoch: 6| Step: 7
Training loss: 0.05400963872671127
Validation loss: 1.3965824124633626

Epoch: 6| Step: 8
Training loss: 0.10020415484905243
Validation loss: 1.379773630890795

Epoch: 6| Step: 9
Training loss: 0.07994867116212845
Validation loss: 1.4157808942179526

Epoch: 6| Step: 10
Training loss: 0.08355674892663956
Validation loss: 1.4530966019117704

Epoch: 6| Step: 11
Training loss: 0.1068895012140274
Validation loss: 1.4446394699876026

Epoch: 6| Step: 12
Training loss: 0.07646684348583221
Validation loss: 1.4565566086000012

Epoch: 6| Step: 13
Training loss: 0.08186677098274231
Validation loss: 1.4311413662407988

Epoch: 681| Step: 0
Training loss: 0.03973790258169174
Validation loss: 1.4039450217318792

Epoch: 6| Step: 1
Training loss: 0.044865090399980545
Validation loss: 1.4128397292988275

Epoch: 6| Step: 2
Training loss: 0.11462707072496414
Validation loss: 1.4198429584503174

Epoch: 6| Step: 3
Training loss: 0.07963024824857712
Validation loss: 1.4502023971208962

Epoch: 6| Step: 4
Training loss: 0.19932526350021362
Validation loss: 1.4396199923689648

Epoch: 6| Step: 5
Training loss: 0.04867462068796158
Validation loss: 1.4292247295379639

Epoch: 6| Step: 6
Training loss: 0.13334974646568298
Validation loss: 1.440773102544969

Epoch: 6| Step: 7
Training loss: 0.06929314136505127
Validation loss: 1.4471240928096156

Epoch: 6| Step: 8
Training loss: 0.07676641643047333
Validation loss: 1.4682706376557708

Epoch: 6| Step: 9
Training loss: 0.07530605792999268
Validation loss: 1.4752231785046157

Epoch: 6| Step: 10
Training loss: 0.07835578918457031
Validation loss: 1.5030705198164909

Epoch: 6| Step: 11
Training loss: 0.1170569509267807
Validation loss: 1.4932356899784458

Epoch: 6| Step: 12
Training loss: 0.0660732090473175
Validation loss: 1.4572172626372306

Epoch: 6| Step: 13
Training loss: 0.1023971289396286
Validation loss: 1.4157140767702492

Epoch: 682| Step: 0
Training loss: 0.07327120006084442
Validation loss: 1.3953584163419661

Epoch: 6| Step: 1
Training loss: 0.11110055446624756
Validation loss: 1.42644210784666

Epoch: 6| Step: 2
Training loss: 0.08860933035612106
Validation loss: 1.3860258030635055

Epoch: 6| Step: 3
Training loss: 0.04643569141626358
Validation loss: 1.4008620656946653

Epoch: 6| Step: 4
Training loss: 0.08844384551048279
Validation loss: 1.3946647272315076

Epoch: 6| Step: 5
Training loss: 0.09877084195613861
Validation loss: 1.385733639040301

Epoch: 6| Step: 6
Training loss: 0.0594194233417511
Validation loss: 1.383495452583477

Epoch: 6| Step: 7
Training loss: 0.07217250764369965
Validation loss: 1.4050097132241854

Epoch: 6| Step: 8
Training loss: 0.052817776799201965
Validation loss: 1.4102238673035816

Epoch: 6| Step: 9
Training loss: 0.04744815081357956
Validation loss: 1.4539931743375716

Epoch: 6| Step: 10
Training loss: 0.05520929768681526
Validation loss: 1.4525468875003118

Epoch: 6| Step: 11
Training loss: 0.06322211027145386
Validation loss: 1.478720893142044

Epoch: 6| Step: 12
Training loss: 0.12917232513427734
Validation loss: 1.491979032434443

Epoch: 6| Step: 13
Training loss: 0.05370352789759636
Validation loss: 1.4710545321946502

Epoch: 683| Step: 0
Training loss: 0.058292750269174576
Validation loss: 1.4733145397196534

Epoch: 6| Step: 1
Training loss: 0.1305980682373047
Validation loss: 1.4129639415330784

Epoch: 6| Step: 2
Training loss: 0.056734971702098846
Validation loss: 1.4215184155330862

Epoch: 6| Step: 3
Training loss: 0.05557665228843689
Validation loss: 1.4350453487006567

Epoch: 6| Step: 4
Training loss: 0.0740785002708435
Validation loss: 1.4330231912674443

Epoch: 6| Step: 5
Training loss: 0.07338106632232666
Validation loss: 1.3936922652747041

Epoch: 6| Step: 6
Training loss: 0.07490141689777374
Validation loss: 1.3908733706320486

Epoch: 6| Step: 7
Training loss: 0.061415668576955795
Validation loss: 1.413856444820281

Epoch: 6| Step: 8
Training loss: 0.08394479751586914
Validation loss: 1.4049595094496203

Epoch: 6| Step: 9
Training loss: 0.04577001929283142
Validation loss: 1.4039831481954104

Epoch: 6| Step: 10
Training loss: 0.06571175158023834
Validation loss: 1.4396295880758634

Epoch: 6| Step: 11
Training loss: 0.046283937990665436
Validation loss: 1.4592919695761897

Epoch: 6| Step: 12
Training loss: 0.10819432139396667
Validation loss: 1.4648138182137602

Epoch: 6| Step: 13
Training loss: 0.06589621305465698
Validation loss: 1.4751827357917704

Epoch: 684| Step: 0
Training loss: 0.0769534558057785
Validation loss: 1.4940699774731871

Epoch: 6| Step: 1
Training loss: 0.10751214623451233
Validation loss: 1.497830048684151

Epoch: 6| Step: 2
Training loss: 0.056766577064991
Validation loss: 1.4724611415657947

Epoch: 6| Step: 3
Training loss: 0.03651539236307144
Validation loss: 1.4807459506937253

Epoch: 6| Step: 4
Training loss: 0.049546826630830765
Validation loss: 1.4629941409634006

Epoch: 6| Step: 5
Training loss: 0.05616692453622818
Validation loss: 1.4693305697492374

Epoch: 6| Step: 6
Training loss: 0.06619083136320114
Validation loss: 1.4652655284891847

Epoch: 6| Step: 7
Training loss: 0.06309211254119873
Validation loss: 1.4763547079537505

Epoch: 6| Step: 8
Training loss: 0.07925684750080109
Validation loss: 1.4625424556834723

Epoch: 6| Step: 9
Training loss: 0.09361246228218079
Validation loss: 1.468212514795283

Epoch: 6| Step: 10
Training loss: 0.07147621363401413
Validation loss: 1.4747264949224328

Epoch: 6| Step: 11
Training loss: 0.06400640308856964
Validation loss: 1.461935773972542

Epoch: 6| Step: 12
Training loss: 0.07180766016244888
Validation loss: 1.461370510439719

Epoch: 6| Step: 13
Training loss: 0.0813056081533432
Validation loss: 1.4608494357396198

Epoch: 685| Step: 0
Training loss: 0.07791103422641754
Validation loss: 1.4409431719010877

Epoch: 6| Step: 1
Training loss: 0.07207596302032471
Validation loss: 1.438331824477001

Epoch: 6| Step: 2
Training loss: 0.06939402967691422
Validation loss: 1.431508300124958

Epoch: 6| Step: 3
Training loss: 0.041172124445438385
Validation loss: 1.4348859030713317

Epoch: 6| Step: 4
Training loss: 0.05089360848069191
Validation loss: 1.453499553024128

Epoch: 6| Step: 5
Training loss: 0.054185397922992706
Validation loss: 1.477147643284131

Epoch: 6| Step: 6
Training loss: 0.06337869167327881
Validation loss: 1.475125592242005

Epoch: 6| Step: 7
Training loss: 0.04960261285305023
Validation loss: 1.4763849114858976

Epoch: 6| Step: 8
Training loss: 0.06715036183595657
Validation loss: 1.4971774060239074

Epoch: 6| Step: 9
Training loss: 0.07339644432067871
Validation loss: 1.5174645928926365

Epoch: 6| Step: 10
Training loss: 0.07453064620494843
Validation loss: 1.4991129752128356

Epoch: 6| Step: 11
Training loss: 0.11692073941230774
Validation loss: 1.4688671673497846

Epoch: 6| Step: 12
Training loss: 0.05140899121761322
Validation loss: 1.4770098245272072

Epoch: 6| Step: 13
Training loss: 0.04925115779042244
Validation loss: 1.4465481068498345

Epoch: 686| Step: 0
Training loss: 0.039293959736824036
Validation loss: 1.446437890811633

Epoch: 6| Step: 1
Training loss: 0.0429866723716259
Validation loss: 1.4549046947110085

Epoch: 6| Step: 2
Training loss: 0.08754144608974457
Validation loss: 1.445830725854443

Epoch: 6| Step: 3
Training loss: 0.06220371276140213
Validation loss: 1.460865177134032

Epoch: 6| Step: 4
Training loss: 0.03320487588644028
Validation loss: 1.4545122449116041

Epoch: 6| Step: 5
Training loss: 0.04797927290201187
Validation loss: 1.4550468870388564

Epoch: 6| Step: 6
Training loss: 0.03566906601190567
Validation loss: 1.4376418282908778

Epoch: 6| Step: 7
Training loss: 0.06319242715835571
Validation loss: 1.4575237984298377

Epoch: 6| Step: 8
Training loss: 0.10204202681779861
Validation loss: 1.4429238214287707

Epoch: 6| Step: 9
Training loss: 0.06746140122413635
Validation loss: 1.420970533483772

Epoch: 6| Step: 10
Training loss: 0.08817210793495178
Validation loss: 1.4276970830014957

Epoch: 6| Step: 11
Training loss: 0.09119980037212372
Validation loss: 1.4219992462024893

Epoch: 6| Step: 12
Training loss: 0.1262666881084442
Validation loss: 1.4053925782121637

Epoch: 6| Step: 13
Training loss: 0.0708889439702034
Validation loss: 1.4182249256359634

Epoch: 687| Step: 0
Training loss: 0.05965866893529892
Validation loss: 1.3915203258555422

Epoch: 6| Step: 1
Training loss: 0.0645357221364975
Validation loss: 1.4323696269783923

Epoch: 6| Step: 2
Training loss: 0.06023205444216728
Validation loss: 1.427976110930084

Epoch: 6| Step: 3
Training loss: 0.0751417726278305
Validation loss: 1.429609284606031

Epoch: 6| Step: 4
Training loss: 0.07364290952682495
Validation loss: 1.4319497205877816

Epoch: 6| Step: 5
Training loss: 0.09751300513744354
Validation loss: 1.4571638825119182

Epoch: 6| Step: 6
Training loss: 0.04578113555908203
Validation loss: 1.4795137284904398

Epoch: 6| Step: 7
Training loss: 0.04079414904117584
Validation loss: 1.4927414296775736

Epoch: 6| Step: 8
Training loss: 0.06077171489596367
Validation loss: 1.4909861792800247

Epoch: 6| Step: 9
Training loss: 0.09259001910686493
Validation loss: 1.487350510012719

Epoch: 6| Step: 10
Training loss: 0.08293680846691132
Validation loss: 1.495860384356591

Epoch: 6| Step: 11
Training loss: 0.03848543390631676
Validation loss: 1.4572544033809374

Epoch: 6| Step: 12
Training loss: 0.07587064057588577
Validation loss: 1.435059940943154

Epoch: 6| Step: 13
Training loss: 0.10610813647508621
Validation loss: 1.4444574566297634

Epoch: 688| Step: 0
Training loss: 0.0979977399110794
Validation loss: 1.4110127059362267

Epoch: 6| Step: 1
Training loss: 0.0675116553902626
Validation loss: 1.403373424724866

Epoch: 6| Step: 2
Training loss: 0.08746512234210968
Validation loss: 1.3949073258266653

Epoch: 6| Step: 3
Training loss: 0.06685839593410492
Validation loss: 1.3955222932241296

Epoch: 6| Step: 4
Training loss: 0.07575635612010956
Validation loss: 1.4116601277423162

Epoch: 6| Step: 5
Training loss: 0.09281547367572784
Validation loss: 1.4103054872123144

Epoch: 6| Step: 6
Training loss: 0.0621693879365921
Validation loss: 1.3789650535070768

Epoch: 6| Step: 7
Training loss: 0.0840524435043335
Validation loss: 1.3785608186516711

Epoch: 6| Step: 8
Training loss: 0.05416206270456314
Validation loss: 1.4284482015076505

Epoch: 6| Step: 9
Training loss: 0.04043254628777504
Validation loss: 1.4167013117062148

Epoch: 6| Step: 10
Training loss: 0.07565028220415115
Validation loss: 1.4166285530213387

Epoch: 6| Step: 11
Training loss: 0.07311572134494781
Validation loss: 1.4288288277964438

Epoch: 6| Step: 12
Training loss: 0.08473028987646103
Validation loss: 1.4483795794107581

Epoch: 6| Step: 13
Training loss: 0.03943302854895592
Validation loss: 1.418781098499093

Epoch: 689| Step: 0
Training loss: 0.09645923972129822
Validation loss: 1.4181678192589873

Epoch: 6| Step: 1
Training loss: 0.05024141073226929
Validation loss: 1.387605236422631

Epoch: 6| Step: 2
Training loss: 0.08544383943080902
Validation loss: 1.3813438594982188

Epoch: 6| Step: 3
Training loss: 0.08813519775867462
Validation loss: 1.3926759048174786

Epoch: 6| Step: 4
Training loss: 0.08314632624387741
Validation loss: 1.3893874255559777

Epoch: 6| Step: 5
Training loss: 0.04846309870481491
Validation loss: 1.4071217749708442

Epoch: 6| Step: 6
Training loss: 0.08851666748523712
Validation loss: 1.4063056002381027

Epoch: 6| Step: 7
Training loss: 0.05746573954820633
Validation loss: 1.4288333180130168

Epoch: 6| Step: 8
Training loss: 0.08548816293478012
Validation loss: 1.4237473216108096

Epoch: 6| Step: 9
Training loss: 0.06249881163239479
Validation loss: 1.4244056658078266

Epoch: 6| Step: 10
Training loss: 0.061806514859199524
Validation loss: 1.450629142022902

Epoch: 6| Step: 11
Training loss: 0.10085178911685944
Validation loss: 1.4598295560447119

Epoch: 6| Step: 12
Training loss: 0.11638949066400528
Validation loss: 1.441655626860998

Epoch: 6| Step: 13
Training loss: 0.03836928308010101
Validation loss: 1.418844114067734

Epoch: 690| Step: 0
Training loss: 0.07520310580730438
Validation loss: 1.4218115216942244

Epoch: 6| Step: 1
Training loss: 0.07620283961296082
Validation loss: 1.430448667977446

Epoch: 6| Step: 2
Training loss: 0.06963901221752167
Validation loss: 1.4416659467963762

Epoch: 6| Step: 3
Training loss: 0.09277476370334625
Validation loss: 1.428543895803472

Epoch: 6| Step: 4
Training loss: 0.0963096022605896
Validation loss: 1.430373821207272

Epoch: 6| Step: 5
Training loss: 0.08900772780179977
Validation loss: 1.413188096015684

Epoch: 6| Step: 6
Training loss: 0.06442460417747498
Validation loss: 1.4308693139783797

Epoch: 6| Step: 7
Training loss: 0.06964205205440521
Validation loss: 1.429730349971402

Epoch: 6| Step: 8
Training loss: 0.056653425097465515
Validation loss: 1.4500808690183906

Epoch: 6| Step: 9
Training loss: 0.04939911514520645
Validation loss: 1.4745012842198855

Epoch: 6| Step: 10
Training loss: 0.058251455426216125
Validation loss: 1.4776532393629833

Epoch: 6| Step: 11
Training loss: 0.14468900859355927
Validation loss: 1.4857049513888616

Epoch: 6| Step: 12
Training loss: 0.07124226540327072
Validation loss: 1.525277155701832

Epoch: 6| Step: 13
Training loss: 0.05899816006422043
Validation loss: 1.4871764362499278

Epoch: 691| Step: 0
Training loss: 0.07972357422113419
Validation loss: 1.4452817414396553

Epoch: 6| Step: 1
Training loss: 0.07159184664487839
Validation loss: 1.4302686068319506

Epoch: 6| Step: 2
Training loss: 0.07772901654243469
Validation loss: 1.426243346224549

Epoch: 6| Step: 3
Training loss: 0.06525204330682755
Validation loss: 1.411192024266848

Epoch: 6| Step: 4
Training loss: 0.07006308436393738
Validation loss: 1.4090819205007246

Epoch: 6| Step: 5
Training loss: 0.07861688733100891
Validation loss: 1.4208667214198778

Epoch: 6| Step: 6
Training loss: 0.15515847504138947
Validation loss: 1.4425309153013333

Epoch: 6| Step: 7
Training loss: 0.07243694365024567
Validation loss: 1.4521332992020475

Epoch: 6| Step: 8
Training loss: 0.08955658972263336
Validation loss: 1.4348642685080086

Epoch: 6| Step: 9
Training loss: 0.07367454469203949
Validation loss: 1.4564699460101385

Epoch: 6| Step: 10
Training loss: 0.09530080854892731
Validation loss: 1.449185840545162

Epoch: 6| Step: 11
Training loss: 0.08804705739021301
Validation loss: 1.4667086178256619

Epoch: 6| Step: 12
Training loss: 0.06970987468957901
Validation loss: 1.4713512345026898

Epoch: 6| Step: 13
Training loss: 0.10155531764030457
Validation loss: 1.4596588893603253

Epoch: 692| Step: 0
Training loss: 0.03853511065244675
Validation loss: 1.469302459429669

Epoch: 6| Step: 1
Training loss: 0.088174968957901
Validation loss: 1.4650899697375555

Epoch: 6| Step: 2
Training loss: 0.040659233927726746
Validation loss: 1.4522430717304189

Epoch: 6| Step: 3
Training loss: 0.09809563308954239
Validation loss: 1.4354790244051205

Epoch: 6| Step: 4
Training loss: 0.0884178951382637
Validation loss: 1.4444016487367692

Epoch: 6| Step: 5
Training loss: 0.046564001590013504
Validation loss: 1.421346051718599

Epoch: 6| Step: 6
Training loss: 0.11252056807279587
Validation loss: 1.429971533436929

Epoch: 6| Step: 7
Training loss: 0.06816995143890381
Validation loss: 1.444614621900743

Epoch: 6| Step: 8
Training loss: 0.03615641966462135
Validation loss: 1.426233337771508

Epoch: 6| Step: 9
Training loss: 0.06418463587760925
Validation loss: 1.4300490579297465

Epoch: 6| Step: 10
Training loss: 0.06169295310974121
Validation loss: 1.413193509142886

Epoch: 6| Step: 11
Training loss: 0.05150030180811882
Validation loss: 1.4214680412764191

Epoch: 6| Step: 12
Training loss: 0.08954960107803345
Validation loss: 1.4227588138272684

Epoch: 6| Step: 13
Training loss: 0.061573997139930725
Validation loss: 1.412423131286457

Epoch: 693| Step: 0
Training loss: 0.05552566051483154
Validation loss: 1.4559784089365313

Epoch: 6| Step: 1
Training loss: 0.06248001009225845
Validation loss: 1.3983207030962872

Epoch: 6| Step: 2
Training loss: 0.07439541816711426
Validation loss: 1.4116862256039855

Epoch: 6| Step: 3
Training loss: 0.06658174097537994
Validation loss: 1.4115627811801048

Epoch: 6| Step: 4
Training loss: 0.12310671806335449
Validation loss: 1.418913237510189

Epoch: 6| Step: 5
Training loss: 0.10099277645349503
Validation loss: 1.4372620851762834

Epoch: 6| Step: 6
Training loss: 0.06329753994941711
Validation loss: 1.4362694153221705

Epoch: 6| Step: 7
Training loss: 0.10034766048192978
Validation loss: 1.4608170306810768

Epoch: 6| Step: 8
Training loss: 0.05669335275888443
Validation loss: 1.4813701683475125

Epoch: 6| Step: 9
Training loss: 0.0785338506102562
Validation loss: 1.4818115324102423

Epoch: 6| Step: 10
Training loss: 0.07161407917737961
Validation loss: 1.4818810660351989

Epoch: 6| Step: 11
Training loss: 0.045120809227228165
Validation loss: 1.4779512420777352

Epoch: 6| Step: 12
Training loss: 0.03867274522781372
Validation loss: 1.4764365188537105

Epoch: 6| Step: 13
Training loss: 0.04562152922153473
Validation loss: 1.4544091839944162

Epoch: 694| Step: 0
Training loss: 0.059414319694042206
Validation loss: 1.4411049068615

Epoch: 6| Step: 1
Training loss: 0.10288824886083603
Validation loss: 1.4237610729791785

Epoch: 6| Step: 2
Training loss: 0.07072028517723083
Validation loss: 1.4051997982045656

Epoch: 6| Step: 3
Training loss: 0.058070965111255646
Validation loss: 1.4035267919622443

Epoch: 6| Step: 4
Training loss: 0.04669203609228134
Validation loss: 1.396654801983987

Epoch: 6| Step: 5
Training loss: 0.11073556542396545
Validation loss: 1.3955817427686465

Epoch: 6| Step: 6
Training loss: 0.07959061861038208
Validation loss: 1.3712903645730787

Epoch: 6| Step: 7
Training loss: 0.07034376263618469
Validation loss: 1.3656547697641517

Epoch: 6| Step: 8
Training loss: 0.05169828236103058
Validation loss: 1.378442851446008

Epoch: 6| Step: 9
Training loss: 0.04516257345676422
Validation loss: 1.4257964895617576

Epoch: 6| Step: 10
Training loss: 0.06510577350854874
Validation loss: 1.4212172858176693

Epoch: 6| Step: 11
Training loss: 0.15176352858543396
Validation loss: 1.4363187602771226

Epoch: 6| Step: 12
Training loss: 0.09592601656913757
Validation loss: 1.4714562751913582

Epoch: 6| Step: 13
Training loss: 0.0604938268661499
Validation loss: 1.456685399496427

Epoch: 695| Step: 0
Training loss: 0.13012149930000305
Validation loss: 1.4573845658251035

Epoch: 6| Step: 1
Training loss: 0.032741792500019073
Validation loss: 1.4458857249188166

Epoch: 6| Step: 2
Training loss: 0.05726717412471771
Validation loss: 1.4234854399517018

Epoch: 6| Step: 3
Training loss: 0.09300456941127777
Validation loss: 1.4045942509046165

Epoch: 6| Step: 4
Training loss: 0.08175896853208542
Validation loss: 1.4375048074671017

Epoch: 6| Step: 5
Training loss: 0.09486518800258636
Validation loss: 1.3954938560403802

Epoch: 6| Step: 6
Training loss: 0.11940018087625504
Validation loss: 1.395245651404063

Epoch: 6| Step: 7
Training loss: 0.09455865621566772
Validation loss: 1.4155991811265227

Epoch: 6| Step: 8
Training loss: 0.07519237697124481
Validation loss: 1.4082591546479093

Epoch: 6| Step: 9
Training loss: 0.07501231133937836
Validation loss: 1.416263077848701

Epoch: 6| Step: 10
Training loss: 0.07485125958919525
Validation loss: 1.4699398151008032

Epoch: 6| Step: 11
Training loss: 0.07708786427974701
Validation loss: 1.4774515577541885

Epoch: 6| Step: 12
Training loss: 0.08039012551307678
Validation loss: 1.4612160177641018

Epoch: 6| Step: 13
Training loss: 0.15211455523967743
Validation loss: 1.4918434530176141

Epoch: 696| Step: 0
Training loss: 0.07120300829410553
Validation loss: 1.4582588249637234

Epoch: 6| Step: 1
Training loss: 0.057015560567379
Validation loss: 1.476830784992505

Epoch: 6| Step: 2
Training loss: 0.0732877254486084
Validation loss: 1.4387300040132256

Epoch: 6| Step: 3
Training loss: 0.057621993124485016
Validation loss: 1.4220282845599677

Epoch: 6| Step: 4
Training loss: 0.08136215806007385
Validation loss: 1.4181906125878776

Epoch: 6| Step: 5
Training loss: 0.10107836127281189
Validation loss: 1.4412962031620804

Epoch: 6| Step: 6
Training loss: 0.1109161227941513
Validation loss: 1.4402636597233434

Epoch: 6| Step: 7
Training loss: 0.07494333386421204
Validation loss: 1.4233717380031463

Epoch: 6| Step: 8
Training loss: 0.11299426853656769
Validation loss: 1.4594514562237648

Epoch: 6| Step: 9
Training loss: 0.08583380281925201
Validation loss: 1.4325287931708879

Epoch: 6| Step: 10
Training loss: 0.07114525139331818
Validation loss: 1.4439050818002352

Epoch: 6| Step: 11
Training loss: 0.07989349216222763
Validation loss: 1.4369116239650275

Epoch: 6| Step: 12
Training loss: 0.10768765211105347
Validation loss: 1.441386708649256

Epoch: 6| Step: 13
Training loss: 0.0389360748231411
Validation loss: 1.4320186325298843

Epoch: 697| Step: 0
Training loss: 0.06332146376371384
Validation loss: 1.4196783163214242

Epoch: 6| Step: 1
Training loss: 0.04131177067756653
Validation loss: 1.4089316104048042

Epoch: 6| Step: 2
Training loss: 0.08004776388406754
Validation loss: 1.4043933037788636

Epoch: 6| Step: 3
Training loss: 0.10799703001976013
Validation loss: 1.4099692683066092

Epoch: 6| Step: 4
Training loss: 0.05279064178466797
Validation loss: 1.4213256733391875

Epoch: 6| Step: 5
Training loss: 0.05709775537252426
Validation loss: 1.4060571193695068

Epoch: 6| Step: 6
Training loss: 0.051492348313331604
Validation loss: 1.4190187056859334

Epoch: 6| Step: 7
Training loss: 0.04403073713183403
Validation loss: 1.4388928426209318

Epoch: 6| Step: 8
Training loss: 0.0721578299999237
Validation loss: 1.4313614624802784

Epoch: 6| Step: 9
Training loss: 0.043185681104660034
Validation loss: 1.4298425515492756

Epoch: 6| Step: 10
Training loss: 0.04487898200750351
Validation loss: 1.445843949112841

Epoch: 6| Step: 11
Training loss: 0.065215103328228
Validation loss: 1.4257673986496464

Epoch: 6| Step: 12
Training loss: 0.06703604757785797
Validation loss: 1.4468602800881991

Epoch: 6| Step: 13
Training loss: 0.057474032044410706
Validation loss: 1.4407533381574897

Epoch: 698| Step: 0
Training loss: 0.05724490433931351
Validation loss: 1.4649783142151371

Epoch: 6| Step: 1
Training loss: 0.04433169215917587
Validation loss: 1.4883604331683087

Epoch: 6| Step: 2
Training loss: 0.09991443157196045
Validation loss: 1.5215205466875465

Epoch: 6| Step: 3
Training loss: 0.1107388362288475
Validation loss: 1.4959717815922153

Epoch: 6| Step: 4
Training loss: 0.1010926216840744
Validation loss: 1.5153500373645494

Epoch: 6| Step: 5
Training loss: 0.08611741662025452
Validation loss: 1.5246018248219644

Epoch: 6| Step: 6
Training loss: 0.13181447982788086
Validation loss: 1.5063610294813752

Epoch: 6| Step: 7
Training loss: 0.1297069489955902
Validation loss: 1.481210825263813

Epoch: 6| Step: 8
Training loss: 0.06789248436689377
Validation loss: 1.438329827400946

Epoch: 6| Step: 9
Training loss: 0.08803059905767441
Validation loss: 1.4442198622611262

Epoch: 6| Step: 10
Training loss: 0.04101558402180672
Validation loss: 1.425953451023307

Epoch: 6| Step: 11
Training loss: 0.037248142063617706
Validation loss: 1.3850620658166948

Epoch: 6| Step: 12
Training loss: 0.10051377862691879
Validation loss: 1.3930791065257082

Epoch: 6| Step: 13
Training loss: 0.10020540654659271
Validation loss: 1.3807773538815078

Epoch: 699| Step: 0
Training loss: 0.07493792474269867
Validation loss: 1.3663731890340005

Epoch: 6| Step: 1
Training loss: 0.0977032333612442
Validation loss: 1.382866503089987

Epoch: 6| Step: 2
Training loss: 0.1401567906141281
Validation loss: 1.422079352922337

Epoch: 6| Step: 3
Training loss: 0.1558113992214203
Validation loss: 1.3684059061029905

Epoch: 6| Step: 4
Training loss: 0.11199306696653366
Validation loss: 1.3849523862202961

Epoch: 6| Step: 5
Training loss: 0.09969227015972137
Validation loss: 1.4068319489878993

Epoch: 6| Step: 6
Training loss: 0.05818125605583191
Validation loss: 1.4220151657699256

Epoch: 6| Step: 7
Training loss: 0.07565213739871979
Validation loss: 1.4712790846824646

Epoch: 6| Step: 8
Training loss: 0.1342475712299347
Validation loss: 1.487925116733838

Epoch: 6| Step: 9
Training loss: 0.060762349516153336
Validation loss: 1.51539614892775

Epoch: 6| Step: 10
Training loss: 0.09760180115699768
Validation loss: 1.508012907479399

Epoch: 6| Step: 11
Training loss: 0.04762139171361923
Validation loss: 1.475947436466012

Epoch: 6| Step: 12
Training loss: 0.09239985048770905
Validation loss: 1.4887817136702999

Epoch: 6| Step: 13
Training loss: 0.040764518082141876
Validation loss: 1.4478996415292062

Epoch: 700| Step: 0
Training loss: 0.06640487909317017
Validation loss: 1.4730597747269498

Epoch: 6| Step: 1
Training loss: 0.1263595074415207
Validation loss: 1.469905960944391

Epoch: 6| Step: 2
Training loss: 0.04648461192846298
Validation loss: 1.4565883490347094

Epoch: 6| Step: 3
Training loss: 0.10807614028453827
Validation loss: 1.4408702517068515

Epoch: 6| Step: 4
Training loss: 0.10723720490932465
Validation loss: 1.4363004699830086

Epoch: 6| Step: 5
Training loss: 0.055372580885887146
Validation loss: 1.419547075866371

Epoch: 6| Step: 6
Training loss: 0.05348055809736252
Validation loss: 1.3962815000164894

Epoch: 6| Step: 7
Training loss: 0.10259883105754852
Validation loss: 1.4003578667999597

Epoch: 6| Step: 8
Training loss: 0.04489331319928169
Validation loss: 1.4074606446809665

Epoch: 6| Step: 9
Training loss: 0.04502556100487709
Validation loss: 1.3779948116630636

Epoch: 6| Step: 10
Training loss: 0.07279455661773682
Validation loss: 1.3886524887495144

Epoch: 6| Step: 11
Training loss: 0.05146405100822449
Validation loss: 1.3830692627096688

Epoch: 6| Step: 12
Training loss: 0.0902777835726738
Validation loss: 1.4076437181042087

Epoch: 6| Step: 13
Training loss: 0.036734238266944885
Validation loss: 1.3967614122616347

Testing loss: 2.1361511495378283
