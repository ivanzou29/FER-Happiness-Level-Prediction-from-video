Epoch: 1| Step: 0
Training loss: 3.9749596118927
Validation loss: 5.2491524757877475

Epoch: 6| Step: 1
Training loss: 4.22111177444458
Validation loss: 5.233575656849851

Epoch: 6| Step: 2
Training loss: 5.1652913093566895
Validation loss: 5.217383687214185

Epoch: 6| Step: 3
Training loss: 5.144202709197998
Validation loss: 5.200113055526569

Epoch: 6| Step: 4
Training loss: 5.30002498626709
Validation loss: 5.181151790003622

Epoch: 6| Step: 5
Training loss: 4.128629684448242
Validation loss: 5.159597181504773

Epoch: 6| Step: 6
Training loss: 5.264090538024902
Validation loss: 5.134764384197933

Epoch: 6| Step: 7
Training loss: 5.374271392822266
Validation loss: 5.1066367856917845

Epoch: 6| Step: 8
Training loss: 4.300858497619629
Validation loss: 5.073829415023968

Epoch: 6| Step: 9
Training loss: 5.271718978881836
Validation loss: 5.036944804653045

Epoch: 6| Step: 10
Training loss: 5.320754528045654
Validation loss: 4.9951028695670505

Epoch: 6| Step: 11
Training loss: 4.681979179382324
Validation loss: 4.948669084938624

Epoch: 6| Step: 12
Training loss: 4.853033065795898
Validation loss: 4.898605167224843

Epoch: 6| Step: 13
Training loss: 5.964630603790283
Validation loss: 4.840676087205128

Epoch: 2| Step: 0
Training loss: 4.008356094360352
Validation loss: 4.782518832914291

Epoch: 6| Step: 1
Training loss: 3.502445936203003
Validation loss: 4.7215769675470165

Epoch: 6| Step: 2
Training loss: 5.522341251373291
Validation loss: 4.661855333594866

Epoch: 6| Step: 3
Training loss: 5.205421447753906
Validation loss: 4.6018093221931045

Epoch: 6| Step: 4
Training loss: 4.977229595184326
Validation loss: 4.543283816306822

Epoch: 6| Step: 5
Training loss: 3.6628427505493164
Validation loss: 4.485995615682294

Epoch: 6| Step: 6
Training loss: 3.0512475967407227
Validation loss: 4.4286968169673795

Epoch: 6| Step: 7
Training loss: 6.618976593017578
Validation loss: 4.379486422384939

Epoch: 6| Step: 8
Training loss: 4.389247894287109
Validation loss: 4.328252741085586

Epoch: 6| Step: 9
Training loss: 3.637539863586426
Validation loss: 4.279899161349061

Epoch: 6| Step: 10
Training loss: 3.826077938079834
Validation loss: 4.232342755922708

Epoch: 6| Step: 11
Training loss: 3.536703109741211
Validation loss: 4.186334169039163

Epoch: 6| Step: 12
Training loss: 3.619631290435791
Validation loss: 4.140003004381733

Epoch: 6| Step: 13
Training loss: 3.136108875274658
Validation loss: 4.093980114947083

Epoch: 3| Step: 0
Training loss: 3.9358205795288086
Validation loss: 4.046346956683744

Epoch: 6| Step: 1
Training loss: 2.6608920097351074
Validation loss: 4.007149645077285

Epoch: 6| Step: 2
Training loss: 3.665342092514038
Validation loss: 3.9868574962821057

Epoch: 6| Step: 3
Training loss: 3.7592599391937256
Validation loss: 3.9670246903614332

Epoch: 6| Step: 4
Training loss: 4.6311116218566895
Validation loss: 3.946602713677191

Epoch: 6| Step: 5
Training loss: 4.326630592346191
Validation loss: 3.924211673839118

Epoch: 6| Step: 6
Training loss: 2.9464383125305176
Validation loss: 3.9039959240985174

Epoch: 6| Step: 7
Training loss: 4.051807403564453
Validation loss: 3.883026712684221

Epoch: 6| Step: 8
Training loss: 3.681882381439209
Validation loss: 3.8629280751751316

Epoch: 6| Step: 9
Training loss: 3.646115779876709
Validation loss: 3.8494351858733804

Epoch: 6| Step: 10
Training loss: 5.167812347412109
Validation loss: 3.83424743529289

Epoch: 6| Step: 11
Training loss: 3.271725654602051
Validation loss: 3.82455777096492

Epoch: 6| Step: 12
Training loss: 2.9438459873199463
Validation loss: 3.807641711286319

Epoch: 6| Step: 13
Training loss: 4.2919793128967285
Validation loss: 3.793375312641103

Epoch: 4| Step: 0
Training loss: 3.1161465644836426
Validation loss: 3.778986241227837

Epoch: 6| Step: 1
Training loss: 3.172800064086914
Validation loss: 3.7678308486938477

Epoch: 6| Step: 2
Training loss: 3.2585015296936035
Validation loss: 3.761949990385322

Epoch: 6| Step: 3
Training loss: 3.514349937438965
Validation loss: 3.745155898473596

Epoch: 6| Step: 4
Training loss: 4.69327449798584
Validation loss: 3.725253358963997

Epoch: 6| Step: 5
Training loss: 3.136659860610962
Validation loss: 3.709364175796509

Epoch: 6| Step: 6
Training loss: 4.402631759643555
Validation loss: 3.6967782948606756

Epoch: 6| Step: 7
Training loss: 3.977691411972046
Validation loss: 3.688030683866111

Epoch: 6| Step: 8
Training loss: 3.539777994155884
Validation loss: 3.678839970660466

Epoch: 6| Step: 9
Training loss: 3.6392264366149902
Validation loss: 3.667093905069495

Epoch: 6| Step: 10
Training loss: 3.5264642238616943
Validation loss: 3.6561027573001

Epoch: 6| Step: 11
Training loss: 3.757779598236084
Validation loss: 3.643955930586784

Epoch: 6| Step: 12
Training loss: 2.69771671295166
Validation loss: 3.629939817613171

Epoch: 6| Step: 13
Training loss: 4.353696346282959
Validation loss: 3.619864179242042

Epoch: 5| Step: 0
Training loss: 3.0624871253967285
Validation loss: 3.6080006425098707

Epoch: 6| Step: 1
Training loss: 3.148610830307007
Validation loss: 3.5958760220517396

Epoch: 6| Step: 2
Training loss: 3.6965205669403076
Validation loss: 3.584298236395723

Epoch: 6| Step: 3
Training loss: 3.512202262878418
Validation loss: 3.5734403774302494

Epoch: 6| Step: 4
Training loss: 4.0279221534729
Validation loss: 3.5630687718750327

Epoch: 6| Step: 5
Training loss: 3.3045237064361572
Validation loss: 3.5543539703533216

Epoch: 6| Step: 6
Training loss: 4.480683326721191
Validation loss: 3.5401626197240685

Epoch: 6| Step: 7
Training loss: 3.680996894836426
Validation loss: 3.5281673400632796

Epoch: 6| Step: 8
Training loss: 2.1727519035339355
Validation loss: 3.533286320265903

Epoch: 6| Step: 9
Training loss: 2.795339584350586
Validation loss: 3.50003570125949

Epoch: 6| Step: 10
Training loss: 2.765676975250244
Validation loss: 3.4956331842689106

Epoch: 6| Step: 11
Training loss: 3.9791617393493652
Validation loss: 3.486212556080152

Epoch: 6| Step: 12
Training loss: 3.7431607246398926
Validation loss: 3.470340662105109

Epoch: 6| Step: 13
Training loss: 4.754568576812744
Validation loss: 3.4572052801809003

Epoch: 6| Step: 0
Training loss: 2.531430721282959
Validation loss: 3.4485749326726443

Epoch: 6| Step: 1
Training loss: 3.599336624145508
Validation loss: 3.441098972033429

Epoch: 6| Step: 2
Training loss: 3.9360742568969727
Validation loss: 3.439240353081816

Epoch: 6| Step: 3
Training loss: 2.9374513626098633
Validation loss: 3.4220903355588197

Epoch: 6| Step: 4
Training loss: 3.0001211166381836
Validation loss: 3.407565386064591

Epoch: 6| Step: 5
Training loss: 3.8907670974731445
Validation loss: 3.397950223697129

Epoch: 6| Step: 6
Training loss: 4.020209312438965
Validation loss: 3.391857408708142

Epoch: 6| Step: 7
Training loss: 2.270297050476074
Validation loss: 3.382894492918445

Epoch: 6| Step: 8
Training loss: 3.9801993370056152
Validation loss: 3.3750409310863865

Epoch: 6| Step: 9
Training loss: 3.3352408409118652
Validation loss: 3.368787222011115

Epoch: 6| Step: 10
Training loss: 3.375082492828369
Validation loss: 3.3617633209433606

Epoch: 6| Step: 11
Training loss: 2.646450996398926
Validation loss: 3.3537496289899273

Epoch: 6| Step: 12
Training loss: 3.577228307723999
Validation loss: 3.34598873507592

Epoch: 6| Step: 13
Training loss: 4.048320293426514
Validation loss: 3.3430526974380657

Epoch: 7| Step: 0
Training loss: 3.773237705230713
Validation loss: 3.3404898643493652

Epoch: 6| Step: 1
Training loss: 3.363285779953003
Validation loss: 3.3302808448832524

Epoch: 6| Step: 2
Training loss: 1.906522512435913
Validation loss: 3.3265385679019395

Epoch: 6| Step: 3
Training loss: 3.9832749366760254
Validation loss: 3.327446501742127

Epoch: 6| Step: 4
Training loss: 2.864603042602539
Validation loss: 3.317829088498187

Epoch: 6| Step: 5
Training loss: 3.494288682937622
Validation loss: 3.3121501707261607

Epoch: 6| Step: 6
Training loss: 2.7790889739990234
Validation loss: 3.3068840272964968

Epoch: 6| Step: 7
Training loss: 3.476339340209961
Validation loss: 3.300530766928068

Epoch: 6| Step: 8
Training loss: 4.013538837432861
Validation loss: 3.2968869824563303

Epoch: 6| Step: 9
Training loss: 3.8846638202667236
Validation loss: 3.3126094084914013

Epoch: 6| Step: 10
Training loss: 3.7707746028900146
Validation loss: 3.281665802001953

Epoch: 6| Step: 11
Training loss: 2.9597363471984863
Validation loss: 3.279997456458307

Epoch: 6| Step: 12
Training loss: 2.282881736755371
Validation loss: 3.2832299663174536

Epoch: 6| Step: 13
Training loss: 3.3402304649353027
Validation loss: 3.2685112107184624

Epoch: 8| Step: 0
Training loss: 3.3478922843933105
Validation loss: 3.2616459169695453

Epoch: 6| Step: 1
Training loss: 2.2356605529785156
Validation loss: 3.2665191824718187

Epoch: 6| Step: 2
Training loss: 3.5292856693267822
Validation loss: 3.2549871552375054

Epoch: 6| Step: 3
Training loss: 4.093442916870117
Validation loss: 3.2539271231620543

Epoch: 6| Step: 4
Training loss: 2.8558411598205566
Validation loss: 3.249054503697221

Epoch: 6| Step: 5
Training loss: 3.708487033843994
Validation loss: 3.2476676894772436

Epoch: 6| Step: 6
Training loss: 3.2288291454315186
Validation loss: 3.2421642785431235

Epoch: 6| Step: 7
Training loss: 3.670386791229248
Validation loss: 3.23364007601174

Epoch: 6| Step: 8
Training loss: 2.3384268283843994
Validation loss: 3.2223575063931045

Epoch: 6| Step: 9
Training loss: 2.9473865032196045
Validation loss: 3.219077907582765

Epoch: 6| Step: 10
Training loss: 3.3463363647460938
Validation loss: 3.2144271942877

Epoch: 6| Step: 11
Training loss: 2.723191738128662
Validation loss: 3.2120947145646617

Epoch: 6| Step: 12
Training loss: 3.7136929035186768
Validation loss: 3.206410848966209

Epoch: 6| Step: 13
Training loss: 3.576753854751587
Validation loss: 3.1969035671603296

Epoch: 9| Step: 0
Training loss: 3.4378609657287598
Validation loss: 3.1883385078881377

Epoch: 6| Step: 1
Training loss: 3.5183653831481934
Validation loss: 3.1796884793107227

Epoch: 6| Step: 2
Training loss: 3.4235851764678955
Validation loss: 3.1755939504151702

Epoch: 6| Step: 3
Training loss: 3.7307608127593994
Validation loss: 3.171213073115195

Epoch: 6| Step: 4
Training loss: 3.0692124366760254
Validation loss: 3.1636462442336546

Epoch: 6| Step: 5
Training loss: 2.672440528869629
Validation loss: 3.1599717832380727

Epoch: 6| Step: 6
Training loss: 3.3689217567443848
Validation loss: 3.155473965470509

Epoch: 6| Step: 7
Training loss: 3.7799391746520996
Validation loss: 3.14545105349633

Epoch: 6| Step: 8
Training loss: 2.8069064617156982
Validation loss: 3.140556202139906

Epoch: 6| Step: 9
Training loss: 3.3863649368286133
Validation loss: 3.145043942236131

Epoch: 6| Step: 10
Training loss: 3.051443576812744
Validation loss: 3.1292204190325994

Epoch: 6| Step: 11
Training loss: 2.3265066146850586
Validation loss: 3.1248187121524604

Epoch: 6| Step: 12
Training loss: 2.8535211086273193
Validation loss: 3.114575788538943

Epoch: 6| Step: 13
Training loss: 2.6590635776519775
Validation loss: 3.1098589794610136

Epoch: 10| Step: 0
Training loss: 3.4313790798187256
Validation loss: 3.099844135263915

Epoch: 6| Step: 1
Training loss: 2.489492416381836
Validation loss: 3.0942793046274493

Epoch: 6| Step: 2
Training loss: 2.8225479125976562
Validation loss: 3.0866816095126572

Epoch: 6| Step: 3
Training loss: 3.477320671081543
Validation loss: 3.083978440171929

Epoch: 6| Step: 4
Training loss: 2.940380096435547
Validation loss: 3.0812114925794702

Epoch: 6| Step: 5
Training loss: 2.2889699935913086
Validation loss: 3.0785508360914005

Epoch: 6| Step: 6
Training loss: 2.3510518074035645
Validation loss: 3.0772640679472234

Epoch: 6| Step: 7
Training loss: 4.758458614349365
Validation loss: 3.0812986768702024

Epoch: 6| Step: 8
Training loss: 2.884408712387085
Validation loss: 3.066798425489856

Epoch: 6| Step: 9
Training loss: 3.72066068649292
Validation loss: 3.0647048386194373

Epoch: 6| Step: 10
Training loss: 3.485790252685547
Validation loss: 3.0625187761040142

Epoch: 6| Step: 11
Training loss: 2.786775588989258
Validation loss: 3.055791708730882

Epoch: 6| Step: 12
Training loss: 2.9094841480255127
Validation loss: 3.05709453680182

Epoch: 6| Step: 13
Training loss: 3.304062843322754
Validation loss: 3.0523090875276955

Epoch: 11| Step: 0
Training loss: 2.4673309326171875
Validation loss: 3.050030767276723

Epoch: 6| Step: 1
Training loss: 3.7884678840637207
Validation loss: 3.050847953365695

Epoch: 6| Step: 2
Training loss: 3.433563232421875
Validation loss: 3.0434156284537366

Epoch: 6| Step: 3
Training loss: 3.306262969970703
Validation loss: 3.0388909462959535

Epoch: 6| Step: 4
Training loss: 3.2117385864257812
Validation loss: 3.0364357758593816

Epoch: 6| Step: 5
Training loss: 3.1843395233154297
Validation loss: 3.031607361250026

Epoch: 6| Step: 6
Training loss: 3.2825777530670166
Validation loss: 3.0287188740186792

Epoch: 6| Step: 7
Training loss: 3.1729631423950195
Validation loss: 3.0256448894418697

Epoch: 6| Step: 8
Training loss: 2.6751015186309814
Validation loss: 3.0216324226830595

Epoch: 6| Step: 9
Training loss: 3.486232280731201
Validation loss: 3.016959600551154

Epoch: 6| Step: 10
Training loss: 2.7369561195373535
Validation loss: 3.016659272614346

Epoch: 6| Step: 11
Training loss: 2.8386778831481934
Validation loss: 3.0135863391301965

Epoch: 6| Step: 12
Training loss: 2.9955825805664062
Validation loss: 3.0106145874146493

Epoch: 6| Step: 13
Training loss: 2.2430670261383057
Validation loss: 3.0096325233418453

Epoch: 12| Step: 0
Training loss: 3.7759790420532227
Validation loss: 3.011829173693093

Epoch: 6| Step: 1
Training loss: 3.5982513427734375
Validation loss: 3.0018434216899257

Epoch: 6| Step: 2
Training loss: 2.2325663566589355
Validation loss: 2.9990159593602663

Epoch: 6| Step: 3
Training loss: 2.608546733856201
Validation loss: 2.9978237844282583

Epoch: 6| Step: 4
Training loss: 3.4187822341918945
Validation loss: 2.9962158100579375

Epoch: 6| Step: 5
Training loss: 2.7271013259887695
Validation loss: 2.991922358030914

Epoch: 6| Step: 6
Training loss: 3.928603410720825
Validation loss: 2.99121884376772

Epoch: 6| Step: 7
Training loss: 3.0553054809570312
Validation loss: 2.987500482989896

Epoch: 6| Step: 8
Training loss: 3.500473976135254
Validation loss: 2.9857809210336335

Epoch: 6| Step: 9
Training loss: 2.974506139755249
Validation loss: 2.983420951392061

Epoch: 6| Step: 10
Training loss: 3.0592355728149414
Validation loss: 2.98216760799449

Epoch: 6| Step: 11
Training loss: 3.047219753265381
Validation loss: 2.9809075683675785

Epoch: 6| Step: 12
Training loss: 2.2460594177246094
Validation loss: 2.9804219609947613

Epoch: 6| Step: 13
Training loss: 2.4457998275756836
Validation loss: 2.9768184666992514

Epoch: 13| Step: 0
Training loss: 2.8825652599334717
Validation loss: 2.9761812430556103

Epoch: 6| Step: 1
Training loss: 2.9390740394592285
Validation loss: 2.976583762835431

Epoch: 6| Step: 2
Training loss: 2.9570775032043457
Validation loss: 2.973043264881257

Epoch: 6| Step: 3
Training loss: 2.0198376178741455
Validation loss: 2.969524452763219

Epoch: 6| Step: 4
Training loss: 3.2209572792053223
Validation loss: 2.971374175881827

Epoch: 6| Step: 5
Training loss: 2.732663154602051
Validation loss: 2.9688947226411555

Epoch: 6| Step: 6
Training loss: 3.7408909797668457
Validation loss: 2.9692942224523073

Epoch: 6| Step: 7
Training loss: 2.9511947631835938
Validation loss: 2.9645294399671656

Epoch: 6| Step: 8
Training loss: 2.929492473602295
Validation loss: 2.9641937286623063

Epoch: 6| Step: 9
Training loss: 2.445415735244751
Validation loss: 2.962278830107822

Epoch: 6| Step: 10
Training loss: 2.6539011001586914
Validation loss: 2.964280943716726

Epoch: 6| Step: 11
Training loss: 3.5043694972991943
Validation loss: 2.961943439258042

Epoch: 6| Step: 12
Training loss: 4.0299577713012695
Validation loss: 2.958573459297098

Epoch: 6| Step: 13
Training loss: 4.080728054046631
Validation loss: 2.9576600956660446

Epoch: 14| Step: 0
Training loss: 3.036426067352295
Validation loss: 2.956378952149422

Epoch: 6| Step: 1
Training loss: 2.9964141845703125
Validation loss: 2.9564342703870548

Epoch: 6| Step: 2
Training loss: 2.933551788330078
Validation loss: 2.9538154217504684

Epoch: 6| Step: 3
Training loss: 3.0426223278045654
Validation loss: 2.951111826845395

Epoch: 6| Step: 4
Training loss: 3.3279032707214355
Validation loss: 2.951224216850855

Epoch: 6| Step: 5
Training loss: 3.6868157386779785
Validation loss: 2.947623618187443

Epoch: 6| Step: 6
Training loss: 2.4208574295043945
Validation loss: 2.9471934662070325

Epoch: 6| Step: 7
Training loss: 3.175297975540161
Validation loss: 2.9460202237611175

Epoch: 6| Step: 8
Training loss: 2.6214141845703125
Validation loss: 2.9446133080349175

Epoch: 6| Step: 9
Training loss: 2.739128351211548
Validation loss: 2.9426983735894643

Epoch: 6| Step: 10
Training loss: 2.1742238998413086
Validation loss: 2.941869702390445

Epoch: 6| Step: 11
Training loss: 3.1530942916870117
Validation loss: 2.939530905856881

Epoch: 6| Step: 12
Training loss: 3.1174139976501465
Validation loss: 2.938683038116783

Epoch: 6| Step: 13
Training loss: 4.798676490783691
Validation loss: 2.936682270419213

Epoch: 15| Step: 0
Training loss: 2.671750545501709
Validation loss: 2.935342432350241

Epoch: 6| Step: 1
Training loss: 3.1072182655334473
Validation loss: 2.933372292467343

Epoch: 6| Step: 2
Training loss: 3.387633800506592
Validation loss: 2.9354611827481176

Epoch: 6| Step: 3
Training loss: 3.4342246055603027
Validation loss: 2.932614936623522

Epoch: 6| Step: 4
Training loss: 3.245300769805908
Validation loss: 2.931008195364347

Epoch: 6| Step: 5
Training loss: 2.887969970703125
Validation loss: 2.9290623382855485

Epoch: 6| Step: 6
Training loss: 3.0854291915893555
Validation loss: 2.926897902642527

Epoch: 6| Step: 7
Training loss: 3.565558910369873
Validation loss: 2.9474590798859954

Epoch: 6| Step: 8
Training loss: 3.009039878845215
Validation loss: 2.926413756544872

Epoch: 6| Step: 9
Training loss: 3.16064715385437
Validation loss: 2.926516886680357

Epoch: 6| Step: 10
Training loss: 2.947258234024048
Validation loss: 2.9333446564212924

Epoch: 6| Step: 11
Training loss: 2.272024154663086
Validation loss: 2.945609159367059

Epoch: 6| Step: 12
Training loss: 2.3054590225219727
Validation loss: 2.941185974305676

Epoch: 6| Step: 13
Training loss: 3.377272367477417
Validation loss: 2.936249230497627

Epoch: 16| Step: 0
Training loss: 2.9604835510253906
Validation loss: 2.9659469640383156

Epoch: 6| Step: 1
Training loss: 3.1077053546905518
Validation loss: 2.9427363898164485

Epoch: 6| Step: 2
Training loss: 2.595120906829834
Validation loss: 2.9240558480703704

Epoch: 6| Step: 3
Training loss: 2.8619630336761475
Validation loss: 2.9178710419644593

Epoch: 6| Step: 4
Training loss: 3.0050063133239746
Validation loss: 2.913343462892758

Epoch: 6| Step: 5
Training loss: 3.3080966472625732
Validation loss: 2.9133340850953133

Epoch: 6| Step: 6
Training loss: 3.053201913833618
Validation loss: 2.9143978805952173

Epoch: 6| Step: 7
Training loss: 3.2473959922790527
Validation loss: 2.928204890220396

Epoch: 6| Step: 8
Training loss: 2.8008480072021484
Validation loss: 2.9095420452856247

Epoch: 6| Step: 9
Training loss: 2.1118428707122803
Validation loss: 2.9083318300144647

Epoch: 6| Step: 10
Training loss: 3.6564440727233887
Validation loss: 2.9149293745717695

Epoch: 6| Step: 11
Training loss: 3.01133131980896
Validation loss: 2.918646179219728

Epoch: 6| Step: 12
Training loss: 3.2103219032287598
Validation loss: 2.9199230594019734

Epoch: 6| Step: 13
Training loss: 3.529020309448242
Validation loss: 2.923204611706477

Epoch: 17| Step: 0
Training loss: 2.7800235748291016
Validation loss: 2.9138690963868172

Epoch: 6| Step: 1
Training loss: 2.103907585144043
Validation loss: 2.912166113494545

Epoch: 6| Step: 2
Training loss: 3.4653234481811523
Validation loss: 2.9065854498135146

Epoch: 6| Step: 3
Training loss: 3.1291751861572266
Validation loss: 2.908192942219396

Epoch: 6| Step: 4
Training loss: 2.299851417541504
Validation loss: 2.9053148659326697

Epoch: 6| Step: 5
Training loss: 3.418613910675049
Validation loss: 2.9001476815951768

Epoch: 6| Step: 6
Training loss: 3.3341574668884277
Validation loss: 2.8959300466763076

Epoch: 6| Step: 7
Training loss: 2.50826096534729
Validation loss: 2.9067392708152853

Epoch: 6| Step: 8
Training loss: 3.2059552669525146
Validation loss: 2.8872056443204164

Epoch: 6| Step: 9
Training loss: 2.728163719177246
Validation loss: 2.8936697744554087

Epoch: 6| Step: 10
Training loss: 2.47074031829834
Validation loss: 2.9499939898008942

Epoch: 6| Step: 11
Training loss: 3.176985502243042
Validation loss: 2.9425298347268054

Epoch: 6| Step: 12
Training loss: 4.601393699645996
Validation loss: 2.9019079336556057

Epoch: 6| Step: 13
Training loss: 2.808260917663574
Validation loss: 2.907068965255573

Epoch: 18| Step: 0
Training loss: 2.8040719032287598
Validation loss: 2.9365752845682125

Epoch: 6| Step: 1
Training loss: 2.6510634422302246
Validation loss: 2.931406723555698

Epoch: 6| Step: 2
Training loss: 3.114584445953369
Validation loss: 2.914023850553779

Epoch: 6| Step: 3
Training loss: 2.935837507247925
Validation loss: 2.886198095096055

Epoch: 6| Step: 4
Training loss: 3.5674095153808594
Validation loss: 2.885488215313163

Epoch: 6| Step: 5
Training loss: 2.836808919906616
Validation loss: 2.8872208415821032

Epoch: 6| Step: 6
Training loss: 3.767547369003296
Validation loss: 2.892403389817925

Epoch: 6| Step: 7
Training loss: 2.562253952026367
Validation loss: 2.8940813156866256

Epoch: 6| Step: 8
Training loss: 3.574481248855591
Validation loss: 2.8995459836016417

Epoch: 6| Step: 9
Training loss: 2.6039533615112305
Validation loss: 2.924944446932885

Epoch: 6| Step: 10
Training loss: 2.821293830871582
Validation loss: 2.994045175531859

Epoch: 6| Step: 11
Training loss: 2.741608142852783
Validation loss: 3.0017034879294773

Epoch: 6| Step: 12
Training loss: 2.3729805946350098
Validation loss: 3.024555085807718

Epoch: 6| Step: 13
Training loss: 4.58754825592041
Validation loss: 2.990683437675558

Epoch: 19| Step: 0
Training loss: 3.075577735900879
Validation loss: 2.9600259437355945

Epoch: 6| Step: 1
Training loss: 2.63405704498291
Validation loss: 2.94079686749366

Epoch: 6| Step: 2
Training loss: 2.5357513427734375
Validation loss: 2.9178017672672065

Epoch: 6| Step: 3
Training loss: 2.947948455810547
Validation loss: 2.876532164953088

Epoch: 6| Step: 4
Training loss: 2.8105623722076416
Validation loss: 2.8801220975896364

Epoch: 6| Step: 5
Training loss: 3.6187942028045654
Validation loss: 2.9036330638393277

Epoch: 6| Step: 6
Training loss: 3.043635845184326
Validation loss: 2.9121299738525064

Epoch: 6| Step: 7
Training loss: 2.814962387084961
Validation loss: 2.9008775552113852

Epoch: 6| Step: 8
Training loss: 2.705331802368164
Validation loss: 2.888565804368706

Epoch: 6| Step: 9
Training loss: 2.966975688934326
Validation loss: 2.867898238602505

Epoch: 6| Step: 10
Training loss: 2.7477405071258545
Validation loss: 2.859732776559809

Epoch: 6| Step: 11
Training loss: 3.8410847187042236
Validation loss: 2.8559954807322514

Epoch: 6| Step: 12
Training loss: 3.2892236709594727
Validation loss: 2.852838503417148

Epoch: 6| Step: 13
Training loss: 2.8655030727386475
Validation loss: 2.850663579920287

Epoch: 20| Step: 0
Training loss: 3.0059401988983154
Validation loss: 2.84913137907623

Epoch: 6| Step: 1
Training loss: 3.0887796878814697
Validation loss: 2.848610811336066

Epoch: 6| Step: 2
Training loss: 3.3489816188812256
Validation loss: 2.8469498054955595

Epoch: 6| Step: 3
Training loss: 2.75825834274292
Validation loss: 2.8467771032805085

Epoch: 6| Step: 4
Training loss: 3.233779191970825
Validation loss: 2.849375065936837

Epoch: 6| Step: 5
Training loss: 3.8157505989074707
Validation loss: 2.8476423858314432

Epoch: 6| Step: 6
Training loss: 2.84066104888916
Validation loss: 2.840164158933906

Epoch: 6| Step: 7
Training loss: 1.9630130529403687
Validation loss: 2.841452270425776

Epoch: 6| Step: 8
Training loss: 3.557542324066162
Validation loss: 2.8439383404229277

Epoch: 6| Step: 9
Training loss: 2.200288772583008
Validation loss: 2.8386700537896927

Epoch: 6| Step: 10
Training loss: 2.7885146141052246
Validation loss: 2.8470508988185594

Epoch: 6| Step: 11
Training loss: 2.6932451725006104
Validation loss: 2.859121109849663

Epoch: 6| Step: 12
Training loss: 3.8737456798553467
Validation loss: 2.8795433095706406

Epoch: 6| Step: 13
Training loss: 1.8821969032287598
Validation loss: 2.872349754456551

Epoch: 21| Step: 0
Training loss: 2.652843475341797
Validation loss: 2.8522533652602986

Epoch: 6| Step: 1
Training loss: 3.675737142562866
Validation loss: 2.8392883885291313

Epoch: 6| Step: 2
Training loss: 2.63952898979187
Validation loss: 2.830497416116858

Epoch: 6| Step: 3
Training loss: 3.0283021926879883
Validation loss: 2.831468041225146

Epoch: 6| Step: 4
Training loss: 2.7747931480407715
Validation loss: 2.8314297917068645

Epoch: 6| Step: 5
Training loss: 3.4983861446380615
Validation loss: 2.8278481268113658

Epoch: 6| Step: 6
Training loss: 3.135986566543579
Validation loss: 2.829940706171015

Epoch: 6| Step: 7
Training loss: 2.4770541191101074
Validation loss: 2.828988121401879

Epoch: 6| Step: 8
Training loss: 2.7885007858276367
Validation loss: 2.826892432346139

Epoch: 6| Step: 9
Training loss: 3.4898874759674072
Validation loss: 2.8241852329623316

Epoch: 6| Step: 10
Training loss: 2.823556423187256
Validation loss: 2.82350185865997

Epoch: 6| Step: 11
Training loss: 2.0653913021087646
Validation loss: 2.821497214737759

Epoch: 6| Step: 12
Training loss: 3.448422431945801
Validation loss: 2.8213433347722536

Epoch: 6| Step: 13
Training loss: 2.7830159664154053
Validation loss: 2.821243137441656

Epoch: 22| Step: 0
Training loss: 3.4318606853485107
Validation loss: 2.8208675461430706

Epoch: 6| Step: 1
Training loss: 2.77221941947937
Validation loss: 2.8228117445463776

Epoch: 6| Step: 2
Training loss: 3.459974765777588
Validation loss: 2.8217437421121905

Epoch: 6| Step: 3
Training loss: 3.0039567947387695
Validation loss: 2.8233632785017773

Epoch: 6| Step: 4
Training loss: 3.544023275375366
Validation loss: 2.8239504444983696

Epoch: 6| Step: 5
Training loss: 2.1574950218200684
Validation loss: 2.822048771765924

Epoch: 6| Step: 6
Training loss: 2.618704080581665
Validation loss: 2.82160363786964

Epoch: 6| Step: 7
Training loss: 2.7181270122528076
Validation loss: 2.829538445318899

Epoch: 6| Step: 8
Training loss: 3.092501401901245
Validation loss: 2.833008325228127

Epoch: 6| Step: 9
Training loss: 2.544776201248169
Validation loss: 2.8226838086241033

Epoch: 6| Step: 10
Training loss: 2.6677637100219727
Validation loss: 2.822180019911899

Epoch: 6| Step: 11
Training loss: 3.454523801803589
Validation loss: 2.8148739619921614

Epoch: 6| Step: 12
Training loss: 2.4777956008911133
Validation loss: 2.815296301277735

Epoch: 6| Step: 13
Training loss: 3.573875904083252
Validation loss: 2.813393920980474

Epoch: 23| Step: 0
Training loss: 2.3352863788604736
Validation loss: 2.8105600085309757

Epoch: 6| Step: 1
Training loss: 2.390319585800171
Validation loss: 2.810083576427993

Epoch: 6| Step: 2
Training loss: 2.7831990718841553
Validation loss: 2.8099585912560903

Epoch: 6| Step: 3
Training loss: 2.919696807861328
Validation loss: 2.812006576086885

Epoch: 6| Step: 4
Training loss: 3.425870180130005
Validation loss: 2.809022888060539

Epoch: 6| Step: 5
Training loss: 2.8660624027252197
Validation loss: 2.8105914131287606

Epoch: 6| Step: 6
Training loss: 3.182070255279541
Validation loss: 2.810363102984685

Epoch: 6| Step: 7
Training loss: 2.935515880584717
Validation loss: 2.8095818104282504

Epoch: 6| Step: 8
Training loss: 2.2724204063415527
Validation loss: 2.8069196208830802

Epoch: 6| Step: 9
Training loss: 3.2984654903411865
Validation loss: 2.8079706827799478

Epoch: 6| Step: 10
Training loss: 3.026146650314331
Validation loss: 2.8071632539072344

Epoch: 6| Step: 11
Training loss: 3.5747907161712646
Validation loss: 2.8054237083722184

Epoch: 6| Step: 12
Training loss: 3.074500799179077
Validation loss: 2.8069616235712522

Epoch: 6| Step: 13
Training loss: 3.1465396881103516
Validation loss: 2.8076392630095124

Epoch: 24| Step: 0
Training loss: 2.9310035705566406
Validation loss: 2.809937277147847

Epoch: 6| Step: 1
Training loss: 3.7288479804992676
Validation loss: 2.803481892872882

Epoch: 6| Step: 2
Training loss: 2.573348045349121
Validation loss: 2.803166038246565

Epoch: 6| Step: 3
Training loss: 3.6222219467163086
Validation loss: 2.803077769535844

Epoch: 6| Step: 4
Training loss: 2.474836587905884
Validation loss: 2.8061990071368474

Epoch: 6| Step: 5
Training loss: 3.265263319015503
Validation loss: 2.799048710894841

Epoch: 6| Step: 6
Training loss: 2.519211769104004
Validation loss: 2.8009532549047984

Epoch: 6| Step: 7
Training loss: 3.6863574981689453
Validation loss: 2.7979165097718597

Epoch: 6| Step: 8
Training loss: 2.291839838027954
Validation loss: 2.797562104399486

Epoch: 6| Step: 9
Training loss: 3.591823101043701
Validation loss: 2.7951451398993052

Epoch: 6| Step: 10
Training loss: 2.648369312286377
Validation loss: 2.79158946775621

Epoch: 6| Step: 11
Training loss: 2.5549991130828857
Validation loss: 2.79345957181787

Epoch: 6| Step: 12
Training loss: 2.146423816680908
Validation loss: 2.7936620917371524

Epoch: 6| Step: 13
Training loss: 3.07399845123291
Validation loss: 2.795737579304685

Epoch: 25| Step: 0
Training loss: 2.817812442779541
Validation loss: 2.7925935406838693

Epoch: 6| Step: 1
Training loss: 2.6085801124572754
Validation loss: 2.794796864191691

Epoch: 6| Step: 2
Training loss: 2.6223361492156982
Validation loss: 2.7937400597398

Epoch: 6| Step: 3
Training loss: 2.181183099746704
Validation loss: 2.795442586304039

Epoch: 6| Step: 4
Training loss: 3.1135783195495605
Validation loss: 2.791326904809603

Epoch: 6| Step: 5
Training loss: 3.0870418548583984
Validation loss: 2.791573868002943

Epoch: 6| Step: 6
Training loss: 2.9056270122528076
Validation loss: 2.7933209250050206

Epoch: 6| Step: 7
Training loss: 3.332357406616211
Validation loss: 2.7914345315707627

Epoch: 6| Step: 8
Training loss: 2.094147205352783
Validation loss: 2.792023333170081

Epoch: 6| Step: 9
Training loss: 3.408820152282715
Validation loss: 2.7904440767021588

Epoch: 6| Step: 10
Training loss: 3.0004096031188965
Validation loss: 2.7920480812749555

Epoch: 6| Step: 11
Training loss: 3.435826539993286
Validation loss: 2.7911593529485885

Epoch: 6| Step: 12
Training loss: 3.2454652786254883
Validation loss: 2.793576140557566

Epoch: 6| Step: 13
Training loss: 3.2605934143066406
Validation loss: 2.7837807414352254

Epoch: 26| Step: 0
Training loss: 3.4878811836242676
Validation loss: 2.782945368879585

Epoch: 6| Step: 1
Training loss: 2.5766305923461914
Validation loss: 2.7829793909544587

Epoch: 6| Step: 2
Training loss: 2.834803819656372
Validation loss: 2.7803937824823524

Epoch: 6| Step: 3
Training loss: 2.387019395828247
Validation loss: 2.78232208887736

Epoch: 6| Step: 4
Training loss: 3.5980119705200195
Validation loss: 2.7796551899243425

Epoch: 6| Step: 5
Training loss: 2.799635410308838
Validation loss: 2.780642637642481

Epoch: 6| Step: 6
Training loss: 2.517716884613037
Validation loss: 2.7796917448761644

Epoch: 6| Step: 7
Training loss: 2.869983673095703
Validation loss: 2.781248181096969

Epoch: 6| Step: 8
Training loss: 3.6669721603393555
Validation loss: 2.777898862797727

Epoch: 6| Step: 9
Training loss: 3.416384696960449
Validation loss: 2.777166579359321

Epoch: 6| Step: 10
Training loss: 2.134121894836426
Validation loss: 2.777768914417554

Epoch: 6| Step: 11
Training loss: 2.398942708969116
Validation loss: 2.776507713461435

Epoch: 6| Step: 12
Training loss: 3.346143960952759
Validation loss: 2.7769444296436925

Epoch: 6| Step: 13
Training loss: 2.860117197036743
Validation loss: 2.7743276396105365

Epoch: 27| Step: 0
Training loss: 2.815020799636841
Validation loss: 2.773229378525929

Epoch: 6| Step: 1
Training loss: 3.321105480194092
Validation loss: 2.7727061369085826

Epoch: 6| Step: 2
Training loss: 2.654531955718994
Validation loss: 2.775267611267746

Epoch: 6| Step: 3
Training loss: 2.7352523803710938
Validation loss: 2.7743828476116223

Epoch: 6| Step: 4
Training loss: 2.336198329925537
Validation loss: 2.768942468909807

Epoch: 6| Step: 5
Training loss: 2.5831239223480225
Validation loss: 2.7729128458166636

Epoch: 6| Step: 6
Training loss: 2.8755288124084473
Validation loss: 2.7728653287374847

Epoch: 6| Step: 7
Training loss: 3.525388717651367
Validation loss: 2.770245575135754

Epoch: 6| Step: 8
Training loss: 2.8642678260803223
Validation loss: 2.770546192763954

Epoch: 6| Step: 9
Training loss: 2.947157859802246
Validation loss: 2.7728258640535417

Epoch: 6| Step: 10
Training loss: 3.0534017086029053
Validation loss: 2.7712700033700592

Epoch: 6| Step: 11
Training loss: 3.5474448204040527
Validation loss: 2.773159929501113

Epoch: 6| Step: 12
Training loss: 2.6324257850646973
Validation loss: 2.7716788835422967

Epoch: 6| Step: 13
Training loss: 2.924741268157959
Validation loss: 2.771643123319072

Epoch: 28| Step: 0
Training loss: 3.481330394744873
Validation loss: 2.7674028104351414

Epoch: 6| Step: 1
Training loss: 2.1222798824310303
Validation loss: 2.763761099948678

Epoch: 6| Step: 2
Training loss: 2.5767974853515625
Validation loss: 2.763897593303393

Epoch: 6| Step: 3
Training loss: 2.7812204360961914
Validation loss: 2.761979249215895

Epoch: 6| Step: 4
Training loss: 2.6222753524780273
Validation loss: 2.765798209815897

Epoch: 6| Step: 5
Training loss: 2.928929328918457
Validation loss: 2.7636810348879908

Epoch: 6| Step: 6
Training loss: 3.1558425426483154
Validation loss: 2.7623275300507903

Epoch: 6| Step: 7
Training loss: 2.973174571990967
Validation loss: 2.7604911660635345

Epoch: 6| Step: 8
Training loss: 3.1031980514526367
Validation loss: 2.75671544126285

Epoch: 6| Step: 9
Training loss: 2.680476188659668
Validation loss: 2.7590078025735836

Epoch: 6| Step: 10
Training loss: 2.838860511779785
Validation loss: 2.755519525979155

Epoch: 6| Step: 11
Training loss: 3.2226390838623047
Validation loss: 2.757686527826453

Epoch: 6| Step: 12
Training loss: 2.904172658920288
Validation loss: 2.7538608299788607

Epoch: 6| Step: 13
Training loss: 3.6381657123565674
Validation loss: 2.756680114294893

Epoch: 29| Step: 0
Training loss: 1.5477005243301392
Validation loss: 2.756922932081325

Epoch: 6| Step: 1
Training loss: 2.28806209564209
Validation loss: 2.7543718379030944

Epoch: 6| Step: 2
Training loss: 1.9521422386169434
Validation loss: 2.7526959603832615

Epoch: 6| Step: 3
Training loss: 3.7432944774627686
Validation loss: 2.753406540040047

Epoch: 6| Step: 4
Training loss: 4.257823944091797
Validation loss: 2.7516224691944737

Epoch: 6| Step: 5
Training loss: 3.4712014198303223
Validation loss: 2.752740785639773

Epoch: 6| Step: 6
Training loss: 2.4962379932403564
Validation loss: 2.7519105019107943

Epoch: 6| Step: 7
Training loss: 3.506511688232422
Validation loss: 2.7494025961045296

Epoch: 6| Step: 8
Training loss: 2.3494904041290283
Validation loss: 2.748319184908303

Epoch: 6| Step: 9
Training loss: 2.5977072715759277
Validation loss: 2.7464757760365806

Epoch: 6| Step: 10
Training loss: 2.7102911472320557
Validation loss: 2.746731904245192

Epoch: 6| Step: 11
Training loss: 3.0548272132873535
Validation loss: 2.7489420188370572

Epoch: 6| Step: 12
Training loss: 3.599025249481201
Validation loss: 2.7511230412349907

Epoch: 6| Step: 13
Training loss: 3.1418333053588867
Validation loss: 2.760100713340185

Epoch: 30| Step: 0
Training loss: 2.606076955795288
Validation loss: 2.7515300268767984

Epoch: 6| Step: 1
Training loss: 2.708786964416504
Validation loss: 2.752714644196213

Epoch: 6| Step: 2
Training loss: 3.5388340950012207
Validation loss: 2.7454188716027046

Epoch: 6| Step: 3
Training loss: 3.5657007694244385
Validation loss: 2.745656472380443

Epoch: 6| Step: 4
Training loss: 2.4440741539001465
Validation loss: 2.7480576679270756

Epoch: 6| Step: 5
Training loss: 3.2915024757385254
Validation loss: 2.7469525926856586

Epoch: 6| Step: 6
Training loss: 1.6525157690048218
Validation loss: 2.7457522576855076

Epoch: 6| Step: 7
Training loss: 2.288130044937134
Validation loss: 2.743868591964886

Epoch: 6| Step: 8
Training loss: 3.0216593742370605
Validation loss: 2.7452655376926547

Epoch: 6| Step: 9
Training loss: 2.9889888763427734
Validation loss: 2.7453514299085064

Epoch: 6| Step: 10
Training loss: 3.612286329269409
Validation loss: 2.7418483354712047

Epoch: 6| Step: 11
Training loss: 2.988778829574585
Validation loss: 2.747466512905654

Epoch: 6| Step: 12
Training loss: 3.2244935035705566
Validation loss: 2.750872617126793

Epoch: 6| Step: 13
Training loss: 2.330930709838867
Validation loss: 2.7482606262289067

Epoch: 31| Step: 0
Training loss: 2.638460397720337
Validation loss: 2.743293813479844

Epoch: 6| Step: 1
Training loss: 2.9707422256469727
Validation loss: 2.739646803948187

Epoch: 6| Step: 2
Training loss: 2.4230716228485107
Validation loss: 2.7408287499540593

Epoch: 6| Step: 3
Training loss: 2.7334389686584473
Validation loss: 2.739701573566724

Epoch: 6| Step: 4
Training loss: 3.389443874359131
Validation loss: 2.743348777935069

Epoch: 6| Step: 5
Training loss: 2.658207654953003
Validation loss: 2.7491166155825377

Epoch: 6| Step: 6
Training loss: 2.5365848541259766
Validation loss: 2.7474864900753064

Epoch: 6| Step: 7
Training loss: 2.9721736907958984
Validation loss: 2.7406268529994513

Epoch: 6| Step: 8
Training loss: 2.969148635864258
Validation loss: 2.7367448601671445

Epoch: 6| Step: 9
Training loss: 3.197906494140625
Validation loss: 2.7364952897512786

Epoch: 6| Step: 10
Training loss: 3.606706380844116
Validation loss: 2.755881614582513

Epoch: 6| Step: 11
Training loss: 2.4710693359375
Validation loss: 2.827942168840798

Epoch: 6| Step: 12
Training loss: 3.060533046722412
Validation loss: 2.8257029543640795

Epoch: 6| Step: 13
Training loss: 2.527759552001953
Validation loss: 2.779679375310098

Epoch: 32| Step: 0
Training loss: 2.510807752609253
Validation loss: 2.786630110074115

Epoch: 6| Step: 1
Training loss: 3.2025089263916016
Validation loss: 2.7667182645490094

Epoch: 6| Step: 2
Training loss: 3.637699842453003
Validation loss: 2.7537058732842885

Epoch: 6| Step: 3
Training loss: 2.8151347637176514
Validation loss: 2.7497140053779847

Epoch: 6| Step: 4
Training loss: 2.541311264038086
Validation loss: 2.747905869637766

Epoch: 6| Step: 5
Training loss: 2.3303027153015137
Validation loss: 2.742345210044615

Epoch: 6| Step: 6
Training loss: 3.4510297775268555
Validation loss: 2.735968194982057

Epoch: 6| Step: 7
Training loss: 2.2150089740753174
Validation loss: 2.7321414588600077

Epoch: 6| Step: 8
Training loss: 2.941828489303589
Validation loss: 2.735892685510779

Epoch: 6| Step: 9
Training loss: 2.478287696838379
Validation loss: 2.7398016222061647

Epoch: 6| Step: 10
Training loss: 3.5891504287719727
Validation loss: 2.7384000824343775

Epoch: 6| Step: 11
Training loss: 2.794990062713623
Validation loss: 2.745082765497187

Epoch: 6| Step: 12
Training loss: 2.60214900970459
Validation loss: 2.7333047723257415

Epoch: 6| Step: 13
Training loss: 3.3525991439819336
Validation loss: 2.728900832514609

Epoch: 33| Step: 0
Training loss: 3.0167489051818848
Validation loss: 2.7262766130508913

Epoch: 6| Step: 1
Training loss: 2.194835662841797
Validation loss: 2.7255202621541996

Epoch: 6| Step: 2
Training loss: 3.2050888538360596
Validation loss: 2.7237831084958968

Epoch: 6| Step: 3
Training loss: 3.2096362113952637
Validation loss: 2.727256603138421

Epoch: 6| Step: 4
Training loss: 3.384005308151245
Validation loss: 2.7282966952170096

Epoch: 6| Step: 5
Training loss: 2.187401056289673
Validation loss: 2.7309762559911257

Epoch: 6| Step: 6
Training loss: 2.16241717338562
Validation loss: 2.7339844934401976

Epoch: 6| Step: 7
Training loss: 2.623967170715332
Validation loss: 2.7316938395141275

Epoch: 6| Step: 8
Training loss: 3.4400906562805176
Validation loss: 2.7271062866333993

Epoch: 6| Step: 9
Training loss: 3.7112627029418945
Validation loss: 2.716468434179983

Epoch: 6| Step: 10
Training loss: 2.8214361667633057
Validation loss: 2.7200542675551547

Epoch: 6| Step: 11
Training loss: 3.3724799156188965
Validation loss: 2.7173433970379572

Epoch: 6| Step: 12
Training loss: 2.3371312618255615
Validation loss: 2.7171243980366695

Epoch: 6| Step: 13
Training loss: 2.034573793411255
Validation loss: 2.716854920951269

Epoch: 34| Step: 0
Training loss: 3.245286703109741
Validation loss: 2.7162994774439

Epoch: 6| Step: 1
Training loss: 3.3219637870788574
Validation loss: 2.716633286527408

Epoch: 6| Step: 2
Training loss: 2.8628339767456055
Validation loss: 2.7175072777655815

Epoch: 6| Step: 3
Training loss: 3.7227962017059326
Validation loss: 2.715882452585364

Epoch: 6| Step: 4
Training loss: 2.994469165802002
Validation loss: 2.7141195727932836

Epoch: 6| Step: 5
Training loss: 2.438366413116455
Validation loss: 2.7134185170614593

Epoch: 6| Step: 6
Training loss: 3.1461541652679443
Validation loss: 2.709607470420099

Epoch: 6| Step: 7
Training loss: 2.6271674633026123
Validation loss: 2.7088055354292675

Epoch: 6| Step: 8
Training loss: 2.7304978370666504
Validation loss: 2.712079886467226

Epoch: 6| Step: 9
Training loss: 2.9579789638519287
Validation loss: 2.710676923874886

Epoch: 6| Step: 10
Training loss: 2.6834983825683594
Validation loss: 2.712242490501814

Epoch: 6| Step: 11
Training loss: 1.811830997467041
Validation loss: 2.7135789804561163

Epoch: 6| Step: 12
Training loss: 2.541781425476074
Validation loss: 2.7124640198164087

Epoch: 6| Step: 13
Training loss: 2.8604581356048584
Validation loss: 2.7097997434677614

Epoch: 35| Step: 0
Training loss: 2.986668825149536
Validation loss: 2.707775910695394

Epoch: 6| Step: 1
Training loss: 2.7990036010742188
Validation loss: 2.7065302428378852

Epoch: 6| Step: 2
Training loss: 3.613185405731201
Validation loss: 2.7048419367882515

Epoch: 6| Step: 3
Training loss: 3.0818278789520264
Validation loss: 2.7073788258337204

Epoch: 6| Step: 4
Training loss: 2.990939140319824
Validation loss: 2.7044594774964037

Epoch: 6| Step: 5
Training loss: 1.9945077896118164
Validation loss: 2.7053107830785934

Epoch: 6| Step: 6
Training loss: 1.8304169178009033
Validation loss: 2.7029439121164303

Epoch: 6| Step: 7
Training loss: 2.8750545978546143
Validation loss: 2.7002990784183627

Epoch: 6| Step: 8
Training loss: 2.7099993228912354
Validation loss: 2.70871034232519

Epoch: 6| Step: 9
Training loss: 3.5865511894226074
Validation loss: 2.713115922866329

Epoch: 6| Step: 10
Training loss: 2.9706289768218994
Validation loss: 2.7127948909677486

Epoch: 6| Step: 11
Training loss: 3.507073402404785
Validation loss: 2.6998931797601844

Epoch: 6| Step: 12
Training loss: 2.56101131439209
Validation loss: 2.699518426772087

Epoch: 6| Step: 13
Training loss: 1.9946708679199219
Validation loss: 2.6963016909937703

Epoch: 36| Step: 0
Training loss: 3.9108004570007324
Validation loss: 2.6984863024885937

Epoch: 6| Step: 1
Training loss: 2.635479688644409
Validation loss: 2.6964716296042166

Epoch: 6| Step: 2
Training loss: 3.0553030967712402
Validation loss: 2.692806210569156

Epoch: 6| Step: 3
Training loss: 2.1234285831451416
Validation loss: 2.6944346607372327

Epoch: 6| Step: 4
Training loss: 2.4445481300354004
Validation loss: 2.7026718175539406

Epoch: 6| Step: 5
Training loss: 2.4772274494171143
Validation loss: 2.7117204666137695

Epoch: 6| Step: 6
Training loss: 2.811680316925049
Validation loss: 2.7153384224061043

Epoch: 6| Step: 7
Training loss: 2.5433077812194824
Validation loss: 2.7062510059725855

Epoch: 6| Step: 8
Training loss: 2.588894844055176
Validation loss: 2.7045775254567466

Epoch: 6| Step: 9
Training loss: 3.139054775238037
Validation loss: 2.7147138349471556

Epoch: 6| Step: 10
Training loss: 3.0266127586364746
Validation loss: 2.7196040384231077

Epoch: 6| Step: 11
Training loss: 3.073930025100708
Validation loss: 2.742071182497086

Epoch: 6| Step: 12
Training loss: 3.059562921524048
Validation loss: 2.7198277211958364

Epoch: 6| Step: 13
Training loss: 3.137051582336426
Validation loss: 2.6943149105195077

Epoch: 37| Step: 0
Training loss: 2.3493058681488037
Validation loss: 2.6949370573925715

Epoch: 6| Step: 1
Training loss: 2.4911253452301025
Validation loss: 2.693495883736559

Epoch: 6| Step: 2
Training loss: 3.5164079666137695
Validation loss: 2.6865466974114858

Epoch: 6| Step: 3
Training loss: 3.241997718811035
Validation loss: 2.685818813180411

Epoch: 6| Step: 4
Training loss: 2.182840347290039
Validation loss: 2.687634983370381

Epoch: 6| Step: 5
Training loss: 2.305691719055176
Validation loss: 2.688142881598524

Epoch: 6| Step: 6
Training loss: 2.998148202896118
Validation loss: 2.689735366452125

Epoch: 6| Step: 7
Training loss: 2.9851784706115723
Validation loss: 2.6885706583658853

Epoch: 6| Step: 8
Training loss: 3.009019136428833
Validation loss: 2.6918652006374892

Epoch: 6| Step: 9
Training loss: 3.4352285861968994
Validation loss: 2.68950588985156

Epoch: 6| Step: 10
Training loss: 2.6963624954223633
Validation loss: 2.688513994216919

Epoch: 6| Step: 11
Training loss: 2.8540894985198975
Validation loss: 2.687958825019098

Epoch: 6| Step: 12
Training loss: 2.5787487030029297
Validation loss: 2.682968247321344

Epoch: 6| Step: 13
Training loss: 3.0623624324798584
Validation loss: 2.682456588232389

Epoch: 38| Step: 0
Training loss: 2.9502170085906982
Validation loss: 2.6801561488900134

Epoch: 6| Step: 1
Training loss: 3.0456202030181885
Validation loss: 2.6850125584551083

Epoch: 6| Step: 2
Training loss: 2.490649700164795
Validation loss: 2.6902551599728164

Epoch: 6| Step: 3
Training loss: 2.7245826721191406
Validation loss: 2.6837207527570826

Epoch: 6| Step: 4
Training loss: 2.973137617111206
Validation loss: 2.691024531600296

Epoch: 6| Step: 5
Training loss: 2.2252979278564453
Validation loss: 2.713318101821407

Epoch: 6| Step: 6
Training loss: 3.2274656295776367
Validation loss: 2.717519570422429

Epoch: 6| Step: 7
Training loss: 3.282594680786133
Validation loss: 2.696925160705402

Epoch: 6| Step: 8
Training loss: 2.9592394828796387
Validation loss: 2.690379270943262

Epoch: 6| Step: 9
Training loss: 3.1601123809814453
Validation loss: 2.688227302284651

Epoch: 6| Step: 10
Training loss: 3.2172465324401855
Validation loss: 2.6906973623460337

Epoch: 6| Step: 11
Training loss: 2.338343381881714
Validation loss: 2.6916026299999607

Epoch: 6| Step: 12
Training loss: 2.134645938873291
Validation loss: 2.692381135879024

Epoch: 6| Step: 13
Training loss: 2.913672685623169
Validation loss: 2.6902129419388308

Epoch: 39| Step: 0
Training loss: 2.397564172744751
Validation loss: 2.671869641991072

Epoch: 6| Step: 1
Training loss: 3.0492334365844727
Validation loss: 2.673819577822121

Epoch: 6| Step: 2
Training loss: 1.9638608694076538
Validation loss: 2.677648949366744

Epoch: 6| Step: 3
Training loss: 2.573305368423462
Validation loss: 2.678722719992361

Epoch: 6| Step: 4
Training loss: 2.964876651763916
Validation loss: 2.6795678010550876

Epoch: 6| Step: 5
Training loss: 3.2185170650482178
Validation loss: 2.685924240337905

Epoch: 6| Step: 6
Training loss: 3.2311253547668457
Validation loss: 2.6873603020944903

Epoch: 6| Step: 7
Training loss: 2.31915283203125
Validation loss: 2.6921166437928394

Epoch: 6| Step: 8
Training loss: 2.767557382583618
Validation loss: 2.67634565343139

Epoch: 6| Step: 9
Training loss: 2.6030492782592773
Validation loss: 2.6700887423689648

Epoch: 6| Step: 10
Training loss: 3.5902936458587646
Validation loss: 2.6650674009835846

Epoch: 6| Step: 11
Training loss: 2.795675754547119
Validation loss: 2.661062027818413

Epoch: 6| Step: 12
Training loss: 3.181717872619629
Validation loss: 2.660719520302229

Epoch: 6| Step: 13
Training loss: 2.788966417312622
Validation loss: 2.660077820542038

Epoch: 40| Step: 0
Training loss: 1.7518539428710938
Validation loss: 2.6618300971164497

Epoch: 6| Step: 1
Training loss: 3.558457612991333
Validation loss: 2.6630163320931057

Epoch: 6| Step: 2
Training loss: 3.267199993133545
Validation loss: 2.6585881838234524

Epoch: 6| Step: 3
Training loss: 3.293417453765869
Validation loss: 2.656995104205224

Epoch: 6| Step: 4
Training loss: 1.7412657737731934
Validation loss: 2.655864797612672

Epoch: 6| Step: 5
Training loss: 2.6666860580444336
Validation loss: 2.6542551363668134

Epoch: 6| Step: 6
Training loss: 3.036365032196045
Validation loss: 2.6560304728887414

Epoch: 6| Step: 7
Training loss: 2.9223265647888184
Validation loss: 2.6567585468292236

Epoch: 6| Step: 8
Training loss: 2.7010178565979004
Validation loss: 2.6564509842985418

Epoch: 6| Step: 9
Training loss: 2.9468133449554443
Validation loss: 2.6562629950943815

Epoch: 6| Step: 10
Training loss: 2.4921860694885254
Validation loss: 2.654895233851607

Epoch: 6| Step: 11
Training loss: 2.91908860206604
Validation loss: 2.6609431364203013

Epoch: 6| Step: 12
Training loss: 2.9107232093811035
Validation loss: 2.659574293321179

Epoch: 6| Step: 13
Training loss: 3.291342258453369
Validation loss: 2.6574154259056173

Epoch: 41| Step: 0
Training loss: 2.9788594245910645
Validation loss: 2.6601179927907963

Epoch: 6| Step: 1
Training loss: 2.3089189529418945
Validation loss: 2.657288300093784

Epoch: 6| Step: 2
Training loss: 2.4922027587890625
Validation loss: 2.6639297162332842

Epoch: 6| Step: 3
Training loss: 2.774837017059326
Validation loss: 2.659893448634814

Epoch: 6| Step: 4
Training loss: 2.660634994506836
Validation loss: 2.668734588930684

Epoch: 6| Step: 5
Training loss: 3.830775737762451
Validation loss: 2.679157821081018

Epoch: 6| Step: 6
Training loss: 2.646265983581543
Validation loss: 2.693559290260397

Epoch: 6| Step: 7
Training loss: 2.3627543449401855
Validation loss: 2.6717537115978938

Epoch: 6| Step: 8
Training loss: 3.7312328815460205
Validation loss: 2.651004022167575

Epoch: 6| Step: 9
Training loss: 2.423823595046997
Validation loss: 2.642514641566943

Epoch: 6| Step: 10
Training loss: 2.456092357635498
Validation loss: 2.6535660169457875

Epoch: 6| Step: 11
Training loss: 2.880312919616699
Validation loss: 2.6937567187893774

Epoch: 6| Step: 12
Training loss: 2.835334062576294
Validation loss: 2.754630616916123

Epoch: 6| Step: 13
Training loss: 3.1773173809051514
Validation loss: 2.798493572460708

Epoch: 42| Step: 0
Training loss: 3.3137331008911133
Validation loss: 2.707583445374684

Epoch: 6| Step: 1
Training loss: 2.494541645050049
Validation loss: 2.644266628449963

Epoch: 6| Step: 2
Training loss: 3.020761013031006
Validation loss: 2.6382160494404454

Epoch: 6| Step: 3
Training loss: 4.153106212615967
Validation loss: 2.65525544587002

Epoch: 6| Step: 4
Training loss: 1.778401255607605
Validation loss: 2.6613833006992134

Epoch: 6| Step: 5
Training loss: 2.4493446350097656
Validation loss: 2.6702502158380326

Epoch: 6| Step: 6
Training loss: 2.5774080753326416
Validation loss: 2.6659106080250075

Epoch: 6| Step: 7
Training loss: 2.2211415767669678
Validation loss: 2.6675051963457497

Epoch: 6| Step: 8
Training loss: 3.0066006183624268
Validation loss: 2.657017666806457

Epoch: 6| Step: 9
Training loss: 3.659031867980957
Validation loss: 2.6553799926593737

Epoch: 6| Step: 10
Training loss: 2.641785144805908
Validation loss: 2.644409277105844

Epoch: 6| Step: 11
Training loss: 3.251646041870117
Validation loss: 2.6352372323313067

Epoch: 6| Step: 12
Training loss: 2.1241865158081055
Validation loss: 2.6328084930296867

Epoch: 6| Step: 13
Training loss: 2.4007441997528076
Validation loss: 2.6358928167691795

Epoch: 43| Step: 0
Training loss: 3.006121873855591
Validation loss: 2.6298668871643724

Epoch: 6| Step: 1
Training loss: 2.5867180824279785
Validation loss: 2.632768964254728

Epoch: 6| Step: 2
Training loss: 2.753854513168335
Validation loss: 2.6336854093818256

Epoch: 6| Step: 3
Training loss: 2.541757106781006
Validation loss: 2.637283525159282

Epoch: 6| Step: 4
Training loss: 2.5008296966552734
Validation loss: 2.6486736523207797

Epoch: 6| Step: 5
Training loss: 3.5142245292663574
Validation loss: 2.678955570344002

Epoch: 6| Step: 6
Training loss: 2.5804996490478516
Validation loss: 2.6549475859570246

Epoch: 6| Step: 7
Training loss: 2.822554111480713
Validation loss: 2.6480965152863534

Epoch: 6| Step: 8
Training loss: 2.9320805072784424
Validation loss: 2.640474514294696

Epoch: 6| Step: 9
Training loss: 3.1681740283966064
Validation loss: 2.6344797739418606

Epoch: 6| Step: 10
Training loss: 2.4575960636138916
Validation loss: 2.6288385288689726

Epoch: 6| Step: 11
Training loss: 2.615171432495117
Validation loss: 2.6275016146321453

Epoch: 6| Step: 12
Training loss: 3.0949552059173584
Validation loss: 2.638812962398734

Epoch: 6| Step: 13
Training loss: 2.521040439605713
Validation loss: 2.6798792859559417

Epoch: 44| Step: 0
Training loss: 2.462468147277832
Validation loss: 2.6871269800329722

Epoch: 6| Step: 1
Training loss: 2.841426372528076
Validation loss: 2.6895608235430974

Epoch: 6| Step: 2
Training loss: 2.8073039054870605
Validation loss: 2.6851585193346907

Epoch: 6| Step: 3
Training loss: 2.072551965713501
Validation loss: 2.655340874066917

Epoch: 6| Step: 4
Training loss: 2.9408040046691895
Validation loss: 2.632495403289795

Epoch: 6| Step: 5
Training loss: 3.036151885986328
Validation loss: 2.6221411510180404

Epoch: 6| Step: 6
Training loss: 2.7262747287750244
Validation loss: 2.6192902544493317

Epoch: 6| Step: 7
Training loss: 2.4714221954345703
Validation loss: 2.615912575875559

Epoch: 6| Step: 8
Training loss: 2.5931315422058105
Validation loss: 2.616392445820634

Epoch: 6| Step: 9
Training loss: 2.4497737884521484
Validation loss: 2.6202190768334175

Epoch: 6| Step: 10
Training loss: 3.3438079357147217
Validation loss: 2.617693175551712

Epoch: 6| Step: 11
Training loss: 4.05186653137207
Validation loss: 2.6208661704935055

Epoch: 6| Step: 12
Training loss: 2.9674923419952393
Validation loss: 2.6232119580750823

Epoch: 6| Step: 13
Training loss: 1.944225549697876
Validation loss: 2.625493477749568

Epoch: 45| Step: 0
Training loss: 2.862671375274658
Validation loss: 2.623172611318609

Epoch: 6| Step: 1
Training loss: 2.346811532974243
Validation loss: 2.6189155706795315

Epoch: 6| Step: 2
Training loss: 3.0839037895202637
Validation loss: 2.632743925176641

Epoch: 6| Step: 3
Training loss: 2.8563971519470215
Validation loss: 2.6444786312759563

Epoch: 6| Step: 4
Training loss: 2.708070755004883
Validation loss: 2.6414472902974775

Epoch: 6| Step: 5
Training loss: 2.9015820026397705
Validation loss: 2.6356338634285876

Epoch: 6| Step: 6
Training loss: 2.9794490337371826
Validation loss: 2.646017228403399

Epoch: 6| Step: 7
Training loss: 3.1435537338256836
Validation loss: 2.6531938378528883

Epoch: 6| Step: 8
Training loss: 3.4572701454162598
Validation loss: 2.6399930446378645

Epoch: 6| Step: 9
Training loss: 2.1665899753570557
Validation loss: 2.627390807674777

Epoch: 6| Step: 10
Training loss: 2.659498691558838
Validation loss: 2.6290037144896803

Epoch: 6| Step: 11
Training loss: 3.1276907920837402
Validation loss: 2.6220959591609176

Epoch: 6| Step: 12
Training loss: 1.9168555736541748
Validation loss: 2.6218087750096477

Epoch: 6| Step: 13
Training loss: 2.794261932373047
Validation loss: 2.6307727957284577

Epoch: 46| Step: 0
Training loss: 3.5557968616485596
Validation loss: 2.6252273897970877

Epoch: 6| Step: 1
Training loss: 2.585183620452881
Validation loss: 2.619653114708521

Epoch: 6| Step: 2
Training loss: 2.7054076194763184
Validation loss: 2.620560848584739

Epoch: 6| Step: 3
Training loss: 2.8295793533325195
Validation loss: 2.6149537332596315

Epoch: 6| Step: 4
Training loss: 2.1359689235687256
Validation loss: 2.618279359673941

Epoch: 6| Step: 5
Training loss: 2.8996684551239014
Validation loss: 2.621584476963166

Epoch: 6| Step: 6
Training loss: 3.3615500926971436
Validation loss: 2.617657812692786

Epoch: 6| Step: 7
Training loss: 2.781951904296875
Validation loss: 2.6111019503685737

Epoch: 6| Step: 8
Training loss: 2.3410000801086426
Validation loss: 2.604701477994201

Epoch: 6| Step: 9
Training loss: 2.915529251098633
Validation loss: 2.601986221087876

Epoch: 6| Step: 10
Training loss: 2.259697437286377
Validation loss: 2.5997910499572754

Epoch: 6| Step: 11
Training loss: 2.4560742378234863
Validation loss: 2.5969551173589562

Epoch: 6| Step: 12
Training loss: 2.9002115726470947
Validation loss: 2.599518632376066

Epoch: 6| Step: 13
Training loss: 3.201310873031616
Validation loss: 2.5937355667032223

Epoch: 47| Step: 0
Training loss: 3.1353516578674316
Validation loss: 2.5999159325835524

Epoch: 6| Step: 1
Training loss: 2.206961154937744
Validation loss: 2.610891103744507

Epoch: 6| Step: 2
Training loss: 2.821587562561035
Validation loss: 2.6017684603250153

Epoch: 6| Step: 3
Training loss: 4.11781120300293
Validation loss: 2.5943222814990627

Epoch: 6| Step: 4
Training loss: 3.1465702056884766
Validation loss: 2.591497072609522

Epoch: 6| Step: 5
Training loss: 2.325127601623535
Validation loss: 2.5926615781681512

Epoch: 6| Step: 6
Training loss: 2.3083982467651367
Validation loss: 2.591565662814725

Epoch: 6| Step: 7
Training loss: 3.469163179397583
Validation loss: 2.5896302230896486

Epoch: 6| Step: 8
Training loss: 2.9328999519348145
Validation loss: 2.5913627532220658

Epoch: 6| Step: 9
Training loss: 2.4772326946258545
Validation loss: 2.5899546633484545

Epoch: 6| Step: 10
Training loss: 2.4273595809936523
Validation loss: 2.5890943029875397

Epoch: 6| Step: 11
Training loss: 1.9724647998809814
Validation loss: 2.5893178114327053

Epoch: 6| Step: 12
Training loss: 2.524757146835327
Validation loss: 2.5898709322816584

Epoch: 6| Step: 13
Training loss: 2.7695491313934326
Validation loss: 2.5906151520308627

Epoch: 48| Step: 0
Training loss: 2.959266185760498
Validation loss: 2.5860975634667183

Epoch: 6| Step: 1
Training loss: 3.087441921234131
Validation loss: 2.5948944860889065

Epoch: 6| Step: 2
Training loss: 2.237262725830078
Validation loss: 2.6023541048008907

Epoch: 6| Step: 3
Training loss: 2.684001922607422
Validation loss: 2.593636856284193

Epoch: 6| Step: 4
Training loss: 2.571831703186035
Validation loss: 2.5829864855735534

Epoch: 6| Step: 5
Training loss: 2.8557047843933105
Validation loss: 2.5861688583127913

Epoch: 6| Step: 6
Training loss: 2.3747048377990723
Validation loss: 2.5816112667001705

Epoch: 6| Step: 7
Training loss: 2.348938465118408
Validation loss: 2.5824785027452695

Epoch: 6| Step: 8
Training loss: 2.9223198890686035
Validation loss: 2.582316029456354

Epoch: 6| Step: 9
Training loss: 2.1456127166748047
Validation loss: 2.5812829207348567

Epoch: 6| Step: 10
Training loss: 3.484891653060913
Validation loss: 2.5819727272115727

Epoch: 6| Step: 11
Training loss: 2.9720683097839355
Validation loss: 2.5840518474578857

Epoch: 6| Step: 12
Training loss: 3.301694631576538
Validation loss: 2.587594662943194

Epoch: 6| Step: 13
Training loss: 2.51849627494812
Validation loss: 2.5838566800599456

Epoch: 49| Step: 0
Training loss: 3.0491414070129395
Validation loss: 2.5874067634664555

Epoch: 6| Step: 1
Training loss: 2.8088767528533936
Validation loss: 2.5815477678852696

Epoch: 6| Step: 2
Training loss: 2.5942647457122803
Validation loss: 2.5832170312122633

Epoch: 6| Step: 3
Training loss: 2.6361770629882812
Validation loss: 2.580381316523398

Epoch: 6| Step: 4
Training loss: 2.6433801651000977
Validation loss: 2.5792236225579375

Epoch: 6| Step: 5
Training loss: 2.4546871185302734
Validation loss: 2.576492868443971

Epoch: 6| Step: 6
Training loss: 2.0124282836914062
Validation loss: 2.5764635916679137

Epoch: 6| Step: 7
Training loss: 2.948430299758911
Validation loss: 2.582134673672338

Epoch: 6| Step: 8
Training loss: 2.735053062438965
Validation loss: 2.592088735231789

Epoch: 6| Step: 9
Training loss: 3.260303020477295
Validation loss: 2.604000509426158

Epoch: 6| Step: 10
Training loss: 2.8301472663879395
Validation loss: 2.602236824650918

Epoch: 6| Step: 11
Training loss: 2.9566650390625
Validation loss: 2.591317448564755

Epoch: 6| Step: 12
Training loss: 2.670344352722168
Validation loss: 2.58358177574732

Epoch: 6| Step: 13
Training loss: 3.088958501815796
Validation loss: 2.577596354228194

Epoch: 50| Step: 0
Training loss: 1.3125271797180176
Validation loss: 2.5696003949770363

Epoch: 6| Step: 1
Training loss: 2.3888168334960938
Validation loss: 2.5651277547241538

Epoch: 6| Step: 2
Training loss: 2.9403085708618164
Validation loss: 2.5705080109257854

Epoch: 6| Step: 3
Training loss: 2.9262609481811523
Validation loss: 2.5728787709307928

Epoch: 6| Step: 4
Training loss: 2.7572073936462402
Validation loss: 2.5692082092326176

Epoch: 6| Step: 5
Training loss: 2.951434850692749
Validation loss: 2.565947640326715

Epoch: 6| Step: 6
Training loss: 2.6430554389953613
Validation loss: 2.5656766865843084

Epoch: 6| Step: 7
Training loss: 2.9160561561584473
Validation loss: 2.5790638821099394

Epoch: 6| Step: 8
Training loss: 2.380112886428833
Validation loss: 2.578280528386434

Epoch: 6| Step: 9
Training loss: 3.561981439590454
Validation loss: 2.5892260215615712

Epoch: 6| Step: 10
Training loss: 2.8391590118408203
Validation loss: 2.5833703061585784

Epoch: 6| Step: 11
Training loss: 3.064283609390259
Validation loss: 2.583448351070445

Epoch: 6| Step: 12
Training loss: 3.0986199378967285
Validation loss: 2.5764958602125927

Epoch: 6| Step: 13
Training loss: 2.65657901763916
Validation loss: 2.5712019141002367

Epoch: 51| Step: 0
Training loss: 2.95512056350708
Validation loss: 2.56488601879407

Epoch: 6| Step: 1
Training loss: 2.8422422409057617
Validation loss: 2.5617549419403076

Epoch: 6| Step: 2
Training loss: 2.835425615310669
Validation loss: 2.55857575837002

Epoch: 6| Step: 3
Training loss: 2.668645143508911
Validation loss: 2.5563042548394974

Epoch: 6| Step: 4
Training loss: 3.2397284507751465
Validation loss: 2.5497519149575183

Epoch: 6| Step: 5
Training loss: 2.582340955734253
Validation loss: 2.5532305317540325

Epoch: 6| Step: 6
Training loss: 2.663484573364258
Validation loss: 2.5526574555263726

Epoch: 6| Step: 7
Training loss: 2.5950090885162354
Validation loss: 2.5528183701217815

Epoch: 6| Step: 8
Training loss: 2.4747233390808105
Validation loss: 2.5550607712038103

Epoch: 6| Step: 9
Training loss: 3.4763436317443848
Validation loss: 2.5603187263652845

Epoch: 6| Step: 10
Training loss: 2.7289633750915527
Validation loss: 2.55555473860874

Epoch: 6| Step: 11
Training loss: 2.5734784603118896
Validation loss: 2.5573751413693993

Epoch: 6| Step: 12
Training loss: 2.633122444152832
Validation loss: 2.562441010628977

Epoch: 6| Step: 13
Training loss: 1.385206937789917
Validation loss: 2.560135796505918

Epoch: 52| Step: 0
Training loss: 2.5480949878692627
Validation loss: 2.549457662849016

Epoch: 6| Step: 1
Training loss: 2.5507423877716064
Validation loss: 2.5489787901601484

Epoch: 6| Step: 2
Training loss: 3.34085750579834
Validation loss: 2.5606868036331667

Epoch: 6| Step: 3
Training loss: 3.0006790161132812
Validation loss: 2.582090139389038

Epoch: 6| Step: 4
Training loss: 3.2469730377197266
Validation loss: 2.5906063459252797

Epoch: 6| Step: 5
Training loss: 1.817765235900879
Validation loss: 2.6143547719524753

Epoch: 6| Step: 6
Training loss: 2.600360631942749
Validation loss: 2.624783305711644

Epoch: 6| Step: 7
Training loss: 2.579056739807129
Validation loss: 2.617796831233527

Epoch: 6| Step: 8
Training loss: 3.175262928009033
Validation loss: 2.586216136973391

Epoch: 6| Step: 9
Training loss: 2.438051700592041
Validation loss: 2.5615578210482033

Epoch: 6| Step: 10
Training loss: 2.5522475242614746
Validation loss: 2.560985824113251

Epoch: 6| Step: 11
Training loss: 3.150386333465576
Validation loss: 2.5555229289557344

Epoch: 6| Step: 12
Training loss: 2.230299234390259
Validation loss: 2.549902880063621

Epoch: 6| Step: 13
Training loss: 3.6442158222198486
Validation loss: 2.548017433894578

Epoch: 53| Step: 0
Training loss: 2.887528657913208
Validation loss: 2.5526834636606197

Epoch: 6| Step: 1
Training loss: 2.777971029281616
Validation loss: 2.5519839909768876

Epoch: 6| Step: 2
Training loss: 2.7526066303253174
Validation loss: 2.5436927144245436

Epoch: 6| Step: 3
Training loss: 3.981334686279297
Validation loss: 2.5505662374599005

Epoch: 6| Step: 4
Training loss: 2.212127208709717
Validation loss: 2.545791064539263

Epoch: 6| Step: 5
Training loss: 3.5811057090759277
Validation loss: 2.5441725587332122

Epoch: 6| Step: 6
Training loss: 2.7036635875701904
Validation loss: 2.547973863540157

Epoch: 6| Step: 7
Training loss: 1.9221901893615723
Validation loss: 2.5406655726894254

Epoch: 6| Step: 8
Training loss: 1.944674015045166
Validation loss: 2.5427795456301783

Epoch: 6| Step: 9
Training loss: 1.8955397605895996
Validation loss: 2.5435992466506137

Epoch: 6| Step: 10
Training loss: 2.4231810569763184
Validation loss: 2.540015833352202

Epoch: 6| Step: 11
Training loss: 3.151865005493164
Validation loss: 2.5523560611150597

Epoch: 6| Step: 12
Training loss: 2.972259998321533
Validation loss: 2.550228429097001

Epoch: 6| Step: 13
Training loss: 3.1561474800109863
Validation loss: 2.553260346894623

Epoch: 54| Step: 0
Training loss: 2.885241746902466
Validation loss: 2.5579590669242283

Epoch: 6| Step: 1
Training loss: 2.4804701805114746
Validation loss: 2.5523582402096

Epoch: 6| Step: 2
Training loss: 3.0686798095703125
Validation loss: 2.542906174095728

Epoch: 6| Step: 3
Training loss: 3.2935256958007812
Validation loss: 2.5387294574450423

Epoch: 6| Step: 4
Training loss: 2.8499484062194824
Validation loss: 2.5338734734442925

Epoch: 6| Step: 5
Training loss: 2.3351972103118896
Validation loss: 2.536576060838597

Epoch: 6| Step: 6
Training loss: 2.010399341583252
Validation loss: 2.532779524403234

Epoch: 6| Step: 7
Training loss: 2.5841236114501953
Validation loss: 2.536460148390903

Epoch: 6| Step: 8
Training loss: 2.7716877460479736
Validation loss: 2.5333139947665635

Epoch: 6| Step: 9
Training loss: 2.4744272232055664
Validation loss: 2.530079241721861

Epoch: 6| Step: 10
Training loss: 2.9544880390167236
Validation loss: 2.5309697120420394

Epoch: 6| Step: 11
Training loss: 2.8736910820007324
Validation loss: 2.5308182111350437

Epoch: 6| Step: 12
Training loss: 2.5459072589874268
Validation loss: 2.527416334357313

Epoch: 6| Step: 13
Training loss: 2.956667184829712
Validation loss: 2.5220364319380892

Epoch: 55| Step: 0
Training loss: 2.5735888481140137
Validation loss: 2.52210678849169

Epoch: 6| Step: 1
Training loss: 2.005526065826416
Validation loss: 2.5233590884875228

Epoch: 6| Step: 2
Training loss: 3.5352532863616943
Validation loss: 2.524005630964874

Epoch: 6| Step: 3
Training loss: 3.027163028717041
Validation loss: 2.5235206721931376

Epoch: 6| Step: 4
Training loss: 2.342595100402832
Validation loss: 2.531456883235644

Epoch: 6| Step: 5
Training loss: 2.8524537086486816
Validation loss: 2.538125730329944

Epoch: 6| Step: 6
Training loss: 2.9301040172576904
Validation loss: 2.5483828411307385

Epoch: 6| Step: 7
Training loss: 2.8306427001953125
Validation loss: 2.54117759068807

Epoch: 6| Step: 8
Training loss: 2.7830557823181152
Validation loss: 2.5344547148673766

Epoch: 6| Step: 9
Training loss: 2.8464386463165283
Validation loss: 2.537289152863205

Epoch: 6| Step: 10
Training loss: 2.7942886352539062
Validation loss: 2.538004590618995

Epoch: 6| Step: 11
Training loss: 2.541506767272949
Validation loss: 2.5287052123777327

Epoch: 6| Step: 12
Training loss: 2.190028429031372
Validation loss: 2.52316855102457

Epoch: 6| Step: 13
Training loss: 2.703840732574463
Validation loss: 2.528230078758732

Epoch: 56| Step: 0
Training loss: 3.5114428997039795
Validation loss: 2.520115275536814

Epoch: 6| Step: 1
Training loss: 2.728764772415161
Validation loss: 2.5128661483846684

Epoch: 6| Step: 2
Training loss: 2.2530031204223633
Validation loss: 2.51130578594823

Epoch: 6| Step: 3
Training loss: 2.5374562740325928
Validation loss: 2.512653302120906

Epoch: 6| Step: 4
Training loss: 2.5945773124694824
Validation loss: 2.516733543847197

Epoch: 6| Step: 5
Training loss: 2.049684524536133
Validation loss: 2.515230481342603

Epoch: 6| Step: 6
Training loss: 3.471099376678467
Validation loss: 2.518749888225268

Epoch: 6| Step: 7
Training loss: 2.870530128479004
Validation loss: 2.517836691230856

Epoch: 6| Step: 8
Training loss: 3.081021547317505
Validation loss: 2.5182437537818827

Epoch: 6| Step: 9
Training loss: 1.8586418628692627
Validation loss: 2.5203843911488852

Epoch: 6| Step: 10
Training loss: 3.267882823944092
Validation loss: 2.524760846168764

Epoch: 6| Step: 11
Training loss: 2.41548490524292
Validation loss: 2.517592094277823

Epoch: 6| Step: 12
Training loss: 2.695080041885376
Validation loss: 2.5179069811298

Epoch: 6| Step: 13
Training loss: 2.45373272895813
Validation loss: 2.518910987402803

Epoch: 57| Step: 0
Training loss: 3.255753755569458
Validation loss: 2.5154973255690707

Epoch: 6| Step: 1
Training loss: 2.3505735397338867
Validation loss: 2.515941796764251

Epoch: 6| Step: 2
Training loss: 1.7522549629211426
Validation loss: 2.5179639682974866

Epoch: 6| Step: 3
Training loss: 3.371394395828247
Validation loss: 2.524725603800948

Epoch: 6| Step: 4
Training loss: 2.4115335941314697
Validation loss: 2.5297853408321256

Epoch: 6| Step: 5
Training loss: 2.756984233856201
Validation loss: 2.5278467901291384

Epoch: 6| Step: 6
Training loss: 2.604193687438965
Validation loss: 2.5325912660168064

Epoch: 6| Step: 7
Training loss: 2.445434808731079
Validation loss: 2.518243597399804

Epoch: 6| Step: 8
Training loss: 1.915265440940857
Validation loss: 2.5081043294681016

Epoch: 6| Step: 9
Training loss: 3.2111804485321045
Validation loss: 2.5069284580087148

Epoch: 6| Step: 10
Training loss: 2.8961310386657715
Validation loss: 2.5058207793902327

Epoch: 6| Step: 11
Training loss: 3.1846070289611816
Validation loss: 2.5038732021085677

Epoch: 6| Step: 12
Training loss: 2.4211342334747314
Validation loss: 2.508056430406468

Epoch: 6| Step: 13
Training loss: 3.6609790325164795
Validation loss: 2.5104542240019767

Epoch: 58| Step: 0
Training loss: 2.436196804046631
Validation loss: 2.5103486814806537

Epoch: 6| Step: 1
Training loss: 2.3369874954223633
Validation loss: 2.5101366786546606

Epoch: 6| Step: 2
Training loss: 2.4255175590515137
Validation loss: 2.5057613054911294

Epoch: 6| Step: 3
Training loss: 2.6143667697906494
Validation loss: 2.505245119012812

Epoch: 6| Step: 4
Training loss: 2.7049496173858643
Validation loss: 2.505935138271701

Epoch: 6| Step: 5
Training loss: 3.6368348598480225
Validation loss: 2.499483989131066

Epoch: 6| Step: 6
Training loss: 2.283707618713379
Validation loss: 2.506690812367265

Epoch: 6| Step: 7
Training loss: 2.87778902053833
Validation loss: 2.5074714999045096

Epoch: 6| Step: 8
Training loss: 3.091769218444824
Validation loss: 2.5069713387438046

Epoch: 6| Step: 9
Training loss: 2.651092290878296
Validation loss: 2.5156197778640257

Epoch: 6| Step: 10
Training loss: 2.5431339740753174
Validation loss: 2.527883247662616

Epoch: 6| Step: 11
Training loss: 2.381986618041992
Validation loss: 2.5248918507688787

Epoch: 6| Step: 12
Training loss: 2.997957706451416
Validation loss: 2.51385417292195

Epoch: 6| Step: 13
Training loss: 2.957449197769165
Validation loss: 2.5129172109788462

Epoch: 59| Step: 0
Training loss: 2.3286564350128174
Validation loss: 2.507823682600452

Epoch: 6| Step: 1
Training loss: 2.532411813735962
Validation loss: 2.503633524781914

Epoch: 6| Step: 2
Training loss: 2.9888319969177246
Validation loss: 2.5056487744854343

Epoch: 6| Step: 3
Training loss: 3.1597728729248047
Validation loss: 2.49852127926324

Epoch: 6| Step: 4
Training loss: 2.417544364929199
Validation loss: 2.500703993663993

Epoch: 6| Step: 5
Training loss: 2.990668535232544
Validation loss: 2.4905320982779227

Epoch: 6| Step: 6
Training loss: 2.621058702468872
Validation loss: 2.496314969114078

Epoch: 6| Step: 7
Training loss: 3.2420361042022705
Validation loss: 2.4946230919130388

Epoch: 6| Step: 8
Training loss: 2.7257347106933594
Validation loss: 2.4927256722604074

Epoch: 6| Step: 9
Training loss: 2.500985622406006
Validation loss: 2.4939401380477415

Epoch: 6| Step: 10
Training loss: 2.89717435836792
Validation loss: 2.4935317398399435

Epoch: 6| Step: 11
Training loss: 2.304447650909424
Validation loss: 2.4902245306199595

Epoch: 6| Step: 12
Training loss: 2.34993839263916
Validation loss: 2.488332958631618

Epoch: 6| Step: 13
Training loss: 2.520045518875122
Validation loss: 2.497297174187117

Epoch: 60| Step: 0
Training loss: 2.8414225578308105
Validation loss: 2.4952783097503004

Epoch: 6| Step: 1
Training loss: 2.7046093940734863
Validation loss: 2.5027046511250157

Epoch: 6| Step: 2
Training loss: 2.6472063064575195
Validation loss: 2.5067221631285963

Epoch: 6| Step: 3
Training loss: 2.089139938354492
Validation loss: 2.5103239756758495

Epoch: 6| Step: 4
Training loss: 2.7117209434509277
Validation loss: 2.4985352793047504

Epoch: 6| Step: 5
Training loss: 2.765028238296509
Validation loss: 2.494607786978445

Epoch: 6| Step: 6
Training loss: 2.531883716583252
Validation loss: 2.5132992165063017

Epoch: 6| Step: 7
Training loss: 3.2974603176116943
Validation loss: 2.562891901180308

Epoch: 6| Step: 8
Training loss: 2.4551596641540527
Validation loss: 2.563804349591655

Epoch: 6| Step: 9
Training loss: 2.724600315093994
Validation loss: 2.5690790709628852

Epoch: 6| Step: 10
Training loss: 2.9345600605010986
Validation loss: 2.570591708665253

Epoch: 6| Step: 11
Training loss: 2.6594200134277344
Validation loss: 2.554821091313516

Epoch: 6| Step: 12
Training loss: 2.600231170654297
Validation loss: 2.5517998280063754

Epoch: 6| Step: 13
Training loss: 3.2538552284240723
Validation loss: 2.5522866146538847

Epoch: 61| Step: 0
Training loss: 2.832887887954712
Validation loss: 2.5658237447020826

Epoch: 6| Step: 1
Training loss: 2.3193318843841553
Validation loss: 2.569033186922791

Epoch: 6| Step: 2
Training loss: 2.5583159923553467
Validation loss: 2.5805915376191497

Epoch: 6| Step: 3
Training loss: 3.1243948936462402
Validation loss: 2.5516256619525213

Epoch: 6| Step: 4
Training loss: 1.8791230916976929
Validation loss: 2.550595668054396

Epoch: 6| Step: 5
Training loss: 3.382072925567627
Validation loss: 2.548552692577403

Epoch: 6| Step: 6
Training loss: 2.9659616947174072
Validation loss: 2.5462192925073768

Epoch: 6| Step: 7
Training loss: 3.0751614570617676
Validation loss: 2.540005640317035

Epoch: 6| Step: 8
Training loss: 3.358774423599243
Validation loss: 2.5415252844492593

Epoch: 6| Step: 9
Training loss: 1.8797096014022827
Validation loss: 2.547830299664569

Epoch: 6| Step: 10
Training loss: 3.0339908599853516
Validation loss: 2.5432261523380073

Epoch: 6| Step: 11
Training loss: 2.1668057441711426
Validation loss: 2.5457418375117804

Epoch: 6| Step: 12
Training loss: 2.439225196838379
Validation loss: 2.5455974865985174

Epoch: 6| Step: 13
Training loss: 3.3745858669281006
Validation loss: 2.5435676831071095

Epoch: 62| Step: 0
Training loss: 2.7317328453063965
Validation loss: 2.5417365925286406

Epoch: 6| Step: 1
Training loss: 1.9973883628845215
Validation loss: 2.5444245235894316

Epoch: 6| Step: 2
Training loss: 2.5035414695739746
Validation loss: 2.543333202280024

Epoch: 6| Step: 3
Training loss: 2.0897650718688965
Validation loss: 2.5397792067579044

Epoch: 6| Step: 4
Training loss: 2.3314337730407715
Validation loss: 2.5411408075722317

Epoch: 6| Step: 5
Training loss: 3.0803399085998535
Validation loss: 2.539000367605558

Epoch: 6| Step: 6
Training loss: 3.5510852336883545
Validation loss: 2.5392691012351745

Epoch: 6| Step: 7
Training loss: 2.5414223670959473
Validation loss: 2.536899102631436

Epoch: 6| Step: 8
Training loss: 2.2812342643737793
Validation loss: 2.538055581431235

Epoch: 6| Step: 9
Training loss: 2.7166287899017334
Validation loss: 2.5378619573449575

Epoch: 6| Step: 10
Training loss: 3.6769704818725586
Validation loss: 2.542659672357703

Epoch: 6| Step: 11
Training loss: 2.4175448417663574
Validation loss: 2.5494037007772796

Epoch: 6| Step: 12
Training loss: 2.7203495502471924
Validation loss: 2.5481317889305855

Epoch: 6| Step: 13
Training loss: 3.8595080375671387
Validation loss: 2.5511514730350946

Epoch: 63| Step: 0
Training loss: 2.982217311859131
Validation loss: 2.5566742497105754

Epoch: 6| Step: 1
Training loss: 2.3913779258728027
Validation loss: 2.5461164648814867

Epoch: 6| Step: 2
Training loss: 2.5674352645874023
Validation loss: 2.5429147725464194

Epoch: 6| Step: 3
Training loss: 2.3480224609375
Validation loss: 2.5384290910536245

Epoch: 6| Step: 4
Training loss: 2.1631369590759277
Validation loss: 2.542277177174886

Epoch: 6| Step: 5
Training loss: 1.9542804956436157
Validation loss: 2.552033696123349

Epoch: 6| Step: 6
Training loss: 3.234358072280884
Validation loss: 2.5557720481708484

Epoch: 6| Step: 7
Training loss: 3.138936996459961
Validation loss: 2.5627939983080794

Epoch: 6| Step: 8
Training loss: 2.4722681045532227
Validation loss: 2.55183401671789

Epoch: 6| Step: 9
Training loss: 2.548095226287842
Validation loss: 2.528020728018976

Epoch: 6| Step: 10
Training loss: 3.4289822578430176
Validation loss: 2.5257224062437653

Epoch: 6| Step: 11
Training loss: 2.529290199279785
Validation loss: 2.5210420598265944

Epoch: 6| Step: 12
Training loss: 2.72963809967041
Validation loss: 2.522254915647609

Epoch: 6| Step: 13
Training loss: 4.017427921295166
Validation loss: 2.521318688187548

Epoch: 64| Step: 0
Training loss: 2.4450953006744385
Validation loss: 2.5268061750678608

Epoch: 6| Step: 1
Training loss: 2.9315762519836426
Validation loss: 2.5250244602080314

Epoch: 6| Step: 2
Training loss: 3.2764906883239746
Validation loss: 2.5307110612110426

Epoch: 6| Step: 3
Training loss: 3.406024932861328
Validation loss: 2.532482624053955

Epoch: 6| Step: 4
Training loss: 2.383605718612671
Validation loss: 2.531407453680551

Epoch: 6| Step: 5
Training loss: 2.8944623470306396
Validation loss: 2.5270256175789783

Epoch: 6| Step: 6
Training loss: 2.3829262256622314
Validation loss: 2.5239913412319717

Epoch: 6| Step: 7
Training loss: 2.862856388092041
Validation loss: 2.5153210086207234

Epoch: 6| Step: 8
Training loss: 2.3791756629943848
Validation loss: 2.5206283318099154

Epoch: 6| Step: 9
Training loss: 2.8159725666046143
Validation loss: 2.511893169854277

Epoch: 6| Step: 10
Training loss: 2.381600856781006
Validation loss: 2.5178673344273723

Epoch: 6| Step: 11
Training loss: 2.7208290100097656
Validation loss: 2.5239432857882593

Epoch: 6| Step: 12
Training loss: 2.144698143005371
Validation loss: 2.5228164836924565

Epoch: 6| Step: 13
Training loss: 3.2587811946868896
Validation loss: 2.493039108091785

Epoch: 65| Step: 0
Training loss: 2.450042247772217
Validation loss: 2.4929999920629684

Epoch: 6| Step: 1
Training loss: 3.5816001892089844
Validation loss: 2.537248916523431

Epoch: 6| Step: 2
Training loss: 2.8043885231018066
Validation loss: 2.532317307687575

Epoch: 6| Step: 3
Training loss: 2.754218101501465
Validation loss: 2.5095701217651367

Epoch: 6| Step: 4
Training loss: 3.1021533012390137
Validation loss: 2.5008971947495655

Epoch: 6| Step: 5
Training loss: 2.6345555782318115
Validation loss: 2.507195677808536

Epoch: 6| Step: 6
Training loss: 2.4586129188537598
Validation loss: 2.5126888444346767

Epoch: 6| Step: 7
Training loss: 1.9960983991622925
Validation loss: 2.518479078046737

Epoch: 6| Step: 8
Training loss: 1.885647177696228
Validation loss: 2.526363303584437

Epoch: 6| Step: 9
Training loss: 3.0919952392578125
Validation loss: 2.5233525973494335

Epoch: 6| Step: 10
Training loss: 2.648587703704834
Validation loss: 2.493472053158668

Epoch: 6| Step: 11
Training loss: 3.0988805294036865
Validation loss: 2.483637927680887

Epoch: 6| Step: 12
Training loss: 2.719848155975342
Validation loss: 2.493624251375916

Epoch: 6| Step: 13
Training loss: 2.8069140911102295
Validation loss: 2.4908286217720277

Epoch: 66| Step: 0
Training loss: 2.2572717666625977
Validation loss: 2.48467727117641

Epoch: 6| Step: 1
Training loss: 3.3147692680358887
Validation loss: 2.4770694894175374

Epoch: 6| Step: 2
Training loss: 3.6032769680023193
Validation loss: 2.471586519672025

Epoch: 6| Step: 3
Training loss: 2.95925235748291
Validation loss: 2.462693155452769

Epoch: 6| Step: 4
Training loss: 2.304206609725952
Validation loss: 2.4623418828492523

Epoch: 6| Step: 5
Training loss: 2.3045971393585205
Validation loss: 2.457523453620172

Epoch: 6| Step: 6
Training loss: 2.6501824855804443
Validation loss: 2.45183805752826

Epoch: 6| Step: 7
Training loss: 2.3455512523651123
Validation loss: 2.447501387647403

Epoch: 6| Step: 8
Training loss: 2.529724597930908
Validation loss: 2.4485489181292954

Epoch: 6| Step: 9
Training loss: 2.1853561401367188
Validation loss: 2.456207162590437

Epoch: 6| Step: 10
Training loss: 2.000087261199951
Validation loss: 2.466432986720916

Epoch: 6| Step: 11
Training loss: 2.9354183673858643
Validation loss: 2.4803152673987934

Epoch: 6| Step: 12
Training loss: 3.3855810165405273
Validation loss: 2.4698968574564946

Epoch: 6| Step: 13
Training loss: 2.9615707397460938
Validation loss: 2.4537315291743123

Epoch: 67| Step: 0
Training loss: 2.395354747772217
Validation loss: 2.441400712536227

Epoch: 6| Step: 1
Training loss: 2.9827566146850586
Validation loss: 2.4384297247855895

Epoch: 6| Step: 2
Training loss: 2.0895493030548096
Validation loss: 2.4382670156417356

Epoch: 6| Step: 3
Training loss: 3.3368568420410156
Validation loss: 2.438754686745264

Epoch: 6| Step: 4
Training loss: 2.6480510234832764
Validation loss: 2.44507029492368

Epoch: 6| Step: 5
Training loss: 2.6687960624694824
Validation loss: 2.4408861334605882

Epoch: 6| Step: 6
Training loss: 2.454068899154663
Validation loss: 2.44349048214574

Epoch: 6| Step: 7
Training loss: 2.3882696628570557
Validation loss: 2.441541043660974

Epoch: 6| Step: 8
Training loss: 2.7052671909332275
Validation loss: 2.437751511091827

Epoch: 6| Step: 9
Training loss: 2.555509567260742
Validation loss: 2.440283957348075

Epoch: 6| Step: 10
Training loss: 2.148770332336426
Validation loss: 2.4361181669337775

Epoch: 6| Step: 11
Training loss: 2.5364861488342285
Validation loss: 2.433524908558015

Epoch: 6| Step: 12
Training loss: 3.3054089546203613
Validation loss: 2.433356649132185

Epoch: 6| Step: 13
Training loss: 3.4902617931365967
Validation loss: 2.432542439429991

Epoch: 68| Step: 0
Training loss: 1.4608066082000732
Validation loss: 2.428830251898817

Epoch: 6| Step: 1
Training loss: 3.4897165298461914
Validation loss: 2.429798574857814

Epoch: 6| Step: 2
Training loss: 2.392487049102783
Validation loss: 2.429503133220057

Epoch: 6| Step: 3
Training loss: 2.1400439739227295
Validation loss: 2.4290823577552714

Epoch: 6| Step: 4
Training loss: 2.744413137435913
Validation loss: 2.429065424908874

Epoch: 6| Step: 5
Training loss: 2.716515064239502
Validation loss: 2.430108498501521

Epoch: 6| Step: 6
Training loss: 2.6370391845703125
Validation loss: 2.435778530695105

Epoch: 6| Step: 7
Training loss: 3.0868937969207764
Validation loss: 2.4369509348305325

Epoch: 6| Step: 8
Training loss: 2.9711802005767822
Validation loss: 2.432529334099062

Epoch: 6| Step: 9
Training loss: 3.2128114700317383
Validation loss: 2.434888529521163

Epoch: 6| Step: 10
Training loss: 3.0642056465148926
Validation loss: 2.436099595921014

Epoch: 6| Step: 11
Training loss: 2.5890517234802246
Validation loss: 2.425870854367492

Epoch: 6| Step: 12
Training loss: 1.9620263576507568
Validation loss: 2.4323079560392644

Epoch: 6| Step: 13
Training loss: 2.8724703788757324
Validation loss: 2.4322998446802937

Epoch: 69| Step: 0
Training loss: 2.398253917694092
Validation loss: 2.4310415470471947

Epoch: 6| Step: 1
Training loss: 3.0463218688964844
Validation loss: 2.4232688488498813

Epoch: 6| Step: 2
Training loss: 2.4422411918640137
Validation loss: 2.42415960373417

Epoch: 6| Step: 3
Training loss: 2.0734095573425293
Validation loss: 2.4261651398033224

Epoch: 6| Step: 4
Training loss: 2.0761728286743164
Validation loss: 2.4248781409314883

Epoch: 6| Step: 5
Training loss: 3.520824432373047
Validation loss: 2.424437033232822

Epoch: 6| Step: 6
Training loss: 2.9792189598083496
Validation loss: 2.4274708686336393

Epoch: 6| Step: 7
Training loss: 3.241042375564575
Validation loss: 2.4305677926668556

Epoch: 6| Step: 8
Training loss: 2.7843661308288574
Validation loss: 2.4263614300758607

Epoch: 6| Step: 9
Training loss: 2.679802417755127
Validation loss: 2.425155028220146

Epoch: 6| Step: 10
Training loss: 2.223456859588623
Validation loss: 2.4362115757439726

Epoch: 6| Step: 11
Training loss: 2.956413745880127
Validation loss: 2.4383764395149807

Epoch: 6| Step: 12
Training loss: 2.467042922973633
Validation loss: 2.4515884948033158

Epoch: 6| Step: 13
Training loss: 1.9799573421478271
Validation loss: 2.441999755879884

Epoch: 70| Step: 0
Training loss: 2.0795180797576904
Validation loss: 2.429961232728856

Epoch: 6| Step: 1
Training loss: 1.7862821817398071
Validation loss: 2.4313976995406614

Epoch: 6| Step: 2
Training loss: 3.0733041763305664
Validation loss: 2.4234570841635428

Epoch: 6| Step: 3
Training loss: 2.3684918880462646
Validation loss: 2.422698320881013

Epoch: 6| Step: 4
Training loss: 3.1771249771118164
Validation loss: 2.4242308614074544

Epoch: 6| Step: 5
Training loss: 3.0761899948120117
Validation loss: 2.4278025114408104

Epoch: 6| Step: 6
Training loss: 3.057711362838745
Validation loss: 2.427486006931592

Epoch: 6| Step: 7
Training loss: 2.7561569213867188
Validation loss: 2.4304556692800214

Epoch: 6| Step: 8
Training loss: 3.093022584915161
Validation loss: 2.432557826401085

Epoch: 6| Step: 9
Training loss: 2.5949270725250244
Validation loss: 2.431529812915351

Epoch: 6| Step: 10
Training loss: 2.7864184379577637
Validation loss: 2.429855667134767

Epoch: 6| Step: 11
Training loss: 2.0390191078186035
Validation loss: 2.419932452581262

Epoch: 6| Step: 12
Training loss: 2.3829751014709473
Validation loss: 2.411830520117155

Epoch: 6| Step: 13
Training loss: 3.23284912109375
Validation loss: 2.421676212741483

Epoch: 71| Step: 0
Training loss: 2.411698341369629
Validation loss: 2.4521042634082097

Epoch: 6| Step: 1
Training loss: 2.588345527648926
Validation loss: 2.4558727331058954

Epoch: 6| Step: 2
Training loss: 3.384272336959839
Validation loss: 2.476098552826912

Epoch: 6| Step: 3
Training loss: 2.7212696075439453
Validation loss: 2.487369506589828

Epoch: 6| Step: 4
Training loss: 2.76320481300354
Validation loss: 2.4908803380945677

Epoch: 6| Step: 5
Training loss: 3.0611114501953125
Validation loss: 2.4705760196972917

Epoch: 6| Step: 6
Training loss: 2.6768198013305664
Validation loss: 2.4264468864728044

Epoch: 6| Step: 7
Training loss: 2.6252946853637695
Validation loss: 2.421291735864455

Epoch: 6| Step: 8
Training loss: 3.1407229900360107
Validation loss: 2.4139663250215593

Epoch: 6| Step: 9
Training loss: 2.6086502075195312
Validation loss: 2.4193088341784734

Epoch: 6| Step: 10
Training loss: 1.8843437433242798
Validation loss: 2.431231200054128

Epoch: 6| Step: 11
Training loss: 2.6815922260284424
Validation loss: 2.42824899765753

Epoch: 6| Step: 12
Training loss: 2.555370330810547
Validation loss: 2.4305848690771286

Epoch: 6| Step: 13
Training loss: 1.729788899421692
Validation loss: 2.4253246861119426

Epoch: 72| Step: 0
Training loss: 2.573700428009033
Validation loss: 2.4226689005410798

Epoch: 6| Step: 1
Training loss: 2.845973491668701
Validation loss: 2.4179468308725665

Epoch: 6| Step: 2
Training loss: 2.7038490772247314
Validation loss: 2.4129515694033716

Epoch: 6| Step: 3
Training loss: 3.2346413135528564
Validation loss: 2.415391342614287

Epoch: 6| Step: 4
Training loss: 2.9209723472595215
Validation loss: 2.411381180568408

Epoch: 6| Step: 5
Training loss: 2.338521718978882
Validation loss: 2.4174845372476885

Epoch: 6| Step: 6
Training loss: 2.8293824195861816
Validation loss: 2.4199964154151177

Epoch: 6| Step: 7
Training loss: 2.3014976978302
Validation loss: 2.439524869765005

Epoch: 6| Step: 8
Training loss: 2.4983325004577637
Validation loss: 2.458058467475317

Epoch: 6| Step: 9
Training loss: 2.866934299468994
Validation loss: 2.468306969570857

Epoch: 6| Step: 10
Training loss: 2.9496994018554688
Validation loss: 2.4442496966290217

Epoch: 6| Step: 11
Training loss: 2.4821202754974365
Validation loss: 2.433203781804731

Epoch: 6| Step: 12
Training loss: 1.8570516109466553
Validation loss: 2.423265669935493

Epoch: 6| Step: 13
Training loss: 2.8879716396331787
Validation loss: 2.4188699824835664

Epoch: 73| Step: 0
Training loss: 3.0723304748535156
Validation loss: 2.4181513529951855

Epoch: 6| Step: 1
Training loss: 2.908202648162842
Validation loss: 2.4130658898302304

Epoch: 6| Step: 2
Training loss: 1.7679246664047241
Validation loss: 2.418177427784089

Epoch: 6| Step: 3
Training loss: 2.7395291328430176
Validation loss: 2.4275009427019345

Epoch: 6| Step: 4
Training loss: 1.9346115589141846
Validation loss: 2.42914306476552

Epoch: 6| Step: 5
Training loss: 2.3641860485076904
Validation loss: 2.4315008732580368

Epoch: 6| Step: 6
Training loss: 2.8136396408081055
Validation loss: 2.429203810230378

Epoch: 6| Step: 7
Training loss: 2.345388174057007
Validation loss: 2.4304860381669897

Epoch: 6| Step: 8
Training loss: 2.746852397918701
Validation loss: 2.4249266885942027

Epoch: 6| Step: 9
Training loss: 2.553218364715576
Validation loss: 2.4229814288436726

Epoch: 6| Step: 10
Training loss: 3.832146406173706
Validation loss: 2.4209016010325444

Epoch: 6| Step: 11
Training loss: 2.8078885078430176
Validation loss: 2.414061107943135

Epoch: 6| Step: 12
Training loss: 2.775355815887451
Validation loss: 2.4105706240541194

Epoch: 6| Step: 13
Training loss: 2.1998467445373535
Validation loss: 2.4085022813530377

Epoch: 74| Step: 0
Training loss: 2.613067626953125
Validation loss: 2.415668277330296

Epoch: 6| Step: 1
Training loss: 2.1071646213531494
Validation loss: 2.4181286750301236

Epoch: 6| Step: 2
Training loss: 2.257265329360962
Validation loss: 2.4288769486129924

Epoch: 6| Step: 3
Training loss: 2.7186083793640137
Validation loss: 2.4305086251228087

Epoch: 6| Step: 4
Training loss: 2.474968194961548
Validation loss: 2.4419787468448764

Epoch: 6| Step: 5
Training loss: 2.019362449645996
Validation loss: 2.4536001361826414

Epoch: 6| Step: 6
Training loss: 4.163042068481445
Validation loss: 2.4413977669131373

Epoch: 6| Step: 7
Training loss: 2.4483652114868164
Validation loss: 2.42028594786121

Epoch: 6| Step: 8
Training loss: 2.706559419631958
Validation loss: 2.4131793642556794

Epoch: 6| Step: 9
Training loss: 2.906212091445923
Validation loss: 2.407366639824324

Epoch: 6| Step: 10
Training loss: 2.6884024143218994
Validation loss: 2.4022549454883864

Epoch: 6| Step: 11
Training loss: 2.7210049629211426
Validation loss: 2.402269155748429

Epoch: 6| Step: 12
Training loss: 2.501574993133545
Validation loss: 2.4042958444164646

Epoch: 6| Step: 13
Training loss: 2.6989402770996094
Validation loss: 2.4019697789222962

Epoch: 75| Step: 0
Training loss: 2.83315110206604
Validation loss: 2.4120435099447928

Epoch: 6| Step: 1
Training loss: 2.3306150436401367
Validation loss: 2.410025178745229

Epoch: 6| Step: 2
Training loss: 2.6202316284179688
Validation loss: 2.4024000834393244

Epoch: 6| Step: 3
Training loss: 3.475334882736206
Validation loss: 2.4037595820683304

Epoch: 6| Step: 4
Training loss: 2.6181411743164062
Validation loss: 2.4003274056219284

Epoch: 6| Step: 5
Training loss: 2.7581403255462646
Validation loss: 2.396024488633679

Epoch: 6| Step: 6
Training loss: 2.056065082550049
Validation loss: 2.399225322149133

Epoch: 6| Step: 7
Training loss: 3.0029830932617188
Validation loss: 2.3990463800327753

Epoch: 6| Step: 8
Training loss: 2.677616596221924
Validation loss: 2.4061865704033965

Epoch: 6| Step: 9
Training loss: 2.2456657886505127
Validation loss: 2.402620292478992

Epoch: 6| Step: 10
Training loss: 2.5341053009033203
Validation loss: 2.398760523847354

Epoch: 6| Step: 11
Training loss: 2.374342679977417
Validation loss: 2.3972298047875844

Epoch: 6| Step: 12
Training loss: 2.4870946407318115
Validation loss: 2.3958714956878335

Epoch: 6| Step: 13
Training loss: 3.0597212314605713
Validation loss: 2.398784278541483

Epoch: 76| Step: 0
Training loss: 2.6269121170043945
Validation loss: 2.4138753939700384

Epoch: 6| Step: 1
Training loss: 2.3240303993225098
Validation loss: 2.4380208394860707

Epoch: 6| Step: 2
Training loss: 3.5000267028808594
Validation loss: 2.4610009706148537

Epoch: 6| Step: 3
Training loss: 2.3363571166992188
Validation loss: 2.476618338656682

Epoch: 6| Step: 4
Training loss: 1.9203975200653076
Validation loss: 2.4483251340927614

Epoch: 6| Step: 5
Training loss: 3.173842191696167
Validation loss: 2.427748082786478

Epoch: 6| Step: 6
Training loss: 2.557868719100952
Validation loss: 2.4165684048847487

Epoch: 6| Step: 7
Training loss: 2.0506558418273926
Validation loss: 2.396091394526984

Epoch: 6| Step: 8
Training loss: 3.0151681900024414
Validation loss: 2.386114904957433

Epoch: 6| Step: 9
Training loss: 2.3720850944519043
Validation loss: 2.389662686214652

Epoch: 6| Step: 10
Training loss: 2.8915762901306152
Validation loss: 2.3890688829524542

Epoch: 6| Step: 11
Training loss: 2.472241163253784
Validation loss: 2.3897245007176555

Epoch: 6| Step: 12
Training loss: 2.741482973098755
Validation loss: 2.387799119436613

Epoch: 6| Step: 13
Training loss: 3.456839084625244
Validation loss: 2.3854167692122923

Epoch: 77| Step: 0
Training loss: 2.594449758529663
Validation loss: 2.383777731208391

Epoch: 6| Step: 1
Training loss: 2.2729902267456055
Validation loss: 2.3856869000260548

Epoch: 6| Step: 2
Training loss: 2.8325414657592773
Validation loss: 2.398859372702978

Epoch: 6| Step: 3
Training loss: 3.423794746398926
Validation loss: 2.4037801232389224

Epoch: 6| Step: 4
Training loss: 2.687986373901367
Validation loss: 2.421580481272872

Epoch: 6| Step: 5
Training loss: 2.04510235786438
Validation loss: 2.4460722938660653

Epoch: 6| Step: 6
Training loss: 2.191981077194214
Validation loss: 2.4617167544621292

Epoch: 6| Step: 7
Training loss: 2.336501121520996
Validation loss: 2.4524346115768596

Epoch: 6| Step: 8
Training loss: 2.656769037246704
Validation loss: 2.4200821461216098

Epoch: 6| Step: 9
Training loss: 2.067695140838623
Validation loss: 2.397338728750906

Epoch: 6| Step: 10
Training loss: 2.6913766860961914
Validation loss: 2.3909591423567904

Epoch: 6| Step: 11
Training loss: 2.5255017280578613
Validation loss: 2.37971217273384

Epoch: 6| Step: 12
Training loss: 3.7618370056152344
Validation loss: 2.3806031134820755

Epoch: 6| Step: 13
Training loss: 2.7853126525878906
Validation loss: 2.380057696373232

Epoch: 78| Step: 0
Training loss: 2.947873592376709
Validation loss: 2.3816865900511384

Epoch: 6| Step: 1
Training loss: 2.5169811248779297
Validation loss: 2.378686653670444

Epoch: 6| Step: 2
Training loss: 2.2542903423309326
Validation loss: 2.3835772083651636

Epoch: 6| Step: 3
Training loss: 2.2643051147460938
Validation loss: 2.382241961776569

Epoch: 6| Step: 4
Training loss: 3.476747989654541
Validation loss: 2.3877171611273162

Epoch: 6| Step: 5
Training loss: 3.235872745513916
Validation loss: 2.3915364819188274

Epoch: 6| Step: 6
Training loss: 2.94075608253479
Validation loss: 2.4024729574880292

Epoch: 6| Step: 7
Training loss: 2.5887906551361084
Validation loss: 2.4177522044028006

Epoch: 6| Step: 8
Training loss: 1.5890591144561768
Validation loss: 2.4268429920237553

Epoch: 6| Step: 9
Training loss: 2.488076686859131
Validation loss: 2.4270827744596746

Epoch: 6| Step: 10
Training loss: 2.2658908367156982
Validation loss: 2.4240462856908

Epoch: 6| Step: 11
Training loss: 2.626286506652832
Validation loss: 2.423495369572793

Epoch: 6| Step: 12
Training loss: 2.9908199310302734
Validation loss: 2.4220728310205604

Epoch: 6| Step: 13
Training loss: 2.721648693084717
Validation loss: 2.3981523744521605

Epoch: 79| Step: 0
Training loss: 2.2360424995422363
Validation loss: 2.3808682323783956

Epoch: 6| Step: 1
Training loss: 3.0764689445495605
Validation loss: 2.3774016211109776

Epoch: 6| Step: 2
Training loss: 3.2942094802856445
Validation loss: 2.3756513621217463

Epoch: 6| Step: 3
Training loss: 2.525902271270752
Validation loss: 2.374496254869687

Epoch: 6| Step: 4
Training loss: 2.799384593963623
Validation loss: 2.3791048449854695

Epoch: 6| Step: 5
Training loss: 2.24658465385437
Validation loss: 2.3752031121202695

Epoch: 6| Step: 6
Training loss: 2.788142204284668
Validation loss: 2.376320961982973

Epoch: 6| Step: 7
Training loss: 3.580085277557373
Validation loss: 2.370404117850847

Epoch: 6| Step: 8
Training loss: 2.992521047592163
Validation loss: 2.3729479056532665

Epoch: 6| Step: 9
Training loss: 2.691725254058838
Validation loss: 2.371659378851614

Epoch: 6| Step: 10
Training loss: 1.7678923606872559
Validation loss: 2.3752531928400837

Epoch: 6| Step: 11
Training loss: 1.510093092918396
Validation loss: 2.3865385901543403

Epoch: 6| Step: 12
Training loss: 2.5567986965179443
Validation loss: 2.388235422872728

Epoch: 6| Step: 13
Training loss: 2.796851396560669
Validation loss: 2.4050033425772064

Epoch: 80| Step: 0
Training loss: 3.0490431785583496
Validation loss: 2.419493018939931

Epoch: 6| Step: 1
Training loss: 2.3763747215270996
Validation loss: 2.413705720696398

Epoch: 6| Step: 2
Training loss: 2.824101686477661
Validation loss: 2.4017056470276206

Epoch: 6| Step: 3
Training loss: 2.0721096992492676
Validation loss: 2.3991858972016202

Epoch: 6| Step: 4
Training loss: 3.2231006622314453
Validation loss: 2.3920176516297045

Epoch: 6| Step: 5
Training loss: 3.1370131969451904
Validation loss: 2.380890223287767

Epoch: 6| Step: 6
Training loss: 2.674921989440918
Validation loss: 2.3726200954888457

Epoch: 6| Step: 7
Training loss: 2.12459397315979
Validation loss: 2.378059874298752

Epoch: 6| Step: 8
Training loss: 2.6006860733032227
Validation loss: 2.37641728308893

Epoch: 6| Step: 9
Training loss: 2.7755653858184814
Validation loss: 2.387305482741325

Epoch: 6| Step: 10
Training loss: 3.0765485763549805
Validation loss: 2.4047859484149563

Epoch: 6| Step: 11
Training loss: 2.3516814708709717
Validation loss: 2.4089409356476157

Epoch: 6| Step: 12
Training loss: 1.8888481855392456
Validation loss: 2.4083273154433056

Epoch: 6| Step: 13
Training loss: 2.2689218521118164
Validation loss: 2.4776531034900295

Epoch: 81| Step: 0
Training loss: 2.6536693572998047
Validation loss: 2.490252520448418

Epoch: 6| Step: 1
Training loss: 2.3584229946136475
Validation loss: 2.4631574333354993

Epoch: 6| Step: 2
Training loss: 2.6555466651916504
Validation loss: 2.462495942269602

Epoch: 6| Step: 3
Training loss: 2.810856342315674
Validation loss: 2.433593391090311

Epoch: 6| Step: 4
Training loss: 2.4746313095092773
Validation loss: 2.4308030425861316

Epoch: 6| Step: 5
Training loss: 2.6343512535095215
Validation loss: 2.42912898525115

Epoch: 6| Step: 6
Training loss: 2.714616298675537
Validation loss: 2.424234087749194

Epoch: 6| Step: 7
Training loss: 1.9595082998275757
Validation loss: 2.4252443313598633

Epoch: 6| Step: 8
Training loss: 3.006727933883667
Validation loss: 2.422620488751319

Epoch: 6| Step: 9
Training loss: 3.3271069526672363
Validation loss: 2.4237901856822353

Epoch: 6| Step: 10
Training loss: 3.0831031799316406
Validation loss: 2.43286645156081

Epoch: 6| Step: 11
Training loss: 2.321932315826416
Validation loss: 2.4268656469160512

Epoch: 6| Step: 12
Training loss: 2.7056727409362793
Validation loss: 2.415974324749362

Epoch: 6| Step: 13
Training loss: 2.2781808376312256
Validation loss: 2.410995107825084

Epoch: 82| Step: 0
Training loss: 3.455138683319092
Validation loss: 2.4161190268813924

Epoch: 6| Step: 1
Training loss: 2.6253859996795654
Validation loss: 2.3995600246614024

Epoch: 6| Step: 2
Training loss: 2.3679676055908203
Validation loss: 2.386505506371939

Epoch: 6| Step: 3
Training loss: 2.005953311920166
Validation loss: 2.3750543645633164

Epoch: 6| Step: 4
Training loss: 3.403616189956665
Validation loss: 2.3919040464585826

Epoch: 6| Step: 5
Training loss: 3.3916540145874023
Validation loss: 2.3973801212926067

Epoch: 6| Step: 6
Training loss: 2.3351473808288574
Validation loss: 2.3892711875259236

Epoch: 6| Step: 7
Training loss: 2.1987533569335938
Validation loss: 2.370509009207449

Epoch: 6| Step: 8
Training loss: 2.7245407104492188
Validation loss: 2.361121981374679

Epoch: 6| Step: 9
Training loss: 2.57948637008667
Validation loss: 2.356506916784471

Epoch: 6| Step: 10
Training loss: 2.988262891769409
Validation loss: 2.3612831741250973

Epoch: 6| Step: 11
Training loss: 2.4492151737213135
Validation loss: 2.3580138132136357

Epoch: 6| Step: 12
Training loss: 2.1595497131347656
Validation loss: 2.3668936734558432

Epoch: 6| Step: 13
Training loss: 1.6336151361465454
Validation loss: 2.3714210192362466

Epoch: 83| Step: 0
Training loss: 2.813298225402832
Validation loss: 2.392979411668675

Epoch: 6| Step: 1
Training loss: 2.093233108520508
Validation loss: 2.42364901368336

Epoch: 6| Step: 2
Training loss: 2.5908284187316895
Validation loss: 2.503418061041063

Epoch: 6| Step: 3
Training loss: 2.042259693145752
Validation loss: 2.519247349872384

Epoch: 6| Step: 4
Training loss: 2.648102283477783
Validation loss: 2.4745563742935017

Epoch: 6| Step: 5
Training loss: 2.7866272926330566
Validation loss: 2.454905968840404

Epoch: 6| Step: 6
Training loss: 2.1453025341033936
Validation loss: 2.4347772213720504

Epoch: 6| Step: 7
Training loss: 2.9698362350463867
Validation loss: 2.3833482316745225

Epoch: 6| Step: 8
Training loss: 2.720280647277832
Validation loss: 2.354234162197318

Epoch: 6| Step: 9
Training loss: 3.640934705734253
Validation loss: 2.3434031214765323

Epoch: 6| Step: 10
Training loss: 2.521239757537842
Validation loss: 2.353355256460046

Epoch: 6| Step: 11
Training loss: 2.656722068786621
Validation loss: 2.3534496215081986

Epoch: 6| Step: 12
Training loss: 2.6793196201324463
Validation loss: 2.3447045459542224

Epoch: 6| Step: 13
Training loss: 2.7534708976745605
Validation loss: 2.3431561980196225

Epoch: 84| Step: 0
Training loss: 3.1819677352905273
Validation loss: 2.3475229176141883

Epoch: 6| Step: 1
Training loss: 2.003485918045044
Validation loss: 2.352410258785371

Epoch: 6| Step: 2
Training loss: 2.489717483520508
Validation loss: 2.3512175301069855

Epoch: 6| Step: 3
Training loss: 2.6201374530792236
Validation loss: 2.378730156088388

Epoch: 6| Step: 4
Training loss: 2.4902493953704834
Validation loss: 2.3498592633073048

Epoch: 6| Step: 5
Training loss: 2.4647469520568848
Validation loss: 2.352473724272943

Epoch: 6| Step: 6
Training loss: 2.864133358001709
Validation loss: 2.3325513742303334

Epoch: 6| Step: 7
Training loss: 3.0893735885620117
Validation loss: 2.3235705565380793

Epoch: 6| Step: 8
Training loss: 2.4881584644317627
Validation loss: 2.3214754904470136

Epoch: 6| Step: 9
Training loss: 2.920043468475342
Validation loss: 2.3199142615000405

Epoch: 6| Step: 10
Training loss: 2.046649694442749
Validation loss: 2.3177907620706866

Epoch: 6| Step: 11
Training loss: 2.7489852905273438
Validation loss: 2.3193881127142135

Epoch: 6| Step: 12
Training loss: 2.349428653717041
Validation loss: 2.3217341207688853

Epoch: 6| Step: 13
Training loss: 3.0227198600769043
Validation loss: 2.321089680476855

Epoch: 85| Step: 0
Training loss: 2.0464673042297363
Validation loss: 2.327404281144501

Epoch: 6| Step: 1
Training loss: 3.1016736030578613
Validation loss: 2.338939928239392

Epoch: 6| Step: 2
Training loss: 2.693240165710449
Validation loss: 2.349454164505005

Epoch: 6| Step: 3
Training loss: 2.47314453125
Validation loss: 2.356229164267099

Epoch: 6| Step: 4
Training loss: 1.7362182140350342
Validation loss: 2.342049370529831

Epoch: 6| Step: 5
Training loss: 3.267390489578247
Validation loss: 2.3459799033339306

Epoch: 6| Step: 6
Training loss: 2.6669483184814453
Validation loss: 2.3383943752575944

Epoch: 6| Step: 7
Training loss: 2.366313934326172
Validation loss: 2.3577164629454255

Epoch: 6| Step: 8
Training loss: 2.4701600074768066
Validation loss: 2.3623466158425934

Epoch: 6| Step: 9
Training loss: 2.8725504875183105
Validation loss: 2.3747705644176853

Epoch: 6| Step: 10
Training loss: 2.8439314365386963
Validation loss: 2.3517841369875017

Epoch: 6| Step: 11
Training loss: 2.1976699829101562
Validation loss: 2.340514152280746

Epoch: 6| Step: 12
Training loss: 2.698050022125244
Validation loss: 2.3383348065037883

Epoch: 6| Step: 13
Training loss: 3.3202061653137207
Validation loss: 2.3390076493704193

Epoch: 86| Step: 0
Training loss: 3.1657094955444336
Validation loss: 2.3381417515457317

Epoch: 6| Step: 1
Training loss: 3.0425796508789062
Validation loss: 2.3386020532218357

Epoch: 6| Step: 2
Training loss: 2.734245538711548
Validation loss: 2.3259043475633026

Epoch: 6| Step: 3
Training loss: 2.9446353912353516
Validation loss: 2.325825463059128

Epoch: 6| Step: 4
Training loss: 2.495061159133911
Validation loss: 2.316438413435413

Epoch: 6| Step: 5
Training loss: 2.1319234371185303
Validation loss: 2.308362695478624

Epoch: 6| Step: 6
Training loss: 2.2460365295410156
Validation loss: 2.313548195746637

Epoch: 6| Step: 7
Training loss: 2.567915201187134
Validation loss: 2.3059885309588526

Epoch: 6| Step: 8
Training loss: 3.0453240871429443
Validation loss: 2.3158473019958823

Epoch: 6| Step: 9
Training loss: 2.1331305503845215
Validation loss: 2.314203195674445

Epoch: 6| Step: 10
Training loss: 3.6371707916259766
Validation loss: 2.3130777612809212

Epoch: 6| Step: 11
Training loss: 2.5100579261779785
Validation loss: 2.3319364542602212

Epoch: 6| Step: 12
Training loss: 1.65987229347229
Validation loss: 2.354525840410622

Epoch: 6| Step: 13
Training loss: 1.4027106761932373
Validation loss: 2.3610070418286067

Epoch: 87| Step: 0
Training loss: 2.780806064605713
Validation loss: 2.419658996725595

Epoch: 6| Step: 1
Training loss: 2.3485612869262695
Validation loss: 2.4697654478011595

Epoch: 6| Step: 2
Training loss: 3.3100028038024902
Validation loss: 2.4845794836680093

Epoch: 6| Step: 3
Training loss: 2.9302523136138916
Validation loss: 2.3893449511579288

Epoch: 6| Step: 4
Training loss: 2.079972267150879
Validation loss: 2.3428262459334506

Epoch: 6| Step: 5
Training loss: 2.382974624633789
Validation loss: 2.321725240317724

Epoch: 6| Step: 6
Training loss: 2.8378095626831055
Validation loss: 2.3003676053016417

Epoch: 6| Step: 7
Training loss: 2.5057950019836426
Validation loss: 2.3105549786680486

Epoch: 6| Step: 8
Training loss: 2.9155445098876953
Validation loss: 2.341776042856196

Epoch: 6| Step: 9
Training loss: 2.297165632247925
Validation loss: 2.3610586043327086

Epoch: 6| Step: 10
Training loss: 2.8619790077209473
Validation loss: 2.376970757720291

Epoch: 6| Step: 11
Training loss: 3.537318229675293
Validation loss: 2.357110390099146

Epoch: 6| Step: 12
Training loss: 2.019789218902588
Validation loss: 2.327381707006885

Epoch: 6| Step: 13
Training loss: 1.8660768270492554
Validation loss: 2.299741386085428

Epoch: 88| Step: 0
Training loss: 2.1464743614196777
Validation loss: 2.2947366417095227

Epoch: 6| Step: 1
Training loss: 2.3573617935180664
Validation loss: 2.2970756664071033

Epoch: 6| Step: 2
Training loss: 1.9039419889450073
Validation loss: 2.3005186037350724

Epoch: 6| Step: 3
Training loss: 2.5543694496154785
Validation loss: 2.3134699534344416

Epoch: 6| Step: 4
Training loss: 2.314931869506836
Validation loss: 2.3304026947226575

Epoch: 6| Step: 5
Training loss: 2.720249652862549
Validation loss: 2.3780306821228354

Epoch: 6| Step: 6
Training loss: 2.843898296356201
Validation loss: 2.400047743192283

Epoch: 6| Step: 7
Training loss: 2.3826546669006348
Validation loss: 2.469253738721212

Epoch: 6| Step: 8
Training loss: 3.6009106636047363
Validation loss: 2.4805424623591925

Epoch: 6| Step: 9
Training loss: 3.198683500289917
Validation loss: 2.488665831986294

Epoch: 6| Step: 10
Training loss: 2.142078399658203
Validation loss: 2.3973125591072986

Epoch: 6| Step: 11
Training loss: 2.6671714782714844
Validation loss: 2.3299383835125993

Epoch: 6| Step: 12
Training loss: 2.4881591796875
Validation loss: 2.296079840711368

Epoch: 6| Step: 13
Training loss: 3.7565536499023438
Validation loss: 2.2884890135898384

Epoch: 89| Step: 0
Training loss: 2.6202304363250732
Validation loss: 2.292345098269883

Epoch: 6| Step: 1
Training loss: 2.491420269012451
Validation loss: 2.2955882087830575

Epoch: 6| Step: 2
Training loss: 2.2755541801452637
Validation loss: 2.3072850114555767

Epoch: 6| Step: 3
Training loss: 2.5261073112487793
Validation loss: 2.305928610986279

Epoch: 6| Step: 4
Training loss: 2.1083574295043945
Validation loss: 2.3108792586993148

Epoch: 6| Step: 5
Training loss: 2.814427375793457
Validation loss: 2.3097961692399878

Epoch: 6| Step: 6
Training loss: 2.538177013397217
Validation loss: 2.304678555457823

Epoch: 6| Step: 7
Training loss: 2.0554275512695312
Validation loss: 2.3005612870698333

Epoch: 6| Step: 8
Training loss: 1.8935911655426025
Validation loss: 2.2947262615285893

Epoch: 6| Step: 9
Training loss: 3.2830865383148193
Validation loss: 2.289742849206412

Epoch: 6| Step: 10
Training loss: 2.723853588104248
Validation loss: 2.2899093089565152

Epoch: 6| Step: 11
Training loss: 2.8610007762908936
Validation loss: 2.2942823517707085

Epoch: 6| Step: 12
Training loss: 3.463155746459961
Validation loss: 2.2905956699002172

Epoch: 6| Step: 13
Training loss: 3.0110418796539307
Validation loss: 2.2967172540644163

Epoch: 90| Step: 0
Training loss: 2.299889087677002
Validation loss: 2.2942442688890683

Epoch: 6| Step: 1
Training loss: 2.9713971614837646
Validation loss: 2.2958548069000244

Epoch: 6| Step: 2
Training loss: 2.817368507385254
Validation loss: 2.2908549693322953

Epoch: 6| Step: 3
Training loss: 3.4260239601135254
Validation loss: 2.2954131839095906

Epoch: 6| Step: 4
Training loss: 2.7456161975860596
Validation loss: 2.2972585155117895

Epoch: 6| Step: 5
Training loss: 2.0518808364868164
Validation loss: 2.297070774980771

Epoch: 6| Step: 6
Training loss: 2.6819427013397217
Validation loss: 2.3168729864140993

Epoch: 6| Step: 7
Training loss: 2.1645753383636475
Validation loss: 2.3135960614809425

Epoch: 6| Step: 8
Training loss: 2.2783761024475098
Validation loss: 2.304950932020782

Epoch: 6| Step: 9
Training loss: 2.362377643585205
Validation loss: 2.3058078071122527

Epoch: 6| Step: 10
Training loss: 2.890648365020752
Validation loss: 2.3096325448764268

Epoch: 6| Step: 11
Training loss: 2.2344579696655273
Validation loss: 2.303138450909686

Epoch: 6| Step: 12
Training loss: 2.982099771499634
Validation loss: 2.3061120740828978

Epoch: 6| Step: 13
Training loss: 1.8509140014648438
Validation loss: 2.308955530966482

Epoch: 91| Step: 0
Training loss: 2.7732279300689697
Validation loss: 2.293119169050647

Epoch: 6| Step: 1
Training loss: 2.8506529331207275
Validation loss: 2.287492823857133

Epoch: 6| Step: 2
Training loss: 1.987257480621338
Validation loss: 2.2823662911691973

Epoch: 6| Step: 3
Training loss: 2.2322185039520264
Validation loss: 2.282399046805597

Epoch: 6| Step: 4
Training loss: 2.5942907333374023
Validation loss: 2.282343472203901

Epoch: 6| Step: 5
Training loss: 2.876042127609253
Validation loss: 2.282404321496205

Epoch: 6| Step: 6
Training loss: 2.635136127471924
Validation loss: 2.287258707067018

Epoch: 6| Step: 7
Training loss: 2.0986781120300293
Validation loss: 2.291431341119992

Epoch: 6| Step: 8
Training loss: 2.802711248397827
Validation loss: 2.2887862074759697

Epoch: 6| Step: 9
Training loss: 2.0552048683166504
Validation loss: 2.2977967134086033

Epoch: 6| Step: 10
Training loss: 3.0190889835357666
Validation loss: 2.2945960388388684

Epoch: 6| Step: 11
Training loss: 3.667539358139038
Validation loss: 2.296338450524115

Epoch: 6| Step: 12
Training loss: 2.1652615070343018
Validation loss: 2.3002213457579255

Epoch: 6| Step: 13
Training loss: 2.0213472843170166
Validation loss: 2.2952249947414605

Epoch: 92| Step: 0
Training loss: 2.492889881134033
Validation loss: 2.2965540860288884

Epoch: 6| Step: 1
Training loss: 2.565372943878174
Validation loss: 2.303746392649989

Epoch: 6| Step: 2
Training loss: 2.6413750648498535
Validation loss: 2.2923807392838182

Epoch: 6| Step: 3
Training loss: 1.945802927017212
Validation loss: 2.314173993243966

Epoch: 6| Step: 4
Training loss: 2.133730411529541
Validation loss: 2.308609338216884

Epoch: 6| Step: 5
Training loss: 2.0639097690582275
Validation loss: 2.3034793561504734

Epoch: 6| Step: 6
Training loss: 2.056670665740967
Validation loss: 2.302758391185473

Epoch: 6| Step: 7
Training loss: 3.5701160430908203
Validation loss: 2.312123333254168

Epoch: 6| Step: 8
Training loss: 3.1174826622009277
Validation loss: 2.2954193110107095

Epoch: 6| Step: 9
Training loss: 3.3195641040802
Validation loss: 2.2843515514045634

Epoch: 6| Step: 10
Training loss: 2.643038272857666
Validation loss: 2.2749343302942093

Epoch: 6| Step: 11
Training loss: 2.2294697761535645
Validation loss: 2.2732679433720087

Epoch: 6| Step: 12
Training loss: 2.9376566410064697
Validation loss: 2.2780858662820633

Epoch: 6| Step: 13
Training loss: 1.7477397918701172
Validation loss: 2.282075951176305

Epoch: 93| Step: 0
Training loss: 2.5462770462036133
Validation loss: 2.2796226701428814

Epoch: 6| Step: 1
Training loss: 2.1280438899993896
Validation loss: 2.292746105501729

Epoch: 6| Step: 2
Training loss: 2.4498467445373535
Validation loss: 2.300202270989777

Epoch: 6| Step: 3
Training loss: 2.4609289169311523
Validation loss: 2.3160175892614547

Epoch: 6| Step: 4
Training loss: 2.5919811725616455
Validation loss: 2.3100059109349407

Epoch: 6| Step: 5
Training loss: 2.712111473083496
Validation loss: 2.3178347285075853

Epoch: 6| Step: 6
Training loss: 2.7689290046691895
Validation loss: 2.3179407504297074

Epoch: 6| Step: 7
Training loss: 2.9374518394470215
Validation loss: 2.3129469502356743

Epoch: 6| Step: 8
Training loss: 2.7031593322753906
Validation loss: 2.307178715223907

Epoch: 6| Step: 9
Training loss: 2.160571575164795
Validation loss: 2.291899788764215

Epoch: 6| Step: 10
Training loss: 2.610353946685791
Validation loss: 2.2754679392742854

Epoch: 6| Step: 11
Training loss: 2.2935590744018555
Validation loss: 2.2726348830807592

Epoch: 6| Step: 12
Training loss: 3.040534019470215
Validation loss: 2.2844332546316166

Epoch: 6| Step: 13
Training loss: 2.008117914199829
Validation loss: 2.2784812399136123

Epoch: 94| Step: 0
Training loss: 1.9522457122802734
Validation loss: 2.2928618820764686

Epoch: 6| Step: 1
Training loss: 2.60256028175354
Validation loss: 2.3020537232839935

Epoch: 6| Step: 2
Training loss: 3.307079792022705
Validation loss: 2.3199345552793114

Epoch: 6| Step: 3
Training loss: 2.4597740173339844
Validation loss: 2.3201208345351683

Epoch: 6| Step: 4
Training loss: 1.324744462966919
Validation loss: 2.331967132065886

Epoch: 6| Step: 5
Training loss: 2.744439125061035
Validation loss: 2.3277316452354513

Epoch: 6| Step: 6
Training loss: 3.1039345264434814
Validation loss: 2.3298049537084435

Epoch: 6| Step: 7
Training loss: 2.352851629257202
Validation loss: 2.303324645565402

Epoch: 6| Step: 8
Training loss: 2.579718828201294
Validation loss: 2.2842599063791256

Epoch: 6| Step: 9
Training loss: 2.7770907878875732
Validation loss: 2.27985793031672

Epoch: 6| Step: 10
Training loss: 2.653308391571045
Validation loss: 2.278051245597101

Epoch: 6| Step: 11
Training loss: 2.4157066345214844
Validation loss: 2.2988353493393108

Epoch: 6| Step: 12
Training loss: 2.8645405769348145
Validation loss: 2.291286841515572

Epoch: 6| Step: 13
Training loss: 2.8820486068725586
Validation loss: 2.320068549084407

Epoch: 95| Step: 0
Training loss: 2.106621742248535
Validation loss: 2.3141057978394213

Epoch: 6| Step: 1
Training loss: 2.9903275966644287
Validation loss: 2.3180828966120237

Epoch: 6| Step: 2
Training loss: 2.979416608810425
Validation loss: 2.324380418305756

Epoch: 6| Step: 3
Training loss: 2.396115303039551
Validation loss: 2.351732820592901

Epoch: 6| Step: 4
Training loss: 3.241316795349121
Validation loss: 2.344011692590611

Epoch: 6| Step: 5
Training loss: 2.5309042930603027
Validation loss: 2.2758313942981023

Epoch: 6| Step: 6
Training loss: 2.350867748260498
Validation loss: 2.263277840870683

Epoch: 6| Step: 7
Training loss: 2.312736988067627
Validation loss: 2.2582719326019287

Epoch: 6| Step: 8
Training loss: 2.2707879543304443
Validation loss: 2.259985713548558

Epoch: 6| Step: 9
Training loss: 2.0983564853668213
Validation loss: 2.2663069707091137

Epoch: 6| Step: 10
Training loss: 2.884611129760742
Validation loss: 2.2736811099513883

Epoch: 6| Step: 11
Training loss: 2.432469606399536
Validation loss: 2.2810886393311205

Epoch: 6| Step: 12
Training loss: 2.991966962814331
Validation loss: 2.304288669299054

Epoch: 6| Step: 13
Training loss: 2.0115764141082764
Validation loss: 2.3314699870283886

Epoch: 96| Step: 0
Training loss: 2.271401882171631
Validation loss: 2.3575504415778705

Epoch: 6| Step: 1
Training loss: 2.0296545028686523
Validation loss: 2.374160643546812

Epoch: 6| Step: 2
Training loss: 2.187391519546509
Validation loss: 2.359872128373833

Epoch: 6| Step: 3
Training loss: 2.437943935394287
Validation loss: 2.362097722227855

Epoch: 6| Step: 4
Training loss: 2.5468475818634033
Validation loss: 2.3467091539854645

Epoch: 6| Step: 5
Training loss: 3.5466604232788086
Validation loss: 2.3359212695911364

Epoch: 6| Step: 6
Training loss: 2.7795588970184326
Validation loss: 2.303907320063601

Epoch: 6| Step: 7
Training loss: 2.4554219245910645
Validation loss: 2.2868586663276917

Epoch: 6| Step: 8
Training loss: 2.45269775390625
Validation loss: 2.278948868474653

Epoch: 6| Step: 9
Training loss: 3.0376791954040527
Validation loss: 2.2639127815923383

Epoch: 6| Step: 10
Training loss: 2.5185041427612305
Validation loss: 2.2568915685017905

Epoch: 6| Step: 11
Training loss: 2.6896162033081055
Validation loss: 2.2568502118510585

Epoch: 6| Step: 12
Training loss: 2.568176746368408
Validation loss: 2.269365282468898

Epoch: 6| Step: 13
Training loss: 2.6585679054260254
Validation loss: 2.2785940939380276

Epoch: 97| Step: 0
Training loss: 3.2166738510131836
Validation loss: 2.2948211187957437

Epoch: 6| Step: 1
Training loss: 3.263462543487549
Validation loss: 2.318786713384813

Epoch: 6| Step: 2
Training loss: 2.0474748611450195
Validation loss: 2.324106665067775

Epoch: 6| Step: 3
Training loss: 2.6432671546936035
Validation loss: 2.320049011579124

Epoch: 6| Step: 4
Training loss: 1.9540220499038696
Validation loss: 2.3066406121817966

Epoch: 6| Step: 5
Training loss: 2.196967124938965
Validation loss: 2.2912755320149083

Epoch: 6| Step: 6
Training loss: 2.6023340225219727
Validation loss: 2.2848190107653217

Epoch: 6| Step: 7
Training loss: 2.994213581085205
Validation loss: 2.26049708038248

Epoch: 6| Step: 8
Training loss: 2.455409049987793
Validation loss: 2.2536926961714223

Epoch: 6| Step: 9
Training loss: 2.4562644958496094
Validation loss: 2.2408531558129097

Epoch: 6| Step: 10
Training loss: 2.818171501159668
Validation loss: 2.2471031322274158

Epoch: 6| Step: 11
Training loss: 2.690216302871704
Validation loss: 2.2461023715234574

Epoch: 6| Step: 12
Training loss: 1.854429006576538
Validation loss: 2.2504305608810915

Epoch: 6| Step: 13
Training loss: 2.2842905521392822
Validation loss: 2.25053160677674

Epoch: 98| Step: 0
Training loss: 2.917262554168701
Validation loss: 2.249444814138515

Epoch: 6| Step: 1
Training loss: 2.3346915245056152
Validation loss: 2.2430642574064192

Epoch: 6| Step: 2
Training loss: 2.631772041320801
Validation loss: 2.2409494000096477

Epoch: 6| Step: 3
Training loss: 2.5669074058532715
Validation loss: 2.245898082692136

Epoch: 6| Step: 4
Training loss: 2.7969655990600586
Validation loss: 2.2480512652345883

Epoch: 6| Step: 5
Training loss: 2.2395472526550293
Validation loss: 2.2614981384687525

Epoch: 6| Step: 6
Training loss: 2.5591042041778564
Validation loss: 2.2752227757566716

Epoch: 6| Step: 7
Training loss: 2.575965404510498
Validation loss: 2.285149176915487

Epoch: 6| Step: 8
Training loss: 1.5454232692718506
Validation loss: 2.2727301146394465

Epoch: 6| Step: 9
Training loss: 2.5759384632110596
Validation loss: 2.3108421782011628

Epoch: 6| Step: 10
Training loss: 2.128831386566162
Validation loss: 2.3087054632043325

Epoch: 6| Step: 11
Training loss: 3.2294602394104004
Validation loss: 2.3134369491249003

Epoch: 6| Step: 12
Training loss: 3.202275514602661
Validation loss: 2.2732299348359466

Epoch: 6| Step: 13
Training loss: 2.0765504837036133
Validation loss: 2.2409982527455976

Epoch: 99| Step: 0
Training loss: 2.479581832885742
Validation loss: 2.2426569282367663

Epoch: 6| Step: 1
Training loss: 2.3215556144714355
Validation loss: 2.242560660967263

Epoch: 6| Step: 2
Training loss: 2.280036449432373
Validation loss: 2.2463798856222503

Epoch: 6| Step: 3
Training loss: 3.009232997894287
Validation loss: 2.2447020212809243

Epoch: 6| Step: 4
Training loss: 2.3375048637390137
Validation loss: 2.256495434750793

Epoch: 6| Step: 5
Training loss: 2.168354034423828
Validation loss: 2.2596305262657905

Epoch: 6| Step: 6
Training loss: 2.3756296634674072
Validation loss: 2.2618701509250108

Epoch: 6| Step: 7
Training loss: 3.0968189239501953
Validation loss: 2.2653842946534515

Epoch: 6| Step: 8
Training loss: 2.516555070877075
Validation loss: 2.258335510889689

Epoch: 6| Step: 9
Training loss: 2.972233533859253
Validation loss: 2.2564036089886903

Epoch: 6| Step: 10
Training loss: 2.7173709869384766
Validation loss: 2.2512691085056593

Epoch: 6| Step: 11
Training loss: 2.960219383239746
Validation loss: 2.266839245314239

Epoch: 6| Step: 12
Training loss: 2.4773545265197754
Validation loss: 2.2892143034165904

Epoch: 6| Step: 13
Training loss: 1.92265784740448
Validation loss: 2.2916337264481412

Epoch: 100| Step: 0
Training loss: 2.2254109382629395
Validation loss: 2.319907654998123

Epoch: 6| Step: 1
Training loss: 2.015272378921509
Validation loss: 2.35408720918881

Epoch: 6| Step: 2
Training loss: 2.6489644050598145
Validation loss: 2.3608884401218866

Epoch: 6| Step: 3
Training loss: 2.2734851837158203
Validation loss: 2.356677468105029

Epoch: 6| Step: 4
Training loss: 1.8892128467559814
Validation loss: 2.3488019768909743

Epoch: 6| Step: 5
Training loss: 3.2737925052642822
Validation loss: 2.329224596741379

Epoch: 6| Step: 6
Training loss: 2.6127986907958984
Validation loss: 2.3005352686810236

Epoch: 6| Step: 7
Training loss: 2.8097660541534424
Validation loss: 2.278703852366376

Epoch: 6| Step: 8
Training loss: 3.5204553604125977
Validation loss: 2.257986250744071

Epoch: 6| Step: 9
Training loss: 2.6783175468444824
Validation loss: 2.2482280628655547

Epoch: 6| Step: 10
Training loss: 2.4765515327453613
Validation loss: 2.2382605742382746

Epoch: 6| Step: 11
Training loss: 2.478303909301758
Validation loss: 2.2332325109871487

Epoch: 6| Step: 12
Training loss: 2.295358657836914
Validation loss: 2.2366591166424494

Epoch: 6| Step: 13
Training loss: 2.58640193939209
Validation loss: 2.2300178902123564

Epoch: 101| Step: 0
Training loss: 2.3927111625671387
Validation loss: 2.22699672432356

Epoch: 6| Step: 1
Training loss: 2.478537082672119
Validation loss: 2.224690359125855

Epoch: 6| Step: 2
Training loss: 3.164999008178711
Validation loss: 2.2327165719001525

Epoch: 6| Step: 3
Training loss: 2.0979228019714355
Validation loss: 2.2457561980011644

Epoch: 6| Step: 4
Training loss: 2.818964958190918
Validation loss: 2.2527807476699993

Epoch: 6| Step: 5
Training loss: 2.311957836151123
Validation loss: 2.2495299872531684

Epoch: 6| Step: 6
Training loss: 1.7309774160385132
Validation loss: 2.2415117627830914

Epoch: 6| Step: 7
Training loss: 2.1893415451049805
Validation loss: 2.231491493922408

Epoch: 6| Step: 8
Training loss: 3.0133285522460938
Validation loss: 2.2248545103175665

Epoch: 6| Step: 9
Training loss: 2.995112419128418
Validation loss: 2.2255973187826013

Epoch: 6| Step: 10
Training loss: 2.685063123703003
Validation loss: 2.2257147912056214

Epoch: 6| Step: 11
Training loss: 2.2330148220062256
Validation loss: 2.227068280660978

Epoch: 6| Step: 12
Training loss: 2.94620680809021
Validation loss: 2.233987744136523

Epoch: 6| Step: 13
Training loss: 2.550884246826172
Validation loss: 2.228905221467377

Epoch: 102| Step: 0
Training loss: 2.44616436958313
Validation loss: 2.2233737450774

Epoch: 6| Step: 1
Training loss: 2.5292088985443115
Validation loss: 2.222309204839891

Epoch: 6| Step: 2
Training loss: 2.548015832901001
Validation loss: 2.226466755713186

Epoch: 6| Step: 3
Training loss: 3.2403178215026855
Validation loss: 2.2431278074941328

Epoch: 6| Step: 4
Training loss: 2.271195888519287
Validation loss: 2.2666356512295303

Epoch: 6| Step: 5
Training loss: 2.2306971549987793
Validation loss: 2.282622278377574

Epoch: 6| Step: 6
Training loss: 2.113145112991333
Validation loss: 2.307335968940489

Epoch: 6| Step: 7
Training loss: 3.119274616241455
Validation loss: 2.33139068336897

Epoch: 6| Step: 8
Training loss: 2.294790744781494
Validation loss: 2.3704122061370523

Epoch: 6| Step: 9
Training loss: 3.0652008056640625
Validation loss: 2.3826996998120378

Epoch: 6| Step: 10
Training loss: 3.0377678871154785
Validation loss: 2.3599159358650126

Epoch: 6| Step: 11
Training loss: 2.2721354961395264
Validation loss: 2.3213810702805877

Epoch: 6| Step: 12
Training loss: 1.927886962890625
Validation loss: 2.273716244646298

Epoch: 6| Step: 13
Training loss: 2.9712939262390137
Validation loss: 2.245566770594607

Epoch: 103| Step: 0
Training loss: 2.727337121963501
Validation loss: 2.235045756063154

Epoch: 6| Step: 1
Training loss: 3.3891968727111816
Validation loss: 2.213904171861628

Epoch: 6| Step: 2
Training loss: 2.9159622192382812
Validation loss: 2.2161908252264864

Epoch: 6| Step: 3
Training loss: 2.3377254009246826
Validation loss: 2.2127026806595507

Epoch: 6| Step: 4
Training loss: 2.840920925140381
Validation loss: 2.2175085672768216

Epoch: 6| Step: 5
Training loss: 1.9284769296646118
Validation loss: 2.2281807994329803

Epoch: 6| Step: 6
Training loss: 2.45350980758667
Validation loss: 2.2206310866981425

Epoch: 6| Step: 7
Training loss: 2.4459259510040283
Validation loss: 2.222085283648583

Epoch: 6| Step: 8
Training loss: 2.5178399085998535
Validation loss: 2.2252290633416947

Epoch: 6| Step: 9
Training loss: 2.502826690673828
Validation loss: 2.221212253775648

Epoch: 6| Step: 10
Training loss: 2.471986770629883
Validation loss: 2.218713575793851

Epoch: 6| Step: 11
Training loss: 2.9340598583221436
Validation loss: 2.222466289356191

Epoch: 6| Step: 12
Training loss: 2.1823818683624268
Validation loss: 2.2282036299346597

Epoch: 6| Step: 13
Training loss: 1.576468825340271
Validation loss: 2.2460949062019266

Epoch: 104| Step: 0
Training loss: 2.002422332763672
Validation loss: 2.2658969484349734

Epoch: 6| Step: 1
Training loss: 2.7001750469207764
Validation loss: 2.289359543913154

Epoch: 6| Step: 2
Training loss: 3.4294419288635254
Validation loss: 2.320760957656368

Epoch: 6| Step: 3
Training loss: 2.7037405967712402
Validation loss: 2.3453657755287747

Epoch: 6| Step: 4
Training loss: 2.760226249694824
Validation loss: 2.3441291778318343

Epoch: 6| Step: 5
Training loss: 1.6324732303619385
Validation loss: 2.3655450831177416

Epoch: 6| Step: 6
Training loss: 2.3462846279144287
Validation loss: 2.352711130213994

Epoch: 6| Step: 7
Training loss: 3.094266414642334
Validation loss: 2.3165163173470447

Epoch: 6| Step: 8
Training loss: 2.590054988861084
Validation loss: 2.27527392038735

Epoch: 6| Step: 9
Training loss: 2.6003963947296143
Validation loss: 2.240922410001037

Epoch: 6| Step: 10
Training loss: 2.857640027999878
Validation loss: 2.2308968549133628

Epoch: 6| Step: 11
Training loss: 2.217463493347168
Validation loss: 2.2262240417541994

Epoch: 6| Step: 12
Training loss: 2.312732696533203
Validation loss: 2.214912114604827

Epoch: 6| Step: 13
Training loss: 2.1880171298980713
Validation loss: 2.2107753292206795

Epoch: 105| Step: 0
Training loss: 2.5995938777923584
Validation loss: 2.209533706788094

Epoch: 6| Step: 1
Training loss: 2.7819976806640625
Validation loss: 2.2199327125344226

Epoch: 6| Step: 2
Training loss: 3.239551067352295
Validation loss: 2.219804345920522

Epoch: 6| Step: 3
Training loss: 2.175259590148926
Validation loss: 2.219362617820822

Epoch: 6| Step: 4
Training loss: 2.4766526222229004
Validation loss: 2.2141911496398268

Epoch: 6| Step: 5
Training loss: 1.8819763660430908
Validation loss: 2.207328170858404

Epoch: 6| Step: 6
Training loss: 2.1038575172424316
Validation loss: 2.216304018933286

Epoch: 6| Step: 7
Training loss: 2.966259241104126
Validation loss: 2.237441106509137

Epoch: 6| Step: 8
Training loss: 2.7325329780578613
Validation loss: 2.2554309650134017

Epoch: 6| Step: 9
Training loss: 2.455874443054199
Validation loss: 2.2648257440136326

Epoch: 6| Step: 10
Training loss: 2.214341402053833
Validation loss: 2.3027399073364916

Epoch: 6| Step: 11
Training loss: 2.127995014190674
Validation loss: 2.3239794110739105

Epoch: 6| Step: 12
Training loss: 2.822857141494751
Validation loss: 2.369508553576726

Epoch: 6| Step: 13
Training loss: 3.0620718002319336
Validation loss: 2.3462796390697522

Epoch: 106| Step: 0
Training loss: 2.2118234634399414
Validation loss: 2.3188850495123092

Epoch: 6| Step: 1
Training loss: 2.1165719032287598
Validation loss: 2.299690672146377

Epoch: 6| Step: 2
Training loss: 2.7499406337738037
Validation loss: 2.286273225661247

Epoch: 6| Step: 3
Training loss: 2.1965107917785645
Validation loss: 2.288865145816598

Epoch: 6| Step: 4
Training loss: 2.3528084754943848
Validation loss: 2.280323359274095

Epoch: 6| Step: 5
Training loss: 3.1061809062957764
Validation loss: 2.2703963325869654

Epoch: 6| Step: 6
Training loss: 3.3273980617523193
Validation loss: 2.248092228366483

Epoch: 6| Step: 7
Training loss: 2.9075236320495605
Validation loss: 2.23424018326626

Epoch: 6| Step: 8
Training loss: 2.7953243255615234
Validation loss: 2.23025171731108

Epoch: 6| Step: 9
Training loss: 1.9581483602523804
Validation loss: 2.2269644519334197

Epoch: 6| Step: 10
Training loss: 2.7723183631896973
Validation loss: 2.212514163345419

Epoch: 6| Step: 11
Training loss: 2.467508316040039
Validation loss: 2.200155927288917

Epoch: 6| Step: 12
Training loss: 1.9325448274612427
Validation loss: 2.1972143778236966

Epoch: 6| Step: 13
Training loss: 1.960328221321106
Validation loss: 2.203064674972206

Epoch: 107| Step: 0
Training loss: 2.3724327087402344
Validation loss: 2.198153336842855

Epoch: 6| Step: 1
Training loss: 2.7455825805664062
Validation loss: 2.2078683530130694

Epoch: 6| Step: 2
Training loss: 2.9318220615386963
Validation loss: 2.198832955411685

Epoch: 6| Step: 3
Training loss: 2.0485007762908936
Validation loss: 2.196505723461028

Epoch: 6| Step: 4
Training loss: 2.1377625465393066
Validation loss: 2.19404500274248

Epoch: 6| Step: 5
Training loss: 2.190730571746826
Validation loss: 2.201417007753926

Epoch: 6| Step: 6
Training loss: 2.153040885925293
Validation loss: 2.2079072729233773

Epoch: 6| Step: 7
Training loss: 2.8331003189086914
Validation loss: 2.214362311106856

Epoch: 6| Step: 8
Training loss: 2.232973575592041
Validation loss: 2.234587502735917

Epoch: 6| Step: 9
Training loss: 2.6876397132873535
Validation loss: 2.2643645553178686

Epoch: 6| Step: 10
Training loss: 2.5376288890838623
Validation loss: 2.300450642903646

Epoch: 6| Step: 11
Training loss: 2.738673448562622
Validation loss: 2.390775196013912

Epoch: 6| Step: 12
Training loss: 3.087005853652954
Validation loss: 2.389603114897205

Epoch: 6| Step: 13
Training loss: 3.301279306411743
Validation loss: 2.2969559264439408

Epoch: 108| Step: 0
Training loss: 2.2511539459228516
Validation loss: 2.2231559061234996

Epoch: 6| Step: 1
Training loss: 2.144418239593506
Validation loss: 2.18748571923984

Epoch: 6| Step: 2
Training loss: 2.669833183288574
Validation loss: 2.1779195031812115

Epoch: 6| Step: 3
Training loss: 2.779423713684082
Validation loss: 2.1869476636250815

Epoch: 6| Step: 4
Training loss: 2.534560203552246
Validation loss: 2.1919617165801344

Epoch: 6| Step: 5
Training loss: 2.6642205715179443
Validation loss: 2.188632216504825

Epoch: 6| Step: 6
Training loss: 2.947705030441284
Validation loss: 2.1945259263438563

Epoch: 6| Step: 7
Training loss: 1.9579651355743408
Validation loss: 2.2003212180188907

Epoch: 6| Step: 8
Training loss: 2.3071627616882324
Validation loss: 2.1998339596615044

Epoch: 6| Step: 9
Training loss: 2.841446876525879
Validation loss: 2.1954746374519925

Epoch: 6| Step: 10
Training loss: 2.4590539932250977
Validation loss: 2.187512900239678

Epoch: 6| Step: 11
Training loss: 2.9060049057006836
Validation loss: 2.1837786756536013

Epoch: 6| Step: 12
Training loss: 2.140166759490967
Validation loss: 2.173256088328618

Epoch: 6| Step: 13
Training loss: 3.075932502746582
Validation loss: 2.175800600359517

Epoch: 109| Step: 0
Training loss: 3.166630983352661
Validation loss: 2.182843244203957

Epoch: 6| Step: 1
Training loss: 3.2717478275299072
Validation loss: 2.190957934625687

Epoch: 6| Step: 2
Training loss: 3.0942342281341553
Validation loss: 2.2147496823341615

Epoch: 6| Step: 3
Training loss: 2.169386386871338
Validation loss: 2.2279970376722273

Epoch: 6| Step: 4
Training loss: 1.5769963264465332
Validation loss: 2.24387788772583

Epoch: 6| Step: 5
Training loss: 2.437232494354248
Validation loss: 2.2456656220138713

Epoch: 6| Step: 6
Training loss: 2.3958992958068848
Validation loss: 2.2454566494111092

Epoch: 6| Step: 7
Training loss: 1.881384015083313
Validation loss: 2.2400961742606214

Epoch: 6| Step: 8
Training loss: 2.781411647796631
Validation loss: 2.2358392259126068

Epoch: 6| Step: 9
Training loss: 2.6899337768554688
Validation loss: 2.2453050946676605

Epoch: 6| Step: 10
Training loss: 2.425355911254883
Validation loss: 2.2345900304855837

Epoch: 6| Step: 11
Training loss: 1.6406960487365723
Validation loss: 2.2507886348232145

Epoch: 6| Step: 12
Training loss: 2.244445562362671
Validation loss: 2.2480527534279773

Epoch: 6| Step: 13
Training loss: 3.936458110809326
Validation loss: 2.2254207108610418

Epoch: 110| Step: 0
Training loss: 1.8239938020706177
Validation loss: 2.220321306618311

Epoch: 6| Step: 1
Training loss: 2.985060691833496
Validation loss: 2.2062155841499247

Epoch: 6| Step: 2
Training loss: 2.440744400024414
Validation loss: 2.196968665686987

Epoch: 6| Step: 3
Training loss: 2.650965690612793
Validation loss: 2.186333776802145

Epoch: 6| Step: 4
Training loss: 2.5446739196777344
Validation loss: 2.179233713816571

Epoch: 6| Step: 5
Training loss: 2.4642491340637207
Validation loss: 2.1734881657426075

Epoch: 6| Step: 6
Training loss: 2.484062910079956
Validation loss: 2.1681057637737644

Epoch: 6| Step: 7
Training loss: 2.363086700439453
Validation loss: 2.1692061706255843

Epoch: 6| Step: 8
Training loss: 2.314039468765259
Validation loss: 2.1753647353059504

Epoch: 6| Step: 9
Training loss: 2.8760390281677246
Validation loss: 2.166013520251038

Epoch: 6| Step: 10
Training loss: 2.4407498836517334
Validation loss: 2.1640028389551307

Epoch: 6| Step: 11
Training loss: 2.080869674682617
Validation loss: 2.1607881258892756

Epoch: 6| Step: 12
Training loss: 2.7997772693634033
Validation loss: 2.1628931901788198

Epoch: 6| Step: 13
Training loss: 2.974653959274292
Validation loss: 2.171983339453256

Epoch: 111| Step: 0
Training loss: 2.8882784843444824
Validation loss: 2.170476044377973

Epoch: 6| Step: 1
Training loss: 2.0543293952941895
Validation loss: 2.152567077708501

Epoch: 6| Step: 2
Training loss: 2.5704548358917236
Validation loss: 2.1501606818168395

Epoch: 6| Step: 3
Training loss: 2.191002368927002
Validation loss: 2.147367085179975

Epoch: 6| Step: 4
Training loss: 2.53311824798584
Validation loss: 2.151095865875162

Epoch: 6| Step: 5
Training loss: 2.930907964706421
Validation loss: 2.154524778807035

Epoch: 6| Step: 6
Training loss: 2.181591033935547
Validation loss: 2.1538452256110405

Epoch: 6| Step: 7
Training loss: 1.812052607536316
Validation loss: 2.166956514440557

Epoch: 6| Step: 8
Training loss: 2.377039909362793
Validation loss: 2.173350589249724

Epoch: 6| Step: 9
Training loss: 2.631772518157959
Validation loss: 2.1715368532365367

Epoch: 6| Step: 10
Training loss: 2.7355875968933105
Validation loss: 2.1840948058712866

Epoch: 6| Step: 11
Training loss: 2.055695056915283
Validation loss: 2.1791013184414116

Epoch: 6| Step: 12
Training loss: 2.7132792472839355
Validation loss: 2.191164191051196

Epoch: 6| Step: 13
Training loss: 3.6255717277526855
Validation loss: 2.184289386195521

Epoch: 112| Step: 0
Training loss: 2.2545814514160156
Validation loss: 2.192564841239683

Epoch: 6| Step: 1
Training loss: 2.213778018951416
Validation loss: 2.2105648133062545

Epoch: 6| Step: 2
Training loss: 2.4291648864746094
Validation loss: 2.2091721052764566

Epoch: 6| Step: 3
Training loss: 3.0385608673095703
Validation loss: 2.2039001295643468

Epoch: 6| Step: 4
Training loss: 1.9722166061401367
Validation loss: 2.198528625631845

Epoch: 6| Step: 5
Training loss: 2.8595619201660156
Validation loss: 2.1989034375836773

Epoch: 6| Step: 6
Training loss: 2.85187029838562
Validation loss: 2.189756367796211

Epoch: 6| Step: 7
Training loss: 2.5506680011749268
Validation loss: 2.176768649008966

Epoch: 6| Step: 8
Training loss: 2.743786334991455
Validation loss: 2.1619014099080074

Epoch: 6| Step: 9
Training loss: 2.4468884468078613
Validation loss: 2.160398006439209

Epoch: 6| Step: 10
Training loss: 2.1054182052612305
Validation loss: 2.157676536549804

Epoch: 6| Step: 11
Training loss: 2.3929355144500732
Validation loss: 2.170488137070851

Epoch: 6| Step: 12
Training loss: 2.740016460418701
Validation loss: 2.1853203209497596

Epoch: 6| Step: 13
Training loss: 1.900561809539795
Validation loss: 2.1934909512919765

Epoch: 113| Step: 0
Training loss: 2.249918222427368
Validation loss: 2.2095874483867357

Epoch: 6| Step: 1
Training loss: 2.457123279571533
Validation loss: 2.245501143957979

Epoch: 6| Step: 2
Training loss: 2.6016387939453125
Validation loss: 2.2598543115841445

Epoch: 6| Step: 3
Training loss: 2.6419167518615723
Validation loss: 2.268112487690423

Epoch: 6| Step: 4
Training loss: 2.5082669258117676
Validation loss: 2.258668235553208

Epoch: 6| Step: 5
Training loss: 2.1819610595703125
Validation loss: 2.2428974900194394

Epoch: 6| Step: 6
Training loss: 2.298297882080078
Validation loss: 2.2333895083396667

Epoch: 6| Step: 7
Training loss: 2.8588666915893555
Validation loss: 2.218905959078061

Epoch: 6| Step: 8
Training loss: 3.381865978240967
Validation loss: 2.2180292734535794

Epoch: 6| Step: 9
Training loss: 2.4094858169555664
Validation loss: 2.2090947294747956

Epoch: 6| Step: 10
Training loss: 1.7716310024261475
Validation loss: 2.198516650866437

Epoch: 6| Step: 11
Training loss: 2.459308624267578
Validation loss: 2.2077994564528107

Epoch: 6| Step: 12
Training loss: 2.648672580718994
Validation loss: 2.2118736518326627

Epoch: 6| Step: 13
Training loss: 2.445399284362793
Validation loss: 2.2175979306620937

Epoch: 114| Step: 0
Training loss: 2.393528461456299
Validation loss: 2.2152453545601136

Epoch: 6| Step: 1
Training loss: 2.5687661170959473
Validation loss: 2.2196551458809965

Epoch: 6| Step: 2
Training loss: 2.30216121673584
Validation loss: 2.2282081932149906

Epoch: 6| Step: 3
Training loss: 2.2848782539367676
Validation loss: 2.2345521501315537

Epoch: 6| Step: 4
Training loss: 2.2335169315338135
Validation loss: 2.2426263901495163

Epoch: 6| Step: 5
Training loss: 2.9528613090515137
Validation loss: 2.2554110814166326

Epoch: 6| Step: 6
Training loss: 1.7662994861602783
Validation loss: 2.2345696572334535

Epoch: 6| Step: 7
Training loss: 3.2301011085510254
Validation loss: 2.2192763769498436

Epoch: 6| Step: 8
Training loss: 2.9197187423706055
Validation loss: 2.177279160868737

Epoch: 6| Step: 9
Training loss: 2.3946170806884766
Validation loss: 2.1642209483731176

Epoch: 6| Step: 10
Training loss: 1.9974370002746582
Validation loss: 2.1516601167699343

Epoch: 6| Step: 11
Training loss: 2.5476531982421875
Validation loss: 2.1603906936542963

Epoch: 6| Step: 12
Training loss: 2.7165465354919434
Validation loss: 2.152244747325938

Epoch: 6| Step: 13
Training loss: 2.6876602172851562
Validation loss: 2.155089780848513

Epoch: 115| Step: 0
Training loss: 3.1516318321228027
Validation loss: 2.1505558721480833

Epoch: 6| Step: 1
Training loss: 2.448272705078125
Validation loss: 2.154640313117735

Epoch: 6| Step: 2
Training loss: 1.9647272825241089
Validation loss: 2.1673427563841625

Epoch: 6| Step: 3
Training loss: 2.340649127960205
Validation loss: 2.206276783379175

Epoch: 6| Step: 4
Training loss: 2.309380531311035
Validation loss: 2.221366754142187

Epoch: 6| Step: 5
Training loss: 2.7269201278686523
Validation loss: 2.2538790959183888

Epoch: 6| Step: 6
Training loss: 2.174095869064331
Validation loss: 2.239755440783757

Epoch: 6| Step: 7
Training loss: 3.000525951385498
Validation loss: 2.223207050754178

Epoch: 6| Step: 8
Training loss: 2.175684928894043
Validation loss: 2.1846550049320346

Epoch: 6| Step: 9
Training loss: 1.9941221475601196
Validation loss: 2.16871444384257

Epoch: 6| Step: 10
Training loss: 3.2081539630889893
Validation loss: 2.1645679525149766

Epoch: 6| Step: 11
Training loss: 1.6382310390472412
Validation loss: 2.147453946451987

Epoch: 6| Step: 12
Training loss: 3.1569113731384277
Validation loss: 2.1472077382508146

Epoch: 6| Step: 13
Training loss: 2.2105722427368164
Validation loss: 2.1465369411694106

Epoch: 116| Step: 0
Training loss: 2.145897150039673
Validation loss: 2.139368453333455

Epoch: 6| Step: 1
Training loss: 1.6443147659301758
Validation loss: 2.1402313555440595

Epoch: 6| Step: 2
Training loss: 2.91159725189209
Validation loss: 2.1563716319299515

Epoch: 6| Step: 3
Training loss: 1.6425862312316895
Validation loss: 2.1555630186552643

Epoch: 6| Step: 4
Training loss: 2.1691815853118896
Validation loss: 2.158995552729535

Epoch: 6| Step: 5
Training loss: 3.272803783416748
Validation loss: 2.1706658640215473

Epoch: 6| Step: 6
Training loss: 2.129296064376831
Validation loss: 2.163057445197977

Epoch: 6| Step: 7
Training loss: 2.157679557800293
Validation loss: 2.1605538680989254

Epoch: 6| Step: 8
Training loss: 2.3177995681762695
Validation loss: 2.1570049690943893

Epoch: 6| Step: 9
Training loss: 2.5062854290008545
Validation loss: 2.1532485741440968

Epoch: 6| Step: 10
Training loss: 2.3865199089050293
Validation loss: 2.1438816824266986

Epoch: 6| Step: 11
Training loss: 3.3420352935791016
Validation loss: 2.14452225418501

Epoch: 6| Step: 12
Training loss: 2.9019768238067627
Validation loss: 2.136958404253888

Epoch: 6| Step: 13
Training loss: 3.265761137008667
Validation loss: 2.13550825272837

Epoch: 117| Step: 0
Training loss: 2.7702620029449463
Validation loss: 2.1414507242941085

Epoch: 6| Step: 1
Training loss: 2.7790327072143555
Validation loss: 2.1431556696532876

Epoch: 6| Step: 2
Training loss: 3.0285956859588623
Validation loss: 2.1407213339241604

Epoch: 6| Step: 3
Training loss: 2.24973464012146
Validation loss: 2.1532422111880396

Epoch: 6| Step: 4
Training loss: 2.259284257888794
Validation loss: 2.153120069093602

Epoch: 6| Step: 5
Training loss: 2.042571783065796
Validation loss: 2.1514006122466056

Epoch: 6| Step: 6
Training loss: 2.8306639194488525
Validation loss: 2.1592566069736274

Epoch: 6| Step: 7
Training loss: 2.6079306602478027
Validation loss: 2.1682998262425905

Epoch: 6| Step: 8
Training loss: 2.3598082065582275
Validation loss: 2.184876565010317

Epoch: 6| Step: 9
Training loss: 1.7145963907241821
Validation loss: 2.2090224142997497

Epoch: 6| Step: 10
Training loss: 2.5789897441864014
Validation loss: 2.2150225844434512

Epoch: 6| Step: 11
Training loss: 2.08488392829895
Validation loss: 2.1756650068426646

Epoch: 6| Step: 12
Training loss: 1.906470775604248
Validation loss: 2.17067951028065

Epoch: 6| Step: 13
Training loss: 3.4123854637145996
Validation loss: 2.1418358754086237

Epoch: 118| Step: 0
Training loss: 2.266836643218994
Validation loss: 2.135794678042012

Epoch: 6| Step: 1
Training loss: 2.279341220855713
Validation loss: 2.127215885346936

Epoch: 6| Step: 2
Training loss: 2.0263121128082275
Validation loss: 2.127379946811225

Epoch: 6| Step: 3
Training loss: 2.2325587272644043
Validation loss: 2.134106147673822

Epoch: 6| Step: 4
Training loss: 2.6009202003479004
Validation loss: 2.1328043783864667

Epoch: 6| Step: 5
Training loss: 2.3600144386291504
Validation loss: 2.1390151208446873

Epoch: 6| Step: 6
Training loss: 2.340487241744995
Validation loss: 2.140928045395882

Epoch: 6| Step: 7
Training loss: 2.8283627033233643
Validation loss: 2.1444037345147904

Epoch: 6| Step: 8
Training loss: 2.5141539573669434
Validation loss: 2.1493258553166545

Epoch: 6| Step: 9
Training loss: 2.8479228019714355
Validation loss: 2.138803930692775

Epoch: 6| Step: 10
Training loss: 2.743321657180786
Validation loss: 2.14135903440496

Epoch: 6| Step: 11
Training loss: 2.0218472480773926
Validation loss: 2.130800272828789

Epoch: 6| Step: 12
Training loss: 2.911674976348877
Validation loss: 2.1392307140493907

Epoch: 6| Step: 13
Training loss: 2.1828434467315674
Validation loss: 2.1429390112559

Epoch: 119| Step: 0
Training loss: 1.407468557357788
Validation loss: 2.175863454418798

Epoch: 6| Step: 1
Training loss: 2.0860230922698975
Validation loss: 2.2246782625875166

Epoch: 6| Step: 2
Training loss: 2.8456404209136963
Validation loss: 2.2933842212923112

Epoch: 6| Step: 3
Training loss: 2.0878915786743164
Validation loss: 2.3224240144093833

Epoch: 6| Step: 4
Training loss: 3.1775963306427
Validation loss: 2.355496821864959

Epoch: 6| Step: 5
Training loss: 2.7514419555664062
Validation loss: 2.3521148594476844

Epoch: 6| Step: 6
Training loss: 3.4998979568481445
Validation loss: 2.303462379722185

Epoch: 6| Step: 7
Training loss: 1.9911940097808838
Validation loss: 2.2266744670047554

Epoch: 6| Step: 8
Training loss: 2.7211570739746094
Validation loss: 2.1806348933968493

Epoch: 6| Step: 9
Training loss: 1.6080464124679565
Validation loss: 2.1641718854186354

Epoch: 6| Step: 10
Training loss: 2.347355365753174
Validation loss: 2.1327991126686014

Epoch: 6| Step: 11
Training loss: 2.260324239730835
Validation loss: 2.1209771389602334

Epoch: 6| Step: 12
Training loss: 2.7411417961120605
Validation loss: 2.12079252735261

Epoch: 6| Step: 13
Training loss: 3.238485336303711
Validation loss: 2.125000028200047

Epoch: 120| Step: 0
Training loss: 2.2323474884033203
Validation loss: 2.1314037640889487

Epoch: 6| Step: 1
Training loss: 2.686033010482788
Validation loss: 2.143924187588435

Epoch: 6| Step: 2
Training loss: 2.679171562194824
Validation loss: 2.1499034743155203

Epoch: 6| Step: 3
Training loss: 3.068114757537842
Validation loss: 2.1639386735936648

Epoch: 6| Step: 4
Training loss: 2.407674789428711
Validation loss: 2.1699135277860906

Epoch: 6| Step: 5
Training loss: 2.7078945636749268
Validation loss: 2.2092149360205537

Epoch: 6| Step: 6
Training loss: 2.5105185508728027
Validation loss: 2.271380842372935

Epoch: 6| Step: 7
Training loss: 2.4592998027801514
Validation loss: 2.275486130868235

Epoch: 6| Step: 8
Training loss: 2.3112916946411133
Validation loss: 2.2715040906783073

Epoch: 6| Step: 9
Training loss: 2.3947672843933105
Validation loss: 2.2864969443249445

Epoch: 6| Step: 10
Training loss: 1.8041731119155884
Validation loss: 2.291337145272122

Epoch: 6| Step: 11
Training loss: 1.8870222568511963
Validation loss: 2.2850552681953675

Epoch: 6| Step: 12
Training loss: 2.79195499420166
Validation loss: 2.30076951108953

Epoch: 6| Step: 13
Training loss: 3.1336560249328613
Validation loss: 2.298311665493955

Epoch: 121| Step: 0
Training loss: 2.925572395324707
Validation loss: 2.2958752186067644

Epoch: 6| Step: 1
Training loss: 2.4668426513671875
Validation loss: 2.2709780764836136

Epoch: 6| Step: 2
Training loss: 2.156083106994629
Validation loss: 2.246513351317375

Epoch: 6| Step: 3
Training loss: 2.8301987648010254
Validation loss: 2.228925920301868

Epoch: 6| Step: 4
Training loss: 2.25844144821167
Validation loss: 2.2172397541743454

Epoch: 6| Step: 5
Training loss: 2.4292984008789062
Validation loss: 2.205210865184825

Epoch: 6| Step: 6
Training loss: 1.6805686950683594
Validation loss: 2.193997718954599

Epoch: 6| Step: 7
Training loss: 2.1527390480041504
Validation loss: 2.1852209465478056

Epoch: 6| Step: 8
Training loss: 2.42140793800354
Validation loss: 2.181051392709055

Epoch: 6| Step: 9
Training loss: 3.036374568939209
Validation loss: 2.1606783251608572

Epoch: 6| Step: 10
Training loss: 2.1595959663391113
Validation loss: 2.155248531731226

Epoch: 6| Step: 11
Training loss: 2.5367684364318848
Validation loss: 2.1580099034053024

Epoch: 6| Step: 12
Training loss: 3.129916191101074
Validation loss: 2.17551980351889

Epoch: 6| Step: 13
Training loss: 2.386052131652832
Validation loss: 2.1859751439863637

Epoch: 122| Step: 0
Training loss: 2.337052822113037
Validation loss: 2.2133279667105725

Epoch: 6| Step: 1
Training loss: 2.721930980682373
Validation loss: 2.2167651653289795

Epoch: 6| Step: 2
Training loss: 2.5147523880004883
Validation loss: 2.1921561533404934

Epoch: 6| Step: 3
Training loss: 2.2108325958251953
Validation loss: 2.1720840123391922

Epoch: 6| Step: 4
Training loss: 2.771106004714966
Validation loss: 2.1635495257633988

Epoch: 6| Step: 5
Training loss: 2.6420392990112305
Validation loss: 2.1663855301436556

Epoch: 6| Step: 6
Training loss: 1.4522510766983032
Validation loss: 2.16120506102039

Epoch: 6| Step: 7
Training loss: 2.19883394241333
Validation loss: 2.168885395091067

Epoch: 6| Step: 8
Training loss: 2.130185127258301
Validation loss: 2.1670081000174246

Epoch: 6| Step: 9
Training loss: 3.4924826622009277
Validation loss: 2.175008517439647

Epoch: 6| Step: 10
Training loss: 2.0682930946350098
Validation loss: 2.1941053892976496

Epoch: 6| Step: 11
Training loss: 3.4912636280059814
Validation loss: 2.1989400873902025

Epoch: 6| Step: 12
Training loss: 2.379894733428955
Validation loss: 2.201331792339202

Epoch: 6| Step: 13
Training loss: 1.5512827634811401
Validation loss: 2.1929960737946215

Epoch: 123| Step: 0
Training loss: 3.3999462127685547
Validation loss: 2.1847669257912585

Epoch: 6| Step: 1
Training loss: 1.9002506732940674
Validation loss: 2.1570845573179183

Epoch: 6| Step: 2
Training loss: 2.78433895111084
Validation loss: 2.1526676736852175

Epoch: 6| Step: 3
Training loss: 2.347133159637451
Validation loss: 2.143938758039987

Epoch: 6| Step: 4
Training loss: 2.477769613265991
Validation loss: 2.1428309127848637

Epoch: 6| Step: 5
Training loss: 2.0280821323394775
Validation loss: 2.140053177392611

Epoch: 6| Step: 6
Training loss: 2.16469144821167
Validation loss: 2.128200625860563

Epoch: 6| Step: 7
Training loss: 2.4575934410095215
Validation loss: 2.1471273206895396

Epoch: 6| Step: 8
Training loss: 2.317269802093506
Validation loss: 2.139508162775347

Epoch: 6| Step: 9
Training loss: 2.7598230838775635
Validation loss: 2.1454637127537883

Epoch: 6| Step: 10
Training loss: 2.298499584197998
Validation loss: 2.138123539186293

Epoch: 6| Step: 11
Training loss: 1.9510416984558105
Validation loss: 2.135930674050444

Epoch: 6| Step: 12
Training loss: 2.6531431674957275
Validation loss: 2.1487260762081353

Epoch: 6| Step: 13
Training loss: 2.4999780654907227
Validation loss: 2.1715056409117994

Epoch: 124| Step: 0
Training loss: 2.761348247528076
Validation loss: 2.2251449477288032

Epoch: 6| Step: 1
Training loss: 2.2289199829101562
Validation loss: 2.298819504758363

Epoch: 6| Step: 2
Training loss: 2.7609565258026123
Validation loss: 2.3524805961116666

Epoch: 6| Step: 3
Training loss: 2.5413596630096436
Validation loss: 2.352125157592117

Epoch: 6| Step: 4
Training loss: 2.554173469543457
Validation loss: 2.2931369760985016

Epoch: 6| Step: 5
Training loss: 1.839259147644043
Validation loss: 2.227483078997622

Epoch: 6| Step: 6
Training loss: 2.916433334350586
Validation loss: 2.184842601899178

Epoch: 6| Step: 7
Training loss: 2.5297532081604004
Validation loss: 2.141738219927716

Epoch: 6| Step: 8
Training loss: 2.7909789085388184
Validation loss: 2.1174497835097776

Epoch: 6| Step: 9
Training loss: 2.1945881843566895
Validation loss: 2.1064918759048625

Epoch: 6| Step: 10
Training loss: 2.183657169342041
Validation loss: 2.113293642638832

Epoch: 6| Step: 11
Training loss: 2.944641351699829
Validation loss: 2.1264306178656955

Epoch: 6| Step: 12
Training loss: 2.096895694732666
Validation loss: 2.122566253908219

Epoch: 6| Step: 13
Training loss: 2.0881102085113525
Validation loss: 2.121774004351708

Epoch: 125| Step: 0
Training loss: 2.474712371826172
Validation loss: 2.1239481920837076

Epoch: 6| Step: 1
Training loss: 2.7091023921966553
Validation loss: 2.137700749981788

Epoch: 6| Step: 2
Training loss: 3.430945873260498
Validation loss: 2.1424603180218766

Epoch: 6| Step: 3
Training loss: 2.4052882194519043
Validation loss: 2.160730464484102

Epoch: 6| Step: 4
Training loss: 2.9768595695495605
Validation loss: 2.144644543688784

Epoch: 6| Step: 5
Training loss: 2.74969220161438
Validation loss: 2.1378279527028403

Epoch: 6| Step: 6
Training loss: 2.7357707023620605
Validation loss: 2.1427302386171077

Epoch: 6| Step: 7
Training loss: 2.31630802154541
Validation loss: 2.143770807532854

Epoch: 6| Step: 8
Training loss: 2.1696090698242188
Validation loss: 2.1379008882789203

Epoch: 6| Step: 9
Training loss: 1.3192155361175537
Validation loss: 2.1339879343586583

Epoch: 6| Step: 10
Training loss: 2.407198905944824
Validation loss: 2.1434431101686213

Epoch: 6| Step: 11
Training loss: 1.49466872215271
Validation loss: 2.1552932467511905

Epoch: 6| Step: 12
Training loss: 2.5254993438720703
Validation loss: 2.165896249073808

Epoch: 6| Step: 13
Training loss: 3.028503894805908
Validation loss: 2.1698839126094693

Epoch: 126| Step: 0
Training loss: 2.078446865081787
Validation loss: 2.1899065779101465

Epoch: 6| Step: 1
Training loss: 2.784008026123047
Validation loss: 2.190035878971059

Epoch: 6| Step: 2
Training loss: 2.7416396141052246
Validation loss: 2.1972865109802573

Epoch: 6| Step: 3
Training loss: 2.148836135864258
Validation loss: 2.1859034274214055

Epoch: 6| Step: 4
Training loss: 3.073887825012207
Validation loss: 2.178465767573285

Epoch: 6| Step: 5
Training loss: 2.530789852142334
Validation loss: 2.172243195195352

Epoch: 6| Step: 6
Training loss: 1.850637674331665
Validation loss: 2.1621762180841095

Epoch: 6| Step: 7
Training loss: 2.253086566925049
Validation loss: 2.1557320907551754

Epoch: 6| Step: 8
Training loss: 2.2283201217651367
Validation loss: 2.1546046605674167

Epoch: 6| Step: 9
Training loss: 2.439246416091919
Validation loss: 2.1572593822274158

Epoch: 6| Step: 10
Training loss: 2.5922439098358154
Validation loss: 2.172671377017934

Epoch: 6| Step: 11
Training loss: 2.2390570640563965
Validation loss: 2.1708361256507134

Epoch: 6| Step: 12
Training loss: 2.5126023292541504
Validation loss: 2.176263898931524

Epoch: 6| Step: 13
Training loss: 2.8355624675750732
Validation loss: 2.1562626848938646

Epoch: 127| Step: 0
Training loss: 3.2591958045959473
Validation loss: 2.1420030773326917

Epoch: 6| Step: 1
Training loss: 1.8539448976516724
Validation loss: 2.124990128701733

Epoch: 6| Step: 2
Training loss: 2.67740535736084
Validation loss: 2.1235628076778945

Epoch: 6| Step: 3
Training loss: 1.8111450672149658
Validation loss: 2.113869479907456

Epoch: 6| Step: 4
Training loss: 2.5830488204956055
Validation loss: 2.1072541052295315

Epoch: 6| Step: 5
Training loss: 3.0737040042877197
Validation loss: 2.1034385235078874

Epoch: 6| Step: 6
Training loss: 2.0326004028320312
Validation loss: 2.0952188507203133

Epoch: 6| Step: 7
Training loss: 2.910057544708252
Validation loss: 2.097057911657518

Epoch: 6| Step: 8
Training loss: 2.5581538677215576
Validation loss: 2.0960654699674217

Epoch: 6| Step: 9
Training loss: 2.228567123413086
Validation loss: 2.0978559858055523

Epoch: 6| Step: 10
Training loss: 2.140934944152832
Validation loss: 2.0911478201548257

Epoch: 6| Step: 11
Training loss: 2.5110435485839844
Validation loss: 2.1012967619844662

Epoch: 6| Step: 12
Training loss: 1.9900609254837036
Validation loss: 2.1196390941578853

Epoch: 6| Step: 13
Training loss: 2.0699357986450195
Validation loss: 2.1337321035323606

Epoch: 128| Step: 0
Training loss: 2.7573952674865723
Validation loss: 2.1219579994037585

Epoch: 6| Step: 1
Training loss: 2.197721481323242
Validation loss: 2.126519162167785

Epoch: 6| Step: 2
Training loss: 2.0716729164123535
Validation loss: 2.1153657808098743

Epoch: 6| Step: 3
Training loss: 2.4206557273864746
Validation loss: 2.1099148552904845

Epoch: 6| Step: 4
Training loss: 2.4172279834747314
Validation loss: 2.1093941760319534

Epoch: 6| Step: 5
Training loss: 2.514692544937134
Validation loss: 2.1088170415611676

Epoch: 6| Step: 6
Training loss: 2.200099229812622
Validation loss: 2.10817729144968

Epoch: 6| Step: 7
Training loss: 1.9946848154067993
Validation loss: 2.095908841779155

Epoch: 6| Step: 8
Training loss: 3.5469813346862793
Validation loss: 2.1015578264831216

Epoch: 6| Step: 9
Training loss: 2.635424852371216
Validation loss: 2.095532250660722

Epoch: 6| Step: 10
Training loss: 2.368831157684326
Validation loss: 2.0902229714137253

Epoch: 6| Step: 11
Training loss: 2.313718795776367
Validation loss: 2.1092566072299914

Epoch: 6| Step: 12
Training loss: 1.9383931159973145
Validation loss: 2.1314259549622894

Epoch: 6| Step: 13
Training loss: 2.1209747791290283
Validation loss: 2.1414280963200394

Epoch: 129| Step: 0
Training loss: 3.1153011322021484
Validation loss: 2.168118969086678

Epoch: 6| Step: 1
Training loss: 1.6874796152114868
Validation loss: 2.166796476610245

Epoch: 6| Step: 2
Training loss: 2.358335494995117
Validation loss: 2.135111073011993

Epoch: 6| Step: 3
Training loss: 2.194596290588379
Validation loss: 2.1249788345829135

Epoch: 6| Step: 4
Training loss: 3.0665359497070312
Validation loss: 2.114432491281981

Epoch: 6| Step: 5
Training loss: 1.6845686435699463
Validation loss: 2.0991211886047036

Epoch: 6| Step: 6
Training loss: 1.9699492454528809
Validation loss: 2.09536624082955

Epoch: 6| Step: 7
Training loss: 2.7506752014160156
Validation loss: 2.0945163067950996

Epoch: 6| Step: 8
Training loss: 2.7911159992218018
Validation loss: 2.073733973246749

Epoch: 6| Step: 9
Training loss: 2.6436877250671387
Validation loss: 2.0856453936587096

Epoch: 6| Step: 10
Training loss: 2.0801825523376465
Validation loss: 2.097499542338874

Epoch: 6| Step: 11
Training loss: 3.04282283782959
Validation loss: 2.0933607803877963

Epoch: 6| Step: 12
Training loss: 2.5953826904296875
Validation loss: 2.0957510727708057

Epoch: 6| Step: 13
Training loss: 0.9499377012252808
Validation loss: 2.0938653484467538

Epoch: 130| Step: 0
Training loss: 2.5786242485046387
Validation loss: 2.1043906904036

Epoch: 6| Step: 1
Training loss: 1.4486205577850342
Validation loss: 2.139193081086682

Epoch: 6| Step: 2
Training loss: 2.6571602821350098
Validation loss: 2.182400245820322

Epoch: 6| Step: 3
Training loss: 2.7703287601470947
Validation loss: 2.2240118826589277

Epoch: 6| Step: 4
Training loss: 2.5832271575927734
Validation loss: 2.220251597383971

Epoch: 6| Step: 5
Training loss: 2.0952630043029785
Validation loss: 2.2252879245306856

Epoch: 6| Step: 6
Training loss: 2.0414090156555176
Validation loss: 2.214720892649825

Epoch: 6| Step: 7
Training loss: 2.8992629051208496
Validation loss: 2.188214555863411

Epoch: 6| Step: 8
Training loss: 2.230287790298462
Validation loss: 2.1580203963864233

Epoch: 6| Step: 9
Training loss: 2.6487207412719727
Validation loss: 2.1060819241308395

Epoch: 6| Step: 10
Training loss: 1.950526475906372
Validation loss: 2.091775176345661

Epoch: 6| Step: 11
Training loss: 2.1136395931243896
Validation loss: 2.0753974248004217

Epoch: 6| Step: 12
Training loss: 2.714508533477783
Validation loss: 2.0707364287427676

Epoch: 6| Step: 13
Training loss: 3.4561777114868164
Validation loss: 2.0767444256813294

Epoch: 131| Step: 0
Training loss: 2.428668975830078
Validation loss: 2.0766183932622275

Epoch: 6| Step: 1
Training loss: 2.424135684967041
Validation loss: 2.0853468192520963

Epoch: 6| Step: 2
Training loss: 2.6525208950042725
Validation loss: 2.0776571907022947

Epoch: 6| Step: 3
Training loss: 2.1453311443328857
Validation loss: 2.075646418397145

Epoch: 6| Step: 4
Training loss: 2.558276414871216
Validation loss: 2.0817933851672756

Epoch: 6| Step: 5
Training loss: 2.452512502670288
Validation loss: 2.0823580347081667

Epoch: 6| Step: 6
Training loss: 2.3687424659729004
Validation loss: 2.089774568875631

Epoch: 6| Step: 7
Training loss: 2.617076873779297
Validation loss: 2.1096380128655383

Epoch: 6| Step: 8
Training loss: 2.59755802154541
Validation loss: 2.148331073022658

Epoch: 6| Step: 9
Training loss: 2.483036518096924
Validation loss: 2.158453513217229

Epoch: 6| Step: 10
Training loss: 2.379423141479492
Validation loss: 2.2128418709642146

Epoch: 6| Step: 11
Training loss: 2.995532274246216
Validation loss: 2.246272410115888

Epoch: 6| Step: 12
Training loss: 2.0206756591796875
Validation loss: 2.2280254210195234

Epoch: 6| Step: 13
Training loss: 1.6689497232437134
Validation loss: 2.1820704193525415

Epoch: 132| Step: 0
Training loss: 2.772552728652954
Validation loss: 2.1358275490422405

Epoch: 6| Step: 1
Training loss: 1.7852469682693481
Validation loss: 2.1011880905397478

Epoch: 6| Step: 2
Training loss: 2.4674243927001953
Validation loss: 2.087935527165731

Epoch: 6| Step: 3
Training loss: 2.5050408840179443
Validation loss: 2.0819518386676745

Epoch: 6| Step: 4
Training loss: 2.4356091022491455
Validation loss: 2.080139999748558

Epoch: 6| Step: 5
Training loss: 2.4127485752105713
Validation loss: 2.072887446290703

Epoch: 6| Step: 6
Training loss: 1.925354242324829
Validation loss: 2.067801331961027

Epoch: 6| Step: 7
Training loss: 3.2847509384155273
Validation loss: 2.070385303548587

Epoch: 6| Step: 8
Training loss: 2.542252779006958
Validation loss: 2.0659356091612127

Epoch: 6| Step: 9
Training loss: 2.8978047370910645
Validation loss: 2.0663317480394916

Epoch: 6| Step: 10
Training loss: 2.273366689682007
Validation loss: 2.068895350220383

Epoch: 6| Step: 11
Training loss: 1.8225243091583252
Validation loss: 2.0773469196852816

Epoch: 6| Step: 12
Training loss: 2.262359142303467
Validation loss: 2.0778644136203233

Epoch: 6| Step: 13
Training loss: 2.2299699783325195
Validation loss: 2.0761131548112437

Epoch: 133| Step: 0
Training loss: 1.9199612140655518
Validation loss: 2.0806794704929477

Epoch: 6| Step: 1
Training loss: 2.9225094318389893
Validation loss: 2.080096108939058

Epoch: 6| Step: 2
Training loss: 2.0644004344940186
Validation loss: 2.0898956034773137

Epoch: 6| Step: 3
Training loss: 2.1226983070373535
Validation loss: 2.094410099009032

Epoch: 6| Step: 4
Training loss: 2.6930510997772217
Validation loss: 2.1046404120742634

Epoch: 6| Step: 5
Training loss: 2.463822364807129
Validation loss: 2.1283806152241205

Epoch: 6| Step: 6
Training loss: 2.350912570953369
Validation loss: 2.1511017455849597

Epoch: 6| Step: 7
Training loss: 2.5916342735290527
Validation loss: 2.176888335135675

Epoch: 6| Step: 8
Training loss: 2.843968152999878
Validation loss: 2.1883722607807448

Epoch: 6| Step: 9
Training loss: 2.2442173957824707
Validation loss: 2.1922390332785984

Epoch: 6| Step: 10
Training loss: 1.9522695541381836
Validation loss: 2.1294618063075568

Epoch: 6| Step: 11
Training loss: 2.0665059089660645
Validation loss: 2.0948653272403184

Epoch: 6| Step: 12
Training loss: 2.805605173110962
Validation loss: 2.065305727784352

Epoch: 6| Step: 13
Training loss: 2.659364938735962
Validation loss: 2.0572832104980305

Epoch: 134| Step: 0
Training loss: 2.4891672134399414
Validation loss: 2.055135187282357

Epoch: 6| Step: 1
Training loss: 2.0698578357696533
Validation loss: 2.062378914125504

Epoch: 6| Step: 2
Training loss: 2.741565704345703
Validation loss: 2.07394080264594

Epoch: 6| Step: 3
Training loss: 2.5058209896087646
Validation loss: 2.0731305845322145

Epoch: 6| Step: 4
Training loss: 2.1556570529937744
Validation loss: 2.074637072060698

Epoch: 6| Step: 5
Training loss: 3.1664791107177734
Validation loss: 2.0671068083855415

Epoch: 6| Step: 6
Training loss: 2.1414096355438232
Validation loss: 2.0718742057841313

Epoch: 6| Step: 7
Training loss: 2.5947937965393066
Validation loss: 2.0657220117507444

Epoch: 6| Step: 8
Training loss: 2.495971202850342
Validation loss: 2.066267216077415

Epoch: 6| Step: 9
Training loss: 2.626443862915039
Validation loss: 2.073052321710894

Epoch: 6| Step: 10
Training loss: 2.0072576999664307
Validation loss: 2.095147561001521

Epoch: 6| Step: 11
Training loss: 2.142404794692993
Validation loss: 2.1248322507386566

Epoch: 6| Step: 12
Training loss: 2.3098669052124023
Validation loss: 2.154993849415933

Epoch: 6| Step: 13
Training loss: 2.4581401348114014
Validation loss: 2.1626938132829565

Epoch: 135| Step: 0
Training loss: 2.1157164573669434
Validation loss: 2.1690224550103627

Epoch: 6| Step: 1
Training loss: 2.848585367202759
Validation loss: 2.1511844665773454

Epoch: 6| Step: 2
Training loss: 2.7204761505126953
Validation loss: 2.1350341458474436

Epoch: 6| Step: 3
Training loss: 3.1970348358154297
Validation loss: 2.1274502790102394

Epoch: 6| Step: 4
Training loss: 3.2528059482574463
Validation loss: 2.1115171588877195

Epoch: 6| Step: 5
Training loss: 2.7907323837280273
Validation loss: 2.099830824841735

Epoch: 6| Step: 6
Training loss: 1.659440517425537
Validation loss: 2.094272082851779

Epoch: 6| Step: 7
Training loss: 2.3004963397979736
Validation loss: 2.081245555672594

Epoch: 6| Step: 8
Training loss: 2.4717612266540527
Validation loss: 2.0791963479852162

Epoch: 6| Step: 9
Training loss: 2.476588487625122
Validation loss: 2.0686824757565736

Epoch: 6| Step: 10
Training loss: 2.257887840270996
Validation loss: 2.0622429924626506

Epoch: 6| Step: 11
Training loss: 1.8947721719741821
Validation loss: 2.064066316491814

Epoch: 6| Step: 12
Training loss: 1.6698081493377686
Validation loss: 2.0712975084140735

Epoch: 6| Step: 13
Training loss: 0.9088541865348816
Validation loss: 2.07636014364099

Epoch: 136| Step: 0
Training loss: 3.2892234325408936
Validation loss: 2.079095894290555

Epoch: 6| Step: 1
Training loss: 1.8670083284378052
Validation loss: 2.090688370889233

Epoch: 6| Step: 2
Training loss: 2.238298177719116
Validation loss: 2.109044454431021

Epoch: 6| Step: 3
Training loss: 2.9340882301330566
Validation loss: 2.12561039258075

Epoch: 6| Step: 4
Training loss: 2.2006149291992188
Validation loss: 2.1474473322591474

Epoch: 6| Step: 5
Training loss: 2.405867576599121
Validation loss: 2.187626128555626

Epoch: 6| Step: 6
Training loss: 1.9893079996109009
Validation loss: 2.1768834514002644

Epoch: 6| Step: 7
Training loss: 2.581014394760132
Validation loss: 2.156992366237025

Epoch: 6| Step: 8
Training loss: 1.9210988283157349
Validation loss: 2.12879886293924

Epoch: 6| Step: 9
Training loss: 2.4331741333007812
Validation loss: 2.108329757567375

Epoch: 6| Step: 10
Training loss: 2.6395230293273926
Validation loss: 2.100594264204784

Epoch: 6| Step: 11
Training loss: 2.2496461868286133
Validation loss: 2.1006083411555134

Epoch: 6| Step: 12
Training loss: 2.3030169010162354
Validation loss: 2.1054502148782053

Epoch: 6| Step: 13
Training loss: 2.443067789077759
Validation loss: 2.1044351413685787

Epoch: 137| Step: 0
Training loss: 2.9714558124542236
Validation loss: 2.103594386449424

Epoch: 6| Step: 1
Training loss: 2.1209418773651123
Validation loss: 2.0990041609733336

Epoch: 6| Step: 2
Training loss: 2.438079357147217
Validation loss: 2.1005591936008905

Epoch: 6| Step: 3
Training loss: 1.867145299911499
Validation loss: 2.1024310768291516

Epoch: 6| Step: 4
Training loss: 3.252742290496826
Validation loss: 2.0990703593018236

Epoch: 6| Step: 5
Training loss: 2.7487709522247314
Validation loss: 2.0955229446452153

Epoch: 6| Step: 6
Training loss: 2.8930625915527344
Validation loss: 2.0976541913965696

Epoch: 6| Step: 7
Training loss: 2.3663291931152344
Validation loss: 2.098799326086557

Epoch: 6| Step: 8
Training loss: 2.668475866317749
Validation loss: 2.111866965088793

Epoch: 6| Step: 9
Training loss: 1.813530445098877
Validation loss: 2.1055610154264714

Epoch: 6| Step: 10
Training loss: 1.3380300998687744
Validation loss: 2.1034016288736814

Epoch: 6| Step: 11
Training loss: 2.4644269943237305
Validation loss: 2.1100903505920083

Epoch: 6| Step: 12
Training loss: 1.9787002801895142
Validation loss: 2.1128177412094606

Epoch: 6| Step: 13
Training loss: 2.4889886379241943
Validation loss: 2.092860596154326

Epoch: 138| Step: 0
Training loss: 2.6003284454345703
Validation loss: 2.0901060860644103

Epoch: 6| Step: 1
Training loss: 2.9449076652526855
Validation loss: 2.085151428817421

Epoch: 6| Step: 2
Training loss: 2.208472490310669
Validation loss: 2.0974214987088273

Epoch: 6| Step: 3
Training loss: 2.6540586948394775
Validation loss: 2.0899824429583806

Epoch: 6| Step: 4
Training loss: 1.9510610103607178
Validation loss: 2.0769113468867477

Epoch: 6| Step: 5
Training loss: 2.1342034339904785
Validation loss: 2.088061491648356

Epoch: 6| Step: 6
Training loss: 2.514403820037842
Validation loss: 2.078175110201682

Epoch: 6| Step: 7
Training loss: 1.8282310962677002
Validation loss: 2.065289871667021

Epoch: 6| Step: 8
Training loss: 1.9638214111328125
Validation loss: 2.0644630052710093

Epoch: 6| Step: 9
Training loss: 2.703537702560425
Validation loss: 2.040019494231029

Epoch: 6| Step: 10
Training loss: 2.0032267570495605
Validation loss: 2.0403511985655753

Epoch: 6| Step: 11
Training loss: 2.2910690307617188
Validation loss: 2.0394631790858444

Epoch: 6| Step: 12
Training loss: 2.634402275085449
Validation loss: 2.036329789828229

Epoch: 6| Step: 13
Training loss: 3.2679052352905273
Validation loss: 2.041109518338275

Epoch: 139| Step: 0
Training loss: 2.286076307296753
Validation loss: 2.0459058336032334

Epoch: 6| Step: 1
Training loss: 2.3235831260681152
Validation loss: 2.0636088694295576

Epoch: 6| Step: 2
Training loss: 1.879899024963379
Validation loss: 2.0972075487977717

Epoch: 6| Step: 3
Training loss: 2.906778573989868
Validation loss: 2.118174499081027

Epoch: 6| Step: 4
Training loss: 1.8909499645233154
Validation loss: 2.13310287075658

Epoch: 6| Step: 5
Training loss: 2.20105242729187
Validation loss: 2.14473880234585

Epoch: 6| Step: 6
Training loss: 2.7131552696228027
Validation loss: 2.1394622889898156

Epoch: 6| Step: 7
Training loss: 2.5601985454559326
Validation loss: 2.1000072033174577

Epoch: 6| Step: 8
Training loss: 1.8403620719909668
Validation loss: 2.0811998562146257

Epoch: 6| Step: 9
Training loss: 2.6540579795837402
Validation loss: 2.0676948075653403

Epoch: 6| Step: 10
Training loss: 2.010256290435791
Validation loss: 2.0576671220922984

Epoch: 6| Step: 11
Training loss: 3.1237642765045166
Validation loss: 2.047556864318027

Epoch: 6| Step: 12
Training loss: 2.524125099182129
Validation loss: 2.0531395686570035

Epoch: 6| Step: 13
Training loss: 2.073728084564209
Validation loss: 2.0455891316936863

Epoch: 140| Step: 0
Training loss: 2.0196645259857178
Validation loss: 2.0399780004255232

Epoch: 6| Step: 1
Training loss: 2.4161391258239746
Validation loss: 2.0317830680519022

Epoch: 6| Step: 2
Training loss: 2.5039992332458496
Validation loss: 2.030797794301023

Epoch: 6| Step: 3
Training loss: 2.2898497581481934
Validation loss: 2.0297267859981907

Epoch: 6| Step: 4
Training loss: 2.071967601776123
Validation loss: 2.027808799538561

Epoch: 6| Step: 5
Training loss: 2.400602102279663
Validation loss: 2.0264132881677277

Epoch: 6| Step: 6
Training loss: 2.5447254180908203
Validation loss: 2.04024750186551

Epoch: 6| Step: 7
Training loss: 2.4898903369903564
Validation loss: 2.0441995923237135

Epoch: 6| Step: 8
Training loss: 3.398956060409546
Validation loss: 2.0489998402134066

Epoch: 6| Step: 9
Training loss: 2.5044054985046387
Validation loss: 2.0478054297867643

Epoch: 6| Step: 10
Training loss: 2.14284610748291
Validation loss: 2.0533484848596717

Epoch: 6| Step: 11
Training loss: 2.2886500358581543
Validation loss: 2.048538002916562

Epoch: 6| Step: 12
Training loss: 1.883556604385376
Validation loss: 2.053013518292417

Epoch: 6| Step: 13
Training loss: 2.2442944049835205
Validation loss: 2.07606444820281

Epoch: 141| Step: 0
Training loss: 2.427607536315918
Validation loss: 2.0941716214661956

Epoch: 6| Step: 1
Training loss: 2.7066965103149414
Validation loss: 2.0835982343201995

Epoch: 6| Step: 2
Training loss: 2.3967459201812744
Validation loss: 2.0734687415502404

Epoch: 6| Step: 3
Training loss: 2.387810230255127
Validation loss: 2.069695306080644

Epoch: 6| Step: 4
Training loss: 1.7791110277175903
Validation loss: 2.075262713175948

Epoch: 6| Step: 5
Training loss: 2.7815802097320557
Validation loss: 2.096240790941382

Epoch: 6| Step: 6
Training loss: 2.448197603225708
Validation loss: 2.0771878893657396

Epoch: 6| Step: 7
Training loss: 1.800673007965088
Validation loss: 2.069557387341735

Epoch: 6| Step: 8
Training loss: 2.242058038711548
Validation loss: 2.0569630322917813

Epoch: 6| Step: 9
Training loss: 2.89884090423584
Validation loss: 2.0513499641931183

Epoch: 6| Step: 10
Training loss: 2.2307028770446777
Validation loss: 2.0376851174139206

Epoch: 6| Step: 11
Training loss: 2.020493507385254
Validation loss: 2.027945949185279

Epoch: 6| Step: 12
Training loss: 2.545442581176758
Validation loss: 2.025255136592414

Epoch: 6| Step: 13
Training loss: 2.1165409088134766
Validation loss: 2.0348046082322315

Epoch: 142| Step: 0
Training loss: 2.3193421363830566
Validation loss: 2.0396561494437595

Epoch: 6| Step: 1
Training loss: 2.0755906105041504
Validation loss: 2.031460628714613

Epoch: 6| Step: 2
Training loss: 2.671130895614624
Validation loss: 2.0461805558973745

Epoch: 6| Step: 3
Training loss: 2.0548274517059326
Validation loss: 2.041805431406985

Epoch: 6| Step: 4
Training loss: 2.369567632675171
Validation loss: 2.0476966122145295

Epoch: 6| Step: 5
Training loss: 1.479981780052185
Validation loss: 2.052793912990119

Epoch: 6| Step: 6
Training loss: 3.4814605712890625
Validation loss: 2.0555488563353017

Epoch: 6| Step: 7
Training loss: 2.0599799156188965
Validation loss: 2.0439435922971336

Epoch: 6| Step: 8
Training loss: 2.425957202911377
Validation loss: 2.050067583719889

Epoch: 6| Step: 9
Training loss: 2.102560520172119
Validation loss: 2.0703179195363033

Epoch: 6| Step: 10
Training loss: 1.8321869373321533
Validation loss: 2.094423306885586

Epoch: 6| Step: 11
Training loss: 2.941459894180298
Validation loss: 2.1362323478985856

Epoch: 6| Step: 12
Training loss: 2.418602466583252
Validation loss: 2.1159647972353044

Epoch: 6| Step: 13
Training loss: 2.7922849655151367
Validation loss: 2.0541149339368268

Epoch: 143| Step: 0
Training loss: 2.3656973838806152
Validation loss: 2.0474392598675144

Epoch: 6| Step: 1
Training loss: 2.2997188568115234
Validation loss: 2.037360432327435

Epoch: 6| Step: 2
Training loss: 2.0776724815368652
Validation loss: 2.0285523604321223

Epoch: 6| Step: 3
Training loss: 2.690481662750244
Validation loss: 2.038049139002318

Epoch: 6| Step: 4
Training loss: 2.3110904693603516
Validation loss: 2.0503349317017423

Epoch: 6| Step: 5
Training loss: 2.12532901763916
Validation loss: 2.057297134912142

Epoch: 6| Step: 6
Training loss: 2.739506721496582
Validation loss: 2.071186283583282

Epoch: 6| Step: 7
Training loss: 2.3515758514404297
Validation loss: 2.0541020849699616

Epoch: 6| Step: 8
Training loss: 2.497192144393921
Validation loss: 2.0633392385257188

Epoch: 6| Step: 9
Training loss: 2.182821273803711
Validation loss: 2.0514293434799358

Epoch: 6| Step: 10
Training loss: 1.8616503477096558
Validation loss: 2.053293699859291

Epoch: 6| Step: 11
Training loss: 2.427689790725708
Validation loss: 2.0531021164309595

Epoch: 6| Step: 12
Training loss: 2.2647669315338135
Validation loss: 2.062151630719503

Epoch: 6| Step: 13
Training loss: 2.7090044021606445
Validation loss: 2.0601128775586366

Epoch: 144| Step: 0
Training loss: 3.0852575302124023
Validation loss: 2.070513848335512

Epoch: 6| Step: 1
Training loss: 2.029585599899292
Validation loss: 2.070270930567095

Epoch: 6| Step: 2
Training loss: 2.731428861618042
Validation loss: 2.0665818209289224

Epoch: 6| Step: 3
Training loss: 1.6293524503707886
Validation loss: 2.0831331847816386

Epoch: 6| Step: 4
Training loss: 1.9055824279785156
Validation loss: 2.0582083348304994

Epoch: 6| Step: 5
Training loss: 2.1652817726135254
Validation loss: 2.0689281148295247

Epoch: 6| Step: 6
Training loss: 2.0490200519561768
Validation loss: 2.0495902927972938

Epoch: 6| Step: 7
Training loss: 2.361952781677246
Validation loss: 2.0411787879082466

Epoch: 6| Step: 8
Training loss: 3.3379569053649902
Validation loss: 2.0454610111892864

Epoch: 6| Step: 9
Training loss: 2.209256410598755
Validation loss: 2.0391985088266353

Epoch: 6| Step: 10
Training loss: 2.300279140472412
Validation loss: 2.053591905101653

Epoch: 6| Step: 11
Training loss: 2.1758298873901367
Validation loss: 2.0379060365820445

Epoch: 6| Step: 12
Training loss: 2.1538922786712646
Validation loss: 2.0382324316168345

Epoch: 6| Step: 13
Training loss: 2.295659303665161
Validation loss: 2.0418470034035305

Epoch: 145| Step: 0
Training loss: 2.316188335418701
Validation loss: 2.0303879335362423

Epoch: 6| Step: 1
Training loss: 1.8947848081588745
Validation loss: 2.024640867787023

Epoch: 6| Step: 2
Training loss: 2.78739070892334
Validation loss: 2.029541213025329

Epoch: 6| Step: 3
Training loss: 1.7603404521942139
Validation loss: 2.0305220568051903

Epoch: 6| Step: 4
Training loss: 2.148141860961914
Validation loss: 2.036537680574643

Epoch: 6| Step: 5
Training loss: 2.9586615562438965
Validation loss: 2.045579728259835

Epoch: 6| Step: 6
Training loss: 2.5332155227661133
Validation loss: 2.0576622293841456

Epoch: 6| Step: 7
Training loss: 2.6142969131469727
Validation loss: 2.0835533398453907

Epoch: 6| Step: 8
Training loss: 1.9284156560897827
Validation loss: 2.081891575167256

Epoch: 6| Step: 9
Training loss: 2.3016133308410645
Validation loss: 2.0717404298884894

Epoch: 6| Step: 10
Training loss: 2.165477991104126
Validation loss: 2.038280646006266

Epoch: 6| Step: 11
Training loss: 2.5513968467712402
Validation loss: 2.0321915662416847

Epoch: 6| Step: 12
Training loss: 1.8325384855270386
Validation loss: 2.0316169966933546

Epoch: 6| Step: 13
Training loss: 3.138029098510742
Validation loss: 2.025885505060996

Epoch: 146| Step: 0
Training loss: 2.6279354095458984
Validation loss: 2.025793780562698

Epoch: 6| Step: 1
Training loss: 2.0532753467559814
Validation loss: 2.0237834222855104

Epoch: 6| Step: 2
Training loss: 2.116657257080078
Validation loss: 2.0378796515926236

Epoch: 6| Step: 3
Training loss: 2.1011784076690674
Validation loss: 2.0474512141237975

Epoch: 6| Step: 4
Training loss: 2.5352320671081543
Validation loss: 2.0495326647194485

Epoch: 6| Step: 5
Training loss: 2.9593911170959473
Validation loss: 2.0303284352825535

Epoch: 6| Step: 6
Training loss: 3.091582775115967
Validation loss: 2.034023436166907

Epoch: 6| Step: 7
Training loss: 1.7978178262710571
Validation loss: 2.0230556559819046

Epoch: 6| Step: 8
Training loss: 1.9283838272094727
Validation loss: 2.0133921484793387

Epoch: 6| Step: 9
Training loss: 2.154752731323242
Validation loss: 2.014365155209777

Epoch: 6| Step: 10
Training loss: 1.6115442514419556
Validation loss: 2.00776937700087

Epoch: 6| Step: 11
Training loss: 2.694423198699951
Validation loss: 2.0213690970533635

Epoch: 6| Step: 12
Training loss: 2.231776237487793
Validation loss: 2.0478006101423696

Epoch: 6| Step: 13
Training loss: 3.0378851890563965
Validation loss: 2.1050307391792216

Epoch: 147| Step: 0
Training loss: 2.7695436477661133
Validation loss: 2.105780093900619

Epoch: 6| Step: 1
Training loss: 2.317436456680298
Validation loss: 2.0920400773325274

Epoch: 6| Step: 2
Training loss: 2.7032828330993652
Validation loss: 2.0479013330192974

Epoch: 6| Step: 3
Training loss: 1.8295063972473145
Validation loss: 2.0275741354111703

Epoch: 6| Step: 4
Training loss: 1.8636966943740845
Validation loss: 2.0021207063428816

Epoch: 6| Step: 5
Training loss: 2.6245245933532715
Validation loss: 2.005132544425226

Epoch: 6| Step: 6
Training loss: 2.473125457763672
Validation loss: 2.000017732702276

Epoch: 6| Step: 7
Training loss: 2.8011231422424316
Validation loss: 2.0053986528868317

Epoch: 6| Step: 8
Training loss: 1.8903026580810547
Validation loss: 2.0100905292777607

Epoch: 6| Step: 9
Training loss: 2.0931167602539062
Validation loss: 2.00667247849126

Epoch: 6| Step: 10
Training loss: 1.7565288543701172
Validation loss: 2.0196769929701284

Epoch: 6| Step: 11
Training loss: 2.4032392501831055
Validation loss: 2.0250468292543964

Epoch: 6| Step: 12
Training loss: 2.397834300994873
Validation loss: 2.0476661215546312

Epoch: 6| Step: 13
Training loss: 3.0497589111328125
Validation loss: 2.0658292872931368

Epoch: 148| Step: 0
Training loss: 2.010467767715454
Validation loss: 2.064002431848998

Epoch: 6| Step: 1
Training loss: 1.8210737705230713
Validation loss: 2.076499472382248

Epoch: 6| Step: 2
Training loss: 2.179609537124634
Validation loss: 2.0788784360372894

Epoch: 6| Step: 3
Training loss: 2.086090564727783
Validation loss: 2.07934174999114

Epoch: 6| Step: 4
Training loss: 2.5382189750671387
Validation loss: 2.083473720858174

Epoch: 6| Step: 5
Training loss: 2.4486875534057617
Validation loss: 2.0837322050525295

Epoch: 6| Step: 6
Training loss: 3.0079965591430664
Validation loss: 2.0667973410698677

Epoch: 6| Step: 7
Training loss: 1.7967615127563477
Validation loss: 2.0672066955156225

Epoch: 6| Step: 8
Training loss: 3.6162636280059814
Validation loss: 2.060555041477244

Epoch: 6| Step: 9
Training loss: 2.2894654273986816
Validation loss: 2.06373329060052

Epoch: 6| Step: 10
Training loss: 1.5615614652633667
Validation loss: 2.0584161743041007

Epoch: 6| Step: 11
Training loss: 2.073740005493164
Validation loss: 2.050452821998186

Epoch: 6| Step: 12
Training loss: 3.0266993045806885
Validation loss: 2.058337080863214

Epoch: 6| Step: 13
Training loss: 1.4837366342544556
Validation loss: 2.065058944045856

Epoch: 149| Step: 0
Training loss: 2.60603666305542
Validation loss: 2.0543038140061083

Epoch: 6| Step: 1
Training loss: 2.40478777885437
Validation loss: 2.0436663435351465

Epoch: 6| Step: 2
Training loss: 2.1647939682006836
Validation loss: 2.044113782144362

Epoch: 6| Step: 3
Training loss: 2.361445903778076
Validation loss: 2.0284341355805755

Epoch: 6| Step: 4
Training loss: 2.5192465782165527
Validation loss: 2.032441108457504

Epoch: 6| Step: 5
Training loss: 2.1029272079467773
Validation loss: 2.0265969768647225

Epoch: 6| Step: 6
Training loss: 1.9315494298934937
Validation loss: 2.034414909219229

Epoch: 6| Step: 7
Training loss: 2.2617688179016113
Validation loss: 2.0383640361088577

Epoch: 6| Step: 8
Training loss: 2.019705057144165
Validation loss: 2.0353779677421815

Epoch: 6| Step: 9
Training loss: 2.2286393642425537
Validation loss: 2.0484814695132676

Epoch: 6| Step: 10
Training loss: 2.985158681869507
Validation loss: 2.0730891381540606

Epoch: 6| Step: 11
Training loss: 2.8540101051330566
Validation loss: 2.1026290155226186

Epoch: 6| Step: 12
Training loss: 2.118213415145874
Validation loss: 2.128639849283362

Epoch: 6| Step: 13
Training loss: 1.598196268081665
Validation loss: 2.1256519684227566

Epoch: 150| Step: 0
Training loss: 2.801699638366699
Validation loss: 2.097924914411319

Epoch: 6| Step: 1
Training loss: 1.5655766725540161
Validation loss: 2.0759779791678152

Epoch: 6| Step: 2
Training loss: 2.1784613132476807
Validation loss: 2.0499477642838673

Epoch: 6| Step: 3
Training loss: 1.8289109468460083
Validation loss: 2.034612404402866

Epoch: 6| Step: 4
Training loss: 3.6955792903900146
Validation loss: 2.0399238935080906

Epoch: 6| Step: 5
Training loss: 1.7975561618804932
Validation loss: 2.034570783697149

Epoch: 6| Step: 6
Training loss: 1.9539856910705566
Validation loss: 2.045963361699094

Epoch: 6| Step: 7
Training loss: 2.7900357246398926
Validation loss: 2.0454963009844542

Epoch: 6| Step: 8
Training loss: 2.254209280014038
Validation loss: 2.0511399238340315

Epoch: 6| Step: 9
Training loss: 1.943238615989685
Validation loss: 2.0531721320203555

Epoch: 6| Step: 10
Training loss: 2.0810749530792236
Validation loss: 2.059020919184531

Epoch: 6| Step: 11
Training loss: 3.0963099002838135
Validation loss: 2.071196074126869

Epoch: 6| Step: 12
Training loss: 2.515881061553955
Validation loss: 2.0713204055704098

Epoch: 6| Step: 13
Training loss: 1.84861159324646
Validation loss: 2.086945008206111

Epoch: 151| Step: 0
Training loss: 2.493872880935669
Validation loss: 2.126115988659602

Epoch: 6| Step: 1
Training loss: 1.9243180751800537
Validation loss: 2.145002377930508

Epoch: 6| Step: 2
Training loss: 2.6276845932006836
Validation loss: 2.1637378302953576

Epoch: 6| Step: 3
Training loss: 2.5395750999450684
Validation loss: 2.1953563869640393

Epoch: 6| Step: 4
Training loss: 2.2676987648010254
Validation loss: 2.1852592652843845

Epoch: 6| Step: 5
Training loss: 1.9297137260437012
Validation loss: 2.1545934497669177

Epoch: 6| Step: 6
Training loss: 1.9101167917251587
Validation loss: 2.133533175273608

Epoch: 6| Step: 7
Training loss: 3.0242538452148438
Validation loss: 2.110091996449296

Epoch: 6| Step: 8
Training loss: 1.9577038288116455
Validation loss: 2.0903256195847706

Epoch: 6| Step: 9
Training loss: 2.643700122833252
Validation loss: 2.0719931587096183

Epoch: 6| Step: 10
Training loss: 2.1664228439331055
Validation loss: 2.0465265448375414

Epoch: 6| Step: 11
Training loss: 2.2485032081604004
Validation loss: 2.044976927900827

Epoch: 6| Step: 12
Training loss: 2.476794481277466
Validation loss: 2.019053948822842

Epoch: 6| Step: 13
Training loss: 1.7240973711013794
Validation loss: 2.014997879664103

Epoch: 152| Step: 0
Training loss: 1.9193506240844727
Validation loss: 1.996995633648288

Epoch: 6| Step: 1
Training loss: 1.8083817958831787
Validation loss: 2.010545825445524

Epoch: 6| Step: 2
Training loss: 2.594916820526123
Validation loss: 2.0158604985924176

Epoch: 6| Step: 3
Training loss: 1.7306559085845947
Validation loss: 2.017348697108607

Epoch: 6| Step: 4
Training loss: 2.5925612449645996
Validation loss: 2.0033359348133044

Epoch: 6| Step: 5
Training loss: 2.691823959350586
Validation loss: 1.9975711043163011

Epoch: 6| Step: 6
Training loss: 2.979274034500122
Validation loss: 2.0079076700313117

Epoch: 6| Step: 7
Training loss: 2.072035789489746
Validation loss: 2.0176462909226776

Epoch: 6| Step: 8
Training loss: 2.2933926582336426
Validation loss: 2.0485910664322557

Epoch: 6| Step: 9
Training loss: 2.3919365406036377
Validation loss: 2.08113448081478

Epoch: 6| Step: 10
Training loss: 2.2794036865234375
Validation loss: 2.085980176925659

Epoch: 6| Step: 11
Training loss: 2.2714545726776123
Validation loss: 2.0629288265782018

Epoch: 6| Step: 12
Training loss: 2.4299938678741455
Validation loss: 2.037511717888617

Epoch: 6| Step: 13
Training loss: 2.3018741607666016
Validation loss: 2.0122325369106826

Epoch: 153| Step: 0
Training loss: 2.463547706604004
Validation loss: 2.009970090722525

Epoch: 6| Step: 1
Training loss: 2.4150774478912354
Validation loss: 2.006473602787141

Epoch: 6| Step: 2
Training loss: 2.3439488410949707
Validation loss: 2.018041585081367

Epoch: 6| Step: 3
Training loss: 2.7969961166381836
Validation loss: 2.015470084323678

Epoch: 6| Step: 4
Training loss: 2.159834861755371
Validation loss: 2.011457230455132

Epoch: 6| Step: 5
Training loss: 2.1103243827819824
Validation loss: 2.0129667687159714

Epoch: 6| Step: 6
Training loss: 1.9820969104766846
Validation loss: 2.0017859294850338

Epoch: 6| Step: 7
Training loss: 1.6427817344665527
Validation loss: 2.0227821091169953

Epoch: 6| Step: 8
Training loss: 2.354581594467163
Validation loss: 2.0217838941081876

Epoch: 6| Step: 9
Training loss: 2.198742389678955
Validation loss: 2.026325833412909

Epoch: 6| Step: 10
Training loss: 2.4421801567077637
Validation loss: 2.046712181901419

Epoch: 6| Step: 11
Training loss: 2.098018169403076
Validation loss: 2.046534222941245

Epoch: 6| Step: 12
Training loss: 2.2701821327209473
Validation loss: 2.0522230414934057

Epoch: 6| Step: 13
Training loss: 2.923339605331421
Validation loss: 2.0394461129301336

Epoch: 154| Step: 0
Training loss: 2.5778372287750244
Validation loss: 2.043598469867501

Epoch: 6| Step: 1
Training loss: 2.4269204139709473
Validation loss: 2.052426019022542

Epoch: 6| Step: 2
Training loss: 2.6063246726989746
Validation loss: 2.029805967884679

Epoch: 6| Step: 3
Training loss: 2.7951292991638184
Validation loss: 2.0447384234397643

Epoch: 6| Step: 4
Training loss: 2.237112522125244
Validation loss: 2.01526346898848

Epoch: 6| Step: 5
Training loss: 1.7152063846588135
Validation loss: 2.014657300005677

Epoch: 6| Step: 6
Training loss: 2.6381430625915527
Validation loss: 2.004612240740048

Epoch: 6| Step: 7
Training loss: 2.4940378665924072
Validation loss: 2.0175579850391676

Epoch: 6| Step: 8
Training loss: 2.4585983753204346
Validation loss: 2.0109587356608403

Epoch: 6| Step: 9
Training loss: 1.58027982711792
Validation loss: 2.0205474207478185

Epoch: 6| Step: 10
Training loss: 2.672990083694458
Validation loss: 2.0248535551050657

Epoch: 6| Step: 11
Training loss: 1.815133810043335
Validation loss: 2.0387352922911286

Epoch: 6| Step: 12
Training loss: 2.213613986968994
Validation loss: 2.0974334837287985

Epoch: 6| Step: 13
Training loss: 1.7081992626190186
Validation loss: 2.1166065867229173

Epoch: 155| Step: 0
Training loss: 2.0995731353759766
Validation loss: 2.1113703186793993

Epoch: 6| Step: 1
Training loss: 2.2568371295928955
Validation loss: 2.072515808125978

Epoch: 6| Step: 2
Training loss: 1.8154361248016357
Validation loss: 2.0643246302040676

Epoch: 6| Step: 3
Training loss: 1.6248515844345093
Validation loss: 2.0411330935775593

Epoch: 6| Step: 4
Training loss: 2.7512454986572266
Validation loss: 2.0251897278652398

Epoch: 6| Step: 5
Training loss: 2.578664779663086
Validation loss: 2.0234514795323855

Epoch: 6| Step: 6
Training loss: 2.546339511871338
Validation loss: 2.0259077484889696

Epoch: 6| Step: 7
Training loss: 2.0835700035095215
Validation loss: 2.020774890017766

Epoch: 6| Step: 8
Training loss: 2.526378631591797
Validation loss: 2.018264642325781

Epoch: 6| Step: 9
Training loss: 2.2429447174072266
Validation loss: 2.0081269997422413

Epoch: 6| Step: 10
Training loss: 2.156442642211914
Validation loss: 1.9997287616934827

Epoch: 6| Step: 11
Training loss: 2.675698757171631
Validation loss: 2.011919452298072

Epoch: 6| Step: 12
Training loss: 1.7914741039276123
Validation loss: 2.011223339265393

Epoch: 6| Step: 13
Training loss: 3.2007861137390137
Validation loss: 2.032021504576488

Epoch: 156| Step: 0
Training loss: 1.905498743057251
Validation loss: 2.0477923039467103

Epoch: 6| Step: 1
Training loss: 2.045452117919922
Validation loss: 2.050039845128213

Epoch: 6| Step: 2
Training loss: 2.199244260787964
Validation loss: 2.08168553280574

Epoch: 6| Step: 3
Training loss: 2.80224871635437
Validation loss: 2.081628163655599

Epoch: 6| Step: 4
Training loss: 2.0892515182495117
Validation loss: 2.075737637858237

Epoch: 6| Step: 5
Training loss: 2.2752294540405273
Validation loss: 2.0688070276732087

Epoch: 6| Step: 6
Training loss: 1.9929606914520264
Validation loss: 2.0357321423868977

Epoch: 6| Step: 7
Training loss: 2.4579505920410156
Validation loss: 2.02641616072706

Epoch: 6| Step: 8
Training loss: 2.7070116996765137
Validation loss: 2.0272352926192747

Epoch: 6| Step: 9
Training loss: 3.0004708766937256
Validation loss: 2.0256822891132806

Epoch: 6| Step: 10
Training loss: 1.988175392150879
Validation loss: 2.0282655198086976

Epoch: 6| Step: 11
Training loss: 1.7427242994308472
Validation loss: 2.0235185648805354

Epoch: 6| Step: 12
Training loss: 2.409879684448242
Validation loss: 2.029994117316379

Epoch: 6| Step: 13
Training loss: 2.283480405807495
Validation loss: 2.048949762057233

Epoch: 157| Step: 0
Training loss: 2.2478866577148438
Validation loss: 2.0500750310959353

Epoch: 6| Step: 1
Training loss: 2.131009101867676
Validation loss: 2.0669175796611334

Epoch: 6| Step: 2
Training loss: 2.2183446884155273
Validation loss: 2.08080469664707

Epoch: 6| Step: 3
Training loss: 1.926633596420288
Validation loss: 2.0559181949143768

Epoch: 6| Step: 4
Training loss: 2.2665603160858154
Validation loss: 2.052674606282224

Epoch: 6| Step: 5
Training loss: 2.594491958618164
Validation loss: 2.0558577840046217

Epoch: 6| Step: 6
Training loss: 2.6446876525878906
Validation loss: 2.0612829731356714

Epoch: 6| Step: 7
Training loss: 2.025902032852173
Validation loss: 2.0376485355438723

Epoch: 6| Step: 8
Training loss: 1.92366623878479
Validation loss: 2.0465854778084704

Epoch: 6| Step: 9
Training loss: 2.4360907077789307
Validation loss: 2.0243895989592358

Epoch: 6| Step: 10
Training loss: 2.668236255645752
Validation loss: 2.0260910590489707

Epoch: 6| Step: 11
Training loss: 2.659419536590576
Validation loss: 2.026356686827957

Epoch: 6| Step: 12
Training loss: 1.5476453304290771
Validation loss: 2.0230910060226277

Epoch: 6| Step: 13
Training loss: 2.7857778072357178
Validation loss: 2.0480973515459286

Epoch: 158| Step: 0
Training loss: 1.9413444995880127
Validation loss: 2.0643211923619753

Epoch: 6| Step: 1
Training loss: 2.358128547668457
Validation loss: 2.05068455460251

Epoch: 6| Step: 2
Training loss: 2.4997847080230713
Validation loss: 2.0501187437324115

Epoch: 6| Step: 3
Training loss: 2.4229164123535156
Validation loss: 2.030789852142334

Epoch: 6| Step: 4
Training loss: 2.1295621395111084
Validation loss: 2.016300844889815

Epoch: 6| Step: 5
Training loss: 1.9168272018432617
Validation loss: 2.0084432094327864

Epoch: 6| Step: 6
Training loss: 1.9036000967025757
Validation loss: 2.0219460815511723

Epoch: 6| Step: 7
Training loss: 1.8983948230743408
Validation loss: 2.0286325254747943

Epoch: 6| Step: 8
Training loss: 2.9395503997802734
Validation loss: 2.030188342576386

Epoch: 6| Step: 9
Training loss: 2.4816431999206543
Validation loss: 2.0393975985947477

Epoch: 6| Step: 10
Training loss: 1.969935417175293
Validation loss: 2.0314615029160694

Epoch: 6| Step: 11
Training loss: 2.754504680633545
Validation loss: 2.007898658834478

Epoch: 6| Step: 12
Training loss: 2.231170654296875
Validation loss: 2.020299255207021

Epoch: 6| Step: 13
Training loss: 2.2828798294067383
Validation loss: 2.0163737061203166

Epoch: 159| Step: 0
Training loss: 1.8796021938323975
Validation loss: 2.0121181908474175

Epoch: 6| Step: 1
Training loss: 2.313817024230957
Validation loss: 2.007232259678584

Epoch: 6| Step: 2
Training loss: 2.835683822631836
Validation loss: 1.9934218365658996

Epoch: 6| Step: 3
Training loss: 1.951798677444458
Validation loss: 2.012439215055076

Epoch: 6| Step: 4
Training loss: 2.6469550132751465
Validation loss: 1.9970236721859183

Epoch: 6| Step: 5
Training loss: 2.4406168460845947
Validation loss: 1.988096119255148

Epoch: 6| Step: 6
Training loss: 2.1218152046203613
Validation loss: 2.003767890314902

Epoch: 6| Step: 7
Training loss: 2.030010223388672
Validation loss: 1.9930452095564974

Epoch: 6| Step: 8
Training loss: 1.9581445455551147
Validation loss: 1.9872648626245477

Epoch: 6| Step: 9
Training loss: 2.553813934326172
Validation loss: 1.974517080091661

Epoch: 6| Step: 10
Training loss: 1.7732800245285034
Validation loss: 1.9795457701529227

Epoch: 6| Step: 11
Training loss: 1.679761528968811
Validation loss: 1.991650942833193

Epoch: 6| Step: 12
Training loss: 2.566873073577881
Validation loss: 2.00343571939776

Epoch: 6| Step: 13
Training loss: 2.510594367980957
Validation loss: 2.0287447334617696

Epoch: 160| Step: 0
Training loss: 2.8145599365234375
Validation loss: 2.0429323847575853

Epoch: 6| Step: 1
Training loss: 2.687760829925537
Validation loss: 2.066834875332412

Epoch: 6| Step: 2
Training loss: 2.5304999351501465
Validation loss: 2.062227487564087

Epoch: 6| Step: 3
Training loss: 2.2639381885528564
Validation loss: 2.0578266164307952

Epoch: 6| Step: 4
Training loss: 1.7884670495986938
Validation loss: 2.0448567123823267

Epoch: 6| Step: 5
Training loss: 1.7008954286575317
Validation loss: 2.0340958949058288

Epoch: 6| Step: 6
Training loss: 2.1422629356384277
Validation loss: 2.0126657370598084

Epoch: 6| Step: 7
Training loss: 2.738102436065674
Validation loss: 2.0163690018397507

Epoch: 6| Step: 8
Training loss: 2.0671355724334717
Validation loss: 2.00889673027941

Epoch: 6| Step: 9
Training loss: 1.8577072620391846
Validation loss: 2.01461317975034

Epoch: 6| Step: 10
Training loss: 1.8870052099227905
Validation loss: 2.025810485245079

Epoch: 6| Step: 11
Training loss: 2.478407859802246
Validation loss: 2.038342672009622

Epoch: 6| Step: 12
Training loss: 2.5028951168060303
Validation loss: 2.0513692312343146

Epoch: 6| Step: 13
Training loss: 2.0401246547698975
Validation loss: 2.078949870601777

Epoch: 161| Step: 0
Training loss: 2.201758623123169
Validation loss: 2.086985767528575

Epoch: 6| Step: 1
Training loss: 2.1721181869506836
Validation loss: 2.089389549788608

Epoch: 6| Step: 2
Training loss: 2.4054083824157715
Validation loss: 2.0859266865637993

Epoch: 6| Step: 3
Training loss: 1.8814200162887573
Validation loss: 2.071809608449218

Epoch: 6| Step: 4
Training loss: 2.0337629318237305
Validation loss: 2.058274571613599

Epoch: 6| Step: 5
Training loss: 1.9521737098693848
Validation loss: 2.0424723343182634

Epoch: 6| Step: 6
Training loss: 2.303865909576416
Validation loss: 2.0291281528370355

Epoch: 6| Step: 7
Training loss: 2.655122756958008
Validation loss: 2.026817407659305

Epoch: 6| Step: 8
Training loss: 2.5284457206726074
Validation loss: 2.0250981110398487

Epoch: 6| Step: 9
Training loss: 1.822312355041504
Validation loss: 2.022831557899393

Epoch: 6| Step: 10
Training loss: 2.8229334354400635
Validation loss: 2.0188815696265108

Epoch: 6| Step: 11
Training loss: 2.217771053314209
Validation loss: 2.0058946865861134

Epoch: 6| Step: 12
Training loss: 2.0964128971099854
Validation loss: 2.006499776276209

Epoch: 6| Step: 13
Training loss: 1.719806432723999
Validation loss: 2.0028548522662093

Epoch: 162| Step: 0
Training loss: 2.8879637718200684
Validation loss: 1.9927762721174507

Epoch: 6| Step: 1
Training loss: 1.774234414100647
Validation loss: 2.000044268946494

Epoch: 6| Step: 2
Training loss: 2.3060641288757324
Validation loss: 1.9906308304878972

Epoch: 6| Step: 3
Training loss: 1.6802171468734741
Validation loss: 2.0024913651968843

Epoch: 6| Step: 4
Training loss: 2.3244524002075195
Validation loss: 1.9936478586607083

Epoch: 6| Step: 5
Training loss: 2.177180767059326
Validation loss: 2.000662256312627

Epoch: 6| Step: 6
Training loss: 1.888129472732544
Validation loss: 2.0160015039546515

Epoch: 6| Step: 7
Training loss: 2.158799409866333
Validation loss: 2.0309088819770404

Epoch: 6| Step: 8
Training loss: 2.103120803833008
Validation loss: 2.0425753388353574

Epoch: 6| Step: 9
Training loss: 2.96962833404541
Validation loss: 2.0383374152644986

Epoch: 6| Step: 10
Training loss: 2.3680295944213867
Validation loss: 2.0481600530685915

Epoch: 6| Step: 11
Training loss: 2.1232059001922607
Validation loss: 2.028082912968051

Epoch: 6| Step: 12
Training loss: 2.18386173248291
Validation loss: 1.9969993791272562

Epoch: 6| Step: 13
Training loss: 1.8467845916748047
Validation loss: 1.9782588840812765

Epoch: 163| Step: 0
Training loss: 1.7502241134643555
Validation loss: 1.971505106136363

Epoch: 6| Step: 1
Training loss: 2.2909741401672363
Validation loss: 1.9694134227691158

Epoch: 6| Step: 2
Training loss: 1.6567058563232422
Validation loss: 1.9750830588802215

Epoch: 6| Step: 3
Training loss: 2.089385509490967
Validation loss: 1.9807166489221717

Epoch: 6| Step: 4
Training loss: 1.8158334493637085
Validation loss: 1.977082940839952

Epoch: 6| Step: 5
Training loss: 2.7608048915863037
Validation loss: 2.0092300881621656

Epoch: 6| Step: 6
Training loss: 2.3896431922912598
Validation loss: 1.9964633180249123

Epoch: 6| Step: 7
Training loss: 2.2285714149475098
Validation loss: 1.9927735559401973

Epoch: 6| Step: 8
Training loss: 2.6134753227233887
Validation loss: 1.986249998051633

Epoch: 6| Step: 9
Training loss: 1.3424112796783447
Validation loss: 1.9834063206949542

Epoch: 6| Step: 10
Training loss: 2.2320594787597656
Validation loss: 1.9745091776694021

Epoch: 6| Step: 11
Training loss: 2.41549015045166
Validation loss: 1.9838143164111721

Epoch: 6| Step: 12
Training loss: 2.614326000213623
Validation loss: 1.9869358078125985

Epoch: 6| Step: 13
Training loss: 2.641491174697876
Validation loss: 2.02104809207301

Epoch: 164| Step: 0
Training loss: 2.299198627471924
Validation loss: 2.0236657511803413

Epoch: 6| Step: 1
Training loss: 2.613765239715576
Validation loss: 2.0315889030374508

Epoch: 6| Step: 2
Training loss: 2.0470523834228516
Validation loss: 2.0451660976615003

Epoch: 6| Step: 3
Training loss: 1.946877360343933
Validation loss: 2.0815761422598236

Epoch: 6| Step: 4
Training loss: 2.4945502281188965
Validation loss: 2.0438752520468926

Epoch: 6| Step: 5
Training loss: 2.5433616638183594
Validation loss: 2.047864456330576

Epoch: 6| Step: 6
Training loss: 2.7516064643859863
Validation loss: 2.022874803953273

Epoch: 6| Step: 7
Training loss: 2.1581318378448486
Validation loss: 2.003836966330005

Epoch: 6| Step: 8
Training loss: 2.1090281009674072
Validation loss: 1.9949166159476004

Epoch: 6| Step: 9
Training loss: 1.2108625173568726
Validation loss: 1.989315321368556

Epoch: 6| Step: 10
Training loss: 2.2770016193389893
Validation loss: 1.9869188416388728

Epoch: 6| Step: 11
Training loss: 1.8971607685089111
Validation loss: 1.9809653028365104

Epoch: 6| Step: 12
Training loss: 2.4661192893981934
Validation loss: 1.9860173874003912

Epoch: 6| Step: 13
Training loss: 1.8947383165359497
Validation loss: 1.9875964528770858

Epoch: 165| Step: 0
Training loss: 2.3911943435668945
Validation loss: 1.985662700027548

Epoch: 6| Step: 1
Training loss: 2.741877555847168
Validation loss: 2.004228179172803

Epoch: 6| Step: 2
Training loss: 1.7612311840057373
Validation loss: 2.0339507415730465

Epoch: 6| Step: 3
Training loss: 1.6218907833099365
Validation loss: 2.055781618241341

Epoch: 6| Step: 4
Training loss: 2.1927127838134766
Validation loss: 2.0781177038787515

Epoch: 6| Step: 5
Training loss: 2.1790881156921387
Validation loss: 2.0815254821572253

Epoch: 6| Step: 6
Training loss: 1.5010005235671997
Validation loss: 2.07338499381978

Epoch: 6| Step: 7
Training loss: 2.3876099586486816
Validation loss: 2.061956456912461

Epoch: 6| Step: 8
Training loss: 2.29799485206604
Validation loss: 2.036480930543715

Epoch: 6| Step: 9
Training loss: 2.9235281944274902
Validation loss: 2.054683610957156

Epoch: 6| Step: 10
Training loss: 2.065323829650879
Validation loss: 2.052636674655381

Epoch: 6| Step: 11
Training loss: 2.74220609664917
Validation loss: 2.0324470163673483

Epoch: 6| Step: 12
Training loss: 2.225013256072998
Validation loss: 2.0287336559705835

Epoch: 6| Step: 13
Training loss: 1.455933928489685
Validation loss: 2.0258715280922512

Epoch: 166| Step: 0
Training loss: 1.9372022151947021
Validation loss: 2.032430551385367

Epoch: 6| Step: 1
Training loss: 2.591230869293213
Validation loss: 2.0263101644413446

Epoch: 6| Step: 2
Training loss: 3.003736972808838
Validation loss: 2.015450264817925

Epoch: 6| Step: 3
Training loss: 2.725536823272705
Validation loss: 2.0116748861087266

Epoch: 6| Step: 4
Training loss: 1.628949761390686
Validation loss: 2.0164049171632334

Epoch: 6| Step: 5
Training loss: 2.0726757049560547
Validation loss: 2.011799059888368

Epoch: 6| Step: 6
Training loss: 1.3107526302337646
Validation loss: 2.010673963895408

Epoch: 6| Step: 7
Training loss: 1.5264800786972046
Validation loss: 2.021274547423086

Epoch: 6| Step: 8
Training loss: 1.3416982889175415
Validation loss: 2.013857981210114

Epoch: 6| Step: 9
Training loss: 2.7443037033081055
Validation loss: 2.027182294476417

Epoch: 6| Step: 10
Training loss: 2.423234462738037
Validation loss: 2.0164038032613774

Epoch: 6| Step: 11
Training loss: 2.6690359115600586
Validation loss: 2.016113399177469

Epoch: 6| Step: 12
Training loss: 2.012941360473633
Validation loss: 2.0068104728575675

Epoch: 6| Step: 13
Training loss: 2.487528085708618
Validation loss: 1.9985648303903558

Epoch: 167| Step: 0
Training loss: 2.383553981781006
Validation loss: 1.9893564306279665

Epoch: 6| Step: 1
Training loss: 1.9827535152435303
Validation loss: 1.9971084030725623

Epoch: 6| Step: 2
Training loss: 2.0841097831726074
Validation loss: 1.9926127669631795

Epoch: 6| Step: 3
Training loss: 1.611063838005066
Validation loss: 1.9997372934895177

Epoch: 6| Step: 4
Training loss: 2.458927631378174
Validation loss: 2.0015368692336546

Epoch: 6| Step: 5
Training loss: 2.6359505653381348
Validation loss: 2.02050639993401

Epoch: 6| Step: 6
Training loss: 2.3393473625183105
Validation loss: 2.035652405472212

Epoch: 6| Step: 7
Training loss: 2.0732736587524414
Validation loss: 2.0596324423308014

Epoch: 6| Step: 8
Training loss: 2.199831962585449
Validation loss: 2.0786348260859007

Epoch: 6| Step: 9
Training loss: 1.6528277397155762
Validation loss: 2.0515387852986655

Epoch: 6| Step: 10
Training loss: 2.3844337463378906
Validation loss: 2.0163369794045725

Epoch: 6| Step: 11
Training loss: 2.2177484035491943
Validation loss: 1.9996164665427258

Epoch: 6| Step: 12
Training loss: 1.7460192441940308
Validation loss: 1.9947711434415591

Epoch: 6| Step: 13
Training loss: 2.9274308681488037
Validation loss: 2.0044915881208194

Epoch: 168| Step: 0
Training loss: 1.9179028272628784
Validation loss: 2.0044738195275746

Epoch: 6| Step: 1
Training loss: 1.8464363813400269
Validation loss: 2.0005045090952227

Epoch: 6| Step: 2
Training loss: 2.399106502532959
Validation loss: 2.0057606684264315

Epoch: 6| Step: 3
Training loss: 1.8977317810058594
Validation loss: 2.0048913301960116

Epoch: 6| Step: 4
Training loss: 1.9205511808395386
Validation loss: 1.9952701496821579

Epoch: 6| Step: 5
Training loss: 1.9941612482070923
Validation loss: 1.9866311985959288

Epoch: 6| Step: 6
Training loss: 2.0210676193237305
Validation loss: 1.9988972653624832

Epoch: 6| Step: 7
Training loss: 2.4248881340026855
Validation loss: 2.0119858262359456

Epoch: 6| Step: 8
Training loss: 2.0747079849243164
Validation loss: 2.032496211349323

Epoch: 6| Step: 9
Training loss: 2.175475835800171
Validation loss: 2.0648118231886174

Epoch: 6| Step: 10
Training loss: 2.843398332595825
Validation loss: 2.048829586275162

Epoch: 6| Step: 11
Training loss: 2.1825573444366455
Validation loss: 2.025110270387383

Epoch: 6| Step: 12
Training loss: 2.2471680641174316
Validation loss: 2.0016362795265774

Epoch: 6| Step: 13
Training loss: 2.3838741779327393
Validation loss: 1.9985232455756075

Epoch: 169| Step: 0
Training loss: 1.9268529415130615
Validation loss: 1.9875179401008032

Epoch: 6| Step: 1
Training loss: 1.6432888507843018
Validation loss: 2.0071816559760802

Epoch: 6| Step: 2
Training loss: 2.1136398315429688
Validation loss: 2.020272047288956

Epoch: 6| Step: 3
Training loss: 2.359175205230713
Validation loss: 2.0355766729641984

Epoch: 6| Step: 4
Training loss: 2.853890895843506
Validation loss: 2.054033872901752

Epoch: 6| Step: 5
Training loss: 2.136519432067871
Validation loss: 2.0546221066546697

Epoch: 6| Step: 6
Training loss: 2.1994473934173584
Validation loss: 2.0844027483335106

Epoch: 6| Step: 7
Training loss: 1.9796218872070312
Validation loss: 2.1008625697064143

Epoch: 6| Step: 8
Training loss: 1.9093854427337646
Validation loss: 2.091142192963631

Epoch: 6| Step: 9
Training loss: 2.36749529838562
Validation loss: 2.091145949978982

Epoch: 6| Step: 10
Training loss: 2.47990083694458
Validation loss: 2.0567040930512133

Epoch: 6| Step: 11
Training loss: 2.3835995197296143
Validation loss: 2.044331281415878

Epoch: 6| Step: 12
Training loss: 1.8248512744903564
Validation loss: 2.0435545162488054

Epoch: 6| Step: 13
Training loss: 1.7226622104644775
Validation loss: 2.0389365790992655

Epoch: 170| Step: 0
Training loss: 2.340487480163574
Validation loss: 2.04255521938365

Epoch: 6| Step: 1
Training loss: 1.7743812799453735
Validation loss: 2.0469447515344106

Epoch: 6| Step: 2
Training loss: 2.001831531524658
Validation loss: 2.0256474043733332

Epoch: 6| Step: 3
Training loss: 1.7416493892669678
Validation loss: 2.0092242661342827

Epoch: 6| Step: 4
Training loss: 2.2038300037384033
Validation loss: 2.0102499197888117

Epoch: 6| Step: 5
Training loss: 1.6638644933700562
Validation loss: 1.9981070000638244

Epoch: 6| Step: 6
Training loss: 2.410574436187744
Validation loss: 2.037198866567304

Epoch: 6| Step: 7
Training loss: 1.8214622735977173
Validation loss: 2.045762597873647

Epoch: 6| Step: 8
Training loss: 2.764699935913086
Validation loss: 2.1163352574071577

Epoch: 6| Step: 9
Training loss: 2.421234607696533
Validation loss: 2.144937553713399

Epoch: 6| Step: 10
Training loss: 1.9591152667999268
Validation loss: 2.1373620866447367

Epoch: 6| Step: 11
Training loss: 2.0427613258361816
Validation loss: 2.1205735052785566

Epoch: 6| Step: 12
Training loss: 2.861886978149414
Validation loss: 2.0811217805390716

Epoch: 6| Step: 13
Training loss: 2.0997469425201416
Validation loss: 2.043948799051264

Epoch: 171| Step: 0
Training loss: 2.330718994140625
Validation loss: 2.0154511441466627

Epoch: 6| Step: 1
Training loss: 2.707875967025757
Validation loss: 2.0281608566161125

Epoch: 6| Step: 2
Training loss: 2.5473175048828125
Validation loss: 2.042407630592264

Epoch: 6| Step: 3
Training loss: 2.671957015991211
Validation loss: 2.0670805259417464

Epoch: 6| Step: 4
Training loss: 1.1386761665344238
Validation loss: 2.076095861773337

Epoch: 6| Step: 5
Training loss: 2.253852128982544
Validation loss: 2.0491328188168105

Epoch: 6| Step: 6
Training loss: 2.4286880493164062
Validation loss: 2.029531955718994

Epoch: 6| Step: 7
Training loss: 1.2993292808532715
Validation loss: 2.0430341279634865

Epoch: 6| Step: 8
Training loss: 2.678152561187744
Validation loss: 2.067065706817053

Epoch: 6| Step: 9
Training loss: 2.420360565185547
Validation loss: 2.1354333675035866

Epoch: 6| Step: 10
Training loss: 2.2690505981445312
Validation loss: 2.1636737213339856

Epoch: 6| Step: 11
Training loss: 1.8976815938949585
Validation loss: 2.119460278941739

Epoch: 6| Step: 12
Training loss: 1.9564032554626465
Validation loss: 2.0851690999923216

Epoch: 6| Step: 13
Training loss: 1.7031060457229614
Validation loss: 2.0430755653688983

Epoch: 172| Step: 0
Training loss: 2.2527225017547607
Validation loss: 2.0397398907651185

Epoch: 6| Step: 1
Training loss: 2.008794069290161
Validation loss: 2.0307284914037234

Epoch: 6| Step: 2
Training loss: 1.7512037754058838
Validation loss: 2.0460119708891837

Epoch: 6| Step: 3
Training loss: 2.6470696926116943
Validation loss: 2.035676253739224

Epoch: 6| Step: 4
Training loss: 2.2658233642578125
Validation loss: 2.030261121770387

Epoch: 6| Step: 5
Training loss: 2.3279170989990234
Validation loss: 2.0288421569332

Epoch: 6| Step: 6
Training loss: 2.067150115966797
Validation loss: 2.0303609422458115

Epoch: 6| Step: 7
Training loss: 1.9090287685394287
Validation loss: 2.0315263296968196

Epoch: 6| Step: 8
Training loss: 2.146131753921509
Validation loss: 2.0371449455138175

Epoch: 6| Step: 9
Training loss: 1.6130743026733398
Validation loss: 2.0270242075766287

Epoch: 6| Step: 10
Training loss: 2.43782377243042
Validation loss: 2.022347755329583

Epoch: 6| Step: 11
Training loss: 1.8610994815826416
Validation loss: 2.0352303981781006

Epoch: 6| Step: 12
Training loss: 2.0040760040283203
Validation loss: 2.028558224760076

Epoch: 6| Step: 13
Training loss: 2.250208854675293
Validation loss: 2.0362408622618644

Epoch: 173| Step: 0
Training loss: 2.8948171138763428
Validation loss: 2.051407757625785

Epoch: 6| Step: 1
Training loss: 1.7534343004226685
Validation loss: 2.0458114852187452

Epoch: 6| Step: 2
Training loss: 2.0164806842803955
Validation loss: 2.073580663691285

Epoch: 6| Step: 3
Training loss: 1.9615089893341064
Validation loss: 2.0791883930083244

Epoch: 6| Step: 4
Training loss: 2.202847719192505
Validation loss: 2.0518694487951135

Epoch: 6| Step: 5
Training loss: 2.0541839599609375
Validation loss: 2.0388137422582155

Epoch: 6| Step: 6
Training loss: 1.591576099395752
Validation loss: 2.0379980200080463

Epoch: 6| Step: 7
Training loss: 1.806278944015503
Validation loss: 2.043003051511703

Epoch: 6| Step: 8
Training loss: 2.201742172241211
Validation loss: 2.056873277951312

Epoch: 6| Step: 9
Training loss: 1.3987693786621094
Validation loss: 2.04375030661142

Epoch: 6| Step: 10
Training loss: 2.3252527713775635
Validation loss: 2.0539121371443554

Epoch: 6| Step: 11
Training loss: 2.5367355346679688
Validation loss: 2.0548428617497927

Epoch: 6| Step: 12
Training loss: 2.266589641571045
Validation loss: 2.0654706724228395

Epoch: 6| Step: 13
Training loss: 2.2726471424102783
Validation loss: 2.062176894116145

Epoch: 174| Step: 0
Training loss: 2.236860752105713
Validation loss: 2.057946135920863

Epoch: 6| Step: 1
Training loss: 2.47467041015625
Validation loss: 2.061094045639038

Epoch: 6| Step: 2
Training loss: 3.0593345165252686
Validation loss: 2.0507797682157127

Epoch: 6| Step: 3
Training loss: 2.2441489696502686
Validation loss: 2.0465108861205397

Epoch: 6| Step: 4
Training loss: 2.4066896438598633
Validation loss: 2.0372811978863132

Epoch: 6| Step: 5
Training loss: 1.0945568084716797
Validation loss: 2.053312768218338

Epoch: 6| Step: 6
Training loss: 1.6944293975830078
Validation loss: 2.089359248838117

Epoch: 6| Step: 7
Training loss: 1.4188950061798096
Validation loss: 2.13475324005209

Epoch: 6| Step: 8
Training loss: 2.7156341075897217
Validation loss: 2.1665974816968365

Epoch: 6| Step: 9
Training loss: 2.432908296585083
Validation loss: 2.2015372271178872

Epoch: 6| Step: 10
Training loss: 2.037904739379883
Validation loss: 2.131280956729766

Epoch: 6| Step: 11
Training loss: 1.9704346656799316
Validation loss: 2.0665496780026342

Epoch: 6| Step: 12
Training loss: 1.3222806453704834
Validation loss: 2.0463474130117767

Epoch: 6| Step: 13
Training loss: 1.8800277709960938
Validation loss: 2.0762796504523164

Epoch: 175| Step: 0
Training loss: 1.814430594444275
Validation loss: 2.0815512108546432

Epoch: 6| Step: 1
Training loss: 2.3783230781555176
Validation loss: 2.1084210257376395

Epoch: 6| Step: 2
Training loss: 2.1669111251831055
Validation loss: 2.103851282468406

Epoch: 6| Step: 3
Training loss: 2.9322125911712646
Validation loss: 2.082813580830892

Epoch: 6| Step: 4
Training loss: 1.5119380950927734
Validation loss: 2.0800345508001183

Epoch: 6| Step: 5
Training loss: 2.371448516845703
Validation loss: 2.074304239724272

Epoch: 6| Step: 6
Training loss: 1.7352294921875
Validation loss: 2.091076584272487

Epoch: 6| Step: 7
Training loss: 1.3291467428207397
Validation loss: 2.083935711973457

Epoch: 6| Step: 8
Training loss: 1.9815549850463867
Validation loss: 2.087899705415131

Epoch: 6| Step: 9
Training loss: 2.4264369010925293
Validation loss: 2.091766988077471

Epoch: 6| Step: 10
Training loss: 2.4129230976104736
Validation loss: 2.1179377776320263

Epoch: 6| Step: 11
Training loss: 2.3228628635406494
Validation loss: 2.147430730122392

Epoch: 6| Step: 12
Training loss: 2.0681540966033936
Validation loss: 2.1721788273062757

Epoch: 6| Step: 13
Training loss: 2.2890825271606445
Validation loss: 2.1701289299995667

Epoch: 176| Step: 0
Training loss: 2.3921494483947754
Validation loss: 2.1509704461661716

Epoch: 6| Step: 1
Training loss: 1.8864554166793823
Validation loss: 2.128273897273566

Epoch: 6| Step: 2
Training loss: 1.4626882076263428
Validation loss: 2.115310420272171

Epoch: 6| Step: 3
Training loss: 2.221559524536133
Validation loss: 2.090613915074256

Epoch: 6| Step: 4
Training loss: 2.170387029647827
Validation loss: 2.0860160832764

Epoch: 6| Step: 5
Training loss: 1.8869123458862305
Validation loss: 2.079538914465135

Epoch: 6| Step: 6
Training loss: 1.893234133720398
Validation loss: 2.071196820146294

Epoch: 6| Step: 7
Training loss: 1.9603878259658813
Validation loss: 2.073345572717728

Epoch: 6| Step: 8
Training loss: 2.28853702545166
Validation loss: 2.088993524992338

Epoch: 6| Step: 9
Training loss: 1.7740490436553955
Validation loss: 2.0791020367735173

Epoch: 6| Step: 10
Training loss: 2.2503342628479004
Validation loss: 2.0766759226399083

Epoch: 6| Step: 11
Training loss: 2.1074259281158447
Validation loss: 2.095659896891604

Epoch: 6| Step: 12
Training loss: 2.5678067207336426
Validation loss: 2.1212671264525382

Epoch: 6| Step: 13
Training loss: 1.9940276145935059
Validation loss: 2.1249722165446125

Epoch: 177| Step: 0
Training loss: 2.1844775676727295
Validation loss: 2.1472335323210685

Epoch: 6| Step: 1
Training loss: 2.7168214321136475
Validation loss: 2.156539294027513

Epoch: 6| Step: 2
Training loss: 1.9266726970672607
Validation loss: 2.1667776671789025

Epoch: 6| Step: 3
Training loss: 1.3054146766662598
Validation loss: 2.160999817232932

Epoch: 6| Step: 4
Training loss: 2.236722946166992
Validation loss: 2.166385740362188

Epoch: 6| Step: 5
Training loss: 2.6515281200408936
Validation loss: 2.1342324710661367

Epoch: 6| Step: 6
Training loss: 2.0239779949188232
Validation loss: 2.123753989896467

Epoch: 6| Step: 7
Training loss: 1.8204797506332397
Validation loss: 2.091528054206602

Epoch: 6| Step: 8
Training loss: 2.537482738494873
Validation loss: 2.0902258567912604

Epoch: 6| Step: 9
Training loss: 2.271451473236084
Validation loss: 2.0997397104899087

Epoch: 6| Step: 10
Training loss: 1.8653721809387207
Validation loss: 2.1091004315242974

Epoch: 6| Step: 11
Training loss: 1.9490830898284912
Validation loss: 2.114972770854991

Epoch: 6| Step: 12
Training loss: 1.6625192165374756
Validation loss: 2.1160338360776185

Epoch: 6| Step: 13
Training loss: 1.0592644214630127
Validation loss: 2.108189389269839

Epoch: 178| Step: 0
Training loss: 2.5570621490478516
Validation loss: 2.112336979117445

Epoch: 6| Step: 1
Training loss: 2.085946559906006
Validation loss: 2.122412545706636

Epoch: 6| Step: 2
Training loss: 1.5499436855316162
Validation loss: 2.1234286959453295

Epoch: 6| Step: 3
Training loss: 2.475565195083618
Validation loss: 2.1065486105539466

Epoch: 6| Step: 4
Training loss: 2.2304887771606445
Validation loss: 2.113123127209243

Epoch: 6| Step: 5
Training loss: 1.8017313480377197
Validation loss: 2.0969928169763214

Epoch: 6| Step: 6
Training loss: 1.3641730546951294
Validation loss: 2.1035696101445023

Epoch: 6| Step: 7
Training loss: 2.014395236968994
Validation loss: 2.1056076890678814

Epoch: 6| Step: 8
Training loss: 2.1963446140289307
Validation loss: 2.118723325831916

Epoch: 6| Step: 9
Training loss: 1.9770286083221436
Validation loss: 2.0794682477110173

Epoch: 6| Step: 10
Training loss: 1.8985912799835205
Validation loss: 2.0818702969499814

Epoch: 6| Step: 11
Training loss: 2.2451484203338623
Validation loss: 2.079818889658938

Epoch: 6| Step: 12
Training loss: 1.8872840404510498
Validation loss: 2.0748481878670315

Epoch: 6| Step: 13
Training loss: 2.2872838973999023
Validation loss: 2.054608873141709

Epoch: 179| Step: 0
Training loss: 1.9926129579544067
Validation loss: 2.0540269267174507

Epoch: 6| Step: 1
Training loss: 1.3637466430664062
Validation loss: 2.0551968133577736

Epoch: 6| Step: 2
Training loss: 1.7540197372436523
Validation loss: 2.072035215234244

Epoch: 6| Step: 3
Training loss: 2.2882797718048096
Validation loss: 2.079882162873463

Epoch: 6| Step: 4
Training loss: 2.4442906379699707
Validation loss: 2.072221591908445

Epoch: 6| Step: 5
Training loss: 1.237269401550293
Validation loss: 2.0690631404999764

Epoch: 6| Step: 6
Training loss: 1.765198826789856
Validation loss: 2.060239145832677

Epoch: 6| Step: 7
Training loss: 2.329850673675537
Validation loss: 2.054303305123442

Epoch: 6| Step: 8
Training loss: 2.734292984008789
Validation loss: 2.0755035928500596

Epoch: 6| Step: 9
Training loss: 1.9519290924072266
Validation loss: 2.0655745690868748

Epoch: 6| Step: 10
Training loss: 2.1604015827178955
Validation loss: 2.0410527875346522

Epoch: 6| Step: 11
Training loss: 2.012979030609131
Validation loss: 2.049655604106124

Epoch: 6| Step: 12
Training loss: 1.8127212524414062
Validation loss: 2.023515869212407

Epoch: 6| Step: 13
Training loss: 1.99246084690094
Validation loss: 2.0375170630793416

Epoch: 180| Step: 0
Training loss: 1.484386682510376
Validation loss: 2.0346672842579503

Epoch: 6| Step: 1
Training loss: 2.6102890968322754
Validation loss: 2.041677436520976

Epoch: 6| Step: 2
Training loss: 0.965774655342102
Validation loss: 2.063414858233544

Epoch: 6| Step: 3
Training loss: 1.471799612045288
Validation loss: 2.0729362951811923

Epoch: 6| Step: 4
Training loss: 2.296222686767578
Validation loss: 2.067882932642455

Epoch: 6| Step: 5
Training loss: 1.3379905223846436
Validation loss: 2.07282688284433

Epoch: 6| Step: 6
Training loss: 2.1479387283325195
Validation loss: 2.071194843579364

Epoch: 6| Step: 7
Training loss: 2.4076030254364014
Validation loss: 2.0767912121229273

Epoch: 6| Step: 8
Training loss: 1.5353038311004639
Validation loss: 2.0986733436584473

Epoch: 6| Step: 9
Training loss: 2.6519668102264404
Validation loss: 2.122001022420904

Epoch: 6| Step: 10
Training loss: 3.0104002952575684
Validation loss: 2.146670941383608

Epoch: 6| Step: 11
Training loss: 3.0930442810058594
Validation loss: 2.1674303636755994

Epoch: 6| Step: 12
Training loss: 1.9959344863891602
Validation loss: 2.111516664105077

Epoch: 6| Step: 13
Training loss: 1.5905156135559082
Validation loss: 2.0847967542627805

Epoch: 181| Step: 0
Training loss: 2.1945743560791016
Validation loss: 2.074934615883776

Epoch: 6| Step: 1
Training loss: 1.633981466293335
Validation loss: 2.0898749994975265

Epoch: 6| Step: 2
Training loss: 2.188384771347046
Validation loss: 2.108509079102547

Epoch: 6| Step: 3
Training loss: 2.260401487350464
Validation loss: 2.1025416492134013

Epoch: 6| Step: 4
Training loss: 1.786705493927002
Validation loss: 2.122426948239726

Epoch: 6| Step: 5
Training loss: 1.598442792892456
Validation loss: 2.0923112489843882

Epoch: 6| Step: 6
Training loss: 2.0146055221557617
Validation loss: 2.0724247809379333

Epoch: 6| Step: 7
Training loss: 1.8278772830963135
Validation loss: 2.08381405697074

Epoch: 6| Step: 8
Training loss: 1.9842902421951294
Validation loss: 2.0936737714275235

Epoch: 6| Step: 9
Training loss: 2.699735164642334
Validation loss: 2.102566506273003

Epoch: 6| Step: 10
Training loss: 2.154907703399658
Validation loss: 2.1274643687791723

Epoch: 6| Step: 11
Training loss: 2.0215559005737305
Validation loss: 2.102624170241817

Epoch: 6| Step: 12
Training loss: 2.1662304401397705
Validation loss: 2.0973264607050086

Epoch: 6| Step: 13
Training loss: 1.6146589517593384
Validation loss: 2.0985974240046676

Epoch: 182| Step: 0
Training loss: 2.191969156265259
Validation loss: 2.0770129003832416

Epoch: 6| Step: 1
Training loss: 1.9898767471313477
Validation loss: 2.0381868987955074

Epoch: 6| Step: 2
Training loss: 1.942946195602417
Validation loss: 2.0583091910167406

Epoch: 6| Step: 3
Training loss: 1.7593573331832886
Validation loss: 2.0811886390050254

Epoch: 6| Step: 4
Training loss: 2.7945022583007812
Validation loss: 2.104506584905809

Epoch: 6| Step: 5
Training loss: 1.6530355215072632
Validation loss: 2.1229217847188315

Epoch: 6| Step: 6
Training loss: 1.8793554306030273
Validation loss: 2.109058641618298

Epoch: 6| Step: 7
Training loss: 1.971502661705017
Validation loss: 2.1017414574982016

Epoch: 6| Step: 8
Training loss: 2.5435376167297363
Validation loss: 2.0833006674243557

Epoch: 6| Step: 9
Training loss: 1.7172296047210693
Validation loss: 2.0542159567597094

Epoch: 6| Step: 10
Training loss: 1.898141860961914
Validation loss: 2.049548820782733

Epoch: 6| Step: 11
Training loss: 2.255730152130127
Validation loss: 2.0717087561084377

Epoch: 6| Step: 12
Training loss: 2.083841323852539
Validation loss: 2.1058281365261284

Epoch: 6| Step: 13
Training loss: 1.6267236471176147
Validation loss: 2.1403118359145297

Epoch: 183| Step: 0
Training loss: 2.1249499320983887
Validation loss: 2.1836210014999553

Epoch: 6| Step: 1
Training loss: 2.5697073936462402
Validation loss: 2.1457438315114667

Epoch: 6| Step: 2
Training loss: 2.6590728759765625
Validation loss: 2.132344542011138

Epoch: 6| Step: 3
Training loss: 1.7713024616241455
Validation loss: 2.1162944698846466

Epoch: 6| Step: 4
Training loss: 1.4855644702911377
Validation loss: 2.0909818987692557

Epoch: 6| Step: 5
Training loss: 2.0328691005706787
Validation loss: 2.098993364200797

Epoch: 6| Step: 6
Training loss: 2.1991190910339355
Validation loss: 2.1021636404016966

Epoch: 6| Step: 7
Training loss: 2.071049690246582
Validation loss: 2.0901587291430404

Epoch: 6| Step: 8
Training loss: 1.8433493375778198
Validation loss: 2.0814423650823612

Epoch: 6| Step: 9
Training loss: 1.5499396324157715
Validation loss: 2.0722047744258756

Epoch: 6| Step: 10
Training loss: 1.5477039813995361
Validation loss: 2.0759561843769525

Epoch: 6| Step: 11
Training loss: 1.8127045631408691
Validation loss: 2.071964115224859

Epoch: 6| Step: 12
Training loss: 1.8408459424972534
Validation loss: 2.0711222848584576

Epoch: 6| Step: 13
Training loss: 2.286926507949829
Validation loss: 2.061501315844956

Epoch: 184| Step: 0
Training loss: 1.8064029216766357
Validation loss: 2.0817702201104935

Epoch: 6| Step: 1
Training loss: 1.6706209182739258
Validation loss: 2.0955562232643046

Epoch: 6| Step: 2
Training loss: 2.316645622253418
Validation loss: 2.0837578004406345

Epoch: 6| Step: 3
Training loss: 2.1472320556640625
Validation loss: 2.092273924940376

Epoch: 6| Step: 4
Training loss: 1.9557243585586548
Validation loss: 2.113681923958563

Epoch: 6| Step: 5
Training loss: 2.2385220527648926
Validation loss: 2.119229023174573

Epoch: 6| Step: 6
Training loss: 1.4533778429031372
Validation loss: 2.124766404910754

Epoch: 6| Step: 7
Training loss: 2.0078647136688232
Validation loss: 2.1082470865659815

Epoch: 6| Step: 8
Training loss: 1.709595799446106
Validation loss: 2.1038930608380224

Epoch: 6| Step: 9
Training loss: 2.6486825942993164
Validation loss: 2.084244517869847

Epoch: 6| Step: 10
Training loss: 1.5107656717300415
Validation loss: 2.071893153652068

Epoch: 6| Step: 11
Training loss: 1.8078348636627197
Validation loss: 2.0623644039195073

Epoch: 6| Step: 12
Training loss: 2.1671559810638428
Validation loss: 2.0513954611234766

Epoch: 6| Step: 13
Training loss: 1.6844429969787598
Validation loss: 2.0406635551042456

Epoch: 185| Step: 0
Training loss: 1.8722559213638306
Validation loss: 2.0141579848463818

Epoch: 6| Step: 1
Training loss: 2.140298843383789
Validation loss: 2.0232956383817937

Epoch: 6| Step: 2
Training loss: 1.399094820022583
Validation loss: 2.0146199874980475

Epoch: 6| Step: 3
Training loss: 2.332733154296875
Validation loss: 2.0256892916976765

Epoch: 6| Step: 4
Training loss: 2.8364524841308594
Validation loss: 2.041574215376249

Epoch: 6| Step: 5
Training loss: 1.8606140613555908
Validation loss: 2.046088498125794

Epoch: 6| Step: 6
Training loss: 2.1161704063415527
Validation loss: 2.045448436531969

Epoch: 6| Step: 7
Training loss: 1.5350602865219116
Validation loss: 2.0353084687263734

Epoch: 6| Step: 8
Training loss: 1.7458974123001099
Validation loss: 2.053539014631702

Epoch: 6| Step: 9
Training loss: 1.4234308004379272
Validation loss: 2.0678419067013647

Epoch: 6| Step: 10
Training loss: 2.1864194869995117
Validation loss: 2.0756023160872923

Epoch: 6| Step: 11
Training loss: 2.103893518447876
Validation loss: 2.0687508493341427

Epoch: 6| Step: 12
Training loss: 1.7055280208587646
Validation loss: 2.0710806256981305

Epoch: 6| Step: 13
Training loss: 1.9835278987884521
Validation loss: 2.0691949834105787

Epoch: 186| Step: 0
Training loss: 1.838263750076294
Validation loss: 2.0564640452784877

Epoch: 6| Step: 1
Training loss: 2.6645703315734863
Validation loss: 2.0519902526691394

Epoch: 6| Step: 2
Training loss: 2.0965704917907715
Validation loss: 2.058217299881802

Epoch: 6| Step: 3
Training loss: 1.5980613231658936
Validation loss: 2.0823024524155485

Epoch: 6| Step: 4
Training loss: 1.2867240905761719
Validation loss: 2.0752520215126777

Epoch: 6| Step: 5
Training loss: 1.9636353254318237
Validation loss: 2.081859181004186

Epoch: 6| Step: 6
Training loss: 2.4316749572753906
Validation loss: 2.066917762961439

Epoch: 6| Step: 7
Training loss: 2.0011024475097656
Validation loss: 2.070401353220786

Epoch: 6| Step: 8
Training loss: 1.4480657577514648
Validation loss: 2.0733533751580024

Epoch: 6| Step: 9
Training loss: 2.234902858734131
Validation loss: 2.097194549857929

Epoch: 6| Step: 10
Training loss: 1.7344754934310913
Validation loss: 2.1121507421616585

Epoch: 6| Step: 11
Training loss: 1.8981022834777832
Validation loss: 2.12142869733995

Epoch: 6| Step: 12
Training loss: 1.7492753267288208
Validation loss: 2.102973381678263

Epoch: 6| Step: 13
Training loss: 2.378370523452759
Validation loss: 2.0657541751861572

Epoch: 187| Step: 0
Training loss: 1.8200654983520508
Validation loss: 2.0552576664955384

Epoch: 6| Step: 1
Training loss: 2.0849881172180176
Validation loss: 2.0339866633056314

Epoch: 6| Step: 2
Training loss: 1.6623411178588867
Validation loss: 2.026040273327981

Epoch: 6| Step: 3
Training loss: 2.2260990142822266
Validation loss: 2.040628728046212

Epoch: 6| Step: 4
Training loss: 1.2810282707214355
Validation loss: 2.046617700207618

Epoch: 6| Step: 5
Training loss: 1.9224642515182495
Validation loss: 2.044652718369679

Epoch: 6| Step: 6
Training loss: 2.0593299865722656
Validation loss: 2.059401877464787

Epoch: 6| Step: 7
Training loss: 1.7125060558319092
Validation loss: 2.0703918856959187

Epoch: 6| Step: 8
Training loss: 1.6315606832504272
Validation loss: 2.0981662170861357

Epoch: 6| Step: 9
Training loss: 2.741278648376465
Validation loss: 2.113992783331102

Epoch: 6| Step: 10
Training loss: 1.71291184425354
Validation loss: 2.1204560418282785

Epoch: 6| Step: 11
Training loss: 1.3879454135894775
Validation loss: 2.134736991697742

Epoch: 6| Step: 12
Training loss: 2.7565693855285645
Validation loss: 2.1282184111174716

Epoch: 6| Step: 13
Training loss: 1.8512834310531616
Validation loss: 2.134923945191086

Epoch: 188| Step: 0
Training loss: 1.4863088130950928
Validation loss: 2.122404585602463

Epoch: 6| Step: 1
Training loss: 1.539005994796753
Validation loss: 2.0931723066555556

Epoch: 6| Step: 2
Training loss: 2.344020366668701
Validation loss: 2.055209893052296

Epoch: 6| Step: 3
Training loss: 1.492478609085083
Validation loss: 2.048560001516855

Epoch: 6| Step: 4
Training loss: 1.5953829288482666
Validation loss: 2.0393065150066088

Epoch: 6| Step: 5
Training loss: 1.6804542541503906
Validation loss: 2.0232017424798783

Epoch: 6| Step: 6
Training loss: 2.0196049213409424
Validation loss: 2.048957727288687

Epoch: 6| Step: 7
Training loss: 2.095855474472046
Validation loss: 2.0643916527430215

Epoch: 6| Step: 8
Training loss: 1.7903640270233154
Validation loss: 2.0660172085608206

Epoch: 6| Step: 9
Training loss: 1.884252905845642
Validation loss: 2.0737095955879457

Epoch: 6| Step: 10
Training loss: 1.7639541625976562
Validation loss: 2.0720177312051096

Epoch: 6| Step: 11
Training loss: 2.2807512283325195
Validation loss: 2.0793533978923673

Epoch: 6| Step: 12
Training loss: 1.9675263166427612
Validation loss: 2.080391817195441

Epoch: 6| Step: 13
Training loss: 3.090053081512451
Validation loss: 2.0720204948097147

Epoch: 189| Step: 0
Training loss: 2.0160255432128906
Validation loss: 2.0698442664197696

Epoch: 6| Step: 1
Training loss: 1.7380435466766357
Validation loss: 2.078678689977174

Epoch: 6| Step: 2
Training loss: 2.4754109382629395
Validation loss: 2.0861595292245187

Epoch: 6| Step: 3
Training loss: 2.348705291748047
Validation loss: 2.0767944961465816

Epoch: 6| Step: 4
Training loss: 1.7208786010742188
Validation loss: 2.046875020509125

Epoch: 6| Step: 5
Training loss: 2.2037365436553955
Validation loss: 2.0476661677001626

Epoch: 6| Step: 6
Training loss: 1.9728128910064697
Validation loss: 2.064688842783692

Epoch: 6| Step: 7
Training loss: 1.569990873336792
Validation loss: 2.0487721658522084

Epoch: 6| Step: 8
Training loss: 2.2484354972839355
Validation loss: 2.0477895890512774

Epoch: 6| Step: 9
Training loss: 1.7939178943634033
Validation loss: 2.0400723872646207

Epoch: 6| Step: 10
Training loss: 1.13960862159729
Validation loss: 2.0279948185848933

Epoch: 6| Step: 11
Training loss: 1.510252833366394
Validation loss: 2.0152647443996963

Epoch: 6| Step: 12
Training loss: 2.0869193077087402
Validation loss: 2.026910448587069

Epoch: 6| Step: 13
Training loss: 1.649250864982605
Validation loss: 2.047847563220609

Epoch: 190| Step: 0
Training loss: 2.1330437660217285
Validation loss: 2.060391555550278

Epoch: 6| Step: 1
Training loss: 1.8929908275604248
Validation loss: 2.083620576448338

Epoch: 6| Step: 2
Training loss: 2.0140907764434814
Validation loss: 2.084039557364679

Epoch: 6| Step: 3
Training loss: 2.6486034393310547
Validation loss: 2.0919228369189846

Epoch: 6| Step: 4
Training loss: 2.202357530593872
Validation loss: 2.0794618129730225

Epoch: 6| Step: 5
Training loss: 1.4175785779953003
Validation loss: 2.0668396052493843

Epoch: 6| Step: 6
Training loss: 2.0956974029541016
Validation loss: 2.0765749831353464

Epoch: 6| Step: 7
Training loss: 1.5329012870788574
Validation loss: 2.065976647920506

Epoch: 6| Step: 8
Training loss: 1.4916776418685913
Validation loss: 2.068048677136821

Epoch: 6| Step: 9
Training loss: 1.8417357206344604
Validation loss: 2.076447718886919

Epoch: 6| Step: 10
Training loss: 2.4384665489196777
Validation loss: 2.0816569764127015

Epoch: 6| Step: 11
Training loss: 0.9226014614105225
Validation loss: 2.0658777747102963

Epoch: 6| Step: 12
Training loss: 2.0216879844665527
Validation loss: 2.055093954968196

Epoch: 6| Step: 13
Training loss: 1.1587532758712769
Validation loss: 2.0560381540688137

Epoch: 191| Step: 0
Training loss: 2.137732744216919
Validation loss: 2.0483803031265095

Epoch: 6| Step: 1
Training loss: 1.5739967823028564
Validation loss: 2.078108873418582

Epoch: 6| Step: 2
Training loss: 1.570690631866455
Validation loss: 2.054303717869584

Epoch: 6| Step: 3
Training loss: 2.0450291633605957
Validation loss: 2.0756897631511895

Epoch: 6| Step: 4
Training loss: 1.526650071144104
Validation loss: 2.062268316104848

Epoch: 6| Step: 5
Training loss: 2.5264573097229004
Validation loss: 2.071336559070054

Epoch: 6| Step: 6
Training loss: 1.3541362285614014
Validation loss: 2.0554120489346084

Epoch: 6| Step: 7
Training loss: 1.6242189407348633
Validation loss: 2.0413898216780795

Epoch: 6| Step: 8
Training loss: 1.4443602561950684
Validation loss: 2.0253440385223715

Epoch: 6| Step: 9
Training loss: 1.9717565774917603
Validation loss: 2.0169081277744745

Epoch: 6| Step: 10
Training loss: 2.6069021224975586
Validation loss: 2.0206136165126676

Epoch: 6| Step: 11
Training loss: 1.345418930053711
Validation loss: 2.004740256135182

Epoch: 6| Step: 12
Training loss: 1.1763603687286377
Validation loss: 2.0123684073007233

Epoch: 6| Step: 13
Training loss: 3.4524214267730713
Validation loss: 2.013462858815347

Epoch: 192| Step: 0
Training loss: 1.5592708587646484
Validation loss: 2.019306121333953

Epoch: 6| Step: 1
Training loss: 2.1056509017944336
Validation loss: 2.047485787381408

Epoch: 6| Step: 2
Training loss: 1.5572984218597412
Validation loss: 2.057714876308236

Epoch: 6| Step: 3
Training loss: 1.8674290180206299
Validation loss: 2.0811814544021443

Epoch: 6| Step: 4
Training loss: 2.399810314178467
Validation loss: 2.0980038463428454

Epoch: 6| Step: 5
Training loss: 1.3687798976898193
Validation loss: 2.1346248426745014

Epoch: 6| Step: 6
Training loss: 1.5658568143844604
Validation loss: 2.1110282815912718

Epoch: 6| Step: 7
Training loss: 2.151986598968506
Validation loss: 2.1157319045835927

Epoch: 6| Step: 8
Training loss: 1.120401382446289
Validation loss: 2.089304498446885

Epoch: 6| Step: 9
Training loss: 1.6220327615737915
Validation loss: 2.088516009751187

Epoch: 6| Step: 10
Training loss: 1.74173903465271
Validation loss: 2.058451288489885

Epoch: 6| Step: 11
Training loss: 2.538794994354248
Validation loss: 2.0508723617881857

Epoch: 6| Step: 12
Training loss: 2.1671223640441895
Validation loss: 2.031139301997359

Epoch: 6| Step: 13
Training loss: 1.8540444374084473
Validation loss: 2.035250529166191

Epoch: 193| Step: 0
Training loss: 2.250958204269409
Validation loss: 2.0215911057687577

Epoch: 6| Step: 1
Training loss: 1.7434417009353638
Validation loss: 2.0184324095326085

Epoch: 6| Step: 2
Training loss: 1.6688679456710815
Validation loss: 2.0241387633867163

Epoch: 6| Step: 3
Training loss: 1.7909189462661743
Validation loss: 2.019454509981217

Epoch: 6| Step: 4
Training loss: 1.7711049318313599
Validation loss: 2.0355678809586393

Epoch: 6| Step: 5
Training loss: 1.2183740139007568
Validation loss: 2.0516579125517156

Epoch: 6| Step: 6
Training loss: 1.4938442707061768
Validation loss: 2.0601018116038334

Epoch: 6| Step: 7
Training loss: 1.6232208013534546
Validation loss: 2.0750482979641167

Epoch: 6| Step: 8
Training loss: 1.9292800426483154
Validation loss: 2.0900226331526235

Epoch: 6| Step: 9
Training loss: 1.9193906784057617
Validation loss: 2.0982064021530973

Epoch: 6| Step: 10
Training loss: 2.3779449462890625
Validation loss: 2.115222607889483

Epoch: 6| Step: 11
Training loss: 1.778175711631775
Validation loss: 2.0866300918722667

Epoch: 6| Step: 12
Training loss: 1.9956897497177124
Validation loss: 2.075618146568216

Epoch: 6| Step: 13
Training loss: 2.0661823749542236
Validation loss: 2.055792300931869

Epoch: 194| Step: 0
Training loss: 2.296891212463379
Validation loss: 2.0254651359332505

Epoch: 6| Step: 1
Training loss: 1.482557773590088
Validation loss: 2.0170495176828034

Epoch: 6| Step: 2
Training loss: 1.6736103296279907
Validation loss: 1.998677933087913

Epoch: 6| Step: 3
Training loss: 2.3228883743286133
Validation loss: 2.0066088873852967

Epoch: 6| Step: 4
Training loss: 1.3662930727005005
Validation loss: 1.9861107731378207

Epoch: 6| Step: 5
Training loss: 1.5328307151794434
Validation loss: 1.9897923341361425

Epoch: 6| Step: 6
Training loss: 1.4446353912353516
Validation loss: 1.989769131906571

Epoch: 6| Step: 7
Training loss: 2.0491299629211426
Validation loss: 1.9832342978446715

Epoch: 6| Step: 8
Training loss: 2.2956042289733887
Validation loss: 1.9998872895394602

Epoch: 6| Step: 9
Training loss: 1.8190932273864746
Validation loss: 1.9978942448093044

Epoch: 6| Step: 10
Training loss: 1.6979942321777344
Validation loss: 2.0197548238180016

Epoch: 6| Step: 11
Training loss: 2.079564332962036
Validation loss: 2.0356380580573954

Epoch: 6| Step: 12
Training loss: 1.2549934387207031
Validation loss: 2.0209631535314743

Epoch: 6| Step: 13
Training loss: 2.42447566986084
Validation loss: 2.0325607779205486

Epoch: 195| Step: 0
Training loss: 2.051862955093384
Validation loss: 2.0630654224785427

Epoch: 6| Step: 1
Training loss: 1.5697314739227295
Validation loss: 2.0775937752057145

Epoch: 6| Step: 2
Training loss: 1.7732412815093994
Validation loss: 2.107516227229949

Epoch: 6| Step: 3
Training loss: 1.6375248432159424
Validation loss: 2.1121460237810687

Epoch: 6| Step: 4
Training loss: 1.8359222412109375
Validation loss: 2.134435543449976

Epoch: 6| Step: 5
Training loss: 2.0943729877471924
Validation loss: 2.160059718675511

Epoch: 6| Step: 6
Training loss: 2.2325544357299805
Validation loss: 2.1297652413768153

Epoch: 6| Step: 7
Training loss: 1.8217682838439941
Validation loss: 2.0957279051503828

Epoch: 6| Step: 8
Training loss: 1.719123363494873
Validation loss: 2.0811220702304634

Epoch: 6| Step: 9
Training loss: 1.8542835712432861
Validation loss: 2.051950189375108

Epoch: 6| Step: 10
Training loss: 1.7419943809509277
Validation loss: 2.0499753618753083

Epoch: 6| Step: 11
Training loss: 1.9502665996551514
Validation loss: 2.047838863506112

Epoch: 6| Step: 12
Training loss: 1.413619041442871
Validation loss: 2.0512994617544194

Epoch: 6| Step: 13
Training loss: 2.1052145957946777
Validation loss: 2.028686664437735

Epoch: 196| Step: 0
Training loss: 1.590688705444336
Validation loss: 2.028710754968787

Epoch: 6| Step: 1
Training loss: 1.468320608139038
Validation loss: 2.016691759068479

Epoch: 6| Step: 2
Training loss: 1.8876445293426514
Validation loss: 2.027781063510526

Epoch: 6| Step: 3
Training loss: 1.6045249700546265
Validation loss: 2.0077147842735372

Epoch: 6| Step: 4
Training loss: 2.2969472408294678
Validation loss: 2.017320397079632

Epoch: 6| Step: 5
Training loss: 1.5559710264205933
Validation loss: 2.020571472824261

Epoch: 6| Step: 6
Training loss: 1.9707342386245728
Validation loss: 2.0213520116703485

Epoch: 6| Step: 7
Training loss: 1.6084871292114258
Validation loss: 2.0259888595150364

Epoch: 6| Step: 8
Training loss: 1.3656055927276611
Validation loss: 2.02151301599318

Epoch: 6| Step: 9
Training loss: 1.0455303192138672
Validation loss: 2.020233667025002

Epoch: 6| Step: 10
Training loss: 2.5355992317199707
Validation loss: 2.0367185915670087

Epoch: 6| Step: 11
Training loss: 1.488903284072876
Validation loss: 2.0358088554874545

Epoch: 6| Step: 12
Training loss: 2.827545166015625
Validation loss: 2.046707166138516

Epoch: 6| Step: 13
Training loss: 1.8598848581314087
Validation loss: 2.05847906297253

Epoch: 197| Step: 0
Training loss: 2.074601173400879
Validation loss: 2.039698959678732

Epoch: 6| Step: 1
Training loss: 1.7467390298843384
Validation loss: 2.0637455960755706

Epoch: 6| Step: 2
Training loss: 1.4200224876403809
Validation loss: 2.0484845189638037

Epoch: 6| Step: 3
Training loss: 1.283893346786499
Validation loss: 2.0579625457845707

Epoch: 6| Step: 4
Training loss: 1.0218091011047363
Validation loss: 2.0459378688566145

Epoch: 6| Step: 5
Training loss: 1.774774193763733
Validation loss: 2.0565362066350956

Epoch: 6| Step: 6
Training loss: 2.006728410720825
Validation loss: 2.0414848712182816

Epoch: 6| Step: 7
Training loss: 1.9244964122772217
Validation loss: 2.048604763964171

Epoch: 6| Step: 8
Training loss: 1.686543345451355
Validation loss: 2.0418156321330736

Epoch: 6| Step: 9
Training loss: 2.229236125946045
Validation loss: 2.0394229606915544

Epoch: 6| Step: 10
Training loss: 2.0173845291137695
Validation loss: 2.0289879075942503

Epoch: 6| Step: 11
Training loss: 1.6124382019042969
Validation loss: 2.0139162668617825

Epoch: 6| Step: 12
Training loss: 1.902592658996582
Validation loss: 2.015489121919037

Epoch: 6| Step: 13
Training loss: 2.3676083087921143
Validation loss: 2.0219676648416827

Epoch: 198| Step: 0
Training loss: 1.2837847471237183
Validation loss: 2.0108350912729898

Epoch: 6| Step: 1
Training loss: 1.4751641750335693
Validation loss: 2.036409208851476

Epoch: 6| Step: 2
Training loss: 1.381652593612671
Validation loss: 2.05293212398406

Epoch: 6| Step: 3
Training loss: 1.3797898292541504
Validation loss: 2.062426127413268

Epoch: 6| Step: 4
Training loss: 1.6256357431411743
Validation loss: 2.0604996258212673

Epoch: 6| Step: 5
Training loss: 1.7061028480529785
Validation loss: 2.0616997800847536

Epoch: 6| Step: 6
Training loss: 1.404297113418579
Validation loss: 2.0737858972241803

Epoch: 6| Step: 7
Training loss: 2.1087357997894287
Validation loss: 2.061961676484795

Epoch: 6| Step: 8
Training loss: 2.541431188583374
Validation loss: 2.07292765186679

Epoch: 6| Step: 9
Training loss: 1.3956570625305176
Validation loss: 2.063577366131608

Epoch: 6| Step: 10
Training loss: 1.5519237518310547
Validation loss: 2.0429592465841644

Epoch: 6| Step: 11
Training loss: 2.6428842544555664
Validation loss: 2.0291812778801046

Epoch: 6| Step: 12
Training loss: 2.211055278778076
Validation loss: 2.033881322030098

Epoch: 6| Step: 13
Training loss: 1.7896249294281006
Validation loss: 2.0363864027043825

Epoch: 199| Step: 0
Training loss: 1.5869505405426025
Validation loss: 2.050803940783265

Epoch: 6| Step: 1
Training loss: 2.3193514347076416
Validation loss: 2.076182723045349

Epoch: 6| Step: 2
Training loss: 1.5288947820663452
Validation loss: 2.0722287957386305

Epoch: 6| Step: 3
Training loss: 1.5990021228790283
Validation loss: 2.073950304779955

Epoch: 6| Step: 4
Training loss: 1.3938210010528564
Validation loss: 2.0653471100714897

Epoch: 6| Step: 5
Training loss: 2.379899740219116
Validation loss: 2.048305660165766

Epoch: 6| Step: 6
Training loss: 1.649263858795166
Validation loss: 2.0453284696866105

Epoch: 6| Step: 7
Training loss: 1.580618143081665
Validation loss: 2.0340383116916945

Epoch: 6| Step: 8
Training loss: 1.9176682233810425
Validation loss: 2.0431195741058676

Epoch: 6| Step: 9
Training loss: 1.700620174407959
Validation loss: 2.035817369338005

Epoch: 6| Step: 10
Training loss: 1.8580410480499268
Validation loss: 2.0580826677301878

Epoch: 6| Step: 11
Training loss: 1.7591571807861328
Validation loss: 2.0711145195909726

Epoch: 6| Step: 12
Training loss: 1.8156683444976807
Validation loss: 2.109444092678767

Epoch: 6| Step: 13
Training loss: 1.7442374229431152
Validation loss: 2.1214061501205608

Epoch: 200| Step: 0
Training loss: 1.439314603805542
Validation loss: 2.106488909772647

Epoch: 6| Step: 1
Training loss: 1.8997726440429688
Validation loss: 2.122532726615988

Epoch: 6| Step: 2
Training loss: 1.479874610900879
Validation loss: 2.101908532522058

Epoch: 6| Step: 3
Training loss: 2.8014588356018066
Validation loss: 2.102561225173294

Epoch: 6| Step: 4
Training loss: 1.682237982749939
Validation loss: 2.0776108939160585

Epoch: 6| Step: 5
Training loss: 1.7594397068023682
Validation loss: 2.0630037092393443

Epoch: 6| Step: 6
Training loss: 2.433358907699585
Validation loss: 2.0634372516344954

Epoch: 6| Step: 7
Training loss: 1.417860507965088
Validation loss: 2.0349730753129527

Epoch: 6| Step: 8
Training loss: 1.2366654872894287
Validation loss: 2.030497750928325

Epoch: 6| Step: 9
Training loss: 1.716521978378296
Validation loss: 2.031578743329612

Epoch: 6| Step: 10
Training loss: 1.8152704238891602
Validation loss: 2.051376740137736

Epoch: 6| Step: 11
Training loss: 1.7378381490707397
Validation loss: 2.061581491142191

Epoch: 6| Step: 12
Training loss: 1.8446950912475586
Validation loss: 2.0665296482783493

Epoch: 6| Step: 13
Training loss: 1.4414088726043701
Validation loss: 2.0552370625157512

Epoch: 201| Step: 0
Training loss: 1.5502898693084717
Validation loss: 2.0469089554202173

Epoch: 6| Step: 1
Training loss: 1.673567295074463
Validation loss: 2.0381389074428107

Epoch: 6| Step: 2
Training loss: 1.767045021057129
Validation loss: 2.03229344788418

Epoch: 6| Step: 3
Training loss: 1.7448539733886719
Validation loss: 2.060382189289216

Epoch: 6| Step: 4
Training loss: 1.7894588708877563
Validation loss: 2.0670819179986113

Epoch: 6| Step: 5
Training loss: 1.5311923027038574
Validation loss: 2.061745641052082

Epoch: 6| Step: 6
Training loss: 2.5576024055480957
Validation loss: 2.0581867323126843

Epoch: 6| Step: 7
Training loss: 1.7544856071472168
Validation loss: 2.05115593120616

Epoch: 6| Step: 8
Training loss: 1.5263564586639404
Validation loss: 2.051544850872409

Epoch: 6| Step: 9
Training loss: 2.021063804626465
Validation loss: 2.0151326233340847

Epoch: 6| Step: 10
Training loss: 1.3367352485656738
Validation loss: 1.9939650925256873

Epoch: 6| Step: 11
Training loss: 2.293867349624634
Validation loss: 1.9844963473658408

Epoch: 6| Step: 12
Training loss: 0.9511649012565613
Validation loss: 1.9949164429018575

Epoch: 6| Step: 13
Training loss: 1.690087914466858
Validation loss: 2.010249586515529

Epoch: 202| Step: 0
Training loss: 1.5670559406280518
Validation loss: 2.027425407081522

Epoch: 6| Step: 1
Training loss: 2.424062967300415
Validation loss: 2.024782052604101

Epoch: 6| Step: 2
Training loss: 2.1308140754699707
Validation loss: 2.0243630614331973

Epoch: 6| Step: 3
Training loss: 1.3576639890670776
Validation loss: 2.0194660540549987

Epoch: 6| Step: 4
Training loss: 1.9161970615386963
Validation loss: 2.0441091009365615

Epoch: 6| Step: 5
Training loss: 2.101613998413086
Validation loss: 2.0594942633823683

Epoch: 6| Step: 6
Training loss: 1.897074580192566
Validation loss: 2.0814949338154127

Epoch: 6| Step: 7
Training loss: 1.1741427183151245
Validation loss: 2.0753727805229927

Epoch: 6| Step: 8
Training loss: 1.2858693599700928
Validation loss: 2.0822598703445925

Epoch: 6| Step: 9
Training loss: 1.3070716857910156
Validation loss: 2.0574143983984507

Epoch: 6| Step: 10
Training loss: 2.0836825370788574
Validation loss: 2.0355019466851347

Epoch: 6| Step: 11
Training loss: 2.2132201194763184
Validation loss: 2.0267117895105833

Epoch: 6| Step: 12
Training loss: 1.424137830734253
Validation loss: 2.043237805366516

Epoch: 6| Step: 13
Training loss: 1.5130152702331543
Validation loss: 2.0596070238339004

Epoch: 203| Step: 0
Training loss: 1.5115911960601807
Validation loss: 2.060855339932185

Epoch: 6| Step: 1
Training loss: 2.3305978775024414
Validation loss: 2.0478898889275006

Epoch: 6| Step: 2
Training loss: 1.490391731262207
Validation loss: 2.0401756814731065

Epoch: 6| Step: 3
Training loss: 1.8429774045944214
Validation loss: 2.041341504743022

Epoch: 6| Step: 4
Training loss: 1.503466010093689
Validation loss: 2.034924932705459

Epoch: 6| Step: 5
Training loss: 1.2698006629943848
Validation loss: 2.038249202953872

Epoch: 6| Step: 6
Training loss: 2.051990032196045
Validation loss: 2.0566870499682683

Epoch: 6| Step: 7
Training loss: 2.0063343048095703
Validation loss: 2.0316402758321455

Epoch: 6| Step: 8
Training loss: 1.524393081665039
Validation loss: 2.0040185515598585

Epoch: 6| Step: 9
Training loss: 1.804042100906372
Validation loss: 1.993751468196992

Epoch: 6| Step: 10
Training loss: 1.8169972896575928
Validation loss: 1.971919382772138

Epoch: 6| Step: 11
Training loss: 1.837428331375122
Validation loss: 1.9695534193387596

Epoch: 6| Step: 12
Training loss: 1.5570310354232788
Validation loss: 1.9757203876331288

Epoch: 6| Step: 13
Training loss: 1.603509783744812
Validation loss: 1.9710264526387697

Epoch: 204| Step: 0
Training loss: 1.3880082368850708
Validation loss: 1.990159902521359

Epoch: 6| Step: 1
Training loss: 1.500894546508789
Validation loss: 1.9924652358537078

Epoch: 6| Step: 2
Training loss: 2.1331515312194824
Validation loss: 2.0071647628661125

Epoch: 6| Step: 3
Training loss: 2.376638889312744
Validation loss: 2.010543369477795

Epoch: 6| Step: 4
Training loss: 1.4275341033935547
Validation loss: 2.03475385455675

Epoch: 6| Step: 5
Training loss: 1.9277141094207764
Validation loss: 2.0238471646462717

Epoch: 6| Step: 6
Training loss: 1.2086119651794434
Validation loss: 2.0257652523697063

Epoch: 6| Step: 7
Training loss: 1.9058811664581299
Validation loss: 2.059623541370515

Epoch: 6| Step: 8
Training loss: 1.1275067329406738
Validation loss: 2.0550982259934947

Epoch: 6| Step: 9
Training loss: 1.8662796020507812
Validation loss: 2.042488231453844

Epoch: 6| Step: 10
Training loss: 1.5834474563598633
Validation loss: 2.0385492053083194

Epoch: 6| Step: 11
Training loss: 2.323014259338379
Validation loss: 2.028835556840384

Epoch: 6| Step: 12
Training loss: 1.7410438060760498
Validation loss: 2.0114894349087953

Epoch: 6| Step: 13
Training loss: 1.1158736944198608
Validation loss: 2.0153985254226194

Epoch: 205| Step: 0
Training loss: 1.919093370437622
Validation loss: 2.0210164952021774

Epoch: 6| Step: 1
Training loss: 1.2035151720046997
Validation loss: 2.0456492054846978

Epoch: 6| Step: 2
Training loss: 1.2822840213775635
Validation loss: 2.0596375337211033

Epoch: 6| Step: 3
Training loss: 2.061300277709961
Validation loss: 2.0807177905113465

Epoch: 6| Step: 4
Training loss: 1.6978003978729248
Validation loss: 2.0801533575980895

Epoch: 6| Step: 5
Training loss: 1.5954031944274902
Validation loss: 2.081093836856145

Epoch: 6| Step: 6
Training loss: 1.9297459125518799
Validation loss: 2.093194741074757

Epoch: 6| Step: 7
Training loss: 2.077944278717041
Validation loss: 2.1115520436276674

Epoch: 6| Step: 8
Training loss: 2.4726576805114746
Validation loss: 2.120616010440293

Epoch: 6| Step: 9
Training loss: 1.3417730331420898
Validation loss: 2.1083444959373883

Epoch: 6| Step: 10
Training loss: 1.5375546216964722
Validation loss: 2.0922576099313717

Epoch: 6| Step: 11
Training loss: 2.0122950077056885
Validation loss: 2.0497115632539153

Epoch: 6| Step: 12
Training loss: 1.4517793655395508
Validation loss: 2.021806691282539

Epoch: 6| Step: 13
Training loss: 1.2682114839553833
Validation loss: 2.0037103827281664

Epoch: 206| Step: 0
Training loss: 1.9618988037109375
Validation loss: 1.9847232449439265

Epoch: 6| Step: 1
Training loss: 1.8585865497589111
Validation loss: 1.9670734174789921

Epoch: 6| Step: 2
Training loss: 1.8481411933898926
Validation loss: 1.9837982782753565

Epoch: 6| Step: 3
Training loss: 1.9404609203338623
Validation loss: 1.983521540959676

Epoch: 6| Step: 4
Training loss: 1.895829677581787
Validation loss: 1.9981518586476643

Epoch: 6| Step: 5
Training loss: 1.6408663988113403
Validation loss: 1.971594334930502

Epoch: 6| Step: 6
Training loss: 0.9816634058952332
Validation loss: 1.9837406373793078

Epoch: 6| Step: 7
Training loss: 1.9174168109893799
Validation loss: 2.009723958148751

Epoch: 6| Step: 8
Training loss: 1.472459316253662
Validation loss: 2.0136804003869333

Epoch: 6| Step: 9
Training loss: 1.707372784614563
Validation loss: 2.053682788725822

Epoch: 6| Step: 10
Training loss: 1.3395159244537354
Validation loss: 2.0529484479658064

Epoch: 6| Step: 11
Training loss: 1.9395575523376465
Validation loss: 2.073303036792304

Epoch: 6| Step: 12
Training loss: 1.9984902143478394
Validation loss: 2.082419582592544

Epoch: 6| Step: 13
Training loss: 1.2896265983581543
Validation loss: 2.095148737712573

Epoch: 207| Step: 0
Training loss: 1.7458369731903076
Validation loss: 2.100041820156959

Epoch: 6| Step: 1
Training loss: 1.826837182044983
Validation loss: 2.0819026500948015

Epoch: 6| Step: 2
Training loss: 1.793090581893921
Validation loss: 2.084404101935766

Epoch: 6| Step: 3
Training loss: 2.3109946250915527
Validation loss: 2.1028738137214416

Epoch: 6| Step: 4
Training loss: 1.338089942932129
Validation loss: 2.0757234442618584

Epoch: 6| Step: 5
Training loss: 1.6559607982635498
Validation loss: 2.0647488588927896

Epoch: 6| Step: 6
Training loss: 0.9453103542327881
Validation loss: 2.0693405187258156

Epoch: 6| Step: 7
Training loss: 2.0302276611328125
Validation loss: 2.0472733897547566

Epoch: 6| Step: 8
Training loss: 1.267840027809143
Validation loss: 2.0358251781873804

Epoch: 6| Step: 9
Training loss: 1.2375168800354004
Validation loss: 2.0198365719087663

Epoch: 6| Step: 10
Training loss: 2.256704330444336
Validation loss: 2.0058185028773483

Epoch: 6| Step: 11
Training loss: 1.706275463104248
Validation loss: 2.017450386478055

Epoch: 6| Step: 12
Training loss: 1.7475520372390747
Validation loss: 2.006016118552095

Epoch: 6| Step: 13
Training loss: 1.7603503465652466
Validation loss: 2.000867630845757

Epoch: 208| Step: 0
Training loss: 1.9701216220855713
Validation loss: 1.99602331525536

Epoch: 6| Step: 1
Training loss: 1.7829087972640991
Validation loss: 2.0046085183338453

Epoch: 6| Step: 2
Training loss: 1.8943660259246826
Validation loss: 2.0190531643488074

Epoch: 6| Step: 3
Training loss: 1.7089190483093262
Validation loss: 2.038779112600511

Epoch: 6| Step: 4
Training loss: 1.7309043407440186
Validation loss: 2.015536706934693

Epoch: 6| Step: 5
Training loss: 1.1842703819274902
Validation loss: 2.0046702559276293

Epoch: 6| Step: 6
Training loss: 1.186465859413147
Validation loss: 2.004228985437783

Epoch: 6| Step: 7
Training loss: 1.8803991079330444
Validation loss: 2.043128680157405

Epoch: 6| Step: 8
Training loss: 2.002941131591797
Validation loss: 2.046431400442636

Epoch: 6| Step: 9
Training loss: 1.787883996963501
Validation loss: 2.0498024135507564

Epoch: 6| Step: 10
Training loss: 2.2732043266296387
Validation loss: 2.0661610762278237

Epoch: 6| Step: 11
Training loss: 1.6662780046463013
Validation loss: 2.0663486232039747

Epoch: 6| Step: 12
Training loss: 1.1672613620758057
Validation loss: 2.0544458896883073

Epoch: 6| Step: 13
Training loss: 0.9473664164543152
Validation loss: 2.051465981750078

Epoch: 209| Step: 0
Training loss: 2.493302345275879
Validation loss: 2.046295868453159

Epoch: 6| Step: 1
Training loss: 2.3804259300231934
Validation loss: 2.0412365851863736

Epoch: 6| Step: 2
Training loss: 1.9058929681777954
Validation loss: 2.01868313230494

Epoch: 6| Step: 3
Training loss: 1.8440660238265991
Validation loss: 2.01496377811637

Epoch: 6| Step: 4
Training loss: 1.3095320463180542
Validation loss: 1.9987945889913907

Epoch: 6| Step: 5
Training loss: 1.2830021381378174
Validation loss: 2.0055485053728987

Epoch: 6| Step: 6
Training loss: 1.69944167137146
Validation loss: 2.01130667296789

Epoch: 6| Step: 7
Training loss: 1.5738003253936768
Validation loss: 2.0128067308856594

Epoch: 6| Step: 8
Training loss: 2.1955599784851074
Validation loss: 2.0372726301993094

Epoch: 6| Step: 9
Training loss: 1.2684524059295654
Validation loss: 2.002816915512085

Epoch: 6| Step: 10
Training loss: 1.2534770965576172
Validation loss: 2.0060669337549517

Epoch: 6| Step: 11
Training loss: 1.0736140012741089
Validation loss: 1.9908394685355566

Epoch: 6| Step: 12
Training loss: 1.681053876876831
Validation loss: 2.0026537846493464

Epoch: 6| Step: 13
Training loss: 1.382264256477356
Validation loss: 2.006108958234069

Epoch: 210| Step: 0
Training loss: 1.6906192302703857
Validation loss: 2.0551301792103756

Epoch: 6| Step: 1
Training loss: 2.546720266342163
Validation loss: 2.0971970032620173

Epoch: 6| Step: 2
Training loss: 2.2383816242218018
Validation loss: 2.095628282075287

Epoch: 6| Step: 3
Training loss: 1.484532356262207
Validation loss: 2.1242352083165157

Epoch: 6| Step: 4
Training loss: 1.974616527557373
Validation loss: 2.1342975003744966

Epoch: 6| Step: 5
Training loss: 0.7546142935752869
Validation loss: 2.146673605006228

Epoch: 6| Step: 6
Training loss: 1.5494897365570068
Validation loss: 2.110612246298021

Epoch: 6| Step: 7
Training loss: 1.78791081905365
Validation loss: 2.109396328208267

Epoch: 6| Step: 8
Training loss: 1.9929771423339844
Validation loss: 2.0898452574206936

Epoch: 6| Step: 9
Training loss: 1.5369203090667725
Validation loss: 2.0505162874857583

Epoch: 6| Step: 10
Training loss: 0.9498306512832642
Validation loss: 2.0446312965885287

Epoch: 6| Step: 11
Training loss: 1.9001163244247437
Validation loss: 2.0150962234825216

Epoch: 6| Step: 12
Training loss: 1.3351843357086182
Validation loss: 1.9887538827875608

Epoch: 6| Step: 13
Training loss: 1.5596641302108765
Validation loss: 1.967677140748629

Epoch: 211| Step: 0
Training loss: 1.0409506559371948
Validation loss: 1.9656565855908137

Epoch: 6| Step: 1
Training loss: 1.9638373851776123
Validation loss: 1.976778834096847

Epoch: 6| Step: 2
Training loss: 1.1294615268707275
Validation loss: 1.9490643701245707

Epoch: 6| Step: 3
Training loss: 1.6239792108535767
Validation loss: 1.974399306440866

Epoch: 6| Step: 4
Training loss: 1.7650223970413208
Validation loss: 1.9743981489571192

Epoch: 6| Step: 5
Training loss: 1.3316636085510254
Validation loss: 1.9800038952981271

Epoch: 6| Step: 6
Training loss: 1.648508071899414
Validation loss: 2.0010177909687

Epoch: 6| Step: 7
Training loss: 2.271437883377075
Validation loss: 1.993824012817875

Epoch: 6| Step: 8
Training loss: 1.7499642372131348
Validation loss: 1.9925033302717312

Epoch: 6| Step: 9
Training loss: 1.546098232269287
Validation loss: 1.975017314316124

Epoch: 6| Step: 10
Training loss: 2.0800962448120117
Validation loss: 1.9937229964040941

Epoch: 6| Step: 11
Training loss: 1.691854476928711
Validation loss: 2.0138722555611723

Epoch: 6| Step: 12
Training loss: 2.0341718196868896
Validation loss: 2.0385800023232736

Epoch: 6| Step: 13
Training loss: 1.053792953491211
Validation loss: 2.0489823177296627

Epoch: 212| Step: 0
Training loss: 2.55621337890625
Validation loss: 2.053302522628538

Epoch: 6| Step: 1
Training loss: 1.7498137950897217
Validation loss: 2.031197363330472

Epoch: 6| Step: 2
Training loss: 1.972672462463379
Validation loss: 1.988893957548244

Epoch: 6| Step: 3
Training loss: 1.9968750476837158
Validation loss: 2.0139091707045034

Epoch: 6| Step: 4
Training loss: 1.546952247619629
Validation loss: 2.0409814106520785

Epoch: 6| Step: 5
Training loss: 1.1365580558776855
Validation loss: 2.097993664844062

Epoch: 6| Step: 6
Training loss: 2.278733730316162
Validation loss: 2.141276869722592

Epoch: 6| Step: 7
Training loss: 1.9277877807617188
Validation loss: 2.127271649658039

Epoch: 6| Step: 8
Training loss: 1.6045739650726318
Validation loss: 2.0616519322959324

Epoch: 6| Step: 9
Training loss: 1.5128211975097656
Validation loss: 2.024900626110774

Epoch: 6| Step: 10
Training loss: 1.33579683303833
Validation loss: 2.0228361750161774

Epoch: 6| Step: 11
Training loss: 1.1223983764648438
Validation loss: 2.0384849476557907

Epoch: 6| Step: 12
Training loss: 1.553485631942749
Validation loss: 2.0478208603397494

Epoch: 6| Step: 13
Training loss: 1.0770275592803955
Validation loss: 2.0368473170905985

Epoch: 213| Step: 0
Training loss: 1.6017860174179077
Validation loss: 2.021512254591911

Epoch: 6| Step: 1
Training loss: 1.8857051134109497
Validation loss: 2.0323621970351025

Epoch: 6| Step: 2
Training loss: 1.7497879266738892
Validation loss: 2.0243834167398433

Epoch: 6| Step: 3
Training loss: 1.782867431640625
Validation loss: 2.008438256479079

Epoch: 6| Step: 4
Training loss: 1.5814197063446045
Validation loss: 2.028910408737839

Epoch: 6| Step: 5
Training loss: 1.6392220258712769
Validation loss: 2.0443101454806585

Epoch: 6| Step: 6
Training loss: 1.4754157066345215
Validation loss: 2.0478359806922173

Epoch: 6| Step: 7
Training loss: 1.5358929634094238
Validation loss: 2.0621493490793372

Epoch: 6| Step: 8
Training loss: 1.6010199785232544
Validation loss: 2.0567124120650755

Epoch: 6| Step: 9
Training loss: 1.0318748950958252
Validation loss: 2.039672387543545

Epoch: 6| Step: 10
Training loss: 1.2106162309646606
Validation loss: 2.0073128848947506

Epoch: 6| Step: 11
Training loss: 2.083069324493408
Validation loss: 2.010335638958921

Epoch: 6| Step: 12
Training loss: 1.9016846418380737
Validation loss: 1.9941660127332133

Epoch: 6| Step: 13
Training loss: 2.068938732147217
Validation loss: 1.977219335494503

Epoch: 214| Step: 0
Training loss: 1.967695951461792
Validation loss: 1.965730244113553

Epoch: 6| Step: 1
Training loss: 1.4561632871627808
Validation loss: 1.9728457876431045

Epoch: 6| Step: 2
Training loss: 1.8658806085586548
Validation loss: 1.9782388902479602

Epoch: 6| Step: 3
Training loss: 1.3023600578308105
Validation loss: 1.9915888745297667

Epoch: 6| Step: 4
Training loss: 1.490932822227478
Validation loss: 1.9643021783521097

Epoch: 6| Step: 5
Training loss: 1.131418228149414
Validation loss: 1.983363756569483

Epoch: 6| Step: 6
Training loss: 1.1844477653503418
Validation loss: 1.9634977912390104

Epoch: 6| Step: 7
Training loss: 1.89181387424469
Validation loss: 1.9622013120241062

Epoch: 6| Step: 8
Training loss: 2.614020824432373
Validation loss: 1.9756383652328162

Epoch: 6| Step: 9
Training loss: 1.8871482610702515
Validation loss: 1.964428218462134

Epoch: 6| Step: 10
Training loss: 1.5545518398284912
Validation loss: 1.995385403274208

Epoch: 6| Step: 11
Training loss: 1.7736519575119019
Validation loss: 2.016816998040804

Epoch: 6| Step: 12
Training loss: 1.4814778566360474
Validation loss: 2.045296767706512

Epoch: 6| Step: 13
Training loss: 1.5906988382339478
Validation loss: 2.0506510811467327

Epoch: 215| Step: 0
Training loss: 1.765032410621643
Validation loss: 2.042737571142053

Epoch: 6| Step: 1
Training loss: 1.73953115940094
Validation loss: 2.0091113685279764

Epoch: 6| Step: 2
Training loss: 1.2298201322555542
Validation loss: 1.999802512507285

Epoch: 6| Step: 3
Training loss: 1.9435702562332153
Validation loss: 2.013543733986475

Epoch: 6| Step: 4
Training loss: 1.5894205570220947
Validation loss: 1.985801407085952

Epoch: 6| Step: 5
Training loss: 1.5068564414978027
Validation loss: 1.9811333751165738

Epoch: 6| Step: 6
Training loss: 1.4608334302902222
Validation loss: 1.9653161828235914

Epoch: 6| Step: 7
Training loss: 1.9359127283096313
Validation loss: 1.9630177687573176

Epoch: 6| Step: 8
Training loss: 1.5181705951690674
Validation loss: 1.9716087092635453

Epoch: 6| Step: 9
Training loss: 1.2936561107635498
Validation loss: 1.9949381761653449

Epoch: 6| Step: 10
Training loss: 1.3068151473999023
Validation loss: 1.9727598620999245

Epoch: 6| Step: 11
Training loss: 1.9839487075805664
Validation loss: 1.9715912470253565

Epoch: 6| Step: 12
Training loss: 1.4752557277679443
Validation loss: 1.9714069584364533

Epoch: 6| Step: 13
Training loss: 2.045766592025757
Validation loss: 1.9948335629637524

Epoch: 216| Step: 0
Training loss: 1.5624511241912842
Validation loss: 2.00992997231022

Epoch: 6| Step: 1
Training loss: 1.790448784828186
Validation loss: 2.0361725450843893

Epoch: 6| Step: 2
Training loss: 1.478110909461975
Validation loss: 2.03358518949119

Epoch: 6| Step: 3
Training loss: 2.1434738636016846
Validation loss: 2.0137010556395336

Epoch: 6| Step: 4
Training loss: 1.7616088390350342
Validation loss: 1.9984773820446384

Epoch: 6| Step: 5
Training loss: 1.4211089611053467
Validation loss: 1.998449456307196

Epoch: 6| Step: 6
Training loss: 1.6740522384643555
Validation loss: 1.9677924853499218

Epoch: 6| Step: 7
Training loss: 2.4470486640930176
Validation loss: 1.975059781023251

Epoch: 6| Step: 8
Training loss: 1.8431397676467896
Validation loss: 1.9880316129294775

Epoch: 6| Step: 9
Training loss: 1.3505724668502808
Validation loss: 2.0130736289485807

Epoch: 6| Step: 10
Training loss: 1.090075969696045
Validation loss: 1.9911254170120403

Epoch: 6| Step: 11
Training loss: 1.0006954669952393
Validation loss: 1.9998699208741546

Epoch: 6| Step: 12
Training loss: 1.8545310497283936
Validation loss: 1.9968996893975042

Epoch: 6| Step: 13
Training loss: 1.3287127017974854
Validation loss: 1.990352633178875

Epoch: 217| Step: 0
Training loss: 0.9194818735122681
Validation loss: 1.9734999992514168

Epoch: 6| Step: 1
Training loss: 1.668508529663086
Validation loss: 1.9949543886287238

Epoch: 6| Step: 2
Training loss: 1.427904725074768
Validation loss: 1.9880771265234998

Epoch: 6| Step: 3
Training loss: 0.9653767347335815
Validation loss: 1.995293519830191

Epoch: 6| Step: 4
Training loss: 0.9537925124168396
Validation loss: 1.992826448973789

Epoch: 6| Step: 5
Training loss: 1.6420387029647827
Validation loss: 1.9988686089874597

Epoch: 6| Step: 6
Training loss: 1.4344573020935059
Validation loss: 1.996898506277351

Epoch: 6| Step: 7
Training loss: 2.376352310180664
Validation loss: 2.000363690878755

Epoch: 6| Step: 8
Training loss: 1.577143669128418
Validation loss: 1.9981067898452922

Epoch: 6| Step: 9
Training loss: 2.019686222076416
Validation loss: 1.9868463047089115

Epoch: 6| Step: 10
Training loss: 1.863732099533081
Validation loss: 1.976694078855617

Epoch: 6| Step: 11
Training loss: 1.8277580738067627
Validation loss: 1.9833280623600047

Epoch: 6| Step: 12
Training loss: 2.4124691486358643
Validation loss: 1.9863231617917296

Epoch: 6| Step: 13
Training loss: 0.8960282206535339
Validation loss: 1.9723228485353532

Epoch: 218| Step: 0
Training loss: 1.2577202320098877
Validation loss: 1.9729262257135043

Epoch: 6| Step: 1
Training loss: 1.6699254512786865
Validation loss: 1.9639072956577424

Epoch: 6| Step: 2
Training loss: 1.483413577079773
Validation loss: 1.9629839030645226

Epoch: 6| Step: 3
Training loss: 1.2092218399047852
Validation loss: 1.957507574430076

Epoch: 6| Step: 4
Training loss: 2.044821262359619
Validation loss: 1.9531501877692439

Epoch: 6| Step: 5
Training loss: 1.7047314643859863
Validation loss: 1.9586618946444603

Epoch: 6| Step: 6
Training loss: 0.9354474544525146
Validation loss: 1.9558913746187765

Epoch: 6| Step: 7
Training loss: 1.7783360481262207
Validation loss: 1.966349668400262

Epoch: 6| Step: 8
Training loss: 1.4353339672088623
Validation loss: 1.9853924974318473

Epoch: 6| Step: 9
Training loss: 1.6316173076629639
Validation loss: 1.9960333570357291

Epoch: 6| Step: 10
Training loss: 1.6758675575256348
Validation loss: 1.9915899102405836

Epoch: 6| Step: 11
Training loss: 1.3883390426635742
Validation loss: 2.010052957842427

Epoch: 6| Step: 12
Training loss: 2.5384671688079834
Validation loss: 2.0232846839453584

Epoch: 6| Step: 13
Training loss: 1.0999475717544556
Validation loss: 2.024797385738742

Epoch: 219| Step: 0
Training loss: 1.2716259956359863
Validation loss: 2.0186272462209067

Epoch: 6| Step: 1
Training loss: 1.85016930103302
Validation loss: 2.0453019731788227

Epoch: 6| Step: 2
Training loss: 1.2701932191848755
Validation loss: 2.021721878359395

Epoch: 6| Step: 3
Training loss: 1.3141781091690063
Validation loss: 2.0303904676950104

Epoch: 6| Step: 4
Training loss: 1.6775271892547607
Validation loss: 2.028268990978118

Epoch: 6| Step: 5
Training loss: 1.064621090888977
Validation loss: 2.0014621903819423

Epoch: 6| Step: 6
Training loss: 1.5249062776565552
Validation loss: 2.003625133986114

Epoch: 6| Step: 7
Training loss: 1.8575741052627563
Validation loss: 2.005010311321546

Epoch: 6| Step: 8
Training loss: 2.137936592102051
Validation loss: 1.9993563890457153

Epoch: 6| Step: 9
Training loss: 1.3175280094146729
Validation loss: 2.0002749094399075

Epoch: 6| Step: 10
Training loss: 1.823232650756836
Validation loss: 1.9883114176411782

Epoch: 6| Step: 11
Training loss: 1.218245506286621
Validation loss: 1.9870486656824748

Epoch: 6| Step: 12
Training loss: 1.9256125688552856
Validation loss: 1.9927983373724005

Epoch: 6| Step: 13
Training loss: 1.693961501121521
Validation loss: 2.0084603217340287

Epoch: 220| Step: 0
Training loss: 1.421891450881958
Validation loss: 2.0151692103314143

Epoch: 6| Step: 1
Training loss: 1.3845443725585938
Validation loss: 2.0340927390642065

Epoch: 6| Step: 2
Training loss: 1.4846584796905518
Validation loss: 2.0324357632667787

Epoch: 6| Step: 3
Training loss: 0.7075468301773071
Validation loss: 2.0250615227606987

Epoch: 6| Step: 4
Training loss: 1.8769291639328003
Validation loss: 2.017320704716508

Epoch: 6| Step: 5
Training loss: 2.354585647583008
Validation loss: 2.018006596513974

Epoch: 6| Step: 6
Training loss: 1.140836477279663
Validation loss: 2.026333552534862

Epoch: 6| Step: 7
Training loss: 1.4563500881195068
Validation loss: 2.0075224778985463

Epoch: 6| Step: 8
Training loss: 2.1673741340637207
Validation loss: 2.006808356572223

Epoch: 6| Step: 9
Training loss: 2.11570405960083
Validation loss: 2.014613033622824

Epoch: 6| Step: 10
Training loss: 1.5736300945281982
Validation loss: 2.0031895663148616

Epoch: 6| Step: 11
Training loss: 1.1757197380065918
Validation loss: 2.012515914055609

Epoch: 6| Step: 12
Training loss: 1.069509506225586
Validation loss: 1.9917971280313307

Epoch: 6| Step: 13
Training loss: 1.5071165561676025
Validation loss: 1.9964827299118042

Epoch: 221| Step: 0
Training loss: 1.380886197090149
Validation loss: 1.986538347377572

Epoch: 6| Step: 1
Training loss: 2.1589741706848145
Validation loss: 1.972674395448418

Epoch: 6| Step: 2
Training loss: 1.4939063787460327
Validation loss: 1.9775123468009375

Epoch: 6| Step: 3
Training loss: 1.1969141960144043
Validation loss: 1.9754643042882283

Epoch: 6| Step: 4
Training loss: 1.6136972904205322
Validation loss: 1.9730039232520646

Epoch: 6| Step: 5
Training loss: 1.4089598655700684
Validation loss: 1.9647105278507355

Epoch: 6| Step: 6
Training loss: 1.4880080223083496
Validation loss: 1.9765711112688946

Epoch: 6| Step: 7
Training loss: 1.3812501430511475
Validation loss: 2.01319726820915

Epoch: 6| Step: 8
Training loss: 1.8628671169281006
Validation loss: 2.0039719048366753

Epoch: 6| Step: 9
Training loss: 1.6172558069229126
Validation loss: 1.9793157897969729

Epoch: 6| Step: 10
Training loss: 1.5057880878448486
Validation loss: 1.9983528673007924

Epoch: 6| Step: 11
Training loss: 1.5151612758636475
Validation loss: 1.9838291098994594

Epoch: 6| Step: 12
Training loss: 1.1307674646377563
Validation loss: 1.9926923577503493

Epoch: 6| Step: 13
Training loss: 1.442001461982727
Validation loss: 1.993638700054538

Epoch: 222| Step: 0
Training loss: 2.104705810546875
Validation loss: 1.9878033835400817

Epoch: 6| Step: 1
Training loss: 1.2543270587921143
Validation loss: 1.9776141887070031

Epoch: 6| Step: 2
Training loss: 1.5415408611297607
Validation loss: 1.986201669580193

Epoch: 6| Step: 3
Training loss: 1.5283384323120117
Validation loss: 1.9701017628433883

Epoch: 6| Step: 4
Training loss: 1.2038323879241943
Validation loss: 1.9831084115530855

Epoch: 6| Step: 5
Training loss: 1.6018002033233643
Validation loss: 1.9611810330421693

Epoch: 6| Step: 6
Training loss: 1.4727110862731934
Validation loss: 1.9751219557177635

Epoch: 6| Step: 7
Training loss: 1.3940600156784058
Validation loss: 1.9790466523939563

Epoch: 6| Step: 8
Training loss: 1.938633918762207
Validation loss: 1.9791483622725292

Epoch: 6| Step: 9
Training loss: 1.2853705883026123
Validation loss: 1.9920531101124261

Epoch: 6| Step: 10
Training loss: 1.5039317607879639
Validation loss: 2.0043332602388118

Epoch: 6| Step: 11
Training loss: 1.6348514556884766
Validation loss: 2.045254862436684

Epoch: 6| Step: 12
Training loss: 1.1871693134307861
Validation loss: 2.0756785203051824

Epoch: 6| Step: 13
Training loss: 2.258580207824707
Validation loss: 2.073583536250617

Epoch: 223| Step: 0
Training loss: 1.090023159980774
Validation loss: 2.105591256131408

Epoch: 6| Step: 1
Training loss: 1.1208748817443848
Validation loss: 2.1059583438340055

Epoch: 6| Step: 2
Training loss: 1.9879851341247559
Validation loss: 2.098740267497237

Epoch: 6| Step: 3
Training loss: 1.9717319011688232
Validation loss: 2.0796777279146257

Epoch: 6| Step: 4
Training loss: 1.1891807317733765
Validation loss: 2.0625795741235056

Epoch: 6| Step: 5
Training loss: 1.7390838861465454
Validation loss: 2.003635657730923

Epoch: 6| Step: 6
Training loss: 2.3376665115356445
Validation loss: 2.032630414091131

Epoch: 6| Step: 7
Training loss: 1.079545021057129
Validation loss: 1.982512589423887

Epoch: 6| Step: 8
Training loss: 1.8545846939086914
Validation loss: 1.9659853955750823

Epoch: 6| Step: 9
Training loss: 1.5450477600097656
Validation loss: 1.968923245706866

Epoch: 6| Step: 10
Training loss: 1.8003216981887817
Validation loss: 1.942506549178913

Epoch: 6| Step: 11
Training loss: 1.0406150817871094
Validation loss: 1.9565818912239485

Epoch: 6| Step: 12
Training loss: 1.2732049226760864
Validation loss: 1.9528488395034627

Epoch: 6| Step: 13
Training loss: 1.2827143669128418
Validation loss: 1.9729939301808674

Epoch: 224| Step: 0
Training loss: 1.4541735649108887
Validation loss: 1.9492922418860978

Epoch: 6| Step: 1
Training loss: 1.4078855514526367
Validation loss: 1.966616516472191

Epoch: 6| Step: 2
Training loss: 1.5936307907104492
Validation loss: 1.973910568862833

Epoch: 6| Step: 3
Training loss: 1.7877775430679321
Validation loss: 2.017956772158223

Epoch: 6| Step: 4
Training loss: 1.1868077516555786
Validation loss: 2.008910616238912

Epoch: 6| Step: 5
Training loss: 1.3658581972122192
Validation loss: 2.026284758762647

Epoch: 6| Step: 6
Training loss: 2.064161777496338
Validation loss: 2.0358239104670863

Epoch: 6| Step: 7
Training loss: 1.4670740365982056
Validation loss: 2.0531119813201246

Epoch: 6| Step: 8
Training loss: 1.600341796875
Validation loss: 2.0351921384052565

Epoch: 6| Step: 9
Training loss: 1.1064746379852295
Validation loss: 2.03030337056806

Epoch: 6| Step: 10
Training loss: 2.0239992141723633
Validation loss: 2.0193896332094745

Epoch: 6| Step: 11
Training loss: 1.0906254053115845
Validation loss: 2.01473375802399

Epoch: 6| Step: 12
Training loss: 1.572218894958496
Validation loss: 2.0087349799371537

Epoch: 6| Step: 13
Training loss: 1.486889362335205
Validation loss: 1.982596863982498

Epoch: 225| Step: 0
Training loss: 1.621094822883606
Validation loss: 1.9770032872435868

Epoch: 6| Step: 1
Training loss: 1.9000556468963623
Validation loss: 1.9648580576783867

Epoch: 6| Step: 2
Training loss: 0.9237722754478455
Validation loss: 1.9740538404833885

Epoch: 6| Step: 3
Training loss: 1.7189160585403442
Validation loss: 1.9768737541731967

Epoch: 6| Step: 4
Training loss: 1.1077412366867065
Validation loss: 1.980136158645794

Epoch: 6| Step: 5
Training loss: 1.5729858875274658
Validation loss: 1.9469409514498968

Epoch: 6| Step: 6
Training loss: 1.4807968139648438
Validation loss: 1.9647266493048718

Epoch: 6| Step: 7
Training loss: 1.6199874877929688
Validation loss: 1.959980405786986

Epoch: 6| Step: 8
Training loss: 2.1170294284820557
Validation loss: 1.9697720376394128

Epoch: 6| Step: 9
Training loss: 2.039372205734253
Validation loss: 1.9759456829358173

Epoch: 6| Step: 10
Training loss: 1.2759279012680054
Validation loss: 1.9928505651412471

Epoch: 6| Step: 11
Training loss: 1.2002015113830566
Validation loss: 1.9892530300283944

Epoch: 6| Step: 12
Training loss: 1.251293420791626
Validation loss: 2.012773072847756

Epoch: 6| Step: 13
Training loss: 0.7834131717681885
Validation loss: 2.014429259043868

Epoch: 226| Step: 0
Training loss: 1.5237596035003662
Validation loss: 2.005424089329217

Epoch: 6| Step: 1
Training loss: 1.6197640895843506
Validation loss: 1.9907222499129593

Epoch: 6| Step: 2
Training loss: 1.5856733322143555
Validation loss: 1.967837490061278

Epoch: 6| Step: 3
Training loss: 2.0128767490386963
Validation loss: 1.9665138362556376

Epoch: 6| Step: 4
Training loss: 1.0376020669937134
Validation loss: 1.9698297285264539

Epoch: 6| Step: 5
Training loss: 1.2415745258331299
Validation loss: 1.9503016856408888

Epoch: 6| Step: 6
Training loss: 1.2827515602111816
Validation loss: 1.9459536178137666

Epoch: 6| Step: 7
Training loss: 1.6331982612609863
Validation loss: 1.9277980135333153

Epoch: 6| Step: 8
Training loss: 1.6261465549468994
Validation loss: 1.9362770075439124

Epoch: 6| Step: 9
Training loss: 1.3314425945281982
Validation loss: 1.9791317934631019

Epoch: 6| Step: 10
Training loss: 2.463517189025879
Validation loss: 1.96421738337445

Epoch: 6| Step: 11
Training loss: 1.048046588897705
Validation loss: 1.9871886340520715

Epoch: 6| Step: 12
Training loss: 1.2176673412322998
Validation loss: 1.969203863092648

Epoch: 6| Step: 13
Training loss: 1.108102560043335
Validation loss: 2.003765941948019

Epoch: 227| Step: 0
Training loss: 1.4419270753860474
Validation loss: 2.02153718215163

Epoch: 6| Step: 1
Training loss: 0.8896660804748535
Validation loss: 2.0470014413197837

Epoch: 6| Step: 2
Training loss: 1.0980898141860962
Validation loss: 2.021695431842599

Epoch: 6| Step: 3
Training loss: 1.1830443143844604
Validation loss: 2.027363610524003

Epoch: 6| Step: 4
Training loss: 1.6246371269226074
Validation loss: 2.0222509522591867

Epoch: 6| Step: 5
Training loss: 1.031914234161377
Validation loss: 2.0504892679952804

Epoch: 6| Step: 6
Training loss: 1.2546550035476685
Validation loss: 2.040076873635733

Epoch: 6| Step: 7
Training loss: 1.5079224109649658
Validation loss: 2.043572010532502

Epoch: 6| Step: 8
Training loss: 2.101149320602417
Validation loss: 2.029015609013137

Epoch: 6| Step: 9
Training loss: 1.8466957807540894
Validation loss: 2.0184672673543296

Epoch: 6| Step: 10
Training loss: 1.6280490159988403
Validation loss: 2.0028306771350164

Epoch: 6| Step: 11
Training loss: 1.630025863647461
Validation loss: 2.0160729628737255

Epoch: 6| Step: 12
Training loss: 1.7210237979888916
Validation loss: 2.0070778041757564

Epoch: 6| Step: 13
Training loss: 1.603813648223877
Validation loss: 2.0062602873771422

Epoch: 228| Step: 0
Training loss: 2.0611636638641357
Validation loss: 2.0257942189452467

Epoch: 6| Step: 1
Training loss: 1.273951530456543
Validation loss: 2.0298964054353776

Epoch: 6| Step: 2
Training loss: 1.4943010807037354
Validation loss: 2.0386683812705417

Epoch: 6| Step: 3
Training loss: 0.7346142530441284
Validation loss: 2.0298140959073137

Epoch: 6| Step: 4
Training loss: 1.9200267791748047
Validation loss: 1.9964332131929294

Epoch: 6| Step: 5
Training loss: 1.5326192378997803
Validation loss: 2.022029220416982

Epoch: 6| Step: 6
Training loss: 2.279834270477295
Validation loss: 2.0142530959139586

Epoch: 6| Step: 7
Training loss: 1.0227168798446655
Validation loss: 1.999145930813205

Epoch: 6| Step: 8
Training loss: 1.5256415605545044
Validation loss: 1.9828701685833674

Epoch: 6| Step: 9
Training loss: 1.375186800956726
Validation loss: 1.9683345902350642

Epoch: 6| Step: 10
Training loss: 0.8476532697677612
Validation loss: 1.9555484530746297

Epoch: 6| Step: 11
Training loss: 1.9611396789550781
Validation loss: 1.9658043230733564

Epoch: 6| Step: 12
Training loss: 1.757491111755371
Validation loss: 1.9607211556485904

Epoch: 6| Step: 13
Training loss: 1.3351480960845947
Validation loss: 1.9670384212206768

Epoch: 229| Step: 0
Training loss: 1.1070122718811035
Validation loss: 1.9629407326380413

Epoch: 6| Step: 1
Training loss: 1.5895018577575684
Validation loss: 1.9523964928042503

Epoch: 6| Step: 2
Training loss: 2.621403455734253
Validation loss: 1.9394593354194396

Epoch: 6| Step: 3
Training loss: 2.1607890129089355
Validation loss: 1.9347175295634935

Epoch: 6| Step: 4
Training loss: 1.0599826574325562
Validation loss: 1.9099075102037

Epoch: 6| Step: 5
Training loss: 1.1816842555999756
Validation loss: 1.9247851653765606

Epoch: 6| Step: 6
Training loss: 1.5839227437973022
Validation loss: 1.9395332938881331

Epoch: 6| Step: 7
Training loss: 1.326228380203247
Validation loss: 1.958670372604042

Epoch: 6| Step: 8
Training loss: 1.7874395847320557
Validation loss: 1.970977311493248

Epoch: 6| Step: 9
Training loss: 1.3093655109405518
Validation loss: 1.9686939754793722

Epoch: 6| Step: 10
Training loss: 1.0269441604614258
Validation loss: 1.9890618734462286

Epoch: 6| Step: 11
Training loss: 1.6231930255889893
Validation loss: 2.009612073180496

Epoch: 6| Step: 12
Training loss: 1.2677781581878662
Validation loss: 1.9913184617155342

Epoch: 6| Step: 13
Training loss: 0.8643488883972168
Validation loss: 1.9743340656321535

Epoch: 230| Step: 0
Training loss: 1.355309247970581
Validation loss: 1.9727862060710948

Epoch: 6| Step: 1
Training loss: 0.9735039472579956
Validation loss: 1.9821533028797438

Epoch: 6| Step: 2
Training loss: 1.6589864492416382
Validation loss: 1.979220180101292

Epoch: 6| Step: 3
Training loss: 1.9646379947662354
Validation loss: 1.9769181948836132

Epoch: 6| Step: 4
Training loss: 1.5599793195724487
Validation loss: 1.9566040487699612

Epoch: 6| Step: 5
Training loss: 1.7864134311676025
Validation loss: 1.9415387107479958

Epoch: 6| Step: 6
Training loss: 1.596860647201538
Validation loss: 1.954119792548559

Epoch: 6| Step: 7
Training loss: 1.9902794361114502
Validation loss: 1.9414694181052587

Epoch: 6| Step: 8
Training loss: 1.2658674716949463
Validation loss: 1.9596558360643284

Epoch: 6| Step: 9
Training loss: 0.8588533401489258
Validation loss: 1.9522756453483336

Epoch: 6| Step: 10
Training loss: 1.5140973329544067
Validation loss: 1.949004941089179

Epoch: 6| Step: 11
Training loss: 1.2840439081192017
Validation loss: 1.9425491415044314

Epoch: 6| Step: 12
Training loss: 1.269472360610962
Validation loss: 1.9383102616956156

Epoch: 6| Step: 13
Training loss: 0.7263792157173157
Validation loss: 1.9470444904860629

Epoch: 231| Step: 0
Training loss: 1.4088492393493652
Validation loss: 1.9480490889600528

Epoch: 6| Step: 1
Training loss: 2.200976610183716
Validation loss: 1.9892754785476192

Epoch: 6| Step: 2
Training loss: 1.3829126358032227
Validation loss: 1.9732521093019875

Epoch: 6| Step: 3
Training loss: 1.7866415977478027
Validation loss: 1.9921645874618201

Epoch: 6| Step: 4
Training loss: 1.0769411325454712
Validation loss: 1.9930819747268513

Epoch: 6| Step: 5
Training loss: 1.6937507390975952
Validation loss: 2.0128365626899143

Epoch: 6| Step: 6
Training loss: 0.5592777729034424
Validation loss: 2.0148689131582938

Epoch: 6| Step: 7
Training loss: 1.2714688777923584
Validation loss: 1.988126890633696

Epoch: 6| Step: 8
Training loss: 0.9990389943122864
Validation loss: 1.9964272386284285

Epoch: 6| Step: 9
Training loss: 1.4886975288391113
Validation loss: 1.9868724243615263

Epoch: 6| Step: 10
Training loss: 1.509130835533142
Validation loss: 1.9693677169020458

Epoch: 6| Step: 11
Training loss: 0.8949201107025146
Validation loss: 1.9448864626628097

Epoch: 6| Step: 12
Training loss: 1.645355224609375
Validation loss: 1.9354317124171923

Epoch: 6| Step: 13
Training loss: 2.158538818359375
Validation loss: 1.9419545588954803

Epoch: 232| Step: 0
Training loss: 1.1182379722595215
Validation loss: 1.94228434178137

Epoch: 6| Step: 1
Training loss: 1.2974880933761597
Validation loss: 1.9180018235278387

Epoch: 6| Step: 2
Training loss: 1.3557085990905762
Validation loss: 1.9319371446486442

Epoch: 6| Step: 3
Training loss: 1.406606912612915
Validation loss: 1.9273517772715578

Epoch: 6| Step: 4
Training loss: 1.420623779296875
Validation loss: 1.9343097402203469

Epoch: 6| Step: 5
Training loss: 1.7251250743865967
Validation loss: 1.9425250381551764

Epoch: 6| Step: 6
Training loss: 1.7034106254577637
Validation loss: 1.9495137673552319

Epoch: 6| Step: 7
Training loss: 1.6159827709197998
Validation loss: 1.9690241403477167

Epoch: 6| Step: 8
Training loss: 1.1787564754486084
Validation loss: 1.9475218865179247

Epoch: 6| Step: 9
Training loss: 1.3729604482650757
Validation loss: 1.971154587243193

Epoch: 6| Step: 10
Training loss: 1.3659214973449707
Validation loss: 1.9782565806501655

Epoch: 6| Step: 11
Training loss: 1.6107444763183594
Validation loss: 1.991457559729135

Epoch: 6| Step: 12
Training loss: 1.3941998481750488
Validation loss: 1.980122535459457

Epoch: 6| Step: 13
Training loss: 0.9391651153564453
Validation loss: 1.9851523471134964

Epoch: 233| Step: 0
Training loss: 0.9495345950126648
Validation loss: 1.9671849409739177

Epoch: 6| Step: 1
Training loss: 1.2370563745498657
Validation loss: 1.9527618987585909

Epoch: 6| Step: 2
Training loss: 1.6430671215057373
Validation loss: 1.9651716037463116

Epoch: 6| Step: 3
Training loss: 1.9236736297607422
Validation loss: 1.9566175732561337

Epoch: 6| Step: 4
Training loss: 1.9302098751068115
Validation loss: 1.9558820045122536

Epoch: 6| Step: 5
Training loss: 1.318344235420227
Validation loss: 1.945532484721112

Epoch: 6| Step: 6
Training loss: 1.3003599643707275
Validation loss: 1.9389037932119062

Epoch: 6| Step: 7
Training loss: 1.320848822593689
Validation loss: 1.9472465592045938

Epoch: 6| Step: 8
Training loss: 1.250124454498291
Validation loss: 1.9485177929683397

Epoch: 6| Step: 9
Training loss: 1.2192065715789795
Validation loss: 1.9407130082448323

Epoch: 6| Step: 10
Training loss: 1.4949967861175537
Validation loss: 1.9525080342446604

Epoch: 6| Step: 11
Training loss: 1.9820181131362915
Validation loss: 1.9275764111549623

Epoch: 6| Step: 12
Training loss: 1.3044440746307373
Validation loss: 1.9185016988426127

Epoch: 6| Step: 13
Training loss: 0.5044133067131042
Validation loss: 1.9269711227827175

Epoch: 234| Step: 0
Training loss: 1.4116911888122559
Validation loss: 1.9369516846954182

Epoch: 6| Step: 1
Training loss: 1.4818388223648071
Validation loss: 1.9322848653280607

Epoch: 6| Step: 2
Training loss: 0.8403374552726746
Validation loss: 1.909283426500136

Epoch: 6| Step: 3
Training loss: 0.8970958590507507
Validation loss: 1.9027776718139648

Epoch: 6| Step: 4
Training loss: 1.3423130512237549
Validation loss: 1.920314169699146

Epoch: 6| Step: 5
Training loss: 1.0769509077072144
Validation loss: 1.9427716116751395

Epoch: 6| Step: 6
Training loss: 1.075657844543457
Validation loss: 1.966066341246328

Epoch: 6| Step: 7
Training loss: 1.676687479019165
Validation loss: 1.9615572396145071

Epoch: 6| Step: 8
Training loss: 1.2979075908660889
Validation loss: 1.9645892727759577

Epoch: 6| Step: 9
Training loss: 1.2156645059585571
Validation loss: 1.9426044161601732

Epoch: 6| Step: 10
Training loss: 2.0293984413146973
Validation loss: 1.9559413194656372

Epoch: 6| Step: 11
Training loss: 1.2015419006347656
Validation loss: 1.9393801317420056

Epoch: 6| Step: 12
Training loss: 1.8523460626602173
Validation loss: 1.9578142601956603

Epoch: 6| Step: 13
Training loss: 2.4388411045074463
Validation loss: 1.960823969174457

Epoch: 235| Step: 0
Training loss: 1.6820029020309448
Validation loss: 1.9603094490625526

Epoch: 6| Step: 1
Training loss: 1.0792064666748047
Validation loss: 1.967347204044301

Epoch: 6| Step: 2
Training loss: 1.6508861780166626
Validation loss: 1.956386153415967

Epoch: 6| Step: 3
Training loss: 1.2643253803253174
Validation loss: 1.9320232624648719

Epoch: 6| Step: 4
Training loss: 0.9900745153427124
Validation loss: 1.9352761481397895

Epoch: 6| Step: 5
Training loss: 1.3432860374450684
Validation loss: 1.938769866061467

Epoch: 6| Step: 6
Training loss: 2.311400890350342
Validation loss: 1.934619257527013

Epoch: 6| Step: 7
Training loss: 1.2644877433776855
Validation loss: 1.9451552744834655

Epoch: 6| Step: 8
Training loss: 1.2466787099838257
Validation loss: 1.9202117945558281

Epoch: 6| Step: 9
Training loss: 1.1168785095214844
Validation loss: 1.9265333042349866

Epoch: 6| Step: 10
Training loss: 1.1935254335403442
Validation loss: 1.9436415549247497

Epoch: 6| Step: 11
Training loss: 1.6529054641723633
Validation loss: 1.9454847689597838

Epoch: 6| Step: 12
Training loss: 1.2241942882537842
Validation loss: 1.9370962227544477

Epoch: 6| Step: 13
Training loss: 0.9646587371826172
Validation loss: 1.9512839522413028

Epoch: 236| Step: 0
Training loss: 0.7287852168083191
Validation loss: 1.9520492143528436

Epoch: 6| Step: 1
Training loss: 1.3171899318695068
Validation loss: 1.9595642961481565

Epoch: 6| Step: 2
Training loss: 1.7352544069290161
Validation loss: 1.9607348288259199

Epoch: 6| Step: 3
Training loss: 1.915604591369629
Validation loss: 1.9476017516146424

Epoch: 6| Step: 4
Training loss: 1.6989777088165283
Validation loss: 1.9393482541525235

Epoch: 6| Step: 5
Training loss: 1.31809663772583
Validation loss: 1.973075154007122

Epoch: 6| Step: 6
Training loss: 1.1789668798446655
Validation loss: 1.9748337704648253

Epoch: 6| Step: 7
Training loss: 1.5677235126495361
Validation loss: 1.9575603982453704

Epoch: 6| Step: 8
Training loss: 1.3469841480255127
Validation loss: 1.9391585601273404

Epoch: 6| Step: 9
Training loss: 1.0614320039749146
Validation loss: 1.911512428714383

Epoch: 6| Step: 10
Training loss: 1.3296648263931274
Validation loss: 1.917336804892427

Epoch: 6| Step: 11
Training loss: 1.3388670682907104
Validation loss: 1.9326711546990178

Epoch: 6| Step: 12
Training loss: 1.2484407424926758
Validation loss: 1.942546611191124

Epoch: 6| Step: 13
Training loss: 1.498626470565796
Validation loss: 1.910312480823968

Epoch: 237| Step: 0
Training loss: 1.7174806594848633
Validation loss: 1.918217420578003

Epoch: 6| Step: 1
Training loss: 1.045579195022583
Validation loss: 1.9273719300505936

Epoch: 6| Step: 2
Training loss: 1.4860986471176147
Validation loss: 1.9516888933797036

Epoch: 6| Step: 3
Training loss: 1.632715106010437
Validation loss: 1.9633281602654407

Epoch: 6| Step: 4
Training loss: 1.5754584074020386
Validation loss: 1.9567288993507304

Epoch: 6| Step: 5
Training loss: 1.361706256866455
Validation loss: 1.9583381798959547

Epoch: 6| Step: 6
Training loss: 1.8695456981658936
Validation loss: 1.9547704573600524

Epoch: 6| Step: 7
Training loss: 1.2398931980133057
Validation loss: 1.9373130349702732

Epoch: 6| Step: 8
Training loss: 0.9479433298110962
Validation loss: 1.9249209255300543

Epoch: 6| Step: 9
Training loss: 0.8411664366722107
Validation loss: 1.9296962432963873

Epoch: 6| Step: 10
Training loss: 0.8268969058990479
Validation loss: 1.921948779013849

Epoch: 6| Step: 11
Training loss: 1.390427827835083
Validation loss: 1.9310581466203094

Epoch: 6| Step: 12
Training loss: 1.2102022171020508
Validation loss: 1.9063481771817772

Epoch: 6| Step: 13
Training loss: 2.114419937133789
Validation loss: 1.9177712009799095

Epoch: 238| Step: 0
Training loss: 1.6458019018173218
Validation loss: 1.9408129748477732

Epoch: 6| Step: 1
Training loss: 1.0646095275878906
Validation loss: 1.913627274574772

Epoch: 6| Step: 2
Training loss: 1.313486099243164
Validation loss: 1.9217018606842204

Epoch: 6| Step: 3
Training loss: 1.0306739807128906
Validation loss: 1.9067553961148827

Epoch: 6| Step: 4
Training loss: 1.6640636920928955
Validation loss: 1.9161885938336771

Epoch: 6| Step: 5
Training loss: 1.1194342374801636
Validation loss: 1.9134093946026218

Epoch: 6| Step: 6
Training loss: 1.2696083784103394
Validation loss: 1.93396419607183

Epoch: 6| Step: 7
Training loss: 1.3521584272384644
Validation loss: 1.946229778310304

Epoch: 6| Step: 8
Training loss: 1.3066024780273438
Validation loss: 1.925505950886716

Epoch: 6| Step: 9
Training loss: 1.5178117752075195
Validation loss: 1.9053666207098192

Epoch: 6| Step: 10
Training loss: 1.2851028442382812
Validation loss: 1.9351790451234387

Epoch: 6| Step: 11
Training loss: 2.0612900257110596
Validation loss: 1.9365519477475075

Epoch: 6| Step: 12
Training loss: 0.9336632490158081
Validation loss: 1.9298940550896428

Epoch: 6| Step: 13
Training loss: 1.7308757305145264
Validation loss: 1.8872681933064615

Epoch: 239| Step: 0
Training loss: 1.5480782985687256
Validation loss: 1.8996029233419767

Epoch: 6| Step: 1
Training loss: 1.3310744762420654
Validation loss: 1.905623302664808

Epoch: 6| Step: 2
Training loss: 1.8484911918640137
Validation loss: 1.933491535084222

Epoch: 6| Step: 3
Training loss: 1.5395982265472412
Validation loss: 1.9376193618261686

Epoch: 6| Step: 4
Training loss: 2.095893383026123
Validation loss: 1.9448935037018151

Epoch: 6| Step: 5
Training loss: 0.7881730794906616
Validation loss: 1.9523417821494482

Epoch: 6| Step: 6
Training loss: 1.3045016527175903
Validation loss: 1.9411128567111107

Epoch: 6| Step: 7
Training loss: 1.0544095039367676
Validation loss: 1.9379791713530017

Epoch: 6| Step: 8
Training loss: 0.8087005019187927
Validation loss: 1.9518906224158503

Epoch: 6| Step: 9
Training loss: 1.5074710845947266
Validation loss: 1.9397759924652755

Epoch: 6| Step: 10
Training loss: 1.3782329559326172
Validation loss: 1.934093362541609

Epoch: 6| Step: 11
Training loss: 1.1300175189971924
Validation loss: 1.9314642337060743

Epoch: 6| Step: 12
Training loss: 1.2576425075531006
Validation loss: 1.909553757277868

Epoch: 6| Step: 13
Training loss: 1.5912295579910278
Validation loss: 1.898204807312258

Epoch: 240| Step: 0
Training loss: 1.2292118072509766
Validation loss: 1.8931153205133253

Epoch: 6| Step: 1
Training loss: 1.6933199167251587
Validation loss: 1.8975601888472033

Epoch: 6| Step: 2
Training loss: 1.973250150680542
Validation loss: 1.9135903966042302

Epoch: 6| Step: 3
Training loss: 1.2106056213378906
Validation loss: 1.9099459801950762

Epoch: 6| Step: 4
Training loss: 1.4662644863128662
Validation loss: 1.9035811834437872

Epoch: 6| Step: 5
Training loss: 1.1458497047424316
Validation loss: 1.896921552637572

Epoch: 6| Step: 6
Training loss: 1.5137600898742676
Validation loss: 1.9044930409359675

Epoch: 6| Step: 7
Training loss: 1.2411777973175049
Validation loss: 1.8986951920293993

Epoch: 6| Step: 8
Training loss: 0.775067925453186
Validation loss: 1.9151032893888411

Epoch: 6| Step: 9
Training loss: 1.136962890625
Validation loss: 1.92798581687353

Epoch: 6| Step: 10
Training loss: 1.2165868282318115
Validation loss: 1.9468934446252801

Epoch: 6| Step: 11
Training loss: 1.430153250694275
Validation loss: 1.9344802325771702

Epoch: 6| Step: 12
Training loss: 1.3678804636001587
Validation loss: 1.9444666806087698

Epoch: 6| Step: 13
Training loss: 1.285784125328064
Validation loss: 1.933251210438308

Epoch: 241| Step: 0
Training loss: 1.2297451496124268
Validation loss: 1.9518332494202482

Epoch: 6| Step: 1
Training loss: 1.3184289932250977
Validation loss: 1.9316368577300862

Epoch: 6| Step: 2
Training loss: 1.6278517246246338
Validation loss: 1.9399417677233297

Epoch: 6| Step: 3
Training loss: 0.7054823637008667
Validation loss: 1.8939356932076075

Epoch: 6| Step: 4
Training loss: 1.412750244140625
Validation loss: 1.878025467677783

Epoch: 6| Step: 5
Training loss: 1.0333632230758667
Validation loss: 1.8828560126725065

Epoch: 6| Step: 6
Training loss: 0.9053016901016235
Validation loss: 1.8894913132472704

Epoch: 6| Step: 7
Training loss: 1.4672378301620483
Validation loss: 1.884587308411957

Epoch: 6| Step: 8
Training loss: 1.7546669244766235
Validation loss: 1.889113490299512

Epoch: 6| Step: 9
Training loss: 0.7630141973495483
Validation loss: 1.8913430180600894

Epoch: 6| Step: 10
Training loss: 1.6088674068450928
Validation loss: 1.902960628591558

Epoch: 6| Step: 11
Training loss: 1.3949849605560303
Validation loss: 1.8980419956227785

Epoch: 6| Step: 12
Training loss: 1.8599853515625
Validation loss: 1.8982163859951882

Epoch: 6| Step: 13
Training loss: 1.5648666620254517
Validation loss: 1.8789449737917991

Epoch: 242| Step: 0
Training loss: 0.8053631782531738
Validation loss: 1.911219294353198

Epoch: 6| Step: 1
Training loss: 1.8593363761901855
Validation loss: 1.9225345478262952

Epoch: 6| Step: 2
Training loss: 1.6357853412628174
Validation loss: 1.931394132234717

Epoch: 6| Step: 3
Training loss: 1.4312889575958252
Validation loss: 1.9537410389992498

Epoch: 6| Step: 4
Training loss: 1.0129292011260986
Validation loss: 1.9536631363694386

Epoch: 6| Step: 5
Training loss: 1.4045320749282837
Validation loss: 1.9665278798790389

Epoch: 6| Step: 6
Training loss: 0.6361066102981567
Validation loss: 1.942661795564877

Epoch: 6| Step: 7
Training loss: 1.8029884099960327
Validation loss: 1.9317662151910926

Epoch: 6| Step: 8
Training loss: 1.7902971506118774
Validation loss: 1.9200613293596493

Epoch: 6| Step: 9
Training loss: 1.2187438011169434
Validation loss: 1.8935000845181045

Epoch: 6| Step: 10
Training loss: 0.9714946746826172
Validation loss: 1.8943866606681579

Epoch: 6| Step: 11
Training loss: 1.100442886352539
Validation loss: 1.8842341515325731

Epoch: 6| Step: 12
Training loss: 1.7388694286346436
Validation loss: 1.8811850727245372

Epoch: 6| Step: 13
Training loss: 0.7021927833557129
Validation loss: 1.8785706104770783

Epoch: 243| Step: 0
Training loss: 1.1043198108673096
Validation loss: 1.8970104571311706

Epoch: 6| Step: 1
Training loss: 0.8014746904373169
Validation loss: 1.8973064909699142

Epoch: 6| Step: 2
Training loss: 1.0501773357391357
Validation loss: 1.912196877182171

Epoch: 6| Step: 3
Training loss: 1.1893123388290405
Validation loss: 1.921311737388693

Epoch: 6| Step: 4
Training loss: 1.4722696542739868
Validation loss: 1.931334287889542

Epoch: 6| Step: 5
Training loss: 1.235560417175293
Validation loss: 1.913932559310749

Epoch: 6| Step: 6
Training loss: 1.4873592853546143
Validation loss: 1.932082922227921

Epoch: 6| Step: 7
Training loss: 1.1116676330566406
Validation loss: 1.9219422699302755

Epoch: 6| Step: 8
Training loss: 1.8895835876464844
Validation loss: 1.922884056645055

Epoch: 6| Step: 9
Training loss: 1.3779373168945312
Validation loss: 1.9242887958403556

Epoch: 6| Step: 10
Training loss: 1.9478108882904053
Validation loss: 1.9354160088364796

Epoch: 6| Step: 11
Training loss: 1.5524141788482666
Validation loss: 1.915110549619121

Epoch: 6| Step: 12
Training loss: 0.8283157348632812
Validation loss: 1.9059944152832031

Epoch: 6| Step: 13
Training loss: 0.9522068500518799
Validation loss: 1.9167467919729089

Epoch: 244| Step: 0
Training loss: 1.6976755857467651
Validation loss: 1.9168855849132742

Epoch: 6| Step: 1
Training loss: 0.8012005090713501
Validation loss: 1.908678393210134

Epoch: 6| Step: 2
Training loss: 1.4585543870925903
Validation loss: 1.913431667512463

Epoch: 6| Step: 3
Training loss: 1.0057162046432495
Validation loss: 1.8925949860644597

Epoch: 6| Step: 4
Training loss: 0.8191123008728027
Validation loss: 1.910534530557612

Epoch: 6| Step: 5
Training loss: 0.9304341673851013
Validation loss: 1.8990423628078994

Epoch: 6| Step: 6
Training loss: 1.696580410003662
Validation loss: 1.905805173740592

Epoch: 6| Step: 7
Training loss: 0.8767354488372803
Validation loss: 1.947365842839723

Epoch: 6| Step: 8
Training loss: 1.9031301736831665
Validation loss: 1.9368343199453046

Epoch: 6| Step: 9
Training loss: 1.6729003190994263
Validation loss: 1.9256471869766072

Epoch: 6| Step: 10
Training loss: 1.3773601055145264
Validation loss: 1.9028512547093053

Epoch: 6| Step: 11
Training loss: 1.4707837104797363
Validation loss: 1.9254758011910222

Epoch: 6| Step: 12
Training loss: 1.464566946029663
Validation loss: 1.9290039077881844

Epoch: 6| Step: 13
Training loss: 1.4864039421081543
Validation loss: 1.9172429089905114

Epoch: 245| Step: 0
Training loss: 1.4958031177520752
Validation loss: 1.916450910670783

Epoch: 6| Step: 1
Training loss: 1.3108570575714111
Validation loss: 1.9156561410555275

Epoch: 6| Step: 2
Training loss: 1.5600345134735107
Validation loss: 1.928864981538506

Epoch: 6| Step: 3
Training loss: 1.3788032531738281
Validation loss: 1.9441445617265598

Epoch: 6| Step: 4
Training loss: 1.2019621133804321
Validation loss: 1.9243315650570778

Epoch: 6| Step: 5
Training loss: 1.2102108001708984
Validation loss: 1.8871995454193444

Epoch: 6| Step: 6
Training loss: 0.9912359714508057
Validation loss: 1.9083769347078057

Epoch: 6| Step: 7
Training loss: 1.7037736177444458
Validation loss: 1.8787725984409291

Epoch: 6| Step: 8
Training loss: 1.2238576412200928
Validation loss: 1.9040105701774679

Epoch: 6| Step: 9
Training loss: 1.4302849769592285
Validation loss: 1.897218946487673

Epoch: 6| Step: 10
Training loss: 1.0924296379089355
Validation loss: 1.8858208502492597

Epoch: 6| Step: 11
Training loss: 1.532706618309021
Validation loss: 1.8905358737514866

Epoch: 6| Step: 12
Training loss: 0.9849672317504883
Validation loss: 1.895973797767393

Epoch: 6| Step: 13
Training loss: 1.0377521514892578
Validation loss: 1.8969692119988062

Epoch: 246| Step: 0
Training loss: 0.9252883195877075
Validation loss: 1.9092281133897844

Epoch: 6| Step: 1
Training loss: 0.8688974976539612
Validation loss: 1.9282290743243309

Epoch: 6| Step: 2
Training loss: 1.1605894565582275
Validation loss: 1.9341435368343065

Epoch: 6| Step: 3
Training loss: 0.9198218584060669
Validation loss: 1.9319971005121868

Epoch: 6| Step: 4
Training loss: 1.7230277061462402
Validation loss: 1.9335135106117494

Epoch: 6| Step: 5
Training loss: 1.34450364112854
Validation loss: 1.959413856588384

Epoch: 6| Step: 6
Training loss: 1.1568183898925781
Validation loss: 1.944538467673845

Epoch: 6| Step: 7
Training loss: 1.495309591293335
Validation loss: 1.923746710182518

Epoch: 6| Step: 8
Training loss: 1.233962059020996
Validation loss: 1.9037392959799817

Epoch: 6| Step: 9
Training loss: 0.9164752960205078
Validation loss: 1.895301761165742

Epoch: 6| Step: 10
Training loss: 1.2249749898910522
Validation loss: 1.8784887611225087

Epoch: 6| Step: 11
Training loss: 2.074518918991089
Validation loss: 1.877389257954013

Epoch: 6| Step: 12
Training loss: 1.45130455493927
Validation loss: 1.8770681388916508

Epoch: 6| Step: 13
Training loss: 1.4768766164779663
Validation loss: 1.9000733539622316

Epoch: 247| Step: 0
Training loss: 0.8166012763977051
Validation loss: 1.911663072083586

Epoch: 6| Step: 1
Training loss: 1.4139513969421387
Validation loss: 1.9289255103757303

Epoch: 6| Step: 2
Training loss: 1.0886310338974
Validation loss: 1.9199354135861961

Epoch: 6| Step: 3
Training loss: 1.07575523853302
Validation loss: 1.9328764330956243

Epoch: 6| Step: 4
Training loss: 1.1350898742675781
Validation loss: 1.9254205598626086

Epoch: 6| Step: 5
Training loss: 1.3382229804992676
Validation loss: 1.9299654345358572

Epoch: 6| Step: 6
Training loss: 1.6428093910217285
Validation loss: 1.9153206989329348

Epoch: 6| Step: 7
Training loss: 1.6814649105072021
Validation loss: 1.9023052389903734

Epoch: 6| Step: 8
Training loss: 1.403132677078247
Validation loss: 1.9080449637546335

Epoch: 6| Step: 9
Training loss: 1.9050945043563843
Validation loss: 1.918560811268386

Epoch: 6| Step: 10
Training loss: 0.9587122201919556
Validation loss: 1.9249522480913388

Epoch: 6| Step: 11
Training loss: 0.9889864325523376
Validation loss: 1.9070830216971777

Epoch: 6| Step: 12
Training loss: 1.2346292734146118
Validation loss: 1.8840755621592205

Epoch: 6| Step: 13
Training loss: 1.1081267595291138
Validation loss: 1.8770059526607554

Epoch: 248| Step: 0
Training loss: 1.324439287185669
Validation loss: 1.8846063652346212

Epoch: 6| Step: 1
Training loss: 1.025769591331482
Validation loss: 1.8644723251301756

Epoch: 6| Step: 2
Training loss: 1.2036123275756836
Validation loss: 1.872372111966533

Epoch: 6| Step: 3
Training loss: 1.32080078125
Validation loss: 1.8843757003866217

Epoch: 6| Step: 4
Training loss: 1.5864276885986328
Validation loss: 1.8972207397542975

Epoch: 6| Step: 5
Training loss: 1.2750624418258667
Validation loss: 1.9121064319405505

Epoch: 6| Step: 6
Training loss: 1.7741591930389404
Validation loss: 1.9203305910992365

Epoch: 6| Step: 7
Training loss: 0.44726479053497314
Validation loss: 1.9127130828877932

Epoch: 6| Step: 8
Training loss: 0.8126810789108276
Validation loss: 1.9556399942726217

Epoch: 6| Step: 9
Training loss: 1.009056568145752
Validation loss: 1.945060960708126

Epoch: 6| Step: 10
Training loss: 1.234764575958252
Validation loss: 1.9178900693052559

Epoch: 6| Step: 11
Training loss: 1.786095142364502
Validation loss: 1.9374370151950466

Epoch: 6| Step: 12
Training loss: 1.4242076873779297
Validation loss: 1.9363703202175837

Epoch: 6| Step: 13
Training loss: 1.8264204263687134
Validation loss: 1.942646909785527

Epoch: 249| Step: 0
Training loss: 1.2571964263916016
Validation loss: 1.9045125028138519

Epoch: 6| Step: 1
Training loss: 1.7078194618225098
Validation loss: 1.8806666020424134

Epoch: 6| Step: 2
Training loss: 1.1455358266830444
Validation loss: 1.9179413369906846

Epoch: 6| Step: 3
Training loss: 1.9183118343353271
Validation loss: 1.9290719775743381

Epoch: 6| Step: 4
Training loss: 1.9151300191879272
Validation loss: 1.9595437588230256

Epoch: 6| Step: 5
Training loss: 1.3893989324569702
Validation loss: 1.9105714290372786

Epoch: 6| Step: 6
Training loss: 1.013535737991333
Validation loss: 1.9010664519443308

Epoch: 6| Step: 7
Training loss: 0.8803519010543823
Validation loss: 1.8723830753757107

Epoch: 6| Step: 8
Training loss: 1.1477293968200684
Validation loss: 1.891093679653701

Epoch: 6| Step: 9
Training loss: 1.260019063949585
Validation loss: 1.897961878007458

Epoch: 6| Step: 10
Training loss: 1.0808113813400269
Validation loss: 1.9367796323632682

Epoch: 6| Step: 11
Training loss: 0.5678703784942627
Validation loss: 1.9392859551214403

Epoch: 6| Step: 12
Training loss: 1.4231679439544678
Validation loss: 1.9395944687627977

Epoch: 6| Step: 13
Training loss: 1.125290036201477
Validation loss: 1.943519538448703

Epoch: 250| Step: 0
Training loss: 1.0042717456817627
Validation loss: 1.941018355790005

Epoch: 6| Step: 1
Training loss: 1.1913871765136719
Validation loss: 1.9224103599466302

Epoch: 6| Step: 2
Training loss: 1.6571671962738037
Validation loss: 1.9441349301286923

Epoch: 6| Step: 3
Training loss: 1.143548846244812
Validation loss: 1.9603223467385897

Epoch: 6| Step: 4
Training loss: 1.411226749420166
Validation loss: 1.9339384430198259

Epoch: 6| Step: 5
Training loss: 1.1873152256011963
Validation loss: 1.9317163780171385

Epoch: 6| Step: 6
Training loss: 0.9411188960075378
Validation loss: 1.9285682965350408

Epoch: 6| Step: 7
Training loss: 1.3371981382369995
Validation loss: 1.899436055973012

Epoch: 6| Step: 8
Training loss: 1.090813159942627
Validation loss: 1.887898297720058

Epoch: 6| Step: 9
Training loss: 1.8161370754241943
Validation loss: 1.8914067655481317

Epoch: 6| Step: 10
Training loss: 0.6692639589309692
Validation loss: 1.8704320461519304

Epoch: 6| Step: 11
Training loss: 1.065358281135559
Validation loss: 1.8792880094179543

Epoch: 6| Step: 12
Training loss: 1.0647252798080444
Validation loss: 1.868684539230921

Epoch: 6| Step: 13
Training loss: 2.157562732696533
Validation loss: 1.8488278337704238

Epoch: 251| Step: 0
Training loss: 0.5929785966873169
Validation loss: 1.8628583672226116

Epoch: 6| Step: 1
Training loss: 0.8418346047401428
Validation loss: 1.8670555712074361

Epoch: 6| Step: 2
Training loss: 1.0693180561065674
Validation loss: 1.8795819987532913

Epoch: 6| Step: 3
Training loss: 1.0737115144729614
Validation loss: 1.881135973879086

Epoch: 6| Step: 4
Training loss: 1.3270529508590698
Validation loss: 1.8972872034195931

Epoch: 6| Step: 5
Training loss: 1.2551137208938599
Validation loss: 1.8809621257166709

Epoch: 6| Step: 6
Training loss: 1.0291093587875366
Validation loss: 1.8938363226511146

Epoch: 6| Step: 7
Training loss: 0.8809489011764526
Validation loss: 1.9050103079888128

Epoch: 6| Step: 8
Training loss: 1.1609179973602295
Validation loss: 1.9039255098630024

Epoch: 6| Step: 9
Training loss: 2.2599596977233887
Validation loss: 1.9183219132884857

Epoch: 6| Step: 10
Training loss: 1.9273145198822021
Validation loss: 1.9276194700630762

Epoch: 6| Step: 11
Training loss: 1.1824840307235718
Validation loss: 1.886021198764924

Epoch: 6| Step: 12
Training loss: 1.3557655811309814
Validation loss: 1.9121909038994902

Epoch: 6| Step: 13
Training loss: 1.0842440128326416
Validation loss: 1.9113914928128641

Epoch: 252| Step: 0
Training loss: 1.5564384460449219
Validation loss: 1.8986366577045892

Epoch: 6| Step: 1
Training loss: 1.47395920753479
Validation loss: 1.88048933141975

Epoch: 6| Step: 2
Training loss: 1.3050510883331299
Validation loss: 1.8829580468516196

Epoch: 6| Step: 3
Training loss: 0.9512319564819336
Validation loss: 1.8697231431161203

Epoch: 6| Step: 4
Training loss: 0.8656414151191711
Validation loss: 1.8801277093989874

Epoch: 6| Step: 5
Training loss: 0.9995409846305847
Validation loss: 1.8965662653728197

Epoch: 6| Step: 6
Training loss: 0.8954486846923828
Validation loss: 1.8940512877638622

Epoch: 6| Step: 7
Training loss: 1.4434587955474854
Validation loss: 1.9013528490579257

Epoch: 6| Step: 8
Training loss: 1.4704874753952026
Validation loss: 1.9046108825232393

Epoch: 6| Step: 9
Training loss: 1.5569263696670532
Validation loss: 1.8883545937076691

Epoch: 6| Step: 10
Training loss: 1.6825387477874756
Validation loss: 1.8712663240330194

Epoch: 6| Step: 11
Training loss: 0.6270711421966553
Validation loss: 1.8719564907012447

Epoch: 6| Step: 12
Training loss: 1.3887197971343994
Validation loss: 1.8957450364225654

Epoch: 6| Step: 13
Training loss: 1.270000696182251
Validation loss: 1.8742217786850468

Epoch: 253| Step: 0
Training loss: 1.006606101989746
Validation loss: 1.864808654272428

Epoch: 6| Step: 1
Training loss: 1.461700439453125
Validation loss: 1.8818858182558449

Epoch: 6| Step: 2
Training loss: 0.881532609462738
Validation loss: 1.8771772538461993

Epoch: 6| Step: 3
Training loss: 1.421082615852356
Validation loss: 1.876600189875531

Epoch: 6| Step: 4
Training loss: 1.590561032295227
Validation loss: 1.8880545580258934

Epoch: 6| Step: 5
Training loss: 1.1360726356506348
Validation loss: 1.8804858076956965

Epoch: 6| Step: 6
Training loss: 0.6382570862770081
Validation loss: 1.8672177125048894

Epoch: 6| Step: 7
Training loss: 1.4296287298202515
Validation loss: 1.8613057328808693

Epoch: 6| Step: 8
Training loss: 1.7462345361709595
Validation loss: 1.8449401394013436

Epoch: 6| Step: 9
Training loss: 0.9323738217353821
Validation loss: 1.86519451807904

Epoch: 6| Step: 10
Training loss: 1.1417629718780518
Validation loss: 1.862441139836465

Epoch: 6| Step: 11
Training loss: 1.3868563175201416
Validation loss: 1.8797437888319775

Epoch: 6| Step: 12
Training loss: 0.9173759818077087
Validation loss: 1.8687462627246816

Epoch: 6| Step: 13
Training loss: 1.3639795780181885
Validation loss: 1.8714142871159378

Epoch: 254| Step: 0
Training loss: 1.4590481519699097
Validation loss: 1.8712908862739481

Epoch: 6| Step: 1
Training loss: 1.2040330171585083
Validation loss: 1.8690918466096282

Epoch: 6| Step: 2
Training loss: 1.2307665348052979
Validation loss: 1.8927822907765706

Epoch: 6| Step: 3
Training loss: 1.280429482460022
Validation loss: 1.9153937139818746

Epoch: 6| Step: 4
Training loss: 0.914800763130188
Validation loss: 1.907771054134574

Epoch: 6| Step: 5
Training loss: 1.2010266780853271
Validation loss: 1.9172990834841164

Epoch: 6| Step: 6
Training loss: 1.4061927795410156
Validation loss: 1.929588161489015

Epoch: 6| Step: 7
Training loss: 0.728569507598877
Validation loss: 1.934378594480535

Epoch: 6| Step: 8
Training loss: 1.1298036575317383
Validation loss: 1.9087679975776262

Epoch: 6| Step: 9
Training loss: 1.265412449836731
Validation loss: 1.8893508988042031

Epoch: 6| Step: 10
Training loss: 1.3927061557769775
Validation loss: 1.8839550287492814

Epoch: 6| Step: 11
Training loss: 0.8353397250175476
Validation loss: 1.8764790770828084

Epoch: 6| Step: 12
Training loss: 1.634810447692871
Validation loss: 1.8566254518365348

Epoch: 6| Step: 13
Training loss: 0.9149087071418762
Validation loss: 1.8499517158795429

Epoch: 255| Step: 0
Training loss: 1.2933800220489502
Validation loss: 1.8477605953011462

Epoch: 6| Step: 1
Training loss: 1.3451192378997803
Validation loss: 1.8539242488081737

Epoch: 6| Step: 2
Training loss: 1.2023513317108154
Validation loss: 1.867883728396508

Epoch: 6| Step: 3
Training loss: 1.10359787940979
Validation loss: 1.8965911070505779

Epoch: 6| Step: 4
Training loss: 1.4617013931274414
Validation loss: 1.8889212185336697

Epoch: 6| Step: 5
Training loss: 1.0504802465438843
Validation loss: 1.8906389385141351

Epoch: 6| Step: 6
Training loss: 1.5366432666778564
Validation loss: 1.8740664938444733

Epoch: 6| Step: 7
Training loss: 1.0747637748718262
Validation loss: 1.8750305996146253

Epoch: 6| Step: 8
Training loss: 0.4927518963813782
Validation loss: 1.8763598165204447

Epoch: 6| Step: 9
Training loss: 1.2037580013275146
Validation loss: 1.8632735154962028

Epoch: 6| Step: 10
Training loss: 1.2075085639953613
Validation loss: 1.8881208383908836

Epoch: 6| Step: 11
Training loss: 1.7943556308746338
Validation loss: 1.8700208112757692

Epoch: 6| Step: 12
Training loss: 0.8124867081642151
Validation loss: 1.8686717812732985

Epoch: 6| Step: 13
Training loss: 0.9779217839241028
Validation loss: 1.870232339828245

Epoch: 256| Step: 0
Training loss: 1.2418272495269775
Validation loss: 1.8772768102666384

Epoch: 6| Step: 1
Training loss: 0.9147322177886963
Validation loss: 1.9079902146452217

Epoch: 6| Step: 2
Training loss: 1.510284662246704
Validation loss: 1.925737375854164

Epoch: 6| Step: 3
Training loss: 0.399569571018219
Validation loss: 1.928159208707912

Epoch: 6| Step: 4
Training loss: 1.3441011905670166
Validation loss: 1.8951391071401618

Epoch: 6| Step: 5
Training loss: 1.495528221130371
Validation loss: 1.8853162898812243

Epoch: 6| Step: 6
Training loss: 1.4845225811004639
Validation loss: 1.8629581056615359

Epoch: 6| Step: 7
Training loss: 0.8022240400314331
Validation loss: 1.8538892435771164

Epoch: 6| Step: 8
Training loss: 0.9598791599273682
Validation loss: 1.8437711878489422

Epoch: 6| Step: 9
Training loss: 1.3024400472640991
Validation loss: 1.8308098828920754

Epoch: 6| Step: 10
Training loss: 1.1114031076431274
Validation loss: 1.8254411951188119

Epoch: 6| Step: 11
Training loss: 1.2542272806167603
Validation loss: 1.8184390350054669

Epoch: 6| Step: 12
Training loss: 1.5632359981536865
Validation loss: 1.8128051565539451

Epoch: 6| Step: 13
Training loss: 0.8435035943984985
Validation loss: 1.8240190065035256

Epoch: 257| Step: 0
Training loss: 1.0000289678573608
Validation loss: 1.8076086890312932

Epoch: 6| Step: 1
Training loss: 1.5614527463912964
Validation loss: 1.8287436141762683

Epoch: 6| Step: 2
Training loss: 1.5127151012420654
Validation loss: 1.8280851571790633

Epoch: 6| Step: 3
Training loss: 1.1505722999572754
Validation loss: 1.8357432965309388

Epoch: 6| Step: 4
Training loss: 1.4005601406097412
Validation loss: 1.8347611709307599

Epoch: 6| Step: 5
Training loss: 0.9218299388885498
Validation loss: 1.8530238764260405

Epoch: 6| Step: 6
Training loss: 1.0627351999282837
Validation loss: 1.91017202279901

Epoch: 6| Step: 7
Training loss: 1.4475855827331543
Validation loss: 1.9301038890756586

Epoch: 6| Step: 8
Training loss: 0.7790218591690063
Validation loss: 1.9519506615977134

Epoch: 6| Step: 9
Training loss: 1.2881839275360107
Validation loss: 2.005086423248373

Epoch: 6| Step: 10
Training loss: 1.3314573764801025
Validation loss: 1.9733568699129167

Epoch: 6| Step: 11
Training loss: 1.1353758573532104
Validation loss: 1.9439318333902667

Epoch: 6| Step: 12
Training loss: 0.8810209631919861
Validation loss: 1.965059413704821

Epoch: 6| Step: 13
Training loss: 1.4949002265930176
Validation loss: 1.9666060914275467

Epoch: 258| Step: 0
Training loss: 1.3896074295043945
Validation loss: 1.9677935761790122

Epoch: 6| Step: 1
Training loss: 1.1894828081130981
Validation loss: 1.979686096150388

Epoch: 6| Step: 2
Training loss: 1.7020114660263062
Validation loss: 1.9464782309788529

Epoch: 6| Step: 3
Training loss: 0.9783146977424622
Validation loss: 1.8848643918191232

Epoch: 6| Step: 4
Training loss: 1.4929641485214233
Validation loss: 1.8587724560050554

Epoch: 6| Step: 5
Training loss: 0.8574040532112122
Validation loss: 1.8923012710386706

Epoch: 6| Step: 6
Training loss: 1.4169411659240723
Validation loss: 1.8666926891573015

Epoch: 6| Step: 7
Training loss: 1.2536866664886475
Validation loss: 1.884582870750017

Epoch: 6| Step: 8
Training loss: 1.4982393980026245
Validation loss: 1.8894841940172258

Epoch: 6| Step: 9
Training loss: 1.209695816040039
Validation loss: 1.880000328504911

Epoch: 6| Step: 10
Training loss: 1.2226234674453735
Validation loss: 1.8686113242180116

Epoch: 6| Step: 11
Training loss: 0.9021037817001343
Validation loss: 1.8802903506063646

Epoch: 6| Step: 12
Training loss: 0.692833423614502
Validation loss: 1.882195315053386

Epoch: 6| Step: 13
Training loss: 1.3433313369750977
Validation loss: 1.884661313026182

Epoch: 259| Step: 0
Training loss: 1.259123682975769
Validation loss: 1.8893265660091112

Epoch: 6| Step: 1
Training loss: 1.0418565273284912
Validation loss: 1.9092820613614974

Epoch: 6| Step: 2
Training loss: 1.0106905698776245
Validation loss: 1.890907331179547

Epoch: 6| Step: 3
Training loss: 1.2599272727966309
Validation loss: 1.921478025374874

Epoch: 6| Step: 4
Training loss: 1.5577608346939087
Validation loss: 1.946680945734824

Epoch: 6| Step: 5
Training loss: 0.9427745342254639
Validation loss: 1.9509746361804265

Epoch: 6| Step: 6
Training loss: 1.450331687927246
Validation loss: 1.9251344691040695

Epoch: 6| Step: 7
Training loss: 1.3651589155197144
Validation loss: 1.9149971521028908

Epoch: 6| Step: 8
Training loss: 1.2837425470352173
Validation loss: 1.907732040651383

Epoch: 6| Step: 9
Training loss: 1.2041406631469727
Validation loss: 1.8949635233930362

Epoch: 6| Step: 10
Training loss: 0.7853186130523682
Validation loss: 1.8899205987171461

Epoch: 6| Step: 11
Training loss: 0.4986397624015808
Validation loss: 1.8874470662045222

Epoch: 6| Step: 12
Training loss: 1.4986814260482788
Validation loss: 1.870581373091667

Epoch: 6| Step: 13
Training loss: 1.3241069316864014
Validation loss: 1.850308056800596

Epoch: 260| Step: 0
Training loss: 1.3189929723739624
Validation loss: 1.855025831089225

Epoch: 6| Step: 1
Training loss: 1.2247979640960693
Validation loss: 1.838239498035882

Epoch: 6| Step: 2
Training loss: 0.9124887585639954
Validation loss: 1.8445907074918029

Epoch: 6| Step: 3
Training loss: 0.7160717248916626
Validation loss: 1.8361553338266188

Epoch: 6| Step: 4
Training loss: 1.027616262435913
Validation loss: 1.8457883993784587

Epoch: 6| Step: 5
Training loss: 1.4100699424743652
Validation loss: 1.8498641444790749

Epoch: 6| Step: 6
Training loss: 1.5975703001022339
Validation loss: 1.8715049220669655

Epoch: 6| Step: 7
Training loss: 0.8985321521759033
Validation loss: 1.8875878805755286

Epoch: 6| Step: 8
Training loss: 1.2726199626922607
Validation loss: 1.901718080684703

Epoch: 6| Step: 9
Training loss: 1.3126084804534912
Validation loss: 1.9063213909825971

Epoch: 6| Step: 10
Training loss: 0.9794216752052307
Validation loss: 1.8949012589711014

Epoch: 6| Step: 11
Training loss: 1.1574039459228516
Validation loss: 1.9097112353130052

Epoch: 6| Step: 12
Training loss: 1.0604356527328491
Validation loss: 1.9093118611202444

Epoch: 6| Step: 13
Training loss: 1.097420573234558
Validation loss: 1.921033368315748

Epoch: 261| Step: 0
Training loss: 0.7926928400993347
Validation loss: 1.9417152033057263

Epoch: 6| Step: 1
Training loss: 0.9289819002151489
Validation loss: 1.9529623113652712

Epoch: 6| Step: 2
Training loss: 1.2914797067642212
Validation loss: 1.923750569743495

Epoch: 6| Step: 3
Training loss: 1.2276605367660522
Validation loss: 1.9304659533244308

Epoch: 6| Step: 4
Training loss: 1.0374202728271484
Validation loss: 1.8974860355418215

Epoch: 6| Step: 5
Training loss: 1.4619905948638916
Validation loss: 1.857418833240386

Epoch: 6| Step: 6
Training loss: 0.9306529760360718
Validation loss: 1.8614979456829768

Epoch: 6| Step: 7
Training loss: 1.1623942852020264
Validation loss: 1.8241029118978849

Epoch: 6| Step: 8
Training loss: 1.2093136310577393
Validation loss: 1.8242160556136922

Epoch: 6| Step: 9
Training loss: 1.2808666229248047
Validation loss: 1.8124939677535847

Epoch: 6| Step: 10
Training loss: 1.0087077617645264
Validation loss: 1.8098834317217591

Epoch: 6| Step: 11
Training loss: 1.8338956832885742
Validation loss: 1.8304726859574676

Epoch: 6| Step: 12
Training loss: 0.9618231654167175
Validation loss: 1.8258082200122137

Epoch: 6| Step: 13
Training loss: 0.8680477738380432
Validation loss: 1.8225038948879446

Epoch: 262| Step: 0
Training loss: 1.509234070777893
Validation loss: 1.8045870386144167

Epoch: 6| Step: 1
Training loss: 0.9725195169448853
Validation loss: 1.829884043303869

Epoch: 6| Step: 2
Training loss: 1.1344056129455566
Validation loss: 1.8437426833696262

Epoch: 6| Step: 3
Training loss: 0.8462649583816528
Validation loss: 1.879468289754724

Epoch: 6| Step: 4
Training loss: 0.927937388420105
Validation loss: 1.8917516328955208

Epoch: 6| Step: 5
Training loss: 1.13468337059021
Validation loss: 1.9127559520864998

Epoch: 6| Step: 6
Training loss: 1.1973230838775635
Validation loss: 1.9212374815376856

Epoch: 6| Step: 7
Training loss: 1.279893398284912
Validation loss: 1.9214312440605574

Epoch: 6| Step: 8
Training loss: 0.9975093603134155
Validation loss: 1.9155588303842852

Epoch: 6| Step: 9
Training loss: 0.7453421354293823
Validation loss: 1.8975787278144591

Epoch: 6| Step: 10
Training loss: 1.3587356805801392
Validation loss: 1.9010135717289423

Epoch: 6| Step: 11
Training loss: 1.6063284873962402
Validation loss: 1.8811351855595906

Epoch: 6| Step: 12
Training loss: 0.8828268051147461
Validation loss: 1.858857944447507

Epoch: 6| Step: 13
Training loss: 1.1179311275482178
Validation loss: 1.85024639227057

Epoch: 263| Step: 0
Training loss: 0.3269081711769104
Validation loss: 1.8573379772965626

Epoch: 6| Step: 1
Training loss: 0.9698644876480103
Validation loss: 1.8626194666790705

Epoch: 6| Step: 2
Training loss: 0.9527091979980469
Validation loss: 1.8628311080317344

Epoch: 6| Step: 3
Training loss: 0.6714744567871094
Validation loss: 1.874352583321192

Epoch: 6| Step: 4
Training loss: 0.7894167900085449
Validation loss: 1.8632355505420315

Epoch: 6| Step: 5
Training loss: 1.6159985065460205
Validation loss: 1.8690987453665784

Epoch: 6| Step: 6
Training loss: 1.4216229915618896
Validation loss: 1.8727573483220992

Epoch: 6| Step: 7
Training loss: 1.220527172088623
Validation loss: 1.8508528355629212

Epoch: 6| Step: 8
Training loss: 1.3944838047027588
Validation loss: 1.8526173906941568

Epoch: 6| Step: 9
Training loss: 1.0206563472747803
Validation loss: 1.848024897677924

Epoch: 6| Step: 10
Training loss: 1.23097825050354
Validation loss: 1.852401779543969

Epoch: 6| Step: 11
Training loss: 1.4991480112075806
Validation loss: 1.8810081840843282

Epoch: 6| Step: 12
Training loss: 1.2709910869598389
Validation loss: 1.853370032002849

Epoch: 6| Step: 13
Training loss: 0.8915725350379944
Validation loss: 1.8897603455410208

Epoch: 264| Step: 0
Training loss: 1.0757721662521362
Validation loss: 1.8769703270286642

Epoch: 6| Step: 1
Training loss: 0.9797430038452148
Validation loss: 1.8774235992021457

Epoch: 6| Step: 2
Training loss: 1.1607208251953125
Validation loss: 1.875003921088352

Epoch: 6| Step: 3
Training loss: 0.9399003982543945
Validation loss: 1.8869723735317108

Epoch: 6| Step: 4
Training loss: 1.296201229095459
Validation loss: 1.857010672169347

Epoch: 6| Step: 5
Training loss: 1.3023381233215332
Validation loss: 1.8454248110453289

Epoch: 6| Step: 6
Training loss: 0.8869812488555908
Validation loss: 1.8399934871222383

Epoch: 6| Step: 7
Training loss: 1.2166178226470947
Validation loss: 1.852292537689209

Epoch: 6| Step: 8
Training loss: 1.05623197555542
Validation loss: 1.84215711521846

Epoch: 6| Step: 9
Training loss: 1.1848502159118652
Validation loss: 1.8441787637690061

Epoch: 6| Step: 10
Training loss: 0.9302497506141663
Validation loss: 1.829781965542865

Epoch: 6| Step: 11
Training loss: 1.1388239860534668
Validation loss: 1.8333649942951817

Epoch: 6| Step: 12
Training loss: 1.257462739944458
Validation loss: 1.8240023966758483

Epoch: 6| Step: 13
Training loss: 0.8674874305725098
Validation loss: 1.8209710941519788

Epoch: 265| Step: 0
Training loss: 0.8735311031341553
Validation loss: 1.8244288121500323

Epoch: 6| Step: 1
Training loss: 1.2661573886871338
Validation loss: 1.83081191842274

Epoch: 6| Step: 2
Training loss: 0.8311766386032104
Validation loss: 1.8443055268256896

Epoch: 6| Step: 3
Training loss: 1.4979493618011475
Validation loss: 1.8345225908422982

Epoch: 6| Step: 4
Training loss: 1.2027230262756348
Validation loss: 1.8372407664534867

Epoch: 6| Step: 5
Training loss: 1.4347176551818848
Validation loss: 1.8640990436718028

Epoch: 6| Step: 6
Training loss: 0.9026839137077332
Validation loss: 1.8587401195238995

Epoch: 6| Step: 7
Training loss: 1.2039384841918945
Validation loss: 1.8504239320755005

Epoch: 6| Step: 8
Training loss: 0.6407756805419922
Validation loss: 1.8379905826301985

Epoch: 6| Step: 9
Training loss: 1.4047036170959473
Validation loss: 1.8627586800565001

Epoch: 6| Step: 10
Training loss: 0.6185389757156372
Validation loss: 1.8363112762410154

Epoch: 6| Step: 11
Training loss: 1.341965675354004
Validation loss: 1.8213103458445559

Epoch: 6| Step: 12
Training loss: 0.9493158459663391
Validation loss: 1.8284983327311854

Epoch: 6| Step: 13
Training loss: 1.0380017757415771
Validation loss: 1.8308733881160777

Epoch: 266| Step: 0
Training loss: 0.338358998298645
Validation loss: 1.8318460256822648

Epoch: 6| Step: 1
Training loss: 1.283790111541748
Validation loss: 1.8204728954581804

Epoch: 6| Step: 2
Training loss: 1.9730770587921143
Validation loss: 1.8300207020134054

Epoch: 6| Step: 3
Training loss: 1.1892045736312866
Validation loss: 1.835587078525174

Epoch: 6| Step: 4
Training loss: 1.1089346408843994
Validation loss: 1.838199197605092

Epoch: 6| Step: 5
Training loss: 1.3217792510986328
Validation loss: 1.8240777049013364

Epoch: 6| Step: 6
Training loss: 0.859966516494751
Validation loss: 1.8161667085463

Epoch: 6| Step: 7
Training loss: 0.7403837442398071
Validation loss: 1.8437831401824951

Epoch: 6| Step: 8
Training loss: 0.8991107940673828
Validation loss: 1.842156160262323

Epoch: 6| Step: 9
Training loss: 1.2242274284362793
Validation loss: 1.8490395597232285

Epoch: 6| Step: 10
Training loss: 1.2525646686553955
Validation loss: 1.8325545275083153

Epoch: 6| Step: 11
Training loss: 0.635045051574707
Validation loss: 1.8472292025883992

Epoch: 6| Step: 12
Training loss: 1.233649730682373
Validation loss: 1.8218282845712477

Epoch: 6| Step: 13
Training loss: 0.6688868999481201
Validation loss: 1.8172036114559378

Epoch: 267| Step: 0
Training loss: 0.6018136739730835
Validation loss: 1.8250306037164503

Epoch: 6| Step: 1
Training loss: 0.9145312309265137
Validation loss: 1.8319175243377686

Epoch: 6| Step: 2
Training loss: 1.0685083866119385
Validation loss: 1.8224216571418188

Epoch: 6| Step: 3
Training loss: 0.8923540711402893
Validation loss: 1.8330063896794473

Epoch: 6| Step: 4
Training loss: 0.657342791557312
Validation loss: 1.8464844419110207

Epoch: 6| Step: 5
Training loss: 1.384709119796753
Validation loss: 1.8321446167525424

Epoch: 6| Step: 6
Training loss: 1.0056822299957275
Validation loss: 1.8248861220575148

Epoch: 6| Step: 7
Training loss: 1.5355851650238037
Validation loss: 1.8357430683669222

Epoch: 6| Step: 8
Training loss: 0.8474392294883728
Validation loss: 1.8127320607503254

Epoch: 6| Step: 9
Training loss: 1.0977883338928223
Validation loss: 1.8247060570665585

Epoch: 6| Step: 10
Training loss: 1.4663559198379517
Validation loss: 1.8399151755917458

Epoch: 6| Step: 11
Training loss: 1.2462944984436035
Validation loss: 1.8641383981191983

Epoch: 6| Step: 12
Training loss: 1.126001238822937
Validation loss: 1.8719106457566703

Epoch: 6| Step: 13
Training loss: 1.2588534355163574
Validation loss: 1.899500411043885

Epoch: 268| Step: 0
Training loss: 1.2748329639434814
Validation loss: 1.8847836063754173

Epoch: 6| Step: 1
Training loss: 0.9103062152862549
Validation loss: 1.8872776659586097

Epoch: 6| Step: 2
Training loss: 1.1096073389053345
Validation loss: 1.8773743670473817

Epoch: 6| Step: 3
Training loss: 0.8403193354606628
Validation loss: 1.8726518500235774

Epoch: 6| Step: 4
Training loss: 1.5405548810958862
Validation loss: 1.8655591587866507

Epoch: 6| Step: 5
Training loss: 0.9617406129837036
Validation loss: 1.8594218018234416

Epoch: 6| Step: 6
Training loss: 1.1373350620269775
Validation loss: 1.8418022945363035

Epoch: 6| Step: 7
Training loss: 0.9749981164932251
Validation loss: 1.8456138410875875

Epoch: 6| Step: 8
Training loss: 0.9016851782798767
Validation loss: 1.842240305357082

Epoch: 6| Step: 9
Training loss: 0.9218963980674744
Validation loss: 1.815542172360164

Epoch: 6| Step: 10
Training loss: 1.1101104021072388
Validation loss: 1.796054784969617

Epoch: 6| Step: 11
Training loss: 0.91656893491745
Validation loss: 1.7774925924116565

Epoch: 6| Step: 12
Training loss: 1.0215957164764404
Validation loss: 1.8066287976439281

Epoch: 6| Step: 13
Training loss: 0.9760672450065613
Validation loss: 1.8104713257922922

Epoch: 269| Step: 0
Training loss: 1.2165367603302002
Validation loss: 1.8492786230579499

Epoch: 6| Step: 1
Training loss: 0.8639499545097351
Validation loss: 1.869208469185778

Epoch: 6| Step: 2
Training loss: 0.9584301710128784
Validation loss: 1.8819424670229676

Epoch: 6| Step: 3
Training loss: 1.0577812194824219
Validation loss: 1.9109214839114939

Epoch: 6| Step: 4
Training loss: 0.9858508706092834
Validation loss: 1.9172606993747014

Epoch: 6| Step: 5
Training loss: 1.0087721347808838
Validation loss: 1.9280412120203818

Epoch: 6| Step: 6
Training loss: 1.7093524932861328
Validation loss: 1.8952574601737402

Epoch: 6| Step: 7
Training loss: 0.8370450735092163
Validation loss: 1.8916943727001068

Epoch: 6| Step: 8
Training loss: 0.9494580626487732
Validation loss: 1.9031790289827573

Epoch: 6| Step: 9
Training loss: 1.3535981178283691
Validation loss: 1.8667299183466102

Epoch: 6| Step: 10
Training loss: 0.45703521370887756
Validation loss: 1.8568043478073613

Epoch: 6| Step: 11
Training loss: 1.2752652168273926
Validation loss: 1.84254547344741

Epoch: 6| Step: 12
Training loss: 0.8171462416648865
Validation loss: 1.8396483993017545

Epoch: 6| Step: 13
Training loss: 1.2786058187484741
Validation loss: 1.8187682320994716

Epoch: 270| Step: 0
Training loss: 1.2573014497756958
Validation loss: 1.8268785989412697

Epoch: 6| Step: 1
Training loss: 1.1948204040527344
Validation loss: 1.841719062097611

Epoch: 6| Step: 2
Training loss: 0.9411135911941528
Validation loss: 1.8373514375379008

Epoch: 6| Step: 3
Training loss: 0.5433162450790405
Validation loss: 1.8194422221952868

Epoch: 6| Step: 4
Training loss: 0.9057713150978088
Validation loss: 1.8308884123320222

Epoch: 6| Step: 5
Training loss: 0.5595071911811829
Validation loss: 1.8165748914082844

Epoch: 6| Step: 6
Training loss: 1.4594743251800537
Validation loss: 1.8210127859987237

Epoch: 6| Step: 7
Training loss: 0.8401216268539429
Validation loss: 1.825641127042873

Epoch: 6| Step: 8
Training loss: 1.5062025785446167
Validation loss: 1.8234019407662012

Epoch: 6| Step: 9
Training loss: 1.174539566040039
Validation loss: 1.8344961443255026

Epoch: 6| Step: 10
Training loss: 0.9567165970802307
Validation loss: 1.8416461329306326

Epoch: 6| Step: 11
Training loss: 0.9205664992332458
Validation loss: 1.837147290988635

Epoch: 6| Step: 12
Training loss: 0.5499460101127625
Validation loss: 1.840098040078276

Epoch: 6| Step: 13
Training loss: 1.6235861778259277
Validation loss: 1.8441880441481067

Epoch: 271| Step: 0
Training loss: 0.9273554682731628
Validation loss: 1.8228977713533627

Epoch: 6| Step: 1
Training loss: 1.1300649642944336
Validation loss: 1.8158515204665482

Epoch: 6| Step: 2
Training loss: 1.0498734712600708
Validation loss: 1.8092625679508332

Epoch: 6| Step: 3
Training loss: 1.1645411252975464
Validation loss: 1.8076085723856443

Epoch: 6| Step: 4
Training loss: 1.3088366985321045
Validation loss: 1.7996537121393348

Epoch: 6| Step: 5
Training loss: 1.0082204341888428
Validation loss: 1.8232601611844954

Epoch: 6| Step: 6
Training loss: 0.8808894157409668
Validation loss: 1.8258234506012292

Epoch: 6| Step: 7
Training loss: 0.5653783679008484
Validation loss: 1.8168488984466882

Epoch: 6| Step: 8
Training loss: 1.1207740306854248
Validation loss: 1.8149142919048187

Epoch: 6| Step: 9
Training loss: 1.2659214735031128
Validation loss: 1.8304352042495564

Epoch: 6| Step: 10
Training loss: 0.7779258489608765
Validation loss: 1.8592178526745047

Epoch: 6| Step: 11
Training loss: 1.2336702346801758
Validation loss: 1.852547150786205

Epoch: 6| Step: 12
Training loss: 0.746078372001648
Validation loss: 1.8564694261038175

Epoch: 6| Step: 13
Training loss: 0.47890669107437134
Validation loss: 1.852733358260124

Epoch: 272| Step: 0
Training loss: 0.9842047691345215
Validation loss: 1.844509942557222

Epoch: 6| Step: 1
Training loss: 0.8219103813171387
Validation loss: 1.8495179491658365

Epoch: 6| Step: 2
Training loss: 1.4629720449447632
Validation loss: 1.8500193293376634

Epoch: 6| Step: 3
Training loss: 0.8499887585639954
Validation loss: 1.8423252112121993

Epoch: 6| Step: 4
Training loss: 0.7524752616882324
Validation loss: 1.8349677452477076

Epoch: 6| Step: 5
Training loss: 0.8104403614997864
Validation loss: 1.8102332122864262

Epoch: 6| Step: 6
Training loss: 1.5253653526306152
Validation loss: 1.8114991546959005

Epoch: 6| Step: 7
Training loss: 0.7961731553077698
Validation loss: 1.8077559714676232

Epoch: 6| Step: 8
Training loss: 1.0178310871124268
Validation loss: 1.7786672025598504

Epoch: 6| Step: 9
Training loss: 1.1790978908538818
Validation loss: 1.7833821017255065

Epoch: 6| Step: 10
Training loss: 1.341416835784912
Validation loss: 1.7883491644295313

Epoch: 6| Step: 11
Training loss: 0.9252239465713501
Validation loss: 1.7964054576812252

Epoch: 6| Step: 12
Training loss: 0.9308091998100281
Validation loss: 1.820988033407478

Epoch: 6| Step: 13
Training loss: 0.9241628646850586
Validation loss: 1.8137793002590057

Epoch: 273| Step: 0
Training loss: 0.946386456489563
Validation loss: 1.8368279036655222

Epoch: 6| Step: 1
Training loss: 0.7828503251075745
Validation loss: 1.866103249211465

Epoch: 6| Step: 2
Training loss: 1.6196156740188599
Validation loss: 1.8732474298887356

Epoch: 6| Step: 3
Training loss: 0.8607543706893921
Validation loss: 1.876925386408324

Epoch: 6| Step: 4
Training loss: 0.9408647418022156
Validation loss: 1.8627964899104128

Epoch: 6| Step: 5
Training loss: 0.9574742317199707
Validation loss: 1.886064483273414

Epoch: 6| Step: 6
Training loss: 1.2726736068725586
Validation loss: 1.8459193706512451

Epoch: 6| Step: 7
Training loss: 0.8942289352416992
Validation loss: 1.8447527129163024

Epoch: 6| Step: 8
Training loss: 1.0344946384429932
Validation loss: 1.8137967560880928

Epoch: 6| Step: 9
Training loss: 0.37058743834495544
Validation loss: 1.831359209552888

Epoch: 6| Step: 10
Training loss: 1.0918266773223877
Validation loss: 1.8389029989960373

Epoch: 6| Step: 11
Training loss: 1.3752365112304688
Validation loss: 1.8409643327036211

Epoch: 6| Step: 12
Training loss: 0.6559513807296753
Validation loss: 1.8196263069747596

Epoch: 6| Step: 13
Training loss: 1.6461944580078125
Validation loss: 1.800103747716514

Epoch: 274| Step: 0
Training loss: 1.6374739408493042
Validation loss: 1.7947156044744677

Epoch: 6| Step: 1
Training loss: 0.7338712215423584
Validation loss: 1.806441166067636

Epoch: 6| Step: 2
Training loss: 1.118956208229065
Validation loss: 1.7952591834529754

Epoch: 6| Step: 3
Training loss: 1.0935512781143188
Validation loss: 1.8390462795893352

Epoch: 6| Step: 4
Training loss: 0.9615183472633362
Validation loss: 1.8327549657514017

Epoch: 6| Step: 5
Training loss: 1.007562518119812
Validation loss: 1.846696405000584

Epoch: 6| Step: 6
Training loss: 0.9647291302680969
Validation loss: 1.8498424394156343

Epoch: 6| Step: 7
Training loss: 0.6385528445243835
Validation loss: 1.8597777646075013

Epoch: 6| Step: 8
Training loss: 0.8985080718994141
Validation loss: 1.8477743646149993

Epoch: 6| Step: 9
Training loss: 1.1869220733642578
Validation loss: 1.8508511153600549

Epoch: 6| Step: 10
Training loss: 0.8223522305488586
Validation loss: 1.829676680667426

Epoch: 6| Step: 11
Training loss: 0.9216058850288391
Validation loss: 1.8497316670674149

Epoch: 6| Step: 12
Training loss: 1.3328046798706055
Validation loss: 1.8195972660536408

Epoch: 6| Step: 13
Training loss: 1.0185552835464478
Validation loss: 1.8001113989019906

Epoch: 275| Step: 0
Training loss: 0.8468915224075317
Validation loss: 1.7765795851266513

Epoch: 6| Step: 1
Training loss: 1.418331503868103
Validation loss: 1.7835661185685026

Epoch: 6| Step: 2
Training loss: 1.342803716659546
Validation loss: 1.7856903358172345

Epoch: 6| Step: 3
Training loss: 0.9989795684814453
Validation loss: 1.8108123181968607

Epoch: 6| Step: 4
Training loss: 1.2607691287994385
Validation loss: 1.8020993894146335

Epoch: 6| Step: 5
Training loss: 0.912905752658844
Validation loss: 1.8106221639981834

Epoch: 6| Step: 6
Training loss: 1.2895152568817139
Validation loss: 1.8270268158246112

Epoch: 6| Step: 7
Training loss: 1.284604787826538
Validation loss: 1.78218872316422

Epoch: 6| Step: 8
Training loss: 0.7267230749130249
Validation loss: 1.7837201536342662

Epoch: 6| Step: 9
Training loss: 0.47765323519706726
Validation loss: 1.7857017754226603

Epoch: 6| Step: 10
Training loss: 0.752596378326416
Validation loss: 1.8046942308384886

Epoch: 6| Step: 11
Training loss: 1.0614720582962036
Validation loss: 1.8045227476345596

Epoch: 6| Step: 12
Training loss: 1.041003942489624
Validation loss: 1.8291371496774818

Epoch: 6| Step: 13
Training loss: 0.3035939037799835
Validation loss: 1.82906820056259

Epoch: 276| Step: 0
Training loss: 1.6531099081039429
Validation loss: 1.8306878741069506

Epoch: 6| Step: 1
Training loss: 0.40627601742744446
Validation loss: 1.8305391547500447

Epoch: 6| Step: 2
Training loss: 1.1704926490783691
Validation loss: 1.8357780107887842

Epoch: 6| Step: 3
Training loss: 0.9018775224685669
Validation loss: 1.8360158794669694

Epoch: 6| Step: 4
Training loss: 1.3277182579040527
Validation loss: 1.8306861923586937

Epoch: 6| Step: 5
Training loss: 1.5293655395507812
Validation loss: 1.8332437725477322

Epoch: 6| Step: 6
Training loss: 1.1628170013427734
Validation loss: 1.8177609059118456

Epoch: 6| Step: 7
Training loss: 0.8350756168365479
Validation loss: 1.787796558872346

Epoch: 6| Step: 8
Training loss: 0.7019908428192139
Validation loss: 1.8068159562285229

Epoch: 6| Step: 9
Training loss: 0.7200909852981567
Validation loss: 1.8115210148595995

Epoch: 6| Step: 10
Training loss: 1.0974335670471191
Validation loss: 1.8083752867996052

Epoch: 6| Step: 11
Training loss: 0.7695062756538391
Validation loss: 1.7994588959601618

Epoch: 6| Step: 12
Training loss: 0.7965875864028931
Validation loss: 1.8232329442936888

Epoch: 6| Step: 13
Training loss: 0.414908766746521
Validation loss: 1.8164595711615779

Epoch: 277| Step: 0
Training loss: 1.2283165454864502
Validation loss: 1.838784510089505

Epoch: 6| Step: 1
Training loss: 1.2966718673706055
Validation loss: 1.8560669729786534

Epoch: 6| Step: 2
Training loss: 1.2949318885803223
Validation loss: 1.8641651330455657

Epoch: 6| Step: 3
Training loss: 0.42571622133255005
Validation loss: 1.8436481875758017

Epoch: 6| Step: 4
Training loss: 0.5394562482833862
Validation loss: 1.8417495207120014

Epoch: 6| Step: 5
Training loss: 1.0160553455352783
Validation loss: 1.8530676749444777

Epoch: 6| Step: 6
Training loss: 0.8708057403564453
Validation loss: 1.8519161196165188

Epoch: 6| Step: 7
Training loss: 1.4097073078155518
Validation loss: 1.8503629289647585

Epoch: 6| Step: 8
Training loss: 0.6995444297790527
Validation loss: 1.866074033962783

Epoch: 6| Step: 9
Training loss: 0.869148313999176
Validation loss: 1.8649669513907483

Epoch: 6| Step: 10
Training loss: 0.9183739423751831
Validation loss: 1.8467988865349882

Epoch: 6| Step: 11
Training loss: 1.150112509727478
Validation loss: 1.8347299701424056

Epoch: 6| Step: 12
Training loss: 0.631122350692749
Validation loss: 1.8346078318934287

Epoch: 6| Step: 13
Training loss: 1.1074084043502808
Validation loss: 1.816743448216428

Epoch: 278| Step: 0
Training loss: 0.8964623808860779
Validation loss: 1.8261003622444727

Epoch: 6| Step: 1
Training loss: 0.8460766077041626
Validation loss: 1.8136582861664474

Epoch: 6| Step: 2
Training loss: 0.5045710802078247
Validation loss: 1.840272613750991

Epoch: 6| Step: 3
Training loss: 0.7426533699035645
Validation loss: 1.8254770873695292

Epoch: 6| Step: 4
Training loss: 1.0480455160140991
Validation loss: 1.8146900976857832

Epoch: 6| Step: 5
Training loss: 0.8917609453201294
Validation loss: 1.802832975182482

Epoch: 6| Step: 6
Training loss: 1.0892083644866943
Validation loss: 1.806701946002181

Epoch: 6| Step: 7
Training loss: 0.8057918548583984
Validation loss: 1.8385210755050823

Epoch: 6| Step: 8
Training loss: 0.9741553068161011
Validation loss: 1.8581745932179112

Epoch: 6| Step: 9
Training loss: 1.122541904449463
Validation loss: 1.8458378263699111

Epoch: 6| Step: 10
Training loss: 1.1523789167404175
Validation loss: 1.8346721703006375

Epoch: 6| Step: 11
Training loss: 1.3845090866088867
Validation loss: 1.8704377117977347

Epoch: 6| Step: 12
Training loss: 1.0442782640457153
Validation loss: 1.8445354341178812

Epoch: 6| Step: 13
Training loss: 0.6581820249557495
Validation loss: 1.829276668128147

Epoch: 279| Step: 0
Training loss: 0.6017641425132751
Validation loss: 1.8524128826715613

Epoch: 6| Step: 1
Training loss: 0.7141760587692261
Validation loss: 1.8319345917752994

Epoch: 6| Step: 2
Training loss: 1.0641134977340698
Validation loss: 1.8118148567855998

Epoch: 6| Step: 3
Training loss: 1.0140392780303955
Validation loss: 1.8054290407447404

Epoch: 6| Step: 4
Training loss: 1.0815832614898682
Validation loss: 1.798143853423416

Epoch: 6| Step: 5
Training loss: 0.8521090745925903
Validation loss: 1.807811237150623

Epoch: 6| Step: 6
Training loss: 1.0677909851074219
Validation loss: 1.8134847789682367

Epoch: 6| Step: 7
Training loss: 1.176867127418518
Validation loss: 1.8367957184391637

Epoch: 6| Step: 8
Training loss: 1.3269450664520264
Validation loss: 1.810396126521531

Epoch: 6| Step: 9
Training loss: 1.0173532962799072
Validation loss: 1.825086598755211

Epoch: 6| Step: 10
Training loss: 0.6154399514198303
Validation loss: 1.8467826458715624

Epoch: 6| Step: 11
Training loss: 0.7238030433654785
Validation loss: 1.85679155524059

Epoch: 6| Step: 12
Training loss: 0.9262352585792542
Validation loss: 1.871564526711741

Epoch: 6| Step: 13
Training loss: 0.8462127447128296
Validation loss: 1.8882341589978946

Epoch: 280| Step: 0
Training loss: 0.818963885307312
Validation loss: 1.8789644959152385

Epoch: 6| Step: 1
Training loss: 0.9841277599334717
Validation loss: 1.876692110492337

Epoch: 6| Step: 2
Training loss: 0.7379177212715149
Validation loss: 1.874018366618823

Epoch: 6| Step: 3
Training loss: 1.0047014951705933
Validation loss: 1.8415711515693254

Epoch: 6| Step: 4
Training loss: 0.9510941505432129
Validation loss: 1.8530075370624501

Epoch: 6| Step: 5
Training loss: 1.3286514282226562
Validation loss: 1.8300373067138016

Epoch: 6| Step: 6
Training loss: 0.9920373558998108
Validation loss: 1.8294891388185563

Epoch: 6| Step: 7
Training loss: 1.0608553886413574
Validation loss: 1.840641342183595

Epoch: 6| Step: 8
Training loss: 0.9503505229949951
Validation loss: 1.8256232943586124

Epoch: 6| Step: 9
Training loss: 1.0221093893051147
Validation loss: 1.8080871887104486

Epoch: 6| Step: 10
Training loss: 0.8401131629943848
Validation loss: 1.813884383888655

Epoch: 6| Step: 11
Training loss: 0.8752174973487854
Validation loss: 1.81741375307883

Epoch: 6| Step: 12
Training loss: 0.7247363328933716
Validation loss: 1.8115430057689708

Epoch: 6| Step: 13
Training loss: 1.0583624839782715
Validation loss: 1.8082417775225896

Epoch: 281| Step: 0
Training loss: 1.0867538452148438
Validation loss: 1.8316948926577004

Epoch: 6| Step: 1
Training loss: 1.2385936975479126
Validation loss: 1.8228159848079886

Epoch: 6| Step: 2
Training loss: 0.9935162663459778
Validation loss: 1.8148358534741145

Epoch: 6| Step: 3
Training loss: 1.1175252199172974
Validation loss: 1.8159245034699798

Epoch: 6| Step: 4
Training loss: 0.9489583969116211
Validation loss: 1.8560313358101794

Epoch: 6| Step: 5
Training loss: 0.9205895066261292
Validation loss: 1.8208565788884317

Epoch: 6| Step: 6
Training loss: 0.9378632307052612
Validation loss: 1.8233573885374172

Epoch: 6| Step: 7
Training loss: 0.8802441358566284
Validation loss: 1.8111191846991097

Epoch: 6| Step: 8
Training loss: 0.8079917430877686
Validation loss: 1.8173014310098463

Epoch: 6| Step: 9
Training loss: 0.9348119497299194
Validation loss: 1.8143666867286927

Epoch: 6| Step: 10
Training loss: 1.1519207954406738
Validation loss: 1.8274365163618518

Epoch: 6| Step: 11
Training loss: 0.7690926790237427
Validation loss: 1.808223165491576

Epoch: 6| Step: 12
Training loss: 0.6781145334243774
Validation loss: 1.7953261060099448

Epoch: 6| Step: 13
Training loss: 0.8998813629150391
Validation loss: 1.8266794604639853

Epoch: 282| Step: 0
Training loss: 1.1618189811706543
Validation loss: 1.8474118094290457

Epoch: 6| Step: 1
Training loss: 0.7914261221885681
Validation loss: 1.8537654530617498

Epoch: 6| Step: 2
Training loss: 0.6859093904495239
Validation loss: 1.8625809672058269

Epoch: 6| Step: 3
Training loss: 1.679497241973877
Validation loss: 1.862246213420745

Epoch: 6| Step: 4
Training loss: 0.6042304039001465
Validation loss: 1.862668514251709

Epoch: 6| Step: 5
Training loss: 0.8033913969993591
Validation loss: 1.8216159728265577

Epoch: 6| Step: 6
Training loss: 0.8439570665359497
Validation loss: 1.8460804749560613

Epoch: 6| Step: 7
Training loss: 1.0153701305389404
Validation loss: 1.824136653254109

Epoch: 6| Step: 8
Training loss: 0.9786866903305054
Validation loss: 1.8163518123729254

Epoch: 6| Step: 9
Training loss: 1.0382704734802246
Validation loss: 1.8103696556501492

Epoch: 6| Step: 10
Training loss: 0.9341081380844116
Validation loss: 1.8066141784832042

Epoch: 6| Step: 11
Training loss: 0.778059720993042
Validation loss: 1.809150331763811

Epoch: 6| Step: 12
Training loss: 0.8943485617637634
Validation loss: 1.7688734390402352

Epoch: 6| Step: 13
Training loss: 0.7784532904624939
Validation loss: 1.801220041449352

Epoch: 283| Step: 0
Training loss: 0.7128586769104004
Validation loss: 1.7649923011820803

Epoch: 6| Step: 1
Training loss: 0.8030062317848206
Validation loss: 1.7862713772763488

Epoch: 6| Step: 2
Training loss: 0.9522854089736938
Validation loss: 1.779184961831698

Epoch: 6| Step: 3
Training loss: 1.1945934295654297
Validation loss: 1.7834798917975476

Epoch: 6| Step: 4
Training loss: 1.1865570545196533
Validation loss: 1.802322042885647

Epoch: 6| Step: 5
Training loss: 0.3154834508895874
Validation loss: 1.7896217248773063

Epoch: 6| Step: 6
Training loss: 0.9031547904014587
Validation loss: 1.7933874463522306

Epoch: 6| Step: 7
Training loss: 1.033144474029541
Validation loss: 1.8180014958945654

Epoch: 6| Step: 8
Training loss: 0.5704646110534668
Validation loss: 1.8367352870202833

Epoch: 6| Step: 9
Training loss: 0.8197182416915894
Validation loss: 1.8558710031611945

Epoch: 6| Step: 10
Training loss: 1.0105060338974
Validation loss: 1.875193044703494

Epoch: 6| Step: 11
Training loss: 1.2824786901474
Validation loss: 1.8450101011542863

Epoch: 6| Step: 12
Training loss: 0.45660048723220825
Validation loss: 1.854396104812622

Epoch: 6| Step: 13
Training loss: 1.688324213027954
Validation loss: 1.8497088493839386

Epoch: 284| Step: 0
Training loss: 0.7972033023834229
Validation loss: 1.830748014552619

Epoch: 6| Step: 1
Training loss: 0.9102218151092529
Validation loss: 1.8376097461228729

Epoch: 6| Step: 2
Training loss: 1.0445556640625
Validation loss: 1.8271302407787693

Epoch: 6| Step: 3
Training loss: 0.8218764066696167
Validation loss: 1.8007201328072497

Epoch: 6| Step: 4
Training loss: 0.5872249603271484
Validation loss: 1.7909782304558703

Epoch: 6| Step: 5
Training loss: 0.8274158835411072
Validation loss: 1.7614467720831595

Epoch: 6| Step: 6
Training loss: 1.1997638940811157
Validation loss: 1.8059152531367477

Epoch: 6| Step: 7
Training loss: 1.098526954650879
Validation loss: 1.7964658801273634

Epoch: 6| Step: 8
Training loss: 1.0980323553085327
Validation loss: 1.788690395252679

Epoch: 6| Step: 9
Training loss: 0.5768071413040161
Validation loss: 1.760824372691493

Epoch: 6| Step: 10
Training loss: 1.2205455303192139
Validation loss: 1.772895020823325

Epoch: 6| Step: 11
Training loss: 0.845799446105957
Validation loss: 1.7970422134604505

Epoch: 6| Step: 12
Training loss: 1.0711332559585571
Validation loss: 1.7770555557743195

Epoch: 6| Step: 13
Training loss: 0.4969059228897095
Validation loss: 1.7953966484274915

Epoch: 285| Step: 0
Training loss: 0.7357308864593506
Validation loss: 1.8055912320331862

Epoch: 6| Step: 1
Training loss: 0.9822169542312622
Validation loss: 1.8196101650114982

Epoch: 6| Step: 2
Training loss: 0.5651643872261047
Validation loss: 1.8312776934716009

Epoch: 6| Step: 3
Training loss: 1.1526256799697876
Validation loss: 1.8361258814411778

Epoch: 6| Step: 4
Training loss: 0.9366909265518188
Validation loss: 1.8292906822696808

Epoch: 6| Step: 5
Training loss: 0.7697327733039856
Validation loss: 1.8652777184722245

Epoch: 6| Step: 6
Training loss: 1.0894945859909058
Validation loss: 1.8509897365364978

Epoch: 6| Step: 7
Training loss: 0.9685381054878235
Validation loss: 1.8735643535531976

Epoch: 6| Step: 8
Training loss: 0.8476482033729553
Validation loss: 1.8151729440176358

Epoch: 6| Step: 9
Training loss: 1.3155462741851807
Validation loss: 1.8137096769066268

Epoch: 6| Step: 10
Training loss: 1.0835044384002686
Validation loss: 1.7954997503629295

Epoch: 6| Step: 11
Training loss: 0.7917115688323975
Validation loss: 1.7983099222183228

Epoch: 6| Step: 12
Training loss: 0.46341264247894287
Validation loss: 1.8029600702306277

Epoch: 6| Step: 13
Training loss: 1.035189151763916
Validation loss: 1.7983429073005595

Epoch: 286| Step: 0
Training loss: 0.7760334014892578
Validation loss: 1.8047254316268428

Epoch: 6| Step: 1
Training loss: 1.0585439205169678
Validation loss: 1.8095260640626312

Epoch: 6| Step: 2
Training loss: 1.210541009902954
Validation loss: 1.828593921917741

Epoch: 6| Step: 3
Training loss: 0.9899746179580688
Validation loss: 1.8337091066504037

Epoch: 6| Step: 4
Training loss: 0.7162200212478638
Validation loss: 1.8396236511968798

Epoch: 6| Step: 5
Training loss: 1.0791295766830444
Validation loss: 1.8370837780737108

Epoch: 6| Step: 6
Training loss: 1.092964768409729
Validation loss: 1.8214166984763196

Epoch: 6| Step: 7
Training loss: 0.3553823232650757
Validation loss: 1.832859403343611

Epoch: 6| Step: 8
Training loss: 1.2950365543365479
Validation loss: 1.8613858069142988

Epoch: 6| Step: 9
Training loss: 0.5639158487319946
Validation loss: 1.8575194984353998

Epoch: 6| Step: 10
Training loss: 1.1037943363189697
Validation loss: 1.8900720432240476

Epoch: 6| Step: 11
Training loss: 1.0234341621398926
Validation loss: 1.8797327446681198

Epoch: 6| Step: 12
Training loss: 0.48944735527038574
Validation loss: 1.8862999536657845

Epoch: 6| Step: 13
Training loss: 0.47577422857284546
Validation loss: 1.9215881850129815

Epoch: 287| Step: 0
Training loss: 1.0481948852539062
Validation loss: 1.8923299902228898

Epoch: 6| Step: 1
Training loss: 1.01127290725708
Validation loss: 1.889330187151509

Epoch: 6| Step: 2
Training loss: 1.0789779424667358
Validation loss: 1.8460360355274652

Epoch: 6| Step: 3
Training loss: 0.9138430953025818
Validation loss: 1.816304333748356

Epoch: 6| Step: 4
Training loss: 0.5905269384384155
Validation loss: 1.796711278218095

Epoch: 6| Step: 5
Training loss: 1.3718416690826416
Validation loss: 1.78800771761966

Epoch: 6| Step: 6
Training loss: 0.6002665162086487
Validation loss: 1.782842388717077

Epoch: 6| Step: 7
Training loss: 0.576838493347168
Validation loss: 1.7721066090368456

Epoch: 6| Step: 8
Training loss: 0.6992523670196533
Validation loss: 1.7734168678201654

Epoch: 6| Step: 9
Training loss: 0.9285295605659485
Validation loss: 1.8087788858721334

Epoch: 6| Step: 10
Training loss: 0.8626872897148132
Validation loss: 1.8098483623996857

Epoch: 6| Step: 11
Training loss: 0.7932633757591248
Validation loss: 1.8377826841928626

Epoch: 6| Step: 12
Training loss: 1.0852901935577393
Validation loss: 1.9036189099793792

Epoch: 6| Step: 13
Training loss: 0.5455288290977478
Validation loss: 1.8757905857537382

Epoch: 288| Step: 0
Training loss: 0.8231307864189148
Validation loss: 1.8673543865962694

Epoch: 6| Step: 1
Training loss: 0.509887158870697
Validation loss: 1.8447652862917991

Epoch: 6| Step: 2
Training loss: 0.6192631721496582
Validation loss: 1.8299974779928885

Epoch: 6| Step: 3
Training loss: 1.0291688442230225
Validation loss: 1.8130058037337435

Epoch: 6| Step: 4
Training loss: 1.2145658731460571
Validation loss: 1.803367918537509

Epoch: 6| Step: 5
Training loss: 0.8974155783653259
Validation loss: 1.7827647834695795

Epoch: 6| Step: 6
Training loss: 0.5784793496131897
Validation loss: 1.8048724589809295

Epoch: 6| Step: 7
Training loss: 1.1153178215026855
Validation loss: 1.808744269032632

Epoch: 6| Step: 8
Training loss: 1.0132322311401367
Validation loss: 1.8128974283895185

Epoch: 6| Step: 9
Training loss: 1.1919710636138916
Validation loss: 1.8338934375393776

Epoch: 6| Step: 10
Training loss: 0.9331115484237671
Validation loss: 1.8241974435826784

Epoch: 6| Step: 11
Training loss: 0.8985344171524048
Validation loss: 1.8119593801036957

Epoch: 6| Step: 12
Training loss: 1.1140940189361572
Validation loss: 1.8161539198249899

Epoch: 6| Step: 13
Training loss: 0.28654083609580994
Validation loss: 1.8196646910841747

Epoch: 289| Step: 0
Training loss: 0.5001763701438904
Validation loss: 1.816641487101073

Epoch: 6| Step: 1
Training loss: 0.8146255016326904
Validation loss: 1.8439700975213

Epoch: 6| Step: 2
Training loss: 0.7229949235916138
Validation loss: 1.8344828377487838

Epoch: 6| Step: 3
Training loss: 1.367133617401123
Validation loss: 1.8636312536014024

Epoch: 6| Step: 4
Training loss: 0.6227366328239441
Validation loss: 1.8590761384656351

Epoch: 6| Step: 5
Training loss: 0.9596696496009827
Validation loss: 1.8572776625233312

Epoch: 6| Step: 6
Training loss: 0.9486819505691528
Validation loss: 1.8661869661782378

Epoch: 6| Step: 7
Training loss: 0.7367694973945618
Validation loss: 1.8410388513277935

Epoch: 6| Step: 8
Training loss: 0.9164162874221802
Validation loss: 1.821664564071163

Epoch: 6| Step: 9
Training loss: 0.7907336950302124
Validation loss: 1.8094237773649153

Epoch: 6| Step: 10
Training loss: 1.0402588844299316
Validation loss: 1.7996788358175626

Epoch: 6| Step: 11
Training loss: 0.5956048965454102
Validation loss: 1.783358746959317

Epoch: 6| Step: 12
Training loss: 1.6692410707473755
Validation loss: 1.7808228359427503

Epoch: 6| Step: 13
Training loss: 0.8120913505554199
Validation loss: 1.7502545182422926

Epoch: 290| Step: 0
Training loss: 0.8480799198150635
Validation loss: 1.7599609321163547

Epoch: 6| Step: 1
Training loss: 1.3176493644714355
Validation loss: 1.7615963259050924

Epoch: 6| Step: 2
Training loss: 1.2099828720092773
Validation loss: 1.7417119356893724

Epoch: 6| Step: 3
Training loss: 0.44405508041381836
Validation loss: 1.7561236748131372

Epoch: 6| Step: 4
Training loss: 0.2762444019317627
Validation loss: 1.7562897102807158

Epoch: 6| Step: 5
Training loss: 0.9242202043533325
Validation loss: 1.7749052573275823

Epoch: 6| Step: 6
Training loss: 0.6540161371231079
Validation loss: 1.803071122015676

Epoch: 6| Step: 7
Training loss: 0.9730993509292603
Validation loss: 1.8214621005519744

Epoch: 6| Step: 8
Training loss: 0.8556126952171326
Validation loss: 1.8581706695659186

Epoch: 6| Step: 9
Training loss: 0.9315233826637268
Validation loss: 1.8617888342949651

Epoch: 6| Step: 10
Training loss: 1.2806460857391357
Validation loss: 1.8949935615703624

Epoch: 6| Step: 11
Training loss: 0.790276288986206
Validation loss: 1.9009905399814728

Epoch: 6| Step: 12
Training loss: 0.8542477488517761
Validation loss: 1.9034470281293314

Epoch: 6| Step: 13
Training loss: 0.67872154712677
Validation loss: 1.8964065121066185

Epoch: 291| Step: 0
Training loss: 0.8418880701065063
Validation loss: 1.8864629704465148

Epoch: 6| Step: 1
Training loss: 0.37060868740081787
Validation loss: 1.854275450911573

Epoch: 6| Step: 2
Training loss: 0.6291421055793762
Validation loss: 1.8409407138824463

Epoch: 6| Step: 3
Training loss: 1.0253629684448242
Validation loss: 1.8325642026880735

Epoch: 6| Step: 4
Training loss: 1.001200556755066
Validation loss: 1.8046724437385477

Epoch: 6| Step: 5
Training loss: 0.9647119641304016
Validation loss: 1.7842800655672628

Epoch: 6| Step: 6
Training loss: 1.2109391689300537
Validation loss: 1.76822288702893

Epoch: 6| Step: 7
Training loss: 0.5881403684616089
Validation loss: 1.7477021319891817

Epoch: 6| Step: 8
Training loss: 0.9407306909561157
Validation loss: 1.749708588405322

Epoch: 6| Step: 9
Training loss: 1.2295196056365967
Validation loss: 1.777762492497762

Epoch: 6| Step: 10
Training loss: 0.6278575658798218
Validation loss: 1.7836958836483698

Epoch: 6| Step: 11
Training loss: 0.7345555424690247
Validation loss: 1.7885251865592053

Epoch: 6| Step: 12
Training loss: 0.9753350615501404
Validation loss: 1.790705060446134

Epoch: 6| Step: 13
Training loss: 1.5695949792861938
Validation loss: 1.8057449556166125

Epoch: 292| Step: 0
Training loss: 0.9972485899925232
Validation loss: 1.8540069492914344

Epoch: 6| Step: 1
Training loss: 0.6908071041107178
Validation loss: 1.8347406156601445

Epoch: 6| Step: 2
Training loss: 0.7144598960876465
Validation loss: 1.8837439757521435

Epoch: 6| Step: 3
Training loss: 1.158154010772705
Validation loss: 1.918833468549995

Epoch: 6| Step: 4
Training loss: 1.0518850088119507
Validation loss: 1.9711346023826188

Epoch: 6| Step: 5
Training loss: 0.9368981122970581
Validation loss: 1.9687038724140455

Epoch: 6| Step: 6
Training loss: 0.8370263576507568
Validation loss: 1.9219358249377179

Epoch: 6| Step: 7
Training loss: 0.8342018723487854
Validation loss: 1.9162366620955928

Epoch: 6| Step: 8
Training loss: 0.7717678546905518
Validation loss: 1.8763425222007177

Epoch: 6| Step: 9
Training loss: 0.8783994317054749
Validation loss: 1.8806726535161336

Epoch: 6| Step: 10
Training loss: 0.646223783493042
Validation loss: 1.8364209821147304

Epoch: 6| Step: 11
Training loss: 0.6466697454452515
Validation loss: 1.8368601888738654

Epoch: 6| Step: 12
Training loss: 0.865891695022583
Validation loss: 1.796416244199199

Epoch: 6| Step: 13
Training loss: 1.0531514883041382
Validation loss: 1.8131750950249292

Epoch: 293| Step: 0
Training loss: 0.8911328911781311
Validation loss: 1.7897969676602272

Epoch: 6| Step: 1
Training loss: 0.5763334035873413
Validation loss: 1.794895988638683

Epoch: 6| Step: 2
Training loss: 0.8068155646324158
Validation loss: 1.802142632904873

Epoch: 6| Step: 3
Training loss: 0.6489642262458801
Validation loss: 1.7957961956659954

Epoch: 6| Step: 4
Training loss: 0.7424824833869934
Validation loss: 1.8020230531692505

Epoch: 6| Step: 5
Training loss: 0.6327726244926453
Validation loss: 1.8002713675140052

Epoch: 6| Step: 6
Training loss: 0.37334439158439636
Validation loss: 1.8299283289140271

Epoch: 6| Step: 7
Training loss: 0.988612174987793
Validation loss: 1.8415326995234336

Epoch: 6| Step: 8
Training loss: 1.145007610321045
Validation loss: 1.8589431854986376

Epoch: 6| Step: 9
Training loss: 0.8012698292732239
Validation loss: 1.876537101243132

Epoch: 6| Step: 10
Training loss: 0.8577922582626343
Validation loss: 1.8531745595316733

Epoch: 6| Step: 11
Training loss: 0.9990178346633911
Validation loss: 1.8746832852722497

Epoch: 6| Step: 12
Training loss: 0.945732593536377
Validation loss: 1.86332836715124

Epoch: 6| Step: 13
Training loss: 1.804585576057434
Validation loss: 1.8660549502218924

Epoch: 294| Step: 0
Training loss: 0.7575726509094238
Validation loss: 1.8522598845984346

Epoch: 6| Step: 1
Training loss: 1.111137866973877
Validation loss: 1.85546661192371

Epoch: 6| Step: 2
Training loss: 0.8020985126495361
Validation loss: 1.8591260384487849

Epoch: 6| Step: 3
Training loss: 1.1135342121124268
Validation loss: 1.8079299375575075

Epoch: 6| Step: 4
Training loss: 1.0409126281738281
Validation loss: 1.7742232661093436

Epoch: 6| Step: 5
Training loss: 0.41361474990844727
Validation loss: 1.7458979070827525

Epoch: 6| Step: 6
Training loss: 0.9745118021965027
Validation loss: 1.7970988583821121

Epoch: 6| Step: 7
Training loss: 1.1749622821807861
Validation loss: 1.7797820465539091

Epoch: 6| Step: 8
Training loss: 0.889976978302002
Validation loss: 1.8198360884061424

Epoch: 6| Step: 9
Training loss: 0.6894186735153198
Validation loss: 1.8296292635702318

Epoch: 6| Step: 10
Training loss: 0.9388588666915894
Validation loss: 1.8453491477556125

Epoch: 6| Step: 11
Training loss: 0.7413679361343384
Validation loss: 1.7976880009456346

Epoch: 6| Step: 12
Training loss: 0.6255382299423218
Validation loss: 1.834007102956054

Epoch: 6| Step: 13
Training loss: 0.8026381731033325
Validation loss: 1.8500062855341102

Epoch: 295| Step: 0
Training loss: 0.6456366777420044
Validation loss: 1.8468714311558714

Epoch: 6| Step: 1
Training loss: 0.5757884979248047
Validation loss: 1.8477420153156403

Epoch: 6| Step: 2
Training loss: 0.9019505381584167
Validation loss: 1.8513347256568171

Epoch: 6| Step: 3
Training loss: 0.5993109941482544
Validation loss: 1.8228052816083353

Epoch: 6| Step: 4
Training loss: 0.7973686456680298
Validation loss: 1.830043952952149

Epoch: 6| Step: 5
Training loss: 0.9602851867675781
Validation loss: 1.8245794439828524

Epoch: 6| Step: 6
Training loss: 1.005099892616272
Validation loss: 1.8254484386854275

Epoch: 6| Step: 7
Training loss: 0.9886990785598755
Validation loss: 1.8662405014038086

Epoch: 6| Step: 8
Training loss: 0.9447224736213684
Validation loss: 1.858808789201962

Epoch: 6| Step: 9
Training loss: 0.8436275124549866
Validation loss: 1.8503782262084305

Epoch: 6| Step: 10
Training loss: 0.7625808715820312
Validation loss: 1.8375105986031153

Epoch: 6| Step: 11
Training loss: 1.135016918182373
Validation loss: 1.85957932472229

Epoch: 6| Step: 12
Training loss: 0.8545776605606079
Validation loss: 1.872057778860933

Epoch: 6| Step: 13
Training loss: 1.4019222259521484
Validation loss: 1.8586796022230578

Epoch: 296| Step: 0
Training loss: 0.510852575302124
Validation loss: 1.8611031834797194

Epoch: 6| Step: 1
Training loss: 1.0059611797332764
Validation loss: 1.8545629465451805

Epoch: 6| Step: 2
Training loss: 0.7868998050689697
Validation loss: 1.86321977133392

Epoch: 6| Step: 3
Training loss: 0.3664809465408325
Validation loss: 1.846727830107494

Epoch: 6| Step: 4
Training loss: 0.9405747056007385
Validation loss: 1.8308353270253828

Epoch: 6| Step: 5
Training loss: 1.0429253578186035
Validation loss: 1.8598303974315684

Epoch: 6| Step: 6
Training loss: 0.688493013381958
Validation loss: 1.8778409573339647

Epoch: 6| Step: 7
Training loss: 0.8553522229194641
Validation loss: 1.9012582507184757

Epoch: 6| Step: 8
Training loss: 0.7637077569961548
Validation loss: 1.919873377328278

Epoch: 6| Step: 9
Training loss: 1.0100150108337402
Validation loss: 1.90970790514382

Epoch: 6| Step: 10
Training loss: 1.0418695211410522
Validation loss: 1.8998612267996675

Epoch: 6| Step: 11
Training loss: 0.7705916166305542
Validation loss: 1.8765728294208486

Epoch: 6| Step: 12
Training loss: 0.9626907110214233
Validation loss: 1.864667175918497

Epoch: 6| Step: 13
Training loss: 1.2462838888168335
Validation loss: 1.8951548684027888

Epoch: 297| Step: 0
Training loss: 1.026724100112915
Validation loss: 1.8657992937231576

Epoch: 6| Step: 1
Training loss: 1.3320882320404053
Validation loss: 1.8679135909644506

Epoch: 6| Step: 2
Training loss: 0.695650577545166
Validation loss: 1.883315013300988

Epoch: 6| Step: 3
Training loss: 0.8429146409034729
Validation loss: 1.878932640116702

Epoch: 6| Step: 4
Training loss: 0.5575605034828186
Validation loss: 1.8449127802284815

Epoch: 6| Step: 5
Training loss: 1.0531755685806274
Validation loss: 1.841066837310791

Epoch: 6| Step: 6
Training loss: 0.6911224722862244
Validation loss: 1.8354130842352425

Epoch: 6| Step: 7
Training loss: 0.6899672746658325
Validation loss: 1.8498305223321403

Epoch: 6| Step: 8
Training loss: 0.5265660881996155
Validation loss: 1.8698366790689447

Epoch: 6| Step: 9
Training loss: 0.865659773349762
Validation loss: 1.846758871950129

Epoch: 6| Step: 10
Training loss: 0.6737139225006104
Validation loss: 1.8352591735060497

Epoch: 6| Step: 11
Training loss: 0.7498302459716797
Validation loss: 1.8390735785166423

Epoch: 6| Step: 12
Training loss: 0.8510404825210571
Validation loss: 1.836243837110458

Epoch: 6| Step: 13
Training loss: 1.1269463300704956
Validation loss: 1.8348856767018635

Epoch: 298| Step: 0
Training loss: 1.1407667398452759
Validation loss: 1.8286833455485683

Epoch: 6| Step: 1
Training loss: 1.1177499294281006
Validation loss: 1.8480176464203866

Epoch: 6| Step: 2
Training loss: 1.115389108657837
Validation loss: 1.8488028972379622

Epoch: 6| Step: 3
Training loss: 0.7399649620056152
Validation loss: 1.8588623128911501

Epoch: 6| Step: 4
Training loss: 0.6045569181442261
Validation loss: 1.8471483158808883

Epoch: 6| Step: 5
Training loss: 0.6341359615325928
Validation loss: 1.8557225055592035

Epoch: 6| Step: 6
Training loss: 0.8807793259620667
Validation loss: 1.8657823775404243

Epoch: 6| Step: 7
Training loss: 0.6096093058586121
Validation loss: 1.8496767167122132

Epoch: 6| Step: 8
Training loss: 1.1391775608062744
Validation loss: 1.871820072973928

Epoch: 6| Step: 9
Training loss: 0.6939070224761963
Validation loss: 1.8482775201079666

Epoch: 6| Step: 10
Training loss: 0.5968375205993652
Validation loss: 1.851156775669385

Epoch: 6| Step: 11
Training loss: 0.5071166753768921
Validation loss: 1.8466442695228003

Epoch: 6| Step: 12
Training loss: 0.7956638336181641
Validation loss: 1.798746096190586

Epoch: 6| Step: 13
Training loss: 0.8637963533401489
Validation loss: 1.7627665278732136

Epoch: 299| Step: 0
Training loss: 1.1185170412063599
Validation loss: 1.7829356026905838

Epoch: 6| Step: 1
Training loss: 1.2995920181274414
Validation loss: 1.724584867877345

Epoch: 6| Step: 2
Training loss: 1.0350465774536133
Validation loss: 1.7403192238141132

Epoch: 6| Step: 3
Training loss: 0.6707552671432495
Validation loss: 1.770687876209136

Epoch: 6| Step: 4
Training loss: 1.023781180381775
Validation loss: 1.7713886448132095

Epoch: 6| Step: 5
Training loss: 0.6567485928535461
Validation loss: 1.7849646358079807

Epoch: 6| Step: 6
Training loss: 0.767294704914093
Validation loss: 1.8203632331663562

Epoch: 6| Step: 7
Training loss: 0.724805474281311
Validation loss: 1.8219625373040476

Epoch: 6| Step: 8
Training loss: 0.5772547721862793
Validation loss: 1.8359218348738968

Epoch: 6| Step: 9
Training loss: 0.48656803369522095
Validation loss: 1.847029060445806

Epoch: 6| Step: 10
Training loss: 1.3143606185913086
Validation loss: 1.8745198224180488

Epoch: 6| Step: 11
Training loss: 0.5852692127227783
Validation loss: 1.867476140299151

Epoch: 6| Step: 12
Training loss: 0.8301774263381958
Validation loss: 1.8539381847586682

Epoch: 6| Step: 13
Training loss: 0.5297556519508362
Validation loss: 1.8520894422326037

Epoch: 300| Step: 0
Training loss: 0.8288406133651733
Validation loss: 1.8778581696171914

Epoch: 6| Step: 1
Training loss: 0.6862283945083618
Validation loss: 1.857591672610211

Epoch: 6| Step: 2
Training loss: 0.7697855234146118
Validation loss: 1.8396277196945683

Epoch: 6| Step: 3
Training loss: 0.9870718717575073
Validation loss: 1.833239992459615

Epoch: 6| Step: 4
Training loss: 0.9481627941131592
Validation loss: 1.8468670665576894

Epoch: 6| Step: 5
Training loss: 0.9268505573272705
Validation loss: 1.872549727398862

Epoch: 6| Step: 6
Training loss: 0.9517611265182495
Validation loss: 1.8576749883672243

Epoch: 6| Step: 7
Training loss: 0.6338970065116882
Validation loss: 1.852986551100208

Epoch: 6| Step: 8
Training loss: 0.5988980531692505
Validation loss: 1.838841151165706

Epoch: 6| Step: 9
Training loss: 0.6674634218215942
Validation loss: 1.8312220060697166

Epoch: 6| Step: 10
Training loss: 0.48622292280197144
Validation loss: 1.8451718412419802

Epoch: 6| Step: 11
Training loss: 0.6762911677360535
Validation loss: 1.8717860508990545

Epoch: 6| Step: 12
Training loss: 1.1234406232833862
Validation loss: 1.8684043551004061

Epoch: 6| Step: 13
Training loss: 0.9501472115516663
Validation loss: 1.861421379991757

Epoch: 301| Step: 0
Training loss: 0.8039833307266235
Validation loss: 1.828844786972128

Epoch: 6| Step: 1
Training loss: 0.7601962089538574
Validation loss: 1.8344447599944247

Epoch: 6| Step: 2
Training loss: 0.8252403736114502
Validation loss: 1.8019532311347224

Epoch: 6| Step: 3
Training loss: 0.8322274684906006
Validation loss: 1.824625862542019

Epoch: 6| Step: 4
Training loss: 0.6494904160499573
Validation loss: 1.8103042046229045

Epoch: 6| Step: 5
Training loss: 0.9460891485214233
Validation loss: 1.8374016682306926

Epoch: 6| Step: 6
Training loss: 0.6753227710723877
Validation loss: 1.7862092346273444

Epoch: 6| Step: 7
Training loss: 0.8444156050682068
Validation loss: 1.8053152766278995

Epoch: 6| Step: 8
Training loss: 0.7733044624328613
Validation loss: 1.7738495565229846

Epoch: 6| Step: 9
Training loss: 1.0074595212936401
Validation loss: 1.787216185241617

Epoch: 6| Step: 10
Training loss: 0.9897924661636353
Validation loss: 1.799151341761312

Epoch: 6| Step: 11
Training loss: 0.49756181240081787
Validation loss: 1.8344876048385457

Epoch: 6| Step: 12
Training loss: 0.9929364919662476
Validation loss: 1.8574283892108547

Epoch: 6| Step: 13
Training loss: 0.551967203617096
Validation loss: 1.8118771173620736

Epoch: 302| Step: 0
Training loss: 1.12074613571167
Validation loss: 1.8356028654242074

Epoch: 6| Step: 1
Training loss: 0.9813629388809204
Validation loss: 1.8536527925922024

Epoch: 6| Step: 2
Training loss: 0.51665198802948
Validation loss: 1.8570436046969505

Epoch: 6| Step: 3
Training loss: 0.5312670469284058
Validation loss: 1.853660628359805

Epoch: 6| Step: 4
Training loss: 1.1142618656158447
Validation loss: 1.836993282841098

Epoch: 6| Step: 5
Training loss: 0.9429514408111572
Validation loss: 1.8373973651598858

Epoch: 6| Step: 6
Training loss: 0.776475191116333
Validation loss: 1.851434253877209

Epoch: 6| Step: 7
Training loss: 0.47051239013671875
Validation loss: 1.8310856716607207

Epoch: 6| Step: 8
Training loss: 0.6276885271072388
Validation loss: 1.8464417572944396

Epoch: 6| Step: 9
Training loss: 0.7702552676200867
Validation loss: 1.8352949337292743

Epoch: 6| Step: 10
Training loss: 1.1108723878860474
Validation loss: 1.8322855387964556

Epoch: 6| Step: 11
Training loss: 0.7664154171943665
Validation loss: 1.8671904199866838

Epoch: 6| Step: 12
Training loss: 0.6235091686248779
Validation loss: 1.845329830723424

Epoch: 6| Step: 13
Training loss: 0.6630027294158936
Validation loss: 1.7935596691664828

Epoch: 303| Step: 0
Training loss: 0.8467372059822083
Validation loss: 1.7466918012147308

Epoch: 6| Step: 1
Training loss: 0.9937472343444824
Validation loss: 1.7708299301003898

Epoch: 6| Step: 2
Training loss: 0.7101117372512817
Validation loss: 1.806884414406233

Epoch: 6| Step: 3
Training loss: 0.5472564697265625
Validation loss: 1.7936159308238695

Epoch: 6| Step: 4
Training loss: 1.056649088859558
Validation loss: 1.8072556590521207

Epoch: 6| Step: 5
Training loss: 1.0500363111495972
Validation loss: 1.8074215150648547

Epoch: 6| Step: 6
Training loss: 0.6254317760467529
Validation loss: 1.8005090887828539

Epoch: 6| Step: 7
Training loss: 0.5242792367935181
Validation loss: 1.7905204129475418

Epoch: 6| Step: 8
Training loss: 1.1553075313568115
Validation loss: 1.8038248067261071

Epoch: 6| Step: 9
Training loss: 0.8041362166404724
Validation loss: 1.8393313961644326

Epoch: 6| Step: 10
Training loss: 0.8252716660499573
Validation loss: 1.8475227009865545

Epoch: 6| Step: 11
Training loss: 0.9343621730804443
Validation loss: 1.846107329091718

Epoch: 6| Step: 12
Training loss: 0.6068708300590515
Validation loss: 1.8262841957871632

Epoch: 6| Step: 13
Training loss: 0.41108494997024536
Validation loss: 1.847275177637736

Epoch: 304| Step: 0
Training loss: 0.5962599515914917
Validation loss: 1.8455344323189027

Epoch: 6| Step: 1
Training loss: 0.6134409308433533
Validation loss: 1.8446852930130497

Epoch: 6| Step: 2
Training loss: 0.6196044683456421
Validation loss: 1.8181660021505048

Epoch: 6| Step: 3
Training loss: 0.7688407897949219
Validation loss: 1.8233427219493414

Epoch: 6| Step: 4
Training loss: 0.9473365545272827
Validation loss: 1.8295377223722395

Epoch: 6| Step: 5
Training loss: 0.5565431118011475
Validation loss: 1.806325940675633

Epoch: 6| Step: 6
Training loss: 0.9822754859924316
Validation loss: 1.800219069245041

Epoch: 6| Step: 7
Training loss: 1.0322800874710083
Validation loss: 1.8039399359815864

Epoch: 6| Step: 8
Training loss: 0.5751208662986755
Validation loss: 1.7928713098649056

Epoch: 6| Step: 9
Training loss: 0.4883215129375458
Validation loss: 1.787873439891364

Epoch: 6| Step: 10
Training loss: 0.8188410997390747
Validation loss: 1.7861907148873934

Epoch: 6| Step: 11
Training loss: 0.745812714099884
Validation loss: 1.8195112969285698

Epoch: 6| Step: 12
Training loss: 0.6551434993743896
Validation loss: 1.80560435787324

Epoch: 6| Step: 13
Training loss: 1.2394285202026367
Validation loss: 1.8180350244686168

Epoch: 305| Step: 0
Training loss: 0.559775710105896
Validation loss: 1.8411670346413889

Epoch: 6| Step: 1
Training loss: 0.4972039759159088
Validation loss: 1.8505864707372521

Epoch: 6| Step: 2
Training loss: 0.8372291326522827
Validation loss: 1.8332067702406196

Epoch: 6| Step: 3
Training loss: 0.776317834854126
Validation loss: 1.8109531005223591

Epoch: 6| Step: 4
Training loss: 0.4780130982398987
Validation loss: 1.8322975353528095

Epoch: 6| Step: 5
Training loss: 0.5543550848960876
Validation loss: 1.8290496410862092

Epoch: 6| Step: 6
Training loss: 0.7903631925582886
Validation loss: 1.8436860499843475

Epoch: 6| Step: 7
Training loss: 0.5627585053443909
Validation loss: 1.8457626450446345

Epoch: 6| Step: 8
Training loss: 0.7159855961799622
Validation loss: 1.8589466335952922

Epoch: 6| Step: 9
Training loss: 0.6305981278419495
Validation loss: 1.8362328544739754

Epoch: 6| Step: 10
Training loss: 0.7120054364204407
Validation loss: 1.858828781753458

Epoch: 6| Step: 11
Training loss: 1.4162983894348145
Validation loss: 1.8532127923862909

Epoch: 6| Step: 12
Training loss: 0.9380902051925659
Validation loss: 1.8566618465608167

Epoch: 6| Step: 13
Training loss: 0.6499783396720886
Validation loss: 1.848656403121128

Epoch: 306| Step: 0
Training loss: 0.8340252637863159
Validation loss: 1.8487282004407657

Epoch: 6| Step: 1
Training loss: 0.7850466966629028
Validation loss: 1.800561665206827

Epoch: 6| Step: 2
Training loss: 0.7808890342712402
Validation loss: 1.7866049607594807

Epoch: 6| Step: 3
Training loss: 0.7424193620681763
Validation loss: 1.7746190255688084

Epoch: 6| Step: 4
Training loss: 0.5731759071350098
Validation loss: 1.7463952213205316

Epoch: 6| Step: 5
Training loss: 0.6337413787841797
Validation loss: 1.7780585417183496

Epoch: 6| Step: 6
Training loss: 0.36380183696746826
Validation loss: 1.7537736969609414

Epoch: 6| Step: 7
Training loss: 0.8451592326164246
Validation loss: 1.7799580827836068

Epoch: 6| Step: 8
Training loss: 0.5152426958084106
Validation loss: 1.786508026943412

Epoch: 6| Step: 9
Training loss: 0.7496205568313599
Validation loss: 1.781139007178686

Epoch: 6| Step: 10
Training loss: 1.277261734008789
Validation loss: 1.8103794513210174

Epoch: 6| Step: 11
Training loss: 0.49288493394851685
Validation loss: 1.8049481658525364

Epoch: 6| Step: 12
Training loss: 0.7578720450401306
Validation loss: 1.8308762799027145

Epoch: 6| Step: 13
Training loss: 0.6852792501449585
Validation loss: 1.8406867839956795

Epoch: 307| Step: 0
Training loss: 0.5863790512084961
Validation loss: 1.8511331747936945

Epoch: 6| Step: 1
Training loss: 0.6400822997093201
Validation loss: 1.854806169386833

Epoch: 6| Step: 2
Training loss: 0.9900414347648621
Validation loss: 1.858008921787303

Epoch: 6| Step: 3
Training loss: 0.5019406080245972
Validation loss: 1.8285175113267795

Epoch: 6| Step: 4
Training loss: 0.5274118185043335
Validation loss: 1.82221294026221

Epoch: 6| Step: 5
Training loss: 0.5684289336204529
Validation loss: 1.80401090909076

Epoch: 6| Step: 6
Training loss: 0.868059515953064
Validation loss: 1.814294607408585

Epoch: 6| Step: 7
Training loss: 0.77640300989151
Validation loss: 1.806299973559636

Epoch: 6| Step: 8
Training loss: 0.73738694190979
Validation loss: 1.7813105096099198

Epoch: 6| Step: 9
Training loss: 0.8409061431884766
Validation loss: 1.804943747417901

Epoch: 6| Step: 10
Training loss: 0.7406654357910156
Validation loss: 1.8035202859550394

Epoch: 6| Step: 11
Training loss: 0.5718494653701782
Validation loss: 1.8141054209842478

Epoch: 6| Step: 12
Training loss: 0.7933790683746338
Validation loss: 1.837875605911337

Epoch: 6| Step: 13
Training loss: 0.7902198433876038
Validation loss: 1.8204723660663893

Epoch: 308| Step: 0
Training loss: 0.7616874575614929
Validation loss: 1.8010703953363563

Epoch: 6| Step: 1
Training loss: 0.6006363034248352
Validation loss: 1.7986931993115334

Epoch: 6| Step: 2
Training loss: 0.7822219133377075
Validation loss: 1.8146489717627083

Epoch: 6| Step: 3
Training loss: 0.8496012687683105
Validation loss: 1.8492021996487853

Epoch: 6| Step: 4
Training loss: 0.4704950749874115
Validation loss: 1.87799826616882

Epoch: 6| Step: 5
Training loss: 0.6267262697219849
Validation loss: 1.8745198454908145

Epoch: 6| Step: 6
Training loss: 0.5814764499664307
Validation loss: 1.8473450278723111

Epoch: 6| Step: 7
Training loss: 0.804456353187561
Validation loss: 1.8531151304962814

Epoch: 6| Step: 8
Training loss: 0.7955799102783203
Validation loss: 1.8412824676882835

Epoch: 6| Step: 9
Training loss: 1.2336746454238892
Validation loss: 1.8390557048141316

Epoch: 6| Step: 10
Training loss: 0.7647533416748047
Validation loss: 1.8107724176940097

Epoch: 6| Step: 11
Training loss: 0.36685723066329956
Validation loss: 1.810740678541122

Epoch: 6| Step: 12
Training loss: 0.4807097613811493
Validation loss: 1.823283121150027

Epoch: 6| Step: 13
Training loss: 0.8934044241905212
Validation loss: 1.8117537472837715

Epoch: 309| Step: 0
Training loss: 0.42921996116638184
Validation loss: 1.7798163672929168

Epoch: 6| Step: 1
Training loss: 0.4951128363609314
Validation loss: 1.782868762170115

Epoch: 6| Step: 2
Training loss: 0.5928839445114136
Validation loss: 1.7821912419411443

Epoch: 6| Step: 3
Training loss: 1.1371216773986816
Validation loss: 1.7831053451825214

Epoch: 6| Step: 4
Training loss: 0.48890626430511475
Validation loss: 1.8235726151415097

Epoch: 6| Step: 5
Training loss: 1.0301363468170166
Validation loss: 1.8221398732995475

Epoch: 6| Step: 6
Training loss: 0.9171302318572998
Validation loss: 1.82304052511851

Epoch: 6| Step: 7
Training loss: 0.7107465267181396
Validation loss: 1.8209331599614953

Epoch: 6| Step: 8
Training loss: 0.6378504037857056
Validation loss: 1.8323565183147308

Epoch: 6| Step: 9
Training loss: 0.5105195045471191
Validation loss: 1.8302777915872552

Epoch: 6| Step: 10
Training loss: 0.5502378344535828
Validation loss: 1.8448977047397244

Epoch: 6| Step: 11
Training loss: 0.6145743131637573
Validation loss: 1.8215737355652677

Epoch: 6| Step: 12
Training loss: 1.0954177379608154
Validation loss: 1.8494373572769987

Epoch: 6| Step: 13
Training loss: 0.7052934765815735
Validation loss: 1.840882065475628

Epoch: 310| Step: 0
Training loss: 0.7802160382270813
Validation loss: 1.83358427786058

Epoch: 6| Step: 1
Training loss: 0.7053519487380981
Validation loss: 1.8318924416777909

Epoch: 6| Step: 2
Training loss: 0.4835936427116394
Validation loss: 1.8077515402147848

Epoch: 6| Step: 3
Training loss: 1.1708400249481201
Validation loss: 1.81582934112959

Epoch: 6| Step: 4
Training loss: 0.7314448952674866
Validation loss: 1.814138925203713

Epoch: 6| Step: 5
Training loss: 0.6217253804206848
Validation loss: 1.802159252987113

Epoch: 6| Step: 6
Training loss: 0.6712360382080078
Validation loss: 1.7980196193982196

Epoch: 6| Step: 7
Training loss: 0.5944724082946777
Validation loss: 1.8125991821289062

Epoch: 6| Step: 8
Training loss: 0.42322054505348206
Validation loss: 1.7770599011451966

Epoch: 6| Step: 9
Training loss: 0.5103541612625122
Validation loss: 1.7821771162812428

Epoch: 6| Step: 10
Training loss: 0.5464085936546326
Validation loss: 1.7787744306748914

Epoch: 6| Step: 11
Training loss: 0.6835135221481323
Validation loss: 1.769970586222987

Epoch: 6| Step: 12
Training loss: 0.8055210113525391
Validation loss: 1.784917377656506

Epoch: 6| Step: 13
Training loss: 0.6719481945037842
Validation loss: 1.7769455807183379

Epoch: 311| Step: 0
Training loss: 0.4588828682899475
Validation loss: 1.7763962309847596

Epoch: 6| Step: 1
Training loss: 0.675365149974823
Validation loss: 1.7951409983378586

Epoch: 6| Step: 2
Training loss: 0.6221885681152344
Validation loss: 1.7667492487097298

Epoch: 6| Step: 3
Training loss: 1.0112099647521973
Validation loss: 1.7821697881144862

Epoch: 6| Step: 4
Training loss: 0.5896299481391907
Validation loss: 1.7988636698774112

Epoch: 6| Step: 5
Training loss: 0.728248119354248
Validation loss: 1.8007281070114465

Epoch: 6| Step: 6
Training loss: 0.6078522205352783
Validation loss: 1.8241823129756476

Epoch: 6| Step: 7
Training loss: 0.7932869791984558
Validation loss: 1.8242655313143166

Epoch: 6| Step: 8
Training loss: 0.6145869493484497
Validation loss: 1.8112151251044324

Epoch: 6| Step: 9
Training loss: 0.5045285820960999
Validation loss: 1.7808612649158766

Epoch: 6| Step: 10
Training loss: 1.0413808822631836
Validation loss: 1.7922182339493946

Epoch: 6| Step: 11
Training loss: 0.2974359393119812
Validation loss: 1.7607629811891945

Epoch: 6| Step: 12
Training loss: 0.696120023727417
Validation loss: 1.7835617629430627

Epoch: 6| Step: 13
Training loss: 0.739030122756958
Validation loss: 1.7662401122431601

Epoch: 312| Step: 0
Training loss: 0.7310660481452942
Validation loss: 1.7890838910174627

Epoch: 6| Step: 1
Training loss: 0.4962383508682251
Validation loss: 1.7616021146056473

Epoch: 6| Step: 2
Training loss: 0.6896246671676636
Validation loss: 1.7607654217750794

Epoch: 6| Step: 3
Training loss: 0.3262881338596344
Validation loss: 1.781329062677199

Epoch: 6| Step: 4
Training loss: 0.964780330657959
Validation loss: 1.7777650920293664

Epoch: 6| Step: 5
Training loss: 0.8215474486351013
Validation loss: 1.7830299100568217

Epoch: 6| Step: 6
Training loss: 0.7097776532173157
Validation loss: 1.7689653545297601

Epoch: 6| Step: 7
Training loss: 0.8582530617713928
Validation loss: 1.7991572721030122

Epoch: 6| Step: 8
Training loss: 0.5572739839553833
Validation loss: 1.8322761520262687

Epoch: 6| Step: 9
Training loss: 0.4092959463596344
Validation loss: 1.8365694104984243

Epoch: 6| Step: 10
Training loss: 0.8881655931472778
Validation loss: 1.8357133890992852

Epoch: 6| Step: 11
Training loss: 0.604971706867218
Validation loss: 1.8695762670168312

Epoch: 6| Step: 12
Training loss: 0.6537884473800659
Validation loss: 1.8608741580799062

Epoch: 6| Step: 13
Training loss: 0.4824172258377075
Validation loss: 1.8895393597182406

Epoch: 313| Step: 0
Training loss: 0.3926861882209778
Validation loss: 1.827164480763097

Epoch: 6| Step: 1
Training loss: 0.9590924978256226
Validation loss: 1.8403023737733082

Epoch: 6| Step: 2
Training loss: 0.5099983811378479
Validation loss: 1.7933152555137553

Epoch: 6| Step: 3
Training loss: 0.2821364998817444
Validation loss: 1.7955578962961833

Epoch: 6| Step: 4
Training loss: 0.6335047483444214
Validation loss: 1.7821062816086637

Epoch: 6| Step: 5
Training loss: 0.8581337928771973
Validation loss: 1.7433030451497724

Epoch: 6| Step: 6
Training loss: 0.4875459671020508
Validation loss: 1.745169892106005

Epoch: 6| Step: 7
Training loss: 0.6310033202171326
Validation loss: 1.7447617425713489

Epoch: 6| Step: 8
Training loss: 0.64171302318573
Validation loss: 1.7502351883919007

Epoch: 6| Step: 9
Training loss: 0.7817168831825256
Validation loss: 1.7431433828928138

Epoch: 6| Step: 10
Training loss: 1.009912133216858
Validation loss: 1.7424985401092037

Epoch: 6| Step: 11
Training loss: 0.6504849195480347
Validation loss: 1.8033863447045768

Epoch: 6| Step: 12
Training loss: 0.7377710342407227
Validation loss: 1.8030225833257039

Epoch: 6| Step: 13
Training loss: 0.9483981728553772
Validation loss: 1.8153095181270311

Epoch: 314| Step: 0
Training loss: 0.4431544244289398
Validation loss: 1.8596253818081272

Epoch: 6| Step: 1
Training loss: 0.5322138071060181
Validation loss: 1.8424034375016407

Epoch: 6| Step: 2
Training loss: 0.8592374920845032
Validation loss: 1.8577876155094435

Epoch: 6| Step: 3
Training loss: 0.653989315032959
Validation loss: 1.8345060630511212

Epoch: 6| Step: 4
Training loss: 0.7438495755195618
Validation loss: 1.8264322844884728

Epoch: 6| Step: 5
Training loss: 0.7799212336540222
Validation loss: 1.8279328115524784

Epoch: 6| Step: 6
Training loss: 0.5367981195449829
Validation loss: 1.7916619700770224

Epoch: 6| Step: 7
Training loss: 0.671676516532898
Validation loss: 1.800052696658719

Epoch: 6| Step: 8
Training loss: 0.8259986042976379
Validation loss: 1.807812645871152

Epoch: 6| Step: 9
Training loss: 0.5627212524414062
Validation loss: 1.7949314976251254

Epoch: 6| Step: 10
Training loss: 0.4311434030532837
Validation loss: 1.793256725034406

Epoch: 6| Step: 11
Training loss: 0.42074257135391235
Validation loss: 1.7941871407211467

Epoch: 6| Step: 12
Training loss: 0.6523274183273315
Validation loss: 1.8220394272958078

Epoch: 6| Step: 13
Training loss: 1.3709843158721924
Validation loss: 1.8327588291578396

Epoch: 315| Step: 0
Training loss: 0.6850571632385254
Validation loss: 1.874159110489712

Epoch: 6| Step: 1
Training loss: 0.8229360580444336
Validation loss: 1.8965954011486423

Epoch: 6| Step: 2
Training loss: 0.4435211420059204
Validation loss: 1.8875543661015008

Epoch: 6| Step: 3
Training loss: 0.744368851184845
Validation loss: 1.8891904713005148

Epoch: 6| Step: 4
Training loss: 0.6493797302246094
Validation loss: 1.8512760798136394

Epoch: 6| Step: 5
Training loss: 1.0006312131881714
Validation loss: 1.861793738539501

Epoch: 6| Step: 6
Training loss: 0.4251430630683899
Validation loss: 1.8487722104595554

Epoch: 6| Step: 7
Training loss: 0.687088131904602
Validation loss: 1.8395191956591863

Epoch: 6| Step: 8
Training loss: 0.8958214521408081
Validation loss: 1.8353206419175672

Epoch: 6| Step: 9
Training loss: 0.6036874055862427
Validation loss: 1.7856259051189627

Epoch: 6| Step: 10
Training loss: 0.5191044807434082
Validation loss: 1.7713083913249354

Epoch: 6| Step: 11
Training loss: 0.7673467397689819
Validation loss: 1.7792712732027935

Epoch: 6| Step: 12
Training loss: 0.5690048933029175
Validation loss: 1.7818535374056907

Epoch: 6| Step: 13
Training loss: 0.42428937554359436
Validation loss: 1.7519958262802453

Epoch: 316| Step: 0
Training loss: 0.3926352262496948
Validation loss: 1.7329261482402842

Epoch: 6| Step: 1
Training loss: 0.29413801431655884
Validation loss: 1.7790641887213594

Epoch: 6| Step: 2
Training loss: 0.5075551271438599
Validation loss: 1.8093352612628733

Epoch: 6| Step: 3
Training loss: 0.8083449602127075
Validation loss: 1.7856253577816872

Epoch: 6| Step: 4
Training loss: 0.9746600985527039
Validation loss: 1.8156286093496508

Epoch: 6| Step: 5
Training loss: 0.9454202651977539
Validation loss: 1.817704854472991

Epoch: 6| Step: 6
Training loss: 0.9588866233825684
Validation loss: 1.8325258429332445

Epoch: 6| Step: 7
Training loss: 0.5583984851837158
Validation loss: 1.8447896818960867

Epoch: 6| Step: 8
Training loss: 0.5992633700370789
Validation loss: 1.8409921251317507

Epoch: 6| Step: 9
Training loss: 0.7735930681228638
Validation loss: 1.8613348186656993

Epoch: 6| Step: 10
Training loss: 0.8657312393188477
Validation loss: 1.849767965655173

Epoch: 6| Step: 11
Training loss: 0.33727920055389404
Validation loss: 1.8448699469207435

Epoch: 6| Step: 12
Training loss: 0.45166629552841187
Validation loss: 1.8456938241117744

Epoch: 6| Step: 13
Training loss: 0.4152671694755554
Validation loss: 1.8193929682495773

Epoch: 317| Step: 0
Training loss: 0.4380171298980713
Validation loss: 1.7972402713632072

Epoch: 6| Step: 1
Training loss: 0.4942684769630432
Validation loss: 1.817213576327088

Epoch: 6| Step: 2
Training loss: 0.9447170495986938
Validation loss: 1.8356014156854281

Epoch: 6| Step: 3
Training loss: 0.7511135339736938
Validation loss: 1.8169558253339542

Epoch: 6| Step: 4
Training loss: 0.5545520782470703
Validation loss: 1.8306059209249352

Epoch: 6| Step: 5
Training loss: 0.9029498100280762
Validation loss: 1.806130870696037

Epoch: 6| Step: 6
Training loss: 0.3658725619316101
Validation loss: 1.8056372775826404

Epoch: 6| Step: 7
Training loss: 0.5106757879257202
Validation loss: 1.777692901190891

Epoch: 6| Step: 8
Training loss: 0.7772048115730286
Validation loss: 1.8032159895025275

Epoch: 6| Step: 9
Training loss: 0.5131362676620483
Validation loss: 1.8094598375340945

Epoch: 6| Step: 10
Training loss: 0.3659602403640747
Validation loss: 1.8074654802199333

Epoch: 6| Step: 11
Training loss: 0.9890264868736267
Validation loss: 1.8216009934743245

Epoch: 6| Step: 12
Training loss: 0.3811907172203064
Validation loss: 1.8139432668685913

Epoch: 6| Step: 13
Training loss: 0.7527914047241211
Validation loss: 1.8058801633055492

Epoch: 318| Step: 0
Training loss: 0.9018347263336182
Validation loss: 1.8313647508621216

Epoch: 6| Step: 1
Training loss: 0.5309497714042664
Validation loss: 1.8428668745102421

Epoch: 6| Step: 2
Training loss: 0.7191396951675415
Validation loss: 1.8410408343038251

Epoch: 6| Step: 3
Training loss: 0.4801633358001709
Validation loss: 1.8584176186592347

Epoch: 6| Step: 4
Training loss: 0.4770534038543701
Validation loss: 1.8412081246734948

Epoch: 6| Step: 5
Training loss: 0.6021147966384888
Validation loss: 1.7867424923886535

Epoch: 6| Step: 6
Training loss: 0.3750050663948059
Validation loss: 1.7939278220617643

Epoch: 6| Step: 7
Training loss: 1.2361066341400146
Validation loss: 1.8223290469056816

Epoch: 6| Step: 8
Training loss: 0.5328373908996582
Validation loss: 1.8293294368251678

Epoch: 6| Step: 9
Training loss: 0.557669997215271
Validation loss: 1.826974641892218

Epoch: 6| Step: 10
Training loss: 0.382386714220047
Validation loss: 1.8478325528483237

Epoch: 6| Step: 11
Training loss: 0.5474902391433716
Validation loss: 1.812786691932268

Epoch: 6| Step: 12
Training loss: 0.7814714312553406
Validation loss: 1.8270303421123053

Epoch: 6| Step: 13
Training loss: 0.4390198886394501
Validation loss: 1.809236490598289

Epoch: 319| Step: 0
Training loss: 0.562006950378418
Validation loss: 1.7845558222904

Epoch: 6| Step: 1
Training loss: 0.6011407375335693
Validation loss: 1.8062795208346458

Epoch: 6| Step: 2
Training loss: 0.8452978134155273
Validation loss: 1.8017808519383913

Epoch: 6| Step: 3
Training loss: 0.38171881437301636
Validation loss: 1.8025093206795313

Epoch: 6| Step: 4
Training loss: 0.21578553318977356
Validation loss: 1.8014439575133785

Epoch: 6| Step: 5
Training loss: 0.6650000810623169
Validation loss: 1.818754623013158

Epoch: 6| Step: 6
Training loss: 0.4782731831073761
Validation loss: 1.8404343781932708

Epoch: 6| Step: 7
Training loss: 0.7407323718070984
Validation loss: 1.8162009844215967

Epoch: 6| Step: 8
Training loss: 0.8337203860282898
Validation loss: 1.8395062351739535

Epoch: 6| Step: 9
Training loss: 0.8124538660049438
Validation loss: 1.8221734326372865

Epoch: 6| Step: 10
Training loss: 0.6824387311935425
Validation loss: 1.7834635575612385

Epoch: 6| Step: 11
Training loss: 0.6873739361763
Validation loss: 1.8013135233233053

Epoch: 6| Step: 12
Training loss: 0.5540444850921631
Validation loss: 1.7653711611224758

Epoch: 6| Step: 13
Training loss: 0.5550759434700012
Validation loss: 1.7685013919748285

Epoch: 320| Step: 0
Training loss: 0.5354490280151367
Validation loss: 1.7221716450106712

Epoch: 6| Step: 1
Training loss: 0.6578373908996582
Validation loss: 1.7150090586754583

Epoch: 6| Step: 2
Training loss: 0.549809455871582
Validation loss: 1.7251257640059277

Epoch: 6| Step: 3
Training loss: 0.6238136291503906
Validation loss: 1.7370218794832948

Epoch: 6| Step: 4
Training loss: 0.4822227358818054
Validation loss: 1.758459416768884

Epoch: 6| Step: 5
Training loss: 0.646021842956543
Validation loss: 1.7724682195212251

Epoch: 6| Step: 6
Training loss: 0.6459065675735474
Validation loss: 1.7794245955764607

Epoch: 6| Step: 7
Training loss: 0.6164366006851196
Validation loss: 1.8026229284142936

Epoch: 6| Step: 8
Training loss: 0.3816927969455719
Validation loss: 1.7977477312088013

Epoch: 6| Step: 9
Training loss: 0.5815819501876831
Validation loss: 1.8084075527806436

Epoch: 6| Step: 10
Training loss: 0.5648272037506104
Validation loss: 1.8071443560302898

Epoch: 6| Step: 11
Training loss: 0.6505279541015625
Validation loss: 1.799725704295661

Epoch: 6| Step: 12
Training loss: 0.7305724620819092
Validation loss: 1.8105462725444506

Epoch: 6| Step: 13
Training loss: 0.8136005997657776
Validation loss: 1.7947341293416998

Epoch: 321| Step: 0
Training loss: 0.7961395978927612
Validation loss: 1.789160269562916

Epoch: 6| Step: 1
Training loss: 0.40845853090286255
Validation loss: 1.761376941075889

Epoch: 6| Step: 2
Training loss: 0.4638386368751526
Validation loss: 1.756689715129073

Epoch: 6| Step: 3
Training loss: 0.4424067735671997
Validation loss: 1.7688356689227525

Epoch: 6| Step: 4
Training loss: 0.5457392930984497
Validation loss: 1.7535483080853698

Epoch: 6| Step: 5
Training loss: 0.9409912824630737
Validation loss: 1.7749535781081005

Epoch: 6| Step: 6
Training loss: 0.7042198777198792
Validation loss: 1.7547429069395988

Epoch: 6| Step: 7
Training loss: 0.7049132585525513
Validation loss: 1.7983095581813524

Epoch: 6| Step: 8
Training loss: 0.7508184909820557
Validation loss: 1.78765364872512

Epoch: 6| Step: 9
Training loss: 0.6656352281570435
Validation loss: 1.7984071649530882

Epoch: 6| Step: 10
Training loss: 0.46116867661476135
Validation loss: 1.810495485541641

Epoch: 6| Step: 11
Training loss: 0.5208722352981567
Validation loss: 1.7873736402039886

Epoch: 6| Step: 12
Training loss: 0.6312074065208435
Validation loss: 1.8214435526119765

Epoch: 6| Step: 13
Training loss: 0.44821304082870483
Validation loss: 1.8093926624585224

Epoch: 322| Step: 0
Training loss: 0.5094285011291504
Validation loss: 1.8134012581199728

Epoch: 6| Step: 1
Training loss: 0.40476539731025696
Validation loss: 1.8262578825796805

Epoch: 6| Step: 2
Training loss: 1.0464534759521484
Validation loss: 1.819978796025758

Epoch: 6| Step: 3
Training loss: 0.5112820863723755
Validation loss: 1.8424857765115716

Epoch: 6| Step: 4
Training loss: 0.5148170590400696
Validation loss: 1.8327829248161727

Epoch: 6| Step: 5
Training loss: 0.47541341185569763
Validation loss: 1.8432919069003033

Epoch: 6| Step: 6
Training loss: 0.33255723118782043
Validation loss: 1.8237062192732287

Epoch: 6| Step: 7
Training loss: 0.5945665836334229
Validation loss: 1.8256572933607205

Epoch: 6| Step: 8
Training loss: 0.8953186273574829
Validation loss: 1.8113544666638939

Epoch: 6| Step: 9
Training loss: 0.4463302791118622
Validation loss: 1.8447263471541866

Epoch: 6| Step: 10
Training loss: 0.8156319856643677
Validation loss: 1.8526320342094666

Epoch: 6| Step: 11
Training loss: 0.7069193720817566
Validation loss: 1.842455651170464

Epoch: 6| Step: 12
Training loss: 0.723691463470459
Validation loss: 1.8325538173798592

Epoch: 6| Step: 13
Training loss: 0.37531033158302307
Validation loss: 1.8368704601000714

Epoch: 323| Step: 0
Training loss: 0.4573878049850464
Validation loss: 1.809503157933553

Epoch: 6| Step: 1
Training loss: 0.6729748249053955
Validation loss: 1.8132117691860403

Epoch: 6| Step: 2
Training loss: 0.434504896402359
Validation loss: 1.7804165232566096

Epoch: 6| Step: 3
Training loss: 0.7954557538032532
Validation loss: 1.786974589670858

Epoch: 6| Step: 4
Training loss: 0.49171167612075806
Validation loss: 1.7858535564073952

Epoch: 6| Step: 5
Training loss: 0.37086838483810425
Validation loss: 1.7661377460725847

Epoch: 6| Step: 6
Training loss: 0.4564743638038635
Validation loss: 1.7370590458634079

Epoch: 6| Step: 7
Training loss: 0.8258888721466064
Validation loss: 1.758599700466279

Epoch: 6| Step: 8
Training loss: 0.347168892621994
Validation loss: 1.7584037332124607

Epoch: 6| Step: 9
Training loss: 0.5567585825920105
Validation loss: 1.7785925890809746

Epoch: 6| Step: 10
Training loss: 0.442452073097229
Validation loss: 1.7833947161192536

Epoch: 6| Step: 11
Training loss: 0.8925460577011108
Validation loss: 1.8100796989215318

Epoch: 6| Step: 12
Training loss: 0.691585123538971
Validation loss: 1.8010380204005907

Epoch: 6| Step: 13
Training loss: 0.4787953197956085
Validation loss: 1.829631854129094

Epoch: 324| Step: 0
Training loss: 0.5520866513252258
Validation loss: 1.8498690166781027

Epoch: 6| Step: 1
Training loss: 0.5891799926757812
Validation loss: 1.8336258421662033

Epoch: 6| Step: 2
Training loss: 0.5436553359031677
Validation loss: 1.8300081132560648

Epoch: 6| Step: 3
Training loss: 0.45547860860824585
Validation loss: 1.8411387833215858

Epoch: 6| Step: 4
Training loss: 0.5681648254394531
Validation loss: 1.8368861598353232

Epoch: 6| Step: 5
Training loss: 0.40367603302001953
Validation loss: 1.8299086721994544

Epoch: 6| Step: 6
Training loss: 0.5671798586845398
Validation loss: 1.8072194489099647

Epoch: 6| Step: 7
Training loss: 0.858004093170166
Validation loss: 1.8070642666150165

Epoch: 6| Step: 8
Training loss: 0.5291942358016968
Validation loss: 1.8384673236518778

Epoch: 6| Step: 9
Training loss: 0.57499098777771
Validation loss: 1.822017829905274

Epoch: 6| Step: 10
Training loss: 0.3751713037490845
Validation loss: 1.8145709537690686

Epoch: 6| Step: 11
Training loss: 0.652109682559967
Validation loss: 1.8213548403914257

Epoch: 6| Step: 12
Training loss: 0.6133055090904236
Validation loss: 1.7898235705591017

Epoch: 6| Step: 13
Training loss: 0.6402177810668945
Validation loss: 1.7885276079177856

Epoch: 325| Step: 0
Training loss: 0.42871975898742676
Validation loss: 1.773803121300154

Epoch: 6| Step: 1
Training loss: 0.41936159133911133
Validation loss: 1.776873375779839

Epoch: 6| Step: 2
Training loss: 0.4077213406562805
Validation loss: 1.7662661947229856

Epoch: 6| Step: 3
Training loss: 0.7500724792480469
Validation loss: 1.771853018832463

Epoch: 6| Step: 4
Training loss: 0.7157964110374451
Validation loss: 1.7619141737620037

Epoch: 6| Step: 5
Training loss: 0.7212837934494019
Validation loss: 1.7712533909787413

Epoch: 6| Step: 6
Training loss: 1.0241835117340088
Validation loss: 1.7618284533100743

Epoch: 6| Step: 7
Training loss: 0.48429879546165466
Validation loss: 1.7984652749953731

Epoch: 6| Step: 8
Training loss: 0.5044316053390503
Validation loss: 1.7879198379414056

Epoch: 6| Step: 9
Training loss: 0.7386773824691772
Validation loss: 1.8289408606867636

Epoch: 6| Step: 10
Training loss: 0.43265479803085327
Validation loss: 1.8167119128729707

Epoch: 6| Step: 11
Training loss: 0.6810775399208069
Validation loss: 1.8409363979934363

Epoch: 6| Step: 12
Training loss: 0.2855084538459778
Validation loss: 1.8222559818657496

Epoch: 6| Step: 13
Training loss: 0.4831300377845764
Validation loss: 1.8574771804194297

Epoch: 326| Step: 0
Training loss: 0.7697187066078186
Validation loss: 1.8307855180514756

Epoch: 6| Step: 1
Training loss: 0.7038052082061768
Validation loss: 1.8056341640410885

Epoch: 6| Step: 2
Training loss: 0.24847553670406342
Validation loss: 1.8068646205368863

Epoch: 6| Step: 3
Training loss: 0.5588818788528442
Validation loss: 1.825954980747674

Epoch: 6| Step: 4
Training loss: 0.3849242031574249
Validation loss: 1.7843703044358121

Epoch: 6| Step: 5
Training loss: 0.3272246718406677
Validation loss: 1.817516114122124

Epoch: 6| Step: 6
Training loss: 0.4301365613937378
Validation loss: 1.7894759011524979

Epoch: 6| Step: 7
Training loss: 0.6323984861373901
Validation loss: 1.769557620889397

Epoch: 6| Step: 8
Training loss: 0.8228104710578918
Validation loss: 1.7491453360485774

Epoch: 6| Step: 9
Training loss: 0.637493371963501
Validation loss: 1.7642537970696726

Epoch: 6| Step: 10
Training loss: 0.4692520499229431
Validation loss: 1.7972002349874026

Epoch: 6| Step: 11
Training loss: 0.6259560585021973
Validation loss: 1.7910171529298187

Epoch: 6| Step: 12
Training loss: 0.7071864008903503
Validation loss: 1.7705303539511978

Epoch: 6| Step: 13
Training loss: 0.6572592258453369
Validation loss: 1.7769810666320145

Epoch: 327| Step: 0
Training loss: 0.6612412333488464
Validation loss: 1.7256575835648404

Epoch: 6| Step: 1
Training loss: 0.4341500997543335
Validation loss: 1.752779012085289

Epoch: 6| Step: 2
Training loss: 0.5756549835205078
Validation loss: 1.7746760665729482

Epoch: 6| Step: 3
Training loss: 0.7712802886962891
Validation loss: 1.745513319328267

Epoch: 6| Step: 4
Training loss: 0.5001615285873413
Validation loss: 1.7766117126710954

Epoch: 6| Step: 5
Training loss: 0.5531352758407593
Validation loss: 1.7594009740378267

Epoch: 6| Step: 6
Training loss: 0.40201812982559204
Validation loss: 1.7597495163640668

Epoch: 6| Step: 7
Training loss: 0.7889578342437744
Validation loss: 1.735554418256206

Epoch: 6| Step: 8
Training loss: 0.5051601529121399
Validation loss: 1.753689880012184

Epoch: 6| Step: 9
Training loss: 0.712769091129303
Validation loss: 1.746603883722777

Epoch: 6| Step: 10
Training loss: 0.6623712778091431
Validation loss: 1.7446695784086823

Epoch: 6| Step: 11
Training loss: 0.4444647431373596
Validation loss: 1.731222851302034

Epoch: 6| Step: 12
Training loss: 0.3557402789592743
Validation loss: 1.730462404989427

Epoch: 6| Step: 13
Training loss: 0.8301454186439514
Validation loss: 1.7889877070662796

Epoch: 328| Step: 0
Training loss: 1.204761266708374
Validation loss: 1.8081626046088435

Epoch: 6| Step: 1
Training loss: 0.46963581442832947
Validation loss: 1.8090726854980632

Epoch: 6| Step: 2
Training loss: 0.666810154914856
Validation loss: 1.816755046126663

Epoch: 6| Step: 3
Training loss: 0.3986099660396576
Validation loss: 1.8346016560831377

Epoch: 6| Step: 4
Training loss: 0.5237072706222534
Validation loss: 1.8451399162251463

Epoch: 6| Step: 5
Training loss: 0.6434184908866882
Validation loss: 1.8290464749900244

Epoch: 6| Step: 6
Training loss: 0.6117199659347534
Validation loss: 1.822846354976777

Epoch: 6| Step: 7
Training loss: 0.5427644848823547
Validation loss: 1.8004115038020636

Epoch: 6| Step: 8
Training loss: 0.3459005355834961
Validation loss: 1.7877275033663678

Epoch: 6| Step: 9
Training loss: 0.40166908502578735
Validation loss: 1.7675013734448342

Epoch: 6| Step: 10
Training loss: 0.45346778631210327
Validation loss: 1.7954704300049813

Epoch: 6| Step: 11
Training loss: 0.46863502264022827
Validation loss: 1.7658585604800974

Epoch: 6| Step: 12
Training loss: 0.6181355714797974
Validation loss: 1.7766628137198828

Epoch: 6| Step: 13
Training loss: 0.3341361880302429
Validation loss: 1.7569593139874038

Epoch: 329| Step: 0
Training loss: 0.45174944400787354
Validation loss: 1.7588081705954768

Epoch: 6| Step: 1
Training loss: 0.7805203199386597
Validation loss: 1.7796289433715164

Epoch: 6| Step: 2
Training loss: 0.522302508354187
Validation loss: 1.7698120045405563

Epoch: 6| Step: 3
Training loss: 0.46367311477661133
Validation loss: 1.754223322355619

Epoch: 6| Step: 4
Training loss: 0.5395742058753967
Validation loss: 1.7751174742175686

Epoch: 6| Step: 5
Training loss: 0.6090601682662964
Validation loss: 1.7919301050965504

Epoch: 6| Step: 6
Training loss: 0.5159531831741333
Validation loss: 1.7915522244668776

Epoch: 6| Step: 7
Training loss: 0.48718273639678955
Validation loss: 1.792991425401421

Epoch: 6| Step: 8
Training loss: 0.5712359547615051
Validation loss: 1.813642753067837

Epoch: 6| Step: 9
Training loss: 0.4847991466522217
Validation loss: 1.8240383466084797

Epoch: 6| Step: 10
Training loss: 0.5753781199455261
Validation loss: 1.8014302894633303

Epoch: 6| Step: 11
Training loss: 0.3243687152862549
Validation loss: 1.8084858463656517

Epoch: 6| Step: 12
Training loss: 0.7605710029602051
Validation loss: 1.805477576871072

Epoch: 6| Step: 13
Training loss: 0.35297709703445435
Validation loss: 1.7788174254919893

Epoch: 330| Step: 0
Training loss: 0.3659811019897461
Validation loss: 1.7883550313211256

Epoch: 6| Step: 1
Training loss: 0.5486617088317871
Validation loss: 1.7948777970447336

Epoch: 6| Step: 2
Training loss: 0.5120569467544556
Validation loss: 1.8103570553564257

Epoch: 6| Step: 3
Training loss: 0.5521114468574524
Validation loss: 1.7704731264422018

Epoch: 6| Step: 4
Training loss: 0.4117492735385895
Validation loss: 1.8060325461049234

Epoch: 6| Step: 5
Training loss: 0.3264208137989044
Validation loss: 1.7814473682834255

Epoch: 6| Step: 6
Training loss: 1.0445144176483154
Validation loss: 1.787045698012075

Epoch: 6| Step: 7
Training loss: 0.6316747665405273
Validation loss: 1.7786777198955577

Epoch: 6| Step: 8
Training loss: 0.32179951667785645
Validation loss: 1.7872235108447332

Epoch: 6| Step: 9
Training loss: 0.4935838580131531
Validation loss: 1.7842192393477245

Epoch: 6| Step: 10
Training loss: 0.7322826981544495
Validation loss: 1.8028144605698124

Epoch: 6| Step: 11
Training loss: 0.385845422744751
Validation loss: 1.805140741409794

Epoch: 6| Step: 12
Training loss: 0.4377637505531311
Validation loss: 1.8234853667597617

Epoch: 6| Step: 13
Training loss: 0.6564772129058838
Validation loss: 1.80523399255609

Epoch: 331| Step: 0
Training loss: 0.5369641184806824
Validation loss: 1.8247049521374445

Epoch: 6| Step: 1
Training loss: 0.6420549750328064
Validation loss: 1.8283795746423865

Epoch: 6| Step: 2
Training loss: 0.5692868232727051
Validation loss: 1.8233726665537844

Epoch: 6| Step: 3
Training loss: 0.6236859560012817
Validation loss: 1.8132347881153066

Epoch: 6| Step: 4
Training loss: 0.8473652005195618
Validation loss: 1.8308047761199295

Epoch: 6| Step: 5
Training loss: 0.4109501242637634
Validation loss: 1.8136886819716422

Epoch: 6| Step: 6
Training loss: 0.5402834415435791
Validation loss: 1.7872164928784935

Epoch: 6| Step: 7
Training loss: 0.3808278441429138
Validation loss: 1.7746578935653932

Epoch: 6| Step: 8
Training loss: 0.40431541204452515
Validation loss: 1.7647555002602198

Epoch: 6| Step: 9
Training loss: 0.4487541913986206
Validation loss: 1.7754782271641556

Epoch: 6| Step: 10
Training loss: 0.4393259286880493
Validation loss: 1.7590858782491376

Epoch: 6| Step: 11
Training loss: 0.27870187163352966
Validation loss: 1.7683551362765733

Epoch: 6| Step: 12
Training loss: 0.5656529664993286
Validation loss: 1.785860361591462

Epoch: 6| Step: 13
Training loss: 0.6673253178596497
Validation loss: 1.7830923065062492

Epoch: 332| Step: 0
Training loss: 0.36251336336135864
Validation loss: 1.7773364308059856

Epoch: 6| Step: 1
Training loss: 0.34582412242889404
Validation loss: 1.7925503856392317

Epoch: 6| Step: 2
Training loss: 0.6413350105285645
Validation loss: 1.7848180122272943

Epoch: 6| Step: 3
Training loss: 0.5735738277435303
Validation loss: 1.7876818885085404

Epoch: 6| Step: 4
Training loss: 0.36370620131492615
Validation loss: 1.7998450225399387

Epoch: 6| Step: 5
Training loss: 0.784079909324646
Validation loss: 1.8102474046009842

Epoch: 6| Step: 6
Training loss: 0.8826801180839539
Validation loss: 1.7895201329262025

Epoch: 6| Step: 7
Training loss: 0.3863111138343811
Validation loss: 1.7689378159020537

Epoch: 6| Step: 8
Training loss: 0.5524613261222839
Validation loss: 1.7412595928356212

Epoch: 6| Step: 9
Training loss: 0.410740464925766
Validation loss: 1.7525788443062895

Epoch: 6| Step: 10
Training loss: 0.3717063069343567
Validation loss: 1.7414702830776092

Epoch: 6| Step: 11
Training loss: 0.36441946029663086
Validation loss: 1.7608964802116476

Epoch: 6| Step: 12
Training loss: 0.6084063053131104
Validation loss: 1.7314224166254844

Epoch: 6| Step: 13
Training loss: 0.4518168866634369
Validation loss: 1.7406645333895119

Epoch: 333| Step: 0
Training loss: 0.19039583206176758
Validation loss: 1.7336800816238567

Epoch: 6| Step: 1
Training loss: 0.34496766328811646
Validation loss: 1.757367096921449

Epoch: 6| Step: 2
Training loss: 0.3252279758453369
Validation loss: 1.778143649460167

Epoch: 6| Step: 3
Training loss: 0.848177433013916
Validation loss: 1.8265280928663028

Epoch: 6| Step: 4
Training loss: 0.5178083181381226
Validation loss: 1.869161282816241

Epoch: 6| Step: 5
Training loss: 0.5064518451690674
Validation loss: 1.8526400058500228

Epoch: 6| Step: 6
Training loss: 0.6494515538215637
Validation loss: 1.854636005176011

Epoch: 6| Step: 7
Training loss: 0.5942463278770447
Validation loss: 1.852980294535237

Epoch: 6| Step: 8
Training loss: 0.4873681664466858
Validation loss: 1.8370525119125203

Epoch: 6| Step: 9
Training loss: 1.06997811794281
Validation loss: 1.8269718577784877

Epoch: 6| Step: 10
Training loss: 0.5368466377258301
Validation loss: 1.8069079409363449

Epoch: 6| Step: 11
Training loss: 0.6132469177246094
Validation loss: 1.786005267532923

Epoch: 6| Step: 12
Training loss: 0.40171897411346436
Validation loss: 1.7725935623209963

Epoch: 6| Step: 13
Training loss: 0.29327577352523804
Validation loss: 1.7520771045838632

Epoch: 334| Step: 0
Training loss: 0.4254058599472046
Validation loss: 1.7626286732253207

Epoch: 6| Step: 1
Training loss: 0.5665078163146973
Validation loss: 1.7551331853353849

Epoch: 6| Step: 2
Training loss: 0.6593483686447144
Validation loss: 1.780197948537847

Epoch: 6| Step: 3
Training loss: 0.5883925557136536
Validation loss: 1.7582496366193217

Epoch: 6| Step: 4
Training loss: 0.35702502727508545
Validation loss: 1.7708788712819417

Epoch: 6| Step: 5
Training loss: 0.5264452695846558
Validation loss: 1.75457638566212

Epoch: 6| Step: 6
Training loss: 0.3624526262283325
Validation loss: 1.742598759230747

Epoch: 6| Step: 7
Training loss: 0.6720650792121887
Validation loss: 1.7265315645484514

Epoch: 6| Step: 8
Training loss: 0.5130365490913391
Validation loss: 1.7291645234630955

Epoch: 6| Step: 9
Training loss: 0.3774186074733734
Validation loss: 1.733886908459407

Epoch: 6| Step: 10
Training loss: 0.3886532783508301
Validation loss: 1.73722396614731

Epoch: 6| Step: 11
Training loss: 0.6133604645729065
Validation loss: 1.7739358307212911

Epoch: 6| Step: 12
Training loss: 0.6210460662841797
Validation loss: 1.7679144925968622

Epoch: 6| Step: 13
Training loss: 0.5393715500831604
Validation loss: 1.7695401983876382

Epoch: 335| Step: 0
Training loss: 0.40123850107192993
Validation loss: 1.8086390687573342

Epoch: 6| Step: 1
Training loss: 0.46842727065086365
Validation loss: 1.8444265883455995

Epoch: 6| Step: 2
Training loss: 0.3705996870994568
Validation loss: 1.840035379573863

Epoch: 6| Step: 3
Training loss: 0.5243141651153564
Validation loss: 1.8345839438899871

Epoch: 6| Step: 4
Training loss: 1.1879525184631348
Validation loss: 1.855417997606339

Epoch: 6| Step: 5
Training loss: 0.44744613766670227
Validation loss: 1.826484235384131

Epoch: 6| Step: 6
Training loss: 0.4081534147262573
Validation loss: 1.8154879564880042

Epoch: 6| Step: 7
Training loss: 0.9780663251876831
Validation loss: 1.7850890492880216

Epoch: 6| Step: 8
Training loss: 0.4178377389907837
Validation loss: 1.797697890189386

Epoch: 6| Step: 9
Training loss: 0.352841854095459
Validation loss: 1.77013833420251

Epoch: 6| Step: 10
Training loss: 0.2415265142917633
Validation loss: 1.748052663700555

Epoch: 6| Step: 11
Training loss: 0.6166689395904541
Validation loss: 1.770438414747997

Epoch: 6| Step: 12
Training loss: 0.5217198133468628
Validation loss: 1.7649409232601043

Epoch: 6| Step: 13
Training loss: 0.3135162591934204
Validation loss: 1.7675317102862942

Epoch: 336| Step: 0
Training loss: 0.47828370332717896
Validation loss: 1.7666111799978441

Epoch: 6| Step: 1
Training loss: 0.6478868722915649
Validation loss: 1.767778750388853

Epoch: 6| Step: 2
Training loss: 0.2048388421535492
Validation loss: 1.7542904435947377

Epoch: 6| Step: 3
Training loss: 0.5803947448730469
Validation loss: 1.7311457626281246

Epoch: 6| Step: 4
Training loss: 0.7223353385925293
Validation loss: 1.744976015501125

Epoch: 6| Step: 5
Training loss: 0.44841304421424866
Validation loss: 1.7707800647263885

Epoch: 6| Step: 6
Training loss: 0.561285138130188
Validation loss: 1.7643879472568471

Epoch: 6| Step: 7
Training loss: 0.5493199825286865
Validation loss: 1.763069498923517

Epoch: 6| Step: 8
Training loss: 0.5941284894943237
Validation loss: 1.7780229981227587

Epoch: 6| Step: 9
Training loss: 0.33172833919525146
Validation loss: 1.7885832402013964

Epoch: 6| Step: 10
Training loss: 0.7059212923049927
Validation loss: 1.7741762809855963

Epoch: 6| Step: 11
Training loss: 0.276964008808136
Validation loss: 1.7645815431430776

Epoch: 6| Step: 12
Training loss: 0.3330218195915222
Validation loss: 1.757369734907663

Epoch: 6| Step: 13
Training loss: 0.4880293607711792
Validation loss: 1.7628963993441673

Epoch: 337| Step: 0
Training loss: 0.2840210497379303
Validation loss: 1.7451140688311668

Epoch: 6| Step: 1
Training loss: 0.31140029430389404
Validation loss: 1.754674014224801

Epoch: 6| Step: 2
Training loss: 0.3907904624938965
Validation loss: 1.7619415047348186

Epoch: 6| Step: 3
Training loss: 0.7502943277359009
Validation loss: 1.7413383299304592

Epoch: 6| Step: 4
Training loss: 0.4467526078224182
Validation loss: 1.757786553393128

Epoch: 6| Step: 5
Training loss: 0.46978503465652466
Validation loss: 1.7492253639364754

Epoch: 6| Step: 6
Training loss: 0.30632948875427246
Validation loss: 1.7325327524574854

Epoch: 6| Step: 7
Training loss: 0.6419682502746582
Validation loss: 1.7697238947755547

Epoch: 6| Step: 8
Training loss: 0.43575501441955566
Validation loss: 1.7622048213917723

Epoch: 6| Step: 9
Training loss: 1.002946138381958
Validation loss: 1.7714234987894695

Epoch: 6| Step: 10
Training loss: 0.5516401529312134
Validation loss: 1.7712423750149306

Epoch: 6| Step: 11
Training loss: 0.5240402221679688
Validation loss: 1.7971811576556134

Epoch: 6| Step: 12
Training loss: 0.47155389189720154
Validation loss: 1.8053878814943376

Epoch: 6| Step: 13
Training loss: 0.778692901134491
Validation loss: 1.789477748896486

Epoch: 338| Step: 0
Training loss: 0.49621906876564026
Validation loss: 1.8031621709946664

Epoch: 6| Step: 1
Training loss: 0.7943022847175598
Validation loss: 1.8167768152811195

Epoch: 6| Step: 2
Training loss: 0.3497363328933716
Validation loss: 1.786402335730932

Epoch: 6| Step: 3
Training loss: 0.5382758378982544
Validation loss: 1.792729111127956

Epoch: 6| Step: 4
Training loss: 0.6055314540863037
Validation loss: 1.764659240681638

Epoch: 6| Step: 5
Training loss: 0.4774499535560608
Validation loss: 1.769155365164562

Epoch: 6| Step: 6
Training loss: 0.3345305919647217
Validation loss: 1.7490595797056794

Epoch: 6| Step: 7
Training loss: 0.8518800735473633
Validation loss: 1.7669701383959862

Epoch: 6| Step: 8
Training loss: 0.5547860860824585
Validation loss: 1.7491321204811014

Epoch: 6| Step: 9
Training loss: 0.39890873432159424
Validation loss: 1.7403656321187173

Epoch: 6| Step: 10
Training loss: 0.22859269380569458
Validation loss: 1.7558055129102481

Epoch: 6| Step: 11
Training loss: 0.5425317287445068
Validation loss: 1.7421617059297458

Epoch: 6| Step: 12
Training loss: 0.3275309205055237
Validation loss: 1.758445232145248

Epoch: 6| Step: 13
Training loss: 0.6047602295875549
Validation loss: 1.744089275278071

Epoch: 339| Step: 0
Training loss: 0.9012653231620789
Validation loss: 1.7692979599839898

Epoch: 6| Step: 1
Training loss: 0.5108987092971802
Validation loss: 1.733213299064226

Epoch: 6| Step: 2
Training loss: 0.5816798806190491
Validation loss: 1.741849672409796

Epoch: 6| Step: 3
Training loss: 0.5962581038475037
Validation loss: 1.7516255391541349

Epoch: 6| Step: 4
Training loss: 0.30705201625823975
Validation loss: 1.777233048151898

Epoch: 6| Step: 5
Training loss: 0.4218117296695709
Validation loss: 1.7836158147422216

Epoch: 6| Step: 6
Training loss: 0.34462207555770874
Validation loss: 1.7920973723934543

Epoch: 6| Step: 7
Training loss: 0.3254011273384094
Validation loss: 1.7978479323848602

Epoch: 6| Step: 8
Training loss: 0.4080033302307129
Validation loss: 1.8002006905053252

Epoch: 6| Step: 9
Training loss: 0.5379403233528137
Validation loss: 1.7738827672055972

Epoch: 6| Step: 10
Training loss: 0.4118180274963379
Validation loss: 1.7135918832594348

Epoch: 6| Step: 11
Training loss: 0.30223268270492554
Validation loss: 1.6899095478878225

Epoch: 6| Step: 12
Training loss: 0.6206706166267395
Validation loss: 1.6886197367022115

Epoch: 6| Step: 13
Training loss: 0.5766702890396118
Validation loss: 1.6853704926788167

Epoch: 340| Step: 0
Training loss: 0.4857822358608246
Validation loss: 1.673919044515138

Epoch: 6| Step: 1
Training loss: 0.45977726578712463
Validation loss: 1.6790575968321932

Epoch: 6| Step: 2
Training loss: 0.29514768719673157
Validation loss: 1.6814386472907117

Epoch: 6| Step: 3
Training loss: 0.3335114121437073
Validation loss: 1.6768491242521553

Epoch: 6| Step: 4
Training loss: 0.5920243859291077
Validation loss: 1.685821238384452

Epoch: 6| Step: 5
Training loss: 0.5846095085144043
Validation loss: 1.6999774799552014

Epoch: 6| Step: 6
Training loss: 0.44762539863586426
Validation loss: 1.7163231270287627

Epoch: 6| Step: 7
Training loss: 0.40380898118019104
Validation loss: 1.7240652717569822

Epoch: 6| Step: 8
Training loss: 0.40074360370635986
Validation loss: 1.708455131899926

Epoch: 6| Step: 9
Training loss: 0.6415280699729919
Validation loss: 1.7273459383236465

Epoch: 6| Step: 10
Training loss: 0.4976693391799927
Validation loss: 1.7759324184028051

Epoch: 6| Step: 11
Training loss: 0.5871034860610962
Validation loss: 1.7627008063818819

Epoch: 6| Step: 12
Training loss: 0.6598314046859741
Validation loss: 1.786168021540488

Epoch: 6| Step: 13
Training loss: 0.5574209690093994
Validation loss: 1.8048110110785371

Epoch: 341| Step: 0
Training loss: 0.21495483815670013
Validation loss: 1.7871324913476103

Epoch: 6| Step: 1
Training loss: 0.4349736273288727
Validation loss: 1.8170740835128292

Epoch: 6| Step: 2
Training loss: 0.5457290410995483
Validation loss: 1.8003235042736094

Epoch: 6| Step: 3
Training loss: 0.24937625229358673
Validation loss: 1.7785086913775372

Epoch: 6| Step: 4
Training loss: 0.5220186114311218
Validation loss: 1.7654672194552679

Epoch: 6| Step: 5
Training loss: 0.5299257636070251
Validation loss: 1.769979933256744

Epoch: 6| Step: 6
Training loss: 0.3485463857650757
Validation loss: 1.780140499914846

Epoch: 6| Step: 7
Training loss: 0.38599997758865356
Validation loss: 1.7754936090079687

Epoch: 6| Step: 8
Training loss: 0.41709694266319275
Validation loss: 1.793977282380545

Epoch: 6| Step: 9
Training loss: 0.4908076524734497
Validation loss: 1.7769919108319026

Epoch: 6| Step: 10
Training loss: 0.5945132970809937
Validation loss: 1.7774802433547152

Epoch: 6| Step: 11
Training loss: 0.16697607934474945
Validation loss: 1.7503758540717504

Epoch: 6| Step: 12
Training loss: 0.7292301654815674
Validation loss: 1.7475625238110941

Epoch: 6| Step: 13
Training loss: 0.9696517586708069
Validation loss: 1.7360683538580453

Epoch: 342| Step: 0
Training loss: 0.47497934103012085
Validation loss: 1.7335799278751496

Epoch: 6| Step: 1
Training loss: 0.23038603365421295
Validation loss: 1.717423508244176

Epoch: 6| Step: 2
Training loss: 0.7722768187522888
Validation loss: 1.7251323179532123

Epoch: 6| Step: 3
Training loss: 0.33522313833236694
Validation loss: 1.763992928689526

Epoch: 6| Step: 4
Training loss: 0.23909756541252136
Validation loss: 1.7373468927157822

Epoch: 6| Step: 5
Training loss: 0.5446487665176392
Validation loss: 1.7319496664949643

Epoch: 6| Step: 6
Training loss: 0.38972949981689453
Validation loss: 1.7246953697614773

Epoch: 6| Step: 7
Training loss: 0.2691882848739624
Validation loss: 1.7495074682338263

Epoch: 6| Step: 8
Training loss: 0.8632370829582214
Validation loss: 1.7542195512402443

Epoch: 6| Step: 9
Training loss: 0.42131978273391724
Validation loss: 1.7485733032226562

Epoch: 6| Step: 10
Training loss: 0.5272085070610046
Validation loss: 1.732993846298546

Epoch: 6| Step: 11
Training loss: 0.4159414768218994
Validation loss: 1.7554638155045048

Epoch: 6| Step: 12
Training loss: 0.27934372425079346
Validation loss: 1.7801652877561507

Epoch: 6| Step: 13
Training loss: 0.7738933563232422
Validation loss: 1.792206242520322

Epoch: 343| Step: 0
Training loss: 0.547718346118927
Validation loss: 1.777600775482834

Epoch: 6| Step: 1
Training loss: 0.3817386031150818
Validation loss: 1.763464327781431

Epoch: 6| Step: 2
Training loss: 0.7500462532043457
Validation loss: 1.7703617683020971

Epoch: 6| Step: 3
Training loss: 0.5796065926551819
Validation loss: 1.7574702142387308

Epoch: 6| Step: 4
Training loss: 0.22419455647468567
Validation loss: 1.7687353498192244

Epoch: 6| Step: 5
Training loss: 0.36287593841552734
Validation loss: 1.7307974651295652

Epoch: 6| Step: 6
Training loss: 0.5366083383560181
Validation loss: 1.7351409466035905

Epoch: 6| Step: 7
Training loss: 0.43379998207092285
Validation loss: 1.6983082461100754

Epoch: 6| Step: 8
Training loss: 0.44563835859298706
Validation loss: 1.7367050288825907

Epoch: 6| Step: 9
Training loss: 0.5193570852279663
Validation loss: 1.7405473288669382

Epoch: 6| Step: 10
Training loss: 0.5076489448547363
Validation loss: 1.731377290141198

Epoch: 6| Step: 11
Training loss: 0.36419185996055603
Validation loss: 1.7524652891261603

Epoch: 6| Step: 12
Training loss: 0.26754939556121826
Validation loss: 1.7465532466929445

Epoch: 6| Step: 13
Training loss: 0.4778771996498108
Validation loss: 1.7476649412544825

Epoch: 344| Step: 0
Training loss: 0.547417402267456
Validation loss: 1.7598688910084386

Epoch: 6| Step: 1
Training loss: 0.33990752696990967
Validation loss: 1.7440095242633615

Epoch: 6| Step: 2
Training loss: 0.34339290857315063
Validation loss: 1.7465983488226449

Epoch: 6| Step: 3
Training loss: 0.8951383233070374
Validation loss: 1.7294028036056026

Epoch: 6| Step: 4
Training loss: 0.5768006443977356
Validation loss: 1.7335868612412484

Epoch: 6| Step: 5
Training loss: 0.6621383428573608
Validation loss: 1.7347877589605187

Epoch: 6| Step: 6
Training loss: 0.5514973402023315
Validation loss: 1.7447135512546827

Epoch: 6| Step: 7
Training loss: 0.2369840145111084
Validation loss: 1.750328484401908

Epoch: 6| Step: 8
Training loss: 0.3844441771507263
Validation loss: 1.7730021989473732

Epoch: 6| Step: 9
Training loss: 0.5354574918746948
Validation loss: 1.7532660038240495

Epoch: 6| Step: 10
Training loss: 0.3211836814880371
Validation loss: 1.778989262478326

Epoch: 6| Step: 11
Training loss: 0.22059455513954163
Validation loss: 1.781205338816489

Epoch: 6| Step: 12
Training loss: 0.4804682433605194
Validation loss: 1.8019457247949415

Epoch: 6| Step: 13
Training loss: 0.15267477929592133
Validation loss: 1.8007830368575228

Epoch: 345| Step: 0
Training loss: 0.7955095767974854
Validation loss: 1.8364080972568964

Epoch: 6| Step: 1
Training loss: 0.6067893505096436
Validation loss: 1.8267904789217058

Epoch: 6| Step: 2
Training loss: 0.4054970443248749
Validation loss: 1.7839493623343847

Epoch: 6| Step: 3
Training loss: 0.4324437379837036
Validation loss: 1.7665401427976546

Epoch: 6| Step: 4
Training loss: 0.2654575705528259
Validation loss: 1.7448999599743915

Epoch: 6| Step: 5
Training loss: 0.6356407403945923
Validation loss: 1.754689895978538

Epoch: 6| Step: 6
Training loss: 0.5107153058052063
Validation loss: 1.726305280962298

Epoch: 6| Step: 7
Training loss: 0.3221067190170288
Validation loss: 1.7520081971281318

Epoch: 6| Step: 8
Training loss: 0.3063344359397888
Validation loss: 1.747709140982679

Epoch: 6| Step: 9
Training loss: 0.676131010055542
Validation loss: 1.7500431140263875

Epoch: 6| Step: 10
Training loss: 0.19912314414978027
Validation loss: 1.7542502546823153

Epoch: 6| Step: 11
Training loss: 0.2971366047859192
Validation loss: 1.7590222512522051

Epoch: 6| Step: 12
Training loss: 0.38353776931762695
Validation loss: 1.7842828201991257

Epoch: 6| Step: 13
Training loss: 0.22558826208114624
Validation loss: 1.7724149714234054

Epoch: 346| Step: 0
Training loss: 0.25244849920272827
Validation loss: 1.7608614890806136

Epoch: 6| Step: 1
Training loss: 0.3062936067581177
Validation loss: 1.7617844689276911

Epoch: 6| Step: 2
Training loss: 0.5061586499214172
Validation loss: 1.7620311821660688

Epoch: 6| Step: 3
Training loss: 0.3171504735946655
Validation loss: 1.7512450705292404

Epoch: 6| Step: 4
Training loss: 0.31598085165023804
Validation loss: 1.7557017828828545

Epoch: 6| Step: 5
Training loss: 0.4218110144138336
Validation loss: 1.7562936018872004

Epoch: 6| Step: 6
Training loss: 0.6362920999526978
Validation loss: 1.750319383477652

Epoch: 6| Step: 7
Training loss: 0.5399306416511536
Validation loss: 1.7351820263811337

Epoch: 6| Step: 8
Training loss: 0.2592248320579529
Validation loss: 1.784636385979191

Epoch: 6| Step: 9
Training loss: 0.5846958160400391
Validation loss: 1.7812174366366478

Epoch: 6| Step: 10
Training loss: 0.4472424387931824
Validation loss: 1.783553026055777

Epoch: 6| Step: 11
Training loss: 0.5796119570732117
Validation loss: 1.8190546804858791

Epoch: 6| Step: 12
Training loss: 0.3742454946041107
Validation loss: 1.8135891217057423

Epoch: 6| Step: 13
Training loss: 0.37135905027389526
Validation loss: 1.7928694781436716

Epoch: 347| Step: 0
Training loss: 0.8427074551582336
Validation loss: 1.782053562902635

Epoch: 6| Step: 1
Training loss: 0.3024139404296875
Validation loss: 1.8070259683875627

Epoch: 6| Step: 2
Training loss: 0.4151294231414795
Validation loss: 1.7968863620552966

Epoch: 6| Step: 3
Training loss: 0.2755730152130127
Validation loss: 1.804480948755818

Epoch: 6| Step: 4
Training loss: 0.3660871982574463
Validation loss: 1.7584375335324196

Epoch: 6| Step: 5
Training loss: 0.3366377651691437
Validation loss: 1.7522103222467567

Epoch: 6| Step: 6
Training loss: 0.44920819997787476
Validation loss: 1.7608593074224328

Epoch: 6| Step: 7
Training loss: 0.2719387412071228
Validation loss: 1.7450178182253273

Epoch: 6| Step: 8
Training loss: 0.6174229383468628
Validation loss: 1.764019860375312

Epoch: 6| Step: 9
Training loss: 0.3547394573688507
Validation loss: 1.7381861338051416

Epoch: 6| Step: 10
Training loss: 0.25932830572128296
Validation loss: 1.7530639210054952

Epoch: 6| Step: 11
Training loss: 0.6269736886024475
Validation loss: 1.729593579487134

Epoch: 6| Step: 12
Training loss: 0.32740747928619385
Validation loss: 1.766619933548794

Epoch: 6| Step: 13
Training loss: 0.39006587862968445
Validation loss: 1.7859382796031174

Epoch: 348| Step: 0
Training loss: 0.3877345323562622
Validation loss: 1.7751914506317468

Epoch: 6| Step: 1
Training loss: 0.42323505878448486
Validation loss: 1.7524569944668842

Epoch: 6| Step: 2
Training loss: 0.5750527381896973
Validation loss: 1.771855136399628

Epoch: 6| Step: 3
Training loss: 0.37681323289871216
Validation loss: 1.7600402934576875

Epoch: 6| Step: 4
Training loss: 0.7805646657943726
Validation loss: 1.7260647781433598

Epoch: 6| Step: 5
Training loss: 0.7388333082199097
Validation loss: 1.7394244017139557

Epoch: 6| Step: 6
Training loss: 0.2873210310935974
Validation loss: 1.7357530234962382

Epoch: 6| Step: 7
Training loss: 0.4429481029510498
Validation loss: 1.725999648853015

Epoch: 6| Step: 8
Training loss: 0.28560835123062134
Validation loss: 1.7477195134726904

Epoch: 6| Step: 9
Training loss: 0.40348708629608154
Validation loss: 1.7392212114026468

Epoch: 6| Step: 10
Training loss: 0.38109588623046875
Validation loss: 1.752386563567705

Epoch: 6| Step: 11
Training loss: 0.27546796202659607
Validation loss: 1.7610804009181198

Epoch: 6| Step: 12
Training loss: 0.45201876759529114
Validation loss: 1.760501180925677

Epoch: 6| Step: 13
Training loss: 0.24690228700637817
Validation loss: 1.7586455011880526

Epoch: 349| Step: 0
Training loss: 0.7005475759506226
Validation loss: 1.754541172776171

Epoch: 6| Step: 1
Training loss: 0.25197333097457886
Validation loss: 1.7463977208701513

Epoch: 6| Step: 2
Training loss: 0.22568275034427643
Validation loss: 1.7389818686310963

Epoch: 6| Step: 3
Training loss: 0.5161054134368896
Validation loss: 1.7454475754050798

Epoch: 6| Step: 4
Training loss: 0.3950980305671692
Validation loss: 1.7431691205629738

Epoch: 6| Step: 5
Training loss: 0.4627489447593689
Validation loss: 1.6989837436265842

Epoch: 6| Step: 6
Training loss: 0.46705615520477295
Validation loss: 1.7380555739966772

Epoch: 6| Step: 7
Training loss: 0.40104007720947266
Validation loss: 1.715242793483119

Epoch: 6| Step: 8
Training loss: 0.31792593002319336
Validation loss: 1.736863233709848

Epoch: 6| Step: 9
Training loss: 0.36396217346191406
Validation loss: 1.7386871819855065

Epoch: 6| Step: 10
Training loss: 0.5512188076972961
Validation loss: 1.7332487997188364

Epoch: 6| Step: 11
Training loss: 0.35064852237701416
Validation loss: 1.7469598131795083

Epoch: 6| Step: 12
Training loss: 0.4013698995113373
Validation loss: 1.7482286114846506

Epoch: 6| Step: 13
Training loss: 0.4724414050579071
Validation loss: 1.7382135083598476

Epoch: 350| Step: 0
Training loss: 0.38275718688964844
Validation loss: 1.7245810057527275

Epoch: 6| Step: 1
Training loss: 0.4105720520019531
Validation loss: 1.7247436085054952

Epoch: 6| Step: 2
Training loss: 0.4138130247592926
Validation loss: 1.7212609578204412

Epoch: 6| Step: 3
Training loss: 0.3486626148223877
Validation loss: 1.7478841325288177

Epoch: 6| Step: 4
Training loss: 0.5029986500740051
Validation loss: 1.7348665652736541

Epoch: 6| Step: 5
Training loss: 0.2923445701599121
Validation loss: 1.7339527863328175

Epoch: 6| Step: 6
Training loss: 0.433152437210083
Validation loss: 1.7763368980858916

Epoch: 6| Step: 7
Training loss: 0.3834190368652344
Validation loss: 1.7428079638429868

Epoch: 6| Step: 8
Training loss: 0.7440671920776367
Validation loss: 1.7364356902337843

Epoch: 6| Step: 9
Training loss: 0.47442567348480225
Validation loss: 1.7520272834326631

Epoch: 6| Step: 10
Training loss: 0.3162572681903839
Validation loss: 1.7888712318994666

Epoch: 6| Step: 11
Training loss: 0.328496515750885
Validation loss: 1.777711922122586

Epoch: 6| Step: 12
Training loss: 0.3654494881629944
Validation loss: 1.7632025646907028

Epoch: 6| Step: 13
Training loss: 0.46741777658462524
Validation loss: 1.7591657305276522

Epoch: 351| Step: 0
Training loss: 0.556684136390686
Validation loss: 1.7617091132748512

Epoch: 6| Step: 1
Training loss: 0.5797930955886841
Validation loss: 1.7824434259886384

Epoch: 6| Step: 2
Training loss: 0.6776680946350098
Validation loss: 1.7502374392683788

Epoch: 6| Step: 3
Training loss: 0.45525020360946655
Validation loss: 1.782641859464748

Epoch: 6| Step: 4
Training loss: 0.41338402032852173
Validation loss: 1.7658155771993822

Epoch: 6| Step: 5
Training loss: 0.33553647994995117
Validation loss: 1.7706383787175661

Epoch: 6| Step: 6
Training loss: 0.3628988564014435
Validation loss: 1.7872492062148226

Epoch: 6| Step: 7
Training loss: 0.1536080241203308
Validation loss: 1.7893473858474402

Epoch: 6| Step: 8
Training loss: 0.45813244581222534
Validation loss: 1.7985747616778138

Epoch: 6| Step: 9
Training loss: 0.3429613709449768
Validation loss: 1.7939100521866993

Epoch: 6| Step: 10
Training loss: 0.45229822397232056
Validation loss: 1.7901039277353594

Epoch: 6| Step: 11
Training loss: 0.5476978421211243
Validation loss: 1.7868390237131426

Epoch: 6| Step: 12
Training loss: 0.2954113483428955
Validation loss: 1.7844654667762019

Epoch: 6| Step: 13
Training loss: 0.37624138593673706
Validation loss: 1.778074748413537

Epoch: 352| Step: 0
Training loss: 0.44665229320526123
Validation loss: 1.7778201487756544

Epoch: 6| Step: 1
Training loss: 0.31752294301986694
Validation loss: 1.787285897039598

Epoch: 6| Step: 2
Training loss: 0.4769875109195709
Validation loss: 1.8125290306665565

Epoch: 6| Step: 3
Training loss: 0.5363361835479736
Validation loss: 1.8026344340334657

Epoch: 6| Step: 4
Training loss: 0.3094147741794586
Validation loss: 1.7791901801222114

Epoch: 6| Step: 5
Training loss: 0.26360952854156494
Validation loss: 1.7971074632419053

Epoch: 6| Step: 6
Training loss: 0.43444663286209106
Validation loss: 1.7760736609017977

Epoch: 6| Step: 7
Training loss: 0.25423187017440796
Validation loss: 1.7524967872968285

Epoch: 6| Step: 8
Training loss: 0.2651198208332062
Validation loss: 1.7095522854917793

Epoch: 6| Step: 9
Training loss: 0.7198411822319031
Validation loss: 1.745738806263093

Epoch: 6| Step: 10
Training loss: 0.3059179186820984
Validation loss: 1.73936588533463

Epoch: 6| Step: 11
Training loss: 0.3569989502429962
Validation loss: 1.7216728759068314

Epoch: 6| Step: 12
Training loss: 0.38108551502227783
Validation loss: 1.7219822317041376

Epoch: 6| Step: 13
Training loss: 0.5696956515312195
Validation loss: 1.7222146295732068

Epoch: 353| Step: 0
Training loss: 0.2741025686264038
Validation loss: 1.7149811688289847

Epoch: 6| Step: 1
Training loss: 0.4732872247695923
Validation loss: 1.767752157744541

Epoch: 6| Step: 2
Training loss: 0.42838218808174133
Validation loss: 1.736219636855587

Epoch: 6| Step: 3
Training loss: 0.4913882911205292
Validation loss: 1.7564399229582919

Epoch: 6| Step: 4
Training loss: 0.27538377046585083
Validation loss: 1.7507534821828206

Epoch: 6| Step: 5
Training loss: 0.4326319396495819
Validation loss: 1.7504958914172264

Epoch: 6| Step: 6
Training loss: 0.4430166184902191
Validation loss: 1.797270783814051

Epoch: 6| Step: 7
Training loss: 0.3325601816177368
Validation loss: 1.8147359253257833

Epoch: 6| Step: 8
Training loss: 0.696587085723877
Validation loss: 1.8239379172684045

Epoch: 6| Step: 9
Training loss: 0.3233410716056824
Validation loss: 1.8107552887291036

Epoch: 6| Step: 10
Training loss: 0.4768093526363373
Validation loss: 1.8292375110810803

Epoch: 6| Step: 11
Training loss: 0.29098957777023315
Validation loss: 1.8115427096684773

Epoch: 6| Step: 12
Training loss: 0.2771730422973633
Validation loss: 1.8002142496006464

Epoch: 6| Step: 13
Training loss: 0.4740917980670929
Validation loss: 1.790822854606054

Epoch: 354| Step: 0
Training loss: 0.4585362672805786
Validation loss: 1.7824414340398644

Epoch: 6| Step: 1
Training loss: 0.5870144367218018
Validation loss: 1.7549703044276084

Epoch: 6| Step: 2
Training loss: 0.3006914258003235
Validation loss: 1.7453815334586686

Epoch: 6| Step: 3
Training loss: 0.3803519010543823
Validation loss: 1.7523768037878058

Epoch: 6| Step: 4
Training loss: 0.5579803586006165
Validation loss: 1.7185085050521358

Epoch: 6| Step: 5
Training loss: 0.3452516794204712
Validation loss: 1.7314649730600336

Epoch: 6| Step: 6
Training loss: 0.37918660044670105
Validation loss: 1.7279036045074463

Epoch: 6| Step: 7
Training loss: 0.3461546301841736
Validation loss: 1.741672460750867

Epoch: 6| Step: 8
Training loss: 0.5101691484451294
Validation loss: 1.7557626514024631

Epoch: 6| Step: 9
Training loss: 0.3961181044578552
Validation loss: 1.765594095312139

Epoch: 6| Step: 10
Training loss: 0.4730472266674042
Validation loss: 1.7611452930717058

Epoch: 6| Step: 11
Training loss: 0.2978103756904602
Validation loss: 1.788725217183431

Epoch: 6| Step: 12
Training loss: 0.44766342639923096
Validation loss: 1.7915019835195234

Epoch: 6| Step: 13
Training loss: 0.31352493166923523
Validation loss: 1.7988517233120498

Epoch: 355| Step: 0
Training loss: 0.2669224143028259
Validation loss: 1.7782688371596798

Epoch: 6| Step: 1
Training loss: 0.6300709247589111
Validation loss: 1.7780227507314375

Epoch: 6| Step: 2
Training loss: 0.5572848320007324
Validation loss: 1.8018037901129773

Epoch: 6| Step: 3
Training loss: 0.4021095037460327
Validation loss: 1.8054338142436037

Epoch: 6| Step: 4
Training loss: 0.24621261656284332
Validation loss: 1.8280586042711813

Epoch: 6| Step: 5
Training loss: 0.44917094707489014
Validation loss: 1.8036526723574566

Epoch: 6| Step: 6
Training loss: 0.4018334746360779
Validation loss: 1.7813337259395148

Epoch: 6| Step: 7
Training loss: 0.370678573846817
Validation loss: 1.7721733111207203

Epoch: 6| Step: 8
Training loss: 0.3202100396156311
Validation loss: 1.7657962229944044

Epoch: 6| Step: 9
Training loss: 0.1840045005083084
Validation loss: 1.7509398332206152

Epoch: 6| Step: 10
Training loss: 0.3734961450099945
Validation loss: 1.7685438740637995

Epoch: 6| Step: 11
Training loss: 0.523490309715271
Validation loss: 1.7601721094500633

Epoch: 6| Step: 12
Training loss: 0.6811265349388123
Validation loss: 1.7630362049225838

Epoch: 6| Step: 13
Training loss: 0.13912037014961243
Validation loss: 1.7367680534239738

Epoch: 356| Step: 0
Training loss: 0.8742048740386963
Validation loss: 1.7693436043236845

Epoch: 6| Step: 1
Training loss: 0.32724130153656006
Validation loss: 1.7545893294836885

Epoch: 6| Step: 2
Training loss: 0.3483019471168518
Validation loss: 1.7806198827682003

Epoch: 6| Step: 3
Training loss: 0.3036963939666748
Validation loss: 1.7631347589595343

Epoch: 6| Step: 4
Training loss: 0.3181401789188385
Validation loss: 1.7487434943517048

Epoch: 6| Step: 5
Training loss: 0.43895193934440613
Validation loss: 1.7505869442416775

Epoch: 6| Step: 6
Training loss: 0.411149263381958
Validation loss: 1.7205718114811888

Epoch: 6| Step: 7
Training loss: 0.4246865510940552
Validation loss: 1.7307147146553121

Epoch: 6| Step: 8
Training loss: 0.46935969591140747
Validation loss: 1.7184325661710513

Epoch: 6| Step: 9
Training loss: 0.30982381105422974
Validation loss: 1.7206036185705533

Epoch: 6| Step: 10
Training loss: 0.3606629967689514
Validation loss: 1.7057120748745498

Epoch: 6| Step: 11
Training loss: 0.40897610783576965
Validation loss: 1.724219984905694

Epoch: 6| Step: 12
Training loss: 0.49130532145500183
Validation loss: 1.7108179394916823

Epoch: 6| Step: 13
Training loss: 0.20104540884494781
Validation loss: 1.6985384661664245

Epoch: 357| Step: 0
Training loss: 0.6029844880104065
Validation loss: 1.710138427313938

Epoch: 6| Step: 1
Training loss: 0.4129370450973511
Validation loss: 1.664500924848741

Epoch: 6| Step: 2
Training loss: 0.3688333034515381
Validation loss: 1.6880774728713497

Epoch: 6| Step: 3
Training loss: 0.4072745442390442
Validation loss: 1.6758943411611742

Epoch: 6| Step: 4
Training loss: 0.1465599238872528
Validation loss: 1.691312292570709

Epoch: 6| Step: 5
Training loss: 0.25523582100868225
Validation loss: 1.6747195054126043

Epoch: 6| Step: 6
Training loss: 0.39141708612442017
Validation loss: 1.6897375519557665

Epoch: 6| Step: 7
Training loss: 0.3790522813796997
Validation loss: 1.6643705893588323

Epoch: 6| Step: 8
Training loss: 0.262868732213974
Validation loss: 1.6817072001836633

Epoch: 6| Step: 9
Training loss: 0.41245490312576294
Validation loss: 1.6484682252330165

Epoch: 6| Step: 10
Training loss: 0.47707828879356384
Validation loss: 1.7023645677874166

Epoch: 6| Step: 11
Training loss: 0.39704620838165283
Validation loss: 1.6872913593887

Epoch: 6| Step: 12
Training loss: 0.4534505307674408
Validation loss: 1.7133494705282233

Epoch: 6| Step: 13
Training loss: 0.4308292865753174
Validation loss: 1.707276839081959

Epoch: 358| Step: 0
Training loss: 0.2467670440673828
Validation loss: 1.7559131704350954

Epoch: 6| Step: 1
Training loss: 0.5141261219978333
Validation loss: 1.747254071697112

Epoch: 6| Step: 2
Training loss: 0.22465936839580536
Validation loss: 1.7817404423990557

Epoch: 6| Step: 3
Training loss: 0.33832812309265137
Validation loss: 1.800324115701901

Epoch: 6| Step: 4
Training loss: 0.3225109875202179
Validation loss: 1.7981982026048886

Epoch: 6| Step: 5
Training loss: 0.4542843699455261
Validation loss: 1.8174081169148928

Epoch: 6| Step: 6
Training loss: 0.24327214062213898
Validation loss: 1.7575322210147817

Epoch: 6| Step: 7
Training loss: 0.347697377204895
Validation loss: 1.7166859565242645

Epoch: 6| Step: 8
Training loss: 0.378379762172699
Validation loss: 1.6805378660078971

Epoch: 6| Step: 9
Training loss: 0.4628668427467346
Validation loss: 1.712065044269767

Epoch: 6| Step: 10
Training loss: 0.700947642326355
Validation loss: 1.6867462665803972

Epoch: 6| Step: 11
Training loss: 0.5651272535324097
Validation loss: 1.6855317418293287

Epoch: 6| Step: 12
Training loss: 0.5319986343383789
Validation loss: 1.6964234305966286

Epoch: 6| Step: 13
Training loss: 0.24442058801651
Validation loss: 1.6932949763472362

Epoch: 359| Step: 0
Training loss: 0.30063343048095703
Validation loss: 1.6829518784758866

Epoch: 6| Step: 1
Training loss: 0.3649711608886719
Validation loss: 1.6745616569313952

Epoch: 6| Step: 2
Training loss: 0.5777684450149536
Validation loss: 1.7075820584450998

Epoch: 6| Step: 3
Training loss: 0.28097742795944214
Validation loss: 1.716195252633864

Epoch: 6| Step: 4
Training loss: 0.7060403823852539
Validation loss: 1.7508012133259927

Epoch: 6| Step: 5
Training loss: 0.4139134883880615
Validation loss: 1.7390074447918964

Epoch: 6| Step: 6
Training loss: 0.44646409153938293
Validation loss: 1.7890578213558401

Epoch: 6| Step: 7
Training loss: 0.3637835383415222
Validation loss: 1.7695934580218406

Epoch: 6| Step: 8
Training loss: 0.28887468576431274
Validation loss: 1.7643664883029075

Epoch: 6| Step: 9
Training loss: 0.23249712586402893
Validation loss: 1.7687710023695422

Epoch: 6| Step: 10
Training loss: 0.48040932416915894
Validation loss: 1.7615023941122077

Epoch: 6| Step: 11
Training loss: 0.35263198614120483
Validation loss: 1.718179081075935

Epoch: 6| Step: 12
Training loss: 0.3909856677055359
Validation loss: 1.7276051903283725

Epoch: 6| Step: 13
Training loss: 0.29318317770957947
Validation loss: 1.7253868105590984

Epoch: 360| Step: 0
Training loss: 0.18576699495315552
Validation loss: 1.723247431939648

Epoch: 6| Step: 1
Training loss: 0.29501351714134216
Validation loss: 1.6781599419091338

Epoch: 6| Step: 2
Training loss: 0.4969138503074646
Validation loss: 1.6714625691854825

Epoch: 6| Step: 3
Training loss: 0.2496747523546219
Validation loss: 1.7015300899423578

Epoch: 6| Step: 4
Training loss: 0.9608151912689209
Validation loss: 1.6744558785551338

Epoch: 6| Step: 5
Training loss: 0.2772531509399414
Validation loss: 1.6711535082068494

Epoch: 6| Step: 6
Training loss: 0.16165724396705627
Validation loss: 1.6703744357632053

Epoch: 6| Step: 7
Training loss: 0.4513590633869171
Validation loss: 1.6940577542910011

Epoch: 6| Step: 8
Training loss: 0.5810813307762146
Validation loss: 1.7060498088918707

Epoch: 6| Step: 9
Training loss: 0.24092775583267212
Validation loss: 1.7282940008307015

Epoch: 6| Step: 10
Training loss: 0.3930826485157013
Validation loss: 1.7623736191821355

Epoch: 6| Step: 11
Training loss: 0.2799302339553833
Validation loss: 1.7709478511605212

Epoch: 6| Step: 12
Training loss: 0.4339977204799652
Validation loss: 1.759780007023965

Epoch: 6| Step: 13
Training loss: 0.09928736090660095
Validation loss: 1.7844316728653447

Epoch: 361| Step: 0
Training loss: 0.29174649715423584
Validation loss: 1.7992458689597346

Epoch: 6| Step: 1
Training loss: 0.2596290707588196
Validation loss: 1.7806243063301168

Epoch: 6| Step: 2
Training loss: 0.33237236738204956
Validation loss: 1.7805581720926429

Epoch: 6| Step: 3
Training loss: 0.6252901554107666
Validation loss: 1.77872036862117

Epoch: 6| Step: 4
Training loss: 0.26563137769699097
Validation loss: 1.7713722336676814

Epoch: 6| Step: 5
Training loss: 0.1940360963344574
Validation loss: 1.7230778919753207

Epoch: 6| Step: 6
Training loss: 0.3126940131187439
Validation loss: 1.7491924660180205

Epoch: 6| Step: 7
Training loss: 0.46196502447128296
Validation loss: 1.7326650581052225

Epoch: 6| Step: 8
Training loss: 0.2971038818359375
Validation loss: 1.7157630792228125

Epoch: 6| Step: 9
Training loss: 0.45221012830734253
Validation loss: 1.6920383399532688

Epoch: 6| Step: 10
Training loss: 0.3533775806427002
Validation loss: 1.6721366740042163

Epoch: 6| Step: 11
Training loss: 0.6726628541946411
Validation loss: 1.6580249878668016

Epoch: 6| Step: 12
Training loss: 0.1898120492696762
Validation loss: 1.6712713946578324

Epoch: 6| Step: 13
Training loss: 0.7649056315422058
Validation loss: 1.6993964961780015

Epoch: 362| Step: 0
Training loss: 0.2716636657714844
Validation loss: 1.6628319217312721

Epoch: 6| Step: 1
Training loss: 0.6871502995491028
Validation loss: 1.6384596337554276

Epoch: 6| Step: 2
Training loss: 0.42522433400154114
Validation loss: 1.6457770357849777

Epoch: 6| Step: 3
Training loss: 0.5702706575393677
Validation loss: 1.6632093460329118

Epoch: 6| Step: 4
Training loss: 0.1758471429347992
Validation loss: 1.6603378980390486

Epoch: 6| Step: 5
Training loss: 0.2729218602180481
Validation loss: 1.710003879762465

Epoch: 6| Step: 6
Training loss: 0.33927375078201294
Validation loss: 1.6997989736577517

Epoch: 6| Step: 7
Training loss: 0.46473413705825806
Validation loss: 1.6776030396902433

Epoch: 6| Step: 8
Training loss: 0.2797132432460785
Validation loss: 1.6831609472151725

Epoch: 6| Step: 9
Training loss: 0.3305579423904419
Validation loss: 1.705476794191586

Epoch: 6| Step: 10
Training loss: 0.2844972014427185
Validation loss: 1.707381509965466

Epoch: 6| Step: 11
Training loss: 0.1484607458114624
Validation loss: 1.691433378445205

Epoch: 6| Step: 12
Training loss: 0.435824990272522
Validation loss: 1.729117758812443

Epoch: 6| Step: 13
Training loss: 0.4808040261268616
Validation loss: 1.7293833994096326

Epoch: 363| Step: 0
Training loss: 0.29635876417160034
Validation loss: 1.7547147466290383

Epoch: 6| Step: 1
Training loss: 0.11788864433765411
Validation loss: 1.7083462322911909

Epoch: 6| Step: 2
Training loss: 0.18237003684043884
Validation loss: 1.7117182798283075

Epoch: 6| Step: 3
Training loss: 0.29110363125801086
Validation loss: 1.7081332001634824

Epoch: 6| Step: 4
Training loss: 0.42250433564186096
Validation loss: 1.7158003212303243

Epoch: 6| Step: 5
Training loss: 0.4582250118255615
Validation loss: 1.6854467955968713

Epoch: 6| Step: 6
Training loss: 0.6138237118721008
Validation loss: 1.6771681988111107

Epoch: 6| Step: 7
Training loss: 0.4022177457809448
Validation loss: 1.7153275935880599

Epoch: 6| Step: 8
Training loss: 0.44239741563796997
Validation loss: 1.6978190663040325

Epoch: 6| Step: 9
Training loss: 0.35243046283721924
Validation loss: 1.7053800270121584

Epoch: 6| Step: 10
Training loss: 0.3961441218852997
Validation loss: 1.7058249865808794

Epoch: 6| Step: 11
Training loss: 0.4327406585216522
Validation loss: 1.716892425731946

Epoch: 6| Step: 12
Training loss: 0.42180463671684265
Validation loss: 1.6999629242445833

Epoch: 6| Step: 13
Training loss: 0.41267791390419006
Validation loss: 1.7184875395990187

Epoch: 364| Step: 0
Training loss: 0.3290916085243225
Validation loss: 1.722097066140944

Epoch: 6| Step: 1
Training loss: 0.19213488698005676
Validation loss: 1.7215504864210724

Epoch: 6| Step: 2
Training loss: 0.5129329562187195
Validation loss: 1.6976592169013074

Epoch: 6| Step: 3
Training loss: 0.38615477085113525
Validation loss: 1.7256217105414278

Epoch: 6| Step: 4
Training loss: 0.39455097913742065
Validation loss: 1.7162730514362294

Epoch: 6| Step: 5
Training loss: 0.40551844239234924
Validation loss: 1.7515381241357455

Epoch: 6| Step: 6
Training loss: 0.29818540811538696
Validation loss: 1.7748994545270038

Epoch: 6| Step: 7
Training loss: 0.32101693749427795
Validation loss: 1.7392063551051642

Epoch: 6| Step: 8
Training loss: 0.4696439504623413
Validation loss: 1.7442548890267648

Epoch: 6| Step: 9
Training loss: 0.45613646507263184
Validation loss: 1.7296682570570259

Epoch: 6| Step: 10
Training loss: 0.3203495740890503
Validation loss: 1.6932650586610198

Epoch: 6| Step: 11
Training loss: 0.4510068893432617
Validation loss: 1.7267337024852794

Epoch: 6| Step: 12
Training loss: 0.4883933663368225
Validation loss: 1.7041462249653314

Epoch: 6| Step: 13
Training loss: 0.4028773009777069
Validation loss: 1.7401954512442313

Epoch: 365| Step: 0
Training loss: 0.3407227396965027
Validation loss: 1.699906341491207

Epoch: 6| Step: 1
Training loss: 0.2634831964969635
Validation loss: 1.6772065829205256

Epoch: 6| Step: 2
Training loss: 0.13012418150901794
Validation loss: 1.6458720584069528

Epoch: 6| Step: 3
Training loss: 0.5137029886245728
Validation loss: 1.6750153559510426

Epoch: 6| Step: 4
Training loss: 0.2866891324520111
Validation loss: 1.6759597550156295

Epoch: 6| Step: 5
Training loss: 0.46815621852874756
Validation loss: 1.669237563686986

Epoch: 6| Step: 6
Training loss: 0.528641939163208
Validation loss: 1.7055221232034827

Epoch: 6| Step: 7
Training loss: 0.273099809885025
Validation loss: 1.7228129756066106

Epoch: 6| Step: 8
Training loss: 0.26496607065200806
Validation loss: 1.722648843642204

Epoch: 6| Step: 9
Training loss: 0.4369874596595764
Validation loss: 1.708182672018646

Epoch: 6| Step: 10
Training loss: 0.5029934048652649
Validation loss: 1.7230080443043863

Epoch: 6| Step: 11
Training loss: 0.42905986309051514
Validation loss: 1.7362587887753722

Epoch: 6| Step: 12
Training loss: 0.3688892722129822
Validation loss: 1.7637661323752454

Epoch: 6| Step: 13
Training loss: 0.5676935315132141
Validation loss: 1.7882895097937634

Epoch: 366| Step: 0
Training loss: 0.32751691341400146
Validation loss: 1.7610758222559446

Epoch: 6| Step: 1
Training loss: 0.32283422350883484
Validation loss: 1.7704387223848732

Epoch: 6| Step: 2
Training loss: 0.4665260910987854
Validation loss: 1.7657428813237015

Epoch: 6| Step: 3
Training loss: 0.38390228152275085
Validation loss: 1.731882813156292

Epoch: 6| Step: 4
Training loss: 0.6079365611076355
Validation loss: 1.7387358014301588

Epoch: 6| Step: 5
Training loss: 0.2536783218383789
Validation loss: 1.7007152380481843

Epoch: 6| Step: 6
Training loss: 0.3354768455028534
Validation loss: 1.657098384313686

Epoch: 6| Step: 7
Training loss: 0.2763584554195404
Validation loss: 1.6502152668532504

Epoch: 6| Step: 8
Training loss: 0.2319696545600891
Validation loss: 1.6619831246714438

Epoch: 6| Step: 9
Training loss: 0.3924473822116852
Validation loss: 1.665694038073222

Epoch: 6| Step: 10
Training loss: 0.36347267031669617
Validation loss: 1.6504819944340696

Epoch: 6| Step: 11
Training loss: 0.3466474413871765
Validation loss: 1.680434529499341

Epoch: 6| Step: 12
Training loss: 0.32249170541763306
Validation loss: 1.6865426494229225

Epoch: 6| Step: 13
Training loss: 0.14079539477825165
Validation loss: 1.703656736240592

Epoch: 367| Step: 0
Training loss: 0.552092432975769
Validation loss: 1.715878858361193

Epoch: 6| Step: 1
Training loss: 0.4124545156955719
Validation loss: 1.7369629426669049

Epoch: 6| Step: 2
Training loss: 0.30827033519744873
Validation loss: 1.7390358499301377

Epoch: 6| Step: 3
Training loss: 0.2461165189743042
Validation loss: 1.7422140541897024

Epoch: 6| Step: 4
Training loss: 0.2449420988559723
Validation loss: 1.7214224018076414

Epoch: 6| Step: 5
Training loss: 0.6345390677452087
Validation loss: 1.7414546807607014

Epoch: 6| Step: 6
Training loss: 0.30537086725234985
Validation loss: 1.7720889096618981

Epoch: 6| Step: 7
Training loss: 0.3749508261680603
Validation loss: 1.7474556763966878

Epoch: 6| Step: 8
Training loss: 0.37582194805145264
Validation loss: 1.750060445518904

Epoch: 6| Step: 9
Training loss: 0.40208083391189575
Validation loss: 1.7736884958000594

Epoch: 6| Step: 10
Training loss: 0.2313256859779358
Validation loss: 1.7440998964412238

Epoch: 6| Step: 11
Training loss: 0.34739136695861816
Validation loss: 1.7451649981160318

Epoch: 6| Step: 12
Training loss: 0.23077596724033356
Validation loss: 1.6935645713601062

Epoch: 6| Step: 13
Training loss: 0.46096548438072205
Validation loss: 1.681903895511422

Epoch: 368| Step: 0
Training loss: 0.5231941938400269
Validation loss: 1.6772697241075578

Epoch: 6| Step: 1
Training loss: 0.3149421811103821
Validation loss: 1.6463634519166843

Epoch: 6| Step: 2
Training loss: 0.224092036485672
Validation loss: 1.6479694971474268

Epoch: 6| Step: 3
Training loss: 0.31747087836265564
Validation loss: 1.6769808248807025

Epoch: 6| Step: 4
Training loss: 0.2530318796634674
Validation loss: 1.659476803195092

Epoch: 6| Step: 5
Training loss: 0.1897534728050232
Validation loss: 1.6484754457268664

Epoch: 6| Step: 6
Training loss: 0.3092385530471802
Validation loss: 1.6707691454118299

Epoch: 6| Step: 7
Training loss: 0.2260899543762207
Validation loss: 1.672905425871572

Epoch: 6| Step: 8
Training loss: 0.48699232935905457
Validation loss: 1.7064187449793662

Epoch: 6| Step: 9
Training loss: 0.39745593070983887
Validation loss: 1.706138683903602

Epoch: 6| Step: 10
Training loss: 0.39783915877342224
Validation loss: 1.7013192869001819

Epoch: 6| Step: 11
Training loss: 0.2212550938129425
Validation loss: 1.7319577201720207

Epoch: 6| Step: 12
Training loss: 0.5758340358734131
Validation loss: 1.7378027067389539

Epoch: 6| Step: 13
Training loss: 0.3566770851612091
Validation loss: 1.7394449608300322

Epoch: 369| Step: 0
Training loss: 0.336880624294281
Validation loss: 1.754982481720627

Epoch: 6| Step: 1
Training loss: 0.3268873691558838
Validation loss: 1.7730715813175324

Epoch: 6| Step: 2
Training loss: 0.2076646089553833
Validation loss: 1.754474102809865

Epoch: 6| Step: 3
Training loss: 0.24102967977523804
Validation loss: 1.7669620449824999

Epoch: 6| Step: 4
Training loss: 0.11262723058462143
Validation loss: 1.75457122248988

Epoch: 6| Step: 5
Training loss: 0.4587888717651367
Validation loss: 1.7168547581600886

Epoch: 6| Step: 6
Training loss: 0.35656028985977173
Validation loss: 1.687620396255165

Epoch: 6| Step: 7
Training loss: 0.26518210768699646
Validation loss: 1.7331733101157731

Epoch: 6| Step: 8
Training loss: 0.3465946316719055
Validation loss: 1.7439323202256234

Epoch: 6| Step: 9
Training loss: 0.33812034130096436
Validation loss: 1.7212291494492562

Epoch: 6| Step: 10
Training loss: 0.6860788464546204
Validation loss: 1.6800463789252824

Epoch: 6| Step: 11
Training loss: 0.26464876532554626
Validation loss: 1.691526815455447

Epoch: 6| Step: 12
Training loss: 0.47713321447372437
Validation loss: 1.7256119392251457

Epoch: 6| Step: 13
Training loss: 0.3544708788394928
Validation loss: 1.692110905083277

Epoch: 370| Step: 0
Training loss: 0.42562752962112427
Validation loss: 1.6659599837436472

Epoch: 6| Step: 1
Training loss: 0.3764856457710266
Validation loss: 1.6772739438600437

Epoch: 6| Step: 2
Training loss: 0.23407664895057678
Validation loss: 1.689069095478263

Epoch: 6| Step: 3
Training loss: 0.6497079730033875
Validation loss: 1.7115112709742721

Epoch: 6| Step: 4
Training loss: 0.5048216581344604
Validation loss: 1.6892939024074103

Epoch: 6| Step: 5
Training loss: 0.4074341058731079
Validation loss: 1.7214669360909411

Epoch: 6| Step: 6
Training loss: 0.27837908267974854
Validation loss: 1.6945364423977431

Epoch: 6| Step: 7
Training loss: 0.21909865736961365
Validation loss: 1.664745847384135

Epoch: 6| Step: 8
Training loss: 0.18356558680534363
Validation loss: 1.692402906315301

Epoch: 6| Step: 9
Training loss: 0.28780534863471985
Validation loss: 1.679405112420359

Epoch: 6| Step: 10
Training loss: 0.29347050189971924
Validation loss: 1.6864905857270764

Epoch: 6| Step: 11
Training loss: 0.2929726839065552
Validation loss: 1.6787820144366192

Epoch: 6| Step: 12
Training loss: 0.3854216933250427
Validation loss: 1.6855209860750424

Epoch: 6| Step: 13
Training loss: 0.5546633005142212
Validation loss: 1.6696890887393747

Epoch: 371| Step: 0
Training loss: 0.4460427761077881
Validation loss: 1.6836439486472838

Epoch: 6| Step: 1
Training loss: 0.2561389207839966
Validation loss: 1.6843864584481845

Epoch: 6| Step: 2
Training loss: 0.3837595283985138
Validation loss: 1.6732828014640397

Epoch: 6| Step: 3
Training loss: 0.43480750918388367
Validation loss: 1.675508652963946

Epoch: 6| Step: 4
Training loss: 0.2951520085334778
Validation loss: 1.7295621325892787

Epoch: 6| Step: 5
Training loss: 0.40876027941703796
Validation loss: 1.7389985220406645

Epoch: 6| Step: 6
Training loss: 0.37922602891921997
Validation loss: 1.7465688451643913

Epoch: 6| Step: 7
Training loss: 0.5082772374153137
Validation loss: 1.7409664841108425

Epoch: 6| Step: 8
Training loss: 0.1148793175816536
Validation loss: 1.7335677595548733

Epoch: 6| Step: 9
Training loss: 0.23637965321540833
Validation loss: 1.751769320939177

Epoch: 6| Step: 10
Training loss: 0.3859621286392212
Validation loss: 1.7280062231966244

Epoch: 6| Step: 11
Training loss: 0.27082645893096924
Validation loss: 1.7227906411693943

Epoch: 6| Step: 12
Training loss: 0.2575279474258423
Validation loss: 1.7226520315293343

Epoch: 6| Step: 13
Training loss: 0.23742151260375977
Validation loss: 1.730746808872428

Epoch: 372| Step: 0
Training loss: 0.27558109164237976
Validation loss: 1.7241693773577291

Epoch: 6| Step: 1
Training loss: 0.14650824666023254
Validation loss: 1.7295234921158

Epoch: 6| Step: 2
Training loss: 0.2575315237045288
Validation loss: 1.7120657005617697

Epoch: 6| Step: 3
Training loss: 0.3442225754261017
Validation loss: 1.6967373253196798

Epoch: 6| Step: 4
Training loss: 0.42098891735076904
Validation loss: 1.6937486023031256

Epoch: 6| Step: 5
Training loss: 0.3692433834075928
Validation loss: 1.7078082548674716

Epoch: 6| Step: 6
Training loss: 0.21218472719192505
Validation loss: 1.722860405522008

Epoch: 6| Step: 7
Training loss: 0.25882408022880554
Validation loss: 1.7333466506773425

Epoch: 6| Step: 8
Training loss: 0.24047695100307465
Validation loss: 1.726887978533263

Epoch: 6| Step: 9
Training loss: 0.3561515212059021
Validation loss: 1.7262270117318759

Epoch: 6| Step: 10
Training loss: 0.9370777606964111
Validation loss: 1.7173445340125792

Epoch: 6| Step: 11
Training loss: 0.3373975157737732
Validation loss: 1.7355167878571378

Epoch: 6| Step: 12
Training loss: 0.36921924352645874
Validation loss: 1.7150683685015606

Epoch: 6| Step: 13
Training loss: 0.11433906108140945
Validation loss: 1.6811740936771515

Epoch: 373| Step: 0
Training loss: 0.6655736565589905
Validation loss: 1.716323705129726

Epoch: 6| Step: 1
Training loss: 0.3408317565917969
Validation loss: 1.7148529098879906

Epoch: 6| Step: 2
Training loss: 0.23988372087478638
Validation loss: 1.7141108102695917

Epoch: 6| Step: 3
Training loss: 0.3359085023403168
Validation loss: 1.6769086186603834

Epoch: 6| Step: 4
Training loss: 0.28037482500076294
Validation loss: 1.6695047681049635

Epoch: 6| Step: 5
Training loss: 0.4334678649902344
Validation loss: 1.66196915154816

Epoch: 6| Step: 6
Training loss: 0.3025958240032196
Validation loss: 1.6451156370101436

Epoch: 6| Step: 7
Training loss: 0.36825454235076904
Validation loss: 1.6624461809794109

Epoch: 6| Step: 8
Training loss: 0.5351423025131226
Validation loss: 1.638164169044905

Epoch: 6| Step: 9
Training loss: 0.3747299313545227
Validation loss: 1.687175840459844

Epoch: 6| Step: 10
Training loss: 0.2738359272480011
Validation loss: 1.6741472803136355

Epoch: 6| Step: 11
Training loss: 0.37438300251960754
Validation loss: 1.6886337681483197

Epoch: 6| Step: 12
Training loss: 0.3537129759788513
Validation loss: 1.69568109127783

Epoch: 6| Step: 13
Training loss: 0.28583309054374695
Validation loss: 1.7145123712478145

Epoch: 374| Step: 0
Training loss: 0.36812710762023926
Validation loss: 1.7112933384474887

Epoch: 6| Step: 1
Training loss: 0.5125166773796082
Validation loss: 1.6847466909757225

Epoch: 6| Step: 2
Training loss: 0.4089553952217102
Validation loss: 1.7377419087194628

Epoch: 6| Step: 3
Training loss: 0.32794708013534546
Validation loss: 1.751276308490384

Epoch: 6| Step: 4
Training loss: 0.30710649490356445
Validation loss: 1.7594978975993332

Epoch: 6| Step: 5
Training loss: 0.3038119077682495
Validation loss: 1.7636957489034182

Epoch: 6| Step: 6
Training loss: 0.49521777033805847
Validation loss: 1.7686585264821206

Epoch: 6| Step: 7
Training loss: 0.20442533493041992
Validation loss: 1.781283816983623

Epoch: 6| Step: 8
Training loss: 0.42846357822418213
Validation loss: 1.7399645159321446

Epoch: 6| Step: 9
Training loss: 0.4059993028640747
Validation loss: 1.7419149337276336

Epoch: 6| Step: 10
Training loss: 0.22273313999176025
Validation loss: 1.7249000790298625

Epoch: 6| Step: 11
Training loss: 0.6050503849983215
Validation loss: 1.7038850117755193

Epoch: 6| Step: 12
Training loss: 0.36040282249450684
Validation loss: 1.6555465716187672

Epoch: 6| Step: 13
Training loss: 0.10061119496822357
Validation loss: 1.6686489530788955

Epoch: 375| Step: 0
Training loss: 0.26337653398513794
Validation loss: 1.6531911255210958

Epoch: 6| Step: 1
Training loss: 0.2349959760904312
Validation loss: 1.6360335580764278

Epoch: 6| Step: 2
Training loss: 0.31969982385635376
Validation loss: 1.6252833168993714

Epoch: 6| Step: 3
Training loss: 0.29805445671081543
Validation loss: 1.6517020322943246

Epoch: 6| Step: 4
Training loss: 0.6190811991691589
Validation loss: 1.6522449947172595

Epoch: 6| Step: 5
Training loss: 0.34537380933761597
Validation loss: 1.6572228862393288

Epoch: 6| Step: 6
Training loss: 0.40500587224960327
Validation loss: 1.6675255631887784

Epoch: 6| Step: 7
Training loss: 0.17454245686531067
Validation loss: 1.6766081804870276

Epoch: 6| Step: 8
Training loss: 0.2326241433620453
Validation loss: 1.7127828213476366

Epoch: 6| Step: 9
Training loss: 0.5210307836532593
Validation loss: 1.7296158600878972

Epoch: 6| Step: 10
Training loss: 0.2926003932952881
Validation loss: 1.7312401545945035

Epoch: 6| Step: 11
Training loss: 0.21422268450260162
Validation loss: 1.7240268491929578

Epoch: 6| Step: 12
Training loss: 0.4033997356891632
Validation loss: 1.693659395299932

Epoch: 6| Step: 13
Training loss: 0.748369038105011
Validation loss: 1.7181353287030292

Epoch: 376| Step: 0
Training loss: 0.45644137263298035
Validation loss: 1.6942257983710176

Epoch: 6| Step: 1
Training loss: 0.2327117621898651
Validation loss: 1.6659288239735428

Epoch: 6| Step: 2
Training loss: 0.6502295732498169
Validation loss: 1.6652970878026818

Epoch: 6| Step: 3
Training loss: 0.1723216474056244
Validation loss: 1.6864239150477993

Epoch: 6| Step: 4
Training loss: 0.2593051791191101
Validation loss: 1.7035994068268807

Epoch: 6| Step: 5
Training loss: 0.3950933814048767
Validation loss: 1.6906634210258402

Epoch: 6| Step: 6
Training loss: 0.40143224596977234
Validation loss: 1.688333490843414

Epoch: 6| Step: 7
Training loss: 0.24737682938575745
Validation loss: 1.7013675358987623

Epoch: 6| Step: 8
Training loss: 0.22675859928131104
Validation loss: 1.7220987953165525

Epoch: 6| Step: 9
Training loss: 0.3177480101585388
Validation loss: 1.7048167785008748

Epoch: 6| Step: 10
Training loss: 0.13468073308467865
Validation loss: 1.7132289037909558

Epoch: 6| Step: 11
Training loss: 0.430319219827652
Validation loss: 1.7301997048880464

Epoch: 6| Step: 12
Training loss: 0.23538923263549805
Validation loss: 1.7120388566806752

Epoch: 6| Step: 13
Training loss: 0.6482154130935669
Validation loss: 1.7451256295686126

Epoch: 377| Step: 0
Training loss: 0.17838507890701294
Validation loss: 1.7406731933675788

Epoch: 6| Step: 1
Training loss: 0.3758387863636017
Validation loss: 1.742239518832135

Epoch: 6| Step: 2
Training loss: 0.6048015356063843
Validation loss: 1.749517422850414

Epoch: 6| Step: 3
Training loss: 0.3763066232204437
Validation loss: 1.7486725122697893

Epoch: 6| Step: 4
Training loss: 0.2540133595466614
Validation loss: 1.6989913576392717

Epoch: 6| Step: 5
Training loss: 0.3766341805458069
Validation loss: 1.7195869773946784

Epoch: 6| Step: 6
Training loss: 0.2602466642856598
Validation loss: 1.6946872447126655

Epoch: 6| Step: 7
Training loss: 0.2504896819591522
Validation loss: 1.6736259486085625

Epoch: 6| Step: 8
Training loss: 0.4078288674354553
Validation loss: 1.6766828901024275

Epoch: 6| Step: 9
Training loss: 0.5941569805145264
Validation loss: 1.6679247194720852

Epoch: 6| Step: 10
Training loss: 0.3101467490196228
Validation loss: 1.6685686636996526

Epoch: 6| Step: 11
Training loss: 0.2607656717300415
Validation loss: 1.6498477984500188

Epoch: 6| Step: 12
Training loss: 0.3189091980457306
Validation loss: 1.6650348042929044

Epoch: 6| Step: 13
Training loss: 0.28364866971969604
Validation loss: 1.676033341756431

Epoch: 378| Step: 0
Training loss: 0.15146282315254211
Validation loss: 1.6693868406357304

Epoch: 6| Step: 1
Training loss: 0.28980955481529236
Validation loss: 1.71547737813765

Epoch: 6| Step: 2
Training loss: 0.8101191520690918
Validation loss: 1.7035387062257337

Epoch: 6| Step: 3
Training loss: 0.43748265504837036
Validation loss: 1.6915119719761673

Epoch: 6| Step: 4
Training loss: 0.204222172498703
Validation loss: 1.6957796619784447

Epoch: 6| Step: 5
Training loss: 0.1568862944841385
Validation loss: 1.6451715397578415

Epoch: 6| Step: 6
Training loss: 0.1897181123495102
Validation loss: 1.6692483194412724

Epoch: 6| Step: 7
Training loss: 0.18320688605308533
Validation loss: 1.6842470245976602

Epoch: 6| Step: 8
Training loss: 0.36961913108825684
Validation loss: 1.7014134289115987

Epoch: 6| Step: 9
Training loss: 0.471778929233551
Validation loss: 1.7118332552653488

Epoch: 6| Step: 10
Training loss: 0.19145742058753967
Validation loss: 1.702776631360413

Epoch: 6| Step: 11
Training loss: 0.36666250228881836
Validation loss: 1.6695479769860544

Epoch: 6| Step: 12
Training loss: 0.32815244793891907
Validation loss: 1.6897628896979875

Epoch: 6| Step: 13
Training loss: 0.46436643600463867
Validation loss: 1.6809826140762658

Epoch: 379| Step: 0
Training loss: 0.3322986364364624
Validation loss: 1.679813019690975

Epoch: 6| Step: 1
Training loss: 0.13155201077461243
Validation loss: 1.6780609802533222

Epoch: 6| Step: 2
Training loss: 0.3550682067871094
Validation loss: 1.6705525254690519

Epoch: 6| Step: 3
Training loss: 0.36709487438201904
Validation loss: 1.6956291762731408

Epoch: 6| Step: 4
Training loss: 0.28646349906921387
Validation loss: 1.6866509593943113

Epoch: 6| Step: 5
Training loss: 0.16258734464645386
Validation loss: 1.6927735972148117

Epoch: 6| Step: 6
Training loss: 0.36270561814308167
Validation loss: 1.696364354061824

Epoch: 6| Step: 7
Training loss: 0.5102644562721252
Validation loss: 1.7204046928754417

Epoch: 6| Step: 8
Training loss: 0.21181349456310272
Validation loss: 1.7290360517399286

Epoch: 6| Step: 9
Training loss: 0.6431735157966614
Validation loss: 1.6944574886752712

Epoch: 6| Step: 10
Training loss: 0.30070483684539795
Validation loss: 1.7250045038038684

Epoch: 6| Step: 11
Training loss: 0.2358558475971222
Validation loss: 1.722390369702411

Epoch: 6| Step: 12
Training loss: 0.230539470911026
Validation loss: 1.7580447504597325

Epoch: 6| Step: 13
Training loss: 0.34720057249069214
Validation loss: 1.7406891545941752

Epoch: 380| Step: 0
Training loss: 0.35189417004585266
Validation loss: 1.7380545152130948

Epoch: 6| Step: 1
Training loss: 0.2938818633556366
Validation loss: 1.7458501438940726

Epoch: 6| Step: 2
Training loss: 0.38970711827278137
Validation loss: 1.7571083025265766

Epoch: 6| Step: 3
Training loss: 0.2098579853773117
Validation loss: 1.7293794103848037

Epoch: 6| Step: 4
Training loss: 0.42941537499427795
Validation loss: 1.7360659978723014

Epoch: 6| Step: 5
Training loss: 0.4678889811038971
Validation loss: 1.7277772221513974

Epoch: 6| Step: 6
Training loss: 0.30560100078582764
Validation loss: 1.704997803575249

Epoch: 6| Step: 7
Training loss: 0.27388325333595276
Validation loss: 1.676130687036822

Epoch: 6| Step: 8
Training loss: 0.26156604290008545
Validation loss: 1.6687675945220455

Epoch: 6| Step: 9
Training loss: 0.3283838629722595
Validation loss: 1.631244097986529

Epoch: 6| Step: 10
Training loss: 0.3315514326095581
Validation loss: 1.613740430083326

Epoch: 6| Step: 11
Training loss: 0.17864491045475006
Validation loss: 1.622512504618655

Epoch: 6| Step: 12
Training loss: 0.3025062382221222
Validation loss: 1.6060913211555892

Epoch: 6| Step: 13
Training loss: 0.2792717516422272
Validation loss: 1.6381529659353278

Epoch: 381| Step: 0
Training loss: 0.5982236862182617
Validation loss: 1.6487676276955554

Epoch: 6| Step: 1
Training loss: 0.31471559405326843
Validation loss: 1.695146640141805

Epoch: 6| Step: 2
Training loss: 0.2876690626144409
Validation loss: 1.6754847739332466

Epoch: 6| Step: 3
Training loss: 0.31164225935935974
Validation loss: 1.6961289823696177

Epoch: 6| Step: 4
Training loss: 0.23518604040145874
Validation loss: 1.7153770936432706

Epoch: 6| Step: 5
Training loss: 0.30828458070755005
Validation loss: 1.7189979348131406

Epoch: 6| Step: 6
Training loss: 0.3049306869506836
Validation loss: 1.7503260643251481

Epoch: 6| Step: 7
Training loss: 0.42759567499160767
Validation loss: 1.736442518490617

Epoch: 6| Step: 8
Training loss: 0.26007604598999023
Validation loss: 1.7354835387199157

Epoch: 6| Step: 9
Training loss: 0.20380143821239471
Validation loss: 1.7142748666065994

Epoch: 6| Step: 10
Training loss: 0.4699183702468872
Validation loss: 1.7117207075959893

Epoch: 6| Step: 11
Training loss: 0.22357222437858582
Validation loss: 1.6877364215030466

Epoch: 6| Step: 12
Training loss: 0.17991821467876434
Validation loss: 1.6640044117486605

Epoch: 6| Step: 13
Training loss: 0.17837899923324585
Validation loss: 1.6100053428321757

Epoch: 382| Step: 0
Training loss: 0.1893351972103119
Validation loss: 1.622170325248472

Epoch: 6| Step: 1
Training loss: 0.3106650412082672
Validation loss: 1.6087224124580302

Epoch: 6| Step: 2
Training loss: 0.30414992570877075
Validation loss: 1.6211881893937305

Epoch: 6| Step: 3
Training loss: 0.23903927206993103
Validation loss: 1.650347791692262

Epoch: 6| Step: 4
Training loss: 0.2496243119239807
Validation loss: 1.6181544821749452

Epoch: 6| Step: 5
Training loss: 0.3308100998401642
Validation loss: 1.6372806666999735

Epoch: 6| Step: 6
Training loss: 0.5091013312339783
Validation loss: 1.6388683934365549

Epoch: 6| Step: 7
Training loss: 0.2892346680164337
Validation loss: 1.639092618419278

Epoch: 6| Step: 8
Training loss: 0.27095353603363037
Validation loss: 1.6359798882597236

Epoch: 6| Step: 9
Training loss: 0.3451979160308838
Validation loss: 1.6476146457015828

Epoch: 6| Step: 10
Training loss: 0.3346526622772217
Validation loss: 1.6324277154860958

Epoch: 6| Step: 11
Training loss: 0.1866057813167572
Validation loss: 1.6539605356031848

Epoch: 6| Step: 12
Training loss: 0.2721397876739502
Validation loss: 1.6575669396308161

Epoch: 6| Step: 13
Training loss: 0.24592266976833344
Validation loss: 1.631303793640547

Epoch: 383| Step: 0
Training loss: 0.44977763295173645
Validation loss: 1.6263311498908586

Epoch: 6| Step: 1
Training loss: 0.30411380529403687
Validation loss: 1.6332673885489022

Epoch: 6| Step: 2
Training loss: 0.35397183895111084
Validation loss: 1.6261973240042245

Epoch: 6| Step: 3
Training loss: 0.5055364370346069
Validation loss: 1.6275965411175963

Epoch: 6| Step: 4
Training loss: 0.4059487581253052
Validation loss: 1.631213024098386

Epoch: 6| Step: 5
Training loss: 0.2551230788230896
Validation loss: 1.6312338536785496

Epoch: 6| Step: 6
Training loss: 0.24119949340820312
Validation loss: 1.650825258224241

Epoch: 6| Step: 7
Training loss: 0.40772464871406555
Validation loss: 1.606785035902454

Epoch: 6| Step: 8
Training loss: 0.21894997358322144
Validation loss: 1.6332584991249988

Epoch: 6| Step: 9
Training loss: 0.1446726769208908
Validation loss: 1.6499190356141777

Epoch: 6| Step: 10
Training loss: 0.20990127325057983
Validation loss: 1.6350285776199833

Epoch: 6| Step: 11
Training loss: 0.19103270769119263
Validation loss: 1.619010902220203

Epoch: 6| Step: 12
Training loss: 0.12354028224945068
Validation loss: 1.6635885610375354

Epoch: 6| Step: 13
Training loss: 0.4335169196128845
Validation loss: 1.6815277299573343

Epoch: 384| Step: 0
Training loss: 0.21960589289665222
Validation loss: 1.6673388147866854

Epoch: 6| Step: 1
Training loss: 0.6791796088218689
Validation loss: 1.7135875199430732

Epoch: 6| Step: 2
Training loss: 0.2521662414073944
Validation loss: 1.706253449122111

Epoch: 6| Step: 3
Training loss: 0.27844130992889404
Validation loss: 1.7169723728651642

Epoch: 6| Step: 4
Training loss: 0.3383050262928009
Validation loss: 1.7051815486723376

Epoch: 6| Step: 5
Training loss: 0.23408527672290802
Validation loss: 1.6862978191785916

Epoch: 6| Step: 6
Training loss: 0.44704341888427734
Validation loss: 1.6817096523059312

Epoch: 6| Step: 7
Training loss: 0.27667635679244995
Validation loss: 1.6699835933664793

Epoch: 6| Step: 8
Training loss: 0.17923110723495483
Validation loss: 1.6772328961280085

Epoch: 6| Step: 9
Training loss: 0.18610894680023193
Validation loss: 1.6349702656909983

Epoch: 6| Step: 10
Training loss: 0.30166465044021606
Validation loss: 1.6236364841461182

Epoch: 6| Step: 11
Training loss: 0.30482834577560425
Validation loss: 1.6202486997009606

Epoch: 6| Step: 12
Training loss: 0.22319872677326202
Validation loss: 1.6158482490047332

Epoch: 6| Step: 13
Training loss: 0.21298080682754517
Validation loss: 1.6421325424666047

Epoch: 385| Step: 0
Training loss: 0.3281327784061432
Validation loss: 1.6127139958002235

Epoch: 6| Step: 1
Training loss: 0.25022587180137634
Validation loss: 1.6160505907509917

Epoch: 6| Step: 2
Training loss: 0.37568455934524536
Validation loss: 1.6224468561910814

Epoch: 6| Step: 3
Training loss: 0.5037808418273926
Validation loss: 1.6251454609696583

Epoch: 6| Step: 4
Training loss: 0.283790647983551
Validation loss: 1.6421936981139644

Epoch: 6| Step: 5
Training loss: 0.18563231825828552
Validation loss: 1.6421882747322

Epoch: 6| Step: 6
Training loss: 0.285844087600708
Validation loss: 1.6591510426613592

Epoch: 6| Step: 7
Training loss: 0.4463365077972412
Validation loss: 1.6397832593610209

Epoch: 6| Step: 8
Training loss: 0.1783456802368164
Validation loss: 1.6610927774060158

Epoch: 6| Step: 9
Training loss: 0.2849581837654114
Validation loss: 1.640769794423093

Epoch: 6| Step: 10
Training loss: 0.2030082643032074
Validation loss: 1.6534221979879564

Epoch: 6| Step: 11
Training loss: 0.3023272156715393
Validation loss: 1.6404592683238368

Epoch: 6| Step: 12
Training loss: 0.1492060422897339
Validation loss: 1.6616160203051824

Epoch: 6| Step: 13
Training loss: 0.31846490502357483
Validation loss: 1.6817774849553262

Epoch: 386| Step: 0
Training loss: 0.3395223617553711
Validation loss: 1.6694731930250764

Epoch: 6| Step: 1
Training loss: 0.22064530849456787
Validation loss: 1.6572117151752594

Epoch: 6| Step: 2
Training loss: 0.3204292058944702
Validation loss: 1.6541170535549041

Epoch: 6| Step: 3
Training loss: 0.3231462240219116
Validation loss: 1.6750832014186408

Epoch: 6| Step: 4
Training loss: 0.10541252046823502
Validation loss: 1.6632636208688059

Epoch: 6| Step: 5
Training loss: 0.1742837280035019
Validation loss: 1.6876876713127218

Epoch: 6| Step: 6
Training loss: 0.3631172180175781
Validation loss: 1.678674212066076

Epoch: 6| Step: 7
Training loss: 0.43898850679397583
Validation loss: 1.6535839432029313

Epoch: 6| Step: 8
Training loss: 0.3100155293941498
Validation loss: 1.633413295592031

Epoch: 6| Step: 9
Training loss: 0.5406416654586792
Validation loss: 1.6599345937851937

Epoch: 6| Step: 10
Training loss: 0.3174072206020355
Validation loss: 1.6558446961064492

Epoch: 6| Step: 11
Training loss: 0.24526669085025787
Validation loss: 1.6769062639564596

Epoch: 6| Step: 12
Training loss: 0.14600525796413422
Validation loss: 1.636725196274378

Epoch: 6| Step: 13
Training loss: 0.1475905478000641
Validation loss: 1.6439443999721157

Epoch: 387| Step: 0
Training loss: 0.20815470814704895
Validation loss: 1.6260445630678566

Epoch: 6| Step: 1
Training loss: 0.2522774040699005
Validation loss: 1.6268436030675006

Epoch: 6| Step: 2
Training loss: 0.26596373319625854
Validation loss: 1.6233431946846746

Epoch: 6| Step: 3
Training loss: 0.2800205945968628
Validation loss: 1.6619243262916483

Epoch: 6| Step: 4
Training loss: 0.6524312496185303
Validation loss: 1.6928599162768292

Epoch: 6| Step: 5
Training loss: 0.3348417282104492
Validation loss: 1.6806437315479401

Epoch: 6| Step: 6
Training loss: 0.21371310949325562
Validation loss: 1.6934082866996847

Epoch: 6| Step: 7
Training loss: 0.2051084190607071
Validation loss: 1.7125204135012884

Epoch: 6| Step: 8
Training loss: 0.5132985711097717
Validation loss: 1.7234445797499789

Epoch: 6| Step: 9
Training loss: 0.2900838851928711
Validation loss: 1.7318987243918962

Epoch: 6| Step: 10
Training loss: 0.24283374845981598
Validation loss: 1.7361501339943177

Epoch: 6| Step: 11
Training loss: 0.4023130238056183
Validation loss: 1.7197184402455565

Epoch: 6| Step: 12
Training loss: 0.275719553232193
Validation loss: 1.726910400134261

Epoch: 6| Step: 13
Training loss: 0.37575563788414
Validation loss: 1.6878255990243727

Epoch: 388| Step: 0
Training loss: 0.219833642244339
Validation loss: 1.6921388961935555

Epoch: 6| Step: 1
Training loss: 0.2620513439178467
Validation loss: 1.6762552363898164

Epoch: 6| Step: 2
Training loss: 0.2614688575267792
Validation loss: 1.6525795613565752

Epoch: 6| Step: 3
Training loss: 0.5844120979309082
Validation loss: 1.6525796664658414

Epoch: 6| Step: 4
Training loss: 0.31071940064430237
Validation loss: 1.650495917245906

Epoch: 6| Step: 5
Training loss: 0.3890724778175354
Validation loss: 1.6580273464161863

Epoch: 6| Step: 6
Training loss: 0.2703353464603424
Validation loss: 1.640319170490388

Epoch: 6| Step: 7
Training loss: 0.12458857893943787
Validation loss: 1.6682484393478723

Epoch: 6| Step: 8
Training loss: 0.3537077009677887
Validation loss: 1.6562122914098925

Epoch: 6| Step: 9
Training loss: 0.4430363178253174
Validation loss: 1.643048547929333

Epoch: 6| Step: 10
Training loss: 0.2305031716823578
Validation loss: 1.6527241558156989

Epoch: 6| Step: 11
Training loss: 0.24964773654937744
Validation loss: 1.6463009772762176

Epoch: 6| Step: 12
Training loss: 0.46293050050735474
Validation loss: 1.6822279653241556

Epoch: 6| Step: 13
Training loss: 0.22241589426994324
Validation loss: 1.6692132834465272

Epoch: 389| Step: 0
Training loss: 0.1952226608991623
Validation loss: 1.6935849157712792

Epoch: 6| Step: 1
Training loss: 0.3360847234725952
Validation loss: 1.7327750344430246

Epoch: 6| Step: 2
Training loss: 0.44486260414123535
Validation loss: 1.7068687074927873

Epoch: 6| Step: 3
Training loss: 0.16999876499176025
Validation loss: 1.7129834928820211

Epoch: 6| Step: 4
Training loss: 0.3804127275943756
Validation loss: 1.7025331899683962

Epoch: 6| Step: 5
Training loss: 0.32225295901298523
Validation loss: 1.696118999552983

Epoch: 6| Step: 6
Training loss: 0.2196202427148819
Validation loss: 1.6663770944841447

Epoch: 6| Step: 7
Training loss: 0.4008423089981079
Validation loss: 1.6610246332742835

Epoch: 6| Step: 8
Training loss: 0.3614068925380707
Validation loss: 1.67818328385712

Epoch: 6| Step: 9
Training loss: 0.2533927857875824
Validation loss: 1.6649613662432599

Epoch: 6| Step: 10
Training loss: 0.18365982174873352
Validation loss: 1.6508706077452628

Epoch: 6| Step: 11
Training loss: 0.18230468034744263
Validation loss: 1.6554323678375573

Epoch: 6| Step: 12
Training loss: 0.3212047815322876
Validation loss: 1.6390249934247745

Epoch: 6| Step: 13
Training loss: 0.3901344835758209
Validation loss: 1.649810048841661

Epoch: 390| Step: 0
Training loss: 0.15572360157966614
Validation loss: 1.6407558584725985

Epoch: 6| Step: 1
Training loss: 0.3984701633453369
Validation loss: 1.6391707786949732

Epoch: 6| Step: 2
Training loss: 0.4410076141357422
Validation loss: 1.641414943561759

Epoch: 6| Step: 3
Training loss: 0.4117160439491272
Validation loss: 1.6574865361695648

Epoch: 6| Step: 4
Training loss: 0.3315936326980591
Validation loss: 1.6825283765792847

Epoch: 6| Step: 5
Training loss: 0.35579925775527954
Validation loss: 1.7034089462731474

Epoch: 6| Step: 6
Training loss: 0.31264543533325195
Validation loss: 1.6742016359042096

Epoch: 6| Step: 7
Training loss: 0.11002784222364426
Validation loss: 1.660312924333798

Epoch: 6| Step: 8
Training loss: 0.2288343608379364
Validation loss: 1.6796414018959127

Epoch: 6| Step: 9
Training loss: 0.2493743747472763
Validation loss: 1.6558938962157055

Epoch: 6| Step: 10
Training loss: 0.47963395714759827
Validation loss: 1.6820640525510233

Epoch: 6| Step: 11
Training loss: 0.23847445845603943
Validation loss: 1.6553791415306829

Epoch: 6| Step: 12
Training loss: 0.4327796995639801
Validation loss: 1.6852961124912385

Epoch: 6| Step: 13
Training loss: 0.17852090299129486
Validation loss: 1.6699519183046074

Epoch: 391| Step: 0
Training loss: 0.573845624923706
Validation loss: 1.671608142955329

Epoch: 6| Step: 1
Training loss: 0.19277805089950562
Validation loss: 1.6777063056986818

Epoch: 6| Step: 2
Training loss: 0.2184194177389145
Validation loss: 1.6755336715329079

Epoch: 6| Step: 3
Training loss: 0.32097840309143066
Validation loss: 1.6654945342771468

Epoch: 6| Step: 4
Training loss: 0.16905242204666138
Validation loss: 1.6515067290234309

Epoch: 6| Step: 5
Training loss: 0.17462025582790375
Validation loss: 1.668556820961737

Epoch: 6| Step: 6
Training loss: 0.3089386820793152
Validation loss: 1.6251029711897655

Epoch: 6| Step: 7
Training loss: 0.22492104768753052
Validation loss: 1.6443213839684763

Epoch: 6| Step: 8
Training loss: 0.22348695993423462
Validation loss: 1.674729670247724

Epoch: 6| Step: 9
Training loss: 0.322448194026947
Validation loss: 1.672009568060598

Epoch: 6| Step: 10
Training loss: 0.18535509705543518
Validation loss: 1.6452599135778283

Epoch: 6| Step: 11
Training loss: 0.3824310004711151
Validation loss: 1.6422395052448395

Epoch: 6| Step: 12
Training loss: 0.29507505893707275
Validation loss: 1.6645073172866658

Epoch: 6| Step: 13
Training loss: 0.34272754192352295
Validation loss: 1.6772261550349574

Epoch: 392| Step: 0
Training loss: 0.325320303440094
Validation loss: 1.6596979184817242

Epoch: 6| Step: 1
Training loss: 0.21998673677444458
Validation loss: 1.6569936852301321

Epoch: 6| Step: 2
Training loss: 0.44199711084365845
Validation loss: 1.6655141486916492

Epoch: 6| Step: 3
Training loss: 0.17172503471374512
Validation loss: 1.6655979002675703

Epoch: 6| Step: 4
Training loss: 0.3907347321510315
Validation loss: 1.660934490542258

Epoch: 6| Step: 5
Training loss: 0.21565835177898407
Validation loss: 1.6795275083152197

Epoch: 6| Step: 6
Training loss: 0.21362201869487762
Validation loss: 1.651975607359281

Epoch: 6| Step: 7
Training loss: 0.2974683344364166
Validation loss: 1.6701975304593322

Epoch: 6| Step: 8
Training loss: 0.3579193949699402
Validation loss: 1.6688294026159471

Epoch: 6| Step: 9
Training loss: 0.3412170112133026
Validation loss: 1.6968615311448292

Epoch: 6| Step: 10
Training loss: 0.2881202697753906
Validation loss: 1.6810368235393236

Epoch: 6| Step: 11
Training loss: 0.36429786682128906
Validation loss: 1.6827579429072719

Epoch: 6| Step: 12
Training loss: 0.34491395950317383
Validation loss: 1.6763935281384377

Epoch: 6| Step: 13
Training loss: 0.10706789791584015
Validation loss: 1.6684969599528978

Epoch: 393| Step: 0
Training loss: 0.16198231279850006
Validation loss: 1.6936475538438367

Epoch: 6| Step: 1
Training loss: 0.21153667569160461
Validation loss: 1.6730059885209607

Epoch: 6| Step: 2
Training loss: 0.1700928509235382
Validation loss: 1.6760893316679104

Epoch: 6| Step: 3
Training loss: 0.41713234782218933
Validation loss: 1.6591055547037432

Epoch: 6| Step: 4
Training loss: 0.30643928050994873
Validation loss: 1.6757290286402549

Epoch: 6| Step: 5
Training loss: 0.34908026456832886
Validation loss: 1.6648072196591286

Epoch: 6| Step: 6
Training loss: 0.4454687535762787
Validation loss: 1.6442301965528918

Epoch: 6| Step: 7
Training loss: 0.25047796964645386
Validation loss: 1.655229841509173

Epoch: 6| Step: 8
Training loss: 0.1846168339252472
Validation loss: 1.6618916719190535

Epoch: 6| Step: 9
Training loss: 0.34510254859924316
Validation loss: 1.6611614804114065

Epoch: 6| Step: 10
Training loss: 0.14880722761154175
Validation loss: 1.6489996628094745

Epoch: 6| Step: 11
Training loss: 0.38948535919189453
Validation loss: 1.6551732452966834

Epoch: 6| Step: 12
Training loss: 0.17038536071777344
Validation loss: 1.6567575290638914

Epoch: 6| Step: 13
Training loss: 0.20055565237998962
Validation loss: 1.671393890534678

Epoch: 394| Step: 0
Training loss: 0.23949629068374634
Validation loss: 1.61434615811994

Epoch: 6| Step: 1
Training loss: 0.34995362162590027
Validation loss: 1.634214367917789

Epoch: 6| Step: 2
Training loss: 0.34364309906959534
Validation loss: 1.6256505558567662

Epoch: 6| Step: 3
Training loss: 0.18129128217697144
Validation loss: 1.6437621924184984

Epoch: 6| Step: 4
Training loss: 0.27769574522972107
Validation loss: 1.615798842522406

Epoch: 6| Step: 5
Training loss: 0.379638671875
Validation loss: 1.6279289030259656

Epoch: 6| Step: 6
Training loss: 0.3299790620803833
Validation loss: 1.6436812646927372

Epoch: 6| Step: 7
Training loss: 0.40238770842552185
Validation loss: 1.611905873462718

Epoch: 6| Step: 8
Training loss: 0.17040285468101501
Validation loss: 1.6359655857086182

Epoch: 6| Step: 9
Training loss: 0.3267293870449066
Validation loss: 1.600415829689272

Epoch: 6| Step: 10
Training loss: 0.17008695006370544
Validation loss: 1.6197736147911317

Epoch: 6| Step: 11
Training loss: 0.16452176868915558
Validation loss: 1.6376394635887557

Epoch: 6| Step: 12
Training loss: 0.16513893008232117
Validation loss: 1.6485698332068741

Epoch: 6| Step: 13
Training loss: 0.18327367305755615
Validation loss: 1.6477844907391457

Epoch: 395| Step: 0
Training loss: 0.29711025953292847
Validation loss: 1.640326524293551

Epoch: 6| Step: 1
Training loss: 0.27986109256744385
Validation loss: 1.6141112478830482

Epoch: 6| Step: 2
Training loss: 0.245155930519104
Validation loss: 1.6515282059228549

Epoch: 6| Step: 3
Training loss: 0.27460968494415283
Validation loss: 1.675174359352358

Epoch: 6| Step: 4
Training loss: 0.237306609749794
Validation loss: 1.679024015703509

Epoch: 6| Step: 5
Training loss: 0.2558019161224365
Validation loss: 1.6872483812352663

Epoch: 6| Step: 6
Training loss: 0.33004486560821533
Validation loss: 1.669684415222496

Epoch: 6| Step: 7
Training loss: 0.2865656614303589
Validation loss: 1.6360219793934976

Epoch: 6| Step: 8
Training loss: 0.6217673420906067
Validation loss: 1.6428769224433488

Epoch: 6| Step: 9
Training loss: 0.29704612493515015
Validation loss: 1.6544658471179265

Epoch: 6| Step: 10
Training loss: 0.1811671406030655
Validation loss: 1.6670720141421083

Epoch: 6| Step: 11
Training loss: 0.21261954307556152
Validation loss: 1.6610347852912

Epoch: 6| Step: 12
Training loss: 0.20203125476837158
Validation loss: 1.653161177071192

Epoch: 6| Step: 13
Training loss: 0.08753453195095062
Validation loss: 1.6221089709189631

Epoch: 396| Step: 0
Training loss: 0.41410326957702637
Validation loss: 1.6321015665608067

Epoch: 6| Step: 1
Training loss: 0.22367793321609497
Validation loss: 1.6307489320796023

Epoch: 6| Step: 2
Training loss: 0.20619289577007294
Validation loss: 1.6496820167828632

Epoch: 6| Step: 3
Training loss: 0.291512131690979
Validation loss: 1.6432575333502986

Epoch: 6| Step: 4
Training loss: 0.3465248942375183
Validation loss: 1.6634552850518176

Epoch: 6| Step: 5
Training loss: 0.4182392656803131
Validation loss: 1.6294241425811604

Epoch: 6| Step: 6
Training loss: 0.33108124136924744
Validation loss: 1.6328592979779808

Epoch: 6| Step: 7
Training loss: 0.16869361698627472
Validation loss: 1.627240252751176

Epoch: 6| Step: 8
Training loss: 0.22967177629470825
Validation loss: 1.625104824701945

Epoch: 6| Step: 9
Training loss: 0.23855380713939667
Validation loss: 1.678462492522373

Epoch: 6| Step: 10
Training loss: 0.32229307293891907
Validation loss: 1.6804217958963046

Epoch: 6| Step: 11
Training loss: 0.1594613790512085
Validation loss: 1.6883557445259505

Epoch: 6| Step: 12
Training loss: 0.2902207672595978
Validation loss: 1.7075758569984025

Epoch: 6| Step: 13
Training loss: 0.19734707474708557
Validation loss: 1.7190088302858415

Epoch: 397| Step: 0
Training loss: 0.24377626180648804
Validation loss: 1.6662379618613952

Epoch: 6| Step: 1
Training loss: 0.34123194217681885
Validation loss: 1.6708564726255273

Epoch: 6| Step: 2
Training loss: 0.24461369216442108
Validation loss: 1.6580858128045195

Epoch: 6| Step: 3
Training loss: 0.16427919268608093
Validation loss: 1.6160861612648092

Epoch: 6| Step: 4
Training loss: 0.3031120002269745
Validation loss: 1.6067448739082582

Epoch: 6| Step: 5
Training loss: 0.460954487323761
Validation loss: 1.613484255729183

Epoch: 6| Step: 6
Training loss: 0.2678298354148865
Validation loss: 1.5783225490200905

Epoch: 6| Step: 7
Training loss: 0.19912922382354736
Validation loss: 1.6033028876909645

Epoch: 6| Step: 8
Training loss: 0.25244081020355225
Validation loss: 1.5788645577687088

Epoch: 6| Step: 9
Training loss: 0.22244450449943542
Validation loss: 1.5828592008160007

Epoch: 6| Step: 10
Training loss: 0.36465758085250854
Validation loss: 1.5946211917425996

Epoch: 6| Step: 11
Training loss: 0.33079302310943604
Validation loss: 1.6181166851392357

Epoch: 6| Step: 12
Training loss: 0.2784147560596466
Validation loss: 1.612044676657646

Epoch: 6| Step: 13
Training loss: 0.2114996463060379
Validation loss: 1.6519676203368812

Epoch: 398| Step: 0
Training loss: 0.2906453609466553
Validation loss: 1.659669804316695

Epoch: 6| Step: 1
Training loss: 0.19889557361602783
Validation loss: 1.6627709340023737

Epoch: 6| Step: 2
Training loss: 0.16273298859596252
Validation loss: 1.6926685667807055

Epoch: 6| Step: 3
Training loss: 0.35490894317626953
Validation loss: 1.6795974187953497

Epoch: 6| Step: 4
Training loss: 0.20411242544651031
Validation loss: 1.6745574602516748

Epoch: 6| Step: 5
Training loss: 0.27834099531173706
Validation loss: 1.660191141149049

Epoch: 6| Step: 6
Training loss: 0.31455057859420776
Validation loss: 1.644326207458332

Epoch: 6| Step: 7
Training loss: 0.2550486922264099
Validation loss: 1.6355125904083252

Epoch: 6| Step: 8
Training loss: 0.4141956567764282
Validation loss: 1.605012818049359

Epoch: 6| Step: 9
Training loss: 0.2821882367134094
Validation loss: 1.6397379585491714

Epoch: 6| Step: 10
Training loss: 0.35204559564590454
Validation loss: 1.6165946170847902

Epoch: 6| Step: 11
Training loss: 0.20056326687335968
Validation loss: 1.635453986865218

Epoch: 6| Step: 12
Training loss: 0.22145965695381165
Validation loss: 1.6479150556748914

Epoch: 6| Step: 13
Training loss: 0.4340023398399353
Validation loss: 1.6392953959844445

Epoch: 399| Step: 0
Training loss: 0.25423523783683777
Validation loss: 1.6547619168476393

Epoch: 6| Step: 1
Training loss: 0.09598410129547119
Validation loss: 1.652575518495293

Epoch: 6| Step: 2
Training loss: 0.2472369372844696
Validation loss: 1.6572534589357273

Epoch: 6| Step: 3
Training loss: 0.4092225432395935
Validation loss: 1.6808994431649484

Epoch: 6| Step: 4
Training loss: 0.20795926451683044
Validation loss: 1.6512710227761218

Epoch: 6| Step: 5
Training loss: 0.19354990124702454
Validation loss: 1.6620475951061453

Epoch: 6| Step: 6
Training loss: 0.3055083155632019
Validation loss: 1.6649247100276332

Epoch: 6| Step: 7
Training loss: 0.17147371172904968
Validation loss: 1.653621478747296

Epoch: 6| Step: 8
Training loss: 0.2993733286857605
Validation loss: 1.6755218557132188

Epoch: 6| Step: 9
Training loss: 0.18582533299922943
Validation loss: 1.6871674650458879

Epoch: 6| Step: 10
Training loss: 0.2938694655895233
Validation loss: 1.6634152102214035

Epoch: 6| Step: 11
Training loss: 0.29198819398880005
Validation loss: 1.6680077929650583

Epoch: 6| Step: 12
Training loss: 0.291095495223999
Validation loss: 1.6739909930895733

Epoch: 6| Step: 13
Training loss: 0.4644836187362671
Validation loss: 1.6930087824021616

Epoch: 400| Step: 0
Training loss: 0.26343655586242676
Validation loss: 1.6863333025286276

Epoch: 6| Step: 1
Training loss: 0.1767776757478714
Validation loss: 1.6605170696012435

Epoch: 6| Step: 2
Training loss: 0.1766034960746765
Validation loss: 1.6834224103599467

Epoch: 6| Step: 3
Training loss: 0.2631056010723114
Validation loss: 1.6724924143924509

Epoch: 6| Step: 4
Training loss: 0.3258458971977234
Validation loss: 1.6341913630885463

Epoch: 6| Step: 5
Training loss: 0.29349231719970703
Validation loss: 1.658024667411722

Epoch: 6| Step: 6
Training loss: 0.23575754463672638
Validation loss: 1.611660272844376

Epoch: 6| Step: 7
Training loss: 0.23631325364112854
Validation loss: 1.620347156319567

Epoch: 6| Step: 8
Training loss: 0.3330749273300171
Validation loss: 1.6005752560912923

Epoch: 6| Step: 9
Training loss: 0.21943897008895874
Validation loss: 1.591611159745083

Epoch: 6| Step: 10
Training loss: 0.3138967752456665
Validation loss: 1.5897293654821252

Epoch: 6| Step: 11
Training loss: 0.2734629809856415
Validation loss: 1.6178184234967796

Epoch: 6| Step: 12
Training loss: 0.2711717486381531
Validation loss: 1.6157992988504388

Epoch: 6| Step: 13
Training loss: 0.3357775807380676
Validation loss: 1.6461208071759952

Testing loss: 2.07328241666158
