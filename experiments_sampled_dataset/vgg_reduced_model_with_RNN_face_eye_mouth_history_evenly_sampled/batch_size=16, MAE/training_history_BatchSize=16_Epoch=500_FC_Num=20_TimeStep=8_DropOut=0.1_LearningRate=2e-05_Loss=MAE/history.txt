Epoch: 1| Step: 0
Training loss: 5.848413467407227
Validation loss: 5.27145556993382

Epoch: 6| Step: 1
Training loss: 4.71409797668457
Validation loss: 5.251746628874091

Epoch: 6| Step: 2
Training loss: 7.062114715576172
Validation loss: 5.23366972707933

Epoch: 6| Step: 3
Training loss: 4.7002410888671875
Validation loss: 5.213713133206931

Epoch: 6| Step: 4
Training loss: 6.0721540451049805
Validation loss: 5.190893270636118

Epoch: 6| Step: 5
Training loss: 3.087980270385742
Validation loss: 5.1646283877793175

Epoch: 6| Step: 6
Training loss: 5.442959785461426
Validation loss: 5.135375381797872

Epoch: 6| Step: 7
Training loss: 3.812410831451416
Validation loss: 5.102089522987284

Epoch: 6| Step: 8
Training loss: 4.999663829803467
Validation loss: 5.063511022957423

Epoch: 6| Step: 9
Training loss: 5.230849266052246
Validation loss: 5.020108894635272

Epoch: 6| Step: 10
Training loss: 4.169687271118164
Validation loss: 4.971803203705819

Epoch: 6| Step: 11
Training loss: 4.524422645568848
Validation loss: 4.917707735492337

Epoch: 6| Step: 12
Training loss: 4.784589767456055
Validation loss: 4.859198759960872

Epoch: 6| Step: 13
Training loss: 3.4162888526916504
Validation loss: 4.796094835445445

Epoch: 2| Step: 0
Training loss: 4.811118125915527
Validation loss: 4.732016999234435

Epoch: 6| Step: 1
Training loss: 4.222723007202148
Validation loss: 4.6682637865825365

Epoch: 6| Step: 2
Training loss: 5.358232021331787
Validation loss: 4.6041955332602225

Epoch: 6| Step: 3
Training loss: 4.22690486907959
Validation loss: 4.543566288486604

Epoch: 6| Step: 4
Training loss: 3.7913684844970703
Validation loss: 4.486935641175958

Epoch: 6| Step: 5
Training loss: 4.393373012542725
Validation loss: 4.43062198802989

Epoch: 6| Step: 6
Training loss: 3.0839223861694336
Validation loss: 4.379641368824949

Epoch: 6| Step: 7
Training loss: 2.7821664810180664
Validation loss: 4.327645368473505

Epoch: 6| Step: 8
Training loss: 4.922095775604248
Validation loss: 4.28240583788964

Epoch: 6| Step: 9
Training loss: 4.761045455932617
Validation loss: 4.237916141427974

Epoch: 6| Step: 10
Training loss: 5.973623275756836
Validation loss: 4.200837622406662

Epoch: 6| Step: 11
Training loss: 3.81321120262146
Validation loss: 4.169221037177629

Epoch: 6| Step: 12
Training loss: 3.250000476837158
Validation loss: 4.142534184199508

Epoch: 6| Step: 13
Training loss: 2.86647891998291
Validation loss: 4.1140152049321

Epoch: 3| Step: 0
Training loss: 3.0896036624908447
Validation loss: 4.087985866813249

Epoch: 6| Step: 1
Training loss: 3.2938005924224854
Validation loss: 4.058901258694228

Epoch: 6| Step: 2
Training loss: 3.249861478805542
Validation loss: 4.025616320230627

Epoch: 6| Step: 3
Training loss: 3.954486846923828
Validation loss: 3.9799225663626068

Epoch: 6| Step: 4
Training loss: 3.732357978820801
Validation loss: 3.9432827221449984

Epoch: 6| Step: 5
Training loss: 4.22946834564209
Validation loss: 3.9272540666723765

Epoch: 6| Step: 6
Training loss: 3.6124372482299805
Validation loss: 3.910800882565078

Epoch: 6| Step: 7
Training loss: 2.659677267074585
Validation loss: 3.895222792061426

Epoch: 6| Step: 8
Training loss: 4.844679355621338
Validation loss: 3.8767216179960515

Epoch: 6| Step: 9
Training loss: 4.701850414276123
Validation loss: 3.846430932321856

Epoch: 6| Step: 10
Training loss: 3.3898353576660156
Validation loss: 3.828448321229668

Epoch: 6| Step: 11
Training loss: 4.504731178283691
Validation loss: 3.809120726841752

Epoch: 6| Step: 12
Training loss: 3.774738311767578
Validation loss: 3.7910369262900403

Epoch: 6| Step: 13
Training loss: 4.113370895385742
Validation loss: 3.773401347539758

Epoch: 4| Step: 0
Training loss: 2.9086833000183105
Validation loss: 3.75589931139382

Epoch: 6| Step: 1
Training loss: 4.542723178863525
Validation loss: 3.7402136197654148

Epoch: 6| Step: 2
Training loss: 3.2294931411743164
Validation loss: 3.7234032051537627

Epoch: 6| Step: 3
Training loss: 4.236478805541992
Validation loss: 3.7034103075663247

Epoch: 6| Step: 4
Training loss: 3.824495792388916
Validation loss: 3.681237374582598

Epoch: 6| Step: 5
Training loss: 3.068147659301758
Validation loss: 3.660580522270613

Epoch: 6| Step: 6
Training loss: 3.447594165802002
Validation loss: 3.637332139476653

Epoch: 6| Step: 7
Training loss: 3.545539379119873
Validation loss: 3.616269806379913

Epoch: 6| Step: 8
Training loss: 2.762890100479126
Validation loss: 3.5938472106892574

Epoch: 6| Step: 9
Training loss: 4.128261566162109
Validation loss: 3.5714966686823035

Epoch: 6| Step: 10
Training loss: 3.5013866424560547
Validation loss: 3.5533919411320842

Epoch: 6| Step: 11
Training loss: 3.081967830657959
Validation loss: 3.532380050228488

Epoch: 6| Step: 12
Training loss: 3.509317398071289
Validation loss: 3.519624048663724

Epoch: 6| Step: 13
Training loss: 4.03955078125
Validation loss: 3.5049169499387025

Epoch: 5| Step: 0
Training loss: 2.8806581497192383
Validation loss: 3.493252008192001

Epoch: 6| Step: 1
Training loss: 3.6925690174102783
Validation loss: 3.477153314057217

Epoch: 6| Step: 2
Training loss: 2.996070623397827
Validation loss: 3.4678264023155294

Epoch: 6| Step: 3
Training loss: 4.360576629638672
Validation loss: 3.4540221024585027

Epoch: 6| Step: 4
Training loss: 3.3200550079345703
Validation loss: 3.4408877075359388

Epoch: 6| Step: 5
Training loss: 3.879885196685791
Validation loss: 3.430859299116237

Epoch: 6| Step: 6
Training loss: 4.0185041427612305
Validation loss: 3.426176486476775

Epoch: 6| Step: 7
Training loss: 3.3230223655700684
Validation loss: 3.414614987629716

Epoch: 6| Step: 8
Training loss: 3.1978812217712402
Validation loss: 3.4009538055748068

Epoch: 6| Step: 9
Training loss: 3.5265064239501953
Validation loss: 3.396084554733769

Epoch: 6| Step: 10
Training loss: 2.02626895904541
Validation loss: 3.3918637562823553

Epoch: 6| Step: 11
Training loss: 3.0225107669830322
Validation loss: 3.3907635263217393

Epoch: 6| Step: 12
Training loss: 3.2089405059814453
Validation loss: 3.366499754690355

Epoch: 6| Step: 13
Training loss: 4.08960485458374
Validation loss: 3.362154486358807

Epoch: 6| Step: 0
Training loss: 4.167045593261719
Validation loss: 3.358270140104396

Epoch: 6| Step: 1
Training loss: 3.889092206954956
Validation loss: 3.3478417499091035

Epoch: 6| Step: 2
Training loss: 3.566713809967041
Validation loss: 3.3381840798162643

Epoch: 6| Step: 3
Training loss: 2.7209887504577637
Validation loss: 3.3323695326364167

Epoch: 6| Step: 4
Training loss: 4.127223491668701
Validation loss: 3.332444311470114

Epoch: 6| Step: 5
Training loss: 3.3912711143493652
Validation loss: 3.317888859779604

Epoch: 6| Step: 6
Training loss: 2.586395740509033
Validation loss: 3.308978514004779

Epoch: 6| Step: 7
Training loss: 2.8470816612243652
Validation loss: 3.297785476971698

Epoch: 6| Step: 8
Training loss: 2.6935503482818604
Validation loss: 3.2917398150249193

Epoch: 6| Step: 9
Training loss: 2.9761197566986084
Validation loss: 3.2852162135544645

Epoch: 6| Step: 10
Training loss: 3.5100598335266113
Validation loss: 3.2784136213282102

Epoch: 6| Step: 11
Training loss: 3.1270251274108887
Validation loss: 3.272673124908119

Epoch: 6| Step: 12
Training loss: 2.493130683898926
Validation loss: 3.2663412504298712

Epoch: 6| Step: 13
Training loss: 4.269821643829346
Validation loss: 3.2631394119672876

Epoch: 7| Step: 0
Training loss: 2.9646754264831543
Validation loss: 3.256345466900897

Epoch: 6| Step: 1
Training loss: 3.286799907684326
Validation loss: 3.2496807626498643

Epoch: 6| Step: 2
Training loss: 3.2294507026672363
Validation loss: 3.24289729005547

Epoch: 6| Step: 3
Training loss: 3.2219619750976562
Validation loss: 3.2362574249185543

Epoch: 6| Step: 4
Training loss: 2.4555959701538086
Validation loss: 3.2301141267181723

Epoch: 6| Step: 5
Training loss: 4.266453742980957
Validation loss: 3.226527116631949

Epoch: 6| Step: 6
Training loss: 2.9634437561035156
Validation loss: 3.22245369931703

Epoch: 6| Step: 7
Training loss: 3.177734851837158
Validation loss: 3.2169800625052503

Epoch: 6| Step: 8
Training loss: 2.8460376262664795
Validation loss: 3.214299730075303

Epoch: 6| Step: 9
Training loss: 4.420017719268799
Validation loss: 3.207076290602325

Epoch: 6| Step: 10
Training loss: 2.627323627471924
Validation loss: 3.2039221589283278

Epoch: 6| Step: 11
Training loss: 2.8392839431762695
Validation loss: 3.1983459303455968

Epoch: 6| Step: 12
Training loss: 3.821791648864746
Validation loss: 3.195615917123774

Epoch: 6| Step: 13
Training loss: 2.54836106300354
Validation loss: 3.188418980567686

Epoch: 8| Step: 0
Training loss: 2.2164466381073
Validation loss: 3.183909231616605

Epoch: 6| Step: 1
Training loss: 4.224484920501709
Validation loss: 3.178677866535802

Epoch: 6| Step: 2
Training loss: 3.4724459648132324
Validation loss: 3.169499438296082

Epoch: 6| Step: 3
Training loss: 2.01662278175354
Validation loss: 3.1615264569559405

Epoch: 6| Step: 4
Training loss: 2.7791988849639893
Validation loss: 3.156157139808901

Epoch: 6| Step: 5
Training loss: 2.1981639862060547
Validation loss: 3.1506361910091933

Epoch: 6| Step: 6
Training loss: 3.1674692630767822
Validation loss: 3.1503200351551013

Epoch: 6| Step: 7
Training loss: 3.3268027305603027
Validation loss: 3.173405688296082

Epoch: 6| Step: 8
Training loss: 3.917236328125
Validation loss: 3.1345486871657835

Epoch: 6| Step: 9
Training loss: 3.854483127593994
Validation loss: 3.134230439380933

Epoch: 6| Step: 10
Training loss: 3.613147020339966
Validation loss: 3.131762432795699

Epoch: 6| Step: 11
Training loss: 3.5771474838256836
Validation loss: 3.129471445596346

Epoch: 6| Step: 12
Training loss: 3.1732754707336426
Validation loss: 3.122205508652554

Epoch: 6| Step: 13
Training loss: 2.49704647064209
Validation loss: 3.117149147936093

Epoch: 9| Step: 0
Training loss: 3.828211784362793
Validation loss: 3.113459510187949

Epoch: 6| Step: 1
Training loss: 2.9688658714294434
Validation loss: 3.108456791088145

Epoch: 6| Step: 2
Training loss: 3.7065491676330566
Validation loss: 3.1059464229050504

Epoch: 6| Step: 3
Training loss: 2.619006633758545
Validation loss: 3.098731581882764

Epoch: 6| Step: 4
Training loss: 3.6590495109558105
Validation loss: 3.0953752789446103

Epoch: 6| Step: 5
Training loss: 2.481823444366455
Validation loss: 3.0897825225707023

Epoch: 6| Step: 6
Training loss: 3.3640663623809814
Validation loss: 3.0870582339584187

Epoch: 6| Step: 7
Training loss: 2.960878849029541
Validation loss: 3.080934868063978

Epoch: 6| Step: 8
Training loss: 2.6242873668670654
Validation loss: 3.0827660816971973

Epoch: 6| Step: 9
Training loss: 2.8845138549804688
Validation loss: 3.075093061693253

Epoch: 6| Step: 10
Training loss: 2.9014370441436768
Validation loss: 3.0664967285689486

Epoch: 6| Step: 11
Training loss: 2.8718390464782715
Validation loss: 3.0685836781737623

Epoch: 6| Step: 12
Training loss: 3.8415281772613525
Validation loss: 3.077851464671473

Epoch: 6| Step: 13
Training loss: 2.9180407524108887
Validation loss: 3.0590977463670956

Epoch: 10| Step: 0
Training loss: 3.0988831520080566
Validation loss: 3.057189772205968

Epoch: 6| Step: 1
Training loss: 2.924318790435791
Validation loss: 3.0539476615126415

Epoch: 6| Step: 2
Training loss: 3.6718664169311523
Validation loss: 3.0582205300690024

Epoch: 6| Step: 3
Training loss: 3.006430149078369
Validation loss: 3.038763669229323

Epoch: 6| Step: 4
Training loss: 3.1423301696777344
Validation loss: 3.0361511450941845

Epoch: 6| Step: 5
Training loss: 2.5029518604278564
Validation loss: 3.0355814733812885

Epoch: 6| Step: 6
Training loss: 3.696944236755371
Validation loss: 3.0325752868447253

Epoch: 6| Step: 7
Training loss: 3.242072105407715
Validation loss: 3.0287067403075514

Epoch: 6| Step: 8
Training loss: 2.837378740310669
Validation loss: 3.0246114038651988

Epoch: 6| Step: 9
Training loss: 2.4959230422973633
Validation loss: 3.0243153443900486

Epoch: 6| Step: 10
Training loss: 2.683659315109253
Validation loss: 3.0237290192675847

Epoch: 6| Step: 11
Training loss: 3.139115333557129
Validation loss: 3.024403238809237

Epoch: 6| Step: 12
Training loss: 4.1052141189575195
Validation loss: 3.0172450721904798

Epoch: 6| Step: 13
Training loss: 2.3944621086120605
Validation loss: 3.0114409692825808

Epoch: 11| Step: 0
Training loss: 2.983658790588379
Validation loss: 3.0093766130426878

Epoch: 6| Step: 1
Training loss: 2.6402432918548584
Validation loss: 3.016316931734803

Epoch: 6| Step: 2
Training loss: 3.6195316314697266
Validation loss: 3.0009487495627454

Epoch: 6| Step: 3
Training loss: 3.0293467044830322
Validation loss: 2.9951580980772614

Epoch: 6| Step: 4
Training loss: 1.8328208923339844
Validation loss: 3.003352831768733

Epoch: 6| Step: 5
Training loss: 3.3856163024902344
Validation loss: 3.0074026302624772

Epoch: 6| Step: 6
Training loss: 2.501328468322754
Validation loss: 2.997001317239577

Epoch: 6| Step: 7
Training loss: 2.4770560264587402
Validation loss: 2.9923375037408646

Epoch: 6| Step: 8
Training loss: 2.5596554279327393
Validation loss: 2.9903848427598194

Epoch: 6| Step: 9
Training loss: 3.32958722114563
Validation loss: 2.995205771538519

Epoch: 6| Step: 10
Training loss: 4.67094612121582
Validation loss: 2.986157840298068

Epoch: 6| Step: 11
Training loss: 2.9034035205841064
Validation loss: 2.975746147094234

Epoch: 6| Step: 12
Training loss: 3.857335329055786
Validation loss: 2.9781937471000095

Epoch: 6| Step: 13
Training loss: 3.1222825050354004
Validation loss: 2.985893808385377

Epoch: 12| Step: 0
Training loss: 3.543088912963867
Validation loss: 2.985426666916058

Epoch: 6| Step: 1
Training loss: 3.2889113426208496
Validation loss: 2.973047064196679

Epoch: 6| Step: 2
Training loss: 3.4086828231811523
Validation loss: 2.967495156872657

Epoch: 6| Step: 3
Training loss: 2.538717746734619
Validation loss: 2.9650765157515004

Epoch: 6| Step: 4
Training loss: 2.7526028156280518
Validation loss: 2.9649631900172078

Epoch: 6| Step: 5
Training loss: 2.792733669281006
Validation loss: 2.971682445977324

Epoch: 6| Step: 6
Training loss: 2.8225159645080566
Validation loss: 2.962666678172286

Epoch: 6| Step: 7
Training loss: 3.4678192138671875
Validation loss: 2.953965920273976

Epoch: 6| Step: 8
Training loss: 2.710479974746704
Validation loss: 2.9458381642577467

Epoch: 6| Step: 9
Training loss: 3.4876551628112793
Validation loss: 2.948154926300049

Epoch: 6| Step: 10
Training loss: 2.0443313121795654
Validation loss: 2.944526172453357

Epoch: 6| Step: 11
Training loss: 2.7128844261169434
Validation loss: 2.9405605331543954

Epoch: 6| Step: 12
Training loss: 2.9795918464660645
Validation loss: 2.934432501433998

Epoch: 6| Step: 13
Training loss: 4.730958461761475
Validation loss: 2.926488991706602

Epoch: 13| Step: 0
Training loss: 2.2223305702209473
Validation loss: 2.9237082030183528

Epoch: 6| Step: 1
Training loss: 3.3357794284820557
Validation loss: 2.923111892515613

Epoch: 6| Step: 2
Training loss: 4.179798603057861
Validation loss: 2.9209507203871206

Epoch: 6| Step: 3
Training loss: 3.148003339767456
Validation loss: 2.9309379413563716

Epoch: 6| Step: 4
Training loss: 2.0262975692749023
Validation loss: 2.923916801329582

Epoch: 6| Step: 5
Training loss: 2.3167853355407715
Validation loss: 2.9110553597891204

Epoch: 6| Step: 6
Training loss: 2.9318366050720215
Validation loss: 2.9136045440550773

Epoch: 6| Step: 7
Training loss: 4.200745582580566
Validation loss: 2.912210443968414

Epoch: 6| Step: 8
Training loss: 3.13188099861145
Validation loss: 2.911797720898864

Epoch: 6| Step: 9
Training loss: 2.185910224914551
Validation loss: 2.9088184115707234

Epoch: 6| Step: 10
Training loss: 3.646886110305786
Validation loss: 2.921539145131265

Epoch: 6| Step: 11
Training loss: 3.531635284423828
Validation loss: 2.9106853367179952

Epoch: 6| Step: 12
Training loss: 2.5411276817321777
Validation loss: 2.932146820970761

Epoch: 6| Step: 13
Training loss: 2.631049156188965
Validation loss: 2.9491477781726467

Epoch: 14| Step: 0
Training loss: 2.9360294342041016
Validation loss: 2.936760546058737

Epoch: 6| Step: 1
Training loss: 3.1025590896606445
Validation loss: 2.9414064627821728

Epoch: 6| Step: 2
Training loss: 3.6754539012908936
Validation loss: 2.9094198083364837

Epoch: 6| Step: 3
Training loss: 2.7515950202941895
Validation loss: 2.8980543844161497

Epoch: 6| Step: 4
Training loss: 3.084151268005371
Validation loss: 2.897439141427317

Epoch: 6| Step: 5
Training loss: 1.9039337635040283
Validation loss: 2.9287336231559835

Epoch: 6| Step: 6
Training loss: 3.2902214527130127
Validation loss: 2.9644914416856665

Epoch: 6| Step: 7
Training loss: 3.3765382766723633
Validation loss: 2.91074994046201

Epoch: 6| Step: 8
Training loss: 3.4352059364318848
Validation loss: 2.8824300509627148

Epoch: 6| Step: 9
Training loss: 2.9521169662475586
Validation loss: 2.887253312654393

Epoch: 6| Step: 10
Training loss: 3.13830304145813
Validation loss: 2.9232718201093775

Epoch: 6| Step: 11
Training loss: 2.8374438285827637
Validation loss: 2.956443514875186

Epoch: 6| Step: 12
Training loss: 2.940108299255371
Validation loss: 2.8978534565177014

Epoch: 6| Step: 13
Training loss: 2.482858896255493
Validation loss: 2.877542729018837

Epoch: 15| Step: 0
Training loss: 2.7698965072631836
Validation loss: 2.8692441730089087

Epoch: 6| Step: 1
Training loss: 3.457637310028076
Validation loss: 2.8748928859669673

Epoch: 6| Step: 2
Training loss: 3.6703741550445557
Validation loss: 2.884887162075248

Epoch: 6| Step: 3
Training loss: 3.4787793159484863
Validation loss: 2.8854225784219723

Epoch: 6| Step: 4
Training loss: 3.3444175720214844
Validation loss: 2.861528758079775

Epoch: 6| Step: 5
Training loss: 2.9460506439208984
Validation loss: 2.858191138954573

Epoch: 6| Step: 6
Training loss: 2.914280414581299
Validation loss: 2.862684647242228

Epoch: 6| Step: 7
Training loss: 2.871704578399658
Validation loss: 2.867438970073577

Epoch: 6| Step: 8
Training loss: 2.1112890243530273
Validation loss: 2.8726644259627148

Epoch: 6| Step: 9
Training loss: 2.376861572265625
Validation loss: 2.8641842590865267

Epoch: 6| Step: 10
Training loss: 3.4276599884033203
Validation loss: 2.8575924006841515

Epoch: 6| Step: 11
Training loss: 2.5648305416107178
Validation loss: 2.85904719239922

Epoch: 6| Step: 12
Training loss: 2.8680849075317383
Validation loss: 2.855236009884906

Epoch: 6| Step: 13
Training loss: 2.908111095428467
Validation loss: 2.851524076154155

Epoch: 16| Step: 0
Training loss: 3.557528018951416
Validation loss: 2.8485911353941886

Epoch: 6| Step: 1
Training loss: 1.9531739950180054
Validation loss: 2.844954134315573

Epoch: 6| Step: 2
Training loss: 2.6640822887420654
Validation loss: 2.839981186774469

Epoch: 6| Step: 3
Training loss: 3.190673828125
Validation loss: 2.8352930109987975

Epoch: 6| Step: 4
Training loss: 2.203258752822876
Validation loss: 2.8319782416025796

Epoch: 6| Step: 5
Training loss: 2.572335958480835
Validation loss: 2.836110717506819

Epoch: 6| Step: 6
Training loss: 3.264680862426758
Validation loss: 2.8562936398290817

Epoch: 6| Step: 7
Training loss: 3.620802402496338
Validation loss: 2.8420072729869554

Epoch: 6| Step: 8
Training loss: 3.698819637298584
Validation loss: 2.8203646265050417

Epoch: 6| Step: 9
Training loss: 3.0436978340148926
Validation loss: 2.8166574765277166

Epoch: 6| Step: 10
Training loss: 2.828416585922241
Validation loss: 2.820162726986793

Epoch: 6| Step: 11
Training loss: 3.2193655967712402
Validation loss: 2.824002076220769

Epoch: 6| Step: 12
Training loss: 2.6227314472198486
Validation loss: 2.824345865557271

Epoch: 6| Step: 13
Training loss: 2.930586814880371
Validation loss: 2.8206436480245283

Epoch: 17| Step: 0
Training loss: 2.662869453430176
Validation loss: 2.811151368643648

Epoch: 6| Step: 1
Training loss: 3.193328380584717
Validation loss: 2.810825381227719

Epoch: 6| Step: 2
Training loss: 2.6045637130737305
Validation loss: 2.8106520534843527

Epoch: 6| Step: 3
Training loss: 3.397390604019165
Validation loss: 2.8205406768347627

Epoch: 6| Step: 4
Training loss: 3.808730125427246
Validation loss: 2.8075029260368756

Epoch: 6| Step: 5
Training loss: 2.9795963764190674
Validation loss: 2.8123214988298315

Epoch: 6| Step: 6
Training loss: 3.2930431365966797
Validation loss: 2.8161435742532053

Epoch: 6| Step: 7
Training loss: 2.60481595993042
Validation loss: 2.811990837897024

Epoch: 6| Step: 8
Training loss: 2.8518292903900146
Validation loss: 2.8178915900568806

Epoch: 6| Step: 9
Training loss: 2.4460244178771973
Validation loss: 2.8237356626859276

Epoch: 6| Step: 10
Training loss: 2.1726207733154297
Validation loss: 2.819772199917865

Epoch: 6| Step: 11
Training loss: 3.213327646255493
Validation loss: 2.817526883976434

Epoch: 6| Step: 12
Training loss: 3.428920030593872
Validation loss: 2.804046748786844

Epoch: 6| Step: 13
Training loss: 2.2339460849761963
Validation loss: 2.797190994344732

Epoch: 18| Step: 0
Training loss: 3.2628746032714844
Validation loss: 2.796167755639681

Epoch: 6| Step: 1
Training loss: 2.7628002166748047
Validation loss: 2.799609527792982

Epoch: 6| Step: 2
Training loss: 3.6010994911193848
Validation loss: 2.8031087972784556

Epoch: 6| Step: 3
Training loss: 2.7854084968566895
Validation loss: 2.806605346741215

Epoch: 6| Step: 4
Training loss: 2.661482334136963
Validation loss: 2.807373180184313

Epoch: 6| Step: 5
Training loss: 3.4763448238372803
Validation loss: 2.803631933786536

Epoch: 6| Step: 6
Training loss: 2.8469903469085693
Validation loss: 2.7926161853216027

Epoch: 6| Step: 7
Training loss: 2.4222397804260254
Validation loss: 2.7848417502577587

Epoch: 6| Step: 8
Training loss: 2.756646156311035
Validation loss: 2.7812147678867465

Epoch: 6| Step: 9
Training loss: 2.7174477577209473
Validation loss: 2.7781571983009257

Epoch: 6| Step: 10
Training loss: 2.3121728897094727
Validation loss: 2.784501532072662

Epoch: 6| Step: 11
Training loss: 2.4669840335845947
Validation loss: 2.781478927981469

Epoch: 6| Step: 12
Training loss: 3.330379009246826
Validation loss: 2.7827057915349163

Epoch: 6| Step: 13
Training loss: 4.170780181884766
Validation loss: 2.7855769229191605

Epoch: 19| Step: 0
Training loss: 3.2953100204467773
Validation loss: 2.7767698610982587

Epoch: 6| Step: 1
Training loss: 2.67055082321167
Validation loss: 2.7707838781418337

Epoch: 6| Step: 2
Training loss: 3.7128024101257324
Validation loss: 2.770075394261268

Epoch: 6| Step: 3
Training loss: 3.462268590927124
Validation loss: 2.767531362912988

Epoch: 6| Step: 4
Training loss: 2.226478099822998
Validation loss: 2.7672312798038607

Epoch: 6| Step: 5
Training loss: 2.8807544708251953
Validation loss: 2.7665529148553007

Epoch: 6| Step: 6
Training loss: 2.6180074214935303
Validation loss: 2.765045896653206

Epoch: 6| Step: 7
Training loss: 2.770824909210205
Validation loss: 2.7639125008736887

Epoch: 6| Step: 8
Training loss: 2.8680930137634277
Validation loss: 2.764510364942653

Epoch: 6| Step: 9
Training loss: 2.6735100746154785
Validation loss: 2.7611955314554195

Epoch: 6| Step: 10
Training loss: 3.287391424179077
Validation loss: 2.758660703577021

Epoch: 6| Step: 11
Training loss: 2.282029867172241
Validation loss: 2.7605932809973277

Epoch: 6| Step: 12
Training loss: 3.0486693382263184
Validation loss: 2.7604819074753792

Epoch: 6| Step: 13
Training loss: 2.9956228733062744
Validation loss: 2.753597408212641

Epoch: 20| Step: 0
Training loss: 3.566373348236084
Validation loss: 2.750380036651447

Epoch: 6| Step: 1
Training loss: 2.721146821975708
Validation loss: 2.744875154187602

Epoch: 6| Step: 2
Training loss: 2.452749252319336
Validation loss: 2.7445442855999036

Epoch: 6| Step: 3
Training loss: 2.3973135948181152
Validation loss: 2.741101267517254

Epoch: 6| Step: 4
Training loss: 2.9885973930358887
Validation loss: 2.740405326248497

Epoch: 6| Step: 5
Training loss: 2.172379970550537
Validation loss: 2.73879321159855

Epoch: 6| Step: 6
Training loss: 3.045196294784546
Validation loss: 2.7380108089857202

Epoch: 6| Step: 7
Training loss: 3.305690288543701
Validation loss: 2.7382064609117407

Epoch: 6| Step: 8
Training loss: 2.28653621673584
Validation loss: 2.7371335926876275

Epoch: 6| Step: 9
Training loss: 2.700760841369629
Validation loss: 2.739265554694719

Epoch: 6| Step: 10
Training loss: 3.3704440593719482
Validation loss: 2.7377222250866633

Epoch: 6| Step: 11
Training loss: 3.6796863079071045
Validation loss: 2.738624377917218

Epoch: 6| Step: 12
Training loss: 3.081099510192871
Validation loss: 2.7377800582557597

Epoch: 6| Step: 13
Training loss: 2.6491539478302
Validation loss: 2.7336455801481843

Epoch: 21| Step: 0
Training loss: 2.220663547515869
Validation loss: 2.733508115173668

Epoch: 6| Step: 1
Training loss: 1.5291645526885986
Validation loss: 2.7311812857145905

Epoch: 6| Step: 2
Training loss: 1.7247501611709595
Validation loss: 2.730106779324111

Epoch: 6| Step: 3
Training loss: 3.194715738296509
Validation loss: 2.730578835292529

Epoch: 6| Step: 4
Training loss: 3.8134639263153076
Validation loss: 2.7256078130455426

Epoch: 6| Step: 5
Training loss: 2.9832677841186523
Validation loss: 2.7261614568771853

Epoch: 6| Step: 6
Training loss: 3.4815919399261475
Validation loss: 2.724611092639226

Epoch: 6| Step: 7
Training loss: 2.2067677974700928
Validation loss: 2.7229860521131948

Epoch: 6| Step: 8
Training loss: 2.742563247680664
Validation loss: 2.7587392919807026

Epoch: 6| Step: 9
Training loss: 3.8401029109954834
Validation loss: 2.8344700644093175

Epoch: 6| Step: 10
Training loss: 3.404646396636963
Validation loss: 2.805225469732797

Epoch: 6| Step: 11
Training loss: 3.5438742637634277
Validation loss: 2.788296189359439

Epoch: 6| Step: 12
Training loss: 3.3025803565979004
Validation loss: 2.7250541871593845

Epoch: 6| Step: 13
Training loss: 2.6579177379608154
Validation loss: 2.751783263298773

Epoch: 22| Step: 0
Training loss: 1.9266377687454224
Validation loss: 2.792974700209915

Epoch: 6| Step: 1
Training loss: 2.6481735706329346
Validation loss: 2.8216699605347006

Epoch: 6| Step: 2
Training loss: 3.1066160202026367
Validation loss: 2.818770900849373

Epoch: 6| Step: 3
Training loss: 3.2890071868896484
Validation loss: 2.755047257228564

Epoch: 6| Step: 4
Training loss: 2.8663508892059326
Validation loss: 2.7307537653112925

Epoch: 6| Step: 5
Training loss: 3.0205531120300293
Validation loss: 2.7211067163816063

Epoch: 6| Step: 6
Training loss: 2.726827621459961
Validation loss: 2.719068432366976

Epoch: 6| Step: 7
Training loss: 3.3303699493408203
Validation loss: 2.725301960463165

Epoch: 6| Step: 8
Training loss: 2.7395787239074707
Validation loss: 2.7427926012264785

Epoch: 6| Step: 9
Training loss: 3.1182661056518555
Validation loss: 2.733967573412003

Epoch: 6| Step: 10
Training loss: 2.6537394523620605
Validation loss: 2.7403186700677358

Epoch: 6| Step: 11
Training loss: 2.8889031410217285
Validation loss: 2.744714270355881

Epoch: 6| Step: 12
Training loss: 3.2402820587158203
Validation loss: 2.7464263618633313

Epoch: 6| Step: 13
Training loss: 3.2396979331970215
Validation loss: 2.7502559051718762

Epoch: 23| Step: 0
Training loss: 2.69785475730896
Validation loss: 2.7272562903742634

Epoch: 6| Step: 1
Training loss: 2.8121275901794434
Validation loss: 2.726337230333718

Epoch: 6| Step: 2
Training loss: 3.3454222679138184
Validation loss: 2.7229437546063493

Epoch: 6| Step: 3
Training loss: 2.5725622177124023
Validation loss: 2.724654036183511

Epoch: 6| Step: 4
Training loss: 2.543919086456299
Validation loss: 2.7294844760689685

Epoch: 6| Step: 5
Training loss: 2.524470329284668
Validation loss: 2.731637659893241

Epoch: 6| Step: 6
Training loss: 3.9755613803863525
Validation loss: 2.7326067083625385

Epoch: 6| Step: 7
Training loss: 2.8454246520996094
Validation loss: 2.7260507614381853

Epoch: 6| Step: 8
Training loss: 2.2115416526794434
Validation loss: 2.725973839400917

Epoch: 6| Step: 9
Training loss: 2.3726437091827393
Validation loss: 2.7168185685270574

Epoch: 6| Step: 10
Training loss: 2.9044137001037598
Validation loss: 2.7112378356277302

Epoch: 6| Step: 11
Training loss: 3.551454544067383
Validation loss: 2.7076722293771724

Epoch: 6| Step: 12
Training loss: 2.750580310821533
Validation loss: 2.70275176981444

Epoch: 6| Step: 13
Training loss: 3.475919485092163
Validation loss: 2.695742250770651

Epoch: 24| Step: 0
Training loss: 3.3764615058898926
Validation loss: 2.6947086421392297

Epoch: 6| Step: 1
Training loss: 2.9422390460968018
Validation loss: 2.691897602491481

Epoch: 6| Step: 2
Training loss: 3.0840468406677246
Validation loss: 2.6870506578876125

Epoch: 6| Step: 3
Training loss: 3.5818586349487305
Validation loss: 2.6894210436010875

Epoch: 6| Step: 4
Training loss: 3.381659507751465
Validation loss: 2.6848347827952397

Epoch: 6| Step: 5
Training loss: 2.6394665241241455
Validation loss: 2.683102177035424

Epoch: 6| Step: 6
Training loss: 2.9421443939208984
Validation loss: 2.681747095559233

Epoch: 6| Step: 7
Training loss: 2.738487720489502
Validation loss: 2.680288945474932

Epoch: 6| Step: 8
Training loss: 2.1496849060058594
Validation loss: 2.67970262804339

Epoch: 6| Step: 9
Training loss: 2.2483677864074707
Validation loss: 2.6801040531486593

Epoch: 6| Step: 10
Training loss: 2.2829627990722656
Validation loss: 2.6792814218869774

Epoch: 6| Step: 11
Training loss: 3.4970974922180176
Validation loss: 2.6770752219743628

Epoch: 6| Step: 12
Training loss: 2.0745134353637695
Validation loss: 2.677907907834617

Epoch: 6| Step: 13
Training loss: 3.247964859008789
Validation loss: 2.6787748413701213

Epoch: 25| Step: 0
Training loss: 2.9724955558776855
Validation loss: 2.6765151203319593

Epoch: 6| Step: 1
Training loss: 2.4868922233581543
Validation loss: 2.6757268200638475

Epoch: 6| Step: 2
Training loss: 3.2191967964172363
Validation loss: 2.672526059612151

Epoch: 6| Step: 3
Training loss: 2.3350212574005127
Validation loss: 2.6733132587966097

Epoch: 6| Step: 4
Training loss: 3.020782709121704
Validation loss: 2.6724815368652344

Epoch: 6| Step: 5
Training loss: 2.5978212356567383
Validation loss: 2.6701370695585847

Epoch: 6| Step: 6
Training loss: 2.480109453201294
Validation loss: 2.6681342560757875

Epoch: 6| Step: 7
Training loss: 2.55013370513916
Validation loss: 2.6705146681877876

Epoch: 6| Step: 8
Training loss: 2.1578125953674316
Validation loss: 2.6684172486746185

Epoch: 6| Step: 9
Training loss: 3.048203229904175
Validation loss: 2.6660606066385903

Epoch: 6| Step: 10
Training loss: 3.339878797531128
Validation loss: 2.665819155272617

Epoch: 6| Step: 11
Training loss: 3.3306479454040527
Validation loss: 2.6651005821843303

Epoch: 6| Step: 12
Training loss: 3.0611491203308105
Validation loss: 2.664960991951727

Epoch: 6| Step: 13
Training loss: 3.6117825508117676
Validation loss: 2.6616179661084245

Epoch: 26| Step: 0
Training loss: 2.7253732681274414
Validation loss: 2.65836432415952

Epoch: 6| Step: 1
Training loss: 2.3345119953155518
Validation loss: 2.656229826711839

Epoch: 6| Step: 2
Training loss: 2.9121601581573486
Validation loss: 2.65549865845711

Epoch: 6| Step: 3
Training loss: 2.8818271160125732
Validation loss: 2.657550299039451

Epoch: 6| Step: 4
Training loss: 2.9589083194732666
Validation loss: 2.6506146820642615

Epoch: 6| Step: 5
Training loss: 2.664095878601074
Validation loss: 2.649169091255434

Epoch: 6| Step: 6
Training loss: 2.586884021759033
Validation loss: 2.647436293222571

Epoch: 6| Step: 7
Training loss: 3.5309414863586426
Validation loss: 2.6455460235636723

Epoch: 6| Step: 8
Training loss: 2.54020357131958
Validation loss: 2.6428922350688646

Epoch: 6| Step: 9
Training loss: 2.9457976818084717
Validation loss: 2.6438782445846067

Epoch: 6| Step: 10
Training loss: 2.836742401123047
Validation loss: 2.6421744695273777

Epoch: 6| Step: 11
Training loss: 2.908992052078247
Validation loss: 2.6402138228057535

Epoch: 6| Step: 12
Training loss: 3.032038688659668
Validation loss: 2.637274719053699

Epoch: 6| Step: 13
Training loss: 2.8476152420043945
Validation loss: 2.6363982231386247

Epoch: 27| Step: 0
Training loss: 2.932582378387451
Validation loss: 2.63734314005862

Epoch: 6| Step: 1
Training loss: 2.673480749130249
Validation loss: 2.6349866121046004

Epoch: 6| Step: 2
Training loss: 2.649376392364502
Validation loss: 2.632949488137358

Epoch: 6| Step: 3
Training loss: 3.5436291694641113
Validation loss: 2.63442297391994

Epoch: 6| Step: 4
Training loss: 3.4558730125427246
Validation loss: 2.628117702340567

Epoch: 6| Step: 5
Training loss: 3.5706934928894043
Validation loss: 2.630756167955296

Epoch: 6| Step: 6
Training loss: 2.264103889465332
Validation loss: 2.6277686780498875

Epoch: 6| Step: 7
Training loss: 2.678112745285034
Validation loss: 2.6302486670914518

Epoch: 6| Step: 8
Training loss: 2.5746114253997803
Validation loss: 2.6351549497214695

Epoch: 6| Step: 9
Training loss: 3.3407251834869385
Validation loss: 2.645435015360514

Epoch: 6| Step: 10
Training loss: 1.711388111114502
Validation loss: 2.6628740808015228

Epoch: 6| Step: 11
Training loss: 2.4742488861083984
Validation loss: 2.6439512801426712

Epoch: 6| Step: 12
Training loss: 2.638045072555542
Validation loss: 2.6374404353480183

Epoch: 6| Step: 13
Training loss: 3.3205769062042236
Validation loss: 2.6354539650742725

Epoch: 28| Step: 0
Training loss: 2.4191207885742188
Validation loss: 2.630676113149171

Epoch: 6| Step: 1
Training loss: 2.805483341217041
Validation loss: 2.638602711821115

Epoch: 6| Step: 2
Training loss: 2.7075040340423584
Validation loss: 2.644626530267859

Epoch: 6| Step: 3
Training loss: 3.092978000640869
Validation loss: 2.632845683764386

Epoch: 6| Step: 4
Training loss: 3.634589195251465
Validation loss: 2.6232793664419525

Epoch: 6| Step: 5
Training loss: 2.9355835914611816
Validation loss: 2.617946550410281

Epoch: 6| Step: 6
Training loss: 3.3603053092956543
Validation loss: 2.6458835704352266

Epoch: 6| Step: 7
Training loss: 3.4006333351135254
Validation loss: 2.619969370544598

Epoch: 6| Step: 8
Training loss: 3.1317572593688965
Validation loss: 2.6209644553481892

Epoch: 6| Step: 9
Training loss: 2.1556925773620605
Validation loss: 2.6244285491205033

Epoch: 6| Step: 10
Training loss: 2.009341239929199
Validation loss: 2.6220315092353412

Epoch: 6| Step: 11
Training loss: 2.8789305686950684
Validation loss: 2.6248669316691737

Epoch: 6| Step: 12
Training loss: 2.2218098640441895
Validation loss: 2.6270401375268095

Epoch: 6| Step: 13
Training loss: 2.774902582168579
Validation loss: 2.628782759430588

Epoch: 29| Step: 0
Training loss: 2.2149620056152344
Validation loss: 2.6347214816718973

Epoch: 6| Step: 1
Training loss: 2.9120662212371826
Validation loss: 2.6417086483329855

Epoch: 6| Step: 2
Training loss: 2.783930778503418
Validation loss: 2.6237507045909925

Epoch: 6| Step: 3
Training loss: 2.9007253646850586
Validation loss: 2.6184635546899613

Epoch: 6| Step: 4
Training loss: 3.1853091716766357
Validation loss: 2.6187076337875856

Epoch: 6| Step: 5
Training loss: 2.9824485778808594
Validation loss: 2.615570891288019

Epoch: 6| Step: 6
Training loss: 2.447002649307251
Validation loss: 2.616874312841764

Epoch: 6| Step: 7
Training loss: 3.0638744831085205
Validation loss: 2.616533161491476

Epoch: 6| Step: 8
Training loss: 3.1166000366210938
Validation loss: 2.617091099421183

Epoch: 6| Step: 9
Training loss: 2.7990474700927734
Validation loss: 2.6160597442298807

Epoch: 6| Step: 10
Training loss: 2.6518845558166504
Validation loss: 2.615309061542634

Epoch: 6| Step: 11
Training loss: 2.576411247253418
Validation loss: 2.6168123522112445

Epoch: 6| Step: 12
Training loss: 3.0437512397766113
Validation loss: 2.6152365797309467

Epoch: 6| Step: 13
Training loss: 2.6875696182250977
Validation loss: 2.6115417967560473

Epoch: 30| Step: 0
Training loss: 2.7145626544952393
Validation loss: 2.6053889387397358

Epoch: 6| Step: 1
Training loss: 3.2985401153564453
Validation loss: 2.606306383686681

Epoch: 6| Step: 2
Training loss: 2.7620558738708496
Validation loss: 2.6032358164428384

Epoch: 6| Step: 3
Training loss: 2.581587076187134
Validation loss: 2.600906974525862

Epoch: 6| Step: 4
Training loss: 2.3071963787078857
Validation loss: 2.6058497633985294

Epoch: 6| Step: 5
Training loss: 2.7749946117401123
Validation loss: 2.601773056932675

Epoch: 6| Step: 6
Training loss: 2.202177047729492
Validation loss: 2.6015008649518414

Epoch: 6| Step: 7
Training loss: 2.523268938064575
Validation loss: 2.6154684558991463

Epoch: 6| Step: 8
Training loss: 2.944870948791504
Validation loss: 2.5989146565878265

Epoch: 6| Step: 9
Training loss: 3.0604522228240967
Validation loss: 2.6023792887246735

Epoch: 6| Step: 10
Training loss: 3.2889657020568848
Validation loss: 2.599549492200216

Epoch: 6| Step: 11
Training loss: 3.578220844268799
Validation loss: 2.602935988415954

Epoch: 6| Step: 12
Training loss: 2.3172333240509033
Validation loss: 2.6022989493544384

Epoch: 6| Step: 13
Training loss: 3.0096263885498047
Validation loss: 2.6122084817578717

Epoch: 31| Step: 0
Training loss: 2.5979952812194824
Validation loss: 2.614244907133041

Epoch: 6| Step: 1
Training loss: 3.3445076942443848
Validation loss: 2.617080080893732

Epoch: 6| Step: 2
Training loss: 2.845724582672119
Validation loss: 2.614792311063377

Epoch: 6| Step: 3
Training loss: 2.7731990814208984
Validation loss: 2.615268122765326

Epoch: 6| Step: 4
Training loss: 2.836090564727783
Validation loss: 2.6159972631803123

Epoch: 6| Step: 5
Training loss: 2.850555181503296
Validation loss: 2.60133372840061

Epoch: 6| Step: 6
Training loss: 2.7399158477783203
Validation loss: 2.5947707032644622

Epoch: 6| Step: 7
Training loss: 3.2031826972961426
Validation loss: 2.5824248226740028

Epoch: 6| Step: 8
Training loss: 2.773550510406494
Validation loss: 2.580844868895828

Epoch: 6| Step: 9
Training loss: 2.5674233436584473
Validation loss: 2.585516027224961

Epoch: 6| Step: 10
Training loss: 2.532400608062744
Validation loss: 2.754436792865876

Epoch: 6| Step: 11
Training loss: 2.5535929203033447
Validation loss: 2.7618449503375637

Epoch: 6| Step: 12
Training loss: 2.7403578758239746
Validation loss: 2.7560371480962282

Epoch: 6| Step: 13
Training loss: 3.1239397525787354
Validation loss: 2.740252758866997

Epoch: 32| Step: 0
Training loss: 2.754941463470459
Validation loss: 2.7200542214096233

Epoch: 6| Step: 1
Training loss: 2.8087689876556396
Validation loss: 2.6692493936066986

Epoch: 6| Step: 2
Training loss: 2.568845272064209
Validation loss: 2.654717776083177

Epoch: 6| Step: 3
Training loss: 2.1221137046813965
Validation loss: 2.6558402148626183

Epoch: 6| Step: 4
Training loss: 2.395526647567749
Validation loss: 2.6234415128666866

Epoch: 6| Step: 5
Training loss: 2.7240242958068848
Validation loss: 2.6253351998585526

Epoch: 6| Step: 6
Training loss: 2.92014217376709
Validation loss: 2.6387365915442027

Epoch: 6| Step: 7
Training loss: 3.4541444778442383
Validation loss: 2.6490074306406

Epoch: 6| Step: 8
Training loss: 2.607046127319336
Validation loss: 2.629774408955728

Epoch: 6| Step: 9
Training loss: 2.430795431137085
Validation loss: 2.6132588591626895

Epoch: 6| Step: 10
Training loss: 3.717060089111328
Validation loss: 2.5972407812713296

Epoch: 6| Step: 11
Training loss: 2.9356186389923096
Validation loss: 2.5907829192376908

Epoch: 6| Step: 12
Training loss: 2.911503791809082
Validation loss: 2.5876123418090162

Epoch: 6| Step: 13
Training loss: 3.5591256618499756
Validation loss: 2.5846429358246508

Epoch: 33| Step: 0
Training loss: 2.6672275066375732
Validation loss: 2.5809330376245643

Epoch: 6| Step: 1
Training loss: 2.9423632621765137
Validation loss: 2.5722937250650055

Epoch: 6| Step: 2
Training loss: 2.682124614715576
Validation loss: 2.5710013758751655

Epoch: 6| Step: 3
Training loss: 2.4569292068481445
Validation loss: 2.577027086288698

Epoch: 6| Step: 4
Training loss: 2.578465700149536
Validation loss: 2.6360503268498245

Epoch: 6| Step: 5
Training loss: 3.1810102462768555
Validation loss: 3.037743901693693

Epoch: 6| Step: 6
Training loss: 3.8456928730010986
Validation loss: 3.16538312614605

Epoch: 6| Step: 7
Training loss: 3.1613354682922363
Validation loss: 2.759271490958429

Epoch: 6| Step: 8
Training loss: 2.5568699836730957
Validation loss: 2.5620583090730893

Epoch: 6| Step: 9
Training loss: 2.2489147186279297
Validation loss: 2.565387147729115

Epoch: 6| Step: 10
Training loss: 2.075039863586426
Validation loss: 2.6157338157776864

Epoch: 6| Step: 11
Training loss: 3.8913450241088867
Validation loss: 2.8059066521224154

Epoch: 6| Step: 12
Training loss: 2.433642864227295
Validation loss: 2.696000591401131

Epoch: 6| Step: 13
Training loss: 3.6140756607055664
Validation loss: 2.6318452614609913

Epoch: 34| Step: 0
Training loss: 2.1550779342651367
Validation loss: 2.6218476116016345

Epoch: 6| Step: 1
Training loss: 1.4250916242599487
Validation loss: 2.6235063255474134

Epoch: 6| Step: 2
Training loss: 2.3360066413879395
Validation loss: 2.614118391467679

Epoch: 6| Step: 3
Training loss: 3.1533150672912598
Validation loss: 2.6182059754607496

Epoch: 6| Step: 4
Training loss: 2.6095614433288574
Validation loss: 2.622357363341957

Epoch: 6| Step: 5
Training loss: 3.574409008026123
Validation loss: 2.6578237420769146

Epoch: 6| Step: 6
Training loss: 3.719104290008545
Validation loss: 2.694239019065775

Epoch: 6| Step: 7
Training loss: 2.881438732147217
Validation loss: 2.7376602490743003

Epoch: 6| Step: 8
Training loss: 3.240056037902832
Validation loss: 2.679328231401341

Epoch: 6| Step: 9
Training loss: 3.0846028327941895
Validation loss: 2.6480539767972884

Epoch: 6| Step: 10
Training loss: 2.6381356716156006
Validation loss: 2.587677009644047

Epoch: 6| Step: 11
Training loss: 3.358875274658203
Validation loss: 2.583368444955477

Epoch: 6| Step: 12
Training loss: 2.5341110229492188
Validation loss: 2.581966861601799

Epoch: 6| Step: 13
Training loss: 2.8021366596221924
Validation loss: 2.5694502681814213

Epoch: 35| Step: 0
Training loss: 2.1262238025665283
Validation loss: 2.5595059343563613

Epoch: 6| Step: 1
Training loss: 3.1976940631866455
Validation loss: 2.550265076339886

Epoch: 6| Step: 2
Training loss: 2.3300654888153076
Validation loss: 2.553158119160642

Epoch: 6| Step: 3
Training loss: 2.73654842376709
Validation loss: 2.55853561944859

Epoch: 6| Step: 4
Training loss: 2.0246808528900146
Validation loss: 2.5647829142949914

Epoch: 6| Step: 5
Training loss: 2.5849404335021973
Validation loss: 2.561581121977939

Epoch: 6| Step: 6
Training loss: 3.4008097648620605
Validation loss: 2.5535186003613215

Epoch: 6| Step: 7
Training loss: 3.7394776344299316
Validation loss: 2.543291753338229

Epoch: 6| Step: 8
Training loss: 3.166492462158203
Validation loss: 2.538218346975183

Epoch: 6| Step: 9
Training loss: 2.7382946014404297
Validation loss: 2.5392065125126995

Epoch: 6| Step: 10
Training loss: 2.7459449768066406
Validation loss: 2.537212453862672

Epoch: 6| Step: 11
Training loss: 1.730196237564087
Validation loss: 2.5427471130124983

Epoch: 6| Step: 12
Training loss: 3.087576150894165
Validation loss: 2.549239368848903

Epoch: 6| Step: 13
Training loss: 3.4388580322265625
Validation loss: 2.5533737213380876

Epoch: 36| Step: 0
Training loss: 2.559981346130371
Validation loss: 2.553323514999882

Epoch: 6| Step: 1
Training loss: 2.9100143909454346
Validation loss: 2.5479686183314167

Epoch: 6| Step: 2
Training loss: 2.466848134994507
Validation loss: 2.5420901160086355

Epoch: 6| Step: 3
Training loss: 2.991804599761963
Validation loss: 2.5346919977536766

Epoch: 6| Step: 4
Training loss: 3.133586883544922
Validation loss: 2.533842891775152

Epoch: 6| Step: 5
Training loss: 2.252173900604248
Validation loss: 2.5301166196023264

Epoch: 6| Step: 6
Training loss: 3.21402907371521
Validation loss: 2.5289678265971522

Epoch: 6| Step: 7
Training loss: 3.1513123512268066
Validation loss: 2.524253337613998

Epoch: 6| Step: 8
Training loss: 3.122377872467041
Validation loss: 2.525526367208009

Epoch: 6| Step: 9
Training loss: 2.302122116088867
Validation loss: 2.5244013135151198

Epoch: 6| Step: 10
Training loss: 2.797947406768799
Validation loss: 2.523208802746188

Epoch: 6| Step: 11
Training loss: 3.0184707641601562
Validation loss: 2.5223856510654574

Epoch: 6| Step: 12
Training loss: 1.7915587425231934
Validation loss: 2.5137947502956597

Epoch: 6| Step: 13
Training loss: 2.7728445529937744
Validation loss: 2.5140344660769225

Epoch: 37| Step: 0
Training loss: 2.9100520610809326
Validation loss: 2.5124600882171304

Epoch: 6| Step: 1
Training loss: 2.1023030281066895
Validation loss: 2.53440365740048

Epoch: 6| Step: 2
Training loss: 2.1715199947357178
Validation loss: 2.538140853246053

Epoch: 6| Step: 3
Training loss: 2.8645811080932617
Validation loss: 2.529692795968825

Epoch: 6| Step: 4
Training loss: 2.616183280944824
Validation loss: 2.5189198396539174

Epoch: 6| Step: 5
Training loss: 3.2280101776123047
Validation loss: 2.5104002721848024

Epoch: 6| Step: 6
Training loss: 3.1710305213928223
Validation loss: 2.510128172495032

Epoch: 6| Step: 7
Training loss: 2.5778913497924805
Validation loss: 2.5072978286332983

Epoch: 6| Step: 8
Training loss: 2.730295419692993
Validation loss: 2.511924248869701

Epoch: 6| Step: 9
Training loss: 2.772165298461914
Validation loss: 2.51440550691338

Epoch: 6| Step: 10
Training loss: 2.206481456756592
Validation loss: 2.521410736986386

Epoch: 6| Step: 11
Training loss: 2.463573455810547
Validation loss: 2.5359873310212167

Epoch: 6| Step: 12
Training loss: 2.9155490398406982
Validation loss: 2.5360917070860505

Epoch: 6| Step: 13
Training loss: 4.141851425170898
Validation loss: 2.5259467811994654

Epoch: 38| Step: 0
Training loss: 2.6951258182525635
Validation loss: 2.5268335585953086

Epoch: 6| Step: 1
Training loss: 2.975461959838867
Validation loss: 2.510861660844536

Epoch: 6| Step: 2
Training loss: 2.213876724243164
Validation loss: 2.5070682366689048

Epoch: 6| Step: 3
Training loss: 2.194023609161377
Validation loss: 2.5067334610928773

Epoch: 6| Step: 4
Training loss: 3.0524520874023438
Validation loss: 2.50887724661058

Epoch: 6| Step: 5
Training loss: 2.7156357765197754
Validation loss: 2.506860884287024

Epoch: 6| Step: 6
Training loss: 3.4042630195617676
Validation loss: 2.5025513325968096

Epoch: 6| Step: 7
Training loss: 2.6399691104888916
Validation loss: 2.5085113202371905

Epoch: 6| Step: 8
Training loss: 2.653367042541504
Validation loss: 2.5099319668226343

Epoch: 6| Step: 9
Training loss: 3.553739547729492
Validation loss: 2.506736880989485

Epoch: 6| Step: 10
Training loss: 2.995424509048462
Validation loss: 2.5007791416619414

Epoch: 6| Step: 11
Training loss: 2.10037899017334
Validation loss: 2.497579989894744

Epoch: 6| Step: 12
Training loss: 2.817692756652832
Validation loss: 2.4959235268254436

Epoch: 6| Step: 13
Training loss: 1.8512606620788574
Validation loss: 2.510338488445487

Epoch: 39| Step: 0
Training loss: 2.9657154083251953
Validation loss: 2.5209011031735327

Epoch: 6| Step: 1
Training loss: 3.054213285446167
Validation loss: 2.5265389334770942

Epoch: 6| Step: 2
Training loss: 2.0057802200317383
Validation loss: 2.5186356318894254

Epoch: 6| Step: 3
Training loss: 2.7332851886749268
Validation loss: 2.5037558770948842

Epoch: 6| Step: 4
Training loss: 2.9606406688690186
Validation loss: 2.494855487218467

Epoch: 6| Step: 5
Training loss: 2.2559943199157715
Validation loss: 2.4967915268354517

Epoch: 6| Step: 6
Training loss: 2.8224549293518066
Validation loss: 2.495825611135011

Epoch: 6| Step: 7
Training loss: 2.9576711654663086
Validation loss: 2.5008744578207693

Epoch: 6| Step: 8
Training loss: 2.8688526153564453
Validation loss: 2.5201159138833322

Epoch: 6| Step: 9
Training loss: 2.019608497619629
Validation loss: 2.5439631528751825

Epoch: 6| Step: 10
Training loss: 2.914377450942993
Validation loss: 2.554829615418629

Epoch: 6| Step: 11
Training loss: 2.8048479557037354
Validation loss: 2.518905799875977

Epoch: 6| Step: 12
Training loss: 2.6206843852996826
Validation loss: 2.500243268987184

Epoch: 6| Step: 13
Training loss: 3.5053517818450928
Validation loss: 2.489592875203779

Epoch: 40| Step: 0
Training loss: 2.1817755699157715
Validation loss: 2.4919335713950534

Epoch: 6| Step: 1
Training loss: 2.69010591506958
Validation loss: 2.493449459793747

Epoch: 6| Step: 2
Training loss: 3.4717817306518555
Validation loss: 2.4887751148593042

Epoch: 6| Step: 3
Training loss: 3.226344585418701
Validation loss: 2.4885371884992047

Epoch: 6| Step: 4
Training loss: 3.167116165161133
Validation loss: 2.4910537478744343

Epoch: 6| Step: 5
Training loss: 3.2881526947021484
Validation loss: 2.4956783915078766

Epoch: 6| Step: 6
Training loss: 3.635655403137207
Validation loss: 2.508686691202143

Epoch: 6| Step: 7
Training loss: 1.9208035469055176
Validation loss: 2.5028568416513424

Epoch: 6| Step: 8
Training loss: 2.5180561542510986
Validation loss: 2.499643130968976

Epoch: 6| Step: 9
Training loss: 1.8986985683441162
Validation loss: 2.505619031126781

Epoch: 6| Step: 10
Training loss: 2.576958179473877
Validation loss: 2.5115688385501986

Epoch: 6| Step: 11
Training loss: 2.589946746826172
Validation loss: 2.4918341072656776

Epoch: 6| Step: 12
Training loss: 2.7176151275634766
Validation loss: 2.4890778116000596

Epoch: 6| Step: 13
Training loss: 1.54587721824646
Validation loss: 2.4869590113239903

Epoch: 41| Step: 0
Training loss: 3.1023969650268555
Validation loss: 2.4915258140974146

Epoch: 6| Step: 1
Training loss: 3.1438941955566406
Validation loss: 2.4979037982161327

Epoch: 6| Step: 2
Training loss: 2.2639081478118896
Validation loss: 2.497784665835801

Epoch: 6| Step: 3
Training loss: 2.617298126220703
Validation loss: 2.503929030510687

Epoch: 6| Step: 4
Training loss: 3.4771728515625
Validation loss: 2.4927671827295774

Epoch: 6| Step: 5
Training loss: 2.1908650398254395
Validation loss: 2.488785292512627

Epoch: 6| Step: 6
Training loss: 2.7462072372436523
Validation loss: 2.486417302521326

Epoch: 6| Step: 7
Training loss: 2.8067069053649902
Validation loss: 2.4862923006857596

Epoch: 6| Step: 8
Training loss: 2.4343724250793457
Validation loss: 2.4846886357953473

Epoch: 6| Step: 9
Training loss: 2.0528998374938965
Validation loss: 2.485000859024704

Epoch: 6| Step: 10
Training loss: 3.5490148067474365
Validation loss: 2.4888822109468522

Epoch: 6| Step: 11
Training loss: 2.304774761199951
Validation loss: 2.4910199026907645

Epoch: 6| Step: 12
Training loss: 2.9476318359375
Validation loss: 2.484622232375606

Epoch: 6| Step: 13
Training loss: 2.0173959732055664
Validation loss: 2.487976269055438

Epoch: 42| Step: 0
Training loss: 2.7536425590515137
Validation loss: 2.4961130670321885

Epoch: 6| Step: 1
Training loss: 2.7713348865509033
Validation loss: 2.491859389889625

Epoch: 6| Step: 2
Training loss: 3.1140336990356445
Validation loss: 2.4908095431584183

Epoch: 6| Step: 3
Training loss: 2.2781295776367188
Validation loss: 2.4876284060939664

Epoch: 6| Step: 4
Training loss: 3.1736865043640137
Validation loss: 2.483681240389424

Epoch: 6| Step: 5
Training loss: 2.612245798110962
Validation loss: 2.4858306530983216

Epoch: 6| Step: 6
Training loss: 2.6455161571502686
Validation loss: 2.4790640325956446

Epoch: 6| Step: 7
Training loss: 2.5236024856567383
Validation loss: 2.4788915880264772

Epoch: 6| Step: 8
Training loss: 2.5540664196014404
Validation loss: 2.4824340446020967

Epoch: 6| Step: 9
Training loss: 2.789677619934082
Validation loss: 2.4795830019058718

Epoch: 6| Step: 10
Training loss: 3.0694024562835693
Validation loss: 2.4809438259370866

Epoch: 6| Step: 11
Training loss: 2.597029685974121
Validation loss: 2.4818051271541144

Epoch: 6| Step: 12
Training loss: 2.283257007598877
Validation loss: 2.4959221040048907

Epoch: 6| Step: 13
Training loss: 2.3830320835113525
Validation loss: 2.523436261761573

Epoch: 43| Step: 0
Training loss: 3.3641085624694824
Validation loss: 2.5460714268428024

Epoch: 6| Step: 1
Training loss: 3.0406806468963623
Validation loss: 2.5557891989267

Epoch: 6| Step: 2
Training loss: 2.2920939922332764
Validation loss: 2.5035427155033236

Epoch: 6| Step: 3
Training loss: 2.491328239440918
Validation loss: 2.4797929384375132

Epoch: 6| Step: 4
Training loss: 2.759591579437256
Validation loss: 2.4744725945175334

Epoch: 6| Step: 5
Training loss: 3.0262370109558105
Validation loss: 2.4815855667155278

Epoch: 6| Step: 6
Training loss: 2.4804019927978516
Validation loss: 2.48886033796495

Epoch: 6| Step: 7
Training loss: 2.828331232070923
Validation loss: 2.489539595060451

Epoch: 6| Step: 8
Training loss: 2.190483570098877
Validation loss: 2.49289305492114

Epoch: 6| Step: 9
Training loss: 3.3236544132232666
Validation loss: 2.49000064275598

Epoch: 6| Step: 10
Training loss: 3.200885057449341
Validation loss: 2.479775259571691

Epoch: 6| Step: 11
Training loss: 2.681462287902832
Validation loss: 2.4815592676080684

Epoch: 6| Step: 12
Training loss: 2.100393772125244
Validation loss: 2.479896988919986

Epoch: 6| Step: 13
Training loss: 2.1033966541290283
Validation loss: 2.4905742086390013

Epoch: 44| Step: 0
Training loss: 2.7344889640808105
Validation loss: 2.5030468817680114

Epoch: 6| Step: 1
Training loss: 1.869940161705017
Validation loss: 2.5487627957456853

Epoch: 6| Step: 2
Training loss: 2.7706551551818848
Validation loss: 2.609190299946775

Epoch: 6| Step: 3
Training loss: 3.454561233520508
Validation loss: 2.6329553588744132

Epoch: 6| Step: 4
Training loss: 1.8473656177520752
Validation loss: 2.6470437947139946

Epoch: 6| Step: 5
Training loss: 3.692188262939453
Validation loss: 2.606937651993126

Epoch: 6| Step: 6
Training loss: 2.6278834342956543
Validation loss: 2.531398860357141

Epoch: 6| Step: 7
Training loss: 3.303098201751709
Validation loss: 2.496487243201143

Epoch: 6| Step: 8
Training loss: 2.2738490104675293
Validation loss: 2.4723401300368772

Epoch: 6| Step: 9
Training loss: 3.065580368041992
Validation loss: 2.480658141515588

Epoch: 6| Step: 10
Training loss: 2.2250139713287354
Validation loss: 2.518784622992239

Epoch: 6| Step: 11
Training loss: 2.8761322498321533
Validation loss: 2.5594961284309306

Epoch: 6| Step: 12
Training loss: 2.554978609085083
Validation loss: 2.5908830319681475

Epoch: 6| Step: 13
Training loss: 3.153938055038452
Validation loss: 2.5843917708243094

Epoch: 45| Step: 0
Training loss: 2.1752376556396484
Validation loss: 2.5822549353363695

Epoch: 6| Step: 1
Training loss: 2.647819995880127
Validation loss: 2.5615063687806487

Epoch: 6| Step: 2
Training loss: 2.8892035484313965
Validation loss: 2.5336641137317946

Epoch: 6| Step: 3
Training loss: 2.9385790824890137
Validation loss: 2.506141306251608

Epoch: 6| Step: 4
Training loss: 2.6770999431610107
Validation loss: 2.483147777536864

Epoch: 6| Step: 5
Training loss: 2.745751142501831
Validation loss: 2.4680751292936263

Epoch: 6| Step: 6
Training loss: 2.701932430267334
Validation loss: 2.4768470436014156

Epoch: 6| Step: 7
Training loss: 3.308483600616455
Validation loss: 2.50134793660974

Epoch: 6| Step: 8
Training loss: 3.1560754776000977
Validation loss: 2.526899960733229

Epoch: 6| Step: 9
Training loss: 1.896653175354004
Validation loss: 2.5154402896922123

Epoch: 6| Step: 10
Training loss: 2.390108108520508
Validation loss: 2.5112581970871135

Epoch: 6| Step: 11
Training loss: 2.962709903717041
Validation loss: 2.5095858061185448

Epoch: 6| Step: 12
Training loss: 3.062220335006714
Validation loss: 2.489296564491846

Epoch: 6| Step: 13
Training loss: 2.5641963481903076
Validation loss: 2.4856615527983634

Epoch: 46| Step: 0
Training loss: 3.0848891735076904
Validation loss: 2.4506751901359967

Epoch: 6| Step: 1
Training loss: 2.668360710144043
Validation loss: 2.448959735132033

Epoch: 6| Step: 2
Training loss: 3.43389892578125
Validation loss: 2.4491371006094

Epoch: 6| Step: 3
Training loss: 1.5665018558502197
Validation loss: 2.4486272847780617

Epoch: 6| Step: 4
Training loss: 2.238640546798706
Validation loss: 2.4649192569076375

Epoch: 6| Step: 5
Training loss: 3.0118839740753174
Validation loss: 2.4912654789545203

Epoch: 6| Step: 6
Training loss: 2.835986852645874
Validation loss: 2.509154591509091

Epoch: 6| Step: 7
Training loss: 2.9894185066223145
Validation loss: 2.531041660616475

Epoch: 6| Step: 8
Training loss: 2.7894465923309326
Validation loss: 2.5874338432024886

Epoch: 6| Step: 9
Training loss: 2.378793478012085
Validation loss: 2.526410625826928

Epoch: 6| Step: 10
Training loss: 3.013195514678955
Validation loss: 2.4729592287412254

Epoch: 6| Step: 11
Training loss: 2.9402096271514893
Validation loss: 2.450933917876213

Epoch: 6| Step: 12
Training loss: 2.1115670204162598
Validation loss: 2.45345825277349

Epoch: 6| Step: 13
Training loss: 2.5697031021118164
Validation loss: 2.4588378680649625

Epoch: 47| Step: 0
Training loss: 3.3667643070220947
Validation loss: 2.4686224896420716

Epoch: 6| Step: 1
Training loss: 2.3523037433624268
Validation loss: 2.472402275249522

Epoch: 6| Step: 2
Training loss: 2.6922607421875
Validation loss: 2.4795674534254175

Epoch: 6| Step: 3
Training loss: 2.816129207611084
Validation loss: 2.4827294221488376

Epoch: 6| Step: 4
Training loss: 3.183722972869873
Validation loss: 2.4690763565801803

Epoch: 6| Step: 5
Training loss: 2.4108638763427734
Validation loss: 2.4607412533093522

Epoch: 6| Step: 6
Training loss: 3.2624294757843018
Validation loss: 2.4552013310053016

Epoch: 6| Step: 7
Training loss: 2.988215446472168
Validation loss: 2.4570182907965874

Epoch: 6| Step: 8
Training loss: 2.56325626373291
Validation loss: 2.4617208537235054

Epoch: 6| Step: 9
Training loss: 2.713167190551758
Validation loss: 2.4545679887135825

Epoch: 6| Step: 10
Training loss: 2.480116844177246
Validation loss: 2.450732946395874

Epoch: 6| Step: 11
Training loss: 2.0465872287750244
Validation loss: 2.4458412329355874

Epoch: 6| Step: 12
Training loss: 2.5823354721069336
Validation loss: 2.4400998751322427

Epoch: 6| Step: 13
Training loss: 2.0738024711608887
Validation loss: 2.436577994336364

Epoch: 48| Step: 0
Training loss: 2.3667709827423096
Validation loss: 2.4357911745707193

Epoch: 6| Step: 1
Training loss: 2.78468656539917
Validation loss: 2.435435930887858

Epoch: 6| Step: 2
Training loss: 2.5257983207702637
Validation loss: 2.4386329625242498

Epoch: 6| Step: 3
Training loss: 2.189861297607422
Validation loss: 2.4444150309408865

Epoch: 6| Step: 4
Training loss: 1.904476523399353
Validation loss: 2.4510668951977967

Epoch: 6| Step: 5
Training loss: 3.1023149490356445
Validation loss: 2.476041724604945

Epoch: 6| Step: 6
Training loss: 3.375565528869629
Validation loss: 2.4919127264330463

Epoch: 6| Step: 7
Training loss: 2.8521392345428467
Validation loss: 2.478344122568766

Epoch: 6| Step: 8
Training loss: 2.8862533569335938
Validation loss: 2.4504405644632157

Epoch: 6| Step: 9
Training loss: 2.93696928024292
Validation loss: 2.4347797183580298

Epoch: 6| Step: 10
Training loss: 2.8155007362365723
Validation loss: 2.431980966239847

Epoch: 6| Step: 11
Training loss: 2.529106616973877
Validation loss: 2.4304312788030153

Epoch: 6| Step: 12
Training loss: 2.900735855102539
Validation loss: 2.429095568195466

Epoch: 6| Step: 13
Training loss: 2.1542470455169678
Validation loss: 2.4287749157156995

Epoch: 49| Step: 0
Training loss: 2.7603092193603516
Validation loss: 2.425553562820599

Epoch: 6| Step: 1
Training loss: 2.0816941261291504
Validation loss: 2.424326745412683

Epoch: 6| Step: 2
Training loss: 2.587524890899658
Validation loss: 2.42544622318719

Epoch: 6| Step: 3
Training loss: 2.7297537326812744
Validation loss: 2.424379356445805

Epoch: 6| Step: 4
Training loss: 2.09910249710083
Validation loss: 2.432242365293605

Epoch: 6| Step: 5
Training loss: 2.1913552284240723
Validation loss: 2.444599954030847

Epoch: 6| Step: 6
Training loss: 2.249265193939209
Validation loss: 2.4582094248904975

Epoch: 6| Step: 7
Training loss: 3.615471601486206
Validation loss: 2.466110670438377

Epoch: 6| Step: 8
Training loss: 3.577899217605591
Validation loss: 2.459317191954582

Epoch: 6| Step: 9
Training loss: 2.593784809112549
Validation loss: 2.4618370430443877

Epoch: 6| Step: 10
Training loss: 2.8734421730041504
Validation loss: 2.464425169011598

Epoch: 6| Step: 11
Training loss: 2.35850191116333
Validation loss: 2.4480496042518207

Epoch: 6| Step: 12
Training loss: 2.683104991912842
Validation loss: 2.436931784434985

Epoch: 6| Step: 13
Training loss: 3.1316845417022705
Validation loss: 2.427395805235832

Epoch: 50| Step: 0
Training loss: 2.872025489807129
Validation loss: 2.423757630009805

Epoch: 6| Step: 1
Training loss: 2.357541799545288
Validation loss: 2.4241038830049577

Epoch: 6| Step: 2
Training loss: 2.8412668704986572
Validation loss: 2.4267481809021323

Epoch: 6| Step: 3
Training loss: 2.481231689453125
Validation loss: 2.4289138881109094

Epoch: 6| Step: 4
Training loss: 2.579387664794922
Validation loss: 2.436896606158185

Epoch: 6| Step: 5
Training loss: 2.833353042602539
Validation loss: 2.437381734130203

Epoch: 6| Step: 6
Training loss: 2.81528377532959
Validation loss: 2.446199599132743

Epoch: 6| Step: 7
Training loss: 3.0765938758850098
Validation loss: 2.431940729900073

Epoch: 6| Step: 8
Training loss: 2.543428659439087
Validation loss: 2.428848102528562

Epoch: 6| Step: 9
Training loss: 2.2196850776672363
Validation loss: 2.418834364542397

Epoch: 6| Step: 10
Training loss: 2.117885112762451
Validation loss: 2.4146231015523276

Epoch: 6| Step: 11
Training loss: 3.1010901927948
Validation loss: 2.417434807746641

Epoch: 6| Step: 12
Training loss: 2.773407220840454
Validation loss: 2.4193153791530158

Epoch: 6| Step: 13
Training loss: 2.688061237335205
Validation loss: 2.4225078269999516

Epoch: 51| Step: 0
Training loss: 2.939929485321045
Validation loss: 2.4229894812389086

Epoch: 6| Step: 1
Training loss: 2.468578815460205
Validation loss: 2.426962939641809

Epoch: 6| Step: 2
Training loss: 2.9009063243865967
Validation loss: 2.419954198662953

Epoch: 6| Step: 3
Training loss: 2.701587677001953
Validation loss: 2.4306513852970575

Epoch: 6| Step: 4
Training loss: 2.4160876274108887
Validation loss: 2.4352913031014065

Epoch: 6| Step: 5
Training loss: 3.004240036010742
Validation loss: 2.533847531964702

Epoch: 6| Step: 6
Training loss: 3.068385601043701
Validation loss: 2.631392889125373

Epoch: 6| Step: 7
Training loss: 1.6241869926452637
Validation loss: 2.6117628517971245

Epoch: 6| Step: 8
Training loss: 3.237161159515381
Validation loss: 2.4916549754399124

Epoch: 6| Step: 9
Training loss: 2.9117696285247803
Validation loss: 2.4462599318514586

Epoch: 6| Step: 10
Training loss: 1.8826658725738525
Validation loss: 2.4298412722925984

Epoch: 6| Step: 11
Training loss: 3.076951503753662
Validation loss: 2.4077588870961177

Epoch: 6| Step: 12
Training loss: 2.6425819396972656
Validation loss: 2.4055095757207563

Epoch: 6| Step: 13
Training loss: 2.5070958137512207
Validation loss: 2.4099101392171716

Epoch: 52| Step: 0
Training loss: 2.434469223022461
Validation loss: 2.4054316679636636

Epoch: 6| Step: 1
Training loss: 2.445261001586914
Validation loss: 2.409739053377541

Epoch: 6| Step: 2
Training loss: 2.836970090866089
Validation loss: 2.4105323617176344

Epoch: 6| Step: 3
Training loss: 3.2102108001708984
Validation loss: 2.4132871217625116

Epoch: 6| Step: 4
Training loss: 2.5675208568573
Validation loss: 2.4113702850957073

Epoch: 6| Step: 5
Training loss: 1.7608606815338135
Validation loss: 2.4176209075476534

Epoch: 6| Step: 6
Training loss: 2.9056286811828613
Validation loss: 2.450900811021046

Epoch: 6| Step: 7
Training loss: 2.77842378616333
Validation loss: 2.4061848476368892

Epoch: 6| Step: 8
Training loss: 3.167128801345825
Validation loss: 2.3996539782452326

Epoch: 6| Step: 9
Training loss: 2.4491257667541504
Validation loss: 2.3935183299485074

Epoch: 6| Step: 10
Training loss: 2.8682165145874023
Validation loss: 2.405103137416224

Epoch: 6| Step: 11
Training loss: 2.741245985031128
Validation loss: 2.400602909826463

Epoch: 6| Step: 12
Training loss: 1.810727596282959
Validation loss: 2.4133711912298716

Epoch: 6| Step: 13
Training loss: 3.685866117477417
Validation loss: 2.4248955352332002

Epoch: 53| Step: 0
Training loss: 2.3547658920288086
Validation loss: 2.4507726956439275

Epoch: 6| Step: 1
Training loss: 2.2461299896240234
Validation loss: 2.46775282326565

Epoch: 6| Step: 2
Training loss: 2.41424298286438
Validation loss: 2.4846943014411518

Epoch: 6| Step: 3
Training loss: 2.776430606842041
Validation loss: 2.489719183214249

Epoch: 6| Step: 4
Training loss: 3.0079970359802246
Validation loss: 2.5006953798314577

Epoch: 6| Step: 5
Training loss: 1.948991298675537
Validation loss: 2.502364650849373

Epoch: 6| Step: 6
Training loss: 2.7285046577453613
Validation loss: 2.4972188036928893

Epoch: 6| Step: 7
Training loss: 3.126486301422119
Validation loss: 2.446964802280549

Epoch: 6| Step: 8
Training loss: 2.824897289276123
Validation loss: 2.4374776168536116

Epoch: 6| Step: 9
Training loss: 2.3668951988220215
Validation loss: 2.417066281841647

Epoch: 6| Step: 10
Training loss: 2.2958033084869385
Validation loss: 2.407040766490403

Epoch: 6| Step: 11
Training loss: 3.2071731090545654
Validation loss: 2.3931923835508284

Epoch: 6| Step: 12
Training loss: 3.0588502883911133
Validation loss: 2.384818979488906

Epoch: 6| Step: 13
Training loss: 2.8988118171691895
Validation loss: 2.382413464207803

Epoch: 54| Step: 0
Training loss: 2.8363142013549805
Validation loss: 2.3859354821584557

Epoch: 6| Step: 1
Training loss: 2.8464536666870117
Validation loss: 2.387606974570982

Epoch: 6| Step: 2
Training loss: 2.759150981903076
Validation loss: 2.3916985424616004

Epoch: 6| Step: 3
Training loss: 1.6846086978912354
Validation loss: 2.387581499673987

Epoch: 6| Step: 4
Training loss: 2.4038825035095215
Validation loss: 2.3894036252011537

Epoch: 6| Step: 5
Training loss: 2.8823397159576416
Validation loss: 2.385985833342357

Epoch: 6| Step: 6
Training loss: 2.8950557708740234
Validation loss: 2.385525393229659

Epoch: 6| Step: 7
Training loss: 2.5917325019836426
Validation loss: 2.398634059454805

Epoch: 6| Step: 8
Training loss: 2.5771141052246094
Validation loss: 2.4193500472653295

Epoch: 6| Step: 9
Training loss: 2.1949520111083984
Validation loss: 2.437688345550209

Epoch: 6| Step: 10
Training loss: 2.7490782737731934
Validation loss: 2.4084962080883723

Epoch: 6| Step: 11
Training loss: 2.917430877685547
Validation loss: 2.3941361058142876

Epoch: 6| Step: 12
Training loss: 2.7991487979888916
Validation loss: 2.386241635968608

Epoch: 6| Step: 13
Training loss: 3.200082778930664
Validation loss: 2.382114887237549

Epoch: 55| Step: 0
Training loss: 3.114870548248291
Validation loss: 2.3808412192970194

Epoch: 6| Step: 1
Training loss: 2.378045082092285
Validation loss: 2.3778143390532462

Epoch: 6| Step: 2
Training loss: 2.6090266704559326
Validation loss: 2.3780522397769395

Epoch: 6| Step: 3
Training loss: 2.6312568187713623
Validation loss: 2.3777728901114514

Epoch: 6| Step: 4
Training loss: 2.074864387512207
Validation loss: 2.379840435520295

Epoch: 6| Step: 5
Training loss: 2.7239370346069336
Validation loss: 2.3806727906709075

Epoch: 6| Step: 6
Training loss: 2.709994316101074
Validation loss: 2.384174321287422

Epoch: 6| Step: 7
Training loss: 2.7199716567993164
Validation loss: 2.3848500841407367

Epoch: 6| Step: 8
Training loss: 2.4396255016326904
Validation loss: 2.381276492149599

Epoch: 6| Step: 9
Training loss: 2.9425463676452637
Validation loss: 2.383689053596989

Epoch: 6| Step: 10
Training loss: 2.373540163040161
Validation loss: 2.3944431376713577

Epoch: 6| Step: 11
Training loss: 2.900132417678833
Validation loss: 2.405249616151215

Epoch: 6| Step: 12
Training loss: 2.60258412361145
Validation loss: 2.4092901470840618

Epoch: 6| Step: 13
Training loss: 2.8858118057250977
Validation loss: 2.420534667148385

Epoch: 56| Step: 0
Training loss: 2.755336046218872
Validation loss: 2.437423436872421

Epoch: 6| Step: 1
Training loss: 2.7969305515289307
Validation loss: 2.4629021229282504

Epoch: 6| Step: 2
Training loss: 2.579495668411255
Validation loss: 2.4535640747316423

Epoch: 6| Step: 3
Training loss: 3.14957857131958
Validation loss: 2.4318196619710615

Epoch: 6| Step: 4
Training loss: 3.298781633377075
Validation loss: 2.4238705045433453

Epoch: 6| Step: 5
Training loss: 3.077909231185913
Validation loss: 2.4054688817711285

Epoch: 6| Step: 6
Training loss: 2.8007893562316895
Validation loss: 2.4026369023066696

Epoch: 6| Step: 7
Training loss: 1.4872121810913086
Validation loss: 2.401601578599663

Epoch: 6| Step: 8
Training loss: 2.326253890991211
Validation loss: 2.401335629083777

Epoch: 6| Step: 9
Training loss: 1.92836594581604
Validation loss: 2.395027370863063

Epoch: 6| Step: 10
Training loss: 2.6212849617004395
Validation loss: 2.393690901417886

Epoch: 6| Step: 11
Training loss: 2.904874801635742
Validation loss: 2.3942647031558457

Epoch: 6| Step: 12
Training loss: 2.7349445819854736
Validation loss: 2.3974142202766995

Epoch: 6| Step: 13
Training loss: 2.7805488109588623
Validation loss: 2.397549502311214

Epoch: 57| Step: 0
Training loss: 2.246706485748291
Validation loss: 2.3955270936412196

Epoch: 6| Step: 1
Training loss: 2.7298898696899414
Validation loss: 2.3999699854081675

Epoch: 6| Step: 2
Training loss: 3.072108745574951
Validation loss: 2.4045729662782405

Epoch: 6| Step: 3
Training loss: 2.6281957626342773
Validation loss: 2.417423276491063

Epoch: 6| Step: 4
Training loss: 3.065586566925049
Validation loss: 2.4053178935922603

Epoch: 6| Step: 5
Training loss: 2.107182025909424
Validation loss: 2.384894911960889

Epoch: 6| Step: 6
Training loss: 3.279871940612793
Validation loss: 2.368065277735392

Epoch: 6| Step: 7
Training loss: 2.02744197845459
Validation loss: 2.3649699329048075

Epoch: 6| Step: 8
Training loss: 2.109862804412842
Validation loss: 2.3571937596926125

Epoch: 6| Step: 9
Training loss: 2.9454965591430664
Validation loss: 2.3569141562267015

Epoch: 6| Step: 10
Training loss: 2.8201675415039062
Validation loss: 2.367059953751103

Epoch: 6| Step: 11
Training loss: 2.414928674697876
Validation loss: 2.381925388049054

Epoch: 6| Step: 12
Training loss: 2.234070301055908
Validation loss: 2.386778582808792

Epoch: 6| Step: 13
Training loss: 3.3584866523742676
Validation loss: 2.381989282946433

Epoch: 58| Step: 0
Training loss: 3.143418550491333
Validation loss: 2.382672832858178

Epoch: 6| Step: 1
Training loss: 2.046586751937866
Validation loss: 2.3755954606558687

Epoch: 6| Step: 2
Training loss: 3.2357232570648193
Validation loss: 2.3735864188081477

Epoch: 6| Step: 3
Training loss: 1.7578641176223755
Validation loss: 2.3654042546467116

Epoch: 6| Step: 4
Training loss: 3.3511579036712646
Validation loss: 2.3606455377353135

Epoch: 6| Step: 5
Training loss: 2.7364771366119385
Validation loss: 2.355823491209297

Epoch: 6| Step: 6
Training loss: 3.197551727294922
Validation loss: 2.349214143650506

Epoch: 6| Step: 7
Training loss: 2.543938159942627
Validation loss: 2.3467487109604703

Epoch: 6| Step: 8
Training loss: 2.1409711837768555
Validation loss: 2.355628062320012

Epoch: 6| Step: 9
Training loss: 2.820521354675293
Validation loss: 2.357710042307454

Epoch: 6| Step: 10
Training loss: 2.063051700592041
Validation loss: 2.366954982921641

Epoch: 6| Step: 11
Training loss: 2.605842113494873
Validation loss: 2.387658937003023

Epoch: 6| Step: 12
Training loss: 2.3474807739257812
Validation loss: 2.406767293971072

Epoch: 6| Step: 13
Training loss: 3.2607970237731934
Validation loss: 2.431317065351753

Epoch: 59| Step: 0
Training loss: 3.4624617099761963
Validation loss: 2.4335811573971986

Epoch: 6| Step: 1
Training loss: 1.7813754081726074
Validation loss: 2.4330599872014855

Epoch: 6| Step: 2
Training loss: 2.6725997924804688
Validation loss: 2.4351699711174093

Epoch: 6| Step: 3
Training loss: 3.2740478515625
Validation loss: 2.44734767688218

Epoch: 6| Step: 4
Training loss: 2.585921287536621
Validation loss: 2.43469504387148

Epoch: 6| Step: 5
Training loss: 3.003058671951294
Validation loss: 2.3990525455885034

Epoch: 6| Step: 6
Training loss: 2.2466228008270264
Validation loss: 2.384932118077432

Epoch: 6| Step: 7
Training loss: 2.4958388805389404
Validation loss: 2.3700077174812235

Epoch: 6| Step: 8
Training loss: 2.495159387588501
Validation loss: 2.362090536343154

Epoch: 6| Step: 9
Training loss: 2.53987193107605
Validation loss: 2.3652798770576395

Epoch: 6| Step: 10
Training loss: 2.6751859188079834
Validation loss: 2.372342883899648

Epoch: 6| Step: 11
Training loss: 2.5556793212890625
Validation loss: 2.3980956205757717

Epoch: 6| Step: 12
Training loss: 2.8609585762023926
Validation loss: 2.4208270811265513

Epoch: 6| Step: 13
Training loss: 2.4289908409118652
Validation loss: 2.421608676192581

Epoch: 60| Step: 0
Training loss: 2.6189053058624268
Validation loss: 2.4006628528718026

Epoch: 6| Step: 1
Training loss: 2.256674289703369
Validation loss: 2.389852149512178

Epoch: 6| Step: 2
Training loss: 2.521663188934326
Validation loss: 2.369570594961925

Epoch: 6| Step: 3
Training loss: 2.571594476699829
Validation loss: 2.359417910216957

Epoch: 6| Step: 4
Training loss: 2.224762439727783
Validation loss: 2.352485279883108

Epoch: 6| Step: 5
Training loss: 2.7125730514526367
Validation loss: 2.349767085044615

Epoch: 6| Step: 6
Training loss: 2.2016642093658447
Validation loss: 2.34962809214028

Epoch: 6| Step: 7
Training loss: 2.3958611488342285
Validation loss: 2.3557926147214827

Epoch: 6| Step: 8
Training loss: 2.5106518268585205
Validation loss: 2.3596964792538713

Epoch: 6| Step: 9
Training loss: 2.675837755203247
Validation loss: 2.361002932312668

Epoch: 6| Step: 10
Training loss: 2.916289806365967
Validation loss: 2.36230965070827

Epoch: 6| Step: 11
Training loss: 2.840114116668701
Validation loss: 2.3639511882617907

Epoch: 6| Step: 12
Training loss: 3.3791279792785645
Validation loss: 2.361245693699006

Epoch: 6| Step: 13
Training loss: 3.3909575939178467
Validation loss: 2.3549697283775575

Epoch: 61| Step: 0
Training loss: 2.6909122467041016
Validation loss: 2.354956696110387

Epoch: 6| Step: 1
Training loss: 3.05086088180542
Validation loss: 2.3504144068687194

Epoch: 6| Step: 2
Training loss: 2.8051419258117676
Validation loss: 2.337143685228081

Epoch: 6| Step: 3
Training loss: 2.7627735137939453
Validation loss: 2.336927572886149

Epoch: 6| Step: 4
Training loss: 2.24922513961792
Validation loss: 2.3433485954038558

Epoch: 6| Step: 5
Training loss: 2.223388195037842
Validation loss: 2.3508125607685377

Epoch: 6| Step: 6
Training loss: 3.2899513244628906
Validation loss: 2.361655765964139

Epoch: 6| Step: 7
Training loss: 2.3570141792297363
Validation loss: 2.357840099642354

Epoch: 6| Step: 8
Training loss: 2.655524969100952
Validation loss: 2.3440717086997083

Epoch: 6| Step: 9
Training loss: 2.518864154815674
Validation loss: 2.3357170140871437

Epoch: 6| Step: 10
Training loss: 2.106903314590454
Validation loss: 2.3253417476530998

Epoch: 6| Step: 11
Training loss: 2.686213970184326
Validation loss: 2.3220852318630425

Epoch: 6| Step: 12
Training loss: 2.6415610313415527
Validation loss: 2.324278772518199

Epoch: 6| Step: 13
Training loss: 2.8154635429382324
Validation loss: 2.324456545614427

Epoch: 62| Step: 0
Training loss: 2.527238368988037
Validation loss: 2.329173545683584

Epoch: 6| Step: 1
Training loss: 2.4515881538391113
Validation loss: 2.3287458509527226

Epoch: 6| Step: 2
Training loss: 2.8277459144592285
Validation loss: 2.3344900044061805

Epoch: 6| Step: 3
Training loss: 2.048793077468872
Validation loss: 2.3321866963499334

Epoch: 6| Step: 4
Training loss: 2.707362651824951
Validation loss: 2.3276296764291744

Epoch: 6| Step: 5
Training loss: 2.078300952911377
Validation loss: 2.3259781201680503

Epoch: 6| Step: 6
Training loss: 3.35959529876709
Validation loss: 2.332350233549713

Epoch: 6| Step: 7
Training loss: 3.240269184112549
Validation loss: 2.332006564704321

Epoch: 6| Step: 8
Training loss: 2.4134206771850586
Validation loss: 2.3390886142689693

Epoch: 6| Step: 9
Training loss: 2.444476842880249
Validation loss: 2.3350974385456373

Epoch: 6| Step: 10
Training loss: 2.423595428466797
Validation loss: 2.3346677108477523

Epoch: 6| Step: 11
Training loss: 2.7182157039642334
Validation loss: 2.340534189695953

Epoch: 6| Step: 12
Training loss: 2.8037776947021484
Validation loss: 2.3462361302427066

Epoch: 6| Step: 13
Training loss: 2.4036741256713867
Validation loss: 2.353456033173428

Epoch: 63| Step: 0
Training loss: 2.475271463394165
Validation loss: 2.3406956375286145

Epoch: 6| Step: 1
Training loss: 2.624305248260498
Validation loss: 2.3344030508431057

Epoch: 6| Step: 2
Training loss: 2.1662349700927734
Validation loss: 2.321291708177136

Epoch: 6| Step: 3
Training loss: 2.6898906230926514
Validation loss: 2.3173457063654417

Epoch: 6| Step: 4
Training loss: 2.2671914100646973
Validation loss: 2.3181587239747405

Epoch: 6| Step: 5
Training loss: 2.8086133003234863
Validation loss: 2.317128607021865

Epoch: 6| Step: 6
Training loss: 3.179994583129883
Validation loss: 2.319276240564162

Epoch: 6| Step: 7
Training loss: 2.9240221977233887
Validation loss: 2.3178059516414518

Epoch: 6| Step: 8
Training loss: 1.756758689880371
Validation loss: 2.316926387048537

Epoch: 6| Step: 9
Training loss: 2.6702635288238525
Validation loss: 2.31826195152857

Epoch: 6| Step: 10
Training loss: 2.718226909637451
Validation loss: 2.3165113233750865

Epoch: 6| Step: 11
Training loss: 2.6452841758728027
Validation loss: 2.318340693750689

Epoch: 6| Step: 12
Training loss: 2.767681837081909
Validation loss: 2.317066777137018

Epoch: 6| Step: 13
Training loss: 2.801072359085083
Validation loss: 2.3226698957463747

Epoch: 64| Step: 0
Training loss: 2.3235065937042236
Validation loss: 2.331496479690716

Epoch: 6| Step: 1
Training loss: 2.212904453277588
Validation loss: 2.3404253400782102

Epoch: 6| Step: 2
Training loss: 2.644073247909546
Validation loss: 2.3553693012524675

Epoch: 6| Step: 3
Training loss: 3.081515312194824
Validation loss: 2.3674839850394958

Epoch: 6| Step: 4
Training loss: 2.5651156902313232
Validation loss: 2.3673529983848653

Epoch: 6| Step: 5
Training loss: 2.290876865386963
Validation loss: 2.380347539019841

Epoch: 6| Step: 6
Training loss: 3.222425937652588
Validation loss: 2.3522265059973604

Epoch: 6| Step: 7
Training loss: 2.4574999809265137
Validation loss: 2.3285875217888945

Epoch: 6| Step: 8
Training loss: 2.9039113521575928
Validation loss: 2.311760510167768

Epoch: 6| Step: 9
Training loss: 2.683528423309326
Validation loss: 2.3095428136087235

Epoch: 6| Step: 10
Training loss: 2.4306952953338623
Validation loss: 2.3141012730136996

Epoch: 6| Step: 11
Training loss: 2.773831367492676
Validation loss: 2.3220189720071773

Epoch: 6| Step: 12
Training loss: 2.4063963890075684
Validation loss: 2.322217987429711

Epoch: 6| Step: 13
Training loss: 2.4084486961364746
Validation loss: 2.3294331437797955

Epoch: 65| Step: 0
Training loss: 1.6994946002960205
Validation loss: 2.329675171964912

Epoch: 6| Step: 1
Training loss: 2.8764734268188477
Validation loss: 2.3270283822090394

Epoch: 6| Step: 2
Training loss: 2.674856185913086
Validation loss: 2.3265966971715293

Epoch: 6| Step: 3
Training loss: 2.4950618743896484
Validation loss: 2.318923209303169

Epoch: 6| Step: 4
Training loss: 3.351548671722412
Validation loss: 2.313974139510944

Epoch: 6| Step: 5
Training loss: 3.279675006866455
Validation loss: 2.321521638542093

Epoch: 6| Step: 6
Training loss: 2.9758219718933105
Validation loss: 2.3259221623020787

Epoch: 6| Step: 7
Training loss: 2.956965208053589
Validation loss: 2.3294843550651305

Epoch: 6| Step: 8
Training loss: 2.6321353912353516
Validation loss: 2.326965888341268

Epoch: 6| Step: 9
Training loss: 2.4149892330169678
Validation loss: 2.3186065355936685

Epoch: 6| Step: 10
Training loss: 2.0491485595703125
Validation loss: 2.3187714058865785

Epoch: 6| Step: 11
Training loss: 2.2853522300720215
Validation loss: 2.3196701413841656

Epoch: 6| Step: 12
Training loss: 2.3616647720336914
Validation loss: 2.3156701954462195

Epoch: 6| Step: 13
Training loss: 2.24483585357666
Validation loss: 2.319524093340802

Epoch: 66| Step: 0
Training loss: 2.876011371612549
Validation loss: 2.3439386454961633

Epoch: 6| Step: 1
Training loss: 2.6783065795898438
Validation loss: 2.359586536243398

Epoch: 6| Step: 2
Training loss: 2.286928176879883
Validation loss: 2.3919040336403796

Epoch: 6| Step: 3
Training loss: 2.244865655899048
Validation loss: 2.4232586481237925

Epoch: 6| Step: 4
Training loss: 2.7706823348999023
Validation loss: 2.4270419484825543

Epoch: 6| Step: 5
Training loss: 2.529845714569092
Validation loss: 2.435188226802375

Epoch: 6| Step: 6
Training loss: 2.107377529144287
Validation loss: 2.4311867144800003

Epoch: 6| Step: 7
Training loss: 3.2635836601257324
Validation loss: 2.429213749465122

Epoch: 6| Step: 8
Training loss: 2.0585741996765137
Validation loss: 2.413676469556747

Epoch: 6| Step: 9
Training loss: 2.465388298034668
Validation loss: 2.412144637876941

Epoch: 6| Step: 10
Training loss: 3.1605989933013916
Validation loss: 2.387667658508465

Epoch: 6| Step: 11
Training loss: 3.1413938999176025
Validation loss: 2.382870581842238

Epoch: 6| Step: 12
Training loss: 2.5824031829833984
Validation loss: 2.329322317595123

Epoch: 6| Step: 13
Training loss: 2.2221009731292725
Validation loss: 2.292866317174768

Epoch: 67| Step: 0
Training loss: 2.604384422302246
Validation loss: 2.2990705326039302

Epoch: 6| Step: 1
Training loss: 2.8867626190185547
Validation loss: 2.303059526669082

Epoch: 6| Step: 2
Training loss: 2.442249059677124
Validation loss: 2.3063268892226683

Epoch: 6| Step: 3
Training loss: 3.5547189712524414
Validation loss: 2.3200569255377657

Epoch: 6| Step: 4
Training loss: 2.6014394760131836
Validation loss: 2.311204512914022

Epoch: 6| Step: 5
Training loss: 2.4111201763153076
Validation loss: 2.308132204958188

Epoch: 6| Step: 6
Training loss: 2.2480239868164062
Validation loss: 2.30103208685434

Epoch: 6| Step: 7
Training loss: 3.2899608612060547
Validation loss: 2.302028371441749

Epoch: 6| Step: 8
Training loss: 2.3727657794952393
Validation loss: 2.2966420637663973

Epoch: 6| Step: 9
Training loss: 2.7527477741241455
Validation loss: 2.2950365774093138

Epoch: 6| Step: 10
Training loss: 2.3998639583587646
Validation loss: 2.292845461958198

Epoch: 6| Step: 11
Training loss: 2.2944416999816895
Validation loss: 2.298608528670444

Epoch: 6| Step: 12
Training loss: 2.305269718170166
Validation loss: 2.310818572198191

Epoch: 6| Step: 13
Training loss: 2.4042835235595703
Validation loss: 2.3159330711569837

Epoch: 68| Step: 0
Training loss: 3.139620065689087
Validation loss: 2.340405200117378

Epoch: 6| Step: 1
Training loss: 2.341163158416748
Validation loss: 2.357466338783182

Epoch: 6| Step: 2
Training loss: 2.4663453102111816
Validation loss: 2.3556815142272622

Epoch: 6| Step: 3
Training loss: 2.0888426303863525
Validation loss: 2.3534784188834568

Epoch: 6| Step: 4
Training loss: 2.3477890491485596
Validation loss: 2.339276880346319

Epoch: 6| Step: 5
Training loss: 2.2055840492248535
Validation loss: 2.3091410103664605

Epoch: 6| Step: 6
Training loss: 2.8826024532318115
Validation loss: 2.299306869506836

Epoch: 6| Step: 7
Training loss: 2.7815585136413574
Validation loss: 2.293043574979228

Epoch: 6| Step: 8
Training loss: 2.6249983310699463
Validation loss: 2.286309725494795

Epoch: 6| Step: 9
Training loss: 2.9267640113830566
Validation loss: 2.2818551730084162

Epoch: 6| Step: 10
Training loss: 2.9920620918273926
Validation loss: 2.280223533671389

Epoch: 6| Step: 11
Training loss: 2.3045170307159424
Validation loss: 2.281903656580115

Epoch: 6| Step: 12
Training loss: 2.692542552947998
Validation loss: 2.282173425920548

Epoch: 6| Step: 13
Training loss: 2.6033835411071777
Validation loss: 2.2793981439323834

Epoch: 69| Step: 0
Training loss: 3.232814311981201
Validation loss: 2.283412116830067

Epoch: 6| Step: 1
Training loss: 2.6825766563415527
Validation loss: 2.281116880396361

Epoch: 6| Step: 2
Training loss: 1.8003361225128174
Validation loss: 2.2818769126810055

Epoch: 6| Step: 3
Training loss: 2.2074527740478516
Validation loss: 2.284893743453487

Epoch: 6| Step: 4
Training loss: 2.192277193069458
Validation loss: 2.2896985520598707

Epoch: 6| Step: 5
Training loss: 2.7043166160583496
Validation loss: 2.2963091096570416

Epoch: 6| Step: 6
Training loss: 2.8422670364379883
Validation loss: 2.3101415634155273

Epoch: 6| Step: 7
Training loss: 2.9562878608703613
Validation loss: 2.3377501298022527

Epoch: 6| Step: 8
Training loss: 2.6553802490234375
Validation loss: 2.3415786271454184

Epoch: 6| Step: 9
Training loss: 2.1509335041046143
Validation loss: 2.336124507329797

Epoch: 6| Step: 10
Training loss: 2.612847328186035
Validation loss: 2.3379638297583467

Epoch: 6| Step: 11
Training loss: 2.6875340938568115
Validation loss: 2.3207503570023404

Epoch: 6| Step: 12
Training loss: 2.419408082962036
Validation loss: 2.3169516747997654

Epoch: 6| Step: 13
Training loss: 3.188093662261963
Validation loss: 2.2925688887155182

Epoch: 70| Step: 0
Training loss: 2.402341604232788
Validation loss: 2.2845285989904918

Epoch: 6| Step: 1
Training loss: 2.512349843978882
Validation loss: 2.2825104472457722

Epoch: 6| Step: 2
Training loss: 3.3171494007110596
Validation loss: 2.2791194274861324

Epoch: 6| Step: 3
Training loss: 2.2090935707092285
Validation loss: 2.281988077266242

Epoch: 6| Step: 4
Training loss: 2.424654006958008
Validation loss: 2.27625471802168

Epoch: 6| Step: 5
Training loss: 2.294233798980713
Validation loss: 2.275482085443312

Epoch: 6| Step: 6
Training loss: 2.5862841606140137
Validation loss: 2.273510022829938

Epoch: 6| Step: 7
Training loss: 2.297687530517578
Validation loss: 2.273104052389822

Epoch: 6| Step: 8
Training loss: 3.0340092182159424
Validation loss: 2.2894395679555912

Epoch: 6| Step: 9
Training loss: 2.7707765102386475
Validation loss: 2.2944411757171794

Epoch: 6| Step: 10
Training loss: 3.0988359451293945
Validation loss: 2.305864816070885

Epoch: 6| Step: 11
Training loss: 2.275480031967163
Validation loss: 2.3095784264226116

Epoch: 6| Step: 12
Training loss: 2.201235294342041
Validation loss: 2.315729464254072

Epoch: 6| Step: 13
Training loss: 2.639993667602539
Validation loss: 2.3212839659824165

Epoch: 71| Step: 0
Training loss: 2.5269384384155273
Validation loss: 2.325848340988159

Epoch: 6| Step: 1
Training loss: 2.7941670417785645
Validation loss: 2.325436422901769

Epoch: 6| Step: 2
Training loss: 1.5568702220916748
Validation loss: 2.3206805516314764

Epoch: 6| Step: 3
Training loss: 2.759509801864624
Validation loss: 2.3276778651821997

Epoch: 6| Step: 4
Training loss: 3.1344246864318848
Validation loss: 2.326463378885741

Epoch: 6| Step: 5
Training loss: 2.6351232528686523
Validation loss: 2.3237664904645694

Epoch: 6| Step: 6
Training loss: 2.7892212867736816
Validation loss: 2.3244639006994103

Epoch: 6| Step: 7
Training loss: 2.1639482975006104
Validation loss: 2.3227282595890824

Epoch: 6| Step: 8
Training loss: 2.830819845199585
Validation loss: 2.316152290631366

Epoch: 6| Step: 9
Training loss: 2.8817105293273926
Validation loss: 2.3156280107395624

Epoch: 6| Step: 10
Training loss: 2.3362364768981934
Validation loss: 2.3171176730945544

Epoch: 6| Step: 11
Training loss: 2.355804443359375
Validation loss: 2.3233534277126355

Epoch: 6| Step: 12
Training loss: 2.6612889766693115
Validation loss: 2.330262945544335

Epoch: 6| Step: 13
Training loss: 3.0626463890075684
Validation loss: 2.34097461546621

Epoch: 72| Step: 0
Training loss: 2.592733860015869
Validation loss: 2.3467637467127975

Epoch: 6| Step: 1
Training loss: 1.969287633895874
Validation loss: 2.351805717714371

Epoch: 6| Step: 2
Training loss: 3.0285935401916504
Validation loss: 2.344799744185581

Epoch: 6| Step: 3
Training loss: 2.7940239906311035
Validation loss: 2.341123837296681

Epoch: 6| Step: 4
Training loss: 2.6128387451171875
Validation loss: 2.3369732569622736

Epoch: 6| Step: 5
Training loss: 2.615729808807373
Validation loss: 2.325042709227531

Epoch: 6| Step: 6
Training loss: 2.653501033782959
Validation loss: 2.3266383576136764

Epoch: 6| Step: 7
Training loss: 2.375976085662842
Validation loss: 2.3195925399821293

Epoch: 6| Step: 8
Training loss: 2.6511757373809814
Validation loss: 2.3059034808989494

Epoch: 6| Step: 9
Training loss: 2.482496976852417
Validation loss: 2.303460563382795

Epoch: 6| Step: 10
Training loss: 2.614888906478882
Validation loss: 2.302402984711432

Epoch: 6| Step: 11
Training loss: 2.368018627166748
Validation loss: 2.3045977802686792

Epoch: 6| Step: 12
Training loss: 2.6662487983703613
Validation loss: 2.301899028080766

Epoch: 6| Step: 13
Training loss: 2.595001459121704
Validation loss: 2.307204415721278

Epoch: 73| Step: 0
Training loss: 2.588310956954956
Validation loss: 2.312891783252839

Epoch: 6| Step: 1
Training loss: 3.1630911827087402
Validation loss: 2.3248841877906554

Epoch: 6| Step: 2
Training loss: 2.1038615703582764
Validation loss: 2.3220455082513953

Epoch: 6| Step: 3
Training loss: 2.8796844482421875
Validation loss: 2.37315607583651

Epoch: 6| Step: 4
Training loss: 2.9166975021362305
Validation loss: 2.4533315935442523

Epoch: 6| Step: 5
Training loss: 2.8620996475219727
Validation loss: 2.4630684442417596

Epoch: 6| Step: 6
Training loss: 2.370424747467041
Validation loss: 2.410997900911557

Epoch: 6| Step: 7
Training loss: 2.0120816230773926
Validation loss: 2.3505426094096196

Epoch: 6| Step: 8
Training loss: 3.458307981491089
Validation loss: 2.335416014476489

Epoch: 6| Step: 9
Training loss: 2.6167373657226562
Validation loss: 2.317877459269698

Epoch: 6| Step: 10
Training loss: 2.293546676635742
Validation loss: 2.3124027406015704

Epoch: 6| Step: 11
Training loss: 2.510251045227051
Validation loss: 2.315635004351216

Epoch: 6| Step: 12
Training loss: 2.4159560203552246
Validation loss: 2.311966662765831

Epoch: 6| Step: 13
Training loss: 1.8622593879699707
Validation loss: 2.3197041839681645

Epoch: 74| Step: 0
Training loss: 3.002626419067383
Validation loss: 2.3366314185562955

Epoch: 6| Step: 1
Training loss: 2.0427165031433105
Validation loss: 2.3758794235926803

Epoch: 6| Step: 2
Training loss: 2.40374493598938
Validation loss: 2.397433593708982

Epoch: 6| Step: 3
Training loss: 2.445228338241577
Validation loss: 2.374786474371469

Epoch: 6| Step: 4
Training loss: 2.525817632675171
Validation loss: 2.3557338458235546

Epoch: 6| Step: 5
Training loss: 2.854604721069336
Validation loss: 2.3398793487138647

Epoch: 6| Step: 6
Training loss: 3.1377832889556885
Validation loss: 2.335781563994705

Epoch: 6| Step: 7
Training loss: 2.9580020904541016
Validation loss: 2.3371506250032814

Epoch: 6| Step: 8
Training loss: 2.107609748840332
Validation loss: 2.339779717947847

Epoch: 6| Step: 9
Training loss: 1.904337763786316
Validation loss: 2.320733792038374

Epoch: 6| Step: 10
Training loss: 3.142655849456787
Validation loss: 2.3551440751680763

Epoch: 6| Step: 11
Training loss: 2.6158947944641113
Validation loss: 2.39753391409433

Epoch: 6| Step: 12
Training loss: 3.0101404190063477
Validation loss: 2.4322368791026454

Epoch: 6| Step: 13
Training loss: 2.3059518337249756
Validation loss: 2.376092787711851

Epoch: 75| Step: 0
Training loss: 2.315809726715088
Validation loss: 2.342019678443991

Epoch: 6| Step: 1
Training loss: 2.6216821670532227
Validation loss: 2.309102935175742

Epoch: 6| Step: 2
Training loss: 2.8701257705688477
Validation loss: 2.2876566533119447

Epoch: 6| Step: 3
Training loss: 2.8049280643463135
Validation loss: 2.2788309640781854

Epoch: 6| Step: 4
Training loss: 3.356903314590454
Validation loss: 2.3018621962557555

Epoch: 6| Step: 5
Training loss: 2.519439697265625
Validation loss: 2.3244244360154673

Epoch: 6| Step: 6
Training loss: 3.188394546508789
Validation loss: 2.3300551855435936

Epoch: 6| Step: 7
Training loss: 3.131413459777832
Validation loss: 2.334242897648965

Epoch: 6| Step: 8
Training loss: 2.085230827331543
Validation loss: 2.3450521871607792

Epoch: 6| Step: 9
Training loss: 2.048588752746582
Validation loss: 2.3460945147340015

Epoch: 6| Step: 10
Training loss: 2.1786351203918457
Validation loss: 2.346453259068151

Epoch: 6| Step: 11
Training loss: 2.9773459434509277
Validation loss: 2.357056684391473

Epoch: 6| Step: 12
Training loss: 2.1127102375030518
Validation loss: 2.3617602625200824

Epoch: 6| Step: 13
Training loss: 1.9406384229660034
Validation loss: 2.353417665727677

Epoch: 76| Step: 0
Training loss: 3.151700496673584
Validation loss: 2.3498872736448884

Epoch: 6| Step: 1
Training loss: 2.3737940788269043
Validation loss: 2.3414630351528043

Epoch: 6| Step: 2
Training loss: 2.039386510848999
Validation loss: 2.332556947585075

Epoch: 6| Step: 3
Training loss: 3.1574859619140625
Validation loss: 2.332320761936967

Epoch: 6| Step: 4
Training loss: 2.32978892326355
Validation loss: 2.331224415891914

Epoch: 6| Step: 5
Training loss: 2.0331320762634277
Validation loss: 2.3264087246310328

Epoch: 6| Step: 6
Training loss: 2.6756231784820557
Validation loss: 2.329292233272265

Epoch: 6| Step: 7
Training loss: 2.3221230506896973
Validation loss: 2.3303869129509054

Epoch: 6| Step: 8
Training loss: 2.480513334274292
Validation loss: 2.3385469708391415

Epoch: 6| Step: 9
Training loss: 3.0036368370056152
Validation loss: 2.3450087142247025

Epoch: 6| Step: 10
Training loss: 3.023355484008789
Validation loss: 2.3328510356205765

Epoch: 6| Step: 11
Training loss: 2.6481380462646484
Validation loss: 2.3283200161431425

Epoch: 6| Step: 12
Training loss: 2.469593048095703
Validation loss: 2.323624659610051

Epoch: 6| Step: 13
Training loss: 2.7975950241088867
Validation loss: 2.3237625501489125

Epoch: 77| Step: 0
Training loss: 2.6866068840026855
Validation loss: 2.3212930335793445

Epoch: 6| Step: 1
Training loss: 2.889362335205078
Validation loss: 2.3198920578084965

Epoch: 6| Step: 2
Training loss: 3.4476261138916016
Validation loss: 2.3186067817031697

Epoch: 6| Step: 3
Training loss: 1.9433119297027588
Validation loss: 2.322888538401614

Epoch: 6| Step: 4
Training loss: 3.0812087059020996
Validation loss: 2.3260431058945192

Epoch: 6| Step: 5
Training loss: 2.201462984085083
Validation loss: 2.3272122208790114

Epoch: 6| Step: 6
Training loss: 1.7489382028579712
Validation loss: 2.3319105461079586

Epoch: 6| Step: 7
Training loss: 3.480546712875366
Validation loss: 2.358507607572822

Epoch: 6| Step: 8
Training loss: 2.5498197078704834
Validation loss: 2.3622691092952603

Epoch: 6| Step: 9
Training loss: 2.4148597717285156
Validation loss: 2.3600770196607037

Epoch: 6| Step: 10
Training loss: 2.190394878387451
Validation loss: 2.345923295585058

Epoch: 6| Step: 11
Training loss: 2.7619705200195312
Validation loss: 2.3315068060351956

Epoch: 6| Step: 12
Training loss: 2.349742889404297
Validation loss: 2.324689265220396

Epoch: 6| Step: 13
Training loss: 2.5000007152557373
Validation loss: 2.3254082228547786

Epoch: 78| Step: 0
Training loss: 2.679135799407959
Validation loss: 2.332306323512908

Epoch: 6| Step: 1
Training loss: 2.6978330612182617
Validation loss: 2.335164395711755

Epoch: 6| Step: 2
Training loss: 2.6607766151428223
Validation loss: 2.3305847234623407

Epoch: 6| Step: 3
Training loss: 2.938159465789795
Validation loss: 2.320054631079397

Epoch: 6| Step: 4
Training loss: 2.7043251991271973
Validation loss: 2.312869547515787

Epoch: 6| Step: 5
Training loss: 2.8927950859069824
Validation loss: 2.310318431546611

Epoch: 6| Step: 6
Training loss: 2.5411155223846436
Validation loss: 2.3054350832457184

Epoch: 6| Step: 7
Training loss: 2.5532374382019043
Validation loss: 2.3042958090382237

Epoch: 6| Step: 8
Training loss: 2.6836342811584473
Validation loss: 2.302082336077126

Epoch: 6| Step: 9
Training loss: 2.0760388374328613
Validation loss: 2.307866987361703

Epoch: 6| Step: 10
Training loss: 1.8778756856918335
Validation loss: 2.307705158828407

Epoch: 6| Step: 11
Training loss: 2.8123786449432373
Validation loss: 2.3176055313438497

Epoch: 6| Step: 12
Training loss: 2.4268813133239746
Validation loss: 2.316847562789917

Epoch: 6| Step: 13
Training loss: 2.764672040939331
Validation loss: 2.3247835995048605

Epoch: 79| Step: 0
Training loss: 2.7125086784362793
Validation loss: 2.3254318160395466

Epoch: 6| Step: 1
Training loss: 1.6186027526855469
Validation loss: 2.3187774381329938

Epoch: 6| Step: 2
Training loss: 1.8136441707611084
Validation loss: 2.328591166004058

Epoch: 6| Step: 3
Training loss: 2.7955517768859863
Validation loss: 2.3272659522230907

Epoch: 6| Step: 4
Training loss: 3.311340570449829
Validation loss: 2.314396855651691

Epoch: 6| Step: 5
Training loss: 2.339620590209961
Validation loss: 2.3124824364980063

Epoch: 6| Step: 6
Training loss: 2.640549659729004
Validation loss: 2.3085546339711835

Epoch: 6| Step: 7
Training loss: 1.9283260107040405
Validation loss: 2.3115193972023587

Epoch: 6| Step: 8
Training loss: 2.717571258544922
Validation loss: 2.3169855815108105

Epoch: 6| Step: 9
Training loss: 2.3929314613342285
Validation loss: 2.3323195339531027

Epoch: 6| Step: 10
Training loss: 3.499716281890869
Validation loss: 2.3302581823000343

Epoch: 6| Step: 11
Training loss: 2.936264753341675
Validation loss: 2.3250093818992696

Epoch: 6| Step: 12
Training loss: 2.8512449264526367
Validation loss: 2.312006576086885

Epoch: 6| Step: 13
Training loss: 2.4781084060668945
Validation loss: 2.3110722444390737

Epoch: 80| Step: 0
Training loss: 2.9524474143981934
Validation loss: 2.3078432570221605

Epoch: 6| Step: 1
Training loss: 2.6621508598327637
Validation loss: 2.3085615609281804

Epoch: 6| Step: 2
Training loss: 1.9692145586013794
Validation loss: 2.31048616286247

Epoch: 6| Step: 3
Training loss: 2.511502265930176
Validation loss: 2.313082674498199

Epoch: 6| Step: 4
Training loss: 2.860823154449463
Validation loss: 2.3127783190819526

Epoch: 6| Step: 5
Training loss: 3.251814842224121
Validation loss: 2.3138337878770727

Epoch: 6| Step: 6
Training loss: 2.0314736366271973
Validation loss: 2.3155630762859056

Epoch: 6| Step: 7
Training loss: 2.692401170730591
Validation loss: 2.3161327403078795

Epoch: 6| Step: 8
Training loss: 1.9714423418045044
Validation loss: 2.322684177788355

Epoch: 6| Step: 9
Training loss: 2.3045883178710938
Validation loss: 2.3117896177435435

Epoch: 6| Step: 10
Training loss: 2.5982303619384766
Validation loss: 2.319056031524494

Epoch: 6| Step: 11
Training loss: 2.53657865524292
Validation loss: 2.3249349850480274

Epoch: 6| Step: 12
Training loss: 2.8310024738311768
Validation loss: 2.330204825247488

Epoch: 6| Step: 13
Training loss: 2.739161968231201
Validation loss: 2.3205086954178347

Epoch: 81| Step: 0
Training loss: 2.5805015563964844
Validation loss: 2.31633157883921

Epoch: 6| Step: 1
Training loss: 3.0392093658447266
Validation loss: 2.3081455358894925

Epoch: 6| Step: 2
Training loss: 2.0706117153167725
Validation loss: 2.3061283967828237

Epoch: 6| Step: 3
Training loss: 2.1936490535736084
Validation loss: 2.2934204557890534

Epoch: 6| Step: 4
Training loss: 2.6812541484832764
Validation loss: 2.2778502048984652

Epoch: 6| Step: 5
Training loss: 1.7482967376708984
Validation loss: 2.268195806011077

Epoch: 6| Step: 6
Training loss: 2.6951968669891357
Validation loss: 2.264313322241588

Epoch: 6| Step: 7
Training loss: 2.2171859741210938
Validation loss: 2.2683713461763118

Epoch: 6| Step: 8
Training loss: 3.514176368713379
Validation loss: 2.2650380724219867

Epoch: 6| Step: 9
Training loss: 2.9412472248077393
Validation loss: 2.259972905599943

Epoch: 6| Step: 10
Training loss: 2.4988584518432617
Validation loss: 2.2577786214890017

Epoch: 6| Step: 11
Training loss: 1.9518489837646484
Validation loss: 2.2734181752768894

Epoch: 6| Step: 12
Training loss: 2.8040273189544678
Validation loss: 2.2807672921047417

Epoch: 6| Step: 13
Training loss: 3.1279547214508057
Validation loss: 2.2798458068601546

Epoch: 82| Step: 0
Training loss: 2.2369630336761475
Validation loss: 2.2772601830062045

Epoch: 6| Step: 1
Training loss: 2.1046295166015625
Validation loss: 2.281262913057881

Epoch: 6| Step: 2
Training loss: 3.246945858001709
Validation loss: 2.2978093970206475

Epoch: 6| Step: 3
Training loss: 2.963315963745117
Validation loss: 2.2920601470496065

Epoch: 6| Step: 4
Training loss: 2.1066994667053223
Validation loss: 2.294984168903802

Epoch: 6| Step: 5
Training loss: 2.7707467079162598
Validation loss: 2.298327769002607

Epoch: 6| Step: 6
Training loss: 2.597374200820923
Validation loss: 2.2774438652940976

Epoch: 6| Step: 7
Training loss: 1.7254691123962402
Validation loss: 2.283466093001827

Epoch: 6| Step: 8
Training loss: 2.6413581371307373
Validation loss: 2.2908316427661526

Epoch: 6| Step: 9
Training loss: 2.480787992477417
Validation loss: 2.2929602117948633

Epoch: 6| Step: 10
Training loss: 2.0834853649139404
Validation loss: 2.2821706930796304

Epoch: 6| Step: 11
Training loss: 3.0579371452331543
Validation loss: 2.275978454979517

Epoch: 6| Step: 12
Training loss: 2.914649724960327
Validation loss: 2.267728426123178

Epoch: 6| Step: 13
Training loss: 2.8406031131744385
Validation loss: 2.2643920913819344

Epoch: 83| Step: 0
Training loss: 2.6002771854400635
Validation loss: 2.2627568860207834

Epoch: 6| Step: 1
Training loss: 3.1628336906433105
Validation loss: 2.255679440754716

Epoch: 6| Step: 2
Training loss: 2.8317275047302246
Validation loss: 2.2555218935012817

Epoch: 6| Step: 3
Training loss: 2.5760445594787598
Validation loss: 2.2557911744681736

Epoch: 6| Step: 4
Training loss: 2.671570062637329
Validation loss: 2.256049980399429

Epoch: 6| Step: 5
Training loss: 2.2134006023406982
Validation loss: 2.2522415627715406

Epoch: 6| Step: 6
Training loss: 1.8660680055618286
Validation loss: 2.253946499157977

Epoch: 6| Step: 7
Training loss: 3.448432683944702
Validation loss: 2.2548856376319804

Epoch: 6| Step: 8
Training loss: 2.4975028038024902
Validation loss: 2.2591430653807936

Epoch: 6| Step: 9
Training loss: 1.75177001953125
Validation loss: 2.264842907587687

Epoch: 6| Step: 10
Training loss: 2.8882665634155273
Validation loss: 2.2800249181767946

Epoch: 6| Step: 11
Training loss: 2.3841309547424316
Validation loss: 2.2777417757177867

Epoch: 6| Step: 12
Training loss: 2.6614670753479004
Validation loss: 2.2849568846405193

Epoch: 6| Step: 13
Training loss: 1.807589054107666
Validation loss: 2.292651950672109

Epoch: 84| Step: 0
Training loss: 2.425058364868164
Validation loss: 2.283801668433733

Epoch: 6| Step: 1
Training loss: 2.6555416584014893
Validation loss: 2.285504456489317

Epoch: 6| Step: 2
Training loss: 2.8663272857666016
Validation loss: 2.2779702114802536

Epoch: 6| Step: 3
Training loss: 2.252047061920166
Validation loss: 2.2803439145447104

Epoch: 6| Step: 4
Training loss: 2.0602850914001465
Validation loss: 2.2702127938629477

Epoch: 6| Step: 5
Training loss: 2.6123499870300293
Validation loss: 2.2796497037333827

Epoch: 6| Step: 6
Training loss: 2.8190670013427734
Validation loss: 2.284663769506639

Epoch: 6| Step: 7
Training loss: 1.7431516647338867
Validation loss: 2.276660870480281

Epoch: 6| Step: 8
Training loss: 2.9522528648376465
Validation loss: 2.2606878408821682

Epoch: 6| Step: 9
Training loss: 2.275604248046875
Validation loss: 2.257281312378504

Epoch: 6| Step: 10
Training loss: 2.663862466812134
Validation loss: 2.2573038736979165

Epoch: 6| Step: 11
Training loss: 2.3498098850250244
Validation loss: 2.2519762105839227

Epoch: 6| Step: 12
Training loss: 3.1074490547180176
Validation loss: 2.262672972935502

Epoch: 6| Step: 13
Training loss: 2.5596654415130615
Validation loss: 2.241565696654781

Epoch: 85| Step: 0
Training loss: 2.2993853092193604
Validation loss: 2.238515273217232

Epoch: 6| Step: 1
Training loss: 3.0742106437683105
Validation loss: 2.2480003679952314

Epoch: 6| Step: 2
Training loss: 2.564915657043457
Validation loss: 2.2564756049904773

Epoch: 6| Step: 3
Training loss: 3.330974817276001
Validation loss: 2.282108740140033

Epoch: 6| Step: 4
Training loss: 2.7231040000915527
Validation loss: 2.304459200110487

Epoch: 6| Step: 5
Training loss: 2.263430118560791
Validation loss: 2.3049008025917956

Epoch: 6| Step: 6
Training loss: 2.8230085372924805
Validation loss: 2.3025704276177192

Epoch: 6| Step: 7
Training loss: 1.8534767627716064
Validation loss: 2.2906435305072415

Epoch: 6| Step: 8
Training loss: 2.8387393951416016
Validation loss: 2.266797750226913

Epoch: 6| Step: 9
Training loss: 2.3161730766296387
Validation loss: 2.2337249760986655

Epoch: 6| Step: 10
Training loss: 2.4583687782287598
Validation loss: 2.2141323833055395

Epoch: 6| Step: 11
Training loss: 2.3237056732177734
Validation loss: 2.1892243495551487

Epoch: 6| Step: 12
Training loss: 1.9144923686981201
Validation loss: 2.1724608944308375

Epoch: 6| Step: 13
Training loss: 2.329556465148926
Validation loss: 2.1751091223891064

Epoch: 86| Step: 0
Training loss: 1.7813504934310913
Validation loss: 2.1702663078103015

Epoch: 6| Step: 1
Training loss: 2.93007230758667
Validation loss: 2.175066342917822

Epoch: 6| Step: 2
Training loss: 2.522106647491455
Validation loss: 2.1966785154035016

Epoch: 6| Step: 3
Training loss: 2.268439531326294
Validation loss: 2.191566164775561

Epoch: 6| Step: 4
Training loss: 2.2509512901306152
Validation loss: 2.2034117098777526

Epoch: 6| Step: 5
Training loss: 2.165531635284424
Validation loss: 2.209201661489343

Epoch: 6| Step: 6
Training loss: 3.474093437194824
Validation loss: 2.2245753734342513

Epoch: 6| Step: 7
Training loss: 3.3609979152679443
Validation loss: 2.257022962775282

Epoch: 6| Step: 8
Training loss: 1.8530802726745605
Validation loss: 2.216133843186081

Epoch: 6| Step: 9
Training loss: 2.7060697078704834
Validation loss: 2.185156382540221

Epoch: 6| Step: 10
Training loss: 2.8420004844665527
Validation loss: 2.1696653237906833

Epoch: 6| Step: 11
Training loss: 2.0599730014801025
Validation loss: 2.1817272504170737

Epoch: 6| Step: 12
Training loss: 2.3963441848754883
Validation loss: 2.180428453671035

Epoch: 6| Step: 13
Training loss: 2.6655640602111816
Validation loss: 2.176367312349299

Epoch: 87| Step: 0
Training loss: 3.0054070949554443
Validation loss: 2.170253340915967

Epoch: 6| Step: 1
Training loss: 1.8346832990646362
Validation loss: 2.176277942554925

Epoch: 6| Step: 2
Training loss: 2.295597553253174
Validation loss: 2.1897642086910944

Epoch: 6| Step: 3
Training loss: 2.4050490856170654
Validation loss: 2.19296311050333

Epoch: 6| Step: 4
Training loss: 1.8998326063156128
Validation loss: 2.206373614649619

Epoch: 6| Step: 5
Training loss: 3.1967883110046387
Validation loss: 2.213548319314116

Epoch: 6| Step: 6
Training loss: 2.434359073638916
Validation loss: 2.222424691723239

Epoch: 6| Step: 7
Training loss: 2.6926536560058594
Validation loss: 2.247724658699446

Epoch: 6| Step: 8
Training loss: 2.6277074813842773
Validation loss: 2.274252114757415

Epoch: 6| Step: 9
Training loss: 2.55899977684021
Validation loss: 2.2770052904723794

Epoch: 6| Step: 10
Training loss: 2.656036853790283
Validation loss: 2.2182376756463

Epoch: 6| Step: 11
Training loss: 2.433454990386963
Validation loss: 2.1871405647646998

Epoch: 6| Step: 12
Training loss: 2.8724446296691895
Validation loss: 2.1807286816258586

Epoch: 6| Step: 13
Training loss: 2.0158047676086426
Validation loss: 2.1772151582984516

Epoch: 88| Step: 0
Training loss: 3.1838250160217285
Validation loss: 2.16876503088141

Epoch: 6| Step: 1
Training loss: 2.181117057800293
Validation loss: 2.163264113087808

Epoch: 6| Step: 2
Training loss: 2.3572566509246826
Validation loss: 2.1588794595451763

Epoch: 6| Step: 3
Training loss: 2.9474964141845703
Validation loss: 2.159733490277362

Epoch: 6| Step: 4
Training loss: 1.8341028690338135
Validation loss: 2.169050003892632

Epoch: 6| Step: 5
Training loss: 2.5232276916503906
Validation loss: 2.162253737449646

Epoch: 6| Step: 6
Training loss: 2.8569440841674805
Validation loss: 2.1602055885458507

Epoch: 6| Step: 7
Training loss: 2.637815475463867
Validation loss: 2.1653125875739643

Epoch: 6| Step: 8
Training loss: 2.182896852493286
Validation loss: 2.1655842052992953

Epoch: 6| Step: 9
Training loss: 2.547353982925415
Validation loss: 2.1701527334028676

Epoch: 6| Step: 10
Training loss: 2.074991226196289
Validation loss: 2.195024477538242

Epoch: 6| Step: 11
Training loss: 2.3540568351745605
Validation loss: 2.241070588429769

Epoch: 6| Step: 12
Training loss: 2.592164993286133
Validation loss: 2.28119646861989

Epoch: 6| Step: 13
Training loss: 3.4649789333343506
Validation loss: 2.2700424258426954

Epoch: 89| Step: 0
Training loss: 2.675732135772705
Validation loss: 2.2174511468538673

Epoch: 6| Step: 1
Training loss: 2.7366509437561035
Validation loss: 2.174293646248438

Epoch: 6| Step: 2
Training loss: 2.4534730911254883
Validation loss: 2.177974593254828

Epoch: 6| Step: 3
Training loss: 2.8779468536376953
Validation loss: 2.1965060926252797

Epoch: 6| Step: 4
Training loss: 3.056917190551758
Validation loss: 2.1962301628563994

Epoch: 6| Step: 5
Training loss: 2.3296759128570557
Validation loss: 2.2201094729925996

Epoch: 6| Step: 6
Training loss: 2.972799301147461
Validation loss: 2.2368254469287012

Epoch: 6| Step: 7
Training loss: 2.273381233215332
Validation loss: 2.2681714309159147

Epoch: 6| Step: 8
Training loss: 1.4955425262451172
Validation loss: 2.2484114785348215

Epoch: 6| Step: 9
Training loss: 2.1780495643615723
Validation loss: 2.2218422940982285

Epoch: 6| Step: 10
Training loss: 2.4837446212768555
Validation loss: 2.221924322907643

Epoch: 6| Step: 11
Training loss: 2.713920831680298
Validation loss: 2.231694480424286

Epoch: 6| Step: 12
Training loss: 1.6846293210983276
Validation loss: 2.2094983157291206

Epoch: 6| Step: 13
Training loss: 3.3501603603363037
Validation loss: 2.1922299733725925

Epoch: 90| Step: 0
Training loss: 2.0997438430786133
Validation loss: 2.1781328288457726

Epoch: 6| Step: 1
Training loss: 2.8402445316314697
Validation loss: 2.1750255656498734

Epoch: 6| Step: 2
Training loss: 2.2817721366882324
Validation loss: 2.1690012101204164

Epoch: 6| Step: 3
Training loss: 2.7832255363464355
Validation loss: 2.170751219154686

Epoch: 6| Step: 4
Training loss: 2.570666790008545
Validation loss: 2.170448082749562

Epoch: 6| Step: 5
Training loss: 3.268800973892212
Validation loss: 2.171840190887451

Epoch: 6| Step: 6
Training loss: 2.3907270431518555
Validation loss: 2.1665633698945403

Epoch: 6| Step: 7
Training loss: 2.407444953918457
Validation loss: 2.1609431979476765

Epoch: 6| Step: 8
Training loss: 2.0045042037963867
Validation loss: 2.1632926130807526

Epoch: 6| Step: 9
Training loss: 2.543771743774414
Validation loss: 2.1554241000965075

Epoch: 6| Step: 10
Training loss: 2.0464179515838623
Validation loss: 2.1631641849394767

Epoch: 6| Step: 11
Training loss: 2.5329439640045166
Validation loss: 2.166666506439127

Epoch: 6| Step: 12
Training loss: 2.5412333011627197
Validation loss: 2.1678362738701606

Epoch: 6| Step: 13
Training loss: 2.1850545406341553
Validation loss: 2.1765303906574043

Epoch: 91| Step: 0
Training loss: 2.339376449584961
Validation loss: 2.187741054001675

Epoch: 6| Step: 1
Training loss: 2.2479615211486816
Validation loss: 2.2031046062387447

Epoch: 6| Step: 2
Training loss: 1.7957347631454468
Validation loss: 2.223154503812072

Epoch: 6| Step: 3
Training loss: 2.245295763015747
Validation loss: 2.235642433166504

Epoch: 6| Step: 4
Training loss: 2.2850446701049805
Validation loss: 2.253746832570722

Epoch: 6| Step: 5
Training loss: 3.5405330657958984
Validation loss: 2.291973554959861

Epoch: 6| Step: 6
Training loss: 2.1223227977752686
Validation loss: 2.3211972816016084

Epoch: 6| Step: 7
Training loss: 3.0396382808685303
Validation loss: 2.3475904285266833

Epoch: 6| Step: 8
Training loss: 2.1359801292419434
Validation loss: 2.3378184815888763

Epoch: 6| Step: 9
Training loss: 2.5210695266723633
Validation loss: 2.3260492406865603

Epoch: 6| Step: 10
Training loss: 3.0817925930023193
Validation loss: 2.2999264527392644

Epoch: 6| Step: 11
Training loss: 2.5563817024230957
Validation loss: 2.266852850555092

Epoch: 6| Step: 12
Training loss: 2.5242793560028076
Validation loss: 2.229837284293226

Epoch: 6| Step: 13
Training loss: 3.05110239982605
Validation loss: 2.2225779230876634

Epoch: 92| Step: 0
Training loss: 1.7678718566894531
Validation loss: 2.203962336304367

Epoch: 6| Step: 1
Training loss: 2.851086139678955
Validation loss: 2.2015403278412355

Epoch: 6| Step: 2
Training loss: 2.3874316215515137
Validation loss: 2.1839799598980973

Epoch: 6| Step: 3
Training loss: 2.4603002071380615
Validation loss: 2.1821825965758292

Epoch: 6| Step: 4
Training loss: 2.458542823791504
Validation loss: 2.1727424872818815

Epoch: 6| Step: 5
Training loss: 2.0140106678009033
Validation loss: 2.1631527998114146

Epoch: 6| Step: 6
Training loss: 2.285191535949707
Validation loss: 2.15091432550902

Epoch: 6| Step: 7
Training loss: 2.2667653560638428
Validation loss: 2.1479869606674358

Epoch: 6| Step: 8
Training loss: 2.916919469833374
Validation loss: 2.143464216621973

Epoch: 6| Step: 9
Training loss: 2.5891506671905518
Validation loss: 2.1449907800202728

Epoch: 6| Step: 10
Training loss: 2.315415382385254
Validation loss: 2.147949336677469

Epoch: 6| Step: 11
Training loss: 3.1979289054870605
Validation loss: 2.159939145529142

Epoch: 6| Step: 12
Training loss: 2.661672592163086
Validation loss: 2.1633194338890815

Epoch: 6| Step: 13
Training loss: 2.327249050140381
Validation loss: 2.162683412592898

Epoch: 93| Step: 0
Training loss: 2.7028236389160156
Validation loss: 2.1720068070196334

Epoch: 6| Step: 1
Training loss: 3.028298854827881
Validation loss: 2.1602598146725724

Epoch: 6| Step: 2
Training loss: 2.3118484020233154
Validation loss: 2.15430691934401

Epoch: 6| Step: 3
Training loss: 2.0418617725372314
Validation loss: 2.154158728097075

Epoch: 6| Step: 4
Training loss: 2.7279205322265625
Validation loss: 2.1581113364106868

Epoch: 6| Step: 5
Training loss: 2.1867966651916504
Validation loss: 2.1520801180152485

Epoch: 6| Step: 6
Training loss: 2.4955248832702637
Validation loss: 2.167067991789951

Epoch: 6| Step: 7
Training loss: 2.596652030944824
Validation loss: 2.1523664587287494

Epoch: 6| Step: 8
Training loss: 3.251879930496216
Validation loss: 2.138531965594138

Epoch: 6| Step: 9
Training loss: 2.390990734100342
Validation loss: 2.1424204816100416

Epoch: 6| Step: 10
Training loss: 2.131324529647827
Validation loss: 2.139282344489969

Epoch: 6| Step: 11
Training loss: 1.9071451425552368
Validation loss: 2.1426743384330504

Epoch: 6| Step: 12
Training loss: 2.061267614364624
Validation loss: 2.1437072241178123

Epoch: 6| Step: 13
Training loss: 2.4384689331054688
Validation loss: 2.144627349351042

Epoch: 94| Step: 0
Training loss: 2.7856786251068115
Validation loss: 2.1507150127041723

Epoch: 6| Step: 1
Training loss: 2.156489849090576
Validation loss: 2.1451953418793215

Epoch: 6| Step: 2
Training loss: 2.0796897411346436
Validation loss: 2.1576864668118056

Epoch: 6| Step: 3
Training loss: 2.5039172172546387
Validation loss: 2.1792122958808817

Epoch: 6| Step: 4
Training loss: 2.3234732151031494
Validation loss: 2.1889613084895636

Epoch: 6| Step: 5
Training loss: 2.2451279163360596
Validation loss: 2.2042686990512315

Epoch: 6| Step: 6
Training loss: 2.1535401344299316
Validation loss: 2.2238847568470943

Epoch: 6| Step: 7
Training loss: 2.216859817504883
Validation loss: 2.2018616353311846

Epoch: 6| Step: 8
Training loss: 2.2621636390686035
Validation loss: 2.195534772770379

Epoch: 6| Step: 9
Training loss: 2.8242974281311035
Validation loss: 2.1800068937322146

Epoch: 6| Step: 10
Training loss: 3.1719398498535156
Validation loss: 2.1721780633413665

Epoch: 6| Step: 11
Training loss: 2.986811637878418
Validation loss: 2.1545004998483965

Epoch: 6| Step: 12
Training loss: 1.9518110752105713
Validation loss: 2.1455505765894407

Epoch: 6| Step: 13
Training loss: 2.8460378646850586
Validation loss: 2.144206318804013

Epoch: 95| Step: 0
Training loss: 2.0982508659362793
Validation loss: 2.1537403009271108

Epoch: 6| Step: 1
Training loss: 2.9495887756347656
Validation loss: 2.1433996282598025

Epoch: 6| Step: 2
Training loss: 2.3567631244659424
Validation loss: 2.144907985964129

Epoch: 6| Step: 3
Training loss: 2.354093074798584
Validation loss: 2.1297382013772124

Epoch: 6| Step: 4
Training loss: 2.9794235229492188
Validation loss: 2.1297754203119585

Epoch: 6| Step: 5
Training loss: 2.290379524230957
Validation loss: 2.132818850137854

Epoch: 6| Step: 6
Training loss: 2.308515787124634
Validation loss: 2.1312799094825663

Epoch: 6| Step: 7
Training loss: 1.7584584951400757
Validation loss: 2.1219908319493777

Epoch: 6| Step: 8
Training loss: 2.4117445945739746
Validation loss: 2.1294792365002375

Epoch: 6| Step: 9
Training loss: 2.887932300567627
Validation loss: 2.1284926732381186

Epoch: 6| Step: 10
Training loss: 1.5957247018814087
Validation loss: 2.1373114637149278

Epoch: 6| Step: 11
Training loss: 2.8317251205444336
Validation loss: 2.1416312520222

Epoch: 6| Step: 12
Training loss: 3.006761074066162
Validation loss: 2.1299950858598113

Epoch: 6| Step: 13
Training loss: 2.282115936279297
Validation loss: 2.1433554977499027

Epoch: 96| Step: 0
Training loss: 2.1838760375976562
Validation loss: 2.149323868495162

Epoch: 6| Step: 1
Training loss: 1.8357948064804077
Validation loss: 2.1410756867419005

Epoch: 6| Step: 2
Training loss: 2.0893959999084473
Validation loss: 2.1519419864941667

Epoch: 6| Step: 3
Training loss: 2.54691743850708
Validation loss: 2.137106441682385

Epoch: 6| Step: 4
Training loss: 2.431922435760498
Validation loss: 2.1346478564764864

Epoch: 6| Step: 5
Training loss: 1.738895058631897
Validation loss: 2.1338373922532603

Epoch: 6| Step: 6
Training loss: 3.006300926208496
Validation loss: 2.1390270469009236

Epoch: 6| Step: 7
Training loss: 2.6967933177948
Validation loss: 2.161290871199741

Epoch: 6| Step: 8
Training loss: 2.1613667011260986
Validation loss: 2.1527688759629444

Epoch: 6| Step: 9
Training loss: 2.3350648880004883
Validation loss: 2.172059694925944

Epoch: 6| Step: 10
Training loss: 2.651604652404785
Validation loss: 2.1585711881678593

Epoch: 6| Step: 11
Training loss: 2.6931746006011963
Validation loss: 2.1374924157255437

Epoch: 6| Step: 12
Training loss: 3.2301034927368164
Validation loss: 2.1204166617444766

Epoch: 6| Step: 13
Training loss: 2.3523359298706055
Validation loss: 2.125547747458181

Epoch: 97| Step: 0
Training loss: 2.602022409439087
Validation loss: 2.11553216877804

Epoch: 6| Step: 1
Training loss: 2.318321704864502
Validation loss: 2.120295165687479

Epoch: 6| Step: 2
Training loss: 2.5899295806884766
Validation loss: 2.138117064711868

Epoch: 6| Step: 3
Training loss: 2.4417049884796143
Validation loss: 2.157087810577885

Epoch: 6| Step: 4
Training loss: 2.522050380706787
Validation loss: 2.2077553041519655

Epoch: 6| Step: 5
Training loss: 2.3902230262756348
Validation loss: 2.1774551483892624

Epoch: 6| Step: 6
Training loss: 2.9081649780273438
Validation loss: 2.143450960036247

Epoch: 6| Step: 7
Training loss: 2.381564140319824
Validation loss: 2.1162263167801725

Epoch: 6| Step: 8
Training loss: 2.592697858810425
Validation loss: 2.1129405088322137

Epoch: 6| Step: 9
Training loss: 2.813079833984375
Validation loss: 2.118938038426061

Epoch: 6| Step: 10
Training loss: 2.3347272872924805
Validation loss: 2.121130694625198

Epoch: 6| Step: 11
Training loss: 2.0152089595794678
Validation loss: 2.1320141515424176

Epoch: 6| Step: 12
Training loss: 1.8843073844909668
Validation loss: 2.141014519558158

Epoch: 6| Step: 13
Training loss: 2.1614866256713867
Validation loss: 2.1445797079352924

Epoch: 98| Step: 0
Training loss: 2.609715461730957
Validation loss: 2.1469311521899317

Epoch: 6| Step: 1
Training loss: 2.4111857414245605
Validation loss: 2.1586695512135825

Epoch: 6| Step: 2
Training loss: 2.4839110374450684
Validation loss: 2.1750549039533063

Epoch: 6| Step: 3
Training loss: 2.5791029930114746
Validation loss: 2.1772193742054764

Epoch: 6| Step: 4
Training loss: 3.0951180458068848
Validation loss: 2.1622202165665163

Epoch: 6| Step: 5
Training loss: 3.2525432109832764
Validation loss: 2.1558095998661493

Epoch: 6| Step: 6
Training loss: 1.7734265327453613
Validation loss: 2.1750638279863583

Epoch: 6| Step: 7
Training loss: 2.169877529144287
Validation loss: 2.216148876374768

Epoch: 6| Step: 8
Training loss: 1.9001171588897705
Validation loss: 2.2879768802273657

Epoch: 6| Step: 9
Training loss: 2.5076422691345215
Validation loss: 2.3582418426390617

Epoch: 6| Step: 10
Training loss: 2.1064562797546387
Validation loss: 2.3731417245762323

Epoch: 6| Step: 11
Training loss: 2.6380069255828857
Validation loss: 2.284690016059465

Epoch: 6| Step: 12
Training loss: 2.040347099304199
Validation loss: 2.1997335034032024

Epoch: 6| Step: 13
Training loss: 2.950089454650879
Validation loss: 2.154003897020894

Epoch: 99| Step: 0
Training loss: 2.495251178741455
Validation loss: 2.1167220633517028

Epoch: 6| Step: 1
Training loss: 3.1737349033355713
Validation loss: 2.1162964579879597

Epoch: 6| Step: 2
Training loss: 1.878474473953247
Validation loss: 2.1181480294914654

Epoch: 6| Step: 3
Training loss: 1.9963232278823853
Validation loss: 2.116204705289615

Epoch: 6| Step: 4
Training loss: 2.894423007965088
Validation loss: 2.1170942142445552

Epoch: 6| Step: 5
Training loss: 2.640495777130127
Validation loss: 2.1078367105094333

Epoch: 6| Step: 6
Training loss: 1.9426971673965454
Validation loss: 2.1122910232954126

Epoch: 6| Step: 7
Training loss: 2.664088249206543
Validation loss: 2.11012775410888

Epoch: 6| Step: 8
Training loss: 2.3231730461120605
Validation loss: 2.115942221815868

Epoch: 6| Step: 9
Training loss: 2.4596362113952637
Validation loss: 2.1133934605506157

Epoch: 6| Step: 10
Training loss: 2.3481569290161133
Validation loss: 2.1094276815332393

Epoch: 6| Step: 11
Training loss: 2.5081167221069336
Validation loss: 2.107203152871901

Epoch: 6| Step: 12
Training loss: 2.2589640617370605
Validation loss: 2.121746714397143

Epoch: 6| Step: 13
Training loss: 2.633800745010376
Validation loss: 2.1212449150700725

Epoch: 100| Step: 0
Training loss: 2.1223371028900146
Validation loss: 2.1581885404484247

Epoch: 6| Step: 1
Training loss: 2.692495346069336
Validation loss: 2.178644553307564

Epoch: 6| Step: 2
Training loss: 3.111459255218506
Validation loss: 2.192750261675927

Epoch: 6| Step: 3
Training loss: 2.5935497283935547
Validation loss: 2.2039589317896033

Epoch: 6| Step: 4
Training loss: 2.776577949523926
Validation loss: 2.207332944357267

Epoch: 6| Step: 5
Training loss: 2.3187103271484375
Validation loss: 2.195526522974814

Epoch: 6| Step: 6
Training loss: 2.7982921600341797
Validation loss: 2.22571684211813

Epoch: 6| Step: 7
Training loss: 2.0031776428222656
Validation loss: 2.2262356512008177

Epoch: 6| Step: 8
Training loss: 1.6520131826400757
Validation loss: 2.2259611096433414

Epoch: 6| Step: 9
Training loss: 2.245095729827881
Validation loss: 2.2413704113293718

Epoch: 6| Step: 10
Training loss: 2.2113759517669678
Validation loss: 2.2160897652308145

Epoch: 6| Step: 11
Training loss: 2.0394697189331055
Validation loss: 2.199495379642774

Epoch: 6| Step: 12
Training loss: 2.389979362487793
Validation loss: 2.189298329814788

Epoch: 6| Step: 13
Training loss: 3.0970020294189453
Validation loss: 2.1563005473024104

Epoch: 101| Step: 0
Training loss: 2.376765251159668
Validation loss: 2.1373688918288036

Epoch: 6| Step: 1
Training loss: 2.786137819290161
Validation loss: 2.131017697754727

Epoch: 6| Step: 2
Training loss: 2.6348912715911865
Validation loss: 2.1237097247954337

Epoch: 6| Step: 3
Training loss: 2.25746488571167
Validation loss: 2.1184803913998347

Epoch: 6| Step: 4
Training loss: 2.6275038719177246
Validation loss: 2.120850439994566

Epoch: 6| Step: 5
Training loss: 2.170869827270508
Validation loss: 2.1105433164104337

Epoch: 6| Step: 6
Training loss: 2.8299832344055176
Validation loss: 2.111609561468965

Epoch: 6| Step: 7
Training loss: 2.0628223419189453
Validation loss: 2.1141666417480796

Epoch: 6| Step: 8
Training loss: 2.482387065887451
Validation loss: 2.1196315275725497

Epoch: 6| Step: 9
Training loss: 2.302309513092041
Validation loss: 2.1179879814065914

Epoch: 6| Step: 10
Training loss: 2.2957396507263184
Validation loss: 2.1188112381965882

Epoch: 6| Step: 11
Training loss: 2.6924972534179688
Validation loss: 2.1496665939208

Epoch: 6| Step: 12
Training loss: 1.8367997407913208
Validation loss: 2.161610790478286

Epoch: 6| Step: 13
Training loss: 2.473320960998535
Validation loss: 2.151831549982871

Epoch: 102| Step: 0
Training loss: 2.828239679336548
Validation loss: 2.1855889520337506

Epoch: 6| Step: 1
Training loss: 1.925547480583191
Validation loss: 2.1689468711935063

Epoch: 6| Step: 2
Training loss: 2.027523994445801
Validation loss: 2.1533105963019916

Epoch: 6| Step: 3
Training loss: 3.143489360809326
Validation loss: 2.151741796924222

Epoch: 6| Step: 4
Training loss: 2.5052409172058105
Validation loss: 2.128217581779726

Epoch: 6| Step: 5
Training loss: 2.321678876876831
Validation loss: 2.100025394911407

Epoch: 6| Step: 6
Training loss: 2.1435515880584717
Validation loss: 2.079165397151824

Epoch: 6| Step: 7
Training loss: 2.9294819831848145
Validation loss: 2.0803176664536998

Epoch: 6| Step: 8
Training loss: 2.486858367919922
Validation loss: 2.1012077190542735

Epoch: 6| Step: 9
Training loss: 2.608198642730713
Validation loss: 2.094700397983674

Epoch: 6| Step: 10
Training loss: 2.60872220993042
Validation loss: 2.099268033940305

Epoch: 6| Step: 11
Training loss: 2.174774169921875
Validation loss: 2.1112077236175537

Epoch: 6| Step: 12
Training loss: 1.3897550106048584
Validation loss: 2.126829793376307

Epoch: 6| Step: 13
Training loss: 2.7222793102264404
Validation loss: 2.1290361496710006

Epoch: 103| Step: 0
Training loss: 2.533640146255493
Validation loss: 2.1616753942223004

Epoch: 6| Step: 1
Training loss: 2.1480746269226074
Validation loss: 2.1498213634696057

Epoch: 6| Step: 2
Training loss: 1.9290874004364014
Validation loss: 2.147670163903185

Epoch: 6| Step: 3
Training loss: 2.0726358890533447
Validation loss: 2.1513493432793567

Epoch: 6| Step: 4
Training loss: 2.3728787899017334
Validation loss: 2.1565373354060675

Epoch: 6| Step: 5
Training loss: 2.46329402923584
Validation loss: 2.1534398871083416

Epoch: 6| Step: 6
Training loss: 2.587034225463867
Validation loss: 2.146626382745722

Epoch: 6| Step: 7
Training loss: 3.1968612670898438
Validation loss: 2.138451888997068

Epoch: 6| Step: 8
Training loss: 2.862529754638672
Validation loss: 2.140263767652614

Epoch: 6| Step: 9
Training loss: 1.986421823501587
Validation loss: 2.140546361605326

Epoch: 6| Step: 10
Training loss: 1.8220617771148682
Validation loss: 2.1603268320842455

Epoch: 6| Step: 11
Training loss: 2.662837028503418
Validation loss: 2.18765026779585

Epoch: 6| Step: 12
Training loss: 2.3402438163757324
Validation loss: 2.222042691323065

Epoch: 6| Step: 13
Training loss: 2.47365665435791
Validation loss: 2.2308855056762695

Epoch: 104| Step: 0
Training loss: 2.544111728668213
Validation loss: 2.2587182316728818

Epoch: 6| Step: 1
Training loss: 1.9866530895233154
Validation loss: 2.236786548809339

Epoch: 6| Step: 2
Training loss: 1.9029000997543335
Validation loss: 2.216237211740145

Epoch: 6| Step: 3
Training loss: 2.6225523948669434
Validation loss: 2.2168652703685146

Epoch: 6| Step: 4
Training loss: 1.629246473312378
Validation loss: 2.2316376060567875

Epoch: 6| Step: 5
Training loss: 3.2162723541259766
Validation loss: 2.250258655958278

Epoch: 6| Step: 6
Training loss: 2.708021640777588
Validation loss: 2.2479414811698337

Epoch: 6| Step: 7
Training loss: 2.903350830078125
Validation loss: 2.210850892528411

Epoch: 6| Step: 8
Training loss: 2.7334914207458496
Validation loss: 2.1873724409328994

Epoch: 6| Step: 9
Training loss: 2.8170266151428223
Validation loss: 2.1836765594379877

Epoch: 6| Step: 10
Training loss: 2.0896763801574707
Validation loss: 2.1738818050712667

Epoch: 6| Step: 11
Training loss: 2.228175163269043
Validation loss: 2.174933018222932

Epoch: 6| Step: 12
Training loss: 1.8588013648986816
Validation loss: 2.178898437048799

Epoch: 6| Step: 13
Training loss: 3.24484920501709
Validation loss: 2.1884220389909643

Epoch: 105| Step: 0
Training loss: 2.886606216430664
Validation loss: 2.239199792185137

Epoch: 6| Step: 1
Training loss: 2.091207981109619
Validation loss: 2.230032923401043

Epoch: 6| Step: 2
Training loss: 3.0174014568328857
Validation loss: 2.2071126276446926

Epoch: 6| Step: 3
Training loss: 2.9713406562805176
Validation loss: 2.1597865948113064

Epoch: 6| Step: 4
Training loss: 1.5742640495300293
Validation loss: 2.11928468109459

Epoch: 6| Step: 5
Training loss: 2.094214916229248
Validation loss: 2.0783131737862863

Epoch: 6| Step: 6
Training loss: 2.8446059226989746
Validation loss: 2.0800971638771797

Epoch: 6| Step: 7
Training loss: 1.9948524236679077
Validation loss: 2.0629840602156935

Epoch: 6| Step: 8
Training loss: 2.403303384780884
Validation loss: 2.0663324581679476

Epoch: 6| Step: 9
Training loss: 2.698934555053711
Validation loss: 2.069471859162854

Epoch: 6| Step: 10
Training loss: 2.483954906463623
Validation loss: 2.0773841745109967

Epoch: 6| Step: 11
Training loss: 2.145665168762207
Validation loss: 2.085648144445112

Epoch: 6| Step: 12
Training loss: 2.238940715789795
Validation loss: 2.092498221705037

Epoch: 6| Step: 13
Training loss: 1.8435935974121094
Validation loss: 2.1050450776212957

Epoch: 106| Step: 0
Training loss: 1.8787990808486938
Validation loss: 2.1575942552217873

Epoch: 6| Step: 1
Training loss: 1.9908545017242432
Validation loss: 2.232931608794838

Epoch: 6| Step: 2
Training loss: 3.002122402191162
Validation loss: 2.314990133367559

Epoch: 6| Step: 3
Training loss: 3.1870665550231934
Validation loss: 2.3768637718692904

Epoch: 6| Step: 4
Training loss: 2.396449565887451
Validation loss: 2.3618656768593738

Epoch: 6| Step: 5
Training loss: 2.2338263988494873
Validation loss: 2.303257203871204

Epoch: 6| Step: 6
Training loss: 2.30501389503479
Validation loss: 2.24538847707933

Epoch: 6| Step: 7
Training loss: 3.1129446029663086
Validation loss: 2.161616304869293

Epoch: 6| Step: 8
Training loss: 1.7684104442596436
Validation loss: 2.1019402447567193

Epoch: 6| Step: 9
Training loss: 3.067105770111084
Validation loss: 2.0675693532472015

Epoch: 6| Step: 10
Training loss: 2.656404495239258
Validation loss: 2.0718677325915267

Epoch: 6| Step: 11
Training loss: 2.6851067543029785
Validation loss: 2.086340094125399

Epoch: 6| Step: 12
Training loss: 1.8318607807159424
Validation loss: 2.100924209881854

Epoch: 6| Step: 13
Training loss: 1.790015697479248
Validation loss: 2.116349494585427

Epoch: 107| Step: 0
Training loss: 2.306896209716797
Validation loss: 2.1380369509420087

Epoch: 6| Step: 1
Training loss: 2.7588658332824707
Validation loss: 2.133563987670406

Epoch: 6| Step: 2
Training loss: 1.966618299484253
Validation loss: 2.1443676512728453

Epoch: 6| Step: 3
Training loss: 2.392946243286133
Validation loss: 2.137418916148524

Epoch: 6| Step: 4
Training loss: 2.7483272552490234
Validation loss: 2.1372052341379146

Epoch: 6| Step: 5
Training loss: 2.3568906784057617
Validation loss: 2.1128325000885995

Epoch: 6| Step: 6
Training loss: 3.0749611854553223
Validation loss: 2.1073784007821033

Epoch: 6| Step: 7
Training loss: 1.7787680625915527
Validation loss: 2.1009716346699703

Epoch: 6| Step: 8
Training loss: 2.199702739715576
Validation loss: 2.1036936365148073

Epoch: 6| Step: 9
Training loss: 2.1489083766937256
Validation loss: 2.1154731678706344

Epoch: 6| Step: 10
Training loss: 2.181863784790039
Validation loss: 2.15636884268894

Epoch: 6| Step: 11
Training loss: 1.9818636178970337
Validation loss: 2.227504702024562

Epoch: 6| Step: 12
Training loss: 2.8749890327453613
Validation loss: 2.290755466748309

Epoch: 6| Step: 13
Training loss: 3.030910015106201
Validation loss: 2.34399478666244

Epoch: 108| Step: 0
Training loss: 2.205288887023926
Validation loss: 2.3713077934839393

Epoch: 6| Step: 1
Training loss: 2.459796667098999
Validation loss: 2.3480171952196347

Epoch: 6| Step: 2
Training loss: 1.7797446250915527
Validation loss: 2.3141018498328423

Epoch: 6| Step: 3
Training loss: 2.6682088375091553
Validation loss: 2.2807463061424995

Epoch: 6| Step: 4
Training loss: 2.8354263305664062
Validation loss: 2.2538296945633425

Epoch: 6| Step: 5
Training loss: 2.459080219268799
Validation loss: 2.216794498505131

Epoch: 6| Step: 6
Training loss: 2.021209239959717
Validation loss: 2.1798390688434726

Epoch: 6| Step: 7
Training loss: 2.1631405353546143
Validation loss: 2.158109429062054

Epoch: 6| Step: 8
Training loss: 2.3122358322143555
Validation loss: 2.169487628885495

Epoch: 6| Step: 9
Training loss: 2.8022947311401367
Validation loss: 2.161371715607182

Epoch: 6| Step: 10
Training loss: 2.0784027576446533
Validation loss: 2.147646447663666

Epoch: 6| Step: 11
Training loss: 2.773777723312378
Validation loss: 2.157862713260035

Epoch: 6| Step: 12
Training loss: 2.63095760345459
Validation loss: 2.1561321353399627

Epoch: 6| Step: 13
Training loss: 2.4110255241394043
Validation loss: 2.1564871752133934

Epoch: 109| Step: 0
Training loss: 2.247453212738037
Validation loss: 2.1443810642406507

Epoch: 6| Step: 1
Training loss: 2.193737268447876
Validation loss: 2.1518137531895793

Epoch: 6| Step: 2
Training loss: 2.6359148025512695
Validation loss: 2.1389292773380073

Epoch: 6| Step: 3
Training loss: 2.518653392791748
Validation loss: 2.12585199007424

Epoch: 6| Step: 4
Training loss: 2.6956090927124023
Validation loss: 2.109819039221733

Epoch: 6| Step: 5
Training loss: 2.4425556659698486
Validation loss: 2.120066535088324

Epoch: 6| Step: 6
Training loss: 2.1208014488220215
Validation loss: 2.097251089670325

Epoch: 6| Step: 7
Training loss: 2.491802215576172
Validation loss: 2.094734130367156

Epoch: 6| Step: 8
Training loss: 1.943869709968567
Validation loss: 2.1012695899573703

Epoch: 6| Step: 9
Training loss: 2.2081239223480225
Validation loss: 2.0943113270626275

Epoch: 6| Step: 10
Training loss: 3.2274694442749023
Validation loss: 2.127841627725991

Epoch: 6| Step: 11
Training loss: 2.326144218444824
Validation loss: 2.134902141427481

Epoch: 6| Step: 12
Training loss: 1.629516363143921
Validation loss: 2.152614560178531

Epoch: 6| Step: 13
Training loss: 2.619488000869751
Validation loss: 2.181519757034958

Epoch: 110| Step: 0
Training loss: 1.7857517004013062
Validation loss: 2.1927716116751395

Epoch: 6| Step: 1
Training loss: 1.9937129020690918
Validation loss: 2.1971022723823466

Epoch: 6| Step: 2
Training loss: 2.580601453781128
Validation loss: 2.153600267184678

Epoch: 6| Step: 3
Training loss: 2.427595376968384
Validation loss: 2.1246405237464496

Epoch: 6| Step: 4
Training loss: 2.445636510848999
Validation loss: 2.1018107885955484

Epoch: 6| Step: 5
Training loss: 2.1459362506866455
Validation loss: 2.098607122257192

Epoch: 6| Step: 6
Training loss: 3.3160367012023926
Validation loss: 2.0822499413644113

Epoch: 6| Step: 7
Training loss: 2.576401710510254
Validation loss: 2.0983902382594284

Epoch: 6| Step: 8
Training loss: 1.8441791534423828
Validation loss: 2.111537712876515

Epoch: 6| Step: 9
Training loss: 2.1521129608154297
Validation loss: 2.1209605637417046

Epoch: 6| Step: 10
Training loss: 3.2581241130828857
Validation loss: 2.120146410439604

Epoch: 6| Step: 11
Training loss: 2.4735217094421387
Validation loss: 2.1497421944013206

Epoch: 6| Step: 12
Training loss: 1.5535978078842163
Validation loss: 2.1433653652027087

Epoch: 6| Step: 13
Training loss: 3.246854066848755
Validation loss: 2.1583413577848867

Epoch: 111| Step: 0
Training loss: 2.8289613723754883
Validation loss: 2.1417293522947576

Epoch: 6| Step: 1
Training loss: 2.720248222351074
Validation loss: 2.12734039368168

Epoch: 6| Step: 2
Training loss: 2.3840794563293457
Validation loss: 2.1145712739677838

Epoch: 6| Step: 3
Training loss: 2.256554126739502
Validation loss: 2.122033093565254

Epoch: 6| Step: 4
Training loss: 2.3459343910217285
Validation loss: 2.1234609106535554

Epoch: 6| Step: 5
Training loss: 2.5637221336364746
Validation loss: 2.12937254546791

Epoch: 6| Step: 6
Training loss: 2.6084704399108887
Validation loss: 2.124027990525769

Epoch: 6| Step: 7
Training loss: 2.212385416030884
Validation loss: 2.130112863356067

Epoch: 6| Step: 8
Training loss: 1.399526834487915
Validation loss: 2.1500508477610927

Epoch: 6| Step: 9
Training loss: 2.142463445663452
Validation loss: 2.166648421236264

Epoch: 6| Step: 10
Training loss: 1.8551719188690186
Validation loss: 2.1988918166006766

Epoch: 6| Step: 11
Training loss: 2.4781198501586914
Validation loss: 2.2261663662490023

Epoch: 6| Step: 12
Training loss: 2.448855400085449
Validation loss: 2.2220821431888047

Epoch: 6| Step: 13
Training loss: 2.113600015640259
Validation loss: 2.1913823209783083

Epoch: 112| Step: 0
Training loss: 2.0363831520080566
Validation loss: 2.19661731361061

Epoch: 6| Step: 1
Training loss: 2.2497963905334473
Validation loss: 2.2029071315642326

Epoch: 6| Step: 2
Training loss: 2.7234668731689453
Validation loss: 2.2056485529868834

Epoch: 6| Step: 3
Training loss: 2.1228437423706055
Validation loss: 2.1995349699451077

Epoch: 6| Step: 4
Training loss: 1.5209662914276123
Validation loss: 2.181709554887587

Epoch: 6| Step: 5
Training loss: 2.1828417778015137
Validation loss: 2.1666824535657

Epoch: 6| Step: 6
Training loss: 2.678652286529541
Validation loss: 2.1596553889654015

Epoch: 6| Step: 7
Training loss: 3.0023112297058105
Validation loss: 2.1708846579315844

Epoch: 6| Step: 8
Training loss: 2.7421953678131104
Validation loss: 2.150239339438818

Epoch: 6| Step: 9
Training loss: 2.066967010498047
Validation loss: 2.161524804689551

Epoch: 6| Step: 10
Training loss: 2.2431516647338867
Validation loss: 2.1415254249367663

Epoch: 6| Step: 11
Training loss: 2.673013687133789
Validation loss: 2.132903286205825

Epoch: 6| Step: 12
Training loss: 2.3921661376953125
Validation loss: 2.131150407175864

Epoch: 6| Step: 13
Training loss: 1.5120707750320435
Validation loss: 2.114400976447649

Epoch: 113| Step: 0
Training loss: 1.5832264423370361
Validation loss: 2.101003007222247

Epoch: 6| Step: 1
Training loss: 2.537935256958008
Validation loss: 2.1034873429165093

Epoch: 6| Step: 2
Training loss: 2.9433231353759766
Validation loss: 2.101171011565834

Epoch: 6| Step: 3
Training loss: 2.2099287509918213
Validation loss: 2.1009616915897658

Epoch: 6| Step: 4
Training loss: 2.9550042152404785
Validation loss: 2.0965254588793685

Epoch: 6| Step: 5
Training loss: 2.121222972869873
Validation loss: 2.1057476138555877

Epoch: 6| Step: 6
Training loss: 1.8450462818145752
Validation loss: 2.1120298806057183

Epoch: 6| Step: 7
Training loss: 2.1052403450012207
Validation loss: 2.107626202285931

Epoch: 6| Step: 8
Training loss: 1.6386667490005493
Validation loss: 2.109887553799537

Epoch: 6| Step: 9
Training loss: 2.273135185241699
Validation loss: 2.1239455489702124

Epoch: 6| Step: 10
Training loss: 2.892098903656006
Validation loss: 2.1428031665022655

Epoch: 6| Step: 11
Training loss: 2.1486763954162598
Validation loss: 2.171810911547753

Epoch: 6| Step: 12
Training loss: 2.9836106300354004
Validation loss: 2.153396083462623

Epoch: 6| Step: 13
Training loss: 2.079860210418701
Validation loss: 2.141589267279512

Epoch: 114| Step: 0
Training loss: 2.6389331817626953
Validation loss: 2.1225220157254125

Epoch: 6| Step: 1
Training loss: 2.1756105422973633
Validation loss: 2.120322045459542

Epoch: 6| Step: 2
Training loss: 2.3175837993621826
Validation loss: 2.1151141838360856

Epoch: 6| Step: 3
Training loss: 2.1846535205841064
Validation loss: 2.1030445585968676

Epoch: 6| Step: 4
Training loss: 2.5259833335876465
Validation loss: 2.1086972733979583

Epoch: 6| Step: 5
Training loss: 1.7080495357513428
Validation loss: 2.1279554700338714

Epoch: 6| Step: 6
Training loss: 2.2672975063323975
Validation loss: 2.122774321545837

Epoch: 6| Step: 7
Training loss: 2.435279369354248
Validation loss: 2.122386714463593

Epoch: 6| Step: 8
Training loss: 2.3162591457366943
Validation loss: 2.12811606032874

Epoch: 6| Step: 9
Training loss: 1.8916594982147217
Validation loss: 2.1287374547732774

Epoch: 6| Step: 10
Training loss: 2.6194262504577637
Validation loss: 2.141341596521357

Epoch: 6| Step: 11
Training loss: 2.426150321960449
Validation loss: 2.128814558829031

Epoch: 6| Step: 12
Training loss: 2.73042631149292
Validation loss: 2.115818462064189

Epoch: 6| Step: 13
Training loss: 1.7278382778167725
Validation loss: 2.1207099319786153

Epoch: 115| Step: 0
Training loss: 2.6423161029815674
Validation loss: 2.099084246543146

Epoch: 6| Step: 1
Training loss: 2.7052464485168457
Validation loss: 2.090242667864728

Epoch: 6| Step: 2
Training loss: 1.7159847021102905
Validation loss: 2.097894908279501

Epoch: 6| Step: 3
Training loss: 2.008502721786499
Validation loss: 2.0873518105476134

Epoch: 6| Step: 4
Training loss: 2.022549629211426
Validation loss: 2.0870711931618313

Epoch: 6| Step: 5
Training loss: 1.7121671438217163
Validation loss: 2.1055934249713855

Epoch: 6| Step: 6
Training loss: 2.9378504753112793
Validation loss: 2.109863760650799

Epoch: 6| Step: 7
Training loss: 1.9866561889648438
Validation loss: 2.111019503685736

Epoch: 6| Step: 8
Training loss: 2.204514980316162
Validation loss: 2.1125301981485016

Epoch: 6| Step: 9
Training loss: 2.8425145149230957
Validation loss: 2.1347109284452213

Epoch: 6| Step: 10
Training loss: 2.2539687156677246
Validation loss: 2.120747512386691

Epoch: 6| Step: 11
Training loss: 2.6667819023132324
Validation loss: 2.104670642524637

Epoch: 6| Step: 12
Training loss: 1.972548246383667
Validation loss: 2.098693311855357

Epoch: 6| Step: 13
Training loss: 1.628408432006836
Validation loss: 2.104142669708498

Epoch: 116| Step: 0
Training loss: 2.646040439605713
Validation loss: 2.1373371437031734

Epoch: 6| Step: 1
Training loss: 2.0063281059265137
Validation loss: 2.152490741463118

Epoch: 6| Step: 2
Training loss: 2.403639554977417
Validation loss: 2.1760372577175016

Epoch: 6| Step: 3
Training loss: 2.425935745239258
Validation loss: 2.183791965566656

Epoch: 6| Step: 4
Training loss: 2.575336456298828
Validation loss: 2.186913567204629

Epoch: 6| Step: 5
Training loss: 1.7103136777877808
Validation loss: 2.1692243981105026

Epoch: 6| Step: 6
Training loss: 2.7178244590759277
Validation loss: 2.1449819328964397

Epoch: 6| Step: 7
Training loss: 2.929701328277588
Validation loss: 2.1497527553189184

Epoch: 6| Step: 8
Training loss: 2.164684295654297
Validation loss: 2.117748652735064

Epoch: 6| Step: 9
Training loss: 1.8868472576141357
Validation loss: 2.117127198044972

Epoch: 6| Step: 10
Training loss: 2.1098599433898926
Validation loss: 2.1092200663781937

Epoch: 6| Step: 11
Training loss: 2.1368160247802734
Validation loss: 2.0954780040248746

Epoch: 6| Step: 12
Training loss: 1.9803478717803955
Validation loss: 2.0977179029936432

Epoch: 6| Step: 13
Training loss: 1.7584301233291626
Validation loss: 2.1130663938419794

Epoch: 117| Step: 0
Training loss: 2.6543593406677246
Validation loss: 2.085968404687861

Epoch: 6| Step: 1
Training loss: 1.9955708980560303
Validation loss: 2.096765841207197

Epoch: 6| Step: 2
Training loss: 2.9939088821411133
Validation loss: 2.105501533836447

Epoch: 6| Step: 3
Training loss: 1.949186086654663
Validation loss: 2.102105696996053

Epoch: 6| Step: 4
Training loss: 2.405623435974121
Validation loss: 2.080493386073779

Epoch: 6| Step: 5
Training loss: 2.1071743965148926
Validation loss: 2.059459222260342

Epoch: 6| Step: 6
Training loss: 1.9232579469680786
Validation loss: 2.054546986856768

Epoch: 6| Step: 7
Training loss: 1.8459848165512085
Validation loss: 2.062929044487656

Epoch: 6| Step: 8
Training loss: 1.8437920808792114
Validation loss: 2.07596597620236

Epoch: 6| Step: 9
Training loss: 2.0820984840393066
Validation loss: 2.093944687997141

Epoch: 6| Step: 10
Training loss: 2.7211384773254395
Validation loss: 2.0909313553123066

Epoch: 6| Step: 11
Training loss: 2.643385887145996
Validation loss: 2.104927626989221

Epoch: 6| Step: 12
Training loss: 2.6535589694976807
Validation loss: 2.124342792777605

Epoch: 6| Step: 13
Training loss: 1.6942459344863892
Validation loss: 2.1233612029783187

Epoch: 118| Step: 0
Training loss: 1.6645092964172363
Validation loss: 2.1574581118040186

Epoch: 6| Step: 1
Training loss: 2.5949840545654297
Validation loss: 2.1584529107616794

Epoch: 6| Step: 2
Training loss: 2.8206520080566406
Validation loss: 2.1631042495850594

Epoch: 6| Step: 3
Training loss: 2.3189964294433594
Validation loss: 2.180094272859635

Epoch: 6| Step: 4
Training loss: 2.70359468460083
Validation loss: 2.1867996210693033

Epoch: 6| Step: 5
Training loss: 2.090156316757202
Validation loss: 2.197298276808954

Epoch: 6| Step: 6
Training loss: 2.3334715366363525
Validation loss: 2.2073109816479426

Epoch: 6| Step: 7
Training loss: 2.833967924118042
Validation loss: 2.2086695112207884

Epoch: 6| Step: 8
Training loss: 1.7132787704467773
Validation loss: 2.203551564165341

Epoch: 6| Step: 9
Training loss: 2.24981689453125
Validation loss: 2.1959764854882353

Epoch: 6| Step: 10
Training loss: 1.367903232574463
Validation loss: 2.165564557557465

Epoch: 6| Step: 11
Training loss: 2.279183864593506
Validation loss: 2.1453194490043064

Epoch: 6| Step: 12
Training loss: 2.08634090423584
Validation loss: 2.1248782911608295

Epoch: 6| Step: 13
Training loss: 2.2914342880249023
Validation loss: 2.103066293142175

Epoch: 119| Step: 0
Training loss: 1.7555851936340332
Validation loss: 2.1057273418672624

Epoch: 6| Step: 1
Training loss: 2.558345317840576
Validation loss: 2.1119803433777182

Epoch: 6| Step: 2
Training loss: 2.0783867835998535
Validation loss: 2.1309930778318837

Epoch: 6| Step: 3
Training loss: 2.378155469894409
Validation loss: 2.1322356142023557

Epoch: 6| Step: 4
Training loss: 1.3720650672912598
Validation loss: 2.136374509462746

Epoch: 6| Step: 5
Training loss: 1.6304274797439575
Validation loss: 2.144989630227448

Epoch: 6| Step: 6
Training loss: 2.234550952911377
Validation loss: 2.1435062859648015

Epoch: 6| Step: 7
Training loss: 2.4304919242858887
Validation loss: 2.1730395799042075

Epoch: 6| Step: 8
Training loss: 2.5316059589385986
Validation loss: 2.186497139674361

Epoch: 6| Step: 9
Training loss: 2.781954050064087
Validation loss: 2.203086846618242

Epoch: 6| Step: 10
Training loss: 2.4751474857330322
Validation loss: 2.208620525175525

Epoch: 6| Step: 11
Training loss: 2.2878384590148926
Validation loss: 2.2023313635139057

Epoch: 6| Step: 12
Training loss: 2.0711984634399414
Validation loss: 2.19978000784433

Epoch: 6| Step: 13
Training loss: 2.766433000564575
Validation loss: 2.1851584885710027

Epoch: 120| Step: 0
Training loss: 3.006606340408325
Validation loss: 2.1456459888847927

Epoch: 6| Step: 1
Training loss: 1.3280742168426514
Validation loss: 2.134709335142566

Epoch: 6| Step: 2
Training loss: 1.7244877815246582
Validation loss: 2.1300044854482016

Epoch: 6| Step: 3
Training loss: 1.9497265815734863
Validation loss: 2.129607977405671

Epoch: 6| Step: 4
Training loss: 2.845611572265625
Validation loss: 2.1360033173714914

Epoch: 6| Step: 5
Training loss: 2.4292635917663574
Validation loss: 2.09278134376772

Epoch: 6| Step: 6
Training loss: 2.151988983154297
Validation loss: 2.0913555237554733

Epoch: 6| Step: 7
Training loss: 2.0887317657470703
Validation loss: 2.081297169449509

Epoch: 6| Step: 8
Training loss: 1.450623869895935
Validation loss: 2.0783036780613724

Epoch: 6| Step: 9
Training loss: 2.2258358001708984
Validation loss: 2.0800355557472474

Epoch: 6| Step: 10
Training loss: 2.310718297958374
Validation loss: 2.0944727774589293

Epoch: 6| Step: 11
Training loss: 2.4396612644195557
Validation loss: 2.108580204748338

Epoch: 6| Step: 12
Training loss: 2.9514846801757812
Validation loss: 2.179748148046514

Epoch: 6| Step: 13
Training loss: 2.2470738887786865
Validation loss: 2.197807255611625

Epoch: 121| Step: 0
Training loss: 2.5724329948425293
Validation loss: 2.167411514507827

Epoch: 6| Step: 1
Training loss: 2.0764684677124023
Validation loss: 2.1411722603664605

Epoch: 6| Step: 2
Training loss: 2.5137667655944824
Validation loss: 2.1280938476644535

Epoch: 6| Step: 3
Training loss: 1.6032955646514893
Validation loss: 2.1184227312764814

Epoch: 6| Step: 4
Training loss: 2.991626024246216
Validation loss: 2.1157722139871247

Epoch: 6| Step: 5
Training loss: 1.7783901691436768
Validation loss: 2.114155400183893

Epoch: 6| Step: 6
Training loss: 1.9178683757781982
Validation loss: 2.1104373701157106

Epoch: 6| Step: 7
Training loss: 2.6916236877441406
Validation loss: 2.118279451965004

Epoch: 6| Step: 8
Training loss: 2.2437705993652344
Validation loss: 2.1024753637211298

Epoch: 6| Step: 9
Training loss: 1.769856572151184
Validation loss: 2.112390764297978

Epoch: 6| Step: 10
Training loss: 2.0182485580444336
Validation loss: 2.1162711164002777

Epoch: 6| Step: 11
Training loss: 1.8551039695739746
Validation loss: 2.103341028254519

Epoch: 6| Step: 12
Training loss: 2.4429588317871094
Validation loss: 2.112027291328676

Epoch: 6| Step: 13
Training loss: 1.7696986198425293
Validation loss: 2.0919829722373717

Epoch: 122| Step: 0
Training loss: 1.1614105701446533
Validation loss: 2.0885610170261835

Epoch: 6| Step: 1
Training loss: 2.1304163932800293
Validation loss: 2.112216813589937

Epoch: 6| Step: 2
Training loss: 2.1571171283721924
Validation loss: 2.1028965288592922

Epoch: 6| Step: 3
Training loss: 1.787922978401184
Validation loss: 2.1072281586226596

Epoch: 6| Step: 4
Training loss: 1.2720351219177246
Validation loss: 2.104532116202898

Epoch: 6| Step: 5
Training loss: 2.2807393074035645
Validation loss: 2.100972456316794

Epoch: 6| Step: 6
Training loss: 2.040010929107666
Validation loss: 2.08287489029669

Epoch: 6| Step: 7
Training loss: 2.3986876010894775
Validation loss: 2.074736302898776

Epoch: 6| Step: 8
Training loss: 2.813852310180664
Validation loss: 2.0712914159221034

Epoch: 6| Step: 9
Training loss: 2.1970343589782715
Validation loss: 2.0775848447635608

Epoch: 6| Step: 10
Training loss: 2.8919315338134766
Validation loss: 2.085989526523057

Epoch: 6| Step: 11
Training loss: 2.166700839996338
Validation loss: 2.0956018765767417

Epoch: 6| Step: 12
Training loss: 2.5361056327819824
Validation loss: 2.0908633303898636

Epoch: 6| Step: 13
Training loss: 2.519205331802368
Validation loss: 2.0917473198265157

Epoch: 123| Step: 0
Training loss: 1.9480564594268799
Validation loss: 2.0969326367942234

Epoch: 6| Step: 1
Training loss: 2.4844067096710205
Validation loss: 2.129344218520708

Epoch: 6| Step: 2
Training loss: 1.8534212112426758
Validation loss: 2.1687151437164633

Epoch: 6| Step: 3
Training loss: 1.7615141868591309
Validation loss: 2.185264960412056

Epoch: 6| Step: 4
Training loss: 1.6238250732421875
Validation loss: 2.1467035637106946

Epoch: 6| Step: 5
Training loss: 2.584468126296997
Validation loss: 2.1022483507792153

Epoch: 6| Step: 6
Training loss: 2.195578098297119
Validation loss: 2.0804280657922067

Epoch: 6| Step: 7
Training loss: 2.641774892807007
Validation loss: 2.0839118419154996

Epoch: 6| Step: 8
Training loss: 2.0871660709381104
Validation loss: 2.093375285466512

Epoch: 6| Step: 9
Training loss: 3.070235013961792
Validation loss: 2.1058939041629916

Epoch: 6| Step: 10
Training loss: 2.5143795013427734
Validation loss: 2.096596961380333

Epoch: 6| Step: 11
Training loss: 1.6360230445861816
Validation loss: 2.1025007745271087

Epoch: 6| Step: 12
Training loss: 2.64559006690979
Validation loss: 2.0943948043290006

Epoch: 6| Step: 13
Training loss: 0.7191779613494873
Validation loss: 2.1031377776976554

Epoch: 124| Step: 0
Training loss: 2.1569933891296387
Validation loss: 2.0974895082494265

Epoch: 6| Step: 1
Training loss: 2.2069640159606934
Validation loss: 2.1381013854857414

Epoch: 6| Step: 2
Training loss: 2.445437431335449
Validation loss: 2.1881958823050223

Epoch: 6| Step: 3
Training loss: 2.059145927429199
Validation loss: 2.1850596038244103

Epoch: 6| Step: 4
Training loss: 2.388734817504883
Validation loss: 2.1382053718771985

Epoch: 6| Step: 5
Training loss: 2.3522636890411377
Validation loss: 2.1048067513332573

Epoch: 6| Step: 6
Training loss: 2.64048433303833
Validation loss: 2.086821502254855

Epoch: 6| Step: 7
Training loss: 1.8465266227722168
Validation loss: 2.0816181923753474

Epoch: 6| Step: 8
Training loss: 2.230952501296997
Validation loss: 2.0675070644706808

Epoch: 6| Step: 9
Training loss: 1.8618340492248535
Validation loss: 2.0603714425076722

Epoch: 6| Step: 10
Training loss: 1.8868215084075928
Validation loss: 2.112154805532066

Epoch: 6| Step: 11
Training loss: 2.2955987453460693
Validation loss: 2.2002869165071877

Epoch: 6| Step: 12
Training loss: 2.099952459335327
Validation loss: 2.2258892392599456

Epoch: 6| Step: 13
Training loss: 2.1462953090667725
Validation loss: 2.228468656539917

Epoch: 125| Step: 0
Training loss: 1.74429452419281
Validation loss: 2.1871762403877835

Epoch: 6| Step: 1
Training loss: 2.486039638519287
Validation loss: 2.153941927417632

Epoch: 6| Step: 2
Training loss: 2.1869945526123047
Validation loss: 2.145069173587266

Epoch: 6| Step: 3
Training loss: 2.279743194580078
Validation loss: 2.1017142341982935

Epoch: 6| Step: 4
Training loss: 1.859400987625122
Validation loss: 2.0784644285837808

Epoch: 6| Step: 5
Training loss: 1.8632745742797852
Validation loss: 2.0905330373394873

Epoch: 6| Step: 6
Training loss: 2.000978946685791
Validation loss: 2.0851165440774735

Epoch: 6| Step: 7
Training loss: 2.071415662765503
Validation loss: 2.085333915166957

Epoch: 6| Step: 8
Training loss: 2.6059799194335938
Validation loss: 2.086504764454339

Epoch: 6| Step: 9
Training loss: 2.374680995941162
Validation loss: 2.10369102672864

Epoch: 6| Step: 10
Training loss: 2.682373523712158
Validation loss: 2.1214794369154077

Epoch: 6| Step: 11
Training loss: 2.6648168563842773
Validation loss: 2.1308494242288734

Epoch: 6| Step: 12
Training loss: 1.7017478942871094
Validation loss: 2.1554468985526793

Epoch: 6| Step: 13
Training loss: 1.2918950319290161
Validation loss: 2.18130128101636

Epoch: 126| Step: 0
Training loss: 2.0059351921081543
Validation loss: 2.1806536579644806

Epoch: 6| Step: 1
Training loss: 2.0439629554748535
Validation loss: 2.1823005983906407

Epoch: 6| Step: 2
Training loss: 1.4281823635101318
Validation loss: 2.169137763720687

Epoch: 6| Step: 3
Training loss: 1.8317736387252808
Validation loss: 2.162276493605747

Epoch: 6| Step: 4
Training loss: 2.3554062843322754
Validation loss: 2.138631410496209

Epoch: 6| Step: 5
Training loss: 2.1776671409606934
Validation loss: 2.128389914830526

Epoch: 6| Step: 6
Training loss: 2.2486414909362793
Validation loss: 2.093924678781981

Epoch: 6| Step: 7
Training loss: 2.321451187133789
Validation loss: 2.0721692654394333

Epoch: 6| Step: 8
Training loss: 1.9710888862609863
Validation loss: 2.0554899233643726

Epoch: 6| Step: 9
Training loss: 1.4972691535949707
Validation loss: 2.0599547560496996

Epoch: 6| Step: 10
Training loss: 2.7572078704833984
Validation loss: 2.054462250842843

Epoch: 6| Step: 11
Training loss: 2.305673122406006
Validation loss: 2.03209666539264

Epoch: 6| Step: 12
Training loss: 2.715129852294922
Validation loss: 2.041836843695692

Epoch: 6| Step: 13
Training loss: 2.497581958770752
Validation loss: 2.0437107137454453

Epoch: 127| Step: 0
Training loss: 2.1458864212036133
Validation loss: 2.0512569835109096

Epoch: 6| Step: 1
Training loss: 2.9490246772766113
Validation loss: 2.0748077746360534

Epoch: 6| Step: 2
Training loss: 1.9353270530700684
Validation loss: 2.072196214429794

Epoch: 6| Step: 3
Training loss: 0.986972451210022
Validation loss: 2.085283825474401

Epoch: 6| Step: 4
Training loss: 1.8798693418502808
Validation loss: 2.0956093431800924

Epoch: 6| Step: 5
Training loss: 2.3757362365722656
Validation loss: 2.0971371512259207

Epoch: 6| Step: 6
Training loss: 2.3728184700012207
Validation loss: 2.106511298046317

Epoch: 6| Step: 7
Training loss: 2.8223459720611572
Validation loss: 2.1264233409717517

Epoch: 6| Step: 8
Training loss: 1.5944101810455322
Validation loss: 2.1234849511936145

Epoch: 6| Step: 9
Training loss: 2.556647539138794
Validation loss: 2.1081109816028225

Epoch: 6| Step: 10
Training loss: 2.11985445022583
Validation loss: 2.1199284240763676

Epoch: 6| Step: 11
Training loss: 2.0061779022216797
Validation loss: 2.1191959893831642

Epoch: 6| Step: 12
Training loss: 1.8236289024353027
Validation loss: 2.1394965738378544

Epoch: 6| Step: 13
Training loss: 1.6301348209381104
Validation loss: 2.130937091765865

Epoch: 128| Step: 0
Training loss: 2.138218402862549
Validation loss: 2.1350936889648438

Epoch: 6| Step: 1
Training loss: 2.5082926750183105
Validation loss: 2.1658289458162043

Epoch: 6| Step: 2
Training loss: 1.876997709274292
Validation loss: 2.1633267838467836

Epoch: 6| Step: 3
Training loss: 2.5799179077148438
Validation loss: 2.143358181881648

Epoch: 6| Step: 4
Training loss: 2.1600749492645264
Validation loss: 2.1230399480430027

Epoch: 6| Step: 5
Training loss: 1.9917550086975098
Validation loss: 2.1121545581407446

Epoch: 6| Step: 6
Training loss: 2.038802146911621
Validation loss: 2.124329468255402

Epoch: 6| Step: 7
Training loss: 1.7215763330459595
Validation loss: 2.1297119740516908

Epoch: 6| Step: 8
Training loss: 2.068986415863037
Validation loss: 2.1641761487530125

Epoch: 6| Step: 9
Training loss: 2.87322998046875
Validation loss: 2.179862532564389

Epoch: 6| Step: 10
Training loss: 1.8852711915969849
Validation loss: 2.16252218010605

Epoch: 6| Step: 11
Training loss: 2.0273587703704834
Validation loss: 2.095182136822772

Epoch: 6| Step: 12
Training loss: 2.1671385765075684
Validation loss: 2.0807197324691282

Epoch: 6| Step: 13
Training loss: 1.399937629699707
Validation loss: 2.096809752525822

Epoch: 129| Step: 0
Training loss: 2.0060675144195557
Validation loss: 2.1148114627407444

Epoch: 6| Step: 1
Training loss: 2.1750576496124268
Validation loss: 2.131970141523628

Epoch: 6| Step: 2
Training loss: 1.8662954568862915
Validation loss: 2.139960468456309

Epoch: 6| Step: 3
Training loss: 2.565495729446411
Validation loss: 2.1518979290480256

Epoch: 6| Step: 4
Training loss: 2.5574355125427246
Validation loss: 2.1531376095228296

Epoch: 6| Step: 5
Training loss: 2.782547950744629
Validation loss: 2.1593342173484062

Epoch: 6| Step: 6
Training loss: 2.478254795074463
Validation loss: 2.1278043357274865

Epoch: 6| Step: 7
Training loss: 1.474363923072815
Validation loss: 2.1172210567740986

Epoch: 6| Step: 8
Training loss: 1.461718201637268
Validation loss: 2.098230710593603

Epoch: 6| Step: 9
Training loss: 2.120804786682129
Validation loss: 2.0871669220668014

Epoch: 6| Step: 10
Training loss: 2.3090643882751465
Validation loss: 2.0928371696061987

Epoch: 6| Step: 11
Training loss: 1.750740885734558
Validation loss: 2.081514581557243

Epoch: 6| Step: 12
Training loss: 1.648239016532898
Validation loss: 2.080669851713283

Epoch: 6| Step: 13
Training loss: 2.63434100151062
Validation loss: 2.07632270936043

Epoch: 130| Step: 0
Training loss: 1.8203091621398926
Validation loss: 2.0611350485073623

Epoch: 6| Step: 1
Training loss: 1.9181973934173584
Validation loss: 2.0487469985920894

Epoch: 6| Step: 2
Training loss: 2.1843178272247314
Validation loss: 2.0373131254667878

Epoch: 6| Step: 3
Training loss: 1.73311185836792
Validation loss: 2.0230471805859636

Epoch: 6| Step: 4
Training loss: 2.031942844390869
Validation loss: 2.023607910320323

Epoch: 6| Step: 5
Training loss: 1.6951937675476074
Validation loss: 2.041034718995453

Epoch: 6| Step: 6
Training loss: 1.9408845901489258
Validation loss: 2.062780587903915

Epoch: 6| Step: 7
Training loss: 2.70192551612854
Validation loss: 2.089713663183233

Epoch: 6| Step: 8
Training loss: 2.3889594078063965
Validation loss: 2.106398259439776

Epoch: 6| Step: 9
Training loss: 2.387448310852051
Validation loss: 2.1201923995889644

Epoch: 6| Step: 10
Training loss: 1.977365255355835
Validation loss: 2.1067005613798737

Epoch: 6| Step: 11
Training loss: 2.4864914417266846
Validation loss: 2.1134792963663735

Epoch: 6| Step: 12
Training loss: 1.8961024284362793
Validation loss: 2.102915576709214

Epoch: 6| Step: 13
Training loss: 2.78918719291687
Validation loss: 2.099133606879942

Epoch: 131| Step: 0
Training loss: 2.062361001968384
Validation loss: 2.0928100398791734

Epoch: 6| Step: 1
Training loss: 1.9069794416427612
Validation loss: 2.0803390497802408

Epoch: 6| Step: 2
Training loss: 1.3046021461486816
Validation loss: 2.0839219170231975

Epoch: 6| Step: 3
Training loss: 2.3200783729553223
Validation loss: 2.06783793305838

Epoch: 6| Step: 4
Training loss: 2.729666233062744
Validation loss: 2.08684092567813

Epoch: 6| Step: 5
Training loss: 2.2225470542907715
Validation loss: 2.0921867842315347

Epoch: 6| Step: 6
Training loss: 1.993212342262268
Validation loss: 2.0883257824887513

Epoch: 6| Step: 7
Training loss: 2.3121023178100586
Validation loss: 2.091788713650037

Epoch: 6| Step: 8
Training loss: 1.914663553237915
Validation loss: 2.0545161513872046

Epoch: 6| Step: 9
Training loss: 2.1303412914276123
Validation loss: 2.027068755959952

Epoch: 6| Step: 10
Training loss: 1.8880952596664429
Validation loss: 2.039557433897449

Epoch: 6| Step: 11
Training loss: 1.982004165649414
Validation loss: 2.0674488211190827

Epoch: 6| Step: 12
Training loss: 2.1989572048187256
Validation loss: 2.076511001074186

Epoch: 6| Step: 13
Training loss: 2.7462759017944336
Validation loss: 2.0808428500288274

Epoch: 132| Step: 0
Training loss: 2.173172950744629
Validation loss: 2.0776738838482927

Epoch: 6| Step: 1
Training loss: 2.5504961013793945
Validation loss: 2.0889013428841867

Epoch: 6| Step: 2
Training loss: 2.100942373275757
Validation loss: 2.07701862242914

Epoch: 6| Step: 3
Training loss: 2.220517873764038
Validation loss: 2.0744826409124557

Epoch: 6| Step: 4
Training loss: 1.687908411026001
Validation loss: 2.136005122174499

Epoch: 6| Step: 5
Training loss: 2.8441076278686523
Validation loss: 2.1666448808485463

Epoch: 6| Step: 6
Training loss: 1.719988465309143
Validation loss: 2.1831803065474316

Epoch: 6| Step: 7
Training loss: 2.3922314643859863
Validation loss: 2.178887042947995

Epoch: 6| Step: 8
Training loss: 1.4477736949920654
Validation loss: 2.134403920942737

Epoch: 6| Step: 9
Training loss: 2.2367844581604004
Validation loss: 2.1008433949562813

Epoch: 6| Step: 10
Training loss: 1.9114820957183838
Validation loss: 2.071927980710101

Epoch: 6| Step: 11
Training loss: 1.8470189571380615
Validation loss: 2.076131671987554

Epoch: 6| Step: 12
Training loss: 2.2212696075439453
Validation loss: 2.0738457633603002

Epoch: 6| Step: 13
Training loss: 2.1872897148132324
Validation loss: 2.0779100079690256

Epoch: 133| Step: 0
Training loss: 1.691558599472046
Validation loss: 2.0626722292233537

Epoch: 6| Step: 1
Training loss: 1.9626017808914185
Validation loss: 2.049856593531947

Epoch: 6| Step: 2
Training loss: 1.8751438856124878
Validation loss: 2.0514082113901773

Epoch: 6| Step: 3
Training loss: 1.4553766250610352
Validation loss: 2.071387792146334

Epoch: 6| Step: 4
Training loss: 1.2897837162017822
Validation loss: 2.0976399221727924

Epoch: 6| Step: 5
Training loss: 1.9393349885940552
Validation loss: 2.1429180355482202

Epoch: 6| Step: 6
Training loss: 3.2857823371887207
Validation loss: 2.136285835696805

Epoch: 6| Step: 7
Training loss: 1.3523998260498047
Validation loss: 2.135325280568933

Epoch: 6| Step: 8
Training loss: 2.32753586769104
Validation loss: 2.1471802124413113

Epoch: 6| Step: 9
Training loss: 2.350771903991699
Validation loss: 2.135523383335401

Epoch: 6| Step: 10
Training loss: 2.8774170875549316
Validation loss: 2.1178794445530063

Epoch: 6| Step: 11
Training loss: 2.029017448425293
Validation loss: 2.08989611235998

Epoch: 6| Step: 12
Training loss: 2.1469273567199707
Validation loss: 2.082032690766037

Epoch: 6| Step: 13
Training loss: 2.662653923034668
Validation loss: 2.0744499878216813

Epoch: 134| Step: 0
Training loss: 2.2234349250793457
Validation loss: 2.081609364478819

Epoch: 6| Step: 1
Training loss: 1.8078421354293823
Validation loss: 2.0762665605032318

Epoch: 6| Step: 2
Training loss: 2.7351725101470947
Validation loss: 2.072728523644068

Epoch: 6| Step: 3
Training loss: 1.5927828550338745
Validation loss: 2.0586825980935046

Epoch: 6| Step: 4
Training loss: 1.7384181022644043
Validation loss: 2.045445106362784

Epoch: 6| Step: 5
Training loss: 2.1715965270996094
Validation loss: 2.049273298632714

Epoch: 6| Step: 6
Training loss: 2.2781598567962646
Validation loss: 2.053818195096908

Epoch: 6| Step: 7
Training loss: 2.501720666885376
Validation loss: 2.07578876197979

Epoch: 6| Step: 8
Training loss: 2.0444741249084473
Validation loss: 2.0823256161905106

Epoch: 6| Step: 9
Training loss: 1.8023625612258911
Validation loss: 2.101826634458316

Epoch: 6| Step: 10
Training loss: 1.9380589723587036
Validation loss: 2.125415484110514

Epoch: 6| Step: 11
Training loss: 2.587859869003296
Validation loss: 2.1187175281586184

Epoch: 6| Step: 12
Training loss: 2.012873649597168
Validation loss: 2.1304758953791794

Epoch: 6| Step: 13
Training loss: 1.543165683746338
Validation loss: 2.118626553525207

Epoch: 135| Step: 0
Training loss: 1.5766249895095825
Validation loss: 2.1039116562053723

Epoch: 6| Step: 1
Training loss: 2.5931992530822754
Validation loss: 2.086519779697541

Epoch: 6| Step: 2
Training loss: 1.9863002300262451
Validation loss: 2.086487659844019

Epoch: 6| Step: 3
Training loss: 2.19797945022583
Validation loss: 2.087541510981898

Epoch: 6| Step: 4
Training loss: 2.781099796295166
Validation loss: 2.090780669643033

Epoch: 6| Step: 5
Training loss: 2.0792336463928223
Validation loss: 2.1003433555685063

Epoch: 6| Step: 6
Training loss: 1.3511667251586914
Validation loss: 2.0948747588742163

Epoch: 6| Step: 7
Training loss: 1.971256136894226
Validation loss: 2.1087264937739216

Epoch: 6| Step: 8
Training loss: 2.06685471534729
Validation loss: 2.1080116661646033

Epoch: 6| Step: 9
Training loss: 1.376612901687622
Validation loss: 2.1183771112913727

Epoch: 6| Step: 10
Training loss: 1.8869127035140991
Validation loss: 2.12457436643621

Epoch: 6| Step: 11
Training loss: 2.1794216632843018
Validation loss: 2.135675435425133

Epoch: 6| Step: 12
Training loss: 1.7654668092727661
Validation loss: 2.145999090645903

Epoch: 6| Step: 13
Training loss: 3.2215945720672607
Validation loss: 2.1453723599833827

Epoch: 136| Step: 0
Training loss: 2.094564914703369
Validation loss: 2.1180570689580773

Epoch: 6| Step: 1
Training loss: 1.8202745914459229
Validation loss: 2.0954658087863716

Epoch: 6| Step: 2
Training loss: 2.061147689819336
Validation loss: 2.0514800215280182

Epoch: 6| Step: 3
Training loss: 1.8324177265167236
Validation loss: 2.0506135597023913

Epoch: 6| Step: 4
Training loss: 2.193279981613159
Validation loss: 2.0658454587382655

Epoch: 6| Step: 5
Training loss: 1.8464710712432861
Validation loss: 2.0822535330249416

Epoch: 6| Step: 6
Training loss: 2.1285688877105713
Validation loss: 2.1027464866638184

Epoch: 6| Step: 7
Training loss: 2.3489856719970703
Validation loss: 2.0867059794805383

Epoch: 6| Step: 8
Training loss: 2.5013248920440674
Validation loss: 2.0625220601276686

Epoch: 6| Step: 9
Training loss: 2.4137396812438965
Validation loss: 2.0505857826561056

Epoch: 6| Step: 10
Training loss: 2.319658041000366
Validation loss: 2.052711763689595

Epoch: 6| Step: 11
Training loss: 1.9599825143814087
Validation loss: 2.0950851837793985

Epoch: 6| Step: 12
Training loss: 1.5393415689468384
Validation loss: 2.16939894101953

Epoch: 6| Step: 13
Training loss: 2.1726255416870117
Validation loss: 2.2451263704607562

Epoch: 137| Step: 0
Training loss: 1.8597867488861084
Validation loss: 2.3192481827992264

Epoch: 6| Step: 1
Training loss: 2.880934238433838
Validation loss: 2.341459402474024

Epoch: 6| Step: 2
Training loss: 1.3867974281311035
Validation loss: 2.2549861374721734

Epoch: 6| Step: 3
Training loss: 1.9491479396820068
Validation loss: 2.131760512628863

Epoch: 6| Step: 4
Training loss: 1.9666476249694824
Validation loss: 2.108024186985467

Epoch: 6| Step: 5
Training loss: 2.3805530071258545
Validation loss: 2.1200566458445724

Epoch: 6| Step: 6
Training loss: 2.623690366744995
Validation loss: 2.181586734710201

Epoch: 6| Step: 7
Training loss: 2.3974695205688477
Validation loss: 2.191915983794838

Epoch: 6| Step: 8
Training loss: 2.6850600242614746
Validation loss: 2.2459645373846895

Epoch: 6| Step: 9
Training loss: 1.772912621498108
Validation loss: 2.2515885701743503

Epoch: 6| Step: 10
Training loss: 3.2741494178771973
Validation loss: 2.233117982905398

Epoch: 6| Step: 11
Training loss: 2.4265732765197754
Validation loss: 2.2248577199956423

Epoch: 6| Step: 12
Training loss: 1.5264413356781006
Validation loss: 2.181504773837264

Epoch: 6| Step: 13
Training loss: 1.99393892288208
Validation loss: 2.1658350754809637

Epoch: 138| Step: 0
Training loss: 2.453369140625
Validation loss: 2.181646982828776

Epoch: 6| Step: 1
Training loss: 2.0371627807617188
Validation loss: 2.150859079053325

Epoch: 6| Step: 2
Training loss: 2.0007119178771973
Validation loss: 2.133215714526433

Epoch: 6| Step: 3
Training loss: 2.295835494995117
Validation loss: 2.11929831453549

Epoch: 6| Step: 4
Training loss: 1.970726728439331
Validation loss: 2.107787201481481

Epoch: 6| Step: 5
Training loss: 2.728577136993408
Validation loss: 2.1090483383465837

Epoch: 6| Step: 6
Training loss: 2.331002712249756
Validation loss: 2.111881899577315

Epoch: 6| Step: 7
Training loss: 1.8228752613067627
Validation loss: 2.1148748782373246

Epoch: 6| Step: 8
Training loss: 1.4495080709457397
Validation loss: 2.122896473894837

Epoch: 6| Step: 9
Training loss: 2.0170071125030518
Validation loss: 2.13801291296559

Epoch: 6| Step: 10
Training loss: 2.450918436050415
Validation loss: 2.1264928515239427

Epoch: 6| Step: 11
Training loss: 2.0698726177215576
Validation loss: 2.119014032425419

Epoch: 6| Step: 12
Training loss: 1.9779455661773682
Validation loss: 2.1170020321364045

Epoch: 6| Step: 13
Training loss: 2.199509382247925
Validation loss: 2.1037763036707395

Epoch: 139| Step: 0
Training loss: 2.0849709510803223
Validation loss: 2.0762381771559357

Epoch: 6| Step: 1
Training loss: 1.4978784322738647
Validation loss: 2.0594551717081377

Epoch: 6| Step: 2
Training loss: 2.675612688064575
Validation loss: 2.060158068133939

Epoch: 6| Step: 3
Training loss: 2.654435634613037
Validation loss: 2.047677965574367

Epoch: 6| Step: 4
Training loss: 2.219521999359131
Validation loss: 2.035933768877419

Epoch: 6| Step: 5
Training loss: 1.4823954105377197
Validation loss: 2.028745751227102

Epoch: 6| Step: 6
Training loss: 1.537665843963623
Validation loss: 2.040191768318094

Epoch: 6| Step: 7
Training loss: 2.0977020263671875
Validation loss: 2.1014965259900658

Epoch: 6| Step: 8
Training loss: 2.756344795227051
Validation loss: 2.1250315404707387

Epoch: 6| Step: 9
Training loss: 2.221193313598633
Validation loss: 2.161154390663229

Epoch: 6| Step: 10
Training loss: 2.7808313369750977
Validation loss: 2.1492808390689153

Epoch: 6| Step: 11
Training loss: 1.049594759941101
Validation loss: 2.145439858077675

Epoch: 6| Step: 12
Training loss: 1.9713083505630493
Validation loss: 2.172318086829237

Epoch: 6| Step: 13
Training loss: 1.831055760383606
Validation loss: 2.172119450825517

Epoch: 140| Step: 0
Training loss: 2.004641532897949
Validation loss: 2.212242370010704

Epoch: 6| Step: 1
Training loss: 2.1645450592041016
Validation loss: 2.2818265602152836

Epoch: 6| Step: 2
Training loss: 2.3387224674224854
Validation loss: 2.306766935574111

Epoch: 6| Step: 3
Training loss: 2.5642333030700684
Validation loss: 2.309652720728228

Epoch: 6| Step: 4
Training loss: 2.665825843811035
Validation loss: 2.327267751898817

Epoch: 6| Step: 5
Training loss: 2.555992603302002
Validation loss: 2.3580416325599916

Epoch: 6| Step: 6
Training loss: 1.7138787508010864
Validation loss: 2.3119838314671672

Epoch: 6| Step: 7
Training loss: 2.0736050605773926
Validation loss: 2.238332163903021

Epoch: 6| Step: 8
Training loss: 1.8621233701705933
Validation loss: 2.1640001368779007

Epoch: 6| Step: 9
Training loss: 1.9178481101989746
Validation loss: 2.1073318155862952

Epoch: 6| Step: 10
Training loss: 1.9138333797454834
Validation loss: 2.051480985456897

Epoch: 6| Step: 11
Training loss: 1.4049140214920044
Validation loss: 2.020042339960734

Epoch: 6| Step: 12
Training loss: 2.3833422660827637
Validation loss: 2.0040467657068723

Epoch: 6| Step: 13
Training loss: 2.2350056171417236
Validation loss: 1.9919393344592022

Epoch: 141| Step: 0
Training loss: 1.3910174369812012
Validation loss: 1.9857812222614084

Epoch: 6| Step: 1
Training loss: 2.373741388320923
Validation loss: 2.0045239899748113

Epoch: 6| Step: 2
Training loss: 2.3999667167663574
Validation loss: 2.022998704705187

Epoch: 6| Step: 3
Training loss: 1.5569653511047363
Validation loss: 2.017234330536217

Epoch: 6| Step: 4
Training loss: 2.71878719329834
Validation loss: 2.023823966262161

Epoch: 6| Step: 5
Training loss: 2.5551466941833496
Validation loss: 2.0256120645871727

Epoch: 6| Step: 6
Training loss: 2.560272216796875
Validation loss: 2.0362346531242452

Epoch: 6| Step: 7
Training loss: 2.323993682861328
Validation loss: 2.0291047147525254

Epoch: 6| Step: 8
Training loss: 1.5196021795272827
Validation loss: 2.0578354430455033

Epoch: 6| Step: 9
Training loss: 1.8737488985061646
Validation loss: 2.0586353501965924

Epoch: 6| Step: 10
Training loss: 1.6927309036254883
Validation loss: 2.0774639626984954

Epoch: 6| Step: 11
Training loss: 2.0247631072998047
Validation loss: 2.1033820067682574

Epoch: 6| Step: 12
Training loss: 1.2982170581817627
Validation loss: 2.1147254654156264

Epoch: 6| Step: 13
Training loss: 2.4409053325653076
Validation loss: 2.145133577367311

Epoch: 142| Step: 0
Training loss: 2.1496095657348633
Validation loss: 2.160093552322798

Epoch: 6| Step: 1
Training loss: 1.7167084217071533
Validation loss: 2.1605989048557896

Epoch: 6| Step: 2
Training loss: 1.2294766902923584
Validation loss: 2.1391434490039782

Epoch: 6| Step: 3
Training loss: 2.309183120727539
Validation loss: 2.1434743506934053

Epoch: 6| Step: 4
Training loss: 2.3306214809417725
Validation loss: 2.1214051631189164

Epoch: 6| Step: 5
Training loss: 2.485663414001465
Validation loss: 2.140727807116765

Epoch: 6| Step: 6
Training loss: 1.9726773500442505
Validation loss: 2.1198105453163065

Epoch: 6| Step: 7
Training loss: 2.4428396224975586
Validation loss: 2.0935954714334137

Epoch: 6| Step: 8
Training loss: 2.4183764457702637
Validation loss: 2.096660683231969

Epoch: 6| Step: 9
Training loss: 2.399940252304077
Validation loss: 2.0850793828246412

Epoch: 6| Step: 10
Training loss: 1.2463488578796387
Validation loss: 2.05505847161816

Epoch: 6| Step: 11
Training loss: 1.9556057453155518
Validation loss: 2.048527438153503

Epoch: 6| Step: 12
Training loss: 1.89430570602417
Validation loss: 2.0891282648168583

Epoch: 6| Step: 13
Training loss: 2.1079680919647217
Validation loss: 2.108726942411033

Epoch: 143| Step: 0
Training loss: 2.317568302154541
Validation loss: 2.1158080229195217

Epoch: 6| Step: 1
Training loss: 1.5126774311065674
Validation loss: 2.1280328842901413

Epoch: 6| Step: 2
Training loss: 1.4486361742019653
Validation loss: 2.100242417345765

Epoch: 6| Step: 3
Training loss: 2.5018248558044434
Validation loss: 2.0830724239349365

Epoch: 6| Step: 4
Training loss: 1.9662290811538696
Validation loss: 2.0550521650621967

Epoch: 6| Step: 5
Training loss: 2.296555280685425
Validation loss: 2.0278132718096495

Epoch: 6| Step: 6
Training loss: 2.210174083709717
Validation loss: 2.008538919110452

Epoch: 6| Step: 7
Training loss: 2.3435354232788086
Validation loss: 2.012607080962068

Epoch: 6| Step: 8
Training loss: 2.9001083374023438
Validation loss: 2.0126614121980566

Epoch: 6| Step: 9
Training loss: 1.6511073112487793
Validation loss: 2.037393464837023

Epoch: 6| Step: 10
Training loss: 1.6051585674285889
Validation loss: 2.043745876640402

Epoch: 6| Step: 11
Training loss: 1.5983161926269531
Validation loss: 2.0669633137282504

Epoch: 6| Step: 12
Training loss: 2.007131576538086
Validation loss: 2.0872152261836554

Epoch: 6| Step: 13
Training loss: 2.067634344100952
Validation loss: 2.1102929333204865

Epoch: 144| Step: 0
Training loss: 2.029876232147217
Validation loss: 2.1356047609800934

Epoch: 6| Step: 1
Training loss: 1.761122703552246
Validation loss: 2.1427466228444088

Epoch: 6| Step: 2
Training loss: 2.4533872604370117
Validation loss: 2.1446672588266353

Epoch: 6| Step: 3
Training loss: 1.7562227249145508
Validation loss: 2.123212234948271

Epoch: 6| Step: 4
Training loss: 2.2350082397460938
Validation loss: 2.0822405071668726

Epoch: 6| Step: 5
Training loss: 2.5477077960968018
Validation loss: 2.0464352330853863

Epoch: 6| Step: 6
Training loss: 1.5798736810684204
Validation loss: 2.0517177915060394

Epoch: 6| Step: 7
Training loss: 2.7653884887695312
Validation loss: 2.064307479448216

Epoch: 6| Step: 8
Training loss: 2.088418483734131
Validation loss: 2.0393563188532347

Epoch: 6| Step: 9
Training loss: 1.4376672506332397
Validation loss: 2.045531718961654

Epoch: 6| Step: 10
Training loss: 1.750713586807251
Validation loss: 2.035181312150853

Epoch: 6| Step: 11
Training loss: 1.884002685546875
Validation loss: 2.045117764062779

Epoch: 6| Step: 12
Training loss: 2.084716558456421
Validation loss: 2.0633074339999946

Epoch: 6| Step: 13
Training loss: 1.4840755462646484
Validation loss: 2.079104656814247

Epoch: 145| Step: 0
Training loss: 1.5651450157165527
Validation loss: 2.0686109886374524

Epoch: 6| Step: 1
Training loss: 1.653924584388733
Validation loss: 2.0648528132387387

Epoch: 6| Step: 2
Training loss: 1.785104513168335
Validation loss: 2.064506564089047

Epoch: 6| Step: 3
Training loss: 2.462886333465576
Validation loss: 2.0617293337339997

Epoch: 6| Step: 4
Training loss: 2.4164931774139404
Validation loss: 2.050285895665487

Epoch: 6| Step: 5
Training loss: 1.9840142726898193
Validation loss: 2.050768190814603

Epoch: 6| Step: 6
Training loss: 2.1916027069091797
Validation loss: 2.0415073261466077

Epoch: 6| Step: 7
Training loss: 1.5415054559707642
Validation loss: 2.048410795068228

Epoch: 6| Step: 8
Training loss: 1.8074144124984741
Validation loss: 2.026601734981742

Epoch: 6| Step: 9
Training loss: 1.7062344551086426
Validation loss: 2.013939719046316

Epoch: 6| Step: 10
Training loss: 1.5228753089904785
Validation loss: 2.021081288655599

Epoch: 6| Step: 11
Training loss: 2.7438817024230957
Validation loss: 2.0351587213495725

Epoch: 6| Step: 12
Training loss: 2.605832099914551
Validation loss: 2.025893680510982

Epoch: 6| Step: 13
Training loss: 1.2131952047348022
Validation loss: 2.036234276269072

Epoch: 146| Step: 0
Training loss: 1.3483282327651978
Validation loss: 2.0366875484425533

Epoch: 6| Step: 1
Training loss: 1.6865849494934082
Validation loss: 2.0561892640206123

Epoch: 6| Step: 2
Training loss: 2.0123438835144043
Validation loss: 2.089923128004997

Epoch: 6| Step: 3
Training loss: 1.4510293006896973
Validation loss: 2.0819834124657417

Epoch: 6| Step: 4
Training loss: 1.6470770835876465
Validation loss: 2.1067953801924184

Epoch: 6| Step: 5
Training loss: 1.864349365234375
Validation loss: 2.1040733296384095

Epoch: 6| Step: 6
Training loss: 2.0413107872009277
Validation loss: 2.1193247418249808

Epoch: 6| Step: 7
Training loss: 2.4657211303710938
Validation loss: 2.118865837333023

Epoch: 6| Step: 8
Training loss: 1.8477228879928589
Validation loss: 2.1002802861634122

Epoch: 6| Step: 9
Training loss: 1.8718855381011963
Validation loss: 2.0706142763937674

Epoch: 6| Step: 10
Training loss: 2.478696346282959
Validation loss: 2.06238111629281

Epoch: 6| Step: 11
Training loss: 2.4164113998413086
Validation loss: 2.0446631357234013

Epoch: 6| Step: 12
Training loss: 2.332838535308838
Validation loss: 2.048458735148112

Epoch: 6| Step: 13
Training loss: 1.8728232383728027
Validation loss: 2.0596998263430852

Epoch: 147| Step: 0
Training loss: 2.5332117080688477
Validation loss: 2.049883637377011

Epoch: 6| Step: 1
Training loss: 1.7872436046600342
Validation loss: 2.051165174412471

Epoch: 6| Step: 2
Training loss: 2.0996756553649902
Validation loss: 2.042771880344678

Epoch: 6| Step: 3
Training loss: 1.9227101802825928
Validation loss: 2.0564245485490367

Epoch: 6| Step: 4
Training loss: 2.0810813903808594
Validation loss: 2.0586654011921217

Epoch: 6| Step: 5
Training loss: 1.7869542837142944
Validation loss: 2.0705215777120283

Epoch: 6| Step: 6
Training loss: 2.3259522914886475
Validation loss: 2.0685249938759753

Epoch: 6| Step: 7
Training loss: 1.3803340196609497
Validation loss: 2.0830330182147283

Epoch: 6| Step: 8
Training loss: 1.9872617721557617
Validation loss: 2.1073651018963067

Epoch: 6| Step: 9
Training loss: 1.6599736213684082
Validation loss: 2.0912550341698433

Epoch: 6| Step: 10
Training loss: 2.850574493408203
Validation loss: 2.0904438444363174

Epoch: 6| Step: 11
Training loss: 1.639063835144043
Validation loss: 2.0877500413566508

Epoch: 6| Step: 12
Training loss: 1.522874116897583
Validation loss: 2.0782792722025225

Epoch: 6| Step: 13
Training loss: 1.7861415147781372
Validation loss: 2.077194534322267

Epoch: 148| Step: 0
Training loss: 1.6496713161468506
Validation loss: 2.062116276833319

Epoch: 6| Step: 1
Training loss: 1.7164690494537354
Validation loss: 2.045429222045406

Epoch: 6| Step: 2
Training loss: 2.1046199798583984
Validation loss: 2.025173899947956

Epoch: 6| Step: 3
Training loss: 2.6551427841186523
Validation loss: 2.014787454758921

Epoch: 6| Step: 4
Training loss: 1.9140703678131104
Validation loss: 2.0218135874758483

Epoch: 6| Step: 5
Training loss: 1.3900926113128662
Validation loss: 2.0090438345427155

Epoch: 6| Step: 6
Training loss: 2.5421926975250244
Validation loss: 2.0618847698293705

Epoch: 6| Step: 7
Training loss: 2.4930858612060547
Validation loss: 2.1240774072626585

Epoch: 6| Step: 8
Training loss: 2.046694278717041
Validation loss: 2.169425261917935

Epoch: 6| Step: 9
Training loss: 2.250929117202759
Validation loss: 2.1874447484170236

Epoch: 6| Step: 10
Training loss: 1.3177614212036133
Validation loss: 2.1723845825400403

Epoch: 6| Step: 11
Training loss: 2.0914628505706787
Validation loss: 2.1205628841154036

Epoch: 6| Step: 12
Training loss: 1.7792065143585205
Validation loss: 2.0564949884209582

Epoch: 6| Step: 13
Training loss: 1.6535674333572388
Validation loss: 2.0732111725755917

Epoch: 149| Step: 0
Training loss: 1.8735182285308838
Validation loss: 2.0971749982526227

Epoch: 6| Step: 1
Training loss: 2.2588951587677
Validation loss: 2.1481005094384633

Epoch: 6| Step: 2
Training loss: 2.4147396087646484
Validation loss: 2.154613740982548

Epoch: 6| Step: 3
Training loss: 2.6146469116210938
Validation loss: 2.1535472177690074

Epoch: 6| Step: 4
Training loss: 1.7173027992248535
Validation loss: 2.131420909717519

Epoch: 6| Step: 5
Training loss: 1.7475054264068604
Validation loss: 2.065195598909932

Epoch: 6| Step: 6
Training loss: 2.260529041290283
Validation loss: 2.0361938899563206

Epoch: 6| Step: 7
Training loss: 1.2384114265441895
Validation loss: 2.022668843628258

Epoch: 6| Step: 8
Training loss: 1.5207008123397827
Validation loss: 2.038947423299154

Epoch: 6| Step: 9
Training loss: 2.6006064414978027
Validation loss: 2.0780410458964687

Epoch: 6| Step: 10
Training loss: 2.2428174018859863
Validation loss: 2.1403936083598802

Epoch: 6| Step: 11
Training loss: 2.147152900695801
Validation loss: 2.133002778535248

Epoch: 6| Step: 12
Training loss: 1.9749062061309814
Validation loss: 2.1086278384731663

Epoch: 6| Step: 13
Training loss: 2.041768789291382
Validation loss: 2.089153774323002

Epoch: 150| Step: 0
Training loss: 2.051586866378784
Validation loss: 2.0246745271067463

Epoch: 6| Step: 1
Training loss: 1.7789877653121948
Validation loss: 1.9861981202197332

Epoch: 6| Step: 2
Training loss: 1.4578412771224976
Validation loss: 1.9960836261831305

Epoch: 6| Step: 3
Training loss: 1.9684627056121826
Validation loss: 2.008414036484175

Epoch: 6| Step: 4
Training loss: 1.372743844985962
Validation loss: 2.028314913472822

Epoch: 6| Step: 5
Training loss: 2.213636636734009
Validation loss: 2.0298599696928457

Epoch: 6| Step: 6
Training loss: 1.7404574155807495
Validation loss: 2.0677606239113757

Epoch: 6| Step: 7
Training loss: 2.375380039215088
Validation loss: 2.049480697160126

Epoch: 6| Step: 8
Training loss: 1.7817323207855225
Validation loss: 2.0678984785592682

Epoch: 6| Step: 9
Training loss: 2.1248433589935303
Validation loss: 2.092378500969179

Epoch: 6| Step: 10
Training loss: 2.256150960922241
Validation loss: 2.1415506947425103

Epoch: 6| Step: 11
Training loss: 2.592653274536133
Validation loss: 2.187226660789982

Epoch: 6| Step: 12
Training loss: 1.9040448665618896
Validation loss: 2.193365107300461

Epoch: 6| Step: 13
Training loss: 2.5661509037017822
Validation loss: 2.1392887074460267

Epoch: 151| Step: 0
Training loss: 1.9519529342651367
Validation loss: 2.1319810933964227

Epoch: 6| Step: 1
Training loss: 1.9829230308532715
Validation loss: 2.1081894136244252

Epoch: 6| Step: 2
Training loss: 1.7388169765472412
Validation loss: 2.103948103484287

Epoch: 6| Step: 3
Training loss: 2.1839213371276855
Validation loss: 2.0878781221246205

Epoch: 6| Step: 4
Training loss: 2.3397130966186523
Validation loss: 2.0819073338662424

Epoch: 6| Step: 5
Training loss: 2.090363025665283
Validation loss: 2.0783098897626324

Epoch: 6| Step: 6
Training loss: 1.8426380157470703
Validation loss: 2.049410402133901

Epoch: 6| Step: 7
Training loss: 1.5051231384277344
Validation loss: 2.031470275694324

Epoch: 6| Step: 8
Training loss: 1.89064359664917
Validation loss: 2.040814736837982

Epoch: 6| Step: 9
Training loss: 2.7561819553375244
Validation loss: 2.0373264358889673

Epoch: 6| Step: 10
Training loss: 1.8711060285568237
Validation loss: 2.0397139915855984

Epoch: 6| Step: 11
Training loss: 1.5688517093658447
Validation loss: 2.041344106838267

Epoch: 6| Step: 12
Training loss: 1.7294988632202148
Validation loss: 2.034211169007004

Epoch: 6| Step: 13
Training loss: 1.8010172843933105
Validation loss: 2.02847643052378

Epoch: 152| Step: 0
Training loss: 1.6538903713226318
Validation loss: 2.0518369982319493

Epoch: 6| Step: 1
Training loss: 1.562138319015503
Validation loss: 2.066862457542009

Epoch: 6| Step: 2
Training loss: 1.8267920017242432
Validation loss: 2.1085606236611643

Epoch: 6| Step: 3
Training loss: 2.1480085849761963
Validation loss: 2.1549096735574866

Epoch: 6| Step: 4
Training loss: 1.5159313678741455
Validation loss: 2.164994065479566

Epoch: 6| Step: 5
Training loss: 1.9785611629486084
Validation loss: 2.119572636901691

Epoch: 6| Step: 6
Training loss: 1.9760626554489136
Validation loss: 2.103200533056772

Epoch: 6| Step: 7
Training loss: 1.505634069442749
Validation loss: 2.0847075446959464

Epoch: 6| Step: 8
Training loss: 2.556957721710205
Validation loss: 2.084909895414947

Epoch: 6| Step: 9
Training loss: 1.6211234331130981
Validation loss: 2.0625754517893635

Epoch: 6| Step: 10
Training loss: 2.6765084266662598
Validation loss: 2.0698323749726817

Epoch: 6| Step: 11
Training loss: 1.9576983451843262
Validation loss: 2.0870778022273893

Epoch: 6| Step: 12
Training loss: 2.160719394683838
Validation loss: 2.0828637576872304

Epoch: 6| Step: 13
Training loss: 2.2541885375976562
Validation loss: 2.048148444903794

Epoch: 153| Step: 0
Training loss: 1.755695104598999
Validation loss: 2.043855808114493

Epoch: 6| Step: 1
Training loss: 2.7370924949645996
Validation loss: 2.0353441699858634

Epoch: 6| Step: 2
Training loss: 1.3350870609283447
Validation loss: 2.041837857615563

Epoch: 6| Step: 3
Training loss: 1.7843128442764282
Validation loss: 2.066027274695776

Epoch: 6| Step: 4
Training loss: 2.003706455230713
Validation loss: 2.0452757471351215

Epoch: 6| Step: 5
Training loss: 1.6132065057754517
Validation loss: 2.039283957532657

Epoch: 6| Step: 6
Training loss: 1.8051788806915283
Validation loss: 2.0221650215887252

Epoch: 6| Step: 7
Training loss: 2.0640530586242676
Validation loss: 2.030526538049021

Epoch: 6| Step: 8
Training loss: 1.855835199356079
Validation loss: 2.030195322088016

Epoch: 6| Step: 9
Training loss: 1.1788722276687622
Validation loss: 2.0312587035599576

Epoch: 6| Step: 10
Training loss: 1.8130214214324951
Validation loss: 2.0459667521138347

Epoch: 6| Step: 11
Training loss: 2.6218008995056152
Validation loss: 2.0864036749768

Epoch: 6| Step: 12
Training loss: 2.260500192642212
Validation loss: 2.076493819554647

Epoch: 6| Step: 13
Training loss: 1.8592935800552368
Validation loss: 2.0631049922717515

Epoch: 154| Step: 0
Training loss: 2.12815523147583
Validation loss: 2.0685664799905594

Epoch: 6| Step: 1
Training loss: 1.7912707328796387
Validation loss: 2.0743703765253865

Epoch: 6| Step: 2
Training loss: 2.3223371505737305
Validation loss: 2.064700908558343

Epoch: 6| Step: 3
Training loss: 1.3116410970687866
Validation loss: 2.056966620106851

Epoch: 6| Step: 4
Training loss: 1.9693894386291504
Validation loss: 2.0583396586038734

Epoch: 6| Step: 5
Training loss: 1.9460248947143555
Validation loss: 2.0527170858075543

Epoch: 6| Step: 6
Training loss: 1.5585429668426514
Validation loss: 2.0488590809606735

Epoch: 6| Step: 7
Training loss: 2.251645088195801
Validation loss: 2.0515622195377143

Epoch: 6| Step: 8
Training loss: 2.2335634231567383
Validation loss: 2.0583457869868123

Epoch: 6| Step: 9
Training loss: 1.6761322021484375
Validation loss: 2.066146889040547

Epoch: 6| Step: 10
Training loss: 2.03145170211792
Validation loss: 2.0389897067059755

Epoch: 6| Step: 11
Training loss: 2.151212215423584
Validation loss: 2.034902980250697

Epoch: 6| Step: 12
Training loss: 1.455918550491333
Validation loss: 2.040366400954544

Epoch: 6| Step: 13
Training loss: 1.5981249809265137
Validation loss: 2.060600147452406

Epoch: 155| Step: 0
Training loss: 1.662614107131958
Validation loss: 2.0774112773197952

Epoch: 6| Step: 1
Training loss: 1.6050326824188232
Validation loss: 2.087122967166285

Epoch: 6| Step: 2
Training loss: 2.1298882961273193
Validation loss: 2.1020911021899154

Epoch: 6| Step: 3
Training loss: 1.492872714996338
Validation loss: 2.0893880013496644

Epoch: 6| Step: 4
Training loss: 1.8725041151046753
Validation loss: 2.075485373056063

Epoch: 6| Step: 5
Training loss: 2.378340721130371
Validation loss: 2.066857437933645

Epoch: 6| Step: 6
Training loss: 2.127969264984131
Validation loss: 2.0656574669704644

Epoch: 6| Step: 7
Training loss: 1.8997609615325928
Validation loss: 2.060410463681785

Epoch: 6| Step: 8
Training loss: 2.2132163047790527
Validation loss: 2.063032370741649

Epoch: 6| Step: 9
Training loss: 1.8088884353637695
Validation loss: 2.06930689273342

Epoch: 6| Step: 10
Training loss: 1.9619520902633667
Validation loss: 2.0764692791046633

Epoch: 6| Step: 11
Training loss: 1.8284118175506592
Validation loss: 2.0768369500355055

Epoch: 6| Step: 12
Training loss: 1.9666627645492554
Validation loss: 2.105508783812164

Epoch: 6| Step: 13
Training loss: 1.1687226295471191
Validation loss: 2.0986415122144964

Epoch: 156| Step: 0
Training loss: 1.6678756475448608
Validation loss: 2.1053069189030635

Epoch: 6| Step: 1
Training loss: 2.3722903728485107
Validation loss: 2.09666242266214

Epoch: 6| Step: 2
Training loss: 1.4873156547546387
Validation loss: 2.099051731888966

Epoch: 6| Step: 3
Training loss: 1.8733323812484741
Validation loss: 2.0816683384679977

Epoch: 6| Step: 4
Training loss: 1.38615083694458
Validation loss: 2.091724805934455

Epoch: 6| Step: 5
Training loss: 1.7362265586853027
Validation loss: 2.0847720279488513

Epoch: 6| Step: 6
Training loss: 2.1611149311065674
Validation loss: 2.0860463726905083

Epoch: 6| Step: 7
Training loss: 2.3293097019195557
Validation loss: 2.0914397226866854

Epoch: 6| Step: 8
Training loss: 2.1550469398498535
Validation loss: 2.106814238332933

Epoch: 6| Step: 9
Training loss: 1.3864951133728027
Validation loss: 2.08472551068952

Epoch: 6| Step: 10
Training loss: 2.606602191925049
Validation loss: 2.0655739230494343

Epoch: 6| Step: 11
Training loss: 1.448838710784912
Validation loss: 2.0471948859512166

Epoch: 6| Step: 12
Training loss: 1.8079779148101807
Validation loss: 2.0165282705778718

Epoch: 6| Step: 13
Training loss: 1.9528783559799194
Validation loss: 2.0262224904952513

Epoch: 157| Step: 0
Training loss: 1.381601333618164
Validation loss: 2.0336712611618863

Epoch: 6| Step: 1
Training loss: 2.568082571029663
Validation loss: 2.0192606167126725

Epoch: 6| Step: 2
Training loss: 1.4114313125610352
Validation loss: 2.011640456414992

Epoch: 6| Step: 3
Training loss: 1.8770298957824707
Validation loss: 1.998297514454011

Epoch: 6| Step: 4
Training loss: 1.5125055313110352
Validation loss: 2.0127308625046925

Epoch: 6| Step: 5
Training loss: 2.43608021736145
Validation loss: 1.975446706177086

Epoch: 6| Step: 6
Training loss: 1.7051799297332764
Validation loss: 1.9896664850173458

Epoch: 6| Step: 7
Training loss: 1.7231106758117676
Validation loss: 2.0076797662242765

Epoch: 6| Step: 8
Training loss: 1.7062628269195557
Validation loss: 2.0373763422812186

Epoch: 6| Step: 9
Training loss: 2.1943485736846924
Validation loss: 2.0599284530967794

Epoch: 6| Step: 10
Training loss: 1.594031810760498
Validation loss: 2.057922517099688

Epoch: 6| Step: 11
Training loss: 2.638817310333252
Validation loss: 2.05172557984629

Epoch: 6| Step: 12
Training loss: 1.7548946142196655
Validation loss: 2.072787291260176

Epoch: 6| Step: 13
Training loss: 1.8446718454360962
Validation loss: 2.067221441576558

Epoch: 158| Step: 0
Training loss: 1.8150789737701416
Validation loss: 2.0741509493961128

Epoch: 6| Step: 1
Training loss: 1.3410730361938477
Validation loss: 2.115944331692111

Epoch: 6| Step: 2
Training loss: 1.0429832935333252
Validation loss: 2.1584738198147027

Epoch: 6| Step: 3
Training loss: 2.044793128967285
Validation loss: 2.1869174203565045

Epoch: 6| Step: 4
Training loss: 2.8423404693603516
Validation loss: 2.1958531128462924

Epoch: 6| Step: 5
Training loss: 2.203822135925293
Validation loss: 2.2130753224895847

Epoch: 6| Step: 6
Training loss: 1.8744115829467773
Validation loss: 2.1539849337711128

Epoch: 6| Step: 7
Training loss: 1.8053183555603027
Validation loss: 2.1113233617556992

Epoch: 6| Step: 8
Training loss: 1.7572803497314453
Validation loss: 2.0975476388008363

Epoch: 6| Step: 9
Training loss: 2.020005226135254
Validation loss: 2.100913042663246

Epoch: 6| Step: 10
Training loss: 2.0296690464019775
Validation loss: 2.1261471843206756

Epoch: 6| Step: 11
Training loss: 2.1296629905700684
Validation loss: 2.145054768490535

Epoch: 6| Step: 12
Training loss: 1.726220726966858
Validation loss: 2.1288826106697

Epoch: 6| Step: 13
Training loss: 1.9859118461608887
Validation loss: 2.138406451030444

Epoch: 159| Step: 0
Training loss: 1.8898074626922607
Validation loss: 2.1474485935703402

Epoch: 6| Step: 1
Training loss: 2.2434792518615723
Validation loss: 2.127031913367651

Epoch: 6| Step: 2
Training loss: 1.370821475982666
Validation loss: 2.1033396336340133

Epoch: 6| Step: 3
Training loss: 1.599077820777893
Validation loss: 2.0751286347707114

Epoch: 6| Step: 4
Training loss: 1.6229419708251953
Validation loss: 2.0530938422808083

Epoch: 6| Step: 5
Training loss: 1.9298759698867798
Validation loss: 2.036338162678544

Epoch: 6| Step: 6
Training loss: 2.19398832321167
Validation loss: 2.045611354612535

Epoch: 6| Step: 7
Training loss: 1.621366024017334
Validation loss: 2.052300842859412

Epoch: 6| Step: 8
Training loss: 1.996977686882019
Validation loss: 2.06519442091706

Epoch: 6| Step: 9
Training loss: 1.909550428390503
Validation loss: 2.0449603693459624

Epoch: 6| Step: 10
Training loss: 1.333512544631958
Validation loss: 2.02480593035298

Epoch: 6| Step: 11
Training loss: 2.5101609230041504
Validation loss: 1.9964517188328568

Epoch: 6| Step: 12
Training loss: 1.8473244905471802
Validation loss: 2.011165418932515

Epoch: 6| Step: 13
Training loss: 2.9527463912963867
Validation loss: 2.019984910565038

Epoch: 160| Step: 0
Training loss: 1.8689379692077637
Validation loss: 2.02221094664707

Epoch: 6| Step: 1
Training loss: 1.598695993423462
Validation loss: 2.038904622036924

Epoch: 6| Step: 2
Training loss: 1.6897509098052979
Validation loss: 2.0497458775838218

Epoch: 6| Step: 3
Training loss: 1.7027201652526855
Validation loss: 2.0537757219806796

Epoch: 6| Step: 4
Training loss: 1.5963290929794312
Validation loss: 2.048567320710869

Epoch: 6| Step: 5
Training loss: 2.5254063606262207
Validation loss: 2.075220154177758

Epoch: 6| Step: 6
Training loss: 2.4616174697875977
Validation loss: 2.081714371199249

Epoch: 6| Step: 7
Training loss: 1.6162221431732178
Validation loss: 2.0915265954950804

Epoch: 6| Step: 8
Training loss: 1.5864307880401611
Validation loss: 2.081491934355869

Epoch: 6| Step: 9
Training loss: 1.4804760217666626
Validation loss: 2.0969114483043714

Epoch: 6| Step: 10
Training loss: 1.8562901020050049
Validation loss: 2.0943588825964157

Epoch: 6| Step: 11
Training loss: 2.4397313594818115
Validation loss: 2.0876395522907214

Epoch: 6| Step: 12
Training loss: 1.7530601024627686
Validation loss: 2.075482640215146

Epoch: 6| Step: 13
Training loss: 2.189581871032715
Validation loss: 2.0651351405728247

Epoch: 161| Step: 0
Training loss: 1.5977329015731812
Validation loss: 2.050164247071871

Epoch: 6| Step: 1
Training loss: 1.760779857635498
Validation loss: 2.057029116538263

Epoch: 6| Step: 2
Training loss: 2.1836490631103516
Validation loss: 2.0550716333491827

Epoch: 6| Step: 3
Training loss: 1.8133182525634766
Validation loss: 2.055148128540285

Epoch: 6| Step: 4
Training loss: 1.858076810836792
Validation loss: 2.0628924062175136

Epoch: 6| Step: 5
Training loss: 1.446730136871338
Validation loss: 2.0343309653702604

Epoch: 6| Step: 6
Training loss: 1.6855463981628418
Validation loss: 2.062882017063838

Epoch: 6| Step: 7
Training loss: 2.3892598152160645
Validation loss: 2.0519761911002536

Epoch: 6| Step: 8
Training loss: 1.4192070960998535
Validation loss: 2.0637896701853764

Epoch: 6| Step: 9
Training loss: 2.074849843978882
Validation loss: 2.063814752845354

Epoch: 6| Step: 10
Training loss: 1.879299521446228
Validation loss: 2.05545759970142

Epoch: 6| Step: 11
Training loss: 2.3839073181152344
Validation loss: 2.0418441372533

Epoch: 6| Step: 12
Training loss: 1.574866771697998
Validation loss: 2.0343813357814664

Epoch: 6| Step: 13
Training loss: 1.4472535848617554
Validation loss: 2.030606333927442

Epoch: 162| Step: 0
Training loss: 2.3566744327545166
Validation loss: 2.026201453260196

Epoch: 6| Step: 1
Training loss: 1.7862762212753296
Validation loss: 2.0331616658036427

Epoch: 6| Step: 2
Training loss: 1.4622447490692139
Validation loss: 2.0258156740537254

Epoch: 6| Step: 3
Training loss: 1.9892081022262573
Validation loss: 2.043876391585155

Epoch: 6| Step: 4
Training loss: 1.4376636743545532
Validation loss: 2.081446865553497

Epoch: 6| Step: 5
Training loss: 2.3764524459838867
Validation loss: 2.102978898632911

Epoch: 6| Step: 6
Training loss: 2.0363805294036865
Validation loss: 2.1211895840142363

Epoch: 6| Step: 7
Training loss: 1.6467150449752808
Validation loss: 2.1118123736432803

Epoch: 6| Step: 8
Training loss: 1.9403972625732422
Validation loss: 2.0914800987448743

Epoch: 6| Step: 9
Training loss: 1.3149268627166748
Validation loss: 2.0869535297475834

Epoch: 6| Step: 10
Training loss: 1.278695821762085
Validation loss: 2.0627435996968257

Epoch: 6| Step: 11
Training loss: 1.8666651248931885
Validation loss: 2.071598493924705

Epoch: 6| Step: 12
Training loss: 1.9999396800994873
Validation loss: 2.062029807798324

Epoch: 6| Step: 13
Training loss: 2.351792335510254
Validation loss: 2.0762578415614303

Epoch: 163| Step: 0
Training loss: 2.549099922180176
Validation loss: 2.089410724178437

Epoch: 6| Step: 1
Training loss: 1.0419819355010986
Validation loss: 2.1118189506633307

Epoch: 6| Step: 2
Training loss: 1.9015471935272217
Validation loss: 2.100123018346807

Epoch: 6| Step: 3
Training loss: 2.54787540435791
Validation loss: 2.0954677161350044

Epoch: 6| Step: 4
Training loss: 1.88926100730896
Validation loss: 2.096302113225383

Epoch: 6| Step: 5
Training loss: 2.010148048400879
Validation loss: 2.1036985843412337

Epoch: 6| Step: 6
Training loss: 1.8088926076889038
Validation loss: 2.1165031822778846

Epoch: 6| Step: 7
Training loss: 2.006850004196167
Validation loss: 2.104045003973028

Epoch: 6| Step: 8
Training loss: 1.2692303657531738
Validation loss: 2.11735188832847

Epoch: 6| Step: 9
Training loss: 1.609855055809021
Validation loss: 2.092310646528839

Epoch: 6| Step: 10
Training loss: 1.8298145532608032
Validation loss: 2.074685712014475

Epoch: 6| Step: 11
Training loss: 1.7027676105499268
Validation loss: 2.0652536756248883

Epoch: 6| Step: 12
Training loss: 1.6690173149108887
Validation loss: 2.0572045695397163

Epoch: 6| Step: 13
Training loss: 2.0340776443481445
Validation loss: 2.0462770782491213

Epoch: 164| Step: 0
Training loss: 1.2300090789794922
Validation loss: 2.054865893497262

Epoch: 6| Step: 1
Training loss: 1.3869035243988037
Validation loss: 2.054970469526065

Epoch: 6| Step: 2
Training loss: 1.6865642070770264
Validation loss: 2.070621318714593

Epoch: 6| Step: 3
Training loss: 2.272305965423584
Validation loss: 2.068306069220266

Epoch: 6| Step: 4
Training loss: 2.0632762908935547
Validation loss: 2.069675786520845

Epoch: 6| Step: 5
Training loss: 1.2546324729919434
Validation loss: 2.0816247822136007

Epoch: 6| Step: 6
Training loss: 1.817920207977295
Validation loss: 2.0570145025048205

Epoch: 6| Step: 7
Training loss: 1.5217570066452026
Validation loss: 2.066508026533229

Epoch: 6| Step: 8
Training loss: 1.4428420066833496
Validation loss: 2.078550745082158

Epoch: 6| Step: 9
Training loss: 1.7769936323165894
Validation loss: 2.083297748719492

Epoch: 6| Step: 10
Training loss: 2.0230140686035156
Validation loss: 2.0737903066860732

Epoch: 6| Step: 11
Training loss: 2.36026668548584
Validation loss: 2.0848979770496325

Epoch: 6| Step: 12
Training loss: 2.5085644721984863
Validation loss: 2.0759701062274236

Epoch: 6| Step: 13
Training loss: 1.7317774295806885
Validation loss: 2.075184517009284

Epoch: 165| Step: 0
Training loss: 1.2733831405639648
Validation loss: 2.041459778303741

Epoch: 6| Step: 1
Training loss: 2.5125083923339844
Validation loss: 2.039405143389138

Epoch: 6| Step: 2
Training loss: 2.5360870361328125
Validation loss: 2.056126550961566

Epoch: 6| Step: 3
Training loss: 1.7497029304504395
Validation loss: 2.041679779688517

Epoch: 6| Step: 4
Training loss: 2.2860002517700195
Validation loss: 2.042218392895114

Epoch: 6| Step: 5
Training loss: 1.6593658924102783
Validation loss: 2.0440291896943124

Epoch: 6| Step: 6
Training loss: 1.3550469875335693
Validation loss: 2.0528575720325595

Epoch: 6| Step: 7
Training loss: 1.3142309188842773
Validation loss: 2.0700688374939786

Epoch: 6| Step: 8
Training loss: 1.7157673835754395
Validation loss: 2.0917688672260573

Epoch: 6| Step: 9
Training loss: 1.9601143598556519
Validation loss: 2.1036847535000054

Epoch: 6| Step: 10
Training loss: 1.8569566011428833
Validation loss: 2.13355323319794

Epoch: 6| Step: 11
Training loss: 1.470327377319336
Validation loss: 2.1557171652393956

Epoch: 6| Step: 12
Training loss: 2.159717559814453
Validation loss: 2.154559420001122

Epoch: 6| Step: 13
Training loss: 1.0402872562408447
Validation loss: 2.134257088425339

Epoch: 166| Step: 0
Training loss: 2.0363261699676514
Validation loss: 2.162920972352387

Epoch: 6| Step: 1
Training loss: 1.845655083656311
Validation loss: 2.1714710907269548

Epoch: 6| Step: 2
Training loss: 1.7742507457733154
Validation loss: 2.173359706837644

Epoch: 6| Step: 3
Training loss: 1.799501657485962
Validation loss: 2.144975974995603

Epoch: 6| Step: 4
Training loss: 1.701681137084961
Validation loss: 2.1555077004176315

Epoch: 6| Step: 5
Training loss: 1.5126055479049683
Validation loss: 2.137885037288871

Epoch: 6| Step: 6
Training loss: 1.390774130821228
Validation loss: 2.104413624732725

Epoch: 6| Step: 7
Training loss: 1.9864370822906494
Validation loss: 2.0687156287572717

Epoch: 6| Step: 8
Training loss: 1.3345236778259277
Validation loss: 2.0510639259892125

Epoch: 6| Step: 9
Training loss: 1.479168176651001
Validation loss: 2.0357039590035715

Epoch: 6| Step: 10
Training loss: 1.745835542678833
Validation loss: 2.052278762222618

Epoch: 6| Step: 11
Training loss: 2.2845444679260254
Validation loss: 2.0489415891708864

Epoch: 6| Step: 12
Training loss: 1.6906030178070068
Validation loss: 2.0576778022191857

Epoch: 6| Step: 13
Training loss: 2.7119624614715576
Validation loss: 2.055091013190567

Epoch: 167| Step: 0
Training loss: 2.0980169773101807
Validation loss: 2.0450023117885796

Epoch: 6| Step: 1
Training loss: 2.054736614227295
Validation loss: 2.0192886885776313

Epoch: 6| Step: 2
Training loss: 1.847977876663208
Validation loss: 2.02029005430078

Epoch: 6| Step: 3
Training loss: 1.605156660079956
Validation loss: 2.0169755412686254

Epoch: 6| Step: 4
Training loss: 1.614149808883667
Validation loss: 1.9981476876043505

Epoch: 6| Step: 5
Training loss: 1.1263867616653442
Validation loss: 1.99938323420863

Epoch: 6| Step: 6
Training loss: 1.877530574798584
Validation loss: 2.026295144070861

Epoch: 6| Step: 7
Training loss: 1.8030248880386353
Validation loss: 2.046746464185817

Epoch: 6| Step: 8
Training loss: 1.8299319744110107
Validation loss: 2.075450122997325

Epoch: 6| Step: 9
Training loss: 1.9537451267242432
Validation loss: 2.1193249225616455

Epoch: 6| Step: 10
Training loss: 2.0017547607421875
Validation loss: 2.143313943698842

Epoch: 6| Step: 11
Training loss: 1.4602019786834717
Validation loss: 2.1680298877018753

Epoch: 6| Step: 12
Training loss: 1.639670491218567
Validation loss: 2.1538804628515757

Epoch: 6| Step: 13
Training loss: 2.3322529792785645
Validation loss: 2.144723057746887

Epoch: 168| Step: 0
Training loss: 1.3643255233764648
Validation loss: 2.1486347106195267

Epoch: 6| Step: 1
Training loss: 1.6643619537353516
Validation loss: 2.1526410092589674

Epoch: 6| Step: 2
Training loss: 2.048007011413574
Validation loss: 2.1470384982324417

Epoch: 6| Step: 3
Training loss: 1.5103280544281006
Validation loss: 2.1598699759411555

Epoch: 6| Step: 4
Training loss: 1.419033408164978
Validation loss: 2.1250481451711347

Epoch: 6| Step: 5
Training loss: 1.6593118906021118
Validation loss: 2.107290598653978

Epoch: 6| Step: 6
Training loss: 1.7573766708374023
Validation loss: 2.0857849492821643

Epoch: 6| Step: 7
Training loss: 1.709137201309204
Validation loss: 2.08994988536322

Epoch: 6| Step: 8
Training loss: 1.661116361618042
Validation loss: 2.082949610166652

Epoch: 6| Step: 9
Training loss: 1.9418046474456787
Validation loss: 2.0894711350881927

Epoch: 6| Step: 10
Training loss: 3.0377039909362793
Validation loss: 2.1231143538669874

Epoch: 6| Step: 11
Training loss: 1.917933702468872
Validation loss: 2.094013326911516

Epoch: 6| Step: 12
Training loss: 1.618478536605835
Validation loss: 2.115734443869642

Epoch: 6| Step: 13
Training loss: 1.1440116167068481
Validation loss: 2.1017180347955353

Epoch: 169| Step: 0
Training loss: 2.0692648887634277
Validation loss: 2.069532899446385

Epoch: 6| Step: 1
Training loss: 1.3423713445663452
Validation loss: 2.048139556761711

Epoch: 6| Step: 2
Training loss: 2.309565544128418
Validation loss: 2.03043032205233

Epoch: 6| Step: 3
Training loss: 1.9651516675949097
Validation loss: 2.048082023538569

Epoch: 6| Step: 4
Training loss: 1.7261970043182373
Validation loss: 2.036551090978807

Epoch: 6| Step: 5
Training loss: 1.90716552734375
Validation loss: 2.07784761921052

Epoch: 6| Step: 6
Training loss: 1.4635944366455078
Validation loss: 2.0540279880646737

Epoch: 6| Step: 7
Training loss: 1.4482911825180054
Validation loss: 2.0719806660888014

Epoch: 6| Step: 8
Training loss: 1.5769383907318115
Validation loss: 2.0836595668587634

Epoch: 6| Step: 9
Training loss: 1.2737061977386475
Validation loss: 2.0972550094768567

Epoch: 6| Step: 10
Training loss: 1.8113915920257568
Validation loss: 2.140604411402056

Epoch: 6| Step: 11
Training loss: 1.9782989025115967
Validation loss: 2.141193130964874

Epoch: 6| Step: 12
Training loss: 1.5900342464447021
Validation loss: 2.1612170691131265

Epoch: 6| Step: 13
Training loss: 2.5371155738830566
Validation loss: 2.1337868039326002

Epoch: 170| Step: 0
Training loss: 1.7307844161987305
Validation loss: 2.110773014765914

Epoch: 6| Step: 1
Training loss: 2.004567861557007
Validation loss: 2.1060393112961964

Epoch: 6| Step: 2
Training loss: 1.834707498550415
Validation loss: 2.096324315635107

Epoch: 6| Step: 3
Training loss: 1.9735445976257324
Validation loss: 2.092905080446633

Epoch: 6| Step: 4
Training loss: 2.097921371459961
Validation loss: 2.105512813855243

Epoch: 6| Step: 5
Training loss: 1.7052638530731201
Validation loss: 2.1294405665448917

Epoch: 6| Step: 6
Training loss: 1.9790046215057373
Validation loss: 2.137710532834453

Epoch: 6| Step: 7
Training loss: 1.7714104652404785
Validation loss: 2.0943654455164427

Epoch: 6| Step: 8
Training loss: 1.2949602603912354
Validation loss: 2.0638826585585073

Epoch: 6| Step: 9
Training loss: 1.1418343782424927
Validation loss: 2.0540123152476486

Epoch: 6| Step: 10
Training loss: 1.5847713947296143
Validation loss: 2.025778889656067

Epoch: 6| Step: 11
Training loss: 1.3255020380020142
Validation loss: 2.02789225885945

Epoch: 6| Step: 12
Training loss: 1.6963350772857666
Validation loss: 2.0384257583207983

Epoch: 6| Step: 13
Training loss: 2.5182955265045166
Validation loss: 2.0191690921783447

Epoch: 171| Step: 0
Training loss: 1.5292253494262695
Validation loss: 2.0276160419628186

Epoch: 6| Step: 1
Training loss: 2.184258222579956
Validation loss: 2.0282446722830496

Epoch: 6| Step: 2
Training loss: 1.4754947423934937
Validation loss: 2.045434110908098

Epoch: 6| Step: 3
Training loss: 1.6223176717758179
Validation loss: 2.073708882895849

Epoch: 6| Step: 4
Training loss: 1.8403576612472534
Validation loss: 2.119970542128368

Epoch: 6| Step: 5
Training loss: 1.8900870084762573
Validation loss: 2.140883325248636

Epoch: 6| Step: 6
Training loss: 2.1090359687805176
Validation loss: 2.16807286970077

Epoch: 6| Step: 7
Training loss: 1.8144201040267944
Validation loss: 2.1653120415185088

Epoch: 6| Step: 8
Training loss: 2.349466323852539
Validation loss: 2.172691709251814

Epoch: 6| Step: 9
Training loss: 1.635624885559082
Validation loss: 2.1394849823367212

Epoch: 6| Step: 10
Training loss: 1.5605920553207397
Validation loss: 2.097125614843061

Epoch: 6| Step: 11
Training loss: 1.4227652549743652
Validation loss: 2.0756741813434068

Epoch: 6| Step: 12
Training loss: 1.3750033378601074
Validation loss: 2.0455218848361763

Epoch: 6| Step: 13
Training loss: 1.3194000720977783
Validation loss: 2.043940322373503

Epoch: 172| Step: 0
Training loss: 1.8227031230926514
Validation loss: 2.032404622723979

Epoch: 6| Step: 1
Training loss: 1.7366509437561035
Validation loss: 2.025611992805235

Epoch: 6| Step: 2
Training loss: 1.938279151916504
Validation loss: 2.026177171737917

Epoch: 6| Step: 3
Training loss: 1.5018880367279053
Validation loss: 2.038750002461095

Epoch: 6| Step: 4
Training loss: 1.5921714305877686
Validation loss: 2.064642758779628

Epoch: 6| Step: 5
Training loss: 1.7321617603302002
Validation loss: 2.088690359105346

Epoch: 6| Step: 6
Training loss: 1.3970943689346313
Validation loss: 2.0946932633717856

Epoch: 6| Step: 7
Training loss: 1.6849462985992432
Validation loss: 2.1054356123811457

Epoch: 6| Step: 8
Training loss: 1.8601731061935425
Validation loss: 2.1077625174676218

Epoch: 6| Step: 9
Training loss: 1.465069055557251
Validation loss: 2.1245870564573552

Epoch: 6| Step: 10
Training loss: 1.4199961423873901
Validation loss: 2.108805129604955

Epoch: 6| Step: 11
Training loss: 1.914119005203247
Validation loss: 2.1100994540799047

Epoch: 6| Step: 12
Training loss: 1.9135462045669556
Validation loss: 2.117819483562182

Epoch: 6| Step: 13
Training loss: 2.1993017196655273
Validation loss: 2.138512634461926

Epoch: 173| Step: 0
Training loss: 1.888229250907898
Validation loss: 2.115779769036078

Epoch: 6| Step: 1
Training loss: 1.541103720664978
Validation loss: 2.1110549819084907

Epoch: 6| Step: 2
Training loss: 1.8202879428863525
Validation loss: 2.063941373619982

Epoch: 6| Step: 3
Training loss: 1.353675365447998
Validation loss: 2.0592978257004932

Epoch: 6| Step: 4
Training loss: 1.5348399877548218
Validation loss: 2.053246380180441

Epoch: 6| Step: 5
Training loss: 2.190643787384033
Validation loss: 2.057035473085219

Epoch: 6| Step: 6
Training loss: 2.10852313041687
Validation loss: 2.0463549808789323

Epoch: 6| Step: 7
Training loss: 1.8655738830566406
Validation loss: 2.05566926669049

Epoch: 6| Step: 8
Training loss: 2.339822769165039
Validation loss: 2.0451907868026407

Epoch: 6| Step: 9
Training loss: 1.894693374633789
Validation loss: 2.0226957669822117

Epoch: 6| Step: 10
Training loss: 1.7922358512878418
Validation loss: 2.029445637938797

Epoch: 6| Step: 11
Training loss: 1.2414257526397705
Validation loss: 2.019132855117962

Epoch: 6| Step: 12
Training loss: 1.1342387199401855
Validation loss: 2.0354183566185737

Epoch: 6| Step: 13
Training loss: 1.8082561492919922
Validation loss: 2.0323628507634646

Epoch: 174| Step: 0
Training loss: 2.7639365196228027
Validation loss: 2.032621434939805

Epoch: 6| Step: 1
Training loss: 1.4575257301330566
Validation loss: 2.075554797726293

Epoch: 6| Step: 2
Training loss: 1.4121074676513672
Validation loss: 2.109786323321763

Epoch: 6| Step: 3
Training loss: 2.168276309967041
Validation loss: 2.1224016592066777

Epoch: 6| Step: 4
Training loss: 1.2834213972091675
Validation loss: 2.1473475630565355

Epoch: 6| Step: 5
Training loss: 1.2188029289245605
Validation loss: 2.1765233867911884

Epoch: 6| Step: 6
Training loss: 1.3857640027999878
Validation loss: 2.193140132452852

Epoch: 6| Step: 7
Training loss: 2.0454654693603516
Validation loss: 2.211537230399347

Epoch: 6| Step: 8
Training loss: 1.4730452299118042
Validation loss: 2.1661592991121355

Epoch: 6| Step: 9
Training loss: 1.9465028047561646
Validation loss: 2.120852199933862

Epoch: 6| Step: 10
Training loss: 1.5199023485183716
Validation loss: 2.0999421458090506

Epoch: 6| Step: 11
Training loss: 1.7309422492980957
Validation loss: 2.0843055837897846

Epoch: 6| Step: 12
Training loss: 1.7146353721618652
Validation loss: 2.03610764139442

Epoch: 6| Step: 13
Training loss: 1.8133972883224487
Validation loss: 2.0177622520795433

Epoch: 175| Step: 0
Training loss: 2.2004551887512207
Validation loss: 2.0189412268259193

Epoch: 6| Step: 1
Training loss: 1.3952949047088623
Validation loss: 2.0162957150449037

Epoch: 6| Step: 2
Training loss: 1.383122444152832
Validation loss: 2.017019587178384

Epoch: 6| Step: 3
Training loss: 1.2091095447540283
Validation loss: 2.0234695813989125

Epoch: 6| Step: 4
Training loss: 2.39194917678833
Validation loss: 2.028801520665487

Epoch: 6| Step: 5
Training loss: 2.0036299228668213
Validation loss: 2.030793615566787

Epoch: 6| Step: 6
Training loss: 1.5611169338226318
Validation loss: 2.0225983268471173

Epoch: 6| Step: 7
Training loss: 1.3334429264068604
Validation loss: 2.0339320833965013

Epoch: 6| Step: 8
Training loss: 2.4421286582946777
Validation loss: 2.055987481148012

Epoch: 6| Step: 9
Training loss: 1.6150741577148438
Validation loss: 2.0772344604615243

Epoch: 6| Step: 10
Training loss: 1.2065954208374023
Validation loss: 2.100843478274602

Epoch: 6| Step: 11
Training loss: 1.2664872407913208
Validation loss: 2.1481697687538723

Epoch: 6| Step: 12
Training loss: 2.206483840942383
Validation loss: 2.152676001671822

Epoch: 6| Step: 13
Training loss: 1.2027573585510254
Validation loss: 2.161114150477994

Epoch: 176| Step: 0
Training loss: 2.1055004596710205
Validation loss: 2.1759100293600433

Epoch: 6| Step: 1
Training loss: 1.6867902278900146
Validation loss: 2.165962490984189

Epoch: 6| Step: 2
Training loss: 1.6393473148345947
Validation loss: 2.1196085893979637

Epoch: 6| Step: 3
Training loss: 1.6686961650848389
Validation loss: 2.0816731658033145

Epoch: 6| Step: 4
Training loss: 1.6263322830200195
Validation loss: 2.0815017633540656

Epoch: 6| Step: 5
Training loss: 1.7870017290115356
Validation loss: 2.0671019605410996

Epoch: 6| Step: 6
Training loss: 1.7631175518035889
Validation loss: 2.067738135655721

Epoch: 6| Step: 7
Training loss: 1.4677784442901611
Validation loss: 2.062871330527849

Epoch: 6| Step: 8
Training loss: 2.2076568603515625
Validation loss: 2.045751622928086

Epoch: 6| Step: 9
Training loss: 1.5560276508331299
Validation loss: 2.042563751179685

Epoch: 6| Step: 10
Training loss: 1.3079924583435059
Validation loss: 2.0386341259043705

Epoch: 6| Step: 11
Training loss: 1.681382656097412
Validation loss: 2.0346050339360393

Epoch: 6| Step: 12
Training loss: 1.4395027160644531
Validation loss: 2.054724011369931

Epoch: 6| Step: 13
Training loss: 1.5650814771652222
Validation loss: 2.0734146025873

Epoch: 177| Step: 0
Training loss: 1.6380304098129272
Validation loss: 2.0986439079366703

Epoch: 6| Step: 1
Training loss: 1.193558692932129
Validation loss: 2.083272785268804

Epoch: 6| Step: 2
Training loss: 1.8774405717849731
Validation loss: 2.0982881002528693

Epoch: 6| Step: 3
Training loss: 2.013937473297119
Validation loss: 2.102176735478063

Epoch: 6| Step: 4
Training loss: 1.7211229801177979
Validation loss: 2.102792662958945

Epoch: 6| Step: 5
Training loss: 1.782216191291809
Validation loss: 2.0917039289269397

Epoch: 6| Step: 6
Training loss: 1.5790417194366455
Validation loss: 2.094417284893733

Epoch: 6| Step: 7
Training loss: 2.092594623565674
Validation loss: 2.0787458714618476

Epoch: 6| Step: 8
Training loss: 1.4236469268798828
Validation loss: 2.07190611029184

Epoch: 6| Step: 9
Training loss: 1.4693999290466309
Validation loss: 2.08905799670886

Epoch: 6| Step: 10
Training loss: 1.9601788520812988
Validation loss: 2.097948674232729

Epoch: 6| Step: 11
Training loss: 1.398705244064331
Validation loss: 2.1032600774559924

Epoch: 6| Step: 12
Training loss: 1.3050941228866577
Validation loss: 2.0458702412984704

Epoch: 6| Step: 13
Training loss: 2.062390089035034
Validation loss: 2.0284506146625807

Epoch: 178| Step: 0
Training loss: 1.4336609840393066
Validation loss: 2.0354491151789182

Epoch: 6| Step: 1
Training loss: 1.83916437625885
Validation loss: 2.049775290232833

Epoch: 6| Step: 2
Training loss: 1.5644036531448364
Validation loss: 2.0438632247268513

Epoch: 6| Step: 3
Training loss: 1.1984716653823853
Validation loss: 2.0565157487828243

Epoch: 6| Step: 4
Training loss: 1.8921749591827393
Validation loss: 2.0322830728305283

Epoch: 6| Step: 5
Training loss: 1.6815418004989624
Validation loss: 2.0326324111671856

Epoch: 6| Step: 6
Training loss: 1.5060514211654663
Validation loss: 2.021218799775647

Epoch: 6| Step: 7
Training loss: 2.204828977584839
Validation loss: 2.0286859927638883

Epoch: 6| Step: 8
Training loss: 0.9604673385620117
Validation loss: 2.0450986892946306

Epoch: 6| Step: 9
Training loss: 1.354926586151123
Validation loss: 2.037191108990741

Epoch: 6| Step: 10
Training loss: 2.016770839691162
Validation loss: 2.0619607087104552

Epoch: 6| Step: 11
Training loss: 1.7094199657440186
Validation loss: 2.0688248462574457

Epoch: 6| Step: 12
Training loss: 1.9677176475524902
Validation loss: 2.0651847649646062

Epoch: 6| Step: 13
Training loss: 1.8014869689941406
Validation loss: 2.0838007311667166

Epoch: 179| Step: 0
Training loss: 1.6887388229370117
Validation loss: 2.0713391304016113

Epoch: 6| Step: 1
Training loss: 1.835085391998291
Validation loss: 2.0320147160560853

Epoch: 6| Step: 2
Training loss: 2.108659505844116
Validation loss: 2.029047155892977

Epoch: 6| Step: 3
Training loss: 1.61174476146698
Validation loss: 2.0262714611586703

Epoch: 6| Step: 4
Training loss: 1.2937906980514526
Validation loss: 2.0481771781880367

Epoch: 6| Step: 5
Training loss: 1.737921118736267
Validation loss: 2.0492262430088495

Epoch: 6| Step: 6
Training loss: 1.6045811176300049
Validation loss: 2.043371167234195

Epoch: 6| Step: 7
Training loss: 1.9455147981643677
Validation loss: 2.0542804220671296

Epoch: 6| Step: 8
Training loss: 1.9539344310760498
Validation loss: 2.0746525538864957

Epoch: 6| Step: 9
Training loss: 1.352819561958313
Validation loss: 2.0901241558854298

Epoch: 6| Step: 10
Training loss: 1.342225432395935
Validation loss: 2.0951785349076792

Epoch: 6| Step: 11
Training loss: 1.5314472913742065
Validation loss: 2.1007460599304526

Epoch: 6| Step: 12
Training loss: 1.0240129232406616
Validation loss: 2.090429107348124

Epoch: 6| Step: 13
Training loss: 1.5481858253479004
Validation loss: 2.0461448546378844

Epoch: 180| Step: 0
Training loss: 1.2915462255477905
Validation loss: 2.056332390795472

Epoch: 6| Step: 1
Training loss: 1.292283058166504
Validation loss: 2.0350604954586236

Epoch: 6| Step: 2
Training loss: 1.6193270683288574
Validation loss: 2.04887814675608

Epoch: 6| Step: 3
Training loss: 2.4204745292663574
Validation loss: 2.058741174718385

Epoch: 6| Step: 4
Training loss: 1.4897594451904297
Validation loss: 2.0525816281636557

Epoch: 6| Step: 5
Training loss: 2.0242538452148438
Validation loss: 2.0754917372939405

Epoch: 6| Step: 6
Training loss: 1.785668134689331
Validation loss: 2.0750182264594623

Epoch: 6| Step: 7
Training loss: 1.314195990562439
Validation loss: 2.0691118317265667

Epoch: 6| Step: 8
Training loss: 1.0273065567016602
Validation loss: 2.0785678381560952

Epoch: 6| Step: 9
Training loss: 1.1808688640594482
Validation loss: 2.0772214192216114

Epoch: 6| Step: 10
Training loss: 1.8768653869628906
Validation loss: 2.11229464315599

Epoch: 6| Step: 11
Training loss: 1.7275139093399048
Validation loss: 2.0969515615893948

Epoch: 6| Step: 12
Training loss: 1.320847749710083
Validation loss: 2.0969868424118205

Epoch: 6| Step: 13
Training loss: 2.3493173122406006
Validation loss: 2.109768613692253

Epoch: 181| Step: 0
Training loss: 1.8771882057189941
Validation loss: 2.071398744019129

Epoch: 6| Step: 1
Training loss: 1.7114276885986328
Validation loss: 2.1105103056917907

Epoch: 6| Step: 2
Training loss: 0.7316258549690247
Validation loss: 2.1323646960719937

Epoch: 6| Step: 3
Training loss: 1.4296358823776245
Validation loss: 2.113017314223833

Epoch: 6| Step: 4
Training loss: 1.5167357921600342
Validation loss: 2.1127923278398413

Epoch: 6| Step: 5
Training loss: 1.3228397369384766
Validation loss: 2.128313508085025

Epoch: 6| Step: 6
Training loss: 1.7600988149642944
Validation loss: 2.20083555611231

Epoch: 6| Step: 7
Training loss: 1.6804014444351196
Validation loss: 2.20426869392395

Epoch: 6| Step: 8
Training loss: 2.192647933959961
Validation loss: 2.214049780240623

Epoch: 6| Step: 9
Training loss: 1.4474058151245117
Validation loss: 2.2217334060258764

Epoch: 6| Step: 10
Training loss: 1.6534512042999268
Validation loss: 2.2061729572152577

Epoch: 6| Step: 11
Training loss: 1.6709868907928467
Validation loss: 2.1611274698729157

Epoch: 6| Step: 12
Training loss: 1.4182301759719849
Validation loss: 2.133296271806122

Epoch: 6| Step: 13
Training loss: 1.9085551500320435
Validation loss: 2.1053695191619215

Epoch: 182| Step: 0
Training loss: 1.1534881591796875
Validation loss: 2.082863420568487

Epoch: 6| Step: 1
Training loss: 1.3788154125213623
Validation loss: 2.0224673940289404

Epoch: 6| Step: 2
Training loss: 1.3450896739959717
Validation loss: 1.986664863042934

Epoch: 6| Step: 3
Training loss: 2.033698081970215
Validation loss: 1.9546212586023475

Epoch: 6| Step: 4
Training loss: 1.9062004089355469
Validation loss: 1.9548031976146083

Epoch: 6| Step: 5
Training loss: 1.8160576820373535
Validation loss: 1.9983856857463878

Epoch: 6| Step: 6
Training loss: 1.7547472715377808
Validation loss: 2.0062193344998103

Epoch: 6| Step: 7
Training loss: 1.5302190780639648
Validation loss: 2.010759094709991

Epoch: 6| Step: 8
Training loss: 1.6345834732055664
Validation loss: 2.013503602755967

Epoch: 6| Step: 9
Training loss: 1.8498904705047607
Validation loss: 2.0430139777480916

Epoch: 6| Step: 10
Training loss: 1.7568423748016357
Validation loss: 2.0927056099778865

Epoch: 6| Step: 11
Training loss: 2.157585382461548
Validation loss: 2.117091317330637

Epoch: 6| Step: 12
Training loss: 1.6906239986419678
Validation loss: 2.1536873027842534

Epoch: 6| Step: 13
Training loss: 1.6680469512939453
Validation loss: 2.1559676278022026

Epoch: 183| Step: 0
Training loss: 1.6473324298858643
Validation loss: 2.1474294226656676

Epoch: 6| Step: 1
Training loss: 1.5813114643096924
Validation loss: 2.1632675445207985

Epoch: 6| Step: 2
Training loss: 1.39274001121521
Validation loss: 2.183259869134554

Epoch: 6| Step: 3
Training loss: 2.070798397064209
Validation loss: 2.2467717996207615

Epoch: 6| Step: 4
Training loss: 1.8834235668182373
Validation loss: 2.2081304416861585

Epoch: 6| Step: 5
Training loss: 2.4592392444610596
Validation loss: 2.180298838564145

Epoch: 6| Step: 6
Training loss: 1.3028308153152466
Validation loss: 2.117600416624418

Epoch: 6| Step: 7
Training loss: 1.110440731048584
Validation loss: 2.10602964380736

Epoch: 6| Step: 8
Training loss: 1.3013415336608887
Validation loss: 2.0475461175364833

Epoch: 6| Step: 9
Training loss: 1.9459543228149414
Validation loss: 2.0373638368421987

Epoch: 6| Step: 10
Training loss: 1.3377881050109863
Validation loss: 2.0150035683826735

Epoch: 6| Step: 11
Training loss: 1.2327849864959717
Validation loss: 2.013008722694971

Epoch: 6| Step: 12
Training loss: 1.6041653156280518
Validation loss: 1.990501775536486

Epoch: 6| Step: 13
Training loss: 1.5786442756652832
Validation loss: 1.99071321692518

Epoch: 184| Step: 0
Training loss: 1.7507092952728271
Validation loss: 2.0083628021260744

Epoch: 6| Step: 1
Training loss: 1.7024569511413574
Validation loss: 2.0074418078186693

Epoch: 6| Step: 2
Training loss: 1.8747544288635254
Validation loss: 2.0252229193205475

Epoch: 6| Step: 3
Training loss: 1.8227399587631226
Validation loss: 2.060342069595091

Epoch: 6| Step: 4
Training loss: 1.3801910877227783
Validation loss: 2.0397085310310445

Epoch: 6| Step: 5
Training loss: 1.7416415214538574
Validation loss: 2.031781168394191

Epoch: 6| Step: 6
Training loss: 1.2246780395507812
Validation loss: 2.0198424631549465

Epoch: 6| Step: 7
Training loss: 1.8246052265167236
Validation loss: 2.062596139087472

Epoch: 6| Step: 8
Training loss: 1.29581880569458
Validation loss: 2.0861362975130797

Epoch: 6| Step: 9
Training loss: 1.838038444519043
Validation loss: 2.1453309469325568

Epoch: 6| Step: 10
Training loss: 1.953709363937378
Validation loss: 2.174142788815242

Epoch: 6| Step: 11
Training loss: 1.4237771034240723
Validation loss: 2.1392995670277584

Epoch: 6| Step: 12
Training loss: 1.2682085037231445
Validation loss: 2.109545430829448

Epoch: 6| Step: 13
Training loss: 1.6708918809890747
Validation loss: 2.091951157457085

Epoch: 185| Step: 0
Training loss: 1.7519981861114502
Validation loss: 2.0747930593388055

Epoch: 6| Step: 1
Training loss: 1.5020999908447266
Validation loss: 2.0417960536095405

Epoch: 6| Step: 2
Training loss: 1.7206859588623047
Validation loss: 2.014323269167254

Epoch: 6| Step: 3
Training loss: 1.5795913934707642
Validation loss: 1.9757123096014864

Epoch: 6| Step: 4
Training loss: 1.5196839570999146
Validation loss: 1.9830536534709315

Epoch: 6| Step: 5
Training loss: 1.6315586566925049
Validation loss: 1.9683767467416742

Epoch: 6| Step: 6
Training loss: 1.7444853782653809
Validation loss: 1.9584677757755402

Epoch: 6| Step: 7
Training loss: 1.6111538410186768
Validation loss: 1.9497160783378027

Epoch: 6| Step: 8
Training loss: 1.279911756515503
Validation loss: 1.9567143840174521

Epoch: 6| Step: 9
Training loss: 1.9179192781448364
Validation loss: 1.9673785099419214

Epoch: 6| Step: 10
Training loss: 1.82997727394104
Validation loss: 1.9668697721214705

Epoch: 6| Step: 11
Training loss: 1.3536607027053833
Validation loss: 1.9761100225551154

Epoch: 6| Step: 12
Training loss: 1.3088990449905396
Validation loss: 2.00404195631704

Epoch: 6| Step: 13
Training loss: 1.7973295450210571
Validation loss: 2.0156053176490207

Epoch: 186| Step: 0
Training loss: 1.1940780878067017
Validation loss: 2.059529373722692

Epoch: 6| Step: 1
Training loss: 1.264909029006958
Validation loss: 2.069670815621653

Epoch: 6| Step: 2
Training loss: 1.5162540674209595
Validation loss: 2.1170101447771956

Epoch: 6| Step: 3
Training loss: 1.4893664121627808
Validation loss: 2.147668074536067

Epoch: 6| Step: 4
Training loss: 1.296443223953247
Validation loss: 2.155345747547765

Epoch: 6| Step: 5
Training loss: 0.7077950239181519
Validation loss: 2.1450678251122914

Epoch: 6| Step: 6
Training loss: 1.950104832649231
Validation loss: 2.1446604779971543

Epoch: 6| Step: 7
Training loss: 1.98398756980896
Validation loss: 2.146455487897319

Epoch: 6| Step: 8
Training loss: 1.692441463470459
Validation loss: 2.148080543805194

Epoch: 6| Step: 9
Training loss: 2.0709524154663086
Validation loss: 2.1055940607542634

Epoch: 6| Step: 10
Training loss: 1.3238918781280518
Validation loss: 2.108175652001494

Epoch: 6| Step: 11
Training loss: 2.1383728981018066
Validation loss: 2.0996301276709444

Epoch: 6| Step: 12
Training loss: 1.8641891479492188
Validation loss: 2.0652374759797127

Epoch: 6| Step: 13
Training loss: 1.3944350481033325
Validation loss: 2.0271068490961546

Epoch: 187| Step: 0
Training loss: 1.498753309249878
Validation loss: 2.0005711765699488

Epoch: 6| Step: 1
Training loss: 1.3162405490875244
Validation loss: 2.008785778476346

Epoch: 6| Step: 2
Training loss: 1.7520681619644165
Validation loss: 2.0098220584213093

Epoch: 6| Step: 3
Training loss: 1.62166166305542
Validation loss: 2.0467667733469317

Epoch: 6| Step: 4
Training loss: 1.8806285858154297
Validation loss: 2.058869279840941

Epoch: 6| Step: 5
Training loss: 1.0676583051681519
Validation loss: 2.066641210227884

Epoch: 6| Step: 6
Training loss: 1.6168564558029175
Validation loss: 2.0095752157190794

Epoch: 6| Step: 7
Training loss: 1.7856768369674683
Validation loss: 1.999345507673038

Epoch: 6| Step: 8
Training loss: 1.266491413116455
Validation loss: 2.047265866751312

Epoch: 6| Step: 9
Training loss: 0.9346050024032593
Validation loss: 2.0660159369950652

Epoch: 6| Step: 10
Training loss: 1.6940721273422241
Validation loss: 2.0853154992544525

Epoch: 6| Step: 11
Training loss: 2.2492988109588623
Validation loss: 2.0941476706535584

Epoch: 6| Step: 12
Training loss: 1.829439401626587
Validation loss: 2.1219525132127988

Epoch: 6| Step: 13
Training loss: 1.3633418083190918
Validation loss: 2.0967717811625493

Epoch: 188| Step: 0
Training loss: 2.2694296836853027
Validation loss: 2.1264895546820854

Epoch: 6| Step: 1
Training loss: 1.109060287475586
Validation loss: 2.1254365341637724

Epoch: 6| Step: 2
Training loss: 1.2316315174102783
Validation loss: 2.1092023464941208

Epoch: 6| Step: 3
Training loss: 1.525031566619873
Validation loss: 2.1044439538832633

Epoch: 6| Step: 4
Training loss: 1.7303900718688965
Validation loss: 2.103118053046606

Epoch: 6| Step: 5
Training loss: 1.235640287399292
Validation loss: 2.080251237397553

Epoch: 6| Step: 6
Training loss: 1.6454086303710938
Validation loss: 2.050281455439906

Epoch: 6| Step: 7
Training loss: 1.63498854637146
Validation loss: 2.0791539915146364

Epoch: 6| Step: 8
Training loss: 1.3295649290084839
Validation loss: 2.082459636913833

Epoch: 6| Step: 9
Training loss: 1.9173269271850586
Validation loss: 2.105864897851021

Epoch: 6| Step: 10
Training loss: 1.4246747493743896
Validation loss: 2.11561865832216

Epoch: 6| Step: 11
Training loss: 1.19606351852417
Validation loss: 2.1190685251707673

Epoch: 6| Step: 12
Training loss: 1.2152307033538818
Validation loss: 2.085610954992233

Epoch: 6| Step: 13
Training loss: 2.3310413360595703
Validation loss: 2.138949107098323

Epoch: 189| Step: 0
Training loss: 1.8364497423171997
Validation loss: 2.1497881181778444

Epoch: 6| Step: 1
Training loss: 2.058675765991211
Validation loss: 2.13546690376856

Epoch: 6| Step: 2
Training loss: 1.5130517482757568
Validation loss: 2.1077394382928007

Epoch: 6| Step: 3
Training loss: 1.6196026802062988
Validation loss: 2.0926800517625708

Epoch: 6| Step: 4
Training loss: 1.6389174461364746
Validation loss: 2.086276420982935

Epoch: 6| Step: 5
Training loss: 1.7440868616104126
Validation loss: 2.0886802442612185

Epoch: 6| Step: 6
Training loss: 1.1920511722564697
Validation loss: 2.070842246855459

Epoch: 6| Step: 7
Training loss: 1.4827861785888672
Validation loss: 2.05665692206352

Epoch: 6| Step: 8
Training loss: 1.236362099647522
Validation loss: 2.047893933070603

Epoch: 6| Step: 9
Training loss: 1.1596145629882812
Validation loss: 2.065663372316668

Epoch: 6| Step: 10
Training loss: 1.879733681678772
Validation loss: 2.1067140589478197

Epoch: 6| Step: 11
Training loss: 1.3665845394134521
Validation loss: 2.127627650896708

Epoch: 6| Step: 12
Training loss: 1.0748658180236816
Validation loss: 2.150954782321889

Epoch: 6| Step: 13
Training loss: 1.3360223770141602
Validation loss: 2.1556119765004804

Epoch: 190| Step: 0
Training loss: 1.2062814235687256
Validation loss: 2.1468961649043585

Epoch: 6| Step: 1
Training loss: 2.0150718688964844
Validation loss: 2.1739475419444423

Epoch: 6| Step: 2
Training loss: 1.594811201095581
Validation loss: 2.158432924619285

Epoch: 6| Step: 3
Training loss: 2.2406673431396484
Validation loss: 2.1340728267546623

Epoch: 6| Step: 4
Training loss: 1.4431066513061523
Validation loss: 2.114903585885161

Epoch: 6| Step: 5
Training loss: 0.7315899729728699
Validation loss: 2.100584924861949

Epoch: 6| Step: 6
Training loss: 1.7071201801300049
Validation loss: 2.0900806444947437

Epoch: 6| Step: 7
Training loss: 1.4999971389770508
Validation loss: 2.081354466817712

Epoch: 6| Step: 8
Training loss: 0.9419236779212952
Validation loss: 2.0199283079434465

Epoch: 6| Step: 9
Training loss: 1.5249059200286865
Validation loss: 2.0095728187150854

Epoch: 6| Step: 10
Training loss: 2.121877908706665
Validation loss: 1.9979114135106404

Epoch: 6| Step: 11
Training loss: 1.0792889595031738
Validation loss: 1.982375971732601

Epoch: 6| Step: 12
Training loss: 1.5486090183258057
Validation loss: 2.018596495351484

Epoch: 6| Step: 13
Training loss: 1.170143485069275
Validation loss: 2.0033218732444187

Epoch: 191| Step: 0
Training loss: 1.1805896759033203
Validation loss: 1.9958338634942168

Epoch: 6| Step: 1
Training loss: 1.8129849433898926
Validation loss: 2.049437939479787

Epoch: 6| Step: 2
Training loss: 1.9426039457321167
Validation loss: 2.066619642319218

Epoch: 6| Step: 3
Training loss: 1.5141284465789795
Validation loss: 2.0893931491400606

Epoch: 6| Step: 4
Training loss: 1.4594008922576904
Validation loss: 2.1183268716258388

Epoch: 6| Step: 5
Training loss: 1.5766944885253906
Validation loss: 2.1527900298436484

Epoch: 6| Step: 6
Training loss: 1.3803950548171997
Validation loss: 2.181678682245234

Epoch: 6| Step: 7
Training loss: 1.5275664329528809
Validation loss: 2.1526736162042104

Epoch: 6| Step: 8
Training loss: 1.8633251190185547
Validation loss: 2.135614771996775

Epoch: 6| Step: 9
Training loss: 0.9984813332557678
Validation loss: 2.1002039319725445

Epoch: 6| Step: 10
Training loss: 1.4070149660110474
Validation loss: 2.0967765072340607

Epoch: 6| Step: 11
Training loss: 1.881151556968689
Validation loss: 2.092018251777977

Epoch: 6| Step: 12
Training loss: 1.0556857585906982
Validation loss: 2.0487632725828435

Epoch: 6| Step: 13
Training loss: 1.3967067003250122
Validation loss: 2.0184625323100756

Epoch: 192| Step: 0
Training loss: 1.0360743999481201
Validation loss: 2.0311975863672074

Epoch: 6| Step: 1
Training loss: 1.3508063554763794
Validation loss: 2.0332818672221196

Epoch: 6| Step: 2
Training loss: 1.497025489807129
Validation loss: 2.0815628754195346

Epoch: 6| Step: 3
Training loss: 1.3890552520751953
Validation loss: 2.1237454773277364

Epoch: 6| Step: 4
Training loss: 1.7757856845855713
Validation loss: 2.1529403027667793

Epoch: 6| Step: 5
Training loss: 1.0691713094711304
Validation loss: 2.1763500577660015

Epoch: 6| Step: 6
Training loss: 1.507812738418579
Validation loss: 2.1663631239245014

Epoch: 6| Step: 7
Training loss: 1.3245792388916016
Validation loss: 2.1762343119549494

Epoch: 6| Step: 8
Training loss: 1.6436786651611328
Validation loss: 2.2661321342632337

Epoch: 6| Step: 9
Training loss: 1.3298943042755127
Validation loss: 2.3004764408193608

Epoch: 6| Step: 10
Training loss: 1.9301179647445679
Validation loss: 2.3030948074915076

Epoch: 6| Step: 11
Training loss: 2.068497896194458
Validation loss: 2.2423488119597077

Epoch: 6| Step: 12
Training loss: 1.8285224437713623
Validation loss: 2.1621484910288165

Epoch: 6| Step: 13
Training loss: 1.4428198337554932
Validation loss: 2.0848014226523777

Epoch: 193| Step: 0
Training loss: 1.521850347518921
Validation loss: 2.024380915908403

Epoch: 6| Step: 1
Training loss: 2.0487217903137207
Validation loss: 1.974408665011006

Epoch: 6| Step: 2
Training loss: 1.5255053043365479
Validation loss: 1.9696047844425324

Epoch: 6| Step: 3
Training loss: 1.4344937801361084
Validation loss: 1.9859224878331667

Epoch: 6| Step: 4
Training loss: 1.7043073177337646
Validation loss: 1.989898100976021

Epoch: 6| Step: 5
Training loss: 1.2461501359939575
Validation loss: 1.9936252665776077

Epoch: 6| Step: 6
Training loss: 2.306025743484497
Validation loss: 1.965444318709835

Epoch: 6| Step: 7
Training loss: 1.7824870347976685
Validation loss: 1.9371339608264226

Epoch: 6| Step: 8
Training loss: 1.643157958984375
Validation loss: 1.93403442957068

Epoch: 6| Step: 9
Training loss: 1.275010585784912
Validation loss: 1.9702936577540573

Epoch: 6| Step: 10
Training loss: 1.357581615447998
Validation loss: 2.024846233347411

Epoch: 6| Step: 11
Training loss: 1.0779739618301392
Validation loss: 2.0628654751726376

Epoch: 6| Step: 12
Training loss: 1.1895638704299927
Validation loss: 2.1068961569058

Epoch: 6| Step: 13
Training loss: 1.7094969749450684
Validation loss: 2.165316556089668

Epoch: 194| Step: 0
Training loss: 1.5380940437316895
Validation loss: 2.1386239810656478

Epoch: 6| Step: 1
Training loss: 1.048750638961792
Validation loss: 2.182756477786649

Epoch: 6| Step: 2
Training loss: 1.267033576965332
Validation loss: 2.153073908180319

Epoch: 6| Step: 3
Training loss: 1.5712491273880005
Validation loss: 2.1608678012765865

Epoch: 6| Step: 4
Training loss: 1.7730450630187988
Validation loss: 2.1509465761082147

Epoch: 6| Step: 5
Training loss: 1.2389416694641113
Validation loss: 2.140156074236798

Epoch: 6| Step: 6
Training loss: 1.7011792659759521
Validation loss: 2.0744422225541967

Epoch: 6| Step: 7
Training loss: 1.1715545654296875
Validation loss: 2.0168178158421672

Epoch: 6| Step: 8
Training loss: 1.3956944942474365
Validation loss: 2.013395424812071

Epoch: 6| Step: 9
Training loss: 1.5526673793792725
Validation loss: 1.9807609691414783

Epoch: 6| Step: 10
Training loss: 1.5497721433639526
Validation loss: 2.021750086097307

Epoch: 6| Step: 11
Training loss: 1.7940677404403687
Validation loss: 2.0314510048076673

Epoch: 6| Step: 12
Training loss: 1.9419004917144775
Validation loss: 2.034671296355545

Epoch: 6| Step: 13
Training loss: 1.1315534114837646
Validation loss: 1.990750200004988

Epoch: 195| Step: 0
Training loss: 1.6526011228561401
Validation loss: 1.9816076191522742

Epoch: 6| Step: 1
Training loss: 1.8791098594665527
Validation loss: 2.0229653209768315

Epoch: 6| Step: 2
Training loss: 0.9428979754447937
Validation loss: 2.0950892676589308

Epoch: 6| Step: 3
Training loss: 1.532216191291809
Validation loss: 2.156136416619824

Epoch: 6| Step: 4
Training loss: 1.6628224849700928
Validation loss: 2.1848635135158414

Epoch: 6| Step: 5
Training loss: 1.4961771965026855
Validation loss: 2.1862905897119993

Epoch: 6| Step: 6
Training loss: 1.2350525856018066
Validation loss: 2.138829137689324

Epoch: 6| Step: 7
Training loss: 1.12748384475708
Validation loss: 2.1258622805277505

Epoch: 6| Step: 8
Training loss: 2.3183908462524414
Validation loss: 2.0996880480038222

Epoch: 6| Step: 9
Training loss: 1.1765925884246826
Validation loss: 2.1132159438184512

Epoch: 6| Step: 10
Training loss: 0.8667464256286621
Validation loss: 2.1514584607975458

Epoch: 6| Step: 11
Training loss: 1.5188603401184082
Validation loss: 2.178555121985815

Epoch: 6| Step: 12
Training loss: 1.8200011253356934
Validation loss: 2.1542846054159184

Epoch: 6| Step: 13
Training loss: 1.4642107486724854
Validation loss: 2.1300191161453084

Epoch: 196| Step: 0
Training loss: 1.8063757419586182
Validation loss: 2.127233196330327

Epoch: 6| Step: 1
Training loss: 1.754057765007019
Validation loss: 2.1072530720823552

Epoch: 6| Step: 2
Training loss: 1.312718391418457
Validation loss: 2.079098073385095

Epoch: 6| Step: 3
Training loss: 1.3206905126571655
Validation loss: 2.0589567640776276

Epoch: 6| Step: 4
Training loss: 1.4386998414993286
Validation loss: 2.0614385348494335

Epoch: 6| Step: 5
Training loss: 1.32454514503479
Validation loss: 2.0596853943281275

Epoch: 6| Step: 6
Training loss: 1.8844759464263916
Validation loss: 2.0684303558000954

Epoch: 6| Step: 7
Training loss: 1.6170997619628906
Validation loss: 2.080833192794554

Epoch: 6| Step: 8
Training loss: 1.3600636720657349
Validation loss: 2.048651820869856

Epoch: 6| Step: 9
Training loss: 1.368880033493042
Validation loss: 1.999444427028779

Epoch: 6| Step: 10
Training loss: 1.4665765762329102
Validation loss: 1.986120758518096

Epoch: 6| Step: 11
Training loss: 0.9699561595916748
Validation loss: 1.9922574694438646

Epoch: 6| Step: 12
Training loss: 1.8351633548736572
Validation loss: 2.0286075274149575

Epoch: 6| Step: 13
Training loss: 0.7351720333099365
Validation loss: 2.061455957351192

Epoch: 197| Step: 0
Training loss: 2.0521240234375
Validation loss: 2.0706768317889144

Epoch: 6| Step: 1
Training loss: 1.7531492710113525
Validation loss: 2.0953383638012792

Epoch: 6| Step: 2
Training loss: 1.852060079574585
Validation loss: 2.0620810549746276

Epoch: 6| Step: 3
Training loss: 1.333432912826538
Validation loss: 2.0378584836118963

Epoch: 6| Step: 4
Training loss: 1.6211698055267334
Validation loss: 2.0300452734834407

Epoch: 6| Step: 5
Training loss: 1.7217016220092773
Validation loss: 2.0418299321205384

Epoch: 6| Step: 6
Training loss: 0.903059720993042
Validation loss: 2.057675637224669

Epoch: 6| Step: 7
Training loss: 1.3950036764144897
Validation loss: 2.0510263814721057

Epoch: 6| Step: 8
Training loss: 1.2789593935012817
Validation loss: 2.041377364948232

Epoch: 6| Step: 9
Training loss: 1.404471755027771
Validation loss: 2.053233051812777

Epoch: 6| Step: 10
Training loss: 1.724104881286621
Validation loss: 2.0628784484760736

Epoch: 6| Step: 11
Training loss: 1.0589144229888916
Validation loss: 2.0834248501767396

Epoch: 6| Step: 12
Training loss: 0.9131724238395691
Validation loss: 2.0703433047058764

Epoch: 6| Step: 13
Training loss: 1.1012861728668213
Validation loss: 2.098540098436417

Epoch: 198| Step: 0
Training loss: 2.013610363006592
Validation loss: 2.1403404076894126

Epoch: 6| Step: 1
Training loss: 1.3797633647918701
Validation loss: 2.167054037893972

Epoch: 6| Step: 2
Training loss: 1.4884896278381348
Validation loss: 2.1755226581327376

Epoch: 6| Step: 3
Training loss: 1.6406400203704834
Validation loss: 2.1419247145293863

Epoch: 6| Step: 4
Training loss: 1.5536909103393555
Validation loss: 2.1597177828511884

Epoch: 6| Step: 5
Training loss: 1.25675630569458
Validation loss: 2.1659820259258313

Epoch: 6| Step: 6
Training loss: 1.8264230489730835
Validation loss: 2.142045864494898

Epoch: 6| Step: 7
Training loss: 0.9855417609214783
Validation loss: 2.117475965971588

Epoch: 6| Step: 8
Training loss: 1.536407470703125
Validation loss: 2.100827793921194

Epoch: 6| Step: 9
Training loss: 1.6942943334579468
Validation loss: 2.086772113718012

Epoch: 6| Step: 10
Training loss: 1.2161712646484375
Validation loss: 2.0660098214303293

Epoch: 6| Step: 11
Training loss: 0.965481162071228
Validation loss: 2.0606516586836947

Epoch: 6| Step: 12
Training loss: 1.1870629787445068
Validation loss: 2.0727128828725507

Epoch: 6| Step: 13
Training loss: 0.7746127247810364
Validation loss: 2.055416804487987

Epoch: 199| Step: 0
Training loss: 1.3498454093933105
Validation loss: 1.9861568045872513

Epoch: 6| Step: 1
Training loss: 1.6766688823699951
Validation loss: 1.9822688102722168

Epoch: 6| Step: 2
Training loss: 1.7361252307891846
Validation loss: 1.9789901651361936

Epoch: 6| Step: 3
Training loss: 1.4472873210906982
Validation loss: 1.958074431265554

Epoch: 6| Step: 4
Training loss: 1.5126967430114746
Validation loss: 1.9829882896074684

Epoch: 6| Step: 5
Training loss: 1.3745027780532837
Validation loss: 2.0248169540077128

Epoch: 6| Step: 6
Training loss: 1.5638930797576904
Validation loss: 2.0746997364105715

Epoch: 6| Step: 7
Training loss: 0.8432145714759827
Validation loss: 2.085523654055852

Epoch: 6| Step: 8
Training loss: 1.0172278881072998
Validation loss: 2.118152186434756

Epoch: 6| Step: 9
Training loss: 1.60901939868927
Validation loss: 2.1439454196601786

Epoch: 6| Step: 10
Training loss: 1.0022132396697998
Validation loss: 2.1447190648765972

Epoch: 6| Step: 11
Training loss: 1.7435649633407593
Validation loss: 2.122183035778743

Epoch: 6| Step: 12
Training loss: 1.787339210510254
Validation loss: 2.103249067901283

Epoch: 6| Step: 13
Training loss: 1.1543699502944946
Validation loss: 2.101723829905192

Epoch: 200| Step: 0
Training loss: 1.303799033164978
Validation loss: 2.0597604872078024

Epoch: 6| Step: 1
Training loss: 0.9570480585098267
Validation loss: 2.093978138380153

Epoch: 6| Step: 2
Training loss: 1.196408748626709
Validation loss: 2.065617325485394

Epoch: 6| Step: 3
Training loss: 1.1484514474868774
Validation loss: 2.059084426972174

Epoch: 6| Step: 4
Training loss: 1.6120797395706177
Validation loss: 2.0617166462764946

Epoch: 6| Step: 5
Training loss: 0.9590746164321899
Validation loss: 2.0775810108389905

Epoch: 6| Step: 6
Training loss: 1.6560845375061035
Validation loss: 2.09921008540738

Epoch: 6| Step: 7
Training loss: 1.6046286821365356
Validation loss: 2.127723350319811

Epoch: 6| Step: 8
Training loss: 1.9129096269607544
Validation loss: 2.1063213809843986

Epoch: 6| Step: 9
Training loss: 1.0450786352157593
Validation loss: 2.111777379948606

Epoch: 6| Step: 10
Training loss: 1.884203314781189
Validation loss: 2.1181533413548626

Epoch: 6| Step: 11
Training loss: 1.1426101922988892
Validation loss: 2.12299761977247

Epoch: 6| Step: 12
Training loss: 1.7678313255310059
Validation loss: 2.1230279578957507

Epoch: 6| Step: 13
Training loss: 1.0587098598480225
Validation loss: 2.093935437099908

Epoch: 201| Step: 0
Training loss: 1.08757746219635
Validation loss: 2.1101545544080835

Epoch: 6| Step: 1
Training loss: 1.601524829864502
Validation loss: 2.122520057103967

Epoch: 6| Step: 2
Training loss: 1.4219073057174683
Validation loss: 2.1607673732183312

Epoch: 6| Step: 3
Training loss: 1.8258455991744995
Validation loss: 2.181705690199329

Epoch: 6| Step: 4
Training loss: 1.2380337715148926
Validation loss: 2.1832340776279406

Epoch: 6| Step: 5
Training loss: 1.2668583393096924
Validation loss: 2.1549500855066444

Epoch: 6| Step: 6
Training loss: 1.3366533517837524
Validation loss: 2.1408896753864903

Epoch: 6| Step: 7
Training loss: 1.5147477388381958
Validation loss: 2.148356976047639

Epoch: 6| Step: 8
Training loss: 1.6979820728302002
Validation loss: 2.1105424152907504

Epoch: 6| Step: 9
Training loss: 1.273515224456787
Validation loss: 2.0690240706166914

Epoch: 6| Step: 10
Training loss: 1.3376868963241577
Validation loss: 2.046642544449017

Epoch: 6| Step: 11
Training loss: 1.1103583574295044
Validation loss: 2.038677591149525

Epoch: 6| Step: 12
Training loss: 0.9398353099822998
Validation loss: 2.009309322603287

Epoch: 6| Step: 13
Training loss: 1.6218397617340088
Validation loss: 2.0970477775860856

Epoch: 202| Step: 0
Training loss: 1.1416027545928955
Validation loss: 2.1497383194585002

Epoch: 6| Step: 1
Training loss: 1.8369107246398926
Validation loss: 2.1962643643861175

Epoch: 6| Step: 2
Training loss: 1.3934801816940308
Validation loss: 2.203154371630761

Epoch: 6| Step: 3
Training loss: 1.1342628002166748
Validation loss: 2.213624664532241

Epoch: 6| Step: 4
Training loss: 1.506047248840332
Validation loss: 2.2064293635788785

Epoch: 6| Step: 5
Training loss: 1.9534146785736084
Validation loss: 2.180266930210975

Epoch: 6| Step: 6
Training loss: 1.1057777404785156
Validation loss: 2.152627524509225

Epoch: 6| Step: 7
Training loss: 1.1846647262573242
Validation loss: 2.0988406340281167

Epoch: 6| Step: 8
Training loss: 1.1267807483673096
Validation loss: 2.0927632983012865

Epoch: 6| Step: 9
Training loss: 1.0139446258544922
Validation loss: 2.024276371925108

Epoch: 6| Step: 10
Training loss: 1.8359624147415161
Validation loss: 2.0100012197289416

Epoch: 6| Step: 11
Training loss: 1.323228120803833
Validation loss: 2.027807991991761

Epoch: 6| Step: 12
Training loss: 0.7813133001327515
Validation loss: 2.0085814640086186

Epoch: 6| Step: 13
Training loss: 1.9706121683120728
Validation loss: 1.9997877228644587

Epoch: 203| Step: 0
Training loss: 1.4925057888031006
Validation loss: 2.0062498046505834

Epoch: 6| Step: 1
Training loss: 1.224196434020996
Validation loss: 2.0252598511275424

Epoch: 6| Step: 2
Training loss: 1.2893227338790894
Validation loss: 2.0390889285713114

Epoch: 6| Step: 3
Training loss: 1.0451843738555908
Validation loss: 2.080462162212659

Epoch: 6| Step: 4
Training loss: 1.1935049295425415
Validation loss: 2.075291633605957

Epoch: 6| Step: 5
Training loss: 1.4666478633880615
Validation loss: 2.1056729670493834

Epoch: 6| Step: 6
Training loss: 0.8201028108596802
Validation loss: 2.1556927183622956

Epoch: 6| Step: 7
Training loss: 2.20475172996521
Validation loss: 2.167926408911264

Epoch: 6| Step: 8
Training loss: 1.2387683391571045
Validation loss: 2.182624950203844

Epoch: 6| Step: 9
Training loss: 1.3394525051116943
Validation loss: 2.1722322561407603

Epoch: 6| Step: 10
Training loss: 1.5048158168792725
Validation loss: 2.1825505225889144

Epoch: 6| Step: 11
Training loss: 1.7237052917480469
Validation loss: 2.1586988049168743

Epoch: 6| Step: 12
Training loss: 1.0299164056777954
Validation loss: 2.1657960209795224

Epoch: 6| Step: 13
Training loss: 1.2187598943710327
Validation loss: 2.110026263421582

Epoch: 204| Step: 0
Training loss: 1.0844906568527222
Validation loss: 2.1108190333971413

Epoch: 6| Step: 1
Training loss: 0.8399243354797363
Validation loss: 2.123991104864305

Epoch: 6| Step: 2
Training loss: 1.1255888938903809
Validation loss: 2.1370997275075605

Epoch: 6| Step: 3
Training loss: 1.2767786979675293
Validation loss: 2.10482951389846

Epoch: 6| Step: 4
Training loss: 1.3646310567855835
Validation loss: 2.105282247707408

Epoch: 6| Step: 5
Training loss: 1.8031338453292847
Validation loss: 2.1156911760248165

Epoch: 6| Step: 6
Training loss: 1.3563774824142456
Validation loss: 2.1165513620581677

Epoch: 6| Step: 7
Training loss: 1.3798562288284302
Validation loss: 2.0924050628498034

Epoch: 6| Step: 8
Training loss: 1.440244436264038
Validation loss: 2.103629417316888

Epoch: 6| Step: 9
Training loss: 1.6993317604064941
Validation loss: 2.096877214729145

Epoch: 6| Step: 10
Training loss: 1.4572620391845703
Validation loss: 2.102157263345616

Epoch: 6| Step: 11
Training loss: 1.6555614471435547
Validation loss: 2.1168857671881236

Epoch: 6| Step: 12
Training loss: 1.4076778888702393
Validation loss: 2.1256464348044446

Epoch: 6| Step: 13
Training loss: 0.32777130603790283
Validation loss: 2.1191388586516022

Epoch: 205| Step: 0
Training loss: 1.3031675815582275
Validation loss: 2.1522983094697357

Epoch: 6| Step: 1
Training loss: 1.1815412044525146
Validation loss: 2.1332947848945536

Epoch: 6| Step: 2
Training loss: 1.2120131254196167
Validation loss: 2.127112386047199

Epoch: 6| Step: 3
Training loss: 1.1467691659927368
Validation loss: 2.111246109008789

Epoch: 6| Step: 4
Training loss: 2.0751290321350098
Validation loss: 2.130745060982243

Epoch: 6| Step: 5
Training loss: 1.716286063194275
Validation loss: 2.0848404245991863

Epoch: 6| Step: 6
Training loss: 0.6686214208602905
Validation loss: 2.050566209259854

Epoch: 6| Step: 7
Training loss: 2.0071797370910645
Validation loss: 2.055082723658572

Epoch: 6| Step: 8
Training loss: 1.2251183986663818
Validation loss: 2.0100006159915718

Epoch: 6| Step: 9
Training loss: 1.141040325164795
Validation loss: 2.0636155656588975

Epoch: 6| Step: 10
Training loss: 1.4575071334838867
Validation loss: 2.0713813202355498

Epoch: 6| Step: 11
Training loss: 1.2637150287628174
Validation loss: 2.0997188501460577

Epoch: 6| Step: 12
Training loss: 1.224603533744812
Validation loss: 2.0671175628580074

Epoch: 6| Step: 13
Training loss: 1.2175034284591675
Validation loss: 2.0554580842295

Epoch: 206| Step: 0
Training loss: 1.807437777519226
Validation loss: 2.101192469237953

Epoch: 6| Step: 1
Training loss: 1.338049054145813
Validation loss: 2.126721136031612

Epoch: 6| Step: 2
Training loss: 1.6372947692871094
Validation loss: 2.154656525581114

Epoch: 6| Step: 3
Training loss: 1.1240321397781372
Validation loss: 2.2013085542186612

Epoch: 6| Step: 4
Training loss: 1.5542197227478027
Validation loss: 2.1955181578154206

Epoch: 6| Step: 5
Training loss: 1.126814842224121
Validation loss: 2.173099074312436

Epoch: 6| Step: 6
Training loss: 0.8473793864250183
Validation loss: 2.1144099620080765

Epoch: 6| Step: 7
Training loss: 1.9786320924758911
Validation loss: 2.0780843252776773

Epoch: 6| Step: 8
Training loss: 1.6423578262329102
Validation loss: 2.080950924145278

Epoch: 6| Step: 9
Training loss: 1.4649360179901123
Validation loss: 2.0909172206796627

Epoch: 6| Step: 10
Training loss: 0.9444506764411926
Validation loss: 2.1492837603374193

Epoch: 6| Step: 11
Training loss: 0.7542984485626221
Validation loss: 2.1692273757791005

Epoch: 6| Step: 12
Training loss: 0.9448202252388
Validation loss: 2.192581284430719

Epoch: 6| Step: 13
Training loss: 1.526624083518982
Validation loss: 2.2336120092740623

Epoch: 207| Step: 0
Training loss: 0.9182807207107544
Validation loss: 2.2741380301854943

Epoch: 6| Step: 1
Training loss: 1.7330260276794434
Validation loss: 2.2538457262900566

Epoch: 6| Step: 2
Training loss: 1.6531213521957397
Validation loss: 2.284990026104835

Epoch: 6| Step: 3
Training loss: 1.3367063999176025
Validation loss: 2.2009594850642706

Epoch: 6| Step: 4
Training loss: 1.9970020055770874
Validation loss: 2.186833809780818

Epoch: 6| Step: 5
Training loss: 1.7160229682922363
Validation loss: 2.153652047598234

Epoch: 6| Step: 6
Training loss: 0.739088773727417
Validation loss: 2.1155581141030915

Epoch: 6| Step: 7
Training loss: 1.3852248191833496
Validation loss: 2.08070695272056

Epoch: 6| Step: 8
Training loss: 1.5777990818023682
Validation loss: 2.0508966292104414

Epoch: 6| Step: 9
Training loss: 1.2026762962341309
Validation loss: 2.005871912484528

Epoch: 6| Step: 10
Training loss: 0.7331123352050781
Validation loss: 2.0193774623255574

Epoch: 6| Step: 11
Training loss: 1.262878656387329
Validation loss: 2.048706252087829

Epoch: 6| Step: 12
Training loss: 1.4221796989440918
Validation loss: 2.093945227643495

Epoch: 6| Step: 13
Training loss: 0.8268442153930664
Validation loss: 2.0890967025551745

Epoch: 208| Step: 0
Training loss: 1.6572976112365723
Validation loss: 2.1356070272384153

Epoch: 6| Step: 1
Training loss: 0.7841849327087402
Validation loss: 2.1312755000206733

Epoch: 6| Step: 2
Training loss: 1.549952507019043
Validation loss: 2.1291382056410595

Epoch: 6| Step: 3
Training loss: 1.5668014287948608
Validation loss: 2.1325636281762073

Epoch: 6| Step: 4
Training loss: 1.0675444602966309
Validation loss: 2.0967754574232202

Epoch: 6| Step: 5
Training loss: 1.3054559230804443
Validation loss: 2.10887808569016

Epoch: 6| Step: 6
Training loss: 1.7791459560394287
Validation loss: 2.109758891085143

Epoch: 6| Step: 7
Training loss: 0.7118964195251465
Validation loss: 2.118252541429253

Epoch: 6| Step: 8
Training loss: 1.3032543659210205
Validation loss: 2.1293881964939896

Epoch: 6| Step: 9
Training loss: 1.0885810852050781
Validation loss: 2.1298645004149406

Epoch: 6| Step: 10
Training loss: 1.3000686168670654
Validation loss: 2.093071694015175

Epoch: 6| Step: 11
Training loss: 0.9763742685317993
Validation loss: 2.0993528724998556

Epoch: 6| Step: 12
Training loss: 1.540783166885376
Validation loss: 2.0277551733037478

Epoch: 6| Step: 13
Training loss: 1.0755594968795776
Validation loss: 1.9807110050673127

Epoch: 209| Step: 0
Training loss: 1.5316331386566162
Validation loss: 1.9854333862181632

Epoch: 6| Step: 1
Training loss: 0.8760663270950317
Validation loss: 1.9578175326829315

Epoch: 6| Step: 2
Training loss: 1.47308349609375
Validation loss: 1.9928900759707215

Epoch: 6| Step: 3
Training loss: 1.8854362964630127
Validation loss: 2.0019858780727593

Epoch: 6| Step: 4
Training loss: 1.0442578792572021
Validation loss: 2.01282988825152

Epoch: 6| Step: 5
Training loss: 1.1025454998016357
Validation loss: 2.0083166899219638

Epoch: 6| Step: 6
Training loss: 1.5119297504425049
Validation loss: 2.016095843366397

Epoch: 6| Step: 7
Training loss: 1.5474883317947388
Validation loss: 2.052711861107939

Epoch: 6| Step: 8
Training loss: 1.0612542629241943
Validation loss: 2.0735379624110397

Epoch: 6| Step: 9
Training loss: 1.2760567665100098
Validation loss: 2.1215984488046296

Epoch: 6| Step: 10
Training loss: 1.106305480003357
Validation loss: 2.1569755372180732

Epoch: 6| Step: 11
Training loss: 1.6214780807495117
Validation loss: 2.1235835577851985

Epoch: 6| Step: 12
Training loss: 0.977175772190094
Validation loss: 2.066132558289395

Epoch: 6| Step: 13
Training loss: 0.9807609915733337
Validation loss: 2.0188907231054

Epoch: 210| Step: 0
Training loss: 1.8946465253829956
Validation loss: 2.063161209065427

Epoch: 6| Step: 1
Training loss: 1.6624228954315186
Validation loss: 2.101287728996687

Epoch: 6| Step: 2
Training loss: 1.4465837478637695
Validation loss: 2.1401370443323606

Epoch: 6| Step: 3
Training loss: 1.0337433815002441
Validation loss: 2.1522084743745866

Epoch: 6| Step: 4
Training loss: 1.0612609386444092
Validation loss: 2.1929468544580604

Epoch: 6| Step: 5
Training loss: 0.7345508337020874
Validation loss: 2.1539911813633417

Epoch: 6| Step: 6
Training loss: 1.5010074377059937
Validation loss: 2.1925057006138626

Epoch: 6| Step: 7
Training loss: 1.3846415281295776
Validation loss: 2.1628953538915163

Epoch: 6| Step: 8
Training loss: 0.7786554098129272
Validation loss: 2.0965473292976298

Epoch: 6| Step: 9
Training loss: 1.3434828519821167
Validation loss: 2.1009305805288334

Epoch: 6| Step: 10
Training loss: 0.900294840335846
Validation loss: 2.0419805434442337

Epoch: 6| Step: 11
Training loss: 1.26710844039917
Validation loss: 2.0108323238229238

Epoch: 6| Step: 12
Training loss: 0.9193400144577026
Validation loss: 2.0070992362114692

Epoch: 6| Step: 13
Training loss: 2.6088476181030273
Validation loss: 2.0098310837181668

Epoch: 211| Step: 0
Training loss: 0.8702919483184814
Validation loss: 2.0163904172117992

Epoch: 6| Step: 1
Training loss: 1.1368274688720703
Validation loss: 2.020060504636457

Epoch: 6| Step: 2
Training loss: 1.2448806762695312
Validation loss: 2.038107038826071

Epoch: 6| Step: 3
Training loss: 1.370250940322876
Validation loss: 2.037167964443084

Epoch: 6| Step: 4
Training loss: 0.9870610237121582
Validation loss: 2.0521659799801406

Epoch: 6| Step: 5
Training loss: 1.1297426223754883
Validation loss: 2.061602568113676

Epoch: 6| Step: 6
Training loss: 0.9079781770706177
Validation loss: 2.0817011402499292

Epoch: 6| Step: 7
Training loss: 1.1332247257232666
Validation loss: 2.0660389149060814

Epoch: 6| Step: 8
Training loss: 0.9387016892433167
Validation loss: 2.0076313364890312

Epoch: 6| Step: 9
Training loss: 2.0032362937927246
Validation loss: 1.998436204848751

Epoch: 6| Step: 10
Training loss: 1.1054744720458984
Validation loss: 1.9846390716491207

Epoch: 6| Step: 11
Training loss: 1.8174117803573608
Validation loss: 1.9582950235694967

Epoch: 6| Step: 12
Training loss: 1.3894226551055908
Validation loss: 1.9525159405123802

Epoch: 6| Step: 13
Training loss: 0.7117828726768494
Validation loss: 1.9985601209825086

Epoch: 212| Step: 0
Training loss: 0.5853230953216553
Validation loss: 2.0069613815635763

Epoch: 6| Step: 1
Training loss: 1.1418321132659912
Validation loss: 2.0297975104342223

Epoch: 6| Step: 2
Training loss: 1.1580455303192139
Validation loss: 2.0586744469981038

Epoch: 6| Step: 3
Training loss: 1.1854734420776367
Validation loss: 2.0850027171514367

Epoch: 6| Step: 4
Training loss: 1.5382661819458008
Validation loss: 2.125776457530196

Epoch: 6| Step: 5
Training loss: 1.575575828552246
Validation loss: 2.1679650737393286

Epoch: 6| Step: 6
Training loss: 1.1091574430465698
Validation loss: 2.1843815567672893

Epoch: 6| Step: 7
Training loss: 2.0525007247924805
Validation loss: 2.212744197537822

Epoch: 6| Step: 8
Training loss: 1.0783947706222534
Validation loss: 2.117835779343882

Epoch: 6| Step: 9
Training loss: 1.0986511707305908
Validation loss: 2.066591203853648

Epoch: 6| Step: 10
Training loss: 1.183302879333496
Validation loss: 2.0257928486793273

Epoch: 6| Step: 11
Training loss: 1.3211145401000977
Validation loss: 2.0041213599584435

Epoch: 6| Step: 12
Training loss: 1.4514515399932861
Validation loss: 2.011834490683771

Epoch: 6| Step: 13
Training loss: 0.9352336525917053
Validation loss: 1.9953207149300525

Epoch: 213| Step: 0
Training loss: 0.5926883220672607
Validation loss: 1.9978806049593034

Epoch: 6| Step: 1
Training loss: 1.3527073860168457
Validation loss: 2.0495852783162105

Epoch: 6| Step: 2
Training loss: 1.1175451278686523
Validation loss: 2.1145766986313688

Epoch: 6| Step: 3
Training loss: 1.4819066524505615
Validation loss: 2.1441825641098844

Epoch: 6| Step: 4
Training loss: 1.269547700881958
Validation loss: 2.1597940511600946

Epoch: 6| Step: 5
Training loss: 1.2686290740966797
Validation loss: 2.191556930541992

Epoch: 6| Step: 6
Training loss: 1.2264060974121094
Validation loss: 2.192058858051095

Epoch: 6| Step: 7
Training loss: 0.8933256268501282
Validation loss: 2.2221199145881076

Epoch: 6| Step: 8
Training loss: 1.2361892461776733
Validation loss: 2.189877284470425

Epoch: 6| Step: 9
Training loss: 1.346109390258789
Validation loss: 2.1448180496051745

Epoch: 6| Step: 10
Training loss: 1.0318766832351685
Validation loss: 2.1069836501152284

Epoch: 6| Step: 11
Training loss: 1.4148319959640503
Validation loss: 2.124688761208647

Epoch: 6| Step: 12
Training loss: 1.4862678050994873
Validation loss: 2.0929648312189246

Epoch: 6| Step: 13
Training loss: 1.5832892656326294
Validation loss: 2.0554710767602407

Epoch: 214| Step: 0
Training loss: 1.5419776439666748
Validation loss: 2.002359741477556

Epoch: 6| Step: 1
Training loss: 1.4108728170394897
Validation loss: 1.9777670150162072

Epoch: 6| Step: 2
Training loss: 1.1625549793243408
Validation loss: 1.917097016047406

Epoch: 6| Step: 3
Training loss: 1.0344910621643066
Validation loss: 1.9137835643624748

Epoch: 6| Step: 4
Training loss: 1.7356860637664795
Validation loss: 1.914946299727245

Epoch: 6| Step: 5
Training loss: 0.9745984077453613
Validation loss: 1.9377752747586978

Epoch: 6| Step: 6
Training loss: 0.8890916705131531
Validation loss: 1.9691973040180821

Epoch: 6| Step: 7
Training loss: 0.939836859703064
Validation loss: 1.9977081334719093

Epoch: 6| Step: 8
Training loss: 1.1636202335357666
Validation loss: 2.0260632115025676

Epoch: 6| Step: 9
Training loss: 1.0495555400848389
Validation loss: 2.0502388938780753

Epoch: 6| Step: 10
Training loss: 1.113128900527954
Validation loss: 2.117543767857295

Epoch: 6| Step: 11
Training loss: 1.5493526458740234
Validation loss: 2.144658721903319

Epoch: 6| Step: 12
Training loss: 1.1798474788665771
Validation loss: 2.139071786275474

Epoch: 6| Step: 13
Training loss: 1.065736174583435
Validation loss: 2.124870720730033

Epoch: 215| Step: 0
Training loss: 0.8592082262039185
Validation loss: 2.147413670375783

Epoch: 6| Step: 1
Training loss: 1.055323839187622
Validation loss: 2.1454601313478205

Epoch: 6| Step: 2
Training loss: 1.012158751487732
Validation loss: 2.1334899881834626

Epoch: 6| Step: 3
Training loss: 1.6603670120239258
Validation loss: 2.118037759616811

Epoch: 6| Step: 4
Training loss: 1.2477686405181885
Validation loss: 2.100699632398544

Epoch: 6| Step: 5
Training loss: 1.2822132110595703
Validation loss: 2.083753763988454

Epoch: 6| Step: 6
Training loss: 1.2420756816864014
Validation loss: 2.0358418674879175

Epoch: 6| Step: 7
Training loss: 0.9434553980827332
Validation loss: 2.019419490650136

Epoch: 6| Step: 8
Training loss: 1.1933051347732544
Validation loss: 1.982115968581169

Epoch: 6| Step: 9
Training loss: 0.9589781165122986
Validation loss: 1.9776081474878455

Epoch: 6| Step: 10
Training loss: 1.0408790111541748
Validation loss: 1.955886907474969

Epoch: 6| Step: 11
Training loss: 1.1653095483779907
Validation loss: 1.96176823236609

Epoch: 6| Step: 12
Training loss: 1.7486305236816406
Validation loss: 1.970492434758012

Epoch: 6| Step: 13
Training loss: 0.7689266204833984
Validation loss: 2.0333138127480783

Epoch: 216| Step: 0
Training loss: 1.452528953552246
Validation loss: 2.0513700067356067

Epoch: 6| Step: 1
Training loss: 0.930199384689331
Validation loss: 2.1001677051667245

Epoch: 6| Step: 2
Training loss: 1.4475985765457153
Validation loss: 2.1476505674341673

Epoch: 6| Step: 3
Training loss: 0.5298939943313599
Validation loss: 2.154427364308347

Epoch: 6| Step: 4
Training loss: 1.1904749870300293
Validation loss: 2.1413638155947448

Epoch: 6| Step: 5
Training loss: 1.182530403137207
Validation loss: 2.0975363844184467

Epoch: 6| Step: 6
Training loss: 1.5609197616577148
Validation loss: 2.061242490686396

Epoch: 6| Step: 7
Training loss: 1.7006263732910156
Validation loss: 2.041246365475398

Epoch: 6| Step: 8
Training loss: 1.2421073913574219
Validation loss: 2.042618182397658

Epoch: 6| Step: 9
Training loss: 0.8055766820907593
Validation loss: 2.035407461145873

Epoch: 6| Step: 10
Training loss: 0.6817502975463867
Validation loss: 2.0168545669124973

Epoch: 6| Step: 11
Training loss: 1.0240657329559326
Validation loss: 2.045332867612121

Epoch: 6| Step: 12
Training loss: 1.283881664276123
Validation loss: 2.00666541822495

Epoch: 6| Step: 13
Training loss: 0.9753242135047913
Validation loss: 2.0133561934194257

Epoch: 217| Step: 0
Training loss: 1.039305329322815
Validation loss: 2.0353275140126548

Epoch: 6| Step: 1
Training loss: 0.8826982975006104
Validation loss: 2.064501030470735

Epoch: 6| Step: 2
Training loss: 1.0004266500473022
Validation loss: 2.087997623669204

Epoch: 6| Step: 3
Training loss: 0.8669954538345337
Validation loss: 2.0873284288631972

Epoch: 6| Step: 4
Training loss: 1.1675755977630615
Validation loss: 2.088032771182317

Epoch: 6| Step: 5
Training loss: 0.9725356101989746
Validation loss: 2.070257968800042

Epoch: 6| Step: 6
Training loss: 1.3921020030975342
Validation loss: 2.0321967178775417

Epoch: 6| Step: 7
Training loss: 1.4453425407409668
Validation loss: 2.042752297975684

Epoch: 6| Step: 8
Training loss: 1.5310776233673096
Validation loss: 2.0495293524957474

Epoch: 6| Step: 9
Training loss: 0.8462418913841248
Validation loss: 2.0444376186657975

Epoch: 6| Step: 10
Training loss: 1.195997953414917
Validation loss: 2.035988059095157

Epoch: 6| Step: 11
Training loss: 1.29288649559021
Validation loss: 2.0267273200455533

Epoch: 6| Step: 12
Training loss: 1.069839358329773
Validation loss: 2.0870543320973716

Epoch: 6| Step: 13
Training loss: 0.9703614711761475
Validation loss: 2.1006682880463137

Epoch: 218| Step: 0
Training loss: 1.4943079948425293
Validation loss: 2.1746404709354525

Epoch: 6| Step: 1
Training loss: 0.9544610381126404
Validation loss: 2.2010033412646224

Epoch: 6| Step: 2
Training loss: 1.8855552673339844
Validation loss: 2.195614460975893

Epoch: 6| Step: 3
Training loss: 1.2154872417449951
Validation loss: 2.1542264517917427

Epoch: 6| Step: 4
Training loss: 0.6322274208068848
Validation loss: 2.1089497150913363

Epoch: 6| Step: 5
Training loss: 0.7930407524108887
Validation loss: 2.0341852531638196

Epoch: 6| Step: 6
Training loss: 1.294334888458252
Validation loss: 2.000892077722857

Epoch: 6| Step: 7
Training loss: 0.8994746804237366
Validation loss: 1.997543001687655

Epoch: 6| Step: 8
Training loss: 0.8914850354194641
Validation loss: 1.9824734554495862

Epoch: 6| Step: 9
Training loss: 1.1122634410858154
Validation loss: 1.942382102371544

Epoch: 6| Step: 10
Training loss: 1.300938606262207
Validation loss: 1.9439196407154042

Epoch: 6| Step: 11
Training loss: 1.49540376663208
Validation loss: 1.9557953560224144

Epoch: 6| Step: 12
Training loss: 0.9922845363616943
Validation loss: 1.9630672918852938

Epoch: 6| Step: 13
Training loss: 0.8742440342903137
Validation loss: 1.9938301065916657

Epoch: 219| Step: 0
Training loss: 0.890741765499115
Validation loss: 2.0424056565889748

Epoch: 6| Step: 1
Training loss: 1.1106481552124023
Validation loss: 2.1037850572216894

Epoch: 6| Step: 2
Training loss: 0.941493034362793
Validation loss: 2.1346336564710064

Epoch: 6| Step: 3
Training loss: 1.1113168001174927
Validation loss: 2.1611818190543883

Epoch: 6| Step: 4
Training loss: 1.2116872072219849
Validation loss: 2.200213033665893

Epoch: 6| Step: 5
Training loss: 1.7731117010116577
Validation loss: 2.2549374641910678

Epoch: 6| Step: 6
Training loss: 1.168368935585022
Validation loss: 2.2165819111690728

Epoch: 6| Step: 7
Training loss: 1.3216031789779663
Validation loss: 2.159601883221698

Epoch: 6| Step: 8
Training loss: 0.9485825300216675
Validation loss: 2.1046505589638986

Epoch: 6| Step: 9
Training loss: 0.7267246246337891
Validation loss: 2.0402177046704035

Epoch: 6| Step: 10
Training loss: 1.326650619506836
Validation loss: 2.0163469109483945

Epoch: 6| Step: 11
Training loss: 1.141356348991394
Validation loss: 2.0177065659594793

Epoch: 6| Step: 12
Training loss: 1.1449886560440063
Validation loss: 2.0086341570782404

Epoch: 6| Step: 13
Training loss: 1.8958642482757568
Validation loss: 2.015056392197968

Epoch: 220| Step: 0
Training loss: 1.0662848949432373
Validation loss: 2.0038545388047413

Epoch: 6| Step: 1
Training loss: 1.6261601448059082
Validation loss: 2.0259974207929385

Epoch: 6| Step: 2
Training loss: 0.862118661403656
Validation loss: 1.9964595994641703

Epoch: 6| Step: 3
Training loss: 0.7818214297294617
Validation loss: 2.0375466244195097

Epoch: 6| Step: 4
Training loss: 1.1585137844085693
Validation loss: 2.0541311976730183

Epoch: 6| Step: 5
Training loss: 1.0871403217315674
Validation loss: 2.0577193075610745

Epoch: 6| Step: 6
Training loss: 0.9573009014129639
Validation loss: 2.09876742926977

Epoch: 6| Step: 7
Training loss: 1.0671672821044922
Validation loss: 2.098540343264098

Epoch: 6| Step: 8
Training loss: 1.103581190109253
Validation loss: 2.0853545845195813

Epoch: 6| Step: 9
Training loss: 1.6076586246490479
Validation loss: 2.1060577720724125

Epoch: 6| Step: 10
Training loss: 1.2299553155899048
Validation loss: 2.102166668061287

Epoch: 6| Step: 11
Training loss: 1.013857126235962
Validation loss: 2.139479831982684

Epoch: 6| Step: 12
Training loss: 0.7780821323394775
Validation loss: 2.1623463451221423

Epoch: 6| Step: 13
Training loss: 1.3684029579162598
Validation loss: 2.1360197605625277

Epoch: 221| Step: 0
Training loss: 1.1430995464324951
Validation loss: 2.1049760990245368

Epoch: 6| Step: 1
Training loss: 1.215502142906189
Validation loss: 2.0715181827545166

Epoch: 6| Step: 2
Training loss: 0.8930623531341553
Validation loss: 2.0505051587217595

Epoch: 6| Step: 3
Training loss: 1.0075401067733765
Validation loss: 2.021552097412848

Epoch: 6| Step: 4
Training loss: 0.8370888829231262
Validation loss: 1.9920134211099276

Epoch: 6| Step: 5
Training loss: 1.0223290920257568
Validation loss: 1.974573266121649

Epoch: 6| Step: 6
Training loss: 1.412520170211792
Validation loss: 1.9797799689795381

Epoch: 6| Step: 7
Training loss: 1.1222257614135742
Validation loss: 1.9994246908413467

Epoch: 6| Step: 8
Training loss: 0.9222813844680786
Validation loss: 2.010871402678951

Epoch: 6| Step: 9
Training loss: 0.664821445941925
Validation loss: 2.0139738744305027

Epoch: 6| Step: 10
Training loss: 1.1329562664031982
Validation loss: 2.0469853813930223

Epoch: 6| Step: 11
Training loss: 1.346139907836914
Validation loss: 2.0565138811706216

Epoch: 6| Step: 12
Training loss: 1.2917275428771973
Validation loss: 2.0529337083139727

Epoch: 6| Step: 13
Training loss: 1.1818275451660156
Validation loss: 2.0749808716517624

Epoch: 222| Step: 0
Training loss: 1.1008996963500977
Validation loss: 2.073321721887076

Epoch: 6| Step: 1
Training loss: 0.8367247581481934
Validation loss: 2.0624159843690935

Epoch: 6| Step: 2
Training loss: 1.1991996765136719
Validation loss: 2.091767567460255

Epoch: 6| Step: 3
Training loss: 0.4802723526954651
Validation loss: 2.1210556068728046

Epoch: 6| Step: 4
Training loss: 1.246558666229248
Validation loss: 2.149340452686433

Epoch: 6| Step: 5
Training loss: 1.5353147983551025
Validation loss: 2.1142371880110873

Epoch: 6| Step: 6
Training loss: 0.9056553244590759
Validation loss: 2.126790769638554

Epoch: 6| Step: 7
Training loss: 0.9117121696472168
Validation loss: 2.0841087602799937

Epoch: 6| Step: 8
Training loss: 1.0221842527389526
Validation loss: 2.0792280192016275

Epoch: 6| Step: 9
Training loss: 1.721696376800537
Validation loss: 2.0683584443984495

Epoch: 6| Step: 10
Training loss: 1.2843730449676514
Validation loss: 2.023983088872766

Epoch: 6| Step: 11
Training loss: 1.1365301609039307
Validation loss: 1.9710949326074252

Epoch: 6| Step: 12
Training loss: 0.5822535753250122
Validation loss: 1.9732550382614136

Epoch: 6| Step: 13
Training loss: 1.0316576957702637
Validation loss: 1.964330844981696

Epoch: 223| Step: 0
Training loss: 1.0182493925094604
Validation loss: 1.9534245793537428

Epoch: 6| Step: 1
Training loss: 0.8907842040061951
Validation loss: 2.0513183493768015

Epoch: 6| Step: 2
Training loss: 0.6669532060623169
Validation loss: 2.099570590962646

Epoch: 6| Step: 3
Training loss: 1.4462060928344727
Validation loss: 2.1356646527526197

Epoch: 6| Step: 4
Training loss: 1.215431809425354
Validation loss: 2.1434863767316266

Epoch: 6| Step: 5
Training loss: 1.266723871231079
Validation loss: 2.1454447546312885

Epoch: 6| Step: 6
Training loss: 0.8542578816413879
Validation loss: 2.074450300585839

Epoch: 6| Step: 7
Training loss: 0.942534327507019
Validation loss: 1.9845521411588114

Epoch: 6| Step: 8
Training loss: 1.2518665790557861
Validation loss: 1.986374411531674

Epoch: 6| Step: 9
Training loss: 0.9106414318084717
Validation loss: 1.9707395774061962

Epoch: 6| Step: 10
Training loss: 1.8220174312591553
Validation loss: 1.9600581686983827

Epoch: 6| Step: 11
Training loss: 0.8688364028930664
Validation loss: 1.9785533464083107

Epoch: 6| Step: 12
Training loss: 0.9106326103210449
Validation loss: 1.982003378611739

Epoch: 6| Step: 13
Training loss: 0.8426631093025208
Validation loss: 1.9942816534349996

Epoch: 224| Step: 0
Training loss: 0.9301955699920654
Validation loss: 2.0377858556726927

Epoch: 6| Step: 1
Training loss: 1.5376489162445068
Validation loss: 2.0924485011767318

Epoch: 6| Step: 2
Training loss: 1.081412672996521
Validation loss: 2.1447177612653343

Epoch: 6| Step: 3
Training loss: 1.3239741325378418
Validation loss: 2.131028985464445

Epoch: 6| Step: 4
Training loss: 0.916821300983429
Validation loss: 2.1669326982190533

Epoch: 6| Step: 5
Training loss: 0.6625056266784668
Validation loss: 2.2099934175450313

Epoch: 6| Step: 6
Training loss: 1.0986229181289673
Validation loss: 2.1996280583002235

Epoch: 6| Step: 7
Training loss: 1.1616536378860474
Validation loss: 2.222720848616733

Epoch: 6| Step: 8
Training loss: 0.889969527721405
Validation loss: 2.2053682317015944

Epoch: 6| Step: 9
Training loss: 0.8513557314872742
Validation loss: 2.1525226716072328

Epoch: 6| Step: 10
Training loss: 1.7349307537078857
Validation loss: 2.107918938000997

Epoch: 6| Step: 11
Training loss: 0.9430109262466431
Validation loss: 2.0481329746143793

Epoch: 6| Step: 12
Training loss: 0.7826027870178223
Validation loss: 2.0348858628221738

Epoch: 6| Step: 13
Training loss: 0.8650608062744141
Validation loss: 1.9870578935069423

Epoch: 225| Step: 0
Training loss: 0.8890380263328552
Validation loss: 1.9531637340463617

Epoch: 6| Step: 1
Training loss: 1.2222862243652344
Validation loss: 2.0004439533397718

Epoch: 6| Step: 2
Training loss: 0.948442816734314
Validation loss: 1.9751656491269347

Epoch: 6| Step: 3
Training loss: 1.846867561340332
Validation loss: 1.9776368051446893

Epoch: 6| Step: 4
Training loss: 0.9287940859794617
Validation loss: 2.0374966257361957

Epoch: 6| Step: 5
Training loss: 0.9103640913963318
Validation loss: 2.0347981478578303

Epoch: 6| Step: 6
Training loss: 0.5506210327148438
Validation loss: 2.0786281836930143

Epoch: 6| Step: 7
Training loss: 0.7656536102294922
Validation loss: 2.134958715849025

Epoch: 6| Step: 8
Training loss: 1.0432136058807373
Validation loss: 2.130055735188146

Epoch: 6| Step: 9
Training loss: 1.0107786655426025
Validation loss: 2.1915878416389547

Epoch: 6| Step: 10
Training loss: 1.2884304523468018
Validation loss: 2.1970394042230423

Epoch: 6| Step: 11
Training loss: 1.3071162700653076
Validation loss: 2.190515011869451

Epoch: 6| Step: 12
Training loss: 1.1095845699310303
Validation loss: 2.252935773582869

Epoch: 6| Step: 13
Training loss: 1.2596933841705322
Validation loss: 2.163660574984807

Epoch: 226| Step: 0
Training loss: 0.8051222562789917
Validation loss: 2.039978195262212

Epoch: 6| Step: 1
Training loss: 1.017168641090393
Validation loss: 1.9321515765241397

Epoch: 6| Step: 2
Training loss: 0.930809736251831
Validation loss: 1.8780496530635382

Epoch: 6| Step: 3
Training loss: 1.1764044761657715
Validation loss: 1.8786768362086306

Epoch: 6| Step: 4
Training loss: 1.3043994903564453
Validation loss: 1.8729113526241754

Epoch: 6| Step: 5
Training loss: 1.8140945434570312
Validation loss: 1.833528975004791

Epoch: 6| Step: 6
Training loss: 0.8124538064002991
Validation loss: 1.8678673121236986

Epoch: 6| Step: 7
Training loss: 1.1352500915527344
Validation loss: 1.8436877753144951

Epoch: 6| Step: 8
Training loss: 1.3014805316925049
Validation loss: 1.874700084809334

Epoch: 6| Step: 9
Training loss: 1.2249305248260498
Validation loss: 1.9091327036580732

Epoch: 6| Step: 10
Training loss: 1.0229508876800537
Validation loss: 1.98513408758307

Epoch: 6| Step: 11
Training loss: 0.77513587474823
Validation loss: 2.037862636709726

Epoch: 6| Step: 12
Training loss: 1.0615700483322144
Validation loss: 2.089187965598158

Epoch: 6| Step: 13
Training loss: 1.1091053485870361
Validation loss: 2.167623495542875

Epoch: 227| Step: 0
Training loss: 1.0022685527801514
Validation loss: 2.238389251052692

Epoch: 6| Step: 1
Training loss: 0.7328668236732483
Validation loss: 2.2761280177741923

Epoch: 6| Step: 2
Training loss: 1.1629488468170166
Validation loss: 2.2643665652121268

Epoch: 6| Step: 3
Training loss: 1.0918362140655518
Validation loss: 2.242060246006135

Epoch: 6| Step: 4
Training loss: 1.2419222593307495
Validation loss: 2.229459911264399

Epoch: 6| Step: 5
Training loss: 1.2148442268371582
Validation loss: 2.158116184255128

Epoch: 6| Step: 6
Training loss: 1.15394127368927
Validation loss: 2.091031684670397

Epoch: 6| Step: 7
Training loss: 1.302802324295044
Validation loss: 2.061146434917245

Epoch: 6| Step: 8
Training loss: 0.9254499077796936
Validation loss: 2.002188887647403

Epoch: 6| Step: 9
Training loss: 0.6603308916091919
Validation loss: 1.977310711337674

Epoch: 6| Step: 10
Training loss: 1.1072347164154053
Validation loss: 1.9658125651779996

Epoch: 6| Step: 11
Training loss: 1.473758339881897
Validation loss: 1.977590867268142

Epoch: 6| Step: 12
Training loss: 1.2744569778442383
Validation loss: 1.9804462655898063

Epoch: 6| Step: 13
Training loss: 1.10814368724823
Validation loss: 1.986946467430361

Epoch: 228| Step: 0
Training loss: 0.9235627055168152
Validation loss: 2.007033368592621

Epoch: 6| Step: 1
Training loss: 0.7438592910766602
Validation loss: 2.053362223409837

Epoch: 6| Step: 2
Training loss: 0.7949906587600708
Validation loss: 2.113735488666001

Epoch: 6| Step: 3
Training loss: 1.0315748453140259
Validation loss: 2.1482424223294823

Epoch: 6| Step: 4
Training loss: 1.106640338897705
Validation loss: 2.170307377333282

Epoch: 6| Step: 5
Training loss: 1.3017066717147827
Validation loss: 2.169564806005006

Epoch: 6| Step: 6
Training loss: 1.1344966888427734
Validation loss: 2.159088994867058

Epoch: 6| Step: 7
Training loss: 1.087677001953125
Validation loss: 2.139916737874349

Epoch: 6| Step: 8
Training loss: 0.8198539018630981
Validation loss: 2.120141616431616

Epoch: 6| Step: 9
Training loss: 0.9653923511505127
Validation loss: 2.067326878988615

Epoch: 6| Step: 10
Training loss: 0.9758124947547913
Validation loss: 2.001038155248088

Epoch: 6| Step: 11
Training loss: 1.1705453395843506
Validation loss: 1.9964430550093293

Epoch: 6| Step: 12
Training loss: 1.3703148365020752
Validation loss: 1.9494539973556355

Epoch: 6| Step: 13
Training loss: 1.1630499362945557
Validation loss: 1.9306361982899327

Epoch: 229| Step: 0
Training loss: 0.7446687817573547
Validation loss: 1.9095896110739758

Epoch: 6| Step: 1
Training loss: 0.4648059010505676
Validation loss: 1.9115640745368054

Epoch: 6| Step: 2
Training loss: 1.277894377708435
Validation loss: 1.9204396458082302

Epoch: 6| Step: 3
Training loss: 0.9766026735305786
Validation loss: 1.9584506404015325

Epoch: 6| Step: 4
Training loss: 1.9510959386825562
Validation loss: 2.0032496888150453

Epoch: 6| Step: 5
Training loss: 1.0208500623703003
Validation loss: 2.0440901479413434

Epoch: 6| Step: 6
Training loss: 0.8846126794815063
Validation loss: 2.1173480082583684

Epoch: 6| Step: 7
Training loss: 1.5585157871246338
Validation loss: 2.156670324264034

Epoch: 6| Step: 8
Training loss: 1.2549569606781006
Validation loss: 2.208781962753624

Epoch: 6| Step: 9
Training loss: 1.1380836963653564
Validation loss: 2.2156096043125277

Epoch: 6| Step: 10
Training loss: 0.5164481401443481
Validation loss: 2.142406202131702

Epoch: 6| Step: 11
Training loss: 0.9906764626502991
Validation loss: 2.1698835216542727

Epoch: 6| Step: 12
Training loss: 1.3381733894348145
Validation loss: 2.141952581303094

Epoch: 6| Step: 13
Training loss: 0.2554818093776703
Validation loss: 2.068245974920129

Epoch: 230| Step: 0
Training loss: 1.1809148788452148
Validation loss: 2.0636931516790904

Epoch: 6| Step: 1
Training loss: 1.0849583148956299
Validation loss: 2.0352736621774654

Epoch: 6| Step: 2
Training loss: 1.442044973373413
Validation loss: 2.026053987523561

Epoch: 6| Step: 3
Training loss: 0.4915584921836853
Validation loss: 1.9792800718738186

Epoch: 6| Step: 4
Training loss: 1.3583347797393799
Validation loss: 1.9520148154227965

Epoch: 6| Step: 5
Training loss: 1.0787854194641113
Validation loss: 1.9688556578851515

Epoch: 6| Step: 6
Training loss: 1.151702642440796
Validation loss: 1.9477191586648264

Epoch: 6| Step: 7
Training loss: 0.5084351301193237
Validation loss: 1.9437175309786232

Epoch: 6| Step: 8
Training loss: 1.256178855895996
Validation loss: 1.9878295237018215

Epoch: 6| Step: 9
Training loss: 1.1802748441696167
Validation loss: 2.040950903328516

Epoch: 6| Step: 10
Training loss: 0.8197838664054871
Validation loss: 2.094054965562718

Epoch: 6| Step: 11
Training loss: 1.1653461456298828
Validation loss: 2.130389057179933

Epoch: 6| Step: 12
Training loss: 1.1715061664581299
Validation loss: 2.125304606653029

Epoch: 6| Step: 13
Training loss: 0.32299354672431946
Validation loss: 2.1047918065901725

Epoch: 231| Step: 0
Training loss: 0.9166913032531738
Validation loss: 2.0612854547398065

Epoch: 6| Step: 1
Training loss: 0.5726104974746704
Validation loss: 2.056018434545045

Epoch: 6| Step: 2
Training loss: 1.165788173675537
Validation loss: 1.9982319903630081

Epoch: 6| Step: 3
Training loss: 1.3421049118041992
Validation loss: 2.008810048462242

Epoch: 6| Step: 4
Training loss: 0.8827385306358337
Validation loss: 1.970632613346141

Epoch: 6| Step: 5
Training loss: 1.5451734066009521
Validation loss: 1.923878785102598

Epoch: 6| Step: 6
Training loss: 0.9911850690841675
Validation loss: 1.9136448855041175

Epoch: 6| Step: 7
Training loss: 0.7078171968460083
Validation loss: 1.9218224549806247

Epoch: 6| Step: 8
Training loss: 1.164561152458191
Validation loss: 1.9257743666248937

Epoch: 6| Step: 9
Training loss: 1.038333535194397
Validation loss: 1.9900512272311794

Epoch: 6| Step: 10
Training loss: 1.1442275047302246
Validation loss: 2.0186998946692354

Epoch: 6| Step: 11
Training loss: 0.9913383722305298
Validation loss: 2.0660536032851025

Epoch: 6| Step: 12
Training loss: 1.0176156759262085
Validation loss: 2.0683374327998005

Epoch: 6| Step: 13
Training loss: 0.8340708017349243
Validation loss: 2.0999536232281755

Epoch: 232| Step: 0
Training loss: 1.0340460538864136
Validation loss: 2.075427924433062

Epoch: 6| Step: 1
Training loss: 1.0587464570999146
Validation loss: 2.0971960918877715

Epoch: 6| Step: 2
Training loss: 0.6195499897003174
Validation loss: 2.0728226169463126

Epoch: 6| Step: 3
Training loss: 1.2436976432800293
Validation loss: 2.029159220316077

Epoch: 6| Step: 4
Training loss: 0.5931273698806763
Validation loss: 2.01158707885332

Epoch: 6| Step: 5
Training loss: 0.790195643901825
Validation loss: 1.9958560825676046

Epoch: 6| Step: 6
Training loss: 1.129354476928711
Validation loss: 1.9847940565437399

Epoch: 6| Step: 7
Training loss: 1.1589330434799194
Validation loss: 1.991576402418075

Epoch: 6| Step: 8
Training loss: 1.1233690977096558
Validation loss: 1.9913200921909784

Epoch: 6| Step: 9
Training loss: 0.5622076988220215
Validation loss: 2.007240213373656

Epoch: 6| Step: 10
Training loss: 0.7524117231369019
Validation loss: 2.039141560113558

Epoch: 6| Step: 11
Training loss: 1.20967698097229
Validation loss: 2.068153240347421

Epoch: 6| Step: 12
Training loss: 1.5421171188354492
Validation loss: 2.0859114662293465

Epoch: 6| Step: 13
Training loss: 1.042158603668213
Validation loss: 2.1129460027140956

Epoch: 233| Step: 0
Training loss: 1.0773528814315796
Validation loss: 2.119265141025666

Epoch: 6| Step: 1
Training loss: 0.829815149307251
Validation loss: 2.1410669319091307

Epoch: 6| Step: 2
Training loss: 0.7978001832962036
Validation loss: 2.1568895950112292

Epoch: 6| Step: 3
Training loss: 1.2238879203796387
Validation loss: 2.118467915442682

Epoch: 6| Step: 4
Training loss: 1.083024501800537
Validation loss: 2.0741237594235327

Epoch: 6| Step: 5
Training loss: 0.8434120416641235
Validation loss: 2.0304092745627127

Epoch: 6| Step: 6
Training loss: 0.9681873321533203
Validation loss: 2.0024237607115056

Epoch: 6| Step: 7
Training loss: 1.2442340850830078
Validation loss: 1.9636901681141188

Epoch: 6| Step: 8
Training loss: 1.033098578453064
Validation loss: 1.9823780508451565

Epoch: 6| Step: 9
Training loss: 0.590319812297821
Validation loss: 1.9826666949897684

Epoch: 6| Step: 10
Training loss: 0.9072977900505066
Validation loss: 2.0315288471919235

Epoch: 6| Step: 11
Training loss: 1.1719850301742554
Validation loss: 2.032480278322774

Epoch: 6| Step: 12
Training loss: 0.9238267540931702
Validation loss: 2.0447163338302285

Epoch: 6| Step: 13
Training loss: 1.4790630340576172
Validation loss: 2.043655905672299

Epoch: 234| Step: 0
Training loss: 0.9280189871788025
Validation loss: 2.093227699238767

Epoch: 6| Step: 1
Training loss: 0.5487549304962158
Validation loss: 2.0851625780905447

Epoch: 6| Step: 2
Training loss: 2.0307087898254395
Validation loss: 2.055474035201534

Epoch: 6| Step: 3
Training loss: 0.6950538754463196
Validation loss: 2.0293191299643567

Epoch: 6| Step: 4
Training loss: 0.8239510655403137
Validation loss: 2.01336383563216

Epoch: 6| Step: 5
Training loss: 0.6501874327659607
Validation loss: 1.9948874827354186

Epoch: 6| Step: 6
Training loss: 1.1029775142669678
Validation loss: 2.0004674926880868

Epoch: 6| Step: 7
Training loss: 0.8885958194732666
Validation loss: 1.9964577510792723

Epoch: 6| Step: 8
Training loss: 0.9508269429206848
Validation loss: 2.022045035516062

Epoch: 6| Step: 9
Training loss: 1.1506462097167969
Validation loss: 2.0088503847840014

Epoch: 6| Step: 10
Training loss: 1.2007559537887573
Validation loss: 2.0359915943555933

Epoch: 6| Step: 11
Training loss: 0.4117692708969116
Validation loss: 2.071871283233807

Epoch: 6| Step: 12
Training loss: 1.1712031364440918
Validation loss: 2.0658169459271174

Epoch: 6| Step: 13
Training loss: 0.6939681172370911
Validation loss: 2.0586586716354534

Epoch: 235| Step: 0
Training loss: 1.3755948543548584
Validation loss: 2.0346288732303086

Epoch: 6| Step: 1
Training loss: 0.46056532859802246
Validation loss: 2.0382103291890954

Epoch: 6| Step: 2
Training loss: 0.7766574621200562
Validation loss: 2.0392412152341617

Epoch: 6| Step: 3
Training loss: 1.2851111888885498
Validation loss: 2.059077655115435

Epoch: 6| Step: 4
Training loss: 1.2886993885040283
Validation loss: 2.0524133764287478

Epoch: 6| Step: 5
Training loss: 0.9840173125267029
Validation loss: 2.0913424081699823

Epoch: 6| Step: 6
Training loss: 0.6866687536239624
Validation loss: 2.1145193422994306

Epoch: 6| Step: 7
Training loss: 0.8039721250534058
Validation loss: 2.1079872218511437

Epoch: 6| Step: 8
Training loss: 0.7550705671310425
Validation loss: 2.1067697848043134

Epoch: 6| Step: 9
Training loss: 0.6460045576095581
Validation loss: 2.1107902924219766

Epoch: 6| Step: 10
Training loss: 1.399120807647705
Validation loss: 2.128187603847955

Epoch: 6| Step: 11
Training loss: 1.7067012786865234
Validation loss: 2.1463804116813083

Epoch: 6| Step: 12
Training loss: 0.47681090235710144
Validation loss: 2.0948411726182505

Epoch: 6| Step: 13
Training loss: 0.49353647232055664
Validation loss: 2.076631348620179

Epoch: 236| Step: 0
Training loss: 0.9945284128189087
Validation loss: 2.024948235481016

Epoch: 6| Step: 1
Training loss: 1.180901288986206
Validation loss: 1.966254121513777

Epoch: 6| Step: 2
Training loss: 0.9275522828102112
Validation loss: 1.9297431515109154

Epoch: 6| Step: 3
Training loss: 0.6902355551719666
Validation loss: 1.9170728396343928

Epoch: 6| Step: 4
Training loss: 0.7068878412246704
Validation loss: 1.8981241000595914

Epoch: 6| Step: 5
Training loss: 1.0388166904449463
Validation loss: 1.9057708530015842

Epoch: 6| Step: 6
Training loss: 1.114950180053711
Validation loss: 1.9438256858497538

Epoch: 6| Step: 7
Training loss: 0.8082217574119568
Validation loss: 1.964500657973751

Epoch: 6| Step: 8
Training loss: 0.9211870431900024
Validation loss: 2.029695946683166

Epoch: 6| Step: 9
Training loss: 0.6604425311088562
Validation loss: 2.1094419674206804

Epoch: 6| Step: 10
Training loss: 1.1865724325180054
Validation loss: 2.1380028135033062

Epoch: 6| Step: 11
Training loss: 0.8292135000228882
Validation loss: 2.1311659172017086

Epoch: 6| Step: 12
Training loss: 1.0815149545669556
Validation loss: 2.119448922013724

Epoch: 6| Step: 13
Training loss: 0.852055013179779
Validation loss: 2.107613668646864

Epoch: 237| Step: 0
Training loss: 0.6728775501251221
Validation loss: 2.1012343206713275

Epoch: 6| Step: 1
Training loss: 1.044152021408081
Validation loss: 2.0820720631589174

Epoch: 6| Step: 2
Training loss: 1.3285261392593384
Validation loss: 2.055261408129046

Epoch: 6| Step: 3
Training loss: 0.6807861328125
Validation loss: 2.065596439505136

Epoch: 6| Step: 4
Training loss: 1.0795413255691528
Validation loss: 2.038449151541597

Epoch: 6| Step: 5
Training loss: 0.7429733276367188
Validation loss: 1.9980637065825924

Epoch: 6| Step: 6
Training loss: 0.8989219069480896
Validation loss: 1.9797492770738498

Epoch: 6| Step: 7
Training loss: 1.165468454360962
Validation loss: 2.009275192855507

Epoch: 6| Step: 8
Training loss: 0.9422934055328369
Validation loss: 2.0493478057205037

Epoch: 6| Step: 9
Training loss: 0.867467999458313
Validation loss: 2.0495623286052416

Epoch: 6| Step: 10
Training loss: 0.7134860157966614
Validation loss: 2.067865953650526

Epoch: 6| Step: 11
Training loss: 0.9265801310539246
Validation loss: 2.104852314918272

Epoch: 6| Step: 12
Training loss: 1.077116847038269
Validation loss: 2.1517596026902557

Epoch: 6| Step: 13
Training loss: 1.1689743995666504
Validation loss: 2.146921523155705

Epoch: 238| Step: 0
Training loss: 1.23366117477417
Validation loss: 2.102625021370508

Epoch: 6| Step: 1
Training loss: 0.8629677891731262
Validation loss: 2.1057291376975273

Epoch: 6| Step: 2
Training loss: 0.9459251165390015
Validation loss: 2.057141419379942

Epoch: 6| Step: 3
Training loss: 1.1187753677368164
Validation loss: 2.016212494142594

Epoch: 6| Step: 4
Training loss: 1.087512493133545
Validation loss: 1.9693255962864045

Epoch: 6| Step: 5
Training loss: 1.3705403804779053
Validation loss: 1.9352300269629366

Epoch: 6| Step: 6
Training loss: 0.918795645236969
Validation loss: 1.9093674023946126

Epoch: 6| Step: 7
Training loss: 0.686801552772522
Validation loss: 1.9185650540936379

Epoch: 6| Step: 8
Training loss: 0.9957603812217712
Validation loss: 1.908114726825427

Epoch: 6| Step: 9
Training loss: 0.46431368589401245
Validation loss: 1.948363104174214

Epoch: 6| Step: 10
Training loss: 0.6964106559753418
Validation loss: 1.9667692966358636

Epoch: 6| Step: 11
Training loss: 0.6139934062957764
Validation loss: 2.029784840922202

Epoch: 6| Step: 12
Training loss: 0.9676585793495178
Validation loss: 2.048752961620208

Epoch: 6| Step: 13
Training loss: 1.2509572505950928
Validation loss: 2.0914119315403763

Epoch: 239| Step: 0
Training loss: 1.086391806602478
Validation loss: 2.07281913808597

Epoch: 6| Step: 1
Training loss: 0.9830201864242554
Validation loss: 2.11967642845646

Epoch: 6| Step: 2
Training loss: 0.6261775493621826
Validation loss: 2.10080736683261

Epoch: 6| Step: 3
Training loss: 0.6031488180160522
Validation loss: 2.0824169599881737

Epoch: 6| Step: 4
Training loss: 0.9198765754699707
Validation loss: 2.0842207554847962

Epoch: 6| Step: 5
Training loss: 0.9322148561477661
Validation loss: 2.024988038565523

Epoch: 6| Step: 6
Training loss: 1.262047529220581
Validation loss: 2.01607314104675

Epoch: 6| Step: 7
Training loss: 0.8562658429145813
Validation loss: 1.9647665318622385

Epoch: 6| Step: 8
Training loss: 0.6356436014175415
Validation loss: 1.9703819879921534

Epoch: 6| Step: 9
Training loss: 1.419783115386963
Validation loss: 1.9194887902147026

Epoch: 6| Step: 10
Training loss: 0.9079615473747253
Validation loss: 1.9131343877443703

Epoch: 6| Step: 11
Training loss: 0.9575756788253784
Validation loss: 1.9332348159564439

Epoch: 6| Step: 12
Training loss: 0.8329634666442871
Validation loss: 1.9579369509091942

Epoch: 6| Step: 13
Training loss: 0.8245354890823364
Validation loss: 2.0594397591006373

Epoch: 240| Step: 0
Training loss: 1.1205906867980957
Validation loss: 2.0654260676394225

Epoch: 6| Step: 1
Training loss: 1.4009525775909424
Validation loss: 2.079823692639669

Epoch: 6| Step: 2
Training loss: 1.4169448614120483
Validation loss: 2.08044909533634

Epoch: 6| Step: 3
Training loss: 0.8492568731307983
Validation loss: 2.113410790761312

Epoch: 6| Step: 4
Training loss: 0.7883212566375732
Validation loss: 2.0763020220623223

Epoch: 6| Step: 5
Training loss: 0.9539928436279297
Validation loss: 2.085554983026238

Epoch: 6| Step: 6
Training loss: 0.5903482437133789
Validation loss: 2.053642903604815

Epoch: 6| Step: 7
Training loss: 0.6186466217041016
Validation loss: 2.023964138441188

Epoch: 6| Step: 8
Training loss: 1.0040230751037598
Validation loss: 2.023944806027156

Epoch: 6| Step: 9
Training loss: 0.6416392922401428
Validation loss: 2.0339207828685804

Epoch: 6| Step: 10
Training loss: 0.6557818651199341
Validation loss: 2.0218529880687757

Epoch: 6| Step: 11
Training loss: 0.9172760248184204
Validation loss: 2.0402186967993297

Epoch: 6| Step: 12
Training loss: 0.8320474624633789
Validation loss: 2.0828035903233353

Epoch: 6| Step: 13
Training loss: 0.4915231466293335
Validation loss: 2.0873943144275295

Epoch: 241| Step: 0
Training loss: 1.7231906652450562
Validation loss: 2.100936112865325

Epoch: 6| Step: 1
Training loss: 0.9965823888778687
Validation loss: 2.053152803451784

Epoch: 6| Step: 2
Training loss: 0.7372151613235474
Validation loss: 2.038895155793877

Epoch: 6| Step: 3
Training loss: 0.7862998247146606
Validation loss: 2.0082739245507026

Epoch: 6| Step: 4
Training loss: 0.7853729724884033
Validation loss: 1.9568707968599053

Epoch: 6| Step: 5
Training loss: 0.7196539044380188
Validation loss: 2.0069247573934574

Epoch: 6| Step: 6
Training loss: 1.0978598594665527
Validation loss: 1.9691166647018925

Epoch: 6| Step: 7
Training loss: 0.494793564081192
Validation loss: 1.9582503611041653

Epoch: 6| Step: 8
Training loss: 0.745613157749176
Validation loss: 1.9439219736283826

Epoch: 6| Step: 9
Training loss: 0.786927342414856
Validation loss: 1.9642214236720916

Epoch: 6| Step: 10
Training loss: 0.7501437067985535
Validation loss: 2.0000679954405753

Epoch: 6| Step: 11
Training loss: 1.0625932216644287
Validation loss: 2.0090705322962936

Epoch: 6| Step: 12
Training loss: 0.7356882095336914
Validation loss: 2.0594243157294487

Epoch: 6| Step: 13
Training loss: 0.8017953634262085
Validation loss: 2.0991702669410297

Epoch: 242| Step: 0
Training loss: 1.149632453918457
Validation loss: 2.074754406047124

Epoch: 6| Step: 1
Training loss: 0.7736985683441162
Validation loss: 2.0886746760337584

Epoch: 6| Step: 2
Training loss: 0.9176778793334961
Validation loss: 2.1304626721207813

Epoch: 6| Step: 3
Training loss: 0.7093321084976196
Validation loss: 2.113599077347786

Epoch: 6| Step: 4
Training loss: 1.1428595781326294
Validation loss: 2.0388428395794285

Epoch: 6| Step: 5
Training loss: 1.1195793151855469
Validation loss: 1.9722177700329853

Epoch: 6| Step: 6
Training loss: 0.5129384994506836
Validation loss: 1.9098221922433505

Epoch: 6| Step: 7
Training loss: 1.0570287704467773
Validation loss: 1.909803346921039

Epoch: 6| Step: 8
Training loss: 0.9152759313583374
Validation loss: 1.9338283936182659

Epoch: 6| Step: 9
Training loss: 0.5997278690338135
Validation loss: 1.9138840642026675

Epoch: 6| Step: 10
Training loss: 0.8561221361160278
Validation loss: 1.9664670395594772

Epoch: 6| Step: 11
Training loss: 1.0829381942749023
Validation loss: 1.9653839231819235

Epoch: 6| Step: 12
Training loss: 0.7938507795333862
Validation loss: 1.9752911585633472

Epoch: 6| Step: 13
Training loss: 1.5931354761123657
Validation loss: 1.9651167674731183

Epoch: 243| Step: 0
Training loss: 0.8976168632507324
Validation loss: 1.9792079489718202

Epoch: 6| Step: 1
Training loss: 0.7148902416229248
Validation loss: 2.0531460828678583

Epoch: 6| Step: 2
Training loss: 1.2453515529632568
Validation loss: 2.1024821035323606

Epoch: 6| Step: 3
Training loss: 1.1143550872802734
Validation loss: 2.089647285399898

Epoch: 6| Step: 4
Training loss: 0.7173867225646973
Validation loss: 2.0809671468632196

Epoch: 6| Step: 5
Training loss: 0.612257719039917
Validation loss: 2.0384425065850698

Epoch: 6| Step: 6
Training loss: 0.6308404803276062
Validation loss: 1.9802405859834404

Epoch: 6| Step: 7
Training loss: 1.0389127731323242
Validation loss: 1.9516905994825466

Epoch: 6| Step: 8
Training loss: 0.5028975009918213
Validation loss: 1.9331383166774627

Epoch: 6| Step: 9
Training loss: 0.6539435386657715
Validation loss: 1.9189657152339976

Epoch: 6| Step: 10
Training loss: 1.3712644577026367
Validation loss: 1.8763745548904582

Epoch: 6| Step: 11
Training loss: 0.770497739315033
Validation loss: 1.8247603319024528

Epoch: 6| Step: 12
Training loss: 0.9845327138900757
Validation loss: 1.856800934319855

Epoch: 6| Step: 13
Training loss: 1.117624044418335
Validation loss: 1.9051979511014876

Epoch: 244| Step: 0
Training loss: 0.5460166335105896
Validation loss: 1.9200069263417234

Epoch: 6| Step: 1
Training loss: 0.7033402919769287
Validation loss: 2.0090495386431293

Epoch: 6| Step: 2
Training loss: 0.5702235698699951
Validation loss: 2.031954134664228

Epoch: 6| Step: 3
Training loss: 0.9656562805175781
Validation loss: 2.048366255657647

Epoch: 6| Step: 4
Training loss: 1.0388141870498657
Validation loss: 2.1204300747122815

Epoch: 6| Step: 5
Training loss: 0.9984840750694275
Validation loss: 2.0867430215240805

Epoch: 6| Step: 6
Training loss: 0.9009485244750977
Validation loss: 2.0635492929848294

Epoch: 6| Step: 7
Training loss: 0.5305452942848206
Validation loss: 2.025567845631671

Epoch: 6| Step: 8
Training loss: 0.757636308670044
Validation loss: 2.0651150006119923

Epoch: 6| Step: 9
Training loss: 1.0212886333465576
Validation loss: 2.0627514982736237

Epoch: 6| Step: 10
Training loss: 0.8250308036804199
Validation loss: 2.059109533986738

Epoch: 6| Step: 11
Training loss: 1.2178077697753906
Validation loss: 2.0848134051087084

Epoch: 6| Step: 12
Training loss: 1.1657497882843018
Validation loss: 2.0610463080867643

Epoch: 6| Step: 13
Training loss: 1.5378257036209106
Validation loss: 2.0209889514471895

Epoch: 245| Step: 0
Training loss: 1.1418232917785645
Validation loss: 1.9805467462026944

Epoch: 6| Step: 1
Training loss: 0.7148531675338745
Validation loss: 1.988641292818131

Epoch: 6| Step: 2
Training loss: 0.7530527710914612
Validation loss: 1.9604777136156637

Epoch: 6| Step: 3
Training loss: 0.38225144147872925
Validation loss: 1.9423183369380173

Epoch: 6| Step: 4
Training loss: 0.7502619624137878
Validation loss: 2.015812740531019

Epoch: 6| Step: 5
Training loss: 1.1419041156768799
Validation loss: 2.0541712366124636

Epoch: 6| Step: 6
Training loss: 1.2093257904052734
Validation loss: 2.095327733665384

Epoch: 6| Step: 7
Training loss: 0.8920327425003052
Validation loss: 2.103865833692653

Epoch: 6| Step: 8
Training loss: 0.9905579090118408
Validation loss: 2.121691493577855

Epoch: 6| Step: 9
Training loss: 1.2267285585403442
Validation loss: 2.1015163877958893

Epoch: 6| Step: 10
Training loss: 0.8104985952377319
Validation loss: 2.037484645843506

Epoch: 6| Step: 11
Training loss: 0.7213447690010071
Validation loss: 2.0054183954833658

Epoch: 6| Step: 12
Training loss: 0.6294773817062378
Validation loss: 1.9448849065329439

Epoch: 6| Step: 13
Training loss: 0.584171712398529
Validation loss: 1.976341547504548

Epoch: 246| Step: 0
Training loss: 1.0202678442001343
Validation loss: 1.9583570585455945

Epoch: 6| Step: 1
Training loss: 1.0943074226379395
Validation loss: 1.9431910002103416

Epoch: 6| Step: 2
Training loss: 0.6679721474647522
Validation loss: 1.951673371817476

Epoch: 6| Step: 3
Training loss: 1.0674777030944824
Validation loss: 1.9406916172273698

Epoch: 6| Step: 4
Training loss: 0.9916472434997559
Validation loss: 1.9477677012002597

Epoch: 6| Step: 5
Training loss: 0.820981502532959
Validation loss: 1.9288501149864608

Epoch: 6| Step: 6
Training loss: 0.41699835658073425
Validation loss: 2.02010880490785

Epoch: 6| Step: 7
Training loss: 0.8906942009925842
Validation loss: 2.0524243590652302

Epoch: 6| Step: 8
Training loss: 0.7308580875396729
Validation loss: 2.092319414179812

Epoch: 6| Step: 9
Training loss: 0.6650763154029846
Validation loss: 2.1030693836109613

Epoch: 6| Step: 10
Training loss: 1.1523051261901855
Validation loss: 2.0733671649809806

Epoch: 6| Step: 11
Training loss: 0.9905815124511719
Validation loss: 2.02539248107582

Epoch: 6| Step: 12
Training loss: 0.6558157205581665
Validation loss: 2.010623226883591

Epoch: 6| Step: 13
Training loss: 0.6205892562866211
Validation loss: 1.9957047970064226

Epoch: 247| Step: 0
Training loss: 0.7889562845230103
Validation loss: 1.9505337592094176

Epoch: 6| Step: 1
Training loss: 0.8550269603729248
Validation loss: 1.9448551016469156

Epoch: 6| Step: 2
Training loss: 0.7259513735771179
Validation loss: 1.9552653899756811

Epoch: 6| Step: 3
Training loss: 0.8854955434799194
Validation loss: 1.9312225618670065

Epoch: 6| Step: 4
Training loss: 0.8284865021705627
Validation loss: 1.9604227645422823

Epoch: 6| Step: 5
Training loss: 0.6624842286109924
Validation loss: 1.9595874483867357

Epoch: 6| Step: 6
Training loss: 0.9972778558731079
Validation loss: 2.007765516158073

Epoch: 6| Step: 7
Training loss: 0.7473173141479492
Validation loss: 1.9942493515629922

Epoch: 6| Step: 8
Training loss: 0.5163872838020325
Validation loss: 2.017019121877609

Epoch: 6| Step: 9
Training loss: 1.0628273487091064
Validation loss: 2.0078664941172444

Epoch: 6| Step: 10
Training loss: 0.9528684616088867
Validation loss: 1.9725142858361686

Epoch: 6| Step: 11
Training loss: 1.1456820964813232
Validation loss: 1.9953514581085534

Epoch: 6| Step: 12
Training loss: 0.5699627995491028
Validation loss: 1.9801081559991325

Epoch: 6| Step: 13
Training loss: 1.3809199333190918
Validation loss: 2.000126777156707

Epoch: 248| Step: 0
Training loss: 0.6900463104248047
Validation loss: 1.9810060237043647

Epoch: 6| Step: 1
Training loss: 0.6587262153625488
Validation loss: 1.9995272492849698

Epoch: 6| Step: 2
Training loss: 0.6708570718765259
Validation loss: 2.0420771516779417

Epoch: 6| Step: 3
Training loss: 0.6882111430168152
Validation loss: 2.019887355066115

Epoch: 6| Step: 4
Training loss: 0.6544078588485718
Validation loss: 2.022797523006316

Epoch: 6| Step: 5
Training loss: 0.939258873462677
Validation loss: 2.012671393732871

Epoch: 6| Step: 6
Training loss: 0.7185651659965515
Validation loss: 2.050134374249366

Epoch: 6| Step: 7
Training loss: 0.8080615401268005
Validation loss: 2.0585593049244215

Epoch: 6| Step: 8
Training loss: 0.9265232086181641
Validation loss: 2.07974495426301

Epoch: 6| Step: 9
Training loss: 1.1360387802124023
Validation loss: 2.110579039460869

Epoch: 6| Step: 10
Training loss: 0.8924896717071533
Validation loss: 2.068967510295171

Epoch: 6| Step: 11
Training loss: 1.0809478759765625
Validation loss: 2.053441560396584

Epoch: 6| Step: 12
Training loss: 0.7488621473312378
Validation loss: 2.0181937550985687

Epoch: 6| Step: 13
Training loss: 0.8792926669120789
Validation loss: 2.0180432758023663

Epoch: 249| Step: 0
Training loss: 0.8724204301834106
Validation loss: 2.012744744618734

Epoch: 6| Step: 1
Training loss: 0.9204426407814026
Validation loss: 1.9889302266541349

Epoch: 6| Step: 2
Training loss: 0.39892667531967163
Validation loss: 1.9819055526487288

Epoch: 6| Step: 3
Training loss: 0.6373330354690552
Validation loss: 1.9684284399914485

Epoch: 6| Step: 4
Training loss: 0.5884299278259277
Validation loss: 2.006990868558166

Epoch: 6| Step: 5
Training loss: 0.8483631610870361
Validation loss: 2.0028570634062572

Epoch: 6| Step: 6
Training loss: 1.060270071029663
Validation loss: 1.9926848667924122

Epoch: 6| Step: 7
Training loss: 1.0006295442581177
Validation loss: 2.0348748173764957

Epoch: 6| Step: 8
Training loss: 0.5797977447509766
Validation loss: 2.045509188405929

Epoch: 6| Step: 9
Training loss: 0.9185814261436462
Validation loss: 2.0563472227383683

Epoch: 6| Step: 10
Training loss: 0.8816976547241211
Validation loss: 2.015789972838535

Epoch: 6| Step: 11
Training loss: 0.7307472229003906
Validation loss: 2.0175936247712825

Epoch: 6| Step: 12
Training loss: 0.7405699491500854
Validation loss: 2.036594908724549

Epoch: 6| Step: 13
Training loss: 1.2867830991744995
Validation loss: 2.0256347143521873

Epoch: 250| Step: 0
Training loss: 0.43191632628440857
Validation loss: 2.0508960190639702

Epoch: 6| Step: 1
Training loss: 0.6339382529258728
Validation loss: 2.0240399311947566

Epoch: 6| Step: 2
Training loss: 0.9203689098358154
Validation loss: 1.9843844085611322

Epoch: 6| Step: 3
Training loss: 0.5497296452522278
Validation loss: 1.988886083326032

Epoch: 6| Step: 4
Training loss: 1.1002988815307617
Validation loss: 1.9437857763741606

Epoch: 6| Step: 5
Training loss: 1.2388417720794678
Validation loss: 1.9565158377411545

Epoch: 6| Step: 6
Training loss: 0.798801839351654
Validation loss: 1.9321581753351356

Epoch: 6| Step: 7
Training loss: 0.8688275218009949
Validation loss: 1.9814767811888008

Epoch: 6| Step: 8
Training loss: 0.667224109172821
Validation loss: 2.013191565390556

Epoch: 6| Step: 9
Training loss: 1.2469000816345215
Validation loss: 2.007452318745275

Epoch: 6| Step: 10
Training loss: 0.7303236722946167
Validation loss: 2.0374897115974018

Epoch: 6| Step: 11
Training loss: 0.6819477081298828
Validation loss: 2.05302337420884

Epoch: 6| Step: 12
Training loss: 0.7663693428039551
Validation loss: 2.0608434356668943

Epoch: 6| Step: 13
Training loss: 0.5936129093170166
Validation loss: 2.038898778218095

Epoch: 251| Step: 0
Training loss: 0.5614316463470459
Validation loss: 2.045863493796318

Epoch: 6| Step: 1
Training loss: 0.4914867579936981
Validation loss: 2.05962973512629

Epoch: 6| Step: 2
Training loss: 0.948133647441864
Validation loss: 2.0568038801993094

Epoch: 6| Step: 3
Training loss: 0.7605819702148438
Validation loss: 2.0554437278419413

Epoch: 6| Step: 4
Training loss: 0.9923873543739319
Validation loss: 1.9980634194548412

Epoch: 6| Step: 5
Training loss: 1.2734371423721313
Validation loss: 2.0188597376628588

Epoch: 6| Step: 6
Training loss: 0.7527175545692444
Validation loss: 2.0031505297589045

Epoch: 6| Step: 7
Training loss: 0.7645967602729797
Validation loss: 1.9932573277463195

Epoch: 6| Step: 8
Training loss: 1.0407629013061523
Validation loss: 1.9794561042580554

Epoch: 6| Step: 9
Training loss: 0.9527088403701782
Validation loss: 2.007675051689148

Epoch: 6| Step: 10
Training loss: 0.5674148201942444
Validation loss: 1.9973730464135446

Epoch: 6| Step: 11
Training loss: 0.8803784847259521
Validation loss: 1.9990143237575408

Epoch: 6| Step: 12
Training loss: 0.933529257774353
Validation loss: 2.0583958497611423

Epoch: 6| Step: 13
Training loss: 1.3398200273513794
Validation loss: 2.060743707482533

Epoch: 252| Step: 0
Training loss: 0.3924762010574341
Validation loss: 2.0328476864804506

Epoch: 6| Step: 1
Training loss: 0.7285770177841187
Validation loss: 2.008803677815263

Epoch: 6| Step: 2
Training loss: 0.64354407787323
Validation loss: 1.9727220842915196

Epoch: 6| Step: 3
Training loss: 0.7954550981521606
Validation loss: 1.9724023598496632

Epoch: 6| Step: 4
Training loss: 0.8376008868217468
Validation loss: 1.9742551196006037

Epoch: 6| Step: 5
Training loss: 0.9263598322868347
Validation loss: 1.9774333097601449

Epoch: 6| Step: 6
Training loss: 0.7766635417938232
Validation loss: 1.976760995003485

Epoch: 6| Step: 7
Training loss: 1.1993675231933594
Validation loss: 1.9203511796971804

Epoch: 6| Step: 8
Training loss: 0.9202342629432678
Validation loss: 1.9609750355443647

Epoch: 6| Step: 9
Training loss: 1.0867630243301392
Validation loss: 1.9439317564810477

Epoch: 6| Step: 10
Training loss: 0.7754553556442261
Validation loss: 1.9396271051899079

Epoch: 6| Step: 11
Training loss: 1.1024138927459717
Validation loss: 1.9716055047127508

Epoch: 6| Step: 12
Training loss: 0.6243889331817627
Validation loss: 1.984859775471431

Epoch: 6| Step: 13
Training loss: 0.7501388192176819
Validation loss: 1.9637986998404227

Epoch: 253| Step: 0
Training loss: 0.9640262126922607
Validation loss: 1.9825589374829364

Epoch: 6| Step: 1
Training loss: 0.408150315284729
Validation loss: 1.9944714858967771

Epoch: 6| Step: 2
Training loss: 0.6988446712493896
Validation loss: 1.9706985976106377

Epoch: 6| Step: 3
Training loss: 0.8078337907791138
Validation loss: 1.9980235035701464

Epoch: 6| Step: 4
Training loss: 0.981482207775116
Validation loss: 1.9645134197768344

Epoch: 6| Step: 5
Training loss: 0.7551833391189575
Validation loss: 1.9683194288643457

Epoch: 6| Step: 6
Training loss: 0.49830830097198486
Validation loss: 1.995442723715177

Epoch: 6| Step: 7
Training loss: 0.7076940536499023
Validation loss: 1.9997106085541427

Epoch: 6| Step: 8
Training loss: 0.691011905670166
Validation loss: 1.976897511430966

Epoch: 6| Step: 9
Training loss: 0.9407386183738708
Validation loss: 2.010461473977694

Epoch: 6| Step: 10
Training loss: 0.872442364692688
Validation loss: 2.0077438405765

Epoch: 6| Step: 11
Training loss: 0.6447665691375732
Validation loss: 1.981216694719048

Epoch: 6| Step: 12
Training loss: 0.7142090201377869
Validation loss: 1.9932763538052958

Epoch: 6| Step: 13
Training loss: 1.0989391803741455
Validation loss: 2.0273836376846477

Epoch: 254| Step: 0
Training loss: 0.6485817432403564
Validation loss: 2.0293932896788403

Epoch: 6| Step: 1
Training loss: 1.1160880327224731
Validation loss: 2.0303945220926756

Epoch: 6| Step: 2
Training loss: 0.7747817039489746
Validation loss: 2.0395141852799283

Epoch: 6| Step: 3
Training loss: 0.757348358631134
Validation loss: 2.022923363152371

Epoch: 6| Step: 4
Training loss: 0.8619754314422607
Validation loss: 1.9658919111374886

Epoch: 6| Step: 5
Training loss: 1.5417418479919434
Validation loss: 1.9067181784619567

Epoch: 6| Step: 6
Training loss: 0.6738858222961426
Validation loss: 1.884618438700194

Epoch: 6| Step: 7
Training loss: 0.7388836145401001
Validation loss: 1.884954088477678

Epoch: 6| Step: 8
Training loss: 1.0431327819824219
Validation loss: 1.8526726935499458

Epoch: 6| Step: 9
Training loss: 0.8112413883209229
Validation loss: 1.8940341652080577

Epoch: 6| Step: 10
Training loss: 0.5332930088043213
Validation loss: 1.8776302670919767

Epoch: 6| Step: 11
Training loss: 0.5536357760429382
Validation loss: 1.9140308480108938

Epoch: 6| Step: 12
Training loss: 0.49437734484672546
Validation loss: 1.9248967580897833

Epoch: 6| Step: 13
Training loss: 0.4810331165790558
Validation loss: 1.946760085321242

Epoch: 255| Step: 0
Training loss: 0.5487518310546875
Validation loss: 2.040622695799797

Epoch: 6| Step: 1
Training loss: 0.4530935287475586
Validation loss: 2.059057148553992

Epoch: 6| Step: 2
Training loss: 1.2397867441177368
Validation loss: 2.115588939318093

Epoch: 6| Step: 3
Training loss: 0.7187767028808594
Validation loss: 2.0648676618452995

Epoch: 6| Step: 4
Training loss: 0.8644237518310547
Validation loss: 2.055811566691245

Epoch: 6| Step: 5
Training loss: 0.7265251278877258
Validation loss: 2.0449343624935357

Epoch: 6| Step: 6
Training loss: 0.9696399569511414
Validation loss: 2.008095302889424

Epoch: 6| Step: 7
Training loss: 0.8015632629394531
Validation loss: 1.9146554021425144

Epoch: 6| Step: 8
Training loss: 0.7606836557388306
Validation loss: 1.9205763827088058

Epoch: 6| Step: 9
Training loss: 0.941225528717041
Validation loss: 1.8959341741377307

Epoch: 6| Step: 10
Training loss: 0.4672439992427826
Validation loss: 1.8836290118514851

Epoch: 6| Step: 11
Training loss: 0.44738662242889404
Validation loss: 1.902216044805383

Epoch: 6| Step: 12
Training loss: 0.6805822849273682
Validation loss: 1.9336649179458618

Epoch: 6| Step: 13
Training loss: 1.128531813621521
Validation loss: 1.9323032927769486

Epoch: 256| Step: 0
Training loss: 0.7429304122924805
Validation loss: 1.9671036786930536

Epoch: 6| Step: 1
Training loss: 0.923788845539093
Validation loss: 1.9821624960950626

Epoch: 6| Step: 2
Training loss: 0.5366591215133667
Validation loss: 1.972124344559126

Epoch: 6| Step: 3
Training loss: 0.8890523910522461
Validation loss: 1.9871905183279386

Epoch: 6| Step: 4
Training loss: 0.7885535955429077
Validation loss: 2.0088647719352477

Epoch: 6| Step: 5
Training loss: 0.350116103887558
Validation loss: 1.9924536417889338

Epoch: 6| Step: 6
Training loss: 0.7551190257072449
Validation loss: 1.9586330049781389

Epoch: 6| Step: 7
Training loss: 0.6949170231819153
Validation loss: 1.9745063961193126

Epoch: 6| Step: 8
Training loss: 0.7073403000831604
Validation loss: 1.937771556197956

Epoch: 6| Step: 9
Training loss: 0.9814603328704834
Validation loss: 1.9550735617196688

Epoch: 6| Step: 10
Training loss: 0.6974039077758789
Validation loss: 1.952738582447011

Epoch: 6| Step: 11
Training loss: 1.1326512098312378
Validation loss: 1.9498807076484925

Epoch: 6| Step: 12
Training loss: 0.4169321060180664
Validation loss: 1.9732303683475783

Epoch: 6| Step: 13
Training loss: 1.2202742099761963
Validation loss: 1.9474619434725853

Epoch: 257| Step: 0
Training loss: 1.1763105392456055
Validation loss: 1.9384673821028842

Epoch: 6| Step: 1
Training loss: 0.8405299186706543
Validation loss: 1.9537598266396472

Epoch: 6| Step: 2
Training loss: 0.4707697033882141
Validation loss: 1.9566835562388103

Epoch: 6| Step: 3
Training loss: 0.9801738262176514
Validation loss: 1.979146852288195

Epoch: 6| Step: 4
Training loss: 0.6321356296539307
Validation loss: 1.9927414283957532

Epoch: 6| Step: 5
Training loss: 0.45765018463134766
Validation loss: 1.993323331238121

Epoch: 6| Step: 6
Training loss: 0.5391998887062073
Validation loss: 1.9682495568388252

Epoch: 6| Step: 7
Training loss: 0.5547921657562256
Validation loss: 1.9737143439631308

Epoch: 6| Step: 8
Training loss: 0.4281511902809143
Validation loss: 1.9362096965953868

Epoch: 6| Step: 9
Training loss: 1.0919725894927979
Validation loss: 1.9300717730675974

Epoch: 6| Step: 10
Training loss: 1.0377949476242065
Validation loss: 1.9467355743531258

Epoch: 6| Step: 11
Training loss: 0.729145348072052
Validation loss: 1.9466225626648113

Epoch: 6| Step: 12
Training loss: 0.38754504919052124
Validation loss: 1.9827219286272604

Epoch: 6| Step: 13
Training loss: 0.7650063633918762
Validation loss: 1.9546533733285882

Epoch: 258| Step: 0
Training loss: 1.1409761905670166
Validation loss: 1.9686936409242692

Epoch: 6| Step: 1
Training loss: 0.7260693907737732
Validation loss: 1.982443683890886

Epoch: 6| Step: 2
Training loss: 0.5123965740203857
Validation loss: 2.0027766150812947

Epoch: 6| Step: 3
Training loss: 0.7268269062042236
Validation loss: 1.9839291944298694

Epoch: 6| Step: 4
Training loss: 0.8219382166862488
Validation loss: 2.000165452239334

Epoch: 6| Step: 5
Training loss: 0.6405367255210876
Validation loss: 2.041190613982498

Epoch: 6| Step: 6
Training loss: 0.5270271897315979
Validation loss: 2.0481439687872447

Epoch: 6| Step: 7
Training loss: 0.48573803901672363
Validation loss: 2.0586342298856346

Epoch: 6| Step: 8
Training loss: 1.0738824605941772
Validation loss: 2.076312026669902

Epoch: 6| Step: 9
Training loss: 0.909852921962738
Validation loss: 2.0664797713679652

Epoch: 6| Step: 10
Training loss: 0.816710889339447
Validation loss: 2.026847829100906

Epoch: 6| Step: 11
Training loss: 0.38918793201446533
Validation loss: 1.9848669793016167

Epoch: 6| Step: 12
Training loss: 0.6489315032958984
Validation loss: 2.0260701089776973

Epoch: 6| Step: 13
Training loss: 0.42250531911849976
Validation loss: 2.00762527988803

Epoch: 259| Step: 0
Training loss: 0.5357779860496521
Validation loss: 1.9642532281978156

Epoch: 6| Step: 1
Training loss: 0.8405947685241699
Validation loss: 1.983119681317319

Epoch: 6| Step: 2
Training loss: 0.9168137311935425
Validation loss: 1.987277187326903

Epoch: 6| Step: 3
Training loss: 0.6268057227134705
Validation loss: 1.9965898503539383

Epoch: 6| Step: 4
Training loss: 0.40219491720199585
Validation loss: 2.0091873856001

Epoch: 6| Step: 5
Training loss: 0.9495875835418701
Validation loss: 1.9986427676293157

Epoch: 6| Step: 6
Training loss: 0.37944602966308594
Validation loss: 2.0296317967035438

Epoch: 6| Step: 7
Training loss: 0.808948814868927
Validation loss: 1.9934016619959185

Epoch: 6| Step: 8
Training loss: 0.6574064493179321
Validation loss: 2.0039143793044554

Epoch: 6| Step: 9
Training loss: 0.7607570886611938
Validation loss: 2.024600085391793

Epoch: 6| Step: 10
Training loss: 0.5416350364685059
Validation loss: 2.0139123137279222

Epoch: 6| Step: 11
Training loss: 0.9671981930732727
Validation loss: 2.004545191282867

Epoch: 6| Step: 12
Training loss: 0.7472261190414429
Validation loss: 1.984860534309059

Epoch: 6| Step: 13
Training loss: 0.586370587348938
Validation loss: 1.9743124079960648

Epoch: 260| Step: 0
Training loss: 0.7532497644424438
Validation loss: 1.9682594345461937

Epoch: 6| Step: 1
Training loss: 0.6079680323600769
Validation loss: 1.9856969733392038

Epoch: 6| Step: 2
Training loss: 0.5491368770599365
Validation loss: 1.989533644850536

Epoch: 6| Step: 3
Training loss: 0.9747378826141357
Validation loss: 2.0095093557911534

Epoch: 6| Step: 4
Training loss: 0.48033323884010315
Validation loss: 2.0217200056199105

Epoch: 6| Step: 5
Training loss: 0.6044902801513672
Validation loss: 2.04227888712319

Epoch: 6| Step: 6
Training loss: 0.8371433615684509
Validation loss: 2.0150681285447973

Epoch: 6| Step: 7
Training loss: 0.5679700970649719
Validation loss: 1.9998575359262445

Epoch: 6| Step: 8
Training loss: 0.7160211801528931
Validation loss: 1.9957129980928154

Epoch: 6| Step: 9
Training loss: 0.40181785821914673
Validation loss: 2.0110476721999464

Epoch: 6| Step: 10
Training loss: 0.9698934555053711
Validation loss: 2.013425765498992

Epoch: 6| Step: 11
Training loss: 0.9213813543319702
Validation loss: 2.021173042635764

Epoch: 6| Step: 12
Training loss: 0.7275843024253845
Validation loss: 2.0056995525155017

Epoch: 6| Step: 13
Training loss: 0.7951200008392334
Validation loss: 2.0350346975429083

Epoch: 261| Step: 0
Training loss: 0.7422269582748413
Validation loss: 1.9881188984840148

Epoch: 6| Step: 1
Training loss: 0.6416753530502319
Validation loss: 1.9674437174233057

Epoch: 6| Step: 2
Training loss: 0.5765641331672668
Validation loss: 1.9017876296915033

Epoch: 6| Step: 3
Training loss: 0.7201601266860962
Validation loss: 1.926117927797379

Epoch: 6| Step: 4
Training loss: 0.58759605884552
Validation loss: 1.895779473807222

Epoch: 6| Step: 5
Training loss: 0.6232575178146362
Validation loss: 1.8958834935260076

Epoch: 6| Step: 6
Training loss: 0.7529045343399048
Validation loss: 1.927964251528504

Epoch: 6| Step: 7
Training loss: 0.7737741470336914
Validation loss: 1.9282592342745872

Epoch: 6| Step: 8
Training loss: 0.6547375321388245
Validation loss: 1.949481733383671

Epoch: 6| Step: 9
Training loss: 0.982053279876709
Validation loss: 1.9676040500722907

Epoch: 6| Step: 10
Training loss: 0.367121160030365
Validation loss: 2.0058982603011595

Epoch: 6| Step: 11
Training loss: 0.8417513966560364
Validation loss: 2.0082728144943074

Epoch: 6| Step: 12
Training loss: 0.7396379709243774
Validation loss: 1.98845382659666

Epoch: 6| Step: 13
Training loss: 0.37196633219718933
Validation loss: 1.9729554730076944

Epoch: 262| Step: 0
Training loss: 0.4872070550918579
Validation loss: 1.9990566494644328

Epoch: 6| Step: 1
Training loss: 0.7710968255996704
Validation loss: 2.0211680999366184

Epoch: 6| Step: 2
Training loss: 0.45949217677116394
Validation loss: 1.952046440493676

Epoch: 6| Step: 3
Training loss: 0.5844326019287109
Validation loss: 1.92395781957975

Epoch: 6| Step: 4
Training loss: 0.49259859323501587
Validation loss: 1.9172138347420642

Epoch: 6| Step: 5
Training loss: 0.7452791929244995
Validation loss: 1.94987327437247

Epoch: 6| Step: 6
Training loss: 0.8485202789306641
Validation loss: 1.927965619230783

Epoch: 6| Step: 7
Training loss: 0.8761430978775024
Validation loss: 1.9340471644555368

Epoch: 6| Step: 8
Training loss: 0.7824876308441162
Validation loss: 1.9691031312429776

Epoch: 6| Step: 9
Training loss: 0.7929702997207642
Validation loss: 1.994055563403714

Epoch: 6| Step: 10
Training loss: 0.6387447714805603
Validation loss: 1.9901324433665122

Epoch: 6| Step: 11
Training loss: 0.8633968830108643
Validation loss: 1.9543852498454433

Epoch: 6| Step: 12
Training loss: 0.9223177433013916
Validation loss: 1.9911618848000803

Epoch: 6| Step: 13
Training loss: 0.19997189939022064
Validation loss: 1.9450438022613525

Epoch: 263| Step: 0
Training loss: 0.28488850593566895
Validation loss: 1.9696106654341503

Epoch: 6| Step: 1
Training loss: 0.6977709531784058
Validation loss: 1.9478894228576331

Epoch: 6| Step: 2
Training loss: 0.685055136680603
Validation loss: 1.9604274739501297

Epoch: 6| Step: 3
Training loss: 0.9284046292304993
Validation loss: 1.9499443320817844

Epoch: 6| Step: 4
Training loss: 0.7769633531570435
Validation loss: 1.9466457443852578

Epoch: 6| Step: 5
Training loss: 0.4345318675041199
Validation loss: 1.9239833175495107

Epoch: 6| Step: 6
Training loss: 0.7840341329574585
Validation loss: 1.9355123914698118

Epoch: 6| Step: 7
Training loss: 0.6854182481765747
Validation loss: 1.9595715076692644

Epoch: 6| Step: 8
Training loss: 0.5475997924804688
Validation loss: 1.9609025755236227

Epoch: 6| Step: 9
Training loss: 0.8700705766677856
Validation loss: 1.9478878462186424

Epoch: 6| Step: 10
Training loss: 0.47978365421295166
Validation loss: 1.9555895328521729

Epoch: 6| Step: 11
Training loss: 0.3907328248023987
Validation loss: 1.9409341312223864

Epoch: 6| Step: 12
Training loss: 0.7940880656242371
Validation loss: 1.9112221899852957

Epoch: 6| Step: 13
Training loss: 1.1708875894546509
Validation loss: 1.9311120292191863

Epoch: 264| Step: 0
Training loss: 1.0247496366500854
Validation loss: 1.911684657937737

Epoch: 6| Step: 1
Training loss: 0.5840094089508057
Validation loss: 1.9527307774430962

Epoch: 6| Step: 2
Training loss: 0.498332679271698
Validation loss: 1.9606792055150515

Epoch: 6| Step: 3
Training loss: 0.44024816155433655
Validation loss: 1.9212076074333602

Epoch: 6| Step: 4
Training loss: 0.6756082773208618
Validation loss: 1.9054304515161822

Epoch: 6| Step: 5
Training loss: 0.48416727781295776
Validation loss: 1.9225269697045768

Epoch: 6| Step: 6
Training loss: 0.8687002658843994
Validation loss: 1.9246202092016897

Epoch: 6| Step: 7
Training loss: 0.6072152853012085
Validation loss: 1.9377899798013831

Epoch: 6| Step: 8
Training loss: 0.5166261196136475
Validation loss: 1.9297302858803862

Epoch: 6| Step: 9
Training loss: 0.8408821821212769
Validation loss: 1.8905463872417327

Epoch: 6| Step: 10
Training loss: 0.4756428599357605
Validation loss: 1.8806589829024447

Epoch: 6| Step: 11
Training loss: 0.808189868927002
Validation loss: 1.9304797623747139

Epoch: 6| Step: 12
Training loss: 0.6869477033615112
Validation loss: 1.966412418632097

Epoch: 6| Step: 13
Training loss: 1.317677617073059
Validation loss: 1.9653905091747161

Epoch: 265| Step: 0
Training loss: 0.4725244641304016
Validation loss: 1.9907081319439797

Epoch: 6| Step: 1
Training loss: 0.47416067123413086
Validation loss: 2.0067274903738372

Epoch: 6| Step: 2
Training loss: 0.5858725309371948
Validation loss: 1.990015168343821

Epoch: 6| Step: 3
Training loss: 0.692611038684845
Validation loss: 1.9708304802576702

Epoch: 6| Step: 4
Training loss: 0.3493233323097229
Validation loss: 1.9263370190897295

Epoch: 6| Step: 5
Training loss: 0.6277498006820679
Validation loss: 1.9124706855384253

Epoch: 6| Step: 6
Training loss: 0.5258099436759949
Validation loss: 1.9363676655677058

Epoch: 6| Step: 7
Training loss: 1.224588394165039
Validation loss: 1.9023281553740143

Epoch: 6| Step: 8
Training loss: 0.528110146522522
Validation loss: 1.9246532763204267

Epoch: 6| Step: 9
Training loss: 0.6123080253601074
Validation loss: 1.8990003498651649

Epoch: 6| Step: 10
Training loss: 0.5066468119621277
Validation loss: 1.8710289193737892

Epoch: 6| Step: 11
Training loss: 0.7437940239906311
Validation loss: 1.8566847155171056

Epoch: 6| Step: 12
Training loss: 0.9248854517936707
Validation loss: 1.8868830550101496

Epoch: 6| Step: 13
Training loss: 1.252373218536377
Validation loss: 1.9048059460937337

Epoch: 266| Step: 0
Training loss: 0.5810412168502808
Validation loss: 1.8522634326770742

Epoch: 6| Step: 1
Training loss: 0.7276360392570496
Validation loss: 1.8996612692392

Epoch: 6| Step: 2
Training loss: 0.8530382513999939
Validation loss: 1.8997754666113085

Epoch: 6| Step: 3
Training loss: 0.4353276193141937
Validation loss: 1.9117619555483583

Epoch: 6| Step: 4
Training loss: 0.3974302113056183
Validation loss: 1.9121897733339699

Epoch: 6| Step: 5
Training loss: 0.8250081539154053
Validation loss: 1.9501152512847737

Epoch: 6| Step: 6
Training loss: 0.2435491979122162
Validation loss: 1.9736043624980475

Epoch: 6| Step: 7
Training loss: 0.39172643423080444
Validation loss: 1.9376118208772393

Epoch: 6| Step: 8
Training loss: 0.8993843793869019
Validation loss: 1.9718935720382198

Epoch: 6| Step: 9
Training loss: 0.6192828416824341
Validation loss: 2.0021694193604174

Epoch: 6| Step: 10
Training loss: 0.6326749324798584
Validation loss: 2.021933986294654

Epoch: 6| Step: 11
Training loss: 0.5220139622688293
Validation loss: 1.9936927749264626

Epoch: 6| Step: 12
Training loss: 0.9078578352928162
Validation loss: 1.971607510761548

Epoch: 6| Step: 13
Training loss: 1.176344871520996
Validation loss: 1.978257288214981

Epoch: 267| Step: 0
Training loss: 0.8344277143478394
Validation loss: 1.940068139824816

Epoch: 6| Step: 1
Training loss: 0.8711355328559875
Validation loss: 1.9000945193793184

Epoch: 6| Step: 2
Training loss: 0.8089788556098938
Validation loss: 1.8926266765081754

Epoch: 6| Step: 3
Training loss: 0.9507032632827759
Validation loss: 1.8414420132995934

Epoch: 6| Step: 4
Training loss: 0.5124357342720032
Validation loss: 1.850061337153117

Epoch: 6| Step: 5
Training loss: 0.7668392658233643
Validation loss: 1.8681929842118294

Epoch: 6| Step: 6
Training loss: 0.6029970645904541
Validation loss: 1.8730386662226852

Epoch: 6| Step: 7
Training loss: 0.6874465346336365
Validation loss: 1.8857051916019891

Epoch: 6| Step: 8
Training loss: 0.4251646101474762
Validation loss: 1.8993705639275171

Epoch: 6| Step: 9
Training loss: 0.4404391646385193
Validation loss: 1.912658574760601

Epoch: 6| Step: 10
Training loss: 0.7979096174240112
Validation loss: 1.9551088374148133

Epoch: 6| Step: 11
Training loss: 0.4344496726989746
Validation loss: 2.038458908757856

Epoch: 6| Step: 12
Training loss: 0.7867909669876099
Validation loss: 2.0563115906971756

Epoch: 6| Step: 13
Training loss: 0.9997117519378662
Validation loss: 2.0150422844835507

Epoch: 268| Step: 0
Training loss: 0.5974255800247192
Validation loss: 1.9580759822681386

Epoch: 6| Step: 1
Training loss: 0.3582228422164917
Validation loss: 1.9321231226767264

Epoch: 6| Step: 2
Training loss: 0.549909770488739
Validation loss: 1.8925233041086504

Epoch: 6| Step: 3
Training loss: 0.7756956219673157
Validation loss: 1.9233644213727725

Epoch: 6| Step: 4
Training loss: 0.7260117530822754
Validation loss: 1.9348136314781763

Epoch: 6| Step: 5
Training loss: 0.5999770164489746
Validation loss: 1.9338683453939294

Epoch: 6| Step: 6
Training loss: 0.9096250534057617
Validation loss: 1.9384908214692147

Epoch: 6| Step: 7
Training loss: 0.6618614792823792
Validation loss: 1.9598868418765325

Epoch: 6| Step: 8
Training loss: 0.6985471248626709
Validation loss: 1.9190403440947175

Epoch: 6| Step: 9
Training loss: 0.7326536774635315
Validation loss: 1.909228281308246

Epoch: 6| Step: 10
Training loss: 1.3765588998794556
Validation loss: 1.928164610298731

Epoch: 6| Step: 11
Training loss: 0.44146764278411865
Validation loss: 1.9460561070390927

Epoch: 6| Step: 12
Training loss: 0.578012228012085
Validation loss: 1.9714049434149137

Epoch: 6| Step: 13
Training loss: 0.5330535769462585
Validation loss: 1.9993993005444926

Epoch: 269| Step: 0
Training loss: 0.7662001848220825
Validation loss: 2.0300258705692906

Epoch: 6| Step: 1
Training loss: 0.6438133120536804
Validation loss: 2.020433992467901

Epoch: 6| Step: 2
Training loss: 0.557712197303772
Validation loss: 2.002391130693497

Epoch: 6| Step: 3
Training loss: 0.7401409149169922
Validation loss: 2.0053764799589753

Epoch: 6| Step: 4
Training loss: 0.6969953775405884
Validation loss: 1.992033677716409

Epoch: 6| Step: 5
Training loss: 0.6511967182159424
Validation loss: 1.946972124038204

Epoch: 6| Step: 6
Training loss: 0.453660786151886
Validation loss: 1.9198919393682992

Epoch: 6| Step: 7
Training loss: 0.8079671859741211
Validation loss: 1.9054191650882844

Epoch: 6| Step: 8
Training loss: 0.8344253897666931
Validation loss: 1.877703066795103

Epoch: 6| Step: 9
Training loss: 0.7600702047348022
Validation loss: 1.892110668202882

Epoch: 6| Step: 10
Training loss: 0.6940633654594421
Validation loss: 1.89456739476932

Epoch: 6| Step: 11
Training loss: 1.0775344371795654
Validation loss: 1.8792695460780975

Epoch: 6| Step: 12
Training loss: 0.738234281539917
Validation loss: 1.9126057009543143

Epoch: 6| Step: 13
Training loss: 0.8077467679977417
Validation loss: 1.8960952720334452

Epoch: 270| Step: 0
Training loss: 0.5198200941085815
Validation loss: 1.9250906295673822

Epoch: 6| Step: 1
Training loss: 0.9582527279853821
Validation loss: 1.8931037354212936

Epoch: 6| Step: 2
Training loss: 1.1311922073364258
Validation loss: 1.8959866992888912

Epoch: 6| Step: 3
Training loss: 0.5833505392074585
Validation loss: 1.893056418306084

Epoch: 6| Step: 4
Training loss: 0.9191332459449768
Validation loss: 1.8915041377467494

Epoch: 6| Step: 5
Training loss: 0.6919087171554565
Validation loss: 1.8419165906085764

Epoch: 6| Step: 6
Training loss: 0.47174304723739624
Validation loss: 1.860414299913632

Epoch: 6| Step: 7
Training loss: 0.7907216548919678
Validation loss: 1.8476440393796532

Epoch: 6| Step: 8
Training loss: 0.7436828017234802
Validation loss: 1.8886966025957497

Epoch: 6| Step: 9
Training loss: 0.6645997762680054
Validation loss: 1.9545397579029042

Epoch: 6| Step: 10
Training loss: 0.7849770784378052
Validation loss: 2.0104792425709386

Epoch: 6| Step: 11
Training loss: 0.669673502445221
Validation loss: 2.0390353766820764

Epoch: 6| Step: 12
Training loss: 0.751934289932251
Validation loss: 2.0437937872384184

Epoch: 6| Step: 13
Training loss: 0.7175814509391785
Validation loss: 1.9932537245494064

Epoch: 271| Step: 0
Training loss: 0.7349110245704651
Validation loss: 1.971019951246118

Epoch: 6| Step: 1
Training loss: 0.4239053726196289
Validation loss: 1.9561353370707522

Epoch: 6| Step: 2
Training loss: 0.4604772627353668
Validation loss: 1.9381825718828427

Epoch: 6| Step: 3
Training loss: 0.6760644912719727
Validation loss: 1.918591522401379

Epoch: 6| Step: 4
Training loss: 0.9146798253059387
Validation loss: 1.9597330349747852

Epoch: 6| Step: 5
Training loss: 0.7223630547523499
Validation loss: 1.9763437445445726

Epoch: 6| Step: 6
Training loss: 0.8820852041244507
Validation loss: 1.9419872478772235

Epoch: 6| Step: 7
Training loss: 0.5815879702568054
Validation loss: 1.9008411822780487

Epoch: 6| Step: 8
Training loss: 0.8868715763092041
Validation loss: 1.9060950458690684

Epoch: 6| Step: 9
Training loss: 0.6939157247543335
Validation loss: 1.8719781034736223

Epoch: 6| Step: 10
Training loss: 0.5935835242271423
Validation loss: 1.8295078264769686

Epoch: 6| Step: 11
Training loss: 0.5015266537666321
Validation loss: 1.8585064462436143

Epoch: 6| Step: 12
Training loss: 0.7495537400245667
Validation loss: 1.8491586837717282

Epoch: 6| Step: 13
Training loss: 0.41649362444877625
Validation loss: 1.8336894435267295

Epoch: 272| Step: 0
Training loss: 1.0150266885757446
Validation loss: 1.8843756491138088

Epoch: 6| Step: 1
Training loss: 0.7452316284179688
Validation loss: 1.869732682422925

Epoch: 6| Step: 2
Training loss: 0.7226952314376831
Validation loss: 1.926310630254848

Epoch: 6| Step: 3
Training loss: 1.0910753011703491
Validation loss: 1.9504385225234493

Epoch: 6| Step: 4
Training loss: 0.5720738768577576
Validation loss: 1.9758459624423776

Epoch: 6| Step: 5
Training loss: 0.6448167562484741
Validation loss: 1.9209723318776777

Epoch: 6| Step: 6
Training loss: 0.4145295023918152
Validation loss: 1.9193182299214024

Epoch: 6| Step: 7
Training loss: 0.5114054679870605
Validation loss: 1.8894180354251657

Epoch: 6| Step: 8
Training loss: 0.44145703315734863
Validation loss: 1.9134721012525662

Epoch: 6| Step: 9
Training loss: 0.503216028213501
Validation loss: 1.8923552190103838

Epoch: 6| Step: 10
Training loss: 0.4798632860183716
Validation loss: 1.8580475263698126

Epoch: 6| Step: 11
Training loss: 1.029883861541748
Validation loss: 1.8563913747828493

Epoch: 6| Step: 12
Training loss: 0.5387664437294006
Validation loss: 1.850717129245881

Epoch: 6| Step: 13
Training loss: 0.39716508984565735
Validation loss: 1.82789635017354

Epoch: 273| Step: 0
Training loss: 0.6926655769348145
Validation loss: 1.8651935105682702

Epoch: 6| Step: 1
Training loss: 0.5436465740203857
Validation loss: 1.8249179599105672

Epoch: 6| Step: 2
Training loss: 0.7213265895843506
Validation loss: 1.8643234340093469

Epoch: 6| Step: 3
Training loss: 0.5146951675415039
Validation loss: 1.8691054979960124

Epoch: 6| Step: 4
Training loss: 0.6862599849700928
Validation loss: 1.831490300034964

Epoch: 6| Step: 5
Training loss: 1.0651206970214844
Validation loss: 1.8570687540115849

Epoch: 6| Step: 6
Training loss: 0.5222451686859131
Validation loss: 1.9385348250789027

Epoch: 6| Step: 7
Training loss: 0.505010724067688
Validation loss: 1.961576497682961

Epoch: 6| Step: 8
Training loss: 0.8384081721305847
Validation loss: 1.956677912383951

Epoch: 6| Step: 9
Training loss: 0.4120332598686218
Validation loss: 1.941176708026599

Epoch: 6| Step: 10
Training loss: 0.7255712747573853
Validation loss: 1.9111551238644509

Epoch: 6| Step: 11
Training loss: 0.4142359495162964
Validation loss: 1.8872091154898367

Epoch: 6| Step: 12
Training loss: 0.28648868203163147
Validation loss: 1.875784917544293

Epoch: 6| Step: 13
Training loss: 0.5679740905761719
Validation loss: 1.8841671007935719

Epoch: 274| Step: 0
Training loss: 0.403952956199646
Validation loss: 1.8802174034939017

Epoch: 6| Step: 1
Training loss: 0.8185982704162598
Validation loss: 1.9134629900737474

Epoch: 6| Step: 2
Training loss: 0.4346788823604584
Validation loss: 1.9041531201331847

Epoch: 6| Step: 3
Training loss: 0.45190703868865967
Validation loss: 1.9645839942398893

Epoch: 6| Step: 4
Training loss: 0.8345695734024048
Validation loss: 1.9464862013375888

Epoch: 6| Step: 5
Training loss: 0.73743736743927
Validation loss: 1.9827596936174618

Epoch: 6| Step: 6
Training loss: 0.6223621368408203
Validation loss: 2.034386493826425

Epoch: 6| Step: 7
Training loss: 0.6051905155181885
Validation loss: 2.0376880784188547

Epoch: 6| Step: 8
Training loss: 0.7924643754959106
Validation loss: 2.024304736045099

Epoch: 6| Step: 9
Training loss: 0.5532917976379395
Validation loss: 1.9692367430656188

Epoch: 6| Step: 10
Training loss: 0.4686358869075775
Validation loss: 1.967599964910938

Epoch: 6| Step: 11
Training loss: 0.4507904648780823
Validation loss: 1.9326201228685276

Epoch: 6| Step: 12
Training loss: 0.5629883408546448
Validation loss: 1.8911628787235548

Epoch: 6| Step: 13
Training loss: 0.8054805397987366
Validation loss: 1.8809140856548021

Epoch: 275| Step: 0
Training loss: 0.6683549284934998
Validation loss: 1.8568385160097511

Epoch: 6| Step: 1
Training loss: 0.5246484875679016
Validation loss: 1.8498460144125006

Epoch: 6| Step: 2
Training loss: 0.41135531663894653
Validation loss: 1.8326908388445455

Epoch: 6| Step: 3
Training loss: 0.33796077966690063
Validation loss: 1.871159856037427

Epoch: 6| Step: 4
Training loss: 0.8371955156326294
Validation loss: 1.8782104317859938

Epoch: 6| Step: 5
Training loss: 0.711866021156311
Validation loss: 1.8719378056064728

Epoch: 6| Step: 6
Training loss: 0.7910156846046448
Validation loss: 1.8307070680843887

Epoch: 6| Step: 7
Training loss: 0.6655932068824768
Validation loss: 1.8825470965395692

Epoch: 6| Step: 8
Training loss: 0.6794412732124329
Validation loss: 1.879188383779218

Epoch: 6| Step: 9
Training loss: 0.4642285704612732
Validation loss: 1.893929576361051

Epoch: 6| Step: 10
Training loss: 0.724631130695343
Validation loss: 1.8845360740538566

Epoch: 6| Step: 11
Training loss: 0.33354368805885315
Validation loss: 1.920005254848029

Epoch: 6| Step: 12
Training loss: 0.6878194808959961
Validation loss: 1.9284058629825551

Epoch: 6| Step: 13
Training loss: 0.4185596704483032
Validation loss: 1.9464198004814885

Epoch: 276| Step: 0
Training loss: 0.5156985521316528
Validation loss: 1.9176387171591482

Epoch: 6| Step: 1
Training loss: 0.7384677529335022
Validation loss: 1.8980999415920627

Epoch: 6| Step: 2
Training loss: 0.8071914911270142
Validation loss: 1.8309276885883783

Epoch: 6| Step: 3
Training loss: 0.2169533669948578
Validation loss: 1.8018079086016583

Epoch: 6| Step: 4
Training loss: 0.4179309904575348
Validation loss: 1.7861233090841642

Epoch: 6| Step: 5
Training loss: 0.7237409353256226
Validation loss: 1.8053087701079666

Epoch: 6| Step: 6
Training loss: 0.8030727505683899
Validation loss: 1.785395109525291

Epoch: 6| Step: 7
Training loss: 0.8444032073020935
Validation loss: 1.8191923095333962

Epoch: 6| Step: 8
Training loss: 0.46863144636154175
Validation loss: 1.840887414511814

Epoch: 6| Step: 9
Training loss: 0.31782424449920654
Validation loss: 1.884471877928703

Epoch: 6| Step: 10
Training loss: 0.5539542436599731
Validation loss: 1.9023283899471324

Epoch: 6| Step: 11
Training loss: 0.6249002814292908
Validation loss: 1.9060189890605148

Epoch: 6| Step: 12
Training loss: 0.5888218879699707
Validation loss: 1.8728585679044005

Epoch: 6| Step: 13
Training loss: 0.36998140811920166
Validation loss: 1.8491479260947115

Epoch: 277| Step: 0
Training loss: 0.41529035568237305
Validation loss: 1.8624249889004616

Epoch: 6| Step: 1
Training loss: 0.7859739065170288
Validation loss: 1.8591030336195422

Epoch: 6| Step: 2
Training loss: 0.40731632709503174
Validation loss: 1.8485331304611698

Epoch: 6| Step: 3
Training loss: 0.9210076332092285
Validation loss: 1.895952700286783

Epoch: 6| Step: 4
Training loss: 0.6732795238494873
Validation loss: 1.8624297803448093

Epoch: 6| Step: 5
Training loss: 0.5493156909942627
Validation loss: 1.886705296013945

Epoch: 6| Step: 6
Training loss: 0.5941415429115295
Validation loss: 1.9194810300744989

Epoch: 6| Step: 7
Training loss: 0.7754933834075928
Validation loss: 1.9116569975371003

Epoch: 6| Step: 8
Training loss: 0.40997135639190674
Validation loss: 1.9210598443144111

Epoch: 6| Step: 9
Training loss: 0.4671987295150757
Validation loss: 1.9224553928580335

Epoch: 6| Step: 10
Training loss: 0.5748400688171387
Validation loss: 1.9420752781693653

Epoch: 6| Step: 11
Training loss: 0.3636016249656677
Validation loss: 1.8936777211004687

Epoch: 6| Step: 12
Training loss: 0.6895953416824341
Validation loss: 1.891752762179221

Epoch: 6| Step: 13
Training loss: 0.3795353174209595
Validation loss: 1.8906186972894976

Epoch: 278| Step: 0
Training loss: 0.6865378618240356
Validation loss: 1.8686302502950032

Epoch: 6| Step: 1
Training loss: 0.6768345236778259
Validation loss: 1.8377440219284387

Epoch: 6| Step: 2
Training loss: 0.4425516128540039
Validation loss: 1.837328621136245

Epoch: 6| Step: 3
Training loss: 0.6003526449203491
Validation loss: 1.844654788253128

Epoch: 6| Step: 4
Training loss: 0.5962637662887573
Validation loss: 1.8486625840587

Epoch: 6| Step: 5
Training loss: 0.3787583112716675
Validation loss: 1.8566310354458389

Epoch: 6| Step: 6
Training loss: 0.8731375932693481
Validation loss: 1.887727898936118

Epoch: 6| Step: 7
Training loss: 0.6686488389968872
Validation loss: 1.8820449690664969

Epoch: 6| Step: 8
Training loss: 0.4938053488731384
Validation loss: 1.8823133040499944

Epoch: 6| Step: 9
Training loss: 0.8247491717338562
Validation loss: 1.8947948768574705

Epoch: 6| Step: 10
Training loss: 0.47982752323150635
Validation loss: 1.9379252823450233

Epoch: 6| Step: 11
Training loss: 0.2503730058670044
Validation loss: 1.9604971485753213

Epoch: 6| Step: 12
Training loss: 0.5434711575508118
Validation loss: 1.9471099825315579

Epoch: 6| Step: 13
Training loss: 0.5086120367050171
Validation loss: 2.0012775762106783

Epoch: 279| Step: 0
Training loss: 0.5474158525466919
Validation loss: 1.9943841913694977

Epoch: 6| Step: 1
Training loss: 0.3868740499019623
Validation loss: 1.9665549262877433

Epoch: 6| Step: 2
Training loss: 0.42739009857177734
Validation loss: 1.9816379380482498

Epoch: 6| Step: 3
Training loss: 0.40348997712135315
Validation loss: 1.9642941080113894

Epoch: 6| Step: 4
Training loss: 0.7638963460922241
Validation loss: 1.9731455772153792

Epoch: 6| Step: 5
Training loss: 0.5945443511009216
Validation loss: 1.9318168983664563

Epoch: 6| Step: 6
Training loss: 0.44967493414878845
Validation loss: 1.9520984580439906

Epoch: 6| Step: 7
Training loss: 0.8935714960098267
Validation loss: 1.9625325356760333

Epoch: 6| Step: 8
Training loss: 0.739845871925354
Validation loss: 1.9918996095657349

Epoch: 6| Step: 9
Training loss: 0.609401285648346
Validation loss: 1.9706238828679568

Epoch: 6| Step: 10
Training loss: 0.5180872678756714
Validation loss: 1.9772651592890422

Epoch: 6| Step: 11
Training loss: 0.3296172618865967
Validation loss: 1.9943232818316388

Epoch: 6| Step: 12
Training loss: 0.8617533445358276
Validation loss: 1.9791415916976107

Epoch: 6| Step: 13
Training loss: 0.3849281966686249
Validation loss: 1.888392061315557

Epoch: 280| Step: 0
Training loss: 0.9253502488136292
Validation loss: 1.8720868633639427

Epoch: 6| Step: 1
Training loss: 0.4461791217327118
Validation loss: 1.8874314933694818

Epoch: 6| Step: 2
Training loss: 0.6817505359649658
Validation loss: 1.8261466833852953

Epoch: 6| Step: 3
Training loss: 0.4275028109550476
Validation loss: 1.835323925941221

Epoch: 6| Step: 4
Training loss: 0.37553679943084717
Validation loss: 1.7901279900663642

Epoch: 6| Step: 5
Training loss: 0.45704370737075806
Validation loss: 1.835440904863419

Epoch: 6| Step: 6
Training loss: 0.51308274269104
Validation loss: 1.8645832179695048

Epoch: 6| Step: 7
Training loss: 0.3505086600780487
Validation loss: 1.8642273974675003

Epoch: 6| Step: 8
Training loss: 1.2208093404769897
Validation loss: 1.8186310414345033

Epoch: 6| Step: 9
Training loss: 0.49806976318359375
Validation loss: 1.7982410487308298

Epoch: 6| Step: 10
Training loss: 0.5461626052856445
Validation loss: 1.827016781735164

Epoch: 6| Step: 11
Training loss: 0.30445215106010437
Validation loss: 1.8027885229356828

Epoch: 6| Step: 12
Training loss: 0.7280381917953491
Validation loss: 1.8036917986408356

Epoch: 6| Step: 13
Training loss: 0.5682672262191772
Validation loss: 1.8607940186736405

Epoch: 281| Step: 0
Training loss: 0.3298720121383667
Validation loss: 1.8698484359248992

Epoch: 6| Step: 1
Training loss: 0.5972088575363159
Validation loss: 1.8846739543381559

Epoch: 6| Step: 2
Training loss: 0.5003598928451538
Validation loss: 1.92276168382296

Epoch: 6| Step: 3
Training loss: 0.6723875403404236
Validation loss: 1.9179540603391585

Epoch: 6| Step: 4
Training loss: 0.49754270911216736
Validation loss: 1.94001373680689

Epoch: 6| Step: 5
Training loss: 0.7846484184265137
Validation loss: 1.9437511479982765

Epoch: 6| Step: 6
Training loss: 0.6339296102523804
Validation loss: 1.9674807120394964

Epoch: 6| Step: 7
Training loss: 0.6052929162979126
Validation loss: 1.9758853425261795

Epoch: 6| Step: 8
Training loss: 0.49973148107528687
Validation loss: 1.979547627510563

Epoch: 6| Step: 9
Training loss: 0.6937204599380493
Validation loss: 1.9279376153023011

Epoch: 6| Step: 10
Training loss: 0.7642687559127808
Validation loss: 1.8534438904895578

Epoch: 6| Step: 11
Training loss: 0.6061153411865234
Validation loss: 1.8608605348935692

Epoch: 6| Step: 12
Training loss: 0.341962605714798
Validation loss: 1.8571122948841383

Epoch: 6| Step: 13
Training loss: 0.3707233667373657
Validation loss: 1.8486752125524706

Epoch: 282| Step: 0
Training loss: 0.40308088064193726
Validation loss: 1.8461445223900579

Epoch: 6| Step: 1
Training loss: 0.8274598121643066
Validation loss: 1.8611902267702165

Epoch: 6| Step: 2
Training loss: 0.4679776132106781
Validation loss: 1.8495766642273113

Epoch: 6| Step: 3
Training loss: 0.9961912035942078
Validation loss: 1.8936935176131546

Epoch: 6| Step: 4
Training loss: 0.572264552116394
Validation loss: 1.8987358603426205

Epoch: 6| Step: 5
Training loss: 0.6890380382537842
Validation loss: 1.9379976257201164

Epoch: 6| Step: 6
Training loss: 0.45732760429382324
Validation loss: 1.9043840977453417

Epoch: 6| Step: 7
Training loss: 0.6808298230171204
Validation loss: 1.9068563035739365

Epoch: 6| Step: 8
Training loss: 0.5107175707817078
Validation loss: 1.8863244479702366

Epoch: 6| Step: 9
Training loss: 0.6683946847915649
Validation loss: 1.875957045503842

Epoch: 6| Step: 10
Training loss: 0.3005509376525879
Validation loss: 1.8646505571180774

Epoch: 6| Step: 11
Training loss: 0.46184080839157104
Validation loss: 1.8735267833996845

Epoch: 6| Step: 12
Training loss: 0.33468151092529297
Validation loss: 1.8620404120414489

Epoch: 6| Step: 13
Training loss: 0.5988708138465881
Validation loss: 1.865197257329059

Epoch: 283| Step: 0
Training loss: 0.47274333238601685
Validation loss: 1.9084175940482848

Epoch: 6| Step: 1
Training loss: 0.455841600894928
Validation loss: 1.8925913803039058

Epoch: 6| Step: 2
Training loss: 0.7837667465209961
Validation loss: 1.887451446184548

Epoch: 6| Step: 3
Training loss: 0.733169674873352
Validation loss: 1.8684616524686095

Epoch: 6| Step: 4
Training loss: 0.7010069489479065
Validation loss: 1.8714092187984015

Epoch: 6| Step: 5
Training loss: 0.36614686250686646
Validation loss: 1.8219684221411263

Epoch: 6| Step: 6
Training loss: 0.46791425347328186
Validation loss: 1.821736434454559

Epoch: 6| Step: 7
Training loss: 0.3031548857688904
Validation loss: 1.870200680148217

Epoch: 6| Step: 8
Training loss: 0.3219243288040161
Validation loss: 1.8537399576556297

Epoch: 6| Step: 9
Training loss: 0.4235539436340332
Validation loss: 1.9095583551673478

Epoch: 6| Step: 10
Training loss: 0.6022424101829529
Validation loss: 1.9244466840579946

Epoch: 6| Step: 11
Training loss: 1.0427608489990234
Validation loss: 1.9425094768565188

Epoch: 6| Step: 12
Training loss: 0.7892661690711975
Validation loss: 1.9547933045253958

Epoch: 6| Step: 13
Training loss: 0.15269409120082855
Validation loss: 1.8698550014085666

Epoch: 284| Step: 0
Training loss: 0.3655932545661926
Validation loss: 1.8539725721523326

Epoch: 6| Step: 1
Training loss: 0.7793905735015869
Validation loss: 1.8072932317692747

Epoch: 6| Step: 2
Training loss: 0.3632558584213257
Validation loss: 1.82668335207047

Epoch: 6| Step: 3
Training loss: 0.8191111087799072
Validation loss: 1.810544994569594

Epoch: 6| Step: 4
Training loss: 0.3850165605545044
Validation loss: 1.8087412362457604

Epoch: 6| Step: 5
Training loss: 0.5780671834945679
Validation loss: 1.8114175617053945

Epoch: 6| Step: 6
Training loss: 0.7367361783981323
Validation loss: 1.8528680083572224

Epoch: 6| Step: 7
Training loss: 0.36182165145874023
Validation loss: 1.8882343807528097

Epoch: 6| Step: 8
Training loss: 0.5426316261291504
Validation loss: 1.920143191532422

Epoch: 6| Step: 9
Training loss: 0.6965681314468384
Validation loss: 1.9432586751958376

Epoch: 6| Step: 10
Training loss: 0.4943896532058716
Validation loss: 1.9572500195554507

Epoch: 6| Step: 11
Training loss: 0.586359441280365
Validation loss: 1.9923153077402422

Epoch: 6| Step: 12
Training loss: 0.6430687308311462
Validation loss: 1.9965752888751287

Epoch: 6| Step: 13
Training loss: 0.2831258177757263
Validation loss: 1.9931296712608748

Epoch: 285| Step: 0
Training loss: 0.30741196870803833
Validation loss: 1.9633742506786058

Epoch: 6| Step: 1
Training loss: 0.5248744487762451
Validation loss: 1.9293290799663914

Epoch: 6| Step: 2
Training loss: 0.6833281517028809
Validation loss: 2.0209260268877913

Epoch: 6| Step: 3
Training loss: 0.5872761011123657
Validation loss: 2.0085055905003704

Epoch: 6| Step: 4
Training loss: 0.5181134939193726
Validation loss: 1.9432709396526378

Epoch: 6| Step: 5
Training loss: 0.4059484601020813
Validation loss: 1.9543724829150784

Epoch: 6| Step: 6
Training loss: 0.572516918182373
Validation loss: 1.9082020380163704

Epoch: 6| Step: 7
Training loss: 0.3558303415775299
Validation loss: 1.8227602102423226

Epoch: 6| Step: 8
Training loss: 0.6301950216293335
Validation loss: 1.8077581954258743

Epoch: 6| Step: 9
Training loss: 0.8723684549331665
Validation loss: 1.8081142915192472

Epoch: 6| Step: 10
Training loss: 0.5355677604675293
Validation loss: 1.811441393308742

Epoch: 6| Step: 11
Training loss: 0.3257036805152893
Validation loss: 1.842230349458674

Epoch: 6| Step: 12
Training loss: 0.4392121732234955
Validation loss: 1.8436971402937365

Epoch: 6| Step: 13
Training loss: 0.4147416353225708
Validation loss: 1.8764855246390066

Epoch: 286| Step: 0
Training loss: 0.5570592880249023
Validation loss: 1.9273739924994848

Epoch: 6| Step: 1
Training loss: 0.512202799320221
Validation loss: 1.9729198640392673

Epoch: 6| Step: 2
Training loss: 0.6554656028747559
Validation loss: 2.0364173509741343

Epoch: 6| Step: 3
Training loss: 0.7917582988739014
Validation loss: 2.0397035485954693

Epoch: 6| Step: 4
Training loss: 0.3166424632072449
Validation loss: 2.017268265447309

Epoch: 6| Step: 5
Training loss: 0.5135714411735535
Validation loss: 1.9870946920046242

Epoch: 6| Step: 6
Training loss: 0.6755708456039429
Validation loss: 1.943503886140803

Epoch: 6| Step: 7
Training loss: 0.4215758144855499
Validation loss: 1.8518933121876051

Epoch: 6| Step: 8
Training loss: 0.6969081163406372
Validation loss: 1.8365084766059794

Epoch: 6| Step: 9
Training loss: 0.8749110102653503
Validation loss: 1.8095213495275027

Epoch: 6| Step: 10
Training loss: 0.4559416174888611
Validation loss: 1.791313648223877

Epoch: 6| Step: 11
Training loss: 0.6022900938987732
Validation loss: 1.8061430402981338

Epoch: 6| Step: 12
Training loss: 0.3346386253833771
Validation loss: 1.7823152003749725

Epoch: 6| Step: 13
Training loss: 0.2569825351238251
Validation loss: 1.8394631416566911

Epoch: 287| Step: 0
Training loss: 0.3495607376098633
Validation loss: 1.8181200976012855

Epoch: 6| Step: 1
Training loss: 0.2928454875946045
Validation loss: 1.8428483060611192

Epoch: 6| Step: 2
Training loss: 0.2605340778827667
Validation loss: 1.88457259567835

Epoch: 6| Step: 3
Training loss: 0.7058990001678467
Validation loss: 1.8990737263874342

Epoch: 6| Step: 4
Training loss: 0.36140912771224976
Validation loss: 1.9449423487468431

Epoch: 6| Step: 5
Training loss: 0.9106259942054749
Validation loss: 1.9406418390171503

Epoch: 6| Step: 6
Training loss: 0.5015525817871094
Validation loss: 1.8988097265202513

Epoch: 6| Step: 7
Training loss: 0.42340710759162903
Validation loss: 1.931637389685518

Epoch: 6| Step: 8
Training loss: 0.7245965600013733
Validation loss: 1.8956710728265906

Epoch: 6| Step: 9
Training loss: 0.5096096396446228
Validation loss: 1.8807997011369275

Epoch: 6| Step: 10
Training loss: 0.6336199045181274
Validation loss: 1.854198996738721

Epoch: 6| Step: 11
Training loss: 0.766115128993988
Validation loss: 1.814047348114752

Epoch: 6| Step: 12
Training loss: 0.47601181268692017
Validation loss: 1.816449135862371

Epoch: 6| Step: 13
Training loss: 0.5119462609291077
Validation loss: 1.7820264216392272

Epoch: 288| Step: 0
Training loss: 1.0893871784210205
Validation loss: 1.7886728522598103

Epoch: 6| Step: 1
Training loss: 0.6723136901855469
Validation loss: 1.8014154741840978

Epoch: 6| Step: 2
Training loss: 0.6442317962646484
Validation loss: 1.799675387720908

Epoch: 6| Step: 3
Training loss: 0.43789494037628174
Validation loss: 1.8462878747652935

Epoch: 6| Step: 4
Training loss: 0.3942374289035797
Validation loss: 1.8451709183313514

Epoch: 6| Step: 5
Training loss: 0.4788561463356018
Validation loss: 1.8729803562164307

Epoch: 6| Step: 6
Training loss: 0.44600409269332886
Validation loss: 1.8358983647438787

Epoch: 6| Step: 7
Training loss: 0.44363176822662354
Validation loss: 1.8378272344989162

Epoch: 6| Step: 8
Training loss: 0.48800763487815857
Validation loss: 1.882291232385943

Epoch: 6| Step: 9
Training loss: 0.49730974435806274
Validation loss: 1.8291812378873107

Epoch: 6| Step: 10
Training loss: 0.4190811514854431
Validation loss: 1.8653298142135784

Epoch: 6| Step: 11
Training loss: 0.6228163242340088
Validation loss: 1.8533686412278043

Epoch: 6| Step: 12
Training loss: 0.3145905137062073
Validation loss: 1.8455960622397802

Epoch: 6| Step: 13
Training loss: 0.6872353553771973
Validation loss: 1.8648720146507345

Epoch: 289| Step: 0
Training loss: 0.6547894477844238
Validation loss: 1.8279455720737416

Epoch: 6| Step: 1
Training loss: 0.5058860182762146
Validation loss: 1.8023123305330995

Epoch: 6| Step: 2
Training loss: 0.578549325466156
Validation loss: 1.8122050121266355

Epoch: 6| Step: 3
Training loss: 0.27740156650543213
Validation loss: 1.819686189774544

Epoch: 6| Step: 4
Training loss: 0.49263203144073486
Validation loss: 1.880493522972189

Epoch: 6| Step: 5
Training loss: 0.7000795006752014
Validation loss: 1.8653179343028734

Epoch: 6| Step: 6
Training loss: 0.3489186465740204
Validation loss: 1.867367588063722

Epoch: 6| Step: 7
Training loss: 0.16054873168468475
Validation loss: 1.8473899723381124

Epoch: 6| Step: 8
Training loss: 0.6685184240341187
Validation loss: 1.8313966630607523

Epoch: 6| Step: 9
Training loss: 0.49720582365989685
Validation loss: 1.8699653635742843

Epoch: 6| Step: 10
Training loss: 0.9098103046417236
Validation loss: 1.8456176903940016

Epoch: 6| Step: 11
Training loss: 0.520313024520874
Validation loss: 1.840945762972678

Epoch: 6| Step: 12
Training loss: 0.6376622915267944
Validation loss: 1.8555804068042385

Epoch: 6| Step: 13
Training loss: 0.3248752951622009
Validation loss: 1.8339985814145816

Epoch: 290| Step: 0
Training loss: 0.47381818294525146
Validation loss: 1.8507110149629655

Epoch: 6| Step: 1
Training loss: 0.515487015247345
Validation loss: 1.8677021508575768

Epoch: 6| Step: 2
Training loss: 0.3758627772331238
Validation loss: 1.8516660262179632

Epoch: 6| Step: 3
Training loss: 0.5627988576889038
Validation loss: 1.863324660126881

Epoch: 6| Step: 4
Training loss: 0.4512709975242615
Validation loss: 1.8879948623718754

Epoch: 6| Step: 5
Training loss: 0.5220561027526855
Validation loss: 1.846297517899544

Epoch: 6| Step: 6
Training loss: 0.4504144489765167
Validation loss: 1.856124354946998

Epoch: 6| Step: 7
Training loss: 0.9009091854095459
Validation loss: 1.8388202613399875

Epoch: 6| Step: 8
Training loss: 0.4132291376590729
Validation loss: 1.8109667172995947

Epoch: 6| Step: 9
Training loss: 0.17585934698581696
Validation loss: 1.8215855039576048

Epoch: 6| Step: 10
Training loss: 0.6031939387321472
Validation loss: 1.8118980353878391

Epoch: 6| Step: 11
Training loss: 0.5766498446464539
Validation loss: 1.7574517201351862

Epoch: 6| Step: 12
Training loss: 0.4914467930793762
Validation loss: 1.78426904191253

Epoch: 6| Step: 13
Training loss: 0.5430083870887756
Validation loss: 1.7713257010265062

Epoch: 291| Step: 0
Training loss: 0.5935784578323364
Validation loss: 1.8339144581107683

Epoch: 6| Step: 1
Training loss: 0.4799115061759949
Validation loss: 1.8057626537097398

Epoch: 6| Step: 2
Training loss: 0.374572217464447
Validation loss: 1.824520843003386

Epoch: 6| Step: 3
Training loss: 0.6047541499137878
Validation loss: 1.8622283320273123

Epoch: 6| Step: 4
Training loss: 0.31962454319000244
Validation loss: 1.8492484297803653

Epoch: 6| Step: 5
Training loss: 0.7278503179550171
Validation loss: 1.8758149531579786

Epoch: 6| Step: 6
Training loss: 0.46311840415000916
Validation loss: 1.8517870736378494

Epoch: 6| Step: 7
Training loss: 0.4494766592979431
Validation loss: 1.883033226895076

Epoch: 6| Step: 8
Training loss: 0.3912029564380646
Validation loss: 1.8801241638839885

Epoch: 6| Step: 9
Training loss: 0.22263197600841522
Validation loss: 1.8707316357602355

Epoch: 6| Step: 10
Training loss: 0.8205779194831848
Validation loss: 1.8445458437806816

Epoch: 6| Step: 11
Training loss: 0.6698433756828308
Validation loss: 1.8171478881630847

Epoch: 6| Step: 12
Training loss: 0.4289848804473877
Validation loss: 1.7641976059124034

Epoch: 6| Step: 13
Training loss: 0.4498116075992584
Validation loss: 1.8050361012899747

Epoch: 292| Step: 0
Training loss: 0.4444994628429413
Validation loss: 1.7879742050683627

Epoch: 6| Step: 1
Training loss: 0.5938102006912231
Validation loss: 1.8242049524860997

Epoch: 6| Step: 2
Training loss: 0.5341001749038696
Validation loss: 1.861022969727875

Epoch: 6| Step: 3
Training loss: 0.42461177706718445
Validation loss: 1.8363166111771778

Epoch: 6| Step: 4
Training loss: 0.5699777603149414
Validation loss: 1.8945015322777532

Epoch: 6| Step: 5
Training loss: 0.5323457717895508
Validation loss: 1.8981318576361543

Epoch: 6| Step: 6
Training loss: 0.7438977956771851
Validation loss: 1.866560552709846

Epoch: 6| Step: 7
Training loss: 0.5602397918701172
Validation loss: 1.8516635279501639

Epoch: 6| Step: 8
Training loss: 0.4191397428512573
Validation loss: 1.8336447861886793

Epoch: 6| Step: 9
Training loss: 0.5501514077186584
Validation loss: 1.8459205704350625

Epoch: 6| Step: 10
Training loss: 0.8170016407966614
Validation loss: 1.8441499343482397

Epoch: 6| Step: 11
Training loss: 0.4442041516304016
Validation loss: 1.8491854590754355

Epoch: 6| Step: 12
Training loss: 0.4996767044067383
Validation loss: 1.8607170863818097

Epoch: 6| Step: 13
Training loss: 0.15058963000774384
Validation loss: 1.853739002699493

Epoch: 293| Step: 0
Training loss: 0.5200784802436829
Validation loss: 1.8881469580434984

Epoch: 6| Step: 1
Training loss: 0.36217087507247925
Validation loss: 1.8727999246248634

Epoch: 6| Step: 2
Training loss: 0.18011951446533203
Validation loss: 1.87929335717232

Epoch: 6| Step: 3
Training loss: 0.9994307160377502
Validation loss: 1.8194634414488269

Epoch: 6| Step: 4
Training loss: 0.7742621898651123
Validation loss: 1.8025951590589298

Epoch: 6| Step: 5
Training loss: 0.5727869868278503
Validation loss: 1.8055024236761115

Epoch: 6| Step: 6
Training loss: 0.4459553360939026
Validation loss: 1.782702947175631

Epoch: 6| Step: 7
Training loss: 0.7071446180343628
Validation loss: 1.798366537658117

Epoch: 6| Step: 8
Training loss: 0.28240543603897095
Validation loss: 1.78081174050608

Epoch: 6| Step: 9
Training loss: 0.5758447647094727
Validation loss: 1.8159067130857898

Epoch: 6| Step: 10
Training loss: 0.39514219760894775
Validation loss: 1.826163500867864

Epoch: 6| Step: 11
Training loss: 0.2904284596443176
Validation loss: 1.867381344559372

Epoch: 6| Step: 12
Training loss: 0.5452815890312195
Validation loss: 1.9177702678147184

Epoch: 6| Step: 13
Training loss: 0.46868664026260376
Validation loss: 1.964963105417067

Epoch: 294| Step: 0
Training loss: 0.49002888798713684
Validation loss: 1.9714094643951745

Epoch: 6| Step: 1
Training loss: 0.5136516690254211
Validation loss: 1.9941917875761628

Epoch: 6| Step: 2
Training loss: 0.4082726240158081
Validation loss: 1.973893178406582

Epoch: 6| Step: 3
Training loss: 0.5723561644554138
Validation loss: 1.873613626726212

Epoch: 6| Step: 4
Training loss: 0.23218360543251038
Validation loss: 1.8295969834891699

Epoch: 6| Step: 5
Training loss: 0.7869125008583069
Validation loss: 1.776067062090802

Epoch: 6| Step: 6
Training loss: 0.5140681266784668
Validation loss: 1.750063992315723

Epoch: 6| Step: 7
Training loss: 0.36802005767822266
Validation loss: 1.7548000158802155

Epoch: 6| Step: 8
Training loss: 0.5904896259307861
Validation loss: 1.747410992140411

Epoch: 6| Step: 9
Training loss: 0.8162786364555359
Validation loss: 1.7450505661708053

Epoch: 6| Step: 10
Training loss: 0.3232935070991516
Validation loss: 1.7588888470844557

Epoch: 6| Step: 11
Training loss: 0.3428729474544525
Validation loss: 1.802806797847953

Epoch: 6| Step: 12
Training loss: 0.5103379487991333
Validation loss: 1.8250728396959202

Epoch: 6| Step: 13
Training loss: 1.1845510005950928
Validation loss: 1.915930163475775

Epoch: 295| Step: 0
Training loss: 0.45855018496513367
Validation loss: 1.9369075772582844

Epoch: 6| Step: 1
Training loss: 0.5859410762786865
Validation loss: 1.9798663188052434

Epoch: 6| Step: 2
Training loss: 0.7948739528656006
Validation loss: 1.9532127829008206

Epoch: 6| Step: 3
Training loss: 0.4759249687194824
Validation loss: 1.8725386768259027

Epoch: 6| Step: 4
Training loss: 0.46351730823516846
Validation loss: 1.854623766355617

Epoch: 6| Step: 5
Training loss: 0.24290874600410461
Validation loss: 1.8061956308221305

Epoch: 6| Step: 6
Training loss: 0.6681331992149353
Validation loss: 1.7666284486811648

Epoch: 6| Step: 7
Training loss: 0.3107861876487732
Validation loss: 1.746429148540702

Epoch: 6| Step: 8
Training loss: 0.5141838788986206
Validation loss: 1.7175292994386406

Epoch: 6| Step: 9
Training loss: 0.5693158507347107
Validation loss: 1.775238754928753

Epoch: 6| Step: 10
Training loss: 0.3815430700778961
Validation loss: 1.788379205170498

Epoch: 6| Step: 11
Training loss: 0.5296295285224915
Validation loss: 1.8611158888827088

Epoch: 6| Step: 12
Training loss: 0.3882426917552948
Validation loss: 1.8912483671660065

Epoch: 6| Step: 13
Training loss: 1.2426199913024902
Validation loss: 1.96909930757297

Epoch: 296| Step: 0
Training loss: 0.6195313334465027
Validation loss: 1.9631852693455194

Epoch: 6| Step: 1
Training loss: 0.42812633514404297
Validation loss: 1.941148063187958

Epoch: 6| Step: 2
Training loss: 0.3906182646751404
Validation loss: 1.9223010604099562

Epoch: 6| Step: 3
Training loss: 0.41159290075302124
Validation loss: 1.893665526502876

Epoch: 6| Step: 4
Training loss: 0.28298506140708923
Validation loss: 1.917653586274834

Epoch: 6| Step: 5
Training loss: 0.37994587421417236
Validation loss: 1.8996771702202417

Epoch: 6| Step: 6
Training loss: 0.48140662908554077
Validation loss: 1.9185977405117405

Epoch: 6| Step: 7
Training loss: 0.8306714296340942
Validation loss: 1.8893613148761053

Epoch: 6| Step: 8
Training loss: 0.700678825378418
Validation loss: 1.9366038294248684

Epoch: 6| Step: 9
Training loss: 0.674223780632019
Validation loss: 1.8950231613651398

Epoch: 6| Step: 10
Training loss: 0.3518672585487366
Validation loss: 1.8944205750701248

Epoch: 6| Step: 11
Training loss: 0.6755101680755615
Validation loss: 1.8327969094758392

Epoch: 6| Step: 12
Training loss: 0.28141719102859497
Validation loss: 1.830490742960284

Epoch: 6| Step: 13
Training loss: 0.3751879632472992
Validation loss: 1.8050810034557054

Epoch: 297| Step: 0
Training loss: 0.37743842601776123
Validation loss: 1.7961891197389173

Epoch: 6| Step: 1
Training loss: 0.44967910647392273
Validation loss: 1.7871942033049881

Epoch: 6| Step: 2
Training loss: 0.528693675994873
Validation loss: 1.8405106170203096

Epoch: 6| Step: 3
Training loss: 0.4588448405265808
Validation loss: 1.8235174045767835

Epoch: 6| Step: 4
Training loss: 0.4839267134666443
Validation loss: 1.8344443792937903

Epoch: 6| Step: 5
Training loss: 0.24710044264793396
Validation loss: 1.8488414582385813

Epoch: 6| Step: 6
Training loss: 0.49334394931793213
Validation loss: 1.9017980534543273

Epoch: 6| Step: 7
Training loss: 0.35775548219680786
Validation loss: 1.943175313293293

Epoch: 6| Step: 8
Training loss: 0.5144232511520386
Validation loss: 1.951312659889139

Epoch: 6| Step: 9
Training loss: 0.9879620671272278
Validation loss: 1.9657378786353654

Epoch: 6| Step: 10
Training loss: 0.29184526205062866
Validation loss: 1.9854919807885283

Epoch: 6| Step: 11
Training loss: 0.670049786567688
Validation loss: 1.9889510267524309

Epoch: 6| Step: 12
Training loss: 0.3426343500614166
Validation loss: 1.9704367909380185

Epoch: 6| Step: 13
Training loss: 0.35519373416900635
Validation loss: 1.9714124177091865

Epoch: 298| Step: 0
Training loss: 0.6321686506271362
Validation loss: 1.9254097374536658

Epoch: 6| Step: 1
Training loss: 0.4829067587852478
Validation loss: 1.891272291060417

Epoch: 6| Step: 2
Training loss: 0.4316626787185669
Validation loss: 1.9119003947063158

Epoch: 6| Step: 3
Training loss: 0.6130857467651367
Validation loss: 1.8736197769000966

Epoch: 6| Step: 4
Training loss: 0.26311349868774414
Validation loss: 1.832681643065586

Epoch: 6| Step: 5
Training loss: 0.4042901396751404
Validation loss: 1.8437037801229825

Epoch: 6| Step: 6
Training loss: 0.9682204127311707
Validation loss: 1.807109163653466

Epoch: 6| Step: 7
Training loss: 0.4624938666820526
Validation loss: 1.8327881777158348

Epoch: 6| Step: 8
Training loss: 0.3080313205718994
Validation loss: 1.7724461017116424

Epoch: 6| Step: 9
Training loss: 0.44772082567214966
Validation loss: 1.8270552414719776

Epoch: 6| Step: 10
Training loss: 0.40170109272003174
Validation loss: 1.8433544571681688

Epoch: 6| Step: 11
Training loss: 0.3221738934516907
Validation loss: 1.8528393186548704

Epoch: 6| Step: 12
Training loss: 0.6173536777496338
Validation loss: 1.8429742397800568

Epoch: 6| Step: 13
Training loss: 0.4363076388835907
Validation loss: 1.8926569928405106

Epoch: 299| Step: 0
Training loss: 0.5847795009613037
Validation loss: 1.883647382900279

Epoch: 6| Step: 1
Training loss: 0.4644409418106079
Validation loss: 1.844904556069323

Epoch: 6| Step: 2
Training loss: 0.27819496393203735
Validation loss: 1.8590151186912292

Epoch: 6| Step: 3
Training loss: 0.23781387507915497
Validation loss: 1.8245047856402654

Epoch: 6| Step: 4
Training loss: 0.4271748661994934
Validation loss: 1.8395969239614343

Epoch: 6| Step: 5
Training loss: 0.3838944435119629
Validation loss: 1.8604836463928223

Epoch: 6| Step: 6
Training loss: 0.3880983293056488
Validation loss: 1.83270638860682

Epoch: 6| Step: 7
Training loss: 0.38173627853393555
Validation loss: 1.8804157613426127

Epoch: 6| Step: 8
Training loss: 0.6365536451339722
Validation loss: 1.8866390515399236

Epoch: 6| Step: 9
Training loss: 0.4003143012523651
Validation loss: 1.8915543146030878

Epoch: 6| Step: 10
Training loss: 0.8360223174095154
Validation loss: 1.8836496773586477

Epoch: 6| Step: 11
Training loss: 0.23938071727752686
Validation loss: 1.8579506771538847

Epoch: 6| Step: 12
Training loss: 0.5880511403083801
Validation loss: 1.8307885636565506

Epoch: 6| Step: 13
Training loss: 0.2541181445121765
Validation loss: 1.7844599498215543

Epoch: 300| Step: 0
Training loss: 0.2692584991455078
Validation loss: 1.7967044473976217

Epoch: 6| Step: 1
Training loss: 0.7731315493583679
Validation loss: 1.796376779515256

Epoch: 6| Step: 2
Training loss: 0.49352291226387024
Validation loss: 1.821920867889158

Epoch: 6| Step: 3
Training loss: 0.6146800518035889
Validation loss: 1.7929182385885587

Epoch: 6| Step: 4
Training loss: 0.3159976005554199
Validation loss: 1.8336423468846146

Epoch: 6| Step: 5
Training loss: 0.6829264163970947
Validation loss: 1.8001751720264394

Epoch: 6| Step: 6
Training loss: 0.3272794783115387
Validation loss: 1.8457139256179973

Epoch: 6| Step: 7
Training loss: 0.3173332214355469
Validation loss: 1.8370710419070335

Epoch: 6| Step: 8
Training loss: 0.5286592245101929
Validation loss: 1.864824712917369

Epoch: 6| Step: 9
Training loss: 0.31410229206085205
Validation loss: 1.8265736103057861

Epoch: 6| Step: 10
Training loss: 0.4392206072807312
Validation loss: 1.8535902961607902

Epoch: 6| Step: 11
Training loss: 0.3715248703956604
Validation loss: 1.856575685162698

Epoch: 6| Step: 12
Training loss: 0.31774789094924927
Validation loss: 1.8203898040197228

Epoch: 6| Step: 13
Training loss: 0.4467911124229431
Validation loss: 1.819460134352407

Epoch: 301| Step: 0
Training loss: 0.34155040979385376
Validation loss: 1.790623035482181

Epoch: 6| Step: 1
Training loss: 0.5693790912628174
Validation loss: 1.8223844305161507

Epoch: 6| Step: 2
Training loss: 0.30470991134643555
Validation loss: 1.815684937661694

Epoch: 6| Step: 3
Training loss: 0.3160158097743988
Validation loss: 1.8353133214417325

Epoch: 6| Step: 4
Training loss: 0.4538302421569824
Validation loss: 1.8639319609570246

Epoch: 6| Step: 5
Training loss: 0.3007696270942688
Validation loss: 1.8656116044649513

Epoch: 6| Step: 6
Training loss: 0.8750225305557251
Validation loss: 1.8586800611147316

Epoch: 6| Step: 7
Training loss: 0.4252166152000427
Validation loss: 1.8919245055926743

Epoch: 6| Step: 8
Training loss: 0.5417126417160034
Validation loss: 1.8518355072185557

Epoch: 6| Step: 9
Training loss: 0.3143801689147949
Validation loss: 1.845134961989618

Epoch: 6| Step: 10
Training loss: 0.2974328398704529
Validation loss: 1.8592083761768956

Epoch: 6| Step: 11
Training loss: 0.6074033379554749
Validation loss: 1.8860995359318231

Epoch: 6| Step: 12
Training loss: 0.5860901474952698
Validation loss: 1.8237851896593649

Epoch: 6| Step: 13
Training loss: 0.2798595130443573
Validation loss: 1.8353051754736132

Epoch: 302| Step: 0
Training loss: 0.22034069895744324
Validation loss: 1.8148040822757188

Epoch: 6| Step: 1
Training loss: 0.29177677631378174
Validation loss: 1.8037978782448718

Epoch: 6| Step: 2
Training loss: 0.39432114362716675
Validation loss: 1.8302659834584882

Epoch: 6| Step: 3
Training loss: 0.5413551330566406
Validation loss: 1.805820195905624

Epoch: 6| Step: 4
Training loss: 0.5125342607498169
Validation loss: 1.8484464332621584

Epoch: 6| Step: 5
Training loss: 0.6632348299026489
Validation loss: 1.8095606719293902

Epoch: 6| Step: 6
Training loss: 0.4748968780040741
Validation loss: 1.8487715554493729

Epoch: 6| Step: 7
Training loss: 0.30453383922576904
Validation loss: 1.7757943714818647

Epoch: 6| Step: 8
Training loss: 0.6954768896102905
Validation loss: 1.8351913203475296

Epoch: 6| Step: 9
Training loss: 0.38135743141174316
Validation loss: 1.855187718586255

Epoch: 6| Step: 10
Training loss: 0.4140024781227112
Validation loss: 1.8413530626604635

Epoch: 6| Step: 11
Training loss: 0.4980866312980652
Validation loss: 1.8357301604363225

Epoch: 6| Step: 12
Training loss: 0.3581142723560333
Validation loss: 1.84916014312416

Epoch: 6| Step: 13
Training loss: 0.5121169686317444
Validation loss: 1.8108077869620374

Epoch: 303| Step: 0
Training loss: 0.6382063031196594
Validation loss: 1.8129698243192447

Epoch: 6| Step: 1
Training loss: 0.35238730907440186
Validation loss: 1.7934548213917723

Epoch: 6| Step: 2
Training loss: 0.5018476247787476
Validation loss: 1.792782022107032

Epoch: 6| Step: 3
Training loss: 0.502086877822876
Validation loss: 1.8150810926191268

Epoch: 6| Step: 4
Training loss: 0.8305802345275879
Validation loss: 1.8040876106549335

Epoch: 6| Step: 5
Training loss: 0.3346050977706909
Validation loss: 1.781913815006133

Epoch: 6| Step: 6
Training loss: 0.401750385761261
Validation loss: 1.7890024761999808

Epoch: 6| Step: 7
Training loss: 0.5523365139961243
Validation loss: 1.7988571838666034

Epoch: 6| Step: 8
Training loss: 0.42559728026390076
Validation loss: 1.7814085637369463

Epoch: 6| Step: 9
Training loss: 0.4464486241340637
Validation loss: 1.8072167865691646

Epoch: 6| Step: 10
Training loss: 0.3030080497264862
Validation loss: 1.8292217100820234

Epoch: 6| Step: 11
Training loss: 0.4383260905742645
Validation loss: 1.868327538172404

Epoch: 6| Step: 12
Training loss: 0.439344584941864
Validation loss: 1.8601732894938479

Epoch: 6| Step: 13
Training loss: 0.4355425536632538
Validation loss: 1.8746654128515592

Epoch: 304| Step: 0
Training loss: 0.4321707785129547
Validation loss: 1.8604489590532036

Epoch: 6| Step: 1
Training loss: 0.5084933042526245
Validation loss: 1.838100573068024

Epoch: 6| Step: 2
Training loss: 0.36514854431152344
Validation loss: 1.827078801329418

Epoch: 6| Step: 3
Training loss: 0.4523381292819977
Validation loss: 1.785683520378605

Epoch: 6| Step: 4
Training loss: 0.6140346527099609
Validation loss: 1.7817855919561079

Epoch: 6| Step: 5
Training loss: 0.4200495183467865
Validation loss: 1.7675235681636359

Epoch: 6| Step: 6
Training loss: 0.637079656124115
Validation loss: 1.826604588057405

Epoch: 6| Step: 7
Training loss: 0.294241726398468
Validation loss: 1.8448890691162438

Epoch: 6| Step: 8
Training loss: 0.27475014328956604
Validation loss: 1.789862096950572

Epoch: 6| Step: 9
Training loss: 0.32465964555740356
Validation loss: 1.8001936994573122

Epoch: 6| Step: 10
Training loss: 0.280805766582489
Validation loss: 1.7975785193904754

Epoch: 6| Step: 11
Training loss: 0.518906831741333
Validation loss: 1.8307371600981681

Epoch: 6| Step: 12
Training loss: 0.3932632803916931
Validation loss: 1.8177151731265488

Epoch: 6| Step: 13
Training loss: 0.5656532049179077
Validation loss: 1.8592555164009013

Epoch: 305| Step: 0
Training loss: 0.2722080945968628
Validation loss: 1.8525856816640465

Epoch: 6| Step: 1
Training loss: 0.41885048151016235
Validation loss: 1.8786649678343086

Epoch: 6| Step: 2
Training loss: 0.5357908010482788
Validation loss: 1.8380778630574544

Epoch: 6| Step: 3
Training loss: 0.766060471534729
Validation loss: 1.842976967493693

Epoch: 6| Step: 4
Training loss: 0.6185954213142395
Validation loss: 1.8823256595160371

Epoch: 6| Step: 5
Training loss: 0.5052387118339539
Validation loss: 1.8846449134170369

Epoch: 6| Step: 6
Training loss: 0.6575469374656677
Validation loss: 1.8944658105091383

Epoch: 6| Step: 7
Training loss: 0.21979200839996338
Validation loss: 1.8763689007810367

Epoch: 6| Step: 8
Training loss: 0.5438235998153687
Validation loss: 1.8859521458225865

Epoch: 6| Step: 9
Training loss: 0.4448314309120178
Validation loss: 1.9040497631155036

Epoch: 6| Step: 10
Training loss: 0.5888693928718567
Validation loss: 1.8484701084834274

Epoch: 6| Step: 11
Training loss: 0.2543536424636841
Validation loss: 1.8208765842581307

Epoch: 6| Step: 12
Training loss: 0.5269789695739746
Validation loss: 1.7722239942960842

Epoch: 6| Step: 13
Training loss: 0.28401386737823486
Validation loss: 1.7875646532222789

Epoch: 306| Step: 0
Training loss: 0.29176995158195496
Validation loss: 1.741730777166223

Epoch: 6| Step: 1
Training loss: 0.23085463047027588
Validation loss: 1.7325006787494948

Epoch: 6| Step: 2
Training loss: 0.3711020350456238
Validation loss: 1.713216377842811

Epoch: 6| Step: 3
Training loss: 0.4486502707004547
Validation loss: 1.7743557960756364

Epoch: 6| Step: 4
Training loss: 0.40343695878982544
Validation loss: 1.7940045069622736

Epoch: 6| Step: 5
Training loss: 0.5975714921951294
Validation loss: 1.8004196202883156

Epoch: 6| Step: 6
Training loss: 0.5347184538841248
Validation loss: 1.8425394899101668

Epoch: 6| Step: 7
Training loss: 0.431463360786438
Validation loss: 1.811671022445925

Epoch: 6| Step: 8
Training loss: 1.006213903427124
Validation loss: 1.8141134477430774

Epoch: 6| Step: 9
Training loss: 0.3646829128265381
Validation loss: 1.7666929767977806

Epoch: 6| Step: 10
Training loss: 0.32024839520454407
Validation loss: 1.7807122161311488

Epoch: 6| Step: 11
Training loss: 0.26638078689575195
Validation loss: 1.8111805210831344

Epoch: 6| Step: 12
Training loss: 0.23679523169994354
Validation loss: 1.7997910002226472

Epoch: 6| Step: 13
Training loss: 0.11729288101196289
Validation loss: 1.825813921548987

Epoch: 307| Step: 0
Training loss: 0.7090479135513306
Validation loss: 1.8902481704629877

Epoch: 6| Step: 1
Training loss: 0.6349998712539673
Validation loss: 1.8935765784273866

Epoch: 6| Step: 2
Training loss: 0.3037452697753906
Validation loss: 1.907594564140484

Epoch: 6| Step: 3
Training loss: 0.31758594512939453
Validation loss: 1.894283789460377

Epoch: 6| Step: 4
Training loss: 0.7504580616950989
Validation loss: 1.8569998561695058

Epoch: 6| Step: 5
Training loss: 0.3940378725528717
Validation loss: 1.8603149614026468

Epoch: 6| Step: 6
Training loss: 0.23687171936035156
Validation loss: 1.820231004427838

Epoch: 6| Step: 7
Training loss: 0.5257587432861328
Validation loss: 1.8053610119768368

Epoch: 6| Step: 8
Training loss: 0.27967435121536255
Validation loss: 1.7421408481495355

Epoch: 6| Step: 9
Training loss: 0.2187052071094513
Validation loss: 1.750364621480306

Epoch: 6| Step: 10
Training loss: 0.36942175030708313
Validation loss: 1.740862770747113

Epoch: 6| Step: 11
Training loss: 0.40880903601646423
Validation loss: 1.7545542819525606

Epoch: 6| Step: 12
Training loss: 0.2688550353050232
Validation loss: 1.7148276029094573

Epoch: 6| Step: 13
Training loss: 0.36283227801322937
Validation loss: 1.7422833404233378

Epoch: 308| Step: 0
Training loss: 0.2279987931251526
Validation loss: 1.7485946557855094

Epoch: 6| Step: 1
Training loss: 0.4866999685764313
Validation loss: 1.7337921383560344

Epoch: 6| Step: 2
Training loss: 0.5101069211959839
Validation loss: 1.7528418071808354

Epoch: 6| Step: 3
Training loss: 0.2999595105648041
Validation loss: 1.754768898410182

Epoch: 6| Step: 4
Training loss: 0.4069174826145172
Validation loss: 1.8082207556693786

Epoch: 6| Step: 5
Training loss: 0.4071938991546631
Validation loss: 1.7790043789853331

Epoch: 6| Step: 6
Training loss: 0.8831226825714111
Validation loss: 1.816359766067997

Epoch: 6| Step: 7
Training loss: 0.2365318238735199
Validation loss: 1.8394396817812355

Epoch: 6| Step: 8
Training loss: 0.5782088041305542
Validation loss: 1.839106834062966

Epoch: 6| Step: 9
Training loss: 0.30683064460754395
Validation loss: 1.8171611639761156

Epoch: 6| Step: 10
Training loss: 0.4594227969646454
Validation loss: 1.877645190044116

Epoch: 6| Step: 11
Training loss: 0.391767680644989
Validation loss: 1.8363407581083235

Epoch: 6| Step: 12
Training loss: 0.22357356548309326
Validation loss: 1.8429457833690028

Epoch: 6| Step: 13
Training loss: 0.35827362537384033
Validation loss: 1.8332431431739562

Epoch: 309| Step: 0
Training loss: 0.5466669797897339
Validation loss: 1.8578024141250118

Epoch: 6| Step: 1
Training loss: 0.6403899192810059
Validation loss: 1.845292002924027

Epoch: 6| Step: 2
Training loss: 0.3710920810699463
Validation loss: 1.8040741182142688

Epoch: 6| Step: 3
Training loss: 0.3702639937400818
Validation loss: 1.8270475069681804

Epoch: 6| Step: 4
Training loss: 0.309139609336853
Validation loss: 1.7804811359733663

Epoch: 6| Step: 5
Training loss: 0.45630332827568054
Validation loss: 1.7489111038946337

Epoch: 6| Step: 6
Training loss: 0.2226048707962036
Validation loss: 1.7166780226974077

Epoch: 6| Step: 7
Training loss: 0.40721362829208374
Validation loss: 1.7458231974673528

Epoch: 6| Step: 8
Training loss: 0.7006887793540955
Validation loss: 1.7173128410052227

Epoch: 6| Step: 9
Training loss: 0.2809731960296631
Validation loss: 1.6752523324822868

Epoch: 6| Step: 10
Training loss: 0.4774167537689209
Validation loss: 1.7829406851081437

Epoch: 6| Step: 11
Training loss: 0.260824590921402
Validation loss: 1.7938068733420423

Epoch: 6| Step: 12
Training loss: 0.36561378836631775
Validation loss: 1.8146920152889785

Epoch: 6| Step: 13
Training loss: 0.5136505961418152
Validation loss: 1.8028856451793382

Epoch: 310| Step: 0
Training loss: 0.5917176008224487
Validation loss: 1.8343425431559164

Epoch: 6| Step: 1
Training loss: 0.6894228458404541
Validation loss: 1.847265156366492

Epoch: 6| Step: 2
Training loss: 0.39696404337882996
Validation loss: 1.865986293362033

Epoch: 6| Step: 3
Training loss: 0.3205617070198059
Validation loss: 1.8899240852684103

Epoch: 6| Step: 4
Training loss: 0.3491959571838379
Validation loss: 1.8549706923064364

Epoch: 6| Step: 5
Training loss: 0.3528374433517456
Validation loss: 1.8395852952875116

Epoch: 6| Step: 6
Training loss: 0.33027470111846924
Validation loss: 1.8397549531793083

Epoch: 6| Step: 7
Training loss: 0.5072991251945496
Validation loss: 1.8368547936921478

Epoch: 6| Step: 8
Training loss: 0.318403035402298
Validation loss: 1.8244681858247327

Epoch: 6| Step: 9
Training loss: 0.6085079908370972
Validation loss: 1.8393534870557888

Epoch: 6| Step: 10
Training loss: 0.2394241988658905
Validation loss: 1.8251892879445066

Epoch: 6| Step: 11
Training loss: 0.7334716320037842
Validation loss: 1.8793346189683484

Epoch: 6| Step: 12
Training loss: 0.39965879917144775
Validation loss: 1.8449208691555967

Epoch: 6| Step: 13
Training loss: 0.3194013833999634
Validation loss: 1.8186867788273802

Epoch: 311| Step: 0
Training loss: 0.48859280347824097
Validation loss: 1.7709585056510022

Epoch: 6| Step: 1
Training loss: 0.32374322414398193
Validation loss: 1.7718188954937844

Epoch: 6| Step: 2
Training loss: 0.7434125542640686
Validation loss: 1.7645732254110358

Epoch: 6| Step: 3
Training loss: 0.2769523859024048
Validation loss: 1.761076355493197

Epoch: 6| Step: 4
Training loss: 0.23435784876346588
Validation loss: 1.7761554512926327

Epoch: 6| Step: 5
Training loss: 0.38390108942985535
Validation loss: 1.8229615175595848

Epoch: 6| Step: 6
Training loss: 0.49356478452682495
Validation loss: 1.8454777553517332

Epoch: 6| Step: 7
Training loss: 0.305219829082489
Validation loss: 1.8433392714428645

Epoch: 6| Step: 8
Training loss: 0.6127429008483887
Validation loss: 1.887131570487894

Epoch: 6| Step: 9
Training loss: 0.5100369453430176
Validation loss: 1.8737028196293821

Epoch: 6| Step: 10
Training loss: 0.3558015823364258
Validation loss: 1.8623715664750786

Epoch: 6| Step: 11
Training loss: 0.3586218059062958
Validation loss: 1.856864519016717

Epoch: 6| Step: 12
Training loss: 0.44958704710006714
Validation loss: 1.8342202145566222

Epoch: 6| Step: 13
Training loss: 0.25497716665267944
Validation loss: 1.7801430943191692

Epoch: 312| Step: 0
Training loss: 0.43993687629699707
Validation loss: 1.7711946464353991

Epoch: 6| Step: 1
Training loss: 0.48516762256622314
Validation loss: 1.7466606491355485

Epoch: 6| Step: 2
Training loss: 0.4901273846626282
Validation loss: 1.734906332467192

Epoch: 6| Step: 3
Training loss: 0.5314151644706726
Validation loss: 1.710441831619509

Epoch: 6| Step: 4
Training loss: 0.4109562039375305
Validation loss: 1.7653703958757463

Epoch: 6| Step: 5
Training loss: 0.2052382379770279
Validation loss: 1.804336379933101

Epoch: 6| Step: 6
Training loss: 0.8067753911018372
Validation loss: 1.7859183690881217

Epoch: 6| Step: 7
Training loss: 0.30801671743392944
Validation loss: 1.7880444142126268

Epoch: 6| Step: 8
Training loss: 0.2196459174156189
Validation loss: 1.759209845655708

Epoch: 6| Step: 9
Training loss: 0.386481910943985
Validation loss: 1.7526454835809686

Epoch: 6| Step: 10
Training loss: 0.3112291097640991
Validation loss: 1.7530291529111965

Epoch: 6| Step: 11
Training loss: 0.2972588539123535
Validation loss: 1.7339586275880055

Epoch: 6| Step: 12
Training loss: 0.33576536178588867
Validation loss: 1.7212910536796815

Epoch: 6| Step: 13
Training loss: 0.4844367802143097
Validation loss: 1.7089405867361254

Epoch: 313| Step: 0
Training loss: 0.6356786489486694
Validation loss: 1.7346484584193076

Epoch: 6| Step: 1
Training loss: 0.33426031470298767
Validation loss: 1.7408850308387511

Epoch: 6| Step: 2
Training loss: 1.087426781654358
Validation loss: 1.793653662486743

Epoch: 6| Step: 3
Training loss: 0.33780062198638916
Validation loss: 1.7769907033571632

Epoch: 6| Step: 4
Training loss: 0.4197522699832916
Validation loss: 1.8379306895758516

Epoch: 6| Step: 5
Training loss: 0.3730320334434509
Validation loss: 1.796186472779961

Epoch: 6| Step: 6
Training loss: 0.4780257046222687
Validation loss: 1.7885869369711926

Epoch: 6| Step: 7
Training loss: 0.35373979806900024
Validation loss: 1.798274891350859

Epoch: 6| Step: 8
Training loss: 0.38068628311157227
Validation loss: 1.8193374090297247

Epoch: 6| Step: 9
Training loss: 0.23706066608428955
Validation loss: 1.7729408894815752

Epoch: 6| Step: 10
Training loss: 0.30485793948173523
Validation loss: 1.7617722429255003

Epoch: 6| Step: 11
Training loss: 0.362689733505249
Validation loss: 1.7327531883793492

Epoch: 6| Step: 12
Training loss: 0.18667790293693542
Validation loss: 1.755485036039865

Epoch: 6| Step: 13
Training loss: 0.3763352930545807
Validation loss: 1.7064186270518968

Epoch: 314| Step: 0
Training loss: 0.7448049783706665
Validation loss: 1.744659472537297

Epoch: 6| Step: 1
Training loss: 0.42194312810897827
Validation loss: 1.7455437683290052

Epoch: 6| Step: 2
Training loss: 0.2849521338939667
Validation loss: 1.7759141627178396

Epoch: 6| Step: 3
Training loss: 0.3115193545818329
Validation loss: 1.7602232784353278

Epoch: 6| Step: 4
Training loss: 0.27621740102767944
Validation loss: 1.786864257627918

Epoch: 6| Step: 5
Training loss: 0.3253151774406433
Validation loss: 1.7862587564735002

Epoch: 6| Step: 6
Training loss: 0.33683720231056213
Validation loss: 1.79115633297992

Epoch: 6| Step: 7
Training loss: 0.4617125391960144
Validation loss: 1.8072830759068972

Epoch: 6| Step: 8
Training loss: 0.4974822998046875
Validation loss: 1.849849541982015

Epoch: 6| Step: 9
Training loss: 0.29859673976898193
Validation loss: 1.837535737663187

Epoch: 6| Step: 10
Training loss: 0.23067276179790497
Validation loss: 1.808151424572032

Epoch: 6| Step: 11
Training loss: 0.363476037979126
Validation loss: 1.7818968860051965

Epoch: 6| Step: 12
Training loss: 0.42236384749412537
Validation loss: 1.7229727929638279

Epoch: 6| Step: 13
Training loss: 0.1894330233335495
Validation loss: 1.7332455112088112

Epoch: 315| Step: 0
Training loss: 0.41963112354278564
Validation loss: 1.7626330455144246

Epoch: 6| Step: 1
Training loss: 0.6545486450195312
Validation loss: 1.747028209829843

Epoch: 6| Step: 2
Training loss: 0.3253330886363983
Validation loss: 1.7517516920643468

Epoch: 6| Step: 3
Training loss: 0.2732660174369812
Validation loss: 1.759032348150848

Epoch: 6| Step: 4
Training loss: 0.21504896879196167
Validation loss: 1.7798075329872869

Epoch: 6| Step: 5
Training loss: 0.3607105016708374
Validation loss: 1.7503802058517293

Epoch: 6| Step: 6
Training loss: 0.36493974924087524
Validation loss: 1.792338437931512

Epoch: 6| Step: 7
Training loss: 0.5217128992080688
Validation loss: 1.775097135574587

Epoch: 6| Step: 8
Training loss: 0.20184028148651123
Validation loss: 1.7991166281443771

Epoch: 6| Step: 9
Training loss: 0.2632693648338318
Validation loss: 1.7963911910210886

Epoch: 6| Step: 10
Training loss: 0.42560815811157227
Validation loss: 1.8037967745975783

Epoch: 6| Step: 11
Training loss: 0.42315536737442017
Validation loss: 1.803998786916015

Epoch: 6| Step: 12
Training loss: 0.37515851855278015
Validation loss: 1.7778481744950818

Epoch: 6| Step: 13
Training loss: 0.23493129014968872
Validation loss: 1.7521881903371503

Epoch: 316| Step: 0
Training loss: 0.27356624603271484
Validation loss: 1.7452944645317652

Epoch: 6| Step: 1
Training loss: 0.41572821140289307
Validation loss: 1.6841288074370353

Epoch: 6| Step: 2
Training loss: 0.6860907673835754
Validation loss: 1.7096118427092029

Epoch: 6| Step: 3
Training loss: 0.34680211544036865
Validation loss: 1.705222447713216

Epoch: 6| Step: 4
Training loss: 0.6483093500137329
Validation loss: 1.7254827689099055

Epoch: 6| Step: 5
Training loss: 0.24654540419578552
Validation loss: 1.7497976338991554

Epoch: 6| Step: 6
Training loss: 0.28882479667663574
Validation loss: 1.7810064874669558

Epoch: 6| Step: 7
Training loss: 0.27182239294052124
Validation loss: 1.7942512932644095

Epoch: 6| Step: 8
Training loss: 0.5903668403625488
Validation loss: 1.840479862305426

Epoch: 6| Step: 9
Training loss: 0.3253082036972046
Validation loss: 1.8333946581809752

Epoch: 6| Step: 10
Training loss: 0.26379257440567017
Validation loss: 1.9002186367588658

Epoch: 6| Step: 11
Training loss: 0.47603005170822144
Validation loss: 1.8897565603256226

Epoch: 6| Step: 12
Training loss: 0.19306233525276184
Validation loss: 1.8397579462297502

Epoch: 6| Step: 13
Training loss: 0.25984054803848267
Validation loss: 1.8731391532446748

Epoch: 317| Step: 0
Training loss: 0.33835166692733765
Validation loss: 1.8443872031345163

Epoch: 6| Step: 1
Training loss: 0.3042140007019043
Validation loss: 1.8254986475872736

Epoch: 6| Step: 2
Training loss: 0.40135836601257324
Validation loss: 1.8218010189712688

Epoch: 6| Step: 3
Training loss: 0.5468481779098511
Validation loss: 1.823516539348069

Epoch: 6| Step: 4
Training loss: 0.34185969829559326
Validation loss: 1.7526603962785454

Epoch: 6| Step: 5
Training loss: 0.45010706782341003
Validation loss: 1.7952143787055888

Epoch: 6| Step: 6
Training loss: 0.298470139503479
Validation loss: 1.842038623748287

Epoch: 6| Step: 7
Training loss: 0.23854488134384155
Validation loss: 1.8323202299815353

Epoch: 6| Step: 8
Training loss: 0.2507895827293396
Validation loss: 1.8102553454778527

Epoch: 6| Step: 9
Training loss: 0.4440154433250427
Validation loss: 1.8068354386155323

Epoch: 6| Step: 10
Training loss: 0.44176262617111206
Validation loss: 1.7513052622477214

Epoch: 6| Step: 11
Training loss: 0.4778844714164734
Validation loss: 1.805406339706913

Epoch: 6| Step: 12
Training loss: 0.279377818107605
Validation loss: 1.7684347783365557

Epoch: 6| Step: 13
Training loss: 0.42168352007865906
Validation loss: 1.7872614052987867

Epoch: 318| Step: 0
Training loss: 0.41652894020080566
Validation loss: 1.743539289761615

Epoch: 6| Step: 1
Training loss: 0.419761598110199
Validation loss: 1.7734533907264791

Epoch: 6| Step: 2
Training loss: 0.4908221960067749
Validation loss: 1.7840879681289836

Epoch: 6| Step: 3
Training loss: 0.17176216840744019
Validation loss: 1.8084709849408878

Epoch: 6| Step: 4
Training loss: 0.4655357301235199
Validation loss: 1.826769043040532

Epoch: 6| Step: 5
Training loss: 0.40352147817611694
Validation loss: 1.8369026030263593

Epoch: 6| Step: 6
Training loss: 0.27934330701828003
Validation loss: 1.821120862037905

Epoch: 6| Step: 7
Training loss: 0.7298466563224792
Validation loss: 1.7939915605770644

Epoch: 6| Step: 8
Training loss: 0.24705594778060913
Validation loss: 1.7695769468943279

Epoch: 6| Step: 9
Training loss: 0.32670894265174866
Validation loss: 1.770993003281214

Epoch: 6| Step: 10
Training loss: 0.349041223526001
Validation loss: 1.7312090755790792

Epoch: 6| Step: 11
Training loss: 0.2554931342601776
Validation loss: 1.7457697647874073

Epoch: 6| Step: 12
Training loss: 0.22840768098831177
Validation loss: 1.8094955900663972

Epoch: 6| Step: 13
Training loss: 0.14893022179603577
Validation loss: 1.7439771980367682

Epoch: 319| Step: 0
Training loss: 0.2512633502483368
Validation loss: 1.7161054201023553

Epoch: 6| Step: 1
Training loss: 0.20963595807552338
Validation loss: 1.7225549567130305

Epoch: 6| Step: 2
Training loss: 0.22372294962406158
Validation loss: 1.7030458693863244

Epoch: 6| Step: 3
Training loss: 0.3777167499065399
Validation loss: 1.704958899046785

Epoch: 6| Step: 4
Training loss: 0.25598037242889404
Validation loss: 1.7057250661234702

Epoch: 6| Step: 5
Training loss: 0.2962818741798401
Validation loss: 1.7572932832984514

Epoch: 6| Step: 6
Training loss: 0.654975950717926
Validation loss: 1.7046769613860755

Epoch: 6| Step: 7
Training loss: 0.4307926297187805
Validation loss: 1.7073269371063478

Epoch: 6| Step: 8
Training loss: 0.6700048446655273
Validation loss: 1.702992605906661

Epoch: 6| Step: 9
Training loss: 0.589754045009613
Validation loss: 1.6821348474871727

Epoch: 6| Step: 10
Training loss: 0.43923670053482056
Validation loss: 1.6687331045827558

Epoch: 6| Step: 11
Training loss: 0.15797173976898193
Validation loss: 1.6645384616749261

Epoch: 6| Step: 12
Training loss: 0.2630840837955475
Validation loss: 1.6910907555651922

Epoch: 6| Step: 13
Training loss: 0.2739650011062622
Validation loss: 1.6912940048402356

Epoch: 320| Step: 0
Training loss: 0.38891929388046265
Validation loss: 1.6980163986964891

Epoch: 6| Step: 1
Training loss: 0.31210026144981384
Validation loss: 1.7374434214766308

Epoch: 6| Step: 2
Training loss: 0.5425528287887573
Validation loss: 1.77962907924447

Epoch: 6| Step: 3
Training loss: 0.17804452776908875
Validation loss: 1.7647351218808083

Epoch: 6| Step: 4
Training loss: 0.38649725914001465
Validation loss: 1.7345115638548327

Epoch: 6| Step: 5
Training loss: 0.2671542465686798
Validation loss: 1.728510591291612

Epoch: 6| Step: 6
Training loss: 0.2787553668022156
Validation loss: 1.6973094863276328

Epoch: 6| Step: 7
Training loss: 0.35496097803115845
Validation loss: 1.680656385678117

Epoch: 6| Step: 8
Training loss: 0.4865330755710602
Validation loss: 1.7249026965069514

Epoch: 6| Step: 9
Training loss: 0.2901023030281067
Validation loss: 1.7047348906916957

Epoch: 6| Step: 10
Training loss: 0.5984548926353455
Validation loss: 1.734109927249211

Epoch: 6| Step: 11
Training loss: 0.479302316904068
Validation loss: 1.7425177763867121

Epoch: 6| Step: 12
Training loss: 0.493572473526001
Validation loss: 1.8281729541799074

Epoch: 6| Step: 13
Training loss: 0.407646507024765
Validation loss: 1.8482938402442521

Epoch: 321| Step: 0
Training loss: 0.24680422246456146
Validation loss: 1.921773333703318

Epoch: 6| Step: 1
Training loss: 0.39568737149238586
Validation loss: 1.944031443647159

Epoch: 6| Step: 2
Training loss: 0.3972150683403015
Validation loss: 1.9476963230358657

Epoch: 6| Step: 3
Training loss: 0.20228402316570282
Validation loss: 1.908608974949006

Epoch: 6| Step: 4
Training loss: 0.28871241211891174
Validation loss: 1.8807326516797465

Epoch: 6| Step: 5
Training loss: 0.3239973485469818
Validation loss: 1.8404122180836175

Epoch: 6| Step: 6
Training loss: 0.37408676743507385
Validation loss: 1.786197502125976

Epoch: 6| Step: 7
Training loss: 0.4483085870742798
Validation loss: 1.769158048014487

Epoch: 6| Step: 8
Training loss: 0.36543822288513184
Validation loss: 1.7404943704605103

Epoch: 6| Step: 9
Training loss: 0.44211345911026
Validation loss: 1.7879267610529417

Epoch: 6| Step: 10
Training loss: 0.44383788108825684
Validation loss: 1.7359318630669707

Epoch: 6| Step: 11
Training loss: 0.5954020023345947
Validation loss: 1.765205410219008

Epoch: 6| Step: 12
Training loss: 0.29897746443748474
Validation loss: 1.8044445078860047

Epoch: 6| Step: 13
Training loss: 0.43531227111816406
Validation loss: 1.8369328924404678

Epoch: 322| Step: 0
Training loss: 0.39377474784851074
Validation loss: 1.868540007580993

Epoch: 6| Step: 1
Training loss: 0.4042583107948303
Validation loss: 1.8614632762888426

Epoch: 6| Step: 2
Training loss: 0.4042254090309143
Validation loss: 1.827484671787549

Epoch: 6| Step: 3
Training loss: 0.8745943307876587
Validation loss: 1.7875014697351763

Epoch: 6| Step: 4
Training loss: 0.2657627761363983
Validation loss: 1.7546886397946266

Epoch: 6| Step: 5
Training loss: 0.2429800033569336
Validation loss: 1.7510997428688952

Epoch: 6| Step: 6
Training loss: 0.2920246124267578
Validation loss: 1.7365252561466669

Epoch: 6| Step: 7
Training loss: 0.4028344750404358
Validation loss: 1.7741801213192683

Epoch: 6| Step: 8
Training loss: 0.28130409121513367
Validation loss: 1.7325279167903367

Epoch: 6| Step: 9
Training loss: 0.19524824619293213
Validation loss: 1.7597954145041845

Epoch: 6| Step: 10
Training loss: 0.2280190885066986
Validation loss: 1.735686517530872

Epoch: 6| Step: 11
Training loss: 0.2323891520500183
Validation loss: 1.7544616319799935

Epoch: 6| Step: 12
Training loss: 0.2416355013847351
Validation loss: 1.7838745565824612

Epoch: 6| Step: 13
Training loss: 0.1911879926919937
Validation loss: 1.7563260293775989

Epoch: 323| Step: 0
Training loss: 0.4275714159011841
Validation loss: 1.7456661911420925

Epoch: 6| Step: 1
Training loss: 0.26838767528533936
Validation loss: 1.7384254035129343

Epoch: 6| Step: 2
Training loss: 0.31746190786361694
Validation loss: 1.7011912215140559

Epoch: 6| Step: 3
Training loss: 0.5826084613800049
Validation loss: 1.7266803390236312

Epoch: 6| Step: 4
Training loss: 0.16718873381614685
Validation loss: 1.7123528039583595

Epoch: 6| Step: 5
Training loss: 0.3209185302257538
Validation loss: 1.742437695944181

Epoch: 6| Step: 6
Training loss: 0.24760255217552185
Validation loss: 1.7386588153018747

Epoch: 6| Step: 7
Training loss: 0.37644898891448975
Validation loss: 1.7244196040655977

Epoch: 6| Step: 8
Training loss: 0.48149555921554565
Validation loss: 1.7608495668698383

Epoch: 6| Step: 9
Training loss: 0.2094656378030777
Validation loss: 1.6863722711481073

Epoch: 6| Step: 10
Training loss: 0.3384639620780945
Validation loss: 1.7219858374646915

Epoch: 6| Step: 11
Training loss: 0.4500015377998352
Validation loss: 1.6907811921129945

Epoch: 6| Step: 12
Training loss: 0.3635040521621704
Validation loss: 1.7571666868784095

Epoch: 6| Step: 13
Training loss: 0.2934882342815399
Validation loss: 1.7106760150642806

Epoch: 324| Step: 0
Training loss: 0.5815403461456299
Validation loss: 1.7579634317787745

Epoch: 6| Step: 1
Training loss: 0.30193620920181274
Validation loss: 1.7264886056223223

Epoch: 6| Step: 2
Training loss: 0.21845248341560364
Validation loss: 1.759289864570864

Epoch: 6| Step: 3
Training loss: 0.3198856711387634
Validation loss: 1.727721130976113

Epoch: 6| Step: 4
Training loss: 0.547883152961731
Validation loss: 1.7278910477956135

Epoch: 6| Step: 5
Training loss: 0.3494241237640381
Validation loss: 1.7454583978140226

Epoch: 6| Step: 6
Training loss: 0.2368158996105194
Validation loss: 1.7435493033419374

Epoch: 6| Step: 7
Training loss: 0.335000604391098
Validation loss: 1.7520878032971454

Epoch: 6| Step: 8
Training loss: 0.2628840506076813
Validation loss: 1.75027338791919

Epoch: 6| Step: 9
Training loss: 0.39709240198135376
Validation loss: 1.7792279258851083

Epoch: 6| Step: 10
Training loss: 0.39503949880599976
Validation loss: 1.7993614647978096

Epoch: 6| Step: 11
Training loss: 0.22514286637306213
Validation loss: 1.8026708249122865

Epoch: 6| Step: 12
Training loss: 0.22960567474365234
Validation loss: 1.8250674201596169

Epoch: 6| Step: 13
Training loss: 0.3372572958469391
Validation loss: 1.8431381576804704

Epoch: 325| Step: 0
Training loss: 0.3348803222179413
Validation loss: 1.8778140416709326

Epoch: 6| Step: 1
Training loss: 0.45827311277389526
Validation loss: 1.8839960405903478

Epoch: 6| Step: 2
Training loss: 0.25041383504867554
Validation loss: 1.871864552138954

Epoch: 6| Step: 3
Training loss: 0.24727049469947815
Validation loss: 1.8163527160562494

Epoch: 6| Step: 4
Training loss: 0.26433685421943665
Validation loss: 1.7633482140879477

Epoch: 6| Step: 5
Training loss: 0.30164188146591187
Validation loss: 1.7050128444548576

Epoch: 6| Step: 6
Training loss: 0.5049721002578735
Validation loss: 1.7818719199908677

Epoch: 6| Step: 7
Training loss: 0.4133179187774658
Validation loss: 1.7101854855014431

Epoch: 6| Step: 8
Training loss: 0.5887759327888489
Validation loss: 1.7462871343858781

Epoch: 6| Step: 9
Training loss: 0.24581162631511688
Validation loss: 1.7468915524021271

Epoch: 6| Step: 10
Training loss: 0.3949962854385376
Validation loss: 1.756582595968759

Epoch: 6| Step: 11
Training loss: 0.19277852773666382
Validation loss: 1.7851040568403018

Epoch: 6| Step: 12
Training loss: 0.3195973038673401
Validation loss: 1.7855425034799883

Epoch: 6| Step: 13
Training loss: 0.551074743270874
Validation loss: 1.7719455047320294

Epoch: 326| Step: 0
Training loss: 0.38718920946121216
Validation loss: 1.7439197904320174

Epoch: 6| Step: 1
Training loss: 0.6354839205741882
Validation loss: 1.715101977830292

Epoch: 6| Step: 2
Training loss: 0.2929040789604187
Validation loss: 1.7181629858991152

Epoch: 6| Step: 3
Training loss: 0.2810943126678467
Validation loss: 1.686514223775556

Epoch: 6| Step: 4
Training loss: 0.4925275444984436
Validation loss: 1.6979301244981828

Epoch: 6| Step: 5
Training loss: 0.23900720477104187
Validation loss: 1.6691585612553421

Epoch: 6| Step: 6
Training loss: 0.355792760848999
Validation loss: 1.7086704443859797

Epoch: 6| Step: 7
Training loss: 0.20129361748695374
Validation loss: 1.6947334171623312

Epoch: 6| Step: 8
Training loss: 0.2741699814796448
Validation loss: 1.7649145997980589

Epoch: 6| Step: 9
Training loss: 0.13076700270175934
Validation loss: 1.7755978568907707

Epoch: 6| Step: 10
Training loss: 0.3104666471481323
Validation loss: 1.8417540442559026

Epoch: 6| Step: 11
Training loss: 0.3401070833206177
Validation loss: 1.8397748457488192

Epoch: 6| Step: 12
Training loss: 0.20318344235420227
Validation loss: 1.8815661335504184

Epoch: 6| Step: 13
Training loss: 0.4343563914299011
Validation loss: 1.8542696147836664

Epoch: 327| Step: 0
Training loss: 0.24905936419963837
Validation loss: 1.8128761450449626

Epoch: 6| Step: 1
Training loss: 0.2002319097518921
Validation loss: 1.7698208375643658

Epoch: 6| Step: 2
Training loss: 0.2823394238948822
Validation loss: 1.7699302781012751

Epoch: 6| Step: 3
Training loss: 0.371538370847702
Validation loss: 1.7108265699878815

Epoch: 6| Step: 4
Training loss: 0.2881494462490082
Validation loss: 1.730301490394018

Epoch: 6| Step: 5
Training loss: 0.626022458076477
Validation loss: 1.7096966530687066

Epoch: 6| Step: 6
Training loss: 0.223780557513237
Validation loss: 1.7061440380670692

Epoch: 6| Step: 7
Training loss: 0.2997395992279053
Validation loss: 1.6996857735418505

Epoch: 6| Step: 8
Training loss: 0.3665879964828491
Validation loss: 1.7080282600977088

Epoch: 6| Step: 9
Training loss: 0.37492066621780396
Validation loss: 1.7718314996329687

Epoch: 6| Step: 10
Training loss: 0.2686840891838074
Validation loss: 1.7726020633533437

Epoch: 6| Step: 11
Training loss: 0.2798268795013428
Validation loss: 1.8008257330104869

Epoch: 6| Step: 12
Training loss: 0.34126847982406616
Validation loss: 1.8171955808516471

Epoch: 6| Step: 13
Training loss: 0.6964436769485474
Validation loss: 1.829828969893917

Epoch: 328| Step: 0
Training loss: 0.24188092350959778
Validation loss: 1.8388203754219958

Epoch: 6| Step: 1
Training loss: 0.2404404878616333
Validation loss: 1.79876539527729

Epoch: 6| Step: 2
Training loss: 0.32587742805480957
Validation loss: 1.8112127114367742

Epoch: 6| Step: 3
Training loss: 0.28574925661087036
Validation loss: 1.8032652280663932

Epoch: 6| Step: 4
Training loss: 0.6437766551971436
Validation loss: 1.772989813999463

Epoch: 6| Step: 5
Training loss: 0.4534524381160736
Validation loss: 1.7691837863255573

Epoch: 6| Step: 6
Training loss: 0.2083870768547058
Validation loss: 1.7774138283985916

Epoch: 6| Step: 7
Training loss: 0.40387052297592163
Validation loss: 1.7536100533700758

Epoch: 6| Step: 8
Training loss: 0.2867380380630493
Validation loss: 1.8040721006290887

Epoch: 6| Step: 9
Training loss: 0.36671584844589233
Validation loss: 1.845630556024531

Epoch: 6| Step: 10
Training loss: 0.40539780259132385
Validation loss: 1.8537661490901824

Epoch: 6| Step: 11
Training loss: 0.30346959829330444
Validation loss: 1.820668161556285

Epoch: 6| Step: 12
Training loss: 0.3795316219329834
Validation loss: 1.8328292446751748

Epoch: 6| Step: 13
Training loss: 0.29421621561050415
Validation loss: 1.8207591246533137

Epoch: 329| Step: 0
Training loss: 0.2951218783855438
Validation loss: 1.795544598692207

Epoch: 6| Step: 1
Training loss: 0.4215146601200104
Validation loss: 1.7445082062034196

Epoch: 6| Step: 2
Training loss: 0.3142724931240082
Validation loss: 1.7468174965150896

Epoch: 6| Step: 3
Training loss: 0.22584396600723267
Validation loss: 1.694748164505087

Epoch: 6| Step: 4
Training loss: 0.24682268500328064
Validation loss: 1.6908407031848867

Epoch: 6| Step: 5
Training loss: 0.1901174783706665
Validation loss: 1.68913298268472

Epoch: 6| Step: 6
Training loss: 0.7403091192245483
Validation loss: 1.686935737568845

Epoch: 6| Step: 7
Training loss: 0.20360422134399414
Validation loss: 1.7421460895128147

Epoch: 6| Step: 8
Training loss: 0.34248581528663635
Validation loss: 1.786924119918577

Epoch: 6| Step: 9
Training loss: 0.41626179218292236
Validation loss: 1.852615894809846

Epoch: 6| Step: 10
Training loss: 0.30368831753730774
Validation loss: 1.84272139815874

Epoch: 6| Step: 11
Training loss: 0.32059985399246216
Validation loss: 1.846796549776549

Epoch: 6| Step: 12
Training loss: 0.3069954812526703
Validation loss: 1.824308733786306

Epoch: 6| Step: 13
Training loss: 0.339034765958786
Validation loss: 1.7888286370103077

Epoch: 330| Step: 0
Training loss: 0.2976008951663971
Validation loss: 1.7760526826304774

Epoch: 6| Step: 1
Training loss: 0.26341837644577026
Validation loss: 1.7292042188746954

Epoch: 6| Step: 2
Training loss: 0.4796779453754425
Validation loss: 1.7448632614586943

Epoch: 6| Step: 3
Training loss: 0.38390615582466125
Validation loss: 1.7601110435301257

Epoch: 6| Step: 4
Training loss: 0.42688703536987305
Validation loss: 1.7724223470175138

Epoch: 6| Step: 5
Training loss: 0.672561764717102
Validation loss: 1.793892365629955

Epoch: 6| Step: 6
Training loss: 0.3251068890094757
Validation loss: 1.821764922911121

Epoch: 6| Step: 7
Training loss: 0.18329235911369324
Validation loss: 1.8471104137359127

Epoch: 6| Step: 8
Training loss: 0.27098098397254944
Validation loss: 1.8503384641421738

Epoch: 6| Step: 9
Training loss: 0.2695614695549011
Validation loss: 1.823231626582402

Epoch: 6| Step: 10
Training loss: 0.36896926164627075
Validation loss: 1.8354310143378474

Epoch: 6| Step: 11
Training loss: 0.31517493724823
Validation loss: 1.7541731608811246

Epoch: 6| Step: 12
Training loss: 0.2214183211326599
Validation loss: 1.6726667483647664

Epoch: 6| Step: 13
Training loss: 0.33073481917381287
Validation loss: 1.6511497113012499

Epoch: 331| Step: 0
Training loss: 0.23488014936447144
Validation loss: 1.6645933825482604

Epoch: 6| Step: 1
Training loss: 0.17317545413970947
Validation loss: 1.632266067689465

Epoch: 6| Step: 2
Training loss: 0.5217844247817993
Validation loss: 1.6035697319174325

Epoch: 6| Step: 3
Training loss: 0.2407396137714386
Validation loss: 1.625354656609156

Epoch: 6| Step: 4
Training loss: 0.2704271674156189
Validation loss: 1.6548957587570272

Epoch: 6| Step: 5
Training loss: 0.3379012942314148
Validation loss: 1.696762869434972

Epoch: 6| Step: 6
Training loss: 0.28524675965309143
Validation loss: 1.7156394489349858

Epoch: 6| Step: 7
Training loss: 0.23135600984096527
Validation loss: 1.7481979759790565

Epoch: 6| Step: 8
Training loss: 0.3334099054336548
Validation loss: 1.7983314760269657

Epoch: 6| Step: 9
Training loss: 0.633517861366272
Validation loss: 1.814759644128943

Epoch: 6| Step: 10
Training loss: 0.3866581916809082
Validation loss: 1.8319413738866006

Epoch: 6| Step: 11
Training loss: 0.8230026960372925
Validation loss: 1.8489114558824928

Epoch: 6| Step: 12
Training loss: 0.3337746560573578
Validation loss: 1.8401313507428734

Epoch: 6| Step: 13
Training loss: 0.2963041067123413
Validation loss: 1.88732498691928

Epoch: 332| Step: 0
Training loss: 0.37935149669647217
Validation loss: 1.816794664629044

Epoch: 6| Step: 1
Training loss: 0.5282201766967773
Validation loss: 1.7724595159612677

Epoch: 6| Step: 2
Training loss: 0.41200125217437744
Validation loss: 1.7189134679814821

Epoch: 6| Step: 3
Training loss: 0.2146538645029068
Validation loss: 1.707570263134536

Epoch: 6| Step: 4
Training loss: 0.2657836377620697
Validation loss: 1.7003771515302761

Epoch: 6| Step: 5
Training loss: 0.27043166756629944
Validation loss: 1.681668951306292

Epoch: 6| Step: 6
Training loss: 0.4198743999004364
Validation loss: 1.7283910718015445

Epoch: 6| Step: 7
Training loss: 0.4042714834213257
Validation loss: 1.7559339897606963

Epoch: 6| Step: 8
Training loss: 0.6139398217201233
Validation loss: 1.8163779627892278

Epoch: 6| Step: 9
Training loss: 0.38508185744285583
Validation loss: 1.8744687329056442

Epoch: 6| Step: 10
Training loss: 0.4272078275680542
Validation loss: 1.850808310252364

Epoch: 6| Step: 11
Training loss: 0.21673691272735596
Validation loss: 1.8690551775757984

Epoch: 6| Step: 12
Training loss: 0.39417436718940735
Validation loss: 1.8639744956006286

Epoch: 6| Step: 13
Training loss: 0.392509400844574
Validation loss: 1.8370717981810212

Epoch: 333| Step: 0
Training loss: 0.22756066918373108
Validation loss: 1.846872406621133

Epoch: 6| Step: 1
Training loss: 0.2087121307849884
Validation loss: 1.823055508316204

Epoch: 6| Step: 2
Training loss: 0.20537371933460236
Validation loss: 1.7648772860086093

Epoch: 6| Step: 3
Training loss: 0.27873694896698
Validation loss: 1.7723004535962177

Epoch: 6| Step: 4
Training loss: 0.3118900656700134
Validation loss: 1.77067861377552

Epoch: 6| Step: 5
Training loss: 0.18600119650363922
Validation loss: 1.7351006154091126

Epoch: 6| Step: 6
Training loss: 0.3576606512069702
Validation loss: 1.7833527582947926

Epoch: 6| Step: 7
Training loss: 0.18903177976608276
Validation loss: 1.804018566685338

Epoch: 6| Step: 8
Training loss: 0.34843575954437256
Validation loss: 1.7785484278073875

Epoch: 6| Step: 9
Training loss: 0.3221045732498169
Validation loss: 1.7669566574917044

Epoch: 6| Step: 10
Training loss: 0.24401769042015076
Validation loss: 1.7947877824947398

Epoch: 6| Step: 11
Training loss: 0.5764434337615967
Validation loss: 1.802367159115371

Epoch: 6| Step: 12
Training loss: 0.3203428387641907
Validation loss: 1.8441149086080573

Epoch: 6| Step: 13
Training loss: 0.658900260925293
Validation loss: 1.804103676990796

Epoch: 334| Step: 0
Training loss: 0.940880298614502
Validation loss: 1.7390854320218485

Epoch: 6| Step: 1
Training loss: 0.26065927743911743
Validation loss: 1.7089980802228373

Epoch: 6| Step: 2
Training loss: 0.3296452760696411
Validation loss: 1.6801517086644326

Epoch: 6| Step: 3
Training loss: 0.23018911480903625
Validation loss: 1.708010772864024

Epoch: 6| Step: 4
Training loss: 0.3200027346611023
Validation loss: 1.6957530360068045

Epoch: 6| Step: 5
Training loss: 0.31501859426498413
Validation loss: 1.7174512634995163

Epoch: 6| Step: 6
Training loss: 0.052534282207489014
Validation loss: 1.6948948239767423

Epoch: 6| Step: 7
Training loss: 0.1685836911201477
Validation loss: 1.6713878339336765

Epoch: 6| Step: 8
Training loss: 0.24354103207588196
Validation loss: 1.6529386402458273

Epoch: 6| Step: 9
Training loss: 0.3582916855812073
Validation loss: 1.6668122763274817

Epoch: 6| Step: 10
Training loss: 0.2217695116996765
Validation loss: 1.6671348207740373

Epoch: 6| Step: 11
Training loss: 0.3822575509548187
Validation loss: 1.695436195660663

Epoch: 6| Step: 12
Training loss: 0.2287973016500473
Validation loss: 1.703330587315303

Epoch: 6| Step: 13
Training loss: 0.27897411584854126
Validation loss: 1.7271372451577136

Epoch: 335| Step: 0
Training loss: 0.3551986813545227
Validation loss: 1.800464904436501

Epoch: 6| Step: 1
Training loss: 0.5955185890197754
Validation loss: 1.8298322667357743

Epoch: 6| Step: 2
Training loss: 0.21733036637306213
Validation loss: 1.8949675854816233

Epoch: 6| Step: 3
Training loss: 0.3094569742679596
Validation loss: 1.912973411621586

Epoch: 6| Step: 4
Training loss: 0.4878220558166504
Validation loss: 1.9465283809169647

Epoch: 6| Step: 5
Training loss: 0.30895835161209106
Validation loss: 1.9077876742168138

Epoch: 6| Step: 6
Training loss: 0.3669799268245697
Validation loss: 1.8529995820855583

Epoch: 6| Step: 7
Training loss: 0.5027385354042053
Validation loss: 1.8037202794064757

Epoch: 6| Step: 8
Training loss: 0.4193246066570282
Validation loss: 1.7446235738774782

Epoch: 6| Step: 9
Training loss: 0.2612525224685669
Validation loss: 1.68656022830676

Epoch: 6| Step: 10
Training loss: 0.1704137623310089
Validation loss: 1.67392167481043

Epoch: 6| Step: 11
Training loss: 0.204627126455307
Validation loss: 1.6060933515589724

Epoch: 6| Step: 12
Training loss: 0.31709080934524536
Validation loss: 1.610641029573256

Epoch: 6| Step: 13
Training loss: 0.2723551392555237
Validation loss: 1.5940737980668263

Epoch: 336| Step: 0
Training loss: 0.33616939187049866
Validation loss: 1.6479741834825086

Epoch: 6| Step: 1
Training loss: 0.5614679455757141
Validation loss: 1.649313324241228

Epoch: 6| Step: 2
Training loss: 0.27184590697288513
Validation loss: 1.692534669753044

Epoch: 6| Step: 3
Training loss: 0.3584054112434387
Validation loss: 1.7414379145509453

Epoch: 6| Step: 4
Training loss: 0.3730655610561371
Validation loss: 1.7500232932388142

Epoch: 6| Step: 5
Training loss: 0.3133676052093506
Validation loss: 1.75032437744961

Epoch: 6| Step: 6
Training loss: 0.7527315020561218
Validation loss: 1.775218597022436

Epoch: 6| Step: 7
Training loss: 0.38822096586227417
Validation loss: 1.7711812027039067

Epoch: 6| Step: 8
Training loss: 0.29494333267211914
Validation loss: 1.7422831199502433

Epoch: 6| Step: 9
Training loss: 0.22466644644737244
Validation loss: 1.7187810046698457

Epoch: 6| Step: 10
Training loss: 0.3261967599391937
Validation loss: 1.7044582713034846

Epoch: 6| Step: 11
Training loss: 0.2656898498535156
Validation loss: 1.7054103394990325

Epoch: 6| Step: 12
Training loss: 0.19979386031627655
Validation loss: 1.671846705098306

Epoch: 6| Step: 13
Training loss: 0.33983972668647766
Validation loss: 1.694663029845043

Epoch: 337| Step: 0
Training loss: 0.38694316148757935
Validation loss: 1.6752763512314006

Epoch: 6| Step: 1
Training loss: 0.2637092173099518
Validation loss: 1.699506530197718

Epoch: 6| Step: 2
Training loss: 0.3463073968887329
Validation loss: 1.7025940328515985

Epoch: 6| Step: 3
Training loss: 0.5344361066818237
Validation loss: 1.7024539747545797

Epoch: 6| Step: 4
Training loss: 0.3704821467399597
Validation loss: 1.7315310060337026

Epoch: 6| Step: 5
Training loss: 0.331159770488739
Validation loss: 1.7300975707269484

Epoch: 6| Step: 6
Training loss: 0.28432726860046387
Validation loss: 1.7627855449594476

Epoch: 6| Step: 7
Training loss: 0.5244060158729553
Validation loss: 1.7802390167790074

Epoch: 6| Step: 8
Training loss: 0.35916513204574585
Validation loss: 1.7479900480598531

Epoch: 6| Step: 9
Training loss: 0.22346258163452148
Validation loss: 1.6957013709570772

Epoch: 6| Step: 10
Training loss: 0.20290078222751617
Validation loss: 1.6698773573803645

Epoch: 6| Step: 11
Training loss: 0.21801835298538208
Validation loss: 1.6747697386690366

Epoch: 6| Step: 12
Training loss: 0.22769087553024292
Validation loss: 1.71979473867724

Epoch: 6| Step: 13
Training loss: 0.20722712576389313
Validation loss: 1.6660252489069456

Epoch: 338| Step: 0
Training loss: 0.20443817973136902
Validation loss: 1.6914918461153585

Epoch: 6| Step: 1
Training loss: 0.35866373777389526
Validation loss: 1.72133755940263

Epoch: 6| Step: 2
Training loss: 0.26669958233833313
Validation loss: 1.751669010808391

Epoch: 6| Step: 3
Training loss: 0.49557411670684814
Validation loss: 1.768407142290505

Epoch: 6| Step: 4
Training loss: 0.1794993281364441
Validation loss: 1.7361394782220163

Epoch: 6| Step: 5
Training loss: 0.6295093297958374
Validation loss: 1.7479033854699904

Epoch: 6| Step: 6
Training loss: 0.2860991060733795
Validation loss: 1.755258637089883

Epoch: 6| Step: 7
Training loss: 0.3310116231441498
Validation loss: 1.7506532912613244

Epoch: 6| Step: 8
Training loss: 0.26361411809921265
Validation loss: 1.807791152308064

Epoch: 6| Step: 9
Training loss: 0.3631686568260193
Validation loss: 1.7948363942484702

Epoch: 6| Step: 10
Training loss: 0.23500056564807892
Validation loss: 1.8277039335620018

Epoch: 6| Step: 11
Training loss: 0.3011707663536072
Validation loss: 1.8237551361001947

Epoch: 6| Step: 12
Training loss: 0.3169689178466797
Validation loss: 1.7723383595866542

Epoch: 6| Step: 13
Training loss: 0.3288508653640747
Validation loss: 1.7785424801611132

Epoch: 339| Step: 0
Training loss: 0.23754775524139404
Validation loss: 1.704994543906181

Epoch: 6| Step: 1
Training loss: 0.615892767906189
Validation loss: 1.7196561175007974

Epoch: 6| Step: 2
Training loss: 0.4121015667915344
Validation loss: 1.7538363305471276

Epoch: 6| Step: 3
Training loss: 0.29576098918914795
Validation loss: 1.708769945688145

Epoch: 6| Step: 4
Training loss: 0.24539990723133087
Validation loss: 1.7207643998566495

Epoch: 6| Step: 5
Training loss: 0.22802650928497314
Validation loss: 1.6883887642173356

Epoch: 6| Step: 6
Training loss: 0.6513882875442505
Validation loss: 1.6729208884700653

Epoch: 6| Step: 7
Training loss: 0.250729501247406
Validation loss: 1.6335033678239392

Epoch: 6| Step: 8
Training loss: 0.1814027726650238
Validation loss: 1.6689296294284124

Epoch: 6| Step: 9
Training loss: 0.18961843848228455
Validation loss: 1.6663814437004827

Epoch: 6| Step: 10
Training loss: 0.25278425216674805
Validation loss: 1.6827496918298865

Epoch: 6| Step: 11
Training loss: 0.1730685532093048
Validation loss: 1.7490328499065932

Epoch: 6| Step: 12
Training loss: 0.37015244364738464
Validation loss: 1.7489704009025329

Epoch: 6| Step: 13
Training loss: 0.19455204904079437
Validation loss: 1.7810852835255284

Epoch: 340| Step: 0
Training loss: 0.42882004380226135
Validation loss: 1.7305053421246108

Epoch: 6| Step: 1
Training loss: 0.4161650538444519
Validation loss: 1.7278987874266922

Epoch: 6| Step: 2
Training loss: 0.37873995304107666
Validation loss: 1.6765061706625006

Epoch: 6| Step: 3
Training loss: 0.5544804930686951
Validation loss: 1.699470862265556

Epoch: 6| Step: 4
Training loss: 0.36835983395576477
Validation loss: 1.6802423846337102

Epoch: 6| Step: 5
Training loss: 0.17214688658714294
Validation loss: 1.6801095560032835

Epoch: 6| Step: 6
Training loss: 0.34403038024902344
Validation loss: 1.7226526685940322

Epoch: 6| Step: 7
Training loss: 0.2186822146177292
Validation loss: 1.7067367030728249

Epoch: 6| Step: 8
Training loss: 0.21445319056510925
Validation loss: 1.7490115601529357

Epoch: 6| Step: 9
Training loss: 0.16845400631427765
Validation loss: 1.7877871374930105

Epoch: 6| Step: 10
Training loss: 0.21811449527740479
Validation loss: 1.7956678457157587

Epoch: 6| Step: 11
Training loss: 0.12024710327386856
Validation loss: 1.8180538133908344

Epoch: 6| Step: 12
Training loss: 0.4221208095550537
Validation loss: 1.7871124782869894

Epoch: 6| Step: 13
Training loss: 0.2776280641555786
Validation loss: 1.7598318707558416

Epoch: 341| Step: 0
Training loss: 0.2412775754928589
Validation loss: 1.6653870241616362

Epoch: 6| Step: 1
Training loss: 0.2953681945800781
Validation loss: 1.657676096885435

Epoch: 6| Step: 2
Training loss: 0.2297101616859436
Validation loss: 1.6374212939252135

Epoch: 6| Step: 3
Training loss: 0.4348551034927368
Validation loss: 1.6082527483663251

Epoch: 6| Step: 4
Training loss: 0.3980286121368408
Validation loss: 1.6252761361419514

Epoch: 6| Step: 5
Training loss: 0.43147894740104675
Validation loss: 1.6416459314284786

Epoch: 6| Step: 6
Training loss: 0.3208664059638977
Validation loss: 1.65642197157747

Epoch: 6| Step: 7
Training loss: 0.16284507513046265
Validation loss: 1.6067572152742775

Epoch: 6| Step: 8
Training loss: 0.31635230779647827
Validation loss: 1.6091358866742862

Epoch: 6| Step: 9
Training loss: 0.23013292253017426
Validation loss: 1.6638709447717155

Epoch: 6| Step: 10
Training loss: 0.18102723360061646
Validation loss: 1.6882555792408604

Epoch: 6| Step: 11
Training loss: 0.3151782751083374
Validation loss: 1.7251368530334965

Epoch: 6| Step: 12
Training loss: 0.5736405849456787
Validation loss: 1.749212331669305

Epoch: 6| Step: 13
Training loss: 0.18115872144699097
Validation loss: 1.800336141099212

Epoch: 342| Step: 0
Training loss: 0.2879585027694702
Validation loss: 1.8135802156181746

Epoch: 6| Step: 1
Training loss: 0.7187052369117737
Validation loss: 1.8005218031585857

Epoch: 6| Step: 2
Training loss: 0.3569038510322571
Validation loss: 1.8080235719680786

Epoch: 6| Step: 3
Training loss: 0.30584120750427246
Validation loss: 1.834886472712281

Epoch: 6| Step: 4
Training loss: 0.26303064823150635
Validation loss: 1.785767150181596

Epoch: 6| Step: 5
Training loss: 0.21887686848640442
Validation loss: 1.7778514328823294

Epoch: 6| Step: 6
Training loss: 0.22843696177005768
Validation loss: 1.744666161075715

Epoch: 6| Step: 7
Training loss: 0.1678958237171173
Validation loss: 1.7469835672327267

Epoch: 6| Step: 8
Training loss: 0.21794478595256805
Validation loss: 1.7323557728080339

Epoch: 6| Step: 9
Training loss: 0.28732508420944214
Validation loss: 1.7415033386599632

Epoch: 6| Step: 10
Training loss: 0.2231275886297226
Validation loss: 1.7144016476087673

Epoch: 6| Step: 11
Training loss: 0.31961166858673096
Validation loss: 1.6963829891656035

Epoch: 6| Step: 12
Training loss: 0.23580732941627502
Validation loss: 1.7089986942147697

Epoch: 6| Step: 13
Training loss: 0.34911346435546875
Validation loss: 1.7475151297866658

Epoch: 343| Step: 0
Training loss: 0.44395607709884644
Validation loss: 1.6922655374773088

Epoch: 6| Step: 1
Training loss: 0.186679869890213
Validation loss: 1.7044209357230895

Epoch: 6| Step: 2
Training loss: 0.2713494896888733
Validation loss: 1.7245515969491774

Epoch: 6| Step: 3
Training loss: 0.22276276350021362
Validation loss: 1.7164966983179892

Epoch: 6| Step: 4
Training loss: 0.5074400305747986
Validation loss: 1.7113294127166911

Epoch: 6| Step: 5
Training loss: 0.31780508160591125
Validation loss: 1.7028168644956363

Epoch: 6| Step: 6
Training loss: 0.2370675504207611
Validation loss: 1.7348957536041096

Epoch: 6| Step: 7
Training loss: 0.31478145718574524
Validation loss: 1.6926775247819963

Epoch: 6| Step: 8
Training loss: 0.21196052432060242
Validation loss: 1.6576181291252055

Epoch: 6| Step: 9
Training loss: 0.3001369833946228
Validation loss: 1.6611679677040345

Epoch: 6| Step: 10
Training loss: 0.3322256803512573
Validation loss: 1.6365439058631979

Epoch: 6| Step: 11
Training loss: 0.1827656775712967
Validation loss: 1.6545411232979066

Epoch: 6| Step: 12
Training loss: 0.408428430557251
Validation loss: 1.6394496617778656

Epoch: 6| Step: 13
Training loss: 0.23088547587394714
Validation loss: 1.693572667337233

Epoch: 344| Step: 0
Training loss: 0.29636216163635254
Validation loss: 1.7245322747897076

Epoch: 6| Step: 1
Training loss: 0.25769510865211487
Validation loss: 1.7476124789125176

Epoch: 6| Step: 2
Training loss: 0.27816975116729736
Validation loss: 1.7563610743450861

Epoch: 6| Step: 3
Training loss: 0.14930397272109985
Validation loss: 1.7324578492872176

Epoch: 6| Step: 4
Training loss: 0.2132711261510849
Validation loss: 1.7276568822963263

Epoch: 6| Step: 5
Training loss: 0.2892305552959442
Validation loss: 1.698559727720035

Epoch: 6| Step: 6
Training loss: 0.6573313474655151
Validation loss: 1.6949201796644477

Epoch: 6| Step: 7
Training loss: 0.28613951802253723
Validation loss: 1.6744020446654289

Epoch: 6| Step: 8
Training loss: 0.20870034396648407
Validation loss: 1.6443630713288502

Epoch: 6| Step: 9
Training loss: 0.2295946329832077
Validation loss: 1.6499740923604658

Epoch: 6| Step: 10
Training loss: 0.37004226446151733
Validation loss: 1.6549013686436478

Epoch: 6| Step: 11
Training loss: 0.34267938137054443
Validation loss: 1.6472955288425568

Epoch: 6| Step: 12
Training loss: 0.28952088952064514
Validation loss: 1.6596551864377913

Epoch: 6| Step: 13
Training loss: 0.16753113269805908
Validation loss: 1.6612805064006517

Epoch: 345| Step: 0
Training loss: 0.19243353605270386
Validation loss: 1.6697367698915544

Epoch: 6| Step: 1
Training loss: 0.2566916346549988
Validation loss: 1.6496086056514452

Epoch: 6| Step: 2
Training loss: 0.6163727641105652
Validation loss: 1.6710096866853776

Epoch: 6| Step: 3
Training loss: 0.2746143341064453
Validation loss: 1.7008189514119139

Epoch: 6| Step: 4
Training loss: 0.2553052306175232
Validation loss: 1.7403605689284622

Epoch: 6| Step: 5
Training loss: 0.4939148724079132
Validation loss: 1.7316831696418025

Epoch: 6| Step: 6
Training loss: 0.16190150380134583
Validation loss: 1.6793808949890958

Epoch: 6| Step: 7
Training loss: 0.23781853914260864
Validation loss: 1.6773807297470749

Epoch: 6| Step: 8
Training loss: 0.13082394003868103
Validation loss: 1.6559789539665304

Epoch: 6| Step: 9
Training loss: 0.1422574818134308
Validation loss: 1.648909044522111

Epoch: 6| Step: 10
Training loss: 0.33934032917022705
Validation loss: 1.5926948401235765

Epoch: 6| Step: 11
Training loss: 0.3465133309364319
Validation loss: 1.6489884109907254

Epoch: 6| Step: 12
Training loss: 0.25633323192596436
Validation loss: 1.6464443629787815

Epoch: 6| Step: 13
Training loss: 0.13433368504047394
Validation loss: 1.6622549013424945

Epoch: 346| Step: 0
Training loss: 0.5011699795722961
Validation loss: 1.6699655414909444

Epoch: 6| Step: 1
Training loss: 0.39186400175094604
Validation loss: 1.676677260347592

Epoch: 6| Step: 2
Training loss: 0.2749822437763214
Validation loss: 1.7161794298438615

Epoch: 6| Step: 3
Training loss: 0.269216388463974
Validation loss: 1.7629020188444404

Epoch: 6| Step: 4
Training loss: 0.17885611951351166
Validation loss: 1.7663204785316222

Epoch: 6| Step: 5
Training loss: 0.32260313630104065
Validation loss: 1.7624992042459466

Epoch: 6| Step: 6
Training loss: 0.3420518636703491
Validation loss: 1.7651260463140344

Epoch: 6| Step: 7
Training loss: 0.19730108976364136
Validation loss: 1.7458641426537627

Epoch: 6| Step: 8
Training loss: 0.11199311167001724
Validation loss: 1.7562887501972977

Epoch: 6| Step: 9
Training loss: 0.3264979124069214
Validation loss: 1.7712326806078675

Epoch: 6| Step: 10
Training loss: 0.22853845357894897
Validation loss: 1.7289777673700804

Epoch: 6| Step: 11
Training loss: 0.24874362349510193
Validation loss: 1.7202133132565407

Epoch: 6| Step: 12
Training loss: 0.30388692021369934
Validation loss: 1.697149290833422

Epoch: 6| Step: 13
Training loss: 0.2951393127441406
Validation loss: 1.728306608815347

Epoch: 347| Step: 0
Training loss: 0.5381823778152466
Validation loss: 1.7328114522400724

Epoch: 6| Step: 1
Training loss: 0.23940902948379517
Validation loss: 1.7057504935931134

Epoch: 6| Step: 2
Training loss: 0.42871037125587463
Validation loss: 1.7038944293093938

Epoch: 6| Step: 3
Training loss: 0.25914907455444336
Validation loss: 1.7103368877082743

Epoch: 6| Step: 4
Training loss: 0.27484697103500366
Validation loss: 1.685124917696881

Epoch: 6| Step: 5
Training loss: 0.2370137870311737
Validation loss: 1.7130172688473937

Epoch: 6| Step: 6
Training loss: 0.21732431650161743
Validation loss: 1.750685796942762

Epoch: 6| Step: 7
Training loss: 0.27400076389312744
Validation loss: 1.7681770337525236

Epoch: 6| Step: 8
Training loss: 0.4401518702507019
Validation loss: 1.7728589824450913

Epoch: 6| Step: 9
Training loss: 0.14285849034786224
Validation loss: 1.783616255688411

Epoch: 6| Step: 10
Training loss: 0.30344897508621216
Validation loss: 1.7511413097381592

Epoch: 6| Step: 11
Training loss: 0.2998720407485962
Validation loss: 1.7136398060347444

Epoch: 6| Step: 12
Training loss: 0.1562352180480957
Validation loss: 1.6812886076588784

Epoch: 6| Step: 13
Training loss: 0.1577986627817154
Validation loss: 1.687748057867891

Epoch: 348| Step: 0
Training loss: 0.3534756302833557
Validation loss: 1.7002441703632314

Epoch: 6| Step: 1
Training loss: 0.4191293716430664
Validation loss: 1.6860589916988085

Epoch: 6| Step: 2
Training loss: 0.18709205090999603
Validation loss: 1.7089515860362718

Epoch: 6| Step: 3
Training loss: 0.17315331101417542
Validation loss: 1.7147351580281411

Epoch: 6| Step: 4
Training loss: 0.1776387095451355
Validation loss: 1.7349831032496628

Epoch: 6| Step: 5
Training loss: 0.17659452557563782
Validation loss: 1.694221221631573

Epoch: 6| Step: 6
Training loss: 0.19698916375637054
Validation loss: 1.7351768785907375

Epoch: 6| Step: 7
Training loss: 0.24172398447990417
Validation loss: 1.7315430512992285

Epoch: 6| Step: 8
Training loss: 0.20803110301494598
Validation loss: 1.7317539671415925

Epoch: 6| Step: 9
Training loss: 0.20231248438358307
Validation loss: 1.7500595123537126

Epoch: 6| Step: 10
Training loss: 0.4431227445602417
Validation loss: 1.7032059648985505

Epoch: 6| Step: 11
Training loss: 0.4987693428993225
Validation loss: 1.766898819195327

Epoch: 6| Step: 12
Training loss: 0.20986123383045197
Validation loss: 1.7797613028557069

Epoch: 6| Step: 13
Training loss: 0.25480222702026367
Validation loss: 1.7761710350231459

Epoch: 349| Step: 0
Training loss: 0.2639274597167969
Validation loss: 1.7606669933565202

Epoch: 6| Step: 1
Training loss: 0.365481972694397
Validation loss: 1.786965452214723

Epoch: 6| Step: 2
Training loss: 0.34007564187049866
Validation loss: 1.7439019116022254

Epoch: 6| Step: 3
Training loss: 0.24779120087623596
Validation loss: 1.7321918446530578

Epoch: 6| Step: 4
Training loss: 0.5210846066474915
Validation loss: 1.7104550587233676

Epoch: 6| Step: 5
Training loss: 0.2960895299911499
Validation loss: 1.722913521592335

Epoch: 6| Step: 6
Training loss: 0.269307404756546
Validation loss: 1.709604073596257

Epoch: 6| Step: 7
Training loss: 0.16127556562423706
Validation loss: 1.6905691905688214

Epoch: 6| Step: 8
Training loss: 0.24342508614063263
Validation loss: 1.7035522512210313

Epoch: 6| Step: 9
Training loss: 0.2392425239086151
Validation loss: 1.7216725977518226

Epoch: 6| Step: 10
Training loss: 0.14906102418899536
Validation loss: 1.7291699378721175

Epoch: 6| Step: 11
Training loss: 0.19209176301956177
Validation loss: 1.736056427801809

Epoch: 6| Step: 12
Training loss: 0.18378064036369324
Validation loss: 1.7422362245539182

Epoch: 6| Step: 13
Training loss: 0.757646381855011
Validation loss: 1.732026230904364

Epoch: 350| Step: 0
Training loss: 0.11867646127939224
Validation loss: 1.7056093344124414

Epoch: 6| Step: 1
Training loss: 0.25495538115501404
Validation loss: 1.711415788819713

Epoch: 6| Step: 2
Training loss: 0.1831216961145401
Validation loss: 1.6999091961050545

Epoch: 6| Step: 3
Training loss: 0.23837393522262573
Validation loss: 1.6749913807838195

Epoch: 6| Step: 4
Training loss: 0.20825666189193726
Validation loss: 1.676728884379069

Epoch: 6| Step: 5
Training loss: 0.1313927173614502
Validation loss: 1.6451198747081142

Epoch: 6| Step: 6
Training loss: 0.19026371836662292
Validation loss: 1.6477709277983634

Epoch: 6| Step: 7
Training loss: 0.34722375869750977
Validation loss: 1.6322004231073524

Epoch: 6| Step: 8
Training loss: 0.25117236375808716
Validation loss: 1.6665813025607858

Epoch: 6| Step: 9
Training loss: 0.27774837613105774
Validation loss: 1.6837119094787105

Epoch: 6| Step: 10
Training loss: 0.26124635338783264
Validation loss: 1.6937084223634453

Epoch: 6| Step: 11
Training loss: 0.612787127494812
Validation loss: 1.6926852874858405

Epoch: 6| Step: 12
Training loss: 0.2941654324531555
Validation loss: 1.7236430644989014

Epoch: 6| Step: 13
Training loss: 0.2554316222667694
Validation loss: 1.713883476872598

Epoch: 351| Step: 0
Training loss: 0.21683186292648315
Validation loss: 1.6710861306036673

Epoch: 6| Step: 1
Training loss: 0.26634371280670166
Validation loss: 1.6616394840260988

Epoch: 6| Step: 2
Training loss: 0.2891155481338501
Validation loss: 1.7014283082818473

Epoch: 6| Step: 3
Training loss: 0.27953648567199707
Validation loss: 1.6999832782694089

Epoch: 6| Step: 4
Training loss: 0.19839178025722504
Validation loss: 1.7442577269769484

Epoch: 6| Step: 5
Training loss: 0.23403751850128174
Validation loss: 1.7609312136967976

Epoch: 6| Step: 6
Training loss: 0.5026863217353821
Validation loss: 1.7771870859207646

Epoch: 6| Step: 7
Training loss: 0.3557153344154358
Validation loss: 1.7584567044370918

Epoch: 6| Step: 8
Training loss: 0.22760799527168274
Validation loss: 1.8171128355046755

Epoch: 6| Step: 9
Training loss: 0.19138962030410767
Validation loss: 1.829790405047837

Epoch: 6| Step: 10
Training loss: 0.22517715394496918
Validation loss: 1.8120542521117835

Epoch: 6| Step: 11
Training loss: 0.7327102422714233
Validation loss: 1.8233896583639166

Epoch: 6| Step: 12
Training loss: 0.2525707185268402
Validation loss: 1.82888085995951

Epoch: 6| Step: 13
Training loss: 0.34636494517326355
Validation loss: 1.7974071143775858

Epoch: 352| Step: 0
Training loss: 0.6275447607040405
Validation loss: 1.7452297851603518

Epoch: 6| Step: 1
Training loss: 0.18405607342720032
Validation loss: 1.7285374928546209

Epoch: 6| Step: 2
Training loss: 0.19411484897136688
Validation loss: 1.7118082123418008

Epoch: 6| Step: 3
Training loss: 0.15415655076503754
Validation loss: 1.680796383529581

Epoch: 6| Step: 4
Training loss: 0.2855392098426819
Validation loss: 1.6861643252834198

Epoch: 6| Step: 5
Training loss: 0.44523531198501587
Validation loss: 1.6541100855796569

Epoch: 6| Step: 6
Training loss: 0.18519151210784912
Validation loss: 1.6823687963588263

Epoch: 6| Step: 7
Training loss: 0.28900569677352905
Validation loss: 1.6774904702299385

Epoch: 6| Step: 8
Training loss: 0.1786642223596573
Validation loss: 1.655225138510427

Epoch: 6| Step: 9
Training loss: 0.42059606313705444
Validation loss: 1.6543769490334295

Epoch: 6| Step: 10
Training loss: 0.21096408367156982
Validation loss: 1.6165911760381473

Epoch: 6| Step: 11
Training loss: 0.40619945526123047
Validation loss: 1.6557727449683732

Epoch: 6| Step: 12
Training loss: 0.13951845467090607
Validation loss: 1.6432359128869989

Epoch: 6| Step: 13
Training loss: 0.17913317680358887
Validation loss: 1.6525431435595277

Epoch: 353| Step: 0
Training loss: 0.18456344306468964
Validation loss: 1.6582908027915544

Epoch: 6| Step: 1
Training loss: 0.2181559056043625
Validation loss: 1.6876427101832565

Epoch: 6| Step: 2
Training loss: 0.3317713439464569
Validation loss: 1.6796214631808701

Epoch: 6| Step: 3
Training loss: 0.23491984605789185
Validation loss: 1.6693588738800378

Epoch: 6| Step: 4
Training loss: 0.18302656710147858
Validation loss: 1.6318444385323474

Epoch: 6| Step: 5
Training loss: 0.2287467122077942
Validation loss: 1.6833828008303078

Epoch: 6| Step: 6
Training loss: 0.42403310537338257
Validation loss: 1.6619966299303117

Epoch: 6| Step: 7
Training loss: 0.15141458809375763
Validation loss: 1.6171309127602527

Epoch: 6| Step: 8
Training loss: 0.1849721074104309
Validation loss: 1.617208545566887

Epoch: 6| Step: 9
Training loss: 0.4463390111923218
Validation loss: 1.6435042171068088

Epoch: 6| Step: 10
Training loss: 0.2342517077922821
Validation loss: 1.6544082485219485

Epoch: 6| Step: 11
Training loss: 0.6062982082366943
Validation loss: 1.6847072134735763

Epoch: 6| Step: 12
Training loss: 0.17331784963607788
Validation loss: 1.6847622138197704

Epoch: 6| Step: 13
Training loss: 0.2438593953847885
Validation loss: 1.6876045157832484

Epoch: 354| Step: 0
Training loss: 0.21402721107006073
Validation loss: 1.6816305268195368

Epoch: 6| Step: 1
Training loss: 0.3199455738067627
Validation loss: 1.6663041422444005

Epoch: 6| Step: 2
Training loss: 0.21292635798454285
Validation loss: 1.6703892933425082

Epoch: 6| Step: 3
Training loss: 0.16143690049648285
Validation loss: 1.6872497540648266

Epoch: 6| Step: 4
Training loss: 0.3068268299102783
Validation loss: 1.6609508183694655

Epoch: 6| Step: 5
Training loss: 0.19316858053207397
Validation loss: 1.7263318146428754

Epoch: 6| Step: 6
Training loss: 0.19492319226264954
Validation loss: 1.7097902477428477

Epoch: 6| Step: 7
Training loss: 0.253371924161911
Validation loss: 1.7540574855701898

Epoch: 6| Step: 8
Training loss: 0.21055814623832703
Validation loss: 1.781750258579049

Epoch: 6| Step: 9
Training loss: 0.22190196812152863
Validation loss: 1.7277766530231764

Epoch: 6| Step: 10
Training loss: 0.7785763740539551
Validation loss: 1.8043475971427014

Epoch: 6| Step: 11
Training loss: 0.15562009811401367
Validation loss: 1.7730187998023084

Epoch: 6| Step: 12
Training loss: 0.297049343585968
Validation loss: 1.756185559816258

Epoch: 6| Step: 13
Training loss: 0.35910564661026
Validation loss: 1.7794558021330065

Epoch: 355| Step: 0
Training loss: 0.1913507580757141
Validation loss: 1.777302611258722

Epoch: 6| Step: 1
Training loss: 0.22439923882484436
Validation loss: 1.7530433977803876

Epoch: 6| Step: 2
Training loss: 0.3170580565929413
Validation loss: 1.71934143189461

Epoch: 6| Step: 3
Training loss: 0.2637913227081299
Validation loss: 1.7035331649165

Epoch: 6| Step: 4
Training loss: 0.25002267956733704
Validation loss: 1.6847725632370159

Epoch: 6| Step: 5
Training loss: 0.2848738729953766
Validation loss: 1.6677488037334975

Epoch: 6| Step: 6
Training loss: 0.7086812853813171
Validation loss: 1.6584334341428613

Epoch: 6| Step: 7
Training loss: 0.28998976945877075
Validation loss: 1.6818476825632074

Epoch: 6| Step: 8
Training loss: 0.23570799827575684
Validation loss: 1.6982844837250248

Epoch: 6| Step: 9
Training loss: 0.3526042103767395
Validation loss: 1.723042372734316

Epoch: 6| Step: 10
Training loss: 0.30434006452560425
Validation loss: 1.703482865005411

Epoch: 6| Step: 11
Training loss: 0.2191462516784668
Validation loss: 1.731092232529835

Epoch: 6| Step: 12
Training loss: 0.1965503990650177
Validation loss: 1.7200530523894935

Epoch: 6| Step: 13
Training loss: 0.11337193101644516
Validation loss: 1.7190256246956446

Epoch: 356| Step: 0
Training loss: 0.21264812350273132
Validation loss: 1.7485746619521931

Epoch: 6| Step: 1
Training loss: 0.20860758423805237
Validation loss: 1.7467078547323904

Epoch: 6| Step: 2
Training loss: 0.5085558295249939
Validation loss: 1.7806906418133808

Epoch: 6| Step: 3
Training loss: 0.275926798582077
Validation loss: 1.770969395996422

Epoch: 6| Step: 4
Training loss: 0.30135273933410645
Validation loss: 1.752329158526595

Epoch: 6| Step: 5
Training loss: 0.17779476940631866
Validation loss: 1.7509631495321951

Epoch: 6| Step: 6
Training loss: 0.24109593033790588
Validation loss: 1.7085773496217624

Epoch: 6| Step: 7
Training loss: 0.1957489401102066
Validation loss: 1.7098675645807737

Epoch: 6| Step: 8
Training loss: 0.2058674544095993
Validation loss: 1.7085334331758562

Epoch: 6| Step: 9
Training loss: 0.2477560043334961
Validation loss: 1.7246329476756435

Epoch: 6| Step: 10
Training loss: 0.3939453959465027
Validation loss: 1.7139167234461794

Epoch: 6| Step: 11
Training loss: 0.31840240955352783
Validation loss: 1.7089436041411532

Epoch: 6| Step: 12
Training loss: 0.18237905204296112
Validation loss: 1.6528735122373026

Epoch: 6| Step: 13
Training loss: 0.24053451418876648
Validation loss: 1.6955935352592058

Epoch: 357| Step: 0
Training loss: 0.546699583530426
Validation loss: 1.7117843012655936

Epoch: 6| Step: 1
Training loss: 0.28552114963531494
Validation loss: 1.6940086298091437

Epoch: 6| Step: 2
Training loss: 0.38139021396636963
Validation loss: 1.697375650046974

Epoch: 6| Step: 3
Training loss: 0.15276110172271729
Validation loss: 1.6941538267238165

Epoch: 6| Step: 4
Training loss: 0.11342578381299973
Validation loss: 1.714743359114534

Epoch: 6| Step: 5
Training loss: 0.3542746901512146
Validation loss: 1.7214279777260237

Epoch: 6| Step: 6
Training loss: 0.24462006986141205
Validation loss: 1.746323694464981

Epoch: 6| Step: 7
Training loss: 0.2923860549926758
Validation loss: 1.7468051461763279

Epoch: 6| Step: 8
Training loss: 0.30292555689811707
Validation loss: 1.7798804865088513

Epoch: 6| Step: 9
Training loss: 0.187658429145813
Validation loss: 1.7502046951683619

Epoch: 6| Step: 10
Training loss: 0.36284518241882324
Validation loss: 1.7207616439429663

Epoch: 6| Step: 11
Training loss: 0.2657868564128876
Validation loss: 1.726872092934065

Epoch: 6| Step: 12
Training loss: 0.36123692989349365
Validation loss: 1.7769747344396447

Epoch: 6| Step: 13
Training loss: 0.06982458382844925
Validation loss: 1.7362035346287552

Epoch: 358| Step: 0
Training loss: 0.4964410662651062
Validation loss: 1.7248407307491507

Epoch: 6| Step: 1
Training loss: 0.19264502823352814
Validation loss: 1.7539486551797518

Epoch: 6| Step: 2
Training loss: 0.2695278823375702
Validation loss: 1.7454794683764059

Epoch: 6| Step: 3
Training loss: 0.2847042679786682
Validation loss: 1.6851871449460265

Epoch: 6| Step: 4
Training loss: 0.2814379334449768
Validation loss: 1.7135522057933192

Epoch: 6| Step: 5
Training loss: 0.18335381150245667
Validation loss: 1.7063543950357745

Epoch: 6| Step: 6
Training loss: 0.16278958320617676
Validation loss: 1.6931363869738836

Epoch: 6| Step: 7
Training loss: 0.19997917115688324
Validation loss: 1.694876911819622

Epoch: 6| Step: 8
Training loss: 0.25071871280670166
Validation loss: 1.7068314988126037

Epoch: 6| Step: 9
Training loss: 0.11864062398672104
Validation loss: 1.7141984226883098

Epoch: 6| Step: 10
Training loss: 0.1842385083436966
Validation loss: 1.755000631014506

Epoch: 6| Step: 11
Training loss: 0.35876673460006714
Validation loss: 1.707080610336796

Epoch: 6| Step: 12
Training loss: 0.26926925778388977
Validation loss: 1.7095474530291814

Epoch: 6| Step: 13
Training loss: 0.3216188848018646
Validation loss: 1.6900330410208753

Epoch: 359| Step: 0
Training loss: 0.1648310124874115
Validation loss: 1.6872658524461972

Epoch: 6| Step: 1
Training loss: 0.13518798351287842
Validation loss: 1.6187266483101794

Epoch: 6| Step: 2
Training loss: 0.2542576193809509
Validation loss: 1.6660755782999017

Epoch: 6| Step: 3
Training loss: 0.24120746552944183
Validation loss: 1.6499566801132695

Epoch: 6| Step: 4
Training loss: 0.2912343144416809
Validation loss: 1.680775652649582

Epoch: 6| Step: 5
Training loss: 0.3758203685283661
Validation loss: 1.6950144216578493

Epoch: 6| Step: 6
Training loss: 0.224713534116745
Validation loss: 1.6660621550775343

Epoch: 6| Step: 7
Training loss: 0.29389721155166626
Validation loss: 1.6692771065619685

Epoch: 6| Step: 8
Training loss: 0.28092366456985474
Validation loss: 1.6877464414924703

Epoch: 6| Step: 9
Training loss: 0.16067247092723846
Validation loss: 1.712066037680513

Epoch: 6| Step: 10
Training loss: 0.5165451765060425
Validation loss: 1.7326302720654396

Epoch: 6| Step: 11
Training loss: 0.11197839677333832
Validation loss: 1.738269934090235

Epoch: 6| Step: 12
Training loss: 0.19909797608852386
Validation loss: 1.754006866485842

Epoch: 6| Step: 13
Training loss: 0.2039271742105484
Validation loss: 1.8048405493459394

Epoch: 360| Step: 0
Training loss: 0.2477157860994339
Validation loss: 1.7747847982632217

Epoch: 6| Step: 1
Training loss: 0.24350222945213318
Validation loss: 1.7947038168548255

Epoch: 6| Step: 2
Training loss: 0.14188982546329498
Validation loss: 1.7446716716212611

Epoch: 6| Step: 3
Training loss: 0.23850050568580627
Validation loss: 1.7879067633741645

Epoch: 6| Step: 4
Training loss: 0.4703823924064636
Validation loss: 1.7464550169565345

Epoch: 6| Step: 5
Training loss: 0.21334221959114075
Validation loss: 1.7254002812088176

Epoch: 6| Step: 6
Training loss: 0.4626656770706177
Validation loss: 1.7039729151674496

Epoch: 6| Step: 7
Training loss: 0.18911853432655334
Validation loss: 1.7120269370335404

Epoch: 6| Step: 8
Training loss: 0.21812941133975983
Validation loss: 1.6619038697211974

Epoch: 6| Step: 9
Training loss: 0.20342597365379333
Validation loss: 1.6379528122563516

Epoch: 6| Step: 10
Training loss: 0.3507933020591736
Validation loss: 1.6110163709168792

Epoch: 6| Step: 11
Training loss: 0.2462484985589981
Validation loss: 1.601067167456432

Epoch: 6| Step: 12
Training loss: 0.1644311398267746
Validation loss: 1.6121018381528958

Epoch: 6| Step: 13
Training loss: 0.3291388750076294
Validation loss: 1.602131930730676

Epoch: 361| Step: 0
Training loss: 0.18482425808906555
Validation loss: 1.5955689491764191

Epoch: 6| Step: 1
Training loss: 0.15805205702781677
Validation loss: 1.6310159852427821

Epoch: 6| Step: 2
Training loss: 0.35639187693595886
Validation loss: 1.643287899673626

Epoch: 6| Step: 3
Training loss: 0.26741474866867065
Validation loss: 1.6640111111825513

Epoch: 6| Step: 4
Training loss: 0.20377103984355927
Validation loss: 1.6391986377777592

Epoch: 6| Step: 5
Training loss: 0.1369326263666153
Validation loss: 1.6447608342734716

Epoch: 6| Step: 6
Training loss: 0.20622438192367554
Validation loss: 1.6462241295845277

Epoch: 6| Step: 7
Training loss: 0.2883175015449524
Validation loss: 1.6425003941341112

Epoch: 6| Step: 8
Training loss: 0.19231463968753815
Validation loss: 1.6492456108011224

Epoch: 6| Step: 9
Training loss: 0.21581806242465973
Validation loss: 1.598825184247827

Epoch: 6| Step: 10
Training loss: 0.31815046072006226
Validation loss: 1.6156420938430294

Epoch: 6| Step: 11
Training loss: 0.7049382925033569
Validation loss: 1.5930264790852864

Epoch: 6| Step: 12
Training loss: 0.2102469652891159
Validation loss: 1.6259946015573317

Epoch: 6| Step: 13
Training loss: 0.3502015471458435
Validation loss: 1.6054807965473463

Epoch: 362| Step: 0
Training loss: 0.3824382424354553
Validation loss: 1.6355469060200516

Epoch: 6| Step: 1
Training loss: 0.14667539298534393
Validation loss: 1.6521028754531697

Epoch: 6| Step: 2
Training loss: 0.19236096739768982
Validation loss: 1.6935411448119788

Epoch: 6| Step: 3
Training loss: 0.5733386278152466
Validation loss: 1.6931011702424736

Epoch: 6| Step: 4
Training loss: 0.2838876247406006
Validation loss: 1.7036013859574513

Epoch: 6| Step: 5
Training loss: 0.322729229927063
Validation loss: 1.7681776028807445

Epoch: 6| Step: 6
Training loss: 0.3632371127605438
Validation loss: 1.7761493139369513

Epoch: 6| Step: 7
Training loss: 0.22971788048744202
Validation loss: 1.7839395333361883

Epoch: 6| Step: 8
Training loss: 0.29207757115364075
Validation loss: 1.7667983270460559

Epoch: 6| Step: 9
Training loss: 0.16666454076766968
Validation loss: 1.7199905277580343

Epoch: 6| Step: 10
Training loss: 0.20242635905742645
Validation loss: 1.669537991605779

Epoch: 6| Step: 11
Training loss: 0.13656461238861084
Validation loss: 1.6761902891179568

Epoch: 6| Step: 12
Training loss: 0.24337583780288696
Validation loss: 1.656878673902122

Epoch: 6| Step: 13
Training loss: 0.1401754915714264
Validation loss: 1.6610046612319125

Epoch: 363| Step: 0
Training loss: 0.1714755892753601
Validation loss: 1.6413159101240096

Epoch: 6| Step: 1
Training loss: 0.31795671582221985
Validation loss: 1.6608649851173483

Epoch: 6| Step: 2
Training loss: 0.22003473341464996
Validation loss: 1.6531591992224417

Epoch: 6| Step: 3
Training loss: 0.5483410358428955
Validation loss: 1.720739177478257

Epoch: 6| Step: 4
Training loss: 0.14495059847831726
Validation loss: 1.7419434350023988

Epoch: 6| Step: 5
Training loss: 0.08959048986434937
Validation loss: 1.7183708375500095

Epoch: 6| Step: 6
Training loss: 0.3210601806640625
Validation loss: 1.796787888773026

Epoch: 6| Step: 7
Training loss: 0.20631210505962372
Validation loss: 1.793205770113135

Epoch: 6| Step: 8
Training loss: 0.1541062444448471
Validation loss: 1.7780991754224222

Epoch: 6| Step: 9
Training loss: 0.22281965613365173
Validation loss: 1.7385997028761013

Epoch: 6| Step: 10
Training loss: 0.24529042840003967
Validation loss: 1.7225038082368913

Epoch: 6| Step: 11
Training loss: 0.25353288650512695
Validation loss: 1.646899671964748

Epoch: 6| Step: 12
Training loss: 0.31376877427101135
Validation loss: 1.6540127761902348

Epoch: 6| Step: 13
Training loss: 0.13585175573825836
Validation loss: 1.589840627485706

Epoch: 364| Step: 0
Training loss: 0.18260928988456726
Validation loss: 1.6132206891172676

Epoch: 6| Step: 1
Training loss: 0.22533702850341797
Validation loss: 1.6534052125869259

Epoch: 6| Step: 2
Training loss: 0.24638991057872772
Validation loss: 1.6709625374886297

Epoch: 6| Step: 3
Training loss: 0.35731446743011475
Validation loss: 1.7276056940837572

Epoch: 6| Step: 4
Training loss: 0.22318658232688904
Validation loss: 1.7276199927894018

Epoch: 6| Step: 5
Training loss: 0.5523929595947266
Validation loss: 1.7436843431124123

Epoch: 6| Step: 6
Training loss: 0.1855691522359848
Validation loss: 1.8121139311021375

Epoch: 6| Step: 7
Training loss: 0.22356706857681274
Validation loss: 1.83546479030322

Epoch: 6| Step: 8
Training loss: 0.18275444209575653
Validation loss: 1.8558153849776073

Epoch: 6| Step: 9
Training loss: 0.32874616980552673
Validation loss: 1.880695225090109

Epoch: 6| Step: 10
Training loss: 0.14744949340820312
Validation loss: 1.8439161162222586

Epoch: 6| Step: 11
Training loss: 0.20406413078308105
Validation loss: 1.8076704881524528

Epoch: 6| Step: 12
Training loss: 0.37759149074554443
Validation loss: 1.7661357977057015

Epoch: 6| Step: 13
Training loss: 0.25883495807647705
Validation loss: 1.6980593448044152

Epoch: 365| Step: 0
Training loss: 0.282263845205307
Validation loss: 1.6725715142424389

Epoch: 6| Step: 1
Training loss: 0.18059886991977692
Validation loss: 1.6575028845058974

Epoch: 6| Step: 2
Training loss: 0.38344162702560425
Validation loss: 1.6650249086400515

Epoch: 6| Step: 3
Training loss: 0.09414838254451752
Validation loss: 1.6901248014101418

Epoch: 6| Step: 4
Training loss: 0.1433485448360443
Validation loss: 1.6980194968561972

Epoch: 6| Step: 5
Training loss: 0.32495927810668945
Validation loss: 1.7211184783648419

Epoch: 6| Step: 6
Training loss: 0.30161190032958984
Validation loss: 1.7441614250982962

Epoch: 6| Step: 7
Training loss: 0.20667733252048492
Validation loss: 1.776135427977449

Epoch: 6| Step: 8
Training loss: 0.1520487368106842
Validation loss: 1.7505467271292081

Epoch: 6| Step: 9
Training loss: 0.18642321228981018
Validation loss: 1.7847720153870121

Epoch: 6| Step: 10
Training loss: 0.11167706549167633
Validation loss: 1.7872385042969898

Epoch: 6| Step: 11
Training loss: 0.20955511927604675
Validation loss: 1.8044412917988275

Epoch: 6| Step: 12
Training loss: 0.31663286685943604
Validation loss: 1.738998983495979

Epoch: 6| Step: 13
Training loss: 0.7125106453895569
Validation loss: 1.7489674078520907

Epoch: 366| Step: 0
Training loss: 0.2355535477399826
Validation loss: 1.7315235291757891

Epoch: 6| Step: 1
Training loss: 0.16727286577224731
Validation loss: 1.6849504773334791

Epoch: 6| Step: 2
Training loss: 0.1878719925880432
Validation loss: 1.720500062870723

Epoch: 6| Step: 3
Training loss: 0.1921670138835907
Validation loss: 1.6730666288765528

Epoch: 6| Step: 4
Training loss: 0.5563509464263916
Validation loss: 1.6762987554714244

Epoch: 6| Step: 5
Training loss: 0.23754668235778809
Validation loss: 1.6701225285889

Epoch: 6| Step: 6
Training loss: 0.16947615146636963
Validation loss: 1.715384465391918

Epoch: 6| Step: 7
Training loss: 0.35480642318725586
Validation loss: 1.7247447634256015

Epoch: 6| Step: 8
Training loss: 0.13905833661556244
Validation loss: 1.7411465465381581

Epoch: 6| Step: 9
Training loss: 0.28991031646728516
Validation loss: 1.7540326336378693

Epoch: 6| Step: 10
Training loss: 0.20383690297603607
Validation loss: 1.7696229847528602

Epoch: 6| Step: 11
Training loss: 0.3425678014755249
Validation loss: 1.745138511862806

Epoch: 6| Step: 12
Training loss: 0.15934652090072632
Validation loss: 1.680225222341476

Epoch: 6| Step: 13
Training loss: 0.17945244908332825
Validation loss: 1.6507308137032293

Epoch: 367| Step: 0
Training loss: 0.4528052806854248
Validation loss: 1.6443911496029104

Epoch: 6| Step: 1
Training loss: 0.09832898527383804
Validation loss: 1.6145484101387761

Epoch: 6| Step: 2
Training loss: 0.20775818824768066
Validation loss: 1.6110899653486026

Epoch: 6| Step: 3
Training loss: 0.24117960035800934
Validation loss: 1.5778346446252638

Epoch: 6| Step: 4
Training loss: 0.3401789665222168
Validation loss: 1.5872907100185272

Epoch: 6| Step: 5
Training loss: 0.26952099800109863
Validation loss: 1.5895655424364152

Epoch: 6| Step: 6
Training loss: 0.2108190655708313
Validation loss: 1.6179956889921618

Epoch: 6| Step: 7
Training loss: 0.17030256986618042
Validation loss: 1.622680348734702

Epoch: 6| Step: 8
Training loss: 0.33560600876808167
Validation loss: 1.6762928731979863

Epoch: 6| Step: 9
Training loss: 0.15197935700416565
Validation loss: 1.6645957436612857

Epoch: 6| Step: 10
Training loss: 0.2493315041065216
Validation loss: 1.686769034272881

Epoch: 6| Step: 11
Training loss: 0.236078679561615
Validation loss: 1.7152573306073424

Epoch: 6| Step: 12
Training loss: 0.3664310872554779
Validation loss: 1.7019528432558941

Epoch: 6| Step: 13
Training loss: 0.09442134946584702
Validation loss: 1.6998244767547936

Epoch: 368| Step: 0
Training loss: 0.24852383136749268
Validation loss: 1.7002199413955852

Epoch: 6| Step: 1
Training loss: 0.16395661234855652
Validation loss: 1.7315754031622281

Epoch: 6| Step: 2
Training loss: 0.10165536403656006
Validation loss: 1.741726142103954

Epoch: 6| Step: 3
Training loss: 0.15046817064285278
Validation loss: 1.6917652186527048

Epoch: 6| Step: 4
Training loss: 0.2674987316131592
Validation loss: 1.727794402389116

Epoch: 6| Step: 5
Training loss: 0.44948700070381165
Validation loss: 1.6787425984618485

Epoch: 6| Step: 6
Training loss: 0.3511923551559448
Validation loss: 1.7056689108571699

Epoch: 6| Step: 7
Training loss: 0.153453528881073
Validation loss: 1.69857495574541

Epoch: 6| Step: 8
Training loss: 0.250051885843277
Validation loss: 1.681089073099116

Epoch: 6| Step: 9
Training loss: 0.17973679304122925
Validation loss: 1.6437493447334535

Epoch: 6| Step: 10
Training loss: 0.12472784519195557
Validation loss: 1.6648374334458382

Epoch: 6| Step: 11
Training loss: 0.23816990852355957
Validation loss: 1.6313819116161716

Epoch: 6| Step: 12
Training loss: 0.2246350347995758
Validation loss: 1.6437450685808737

Epoch: 6| Step: 13
Training loss: 0.3246013820171356
Validation loss: 1.6617591034981511

Epoch: 369| Step: 0
Training loss: 0.18987612426280975
Validation loss: 1.674078473480799

Epoch: 6| Step: 1
Training loss: 0.09954413771629333
Validation loss: 1.6755428045026717

Epoch: 6| Step: 2
Training loss: 0.14719584584236145
Validation loss: 1.7152667635230607

Epoch: 6| Step: 3
Training loss: 0.15157832205295563
Validation loss: 1.7287789813933834

Epoch: 6| Step: 4
Training loss: 0.27871012687683105
Validation loss: 1.7344584272753807

Epoch: 6| Step: 5
Training loss: 0.16026821732521057
Validation loss: 1.7368279746783677

Epoch: 6| Step: 6
Training loss: 0.47923994064331055
Validation loss: 1.7634165710018528

Epoch: 6| Step: 7
Training loss: 0.23599740862846375
Validation loss: 1.769532912520952

Epoch: 6| Step: 8
Training loss: 0.12819603085517883
Validation loss: 1.737728444478845

Epoch: 6| Step: 9
Training loss: 0.26995396614074707
Validation loss: 1.773267153770693

Epoch: 6| Step: 10
Training loss: 0.2867884039878845
Validation loss: 1.747159404139365

Epoch: 6| Step: 11
Training loss: 0.22092266380786896
Validation loss: 1.74122574252467

Epoch: 6| Step: 12
Training loss: 0.17640048265457153
Validation loss: 1.7138952055285055

Epoch: 6| Step: 13
Training loss: 0.16693291068077087
Validation loss: 1.7080448647981048

Epoch: 370| Step: 0
Training loss: 0.15669769048690796
Validation loss: 1.7082809568733297

Epoch: 6| Step: 1
Training loss: 0.1850072145462036
Validation loss: 1.7230052448088122

Epoch: 6| Step: 2
Training loss: 0.22085699439048767
Validation loss: 1.730091861499253

Epoch: 6| Step: 3
Training loss: 0.2901458144187927
Validation loss: 1.7560631895578036

Epoch: 6| Step: 4
Training loss: 0.252152681350708
Validation loss: 1.7289363620101765

Epoch: 6| Step: 5
Training loss: 0.15042224526405334
Validation loss: 1.7054082142409457

Epoch: 6| Step: 6
Training loss: 0.1716606765985489
Validation loss: 1.6562835785650438

Epoch: 6| Step: 7
Training loss: 0.17138855159282684
Validation loss: 1.65666917831667

Epoch: 6| Step: 8
Training loss: 0.11863988637924194
Validation loss: 1.7059414168839813

Epoch: 6| Step: 9
Training loss: 0.27169740200042725
Validation loss: 1.6735121780826199

Epoch: 6| Step: 10
Training loss: 0.24746643006801605
Validation loss: 1.6762009013083674

Epoch: 6| Step: 11
Training loss: 0.5172899961471558
Validation loss: 1.694805214481969

Epoch: 6| Step: 12
Training loss: 0.23396632075309753
Validation loss: 1.6935669247822096

Epoch: 6| Step: 13
Training loss: 0.17811265587806702
Validation loss: 1.6881617961391326

Epoch: 371| Step: 0
Training loss: 0.16051360964775085
Validation loss: 1.6659069932917112

Epoch: 6| Step: 1
Training loss: 0.18385618925094604
Validation loss: 1.6873409478895125

Epoch: 6| Step: 2
Training loss: 0.4832150936126709
Validation loss: 1.6872533290616927

Epoch: 6| Step: 3
Training loss: 0.17324453592300415
Validation loss: 1.6940330305407125

Epoch: 6| Step: 4
Training loss: 0.24725809693336487
Validation loss: 1.704748934315097

Epoch: 6| Step: 5
Training loss: 0.2091785967350006
Validation loss: 1.6989758424861456

Epoch: 6| Step: 6
Training loss: 0.29563409090042114
Validation loss: 1.694226002180448

Epoch: 6| Step: 7
Training loss: 0.29099369049072266
Validation loss: 1.6988037401630032

Epoch: 6| Step: 8
Training loss: 0.16320613026618958
Validation loss: 1.6479140648277857

Epoch: 6| Step: 9
Training loss: 0.17510713636875153
Validation loss: 1.6679024645077285

Epoch: 6| Step: 10
Training loss: 0.10023151338100433
Validation loss: 1.6961164154032224

Epoch: 6| Step: 11
Training loss: 0.3083907961845398
Validation loss: 1.6940596180577432

Epoch: 6| Step: 12
Training loss: 0.14285972714424133
Validation loss: 1.7289676435532109

Epoch: 6| Step: 13
Training loss: 0.09401995688676834
Validation loss: 1.72176545153382

Epoch: 372| Step: 0
Training loss: 0.19878646731376648
Validation loss: 1.7326686510475733

Epoch: 6| Step: 1
Training loss: 0.22058260440826416
Validation loss: 1.7120338383541311

Epoch: 6| Step: 2
Training loss: 0.18331952393054962
Validation loss: 1.7448043451514295

Epoch: 6| Step: 3
Training loss: 0.22467951476573944
Validation loss: 1.7330503207381054

Epoch: 6| Step: 4
Training loss: 0.17566697299480438
Validation loss: 1.7622158988829582

Epoch: 6| Step: 5
Training loss: 0.13871224224567413
Validation loss: 1.7810804190174225

Epoch: 6| Step: 6
Training loss: 0.37495893239974976
Validation loss: 1.7907666262759958

Epoch: 6| Step: 7
Training loss: 0.2831096053123474
Validation loss: 1.8177535918451124

Epoch: 6| Step: 8
Training loss: 0.22296391427516937
Validation loss: 1.7520804110393728

Epoch: 6| Step: 9
Training loss: 0.16466504335403442
Validation loss: 1.6898402270450388

Epoch: 6| Step: 10
Training loss: 0.44101661443710327
Validation loss: 1.6655617990801412

Epoch: 6| Step: 11
Training loss: 0.23593895137310028
Validation loss: 1.6443582734754008

Epoch: 6| Step: 12
Training loss: 0.19289135932922363
Validation loss: 1.574723292422551

Epoch: 6| Step: 13
Training loss: 0.23092572391033173
Validation loss: 1.5907917804615472

Epoch: 373| Step: 0
Training loss: 0.24054276943206787
Validation loss: 1.6171366764653115

Epoch: 6| Step: 1
Training loss: 0.25988513231277466
Validation loss: 1.6280248882949993

Epoch: 6| Step: 2
Training loss: 0.2511492371559143
Validation loss: 1.6261084400197512

Epoch: 6| Step: 3
Training loss: 0.22014588117599487
Validation loss: 1.5887992241049325

Epoch: 6| Step: 4
Training loss: 0.1867011934518814
Validation loss: 1.6286286000282533

Epoch: 6| Step: 5
Training loss: 0.1256977617740631
Validation loss: 1.6212737560272217

Epoch: 6| Step: 6
Training loss: 0.17811167240142822
Validation loss: 1.6314088753474656

Epoch: 6| Step: 7
Training loss: 0.13415491580963135
Validation loss: 1.6577561978370912

Epoch: 6| Step: 8
Training loss: 0.11268607527017593
Validation loss: 1.6945353746414185

Epoch: 6| Step: 9
Training loss: 0.27331316471099854
Validation loss: 1.7135738621475876

Epoch: 6| Step: 10
Training loss: 0.405767023563385
Validation loss: 1.751393405340051

Epoch: 6| Step: 11
Training loss: 0.17666858434677124
Validation loss: 1.7637889615951046

Epoch: 6| Step: 12
Training loss: 0.15344688296318054
Validation loss: 1.7443865063369914

Epoch: 6| Step: 13
Training loss: 0.6266109943389893
Validation loss: 1.7234381386028823

Epoch: 374| Step: 0
Training loss: 0.20533928275108337
Validation loss: 1.685391185104206

Epoch: 6| Step: 1
Training loss: 0.20813873410224915
Validation loss: 1.7322185782976047

Epoch: 6| Step: 2
Training loss: 0.11532853543758392
Validation loss: 1.70371453608236

Epoch: 6| Step: 3
Training loss: 0.26901376247406006
Validation loss: 1.7299463390022196

Epoch: 6| Step: 4
Training loss: 0.20059607923030853
Validation loss: 1.7365683676094137

Epoch: 6| Step: 5
Training loss: 0.2163446992635727
Validation loss: 1.7686627654619114

Epoch: 6| Step: 6
Training loss: 0.21005162596702576
Validation loss: 1.7241180301994405

Epoch: 6| Step: 7
Training loss: 0.1465623378753662
Validation loss: 1.6914988089633245

Epoch: 6| Step: 8
Training loss: 0.34485432505607605
Validation loss: 1.6906236320413568

Epoch: 6| Step: 9
Training loss: 0.21971550583839417
Validation loss: 1.6683349776011642

Epoch: 6| Step: 10
Training loss: 0.5589773654937744
Validation loss: 1.6839107108372513

Epoch: 6| Step: 11
Training loss: 0.14817684888839722
Validation loss: 1.667885018933204

Epoch: 6| Step: 12
Training loss: 0.28520286083221436
Validation loss: 1.6760555223752094

Epoch: 6| Step: 13
Training loss: 0.23689624667167664
Validation loss: 1.7023025917750534

Epoch: 375| Step: 0
Training loss: 0.26252785325050354
Validation loss: 1.6833909378256848

Epoch: 6| Step: 1
Training loss: 0.23141822218894958
Validation loss: 1.6609905048083233

Epoch: 6| Step: 2
Training loss: 0.3006177842617035
Validation loss: 1.6413821122979606

Epoch: 6| Step: 3
Training loss: 0.2555522620677948
Validation loss: 1.6779450485783238

Epoch: 6| Step: 4
Training loss: 0.11335715651512146
Validation loss: 1.634269687437242

Epoch: 6| Step: 5
Training loss: 0.2575555443763733
Validation loss: 1.6277754768248527

Epoch: 6| Step: 6
Training loss: 0.12011222541332245
Validation loss: 1.6431116455344743

Epoch: 6| Step: 7
Training loss: 0.23959478735923767
Validation loss: 1.6755495955867152

Epoch: 6| Step: 8
Training loss: 0.2209843099117279
Validation loss: 1.718525601971534

Epoch: 6| Step: 9
Training loss: 0.4729706645011902
Validation loss: 1.7866215795599005

Epoch: 6| Step: 10
Training loss: 0.41744011640548706
Validation loss: 1.8148326950688516

Epoch: 6| Step: 11
Training loss: 0.22450704872608185
Validation loss: 1.7643204683898597

Epoch: 6| Step: 12
Training loss: 0.15120869874954224
Validation loss: 1.813226390910405

Epoch: 6| Step: 13
Training loss: 0.20676927268505096
Validation loss: 1.8205475012461345

Epoch: 376| Step: 0
Training loss: 0.22179819643497467
Validation loss: 1.8169218083863616

Epoch: 6| Step: 1
Training loss: 0.1618930995464325
Validation loss: 1.7061483526742587

Epoch: 6| Step: 2
Training loss: 0.15343531966209412
Validation loss: 1.6664285364971365

Epoch: 6| Step: 3
Training loss: 0.16320013999938965
Validation loss: 1.6047864908813148

Epoch: 6| Step: 4
Training loss: 0.21589775383472443
Validation loss: 1.5992878021732453

Epoch: 6| Step: 5
Training loss: 0.25479328632354736
Validation loss: 1.6266747930998444

Epoch: 6| Step: 6
Training loss: 0.5707337856292725
Validation loss: 1.6434001345788278

Epoch: 6| Step: 7
Training loss: 0.28596559166908264
Validation loss: 1.6308723213852092

Epoch: 6| Step: 8
Training loss: 0.12964865565299988
Validation loss: 1.646903730207874

Epoch: 6| Step: 9
Training loss: 0.18301641941070557
Validation loss: 1.6373347005536478

Epoch: 6| Step: 10
Training loss: 0.3254415988922119
Validation loss: 1.6996036652595765

Epoch: 6| Step: 11
Training loss: 0.17475703358650208
Validation loss: 1.7102693691048572

Epoch: 6| Step: 12
Training loss: 0.24082843959331512
Validation loss: 1.733479102452596

Epoch: 6| Step: 13
Training loss: 0.3612813651561737
Validation loss: 1.7757628374202277

Epoch: 377| Step: 0
Training loss: 0.17846809327602386
Validation loss: 1.7377705061307518

Epoch: 6| Step: 1
Training loss: 0.18308356404304504
Validation loss: 1.7406758480174567

Epoch: 6| Step: 2
Training loss: 0.33741283416748047
Validation loss: 1.7530125674381052

Epoch: 6| Step: 3
Training loss: 0.30220577120780945
Validation loss: 1.7183659204872705

Epoch: 6| Step: 4
Training loss: 0.21173827350139618
Validation loss: 1.7153257336667789

Epoch: 6| Step: 5
Training loss: 0.1540607511997223
Validation loss: 1.6307290664283178

Epoch: 6| Step: 6
Training loss: 0.2296166718006134
Validation loss: 1.6251764790986174

Epoch: 6| Step: 7
Training loss: 0.32064828276634216
Validation loss: 1.610700088162576

Epoch: 6| Step: 8
Training loss: 0.3172130882740021
Validation loss: 1.590306487134708

Epoch: 6| Step: 9
Training loss: 0.24138492345809937
Validation loss: 1.5905459234791417

Epoch: 6| Step: 10
Training loss: 0.20983031392097473
Validation loss: 1.5610077188860985

Epoch: 6| Step: 11
Training loss: 0.2236676812171936
Validation loss: 1.5535538722110052

Epoch: 6| Step: 12
Training loss: 0.4811764061450958
Validation loss: 1.6006184893269693

Epoch: 6| Step: 13
Training loss: 0.14885321259498596
Validation loss: 1.6715071675597981

Epoch: 378| Step: 0
Training loss: 0.47287073731422424
Validation loss: 1.7169556335736347

Epoch: 6| Step: 1
Training loss: 0.17168501019477844
Validation loss: 1.7832504126333422

Epoch: 6| Step: 2
Training loss: 0.23791751265525818
Validation loss: 1.8086828031847555

Epoch: 6| Step: 3
Training loss: 0.3591839671134949
Validation loss: 1.7846252738788564

Epoch: 6| Step: 4
Training loss: 0.3444737493991852
Validation loss: 1.7716713336206251

Epoch: 6| Step: 5
Training loss: 0.19084028899669647
Validation loss: 1.7153655444422076

Epoch: 6| Step: 6
Training loss: 0.16915816068649292
Validation loss: 1.6859398388093518

Epoch: 6| Step: 7
Training loss: 0.19096548855304718
Validation loss: 1.6734467642281645

Epoch: 6| Step: 8
Training loss: 0.24179232120513916
Validation loss: 1.656272824092578

Epoch: 6| Step: 9
Training loss: 0.16957756876945496
Validation loss: 1.6541829955193303

Epoch: 6| Step: 10
Training loss: 0.19713759422302246
Validation loss: 1.6705125070387317

Epoch: 6| Step: 11
Training loss: 0.20859912037849426
Validation loss: 1.6773509133246638

Epoch: 6| Step: 12
Training loss: 0.24165776371955872
Validation loss: 1.6661977524398475

Epoch: 6| Step: 13
Training loss: 0.2268163412809372
Validation loss: 1.6809934646852556

Epoch: 379| Step: 0
Training loss: 0.13034765422344208
Validation loss: 1.7138166914704025

Epoch: 6| Step: 1
Training loss: 0.12826275825500488
Validation loss: 1.7427185363666986

Epoch: 6| Step: 2
Training loss: 0.27934905886650085
Validation loss: 1.790568527354989

Epoch: 6| Step: 3
Training loss: 0.1987951397895813
Validation loss: 1.8035508381423129

Epoch: 6| Step: 4
Training loss: 0.22997090220451355
Validation loss: 1.7714634749197191

Epoch: 6| Step: 5
Training loss: 0.1331951916217804
Validation loss: 1.7999562922344412

Epoch: 6| Step: 6
Training loss: 0.3270593285560608
Validation loss: 1.8188337638813963

Epoch: 6| Step: 7
Training loss: 0.2570919096469879
Validation loss: 1.7798676785602365

Epoch: 6| Step: 8
Training loss: 0.5689634680747986
Validation loss: 1.7634876979294645

Epoch: 6| Step: 9
Training loss: 0.28425854444503784
Validation loss: 1.726216766142076

Epoch: 6| Step: 10
Training loss: 0.2826274037361145
Validation loss: 1.667364497338572

Epoch: 6| Step: 11
Training loss: 0.22994162142276764
Validation loss: 1.6573518988906697

Epoch: 6| Step: 12
Training loss: 0.26486527919769287
Validation loss: 1.6704689405297721

Epoch: 6| Step: 13
Training loss: 0.09007314592599869
Validation loss: 1.6703336110679052

Epoch: 380| Step: 0
Training loss: 0.33938300609588623
Validation loss: 1.6781514139585598

Epoch: 6| Step: 1
Training loss: 0.2498471736907959
Validation loss: 1.6928830441608225

Epoch: 6| Step: 2
Training loss: 0.1854102909564972
Validation loss: 1.709632210834052

Epoch: 6| Step: 3
Training loss: 0.4364386796951294
Validation loss: 1.6899881593642696

Epoch: 6| Step: 4
Training loss: 0.17484930157661438
Validation loss: 1.712224793690507

Epoch: 6| Step: 5
Training loss: 0.2120896726846695
Validation loss: 1.7423893867000457

Epoch: 6| Step: 6
Training loss: 0.20242974162101746
Validation loss: 1.7311852773030598

Epoch: 6| Step: 7
Training loss: 0.17069758474826813
Validation loss: 1.7138963886486587

Epoch: 6| Step: 8
Training loss: 0.21183349192142487
Validation loss: 1.7289347853711856

Epoch: 6| Step: 9
Training loss: 0.2599259614944458
Validation loss: 1.690098890694239

Epoch: 6| Step: 10
Training loss: 0.2869795560836792
Validation loss: 1.6700119074954782

Epoch: 6| Step: 11
Training loss: 0.13752251863479614
Validation loss: 1.688838521639506

Epoch: 6| Step: 12
Training loss: 0.18374809622764587
Validation loss: 1.6879362726724276

Epoch: 6| Step: 13
Training loss: 0.14717993140220642
Validation loss: 1.6534567020272697

Epoch: 381| Step: 0
Training loss: 0.46388038992881775
Validation loss: 1.678132095644551

Epoch: 6| Step: 1
Training loss: 0.23653088510036469
Validation loss: 1.6384709278742473

Epoch: 6| Step: 2
Training loss: 0.2277723252773285
Validation loss: 1.6166829139955583

Epoch: 6| Step: 3
Training loss: 0.1579686999320984
Validation loss: 1.68751391800501

Epoch: 6| Step: 4
Training loss: 0.1980292797088623
Validation loss: 1.6667791643450338

Epoch: 6| Step: 5
Training loss: 0.13099358975887299
Validation loss: 1.6712083226890975

Epoch: 6| Step: 6
Training loss: 0.1604333221912384
Validation loss: 1.669905601009246

Epoch: 6| Step: 7
Training loss: 0.2580382823944092
Validation loss: 1.7086082209822953

Epoch: 6| Step: 8
Training loss: 0.2111656665802002
Validation loss: 1.721909120518674

Epoch: 6| Step: 9
Training loss: 0.1696973443031311
Validation loss: 1.7573905324423185

Epoch: 6| Step: 10
Training loss: 0.24498522281646729
Validation loss: 1.72336947020664

Epoch: 6| Step: 11
Training loss: 0.34083306789398193
Validation loss: 1.6912538364369383

Epoch: 6| Step: 12
Training loss: 0.16650117933750153
Validation loss: 1.665826125811505

Epoch: 6| Step: 13
Training loss: 0.15225030481815338
Validation loss: 1.6570462693450272

Epoch: 382| Step: 0
Training loss: 0.11054351925849915
Validation loss: 1.6349025823736703

Epoch: 6| Step: 1
Training loss: 0.3957762122154236
Validation loss: 1.665258034583061

Epoch: 6| Step: 2
Training loss: 0.17883563041687012
Validation loss: 1.6882168169944518

Epoch: 6| Step: 3
Training loss: 0.4778718054294586
Validation loss: 1.6868599102061281

Epoch: 6| Step: 4
Training loss: 0.2426755726337433
Validation loss: 1.7371748173108665

Epoch: 6| Step: 5
Training loss: 0.17294622957706451
Validation loss: 1.7224586112524873

Epoch: 6| Step: 6
Training loss: 0.3035827875137329
Validation loss: 1.7245946289390646

Epoch: 6| Step: 7
Training loss: 0.1218261867761612
Validation loss: 1.7334531180320247

Epoch: 6| Step: 8
Training loss: 0.21118775010108948
Validation loss: 1.7830464199025144

Epoch: 6| Step: 9
Training loss: 0.1850714087486267
Validation loss: 1.7502458095550537

Epoch: 6| Step: 10
Training loss: 0.17344257235527039
Validation loss: 1.7647814148215837

Epoch: 6| Step: 11
Training loss: 0.16729143261909485
Validation loss: 1.76943072195976

Epoch: 6| Step: 12
Training loss: 0.21943050622940063
Validation loss: 1.7015007311298

Epoch: 6| Step: 13
Training loss: 0.24342018365859985
Validation loss: 1.688649974843507

Epoch: 383| Step: 0
Training loss: 0.11050499975681305
Validation loss: 1.6719913303211171

Epoch: 6| Step: 1
Training loss: 0.27903422713279724
Validation loss: 1.6674307674489997

Epoch: 6| Step: 2
Training loss: 0.16147537529468536
Validation loss: 1.6463514925331197

Epoch: 6| Step: 3
Training loss: 0.2694140672683716
Validation loss: 1.5907870813082623

Epoch: 6| Step: 4
Training loss: 0.17800509929656982
Validation loss: 1.6122001909440564

Epoch: 6| Step: 5
Training loss: 0.23398354649543762
Validation loss: 1.5934025728574364

Epoch: 6| Step: 6
Training loss: 0.2754392623901367
Validation loss: 1.627401610215505

Epoch: 6| Step: 7
Training loss: 0.13838589191436768
Validation loss: 1.6443804630669214

Epoch: 6| Step: 8
Training loss: 0.18078601360321045
Validation loss: 1.6783205411767448

Epoch: 6| Step: 9
Training loss: 0.17008697986602783
Validation loss: 1.6805954133310625

Epoch: 6| Step: 10
Training loss: 0.17925292253494263
Validation loss: 1.698001092480075

Epoch: 6| Step: 11
Training loss: 0.5799415111541748
Validation loss: 1.725180923297841

Epoch: 6| Step: 12
Training loss: 0.14487847685813904
Validation loss: 1.7240905543809295

Epoch: 6| Step: 13
Training loss: 0.17227017879486084
Validation loss: 1.768612718069425

Epoch: 384| Step: 0
Training loss: 0.17523621022701263
Validation loss: 1.7535265837946246

Epoch: 6| Step: 1
Training loss: 0.2770421504974365
Validation loss: 1.7736734395386071

Epoch: 6| Step: 2
Training loss: 0.15991052985191345
Validation loss: 1.7583255716549453

Epoch: 6| Step: 3
Training loss: 0.12858936190605164
Validation loss: 1.7375129358742827

Epoch: 6| Step: 4
Training loss: 0.17106899619102478
Validation loss: 1.7214490598247898

Epoch: 6| Step: 5
Training loss: 0.3121659755706787
Validation loss: 1.724740046326832

Epoch: 6| Step: 6
Training loss: 0.2284523844718933
Validation loss: 1.6745736765605148

Epoch: 6| Step: 7
Training loss: 0.1030845046043396
Validation loss: 1.690732035585629

Epoch: 6| Step: 8
Training loss: 0.15039105713367462
Validation loss: 1.7231133189252628

Epoch: 6| Step: 9
Training loss: 0.20615199208259583
Validation loss: 1.7275153206240745

Epoch: 6| Step: 10
Training loss: 0.21725419163703918
Validation loss: 1.7773706348993445

Epoch: 6| Step: 11
Training loss: 0.2138383686542511
Validation loss: 1.7325034359449982

Epoch: 6| Step: 12
Training loss: 0.15630528330802917
Validation loss: 1.763385723995906

Epoch: 6| Step: 13
Training loss: 0.5972472429275513
Validation loss: 1.7327970945706932

Epoch: 385| Step: 0
Training loss: 0.22487503290176392
Validation loss: 1.7541890631439865

Epoch: 6| Step: 1
Training loss: 0.23665042221546173
Validation loss: 1.7306443875835789

Epoch: 6| Step: 2
Training loss: 0.1696631908416748
Validation loss: 1.686565509406469

Epoch: 6| Step: 3
Training loss: 0.17322346568107605
Validation loss: 1.677555714884112

Epoch: 6| Step: 4
Training loss: 0.24543772637844086
Validation loss: 1.6483112919715144

Epoch: 6| Step: 5
Training loss: 0.4742925763130188
Validation loss: 1.6309097992476596

Epoch: 6| Step: 6
Training loss: 0.29981696605682373
Validation loss: 1.6474602542897707

Epoch: 6| Step: 7
Training loss: 0.12473714351654053
Validation loss: 1.6450791294856737

Epoch: 6| Step: 8
Training loss: 0.16657660901546478
Validation loss: 1.6520582834879558

Epoch: 6| Step: 9
Training loss: 0.17308542132377625
Validation loss: 1.6898618782720258

Epoch: 6| Step: 10
Training loss: 0.1387016326189041
Validation loss: 1.6975233734294932

Epoch: 6| Step: 11
Training loss: 0.12987786531448364
Validation loss: 1.7212766960103025

Epoch: 6| Step: 12
Training loss: 0.16502606868743896
Validation loss: 1.7725147457532986

Epoch: 6| Step: 13
Training loss: 0.06374994665384293
Validation loss: 1.773128076266217

Epoch: 386| Step: 0
Training loss: 0.27922043204307556
Validation loss: 1.7748500634265203

Epoch: 6| Step: 1
Training loss: 0.32720696926116943
Validation loss: 1.7621080260122977

Epoch: 6| Step: 2
Training loss: 0.17390114068984985
Validation loss: 1.7794481656884635

Epoch: 6| Step: 3
Training loss: 0.21573284268379211
Validation loss: 1.7115772142205188

Epoch: 6| Step: 4
Training loss: 0.1814509779214859
Validation loss: 1.7028515851625832

Epoch: 6| Step: 5
Training loss: 0.21049994230270386
Validation loss: 1.6802973119161462

Epoch: 6| Step: 6
Training loss: 0.15306146442890167
Validation loss: 1.6415758068843553

Epoch: 6| Step: 7
Training loss: 0.17228654026985168
Validation loss: 1.623008958755001

Epoch: 6| Step: 8
Training loss: 0.27980464696884155
Validation loss: 1.6374404199661747

Epoch: 6| Step: 9
Training loss: 0.13205376267433167
Validation loss: 1.6290426202999648

Epoch: 6| Step: 10
Training loss: 0.4744434952735901
Validation loss: 1.6120492437834382

Epoch: 6| Step: 11
Training loss: 0.17463450133800507
Validation loss: 1.6543572166914582

Epoch: 6| Step: 12
Training loss: 0.07307185232639313
Validation loss: 1.673840397147722

Epoch: 6| Step: 13
Training loss: 0.14940550923347473
Validation loss: 1.7496024549648326

Epoch: 387| Step: 0
Training loss: 0.19505780935287476
Validation loss: 1.787490265343779

Epoch: 6| Step: 1
Training loss: 0.17660976946353912
Validation loss: 1.8107924730547014

Epoch: 6| Step: 2
Training loss: 0.1512804478406906
Validation loss: 1.8693408248245076

Epoch: 6| Step: 3
Training loss: 0.20495307445526123
Validation loss: 1.8756261653797601

Epoch: 6| Step: 4
Training loss: 0.20680931210517883
Validation loss: 1.8126773911137735

Epoch: 6| Step: 5
Training loss: 0.21087664365768433
Validation loss: 1.843331757412162

Epoch: 6| Step: 6
Training loss: 0.31900233030319214
Validation loss: 1.8106853705580517

Epoch: 6| Step: 7
Training loss: 0.1840917468070984
Validation loss: 1.7765229517413723

Epoch: 6| Step: 8
Training loss: 0.09100402891635895
Validation loss: 1.7518243148762693

Epoch: 6| Step: 9
Training loss: 0.5084095001220703
Validation loss: 1.73991483770391

Epoch: 6| Step: 10
Training loss: 0.1091618686914444
Validation loss: 1.766515347265428

Epoch: 6| Step: 11
Training loss: 0.155716210603714
Validation loss: 1.711691830747871

Epoch: 6| Step: 12
Training loss: 0.19275125861167908
Validation loss: 1.6873718859047018

Epoch: 6| Step: 13
Training loss: 0.2518828213214874
Validation loss: 1.6545434946654944

Epoch: 388| Step: 0
Training loss: 0.299386203289032
Validation loss: 1.6419013661722983

Epoch: 6| Step: 1
Training loss: 0.279382586479187
Validation loss: 1.6313178878958507

Epoch: 6| Step: 2
Training loss: 0.26140502095222473
Validation loss: 1.5973787487194102

Epoch: 6| Step: 3
Training loss: 0.18421030044555664
Validation loss: 1.6455608452520063

Epoch: 6| Step: 4
Training loss: 0.23674607276916504
Validation loss: 1.6336858516098351

Epoch: 6| Step: 5
Training loss: 0.13388606905937195
Validation loss: 1.648674282976376

Epoch: 6| Step: 6
Training loss: 0.28508785367012024
Validation loss: 1.6780178508450907

Epoch: 6| Step: 7
Training loss: 0.18030425906181335
Validation loss: 1.7140230581324587

Epoch: 6| Step: 8
Training loss: 0.2494211196899414
Validation loss: 1.7302458414467432

Epoch: 6| Step: 9
Training loss: 0.4539240002632141
Validation loss: 1.7431333347033429

Epoch: 6| Step: 10
Training loss: 0.15910737216472626
Validation loss: 1.7684934164888115

Epoch: 6| Step: 11
Training loss: 0.1309884637594223
Validation loss: 1.7765626958621445

Epoch: 6| Step: 12
Training loss: 0.17840495705604553
Validation loss: 1.7764996226115892

Epoch: 6| Step: 13
Training loss: 0.3389623761177063
Validation loss: 1.7974431335285146

Epoch: 389| Step: 0
Training loss: 0.1988036334514618
Validation loss: 1.7981129256627892

Epoch: 6| Step: 1
Training loss: 0.15441769361495972
Validation loss: 1.7746973306901994

Epoch: 6| Step: 2
Training loss: 0.5144407749176025
Validation loss: 1.8090143652372463

Epoch: 6| Step: 3
Training loss: 0.2801050841808319
Validation loss: 1.7530268020527338

Epoch: 6| Step: 4
Training loss: 0.19932349026203156
Validation loss: 1.76556549790085

Epoch: 6| Step: 5
Training loss: 0.14366178214550018
Validation loss: 1.7450459849449895

Epoch: 6| Step: 6
Training loss: 0.28149843215942383
Validation loss: 1.733514722957406

Epoch: 6| Step: 7
Training loss: 0.22185121476650238
Validation loss: 1.6950225868532736

Epoch: 6| Step: 8
Training loss: 0.18170160055160522
Validation loss: 1.697915982174617

Epoch: 6| Step: 9
Training loss: 0.1592753827571869
Validation loss: 1.6933650111639371

Epoch: 6| Step: 10
Training loss: 0.11160600185394287
Validation loss: 1.7109474828166347

Epoch: 6| Step: 11
Training loss: 0.2136818915605545
Validation loss: 1.730226550050961

Epoch: 6| Step: 12
Training loss: 0.3189290761947632
Validation loss: 1.7178366363689463

Epoch: 6| Step: 13
Training loss: 0.22328217327594757
Validation loss: 1.7317317378136419

Epoch: 390| Step: 0
Training loss: 0.186639204621315
Validation loss: 1.7574145178641043

Epoch: 6| Step: 1
Training loss: 0.2701558470726013
Validation loss: 1.7735917555388583

Epoch: 6| Step: 2
Training loss: 0.17594879865646362
Validation loss: 1.7500283500199676

Epoch: 6| Step: 3
Training loss: 0.2192384898662567
Validation loss: 1.7127085501147854

Epoch: 6| Step: 4
Training loss: 0.11120477318763733
Validation loss: 1.697110083795363

Epoch: 6| Step: 5
Training loss: 0.1530826836824417
Validation loss: 1.6533446875951623

Epoch: 6| Step: 6
Training loss: 0.2974618077278137
Validation loss: 1.6269460365336428

Epoch: 6| Step: 7
Training loss: 0.42361947894096375
Validation loss: 1.625835689165259

Epoch: 6| Step: 8
Training loss: 0.20441921055316925
Validation loss: 1.631831629301912

Epoch: 6| Step: 9
Training loss: 0.19760379195213318
Validation loss: 1.616787616924573

Epoch: 6| Step: 10
Training loss: 0.3293294608592987
Validation loss: 1.5865902926332207

Epoch: 6| Step: 11
Training loss: 0.29077112674713135
Validation loss: 1.5949167782260525

Epoch: 6| Step: 12
Training loss: 0.13710445165634155
Validation loss: 1.5777182040675994

Epoch: 6| Step: 13
Training loss: 0.26292890310287476
Validation loss: 1.583464660952168

Epoch: 391| Step: 0
Training loss: 0.20894049108028412
Validation loss: 1.5686673348949802

Epoch: 6| Step: 1
Training loss: 0.11481839418411255
Validation loss: 1.5678806715114142

Epoch: 6| Step: 2
Training loss: 0.2143843173980713
Validation loss: 1.5922636690960135

Epoch: 6| Step: 3
Training loss: 0.1796804815530777
Validation loss: 1.5672036396559847

Epoch: 6| Step: 4
Training loss: 0.20839454233646393
Validation loss: 1.5994259932989716

Epoch: 6| Step: 5
Training loss: 0.14072543382644653
Validation loss: 1.5619659026463826

Epoch: 6| Step: 6
Training loss: 0.2310865968465805
Validation loss: 1.5796548115309847

Epoch: 6| Step: 7
Training loss: 0.20190230011940002
Validation loss: 1.6138418002795147

Epoch: 6| Step: 8
Training loss: 0.25263485312461853
Validation loss: 1.624021222514491

Epoch: 6| Step: 9
Training loss: 0.1184234768152237
Validation loss: 1.6557450999495804

Epoch: 6| Step: 10
Training loss: 0.1748008131980896
Validation loss: 1.626953476218767

Epoch: 6| Step: 11
Training loss: 0.20921503007411957
Validation loss: 1.6833143670071837

Epoch: 6| Step: 12
Training loss: 0.17337951064109802
Validation loss: 1.6745971389996108

Epoch: 6| Step: 13
Training loss: 0.5851418375968933
Validation loss: 1.7261180313684608

Epoch: 392| Step: 0
Training loss: 0.10642741620540619
Validation loss: 1.7256955113462222

Epoch: 6| Step: 1
Training loss: 0.1539301574230194
Validation loss: 1.7261089253169235

Epoch: 6| Step: 2
Training loss: 0.12989619374275208
Validation loss: 1.7441732191270398

Epoch: 6| Step: 3
Training loss: 0.14645084738731384
Validation loss: 1.6889925528598089

Epoch: 6| Step: 4
Training loss: 0.1779618114233017
Validation loss: 1.655254897250924

Epoch: 6| Step: 5
Training loss: 0.39203959703445435
Validation loss: 1.6307677325382028

Epoch: 6| Step: 6
Training loss: 0.2153632640838623
Validation loss: 1.6351715005854124

Epoch: 6| Step: 7
Training loss: 0.11390363425016403
Validation loss: 1.6653401159471082

Epoch: 6| Step: 8
Training loss: 0.20851479470729828
Validation loss: 1.6582161668808229

Epoch: 6| Step: 9
Training loss: 0.19610509276390076
Validation loss: 1.694285500434137

Epoch: 6| Step: 10
Training loss: 0.356624573469162
Validation loss: 1.7348346428204608

Epoch: 6| Step: 11
Training loss: 0.30023905634880066
Validation loss: 1.7439744869867961

Epoch: 6| Step: 12
Training loss: 0.36911338567733765
Validation loss: 1.7516789423522128

Epoch: 6| Step: 13
Training loss: 0.10659849643707275
Validation loss: 1.712768240641522

Epoch: 393| Step: 0
Training loss: 0.11838160455226898
Validation loss: 1.729440450668335

Epoch: 6| Step: 1
Training loss: 0.10709258913993835
Validation loss: 1.7004247416732132

Epoch: 6| Step: 2
Training loss: 0.20596420764923096
Validation loss: 1.7311097447590162

Epoch: 6| Step: 3
Training loss: 0.140819251537323
Validation loss: 1.7130421669252458

Epoch: 6| Step: 4
Training loss: 0.22523663938045502
Validation loss: 1.6926377332338722

Epoch: 6| Step: 5
Training loss: 0.08619174361228943
Validation loss: 1.6870951011616697

Epoch: 6| Step: 6
Training loss: 0.2628876566886902
Validation loss: 1.6910170226968744

Epoch: 6| Step: 7
Training loss: 0.21993820369243622
Validation loss: 1.6417200167973836

Epoch: 6| Step: 8
Training loss: 0.20488111674785614
Validation loss: 1.6883190062738234

Epoch: 6| Step: 9
Training loss: 0.11692162603139877
Validation loss: 1.622042038107431

Epoch: 6| Step: 10
Training loss: 0.3943198025226593
Validation loss: 1.635014376332683

Epoch: 6| Step: 11
Training loss: 0.19188258051872253
Validation loss: 1.6546864496764315

Epoch: 6| Step: 12
Training loss: 0.15704599022865295
Validation loss: 1.6320349772771199

Epoch: 6| Step: 13
Training loss: 0.19053173065185547
Validation loss: 1.659716147248463

Epoch: 394| Step: 0
Training loss: 0.4023880064487457
Validation loss: 1.618877883880369

Epoch: 6| Step: 1
Training loss: 0.11731640994548798
Validation loss: 1.6901980318048948

Epoch: 6| Step: 2
Training loss: 0.18324312567710876
Validation loss: 1.662498272875304

Epoch: 6| Step: 3
Training loss: 0.16194629669189453
Validation loss: 1.662072935412007

Epoch: 6| Step: 4
Training loss: 0.1378973424434662
Validation loss: 1.6390776941853185

Epoch: 6| Step: 5
Training loss: 0.16152489185333252
Validation loss: 1.609238793773036

Epoch: 6| Step: 6
Training loss: 0.2219831943511963
Validation loss: 1.5980474474609538

Epoch: 6| Step: 7
Training loss: 0.18282516300678253
Validation loss: 1.5996667518410632

Epoch: 6| Step: 8
Training loss: 0.15168367326259613
Validation loss: 1.604780775244518

Epoch: 6| Step: 9
Training loss: 0.12174108624458313
Validation loss: 1.6279273943234516

Epoch: 6| Step: 10
Training loss: 0.18991714715957642
Validation loss: 1.6181070112412976

Epoch: 6| Step: 11
Training loss: 0.2748557925224304
Validation loss: 1.6187387345939555

Epoch: 6| Step: 12
Training loss: 0.17201806604862213
Validation loss: 1.645766322330762

Epoch: 6| Step: 13
Training loss: 0.1980166733264923
Validation loss: 1.6371869957575234

Epoch: 395| Step: 0
Training loss: 0.14842361211776733
Validation loss: 1.664619017672795

Epoch: 6| Step: 1
Training loss: 0.1934058666229248
Validation loss: 1.6615112904579408

Epoch: 6| Step: 2
Training loss: 0.10513710230588913
Validation loss: 1.6680749436860443

Epoch: 6| Step: 3
Training loss: 0.2456977665424347
Validation loss: 1.7045896450678508

Epoch: 6| Step: 4
Training loss: 0.11829309165477753
Validation loss: 1.6906644336638912

Epoch: 6| Step: 5
Training loss: 0.21988143026828766
Validation loss: 1.6856874112159974

Epoch: 6| Step: 6
Training loss: 0.20560671389102936
Validation loss: 1.6922255434015745

Epoch: 6| Step: 7
Training loss: 0.08611900359392166
Validation loss: 1.677545400076015

Epoch: 6| Step: 8
Training loss: 0.24529752135276794
Validation loss: 1.694763845013034

Epoch: 6| Step: 9
Training loss: 0.22940707206726074
Validation loss: 1.674755573272705

Epoch: 6| Step: 10
Training loss: 0.1103328987956047
Validation loss: 1.6673096085107455

Epoch: 6| Step: 11
Training loss: 0.3948310911655426
Validation loss: 1.6523092395515853

Epoch: 6| Step: 12
Training loss: 0.1094256266951561
Validation loss: 1.6764359525454942

Epoch: 6| Step: 13
Training loss: 0.1124112606048584
Validation loss: 1.6851941193303754

Epoch: 396| Step: 0
Training loss: 0.17548571527004242
Validation loss: 1.6935064023540867

Epoch: 6| Step: 1
Training loss: 0.20744316279888153
Validation loss: 1.6695229250897643

Epoch: 6| Step: 2
Training loss: 0.22278431057929993
Validation loss: 1.7010836831984981

Epoch: 6| Step: 3
Training loss: 0.052438363432884216
Validation loss: 1.693182768360261

Epoch: 6| Step: 4
Training loss: 0.4320216774940491
Validation loss: 1.6546397350167716

Epoch: 6| Step: 5
Training loss: 0.21084707975387573
Validation loss: 1.6869572388228549

Epoch: 6| Step: 6
Training loss: 0.2530989646911621
Validation loss: 1.669004064734264

Epoch: 6| Step: 7
Training loss: 0.2971220314502716
Validation loss: 1.6868900663109236

Epoch: 6| Step: 8
Training loss: 0.13825258612632751
Validation loss: 1.6285234266711819

Epoch: 6| Step: 9
Training loss: 0.12326972186565399
Validation loss: 1.6427466612990185

Epoch: 6| Step: 10
Training loss: 0.13186073303222656
Validation loss: 1.6410175036358576

Epoch: 6| Step: 11
Training loss: 0.13410037755966187
Validation loss: 1.6102264888824955

Epoch: 6| Step: 12
Training loss: 0.1708344668149948
Validation loss: 1.6120189530875093

Epoch: 6| Step: 13
Training loss: 0.24231678247451782
Validation loss: 1.6029093291169854

Epoch: 397| Step: 0
Training loss: 0.16336938738822937
Validation loss: 1.6153292091943885

Epoch: 6| Step: 1
Training loss: 0.08801905810832977
Validation loss: 1.6208419466531405

Epoch: 6| Step: 2
Training loss: 0.1358669102191925
Validation loss: 1.6126117257661716

Epoch: 6| Step: 3
Training loss: 0.1706324815750122
Validation loss: 1.676504409441384

Epoch: 6| Step: 4
Training loss: 0.19911456108093262
Validation loss: 1.658021960207211

Epoch: 6| Step: 5
Training loss: 0.19232578575611115
Validation loss: 1.673696933254119

Epoch: 6| Step: 6
Training loss: 0.1498614102602005
Validation loss: 1.7089702339582546

Epoch: 6| Step: 7
Training loss: 0.12037034332752228
Validation loss: 1.7312266493356356

Epoch: 6| Step: 8
Training loss: 0.13735488057136536
Validation loss: 1.726733015429589

Epoch: 6| Step: 9
Training loss: 0.15823136270046234
Validation loss: 1.7641267879034883

Epoch: 6| Step: 10
Training loss: 0.5260632038116455
Validation loss: 1.7398191331535258

Epoch: 6| Step: 11
Training loss: 0.25991371273994446
Validation loss: 1.7286376965943204

Epoch: 6| Step: 12
Training loss: 0.26109176874160767
Validation loss: 1.6967959967992639

Epoch: 6| Step: 13
Training loss: 0.08378781378269196
Validation loss: 1.657703003575725

Epoch: 398| Step: 0
Training loss: 0.511317253112793
Validation loss: 1.6493921831089964

Epoch: 6| Step: 1
Training loss: 0.13603484630584717
Validation loss: 1.6237654993610997

Epoch: 6| Step: 2
Training loss: 0.22814993560314178
Validation loss: 1.5828112632997575

Epoch: 6| Step: 3
Training loss: 0.15207044780254364
Validation loss: 1.6107238018384544

Epoch: 6| Step: 4
Training loss: 0.1958816945552826
Validation loss: 1.6088495421153244

Epoch: 6| Step: 5
Training loss: 0.20644479990005493
Validation loss: 1.6208817984468193

Epoch: 6| Step: 6
Training loss: 0.21860358119010925
Validation loss: 1.627585994300022

Epoch: 6| Step: 7
Training loss: 0.10555920749902725
Validation loss: 1.6386635713679816

Epoch: 6| Step: 8
Training loss: 0.16123491525650024
Validation loss: 1.6325212576056038

Epoch: 6| Step: 9
Training loss: 0.2930005192756653
Validation loss: 1.6431719128803541

Epoch: 6| Step: 10
Training loss: 0.2322990596294403
Validation loss: 1.6419098492591613

Epoch: 6| Step: 11
Training loss: 0.25963276624679565
Validation loss: 1.6471605159903084

Epoch: 6| Step: 12
Training loss: 0.2001492828130722
Validation loss: 1.667596382479514

Epoch: 6| Step: 13
Training loss: 0.12975145876407623
Validation loss: 1.6349937877347391

Epoch: 399| Step: 0
Training loss: 0.23046070337295532
Validation loss: 1.6816967892390426

Epoch: 6| Step: 1
Training loss: 0.5093179941177368
Validation loss: 1.67623778312437

Epoch: 6| Step: 2
Training loss: 0.3522713780403137
Validation loss: 1.6616251353294618

Epoch: 6| Step: 3
Training loss: 0.2545066475868225
Validation loss: 1.638756263640619

Epoch: 6| Step: 4
Training loss: 0.1638735681772232
Validation loss: 1.6112592169033584

Epoch: 6| Step: 5
Training loss: 0.17658573389053345
Validation loss: 1.5537177734477545

Epoch: 6| Step: 6
Training loss: 0.18364134430885315
Validation loss: 1.5598443708112162

Epoch: 6| Step: 7
Training loss: 0.15650396049022675
Validation loss: 1.6273373096219954

Epoch: 6| Step: 8
Training loss: 0.14020884037017822
Validation loss: 1.6292205677237561

Epoch: 6| Step: 9
Training loss: 0.2825436592102051
Validation loss: 1.627569475481587

Epoch: 6| Step: 10
Training loss: 0.1613353192806244
Validation loss: 1.6656776032140177

Epoch: 6| Step: 11
Training loss: 0.14905908703804016
Validation loss: 1.726760628402874

Epoch: 6| Step: 12
Training loss: 0.2006930112838745
Validation loss: 1.75133361611315

Epoch: 6| Step: 13
Training loss: 0.23124520480632782
Validation loss: 1.8152023400029829

Epoch: 400| Step: 0
Training loss: 0.17489108443260193
Validation loss: 1.802871722047047

Epoch: 6| Step: 1
Training loss: 0.4777638614177704
Validation loss: 1.8250578167617961

Epoch: 6| Step: 2
Training loss: 0.39015012979507446
Validation loss: 1.8908720298479962

Epoch: 6| Step: 3
Training loss: 0.2849121391773224
Validation loss: 1.8285890638187368

Epoch: 6| Step: 4
Training loss: 0.19811075925827026
Validation loss: 1.7574498922594133

Epoch: 6| Step: 5
Training loss: 0.21385972201824188
Validation loss: 1.6617385751457625

Epoch: 6| Step: 6
Training loss: 0.12657521665096283
Validation loss: 1.595734300151948

Epoch: 6| Step: 7
Training loss: 0.22300663590431213
Validation loss: 1.5926884669129566

Epoch: 6| Step: 8
Training loss: 0.2519305944442749
Validation loss: 1.6160308314907936

Epoch: 6| Step: 9
Training loss: 0.2099021077156067
Validation loss: 1.6035168786202707

Epoch: 6| Step: 10
Training loss: 0.2892293930053711
Validation loss: 1.6218583994014288

Epoch: 6| Step: 11
Training loss: 0.270263671875
Validation loss: 1.6026230422399377

Epoch: 6| Step: 12
Training loss: 0.18959379196166992
Validation loss: 1.654206581013177

Epoch: 6| Step: 13
Training loss: 0.09601243585348129
Validation loss: 1.627918093435226

Epoch: 401| Step: 0
Training loss: 0.0888328030705452
Validation loss: 1.6609312103640648

Epoch: 6| Step: 1
Training loss: 0.45557892322540283
Validation loss: 1.7165062914612472

Epoch: 6| Step: 2
Training loss: 0.16904211044311523
Validation loss: 1.7289337817058767

Epoch: 6| Step: 3
Training loss: 0.31431880593299866
Validation loss: 1.7675843431103615

Epoch: 6| Step: 4
Training loss: 0.19506050646305084
Validation loss: 1.767172239160025

Epoch: 6| Step: 5
Training loss: 0.13254350423812866
Validation loss: 1.7686357203350271

Epoch: 6| Step: 6
Training loss: 0.1252307891845703
Validation loss: 1.704631983592946

Epoch: 6| Step: 7
Training loss: 0.10350310802459717
Validation loss: 1.6839954776148642

Epoch: 6| Step: 8
Training loss: 0.2120678424835205
Validation loss: 1.646993084620404

Epoch: 6| Step: 9
Training loss: 0.17618581652641296
Validation loss: 1.617434351674972

Epoch: 6| Step: 10
Training loss: 0.23452208936214447
Validation loss: 1.6260094027365408

Epoch: 6| Step: 11
Training loss: 0.2067662924528122
Validation loss: 1.6546356498554189

Epoch: 6| Step: 12
Training loss: 0.17572301626205444
Validation loss: 1.6479482163665116

Epoch: 6| Step: 13
Training loss: 0.15497323870658875
Validation loss: 1.6612688059447913

Epoch: 402| Step: 0
Training loss: 0.10006632655858994
Validation loss: 1.6498545908158826

Epoch: 6| Step: 1
Training loss: 0.1644044816493988
Validation loss: 1.65400497118632

Epoch: 6| Step: 2
Training loss: 0.4911177158355713
Validation loss: 1.6470687979011125

Epoch: 6| Step: 3
Training loss: 0.20154260098934174
Validation loss: 1.6596375062901487

Epoch: 6| Step: 4
Training loss: 0.1687605082988739
Validation loss: 1.6589391423809914

Epoch: 6| Step: 5
Training loss: 0.2060070037841797
Validation loss: 1.5977389581741825

Epoch: 6| Step: 6
Training loss: 0.2435375601053238
Validation loss: 1.5676227910544283

Epoch: 6| Step: 7
Training loss: 0.22728529572486877
Validation loss: 1.579362193743388

Epoch: 6| Step: 8
Training loss: 0.21704137325286865
Validation loss: 1.5622003052824287

Epoch: 6| Step: 9
Training loss: 0.17715078592300415
Validation loss: 1.5731640849062192

Epoch: 6| Step: 10
Training loss: 0.24941447377204895
Validation loss: 1.6134074490557435

Epoch: 6| Step: 11
Training loss: 0.1659069061279297
Validation loss: 1.6069875699217602

Epoch: 6| Step: 12
Training loss: 0.13480189442634583
Validation loss: 1.5971824199922624

Epoch: 6| Step: 13
Training loss: 0.07911337912082672
Validation loss: 1.6300683931637836

Epoch: 403| Step: 0
Training loss: 0.1523100584745407
Validation loss: 1.5866529121193835

Epoch: 6| Step: 1
Training loss: 0.1837119609117508
Validation loss: 1.5885708607653135

Epoch: 6| Step: 2
Training loss: 0.16069021821022034
Validation loss: 1.5743489541033262

Epoch: 6| Step: 3
Training loss: 0.18520483374595642
Validation loss: 1.5605487131303357

Epoch: 6| Step: 4
Training loss: 0.431968629360199
Validation loss: 1.5824600060780842

Epoch: 6| Step: 5
Training loss: 0.13503895699977875
Validation loss: 1.624787433813977

Epoch: 6| Step: 6
Training loss: 0.18241985142230988
Validation loss: 1.6080118443376274

Epoch: 6| Step: 7
Training loss: 0.13723447918891907
Validation loss: 1.6264130312909362

Epoch: 6| Step: 8
Training loss: 0.23148220777511597
Validation loss: 1.6479345521619242

Epoch: 6| Step: 9
Training loss: 0.10211707651615143
Validation loss: 1.6339202670640842

Epoch: 6| Step: 10
Training loss: 0.34409093856811523
Validation loss: 1.6839139461517334

Epoch: 6| Step: 11
Training loss: 0.154882550239563
Validation loss: 1.6927788449871926

Epoch: 6| Step: 12
Training loss: 0.17228570580482483
Validation loss: 1.6544923320893319

Epoch: 6| Step: 13
Training loss: 0.13060542941093445
Validation loss: 1.7025212549394177

Epoch: 404| Step: 0
Training loss: 0.15445443987846375
Validation loss: 1.7066317886434577

Epoch: 6| Step: 1
Training loss: 0.15687577426433563
Validation loss: 1.6859334886714976

Epoch: 6| Step: 2
Training loss: 0.3957028090953827
Validation loss: 1.665050386100687

Epoch: 6| Step: 3
Training loss: 0.14550389349460602
Validation loss: 1.7027884234664261

Epoch: 6| Step: 4
Training loss: 0.1249617338180542
Validation loss: 1.6602502766475882

Epoch: 6| Step: 5
Training loss: 0.13154850900173187
Validation loss: 1.6660260026172926

Epoch: 6| Step: 6
Training loss: 0.25870218873023987
Validation loss: 1.6608572762499574

Epoch: 6| Step: 7
Training loss: 0.23991098999977112
Validation loss: 1.5895931118278093

Epoch: 6| Step: 8
Training loss: 0.08314552903175354
Validation loss: 1.6146227031625726

Epoch: 6| Step: 9
Training loss: 0.19081589579582214
Validation loss: 1.6063475967735372

Epoch: 6| Step: 10
Training loss: 0.10614216327667236
Validation loss: 1.613965206248786

Epoch: 6| Step: 11
Training loss: 0.28049805760383606
Validation loss: 1.584157984743836

Epoch: 6| Step: 12
Training loss: 0.15955868363380432
Validation loss: 1.5975744724273682

Epoch: 6| Step: 13
Training loss: 0.13228748738765717
Validation loss: 1.5370807673341484

Epoch: 405| Step: 0
Training loss: 0.49386468529701233
Validation loss: 1.5723256526454803

Epoch: 6| Step: 1
Training loss: 0.15315590798854828
Validation loss: 1.5774623437594342

Epoch: 6| Step: 2
Training loss: 0.2438535839319229
Validation loss: 1.5603189776020665

Epoch: 6| Step: 3
Training loss: 0.2122514247894287
Validation loss: 1.5812558640715897

Epoch: 6| Step: 4
Training loss: 0.2138100266456604
Validation loss: 1.6151005606497488

Epoch: 6| Step: 5
Training loss: 0.25220921635627747
Validation loss: 1.657780998496599

Epoch: 6| Step: 6
Training loss: 0.09364224225282669
Validation loss: 1.6367394872891006

Epoch: 6| Step: 7
Training loss: 0.10841052234172821
Validation loss: 1.6664558738790534

Epoch: 6| Step: 8
Training loss: 0.15604624152183533
Validation loss: 1.6719795286014516

Epoch: 6| Step: 9
Training loss: 0.20909729599952698
Validation loss: 1.6311657505650674

Epoch: 6| Step: 10
Training loss: 0.20943090319633484
Validation loss: 1.6116196058129753

Epoch: 6| Step: 11
Training loss: 0.10389246791601181
Validation loss: 1.5971831903662732

Epoch: 6| Step: 12
Training loss: 0.10167694836854935
Validation loss: 1.598757052934298

Epoch: 6| Step: 13
Training loss: 0.18215984106063843
Validation loss: 1.5817117165493708

Epoch: 406| Step: 0
Training loss: 0.32753804326057434
Validation loss: 1.6227240844439434

Epoch: 6| Step: 1
Training loss: 0.17566286027431488
Validation loss: 1.6645115883119646

Epoch: 6| Step: 2
Training loss: 0.15236151218414307
Validation loss: 1.67431721251498

Epoch: 6| Step: 3
Training loss: 0.21787790954113007
Validation loss: 1.7270076967054797

Epoch: 6| Step: 4
Training loss: 0.13780632615089417
Validation loss: 1.702569100164598

Epoch: 6| Step: 5
Training loss: 0.1599823236465454
Validation loss: 1.7014515502478487

Epoch: 6| Step: 6
Training loss: 0.14486397802829742
Validation loss: 1.717172307352866

Epoch: 6| Step: 7
Training loss: 0.16294190287590027
Validation loss: 1.7012101424637662

Epoch: 6| Step: 8
Training loss: 0.42179447412490845
Validation loss: 1.69998086267902

Epoch: 6| Step: 9
Training loss: 0.11985155194997787
Validation loss: 1.7077862831854052

Epoch: 6| Step: 10
Training loss: 0.1864161193370819
Validation loss: 1.722526042692123

Epoch: 6| Step: 11
Training loss: 0.16098138689994812
Validation loss: 1.731959448065809

Epoch: 6| Step: 12
Training loss: 0.20847006142139435
Validation loss: 1.7433822667726906

Epoch: 6| Step: 13
Training loss: 0.06647661328315735
Validation loss: 1.7180781159349667

Epoch: 407| Step: 0
Training loss: 0.1252022683620453
Validation loss: 1.6874355628926268

Epoch: 6| Step: 1
Training loss: 0.5096951723098755
Validation loss: 1.6466952062422229

Epoch: 6| Step: 2
Training loss: 0.0802694708108902
Validation loss: 1.6100407544002737

Epoch: 6| Step: 3
Training loss: 0.11951322853565216
Validation loss: 1.5668076110142533

Epoch: 6| Step: 4
Training loss: 0.20892250537872314
Validation loss: 1.5399021743446268

Epoch: 6| Step: 5
Training loss: 0.1814652383327484
Validation loss: 1.5432632353998

Epoch: 6| Step: 6
Training loss: 0.119517982006073
Validation loss: 1.5214190162638181

Epoch: 6| Step: 7
Training loss: 0.13807344436645508
Validation loss: 1.5515405176788248

Epoch: 6| Step: 8
Training loss: 0.18455226719379425
Validation loss: 1.551839425999631

Epoch: 6| Step: 9
Training loss: 0.20109856128692627
Validation loss: 1.5783706326638498

Epoch: 6| Step: 10
Training loss: 0.13375714421272278
Validation loss: 1.5601673805585472

Epoch: 6| Step: 11
Training loss: 0.12035679817199707
Validation loss: 1.6428626122013215

Epoch: 6| Step: 12
Training loss: 0.28848737478256226
Validation loss: 1.6034621359199606

Epoch: 6| Step: 13
Training loss: 0.14357855916023254
Validation loss: 1.6166870055660125

Epoch: 408| Step: 0
Training loss: 0.1178891733288765
Validation loss: 1.6415483400385866

Epoch: 6| Step: 1
Training loss: 0.13707441091537476
Validation loss: 1.6542740483437814

Epoch: 6| Step: 2
Training loss: 0.18014466762542725
Validation loss: 1.6523057299275552

Epoch: 6| Step: 3
Training loss: 0.1220347136259079
Validation loss: 1.6031536799605175

Epoch: 6| Step: 4
Training loss: 0.1449890434741974
Validation loss: 1.619780041838205

Epoch: 6| Step: 5
Training loss: 0.1398928463459015
Validation loss: 1.6111506556951871

Epoch: 6| Step: 6
Training loss: 0.2833881378173828
Validation loss: 1.6198878608724123

Epoch: 6| Step: 7
Training loss: 0.15231755375862122
Validation loss: 1.6272323029015654

Epoch: 6| Step: 8
Training loss: 0.6159150004386902
Validation loss: 1.6232591572628225

Epoch: 6| Step: 9
Training loss: 0.1403244137763977
Validation loss: 1.613985437218861

Epoch: 6| Step: 10
Training loss: 0.11767953634262085
Validation loss: 1.6501863861596713

Epoch: 6| Step: 11
Training loss: 0.15483784675598145
Validation loss: 1.6122675031744025

Epoch: 6| Step: 12
Training loss: 0.24544303119182587
Validation loss: 1.624633257107068

Epoch: 6| Step: 13
Training loss: 0.13872085511684418
Validation loss: 1.6316793631481867

Epoch: 409| Step: 0
Training loss: 0.09459725767374039
Validation loss: 1.6278381411747267

Epoch: 6| Step: 1
Training loss: 0.07238754630088806
Validation loss: 1.61920755012061

Epoch: 6| Step: 2
Training loss: 0.14043094217777252
Validation loss: 1.5971354412776169

Epoch: 6| Step: 3
Training loss: 0.16838276386260986
Validation loss: 1.6005248664527811

Epoch: 6| Step: 4
Training loss: 0.17223945260047913
Validation loss: 1.5865915129261632

Epoch: 6| Step: 5
Training loss: 0.23502294719219208
Validation loss: 1.6154074854748224

Epoch: 6| Step: 6
Training loss: 0.4712170958518982
Validation loss: 1.5833088762016707

Epoch: 6| Step: 7
Training loss: 0.17143557965755463
Validation loss: 1.6177937356374597

Epoch: 6| Step: 8
Training loss: 0.1564626842737198
Validation loss: 1.6053222904923141

Epoch: 6| Step: 9
Training loss: 0.10250899940729141
Validation loss: 1.6326039362979192

Epoch: 6| Step: 10
Training loss: 0.12723812460899353
Validation loss: 1.6029566923777263

Epoch: 6| Step: 11
Training loss: 0.13769909739494324
Validation loss: 1.6142539760117889

Epoch: 6| Step: 12
Training loss: 0.22946131229400635
Validation loss: 1.6464615816711097

Epoch: 6| Step: 13
Training loss: 0.35696887969970703
Validation loss: 1.6273779292260446

Epoch: 410| Step: 0
Training loss: 0.11001274734735489
Validation loss: 1.6415749685738676

Epoch: 6| Step: 1
Training loss: 0.058199260383844376
Validation loss: 1.628222393733199

Epoch: 6| Step: 2
Training loss: 0.17218619585037231
Validation loss: 1.661011754825551

Epoch: 6| Step: 3
Training loss: 0.2062380462884903
Validation loss: 1.6756840931471957

Epoch: 6| Step: 4
Training loss: 0.1929340362548828
Validation loss: 1.6537926504688878

Epoch: 6| Step: 5
Training loss: 0.24768099188804626
Validation loss: 1.6051859676197011

Epoch: 6| Step: 6
Training loss: 0.38894402980804443
Validation loss: 1.6056893628130677

Epoch: 6| Step: 7
Training loss: 0.19247017800807953
Validation loss: 1.5476668406558294

Epoch: 6| Step: 8
Training loss: 0.12523764371871948
Validation loss: 1.5605202964557114

Epoch: 6| Step: 9
Training loss: 0.14569948613643646
Validation loss: 1.577204144129189

Epoch: 6| Step: 10
Training loss: 0.16091595590114594
Validation loss: 1.5732098638370473

Epoch: 6| Step: 11
Training loss: 0.16628935933113098
Validation loss: 1.5832532169998332

Epoch: 6| Step: 12
Training loss: 0.2060774862766266
Validation loss: 1.6127769690687939

Epoch: 6| Step: 13
Training loss: 0.17520317435264587
Validation loss: 1.6498382322249874

Epoch: 411| Step: 0
Training loss: 0.19388630986213684
Validation loss: 1.6608905779418124

Epoch: 6| Step: 1
Training loss: 0.2518300414085388
Validation loss: 1.696440811439227

Epoch: 6| Step: 2
Training loss: 0.11887259036302567
Validation loss: 1.6406620856254333

Epoch: 6| Step: 3
Training loss: 0.11375916749238968
Validation loss: 1.685029722029163

Epoch: 6| Step: 4
Training loss: 0.24581030011177063
Validation loss: 1.6704506207537908

Epoch: 6| Step: 5
Training loss: 0.17917777597904205
Validation loss: 1.6324026905080324

Epoch: 6| Step: 6
Training loss: 0.09831053763628006
Validation loss: 1.6441499725464852

Epoch: 6| Step: 7
Training loss: 0.20690350234508514
Validation loss: 1.6363062948308966

Epoch: 6| Step: 8
Training loss: 0.1472111940383911
Validation loss: 1.6410568260377454

Epoch: 6| Step: 9
Training loss: 0.18108679354190826
Validation loss: 1.6446676920819026

Epoch: 6| Step: 10
Training loss: 0.08200613409280777
Validation loss: 1.6258598655782721

Epoch: 6| Step: 11
Training loss: 0.424579381942749
Validation loss: 1.6571879027992167

Epoch: 6| Step: 12
Training loss: 0.143093541264534
Validation loss: 1.676442301401528

Epoch: 6| Step: 13
Training loss: 0.09618017822504044
Validation loss: 1.677521441572456

Epoch: 412| Step: 0
Training loss: 0.18014085292816162
Validation loss: 1.6901544409413491

Epoch: 6| Step: 1
Training loss: 0.13304519653320312
Validation loss: 1.6945872742642638

Epoch: 6| Step: 2
Training loss: 0.20377522706985474
Validation loss: 1.7275815638162757

Epoch: 6| Step: 3
Training loss: 0.12193164974451065
Validation loss: 1.715861892187467

Epoch: 6| Step: 4
Training loss: 0.16261500120162964
Validation loss: 1.7475184561103903

Epoch: 6| Step: 5
Training loss: 0.09392572939395905
Validation loss: 1.6933561089218303

Epoch: 6| Step: 6
Training loss: 0.17071011662483215
Validation loss: 1.6941324485245572

Epoch: 6| Step: 7
Training loss: 0.08525882661342621
Validation loss: 1.661857089688701

Epoch: 6| Step: 8
Training loss: 0.3662760257720947
Validation loss: 1.6139207322110412

Epoch: 6| Step: 9
Training loss: 0.15506277978420258
Validation loss: 1.577105499082996

Epoch: 6| Step: 10
Training loss: 0.20914633572101593
Validation loss: 1.578308210578016

Epoch: 6| Step: 11
Training loss: 0.0955745130777359
Validation loss: 1.5679377253337572

Epoch: 6| Step: 12
Training loss: 0.18347465991973877
Validation loss: 1.5387253697200487

Epoch: 6| Step: 13
Training loss: 0.19577568769454956
Validation loss: 1.5510154052447247

Epoch: 413| Step: 0
Training loss: 0.265568345785141
Validation loss: 1.5605907581185783

Epoch: 6| Step: 1
Training loss: 0.4589688181877136
Validation loss: 1.529544033030028

Epoch: 6| Step: 2
Training loss: 0.20365959405899048
Validation loss: 1.5516413360513666

Epoch: 6| Step: 3
Training loss: 0.12663359940052032
Validation loss: 1.5642952239641579

Epoch: 6| Step: 4
Training loss: 0.12448210269212723
Validation loss: 1.5419704875638407

Epoch: 6| Step: 5
Training loss: 0.06224512681365013
Validation loss: 1.545267584503338

Epoch: 6| Step: 6
Training loss: 0.10369908064603806
Validation loss: 1.5850438840927616

Epoch: 6| Step: 7
Training loss: 0.11946618556976318
Validation loss: 1.6282128223808863

Epoch: 6| Step: 8
Training loss: 0.2269710898399353
Validation loss: 1.658078041127933

Epoch: 6| Step: 9
Training loss: 0.12069427222013474
Validation loss: 1.6959624892921858

Epoch: 6| Step: 10
Training loss: 0.12772893905639648
Validation loss: 1.7390785448012813

Epoch: 6| Step: 11
Training loss: 0.108861044049263
Validation loss: 1.7464336195299703

Epoch: 6| Step: 12
Training loss: 0.07381682097911835
Validation loss: 1.7529091822203768

Epoch: 6| Step: 13
Training loss: 0.12460994720458984
Validation loss: 1.7290186202654274

Epoch: 414| Step: 0
Training loss: 0.11686087399721146
Validation loss: 1.6996274417446506

Epoch: 6| Step: 1
Training loss: 0.15986551344394684
Validation loss: 1.690548066810895

Epoch: 6| Step: 2
Training loss: 0.20650294423103333
Validation loss: 1.639048784009872

Epoch: 6| Step: 3
Training loss: 0.13085031509399414
Validation loss: 1.6277213558073966

Epoch: 6| Step: 4
Training loss: 0.11814688891172409
Validation loss: 1.6352935632069905

Epoch: 6| Step: 5
Training loss: 0.22884798049926758
Validation loss: 1.6209346043166293

Epoch: 6| Step: 6
Training loss: 0.1149803102016449
Validation loss: 1.6060627327170423

Epoch: 6| Step: 7
Training loss: 0.1705857664346695
Validation loss: 1.6013102967252013

Epoch: 6| Step: 8
Training loss: 0.42735761404037476
Validation loss: 1.6012504549436672

Epoch: 6| Step: 9
Training loss: 0.1970972716808319
Validation loss: 1.6224429197208856

Epoch: 6| Step: 10
Training loss: 0.22504585981369019
Validation loss: 1.628022018299308

Epoch: 6| Step: 11
Training loss: 0.20653069019317627
Validation loss: 1.6455447135433074

Epoch: 6| Step: 12
Training loss: 0.12887690961360931
Validation loss: 1.6527167674033874

Epoch: 6| Step: 13
Training loss: 0.1329830288887024
Validation loss: 1.6698209842046101

Epoch: 415| Step: 0
Training loss: 0.15429270267486572
Validation loss: 1.6491878519776046

Epoch: 6| Step: 1
Training loss: 0.20314818620681763
Validation loss: 1.630339499442808

Epoch: 6| Step: 2
Training loss: 0.09743726253509521
Validation loss: 1.6402725788854784

Epoch: 6| Step: 3
Training loss: 0.16516342759132385
Validation loss: 1.579619502508512

Epoch: 6| Step: 4
Training loss: 0.14755165576934814
Validation loss: 1.6160466235171083

Epoch: 6| Step: 5
Training loss: 0.16586962342262268
Validation loss: 1.6153696403708508

Epoch: 6| Step: 6
Training loss: 0.11423070728778839
Validation loss: 1.651858305418363

Epoch: 6| Step: 7
Training loss: 0.11264848709106445
Validation loss: 1.6714422343879618

Epoch: 6| Step: 8
Training loss: 0.27266234159469604
Validation loss: 1.691466349427418

Epoch: 6| Step: 9
Training loss: 0.6061502695083618
Validation loss: 1.7097102185731292

Epoch: 6| Step: 10
Training loss: 0.10221772640943527
Validation loss: 1.6975849059320265

Epoch: 6| Step: 11
Training loss: 0.1650407910346985
Validation loss: 1.7248171183370775

Epoch: 6| Step: 12
Training loss: 0.215969979763031
Validation loss: 1.7181507310559672

Epoch: 6| Step: 13
Training loss: 0.18943697214126587
Validation loss: 1.7362233361890238

Epoch: 416| Step: 0
Training loss: 0.18793514370918274
Validation loss: 1.7053144670301867

Epoch: 6| Step: 1
Training loss: 0.11782797425985336
Validation loss: 1.6678904153967415

Epoch: 6| Step: 2
Training loss: 0.14896553754806519
Validation loss: 1.6105795150162072

Epoch: 6| Step: 3
Training loss: 0.08287638425827026
Validation loss: 1.6158649870144424

Epoch: 6| Step: 4
Training loss: 0.11092270910739899
Validation loss: 1.5743222057178456

Epoch: 6| Step: 5
Training loss: 0.27996334433555603
Validation loss: 1.6155875985340407

Epoch: 6| Step: 6
Training loss: 0.149945467710495
Validation loss: 1.589470947942426

Epoch: 6| Step: 7
Training loss: 0.09459402412176132
Validation loss: 1.5792281473836591

Epoch: 6| Step: 8
Training loss: 0.3689887821674347
Validation loss: 1.6146634855578024

Epoch: 6| Step: 9
Training loss: 0.09631183743476868
Validation loss: 1.5968286222027195

Epoch: 6| Step: 10
Training loss: 0.19209207594394684
Validation loss: 1.6289195681131015

Epoch: 6| Step: 11
Training loss: 0.09119357168674469
Validation loss: 1.5914523880327902

Epoch: 6| Step: 12
Training loss: 0.1952146738767624
Validation loss: 1.6086046144526491

Epoch: 6| Step: 13
Training loss: 0.12235657125711441
Validation loss: 1.6141753863262873

Epoch: 417| Step: 0
Training loss: 0.11754605919122696
Validation loss: 1.6175473684905677

Epoch: 6| Step: 1
Training loss: 0.18621201813220978
Validation loss: 1.6621789150340582

Epoch: 6| Step: 2
Training loss: 0.11850988864898682
Validation loss: 1.6873931647628866

Epoch: 6| Step: 3
Training loss: 0.1552465856075287
Validation loss: 1.6873390238772157

Epoch: 6| Step: 4
Training loss: 0.12309043854475021
Validation loss: 1.6503637067733272

Epoch: 6| Step: 5
Training loss: 0.13542711734771729
Validation loss: 1.6275805798909997

Epoch: 6| Step: 6
Training loss: 0.11730407178401947
Validation loss: 1.6206158015035814

Epoch: 6| Step: 7
Training loss: 0.4509586691856384
Validation loss: 1.603841612415929

Epoch: 6| Step: 8
Training loss: 0.13222220540046692
Validation loss: 1.6314325435187227

Epoch: 6| Step: 9
Training loss: 0.29223310947418213
Validation loss: 1.6544633949956586

Epoch: 6| Step: 10
Training loss: 0.18286080658435822
Validation loss: 1.6358419605480727

Epoch: 6| Step: 11
Training loss: 0.12897717952728271
Validation loss: 1.6207587693327217

Epoch: 6| Step: 12
Training loss: 0.20542392134666443
Validation loss: 1.6481297682690363

Epoch: 6| Step: 13
Training loss: 0.17420323193073273
Validation loss: 1.681932831323275

Epoch: 418| Step: 0
Training loss: 0.3420744836330414
Validation loss: 1.7421756816166702

Epoch: 6| Step: 1
Training loss: 0.18310995399951935
Validation loss: 1.7756488425757295

Epoch: 6| Step: 2
Training loss: 0.2068023383617401
Validation loss: 1.7691846944952523

Epoch: 6| Step: 3
Training loss: 0.12489195168018341
Validation loss: 1.752655363851978

Epoch: 6| Step: 4
Training loss: 0.08826658129692078
Validation loss: 1.698673786655549

Epoch: 6| Step: 5
Training loss: 0.2183457911014557
Validation loss: 1.7056371114587272

Epoch: 6| Step: 6
Training loss: 0.19603116810321808
Validation loss: 1.6727186274784867

Epoch: 6| Step: 7
Training loss: 0.16989675164222717
Validation loss: 1.7095426256938646

Epoch: 6| Step: 8
Training loss: 0.14327631890773773
Validation loss: 1.6575243088506884

Epoch: 6| Step: 9
Training loss: 0.12042072415351868
Validation loss: 1.6902804579786075

Epoch: 6| Step: 10
Training loss: 0.13643814623355865
Validation loss: 1.6975234272659465

Epoch: 6| Step: 11
Training loss: 0.18546533584594727
Validation loss: 1.6786400938546786

Epoch: 6| Step: 12
Training loss: 0.2724100947380066
Validation loss: 1.6664513567442536

Epoch: 6| Step: 13
Training loss: 0.09217088669538498
Validation loss: 1.7118020442224318

Epoch: 419| Step: 0
Training loss: 0.18044915795326233
Validation loss: 1.6803593763741114

Epoch: 6| Step: 1
Training loss: 0.3116641640663147
Validation loss: 1.6065279463286042

Epoch: 6| Step: 2
Training loss: 0.2523965537548065
Validation loss: 1.6047265439905145

Epoch: 6| Step: 3
Training loss: 0.13067996501922607
Validation loss: 1.5992244828131892

Epoch: 6| Step: 4
Training loss: 0.17649126052856445
Validation loss: 1.59312117227944

Epoch: 6| Step: 5
Training loss: 0.11768687516450882
Validation loss: 1.608692058952906

Epoch: 6| Step: 6
Training loss: 0.1980212777853012
Validation loss: 1.6293857725717689

Epoch: 6| Step: 7
Training loss: 0.11537562310695648
Validation loss: 1.6590503261935325

Epoch: 6| Step: 8
Training loss: 0.40786096453666687
Validation loss: 1.7462932038050827

Epoch: 6| Step: 9
Training loss: 0.14741119742393494
Validation loss: 1.7804872400017195

Epoch: 6| Step: 10
Training loss: 0.12344510853290558
Validation loss: 1.8036860317312262

Epoch: 6| Step: 11
Training loss: 0.33413100242614746
Validation loss: 1.83921464027897

Epoch: 6| Step: 12
Training loss: 0.2953605055809021
Validation loss: 1.832118688091155

Epoch: 6| Step: 13
Training loss: 0.1835600584745407
Validation loss: 1.793767257403302

Epoch: 420| Step: 0
Training loss: 0.20321497321128845
Validation loss: 1.7170597596835064

Epoch: 6| Step: 1
Training loss: 0.11390047520399094
Validation loss: 1.6960192303503714

Epoch: 6| Step: 2
Training loss: 0.17490538954734802
Validation loss: 1.652007169620965

Epoch: 6| Step: 3
Training loss: 0.195444256067276
Validation loss: 1.6018049845131495

Epoch: 6| Step: 4
Training loss: 0.19390302896499634
Validation loss: 1.6247174816746865

Epoch: 6| Step: 5
Training loss: 0.11433760821819305
Validation loss: 1.5980242298495384

Epoch: 6| Step: 6
Training loss: 0.27738529443740845
Validation loss: 1.587674972831562

Epoch: 6| Step: 7
Training loss: 0.18939927220344543
Validation loss: 1.6144527081520326

Epoch: 6| Step: 8
Training loss: 0.22739389538764954
Validation loss: 1.5779339382725377

Epoch: 6| Step: 9
Training loss: 0.1332024335861206
Validation loss: 1.6154960855360954

Epoch: 6| Step: 10
Training loss: 0.21564419567584991
Validation loss: 1.6433761401843

Epoch: 6| Step: 11
Training loss: 0.23824821412563324
Validation loss: 1.6535382860450334

Epoch: 6| Step: 12
Training loss: 0.5175154209136963
Validation loss: 1.622676085400325

Epoch: 6| Step: 13
Training loss: 0.10905902832746506
Validation loss: 1.6679355380355672

Epoch: 421| Step: 0
Training loss: 0.43158358335494995
Validation loss: 1.688706277519144

Epoch: 6| Step: 1
Training loss: 0.14862608909606934
Validation loss: 1.7286218750861384

Epoch: 6| Step: 2
Training loss: 0.12459023296833038
Validation loss: 1.730113369803275

Epoch: 6| Step: 3
Training loss: 0.12187972664833069
Validation loss: 1.7085015581500145

Epoch: 6| Step: 4
Training loss: 0.14903920888900757
Validation loss: 1.7176400333322503

Epoch: 6| Step: 5
Training loss: 0.11664841324090958
Validation loss: 1.719889408798628

Epoch: 6| Step: 6
Training loss: 0.12740613520145416
Validation loss: 1.6914801648868028

Epoch: 6| Step: 7
Training loss: 0.18140611052513123
Validation loss: 1.6618128066421838

Epoch: 6| Step: 8
Training loss: 0.1004493460059166
Validation loss: 1.6245138029898367

Epoch: 6| Step: 9
Training loss: 0.18201681971549988
Validation loss: 1.5710265892808155

Epoch: 6| Step: 10
Training loss: 0.1898135244846344
Validation loss: 1.5932114752390052

Epoch: 6| Step: 11
Training loss: 0.17005538940429688
Validation loss: 1.566740564120713

Epoch: 6| Step: 12
Training loss: 0.2517675757408142
Validation loss: 1.554452088571364

Epoch: 6| Step: 13
Training loss: 0.12202289700508118
Validation loss: 1.5743760960076445

Epoch: 422| Step: 0
Training loss: 0.09264962375164032
Validation loss: 1.5810870560266639

Epoch: 6| Step: 1
Training loss: 0.10358536243438721
Validation loss: 1.58187626190083

Epoch: 6| Step: 2
Training loss: 0.39728718996047974
Validation loss: 1.6132652669824579

Epoch: 6| Step: 3
Training loss: 0.2119290679693222
Validation loss: 1.6182370096124628

Epoch: 6| Step: 4
Training loss: 0.2611314654350281
Validation loss: 1.63816919249873

Epoch: 6| Step: 5
Training loss: 0.15813550353050232
Validation loss: 1.5938074563139228

Epoch: 6| Step: 6
Training loss: 0.18058790266513824
Validation loss: 1.6580040903501614

Epoch: 6| Step: 7
Training loss: 0.1615215241909027
Validation loss: 1.6791461667706888

Epoch: 6| Step: 8
Training loss: 0.1685781329870224
Validation loss: 1.6365580199867167

Epoch: 6| Step: 9
Training loss: 0.12058724462985992
Validation loss: 1.711402355983693

Epoch: 6| Step: 10
Training loss: 0.16539058089256287
Validation loss: 1.6590007300017982

Epoch: 6| Step: 11
Training loss: 0.14077413082122803
Validation loss: 1.7059833785539031

Epoch: 6| Step: 12
Training loss: 0.20217737555503845
Validation loss: 1.6808022119665658

Epoch: 6| Step: 13
Training loss: 0.08326274901628494
Validation loss: 1.6792064712893577

Epoch: 423| Step: 0
Training loss: 0.15919965505599976
Validation loss: 1.6836311304441063

Epoch: 6| Step: 1
Training loss: 0.18106260895729065
Validation loss: 1.6877919538046724

Epoch: 6| Step: 2
Training loss: 0.39404231309890747
Validation loss: 1.672718369832603

Epoch: 6| Step: 3
Training loss: 0.09515098482370377
Validation loss: 1.6651738125790831

Epoch: 6| Step: 4
Training loss: 0.13418050110340118
Validation loss: 1.6634291025900072

Epoch: 6| Step: 5
Training loss: 0.2339211106300354
Validation loss: 1.6729586124420166

Epoch: 6| Step: 6
Training loss: 0.16972234845161438
Validation loss: 1.6919897704996087

Epoch: 6| Step: 7
Training loss: 0.11616569012403488
Validation loss: 1.6938730362922914

Epoch: 6| Step: 8
Training loss: 0.16201940178871155
Validation loss: 1.7098702384579567

Epoch: 6| Step: 9
Training loss: 0.1918759047985077
Validation loss: 1.7187603981264177

Epoch: 6| Step: 10
Training loss: 0.17728406190872192
Validation loss: 1.7261515868607389

Epoch: 6| Step: 11
Training loss: 0.08915596455335617
Validation loss: 1.7044897938287387

Epoch: 6| Step: 12
Training loss: 0.12068789452314377
Validation loss: 1.7053652988967074

Epoch: 6| Step: 13
Training loss: 0.11815518885850906
Validation loss: 1.6891246111162248

Epoch: 424| Step: 0
Training loss: 0.3095821738243103
Validation loss: 1.711943575130996

Epoch: 6| Step: 1
Training loss: 0.21228234469890594
Validation loss: 1.7422401341058875

Epoch: 6| Step: 2
Training loss: 0.2024601548910141
Validation loss: 1.714452951185165

Epoch: 6| Step: 3
Training loss: 0.11078591644763947
Validation loss: 1.6773255499460364

Epoch: 6| Step: 4
Training loss: 0.15954235196113586
Validation loss: 1.647759267078933

Epoch: 6| Step: 5
Training loss: 0.08957086503505707
Validation loss: 1.6501311409857966

Epoch: 6| Step: 6
Training loss: 0.11087477207183838
Validation loss: 1.6571089772767917

Epoch: 6| Step: 7
Training loss: 0.13247792422771454
Validation loss: 1.641639381326655

Epoch: 6| Step: 8
Training loss: 0.12970830500125885
Validation loss: 1.6133770878596971

Epoch: 6| Step: 9
Training loss: 0.1487537920475006
Validation loss: 1.6453034236866941

Epoch: 6| Step: 10
Training loss: 0.15345774590969086
Validation loss: 1.615638240050244

Epoch: 6| Step: 11
Training loss: 0.11139507591724396
Validation loss: 1.6596635003243723

Epoch: 6| Step: 12
Training loss: 0.22430066764354706
Validation loss: 1.6075748077002905

Epoch: 6| Step: 13
Training loss: 0.1553896814584732
Validation loss: 1.6076780621723463

Epoch: 425| Step: 0
Training loss: 0.13698571920394897
Validation loss: 1.6122392774910055

Epoch: 6| Step: 1
Training loss: 0.22313864529132843
Validation loss: 1.6035954439511864

Epoch: 6| Step: 2
Training loss: 0.3567313253879547
Validation loss: 1.6629645055340183

Epoch: 6| Step: 3
Training loss: 0.15162451565265656
Validation loss: 1.6844755962330809

Epoch: 6| Step: 4
Training loss: 0.11025217920541763
Validation loss: 1.6945379395638742

Epoch: 6| Step: 5
Training loss: 0.17071080207824707
Validation loss: 1.6820521803312405

Epoch: 6| Step: 6
Training loss: 0.17478200793266296
Validation loss: 1.6885081439889886

Epoch: 6| Step: 7
Training loss: 0.18529896438121796
Validation loss: 1.7040622234344482

Epoch: 6| Step: 8
Training loss: 0.10241709649562836
Validation loss: 1.6878053360087897

Epoch: 6| Step: 9
Training loss: 0.11843719333410263
Validation loss: 1.6723959381862352

Epoch: 6| Step: 10
Training loss: 0.0922551304101944
Validation loss: 1.638858401647178

Epoch: 6| Step: 11
Training loss: 0.21014510095119476
Validation loss: 1.6329156326991257

Epoch: 6| Step: 12
Training loss: 0.1473114937543869
Validation loss: 1.639902171268258

Epoch: 6| Step: 13
Training loss: 0.08569220453500748
Validation loss: 1.617697246613041

Epoch: 426| Step: 0
Training loss: 0.16683396697044373
Validation loss: 1.613946250689927

Epoch: 6| Step: 1
Training loss: 0.2200714349746704
Validation loss: 1.6297185062080302

Epoch: 6| Step: 2
Training loss: 0.15891292691230774
Validation loss: 1.6084745455813665

Epoch: 6| Step: 3
Training loss: 0.09316501021385193
Validation loss: 1.6590240360588155

Epoch: 6| Step: 4
Training loss: 0.1607678085565567
Validation loss: 1.6340883457532493

Epoch: 6| Step: 5
Training loss: 0.1275901049375534
Validation loss: 1.687980322427647

Epoch: 6| Step: 6
Training loss: 0.26417866349220276
Validation loss: 1.7201377755852156

Epoch: 6| Step: 7
Training loss: 0.18587854504585266
Validation loss: 1.7352680762608845

Epoch: 6| Step: 8
Training loss: 0.3083575367927551
Validation loss: 1.7560042322322886

Epoch: 6| Step: 9
Training loss: 0.146419957280159
Validation loss: 1.7317003793613885

Epoch: 6| Step: 10
Training loss: 0.12721958756446838
Validation loss: 1.7260290140746741

Epoch: 6| Step: 11
Training loss: 0.3558875024318695
Validation loss: 1.691110090542865

Epoch: 6| Step: 12
Training loss: 0.10177870094776154
Validation loss: 1.6815968021269767

Epoch: 6| Step: 13
Training loss: 0.3322206735610962
Validation loss: 1.6443249128198112

Epoch: 427| Step: 0
Training loss: 0.12282010912895203
Validation loss: 1.6045117339780253

Epoch: 6| Step: 1
Training loss: 0.11699239909648895
Validation loss: 1.592896003876963

Epoch: 6| Step: 2
Training loss: 0.12891389429569244
Validation loss: 1.5833771151881064

Epoch: 6| Step: 3
Training loss: 0.06949373334646225
Validation loss: 1.599318258223995

Epoch: 6| Step: 4
Training loss: 0.2710380554199219
Validation loss: 1.580070609687477

Epoch: 6| Step: 5
Training loss: 0.21339499950408936
Validation loss: 1.5932761789650045

Epoch: 6| Step: 6
Training loss: 0.2347412258386612
Validation loss: 1.6293805722267396

Epoch: 6| Step: 7
Training loss: 0.12494807690382004
Validation loss: 1.6262077182851813

Epoch: 6| Step: 8
Training loss: 0.36607757210731506
Validation loss: 1.637288659490565

Epoch: 6| Step: 9
Training loss: 0.14760246872901917
Validation loss: 1.6575265879272132

Epoch: 6| Step: 10
Training loss: 0.14798292517662048
Validation loss: 1.6770283932326941

Epoch: 6| Step: 11
Training loss: 0.2035466432571411
Validation loss: 1.7488971615350375

Epoch: 6| Step: 12
Training loss: 0.31212520599365234
Validation loss: 1.7914138455544748

Epoch: 6| Step: 13
Training loss: 0.2600838243961334
Validation loss: 1.7805449911343154

Epoch: 428| Step: 0
Training loss: 0.26153087615966797
Validation loss: 1.723211585834462

Epoch: 6| Step: 1
Training loss: 0.14892148971557617
Validation loss: 1.6660993624758977

Epoch: 6| Step: 2
Training loss: 0.18334048986434937
Validation loss: 1.6229745995613836

Epoch: 6| Step: 3
Training loss: 0.27353063225746155
Validation loss: 1.6009168176240818

Epoch: 6| Step: 4
Training loss: 0.2873387932777405
Validation loss: 1.5862987041473389

Epoch: 6| Step: 5
Training loss: 0.44610002636909485
Validation loss: 1.5702939815418695

Epoch: 6| Step: 6
Training loss: 0.2725035548210144
Validation loss: 1.555916105547259

Epoch: 6| Step: 7
Training loss: 0.45015713572502136
Validation loss: 1.5474654795021139

Epoch: 6| Step: 8
Training loss: 0.32936862111091614
Validation loss: 1.588774396527198

Epoch: 6| Step: 9
Training loss: 0.11147195100784302
Validation loss: 1.6352119586801017

Epoch: 6| Step: 10
Training loss: 0.3573729395866394
Validation loss: 1.7481444651080715

Epoch: 6| Step: 11
Training loss: 0.3633408546447754
Validation loss: 1.7839288121910506

Epoch: 6| Step: 12
Training loss: 0.27196991443634033
Validation loss: 1.77473311526801

Epoch: 6| Step: 13
Training loss: 0.26613321900367737
Validation loss: 1.7403324727089173

Epoch: 429| Step: 0
Training loss: 0.2564384341239929
Validation loss: 1.7481360666213497

Epoch: 6| Step: 1
Training loss: 0.18562805652618408
Validation loss: 1.7006287779859317

Epoch: 6| Step: 2
Training loss: 0.18777957558631897
Validation loss: 1.640945739643548

Epoch: 6| Step: 3
Training loss: 0.19460231065750122
Validation loss: 1.5933198262286443

Epoch: 6| Step: 4
Training loss: 0.21326802670955658
Validation loss: 1.5766132787991596

Epoch: 6| Step: 5
Training loss: 0.18978624045848846
Validation loss: 1.567142891627486

Epoch: 6| Step: 6
Training loss: 0.211593896150589
Validation loss: 1.6010319314977175

Epoch: 6| Step: 7
Training loss: 0.13679730892181396
Validation loss: 1.6022142992224744

Epoch: 6| Step: 8
Training loss: 0.1695404350757599
Validation loss: 1.5749659307541386

Epoch: 6| Step: 9
Training loss: 0.14926333725452423
Validation loss: 1.587794884558647

Epoch: 6| Step: 10
Training loss: 0.2059238702058792
Validation loss: 1.5912695584758636

Epoch: 6| Step: 11
Training loss: 0.14240753650665283
Validation loss: 1.655714246534532

Epoch: 6| Step: 12
Training loss: 0.40405911207199097
Validation loss: 1.6795558993534376

Epoch: 6| Step: 13
Training loss: 0.17196981608867645
Validation loss: 1.7217279736713698

Epoch: 430| Step: 0
Training loss: 0.21258625388145447
Validation loss: 1.7230820912186817

Epoch: 6| Step: 1
Training loss: 0.2064872682094574
Validation loss: 1.7796392210068241

Epoch: 6| Step: 2
Training loss: 0.14746412634849548
Validation loss: 1.7784021855682455

Epoch: 6| Step: 3
Training loss: 0.44197359681129456
Validation loss: 1.7756575140901791

Epoch: 6| Step: 4
Training loss: 0.17467603087425232
Validation loss: 1.7632270910406624

Epoch: 6| Step: 5
Training loss: 0.19714879989624023
Validation loss: 1.760768844235328

Epoch: 6| Step: 6
Training loss: 0.23217207193374634
Validation loss: 1.752201992978332

Epoch: 6| Step: 7
Training loss: 0.13666535913944244
Validation loss: 1.7355241083329724

Epoch: 6| Step: 8
Training loss: 0.1281387209892273
Validation loss: 1.7133800188700359

Epoch: 6| Step: 9
Training loss: 0.10718739777803421
Validation loss: 1.6703997683781449

Epoch: 6| Step: 10
Training loss: 0.2683853507041931
Validation loss: 1.6405940325029436

Epoch: 6| Step: 11
Training loss: 0.15150099992752075
Validation loss: 1.6584710613373788

Epoch: 6| Step: 12
Training loss: 0.15923190116882324
Validation loss: 1.638079043357603

Epoch: 6| Step: 13
Training loss: 0.13465915620326996
Validation loss: 1.6579512447439215

Epoch: 431| Step: 0
Training loss: 0.14934754371643066
Validation loss: 1.6514643866528746

Epoch: 6| Step: 1
Training loss: 0.15345504879951477
Validation loss: 1.6634122658801336

Epoch: 6| Step: 2
Training loss: 0.17398691177368164
Validation loss: 1.716042939052787

Epoch: 6| Step: 3
Training loss: 0.2500959038734436
Validation loss: 1.6945476942164923

Epoch: 6| Step: 4
Training loss: 0.3606935143470764
Validation loss: 1.7144990313437678

Epoch: 6| Step: 5
Training loss: 0.14272984862327576
Validation loss: 1.7154529543333157

Epoch: 6| Step: 6
Training loss: 0.2054777890443802
Validation loss: 1.6961402534156718

Epoch: 6| Step: 7
Training loss: 0.17324018478393555
Validation loss: 1.6905082835946033

Epoch: 6| Step: 8
Training loss: 0.12954942882061005
Validation loss: 1.6834739600458453

Epoch: 6| Step: 9
Training loss: 0.12217958271503448
Validation loss: 1.6739598563922349

Epoch: 6| Step: 10
Training loss: 0.1759626865386963
Validation loss: 1.6902665040826286

Epoch: 6| Step: 11
Training loss: 0.1811893880367279
Validation loss: 1.6657538183273808

Epoch: 6| Step: 12
Training loss: 0.17195060849189758
Validation loss: 1.691071210368987

Epoch: 6| Step: 13
Training loss: 0.4423014223575592
Validation loss: 1.7001111353597333

Epoch: 432| Step: 0
Training loss: 0.10577189922332764
Validation loss: 1.6847096232957737

Epoch: 6| Step: 1
Training loss: 0.1121884435415268
Validation loss: 1.6713019878633562

Epoch: 6| Step: 2
Training loss: 0.15852749347686768
Validation loss: 1.713837153168135

Epoch: 6| Step: 3
Training loss: 0.1568392813205719
Validation loss: 1.721906453050593

Epoch: 6| Step: 4
Training loss: 0.2432943731546402
Validation loss: 1.7159135418553506

Epoch: 6| Step: 5
Training loss: 0.2883076071739197
Validation loss: 1.717004080613454

Epoch: 6| Step: 6
Training loss: 0.39203640818595886
Validation loss: 1.693287279016228

Epoch: 6| Step: 7
Training loss: 0.17480877041816711
Validation loss: 1.650323333278779

Epoch: 6| Step: 8
Training loss: 0.14634782075881958
Validation loss: 1.6625701663314656

Epoch: 6| Step: 9
Training loss: 0.14807289838790894
Validation loss: 1.6510295278282576

Epoch: 6| Step: 10
Training loss: 0.20720991492271423
Validation loss: 1.6213493411258986

Epoch: 6| Step: 11
Training loss: 0.18959097564220428
Validation loss: 1.637561599413554

Epoch: 6| Step: 12
Training loss: 0.12850281596183777
Validation loss: 1.61748158290822

Epoch: 6| Step: 13
Training loss: 0.07379253953695297
Validation loss: 1.6110250142312819

Epoch: 433| Step: 0
Training loss: 0.20312708616256714
Validation loss: 1.6615064733771867

Epoch: 6| Step: 1
Training loss: 0.11000929027795792
Validation loss: 1.6231250916757891

Epoch: 6| Step: 2
Training loss: 0.12643709778785706
Validation loss: 1.612798063985763

Epoch: 6| Step: 3
Training loss: 0.18191657960414886
Validation loss: 1.6518570351344284

Epoch: 6| Step: 4
Training loss: 0.1499253511428833
Validation loss: 1.638723493904196

Epoch: 6| Step: 5
Training loss: 0.19526076316833496
Validation loss: 1.639847578540925

Epoch: 6| Step: 6
Training loss: 0.1676093339920044
Validation loss: 1.643874563196654

Epoch: 6| Step: 7
Training loss: 0.10930608212947845
Validation loss: 1.6622103683410152

Epoch: 6| Step: 8
Training loss: 0.14584822952747345
Validation loss: 1.6466845158607728

Epoch: 6| Step: 9
Training loss: 0.19826027750968933
Validation loss: 1.6407729195010277

Epoch: 6| Step: 10
Training loss: 0.4410197138786316
Validation loss: 1.6701017528451898

Epoch: 6| Step: 11
Training loss: 0.1263895034790039
Validation loss: 1.7201113572684668

Epoch: 6| Step: 12
Training loss: 0.14335548877716064
Validation loss: 1.7219172395685667

Epoch: 6| Step: 13
Training loss: 0.16736598312854767
Validation loss: 1.7403790476501628

Epoch: 434| Step: 0
Training loss: 0.11741083115339279
Validation loss: 1.7262142396742297

Epoch: 6| Step: 1
Training loss: 0.10987228900194168
Validation loss: 1.6762447876314963

Epoch: 6| Step: 2
Training loss: 0.11064106225967407
Validation loss: 1.6575807294537943

Epoch: 6| Step: 3
Training loss: 0.12891417741775513
Validation loss: 1.6379401658170967

Epoch: 6| Step: 4
Training loss: 0.17632661759853363
Validation loss: 1.6435071858026649

Epoch: 6| Step: 5
Training loss: 0.17769047617912292
Validation loss: 1.6928543121584

Epoch: 6| Step: 6
Training loss: 0.1901509165763855
Validation loss: 1.6795543214326263

Epoch: 6| Step: 7
Training loss: 0.2426890879869461
Validation loss: 1.6778402648946291

Epoch: 6| Step: 8
Training loss: 0.183738112449646
Validation loss: 1.6869474046973771

Epoch: 6| Step: 9
Training loss: 0.43258920311927795
Validation loss: 1.6864015953515166

Epoch: 6| Step: 10
Training loss: 0.2657117247581482
Validation loss: 1.7405092485489384

Epoch: 6| Step: 11
Training loss: 0.2703762352466583
Validation loss: 1.709628879383046

Epoch: 6| Step: 12
Training loss: 0.19079160690307617
Validation loss: 1.7590434410238778

Epoch: 6| Step: 13
Training loss: 0.42681849002838135
Validation loss: 1.7320904911205333

Epoch: 435| Step: 0
Training loss: 0.18133874237537384
Validation loss: 1.6989884594435334

Epoch: 6| Step: 1
Training loss: 0.12576663494110107
Validation loss: 1.6919733221812914

Epoch: 6| Step: 2
Training loss: 0.08537305146455765
Validation loss: 1.6478473883803173

Epoch: 6| Step: 3
Training loss: 0.3314892053604126
Validation loss: 1.6293200754350232

Epoch: 6| Step: 4
Training loss: 0.17567846179008484
Validation loss: 1.5853595451642108

Epoch: 6| Step: 5
Training loss: 0.18076191842556
Validation loss: 1.575434970599349

Epoch: 6| Step: 6
Training loss: 0.2542315125465393
Validation loss: 1.561170522884656

Epoch: 6| Step: 7
Training loss: 0.21843427419662476
Validation loss: 1.558725433964883

Epoch: 6| Step: 8
Training loss: 0.1296260952949524
Validation loss: 1.5899107802298762

Epoch: 6| Step: 9
Training loss: 0.2226494401693344
Validation loss: 1.6176374022678663

Epoch: 6| Step: 10
Training loss: 0.15467718243598938
Validation loss: 1.5692521961786414

Epoch: 6| Step: 11
Training loss: 0.19628065824508667
Validation loss: 1.6368896166483562

Epoch: 6| Step: 12
Training loss: 0.08296392112970352
Validation loss: 1.627842153272321

Epoch: 6| Step: 13
Training loss: 0.24207867681980133
Validation loss: 1.6705793469182906

Epoch: 436| Step: 0
Training loss: 0.14089970290660858
Validation loss: 1.6606274368942424

Epoch: 6| Step: 1
Training loss: 0.12921693921089172
Validation loss: 1.7189091136378627

Epoch: 6| Step: 2
Training loss: 0.17029589414596558
Validation loss: 1.6719046395312074

Epoch: 6| Step: 3
Training loss: 0.2538694143295288
Validation loss: 1.6594387574862408

Epoch: 6| Step: 4
Training loss: 0.12461110949516296
Validation loss: 1.6483275223803777

Epoch: 6| Step: 5
Training loss: 0.10326370596885681
Validation loss: 1.671296292094774

Epoch: 6| Step: 6
Training loss: 0.3553367555141449
Validation loss: 1.6332595809813468

Epoch: 6| Step: 7
Training loss: 0.10866940021514893
Validation loss: 1.6195012023372035

Epoch: 6| Step: 8
Training loss: 0.1290310025215149
Validation loss: 1.6237413114117039

Epoch: 6| Step: 9
Training loss: 0.23662053048610687
Validation loss: 1.6358780809628066

Epoch: 6| Step: 10
Training loss: 0.15402689576148987
Validation loss: 1.6532642187610749

Epoch: 6| Step: 11
Training loss: 0.118623286485672
Validation loss: 1.6963859424796155

Epoch: 6| Step: 12
Training loss: 0.2013067603111267
Validation loss: 1.6860123577938284

Epoch: 6| Step: 13
Training loss: 0.17686915397644043
Validation loss: 1.664274154170867

Epoch: 437| Step: 0
Training loss: 0.19222742319107056
Validation loss: 1.674910032620994

Epoch: 6| Step: 1
Training loss: 0.1255967915058136
Validation loss: 1.6396285590305124

Epoch: 6| Step: 2
Training loss: 0.14816933870315552
Validation loss: 1.6332945939033263

Epoch: 6| Step: 3
Training loss: 0.10381801426410675
Validation loss: 1.6131648850697342

Epoch: 6| Step: 4
Training loss: 0.14190244674682617
Validation loss: 1.6227729423071748

Epoch: 6| Step: 5
Training loss: 0.16466650366783142
Validation loss: 1.6169947988243514

Epoch: 6| Step: 6
Training loss: 0.08468303084373474
Validation loss: 1.6231127887643793

Epoch: 6| Step: 7
Training loss: 0.11651834845542908
Validation loss: 1.6354816344476515

Epoch: 6| Step: 8
Training loss: 0.2308792769908905
Validation loss: 1.671941577747304

Epoch: 6| Step: 9
Training loss: 0.18455633521080017
Validation loss: 1.6512814369252933

Epoch: 6| Step: 10
Training loss: 0.2548753321170807
Validation loss: 1.6865074647370206

Epoch: 6| Step: 11
Training loss: 0.07625990360975266
Validation loss: 1.6475632844432708

Epoch: 6| Step: 12
Training loss: 0.3649163544178009
Validation loss: 1.6494088326731036

Epoch: 6| Step: 13
Training loss: 0.08008861541748047
Validation loss: 1.6236873749763734

Epoch: 438| Step: 0
Training loss: 0.10968498885631561
Validation loss: 1.6595892175551383

Epoch: 6| Step: 1
Training loss: 0.15999744832515717
Validation loss: 1.6361399107081915

Epoch: 6| Step: 2
Training loss: 0.18033984303474426
Validation loss: 1.631032222060747

Epoch: 6| Step: 3
Training loss: 0.14265727996826172
Validation loss: 1.6180455761571084

Epoch: 6| Step: 4
Training loss: 0.2825300693511963
Validation loss: 1.6426196418782717

Epoch: 6| Step: 5
Training loss: 0.21996554732322693
Validation loss: 1.6033800212285851

Epoch: 6| Step: 6
Training loss: 0.4051258862018585
Validation loss: 1.6419367328766854

Epoch: 6| Step: 7
Training loss: 0.13005401194095612
Validation loss: 1.6145017429064679

Epoch: 6| Step: 8
Training loss: 0.2096233069896698
Validation loss: 1.6081802704000985

Epoch: 6| Step: 9
Training loss: 0.16838116943836212
Validation loss: 1.5976796098934707

Epoch: 6| Step: 10
Training loss: 0.2706681787967682
Validation loss: 1.5919219678448093

Epoch: 6| Step: 11
Training loss: 0.2528742849826813
Validation loss: 1.552361778033677

Epoch: 6| Step: 12
Training loss: 0.13556388020515442
Validation loss: 1.5879986138753994

Epoch: 6| Step: 13
Training loss: 0.15651458501815796
Validation loss: 1.575490556737428

Epoch: 439| Step: 0
Training loss: 0.20453914999961853
Validation loss: 1.5957211595709606

Epoch: 6| Step: 1
Training loss: 0.09974799305200577
Validation loss: 1.6364626256368493

Epoch: 6| Step: 2
Training loss: 0.212630957365036
Validation loss: 1.6297061404874247

Epoch: 6| Step: 3
Training loss: 0.14960023760795593
Validation loss: 1.6806645201098533

Epoch: 6| Step: 4
Training loss: 0.1924302726984024
Validation loss: 1.7272298412938272

Epoch: 6| Step: 5
Training loss: 0.1727355718612671
Validation loss: 1.7284965463863906

Epoch: 6| Step: 6
Training loss: 0.18422085046768188
Validation loss: 1.7401730322068738

Epoch: 6| Step: 7
Training loss: 0.18075791001319885
Validation loss: 1.765927246821824

Epoch: 6| Step: 8
Training loss: 0.11572633683681488
Validation loss: 1.7838537398205008

Epoch: 6| Step: 9
Training loss: 0.4230811595916748
Validation loss: 1.74492343266805

Epoch: 6| Step: 10
Training loss: 0.19053798913955688
Validation loss: 1.7699568835637902

Epoch: 6| Step: 11
Training loss: 0.2880879342556
Validation loss: 1.754984796688121

Epoch: 6| Step: 12
Training loss: 0.23531371355056763
Validation loss: 1.7264953146698654

Epoch: 6| Step: 13
Training loss: 0.16886186599731445
Validation loss: 1.6550460605211155

Epoch: 440| Step: 0
Training loss: 0.11645595729351044
Validation loss: 1.6373892176535823

Epoch: 6| Step: 1
Training loss: 0.16266126930713654
Validation loss: 1.563794820539413

Epoch: 6| Step: 2
Training loss: 0.21932223439216614
Validation loss: 1.5783554674476705

Epoch: 6| Step: 3
Training loss: 0.14290717244148254
Validation loss: 1.5242379173155753

Epoch: 6| Step: 4
Training loss: 0.18562069535255432
Validation loss: 1.5079252040514382

Epoch: 6| Step: 5
Training loss: 0.19457614421844482
Validation loss: 1.5646002933543215

Epoch: 6| Step: 6
Training loss: 0.17915412783622742
Validation loss: 1.5691631545302689

Epoch: 6| Step: 7
Training loss: 0.34959661960601807
Validation loss: 1.6198996420829528

Epoch: 6| Step: 8
Training loss: 0.1758342683315277
Validation loss: 1.636474047937701

Epoch: 6| Step: 9
Training loss: 0.2368471324443817
Validation loss: 1.6902707802352084

Epoch: 6| Step: 10
Training loss: 0.19762665033340454
Validation loss: 1.778061072031657

Epoch: 6| Step: 11
Training loss: 0.18737809360027313
Validation loss: 1.7941527161546933

Epoch: 6| Step: 12
Training loss: 0.1745503544807434
Validation loss: 1.7760039362856137

Epoch: 6| Step: 13
Training loss: 0.22276347875595093
Validation loss: 1.7666783435370332

Epoch: 441| Step: 0
Training loss: 0.1997198611497879
Validation loss: 1.7883526394444127

Epoch: 6| Step: 1
Training loss: 0.15739116072654724
Validation loss: 1.7765532911464732

Epoch: 6| Step: 2
Training loss: 0.17513179779052734
Validation loss: 1.7599009134436165

Epoch: 6| Step: 3
Training loss: 0.21143537759780884
Validation loss: 1.7316756030564666

Epoch: 6| Step: 4
Training loss: 0.16638435423374176
Validation loss: 1.7267467142433248

Epoch: 6| Step: 5
Training loss: 0.17262040078639984
Validation loss: 1.7214568840560092

Epoch: 6| Step: 6
Training loss: 0.1937984973192215
Validation loss: 1.6473851998647053

Epoch: 6| Step: 7
Training loss: 0.22428756952285767
Validation loss: 1.630577789839878

Epoch: 6| Step: 8
Training loss: 0.100606270134449
Validation loss: 1.593682381414598

Epoch: 6| Step: 9
Training loss: 0.16427940130233765
Validation loss: 1.564568042755127

Epoch: 6| Step: 10
Training loss: 0.22237008810043335
Validation loss: 1.5423107916308987

Epoch: 6| Step: 11
Training loss: 0.1365552395582199
Validation loss: 1.545681425320205

Epoch: 6| Step: 12
Training loss: 0.45760929584503174
Validation loss: 1.5356608603590278

Epoch: 6| Step: 13
Training loss: 0.07294394820928574
Validation loss: 1.5430451599500512

Epoch: 442| Step: 0
Training loss: 0.19268791377544403
Validation loss: 1.5410733569052912

Epoch: 6| Step: 1
Training loss: 0.13761882483959198
Validation loss: 1.5625269586040127

Epoch: 6| Step: 2
Training loss: 0.17595162987709045
Validation loss: 1.597613153919097

Epoch: 6| Step: 3
Training loss: 0.0916433036327362
Validation loss: 1.6393655794923023

Epoch: 6| Step: 4
Training loss: 0.16454888880252838
Validation loss: 1.6648604049477527

Epoch: 6| Step: 5
Training loss: 0.10816524922847748
Validation loss: 1.6647961998498568

Epoch: 6| Step: 6
Training loss: 0.0864296555519104
Validation loss: 1.6899646687251266

Epoch: 6| Step: 7
Training loss: 0.186319500207901
Validation loss: 1.6780975787870345

Epoch: 6| Step: 8
Training loss: 0.15694284439086914
Validation loss: 1.6814987967091222

Epoch: 6| Step: 9
Training loss: 0.5331774950027466
Validation loss: 1.7139027157137472

Epoch: 6| Step: 10
Training loss: 0.14994528889656067
Validation loss: 1.7136538682445404

Epoch: 6| Step: 11
Training loss: 0.21039219200611115
Validation loss: 1.7208146972040976

Epoch: 6| Step: 12
Training loss: 0.12167105078697205
Validation loss: 1.6701577171202628

Epoch: 6| Step: 13
Training loss: 0.1588919460773468
Validation loss: 1.6513098106589368

Epoch: 443| Step: 0
Training loss: 0.19763728976249695
Validation loss: 1.6559477390781525

Epoch: 6| Step: 1
Training loss: 0.21079981327056885
Validation loss: 1.6585177144696635

Epoch: 6| Step: 2
Training loss: 0.17053815722465515
Validation loss: 1.6702868682081982

Epoch: 6| Step: 3
Training loss: 0.18441909551620483
Validation loss: 1.6416807738683556

Epoch: 6| Step: 4
Training loss: 0.14352571964263916
Validation loss: 1.6111608218121272

Epoch: 6| Step: 5
Training loss: 0.12999291718006134
Validation loss: 1.6275231735680693

Epoch: 6| Step: 6
Training loss: 0.1551382839679718
Validation loss: 1.630926093747539

Epoch: 6| Step: 7
Training loss: 0.1064043939113617
Validation loss: 1.6215784677895166

Epoch: 6| Step: 8
Training loss: 0.4091174006462097
Validation loss: 1.6269284743134693

Epoch: 6| Step: 9
Training loss: 0.09746876358985901
Validation loss: 1.6352941066988054

Epoch: 6| Step: 10
Training loss: 0.10491980612277985
Validation loss: 1.6248632707903463

Epoch: 6| Step: 11
Training loss: 0.15331915020942688
Validation loss: 1.6515737246441584

Epoch: 6| Step: 12
Training loss: 0.11332176625728607
Validation loss: 1.659292564597181

Epoch: 6| Step: 13
Training loss: 0.12441276013851166
Validation loss: 1.6301848221850652

Epoch: 444| Step: 0
Training loss: 0.13850048184394836
Validation loss: 1.669148040074174

Epoch: 6| Step: 1
Training loss: 0.11692345142364502
Validation loss: 1.631694934701407

Epoch: 6| Step: 2
Training loss: 0.11802749335765839
Validation loss: 1.6043361130581106

Epoch: 6| Step: 3
Training loss: 0.11264078319072723
Validation loss: 1.6051018058612783

Epoch: 6| Step: 4
Training loss: 0.09114193916320801
Validation loss: 1.6210209605514363

Epoch: 6| Step: 5
Training loss: 0.21830126643180847
Validation loss: 1.5957276545545107

Epoch: 6| Step: 6
Training loss: 0.15616512298583984
Validation loss: 1.6167325486419022

Epoch: 6| Step: 7
Training loss: 0.35727500915527344
Validation loss: 1.5967877859710364

Epoch: 6| Step: 8
Training loss: 0.13289226591587067
Validation loss: 1.647482451572213

Epoch: 6| Step: 9
Training loss: 0.21161089837551117
Validation loss: 1.6787995189748786

Epoch: 6| Step: 10
Training loss: 0.13434939086437225
Validation loss: 1.6739881820576166

Epoch: 6| Step: 11
Training loss: 0.10863613337278366
Validation loss: 1.69168903622576

Epoch: 6| Step: 12
Training loss: 0.15732994675636292
Validation loss: 1.734821092697882

Epoch: 6| Step: 13
Training loss: 0.07502380013465881
Validation loss: 1.707499203502491

Epoch: 445| Step: 0
Training loss: 0.15170976519584656
Validation loss: 1.7366622776113532

Epoch: 6| Step: 1
Training loss: 0.1692926585674286
Validation loss: 1.7481006550532516

Epoch: 6| Step: 2
Training loss: 0.20264844596385956
Validation loss: 1.713933462737709

Epoch: 6| Step: 3
Training loss: 0.24222955107688904
Validation loss: 1.6904488840410787

Epoch: 6| Step: 4
Training loss: 0.13383832573890686
Validation loss: 1.6619433177414762

Epoch: 6| Step: 5
Training loss: 0.19935032725334167
Validation loss: 1.6094023732728855

Epoch: 6| Step: 6
Training loss: 0.08836531639099121
Validation loss: 1.6211614698492072

Epoch: 6| Step: 7
Training loss: 0.15216070413589478
Validation loss: 1.6014258476995653

Epoch: 6| Step: 8
Training loss: 0.12299731373786926
Validation loss: 1.588349921728975

Epoch: 6| Step: 9
Training loss: 0.09629006683826447
Validation loss: 1.5575567406992759

Epoch: 6| Step: 10
Training loss: 0.1663396954536438
Validation loss: 1.5942402937078988

Epoch: 6| Step: 11
Training loss: 0.13568013906478882
Validation loss: 1.5910573146676505

Epoch: 6| Step: 12
Training loss: 0.13430556654930115
Validation loss: 1.5881674808840598

Epoch: 6| Step: 13
Training loss: 0.4702264070510864
Validation loss: 1.578058527361962

Epoch: 446| Step: 0
Training loss: 0.20232051610946655
Validation loss: 1.6093073839782386

Epoch: 6| Step: 1
Training loss: 0.10161462426185608
Validation loss: 1.5860135606540147

Epoch: 6| Step: 2
Training loss: 0.43624961376190186
Validation loss: 1.5955925244157032

Epoch: 6| Step: 3
Training loss: 0.08361728489398956
Validation loss: 1.6231158702604231

Epoch: 6| Step: 4
Training loss: 0.13554491102695465
Validation loss: 1.581283910300142

Epoch: 6| Step: 5
Training loss: 0.12186452001333237
Validation loss: 1.629820627550925

Epoch: 6| Step: 6
Training loss: 0.09082171320915222
Validation loss: 1.6207553853270829

Epoch: 6| Step: 7
Training loss: 0.10043437778949738
Validation loss: 1.6761798397187264

Epoch: 6| Step: 8
Training loss: 0.13712744414806366
Validation loss: 1.6817428873431297

Epoch: 6| Step: 9
Training loss: 0.14186546206474304
Validation loss: 1.6946349361891389

Epoch: 6| Step: 10
Training loss: 0.10154319554567337
Validation loss: 1.7017488838523946

Epoch: 6| Step: 11
Training loss: 0.12536069750785828
Validation loss: 1.6895130359998314

Epoch: 6| Step: 12
Training loss: 0.16842232644557953
Validation loss: 1.7150872535603021

Epoch: 6| Step: 13
Training loss: 0.11523538082838058
Validation loss: 1.725308729756263

Epoch: 447| Step: 0
Training loss: 0.11159683018922806
Validation loss: 1.7180745499108427

Epoch: 6| Step: 1
Training loss: 0.20679812133312225
Validation loss: 1.7387029804209226

Epoch: 6| Step: 2
Training loss: 0.14834588766098022
Validation loss: 1.6903060302939465

Epoch: 6| Step: 3
Training loss: 0.11002077162265778
Validation loss: 1.6677011212994974

Epoch: 6| Step: 4
Training loss: 0.39048445224761963
Validation loss: 1.664785897859963

Epoch: 6| Step: 5
Training loss: 0.12519773840904236
Validation loss: 1.6589634514624072

Epoch: 6| Step: 6
Training loss: 0.15374696254730225
Validation loss: 1.6497535705566406

Epoch: 6| Step: 7
Training loss: 0.12189330160617828
Validation loss: 1.6228963841674149

Epoch: 6| Step: 8
Training loss: 0.18903371691703796
Validation loss: 1.6398042196868567

Epoch: 6| Step: 9
Training loss: 0.08688324689865112
Validation loss: 1.6165174450925601

Epoch: 6| Step: 10
Training loss: 0.08485430479049683
Validation loss: 1.6020288787862307

Epoch: 6| Step: 11
Training loss: 0.13956579566001892
Validation loss: 1.6085281346433906

Epoch: 6| Step: 12
Training loss: 0.13072840869426727
Validation loss: 1.6249317994681738

Epoch: 6| Step: 13
Training loss: 0.13245099782943726
Validation loss: 1.5924828065338956

Epoch: 448| Step: 0
Training loss: 0.11975263804197311
Validation loss: 1.6036077686535415

Epoch: 6| Step: 1
Training loss: 0.09894080460071564
Validation loss: 1.5925379132711759

Epoch: 6| Step: 2
Training loss: 0.36792486906051636
Validation loss: 1.5765392498303485

Epoch: 6| Step: 3
Training loss: 0.11392590403556824
Validation loss: 1.594827478290886

Epoch: 6| Step: 4
Training loss: 0.22731593251228333
Validation loss: 1.591278726054776

Epoch: 6| Step: 5
Training loss: 0.1794973462820053
Validation loss: 1.5905374955105525

Epoch: 6| Step: 6
Training loss: 0.12905840575695038
Validation loss: 1.628765336928829

Epoch: 6| Step: 7
Training loss: 0.20284272730350494
Validation loss: 1.6390891318680139

Epoch: 6| Step: 8
Training loss: 0.09814007580280304
Validation loss: 1.6540454151809856

Epoch: 6| Step: 9
Training loss: 0.09206698834896088
Validation loss: 1.663640954161203

Epoch: 6| Step: 10
Training loss: 0.10255435854196548
Validation loss: 1.6536816679021364

Epoch: 6| Step: 11
Training loss: 0.09902137517929077
Validation loss: 1.6232909547385348

Epoch: 6| Step: 12
Training loss: 0.14735132455825806
Validation loss: 1.6560425104633454

Epoch: 6| Step: 13
Training loss: 0.18930761516094208
Validation loss: 1.623934300996924

Epoch: 449| Step: 0
Training loss: 0.12322227656841278
Validation loss: 1.607487868237239

Epoch: 6| Step: 1
Training loss: 0.12743164598941803
Validation loss: 1.630227429892427

Epoch: 6| Step: 2
Training loss: 0.09645149111747742
Validation loss: 1.650403767503718

Epoch: 6| Step: 3
Training loss: 0.12307389080524445
Validation loss: 1.624925183993514

Epoch: 6| Step: 4
Training loss: 0.0843765139579773
Validation loss: 1.6337201941397883

Epoch: 6| Step: 5
Training loss: 0.16575084626674652
Validation loss: 1.593038699960196

Epoch: 6| Step: 6
Training loss: 0.15694330632686615
Validation loss: 1.6153519192049581

Epoch: 6| Step: 7
Training loss: 0.130387082695961
Validation loss: 1.60765488173372

Epoch: 6| Step: 8
Training loss: 0.12825630605220795
Validation loss: 1.621570151339295

Epoch: 6| Step: 9
Training loss: 0.10873141139745712
Validation loss: 1.600730053840145

Epoch: 6| Step: 10
Training loss: 0.2765343487262726
Validation loss: 1.5747663897852744

Epoch: 6| Step: 11
Training loss: 0.4373500943183899
Validation loss: 1.5874354929052374

Epoch: 6| Step: 12
Training loss: 0.0841071829199791
Validation loss: 1.5734019779389905

Epoch: 6| Step: 13
Training loss: 0.2188018411397934
Validation loss: 1.549233119333944

Epoch: 450| Step: 0
Training loss: 0.3606688976287842
Validation loss: 1.5182453317026938

Epoch: 6| Step: 1
Training loss: 0.13304202258586884
Validation loss: 1.5150640421016242

Epoch: 6| Step: 2
Training loss: 0.19661612808704376
Validation loss: 1.5574432649920065

Epoch: 6| Step: 3
Training loss: 0.13300299644470215
Validation loss: 1.570025086402893

Epoch: 6| Step: 4
Training loss: 0.2796739935874939
Validation loss: 1.5813492344271751

Epoch: 6| Step: 5
Training loss: 0.2350669801235199
Validation loss: 1.6162418050150718

Epoch: 6| Step: 6
Training loss: 0.21214067935943604
Validation loss: 1.6007379280623568

Epoch: 6| Step: 7
Training loss: 0.20403851568698883
Validation loss: 1.6344927267361713

Epoch: 6| Step: 8
Training loss: 0.18147262930870056
Validation loss: 1.6516468576205674

Epoch: 6| Step: 9
Training loss: 0.2895417809486389
Validation loss: 1.6520899059951946

Epoch: 6| Step: 10
Training loss: 0.0941379964351654
Validation loss: 1.6600031891176779

Epoch: 6| Step: 11
Training loss: 0.20138028264045715
Validation loss: 1.6886075312091458

Epoch: 6| Step: 12
Training loss: 0.22139911353588104
Validation loss: 1.6793647350803498

Epoch: 6| Step: 13
Training loss: 0.23798421025276184
Validation loss: 1.7074453567945829

Epoch: 451| Step: 0
Training loss: 0.1597345918416977
Validation loss: 1.7033722977484427

Epoch: 6| Step: 1
Training loss: 0.3195798099040985
Validation loss: 1.7139067547295683

Epoch: 6| Step: 2
Training loss: 0.08937971293926239
Validation loss: 1.6879798776359969

Epoch: 6| Step: 3
Training loss: 0.09124340116977692
Validation loss: 1.6997667256221975

Epoch: 6| Step: 4
Training loss: 0.14812520146369934
Validation loss: 1.69883091603556

Epoch: 6| Step: 5
Training loss: 0.09994255006313324
Validation loss: 1.6871360668572046

Epoch: 6| Step: 6
Training loss: 0.16043883562088013
Validation loss: 1.6985902196617537

Epoch: 6| Step: 7
Training loss: 0.192238450050354
Validation loss: 1.6740679240995837

Epoch: 6| Step: 8
Training loss: 0.15206538140773773
Validation loss: 1.6422988253255044

Epoch: 6| Step: 9
Training loss: 0.24706962704658508
Validation loss: 1.6335657104369132

Epoch: 6| Step: 10
Training loss: 0.1333758383989334
Validation loss: 1.586116736935031

Epoch: 6| Step: 11
Training loss: 0.4864422380924225
Validation loss: 1.6025275389353435

Epoch: 6| Step: 12
Training loss: 0.13161250948905945
Validation loss: 1.5836729567538026

Epoch: 6| Step: 13
Training loss: 0.1457025110721588
Validation loss: 1.6015325060454748

Epoch: 452| Step: 0
Training loss: 0.2157474160194397
Validation loss: 1.6654065219304894

Epoch: 6| Step: 1
Training loss: 0.11247227340936661
Validation loss: 1.6870811959748626

Epoch: 6| Step: 2
Training loss: 0.17572739720344543
Validation loss: 1.7206125349126837

Epoch: 6| Step: 3
Training loss: 0.11200898140668869
Validation loss: 1.7533758904344292

Epoch: 6| Step: 4
Training loss: 0.40714961290359497
Validation loss: 1.7579646379716936

Epoch: 6| Step: 5
Training loss: 0.11088021099567413
Validation loss: 1.7252915136275753

Epoch: 6| Step: 6
Training loss: 0.1461012363433838
Validation loss: 1.7085009941490747

Epoch: 6| Step: 7
Training loss: 0.08222378045320511
Validation loss: 1.6920677641386628

Epoch: 6| Step: 8
Training loss: 0.11517560482025146
Validation loss: 1.6704224335250033

Epoch: 6| Step: 9
Training loss: 0.1626230925321579
Validation loss: 1.646322565694009

Epoch: 6| Step: 10
Training loss: 0.16257357597351074
Validation loss: 1.6122875162350234

Epoch: 6| Step: 11
Training loss: 0.19887617230415344
Validation loss: 1.6242989647773005

Epoch: 6| Step: 12
Training loss: 0.0968487560749054
Validation loss: 1.6038889461948025

Epoch: 6| Step: 13
Training loss: 0.11496137082576752
Validation loss: 1.6534777149077384

Epoch: 453| Step: 0
Training loss: 0.1449158936738968
Validation loss: 1.6234958428208546

Epoch: 6| Step: 1
Training loss: 0.17700998485088348
Validation loss: 1.6330195524359261

Epoch: 6| Step: 2
Training loss: 0.37210196256637573
Validation loss: 1.6546765732508835

Epoch: 6| Step: 3
Training loss: 0.12375514209270477
Validation loss: 1.654664299821341

Epoch: 6| Step: 4
Training loss: 0.15958482027053833
Validation loss: 1.6990019659842215

Epoch: 6| Step: 5
Training loss: 0.16221100091934204
Validation loss: 1.6771619704461866

Epoch: 6| Step: 6
Training loss: 0.09530281275510788
Validation loss: 1.6608630982778405

Epoch: 6| Step: 7
Training loss: 0.13037049770355225
Validation loss: 1.6507014254088044

Epoch: 6| Step: 8
Training loss: 0.15739044547080994
Validation loss: 1.6667361772188576

Epoch: 6| Step: 9
Training loss: 0.1450677514076233
Validation loss: 1.6365724212379866

Epoch: 6| Step: 10
Training loss: 0.13180413842201233
Validation loss: 1.6923598268980622

Epoch: 6| Step: 11
Training loss: 0.12907615303993225
Validation loss: 1.7319123232236473

Epoch: 6| Step: 12
Training loss: 0.13772046566009521
Validation loss: 1.7245579009415002

Epoch: 6| Step: 13
Training loss: 0.10107437521219254
Validation loss: 1.7296715833807503

Epoch: 454| Step: 0
Training loss: 0.13341042399406433
Validation loss: 1.7272550687995007

Epoch: 6| Step: 1
Training loss: 0.16198720037937164
Validation loss: 1.7344741308560936

Epoch: 6| Step: 2
Training loss: 0.15659388899803162
Validation loss: 1.6949696233195644

Epoch: 6| Step: 3
Training loss: 0.1701822429895401
Validation loss: 1.7317165315792125

Epoch: 6| Step: 4
Training loss: 0.1754642128944397
Validation loss: 1.7082524722622288

Epoch: 6| Step: 5
Training loss: 0.2118338644504547
Validation loss: 1.6929315610598492

Epoch: 6| Step: 6
Training loss: 0.2677980363368988
Validation loss: 1.6635125196108254

Epoch: 6| Step: 7
Training loss: 0.11424686759710312
Validation loss: 1.661221586247926

Epoch: 6| Step: 8
Training loss: 0.127911776304245
Validation loss: 1.6524699093193136

Epoch: 6| Step: 9
Training loss: 0.32712000608444214
Validation loss: 1.6395823827353857

Epoch: 6| Step: 10
Training loss: 0.08722089231014252
Validation loss: 1.6194989360788816

Epoch: 6| Step: 11
Training loss: 0.1451575756072998
Validation loss: 1.6223196073244976

Epoch: 6| Step: 12
Training loss: 0.16414831578731537
Validation loss: 1.6314064200206468

Epoch: 6| Step: 13
Training loss: 0.09311429411172867
Validation loss: 1.617710905690347

Epoch: 455| Step: 0
Training loss: 0.11509605497121811
Validation loss: 1.6066066347142702

Epoch: 6| Step: 1
Training loss: 0.12089448422193527
Validation loss: 1.5988342479992939

Epoch: 6| Step: 2
Training loss: 0.15229597687721252
Validation loss: 1.611280854030322

Epoch: 6| Step: 3
Training loss: 0.10539279878139496
Validation loss: 1.5899164061392508

Epoch: 6| Step: 4
Training loss: 0.07931452244520187
Validation loss: 1.605783857325072

Epoch: 6| Step: 5
Training loss: 0.11943680793046951
Validation loss: 1.6240843117878

Epoch: 6| Step: 6
Training loss: 0.17704887688159943
Validation loss: 1.625009673897938

Epoch: 6| Step: 7
Training loss: 0.1434558928012848
Validation loss: 1.6466195333388545

Epoch: 6| Step: 8
Training loss: 0.09157771617174149
Validation loss: 1.6508843898773193

Epoch: 6| Step: 9
Training loss: 0.354694128036499
Validation loss: 1.612869554950345

Epoch: 6| Step: 10
Training loss: 0.09530042111873627
Validation loss: 1.6197270026770971

Epoch: 6| Step: 11
Training loss: 0.18842968344688416
Validation loss: 1.6091280188611758

Epoch: 6| Step: 12
Training loss: 0.09074859321117401
Validation loss: 1.6140760849880915

Epoch: 6| Step: 13
Training loss: 0.17330771684646606
Validation loss: 1.605410848894427

Epoch: 456| Step: 0
Training loss: 0.09550189226865768
Validation loss: 1.5854584356789947

Epoch: 6| Step: 1
Training loss: 0.16701918840408325
Validation loss: 1.6104680145940473

Epoch: 6| Step: 2
Training loss: 0.11435631662607193
Validation loss: 1.6207641414416734

Epoch: 6| Step: 3
Training loss: 0.3318951725959778
Validation loss: 1.6446277467153405

Epoch: 6| Step: 4
Training loss: 0.11137302219867706
Validation loss: 1.6333401767156457

Epoch: 6| Step: 5
Training loss: 0.2285965085029602
Validation loss: 1.6195152446787844

Epoch: 6| Step: 6
Training loss: 0.12180894613265991
Validation loss: 1.6356637388147333

Epoch: 6| Step: 7
Training loss: 0.07934773713350296
Validation loss: 1.6481142620886526

Epoch: 6| Step: 8
Training loss: 0.1662532538175583
Validation loss: 1.6719991160977272

Epoch: 6| Step: 9
Training loss: 0.11937743425369263
Validation loss: 1.6987286818924772

Epoch: 6| Step: 10
Training loss: 0.1288774460554123
Validation loss: 1.7103292070409304

Epoch: 6| Step: 11
Training loss: 0.17074522376060486
Validation loss: 1.7004190106545725

Epoch: 6| Step: 12
Training loss: 0.13865962624549866
Validation loss: 1.7304258269648398

Epoch: 6| Step: 13
Training loss: 0.11298481374979019
Validation loss: 1.6717292313934655

Epoch: 457| Step: 0
Training loss: 0.11753720045089722
Validation loss: 1.6158511664277764

Epoch: 6| Step: 1
Training loss: 0.06696993112564087
Validation loss: 1.6232474747524466

Epoch: 6| Step: 2
Training loss: 0.20252814888954163
Validation loss: 1.575149348987046

Epoch: 6| Step: 3
Training loss: 0.19151371717453003
Validation loss: 1.5909454694358252

Epoch: 6| Step: 4
Training loss: 0.15179094672203064
Validation loss: 1.5847388441844652

Epoch: 6| Step: 5
Training loss: 0.16197964549064636
Validation loss: 1.5746213018253286

Epoch: 6| Step: 6
Training loss: 0.09160742163658142
Validation loss: 1.6033317427481375

Epoch: 6| Step: 7
Training loss: 0.1649295687675476
Validation loss: 1.5944269998099214

Epoch: 6| Step: 8
Training loss: 0.3218551278114319
Validation loss: 1.6756385872440953

Epoch: 6| Step: 9
Training loss: 0.14241662621498108
Validation loss: 1.7037336557142195

Epoch: 6| Step: 10
Training loss: 0.11342346668243408
Validation loss: 1.753852068736989

Epoch: 6| Step: 11
Training loss: 0.153173565864563
Validation loss: 1.7234101987654162

Epoch: 6| Step: 12
Training loss: 0.15359407663345337
Validation loss: 1.7387250802850212

Epoch: 6| Step: 13
Training loss: 0.1746162325143814
Validation loss: 1.7060839309487292

Epoch: 458| Step: 0
Training loss: 0.28851330280303955
Validation loss: 1.6628078850366736

Epoch: 6| Step: 1
Training loss: 0.15709532797336578
Validation loss: 1.6166641161005983

Epoch: 6| Step: 2
Training loss: 0.13898980617523193
Validation loss: 1.646778747599612

Epoch: 6| Step: 3
Training loss: 0.2119506299495697
Validation loss: 1.6092594682529409

Epoch: 6| Step: 4
Training loss: 0.16141757369041443
Validation loss: 1.5917549069209764

Epoch: 6| Step: 5
Training loss: 0.13210228085517883
Validation loss: 1.606602689271332

Epoch: 6| Step: 6
Training loss: 0.15527647733688354
Validation loss: 1.5935883906579786

Epoch: 6| Step: 7
Training loss: 0.0906214788556099
Validation loss: 1.622736188673204

Epoch: 6| Step: 8
Training loss: 0.1089772954583168
Validation loss: 1.6523366717882053

Epoch: 6| Step: 9
Training loss: 0.20014679431915283
Validation loss: 1.7008633613586426

Epoch: 6| Step: 10
Training loss: 0.15776926279067993
Validation loss: 1.7224455097670197

Epoch: 6| Step: 11
Training loss: 0.146061509847641
Validation loss: 1.7511213415412492

Epoch: 6| Step: 12
Training loss: 0.22733667492866516
Validation loss: 1.7758323146450905

Epoch: 6| Step: 13
Training loss: 0.6816310882568359
Validation loss: 1.7941443817589873

Epoch: 459| Step: 0
Training loss: 0.2803586423397064
Validation loss: 1.7797471220775316

Epoch: 6| Step: 1
Training loss: 0.13336050510406494
Validation loss: 1.7644387457960395

Epoch: 6| Step: 2
Training loss: 0.21382586658000946
Validation loss: 1.6925518961362942

Epoch: 6| Step: 3
Training loss: 0.12397472560405731
Validation loss: 1.7001363731199695

Epoch: 6| Step: 4
Training loss: 0.09170956909656525
Validation loss: 1.6541592004478618

Epoch: 6| Step: 5
Training loss: 0.14584387838840485
Validation loss: 1.622581131996647

Epoch: 6| Step: 6
Training loss: 0.4377761781215668
Validation loss: 1.6165661811828613

Epoch: 6| Step: 7
Training loss: 0.2026350498199463
Validation loss: 1.6122848212078054

Epoch: 6| Step: 8
Training loss: 0.1767835021018982
Validation loss: 1.597202157461515

Epoch: 6| Step: 9
Training loss: 0.21043457090854645
Validation loss: 1.5734452227110505

Epoch: 6| Step: 10
Training loss: 0.18974709510803223
Validation loss: 1.599402517400762

Epoch: 6| Step: 11
Training loss: 0.12947195768356323
Validation loss: 1.597988720863096

Epoch: 6| Step: 12
Training loss: 0.1418067365884781
Validation loss: 1.5563150759666198

Epoch: 6| Step: 13
Training loss: 0.15556499361991882
Validation loss: 1.5427772870627783

Epoch: 460| Step: 0
Training loss: 0.36439740657806396
Validation loss: 1.5850730057685607

Epoch: 6| Step: 1
Training loss: 0.07774785161018372
Validation loss: 1.607787129699543

Epoch: 6| Step: 2
Training loss: 0.14231398701667786
Validation loss: 1.6200524350648284

Epoch: 6| Step: 3
Training loss: 0.1555245816707611
Validation loss: 1.641969120630654

Epoch: 6| Step: 4
Training loss: 0.20499785244464874
Validation loss: 1.667930931173345

Epoch: 6| Step: 5
Training loss: 0.12895497679710388
Validation loss: 1.6386606500994774

Epoch: 6| Step: 6
Training loss: 0.10911966115236282
Validation loss: 1.6544297907942085

Epoch: 6| Step: 7
Training loss: 0.07757630944252014
Validation loss: 1.637589869960662

Epoch: 6| Step: 8
Training loss: 0.0934605598449707
Validation loss: 1.6540118430250434

Epoch: 6| Step: 9
Training loss: 0.07025609910488129
Validation loss: 1.6387396563765824

Epoch: 6| Step: 10
Training loss: 0.08597569912672043
Validation loss: 1.6129664926118747

Epoch: 6| Step: 11
Training loss: 0.2254847139120102
Validation loss: 1.6433918822196223

Epoch: 6| Step: 12
Training loss: 0.11338275671005249
Validation loss: 1.635449876067459

Epoch: 6| Step: 13
Training loss: 0.13146036863327026
Validation loss: 1.6475437354016047

Epoch: 461| Step: 0
Training loss: 0.08462869375944138
Validation loss: 1.6164700138953425

Epoch: 6| Step: 1
Training loss: 0.18091878294944763
Validation loss: 1.6254815914297616

Epoch: 6| Step: 2
Training loss: 0.08004661649465561
Validation loss: 1.629575934461368

Epoch: 6| Step: 3
Training loss: 0.1679513156414032
Validation loss: 1.6323971966261506

Epoch: 6| Step: 4
Training loss: 0.1679203361272812
Validation loss: 1.67125702417025

Epoch: 6| Step: 5
Training loss: 0.14719530940055847
Validation loss: 1.6788653019935853

Epoch: 6| Step: 6
Training loss: 0.20098862051963806
Validation loss: 1.6854705015818279

Epoch: 6| Step: 7
Training loss: 0.07811424881219864
Validation loss: 1.6161426433952906

Epoch: 6| Step: 8
Training loss: 0.2128516584634781
Validation loss: 1.6489599058704991

Epoch: 6| Step: 9
Training loss: 0.12031537294387817
Validation loss: 1.653785474838749

Epoch: 6| Step: 10
Training loss: 0.08584241569042206
Validation loss: 1.614749538642104

Epoch: 6| Step: 11
Training loss: 0.16010504961013794
Validation loss: 1.626552927878595

Epoch: 6| Step: 12
Training loss: 0.3608093857765198
Validation loss: 1.5900908490662933

Epoch: 6| Step: 13
Training loss: 0.137388676404953
Validation loss: 1.5776813260970577

Epoch: 462| Step: 0
Training loss: 0.14815625548362732
Validation loss: 1.5895923773447673

Epoch: 6| Step: 1
Training loss: 0.33676472306251526
Validation loss: 1.5879901698840562

Epoch: 6| Step: 2
Training loss: 0.10924921184778214
Validation loss: 1.5927527771201184

Epoch: 6| Step: 3
Training loss: 0.17782163619995117
Validation loss: 1.5600524897216468

Epoch: 6| Step: 4
Training loss: 0.13007739186286926
Validation loss: 1.589581936918279

Epoch: 6| Step: 5
Training loss: 0.08280839771032333
Validation loss: 1.672481870138517

Epoch: 6| Step: 6
Training loss: 0.14811024069786072
Validation loss: 1.6857365510796989

Epoch: 6| Step: 7
Training loss: 0.1501833200454712
Validation loss: 1.6387743988344747

Epoch: 6| Step: 8
Training loss: 0.10826919227838516
Validation loss: 1.6578551928202312

Epoch: 6| Step: 9
Training loss: 0.1046472117304802
Validation loss: 1.6917794391673098

Epoch: 6| Step: 10
Training loss: 0.08637087792158127
Validation loss: 1.6440412088107037

Epoch: 6| Step: 11
Training loss: 0.1579110473394394
Validation loss: 1.6763570154866865

Epoch: 6| Step: 12
Training loss: 0.13824962079524994
Validation loss: 1.7144704082960724

Epoch: 6| Step: 13
Training loss: 0.07106640934944153
Validation loss: 1.6728878867241643

Epoch: 463| Step: 0
Training loss: 0.11350581049919128
Validation loss: 1.7310453499517133

Epoch: 6| Step: 1
Training loss: 0.16724495589733124
Validation loss: 1.7151383994728007

Epoch: 6| Step: 2
Training loss: 0.08594100922346115
Validation loss: 1.7041958326934485

Epoch: 6| Step: 3
Training loss: 0.134800523519516
Validation loss: 1.6960102819627332

Epoch: 6| Step: 4
Training loss: 0.09269756078720093
Validation loss: 1.6710971568220405

Epoch: 6| Step: 5
Training loss: 0.13482283055782318
Validation loss: 1.6773813642481321

Epoch: 6| Step: 6
Training loss: 0.11253416538238525
Validation loss: 1.6592643978775188

Epoch: 6| Step: 7
Training loss: 0.10251104831695557
Validation loss: 1.6525111288152716

Epoch: 6| Step: 8
Training loss: 0.24756406247615814
Validation loss: 1.634674713175784

Epoch: 6| Step: 9
Training loss: 0.37910372018814087
Validation loss: 1.6131790786661127

Epoch: 6| Step: 10
Training loss: 0.09162412583827972
Validation loss: 1.6020953219424012

Epoch: 6| Step: 11
Training loss: 0.10427326709032059
Validation loss: 1.6378948316779187

Epoch: 6| Step: 12
Training loss: 0.10428016632795334
Validation loss: 1.5906991061343942

Epoch: 6| Step: 13
Training loss: 0.17530584335327148
Validation loss: 1.6548566164508942

Epoch: 464| Step: 0
Training loss: 0.09178150445222855
Validation loss: 1.611725091934204

Epoch: 6| Step: 1
Training loss: 0.1573578119277954
Validation loss: 1.6042247408179826

Epoch: 6| Step: 2
Training loss: 0.09829148650169373
Validation loss: 1.6334158143689554

Epoch: 6| Step: 3
Training loss: 0.19636768102645874
Validation loss: 1.6684072017669678

Epoch: 6| Step: 4
Training loss: 0.20470647513866425
Validation loss: 1.646874802086943

Epoch: 6| Step: 5
Training loss: 0.10996104031801224
Validation loss: 1.6567572342452181

Epoch: 6| Step: 6
Training loss: 0.14524894952774048
Validation loss: 1.6496987112106816

Epoch: 6| Step: 7
Training loss: 0.11400242149829865
Validation loss: 1.6267971300309705

Epoch: 6| Step: 8
Training loss: 0.05520636588335037
Validation loss: 1.6354829419043757

Epoch: 6| Step: 9
Training loss: 0.1243671178817749
Validation loss: 1.622292241742534

Epoch: 6| Step: 10
Training loss: 0.11237689107656479
Validation loss: 1.6218995573700115

Epoch: 6| Step: 11
Training loss: 0.07039675116539001
Validation loss: 1.6374689596955494

Epoch: 6| Step: 12
Training loss: 0.3593299090862274
Validation loss: 1.6278483790736045

Epoch: 6| Step: 13
Training loss: 0.2611878216266632
Validation loss: 1.6522664446984567

Epoch: 465| Step: 0
Training loss: 0.12336073815822601
Validation loss: 1.6174092062057988

Epoch: 6| Step: 1
Training loss: 0.10996885597705841
Validation loss: 1.6403049128029936

Epoch: 6| Step: 2
Training loss: 0.0940924882888794
Validation loss: 1.6445724797505203

Epoch: 6| Step: 3
Training loss: 0.3341180086135864
Validation loss: 1.6159541497948349

Epoch: 6| Step: 4
Training loss: 0.1305077075958252
Validation loss: 1.6179783844178723

Epoch: 6| Step: 5
Training loss: 0.10979413986206055
Validation loss: 1.6016905064223914

Epoch: 6| Step: 6
Training loss: 0.10963623225688934
Validation loss: 1.6331852994939333

Epoch: 6| Step: 7
Training loss: 0.10341096669435501
Validation loss: 1.6469188351784982

Epoch: 6| Step: 8
Training loss: 0.09884624928236008
Validation loss: 1.6367957976556593

Epoch: 6| Step: 9
Training loss: 0.061862267553806305
Validation loss: 1.6024280440422796

Epoch: 6| Step: 10
Training loss: 0.15519292652606964
Validation loss: 1.6656733546205746

Epoch: 6| Step: 11
Training loss: 0.181129589676857
Validation loss: 1.6358903005558958

Epoch: 6| Step: 12
Training loss: 0.12432781606912613
Validation loss: 1.6559057351081603

Epoch: 6| Step: 13
Training loss: 0.2322896271944046
Validation loss: 1.6839763618284656

Epoch: 466| Step: 0
Training loss: 0.12800391018390656
Validation loss: 1.6942558942302581

Epoch: 6| Step: 1
Training loss: 0.22784340381622314
Validation loss: 1.7037471289275794

Epoch: 6| Step: 2
Training loss: 0.1588802933692932
Validation loss: 1.6430747355184248

Epoch: 6| Step: 3
Training loss: 0.10041181743144989
Validation loss: 1.636254395208051

Epoch: 6| Step: 4
Training loss: 0.12913504242897034
Validation loss: 1.613667102270229

Epoch: 6| Step: 5
Training loss: 0.15680049359798431
Validation loss: 1.6189556685827111

Epoch: 6| Step: 6
Training loss: 0.10185833275318146
Validation loss: 1.5817959013805594

Epoch: 6| Step: 7
Training loss: 0.3497757911682129
Validation loss: 1.5768768992475284

Epoch: 6| Step: 8
Training loss: 0.20738013088703156
Validation loss: 1.5759142650071012

Epoch: 6| Step: 9
Training loss: 0.16804322600364685
Validation loss: 1.5949403380834928

Epoch: 6| Step: 10
Training loss: 0.14179174602031708
Validation loss: 1.5731887035472418

Epoch: 6| Step: 11
Training loss: 0.19079095125198364
Validation loss: 1.5909225299794187

Epoch: 6| Step: 12
Training loss: 0.1640249341726303
Validation loss: 1.6210325315434446

Epoch: 6| Step: 13
Training loss: 0.0973268449306488
Validation loss: 1.6078935015586115

Epoch: 467| Step: 0
Training loss: 0.15966878831386566
Validation loss: 1.631745389712754

Epoch: 6| Step: 1
Training loss: 0.15620312094688416
Validation loss: 1.6386246501758535

Epoch: 6| Step: 2
Training loss: 0.16075745224952698
Validation loss: 1.6713845781100694

Epoch: 6| Step: 3
Training loss: 0.12388011068105698
Validation loss: 1.6704757598138624

Epoch: 6| Step: 4
Training loss: 0.16161200404167175
Validation loss: 1.6682679627531318

Epoch: 6| Step: 5
Training loss: 0.10343734920024872
Validation loss: 1.664392864832314

Epoch: 6| Step: 6
Training loss: 0.11100643873214722
Validation loss: 1.654975433503428

Epoch: 6| Step: 7
Training loss: 0.08991190791130066
Validation loss: 1.6297124444797475

Epoch: 6| Step: 8
Training loss: 0.3491398096084595
Validation loss: 1.5955475171407063

Epoch: 6| Step: 9
Training loss: 0.10450588166713715
Validation loss: 1.5889167016552341

Epoch: 6| Step: 10
Training loss: 0.2773597240447998
Validation loss: 1.612608709642964

Epoch: 6| Step: 11
Training loss: 0.13699063658714294
Validation loss: 1.6228704349969023

Epoch: 6| Step: 12
Training loss: 0.1248769760131836
Validation loss: 1.6095730630300378

Epoch: 6| Step: 13
Training loss: 0.09224192798137665
Validation loss: 1.6223896165047922

Epoch: 468| Step: 0
Training loss: 0.10231655836105347
Validation loss: 1.6369467307162542

Epoch: 6| Step: 1
Training loss: 0.24906393885612488
Validation loss: 1.6159822376825477

Epoch: 6| Step: 2
Training loss: 0.1171497330069542
Validation loss: 1.63967639400113

Epoch: 6| Step: 3
Training loss: 0.14275558292865753
Validation loss: 1.6639294214146112

Epoch: 6| Step: 4
Training loss: 0.11142998933792114
Validation loss: 1.6711060231731785

Epoch: 6| Step: 5
Training loss: 0.17291685938835144
Validation loss: 1.6542637245629424

Epoch: 6| Step: 6
Training loss: 0.10606545954942703
Validation loss: 1.654758777669681

Epoch: 6| Step: 7
Training loss: 0.12890566885471344
Validation loss: 1.7009598311557566

Epoch: 6| Step: 8
Training loss: 0.14744266867637634
Validation loss: 1.7360665875096475

Epoch: 6| Step: 9
Training loss: 0.3353790044784546
Validation loss: 1.7743698909718504

Epoch: 6| Step: 10
Training loss: 0.0884832888841629
Validation loss: 1.7763628293109197

Epoch: 6| Step: 11
Training loss: 0.16131070256233215
Validation loss: 1.7773440794278217

Epoch: 6| Step: 12
Training loss: 0.1115090548992157
Validation loss: 1.7190098749694003

Epoch: 6| Step: 13
Training loss: 0.19687050580978394
Validation loss: 1.6705563965664114

Epoch: 469| Step: 0
Training loss: 0.19116654992103577
Validation loss: 1.6171057147364463

Epoch: 6| Step: 1
Training loss: 0.13737207651138306
Validation loss: 1.6136525292550363

Epoch: 6| Step: 2
Training loss: 0.08407849073410034
Validation loss: 1.5862001539558492

Epoch: 6| Step: 3
Training loss: 0.16188907623291016
Validation loss: 1.58308930038124

Epoch: 6| Step: 4
Training loss: 0.09424993395805359
Validation loss: 1.5641659754578785

Epoch: 6| Step: 5
Training loss: 0.41093653440475464
Validation loss: 1.5282679283490745

Epoch: 6| Step: 6
Training loss: 0.1007428914308548
Validation loss: 1.5510840108317714

Epoch: 6| Step: 7
Training loss: 0.18777087330818176
Validation loss: 1.5797508160273235

Epoch: 6| Step: 8
Training loss: 0.17860329151153564
Validation loss: 1.5779674732556908

Epoch: 6| Step: 9
Training loss: 0.14150241017341614
Validation loss: 1.5669799979015062

Epoch: 6| Step: 10
Training loss: 0.13296642899513245
Validation loss: 1.6058870759061588

Epoch: 6| Step: 11
Training loss: 0.10392377525568008
Validation loss: 1.6333096437556769

Epoch: 6| Step: 12
Training loss: 0.09341418743133545
Validation loss: 1.6391008618057414

Epoch: 6| Step: 13
Training loss: 0.10097106546163559
Validation loss: 1.6352696091898027

Epoch: 470| Step: 0
Training loss: 0.3689589500427246
Validation loss: 1.626347190590315

Epoch: 6| Step: 1
Training loss: 0.13104300200939178
Validation loss: 1.609447095983772

Epoch: 6| Step: 2
Training loss: 0.18986324965953827
Validation loss: 1.6683445515171174

Epoch: 6| Step: 3
Training loss: 0.16260091960430145
Validation loss: 1.665285143800961

Epoch: 6| Step: 4
Training loss: 0.1817362904548645
Validation loss: 1.6576040252562492

Epoch: 6| Step: 5
Training loss: 0.07026791572570801
Validation loss: 1.6479999249981296

Epoch: 6| Step: 6
Training loss: 0.15778294205665588
Validation loss: 1.6434774296258086

Epoch: 6| Step: 7
Training loss: 0.14785660803318024
Validation loss: 1.6728992180157733

Epoch: 6| Step: 8
Training loss: 0.10929849743843079
Validation loss: 1.6966906055327384

Epoch: 6| Step: 9
Training loss: 0.12076880782842636
Validation loss: 1.6748287613673876

Epoch: 6| Step: 10
Training loss: 0.11870744824409485
Validation loss: 1.7125317332565144

Epoch: 6| Step: 11
Training loss: 0.13326382637023926
Validation loss: 1.7207297227715934

Epoch: 6| Step: 12
Training loss: 0.14208775758743286
Validation loss: 1.68129139689989

Epoch: 6| Step: 13
Training loss: 0.07769102603197098
Validation loss: 1.6754160491369103

Epoch: 471| Step: 0
Training loss: 0.15174055099487305
Validation loss: 1.652252681793705

Epoch: 6| Step: 1
Training loss: 0.3033533990383148
Validation loss: 1.603178099919391

Epoch: 6| Step: 2
Training loss: 0.12082195281982422
Validation loss: 1.5879261519319268

Epoch: 6| Step: 3
Training loss: 0.13249853253364563
Validation loss: 1.5740618692931307

Epoch: 6| Step: 4
Training loss: 0.2392168939113617
Validation loss: 1.5860094908745057

Epoch: 6| Step: 5
Training loss: 0.13974140584468842
Validation loss: 1.5534369958344327

Epoch: 6| Step: 6
Training loss: 0.1587435007095337
Validation loss: 1.5426651841850691

Epoch: 6| Step: 7
Training loss: 0.2634941637516022
Validation loss: 1.5446627665591497

Epoch: 6| Step: 8
Training loss: 0.125046968460083
Validation loss: 1.5262240568796794

Epoch: 6| Step: 9
Training loss: 0.16800662875175476
Validation loss: 1.5698609903294554

Epoch: 6| Step: 10
Training loss: 0.17554664611816406
Validation loss: 1.5991244521192325

Epoch: 6| Step: 11
Training loss: 0.09694018214941025
Validation loss: 1.6432721255927958

Epoch: 6| Step: 12
Training loss: 0.15098685026168823
Validation loss: 1.7097552271299465

Epoch: 6| Step: 13
Training loss: 0.1608792096376419
Validation loss: 1.738469648104842

Epoch: 472| Step: 0
Training loss: 0.3300527334213257
Validation loss: 1.7669979205695532

Epoch: 6| Step: 1
Training loss: 0.15224063396453857
Validation loss: 1.7312785335766372

Epoch: 6| Step: 2
Training loss: 0.33055049180984497
Validation loss: 1.6931947687620759

Epoch: 6| Step: 3
Training loss: 0.07974462956190109
Validation loss: 1.6508252300241941

Epoch: 6| Step: 4
Training loss: 0.11702923476696014
Validation loss: 1.6496978523910686

Epoch: 6| Step: 5
Training loss: 0.20590044558048248
Validation loss: 1.6262979404900664

Epoch: 6| Step: 6
Training loss: 0.22427131235599518
Validation loss: 1.5992357833411104

Epoch: 6| Step: 7
Training loss: 0.1273484081029892
Validation loss: 1.5765429619819886

Epoch: 6| Step: 8
Training loss: 0.19860634207725525
Validation loss: 1.5793578022269792

Epoch: 6| Step: 9
Training loss: 0.09912364184856415
Validation loss: 1.5858953358024679

Epoch: 6| Step: 10
Training loss: 0.16548189520835876
Validation loss: 1.5685112373803252

Epoch: 6| Step: 11
Training loss: 0.10115329921245575
Validation loss: 1.6051663480779177

Epoch: 6| Step: 12
Training loss: 0.14551502466201782
Validation loss: 1.593462723557667

Epoch: 6| Step: 13
Training loss: 0.08752094209194183
Validation loss: 1.612956778977507

Epoch: 473| Step: 0
Training loss: 0.10435502231121063
Validation loss: 1.6068616285119006

Epoch: 6| Step: 1
Training loss: 0.06880304962396622
Validation loss: 1.634138153445336

Epoch: 6| Step: 2
Training loss: 0.11560435593128204
Validation loss: 1.6065956225959204

Epoch: 6| Step: 3
Training loss: 0.10182753205299377
Validation loss: 1.6032847704425934

Epoch: 6| Step: 4
Training loss: 0.1420307457447052
Validation loss: 1.5980200998244747

Epoch: 6| Step: 5
Training loss: 0.07080809772014618
Validation loss: 1.6257330166396273

Epoch: 6| Step: 6
Training loss: 0.10156406462192535
Validation loss: 1.629456199625487

Epoch: 6| Step: 7
Training loss: 0.12311446666717529
Validation loss: 1.6731153585577523

Epoch: 6| Step: 8
Training loss: 0.09534551203250885
Validation loss: 1.662787728412177

Epoch: 6| Step: 9
Training loss: 0.17628152668476105
Validation loss: 1.6795692469484063

Epoch: 6| Step: 10
Training loss: 0.14577749371528625
Validation loss: 1.6872363808334514

Epoch: 6| Step: 11
Training loss: 0.08832340687513351
Validation loss: 1.711601241942375

Epoch: 6| Step: 12
Training loss: 0.3359929025173187
Validation loss: 1.704437868569487

Epoch: 6| Step: 13
Training loss: 0.15027891099452972
Validation loss: 1.7257847298857987

Epoch: 474| Step: 0
Training loss: 0.2561184763908386
Validation loss: 1.7258183122963033

Epoch: 6| Step: 1
Training loss: 0.1609479784965515
Validation loss: 1.65965102564904

Epoch: 6| Step: 2
Training loss: 0.15421997010707855
Validation loss: 1.670063139289938

Epoch: 6| Step: 3
Training loss: 0.367430180311203
Validation loss: 1.623256883313579

Epoch: 6| Step: 4
Training loss: 0.09177270531654358
Validation loss: 1.6084972953283658

Epoch: 6| Step: 5
Training loss: 0.12401971220970154
Validation loss: 1.5716968210794593

Epoch: 6| Step: 6
Training loss: 0.14766675233840942
Validation loss: 1.5653957205434

Epoch: 6| Step: 7
Training loss: 0.1267905831336975
Validation loss: 1.5460894492364698

Epoch: 6| Step: 8
Training loss: 0.13861975073814392
Validation loss: 1.528730023291803

Epoch: 6| Step: 9
Training loss: 0.13478994369506836
Validation loss: 1.5494137066666798

Epoch: 6| Step: 10
Training loss: 0.1244884729385376
Validation loss: 1.5736304995834187

Epoch: 6| Step: 11
Training loss: 0.15110909938812256
Validation loss: 1.562477914235925

Epoch: 6| Step: 12
Training loss: 0.22341015934944153
Validation loss: 1.5948645120025964

Epoch: 6| Step: 13
Training loss: 0.08547186851501465
Validation loss: 1.6384741644705496

Epoch: 475| Step: 0
Training loss: 0.21647882461547852
Validation loss: 1.6274834076563518

Epoch: 6| Step: 1
Training loss: 0.07637999951839447
Validation loss: 1.6777794412387315

Epoch: 6| Step: 2
Training loss: 0.16548463702201843
Validation loss: 1.7130701618809854

Epoch: 6| Step: 3
Training loss: 0.17468273639678955
Validation loss: 1.7205463481205765

Epoch: 6| Step: 4
Training loss: 0.1517312228679657
Validation loss: 1.7113722838381284

Epoch: 6| Step: 5
Training loss: 0.16167107224464417
Validation loss: 1.7137546359851796

Epoch: 6| Step: 6
Training loss: 0.3765118718147278
Validation loss: 1.6800228100951

Epoch: 6| Step: 7
Training loss: 0.10940148681402206
Validation loss: 1.6557890215227682

Epoch: 6| Step: 8
Training loss: 0.15324777364730835
Validation loss: 1.5990446902090503

Epoch: 6| Step: 9
Training loss: 0.19306521117687225
Validation loss: 1.5699476913739276

Epoch: 6| Step: 10
Training loss: 0.14692050218582153
Validation loss: 1.5652335869368685

Epoch: 6| Step: 11
Training loss: 0.12157382071018219
Validation loss: 1.5559786647878668

Epoch: 6| Step: 12
Training loss: 0.2622087597846985
Validation loss: 1.5710031012053132

Epoch: 6| Step: 13
Training loss: 0.11399474740028381
Validation loss: 1.5531415054875035

Epoch: 476| Step: 0
Training loss: 0.17144210636615753
Validation loss: 1.5780175526936848

Epoch: 6| Step: 1
Training loss: 0.15601001679897308
Validation loss: 1.5657447256067747

Epoch: 6| Step: 2
Training loss: 0.1503441333770752
Validation loss: 1.5736311610027025

Epoch: 6| Step: 3
Training loss: 0.09481243789196014
Validation loss: 1.5845256928474671

Epoch: 6| Step: 4
Training loss: 0.29722917079925537
Validation loss: 1.6178941585684334

Epoch: 6| Step: 5
Training loss: 0.1853344440460205
Validation loss: 1.6890823148912

Epoch: 6| Step: 6
Training loss: 0.10071280598640442
Validation loss: 1.7101837858077018

Epoch: 6| Step: 7
Training loss: 0.16494937241077423
Validation loss: 1.7480519330629738

Epoch: 6| Step: 8
Training loss: 0.15486028790473938
Validation loss: 1.737048787455405

Epoch: 6| Step: 9
Training loss: 0.10999781638383865
Validation loss: 1.7131276797222834

Epoch: 6| Step: 10
Training loss: 0.2769728899002075
Validation loss: 1.692233540678537

Epoch: 6| Step: 11
Training loss: 0.07679717242717743
Validation loss: 1.6568257603594052

Epoch: 6| Step: 12
Training loss: 0.15760089457035065
Validation loss: 1.6357651833565003

Epoch: 6| Step: 13
Training loss: 0.11202478408813477
Validation loss: 1.6059200866248018

Epoch: 477| Step: 0
Training loss: 0.11745984107255936
Validation loss: 1.581115061236966

Epoch: 6| Step: 1
Training loss: 0.3632064759731293
Validation loss: 1.5843022061932472

Epoch: 6| Step: 2
Training loss: 0.1598246693611145
Validation loss: 1.5825635681870163

Epoch: 6| Step: 3
Training loss: 0.14909997582435608
Validation loss: 1.5590693348197526

Epoch: 6| Step: 4
Training loss: 0.14505445957183838
Validation loss: 1.56254965900093

Epoch: 6| Step: 5
Training loss: 0.09372922778129578
Validation loss: 1.5422226857113581

Epoch: 6| Step: 6
Training loss: 0.13859879970550537
Validation loss: 1.5663203654750701

Epoch: 6| Step: 7
Training loss: 0.10598894208669662
Validation loss: 1.6024334135875906

Epoch: 6| Step: 8
Training loss: 0.1280757188796997
Validation loss: 1.5921126527170981

Epoch: 6| Step: 9
Training loss: 0.1644401252269745
Validation loss: 1.6336596473570792

Epoch: 6| Step: 10
Training loss: 0.15271970629692078
Validation loss: 1.6529887126338096

Epoch: 6| Step: 11
Training loss: 0.14409145712852478
Validation loss: 1.6504948722418917

Epoch: 6| Step: 12
Training loss: 0.09883752465248108
Validation loss: 1.6348644623192408

Epoch: 6| Step: 13
Training loss: 0.1084953099489212
Validation loss: 1.652863407647738

Epoch: 478| Step: 0
Training loss: 0.09308628737926483
Validation loss: 1.6035713252200876

Epoch: 6| Step: 1
Training loss: 0.08261079341173172
Validation loss: 1.6332535525803924

Epoch: 6| Step: 2
Training loss: 0.0979229062795639
Validation loss: 1.6524618966605074

Epoch: 6| Step: 3
Training loss: 0.07767197489738464
Validation loss: 1.637968574800799

Epoch: 6| Step: 4
Training loss: 0.14874966442584991
Validation loss: 1.6523986106277795

Epoch: 6| Step: 5
Training loss: 0.1390381157398224
Validation loss: 1.669123347087573

Epoch: 6| Step: 6
Training loss: 0.1406114101409912
Validation loss: 1.6490358075787943

Epoch: 6| Step: 7
Training loss: 0.11298097670078278
Validation loss: 1.6580767170075448

Epoch: 6| Step: 8
Training loss: 0.3336450159549713
Validation loss: 1.6473766603777487

Epoch: 6| Step: 9
Training loss: 0.14924362301826477
Validation loss: 1.6580125516460789

Epoch: 6| Step: 10
Training loss: 0.10868602991104126
Validation loss: 1.6616769272794005

Epoch: 6| Step: 11
Training loss: 0.12066096812486649
Validation loss: 1.6395358218941638

Epoch: 6| Step: 12
Training loss: 0.07669530808925629
Validation loss: 1.6074338177199006

Epoch: 6| Step: 13
Training loss: 0.26727741956710815
Validation loss: 1.5915973853039485

Epoch: 479| Step: 0
Training loss: 0.14264757931232452
Validation loss: 1.621150255203247

Epoch: 6| Step: 1
Training loss: 0.1414504498243332
Validation loss: 1.6105792368611982

Epoch: 6| Step: 2
Training loss: 0.2006007730960846
Validation loss: 1.6543699310671898

Epoch: 6| Step: 3
Training loss: 0.09951399266719818
Validation loss: 1.6328648610781598

Epoch: 6| Step: 4
Training loss: 0.13463690876960754
Validation loss: 1.611920073468198

Epoch: 6| Step: 5
Training loss: 0.12408167123794556
Validation loss: 1.6201020543293287

Epoch: 6| Step: 6
Training loss: 0.11384746432304382
Validation loss: 1.6128660363535727

Epoch: 6| Step: 7
Training loss: 0.13059842586517334
Validation loss: 1.605675083334728

Epoch: 6| Step: 8
Training loss: 0.08166185021400452
Validation loss: 1.5995212319076701

Epoch: 6| Step: 9
Training loss: 0.06559859216213226
Validation loss: 1.5790581908277286

Epoch: 6| Step: 10
Training loss: 0.1752522885799408
Validation loss: 1.5788808215049006

Epoch: 6| Step: 11
Training loss: 0.10272616147994995
Validation loss: 1.578623575548972

Epoch: 6| Step: 12
Training loss: 0.30951911211013794
Validation loss: 1.583057665055798

Epoch: 6| Step: 13
Training loss: 0.12744462490081787
Validation loss: 1.593165929599475

Epoch: 480| Step: 0
Training loss: 0.12491191923618317
Validation loss: 1.5830714958970264

Epoch: 6| Step: 1
Training loss: 0.0977911427617073
Validation loss: 1.6185834561624834

Epoch: 6| Step: 2
Training loss: 0.11560394614934921
Validation loss: 1.6076219383106436

Epoch: 6| Step: 3
Training loss: 0.15625284612178802
Validation loss: 1.5940122155733005

Epoch: 6| Step: 4
Training loss: 0.09622315317392349
Validation loss: 1.5780579531064598

Epoch: 6| Step: 5
Training loss: 0.11301454901695251
Validation loss: 1.6131130854288738

Epoch: 6| Step: 6
Training loss: 0.12132152169942856
Validation loss: 1.6094615959352063

Epoch: 6| Step: 7
Training loss: 0.3957119584083557
Validation loss: 1.6165268126354422

Epoch: 6| Step: 8
Training loss: 0.08651423454284668
Validation loss: 1.6157081114348544

Epoch: 6| Step: 9
Training loss: 0.17859795689582825
Validation loss: 1.5987197122266215

Epoch: 6| Step: 10
Training loss: 0.09244221448898315
Validation loss: 1.587108628724211

Epoch: 6| Step: 11
Training loss: 0.11216123402118683
Validation loss: 1.6059854927883352

Epoch: 6| Step: 12
Training loss: 0.09654439985752106
Validation loss: 1.6320038380161408

Epoch: 6| Step: 13
Training loss: 0.13020335137844086
Validation loss: 1.5872216160579393

Epoch: 481| Step: 0
Training loss: 0.1827114373445511
Validation loss: 1.6074666720564648

Epoch: 6| Step: 1
Training loss: 0.15346649289131165
Validation loss: 1.621811007940641

Epoch: 6| Step: 2
Training loss: 0.10944326221942902
Validation loss: 1.6155624466557656

Epoch: 6| Step: 3
Training loss: 0.06386072188615799
Validation loss: 1.6339053274482809

Epoch: 6| Step: 4
Training loss: 0.13417688012123108
Validation loss: 1.6699069981933923

Epoch: 6| Step: 5
Training loss: 0.11950311064720154
Validation loss: 1.6264666741894138

Epoch: 6| Step: 6
Training loss: 0.11546574532985687
Validation loss: 1.6304917143237205

Epoch: 6| Step: 7
Training loss: 0.07425035536289215
Validation loss: 1.662128948396252

Epoch: 6| Step: 8
Training loss: 0.08995909988880157
Validation loss: 1.6054362904640935

Epoch: 6| Step: 9
Training loss: 0.08912280201911926
Validation loss: 1.5987473367362894

Epoch: 6| Step: 10
Training loss: 0.1522100865840912
Validation loss: 1.5842285412614063

Epoch: 6| Step: 11
Training loss: 0.12449038028717041
Validation loss: 1.5867855330949188

Epoch: 6| Step: 12
Training loss: 0.34175074100494385
Validation loss: 1.5924396335437734

Epoch: 6| Step: 13
Training loss: 0.11235896497964859
Validation loss: 1.55925376056343

Epoch: 482| Step: 0
Training loss: 0.07632870227098465
Validation loss: 1.5437063222290368

Epoch: 6| Step: 1
Training loss: 0.07913326472043991
Validation loss: 1.550422619106949

Epoch: 6| Step: 2
Training loss: 0.1430160254240036
Validation loss: 1.520044829255791

Epoch: 6| Step: 3
Training loss: 0.155445396900177
Validation loss: 1.554064449443612

Epoch: 6| Step: 4
Training loss: 0.15930670499801636
Validation loss: 1.5685574316209363

Epoch: 6| Step: 5
Training loss: 0.06916064023971558
Validation loss: 1.6114569863965433

Epoch: 6| Step: 6
Training loss: 0.14786329865455627
Validation loss: 1.645736816749778

Epoch: 6| Step: 7
Training loss: 0.19790014624595642
Validation loss: 1.641823055923626

Epoch: 6| Step: 8
Training loss: 0.34342360496520996
Validation loss: 1.6361597635412728

Epoch: 6| Step: 9
Training loss: 0.16122949123382568
Validation loss: 1.6323298036411245

Epoch: 6| Step: 10
Training loss: 0.08698716014623642
Validation loss: 1.6044620865134782

Epoch: 6| Step: 11
Training loss: 0.08584612607955933
Validation loss: 1.6079674228545158

Epoch: 6| Step: 12
Training loss: 0.11526443064212799
Validation loss: 1.5869903487543906

Epoch: 6| Step: 13
Training loss: 0.1194227784872055
Validation loss: 1.6170184971183859

Epoch: 483| Step: 0
Training loss: 0.1487826108932495
Validation loss: 1.5949174460544382

Epoch: 6| Step: 1
Training loss: 0.12145765870809555
Validation loss: 1.592255151400002

Epoch: 6| Step: 2
Training loss: 0.4453408420085907
Validation loss: 1.5812337116528583

Epoch: 6| Step: 3
Training loss: 0.1057301014661789
Validation loss: 1.6054105194666053

Epoch: 6| Step: 4
Training loss: 0.13341554999351501
Validation loss: 1.6252066499443465

Epoch: 6| Step: 5
Training loss: 0.0718279555439949
Validation loss: 1.6108402821325487

Epoch: 6| Step: 6
Training loss: 0.12087377905845642
Validation loss: 1.624160292328045

Epoch: 6| Step: 7
Training loss: 0.07731268554925919
Validation loss: 1.6179412552105483

Epoch: 6| Step: 8
Training loss: 0.0659916028380394
Validation loss: 1.6488113736593595

Epoch: 6| Step: 9
Training loss: 0.1047302857041359
Validation loss: 1.6490373444813553

Epoch: 6| Step: 10
Training loss: 0.22517506778240204
Validation loss: 1.6754612730395408

Epoch: 6| Step: 11
Training loss: 0.188490629196167
Validation loss: 1.6872045122167116

Epoch: 6| Step: 12
Training loss: 0.11931079626083374
Validation loss: 1.6470576652916529

Epoch: 6| Step: 13
Training loss: 0.16972750425338745
Validation loss: 1.6340127196363223

Epoch: 484| Step: 0
Training loss: 0.14874807000160217
Validation loss: 1.6292869839617001

Epoch: 6| Step: 1
Training loss: 0.09825493395328522
Validation loss: 1.5958543439065256

Epoch: 6| Step: 2
Training loss: 0.11738277971744537
Validation loss: 1.611464693982114

Epoch: 6| Step: 3
Training loss: 0.17320194840431213
Validation loss: 1.5712611623989639

Epoch: 6| Step: 4
Training loss: 0.11415697634220123
Validation loss: 1.5890382964123961

Epoch: 6| Step: 5
Training loss: 0.13404199481010437
Validation loss: 1.5589570332598943

Epoch: 6| Step: 6
Training loss: 0.15822052955627441
Validation loss: 1.5928381463532806

Epoch: 6| Step: 7
Training loss: 0.1152300164103508
Validation loss: 1.594001095782044

Epoch: 6| Step: 8
Training loss: 0.10971103608608246
Validation loss: 1.6240354122654084

Epoch: 6| Step: 9
Training loss: 0.1539638191461563
Validation loss: 1.6308786471684773

Epoch: 6| Step: 10
Training loss: 0.3792039453983307
Validation loss: 1.6042843762264456

Epoch: 6| Step: 11
Training loss: 0.11033900827169418
Validation loss: 1.6183439531633932

Epoch: 6| Step: 12
Training loss: 0.13740085065364838
Validation loss: 1.6054313951923

Epoch: 6| Step: 13
Training loss: 0.13432441651821136
Validation loss: 1.606796908122237

Epoch: 485| Step: 0
Training loss: 0.11846344918012619
Validation loss: 1.607856995315962

Epoch: 6| Step: 1
Training loss: 0.17746354639530182
Validation loss: 1.6402747502890966

Epoch: 6| Step: 2
Training loss: 0.08441942930221558
Validation loss: 1.6438014135565808

Epoch: 6| Step: 3
Training loss: 0.1178973913192749
Validation loss: 1.6403378568669802

Epoch: 6| Step: 4
Training loss: 0.15215344727039337
Validation loss: 1.6507371241046536

Epoch: 6| Step: 5
Training loss: 0.12260635197162628
Validation loss: 1.6196432562284573

Epoch: 6| Step: 6
Training loss: 0.08642694354057312
Validation loss: 1.6583123437819942

Epoch: 6| Step: 7
Training loss: 0.48047277331352234
Validation loss: 1.6397489668220602

Epoch: 6| Step: 8
Training loss: 0.08692724257707596
Validation loss: 1.6464353915183776

Epoch: 6| Step: 9
Training loss: 0.10932721942663193
Validation loss: 1.6205195419249996

Epoch: 6| Step: 10
Training loss: 0.1189887598156929
Validation loss: 1.6040155746603524

Epoch: 6| Step: 11
Training loss: 0.10463681071996689
Validation loss: 1.571528350153277

Epoch: 6| Step: 12
Training loss: 0.07760877907276154
Validation loss: 1.5701632691967873

Epoch: 6| Step: 13
Training loss: 0.13809192180633545
Validation loss: 1.5923297853880032

Epoch: 486| Step: 0
Training loss: 0.09305200725793839
Validation loss: 1.5808800945999801

Epoch: 6| Step: 1
Training loss: 0.11836405843496323
Validation loss: 1.568739475742463

Epoch: 6| Step: 2
Training loss: 0.08781635761260986
Validation loss: 1.5597512875833819

Epoch: 6| Step: 3
Training loss: 0.10212583839893341
Validation loss: 1.5309971071058703

Epoch: 6| Step: 4
Training loss: 0.13106831908226013
Validation loss: 1.567251810463526

Epoch: 6| Step: 5
Training loss: 0.11118648946285248
Validation loss: 1.5205578381015408

Epoch: 6| Step: 6
Training loss: 0.08448927104473114
Validation loss: 1.5393770253786476

Epoch: 6| Step: 7
Training loss: 0.3557397723197937
Validation loss: 1.5418864091237385

Epoch: 6| Step: 8
Training loss: 0.1603335440158844
Validation loss: 1.5523534103106427

Epoch: 6| Step: 9
Training loss: 0.06028745323419571
Validation loss: 1.6005109087113412

Epoch: 6| Step: 10
Training loss: 0.21739554405212402
Validation loss: 1.5953534303172943

Epoch: 6| Step: 11
Training loss: 0.080078125
Validation loss: 1.5953009577207669

Epoch: 6| Step: 12
Training loss: 0.21983054280281067
Validation loss: 1.6474572817484539

Epoch: 6| Step: 13
Training loss: 0.051439907401800156
Validation loss: 1.6219177182002733

Epoch: 487| Step: 0
Training loss: 0.10738836973905563
Validation loss: 1.6474612271913918

Epoch: 6| Step: 1
Training loss: 0.1122351884841919
Validation loss: 1.6327574163354852

Epoch: 6| Step: 2
Training loss: 0.10594356805086136
Validation loss: 1.636322259902954

Epoch: 6| Step: 3
Training loss: 0.34816795587539673
Validation loss: 1.6659812363245154

Epoch: 6| Step: 4
Training loss: 0.10931544005870819
Validation loss: 1.6373224976242229

Epoch: 6| Step: 5
Training loss: 0.11853228509426117
Validation loss: 1.6235753349078599

Epoch: 6| Step: 6
Training loss: 0.14346566796302795
Validation loss: 1.6143088520214122

Epoch: 6| Step: 7
Training loss: 0.10979106277227402
Validation loss: 1.584226676212844

Epoch: 6| Step: 8
Training loss: 0.08491627126932144
Validation loss: 1.6014834155318558

Epoch: 6| Step: 9
Training loss: 0.1288861334323883
Validation loss: 1.600739973847584

Epoch: 6| Step: 10
Training loss: 0.14294391870498657
Validation loss: 1.623839278374949

Epoch: 6| Step: 11
Training loss: 0.13812033832073212
Validation loss: 1.6024036599743752

Epoch: 6| Step: 12
Training loss: 0.13871686160564423
Validation loss: 1.6122710576621435

Epoch: 6| Step: 13
Training loss: 0.07562826573848724
Validation loss: 1.6013798316319783

Epoch: 488| Step: 0
Training loss: 0.08645960688591003
Validation loss: 1.5721111528335079

Epoch: 6| Step: 1
Training loss: 0.08791830390691757
Validation loss: 1.5890610628230597

Epoch: 6| Step: 2
Training loss: 0.15157340466976166
Validation loss: 1.5903047502681773

Epoch: 6| Step: 3
Training loss: 0.10751429200172424
Validation loss: 1.5701878827105287

Epoch: 6| Step: 4
Training loss: 0.14403080940246582
Validation loss: 1.5624199195574688

Epoch: 6| Step: 5
Training loss: 0.16773678362369537
Validation loss: 1.5578166720687703

Epoch: 6| Step: 6
Training loss: 0.08740359544754028
Validation loss: 1.5622383189457718

Epoch: 6| Step: 7
Training loss: 0.13563022017478943
Validation loss: 1.561822732289632

Epoch: 6| Step: 8
Training loss: 0.11239954084157944
Validation loss: 1.605251504528907

Epoch: 6| Step: 9
Training loss: 0.0866042822599411
Validation loss: 1.582432157249861

Epoch: 6| Step: 10
Training loss: 0.1324521005153656
Validation loss: 1.6466979262649373

Epoch: 6| Step: 11
Training loss: 0.0951194316148758
Validation loss: 1.6635547517448344

Epoch: 6| Step: 12
Training loss: 0.3431941866874695
Validation loss: 1.6842747516529535

Epoch: 6| Step: 13
Training loss: 0.22064359486103058
Validation loss: 1.6777134005741408

Epoch: 489| Step: 0
Training loss: 0.2000853717327118
Validation loss: 1.6981691134873258

Epoch: 6| Step: 1
Training loss: 0.09855972975492477
Validation loss: 1.6245860463829451

Epoch: 6| Step: 2
Training loss: 0.1452699601650238
Validation loss: 1.6156199119424308

Epoch: 6| Step: 3
Training loss: 0.08301910012960434
Validation loss: 1.611621864380375

Epoch: 6| Step: 4
Training loss: 0.10393661260604858
Validation loss: 1.5679968967232654

Epoch: 6| Step: 5
Training loss: 0.13088460266590118
Validation loss: 1.55353299520349

Epoch: 6| Step: 6
Training loss: 0.16139790415763855
Validation loss: 1.5517566255343858

Epoch: 6| Step: 7
Training loss: 0.09168010950088501
Validation loss: 1.5409604400716803

Epoch: 6| Step: 8
Training loss: 0.09268760681152344
Validation loss: 1.5719817505087903

Epoch: 6| Step: 9
Training loss: 0.32047373056411743
Validation loss: 1.577623442936969

Epoch: 6| Step: 10
Training loss: 0.10781791806221008
Validation loss: 1.5563433042136572

Epoch: 6| Step: 11
Training loss: 0.13067029416561127
Validation loss: 1.577359954516093

Epoch: 6| Step: 12
Training loss: 0.06718632578849792
Validation loss: 1.5904262552979171

Epoch: 6| Step: 13
Training loss: 0.21249930560588837
Validation loss: 1.6225303872939079

Epoch: 490| Step: 0
Training loss: 0.12565180659294128
Validation loss: 1.5931524948407245

Epoch: 6| Step: 1
Training loss: 0.08288989216089249
Validation loss: 1.5961839204193444

Epoch: 6| Step: 2
Training loss: 0.1255239099264145
Validation loss: 1.6246219681155296

Epoch: 6| Step: 3
Training loss: 0.08823957294225693
Validation loss: 1.6462506171195739

Epoch: 6| Step: 4
Training loss: 0.1634715348482132
Validation loss: 1.6371224554636146

Epoch: 6| Step: 5
Training loss: 0.10403445363044739
Validation loss: 1.6108892617687103

Epoch: 6| Step: 6
Training loss: 0.14010407030582428
Validation loss: 1.630257547542613

Epoch: 6| Step: 7
Training loss: 0.11216464638710022
Validation loss: 1.5679360910128521

Epoch: 6| Step: 8
Training loss: 0.30196449160575867
Validation loss: 1.5536252452481178

Epoch: 6| Step: 9
Training loss: 0.06225787103176117
Validation loss: 1.5983535935801845

Epoch: 6| Step: 10
Training loss: 0.09131703525781631
Validation loss: 1.5854328716954877

Epoch: 6| Step: 11
Training loss: 0.23944352567195892
Validation loss: 1.5837867836798392

Epoch: 6| Step: 12
Training loss: 0.10761371999979019
Validation loss: 1.6179412872560563

Epoch: 6| Step: 13
Training loss: 0.08386998623609543
Validation loss: 1.5739442238243677

Epoch: 491| Step: 0
Training loss: 0.1673073023557663
Validation loss: 1.5971158524995208

Epoch: 6| Step: 1
Training loss: 0.1506575345993042
Validation loss: 1.6129012697486467

Epoch: 6| Step: 2
Training loss: 0.3275255858898163
Validation loss: 1.612915148017227

Epoch: 6| Step: 3
Training loss: 0.10876543074846268
Validation loss: 1.6334710659519318

Epoch: 6| Step: 4
Training loss: 0.08109067380428314
Validation loss: 1.6414777066117974

Epoch: 6| Step: 5
Training loss: 0.12105946987867355
Validation loss: 1.6345126026420183

Epoch: 6| Step: 6
Training loss: 0.09378264844417572
Validation loss: 1.6147322321450839

Epoch: 6| Step: 7
Training loss: 0.10663402080535889
Validation loss: 1.6173491618966545

Epoch: 6| Step: 8
Training loss: 0.07665027678012848
Validation loss: 1.627899964650472

Epoch: 6| Step: 9
Training loss: 0.08408299088478088
Validation loss: 1.6293927828470867

Epoch: 6| Step: 10
Training loss: 0.08618173748254776
Validation loss: 1.6545029096705939

Epoch: 6| Step: 11
Training loss: 0.2023473083972931
Validation loss: 1.6227121276240195

Epoch: 6| Step: 12
Training loss: 0.14067256450653076
Validation loss: 1.635607018265673

Epoch: 6| Step: 13
Training loss: 0.08719133585691452
Validation loss: 1.6217608477479668

Epoch: 492| Step: 0
Training loss: 0.09399986267089844
Validation loss: 1.6133979648672125

Epoch: 6| Step: 1
Training loss: 0.10442860424518585
Validation loss: 1.5722804197701075

Epoch: 6| Step: 2
Training loss: 0.18960216641426086
Validation loss: 1.5902412514532767

Epoch: 6| Step: 3
Training loss: 0.09910376369953156
Validation loss: 1.6100176149798977

Epoch: 6| Step: 4
Training loss: 0.08242465555667877
Validation loss: 1.5710305872783865

Epoch: 6| Step: 5
Training loss: 0.11669597774744034
Validation loss: 1.577834843307413

Epoch: 6| Step: 6
Training loss: 0.20780515670776367
Validation loss: 1.606597633771999

Epoch: 6| Step: 7
Training loss: 0.4126366674900055
Validation loss: 1.6012999864034756

Epoch: 6| Step: 8
Training loss: 0.07214462757110596
Validation loss: 1.5938341976493917

Epoch: 6| Step: 9
Training loss: 0.08231961727142334
Validation loss: 1.601781605392374

Epoch: 6| Step: 10
Training loss: 0.13615682721138
Validation loss: 1.578527021151717

Epoch: 6| Step: 11
Training loss: 0.1391054093837738
Validation loss: 1.6259630251956243

Epoch: 6| Step: 12
Training loss: 0.20415884256362915
Validation loss: 1.6174245175494943

Epoch: 6| Step: 13
Training loss: 0.18679603934288025
Validation loss: 1.6153829789930774

Epoch: 493| Step: 0
Training loss: 0.08838322758674622
Validation loss: 1.5869414191092215

Epoch: 6| Step: 1
Training loss: 0.08169084787368774
Validation loss: 1.5970899687018445

Epoch: 6| Step: 2
Training loss: 0.14085353910923004
Validation loss: 1.5895630595504597

Epoch: 6| Step: 3
Training loss: 0.11324627697467804
Validation loss: 1.5832467066344393

Epoch: 6| Step: 4
Training loss: 0.13970594108104706
Validation loss: 1.5694083629115936

Epoch: 6| Step: 5
Training loss: 0.14437779784202576
Validation loss: 1.5539958054019558

Epoch: 6| Step: 6
Training loss: 0.20823872089385986
Validation loss: 1.54964699668269

Epoch: 6| Step: 7
Training loss: 0.11859196424484253
Validation loss: 1.5453637043635051

Epoch: 6| Step: 8
Training loss: 0.055938757956027985
Validation loss: 1.592896807578302

Epoch: 6| Step: 9
Training loss: 0.13472938537597656
Validation loss: 1.5766390010874758

Epoch: 6| Step: 10
Training loss: 0.12981325387954712
Validation loss: 1.6140748031677739

Epoch: 6| Step: 11
Training loss: 0.07944367825984955
Validation loss: 1.6271692911783855

Epoch: 6| Step: 12
Training loss: 0.3206683099269867
Validation loss: 1.640880036097701

Epoch: 6| Step: 13
Training loss: 0.11967582255601883
Validation loss: 1.6511062627197595

Epoch: 494| Step: 0
Training loss: 0.11021710932254791
Validation loss: 1.6569242964508712

Epoch: 6| Step: 1
Training loss: 0.10897204279899597
Validation loss: 1.6534816424051921

Epoch: 6| Step: 2
Training loss: 0.18168285489082336
Validation loss: 1.6028145974682224

Epoch: 6| Step: 3
Training loss: 0.20635366439819336
Validation loss: 1.638366840218985

Epoch: 6| Step: 4
Training loss: 0.15914589166641235
Validation loss: 1.5928597437438143

Epoch: 6| Step: 5
Training loss: 0.1431473046541214
Validation loss: 1.5619168973738147

Epoch: 6| Step: 6
Training loss: 0.13414953649044037
Validation loss: 1.533649709916884

Epoch: 6| Step: 7
Training loss: 0.14092683792114258
Validation loss: 1.5110822159756896

Epoch: 6| Step: 8
Training loss: 0.12537075579166412
Validation loss: 1.5103423787701515

Epoch: 6| Step: 9
Training loss: 0.16381660103797913
Validation loss: 1.5043999700136081

Epoch: 6| Step: 10
Training loss: 0.3194049894809723
Validation loss: 1.5093038018031786

Epoch: 6| Step: 11
Training loss: 0.07918718457221985
Validation loss: 1.5494993476457493

Epoch: 6| Step: 12
Training loss: 0.13290336728096008
Validation loss: 1.5087985838613203

Epoch: 6| Step: 13
Training loss: 0.14781159162521362
Validation loss: 1.5452379411266697

Epoch: 495| Step: 0
Training loss: 0.11601836234331131
Validation loss: 1.5549325821220235

Epoch: 6| Step: 1
Training loss: 0.08080905675888062
Validation loss: 1.5701940777481243

Epoch: 6| Step: 2
Training loss: 0.30269473791122437
Validation loss: 1.582664083409053

Epoch: 6| Step: 3
Training loss: 0.08438844233751297
Validation loss: 1.6418877122222737

Epoch: 6| Step: 4
Training loss: 0.10828599333763123
Validation loss: 1.65131426113908

Epoch: 6| Step: 5
Training loss: 0.11595970392227173
Validation loss: 1.6566558448217248

Epoch: 6| Step: 6
Training loss: 0.15382340550422668
Validation loss: 1.6707853450570056

Epoch: 6| Step: 7
Training loss: 0.12021131068468094
Validation loss: 1.6637339027979041

Epoch: 6| Step: 8
Training loss: 0.11897337436676025
Validation loss: 1.6882748744821037

Epoch: 6| Step: 9
Training loss: 0.14991027116775513
Validation loss: 1.6485535765206942

Epoch: 6| Step: 10
Training loss: 0.10396227240562439
Validation loss: 1.6196698091363395

Epoch: 6| Step: 11
Training loss: 0.24719293415546417
Validation loss: 1.6236015994061705

Epoch: 6| Step: 12
Training loss: 0.17149922251701355
Validation loss: 1.6045897865808139

Epoch: 6| Step: 13
Training loss: 0.0743388831615448
Validation loss: 1.5906115936976608

Epoch: 496| Step: 0
Training loss: 0.19952112436294556
Validation loss: 1.5753083049610097

Epoch: 6| Step: 1
Training loss: 0.13889703154563904
Validation loss: 1.5598377758456814

Epoch: 6| Step: 2
Training loss: 0.35996338725090027
Validation loss: 1.5655938886827039

Epoch: 6| Step: 3
Training loss: 0.1242968812584877
Validation loss: 1.5664932291994813

Epoch: 6| Step: 4
Training loss: 0.13485047221183777
Validation loss: 1.5517839065162085

Epoch: 6| Step: 5
Training loss: 0.08745496720075607
Validation loss: 1.5778785264620216

Epoch: 6| Step: 6
Training loss: 0.07965634763240814
Validation loss: 1.5442842296374741

Epoch: 6| Step: 7
Training loss: 0.16170811653137207
Validation loss: 1.5605288115880822

Epoch: 6| Step: 8
Training loss: 0.08565982431173325
Validation loss: 1.5449049831718527

Epoch: 6| Step: 9
Training loss: 0.10611317306756973
Validation loss: 1.5493895366627684

Epoch: 6| Step: 10
Training loss: 0.1276969313621521
Validation loss: 1.5793733955711446

Epoch: 6| Step: 11
Training loss: 0.19084465503692627
Validation loss: 1.5513549120195451

Epoch: 6| Step: 12
Training loss: 0.12503401935100555
Validation loss: 1.570790231868785

Epoch: 6| Step: 13
Training loss: 0.09915992617607117
Validation loss: 1.5755536722880539

Epoch: 497| Step: 0
Training loss: 0.22002434730529785
Validation loss: 1.5666491254683463

Epoch: 6| Step: 1
Training loss: 0.08628398180007935
Validation loss: 1.5938895466507121

Epoch: 6| Step: 2
Training loss: 0.19998252391815186
Validation loss: 1.5648174683252971

Epoch: 6| Step: 3
Training loss: 0.11263629794120789
Validation loss: 1.5606479901139454

Epoch: 6| Step: 4
Training loss: 0.1288277804851532
Validation loss: 1.5830164199234338

Epoch: 6| Step: 5
Training loss: 0.06881630420684814
Validation loss: 1.592413806146191

Epoch: 6| Step: 6
Training loss: 0.26486480236053467
Validation loss: 1.5815892046497715

Epoch: 6| Step: 7
Training loss: 0.05645487830042839
Validation loss: 1.6147371235714163

Epoch: 6| Step: 8
Training loss: 0.10280458629131317
Validation loss: 1.6247152128527242

Epoch: 6| Step: 9
Training loss: 0.12306009232997894
Validation loss: 1.6157506178784113

Epoch: 6| Step: 10
Training loss: 0.145460844039917
Validation loss: 1.6137351541108982

Epoch: 6| Step: 11
Training loss: 0.15565258264541626
Validation loss: 1.5863157497939242

Epoch: 6| Step: 12
Training loss: 0.11035841703414917
Validation loss: 1.6340660292615172

Epoch: 6| Step: 13
Training loss: 0.14334744215011597
Validation loss: 1.6236946839158253

Epoch: 498| Step: 0
Training loss: 0.1214478388428688
Validation loss: 1.5913474841784405

Epoch: 6| Step: 1
Training loss: 0.14635303616523743
Validation loss: 1.6576992170785063

Epoch: 6| Step: 2
Training loss: 0.10966330021619797
Validation loss: 1.639212905719716

Epoch: 6| Step: 3
Training loss: 0.07864376157522202
Validation loss: 1.618764672228085

Epoch: 6| Step: 4
Training loss: 0.13270384073257446
Validation loss: 1.637267706855651

Epoch: 6| Step: 5
Training loss: 0.08186326175928116
Validation loss: 1.6367877503877044

Epoch: 6| Step: 6
Training loss: 0.0887620598077774
Validation loss: 1.6335986686009232

Epoch: 6| Step: 7
Training loss: 0.2111286222934723
Validation loss: 1.6177048260165798

Epoch: 6| Step: 8
Training loss: 0.11506310105323792
Validation loss: 1.630129474465565

Epoch: 6| Step: 9
Training loss: 0.28543105721473694
Validation loss: 1.624696716185539

Epoch: 6| Step: 10
Training loss: 0.08568836003541946
Validation loss: 1.6108801903263215

Epoch: 6| Step: 11
Training loss: 0.13983896374702454
Validation loss: 1.6010997346652451

Epoch: 6| Step: 12
Training loss: 0.1892382651567459
Validation loss: 1.585880857641979

Epoch: 6| Step: 13
Training loss: 0.19677980244159698
Validation loss: 1.5594633881763746

Epoch: 499| Step: 0
Training loss: 0.1237674206495285
Validation loss: 1.5686056754922355

Epoch: 6| Step: 1
Training loss: 0.12232863157987595
Validation loss: 1.5546512603759766

Epoch: 6| Step: 2
Training loss: 0.11456938832998276
Validation loss: 1.5950768404109503

Epoch: 6| Step: 3
Training loss: 0.35043224692344666
Validation loss: 1.553699649790282

Epoch: 6| Step: 4
Training loss: 0.12199034541845322
Validation loss: 1.6171919876529324

Epoch: 6| Step: 5
Training loss: 0.12337088584899902
Validation loss: 1.6388995903794483

Epoch: 6| Step: 6
Training loss: 0.07896661013364792
Validation loss: 1.6534517913736322

Epoch: 6| Step: 7
Training loss: 0.09957217425107956
Validation loss: 1.653384768834678

Epoch: 6| Step: 8
Training loss: 0.16543510556221008
Validation loss: 1.6754579364612538

Epoch: 6| Step: 9
Training loss: 0.13199326395988464
Validation loss: 1.7015287645401493

Epoch: 6| Step: 10
Training loss: 0.05788179486989975
Validation loss: 1.683941005378641

Epoch: 6| Step: 11
Training loss: 0.13819482922554016
Validation loss: 1.6713716060884538

Epoch: 6| Step: 12
Training loss: 0.21311619877815247
Validation loss: 1.623391475728763

Epoch: 6| Step: 13
Training loss: 0.07047455757856369
Validation loss: 1.6147203112161288

Epoch: 500| Step: 0
Training loss: 0.0694158747792244
Validation loss: 1.6069476309642996

Epoch: 6| Step: 1
Training loss: 0.12834110856056213
Validation loss: 1.6082438256150933

Epoch: 6| Step: 2
Training loss: 0.10220996290445328
Validation loss: 1.619413815518861

Epoch: 6| Step: 3
Training loss: 0.10541661828756332
Validation loss: 1.5734653088354296

Epoch: 6| Step: 4
Training loss: 0.15918710827827454
Validation loss: 1.6153392394383748

Epoch: 6| Step: 5
Training loss: 0.19170919060707092
Validation loss: 1.6164366558033934

Epoch: 6| Step: 6
Training loss: 0.10558858513832092
Validation loss: 1.6022556276731594

Epoch: 6| Step: 7
Training loss: 0.09177888929843903
Validation loss: 1.6465414070313977

Epoch: 6| Step: 8
Training loss: 0.153615340590477
Validation loss: 1.6307924511612102

Epoch: 6| Step: 9
Training loss: 0.10274233669042587
Validation loss: 1.649264435614309

Epoch: 6| Step: 10
Training loss: 0.058145444840192795
Validation loss: 1.6522597100145073

Epoch: 6| Step: 11
Training loss: 0.384769469499588
Validation loss: 1.6650783387563561

Epoch: 6| Step: 12
Training loss: 0.12987443804740906
Validation loss: 1.6549840101631739

Epoch: 6| Step: 13
Training loss: 0.18752709031105042
Validation loss: 1.6527158201381724

Testing loss: 2.129534509446886
